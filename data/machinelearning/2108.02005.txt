A purely data-driven framework for prediction,
optimization, and control of networked processes:
application to networked SIS epidemic model

Ali Tavasoli1, Teague Henry2,3, Heman Shakeri2 ∗

August 5, 2021

Abstract

Networks are landmarks of many complex phenomena where interweaving inter-
actions between diﬀerent agents transform simple local rule-sets into nonlinear emer-
gent behaviors. While some recent studies unveil associations between the network
structure and the underlying dynamical process, identifying stochastic nonlinear dy-
namical processes continues to be an outstanding problem. Here we develop a simple
data-driven framework based on operator-theoretic techniques to identify and control
stochastic nonlinear dynamics taking place over large-scale networks. The proposed
approach requires no prior knowledge of the network structure and identiﬁes the
underlying dynamics solely using a collection of two-step snapshots of the states.
This data-driven system identiﬁcation is achieved by using the Koopman operator to
ﬁnd a low dimensional representation of the dynamical patterns that evolve linearly.
Further, we use the global linear Koopman model to solve critical control problems
by applying to model predictive control (MPC)–typically, a challenging proposition
when applied to large networks. We show that our proposed approach tackles this
by converting the original nonlinear programming into a more tractable optimization
problem that is both convex and with far fewer variables.

Keywords: Networked dynamical process, data-driven model, epidemic control, Koopman
operator.

∗1Department of Mechanical Engineering, Payame Noor University, Tehran, Iran. 2School of Data Sci-
ence, University of Virginia, Charlottesville, Virginia. 3Department of Psychology, University of Virginia,
Charlottesville, Virginia.

1

1
2
0
2

g
u
A
1

]
I
S
.
s
c
[

1
v
5
0
0
2
0
.
8
0
1
2
:
v
i
X
r
a

 
 
 
 
 
 
1

Introduction

Identifying dynamical systems from observations is central to many scientiﬁc disciplines,
including physical, biological, computer, social sciences, and economics; and opens doors for
engineering and interventions (Wang et al., 2016). Although inferring the network structure
may be impossible in practice, as diﬀerent networks may display similar dynamical behav-
ior, proper identiﬁcation of the dynamics remains feasible (Prasse and Mieghem, 2020).
Besides enabling accurate prediction of the network process, the identiﬁed model must be
well suited for practically implementable strategies to control the underlying dynamics that
are both stochastic and nonlinear.

Deducing laws that govern the relationship between a system’s structure and functions is
a formidable challenge due to diﬃculties associated with nonlinearities, stochasticity, high-
dimensions, and inherent correlations between the network topology and the underlying
dynamical process. As such, approaches such as mean-ﬁeld approximation (Van Mieghem
et al., 2009; Sahneh et al., 2013) have been proposed during recent years to model several
dynamical processes over networks and oﬀer good estimations under limited circumstances.
On the other hand, rapidly developing information technologies leave us with a wealth
of data over larger and more diverse networks; further spurring data-driven approaches
to construct models without requiring explicit prior knowledge when studying diﬀerent
dynamical processes over networks.

Our main goal is to establish a data-driven framework for the identiﬁcation and control
of network processes. Overall, a systematic and accurate method for identifying, estimating,
and controlling spatiotemporal dynamical features of network processes from data is still an
open and challenging issue. To ﬁll this gap, we leverage modern machine learning techniques
to model network dynamics in the operator-theoretic setting eﬀectively. This way, we are
provided with a purely data-driven approach that assumes no knowledge or identiﬁcation of
network parameters and structure. Furthermore, eigenfunctions of the Koopman operator
summarize the network processes on low-order manifolds that are evolving linearly. We
further establish a tractable framework based on the obtained representation to resolve
challenging optimization and control tasks over networks. Finally, we demonstrate the
use of the Koopman operator for system identiﬁcation and control by applying it to a
common model of disease spread on networks, the susceptible-infected-susceptible (SIS)
model (Van Mieghem et al., 2009). We show that approximating the complex non-linear
dynamics of disease spreading using the Koopman operator allows one to develop optimal
control regimes that can quickly mitigate the outbreak, a signiﬁcant improvement over a
uniform intervention strategy. Additionally, we show that eﬀective control over infection

2

rates can be accomplished using an appropriately chosen lower-dimensional representation
of the high dimensional Koopman operator.

1.1 Operator-theoretic approach for the analysis of high-dimensional

interconnected system

Recent advances in data analysis have shown that many complex systems possess dominant
low-dimensional invariant subspaces that are hidden in the high-dimensional ambient space,
an underlying structure that enables compact representations for modeling and control
(Brunton and Kutz, 2019). To infer these compact representations, operator-theoretic
frameworks have been used to address nonlinear relations between subspaces and provide a
principled linear embedding for dynamical systems. In particular, the Koopman operator
(Mezi´c, 2005) is an inﬁnite-dimensional linear operator that studies the time evolution of
measurement functions (observables) of the system state, and its spectral decomposition
completely characterizes the behavior of the nonlinear system (Brunton et al., 2021). One
underlying feature that builds up the Koopman success in the study of nonlinear dynamical
systems is its ﬁnite-dimensional representation connected with ﬁnding eﬀective coordinate
transformations in which the nonlinear dynamics appear linear. Stated another way, the
Koopman operator explores invariant sets of nonlinear observables that evolve linearly.
This is diﬀerent from conventional approaches that commonly rely on linearization and
are only locally valid. As such, the Koopman operator can be viewed as an extension of
Hartman–Grobman theorem–which is locally valid within a vicinity of hyperbolic stationary
points–into the whole basin of attraction. This oﬀers the prospect of prediction, estimation,
and control of nonlinear systems by standard methods developed for linear systems.

λ
|
|

The Koopman operator sketches a rich global picture of the nonlinear system by char-
acterizing several underlying features (Mauroy et al., 2020). For example, Koopman eigen-
functions at eigenvalue λ = 1 determine the invariant sets, and the eigenfunctions associated
with
= 1 form invariant partitions of dynamics (Mezi´c, 2005). In fact, such eigenfunc-
tions are connected with ergodic and harmonic quotients that reveal coherent structures
in dynamics (Budiˇsi´c and Mezi´c, 2012). Level sets of Koopman eigenfunctions also char-
acterize the sets of points (known as isochrons and isostables) that partition the basin
of attraction of limit cycles and ﬁxed points, and reduce such dynamics to action–angle
coordinates (Mauroy and Mezi´c, 2012; Mauroy et al., 2013). Mauroy and Mezi´c (2016)
established relationship between the existence of speciﬁc eigenfunctions of the Koopman
operator and the global stability property of ﬁxed points and limit cycles. Hence the Koop-
man operator oﬀers a framework better suited for control by circumventing complexities

3

due to nonlinearity and transforming the nonlinear dynamics into globally linear represen-
tations (Proctor et al., 2018; Brunton et al., 2021); e.g. Brunton et al. (2017) decomposed
chaotic systems into intermittently forced linear systems.

In recent years, three main approaches for numerical computation of the Koopman
operator are generalized: Laplace analysis, ﬁnite section methods, and Krylov subspace
methods (Mezi´c, 2020). Particularly ﬁnite section methods construct an approximate op-
erator acting on a ﬁnite-dimensional function subspace. The best known such method
is dynamic mode decomposition (DMD) (Schmid, 2010) that features state observables.
DMD works based on proper orthogonal decomposition (POD) of high-dimensional lin-
ear measurements to extract dynamical patterns that evolve on low-dimensional manifolds
(Schmid, 2010; Tu et al., 2014). Therefore, DMD provides a model in terms of the reduced
sets of modes and their progression in time. Although DMD has evolved in recent years
into a popular approach to extract linear models from linear measurements (Kutz et al.,
2016a), it inherits the limitations of singular value decomposition and lacks suﬃcient del-
icacy to dissect rich nonlinear phenomena and the associated transient dynamics (Kutz
et al., 2016b, Chapter 1).

More recently, the extended DMD (EDMD) (Williams et al., 2015) was developed to
account for the limitations of DMD, and employs nonlinear observables to recognize a ﬁnite-
dimensional invariant subset of the Koopman operator that converges to the Galerkin
approximation. Other variants of DMD are developed to represent diﬀerent dynamical
systems or handle numerical challenges, to mention a few: Kernel-DMD (Williams et al.,
2015), Hankel-DMD (Arbabi and Mezi´c, 2017), HAVOK-DMD (Brunton et al., 2017),
tensor-based DMD (Fujii and Kawahara, 2019), and recent works that leverage dictionary
learning (Li et al., 2017) and deep learning architectures (Lusch et al., 2018; Otto and
Rowley, 2019; Mardt et al., 2020; Pan and Duraisamy, 2020).

The simpliﬁed representation of complex nonlinear dynamics using the Koopman opera-
tor provides exciting opportunities to tackle the challenges in controlling nonlinear systems
(Brunton et al., 2016). Korda and Mezi´c (2020) put forward a convex optimization frame-
work for optimal construction of Koopman eigenfunctions for prediction and control. Sev-
eral extensions are developed for actuated and controlled systems in Williams et al. (2016);
Kaiser et al. (2017a); Proctor et al. (2016, 2018). These approaches have recently applied
to a wealth of real-world problems like ﬂuid dynamics (Arbabi and Mezi´c, 2017; Rowley
and Dawson, 2017a), power grids (Korda et al., 2018), molecular dynamics (Wehmeyer
and No´e, 2018), time series classiﬁcation (Surana, 2018), robotic systems (Abraham and
Murphey, 2019; Bruder et al., 2020), energy consumption in buildings (Boskic et al., 2020;
Hiramatsu et al., 2020), traﬃc (Avila and Mezi´c, 2020), spacecraft (Chen and Shan, 2020),

4

and hydraulic fracturing operation (Narasingam and Kwon, 2020).

Given that the Koopman operator’s lower-order representation of a complex non-linear
system is linear, it is very appealing from the perspective of developing control schemes
(Mauroy et al., 2020). Methods for the optimization and on-line control of linear systems
are well developed, and the potential to apply these methods productively to the control of
complex non-linear systems is a marked advantage of the Koopman operator approach. We
want to stress that the Koopman operator captures the dynamics in the whole attraction
basin, and thus it can be a more accurate replacement for locally linearized models in these
approaches. This is achieved by proper nonlinear measurements in the space of intrinsic
coordinates that yield complete information about dynamics. Consequently, the suggested
linear predictor is immediately amenable to the range of mature control design techniques,
such as optimal control (Brunton et al., 2016; Kaiser et al., 2017b; Das et al., 2018) or
switching control (Sootla et al., 2018). In particular, since the Koopman works well for
short prediction horizons, it is promising for model predictive control (MPC) that needs
prediction over a few steps (Korda and Mezi´c, 2018). Furthermore, Koopman yields a linear
predictor that translates the original nonlinear MPC into a convex optimization problem
(Korda and Mezi´c, 2018) that is more appealing for numerical treatments. The Koopman
operator has also proven successful for resolving control challenges of partial diﬀerential
equations (PDEs) by mapping the original nonlinear inﬁnite-dimensional control problem
into a low-dimensional linear one (Peitz and Klus, 2019). Further advantages of this ap-
proach in resolving MPC problems can be found in optimizing power grids (Korda et al.,
2018), active learning of dynamics for robotic systems control (Abraham and Murphey,
2019), and spacecraft altitude stabilization (Chen and Shan, 2020).

1.2 Spreading Processes on Networks

Control of dynamical processes over networks is examined recently for mitigation of net-
worked spreading processes. These spreading processes are often used to model the spread
of disease through networks that represent person to person contact or interaction, which
suggests that eﬀective methods capable of controlling spreading processes have signiﬁcant
public health implications. Preciado and Jadbabaie (2009) analyze network spectral prop-
erties and consider removing nodes and removing links as control inputs to tame an initial
viral infection. In this regard, Van Mieghem et al. (2011) study two problems of optimal
node removal and optimal link removal and show them to be NP-complete and NP-hard,
respectively and propose greedy strategies based on spectral measures.

Worst-case analysis shows that completely removing nodes or links is ineﬀective–not to

5

mention node/link removal in real world networks is often impractical, illegal, or both–and
latter works considered controlling disease spreading processes by preventive resources and
promoting corrective policies. These resources and policies do not alter the structure of the
network itself, but rather theoretically modulate the susceptibility to infection of individual
nodes and/or the probability that infection will spread along speciﬁc links. Preciado et al.
(2014) consider both rate-constrained allocation and budget-constrained allocation simul-
taneously in the framework of geometric programming (Preciado et al., 2014). Nowzari
et al. (2017); Watkins et al. (2018); Shakeri et al. (2015) investigate other variants and
provide general solutions.

The current main strategies for controlling disease spread on networks are to ﬁrst, allo-
cate resources over the network components (individuals or their ties) to ﬁnd the minimum
required budget to eradicate the disease at the desired rate and second, mitigating the
spread in the fastest possible decay rate by allocating a given ﬁxed budget. The optimiza-
tion problems have discrete variables, and relaxing them by letting spreading rates take
values in a feasible continuous interval aid in numerical solutions.

One major limitation of the previously described network-based allocation approaches
is that they are oﬀ-line and thereby without feedback from the current state of the network.
This means that these allocation strategies are incapable of adapting to changing demands,
leading to at best a non-optimal resource allocation, and at worst a failure to control
the disease process due to changing network conditions. Optimal control strategies are
employed to solve this issue by allowing the control allocation to vary over time (Khanafer
and Ba¸sar, 2014; Eshghi et al., 2016); this approach is used in Kandhway and Kuri (2016);
He and Van Mieghem (2019) for application in virus spreading problems and Dashtbali
et al. (2020) for investigating social distancing in response to epidemic using diﬀerential
games approach.

Watkins et al. (2020) use MPC for optimal containment of epidemic over networks. In
particular, and during the recent outbreak of COVID-19, the signiﬁcance of identifying
and intercepting the virus spread over networks is more evident. Carli et al. (2020) study
mitigating the outbreak using a multi-region scenario, with the underlying network repre-
senting inter-region mobility and propose a model-based MPC where the parameters of the
model are ﬁtted based on the collected data from the network of Italian regions.

Despite the vast literature, ﬁnding practical approaches for controlling epidemics over
complex networks remains an outstanding problem with real-world assumptions and the
corresponding uncertainties and unknowns that pose challenges for model-based approaches.
We present a summary of the main results here. Firstly, the existing control methods are
specialized for deterministic models often approximated from the original stochastic mod-

6

els. Despite establishing connections between the two, these connections are only relevant
for simpliﬁed cases, and additionally, the connections between control solutions of the two
models are unclear. Second, the current approaches admit centralized solutions of compu-
tational burden, making them intractable for large networks. Third, conventional methods
assume no uncertainties and require complete knowledge of everything, including natural
recovery rates, infection rates, state information, and network topologies. Avoiding the
above simplifying assumptions while having tools that can handle network and parameter
variations are necessary for practical approaches.

1.3 Contribution statement

This work attempts to address the shortcomings of the available approaches discussed
above, where we consider identifying and controlling epidemics solely based on our spatio-
temporal observations. Our approach is intended to tackle identifying and control of
stochastic processes over complex networks using several features; First, our method is
purely data-driven and have no assumptions about network parameters, structure, or the
underlying dynamical process, and is based on the original stochastic process that produced
the data at the outset. Second, to reach an eﬀective data-driven method that is tractable
for optimization and control over large networks, we use the latest achievements in machine
learning and operator-theoretic to identify a Koopman representation that is interpretable,
low-dimensional, and linear. This way, the underlying high-dimensional dynamics is repre-
sented through extracting the most eﬀective modes evolving linearly under the networked
processes. Third, we revisit the important MPC problem over complex networks and show
our proposed approach maps the original high-dimensional nonlinear optimization prob-
lem into a low-dimensional convex representation that is well suited for existing numerical
approaches and enables real-time softwares.

We organize the paper as follows. Section 2 presents the data-driven Koopman iden-
tiﬁcation of stochastic processes over networks. Section 3 explains the nonlinear MPC
problem over networks and its transformation into Koopman MPC. In Section 4, we ap-
ply our approach to a Markov process representing the SIS epidemic model over network.
Section 5 is devoted to concluding remarks and discussion.

7

2 Koopman operator

2.1 Problem statement

We consider a controlled discrete-time Markov process taking place over a network as

F (x, u; ω)

x

(cid:55)→

(1)

Rn is the system state vector in the state space

Rl
where x
∈ M ⊆
is the control input, and ω
Ω is an element in the probability space associated with
the stochastic dynamics Ω and probability measure P . The aim is to obtain a nonlinear
R, from the
embedding mapping (transformation) ψ = [ψ1, ..., ψN ]T , with ψi :
to a subset of RN that enables us to construct a linear predictor for
original state space
the expected value E[x(k)] of the form

M −→

∈ U ⊆

, u

M

M

∈

z(k + 1) = Az(k) + Bu(k)
E[ˆx(k)
1)] = Cz(k)

ˆx(k
−
|
z0 = ψ(x0)

(2)

∈

∈

∈

∈ M ⊆

RN ×l, C

RN ×N , B

Rn to the lifted state z

Rn×N , and the output E[ˆx(k)
ˆx(k
|

1)] is used for
where A
prediction and control of the expected value of the state vector x given the initial condition
x0. Therefore, we seek a linear system that faithfully represents the original nonlinear
dynamical system. The key is ﬁnding proper transformation ψ that maps the original state
x
n, that evolves linearly–
though the number of dimensions N is still of concern for practical implementation, we
will postpone the discussion on reducing the dimensionality to Section 2.4. The predictor
model (2) is amenable to linear control design approaches in the lifted space z. Moreover,
u remains unlifted in (2) allowing direct use of linear constraints on input or/and states in
the lifted state. As long as the predictions of (2) are accurate for short time horizons, it is
desirable for the use of linear control methodologies (such as linear MPC).

RN , with (typically) N

(cid:29)

−

∈

Next we demonstrate that such transformation can be established in the framework of
Koopman operator by using data of the triplet form x(k), x(k + 1), u(k) (see Figure 1 for
a sketch of the main ideas in the paper).

2.2 Koopman operator for controlled stochastic processes

Koopman operator embeds the nonlinear dynamics into an appropriate Hilbert space
F
where the dynamics is linear and one can construct the predictor (2). Namely, Koopman

8

(a)

(b)

Figure 1: Main idea.
(a) Koopman identiﬁcation. We only collect stochastic (binary)
data in the form of m snapshots including (xi, ui, yi) with yi = F (xi, ui; ω). Although we
assume no prior knowledge of the system parameters, the underlying dynamics, or network
geometry, one can still incorporate available information to enrich the proposed analysis.
The Koopman operator is an inﬁnite-dimensional operator that speciﬁes how functions of
9
state evolve, so that it is projected into an (invariant) observables subspace, where the
lifting set ψ(x) mapps the original system into a linear one in higher dimension. For
eﬀective low-order modeling, a Koopman mode decomposition represents the dynamics in
the most eﬀective Koopman modes. (b) The Koopman operator translates the original
nonlinear MPC into a convex problem that is amenable for numerical solution. We further
use the reduced-order Koopman to decrease the size of the optimization.

ExperimentsNetworkwithstochasticdynamicsx7→F(x,u;ω)DatacollectionX=[x1,...,xm]U=[u1,...,um]Y=[y1,...,ym],yi=F(xi,ui;ω)MappingunderobservablesΨ(X)=[ψ(x1),...,ψ(xm)]E[Ψ(Y)]=E[ψ(y1),...,ψ(ym)]U=[u1,...,um]IdentifyingKoopmanoperatorApproximatingtheinﬁnitedi-mensionalKoopmanoperatorKwithaﬁniterankmatrixKKoopmanLinearpredictorz(k+1)=Az(k)+Bu(k)E[ˆx(k)|ˆx(k−1)]=Cz(k)(ˆxpredictionofx)KoopmanMPCminui,zizTpQpzp+qTpzp+Pp−1i=0zTiQizi+uTiRiui+qTizi+rTiuizi+1=Azi+Bui,i=0,...,p−1Eizi+Diui≤bi,i=0,...,p−1Epzp≤bpz0=ψ(x0)ppredictionhorizonNetworkStochasticdynamicsx7→F(x,u;ω)Koopmanlinearpredictorz(k+1)=Az(k)+Bu(k)E[ˆx(k)|ˆx(k−1)]=Cz(k)(ˆxpredictionofx)Ω

is a linear operator of inﬁnite dimension that takes a scalar observable-function g :

R belonging to

U ×
−→
function space
to fully describe the underlying dynamical system,
state vector x.

M ×
and gives its expected value evolution in the state space. The
is invariant under the action of the Koopman operator. Additionally,
must contain the components of the

F

F

F

Following Proctor et al. (2018), who generalize the Koopman operator for systems with

input, we consider the Koopman operator

:

K

F −→ F

for stochastic process (1) as

g] (xk, uk; ω) = E[g(F (xk, uk; ω), uk+1; ω)] = E[g(xk+1, uk+1; ω)]

(3)

[

K

with xk = x(k) and uk = u(k).
Including actuation in (3) renders the Koopman fam-
ily non-autonomous. In the equivalent autonomous formulation, Korda and Mezi´c (2018)
extend the system state to include all control sequences and apply the shift operator to
advance the observation of input. The Koopman operator’s spectral properties are di-
rectly connected with several geometric characteristics, e.g., invariant sets and partitions
(Mezi´c, 2005) or asymptotic behavior (Mauroy and Mezi´c, 2012; Mauroy et al., 2013), of
the underlying nonlinear system. Moreover, the Koopman modes associated with Koopman
eigenfunctions can yield the evolution of observables and the orbits of the system for all
initial conditions. In this regard, the Koopman operator gives a complete description of the
underlying nonlinear system, provided that the space of observables
spans the elements
is an eigenfunction of Koopman operator and λ its eigenvalue, then the
of x. If ϕ
are eigenfunctions of
spectral problem of Koopman operator reads
with eigenvalue λ1λ2. This
K
is an implication of the Koopman operator being (generally) inﬁnite-dimensional. Budiˇsi´c
et al. (2012) and Mauroy et al. (2020, Chapter 1) provide a detailed review of Koopman
operator properties.

with eigenvalues λ1 and λ2, then ϕ1ϕ2 is eigenfunction of

ϕ = λϕ. If ϕ1, ϕ2

∈ F

∈ F

K

K

F

K

The inﬁnite-dimensional Koopman operator

is approximated by its ﬁnite-dimensional
projection K using data-driven approaches that are well suited for this purpose. DMD pro-
vides a projection of Koopman operator onto the space of linear observables (Brunton and
Kutz, 2019) and EDMD produces more precise approximations by incorporating nonlinear
observables that result in a higher-dimensional approximation (see Williams et al. (2015);
Mauroy and Goncalves (2019) for deterministic and Wu and No´e (2020) for stochastic
systems). Using an extended state vector for systems including input and with the shift
operator of a known input proﬁle, Korda and Mezi´c (2018) argue that ﬁnite-dimensional
yields a predictor of the form (2). Speciﬁcally, K is
approximation K to the operator
of observables spanned by (ψi(x), u), where
the projection of
the lifting functions ψi, i = 1, ..., N, only act on the state x and the control input u

onto a subspace ¯

F ⊆ F

K

K

∈ U

10

remains unlifted1. As such, the control input appears linearly in the resulting model, which
is amenable for control design purposes.

2.3 Finite-dimensional projection using EDMD with control

Recent uses of Koopman operator in control architecture are focused in the context of
deterministic systems (Proctor et al., 2018; Korda and Mezi´c, 2018; Peitz and Klus, 2019;
Brunton et al., 2021); in particular, we follow Korda and Mezi´c (2018) and assume that
the data is collected in the form of m snapshots as

X = [x1, ..., xm], Y = [y1, ..., ym], U = [u1, ..., um], xi, yi

Rn, ui

Rl

∈

∈

where yi = F (xi, ui; ω). Unlike the original DMD formulation (Rowley et al., 2009; Schmid,
2010), the data need not be sequentially ordered along a single trajectory of (1) as yi =
x(i+1), and we generally use diﬀerent snapshot triples (xi, yi, ui) along diﬀerent trajectories
(corresponding to diﬀerent initial conditions with generally yi
= xi+1). The action of lifting
functions is then given as

Ψ(X) = [ψ(x1), ..., ψ(xm)]

where ψ(x) = [ψ1(x), ..., ψN (x)]T is a given dictionary of nonlinear functions. For stochastic
processes, we estimate the expected value of Ψ(Y) directly from experiments.

E[Ψ(Y)] = [E[ψ(y1)], ..., E[ψ(ym)]]

Then the matrices A, B, C in (2) are solutions of following optimization problems:

E[Ψ(Y)]

min
A,B (cid:107)

AΨ(X)

BU
(cid:107)

−

−

(4)

−
We solve 4 and 5 using the normal equations (see Korda and Mezi´c (2018) for a discussion
on the numerical considerations).

C (cid:107)

min

X

CΨ(X)
(cid:107)

(5)

1If subspace ¯
F
eigenvalues and eigenfunctions of
subspace ¯
F

is invariant under

K

is not known in advance, with K we obtain an approximation for

.

K

, then all of the eigenvalues and eigenfunctions of K are also
(Otto and Rowley, 2021). However, since usually such an invariant

K

11

(cid:54)
2.4 Reduced-order linear representation

Koopman operator embeds the networked nonlinear dynamical system into a linear system
but with a higher dimension. One desires a low-dimensional model in practice for fast
optimization and real-time control. In the context of linear measurements, the basic DMD
scheme extends to include exogenous eﬀects and uses a truncated set of decomposed low-
energy modes for order reduction (Proctor et al., 2016). Here, we develop this approach to
Koopman mode decomposition and establish reduced-order Koopman representation with
control. For this purpose, we start by a singular value decomposition

[Ψ(X)T U T ]T = U1Σ1V ∗
1

(6)

where U1 is bipartite, i.e., U1 = [U T
perform SVD on

11 U T

12]T based on the model dimensions. Second, we

where the truncation value is r; hence, a reduced Koopman model of order r is established.
The low-dimensional model matrices are computed as

E[Ψ(Y )] = U2Σ2V ∗
2 ,

(7)

˜A = U T
2
˜B = U T
2

E[Ψ(Y )]V1Σ−1
1 U T
11U2
E[Ψ(Y )]V1Σ−1
1 U12
˜C = CU2

(8)

Thus the Koopman model (2) reduces to the coordinate z = U T
2 ψ(x) by replacing A,
B, and C with ˜A, ˜B, and ˜C.
In this regard, we use the ﬁrst r Koopman modes to
construct a low-dimensional network process representation summarized in Algorithm 1.
This strategy’s success lies in the existence of a low-dimensional manifold on which the
underlying dynamics evolve. Although this manifold depends on the control input, we will
illustrate that this approach is suﬃciently powerful to eﬀectively capture manifolds for a
given input training range. In other words, while our observations are in high-dimension
over networks, the actual collective dynamics evolve in low-dimension. The accuracy of
this manifold identiﬁcation improves with narrowing the input training range. Peitz and
Klus (2019) partition the input space into a set of subspaces and extract a surrogate model
for each range; though the combinatorial nature of this approach prohibits its use on high-
dimensional input spaces present in networks.

12

Algorithm 1 Reduced Koopman identiﬁcation of networked dynamics with inputs
Inputs: Data matrices X, U , Ψ(X), and E[Ψ(Y )]
Outputs: Koopman model matrices ˜A, ˜B, ˜C
1: Choose a truncation value r
2: SVD: [Ψ(X)T U T ]T = U1Σ1V ∗
1
3: Use the number of observables N to bipartite U1 = [U T
4: SVD: E[Ψ(Y )] = U2Σ2V ∗
5: Solve (5) to get C
6: ˜A
U T
2

2 and truncate it for ﬁrst r modes

E[Ψ(Y )]V1Σ−1

E[Ψ(Y )]V1Σ−1

1 U12, ˜C

11U2, ˜B

11 U T

1 U T

CU2

12]T

U T
2

←

←

←

2.5 Choosing an appropriate subset in the function space

Under the assumption of suﬃciently rich basis and a large number of functions, one can
expect a small approximation error (Williams et al., 2015). However, it is an open question:
what type of observables will yield the best result for a speciﬁc problem. There are three
popular choices: Hermite polynomials, radial basis functions (RBFs), and discontinuous
spectral elements (Williams et al., 2015). A partially optimized space of observables can be
attained by ﬁrst selecting a parameterized feature space (Wu and No´e, 2020), e.g. Gaussian
RBFs parameterized with the smoothing parameter, and then optimize the associated
parameters (the smoothing parameter in case of Gaussian RBFs). Recent investigations of
dictionary learning representation by Li et al. (2017); Yeung et al. (2019); Otto and Rowley
(2019) are extremely promising. Generally, the physics of the problem, e.g., continuity
property and locality, can also be used in determining the choice and the number of basis
functions (Chen and Vaidya, 2019).

The dictionary could also include the system state observable (see, e.g., Williams et al.
(2015); Korda and Mezi´c (2018)). This will enhance the linear state reconstruction from
observables, i.e., decoding back to the original coordinates. However, it requires at least
as many functions as the dimension of the original system state, which is undesirable
for large networks evolving in lower intrinsic dimensions. Furthermore, the linear state
observable generally lacks high enough resolution to capture complex features of nonlinear
systems. Hence, when the full state observable is absent in the Koopman eigenfunction set,
forcing the full state observable constraint in the Koopman-invariant subspace will result in
overﬁtting. Moreover, it is impossible to determine a ﬁnite-dimensional Koopman-invariant
subspace that includes the original state variables for any system with multiple ﬁxed points
or any more general attractors (Brunton et al., 2016).

13

3 Model predictive control for networked processes

The fundamental idea behind the MPC is to measure the current state and design an
open-loop optimal control over a ﬁnite-time horizon based on a predictive model. For a
closed-loop control behavior, the MPC applies only the ﬁrst portion of the synthesized
control during a short time interval. The controller uses the updated state measurements
to design the next open-loop control function–and this procedure repeats in the subsequent
steps. Therefore MPC yields a closed-loop control approach that concurrently optimizes
system performance, handles nonlinearity, holds robustness properties, incorporate input
and state constraints with desirable (stability) convergence properties–we refer the reader
to Gr¨une and Pannek (2017) for an exposition. Extension to stochastic systems and the
cumulative reasons above lead to the fast growth of the MPC paradigm in the control
systems literature.

3.1 Original MPC

For the original stochastic process in (1), we consider a nonlinear MPC problem that at
each time step of the closed-loop operation solves the following optimization problem

min
ui,E[¯xi]

subject to

p−1

lp(E[¯xp]) +

li(E[¯xi]) + uT

i Riui + rT

i ui

i=0
(cid:88)
¯xi+1 = F (¯xi, ui; ω),
Ci(E[¯xi]) + Diui
≤
Cp(E[¯xp])
≤
¯x0 = x0

bi,
bp

i = 0, ..., p

−
i = 0, ..., p

1

−

1

(9)

where x0 is the current state, p is the prediction horizon, E[¯x] denotes the prediction of
Rnc nonlinear vector valued functions of state
E[x], li is nonlinear scalar valued and Ci
Rnc,
vector expected value, Ri
Rnc×l, with nc the number of constraints. At each time step, only the
and matrix Di
ﬁrst element of the optimal control sequence is applied and the optimization is repeated in
the next time step.

Rl×l is positive semideﬁnite, vector ri

Rl, vector bi

∈

∈

∈

∈

∈

The optimization problem (9) is, in general, nonconvex and hard to solve to achieve
global optimality, particularly for large networks. Furthermore, we have generally no prior
realization of the dynamics F (.) for accurate state prediction. Applying the Koopman

14

operator, we transform this problem into a low-order convex optimization problem that is
numerically tractable.

3.2 MPC via Koopman

The Koopman operator transforms the original MPC problem (9) into the following convex
problem

p−1

min
ui,zi

p Qpzp + qT
zT

p zp +

i Qizi + uT
zT

i Riui + qT

i zi + rT

i ui

i=0
(cid:88)

subject to zi+1 = Azi + Bui,
bi,
Eizi + Diui
Epzp
bp
z0 = ψ(x0)
RN ×N is positive semideﬁnite and qi

≤
≤

i = 0, ..., p
i = 0, ..., p

1
1

−
−

(10)

Rnc×N deﬁne
where Qi
the state constraints, which become linear in lifted space. The optimization problem (10)
is convex, i.e, quadratic programming.

RN . The matrices Ei

∈

∈

∈

Suggested by Korda and Mezi´c (2018), one can transform the original optimization
problem (9) into (10) by constructing the matrices A and B and the vector z0 using the
ψ(.) embeddings (see Section 2) with including in the lifting set the functions ψi+1(x) = li(x)
and ψ(p+inc+2:p+(i+1)nc+1) = Ci(x) for i = 0,

, p. Consequently

· · ·
Qi = 0, and qi = [01×i, 1, 01×(N −i−1)],

Ei = [0nc×(p+inc+1), Inc×nc, 0nc×(N −p−(i+1)nc−1)],

where 0i×j, 1i×j, and Ii×j are all zeros, all ones, and identity matrices, respectively. Al-
though this canonical approach always returns a linear cost function, if li(xi) is quadratic,
we opt for the freedom of (10) and instead of setting ψi = li, use the Koopman output
matrix C to consider quadratic terms in the cost function of (10), thereby reducing the
dimension of the lift.

Korda and Mezi´c (2018) show that the computational complexity of solving the MPC
problem (10) can be rendered independent of the dimension of the lifted state N by trans-
forming to a dense form. Hence, the computational cost of solving the dense form is
comparable to solving a standard linear MPC on the same prediction horizon, with the
same number of control inputs and the state space’s dimension equal to n rather than N .

15

p−1
i=0

E[¯xp]+

p
bi for i = 0, ..., p

Algorithm 2 Network MPC via Koopman
Cost function in (9): E[¯xp]T ˆQpE[¯xp]+ˆqT
Constraints in (9): ˆEiE[¯xi] + Diui
Input: Current system state x0
Output: Control input
1: For i = 0, ..., p, set qi = ˜C T ˆqi, Qi = ˜C T ˆQi
2: Solve the convex optimization (10) for A = ˜A and B = ˜B
3: Only keep and apply the ﬁrst computed control input u0
4: Update the current system state x0 and repeat the procedure for the next time step

E[¯xi]T ˆQiE[¯xi]+uT
i Riui+ˆqT
i
1, ˆEpE[¯xp]
bp

˜C, Ei = ˆEi

E[¯xi]+rT

(cid:80)

˜C

≤

−

≤

i ui

Although we follow this strategy in our numerical programmings for the full-order Koop-
man MPC, we are less concerned about the dimensionality when using the reduced-order
Koopman for MPC since our approach uses a low-dimensional model. Recall that the ﬁrst
r modes U T
2 ψ(x) are used to represent the dynamics in the reduced-order Koopman MPC
framework. Therefore, matrices A, B, C in (10) are replaced with ˜A, ˜B, ˜C, respectively, and
n < N . Algorithm 2 shows the reduced-order
the dimension value N is replaced with r
Koopman MPC procedure when each function li(E[x]) in the original MPC problem (9)
is quadratic in terms of state vector expected value through the positive deﬁnite matrix
ˆQi

Rn, and each Ci(E[x]) is linear through matrix ˆEi

Rn×n and vector ˆqi

Rnc×n.

(cid:28)

∈

∈

∈

4 Application: network SIS epidemic model

We apply our proposed approach to study the networked SIS model–a benchmark to study
epidemics over networks. We give a short description of the SIS model in the next subsection
but encourage the reader to see Van Mieghem et al. (2009) for a detailed study of dynamical
properties.

4.1 Underlying Markov process

The Markov process is deﬁned based on a set of rules describing the possible transitions
between diﬀerent compartments. In the standard network SIS model (Van Mieghem et al.,
2009), a susceptible agent i adjacent to an infected neighbor experiences infection through
a Poisson process with the rate βi–the independent processes merge, and thus the infection

16

rate increases with the number of infected neighbors. Similarly, an infected agent i recovers
back to the susceptible state with a Poisson process with the rate δi. Figure 2 shows
the transition diagram where S and I denote the Susceptible and Infected compartments
respectively, and Ni denotes the number of infected agents neighboring agent i.

For each node i

1, ..., n
value of Xi at time t, i.e., X t
the following continuous-time Markov process:

, consider a binary random variable Xi, and denote X t
}
i ∈ {

i the
. The transitions between S and I are modeled via

S, I

∈ {

}

X t+∆t
Pr
i
X t+∆t
(cid:0)
i

= S

i = S, X t

X t
= I
|
i = I, X t
X t
|

Pr

= βiN t

i ∆t

= δi∆t + o (∆t)
(cid:1)

where X t ∆=
time t, and ∆t is the time step that undergoes a Poisson process.

(cid:1)
is the joint state of the network, N t
i

i , i = 1, ..., n

X t

{

}

(cid:0)

(11)

is the value of Ni at

Figure 2: Transition graph for node i with Ni number of infected neighbors in the SIS
model.

4.2 Koopman identiﬁcation

We use the stochastic approach proposed in GEMF by Sahneh et al. (2017) to simulate the
Rn
SIS Markov process (11) on arbitrary networks. At each time step, the state vector x
is a discrete binary vector, where the i-th element of x is 0 if agent i is susceptible and
1 if infected. Algorithm 3 describes the data generation and aggregation using stochastic
simulators. We choose a number of ntraj initial conditions randomly initiated from [0, 1]n.
For each ﬁxed initial condition, we then simulate (11) for nsim times and average to obtain
the expected values of dictionary functions ψ. We record the ﬁrst and last data of each
simulation running for the time period T . Therefore, the mapping (1) takes x(t) and gives
x(t+T ). To learn the system response to a range of inputs, we select a random perturbation
vector U within a given range [u, ¯u] and apply that input throughout the corresponding
trajectory.

∈

17

SIβiNiδiAlgorithm 3 Data generation and collection
Inputs: ntraj = m, nsim, T , u, ¯u
Outputs: Data matrices X, U , and E[Ψ(Y )]
GEMF simulator takes the current state x(t) and the picewise-constant control input u(t)
and gives the network state x(t + T ) at t + T
1: for i = 1 : ntraj do
2:
3:
4:
5:
6:
7:
8:
9: X

Run the GEMF for x(0) = xi and ui and get yij = x(T )
Compute ψ(yij)
E[ψ(yi)]
[x1, ..., xntraj ], U

Randomly generate xi in [0, 1]n including 0 and 1 elements
Randomly generate ui in Rn satisfying u
E[ψ(yi)]
←
for j = 1 : nsim do

[E[ψ(y1)], ..., E[ψ(yntraj )]]

E[ψ(yi)] + ψ(yij)/nsim

[u1, ..., untraj ], E[Ψ(Y )]

←

≤

≤

u

¯u

0

←

←

←

We consider the constant function 1 and Gaussian radial basis functions (RBF) for the
dictionary functions. We choose the RBF centers from k-means clustering (Bishop, 2006)
with a pre-speciﬁed value of k on the combined data set. Doing so, the RBF centers are
directly related to the density of data points, eﬀectively distributing the RBF centers over
the cloud of points (Williams et al., 2015).

We adopt the variation of infection rates βi, i = 1, ..., n, as inputs to the spreading
∆βi with β0i indicating a constant (passive) infection rate and
dynamics, letting βi = β0i −
ui = ∆βi the input to agent i. In practice, the infection rate can be regulated by putting
restrictions on traﬃc/travel, quarantining subpopulation, distributing masks, vaccinations,
or raising awareness about the disease (Nowzari et al., 2016). The control input ui is
constrained by constants ¯u and β0i as 0
β0i; thus the total infection rate βi
¯u
remains nonnegative. One may also constraint the total control input for all agents by uT
as

≤

≤

≤

u

(cid:80)

We considered and examined our approach on three random graph models: randomly
(cid:80)
generated geometric (Geo), Erd˝os-R´enyi (ER), and Watts-Strogatz (WS) graphs as testbeds
each with n = 100 nodes and a ﬁxed average degree ˆd = 10. To conserve space, whenever
the results of other models can be interpreted similarly, we present only the results for ER
networks. We compare our data-driven approach in predicting the networked dynamics
to the epidemic mean-ﬁeld model at which we provide both graph structure and the SIS

n
i=1 ui

uT

≤

≤

n
i=1 β0i.

18

model (Sahneh et al., 2013). Note that we are unable to oﬀer a similar comparison for the
control of networked processes (Section 3) due to lack of known algorithms able to handle
large-scale graphs–even with the knowledge of network structure and nodal dynamics.

×

We set β0i = 1, δi = 2, ntraj = 2

104, nsim = 10, and T = 1 in Algorithm 3. Moreover,
we consider averaging the prediction error over 1000 randomly chosen initial conditions
that are allowed to evolve for a time period t = T . Although this time period is equivalent
to one step in Equation (2), i.e. the operator sense, it includes multiple transitions (events)
in Equation (11), i.e. GEMF stochastic simulator. Furthermore, choosing a large T may
incorporate less of the transient pass and even result in better metrics of prediction, but it
lacks precision for our control design later.

4.2.1 Constant input

In this section, we consider a network of agents with the same (constant) infection rate.
Figure 3 shows the average fraction of infected population for βi = 0.5 with 10% (randomly
chosen) initial infection averaged and the predictions using mean-ﬁeld model (Sahneh et al.,
2013), full-order Koopman (4)-(5), and the reduced Koopman (8). Koopman identiﬁcation
operates successfully in predicting the fraction of infected population, and the performance
is comparable with the mean-ﬁeld theory that is model-based and considers full information
of dynamical process, system parameters, and network structure–while our approach does
not. Figure 4 illustrates the corresponding predictions for the nodal probability of infection.
We obtain the reduced order model by truncating the full order Koopman model with
r = 5 for ER and WS networks and r = 10 for Geo network. The number of RBFs for
the ER and WS networks is 200, while it is 300 for Geo network–we use the same values
subsequently.

We choose these numbers by investigating the prediction errors in Figure 5. Each point
represents the Koopman prediction error over a t = T and 1000 initial conditions, averaged
among the prediction errors for all agents. Hence, each error is obtained by computing
two averages: one among all agents and one among all initial conditions. Firstly, we
observe that the average prediction error for each of ER and WS networks remains almost
unchanged by increasing the number of RBFs beyond 200; this number is more considerable
for Geo networks. We stop increasing the number of RBFs beyond these values to avoid the
increase of complexity and thus overﬁtting. Second, the evaluation of prediction error for
reduced Koopman models in Figure 5b illustrates that increasing the number of Koopman
modes r beyond 5 for ER and WS networks and 10 for Geo network has a negligible
eﬀect on error reduction. Consequently, while Koopman embeds the stochastic nonlinear

19

Figure 3: Fraction of infected population for ER network.

system into a high-dimensional linear model, e.g., SIS model over a network of 100 agents
may be embedded into a dimension of 200 or 300, its mode decomposition can yield a
much smaller, but eﬀective, representation. The considered networks with 100 agents are
successfully represented by linear models of 5 and 10 states (ﬁfth and tenth order linear
models). This implies exploring the low-dimensional manifold that describes the underlying
dynamics is a promising approach for challenges of optimization and control over networks.
We further examine average errors for diﬀerent reproduction numbers obtained for dif-
ferent corresponding infection rates in Figure 5c. We observe that the average nodal error
reduces with increasing the reproduction number
. For large reproduction numbers, con-
nections and interactions between agents grow stronger and the overall network operates
more uniformly. This uniformity makes the network more predictable. Figure 5 also signi-
ﬁes that the prediction in ER and WS networks is more eﬀortless than Geo networks; thus,
we can represent them by lower-order models– we attribute this to slower mixing dynamics
and larger diameter in spatial graphs.

R

4.2.2 Varying input

−

We examine the eﬃcacy of the proposed approach when the infection rate varies, i.e.,
Rn is the
β = β0
∆β where β0 = [β0i] = 1 is constant for all agents, and u = ∆β
(heterogeneous) input vector to the system. As an example of conditions under which the
infection rate is both time-varying and heterogeneous, we examine the Koopman model
prediction performance in response to the oscillatory time-varying input shown in Figure
6. We train the Koopman model for two diﬀerent input ranges 0.2
1
and compare the results. Figure 7 illustrates that the prediction error increases by widening
the training range, highlighting the importance of input training range in the identiﬁed

0.7 and 0

≤

≤

≤

≤

∈

β

β

20

024681000.20.40.60.8Figure 4: Probability of each individual infection corresponding to Figure 3. The ﬁg-
ure shows from left the infection probabilities computed by mean ﬁeld, full and reduced
Koopman predictions.

(a)

(b)

(c)

Figure 5: Diﬀerent average errors computed using 1000 randomly generated initial condi-
tions.

21

01234500.20.40.60.8101234500.20.40.60.8101234500.20.40.60.810100200300400500Number of RBFs5101520253035Average error %ERGeoWS12345678910Reduced order (r)051015202530Average error %ERGeoWS13579Reproduction number48121620Average error %ERGeoWSFigure 6: Time varying heterogeneous infection rate input.

model accuracy.

β

β

≤

≤

≤

To further quantify our results, we probe two types of errors as metrics of performance.
First, we compute the relative error when we apply a constant homogeneous input in the
model trained for a given input range. The corresponding results are shown in Figure 8
showing the average prediction errors for the trained Koopman models after a time period
t = T . Figure 8 indicates that the average relative error increases by approaching the
boundaries of the training range. Comparing the errors corresponding to ranges 0.2
≤
1 reveals that narrower input training range, i.e. a Koopman model
0.7 and 0
≤
trained in the range 0.2
0.7, generally produces less error, thus more accurate
model (see Figure 7). Next, while the average error for most inputs in Figure 8 is larger
when using reduced Koopman, we observe an exception for values of u corresponding to
1. This improvement
β near 1 when the model is trained for the broader range 0
is a result of balanced truncation of dynamics in the reduced Koopman model and less
overﬁtting compared to the full Koopman model (Rowley and Dawson, 2017b). Second,
we consider the average error for heterogeneous inputs shown in Table 1; in this case,
the error is averaged among 1000 trajectories corresponding to 1000 randomly generated
initial conditions and control input vectors. Although the prediction error increases by more
broader training range or further reducing the Koopman model, the full Koopman model
may still experience overﬁtting (Figure 8). Then, the reduced Koopman’s proper mode
decomposition results in more accurate prediction by reﬁning and ﬁltering the identiﬁed
model’s noisy part, hence preventing overﬁtting.

≤

≤

≤

β

β

22

0100200300400Time0.20.30.40.50.60.7 for each individualFigure 7: Prediction over ER network for varying input trained for 0.2
and 0

1 (right).

β

≤

≤

β

≤

≤

0.7 (left)

Figure 8: Average prediction error computed by 1000 randomly generated initial conditions
for diﬀerent homogeneous constant inputs u in the ER network. The ﬁrst and second rows
show the result for the training ranges 0.2
1, respectively, by the
left column representing the full Koopman and right the reduced Koopman.

0.7 and 0

≤

≤

≤

≤

β

β

23

010020030040000.20.40.60.81010020030040000.20.40.60.810.70.60.50.40.30.2Infection rate  = 0 - u0306090Error   %0.70.60.50.40.30.2Infection rate  = 0 - u0306090Error   %10.90.80.70.60.50.40.30.20.1Infection rate  = 0 - u0306090Error    %10.90.80.70.60.50.40.30.20.1Infection rate  = 0 - u0306090Error    %Table 1: Average error for diﬀerent input training ranges

Average error %

Training range
Koopman type

0.2
β
Full Reduced

0.7

≤

≤

Network

ER 11.55
12.50
Geo
11.39
WS

24.83
28.65
24.72

1

0

≤

≤

β
Full Reduced
26.48
25.73
26.04

65.40
59.65
65.80

4.3 Koopman MPC for networked SIS

4.3.1 Limited budget problem

In this section, we consider a linear cost function as li(E[¯xi]) = 1T E[¯xi] in (9), where 1
is the all ones vector, thus minimizing the fraction of the infected population. Instead of
explicitly minimizing the control expenditure, we limit the total control action at each time
step by a budget uT by enforcing the constraint 1T u
uT . Furthermore, we assume the
β0i, so that the infection rate βi of each
ui
control input at each node is limited as 0
node can be neither negative nor increased beyond the initial value β0i. We impose no state
constraints, i.e., Ci(E[¯xi]) = 0. The problem becomes an optimal assignment of resources
to mitigate the epidemic with a prediction horizon p = 3.

≤

≤

≤

We assume 90 percent of the population is initially infected. For comparison, we present
the results of another scenario where the total available budget uT is distributed uniformly
n
i=1 β0i = 70. Figure 9
among all agents. For simulation, we set β0i = 1 and uT = 0.7
illustrates a typical system response where on the one hand, a uniform resource allocation
fails to mitigate epidemic by driving the system into an endemic state, and on the other
hand, MPC via Koopman approaches operates successfully to halt the epidemic throughout
the network. Both full and reduced Koopman models perform almost equally, with a slight
advantage with full Koopman MPC, indicating the reduced Koopman MPC is nearly as
eﬀective as the full Koopman MPC, though being of signiﬁcantly lower order. Figure
10 shows the control distributions and the nodes’ Katz centrality. The optimal control
strategy in this limited budget case, with linear MPC cost function, is constant over time
and distributes the total budget to nodes with the most centrality measures. Thus, the most
central nodes are assigned maximum control action while the others with lesser centrality
measures are left without action (ui = 0).

(cid:80)

This strategy is signiﬁcant for practical use, e.g., if the control action is to vaccinate

24

Figure 9: Fraction of infected population under MPC with limited total budget in ER
network.

Figure 10: Control distribution in Figure 9. The left ﬁgure shows the control distribution,
and the right shows the corresponding control input diﬀerences between full and reduced
Koopman MPC.

the agents, the resource allocation policy recommends vaccinating only the most central
agents. We emphasize that control architecture’s assessment of the resource allocation
strategy and identifying the importance of nodes is accomplished exclusively by nonlinear
mode decomposition of the available data, without any knowledge of system parameters
or network geometry. Table 2 compares the average new cases of infection after applying
control, obtained by averaging among trajectories of 1000 randomly selected initial con-
ditions. We observe fewer infection cases using the full Koopman model for ER and Geo
networks in the limited budget problem. However, in the WS network, the reduced-order
Koopman induces fewer infection cases in the limited budget problem; an improvement by
proper mode decomposition in the reduced model that reduces overﬁtting. Table 2 conﬁrms
controlling the epidemic in Geo network is more complicated than in ER and WS.

25

01234567891000.20.40.60.811.21.41.61.822.22.42.62.8300.20.40.60.81Control effort ui=iFull Koopman MPCReduced Koopman MPC1.21.41.61.822.22.42.62.83Katz centrality-101ufull - ureducedTable 2: Average number of transitions S
in a network with 100 nodes

I, i.e. number of infections, after applying MPC

→

MPC strategy
Koopman type

Network

Average transition
Limited budget Minimum cost
Full Reduced
Full Reduced
24.39
30.51
33.80

33.55
126.05
48.11

35.10
86.21
45.13

ER 29.40
92.60
Geo
64.27
WS

4.3.2 Minimum cost problem

∈

∈

In the previous subsection, the control action was concluded to be constant with time for
the linear cost function. To reach a time varying resource allocation strategy, we consider
a quadratic cost function as li(E[¯xi]) = E[¯xi]T ˆQE[¯xi] + ˆqT E[¯xi] in (9), where ˆq
Rn, and
ˆQ
Rn×n is positive semideﬁnite. Although we consider no constraint directly imposed on
the total available budget, the control action of each node is still limited as 0
β0i = 1,
and it also contributes to cost function by choosing nonzero values for ri and Ri in (9).
There is no constraint on system state too, Ci(E[¯xi]) = 0. Consequently, our aim is to
mitigate an existing epidemic while minimizing the costs.

For numerical values we consider ˆQ = In×n, ˆq = 0.51n, Ri = 0.3In×n, and ri = 0.11n,
where In×n denotes identity matrix of size n, and 1n the all ones vector of size n. Figure 11
shows a typical system response where we observe Koopman models’ success in mitigating
the epidemic, something that is not possible with uniform resource distribution. Moreover,
while the full Koopman model performs slightly better, the reduced Koopman model per-
formance is comparable. Figure 12 indicates the control allocation of the full Koopman
model for times t = 1 and t = 10. The reduced Koopman model decides qualitatively
similar control actions (we avoid repeating similar results in the paper).

ui

≤

≤

Figure 12 illustrates that the MPC eﬀort initially concentrates mainly on reducing
the epidemic by increasing and saturating the control actions near the maximum value
1. Hence, only some nodes of small centrality measures are not assigned their maximum
possible control (see Figure 12 on left). With time passing and the epidemic decaying,
the MPC strategy turns to give more priority to minimum control action corresponding to
less budget, so that applied control inputs decrease signiﬁcantly (see Figure 12 on right).
Figure 13 further illustrates this by referring to time variations of the total control action,
where we also plotted the MPC cost function values during the epidemics. For total control

26

Figure 11: Fraction of infected population under MPC with minimum cost in ER network.

Figure 12: Control distribution by full Koopman MPC in Figure 11 at t = 1 (left) and
t = 10 (right).

action, Figure 13 veriﬁes a nonincreasing pattern where the reduced Koopman often induces
more control eﬀort than the full Koopman except for the beginning, i.e., t = 1. Figure 13
also shows the minimum cost function value by full Koopman is smaller than that of the
reduced order. Finally, we observe for the minimum cost problem in Table 2 that, after
applying MPC, the full Koopman model results in fewer new infection cases than reduced
one does.

27

01234567891000.20.40.60.811.21.41.61.822.22.42.62.8300.20.40.60.81Control effort ui=i1.21.41.61.822.22.42.62.8300.20.40.60.81Control effort ui=iFigure 13: Total control applied (solid lines) and cost function value (dash-dotted lines)
in Figure 11. Dark colors show the result of full Koopman and the pale show reduced
Koopman.

5 Conclusion and discussion

Modern data-driven techniques yield promising tools to identify, optimize, and control of
dynamical processes over complex networks. In this work, we use operator-theoretic meth-
ods to characterize stochastic nonlinear dynamics and represent them into low-dimensional
linear forms. This is beneﬁcial to accurately predict complex networked processes through
interpretable models that can be eﬀectively utilized to reformulate the existing optimiza-
tion and control problems on networks. This approach converts the original network MPC,
a nonlinear optimization problem, into a convex problem with fewer decision variables. As
a speciﬁc application of the proposed method, we concluded its power to predict and con-
trol epidemic spread over networks. Among diﬀerent random graphs studied, the random
geometric networks (Geo) showed more complicated features for identiﬁcation and control.
That is, the Geo network needs more eﬀort compared to ER and WS networks. This is
attributed to slower mixing dynamics and larger diameter in spatial graphs.

Optimization of network dynamics has a long-standing history due to its paramount im-
portance in areas as diverse as engineering, physics, biology, the social sciences, computer
science, and economics. However, this vast literature still fails to achieve a comprehensive
solution for challenging features originating from nonlinear phenomena, stochastic pro-
cesses, large system scale, and complex network structures. The control inputs diﬀer from
strategies adopted in (Preciado and Jadbabaie, 2009; Van Mieghem et al., 2011) that consid-
ered removing nodes and/or removing links that lead to combinatorial NP-hard problems,
and similar to (Preciado et al., 2014), by distributing resources that promote corrective be-
haviors in terms of continuous properties of nodes. Moreover, instead of oﬀ-line strategies

28

12345678910Time102030405060708090Cost & Control inputin Preciado et al. (2014); Shakeri et al. (2015); Nowzari et al. (2017); Watkins et al. (2018),
our approach is an online control strategy that monitors the system state. Therefore it
provides feedback and thus possesses robustness properties against system uncertainties
and exogenous disturbances, all when no knowledge of the network structure or parameters
is provided.

While optimal control strategies are recently employed to solve various online control
problems over networks (Khanafer and Ba¸sar, 2014; Eshghi et al., 2016; Kandhway and
Kuri, 2016; He and Van Mieghem, 2019; Dashtbali et al., 2020; Watkins et al., 2020), they
fall short in practice. Speciﬁcally, they are based on unrealistically simpliﬁed deterministic
models, have a computational burden that is intractable for large networks, and require
complete knowledge of network geometry and dynamical parameters. Our proposed ap-
proach leverages the advantages of operator-theoretic methods (Klus et al., 2018) to treat
an original problem within a framework where the fundamental theories and practices are
well developed. Furthermore, we utilize modern data-driven techniques to identify such
operators for network dynamics. The success of our proposed strategy lies in the topolog-
ical conjugacy (Lan and Mezi´c, 2013) that allows us to exploit the linearity of Koopman
dynamics and tame the original nonlinear dynamics. Unlike local linearization approaches
(Khanafer and Ba¸sar, 2014), that are valid within a (small) neighborhood of invariant sets,
Koopman eigenfunctions extend the validity of the linear model into the whole basin of
attraction. Furthermore we oﬀer computationally tractable solutions, in contrary to re-
cent works that use nonlinear models for more accurate and stable control (He and Van
Mieghem, 2019; Watkins et al., 2020) with recalcitrant nonlinear programmings with re-
quirements about the exact knowledge of underlying dynamics, model parameters, and
network geometry. Hence, the importance of this work remains in establishing an approach
that does not ask for often-unknown network information over and enables practical linear
control strategies that are valid over the state space.

Model reductions in networks often are based on graph clustering and aggregation
(Cheng and Scherpen, 2021) with assumptions on network structures. However, network
intricacies and interconnections give rise to dynamics that evolve on low-order manifolds,
and operator-theoretic techniques can capture these manifolds (Klus et al., 2018) eﬃciently.
The approximation of Koopman operator using EDMD with balanced truncation represents
the nonlinear dynamics of low-order manifolds by considering the most eﬀective Koopman
eigenfunctions. We use such low-order linear models to oﬀer a tractable framework for
signiﬁcant control problems, such as MPC, over large networks.

In what follows, we acknowledge and discuss the limitations and possible extensions
of our approach. Although EDMD is a simple approach, it only approximates the Koop-

29

man operator if the observables library is chosen appropriately. Practices such as deep
learning techniques are proposed to improve this choice to better asses invariant Koopman
subspaces (Li et al., 2017; Lusch et al., 2018; Otto and Rowley, 2019; Mardt et al., 2020;
Pan and Duraisamy, 2020). Therefore future inclusions of these techniques may result in
more accurate prediction and control of network processes. Moreover, we assume no prior
knowledge of the system dynamics, but when possible, physics-informed machine learning
techniques (Karniadakis et al., 2021; Pan and Duraisamy, 2020) can reduce data volume
and reach better accuracy, faster training, and improved generalization. On the other hand,
if we have information on the network geometry, we can utilize the sparse reduced-order
modeling approach to full-state estimation (Loiseau et al., 2018) by only monitoring the
states of a few numbers of agents. This will yield a more practical version of this work, since
we are not always provided with full measurement of the network state. Another extension
of this work can be made by multi-scale identiﬁcation of underlying dynamics by collecting
data of agent groups instead of individual agents. Although by the group-based strategy we
only estimate the state in each group state, not each agent, it is eﬀective particularly over
large networks by signiﬁcantly reducing the computational burden (Moon et al., 2021).

References

Abraham, I. and T. D. Murphey (2019). Active learning of dynamics for data-driven control

using koopman operators. IEEE Transactions on Robotics 35 (5), 1071–1083.

Arbabi, H. and I. Mezi´c (2017, Dec). Study of dynamics in post-transient ﬂows using

koopman mode decomposition. Phys. Rev. Fluids 2, 124402.

Arbabi, H. and I. Mezi´c (2017). Ergodic theory, dynamic mode decomposition, and com-
putation of spectral properties of the koopman operator. SIAM Journal on Applied
Dynamical Systems 16 (4), 2096–2126.

Avila, A. M. and I. Mezi´c (2020). Data-driven analysis and forecasting of highway traﬃc

dynamics. Nature Communications 11, 2090.

Bishop, C. (2006). Pattern Recognition and Machine Learning. Springer-Verlag.

Boskic, L., C. N. Brown, and I. Mezi´c (2020). Koopman mode analysis on thermal data

for building energy assessment. Advances in Building Energy Research 0 (0), 1–15.

30

Bruder, D., X. Fu, R. B. Gillespie, C. D. Remy, and R. Vasudevan (2020). Data-driven
control of soft robots using koopman operator theory. IEEE Transactions on Robotics,
1–14.

Brunton, S., M. Budisic, E. Kaiser, and J. Kutz (2021). Modern koopman theory for

dynamical systems. ArXiv abs/2102.12086.

Brunton, S. L., B. W. Brunton, J. L. Proctor, E. Kaiser, and J. N. Kutz (2017). Chaos as

an intermittently forced linear system. Nature Communications 8, 19.

Brunton, S. L., B. W. Brunton, J. L. Proctor, and J. N. Kutz (2016, 02). Koopman
invariant subspaces and ﬁnite linear representations of nonlinear dynamical systems for
control. PLOS ONE 11 (2), 1–19.

Brunton, S. L. and J. N. Kutz (2019). Data-Driven Science and Engineering: Machine

Learning, Dynamical Systems, and Control. Cambridge University Press.

Budiˇsi´c, M. and I. Mezi´c (2012). Geometry of the ergodic quotient reveals coherent struc-

tures in ﬂows. Physica D: Nonlinear Phenomena 241 (15), 1255–1269.

Budiˇsi´c, M., R. Mohr, and I. Mezi´c (2012). Applied koopmanism. Chaos: An Interdisci-

plinary Journal of Nonlinear Science 22 (4), 047510.

Carli, R., G. Cavone, N. Epicoco, P. Scarabaggio, and M. Dotoli (2020). Model predictive
control to mitigate the covid-19 outbreak in a multi-region scenario. Annual Reviews in
Control .

Chen, T. and J. Shan (2020). Koopman-operator-based attitude dynamics and control on

so(3). Journal of Guidance, Control, and Dynamics 43 (11), 2112–2126.

Chen, Y. and U. Vaidya (2019). Sample complexity for nonlinear stochastic dynamics. In

2019 American Control Conference (ACC), pp. 3526–3531.

Cheng, X. and J. Scherpen (2021). Model reduction methods for complex network systems.

Annual Review of Control, Robotics, and Autonomous Systems 4 (1), 425–453.

Das, A. K., B. Huang, and U. Vaidya (2018). Data-driven optimal control using transfer
operators. In 2018 IEEE Conference on Decision and Control (CDC), pp. 3223–3228.

31

Dashtbali, M., A. Malek, and M. Mirzaie (2020). Optimal control and diﬀerential game
solutions for social distancing in response to epidemics of infectious diseases on networks.
Optimal Control Applications and Methods 41 (6), 2149–2165.

Eshghi, S., M. H. R. Khouzani, S. Sarkar, and S. S. Venkatesh (2016). Optimal patching in
clustered malware epidemics. IEEE/ACM Transactions on Networking 24 (1), 283–298.

Fujii, K. and Y. Kawahara (2019). Dynamic mode decomposition in vector-valued re-
producing kernel hilbert spaces for extracting dynamical structure among observables.
Neural Networks 117, 4–103.

Gr¨une, L. and J. Pannek (2017). Nonlinear model predictive control (Second ed.). Springer.

He, Z. and P. Van Mieghem (2019). Optimal induced spreading of sis epidemics in networks.

IEEE Transactions on Control of Network Systems 6 (4), 1344–1353.

Hiramatsu, N., Y. Susuki, and A. Ishigame (2020, Aug). Koopman mode decomposition of

oscillatory temperature ﬁeld inside a room. Phys. Rev. E 102, 022210.

Kaiser, E., J. N. Kutz, and S. L. Brunton (2017a, November). Data-driven discovery
In APS Division of Fluid Dynamics Meeting

of Koopman eigenfunctions for control.
Abstracts, APS Meeting Abstracts, pp. M27.006.

Kaiser, E., J. N. Kutz, and S. L. Brunton (2017b, nov). Data-driven discovery of Koopman
eigenfunctions for control. In APS Division of Fluid Dynamics Meeting Abstracts, APS
Meeting Abstracts, pp. M27.006.

Kandhway, K. and J. Kuri (2016). Campaigning in heterogeneous social networks: Optimal
control of si information epidemics. IEEE/ACM Transactions on Networking 24 (1), 383–
396.

Karniadakis, G. E., I. G. Kevrekidis, L. Lu, P. Perdikaris, S. Wang, and L. Yang (2021).

Physics-informed machine learning. Nature Reviews Physics 3, 422–440.

Khanafer, A. and T. Ba¸sar (2014). An optimal control problem over infected networks. In
Proceedings of the International Conference of Control, Dynamic Systems, and Robotics,
pp. paper 125, pp. 1–6.

Klus, S., F. N¨uske, P. Koltai, H. Wu, I. Kevrekidis, C. Sch¨utte, and F. No´e (2018). Data-
driven model reduction and transfer operator approximation. Journal of Nonlinear Sci-
ence 28 (4), 985–1010.

32

Korda, M. and I. Mezi´c (2018). Linear predictors for nonlinear dynamical systems: Koop-

man operator meets model predictive control. Automatica 93, 149 – 160.

Korda, M. and I. Mezi´c (2020). Optimal construction of koopman eigenfunctions for pre-

diction and control. IEEE Transactions on Automatic Control 65 (12), 5114–5129.

Korda, M., Y. Susuki, and I. Mezi´c (2018). Power grid transient stabilization using koopman
model predictive control. IFAC-PapersOnLine 51 (28), 297–302. 10th IFAC Symposium
on Control of Power and Energy Systems CPES 2018.

Kutz, J. N., S. L. Brunton, B. W. Brunton, and J. L. Proctor (2016a). Dynamic Mode

Decomposition: Data-Driven Modeling of Complex Systems. SIAM.

Kutz, J. N., S. L. Brunton, B. W. Brunton, and J. L. Proctor (2016b). Dynamic mode

decomposition: data-driven modeling of complex systems. SIAM.

Lan, Y. and I. Mezi´c (2013). Linearization in the large of nonlinear systems and koopman

operator spectrum. Physica D: Nonlinear Phenomena 242 (1), 42–53.

Li, Q., F. Dietrich, E. M. Bollt, and I. G. Kevrekidis (2017). Extended dynamic mode de-
composition with dictionary learning: A data-driven adaptive spectral decomposition of
the koopman operator. Chaos: An Interdisciplinary Journal of Nonlinear Science 27 (10),
103111.

Loiseau, J.-C., B. R. Noack, and S. L. Brunton (2018). Sparse reduced-order modelling:
sensor-based dynamics to full-state estimation. Journal of Fluid Mechanics 844, 459–490.

Lusch, B., J. Kutz, and S. Brunton (2018). Deep learning for universal linear embeddings

of nonlinear dynamics. Nature Communications 9, 4950.

Mardt, A., L. Pasquali, F. No´e, and H. Wu (2020). Deep learning markov and koopman
models with physical constraints. Proceedings of Machine Learning Research 107, 451–
–475.

Mauroy, A. and J. Goncalves (2019). Koopman-based lifting techniques for nonlinear
systems identiﬁcation. IEEE Transactions on Automatic Control Early Access, 1–16.

Mauroy, A., I. Mezic, and Y. Susuki (2020). The Koopman Operator in Systems and

Control: Concepts, Methodologies, and Applications. Springer.

33

Mauroy, A. and I. Mezi´c (2012). On the use of fourier averages to compute the global
isochrons of (quasi)periodic dynamics. Chaos: An Interdisciplinary Journal of Nonlinear
Science 22 (3), 033112.

Mauroy, A. and I. Mezi´c (2016). Global stability analysis using the eigenfunctions of the

koopman operator. IEEE Transactions on Automatic Control 61 (11), 3356–3369.

Mauroy, A., I. Mezi´c, and J. Moehlis (2013). Isostables, isochrons, and koopman spectrum
for the action–angle representation of stable ﬁxed point dynamics. Physica D: Nonlinear
Phenomena 261, 19–30.

Mezi´c, I. (2005). Spectral properties of dynamical systems, model reduction and decompo-

sitions. Nonlinear Dynamics 41, 309–325.

Mezi´c,

I.

(2020).
arXiv:2009.05883v1 , 1–24.

On numerical approximations of

the koopman operator.

Moon, S. A., F. D. Sahneh, and C. Scoglio (2021). Group-based general epidemic modeling
for spreading processes on networks: Groupgem. IEEE Transactions on Network Science
and Engineering 8 (1), 434–446.

Narasingam, A. and J. S.-I. Kwon (2020). Application of koopman operator for model-
based control of fracture propagation and proppant transport in hydraulic fracturing
operation. Journal of Process Control 91, 25–36.

Nowzari, C., V. M. Preciado, and G. J. Pappas (2016). Analysis and control of epidemics:
A survey of spreading processes on complex networks. IEEE Control Systems Maga-
zine 36 (1), 26–46.

Nowzari, C., V. M. Preciado, and G. J. Pappas (2017). Optimal resource allocation for
control of networked epidemic models. IEEE Transactions on Control of Network Sys-
tems 4 (2), 159–169.

Otto, S. E. and C. W. Rowley (2019). Linearly recurrent autoencoder networks for learning

dynamics. SIAM Journal on Applied Dynamical Systems 18 (1), 558–593.

Otto, S. E. and C. W. Rowley (2021). Koopman operators for estimation and control of
dynamical systems. Annual Review of Control, Robotics, and Autonomous Systems 4 (1),
null.

34

Pan, S. and K. Duraisamy (2020). Physics-informed probabilistic learning of linear em-
beddings of nonlinear dynamics with guaranteed stability. SIAM Journal on Applied
Dynamical Systems 19 (1), 480–509.

Peitz, S. and S. Klus (2019). Koopman operator-based model reduction for switched-system

control of pdes. Automatica 106, 184 – 191.

Prasse, B. and P. V. Mieghem (2020). Predicting dynamics on networks hardly depends

on the topology. arXiv:2005.14575v1 , 1––24.

Preciado, V. M. and A. Jadbabaie (2009). Spectral analysis of virus spreading in random
geometric networks. In Proceedings of the 48h IEEE Conference on Decision and Control
(CDC) held jointly with 2009 28th Chinese Control Conference, pp. 4802–4807.

Preciado, V. M., M. Zargham, C. Enyioha, A. Jadbabaie, and G. J. Pappas (2014). Optimal
resource allocation for network protection against spreading processes. IEEE Transac-
tions on Control of Network Systems 1 (1), 99–108.

Proctor, J. L., S. L. Brunton, and J. N. Kutz (2016). Including inputs and control within
equation-free architectures for complex systems. The European Physical Journal Special
Topics 225, 2413—-2434.

Proctor, J. L., S. L. Brunton, and J. N. Kutz (2018). Generalizing koopman theory to allow
for inputs and control. SIAM Journal on Applied Dynamical Systems 17 (1), 909–930.

Rowley, C. W. and S. T. Dawson (2017a). Model reduction for ﬂow analysis and control.

Annual Review of Fluid Mechanics 49 (1), 387–417.

Rowley, C. W. and S. T. Dawson (2017b). Model reduction for ﬂow analysis and control.

Annual Review of Fluid Mechanics 49, 387–417.

Rowley, C. W., I. Mezi´c, S. Bagheri, P. Schlatter, and D. S. Henningson (2009). Spectral

analysis of nonlinear ﬂows. Journal of Fluid Mechanics 641, 115–127.

Sahneh, F. D., C. Scoglio, and P. Van Mieghem (2013). Generalized epidemic mean-ﬁeld
model for spreading processes over multilayer complex networks. IEEE/ACM Transac-
tions on Networking (TON) 21 (5), 1609–1620.

Sahneh, F. D., A. Vajdi, H. Shakeri, F. Fan, and C. Scoglio (2017). Gemfsim: A stochastic
simulator for the generalized epidemic modeling framework. Journal of Computational
Science 22, 36—-44.

35

Schmid, P. J. (2010). Dynamic mode decomposition of numerical and experimental data.

Journal of Fluid Mechanics 656, 5–28.

Shakeri, H., F. D. Sahneh, C. Scoglio, P. Poggi-Corradini, and V. M. Preciado (2015). Op-
timal information dissemination strategy to promote preventive behaviors in multilayer
epidemic networks. Mathematical Biosciences & Engineering 12 (3), 609.

Sootla, A., A. Mauroy, and D. Ernst (2018). Optimal control formulation of pulse-based

control using koopman operator. Automatica 91, 217 – 224.

Surana, A. (2018). Koopman operator framework for time series modeling and analysis.

Journal of Nonlinear Science 30, 1973—-2006.

Tu, J. H., C. W. Rowley, D. M. Luchtenburg, S. L. Brunton, and J. N. Kutz (2014).
On dynamic mode decomposition: Theory and applications. Journal of Computational
Dynamics 1 (2), 391–421.

Van Mieghem, P., J. Omic, and R. Kooij (2009). Virus spread in networks. IEEE/ACM

Transactions on Networking (TON) 17 (1), 1–14.

Van Mieghem, P., D. Stevanovi´c, F. Kuipers, C. Li, R. van de Bovenkamp, D. Liu, and
H. Wang (2011, Jul). Decreasing the spectral radius of a graph by link removals. Phys.
Rev. E 84, 016101.

Wang, W.-X., Y.-C. Lai, and C. Grebogi (2016). Data based identiﬁcation and prediction

of nonlinear and complex dynamical systems. Physics Reports 644, 1 – 76.

Watkins, N. J., C. Nowzari, and G. J. Pappas (2020). Robust economic model predic-
tive control of continuous-time epidemic processes. IEEE Transactions on Automatic
Control 65 (3), 1116–1131.

Watkins, N. J., C. Nowzari, V. M. Preciado, and G. J. Pappas (2018). Optimal resource
allocation for competitive spreading processes on bilayer networks. IEEE Transactions
on Control of Network Systems 5 (1), 298–307.

Wehmeyer, C. and F. No´e (2018). Time-lagged autoencoders: Deep learning of slow collec-
tive variables for molecular kinetics. The Journal of Chemical Physics 148 (24), 241703.

36

Williams, M. O., M. S. Hemati, S. T. Dawson, I. G. Kevrekidis, and C. W. Row-
ley (2016). Extending data-driven koopman analysis to actuated systems.
IFAC-
PapersOnLine 49 (18), 704 – 709. 10th IFAC Symposium on Nonlinear Control Systems
NOLCOS 2016.

Williams, M. O., I. G. Kevrekidis, and C. W. Rowley (2015). A data–driven approximation
of the koopman operator: Extending dynamic mode decomposition. Journal of Nonlinear
Science 25, 1307–1346.

Williams, M. O., C. W. Rowley, and I. G. Kevrekidis (2015). A kernel-based method for
data-driven koopman spectral analysis. Journal of Computational Dynamics 2 (2158-
2491-2015-2-247), 247.

Wu, H. and F. No´e (2020). Variational approach for learning markov processes from time

series data. Journal of Nonlinear Science 30, 23–66.

Yeung, E., S. Kundu, and N. Hodas (2019). Learning deep neural network representa-
tions for koopman operators of nonlinear dynamical systems. In 2019 American Control
Conference (ACC), pp. 4832–4839.

37

