9
1
0
2

l
u
J

0
2

]

R
P
.
h
t
a
m

[

1
v
3
8
8
8
0
.
7
0
9
1
:
v
i
X
r
a

Spectral Graph Matching and Regularized Quadratic Relaxations
II: Erd˝os-R´enyi Graphs and Universality

Zhou Fan, Cheng Mao, Yihong Wu, and Jiaming Xu∗

July 23, 2019

Abstract

We analyze a new spectral graph matching algorithm, GRAph Matching by Pairwise eigen-
Alignments (GRAMPA), for recovering the latent vertex correspondence between two unlabeled,
edge-correlated weighted graphs. Extending the exact recovery guarantees established in the
companion paper [FMWX19] for Gaussian weights, in this work, we prove the universality of
these guarantees for a general correlated Wigner model.
In particular, for two Erd˝os-R´enyi
graphs with edge correlation coeﬃcient 1 − σ2 and average degree at least polylog(n), we show
that GRAMPA exactly recovers the latent vertex correspondence with high probability when
σ (cid:46) 1/ polylog(n). Moreover, we establish a similar guarantee for a variant of GRAMPA, corre-
sponding to a tighter quadratic programming relaxation of the quadratic assignment problem.
Our analysis exploits a resolvent representation of the GRAMPA similarity matrix and local
laws for the resolvents of sparse Wigner matrices.

Contents

1 Introduction

2 Exact recovery guarantees for GRAMPA

3 Resolvent representation

2

5

7

4 Tools from random matrix theory

8
9
4.1 Concentration inequalities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.2 The Stieltjes transform . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
4.3 Resolvent bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11

5 Proof of correctness for GRAMPA

12
5.1 Decomposition via Schur complement
. . . . . . . . . . . . . . . . . . . . . . . . . . 13
5.2 Oﬀ-diagonal entries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14

∗Z. Fan, C. Mao, and Y. Wu are with Department of Statistics and Data Science, Yale University, New Haven,
USA, {zhou.fan,cheng.mao,yihong.wu}@yale.edu. J. Xu is with The Fuqua School of Business, Duke University,
Durham, USA, jx77@duke.edu. Y. Wu is supported in part by the NSF Grants CCF-1527105, CCF-1900507, an NSF
CAREER award CCF-1651588, and an Alfred Sloan fellowship. J. Xu is supported by the NSF Grants IIS-1838124,
CCF-1850743, and CCF-1856424.

1

 
 
 
 
 
 
5.2.1 Resolvent approximation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
5.2.2 Term-by-term analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
5.2.3 Bounding the norms of g, h and M . . . . . . . . . . . . . . . . . . . . . . . . 17
5.3 Diagonal entries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
5.3.1 Analyzing the trace of M . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20

6 A tighter regularized QP relaxation

21
6.1 Structure of solutions to QP relaxations . . . . . . . . . . . . . . . . . . . . . . . . . 23
6.2 Proof of Theorem 6.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
6.2.1 Resolvent representation of the solution . . . . . . . . . . . . . . . . . . . . . 25
6.2.2 Entrywise approximation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
6.2.3 Oﬀ-diagonal entries
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
6.2.4 Diagonal entries

7 Proof of resolvent bounds

33
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
7.1 Notation and matrix identities
7.2 Entrywise bound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
7.3 Row sum bound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
7.4 Total sum bound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37

1 Introduction

Given two (weighted) graphs, graph matching aims at ﬁnding a bijection between the vertex sets
that maximizes the total edge weight correlation between the two graphs. It reduces to the graph
isomorphism problem when the two graphs can be matched perfectly. Let A and B be the (weighted)
adjacency matrices of the two graphs on n vertices. Then the graph matching problem can be
formulated as solving the following quadratic assignment problem (QAP) [PRW94, BCPP98]:

(cid:104)A, ΠBΠ(cid:62)(cid:105),

max
Π∈Sn

(1)

where Sn denotes the set of permutation matrices in Rn×n and (cid:104)·, ·(cid:105) denotes the matrix inner
product. The QAP is NP-hard to solve or to approximate within a growing factor [MMS10].

In the companion paper [FMWX19], we proposed a computationally eﬃcient spectral graph
matching method, called GRAph Matching by Pairwise eigen-Alignments (GRAMPA). Let us write
the spectral decompositions of A and B as

(cid:88)

A =

λiviv(cid:62)
i

and B =

i

µjwjw(cid:62)
j .

(cid:88)

j

Given a tuning parameter η > 0, GRAMPA ﬁrst constructs an n × n similarity matrix1

X =

(cid:88)

i,j

η

(λi − µj)2 + η2 viv(cid:62)

i Jwjw(cid:62)
j ,

(2)

(3)

1In [FMWX19], X is deﬁned without the factor η in the numerator. We include η here for convenience in the

proof; this does not aﬀect the algorithm as the rounded solution (cid:98)Π is invariant to rescaling X.

2

where J is the n × n all-ones matrix. Then it outputs a permutation matrix (cid:98)Π by “rounding” X
to a permutation matrix, for example, by solving the following linear assignment problem (LAP)

(cid:98)Π ∈ argmax

Π∈Sn

(cid:104)X, Π(cid:105).

(4)

Let Π∗ ∈ Sn be the latent true matching, and denote the entries of A and Π∗BΠ(cid:62)

∗ as aij and
bπ∗(i)π∗(j). A Gaussian Wigner model is studied in [FMWX19], where {(aij, bπ∗(i)π∗(j))} are i.i.d.
pairs of correlated Gaussian variables such that bπ∗(i)π∗(j) = aij +σzij for a noise level σ ≥ 0, and aij
and zij are independent standard Gaussian. It is shown that GRAMPA exactly recovers the vertex
correspondence Π∗ with high probability when σ = O(1/ log n). Simulation results in [FMWX19,
Section 4.1] further show that the empirical performance of GRAMPA under the Gaussian Wigner
model is very similar to that under the Erd˝os-R´enyi model where {(aij, bπ∗(i)π∗(j))} are i.i.d. pairs
of correlated centered Bernoulli random variables, suggesting that the performance of GRAMPA
enjoys universality.

In this paper, we prove a universal exact-recovery guarantee for GRAMPA, under a general
Wigner matrix model for the weighted adjacency matrix: Let A = (aij) be a symmetric random
matrix in Rn×n, where the entries (aij)i≤j are independent. Suppose that

E [aij] = 0 for all i, j,

E (cid:2)a2
ij

(cid:3) =

1
n

for all i (cid:54)= j,

and

E

|aij|k(cid:105)
(cid:104)

≤

Ck
nd(k−2)/2

for all i, j and each k ∈ [2, (log n)10 log log n],

where d ≡ d(n) is an n-dependent sparsity parameter and C is an absolute positive constant.

Of particular interest are the following special cases:

(5)

(6)

• Bounded case: The entries are bounded in magnitude by C√

n . Then (6) is fulﬁlled for d = n

and all k.

• Sub-Gaussian case: The sub-Gaussian norm of each entry satisﬁes

(cid:107)aij(cid:107)ψ2

(cid:44) sup
k≥1

k−1/2E

(cid:104)

|aij|k(cid:105)1/k

= O (cid:0)1/

√

n(cid:1) .

(7)

It is easily checked that (6) is satisﬁed for d = n/(log n)11 log log n and all large n.

• Erd˝os-R´enyi graphs with edge probability p ≡ p(n). We may center and scale the adjacency
matrix A such that aij ∼ (Bern(p) − p)/(cid:112)np(1 − p) for i (cid:54)= j, which satisﬁes (5) and (6) for
d = np(1 − p) (cf. Lemma 2.3).

With the moment conditions (5) and (6) speciﬁed, we are ready to introduce the correlated
Wigner model, which encompasses the correlated Erd˝os-R´enyi graph model proposed in [PG11] as
a special case.

Deﬁnition 1.1 (Correlated Wigner model). Let n be a positive integer, σ ∈ [0, 1] an (n-dependent)
noise parameter, π∗ a latent permutation on [n], and Π∗ ∈ {0, 1}n×n the corresponding permutation

3

matrix such that (Π∗)iπ∗(i) = 1. Suppose that (cid:8)(aij, bπ∗(i)π∗(j)) : i ≤ j(cid:9) are independent pairs of
random variables such that both A = (aij) and B = (bij) satisfy (5) and (6),

E (cid:2)aijbπ∗(i)π∗(j)

(cid:3) ≥

1 − σ2
n

for all i (cid:54)= j,

and for a constant C > 0, any D > 0, and all n ≥ n0(D),
(cid:111)

P

(cid:110)(cid:13)
(cid:13)A − Π∗BΠ(cid:62)
(cid:13)

∗

(cid:13)
(cid:13)
(cid:13) ≤ Cσ

≥ 1 − n−D

(8)

(9)

where (cid:107) · (cid:107) denotes the spectral norm.

The parameter σ measures the eﬀective noise level in the model. In the special case of sparse
Erd˝os-R´enyi model, A and B are the centered and normalized adjacency matrices of two Erd˝os-
R´enyi graphs, which diﬀer by a fraction 2σ2 of edges approximately.

In this paper, we prove the following exact recovery guarantee for GRAMPA:

Theorem (Informal statement). For the correlated Wigner model, if d ≥ polylog(n) and σ ≤
c (log n)−2κ for any ﬁxed constant κ > 2 and a suﬃciently small constant c > 0, then GRAMPA
with η = 1/ polylog n recovers π∗ exactly with high probability for large n. If furthermore aij and
bij are sub-Gaussian and satisfy (7), then this holds with κ = 1.

This theorem generalizes the exact recovery guarantee for GRAMPA proved in [FMWX19] for
the Gaussian Wigner model, albeit at the expense of a slightly stronger requirement for σ than in
the Gaussian case. The requirement that d ≥ polylog(n) and σ ≤ 1/ polylog(n) is the state-of-the-
art for polynomial time algorithms on sparse Erd˝os-R´enyi graphs [DMWX18], although we note
that the recent work of [BCL+18] provided an algorithm with super-polynomial runtime nO(log n)
that achieves exact recovery when d ≥ no(1) under the much weaker condition of σ ≤ 1−(log n)−o(1).
The analysis in [FMWX19] relies heavily on the rotational invariance of Gaussian Wigner
matrices, and does not extend to non-Gaussian models. Here, instead, our universality anal-
ysis uses a resolvent representation of the GRAMPA similarity matrix (3) via a contour inte-
gral (cf. Proposition 3.2). Capitalizing on local laws for the resolvent of sparse Wigner matri-
ces [EKYY13a, EKYY13b], we show that the similarity matrix (3) is with high probability diagonal
dominant in the sense that mink Xkπ∗(k) > max(cid:96)(cid:54)=π∗(k) Xk(cid:96). This enables rounding procedures as
simple as thresholding to succeed.

From an optimization point of view, GRAMPA can also be interpreted as solving a regularized
quadratic programming (QP) relaxation of the QAP. More precisely, the QAP (1) can be equiva-
lently written as

and the similarity matrix X in (3) is a positive scalar multiple of the solution (cid:101)X to

min
Π∈Sn

(cid:107)AΠ − ΠB(cid:107)2
F ,

argmin
X∈Rn×n

(cid:107)AX − XB(cid:107)2

F + η2(cid:107)X(cid:107)2
F

s.t. 1(cid:62)X1 = n.

(10)

(11)

(See [FMWX19, Corollary 2.2].) This is a convex relaxation of the program (10) with an additional
ridge regularization term. As a result, our analysis immediately yields the same exact recovery
guarantees for algorithms that round the solution (cid:101)X to (11) instead of X. In Section 6, we study a
tighter relaxation of the QAP (10) that imposes row-sum constraints, and establish the same exact
recovery guarantees (up to universal constants) by employing similar technical tools.

4

In Section 2, we state the main
Organization The rest of the paper is organized as follows.
exact recovery guarantees for GRAMPA under the correlated Wigner model, as well as the results
specialized to the (sparse) Erd˝os-R´enyi model. We start the analysis by introducing the key resol-
vent representation of the GRAMPA similarity matrix in Section 3. As a preparation for the main
proof, Section 4 provides the needed tools from random matrix theory. The proof of correctness
for GRAMPA is then presented in Section 5. In Section 6, we extend the theoretical guarantees to
a tighter QP relaxation. Finally, Section 7 is devoted to proving the resolvent bounds which form
the main technical ingredient to our proofs.

Notation Let [n] (cid:44) {1, . . . , n}. Let i =
−1. In a Euclidean space Rn or Cn, let ei be the i-th
standard basis vector, and let 1 = 1n be the all-ones vector. Let J = Jn denote the n × n all-ones
matrix, and let I = In denote the n × n identity matrix. The subscripts are often omitted when
there is no ambiguity.

√

The inner product of u, v ∈ Cn is deﬁned as (cid:104)u, v(cid:105) = u∗v. Similarly, for matrices, (cid:104)A, B(cid:105) =
Tr(A∗B). Let (cid:107)v(cid:107) ≡ (cid:107)v(cid:107)2 = (cid:104)v, v(cid:105) and (cid:107)v(cid:107)∞ = supi |vi| for vectors. Let (cid:107)M (cid:107) ≡ (cid:107)M (cid:107)op =
supv:(cid:107)v(cid:107)=1 (cid:107)M v(cid:107), (cid:107)M (cid:107)F = (cid:104)M, M (cid:105), and (cid:107)M (cid:107)∞ = supi,j |Mij| for matrices.

Let x ∧ y = min(x, y) and x ∨ y = max(x, y). We use C, C(cid:48), c, c(cid:48), . . . to denote positive constants
that may change from line to line. For sequences of positive real numbers (an)∞
n=1, we
write an (cid:46) bn (resp. an (cid:38) bn) if there is a constant C > 0 such that an ≤ Cbn (resp. bn ≤ Can)
for all n ≥ 1, an (cid:16) bn if both relations an (cid:46) bn and an (cid:38) bn hold, and an (cid:28) bn if an/bn → 0 as
n → ∞. We write an = O(bn) if |an| (cid:46) bn and an = o(bn) if |an| (cid:28) bn.

n=1 and (bn)∞

2 Exact recovery guarantees for GRAMPA

In this section, we state the the exact recovery guarantees for GRAMPA, making the earlier informal
statement precise.

Theorem 2.1. Fix constants a > 0 and κ > 2, and let η ∈ [1/(log n)a, 1]. Consider the correlated
Wigner model with n ≥ d ≥ (log n)c0 where c0 > max(32 + 4a, 4 + 7a). Then there exist (a, κ)-
dependent constants C, n0 > 0 and a deterministic quantity r(n) ≡ r(n, η, d, a) satisfying r(n) → 0
as n → ∞, such that for all n ≥ n0, with probability at least 1 − n−10, the matrix X in (3) satisﬁes

|Xk(cid:96)| ≤ C(log n)κ 1
√
η

,

max
(cid:96)(cid:54)=π∗(k)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

max
k

Xkπ∗(k) −

1 − σ2
η

(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤ C

(cid:18) r(n)
η

+

σ

η2 + (log n)κ 1

√

η

(cid:19)

.

(12)

If there is a universal constant K for which aij and bij are sub-Gaussian with (cid:107)aij(cid:107)ψ2, (cid:107)bij(cid:107)ψ2 ≤
K/

n, then the above holds also with κ = 1.

√

As an immediate corollary, we obtain the following exact recovery guarantee for GRAMPA.

Corollary 2.2 (Universal graph matching). Under the conditions of Theorem 2.1, there exist
constants c, c(cid:48) > 0 such that for all n ≥ n0, if

(log n)−a ≤ η ≤ c(log n)−2κ

and

σ ≤ c(cid:48)η,

(13)

5

then with probability at least 1 − n−10,

min
k

Xkπ∗(k) > max
(cid:96)(cid:54)=π∗(k)

Xk(cid:96),

(14)

and hence (cid:98)Π which solves the linear assignment problem (4) equals Π∗.

Proof. Let c = 1/(64C2) and c(cid:48) = 1/(2C), where C is the constant given in Theorem 2.1. Then
under assumption (13), we have

C(log n)κ√

η ≤ C(log n)κ

√
c
(log n)κ = C

√

c ≤ 1/8,

so max(cid:96)(cid:54)=π∗(k) |Xk(cid:96)| ≤ 1/(8η). We also have Cσ/η ≤ Cc(cid:48) = 1/2 and 1 − σ2 > 7/8 and Cr(n) < 1/8
for all large n, so that maxk Xkπ∗(k) > (7/8 − 1/8 − 1/2 − 1/8)/η > 1/(8η). This implies (14).

An important application of the above universality result is matching two correlated sparse
Erd˝os-R´enyi graphs. Let G be an Erd˝os-R´enyi graph with n vertices and edge probability q, denoted
by G ∼ G(n, q). Let A and B(cid:48) be two copies of Erd˝os-R´enyi graphs that are i.i.d. conditional on G,
each of which is obtained from G by deleting every edge of G with probability 1 − s independently
where s ∈ [0, 1]. Then we have that A, B(cid:48) ∼ G(n, p) marginally where p (cid:44) qs. Equivalently, we
may ﬁrst sample an Erd˝os-R´enyi graph A ∼ G(n, p), and then deﬁne B(cid:48) by

B(cid:48)

ij ∼

(cid:40)Bern(s)
Bern

(cid:16) p(1−s)
1−p

(cid:17)

if Aij = 1
if Aij = 0.

Suppose that we observe a pair of graphs A and B = Π(cid:62)
matrix. We then wish to recover the permutation matrix Π∗.

∗ B(cid:48)Π∗, where Π∗ is an unknown permutation

We transform the adjacency matrices A and B so that they satisfy the moment conditions (5)

and (6): Deﬁne the centered, rescaled versions of A and B by

A (cid:44) (np(1 − p))−1/2(A − E[A])

and B (cid:44) (np(1 − p))−1/2(B − E[B]).

(15)

Then (5) clearly holds, and we check the following additional properties.

Lemma 2.3. For all large n, the matrices A = (aij) and B = (bij) satisfy (6), (8), and (9) with
d = np(1 − p) and

σ2 = max

(cid:18) 1 − s
1 − p

,

(log n)7
d

(cid:19)

.

Proof. Assume without loss of generality that Π∗ is the identity matrix. For any k ≥ 2 we have

E

(cid:104)

|aij|k(cid:105)

= (np(1 − p))−k/2 (cid:104)

p (1 − p)k + (1 − p)pk(cid:105)

=

(1 − p)k−1 + pk−1
nd(k−2)/2

≤

1
nd(k−2)/2

.

Thus, the moment condition (6) is satisﬁed. In addition, we have that for all i < j,

E [aijbij] =

1
d

E [(Aij − p) (Bij − p)] =

(cid:0)ps − p2(cid:1) =

1
d

s − p
n(1 − p)

≤

1 − σ2
n

,

6

where the last equality holds by the choice of σ2. Thus, (8) is satisﬁed. Moreover, let ∆ij =
2σ2 (aij − bij) . It follows that E [∆ij] = 0 and
1√

E

|∆ij|k(cid:105)
(cid:104)

=

2p(1 − s)
(2σ2d)k/2

≤

1
n(2σ2d)(k−2)/2

where the last inequality is due to σ2 ≥ 1−s
1−p . Thus, by applying Lemma 4.1 and 2(log n)7 ≤ 2σ2d ≤
n where the upper bound follows from p(1 − s) ≤ s(1 − s) ≤ 1/4, there exists a constant C > 0
such that for any D > 0, with probability at least 1 − n−D for all n ≥ n0(D), we have (cid:107)∆(cid:107) ≤ C
and hence (cid:107)A − B(cid:107) ≤

2Cσ. Thus (9) is satisﬁed.

√

Combining Lemma 2.3 with Corollary 2.2 immediately yields a suﬃcient condition for GRAMPA

to exactly recover Π∗ in the correlated Erd˝os-R´enyi graph model.

Corollary 2.4 (Erd˝os-R´enyi graph matching). Suppose that either

(a) (dense case)

δ ≤ p ≤ 1 − δ,

1 − s
1 − p

≤ (log n)−c1

for constants δ ∈ (0, 1) and c1 > 4, or

(b) (sparse case)

np(1 − p) ≥ (log n)c0,

1 − s
1 − p

≤ (log n)−c1

for constants c0 > 48 and c1 > 8.

There exist (δ, c0, c1)-dependent constants a, n0 > 0 such that if η = (log n)−a and n ≥ n0, then
with probability at least 1 − n−10,

min
k

Xkπ∗(k) > max
(cid:96)(cid:54)=π∗(k)

Xk(cid:96),

and hence the solution (cid:98)Π to the linear assignment problem (4) coincides with Π∗.

Proof. For (a), pick κ = 1 and any a such that c1/2 > a > 2κ = 2. For (b), pick any a, κ such that
c1/2 > a > 2κ > 4 and c0 > 32 + 4a > 4 + 7a. Then all conditions of Theorem 2.1 and Corollary 2.2
are satisﬁed for large n, and the result follows.

3 Resolvent representation

For a real symmetric matrix A with spectral decomposition (2), its resolvent is deﬁned by

RA(z) (cid:44) (A − zI)−1 =

(cid:88)

i

1
λi − z

viv(cid:62)
i

for z ∈ C \ R. Then we have the matrix symmetry RA(z)(cid:62) = RA(z), conjugate symmetry RA(z) =
RA(¯z), and the following Ward identity.

7

Lemma 3.1 (Ward identity). For any z ∈ C \ R and any real symmetric matrix A,

RA(z)RA(z) =

Im RA(z)
Im z

.

Proof. By the deﬁnition of R(z) ≡ RA(z) and conjugate symmetry, it holds

Im R(z)
Im z

=

R(z) − R(z)
z − ¯z

=

(A − zI)−1 − (A − ¯zI)−1
z − ¯z

= (A − zI)−1(A − ¯zI)−1 = R(z)R(z).

The following resolvent representation of X is central to our analysis.

Proposition 3.2. Consider symmetric matrices A and B with spectral decompositions (2), and
suppose that (cid:107)A(cid:107) ≤ 2.5. Then the matrix X deﬁned in (3) admits the following representation

X =

1
2π

(cid:73)

Re

Γ

RA(z)JRB(z + iη)dz,

(16)

where

Γ = {z : | Re z| = 3 and | Im z| ≤ η/2 or

| Im z| = η/2 and | Re z| ≤ 3}

(17)

is the rectangular contour with vertices ±3 ± iη/2.

Proof. We have

(cid:88)

i,j
(cid:88)

X = η

= η

viv(cid:62)
i J

wjw(cid:62)
j
(λi − µj)2 + η2

viv(cid:62)

i JRB(λi + iη)RB(λi − iη)

= Im

i
(cid:88)

i

viv(cid:62)

i JRB(λi + iη)

(18)

by Lemma 3.1. Consider the function f : C → Cn×n deﬁned by f (z) = JRB(z + iη). Then each
entry fk(cid:96) is analytic in the region {z : Im z > −η}. Since Γ encloses each eigenvalue λi of A, the
Cauchy integral formula yields entrywise equality

−

1
2πi

(cid:73)

Γ

f (z)
λi − z

dz = f (λi).

(19)

Substituting this into (18), we obtain

X = Im

(cid:88)

viv(cid:62)
i

i

(cid:18)

−

1
2πi

(cid:73)

Γ

f (z)
λi − z

(cid:19)

dz

=

1
2π

(cid:73)

Re

Γ

RA(z)f (z)dz,

(20)

which completes the proof in view of the deﬁnition of f .

4 Tools from random matrix theory

Before proving our main results, we introduce the relevant tools from random matrix theory. In
particular, the resolvent bounds in Theorem 4.5 constitute an important technical ingredient in our
analysis.

8

4.1 Concentration inequalities

We start with some known concentration inequalities in the literature.

Lemma 4.1 (Norm bounds). For any constant ε > 0 and a universal constant c > 0, if n ≥ d ≥
(log n)6+6ε, then with probability at least 1 − e−c(log n)1+ε,

(cid:107)A(cid:107) ≤ 2 +

(log n)1+ε
d1/4

.

Proof. See [EKYY13b, Lemma 4.3], where we ﬁx the parameter ξ = 1 + ε in [EKYY13b, Eq. (2.4)].
The notational identiﬁcation is q ≡

√

d.

Lemma 4.2 (Concentration inequalities). Let α, β ∈ Rn be independent random vectors with
independent entries, satisfying

E[αi] = E[βi] = 0,

E[α2

i ] = E[β2

i ] =

1
n

,

max(E[|αi|k], E[|βi|k]) ≤

1
nd(k−2)/2

for each k ∈ [2, (log n)10 log log n].

(21)

For any constant ε > 0 and universal constants C, c > 0, if n ≥ d ≥ (log n)6+6ε, then:

(a) For each i ∈ [n], with probability at least 1 − e−c(log n)1+ε,

|αi| ≤

C
√
d

.

(b) For any deterministic vector v ∈ Cn, with probability at least 1 − e−c(log n)1+ε,

(cid:12)
(cid:12)v(cid:62)α
(cid:12)

(cid:12)
(cid:12) ≤ (log n)1+ε
(cid:12)

(cid:18) (cid:107)v(cid:107)∞√
d

+

(cid:107)v(cid:107)2√
n

(cid:19)

.

Furthermore, for any even integer p ∈ [2, (log n)10 log log n],

E

p(cid:105)

(cid:104)(cid:12)
(cid:12)v(cid:62)α
(cid:12)

(cid:12)
(cid:12)
(cid:12)

≤ (Cp)p

(cid:18) (cid:107)v(cid:107)∞√
d

+

(cid:107)v(cid:107)2√
n

(cid:19)p

.

(c) For any deterministic matrix M ∈ Cn×n, with probability at least 1 − e−c(log n)1+ε,
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
α(cid:62)M α −
(cid:12)
(cid:12)

(cid:18) 2(cid:107)M (cid:107)∞√
d

≤ (log n)2+2ε

(cid:107)M (cid:107)F
n

Tr M

1
n

+

(cid:19)

and

(cid:12)
(cid:12)α(cid:62)M β
(cid:12)

(cid:12)
(cid:12) ≤ (log n)2+2ε
(cid:12)

(cid:18) 2(cid:107)M (cid:107)∞√
d

+

(cid:107)M (cid:107)F
n

(cid:19)

.

(22)

(23)

(24)

(25)

(26)

Proof. See [EKYY13b, Lemma 3.7, Lemma 3.8, and Lemma A.1(i)], where again we ﬁx ξ = 1 +
ε.

Next, based on the above lemma, we state concentration inequalities for a bilinear form that

apply to our setting directly.

9

Lemma 4.3 (Concentration of bilinear form). Let α, β ∈ Rn be random vectors such that the pairs
(αi, βi) for i ∈ [n] are independent, with

E[αi] = E[βi] = 0,

E[α2

i ] = E[β2

i ] =

1
n

,

E[αiβi] ≥

1 − σ2
n

.

Let M ∈ Cn×n be any deterministic matrix.

(a) For any constant ε > 0, suppose (21) holds where n ≥ d ≥ (log n)6+6ε. Then there are universal

constants C, c > 0 such that with probability at least 1 − e−c(log n)1+ε,

(cid:12)
(cid:12)
(cid:12)
(cid:12)

α(cid:62)M β −

1 − σ2
n

Tr M

(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤ C (log n)2+2ε

(cid:18) 1
n

(cid:107)M (cid:107)F +

(cid:19)

(cid:107)M (cid:107)∞

.

1
√
d

(27)

(b) Suppose that αi, βi are sub-Gaussian with (cid:107)αi(cid:107)ψ2 = (cid:107)βi(cid:107)ψ2 ≤ K√

n for a constant K > 0. Then
for any D > 0, there exists a constant C ≡ CK,D only depending on K and D such that with
probability at least 1 − n−D,

(cid:12)
(cid:12)
α(cid:62)M β −
(cid:12)
(cid:12)

1 − σ2
n

Tr M

(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤

C log n
n

(cid:107)M (cid:107)F .

(28)

Proof. In view of the polarization identity

α(cid:62)M β =

1
4

(α + β)(cid:62)M (α + β) −

(α − β)(cid:62)M (α − β),

1
4

it suﬃces to analyze the two terms separately. Note that

(cid:105)
(cid:104)
(α + β)(cid:62)M (α + β)

E

=

4 − 2σ2
n

Tr M,

(cid:104)

(cid:105)
(α − β)(cid:62)M (α − β)

E

=

2σ2
n

Tr M,

which yields the desired expectation E[α(cid:62)M β] = 1−σ2

n Tr M. Thus it remains to study the deviation.
To prove the concentration bound (27), we obtain from (25) that, there is a universal constant

c > 0 such that with probability at least 1 − e−c(log n)1+ε,

(cid:12)
(cid:12)
(cid:12) ≤ (log n)2+2ε
(cid:12)(α ± β)(cid:62)M (α ± β) − E[(α ± β)(cid:62)M (α ± β)]
(cid:12)
(cid:12)

(cid:18) 1
n

(cid:107)M (cid:107)F +

(cid:19)

(cid:107)M (cid:107)∞

,

2
√
d

from which (27) easily follows.

The sub-Gaussian concentration bound (28) follows from the Hanson-Wright inequality [HW71,
d, so taking

RV13]. More precisely, note that max{(cid:107)α + β(cid:107)ψ2, (cid:107)α − β(cid:107)ψ2} ≤ (cid:107)α(cid:107)ψ2 + (cid:107)β(cid:107)ψ2 ≤ 2K/
δ = n−D/2 in [FMWX19, Lemma A.2] yields that with probability at least 1 − n−D,

√

(cid:12)
(cid:12)(α ± β)(cid:62)M (α ± β) − E
(cid:12)

(cid:104)

(α ± β)(cid:62)M (α ± β)

(cid:105)(cid:12)
(cid:12)
(cid:12) ≤ CK,D

log n
n

(cid:107)M (cid:107)F ,

which completes the proof.

10

4.2 The Stieltjes transform

Denote the semicircle density and its Stieltjes transform by

ρ(x) =

(cid:112)

4 − x2 1{|x|≤2}

1
2π

and m0(z) =

(cid:90)

ρ(x)dx =

−z +

z2 − 4

√

2

(29)

1
x − z
√

respectively, where m0(z) is deﬁned for z /∈ [−2, 2], and
[−2, 2] so that

√

z2 − 4 ∼ z as |z| → ∞. We have the conjugate symmetry m0(z) = m0(¯z).

z2 − 4 is deﬁned with a branch cut on

We record the following basic facts about the Stieltjes transform.

Proposition 4.4. For each z ∈ C \ R, the Stieltjes transform m0(z) is the unique value satisfying

m0(z)2 + zm0(z) + 1 = 0

and

Im m0(z) · Im z > 0.

(30)

Setting ζ(z) (cid:44) min(| Re z − 2|, | Re z + 2|), uniformly over z ∈ C \ [−2, 2] with |z| ≤ 10,

|m0(z)| (cid:16) 1,

| Im m0(z)| (cid:38) | Im z|,

and | Im m0(z)| (cid:16)

(cid:40)(cid:112)ζ(z) + | Im z|

| Im z|/(cid:112)ζ(z) + | Im z|

if | Re z| ≤ 2,
if | Re z| > 2.
(31)

For x ∈ [−2, 2], the continuous extensions

m+

0 (x) (cid:44)

lim
z→x: z∈C+

m0(z), m−

0 (x) (cid:44)

lim
z→x: z∈C−

m0(z)

from C+ and C− both exist. For all x ∈ [−2, 2], these satisfy

m±

0 (x)2 + xm±

0 (x) + 1 = 0, m+

0 (x) = m−

0 (x),

1
π

Im m+

0 (x) = −

1
π

Im m−

0 (x) = ρ(x),

|m±

0 (x)| = 1.
(32)

(31) follows from [EKYY13a, Lemma 4.3] and
Proof. (30) follows from the deﬁnition of m0.
continuity and conjugate symmetry of m0. For the existence of m+
0 ), see e.g.
the more general statement of [Bia97, Corollary 1]. The ﬁrst claim of (32) follows from continuity
and (30), the second from conjugate symmetry, the third from the Stieltjes inversion formula, and
the last from the fact that the two roots of (30) at z = x ∈ [−2, 2] are m+
0 (x),
so that 1 = m±

0 (and hence also m−

0 (x) and m−

0 (x) = m+

0 (x)m±

0 (x) = |m±

0 (x)|2.

4.3 Resolvent bounds

For a ﬁxed constant a > 0 and all large n, we bound the resolvent R(z) = RA(z) over the spectral
domain

D = D1 ∪ D2, where
D1 = {z ∈ C : Re z ∈ [−3, 3], | Im z| ∈ [1/(log n)a, 1]}, and
D2 = {z ∈ C : | Re z| ∈ [2.6, 3], | Im z| ≤ 1/(log n)a}.

Here, D1 is the union of two strips in the upper and lower half planes, and D2 is the union of two
strips in the left and right half planes.

11

Theorem 4.5 (Resolvent bounds). Suppose A ∈ Rn×n has independent entries (aij)i≤j satisfying
(5) and (6). Fix a constant a > 0 which deﬁnes the domain D, ﬁx ε > 0, and set

b = max(16 + 3ε + 2a, 3 + 3ε + 5a/2),

b(cid:48) = max(16 + 4ε + 2a, 4 + 5ε + 6a).

Suppose n ≥ d ≥ (log n)b(cid:48). Then for some constants C, c, n0 > 0 depending on a and ε, and for all
n ≥ n0, with probability 1 − e−c(log n)(log log n), the following hold simultaneously for every z ∈ D:

(a) (Entrywise bound) For all j (cid:54)= k ∈ [n],

For all j ∈ [n],

|Rjk(z)| ≤

C(log n)2+2ε+a
√
d

.

|Rjj(z) − m0(z)| ≤

C(log n)2+2ε+3a/2
√
d

.

(b) (Row sum bound) For all j ∈ [n],

(c) (Total sum bound)

(cid:12)
(cid:12)e(cid:62)
(cid:12)

j R(z)1

(cid:12)
(cid:12) ≤ C(log n)1+ε+a.
(cid:12)

|1(cid:62)R(z)1 − n · m0(z)| ≤

Cn(log n)b
√
d

.

(33)

(34)

(35)

(36)

The proof follows ideas of [EKYY13b], and we defer this to Section 7. As the spectral parameter
z is allowed to converge to the interval [−2, 2] with increasing n, this type of result is often called
a “local law” in the random matrix theory literature. The focus of the above is a bit diﬀerent from
the results stated in [EKYY13b], as we wish to obtain explicit logarithmic bounds for | Im z| (cid:16)
1/ polylog(n), rather than bounds for more local spectral parameters down to the scale of | Im z| (cid:16)
polylog(n)/n.

5 Proof of correctness for GRAMPA

∗ wj and X (cid:55)→ XΠ∗, since JΠ(cid:62)

In this section, we prove Theorem 2.1. Note that the mapping B (cid:55)→ Π(cid:62)
∗ BΠ∗ for any permutation Π∗
induces wj (cid:55)→ Π(cid:62)
∗ = J. By virtue of this equivariance, throughout the
proof, we may assume without loss of generality that Π∗ = I, i.e. the underlying true permutation
π∗ is the identity permutation. Then we aim to show that X is diagonally dominant, in the sense
that mink Xkk > maxk(cid:54)=(cid:96) Xk(cid:96).

In view of Lemma 4.1, we have that (cid:107)A(cid:107) ≤ 2.5 holds with probability 1−n−D for any D > 0 and
all n ≥ n0(D). In the following, we assume that (cid:107)A(cid:107) ≤ 2.5 holds. On this event, by Proposition 3.2,
we get that

Xk(cid:96) =

1
2π

(cid:73)

Re

Γ

(e(cid:62)

k RA(z)1)(e(cid:62)

(cid:96) RB(z + iη)1)dz

(37)

12

Note that one may attempt to directly apply (35) to bound the row sums e(cid:62)

k RA(z)1 and

e(cid:62)
(cid:96) RB(z + iη)1. This would yield

(cid:12)
(cid:12)(e(cid:62)
(cid:12)

k RA(z)1)(e(cid:62)

(cid:12)
(cid:12)
(cid:96) RB(z + iη)1)
(cid:12)

(cid:46) (log n)2+2ε+2a,

and hence |Xk(cid:96)| (cid:46) (log n)2+2ε+2a. However, this estimate is too crude to capture the diﬀerences
between the diagonal and oﬀ-diagonal entries. In fact, the row sum e(cid:62)
k RA(z)1 does not concentrate
on its mean, and the deviation e(cid:62)
(cid:96) RB(z + iη)1 − m0(z) is uncorrelated for
k (cid:54)= (cid:96) and positively correlated for k = (cid:96). For this reason, the diagonal entries of (37) dominate
the oﬀ-diagonals. Thus it is crucial to gain a better understanding of the deviation terms. We do
so by applying Schur complement decomposition.

k RA(z)1 − m0(z) and e(cid:62)

5.1 Decomposition via Schur complement

We recall the classical Schur complement identity for the inverse of a block matrix.

Lemma 5.1 (Schur complement identity). For any invertible matrix M ∈ Cn×n and block decom-
position

M =

(cid:21)

(cid:20)A B
C D

,

if D is square and invertible, then

M −1 =

where S = (A − BD−1C)−1.

S

(cid:20)
−D−1CS D−1 + D−1CSBD−1

−SBD−1

(cid:21)

(38)

We decompose e(cid:62)

k RA(z)1 and e(cid:62)

(cid:96) RB(z + iη)1 using this identity, focusing without loss of gen-
erality on (k, (cid:96)) = (1, 2). Let RA,12 ∈ C2×2 be the upper-left 2 × 2 sub-matrix of RA, and let
R(12)
A ∈ C(n−2)×(n−2) be the resolvent of the (n − 2) × (n − 2) minor of A with the ﬁrst two rows
and columns removed. Let a(cid:62)
2 be the the ﬁrst two rows of A with ﬁrst two entries removed,
and let A(cid:62)

o ∈ R2×(n−2) be the stacking of a(cid:62)

1 and a(cid:62)

1 and a(cid:62)
2 .

The following deterministic lemma approximates e(cid:62)

1 RA(z)1 based on the Schur complement.

Lemma 5.2. Suppose |z| ≤ 10, and

(cid:107)RA,12(z) − m0(z)I(cid:107) ≤ δ

where 0 ≤ δ ≤ minz:|z|≤10 |m0(z)|/2. Then for a constant C > 0 and k = 1, 2

(cid:12)
(cid:12)e(cid:62)
(cid:12)

k RA(z)1 − m0(z)

(cid:16)

1 − a(cid:62)

k R(12)

A (z)1n−2

(cid:17)(cid:12)
(cid:12)
(cid:12) ≤ Cδ (1 + (cid:107)RA(z)1(cid:107)∞) .

(39)

(40)

Proof. It suﬃces to consider k = 1. Applying the Schur complement identity (38), the ﬁrst two
rows of RA are given by

.

(41)

(cid:105)

(cid:104)

RA,12 −RA,12A(cid:62)

o R(12)

A

13

Thus

1 RA(z)1 = (cid:2)1 0(cid:3) (cid:104)
e(cid:62)

RA,12 −RA,12A(cid:62)

o R(12)

A

(cid:21)

(cid:105) (cid:20) 12
1n−2

= (cid:2)1 0(cid:3) RA,12

(cid:16)

12 − A(cid:62)

o R(12)

A 1n−2

(cid:17)

.

Denote ∆A (cid:44) RA,12(z) − m0(z)I. Then

1 RA(z)1 = (cid:2)1 0(cid:3) (m0(z)I + ∆A)
e(cid:62)

(cid:16)

(cid:16)

(cid:16)

= m0(z)

= m0(z)

1 − a(cid:62)

A 1n−2

1 − a(cid:62)

A 1n−2

1 R(12)
1 R(12)

(cid:17)

.

A 1n−2
(cid:16)

12 − A(cid:62)
(cid:17)

o R(12)
+ (cid:2)1 0(cid:3) ∆A
(cid:16)

(cid:17)

(cid:16)

+ O

δ

1 +

12 − A(cid:62)

o R(12)
A 1n−2
(cid:13)
(cid:17)(cid:17)
(cid:13)
(cid:13)

A 1n−2

,

(cid:13)
(cid:13)A(cid:62)
(cid:13)

o R(12)

(cid:17)

.

(42)

(cid:13)
(cid:13)
(cid:13). In view of the fact
where the last equality applies (39). We next upper bound
that C ≥ |m0(z)| ≥ c for absolute constants c and C, the assumption (39) implies that RA,12 is
invertible with (cid:107)R−1

A,12(cid:107) (cid:46) 1. Using (41) again, we have

A 1n−2

o R(12)

(cid:13)
(cid:13)A(cid:62)
(cid:13)

o R(12)
A(cid:62)

A 1n−2 = 12 − R−1

A,12

(cid:2)e1 e2

(cid:3)(cid:62) RA1n.

It follows that

(cid:13)
(cid:13)A(cid:62)
(cid:13)

o R(12)

A 1n−2

(cid:13)
(cid:13)
(cid:13)

(cid:46) 1 +

(cid:12)
(cid:12)e(cid:62)
(cid:12)

1 RA1n

(cid:12)
(cid:12)
(cid:12) +

(cid:12)
(cid:12)e(cid:62)
(cid:12)

2 RA1n

(cid:12)
(cid:12)
(cid:12)

(cid:46) 1 + (cid:107)RA1n(cid:107)∞ .

(43)

(44)

The desired bound (40) follows by combining (42) and (44).

5.2 Oﬀ-diagonal entries

Without loss of generality, we focus on the oﬀ-diagonal entry X12:

X12 =

1
2π

Re

(cid:73)

(cid:16)

Γ

e(cid:62)
1 RA(z)1

(cid:17) (cid:16)

(cid:17)
e(cid:62)
2 RB(z + iη)1

dz.

For the given value a > 0 in Theorem 2.1, and for some small constant ε > 0, let b, b(cid:48) be as
deﬁned in Theorem 4.5. Under the given condition for c0 in Theorem 2.1, for ε > 0 suﬃciently small,
we have c0 > b(cid:48) and c0 > 2b—thus d (cid:29) (log n)b(cid:48) so Theorem 4.5 applies, and also
d (cid:29) (log n)b.
(cid:46) 1/
Fix the constant κ, where κ = 1 in the sub-Gaussian case where (cid:107)aij(cid:107)ψ2, (cid:107)bij(cid:107)ψ2
n, and κ > 2
otherwise. For ease of notation, we deﬁne

√
√

δ1 =

(log n)2+2ε+3a/2
√
d

,

δ2 =

(log n)1+ε+a
√
n

,

δ3 =

(log n)b
√
d

,

δ4 =

(log n)κ/2
√
n

.

(45)

Note that we have δi = o(1) for each i = 1, 2, 3, 4, and also δ1δ2

2n = o(1).

14

5.2.1 Resolvent approximation

Deﬁne an event E1 wherein the following hold simultaneously for all z ∈ Γ:

(cid:107)RA,12(z) − m0(z)I(cid:107) (cid:46) δ1
(cid:107)RB,12(z + iη) − m0(z + iη)I(cid:107) (cid:46) δ1
(cid:46) δ2
(cid:46) δ2

(cid:107)RA(z)1(cid:107)∞
(cid:107)RB(z + iη)1(cid:107)∞

√

√

n

n.

Applying the resolvent approximations given in Theorem 4.5, we have that

P {E1} ≥ 1 − e−c(log n)(log log n).

In the following, we assume the event E1 holds.

On E1, by Lemma 5.2, we get that uniformly over z ∈ Γ,

e(cid:62)
1 RA(z)1 = m0(z)

(cid:16)

e(cid:62)
2 RB(z + iη)1 = m0(z + iη)

1 − b(cid:62)

B 1n−2

1 − a(cid:62)
(cid:16)

1 R(12)

A 1n−2
2 R(12)

(cid:17)

+ O (cid:0)δ1δ2
(cid:17)

√

n(cid:1) ,
√

+ O (cid:0)δ1δ2

(46)

(47)

(48)

(49)

(50)

(51)

n(cid:1) .

Each of (50) and (51) is itself O(δ2

√

n), by (48) and (49). Then multiplying the two, we have

(cid:104)

e(cid:62)
1 RA(z)1

(cid:105) (cid:104)

(cid:105)
e(cid:62)
2 RB(z + iη)1

= m0(z)m0(z + iη)

(cid:16)

It follows that

1 − a(cid:62)

1 R(12)

A 1n−2 − b(cid:62)

2 R(12)

B 1n−2 + a(cid:62)

1 R(12)

A Jn−2R(12)

B b2

(cid:17)

+ O (cid:0)δ1δ2

2n(cid:1) .

(cid:73)

Γ

=

where

(cid:104)
e(cid:62)
1 RA(z)1

(cid:105) (cid:104)

e(cid:62)
2 RB(z + iη)1

(cid:105)

dz

(cid:73)

Γ

m0(z)m0(z + iη)dz − a(cid:62)

1 g − b(cid:62)

2 h + a(cid:62)

1 M b2 + O (cid:0)δ1δ2

2n(cid:1) ,

g (cid:44)

h (cid:44)

M (cid:44)

(cid:73)

Γ
(cid:73)

Γ
(cid:73)

Γ

m0(z)m0(z + iη)R(12)

A (z)1n−2dz,

m0(z)m0(z + iη)R(12)

B (z + iη)1n−2dz,

m0(z)m0(z + iη)R(12)

A (z)Jn−2R(12)

B (z + iη)dz.

5.2.2 Term-by-term analysis

Next, we bound the individual terms of (52). By the boundedness of m0(z), we have

(cid:73)

Γ

m0(z)m0(z + iη)dz = O(1).

15

(52)

(53)

(54)

Deﬁne the event E2 wherein the following hold simultaneously:

(cid:12)
(cid:12)a(cid:62)
(cid:12)
1 g

(cid:12)
(cid:12)
(cid:12) +
(cid:12)
(cid:12)a(cid:62)
(cid:12)

(cid:12)
(cid:12)
(cid:12)b(cid:62)
(cid:12)
(cid:12)
2 h
(cid:12)
(cid:12)
(cid:12)
1 M b2
(cid:12)

(cid:46) δ1 ((cid:107)g(cid:107)∞ + (cid:107)h(cid:107)∞) + δ4 ((cid:107)g(cid:107)2 + (cid:107)h(cid:107)2)

(cid:46) δ1(cid:107)M (cid:107)∞ + δ2

4(cid:107)M (cid:107)F .

(55)

(56)

Note that the triple (g, h, M ) is independent of the pair (a1, b2) and a1 and b2 are independent.
Hence, by ﬁrst conditioning on (g, h, M ) and then applying (23) and (26), we get that

P {E2} ≥ 1 − n−D

for any constant D > 0,2 and all n ≥ n0(D), in both the sub-Gaussian (κ = 1) and general (κ > 2)
cases. Henceforth, we assume E2 holds. It then remains to bound the (cid:96)2 and (cid:96)∞ norms of g, h, and
M .

−3 −2.6

Im

η/2

η/4

−η/4

−η/2

z ∈ Γ

w ∈ Γ(cid:48)

2.6

3

Re

Figure 1: Nested contours Γ and Γ(cid:48).

Recall that Γ is the rectangular contour with vertices ±3 ± i η

(to be used later) Γ(cid:48) inside Γ, with vertices ±2.6 ± i η
following hold simultaneously for all z ∈ Γ ∪ Γ(cid:48):

2 . Let us deﬁne another contour
4 , cf. Fig. 1. Deﬁne the event E3 wherein the

A (z)1n−2

(cid:13)
(cid:13)R(12)
(cid:13)
B (z + iη)1n−2

(cid:13)
(cid:13)
(cid:13)∞
(cid:13)
(cid:13)
(cid:13)∞
(cid:12)
(cid:12)
A (z)1n−2 − m0(z)(n − 2)
(cid:12)
(cid:12)
(cid:12)
B (z + iη)1n−2 − m0(z + iη)(n − 2)
(cid:12)

(cid:13)
(cid:13)R(12)
(cid:13)

n−2R(12)

(cid:12)
(cid:12)1(cid:62)
(cid:12)

(cid:12)
(cid:12)1(cid:62)
(cid:12)

n−2R(12)

√

√

n,

n,

(cid:46) δ2

(cid:46) δ2

(cid:46) δ3n,

(cid:46) δ3n.

(57)

(58)

(59)

(60)

By Theorem 4.5, we have that P {E3} ≥ 1 − e−c(log n)(log log n). In the following, we assume the event
E3 holds.

Note that

(cid:107)g(cid:107)∞ (cid:46) sup
z∈Γ

(cid:107)R(12)

A (z)1n−2(cid:107)∞ (cid:46) δ2

√

n,

(61)

2The constant D can be made arbitrarily large by setting the hidden constants in (55) and (56) suﬃciently large.

16

where the second inequality holds in view of (57). Similarly, in view of (58), we have that (cid:107)h(cid:107)∞ (cid:46)
δ2

n. Furthermore,

√

(cid:107)M (cid:107)∞ (cid:46) sup
z∈Γ

(cid:13)
(cid:13)R(12)
(cid:13)

A (z)Jn−2R(12)

B (z + iη)

(cid:13)
(cid:13)
(cid:13)∞

≤ sup
z∈Γ

(cid:13)
(cid:13)R(12)
(cid:13)

A (z)1n−2

(cid:13)
(cid:13)
(cid:13)∞

(cid:13)
(cid:13)1(cid:62)
(cid:13)

n−2R(12)

(cid:13)
(cid:13)
B (z + iη)
(cid:13)∞

(cid:46) δ2

2n.

(62)
The (cid:96)2 bounds of g, h and M are deferred to Lemma 5.3 below. Applying (59), (60), and Lemma 5.3
with RA = R(12)

(cid:46) n log 1
Combining the above bounds on the norms of g, h, M with (55), (56), and (54), and plugging

η and (cid:107)M (cid:107)F (cid:46) n/

B , we get (cid:107)g(cid:107)2
2

and RB = R(12)

(cid:46) n log 1

η , (cid:107)h(cid:107)2
2

√

η.

A

into (52), we conclude that on the event {(cid:107)A(cid:107) ≤ 2.5} ∩ E1 ∩ E2 ∩ E3,

|X12| = 2π

[e(cid:62)

1 RA(z)1][e(cid:62)

2 RB(z + iη)1]dz

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:73)
(cid:12)
(cid:12)
(cid:12)

Γ
(cid:114)

(cid:46) 1 + δ4

n log

1
η

+ δ2

4n

1
√
η

+ δ1δ2

2n (cid:46) δ2
4n

where in the third step we used δ1δ2

2n = o(1) and η ≤ 1 so that δ4

= (log n)κ 1
√
η

1
√
η
n = (log n)κ/2 (cid:38) (cid:113)

√

,

(63)

η log 1

η +η1/4.

5.2.3 Bounding the norms of g, h and M
(cid:12)1(cid:62)R(z)1(cid:12)
Lemma 5.3. Suppose (cid:107)A(cid:107) ≤ 2.5 and (cid:12)
R(z) = RB(z + iη). Deﬁne

(cid:12) (cid:46) n for all z ∈ Γ ∪ Γ(cid:48) and both R(z) = RA(z) and

g =

h =

M =

(cid:73)

Γ
(cid:73)

Γ
(cid:73)

Γ

m0(z)m0(z + iη)RA(z)1dz

m0(z)m0(z + iη)RB(z + iη)1dz

m0(z)m0(z + iη)RA(z)JRB(z + iη)dz.

Then (cid:107)g(cid:107)2 (cid:46) n log 1

η , (cid:107)h(cid:107)2 (cid:46) n log 1

η and (cid:107)M (cid:107)2
F

(cid:46) n2
η .

Proof. Since (cid:107)A(cid:107) ≤ 2.5, the function m0(z)m0(z + iη)RA(z)1 is analytic in z in the region between
Γ(cid:48) and Γ. It follows that

g =

(cid:73)

Γ

m0(z)m0(z + iη)RA(z)1dz =

(cid:73)

Γ(cid:48)

m0(w)m0(w + iη)RA(w)1dw.

(cid:73)

Thus

(cid:107)g(cid:107)2 (a)
=

(cid:73)

Γ

(b)
= −

(c)
= −

dz

(cid:73)

Γ
(cid:73)

Γ

dz

Γ(cid:48)

(cid:73)

Γ(cid:48)

dz

dw m0(z)m0(z + iη)m0( ¯w)m0( ¯w − iη)1(cid:62)RA( ¯w)RA(z)1
Γ(cid:48)
(cid:73)

dw m0(z)m0(z + iη)m0(w)m0(w − iη)1(cid:62)RA(w)RA(z)1

dw m0(z)m0(z + iη)m0(w)m0(w − iη)1(cid:62) RA(z) − RA(w)

z − w

1

(cid:73)

(d)
(cid:46) n

(cid:73)

dz

Γ

Γ(cid:48)

1
|z − w|

17

(64)

where (a) applies conjugation symmetry of m0 and RA; (b) changes variables w (cid:55)→ ¯w which reverses
the direction of integration along Γ(cid:48); (c) follows from the identity

RA(z)RA(w) = (A−z)−1(A−w)−1 =

[(A−z)−1 −(A−w)−1] =

1
z − w

[RA(z)−RA(w)] (65)

and (d) holds because |m0(z)| (cid:16) 1 and (cid:12)
(cid:12) (cid:46) n for all z ∈ Γ ∪ Γ(cid:48) by assumption. For either
z or w in the vertical strips of Γ ∪ Γ(cid:48) of length O(η), we apply simply |z − w| (cid:38) η. For both z and w
in the horizontal strips, i.e. | Im z| = η/2 and | Im w| = η/4, we apply |z − w| (cid:38) | Re(z) − Re(w)| + η.
This gives

1
z − w
(cid:12)1(cid:62)RA(z)1(cid:12)

(cid:107)g(cid:107)2 (cid:46) n

For (cid:107)h(cid:107)2, we have similarly

(cid:18)

(cid:90) 3

(cid:90) 2.6

1 +

dx

−3

−2.6

(cid:19)

dy

1
|x − y| + η

(cid:46) n log

1
η

.

(cid:107)h(cid:107)2 = −

(cid:73)

(cid:73)

dz

(cid:46) n

Γ(cid:48)

(cid:73)

Γ

(cid:73)

dz

Γ

Γ(cid:48)

dw m0(z)m0(z + iη)m0(w)m0(w − iη)1(cid:62) RB(z + iη) − RB(w − iη)

(z + iη) − (w − iη)

1

1
|z − w + 2iη|.

We may again bound |z − w + 2iη| (cid:38) η if either z or w belongs to a vertical strip, or |z − w + 2iη| (cid:38)
| Re(z) − Re(w)| + η otherwise, to obtain (cid:107)h(cid:107)2 (cid:46) n log(1/η).

Finally, we bound (cid:107)M (cid:107)F . Since (cid:107)A(cid:107) ≤ 2.5, the function m0(z)m0(z + iη)RA(z)JRB(z + iη) is

analytic in z in the region between Γ(cid:48) and Γ, so

M =

(cid:73)

Γ

m0(z)m0(z + iη)RA(z)JRB(z + iη)dz =

(cid:73)

Γ(cid:48)

m0(w)m0(w + iη)RA(w)JRB(w + iη)dw.

Consequently, by the same arguments that leads to (64),

(cid:107)M (cid:107)2
F
= Tr(M ∗M )

dw m0(z)m0(z + iη)m0(w)m0(w − iη) Tr (cid:2)RA(z)11(cid:62)RB(z + iη)RB(w − iη)11(cid:62)RA(w)(cid:3)
Γ(cid:48)
(cid:73)

dw m0(z)m0(z + iη)m0(w)m0(w − iη)1(cid:62)RA(w)RA(z)11(cid:62)RB(z + iη)RB(w − iη)1

dz

dw m0(z)m0(z + iη)m0(w)m0(w − iη)

1(cid:62)(RA(z) − RA(w))1
z − w

1(cid:62)(RB(z + iη) − RB(w − iη))1
z + iη − (w − iη)

dw

1
|z − w|

1
|z − w + 2iη|

.

If z or w belongs to a vertical strip of Γ ∪ Γ(cid:48), of length O(η), then |z − w| · |z − w + 2iη| (cid:38) η2;
otherwise, |z − w| · |z − w + 2iη| (cid:38) (| Re(z) − Re(w)| + η)2 (cid:38) (Re(z) − Re(w))2 + η2. Then

(cid:107)M (cid:107)2
F

(cid:46) n2

(cid:18) 1
η

+

(cid:90) 3

dx

(cid:90) 2.6

−3

−2.6

dy

1
(x − y)2 + η2

(cid:19)

(cid:46) n2
η

.

18

(cid:73)

=

(cid:73)

Γ

= −

dz

(cid:73)

Γ
(cid:73)

Γ

(cid:73)

Γ

dz

dz

Γ(cid:48)

(cid:73)

Γ(cid:48)

(cid:73)

Γ(cid:48)

= −

(cid:46) n2

5.3 Diagonal entries

Without loss of generality, we consider the diagonal entry X11:
1
2π

(cid:104)
e(cid:62)
1 RA(z)1

X11 =

Re

(cid:105) (cid:104)

(cid:73)

1(cid:62)RB(z + iη)e1

Γ

(cid:105)

dz.

By similar arguments as in the oﬀ-diagonal entry X12 that lead to (50) and (51), we obtain that
for all z ∈ Γ,

e(cid:62)
1 RA(z)1 = m0(z)

(cid:16)

(cid:17)

1 R(1)

1 − a(cid:62)
(cid:16)

A (z)1n−1
1 R(1)

B (z)1n−1

+ O (cid:0)δ1δ2
(cid:17)

√

n(cid:1)

+ O (cid:0)δ1δ2

√

n(cid:1) .

e(cid:62)
1 RB(z + iη)1 = m0(z + iη)

1 − b(cid:62)

It follows that
(cid:104)
e(cid:62)
1 RA(z)1

(cid:105) (cid:104)

(cid:105)

1(cid:62)RB(z + iη)e1
(cid:16)

= m0(z)m0(z + iη)

1 − a(cid:62)

1 R(1)

A 1n−1 − 1(cid:62)

n−1R(1)

B b1 + a(cid:62)

1 R(1)

A Jn−1R(1)

B b1

(cid:17)

+ O (cid:0)δ1δ2

2n(cid:1) ,

1 are the ﬁrst rows of A and B with ﬁrst entries removed; and R(1)
A
B are the resolvents of the minors of A and B with ﬁrst rows and columns removed. Thus,

1 and b(cid:62)

where respectively, a(cid:62)
and R(1)
we get that

e(cid:62)
1 RA(z)1

(cid:105) (cid:104)

1(cid:62)RB(z + iη)e1

(cid:105)

dz

(cid:104)

(cid:73)

(cid:73)

Γ

=

m0(z)m0(z + iη)dz − a(cid:62)

1 g − b(cid:62)

1 h + a(cid:62)

1 M b1 + O (cid:0)δ1δ2

2n(cid:1) ,

(66)

where

Γ

g (cid:44)

h (cid:44)

M (cid:44)

(cid:73)

Γ
(cid:73)

Γ
(cid:73)

Γ

m0(z)m0(z + iη)R(1)

A (z)1dz,

m0(z)m0(z + iη)R(1)

B (z + iη)1dz,

m0(z)m0(z + iη)R(1)

A (z)JR(1)

B (z + iη)dz.

By the same argument as in the oﬀ-diagonal entry X12, we can control each term above. The
only diﬀerence is that for the bilinear form, instead of using (26), applying Lemma 4.3 to control
a(cid:62)
1 M b1 gives an extra expectation term (1 − σ2)n−1 Tr M . Therefore, we obtain that for any ﬁxed
constant D > 0, with probability at least 1 − n−D, for all suﬃciently large n,

(cid:12)
(cid:12)
X11 −
(cid:12)
(cid:12)

1 − σ2
2π

Re

Tr M
n

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:46) (log n)κ 1
√
η

.

(67)

Denote by E4 the event where the following hold simultaneously for all z ∈ Γ:

(cid:107)A − B(cid:107) (cid:46) σ

(cid:12)
(cid:12)1(cid:62)
(cid:12)

n−1R(1)

A (z)1n−1 − m0(z)n

(cid:12)
(cid:12)1(cid:62)
(cid:12)

n−1R(1)

B (z + iη)1n−1 − m0(z + iη)n

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:46) δ3n

(cid:46) δ3n.

19

By the assumption (9) and Theorem 4.5, we have that P {E4} ≥ 1 − n−D for any constant D > 0
and all n ≥ n0(D).

We defer the analysis of Tr M to Lemma 5.4 and Lemma 5.5 below: Assuming E4 holds and

applying Lemma 5.4 and Lemma 5.5 with RA, RB replaced by R(1)

B , respectively, we get

1
n

Re Tr(M ) =

2π + oη(1)
η

+ O

(cid:18) σ

η2 +

δ3
η

Setting r(n) = oη(1) + δ3, we get

(cid:12)
(cid:12)
X11 −
(cid:12)
(cid:12)

1 − σ2
η

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:46) r(n)
η

+

σ

η2 + (log n)κ 1

√

η

A , R(1)
(cid:19)

.

.

5.3.1 Analyzing the trace of M

Lemma 5.4. Suppose (cid:107)A(cid:107) ≤ 2.5 and (cid:107)A − B(cid:107) (cid:46) σ and

(cid:12)
(cid:12)
(cid:12)1(cid:62)RA(z)1 − m0(z)n
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)1(cid:62)RB(z + iη)1 − m0(z + iη)n
(cid:12)
(cid:12)
(cid:12)

(cid:46) δ3n,

(cid:46) δ3n,

for all z ∈ Γ. Deﬁne

M =

(cid:73)

Γ

m0(z)m0(z + iη)RA(z)JRB(z + iη)dz.

Then

1
n

Tr M =

1
iη

(cid:73)

Γ

m0(z)m0(z + iη)(m0(z + iη) − m0(z))dz + O

(cid:18) σ

η2 +

(cid:19)

.

δ3
η

Proof. Applying the identity

RB(z + iη) − RA(z) = (B − (z + iη))−1 − (A − z)−1 = RB(z + iη)(A − B + iη)RA(z),

we get RB(z + iη)RA(z) = 1

iη (RB(z + iη) − RA(z) − RB(z + iη)(A − B)RA(z)). Therefore

Tr M =

=

=

(cid:73)

Γ
(cid:73)

Γ
1
iη

dz m0(z)m0(z + iη) Tr (cid:2)RA(z)JRB(z + iη)(cid:3)

dz m0(z)m0(z + iη)1(cid:62)RB(z + iη)RA(z)1
(cid:73)

dz m0(z)m0(z + iη)1(cid:62) (RB(z + iη) − RA(z) − RB(z + iη)(A − B)RA(z)) 1.

Γ

To proceed, we use the following facts. First, it holds that

(cid:12)
(cid:12)
(cid:12)1(cid:62)RB(z + iη)(A − B)RA(z)1
(cid:12)
(cid:12)
(cid:12) ≤

(cid:13)
(cid:13)1(cid:62)RB(z + iη)
(cid:13)

(cid:13)
(cid:13)
(cid:13) (cid:107)A − B(cid:107) (cid:107)RA(z)1(cid:107) .

For z ∈ Γ with Im z = ±η/2, in view of the Ward identity given in Lemma 3.1 and the assumption
given in (69), we get that

(cid:107)RA(z)1(cid:107)2 = 1(cid:62)RA(z)RA(z)1 =

2
η

| Im 1(cid:62)RA(z)1| (cid:46) n
η

20

(68)

(69)

(70)

For z ∈ Γ with Re z = ±3, we have that (cid:107)RA(z)1(cid:107)2 ≤ n (cid:107)RA(z)(cid:107)2 (cid:46) n thanks to the assump-
tion (cid:107)A(cid:107) ≤ 2.5. Similarly, we have (cid:107)RB(z + iη)1(cid:107)2 (cid:46) n/η. Combining these bounds with the
assumption that (cid:107)A − B(cid:107) (cid:46) σ yields that

(cid:12)
(cid:12)1(cid:62)RB(z + iη)(A − B)RA(z)1
(cid:12)

(cid:12)
(cid:12)
(cid:12)

(cid:46) nσ
η

.

Then applying |m0(z)| (cid:16) 1 and (69), we obtain

1
n

Tr M =

1
iη

(cid:73)

Γ

m0(z)m0(z + iη)(m0(z + iη) − m0(z))dz + O

(cid:18) σ

η2 +

(cid:19)

.

δ3
η

Lemma 5.5. Let Γ be the rectangular contour with vertices ±3 ± iη/2. Then

(cid:20)(cid:73)

Im

Γ

m0(z)m0(z + iη)(m0(z + iη) − m0(z))dz

= 2π + oη(1).

(cid:21)

Proof. By Proposition 4.4, the integrand is analytic and bounded over

{z ∈ C : |z| ≤ 9, z /∈ [−2, 2], z + iη /∈ [−2, 2]}.

Hence we may deform Γ to the contour Γ(cid:15) with vertices ±(2 + ε) ± iε, and take ε → 0 (for ﬁxed η).
The portion of Γ(cid:15) where | Re z| > 2 has total length O(ε), so the integral over this portion vanishes
as ε → 0. We may apply the bounded convergence theorem for the remaining two horizontal strips
of Γ(cid:15) to get (recall that contour integrals are evaluated counterclockwise):

(cid:73)

Γ

=

m0(z)m0(z + iη)(m0(z + iη) − m0(z))dz

(cid:90) −2

2

m+

0 (x)m0(x + iη)(m0(x + iη) − m+

0 (x))dx +

(cid:90) 2

−2

m−

0 (x)m0(x + iη)(m0(x + iη) − m−

0 (x))dx,

where m+
bounded convergence theorem again to take η → 0, we have limη→0 m0(x + iη) = m+

0 are the limits from C+ and C− deﬁned in Proposition 4.4. Now applying the
0 (x) and hence

0 and m−

(cid:73)

m0(z)m0(z + iη)(m0(z + iη) − m0(z))dz

m−

0 (x)m+

0 (x)(m+

0 (x) − m−

0 (x))dx =

(cid:90) 2

−2

|m+

0 (x)|2 · 2πiρ(x)dx = 2πi,

lim
η→0

=

Γ
(cid:90) 2

−2

the last two steps applying (32). Thus the imaginary part of the integral is 2π + oη(1) for small
η.

6 A tighter regularized QP relaxation

As discussed in the introduction, GRAMPA can be interpreted as solving the regularized QP
relaxation (11) of the QAP (10). We further explore this optimization aspect in this section, and
study a tighter regularized QP relaxation.

21

Let us begin by recalling the following QP relaxation of the QAP (10) that replaces the feasible
set of permutation matrices by its convex hull, the Birkhoﬀ polytope consisting of all doubly
stochastic matrices [ZBV08, ABK15]:

min
X∈Rn×n

(cid:107)AX − XB(cid:107)2
F

s.t. X1 = 1, X (cid:62)1 = 1, X ≥ 0.

(71)

This program diﬀers from the QP relaxation (11) that underlies GRAMPA in two aspects. First,
the added ridge penalty η2(cid:107)X(cid:107)2
F in (11) is crucial for ensuring the desired statistical property
of the solution,3 while for (71) there is no such need for regularization. Moreover, the Birkhoﬀ
polytope constraint, being the tightest possible convex relaxation, is signiﬁcantly tighter than the
constraint 1(cid:62)X1 = n. Although it is much slower to solve (71) than to implement GRAMPA,
the doubly stochastic relaxation achieves superior performance over the weaker program (11) as
demonstrated by ample empirical evidence (cf. [DMWX18, FMWX19]); nevertheless, a rigorous
theoretical understanding is still lacking.

As a further step toward understanding the relaxations, we analyze the following intermediate

program between (71) and (11):

min
X∈Rn×n

(cid:107)AX − XB(cid:107)2

F + η2(cid:107)X(cid:107)2
F

s.t. X1 = 1,

(72)

where we enforce the sum of each row of X to be equal to one. The above program without
the regularization term η2(cid:107)X(cid:107)2
F has been studied in [ABK15] in a small noise regime. As we are
analyzing the structure of the solution rather than the value of the program, the exact recovery
guarantee for GRAMPA (and hence for (11)) does not automatically carries over to the tighter
program (72). Fortunately, we are able to employ similar technical tools to analyze the solution
to (72), denoted henceforth by X c.

The following result is the counterpart of Theorem 2.1 and Corollary 2.2:

Theorem 6.1. Fix constants a > 0 and κ > 2, and let η ∈ [1/(log n)a, 1]. Consider the correlated
Wigner model with n ≥ d ≥ (log n)c0 where c0 > max(34 + 11a, 8 + 12a). Then there exist (α, κ)-
dependent constants C, n0 > 0 and a deterministic quantity r(n) ≡ r(n, η, d, a) satisfying r(n) → 0
as n → ∞, such that for all n ≥ n0, with probability at least 1 − n−10,

max
π∗(k)(cid:54)=(cid:96)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

max
k

|n · X c

k(cid:96)| ≤ C(log n)κ 1
√
η
(cid:12)
4(1 − σ2)
(cid:12)
(cid:12)
πη
(cid:12)

kπ∗(k) −

,

≤ C

n · X c

(cid:18) r(n)
η

+

σ

η2 + (log n)κ 1

√

η

(cid:19)

.

(73)

(74)

If (cid:107)aij(cid:107)ψ2, (cid:107)bij(cid:107)ψ2 ≤ K/
depending on K.

√

n, then the above guarantees hold also for κ = 1, with constants possibly

Furthermore, there exist constants c, c(cid:48) > 0 such that for all n ≥ n0, if

(log n)−a ≤ η ≤ c(log n)−2κ

and

σ ≤ c(cid:48)η,

(75)

3See [FMWX19, Section 1.3] for a more detailed discussion in this regard.

22

then with probability at least 1 − n−10,

min
k

Xkπ∗(k) > max
π∗(k)(cid:54)=(cid:96)

Xk(cid:96).

(76)

Compared with Corollary 2.2, the theoretical guarantee for the tighter program (72) is similar to
that for (11) and the GRAMPA method. In practice the performance of the former is slightly better
(cf. Fig. 2). Furthermore, Theorem 6.1 applies verbatim to the solution of (72) with column-sum
constraints X (cid:62)1 = 1 instead. This simply follows by replacing (A, B, X, Π∗) with (B, A, X (cid:62), Π(cid:62)
∗ ).

Figure 2: Fraction of correctly matched pairs of vertices by GRAMPA and the tighter QP (72)
(both followed by linear assignment rounding) on Erd˝os-R´enyi graphs with 1000 vertices and edge
density 0.5, averaged over 10 repetitions.

6.1 Structure of solutions to QP relaxations

Before proving Theorem 6.1, we ﬁrst provide an overview of the structure of solutions to the QP
relaxations (11), (72) and (71). Using the KarushKuhnTucker (KKT) conditions, the solution of
(72) can be expressed as

X c =

(cid:88)

i,j

(cid:104)vi, µ(cid:105)(cid:104)wj, 1(cid:105)
(λi − µj)2 + η2 viw(cid:62)
j ,

(77)

where µ ∈ Rn is the dual variable corresponding to the row sum constraints, chosen so that X c is
feasible. Since

X c1 =

(cid:88)

i,j

where

(cid:104)wj, 1(cid:105)2

(λi − µj)2 + η2 viv(cid:62)

i µ =

(cid:40)

(cid:88)

(cid:41)

τiviv(cid:62)
i

µ,

i

(78)

τi (cid:44) (cid:88)

j

(cid:104)wj, 1(cid:105)2
(λi − µj)2 + η2 .

23

00.10.20.30.40.500.10.20.30.40.50.60.70.80.91Solving X c1 = 1 yields

so we obtain

(cid:88)

µ =

i

(cid:104)vi, 1(cid:105)
τi

vi,

X c =

(cid:88)

i,j

1
(λi − µj)2 + η2

1
τi

viv(cid:62)

i Jwjw(cid:62)
j .

(79)

(80)

Let us provide some heuristics regarding the solution X c. As before we can express τi via

resolvents as follows:

τi =

=

1
η

1
η

(cid:88)

Im

j

(cid:104)wj, 1(cid:105)2
µj − (λi + iη)

=

1
η

(cid:20)

1(cid:62)

Im

(cid:88)

j

1
µj − (λi + iη)

(cid:21)

1

wjw(cid:62)
j

Im[1(cid:62)RB(λi + iη)1].

(81)

Invoking the resolvent bound (36), we expect τi ≈ n
η Im[m0(λi + iη)], where, by properties of the
Stieltjes transform (cf. Proposition 4.4), Im[m0(λi + iη)] ≈ Im[m0(λi)] = πρ(λi) as η → 0. Thus
we have the approximation

X c ≈

1
πn

(cid:88)

i,j

η
(λi − µj)2 + η2

1
ρ(λi)

viv(cid:62)

i Jvjw(cid:62)
j ,

Compared with the unconstrained solution (3), apart from normalization, the only diﬀerence is the
1
extra spectral weight
ρ(λi) according to the inverse semicircle density. The eﬀect is that eigenvalues
near the edge are upweighted while eigenvalues in the bulk are downweighted, the rationale being
that eigenvectors corresponding to the extreme eigenvalues are more robust to noise perturbation.

Remark 6.1 (Structure of the QP solutions). Let us point out that solution of various QP relax-
ations, including (71), (72), and (11), are of the following common form:

X =

(cid:88)

i,j

η

(λi − µj)2 + η2 viv(cid:62)

i Swjw(cid:62)
j ,

(82)

where S is an n × n matrix that can depend on A and B. Speciﬁcally, from the loosest to the
tightest relaxations, we have:

• For (11) with the total sum constraint, S = αJ, where the dual variable α > 0 is chosen for
feasility. Since scaling by α does not eﬀect the subsequent rounding step, this is equivalent
to (3) that we analyze.

• For (72) with the row sum constraint, S = µ1(cid:62) is rank-one with µ given in (79).

• For (71) without the positivity constraint, S = µ1(cid:62) + 1ν(cid:62) is rank-two. Unfortunately, the
dual variables and the spectral structure of the optimal solution turn out to be diﬃcult to
analyze.

• For (71) with the positivity constraint, S = µ1(cid:62) + 1ν(cid:62) + H, where H ≥ 0 is the dual variable

certifying the positivity of the solution and satisﬁes complementary slackness.

24

6.2 Proof of Theorem 6.1

We now apply the resolvent technique to analyze the behavior of the constrained solution X c and
establish its diagonal dominance.

6.2.1 Resolvent representation of the solution

We start by giving a resolvent representation of X c via a contour integral.

Lemma 6.2. Consider symmetric matrices A and B with the spectral decompositions (2), and sup-
pose that (cid:107)A(cid:107) ≤ 2.5. Then the solution X c of the program (72) admits the following representation

X c =

1
2π

(cid:73)

Re

Γ

F (z)RA(z)JRB(z + iη),

where Γ is deﬁned by (17) and

F (z) (cid:44)

2i
1(cid:62)RB(z + iη)1 − 1(cid:62)RB(z − iη)1

.

(83)

(84)

Proof. By (81) we have τ −1
analogous to (16) for the unconstrained solution:

i = ηF (λi). This leads to the following contour representation of X c

X c = η

(cid:88)

F (λi)viv(cid:62)
i J




(cid:88)

1

j



(λi − µj)2 + η2 wjw(cid:62)
(cid:35)
i JRB(λi + iη)

j






F (λi)viv(cid:62)

i
(cid:34)

(a)
= Im

(cid:88)

i
(cid:20) 1
−2πi
(cid:73)

Γ

(b)
= Im

=

1
2π

(cid:21)
F (z)RA(z)JRB(z + iη)

(cid:73)

Γ

Re

F (z)RA(z)JRB(z + iη),

where (a) follows from the Ward identity (Lemma 3.1); (b) follows from Cauchy integral formula
and the analyticity of F in the region enclosed by the contour Γ.

6.2.2 Entrywise approximation

For some small constant ε > 0, let b, b(cid:48) be as deﬁned in Theorem 4.5. Under the assumptions
of Theorem 6.1, we have c0 > b(cid:48) for ε suﬃciently small, so that Theorem 4.5 applies. Recall the
notation δ1, . . . , δ4 deﬁned in (45). For suﬃciently small ε > 0, we may also verify under the
assumptions of Theorem 6.1 that δi = o(1) for each i = 1, 2, 3, 4, and

δ1δ2
2n
η

≤ 1,

δ2
2δ3n
η2 ≤

(log n)κ
√
η

,

and

δ3 ≤ η3.

(85)

We also assume throughout the proof that the high-probability event (cid:107)A(cid:107) ≤ 2.5 holds.

25

Thanks to (36), we can approximate F (z) by

(cid:101)F (z) =

1
n

2i
m0(z + iη) − m0(z − iη)

and approximate X c by

(cid:101)X c =

=

1
2π
−1
πn

(cid:73)

Re

Γ
(cid:73)

Γ

Im

(cid:101)F (z)RA(z)JRB(z + iη)

1
m0(z + iη) − m0(z − iη)

RA(z)JRB(z + iη).

(86)

(87)

(88)

The following lemma makes the approximation of X c precise in the entrywise sense:

Lemma 6.3. Suppose (85) holds. On the high-probability event where Theorem 4.5 holds and also
(cid:107)A(cid:107) ≤ 2.5,

(cid:107) (cid:101)X c − X c(cid:107)(cid:96)∞

(cid:46) δ2

2δ3
η2 ≤

where δ2, δ3 are deﬁned in (45).

(log n)κ
√

n

η

,

(89)

Proof. For notational convenience, put G(z) = 2i/(nF (z)) and (cid:101)G(z) = 2i/(n (cid:101)F (z)). Note that
| Im(z)| ≤ η/2 for z ∈ Γ, and thus Im(z + iη) and Im(z − iη) have diﬀerent signs. Therefore

| (cid:101)G(z)| ≥ | Im (cid:101)G(z)| = | Im m0(z + iη)| + | Im m0(z − iη)| (cid:38) η,

where the last step follows from (31). Furthermore, by (36), we have supz∈Γ |G(z) − (cid:101)G(z)| ≤ 2Cδ3.
In view of (85), δ3 (cid:28) η. Hence we have |G(z)| (cid:38) η and

Finally, by (83) and (87), we have

|F (z) − (cid:101)F (z)| (cid:46) 1
n

δ3
η2 .

sup
z∈Γ

|(X c − (cid:101)X c)k(cid:96)| ≤

dz|F (z) − (cid:101)F (z)||e(cid:62)

k RA(z)1||e(cid:62)

(cid:96) RB(z + iη)1|.

(cid:73)

By (35), for all k, (cid:96), |e(cid:62)
displays yields the desired claim.

Γ
k RA(z)1| (cid:46) δ2

√

n and |e(cid:62)

(cid:96) RB(z + iη)1| (cid:46) δ2

√

n. Combining the last two

In view of the entrywise approximation, we may switch our attention to the approximate solution
(cid:101)X c and establish its diagonal dominance, assuming without loss of generality π∗ is the identity
permutation. The proof parallels the analysis in Section 5 so we focus on the diﬀerences. To make
the scaling identical to the unconstrained case, deﬁne

Y (cid:44) n (cid:101)X c =

1
2π

(cid:73)

Re

Γ

f (z)RA(z)JRB(z + iη),

(90)

with

f (z) (cid:44)

2i
m0(z + iη) − m0(z − iη)

.

Compared with the unconstrained solution (16), the only diﬀerence is the weighting factor f (z).

We aim to show that with probability at least 1 − n−D, for any constant D > 0, the following

holds:

26

1. For oﬀ-diagonals, we have

2. For diagonal entries, we have

|Yk(cid:96)| (cid:46) (log n)κ /

√

η.

max
k(cid:54)=(cid:96)

(91)

(cid:12)
(cid:12)
Ykk −
(cid:12)
(cid:12)

4(1 − σ2)
πη

(cid:12)
(cid:12)
(cid:12)
(cid:12)

min
k

(cid:46) r(n)
η

+

σ

η2 + (log n)κ 1

√

η

.

(92)

In view of Lemma 6.3, this implies the desired (73) and (74). Finally, analogous to Corollary 2.2,
under the assumption (75) with constants c = 1/(64C2) and c(cid:48) = 1/(2C), for all suﬃciently large
n,

4(1 − σ2)
πη

≥

7
8η

> C

(cid:18) r(n)
η

+

σ

η2 + 2(log n)κ 1

√
η

(cid:19)

,

implying the diagonal dominance in (76).

6.2.3 Oﬀ-diagonal entries

Let us ﬁrst consider Y12. Recall that for z ∈ Γ, we have | Im(z + iη)| (cid:38) η, | Im(z − iη)| (cid:38) η, and
these imaginary parts have opposite signs. Then

|f (z)| ≤

2
| Im[m0(z + iη) − m0(z − iη)]|

=

2
| Im m0(z + iη)| + | Im m0(z − iη)|

(cid:46) 1
η

,

(93)

where the last step applies (31). Analogous to (52), we get

2πY12 = Re

(cid:18)(cid:73)

Γ

f (z)

(cid:104)
e(cid:62)
1 RA(z)1

(cid:105) (cid:104)

α − a(cid:62)

1 g − b(cid:62)

2 h + a(cid:62)

1 M b2

(cid:19)

(cid:105)

dz

e(cid:62)
2 RB(z + iη)1
(cid:18) δ1δ2
2n
η

+ O

(cid:17)

(cid:19)

,

(cid:16)

= Re

where

α (cid:44)

g (cid:44)

h (cid:44)

M (cid:44)

(cid:73)

Γ
(cid:73)

Γ
(cid:73)

Γ
(cid:73)

Γ

f (z)m0(z)m0(z + iη)dz,

f (z)m0(z)m0(z + iη)R(12)

A (z)1n−2dz,

f (z)m0(z)m0(z + iη)R(12)

B (z + iη)1n−2dz,

f (z)m0(z)m0(z + iη)R(12)

A (z)Jn−2R(12)

B (z + iη)dz.

(94)

(95)

(96)

(97)

(98)

Here the constant Re α is in fact equal to 2π, which is consistent with the row-sum constraints.

27

Indeed, opening up m0(z) and applying the Cauchy integral formula, we have

Re α = Re

(cid:73)

dz

2i
m0(z + iη) − m0(z − iη)
1
x − z

dz

(cid:73)

ρ(x)dx Re

(cid:20)

ρ(x)dx Re

(−2πi)

(cid:90)

(cid:90)

=

=

m0(z)m0(z + iη)

2i m0(z + iη)
m0(z + iη) − m0(z − iη)
(cid:21)

2i m0(x + iη)
m0(x + iη) − m0(x − iη)
(cid:21)

(cid:90)

(cid:90)

= 2π

ρ(x)dx Re

(cid:20) 2 m0(x + iη)
2i Im m0(x + iη)

= 2π

ρ(x)dx = 2π.

(99)

As in Section 5.2.2, to bound the linear and bilinear terms, we need to bound the (cid:96)∞-norms
and (cid:96)2-norms of g, h and M . Clearly, by (93), the (cid:96)∞-norms are at most an O(1/η) factor of those
obtained in (61) and (62), i.e., (cid:107)g(cid:107)∞ (cid:46) δ2
2n/η. The (cid:96)2-norms need to be
bounded more carefully. The following result is the counterpart of Lemma 5.3:

n/η and (cid:107)M (cid:107)∞ (cid:46) δ2

√

Lemma 6.4. Assume the same setting of Lemma 5.3, and deﬁne M , g, and h as in (96–98) with
RA, RB in place of R(12)

(cid:46) n2/η, (cid:107)g(cid:107)2 (cid:46) n log(1/η), and (cid:107)h(cid:107)2 (cid:46) n log(1/η).

B . Then (cid:107)M (cid:107)2
F

A , R(12)

Proof. We start with (cid:107)M (cid:107)F , as the arguments for (cid:107)g(cid:107) and (cid:107)h(cid:107) are analogous and simpler. Recall
the contour Γ(cid:48) from Fig. 1. Proceeding as in the proof of Lemma 5.3, we have

1
n2 (cid:107)M (cid:107)2
F
(cid:73)
(cid:73)
dz

= −

Γ

Γ(cid:48)

= −

(cid:73)

dz

Γ(cid:48)

(cid:73)

Γ

(cid:124)

+ (II),

dw m0(z)m0(z + iη)m0(w)m0(w − iη)f (z)f (w)×

n−11(cid:62)(RA(z) − RA(w))1
z − w

n−11(cid:62)(RB(z + iη) − RB(w − iη))1
z + iη − (w − iη)

dw m0(z)m0(z + iη)m0(w)m0(w − iη)f (z)f (w)

(cid:123)(cid:122)
(I)

m0(z) − m0(w)
z − w

m0(z + iη) − m0(w − iη)
z + iη − (w − iη)

(cid:125)

where (II) denotes the remainder term. Applying (36), (93), and the boundedness of m0, the
residual term is bounded as

|(II)| (cid:46) δ3

(cid:73)

(cid:73)

dz

Γ

Γ(cid:48)

dw|f (z)||f (w)|

1
|z − w|

1
|z + iη − (w − iη)|

(cid:46) δ3
η4

(cid:46) 1
η

.

(100)

To control the leading term (I), let us deﬁne the auxiliary contours γ with vertices ±(2 + 2η) ±
(η/2)i and γ(cid:48) with vertices ±(2 + η) ± (η/4)i. By ﬁrst deforming Γ(cid:48) to γ(cid:48) for each ﬁxed z ∈ Γ, then
deforming Γ to γ, and ﬁnally taking the complex modulus and applying |m0| (cid:46) 1, we get

|(I)| (cid:46)

(cid:73)

(cid:73)

dz

γ

γ(cid:48)

dw |f (z)||f (w)|

(cid:12)
(cid:12)
(cid:12)
(cid:12)

m0(z) − m0(w)
z − w

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

m0(z + iη) − m0(w − iη)
z + iη − (w − iη)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

.

The reason for performing these deformations is that for any z ∈ γ ∪γ(cid:48), since Re z ∈ [−2−2η, 2+2η],
we have from (31) that Im m0(z + iη) (cid:16) (cid:112)η + ζ(z) and − Im m0(z − iη) (cid:16) (cid:112)η + ζ(z), where ζ(z) is

28

as deﬁned in Proposition 4.4. Then we obtain from (93) the improved bound |f (z)| (cid:46) 1/(cid:112)η + ζ(z),
and hence

|(I)| (cid:46)

(cid:73)

(cid:73)

dz

γ

γ(cid:48)

dw

1
(cid:112)η + ζ(z)

1
(cid:112)η + ζ(w)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

m0(z) − m0(w)
z − w

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

m0(z + iη) − m0(w − iη)
z + iη − (w − iη)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

.

To bound the above integral, for a small constant c0 > 0, consider the two cases where |z − w| ≥
η to

c0 and |z − w| < c0. For the ﬁrst case |z − w| ≥ c0, we simply apply |m0| (cid:46) 1 and
get that

η + κ ≥

√

√

(cid:73) (cid:73)

|z−w|≥c0

dz dw

1
(cid:112)η + ζ(z)

1
(cid:112)η + ζ(w)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

m0(z) − m0(w)
z − w

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

m0(z + iη) − m0(w − iη)
z + iη − (w − iη)

In the second case |z − w| < c0, we claim that for c0 suﬃciently small, we have

|m0(z) − m0(w)| (cid:46) (cid:112)η + ζ(z) + (cid:112)η + ζ(w),
|m0(z + iη) − m0(w − iη)| (cid:46) (cid:112)η + ζ(z) + (cid:112)η + ζ(w).

(cid:12)
(cid:12)
(cid:12)
(cid:12)

.

(cid:46) 1
η
(101)

(102)

(103)

Indeed, if ζ(z) > c0, then (102) and (103) hold because (cid:112)η + ζ(z) + (cid:112)η + ζ(w) (cid:16) 1. If instead
z2−4
ζ(z) ≤ c0, say, Re z ≥ 2−c0, then from the explicit form (29) for m0(z) we get 1+m0(z) = 2−z+
and hence

|1 + m0(z)| (cid:46) |z − 2| + (cid:112)|z − 2||z + 2| (cid:16) (cid:112)|z − 2| (cid:16) (cid:112)η + ζ(z).
Furthermore, since Re w ≥ Re z − |z − w| ≥ 2 − 2c0, we also have |1 + m0(w)| (cid:46) (cid:112)η + ζ(w). Then
(102) follows from the triangle inequality. The case of Re z ≤ −2 + c0, and the argument for (103),
are analogous.

√

2

Having established (102) and (103), we apply

(cid:16)(cid:112)η + ζ(z) + (cid:112)η + ζ(w)
(cid:112)η + ζ(z)(cid:112)η + ζ(w)

(cid:17)2

(cid:46)

≤

(cid:112)η + max(ζ(z), ζ(w))
(cid:112)η + min(ζ(z), ζ(w))
(cid:112)η + min(ζ(z), ζ(w)) + (cid:112)|ζ(z) − ζ(w)|
(cid:112)η + min(ζ(z), ζ(w))

≤ 1 +

(cid:112)|z − w|
√
η

to get

(cid:73) (cid:73)

dz dw

|z−w|<c0

1
(cid:112)η + ζ(z)
(cid:32)

(cid:73) (cid:73)

(cid:46)

dz dw

1 +

|z−w|<c0

(cid:112)|z − w|
√
η

(cid:33)

1
|z − w||z + iη − (w − iη)|

.

1
(cid:112)η + ζ(w)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

m0(z) − m0(w)
z − w

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

m0(z + iη) − m0(w − iη)
z + iη − (w − iη)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

Then divide this into the integrals where |z − w| < η and |z − w| ≥ η, applying

(cid:73) (cid:73)

|z−w|<η

dz dw

1
|z − w||z + iη − (w − iη)|

(cid:46)

(cid:73) (cid:73)

dz dw

1
η2

(cid:46) 1
η

|z−w|<η

29

and

(cid:73) (cid:73)

dz dw

η≤|z−w|<c0
(cid:73) (cid:73)

(cid:46) 1
√
η

η≤|z−w|<c0

(cid:112)|z − w|
√
η

dz dw

·

1
|z − w||z + iη − (w − iη)|
1
|z − w|3/2

(cid:46) 1
√
η

(cid:46) 1
η

1
√
η

.

(104)

Combining with the ﬁrst case (101), we get |(I)| (cid:46) 1/η. Finally, combining with (100), we get
(cid:107)M (cid:107)2
F

(cid:46) n2/η as desired.

Next we bound (cid:107)g(cid:107). Proceeding as in the proof of Lemma 5.3 and following the same argument

as above, we get

1
n

(cid:107)g(cid:107)2 (cid:46)

(cid:46)

(cid:73)

γ
(cid:73)

γ

dz

dz

(cid:73)

γ(cid:48)

(cid:73)

γ(cid:48)

dw |f (z)||f (w)|

|m0(z) − m0(w)|
|z − w|

+ O

(cid:19)

(cid:18) δ3
η3

dw

1
(cid:112)η + ζ(z)

1
(cid:112)η + ζ(w)

|m0(z) − m0(w)|
|z − w|

+ O

(cid:19)

.

(cid:18) δ3
η3

For |z − w| ≥ c0, we have

(cid:73) (cid:73)

dzdw

|z−w|≥c0
(cid:32)(cid:73)

(cid:46)

1
(cid:112)η + ζ(z)

dz

1
(cid:112)η + ζ(z)
(cid:33) (cid:32)(cid:73)

1
(cid:112)η + ζ(w)

|m0(z) − m0(w)|
|z − w|

1
(cid:112)η + ζ(w)

(cid:33)

dw

(cid:46) 1.

For |z − w| < c0, we apply |m0(z) − m0(w)| (cid:46) (cid:112)η + ζ(z) + (cid:112)η + ζ(w) as above, so that

(cid:73) (cid:73)

dzdw

|z−w|<c0

(cid:73)

(cid:46)

dz

1
(cid:112)η + ζ(z)
(cid:32)(cid:73)

(cid:46) log(1/η) ·

1
1
(cid:112)η + ζ(z)
(cid:112)η + ζ(w)
(cid:73)
(cid:73)
1
|z − w|

dw

+

dw

|m0(z) − m0(w)|
|z − w|
1
(cid:112)η + ζ(w)
(cid:33)

(cid:73)

dz

dz

1
(cid:112)η + ζ(z)

(cid:73)

+

dw

1
(cid:112)η + ζ(w)

(cid:46) log(1/η).

1
|z − w|

Combining the above yields (cid:107)g(cid:107)2 (cid:46) n log(1/η). The argument for (cid:107)h(cid:107)2 is the same as that for
(cid:107)g(cid:107)2.

Finally, proceeding as in (55)–(56) and using the preceeding norm bounds, we obtain from (94):

|Y12| (cid:46) 1 + δ4

(cid:114)

n log

1
η

+

δ2
4n
√
η

+

δ1δ2
2n
η

(cid:46) δ2
4n
√
η

= (log n)κ /

√

η,

with probability at least 1 − n−D, for any constant D. This implies the desired (91) by the union
bound.

30

6.2.4 Diagonal entries

We now consider Y11. Following the derivation from (66) to (67) and using Lemma 6.4 in place of
Lemma 5.3, we obtain, with probability at least 1 − n−D for any constant D,

(cid:12)
(cid:12)
Y11 −
(cid:12)
(cid:12)

1 − σ2
2π

Re

Tr(M )
n

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:46) (log n)κ 1
√
η

,

(105)

where

M (cid:44)

(cid:73)

Γ

f (z)m0(z)m0(z + iη)R(1)

A (z)JR(1)

B (z + iη)dz.

The trace is computed by the following result, which parallels Lemma 5.4 and Lemma 5.5:

Lemma 6.5. Suppose δ3 ≤ η2. Assume the setting of Lemma 5.4. Deﬁne

Then

(cid:73)

M =

Γ

1
n

f (z)m0(z)m0(z + iη)RA(z)JRB(z + iη)dz.

Tr(M ) =

8 + oη(1)
η

+ O

(cid:18) σ + δ3
η2

(cid:19)

.

Proof. Analogous to (70), we have 1

n Tr(M ) = (I) − (II), where

(I) =

(II) =

1
iη
1
iη

(cid:73)

Γ
(cid:73)

Γ

f (z)m0(z)m0(z + iη)

f (z)m0(z)m0(z + iη)

1
n
1
n

1(cid:62)(RB(z + iη) − RA(z))1dz

1(cid:62)RB(z + iη)(A − B)RA(z)1 dz.

To bound (II), consider two cases:

• For z ∈ Γ with | Im z| = η/2, by the Ward identity and (36), we have

(cid:107)RA(z)1(cid:107)2 =

2
η

| Im 1(cid:62)RA(z)1| (cid:46) n
η

(| Im m0(z)| + O(δ3)).

and similarly,

Thus it holds that

(cid:107)RB(z + iη)1(cid:107)2 (cid:46) n
η

(| Im m0(z + iη)| + O(δ3)).

(cid:12)
(cid:12)
(cid:12)1(cid:62)RB(z + iη)(A − B)RA(z)1
(cid:12)
(cid:12)
(cid:12)

(cid:46) nσ
η

(cid:16)(cid:112)| Im m0(z) Im m0(z + iη)| +

(cid:112)

δ3

(cid:17)

.

Using (31) and (93), we conclude that

|f (z)|(cid:112)| Im m0(z) Im m0(z + iη)| ≤

2(cid:112)| Im m0(z) Im m0(z + iη)|
| Im m0(z + iη)| + | Im m0(z − iη)|

(cid:16) 1

for all z ∈ Γ with | Im z| = η/2.

31

• For z ∈ Γ with Re z = ±3, since (cid:107)A(cid:107) ≤ 2.5, (cid:12)

(cid:12)1(cid:62)RB(z + iη)(A − B)RA(z)1(cid:12)

(cid:12) (cid:46) nσ.

Furthermore, by (93), |f (z)| (cid:46) 1

η for all z ∈ Γ. Combining the above two cases yields
|(II)| (cid:46) σ
η2

σ
η2 ,

δ3
η

1 +

σ
η

√

+

(cid:16)

(cid:19)

(cid:18)

since δ3 ≤ η2 by the assumption.

For (I), applying (36) again and plugging the deﬁnition of f (z) yields

(I) =

2
η

(cid:73)

Γ

m0(z)m0(z + iη)

m0(z + iη) − m0(z)
m0(z + iη) − m0(z − iη)

dz + O

(cid:19)

.

(cid:18) δ3
η2

We now apply an argument similar to that of Lemma 5.5: Note that

|m0(z + iη) − m0(z − iη)| ≥ Im(m0(z + iη) − m0(z − iη)) (cid:38) η

by (31), so the integrand is bounded for ﬁxed η. Then deforming Γ to Γ(cid:15) with vertices ±(2 + ε) ± iε,
taking ε → 0 for ﬁxed η, and applying the bounded convergence theorem, we have the equality
(cid:73)

m0(z)m0(z + iη)

m0(z + iη) − m0(z)
m0(z + iη) − m0(z − iη)
m0(x + iη) − m+

dz

0 (x)

m0(x + iη) − m0(x − iη)

m+

0 (x)m0(x + iη)

Γ

=

(cid:90) −2

2

dx +

(cid:90) 2

−2

m−

0 (x)m0(x + iη)

m0(x + iη) − m−

0 (x)

m0(x + iη) − m0(x − iη)

dx.

(106)

We show that these integrands are uniformly bounded over small η: For any constant δ > 0

and for |x| ≤ 2 − δ, we have the lower bound

Then the above integrands are bounded by C/

|m0(x + iη) − m0(x − iη)| = 2 Im m0(x + iη) (cid:38) (cid:112)ζ(x) + η ≥
√

√

δ.

(107)

|m0(x + iη) − m+

δ for |x| ≤ 2 − δ. For |x| ∈ [2 − δ, 2], let us apply
0 (x)| (cid:46) (cid:112)ζ(x) + η

as follows from (102) and taking the limit w ∈ C+ → x. We have also |m+
(cid:112)ζ(x) + η, so that

0 (x) − m−

0 (x)| (cid:16) (cid:112)ζ(x) (cid:46)

|m0(x + iη) − m−

0 (x)| (cid:46) (cid:112)ζ(x) + η.

Combining these cases with the ﬁrst inequality of (107), we see that the integrands of (106) are
uniformly bounded for all small η.

Now apply the bounded convergence theorem and take the limit η → 0, noting that limη→0 m0(x+

iη) = m+

0 (x) and limη→0 m0(x − iη) = m−

0 (x). We get

(cid:73)

lim
η→0

m0(z)m0(z + iη)

m0(z + iη) − m0(z)
m0(z + iη) − m0(z − iη)
0 (x) − m−
0 (x) − m−
This gives (I) = (8 + oη(1))/η + O(δ3/η2). Combining with the bound for (II) yields the lemma.

0 (x)|2dx = 4.

0 (x)
0 (x)

0 (x)m+

m+
m+

Γ
(cid:90) 2

0 (x)

dx =

|m+

m−

(cid:90) 2

dz

=

−2

−2

Finally, combining (105) with Lemma 6.5 and δ3 (cid:28) η from (85), and applying a union bound

yields the desired (92).

32

7 Proof of resolvent bounds

In this section, we prove Theorem 4.5. The entrywise bounds of part (a) are essentially the local
semicircle law of [EKYY13b, Theorem 2.8], restricted to the simpler domain {z : dist(z, [−2, 2]) ≥
(log n)−a} and with small modiﬁcations of the logarithmic factors. The bound in (b) follows from
(a) using a straightforward Schur complement identity. The bound in (c) is more involved, and
relies on the ﬂuctuation averaging technique of [EKYY13b, Section 5]. We provide a proof of all
three statements using the tools of [EKYY13b].

For each statement, it suﬃces to establish the claim with the stated probability for each indi-
vidual point z ∈ D. The uniform statement over z ∈ D then follows from a union bound over a
suﬃciently ﬁne discretization of D (of cardinality an arbitrarily large polynomial in n) and standard
Lipschitz bounds for m0 and Rjk on the event of (cid:107)A(cid:107) ≤ 2.5—we omit these details for brevity.

7.1 Notation and matrix identities

In this section, for S ⊂ [n], denote by A(S) ∈ Rn×n the matrix A with all elements in rows and
columns belonging to S replaced by 0. Denote

R(S)(z) = (A(S) − zI)−1 ∈ Cn×n.

Note that R(S)(z) is block-diagonal with respect to the block decomposition Cn = CS ⊕ C[n]\S,
with S × S block equal to (−1/z)I|S| and ([n] \ S) × ([n] \ S) block equal to the resolvent of the
corresponding minor of A. (We will typically only access elements of R(S) in this ([n] \ S) × ([n] \ S)
block, in which case R(S) may be understood as the resolvent of the minor of A.)

For i ∈ [n], we write as shorthand

iS = {i} ∪ S,

(S)
(cid:88)

=

(cid:88)

.

k

k∈[n]\S

We usually omit the spectral argument z for brevity.

Lemma 7.1 (Schur complement identities). For any j ∈ [n],

1
Rjj

= ajj − z −

(j)
(cid:88)

k,(cid:96)

ajkR(j)

k(cid:96) a(cid:96)j.

For any j (cid:54)= k ∈ [n],

Rjk = −Rjj

(j)
(cid:88)

(cid:96)

k R = e(cid:62)
e(cid:62)

k R(j) +

aj(cid:96)R(j)

(cid:96)k = RjjR(j)

kk



−ajk +

(jk)
(cid:88)

(cid:96),m



aj(cid:96)R(jk)

(cid:96)m amk

 ,

j R,

· e(cid:62)

Rkj
Rjj
(Rkj)2
kk RjjRkk

R(j)

1
Rkk

=

1
R(j)
kk

−

.

33

(108)

(109)

(110)

(111)

For any j, k, (cid:96) ∈ [n] with j /∈ {k, (cid:96)},

Rk(cid:96) = R(j)

k(cid:96) +

RkjRj(cid:96)
Rjj

.

(112)

These identities hold also for any S ⊂ [n] with R replaced by R(S) and with j, k, (cid:96) ∈ [n] \ S.

Proof. For all but (110), see [EKYY13a, Lemma 4.5] and [EYY12, Lemma 4.2]. As for (110), it is
equivalent to verify that (112) holds also for (cid:96) = j, which simply follows from R(j)
kj = 0, due to the
block diagonal structure of R(j).

7.2 Entrywise bound
We say an event occurs w.h.p. if its probability is at least 1 − e−c(log n)1+ε for a universal constant
c > 0. Let us show that (33) and (34) hold for z ∈ D w.h.p.

We start with (34). Note that the jth row {ajk : k ∈ [n]} is independent of A(j) and hence R(j).

Applying (108), (22), and (25) conditional on A(j), w.h.p. for all j,

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
Rjj

+ z +

1
n

(j)
(cid:88)

k

R(j)
kk

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

=

(cid:12)
(cid:12)
(cid:12)
ajj −
(cid:12)
(cid:12)
(cid:12)

(j)
(cid:88)

k,(cid:96)

ajkR(j)

k(cid:96) a(cid:96)j +

1
n

(j)
(cid:88)

k

R(j)
kk

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤ (log n)2+2ε

(cid:32)

1
√
d

+

2(cid:107)R(j)(cid:107)∞√
d

+

(cid:107)R(j)(cid:107)F
n

(cid:33)

.

n(cid:107)R(j)(cid:107), and d ≤ n. For z ∈ D1 and any S ⊂ [n], we
Note that (cid:107)R(j)(cid:107)∞ ≤ (cid:107)R(j)(cid:107), (cid:107)R(j)(cid:107)F ≤
have (cid:107)R(S)(cid:107) ≤ 1/| Im z| ≤ (log n)a. For z ∈ D2, we have (cid:107)R(S)(cid:107) ≤ 10 on the event (cid:107)A(cid:107) ≤ 2.5,
which occurs w.h.p. by Lemma 4.1. Then in both cases, we get

√

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
Rjj

+ z +

1
n

(j)
(cid:88)

k

R(j)
kk

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:46) (log n)2+2ε+a
√

d

.

(113)

Since |z| ≤ 10, |R(j)

kk | ≤ (log n)a, and d (cid:29) (log n)4+4ε, this implies 1/|Rjj| (cid:46) (log n)a. Let

mn(z) = n−1 Tr R(z) be the empirical Stieltjes transform. Then
(cid:12)
(cid:12)
(cid:12)
mn −
(cid:12)
(cid:12)
(cid:12)

(Rkk − R(j)
kk )

R2
kj
Rjj

Rjj +

R(j)
kk

(112)
=

(j)
(cid:88)

(j)
(cid:88)

(cid:88)

1
n

1
n

1
n

1
n

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

=

k

k

k

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

=

(cid:107)e(cid:62)
j R(cid:107)2
n|Rjj|

≤

(cid:107)R(cid:107)2
n|Rjj|

(cid:46) (log n)3a
n

.

Using d ≤ n and combining with (113), w.h.p. for all j,

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
Rjj

+ z + mn

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:46) (log n)2+2ε+a
√

d

.

(114)

Then by the triangle inequality, also w.h.p. for all j (cid:54)= k,

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
Rjj

−

1
Rkk

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:46) (log n)2+2ε+a
√

d

,

so

(cid:12)
(cid:12)
(cid:12)
(cid:12)

mn
Rjj

− 1

(cid:12)
(cid:12)
(cid:12)
(cid:12)

=

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

n−1 (cid:88)

k

Rkk − Rjj
Rjj

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤ max

k

(cid:12)
(cid:12)
(cid:12)
(cid:12)

Rkk − Rjj
Rjj

(cid:12)
(cid:12)
(cid:12)
(cid:12)

= max

k

|Rkk|

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
Rjj

−

1
Rkk

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:46) (log n)2+2ε+2a
√

d

.

34

For d (cid:29) (log n)4+4ε+4a, this implies 3

2 |Rjj| ≥ |mn| ≥ |Rjj|/2 w.h.p. for all j. Then also

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
Rjj

−

1
mn

(cid:12)
(cid:12)
(cid:12)
(cid:12)

=

|Rjj − mn|
|Rjj||mn|

≤ max

k

|Rjj − Rkk|
|Rjj||mn|

≤ max

k

2|Rjj − Rkk|
|Rjj||Rkk|

= 2 max

k

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
Rjj

−

1
Rkk

(cid:12)
(cid:12)
(cid:12)
(cid:12)

,

so

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
Rjj

−

1
mn

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:46) (log n)2+2ε+a
√

d

.

(115)

Combining with (114), w.h.p. we have

1
mn

+ z + mn = rn,

|rn| (cid:46) (log n)2+2ε+a

√

d

(cid:28) (log n)−a.

Solving for mn yields

mn ∈

−z + rn ± (cid:112)z2 − 4 − 2zrn + r2
2

n

where the right side denotes the two complex square-roots. Note that |z2 − 4| = |z − 2| · |z + 2| (cid:38)
(log n)−a|z| and |z| ≥ (log n)−a for all z ∈ D. Then, as (log n)−a (cid:29) |rn|, we have |z2 − 4| (cid:29) |zrn| (cid:29)
|rn|2. Letting m0 be the Stieltjes transform of the semicircle law, and letting (cid:101)m0 = 1/m0 be the
other root of the quadratic equation (30), we obtain by a Taylor expansion of the square-root that

min(|mn − m0|, |mn − (cid:101)m0|) (cid:46) |rn|

1 +

(cid:32)

(cid:33)

|z|
(cid:112)|z2 − 4|

(cid:46)

|rn|
(cid:112)ζ(z) + | Im z|

,

(116)

where ζ(z) is as deﬁned in Proposition 4.4.

To argue that this bound holds for |mn − m0| rather than |mn − (cid:101)m0|, consider ﬁrst z ∈ D1 with
Im z > 0. In this case mn ∈ C+ and (cid:101)m0 ∈ C−. Furthermore, note that (31) implies Im m0(z) ≥
(Im z)/(cid:112)ζ(z) + Im z, and hence Im (cid:101)m0 = −(Im m0)/|m0|2 ≤ −c(log n)−a/(cid:112)ζ(z) + Im z. Since
Im mn > 0 and |rn| (cid:28) (log n)−a, (116) must hold for |mn − m0| rather than |mn − (cid:101)m0|. The same
argument applies for z ∈ D1 with Im z < 0. For z ∈ D2, we have ||m0(z)| − 1| ≥ c and hence
|m0(z) − (cid:101)m0(z)| > c for a constant c > 0. Consider the point z(cid:48) ∈ D1 ∩ D2 with Re z(cid:48) = Re z
dz m0(z)| (cid:46) 1 and, on the event (cid:107)A(cid:107) ≤ 2.5,
and Im z(cid:48) = (log n)−a. Note that for all z ∈ D2, | d
dz mn(z)| (cid:46) 1 also. Thus |m0(z) − m0(z(cid:48))| ≤ C(log n)−a and |mn(z) − mn(z(cid:48))| ≤ C(log n)−a. Since
| d
we have already shown that (116) holds for |mn(z(cid:48)) − m0(z(cid:48))| in the previous case, this implies also
that (116) must hold for |mn − m0| rather than for |mn − (cid:101)m0|.

Applying | Im z| ≥ (log n)−a, (116) yields w.h.p.

|mn − m0| (cid:46) (log n)a/2|rn| (cid:46) (log n)2+2ε+3a/2

√

d

.

(117)

Recalling (115), |Rjj| ≤ (log n)a and |mn| ≤ 3

2 |Rjj|, we get

|Rjj − mn| (cid:46) |Rjj||mn| ·

(log n)2+2ε+a
√
d

(cid:46) (log n)2+2ε+3a
√

d

.

(118)

Combining the last two displayed equations gives the weak estimate

|Rjj − m0| (cid:46) (log n)2+2ε+3a

√

d

.

35

Since d (cid:38) (log n)4+4ε+6a by assumption, this and |m0(z)| (cid:16) 1 imply |Rjj| (cid:46) 1 w.h.p. Then applying
the last display and (117) to the ﬁrst inequality of (118) yields the desired estimate

|Rjj − m0| ≤ |Rjj − mn| + |mn − m0| (cid:46) (log n)2+2ε+3a/2

√

d

.

To show (33) for the oﬀ-diagonals, we now apply (109), (22), (26) conditional on R(jk), |Rjj| (cid:46) 1,
kk | (cid:46) 1, (cid:107)R(jk)(cid:107)∞ ≤ (log n)a, (cid:107)R(jk)(cid:107)F ≤

n(log n)a, and d ≤ n to get w.h.p.

√

|R(j)

|Rjk| = |Rjj||R(j)
kk |

−ajk +

aj(cid:96)R(jk)

(cid:96)m amk

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:32)

(jk)
(cid:88)

(cid:96),m

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:107)R(jk)(cid:107)F
n

(cid:46) (log n)2+2ε

1
√
d

+

2(cid:107)R(jk)(cid:107)∞√
d

+

(cid:33)

(cid:46) (log n)2+2ε+a
√

d

.

7.3 Row sum bound

We now show that (35) holds for z ∈ D w.h.p. Set

Zi (cid:44)

(i)
(cid:88)

j,k

aikR(i)

kj =

(i)
(cid:88)

k

(cid:16)

aik

k R(i)1
e(cid:62)

(cid:17)

where the last equality holds because R(i)

ki = 0 for k (cid:54)= i. Applying (109),

e(cid:62)
i R1 =

(cid:88)

j

Rij = Rii − RiiZi.

Then applying (34), w.h.p. for every i ∈ [n],
(cid:12)
(cid:12)e(cid:62)
(cid:12)

i R1

(cid:12)
(cid:12)
(cid:12)

(cid:46) 1 + |Zi|.

Applying (23) conditional on A(i), w.h.p. for every i ∈ [n],

|Zi| ≤ (log n)1+ε





k R(i)1|
maxk(cid:54)=i |e(cid:62)
d

√

+

(cid:115)

(cid:80)(i)

k |e(cid:62)
k R(i)1|2
n



 .

For the second term above, we apply (cid:107)R(i)(cid:107) ≤ (log n)a w.h.p. to get

(i)
(cid:88)

k

(cid:12)
(cid:12)e(cid:62)
(cid:12)

(cid:12)
k R(i)1
(cid:12)
(cid:12)

2

≤ 1(cid:62)R(i)R(i)1 ≤ (log n)2an.

For the ﬁrst term, we apply (110), (33), and (34) to get, w.h.p. for all k (cid:54)= i,
C(log n)2+2ε+a
√
d

(cid:12)
(cid:12)
e(cid:62)
k R1 −
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12) +
k R1

(cid:12)
(cid:12)
i R1
(cid:12)
(cid:12)

k R(i)1

Rki
Rii

(cid:12)
(cid:12)e(cid:62)
(cid:12)

(cid:12)
(cid:12)e(cid:62)
(cid:12)

(cid:12)
(cid:12)
(cid:12) =

· e(cid:62)

≤

(cid:12)
(cid:12)e(cid:62)
(cid:12)

(cid:12)
(cid:12)
(cid:12) .
i R1

(119)

(120)

(121)

(122)

(123)

Applying d (cid:29) (log n)4+4ε+2a and substituting (122) and (123) into (121) and then into (120), we
get that

(cid:12)
(cid:12)e(cid:62)
(cid:12)

i R1

(cid:12)
(cid:12)
(cid:12)

(cid:46) 1 + (log n)1+ε

(cid:18) maxk |e(cid:62)
k R1|
d

√

(cid:19)

+ (log n)a

(124)

Taking the maximum over i and rearranging yields (35).

36

7.4 Total sum bound

Finally, we show that (36) holds with probability 1 − e−c(log n)(log log n) for z ∈ D. As above, we set

Zi =

(i)
(cid:88)

j,k

aikR(i)

kj =

(i)
(cid:88)

k

(cid:16)

aik

k R(i)1
e(cid:62)

(cid:17)

.

Note that if we apply (122), (123), and (35) to (121), we obtain w.h.p. that for every i ∈ [n],

|Zi| ≤ (log n)1+ε+a.

(125)

(126)

The main step of the proof of (36) is to use the weak dependence of Z1, . . . , Zn to obtain a bound
on n−1 (cid:80)
i Zi that is better than (log n)1+ε+a. The idea is encapsulated by the following abstract
lemma from [EKYY13b].

Lemma 7.2 (Fluctuation averaging). Let Ξ be an event deﬁned by A, let Z1, . . . , Zn be random
variables which are functions of A, let p be an (n-dependent) even integer, and let x, y > 0 be
deterministic positive quantities. Suppose there exist random variables Z [U ]
, indexed by U ⊆ [n]
and i ∈ [n] \ U , which satisfy Z [∅]

i
i = Zi as well as the following conditions:

(i) Let ai denote the ith row of A. Then Z [U ]

is independent of {aj : j ∈ U }, and Ei

i

where Ei is the partial expectation over only ai.

(ii) For any U ⊆ S ⊂ [n] with |S| ≤ p, and for any i /∈ S, denote u = |U | + 1 and

Z S,U

i =

(cid:88)

(−1)|T |Z [(S\U )∪T ]
i

.

T : T ⊆U

Then for a constant C > 0 and any integer r ∈ [0, p],

Furthermore,

(cid:104)
1{Ξ}

E

(cid:12)
(cid:12)Z S,U
(cid:12)

i

(cid:12)
r(cid:105)
(cid:12)
(cid:12)

(cid:16)

y(Cxu)u(cid:17)r

.

≤

x ≤ 1/(p5 log n).

(cid:105)

(cid:104)

Z [U ]
i

= 0

(127)

(iii) Let A ⊂ Rn×n be the matrices satisfying Ξ, i.e., Ξ = {A ∈ A}. Let Ai = {B ∈ Rn×n : B(i) =
A(i) for some A ∈ A}, and deﬁne the event Ξi = {A ∈ Ai}. For a constant C > 0 and any
U, S, i as above, E

≤ nCp.

(cid:20)
1{Ξi}

(cid:12)
(cid:12)Z S,U
(cid:12)

i

2(cid:21)
(cid:12)
(cid:12)
(cid:12)

(iv) For a constant C > 0 and any U ⊆ [n], 1{Ξ}

(cid:12)
(cid:12)Z [U ]
(cid:12)

i

(cid:12)
(cid:12) ≤ ynC.
(cid:12)

(v) For a constant ε > 0, P[Ξ] ≥ 1 − e−c(log n)1+εp.

Then for constants C(cid:48), n0 > 0 depending on C, ε above, and for all n ≥ n0,

(cid:34)

P

1{Ξ}

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

n−1 (cid:88)

Zi

i

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

≥ p12y(x2 + n−1)

≤ (C(cid:48)/p)p.

(cid:35)

37

Proof. See [EKYY13b, Theorem 5.6]. (The theorem is stated for 1 + ε = 3/2 in condition (v), but
the proof holds for any ε > 0.)

i

|, and in particular each |Zi| = |Z [∅]
i

The important condition encapsulating weak dependence above is (ii). Applying (ii) with U = ∅,
the condition requires ﬁrst that each |Z [S]
|, is of typical size
Cxy. In the application of this lemma, for S = U and i /∈ U , we will deﬁne the variables Z [V ]
for ∅ ⊆ V ⊆ U such that the quantity Z U,U
in (127) is the variable Zi with its dependence on all
{aj : j ∈ U } projected out by an inclusion-exclusion procedure. Then condition (ii) requires that Zi
depends weakly on {aj : j ∈ U }, in the sense that |Z U,U
| is of typical size x|U |+1y · (C(|U | + 1))|U |+1,
which is roughly smaller than |Zi| by a factor of x|U | for each element of U . Assuming 1/
n (cid:28)
x (cid:28) p−12, the above then estimates the average |n−1 (cid:80)
i Zi| to be of the smaller order p12yx2 (cid:28) xy.
We refer the reader to the discussion in [EKYY13b] for additional details.

√

i

i

i

We will check that the conditions of this lemma hold for Zi as deﬁned by (125), with the
. To this end, we ﬁrst extend (33), (34), and (35) to R(S)

appropriate construction of variables Z [U ]
for |S| ≤ log n in the following deterministic lemma:

i

Lemma 7.3. Suppose (33), (34), and (35) hold with the constant C ≡ C0 for a deterministic
symmetric matrix A, some z ∈ D, and all j, k ∈ [n]. Then for all S ⊂ [n] with |S| ≤ log n, and all
j (cid:54)= k ∈ [n] \ S,

|R(S)

jj (z) − m0(z)| ≤

|R(S)

jk (z)| ≤

2C0(log n)2+2ε+3a
√
d

,

2C0(log n)2+2ε+a
√
d

,

|e(cid:62)

j R(S)(z)1| ≤ 2C0(log n)1+ε+a.

(128)

(129)

(130)

Proof. For integers s ≥ 0, let

Λd

s = max

Λo

s = max

(cid:110)

(cid:110)

|R(S)

jj − m0| : |S| = s, j ∈ [n] \ S
(cid:111)
.

jk | : |S| = s, j (cid:54)= k ∈ [n] \ S

|R(S)

(cid:111)
,

When (33) and (34) hold, we have that Λd
s ≤ C0(log n)2+2ε+3a/
for s = 0. By (112), we have for each s ≥ 1 and ∗ ∈ {d, o} that

√

d and Λo

s ≤ C0(log n)2+2ε+a/

√

d

s+1 ≤ Λ∗
Λ∗

s +

(Λo
s)2
|m0| − Λd
s

.

(131)

Assume inductively that for some s ≤ log n,

Λd

s ≤

C0(log n)2+2ε+3a
√
d

(cid:18)

1 +

4C0(log n)2+2ε+a

√

|m0|

d

(cid:19)s

, Λo

s ≤

C0(log n)2+2ε+a
√
d

(cid:18)

1 +

4C0(log n)2+2ε+a

√

|m0|

d

(cid:19)s

.

(132)

Applying d (cid:29) (log n)6+4ε+2a, |m0| ≥ c, and s ≤ log n, this implies in particular that

Λd

s ≤

2C0(log n)2+2ε+3a
√
d

,

Λo

s ≤

2C0(log n)2+2ε+a
√
d

.

38

We then have |m0| − Λd

s ≥ |m0|/2 for d (cid:29) (log n)4+4ε+6a, so (131) yields

s+1 ≤ max(Λ∗
Λ∗

s, Λo
s)

(cid:18)

1 +

(cid:19)

2Λo
s
|m0|

≤ max(Λ∗

s, Λo
s)

(cid:18)

1 +

4C0(log n)2+2ε+a

√

|m0|

d

(cid:19)

.

Thus both bounds of (132) hold for s + 1, completing the induction. This establishes (128) and
(129).

To show (130), set

Γs = max{|e(cid:62)

j R(S)1| : |S| = s, j /∈ S}.

When (35) holds, Γ0 ≤ C0(log n)1+ε+a. Applying (110) and the bound |m0| − Λd

s ≥ |m0|/2, we have

Γs+1 ≤ (1 + 2Λo

s/|m0|)Γs

(129)
≤

(cid:18)

1 +

Thus Γs ≤ 2Γ0 for all s ≤ log n.

4C0(log n)2+2ε+3a

√

|m0|

d

(cid:19)

Γs,

Lemma 7.4. Fix z ∈ D. Let Zi be deﬁned in (125). For U ⊂ [n] not containing i, deﬁne

Z [U ]

i =

(iU )
(cid:88)

j,k

aikR(iU )

kj =

(iU )
(cid:88)

k

aik(e(cid:62)

k R(iU )1).

Let Ξ be the event where

• (33), (34), and (35) all hold at z, for all distinct j, k ∈ [n],

• |aij| ≤ 1 for all i, j ∈ [n], and

• (cid:107)A(cid:107) ≤ 2.5.

Let p ∈ [2, (log n) − 1] be an even integer, and set

x =

(log n)2+2ε+a
√
d

,

√

y = C(cid:48)

d(log n)−ε

for a suﬃciently large constant C(cid:48) > 0. Then all of the conditions of Lemma 7.2 are satisﬁed.

Proof. Condition (i) is clear by deﬁnition, as row ai of A is independent of R(iU ).

To check (ii), note ﬁrst that the bound x ≤ 1/(p5 log n) follows from d ≥ (log n)16+4ε+2a. For

U ⊆ S and i /∈ S we write

Z S,U

i =

(cid:88)

(−1)|T |Z [(S\U )∪T ]
i

T : T ⊆U

(cid:88)

=

(−1)|T |

((iS\U )∪T )
(cid:88)

T : T ⊆U

k

aik(e(cid:62)

k R((iS\U )∪T )1)

=

(cid:88)

k∈U

(cid:44) (cid:88)
k∈U



aik



(cid:88)

(−1)|T |(e(cid:62)

k R((iS\U )∪T )1)

 +



T : T ⊆U \{k}

aikαk +

(iS)
(cid:88)

k

aikβk.

39



aik



(iS)
(cid:88)

k

(cid:88)

T : T ⊆U

(−1)|T |(e(cid:62)

k R((iS\U )∪T )1)





We claim that deterministically on the event Ξ, there is a constant C > 0 such that for any
W, V ⊂ [n] disjoint with |W ∪ V | ≤ log n, and any i /∈ W ∪ V , we have

(cid:88)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
T : T ⊆W

(−1)|T | (cid:16)

(cid:17)
i R(V ∪T )1
e(cid:62)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤ (cid:101)y(Cxw)w,

(133)

d(log n)−1−ε. We will verify this claim at
where w = |W | + 1, x = (log n)2+2ε+a/
d, and (cid:101)y = C
the end of the proof. Assuming this claim, we apply it above with V = iS \ U and either W = U
or W = U \ {k}. Then setting u = |U | + 1 ≥ w, we have on Ξ that

√

√

|αk| ≤ (cid:101)y(Cxu)|U |,

|βk| ≤ (cid:101)y(Cxu)|U |+1.

(134)

Let r be any even integer with r ≤ p ≤ (log n) − 1. As αk, βk are independent of row ai of A by
deﬁnition, we have for the partial expectation Ei over ai that

(cid:104)

Ei

= Ei

i

(cid:12)
r(cid:105)
(cid:12)
(cid:12)

1{Ξ}

1{Ξ}

(cid:12)
(cid:12)Z S,U
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
k∈U

(cid:88)

aikαk +

(iS)
(cid:88)

k

aikβk

(cid:12)
r
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)



≤ 1{|αk| ≤ (cid:101)y(Cxu)|U | and |βk| ≤ (cid:101)y(Cxu)|U |+1 for all k} · Ei

(cid:88)

(cid:12)

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
k∈U

aikαk +

(iS)
(cid:88)

k

aikβk

(cid:12)
r
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

 .

We apply (24) for the conditional expectation Ei, with v having entries vk = αk for k ∈ U , vk = βk
for k /∈ iS, and vk = 0 otherwise. Recall that w ≤ |U | ≤ |S| ≤ log n. Since Cxw (cid:28) 1 and
|U |(Cxw)2|U | (cid:28) (n − |U |)(Cxw)2|U |+2 by the deﬁnition of x and d ≤ n, the bounds (134) imply

(cid:107)v(cid:107)∞ ≤ (cid:101)y(Cxu)|U |,

√

(cid:107)v(cid:107)2 ≤

2n · (cid:101)y(Cxw)|U |+1.

Then for a constant C(cid:48) > 0, (24) gives

(cid:104)

Ei

1{Ξ}

r(cid:105)

(cid:12)
(cid:12)Z S,U
(cid:12)

i

(cid:12)
(cid:12)
(cid:12)

≤ (C(cid:48)r(cid:101)y(Cxu)u)r.

Then taking the full expectation and setting y = C(cid:48)(log n)(cid:101)y ≥ C(cid:48)r(cid:101)y (since r ≤ p ≤ log n) yields
condition (ii).

For condition (iii), we have

(cid:20)

E

1{Ξi}

(cid:12)
(cid:12)Z S,U
(cid:12)

i

2(cid:21)
(cid:12)
(cid:12)
(cid:12)

≤ 2|U | (cid:88)

E[1{Ξi}|Z [(S\U )∪T ]
i

|2]

T : T ⊆U

= 2|U | (cid:88)

((iS\U )∪T )
(cid:88)

E[aikaik(cid:48)]E

(cid:104)
1{Ξi}(e(cid:62)

k R((iS\U )∪T )1)(e(cid:62)

(cid:105)
k(cid:48)R((iS\U )∪T )1)

T : T ⊆U

k,k(cid:48)

= 2|U | (cid:88)

((iS\U )∪T )
(cid:88)

T : T ⊆U

k

E[a2

ik]E

(cid:20)

1{Ξi}

(cid:12)
(cid:12)e(cid:62)
(cid:12)

k R((iS\U )∪T )1

2(cid:21)
(cid:12)
(cid:12)
(cid:12)

,

40

where the second line applies the independence of ai and A(i). Note that on Ξi, we have (cid:107)A(i)(cid:107) ≤ 2.5.
Then applying |U | ≤ log n, the norm bound (cid:107)R((iS\U )∪T )(cid:107) ≤ (log n)a on Ξi, and E[a2
ik] ≤ C2/n,
we get (iii). For (iv), we apply the condition |aik| ≤ 1 by deﬁnition of Ξ, together with the bound
(cid:107)R(iU )(cid:107) ≤ (log n)a on Ξ. Finally, (v) holds by the probability bound of 1 − e−c(log n)1+ε established
for (33), (34), (35), (22), and in Lemma 4.1.

It remains to establish the claim (133). For W = ∅, this follows from (35). Assume then that
w ≥ 1, and write W = {j1, . . . , jw−1} (in any order). For a function f : Rn×n → C and any index
j ∈ [n], deﬁne Qjf : Rn×n → C by

(Qjf )(A) = f (A) − f (A(j)).
Note that if f is in fact a function of A(S), i.e. f (A) = f (A(S)) for every matrix A ∈ Rn×n,
i R(V )1. This satisﬁes
then Qjf (A) = f (A(S)) − f (A(jS)). Fix i and V , and deﬁne f (A) = e(cid:62)
f (A) = f (A(V )) for every A. Then by inclusion-exclusion, the quantity to be bounded is equivalently
written as

(cid:88)

(−1)|T |(e(cid:62)

i R(V ∪T )1) = (Qjw−1 . . . Qj2Qj1f )(A).

T : T ⊆W

We apply Schur complement identities to iteratively to expand Qjw−1 . . . Qj1f : First applying

(110), we get

Qj1f (A) = e(cid:62)

i R(V )1 − e(cid:62)

i R(j1V )1 = R(V )
ij1

·

1
R(V )
j1j1

· e(cid:62)

j1R(V )1.

Then applying (110), (111), and (112) to the three factors on the right side above, and using the
identity

xyz − (cid:101)x(cid:101)y(cid:101)z = xy(z − (cid:101)z) + x((cid:101)y − y)(cid:101)z + ((cid:101)x − x)(cid:101)y(cid:101)z,

we get

Qj2Qj1f (A) = R(V )
ij1

·

1
R(V )
j1j1

·

(cid:32) R(V )
j1j2
R(V )
j2j2

(cid:33)

· e(cid:62)

j2R(V )1

+ R(V )
ij1

·


−



(cid:16)

(cid:17)2

R(V )
j1j2
R(V )
j2j2

R(V )
j1j1

R(j2V )
j1j1


 · e(cid:62)


j1R(j2V )1

+

R(V )
j2j1

R(V )
ij2
R(V )
j2j2

·

1
R(j2V )
j1j1

· e(cid:62)

j1R(j2V )1.

Applying (112), (111), and (110) to each factor of each summand above, and repeating iteratively,
an induction argument veriﬁes the following claims for each t ∈ {1, . . . , w − 1}:

• Qjt . . . Qj1f (A) is a sum of at most (cid:81)t−1

s=1 4s summands (with the convention (cid:81)0

s=1 4s = 1),

where

• Each summand is a product of at most 4t factors, where

• jach factor is one of the following three forms, for a set S ⊆ V ∪ W : R(S)

jk for j, k /∈ S distinct,

or 1/R(S)
jj

for j /∈ S, or e(cid:62)

j R(S)1 for j /∈ S. Furthermore,

• Each summand of Qjt . . . Qj1f (A) satisﬁes: (a) It has exactly one factor of the form e(cid:62)

j R(S)1.
is less than or equal to the number of factors

(b) The number of factors of the form 1/R(S)
jj
of the form R(S)

jk for j (cid:54)= k. (c) There are at least t factors of the form R(S)

jk for j (cid:54)= k.

41

Finally, we apply this with t = w − 1 and use the bound

t−1
(cid:89)

s=1

4s ≤ (4w)w.

By Lemma 7.3, since |W ∪ V | ≤ log n, we have |R(S)
|e(cid:62)

j R(S)1| ≤ C(log n)1+ε+a on the event Ξ. Thus we get

jk | ≤ C(log n)2+2ε+a/

√

d, |R(S)

jj | ≥ |m0|/2, and

|Qjw−1 . . . Qj1f (A)| ≤ (4w)w ·

(cid:18) C(log n)2+2ε+a
√

d

(cid:19)w−1

· C(log n)1+ε+a ≤ (cid:101)y(C(cid:48)xw)w

for x = (log n)2+2ε+a/

√

d and (cid:101)y = C

√

d(log n)−1−ε, as claimed.

We now show (36) holds for z ∈ D with probability 1 − e−c(log n)(log log n). The diagonal bound

(34) implies

| Tr R − n · m0| ≤

Cn(log n)2+2ε+3a/2
√
d

.

(135)

To bound the sum of oﬀ-diagonal elements of R, we apply (109) to write

(cid:88)

i(cid:54)=k

Rik = −

(cid:88)

i

RiiZi = −m0

(cid:88)

i

Zi −

(cid:88)

i

(Rii − m0)Zi.

(136)

Applying (34) and (126) yields

(cid:88)

i

|(Rii − m0)Zi| ≤

Cn(log n)3+3ε+5a/2
√
d

.

(137)

Then applying Lemma 7.2 with x, y, Ξ as deﬁned in Lemma 7.4 and with p being the largest even
integer less than (log n) − 1, we have

1{Ξ}

(cid:12)
(cid:12)
n−1 (cid:88)
(cid:12)
(cid:12)
(cid:12)

i

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

Zi

≤ C(log n)12 ·

√

d(log n)−ε · (log n)4+4ε+2a/d ≤

C(log n)16+3ε+2a
√
d

(138)

with probability 1 − e−c(log n)(log log n). Since 1(cid:62)R1 = Tr R + (cid:80)
and combining with (135)–(137) yields (36).

i(cid:54)=k Rik, multiplying (138) by n · m0

References

[ABK15]

Yonathan Aﬂalo, Alexander Bronstein, and Ron Kimmel. On convex relaxation of
graph isomorphism. Proceedings of the National Academy of Sciences, 112(10):2942–
2947, 2015.

[BCL+18] Boaz Barak, Chi-Ning Chou, Zhixian Lei, Tselil Schramm, and Yueqi Sheng. (Nearly)
eﬃcient algorithms for the graph matching problem on correlated random graphs.
arXiv preprint arXiv:1805.02349, 2018.

42

[BCPP98] Rainer E Burkard, Eranda Cela, Panos M Pardalos, and Leonidas S Pitsoulis. The
In Handbook of combinatorial optimization, pages

quadratic assignment problem.
1713–1809. Springer, 1998.

[Bia97]

Philippe Biane. On the free convolution with a semi-circular distribution. Indiana
University Mathematics Journal, pages 705–718, 1997.

[DMWX18] Jian Ding, Zongming Ma, Yihong Wu, and Jiaming Xu. Eﬃcient random graph match-

ing via degree proﬁles. arxiv preprint arxiv:1811.07821, Nov 2018.

[EKYY13a] L´aszl´o Erd˝os, Antti Knowles, Horng-Tzer Yau, and Jun Yin. The local semicircle law

for a general class of random matrices. Electron. J. Probab, 18(59):1–58, 2013.

[EKYY13b] L´aszl´o Erd˝os, Antti Knowles, Horng-Tzer Yau, and Jun Yin. Spectral statistics of
Erd˝os–R´enyi graphs I: local semicircle law. The Annals of Probability, 41(3B):2279–
2375, 2013.

[EYY12]

L´aszl´o Erd˝os, Horng-Tzer Yau, and Jun Yin. Bulk universality for generalized Wigner
matrices. Probability Theory and Related Fields, 154(1-2):341–407, 2012.

[FMWX19] Zhou Fan, Cheng Mao, Yihong Wu, and Jiaming Xu. Spectral graph matching and
regularized quadratic relaxations I: The Gaussian model. preprint, 2019.

[HW71]

D. L. Hanson and F. T. Wright. A bound on tail probabilities for quadratic forms in
independent random variables. Ann. Math. Statist., 42:1079–1083, 1971.

[MMS10]

[PG11]

[PRW94]

[RV13]

[ZBV08]

Konstantin Makarychev, Rajsekar Manokaran, and Maxim Sviridenko. Maximum
quadratic assignment problem: Reduction from maximum label cover and LP-based
approximation algorithm. Automata, Languages and Programming, pages 594–604,
2010.

Pedram Pedarsani and Matthias Grossglauser. On the privacy of anonymized networks.
In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,
pages 1235–1243, 2011.

Panos M. Pardalos, Franz Rendl, and Henry Wolkowicz. The quadratic assignment
problem: A survey and recent developments. In In Proceedings of the DIMACS Work-
shop on Quadratic Assignment Problems, volume 16 of DIMACS Series in Discrete
Mathematics and Theoretical Computer Science, pages 1–42. American Mathematical
Society, 1994.

Mark Rudelson and Roman Vershynin. Hanson-Wright inequality and sub-Gaussian
concentration. Electron. Commun. Probab., 18:no. 82, 9, 2013.

Mikhail Zaslavskiy, Francis Bach, and Jean-Philippe Vert. A path following algorithm
for the graph matching problem. IEEE Transactions on Pattern Analysis and Machine
Intelligence, 31(12):2227–2242, 2008.

43

