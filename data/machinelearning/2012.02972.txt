Empiricalobservationofnegligiblefairness-accuracytrade-offsinmachinelearningforpublicpolicyKitT.Rodolfa,1HemankLamba,1RayidGhani1∗1MachineLearningDepartmentandHeinzCollegeofInformationSystemsandPublicPolicy,CarnegieMellonUniversity,Pittsburgh,PA15213,USA∗Towhomcorrespondenceshouldbeaddressed;E-mail:rayid@cmu.edu.AbstractGrowinguseofmachinelearninginpolicyandsocialimpactsettingshaveraisedcon-cernsforfairnessimplications,especiallyforracialminorities.Theseconcernshavegen-eratedconsiderableinterestamongmachinelearningandartiﬁcialintelligenceresearchers,whohavedevelopednewmethodsandestablishedtheoreticalboundsforimprovingfair-ness,focusingonthesourcedata,regularizationandmodeltraining,orpost-hocadjust-mentstomodelscores.However,littleworkhasstudiedthepracticaltrade-offsbetweenfairnessandaccuracyinreal-worldsettingstounderstandhowtheseboundsandmeth-odstranslateintopolicychoicesandimpactonsociety.Ourempiricalstudyﬁllsthisgapbyinvestigatingtheimpactofmitigatingdisparitiesonaccuracy,focusingonthecom-moncontextofusingmachinelearningtoinformbeneﬁtallocationinresource-constrainedprogramsacrosseducation,mentalhealth,criminaljustice,andhousingsafety.Herewedescribeappliedworkinwhichweﬁndfairness-accuracytrade-offstobenegligibleinpractice.Ineachsettingstudied,explicitlyfocusingonachievingequityandusingourpro-posedpost-hocdisparitymitigationmethods,fairnesswassubstantiallyimprovedwithoutsacriﬁcingaccuracy.Thisobservationwasrobustacrosspolicycontextsstudied,scaleofresourcesavailableforintervention,time,andrelativesizeoftheprotectedgroups.Theseempiricalresultschallengeacommonlyheldassumptionthatreducingdisparitieseitherrequiresacceptinganappreciabledropinaccuracyorthedevelopmentofnovel,complexmethods,makingreducingdisparitiesintheseapplicationsmorepractical.Therehasbeenarapidgrowthintheuseofmachinelearningforapplicationswithex-tensiveimpactonsociety,suchasinformingbaildeterminationdecisions,1–3hiring,4healthcaredelivery,5,6andsocialserviceinterventions.7–9Thesewide-reachingapplicationshavebeenmet1arXiv:2012.02972v3  [cs.LG]  3 Sep 2021withheightenedconcernsabouttheirpotentialforintroducingoramplifyinginequities,espe-ciallyforracialminoritiesandeconomicallydisadvantagedindividuals,motivatingexplorationofarangeofpotentialsourcesandmitigationstrategiesforbiases,includingintheunderlyingdata,10labels,5modeltraining,11–13andpost-modelingadjustmentstoscores.14,15Acommonunderpinningofmuchofthisworkistheassumptionthattrade-offsbetweenequityandaccu-racymaynecessitatecomplexmethodsordifﬁcultpolicychoices,16–19howeverlittleworktodatehasexplicitlyevaluatedthemagnitude(oreventheexistence)ofthesetrade-offsinreal-worldproblems.Notethatinthisworkweusetheterm“accuracy”inthemorecolloquialsenseofthecorrectnessofamodel’spredictionsrelativetothetaskathand(incontrasttothefair-nessofthosepredictions),ratherthanthespeciﬁcstatisticalpropertyofthesamename.Foreachpolicysettingwestudyweuseamorespeciﬁc“accuracy”metricbasedonthegoaloftheprogram.Ourstudyfocusesontestingtheassumedaccuracy-fairnesstrade-offsinresourceallocationproblemsacrossseveralpublicpolicydomains.Organizationswithlimitedresourcesareoftenonlyabletointerveneandallocatebeneﬁtstoarelativelysmallnumberofindividualswithneed,presentinga“topk”optimizationproblemwheremodelaccuracyisjudgedbyprecision(alsoknownaspositivepredictivevalue)amongthekhighest-scoringindividuals(althoughprecisioninthetopkreadilymapstoaconceptofefﬁcientlyallocatinglimitedresourcesinthesesettings,itisworthnotingthatforagivenvalueofkonaﬁxeddataset,knowingthevalueofprecisioninthetopkwillfullydetermineboththevaluesofrecallinthetopkandaccuracyinthetopksuchthatoptimizingforanyoneofthesemetricsisequivalenttooptimizingfortheothertwoaswell).Insuchassistiveinterventionsettings,we15andothers14havearguedthatrecall(alsoknownassensitivityortruepositiverate)disparitiesareoftenanappropriateequitymetric,reﬂectingaconceptof“equalityofopportunity.”Inarecentcasestudy,15wefoundthatexplicitlyfocusingonachievingequityandusingsubgroup-speciﬁcscorethresholdsasapost-hocdisparitymitigationmethodimprovedtheequityofpredictionswithonlyaverymodestdecreaseinaccuracy.Whilethatstudyfocusedonourexperiencesincorporatingfairnessintothedeploymentofamachinelearningsystemandtherelatedpolicydecision-makinginasinglecontext(developingsocialserviceinterventionsasameansofjaildiversioninLosAngeles,CA),theempiricalworkhereextendsthatstudy’ssurprisingresulttoseveralnewpolicycontextsandmodelingchoices.Ourresultssuggestthattrade-offsbetweenfairnessandeffectivenesscaninfactbenegligibleinpractice,suggestingthatimprovementinmaybeequityeasierandmorepracticalacrossawiderangeofapplicationsthanisoftenexpected.Wecometothisconclusionusingavarietyofprojectsweundertookoverthepastfewyearswithgovernmentagenciesacrosscriminaljustice,mentalhealth,housingsafety,andeducation,ﬁndingthateachofthesecontextsposesacounterexampletotheassumptionoflargetrade-offsbetweenfairnessandaccuracy.2PolicySettingsandDataInformationaboutthepolicysettingsincludedinthepresentstudyareprovidedinTable1,andabriefdescriptionofthecontextandproblemforeachisprovidedbelow.Notethatthemachinelearningformulation(includingoutcomemeasures,train-validationsplits,evaluationmetrics)anddetailsineachcaseweredeterminedthroughcarefulscopingandcollaborationwiththepartnerorganization.Forinstance,thetopklistsizeineachcasereﬂectstheorganization’sresourceconstraintsforinterveningonentities,whilepolicymakerandstakeholderprioritiesinformedthelabeldeﬁnitionaswellasthesensitiveattributeusedformeasuringfairness.InmateMentalHealthSeekingtobreakthecycleofincarcerationforindividualswithun-treatedmentalhealthconditions,JohnsonCounty,KS,partneredwithustoprioritizelimitedresourcesformentalhealthoutreachonindividualsatriskofafuturejailbooking.Wede-velopedapredictivemodelofriskforabookinginthenextyear,focusingonidentifying500individualsforoutreachina4-monthwindowbasedontheresourcesavailabletotheprogram.Disparitiesonraceandethnicityareparticularlysalientinthecriminaljusticecontext,andwefocusedonthisattributeinourbiasanalyses(here,welookeitherat2-wayresultsbetweenwhiteandnon-whiteindividuals,or3-wayresultsbetweenwhite,Black,andHispanicindivid-uals;individualsinotherorunknownracialorethnicgroupsmakeuponly0.4%ofthedatasetandwereincludedwithwhiteindividualsfortheseanalyses).HousingSafetyTheCodeEnforcementOfﬁceinSanJose,CA,istaskedwithprotectingoccupantsofpropertieswithmultipleunits(suchasapartmentbuildings)byconductingsafetyinspections,butdoesn’thavesufﬁcientstafﬁngtoinspectall4,500propertieseveryyear.Usinginternaldatasuppliedbytheprogram,wedevelopedamodelfortheriskthataseriousviolationwouldbefoundifagivenpropertywereprioritizedforinspection.Wefocusedondisparitiesbetweenhousingunitsinhigher-andlower-incomeneighborhoods(medianincomeaboveorbelow$55,000)whereconsiderabledisparitieswereobservedinourinitialmodelsfavoringhigher-incomeareas.StudentOutcomesElSalvador’sMinistryofEducationseekstosupportstudentstoreducethecountry’ssubstantialdropoutrates(recentlyashighas29%insomeyears),butthebudgetfortheseprogramsisinsufﬁcienttoreacheverystudent.Student-leveldatawasprovidedbytheMinistrytodevelopamodelofstudentsatriskofdroppingout,andouranalysisherefocusesonidentifyingthe10,000highest-riskstudentsinthestateofSanSalvador.TheMinistryofEducationwasconcernedwithpotentialdisparitiesingender,agerelativetogradelevel,andurban-ruraldivide.Initialanalysesfoundlargedisparitieswith“over-age”students(thoseatleast2standarddeviationsabovethemeanoftheirgradelevel),whichwefocusoninthepresentstudy.Sincetheprojectsaboveusedconﬁdentialandsensitivedataandweredoneunderdatauseagreements,wearenotabletomakethatdatapubliclyavailable.Forourworktobeeasilyreproducible,weincludeafourthprobleminthisstudywherethedataisavailablepublicly:EducationCrowdfundingThenon-proﬁtDonorsChoosehelpsalleviateschoolfundingshort-agesbyprovidingacrowdfundingplatformforteacherstopostrequestsfortheirclassroom3needs.Here,wemakeuseofadatasetDonorsChoosemadepubliclyavailablein2014andpositanefforttoassistprojectsatriskofgoingunfunded(forinstance,providingareviewandconsultation)capableofhelping1,000projectsina2-monthwindow.Reﬂectingtheplatform’sgoalofhelpingschoolsandteachersmostatneed,wefocusinthiscontextondisparitiesacrossschoolpovertylevels(65%free/reducedlunchvsothers).Althoughunliketheothersettingsdescribedabove,theEducationCrowdfundinganalysisdidnotarisefromaprojectundertakeninpartnershipwiththeorganization,wesoughttoscopeandformulateaprojectwiththesamecharacteristicsofthosewetypicallyencounterwithpartners.Detailsofthemachinelearningmodelingandevaluationperformedineachcontextarede-scribedintheMethods.Inshort,weexploredanexpansivegridofmachinelearningmodeltypesandhyperparametersineachproblemtogeneratecandidatemodelsforouranalysis.Be-causeoftheinherentlynon-stationarynatureofreal-worldproblemsingeneralandpolicyap-plicationsinparticular(withpolicies,practices,andcontextchangingovertime),trainingandvalidationsetsweregeneratedthroughaprocessofinter-temporalcross-validation.Thisap-proachcreatesasetoftemporallysequentialtrainandvalidationdatasets,reﬂectingdeploy-mentofmachinelearninginthesesettingswheremodelstrainedonpastdatamustgeneralizeintoachangingfuturecontext.Althoughnottheprimaryfocusofthecurrentwork,wenotethatineachcontext,modelingwasabletoprovidemeaningfulimprovementsoverthebaseratefortheoutcome(label)ofinterestinthepopulation(showninTable1),whichcouldtranslateintosubstantiveefﬁciencygainsinpolicyimplementation.Notethatinabaselinemodelwhichrandomlychoseagroupforintervention,theexpectedfractionoftruepositivesinthisgroup(thatis,theprecision)wouldbegivenbythisbaserateofthelabel.IneachoftheHousingSafety,StudentOutcomes,andEducationCrowdfundingproblems,modelperformancepro-videdaroughly2-foldincreaseoverthisbaseline,andintheInmateMentalHealthcontext(wheretheunderlyingeventismorerare,withabaserateof12%),thisimprovementwasbymorethanafactorof4,makingtheMLmodelsusefulcomparedtosimplersolutionsandbase-lines.Thefollowingresultsfocusonusinggroup-speciﬁcscorethresholdstomitigatedisparitiesobservedinthesemodels’predictions.Fig.1aillustratestheintuitionbehindmakinggroup-speciﬁcadjustmentstoauniformscorethresholdinordertoequalizerecall(alsoknownassensitivityortruepositiverate)acrossgroups.Becauserecallincreasesmonotonicallywithlowerscorethresholds,auniquesolutioncanbefoundthatequalizesrecallacrossgroupswhilekeepingaﬁxedtotalnumberofentitiesselectedforintervention.InFig.1b,weprovideaschematicofthetemporalstrategyusedformakingtheseadjustmentsandtestingtheirabilitytogeneralizetounseenfuturedata.Inthisﬁgure,thedark-coloredrectanglesindicatepointsintimeatwhichacohortoftrainingorvalidationexamplesisdeﬁned(thismightbeschoolyearsintheStudentOutcomescontextorquartersintheHousingSafetycontext)andtheassociatedlight-coloredrectanglesreﬂectabufferduringwhichoutcomesaremeasured(forinstance,the4monthsaprojectintheEducationCrowdfundingcontexthastocollectdonations)inordertoavoidleakage20betweenthetrainingandvalidationsets.Notethatfeaturesforeachcohortwillmakeuseofallearlierinformationaswell.Foronepointinouranalysis,agridofmodelsis4trainedusingthebluecohort(t−2),withperformanceonthepurplecohort(t−1)usedtoselectwell-performingmodelsandﬁndthresholdswhichequalizerecallacrossgroups.Inordertoevaluatehowwellthesethresholdswouldthenimprovefairness(aswellasanyassociatedaccuracytrade-off)whenappliedtonewdata,westeptheprocessforwardintime:trainingmodelsusingdatauptothepurplecohortandapplyingthemalongwiththegroup-speciﬁcthresholdsontheorangecohort(t0),whichreﬂectsourtruegeneralizationperformance.Tounderstandconsistencyandstabilityofourresultsovertime,werepeatthisprocessseveraltimes,shiftingthethreecohortstogetheracrossdifferenttemporalvalidationsplits.MeasuringFairnessOnechallengeencounteredbybothresearchersandpractitionersseekingtoimprovethefairnessofmachinelearningmodelsisthenebulousnatureoftheconceptof“fairness”itself.Muchhasbeenwrittenaboutthewiderangeofmetricswhichcanbeusedtomeasureorconceptualizefairnessindifferentcontexts,21,22and,inparticular,themathematicalincompatibilityofvarioussetsofthesemetrics.1,23Asaresult,animportantaspectofprojectscopingisunderstandingthefairnessmetric(ormetrics)mostappropriatetothegivencontext.Wehavepreviouslydescribedaframeworkforthisprocess.15Forinstance,machinelearningapplicationswhichinformbeneﬁtallocationdecisionsmightbeprimarilyconcernedwithavoidingdisparitiesinfalsenegatives(thatis,failingtoreachindividualswithneed),whileapplicationsthataremorepunitiveinnature(suchasbaildenialdecisions)arelikelytobemoreconcernedwithdisparitiesinfalsepositives.Inthepresentwork,wefocusonresource-constrainedassistiveprograms,acontextinwhichwearguedisparitiesinrecall(alsoknownassensitivityortruepositiverate)isanaturalcon-ceptualizationoffairness.Becauserecallisthecomplementofthefalsenegativerate(thatis,recall=TPR=1−FNR),improvingequityintermsofrecallreﬂectsafocusonerrorsofomission,butprovidesmorereadily-interpretableratiosthanthefalsenegativerateitselfwhenresourcesarelimited(suchthatevenahighlypredictivemodelwouldhaveafalsenegativeratenear1).Hardt14providessomeadditionalhelpfulintuitionhere,describingthismetricasare-ﬂectionof“equalityofopportunity.”Speciﬁcally,whenonlyafractionofindividualswithneedcanreceiveabeneﬁt,recallmeasuresthefractionofthoseindividualsaprogramreachesanddisparitiesinrecallthereforemeasurewhetherindividualswithneedacrossdifferentsub-groupshaveanequalchanceofreceivingthebeneﬁt.Inparticular,wemeasurerecalldisparityastheratiobetweentherecallattainedbyamodelforonegroupofinterest(suchasBlackindividuals)andthemodel’srecallforareferencegroup(suchaswhiteindividuals).Incontextswithmorethantwosub-groupsofinterest,wechooseareferencegroupandconsiderdisparitiesforallothergroupsrelativetothisgroupseparately.5EvaluatingTrade-OffsWestartedwiththeassumption,basedonexistingtheoreticalwork,thatthereisatrade-offbe-tween“accuracy”and“fairness.”Asaninitialexperiment,weexploredhowmodel“accuracy”changesuponadjustingfordisparitiesintheInmateMentalHealthsettingusingasingletempo-ralvalidationsplit(withvalidationsetoutcomesspanning4/2018to4/2019).InFigs.1cand1d,eachpairofpointsisamodelspeciﬁcation:withresultsobtainedwithoutadjustingforequityinblueandthosewiththeequityadjustmentinorange.Thex-axisshowstheprecision(positivepredictivevalue)ofeachmodelonthe500selectedindividualsandthey-axisshowstherecalldisparitybetweenwhiteandnon-whiteindividuals.Fig.1cshowsallmodelsconsidered(themodelspeciﬁcationsusedherearedetailedinSupplementaryTable1),whileFig.1dprovidesamoredetailedviewofthebetter-performingmodelsthatmightreasonablybeselected.Alloftheunadjustedmodelshadsigniﬁcantdisparities,indicatingthatmerelymeasuringdisparitiestoinformtheprocessofmodelselectionwouldbeinsufﬁcientforachievingfairness.However,applyingourproposedbiasmitigationmethodtoadjustfordisparities,weﬁndlittleevidenceofafairness-accuracytrade-off:overall,themeanchangeinprecisionafteradjustmentis-0.0006(std:0.0087);Fig.1eshowsthedistributionoftheseshifts.Wealsoinvestigatedcreatingacompositemodel(basedontheworkofDworkandcol-leagues13)bychoosingthebest-performingmodelforeachsubgroupandusingtherecall-equalizingsetofindividuals(maintainingatotallistsizeof500)fromeachsubgroup-optimizedmodel.TheperformanceofthiscompositeonthesubsequentvalidationsetisshownasareddiamondinFigs.1cand1d.Onbothfairnessandaccuracy-relatedmetrics,thiscompositeappearstoperformcompetitivelywithothermodels,butdoesnotstandoutasout-performingthefairness-adjustedindividualmodelsoneithermetric.Thepromiseofthecompositestrategyisthatitmightimprovetheaccuracyoneachsubgroup(and,hence,theoverallperformanceacrosssubgroups)whileyieldingmoreequitableresults.Inthisinitialexperiment,however,themorecomplexapproachofbuildingacompositemodelshowsnoindicationofprovidinggainsbeyondthesimplerapproachofmakingfairness-enhancingadjustmentstoasingle,well-performingmodel.ComparingMitigationStrategiesTheseinitialresultssuggesteddisparitymitigationcouldbeintegratedintotheprocessofmodelselection,andwenextsoughttocomparestrategiesfordoingso(summarizedinTable2anddescribedinmoredetailintheMethods).Inthestrategylabeled“Mitigated-SingleModel,”modelspeciﬁcationsarecomparedbasedontheirprecisionattopkafterapplyinggroup-speciﬁcthresholdstomitigatedisparitiesandthechosenmodelisevaluatedonnewdata.Se-lectingamodelwithoutregardtofairnessandapplyingdisparitymitigationonlytothechosenmodelshowednopracticaldifferenceinperformanceoneitherfairnessoraccuracymetricsinanyofouranalyses(seeSupplementaryDiscussion).Asabaseline,the“Unmitigated”approach6performsmodelselectionwithoutaccountingforanydisparities.Additionally,the“Mitigated-CompositeModel”strategychoosesthebest-performingmodeloneachsubgroupatthemodelselectionstageandpicksrecall-balancingthresholdsacrossthese.Wealsoexploredcompositemodelscreatedfromfully-decoupledmodelstrainedonlyonsubgroup-speciﬁcexamples(alsosuggestedbyDwork13),butsawnodifferenceinperformancefromthecompositemethoddescribedhereintheseinitialexperimentsanddidnotpursuethislineofinvestigationfurther.Likewise,inconsideringotherfairness-enhancingmethodsthathavebeenproposed,wefoundthatsome(suchastheregularizationmethodde-velopedbyZafar12)werenotwell-suitedtothe“topk”problemsettingandothers(suchasthemethodsproposedbyCelis11andMenon24)couldbeshowntobeequivalenttogroup-speciﬁcthresholdsundercertainconditions(seeSupplementaryDiscussion).Applyingourthreestrategiestoawidevarietyofmodelsandhyperparametercombinationsincludingrandomforests,logisticregression,boosting,anddecisiontreesbuiltforeachpol-icyproblem,appreciablerecalldisparitieswerepresentintheunadjustedmodelsinallcases,rangingfrom50%higherrecallfavoringwhiteindividualsintheInmateMentalHealthcontexttoasmuchasa250%disparityintheStudentOutcomessetting.IntheresultsshowninFig.2,strategiesyieldinglargerdisparitieswillhavehighervaluesalongthey-axiswhilestrategiesyieldingprecisiondecreaseswouldmoveleftalongthex-axisrelativetotheunmit-igatedmodels(solidsquaresmarkedwitha’U’).Notethatineachcontext,thetopklistsizeandsensitiveattributeformeasuringperformanceanddisparities,respectively,canbefoundinTable1,reﬂectingtheresourceconstraintsandstakeholderprioritiesofthepolicysettingsdis-cussedabove.However,weseethatmitigatingdisparities,surprisingly,doesnotcomewithanyappreciabledegradationofoverallmodelperformanceonunseendataforanyofthepolicysettingsinvestigated:precisionattopkissimilarinmagnitudefortheunmitigatedandmitigatedmodels,withlittledifferencebetweenthefairness-enhancingapproaches(largeerrorbarsintheunmitigatedStudentOutcomesresultreﬂectthesmallnumberoftemporalsplitsandasinglecohortwithlowbaselinedisparity).Acrossallfourproblems,theprecisionattopkforthemitigatedmodelswasstatisticallyindistinguishablefromthatoftheunmitigatedmod-els(t-testsforthesedifferencesyieldedp-valuesof0.83forEducationCrowdfunding,0.47forHousingSafety,0.84forInmateMentalHealth,and0.71forStudentOutcomes),aswellaspracticallynegligiblewithnodifferenceinprecisionhigherthan1percentagepoint.Thisﬁnd-ingempiricallydemonstratesthatanyinherenttrade-offthatmightbepresentinadjustingfordisparitiesappeartobepracticallynon-existent.Toexploretheseresultsinmoredetail,Fig.3showstheeffectofthesebiasmitigationstrate-giesontheInmateMentalHealthsettingovertemporalvalidationcohorts(seeSupplementaryFigs.2-4forresultsfromtheotherpolicysettings).Inthiscontext,wealsowantedtounder-standhowthesemethodsperformedwhenadjustingfordisparitiesacrossmultiplesubgroups,lookingatrace/ethnicityacrosswhite,Black,andHispanicindividuals.Overallperformance(precisionattop500)wassimilarformodelsselectedfromallthreestrategiesovertime(Fig.3a)andrecalldisparitiesbetweenwhiteandBlackindividualswereconsistentlyandsigniﬁcantlyimprovedbytheadjustments(Fig.3b).Withoutaccountingfor7equityorfairness,recallforwhiteindividualswas40-100%higherthanBlackindividualsinthechosenmodels,whilebothfairnessenhancingstrategiesyieldedarationearone(parity)forthesetwosubgroups.TheresultsfordisparitiesbetweenHispanicandwhiteindividuals(Fig.3c)arebroadlyconsistent,butshowsigniﬁcantlymorevariation,whichappearstobeparticularlyacutewiththecompositemodelapproach.Wehypothesizedthatthisvariabilitymightariseinpartfromaninteractionbetweentherelativelysmallsizeofthisgroupinthepopulation(about11%ofeachcohort)andprocessbywhichthecompositemodeliscreated:whilethemodelselectionprocessforthesinglemodelapproachmakesuseofthefulltopksetofindividualsselectedforintervention,thecompositeapproachperformsmodelselectiononeachgroupseparately,whichmaybelessrobustasthegroupsbecomesmaller.Tobetterunderstandtheinteractionbetweentheoveralltopklistsize,subgroupsizes,andourresults,weperformedaseriesofsensitivityexperiments.Althoughinpractice,eachpolicyproblemcomeswithaspeciﬁcvalueofkdeterminedbytheresourceconstraintsoftheorganizationtakingaction.Fig.4a-cshowsthefairnessandaccuracymetricsforeachstrategyatdifferentlevelsofprogramresourceavailability(k).Consistentwiththeﬁndingsabove,Fig.4cshowsessentiallyidenticalprecisionattopkperformanceacrossallselectionstrategies,bothbias-mitigatedandunmitigated,andoverallvaluesofkexplored.Acrossallk,thefairnessimprovingstrategychoosingasinglemodelconsistentlyshowedimprovementindisparitymetricsforbothBlack(Fig.4a)andHispanic(Fig.4b)individuals.Bycontrast,thecompositestrategywaslesseffectiveatequalizingrecallacrossrace/ethnicitysubgroups,particularlyatlowerlistsizesandwiththesmallerHispanicsubgroup.Theunder-performanceofthecompositemodelsuggestsamechanismdrivingthisresult:evaluatingamodel’sperformanceonsuchasmallgroupmaybeespeciallypronetooverﬁtting,choosingamodelwithanunreasonablyhighestimateofprecisiononthesubgroupthatwon’tgeneralizewellintothefuture.Becauseconstructingthecompositemodelacrosssubgroupsinvolvesdeterminingthenumberofindividualstoselectfromeachsubgroupwiththegoalofequalizingrecallacrossthem,aprocessthatleadstosystematicallyover-estimatingthepreci-sionforHispanicindividualswouldbiastowardsselectingasmallersetofindividualsthanisactuallyneeded(thiscanbeobservedinSupplementaryFig.5b,whichshowsthefractionofHispanicindividualsintheselectedlist).Whentheperformanceofthechosenmodelfailstogeneralizewellontheunseen,futuredata,theunder-estimatedsubgroupsizeresultsinalower-than-expectedrecalland,thus,ahigherdisparity.Bycontrast,choosingasinglemodelacrossallgroups(ratherthanbuildingacomposite)seemslikelytobemoreresilienttothisissue,bothbyvirtueofreducingvarianceinthemodelselectionprocess(bywayofthelargeroverallsam-plesizes)andtothedegreethatanypotentialreductioningeneralizationperformancemightbelikelytoaffectallsubgroupssimilarly.Tofurtherinvestigatetheimpactofsubgroupsizeonthestabilityoftheresults(e.g.,throughsamplingvariation),weperformedaresamplingexperimenttoprogressivelyincreasetheHis-panicfractioninthepopulation,rangingfrom5%to38%(focusingonk=500basedontheactualprogramresources).NotethatalthoughthisexperimentfocusedonchangingthefractionofHispanicindividualsinthepopulation,theanalysismadeuseofdatafromallsubgroups,8keepingtheratiobetweenBlackandwhiteindividualsconstant(seeSupplementaryFig.6foradditionalresults).Asobservedabove,thecompositemodelperformslesswellatreducingdisparitiesbetweenwhiteandHispanicindividualsforthebaselineHispanicfractionof11%(Fig.4d).Whilethisunder-performanceisalsoobservedatotherlowfractions,thisstrategybecomescompetitivewiththeotherthesinglemodelstrategyatHispanicfractionsabove20%,consistentwithourhypothesisthatthesmallpopulationofHispanicindividualsintheunder-lyingdatamaybecreatingatendencytowardsoverﬁttingintheformationofthecompositemodels.DiscussionTakentogether,theseresultssuggestapromisingandnovelconclusion:acrossarangeofpolicydomains,mitigatingdisparitiesdoesnotinherentlyrequirenewandcomplexmachinelearningmethodsoraprohibitivelylargeaccuracysacriﬁceasisoftenassumed.Instead,explicitlydeﬁningthefairnessgoalupfrontinthemachinelearningprocessandmakingdesignchoicestoachievethatgoalbytakingactive,practicalsteps,suchasthepost-hocbiasmitigationstrategiesinvestigatedhere,areimportantstepstoachievingthatgoal.Whileitisofcourseimportanttokeepinmindtheempiricalnatureofthisﬁnding,weseeanimportantcontributionofthisworkinprovidingpracticalcounterexamplestocommonly-heldassumptionsaboutthenatureoftherelationshipbetweenfairnessandaccuracy.Assuch,weseetheconsistencyofthesere-sultsacrosspolicysettingsandcontextshereasstronglysuggestivethatpractitionersapplyingmachinelearningmethodstoinformotherhigh-stakespolicydecisionsshouldquestionthisas-sumptionintheirownwork.Additionally,thisworkcontributestoagrowingbodyofevidencethat,inpractice,straightforwardapproachessuchasthoughtfullabelchoice,5modeldesign,8orpost-modelingmitigationcaneffectivelyreducebiasesinmanymachinelearningsystems.Adetailedunderstandingofthemechanismsdrivingthenominaltrade-offsobservedhereisbeyondthescopeofthecurrentempiricalstudy,buttwofactorsthatwepositmayplayim-portantrolesaretheresource-constrainedtopksettingandtherelativepredictiveperformanceofthemodelsacrosssubgroups.Withregardstothetopkcontext,therelativelysmallnumberofindividualswhocanbeselectedforinterventionwilltranslateintoarelativelyhighscorethresholdwhereexampleswithpositivelabelsarerelativelydensebothjustaboveandjustbelowthethreshold.Becausereducingrecalldisparitiesinvolvestradingtruepositivesfromonesubgroupfortruepositivesfromanother,operatingataregionofthescoredistributionwherepositivelabelsarerelativelydensemeansthattheperturbationstogroup-speciﬁcscorethresholdsrequiredtoeliminateagivenlevelofdisparitymaybereasonablysmall.Here,ourhypothesisisthatsettingsinwhichresourcesarelessconstrainedmayposeagreaterchallengetodisparitymitigation,becauseoperatingdeeperinthescoredistribution(thatis,atlowerpre-dictedscorethresholds)meanstherecallgradientwilltypicallybeﬂatterandlargeradjustmentsmayberequiredtoachieveequity(and,hence,resultingingreatertrade-offs).Likewise,therelativeperformanceofthemodelacrosssubgroupswillbeakeyfactorindeterminingboth9howmuchthescorethresholdswillneedtochangeforeachgrouptocollectenoughtruepos-itivestoachieverecallequityaswellashowmanyfalsepositivesareincludedintheprocessofdoingso.Contextsinwhichtheavailablefeaturesaremuchlesspredictiveoftheoutcomeforsomesubgroupsrelativetootherscouldleadtobothlargerbaselinedisparities(ifrecallatagiventhresholdishigherforthemorereadily-predictedgroup)andmoresigniﬁcantfairness-accuracytrade-offs(bynecessitatinglargeradjustmentstoachieverecallequity).Althoughthesetwofactorsmaybemoresalientinothersettings,ourfocusonhigh-impactbeneﬁtallo-cationprogramswithlimitedresourcesreﬂectsasettingthatoccursverycommonlyinpolicycontexts,andfrequentlyencounteredinourappliedwork6,7,9,15andtheempiricalresultsheresuggestsomeoftheseconcernsmaynotbeprohibitivelycommoninpractice.Nevertheless,animportantavenueforfutureworkwillbefurtherexploringthesehypothesisandbeginningtodevelopabettertheoreticalunderstandingoftheconditionsunderwhichimprovementsinequitywillorwillnotcomeatappreciableexpenseinaccuracy.Muchhasalsobeenwrittenaboutthewidevarietyoffairnessmetricsthatmayberelevantdependingonthecontext,1,14,15,21,22andfurtherexplorationofthefairness-accuracytrade-offsinthosecontextsiscertainlywarranted,particularlywherebalancingmultiplefairnessmetricsmaybedesirable.Likewise,itmaybepossiblethatthereisatensionbetweenimprovingfair-nessacrossdifferentattributes(e.g.,sexandrace)orattheintersectionofattributes.Futureworkshouldalsoextendtheseresultstoexploretheimpactnotonlyonequityindecisionmak-ing,butalsoequityinlonger-termoutcomesandimplicationsinalegalcontextsuchasthosediscussedbyHuq.25SocialImpactofThisWorkBeyondtheimmediateimplicationsforthepolicyandsocialimpactproblemsexploredhere,ourgoalinpresentingtheseempiricalﬁndingshereistobetterinformtheuseofmachinelearninginhigh-stakesdecisionsbychallengingthecommonlyheldbeliefthattherenecessarilyisatrade-offbetween“accuracy”and“fairness”intheseapplications.However,itisalsoimportanttonotethatfairnessisnotonlyafunctionofamodel’spredictionsbutalsohowthosepredictionsareactedonbyhumandecision-makersand,morebroadly,thecontextinwhichitoperates,withhistorical,cultural,andstructuralsourcesofinequitiesthatsocietyasawholemuststrivetoovercomethroughtheongoingprocessofremakingitselftobetterreﬂectitshighestidealsofjusticeandequity.Improvingthefairnessofthemachinelearningmodelsthatcontinuetoﬁndgrowingapplicationsincriticaldecisionsthataffectmanyaspectsofpeople’slivesmaybeonlyonesmallelementofthatprocess,butwehopethisworkwillinspireresearchers,policymakers,anddatasciencepractitionersaliketoexplicitlyconsiderfairnessasagoalandtakesteps,suchasthoseproposedhere,intheirworkthatcan,collectively,contributetobendingthelongarcofhistorytowardsamorejustandequitablesociety.10MethodsPolicyContextsandDataAkeyaimofthisworkwastoexplorethefairness-accuracytrade-offsencounteredinprac-ticeinthecontextofmachinelearningapplicationsforpublicpolicysettings.Assuch,wedrewonseveralprojectswehaveworkedoninpartnershipwithgovernmentagenciesacrosspolicydomains.Wedescribethesecontextsbrieﬂyinthemaintextandprovidemoredetailsabouteachsettingbelow:InmateMentalHealthUntreatedmentalhealthconditionsoftenresultinanegativespiral,whichcanculminateinrepeatedperiodsofincarcerationwithlongtermconsequencesbothfortheaffectedindividualandthecommunityasawhole.26Surveysofinmatepopulationshavesuggestedahighprevalenceofmultipleandcomplexneeds,with64%ofpeopleinlocaljailssufferingfrommentalhealthissuesand55%meetingcriteriaforsubstanceabuseordepen-dence.27Thecriminaljusticesystemispoorlysuitedtoaddresstheseneeds,yethousesthreetimesasmanyindividualswithseriousmentalillnessashospitals.28In2016,JohnsonCounty,KS,partneredwithourgrouptohelpthembreakthiscycleofincarcerationbyidentifyingindi-vidualswhomightbeneﬁtfromoutreachwithmentalhealthresourcesandareatriskforfutureincarceration.WhiletheJohnsonCountyMentalHealthCenter(JCMHC)currentlyprovidesservicestothejailpopulation,needsaregenerallyidentiﬁedreactively,forinstancethroughscreeninginstrumentsindividualsﬁlloutwhenenteringjail.Thenewprogrambeingdevelopedwillsupplementtheseexistingapproachesbyaddinganewautomaticreferralsystemforpeo-plewhoareatriskofbeingbookedintojail,withthehopethattheycanbeoutreachedbeforetheyreturntojail.Throughourpartnership,thecountyprovidedadministrativedatafromtheirmentalhealthcenter,jailsystem,policearrests,andambulanceruns.ModelingwasfocusedonacohortofJohnsonCountyresidentswithanyhistoryofmentalhealthneedwhohadbeenreleasedfromjailwithinthepastthreeyears.Earlyresultsfromthisworkweredescribedpre-viously.7Aﬁeldevaluationofthepredictivemodelisongoingatthetimeofthiswriting,butvalidationonhistoricaldatademonstrateda12%improvementoverabaselinebasedonthenumberofbookingsintheprioryearand4.8-foldincreaseoverthepopulationprevalence.HousingSafetyTheMultipleHousingteaminSanJose’sCodeEnforcementOfﬁceistaskedwithprotectingtheoccupantsofpropertieswiththreeormoreunits,suchasapartmentbuild-ings,fraternities,sororities,andhotels.Theydosobyconductingroutineinspectionsoftheseproperties,lookingforeverythingfromblightandpestinfestationstofaultyconstructionandﬁrehazards(seeworkbyHoltzen29andKlein30foradiscussionoftheimportanceofhousinginspectionstopublichealth).AlthoughthecityofSanJoseinspectsallofthepropertiesonitsMultipleHousingrosterovertime,andexpectstoﬁndminorviolationsatmanyofthem,itisimportantthattheycanidentifyandmitigatedangeroussituationsearlytopreventaccidents.Withmorethan4,500multiplehousingpropertiesinSanJose,CA–manyofwhichcomprisemultiplebuildingsandhundredsofunits–itisnotpossibleforthecitytoinspecteveryuniteveryyear.SanJoserecentlyinstitutedatieredapproachtoprioritizinginspections,inspect-ingriskierpropertiesmorefrequentlyandthoroughly.Althoughthetiersystemhelpedfocus11inspectionsonriskierproperties,thenewsystemhasitslimitations.Thecityevaluatestieras-signmentsforpropertiesinfrequently(every3to6years),andtheseadjustmentsrequireagreatdealofexpertiseandmanualworkwhileleavingoutarichamountofinformation.Inordertoprovideamorenuancedviewofproperties’violationriskovertimeandallowformoreefﬁcientschedulingofinspections,theCodeEnforcementOfﬁcepartneredwithustodevelopamodeltopredicttheriskthataseriousviolationwouldbefoundifagivenpropertywasprioritizedforinspection(similartoolshavebeendevelopedforallocatingﬁreinspectionsinNewYork31andhealthinspectionsinBoston32).Evaluationofthemodelonhistoricaldataindicatedthatitcouldprovidea30%increaseinprecisionrelativetothecurrenttiersystemandthemodel’spredictiveaccuracywasconﬁrmedduringa4-monthﬁeldtrialin2017.StudentOutcomesEachyearfrom2010through2016,15-29%ofstudentsenrolledinschoolinElSalvadordidnotreturntoschoolinthefollowingyear.Thishighdropoutrateiscauseforseriousconcern,withsigniﬁcantconsequencesforeconomicproductivity,workforceskill,inclusivenessofgrowth,socialcohesion,andincreasingyouthrisks.33,34ElSalvador’sMinistryofEducationhasprogramsavailabletosupportstudentswiththegoalofreducingthesehighdropoutrates,butthebudgetfortheseprogramsisnotlargeenoughtoreacheverystudentandschoolinElSalvador.Predictivemodelinghasbeendeployedtohelpschoolsiden-tifystudentsatriskofdroppingoutinseveralcontexts35–37andElSalvadorpartneredwithusin2018tomakeuseofthesemethodstofocustheirlimitedresourcesonthestudentsathighestriskofnotreturningeachyear.Student-leveldatawasprovidedbytheMinistryofEducation,includingdemographics,urbanicity,school-levelresources(e.g.,classrooms,computers,etc),ganganddrugviolence,familycharacteristics,attendancerecords,andgraderepetition.Forthepresentstudy,wefocusedonthestateofSanSalvadorandidentifyingthe10,000highest-riskstudents,consideringannualcohortsofapproximately300,000studentsanddrawingon5years’ofpriorexamplesastrainingdata.EducationCrowdfundingManyschoolsintheUnitedStates,particularlyinpoorercommu-nities,facefundingshortages.38Often,teachersthemselvesarelefttoﬁllthisgap,purchasingsuppliesfortheirclassroomswhentheyhavetheindividualresourcestodoso.39Thenon-proﬁtDonorsChoosewasfoundedin2000tohelpalleviatetheseshortagesbyprovidingaplatformwhereteacherspostprojectrequestsfocusedontheirclassroomneedsandcommunitymemberscanmakeindividualcontributionstosupporttheseprojects.Since2000,theyhavefacilitated$970millionindonationsto40millionstudentsintheUnitedStates.40However,approxi-matelyonethirdofallprojectspostedontheplatformfailtoreachtheirfundinggoal.Here,wemakeuseofadatasetDonorsChoosemadepubliclyavailableforthe2014KDDCup(anannualdataminingcompetition)includinginformationaboutprojects,theschoolspostingthem,anddonationstheyreceived.Becausetheothercasestudiesexploredherefocusedonproprietaryandoftensensitivedatasharedwithusunderdatauseagreementsthatcannotbemadepub-liclyavailable,weincludedacasestudysurroundingthispublicly-availabledataset.WhilewehavenotpartneredwithDonorsChoosetodeploythemachinelearningsystemdescribed,weotherwisetreatedthiscasestudyaswewouldanyofourappliedprojects.Here,weconsideraresource-constrainedefforttoassistprojectsatriskofgoingunfunded(forinstance,providing12areviewandconsultation)capableofhelping1,000projectsina2-monthwindow,focusingonthemostrecent2years’ofdataavailableintheextract(earlierdatahadfarfewerprojectsandinstabilityinthebaselinefundingratesastheplatformrampedup).Thisdatasetispubliclyavailableatkaggle.com.41MachineLearningDetailsAllmachinelearningmodels,includingfeatureengineering,modeltraining,andperfor-manceevaluationwererunusingouropen-sourcepythonMLpipelinepackage,triage.Machinelearningmethodsusedarefromsklearn(apythonpackage)orcatwalk(acom-ponentoftriageforbaselinesmethodsaswellasScaledLogisticRegression,whichwrapsthesklearnlogisticregressiontoensureinputfeatures/predictorsasscaledbetween0and1).ThemodelinggridforeachprojectisdescribedinSupplementaryTables1-4,reﬂectingthemodelingspaceexploredbytheteamsworkingoneachproject.Foreachestimatorinthetables,thegridsearchconsideredreﬂectsthefullcross-productofthehyperparametervaluesspeciﬁed.Herewemakeuseofavarietyofstate-of-the-artmachinelearningmethodsforbi-naryclassiﬁcationproblems.Althoughprecisioninthetopkisthemetricofinterestinallofthesettingsdiscussedhere(asdescribedinthemaintext),fewmethodshavebeendevelopedthatseektooptimizeforthismetricdirectly.Instead,weareconcernedwiththerelationshipbetweenfairness(measuredhereintermsofrecalldisparities)andaccuracy(measuredhereintermsofprecisioninthetopk)throughreal-worldsettingsinpractice.Assuch,wemakeuseofwell-establishedmethodsthatarewidelyappliedinpracticalsettings,whichthemselvesopti-mizeforavarietyofunderlyingtargetmetrics(suchasminimizingtheregularizedlogisticlossinlogisticregressionormaximizingtheinformationgainateachsplitintree-basedmodels).Bytrainingalargegridofestimatortypesandhyperparametervalues,optimizationforperfor-manceintermsofprecisioninthetopkcanthenbeperformedthroughtheprocessofmodelselectionovervalidationsets.AsillustratedinFig.1b,weusedastrategyofinter-temporalcross-validation(asdescribedbyRoberts42andYe43)toensurethatmodelevaluationandse-lectionwasdoneinamannerthatreﬂectedperformanceonnoveldatawhileguardingagainst“leakage”ofinformationfromthefutureaffectingpastresults.Themethodweusedformitigatingdisparitiesbypost-modelingadjustmentinvolvingchoos-ingsub-groupspeciﬁcthresholds(seeFig.1a)wasdescribedindetailinourpreviouscasestudy15anddrawsontheideaof“equalityofopportunity”discussedbyHardt.14Inbrief,be-causethenotionoffairnessrelevantinthesepolicysettingsreliesonequalizingrecallacrossgroups,andrecallmonotonicallyincreaseswithdepthtraversedinamodelscore,uniquescorethresholdsthatbalancerecallacrossgroupscanbereadilyfoundforagivencombinedlistsize.Foreachmodel,wecalculatewithin-grouprecallvaluesuptoeachindividualinaninitialvali-dationset(purple/t−1inFig.1b),orderthecombinedsetbywithin-grouprecallandtakethetopkindividualsfromthisreorderedset,calculatingkgforeachgroupgsuchthatPkg=k(thetotaltopklistsizedesired)andrecallisbalancedacrossgroups.Toevaluatethisprocessonnoveldata,modelsweretestedonafuturecohort(tan/t0inFig.1b)andthetopkgexamples(rankedbyscore,thenrandomlytobreakties)fromeachsub-groupwereselectedtomeasure13precisionattopkandrecalldisparities.Intheprocessofmodelselection,weexploredapplyingthesedisparity-mitigatingthresholdseitherbeforechoosingamodelspeciﬁcation(“Mitigated-SingleModel”)orafter(“Mitigated-Unadj.ModelSeln.”),ﬁndingnosubstantivedifferenceinperformance(SupplementaryFig.1).Forthe“Mitigated-CompositeModel”approach,asimilarmethodwasused,butwithin-groupprecisionuptoeachindividualiscalculatedforeachmodelaswelltodeterminethebestmodelspeciﬁcationforeachsub-groupateachlistdepth(drawingontheideassuggestedbyDworkandcolleagues13),thenkgandgroup-speciﬁcmodelspeciﬁcationsarechosenforevaluationonnoveldata.Codeforallfourprojectsincludingtriageconﬁgurationﬁlesspecifyingthefullfea-turesetsusedaswellascodeusedtomitigatedisparitiesandevaluatefairnessisavailableatgithub.com/dssg/peeps-chiliDataAvailabilityDatafromtheInmateMentalHealthcontextwassharedthroughapartnershipanddatauseagreementwiththecountygovernmentofJohnsonCounty,KS(whichcollectedandmadeavailabledatafromthecounty-andcity-levelagenciesintheirjurisdictionasdescribedintheMethodsabove).DatafromtheHousingSafetycontextwassharedthroughapartnershipanddatauseagreementwiththeCodeEnforcementDivisioninthecityofSanJose,CA.DatafromtheStudentOutcomessettingwassharedthroughapartnershipanddatauseagreementwiththeMinistryofEducationinElSalvador.AlthoughthesensitivenatureofthedataforthesethreecontextsrequiredthattheworkwasperformedunderstrictDUAsandthedatacannotbemadepubliclyavailable,researchersorpractitionersinterestedincollaboratingontheseprojectsorwiththeagenciesinvolvedshouldcontactthecorrespondingauthor(rayid@cmu.edu)formoreinformationandintroductions.TheEducationCrowdfundingdataset,however,ispubliclyavail-ableat:kaggle.com/c/kdd-cup-2014-predicting-excitement-at-donors-choose.Additionally,adatabaseextractwithmodeloutputsanddisparitymitigationresultsusingthisdatasetisavail-ablefordownload(seereplicationinstructionsinthecoderepositorynotedbelow).CodeAvailabilityThecodeusedhereformodeling,disparitymitigation,andanalysisforallfourprojectsisavailableatgithub.com/dssg/peeps-chili.44CompleteinstructionsforreplicationoftheEduca-tionCrowdfundingresultsreportedherecanbefoundintheREADMEofthisrespository,alongwithastep-by-stepjupyternotebooktoperformtheanalysis.AcknowledgmentsWewouldliketothanktheDataScienceforSocialGoodFellowshipfellows,projectpartners,andfundersaswellasourcolleaguesattheCenterforDataScienceandPublicPolicyatUni-versityofChicagofortheinitialworkonprojectsthatwereextendedandusedinthisstudy.14WealsothankKasunAmarasingheforhelpfuldiscussionsonthestudyanddraftsofthispaper.PartsofthisworkwerefundedbytheNationalScienceFoundationundergrantIIS-2040929(KTR,RG)andbyagrant(unnumbered)fromtheC3.aiDigitalTransformationInstitute(KTR,HL,RG).AuthorContributionsStatementKTR:Conceptualization,Methodology,Software,Investigation,Writing-OriginalDraft;HL:Investigation,Software,Writing-Review&Editing;RG:Conceptualization,Supervision,Fundingacquisition,Writing-Review&EditingCompetingInterestsStatementTheauthorshavenoconﬂictsofinteresttodeclare.15Table1:PolicySettingsandDataDetailsInmateMentalHealthHousingSafetyStudentOutcomesEducationCrowdfundingPredictionTaskJailbookingwithinthenext12monthsHousingunithavingaviolationwithinthenextyearStudentnotreturningtoschoolnextyearProjectnotgettingfullyfundedwithin4monthsTimespan2013-01-01to2019-04-012011-01-01to2017-06-012009-01-01to2018-01-012010-01-01to2014-01-01#ofEntities61,1924,593801,242210,310#ofFeatures3,4651,657220319BaseRate0.120.430.250.24EvaluationMetricPrecisionattop500Precisionattop500Precisionattop10,000Precisionattop1,000SensitiveAttributeRaceMedianIncomeAgeRelativetoGradePovertyLevel16Table2:DescriptionsofModelSelectionStrategiesStrategyDescriptionUnmitigatedBaselinestrategywithnoequityadjustmentsMitigated-CompositeModelThehighest-precisionmodelischosenforeachsubgroupandacompositemodelisformedcombiningthese,withequity-balancingthresholdsusedwhencalculatingtestperformanceMitigated-SingleModelAllmodelsareadjustedforrecallequityandthenthebestmodelisselectedbasedonprecisionandequity-balancingthresholdsareappliedforcalculatingtestperformanceMitigated-Unadj.ModelSeln.Modelisselectedbasedonprecisionthenequity-balancingthresholdsareappliedforcalculatingtestperformance(SeetheSupplementaryDiscussionforresultsfromthisapproach)17Lower Scores / Higher RecallWhiteBlackHispanicRecallSingle ThresholdRecallGroup Thresholdsat0t-1t-2t1model selection &ﬁnd thresholdsre-train &evaluateb0.20.30.40.50.6Precision at 5000.00.51.01.52.0Recall Disparity(White to Non-White)Equity/Efﬁciency Movement (All Models)c0.520.530.540.550.560.570.580.59Precision at 500Equity/Efﬁciency Movement (Zoomed)0.020.010.000.010.02Change in Precision at 5000%5%10%15%20%25%Percent of ModelsDistribution of Precision ChangesdeFigure1:Illustrationofthemethodsusedandmotivatingresults.(a)Subgroup-speciﬁcthresh-oldsareappliedtoamodeledriskscoretoimprovetherecallequityamongindividualschosenforinterventionwhilemaintainingadesiredoveralllistsize.(b)Temporalvalidationstrategy:agridofmodelsistrainedusingexamplesasoft−2(darkblue,withlabelsderivedfromthetimeshowninlightblue)andpredictionsonacohortasoft−1(darkpurplewithlabelsderivedfromthetimeshowninlightpurple)areusedtodeterminetheequity-balancingthresholdsdescribedin(a).Modelsarethenre-trainedonthiscohortfor“currentday”predictionsasoft0(darktan,withlabelsinlighttan)usedtoevaluatemodelperformancewithequityadjustments.(candd):Changesinrace/ethnicityrecalldisparitiesbefore(blue)andafter(orange)makingpost-hocscoreadjustmentsforfairnessintheInmateMentalHealthcontext.(c)showsallmodelspec-iﬁcationsand(d)showstheclusterofwell-performingmodels.Thereddiamondreﬂectstheperformanceofacompositemodelcombiningthebest-performingmodelforeachsubgroup.(e)Distributionofprecisionchangesafteradjustingfordisparitiesforthemodelsshownin(c),relativetotheprecisionattainedbythesamemodelspeciﬁcationwithoutadjustment(thatis,thedifferencealongthex-axisoftheblueandorangedots).180.450.500.550.600.650.700.750.80Precision at Top k1.01.52.02.53.03.54.04.5Recall DisparityUUUUdatasetEducation CrowdfundingHousing SafetyInmate Mental HealthStudent OutcomesstrategyMitigated - Single ModelMitigated - Composite ModelUnmitigatedUFigure2:Comparingequity(recalldisparity)andperformance(precisionattopk)metricsfordifferentmodelselectionstrategiesbetweendifferentpolicycontexts.IntheEducationCrowd-fundingcontext,modelsareevaluatedatk=1000across10temporalvalidationcohorts;intheInmateMentalHealthcontext,k=500across10temporalvalidationcohorts;intheStu-dentOutcomescontext,k=10,000across5temporalvalidationcohorts;andintheHousingSafetycontext,k=500across9temporalvalidationcohorts.Unmitigated(baseline)modelsareshownassolidsquaresmarkedwitha‘U’.Decreasesofstrategiesinvolvingdisparitymit-igationsrelativetothey-axisdemonstrateimprovementsinequitywhileshowinglittleornodecreaseinoverallperformance(thatis,leftwardmovementonthex-axis).Errorbarsreﬂect95%conﬁdenceintervalsacrosstemporalvalidationcohorts.19Apr 15Aug 15Dec 15Apr 16Aug 16Dec 16Apr 17Aug 17Dec 17Apr 180.440.460.480.500.520.540.560.580.60Overall Precision at 500UnmitigatedMitigated - Single ModelMitigated - Composite ModelApr 15Aug 15Dec 15Apr 16Aug 16Dec 16Apr 17Aug 17Dec 17Apr 181.01.21.41.61.82.0Recall Disparity: White to BlackApr 15Aug 15Dec 15Apr 16Aug 16Dec 16Apr 17Aug 17Dec 17Apr 18Test Set Date1.01.21.41.61.82.0Recall Disparity: White to HispanicabcFigure3:Comparingdisparityandperformancemetricsovertimefordifferentmodelselectionstrategies.ResultsfromtheInmateMentalHealthpolicysettingusingatotallistsizek=500.(a)Modelperformanceintermsofoverallprecisionattop500.(b)RecalldisparitiesbetweenwhiteandBlackindividuals.(c)RecalldisparitiesbetweenwhiteandHispanicindividuals.202004006008001000Top k List Size1.01.21.41.61.82.0White/Black Disparity2004006008001000Top k List Size1.01.21.41.61.82.0White/Hispanic Disparity2004006008001000Top k List Size0.450.500.550.600.650.70Overall Precision at Top kUnmitigatedMitigated - Single ModelMitigated - Composite Model0.100.150.200.250.300.350.40Resampled Fraction Hispanic1.01.21.41.6White/Hispanic DisparityabcdFigure4:ComparingdisparityandperformancemetricsacrossprogramscaleandprotectedgroupsizeintheInmateMentalHealthpolicysetting.(atoc)Variationinresultsbylistsize:(a)white/Blackdisparities,(b)white/Hispanicdisparities,and(c)overallprecisionattopk.(d)DisparitiesbetweenwhiteandHispanicindividualsbyresampledsizeoftheprotectedgroupintheoverallpopulation(usingalistsizeofk=500).Shadedintervalsreﬂect95%conﬁdenceintervalsfromvariationacrosstemporalvalidationsplits(a-c)aswellasbootstrapsamplesin(d).21References1Chouldechova,A.Fairpredictionwithdisparateimpact:astudyofbiasinrecidivismpredic-tioninstruments.BigData5,153–163(2017).2Skeem,J.L.&Lowenkamp,C.T.Risk,race,andrecidivism:predictivebiasanddisparateimpact.Criminology54,680–712(2016).3Angwin,J.,Larson,J.,Mattu,S.&Kirchner,L.“Machinebias,”ProPublica(23May2016);www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing.4Raghavan,M.,Barocas,S.,Kleinberg,J.&Levy,K.Mitigatingbiasinalgorithmichiring:evaluatingclaimsandpractices.ProceedingsoftheConferenceonFairness,Accountability,andTransparency(ACM,2020),pp.469–481.5Obermeyer,Z.,Powers,B.,Vogeli,C.&Mullainathan,S.Dissectingracialbiasinanalgo-rithmusedtomanagethehealthofpopulations.Science336,447–453(2019).6Ramachandran,A.,etal.PredictiveanalyticsforretentionincareinanurbanHIVclinic.ScientiﬁcReports10.1038/s41598-020-62729-x(2020).7Bauman,M.J.,etal.Reducingincarcerationthroughprioritizedinterventions.ProceedingsoftheConferenceonComputingandSustainableSocieties(COMPASS)(ACM,2018),pp.1–8.8Chouldechova,A.,etal.Acasestudyofalgorithm-assisteddecisionmakinginchildmaltreat-menthotlinescreeningdecisions.ProceedingsofMachineLearningResearch81,134–148(2018).9Potash,E.,etal.Predictivemodelingforpublichealth:preventingchildhoodleadpoisoning.ProceedingsoftheACMSIGKDDInternationalConferenceonKnowledgeDiscoveryandDataMining(ACM,2015),pp.2039–2047.10Chen,I.Y.,Johansson,F.D.&Sontag,D.Whyismyclassiﬁerdiscriminatory?AdvancesinNeuralInformationProcessingSystems31(NIPS,2018),pp.3539–3550.11Celis,L.E.,Huang,L.,Keswani,V.&Vishnoi,N.K.Classiﬁcationwithfairnessconstraints:ameta-algorithmwithprovableguarantees.ProceedingsoftheConferenceonFairness,Ac-countability,andTransparency(ACM,2019),pp.319–328.12Zafar,M.B.,Valera,I.,Rodriguez,M.G.&Gummadi,K.P.Fairnessbeyonddisparatetreatmentanddisparateimpact:learningclassiﬁcationwithoutdisparatemistreatment.26thInternationalWorldWideWebConference(WWW,2017),pp.1171–1180.2213Dwork,C.,Immorlica,N.,Kalai,A.T.&Leiserson,M.Decoupledclassiﬁersforgroup-fairandefﬁcientmachinelearning.ProceedingsofMachineLearningResearch81,119–133(2018).14Hardt,M.,Price,E.&Srebro,N.Equalityofopportunityinsupervisedlearning.AdvancesinNeuralInformationProcessingSystems29(NIPS,2016),pp.3315–3323.15Rodolfa,K.T.,etal.Casestudy:predictivefairnesstoreducemisdemeanorrecidivismthroughsocialserviceinterventions.ProceedingsoftheConferenceonFairness,Account-ability,andTransparency(ACM,2020),pp.142–153.16Heidari,H.,Gummadi,K.P.,Ferrari,C.&Krause,A.Fairnessbehindaveilofignorance:awelfareanalysisforautomateddecisionmaking.AdvancesinNeuralInformationProcessingSystems(NIPS,2018),pp.1265–1276.17Friedler,S.A.,etal.Acomparativestudyoffairness-enhancinginterventionsinmachinelearning.ProceedingsoftheConferenceonFairness,Accountability,andTransparency(ACM,2019),pp.329–338.18Kearns,M.,Roth,A.,Neel,S.&Wu,Z.S.Anempiricalstudyofrichsubgroupfairnessformachinelearning.ProceedingsoftheConferenceonFairness,Accountability,andTrans-parency(ACM,2019),pp.100–109.19Zafar,M.B.,Valera,I.,Rogriguez,M.G.&Gummadi,K.P.Fairnessconstraints:mecha-nismsforfairclassiﬁcation.Proceedingsofthe20thInternationalConferenceonArtiﬁcialIntelligenceandStatistics(PMLR,2017),pp.962–970.20Ghani,R.,Walsh,J.,Wang,J.Top10WaysYourMachineLearningModelsMayHaveLeakage.http://www.rayidghani.com/2020/01/24/top-10-ways-your-machine-learning-models-may-have-leakage/.21Verma,S.&Rubin,J.Fairnessdeﬁnitionsexplained.InternationalWorkshoponSoftwareFairness(IEEE/ACM,2018),pp.1–7.22Gajane,P.&Pechenizkiy,M.OnFormalizingFairnessinPredictionwithMachineLearning.Preprintathttps://arxiv.org/pdf/1710.03184(2018).23Kleinberg,J.M.,Mullainathan,S.&Raghavan,M.InherentTrade-OffsintheFairDetermi-nationofRiskScores.8thInnovationsinTheoreticalComputerScienceConference(ITCS,2017),pp.1–43.24KrishnaMenon,A.&Williamson,R.C.Thecostoffairnessinbinaryclassiﬁcation.Pro-ceedingsofMachineLearningResearch(PMLR,2018),pp.1–12.2325Huq,A.Racialequityinalgorithmiccriminaljustice.DukeLawJournal68,1043–1134(2019).26Hamilton,M.Peoplewithcomplexneedsandthecriminaljusticesystem.CurrentIssuesinCriminalJustice22,307–324(2010).27James,D.J.&Glaze,L.E.“Mentalhealthproblemsofprisonandjailinmates”(DepartmentofJustice,BureauofJusticeStatistics,2006;https://www.bjs.gov/content/pub/pdf/mhppji.pdf)28FullerTorrey,E.,Kennard,A.D.,Eslinger,D.,Lamb,R.&Pavle,J.“Morementallyillpersonsareinjailsandprisonsthanhospitals:asurveyofthestates”(TreatmentAdvocacyCenterandNationalSheriffs’Association,2010;http://tulare.networkofcare.org/library/ﬁnaljailsvhospitalsstudy1.pdf)29Holtzen,H.,Klein,E.G.,Keller,B.&Hood,N.Perceptionsofphysicalinspectionsasatooltoprotecthousingqualityandpromotehealthequity.JournalofHealthCareforthePoorandUnderserved27,549–559(2016).30Klein,E.,Keller,B.,Hood,N.&Holtzen,H.Affordablehousingandhealth:ahealthim-pactassessmentonphysicalinspectionfrequency.JournalofPublicHealthManagementandPractice21,368–374(2015).31Athey,S.Beyondprediction:usingbigdataforpolicyproblems.Science355,483–485(2017).32Glaeser,E.L.,Hillis,A.,Kominers,S.D.&Luca,M.Crowdsourcingcitygovernment:usingtournamentstoimproveinspectionaccuracy.Am.Econ.Rev.106,114–118(2016).33Levin,H.M.&Belﬁeld,C.“Thepricewepay:economicandsocialconsequencesofinade-quateeducation”(BrookingsInstitutionPress,2007).34Atwell,M.N.,Balfanz,R.,Bridgeland,J.&Ingram,E.“Buildingagradnation”(Amer-ica’sPromiseAlliance,2019;https://www.americaspromise.org/2019-building-grad-nation-report)35Lakkaraju,H.,etal.Amachinelearningframeworktoidentifystudentsatriskofadverseaca-demicoutcomes.ProceedingsoftheACMSIGKDDInternationalConferenceonKnowledgeDiscoveryandDataMining(ACM,2015),pp.1909–1918.36Aguiar,E.,etal.Who,when,andwhy:amachinelearningapproachtoprioritizingstudentsatriskofnotgraduatinghighschoolontime.ProceedingsoftheLearningAnalyticsandKnowledgeConference(ACM,2015),pp.93–102.2437Bowers,A.J.,Sprott,R.&Taff,S.A.Doweknowwhowilldropout?Areviewofthepredictorsofdroppingoutofhighschool:precision,sensitivity,andspeciﬁcity.TheHighSchoolJournal96,77–100(2012).38Morgan,I.&Amerikaner,A.“Fundinggaps2018”(TheEducationTrust,2018;https://edtrust.org/wp-content/uploads/2014/09/FundingGapReport2018FINAL.pdf).39Hurza,M.“Whatdoteachersspendonsupplies”(AdoptaClassroom,2015;https://www.adoptaclassroom.org/2015/09/15/infographic-recent-aac-survey-results-on-teacher-spending/).40StatisticsavailablefromDonorsChooseathttps://www.donorschoose.org/about(accessed:23June2020).41Dataavailableathttps://www.kaggle.com/c/kdd-cup-2014-predicting-excitement-at-donors-choose/data(accessed:23June2020).42Roberts,D.R.,etal.Cross-validationstrategiesfordatawithtemporal,spatial,hierarchical,orphylogeneticstructure.Ecography40,913–929(2017).43Ye,T.,etal.UsingmachinelearningtohelpvulnerabletenantsinNewYorkcity.ProceedingsoftheConferenceonComputingandSustainableSocieties(COMPASS)(ACM,2019),pp.248–258.44Rodolfa,K.T.&Lamba,H.dssg/peeps-chili:Releasefortrade-offssubmission.(2021)doi:10.5281/zenodo.5173254.25SupplementaryInformationSupplementaryDiscussionTheresultsdiscussedinthemaintextfocusonpost-hocscoreadjustmentmethods,drawingonseveralpreviouslinesofwork3–5andﬁndsthesestraightforwardmethodssufﬁcetosigniﬁcantlyreducedisparitieswithlittleaccuracytrade-offinthesettingsconsidered.However,wealsodidsomepreliminaryworkexploringanumberofothermethodsthathavebeenproposed,particularlytoenhancefairnessduringthemodelingprocessitself.Inpublicpolicysettingswithlimitedresources,regularizationmethods(suchasthatdescribedbyZafarandcolleagues2)provideaparticularchallenge.Thesetechniquestypicallyseektoﬁndthebestoverallclassiﬁersubjecttosomefairnessconstraint.Thismaybewell-suitedtocontextswheretherearenohardconstraintsontheresourcesavailabletoactonpredictivepositives(forinstance,indecidingwhethertoorderarelativelylow-costmedicaldiagnostictest).However,manyapplications,particularlyinpublicpolicycontexts,aresubjecttothefurtherconstraintoflimitedresources—theseapplicationsarebestformulatedas“top-k”problems,butunfortunatelythisformulationintroducesanon-convexoptimizationthatisnotreadilyin-tegratedintocurrentfairness-constrainedmethods.Likewise,naivelythresholdingtheresultingscorefromthesemethodstoyieldasetnumberofpredictedpositivesprovidesnoguaranteethatthefairnessconstraintswillhold.SupplementaryFig.7providesanexamplewithdatafromtheInmateMentalHealthcontext:usingthemethoddescribedbyZafar2togenerateascorewithafalsenegativeratefairnessconstraint(notethatFNR=1−TPR,sothisconstraintisequivalenttorecallequity)andchoosingthetop500individualsperformsnobetteratbalanc-ingequitythanchoosingthetop500fromanunconstrainedscoreandfarworsethanchoosinggroup-speciﬁcthresholdstobalanceequityasshowninthemaintext.Notably,thisresultisn’tacriticismofZafar’smethodswhenappliedinappropriatecontexts,butratheranindicationofthelimitationsofcurrentfairness-constrainedmethodsintheresource-constrainedsettingwefrequentlyencounterinmachinelearningtosupportpublicpolicydecisionmaking.WealsoexploredthemethodsproposedbyCelis1andMenonandWilliamson,6butnoticedthatbothmethodscouldbeshowntobeequivalenttogroup-speciﬁcscalingorthresholdingofanunderlyingestimateoftherelevantprobabilitydistributionwhenappliedtoasinglefairnessmetricandsub-groupmembershipisknown(notably,themethodproposedbyCelis1seemsquiteﬂexibletobalancingmultiplemetricsorwheregroupmembershipisitselfbeingmod-eledaswell).Forasingle,monotonicmetriclikerecall/equalityofopportunity,therewillSupplementaryInformation1arXiv:2012.02972v3  [cs.LG]  3 Sep 2021beauniquebalancedsolutionofagiventotalsize,soanymethodrelyingonpost-hocscoreadjustmentsshouldyieldsimilarresults.ToseethisinthecontextofthemethoddescribedbyCelisandcolleagues,1wecanstartfromtheirobservationthatanyequitydeﬁnitionbalancingaconfusion-matrixstatisticcanberepresentedinthefollowingform(followingthenotationusedintheirwork):q(i)linf=α(i)0+Pj∈[k]α(i)jP[f=1|Gi,A(i)j]β(i)0+Pj∈[l]β(i)jP[f=1|Gi,B(i)j](1)Here,ireﬂectssubgroupmembership,A(i)jandB(i)jareeventssuchas(Y=1)andα(i)jandβ(i)jareparametersdeﬁnedtorepresentgeneralizedformofequityfunction(likewise,k,l≥0areintegervaluesallowingthefunctiontobewrittenaslinearcombinationofterms).Further,somemetrics(includingrecall(thatis,TPR)asweconsiderinthiswork)canberepresentedwithasimpliﬁedlinearforminwhichβ(i)0=1andβ(i)1=0,giving:q(i)lin=α(i)0+Xj∈[k]α(i)jP[f=1|Gi,A(i)j](2)Inthiscase,theyshowthatfairness-improvedscoreofaninstancebeingclassiﬁedisgivenby:sλ(x)=η(x)−0.5+Xi∈[p]λi Xj∈[k]α(i)jπ(i)jη(i)j(x)!(3)Where,η(x)=P[Y=1|X=x],η(i)j(x)=Pr[Gi,Aij|X=x]andπ(i)j=Pr[Gi,A(i)j],whileλirepresentslangrangianparameters,usedtosolvetheoptimizationproblem.Forrecallspeciﬁcally(deﬁnedasTPR=P[f=1|Gi,Y=1]),thesuminqlinhasasingleterm(j=1),withα(i)0=0,α(i)1=1,A(i)1=(Y=1).Further(andwithoutlossofgenerality),forthecaseinwhichtherearetwosub-groupsoftheprotectedattribute(e.g.,menandwomen),wecanexpandthesumsandrewritetheadjustedscoreas:srecall(x)=P(Y=1|X=x)−0.5+λ0"1P[G0,Y=1]P[G0,Y=1|X]#+λ1"1P[G1,Y=1]P[G1,Y=1|X]#(4)Thisformulationcanbequiteusefulforbalancingrecallequityinthecasewheregroupmembershipisitselfbeinginferred.However,whereweknowG=gforagivenX,wenotethatthiswillpickoutasingletermaseitherP[G1,Y=1|X]=0orP[G0,Y=1|X]=0SupplementaryInformation2(notethatthiswillbetrueifthereweremoresub-groupsaswell,simplyaddingadditionalterms).So,foragivenexampleX,weobtain:srecall(x)=P(Y=1|X=x)−0.5+λg"1P[G=g,Y=1]P[Y=1|X]#(5)Rearrangingleadsto:srecall(x)="1+λgP[G=g,Y=1]#P(Y=1|X)−0.5(6)Asitcanbeseenfromtheaboveequation,1+λg/P[G=g,Y=1]issimplyagroup-speciﬁcconstantwithnodependenceonthevalueofXbeyondgroupmembership.Assuch,thiswillresultinscalingfactorcorrespondingtorescalingofanunderlyingpredictedscoreP(Y=1|X)aroundathreshold,butwithoutreorderingthescorewithinagivensubgroupitself.Further,becauseofthemonotonicallyincreasingnatureofrecallaslistdepthistraversed,therewillbeaunique(uptoexacttiesinthescore)recall-balancingsolutionofagiventotallistsize,regardlessofwhetherthatsolutionisobtainedbysettinggroup-speciﬁcthresholds(asinthemethodwemakeuseofinthecurrentstudy)orgroup-speciﬁcstretchingscoresaroundaﬁxedthreshold(asweseehere),solongasthewithin-grouprankingisnotreordered.SupplementaryInformation3SupplementaryFigure1:Comparingequity(recalldisparity)andperformance(precisionattopk)metricsfordifferentmodelselectionstrategiesbetweendifferentpolicycontexts,asinFig.2,includinganadditionalmodelselectionstrategy(Mitigated-Unadj.ModelSeln.)inwhichmodelspeciﬁcationischosenwithoutregardfordisparitiesthengroup-speciﬁcthresholdsarechosenfortheselectedmodel.Errorbarsreﬂect95%conﬁdenceintervalsacrosstemporalvalidationcohorts.Thisstrategyperformedsimilarlytostrategyaccountingfordisparitiesinthemodelselectionitselfinallpolicysettingsconsidered.SupplementaryInformation4SupplementaryFigure2:Comparingmodelprecision(a)anddisparity(b)metricsovertimefordifferentmodelselectionstrategiesintheHousingSafetypolicycontext.SupplementaryInformation5SupplementaryFigure3:Comparingmodelprecision(a)anddisparity(b)metricsovertimefordifferentmodelselectionstrategiesintheEducationCrowdfundingpolicycontext.SupplementaryInformation6SupplementaryFigure4:Comparingmodelprecision(a)anddisparity(b)metricsovertimefordifferentmodelselectionstrategiesintheStudentOutcomespolicycontext.SupplementaryInformation7SupplementaryFigure5:Fractionoftheselected“top-k”listthatisAfricanAmerican(a)orHispanic(b)bylistsizeintheInmateMentalHealthsetting(seeFig.4a-c).Shadedintervalsreﬂectvariationacrosstemporalvalidationsplits.SupplementaryInformation8SupplementaryFigure6:Precision(a)andwhite-to-Blackdisparities(b)byre-sampledHis-panicfractionfromtheexperimentshowninFig.4d.Shadedintervalsreﬂectvariationacrossbootstrapsamplesandtemporalvalidationsplits.SupplementaryInformation9SupplementaryFigure7:Comparisonofrecalldisparityafterselectingthetop500individualsfromunconstrainedandFalseNegativeRate(FNR)-constrainedmodelsfollowingthemethodsdescribedinZafaretal.ResultsfromtheInmateMentalHealthpolicycontext.SupplementaryInformation10SupplementaryTable1:ModelHyperparameterGridforInmateMenthalHealthPolicySettingEstimatorHyperparamterGridSearchValuesRandomForestClassifiermaxfeaturessqrtcriteriongini,entropynestimators100,1000,5000minsamplessplit10,25,100maxdepth5,10,50ScaledLogisticRegressionpenaltyl1,l2C0.001,0.1,1,10PercentileRankOneFeaturefeatureJailbookingslast1or5yearsSimpleThresholderrulesAnymentalhealthhistory,Jailreleasesinlast:1,3,6months,or1yearlogicaloperatorandSupplementaryInformation11SupplementaryTable2:ModelHyperparameterGridforEducationCrowdfundingPolicySet-tingEstimatorHyperparamterGridSearchValuesDecisionTreeClassifiercriterionginiminsamplessplit2,5,10,100,1000maxdepth1,5,10,20,50,100RandomForestClassifiermaxfeaturessqrtcriteriongini,entropynestimators100,1000,2000,3000minsamplessplit10,50maxdepth10,50,100ExtraTreesClassifiermaxfeatureslog2criterionentropynestimators10,50,1000minsamplessplit5,25,50maxdepth20,50,100ScaledLogisticRegressionpenaltyl1,l2C0.0001,0.001,0.01,0.1,1,10AdaBoostClassifiernestimators500,1000SupplementaryInformation12SupplementaryTable3:ModelHyperparameterGridforHousingSafetyPolicySettingEstimatorHyperparamterGridSearchValuesDecisionTreeClassifiercriteriongini,entropyminsamplessplit10,20,50,100maxdepth1,2,3,5,10,20,50RandomForestClassifiermaxfeaturessqrt,log2criteriongini,entropynestimators100,1000,5000minsamplessplit10,20,50,100maxdepth2,5,10,20,50,100ExtraTreesClassifiermaxfeaturessqrt,log2criteriongini,entropynestimators100,1000,5000minsamplessplit10,20,50,100maxdepth2,5,10,50,100ScaledLogisticRegressionpenaltyl1,l2C0.001,0.01,0.1,1,10PercentileRankOneFeaturefeatureDayssincelastroutineinspectionSupplementaryInformation13SupplementaryTable4:ModelHyperparameterGridforStudentOutcomesPolicySettingEstimatorHyperparamterGridSearchValuesDecisionTreeClassifiercriterionginiminsamplessplit2,5,10,100,1000maxdepth1,5,10,20,50,100RandomForestClassifiermaxfeaturessqrtcriteriongininestimators100,500minsamplessplit2,10classweight˜,balancedsubsample,balancedmaxdepth5,50,100ExtraTreesClassifiermaxfeatureslog2criteriongininestimators100maxdepth5,50ScaledLogisticRegressionpenaltyl1,l2C0.0001,0.001,0.01,0.1,1,10SupplementaryInformation14SupplementaryReferences1Celis,L.E.,Huang,L.,Keswani,V.&Vishnoi,N.K.Classiﬁcationwithfairnessconstraints:ameta-algorithmwithprovableguarantees.ProceedingsoftheConferenceonFairness,Ac-countability,andTransparency(ACM,2019),pp.319–328.2Zafar,M.B.,Valera,I.,Rodriguez,M.G.&Gummadi,K.P.Fairnessbeyonddisparatetreatmentanddisparateimpact:learningclassiﬁcationwithoutdisparatemistreatment.26thInternationalWorldWideWebConference(WWW,2017),pp.1171–1180.3Dwork,C.,Immorlica,N.,Kalai,A.T.&Leiserson,M.Decoupledclassiﬁersforgroup-fairandefﬁcientmachinelearning.ProceedingsofMachineLearningResearch81,119–133(2018).4Hardt,M.,Price,E.&Srebro,N.Equalityofopportunityinsupervisedlearning.AdvancesinNeuralInformationProcessingSystems29(NIPS,2016),pp.3315–3323.5Rodolfa,K.T.,etal.Casestudy:predictivefairnesstoreducemisdemeanorrecidivismthroughsocialserviceinterventions.ProceedingsoftheConferenceonFairness,Account-ability,andTransparency(ACM,2020),pp.142–153.6KrishnaMenon,A.&Williamson,R.C.Thecostoffairnessinbinaryclassiﬁcation.Pro-ceedingsofMachineLearningResearch(PMLR,2018),pp.1–12.SupplementaryInformation15