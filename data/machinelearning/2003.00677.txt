0
2
0
2

r
a

M
4
2

]

O
C
.
h
t
a
m

[

2
v
7
7
6
0
0
.
3
0
0
2
:
v
i
X
r
a

TROPICAL SUPPORT VECTOR MACHINE AND ITS APPLICATIONS TO
PHYLOGENOMICS

BY XIAOXIAN TANG1, HOUJIE WANG2 AND RURIKO YOSHIDA3

1School of Mathematical Sciences, Beihang University, xiaoxian@buaa.edu.cn

2Department of Statistics, Texas A&M University, wanghoujie@tamu.edu

3Department of Operations Research, Naval Postgraduate School, ryoshida@nps.edu

Most data in genome-wide phylogenetic analysis (phylogenomics) is es-
sentially multidimensional, posing a major challenge to human comprehen-
sion and computational analysis. Also, we can not directly apply statistical
learning models in data science to a set of phylogenetic trees since the space
of phylogenetic trees is not Euclidean. In fact, the space of phylogenetic
trees is a tropical Grassmannian in terms of max-plus algebra. Therefore,
to classify multi-locus data sets for phylogenetic analysis, we propose trop-
ical support vector machines (SVMs). Like classical SVMs, a tropical SVM
is a discriminative classiﬁer deﬁned by the tropical hyperplane which max-
imizes the minimum tropical distance from data points to itself in order to
separate these data points into sectors (half-spaces) in the tropical projective
torus. Both hard margin tropical SVMs and soft margin tropical SVMs can
be formulated as linear programming problems. We focus on classifying two
categories of data, and we study a simpler case by assuming the data points
from the same category ideally stay in the same sector of a tropical separat-
ing hyperplane. For hard margin tropical SVMs, we prove the necessary and
sufﬁcient conditions for two categories of data points to be separated, and we
show an explicit formula for the optimal value of the feasible linear program-
ming problem. For soft margin tropical SVMs, we develop novel methods
to compute an optimal tropical separating hyperplane. Computational exper-
iments show our methods work well. We end this paper with open problems.

1. Introduction. Multi-locus data sets in phylogenomics are essentially multidimen-
sional. Thus, we wish to apply tools from data science to analyse how phylogenetic trees
of different genes (loci) are distributed over the space of phylogenetic trees. For example, in
many situations in systematic biology, we wish to classify multi-locus phylogenetic trees over
the space of phylogenetic trees. In order to apply tools from Phylogenomics to multi-locus
data sets, systematists exclusively select alignments of protein or DNA sequences whose
evolutionary histories are congruent to these respective of their species. In order to see how
alignments with such evolutionary events differ from others and to extract important informa-
tion from these alignments, systematists compare sets of multiple phylogenetic trees gener-
ated from different genomic regions to assess concordance or discordance among these trees
across genes [1].

This problem appears not only in analysis on multi-locus phylogenetic data but also assess-
ing convergence of Markov Chain Monte Carlo (MCMC) analyses for the Bayesian inference
on phylogenetic tree reconstruction. When we conduct an MCMC analysis on phylogenetic
tree reconstruction, we run independent multiple chains on the same data and we have to
ensure they converge to the same posterior distribution of trees. Often this process is done by
comparing summary statistics computed from sampled trees, however, naturally computing
a summary statistic from a sample loses information about the sample [11].

Keywords and phrases: Phylogenetic Tree, Phylogenomics, Tropical Geometry, Supervised Learning, Non-

Euclidean Data

1

 
 
 
 
 
 
2

FIG 1. Picture of a hard margin tropical SVM (LEFT) and a soft margin tropical SVM (RIGHT) with two cate-
gories. A hard margin tropical SVM assumes that data points are separated by a tropical hyperplane and a hard
margin tropical SVM maximizes the margin z which is the width of the grey area from the tropical hyperplane in
this ﬁgure. A soft margin tropical SVM maximizes a margin and minimizes the sum of α and β at the same time.

In a Euclidean space, we apply a supervised learning method to classify data points into
different categories. A support vector machine (SVM) is one of the most popular supervised
learning models for classiﬁcation. In a Euclidean space, an SVM is a linear classiﬁer, a hy-
perplane which separates data into half-spaces and maximizes the minimum distances from
data points to the hyperplane. A space of all possible phylogenetic trees with the same set
of labels on their leaves is unfortunately not Euclidean. In addition, this space is a union of
lower dimensional polyhedral cones inside of a Euclidean space [15]. Therefore we cannot
directly apply a classical SVM to a set of phylogenetic trees.

In 2004, Speyer and Sturmfels showed a space of phylogenetic trees with a given set of
labels on their leaves is a tropical Grassmanian [15], which is a tropicalization of a linear
space deﬁned by a set of linear equations [17] with the max-plus algebra. Therefore, in this
paper, we propose applying a tropical SVM to the data sets of phylogenetic trees.

Similar to a classical SVM over a Euclidean space, a hard margin tropical SVM introduced
by [3] is a tropical hyperplane which maximizes the margin, the minimum tropical distance
from data points to the tropical hyperplane (which is z in Figure 1), to separate these data
points into open sectors over a tropical projective torus. Similar to the classical hard margin
SVMs, hard margin tropical SVMs assume that there is a tropical hyperplane which separates
all points from different categories into each open sector (see the left ﬁgure in Figure 1). By
the ideas proposed in [3], we formulate hard margin tropical SVMs as linear programming
problems (see (4)–(7)). Since a hard margin tropical SVM assumes all data points from differ-
ent categories are clearly separated by a tropical hyperplane, we have to check which points
are in which sector. To do so, we have to go through possibly exponentially many linear pro-
gramming problems in terms of the dimension of the data and the sample size of the input
data set. In practice, many of these linear programming problems might be infeasible. Here,
we study a special case when the data points from the same category stay in the same sector
of a separating tropical hyperplane. For this simpler case, we show the necessary and sufﬁ-
cient conditions for each linear programming problem to be feasible and an explicit formula
for the optimal value of a feasible linear programming problem (see Theorems 4.15-4.18).

As a classical SVM, the assumption of a hard margin tropical SVM, such that all data
points from different categories are clearly separated, is not realistic in general. It rarely

H0zH0zαβTROPICAL SUPPORT VECTOR MACHINE

3

happens that all data points from different categories are clearly separated by a tropical hy-
perplane. In a Euclidean space, we use soft margin SVMs if some data points from different
categories are overlapped. In this paper, we introduce soft margin tropical SVMs and show
the soft margin tropical SVMs can be formulated as linear programming problems by adding
slacker variables into the hard margin topical SVMs (see (18)–(21)). We show these linear
programming problems are feasible (see Proposition 4.20), and for proper scalar constants,
the objective functions of these linear programming problems have bounded optimal values
(see Theorem 4.21).

Based on our theorems, we develop algorithms to compute a tropical SVM implemented
in R (see Algorithms 1–4). Finally we apply our methods to simulated data generated by the
multispecies coalescent processes [8]. Computational results show our methods are efﬁcient
in practice and the accuracy rates of soft margin tropical SVMs are much higher than those
of the classical SVMs implemented in the R package e1071 [9] for the simulated data with
a small ratio of the species depth to the population size (see Figure 6).

This paper is organized as follows: In Section 2, we remind readers basics in tropical
geometry with max-plus algebra. In Section 3, we discuss the space of phylogenetic trees
with a ﬁxed set of labels on leaves as a tropical Grassmannian with max-plus algebra. In
Section 4.1, we formulate a hard margin tropical SVM as an optimal solution of a linear
programming problem. When the data points from the same category stay in the same open
sector of a separating tropical hyperplane, we discuss the necessary and sufﬁcient conditions
for data points from different categories to be separated via a tropical hard SVM. In addition,
we show the explicit formulae for the optimal values of feasible linear programing problems.
In Section 4.2, we formulate a soft margin tropical SVM as linear programming problems.
Then we prove properties of soft margin tropical SVMs. In Section 5, we develop algorithms
based on theorems in Section 4.2, and we apply them to simulated data generated under the
multispecies coalescent processes in Section 6. Finally in Section 7, we conclude our results
and propose open problems. The proofs of Theorems 4.15–4.18 are presented in Appendix
A. Our software implemented in R and simulated data can be downloaded at https://
github.com/HoujieWang/Tropical-SVM, see Appendix B.

2. Tropical Basics. Here we review some basics of tropical arithmetic and geometry, as

well as setting up the notation through this paper. For more details, see [6] or [4].

DEFINITION 2.1 (Tropical Arithmetic Operations). Throughout this paper we will per-
form arithmetic in the max-plus tropical semiring ( R ∪ {−∞}, (cid:1), (cid:12)) . In this tropical semir-
ing, the basic tropical arithmetic operations of addition and multiplication are deﬁned as:

a (cid:1) b := max{a, b},

a (cid:12) b := a + b where a, b ∈ R ∪ {−∞}.

Note that −∞ is the identity element under addition and 0 is the identity element under
multiplication.

DEFINITION 2.2 (Tropical Scalar Multiplication and Vector Addition). For any scalars
a, b ∈ R ∪ {−∞} and for any vectors v = (v1, . . . , ve), w = (w1, . . . , we) ∈ (R ∪ −{∞})e,
we deﬁne tropical scalar multiplication and tropical vector addition as follows:

a (cid:12) v := (a + v1, . . . , a + ve),

a (cid:12) v (cid:1) b (cid:12) w := (max{a + v1, b + w1}, . . . , max{a + ve, b + we}).

Throughout this paper we consider the tropical projective torus, that is, the projective
space Re/R1, where 1 := (1, 1, . . . , 1), the all-one vector. In Re/R1, any point (v1, . . . , ve) is
equivalent to (v1 + a, . . . , ve + a) for any scalar a ∈ R.

4

EXAMPLE 2.3. Consider Re/R1. Then let

v = (1, 2, 3), w = (1, 1, 1).

Also let a = −1, b = 3. Then we have
a(cid:12)v (cid:1)b(cid:12)w = (max(−1+1, 3+1), max(−1+2, 3+1), max(−1+3, 3+1)) = (4, 4, 4) = (0, 0, 0).

DEFINITION 2.4 (Generalized Hilbert Projective Metric). For any two points v, w ∈

Re/R1, the tropical distance dtr(v, w) between v and w is deﬁned as:

dtr(v, w) = max

i,j

(cid:8) |vi − wi − vj + wj| : 1 ≤ i < j ≤ e (cid:9) = max

i

(cid:8)vi − wi

(cid:9) − min
i

(cid:8)vi − wi

(cid:9),

where v = (v1, . . . , ve) and w = (w1, . . . , we). This distance measure is a metric in Re/R1.

EXAMPLE 2.5.

Suppose u1, u2 ∈ R3/R1 such that

u1 = (0, 0, 0), u2 = (0, 3, 1).

Then the tropical distance between u1, u2 is

dtr(u1, u2) = max(0, −3, −1) − min(0, −3, −1) = 0 − (−3) = 3.

DEFINITION 2.6 (Tropical Convex Hull). The tropical convex hull or tropical polytope
of a given ﬁnite subset V = {v1, . . . , vs} ⊂ Re/R1 is the smallest tropically-convex subset
containing V ⊂ Re/R1: it is written as the set of all tropical linear combinations of V such
that:

tconv(V ) = {a1 (cid:12) v1 (cid:1) a2 (cid:12) v2 (cid:1) · · · (cid:1) as (cid:12) vs | v1, . . . , vs ∈ V and a1, . . . , as ∈ R}.

A tropical line segment between two points v1, v2 is the tropical convex hull of {v1, v2}.

EXAMPLE 2.7.

Suppose we have a set V = {v1, v2, v3} ⊂ R3/R1 where

v1 = (0, 0, 0), v2 = (0, 3, 1), v3 = (0, 2, 5).

Then we have the tropical convex hull tconv(V ) of V is shown in Figure 2.

3. Phylogenetic Trees. A phylogenetic tree is a tree representation of evolutionary rela-
tionship between taxa. More formally a phylogenetic tree is a weighted tree with unlabeled in-
ternal nodes and labeled leaves. Weights on edges in a phylogenetic tree represent evolution-
ary time multiplied by an evolutionary rate. For more details on evolutionary models on phy-
logenetic trees, see [14]. A phylogenetic tree can be rooted or unrooted. In this paper we focus
on rooted phylogenetic trees. Let N ∈ N be the number of leaves and [N ] := {1, . . . , N } be
the set of labels for leaves.

REMARK 3.1. There exist

(2N − 3)!! = (2N − 3) · (2N − 5) · · · 3 · 1

many binary rooted phylogenetic tree topologies.

EXAMPLE 3.2.

Suppose N = 4. Then there are 15 many different tree topologies for

rooted phylogenetic trees.

TROPICAL SUPPORT VECTOR MACHINE

5

FIG 2. Tropical polytope of three points (0, 0, 0), (0, 3, 1), (0, 2, 5) in R3/R1.

FIG 3. Examples of equidistant trees with 4 leaves and with their height equal to 1.

If a total of weights of all edges in a path from the root to each leaf i ∈ [N ] in a rooted
phylogenetic tree T is the same for all leaves i ∈ [N ], then we call a phylogenetic tree T
equidistant tree. Through this paper we focus on equidistant trees with leaves with labels
[N ]. The height of an equidistant tree is the total weight of all edges in a path from the root
to each leaf in the tree. Through the manuscript we assume that all equidistant trees have the
same height. In phylogenetics this assumption is fairly mild since the multispecies coalescent
model assumes that all gene trees have the same height.

EXAMPLE 3.3.

Suppose N = 4. Rooted phylogenetic trees shown in Figure 3 are

equidistant trees with their height equal to 1.

DEFINITION 3.4 (Dissimilarity Map). A dissimilarity map w is a function w : [N ] ×

[N ] → R≥0 such that

w(i, i) = 0 and w(i, j) = w(j, i) ≥ 0

for every i, j ∈ [N ]. If a dissimilarity map w additionally satisﬁes the triangle inequality,
w(i, j) ≤ w(i, k) + w(k, j) for all i, j, k ∈ [N ], then w is called a metric. If there exists a
phylogenetic tree T such that w(i, j) corresponds a total branch length of the edges in the
unique path from a leaf i to a leaf j for all leaves i, j ∈ [N ], then we call w a tree metric. If
a metric w is a tree metric and w(i, j) corresponds the total branch length of all edges in the
path from a leaf i to a leaf j for all leaves i, j ∈ [N ] in a phylogenetic tree T , then we say w
realises a phylogenetic tree T .

(0, 2, 0)(0, 3, 5)(0, 2, 5)(0, 0, 3)(0, 3, 1)(0, 0, 0)A                 B         C      DA        B      C                  D0.30.10.60.10.90.90.50.50.50.316

In this paper, we interchangeably write wij = w(i, j). Since w is symmetric, i.e., w(i, j) =

w(j, i) and since w(i, j) = 0 if i = j, we write

w = (w(1, 2), w(1, 3), . . . , w(N − 1, N )) .

DEFINITION 3.5 (Three Point Condition).

If a metric w satisﬁes the following condition:

For every distinct leaves i, j, k ∈ [N ],

achieves twice, then we say a metric w satisﬁes the three point condition.

max{w(i, j), w(i, k), w(j, k)}

DEFINITION 3.6 (Ultrametrics).

If a metric w satisﬁes the three point condition then we

call w an ultrametric.

THEOREM 3.7 (Proposition 12 in [10]). A dissimilarity map w : [N ] × [N ] is an ultra-
metric if and only if w is realisable of an equidistant tree with labels [N ]. Also there is
one-to-one relation between an ultrametric w : [N ] × [N ] and an equidistant tree with labels
[N ].

EXAMPLE 3.8. For equidistant trees in Figure 3, the dissimilarity map for the left tree in

Figure 3 is

and the dissimilarity map for the right tree in Figure 3 is

(0.6, 1.8, 2, 1.8, 2, 2),

(0.2, 2, 2, 2, 2, 1).

Note that these dissimilarity maps are tree metrics since these dissimilarity maps are com-
puted from trees and they are also ultrametrics since they satisfy the three point condition.

From Theorem 3.7 we consider the space of ultrametrics with labels [N ] as a space of
all equidistant trees with labels [N ]. Let UN be the space of ultrametrics for the equidistant
trees with leaf labels [N ]. In fact we can write UN as the tropicalization of the linear space
generated by linear equations.

(cid:1), and let LN ⊆ Rd be the linear subspace deﬁned by the linear equations such

Let d := (cid:0)N

2

that

(1)

xij − xik + xjk = 0

for 1 ≤ i < j < k ≤ N . For the linear equations (1) spanning LN , their max-plus tropicaliza-
tion T rop(LN ) is the set of points w such that max {wij, wik, wjk} achieves at least twice
for all i, j, k ∈ [N ] (see e.g., [5]). This is the three point condition deﬁned in Deﬁnition 3.6.

THEOREM 3.9 (Theorem 3 in [17]). The image of UN in the tropical projective torus

Rd/R1 coincides with Trop(LN ), where d = (cid:0)N

(cid:1).

2

EXAMPLE 3.10. For N = 3, then there are three tree topologies for equidistant trees.
The space of ultrametrics U3 corresponding to the equidistant trees with 3 leaves is a union
of polyhedral cones C1, C2, C3 in R3 deﬁned by:

C1 : {(x11, x12, x23)|x11 = x12, x11 ≥ x23, x12 ≥ x13, x11 ≥ 0, x12 ≥ 0, x23 ≥ 0, )} ,
C2 : {(x11, x12, x23)|x11 = x23, x11 ≥ x12, x23 ≥ x12, x11 ≥ 0, x12 ≥ 0, x23 ≥ 0, )} ,
C3 : {(x11, x12, x23)|x12 = x23, x12 ≥ x11, x23 ≥ x11, x11 ≥ 0, x12 ≥ 0, x23 ≥ 0, )} .

C1, C2, C3 are the 1-dimensional cones in R3.

TROPICAL SUPPORT VECTOR MACHINE

7

FIG 4. The tropical hyperplane H0 in R3/R1

4. Tropical SVMs. Since the image of an equidistant tree with labels [N ] under the
dissimilarity map is a point in the tropical projective torus Rd/R1 (see e.g., Example 3.8), in
this section, we consider Rd/R1 and introduce topical SVMs in Rd/R1.

DEFINITION 4.1 (Tropical Hyperplane). For any ω := (ω1, . . . , ωd) ∈ Rd, the tropical

hyperplane deﬁned by ω, denoted by Hω, is the set of points x ∈ Rd/R1 such that

is attained at least twice. We call ω the normal vector of Hω.

max{ω1 + x1, . . . ωd + xd}

DEFINITION 4.2 (Sectors of Tropical Hyperplane). Each tropical hyperplane Hω divides

the tropical projective torus Rd/R1 into n connected components, which are open sectors

ω := { x ∈ Rd/R1 | ωi + xi > ωj + xj, ∀j (cid:54)= i }, i = 1, . . . , d.
Si

Accordingly, we deﬁne closed sectors as

i
ω := { x ∈ Rd/R1 | ωi + xi ≥ ωj + xj, ∀j (cid:54)= i }, i = 1, . . . , d.

S

DEFINITION 4.3 (Tropical Distance to a Tropical Hyperplane). The tropical distance

from a point x ∈ Rd/R1 to a tropical hyperplane Hω is deﬁned as

dtr(x, Hω) := min{dtr(x, y) | y ∈ Hω}.

PROPOSITION 4.4 (Lemma 2.1 in [3]). Let H0 denote the tropical hyperplane deﬁned by
the zero vector 0 ∈ Rd. For any x ∈ Rd/R1, the tropical distance dtr(x, H0) is the difference
between the largest and the second largest coordinate of x.

COROLLARY 4.5 (Corollary 2.3 in [3]). For any ω ∈ Rd, and for any x ∈ Rd/R1, the

tropical distance dtr(x, Hω) is equal to dtr(ω + x, H0).

EXAMPLE 4.6.

Suppose x = (1, 2, 0) ∈ R3/R1. By Proposition 4.4, dtr(x, H0) = 2 −

1 = 1. See x and H0 in Figure 4.

Assume P and Q (P ∩ Q = ∅ and |P | = |Q| = n) are subsets of Rd/R1. Suppose we have
a dataset {(x(1), y1), . . . (x(2n), y2n)}, where x(1), . . . , x(2n) ∈ Rd/R1, and yk is a binomial

H0(1, 2, 0)S01S03S02(0, 0, 0)8

response variable such that if yk = 0, then x(k) ∈ P and if yk = 1, then x(k) ∈ Q. Our goal is
to ﬁnd a tropical hyperplane Hω such that P and Q can be separated by the hyperplane and
the minimum distance from the points in P ∪ Q to the hyperplane Hω can be maximized.
Recall that in Euclidean spaces, two categories of data might be linearly separable (i.e., two
categories can be strictly separated by a hyperplane, see [18, Page 514]) or nonseparable.
So a classical SVM in a Euclidean space has two versions of formulations: hard margin and
soft margin. Similarly, in this section, we discuss two formulations of tropical SVMs: hard
margin (Section 4.1) and soft margin (Section 4.2).

4.1. Hard Margin.

In this section, we introduce hard margin tropical SVMs for classi-
fying two “separable" sets in Rd/R1. First, we formally deﬁne tropically separable sets and
tropical separating hyperplanes in Rd/R1 (see Deifnition 4.7). Similar to linearly separable
data in Euclidean spaces, each point in Rd/R1 from tropically separable sets should stay in
an open sector of a tropical separating hyperplane (see (i) in Deﬁnition 4.7), and any two
points from different categories should stay in different open sectors (see (ii) in Deﬁnition
4.7).

DEFINITION 4.7 (Tropically Separable Sets and Tropical Separating Hyperplane). For

any two ﬁnite sets P and Q in Rd/R1, if there exists ω ∈ Rd such that

(i) for any ξ ∈ P ∪ Q, there exists an index i ∈ {1, . . . , d} such that

for any j ∈ {1, . . . , d}\{i}, ωi + ξi > ωj + ξj, and

(ii) for any p ∈ P , and for any q ∈ Q, we have

argmax
1≤k≤d

{ωk + pk} (cid:54)= argmax
1≤k≤d

{ωk + qk},

then we say P and Q are tropically separable, and we say Hω is a tropical separating hyper-
plane for P and Q.

We introduce hard margin tropical SVMs as follows. Given two ﬁnite and tropically sep-
arable sets P and Q in Rd/R1, assume |P | = |Q| = n > 0 (remark that all our results can be
directly extended when |P | (cid:54)= |Q|). For any ξ ∈ P ∪ Q, we denote by i(ξ) and j(ξ) two in-
dices in terms of ξ, which are integers in the set {1, . . . , d}. We denote the two sets of indices
{i(ξ)|ξ ∈ P ∪ Q} and {j(ξ)|ξ ∈ P ∪ Q} by I and J , respectively. We also assume that

(2)

∀ξ ∈ P ∪ Q, i(ξ) (cid:54)= j(ξ),

and

(3)

∀p ∈ P, ∀q ∈ Q, i(p) (cid:54)= i(q).

We formulate an optimization problem1 for solving the normal vector ω of an optimal tropical
separating hyperplane Hω for P and Q:

max
ω∈Rd

min
ξ∈P ∪Q

{ξi(ξ) + ωi(ξ) − ξj(ξ) − ωj(ξ)}

s.t. ∀ξ ∈ P ∪ Q, ∀l (cid:54)= i(ξ), j(ξ), (ξ + ω)l ≤ (ξ + ω)j(ξ) ≤ (ξ + ω)i(ξ).
By the constraints above we mean that i(ξ) and j(ξ) respectively give the largest and the
second largest coordinate of the vector ξ + ω for each ξ ∈ P ∪ Q (the assumption (2) ensures
these two indices are different), and the object is to maximize the minimum distance

dtr(ξ, Hω) = ξi(ξ) + ωi(ξ) − ξj(ξ) − ωj(ξ).

1Our formulation is modiﬁed from the original formulation proposed in [3, Section 3.1], which computes an
optimal tropical hyperplane through one set of data points in tropical projective spaces. Notice that in their setting,
they are using min-plus algebra while we are using max-plus algebra.

TROPICAL SUPPORT VECTOR MACHINE

9

Note that this optimization problem can be explicitly written as a linear programming prob-
lem (4)–(7) below, where the optimal solution z means the margin of the tropical SVM (i.e.,
the shortest distance from the data point to the tropical separating hyperplane):

(4)

(5)

(6)

(7)

max
z∈R

z

s.t. ∀ξ ∈ P ∪ Q, z + ξj(ξ) + ωj(ξ)−ξi(ξ) − ωi(ξ) ≤ 0,

∀ξ ∈ P ∪ Q, ωj(ξ) − ωi(ξ) ≤ ξi(ξ) − ξj(ξ),

∀ξ ∈ P ∪ Q, ∀l (cid:54)= i(ξ), j(ξ), ωl − ωj(ξ) ≤ ξj(ξ) − ξl.

REMARK 4.8.

It is straightforward to see (5) and (6) imply that the maximum z must
be non-negative. So, we do not add the constraint z ≥ 0 into the above linear programing
problem.

DEFINITION 4.9 (Feasibility and Optimal Solution (hard margin)).

Suppose we have
two sets P and Q in Rd/R1, and assume sets of indices I := {i(ξ)|ξ ∈ P ∪ Q} and
J := {j(ξ)|ξ ∈ P ∪ Q} satisfy the conditions (2)–(3). If there exists (z; ω) ∈ Rd+1 such that
the inequalities (5)–(7) hold, then we say (z; ω) ∈ Rd+1 is a feasible solution to the linear
programming problem (4)–(7) , and we say P and Q are feasible with respect to (w.r.t.) I and
J . If (z; ω) ∈ Rd+1 is a feasible solution such that the objective function in (4) reaches its
maximum value, then we say (z; ω) is an optimal solution to the linear programming problem.

Note that if P and Q are not tropically separable, then they might not be feasilbe w.r.t. any
sets of indices I and J . On the other hand, if P and Q are tropically separable, Theorem
4.10 below ensures that they are feasible w.r.t. some I and J , which also explains why the
hard margin tropical SVMs we propose here are indeed the analogies of hard margin SVMs
in Euclidean spaces.

THEOREM 4.10.

If two ﬁnite sets P and Q in Rd/R1 are tropically separable, then there
exist ω ∈ Rd and two sets of indices I := {i(ξ)|ξ ∈ P ∪ Q} and J := {j(ξ)|ξ ∈ P ∪ Q}
such that the constraints (2)–(3) and (5)–(7) are satisﬁed. More than that, if (z∗; ω∗) is an
optimal solution to (4)–(7) w.r.t. I and J , then the margin z∗ (i.e., the optimal value of (4))
is positive, and Hω∗ is a separating tropical hyperplane for P and Q.

PROOF. In fact, by Deﬁnition 4.7, there exist indices I and J and a tropical separating
hyperplane Hω such that (2)–(3) and (5)–(7) are satisﬁed. The condition (i) in Deﬁnition
4.7 ensures that the distance dtr(ξ, Hω) is nonzero for any ξ ∈ P ∪ Q, and hence, the value
of z corresponding to ω (i.e., the minimum distance from the points in P ∪ Q to Hω) is
positive. If (z∗; ω∗) is an optimal solution w.r.t. I and J , then z∗ ≥ z > 0. Note (z∗; ω∗) is
also a feasible solution, so (5)–(7) also hold for ω∗ w.r.t. I and J . So, the condition (i) in
Deﬁnition 4.7 holds for ω∗. By (3), any two points p and q from different sets will be located
i(q)
in different open sectors S
ω∗ . So, the the condition (ii) in Deﬁnition 4.7 is also
satisﬁed for ω∗. Therefore, Hω∗ is a separating tropical hyperplane for P and Q.

i(p)
ω∗ and S

EXAMPLE 4.11. Here we demonstrate how to formulate the linear programming (4)–(7)
for a pair of tropically separable sets P and Q. Suppose we have four trees (with four leaves
each) shown in Figure 5, which form two categories P = {p(1), p(2)} and Q = {q(1), q(2)}.
The corresponding ultrametrics are

p(1) : (4, 10, 20, 10, 20, 20), p(2) : (8, 16, 20, 16, 20, 20)
q(1) : (2, 20, 20, 20, 20, 10), q(2) : (6, 20, 20, 20, 20, 18).

10

FIG 5. Four trees in Example 4.11.

Here, for k = 1, 2, we set i(p(k)) = 5, j(p(k)) = 6, i(q(k)) = 4 and j(q(k)) = 2. The linear
programming (4)–(7) becomes the following:

max
z∈R

s.t.

z + 20 + ω6 − 20 − ω5 ≤ 0, z + 20 + ω6 − 20 − ω5 ≤ 0, z + 20 + ω2 − 20 − ω4 ≤ 0, z + 20 + ω2 − 20 − ω4 ≤ 0,

ω6 − ω5 ≤ 20 − 20,
ω1 − ω6 ≤ 20 − 4,
ω2 − ω6 ≤ 20 − 10,
ω3 − ω6 ≤ 20 − 20,
ω4 − ω6 ≤ 20 − 10,

ω6 − ω5 ≤ 20 − 20,
ω1 − ω6 ≤ 20 − 8,
ω2 − ω6 ≤ 20 − 16,
ω3 − ω6 ≤ 20 − 20,
ω4 − ω6 ≤ 20 − 16,

ω2 − ω4 ≤ 20 − 20,
ω1 − ω2 ≤ 20 − 2,
ω3 − ω2 ≤ 20 − 20,
ω5 − ω2 ≤ 20 − 20,
ω6 − ω2 ≤ 20 − 10,

ω2 − ω4 ≤ 20 − 20,
ω1 − ω2 ≤ 20 − 6,
ω3 − ω2 ≤ 20 − 20,
ω5 − ω2 ≤ 20 − 20,
ω6 − ω2 ≤ 20 − 18.

By solving this linear programming via the lpSolve package in R [2], we would obtain
the optimal solution (z∗; ω∗), where z∗ = 2 and ω∗ = (0, 2, 0, 4, 2, 0). It is straightforward to
check that points in P and Q are located in the open sectors S5

ω∗ , respectively.

ω∗ and S4

EXAMPLE 4.12. The sets P and Q in Example 4.11 might not be feasible w.r.t. some sets

of indices I and J . For instance, if we replace the indices in Example 4.11 with

i(p(k)) = 5, j(p(k)) = 6, i(q(k)) = 4 and j(q(k)) = 2 (k = 1, 2),

then the linear programming will have no feasible solution.

REMARK 4.13. Example 4.11 and Example 4.12 show that even tropically separable
sets P and Q might not be feasible for some sets of indices I and J . Theorem 4.10 shows
feasible sets of indices must exist for two tropically separable sets (for instance, the sets P
and Q in 4.11 are feasible w.r.t. the indices shown in that example). But Theorem 4.10 does
not say how to ﬁnd I and J such that P and Q are feasible w.r.t. I and J . In general, in
order to ﬁnd the feasible indices, we need go over all possible choices for those indices. That
means we need to solve d2n(d − 1)2n linear programming problems in d + 1 variables with
dn constraints (recall that d = (cid:0)N
(cid:1), where N is the number of leaves, and recall that n is the
cardinality of P and Q).

2

In order to avoid computations on the non-feasible cases, we would like to ask under what
conditions (tropically separable) sets P and Q will be feasible w.r.t. two sets of indices I and

A                 B         C      DA                 B         C      D22355104448210A        B      C                  DA        B      C                  D551159991337P1P2Q1Q2TROPICAL SUPPORT VECTOR MACHINE

11

J ? In the rest of this section, we answer this question when for all p ∈ P , i(p) and j(p) are
constants, say iP and jP and for all q ∈ Q, i(q) and j(q) are constants, say iQ and jQ (as
what has been shown in Example 4.11). Geometrically, this means that the data points in P
and those in Q will respectively stay in the same sector determined by a tropical separating
hyperplane. Notice that if the four indices iP , jP , iQ and jQ satisfy the assumptions (2)–(3)
(i.e. iP (cid:54)= jP , iQ (cid:54)= jQ and iP (cid:54)= iQ), then there are four cases:

(Case 1). the four indices iP , jP , iQ and jQ are pairwise distinct;
(Case 2). iP = jQ and iQ (cid:54)= jP , or, iQ = jP and iP (cid:54)= jQ;
(Case 3). iP = jQ and iQ = jP ;
(Case 4). jQ = jP .

For each case above, we provide a sufﬁcient and necessary condition for the feasibility of
the sets P and Q, and an explicit formula for the optimal value z. See Theorems 4.15–4.18.
We present the proofs in Appendix. If the given sets are not tropically separable (it indeed
happens a lot in practice), then we should apply the soft margin SVMs discussed in Section
4.2.

REMARK 4.14. Remark that in Theorems 4.15–4.18, we do not require P and Q to be

tropically separable.

THEOREM 4.15.

Suppose P and Q are two ﬁnite sets in Rd/R1. For all p ∈ P , assume
i(p) and j(p) are constants, say iP and jP . For all q ∈ Q, assume i(q) and j(q) are constants,
say iQ and jQ. If the four numbers iP , jP , iQ and jQ are pairwise distinct, then the linear
programming (4)–(7) has a feasible solution if and only if

(8)

max{−F, −A − E} ≤ min{D + B, C}.

If a feasible solution exists, then the optimal value z is given by

(9)

where

(10)

min { A + C + E, D + B + F,

1
2

(A + B + D + E) },

A = min
p∈P
B = min
p∈P

{piP − pjP }, C = min
p∈P
{pjP − piQ}, D = min
q∈Q

{pjP − pjQ}, E = min
q∈Q
{qiQ − qjQ}, F = min
q∈Q

{qjQ − qiP },

{qjQ − qjP }.

THEOREM 4.16.

Suppose P and Q are two ﬁnite sets in Rd/R1. For all p ∈ P , assume
i(p) and j(p) are constants, say iP and jP . For all q ∈ Q, assume i(q) and j(p) are constants,
say iQ and jQ.

(i) If iP = jQ and iQ (cid:54)= jP , then linear programming (4)–(7) has a feasible solution if and
only if

(11)

A + B + C ≥ 0.

If a feasible solution exists, then the optimal value z is given by

min { A + B + C,

(cid:0)A(cid:48) + B + C(cid:1)},

1
2

where

A(cid:48) = min
p∈P
B = min
p∈P

{piP − pjP }, A = min
ξ∈P ∪Q
{pjP − piQ}, C = min
q∈Q

{ξiP − ξjP },

{qiQ − qiP }.

12

(ii) If iQ = jP and iP (cid:54)= jQ, then linear programming (4)–(7) has a feasible solution if and
only if

(12)

A + B + C ≥ 0.

If a feasible solution exists, then the optimal value z is given by

min { A + B + C,

(cid:0)A(cid:48) + B + C(cid:1) },

1
2

where

A(cid:48) = min
q∈Q
B = min
q∈Q

{qiQ − qjQ}, A = min
ξ∈P ∪Q
{qjQ − qiP }, C = min
p∈P

{ξiQ − ξjQ},

{piP − piQ}.

THEOREM 4.17.

Suppose P and Q are two ﬁnite sets in Rd/R1. If for all p ∈ P , we have
i(p) = j(q) = k1, and for all q ∈ Q, i(q) = j(p) = k2, then the linear programming (4)–(7)
has a feasible solution if and only if

(13)

max
p∈P

{pk2 − pk1} ≤ min
q∈Q

{qk2 − qk1}

If a feasible solution exists, then the optimal value z is given by

(14)

1
2

(min
p∈P

{pk1 − pk2} + min
q∈Q

{qk2 − qk1})

THEOREM 4.18.

Suppose P and Q are two ﬁnite sets in Rd/R1. If for all p ∈ P and
for all q ∈ Q, the indices i(p) and i(q) are respectively constants, say iP and iQ, and for
all ξ ∈ P ∪ Q, j(ξ) is a constant, say j, then the linear programming (4)–(7) has a feasible
solution if and only if

(15)

and

(16)

max
q∈Q

{qiP − qj} ≤ min
p∈P

{piP − pj}

max
p∈P

{piQ − pj} ≤ min
q∈Q

{qiQ − qj}.

If a feasible solution exists, then the optimal value z is given by

(17)

min{ min
p∈P

{piP − pj} + min
q∈Q

{qj − qiP }, min
q∈Q

{qiQ − qj} + min
p∈P

{pj − piQ} }.

4.2. Soft Margin. We introduce a tropical soft margin SVM in (18)–(22) by adding non-
negative slacker variables αξ, βξ and γξ,l into each constraint in the hard margin tropical
SVM (4)–(7).

max
(z;α;β;γ)∈R2dn+1

z − C



αξ + βξ +



γξ,l



(cid:88)

l(cid:54)=i(ξ),j(ξ)

(cid:88)

ξ∈P ∪Q

s.t. ∀ξ ∈ P ∪ Q, z + ξj(ξ) + ωj(ξ)−ξi(ξ) − ωi(ξ) ≤ αξ,

∀ξ ∈ P ∪ Q, ωj(ξ) − ωi(ξ) ≤ ξi(ξ) − ξj(ξ) + βξ,

∀ξ ∈ P ∪ Q, ∀l (cid:54)= i(ξ), j(ξ), ωl − ωj(ξ) ≤ ξj(ξ) − ξl + γξ,l,

∀ξ ∈ P ∪ Q, ∀l (cid:54)= i(ξ), j(ξ), αξ ≥ 0, βξ ≥ 0, γξ,l ≥ 0, and z ≥ 0,

(18)

(19)

(20)

(21)

(22)

TROPICAL SUPPORT VECTOR MACHINE

13

where n = |P | = |Q|, the term (cid:80)

(cid:32)

αξ + βξ + (cid:80)

(cid:33)

γξ,l

gives the Hinge loss (i.e., a

ξ∈P ∪Q

l(cid:54)=i(ξ),j(ξ)

linear estimate of the deviation from the tropically separable case), and C is a positive scalar
that controls the trade-off between maximizing the margin z or minimizing the loss (see e.g.,
[18, Page 524, Formula (21.24)]).

DEFINITION 4.19 (Feasibility and Optimal Solution (soft margin)).

Suppose we have
two sets P and Q in Rd/R1 (n = |P | = |Q|), and assume two sets of indices I :=
{i(ξ)|ξ ∈ P ∪ Q} and J := {j(ξ)|ξ ∈ P ∪ Q} satisfy the conditions (2)–(3). If there
exists (z; α; β; γ; ω) ∈ R2dn+d+1 such that the inequalities (19)–(22) hold, then we say
(z; α; β; γ; ω) is a feasible solution to the linear programming (19)–(22). If (z; α; β; γ; ω) ∈
R2dn+d+1 is a feasible solution such that the objective function in (19) reaches its maximum
value, then we say (z; α; β; γ; ω) is an optimal solution to the linear programming problem.

PROPOSITION 4.20. Given two sets P and Q in Rd/R1 (n = |P | = |Q|), assume two
sets of indices I and J satisfy the conditions (2)–(3). Then, the linear programming (18)–
(22) has inﬁnitely many feasible solutions.

PROOF. In fact, for any ω∗ ∈ Rn, let z∗ = 0, and let
(cid:16)

(cid:17)

ξ = β∗
α∗

ξ = max{0,

j(ξ) − ω∗
ω∗

i(ξ)

− (cid:0)ξi(ξ) − ξj(ξ)

(cid:1)}, for any ξ ∈ P ∪ Q,

γ∗
ξ,l = max{0,

(cid:16)

l − ω∗
ω∗

j(ξ)

(cid:17)

− (cid:0)ξj(ξ) − ξl

(cid:1)}, for any ξ ∈ P ∪ Q, for any l (cid:54)= i(ξ), j(ξ).

It is straightforward to check that (z∗; α∗; β∗; γ∗; ω∗) ∈ R2dn+d+1 satisﬁes the inequalities
(19)–(22).

THEOREM 4.21. Given two ﬁnite sets P and Q in Rd/R1 (n = |P | = |Q|), assume two
sets of indices I and J satisfy the conditions (2)–(3). If both P and Q are non-empty, and if
C ≥ 1, then the objective function in the linear programming (18)–(22) is upper bounded for
any feasible solution (z; α; β; γ; ω) ∈ R2dn+d+1, which means the maximum of the objective
function is a ﬁnite real number.

PROOF. Since both P and Q are non-empty, pick p and q from P and Q respectively. By
the assumptions (2)–(3), we know i(p) (cid:54)= j(p), i(q) (cid:54)= j(q), and i(p) (cid:54)= i(q). Below, we prove
the conclusion for the two cases: i(p) (cid:54)= j(q) and i(p) = j(q).

(Case A). If i(p) (cid:54)= j(q), then by (21), we have

(23)

ωi(p) − ωj(q) ≤ qj(q) − qi(p) + γq,i(p).

(Case A.1). If j(q) = j(p), then (23) becomes

(24)

ωi(p) − ωj(p) ≤ qj(p) − qi(p) + γq,i(p).

Then, by (19) and (24),

z ≤ pi(p) − pj(p) + qj(p) − qi(p) + γq,i(p) + αp.

So, if C ≥ 1, then we have an upper bound for the objective function





(cid:88)

z − C

αξ + βξ +

(cid:88)

ξ∈P ∪Q

l(cid:54)=i(ξ),j(ξ)

γξ,l

 ≤ z − αp − γq,i(p) ≤ pi(p) − pj(p) + qj(p) − qi(p).

14

(Case A.2). If j(q) (cid:54)= j(p), then by (21), we have

(25)

ωj(q) − ωj(p) ≤ pj(p) − pj(q) + γp,j(q).

By summing up (23) and (25), we have

(26)

ωi(p) − ωj(p) ≤ qj(q) − qi(p) + γq,i(p) + pj(p) − pj(q) + γp,j(q).

So if C ≥ 1, then by (19) and (26), we have an upper bound for the objective function

(cid:88)

z −C

ξ∈P ∪Q



αξ + βξ +

(cid:88)

l(cid:54)=i(ξ),j(ξ)



γξ,l

 ≤ z −αp −γq,i(p) −γp,j(q) ≤ qj(q) −qi(p) +pi(p) −pj(q).

(Case B). If i(p) = j(q), then by (19),

(27)

ωi(p) − ωi(q) ≤ qi(q) − qi(p) + αq.

(Case B.1). If i(q) = j(p), then (27) becomes

(28)

ωi(p) − ωj(p) ≤ qj(p) − qi(p) + αq.

So if C ≥ 1, then by (19) and (28), we have an upper bound for the objective function




(cid:88)

z − C

αξ + βξ +

(cid:88)

ξ∈P ∪Q

l(cid:54)=i(ξ),j(ξ)

γξ,l

 ≤ z − αq − αp ≤ qj(p) − qi(p) + pi(p) − pj(p).

(Case B.2). If i(q) (cid:54)= j(p),then by (21), we have

(29)

ωi(q) − ωj(p) ≤ pj(p) − pi(q) + γp,i(q).

By summing up (27) and (29),

(30)

ωi(p) − ωj(p) ≤ qi(q) − qi(p) + αq + pj(p) − pi(q) + γp,i(q).

So if C ≥ 1, then by (19) and (30), we have an upper bound for the objective function





(cid:88)

z − C

αξ + βξ +

(cid:88)

ξ∈P ∪Q

l(cid:54)=i(ξ),j(ξ)

γξ,l

 ≤ z − αq − αp − γp,i(q) ≤ qi(q) − qi(p) + pi(p) − pi(q).

REMARK 4.22. Although we have assumed from the every beginning that |P | = |Q|, it is
easily seen that Theorem 4.21 still holds if |P | (cid:54)= |Q|. We emphasize the hypothesis “both P
and Q are non-empty" in Theorem 4.21 because if one of P and Q is empty, then the objective
function in the linear programming (18)–(22) might not be upper bounded for C ≥ 1. For
instance, if P = {p} where p = (5, 5, 4, 3, 2, 1) with i(p) = 1 and j(p) = 2, and if Q is empty,
then it is directly to check that the objective function is not upper bounded. However, the sets
P and Q associated with a real dataset should be both non-empty.

REMARK 4.23. We remark that if the assumption C ≥ 1 in Theorem 4.21 is not satisﬁed,
then the objective function in the linear programming (18)–(22) might not be upper bounded.
And, for C < 1, it is also possible for the objective function to be upper bounded. For instance,
for one pair of simulated sets P and Q we have tested (see “unbounded.RData" in Table 2),
the objective function is not upper bounded when C < 0.00625, and it is upper bounded when
C ≥ 0.00625.

TROPICAL SUPPORT VECTOR MACHINE

15

REMARK 4.24.

Similarly to the hard margin tropical SVMs, for ﬁxed sets of indices
I and J , we can get an optimal tropical hyperplane Hω for these indices by solving the
linear programming problem (18)–(22). In general, if we go over all possible choices for
these indices, then we will get d2n(d − 1)2n linear programming problems in 2dn + d + 1
variables with 3dn + 1 constraints.

In order to save computational time, we again consider the simpler case discussed in Sec-
tion 4.1. We assume for all p ∈ P , i(p) and j(p) are constants, say iP and jP and for all
q ∈ Q, i(q) and j(q) are constants, say iQ and jQ. In this case, it is possible for us to simplify
(18)–(22) by removing the slacker variables γξ,l for l (cid:54)= iP , jP , iQ, jQ, see Proposition 4.25.

PROPOSITION 4.25. For all p ∈ P , assume i(p) and j(p) are constants, say iP and jP .
For all q ∈ Q, assume i(q) and j(q) are constants, say iQ and jQ. If (z∗; α∗; β∗; γ∗; ω∗) is
an optimal solution to the linear programming (18)–(22), then for any l (cid:54)= iP , jP , iQ, jQ, we
have γ∗

ξ,l = 0 for all ξ ∈ P ∪ Q.

PROOF. Assume that there exists ˜l (cid:54)= iP , jP , iQ, jQ such that γ∗
ξ,˜l

By (21),

> 0 for some ξ ∈ P ∪ Q.

− ω∗

j(ξ) ≤ ξj(ξ) − ξ˜l + γ∗
ξ,˜l.

ω∗
˜l
= 0. We replace the coordinates ω∗
˜l

= ω∗
˜l

− γ∗
ξ,˜l

Let ˆω∗
of the vector
˜l
(z∗; α∗; β∗; γ∗; ω∗) with ˆω∗
, and we call the resulting vector (z∗; α∗; β∗; ˆγ∗; ˆω∗).
˜l
Then (z∗; α∗; β∗; ˆγ∗; ˆω∗) is still a feasible solution, for which the objective function has the
value

, and let ˆγ∗
ξ,˜l
and ˆγ∗
ξ,˜l

and γ∗
ξ,˜l

z∗ −C

(cid:88)

ξ∈P ∪Q


α∗

ξ + β∗

ξ +

(cid:88)

γ∗
ξ,l

l(cid:54)=i(ξ),j(ξ)


+γ∗

ξ,˜l > z∗ −C

(cid:88)

ξ∈P ∪Q


α∗

ξ + β∗

ξ +



γ∗
ξ,l

 .

(cid:88)

l(cid:54)=i(ξ),j(ξ)

That means (z∗; α∗; β∗; ˆγ∗; ˆω∗) gives a larger function value to the objective function,
which is a contradiction to the fact that the objective function reaches its maximum at
(z∗; α∗; β∗; γ∗; ω∗).

COROLLARY 4.26. For all p ∈ P , assume i(p) and j(p) are constants, say iP and jP .
For all q ∈ Q, assume i(q) and j(q) are constants, say iQ and jQ. Then any point in P is
jP
ω∗ , and any point in Q is located in the closed sector
located in the closed sector S
S

jQ
ω∗ of an optimal tropical hyperplane Hω∗ .

iQ
ω∗ or in S

iP
ω∗ or in S

PROOF. Suppose (z∗; α∗; β∗; γ∗; ω∗) is a feasible solution to the linear programming
(18)–(22) such that the objective function reaches its maximum. By Proposition 4.25, for
any p ∈ P , we have

ω∗
l − ω∗
jP

≤ pjP − pl ⇔ (p + ω∗)l ≤ (p + ω∗)jP ,

for any l (cid:54)= iP , jP . Then the maximum coordinate of vector p + ω∗ can be indexed by iP or
jP
jP . So, any point in P is located in the closed sector S
ω∗ . Similarly, we can show
that any point in Q is located in the closed sector S

iP
ω∗ or in S
jQ
ω∗ .

iQ
ω∗ or in S

Below, for the four cases (Case 1)–(Case 4) list in Section 4.1, we respectively simplify
(18)–(22) as four linear programing problems (LP 1)-(LP 4) (for (Case 2), we only show the

16

simpliﬁed linear programming problem for iP = jQ and iQ (cid:54)= jP ). Notice that we remove the
slacker variables γξ,l for l (cid:54)= iP , jP , iQ, jQ by Proposition 4.25. Also, by Theorem 4.21, we
set C = 1 for making sure these linear programming problems have bounded optimal values.

max
(z;α;β;γ)∈R8n+1

≥0

z −

(cid:88)

(cid:0)αξ + βξ

(cid:1)

ξ∈P ∪Q

(cid:88)

−

γp,l −

(cid:88)

γq,l

p∈P, l=iQ,jQ

q∈Q, l=iP ,jP

max
(z;α;β;γ)∈R6n+1

≥0

z −

(cid:88)

(cid:0)αξ + βξ

(cid:1)

ξ∈P ∪Q

−

(cid:88)

p∈P

γp,iQ −

(cid:88)

q∈Q

γq,jP

s.t. ∀p ∈ P, z + pjP + ωjP −piP − ωiP ≤ αp,

s.t. ∀p ∈ P, z + pjP + ωjP −piP − ωiP ≤ αp,

ωjP − ωiP ≤ piP − pjP + βp,

ωiQ − ωjP ≤ pjP − piQ + γp,iQ ,

ωjQ − ωjP ≤ pjP − pjQ + γp,jQ ,

ωl − ωjP ≤ pjP − pl

(∀l (cid:54)= iP , jP , iQ, jQ),

ωjP − ωiP ≤ piP − pjP + βp,

ωiQ − ωjP ≤ pjP − piQ + γp,iQ ,

ωl − ωjP ≤ pjP − pl

(∀l (cid:54)= iP , jP , iQ),

∀q ∈ Q, z + qjQ + ωjQ −qiQ − ωiQ ≤ αq,

∀q ∈ Q, z + qjQ + ωjQ −qiQ − ωiQ ≤ αq,

ωjQ − ωiQ ≤ qiQ − qjQ + βq,

ωiP − ωjQ ≤ qjQ − qiP + γq,iP ,

ωjP − ωjQ ≤ qjQ − qjP + γq,jP ,

ωl − ωjQ ≤ qjQ − ql

ωjQ − ωiQ ≤ qiQ − qjQ + βq,

ωjP − ωjQ ≤ qjQ − qjP + γq,jP ,

ωl − ωjQ ≤ qjQ − ql

(∀l (cid:54)= iP , jP , iQ).

(LP 1)

(∀l (cid:54)= iP , jP , iQ, jQ).

(LP 2)

max
(z;α;β)∈R4n+1

≥0

z −

(cid:88)

(cid:0)αξ + βξ

(cid:1)

ξ∈P ∪Q

max
(z;α;β;γ)∈R6n+1

≥0

z −

(cid:88)

(cid:0)αξ + βξ

(cid:1)

ξ∈P ∪Q

−

(cid:88)

p∈P

γp,iQ −

(cid:88)

q∈Q

γq,iP

s.t. ∀p ∈ P, z + pk2 + ωk2 −pk1 − ωk1 ≤ αp,

s.t. ∀p ∈ P, z + pjP + ωjP −piP − ωiP ≤ αp,

ωk2 − ωk1 ≤ pk1 − pk2 + βp,

ωl − ωk2 ≤ pk2 − pl

(∀l (cid:54)= k1, k2),

∀q ∈ Q, z + qk1 + ωk1 −qk2 − ωk2 ≤ αq,

ωk1 − ωk2 ≤ qk2 − qk1 + βq,

ωl − ωk1 ≤ qk1 − ql

(∀l (cid:54)= k1, k2).

(LP 3)

ωjP − ωiP ≤ piP − pjP + βp,

ωiQ − ωj ≤ pj − piQ + γp,iQ ,

ωl − ωj ≤ pj − pl

(∀l (cid:54)= iP , j, iQ),

∀q ∈ Q, z + qjQ + ωjQ −qiQ − ωiQ ≤ αq,

ωjQ − ωiQ ≤ qiQ − qjQ + βq,

ωiP − ωj ≤ qj − qiP + γq,iP ,

ωl − ωj ≤ qj − ql

(LP 4)

(∀l (cid:54)= iP , j, iQ).

5. Algorithms.

In this section, we develop Algorithms 1–4 according to the simpliﬁed
linear programmings (LP 1)–(LP 4) respectively for computing an optimal tropical hyper-
plane, which separates two categories of phylogenetic trees. More details on the performance
of these algorithms can be found in Section 6.

Brieﬂy, the input of each algorithm includes a pair of sets P and Q (P ∩ Q = ∅ and
|P | = |Q| = n), a test set T and indices iP , jP , iQ, jQ for formulating the corresponding

TROPICAL SUPPORT VECTOR MACHINE

17

linear programming. As what has been deﬁned in Section 4, the sets P and Q are associated
with a training dataset {(x(1), y1), . . . , (x(2n), y2n)} ⊂ Rd/R1 × {0, 1} such that if yk = 0,
then x(k) ∈ P and if yk = 1, then x(k) ∈ Q. Here, in these algorithms, we simply call P and
Q training sets. The test set T is a ﬁnite subset of Rd/R1. The indices iP , jP , iQ, jQ are all
from {1, . . . , d} and they satisfy iP (cid:54)= jP , iQ (cid:54)= jQ, and iP (cid:54)= iQ. There are two main steps in
each algorihm:
Step 1. In Algorithms 1–4, for the input sets P and Q and indices iP , jP , iQ, jQ, we solve
the corresponding linear programming ((LP 1)–(LP 4) respectively) and obtain the normal
vector ω of an optimal tropical hyperplane, which separates the two categories of data P and
Q.
Step 2. After that, for each point t from the test set T , we add t into the set ˜P or ˜Q (that
means we classify the point t as the category P or Q) according to which sector of Hω the
point t is located in. As a result, the test set T will be divided into two subsets ˜P and ˜Q, and
the output of each algorithm is the optimal normal vector ω and a partition of the test set: ˜P
and ˜Q.

Below, we give more details for the above Step 2. The key of this step is to decide which
category a point t from the test set should go once we have the optimal Hω solved from the
linear programming. The point t might be located in a closed sector, or on an intersection of
many different closed sectors of Hω (in comparison, for a soft margin classical SVM, a point
from the test set might be simply in one of two open half-spaces determined by an optimal
hyperplane, or on the hyperplane). Remark that for a tropical hyperplane in Rd/R1, there are
d closed sectors and 2d − d − 1 possible intersections of different closed sectors. So far, we do
not prove any criteria on how to classify a point according to its location. Here, according to
substantial experiments on simulated data generated by the multispecies coalescent process,
we propose an effective strategy in Algorithms 1–4 as follows. Since our input training data
P and Q are generated by the multispecies coalescent process, we also input two numbers C
and η to these algorithms, where C denotes the ratio of the depth of the species tree to the
effective population size in the multispecies coalescent process (see (31) in Section 6), and
η is a threshold (experiments show that a real number between 4 and 5 is a good choice for
η). In each algorithm, for the input data P and Q, we provide two ways to classify a point
from the test set according to the relative values of C and η. For instance, in Algorithm 3,
the variable I ∗ in Line 6 has 4 possible values: {k1, k2}, {k1}, {k2}, or ∅. That respectively
k2
means the current point t ∈ T read by Line 4 is located on the intersection of S
ω ,
k1
ω , or other cases. When the input C is
in the difference S
not larger than the input η, we apply one method to classify t (see Lines 8–9), and when C
is larger than η, we apply another method (see Lines 11–12). The other three algorithms are
similarly designed. Experimental results show that our algorithms give good accuracy rate
for random simulated data (see Figure 6 in Section 6).

k2
ω , in the difference S

k1
ω and S

k1
ω \S

k2
ω \S

6. Implementation and Experiment.

In this section, we apply Algorithms 1–4 imple-
mented in R (see "Algorithm 1. R"-"Algorithm 4. R" in Table 2) and a classical SVM in
the R package e1071 [9] to simulated data sets of gene trees generated by the multispecies
coalescent process.

First, we describe how we generated the simulated data. We set the parameters for the
multispecies coalescent process, species depth (Depth) under the multispecies coalescent
model and effective population size (P opulation) as:

(31)

Depth = P opulation × C,

where C is a constant, which takes a given value from

{0.2, 0.4, 0.6, 0.8, 1, 1.2, 2.4, 3.6, 4.8, 6, 8, 10}.

18

Algorithm 1: Tropical Classiﬁer via LP 1

input : Training sets: P , Q; Test set: T ;

Indices: pairwise distinct iP , iQ, jP , jQ ; Threshold: η > 0; Parameter: C > 0 (for the multispecies

coalescent process)

output: Optimal normal vector: ω; A partition of T : ˜P , ˜Q such that ˜P ∪ ˜Q = T and ˜P ∩ ˜Q = ∅

1 Solve the linear programming (LP 1) for input data sets P , Q and indices iP , iQ , jP , jQ
2 ω ← optimal ω such that the objective function in (LP 1) reaches its optimal value
3 ˜P ← ∅,
˜Q ← ∅
4 for each t ∈ T do
5
6
7
8
9

I ← the set of indices {i|ωi + ti = max{ωk + tk|1 ≤ k ≤ d}, 1 ≤ i ≤ d}
I∗ ← I ∩ {iP , iQ, jP , jQ}
if C ≤ η then

if I∗ = {iP }, {jP }, {iP , jP }, {iP , iQ}, {jP , iQ}, {jP , jQ}, {jP , iQ, jQ}, or {iP , jP , iQ, jQ} then Add t into ˜P
if I∗ = {iQ}, {jQ}, {iQ, jQ}, {iP , jQ}, {iP , jP , iQ}, {iP , jP , jQ}, {iP , iQ, jQ}, or ∅ then Add t into ˜Q

10
11
12

if C > η then

if I∗ = {iP }, {jP }, {iP , jP }, {iP , iQ}, {jP , jQ}, {iP , iQ, jQ}, {jP , iQ, jQ}, or {iP , jP , iQ, jQ} then Add t into ˜P
if I∗ = {iQ}, {jQ}, {iQ, jQ}, {iP , jQ}, {jP , iQ}, {iP , jP , iQ}, {iP , jP , jQ}, or ∅ then Add t into ˜Q

13 return ω, ˜P , ˜Q

Algorithm 2: Tropical Classiﬁer via LP 2

input : Training sets: P , Q; Test set: T ;

Indices: pairwise distinct iP , iQ, jP (jQ = iP ); Threshold: η > 0; Parameter: C > 0 (for the multispecies

coalescent process)

output: Optimal normal vector: ω; A partition of T : ˜P , ˜Q such that ˜P ∪ ˜Q = T and ˜P ∩ ˜Q = ∅

1 Solve the linear programming (LP 2) for input data sets P , Q and indices iP , iQ , jP
2 ω ← optimal ω such that the objective function in (LP 2) reaches its optimal value
3 ˜P ← ∅,
˜Q ← ∅
4 for each t ∈ T do
5
6
7
8
9

I ← the set of indices {i|ωi + ti = max{ωk + tk|1 ≤ k ≤ d}, 1 ≤ i ≤ d}
I∗ ← I ∩ {iP , iQ, jP }
if C ≤ η then

if I∗ = {iP }, {jP }, {iQ}, or {iQ, jP } then Add t into ˜P
if I∗ = {iP , jP }, {iP , iQ}, {iP , iQ, jP }, or ∅ then Add t into ˜Q

10
11
12

if C > η then

if I∗ = {iP }, {iP , jP }, {iP , iQ, jP }, or ∅ then Add t into ˜P
if I∗ = {jP }, {iQ}, {iP , iQ}, or {iQ, jP } then Add t into ˜Q

13 return ω, ˜P , ˜Q

Algorithm 3: Tropical Classiﬁer via LP 3

input : Training sets: P , Q; Test set: T ;

Indices: distinct k1, k2 (iP = jQ = k1, iQ = jP = k2); Threshold: η > 0; Parameter: C > 0 (for the

multispecies coalescent process)

output: Optimal normal vector: ω; A partition of T : ˜P , ˜Q such that ˜P ∪ ˜Q = T and ˜P ∩ ˜Q = ∅

1 Solve the linear programming (LP 3) for input data sets P , Q and indices k1, k2
2 ω ← optimal ω such that the objective function in (LP 3) reaches its optimal value
3 ˜P ← ∅,
˜Q ← ∅
4 for each t ∈ T do
5
6
7
8
9

I ← the set of indices {i|ωi + ti = max{ωk + tk|1 ≤ k ≤ d}, 1 ≤ i ≤ d}
I∗ ← I ∩ {k1, k2}
if C ≤ η then

if I∗ = {k1}, or {k1, k2} then Add t into ˜P
if I∗ = {k2}, or ∅ then Add t into ˜Q

10
11
12

if C > η then

if I∗ = {k1}, or ∅ then Add t into ˜P
if I∗ = {k2}, or {k1, k2} then Add t into ˜Q

13 return ω, ˜P , ˜Q

In this simulation studies, we ﬁxed P opulation = 10, 000 and determine Depth by Equation
(31). For each value of C, we generate a pair of simulated data sets P and Q by the following
steps:

1. We generate 100 species trees with 5 leaves under the Yule process by Mesquite [7].
2. Given a species tree generated in Step 1, we generate 100 gene trees with 5 leaves each

under the coalescent model. We set P a set of these 100 gene trees.

TROPICAL SUPPORT VECTOR MACHINE

19

Algorithm 4: Tropical Classiﬁer via LP 4

input : Training sets: P , Q; Test set: T ;

Indices: pairwise distinct iP , iQ, j (jP = jQ = j); Threshold: η > 0; Parameter: C > 0 (for the

multispecies coalescent process)

output: Optimal normal vector: ω; A partition of T : ˜P , ˜Q such that ˜P ∪ ˜Q = T and ˜P ∩ ˜Q = ∅

1 Solve the linear programming (LP 4) for input data sets P , Q and indices iP , iQ , j
2 ω ← optimal ω such that the objective function in (LP 4) reaches its optimal value
3 ˜P ← ∅,
˜Q ← ∅
4 for each t ∈ T do
5
6
7
8
9

I ← the set of indices {i|ωi + ti = max{ωk + tk|1 ≤ k ≤ d}, 1 ≤ i ≤ d}
I∗ ← I ∩ {iP , iQ, j}
if C ≤ η then

if I∗ = {iQ}, {iP , iQ}, {iP , j}, or {j} then Add t into ˜P
if I∗ = {iP }, {iQ, j}, {iP , iQ, j}, or ∅ then Add t into ˜Q

10
11
12

if C > η then

if I∗ = {iP }, {iP , iQ}, {iP , iQ, j}, or ∅ then Add t into ˜P
if I∗ = {iQ}, {iP , j}, {iQ, j}, or {j} then Add t into ˜Q

13 return ω, ˜P , ˜Q

3. By repeating Step 2 with another species tree generated in Step 1, we obtain another set

of 100 gene trees and we set this set of gene trees Q.

4. We convert gene trees in P generated by Step 2 and gene trees in Q generated by Step 3

into ultrametrics of length (cid:0)5
2

(cid:1) = 10 by the R package ape [13].

FIG 6. Accuracy rates for different proportions of points: 15%, 20% and 25%, respectively. The y-axis represents
the accuracy rates. All of them are based on simulated data sets generated under the multispecies coalescent
processes via Mesquite. The x-axis shows the ratios of the species depth to effective population size of the
coalescent processes. We used the ggplot2 package [16] to plot them. All lines were smoothed by the Lowess
function in R.

We applied (soft margin) tropical SVMs and classical SVMs to the simulated data sets
generated by the procedure described above and computational results are shown in Figure
6. For each pair of sets P and Q, we chose a proportion (15%, 20%, or 25%) of random
points from P and Q respectively as our test set, and the rest points in P and Q form a
training dataset. To obtain the curve marked as “classical" in Figure 6, we applied classical
SVMs to the simulated data sets and we recorded their accuracy rates. To obtain the curves
marked as “Alogirhm 1"-“Algorithm 4" in Figure 6, for each training dataset (according to its
related C), we applied Algorithms 1 to 4 respectively to obtain classiﬁcations with the test
set, where the input threshold η is 4.8. Note that for each C and for each proportion (15%,
20%, or 25%), we randomly sampled the test sets 10 different times, and we recorded the
best accuracy rate among the 10 times of computation. Figure 6 can be produced by running
"Graph Producer.R" (see Table 2). The input training sets, test set and indices (iP , jP , iQ, jQ)
of these algorithms can be found online (see the folders "Genetree Data" and "Assignment"
in Table 2).

20

Figure 6 shows that when the value of C is small, tropical SVMs give much higher accu-
racy rates than that of classical SVMs. More speciﬁcally, in all three ﬁgures, all Algorithms
1–4 have much better accuracy rates than that of classical SVMs when C is between 0 and
2. And Algorithm 2 has the best accuracy rate when C is less than 6. Algorithm 3 does not
behave as well as the other three Algorithms. A possible reason is that it only uses two sec-
tors (indexed by {k1, k2}) to classify the training dataset, while Algorithm 1, Algorithm 2
and Algorithm 4 use four, three and three sectors (indexed by {iP , iQ, jP , jQ}, {iP , jP , iQ}
and {iP , iQ, j}), respectively. One may ask why Algorithm 1 does not behave better than
Algorithm 2 even though Algorithm 1 uses more sectors. Our explanation is that the method
of classifying test points presented in Algorithm 1 (Lines 7-12) might not be the best way for
the corresponding linear programming problem (LP 1).

From Figure 6, we observed that accuracy rates tend to improve as C increased in overall.
This can be explained by the nature of the multispecies coalescent process. When C is small,
then a gene tree generated by the coalescent process is not constrained by the tree topology of
the species tree so that a gene tree becomes a random tree. Therefore, the two sets P and Q of
gene trees tend to be overlapped over the space of ultrametrics. When C is large, then the tree
topologies of gene trees under a ﬁxed species tree tend to be strongly correlated. Therefore,
the two sets P and Q of gene trees tend to be well separated in the space of ultrametrics.

Also, in order to show the performance of algorithms in Section 5, we recorded the com-
putation time in seconds for each algorithm and classical SVMs shown in Table 1. Each
computational time in Table 1 is the average time over 10 times of computation for the same
input. Here, the input training data sets P and Q have 170 gene trees with 5 leaves in total,
and the test set T have 30 gene trees. These data sets are generated by the same multispecies
coalescent process (for C = 10 and P opulation = 10, 000) as before.

TABLE 1
Computational time (s: second) of each method.

Algorithm 1 Algorithm 2 Algorithm 3 Algorithm 4 Classical

0.052s

0.033s

0.012s

0.037s

0.0041s

7. Discussion. Here we focused on a tropical SVM, a tropical hyperplane over the tropi-
cal projective torus, which separates data points from different categories into sectors. We for-
mulated both hard margin and soft margin tropical SVMs as linear programming problems.
For tropical SVMs, we need to go through exponentially many linear programming problems
in terms of the dimension of the tropical projective torus and the sample size of the input data
to separate data points. Therefore, in this paper, we explored a simper case when all points
from the same category are staying in the same sector of a separating tropical hyperplane. For
the hard margin tropical SVMs, we proved the necessary and sufﬁcient conditions to separate
two tropically separable sets and we showed the explicit formula of an optimal solution for
a feasible linear programming problem. For soft margin tropical SVMs, we simpliﬁed the
linear programming problems by studying their properties, and we developed algorithms to
compute a soft margin tropical SVM from data in the tropical projective torus. We compared
our methods (implemented in R) with the svm() funciton from the e1071 package [9] for
the simulated data generated by the multispecies coalescent processes [8].

In general we have to go through exponentially many linear programming problems to
ﬁnd soft margin and hard margin tropical SVMs in our algorithms. However, we do not know
exactly the time complexity of a tropical SVM.

TROPICAL SUPPORT VECTOR MACHINE

21

PROBLEM 7.1. What is the time complexity of a hard margin tropical SVM over the
tropical projective torus? How about the time complexity of a soft margin tropical SVM over
the tropical projective torus? Is it a NP-hard problem?

In addition, in this paper, we focused on tropical SVMs over the tropical projective torus
2 )/R1 not over the space of ultrametrics. Recall that the space of ultrametrics is an union
R(N
of N − 2 dimensional polyhedral cones in R(N
2 )/R1. In our simulation studies, we generated
points using the multispecies coalescent model. These trees are equidistant trees and then
they are converted to ultrametrics in the space of ultrametrics. Our algorithms return tropical
SVMs with dimension (cid:0)N
(cid:1) − 2 over the tropical projective torus R(N
2 )/R1 and then we used
2
them to separate points within the space of ultrametrics, the union of N − 2 dimensional
2 )/R1. In the previous section, our simulations showed tropical
polyhedral cones subset of R(N
SVMs over R(N
2 )/R1 worked very well to separate points living inside of the union of N − 2
dimensional polyhedral cones while the classical SVMs did not work well. We think there
must be some geometrical explanations why tropical SVMs worked well.

PROBLEM 7.2. Can we describe a tropical SVM over the tropical projective torus
2 )/R1 geometrically how it separates points in the space of ultrametrics, the union of

R(N
N − 2 dimensional polyhedral cones?

Also we are interested in developing algorithms to compute hard margin tropical and soft
margin SVMs over the space of ultrametrics, the union of N − 2 dimensional polyhedral
cones, subset of the tropical projective torus R(N
2 )/R1. Since the space of ultrametrics is a
tropical linear space over the tropical projective torus R(N
2 )/R1, tropical SVMs should be a
tropical linear space with the dimension N − 2. As Yoshida et. al in [17] deﬁned a tropical
principal components over the space of ultrametrics as vertices of a tropical polytope over
the space of ultrametrics and Page et. al showed properties of tropical PCAs over the space of
ultrametrics in [12], we might be able to deﬁne a tropical SVM over the space of ultrametrics
as a tropical polytope over the space of ultrametrics.

PROBLEM 7.3. Can we deﬁne hard and soft margin tropical SVMs over the space of

ultrametrics? If so then how can we formulate them as an optimization problem?

APPENDIX A: TECHNICAL DETAILS

A.1. Proof of Theorem 4.15.

PROOF. For any p ∈ P , by the assumptions i(p) = iP and j(p) = jP , and by (6)–(7), we

have:

ωjP − ωiP ≤ piP − pjP , and ωl − ωjP ≤ pjP − pl, ∀l (cid:54)= iP , jP .
By the assumption that the four numbers iP , jP , iQ and jQ are pairwise distinct, there exists
l (cid:54)= iP , jP such that l = iQ or l = jQ. Similarly, for any q ∈ Q, by (6)–(7), we have

ωjQ − ωiQ ≤ qiQ − qjQ, and ωl − ωjQ ≤ qjQ − ql, ∀l (cid:54)= iQ, jQ,

and there exists l (cid:54)= iQ, jQ such that l = iP or l = jP . So for any p ∈ P , we have

(32)

(33)

(34)

ωjP − ωiP ≤ piP − pjP ,

ωiQ − ωjP ≤ pjP − piQ,

ωjQ − ωjP ≤ pjP − pjQ.

and for any q ∈ Q,

22

(35)

(36)

(37)

ωjQ − ωiQ ≤ qiQ − qjQ,

ωiP − ωjQ ≤ qjQ − qiP ,

ωjP − ωjQ ≤ qjQ − qjP .

By adding (33) and (35), we have

(38)

ωjQ − ωjP ≤ min
q∈Q

{qiQ − qjQ} + min
p∈P

{pjP − piQ}.

By adding (32) and (36), we have

(39)

max
p∈P

{pjP − piP } + max
q∈Q

{qiP − qjQ} ≤ ωjQ − ωjP .

By (34), (37), (38) and (39), the inequality (8) holds. Therefore, if the linear programming
(4)–(7) has a feasible solution, then we have (8).

On the other hand, if we have (8), then there exist real numbers ωjQ and ωjP such that the

inequalities (34), (37), (38) and (39) hold. Notice that the inequality (38) is equivalent to

ωjQ − min
q∈Q

{qiQ − qjQ} ≤ ωjP + min
p∈P

{pjP − piQ}.

So, there exists a number ωiQ such that

(40)

ωjQ − min
q∈Q

{qiQ − qjQ} ≤ ωiQ,

(41)

ωiQ ≤ ωjP + min
p∈P

{pjP − piQ}.

Symmetrically, the inequality (39) is equivalent to

max
p∈P

{pjP − piP } + ωjP ≤ ωjQ − max
q∈Q

{qiP − qjQ}.

So, there exists a number ωiP such that

(42)

max
p∈P

{pjP − piP } + ωjP ≤ ωiP ,

(43)

ωiP ≤ ωjQ − max
q∈Q

{qiP − qjQ}.

The inequality (42) can be rewritten as

(44)

max
p∈P

{pjP − piP } ≤ ωiP − ωjP ⇔ ωjP − ωiP ≤ min
p∈P

{piP − pjP }.

The inequality (43) can be rewritten as

(45)

ωiP − ωjQ ≤ − max
q∈Q

{qiP − qjQ} ⇔ ωiP − ωjQ ≤ min
q∈Q

{qjQ − qiP }.

By (40) and (44), the inequality (6) holds. By (34), (37), (41) and (45), the inequality (7)
holds for l = iQ, jQ when ξ ∈ P , or for l = iP , jP when ξ ∈ Q. For l (cid:54)= iQ, jQ when ξ ∈ P ,
or for l (cid:54)= iP , jP when ξ ∈ Q, there always exist sufﬁciently small numbers for ωl such that
the inequality (7) holds. So the inequality (8) guarantees the feasibility of the inequalities (6)
and (7). Notice that once (6) and (7) are feasible, there is always a non-negative number z
such that (5) holds. So, if we have (8), then the linear programming (4)–(7) has a feasible
solution.

If a feasible solution exists, then by (5), for any feasible solution (ω; z),

(46)

z ≤ min
p∈P

{piP − pjP } + ωiP − ωjP , z ≤ min
q∈Q

{qiQ − qjQ} + ωiQ − ωjQ.

TROPICAL SUPPORT VECTOR MACHINE

23

So, by (33) and (36), and by summing up the above two inequalities, we have

(47)

2z ≤ min
p∈P

{piP − pjP } + min
q∈Q

{qiQ − qjQ} + ωiP − ωjP + ωiQ − ωjQ

= min
p∈P

{piP − pjP } + min
q∈Q

{qiQ − qjQ} + (ωiQ − ωjP ) + (ωiP − ωjQ)

(48)

≤ min
p∈P

{piP − pjP } + min
q∈Q

{qiQ − qjQ} + min
p∈P

{pjP − piQ} + min
q∈Q

{qjQ − qiP }

= A + D + B + E.

Also, by (34), (36) and the ﬁrst inequality in (46), we have

(49)

z ≤ min
p∈P

{piP − pjP } + ωiP − ωjP

= min
p∈P

{piP − pjP } + ωiP − ωjQ + ωjQ − ωjP

= min
p∈P

{piP − pjP } + (ωjQ − ωjP ) + (ωiP − ωjQ)

(50)

≤ min
p∈P

{piP − pjP } + min
p∈P

{pjP − pjQ} + min
q∈Q

{qjQ − qiP } = A + C + E.

Symmetrically, by (33), (37) and the second inequality in (46), we have

(51)

z ≤ min
q∈Q

{qiQ − qjQ} + ωiQ − ωjQ

= min
q∈Q

{qiQ − qjQ} + (ωiQ − ωjP ) + (ωjP − ωjQ)

(52)

≤ min
q∈Q

{qiQ − qjQ} + min
p∈P

{pjP − piQ} + min
q∈Q

{qjQ − qjP } = D + B + F.

2 (A + B + D + E), A + C + E and B + D + F are upper bounds for

2 (A + B + D + E) ≤ min{A + C + E, B + D + F }, then we can choose a feasible ω

Hence, all the values 1
z.

If 1
such that

ωiQ − ωjP = −B, ωiP − ωjQ = −E,

ωjP − ωiP =

1
2

(A − B − D − E) , ωjQ − ωiQ =

1
2
2 (B + D − E − A). For this ω, the equalities in (46), (47) and

(D − A − B − E)

which imply ωjQ − ωjP = 1
(48) hold, and z reaches its optimal value 1

2 (A + B + D + E).

If A + C + E < min{ 1

2 (A + B + D + E) , B + D + F }, then we can choose a feasible

ω such that

ωjQ − ωjP = C, and ωiP − ωjQ = E,

which imply ωjP − ωiP = −C − E. For this ω, the equalities in (49) and (50) hold, and z
reaches its optimal value A + C + E. Symmetrically, if

B + D + F < min{

1
2

(A + B + D + E) , A + C + E},

then we can choose a feasible ω such that

ωjP − ωjQ = F, and ωiQ − ωjP = B,

which imply ωjQ − ωiQ = −B − F . For this ω, the equalities in (51) and (52) hold, and z
reaches its optimal value B + D + F . (cid:3)

24

A.2. Proof of Theorem 4.16.

PROOF. We only need to prove part (i) since part (ii) can be symmetrically argued. For

any p ∈ P , by the assumptions i(p) = iP and j(p) = jP , and by (6)–(7), we have:

ωjP − ωiP ≤ piP − pjP , and ωl − ωjP ≤ pjP − pl, ∀l (cid:54)= iP , jP .
By (2), iP (cid:54)= iQ. Note that we assume iQ (cid:54)= jP . So, there exists l (cid:54)= iP , jP such that l = iQ.
For any q ∈ Q, by (6)–(7), we have

ωjQ − ωiQ ≤ qiQ − qjQ, and ωl − ωjQ ≤ qjQ − ql, ∀l (cid:54)= iQ, jQ.
By the deﬁnition of i(p) and j(p), we have iP (cid:54)= jP . So we have jQ (cid:54)= jP since we assume
that iP = jQ. Notice again that we assume iQ (cid:54)= jP . Hence, there exists l (cid:54)= iQ, jQ such that
l = jP . So, for any p ∈ P ,

(53)

ωjP − ωiP ≤ piP − pjP ,

(54)

ωiQ − ωjP ≤ pjP − piQ,

and for any q ∈ Q,

(55)

ωjQ − ωiQ ≤ qiQ − qjQ,

(56)

ωjP − ωjQ ≤ qjQ − qjP .

If iP = jQ, then by (53) and (56), we have

(57)

max
ξ∈P ∪Q

{ξjP − ξiP } ≤ ωiP − ωjP .

If iP = jQ, then by adding (54) and (55), we have

(58)

ωiP − ωjP ≤ min
p∈P

{pjP − piQ} + min
q∈Q

{qiQ − qiP }.

So, if iP = jQ, then by (57) and (58), we have (11).

On the other hand, if we have (11), then there exist real numbers ωiP and ωjP such that
{pjP − piQ}. Then

(57) and (58) hold. By (57), we have (53) and (56). Let ωiQ = ωiP + min
p∈P
we have the inequality (54), and by (58), we have

max
q∈Q

{qiP − qiQ} ≤ ωiQ − ωiP ,

which is equivalent to (55). By (53), (54), (55) and (56), the inequality (6) holds, and the the
inequality (7) holds for l = iQ when ξ ∈ P , or for l = jP when ξ ∈ Q. For l (cid:54)= iQ when ξ ∈ P ,
or for l (cid:54)= jP when ξ ∈ Q, there always exist sufﬁciently small numbers for ωl such that the
inequality (7) holds. So the inequality (11) guarantees the feasibility of the inequalities (6)
and (7). Notice that once (6) and (7) are feasible, there is always a non-negative number z
such that (5) holds. So, if we have (11), then the linear programming (4)–(7) has a feasible
solution.

If a feasible solution exists, then by (5),

(59)

z ≤ min
p∈P

{piP − pjP } + ωiP − ωjP , z ≤ min
q∈Q

{qiQ − qjQ} + ωiQ − ωjQ.

Note iP = jQ. So, by summing up the above two inequalities and by (54),

(60)

(61)

2z ≤ min
p∈P

{piP − pjP } + min
q∈Q

{qiQ − qjQ} + ωiQ − ωjP

≤ min
p∈P

{piP − pjP } + min
q∈Q

{qiQ − qjQ} + min
p∈P

{pjP − piQ} = A(cid:48) + C + B.

TROPICAL SUPPORT VECTOR MACHINE

25

Also, by (54), (57) and the second inequality in (59), we have

(62)

z ≤ min
q∈Q

{qiQ − qjQ} + ωiQ − ωjQ

= min
q∈Q

{qiQ − qjQ} + ωiQ − ωjP + ωjP − ωjQ

= min
q∈Q

{qiQ − qjQ} + (ωiQ − ωjP ) + (ωjP − ωiP )

(63)

≤ min
q∈Q

{qiQ − qjQ} + min
p∈P

{pjP − piQ} + min
ξ∈P ∪Q

{ξiP − ξjP } = C + B + A.

Hence, both values 1

2 (A(cid:48) + B + C) and A + B + C are upper bounds for z.

If 1

2 (A(cid:48) + B + C) ≤ A + B + C, then we can choose a feasible ω such that

ωiP − ωjP =

1
2

(cid:0)B + C − A(cid:48)(cid:1) , and ωiQ = ωjP + B,

which imply ωiQ − ωjQ = 1
z reaches its optimal value 1

2 (A(cid:48) + B − C). For this ω, the equalities in (59)–(61) hold, and
2 (A(cid:48) + B + C).

If A + B + C < 1

2 (A(cid:48) + B + C), then we can choose a feasible ω such that

ωiQ − ωjQ = A + B, and ωiQ = ωjP + B,
which imply ωiP − ωjP = −A. For this ω, the equalities in (62)–(63) hold, and z reaches its
optimal value A + B + C. (cid:3)

A.3. Proof of Theorem 4.17.

PROOF. For any p ∈ P , and for any q ∈ Q, by the assumptions i(p) = j(q) = k1 and

i(q) = j(p) = k2, and by (6), we have:

ωk2 − ωk1 ≤ pk1 − pk2, and ωk1 − ωk2 ≤ qk2 − qk1

Therefore,

(64)

max
p∈P

{pk2 − pk1} ≤ ωk1 − ωk2 ≤ min
q∈Q

{qk2 − qk1}.

So if the linear programming (4)–(7) has a feasible solution, then we have (13).

On the other hand, if we have (13), then there exist real numbers ωk1 and ωk2 such that (64),
and hence (6) holds. For l (cid:54)= k1, k2, there always exist sufﬁciently small numbers for ωl such
that the inequality (7) holds. So inequalities (13) guarantees the feasibility of the inequalities
(6) and (7). Notice that once (6) and (7) are feasible, there is always a non-negative number
z such that (5) holds. So, if we have (13), then the linear programming (4)–(7) has a feasible
solution.

If a feasible solution exists, then by (5),

(65)

z ≤ min
p∈P

{pk1 − pk2} + ωk1 − ωk2, z ≤ min
q∈Q

{qk2 − qk1} + ωk2 − ωk1.

By summing up the above two inequalities,

2z ≤ min
p∈P

{pk1 − pk2} + min
q∈Q

{qk2 − qk1}.

So the value (14) is an upper bound for z. Note that we can choose a feasible ω such that

ωk1 − ωk2 =

(cid:18)

1
2

min
q∈Q

{qk2 − qk1}+ max
p∈P

{pk2 − pk1}

,

(cid:19)

which satisﬁes the inequality (64). For this ω, the equalities in (65) hold, and z reaches its
the optimal value (14). (cid:3)

26

A.4. Proof of Theorem 4.18.

PROOF. For any p ∈ P , by the assumptions i(p) = iP and j(p) = j, and by (6)–(7), we

have:

ωj − ωiP ≤ piP − pj, and ωl − ωj ≤ pj − pl, ∀l (cid:54)= iP , j.

By (2), iP (cid:54)= iQ. By the deﬁnition of i(q) and j(q), i(q) (cid:54)= j(q), and hence iQ (cid:54)= j. So, there
exists l (cid:54)= iP , j such that l = iQ. Similarly, for any q ∈ Q, we have

ωj − ωiQ ≤ qiQ − qj, and ωl − ωj ≤ qj − ql, ∀l (cid:54)= iQ, j,

and there exists l (cid:54)= iQ, j such that l = iP . So we have

(66)

and

(67)

Therefore,

(68)

and

(69)

∀p ∈ P, ωj − ωiP ≤ piP − pj, and ωiQ − ωj ≤ pj − piQ,

∀q ∈ Q, ωj − ωiQ ≤ qiQ − qj, and ωiP − ωj ≤ qj − qiP .

max
q∈Q

{qiP − qj} ≤ ωj − ωiP ≤ min
p∈P

{piP − pj}

max
p∈P

{piQ − pj} ≤ ωj − ωiQ ≤ min
q∈Q

{qiQ − qj}.

So, if the linear programming (4)–(7) has a feasible solution, then we have (15) and (16).

On the other hand, if we have (15) and (16), then there exist real numbers ωj, ωiP and ωiQ
such that (68) and (69) hold, and hence (66) and (67) hold. For l (cid:54)= iP , j, iQ, there always
exist sufﬁciently small numbers for ωl such that the inequality (7) holds. So inequalities (15)
and (16) guarantee the feasibility of the inequalities (6) and (7). Notice that once (6) and (7)
are feasible, there is always a non-negative number z such that (5) holds. So, if we have (15)
and (16), then the linear programming (4)–(7) has a feasible solution.

If a feasible solution exists, then by (5) and the ﬁrst inequality in (68),

z ≤ min
p∈P

{piP − pj} + ωiP − ωj ≤ min
p∈P

{piP − pj} + min
q∈Q

{qj − qiP }, and

by (5) and the ﬁrst inequality in (69),

z ≤ min
q∈Q

{qiQ − qj} + ωiQ − ωj ≤ min
q∈Q

{qiQ − qj} + min
p∈P

{pj − piQ}.

So the maximum z is given by (17), and this optimal value is reached when either ωiP − ωj =
min
q∈Q

{qj − qiP }, or ωiQ − ωj = min
p∈P

{pj − piQ}. (cid:3)

APPENDIX B: FILES IN THE ONLINE REPOSITORY

Table 2 lists all ﬁles at the online repository: https://github.com/HoujieWang/

Tropical-SVM

TROPICAL SUPPORT VECTOR MACHINE

27

TABLE 2
Supporting Information ﬁles

Name

File Type

Results

unbounded.RData
Algorithm1.R
Algorithm2.R
Algorithm3.R
Algorithm4.R
graph producer.R
Genetree Data
Genetree Data/data_15%.RData
Genetree Data/data_20%.RData
Genetree Data/data_25%.RData
Assignment
Assignment/asgn_1_15%.RData
Assignment/asgn_2_15%.RData
Assignment/asgn_3_15%.RData
Assignment/asgn_4_15%.RData
Assignment/asgn_1_20%.RData
Assignment/asgn_2_20%.RData
Assignment/asgn_3_20%.RData
Assignment/asgn_4_20%.RData
Assignment/asgn_1_25%.RData
Assignment/asgn_2_25%.RData
Assignment/asgn_3_25%.RData
Assignment/asgn_4_25%.RData

RData
R
R
R
R
R
folder
R Data
R Data
R Data
folder
R Data
R Data
R Data
R Data
R Data
R Data
R Data
R Data
R Data
R Data
R Data
R Data

Remark 4.23
Algorithm 1
Algorithm 2
Algorithm 3
Algorithm 4
Figure 6
Figure 6
Figure 6
Figure 6
Figure 6
Figure 6
Figure 6
Figure 6
Figure 6
Figure 6
Figure 6
Figure 6
Figure 6
Figure 6
Figure 6
Figure 6
Figure 6
Figure 6

REFERENCES

[1] ANÉ, C., LARGET, B., BAUM, D. A., SMITH, S. D. and ROKAS, A. (2007). Bayesian estimation of

concordance among gene trees. Mol. Biol. Evol. 24 412–426.

[2] BERKELAAR, M. and OTHERS (2020). lpSolve: Interface to Lp_solve version 5.5 to Solve Linear/Integer
Programs. R package version 5.6.15. https://CRAN.R-project.org/package=lpSolve.
[3] GÄRTNER, B. and JAGGI, M. (2006). Tropical support vector machines. ACS Technical Report. No.: ACS-

TR-362502-01.

[4] JOSWING, M. (2017). Essentials of Tropical Combinatorics. Springer, Berlin.
[5] LIN, B., STURMFELS, B., TANG, X. and YOSHIDA, R. Convexity in Tree Spaces. (2017). SIAM J. Discrete

Math. 31 2015–2038.

[6] MACLAGAN, D. and STURMFELS, B. (2015). Introduction to Tropical Geometry. Grad. Stud. Math. 161

American Mathematical Society, Providence.

[7] MADDISON, W. P. and MADDISON, D. R. (2019). Mesquite: A modular system for evolutionary analysis.

Version 3.61. http://www.mesquiteproject.org.

[8] MADDISON, W. P. (1997). Gene trees in species trees. Syst. Biol. 46 523–536.
[9] MEYER, D., DIMITRIADOU, E., HORNIK, K., WEINGESSEL, A. and LEISCH, F. (2019). e1071: Misc
Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. R
package version 1.7-3. https://CRAN.R-project.org/package=e1071.

[10] MONOD, A., LIN, B., YOSHIDA, R. and KANG, Q.(2019). Tropical geometry of phylogenetic tree space:

a statistical perspective. Arxiv: https://arxiv.org/abs/1805.12400.

[11] NYLANDER, J., WILGENBUSCH, J., WARREN, D. L. and SWOFFORD, D. L. (2007). AWTY: A system for
graphical exploration of MCMC convergence in Bayesian phylogenetic inference. Bioinformatics. 24
581–583.

[12] PAGE, R., ZHANG, L. and YOSHIDA, R. (2019). Tropical principal component analysis on the space of

ultrametrics. Arxiv: https://arxiv.org/abs/1911.10675.

[13] PARADIS, E. and SCHLIEP, K. (2018). ape 5.0: an environment for modern phylogenetics and evolutionary

analyses in R. Bioinformatics. 35 526–528.

[14] SEMPLE, C. and STEEL, M. (2003). Phylogenetics. Oxford Lecture Ser. Math. Appl. 24 Oxford University

Press, Oxford.

[15] SPEYER, D. and STURMFELS, B. (2009). Tropical Mathematics. Math. Mag. 82 163–173.
[16] WICKHAM, H. (2016). ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag, New York. https:

//ggplot2.tidyverse.org.

[17] YOSHIDA, R., ZHANG, L. and ZHANG, X. (2019). Tropical principal component analysis and its applica-

tion to phylogenetics. Bull. Math. Biol. 81 568–597.

[18] ZAKI, M. J. and MEIRA, W, JR. (2014). Data Mining and Analysis: Fundamental Concepts and Algo-

rithms. Cambridge University Press, Cambridge.

