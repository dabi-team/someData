On Scheduling Ring-All-Reduce Learning Jobs in Multi-Tenant
GPU Clusters with Communication Contention
Menglu Yu,1 Bo Ji,2 Hridesh Rajan,1 and Jia Liu3,1
1Department of Computer Science, Iowa State University
2Department of Computer Science, Virginia Tech
3Department of Electrical and Computer Engineering, The Ohio State University

2
2
0
2

g
u
A
4
1

]

C
D
.
s
c
[

2
v
7
1
8
7
0
.
7
0
2
2
:
v
i
X
r
a

ABSTRACT
Powered by advances in deep learning (DL) techniques, machine
learning and artiﬁcial intelligence have achieved astonishing suc-
cesses. However, the rapidly growing needs for DL also led to communication-
and resource-intensive distributed training jobs for large-scale DL
training, which are typically deployed over GPU clusters. To sus-
tain the ever-increasing demand for DL training, the so-called “ring-
all-reduce” (RAR) technologies have recently emerged as a favor-
able computing architecture to eﬃciently process network commu-
nication and computation load in GPU clusters. The most salient
feature of RAR is that it removes the need for dedicated parameter
servers, thus alleviating the potential communication bottleneck.
However, when multiple RAR-based DL training jobs are deployed
over GPU clusters, communication bottlenecks could still occur
due to contentions between DL training jobs. So far, there remains
a lack of theoretical understanding on how to design contention-
aware resource scheduling algorithms for RAR-based DL training
jobs, which motivates us to ﬁll this gap in this work. Our main con-
tributions are three-fold: i) We develop a new analytical model that
characterizes both communication overhead related to the worker
distribution of the job and communication contention related to
the co-location of diﬀerent jobs; ii) Based on the proposed ana-
lytical model, we formulate the problem as a non-convex integer
program to minimize the makespan of all RAR-based DL training
jobs. To address the unique structure in this problem that is not
amenable for optimization algorithm design, we reformulate the
problem into an integer linear program that enables provable ap-
proximation algorithm design called SJF-BCO (Smallest Job First
with Balanced Contention and Overhead); and iii) We conduct ex-
tensive experiments to show the superiority of SJF-BCO over ex-
isting schedulers. Collectively, our results contribute to the state-
of-the-art of distributed GPU system optimization and algorithm
design.

ACM Reference Format:
Menglu Yu,1 Bo Ji,2 Hridesh Rajan,1 and Jia Liu3,1 . 2022. On Scheduling
Ring-All-Reduce Learning Jobs in Multi-Tenant GPU Clusters with Com-
munication Contention. In The Twenty-third International Symposium on
Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks
and Mobile Computing (MobiHoc ’22), October 17–20, 2022, Seoul, Republic of
Korea. ACM, New York, NY, USA, 11 pages. https://doi.org/10.1145/3492866.3549716

1 INTRODUCTION
Background and Motivation: In recent years, the rise of deep
learning has driven an ever-increasing need for large-scale dis-
tributed training in GPU clusters, which leverages massive paral-
lelism to speed up the training processes. This has been evidenced
by the popularity of several prevailing distributed deep learning
(DDL) frameworks (e.g., TensorFlow [1] and PyTorch [12]). In these
DDL frameworks, the traditional and most widely adopted computing-
networking structure is based on the sever-worker (SW) architec-
ture, where DDL training jobs are decomposed into and executed
in parallel by a set of workers under the coordination of a param-
eter server. However, as the number of workers increases, the SW
architecture suﬀers from serious scalability limitations since the
server acts as a communication bottleneck and a single-point-of-
failure. To address the scalability limitations of the SW architec-
ture, the ring-all-reduce (RAR) [13] architecture has attracted in-
creasing attention in recent years. The key idea of RAR is that, by
forming a ring and working collaboratively, the workers can up-
date the learning model parameters without needing any parame-
ter server, thus removing the communication bottleneck and alle-
viating the single point of failure. Moreover, it can be shown that
the RAR architecture enjoys the highly desirable “bandwidth opti-
mality” in the sense that, as the number of workers increases, the
amount of information exchanged in the network is asymptotically
independent of the number of workers (see Section 3 for details).

CCS CONCEPTS
• Computing methodologies
works

→

Network performance analysis.

→

Distributed algorithms; • Net-

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
MobiHoc ’22, October 17–20, 2022, Seoul, Republic of Korea
© 2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9165-8/22/10. . . $15.00
https://doi.org/10.1145/3492866.3549716

However, despite all these salient features, the performance of
deploying RAR-based training jobs in multi-tenant GPU clusters re-
mains far from being satisfactory in practice [19]. The fundamen-
tal reason is that the bandwidth optimality of RAR architecture
only happens when there is only a single training job in the system
(i.e., a contention-free environment). In a multi-tenant GPU clus-
ter, however, such an ideal contention-free condition is rarely satis-
ﬁed. As a result, signiﬁcant communication bottleneck links could
occur when deploying RAR-based training jobs in the system. For
example, researchers in [19] have found that on a cluster of four-
GPU servers connected by 10 Gbps Ethernet, when only one RAR
training job is executed with four GPUs in the cluster, the job com-
pletion time is 295 seconds. In comparison, when four jobs of the
same type are executed simultaneously with each job still using

 
 
 
 
 
 
MobiHoc ’22, October 17–20, 2022, Seoul, Republic of Korea

Yu and Liu, et al.

four GPUs but scheduled across GPU servers, each job’s comple-
tion time dramatically increases to 675 seconds due to the exten-
sive communication contention. These empirical performance re-
sults of RAR indicate that developing eﬃcient and eﬀective sched-
uling for RAR-based DDL training jobs is well warranted to miti-
gate contention-induced communication bottlenecks. However, in
the literature so far, there remains a lack of theoretical understand-
ing on how to design contention-aware resource scheduling algo-
rithms for RAR-based DDL training jobs. In light of the rapidly
growing importance of RAR-based DDL deployment, our goal in
this paper is to ﬁll this gap and develop contention-aware sched-
uling algorithms for RAR-based training jobs in multi-tenant GPU
clusters.

Technical Challenges: We note, however, that due to a num-
ber of technical diﬃculties, developing contention-aware sched-
uling algorithms for RAR-based DDL jobs in multi-tenant GPU
clusters is highly challenging. First and foremost, just as any net-
work optimization problems that deal with contentions and inter-
ferences, the completion time of an RAR-based training job de-
pends not only on its resource allocation decisions (i.e., the num-
ber of ring-forming workers and their locality), but also on the
number of concurrent RAR-based DDL jobs that (partially or com-
pletely) share the communication links of this job. The complex
communication coupling between concurrent RAR-based training
jobs renders it intractable to compute the per-iteration execution
time of an RAR-based DDL job in closed-form. Second, there exists
a fundamental trade-oﬀ in terms of job locality. On one hand, co-
locating all workers of an RAR-based DDL job on the same server
enjoys a faster intra-server communication speed, but could lead
to resource fragmentation. On the other hand, spreading the ring
of an RAR job over multiple servers could also result in more con-
tentions of communication links and overhead in establishing con-
nections between servers. Last but not least, due to the resource
constraints of each server and the iterative nature of DDL train-
ing workload, the resource allocation decision for each RAR-based
training job is subject to a mix of packing and covering types of
constraints, both of which are known to be NP-hard.

Our Contributions: In this paper, we overcome the above chal-
lenges and design a suite of scheduling algorithmic techniques for
eﬃcient RAR-based DDL training in multi-tenant GPU clusters
with theoretical makespan performance guarantees. The key idea
of our algorithmic design is to transfer the structural complexity
of the intractable per-iteration running evaluation in the original
scheduling problem to the dimensional complexity of an equiva-
lent reformulated problem, which has a much cleaner integer lin-
ear program structure to work with. Our main results and technical
contributions are summarized as follows:

•

•

We ﬁrst propose a new analytical framework for RAR-based
DDL training resource allocation and scheduling that charac-
terizes both communication contention and overhead under
the RAR architecture in a multi-tenant GPU cluster. This ana-
lytical modeling serves as the foundation to enable us to formu-
late the scheduling optimization framework to minimize the
makespan of all RAR-based training jobs.
As mentioned earlier, due to the complex resource contentions
and couplings between RAR-based DDL jobs, it is intractable

to determine the closed-form expression for the per-iteration
execution time for each DDL job. To address this challenge, we
further reformulate the original problem into an equivalent in-
teger problem, which has a cleaner problem structure. Doing
so allows us to convert the structural complexity of the origi-
nal problem to the exponential dimensionality complexity in
the reformulated problem, which is more amenable for low-
complexity search-based optimization algorithm design.
Based on the above problem reformulation, we propose an ef-
ﬁcient scheduling algorithm called SJF-BCO (smallest job first
with balanced contention and overhead) with theoretical ap-
proximation ratio guarantee. We conduct extensive experiments
to verify the performance of our proposed SJF-BCO algorithm
and compare with existing scheduling policies to show the su-
periority of SJF-BCO over these baselines.

•

Collectively, our results contribute to a comprehensive and fun-
damental understanding of RAR-based DDL resource scheduling
optimization. The roadmap of the rest of the paper is as follows.
In Section 2, we review the related literature. Section 3 present
preliminaries to familiar readers with the necessary background.
Section 4 introduces the system model and problem formulation.
Section 5 demonstrates our algorithms and Section 6 provides their
performance analysis. Section 7 presents numerical results and Sec-
tion 8 concludes this paper.

2 RELATED WORK
As mentioned in Section 1, DDL training job scheduling algorithms
have received growing interest recently. Research in this area aims
to schedule DDL jobs and manage computing resources eﬃciently
in multi-tenant GPU computing clusters. Early attempts in this
ﬁeld were mostly heuristic approaches based on empirical observa-
tions and models to conduct the resource scheduling (e.g., [3, 7, 10,
11]). For example, Gandiva [20] considered GPU time-slicing and
job scheduling by predicting DDL training jobs characteristics. Op-
timus [14] leveraged performance models through online-ﬁtting to
guide the job scheduling aiming to minimize training completion
time. Rather than using prediction models, another line of research
is to take advantage of the model-less data-riven learning methods
for DDL job scheduling (e.g., [2, 8, 18]). For instance, Harmony [2],
a deep-reinforcement-learning-based scheduler considered mini-
mizing the job completion time. Hu. et al. [8] designed a new sched-
uling framework called Spear to minimize the makespan of jobs
by leveraging the deep reinforcement learning techniques. How-
ever, these works do not provide theoretical performance guar-
antee. Also, none of these works considered RAR-based DDL job
scheduling.

The most related work to this paper is GADGET [22], which
characterized RAR-based DDL job scheduling based on the assump-
tion that the bandwidth of each job is reserved. As a result, there
is no need to consider communication contention in [22]. We note
that a limitation of the reserved bandwidth assumption is that it
could lead to resource under-utilization. In contrast, this paper con-
siders communication contention to avoid this limitation. This, how-
ever, renders the scheduling problem far more challenging. Lastly,
Wang et al. [19] also considered contention under various all-reduce

On Scheduling Ring-All-Reduce Learning Jobs in Multi-Tenant GPU Clusters with Communication Contention

MobiHoc ’22, October 17–20, 2022, Seoul, Republic of Korea

Worker 1
c
a
b

c

Worker 3
b c
a

a

Worker 2
a b c

Step 1
(Share−Reduce)

b

Worker 3
b
a

a

Worker 3
a

b

Initial State

Worker 1
b

c

State 2

Worker 1
a
b c

b

Step 3
(Share−Only)

c

Worker 2
c

Worker 3
c
a

Worker 1
c
b
c

a

State 1

Worker 1
a b

c

Worker 2
c
a

Step 2
(Share−Reduce)

a

Worker 2
b c

Step 4
(Share−Only)

a
State 3

Worker 1

Worker 3
cb
a

Worker 2
a
b c

Effectively

Worker 3

Worker 2

n

State 4

Gradient subvector n of Worker 1

(n = a, b, c)
n Gradient Subvector n of Worker 3
(n = a, b, c)

b

n

Gradient subvector 2 summation
for Workers 2 and 3
Gradient subvector n summation
for Workers 1, 2, and 3 (n = a, b, c)

Final State

Gradient subvector n of Worker 2

(n = a, b, c)

Gradient subvector 1 summation for Workers 1 and 2

Gradient subvector 3 summation for Workers 1 and 3

n

a

c

Sum of full gradient vectors of Workers 1, 2, and 3

Figure 1: A three-worker illustrative example of the ring-all-
reduce (RAR) process.

architectures, including RAR. However, they also relied on a system-
dependent online-ﬁtting model to predict the execution time and
did not explicitly formulate any scheduling optimization problem.
Their solution was based on heuristics without theoretical perfor-
mance guarantee. In contrast, we develop an analytical model to
facilitate the job scheduling as a rigorous optimization problem,
which in turn entails approximation algorithm design with theo-
retical performance guarantee.

= 𝑄, and g𝑖
𝑘 is a stochastic gradient based on a random sam-
|Q𝑘 |
ple 𝛿𝑖
∈ Q𝑘 . The ﬁnite-sum and mini-batch structure of SGD nat-
urally lends itself to a distributed implementation in a 𝑄-worker
DDL system coordinated by a parameter server as follows: First,
the dataset is partitioned by 𝑄 workers. In each iteration 𝑘, each
worker retrieves the current model parameters from the server and
randomly draws a sample from its local dataset, and then computes
a stochastic gradient (e.g., using the backpropagation method). Then,
all workers send their gradients to the server to be aggregated.

2) The Ring-All-Reduce (RAR) Architecture: It can be seen
from the above discussions that SGD-based distributed learning
naturally implies a server-worker (SW) architecture. However, as
mentioned in Section 1, the SW architecture suﬀers from scalabil-
ity limitations as the number of workers increases. This is because
all workers need to communicate with the server, which creates
a bottleneck. Speciﬁcally, a 𝑤-worker SW system that solves a 𝑑-
dimensional ERM problem requires 2𝑤𝑑 amount of data exchange
per iteration (each worker sends and receives a 𝑑-dimensional vec-
tors per iteration), which scales linearly with respect to 𝑤.

)

1

𝑤
(

To address this scalability limitation, the RAR [13] has been pro-
posed to remove the server. Under RAR, the workers form a ring
to exchange and aggregate data collaboratively. For a 𝑤-worker
RAR system, each worker splits its stochastic gradient into 𝑤 sub-
vectors (see Fig. 1 for an example with 𝑤 = 3). Each iteration of
steps that can be divided into two phases. In
RAR has 2
−
1), workers perform gradients re-
the ﬁrst phase (steps 1, . . . , 𝑤
duction (i.e., summation), where each worker receives a gradient
subvector from its upstream worker and sends its local reduction
result to its downstream worker (Share-Reduce phase). In the sec-
ond phase (steps 𝑤, . . . , 2𝑤
2), each worker circulates its resultant
sub-vectors following the same token to obtain its ﬁnal resultant
gradients vector (Share-Only phase). Since each worker sends 𝑑
𝑤
1
𝑤
amount of data for 2
times, the total amount of data any
−
(
)
worker receives is 2𝑑
1
𝑤
, which is asymptotically independent
)𝑤
−
(
of 𝑤 as 𝑤 increases (also referred to as being bandwidth-optimal in
the literature).

−

−

3 RING-ALL-REDUCE (RAR)-BASED

DISTRIBUTED LEARNING: A PRIMER

4 SYSTEM MODEL AND PROBLEM

FORMULATION

In this section, we provide a quick overview on the RAR-based dis-
tributed learning to familiarize readers with necessary background
and ﬁx the terminologies that are useful in the rest of the paper.

In this section, we ﬁrst introduce our system model in Section 4.1
and then present the problem formulation for RAR-based DDL sched-
uling optimization in multi-tenant GPU clusters in Section 4.2.

(

∈

w
)

R𝑑 ¯𝐿

, 1
𝑃

1) SGD-Based Distributed Learning: The training of many
ML problems is typically in the form of an empirical risk minimiza-
𝑃
tion (ERM) problem: minw
, where w
𝑖=1 𝐿
(
is a loss
contains the model parameters to be learned, 𝐿
(
function, and 𝑃 is the total number of samples. Due to the high-
dimensionality and the large dataset size of many ERM problems
(e.g., in deep learning), the stochastic gradient descent (SGD) method
has become the most widely adopted method. The SGD method
1 = w𝑘 −
can be written as the following iterative process: w𝑘
∈Q𝑘 g𝑖
𝑄
𝜂𝑘 /
𝑘 , where 𝜂𝑘 denotes the learning rate in the 𝑘-th
𝑖
(
Q𝑘 represents the mini-batch in the 𝑘-th iteration with
iteration,
Í

w, 𝛿𝑖
)
w, 𝛿𝑖
)

Í

+

)

4.1 System Model
1) Scheduling Model: Consider a multi-tenant GPU cluster that
contains a set of servers
. Each server is equipped with a set of
homogeneous (i.e., of equal computation speed) and synchronized
GPUs. The servers in
are connected by a network and the net-
work topology can be modeled as a connected graph. In the be-
= 𝑇 time-slots,
ginning of a scheduling horizon
there is a set of RAR-based DDL jobs
waiting to be scheduled
J
is associated with a number
for training over

. Each job 𝑗

of length

|T |

S

S

T

T

∈ J

MobiHoc ’22, October 17–20, 2022, Seoul, Republic of Korea

Yu and Liu, et al.

No concurrent jobs

Server 1

Server 2

Two concurrent jobs

Server 1

Server 2

Finally, to ensure that no workers should be allocated for non-
active jobs and positive integer number of workers should be as-
signed to active jobs, we have:

Job 1

Job 2

Job 1

Job 2

(a) Without communication contention

(b) With communication contention

Figure 2: An example of worker placement.

of GPUs 𝐺 𝑗 and a total number of training iterations 𝐹 𝑗 from its
users, both of which are requested by its users.1

In this paper, we consider the “gang-scheduling” discipline that
is widely adopted in practical large-scale GPU clusters [7, 10, 19].
Under gang scheduling, all workers (i.e., GPUs) of an RAR-based
DDL job should be allocated simultaneously. Moreover, once a job
is scheduled to start, all GPUs allocated for this job will run to the
job’s completion and no preemption/migration is allowed.2 Upon
the job’s completion, the occupied resource will also be released
simultaneously. Each GPU can only be occupied by one worker
of some job at any given time. As shown in Fig. 2, the workers
of a job can be allocated within a single server or across multiple
servers, as long as there exists a path in the underlying network
that connects these workers and forms a ring topology to perform
the RAR process. Note that Fig. 2(a) allocates the workers in the
same server for each job, thus having no communication overhead.
On the contrary, Fig. 2(b) allocates workers across diﬀerent servers
for each job, which introduces communication contention when
the two jobs happen to perform RAR communication concurrently.
In this system, the control decisions of the scheduler are: i) de-
termine a feasible scheduling for all jobs in
subject to network
resource capacity; and ii) determine each job’s starting time. Specif-
ically, consider an RAR-based DDL job 𝑗 scheduled with 𝑤 𝑗 work-
Z+ denote the number
ers and its gradient size is 𝑚 𝑗 . Let 𝑦 𝑗𝑠
of GPUs scheduled for job 𝑗 on server 𝑠 in time-slot 𝑡
. Then, a
scheduling decision in time-slot 𝑡 can be fully deﬁned by the vec-
. Let 𝑎 𝑗 = arg min𝑡
tor y
be the
starting time of job 𝑗 (to be determined) by the scheduling and let
𝑇𝑗 be the resultant completion time of job 𝑗. Let
∈
represent the set of active jobs (jobs being executed) in
𝑎 𝑗 ,𝑇𝑗
[
time slot 𝑡. Clearly, to satisfy the 𝐺 𝑗 number of GPUs requested
for job 𝑗 during its training time, we have:

𝑦 𝑗𝑠
{

𝑡
J [

𝑦 𝑗𝑠
[

> 0,

∈ T

𝑠
∀

] ∈

𝑡
[

𝑡
[

𝑡
[

𝑡
[

𝑗, 𝑠

]}

J

,

,

∀

}

{

]

]

]

]

]

𝑡

𝑗

,

|

𝑦 𝑗𝑠

𝑡
[

]

= 𝐺 𝑗 ,

𝑗

∀

𝑡
∈ J [

]

, 𝑡

.

∈ T

(1)

Õ𝑠
∈S

Also, scheduling decisions y
𝑡 are subject to GPU resource con-
∀
straints. Let 𝑂𝑠 represent the GPU capacity of server 𝑠. To ensure
that the allocated GPUs do not exceed each server’s limit, we have:

𝑡
[

]

,

𝑦 𝑗𝑠

𝑡
[

] ≤

𝑂𝑠,

𝑠
∀

, 𝑡

.

∈ T

∈ S

Õ𝑗
𝑡
∈ J [

]

Also, under the non-preemptive gang scheduling, we have:

𝑦 𝑗𝑠

𝑡
[

]

= 𝑦 𝑗𝑠

𝑡
[

1

,

]

−

𝑠
∀

, 𝑗

𝑡
∈ J [

]

∈ S

, 𝑎 𝑗 < 𝑡

𝑇𝑗 .

≤

(2)

(3)

1In practice, to prevent spending excessively long time waiting for the training pro-
cess of a DDL job to converge, a maximum number of training iterations is usually
given.
2Besides the overhead and complication added for both software and hardware, it
has been shown that frequent job preemption and migration may lead to signiﬁcant
performance degradation [7].

𝑦 𝑗𝑠
𝑦 𝑗𝑠

]

𝑡
[
𝑡
[

= 0,

Z++,

𝑠
∀

, 𝑗 ∉

, 𝑡

𝑡
J [

]

𝑡
∈ J [

, 𝑗

∈ S
𝑠
∀

∈ T
, 𝑡

.

,

(4)

(5)

]

] ∈

∈ T

∈ S
2) Communication Contention Modeling: With the above
scheduling model, we are now in a position to present our com-
munication contention model. We assume that no communication
contention will be introduced if at most one server is used for the
job. For example, in Fig. 2(a), jobs 1 and 2 both use intra-server
communication and does not incur any communication contention.
By contrast, in Fig. 2(b), jobs 1 and 2 induce communication con-
tention since they both compete for inter-server link bandwidth
between servers 1 and 2. We let 𝑝 𝑗
denote the largest number
of concurrently running jobs that share an inter-server communi-
cation link with job 𝑗 in time slot 𝑡, which can be computed as:

𝑡
[

]

𝑝 𝑗

𝑡
[

]

= max
𝑠
∈S

1

{

(cid:26)

0 < 𝑦 𝑗𝑠

< 𝐺 𝑗

𝑡
[

]

} Õ𝑗′ ∈ J [

𝑡

]

{

1

0 <𝑦 𝑗′𝑠 [
𝑡
, 𝑡
𝑡
∈ J [

]
𝑗

,

< 𝐺 𝑗′ }(cid:27)
(6)
.

]

{

𝑡
[

∈ T

< 𝐺 𝑗

0 < 𝑦 𝑗𝑠

}
0 < 𝑦 𝑗′𝑠 [
𝑡

∀
In (6), the ﬁrst term 1
indicates that only active
]
jobs using inter-server communication on server 𝑠 will be consid-
1
ered. The second term
represents
]
the number of diﬀerent jobs that compete for inter-server commu-
nication on server 𝑠. Since job 𝑗 may not be transmitting at all
times (due to switching between communication and computation
modes), we let 𝑘 𝑗
be the actual largest number of contending
jobs on average with job 𝑗 in time-slot 𝑡, which can be assumed to
be statistically linearly proportional to 𝑝 𝑗

< 𝐺 𝑗′ }

𝑡
𝑗′ ∈ J [

, i.e.,

𝑡
[

Í

{

]

]

𝑘 𝑗

= 𝜉1𝑝 𝑗

𝑡
𝑡
[
[
is a positive constant.

∀

]

]

𝑗

,

𝑡
[
𝑡
∈ J [

]

]
, 𝑡

,

∈ T

(7)

where 𝜉1

0, 1

]

∈ (

3) RAR-Based DDL Training Completion Time Modeling:
To evaluate the job completion time 𝑇𝑗 of job 𝑗, we need to ﬁrst
characterize the RAR training speed. Note that the per-iteration
RAR operation time of each DDL job can be decomposed into three
parts: i) information exchange time, ii) computation time, and iii)
communication overhead. Next, we will model the operation time
of each part individually.

]

y

])

𝑡
[

𝑡
[

2-1) Information Exchange Time: We use 𝐵 {

𝜔 𝑗,1,𝜔 𝑗,2 } (
to de-
note the bandwidth between two successive workers 𝜔 𝑗,1 and 𝜔 𝑗,2
in job 𝑗’s ring in time-slot 𝑡 under a scheduling decision y
, where
𝜔 𝑗,2 is the downstream worker of 𝜔 𝑗,1. Note that, unlike [22], we
do not reserve bandwidth for each job in this paper, and this band-
width is determined by communication contention with other jobs
,
under the scheduling decisions y
𝑡
[
]
𝜔 𝑗,1,𝜔 𝑗,2 } (
min
𝑡
])
[
bottleneck link of job 𝑗 under scheduling decision y
𝑗
L
is the set of all links of job 𝑗. Recall from Section 3 that the amount
of information exchanged in each time-slot can be computed as
2𝑚 𝑗
. Thus, the number of time-slots for information ex-
𝑤𝑗 (
change can be computed as

(see Fig. 2(b)). We let 𝐵 𝑗
represent the bandwidth of the

𝑤 𝑗
Clearly, the bottleneck link of job 𝑗 occurs in those links that are
shared by the largest number of other concurrently running jobs.

𝜔 𝑗,1,𝜔 𝑗,2) ∈L 𝑗 𝐵 {

2𝑚 𝑗
𝑤𝑗 (

, where

𝑤 𝑗

𝑡
[

𝑡
[

𝑡
[

𝐵 𝑗

)/

])

])

−

−

y

y

y

1

1

)

]

(

(

.

(

On Scheduling Ring-All-Reduce Learning Jobs in Multi-Tenant GPU Clusters with Communication Contention

MobiHoc ’22, October 17–20, 2022, Seoul, Republic of Korea

)

(

(

)

]

]

(

(

1

y

y

∈

])

])

])

])

𝑘 𝑗

≫

𝑡
[

𝑡
[

𝑡
[

𝑡
[

𝑡
[

𝑡
[

] +

𝛼
𝑡
[

𝑘 𝑗
/

𝜶 , 𝑘 𝑗

𝜶 , 𝑘 𝑗

] +
𝑘 𝑗
(

(
] −

= 1 and ii) 𝑓

share of bandwidth if 𝑘 𝑗

𝑏𝑒 in practice [16, 23]. Recall that 𝑘 𝑗

We let 𝑏𝑒 and 𝑏𝑖 be the link bandwidth between and within servers,
respectively, where 𝑏𝑖
𝑡
]
[
denotes the actual largest number of contending jobs on average
with job 𝑗 in time-slot 𝑡. Ideally, each job on this bottleneck link
has an equal share of bandwidth 𝑏𝑒
under communication
contention. In practice, however, the bandwidth performance of-
ten degrades when multiple jobs compete for a link, which results
in each job having less than 𝑏𝑒
𝑡
𝑘 𝑗
] ≥
[
/
to rep-
2 [19]. To model this eﬀect, we use a function 𝑓
(
resent the “bandwidth sharing degradation factor” under commu-
R𝑑 captures all parameters that
nication contention, where 𝜶
satisﬁes the
could lead to degradation. We assume that 𝑓
𝑡
[
])
𝜶 , 1
𝜶 , 𝑘 𝑗
following properties: i) 𝑓
is an in-
𝑡
])
(
[
(
𝜶 , 𝑘 𝑗
. For example, if 𝑓
is a linear
𝑡
𝑡
creasing function of 𝑘 𝑗
])
[
[
]
𝜶 , 𝑘 𝑗
= 𝑏𝑒
=
function 𝑘 𝑗
𝑡
𝑓
, then 𝐵 𝑗
𝑡
𝑡
] −
[
[
[
(
/
𝑏𝑒
.
1
𝛼
𝑘 𝑗
))

/(
Recall that in the special case where all workers of a job 𝑗 are
co-located within a single server, there is no contention. Further,
intra-server communication is typically enabled by fast intercon-
= 𝑏𝑖 .
nect techniques (e.g., NVLink [4]). Hence, we have 𝐵 𝑗
2-2) Computation Time: To characterize the computation time
in the RAR operation, we use 𝐶 to denote the computational speed
of a GPU unit (deﬁned as the amount of data processed in each
time-slot). Since there are
amount of data for reduction
−
in each RAR operation, the number of time-slots to complete all
𝑚 𝑗
reductions can be computed as
𝐶. In addition to the
𝑤𝑗 (
all-reduce operation time, the computation time also includes the
forward pass (FP) time and the backward pass (BP) time to compute
a stochastic gradient. We let Δ𝑓
𝑗 (Δ𝑏
𝑗 ) denote the duration of one FP
(BP) of job 𝑗. Note that the FP time is proportional to the mini-batch
size 𝑀𝑗 , which can be calculated as Δ𝑓
𝑗 𝑀𝑗 (the size of a mini-batch
multiplied by the FP processing time of one sample). Meanwhile,
the BP time Δ𝑏
𝑗 is usually not relevant to the mini-batch size 𝑀𝑗
and is typically ﬁxed. Thus, the total number of time-slots for per-
iteration computation can be computed as
Δ𝑏
𝑗 .
2-3) Communication Overhead: In practice, it has been observed
that typically, the more servers an RAR-based DDL job uses to
perform the training, the larger the latency due to communica-
tion overhead (e.g., ACK time for message transmission, negotia-
tion time among all workers before conducting all-reduce [15]) can
be [19]. In this paper, we use 𝛾 𝑗
to denote the latency of job
y𝑗
𝑗 caused by communication overhead in time-slot 𝑡. We assume
that the latency is linear proportional to the number of servers in
>
use, i.e., 𝛾 𝑗
𝑡
𝑦 𝑗𝑠
[
{
is a positive constant.
𝑠
0,
∀
Lastly, putting 2-1) – 2-3) together, we can compute the RAR
as follows:

operation time of job 𝑗 under scheduling decision y

, where y𝑗

(
and 𝜉2

𝑡
[
∈ (

𝑚 𝑗
𝑤𝑗 (

𝑚 𝑗
𝑤𝑗 (

𝑦 𝑗𝑠
[

𝑠
Í

])
0, 1

= 𝜉2

𝑗 𝑀𝑗

> 0

𝑤 𝑗

𝑤 𝑗

𝑤 𝑗

Δ𝑓

𝑡
[

𝑡
[

𝑡
[

y𝑗

)/

)/

])

1

−

−

𝐶

=

+

+

1

1

1

}

)

]

]

]

]

(

]

𝑡
[

]

=

𝜏 𝑗

𝑡
[

]

𝑚 𝑗
𝑤𝑗

·
𝐵 𝑗

2

𝑤 𝑗
(
y

𝑡
[

1

)

−

𝑚 𝑗
𝑤𝑗

+

𝑤 𝑗

1

)

−

· (
𝐶

(

])
(i.e., the number of mini-
Hence, the RAR training speed 𝜙 𝑗
batch iterations completed by job 𝑗) in time-slot 𝑡 can be computed
. Recall that 𝐹 𝑗 is the requested number of
as 𝜙 𝑗

𝑡
[

𝜏 𝑗

,

]

1

𝑡
[

]

𝑡
[

])−

⌋

⌊(

𝛾 𝑗
+

(

y𝑗

𝑡
[

])+

Δ𝑓

𝑗 𝑀𝑗

+

Δ𝑏
𝑗 .

(8)

Table 1: Notation.

]

𝐺 𝑗
T/
/
N
S
𝑡
J [
]
𝑘 𝑗 [
𝑡
𝑡
𝜏𝑗 [
]
𝑡
𝑦 𝑗𝑠 [
]
𝑂𝑠
𝑇𝑗
𝑎 𝑗 /
Y
y𝑘
𝑗
y𝑘
𝑗 )
y𝑘
𝑗 )
y𝑘
𝑗 )
G (
𝑥𝑘
𝑗
𝑊 𝑘
𝑗𝑔
𝑈 𝑔
𝑠

𝜌
ˆ𝜌

(
(

Scheduling time horizon/# of GPUs requested by job j
Set of servers/GPUs in the cluster
The set of active jobs in time-slot t
Actual largest number of contending jobs on average with
job j in time-slot 𝑡
Per-iteration training time of job j in time-slot t
# of GPUs scheduled on server 𝑠 for job j in time-slot 𝑡
GPU capacity of server 𝑠
Starting/completion time slot of job 𝑗
The set of feasible scheduling schemes over
A schedule of job 𝑗 indexed with 𝑘
Actual execution time of job 𝑗 when schedule y𝑘
Estimated execution time of job 𝑗 when schedule y𝑘
Set of GPUs allocated for job 𝑗 when schedule y𝑘
Indicate whether job 𝑗 follows schedule y𝑘
𝑗 or not
Execution time added to GPU 𝑔 by job 𝑗 if job j follows y𝑘
𝑗
The accumulative execution time of worker 𝑔 on server 𝑠

𝑗 is used

𝑗 is used

T

𝑗 is used

𝑡
[

] ≥

𝑡
∈ J [

]

∀

+

𝑡

𝑡
(cid:8) Õ

iterations for training job 𝑗. Thus, job 𝑗’s completion time can be
calculated as:
𝑇𝑗 = 𝑎 𝑗

arg min

(9)

𝜙 𝑗

𝐹 𝑗

𝑗

,

.

(cid:9)

∈T
4.2 Problem Statement
In this paper, our goal is to determine the scheduling decisions
y
to minimize the makespan (i.e., max𝑗 𝑇𝑗 ), which is one of the
most useful metrics to measure the eﬃciency of multi-tenant GPU
clusters [5, 6]. Putting all modeling constraints and the objective
together, the RAR-based DDL job scheduling problem (RAR-DDLS)
can be formulated as the following optimization problem:

𝑡
[

]

RAR-DDLS:

min
,
𝑡
𝑦 𝑗𝑠 [
∀
]

𝑗,𝑠,𝑡

𝑇𝑗

max
𝑗
∈ J

subject to Constraints

1
) − (

(

9

.

)

We note that Problem RAR-DDLS is an integer non-convex pro-
gram with packing and covering constraints, which is NP-Hard. In
addition, the non-convex constraint in (6) involves indicator func-
tions and the max operator, which cannot be written in a closed-
from expression and hence is not amenable to conventional opti-
mization techniques. Due to these challenges, we will pursue an
approximation algorithmic approach in Section 5 that oﬀers prov-
able approximation ratio guarantee. To conclude this section, we
summarize the key notations in this paper in Table 1.

5 SOLUTION APPROACH
As mentioned in Section 4, a key challenge to solve Problem RAR-
DDLS is that, due to the mixed covering- and packing-type con-
straints, the number of job scheduling combinations grows expo-
nentially as the number of servers/jobs increases. Thus, it is com-
putationally prohibitive to enumerate all possible combinations be-
fore the scheduler decides when to start and which GPU(s) should
be allocated to achieve the optimal scheduling. Exacerbating the
problem is the fact that communication contention renders a mixed-
integer bilinear structure in (6), making it intractable to express
𝑝 𝑗
in closed-form. Due to these challenges, it is diﬃcult to di-
rectly solve Problem RAR-DDLS based on its original formulation.

𝑡
[

]

MobiHoc ’22, October 17–20, 2022, Seoul, Republic of Korea

Yu and Liu, et al.

No

Search for a
y
schedule 

τj[t], ∀t

Evaluate                to 
 estimate makespan

 A ‘‘good enough’’
      schedule ?

Return
y

Yes

Figure 3: Basic idea for solving Problem RAR-DDLS.

To overcome this challenge, we propose the following “indirect”
approach to solve Problem RAR-DDLS.

(

]

]

y

=

𝑡
[

𝑡
[

}
is determined by 𝐵 𝑗

]
increases as 𝑘 𝑗
> 0

1) Basic Idea: First, we note that, although not in closed-form
expressions, the per-iteration time 𝜏 𝑗
for each job can be com-
puted in polynomial time according to (6)-(8) once a schedule (i.e.,
𝑗, 𝑠
) is given. Speciﬁcally, we note that the per-
y
,
𝑦 𝑗𝑠
𝑡
∀
{
]
[
𝑡
𝑡
y𝑗
iteration time 𝜏 𝑗
. More-
𝑡
[
])
[
[
𝜶 , 𝑘 𝑗
in-
𝑡
y𝑗
gets larger, and 𝛾 𝑗
𝑡
over, 𝑓
[
(
])
[
])
1
creases as
can be
𝑡
grows. Thus, the range of 𝜏 𝑗
𝑦 𝑗𝑠
𝑠
[
{
estimated. The largest number of 𝑘 𝑗
is max𝑠 𝑂𝑠 , i.e., the worst
Í
case would be each job places one of its workers into the server
with the biggest capacity and they all compete for the bandwidth.
𝑏𝑒
Thus, we can have 𝐵 𝑗
. In addition,
𝑓
/
1
we have
1, 𝐺 𝑗
𝑠
1
and
𝑦 𝑗𝑠
Í
{
respectively, we can attain the lower and upper bounds.

𝑡
y
(
[
> 0
])
with their lower and upper bounds in Eqn. (8),

𝜶 , max𝑠 𝑂𝑠
(
)
. Then by plugging 𝐵 𝑗
]

𝑦 𝑗𝑠
{
𝑡
[

𝑡
]
[
> 0
}

]) ∈ [
} ∈ [

and 𝛾 𝑗

, 𝑏𝑖

𝑡
[

𝑡
[

𝑡
[

𝑡
[

])

y

}

]

(

]

]

(

]

]

(

]

𝑠
Í

,

]

∀

𝑡
[

The above insight suggests that we can solve Problem RAR-
DDLS via the following search-based approach to circumvent the
structural diﬃculty in (6)-(8) . We can ﬁrst search for a schedule y,
then 𝜏 𝑗
𝑡 can be eﬃciently evaluated to estimate the makespan.
Then, we repeat the process until we ﬁnd a “good enough” sched-
ule. Therefore, we can have the algorithmic framework as shown
in Fig. 3 to obtain an approximate makespan if the search space is
given. Clearly, the search space of y remains huge and diﬃcult to
sample. Nonetheless, in what follows, we show that Problem RAR-
DDLS can be reformulated to facilitate this search-based approach.
2) Problem Reformulation: In order to enable the search of a
schedule, we ﬁrst reformulate Problem RAR-DDLS by introducing
following notations. We let
be the set of all GPUs
be the set of feasible schedul-
in the cluster. Let
ing schemes for the jobs to be scheduled, where y𝑘 =
y𝑘
1, . . . , y𝑘
𝐽 }
{
and y𝑘
𝑦𝑘
. Note that, with a slight
, 𝑡
𝑡
𝑗
𝑗𝑠 [
{
∈ T } ∈
abuse of notation, we use 𝑦𝑘
here as a constant (not a variable)
𝑡
𝑗𝑠 [
to denote the number of workers allocated for job 𝑗 on server 𝑠
in time-slot 𝑡 if schedule y𝑘 is used. We also use 𝜌 𝑗
to de-
note the execution time of job 𝑗 if schedule y𝑘 is used. Also, we
,
denote the starting time of job 𝑗 under schedule y𝑘 as 𝑎 𝑗
. Let 𝑥𝑘
arg min
𝑠
be the binary variable to
∃
indicate whether job 𝑗 follows schedule y𝑘 (𝑥𝑘
= 1) or not (𝑥𝑘
= 0).
𝑗
𝑗
Then Problem RAR-DDLS can be reformulated as the following in-
teger linear program (ILP):

=
N
y1, . . . , y |Y | }
Z𝑆
+

𝑦𝑘
𝑡
𝑗𝑠 [
|

1, . . . , 𝑁

𝑗 ∈ {

> 0,

∈ S

𝑠
∀

0, 1

𝑡
{

y𝑘

y𝑘

Y

=

=

×

{

}

{

}

}

𝑇

]

]

(

)

]

)

(

,

min
𝑥𝑘
𝑗,𝑘
𝑗 ,

∀

max
𝑗

𝑥𝑘
𝑗

𝑎 𝑗
(cid:0)

(

y𝑘

y𝑘

𝜌 𝑗

(

) +

)

(cid:1)

subject to.

|Y | }
,

Õ𝑘
1,...,
∈{
= 𝑥𝑘
𝑥𝑘
𝑗
𝑗′
𝑥𝑘
0, 1
𝑗 ∈ {

,

}

𝑥𝑘
𝑗 = 1,

𝑗

∀

,

∈ J

∀

, 𝑘

𝑗, 𝑗 ′ ∈ J
, 𝑘
𝑗

∀

∈ J

1, . . . ,

∈ {

1, . . . ,

∈ {

,

|Y|}
.

|Y|}

(10)

(11)

(12)

(13)

Constraint (11) ensures that exactly one schedule is chosen. Con-
straint (12) ensures that all jobs use the same schedule y𝑘 . We note
that, although Problem (10) has a simpler structure compared to
Problem RAR-DDLS, it hides the complexity in the dimensionality
, which is intractable to explore.
of the exponential search space
Y
However, based on this reformulated problem, we will show next
that it is possible for one to identify a “good enough” schedule such
that the makespan can be upper bounded.

Unfortunately, Problem (10) remains an NP-hard problem. We
state this formally in Theorem 1, which can be proved based on
the reduction to the vertex coloring problem (VCP).

Theorem 1. Let 𝑛𝑔 = max𝑗 𝐺 𝑗 . Solving Problem (10) to within
-approximate ratio is NP-hard even when the exact

an 𝑂

log 𝑛𝑔
2√log log 𝑛𝑔 )

(

processing time of each job is available.

(

)

y𝑘

Proof. Here, we consider the special case with all jobs having a
= 1). We ﬁrst show that VCP can be re-
unit processing time (𝜌
duced to the job scheduling problem in Problem (14) in polynomial
time. Given an instance 𝐼 of VCP, i.e., given a graph 𝐺 =
with
bounded degree 𝑛𝑔, we can construct our job scheduling problem
, where it
as follows: i) For each node 𝑣
=
has only one schedule 𝑦 𝑗𝑣
𝐸, we add a
worker 𝑤𝑢,𝑣 to
𝑤𝑢,𝑣
}
and 𝑦 𝑗𝑣
. If the graph 𝐺 ′𝑠 maximum degree is no
greater than 𝑛𝑔, then the maximum number of workers that can
be allocated to each job is also 𝑛𝑔.

𝑉 , we create a job 𝑗𝑣
𝑢, 𝑣
(
. Also, update the scheduling as 𝑦 𝑗𝑢

∈ J
) ∈
= 𝑦 𝑗𝑢 ∪{

∈
; ii) For each edge

S
= 𝑦 𝑗𝑣 ∪ {

𝑉 , 𝐸
(

𝑤𝑢,𝑣

∅

}

)

With this reduction, we next show the solution of VCP can be
translated to the solution of Problem (14), and vice verse. First, re-
call that each job has one unit processing time. Thus, all jobs should
be executed inside a unit time interval (
, . . .). If we have
the solution to VCP, then we can schedule jobs with the same color
in the same interval. Also, if we have the solution to the job sched-
uling problem, then the jobs in the same interval can be marked as
the same color. Hence, ﬁnding an optimal solution of Problem (14)
is equivalent to ﬁnd an optimal solution of VCP.

0, 1

1, 2

)

[

[

)

,

Similarly, given an instance of job scheduling, we can construct
an instance of VCP, where the makespan equals to the number of
colors. Therefore, if we have an 𝛼-approximate solution to the job
scheduling problem, we have an 𝛼-approximate solution to VCP.
However, with the graph of degree at most 𝑛𝑔, it is known that
coloring a 2√log log 𝑛𝑔 -colorable graph with 𝑂
colors is NP-
(cid:3)
Hard. This completes the proof.

log 𝑛𝑔

(

)

The hardness result in Theorem 1 suggests that solving Prob-
lem (10) necessitates the design of approximation algorithms, which
is our goal in algorithm development next.

𝑗

)

)

(

(

y𝑘

𝑗 𝜌 𝑗

= 𝑥𝑘

3) Identify a Scheduling with Bounded Makespan: We let
be the set of GPUs allocated for job 𝑗 when schedule y𝑘 is
y𝑘
G
used. We use 𝑊 𝑘
to denote the execution time added
𝑗𝑔
to GPU 𝑔 by job 𝑗 if job 𝑗 follows schedule y𝑘 . Since each job 𝑗
only chooses one schedule, the total execution time of GPU 𝑔 can
be computed as 𝑊𝑔 =
𝑗𝑔. However, due to communication
is hard to evaluate in
contention, the exact processing time 𝜌 𝑗
computing 𝑊 𝑘
y𝑘
(
)
1 and
can be bounded as ˆ𝜌 𝑗

𝑗𝑔. Fortunately, the estimated processing time ˆ𝜌 𝑗

for some 𝑙

𝑘 𝑊 𝑘

, 𝑢𝜌 𝑗

𝑙 𝜌 𝑗

y𝑘

y𝑘

y𝑘

y𝑘

Í

Í

(

)

𝑗

(

) ∈ [

(

)

(

)]

≤

On Scheduling Ring-All-Reduce Learning Jobs in Multi-Tenant GPU Clusters with Communication Contention

MobiHoc ’22, October 17–20, 2022, Seoul, Republic of Korea

:

Y

(14)

≥

1, since 𝜏 𝑗

𝑢
replace 𝜌 𝑗
𝜋 that solves the following ILP to choose one schedule from

𝑡
[
when computing 𝑊 𝑘

y𝑘
to
)𝑢
𝑗𝑔. Consider a search algorithm

is bounded. Here, we use

ˆ𝜌 𝑗 (

y𝑘

y𝑘

𝜌 𝑗

≤

)

]

)

(

(

min

subject to. ˆ𝑊 𝑘
𝑗𝑔

1

−
= 𝑥𝑘
𝑗

ˆ𝜌 𝑗

y𝑘
(
𝑢

)

,

∀
ˆ𝑊 𝑘

𝑗

, 𝑘

∈ {

∈ J

1, . . . ,

𝑗𝑔 ≤

𝜃𝑢,

𝑔
∀

∈ N

, 𝑔

∈ N

,

(15)

(16)

|Y|}
,

Õ𝑗
Õ𝑘
1,...,
∈ J
∈{
Constraints

|Y | }
11

(

.

13
)

) − (

Note that Problem (14) has no objective function to be optimized
since we are only interested in whether a feasible solution no greater
than a given maximum execution time limit 𝜃𝑢 exists (𝜃𝑢 depends
on parameter 𝑢). Constraints (15)–(16) ensure that no GPU’s exe-
cution time would exceed 𝜃𝑢 . Let 𝑊 𝜋
𝑊𝑔 be the max-
imum execution time of all GPUs returned by algorithm 𝜋. Due to

max = max𝑔

∈N

, the solution of 𝜋 ﬁnds a lower bound
max, which is also a lower bound of the makespan under 𝜋

the use of estimated
of 𝑊 𝜋
(due to potential idling resulted from synchronization barrier).

ˆ𝜌 𝑗 (

y𝑘
)𝑢

Note that for any feasible scheduling with the upper bound 𝜃𝑢
for Problem (14), we can ﬁnd a corresponding feasible solution for
Problem (10) by setting 𝑥𝑘
= 1 if job 𝑗 follows schedule y𝑘 ; other-
𝑗
wise, set 𝑥𝑘
= 0. Thus, the challenge of solving Problem (10) be-
𝑗
comes ﬁnding a tightest execution time limit 𝜃𝑢 for Problem (14),
which is relatively easy since there is no need to explore the expo-
nential search space of schedules

Y
It is insightful to understand the choice of 𝜃𝑢 in Problem (14).
On one hand, if 𝜃𝑢 is too small, Problem (14) could be infeasible,
and no scheduling for Problem (10) can be found. On the other
hand, when 𝜃𝑢 is too large, then all schedulings can be considered,
and the gap between the optimal maximum execution time and the
optimal makespan can be large, thus no meaningful lower bound of
𝑊 𝜋
max can be found. Fortunately, since determining an appropriate
𝜃𝑢 is a univariate search, we can simply use the bisection method
to eﬃciently ﬁnd the minimum 𝜃𝑢 feasible to Problem (14).

.

]

∈ [

1, 𝑛𝑔

4) Algorithm Description: We next present our scheduling al-
gorithm based on bisection to search 𝜃𝑢 and the smallest job ﬁrst
strategy to solve Problem (14) for a given 𝜃𝑢 . Note that if a job’s
ring of workers is scheduled over a large number of servers, it
may potentially worsen communication contention with concur-
rent jobs and its communication overhead could be large. There-
fore, to control the number of active servers, we use a threshold
to control the number of maximum servers
parameter 𝜅
for scheduling jobs. We summarize our scheduling approach in Al-
gorithm 1. The intuition behind Algorithm 1 is that: 1) When the
job is small (i.e., 𝐺 𝑗
𝜅), we prefer to pack the job into servers
whose GPUs are already occupied by some other jobs rather than
opening new server(s) to host its workers. Since the job is small, the
induced contention is mild by using the shared servers. Further, by
packing its workers to these servers, we can avoid fragmentation
introduced by a small job and save space for larger jobs that will be
scheduled next. 2) If 𝐺 𝑗 > 𝜅, we prefer to allocate the job’s work-
ers to new server(s). This is because shared servers may only have
limited available GPU(s), and in order to gang-schedule a large job,

≤

(

𝑠 , ˆ𝜌 𝑗

Algorithm 1: Smallest Job First with Balanced Contention
and Overhead (SJF-BCO).
, 𝑈 𝑔
y𝑘
1 Input:
, 𝑢, 𝜆 𝑗 ;
J
)
2 Initialization: Let 𝑈 𝑔
0,
𝑠 ←
3 Sort jobs by 𝐺 𝑗 in non-decreasing order, and denote as
4 𝑚
1, 𝑟𝑖𝑔ℎ𝑡
←
5 while 𝑙𝑒 𝑓 𝑡 <= 𝑟𝑖𝑔ℎ𝑡 do
𝑟𝑖𝑔ℎ𝑡
6

←
𝑇 , y𝜃 ← ∅
2, 𝑚𝜃 ←
𝜃𝑢
)/
+
for 𝜅 = 1, 2, . . . , max𝑗 𝐺 𝑗 do
, m𝑘

, 𝑙𝑒 𝑓 𝑡

← ∅

← (

𝑇 , y

𝑙𝑒 𝑓 𝑡

𝑔, 𝑠;

←

𝑇 ;

∀

;

𝑠 ;

J

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

y𝑘
𝜃 ← ∅
for 𝑗 = 1, 2, . . . ,

1;
𝑠

𝜃 ← −
|J
𝜅 then

if 𝐺 𝑗

≤

do

|

Return y𝑗 , 𝑇𝑗 using Algorithm 2;

else

Return y𝑗 , 𝑇𝑗 using Algorithm 3;

, 𝑚𝑘

𝜃 ←

max

m𝑘

𝜃 , 𝑇𝑗

{

;

}

}

then

if y𝑗 ==
∅
break;
y𝑘
y𝑘
y𝑗
𝜃 ←
𝜃 ∪ {
< 𝑚𝜃 then
if 𝑚𝑘
𝜃
𝑚𝑘
𝑚𝜃 ←
𝜃 , y𝜃 ←
< 𝑚 then
𝑚𝜃 , y
𝜃𝑢

y𝜃 ;
1;

←
−

←

if 𝑚𝜃
𝑚
←
𝑟𝑖𝑔ℎ𝑡

else

y𝑘
𝜃 ;

𝑙𝑒 𝑓 𝑡

23
24 return m, y;

←

𝜃𝑢

1;

+

Algorithm 2: Fragment-Aware First Fit Packing (FA-FFP).

1 Input: A given job 𝑗,

y𝑘
)
available GPUs with execution time not exceed 𝜃𝑢 ;

, 𝑢, 𝜃𝑢 ;

𝑠 , ˆ𝜌 𝑗

S

(

, 𝑈 𝑔

2

G
3 if

4

5

6

𝐺 𝑗 then

𝜃𝑢
𝑖𝑑𝑙𝑒 ←
𝜃𝑢
𝑖𝑑𝑙𝑒 | ≥
|G
Pick top-𝐺 𝑗 workers with least 𝑈 𝑔
arg max𝑡
𝑇𝑗
𝑦 𝑗𝑠
{
←
𝑈 𝑔
𝑈 𝑔
y𝑘
ˆ𝜌 𝑗
𝑠 +
𝑠 ←
(
return y𝑗 , 𝑇𝑗 ;

> 0
𝑦 𝑗𝑠
|
𝑔, 𝑠

𝑡
] ∈
[
y𝑗 ;
) ∈

𝑡
[
]
𝑢,
)/

∀(

7
8 if there exists running jobs then
9
10 return

, 𝑇 ;
∅

𝑠 from
y𝑗 ,

𝜃𝑢
𝑖𝑑𝑙𝑒 as y𝑗 ;
G
𝑠, 𝑡

;

∀

}

Waiting for some job to exit and then goes to Line 2;

a large number of shared servers may be used, which leads to a
high communication overhead.

In Algorithm 1, 𝑈 𝑔

1, 𝑇

𝑠 denotes the accumulative execution time of
worker 𝑔 on server 𝑠. We ﬁrst sort jobs in non-decreasing order of
their sizes 𝐺 𝑗 in Line 3. We search 𝜃𝑢 using the bisection method
in the range
to perform scheduling
(Lines 5-7). We then iterate through each job (Line 9). If its size is
not greater than the threshold 𝜅 (Line 10), Algorithm 2 will be used
to do the scheduling (Line 11); otherwise, Algorithm 3 will be called
(Line 13). If no feasible scheduling of job 𝑗 is returned, then we quit
the current loop and update 𝜅 (Line 14); otherwise, we will update

, and use the pair

𝜃𝑢, 𝜅

]

[

)

(

MobiHoc ’22, October 17–20, 2022, Seoul, Republic of Korea

Yu and Liu, et al.

;

}

Lemma 2 (Maximum Execution Time Upperbound). Algorithm 1

produces a schedule with the maximum execution time ˆ𝑊 Alg1

max = ˜𝜃𝑢 .

y𝑘
(
𝑔 𝑈 𝑔
𝑠 /
Í

Algorithm 3: Least Busy Server-GPU First (LBSGF).
1 Input: A given job 𝑗, 𝑈 𝑔
by
2 Sort the server set

, 𝑢, 𝜆 𝑗 ;
)
𝑂𝑠 in non-decreasing order,

𝑠 , ˆ𝜌 𝑗

S

and choose the top 𝑚-servers s.t.
denote the selected server set as
𝜃𝑢
𝑖𝑑𝑙𝑒 ← ∅

;

𝑚
𝑠=1 𝑂𝑠
≥
S𝑠𝑒𝑙𝑒𝑐𝑡𝑒𝑑 ;
Í

𝜆 𝑗𝐺 𝑗 , and

∈ S𝑠𝑒𝑙𝑒𝑐𝑡𝑒𝑑 do
Sort GPUs whose 𝑈 𝑔
y𝑘
𝜃𝑢 by execution
(
time in non-decreasing order, then append them to

𝑢
)/

𝑠 +

ˆ𝜌 𝑗

≤

𝜃𝑢
𝑖𝑑𝑙𝑒

;

𝐺 𝑗 then

G
𝜃𝑢
𝑖𝑑𝑙𝑒 | ≥
|G
Pick top-𝐺 𝑗 workers with least 𝑈 𝑔
arg max𝑡
𝑇𝑗
𝑦 𝑗𝑠
{
←
𝑈 𝑔
𝑈 𝑔
y𝑘
ˆ𝜌 𝑗
𝑠 +
𝑠 ←
(
return y𝑗 ,𝑇𝑗 ;

> 0
𝑦 𝑗𝑠
|
𝑔, 𝑠

𝑡
[
] ∈
y𝑗 ;
) ∈

𝑡
[
]
𝑢,
)/

∀(

𝑠 as y𝑗 ;
y𝑗 ,

𝑠, 𝑡

∀

10
11 if there are running jobs then
12
13 return

, 𝑇 ;
∅

Waiting for some job to exit and then goes to Line 2;

3
G
4 for 𝑠

5

6 if

7

8

9

)

(

𝜃𝑢, 𝜅

the scheduling and makespan given the current
(Line 16).
Upon ﬁnishing scheduling all jobs, we will update the schedule and
makespan for the given 𝜃𝑢 if it has a smaller makespan (Lines 17-
18). After exhausting all values of 𝜅 for a given 𝜃𝑢 , we will update
the global makespan and the schedule if the current input 𝜃𝑢 has a
better performance (Lines 19-20). Also, it indicates that we can fur-
ther decrease the value of 𝜃𝑢 to ﬁnd a potentially better schedule.
Thus, we search for the left half space by moving the right pointer
(Line 21); otherwise, we should increase the value of 𝜃𝑢 by mov-
ing the left pointer (Line 23). By scheduling workers as described
in Algorithm 1, no worker’s execution time will exceed the given
limit 𝜃𝑢 . We denote the tightest execution time limit returned as
˜𝜃𝑢 .

≤

Algorithm 2 is based on the idea of “fragment-aware ﬁrst ﬁt
packing,” where we ﬁrst add all available GPUs whose 𝑈 𝑔
𝑢
𝑠 +
)/
𝜃𝑢 (Line 2). If there are enough available GPUs to schedule for
job 𝑗’s workers (Line 3), we choose top-𝐺 𝑗 GPUs with least exe-
cution time ﬁrst (Line 4). We then evaluate the completion time of
job 𝑗 (Line 5) and update the corresponding GPUs’ execution time
(Line 6); otherwise, we wait for some job to ﬁnish (Lines 8-9).

y𝑘

ˆ𝜌 𝑗

(

Algorithm 3 is based on the idea of “least busy server-GPU ﬁrst,”
where we sort the servers by its GPU’s average accumulative exe-
cution time (Line 2) and add the available GPUs whose execution
time does not exceed 𝜃𝑢 in a non-decreasing order (Lines 4-5). Here,
1 as a tuning parameter. The smaller the 𝜆 𝑗 is,
we introduce 𝜆 𝑗
the fewer number of servers can be used. If enough idle workers
can be found, we schedule the job, evaluate its completion time,
update the execution time of the chosen GPUs, and return the
schedule (Lines 6-10); otherwise, we wait for some job to ﬁnish
(Lines 11-12). If there is no running job left, then return schedule
∅
and timespan 𝑇 (as makespan) to indicate the scheduling is infea-
sible (Line 13).

≥

6 PERFORMANCE ANALYSIS
In this section, we analyze the theoretical performance of SJF-BCO.
Speciﬁcally, we will establish the approximation ratio guarantee of
our proposed SJF-BCO algorithm as follows:

1) We ﬁrst show in Lemma 2 that the maximum execution time
max ) returned by our algorithm is equal to ˜𝜃𝑢 .

(i.e., ˆ𝑊 Alg1

ˆ𝑊 Alg1
max )
(

2) We then prove that the makespan is 𝑂
3) We further show that the gap between ˜𝜃𝑢 and the tightest exe-
cution time limit 𝜃 ∗𝑢 returned by some oﬄine optimal algorithm
in the right-hand-side (RHS) of (16) is bounded in Lemma 4.
Finally, by putting all these lemmas together, we arrive at the ap-
proximation ratio result stated in Theorem 5.

in Lemma 3.

𝑗

ˆ𝜌 𝑗 (

𝑘 𝑥𝑘
𝑗

y𝑘
)𝑢

Proof. Note that in Algorithm 1, we can obtain a schedule such
that the execution time of every worker will not exceed ˜𝜃𝑢 , i.e.,
𝑔 (cf. Line 2 in Algorithm 2 and Line 5
in Algorithm 3). Note that ˜𝜃𝑢 is the tightest value found by Alg. 1
Í
since we will keep decreasing its value in the RHS of (16) until it
becomes equal to ˆ𝑊 Alg1

max in the LHS of (16). It then follows that:

˜𝜃𝑢 ,

Í

≤

∀

ˆ𝑊 Alg1

max = max

𝑔

𝑥𝑘
𝑗

ˆ𝜌 𝑗

y𝑘
(
𝑢

)

= ˜𝜃𝑢 .

∈N Õ𝑗
∈ J
Thus, we can have the maximum execution time ˆ𝑊 Alg1
˜𝜃𝑢 , and the proof is complete.

Õ𝑘
1,...,
∈{

|Y | }

max is equal to
(cid:3)

Lemma 3 (Makespan Upperbound). Algorithm 1 achieves a makespan

at most 𝑛𝑔 ˆ𝑊 Alg1

max , where 𝑛𝑔 is deﬁned as in Theorem 1.

Proof. To bound the makespan, we need to attain upper bounds
of the total busy and idle time for each worker. Recall that due
to the synchronous gang scheduling for training, the worker may
wait for other workers to ﬁnish executing other jobs before it could
start processing the current job, which may result in idling. First,
we can have the total busy time 𝑇 busy
˜𝜃𝑢 . Next, we
work on bounding the total idle time 𝑇 idle

ˆ𝑊 Alg1
max
.

Lem. 2=

𝑔

≤
𝑔

∈ N

For any worker 𝑔

, we use 𝑔𝑗 to denote the last job 𝑗 on 𝑔.
Suppose job 𝑗 follows schedule y𝑘 . At any time slot 𝑡 before worker
𝑔 processes job 𝑗, there are two cases: i) worker 𝑔 is occupied by
other jobs (i.e., 𝑔 is busy); ii) worker 𝑔 is idle, but at least one worker
is busy with executing other jobs. Since we consider
𝑔′ ∈ G
the gang-scheduling discipline, the job cannot be delayed if there is
a suﬃcient number of GPUs available as requested. Thus we have:

y𝑘

)

(

𝑗

a

)

(

𝑇 idle
𝑔

≤ Õ𝑔′ ∈G𝑗 (

y𝑘

) |

𝑔′≠𝑔

𝑇 busy
𝑔′

ˆ𝑊 Alg1
max

≤ Õ𝑔′ ∈G𝑗 (

y𝑘

) |

𝑔′≠𝑔

b

(
)
≤ (

𝐺 𝑗

1

ˆ𝑊 Alg1
max ,
)

−

y𝑘

where (a) follows from the fact that in any time slot 𝑡 that worker 𝑔
is idle (case ii), we must be able to ﬁnd at least one busy worker 𝑔′ ∈
. To calculate the idle time of worker 𝑔, we can calculate the
G
y𝑘
instead, and the limit of each
busy time of worker(s) 𝑔′ ∈ G
worker’s busy time is ˆ𝑊 Alg1
max . Also, (b) follows from the fact that at

(

(

)

)

𝑗

𝑗

On Scheduling Ring-All-Reduce Learning Jobs in Multi-Tenant GPU Clusters with Communication Contention

MobiHoc ’22, October 17–20, 2022, Seoul, Republic of Korea

most 𝐺 𝑗
can upper bound the makespan 𝑇 total as:

−

1 number of GPUs (except worker 𝑔) are busy. Then, we

𝑔

𝑇 busy
𝑔
(
+
𝐺 𝑗 ˆ𝑊 Alg1

𝑇 total = max
∈N
= max
𝑗
∈ J
and the proof is complete.

𝑇 idle
𝑔

) ≤

max
𝑗
∈ J
max = 𝑛𝑔 ˆ𝑊 Alg1
max ,

ˆ𝑊 Alg1
(cid:18)

max + (

𝐺 𝑗

1

ˆ𝑊 Alg1
max (cid:19)
)

−

(cid:3)

Next, we characterize the gap between the maximum execution
time limit ˜𝜃𝑢 and the optimal execution time 𝜃 ∗𝑢 in the RHS of (16).
Lemma 4. The maximum execution time ˜𝜃𝑢 returned by Algo-

rithm 1 satisﬁes ˜𝜃𝑢

𝜑 𝑢
𝑙

·

≤

𝜃 ∗𝑢 , where 𝜑 = max𝑗

𝜌 𝑗 (
𝜌 𝑗 (

y𝑘1
y𝑘2

,

𝑘1, 𝑘2.
∀

)
)

Proof. Let 𝑘∗ and ˜𝑘 be the schedule indices chosen by solving
y𝑘

Problem (14) optimally and Algorithm 1, respectively. Let
be the set of selected GPUs if schedule y𝑘 is used. We have

G(

)

Lem. 2=

˜𝜃𝑢

max
y ˜𝑘

∈G (

𝑔

b

(
)
≤

max
y𝑘∗

∈G (

𝑔

) Õ𝑗
∈ J

) Õ𝑗
∈ J
𝜑 𝑢

ˆ𝜌 𝑗

˜𝑘
y
(
𝑢

)

a

(
)
≤

max
y ˜𝑘

∈G (

𝑔

𝑙 ˆ𝜌 𝑗
(
𝑢

y𝑘∗

)

Eq. (16)

≤

𝜑

𝜑 𝑢

𝑙 ˆ𝜌 𝑗
(
𝑢

y𝑘∗

)

) Õ𝑗
∈ J
𝑢
𝑙

𝜃 ∗𝑢 .

(

(

)

(

y𝑘

y𝑘

y𝑘

𝑙 𝜌 𝑗

, 𝑢𝜌 𝑗

) ∈ [

To see why (a) holds, recall that for any schedule y𝑘 , we have
ˆ𝜌 𝑗
. Then, for any two diﬀerent sched-
)]
ules y𝑘1 and y𝑘2 , we can calculate the worst-case ratio as

)
) ≤
𝑢𝜌 𝑗 (
𝑙 . The inequality in (b) can be established as fol-
𝑙 𝜌 𝑗 (
lows. First, note that ˜𝑘 is chosen using the least execution time
ﬁrst scheduling strategy in Algorithm 2 (Line 4). Then, we have

)
) ≤

ˆ𝜌 𝑗 (
ˆ𝜌 𝑗 (

y𝑘1
y𝑘2

y𝑘1
y𝑘2

𝜑 𝑢

ˆ𝜌 𝑗 (

y ˜𝑘
)𝑢

ˆ𝜌 𝑗 (

y𝑘
)𝑢

𝑔

𝑗

𝑗

)

,

≤

y𝑘

y ˜𝑘

∈ J

∈G (

∈G (

) Í

max
𝑘, which
max𝑔
𝑔
can be proved by contradiction as follows. Suppose there exists
y𝑘
𝑔′ ∈
∀
. However, we know that ˜𝑘 chooses the GPUs with the least
, which contradicts
(cid:3)

G(
execution time ﬁrst, i.e., 𝑔 should be in
G(
our assumption. This completes the proof.

∈ G(
˜𝑘
y

such that

y ˜𝑘
)𝑢

y𝑘
)𝑢

) \ G(

ˆ𝜌 𝑗 (

ˆ𝜌 𝑗 (

˜𝑘
y

˜𝑘
y

∈ J

∈ J

∈ J

Í

Í

Í

≤

∀

)

)

)

,

𝑗

𝑗

Finally, by putting everything together, we have the following

approximation ratio for our proposed approach:

Theorem 5 (Approximation Ratio). Alg. 1 is 𝑛𝑔𝜑 𝑢

𝑙 -approximate.

Proof. We use 𝑇 ∗ to denote the optimal makespan that pro-

duced by some oﬄine optimal algorithm. It then follows that

𝑇 𝑡𝑜𝑡𝑎𝑙 Lem.3
≤

𝑛𝑔 ˆ𝑊 Alg1
max

Lem.2= 𝑛𝑔 ˜𝜃𝑢

Lem.4
≤

𝑛𝑔𝜑

𝑢
𝑙

𝜃 ∗𝑢

a

(
)
≤

𝑛𝑔𝜑

𝑢
𝑙

𝑇 ∗,

y𝑘
)𝑢

where (a) is due to Problem (14) estimates the processing time as
ˆ𝜌 𝑗 (
nization barrier), which implies 𝜃 ∗𝑢 ≤

without considering potential idling (caused by synchro-
𝑇 ∗. This completes the proof.
(cid:3)

Remark 1. Note that the result in Theorem 5 does not depend
explicitly on the parameter 𝜅 in SJF-BCO. This is because Theo-
rem 5 is only a worst-case upper bound that depends on ˜𝜃𝑢 , which
in turn depends on 𝜅. Hence, 𝜅 is implicitly captured in Theorem 5.

(

𝑛𝑔

|J |

SJF-BCO is 𝑂

𝑁 log 𝑁 log𝑇

Theorem 6 (Polynomial Running Time). Time complexity of
, where 𝑛𝑔 is deﬁned as in Thm. 1.

)
Proof. The sorting operation plays a dominant role in the to-
𝜅, we
tal running time in Algorithm 1. For each job 𝑗, if 𝐺 𝑗
need to sort all GPUs in the cluster, which takes 𝑂
time
in order to choose top-𝐺 𝑗 workers with least execution time ﬁrst
in Algorithm 2 (Line 4). Otherwise, we only need to sort servers,
which takes 𝑂
time in order to choose top-𝑚 servers as in
𝑆 log 𝑆
time to schedule
Algorithm 3 (Line 2). Thus, it takes 𝑂
each job since 𝑁 > 𝑆. Then, for all the jobs to be scheduled given
(𝜃𝑢, 𝜅), it has 𝑂
time complexity. Recall that we use
bisection to search 𝜃𝑢 , where each iteration contains an inner loop
. This implies a total of 𝑛𝑔 log𝑇 trials. Thus,
indexed by 𝜅
∈ [
(cid:3)
the overall time complexity is 𝑂

𝑁 log 𝑁 log𝑇

≤
𝑁 log 𝑁

𝑁 log 𝑁

𝑁 log 𝑁

1, 𝑛𝑔

(|J |

]

(

(

)

)

(

)

)

.

𝑛𝑔

(

|J |

)

7 NUMERICAL RESULTS
In this section, we conduct simulation studies to evaluate the per-
formance of our proposed SJF-BCO algorithm.

]

(

]

}

{

∀

𝑡
[

∈ [

50, 300

1000, 6000

]
) ∈ [

[21], and 𝜆 𝑗 = 1,

0.01, 0.05
y𝑘

uniformly at random.

(evaluated from the product of 𝜏 𝑗

1) Experiment Settings: Similar to the setting in [19], the work-
load is generated based on the Microsoft job trace [9]. We generate
160 DDL jobs by scaling down the original job trace [9] following
the job-type distribution, where there are 80 single-GPU jobs, 14
2-GPU jobs, 26 4-GPU jobs, 30 8-GPU jobs, 8 16-GPU jobs, and 2
32-GPU jobs. We set 𝐹 𝑗
. The extra time cost brought
by communication contention and overhead is within 15% of the
total actual execution time. We let 𝜉1 = 𝜉2 (cf. Sec. 4.1) to make
communication contention and overhead cost comparable. We set
𝜏 𝑗
𝑗. We set the estimated exe-
] ∈ [
cution time ˆ𝜌
𝑡
]
[
and 𝐹 𝑗 ). The GPU cluster has 20 servers. The number of GPUs on
4, 8, 16, 32
each server is chosen from
2) Baselines for Comparison: We compare our algorithm with
three representative job scheduling algorithms: First-Fit (FF) [17],
List-Scheduling (LS) [17], and Random (RAND) [19]. Here, we de-
ﬁne 𝜃 𝑓
𝑢 as the maximum execution time limit returned by the sched-
uling policy 𝑓 . Given a job 𝑗, FF picks the ﬁrst 𝐺 𝑗 available GPUs
such that their accumulative execution time does not exceed the
limit 𝜃 𝐹 𝐹
𝑢 , from server to server. This policy tends to pack diﬀerent
jobs into the fewest number of servers to avoid fragmentation in-
troduced by small jobs, which can save space for large jobs to be
scheduled next. LS selects top-𝐺 𝑗 GPUs with least execution time
ﬁrst, so that the accumulative execution time does not exceed the
limit 𝜃𝐿𝑆
𝑢 . Note that this policy may introduce high communication
overhead since it may choose GPUs from a large number of servers.
Further, LS tries to balance the execution time between GPUs by
always selecting the one with the least execution time. RAND ran-
domly chooses servers and GPUs to schedule jobs. In this policy,
we allocate GPUs to a job as long as it does not exceed 𝑇 , i.e., we
set 𝜃𝑅𝐴𝑁 𝐷
= 𝑇 , to avoid the long running time in order to ﬁnd a
𝑢
feasible schedule.

MobiHoc ’22, October 17–20, 2022, Seoul, Republic of Korea

Yu and Liu, et al.

Average
Bounds
Makespan

)
t
o
s

l

e
m

i
t
(

s
e
m

i
t
n
o
i
t
e
p
m
o
C

l

800

750

700

650

600

550

)
t
o
s

l

e
m

i
t
(

n
a
p
s
e
k
a
M

Turning point 2

Turning point 1

Scheduling policies

500

0

5

10

15
The value of

20

25

30

)
t

o
s

l

e
m

i
t
(

n
a
p
s
e
k
a
M

1500

1000

500

0

SJF-BCO
LS
FF
RAND

10

15
Number of servers

20

1100

1000

900

800

700

600

)
t
o
s

l

e
m

i
t
(
n
a
p
s
e
k
a
M

500

1

2

3

4

5

6

7

8

The value of

Figure 4: Makespan compari-
son under diﬀerent policies.

Figure 5: Impact of value of 𝜅
on makespan.

Figure 6: Makespan as the
number of servers increases.

Figure 7: Impact of the value
of 𝜆 on makespan.

3) Experiment Results: First, we compare the makespan per-
formance achieved by our SJF-BCO algorithm with those of the
baseline policies. We set 𝑇 = 1200. As shown in Fig. 4, SJF-BCO
outperforms other scheduling policies both in terms of makespan
and average job completion times, implying that SJF-BCO is also
superior in terms of total job completion time. Note that SJF-BCO
tends to open new server(s) for large jobs to avoid the large com-
munication overhead and use shared servers for small jobs to avoid
the fragmentation, thus achieving better average completion time
and makespan than FF and RAND. Note that SJF-BCO has more
prominent advantages over these baselines when the cluster has
limited GPU resources.

≤

Then, we examine the impact of 𝜅 on the makespan in our pro-
posed SJF-BCO algorithm. We set 𝑇 = 1200, and select 𝜅 from 1 to
32. As indicated in Fig. 5, as the value of 𝜅 increases, the makespan
ﬁrst drops and then increases and then drops again. Recall that in
Algorithm 1, FA-FFP is used when the number of requested GPUs
𝐺 𝑗
𝜅; otherwise LBSGF is used. Note that before Turning point
1 in Fig. 5, as 𝜅 increases, the makespan drops since more small
jobs are packed into the fewest number of shared servers, result-
ing in decrement of communication contention and overhead in-
troduced by larger jobs to be scheduled later. However, as 𝜅 con-
tinues to grow, communication contention becomes more notice-
able since more large jobs are scheduled to the shared servers, lead-
ing to the increase of makespan. Finally, as 𝜅 becomes suﬃciently
large, then the majority or even all jobs use shared servers to sched-
ule their workers, which can slightly decrease the communication
overhead due to the smaller resultant ring-span (see Turning point
2 in Fig. 5).

Next, we investigate the inﬂuence of communication contention
by reducing the number of servers. We set𝑇 = 1500. Intuitively, the
larger number of servers, the less communication contention. As
we can see from Fig. 6, as we increase the number of servers from
10 to 20, the makespan of FF, LS and SJF-BCO decrease due to the
degradation of contention level. Note that, if enough resources are
available in the cluster, then each job will have a separate set of
servers using SJF-BCO, i.e., its performance will become better as
number of GPUs increases. In this case, no communication con-
tention will be introduced using SJF-BCO. The intuition that FF
has the largest makespan reduction is that the average idle time
for workers drops dramatically since a smaller execution time limit
could be set as the number of servers increases.

Lastly, we inspect the inﬂuence of 𝜆 on the makespan for SJF-
and 𝜅 = 1. As we can see from Fig. 7, the

1, 2, 4, 8

BCO with 𝜆

∈ {

}

makespan monotonically decreases as the 𝜆 increases. Recall that a
larger 𝜆-value implies a larger number of servers could be selected.
Then, the job has a higher chance to open new servers to sched-
ule its workers, resulting in less communication contention and a
smaller communication overhead. Interestingly, 𝜆 plays a similar
role as 𝜅, with the aim to balance communication overhead and
contention. Speciﬁcally, 𝜅 aﬀects the overall balance between all
jobs since it determines the portion of jobs to use either FA-FFP or
LBSGF, while 𝜆 focuses more on the balance between communica-
tion contention and overhead for a speciﬁc job that uses LBSGF to
schedule.

8 CONCLUSION
In this paper, we studied resource scheduling for DDL jobs in a
multi-tenant GPU cluster, where we considered the communica-
tion contention and overhead determined by the distribution of
workers. We showed that this problem can be formulated as a highly
non-trivial non-linear integer program with nonconvex and mixed
packing-covering constraints. We then converted the problem into
a tractable integer linear program, which enables the design of
approximation algorithms. Speciﬁcally, we developed a new an-
alytical model that jointly considers the placements and starting
times of the workers of each DDL job. Through careful reformula-
tion, we then transformed the problem into an integer linear pro-
gram with a more tractable structure, and proposed an approxima-
tion algorithm with an approximation ratio performance guaran-
tee. We provided rigorous theoretical analysis and conducted ex-
periments to demonstrate the eﬃcacy of our algorithms. Collec-
tively, our results contribute to a fundamental understanding on
resource scheduling for DDL jobs in multi-tenant GPU clusters.

9 ACKNOWLEDGEMENTS
J. Liu’s work has been supported in part by NSF grants CAREER
CNS-2110259, CNS-2112471, CNS-2102233, CCF-2110252, and a Cisco
Systems Research Grant GR127298. B. Ji’s work has been supported
in part by NSF CNS-2112694. H. Rajan’s work has been supported
in part by NSF 21-20448 and NSF 19-34884.

REFERENCES
[1] Abadi, M., Barham, P., et al. TensorFlow: A system for large-scale machine

learning. In Proc. of USENIX OSDI (2016).

[2] Bao, Y., Peng, Y., and Wu, C. Deep learning-based job placement in distributed

machine learning clusters. In in IEEE INFOCOM (2019).

 
 
 
 
On Scheduling Ring-All-Reduce Learning Jobs in Multi-Tenant GPU Clusters with Communication Contention

MobiHoc ’22, October 17–20, 2022, Seoul, Republic of Korea

[3] Chau, V., Chu, X., Liu, H., and Leung, Y.-W. Energy eﬃcient job scheduling
with dvfs for cpu-gpu heterogeneous systems. In Proceedings of the Eighth Inter-
national Conference on Future Energy Systems (2017), pp. 1–11.

[4] Foley, D., and Danskin, J. Ultra-performance pascal gpu and nvlink intercon-

nect. In IEEE Micr (2017), vol. 37, pp. 7–17.

[5] Grandl, R., Chowdhury, M., Akella, A., and Ananthanarayanan, G. Altru-

istic scheduling in multi-resource clusters. In OSDI (2016).

[6] Grandl, R., Kandula, S., Rao, S., Akella, A., and Kulkarni, J. Graphene:
Packing and dependency-aware scheduling for data-parallel clusters. In OSDI
(2016).

[7] Gu, J., Chowdhury, M., Shin, K. G., Zhu, Y., Jeon, M., Qian, J., Liu, H., and
Guo, C. Tiresias: A gpu cluster manager for distributed deep learning. In NSDI
19 (2019), pp. 485–500.

[8] Hu, Z., Tu, J., and Li, B. Spear: Optimized dependency-aware task scheduling
with deep reinforcement learning. In in 2019 IEEE 39th International Conference
on Distributed Computing Systems (ICDCS) (2019).

[9] Jeon, M., Venkataraman, S., Phanishayee, A., Qian, J., Xiao, W., and Yang,
F. Analysis of large-scale multi-tenant gpu clusters for dnn training workloads.
In 2019 USENIX Annual Technical Conference (USENIX ATC 19) (2019).

[10] Mahajan, K., Balasubramanian, A., Singhvi, A., Venkataraman, S., Akella,
A., Phanishayee, A., and Chawla, S. Themis: Fair and eﬃcient gpu cluster
scheduling. In 17th USENIX Symposium on Networked Systems Design and Imple-
mentation (NSDI 20) (2020), pp. 289–304.

[11] Mei, X., Chu, X., Liu, H., Leung, Y., and Li, Z. Energy eﬃcient real-time task
scheduling on cpu-gpu hybrid clusters. In IEEE INFOCOM 2017 - IEEE Conference
on Computer Communications (2017), pp. 1–9.

[12] Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Köpf, A., Yang, E., De-
Vito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L., Bai,
J., and Chintala, S. Pytorch: an imperative style, high-performance deep learn-
ing library. In NeurIPS (2019).

[13] Patarasuk, P., and Yuan, X. Bandwidth optimal all-reduce algorithms for clus-
ters of workstations. In Journal of Parallel and Distributed Computing (2009).

[14] Peng, Y., Bao, Y., Chen, Y., Wu, C., and Guo, C. Optimus: An eﬃcient dynamic

resource scheduler for deep learning clusters. In Proc. of ACM EuroSys (2018).

[15] Sergeev, A., and Balso, M. D. Horovod: Fast and easy distributed deep learning

in tensorﬂow. In arXiv preprint arXiv:1802.05799 (2018).

[16] Shi, S., Qiang, W., and Chu, X. Performance modeling and evaluation of dis-
tributed deep learning frameworks on gpus. In The 4th International Conference
on Big Data Intelligence and Computing (DataCom) (2018), pp. 949–957.

[17] Stavrinides, G. L., and Karatza, H. D. Scheduling multiple task graphs in het-
erogeneous distributed real-time systems by exploiting schedule holes with bin
packing techniques. In Simulation Modelling Practice and Theory (2011), vol. 19,
pp. 540–552.

[18] Wang, L., Weng, Q., Wang, W., Chen, C., and Li, B. Metis: Learning to schedule
long-running applications in shared container clusters at scale. In SC20: Inter-
national Conference for High Performance Computing, Networking, Storage and
Analysis (2020), pp. 1–17.

[19] Wang, Q., Shi, S., Wang, C., and Chu, X. Communication contention aware

scheduling of multiple deep learning training jobs. In arXiv:2002.10105 (2020).

[20] Xiao, W., Bhardwaj, R., Ramjee, R., Sivathanu, M., Kwatra, N., Han, Z., Patel,
P., Peng, X., Zhao, H., Zhang, Q., Yang, F., and Zhou, L. Gandiva: Introspective
cluster scheduling for deep learning. In in 13th USENIX Symposium on Operating
Systems Design and Implementation (OSDI 18) (2018), pp. 595–610.

[21] Yu, M., Liu, J., Wu, C., Ji, B., and Bentley, E. S. Toward eﬃcient online sched-
uling for distributed machine learning systems. IEEE Transactions on Network
Science and Engineering (TNSE) (2021).

[22] Yu, M., Tian, Y., Ji, B., Wu, C., Rajan, H., and Liu, J. Gadget: Online resource
In IEEE INFOCOM

optimization for scheduling ring-all-reduce learning jobs.
(2022).

[23] Zhang, H., Zheng, Z., Xu, S., Dai, W., Ho, Q., Liang, X., Hu, Z., Wei, J., Xie,
P., and Xing, E. P. Poseidon: An eﬃcient communication architecture for dis-
tributed deep learning on gpu clusters.
In in 2017 USENIX Annual Technical
Conference (USENIX ATC 17) (2017), pp. 181–193.

