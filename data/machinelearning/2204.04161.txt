Accelerating Stochastic Sequential Quadratic Programming
for Equality Constrained Optimization using Predictive
Variance Reduction

Albert S. Berahas∗†

Jiahao Shi†

Zihong Yi‡

Baoyu Zhou§

April 12, 2022

Abstract

In this paper, we propose a stochastic method for solving equality constrained opti-
mization problems that utilizes predictive variance reduction. Speciﬁcally, we develop
a method based on the sequential quadratic programming paradigm that employs vari-
ance reduction in the gradient approximations. Under reasonable assumptions, we
prove that a measure of ﬁrst-order stationarity evaluated at the iterates generated
by our proposed algorithm converges to zero in expectation from arbitrary starting
points, for both constant and adaptive step size strategies. Finally, we demonstrate
the practical performance of our proposed algorithm on constrained binary classiﬁca-
tion problems that arise in machine learning.

1 Introduction

We consider the design of algorithms for solving equality constrained ﬁnite-sum problems
of the form

min
x∈Rn

f (x) s.t. c(x) = 0, with f (x) =

1
N

N
(cid:88)

i=1

fi(x),

(1.1)

where f : Rn → R, fi : Rn → R for all i ∈ {1, . . . , N }, and c : Rn → Rm are smooth
nonlinear (possibly nonconvex) functions. Such problems arise in a plethora of areas such
as machine/deep learning [1, 19, 22, 27, 32, 41], statistics [7, 12], and stochastic optimal

2
2
0
2

r
p
A
1
1

]

C
O
.
h
t
a
m

[

2
v
1
6
1
4
0
.
4
0
2
2
:
v
i
X
r
a

∗Corresponding author.
†Department of
com,jiahaos@umich.edu)

Industrial and Operations, University of Michigan.

(albertberahas@gmail.

‡Department of Computer Science and Engineering, University of Michigan. (zihongy@umich.edu)
§Department of Industrial and Systems Engineering, Lehigh University. (baoyu.zhou@lehigh.edu)

1

 
 
 
 
 
 
control [17, 18], as well as other science and engineering applications such as optimal power
ﬂow [37, 39, 40], multi-stage modeling [35], and porfolio optimization [38, 42].

Numerous algorithms have been developed over the last half century for solving deter-
ministic equality constrained optimization problems, such as that in (1.1). A few classical
examples are penalty methods, projection methods and sequential quadratic programming
(SQP), each of which have their associated merits and limitations [26]. Penalty methods
are intuitive and simple to implement, however, their performance critically relies on the
choice of the penalty function and penalty parameter, and, in practice, often suﬀers from
ill-conditioning issues and subproblems’ nonsmoothness. On the other hand, projection
methods are powerful feasible methods, however, they assume that projections can be ef-
ﬁciently computed at every iteration, something that is often not the case with general
nonlinear constraints. SQP methods attempt to alleviate these issues by solving a se-
quence of subproblems that minimize a quadratic model of the objective function subject
to a linearization of the constraints, and, as such can handle general nonlinear constraints,
however, this comes at the cost of more expensive iterations (SQP methods require solving
a linear system at every iteration). That being said, all aforementioned deterministic meth-
ods require the computation of the true gradient of the objective function (and constraints)
at every iteration, which can be prohibitively expensive in settings in which n and/or N
are large.

Rather than minimizing the ﬁnite-sum optimization problem (1.1) with a determin-
istic method, one can employ stochastic methods that utilize a stochastic approximation
of the gradient in lieu of the true gradient in order to reduce the per iteration compu-
tational cost.
In this direction, several stochastic penalty and projection methods have
been proposed [8, 13, 15, 16, 22, 23, 29, 36]. Following the SQP paradigm, recent work
[3] proposed a stochastic SQP method with an adaptive step size selection rule for solving
equality constrained stochastic optimization problems endowed with theoretical guarantees
(convergence in expectation) analogous of those of the stochastic gradient (SG) method
for unconstrained problems, and empirical performance superior to that of the stochastic
subgradient method. Several extensions of this work have been developed; namely, in [2]
the authors relax requirements on the constraints (relax constraint qualiﬁcations), in [10]
the authors develop an inexact stochastic SQP method (linear system solved inexactly at
every iteration), and in [9] the authors analyze the complexity of the stochastic SQP algo-
rithm proposed in [3]. Along a slightly diﬀerent direction, under the assumption that the
error in the stochastic gradient approximations employed can be diminished as needed, the
authors in [20, 21] proposed stochastic line search SQP methods for equality and inequal-
ity constrained stochastic optimization problems, respectively, that utilize a diﬀerentiable
exact augmented Lagrangian function as its merit function.

In the last decade, several stochastic ﬁrst-order algorithms have been proposed for
solving unconstrained ﬁnite-sum optimization problems. One such class of algorithms are
variance-reduction methods, that attempt to reduce the the variance in the stochastic
gradient approximation employed as the optimization progresses. Examples of popular

2

variance reduction methods include, but are not limited to, the Stochastic Average Gra-
dient (SAG/SAGA) method [11, 33], the Stochastic Variance Reduced Gradient (SVRG)
method [14], the Stochastic Recursive Gradient Algorithm (SARAH) method [25], and the
Stochastic Dual Coordinate Ascent (SDCA) method [34]. As a result of the variance re-
duction, these methods enjoy improved convergence results as compared to their classical
counter-parts (e.g., SG method [4, 30]), and these beneﬁts are very often also observed
in practice. Motivated by this fact, we design and analyze a stochastic SQP method that
employs variance reduced gradients for solving (1.1).

1.1 Contributions

The contributions of our work can be categorized as follows:

• Algorithmic. We present a stochastic sequential quadratic optimization algorithm
that uses variance reduced gradients. Speciﬁcally, inspired by the theoretical and
empirical advantages of variance reduced methods (unconstrained ﬁnite-sum prob-
lems) and SQP methods (deterministic equality constrained problems), we propose
a stochastic SQP method that uses variance reduced gradients (SVRG-type, [14])
in lieu of the true gradient (SVR-SQP). We propose one algorithm with two possible
step size selection strategies; a constant step size scheme (similar to that in SVRG
[14, 28]), and an adaptive step size scheme (similar to that in [3]).

Our proposed algorithm is based on a stochastic SQP framework, similar to the
stochastic algorithm proposed in [3], but with several distinguishing algorithmic and
theoretical diﬀerences. In particular, our proposed algorithm is of nested form, due
to the nature of the construction of the SVRG gradients, and operates with two
types of iterations (inner and outer). As a direct consequence of the use of variance
reduced gradients, the proposed step size selection strategy only requires minimal
safe-guarding, as compared to the safe-guards imposed in [3], e.g., safe-guarding
parameters or sequences and projections.

We should note that while in this work we chose to employ SVRG-type gradient
approximations, others, e.g., [11, 25, 33, 34], may also be employed. We chose SVRG
because it is based on an intuitive idea (control variates [31]), has no additional
storage requirements, has proven robust and eﬃcient in practice, and, perhaps most
importantly because the unbiasedness of the SVRG gradients allows for simple con-
vergence analysis.

• Theoretical. We provide convergence guarantees for the SVR-SQP method with
the two diﬀerent step size strategies (constant and adaptive). For both strategies,
we present strong theoretical guarantees in the sense that a measure of ﬁrst-order
stationarity evaluated at the iterates generated by SVR-SQP vanishes in expectation
with non-diminishing step size sequences. This is in contrast with the results in [3]

3

Table 1: Summary of asymptotic results for diﬀerent problem settings and diﬀerent meth-
ods (and step size choices) for nonconvex functions. For unconstrained ﬁnite sum problems
the stationarity measure is (cid:107)∇f (x)(cid:107)2
2, whereas for equality constrained ﬁnite sum problems
the stationarity measure is (cid:107)∇f (x) + ∇c(x)y(cid:107)2
2 + (cid:107)c(x)(cid:107)2 (where y are least-squares La-
grange multipliers). In the table, “exact” and “neighborhood” denote convergence to the
stationarity measure in expectation and convergence to a neighborhood of the stationarity
measure in expectation, respectively, and “-” denotes that no result exists. For brevity and
ease of exposition, we do not state the exact constants in the results below.

Setting

Method

Step size

Unconstrained
Finite Sum
Equality
Constrained
Finite Sum

SG
SVRG [14]
Stoch. SQP [3]
SVR-SQP
(this paper)

Diminishing

Constant

Adaptive

exact
-
exact

-

neighborhood
exact

-
-

neighborhood neighborhood

exact

exact

where a diminishing step size sequence is required to ensure exact convergence in
expectation. Our result (equality constrained ﬁnite sum setting) for the SVR-SQP
method with a constant step size can be viewed as analogues of the results that can
be proven for the SVRG method [14, 28] in the unconstrained ﬁnite sum setting.
Similar convergence guarantees are established for the more ﬂexible variant with
adaptive step sizes. Table 1 summarizes our results.

• Empirical. We illustrate the performance of our proposed method on constrained
binary classiﬁcation problems, and we compare our proposed algorithm against other
popular methods, such as the adaptive stochastic SQP method proposed in [3] and a
stochastic subgradient method that utilizes variance reduction. We provide evidence
illustrating the beneﬁts of using variance reduced gradients within the stochastic SQP
framework for solving equality constrained ﬁnite sum optimization problems.

1.2 Organization

The paper is organized as follows. We conclude this section by setting the notation that
will be used throughout the paper. In Section 2 we introduce the assumptions and main al-
gorithmic components of our proposed method. The stochastic variance reduced sequential
quadratic optimization method is presented in Section 3, and its associated convergence
guarantees are presented in Section 4. In Section 5, we demonstrate the empirical perfor-
mance of the proposed algorithm. Finally, in Section 6 we make some concluding remarks.

4

1.3 Notation

Let N denote the set of natural numbers, R denote the set of real numbers and R>0
denote the set of positive real numbers. For any m ∈ N, let [m] denote the set of integers
{1, . . . , m}, and [ ¯m] denote the set of integers {0, 1, . . . , m − 1}. Let Rn denote the set of
n-dimensional real vectors, Rm×n denote the set of m-by-n-dimensional real matrices, and
Sn denote the set of n-by-n-dimensional symmetric matrices.

The algorithms described in this paper will either operate with a single type of iteration
and produce sequences of iterates {xk} where k ∈ N is the index of iterations, or will
operate with two types of iterations (e.g., inner and outer) and produce sequences of
iterates {xk,s}, where k ∈ N is the index of outer iterations and s ∈ (cid:2) ¯S(cid:3) is the index
of inner iterations. The index of iteration number is also appended as a subscript to
other quantities corresponding to each iteration; e.g., fk,s = f (xk,s), respectively for the
single iteration algorithms. Throughout the paper, we use the overline to denote stochastic
quantities; e,g., ¯gk,s is an estimate of gk,s := ∇f (xk,s).

2 Assumptions and Algorithm Preliminaries

Throughout the paper, we assume that the constraint function and its associated ﬁrst-
order derivatives can be computed exactly. With regards to the objective function and
its associated derivatives, we assume that those quantities are prohibitively expensive to
compute at every iteration, however, exact evaluations can be accessed as required by the
algorithm. We formalize our assumptions with regards to (1.1) and the iterates generated
by our algorithm {xk,s} below.

Assumption 2.1. Let X ⊆ Rn be an open convex set containing the iterates {xk,s} gen-
erated by any run of the algorithm. The objective function f : Rn → R is continuously
diﬀerentiable and bounded below over X , and its gradient g := ∇f : Rn → Rn is Lips-
chitz continuous with constant L and bounded over X . For each i ∈ [m], the constraint
function ci : Rn → R is continuously diﬀerentiable and bounded over X , and its gradient
∇ci : Rn → Rn is Lipschitz continuous with constant γi ∈ R>0. We deﬁne Γ := (cid:80)m
i=1 γi.
The Jacobian function J := ∇cT : Rn → Rm×n is bounded over X , and has singular values
being bounded away from zero over X .
Remark 2.2. Under Assumption 2.1, it follows that, for all (k, s) ∈ N × (cid:2) ¯S(cid:3), there exist
positive real numbers (finf , fsup, κg, κc, κJ , κσ) ∈ R × R × R>0 × R>0 × R>0 × R>0 such that

finf ≤ fk,s ≤ fsup,
(cid:107)ck,s(cid:107)1 ≤ κc,

and

(cid:107)gk,s(cid:107)2 ≤ κg,

(cid:107)Jk,s(cid:107)2 ≤ κJ ,

(cid:107)(Jk,sJ T

k,s)−1(cid:107)2 ≤ κ−2
σ .

(2.1)

Assumption 2.1 ensures the smoothness of the objective function and constraint functions.
Unlike many projection methods aimed to solve stochastic optimization problems [24, 36],

5

we do not assume that X is bounded. We remark that the boundedness assumption of the
singular values of ∇cT guarantees the linear independence constraint qualiﬁcation (LICQ).
Note that it is generally not ideal to assume that the objective and constraint function and
derivative values are bounded over X containing stochastic iterates {xk,s}. However, this
assumption is reasonable in our problem setting if we assume the component functions {fi}
have bounded derivatives over X . In addition, this assumption can be loosen if one chooses
to use constant step sizes. This assumption is similar to those in [3, 20].

We deﬁne the Lagrangian, L : Rn × Rm → R, of (1.1) as L(x, y) := f (x) + yT c(x),
where y ∈ Rm represents a vector of Lagrange multipliers. Under Assumption 2.1 (and as
a result of LICQ), necessary conditions for ﬁrst-order stationarity with respect to (1.1) are
given by

0 =

(cid:21)
(cid:20)∇xL(x, y)
∇yL(x, y)

(cid:20)∇f (x) + ∇c(x)y
c(x)

(cid:21)

.

=

Next, we formalize our assumption on the gradient approximation employed by the
SVR-SQP method. Given an iterate xk,s ∈ Rn (where (k, s) ∈ N × (cid:2) ¯S(cid:3)), let ˜gk,s ∈ Rn be
deﬁned as

˜gk,s :=

1
b

(cid:88)

i∈Ik,s

∇fi(xk,s),

(2.2)

where Ik,s ⊂ [N ] of size b is a mini-batch (subset) of all the data. Throughout the paper,
we refer to the gradient approximation in (2.2) as the stochastic gradient.

Assumption 2.3. Each component function fi : Rn → R is continuously diﬀerentiable,
and each component gradient ∇fi : Rn → Rn is Lipschitz continuous with constant L.
Moreover, the gradient approximation (2.2) generates an unbiased estimator of the true
gradient of the objective function, i.e., we have that Ek,s[˜gk,s] = gk,s, where Ek,s denotes
the expectation taken conditioned on the event that the algorithm has reached xk,s ∈ Rn
in iteration (k, s) ∈ N × (cid:2) ¯S(cid:3). (We impose an additional condition on this expectation in
subsequent sections of the paper; see Lemma 4.2.) The unbiasedness assumption of ˜gk,s can
be easily satisﬁed, e.g., when each sample in the mini-batch Ik,s ⊂ [N ] is selected uniformly
at random.

Finally, the variance reduced gradient approximation employed by the SVR-SQP method

¯gk,s ∈ Rn is deﬁned as

¯gk,s : =

1
b

(cid:88)

i∈Ik,s

(∇fi(xk,s) − (∇fi(xk,0) − ∇f (xk,0)))

(2.3)

= ˜gk,s − ˜gk,0 + gk,0,

6

where Ik,s ⊂ [N ] of size b, and xk,0 is known as the reference point (the initial point for the
inner iterations of the kth outer iteration). Throughout the paper, we refer to the gradient
approximation in (2.3) as the SVRG gradient. Under Assumption 2.3, it follows that the
SVRG gradient is an unbiased estimate of the true gradient, i.e., Ek,s[¯gk,s] = gk,s.

3 Stochastic Variance Reduced Sequential Quadratic Pro-

gramming

Our proposed algorithm (SVR-SQP) is based on the Sequential Quadratic Programming
(SQP) paradigm. A high level description of the SVR-SQP method is as follows: SVR-SQP
operates with two types of iterations (inner and outer), employs variance reduced approxi-
mations of the gradient of the objective function following (2.3) in lieu of the true gradient,
and updates the iterates in SQP fashion.

Given an iterate xk,s for all (k, s) ∈ N × (cid:2) ¯S(cid:3), the SVR-SQP methods proceeds to compute

a search direction ¯dk,s ∈ Rn by solving the following subproblem

¯gT
k,s

¯d + 1
2

¯dT Hk,s

¯d s.t

ck,s + Jk,s

¯d = 0,

min
¯d∈Rn

(3.1)

where ¯gk,s is deﬁned in (2.3) and Hk,s ∈ Sn satisﬁes Assumption 3.1 below.

Assumption 3.1. The sequence {Hk,s} is independent of {¯gk,s} and is bounded in norm by
κH ∈ R>0. In addition, there exists a constant ζ ∈ R>0 such that, for all (k, s) ∈ N × (cid:2) ¯S(cid:3),
2 for all u ∈ Rn such that Jk,su = 0.
the matrix Hk,s has the property that uT Hk,su ≥ ζ(cid:107)u(cid:107)2
Under Assumptions 2.1 and 3.1, the solution of (3.1), denoted by ¯dk,s ∈ Rn, can be

equivalently computed by solving the following linear system of equations

(cid:20)Hk,s J T
k,s
0
Jk,s

(cid:21) (cid:20) ¯dk,s
¯yk,s

(cid:21)

= −

(cid:21)

(cid:20)¯gk,s
ck,s

,

(3.2)

where ¯yk,s ∈ Rm is the vector of associated Langrange multipliers of (3.1). The linear
system in (3.2) has a unique solution under Assumptions 2.1 and 3.1; see [26].

With a search direction ¯dk,s ∈ Rn in hand, SVR-SQP proceeds to utilize a merit function,
φ : Rn × R>0 → R, to judge the quality of the computed step (in terms of stationarity
and feasibility), and then compute a positive step size ¯αk,s ∈ R>0 in order to update the
current iterate xk,s ∈ Rn via

xk,s+1 = xk,s + ¯αk,s

¯dk,s.

(3.3)

Similar to [3], our algorithm makes use of, possibly the most common merit (penalty)
function, the l1-norm merit function, deﬁned as

φ(x, τ ) := τ f (x) + (cid:107)c(x)(cid:107)1,

(3.4)

7

where τ ∈ R>0 is known as the merit (penalty) parameter and whose value is set adaptively
as the optimization progresses. Before we proceed, we introduce two quantities that are
used in our proposed algorithm, and that are vital to the analysis. First, a local linear
model of the merit function l : Rn × R>0 × Rn × Rn → R is deﬁned by

l(x, τ, g, d) := τ (f (x) + gT d) + (cid:107)c(x) + ∇c(x)T d(cid:107)1.

(3.5)

Second, the reduction function of the local linear model of the merit function ∆l : Rn ×
R>0 × Rn × Rn → R, given d ∈ Rn with c(x) + ∇c(x)T d = 0, is deﬁned by

∆l(x, τ, g, d) := l(x, τ, g, 0) − l(x, τ, g, d) = −τ gT d + (cid:107)c(x)(cid:107)1.

(3.6)
Given a search direction ¯dk,s ∈ Rn, the merit parameter update strategy goes as follows.

To begin with, a trial merit parameter is deﬁned as

¯τ trial
k,s ←




∞



¯gT
k,s

(1−σ)(cid:107)ck,s(cid:107)1

¯dk,s+max{ ¯dT

k,sHk,s

¯dk,s,0}

¯dk,s + max{ ¯dT

k,sHk,s

if ¯gT
k,s
otherwise,

¯dk,s, 0} ≤ 0;

(3.7)

where the parameter σ ∈ (0, 1) is user-deﬁned. It follows that ¯τ trial
by Assumption 3.1 and (3.2), ¯gT
k,s
− ¯dT
k,sJ T
computed via

k,s > 0 since if (cid:107)ck,s(cid:107)1 = 0,
¯dk,s =
k,s ¯yk,s = 0. Next, for some user-deﬁned parameter (cid:15)τ ∈ (0, 1), ¯τk,s is

¯dk,s, 0} = ¯gT
k,s

¯dk,s + max{ ¯dT

k,s ¯yk,s = cT

¯dk,s + ¯dT

k,sHk,s

k,sHk,s

¯τk,s ←

(cid:40)

¯τk,s−1
(1 − (cid:15)τ )¯τ trial

k,s

if ¯τk,s−1 ≤ ¯τ trial
otherwise.

k,s

(3.8)

Note, the above rule ensures that ¯τk,s ≤ ¯τ trial
updates (3.7)–(3.8) ensure that

k,s

. Moreover, and more importantly, the

∆l(xk,s, ¯τk,s, ¯gk,s, ¯dk,s) ≥ ¯τk,s max{ ¯dT

k,sHk,s

¯dk,s, 0} + σ(cid:107)ck,s(cid:107)1.

(3.9)

The above inequality plays a critical role in our algorithm and analysis.

Finally, the SVR-SQP method computes a positive step size. We propose two diﬀerent
step size selection strategies; a constant step size strategy and an adaptive step size strat-
egy. The constant step size strategy, similar to that in [28], speciﬁes an upper bound on
acceptable step sizes (see Theorem 4.12 for the exact speciﬁcation).

The adaptive step size strategy, inspired by [3], is motivated by the desire to select
a step size that minimizes an upper bound on the change in the merit function. By the
deﬁnition of the merit function (3.4) and under Assumption 2.1, the upper bound on the
change in the merit function is a convex (strongly-convex when (cid:107) ¯dk,s(cid:107) (cid:54)= 0), piece-wise
quadratic function in ¯αk,s ∈ R>0,

φ(xk,s+1, ¯τk,s) − φ(xk,s, ¯τk,s)

≤ ¯αk,s¯τk,sgT
k,s

¯dk,s + (|1 − ¯αk,s| − 1)(cid:107)ck,s(cid:107)1 + 1

2 (¯τk,sL + Γ)¯α2

k,s(cid:107) ¯dk,s(cid:107)2
2.

(3.10)

8

(See [5, Lemma 3.1] for derivation of above inequality.) Our adaptive stategy attempts to
select a step size that approximately minimizes this upper bound. To this end, at iteration
(k, s) ∈ N × (cid:2) ¯S(cid:3), two trial step sizes are computed, speciﬁcally,

¯
(cid:98)αk,s ← min
(cid:101)αk,s ← ¯

(cid:98)αk,s −

(cid:110) ∆l(xk,s,¯τk,s,¯gk,s, ¯dk,s)
(¯τk,sLk,s+Γk,s)(cid:107) ¯dk,s(cid:107)2
2
4(cid:107)ck,s(cid:107)1
(¯τk,sLk,s+Γk,s)(cid:107) ¯dk,s(cid:107)2
2

,

, αu

and ¯

(cid:111)

β

(3.11)

(3.12)

where αu ∈ R>0 is a user-deﬁned parameter that is introduced here to avoid the step size
being arbitrarily large (the precise speciﬁcation of αu is given in Section 4.4). Due to the
nonsmoothness of the upper bound (notice, nonsmooth point at ¯αk,s = 1), the approximate
minimizer, and the step size used by the SVR-SQP, is set as

¯αk,s ←


¯
(cid:98)αk,s

1

¯
(cid:101)αk,s

if ¯
if ¯
if ¯

(cid:98)αk,s < 1
(cid:101)αk,s ≤ 1 ≤ ¯
(cid:101)αk,s > 1

(cid:98)αk,s

(3.13)

Our proposed algorithm SVR-SQP is fully described in Algorithm 1. Similar to the
SVRG method [14, 28], SVR-SQP operates with inner and outer iterations. Each outer
iteration commences with the computation of the full gradient of the objective function
at the reference point xk,0, i.e., gk,0. Given the gk,0 at every inner iteration, a stochastic
variance reduced gradient is computed via (2.3), and then paralleling the SQP paradigm,
the search direction is computed by solving the linear system given in (3.2). Finally, similar
to the stochastic SQP algorithm proposed in [3], the merit parameter is updated following
(3.7)–(3.8), a step size is computed, and the current iterate is updated. The algorithm
allows for two diﬀerent step size choices: constant step size (Option I) and adaptive step
size (Option II) via the equations (3.11)–(3.13).

Remark 3.2. Due to the nature of the SVRG gradient estimate, our proposed algorithm is
of nested nature (inner and outer iterations), and the full batch gradient is computed once
every outer iteration in order to reduce the variance of the gradient estimate. Our proposed
algorithm has two options for selecting the step size. Algorithm 1 with Option I (constant
step size) can be considered a natural extension of [28] to the equality constrained setting.
Algorithm 1 with Option II (adaptive step size) can be considered a natural extension of
[3] where the stochastic gradient estimate is replaced by the SVRG gradient estimate.

4 Convergence Analysis

In this section, we present convergence guarantees for SVR-SQP (Algorithm 1) under the two
step size regimes. We begin with some general technical lemmas (Section 4.1), then discuss
the behavior of the merit parameter (Section 4.2), and ﬁnally present our main theoretical

9

Algorithm 1 Stochastic Variance Reduced SQP (SVR-SQP)
Require: x−1,S ∈ Rn (initial iterate); ¯τ−1,S−1 ∈ R>0 (initial merit parameter value); (cid:15)τ ∈
(0, 1) (merit decrease parameter); σ ∈ (0, 1) (model reduction parameter), b ∈ [N − 1]
(batch size)

Require (Option I: Constant step size algorithm): α ∈ (0, 1] (constant step

size parameter)

Require (Option II: Adaptive step size algorithm): β ∈ (0, 1] (adaptive

step size parameter), αu ∈ R>0 (adaptive step size bound)

1: for k = 0, 1, . . . , do
2:

Set xk,0 = xk−1,S; ¯τk,−1 = ¯τk−1,S−1
Compute gradient gk,0 = ∇f (xk,0)
for s = 0, 1, . . . , S − 1 do

3:

4:

5:

6:

7:

8:

9:

10:

11:

Choose a mini-batch Ik,s ⊂ [N ] of size b, and compute ¯gk,s via (2.3)
Compute ( ¯dk,s, ¯yk,s) as the solution of (3.2)
if ¯dk,s = 0 then set xk,s+1 ← xk,s, ¯τk,s ← ¯τk,s−1; go to Line 5
end if
Set ¯τ trial
Set step size parameter ¯αk,s
Option I: Set ¯αk,s = α
Option II: Compute ¯

via (3.7) and ¯τk,s via (3.8)

(cid:101)αk,s via (3.11)–(3.12)

k,s

(cid:98)αk,s and ¯
Set ¯αk,s via (3.13)
¯dk,s

Set xk,s+1 ← xk,s + ¯αk,s

end for

12:
13: end for

results for constant and adaptive step size choices (Sections 4.3 and 4.4, respectively).
Throughout this section we assume that Assumptions 2.1, 2.3 and 3.1 hold; for brevity, we
do not remind the reader of this fact within the statement of each result.

4.1 General results

The ﬁrst lemma of this section consists of several technical conditions that are used for the
convergence analysis of the SVR-SQP method. These conditions are analogues of those in
[3, Lemma 3.4]1.

Lemma 4.1. There exists a constant κl ∈ R>0 such that the following statements hold
true for all (k, s) ∈ N × (cid:2) ¯S(cid:3):

(a) ∆l(xk,s, τk,s, gk,s, dk,s) ≥ κlτk,s(cid:107)dk,s(cid:107)2
2;

1For lemmas with proofs equivalent to those in [3], we refer interested reader to the appropriate sections.

10

(b) ∆l(xk,s, ¯τk,s, ¯gk,s, ¯dk,s) ≥ κl ¯τk,s(cid:107) ¯dk,s(cid:107)2
2;

(c) and,

φ(xk,s+1, ¯τk,s) − φ(xk,s, ¯τk,s) ≤ ¯αk,s¯τk,sgT
k,s
− (cid:107)ck,s(cid:107)1 + 1

¯dk,s + |1 − ¯αk,s|(cid:107)ck,s(cid:107)1
2 (¯τk,sL + Γ)¯α2

k,s(cid:107) ¯dk,s(cid:107)2
2.

(4.1)

Proof. First note that condition (b) is the stochastic analogue of condition (a). Conditions
(a) and (b) can be derived directly from [3, Lemmas 2.11, 2.12 & 3.4(c),(d)]. Inequality (c)
is identical to that in [3, Lemma 3.4], but accounts for the double indices of the SVR-SQP
algorithm.

In the next lemma, we bound the error in the gradient approximation ¯gk,s employed by

the SVR-SQP algorithm.

Lemma 4.2. Let ¯gk,s ∈ Rn be the gradient approximation computed by Algorithm 1 via
(2.3). Then, for all (k, s) ∈ N × (cid:2) ¯S(cid:3),

Ek,s

(cid:2)(cid:107)¯gk,s − ∇f (xk,s)(cid:107)2

2

(cid:3) ≤ Mk,s,

(4.2)

where Mk,s = L2
2, and Ek,s denotes the expectation taken conditioned on the
event that the algorithm has reached xk,0 ∈ Rn in (outer) iteration k ∈ N and xk,s in
(outer-inner) iteration (k, s) ∈ N × (cid:2) ¯S(cid:3).

b (cid:107)xk,s − xk,0(cid:107)2

Proof. For the ease of exposition, we introduce the following notation,

ζk,s = 1
b

(cid:88)

i∈Ik,s

(∇fi (xk,s) − ∇fi (xk,0)) .

(4.3)

It follows by Assumption 2.3 and (4.3) that Ek,s [ζk,s] = ∇f (xk,s) − ∇f (xk,0). By the
deﬁnition of ¯gk,s (2.3) and Assumption 2.1, and the facts that E[(cid:107)z − E[z](cid:107)2] ≤ E[(cid:107)z(cid:107)2] for
random variable z and E[(cid:107)z1 + · · · + zr(cid:107)2] = E[(cid:107)z1(cid:107)2 + · · · + (cid:107)zr(cid:107)2] for independent mean

11

zero random variables z1, . . . , zr [28],
(cid:3) = Ek,s
(cid:2)(cid:107)¯gk,s − ∇f (xk,s)(cid:107)2
= Ek,s

Ek,s

2

(cid:2)(cid:107)ζk,s + ∇f (xk,0) − ∇f (xk,s)(cid:107)2
(cid:2)(cid:107)ζk,s − Ek,s[ζk,s](cid:107)2

(cid:3)

2

2

(cid:3)





(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:88)

i∈Ik,s





(cid:88)

i∈Ik,s





(cid:88)

(cid:13)
2
(cid:13)
(cid:13)
(∇fi (xk,s) − ∇fi (xk,0) − Ek,s[ζk,s])
(cid:13)
(cid:13)
(cid:13)
2






(cid:107)∇fi (xk,s) − ∇fi (xk,0) − Ek,s[ζk,s](cid:107)2
2



(cid:107)∇fi (xk,s) − ∇fi (xk,0)(cid:107)2
2





i∈Ik,s
(cid:2)(cid:107)xk,s − xk,0(cid:107)2

2

(cid:3) = L2

b (cid:107)xk,s − xk,0(cid:107)2
2.

= 1

b2 Ek,s

= 1

b2 Ek,s

≤ 1

b2 Ek,s

≤ L2
b

Ek,s

Lemma 4.2 is one of the major diﬀerences between this work and that in [3], and in
[2, 9, 10]. Speciﬁcally, in [3] (and in [2, 9, 10]) it is assumed that the variance in the
stochastic gradients employed is bounded uniformly by a constant M ∈ R>0 (i.e., this
would be equivalent to having Mk,s = M for all (k, s) ∈ N × (cid:2) ¯S(cid:3)). This is a classical
assumption for the convergence analysis of the SG method [4, 30], which leads to the fact
that the algorithm can only converge to a neighborhood depending on M in expectation
when a constant step size is employed. By employing variance reduced gradients, this allows
us to control the variance, and diminish it as needed, in order to prove exact convergence
of ﬁrst-order stationary measure in expectation.

In the next two lemmas, we present some useful bounds pertaining to the solutions of

the linear system (3.2).
Lemma 4.3. For all (k, s) ∈ N×(cid:2) ¯S(cid:3), we always have Ek,s[ ¯dk,s] = dk,s and Ek,s[¯yk,s] = yk,s.
In addition, there exists some constant κd ∈ R>0, independent of (k, s) and any run of the
(cid:112)Mk,s.
algorithm, with Ek,s[(cid:107) ¯dk,s − dk,s(cid:107)2] ≤ κd

Proof. The proof of this lemma is similar to that in [3, Lemma 3.8]. The ﬁrst statement
follows from the facts that (i) conditioned on xk,s, the matrix on the left-hand-side of (3.2) is
deterministic; (ii) under Assumption 2.1, the matrix is invertible; (iii) under Assumption
2.3, Ek,s[¯gk,s] = ∇f (xk,s); and (iv) expectation is a linear operator. By (3.2) for any
realization ¯gk,s, it follows that

(cid:21)

(cid:20) ¯dk,s − dk,s
¯yk,s − yk,s

= −

(cid:20)Hk,s J T
k,s
0
Jk,s

(cid:21)−1 (cid:20)¯gk,s − ∇f (xk,s)
(cid:21)

0

.

(4.4)

12

The second result follows by Jensen’s inequality, the concavity of the square root, and
Lemma 4.2, and where κd ∈ R>0 is an upper bound on the norm of the matrix in (4.4).
Lemma 4.4. For all (k, s) ∈ N × (cid:2) ¯S(cid:3), it follows that

k,sdk,s ≥ Ek,s[¯gT
gT
k,s

¯dk,s] ≥ gT

k,sdk,s − ζ −1Mk,s,

(4.5)

Proof. The proof is identical to [3, Lemma 3.9 (proof)] with M replaced by Mk,s (Mk,s
deﬁned in Lemma 4.2).

We conclude this subsection by deﬁning a Lyapunov function R : Rn×Rn×R>0×R>0 →

R that will be used in the analysis. Speciﬁcally,

Rk,s := R(xk,s, xk,0, ¯τk,s, λs) = Ek,s

(cid:2)φ(xk,s, ¯τk,s) + λs(cid:107)xk,s − xk,0(cid:107)2

2

(cid:3) ,

(4.6)

where xk,s ∈ Rn and ¯τk,s ∈ R>0 are the iterate and merit parameter at outer-inner iteration
(k, s) ∈ N × (cid:2) ¯S(cid:3), respectively, xk,0 ∈ Rn is the reference point at the kth outer iteration
and λs ∈ R>0 is a parameter (deﬁned explicitly later in the analysis). The Lyapunov
function is deﬁned as the expected value of the merit function plus the distance squared
between any inner iterate and the reference iterate parameterized by a constant. When
s = 0 the Lyapunov function only involves the merit function. Moreover, the last term in
the Lyapunov function is similar to that of the upper bound in the variance of the SVRG
gradient (see Lemma 4.2), and, if the iterates converge, the Lyapunov function reduces
to the expected value of the merit function. This is by construction, and will allow us to
prove strong theoretical guarantees for SVR-SQP.

4.2 Merit Parameter behavior

The behavior of the merit parameter ¯τk,s requires careful considerations as it is a crucial
component of the SVR-SQP method and the analysis. Speciﬁcally, what is important is the
behavior of ¯τk,s for large k ∈ N. As described in [3], there are three possible outcomes for
¯τk,s: (i) converges to zero (vanishes); (ii) remains constant at a large positive value; (iii)
remains constant at a suﬃciently small positive value. We argue that in the ﬁnite-sum
setting (1.1) and under reasonable assumptions, outcome (i) is not possible, and outcome
(ii) occurs with probability zero.

To show the former, i.e., outcome (i) is not possible, we make the following assumption.

Assumption 4.5. Each component {fi} of the objective function f in (1.1) has bounded
derivatives over X deﬁned in Assumption 2.1.

The next lemmas shows that, under Assumption 4.5, merit parameters cannot vanish.

13

Lemma 4.6. Suppose Assumption 4.5 holds, then there exists ¯kτ ∈ N and ¯τconst ∈ R>0
such that ¯τk,s = ¯τconst for all k ≥ ¯kτ and s ∈ (cid:2) ¯S(cid:3).
Proof. Under Assumption 4.5, there exists gmax ∈ R>0 such that (cid:107)¯gk,s − gk,s(cid:107) ≤ gmax for
all k ≥ ¯kτ and s ∈ (cid:2) ¯S(cid:3). The desired conclusion follows using similar arguments as in [3,
Proposition 3.18].

Following a similar argument as that in [3], we argue the latter, i.e., (ii) occurs with
k,s denote the value of ¯τ trial
that is computed using gk,s
k,s

probability zero. To do so, let τ trial
and dk,s in lieu of their estimates ¯gk,s and ¯dk,s.
Lemma 4.7. Suppose event Eτ ↑ occurs in the sense that there exists inﬁnite ( ¯Kτ , ¯Sτ ) ⊆
N × (cid:2) ¯S(cid:3) and ¯τbig ∈ R>0 such that

¯τk,s = ¯τbig > τ trial

k,s

for all (k, s) ∈ ( ¯Kτ , ¯Sτ ).

(4.7)

Moreover, suppose that ¯dT
probability zero.

k,sHk,s

¯dk,s ≥ 0 for all (k, s) ∈ N × (cid:2) ¯S(cid:3). Then, Eτ,big occurs with

k,sHk,s

¯dk,s +
Proof. Under the assumption that ¯dT
¯dk,s, 0} = ¯gT
max{ ¯dT
k,s ¯yk,s. Since we are considering objectives
k,s
(cid:1) possible
as ﬁnite sum, there must only be a ﬁnite number of realizations for ¯gk,s. Among (cid:0)N
b
diﬀerent realizations of ¯gk,s, there should at least be one realization such that cT
k,s ¯yk,s is no
smaller than cT

k,syk,s since E[¯yk,s] = E[yk,s] by Lemma 4.3. Hence, we have

¯dk,s ≥ 0, by (3.2) it follows that ¯gT
k,s

¯dk,s = cT

¯dk,s + ¯dT

k,sHk,s

k,sHk,s

P[¯gT
k,s

¯dk,s + max{ ¯dT

k,sHk,s

¯dk,s, 0} ≥ gT

k,sdk,s + max{dT

k,sHk,sdk,s, 0}] ≥ 1
(N
b )

The desired conclusion then follows from [3, Proposition 3.16].

If Assumption 4.5 holds and ¯dT

¯dk,s ≥ 0 for all (k, s) ∈ N × (cid:2) ¯S(cid:3), then ¯τk,s is re-
stricted to remain constant at a suﬃciently small positive value eventually with probability
1. For the remainder of the paper, we will assume that (iii) holds, i.e., the merit parameter
remains constant at a suﬃciently small positive value. We formalize this assumption below.

k,sHk,s

Assumption 4.8. Suppose event Eτmin occurs in the sense that there exists an iteration
number ¯kτ ∈ N and a merit parameter value ¯τmin ∈ R>0 such that,
for all k ≥ ¯kτ and s ∈ (cid:2) ¯S(cid:3) .

¯τk,s = ¯τmin ≤ τ trial

(4.8)

k,s

In addition, we further assume that the stochastic gradient sequence {¯gk,s}k≥¯kτ ,s∈[ ¯S] satis-
ﬁes Ek,s,τmin[˜gk,s] = gk,s, where Ek,s,τmin denotes the expectation taken conditioned on the
event that Eτmin occurs and that the algorithm has reached xk,0 ∈ Rn in (outer) iteration
k ∈ N and xk,s in (outer-inner) iteration (k, s) ∈ N × (cid:2) ¯S(cid:3).

14

Assumption 4.8 is a critical assumption in proving the convergence of the SVR-SQP
method, and will be assumed to hold throughout the remainder of this section. For ease
of exposition, we use Ek,s to denote Ek,s,τmin, and we deﬁne the following quantity

Eτmin[·] := E[·|Assumption 4.8],

i.e., the total expectation conditioned on the event Eτmin. Moreover, we deﬁne a constant
φinf > −∞ as

φinf := inf
x∈X

φ(x, ¯τmin),

and whose existence is guaranteed under Assumptions 2.1 and 4.8.

Before we proceed, we state and prove one more technical lemma that will be used in

the analysis in Sections 4.3 and 4.4.
Lemma 4.9. Suppose that Assumption 4.8 holds. For all k ≥ ¯kτ and s ∈ (cid:2) ¯S(cid:3), it follows
that

Ek,s[∆l(xk,s, ¯τk,s, ¯gk,s, ¯dk,s)] ≤ ∆l(xk,s, ¯τmin, gk,s, dk,s) + ¯τminζ −1Mk,s.

Proof. For k ≥ ¯kτ and s ∈ (cid:2) ¯S(cid:3), it follows by (3.6) and Lemma 4.4 that
(cid:3)

Ek,s[∆l(xk,s, ¯τk,s, ¯gk,s, ¯dk,s)] = Ek,s
= Ek,s

k,s

(cid:2)−¯τmin¯gT
(cid:2)−¯τmin¯gT
k,s
−¯τmingT

¯dk,s + (cid:107)ck,s(cid:107)1
¯dk,s + ¯τmingT
k,sdk,s + (cid:107)ck,s(cid:107)1

k,sdk,s
(cid:3)

≤ ∆l(xk,s, ¯τmin, gk,s, dk,s) + ¯τminζ −1Mk,s.

4.3 Constant step size analysis

In this subsection, we present convergence results for Algorithm 1 with the constant step
size strategy (Option I) under Assumption 4.8. The ﬁrst lemma provides a useful upper
bound for the diﬀerence in merit function after a step.
Lemma 4.10. Suppose that Assumption 4.8 holds and α ∈ (0, 1]. For all k ≥ ¯kτ and
s ∈ (cid:2) ¯S(cid:3), it follows that

φ(xk,s+1, ¯τk,s) − φ(xk,s, ¯τk,s)

≤ − α∆l(xk,s, ¯τmin, gk,s, dk,s) + α2(¯τminL+Γ)

2¯τminκl

∆l(xk,s, ¯τmin, ¯gk,s, ¯dk,s)

+ α¯τmingT

k,s( ¯dk,s − dk,s).

15

Proof. For α ∈ (0, 1], k ≥ ¯kτ and s ∈ (cid:2) ¯S(cid:3), by (3.6) and Lemma 4.1(b) it follows that

φ(xk,s+1, ¯τk,s) − φ(xk,s, ¯τk,s)
¯dk,s − (cid:107)ck,s(cid:107)1) + 1

≤ α(¯τmingT
k,s
= α(¯τmingT
k,sdk,s − (cid:107)ck,s(cid:107)1) + α¯τmingT
≤ − α∆l(xk,s, ¯τmin, gk,s, dk,s) + α¯τmingT
∆l(xk,s, ¯τmin, ¯gk,s, ¯dk,s).

+ α2(¯τminL+Γ)
2¯τminκl

2 (¯τminL + Γ)α2(cid:107) ¯dk,s(cid:107)2

2

k,s( ¯dk,s − dk,s) + 1
k,s( ¯dk,s − dk,s)

2 (¯τminL + Γ)α2(cid:107) ¯dk,s(cid:107)2

2

The next lemma is the central lemma of this subsection; it provides a useful upper
bound on the expected value of the sum (over all inner and outer iterations) of the model
reduction function of the merit function.

Lemma 4.11. Suppose that Assumption 4.8 holds. Let λS = 0, and

λs = λs+1( α2L2
Λs = α − α2(¯τminL+Γ)

κlbζ + αz + 1) + α2(¯τminL+Γ)L2
2κlbζ
(α + 1
z ),
− λs+1

α
¯τminκl

2¯τminκl

,

(4.9)

for s ∈ (cid:2) ¯S(cid:3), where α ∈ (0, 1], z ∈ R>0, λs ∈ R>0 are chosen such that Λs ∈ R>0, and
Λmin = mins∈[ ¯S] Λs. Then, for all k ≥ ¯kτ and s ∈ (cid:2) ¯S(cid:3), the sequence of iterates {xk,s}
generated by Algorithm 1 (Option I) satisfy





Eτmin

1
(k−¯kτ +1)S

k
(cid:88)

S−1
(cid:88)

j=¯kτ

s=0

∆l(xj,s, ¯τmin, gj,s, dj,s)

 ≤

Eτmin [φ(x¯kτ ,0,¯τmin)]−φinf
(k−¯kτ +1)SΛmin

.

(4.10)



Proof. Consider arbitrary k ≥ ¯kτ and s ∈ (cid:2) ¯S(cid:3). By Lemmas 4.3, 4.9 and 4.10, we have

Ek,s[φ(xk,s+1, ¯τk,s)] ≤ Ek,s[φ(xk,s, ¯τk,s)] − α∆l(xk,s, ¯τmin, gk,s, dk,s)

+ (¯τminL+Γ)α2
2¯τminκl
= Ek,s[φ(xk,s, ¯τk,s)] −
+ α2(¯τminL+Γ)L2
2κlbζ

(cid:107)xk,s − xk,0(cid:107)2
2.

(cid:0)∆l(xk,s, ¯τmin, gk,s, dk,s) + ¯τminζ −1Mk,s

(cid:1)

(cid:16)

α − α2(¯τminL+Γ)

2¯τminκl

(cid:17)

∆l(xk,s, ¯τmin, gk,s, dk,s)

Moreover, by Lemmas 4.1, 4.3 and 4.9, and the fact that 2XY = 2(

√

zX)(Y /

√

z) ≤

16

zX 2 + Y 2/z for {X, Y } ⊂ R and z ∈ R>0, it follows that

Ek,s

(cid:2)(cid:107)xk,s+1 − xk,0(cid:107)2

2

(cid:3) = Ek,s
= Ek,s
≤ Ek,s

2 + 2αdT

k,s(xk,s − xk,0)

(cid:3)

2

2

(cid:2)(cid:107)xk,s+1 − xk,s + xk,s − xk,0(cid:107)2
(cid:2)α2(cid:107) ¯dk,s(cid:107)2
(cid:2)α2(cid:107) ¯dk,s(cid:107)2
2z (cid:107)dk,s(cid:107)2

(cid:3) + (cid:107)xk,s − xk,0(cid:107)2
(cid:3) + (cid:107)xk,s − xk,0(cid:107)2
2
2 (cid:107)xk,s − xk,0(cid:107)2
2 + z
2
(cid:105)
∆l(xk,s, ¯τmin, ¯gk,s, ¯dk,s)

(cid:1)

2

+ (cid:107)xk,s − xk,0(cid:107)2
2
∆l(xk,s, ¯τmin, gk,s, dk,s) + αz(cid:107)xk,s − xk,0(cid:107)2
2

+ 2α (cid:0) 1
(cid:104) α2
¯τminκl

≤ Ek,s

+ α

z¯τminκl

≤ α

¯τminκl

(cid:0)α + 1
z

(cid:16) α2L2

+

κlbζ + αz + 1

(cid:1) ∆l(xk,s, ¯τmin, gk,s, dk,s)
(cid:107)xk,s − xk,0(cid:107)2
2.

(cid:17)

Taking total expectation conditioned on the event Eτmin, for all k ≥ ¯kτ and s ∈ (cid:2) ¯S(cid:3),
combining the results above and by the deﬁnitions of λs, Rk,s and Λs and the fact that
¯τk,s+1 = ¯τk,s = ¯τmin, it follows that

Eτmin [Rk,s+1] = Eτmin

(cid:2)φ(xk,s+1, ¯τk,s+1) + λs+1(cid:107)xk,s+1 − xk,0(cid:107)2
2
≤ Eτmin [Rk,s] − ΛsEτmin [∆l(xk,s, ¯τmin, gk,s, dk,s)]
≤ Eτmin [Rk,s] − ΛminEτmin [∆l(xk,s, ¯τmin, gk,s, dk,s)] .

(cid:3)

Summing over all inner iterations (s ∈ (cid:2) ¯S(cid:3)), we have

S−1
(cid:88)

s=0

Eτmin [∆l(xk,s, ¯τmin, gk,s, dk,s)] ≤

Eτmin[Rk,0−Rk,S]
Λmin

=

Eτmin[φ(xk,0,¯τmin)−φ(xk+1,0,¯τmin)]
Λmin

.

The equality follows from the fact that λS = 0 and xk,S = xk+1,0. Summing this inequality
for j ∈ {¯kτ , ¯kτ + 1, . . . , k}, we have

k
(cid:88)

S−1
(cid:88)

j=¯kτ

s=0

Eτmin[∆l(xj,s, ¯τmin, gj,s, dj,s)] ≤

Eτmin [φ(x¯kτ ,0,¯τmin)]−φinf
Λmin

,

for which the desired conclusion (4.10) follows.

As a consequence of Lemma 4.11, in Theorem 4.12 we present the main convergence
result of this subsection, along with a speciﬁcation of the controlled parameters (e.g., step
size, inner iteration length, etc).

17

Theorem 4.12. Suppose Assumption 4.8 holds. Let λs, Λs and Λmin be deﬁned as in
Lemma 4.11. Suppose α =
, γ ∈ (0, 1],

(¯τminL+Γ)N γ ∈ (0, 1] with µ0 ∈ (0, 1], z = ¯τminL+Γ

N γ/2

µ0b

b < N γ, and S ≤






(cid:18)

b+

µ0

N 3γ/2
L2
(¯τminL+Γ)2κlζ

(cid:19)




. Then, for all k ≥ ¯kτ and s ∈ (cid:2) ¯S(cid:3), there exist

universal constants µ0 and ν0 ∈ (0, 1) such that Λmin ≥





Eτmin

1
(k−¯kτ +1)S

k
(cid:88)

S−1
(cid:88)

j=¯kτ

s=0

ν0b

(¯τminL+Γ)N γ and, for all


∆l(xj,s, ¯τmin, gj,s, dj,s)



≤

(¯τminL+Γ)N γ (Eτmin [φ(x¯kτ ,0,¯τmin)]−φinf )
(k−¯kτ +1)Sν0b

.

Proof. By the recursive deﬁnition of λs (4.9) and the fact that λS = 0, we have that
2 (¯τminL + Γ) α2L2
κlbζ

((1+ρ)S −1)
ρ

λ0 = 1

,

(4.11)

with

ρ = αz + α2L2
κlbζ
= µ0b
N 3γ/2 +
≤ µ0N −3γ/2 (cid:16)

0bL2
µ2
(¯τminL+Γ)2N 2γ κlζ
bL2
(¯τminL+Γ)2κlζ

b +

(cid:17)

,

where µ0 ∈ (0, 1] and N ≥ 1. (Note, without loss of generality, we assume that the user
deﬁned constants are chosen such that ρ ∈ (0, 1).) Plugging α and ρ into equation (4.11),
it follows that

λ0 = 1
2

L2µ2
0b
κl(¯τminL+Γ)N 2γ ζ

(1+ρ)S −1

µ0b
N 3γ/2 +

0bL2
µ2
(¯τminL+Γ)2N 2γ ζ

≤ L2µ0(e−1)

2κl(¯τminL+Γ)ζ N −γ/2,

where the inequality is obtained by noticing that for l > 0, (1+ 1
l )l is an increasing function
and (1 + 1
l )l → e as l → ∞. Hence, (1 + ρ)S ≤ e by the deﬁnition of S. Now, with the
upper bound of λ0, the fact that λs is decreasing as s increases from 0 to S, and µ0 ∈ (0, 1],
b < N and N ≥ 1, it follows that Λmin can be lower bounded by
(cid:111)
(cid:110)
− (¯τminL+Γ)α2
2¯τminκl

Λmin = min

+ α − λs+1

(α + 1
z )

α
¯τminκl

0≤s≤S−1
> − (¯τminL+Γ)α2

2¯τminκl

+ α − λ0α
¯τminκl

(α + 1
z )
0(e−1)b

L2µ2

≥ − µ0b
2¯τminκlN γ α + α −
(cid:104)
1 − µ0b
¯τminκl

≥ α

2κ2

−

l (¯τminL+Γ)2 ¯τminζ N −3γ/2α −
2κ2
(cid:105)
L2µ0(e−1)
.
l (¯τminL+Γ)2 ¯τminζ

L2µ0(e−1)
l (¯τminL+Γ)2 ¯τminζ α

2κ2

18

Let ν0 = 1 − µ0b
2¯τminκl
ν0 > 0, it follows that Λmin ≥
yields the desired result.

−

L2µ0(e−1)

l (¯τminL+Γ)2 ¯τminζ . By choosing µ0 (independent of N ) such that
κ2
(¯τminL+Γ)N γ . Combining this lower bound with Lemma 4.11

bν0

Finally, we conclude this section by presenting a corollary to Theorem 4.12; this result
shows that SVR-SQP generates a sequence of iterates whose ﬁrst order stationary measure
(corresponding to (1.1)) converges to zero.

Corollary 4.13. Under the conditions of Theorem 4.12, there exists universal constants
µ0, ν0 such that Λmin ≥

ν0b

(¯τminL+Γ)N γ and


Eτmin



1
(k−¯kτ +1)S

(cid:107)gj,s+Jj,syj,s(cid:107)2
2
κ2
H

+ (cid:107)cj,s(cid:107)2





k
(cid:88)

S−1
(cid:88)

j=¯kτ

s=0

≤

(¯τminL+Γ)N γ (Eτmin [φ(x¯kτ ,0,¯τmin)]−φinf )
(k−¯kτ +1)Sν0b

.

Moreover, if for some (k, s) ∈ N × (cid:2) ¯S(cid:3), (cid:107)xk,s − x∗(cid:107)2 ≤ δx, (cid:107)xk,0 − x∗(cid:107)2 ≤ δx,0 and
(cid:107)ck,s(cid:107)2 ≤ δc, for (δx, δx,0, δc) ∈ R>0 × R>0 × R>0, and some stationary point (x∗, y∗) ∈
Rn × Rm of (1.1), then, there exists κg∗ ∈ R>0, such that

Ek,s

(cid:20)(cid:13)
(cid:20)¯gk,s − ∇f (x∗)
(cid:13)
(cid:13)
ck,s
(cid:13)

(cid:21)(cid:13)
(cid:13)
(cid:13)
(cid:13)2

(cid:21)

≤ δy and Ek,s

(cid:2)(cid:107)¯yk,s − yk,s(cid:107)2

(cid:3) ≤ κdδy + 2κ2

dΓδx(cid:107)g∗(cid:107)

where δy = δc + L(δx,0 + δx)/
(cid:21)(cid:13)
(cid:13)
(cid:20) Hk,s J T
(cid:13)
(cid:13)
k,s
(cid:13)
(cid:13)
0
Jk,s
(cid:13)
(cid:13)

−1

.

√

b + Lδx ∈ R>0 and κd ∈ R>0 is an upper bound for

Proof. The ﬁrst part follows by Lemma 4.1 and Theorem 4.12, and the fact that by the
deterministic variant of (3.2) for all (k, s) ∈ N × (cid:2) ¯S(cid:3)

(cid:107)gk,s + Jk,syk,s(cid:107)2 ≤ (cid:107)Hk,sdk,s(cid:107)2 ≤ (cid:107)Hk,s(cid:107)2(cid:107)dk,s(cid:107)2 ≤ κH (cid:107)dk,s(cid:107)2.

The second part follows by Assumptions 2.1 and 2.3, the deﬁnitions of (δx, δx,0, δc), and

the triangle inequality that (cid:107)xk,s − xk,0(cid:107)2 ≤ (cid:107)xk,0 − x∗(cid:107)2 + (cid:107)xk,s − x∗(cid:107)2 ≤ δx,0 + δx

Ek,s

(cid:20)(cid:13)
(cid:20)¯gk,s − ∇f (x∗)
(cid:13)
(cid:13)
ck,s
(cid:13)

(cid:21)

(cid:21)(cid:13)
(cid:13)
(cid:13)
(cid:13)2

≤ (cid:107)ck,s(cid:107)2 + Ek,s [(cid:107)¯gk,s − ∇f (xk,s)(cid:107)2] + (cid:107)∇f (xk,s) − ∇f (x∗)(cid:107)2

≤ (cid:107)ck,s(cid:107)2 +

(cid:113)

Ek,s

(cid:2)(cid:107)¯gk,s − ∇f (xk,s)(cid:107)2
√

2

(cid:3) + (cid:107)∇f (xk,s) − ∇f (x∗)(cid:107)2

≤ δc + L(δx,0 + δx)/

b + Lδx = δy.

19

Let g∗ := ∇f (x∗) and c∗ := c (x∗) = 0, for xk,s suﬃciently close to x∗ there exists κg∗ ∈ R>0
such that

≤Ek,s

=Ek,s

Ek,s

(cid:3)

(cid:2)(cid:107)¯yk,s − y∗(cid:107)2
(cid:34)(cid:13)
(cid:20) Hk,s J T
(cid:13)
(cid:13)
k,s
(cid:13)
0
Jk,s
(cid:13)
(cid:34)(cid:13)
(cid:20) Hk,s J T
(cid:13)
(cid:13)
k,s
(cid:13)
0
Jk,s
(cid:13)
(cid:21)−1(cid:13)
(cid:13)
(cid:20) Hk,s J T
(cid:13)
(cid:13)
(cid:13)
(cid:13)
k,s
(cid:13)
(cid:13)
Jk,s
0
(cid:13)2
(cid:13)
(cid:13)
(cid:20) Hk,s J T
(cid:13)
(cid:13)
k,s
(cid:13)
0
Jk,s
(cid:13)

+ 2

≤

(cid:21)

−

(cid:21)−1 (cid:20) ¯gk,s
ck,s
(cid:21)−1 (cid:20) ¯gk,s − g∗

(cid:21)−1 (cid:20) g∗
c∗

(cid:20) Hk,s J T
∗
J∗
0
(cid:32)(cid:20) Hk,s J T
k,s
0
Jk,s

+

(cid:21)

(cid:35)

(cid:21)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)2

ck,s
(cid:20)(cid:13)
(cid:20) ¯gk,s − g∗
(cid:13)
(cid:13)
ck,s
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

0
J∗ − Jk,s

(cid:20)

Ek,s

(cid:21)−1(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)2

(cid:21)−1

−

(cid:20) Hk,s J T
∗
0
J∗

(cid:21)−1(cid:33) (cid:20) g∗
0

(cid:35)

(cid:21)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)2

(cid:21)

(cid:21)(cid:13)
(cid:13)
(cid:13)
(cid:13)2

(J∗ − Jk,s)T
0

(cid:21)−1(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)2

(cid:13)
(cid:20) Hk,s J T
(cid:13)
(cid:13)
k,s
(cid:13)
0
Jk,s
(cid:13)

(cid:21)−1(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)2

(cid:13)
(cid:20) g∗
(cid:13)
(cid:13)
0
(cid:13)

(cid:21)(cid:13)
(cid:13)
(cid:13)
(cid:13)2

≤κdδy + 2κ2

dΓδx(cid:107)g∗(cid:107)

where the last inequality is satisﬁed since (A+∆)−1 = A−1 −A−1∆A−1 +O((cid:107)∆(cid:107)2), and we
assume that (cid:107)∆(cid:107)2 = (cid:107)J∗−Jk,s(cid:107)2 ≤ Γδx is small enough such that O((cid:107)∆(cid:107)2) ≤ (cid:107)A−1∆A−1(cid:107)2.
This completes the proof.

Corollary 4.13 characterizes the behavior of optimality measure (cid:107)gk,s + Jk,syk,s(cid:107)2
2 and
feasibility measure (cid:107)ck,s(cid:107)2 for all k ≥ ¯kτ and s ∈ (cid:2) ¯S(cid:3). The result of Corollary 4.13 reveals
that, under the assumption that merit parameter ¯τk has stabilized at a suﬃciently small
value, both measures converge to zero in expectation, which justiﬁes our summary in Ta-
ble 1. It is important to note the diﬀerence in nature of the results of Corollary 4.13 and the
analogues proven in the unconstrained setting for the SVRG method [28]. The ﬁrst result
in Corollary 4.13 is with respect to the expectation of the averaged optimality/feasibility
measure across iterations, whereas in [28] the results are with respect the the minimal op-
timality measure ([28] considers the unconstrained setting, and so the optimality measure
is the norm of the gradient) over the iterations. One can easily derive similar convergence
results for SVR-SQP. Moreover, if the output of Algorithm 1 is uniformly chosen from (k, s),
where k ≥ ¯kτ , one can derive a bound for Eτmin
. Finally, we pro-
vide an upper bound for the error of the Lagrange multiplier estimates which is dependent
on a feasibility measure and the distances from xk,s and xk,0 to the optimal solution. As a
result, if the primal iterates converge to a feasible point and in expectation the SVRG gra-
dient approximation converges to the true gradient of the objective function at the optimal
solution, then the Lagrange multipliers also converge.

(cid:104) (cid:107)gk,s+Jk,syk,s(cid:107)2
κ2
H

+ (cid:107)ck,s(cid:107)2

(cid:105)

2

20

4.4 Adaptive step size

In this subsection, we present convergence results for Algorithm 1 with the adaptive step
size strategy (Option II in the Algorithm 1) under Assumption 4.8. The analysis in this
section is signiﬁcantly more involved than the analysis in Section 4.3 primarily due to
the stochastic nature of the step size rule ((3.11)–(3.13)). Paralleling the analysis of the
constant step size strategy, we ﬁrst provide an upper bound for the diﬀerence in merit
function after a step.
Lemma 4.14. Suppose that Assumption 4.8 holds. For all k ≥ ¯kτ and s ∈ (cid:2) ¯S(cid:3), it follows
that

φ(xk,s+1, ¯τk,s) − φ(xk,s, ¯τk,s)
≤ − ¯αk,s∆l(xk,s, ¯τmin, gk,s, dk,s) + 1

2 ¯αk,sβ∆l(xk,s, ¯τmin, ¯gk,s, ¯dk,s)

+ ¯αk,s¯τmingT

k,s( ¯dk,s − dk,s)

Proof. For k ≥ ¯kτ and s ∈ (cid:2) ¯S(cid:3), we consider three cases depending on how the step size is
set in Algorithm 1 (Option II).

Case 1: Suppose in Algorithm 1 (Option II) that ¯

(cid:98)αk,s < 1, meaning that ¯αk,s ← ¯

(cid:98)αk,s ≤

β∆l(xk,s,¯τmin,¯gk,s, ¯dk,s)
(¯τminL+Γ)(cid:107) ¯dk,s(cid:107)2
2

. It then follows from (3.9) and Lemma 4.1 that

¯dk,s, ¯τk,s) − φ(xk,s, ¯τk,s)
φ(xk,s + ¯αk,s
¯dk,s − (cid:107)ck,s(cid:107)1) + 1
≤ ¯αk,s(¯τmingT
k,s
= ¯αk,s(¯τmingT
k,sdk,s − (cid:107)ck,s(cid:107)1) + 1
= − ¯αk,s∆l(xk,s, ¯τmin, gk,s, dk,s) + 1

2 (¯τminL + Γ)¯α2
2 (¯τminL + Γ)¯α2

k,s(cid:107) ¯dk,s(cid:107)2
k,s(cid:107) ¯dk,s(cid:107)2

2
2 + ¯αk,s¯τmingT

k,s( ¯dk,s − dk,s)

2 (¯τminL + Γ)¯α2

k,s(cid:107) ¯dk,s(cid:107)2

2

+ ¯αk,s¯τmingT

k,s( ¯dk,s − dk,s)

≤ − ¯αk,s∆l(xk,s, ¯τmin, gk,s, dk,s) + 1

2 ¯αk,sβ∆l(xk,s, ¯τmin, ¯gk,s, ¯dk,s)

+ ¯αk,s¯τmingT

k,s( ¯dk,s − dk,s)

Case 2: Suppose in Algorithm 1 (Option II) that ¯

(cid:101)αk,s ≤ 1 ≤ ¯

(cid:98)αk,s, meaning that

¯αk,s ← 1 ≤ β∆l(xk,s,¯τmin,gk,s,dk,s)

(¯τminL+Γ)(cid:107) ¯dk,s(cid:107)2
2

. Similar to Case 1, it follows that

φ(xk,s + ¯αk,s

¯dk,s, ¯τk,s) − φ(xk,s, ¯τk,s)

≤ − ¯αk,s∆l(xk,s, ¯τmin, gk,s, dk,s) + 1

2 (¯τminL + Γ)¯α2

k,s(cid:107) ¯dk,s(cid:107)2

2

+ ¯αk,s¯τmingT

k,s( ¯dk,s − dk,s)

≤ − ¯αk,s∆l(xk,s, ¯τmin, gk,s, dk,s) + 1

2 ¯αk,sβ∆l(xk,s, ¯τmin, ¯gk,s, ¯dk,s)

+ ¯αk,s¯τmingT

k,s( ¯dk,s − dk,s)

21

Case 3: Suppose in Algorithm 1 (Option II) that ¯

(cid:101)αk,s > 1, meaning that ¯αk,s ← ¯

(cid:101)αk,s ≤

β∆l(xk,s,¯τmin,gk,s,dk,s)−4(cid:107)ck,s(cid:107)1
(¯τk,sL+Γ)(cid:107) ¯dk,s(cid:107)2
2

. It follows from (3.9) and Lemma 4.1 that

φ(xk,s + ¯αk,s

¯dk,s, ¯τk,s) − φ(xk,s, ¯τk,s)
¯dk,s + (¯αk,s − 1)(cid:107)ck,s(cid:107)1 − (cid:107)ck,s(cid:107)1 + 1
¯dk,s − (cid:107)ck,s(cid:107)1) + 2(¯αk,s − 1)(cid:107)ck,s(cid:107)1 + 1

≤ ¯αk,s¯τmingT
k,s
= ¯αk,s(¯τmingT
k,s
≤ ¯αk,s(¯τmingT
k,sdk,s − (cid:107)ck,s(cid:107)1) + 2¯αk,s(cid:107)ck,s(cid:107)1 + 1

2 (¯τminL + Γ)¯α2

k,s(cid:107) ¯dk,s(cid:107)2

2

2 (¯τminL + Γ)¯α2

k,s(cid:107) ¯dk,s(cid:107)2

2

2 (¯τminL + Γ)¯α2

k,s(cid:107) ¯dk,s(cid:107)2

2

+ ¯αk,s¯τmingT

k,s( ¯dk,s − dk,s)

≤ − ¯αk,s∆l(xk,s, ¯τmin, gk,s, dk,s) + 1

2 ¯αk,sβ∆l(xk,s, ¯τmin, ¯gk,s, ¯dk,s)

+ ¯αk,s¯τmingT

k,s( ¯dk,s − dk,s)

The result follows by combining the three cases.

While the upper bounds for the diﬀerence in merit function after a step for the two
step size strategies are very similar (Lemmas 4.10 and 4.14, respectively), a key diﬀer-
ence pertains to the fact step sizes computed by the adaptive algorithm (Option II) are
stochastic, and as such the last term in the bound in Lemma 4.14 is nonzero in expectation.
Moreover, due to the adaptive and stochastic nature of the step size strategy, an additional
user-deﬁned parameter αu ∈ R>0 is required. Before we proceed, we make the following
remark with regards to the selection of αu.

Remark 4.15. Under Assumption 4.8 and by Lemma 4.1(b), it follows that for all k ≥ ¯kτ
and s ∈ (cid:2) ¯S(cid:3)

∆l(xk,s,¯τmin,¯gk,s, ¯dk,s)
(¯τminL+Γ)(cid:107) ¯dk,s(cid:107)2
2

≥ κl ¯τmin

¯τminL+Γ ∈ R>0.

When the user-deﬁned parameters αu ∈ R>0 and β ∈ (0, 1] are chosen such that αuβ ≤
βκl ¯τmin
¯τminL+Γ ∈ (0, 1], it follows that Option II in Algorithm 1 always selects a constant step
size αuβ ∈ (0, 1], whose analysis has already been discussed in Section 4.3. Therefore,
under Assumption 4.8, for the rest of this subsection we only consider the case where
αu > κl ¯τmin

¯τminL+Γ and β ∈ R>0 is chosen such that βκl ¯τmin

¯τminL+Γ ∈ (0, 1].

Next, we provide upper and lower bounds for the step sizes ¯αk,s ∈ R>0 chosen by

SVR-SQP.

Lemma 4.16. Suppose that Assumption 4.8 holds. Let ¯αk,s be deﬁned as in (3.11)–(3.13),
and consider αl := κl ¯τmin
¯τminL+Γ ∈ R>0 with αl < αu. Suppose β ∈ (0, 1] is chosen such that
¯τminL+Γ ∈ (0, 1], then for all k ≥ ¯kτ and s ∈ (cid:2) ¯S(cid:3), it follows that ¯αk,s ∈ [αlβ, αuβ].
βκl ¯τmin

22

Proof. By Lemma 4.1(b), it follows that ∆l(xk,s,¯τmin,¯gk,s, ¯dk,s)
¯τminL+Γ for all k ≥ ¯kτ and
s ∈ (cid:2) ¯S(cid:3). By (3.11)–(3.13), the desired conclusion follows by considering the following three
cases.

(¯τminL+Γ)(cid:107) ¯dk,s(cid:107)2
2

≥ κl ¯τmin

(cid:110) ∆l(xk,s,¯τk,s,¯gk,s, ¯dk,s)
(¯τk,sLk,s+Γk,s)(cid:107) ¯dk,s(cid:107)2
2

(cid:111)

, αu

β < 1, in which case the

Case 1: Suppose that ¯

algorithm sets ¯αk,s = ¯

(cid:98)αk,s = min
(cid:98)αk,s. It follows that
¯τminL+Γ β ≤ min
(cid:101)αk,s = ¯

αlβ = κl ¯τmin

Case 2: Suppose that ¯

(cid:98)αk,s −
algorithm sets ¯αk,s = 1. It follows that

(cid:111)

(cid:110) κl ¯τmin

¯τminL+Γ , αu
4(cid:107)ck,s(cid:107)1
(¯τk,sLk,s+Γk,s)(cid:107) ¯dk,s(cid:107)2
2

β ≤ ¯αk,s ≤ αuβ.

≤ 1 ≤ ¯

(cid:98)αk,s, in which case the

αlβ ≤ 1 = ¯αk,s ≤ ¯

(cid:98)αk,s ≤ αuβ.

Case 3: Suppose that ¯

(cid:101)αk,s > 1, in which case the algorithm sets ¯αk,s = ¯

(cid:101)αk,s. It follows

that

αlβ ≤ 1 < ¯αk,s = ¯

(cid:98)αk,s −

4(cid:107)ck,s(cid:107)1
(¯τk,sLk,s+Γk,s)(cid:107) ¯dk,s(cid:107)2
2

≤ ¯

(cid:98)αk,s ≤ αuβ

As mentioned above, due to the adaptive (and stochastic) nature of the step size strat-
egy, the third term on the right-hand-side of the bound in Lemma 4.14 is nonzero in
expectation. We provide an upper bound for this quantity in the next lemma.
Lemma 4.17. Suppose that Assumption 4.8 holds. For all k ≥ ¯kτ and s ∈ (cid:2) ¯S(cid:3), it follows
that

(cid:2)¯αk,s¯τk,sgT

k,s( ¯dk,s − dk,s)(cid:3)

Ek,s
≤ αuκH κdβ2
2κl

∆l(xk,s, ¯τmin, gk,s, dk,s) + αu ¯τminκH κdL2

2b

(cid:107)xk,s − xk,0(cid:107)2
2.

Proof. For all k ≥ ¯kτ and s ∈ (cid:2) ¯S(cid:3), by Lemmas 4.1, 4.3 and 4.16, Cauchy–Schwarz inequality
β) ≤ βX 2 + Y 2/β for any {X, Y } ⊂ R, it follows that
and the fact of 2XY = 2(

βX)(Y /

√

√

k,syk,s)T (dk,s − ¯dk,s)(cid:3)

k,s( ¯dk,s − dk,s)(cid:3)

(cid:2)¯αk,s¯τk,sgT
(cid:2)¯αk,s¯τmin(gk,s + J T
(cid:2)¯αk,s¯τmin(−Hk,sdk,s)T (dk,s − ¯dk,s)(cid:3)

Ek,s
= Ek,s
= Ek,s
≤ αuβ ¯τminκH (cid:107)dk,s(cid:107)2Ek,s[(cid:107) ¯dk,s − dk,s(cid:107)2]
(cid:112)Mk,s
≤ αuβ ¯τminκH κd(cid:107)dk,s(cid:107)2
(cid:16) (cid:107)dk,s(cid:107)2
2β

(cid:17)

≤ αuβ ¯τminκH κd
≤ αuκH κdβ2
2κl

+ Mk,s
2β
∆l(xk,s, ¯τmin, gk,s, dk,s) + αu ¯τminκH κdL2

2b

2

(cid:107)xk,s − xk,0(cid:107)2
2.

23

Lemma 4.18 and Theorem 4.19 (below) are the analogues of Lemma 4.11 and Theo-

rem 4.12, respectively, for the adaptive step size case.

Lemma 4.18. Suppose that Assumption 4.8 holds. Let αl and αu be deﬁned as Lemma
4.16, and β ∈ (0, 1] chosen such that

βκl ¯τmin
(¯τminL+Γ) ∈ (0, 1]. In addition, let λS = 0, and

λs = λs+1(1 + z)(1 + a2
Λs = αlβ − 1

2 αuβ2 − αuκH κdβ2

uβ2L2
κlzbζ ) + αu ¯τminL2

2b

(κH κd + β2
ζ )

− λs+1(1 + z) α2

uβ2
¯τminκlz

(4.12)

2κl
for s ∈ (cid:2) ¯S(cid:3), where β, z ∈ R>0, λs ∈ R>0 are chosen such that Λs ∈ R>0, and Λmin =
mins∈[ ¯S] Λs. Then, for all k ≥ ¯kτ and s ∈ (cid:2) ¯S(cid:3), the sequence of iterates {xk,s} generated by
Algorithm 1 (Option II) satisfy





Eτmin

1
(k−¯kτ +1)S

k
(cid:88)

S−1
(cid:88)

j=¯kτ

s=0

∆l(xj,s, ¯τmin, gj,s, dj,s)

 ≤

Eτ,small[φ(x¯kτ ,0,¯τmin)]−φinf
(k−¯kτ +1)SΛmin

.

(4.13)



Proof. Consider arbitrary k ≥ ¯kτ and s ∈ (cid:2) ¯S(cid:3). By Lemmas 4.2, 4.9, 4.17, we have

Ek,s[φ(xk,s+1, ¯τk,s)]

≤ Ek,s[φ(xk,s, ¯τk,s)] − αlβ∆l(xk,s, ¯τmin, gk,s, dk,s)

+ 1

2 αuβ2Ek,s[∆l(xk,s, ¯τmin, ¯gk,s, ¯dk,s)] + Ek[¯αk,s¯τk,sgT

k,s( ¯dk,s − dk,s)]

≤ Ek,s[φ(xk,s, ¯τk,s)] − β

(cid:16)

+ αu ¯τminL2
2b

(cid:16)

κH κd + β2
ζ

(cid:17)

αl − 1
(cid:17)

2 αuβ − αuκH κdβ

2κl
(cid:107)xk,s − xk,0(cid:107)2.

∆l(xk,s, ¯τmin, gk,s, dk,s)

Moreover, similar to the proof of lemma 4.11, we have

Ek,s[(cid:107)xk,s+1 − xk,0(cid:107)2
2]

¯dk,s(cid:107)2

2 + (cid:107)xk,s − xk,0(cid:107)2

= Ek,s[(cid:107)xk,s+1 − xk,s + xk,s − xk,0(cid:107)2
2]
= Ek,s[(cid:107)¯αk,s
≤ Ek,s
≤ (1 + z) a2
≤ (1 + z) a2

(cid:2)(cid:107)(1 + 1
uβ2
¯τminκlz
uβ2
¯τminκlz ∆l(xk,s, ¯τmin, gk,s, dk,s) +

z )¯αk,s
Ek,s

2 + 2¯αk,s

¯dT
k,s(xk,s − xk,0)]

¯dk,s(cid:107)2 + (1 + z)(cid:107)xk,s − xk,0(cid:107)2(cid:3)
(cid:2)∆l(xk,s, ¯τmin, ¯gk,s, ¯dk,s)(cid:3) + (1 + z)(cid:107)xk,s − xk,0(cid:107)2

(cid:104)

1 + z + (1 + z) a2

uβ2L2
κlzbζ

(cid:105)

(cid:107)xk,s − xk,0(cid:107)2.

Taking total expectation conditioned on Eτmin, for all k ≥ ¯kτ and s ∈ (cid:2) ¯S(cid:3), combining

24

the results above and the deﬁnitions of λs, Λs, it follows that

≤ Eτmin[φ(xk,s, ¯τk,s)] +

Eτmin[Rk,s+1] = Eτmin[φ(xk,s+1, ¯τk,s) + λs+1(cid:107)xk,s+1 − xk,0(cid:107)2]
uβ2L2
κlzbζ )
Eτmin[(cid:107)xk,s − xk,0(cid:107)2]
− λs+1(1 + z) a2

λs+1(1 + z)(1 + a2
(cid:105)
(κH κd + β2
ζ )
2 auβ2 − αuκH κdβ2

+ αu ¯τminL2
2b

alβ − 1

−

(cid:16)

(cid:104)

2κl

uβ2
¯τminκlz

(cid:17)

Eτmin[∆l(xk,s, ¯τmin, gk,s, dk,s)]

≤ Eτmin[Rk,s] − ΛsEτmin[∆l(xk,s, ¯τmin, gk,s, dk,s)]
≤ Eτmin[Rk,s] − ΛminEτmin[∆l(xk,s, ¯τmin, gk,s, dk,s)].

Summing over all inner iterations (s ∈ (cid:2) ¯S(cid:3)), we have

S−1
(cid:88)

s=0

Eτmin[∆l(xk,s, ¯τmin, gk,s, dk,s)] ≤

Eτmin [Rk,0−Rk,S ]
Λmin

=

Eτmin [φ(xk,0,¯τmin)−φ(xk+1,0,¯τmin)]
Λmin

.

The equality follows from the fact that λS = 0 and xk,S = xk+1,0. The desired conclusion
(4.13) then follows by summing this inequality for j ∈ {¯kτ , ¯kτ + 1, . . . , k}.

As a consequence of Lemma 4.18, in Theorem 4.19 we present the main convergence

result of this subsection.

Theorem 4.19. Suppose Assumption 4.8 holds. Let λs, Λs and Λmin be deﬁned as in
Lemma 4.18. Suppose β =
, and S ≤








. Deﬁne the quantity Λmin = mins Λs. Then for

(¯τminL+Γ)N γ ∈ (0, 1] with µ1 ∈ (0, 1], z = ¯τminL+Γ

N γ/2

µ1b

(¯τminL+Γ)+

1a2
µ2
(¯τminL+Γ)2κlζ
b < N γ, there exists universal constants µ1, ν1 such that: Λmin ≥

1a2
µ2
(¯τminL+Γ)3κlζ

uL2b

+

N γ/2
uL2b

ν1b

(¯τminL+Γ)N γ and






Eτmin

1
(k−¯kτ +1)S

k
(cid:88)

S−1
(cid:88)

j=¯kτ

s=0

∆l(xj,s, ¯τmin, gj,s, dj,s)



≤

(¯τminL+Γ)N γ (Eτmin [φ(x¯kτ ,0,¯τmin)]−φinf )
(k−¯kτ +1)Sν1b

.

Proof. By the recursive deﬁnition of λs and the fact that λS = 0, we have that

λ0 = (κH κd + β2

ζ ) αu ¯τminL2

2b

(1+ρ)S −1
ρ

,

(4.14)

25

with

It follows that

ρ = z + (1 + z) a2

uβ2L2
κlzbζ
= (¯τminL + Γ)N −γ/2 + ( N γ/2
(¯τminL + Γ) + µ2

≤

(cid:16)

1a2
µ2
¯τminL+Γ + 1)
(¯τminL+Γ)2κlN 2γ ζ
uL2b
1a2
(¯τminL+Γ)3κlζ + µ2
(¯τminL+Γ)2κlζ

uL2b

uL2b

1a2

(cid:17)

N −γ/2

λ0 ≤ αu ¯τminL2

2b

(κH κd +

1b2
µ2
(¯τminL+Γ)2N 2γ ζ )

e−1
(¯τminL+Γ)N −γ/2

where the inequality is obtained by noticing that for l > 0, (1+ 1
l )l is an increasing function
and (1 + 1
l )l → e as l → ∞. Hence, (1 + ρ)S ≤ e by the deﬁnition of S. Now, with the
upper bound of λ0, the fact that λs is decreasing as s increases from 0 to S, and µ0 ∈ (0, 1]
and N ≥ 1, we can lower bound Λmin as

Λmin = min

(cid:110)

αlβ − 1

2 αuβ2 − αuκH κdβ2

2κl

− λs+1(1 + z) α2

uβ2
¯τminκlz

(cid:111)

0≤s≤S−1
> αlβ − 1
(cid:104)
αl −
− α3
uL2κH κd(e−1)µ1
2κl(¯τminL+Γ)2N γ/2 − α3

2 αuβ2 − αuκH κdβ2
2κl
2(¯τminL+Γ)N γ − αuκH κdµ1

− λ0(1 + z) α2
2κl(¯τminL+Γ)N γ − α3
− α3
u ¯τminL2b2(e−1)µ1
2(¯τminL+Γ)5N 2γ ζκl

uβ2
¯τminκlz

αubµ1

≥ β

uL2κH κd(e−1)µ1
2κl(¯τminL+Γ)3
u ¯τminL2b2(e−1)µ1
2(¯τminL+Γ)4N 5γ/2ζκl

(cid:105)

u ¯τminL2b2(e−1)µ1
2(¯τminL+Γ)5N 2γ ζκl

Let ν1 = αl −
− α3
ν1 > 0, it follows that Λmin ≥
yields the desired result.

− α3

αubµ1

2(¯τminL+Γ)N γ − αuκH κdµ1

2κl(¯τminL+Γ)N γ − α3

2κl(¯τminL+Γ)3 − α3
uL2κH κd(e−1)µ1

uL2κH κd(e−1)µ1
2κl(¯τminL+Γ)2N γ/2

u ¯τminL2b2(e−1)µ1
2(¯τminL+Γ)4N 5γ/2ζκl

. By choosing µ1 (independent of N ) such that
(¯τminL+Γ)N γ . Combining this lower bound with Lemma 4.11

bν1

We conclude this section by noting that an analogue of Corollary 4.13 can be proven
for the case in which adaptive step sizes are utilized. For brevity we omit this corollary
since it is identical to Corollary 4.13 up to constants.

5 Numerical Results

In this section, we demonstrate the empirical performance of a Matlab implementation of
Algorithm 1, with both Options I and II, for solving equality constrained binary classiﬁ-
cation machine learning problems. Speciﬁcally, we consider constrained logistic regression
problems (datasets from the LIBSVM collection [6]) with linear equality constraints or an
(cid:96)2 norm squared constraint.

26

In order to illustrate the merits of our proposed algorithm, we compared two variants of
the SVR-SQP method (constant step sizes SVR-SQP-C and adaptive steps sizes SVR-SQP-A )
with the stochastic SQP method from [3] (Sto-SQP) and a Stochastic Subgradient method
that utilizes SVRG-type variance reduced gradient approximations (Sto-Subgrad-VR). The
goals of this section can be summarized as follows: (1) illustrate the power and robustness of
the adaptive step size variant of the SVR-SQP method; (2) show the advantages of utilizing
variance reduced gradient approximations; (3) demonstrate the advantage of the SQP
paradigm over a simple stochastic subgradient method; and, (4) show the robustness of
the SVR-SQP method to user-deﬁned parameters such as the inner iteration length (S) and
the adaptive step size parameter (β).

5.1 Problem Speciﬁcation, Implementation Details and Evaluation Met-

rics

Throughout this section we consider the following two constrained binary classiﬁcation
problems:

min
x∈Rn

f (x) =

min
x∈Rn

f (x) =

1
N

1
N

N
(cid:88)

i=1
N
(cid:88)

i=1

(cid:16)

(cid:16)

log

log

1 + e−yi(X T

i x)(cid:17)

s.t. Ax = a1

1 + e−yi(X T

i x)(cid:17)

s.t. (cid:107)x(cid:107)2

2 = a2

(5.1)

(5.2)

where X ∈ RN ×n is the data matrix (containing feature data for N data points; Xi repre-
senting the ith column of X) and y ∈ {−1, 1}N are the labels (for each data point), and
A ∈ Rm×n, a1 ∈ Rm and a2 = 1 ∈ R>0 deﬁne the constraints. We consider 10 datasets,
listed in Table 2, from the LIBSVM collection [6]. For the linear constraints (5.1), we
generated normal random A and a1 for each problem with m = 10.

Table 2: Binary classiﬁcation data set details. For more information see [6].

dataset

dimension (nnn)

datapoints (NNN )

a9a
australian
heart
ijcnn1
ionosphere
mushrooms
phising
sonar
splice
w8a

123
14
13
22
34
112
68
60
60
300

32, 561
690
270
49, 990
351
8, 124
11, 055
208
1, 000
49, 749

A budget of 30 epochs (i.e., number of eﬀective passes over the dataset; equivalent to the
number of gradient evaluations of the objective function) was used for all methods. For all

27

problems and algorithms, the initial primal iterate (x0) was set to a normal random vector
scaled to have norm 0.1, and the multipliers were initialized as y0 = arg miny∈Rm (cid:107)g0 +
0 y(cid:107)2. For each method, we considered two batch sizes b = 16 (small batch) and b = 128
J T
(large batch). For each problem, dataset, algorithm and batch size, we ran 10 instances
with diﬀerent random seeds. With regards to the Lipszchitz constant estimates, we used
Γk,s = 0 and Γk,s = 2 for all k ∈ N and s ∈ (cid:2) ¯S(cid:3) to problems (5.1) and (5.2), respectively,
for all algorithms. We set Lk,s = L for all k ∈ N and s ∈ (cid:2) ¯S(cid:3) for all algorithms, where L
was estimated by diﬀerences of gradients around the initial iterate.

The details of all parameter settings are given below.

• SVR-SQP-C and SVR-SQP-A: σ = 0.5, θ = 104, ¯τ−1,0 = 0.1, and (cid:15)τ = 10−6

– SVR-SQP-C [Algorithm 1; constant step sizes]:

¯αk,s = α ∈ {10−3, 10−2, 10−1, 100, 101} for all (k, s) ∈ N × (cid:2) ¯S(cid:3);

– SVR-SQP-A [Algorithm 1; adaptive step sizes]: ¯αk,s computed via (3.11)–(3.13)

for all (k, s) ∈ N × (cid:2) ¯S(cid:3), αu = 106, β = 1.

• Sto-SQP [3, Algorithm 3.1]: θ = 104, ¯τ−1 = 0.1, (cid:15)τ = 10−6, ¯ξ−1 = 0.1, (cid:15)ξ = 10−2,

σ = 0.5, and βk = β ∈ {10−3, 10−2, 10−1, 100, 101} for all k ∈ N.

• Sto-Subgrad-VR: ¯αk,s = α

τ L+Γ with α ∈ {10−3, 10−2, 10−1, 100, 101} and τk,s = τ ∈
{10−10, 10−9, . . . , 100} for all (k, s) ∈ N × (cid:2) ¯S(cid:3). We should note that Sto-Subgrad-VR
applies the SVRG algorithm [14] to directly minimize the nonsmooth merit func-
tion (3.4); SVRG directly applied to the smooth part of merit function with the
subgradient of the nonsmooth part added.

For all algorithms with inner outer iterations, the inner itereation length was set as S =
(cid:4) N
2n

(cid:5), unless otherwise speciﬁed.
In all of our experiments, results are given in terms of feasibility and stationarity errors
discussed below. We present the evolution of these measures with respect to epochs in
Figures 1, 3, 4 and 5. Moreover, in Figure 2 and Tables 3 and 4, we report the error
metrics at the best iterate found within the budget deﬁned as follows. Given a ﬁxed epoch
budget, assume we have k ∈ {0, . . . , K} for some K ∈ N. If

min{(cid:107)ck(cid:107)∞ : k = 0, . . . , K} > 10−6,

then xbest ← arg min

(cid:107)ck(cid:107)∞.

xk∈{x0,...,xK }

Otherwise, if min{(cid:107)ck(cid:107)∞ : k = 0, . . . , K} ≤ 10−6, then we set

xbest ← arg min

xk∈{x0,...,xK }

(cid:107)∇fk + J T

k yk,ls(cid:107)∞ s.t. (cid:107)ck(cid:107)∞ ≤ 10−6,

where yk,ls is the least-squares multiplier at xk. Given xbest and the corresponding
dual variables ybest,ls, we report feasibility error ((cid:107)c(xbest)(cid:107)∞) and stationarity error
((cid:107)∇f (xbest) + ∇c(xbest)ybest,ls(cid:107)∞).

28

5.2 Comparison: SVR-SQP-C and SVR-SQP-A

In this section, we compare the performance of SVR-SQP-C and SVR-SQP-A on (5.1) and
(5.2). We ran all methods for 30 epochs with two diﬀerent batch sizes. For SVR-SQP-C we
tuned the step size ¯αk,s = α ∈ {10−3, 10−2, 10−1, 100, 101} for all (k, s) ∈ N × (cid:2) ¯S(cid:3). For the
SVR-SQP-A we set β = 1. For both methods we used S = (cid:4) N
2n

Figures 1a and 1b show the stationarity and feasibility errors versus epochs for two
datasets (australian and splice) for the SVR-SQP-C (with diﬀerent values of α) and
SVR-SQP-A (with β = 1) methods with diﬀerent batch sizes. For each method, the ﬁgure
shows the average trajectory (solid line) over the 10 random seeds of the measures with
respect to epochs, and the 95% conﬁdence interval (dashed lines). As is clear, SVR-SQP-A
appears to be competitive with the best tuned version of the SVR-SQP-C method. Similar
behavior was observed on other datasets. Figure 2 presents boxplots for all datasets showing
the feasibility and stationarity errors for the best iterates generated by the methods.

(cid:5).

29

(a) australian dataset. Top row: feasibility error; Bottom row: stationarity error.

(b) splice dataset. Top row: feasibility error; Bottom row: stationarity error.

1:

Performance

∈
SVR-SQP-C with
Figure
{10−3, 10−2, 10−1, 100, 101} and SVR-SQP-C on logistic regression problems with lin-
ear (columns 1 and 2) and (cid:96)2 norm (columns 3 and 4) constraints. First and third
columns: batch size 16; Second and fourth columns: batch size 128.

sizes α

diﬀerent

step

of

30

051015202530Number of Epochs10-810-610-410-2100102Feasibility Error = 10-3 = 10-2 = 10-1 = 100 = 101SVR-SQP-A051015202530Number of Epochs10-810-610-410-2100102Feasibility Error = 10-3 = 10-2 = 10-1 = 100 = 101SVR-SQP-A051015202530Number of Epochs10-810-610-410-2100102Feasibility Error = 10-3 = 10-2 = 10-1 = 100 = 101SVR-SQP-A051015202530Number of Epochs10-810-610-410-2100102Feasibility Error = 10-3 = 10-2 = 10-1 = 100 = 101SVR-SQP-A051015202530Number of Epochs10-810-610-410-2100102Stationarity Error = 10-3 = 10-2 = 10-1 = 100 = 101SVR-SQP-A051015202530Number of Epochs10-810-610-410-2100102Stationarity Error = 10-3 = 10-2 = 10-1 = 100 = 101SVR-SQP-A051015202530Number of Epochs10-810-610-410-2100102Stationarity Error = 10-3 = 10-2 = 10-1 = 100 = 101SVR-SQP-A051015202530Number of Epochs10-810-610-410-2100102Stationarity Error = 10-3 = 10-2 = 10-1 = 100 = 101SVR-SQP-A051015202530Number of Epochs10-810-610-410-2100102Feasibility Error = 10-3 = 10-2 = 10-1 = 100 = 101SVR-SQP-A051015202530Number of Epochs10-810-610-410-2100102Feasibility Error = 10-3 = 10-2 = 10-1 = 100 = 101SVR-SQP-A051015202530Number of Epochs10-810-610-410-2100102Feasibility Error = 10-3 = 10-2 = 10-1 = 100 = 101SVR-SQP-A051015202530Number of Epochs10-810-610-410-2100102Feasibility Error = 10-3 = 10-2 = 10-1 = 100 = 101SVR-SQP-A051015202530Number of Epochs10-810-610-410-2100102Stationarity Error = 10-3 = 10-2 = 10-1 = 100 = 101SVR-SQP-A051015202530Number of Epochs10-810-610-410-2100102Stationarity Error = 10-3 = 10-2 = 10-1 = 100 = 101SVR-SQP-A051015202530Number of Epochs10-810-610-410-2100102Stationarity Error = 10-3 = 10-2 = 10-1 = 100 = 101SVR-SQP-A051015202530Number of Epochs10-810-610-410-2100102Stationarity Error = 10-3 = 10-2 = 10-1 = 100 = 101SVR-SQP-A(a) a9a; left (5.1), right (5.2)

(b) australian; left (5.1), right (5.2)

(c) heart; left (5.1), right (5.2)

(d) ijcnn1; left (5.1), right (5.2)

(e) ionosphere; left (5.1), right (5.2)

(f) mushrooms; left (5.1), right (5.2)

(g) phishing; left (5.1), right (5.2)

(h) sonar; left (5.1), right (5.2)

(i) splice; left (5.1), right (5.2)

(j) w8a; left (5.1), right (5.2)

Figure 2: Best feasibility and stationarity errors, for SVR-SQP-C and SVR-SQP-A on (5.1)
and (5.2)

.

31

SVR-SQP-C = 10-3SVR-SQP-C = 10-2SVR-SQP-C = 10-1SVR-SQP-C = 100SVR-SQP-C = 101SVR-SQP-AMethod10-810-610-410-2100102Feasibility/Stationarity ErrorFeasibility (b=16)Stationarity (b=16)Feasibility (b=128)Stationarity (b=128)SVR-SQP-C = 10-3SVR-SQP-C = 10-2SVR-SQP-C = 10-1SVR-SQP-C = 100SVR-SQP-C = 101SVR-SQP-AMethod10-810-610-410-2100102Feasibility/Stationarity ErrorFeasibility (b=16)Stationarity (b=16)Feasibility (b=128)Stationarity (b=128)SVR-SQP-C = 10-3SVR-SQP-C = 10-2SVR-SQP-C = 10-1SVR-SQP-C = 100SVR-SQP-C = 101SVR-SQP-AMethod10-810-610-410-2100102Feasibility/Stationarity ErrorFeasibility (b=16)Stationarity (b=16)Feasibility (b=128)Stationarity (b=128)SVR-SQP-C = 10-3SVR-SQP-C = 10-2SVR-SQP-C = 10-1SVR-SQP-C = 100SVR-SQP-C = 101SVR-SQP-AMethod10-810-610-410-2100102Feasibility/Stationarity ErrorFeasibility (b=16)Stationarity (b=16)Feasibility (b=128)Stationarity (b=128)SVR-SQP-C = 10-3SVR-SQP-C = 10-2SVR-SQP-C = 10-1SVR-SQP-C = 100SVR-SQP-C = 101SVR-SQP-AMethod10-810-610-410-2100102Feasibility/Stationarity ErrorFeasibility (b=16)Stationarity (b=16)Feasibility (b=128)Stationarity (b=128)SVR-SQP-C = 10-3SVR-SQP-C = 10-2SVR-SQP-C = 10-1SVR-SQP-C = 100SVR-SQP-C = 101SVR-SQP-AMethod10-810-610-410-2100102Feasibility/Stationarity ErrorFeasibility (b=16)Stationarity (b=16)Feasibility (b=128)Stationarity (b=128)SVR-SQP-C = 10-3SVR-SQP-C = 10-2SVR-SQP-C = 10-1SVR-SQP-C = 100SVR-SQP-C = 101SVR-SQP-AMethod10-810-610-410-2100102Feasibility/Stationarity ErrorFeasibility (b=16)Stationarity (b=16)Feasibility (b=128)Stationarity (b=128)SVR-SQP-C = 10-3SVR-SQP-C = 10-2SVR-SQP-C = 10-1SVR-SQP-C = 100SVR-SQP-C = 101SVR-SQP-AMethod10-810-610-410-2100102Feasibility/Stationarity ErrorFeasibility (b=16)Stationarity (b=16)Feasibility (b=128)Stationarity (b=128)SVR-SQP-C = 10-3SVR-SQP-C = 10-2SVR-SQP-C = 10-1SVR-SQP-C = 100SVR-SQP-C = 101SVR-SQP-AMethod10-810-610-410-2100102Feasibility/Stationarity ErrorFeasibility (b=16)Stationarity (b=16)Feasibility (b=128)Stationarity (b=128)SVR-SQP-C = 10-3SVR-SQP-C = 10-2SVR-SQP-C = 10-1SVR-SQP-C = 100SVR-SQP-C = 101SVR-SQP-AMethod10-810-610-410-2100102Feasibility/Stationarity ErrorFeasibility (b=16)Stationarity (b=16)Feasibility (b=128)Stationarity (b=128)SVR-SQP-C = 10-3SVR-SQP-C = 10-2SVR-SQP-C = 10-1SVR-SQP-C = 100SVR-SQP-C = 101SVR-SQP-AMethod10-810-610-410-2100102Feasibility/Stationarity ErrorFeasibility (b=16)Stationarity (b=16)Feasibility (b=128)Stationarity (b=128)SVR-SQP-C = 10-3SVR-SQP-C = 10-2SVR-SQP-C = 10-1SVR-SQP-C = 100SVR-SQP-C = 101SVR-SQP-AMethod10-810-610-410-2100102Feasibility/Stationarity ErrorFeasibility (b=16)Stationarity (b=16)Feasibility (b=128)Stationarity (b=128)SVR-SQP-C = 10-3SVR-SQP-C = 10-2SVR-SQP-C = 10-1SVR-SQP-C = 100SVR-SQP-C = 101SVR-SQP-AMethod10-810-610-410-2100102Feasibility/Stationarity ErrorFeasibility (b=16)Stationarity (b=16)Feasibility (b=128)Stationarity (b=128)SVR-SQP-C = 10-3SVR-SQP-C = 10-2SVR-SQP-C = 10-1SVR-SQP-C = 100SVR-SQP-C = 101SVR-SQP-AMethod10-810-610-410-2100102Feasibility/Stationarity ErrorFeasibility (b=16)Stationarity (b=16)Feasibility (b=128)Stationarity (b=128)SVR-SQP-C = 10-3SVR-SQP-C = 10-2SVR-SQP-C = 10-1SVR-SQP-C = 100SVR-SQP-C = 101SVR-SQP-AMethod10-810-610-410-2100102Feasibility/Stationarity ErrorFeasibility (b=16)Stationarity (b=16)Feasibility (b=128)Stationarity (b=128)SVR-SQP-C = 10-3SVR-SQP-C = 10-2SVR-SQP-C = 10-1SVR-SQP-C = 100SVR-SQP-C = 101SVR-SQP-AMethod10-810-610-410-2100102Feasibility/Stationarity ErrorFeasibility (b=16)Stationarity (b=16)Feasibility (b=128)Stationarity (b=128)SVR-SQP-C = 10-3SVR-SQP-C = 10-2SVR-SQP-C = 10-1SVR-SQP-C = 100SVR-SQP-C = 101SVR-SQP-AMethod10-810-610-410-2100102Feasibility/Stationarity ErrorFeasibility (b=16)Stationarity (b=16)Feasibility (b=128)Stationarity (b=128)SVR-SQP-C = 10-3SVR-SQP-C = 10-2SVR-SQP-C = 10-1SVR-SQP-C = 100SVR-SQP-C = 101SVR-SQP-AMethod10-810-610-410-2100102Feasibility/Stationarity ErrorFeasibility (b=16)Stationarity (b=16)Feasibility (b=128)Stationarity (b=128)SVR-SQP-C = 10-3SVR-SQP-C = 10-2SVR-SQP-C = 10-1SVR-SQP-C = 100SVR-SQP-C = 101SVR-SQP-AMethod10-810-610-410-2100102Feasibility/Stationarity ErrorFeasibility (b=16)Stationarity (b=16)Feasibility (b=128)Stationarity (b=128)SVR-SQP-C = 10-3SVR-SQP-C = 10-2SVR-SQP-C = 10-1SVR-SQP-C = 100SVR-SQP-C = 101SVR-SQP-AMethod10-810-610-410-2100102Feasibility/Stationarity ErrorFeasibility (b=16)Stationarity (b=16)Feasibility (b=128)Stationarity (b=128)5.3 Sensitivity to user-deﬁned parameters

Given the encouraging numerical results for SVR-SQP-A (Section 5.2), in this subsection
we investigate the robustness of SVR-SQP-A to two user-deﬁned parameters: (1) the step
size parameter β ∈ {10−3, 10−2, 10−1, 100, 101} (Figure 3), and (2) the number of inner
iterations S ∈ (cid:8)(cid:4) N
(cid:5)(cid:9) (Figure 4) for two datasets (australian and splice).
n
Overall, the results on these two datasets suggest that β = 1 is often the best choice.
Moreover, our results in Figure 4 illustrate the robustness of SVR-SQP-A to the choice of
the number of inner iterations.

(cid:5) , (cid:4) N
4n

(cid:5) , (cid:4) N
2n

(a) australian dataset. Top row: feasibility error; Bottom row: stationarity error.

(b) splice dataset. Top row: feasibility error; Bottom row: stationarity error.

Figure 3: Performance of SVR-SQP-A with diﬀerent step sizes parameter values β ∈
{10−3, 10−2, 10−1, 100, 101} on logistic regression problems with linear (columns 1 and 2)
and (cid:96)2 norm (columns 3 and 4) constraints. First and third columns: batch size 16; Second
and fourth columns: batch size 128.

32

051015202530Number of Epochs10-810-610-410-2100102Feasibility Error = 10-3 = 10-2 = 10-1 = 1 = 10051015202530Number of Epochs10-810-610-410-2100102Feasibility Error = 10-3 = 10-2 = 10-1 = 1 = 10051015202530Number of Epochs10-810-610-410-2100102Feasibility Error = 10-3 = 10-2 = 10-1 = 1 = 10051015202530Number of Epochs10-810-610-410-2100102Feasibility Error = 10-3 = 10-2 = 10-1 = 1 = 10051015202530Number of Epochs10-810-610-410-2100102Stationarity Error = 10-3 = 10-2 = 10-1 = 1 = 10051015202530Number of Epochs10-810-610-410-2100102Stationarity Error = 10-3 = 10-2 = 10-1 = 1 = 10051015202530Number of Epochs10-810-610-410-2100102Stationarity Error = 10-3 = 10-2 = 10-1 = 1 = 10051015202530Number of Epochs10-810-610-410-2100102Stationarity Error = 10-3 = 10-2 = 10-1 = 1 = 10051015202530Number of Epochs10-810-610-410-2100102Feasibility Error = 10-3 = 10-2 = 10-1 = 1 = 10051015202530Number of Epochs10-810-610-410-2100102Feasibility Error = 10-3 = 10-2 = 10-1 = 1 = 10051015202530Number of Epochs10-810-610-410-2100102Feasibility Error = 10-3 = 10-2 = 10-1 = 1 = 10051015202530Number of Epochs10-810-610-410-2100102Feasibility Error = 10-3 = 10-2 = 10-1 = 1 = 10051015202530Number of Epochs10-810-610-410-2100102Stationarity Error = 10-3 = 10-2 = 10-1 = 1 = 10051015202530Number of Epochs10-810-610-410-2100102Stationarity Error = 10-3 = 10-2 = 10-1 = 1 = 10051015202530Number of Epochs10-810-610-410-2100102Stationarity Error = 10-3 = 10-2 = 10-1 = 1 = 10051015202530Number of Epochs10-810-610-410-2100102Stationarity Error = 10-3 = 10-2 = 10-1 = 1 = 10(a) australian dataset. Top row: feasibility error; Bottom row: stationarity error.

(b) splice dataset. Top row: feasibility error; Bottom row: stationarity error.

(cid:5) , (cid:4) N
2n

Figure 4: Performance of SVR-SQP-A with diﬀerent step sizes parameter values S ∈
(cid:8)(cid:4) N
(cid:5)(cid:9) on logistic regression problems with linear (columns 1 and 2) and (cid:96)2
n
norm (columns 3 and 4) constraints. First and third columns: batch size 16; Second and
fourth columns: batch size 128.

(cid:5) , (cid:4) N
4n

33

051015202530Number of Epochs10-810-610-410-2100102Feasibility ErrorS =  N/b S =  N/2b S =  N/4b 051015202530Number of Epochs10-810-610-410-2100102Feasibility ErrorS =  N/b S =  N/2b S =  N/4b 051015202530Number of Epochs10-810-610-410-2100102Feasibility ErrorS =  N/b S =  N/2b S =  N/4b 051015202530Number of Epochs10-810-610-410-2100102Feasibility ErrorS =  N/b S =  N/2b S =  N/4b 051015202530Number of Epochs10-810-610-410-2100102Optimality ErrorS =  N/b S =  N/2b S =  N/4b 051015202530Number of Epochs10-810-610-410-2100102Optimality ErrorS =  N/b S =  N/2b S =  N/4b 051015202530Number of Epochs10-810-610-410-2100102Optimality ErrorS =  N/b S =  N/2b S =  N/4b 051015202530Number of Epochs10-810-610-410-2100102Optimality ErrorS =  N/b S =  N/2b S =  N/4b 051015202530Number of Epochs10-810-610-410-2100102Feasibility ErrorS =  N/b S =  N/2b S =  N/4b 051015202530Number of Epochs10-810-610-410-2100102Feasibility ErrorS =  N/b S =  N/2b S =  N/4b 051015202530Number of Epochs10-810-610-410-2100102Feasibility ErrorS =  N/b S =  N/2b S =  N/4b 051015202530Number of Epochs10-810-610-410-2100102Feasibility ErrorS =  N/b S =  N/2b S =  N/4b 051015202530Number of Epochs10-810-610-410-2100102Optimality ErrorS =  N/b S =  N/2b S =  N/4b 051015202530Number of Epochs10-810-610-410-2100102Optimality ErrorS =  N/b S =  N/2b S =  N/4b 051015202530Number of Epochs10-810-610-410-2100102Optimality ErrorS =  N/b S =  N/2b S =  N/4b 051015202530Number of Epochs10-810-610-410-2100102Optimality ErrorS =  N/b S =  N/2b S =  N/4b 5.4 Comparison: SVR-SQP-A, Sto-SQP and Sto-Subgrad-VR

In this ﬁnal subsection, we compare the performance of SVR-SQP-A to that of Sto-SQP
[3, Algorithm 2] and Sto-Subgrad-VR. A budget of 30 epochs was used for all methods.
(cid:5). For the Sto-SQP method
For all methods, the inner iteration length was set to S = (cid:4) N
2n
the step size parameter was tuned β ∈ {10−3, 10−2, 10−1, 100, 101} for all k ∈ N, and for
the Sto-Subgrad-VR method the step size parameter and the merit parameter were tuned
τ L+Γ for all (k, s) ∈ N × (cid:2) ¯S(cid:3) where α ∈ {10−3, 10−2, 10−1, 100, 101}, τk,s = τ ∈
¯αk,s = α
{10−10, 10−9, . . . , 100}. For the SVR-SQP-A, we set β = 1. Overall, this meant that the
Sto-SQP and Sto-Subgrad-VR methods were eﬀectively run for 5 and 55 times the number
of epochs, respectively, than were allowed for our method.

The results of these experiments are reported in Figures 5a and 5b and in Tables 3
and 4. For each batch size and dataset, we report the average feasibility and stationarity
errors for the best iterates generated (deﬁned in Section 5.1) for the best hyper-parameter
settings for each method in Tables 3 and 4. The results suggest that, when small batch
sizes are employed (i.e., b = 16), SVR-SQP-A consistently outperforms the other methods
for both sets of constraints. When large batch sizes are used (i.e., b = 128), SVR-SQP-A is
competitive with Sto-SQP, even though the adaptive step size parameter β is well-tuned
for Sto-SQP whereas for SVR-SQP-A we simply set β = 1. We should note again that 5 and
55 times the tuning eﬀort was allocated to Sto-SQP and Sto-Subgrad-VR, respectively, as
compared to SVR-SQP-A.

34

Table 3: Average feasibility and stationarity errors, along with 95% conﬁdence intervals,
of best tuned variants of Sto-Subgrad-VR and Sto-SQP, and SVR-SQP-A with β = 1 and
S = (cid:4) N
(cid:5) on logistic regression problems with linear constraints (5.1). The results for the
2n
best-performing algorithm for each batch size are shown in bold. The symbol (cid:63) indicates
that all the runs for a given method converged to min{(cid:107)ck(cid:107)∞ : k = 0, . . . , K} ≤ 10−6.

Sto-Subgrad-VR

Sto-SQP

SVR-SQP-A

Dataset

Batch

Feasibility

Stationarity

Feasibility

Stationarity

Feasibility

Stationarity

a9a
a9a

16
128

1.2 × 10−1 ± 7.2 × 10−3
1.1 × 10−1 ± 8.4 × 10−3

2.6 × 10−2 ± 1.1 × 10−2
8.7 × 10−2 ± 1.6 × 10−2

16
australian
australian 128

4.1 × 10−2 ± 1.1 × 10−2
3.1 × 10−1 ± 3.5 × 10−2

2.0 × 10−1 ± 1.5 × 10−3
2.0 × 10−1 ± 4.7 × 10−3

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

8.4 × 10−4 ± 2.9 × 10−5
7.0 × 10−4 ± 2.8 × 10−5

1.2 × 10−3 ± 2.2 × 10−4
2.3 × 10−3 ± 7.3 × 10−4
2.3 × 10−3 ± 7.3 × 10−4
2.3 × 10−3 ± 7.3 × 10−4

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

3.5 × 10−5 ± 4.5 × 10−6
3.5 × 10−5 ± 4.5 × 10−6
3.5 × 10−5 ± 4.5 × 10−6
1.5 × 10−4 ± 1.1 × 10−6
1.5 × 10−4 ± 1.1 × 10−6
1.5 × 10−4 ± 1.1 × 10−6

1.5 × 10−6 ± 5.6 × 10−7
1.5 × 10−6 ± 5.6 × 10−7
1.5 × 10−6 ± 5.6 × 10−7
4.8 × 10−3 ± 2.7 × 10−4

2.3 × 10−1 ± 4.8 × 10−2
8.7 × 10−1 ± 1.6 × 10−2
8.7 × 10−1 ± 1.6 × 10−2
8.7 × 10−1 ± 1.6 × 10−2

1.2 × 101 ± 3.9 × 100
1.2 × 101 ± 3.9 × 100
1.2 × 101 ± 3.9 × 100
2.3 × 101 ± 3.0 × 100
2.3 × 101 ± 3.0 × 100
2.3 × 101 ± 3.0 × 100

7.9 × 10−2 ± 1.2 × 10−2
7.9 × 10−2 ± 1.2 × 10−2
7.9 × 10−2 ± 1.2 × 10−2
1.2 × 100 ± 4.1 × 10−2

2.3 × 101 ± 5.1 × 100
2.4 × 101 ± 2.0 × 100

1.5 × 100 ± 1.6 × 10−2
1.6 × 100 ± 2.3 × 10−3

2.2 × 101 ± 1.3 × 100
2.6 × 101 ± 1.8 × 100

heart
heart

ijcnn1
ijcnn1

16
128

16
128

9.9 × 10−1 ± 1.1 × 10−1
9.7 × 10−1 ± 1.8 × 10−1

6.6 × 10−3 ± 5.5 × 10−3
1.6 × 10−2 ± 6.5 × 10−3

16
ionosphere
ionosphere 128

3.2 × 10−2 ± 4.9 × 10−3
4.4 × 10−1 ± 5.4 × 10−2

1.4 × 10−1 ± 5.3 × 10−3
1.4 × 10−1 ± 1.1 × 10−2

mushrooms
mushrooms

phising
phising

sonar
sonar

splice
splice

w8a
w8a

16
128

16
128

16
128

16
128

16
128

4.8 × 10−2 ± 6.0 × 10−3
5.7 × 10−2 ± 5.5 × 10−3

1.3 × 10−1 ± 2.0 × 10−2
1.8 × 10−1 ± 4.5 × 10−3

3.7 × 10−1 ± 5.4 × 10−2
6.0 × 10−1 ± 2.2 × 10−2

2.6 × 10−2 ± 2.5 × 10−4
3.6 × 10−2 ± 1.4 × 10−4

4.1 × 10−2 ± 2.8 × 10−3
4.1 × 10−1 ± 3.2 × 10−2

3.9 × 10−2 ± 1.2 × 10−3
4.1 × 10−2 ± 3.0 × 10−3

6.8 × 10−4 ± 6.2 × 10−5
7.0 × 10−3 ± 3.3 × 10−4

2.6 × 10−1 ± 2.2 × 10−4
2.6 × 10−1 ± 7.6 × 10−4

5.1 × 10−1 ± 8.6 × 10−3
6.9 × 10−1 ± 2.5 × 10−3

4.8 × 10−3 ± 1.1 × 10−4
2.6 × 10−2 ± 1.8 × 10−4

1.8 × 10−4 ± 1.9 × 10−5
2.1 × 10−4 ± 2.2 × 10−5

4.2 × 10−3 ± 4.3 × 10−4
1.2 × 10−2 ± 9.8 × 10−4
1.2 × 10−2 ± 9.8 × 10−4
1.2 × 10−2 ± 9.8 × 10−4

4.2 × 10−4 ± 9.0 × 10−6
4.2 × 10−4 ± 9.0 × 10−6
4.2 × 10−4 ± 9.0 × 10−6
2.5 × 10−3 ± 9.2 × 10−5
2.5 × 10−3 ± 9.2 × 10−5
2.5 × 10−3 ± 9.2 × 10−5

4.6 × 10−4 ± 1.2 × 10−5
2.7 × 10−3 ± 3.6 × 10−5

7.5 × 10−3 ± 4.4 × 10−4
7.5 × 10−3 ± 4.4 × 10−4
7.5 × 10−3 ± 4.4 × 10−4
1.9 × 10−2 ± 2.9 × 10−4
1.9 × 10−2 ± 2.9 × 10−4
1.9 × 10−2 ± 2.9 × 10−4

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

1.3 × 10−8 ± 7.8 × 10−9
1.3 × 10−8 ± 7.8 × 10−9
1.3 × 10−8 ± 7.8 × 10−9
1.0 × 10−8 ± 1.8 × 10−10
1.0 × 10−8 ± 1.8 × 10−10
1.0 × 10−8 ± 1.8 × 10−10

2.4 × 10−3 ± 1.8 × 10−4
2.4 × 10−3 ± 1.8 × 10−4
2.4 × 10−3 ± 1.8 × 10−4
2.0 × 10−2 ± 4.0 × 10−4

8.0 × 10−4 ± 2.4 × 10−5
4.2 × 10−3 ± 7.7 × 10−5

9.9 × 10−5 ± 3.2 × 10−6
9.9 × 10−5 ± 3.2 × 10−6
9.9 × 10−5 ± 3.2 × 10−6
8.1 × 10−4 ± 1.3 × 10−5
8.1 × 10−4 ± 1.3 × 10−5
8.1 × 10−4 ± 1.3 × 10−5

1.1 × 10−2 ± 3.1 × 10−4
2.2 × 10−2 ± 7.8 × 10−5

4.1 × 10−3 ± 3.7 × 10−4
4.1 × 10−3 ± 3.7 × 10−4
4.1 × 10−3 ± 3.7 × 10−4
1.8 × 10−2 ± 8.0 × 10−4
1.8 × 10−2 ± 8.0 × 10−4
1.8 × 10−2 ± 8.0 × 10−4

(cid:63)(cid:63)(cid:63)
1.9 × 10−3 ± 9.4 × 10−5

7.6 × 10−3 ± 2.0 × 10−4
4.3 × 10−2 ± 1.2 × 10−3

2.6 × 10−4 ± 1.9 × 10−5
1.8 × 10−4 ± 5.0 × 10−6
1.8 × 10−4 ± 5.0 × 10−6
1.8 × 10−4 ± 5.0 × 10−6

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

7.5 × 10−5 ± 7.9 × 10−7
7.5 × 10−5 ± 7.9 × 10−7
7.5 × 10−5 ± 7.9 × 10−7
3.4 × 10−4 ± 2.1 × 10−6

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

35

(a) australian dataset. Top row: feasibility error; Bottom row: stationarity error.

(b) splice dataset. Top row: feasibility error; Bottom row: stationarity error.

Figure 5: Performance of best tuned variants of Sto-Subgrad-VR and Sto-SQP, and
SVR-SQP-A with β = 1 and S = (cid:4) N
(cid:5) on logistic regression problems with linear (columns
2n
1 and 2) and (cid:96)2 norm (columns 3 and 4) constraints. First and third columns: batch size
16; Second and fourth columns: batch size 128.

36

051015202530Number of Epochs10-810-610-410-2100102Feasibility ErrorSVR-SQP-AStochSQPStochSubVR051015202530Number of Epochs10-810-610-410-2100102Feasibility ErrorSVR-SQP-AStochSQPStochSubVR051015202530Number of Epochs10-810-610-410-2100102Feasibility ErrorSVR-SQP-AStochSQPStochSubVR051015202530Number of Epochs10-810-610-410-2100102Feasibility ErrorSVR-SQP-AStochSQPStochSubVR051015202530Number of Epochs10-810-610-410-2100102Stationarity ErrorSVR-SQP-AStochSQPStochSubVR051015202530Number of Epochs10-810-610-410-2100102Stationarity ErrorSVR-SQP-AStochSQPStochSubVR051015202530Number of Epochs10-810-610-410-2100102Stationarity ErrorSVR-SQP-AStochSQPStochSubVR051015202530Number of Epochs10-810-610-410-2100102Stationarity ErrorSVR-SQP-AStochSQPStochSubVR051015202530Number of Epochs10-810-610-410-2100102Feasibility ErrorSVR-SQP-AStochSQPStochSubVR051015202530Number of Epochs10-810-610-410-2100102Feasibility ErrorSVR-SQP-AStochSQPStochSubVR051015202530Number of Epochs10-810-610-410-2100102Feasibility ErrorSVR-SQP-AStochSQPStochSubVR051015202530Number of Epochs10-810-610-410-2100102Feasibility ErrorSVR-SQP-AStochSQPStochSubVR051015202530Number of Epochs10-810-610-410-2100102Stationarity ErrorSVR-SQP-AStochSQPStochSubVR051015202530Number of Epochs10-810-610-410-2100102Stationarity ErrorSVR-SQP-AStochSQPStochSubVR051015202530Number of Epochs10-810-610-410-2100102Stationarity ErrorSVR-SQP-AStochSQPStochSubVR051015202530Number of Epochs10-810-610-410-2100102Stationarity ErrorSVR-SQP-AStochSQPStochSubVRTable 4: Average feasibility and stationarity errors, along with 95% conﬁdence intervals,
of best tuned variants of Sto-Subgrad-VR and Sto-SQP, and SVR-SQP-A with β = 1
and S = (cid:4) N
(cid:5) on logistic regression problems with (cid:96)2 constraint (5.2). The results for the
2n
best-performing algorithm for each batch size are shown in bold. The symbol (cid:63) indicates
that all the runs for a given method converged to min{(cid:107)ck(cid:107)∞ : k = 0, . . . , K} ≤ 10−6.

Sto-Subgrad-VR

Sto-SQP

SVR-SQP-A

Dataset

Batch

Feasibility

Stationarity

Feasibility

Stationarity

Feasibility

Stationarity

a9a
a9a

16
128

3.0 × 10−6 ± 9.7 × 10−7
2.9 × 10−5 ± 3.8 × 10−6

2.5 × 10−1 ± 7.4 × 10−7
2.5 × 10−1 ± 3.6 × 10−8

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

1.1 × 10−2 ± 7.8 × 10−4
8.1 × 10−3 ± 2.2 × 10−4

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

1.5 × 10−8 ± 1.9 × 10−9
1.5 × 10−8 ± 1.9 × 10−9
1.5 × 10−8 ± 1.9 × 10−9
1.7 × 10−5 ± 1.2 × 10−6
1.7 × 10−5 ± 1.2 × 10−6
1.7 × 10−5 ± 1.2 × 10−6

16
australian
australian 128

2.9 × 10−4 ± 5.8 × 10−5
2.6 × 10−3 ± 1.1 × 10−3

3.1 × 10−1 ± 1.3 × 10−6
2.5 × 10−1 ± 3.2 × 10−3

2.9 × 10−4 ± 1.4 × 10−4
1.3 × 10−4 ± 4.1 × 10−6

2.3 × 10−2 ± 1.9 × 10−2
9.1 × 10−3 ± 1.1 × 10−3

(cid:63)(cid:63)(cid:63)
2.4 × 10−5 ± 9.6 × 10−7
2.4 × 10−5 ± 9.6 × 10−7
2.4 × 10−5 ± 9.6 × 10−7

2.1 × 10−4 ± 4.9 × 10−5
2.1 × 10−4 ± 4.9 × 10−5
2.1 × 10−4 ± 4.9 × 10−5
4.7 × 10−3 ± 9.2 × 10−5
4.7 × 10−3 ± 9.2 × 10−5
4.7 × 10−3 ± 9.2 × 10−5

heart
heart

ijcnn1
ijcnn1

16
128

16
128

1.2 × 10−3 ± 5.2 × 10−4
1.2 × 10−3 ± 5.2 × 10−4
1.2 × 10−3 ± 5.2 × 10−4
2.9 × 10−2 ± 1.5 × 10−2
2.9 × 10−2 ± 1.5 × 10−2
2.9 × 10−2 ± 1.5 × 10−2

2.5 × 100 ± 2.3 × 10−1
2.5 × 100 ± 2.3 × 10−1
2.5 × 100 ± 2.3 × 10−1
1.1 × 102 ± 2.5 × 101

3.3 × 10−1 ± 6.1 × 10−2
9.9 × 10−1 ± 5.7 × 10−5

9.1 × 101 ± 2.2 × 101
5.9 × 100 ± 1.1 × 100
5.9 × 100 ± 1.1 × 100
5.9 × 100 ± 1.1 × 100

4.7 × 10−1 ± 3.8 × 10−2
8.8 × 10−1 ± 8.3 × 10−3

8.8 × 101 ± 7.6 × 100
1.1 × 102 ± 1.4 × 101

1.2 × 10−5 ± 8.1 × 10−6
4.4 × 10−6 ± 1.8 × 10−7

1.0 × 10−6 ± 2.6 × 10−9
6.8 × 10−2 ± 8.3 × 10−5
6.8 × 10−2 ± 2.1 × 10−10 1.0 × 10−6 ± 3.2 × 10−10

3.8 × 10−2 ± 7.9 × 10−4
3.1 × 10−2 ± 5.8 × 10−4

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

3.1 × 10−8 ± 3.8 × 10−9
3.1 × 10−8 ± 3.8 × 10−9
3.1 × 10−8 ± 3.8 × 10−9
1.2 × 10−5 ± 1.1 × 10−7
1.2 × 10−5 ± 1.1 × 10−7
1.2 × 10−5 ± 1.1 × 10−7

16
ionosphere
ionosphere 128

1.4 × 10−3 ± 5.4 × 10−4
8.0 × 10−3 ± 7.1 × 10−3

1.1 × 10−1 ± 6.4 × 10−4
1.1 × 10−1 ± 1.5 × 10−3

4.3 × 10−4 ± 4.0 × 10−4
5.8 × 10−4 ± 1.9 × 10−5
5.8 × 10−4 ± 1.9 × 10−5
5.8 × 10−4 ± 1.9 × 10−5

5.2 × 10−2 ± 1.7 × 10−2
2.0 × 10−2 ± 1.2 × 10−3
2.0 × 10−2 ± 1.2 × 10−3
2.0 × 10−2 ± 1.2 × 10−3

1.4 × 10−5 ± 3.2 × 10−6
1.4 × 10−5 ± 3.2 × 10−6
1.4 × 10−5 ± 3.2 × 10−6
7.6 × 10−4 ± 1.4 × 10−5

6.1 × 10−3 ± 7.0 × 10−4
6.1 × 10−3 ± 7.0 × 10−4
6.1 × 10−3 ± 7.0 × 10−4
2.3 × 10−2 ± 3.9 × 10−4

mushrooms
mushrooms

phising
phising

sonar
sonar

splice
splice

w8a
w8a

16
128

16
128

16
128

16
128

16
128

3.4 × 10−5 ± 9.1 × 10−6
4.0 × 10−4 ± 2.4 × 10−4

1.8 × 10−1 ± 6.4 × 10−8
2.9 × 10−2 ± 1.6 × 10−3

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

7.1 × 10−3 ± 1.2 × 10−4
2.2 × 10−2 ± 5.8 × 10−4

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

1.0 × 10−8 ± 2.1 × 10−11
1.0 × 10−8 ± 2.1 × 10−11
1.0 × 10−8 ± 2.1 × 10−11
1.6 × 10−7 ± 2.7 × 10−8
1.6 × 10−7 ± 2.7 × 10−8
1.6 × 10−7 ± 2.7 × 10−8

3.9 × 10−5 ± 2.1 × 10−5
7.1 × 10−4 ± 3.5 × 10−4

4.0 × 10−2 ± 4.1 × 10−6
2.9 × 10−2 ± 1.7 × 10−3

8.4 × 10−5 ± 1.2 × 10−6
1.2 × 10−5 ± 3.4 × 10−7
1.2 × 10−5 ± 3.4 × 10−7
1.2 × 10−5 ± 3.4 × 10−7

1.0 × 10−3 ± 4.0 × 10−4
3.0 × 10−3 ± 3.4 × 10−4
3.0 × 10−3 ± 3.4 × 10−4
3.0 × 10−3 ± 3.4 × 10−4

(cid:63)(cid:63)(cid:63)
1.3 × 10−5 ± 6.2 × 10−8

4.4 × 10−6 ± 5.2 × 10−8
4.4 × 10−6 ± 5.2 × 10−8
4.4 × 10−6 ± 5.2 × 10−8
7.5 × 10−3 ± 2.0 × 10−5

2.5 × 10−3 ± 6.5 × 10−4
3.3 × 10−2 ± 2.1 × 10−2

1.4 × 10−1 ± 2.0 × 10−5
2.9 × 10−2 ± 2.5 × 10−3

7.4 × 10−4 ± 1.9 × 10−4
8.9 × 10−4 ± 6.0 × 10−5
8.9 × 10−4 ± 6.0 × 10−5
8.9 × 10−4 ± 6.0 × 10−5

2.3 × 10−2 ± 3.9 × 10−3
2.7 × 10−2 ± 1.8 × 10−3
2.7 × 10−2 ± 1.8 × 10−3
2.7 × 10−2 ± 1.8 × 10−3

1.7 × 10−4 ± 1.1 × 10−5
1.7 × 10−4 ± 1.1 × 10−5
1.7 × 10−4 ± 1.1 × 10−5
3.2 × 10−3 ± 3.9 × 10−7

2.0 × 10−2 ± 5.6 × 10−4
2.0 × 10−2 ± 5.6 × 10−4
2.0 × 10−2 ± 5.6 × 10−4
3.2 × 10−2 ± 3.5 × 10−6

3.0 × 10−5 ± 3.9 × 10−4
7.1 × 10−4 ± 2.8 × 10−4

1.7 × 100 ± 1.6 × 10−4
1.6 × 100 ± 2.1 × 10−3

1.3 × 10−5 ± 8.4 × 10−6
1.0 × 10−6 ± 5.4 × 10−7
1.0 × 10−6 ± 5.4 × 10−7
1.0 × 10−6 ± 5.4 × 10−7

1.0 × 10−1 ± 3.8 × 10−2
4.5 × 10−2 ± 2.2 × 10−2

(cid:63)(cid:63)(cid:63)
5.2 × 10−5 ± 4.1 × 10−6

6.5 × 10−4 ± 9.0 × 10−5
6.5 × 10−4 ± 9.0 × 10−5
6.5 × 10−4 ± 9.0 × 10−5
1.4 × 10−2 ± 5.2 × 10−4
1.4 × 10−2 ± 5.2 × 10−4
1.4 × 10−2 ± 5.2 × 10−4

3.5 × 10−5 ± 2.2 × 10−5
1.5 × 10−5 ± 1.0 × 10−6

1.6 × 10−1 ± 8.4 × 10−5
1.6 × 10−1 ± 2.2 × 10−9

1.3 × 10−6 ± 5.4 × 10−8
1.0 × 10−6 ± 3.6 × 10−10

3.6 × 10−3 ± 4.6 × 10−5
3.4 × 10−3 ± 8.9 × 10−5

(cid:63)(cid:63)(cid:63)
(cid:63)(cid:63)(cid:63)

1.4 × 10−8 ± 2.1 × 10−9
1.4 × 10−8 ± 2.1 × 10−9
1.4 × 10−8 ± 2.1 × 10−9
2.4 × 10−8 ± 2.4 × 10−9
2.4 × 10−8 ± 2.4 × 10−9
2.4 × 10−8 ± 2.4 × 10−9

37

6 Final Remarks

We have designed and analyzed an adaptive variance reduced SQP method for minimiz-
ing general smooth ﬁnite-sum optimization problems with deterministic nonlinear equality
constraints. Under common assumptions, with constant or adaptive (non-diminishing)
step sizes, we presented comprehensive convergence guarantees for our proposed method.
Speciﬁcally, we proved that the SVR-SQP method generates a sequence of iterates whose
ﬁrst-order stationarity measure converges to zero in expectation. Our theoretical results
can be viewed as analogues of those of the SVRG method on general unconstrained non-
convex ﬁnite-sum optimization problems [28]. The numerical experiments presented on
classiﬁcation problems from the LIBSVM collection [6] demonstrated the eﬃciency, eﬃ-
cacy and robustness of the proposed method.

References

[1] Joshua Achiam, David Held, Aviv Tamar, and Pieter Abbeel. Constrained policy
optimization. In International Conference on Machine Learning, pages 22–31. PMLR,
2017.

[2] Albert S Berahas, Frank E Curtis, Michael J O’Neill, and Daniel P Robinson. A
stochastic sequential quadratic optimization algorithm for nonlinear equality con-
strained optimization with rank-deﬁcient jacobians. arXiv preprint arXiv:2106.13015,
2021.

[3] Albert S Berahas, Frank E Curtis, Daniel Robinson, and Baoyu Zhou. Sequential
Quadratic Optimization for Nonlinear Equality Constrained Stochastic Optimization.
SIAM Journal on Optimization, 31(2):1352–1379, 2021.

[4] L´eon Bottou, Frank E Curtis, and Jorge Nocedal. Optimization methods for large-

scale machine learning. Siam Review, 60(2):223–311, 2018.

[5] Richard H Byrd, Frank E Curtis, and Jorge Nocedal. An inexact SQP method for
equality constrained optimization. SIAM Journal on Optimization, 19(1):351–369,
2008.

[6] Chih-Chung Chang and Chih-Jen Lin. LIBSVM: a library for support vector machines.
ACM Transactions on Intelligent Systems and Technology (TIST), 2(3):1–27, 2011.

[7] Nilanjan Chatterjee, Yi-Hau Chen, Paige Maas, and Raymond J Carroll. Constrained
maximum likelihood estimation for model calibration using summary-level informa-
tion from external big data sources. Journal of the American Statistical Association,
111(513):107–117, 2016.

38

[8] Changan Chen, Frederick Tung, Naveen Vedula, and Greg Mori. Constraint-aware
In Proceedings of the European Conference on

deep neural network compression.
Computer Vision (ECCV), pages 400–415, 2018.

[9] Frank E Curtis, Michael J O’Neill, and Daniel P Robinson. Worst-Case Complexity of
an SQP Method for Nonlinear Equality Constrained Stochastic Optimization. arXiv
preprint arXiv:2112.14799, 2021.

[10] Frank E Curtis, Daniel P Robinson, and Baoyu Zhou. Inexact Sequential Quadratic
Optimization for Minimizing a Stochastic Objective Function Subject to Deterministic
Nonlinear Equality Constraints. arXiv preprint arXiv:2107.03512, 2021.

[11] Aaron Defazio, Francis Bach, and Simon Lacoste-Julien. SAGA: A fast incremen-
tal gradient method with support for non-strongly convex composite objectives. In
Advances in neural information processing systems, pages 1646–1654, 2014.

[12] Charles J Geyer. Constrained maximum likelihood exempliﬁed by isotonic convex
logistic regression. Journal of the American Statistical Association, 86(415):717–724,
1991.

[13] Saeed Ghadimi, Guanghui Lan, and Hongchao Zhang. Mini-batch stochastic approxi-
mation methods for nonconvex stochastic composite optimization. Mathematical Pro-
gramming, 155(1-2):267–305, 2016.

[14] Rie Johnson and Tong Zhang. Accelerating stochastic gradient descent using predictive
variance reduction. Advances in neural information processing systems, 26:315–323,
2013.

[15] Guanghui Lan. An optimal method for stochastic composite optimization. Mathemat-

ical Programming, 133(1):365–397, 2012.

[16] Guanghui Lan. First-order and Stochastic Optimization Methods for Machine Learn-

ing. Springer Nature, 2020.

[17] Rudolf Lioutikov, Alexandros Paraschos, Jan Peters, and Gerhard Neumann. Sample-
based informationl-theoretic stochastic optimal control. In 2014 IEEE International
Conference on Robotics and Automation (ICRA), pages 3896–3902. IEEE, 2014.

[18] Andreas A Malikopoulos. Stochastic optimal control for series hybrid electric vehicles.

In 2013 American Control Conference, pages 1189–1194. IEEE, 2013.

[19] Pablo M´arquez-Neila, Mathieu Salzmann, and Pascal Fua. Imposing hard constraints
on deep networks: Promises and limitations. arXiv preprint arXiv:1706.02025, 2017.

39

[20] Sen Na, Mihai Anitescu, and Mladen Kolar. An adaptive stochastic sequential
arXiv

quadratic programming with diﬀerentiable exact augmented lagrangians.
preprint arXiv:2102.05320, 2021.

[21] Sen Na, Mihai Anitescu, and Mladen Kolar. Inequality constrained stochastic non-
linear optimization via active-set sequential quadratic programming. arXiv preprint
arXiv:2109.11502, 2021.

[22] Yatin Nandwani, Abhishek Pathak, and Parag Singla. A primal-dual formulation
for deep learning with constraints. In Proceedings of Neural Information Processing
Systems (NeurIPS), pages 12157–12168, 2019.

[23] Geoﬀrey N´egiar, Gideon Dresdner, Alicia Tsai, Laurent El Ghaoui, Francesco Lo-
catello, Robert Freund, and Fabian Pedregosa. Stochastic frank-wolfe for constrained
In International Conference on Machine Learning, pages
ﬁnite-sum minimization.
7253–7262. PMLR, 2020.

[24] Arkadi Nemirovski, Anatoli Juditsky, Guanghui Lan, and Alexander Shapiro. Robust
stochastic approximation approach to stochastic programming. SIAM Journal on
optimization, 19(4):1574–1609, 2009.

[25] Lam M Nguyen, Jie Liu, Katya Scheinberg, and Martin Tak´aˇc. SARAH: A novel
method for machine learning problems using stochastic recursive gradient. In Inter-
national Conference on Machine Learning, pages 2613–2621. PMLR, 2017.

[26] Jorge Nocedal and Stephen Wright. Numerical optimization. Springer Series in Op-
erations Research and Financial Engineering. Springer-Verlag New York, New York,
2006.

[27] Sathya N Ravi, Tuan Dinh, Vishnu Suresh Lokhande, and Vikas Singh. Explicitly
imposing constraints in deep networks via conditional gradients gives improved gener-
alization and faster convergence. In Proceedings of the AAAI Conference on Artiﬁcial
Intelligence, volume 33, pages 4772–4779, 2019.

[28] Sashank J Reddi, Ahmed Hefny, Suvrit Sra, Barnabas Poczos, and Alex Smola.
In International confer-

Stochastic variance reduction for nonconvex optimization.
ence on machine learning, pages 314–323. PMLR, 2016.

[29] Sashank J Reddi, Suvrit Sra, Barnab´as P´oczos, and Alex Smola. Stochastic frank-
wolfe methods for nonconvex optimization. In 2016 54th Annual Allerton Conference
on Communication, Control, and Computing (Allerton), pages 1244–1251. IEEE, 2016.

[30] Herbert Robbins and Sutton Monro. A stochastic approximation method. The annals

of mathematical statistics, pages 400–407, 1951.

40

[31] Sheldon M Ross. Simulation. Academic Press, Amsterdam, 2013.

[32] Soumava Kumar Roy, Zakaria Mhammedi, and Mehrtash Harandi. Geometry aware
In Proceedings of the IEEE

constrained optimization techniques for deep learning.
Conference on Computer Vision and Pattern Recognition, pages 4460–4469, 2018.

[33] Mark Schmidt, Nicolas Le Roux, and Francis Bach. Minimizing ﬁnite sums with the
stochastic average gradient. Mathematical Programming, 162(1-2):83–112, 2017.

[34] Shai Shalev-Shwartz and Tong Zhang. Stochastic dual coordinate ascent methods for
regularized loss minimization. Journal of Machine Learning Research, 14(2), 2013.

[35] Alexander Shapiro, Darinka Dentcheva, and Andrzej Ruszczynski. Lectures on stochas-

tic programming: modeling and theory. SIAM, 2021.

[36] Jiahao Shi and James C Spall. SQP-based Projection SPSA Algorithm for Stochas-
tic Optimization with Inequality Constraints. In 2021 American Control Conference
(ACC), pages 1244–1249. IEEE, 2021.

[37] Tyler Summers, Joseph Warrington, Manfred Morari, and John Lygeros. Stochastic
optimal power ﬂow based on conditional value at risk and distributional robustness.
International Journal of Electrical Power & Energy Systems, 72:116–125, 2015.

[38] Stanislav Uryasev and Panos M Pardalos. Stochastic optimization: algorithms and

applications, volume 54. Springer Science & Business Media, 2013.

[39] Maria Vrakopoulou, Johanna L Mathieu, and G¨oran Andersson. Stochastic optimal
power ﬂow with uncertain reserves from demand response. In 2014 47th Hawaii In-
ternational Conference on System Sciences, pages 2353–2362. IEEE, 2014.

[40] Allen J Wood, Bruce F Wollenberg, and Gerald B Shebl´e. Power generation, operation,

and control. John Wiley & Sons, New Jersey, USA, 2013.

[41] Yinhao Zhu, Nicholas Zabaras, Phaedon-Stelios Koutsourelakis, and Paris Perdikaris.
Physics-constrained deep learning for high-dimensional surrogate modeling and uncer-
tainty quantiﬁcation without labeled data. Journal of Computational Physics, 394:56–
81, 2019.

[42] William T Ziemba and Raymond G Vickson. Stochastic optimization models in ﬁnance.

Academic Press, 2014.

41

