Guaranteed Bounds for Posterior Inference
in Universal Probabilistic Programming
C.-H. Luke Ong
Fabian Zaiser
University of Oxford
University of Oxford
United Kingdom
United Kingdom

Raven Beutner‚àó
CISPA Helmholtz Center for
Information Security
Germany

2
2
0
2

n
u
J

6

]
L
P
.
s
c
[

2
v
8
4
9
2
0
.
4
0
2
2
:
v
i
X
r
a

Abstract
We propose a new method to approximate the posterior dis-
tribution of probabilistic programs by means of computing
guaranteed bounds. The starting point of our work is an
interval-based trace semantics for a recursive, higher-order
probabilistic programming language with continuous distri-
butions. Taking the form of (super-/subadditive) measures,
these lower/upper bounds are non-stochastic and provably
correct: using the semantics, we prove that the actual poste-
rior of a given program is sandwiched between the lower and
upper bounds (soundness); moreover, the bounds converge
to the posterior (completeness). As a practical and sound
approximation, we introduce a weight-aware interval type
system, which automatically infers interval bounds on not
just the return value but also the weight of program execu-
tions, simultaneously. We have built a tool implementation,
called GuBPI, which automatically computes these posterior
lower/upper bounds. Our evaluation on examples from the
literature shows that the bounds are useful, and can even be
used to recognise wrong outputs from stochastic posterior
inference procedures.

CCS Concepts: ‚Ä¢ Mathematics of computing ‚Üí Proba-
bilistic inference problems; ‚Ä¢ Theory of computation
‚Üí Program analysis; ‚Ä¢ Software and its engineering ‚Üí
Formal methods.
Keywords: probabilistic programming, Bayesian inference,
verification, abstract interpretation, operational semantics,
interval arithmetic, type system, symbolic execution

ACM Reference Format:
Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser. 2022. Guaran-
teed Bounds for Posterior Inference in Universal Probabilistic Pro-
gramming. In Proceedings of the 43rd ACM SIGPLAN International
Conference on Programming Language Design and Implementation
(PLDI ‚Äô22), June 13‚Äì17, 2022, San Diego, CA, USA. ACM, New York,
NY, USA, 32 pages. https://doi.org/10.1145/3519939.3523721
‚àóMember of the Saarbr√ºcken Graduate School of Computer Science.

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA
¬© 2022 Copyright held by the owner/author(s).
This is the author‚Äôs version of the work. It is posted here for your personal
use. Not for redistribution. The definitive Version of Record was published
in Proceedings of the 43rd ACM SIGPLAN International Conference on Pro-
gramming Language Design and Implementation (PLDI ‚Äô22), June 13‚Äì17, 2022,
San Diego, CA, USA, https://doi.org/10.1145/3519939.3523721.

1 Introduction
Probabilistic programming is a rapidly developing discipline
at the interface of programming and Bayesian statistics [32,
33, 62]. The idea is to express probabilistic models (incor-
porating the prior distributions) and the observed data as
programs, and to use a general-purpose Bayesian inference
engine, which acts directly on these programs, to find the
posterior distribution given the observations.

Some of the most influential probabilistic programming
languages (PPLs) used in practice are universal (i.e. the under-
lying language is Turing-complete); e.g. Church [31], Angli-
can [61], Gen [18], Pyro [5], and Turing [25]. Using stochastic
branching, recursion, and higher-order features, universal
PPLs can express arbitrarily complex models. For instance,
these language constructs can be used to incorporate proba-
bilistic context free grammars [43], statistical phylogenetics
[52], and even physics simulations [3] into probabilistic mod-
els. However, expressivity of the PPL comes at the cost of
complicating the posterior inference. Consider, for example,
the following problem from [41, 42].

Example 1.1 (Pedestrian). A pedestrian has gotten lost on
a long road and only knows that they are a random distance
between 0 and 3 km from their home. They repeatedly walk a
uniform random distance of at most 1 km in either direction,
until they find their home. When they arrive, a step counter
tells them that they have traveled a distance of 1.1 km in total.
Assuming that the measured distance is normally distributed
around the true distance with standard deviation 0.1 km,
what is the posterior distribution of the starting point? We
can model this with a probabilistic program:

let start = 3 √ó sample uniform(0, 1) in
letrec walk ùë• = if ùë• ‚â§ 0 then 0 else

let step = sample uniform(0, 1) in
step + walk (cid:0)(ùë• + step) ‚äï0.5 (ùë• ‚àí step)(cid:1)

let distance = walk start in
observe distance from Normal(1.1, 0.1);
start

Here sample uniform(ùëé, ùëè) samples a uniformly distributed
value in [ùëé, ùëè], ‚äï0.5 is probabilistic branching, and observe
ùëÄ from ùê∑ observes the value of ùëÄ from distribution ùê∑.

Example 1.1 is a challenging model for inference algo-
rithms in several regards: not only does the program use

 
 
 
 
 
 
PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

only applicable to very restricted classes of programs (most
notably, non-recursive models).

(cid:75)

Instead of computing approximate or exact results, this
work is concerned with computing guaranteed bounds on the
posterior distribution of a probabilistic program. Concretely,
given a probabilistic program ùëÉ and a measurable set ùëà ‚äÜ R
(given as an interval), we infer upper and lower bounds on
(ùëà ) (formally defined in Section 2), i.e. the posterior prob-
ùëÉ
ability of ùëÉ on ùëà .2 Such bounds provide a ground truth to
(cid:74)
compare approximate inference results with: if the approx-
imate results violate the bounds, the inference algorithm
has not converged yet or is even ill-suited to the program
in question. Crucially, our method is applicable to arbitrary
(and in particular recursive) programs of a universal PPL. For
Example 1.1, the bounds computed by our method (which
we give in Section 7) are tight enough to separate the IS and
HMC output. In this case, our method infers that the results
given by HMC are wrong (i.e. violate the guaranteed bounds)
whereas the IS results are plausible (i.e. lie within the guar-
anteed bounds). To the best of our knowledge, no existing
methods can provide such definite answers for programs of
a universal PPL.

1.2 Contributions
The starting point of our work is an interval-based opera-
tional semantics [4]. In our semantics, we evaluate a program
on interval traces (i.e. sequences of intervals of reals with
endpoints between 0 and 1) to approximate the outcomes of
sampling, and use interval arithmetic [19] to approximate
numerical operations (Section 3). Our semantics is sound in
the sense that any (compatible and exhaustive) set of inter-
val traces yields lower and upper bounds on the posterior
distribution of a program. These lower/upper bounds are
themselves super-/subadditive measures. Moreover, under
mild conditions (mostly restrictions on primitive operations),
our semantics is also complete, i.e. for any ùúñ > 0 there ex-
ists a countable set of interval traces that provides ùúñ-tight
bounds on the posterior. Our proofs hinge on a combination
of stochastic symbolic execution and the convergence of
Riemann sums, providing a natural correspondence between
our interval trace semantics and the theory of (Riemann)
integration (Section 4).

Based on our interval trace semantics, we present a prac-
tical algorithm to automate the computation of guaranteed
bounds. It employs an interval type system (together with
constraint-based type inference) that bounds both the value
of an expression in a refinement-type fashion and the score
weight of any evaluation thereof. The (interval) bounds in-
ferred by our type system fit naturally in the domain of
our semantics. This enables a sound approximation of the

2By repeated application of our method on a discretisation of the domain
we can compute histogram-like bounds.

Figure 1. Histogram of samples from the posterior distri-
bution of Example 1.1 and wrong samples produced by the
probabilistic programming system Pyro.

stochastic branching and recursion, but the number of ran-
dom variables generated is unbounded ‚Äì it‚Äôs nonparametric
[29, 37, 42]. To approximate the posterior distribution of
the program, we apply two standard inference algorithms:
likelihood-weighted importance sampling (IS), a simple al-
gorithm that works well on low-dimensional models with
few observations [49]; and Hamiltonian Monte Carlo (HMC)
[21], a successful MCMC algorithm that uses gradient infor-
mation to efficiently explore the parameter space of high-
dimensional models. Figure 1 shows the results of the two
inference methods as implemented in Anglican [61] (for IS)
and Pyro [5] (for HMC): they clearly disagree! But how is
the user supposed to know which (if any) of the two results
is correct?

Note that exact inference methods (i.e. methods that try
to compute a closed-form solution of the posterior inference
problem using computer algebra and other forms of symbolic
computation) such as PSI [26, 27], Hakaru [47], Dice [38],
and SPPL [55] are only applicable to non-recursive models,
and so they don‚Äôt work for Example 1.1.

1.1 Guaranteed Bounds
The above example illustrates central problems with both
approximate stochastic and exact inference methods. For
approximate methods, there are no guarantees for the results
they output after a finite amount of time, leading to unclear
inference results (as seen in Fig. 1).1 For exact methods, the
symbolic engine may fail to find a closed-form description
of the posterior distribution and, more importantly, they are

1Take MCMC sampling algorithms. Even though the Markov chain will
eventually converge to the target distribution, we do not know how long to
iterate the chain to ensure convergence [49, 53]. Likewise for variational
inference [64]: given a variational family, there is no guarantee that a
given value for the KL-divergence (from the approximating to the posterior
distribution) is attainable by the minimising distribution.

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

behaviour of a program with finitely many interval traces
(Section 5).

We implemented our approach in a tool called GuBPI3
(Guaranteed Bounds for Posterior Inference), described in
Section 6, and evaluate it on a suite of benchmark programs
from the literature. We find that the bounds computed by
GuBPI are competitive in many cases where the posterior
could already be inferred exactly. Moreover, GuBPI‚Äôs bounds
are useful (in the sense that they are precise enough to rule
out erroneous approximate results as in Fig. 1, for instance)
for recursive models that could not be handled rigorously by
any method before (Section 7).

1.3 Scope and Limitations
The contributions of this paper are of both theoretical and
practical interest. On the theoretical side, our novel seman-
tics underpins a sound and deterministic method to compute
guaranteed bounds on program denotations. As shown by
our completeness theorem, this analysis is applicable‚Äîin the
sense that it computes arbitrarily tight bounds‚Äîto a very
broad class of programs. On the practical side, our analyser
GuBPI implements (an optimised version of) our semantics.
As is usual for exact/guaranteed4 methods, our semantics
considers an exponential number of program paths, and par-
titions each sampled value into a finite number of interval
approximations. Consequently, GuBPI generally struggles
with high-dimensional models. We believe GuBPI to be most
useful for unit-testing of implementations of Bayesian infer-
ence algorithms such as Example 1.1, or to compute results
on (recursive) programs when non-stochastic, guaranteed
bounds are needed.

2 Background
2.1 Basic Probability Theory and Notation
We assume familiarity with basic probability theory, and
refer to [51] for details. Here we just fix the notation. A mea-
surable space is a pair (Œ©, Œ£Œ©) where Œ© is a set (of outcomes)
and Œ£Œ© ‚äÜ 2Œ© is a ùúé-algebra defining the measurable subsets
of Œ©. A measure on (Œ©, Œ£Œ©) is a function ùúá : Œ£Œ© ‚Üí R‚â•0‚à™{‚àû}
that satisfies ùúá (‚àÖ) = 0 and is ùúé-additive. For Rùëõ, we write
Œ£Rùëõ for the Borel ùúé-algebra and ùúÜùëõ for the Lebesgue mea-
sure on (Rùëõ, Œ£Rùëõ ). The Lebesgue integral of a measurable
function ùëì with respect to a measure ùúá is written ‚à´ ùëì dùúá
or ‚à´ ùëì (ùë•) ùúá (dùë•). Given a predicate ùúì on Œ©, we define the
Iverson brackets [ùúì ] : Œ© ‚Üí R by mapping all elements that
satisfy ùúì to 1 and all others to 0. For ùê¥ ‚àà Œ£Œ© we define the
bounded integral ‚à´
ùê¥

ùëì dùúá := ‚à´ ùëì (ùë•) ¬∑ [ùë• ‚àà ùê¥]ùúá (dùë•).

3GuBPI (pronounced ‚Äúguppy‚Äù) is available at gubpi-tool.github.io.
4By ‚Äúexact/guaranteed methods‚Äù, we mean inference algorithms that com-
pute deterministic (non-stochastic) results about the mathematical denota-
tion of a program. In particular, they are correct with probability 1, contrary
to stochastic methods.

((ùúÜùë• .ùëÄ)ùëâ , ùíî, ùë§) ‚Üí (ùëÄ [ùëâ /ùë•], ùíî, ùë§)

(sample, ùëü ùíî, ùë§) ‚Üí (ùëü, ùíî, ùë§)

((ùúáùúë

ùë• . ùëÄ)ùëâ , ùíî, ùë§) ‚Üí (ùëÄ [ùëâ /ùë•, (ùúáùúë

ùë• . ùëÄ)/ùúë], ùíî, ùë§)

(ùëì (ùëü1, . . . , ùëü |ùëì |), ùíî, ùë§) ‚Üí (ùëì (ùëü1, . . . , ùëü |ùëì |), ùíî, ùë§)

ùëü ‚â§ 0
(if (ùëü, ùëÅ , ùëÉ), ùíî, ùë§) ‚Üí (ùëÅ , ùíî, ùë§)
ùëü ‚â• 0
(score(ùëü ), ùíî, ùë§) ‚Üí (ùëü, ùíî, ùë§ ¬∑ ùëü )

ùëü > 0
(if(ùëü, ùëÅ , ùëÉ), ùíî, ùë§) ‚Üí (ùëÉ, ùíî, ùë§)
(ùëÖ, ùíî, ùë§) ‚Üí (ùëÄ, ùíî ‚Ä≤, ùë§ ‚Ä≤)
(ùê∏ [ùëÖ], ùíî, ùë§) ‚Üí (ùê∏ [ùëÄ], ùíî ‚Ä≤, ùë§ ‚Ä≤)

Figure 2. Standard (CbV) reduction rules for SPCF (‚Üí).

2.2 Statistical PCF (SPCF)
As our probabilistic programming language of study, we use
statistical PCF (SPCF) [41], a typed variant of [7]. SPCF in-
cludes primitive operations which are measurable functions
ùëì : R|ùëì | ‚Üí R, where |ùëì | ‚â• 0 denotes the arity of the function.
Values and terms of SPCF are defined as follows:

ùëâ := ùë• | ùëü | ùúÜùë• .ùëÄ | ùúáùúë

ùë• . ùëÄ

ùëÄ, ùëÅ , ùëÉ := ùëâ | ùëÄùëÅ | if (ùëÄ, ùëÅ , ùëÉ) | ùëì (ùëÄ1, . . . , ùëÄ |ùëì |)

| sample | score(ùëÄ)

where ùë• and ùúë are variables, ùëì is a primitive operation, and
ùëü a constant with ùëü ‚àà R. Note that we write ùúáùúë
ùë• . ùëÄ instead
of Y(ùúÜùúëùë• .ùëÄ) for the fixpoint construct. The branching con-
struct is if (ùëÄ, ùëÅ , ùëÉ), which evaluates to ùëÅ if ùëÄ ‚â§ 0 and
ùëÉ otherwise. In SPCF, sample draws a random value from
the uniform distribution on [0, 1], and score(ùëÄ) weights
the current execution with the value of ùëÄ. Samples from
a different real-valued distribution ùê∑ can be obtained by
applying the inverse of the cumulative distribution func-
tion for ùê∑ to a uniform sample [54]. Most PPLs feature an
observe statement instead of manipulating the likelihood
weight directly with score, but they are equally expressive
[59].5 As usual, we write let ùë• = ùëÄ in ùëÅ for (ùúÜùë• .ùëÅ )ùëÄ, ùëÄ; ùëÅ
for let _ = ùëÄ in ùëÅ and ùëÄ ‚äïùëù ùëÅ for if (sample ‚àí ùëù, ùëÄ, ùëÅ ). The
type system of our language is as expected, with simple types
being generated by ùõº, ùõΩ := R | ùõº ‚Üí ùõΩ. Selected rules are
given below:

Œì ‚ä¢ sample : R

Œì, ùúë : ùõº ‚Üí ùõΩ, ùë• : ùõº ‚ä¢ ùëÄ : ùõΩ

Œì ‚ä¢ ùúáùúë

ùë• . ùëÄ : ùõº ‚Üí ùõΩ

Œì ‚ä¢ ùëÄ : R
Œì ‚ä¢ score(ùëÄ) : R
{Œì ‚ä¢ ùëÄùëñ : R} |ùëì |
ùëñ=1
Œì ‚ä¢ ùëì (ùëÄ1, . . . , ùëÄ |ùëì |) : R

5 In Bayesian terms, an observe statement multiplies the likelihood func-
tion by the probability (density) of the observation [33] (as we have used in
Example 1.1). Scoring makes this explicit by keeping a weight for each pro-
gram execution [7]. Observing a value ùë£ from a distribution ùê∑ then simply
multiplies the current weight by pdfùê∑ (ùë£) where pdfùê∑ is the probability
density function of ùê∑ (for continuous distributions) or the probability mass
function of ùê∑ (for discrete distributions).

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

2.3 Trace Semantics
Following [7], we endow SPCF with a trace-based opera-
tional semantics. We evaluate a probabilistic program ùëÉ on
a fixed trace ùíî = ‚ü®ùëü1, . . . , ùëüùëõ‚ü© ‚àà T := (cid:208)ùëõ ‚ààN [0, 1]ùëõ, which
predetermines the probabilistic choices made during the eval-
uation. Our semantics therefore operates on configurations
of the form (ùëÄ, ùíî, ùë§) where ùëÄ is an SPCF term, ùíî is a trace
and ùë§ ‚àà R‚â•0 a weight. The call-by-value (CbV) reduction is
given by the rules in Fig. 2, where ùê∏ [¬∑] denotes a CbV eval-
uation context. The definition is standard [4, 7, 41]. Given
a program ‚ä¢ ùëÉ : R, we call a trace ùíî terminating just if
(ùëÉ, ùíî, 1) ‚Üí‚àó (ùëâ , ‚ü®‚ü©, ùë§) for some value ùëâ and weight ùë§, i.e. if
the samples drawn are as specified by ùíî, the program ùëÉ ter-
minates. Note that we require the trace ùíî to be completely
used up. As ùëÉ is of type R we can assume that ùëâ = ùëü for
some ùëü ‚àà R. Each terminating trace ùíî therefore uniquely
determines the returned value ùëü where ùëü =: valùëÉ (ùíî) ‚àà R,
and the weight ùë§ =: wtùëÉ (ùíî) ‚àà R‚â•0, of the execution. For a
nonterminating trace ùíî, valùëÉ (ùíî) is undefined and wtùëÉ (ùíî) := 0.

Example 2.1. Consider Example 1.1. On the trace ùíî = ‚ü®0.1,
0.2, 0.4, 0.7, 0.8‚ü© ‚àà [0, 1]5 ‚äÜ T, the pedestrian walks 0.2 away
from their home (taking the left branch of ‚äï0.5 as 0.4 ‚â§ 0.5)
and 0.7 towards their home (as 0.8 > 0.5), hence:

valùëÉ (ùíî) = 3 √ó 0.1 = 0.3, wtùëÉ (ùíî) = pdf Normal(1.1,0.1) (0.9).
In order to do measure theory, we need to turn our set of
traces into a measurable space. The trace space T is equipped
with the ùúé-algebra Œ£T := {(cid:208)ùëõ ‚ààN ùëàùëõ | ùëàùëõ ‚àà Œ£ [0,1]ùëõ } where
Œ£ [0,1]ùëõ is the Borel ùúé-algebra on [0, 1]ùëõ . We define a measure
ùúáT by ùúáT (ùëà ) := (cid:205)ùëõ ‚ààN ùúÜùëõ (ùëà ‚à© [0, 1]ùëõ), as in [7].

We can now define the semantics of an SPCF program
‚ä¢ ùëÉ : R by using the weight and returned value of (executions
of ùëÉ determined by) individual traces. Given ùëà ‚àà Œ£R, we need
to define the likelihood of ùëÉ evaluating to a value in ùëà . To this
end, we set val‚àí1
ùëÉ (ùëà ) := {ùíî ‚àà T | (ùëÉ, ùíî, 1) ‚Üí‚àó (ùëü, ‚ü®‚ü©, ùë§), ùëü ‚àà
ùëà }, i.e. the set of traces on which the program ùëÉ reduces to a
value in ùëà . As shown in [7, Lem. 9], val‚àí1
ùëÉ (ùëà ) is measurable.
Thus, we can define (cf. [7, 41])

(ùëà ) := ‚à´

ùëÉ (ùëà ) wtùëÉ (ùíî) ùúáT (dùíî).

val‚àí1

ùëÉ
(cid:74)

(cid:75)

That is, the integral takes all traces ùíî on which ùëÉ evaluates
to a value in ùëà , weighting each ùíî with the weight wtùëÉ (ùíî) of
the corresponding execution. A program ùëÉ is called almost
surely terminating (AST) if it terminates with probability
1, i.e. ùúáT (val‚àí1
ùëÉ (R)) = 1. This is a necessary assumption for
approximate inference algorithms (since they execute the
program). See [7] for a more in-depth discussion of this
(standard) sampling-style semantics.

Normalizing constant and integrability. In Bayesian
statistics, one is usually interested in the normalised pos-
terior, which is a conditional probability distribution. We
ùëÉ
where
obtain the normalised denotation as posteriorùëÉ := (cid:74)
(cid:75)ùëçùëÉ

(cid:75)

ùëÉ
(cid:74)

(R) is the normalising constant. We call ùëÉ inte-
ùëçùëÉ :=
grable if 0 < ùëçùëÉ < ‚àû. The bounds computed in this paper
(on the unnormalised denotation
) allow us to compute
(cid:75)
bounds on the normalizing constant ùëçùëÉ , and thereby also on
the normalised denotation. All bounds reported in this paper
(in particular in Section 7) refer to the normalised denotation.

ùëÉ
(cid:74)

(cid:75)

ùëÉ
(cid:74)

3 Interval Trace Semantics
In order to obtain guaranteed bounds on the distribution
denotation
(and also on posteriorùëÉ ) of a program ùëÉ, we
present an interval-based semantics. In our semantics, we
approximate the outcomes of sample with intervals and han-
dle arithmetic operations by means of interval arithmetic
(which is similar to the approach by Beutner and Ong [4]
in the context of termination analysis). Our semantics en-
ables us to reason about the denotation of a program without
considering the uncountable space of traces explicitly.

3.1 Interval Arithmetic
For our purposes, an interval has the form [ùëé, ùëè] which
denotes the set {ùë• ‚àà R | ùëé ‚â§ ùë• ‚â§ ùëè}, where ùëé ‚àà R ‚à™ {‚àí‚àû},
ùëè ‚àà R ‚à™ {‚àû}, and ùëé ‚â§ ùëè. For consistency, we write [0, ‚àû]
instead of the more typical [0, ‚àû). For ùëã ‚äÜ R ‚à™ {‚àí‚àû, ‚àû}, we
denote by Iùëã the set of intervals with endpoints in ùëã , and
simply write I for IR‚à™{‚àí‚àû,‚àû}. An ùëõ-dimensional box is the
Cartesian product of ùëõ intervals.

We can lift functions on real numbers to intervals as fol-

lows: for each ùëì : Rùëõ ‚Üí R we define ùëì I : Iùëõ ‚Üí I by

ùëì I ([ùëé1, ùëè1], . . . , [ùëéùëõ, ùëèùëõ]) := [inf ùêπ, sup ùêπ ]

where ùêπ := ùëì ([ùëé1, ùëè1], . . . , [ùëéùëõ, ùëèùëõ]). For common functions
like +, ‚àí, √ó, | ¬∑ |, min, max, and monotonically increasing
: R ‚Üí R, their interval-lifted
or decreasing functions ùëì
counterparts can easily be computed, from the values of the
original function on just the endpoints of the input interval.
For example, addition lifts to [ùëé1, ùëè1] +I [ùëé2, ùëè2] = [ùëé1 +ùëé2, ùëè1 +
ùëè2]; similarly for multiplication √óI.

3.2 Interval Traces and Interval SPCF
In our interval interpretation, probabilistic programs are run
on interval traces. An interval trace, ‚ü®ùêº1, . . . , ùêºùëõ‚ü© ‚àà TI
:=
(cid:208)ùëõ ‚ààN(I[0,1])ùëõ, is a finite sequence of intervals ùêº1, . . . , ùêºùëõ, each
with endpoints between 0 and 1. To distinguish ordinary
traces ùíî ‚àà T from interval traces ùíï ‚àà TI, we call the former
concrete traces.

We define the refinement relation ‚ä≥ between concrete
and interval traces as follows: for ùíî = ‚ü®ùëü1, . . . , ùëüùëõ‚ü© ‚àà T and
ùíï = ‚ü®ùêº1, . . . , ùêºùëö‚ü© ‚àà TI, we define ùíî ‚ä≥ ùíï just if ùëõ = ùëö and
for all ùëñ, ùëüùëñ ‚àà ùêºùëñ . For each interval trace ùíï, we denote by
ùíï

:= {ùíî ‚àà T | ùíî ‚ä≥ ùíï } the set of all refinements of ùíï.
(cid:76)
(cid:77)
To define a reduction of a term on an interval trace, we
extend SPCF with interval literals [ùëé, ùëè], which replace the
literals ùëü but are still considered values of type R. In fact, ùëü

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

((ùúÜùë• .ùëÄ)ùëâ , ùíï, ùë§) ‚ÜíI (ùëÄ [ùëâ /ùë•], ùíï, ùë§)

(sample, ùêº ùíï, ùë§) ‚ÜíI (ùêº, ùíï, ùë§)

((ùúáùúë

ùë• . ùëÄ)ùëâ , ùíï, ùë§) ‚ÜíI (ùëÄ [ùëâ /ùë•, (ùúáùúë

ùë• . ùëÄ)/ùúë], ùíï, ùë§)

ùëè ‚â§ 0
(if( [ùëé, ùëè], ùëÅ , ùëÉ), ùíï, ùë§) ‚ÜíI (ùëÅ , ùíï, ùë§)
ùëé > 0
(if ( [ùëé, ùëè], ùëÅ , ùëÉ), ùíï, ùë§) ‚ÜíI (ùëÉ, ùíï, ùë§)

(ùëì (ùêº1, . . . , ùêº |ùëì |), ùíï, ùë§) ‚ÜíI (ùëì I (ùêº1, . . . , ùêº |ùëì |), ùíï, ùë§)

ùëé ‚â• 0
(score([ùëé, ùëè]), ùíï, ùë§) ‚ÜíI ([ùëé, ùëè], ùíï, ùë§ √óI [ùëé, ùëè])

(ùëÖ, ùíï, ùë§) ‚ÜíI (ùëÄ, ùíï ‚Ä≤, ùë§ ‚Ä≤)
(ùê∏ [ùëÖ], ùíï, ùë§) ‚ÜíI (ùê∏ [ùëÄ], ùíï ‚Ä≤, ùë§ ‚Ä≤)

Figure 3. Interval reduction rules for (interval) SPCF (‚ÜíI).

can be read as an abbreviation for [ùëü, ùëü ]. We call such terms
interval terms, and the resulting language Interval SPCF.
Reduction. The interval-based reduction ‚ÜíI now oper-
ates on configurations (ùëÄ, ùíï, ùë§) of interval terms ùëÄ, interval
traces ùíï ‚àà TI, and interval weights ùë§ ‚àà IR‚â•0‚à™{‚àû}. The re-
dexes and evaluation contexts of SPCF extend naturally to
interval terms. The reduction rules are given in Fig. 3.6

Given a program ‚ä¢ ùëÉ : R, the reduction relation ‚ÜíI al-
ùëÉ : TI ‚Üí

lows us to define the interval weight function (wtI
I
ùëÉ : TI ‚Üí I) by:
IR‚â•0‚à™{‚àû}) and interval value function (val
if (ùëÉ, ùíï, 1) ‚Üí‚àó
otherwise,

I
ùëÉ (ùíï) :=
wt

I (ùêº, ‚ü®‚ü©, ùë§)

I
ùëÉ (ùíï) :=
val

if (ùëÉ, ùíï, 1) ‚Üí‚àó
otherwise.

I (ùêº, ‚ü®‚ü©, ùë§)

It is not difficult to prove the following relationship be-

tween standard and interval reduction.

Lemma 3.1. Let ‚ä¢ ùëÉ : R be a program. For any interval trace
ùíï and concrete trace ùíî ‚ä≥ ùíï, we have wtùëÉ (ùíî) ‚àà wtI
ùëÉ (ùíï) and
valùëÉ (ùíî) ‚àà val

I
ùëÉ (ùíï) (provided valùëÉ (ùíî) is defined).

3.3 Bounds from Interval Traces

Lower bounds. How can we use this interval trace seman-
tics to obtain lower bounds on
? We need a few defini-
tions. Two intervals [ùëé1, ùëè1], [ùëé2, ùëè2] ‚àà I are called almost
disjoint if ùëè1 ‚â§ ùëé2 or ùëè2 ‚â§ ùëé1. Interval traces ‚ü®ùêº1, . . . , ùêºùëö‚ü© and
‚ü®ùêΩ1, . . . , ùêΩùëõ‚ü© ‚àà TI are called compatible if there is an index
ùëñ ‚àà {1, . . . , min(ùëö, ùëõ)} such that ùêºùëñ and ùêΩùëñ are almost disjoint.

ùëÉ
(cid:74)

(cid:75)

6For conditionals, the interval bound is not always precise enough to decide
which branch to take, so the reduction can get stuck if ùëé ‚â§ 0 < ùëè. We could
include additional rules to overapproximate the branching behaviour (see
Appendix A.4). But the rules given here simplify the presentation and are
sufficient to prove soundness and completeness.

(cid:40)ùë§
[0, ‚àû]
(cid:40)ùêº
[‚àí‚àû, ‚àû]

A set of interval traces is called compatible if its elements are
pairwise compatible. We define the volume of an interval
trace ùíï = ‚ü®[ùëé1, ùëè1], . . . , [ùëéùëõ, ùëèùëõ]‚ü© as vol(ùíï) := (cid:206)ùëõ
ùëñ=1 (ùëèùëñ ‚àí ùëéùëñ ).
Let T ‚äÜ TI be a countable and compatible set of interval

traces. Define the lower bound on

by
(cid:75)
ùëÉ (ùíï)) ¬∑ (cid:2)val
I
vol(ùíï) ¬∑ (min wt

ùëÉ
(cid:74)

I

ùëÉ (ùíï) ‚äÜ ùëà (cid:3)

lowerBdT

ùëÉ (ùëà ) :=

‚àëÔ∏Å

ùíï ‚àà T

for ùëà ‚àà Œ£R. That is, we sum over each interval trace in
T whose value is guaranteed to be in ùëà , weighted by its
volume and the lower bound of its weight interval. Note
that, in general, lowerBdT
ùëÉ is not a measure, but merely a
superadditive measure.7

Upper bounds. For upper bounds, we require the notion
of a set of interval traces being exhaustive, which is easiest
to express in terms of infinite traces. Let T‚àû := [0, 1]ùúî be
the set of infinite traces. Every interval trace ùíï covers the set
of infinite traces with a prefix contained in ùíï, i.e. cover (ùíï) :=
√ó T‚àû (where the Cartesian product √ó can be viewed
ùíï
(cid:76)
as trace concatenation). A countable set of (finite) interval
traces T ‚äÜ TI is called exhaustive if (cid:208)
ùíï ‚àà T cover (ùíï) covers
ùíï ‚àà T cover (ùíï)) = 0.8 Phrased
almost all of T‚àû, i.e. ùúáT‚àû (T‚àû \ (cid:208)
differently, almost all concrete traces must have a finite prefix
that is contained in some interval trace in T . Therefore, the
analysis in the interval semantics on T covers the behaviour
on almost all concrete traces (in the original semantics).

(cid:77)

2, 1]...ùëõ, [0, 1

Example 3.1. (i) The singleton set {‚ü®[0, 1], [0, 0.6]‚ü©} is not
exhaustive as, e.g. all infinite traces ‚ü®ùëü1, ùëü2, . . . ‚ü© with ùëü2 > 0.6
are not covered. (ii) The set {‚ü®[0, 0.6]‚ü©, ‚ü®[0.3, 1]‚ü©} is exhaus-
tive, but not compatible. (iii) Define T1 := {‚ü®[ 1
3 ]‚ü© |
ùëõ ‚àà N} and T2 := {‚ü®[ 1
2 ]‚ü© | ùëõ ‚àà N} where ùë• ...ùëõ de-
notes ùëõ-fold repetition of ùë•. T1 is compatible but not exhaus-
tive. For example, it doesn‚Äôt cover the set [ 1
2 ) √ó T‚àû,
3, 1
i.e. all traces ‚ü®ùëü1, ùëü2, . . . ‚ü© where ùëü1 ‚àà [ 1
2 ). T2
is compatible and exhaustive (the set of non-covered traces
( 1
2, 1]ùúî has measure 0).
Let T ‚äÜ TI be a countable and exhaustive set of interval

2, 1] √ó ( 1
3, 1
2, 1] and ùëü2 ‚àà ( 1

2, 1]...ùëõ, [0, 1

traces. Define the upper bound on
by
ùëÉ
(cid:74)
(cid:75)
‚àëÔ∏Å
ùëÉ (ùíï)) ¬∑ (cid:2)val
I
upperBdT
vol(ùíï) ¬∑ (sup wt

ùëÉ (ùëà ) :=

I

ùëÉ (ùíï) ‚à© ùëà ‚â† ‚àÖ(cid:3)

ùíï ‚àà T

for ùëà ‚àà Œ£R. That is, we sum over each interval trace in T
whose value may be in ùëà , weighted by its volume and the
upper bound of its weight interval. Note that upperBdT
ùëÉ is
not a measure but only a subadditive measure.9
7A superadditive measure ùúá on (Œ©, Œ£Œ©) is a measure, except that ùúé-additivity
is replaced by ùúé-superadditivity: ùúá ((cid:208)ùëñ‚ààN ùëàùëñ ) ‚â• (cid:205)ùëñ‚ààN ùúá (ùëàùëñ ) for a countable,
pairwise disjoint family (ùëàùëñ )ùëñ‚ààN ‚àà Œ£Œ©.
8The ùúé-algebra on T‚àû is defined as the smallest ùúé-algebra that contains all
sets ùëà √ó T‚àû where ùëà ‚àà Œ£ [0,1]ùëõ for some ùëõ ‚àà N. The measure ùúáT‚àû
is the
unique measure with ùúáT‚àû (ùëà √ó T‚àû) = ùúÜùëõ (ùëà ) when ùëà ‚àà Œ£ [0,1]ùëõ .
9A subadditive measure ùúá on (Œ©, Œ£Œ©) is a measure, except that ùúé-additivity
is replaced by ùúé-subadditivity: ùúá ((cid:208)ùëñ‚ààN ùëàùëñ ) ‚â§ (cid:205)ùëñ‚ààN ùúá (ùëàùëñ ) for a countable,
pairwise disjoint family (ùëàùëñ )ùëñ‚ààN ‚àà Œ£Œ©.

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

4 Soundness and Completeness
4.1 Soundness
We show that the two bounds described above are sound, in
the following sense.

Theorem 4.1 (Sound lower bounds). Let T be a countable
and compatible set of interval traces and ‚ä¢ ùëÉ : R a program.
Then lowerBdT
ùëÉ ‚â§
Proof. For any ùëà ‚àà Œ£R, we have:

ùëÉ
(cid:74)

(cid:75)

.

lowerBdT

ùëÉ (ùëà ) =

‚àëÔ∏Å

I
vol(ùíï)(min wt

ùëÉ (ùíï)) (cid:2)val

I

ùëÉ (ùíï) ‚äÜ ùëà (cid:3)

ùíï ‚ààT
‚àëÔ∏Å

‚à´

I
(min wt

ùëÉ (ùíï)) (cid:2)val

I

ùëÉ (ùíï) ‚äÜ ùëà (cid:3) dùíî

ùíï

(cid:77)

(cid:76)
‚à´

ùíï ‚ààT
‚àëÔ∏Å

ùíï

(cid:76)

(cid:77)

ùíï ‚ààT
‚à´

wtùëÉ (ùíî) (cid:2)valùëÉ (ùíî) ‚àà ùëà (cid:3) dùíî

wtùëÉ (ùíî) (cid:2)valùëÉ (ùíî) ‚àà ùëà (cid:3) dùíî

ùíï ‚ààT

ùíï

(cid:76)

(cid:77)

wtùëÉ (ùíî) (cid:2)valùëÉ (ùíî) ‚àà ùëà (cid:3) dùíî =

(cid:208)
‚à´

T

ùëÉ
(cid:74)

(cid:75)

(1)

(2)

(ùëà )

(3)

=

‚â§

=

‚â§

ùíï ‚ààT

where Eq. (1) follows from Lemma 3.1, Eq. (2) from compati-
bility, and Eq. (3) from (cid:208)
‚ñ°
ùíï

‚äÜ T.

ùëÉ
(cid:74)

‚â§ upperBdT
ùëÉ .

(cid:76)
(cid:77)
Theorem 4.2 (Sound upper bounds). Let T be a countable
and exhaustive set of interval traces and ‚ä¢ ùëÉ : R a program.
Then
Proof sketch. The formal proof is similar to the soundness
proof for the lower bound in Theorem 4.1, but needs an in-
finite trace semantics [16] for probabilistic programs and
is given in Appendix C.1. The idea is that each interval
trace ùíï summarises all infinite traces starting with
, i.e. all
(cid:77)
traces in cover (ùíï). Exhaustivity ensures that almost all infi-
‚ñ°
nite traces are ‚Äúcovered‚Äù.

(cid:75)

(cid:76)

ùíï

4.2 Completeness
The soundness results for upper and lower bounds allow us
to derive bounds on the denotation of a program. One would
expect that a finer partition of interval traces will yield more
precise bounds. In this section, we show that for a program
ùëÉ and an interval ùêº ‚àà I, the approximations lowerBdT
ùëÉ (ùêº )
and upperBdT
(ùêº )
ùëÉ
(cid:74)
for suitable T . However, this is only possible under certain
assumptions.

ùëÉ (ùêº ) can in fact come arbitrarily close to

(cid:75)

Assumption 1: use of sampled values. Interval arith-
metic is imprecise if the same value is used more than once:
consider, for instance, let ùë† = sample in if (ùë† ‚àí ùë†, 0, 1) which
deterministically evaluates to 0. However, in interval arith-
metic, if ùë• is approximated by an interval [ùëé, ùëè] with ùëé < ùëè,
the difference ùë• ‚àí ùë• is approximated as [ùëé ‚àí ùëè, ùëè ‚àí ùëé], which
always contains both positive and negative values. So no
non-trivial interval trace can separate the two branches.

To avoid this, we could consider a call-by-name semantics
(as done in [4]) where sample values can only be used once
by definition. However, many of our examples cannot be
expressed in the call-by-name setting, so we instead propose
a less restrictive criterion to guarantee completeness for
call-by-value: we allow sample values to be used more than
once, but at most once in the guard of each conditional, at
most once in each score expression, and at most once in the
return value. While this prohibits terms like the one above, it
allows, e.g. let ùë† = sample in if (ùë†, ùëì (ùë†), ùëî(ùë†)). This sufficient
condition is formalised in Appendix C.3. Most examples we
encountered in the literature satisfy this assumption.

Assumption 2: primitive functions. In addition, we re-
quire mild assumptions on the primitive functions, called
boxwise continuity and interval separability.

We need to be able to approximate a program‚Äôs weight
function by step functions in order to obtain tight bounds on
its integral. A function ùëì : Rùëõ ‚Üí R is boxwise continuous
if it can be written as the countable union of continuous
functions on boxes, i.e. if there is a countable union of pair-
wise almost disjoint boxes ùêµùëñ such that (cid:208) ùêµùëñ = Rùëõ and the
restriction ùëì |ùêµùëñ is continuous for each ùêµùëñ .

Furthermore, we need to approximate preimages. For-
mally, we say that ùê¥ is a tight subset of ùêµ (written ùê¥ ‚ãê ùêµ) if
ùê¥ ‚äÜ ùêµ and ùêµ \ ùê¥ is a null set. A function ùëì : Rùëõ ‚Üí R is called
interval separable if for every interval [ùëé, ùëè] ‚àà I, there is
a countable set B of boxes in Rùëõ that tightly approximates
the preimage, i.e. (cid:208) B ‚ãê ùëì ‚àí1([ùëé, ùëè]). A sufficient condition
for checking this is the following. If ùëì is boxwise continuous
and preimages of points have measure zero, then ùëì is already
interval separable (cf. Lemma C.4).

We assume the set F of primitive functions is closed under
composition and each ùëì ‚àà F is boxwise continuous and
interval separable.

The completeness theorem. Using these two assumptions,

we can state completeness of our interval semantics.

Theorem 4.3 (Completeness of interval approximations).
Let ùêº ‚àà I and ‚ä¢ ùëÉ : R be an almost surely terminating program
satisfying the two assumptions discussed above. Then, for all
ùúñ > 0, there is a countable set of interval traces T ‚äÜ TI that is
compatible and exhaustive such that

ùëÉ
(cid:74)

upperBdT

ùëÉ (ùêº ) ‚àí ùúñ ‚â§

(ùêº ) ‚â§ lowerBdT

ùëÉ (ùêº ) + ùúñ.

(cid:75)
Proof sketch. We consider each branching path through the
program separately. The set of relevant traces for a given
path is a preimage of intervals under compositions of interval
separable functions, hence can essentially be partitioned into
boxes. By boxwise continuity, we can refine this partition
such that the weight function is continuous on each box. To
approximate the integral, we pass to a refined partition again,
essentially computing Riemann sums. The latter converge

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

to the Riemann integral, which agrees with the Lebesgue
‚ñ°
integral under our conditions, as desired.

For the lower bound, we can actually derive ùúñ-close bounds

using only finitely many interval traces:

ùëÉ
(cid:74)

(cid:75)

Corollary 4.4. Let ùêº ‚àà I and ‚ä¢ ùëÉ : R be as in Theorem 4.3.
There is a sequence of finite, compatible sets of interval traces
T1, T2, . . . ‚äÜ TI s.t. limùëõ‚Üí‚àû lowerBdTùëõ

ùëÉ (ùêº ) =

(ùêº ).

For the upper bound, a restriction to finite sets T of in-
terval traces is, in general, not possible: if the weight func-
tion for a program is unbounded, it is also unbounded on
some ùíï ‚àà T . Then wtI
ùëÉ (ùíï) is an infinite interval, implying
upperBdT
ùëÉ (ùêº ) = ‚àû (see Example C.3 for details). Despite the
(theoretical) need for countably infinite many interval traces,
we can, in many cases, compute finite upper bounds by mak-
ing use of an interval-based static approximation, formalised
as a type system in the next section.

5 Weight-aware Interval Type System
To obtain sound bounds on the denotation with only finitely
many interval traces, we present an interval-based type sys-
tem that can derive static bounds on a program. Crucially,
our type-system is weight-aware: we bound not only the re-
turn value of a program but also the weight of an execution.
Our analyzer GuBPI uses it for two purposes. First, it allows
us to derive upper bounds even for areas of the sample space
not covered with interval traces. Second, we can use our
analysis to derive a finite (and sound) approximation of the
infinite number of symbolic execution paths of a program
(more details are given in Section 6). Note that the bounds
inferred by our system are interval bounds, which allow for
seamless integration with our interval trace semantics. In
this section, we present the interval type system and sketch
a constraint-based type inference method.

5.1 Interval Types
We define interval types by the following grammar:

ùúé := ùêº | ùúé ‚Üí A

A :=

(cid:27)

(cid:26)ùúé
ùêº

where ùêº ‚àà I is an interval. For readers familiar with refine-
ment types, it is easiest to view the type ùúé = ùêº as the refine-
ment type {ùë• : R | ùë• ‚àà ùêº }. The definition of the syntactic
category A by mutual recursion with ùúé gives a bound on the
weight of the execution. We call a type ùúé weightless and a
type A weighted. The following examples should give some
intuition about the types.

Example 5.1. Consider the example term

(cid:0)ùúáùúë

ùë• . 5 √ó ùë• ‚äï0.5 sigm(ùúë ùë• + score sample)(cid:1) (4 √ó sample)
where sigm : R ‚Üí [0, 1] is the sigmoid function. In our type
system, this term can be typed with the weighted type (cid:26)[0, 20]
(cid:27),
[0, 1]
which indicates that any terminating execution of the term

ùë• : ùúé ‚àà Œì
(cid:27)
(cid:26)ùúé
1

Œì ‚ä¢ ùë• :

Œì ‚ä¢ ùëÄ : A A ‚äëA B
Œì ‚ä¢ ùëÄ : B

Œì; ùúë : ùúé ‚Üí A; ùë• : ùúé ‚ä¢ ùëÄ : A

Œì ‚ä¢ ùúáùúë

ùë• . ùëÄ :

(cid:27)

(cid:26)ùúé ‚Üí A
1

Œì; ùë• : ùúé ‚ä¢ ùëÄ : A
(cid:26)ùúé ‚Üí A
1

Œì ‚ä¢ ùúÜùë• .ùëÄ :

(cid:27)

Œì ‚ä¢ ùëÄ :

(cid:27)

(cid:26) ùúé2
[ùëí, ùëì ]

ùúé1 ‚Üí

Ô£±Ô£¥Ô£¥Ô£≤
Ô£¥Ô£¥
Ô£≥
Œì ‚ä¢ ùëÄùëÅ :

[ùëé, ùëè ]
(cid:26)

Ô£ºÔ£¥Ô£¥Ô£Ω
Ô£¥Ô£¥
Ô£æ

ùúé2
[ùëé, ùëè ] √óI [ùëê, ùëë ] √óI [ùëí, ùëì ]

(cid:27)

Œì ‚ä¢ ùëÅ :

(cid:27)

(cid:26) ùúé1
[ùëê, ùëë ]

Œì ‚ä¢ ùëÄ :

(cid:27)

(cid:26) [_, _]
[ùëé, ùëè ]

Œì ‚ä¢ ùëÅ :

(cid:27)

(cid:26) ùúé
[ùëê, ùëë ]

Œì ‚ä¢ ùëÉ :

(cid:27)

(cid:26) ùúé
[ùëê, ùëë ]

Œì ‚ä¢ ùëü :

(cid:27)

(cid:26) [ùëü, ùëü ]
1

Œì ‚ä¢ if (ùëÄ, ùëÅ , ùëÉ ) :

(cid:26)

ùúé
[ùëé, ùëè ] √óI [ùëê, ùëë ]

(cid:27)

Œì ‚ä¢ ùëÄ :

(cid:27)

(cid:26) [ùëé, ùëè ]
[ùëê, ùëë ]

Œì ‚ä¢ sample :

(cid:27)

(cid:26) [0, 1]
1

Œì ‚ä¢ score(ùëÄ) :

(cid:26)

[ùëé, ùëè ] ‚äì [0, ‚àû]
[ùëê, ùëë ] √óI (cid:0) [ùëé, ùëè ] ‚äì [0, ‚àû](cid:1)

(cid:27)

Œì ‚ä¢ ùëÄ1 :

(cid:27)

(cid:26) [ùëé1, ùëè1 ]
[ùëê1, ùëë1 ]

Œì ‚ä¢ ùëì (ùëÄ1, . . . , ùëÄ|ùëì |) :

(cid:27)

¬∑ ¬∑ ¬∑

Œì ‚ä¢ ùëÄ|ùëì | :

(cid:26) [ùëé|ùëì |, ùëè|ùëì | ]
[ùëê |ùëì |, ùëë|ùëì | ]
(cid:41)
(cid:40)ùëì I ( [ùëé1, ùëè1 ], . . . , [ùëé|ùëì |, ùëè|ùëì | ])

(√óI) |ùëì |

ùëñ=1 [ùëêùëñ, ùëëùëñ ]

Figure 4. Weight-aware interval type system for SPCF. We
abbreviate 1 := [1, 1].

reduces to a value (a number) within [0, 20] and the weight
of any such execution lies within [0, 1].

Example 5.2. We consider the fixpoint subexpression of
the pedestrian example in Example 1.1 which is
ùúáùúë
ùë• .if (ùë•, 0, (cid:0)ùúÜstep.step + ùúë ((ùë• +step) ‚äï0.5 (ùë• ‚àístep))(cid:1)sample).

(cid:27)

Ô£ºÔ£¥Ô£¥Ô£Ω
Ô£¥Ô£¥
Ô£æ

[1, 1]

[ùëé, ùëè] ‚Üí

(cid:26)[0, ‚àû]
[1, 1]

Using the typing rules (defined below), we can infer the
for any ùëé, ùëè. This type indicates that any
type Ô£±Ô£¥Ô£¥Ô£≤
Ô£¥Ô£¥
Ô£≥

terminating execution reduces to a function value (of simple
type R ‚Üí R) with weight within [1, 1]. If this function
value is then called on a value within [ùëé, ùëè], any terminating
execution reduces to a value within [0, ‚àû] with a weight
within [1, 1].

Subtyping. The partial order on intervals naturally ex-
tends to our type system. For base types ùêº1 and ùêº2, we define
ùêº1 ‚äëùúé ùêº2 just if ùêº1 ‚äë ùêº2, where ‚äë is interval inclusion. We then
extend this via:

ùúé2 ‚äëùúé ùúé1
A1 ‚äëA A2
ùúé1 ‚Üí A1 ‚äëùúé ùúé2 ‚Üí A2

ùúé1 ‚äëùúé ùúé2
(cid:26)ùúé1
(cid:27)
ùêº1

‚äëA

ùêº1 ‚äë ùêº2
(cid:26)ùúé2
(cid:27)
ùêº2

Note that in the case of weighted types, the subtyping re-
quires not only that the weightless types be subtype-related
(ùúé1 ‚äëùúé ùúé2) but also that the weight bound be refined ùêº1 ‚äë ùêº2.
It is easy to see that both ‚äëA and ‚äëùúé are partial orders on
types with the same underlying base type.

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

5.2 Type System
As for the interval-based semantics, we assume that every
primitive operation ùëì : Rùëõ ‚Üí R has an overapproximating
interval abstraction ùëì I : Iùëõ ‚Üí I (cf. Section 3.1). Interval
typing judgments have the form Œì ‚ä¢ ùëÄ : A where Œì is a
typing context mapping variables to types ùúé. They are given
via the rules in Fig. 4. Our system is sound in the following
sense (which we here only state for first-order programs).

Theorem 5.1. Let ‚ä¢ ùëÉ : R be a simply-typed program. If
‚ä¢ ùëÉ : (cid:26)[ùëé, ùëè]
and (ùëÉ, ùíî, 1) ‚Üí‚àó (ùëü, ‚ü®‚ü©, ùë§) for some ùíî ‚àà T and
[ùëê, ùëë]
ùëü, ùë§ ‚àà R, then ùëü ‚àà [ùëé, ùëè] and ùë§ ‚àà [ùëê, ùëë].

(cid:27)

Note that the bounds derived by our type system only
refer to terminating executions, i.e. they are partial correct-
ness statements. Theorem 5.1 formalises the intuition of an
interval type, i.e. every type derivation in our system bounds
both the returned value (in typical refinement-type fashion
[24]) and the weight of this derivation. Our type system also
comes with a weak completeness statement: for each term,
we can derive some bounds in our system.

Proposition 5.2. Let ‚ä¢ ùëÉ : ùõº be a simply-typed program.
There exists a weighted interval type A such that ‚ä¢ ùëÉ : A.

5.3 Constraint-based Type Inference
In this section, we briefly discuss the automated type infer-
ence in our system, as needed in our tool GuBPI. For space
reasons, we restrict ourselves to an informal overview (see
Appendix D for a full account).

Given a program ùëÉ, we can derive the symbolic skeleton
of a type derivation (the structure of which is determined by
ùëÉ), where each concrete interval is replaced by a placeholder
variable. The validity of a typing judgment within this skele-
ton can then be encoded as constraints. Crucially, as we work
in the fixed interval domain and the subtyping structure ‚äëA
is compositional, they are simple constraints over the place-
holder variables in the abstract interval domain. Solving the
resulting constraints na√Øvely might not terminate since the
interval abstract domain is not chain-complete. Instead, we
approximate the least fixpoint (where the fixpoint denotes a
solution to the constraints) using widening, a standard ap-
proach to ensure termination of static analysis on domains
with infinite chains [13, 14]. This is computationally much
cheaper compared to, say, types with general first-order re-
finements where constraints are typically phrased as con-
strained Horn clauses (see e.g. [11]). This gain in efficiency
is crucial to making our GuBPI tool practical.

6.1 Symbolic Execution
The starting point of our analysis is a symbolic exploration of
the term in question [10, 28, 41]. For space reasons we only
give an informal overview of the approach. A detailed and
formal discussion can be found in Appendix B.

The idea of symbolic execution is to treat outcomes of
sample expressions fully symbolically: each sample evalu-
ates to a fresh variable (ùõº1, ùõº2, . . . ), called sample variable.
The result of symbolic execution is thus a symbolic value: a
term consisting of sample variables and delayed primitive
function applications. We postpone branching decisions and
the weighting with score expressions because the value in
question is symbolic. During execution, we therefore ex-
plore both branches of a conditional and keep track of the
(symbolic) conditions on the sample variables that need to
hold in the current branch. Similarly, we record the (sym-
bolic) values of score expressions. Formally, our symbolic
execution operates on symbolic configurations of the form
ùúì = (M, ùëõ, Œî, Œû) where M is a symbolic term containing
sample variables instead of sample outcomes; ùëõ ‚àà N is a
natural number used to obtain fresh sample variables; Œî is a
list of symbolic constraints of the form V ‚ä≤‚ä≥ ùëü , where V is
a symbolic value, ùëü ‚àà R and ‚ä≤‚ä≥ ‚àà {‚â§, <, >, ‚â•}, to keep track
of the conditions for the current execution path; and Œû is
a set of values that records all symbolic values of score ex-
pressions encountered along the current path. The symbolic
reduction relation (cid:123) includes the following key rules.

(sample, ùëõ, Œî, Œû) (cid:123) (ùõºùëõ+1, ùëõ + 1, Œî, Œû)
(if (V, N, P)), ùëõ, Œî, Œû) (cid:123) (N, ùëõ, Œî ‚à™ {V ‚â§ 0}, Œû)
(if (V, N, P)), ùëõ, Œî, Œû) (cid:123) (P, ùëõ, Œî ‚à™ {V > 0}, Œû)
(score(V), ùëõ, Œî, Œû) (cid:123) (V, ùëõ, Œî ‚à™ {V ‚â• 0}, Œû ‚à™ {V})
That is, we replace sample outcomes with fresh sample vari-
ables (first rule), explore both paths of a conditional (second
and third rule), and record all score values (fourth rule).

Example 6.1. Consider the symbolic execution of Exam-
ple 1.1 where the first step moves the pedestrian towards
their home (taking the right branch of ‚äï0.5) and the second
step moves away from their home (the left branch of ‚äï0.5).
We reach a configuration (M, 5, Œî, Œû) where M is
score(cid:0) pdf Normal(1.1,0.1)
Here ùõº1 is the initial sample for start; ùõº2, ùõº4 the two samples
of step; and ùõº3, ùõº5 the samples involved in the ‚äï0.5 operator.
The fixpoint ùúáùúë
ùë• .N is already given in Example 5.2, Œû = ‚àÖ
and Œî = {3ùõº1 > 0, ùõº3 > 1

ùë• .N )(3ùõº1 ‚àíùõº2 +ùõº4)(cid:1)(cid:1); 3ùõº1.

2, 3ùõº1 ‚àíùõº2 > 0, ùõº5 ‚â§ 1

(cid:0)ùõº2 +ùõº4 + (ùúáùúë

2 }.

6 Symbolic Execution and GuBPI
In this section, we describe the overall structure of our tool
GuBPI (gubpi-tool.github.io), which builds upon symbolic
execution. We also outline how the interval-based semantics
can be accelerated for programs containing linear subexpres-
sions.

For a symbolic value V using sample variables ùõº = ùõº1,
. . . , ùõºùëõ and ùíî ‚àà [0, 1]ùëõ, we write V [ùíî/ùõº] ‚àà R for the substi-
tution of concrete values in ùíî for the sample variables. Call
a symbolic configuration of the form Œ® = (V, ùëõ, Œî, Œû) (i.e. a
configuration that has reached a symbolic value V) a sym-
bolic path. We write symPaths(ùúì ) for the (countable) set of

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Algorithm 1 Symbolic Analysis in GuBPI.

1: Input: Program ‚ä¢ ùëÉ : R, depth limit ùê∑ ‚àà N, and ùêº ‚àà I
2: ùúìinit := (ùëÉ, 0, ‚àÖ, ‚àÖ); ùëÜ := {(ùúìinit, 0)};ùëá := ‚àÖ
3: while ‚àÉ(ùúì, depth) ‚àà ùëÜ do
4:

if ùúì has terminated then

ùëá := ùëá ‚à™ {ùúì }; ùëÜ := ùëÜ \ {(ùúì, depth)}

else if ùúì contains no fixpoints or depth ‚â§ ùê∑ then

ùëÜ := ùëÜ \ {(ùúì, depth)}
for ùúì ‚Ä≤ with ùúì (cid:123) ùúì ‚Ä≤ do

ùëÜ := ùëÜ ‚à™ {(ùúì ‚Ä≤, depth + 1)}

5:
6:
7:
8:
9:
10:
11:
12: return (cid:2) (cid:205)Œ®‚ààùëá

else

ùëÜ := (ùëÜ \ {(ùúì, depth)}) ‚à™ {(approxFix (ùúì ), depth)}

lb (ùêº ), (cid:205)Œ®‚ààùëá

Œ®

(cid:74)

(cid:75)

ub (ùêº )(cid:3)

Œ®

(cid:74)

(cid:75)

symbolic paths reached when evaluating from configuration
ùúì . Given a symbolic path Œ® = (V, ùëõ, Œî, Œû) and a set ùëà ‚àà Œ£R,
we define the denotation along Œ®, written

(ùëà ), as

‚à´

[0,1]ùëõ

(cid:2)V [ùíî/ùõº] ‚àà ùëà (cid:3) (cid:214)
C‚ä≤‚ä≥ùëü ‚ààŒî

Œ®
(cid:74)
(cid:2)C [ùíî/ùõº] ‚ä≤‚ä≥ ùëü (cid:3) (cid:214)
W ‚ààŒû

(cid:75)
W [ùíî/ùõº] dùíî,

i.e. the integral of the product of the score weights Œû over the
traces of length ùëõ where the result value is in ùëà and all the
constraints Œî are satisfied. We can recover the denotation of
a program ùëÉ (as defined in Section 2) from all its symbolic
paths starting from the configuration (ùëÉ, 0, ‚àÖ, ‚àÖ).

Theorem 6.1. Let ‚ä¢ ùëÉ : R be a program and ùëà ‚àà Œ£R. Then

ùëÉ
(cid:74)

(cid:75)

(ùëà ) = (cid:205)Œ®‚ààsymPaths (ùëÉ,0,‚àÖ,‚àÖ)

Œ®

(ùëà ).

(cid:74)

(cid:75)

Analogously to interval SPCF (Section 3), we define sym-
bolic interval terms as symbolic terms that may contain
intervals (and similarly for symbolic interval values, sym-
bolic interval configurations, and symbolic interval paths).

6.2 GuBPI
With symbolic execution at hand, we can outline the struc-
ture of our analysis tool GuBPI (sketched in Algorithm 1).
GuBPI‚Äôs analysis begins with symbolic execution of the in-
put term to accumulate a set of symbolic interval paths ùëá . If
a symbolic configuration ùúì has exceeded the user-defined
depth limit ùê∑ and still contains a fixpoint, we overapproxi-
mate all paths that extend ùúì to ensure a finite set ùëá . We ac-
complish this by using the interval type system (Section 5) to
overapproximate all fixpoint subexpressions, thereby obtain-
ing strongly normalizing terms (in line 11). Formally, given
a symbolic configuration ùúì = (M, ùëõ, Œî, Œû) we derive a typ-
ing judgment for the term M in the system from Section 5.
Each first-order fixpoint subterm is thus given a (weight-
(cid:27). We replace this fixpoint
(cid:26) [ùëê, ùëë]
less) type of the form [ùëé, ùëè] ‚Üí
[ùëí, ùëì ]
with ùúÜ_.(cid:0)score([ùëí, ùëì ]) ; [ùëê, ùëë](cid:1). We denote this operation on
configurations by approxFix (ùúì ) (it extends to higher-order
fixpoints as expected). Note that approxFix (ùúì ) is a symbolic
interval configuration.

(cid:26)[0, ‚àû]
[1, 1]

(cid:27). The function approxFix replaces ùúáùúë

Example 6.2. Consider the symbolic configuration given in
Example 6.1. As in Example 5.2 we infer the type of ùúáùúë
ùë• .N to
be [‚àí1, 4] ‚Üí
ùë• .N with
ùúÜ_.score([1, 1]); [0, ‚àû]. By evaluating the resulting symbolic
interval configuration further, we obtain the symbolic in-
terval path (3ùõº1, 5, Œî, Œû) where Œî is as in Example 6.1 and
Œû = {pdf Normal(1.1,0.1) (ùõº2 +ùõº4 + [0, ‚àû])}. Note that, in general,
the further evaluation of approxFix (ùúì ) can result in multiple
symbolic interval paths.

Afterwards, we‚Äôre left with a finite set ùëá of symbolic in-
terval paths. Due to the presence of intervals, we cannot
define a denotation of such paths directly and instead define
lower and upper bounds. For a symbolic interval value V
that contains no sample variables, we define ‚åúV‚åù ‚äÜ R as
the set of all values that the term can evaluate to by replac-
ing every interval [ùëé, ùëè] with some value ùëü ‚àà [ùëé, ùëè]. Given
a symbolic interval path Œ® = (V, ùëõ, Œî, Œû) and ùëà ‚àà Œ£R we
define
lb (ùëà ) by considering only those concrete traces
that fulfill the constraints in Œ® for all concrete values in the
intervals and take the infimum over all scoring expressions:
‚à´

Œ®

(cid:74)

(cid:75)

(cid:2)‚åúV [ùíî/ùõº]‚åù ‚äÜ ùëà (cid:3)(cid:214)
C‚ä≤‚ä≥ùëü ‚ààŒî

(cid:2)‚àÄùë° ‚àà ‚åúC [ùíî/ùõº]‚åù.ùë° ‚ä≤‚ä≥ ùëü (cid:3) (cid:214)
W ‚ààŒû

inf ‚åúW [ùíî/ùõº]‚åù dùíî.

Œ®

Similarly, we define
‚à´

(cid:74)
(cid:2)‚åúV [ùíî/ùõº]‚åù ‚à© ùëà ‚â† ‚àÖ(cid:3)(cid:214)
C‚ä≤‚ä≥ùëü ‚ààŒî

ub (ùëà ) as
(cid:75)
(cid:2)‚àÉùë° ‚àà ‚åúC [ùíî/ùõº]‚åù.ùë° ‚ä≤‚ä≥ ùëü (cid:3) (cid:214)
W ‚ààŒû
Œ®

Œ®

We note that, if Œ® contains no intervals,
is defined and we
(cid:75)
have
. We can now state the following
ub =
theorem that formalises the observation that approxFix (ùúì )
soundly approximates all symbolic paths that result from ùúì .

lb =

Œ®

Œ®

(cid:74)

(cid:74)

(cid:75)

(cid:74)

(cid:74)

(cid:75)

(cid:75)

sup‚åúW [ùíî/ùõº]‚åù dùíî.

Theorem 6.2. Let ùúì be a symbolic (interval-free) configura-
tion and ùëà ‚àà Œ£R. Define ùê¥ = symPaths(ùúì ) as the (possibly
infinite) set of all symbolic paths reached when evaluating ùúì
and ùêµ = symPaths(approxFix (ùúì )) as the (finite) set of sym-
bolic interval paths reached when evaluating approxFix (ùúì ).
Then

Œ®

(cid:205)Œ®‚ààùêµ
(cid:75)
The correctness of Algorithm 1 is then a direct conse-

lb (ùëà ) ‚â§ (cid:205)Œ®‚ààùê¥

(ùëà ) ‚â§ (cid:205)Œ®‚ààùêµ

ub (ùëà ).

Œ®

Œ®

(cid:74)

(cid:74)

(cid:75)

(cid:74)

(cid:75)

quence of Theorems 6.1 and 6.2:

Corollary 6.3. Let ùëá be the set of symbolic interval paths
computed when at line 12 of Algorithm 1 and ùëà ‚àà Œ£R. Then

(cid:75)

(cid:74)

(cid:75)

Œ®

Œ®

(cid:205)Œ®‚ààùëá

lb (ùëà ) ‚â§

(ùëà ) ‚â§ (cid:205)Œ®‚ààùëá

ùëÉ
(cid:74)
What remains is to compute (lower bounds on)

lb (ùêº )
(cid:75)
ub (ùêº ) for a symbolic interval path
and (upper bounds on)
Œ® ‚àà ùëá and ùêº ‚àà I. We first present the standard interval trace
semantics (Section 6.3) and then a more efficient analysis for
the case that Œ® contains only linear functions (Section 6.4).

ub (ùëà ).

Œ®

Œ®

(cid:75)

(cid:74)

(cid:75)

(cid:74)

(cid:74)

6.3 Standard Interval Trace Semantics
For any symbolic interval path Œ®, we can employ the se-
mantics as introduced in Section 3. Instead of applying the

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

analysis to the entire program, we can restrict to the current
path Œ® (intuitively, by adding a score(0) to all other program
paths). The interval traces split the domain of each sample
variable in Œ® into intervals. It is easy to see that for any
compatible and exhaustive set of interval traces T , we have
lowerBdT
Œ® (ùëà )
for any ùëà ‚àà Œ£R (see Theorem 4.1 and 4.2). Applying the
interval-based semantics on the level of symbolic interval
paths maintains the attractive features, namely soundness
and completeness (relative to the current path) of the se-
mantics. Note that the intervals occurring in Œ® seamlessly
integrate with our interval-based semantics.

ub (ùëà ) ‚â§ upperBdT

lb (ùëà ) and

Œ® (ùëà ) ‚â§

Œ®

Œ®

(cid:75)

(cid:74)

(cid:75)

(cid:74)

6.4 Linear Interval Trace Semantics
In case the score values and the guards of all conditionals
are linear, we can improve and speed up the interval-based
semantics.

Assume all symbolic interval values appearing in Œ® are
interval linear functions of ùõº (i.e. functions ùõº ‚Ü¶‚Üí w‚ä∫ùõº +I [ùëé, ùëè]
for some w ‚àà Rùëõ and [ùëé, ùëè] ‚àà I). We assume, for now, that
each symbolic value W ‚àà Œû denotes an interval-free linear
function (i.e. a function ùõº ‚Ü¶‚Üí w‚ä∫ùõº + ùëü ). Fix some interval
ùêº ‚àà I. We first note that both
ub (ùêº ) are the
(cid:75)
integral of a polynomial over a convex polytope: define

lb (ùêº ) and

Œ®

Œ®

(cid:75)

(cid:74)

(cid:74)

ùîìlb := (cid:8)ùíî ‚àà Rùëõ | ‚åúV [ùíî/ùõº]‚åù ‚äÜ ùêº ‚àß

(cid:219)

‚àÄùë° ‚àà ‚åúC [ùíî/ùõº]‚åù.ùë° ‚ä≤‚ä≥ ùëü (cid:9)

Œ®

C‚ä≤‚ä≥ùëü ‚ààŒî
which is a polytope.10 Then
lb (ùêº ) is the integral of the
polynomial ùõº ‚Ü¶‚Üí (cid:206)
(cid:75)
W ‚ààŒû W over ùîìlb. The definition of ùîìub
(as the region of integration for
ub (ùêº )) is similar. Such
integrals can be computed exactly [2], e.g. with the LattE
tool [20]. Unfortunately, our experiments showed that this
does not scale to interesting probabilistic programs.

Œ®

(cid:75)

(cid:74)

(cid:74)

Instead, we derive guaranteed bounds on the denotation
by means of iterated volume computations. This has the
additional benefit that we can handle non-uniform sam-
ples and non-liner expressions in Œû. We follow an approach
similar to that of the interval-based semantics in Section 4
but do not split/bound individual sample variables and in-
stead directly bound linear functions over the sample vari-
ables. Let Œû = {W1, . . . , Wùëò }. We define a box (by abuse of
language) as an element ùíï = ‚ü®[ùëé1, ùëè1], . . . , [ùëéùëò, ùëèùëò ]‚ü©, where
[ùëéùëñ, ùëèùëñ ] gives a bound on Wùëñ .11 We define lb(ùíï) := (cid:206)ùëò
ùëñ=1 ùëéùëñ
and ub(ùíï) := (cid:206)ùëò
ùëñ=1 ùëèùëñ . The box ùíï naturally defines a subset
= (cid:8)ùíî ‚àà ùîìlb | (cid:211)ùëò
ùëñ=1 Wùëñ [ùíî/ùõº] ‚àà [ùëéùëñ, ùëèùëñ ](cid:9).
of ùîìlb given by ùîìùíï
lb
Then ùîìùíï
) for its
is again a polytope and we write vol(ùîìùíï
lb
lb
) is analogous. As
volume. The definition of ùîìùíï
ub
for interval traces, we call two boxes ùíï 1, ùíï 2 compatible if the
intervals are almost disjoint in at least one position. A set

and vol(ùîìùíï
ub

10For example, if C denotes the function ùõº ‚Ü¶‚Üí w‚ä∫ùõº+[ùëé, ùëè ] we can transform
a constraint ‚àÄùë° ‚àà ‚åú C [ùíî/ùõº ]‚åù.ùë° ‚â§ ùëü into the linear constraint w‚ä∫ùõº + ùëè ‚â§ ùëü .
11Note the similarity to the interval trace semantics. While the ùëñth position
in an interval trace bounds the value of the ùëñth sample variable, the ùëñth
entry of a box bounds the ùëñth score value.

of boxes ùêµ is compatible if its elements are pairwise compat-
ible and exhaustive if (cid:208)
= ùîìub
(cf. Section 3.3).

= ùîìlb and (cid:208)

ùíï ‚ààùêµ ùîìùíï
ub

ùíï ‚ààùêµ ùîìùíï
lb

lb

(cid:74)

(cid:75)

(cid:74)

ub

Œ®

Œ®

(cid:1) ‚â§

lb (ùêº ) and

ùíï ‚ààùêµ lb(ùíï) ¬∑ vol (cid:0)ùîìùíï
(cid:1).

Proposition 6.4. Let ùêµ be a compatible and exhaustive set of
boxes. Then (cid:205)
ub (ùêº ) ‚â§
(cid:75)
(cid:205)

ùíï ‚ààùêµ ub(ùíï) ¬∑ vol (cid:0)ùîìùíï
As in the standard interval semantics, a finer partition into
boxes yields more precise bounds. While the volume com-
putation involved in Proposition 6.4 is expensive [22], the
number of splits on the linear functions is much smaller than
that needed in the standard interval-based semantics. Our
experiments empirically demonstrate that the direct splitting
of linear functions (if applicable) is usually superior to the
standard splitting. In GuBPI we compute a set of exhaustive
boxes by first computing a lower and upper bound on each
Wùëñ ‚àà Œû over ùîìlb (or ùîìub) by solving a linear program (LP)
and splitting the resulting range in evenly sized chunks.

Beyond uniform samples and linear scores. We can ex-
tend our linear optimization to non-uniform samples and
arbitrary symbolic values in Œû. We accomplish the former
by combining the optimised semantics (where we bound lin-
ear expressions) with the standard interval-trace semantics
(where we bound individual sample variables). For the latter,
we can identify linear sub-expressions of the expressions in
Œû, use boxes to bound each linear sub-expression, and use
interval arithmetic to infer bounds on the entire expression
from bounds on its linear sub-expressions. More details can
be found in Appendix E.1.

Example 6.3. Consider the path Œ® = (3ùõº1, 5, Œî, Œû) derived
in Example 6.2. We use 1-dimensional boxes to bound ùõº2 +
ùõº4 (the single linear sub-expression of the symbolic values
in Œû). To obtain a lower bound on
lb (ùêº ), we sum over
(cid:1)
all boxes ùíï = ‚ü®[ùëé1, ùëè1]‚ü© and take the product of vol (cid:0)ùîìùíï
lb
with the lower interval bound of pdf Normal(1.1,0.1) ([ùëé1, ùëè1] +
[0, ‚àû]) (evaluated in interval arithmetic). Analogously, for
(cid:1) with the
the upper bound we take the product of vol (cid:0)ùîìùíï
ub
upper interval bound of pdf Normal(1.1,0.1) ([ùëé1, ùëè1] + [0, ‚àû]).

Œ®

(cid:75)

(cid:74)

7 Practical Evaluation
We have implemented our semantics in the prototype GuBPI
(gubpi-tool.github.io), written in F#. In cases where we apply
the linear optimisation of our semantics, we use Vinci [8] to
discharge volume computations of convex polytopes. We set
out to answer the following questions:

1. How does GuBPI perform on instances that could al-

ready be solved (e.g. by PSI [26])?

2. Is GuBPI able to infer useful bounds on recursive pro-
grams that could not be handled rigorously before?

7.1 Probability Estimation
We collected a suite of 18 benchmarks from [56]. Each bench-
mark consists of a program ùëÉ and a query ùúô over the variables

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Table 1. Evaluation on selected benchmarks from [56]. We
give the times (in seconds) and bounds computed by [56]
and GuBPI. Details on the exact queries (the Q column) can
be found in Table 4 in the appendix.

Tool from [56]

GuBPI

Program

tug-of-war

tug-of-war

beauquier-3

ex-book-s

ex-book-s

ex-cart

ex-cart

Q

Q1

Q2

Q1

ùíï

1.29

1.09

1.15

Q1
8.48
Q2‚òÖ 10.3
2.41
Q1

Q2

2.40

Q3

ex-cart
0.15
ex-ckd-epi-s Q1‚òÖ 0.15
ex-ckd-epi-s Q2‚òÖ 0.08
1.31
ex-fig6

Q1

ex-fig6

ex-fig6

ex-fig6

ex-fig7

example4

example5

herman-3

Q2

Q3

Q4

Q1

Q1

Q1

Q1

1.80

1.51

3.96

0.04

0.02

0.06

0.47

Result

[0.6126, 0.6227]
[0.5973, 0.6266]
[0.5000, 0.5261]
[0.6633, 0.7234]
[0.3365, 0.3848]
[0.8980, 1.1573]
[0.8897, 1.1573]
[0.0000, 0.1150]
[0.5515, 0.5632]
[0.3019, 0.3149]
[0.1619, 0.7956]
[0.2916, 1.0571]
[0.4314, 2.0155]
[0.4400, 3.0956]
[0.9921, 1.0000]
[0.1910, 0.1966]
[0.4478, 0.4708]
[0.3750, 0.4091]

ùíï

0.72

0.79

22.5

6.52

8.01

67.3

68.5

67.4

0.86

0.84

21.2

21.4

24.7

27.4

0.18

0.31

0.27

124

Result

[0.6134, 0.6135]
[0.6134, 0.6135]
[0.4999, 0.5001]
[0.7417, 0.7418]
[0.4137, 0.4138]
[0.9999, 1.0001]
[0.9999, 1.0001]
[0.0000, 0.0001]
[0.0003, 0.0004]
[0.0003, 0.0004]
[0.1899, 0.1903]
[0.3705, 0.3720]
[0.7438, 0.7668]
[0.8682, 0.9666]
[0.9980, 0.9981]
[0.1918, 0.1919]
[0.4540, 0.4541]
[0.3749, 0.3751]

Table 2. Probabilistic programs with discrete domains from
PSI [26]. The times for PSI and GuBPI are given in seconds.

Instance

ùíï PSI
burglarAlarm 0.06
0.04
twoCoins
0.06
grass
0.14
noisyOr
0.04
bertrand
0.04
coinPattern

ùíï GuBPI
0.21
0.21
0.37
0.72
0.22
0.19

Instance

ùíï PSI
0.04
coins
0.04
ev-model1
ev-model2
0.04
murderMystery 0.04
0.13
coinBiasSmall
0.08
gossip

ùíï GuBPI
0.18
0.21
0.20
0.19
1.92
0.24

(a) coinBias example from [26].
The program samples a beta
prior on the bias of a coin and
observes repeated coin flips (26
seconds).

(b) max example from [26]. The
program compute the maximum
of two i.i.d. normal samples (31
seconds).

of ùëÉ. We bound the probability of the event described by ùúô
using the tool from [56] and GuBPI (Table 1). While our
tool is generally slower than the one in [56], the comple-
tion times are still reasonable. Moreover, in many cases, the
bounds returned by GuBPI are tighter than those of [56]. In
addition, for benchmarks marked with a ‚òÖ, the two pairs
of bounds contradict each other.12 We should also remark
that GuBPI cannot handle all benchmarks proposed in [56]
because the heavy use of conditionals causes our precise
symbolic analysis to suffer from the well-documented path
explosion problem [6, 9, 30]. Perhaps unsurprisingly, [56]
can handle such examples much better, as one of their core
contributions is a stochastic method to reduce the number
of paths considered (see Section 8). Also note that [56] is
restricted to uniform samples, linear guards and score-free
programs, whereas we tackle a much more general problem.

7.2 Exact Inference
To evaluate our tool on instances that can be solved exactly,
we compared it with PSI [26, 27], a symbolic solver which
can, in certain cases, compute a closed-form solution of the
posterior. We note that whenever exact inference is possi-
ble, exact solutions will always be superior to mere bounds
and, due to the overhead of our semantics, will often be

12A stochastic simulation using 106 samples in Anglican [61] yielded results
that fall within GuBPI‚Äôs bounds but violate those computed by [56].

(c) Binary Gaussian Mixture
Model from [65] (39 seconds).
MCMC methods usually find
only one mode.

(d) Neal‚Äôs funnel from [34, 48]
(2.8 seconds). HMC misses some
probability mass around 0.

Figure 5. Guaranteed Bounds computed by GuBPI for a
selection of non-recursive models from [26, 27, 48, 65].

found faster. Because of the different output formats (i.e. ex-
act results vs. bounds), a direct comparison between exact
methods and GuBPI is challenging. As a consistency check,
we collected benchmarks from the PSI repository where the
output domain is finite and GuBPI can therefore compute
exact results (tight bounds). They agree with PSI in all cases,
which includes 8 of the 21 benchmarks from [26]. We report
the computation times in Table 2.

We then considered examples where GuBPI computes
non-tight bounds. For space reasons, we can only include a
selection of examples in this paper. The bounds computed by
GuBPI and a short description of each example are shown in
Fig. 5. We can see that, despite the relatively loose bounds,
they are still useful and provide the user with a rough‚Äî
and most importantly, guaranteed to be correct‚Äîidea of the
denotation.

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

(a) cav-example-7. Program taken from
the PSI repository. PSI bounds the depth
resulting in a spike at 10, whereas GuBPI
can compute bounds on the denotation of
the unbounded program (112 seconds).

(b) cav-example-5. Program taken from
the PSI repository. PSI cannot handle this
program due to the unbounded loops (192
seconds).

(c) add_uniform_with_counter_large.
Program taken from the PSI repository.
GuBPI can handle the unbounded loop,
whereas PSI unrolls to a fixed depth (21
seconds).

(d) random-box-walk. The program mod-
els the cumulative distance traveled by a
biased random walk. If a uniformly sam-
pled step ùë† has length less than 1
2 , we move
ùë† to the left, otherwise ùë† to the right. The
walk stops when it crosses a threshold (167
seconds).

(e) growing-walk. The program models a
geometric random walk where (with in-
creasing distance) the step size of the walk
is increased. The cumulative distance is
observed from a normal distribution cen-
tered at 3 (67 seconds).

(f) param-estimation-recursive. We
sample a uniform prior ùëù and (in each step)
travel to the left with probability ùëù and to
the right with probability (1 ‚àí ùëù). We ob-
serve the walk to come to a halt at location
1 (observed from a normal) and wish to
find the posterior on ùëù (162 seconds).

Figure 6. Guaranteed bounds computed by GuBPI for a selection of recursive models.

The success of exact solvers such as PSI depends on the
underlying symbolic solver (and the optimisations imple-
mented). Consequently, there are instances where the sym-
bolic solver cannot compute a closed-form (integral-free)
solution. Conversely, while our method is (theoretically)
applicable to a very broad class of programs, there exist
programs where the symbolic solver finds solutions but the
analysis in GuBPI becomes infeasible due to the large number
of interval traces required.

7.3 Recursive Models
We also evaluated our tool on complex models that can-
not be handled by any of the existing methods. For space
reasons, we only give an overview of some examples. Unex-
pectedly, we found recursive models in the PSI repository:
there are examples that are created by unrolling loops to a
fixed depth. This fixed unrolling changes the posterior of
the model. Using our method we can handle those examples
without bounding the loop. Three such examples are shown
in Figs. 6a to 6c. In Fig. 6a, PSI bounds the iterations resulting
in a spike at 10 (the unrolling bound). For Fig. 6b, PSI does not
provide any solution whereas GuBPI provides useful bounds.
For Fig. 6c, PSI bounds the loop to compute results (displayed

in blue) whereas GuBPI computes the green bounds on the
unbounded program. It is obvious that the bounds differ sig-
nificantly, highlighting the impact that unrolling to a fixed
depth can have on the denotation. This again strengthens
the claim that rigorous methods that can handle unbounded
loops/recursion are needed. There also exist unbounded dis-
crete examples where PSI computes results for the bounded
version that differ from the denotation of the unbounded
program. Figs. 6d to 6f depict further recursive examples
(alongside a small description).

Lastly, as a very challenging example, we consider the
pedestrian example (Example 1.1) again. The bounds com-
puted by GuBPI are given in Fig. 7 together with the two
stochastic results from Fig. 1. The bounds are clearly precise
enough to rule out the HMC samples. Since this example
has infinite expected running time, it is very challenging
and GuBPI takes about 1.5h (84 min).13 In fact, guaranteed
bounds are the only method to recognise the wrong samples
with certainty (see the next section for statistical methods).

13While the running time seems high, we note that Pyro HMC took about an
hour to generate 104 samples and produce the (wrong) histogram. Diagnostic
methods like simulation-based calibration took even longer (>30h) and
delivered inconclusive results (see Section 7.4 for details).

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

7.5 Limitations and Future Improvements
The theoretical foundations of our interval-based semantics
ensure that GuBPI is applicable to a very broad class of pro-
grams (cf. Section 4). In practice, as usual for exact methods,
GuBPI does not handle all examples equally well.

Firstly, as we already saw in Section 7.1, the symbolic
execution‚Äîwhich forms the entry point of the analysis‚Äî
suffers from path explosion. On some extreme loop/recursion-
free programs (such as example-ckd-epi from [56]), our tool
cannot compute all (finitely many) symbolic paths in reason-
able time, let alone analyse them in our semantics. Extending
the approach from [56], to sample representative program
paths (in the presence of conditioning), is an interesting fu-
ture direction that we can combine with the rigorous analysis
provided by our interval type system.

Secondly, our interval-based semantics imposes bounds on
each sampled variable and thus scales exponentially with the
dimension of the model; this is amplified in the case where
the optimised semantics (Section 6.4) is not applicable. It
would be interesting to explore whether this can be alleviated
using different trace splitting techniques.

(cid:26)[‚àí‚àû, ‚àû]
[1, 1]

Lastly, the bounds inferred by our interval type system
take the form of a single interval with no information about
the exact distribution on that interval. For example, the most
precise bound derivable for the term ùúáùúë
ùë• .ùë• ‚äï (cid:2)ùúë (ùë• +sample) ‚äï
ùúë (ùë• ‚àísample)(cid:3) is [ùëé, ùëè] ‚Üí
(cid:27) for any ùëé, ùëè. After unrolling to
a fixed depth, the approximation of the paths not terminating
within the fixed depth is therefore imprecise. For future work,
it would be interesting to improve the bounds in our type
system to provide more information about the distribution
by means of rigorous approximations of the denotation of
the fixpoint in question (i.e. a probabilistic summary of the
fixpoint [46, 50, 63]).

8 Related Work

Interval trace semantics and Interval SPCF. Our inter-
val trace semantics to compute bounds on the denotation is
similar to the semantics introduced by Beutner and Ong [4],
who study an interval approximation to obtain lower bounds
on the termination probability. By contrast, we study the
more challenging problem of bounding the program denota-
tion which requires us to track the weight of an execution,
and to prove that the denotation approximates a Lebesgue in-
tegral, which requires novel proof ideas. Moreover, whereas
the termination probability of a program is always upper
bounded by 1, here we derive both lower and upper bounds.

Probability estimation. Sankaranarayanan et al. [56] in-
troduced a static analysis framework to infer bounds on a
class of definable events in (score-free) probabilistic programs.
The idea of their approach is that if we find a finite set T of
symbolic traces with cumulative probability at least 1 ‚àí ùëê,
and a given event ùúô occurs with probability at most ùëè on the

Figure 7. Bounds for the pedestrian example (Example 1.1).

Table 3. Running times of GuBPI and SBC for (Pyro‚Äôs) HMC.
Times are given in seconds (s) and hours (h).

Instance

Binary GMM (1-dimensional) (Fig. 5c)
Binary GMM (2-dimensional)
Pedestrian Example (Fig. 7)

ùíï GuBPI
39s
4h
1.5h

ùíï SBC
1h
1.5h
>300h

7.4 Comparison with Statistical Validation
A general approach to validating inference algorithms for
a generative Bayesian model is simulation-based calibration
(SBC) [12, 60]. SBC draws a sample ùúÉ from the prior distribu-
tion of the parameters, generates data ùë¶ for these parameters,
and runs the inference algorithm to produce posterior sam-
ples ùúÉ1, . . . , ùúÉùêø given ùë¶. If the posterior samples follow the
true posterior distribution, the rank statistic of the prior
sample ùúÉ relative to the posterior samples will be uniformly
distributed. If the empirical distribution of the rank statistic
after many such simulations is non-uniform, this indicates a
problem with the inference. While SBC is very general, it is
computationally expensive because it performs inference in
every simulation. Moreover, as SBC is a stochastic validation
approach, any fixed number of samples may fail to diagnose
inference errors that only occur on a very low probability
region.

We compare the running times of GuBPI and SBC for three
examples where Pyro‚Äôs HMC yields wrong results (Table 3).
Running SBC on the pedestrian example (with a reduced
sample size and using the parameters recommended in [60])
took 32 hours and was still inconclusive because of strong au-
tocorrelation. Reducing the latter via thinning requires more
samples, and would increase the running time to >300 hours.
Similarly, GuBPI diagnoses the problem with the mixture
model in Fig. 5c in significantly less time than SBC. How-
ever, for higher-dimensional versions of this mixture model,
SBC clearly outperforms GuBPI. We give a more detailed
discussion of SBC for these examples in Appendix F.3.

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

traces in T , then ùúô occurs with probability at most ùëè + ùëê on
the entire program. In the presence of conditioning, the prob-
lem becomes vastly more difficult, as the aggregate weight
on the unexplored paths can be unbounded, giving ‚àû as the
only derivable upper bound (and therefore also ‚àû as the best
upper bound on the normalising constant). In order to infer
guaranteed bounds, it is necessary to analyse all paths in
the program, which we accomplish via static analysis and
in particular our interval type system. The approach from
[56] was extended by Albarghouthi et al. [1] to compute the
probability of events defined by arbitrary SMT constraints
but is restricted to score-free and non-recursive programs.
Our interval-based approach, which may be seen as a variant
of theirs, is founded on a complete semantics (Theorem 4.3),
can handle recursive program with (soft) scoring, and is
applicable to a broad class of primitive functions.

Note that we consider programs with soft conditioning
in which scoring cannot be reduced to volume computation
directly.14 Intuitively, soft conditioning performs a (global)
re-weighting of the set of traces, which cannot be captured by
(local) volume computations. In our interval trace semantics,
we instead track an approximation of the weight along each
interval trace.

Exact inference. There are numerous approaches to infer-
ring the exact denotation of a probabilistic program. Holtzen
et al. [38] introduced an inference method to efficiently com-
pute the denotation of programs with discrete distributions.
By exploiting program structure to factorise inference, their
system Dice can perform exact inference on programs with
hundreds of thousands of random variables. Gehr et al. [26]
introduced PSI, an exact inference system that uses sym-
bolic manipulation and integration. A later extension, ùúÜPSI
[27], adds support for higher-order functions and nested
inference. The PPL Hakaru [47] supports a variety of infer-
ence algorithms on programs with both discrete and con-
tinuous distributions. Using program transformation and
partial evaluation, Hakaru can perform exact inference via
symbolic disintegration [57] on a limited class of programs.
Saad et al. [55] introduced SPPL, a system that can compute
exact answers to a range of probabilistic inference queries,
by translating a restricted class of programs to sum-product
expressions, which are highly effective representations for
inference.

While exact results are obviously desirable, this kind of in-
ference only works for a restricted family of programs: none
of the above exact inference systems allow (unbounded) re-
cursion. Unlike our tool, they are therefore unable to handle,
for instance, the challenging Example 1.1 or the programs in
Fig. 6.

14For programs including only hard-conditioning (i.e. scoring is only possi-
ble with 0 or 1), the posterior probability of an event ùúë can be computed by
dividing the probability of all traces with weight 1 on which ùúë holds by the
probability of all traces with weight 1.

Abstract interpretation. There are various approaches
to probabilistic abstract interpretation, so we can only dis-
cuss a selection. Monniaux [44, 45] developed an abstract
domain for (score-free) probabilistic programs given by a
weighted sum of abstract regions. Smith [58] considered
truncated normal distributions as an abstract domain and de-
veloped analyses restricted to score-free programs with only
linear expressions. Extending both approaches to support
soft conditioning is non-trivial as it requires the computation
of integrals on the abstract regions. In our interval-based
semantics, we abstract the concrete traces (by means of inter-
val traces) and not the denotation. This allows us to derive
bounds on the weight along the abstracted paths.

Huang et al. [39] discretise the domain of continuous sam-
ples into interval cubes and derive posterior approximations
on each cube. The resulting approximation converges to the
true posterior (similarly to approximate/stochastic methods)
but does not provide exact/guaranteed bounds and is not
applicable to recursive programs.

Refinement types. Our interval type system (Section 5)
may be viewed as a type system that refines not just the value
of an expression but also its weight [24]. To our knowledge,
no existing type refinement system can bound the weight
of program executions. Moreover, the seamless integration
with our interval trace semantics by design allows for much
cheaper type inference, without resorting to an SMT or Horn
constraint solver. This is a crucial advantage since a typical
GuBPI execution queries the analysis numerous times.

Stochastic methods. A general approach to validating
inference algorithms for a generative Bayesian model is
simulation-based calibration (SBC) [12, 60], discussed in Sec-
tion 7.4. Grosse et al. [36] introduced a method to estimate
the log marginal likelihood of a model by constructing sto-
chastic lower/upper bounds. They show that the true value
can be sandwiched between these two stochastic bounds
with high probability. In closely related work [17, 35], this
was applied to measure the accuracy of approximate proba-
bilistic inference algorithms on a specified dataset. By con-
trast, our bounds are non-stochastic and our method is ap-
plicable to arbitrary programs of a universal PPL.

9 Conclusion
We have studied the problem of inferring guaranteed bounds
on the posterior of programs written in a universal PPL. Our
work is based on the interval trace semantics, and our weight-
aware interval type system gives rise to a tool that can in-
fer useful bounds on the posterior of interesting recursive
programs. This is a capability beyond the reach of existing
methods, such as exact inference. As a method of Bayesian
inference for statistical probabilistic programs, we can view
our framework as occupying a useful middle ground between
approximate stochastic inference and exact inference.

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

References
[1] Aws Albarghouthi, Loris D‚ÄôAntoni, Samuel Drews, and Aditya V. Nori.
2017. FairSquare: probabilistic verification of program fairness. Pro-
ceedings of the ACM on Programming Languages 1, OOPSLA (2017).
https://doi.org/10.1145/3133904

[2] Velleda Baldoni, Nicole Berline, Jesus De Loera, Matthias K√∂ppe, and
Mich√®le Vergne. 2011. How to integrate a polynomial over a simplex.
Math. Comp. 80, 273 (2011). https://doi.org/10.1090/S0025-5718-2010-
02378-6

[3] Atilim G√ºnes Baydin, Lei Shao, Wahid Bhimji, Lukas Alexander Hein-
rich, Lawrence Meadows, Jialin Liu, Andreas Munk, Saeid Naderi-
parizi, Bradley Gram-Hansen, Gilles Louppe, Mingfei Ma, Xiaohui
Zhao, Philip H. S. Torr, Victor W. Lee, Kyle Cranmer, Prabhat, and
Frank Wood. 2019. Etalumis: bringing probabilistic programming to
scientific simulators at scale. In International Conference for High Per-
formance Computing, Networking, Storage and Analysis, SC 2019. ACM.
https://doi.org/10.1145/3295500.3356180

[4] Raven Beutner and Luke Ong. 2021. On probabilistic termination of
functional programs with continuous distributions. In ACM SIGPLAN
International Conference on Programming Language Design and Imple-
mentation, PLDI 2021. ACM. https://doi.org/10.1145/3453483.3454111
[5] Eli Bingham, Jonathan P. Chen, Martin Jankowiak, Fritz Obermeyer,
Neeraj Pradhan, Theofanis Karaletsos, Rohit Singh, Paul A. Szerlip,
Paul Horsfall, and Noah D. Goodman. 2019. Pyro: Deep Universal
Probabilistic Programming. Journal of Machine Learning Research 20
(2019). http://jmlr.org/papers/v20/18-403.html

[6] Peter Boonstoppel, Cristian Cadar, and Dawson R. Engler. 2008. RWset:
Attacking Path Explosion in Constraint-Based Test Generation. In
International Conference on Tools and Algorithms for the Construction
and Analysis of Systems, TACAS 2008. Springer. https://doi.org/10.
1007/978-3-540-78800-3_27

[7] Johannes Borgstr√∂m, Ugo Dal Lago, Andrew D. Gordon, and Marcin
Szymczak. 2016. A lambda-calculus foundation for universal proba-
bilistic programming. In ACM SIGPLAN International Conference on
Functional Programming, ICFP 2016. ACM. https://doi.org/10.1145/
2951913.2951942

[8] Benno B√ºeler, Andreas Enge, and Komei Fukuda. 2000. Exact Vol-
ume Computation for Polytopes: A Practical Study.
In Polytopes‚Äî
combinatorics and computation. DMV Sem., Vol. 29. Birkh√§user, Basel.
https://doi.org/10.1007/978-3-0348-8438-9_6

[9] Cristian Cadar, Vijay Ganesh, Peter M. Pawlowski, David L. Dill, and
Dawson R. Engler. 2008. EXE: Automatically Generating Inputs of
Death. ACM Transactions on Information and System Security 12, 2
(2008). https://doi.org/10.1145/1455518.1455522

[10] Arun Tejasvi Chaganty, Aditya V. Nori, and Sriram K. Rajamani. 2013.
Efficiently Sampling Probabilistic Programs via Program Analysis. In
International Conference on Artificial Intelligence and Statistics, AISTATS
2013 (JMLR, Vol. 31). http://proceedings.mlr.press/v31/chaganty13a.
html

[11] Adrien Champion, Tomoya Chiba, Naoki Kobayashi, and Ryosuke
Sato. 2020. ICE-Based Refinement Type Discovery for Higher-Order
Functional Programs. Journal of Automated Reasoning 64, 7 (2020).
https://doi.org/10.1007/s10817-020-09571-y

[12] Samantha R Cook, Andrew Gelman, and Donald B Rubin. 2006. Val-
idation of software for Bayesian models using posterior quantiles.
Journal of Computational and Graphical Statistics 15, 3 (2006). https:
//doi.org/10.1198/106186006X136976

[13] Patrick Cousot and Radhia Cousot. 1976. Static determination of
dynamic properties of programs. In International Symposium on Pro-
gramming. Dunod.

[14] Patrick Cousot and Radhia Cousot. 1977. Abstract Interpretation: A
Unified Lattice Model for Static Analysis of Programs by Construction
or Approximation of Fixpoints. In ACM Symposium on Principles of
Programming Languages, POPL 1977. ACM. https://doi.org/10.1145/
512950.512973

[15] Patrick Cousot and Radhia Cousot. 2002. Modular Static Program
Analysis. In International Conference on Compiler Construction, CC 2002
(LNCS, Vol. 2304). Springer. https://doi.org/10.1007/3-540-45937-5_13
[16] Ryan Culpepper and Andrew Cobb. 2017. Contextual Equivalence
for Probabilistic Programs with Continuous Random Variables and
Scoring. In European Symposium on Programming, ESOP 2017 (LNCS,
Vol. 10201). Springer. https://doi.org/10.1007/978-3-662-54434-1_14
[17] Marco F. Cusumano-Towner and Vikash K. Mansinghka. 2017. AIDE:
An algorithm for measuring the accuracy of probabilistic inference
algorithms. In Annual Conference on Neural Information Processing
Systems, NIPS 2017. https://proceedings.neurips.cc/paper/2017/hash/
acab0116c354964a558e65bdd07ff047-Abstract.html

[18] Marco F. Cusumano-Towner, Feras A. Saad, Alexander K. Lew, and
Vikash K. Mansinghka. 2019. Gen: a general-purpose probabilistic
programming system with programmable inference. In ACM SIGPLAN
International Conference on Programming Language Design and Imple-
mentation, PLDI 2019. ACM. https://doi.org/10.1145/3314221.3314642
[19] Hend Dawood. 2011. Theories of Interval Arithmetic: Mathematical
Foundations and Applications. LAP Lambert Academic Publishing.
[20] Jes√∫s A De Loera, Brandon Dutra, Matthias Koeppe, Stanislav Moreinis,
Gregory Pinto, and Jianqiu Wu. 2013. Software for exact integration
of polynomials over polyhedra. Computational Geometry 46, 3 (2013).
https://doi.org/10.1016/j.comgeo.2012.09.001

[21] Simon Duane, Anthony D Kennedy, Brian J Pendleton, and Duncan
Roweth. 1987. Hybrid Monte Carlo. Physics letters B 195, 2 (1987).
https://doi.org/10.1016/0370-2693(87)91197-X

[22] Martin E. Dyer and Alan M. Frieze. 1988. On the Complexity of
Computing the Volume of a Polyhedron. SIAM J. Comput. 17, 5 (1988).
https://doi.org/10.1137/0217060

[23] Christian Fecht and Helmut Seidl. 1999. A Faster Solver for General
Systems of Equations. Science of Computer Programming 35, 2 (1999).
https://doi.org/10.1016/S0167-6423(99)00009-X

[24] Timothy S. Freeman and Frank Pfenning. 1991. Refinement Types
for ML. In ACM SIGPLAN International Conference on Programming
Language Design and Implementation, PLDI 1991. ACM. https://doi.
org/10.1145/113445.113468

[25] Hong Ge, Kai Xu, and Zoubin Ghahramani. 2018. Turing: A Lan-
guage for Flexible Probabilistic Inference. In International Conference
on Artificial Intelligence and Statistics, AISTATS 2018 (PMLR, Vol. 84).
https://proceedings.mlr.press/v84/ge18b.html

[26] Timon Gehr, Sasa Misailovic, and Martin T. Vechev. 2016. PSI: Exact
Symbolic Inference for Probabilistic Programs. In International Con-
ference on Computer Aided Verification, CAV 2016 (LNCS, Vol. 9779).
Springer. https://doi.org/10.1007/978-3-319-41528-4_4

[27] Timon Gehr, Samuel Steffen, and Martin T. Vechev. 2020. ùúÜPSI: exact
inference for higher-order probabilistic programs. In ACM SIGPLAN
International Conference on Programming Language Design and Imple-
mentation, PLDI 2020. ACM. https://doi.org/10.1145/3385412.3386006
[28] Jaco Geldenhuys, Matthew B. Dwyer, and Willem Visser. 2012. Proba-
bilistic symbolic execution. In International Symposium on Software
Testing and Analysis, ISSTA 2012. ACM.
https://doi.org/10.1145/
2338965.2336773

[29] Zoubin Ghahramani. 2013. Bayesian non-parametrics and the proba-
bilistic approach to modelling. Philosophical Transactions of the Royal
Society A 371 (2013). https://doi.org/10.1098/rsta.2011.0553

[30] Patrice Godefroid. 2007. Compositional dynamic test generation. In
ACM SIGPLAN Symposium on Principles of Programming Languages,
POPL 2007. ACM. https://doi.org/10.1145/1190216.1190226

[31] Noah D. Goodman, Vikash K. Mansinghka, Daniel M. Roy, Keith
Bonawitz, and Joshua B. Tenenbaum. 2008. Church: a language for gen-
erative models. In Conference on Uncertainty in Artificial Intelligence,
UAI 2008. AUAI Press.

[32] Noah D. Goodman and Andreas Stuhlm√ºller. 2014. The Design and

Implementation of Probabilistic Programming Languages.

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

[33] Andrew D. Gordon, Thomas A. Henzinger, Aditya V. Nori, and Sri-
ram K. Rajamani. 2014. Probabilistic programming. In Future of Soft-
ware Engineering, FOSE 2014. ACM. https://doi.org/10.1145/2593882.
2593900

[34] Maria I. Gorinova, Dave Moore, and Matthew D. Hoffman. 2020. Au-
tomatic Reparameterisation of Probabilistic Programs. In Interna-
tional Conference on Machine Learning, ICML 2020 (PMLR, Vol. 119).
http://proceedings.mlr.press/v119/gorinova20a.html

[35] Roger B. Grosse, Siddharth Ancha, and Daniel M. Roy. 2016. Mea-
suring the reliability of MCMC inference with bidirectional Monte
Carlo. In Annual Conference on Neural Information Processing Sys-
tems, NIPS 2016.
https://proceedings.neurips.cc/paper/2016/hash/
0e9fa1f3e9e66792401a6972d477dcc3-Abstract.html

[36] Roger B. Grosse, Zoubin Ghahramani, and Ryan P. Adams. 2015. Sand-
wiching the marginal likelihood using bidirectional Monte Carlo. CoRR
abs/1511.02543 (2015). https://doi.org/10.48550/arXiv.1511.02543
[37] N. L. Hjort, Chris Homes, Peter Muller, and Stephen G. Walker. 2010.
Bayesian Nonparametrics. Cambridge University Press. https://doi.
org/10.1017/CBO9780511802478

[38] Steven Holtzen, Guy Van den Broeck, and Todd D. Millstein. 2020.
Scaling exact inference for discrete probabilistic programs. Proceedings
of the ACM on Programming Languages 4, OOPSLA (2020). https:
//doi.org/10.1145/3428208

[39] Zixin Huang, Saikat Dutta, and Sasa Misailovic. 2021. AQUA: Auto-
mated Quantized Inference for Probabilistic Programs. In International
Symposium on Automated Technology for Verification and Analysis,
ATVA 2021 (LNCS, Vol. 12971). Springer. https://doi.org/10.1007/978-3-
030-88885-5_16

[40] Andrew Kenyon-Roberts and C.-H. Luke Ong. 2021. Supermartin-
gales, Ranking Functions and Probabilistic Lambda Calculus. In Annual
ACM/IEEE Symposium on Logic in Computer Science, LICS 2021. IEEE.
https://doi.org/10.1109/LICS52264.2021.9470550

[41] Carol Mak, C.-H. Luke Ong, Hugo Paquet, and Dominik Wagner.
2021. Densities of Almost Surely Terminating Probabilistic Pro-
grams are Differentiable Almost Everywhere. In European Sympo-
sium on Programming, ESOP 2021 (LNCS, Vol. 12648). Springer. https:
//doi.org/10.1007/978-3-030-72019-3_16

[42] Carol Mak, Fabian Zaiser, and Luke Ong. 2021. Nonparametric Hamil-
tonian Monte Carlo. In International Conference on Machine Learning,
ICML 2021 (PMLR, Vol. 139). http://proceedings.mlr.press/v139/mak21a.
html

[43] Chris Manning and Hinrich Sch√ºtze. 1999. Foundations of Statistical

Natural Language Processing. MIT Press. Cambridge, MA.

[44] David Monniaux. 2000. Abstract Interpretation of Probabilistic Seman-
tics. In International Symposium on Static Analysis, SAS 2000 (LNCS,
Vol. 1824). Springer. https://doi.org/10.1007/978-3-540-45099-3_17
[45] David Monniaux. 2001. An abstract Monte-Carlo method for the
analysis of probabilistic programs. In ACM SIGPLAN Symposium on
Principles of Programming Languages, POPL 2001. ACM. https://doi.
org/10.1145/360204.360211

[46] Markus M√ºller-Olm and Helmut Seidl. 2004. Precise interprocedu-
ral analysis through linear algebra. In ACM SIGPLAN Symposium
on Principles of Programming Languages, POPL 2004. ACM. https:
//doi.org/10.1145/964001.964029

[47] Praveen Narayanan, Jacques Carette, Wren Romano, Chung-chieh
Shan, and Robert Zinkov. 2016. Probabilistic Inference by Program
Transformation in Hakaru (System Description). In International Sym-
posium on Functional and Logic Programming, FLOPS 2016 (LNCS,
Vol. 9613). Springer. https://doi.org/10.1007/978-3-319-29604-3_5
[48] Radford M Neal. 2003. Slice sampling. The annals of statistics 31, 3

(2003). https://doi.org/10.1214/aos/1056562461

[49] Art B. Owen. 2013. Monte Carlo theory, methods and examples.
[50] Andreas Podelski, Ina Schaefer, and Silke Wagner. 2005. Summaries
for While Programs with Recursion. In European Symposium on Pro-
gramming, ESOP 2005 (LNCS, Vol. 3444). Springer. https://doi.org/10.
1007/978-3-540-31987-0_8

[51] David Pollard. 2002. A User‚Äôs Guide to Measure-Theoretic Prob-
https://doi.org/10.1017/

Cambridge University Press.

ability.
CBO9780511811555

[52] Fredrik Ronquist, Jan Kudlicka, Viktor Senderov, Johannes Borgstr√∂m,
Nicolas Lartillot, Daniel Lund√©n, Lawrence Murray, Thomas B Sch√∂n,
and David Broman. 2021. Universal probabilistic programming offers
a powerful approach to statistical phylogenetics. Communications
biology 4, 1 (2021). https://doi.org/10.1038/s42003-021-01753-7
[53] Vivekananda Roy. 2020. Convergence Diagnostics for Markov Chain
Monte Carlo. Annual Review of Statistics and Its Application 7 (2020).
https://doi.org/10.1146/annurev-statistics-031219-041300

[54] Reuven Y. Rubinstein and Dirk P. Kroese. 2017.

Simulation and
the Monte Carlo Method (3rd ed.). Wiley. https://doi.org/10.1002/
9781118631980

[55] Feras A. Saad, Martin C. Rinard, and Vikash K. Mansinghka. 2021.
SPPL: probabilistic programming with fast exact symbolic inference.
In ACM SIGPLAN International Conference on Programming Language
Design and Implementation, PLDI 2021. ACM. https://doi.org/10.1145/
3453483.3454078

[56] Sriram Sankaranarayanan, Aleksandar Chakarov, and Sumit Gulwani.
2013. Static analysis for probabilistic programs: inferring whole pro-
gram properties from finitely many paths. In ACM SIGPLAN Interna-
tional Conference on Programming Language Design and Implementa-
tion, PLDI 2013. ACM. https://doi.org/10.1145/2491956.2462179
[57] Chung-chieh Shan and Norman Ramsey. 2017. Exact Bayesian in-
ference by symbolic disintegration. In ACM SIGPLAN Symposium
on Principles of Programming Languages, POPL 2017. ACM. https:
//doi.org/10.1145/3009837.3009852

[58] Michael J. A. Smith. 2008. Probabilistic Abstract Interpretation of
Imperative Programs using Truncated Normal Distributions. Electronic
Notes in Theoretical Computer Science 220, 3 (2008). https://doi.org/10.
1016/j.entcs.2008.11.018

[59] Sam Staton. 2017. Commutative Semantics for Probabilistic Program-
ming. In European Symposium on Programming, ESOP 2017 (LNCS,
Vol. 10201). Springer. https://doi.org/10.1007/978-3-662-54434-1_32
[60] Sean Talts, Michael Betancourta, Daniel Simpson, Aki Vehtari, and
Andrew Gelman. 2018. Validating Bayesian Inference Algorithms
with Simulation-Based Calibration. arXiv 1804.06788 (2018). https:
//doi.org/10.48550/arXiv.1804.06788

[61] David Tolpin, Jan-Willem van de Meent, and Frank D. Wood. 2015.
Probabilistic Programming in Anglican. In European Conference on
Machine Learning and Knowledge Discovery in Databases, ECML PKDD
2015 (LNCS, Vol. 9286). Springer. https://doi.org/10.1007/978-3-319-
23461-8_36

[62] Jan-Willem van de Meent, Brooks Paige, Hongseok Yang, and Frank
Wood. 2018. An Introduction to Probabilistic Programming. CoRR
abs/1809.10756 (2018). https://doi.org/10.48550/arXiv.1809.10756
[63] Di Wang, Jan Hoffmann, and Thomas W. Reps. 2018. PMAF: an alge-
braic framework for static analysis of probabilistic programs. In ACM
SIGPLAN International Conference on Programming Language Design
and Implementation, PLDI 2018. ACM. https://doi.org/10.1145/3192366.
3192408

[64] Cheng Zhang, Judith B√ºtepage, Hedvig Kjellstr√∂m, and Stephan Mandt.
2019. Advances in Variational Inference. IEEE Transactions on Pattern
Analysis and Machine Intelligence 41, 8 (2019). https://doi.org/10.1109/
TPAMI.2018.2889774

[65] Yuan Zhou, Bradley J. Gram-Hansen, Tobias Kohn, Tom Rainforth,
Hongseok Yang, and Frank Wood. 2019. LF-PPL: A Low-Level First
Order Probabilistic Programming Language for Non-Differentiable
Models. In International Conference on Artificial Intelligence and Statis-
tics, AISTATS 2019 (PMLR, Vol. 89). http://proceedings.mlr.press/v89/
zhou19b.html

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

A Supplementary Material for Section 3
A.1 Intervals as a lattice
Intervals I form a partially ordered set under interval in-
clusion (‚äë). We will sometimes need the meet ‚äì and join
‚äî operations, corresponding to the greatest lower bound
and the least upper bound of two intervals. Note that the
meet of two intervals does not exist if the two intervals
are disjoint. Concretely, these two operations are given by
[ùëé, ùëè] ‚äì [ùëê, ùëë] := [max(ùëé, ùëê), min(ùëè, ùëë)] (if the two intervals
overlap) and [ùëé, ùëè] ‚äî [ùëê, ùëë] := [min(ùëé, ùëê), max(ùëè, ùëë)].

For some applications (e.g. the interval type system), we
need the interval domain to be a true lattice. To turn I into
a lattice, we add a bottom element ‚ä• (signifying an empty
interval). The definition of the meet ‚äì and join ‚äî is extended
in the natural way. The meet ‚äì is extended by defining ùêº1 ‚äì
‚ä• = ‚ä• ‚äì ùêº2 = ‚ä• and ùêº1 ‚äì ùêº2 = ‚ä• if the two intervals ùêº1, ùêº2 ‚àà I
are disjoint. The join ‚äî satisfies ùêº ‚äî ‚ä• = ‚ä• ‚äî ùêº = ùêº .

A.2 Lifting Functions to Intervals
For constants ùëê ‚àà R (i.e. nullary functions), for common func-
tions like +, ‚àí, √ó, | ¬∑ |, min, max, for monotonically increasing
functions ùëì‚Üó : R ‚Üí R, and for monotonically decreasing
functions ùëì‚Üò : R ‚Üí R, it is easy to describe the interval-
lifted functions +I, ‚àíI, √óI, | ¬∑ |I, minI, maxI, ùëì I
‚Üó

, and ùëì I
‚Üò

:

ùëêI = [ùëê, ùëê]
‚àíI [ùë•1, ùë¶1] = [‚àíùë¶1, ‚àíùë•1]

(cid:40)

|[ùë•1, ùë¶1]|I =

[0, max(|ùë•1|, |ùë¶1|)] if ùë•1 ‚â§ 0 ‚â§ ùë¶1
[min(|ùë•1|, |ùë¶1|), max(|ùë•1|, |ùë¶1|)] else

[ùë•1, ùë¶1] +I [ùë•2, ùë¶2] = [ùë•1 + ùë•2, ùë¶1 + ùë¶2]
[ùë•1, ùë¶1] ‚àíI [ùë•2, ùë¶2] = [ùë•1 ‚àí ùë¶2, ùë¶1 ‚àí ùë•2]
[ùë•1, ùë¶1] √óI [ùë•2, ùë¶2] = [min(ùë•1ùë•2, ùë•1ùë¶2, ùë¶1ùë•2, ùë¶1ùë¶2),

max(ùë•1ùë•2, ùë•1ùë¶2, ùë¶1ùë•2, ùë¶1ùë¶2)]

minI([ùë•1, ùë¶1], [ùë•2, ùë¶2]) = [min(ùë•1, ùë•2), min(ùë¶1, ùë¶2)]
maxI([ùë•1, ùë¶1], [ùë•ùëõ, ùë¶ùëõ]) = [max(ùë•1, ùë•2), max(ùë¶1, ùë¶2)]
ùëì I
‚Üó ([ùë•1, ùë¶1]) = [ùëì‚Üó (ùë•1), ùëì‚Üó (ùë¶1)]
ùëì I
‚Üò ([ùë•1, ùë¶1]) = [ùëì‚Üò (ùë¶1), ùëì‚Üò(ùë•1)]

where we write ùëì (¬±‚àû) for limùë•‚Üí¬±‚àû ùëì (ùë•) ‚àà R‚àû, respec-
tively.

A.3 Properties of Interval Reduction
We can define a refinement relation ùëÄ ‚ä≥ ùëÄ ‚Ä≤ (‚ÄúùëÄ refines ùëÄ ‚Ä≤‚Äù)
between a standard term ùëÄ and an interval term ùëÄ ‚Ä≤, if ùëÄ
is obtained from ùëÄ ‚Ä≤ by replacing every occurrence of [ùëé, ùëè]
with some ùëü ‚àà [ùëé, ùëè].

Lemma 3.1. Let ‚ä¢ ùëÉ : R be a program. For any interval trace
ùíï and concrete trace ùíî ‚ä≥ ùíï, we have wtùëÉ (ùíî) ‚àà wtI
ùëÉ (ùíï) and
valùëÉ (ùíî) ‚àà val

I
ùëÉ (ùíï) (provided valùëÉ (ùíî) is defined).

Proof. If the interval reduction ‚ÜíI gets stuck, wtI
ùëÉ is [0, ‚àû]
I
ùëÉ is [‚àí‚àû, ‚àû], so the claim is certainly true. Otherwise,
and val
I ) reduction step, we can do
for each (ùëÄI, ùíï, ùë§I) ‚ÜíI (ùëÄ ‚Ä≤
a reduction step (ùëÄ, ùíî, ùë§) ‚Üí (ùëÄ ‚Ä≤, ùíî ‚Ä≤, ùë§ ‚Ä≤) where ùëÄ ‚Ä≤ ‚ä≥ ùëÄ ‚Ä≤
I and
I , and ùíî ‚Ä≤ ‚ä≥ ùíï ‚Ä≤ if ùëÄ ‚ä≥ ùëÄI, ùë§ ‚àà ùë§I, and ùíî ‚ä≥ ùíï. Since the
ùë§ ‚Ä≤ ‚àà ùë§ ‚Ä≤
reduction doesn‚Äôt get stuck, we end up with a value ùëü ‚ä≥ [ùëé, ùëè],
I
‚ñ°
ùëÉ (ùíï).
so valùëÉ (ùíî) = ùëü ‚àà [ùëé, ùëè] = val

I , ùíï ‚Ä≤, ùë§ ‚Ä≤

A.4 Additional Possible Reduction Rules
The interval semantics as presented has the unfortunate
property that even a simple program like

if (sample, score(0), score(1))
requires infinitely many interval traces to achieve a finite
upper bound. The reason is that the right branch score(1) is
taken if the sampled value is in the open interval (0, 1]. To ap-
proximate this using closed intervals [ùëé, ùëè] that our analysis
supports, we need infinitely many intervals, e.g. {[2‚àíùëõ‚àí1, 2‚àíùëõ] |
ùëõ ‚àà N}. Adding (half-)open intervals to the semantics would
solve this specific problem, but not more general ones, where
the guard condition is for example

sample ‚àí sample ‚â§ 0.
In that case, we have to approximate the set {(ùë•, ùë¶) ‚àà [0, 1]2 |
ùë• ‚â§ ùë¶}. For the lower bounds, that is not an issue, but for the
upper bounds, we need an infinite number of interval traces
again. We would like to use the interval traces ‚ü®[0, 1
2 ]‚ü©
and ‚ü®[ 1
2, 1], [0, 1]‚ü© to cover this set, but the reduction gets
stuck on them because it is not clear which branch should
be taken.

2 ], [0, 1

To remedy this, we could add the following two rules.

ùëé ‚â§ 0 < ùëè
(if([ùëé, ùëè], ùëÅ , ùëÉ), ùíï, ùë§) ‚ÜíI (ùëÅ , ùíï, ùë§ √óI [0, 1])

ùëé ‚â§ 0 < ùëè
(if ([ùëé, ùëè], ùëÅ , ùëÉ), ùíï, ùë§) ‚ÜíI (ùëÉ, ùíï, ùë§ √óI [0, 1])
They basically express that if the interval bounds are not
precise enough to decide what branch to take, we can take
both, but have to allow the weight to be zero because it‚Äôs not
guaranteed that the taken branch can actually happen. This
change can only improve the upper bounds, not the lower
bounds because the lower bound on each weight is zero if
the additional rules are used. Then the definition of upper
bound can be modified in the following way:

upperBdT

ùëÉ (ùëà ) :=

‚àëÔ∏Å

ùíï ‚ààT

‚àëÔ∏Å

vol(ùíï) ¬∑ ùë§2 ¬∑ (cid:2)[ùëé, ùëè] ‚à© ùëà ‚â† ‚àÖ(cid:3)

(ùëÉ,ùíï, [1,1])‚ÜíI
( [ùëé,ùëè ], ‚ü®‚ü©, [ùë§1,ùë§2 ])

This is the strategy we use for our implementation and
is a natural extension of the existing semantics: it requires
very few changes to the soundness and completeness proofs.
A downside of the previous approach is that the bounds
are not always very tight: for the term if (. . . ) score(50)

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

((ùúÜùë• .M)V, ùëõ, Œî, Œû) (cid:123) (M [V/ùë•], ùëõ, Œî, Œû)

(score(V), ùëõ, Œî, Œû) (cid:123) (V, ùëõ, Œî ‚à™ {V ‚â• 0}, Œû ‚à™ {V})

((ùúáùúë

ùë• . M)V, ùëõ, Œî, Œû) (cid:123) (M [V/ùë•, (ùúáùúë

ùë• . M)/ùúë], ùëõ, Œî, Œû)

(sample, ùëõ, Œî, Œû) (cid:123) (ùõºùëõ+1, ùëõ + 1, Œî, Œû)

(if(V, N, P)), ùëõ, Œî, Œû) (cid:123) (N, ùëõ, Œî ‚à™ {V ‚â§ 0}, Œû)

(if (V, N, P)), ùëõ, Œî, Œû) (cid:123) (P, ùëõ, Œî ‚à™ {V > 0}, Œû)
(R, ùëõ, Œî, Œû) (cid:123) (M, ùëõ‚Ä≤, Œî‚Ä≤, Œû‚Ä≤)
(E [R], ùëõ, Œî, Œû) (cid:123) (E [M], ùëõ‚Ä≤, Œî‚Ä≤, Œû‚Ä≤)

Figure 8. Reduction rules for symbolic execution

else score(100), it returns bounds [0, 150] instead of [50, 100].
To improve this, we could omit the multiplication with [0, 1].
ùëé ‚â§ 0 < ùëè
(if ([ùëé, ùëè], ùëÅ , ùëÉ), ùíï, ùë§) ‚ÜíI (ùëÅ , ùíï, ùë§)
ùëé ‚â§ 0 < ùëè
(if ([ùëé, ùëè], ùëÅ , ùëÉ), ùíï, ùë§) ‚ÜíI (ùëÉ, ùíï, ùë§)
However, this complicates the equations of our bounds. With
this semantics, we have to compute minima and suprema
instead of a simple sum:

lowerBdT

ùëÉ (ùëà ) :=

upperBdT

ùëÉ (ùëà ) :=

‚àëÔ∏Å

ùíï ‚ààT

‚àëÔ∏Å

ùíï ‚ààT

min
(ùëÉ,ùíï, [1,1])‚ÜíI
( [ùëé,ùëè ], ‚ü®‚ü©, [ùë§1,ùë§2 ])

vol(ùíï) ¬∑ ùë§1 ¬∑ (cid:2)[ùëé, ùëè] ‚äÜ ùëà (cid:3)

vol(ùíï) ¬∑ ùë§2 ¬∑ (cid:2)[ùëé, ùëè] ‚à© ùëà ‚â† ‚àÖ(cid:3)

sup
(ùëÉ,ùíï, [1,1])‚ÜíI
( [ùëé,ùëè ], ‚ü®‚ü©, [ùë§1,ùë§2 ])

This is harder to implement because the sums cannot be
computed incrementally, but many temporary results have
to be kept in memory to compute the minima and suprema.
Proving soundness and completeness for this would require
more substantial changes to the proofs.

B Symbolic Execution
In this section we formally introduce stochastic symbolic
execution. We make use of this form of symbolic execution
in two separate ways. First, our completeness proof hinges
on guarantees provided by the symbolic execution in order
to identify a suitable set of interval traces. Second, our tool
GuBPI relies on the symbolic execution as a first step in the
program analysis, in order to identify relevant paths and in-
dependent subexpressions, and to avoid repeated evaluation
in a small-step semantics.

High-level idea. The overarching idea of symbolic execu-
tion is to postpone the evaluation of sample expressions and
instead use a sample variable to symbolically represent its
outcome. As a consequence, branching and scoring steps can-
not be executed concretely, so we record them symbolically
instead.

Symbolic terms. To postpone concrete sample decisions
we introduce sample variables ùõº1, ùõº2, . . . into our language.
We then define symbolic terms and symbolic values by extend-
ing interval terms and values by adding two new constructs:
every sample variable ùõº ùëó is a symbolic value and for every
primitive function ùëì and symbolic values V1, . . . , V|ùëì |, the
symbolic term ùëì (V1, . . . , V|ùëì |) is a symbolic value, denoting
a function application that is postponed until all sample vari-
ables are instantiated. We denote symbolic terms by M, N, P
and symbolic values by V, W. Formally we define

V := ùë• | ùëü | ùúÜùë• .M | ùúáùúë

ùë• . M | ùõºùëñ | ùëì (V1, . . . , V|ùëì |)
M, N, P := V | MN | if (M, N, P) | ùëì (M1, . . . , M |ùëì |)

| sample | score(M)

The definition of redex and evaluation context extends natu-
rally (recall that we regard ùõº ùëó as a value).

Symbolic execution. A symbolic constraint is a pair (V ‚ä≤‚ä≥
ùëü ) where V is a symbolic value, ‚ä≤‚ä≥ ‚àà {‚â§, <, ‚â•, >} and ùëü ‚àà R.
A symbolic configuration has the form ùúì = (M, ùëõ, Œî, Œû)
where M is a symbolic term, ùëõ ‚àà N a natural number (used to
obtain fresh sample variables), Œî a set of symbolic constraints
(which track the symbolic conditions on the current execu-
tion path), and Œû is a set of symbolic values (which records
all symbolic values scored on the current path). When exe-
cuting symbolically: (1) we evaluate each sample to a fresh
sample variable, (2) we postpone function application, (3) for
each conditional, we explore both branches (our reduction
is nondeterministic) and record the symbolic inequalities
that must hold along the current path, and (4) we record the
symbolic values that we scored with. We give the reduction
rules in Fig. 8.

We call a tuple Œ® = (V, ùëõ, Œî, Œû) (a symbolic configuration
where the symbolic term is a value) a symbolic path. For
a symbolic configuration ùúì , we write symPaths(ùúì ) for the
set of symbolic paths reached when evaluating from ùúì . Note
that symPaths(ùúì ) is countable.

Let V be a symbolic value of type R (no ùúÜ-abstraction
or fixed point) with sample variables within {ùõº1, . . . , ùõºùëõ }.
For a trace ùíî = ‚ü®ùëü1, . . . , ùëüùëõ‚ü© ‚àà [0, 1]ùëõ, we define V [ùíî/ùõº] as
the value (in R) obtained by replacing the sample variables
in ùõº with ùíî and evaluate the postponed primitive function
applications. For a symbolic path Œ® = (V, ùëõ, Œî, Œû), we define
Œ®
(cid:75)
‚à´

(ùëà ) as

(cid:74)

(cid:2)V [ùíî/ùõº] ‚àà ùëà (cid:3) (cid:214)
C‚ä≤‚ä≥ùëü ‚ààŒî

(cid:2)C [ùíî/ùõº] ‚ä≤‚ä≥ ùëü (cid:3) (cid:214)
W ‚ààŒû

[0,1]ùëõ

W [ùíî/ùõº] dùíî.

Solution to symbolic constraints. To simplify notation
(and avoid extensive use of Iverson brackets) we introduce
notation for the set of traces that satisfy a set of symbolic con-
straints. Given a set of symbolic constraints Œî with sample

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

variables contained in {ùõº1, . . . , ùõºùëõ } we define
(cid:217)

Satùëõ (Œî) :=

{ùíî ‚àà [0, 1]ùëõ | V [ùíî/ùõº] ‚ä≤‚ä≥ ùëü }

( V‚ä≤‚ä≥ùëü ) ‚ààŒî

as the set of actual values for the sample variables that satisfy
all constraints. It follows immediately from the definitions
Œ®
that we can replace the Iverson brackets in
by directly
(cid:75)
restricting the integral to the traces in Satùëõ (Œî).
Lemma B.1. For any symbolic path (V, ùëõ, Œî, Œû) and any
ùëà ‚àà Œ£R we have

(cid:74)

(V, ùëõ, Œî, Œû)

(ùëà ) =

(cid:75)

(cid:74)

‚à´

Satùëõ (Œî)

[V [ùíî/ùõº] ‚àà ùëà ]

(cid:214)

W ‚ààŒû

W [ùíî/ùõº] dùíî.

Correctness of symbolic execution. We can now estab-
lish a correspondence between symbolic execution and the
ordinary reduction. If we wish to symbolically analyse a
term ùëÉ, we consider the (symbolic) reductions starting from
(ùëÉ, 0, ‚àÖ, ‚àÖ), resulting in the symbolic paths symPaths(ùëÉ, 0, ‚àÖ, ‚àÖ).
Lemma B.2. Let ‚ä¢ ùëÉ : R and suppose we have (V, ùëõ, Œî, Œû) ‚àà
symPaths(ùëÉ, 0, ‚àÖ, ‚àÖ), where ùëÉ is interpreted as a symbolic term.
Then for any ùíî ‚àà ùëÜùëéùë°ùëõ (Œî), we have

(ùëÉ, ùíî, 1) ‚Üí‚àó (V [ùíî/ùõº], ‚ü®‚ü©, (cid:214)
W ‚ààŒû

W [ùíî/ùõº]).

Proof. A similar proof can be found in [41, Theorem 1]. ‚ñ°
Lemma B.3. Let ‚ä¢ ùëÉ : R and suppose (ùëÉ, ùíî, 1) ‚Üí‚àó (ùëü, ‚ü®‚ü©, ùë§)
for some ùëü ‚àà R. Then there exists a unique (V, ùëõ, Œî, Œû) ‚àà
symPaths(ùëÉ, 0, ‚àÖ, ‚àÖ) such that ùíî ‚àà ùëÜùëéùë°ùëõ (Œî). For this unique
symbolic path we have ùë§ = (cid:206)
W ‚ààŒû W [ùíî/ùõº] and ùëü = V [ùíî/ùõº].
Proof sketch. Choose the same branches in the (cid:123)-reduction
of ùëÉ as in its ‚Üí-reduction. Then it is straightforward to see
that this correspondence holds at every symbolic reduction
step: if (ùëÉ, 0, ‚àÖ, ‚àÖ) (cid:123)‚àó (P ‚Ä≤, ùëõ, Œî, Œû) then the corresponding
‚Üí-reduction steps yield (ùëÉ, ùíîùíî ‚Ä≤, 1) ‚Üí‚àó (ùëÉ ‚Ä≤, ùíî ‚Ä≤, ùë§) where ùíî has
length ùëõ, ùëÉ ‚Ä≤ is P ‚Ä≤[ùíî/ùõº] (after evaluating delayed primitve
function applications), Œî records the guards C [ùíî/ùõº] ‚â§ 0 or
C [ùíî/ùõº] > 0 that need to hold for the trace ùíî, and finally, the
weight ùë§ is given by (cid:206)
‚ñ°

W ‚ààŒû W [ùíî/ùõº] at any point.

Theorem 6.1. Let ‚ä¢ ùëÉ : R be a program and ùëà ‚àà Œ£R. Then

(ùëà ) = (cid:205)Œ®‚ààsymPaths (ùëÉ,0,‚àÖ,‚àÖ)

ùëÉ
(cid:74)

(cid:75)

Œ®

(ùëà ).

(cid:74)

(cid:75)

‚à´

‚àëÔ∏Å

ùëõ ‚ààN
‚àëÔ∏Å

‚à´

ùëõ ‚ààN
(cid:32)

Proof.

(ùëà ) =

ùëÉ
(cid:74)

(cid:75)

=

=

[valùëÉ (ùíî) ‚àà ùëà ]wtùëÉ (ùíî) dùíî

[0,1]ùëõ

‚àëÔ∏Å

[0,1]ùëõ

( V,ùëõ,Œî,Œû)

[ùíî ‚àà Satùëõ (Œî)] [V [ùíî/ùõº] ‚àà ùëà ]

(cid:214)

W [ùíî/ùõº] dùíî

(cid:33)

‚àëÔ∏Å

‚à´

( V,ùëõ,Œî,Œû)

Satùëõ (Œî)

[V [ùíî/ùõº] ‚àà ùëà ]

W ‚ààŒû
(cid:214)

W [ùíî/ùõº] dùíî

W ‚ààŒû

=

‚àëÔ∏Å
( V,ùëõ,Œî,Œû)(cid:74)

(V, ùëõ, Œî, Œû)

(ùëà )

(cid:75)

where the sum ranges over symbolic paths (V, ùëõ, Œî, Œû) ‚àà
symPaths(ùëÉ, 0, ‚àÖ, ‚àÖ). The first equality is by definition, the
second one by Lemmas B.2 and B.3, the third by noting that
Satùëõ (Œî) ‚äÜ [0, 1]ùëõ and exchanging the infinite sum and inte-
gral (which is allowed because everything is nonnegative)
‚ñ°
and the fourth by Lemma B.1.

C Supplementary Material for Section 4
C.1 Infinite Trace Semantics
A convenient alternative to the (finite) trace semantics is
using infinite traces T‚àû := [0, 1]N with a suitable ùúé-algebra
[16, 40]. The ùúé-algebra on T‚àû is defined as
and measure ùúáT‚àû
the smallest ùúé-algebra that contains all sets ùëà √ó T‚àû where
ùëà ‚àà Œ£ [0,1]ùëõ for some ùëõ ‚àà N. The measure ùúáT‚àû
is the unique
measure with ùúáT‚àû (ùëà √ó T‚àû) = ùúÜùëõ (ùëà ) for ùëà ‚àà Œ£ [0,1]ùëõ . We use
the symbol ùíñ for an infinite trace in T‚àû. For a finite trace ùíî
and infinite trace ùíñ we write ùíîùíñ ‚àà T‚àû for their concatenation.
For any infinite trace ùíñ ‚àà T‚àû, there is at most one prefix
ùíî ‚àà T with wtùëÉ (ùíî) > 0 since the reduction is deterministic.
ùëÉ (ùíñ) :=
We can therefore define wt‚àû
valùëÉ (ùíî) if such a prefix ùíî exists, and wt‚àû
ùëÉ (ùíñ)
is undefined otherwise. The infinite trace semantics of a term
is then defined as

ùëÉ (ùíñ) := wtùëÉ (ùíî) and val‚àû

ùëÉ (ùíñ) := 0 and val‚àû

‚à´

(ùëà ) :=

ùëÉ
(cid:74)

(cid:75)

(val‚àû

ùëÉ ) ‚àí1 (ùëà )

wt‚àû

ùëÉ (ùíñ) ùúáT‚àû (dùíñ).

Lemma C.1. The finite and infinite trace semantics agree,
that is:

wtùëÉ (ùíî) ùúáT (dùíî) =

‚à´

wt‚àû

ùëÉ (ùíñ) ùúáT‚àû (dùíñ).

(valùëÉ ) ‚àí1 (ùëà )

Proof. Observe that val‚àû
wtùëÉ (ùíî) for all ùíñ ‚àà T‚àû if wtùëÉ (ùíî) > 0. Then we get:

(val‚àû

ùëÉ ) ‚àí1 (ùëà )
ùëÉ (ùíîùíñ) = valùëÉ (ùíî) and wt‚àû

ùëÉ (ùíîùíñ) =

wtùëÉ (ùíî) ùúáT (dùíî)

(valùëÉ ) ‚àí1 (ùëà )

[valùëÉ (ùíî) ‚àà ùëà ]wtùëÉ (ùíî)

‚à´

T‚àû

ùúáT‚àû (dùíñ)ùúáT (dùíî)

[val‚àû

ùëÉ (ùíîùíñ) ‚àà ùëà ]wt‚àû

ùëÉ (ùíîùíñ)ùúáT‚àû (dùíñ)ùúáT (dùíî)

(wtùëÉ ) ‚àí1 (R>0)

‚à´

(wtùëÉ ) ‚àí1 (R>0)

T‚àû

(wtùëÉ ) ‚àí1 (R>0)√óT‚àû

[val‚àû

ùëÉ (ùíñ) ‚àà ùëà ]wt‚àû

ùëÉ (ùíñ)ùúáT‚àû (dùíñ)

wt‚àû

ùëÉ (ùíñ)ùúáT‚àû (dùíñ)

(val‚àû

ùëÉ ) ‚àí1 (ùëà )

where we used the fact that the sets {ùíî} √ó T‚àû are disjoint
for different ùíî ‚àà wt‚àí1
ùëÉ (R>0) because otherwise we would
be able to find a trace ùíî as a prefix of ùíî ‚Ä≤ and both having
positive weight, which is impossible due to the deterministic
ùëÉ )‚àí1(R>0)
reduction. Therefore (wtùëÉ )‚àí1(R>0) √ó T‚àû = (wt‚àû

‚à´

‚à´

‚à´

‚à´

‚à´

‚à´

=

=

=

=

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

and everything works as desired. Note that the second to
last equality follows from Fubini‚Äôs theorem and the fact that
‚ñ°
the product measure of ùúáT and ùúáT‚àû

is ùúáT‚àû

again.

C.2 Exhaustivity and Soundness
Example C.1 (more examples of exhaustive sets). Here are
more examples and counterexamples for exhaustivity.

(i) {‚ü®‚ü©} is an (uninteresting) exhaustive set and only use-

ful for deterministic programs.

(ii) {‚ü®[2‚àíùëõ‚àí1, 2‚àíùëõ]‚ü© | ùëõ ‚àà N} is exhaustive because only

the trace ‚ü®0‚ü© (with measure 0) is not covered.

(iii) Let ùëéùëõ ‚â• 0 be a converging series, i.e. (cid:205)ùëõ

ùëñ=1 ùëéùëõ < ‚àû,

for example ùëéùëõ = ùëõ‚àí2. Define

T := {‚ü®[0, ùëí‚àíùëé1], . . . , [0, ùëí‚àíùëéùëõ ], [ùëí‚àíùëéùëõ+1, 1]‚ü© | ùëõ ‚àà N}.
This is not an exhaustive set since it doesn‚Äôt cover any of the
traces in

which has measure (cid:206)‚àû

[0, ùëí‚àíùëé1) √ó [0, ùëí‚àíùëé2, 1) √ó ¬∑ ¬∑ ¬∑
ùëñ=1 ùëí‚àíùëéùëñ = exp (cid:0)‚àí (cid:205)‚àû
We also note that exhaustivity can be expressed just in
terms of finite traces as well, at the cost of a more complicated
definition.

ùëñ=1 ùëéùëñ (cid:1) > 0.

Lemma C.2. A set of interval traces T is exhaustive if and
only if

ùúáT (cid:169)
(cid:173)
(cid:171)

[0, 1]ùëõ \ (cid:169)
(cid:173)
(cid:171)

(cid:216)

‚ü®ùêº1,...,ùêºùëö ‚ü© ‚ààT,ùëö ‚â§ùëõ

as ùëõ ‚Üí ‚àû.
Proof. Let ùëÜ := T‚àû \ (cid:208)
haustivity, ùúáT‚àû (ùëÜ) = 0. Let

ùêº1 √ó ¬∑ ¬∑ ¬∑ √ó ùêºùëö √ó [0, 1]ùëõ‚àíùëö(cid:170)
(cid:174)
(cid:172)

(cid:170)
(cid:174)
(cid:172)

‚Üí 0

ùíï ‚ààT cover (ùíï). By the definition of ex-

ùëÜùëõ = [0, 1]ùëõ \ (cid:169)
(cid:173)
(cid:171)

(cid:216)

‚ü®ùêº1,...,ùêºùëö ‚ü© ‚ààT,ùëö ‚â§ùëõ

ùêº1 √ó ¬∑ ¬∑ ¬∑ √ó ùêºùëö √ó [0, 1]ùëõ‚àíùëö(cid:170)
(cid:174)
(cid:172)

.

It‚Äôs easy to see that ùëÜ = (cid:209)‚àû
ùëõ=0 ùëÜùëõ √ó T‚àû where ùëÜùëõ √ó T‚àû is a de-
creasing sequence of sets: ùëÜ1√óT‚àû ‚äá ùëÜ2√óT‚àû ‚äá ¬∑ ¬∑ ¬∑ . Since mea-
sures are continuous from above, we have limùëõ‚Üí‚àû ùúáT (ùëÜùëõ) =
‚ñ°
limùëõ‚Üí‚àû ùúáT‚àû (ùëÜùëõ √ó T‚àû) = ùúáT‚àû (ùëÜ) = 0, as desired.

The following lemma establishes a correspondence be-
tween infinite trace semantics and interval trace semantics.

Lemma C.3. For any interval trace ùíï and infinite trace ùíî‚àû
with a prefix ùíî such that ùíî ‚ä≥ ùíï, we have wt‚àû
ùëÉ (ùíï)
I
and val‚àû
ùëÉ (ùíî‚àû) ‚àà val
ùëÉ (ùíï).
Proof. Follows directly from the definition of infinite trace
‚ñ°
semantics and Lemma 3.1.

ùëÉ (ùíî‚àû) ‚àà wtI

Using the previous results, we can prove soundness of

upper bounds.

=

=

‚â•

‚â•

‚â•

=

ùíï

(cid:77)

(cid:76)
‚à´

‚à´

T‚àû

ùíï

(cid:76)

(cid:77)

ùíï ‚àà T
‚àëÔ∏Å

ùíï ‚àà T
‚à´

(cid:208)

‚à´

T‚àû
ùëÉ
(cid:74)

(cid:75)

(ùëà )

Theorem 4.2 (Sound upper bounds). Let T be a countable
and exhaustive set of interval traces and ‚ä¢ ùëÉ : R a program.
‚â§ upperBdT
ùëÉ .
Then
Proof. For any ùëà ‚àà Œ£R, we have

ùëÉ
(cid:74)

(cid:75)

upperBdT
‚àëÔ∏Å

ùëÉ (ùëà )

vol(ùíï)(sup wt

I
ùëÉ (ùíï)) [val

I
ùëÉ (ùíï) ‚à© ùëà ‚â† ‚àÖ]

ùíï ‚àà T
‚àëÔ∏Å

‚à´

I
I
ùëÉ (ùíï) ‚à© ùëà ‚â† ‚àÖ] dùíî
(sup wt
ùëÉ (ùíï)) [val

wt‚àû

ùëÉ (ùíîùíñ) [val‚àû

ùëÉ (ùíîùíñ) ‚àà ùëà ] dùíñ dùíî

wt‚àû

ùëÉ (ùíñ) [val‚àû

ùëÉ (ùíñ) ‚àà ùëà ] dùíî

ùíï

√óT‚àû

ùíï ‚ààT

(cid:77)
(cid:76)
ùëÉ (ùíñ) [val‚àû
wt‚àû

ùëÉ (ùíñ) ‚àà ùëà ] dùíñ

(4)

(5)

(6)

where Eq. (4) follows from Lemma C.3, Eq. (5) from exhaus-
‚ñ°
tivity and Eq. (6) from Lemma C.1.

C.3 Assumptions for Completeness

Remarks on Assumption 1. We can formally express
Assumption 1 from Section 4 about a given program ‚ä¢ ùëÉ : R
as follows. For each symbolic path Œ® = (V, ùëõ, Œî, Œû), we
require that V, each C with C ‚ä≤‚ä≥ 0 ‚àà Œî, and each W ‚àà Œû
contain each sample variable ùõºùëñ at most once.

Example C.2. The pedestrian example (Example 1.1) satis-
fies Assumption 1 because the symbolic paths have the form
Œ® = (V, ùëõ, Œî, Œû) with:
V = 3ùõº1
ùëõ = 2ùëò + 1
Œî = {ùõº3 ‚àí 1

2 ‚ä≤‚ä≥ 0, . . . , ùõº2ùëò+1 ‚àí 1

2 ‚ä≤‚ä≥ 0, ùõº5 ‚àí 1

2 ‚ä≤‚ä≥ 0}

‚à™ {3ùõº1 > 0,

3ùõº1 ¬± ùõº2 > 0,
. . . ,
3ùõº1 ¬± ùõº2 ¬± ùõº4 ¬∑ ¬∑ ¬∑ ¬± ùõº2ùëò‚àí2 > 0,
3ùõº1 ¬± ùõº2 ¬± ùõº4 ¬∑ ¬∑ ¬∑ ¬± ùõº2ùëò ‚â§ 0}
Œû = {pdf Normal(1.1,0.1) (ùõº2 + ùõº4 + ¬∑ ¬∑ ¬∑ + ùõº2ùëò )}

As we can see, none of the symbolic values contains a sample
variable twice, so the assumption is satisfied.

Remarks on Assumption 2. We first prove the sufficient

condition for interval separability from Section 4.2.

Lemma C.4. If a function ùëì : Rùëõ ‚Üí R is boxwise contin-
uous and preimages of points are null sets then ùëì is interval
separable.

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Proof. We decompose ùëì ‚àí1([ùëé, ùëè]) = ùëì ‚àí1((ùëé, ùëè)) ‚à™ ùëì ‚àí1({ùëé, ùëè})
and deal with the former set first. By boxwise continuity,
ùëì = (cid:208)ùëñ ùëì |ùêµùëñ where (cid:208)ùëñ ùêµùëñ = Rùëõ and each ùëì |ùêµùëñ is continuous
on ùêµùëñ . To show that the preimage ùëì ‚àí1((ùëé, ùëè)) can be tightly
approximated by a countable set of boxes, it suffices to show
this for each (ùëì |ùêµùëñ )‚àí1((ùëé, ùëè)). This set is open in ùêµùëñ by con-
tinuity of ùëì |ùêµùëñ , so it can be written as a countable union of
boxes (e.g. by taking a box within ùêµùëñ around each rational
point, which exists because it‚Äôs an open set). By the assump-
tion, the preimage ùëì ‚àí1({ùëé, ùëè}) is a null set. Hence ùëì ‚àí1([ùëé, ùëè])
‚ñ°
can be approximated by a null set.

Note that a composition of interval separable functions
need not be interval separable. This is an incorrect assump-
tion made in the completeness proof of [4]. (To fix their
Theorem 3.8, one needs to make the additional assumption
that the set of primitive functions be closed under compo-
sition.) To see this, let ùëì , ùëî : R ‚Üí R be interval separable
functions and ùêº an interval. By definition, there are intervals
ùêµùëñ such that (cid:208)ùëñ ùêµùëñ ‚à™ùëÅ = ùëì ‚àí1(ùêº ) where ùëÅ is a null set. Then by
interval separability, the preimage ùëî‚àí1((cid:208)ùëñ ùêµùëñ ) can be tightly
ùëó , but the preimage ùëî‚àí1(ùëÅ ) need
approximated by interals ùêµ ‚Ä≤
not be a null set. It is also not clear at all whether one can
approximate the preimage (ùëì ‚ó¶ùëî)‚àí1(ùêº ) tightly using intervals
without further restrictions on ùëì and ùëî. For this reason, we
require the assumption that the set of primitive functions be
closed under composition.

It is not immediately obvious that such a set of functions
exists. One example is given by the following. A function
: Rùëõ ‚Üí R is called a submersion if it is continuously
ùëì
differentiable and its gradient is nonzero everywhere.

Lemma C.5. The set Fsubm of submersions is closed under
composition and each of its functions is boxwise continuous
and interval separable.
Proof. Boxwise continuity is obvious given that the functions
are even continuously differentiable. For interval separabil-
ity, we use Lemma C.4. Let ùëì : Rùëõ ‚Üí R ‚àà Fsubm. Since ùëì
is a submersion, the preimage ùëì ‚àí1(ùë•) of any point ùë• ‚àà R
is an (ùëõ ‚àí 1)-dimensional submanifold of Rùëõ by the preim-
age theorem (a variation of the implicit function theorem).
Submanifolds of codimension > 1 have measure zero. (This
well-known fact can be shown by writing the submanifold as
a countable union of graphs and applying Fubini‚Äôs theorem
to each of them.) Therefore, the lemma applies.

For closure under composition, let ùëì : Rùëö ‚Üí R and ùëìùëñ :
Rùëõùëñ ‚Üí R for ùëñ ‚àà {1, . . . , ùëö}, all in Fsubm. The composition
ùëî := ùëì ‚ó¶ (ùëì1 √ó ¬∑ ¬∑ ¬∑ √ó ùëìùëö) is clearly ùê∂1 again, so we just have to
check the submersion property. By the chain rule, we find
that the gradient of the composition

‚àáùëî(ùë•1, . . . , ùë•ùëö) = (cid:169)
(cid:173)
(cid:173)
(cid:171)

ùúï1ùëì (ùëì1(ùë•1), . . . , ùëìùëö (ùë•ùëö)) ¬∑ ‚àáùëì1(ùë•1)
...
ùúïùëö ùëì (ùëì1(ùë•1), . . . , ùëìùëö (ùë•ùëö)) ¬∑ ‚àáùëìùëö (ùë•ùëö)

(cid:170)
(cid:174)
(cid:174)
(cid:172)

is nonzero because at least one of the ùúïùëñ ùëì is nonzero and
‚àáùëìùëñ (ùë•ùëñ ) ‚â† 0 by assumption. Hence the composition is a
‚ñ°
submersion again.

Unfortunately, the set of submersions does not contain
constant functions. This is a problem because then it is not
guaranteed that partially applying a primitive function to a
constant is still an admissible primitive function. (For exam-
ple, this would break Lemma C.8.) Hence we need to assume
that all constant functions be primitive functions. Luckily, the
set Fsubm of submersions can be easily extended to accom-
modate this.

subm be the set of functions ùëì : Rùëõ ‚Üí R (for
Lemma C.6. Let F ‚àó
all ùëõ ‚àà N) such that whenever the partial derivative ùúïùëñ ùëì (ùë•) is
zero for some ùëñ ‚àà {1, . . . , ùëõ} and ùë• ‚àà Rùëõ then ùëì is constant in its
ùëñ-th argument, i.e. there is a function ùëì ‚àó : Rùëõ‚àí1 ‚Üí R such that
ùëì (ùë•1, . . . , ùë•ùëõ) = ùëì ‚àó (ùë•1, . . . , ùë•ùëñ‚àí1, ùë•ùëñ+1, . . . ùë•ùëõ). This set satisfies
all the assumptions about sets of primitive functions: it is closed
under composition, contains all constant functions, and all its
functions are boxwise continuous and interval separable.
Proof. Boxwise continuity is obvious given that the functions
are even continuously differentiable. Similarly, it is clear that
F ‚àó

contains all constant functions.

subm
For interval separability, let ùëì : Rùëõ ‚Üí R ‚àà F ‚àó

and ùêΩ ‚äÜ
{1, . . . , ùëõ} be the set of indices in which ùëì is not constant, and
: R|ùêΩ | ‚Üí R
ùêΩ ‚Ä≤ its complement. Hence there is a submersion ùëìùêΩ
such that ùëì (ùë•) = ùëìùêΩ (ùë• ùêΩ ) where ùë• ùêΩ stands for the vector of
coordinates of ùë• with index in ùêΩ . The preimage of ùëì ‚àí1(ùëà ) ‚äÜ
R |ùêΩ | of any set ùëà ‚äÜ R can be tightly approximated by boxes
(ùëà ) can because ùëì ‚àí1(ùëà ) is a Cartesian
if and only if ùëì ‚àí1
(ùëà ) and R |ùêΩ ‚Ä≤ |. Since ùëìùêΩ is interval separable by
product of ùëì ‚àí1
the previous lemma, this shows that ùëì is as well.

subm

ùêΩ

ùêΩ

For closure under composition, let ùëì : Rùëö ‚Üí R and ùëìùëñ :
Rùëõùëñ ‚Üí R for ùëñ ‚àà {1, . . . , ùëö}, all in F ‚àó
. The composition
ùëî := ùëì ‚ó¶ (ùëì1 √ó ¬∑ ¬∑ ¬∑ √ó ùëìùëö) is clearly ùê∂1 again, so we just have
to check the property of the partial derivatives. By the chain
rule, the partial derivatives of the composition are

subm

ùúïùëñùëî(ùë•1, . . . , ùë•ùëö) = ùúïùëó ùëì (ùëì1 (ùë•1), . . . , ùëìùëö (ùë•ùëö))ùúïùëò ùëìùëó (ùë• ùëó1, . . . , ùë• ùëóùëõ ùëó )
for some ùëó ‚àà {1, . . . ùëö} and ùëò ‚àà {1, . . . ùëõ ùëó }, and for all ùë•1 ‚àà
Rùëõ1, . . . , ùë•ùëö ‚àà Rùëõùëö . So if this partial derivative is zero, there
are two cases. First, if ùúïùëó ùëì (ùëì1(ùë•1), . . . , ùëìùëö (ùë•ùëö)) = 0 then ùëì
must be constant in its ùëó-th argument (because ùëì ‚àà F ‚àó
)
subm
and thus ùëî is constant in ùë• ùëó , and in particular the ùëñ-th argu-
ment (which is an entry of ùë• ùëó ). Second, if ùúïùëò ùëìùëó (ùë• ùëó1, . . . , ùë• ùëóùëõ ùëó ) =
0 then ùëìùëó must be constant in its ùëò-th argument (because
) and thus ùëî is constant in its corresponding ùëñ-th
ùëìùëó ‚àà F ‚àó
‚ñ°
argument as well. This proves ùëî ‚àà F ‚àó

, as desired.

subm

subm

Note that exp, sinh, arctan, ùëõ-th roots for ùëõ odd, and all
. So this is a useful set of prim-
linear functions are in F ‚àó
itive functions already. Unfortunately, it does not include

subm

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

multiplication because the gradient of (ùë•, ùë¶) ‚Ü¶‚Üí ùë•ùë¶ is zero at
(0, 0). To fix this issue, we need to restrict the domain.15

For simplicity, we required primitive functions to be de-
fined on all of Rùëõ. Suppose we allow for primitive func-
tions to be defined only on an open subset of Rùëõ, and ap-
plying them to a value outside their domain is disallowed
in SPCF programs. Then we can also include multiplication
(on R2 \ {(0, 0)}), logarithms (on (0, ‚àû)), non-constant uni-
variate polynomials (on the complement of their stationary
points), quantile functions of continuous distributions with
nonzero density (on (0, 1)), and probability density functions
(on the complement of their stationary points). The fact that
some points in the domain are missing is inconvenient for
functions that can be continuously extended to the these
points, but one can work around this in a program by check-
ing for the points that are not in the domain and returning
the function values as constants for those cases.

C.4 Completeness Proof
This section uses the definitions of boxwise continuity and
interval separability from Section 4.2. As discussed there, we
assume that for each symbolic path Œ® = (V, ùëõ, Œî, Œû), we
have that V, each C with C ‚ä≤‚ä≥ 0 ‚àà Œî, and each W ‚àà Œû
contains each sample variable ùõºùëñ at most once (Assumption
1). We also assume that the primitive functions are boxwise
continuous, interval separable and closed under composition
(Assumption 2). Furthermore, we say that T is a subdivision
of ùíï if T is compatible and (cid:208)
ùíï ‚Ä≤ ‚ààT
Theorem 4.3 (Completeness of interval approximations).
Let ùêº ‚àà I and ‚ä¢ ùëÉ : R be an almost surely terminating program
satisfying the two assumptions discussed above. Then, for all
ùúñ > 0, there is a countable set of interval traces T ‚äÜ TI that is
compatible and exhaustive such that

.
(cid:77)

ùíï ‚Ä≤

=

(cid:77)

(cid:76)

(cid:76)

ùíï

ùëÉ
(cid:74)

upperBdT

ùëÉ (ùêº ) ‚àí ùúñ ‚â§

(ùêº ) ‚â§ lowerBdT

ùëÉ (ùêº ) + ùúñ.

(cid:75)
Proof. First, we give a brief outline of how the proof works.
The idea is to cover {ùíî ‚àà T | valùëÉ (ùíî) ‚àà ùêº } using boxes
(interval traces). We can achieve this using symbolic execu-
tion: for a fixed path through the program, the result value
is just a composition of primitive functions applied to the
samples. Similarly, the weight function is a product of such
functions, hence boxwise continuous. By passing to smaller
boxes, we can assume that it is continuous on each box. In
order to approximate the integral of the weight function, we
use Riemann sums (as used in the definition of the Riemann

15Handling these issues at the level of primitive functions directly (without
restricting the domain) seems challenging: even if a function has only
one point with zero gradient, e.g. multiplication, its preimage under other
primitive functions can become very complicated. We tried to handle this by
allowing the primitive functions to be submersions except on a null set given
by a union of lower-dimensional manifolds. However, the preimages of such
manifolds need not be manifolds again. Hence it seems difficult to come
up with a broader class of primitive functions satisfying the assumptions
without restricting the domain.

integral). We partition the domain into smaller and smaller
boxes such that the lower bound and the upper bound of the
weight function come arbitrarily close (by continuity). Then
by properties of the Riemann integral, the bounds arising
from the interval traces representing the boxes in this parti-
tion converge to the desired integral of the weight function.
The details of the proof are as follows.

ùíï

(cid:76)

(cid:77)

ùíï ‚àà TŒ®

Step 1: approximating the branching inequalities. Let
Œ® = (V, ùëõ, Œî, Œû) a symbolic path of ùëÉ. To find a countable set
TŒ® ‚äÜ TI such that (cid:208)
‚ãê Satùëõ (Œî). Note that Satùëõ (Œî)
is a finite intersection of sets of the form {ùíî ‚àà [0, 1]ùëõ |
C [ùíî/ùõº] ‚ä≤‚ä≥ 0} where ‚ä≤‚ä≥‚àà {‚â§, >}. In the ‚â§ case, we can write
this constraint as C [ùíî/ùõº] ‚àà (cid:208)ùëõ ‚ààN [‚àíùëõ, 0] and in the > case
as C [ùíî/ùõº] ‚àà (cid:208)ùëõ ‚ààN [1/ùëõ, ùëõ]. By applying Lemma C.8 to each
of the compact intervals in these unions, we obtain a count-
able union of boxes that is a tight subset of {ùíî ‚àà [0, 1]ùëõ |
C [ùíî/ùõº] ‚ä≤‚ä≥ 0}. Since the intersection of two boxes is a box
and since Satùëõ (Œî) is a finite intersection of such countable
unions of boxes, it can be rewritten as a countable union of
boxes. This yields TŒ®, such that (cid:208)

‚ãê Satùëõ (Œî).

ùíï

ùíï

ùíï

Œ®,ùêºùëê

ùíï ‚ààT‚Ä≤

ùíï ‚àà T‚Ä≤

Œ®,ùêº ‚äÜ TI such that (cid:208)

Step 2: handling the result value. By applying Lemma C.8
and intersecting the obtained interval traces with TŒ®, we
‚ãê
obtain a countable set T ‚Ä≤
Œ®,ùêº (cid:76)
(cid:77)
{ùíî ‚àà Sat(Œî) | V [ùíî/ùõº] ‚àà ùêº }. By the same lemma, we find
Œ®,ùêº ùëê ‚äÜ TI such that (cid:208)
‚ãê {ùíî ‚àà
a countable set T ‚Ä≤
Sat(Œî) | V [ùíî/ùõº] ‚àâ ùêº } because the complement of ùêº can be
written as a countable union of intervals. By Lemma C.10, we
find subdivisions TŒ®,ùêº and TŒ®,ùêº ùëê that even satisfy (cid:208)
‚ãê
ùíï ‚ààTŒ®,ùêº
val‚àí1
ùëÉ (R \ ùêº ) ‚à© Sat(Œî).
By Lemma C.7, we can assume that the interval traces TŒ®,ùêº
are almost disjoint. Because of the almost sure termination
assumption, the set of traces (cid:208)
ùëÉ (R)
where the union ranges over all symbolic paths of ùëÉ has
measure 1. As a consequence, (cid:208)Œ®‚ààsymPaths (ùëÉ,0,‚àÖ,‚àÖ) (TŒ®,ùêº ‚à™TŒ®,ùêº ùëê )
is a compatible and exhaustive set of interval traces. Now

( V,ùëõ,Œî,Œû) Sat(Œî) = val‚àí1

ùëÉ (ùêº ) ‚à© Sat(Œî) and (cid:208)

‚ãê val‚àí1

ùíï ‚àà TŒ®,ùêºùëê

(cid:77)

(cid:77)

(cid:77)

(cid:76)

(cid:76)

(cid:76)

ùíï

ùíï

ùíï ‚àà TŒ®

(cid:76)

(cid:77)

(ùêº ) =

ùëÉ
(cid:74)

(cid:75)

=

=

‚àëÔ∏Å
( V,ùëõ,Œî,Œû) (cid:74)
‚à´
‚àëÔ∏Å

( V,ùëõ,Œî,Œû)
‚àëÔ∏Å

(V, ùëõ, Œî, Œû)

(ùêº )

(cid:75)

[V [ùíî/ùõº] ‚àà ùêº ]

(cid:214)

W ‚ààŒû

W [ùíî/ùõº] dùíî

Satùëõ (Œî)

‚àëÔ∏Å

‚à´

(cid:214)

W [ùíî/ùõº] dùíî

( V,ùëõ,Œî,Œû)

ùíï ‚àà T(V,ùëõ,Œî,Œû),ùêº

ùíï

(cid:76)

(cid:77)

W ‚ààŒû

where the outer sum ranges over the symbolic paths (V,
ùëõ, Œî, Œû) ‚àà symPaths(ùëÉ, 0, ‚àÖ, ‚àÖ). The first equality holds by
Theorem 6.1, the second one by Lemma B.1 and the last one
by the construction of T( V,ùëõ,Œî,Œû),ùêº .

Step 3: approximating the weight function. Let

T ‚Ä≤ := (cid:208)Œ®‚ààsymPaths (ùëÉ,0,‚àÖ,‚àÖ) TŒ®,ùêº .

For each ùíï ‚àà T ‚Ä≤, fix some ùúñùíï > 0, such that (cid:205)
ùíï ‚ààT‚Ä≤ ùúñùíï = ùúñ.
This can be achieved, for example, by enumerating T ‚Ä≤ as
ùíï (1), ùíï (2), . . . and choosing ùúñ
ùíï (ùëñ ) = 2‚àíùëñùúñ. By Lemma C.9, we

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

can find for each ùíï ‚àà T ‚Ä≤ a countable set Sùíï of interval traces
such that:

‚àëÔ∏Å

ùíï ‚Ä≤ ‚ààSùíï
‚à´

‚â§

(cid:214)

W [ùíî/ùõº] ‚àí ùúñùíï /2

vol(ùíï ‚Ä≤) sup
ùíï ‚Ä≤

ùíî ‚àà

W ‚ààŒû

(cid:76)

(cid:77)
W [ùíî/ùõº] dùíî

(cid:214)

ùíï
(cid:76)
(cid:77)
‚àëÔ∏Å

‚â§

W ‚ààŒû
vol(ùíï ‚Ä≤) min
ùíï ‚Ä≤
(cid:77)

(cid:76)

(cid:214)

W [ùíî/ùõº] + ùúñùíï /2

ùíï ‚Ä≤ ‚ààSùíï

ùíî ‚àà
Next, choose ùúñùíï ‚Ä≤ > 0 for each ùíï ‚Ä≤ in such a way that (cid:205)
ùúñùíï ‚Ä≤ <
ùúñùíï /2. By Lemma C.11, we can find for each ùíï ‚Ä≤ a finite subdi-
vision S ‚Ä≤

ùíï ‚Ä≤ ‚ààS‚Ä≤
ùíï

W ‚ààŒû

ùíï ‚Ä≤ such that for all ùíï ‚Ä≤‚Ä≤ ‚àà S ‚Ä≤
wtùëÉ (ùíî) = sup
ùíï ‚Ä≤‚Ä≤

ùíï ‚Ä≤, we have
I
ùëÉ (ùíï ‚Ä≤‚Ä≤) ‚àí ùúñùíï ‚Ä≤
W [ùíî/ùõº] ‚â• sup wt

sup
ùíï ‚Ä≤‚Ä≤
ùíî ‚àà

(cid:214)

ùíî ‚àà

(cid:76)
(cid:77)
min
ùíï ‚Ä≤‚Ä≤
ùíî ‚àà

(cid:76)

(cid:77)

(cid:76)

(cid:77)
wtùëÉ (ùíî) = min
ùíï ‚Ä≤‚Ä≤
(cid:77)

ùíî ‚àà

(cid:76)

W ‚ààŒû
(cid:214)

W ‚ààŒû

I
ùëÉ (ùíï ‚Ä≤‚Ä≤) + ùúñùíï ‚Ä≤.
W [ùíî/ùõº] ‚â§ min wt

Multiplying by vol(ùíï ‚Ä≤‚Ä≤) and summing over all ùíï ‚Ä≤‚Ä≤, we find
together with the previous inequality

‚àëÔ∏Å

‚àëÔ∏Å

vol(ùíï ‚Ä≤‚Ä≤) sup wt

I
ùëÉ (ùíï ‚Ä≤‚Ä≤) ‚àí ùúñùíï

ùíï ‚Ä≤ ‚ààSùíï

ùíï ‚Ä≤‚Ä≤ ‚ààS‚Ä≤
ùíï‚Ä≤
‚àëÔ∏Å

‚àëÔ∏Å

‚â§

‚â§

‚â§

‚â§

vol(ùíï ‚Ä≤‚Ä≤)(sup wt

I
ùëÉ (ùíï ‚Ä≤‚Ä≤) ‚àí ùúñùíï ‚Ä≤) ‚àí ùúñùíï /2

ùíï ‚Ä≤ ‚ààSùíï
‚à´

ùíï ‚Ä≤‚Ä≤ ‚ààS‚Ä≤
ùíï‚Ä≤

(cid:214)

W [ùíî/ùõº] dùíî

ùíï
(cid:76)
(cid:77)
‚àëÔ∏Å

W ‚ààŒû
‚àëÔ∏Å

ùíï ‚Ä≤ ‚ààSùíï
‚àëÔ∏Å

ùíï ‚Ä≤‚Ä≤ ‚ààS‚Ä≤
ùíï‚Ä≤
‚àëÔ∏Å

ùíï ‚Ä≤ ‚ààSùíï

ùíï ‚Ä≤‚Ä≤ ‚ààS‚Ä≤
ùíï‚Ä≤

vol(ùíï ‚Ä≤‚Ä≤)(min wt

I
ùëÉ (ùíï ‚Ä≤‚Ä≤) + ùúñùíï ‚Ä≤) + ùúñùíï /2

I
ùëÉ (ùíï ‚Ä≤‚Ä≤) + ùúñùíï
vol(ùíï ‚Ä≤‚Ä≤) min wt

vol(ùíï ‚Ä≤‚Ä≤) ‚â§ 1 and thus the contribution of all

because (cid:205)
the ùúñùíï ‚Ä≤ is at most ùúñùíï /2.

ùíï ‚Ä≤‚Ä≤ ‚ààS‚Ä≤
ùíï‚Ä≤

Overall, the desired trace set is given by

T :=

(cid:216)

Œ®=( V,ùëõ,Œî,Œû)

TŒ®,ùêº ùëê ‚à™

(cid:216)

(cid:216)

ùíï ‚ààTŒ®,ùêº

ùíï ‚Ä≤ ‚ààSùíï

(cid:169)
(cid:173)
(cid:171)

,

S ‚Ä≤
ùíï ‚Ä≤(cid:170)
(cid:174)
(cid:172)

is compatible and exhaustive because it is a subdivision of
I
TŒ®,ùêº ùëê and TŒ®,ùêº . By construction, we have val
ùëÉ (ùíï) ‚äÜ ùêº for
I
ùíï ‚àà TŒ®,ùêº and val
ùëÉ (ùíï) ‚à© ùêº = ‚àÖ for ùíï ‚àà TŒ®,ùêº ùëê . Hence the TŒ®,ùêº ùëê -
summands vanish in the sum for the bounds and we obtain

upperBdT
‚àëÔ∏Å

ùëÉ (ùêº ) ‚àí ùúñ
I
I
vol(ùíï)(sup wt
ùëÉ (ùíï) ‚à© ùêº ‚â† ‚àÖ] ‚àí ùúñ
ùëÉ (ùíï)) [val

=

ùíï ‚ààT

=

‚àëÔ∏Å

‚àëÔ∏Å

Œ®=( V,ùëõ,Œî,Œû)

ùíï ‚ààTŒ®,ùêº

(cid:169)
(cid:173)
(cid:171)

‚â§

‚àëÔ∏Å

‚àëÔ∏Å

ùíï ‚Ä≤ ‚ààSùíï
‚àëÔ∏Å

ùíï ‚Ä≤‚Ä≤ ‚ààS‚Ä≤
ùíï‚Ä≤
‚àëÔ∏Å

I
ùëÉ (ùíï ‚Ä≤‚Ä≤) ‚àí ùúñùíï (cid:170)
vol(ùíï ‚Ä≤‚Ä≤) sup wt
(cid:174)
(cid:172)

‚à´

(cid:214)

W [ùíî/ùõº] dùíî

Œ®=( V,ùëõ,Œî,Œû)
(cid:124)

(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)

ùíï ‚ààTŒ®,ùêº

ùíï

W ‚ààŒû
(cid:77)
(cid:76)
(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)
(cid:123)(cid:122)
(ùêº )
ùëÉ
(cid:74)

(cid:75)

=

(cid:125)

‚â§

=

‚àëÔ∏Å

‚àëÔ∏Å

Œ®=( V,ùëõ,Œî,Œû)

ùíï ‚àà TŒ®,ùêº

‚àëÔ∏Å

‚àëÔ∏Å

vol(ùíï ‚Ä≤‚Ä≤) min wt

I
ùëÉ (ùíï ‚Ä≤‚Ä≤) + ùúñùíï (cid:170)
(cid:174)
ùíï ‚Ä≤ ‚ààSùíï
(cid:172)
I
I
vol(ùíï)(min wt
ùëÉ (ùíï) ‚äÜ ùêº ] + ùúñ
ùëÉ (ùíï)) [val

ùíï ‚Ä≤‚Ä≤ ‚ààS‚Ä≤
ùíï‚Ä≤

(cid:169)
(cid:173)
(cid:171)
‚àëÔ∏Å

ùíï ‚àà T

= lowerBdT

ùëÉ (ùêº ) + ùúñ.

‚ñ°

Lemma C.7. Given a countable set of interval traces T ‚äÜ Iùëõ,
there is a countable set of interval traces T ‚Ä≤ ‚äÜ Iùëõ that is
compatible and satisfies (cid:208)
ùíï
(cid:76)
Proof. Let ùê¥ : N ‚Üí T be an enumeration. Define ùê¥‚Ä≤ : N ‚Üí
Œ£Rùëõ by ùëö ‚Ü¶‚Üí ùê¥(ùëö) \ (cid:208)ùëö‚àí1
ùëñ=0 ùê¥(ùëñ) where ùëÜ denotes the closure
of ùëÜ. Then the collection {ùê¥‚Ä≤(ùëö) | ùëö ‚àà N} is pairwise almost
disjoint, and each ùê¥‚Ä≤(ùëö) can be written as a finite union of
‚ñ°
boxes, proving the claim.

= (cid:208)

ùíï ‚àà T‚Ä≤

.
(cid:77)

ùíï ‚àà T

(cid:76)

(cid:77)

ùíï

Lemma C.8. Let V a symbolic value of ground type contain-
ing each sample variable ùõº1, . . . , ùõºùëõ at most once and [ùë•, ùë¶]
an interval. Then there is a countable set of pairwise disjoint
interval traces T ‚äÇ Iùëõ
(cid:216)
ùíï ‚àà T(cid:76)

‚ãê {ùíî ‚àà [0, 1]ùëõ | V [ùíî/ùõº] ‚àà [ùë•, ùë¶]}.

[0,1] such that

(cid:77)

ùíï

Proof. If V is of ground type, then it is simply a composi-
tion of primitive functions applied to sample variables and
literals. Since the set of primitive functions is closed un-
der composition and since no sample variable occurs twice,
this composition is still an interval separable function ùëì
of the sample variables. By definition of interval separabil-
ity, there is a countable set of interval traces J such that
(cid:208)
‚ñ°

‚ãê ùëì ‚àí1([ùë•, ùë¶]), as desired.

Lemma C.9. Let ùíï ‚àà Iùëõ be an interval trace and Œû a set of
symbolic values with sample variables from ùõº = ùõº1, . . . , ùõºùëõ.
Then for any ùúñ > 0, there is a countable subdivision T of ùíï
such that

ùíï ‚àà J

ùíï

(cid:76)

(cid:77)

(cid:214)

W [ùíî/ùõº] ‚àí ùúñ

‚àëÔ∏Å

ùíï ‚Ä≤ ‚àà T
‚à´

‚â§

vol(ùíï ‚Ä≤) sup
ùíï ‚Ä≤

ùíî ‚àà

(cid:214)

W ‚ààŒû

(cid:77)

(cid:76)
W [ùíî/ùõº] dùíî

ùíï
(cid:77)
(cid:76)
‚àëÔ∏Å

‚â§

(cid:214)

W ‚ààŒû
vol(ùíï ‚Ä≤) min
ùíï ‚Ä≤
(cid:77)
Proof. Values are simply boxwise continuous functions ap-
plied to the sample variables. Intersecting the boxes for each
W ‚àà Œû, we see that the function

W [ùíî/ùõº] + ùúñ.

W ‚ààŒû

ùíï ‚Ä≤ ‚àà T

ùíî ‚àà

(cid:76)

‚Üí R,

ùíî ‚Ü¶‚Üí

ùëì :

ùíï

(cid:76)

(cid:77)

(cid:214)

W ‚ààŒû

W [ùíî/ùõº]

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

(cid:77)

(cid:76)

(cid:77)

ùíï ‚Ä≤

ùíï ‚Ä≤

is boxwise continuous. We can thus find a countable subdi-
vision Tcont of ùíï such that ùëì is continuous on each ùíï ‚Ä≤ ‚àà Tcont.
Since we can sum over the ùíï ‚Ä≤ ‚àà Tcont, it suffices to prove
that each integral ‚à´
ùëì (ùíî) dùíî can be approximated arbitrar-
ily closely. Note that each such integral is finite because a
(cid:76)
continuous function is bounded on a compact set and the
measure of
is finite. But then such approximations are
given by Riemann sums, i.e. the sums that are used to de-
fine the Riemann integral. As a concrete example, one can
consider the subdivision Tùëö of ùíï ‚Ä≤ in ùëö equidistant sections
in each dimension (consisting of ùëöùëõ parts overall). Then
(cid:205)
ùëì (ùíî) converges to the Riemann in-
ùíï ‚Ä≤‚Ä≤ ‚ààTùëö
tegral ‚à´
ùëì (ùíî) dùíî as ùëö ‚Üí ‚àû (and similarly for the supre-
mum). Since it is known that the Riemann integral and the
(cid:76)
Lebesgue integral have the same value for continuous func-
tions on a Cartesian product of compact intervals, the claim
‚ñ°
follows immediately.

vol(ùíï ‚Ä≤‚Ä≤) minùíî ‚àà

ùíï ‚Ä≤‚Ä≤

ùíï ‚Ä≤

(cid:77)

(cid:76)

(cid:77)

Lemma C.10 (Relationship between symbolic execution and
interval semantics). Let Œ® = (V, ùëõ, Œî, Œû) be a symbolic path
‚äÜ Satùëõ (Œî). Suppose
of ùëÉ and ùíï an interval trace with
furthermore that all the symbolic values contain each of the
sample variables ùõº = ùõº1, . . . , ùõºùëõ at most once. Then there is
a subdivision T of ùíï such that for all ùíï ‚Ä≤ ‚àà T , the interval
semantics for the value is precise:

(cid:76)

(cid:77)

ùíï

val

I
ùëÉ (ùíï ‚Ä≤) = {valùëÉ (ùíî) | ùíî ‚àà

ùíï ‚Ä≤

}.

For each symbolic score value W ‚àà Œû, let [W‚àí

its interval approximation, i.e. W‚àí
W+

ùíï ‚Ä≤ = sup

ùíî ‚àà

ùíï ‚Ä≤

W [ùíî/ùõº]. Then
(cid:34)

(cid:76)

(cid:77)
I
ùëÉ (ùíï ‚Ä≤) =
wt

(cid:214)

W‚àí

ùíï ‚Ä≤ , (cid:214)

W+
ùíï ‚Ä≤

.

(cid:76)

ùíï ‚Ä≤

(cid:77)

(cid:35)

(cid:76)

(cid:77)
ùíï ‚Ä≤ = minùíî ‚àà

ùíï ‚Ä≤ , W+
ùíï ‚Ä≤ ] be
W [ùíî/ùõº] and

W ‚ààŒû

W ‚ààŒû

Proof. The symbolic value V is a composition of primitive
functions applied to ùõº‚Äôs. Hence the are boxwise continuous
functions of the ùõº‚Äôs. We pick a suitable subdivision T such
that all these functions are continuous when restricted to
any ùíï ‚Ä≤ ‚àà T . For any such function ùëì , we have

ùëìI([ùë•1, ùë¶1], . . . , [ùë•ùëö, ùë¶ùëö]) = [inf ùêπ, sup ùêπ ]
where ùêπ := ùëì ([ùë•1, ùë¶1] √ó ¬∑ ¬∑ ¬∑ √ó [ùë•ùëö, ùë¶ùëö]) ‚äÜ R, by definition.
Then continuity implies that the image of any box is a com-
pact and path-connected subset of R, i.e. an interval. Hence
we even have ùëìI([ùë•1, ùë¶1], . . . , [ùë•ùëö, ùë¶ùëö]) = ùêπ , i.e. the image of
any box equals its interval approximation, proving the claim
about the value semantics.

For the interval semantics of the weight, note that the
previous argument applies to every symbolic score value
W ‚àà Œû, proving that

{W [ùíî/ùõº] | ùíî ‚àà

ùíï ‚Ä≤
(cid:77)
Since the interval semantics multiplies the interval approxi-
mation of each score value in interval arithmetic, this implies
‚ñ°
the claim.

ùíï ‚Ä≤ , W+
ùíï ‚Ä≤ ].

} = [W‚àí

(cid:76)

Note that the interval approximation of the weight is im-

precise in the following sense:

I
ùëÉ (ùíï ‚Ä≤) ‚â†
wt

(cid:40)

(cid:214)

W ‚ààŒû

W [ùíî/ùõº]

(cid:41)

.

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

ùíî ‚àà

ùíï ‚Ä≤

(cid:76)

(cid:77)

As an example, if Œû = {ùõº1, 1 ‚àí ùõº1} and ùíï ‚Ä≤‚Ä≤ = ‚ü®[0, 1]‚ü© then
the left-hand side is [0, 1] because each of the weights is
approximated by [0, 1], but the right-hand side is [0, 1/4]
because the function ùõº1(1 ‚àí ùõº1) attains its maximum at 1/4,
not 1.

ùëÉ (ùíï ‚Ä≤) + ùúñ and sup

wtùëÉ (ùíî) ‚â§ min wtI

Lemma C.11. Let Œ® = (V, ùëõ, Œî, Œû) be a symbolic path of ùëÉ
‚äÜ Satùëõ (Œî). Suppose further-
and ùíï an interval trace with
ùíï
(cid:77)
(cid:76)
more that all the symbolic values contain each of the sample
variables ùõº = ùõº1, . . . , ùõºùëõ at most once. Then for all ùúñ > 0,
there is a subdivision T of ùíï such that for all ùíï ‚Ä≤ ‚àà T , we have
minùíî ‚àà
wtùëÉ (ùíî) ‚â•
ùíï ‚Ä≤
(cid:76)
(cid:77)
sup wtI
ùëÉ (ùíï ‚Ä≤) ‚àí ùúñ.
Proof. Since for each W ‚àà Œû, the function ùëì :
‚Üí R, ùíî ‚Ü¶‚Üí
W [ùíî/ùõº] is boxwise continuous (a property of primitive func-
tions), we can find a countable subdivision T ‚Ä≤ of ùíï, such that
. Hence it suffices to
for all ùíï ‚Ä≤ ‚àà T ‚Ä≤, ùëì is continuous on
prove the statement for each ùíï ‚Ä≤.

(cid:76)
is compact (because it‚Äôs closed and bounded),
ùëì attains a maximum ùëä < ‚àû on
and is even uniformly
ùíï ‚Ä≤
continuous on ùíï ‚Ä≤. Hence there is a ùõø > 0 such that whenever
||ùíî ‚àí ùíî ‚Ä≤|| < ùõø then |ùëì (ùíî) ‚àí ùëì (ùíî ‚Ä≤)| < ùúñ ‚Ä≤ :=

Since

ùíï ‚Ä≤

ùíï ‚Ä≤

ùíî ‚àà

ùíï ‚Ä≤

(cid:77)

(cid:76)

(cid:76)

(cid:77)

(cid:76)

(cid:77)

(cid:77)

ùíï

(cid:76)

(cid:77)

ùúñ
ùëä |Œû|‚àí1 .

:= minùíî ‚àà

Let T be a subdivision where each interval trace ùíï ‚àà
T has diameter less than ùõø. For ùíï ‚àà T and W ‚àà Œû, let
W [ùíî/ùõº]. By
W‚àí
ùíï
ùíï
ùíï + ùúñ ‚Ä≤ for ùíï ‚àà T . By
the choice of T , we have W+
(cid:76)
(cid:77)
(cid:77)
Lemma C.10, we find that sup wtI
ùëÉ (ùíï) = (cid:206)
and
W ‚ààŒû W+
ùíï
min wtI
ùëÉ (ùíï) = (cid:206)
. As a consequence, we have
W ‚ààŒû W‚àí
ùíï
I
I
ùëÉ (ùíï) ‚àí min wt
sup wt
ùëÉ (ùíï) =

W [ùíî/ùõº] and W+
ùíï
ùíï ‚â§ W‚àí

:= sup

W+

(cid:214)

(cid:214)

ùíî ‚àà

(cid:76)

ùíï

W‚àí
ùíï

ùíï ‚àí

W ‚ààŒû
< (cid:214)
W ‚ààŒû

W ‚ààŒû
ùíï + ùúñ ‚Ä≤) ‚àí

(W‚àí

(cid:214)

W ‚ààŒû

W‚àí
ùíï

< ùúñ ‚Ä≤ùëä |Œû |‚àí1 = ùúñ

So the interval wtI
interval {wtùëÉ (ùíî) | ùíî ‚àà
the claim follows.

ùëÉ (ùíï) has diameter less than ùúñ. Since the
} is contained in it (by soundness),
‚ñ°

ùíï ‚Ä≤

(cid:77)

(cid:76)

ùëÉ (ùêº ) =

Corollary 4.4. Let ùêº ‚àà I and ‚ä¢ ùëÉ : R be as in Theorem 4.3.
There is a sequence of finite, compatible sets of interval traces
T1, T2, . . . ‚äÜ TI s.t. limùëõ‚Üí‚àû lowerBdTùëõ
Proof. By Theorem 4.3, we can find for each ùëõ ‚àà N a set
of interval traces T ‚Ä≤
ùëõ such that lowerBd
(ùêº ) ‚àí
1/ùëõ. Since the lower bound is defined as a sum over T ‚Ä≤
ùëõ ,
there is a finite subset Tùëõ such that lowerBdTùëõ
(ùêº ) ‚àí
ùëõ is still compatible, the soundness result yields
2/ùëõ. Since T ‚Ä≤
lowerBdTùëõ
‚ñ°

(ùêº ), implying the claim.

T‚Ä≤
ùëÉ (ùêº ) >
ùëõ

(cid:75)
ùëÉ
(cid:74)

ùëÉ (ùêº ) >

ùëÉ
(cid:74)

ùëÉ
(cid:74)

(ùêº ).

ùëÉ (ùêº ) ‚â§

(cid:75)

(cid:75)

ùëÉ
(cid:74)

(cid:75)

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Finitely many interval traces are not enough for complete
upper bounds, if the weight function is unbounded. This
issue arises even if we can compute the tightest possible
bounds on the weight function, as the following program
illustrates.

Example C.3. Consider the following probabilistic program
expressed in pseudocode.
threshold := 1
while (sample ‚â§ threshold) do

threshold := threshold
score(2)

2

The program only requires addition and scalar multiplica-
tion. It can even be implemented using call-by-name (CbN)
semantics (which allows each sampled value to be used at
most once). For example in SPCF we can write

ùëÉ ‚â° (cid:0)ùúáùúë

ùë† . if (sample ‚àí ùë†, score(2); ùúë (ùë†/2), 1)(cid:1) 1

The program ùëÉ has the weight function

wtùëÉ (‚ü®ùë°0, . . . , ùë°ùëõ‚ü©) =

2ùëõ

if ùë°ùëõ > 2‚àíùëõ‚àß

‚àÄùëñ ‚àà {0, . . . , ùëõ ‚àí 1} : ùë°ùëñ ‚â§ 2‚àíùëñ

0

otherwise.

Ô£±Ô£¥Ô£¥Ô£¥Ô£≤
Ô£¥Ô£¥Ô£¥
Ô£≥

ùëÉ is integrable because the normalizing constant is

ùëç =

‚à´

T

wtùëÉ (ùíî) dùíî =

‚àû
‚àëÔ∏Å

ùëõ=1

2ùëõ √ó (1 ‚àí 2‚àíùëõ)

ùëõ‚àí1
(cid:214)

ùëñ=0

2‚àíùëñ

=

‚àû
‚àëÔ∏Å

ùëõ=1

2ùëõ (1 ‚àí 2‚àíùëõ)2‚àíùëõ (ùëõ‚àí1)/2 < ‚àû.

We claim that ùëÉ requires infinitely many interval traces for
the upper bound to converge to the true denotation. Define
the sets of traces ùëáùëõ for ùëõ ‚â• 1 by

ùëáùëõ = [0, 20] √ó [0, 2‚àí1] √ó ¬∑ ¬∑ ¬∑ √ó [0, 2‚àíùëõ+1] √ó (2‚àíùëõ, 1].
Suppose we are given an arbitrary finite exhaustive set of
interval traces. This set needs to cover all of the ùëáùëõ‚Äôs, so
one interval trace, say ùíï, must cover infinitely many ùëáùëõ‚Äôs.
Since wtùëÉ (ùíî) = 2ùëõ for ùíî ‚àà ùëáùëõ, the weight function on ùíï is
unbounded. Therefore, the only possible upper bound for ùíï
is ‚àû, even if our semantics could compute the set {wtùëÉ (ùíî) |
} exactly. Hence any finite exhaustive interval trace
ùíî ‚àà
has upper bound ‚àû, while the true denotation is finite. As
we have seen, this is not because of imprecision of interval
analysis, but an inherent problem if the weight function is
unbounded. So we cannot hope for complete upper bounds
with finitely many interval traces.

(cid:76)

(cid:77)

ùíï

D Supplementary Material for Section 5
We provide additional proofs and material for Section 5. To
have access to named rules, we give the type system in Fig. 9
which agrees with the one in Fig. 4 in everything but the
labels.

D.1 Soundness
To show soundness (Theorem 5.1), we establish a (weight-
aware) subject reduction property for our type system as
follows. For an interval [ùëé, ùëè] ‚àà I and ùëü ‚àà R‚â•0, we define
ùëü ¬∑ [ùëé, ùëè] := [ùëü ¬∑ ùëé, ùëü ¬∑ ùëè]. To simplify notation, we use a
modified transition relation that omits the concrete trace
(which is irrelevant in Theorem 5.1). We write ùëÉ ‚Üíùë§ ùëÉ ‚Ä≤ if
(ùëÉ, ùíî, 1) ‚Üí (ùëÉ ‚Ä≤, ùíî ‚Ä≤, ùë§) for some ùë§ ‚àà R and ùíî, ùíî ‚Ä≤ ‚àà T. Note
that we could define ‚Üíùë§ as a dedicated reduction system by
adapting the rules from ‚Üí in Fig. 2.

ùëñ=1 : A.

: ùúéùëñ }ùëõ
ùëñ=1 ‚ä¢ ùëÉ : A for
(cid:27)
for all ùëñ ‚àà {1, . . . , ùëõ}

Lemma D.1 (Substitution). If Œì; {ùë•ùëñ
(cid:26)ùúéùëñ
distinct variables ùë•ùëñ and if Œì ‚ä¢ ùëÄùëñ :
1
then Œì ‚ä¢ ùëÉ [ùëÄùëñ /ùë•ùëñ ]ùëõ
Proof. By a standard induction on ùëÄ.
Lemma D.2 (Weighted Subject Reduction). Let ùëÉ be any
and ùëÉ ‚Üíùë§ ùëÉ ‚Ä≤ for some ùë§ > 0.
program such that ‚ä¢ ùëÉ :
(cid:26) ùúé
1
ùë§ ¬∑ ùêΩ

Then ‚ä¢ ùëÉ ‚Ä≤ :

(cid:26)ùúé
ùêΩ

‚ñ°

(cid:27)

(cid:27)

.

Proof. We prove this by induction on the structure of ùëÉ.

Case ùëÉ = sample: then ùëÉ ‚Üí1 ùëü for some ùëü ‚àà [0, 1]. As
multiple consecutive application of (Sub) can be replaced
by a single one since (as ‚äëA is transitive), we can assume
w.l.o.g. that the last step in ‚ä¢ ùëÉ :

was:

(cid:27)

(cid:26)ùúé
ùêΩ

(Sample)

(cid:27)

(Sub)

‚ä¢ sample :

‚ä¢ sample :

(cid:26)[0, 1]
1
(cid:26)ùêº
ùêΩ

(cid:27)

By subtyping we have [0, 1] ‚äë ùêº and 1 ‚äë ùêΩ . So [ùëü, ùëü ] ‚äë ùêº and
we can type ‚ä¢ ùëü :

using (Lit) and (Sub) as required.

(cid:27)

(cid:26)ùêº
ùêΩ

Case ùëÉ = ùëì (ùëü1, . . . , ùëü |ùëì |): then ùëÉ ‚Üí1 ùëì (ùëü1, . . . , ùëü |ùëì |). W.l.o.g.,

we can assume that the last step in ‚ä¢ ùëÉ :

(cid:27)

(cid:26)ùúé
ùêΩ

was

‚ä¢ ùëü1 :

‚ä¢ ùëü1 :

(Lit)

(cid:27)

(Sub)

¬∑ ¬∑ ¬∑

(cid:26)[ùëü1, ùëü1]
1
(cid:26)ùêº1
ùêΩ1

(cid:27)

‚ä¢ ùëì (ùëü1, . . . , ùëü |ùëì |) :

(Lit)

(cid:27)

(Sub)

(Prim)

(cid:26)[ùëü |ùëì |, ùëü |ùëì |]
1
(cid:26)ùêº |ùëì |
ùêΩ |ùëì |

(cid:27)

(cid:27)

(Sub)

‚ä¢ ùëü |ùëì | :

‚ä¢ ùëü |ùëì | :

(cid:26)ùëì I(ùêº1, . . . , ùêº |ùëì |)
(√óI) |ùëì |
ùëñ=1ùêΩùëñ
(cid:26)ùêº
(cid:27)
ùêΩ

‚ä¢ ùëì (ùëü1, . . . , ùëü |ùëì |) :

So by subtyping ùëüùëñ ‚àà ùêºùëñ and 1 ‚àà ùêΩùëñ for all ùëñ. By definition of
ùëì I we thus have ùëì (ùëü1, . . . , ùëü |ùëì |) ‚àà ùëì I (ùêº1, . . . , ùêº |ùëì |) and (again
by subtyping) we have ùëì (ùëü1, . . . , ùëü |ùëì |) ‚àà ùêº . Similarly, by def-
inition of √óI we have 1 ‚àà (√óI) |ùëì |
ùëñ=1ùêΩùëñ and thus 1 ‚àà ùêΩ . We can
using (Lit) and (Sub) as required.
type ‚ä¢ ùëì (ùëü1, . . . , ùëü |ùëì |) :
Case ùëÉ = if (ùëü, ùëÄ, ùëÅ ) and ùëü ‚â§ 0: then ùëÉ ‚Üí1 ùëÄ. W.l.o.g.,

(cid:26)ùêº
ùêΩ

(cid:27)

we can assume that the last step in ‚ä¢ ùëÉ :

(cid:27)

(cid:26)ùúé
ùêΩ

is

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

(Var)

ùë• : ùúé ‚àà Œì
(cid:26)ùúé
1

Œì ‚ä¢ ùë• :

(cid:27)

Œì ‚ä¢ ùëÄ : A A ‚äëA B
Œì ‚ä¢ ùëÄ : B

(Sub)

(Sample)

Œì ‚ä¢ sample :

(cid:27)

(cid:26)[0, 1]
1

(Lit)

Œì ‚ä¢ ùëü :

(cid:27)

(cid:26)[ùëü, ùëü ]
1

Œì ‚ä¢ ùúÜùë• .ùëÄ :

(cid:27)

Œì; ùë• : ùúé ‚ä¢ ùëÄ : A (Abs)
(cid:26)ùúé ‚Üí A
1
(cid:26) ùúé2
[ùëí, ùëì ]

ùúé1 ‚Üí

(cid:27)

Œì ‚ä¢ ùëÄ :

Ô£±Ô£¥Ô£¥Ô£≤
Ô£¥Ô£¥
Ô£≥
Œì ‚ä¢ ùëÄùëÅ :

[ùëé, ùëè]
(cid:26)

Ô£ºÔ£¥Ô£¥Ô£Ω
Ô£¥Ô£¥
Ô£æ

Œì; ùúë : ùúé ‚Üí A; ùë• : ùúé ‚ä¢ ùëÄ : A

Œì ‚ä¢ ùúáùúë

ùë• . ùëÄ :

(cid:27)

(cid:26)ùúé ‚Üí A
1

(Fix)

Œì ‚ä¢ ùëÅ :

(cid:27)

(cid:26) ùúé1
[ùëê, ùëë]

Œì ‚ä¢ ùëÄ :

(cid:27)

(cid:26)[_, _]
[ùëé, ùëè]

ùúé2
[ùëé, ùëè] √óI [ùëê, ùëë] √óI [ùëí, ùëì ]
(cid:26) ùúé
[ùëê, ùëë]

Œì ‚ä¢ ùëÅ :

(cid:27)

Œì ‚ä¢ ùëÉ :

(App)

(cid:27)

(cid:27)

(cid:26) ùúé
[ùëê, ùëë]

(If)

Œì ‚ä¢ if(ùëÄ, ùëÅ , ùëÉ) :

(cid:26)

ùúé
[ùëé, ùëè] √óI [ùëê, ùëë]

(cid:27)

Œì ‚ä¢ ùëÄ :

(cid:27)

(cid:26)[ùëé, ùëè]
[ùëê, ùëë]
[ùëé, ùëè] ‚äì [0, ‚àû]
[ùëê, ùëë] √óI (cid:0)[ùëé, ùëè] ‚äì [0, ‚àû](cid:1)

Œì ‚ä¢ score(ùëÄ) :

(cid:26)

(Score)

(cid:27)

Œì ‚ä¢ ùëÄ1 :

(cid:27)

(cid:26)[ùëé1, ùëè1]
[ùëê1, ùëë1]

Œì ‚ä¢ ùëì (ùëÄ1, . . . , ùëÄ |ùëì |) :

¬∑ ¬∑ ¬∑

(cid:26)[ùëé |ùëì |, ùëè |ùëì |]
Œì ‚ä¢ ùëÄ |ùëì | :
[ùëê |ùëì |, ùëë |ùëì |]
(cid:41)
(cid:40)ùëì I ([ùëé1, ùëè1], . . . , [ùëé |ùëì |, ùëè |ùëì |])

(√óI) |ùëì |

ùëñ=1 [ùëêùëñ, ùëëùëñ ]

(cid:27)

(Prim)

Figure 9. Weight-aware interval type system for SPCF with typing rule names. The rules agree with those in Fig. 4.

(cid:26)[ùëü, ùëü ]
1
(cid:26) ùêº
ùêΩ ‚Ä≤‚Ä≤

(cid:27)

(Lit)

(cid:27)

(Sub)

‚ä¢ ùëÄ :

(cid:27)

(cid:26)ùúé ‚Ä≤
ùêΩ ‚Ä≤

‚ä¢ ùëÅ :

(cid:27)

(cid:26)ùúé ‚Ä≤
ùêΩ ‚Ä≤

‚ä¢ ùëü :

‚ä¢ ùëü :

‚ä¢ if (ùëü, ùëÄ, ùëÅ ) :

(cid:26)

‚ä¢ if (ùëü, ùëÄ, ùëÅ ) :

(cid:27)

(Sub)

ùúé ‚Ä≤
ùêΩ ‚Ä≤ √óI ùêΩ ‚Ä≤‚Ä≤
(cid:27)
(cid:26)ùúé
ùêΩ

(If)

and we have 1 ‚àà ùêΩ ‚Ä≤‚Ä≤, ùúé ‚Ä≤ ‚äëùúé ùúé and ùêΩ ‚Ä≤ √óI ùêΩ ‚Ä≤‚Ä≤ ‚äë ùêΩ by subtyping.
As 1 ‚àà ùêΩ ‚Ä≤‚Ä≤, we get ùêΩ ‚Ä≤ ‚äë ùêΩ ‚Ä≤ √óI ùêΩ ‚Ä≤‚Ä≤. Thus we obtain ùêΩ ‚Ä≤ ‚äë ùêΩ and
ùúé ‚Ä≤ ‚äëùúé ùúé, and we can type ‚ä¢ ùëÄ :

using (Sub).

(cid:27)

(cid:26)ùúé
ùêΩ

Case ùëÉ = if (ùëü, ùëÄ, ùëÅ ) and ùëü > 0: then ùëÉ ‚Üí1 ùëÅ . Analogous

to the previous case.

Case ùëÉ = score(ùëü ) and ùëü ‚â• 0: then ùëÉ ‚Üíùëü ùëü . W.l.o.g., we

can assume that the last step in ‚ä¢ ùëÉ :

(cid:27)

(cid:26)ùúé
ùêΩ

is

(Lit)

(cid:27)

(Sub)

‚ä¢ ùëü :

‚ä¢ ùëü :

(cid:26)[ùëü, ùëü ]
1
(cid:26)ùêº ‚Ä≤
ùêΩ ‚Ä≤

(cid:27)

‚ä¢ score(ùëü ) :

(cid:26)

ùêº ‚Ä≤ ‚äì [0, ‚àû]
ùêΩ ‚Ä≤ √óI (ùêº ‚Ä≤ ‚äì [0, ‚àû])
(cid:27)
(cid:26)ùêº
ùêΩ

‚ä¢ score(ùëü ) :

(Score)

(cid:27)

(Sub)

By subtyping we have ùëü ‚àà ùêº ‚Ä≤ and even ùëü ‚àà ùêº ‚Ä≤ ‚äì [0, ‚àû] because
ùëü ‚â• 0. Thus ùëü ‚àà ùêº , again by subtyping. Similarly, 1 ‚àà ùêΩ ‚Ä≤ and
by definition of √óI, we have ùëü ‚àà ùêΩ ‚Ä≤ √óI (ùêº ‚Ä≤ ‚äì [0, ‚àû]). Thus
ùëü ‚àà ùêΩ by subtyping. This already implies 1 ‚àà 1
ùëü ¬∑ ùêΩ and we
(cid:27)
can thus type ‚ä¢ ùëü :

by using (Lit) and (Sub).

(cid:26) ùêº
1
ùëü ¬∑ ùêΩ

Case ùëÉ = (ùúÜùë• .ùëÄ)ùëâ : then ùëÉ ‚Üí1 ùëÄ [ùëâ /ùë•]. W.l.o.g., the last

step in ‚ä¢ ùëÉ :

(cid:27)

(cid:26)ùúé
ùêΩ

is

{ùë• : Àúùúé ‚Ä≤} ‚ä¢ ùëÄ :

(cid:27)

(cid:26) Àúùúé ‚Ä≤‚Ä≤
ÀúùêΩ ‚Ä≤‚Ä≤

‚ä¢ ùúÜùë• .ùëÄ :

‚ä¢ ùúÜùë• .ùëÄ :

(cid:27)

(cid:41)

(cid:26) Àúùúé ‚Ä≤‚Ä≤
ÀúùêΩ ‚Ä≤‚Ä≤

(cid:27)

(cid:41)

(cid:26)ùúé ‚Ä≤‚Ä≤
ùêΩ ‚Ä≤‚Ä≤

(cid:40) Àúùúé ‚Ä≤ ‚Üí
1
(cid:40)ùúé ‚Ä≤ ‚Üí
ùêΩ ‚Ä≤

‚ä¢ (ùúÜùë• .ùëÄ)ùëâ :

(cid:26)

(Abs)

(Sub)

‚ä¢ ùëâ :

(cid:27)

(cid:26) ùúé ‚Ä≤
ùêΩ ‚Ä≤‚Ä≤‚Ä≤

ùúé ‚Ä≤‚Ä≤
ùêΩ ‚Ä≤ √óI ùêΩ ‚Ä≤‚Ä≤ √óI ùêΩ ‚Ä≤‚Ä≤‚Ä≤
(cid:27)
(cid:26)ùúé
ùêΩ

‚ä¢ (ùúÜùë• .ùëÄ)ùëâ :

(App)

(cid:27)

(Sub)

By subtyping we get that ùúé ‚Ä≤ ‚äëùúé Àúùúé ‚Ä≤. It is easy to see that we
because ùëâ is a value and we get
can also type ‚ä¢ ùëâ :
(cid:27)

by (Sub). Using Lemma D.1, we can thus type

(cid:26)ùúé ‚Ä≤
1

(cid:27)

‚ä¢ ùëâ :

(cid:26) Àúùúé ‚Ä≤
1

‚ä¢ ùëÄ [ùëâ /ùë•] :

(cid:27)

.

(cid:26) Àúùúé ‚Ä≤‚Ä≤
ÀúùêΩ ‚Ä≤‚Ä≤

We have 1 ‚àà ùêΩ ‚Ä≤ by subyptying and as ùëâ is a value, it
is easy to see that 1 ‚àà ùêΩ ‚Ä≤‚Ä≤‚Ä≤. Hence ùêΩ ‚Ä≤‚Ä≤ ‚äë ùêΩ ‚Ä≤ √óI ùêΩ ‚Ä≤‚Ä≤ √óI ùêΩ ‚Ä≤‚Ä≤‚Ä≤.
Also by subtyping, we find Àúùúé ‚Ä≤‚Ä≤ ‚äëùúé ùúé ‚Ä≤‚Ä≤ ‚äëùúé ùúé, ÀúùêΩ ‚Ä≤‚Ä≤ ‚äë ùêΩ ‚Ä≤‚Ä≤, and
ùêΩ ‚Ä≤ √óI ùêΩ ‚Ä≤‚Ä≤ √óI ùêΩ ‚Ä≤‚Ä≤‚Ä≤ ‚äë ùêΩ . This implies Àúùúé ‚Ä≤‚Ä≤ ‚äëùúé ùúé and ÀúùêΩ ‚Ä≤‚Ä≤ ‚äë ùêΩ . By
subtyping ‚ä¢ ùëÄ [ùëâ /ùë•] :

, as required.

(cid:27)

(cid:26)ùúé
ùêΩ

Case ùëÉ = (ùúáùúë

ùë• .ùëÄ)ùëâ : then ùëÉ ‚Üí1 ùëÄ [ùëâ /ùë•, (ùúáùúë

ùë• .ùëÄ)/ùúë]. Anal-

ogous to the previous case for abstractions.

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Case ùëÉ = ùê∏ [ùëÉ ‚Ä≤] for an evaluation context ùê∏ ‚â† [¬∑]: then
ùëÉ ‚Ä≤ ‚Üíùëü ùëÉ ‚Ä≤‚Ä≤ and ùëÉ ‚Üíùëü ùê∏ [ùëÉ ‚Ä≤‚Ä≤]. All such cases follow easily
by case analysis on ùê∏. As an example, consider the context
ùê∏ = [¬∑]ùëÅ . In this situation, we have ùëÉ = ùê∏ [ùëÉ ‚Ä≤] = ùëÉ ‚Ä≤ùëÅ with
(cid:27)
(cid:26)ùúé
ùëÉ ‚Ä≤ ‚Üíùëü ùëÉ ‚Ä≤‚Ä≤, so ùëÉ ‚Üíùëü ùëÉ ‚Ä≤‚Ä≤ùëÅ . W.l.o.g., the last step in ‚ä¢ ùëÉ :
ùêΩ
is

‚ä¢ ùëÉ ‚Ä≤ :

(cid:27)

(cid:41)

(cid:26)ùúé ‚Ä≤‚Ä≤
ùêΩ ‚Ä≤‚Ä≤

(cid:40)ùúé ‚Ä≤ ‚Üí
ùêΩ ‚Ä≤

‚ä¢ ùëÅ :

(cid:27)

(cid:26) ùúé ‚Ä≤
ùêΩ ‚Ä≤‚Ä≤‚Ä≤

(cid:26)

‚ä¢ ùëÉ ‚Ä≤ùëÅ :

ùúé ‚Ä≤‚Ä≤
ùêΩ ‚Ä≤ √óI ùêΩ ‚Ä≤‚Ä≤ √óI ùêΩ ‚Ä≤‚Ä≤‚Ä≤
(cid:27)
(cid:26)ùúé
ùêΩ

‚ä¢ ùëÉ ‚Ä≤ùëÅ :

(App)

(cid:27)

(Sub)

By the inductive assumption for ùëÉ ‚Ä≤ ‚Üíùëü ùëÉ ‚Ä≤‚Ä≤, we get ‚ä¢ ùëÉ ‚Ä≤‚Ä≤ :
(cid:40)ùúé ‚Ä≤ ‚Üí

(cid:41)

(cid:27)

and can then type

(cid:26)ùúé ‚Ä≤‚Ä≤
ùêΩ ‚Ä≤‚Ä≤
1
ùëü ¬∑ ùêΩ ‚Ä≤

‚ä¢ ùëÉ ‚Ä≤‚Ä≤ :

(cid:40)ùúé ‚Ä≤ ‚Üí

(cid:26)ùúé ‚Ä≤‚Ä≤
ùêΩ ‚Ä≤‚Ä≤
1
ùëü ¬∑ ùêΩ ‚Ä≤
(cid:26)

‚ä¢ ùëÉ ‚Ä≤ùëÅ :

(cid:27)

(cid:41)

‚ä¢ ùëÅ :

(cid:27)

(cid:26) ùúé ‚Ä≤
ùêΩ ‚Ä≤‚Ä≤‚Ä≤

(App)

(cid:27)

(Sub)

ùúé ‚Ä≤‚Ä≤
1
ùëü ¬∑ ùêΩ ‚Ä≤ √óI ùêΩ ‚Ä≤‚Ä≤ √óI ùêΩ ‚Ä≤‚Ä≤‚Ä≤
(cid:26) ùúé
1
ùëü ¬∑ ùêΩ

(cid:27)

‚ä¢ ùëÉ ‚Ä≤ùëÅ :

because if ùêΩ ‚Ä≤ √óI ùêΩ ‚Ä≤‚Ä≤ √óI ùêΩ ‚Ä≤‚Ä≤‚Ä≤ ‚äë ùêΩ then 1

ùëü ¬∑ ùêΩ .
The proof for the other evaluation contexts, i.e., where ùëÉ =
if (ùëÉ ‚Ä≤, ùëÄ, ùëÅ ), ùëÉ = ùëâ ùëÉ ‚Ä≤, ùëÉ = score(ùëÉ ‚Ä≤), or ùëÉ = ùëì (ùëü1, . . . , ùëüùëñ‚àí1,
ùëÉ ‚Ä≤, ùëÅùëñ+1, . . . , ùëÅ |ùëì |) for some ùëÉ ‚Ä≤ ‚Üíùëü ùëÉ ‚Ä≤‚Ä≤, are all analogous to
‚ñ°
the above.

ùëü ¬∑ ùêΩ ‚Ä≤ √óI ùêΩ ‚Ä≤‚Ä≤ √óI ùêΩ ‚Ä≤‚Ä≤‚Ä≤ ‚äë 1

Lemma D.3 (Zero-Weighted Subject Reduction). Let ùëÉ be
(cid:27)
(cid:26)ùúé
any program such that ‚ä¢ ùëÉ :
ùêΩ
(cid:27)
(cid:26) ùúé
ùêΩ ‚Ä≤

and ùëÉ ‚Üí0 ùëÉ ‚Ä≤. Then

for some ùêΩ ‚Ä≤, and

1. ‚ä¢ ùëÉ ‚Ä≤ :
2. 0 ‚àà ùêΩ

(cid:27)

for some ùêΩ ‚Ä≤ is analogous to

(cid:26) ùúé
Proof. The proof that ‚ä¢ ùëÉ ‚Ä≤ :
ùêΩ ‚Ä≤
the proof of Lemma D.2 with fewer restrictions on the weight.
The claim 0 ‚àà ùêΩ follows by observing that ùëÉ ‚Üí0 ùëÉ ‚Ä≤ is only
possible if the redex in ùëÉ is score(0). In case ùëÉ = score(0),
the claim follows directly from (Score). If ùëÉ = ùê∏ [score(0)],
it is a simple induction on the structure of the evaluation
‚ñ°
context ùê∏.

(cid:27)

Theorem 5.1. Let ‚ä¢ ùëÉ : R be a simply-typed program. If
‚ä¢ ùëÉ : (cid:26)[ùëé, ùëè]
and (ùëÉ, ùíî, 1) ‚Üí‚àó (ùëü, ‚ü®‚ü©, ùë§) for some ùíî ‚àà T and
[ùëê, ùëë]
ùëü, ùë§ ‚àà R, then ùëü ‚àà [ùëé, ùëè] and ùë§ ‚àà [ùëê, ùëë].
Proof. Let

(ùëÉ, ùíî, 1) = (ùëÉ0, ùíî0, ùë§0) ‚Üí ¬∑ ¬∑ ¬∑ ‚Üí (ùëÉùëõ, ùíîùëõ, ùë§ùëõ) = (ùëü, ‚ü®‚ü©, ùë§)
be the reduction sequence of (ùëÉ, ùíî, 1). By definition of ‚Üíùë§ it
is easy to see that we get

ùëÉ = ùëÉ0 ‚Üí Àúùë§1 ùëÉ1 ‚Üí Àúùë§2 ¬∑ ¬∑ ¬∑ ‚Üí Àúùë§ùëõ ùëÉùëõ = ùëü

for unique Àúùë§1, . . . , Àúùë§ùëõ. Note that ùë§ùëñ = (cid:206)ùëñ

ùëó=1 Àúùë§ ùëó .

We first assume that ùë§ ‚â† 0 (so Àúùë§ùëñ ‚â† 0 for all ùëñ). We claim

that for each 0 ‚â§ ùëñ ‚â§ ùëõ, we can type
[ùëé, ùëè]
¬∑ [ùëê, ùëë]

‚ä¢ ùëÉùëñ :

(cid:26)

(cid:27)

1
ùë§ùëñ
Equation (7) follows by simple induction: the base case ùëñ = 0
and because ùë§0 = 1.
holds by the assumption ‚ä¢ ùëÉ0 :
[ùëé, ùëè]
¬∑ [ùëê, ùëë]

For the inductive case, we assume that ‚ä¢ ùëÉùëñ :
. We
apply Lemma D.2 to ùëÉùëñ ‚Üí Àúùë§ùëñ ùëÉùëñ+1 and finish the induction
step using ùë§ùëñ+1 = ùë§ùëñ Àúùë§ùëñ+1:

(cid:26)[ùëé, ùëè]
[ùëê, ùëë]

1
ùë§ùëñ

(cid:26)

(cid:27)

(cid:27)

(7)

‚ä¢ ùëÉùëñ+1 :

(cid:26)

[ùëé, ùëè]
¬∑ 1
ùë§ùëñ

¬∑ [ùëê, ùëë]

1
Àúùë§ùëñ+1

Equation (7) thus implies ‚ä¢ ùëü :

[ùëé, ùëè]

(cid:27)

¬∑ [ùëê, ùëë]

(cid:27)

(cid:26)

=

1
ùë§ùëñ+1
(cid:26) [ùëé, ùëè]
1
ùë§ ¬∑ [ùëê, ùëë]

assume that this type judgment has the form

(cid:27)

. W.l.o.g., we can

(Const)

(cid:27)

‚ä¢ ùëü :

(cid:26)[ùëü, ùëü ]
1
(cid:26) [ùëé, ùëè]
1
ùë§ ¬∑ [ùëê, ùëë]
This implies ùëü ‚àà [ùëé, ùëè] and ùë§ ‚àà [ùëê, ùëë] (because 1 ‚àà 1

‚ä¢ ùëü :

(Sub)

(cid:27)

ùë§ ¬∑

[ùëê, ùëë]), as required.

Now consider the case ùë§ = 0, so at least one Àúùë§ùëñ = 0.
The claim that ùëü ‚àà [ùëé, ùëè] follows easily as above (now using
Item 1 of Lemma D.3 to handle the weight 0 reduction steps).
Let ùëñ‚àó be the smallest index such that Àúùë§ùëñ‚àó = 0. Using the
same argument as above on the (possibly empty) prefix up
to index ùëñ‚àó ‚àí 1 (where all Àúùë§ ùëó are non-zero) we find

(cid:26)

[ùëé, ùëè]

(cid:27)

‚ä¢ ùëÉùëñ‚àó‚àí1 :

1
ùë§ùëñ‚àó‚àí1
Note that this is well defined because Àúùë§ ùëó > 0 for ùëó < ùëñ‚àó.
¬∑ [ùëê, ùëë], which already
Item 2 of Lemma D.3 shows 0 ‚àà
‚ñ°
implies ùë§ = 0 ‚àà [ùëê, ùëë], as required.

¬∑ [ùëê, ùëë]

1
ùë§ùëñ‚àó‚àí1

D.2 Weak Completeness
Proposition 5.2. Let ‚ä¢ ùëÉ : ùõº be a simply-typed program.
There exists a weighted interval type A such that ‚ä¢ ùëÉ : A.
Proof. For every simple type ùõº, we define a weighted type
Aùõº and weightless type ùúéùõº by mutual recursion as follows.
ùúéR := [‚àí‚àû, ‚àû]
ùúéùõº‚ÜíùõΩ := ùúéùõº ‚Üí AùõΩ

Aùõº :=

(cid:27)

(cid:26) ùúéùõº
[0, ‚àû]

That is, we insert [‚àí‚àû, ‚àû] for values and [0, ‚àû] for weights
in all locations. We claim that if ‚ä¢ ùëÉ : ùõº in the simple type
system, then ‚ä¢ ùëÉ : Aùõº in the weight-aware interval type
system.

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

For the proof, we strengthen the induction hypothesis
by claiming: if Œì ‚ä¢ ùëÉ : ùõº in the simple type system then
Œì‚Üëùúé ‚ä¢ ùëÉ : Aùõº where

Œì‚Üëùúé := {ùë• : ùúéùõº | ùë• : ùõº ‚àà Œì}.
The claim can be proved by simple induction on the deriva-
tion of Œì ‚ä¢ ùëÉ : ùõº using the respective typing rule for the
interval type system possibly followed by (Sub) for typing
rules that yield proper subtypes of Aùõº .

Note that this typing derivation does not contain any
‚ñ°

useful information to improve the precision of GuBPI.

D.3 Constraint-based Type Inference
In this section we formalize the constraint-based type infer-
ence algorithm and sketch our constraints-solving method
based on worklist and widening. The overarching idea is
to substitute intervals with variables ùúàùëñ , called interval vari-
ables, and to encode typability as a constraint system. As
we work in the restricted interval domain (as opposed to
e.g. full first-order refinements), the resulting constraints
can be solved very efficiently, which is crucial to the practi-
cality of our tool.

Symbolic types. Symbolic types are defined by the fol-

lowing grammar:

ùúÖ := ùúàùëñ | ùúÖ ‚Üí ùíú

ùíú :=

(cid:27)

(cid:26) ùúÖ
ùúà ùëó

where ùúàùëñ, ùúà ùëó are interval variables. Symbolic types are iden-
tical to interval types but use interval variables instead of
intervals as first-order types and in the weight bound.

Constraints. Constraints on interval variables come in

three forms:

ùëê := ùúàùëõ ‚â° [ùëé, ùëè]

(cid:12)
(cid:12)
(cid:12)

ùúÖ1 ‚äë ùúÖ2

(cid:12)
(cid:12)
(cid:12)

ùúàùëõ ‚â° ùëì (ùúàùëõ1, . . . , ùúàùëõ|ùëì | )

where ùëì is a primitive function and [ùëé, ùëè] an interval. That
is, a constraint can either equate an interval variable to a
particular interval, require a symbolic type ùúÖ1 to be a sub-
type of a type ùúÖ2, or equate an interval variable to the result
of a function applied to interval variables. Note that due to
the compositional nature of our subtype relation ‚äë (which
extends to symbolic types) we can restrict ourself to con-
straints of the form ùúà1 ‚äë ùúà2 because each constraint of the
form ùúÖ1 ‚äë ùúÖ2 or ùíú1 ‚äë ùíú2 (with identical base types) can
be reduced to an equivalent set of constraints on interval
variables by the definition of the subtype relation.

Symbolic type system. In the presentation of our sym-
bolic type inference system, we aim to stay as close as possi-
ble to the implementation. Thus we describe it as an impure
type system, meaning that our typing rules have side effects.
In our case, typing rules can generate fresh interval variables.
For a simple type ùõº, we write fresh(ùõº) for the symbolic
weightless type obtained by replacing every base type R
with a fresh interval variable ùúàùëõ (and adding weights given

by fresh interval variables where needed). We write fresh()
for fresh(R). For a symbolic type ùúÖ we write base(ùúÖ) for the
underlying simple type (defined in the obvious way).

Our constraint generation system is given in Fig. 10. Judg-
ments have the form Œì ‚ä¢ ùëÄ : ùíú, C where Œì maps variables
to weightless symbolic types, ùíú is a weighted symbolic type
and C a list of constraints on the interval variables. The
rules follow the structure of the system in Fig. 4 but replace
all operations on intervals with interval variables and con-
straints. The term structure directly determines the symbolic
typing derivation; there are no choices to be made, contrary
to Fig. 4, which requires ‚Äúcleverness‚Äù, for example to find a
suitable interval for an argument in the fixpoint rule. Note
that in our system, we assume that the simple types of argu-
ments of abstractions and fixpoints are given. These types
can be determined by a simple prior run of any standard
type inference algorithm.

From symbolic to concrete types. An assignment ùê¥ is a
mapping from interval variables to concrete intervals. Given
a symbolic type ùúÖ, we define the interval type ùúÖùê¥ by replac-
ing every interval variable in ùúÖ with the concrete interval
assigned to it in ùê¥. For a weighted symbolic type ùíú, we
define ùíúùê¥ in the same way. Given a set of constraints C, we
say that ùê¥ satisfies C, written ùê¥ |= C if all constraints in C
are satisfied (defined in the obvious way).

Theorem D.4. If ‚ä¢ ùëÄ : ùíú, C and ùê¥ |= C then ‚ä¢ ùëÄ : ùíúùê¥.
Proof. This can be shown by induction on the structure of
the term, which also determines the symbolic typing deriva-
tion. From this, we obtain a valid interval typing derivation
by replacing interval variables in the derivation with the
concrete intervals assigned to them in ùê¥, and by applying
the (Sub) rule in places where subtyping constraints are
‚ñ°
introduced.

This theorem states that solutions to our constraints di-
rectly give us valid judgments in our interval type system,
which allows us to invoke Theorem 5.1.

Solving Constraints. To solve the resulting constraints,
we employ known techniques from abstract interpretation
[14]. Again, note that due to the simplicity of our constraints,
our approach avoids expensive calls to a theorem prover.
When solving a set of constraints C, we are interested in the
smallest solution, i.e. an assignment ùê¥ with ùê¥ |= C where
the intervals in A are smallest possible w.r.t. ‚äë.

Na√Øve algorithm. A na√Øve attempt to find a satisfying
assignment for a set of constraints would be to iterate over
the constraints and to extend the current assignment (ini-
tially chosen to map all elements to the bottom element
‚ä• in the interval domain, i.e. an empty interval) whenever
needed. For example, if ùúàùëñ ‚äë ùúà ùëó is not satisfied by assign-
ment ùê¥, we can update ùê¥ by mapping ùúà ùëó to ùê¥(ùúà ùëó ) ‚äî ùê¥(ùúàùëñ ).
As is well known from abstract interpretation, this na√Øve

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Œì ‚ä¢ score(ùëÄ) :

(cid:27)

(cid:26)ùúà1
ùúà2

, C

ùúà = fresh()

(cid:26)ùúà1
ùúà
(cid:26)ùúÖ1
ùúà1

(cid:27)

(cid:27)

, C ‚à™ {ùúà ‚â° ùúà1 √ó ùúà2}

; ùë• : ùúÖ ‚ä¢ ùëÄ :

(cid:27)

(cid:26)ùúÖ2
ùúà2

, C

ùë• : ùúÖ ‚àà Œì

ùúà = fresh()

ùúÖ = fresh(ùõº)

Œì; ùë• : ùúÖ ‚ä¢ ùëÄ : ùíú, C

Œì ‚ä¢ ùëÄ :

Œì ‚ä¢ ùë• :

(cid:27)

(cid:26)ùúÖ
ùúà

, {ùúà ‚â° 1}

ùúà = fresh()
(cid:26)ùúÖ ‚Üí ùíú
ùúà

Œì ‚ä¢ ùúÜùë•ùõº .ùëÄ :

(cid:27)

, C ‚à™ {ùúà ‚â° 1}

ùúà2 = fresh()

ùúÖ = fresh(ùõº)

ùúÖ1 = fresh(ùõΩ)

ùúà, ùúà1 = fresh()

Œì; ùúë : ùúÖ ‚Üí

ùúà1 = fresh()
(cid:26)ùúà1
ùúà2

Œì ‚ä¢ ùëü :

(cid:27)

, {ùúà1 ‚â° [ùëü, ùëü ], ùúà2 ‚â° 1}

ùúà, ùúà ‚Ä≤ = fresh()
(cid:26) ùúà
ùúà ‚Ä≤

(cid:27)

Œì ‚ä¢ sample :

, {ùúà ‚â° [0, 1], ùúà ‚Ä≤ ‚â° 1}

Œì ‚ä¢ ùëÄ :

(cid:27)

(cid:26)ùúà1
ùúà2

, CùëÄ

Œì ‚ä¢ ùëÅ :

Œì ‚ä¢ if (ùëÄ, ùëÅ , ùëÉ) :

(cid:26)ùúÖ
ùúà

(cid:26)ùúÖ1
ùúà3
(cid:27)

Œì ‚ä¢ ùúáùúë:ùõº‚ÜíùõΩ
ùë•

. ùëÄ :

, C ‚à™ {ùúà ‚â° 1, ùúÖ2 ‚äë ùúÖ1, ùúà2 ‚äë ùúà1}

Ô£ºÔ£¥Ô£¥Ô£Ω
Ô£¥Ô£¥
Ô£æ

(cid:27)

(cid:26)ùúÖ2
ùúà2

ùúà

Ô£±Ô£¥Ô£¥Ô£≤
ùúÖ ‚Üí
Ô£¥Ô£¥
Ô£≥
(cid:26)ùúÖ2
ùúà2

(cid:27)

Œì ‚ä¢ ùëÄ :

Ô£±Ô£¥Ô£¥Ô£≤
ùúÖ1 ‚Üí
Ô£¥Ô£¥
Ô£≥

ùúà1

Œì ‚ä¢ ùëÄùëÅ :

(cid:27)

(cid:26)ùúÖ2
ùúà

(cid:27)

, C1

Œì ‚ä¢ ùëÅ :

(cid:26)ùúÖ3
ùúà3

Ô£ºÔ£¥Ô£¥Ô£Ω
Ô£¥Ô£¥
Ô£æ
, C1 ‚à™ C2 ‚à™ {ùúÖ3 ‚äë ùúÖ1, ùúà ‚â° ùúà1 √ó ùúà2 √ó ùúà3}

, C2

ùúà = fresh()

(cid:27)

, CùëÅ

Œì ‚ä¢ ùëÉ :

(cid:27)

(cid:26)ùúÖ2
ùúà4

, CùëÉ

ùúÖ = fresh(base(ùúÖ1))

ùúà, ùúà ‚Ä≤ = fresh()

, CùëÄ ‚à™ CùëÅ ‚à™ CùëÉ ‚à™ {ùúÖ1 ‚äë ùúÖ, ùúÖ2 ‚äë ùúÖ, ùúà ‚â° ùúà2 √ó ùúà ‚Ä≤, ùúà3 ‚äë ùúà ‚Ä≤, ùúà4 ‚äë ùúà ‚Ä≤}

Œì ‚ä¢ ùëÄ1 :

(cid:27)

(cid:26)ùúà1
ùúà ‚Ä≤
1

, C1

Œì ‚ä¢ ùëì (ùëÄ1, . . . , ùëÄ |ùëì |) :

¬∑ ¬∑ ¬∑

(cid:27)

(cid:26) ùúà
ùúà ‚Ä≤

Œì ‚ä¢ ùëÄ |ùëì | :

(cid:41)

(cid:40)ùúà |ùëì |
ùúà ‚Ä≤
|ùëì |

, C|ùëì |

ùúà, ùúà ‚Ä≤ = fresh()

, (cid:208)|ùëì |

ùëñ=1 Cùëñ ‚à™ {ùúà ‚â° ùëì (ùúà1, . . . , ùúà |ùëì |), ùúà ‚Ä≤ ‚â° (cid:206)|ùëì |

ùëñ=1 ùúà ‚Ä≤
ùëñ }

Figure 10. Symbolic weight-aware type system.

approach may not terminate because the interval domain is
not chain-complete. For instance, consider the constraints
C = {ùúà1 = [0, 0], ùúà2 = [1, 1], ùúà1 ‚äë ùúà3, ùúà3 ‚â° ùúà3 + ùúà2}. The
minimal solution is {ùúà1 ‚Ü¶‚Üí [0, 0], ùúà2 ‚Ü¶‚Üí [1, 1], ùúà3 ‚Ü¶‚Üí [0, ‚àû]},
but the algorithm never terminates and instead assigns the
ascending chain [0, 0], [0, 1], [0, 2], . . . to ùúà3.

Widening. To remedy the above problem, we use widen-
ing, a standard approach to ensure termination of abstract
interpretation on domains with infinite chains [14]. Let ‚àá be
a widening operator for intervals. This means that ùêº1 ‚äî ùêº2 ‚äë
ùêº1‚àáùêº2 for all intervals ùêº1, ùêº2 and for every chain ùêº0 ‚äë ùêº1 ‚äë ùêº2 ‚äë
¬∑ ¬∑ ¬∑ , the chain (ùêº ‚àá
ùëñ‚àí1‚àáùêºùëñ
for ùëñ ‚â• 1 stabilises eventually. A trivial widening operator is
given by only allowing intervals to extend to infinity, defined
as follows:

ùëñ )ùëñ ‚ààN defined by ùêº ‚àá

0 := ùêº0 and ùêº ‚àá
ùëñ

:= ùêº ‚àá

‚ä•‚àáùêº := ùêº ‚àá‚ä• := ùêº

[ùëé, ùëè]‚àá[ùëê, ùëë] := [ùëé, ùëè]
[ùëé, ùëè]‚àá[ùëê, ùëë] := [ùëé, ‚àû]
[ùëé, ùëè]‚àá[ùëê, ùëë] := [‚àí‚àû, ùëè]
[ùëé, ùëè]‚àá[ùëê, ùëë] := [‚àí‚àû, ‚àû]

if ùëé ‚â§ ùëê ‚àß ùëë ‚â§ ùëè
if ùëé ‚â§ ùëê ‚àß ùëë > ùëè
if ùëë ‚â§ ùëè ‚àß ùëê < ùëé
if ùëê < ùëé ‚àß ùëë > ùëè

As soon as the upper bound increases or lower bound de-
creases, the bound is directly set to = ‚àû or ‚àí‚àû respectively.

By using the widening operator in each update step of our
na√Øve algorithm, we break infinite increasing chains and the
resulting algorithm is guaranteed to converge to a satisfying
assignment (if one exists).

GuBPI solves constraints by using a standard worklist
algorithm [15, 23], combined with the previous widening
operator.

E Supplementary Material for Section 6
E.1 Extensions to Linear Splitting
In this section we give additional information about how
our linear optimisation of the interval-trace semantics can
be extended to non-uniform samples and non-linear scoring
values.

Beyond uniform samples. To allow for non-uniform sam-
ples, we can combine the standard interval trace semantics
with the linear optimisation. That is, in addition to bounding
linear score functions, we also split and bound each non-
uniform sample (as in the standard interval trace semantics).
Suppose that ùõºùëñ is sampled from some continuous distribu-
tion ùê∑. We then split the real line into chunks (the size and
number of which is selected by a heuristic depending on
ùê∑). For each such chunk [ùëé, ùëè], we compute the volume and
multiply by the lower and upper bounds of the pdf of ùê∑ on
[ùëé, ùëè]. In this way, we can even approximate integrals where

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

not all variables are sampled from a uniform distribution
(without needing to resort to inverse cumulative distribution
functions). Our experiments show, that as long as the guards
are still linear, this approach is advantageous compared to
the naive interval-based semantics.

ùëñ

ùëñ , . . . , Zùëöùëñ

Beyond linear functions. While guards on conditionals
are often linear, this is rarely the case for score expressions
(as one usually observes values from some non-uniform dis-
tribution with a non-linear pdf). Consider the pedestrian
example again. While all guards are linear, the score expres-
sion has the form pdf Normal(1.1,0.1) (V). We can handle such
non-linear score values by applying linear optimisation to
the linear subexpressions and interval arithmetic for the
nonlinear parts. Formally, we assume that each Wùëñ ‚àà Œû
(each symbolic value we score with) has the form Wùëñ =
ùëó
ùëìùëñ (Z1
ùëñ for 1 ‚â§ ùëó ‚â§ ùëöùëñ denote linear
) where Z
: Rùëöùëñ ‚Üí R is a
functions of the sample variables and ùëì
possibly non-linear function. Every score expression can be
written in this way. For instance, in the pedestrian example,
.
we have ùëì = pdf Normal(1.1,0.1)
ùëó
Let Œû‚Ä≤ = {Z
ùëñ

| ùëñ ‚àà {1, . . . , ùëõ}, ùëó ‚àà {1, . . . , ùëöùëñ }} be the set of
all such linear functions. We bound each linear function in Œû‚Ä≤
using linear optimisation as before. We obtain a box ùëè (which
now has dimension |Œû‚Ä≤| instead of |Œû|) and define the weight
weight (ùëè) by applying the interval liftings ùëì I
ùëñ of the non-
linear functions ùëìùëñ to the bounds for each argument. Formally,
weight (ùëè) = (cid:206)ùëò
ùëñ is the interval
ùëó
bound on Z
ùëñ . Note that this strictly generalizes the approach
outlined before since we can choose ùëìùëñ as the identity if Wùëñ
is already linear. The definition of approx (ùëè) with the new
weight definition still satisfies Proposition 6.4. This way, we
can even approximate integrals over non-linear functions by
means of simple volume computations. As our experiments
(e.g. on the pedestrian example) show, this approximation is
precise enough to obtain useful bounds on the posterior. It
is important to note that while we can deal with non-linear
score values, we cannot handle non-linear guards and instead
use the standard semantics for such cases.

) where ùëè ùëó

ùëñ , . . . , ùëèùëöùëñ

ùëñ=1 ùëì I

ùëñ (ùëè1

ùëñ

F Supplementary Material for Section 7
Our experiments were performed on a server running Ubuntu
18.04 with an 8core Intel(R) Xeon(R) CPU E3-1271 v3 @
3.60GHz CPU with 32Gbp of RAM. The current version of
GuBPI is not parallelised and makes no use of the additional
cores. The running times on a Macbook Pro with Apple M1
were comparable, and sometimes even faster.

F.1 Pyro‚Äôs HMC samples for the pedestrian example
The HMC samples plotted in Figs. 1 and 7 were generated
with the probabilistic programming system Pyro [5]. Since
the original pedestrian program has infinite expected run-
ning time, we introduced a stopping condition in the ran-
dom walk: if the distance traveled exceeded 10, the loop

was exited. (This has a negligible effect on the posterior
distribution because the weight of such a trace is at most
pdf Normal(1.1,0.1) (10) < 10‚àí1700.)

We used Pyro‚Äôs HMC sampler to compute 10 Markov
chains with 1000 samples each for this program. We set
the hyperparamaters to 0.1 for the step size and 50 for the
number of steps. We also tried the NUTS sampler, which
aims to automatically estimate good values for the hyperpa-
rameters, but it performed worse than the manually chosen
values. The running time for the chains varied significantly:
some took around one minute, others almost an hour. This
depended on whether the Markov chain got ‚Äústuck‚Äù in a long
trace. (The length of the traces varied between 2 and about
200.)

We discarded chains with very low acceptance rates (under
1%), aggregated the remaining chains, which had acceptance
rates of over 50%, and used their histogram in Figs. 1 and 7.

F.2 Details on Probability Estimation
In Table 1 (results of our tool for the probability estima-
tion benchmark), we omitted the query for space reasons.
Complete information including the query can be found in
Table 4.

F.3 Simulation-based Calibration
We implemented SBC for both likelihood-weighted impor-
tance sampling and Pyro‚Äôs HMC. As hyperparameters for
SBC, we picked ùêø = 63 samples per simulation (following
the suggestion in [60] to take one less than a power of two)
and ùëÅ simulations with ùëÅ = 10ùêø (also following the paper‚Äôs
suggestion). Note that the number of samples is much less
than the 10000 samples used for Figs. 1 and 7 (10 chains with
1000 samples each). But setting ùêø = 1000 would be at least
100 times slower because ùëÅ has to increase proportionally
to ùêø. Also note that for Pyro, we ran HMC with ùêø warmup
steps before generating ùêø samples. Both importance samples
and HMC samples exhibited significant autocorrelation. As
suggested in [60], we applied thinning to reduce its effect,
choosing a thinning factor of around ùêø
where ùêøeff is the
ùêøeff
effective sample size.

Pedestrian example. For importance sampling, the rank
histogram looks fairly uniform (Fig. 11a), which means that
SBC does not detect an issue with the inference and thus
increases the confidence in the validity of the importance
samples. For Pyro‚Äôs HMC, simulation-based calibration is
very slow: the rank histogram (Fig. 11b) took 32 hours (!) to
produce. (Note that only 332 simulations could be used, the
rest were discarded because the acceptance rate was too low.)
The spikes at the boundary indicate that the samples have
high autocorrelation and in fact, the effective sample size ùêøeff
was at most ùêø
10 , often much lower (depending on the chain).
The suggestion in [60] is thus to apply thinning, with a factor
of ùêø
, which is at least 10 in our case. This would increase
ùêøeff

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Table 4. Evaluation on selected benchmarks from [56]. We give the times (in seconds) and bounds computed by [56] and
GuBPI. The table agrees with Table 1 but spells out the full problem name and the exact query.

Program

tug-of-war

tug-of-war

beauquier-etal-3

example-book-simple

example-book-simple

example-cart

example-cart

Q

Q1

Q2

Q1

Q1
Q2‚òÖ
Q1

Q2

example-cart
Q3
example-ckd-epi-simple Q1‚òÖ
example-ckd-epi-simple Q2‚òÖ
Q1
example-fig6

example-fig6

example-fig6

example-fig6

example-fig7

example4

example5

herman-3

Q2

Q3

Q4

Q1

Q1

Q1

Q1

Query

total_ùëé_ùëè < total_ùë°_ùë†
total_ùëé_ùë† < total_ùëè_ùë°
count < 1
count ‚â• 2
count ‚â• 4
count ‚â• 1
count ‚â• 2
count ‚â• 4
ùëì1 ‚â§ 4.4 ‚àß ùëì ‚â• 4.6
ùëì1 ‚â• 4.6 ‚àß ùëì ‚â§ 4.4
ùëê ‚â§ 1
ùëê ‚â§ 2
ùëê ‚â§ 5
ùëê ‚â§ 8
ùë• ‚â§ 1000
ùë• + ùë¶ > 10
ùë• + ùë¶ > ùëß + 10
count < 1

Tool from [56]

GuBPI

ùíï

1.29

1.09

1.15

8.48

10.3

2.41

2.40

0.15

0.15

0.08

1.31

1.80

1.51

3.96

0.04

0.02

0.06

0.47

Result

[0.6126, 0.6227]
[0.5973, 0.6266]
[0.5000, 0.5261]
[0.6633, 0.7234]
[0.3365, 0.3848]
[0.8980, 1.1573]
[0.8897, 1.1573]
[0.0000, 0.1150]
[0.5515, 0.5632]
[0.3019, 0.3149]
[0.1619, 0.7956]
[0.2916, 1.0571]
[0.4314, 2.0155]
[0.4400, 3.0956]
[0.9921, 1.0000]
[0.1910, 0.1966]
[0.4478, 0.4708]
[0.3750, 0.4091]

ùíï

0.72

0.79

22.5

6.52

8.01

67.3

68.5

67.4

0.86

0.84

21.2

21.4

24.7

27.4

0.18

0.31

0.27

124

Result

[0.6134, 0.6135]
[0.6134, 0.6135]
[0.4999, 0.5001]
[0.7417, 0.7418]
[0.4137, 0.4138]
[0.9999, 1.0001]
[0.9999, 1.0001]
[0.0000, 0.0001]
[0.0003, 0.0004]
[0.0003, 0.0004]
[0.1899, 0.1903]
[0.3705, 0.3720]
[0.7438, 0.7668]
[0.8682, 0.9666]
[0.9980, 0.9981]
[0.1918, 0.1919]
[0.4540, 0.4541]
[0.3749, 0.3751]

(a) Importance sampling for the
pedestrian example, thinning fac-
tor 100.

(b) HMC for the pedestrian exam-
ple, no thinning. (Only 332 simu-
lations were used because the rest
had too low acceptance rates.)

(c) NUTS for the binary Gaussian
mixture model, thinning factor 10.

(d) NUTS for the two-dimensional
binary Gaussian mixture model,
thinning factor 10.

Figure 11. Simulation-based calibration: rank histogram plots (630 simulations with 63 samples each).

the running time of SBC by the same factor, to at least 300
hours, but probably 600 or more. We did not consider it a
good use of resources to carry out this experiment.

Binary Gaussian Mixture Model. We also considered
the binary GMM (Fig. 5c) and a two-dimensional version of
the same model. The spikes at the boundary could again be
a sign of high autocorrelation, but in this case, we already
applied thinning with a factor of 10 (again based on the effec-
tive sample size). Instead, as discussed in [60], this symmetric

U-shape indicates that the computed data-averaged poste-
rior is underdispersed relative to the prior distribution. This
interpretation is consistent with our knowledge about the
model: HMC only finds one mode in the posterior distribu-
tion and misses the others. Hence SBC successfully detects
the issue, and in the case of the higher-dimensional model,
it does so in less time than GuBPI (cf. Table 3). For the other
models, including the pedestrian example, GuBPI is faster.

0102030405060Rank051015202530Count0102030405060Rank020406080100120140160Count0102030405060Rank020406080100Count0102030405060Rank020406080100CountPLDI ‚Äô22, June 13‚Äì17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

Contents

Introduction

Guaranteed Bounds
Contributions
Scope and Limitations

Background

Basic Probability Theory and Notation
Statistical PCF (SPCF)
Trace Semantics

Interval Trace Semantics
Interval Arithmetic
Interval Traces and Interval SPCF
Bounds from Interval Traces

Soundness and Completeness

Soundness
Completeness

Weight-aware Interval Type System

Interval Types
Type System
Constraint-based Type Inference

Symbolic Execution and GuBPI

Symbolic Execution
GuBPI
Standard Interval Trace Semantics
Linear Interval Trace Semantics

Practical Evaluation

Probability Estimation
Exact Inference
Recursive Models

Abstract
1
1.1
1.2
1.3
2
2.1
2.2
2.3
3
3.1
3.2
3.3
4
4.1
4.2
5
5.1
5.2
5.3
6
6.1
6.2
6.3
6.4
7
7.1
7.2
7.3

Comparison with Statistical Validation
Limitations and Future Improvements

Related Work
Conclusion

Supplementary Material for Section 3

Intervals as a lattice
Lifting Functions to Intervals
Properties of Interval Reduction
Additional Possible Reduction Rules

Symbolic Execution
Supplementary Material for Section 4

Infinite Trace Semantics
Exhaustivity and Soundness
Assumptions for Completeness
Completeness Proof

Supplementary Material for Section 5

Soundness
Weak Completeness
Constraint-based Type Inference
Supplementary Material for Section 6
Extensions to Linear Splitting
Supplementary Material for Section 7

Pyro‚Äôs HMC samples for the pedestrian
example
Details on Probability Estimation
Simulation-based Calibration

7.4
7.5
8
9
References
A
A.1
A.2
A.3
A.4
B
C
C.1
C.2
C.3
C.4
D
D.1
D.2
D.3
E
E.1
F
F.1

F.2
F.3
Contents

13
13
13
14
15
17
17
17
17
17
18
19
19
20
20
22
25
25
27
28
29
29
30

30
30
30
32

1
1
2
2
3
3
3
3
4
4
4
4
5
6
6
6
7
7
8
8
8
8
9
9
10
10
10
11
12

