Guaranteed Bounds for Posterior Inference
in Universal Probabilistic Programming
C.-H. Luke Ong
Fabian Zaiser
University of Oxford
University of Oxford
United Kingdom
United Kingdom

Raven Beutnerâˆ—
CISPA Helmholtz Center for
Information Security
Germany

2
2
0
2

n
u
J

6

]
L
P
.
s
c
[

2
v
8
4
9
2
0
.
4
0
2
2
:
v
i
X
r
a

Abstract
We propose a new method to approximate the posterior dis-
tribution of probabilistic programs by means of computing
guaranteed bounds. The starting point of our work is an
interval-based trace semantics for a recursive, higher-order
probabilistic programming language with continuous distri-
butions. Taking the form of (super-/subadditive) measures,
these lower/upper bounds are non-stochastic and provably
correct: using the semantics, we prove that the actual poste-
rior of a given program is sandwiched between the lower and
upper bounds (soundness); moreover, the bounds converge
to the posterior (completeness). As a practical and sound
approximation, we introduce a weight-aware interval type
system, which automatically infers interval bounds on not
just the return value but also the weight of program execu-
tions, simultaneously. We have built a tool implementation,
called GuBPI, which automatically computes these posterior
lower/upper bounds. Our evaluation on examples from the
literature shows that the bounds are useful, and can even be
used to recognise wrong outputs from stochastic posterior
inference procedures.

CCS Concepts: â€¢ Mathematics of computing â†’ Proba-
bilistic inference problems; â€¢ Theory of computation
â†’ Program analysis; â€¢ Software and its engineering â†’
Formal methods.
Keywords: probabilistic programming, Bayesian inference,
verification, abstract interpretation, operational semantics,
interval arithmetic, type system, symbolic execution

ACM Reference Format:
Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser. 2022. Guaran-
teed Bounds for Posterior Inference in Universal Probabilistic Pro-
gramming. In Proceedings of the 43rd ACM SIGPLAN International
Conference on Programming Language Design and Implementation
(PLDI â€™22), June 13â€“17, 2022, San Diego, CA, USA. ACM, New York,
NY, USA, 32 pages. https://doi.org/10.1145/3519939.3523721
âˆ—Member of the SaarbrÃ¼cken Graduate School of Computer Science.

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA
Â© 2022 Copyright held by the owner/author(s).
This is the authorâ€™s version of the work. It is posted here for your personal
use. Not for redistribution. The definitive Version of Record was published
in Proceedings of the 43rd ACM SIGPLAN International Conference on Pro-
gramming Language Design and Implementation (PLDI â€™22), June 13â€“17, 2022,
San Diego, CA, USA, https://doi.org/10.1145/3519939.3523721.

1 Introduction
Probabilistic programming is a rapidly developing discipline
at the interface of programming and Bayesian statistics [32,
33, 62]. The idea is to express probabilistic models (incor-
porating the prior distributions) and the observed data as
programs, and to use a general-purpose Bayesian inference
engine, which acts directly on these programs, to find the
posterior distribution given the observations.

Some of the most influential probabilistic programming
languages (PPLs) used in practice are universal (i.e. the under-
lying language is Turing-complete); e.g. Church [31], Angli-
can [61], Gen [18], Pyro [5], and Turing [25]. Using stochastic
branching, recursion, and higher-order features, universal
PPLs can express arbitrarily complex models. For instance,
these language constructs can be used to incorporate proba-
bilistic context free grammars [43], statistical phylogenetics
[52], and even physics simulations [3] into probabilistic mod-
els. However, expressivity of the PPL comes at the cost of
complicating the posterior inference. Consider, for example,
the following problem from [41, 42].

Example 1.1 (Pedestrian). A pedestrian has gotten lost on
a long road and only knows that they are a random distance
between 0 and 3 km from their home. They repeatedly walk a
uniform random distance of at most 1 km in either direction,
until they find their home. When they arrive, a step counter
tells them that they have traveled a distance of 1.1 km in total.
Assuming that the measured distance is normally distributed
around the true distance with standard deviation 0.1 km,
what is the posterior distribution of the starting point? We
can model this with a probabilistic program:

let start = 3 Ã— sample uniform(0, 1) in
letrec walk ğ‘¥ = if ğ‘¥ â‰¤ 0 then 0 else

let step = sample uniform(0, 1) in
step + walk (cid:0)(ğ‘¥ + step) âŠ•0.5 (ğ‘¥ âˆ’ step)(cid:1)

let distance = walk start in
observe distance from Normal(1.1, 0.1);
start

Here sample uniform(ğ‘, ğ‘) samples a uniformly distributed
value in [ğ‘, ğ‘], âŠ•0.5 is probabilistic branching, and observe
ğ‘€ from ğ· observes the value of ğ‘€ from distribution ğ·.

Example 1.1 is a challenging model for inference algo-
rithms in several regards: not only does the program use

 
 
 
 
 
 
PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

only applicable to very restricted classes of programs (most
notably, non-recursive models).

(cid:75)

Instead of computing approximate or exact results, this
work is concerned with computing guaranteed bounds on the
posterior distribution of a probabilistic program. Concretely,
given a probabilistic program ğ‘ƒ and a measurable set ğ‘ˆ âŠ† R
(given as an interval), we infer upper and lower bounds on
(ğ‘ˆ ) (formally defined in Section 2), i.e. the posterior prob-
ğ‘ƒ
ability of ğ‘ƒ on ğ‘ˆ .2 Such bounds provide a ground truth to
(cid:74)
compare approximate inference results with: if the approx-
imate results violate the bounds, the inference algorithm
has not converged yet or is even ill-suited to the program
in question. Crucially, our method is applicable to arbitrary
(and in particular recursive) programs of a universal PPL. For
Example 1.1, the bounds computed by our method (which
we give in Section 7) are tight enough to separate the IS and
HMC output. In this case, our method infers that the results
given by HMC are wrong (i.e. violate the guaranteed bounds)
whereas the IS results are plausible (i.e. lie within the guar-
anteed bounds). To the best of our knowledge, no existing
methods can provide such definite answers for programs of
a universal PPL.

1.2 Contributions
The starting point of our work is an interval-based opera-
tional semantics [4]. In our semantics, we evaluate a program
on interval traces (i.e. sequences of intervals of reals with
endpoints between 0 and 1) to approximate the outcomes of
sampling, and use interval arithmetic [19] to approximate
numerical operations (Section 3). Our semantics is sound in
the sense that any (compatible and exhaustive) set of inter-
val traces yields lower and upper bounds on the posterior
distribution of a program. These lower/upper bounds are
themselves super-/subadditive measures. Moreover, under
mild conditions (mostly restrictions on primitive operations),
our semantics is also complete, i.e. for any ğœ– > 0 there ex-
ists a countable set of interval traces that provides ğœ–-tight
bounds on the posterior. Our proofs hinge on a combination
of stochastic symbolic execution and the convergence of
Riemann sums, providing a natural correspondence between
our interval trace semantics and the theory of (Riemann)
integration (Section 4).

Based on our interval trace semantics, we present a prac-
tical algorithm to automate the computation of guaranteed
bounds. It employs an interval type system (together with
constraint-based type inference) that bounds both the value
of an expression in a refinement-type fashion and the score
weight of any evaluation thereof. The (interval) bounds in-
ferred by our type system fit naturally in the domain of
our semantics. This enables a sound approximation of the

2By repeated application of our method on a discretisation of the domain
we can compute histogram-like bounds.

Figure 1. Histogram of samples from the posterior distri-
bution of Example 1.1 and wrong samples produced by the
probabilistic programming system Pyro.

stochastic branching and recursion, but the number of ran-
dom variables generated is unbounded â€“ itâ€™s nonparametric
[29, 37, 42]. To approximate the posterior distribution of
the program, we apply two standard inference algorithms:
likelihood-weighted importance sampling (IS), a simple al-
gorithm that works well on low-dimensional models with
few observations [49]; and Hamiltonian Monte Carlo (HMC)
[21], a successful MCMC algorithm that uses gradient infor-
mation to efficiently explore the parameter space of high-
dimensional models. Figure 1 shows the results of the two
inference methods as implemented in Anglican [61] (for IS)
and Pyro [5] (for HMC): they clearly disagree! But how is
the user supposed to know which (if any) of the two results
is correct?

Note that exact inference methods (i.e. methods that try
to compute a closed-form solution of the posterior inference
problem using computer algebra and other forms of symbolic
computation) such as PSI [26, 27], Hakaru [47], Dice [38],
and SPPL [55] are only applicable to non-recursive models,
and so they donâ€™t work for Example 1.1.

1.1 Guaranteed Bounds
The above example illustrates central problems with both
approximate stochastic and exact inference methods. For
approximate methods, there are no guarantees for the results
they output after a finite amount of time, leading to unclear
inference results (as seen in Fig. 1).1 For exact methods, the
symbolic engine may fail to find a closed-form description
of the posterior distribution and, more importantly, they are

1Take MCMC sampling algorithms. Even though the Markov chain will
eventually converge to the target distribution, we do not know how long to
iterate the chain to ensure convergence [49, 53]. Likewise for variational
inference [64]: given a variational family, there is no guarantee that a
given value for the KL-divergence (from the approximating to the posterior
distribution) is attainable by the minimising distribution.

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

behaviour of a program with finitely many interval traces
(Section 5).

We implemented our approach in a tool called GuBPI3
(Guaranteed Bounds for Posterior Inference), described in
Section 6, and evaluate it on a suite of benchmark programs
from the literature. We find that the bounds computed by
GuBPI are competitive in many cases where the posterior
could already be inferred exactly. Moreover, GuBPIâ€™s bounds
are useful (in the sense that they are precise enough to rule
out erroneous approximate results as in Fig. 1, for instance)
for recursive models that could not be handled rigorously by
any method before (Section 7).

1.3 Scope and Limitations
The contributions of this paper are of both theoretical and
practical interest. On the theoretical side, our novel seman-
tics underpins a sound and deterministic method to compute
guaranteed bounds on program denotations. As shown by
our completeness theorem, this analysis is applicableâ€”in the
sense that it computes arbitrarily tight boundsâ€”to a very
broad class of programs. On the practical side, our analyser
GuBPI implements (an optimised version of) our semantics.
As is usual for exact/guaranteed4 methods, our semantics
considers an exponential number of program paths, and par-
titions each sampled value into a finite number of interval
approximations. Consequently, GuBPI generally struggles
with high-dimensional models. We believe GuBPI to be most
useful for unit-testing of implementations of Bayesian infer-
ence algorithms such as Example 1.1, or to compute results
on (recursive) programs when non-stochastic, guaranteed
bounds are needed.

2 Background
2.1 Basic Probability Theory and Notation
We assume familiarity with basic probability theory, and
refer to [51] for details. Here we just fix the notation. A mea-
surable space is a pair (Î©, Î£Î©) where Î© is a set (of outcomes)
and Î£Î© âŠ† 2Î© is a ğœ-algebra defining the measurable subsets
of Î©. A measure on (Î©, Î£Î©) is a function ğœ‡ : Î£Î© â†’ Râ‰¥0âˆª{âˆ}
that satisfies ğœ‡ (âˆ…) = 0 and is ğœ-additive. For Rğ‘›, we write
Î£Rğ‘› for the Borel ğœ-algebra and ğœ†ğ‘› for the Lebesgue mea-
sure on (Rğ‘›, Î£Rğ‘› ). The Lebesgue integral of a measurable
function ğ‘“ with respect to a measure ğœ‡ is written âˆ« ğ‘“ dğœ‡
or âˆ« ğ‘“ (ğ‘¥) ğœ‡ (dğ‘¥). Given a predicate ğœ“ on Î©, we define the
Iverson brackets [ğœ“ ] : Î© â†’ R by mapping all elements that
satisfy ğœ“ to 1 and all others to 0. For ğ´ âˆˆ Î£Î© we define the
bounded integral âˆ«
ğ´

ğ‘“ dğœ‡ := âˆ« ğ‘“ (ğ‘¥) Â· [ğ‘¥ âˆˆ ğ´]ğœ‡ (dğ‘¥).

3GuBPI (pronounced â€œguppyâ€) is available at gubpi-tool.github.io.
4By â€œexact/guaranteed methodsâ€, we mean inference algorithms that com-
pute deterministic (non-stochastic) results about the mathematical denota-
tion of a program. In particular, they are correct with probability 1, contrary
to stochastic methods.

((ğœ†ğ‘¥ .ğ‘€)ğ‘‰ , ğ’”, ğ‘¤) â†’ (ğ‘€ [ğ‘‰ /ğ‘¥], ğ’”, ğ‘¤)

(sample, ğ‘Ÿ ğ’”, ğ‘¤) â†’ (ğ‘Ÿ, ğ’”, ğ‘¤)

((ğœ‡ğœ‘

ğ‘¥ . ğ‘€)ğ‘‰ , ğ’”, ğ‘¤) â†’ (ğ‘€ [ğ‘‰ /ğ‘¥, (ğœ‡ğœ‘

ğ‘¥ . ğ‘€)/ğœ‘], ğ’”, ğ‘¤)

(ğ‘“ (ğ‘Ÿ1, . . . , ğ‘Ÿ |ğ‘“ |), ğ’”, ğ‘¤) â†’ (ğ‘“ (ğ‘Ÿ1, . . . , ğ‘Ÿ |ğ‘“ |), ğ’”, ğ‘¤)

ğ‘Ÿ â‰¤ 0
(if (ğ‘Ÿ, ğ‘ , ğ‘ƒ), ğ’”, ğ‘¤) â†’ (ğ‘ , ğ’”, ğ‘¤)
ğ‘Ÿ â‰¥ 0
(score(ğ‘Ÿ ), ğ’”, ğ‘¤) â†’ (ğ‘Ÿ, ğ’”, ğ‘¤ Â· ğ‘Ÿ )

ğ‘Ÿ > 0
(if(ğ‘Ÿ, ğ‘ , ğ‘ƒ), ğ’”, ğ‘¤) â†’ (ğ‘ƒ, ğ’”, ğ‘¤)
(ğ‘…, ğ’”, ğ‘¤) â†’ (ğ‘€, ğ’” â€², ğ‘¤ â€²)
(ğ¸ [ğ‘…], ğ’”, ğ‘¤) â†’ (ğ¸ [ğ‘€], ğ’” â€², ğ‘¤ â€²)

Figure 2. Standard (CbV) reduction rules for SPCF (â†’).

2.2 Statistical PCF (SPCF)
As our probabilistic programming language of study, we use
statistical PCF (SPCF) [41], a typed variant of [7]. SPCF in-
cludes primitive operations which are measurable functions
ğ‘“ : R|ğ‘“ | â†’ R, where |ğ‘“ | â‰¥ 0 denotes the arity of the function.
Values and terms of SPCF are defined as follows:

ğ‘‰ := ğ‘¥ | ğ‘Ÿ | ğœ†ğ‘¥ .ğ‘€ | ğœ‡ğœ‘

ğ‘¥ . ğ‘€

ğ‘€, ğ‘ , ğ‘ƒ := ğ‘‰ | ğ‘€ğ‘ | if (ğ‘€, ğ‘ , ğ‘ƒ) | ğ‘“ (ğ‘€1, . . . , ğ‘€ |ğ‘“ |)

| sample | score(ğ‘€)

where ğ‘¥ and ğœ‘ are variables, ğ‘“ is a primitive operation, and
ğ‘Ÿ a constant with ğ‘Ÿ âˆˆ R. Note that we write ğœ‡ğœ‘
ğ‘¥ . ğ‘€ instead
of Y(ğœ†ğœ‘ğ‘¥ .ğ‘€) for the fixpoint construct. The branching con-
struct is if (ğ‘€, ğ‘ , ğ‘ƒ), which evaluates to ğ‘ if ğ‘€ â‰¤ 0 and
ğ‘ƒ otherwise. In SPCF, sample draws a random value from
the uniform distribution on [0, 1], and score(ğ‘€) weights
the current execution with the value of ğ‘€. Samples from
a different real-valued distribution ğ· can be obtained by
applying the inverse of the cumulative distribution func-
tion for ğ· to a uniform sample [54]. Most PPLs feature an
observe statement instead of manipulating the likelihood
weight directly with score, but they are equally expressive
[59].5 As usual, we write let ğ‘¥ = ğ‘€ in ğ‘ for (ğœ†ğ‘¥ .ğ‘ )ğ‘€, ğ‘€; ğ‘
for let _ = ğ‘€ in ğ‘ and ğ‘€ âŠ•ğ‘ ğ‘ for if (sample âˆ’ ğ‘, ğ‘€, ğ‘ ). The
type system of our language is as expected, with simple types
being generated by ğ›¼, ğ›½ := R | ğ›¼ â†’ ğ›½. Selected rules are
given below:

Î“ âŠ¢ sample : R

Î“, ğœ‘ : ğ›¼ â†’ ğ›½, ğ‘¥ : ğ›¼ âŠ¢ ğ‘€ : ğ›½

Î“ âŠ¢ ğœ‡ğœ‘

ğ‘¥ . ğ‘€ : ğ›¼ â†’ ğ›½

Î“ âŠ¢ ğ‘€ : R
Î“ âŠ¢ score(ğ‘€) : R
{Î“ âŠ¢ ğ‘€ğ‘– : R} |ğ‘“ |
ğ‘–=1
Î“ âŠ¢ ğ‘“ (ğ‘€1, . . . , ğ‘€ |ğ‘“ |) : R

5 In Bayesian terms, an observe statement multiplies the likelihood func-
tion by the probability (density) of the observation [33] (as we have used in
Example 1.1). Scoring makes this explicit by keeping a weight for each pro-
gram execution [7]. Observing a value ğ‘£ from a distribution ğ· then simply
multiplies the current weight by pdfğ· (ğ‘£) where pdfğ· is the probability
density function of ğ· (for continuous distributions) or the probability mass
function of ğ· (for discrete distributions).

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

2.3 Trace Semantics
Following [7], we endow SPCF with a trace-based opera-
tional semantics. We evaluate a probabilistic program ğ‘ƒ on
a fixed trace ğ’” = âŸ¨ğ‘Ÿ1, . . . , ğ‘Ÿğ‘›âŸ© âˆˆ T := (cid:208)ğ‘› âˆˆN [0, 1]ğ‘›, which
predetermines the probabilistic choices made during the eval-
uation. Our semantics therefore operates on configurations
of the form (ğ‘€, ğ’”, ğ‘¤) where ğ‘€ is an SPCF term, ğ’” is a trace
and ğ‘¤ âˆˆ Râ‰¥0 a weight. The call-by-value (CbV) reduction is
given by the rules in Fig. 2, where ğ¸ [Â·] denotes a CbV eval-
uation context. The definition is standard [4, 7, 41]. Given
a program âŠ¢ ğ‘ƒ : R, we call a trace ğ’” terminating just if
(ğ‘ƒ, ğ’”, 1) â†’âˆ— (ğ‘‰ , âŸ¨âŸ©, ğ‘¤) for some value ğ‘‰ and weight ğ‘¤, i.e. if
the samples drawn are as specified by ğ’”, the program ğ‘ƒ ter-
minates. Note that we require the trace ğ’” to be completely
used up. As ğ‘ƒ is of type R we can assume that ğ‘‰ = ğ‘Ÿ for
some ğ‘Ÿ âˆˆ R. Each terminating trace ğ’” therefore uniquely
determines the returned value ğ‘Ÿ where ğ‘Ÿ =: valğ‘ƒ (ğ’”) âˆˆ R,
and the weight ğ‘¤ =: wtğ‘ƒ (ğ’”) âˆˆ Râ‰¥0, of the execution. For a
nonterminating trace ğ’”, valğ‘ƒ (ğ’”) is undefined and wtğ‘ƒ (ğ’”) := 0.

Example 2.1. Consider Example 1.1. On the trace ğ’” = âŸ¨0.1,
0.2, 0.4, 0.7, 0.8âŸ© âˆˆ [0, 1]5 âŠ† T, the pedestrian walks 0.2 away
from their home (taking the left branch of âŠ•0.5 as 0.4 â‰¤ 0.5)
and 0.7 towards their home (as 0.8 > 0.5), hence:

valğ‘ƒ (ğ’”) = 3 Ã— 0.1 = 0.3, wtğ‘ƒ (ğ’”) = pdf Normal(1.1,0.1) (0.9).
In order to do measure theory, we need to turn our set of
traces into a measurable space. The trace space T is equipped
with the ğœ-algebra Î£T := {(cid:208)ğ‘› âˆˆN ğ‘ˆğ‘› | ğ‘ˆğ‘› âˆˆ Î£ [0,1]ğ‘› } where
Î£ [0,1]ğ‘› is the Borel ğœ-algebra on [0, 1]ğ‘› . We define a measure
ğœ‡T by ğœ‡T (ğ‘ˆ ) := (cid:205)ğ‘› âˆˆN ğœ†ğ‘› (ğ‘ˆ âˆ© [0, 1]ğ‘›), as in [7].

We can now define the semantics of an SPCF program
âŠ¢ ğ‘ƒ : R by using the weight and returned value of (executions
of ğ‘ƒ determined by) individual traces. Given ğ‘ˆ âˆˆ Î£R, we need
to define the likelihood of ğ‘ƒ evaluating to a value in ğ‘ˆ . To this
end, we set valâˆ’1
ğ‘ƒ (ğ‘ˆ ) := {ğ’” âˆˆ T | (ğ‘ƒ, ğ’”, 1) â†’âˆ— (ğ‘Ÿ, âŸ¨âŸ©, ğ‘¤), ğ‘Ÿ âˆˆ
ğ‘ˆ }, i.e. the set of traces on which the program ğ‘ƒ reduces to a
value in ğ‘ˆ . As shown in [7, Lem. 9], valâˆ’1
ğ‘ƒ (ğ‘ˆ ) is measurable.
Thus, we can define (cf. [7, 41])

(ğ‘ˆ ) := âˆ«

ğ‘ƒ (ğ‘ˆ ) wtğ‘ƒ (ğ’”) ğœ‡T (dğ’”).

valâˆ’1

ğ‘ƒ
(cid:74)

(cid:75)

That is, the integral takes all traces ğ’” on which ğ‘ƒ evaluates
to a value in ğ‘ˆ , weighting each ğ’” with the weight wtğ‘ƒ (ğ’”) of
the corresponding execution. A program ğ‘ƒ is called almost
surely terminating (AST) if it terminates with probability
1, i.e. ğœ‡T (valâˆ’1
ğ‘ƒ (R)) = 1. This is a necessary assumption for
approximate inference algorithms (since they execute the
program). See [7] for a more in-depth discussion of this
(standard) sampling-style semantics.

Normalizing constant and integrability. In Bayesian
statistics, one is usually interested in the normalised pos-
terior, which is a conditional probability distribution. We
ğ‘ƒ
where
obtain the normalised denotation as posteriorğ‘ƒ := (cid:74)
(cid:75)ğ‘ğ‘ƒ

(cid:75)

ğ‘ƒ
(cid:74)

(R) is the normalising constant. We call ğ‘ƒ inte-
ğ‘ğ‘ƒ :=
grable if 0 < ğ‘ğ‘ƒ < âˆ. The bounds computed in this paper
(on the unnormalised denotation
) allow us to compute
(cid:75)
bounds on the normalizing constant ğ‘ğ‘ƒ , and thereby also on
the normalised denotation. All bounds reported in this paper
(in particular in Section 7) refer to the normalised denotation.

ğ‘ƒ
(cid:74)

(cid:75)

ğ‘ƒ
(cid:74)

3 Interval Trace Semantics
In order to obtain guaranteed bounds on the distribution
denotation
(and also on posteriorğ‘ƒ ) of a program ğ‘ƒ, we
present an interval-based semantics. In our semantics, we
approximate the outcomes of sample with intervals and han-
dle arithmetic operations by means of interval arithmetic
(which is similar to the approach by Beutner and Ong [4]
in the context of termination analysis). Our semantics en-
ables us to reason about the denotation of a program without
considering the uncountable space of traces explicitly.

3.1 Interval Arithmetic
For our purposes, an interval has the form [ğ‘, ğ‘] which
denotes the set {ğ‘¥ âˆˆ R | ğ‘ â‰¤ ğ‘¥ â‰¤ ğ‘}, where ğ‘ âˆˆ R âˆª {âˆ’âˆ},
ğ‘ âˆˆ R âˆª {âˆ}, and ğ‘ â‰¤ ğ‘. For consistency, we write [0, âˆ]
instead of the more typical [0, âˆ). For ğ‘‹ âŠ† R âˆª {âˆ’âˆ, âˆ}, we
denote by Iğ‘‹ the set of intervals with endpoints in ğ‘‹ , and
simply write I for IRâˆª{âˆ’âˆ,âˆ}. An ğ‘›-dimensional box is the
Cartesian product of ğ‘› intervals.

We can lift functions on real numbers to intervals as fol-

lows: for each ğ‘“ : Rğ‘› â†’ R we define ğ‘“ I : Iğ‘› â†’ I by

ğ‘“ I ([ğ‘1, ğ‘1], . . . , [ğ‘ğ‘›, ğ‘ğ‘›]) := [inf ğ¹, sup ğ¹ ]

where ğ¹ := ğ‘“ ([ğ‘1, ğ‘1], . . . , [ğ‘ğ‘›, ğ‘ğ‘›]). For common functions
like +, âˆ’, Ã—, | Â· |, min, max, and monotonically increasing
: R â†’ R, their interval-lifted
or decreasing functions ğ‘“
counterparts can easily be computed, from the values of the
original function on just the endpoints of the input interval.
For example, addition lifts to [ğ‘1, ğ‘1] +I [ğ‘2, ğ‘2] = [ğ‘1 +ğ‘2, ğ‘1 +
ğ‘2]; similarly for multiplication Ã—I.

3.2 Interval Traces and Interval SPCF
In our interval interpretation, probabilistic programs are run
on interval traces. An interval trace, âŸ¨ğ¼1, . . . , ğ¼ğ‘›âŸ© âˆˆ TI
:=
(cid:208)ğ‘› âˆˆN(I[0,1])ğ‘›, is a finite sequence of intervals ğ¼1, . . . , ğ¼ğ‘›, each
with endpoints between 0 and 1. To distinguish ordinary
traces ğ’” âˆˆ T from interval traces ğ’• âˆˆ TI, we call the former
concrete traces.

We define the refinement relation âŠ³ between concrete
and interval traces as follows: for ğ’” = âŸ¨ğ‘Ÿ1, . . . , ğ‘Ÿğ‘›âŸ© âˆˆ T and
ğ’• = âŸ¨ğ¼1, . . . , ğ¼ğ‘šâŸ© âˆˆ TI, we define ğ’” âŠ³ ğ’• just if ğ‘› = ğ‘š and
for all ğ‘–, ğ‘Ÿğ‘– âˆˆ ğ¼ğ‘– . For each interval trace ğ’•, we denote by
ğ’•

:= {ğ’” âˆˆ T | ğ’” âŠ³ ğ’• } the set of all refinements of ğ’•.
(cid:76)
(cid:77)
To define a reduction of a term on an interval trace, we
extend SPCF with interval literals [ğ‘, ğ‘], which replace the
literals ğ‘Ÿ but are still considered values of type R. In fact, ğ‘Ÿ

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

((ğœ†ğ‘¥ .ğ‘€)ğ‘‰ , ğ’•, ğ‘¤) â†’I (ğ‘€ [ğ‘‰ /ğ‘¥], ğ’•, ğ‘¤)

(sample, ğ¼ ğ’•, ğ‘¤) â†’I (ğ¼, ğ’•, ğ‘¤)

((ğœ‡ğœ‘

ğ‘¥ . ğ‘€)ğ‘‰ , ğ’•, ğ‘¤) â†’I (ğ‘€ [ğ‘‰ /ğ‘¥, (ğœ‡ğœ‘

ğ‘¥ . ğ‘€)/ğœ‘], ğ’•, ğ‘¤)

ğ‘ â‰¤ 0
(if( [ğ‘, ğ‘], ğ‘ , ğ‘ƒ), ğ’•, ğ‘¤) â†’I (ğ‘ , ğ’•, ğ‘¤)
ğ‘ > 0
(if ( [ğ‘, ğ‘], ğ‘ , ğ‘ƒ), ğ’•, ğ‘¤) â†’I (ğ‘ƒ, ğ’•, ğ‘¤)

(ğ‘“ (ğ¼1, . . . , ğ¼ |ğ‘“ |), ğ’•, ğ‘¤) â†’I (ğ‘“ I (ğ¼1, . . . , ğ¼ |ğ‘“ |), ğ’•, ğ‘¤)

ğ‘ â‰¥ 0
(score([ğ‘, ğ‘]), ğ’•, ğ‘¤) â†’I ([ğ‘, ğ‘], ğ’•, ğ‘¤ Ã—I [ğ‘, ğ‘])

(ğ‘…, ğ’•, ğ‘¤) â†’I (ğ‘€, ğ’• â€², ğ‘¤ â€²)
(ğ¸ [ğ‘…], ğ’•, ğ‘¤) â†’I (ğ¸ [ğ‘€], ğ’• â€², ğ‘¤ â€²)

Figure 3. Interval reduction rules for (interval) SPCF (â†’I).

can be read as an abbreviation for [ğ‘Ÿ, ğ‘Ÿ ]. We call such terms
interval terms, and the resulting language Interval SPCF.
Reduction. The interval-based reduction â†’I now oper-
ates on configurations (ğ‘€, ğ’•, ğ‘¤) of interval terms ğ‘€, interval
traces ğ’• âˆˆ TI, and interval weights ğ‘¤ âˆˆ IRâ‰¥0âˆª{âˆ}. The re-
dexes and evaluation contexts of SPCF extend naturally to
interval terms. The reduction rules are given in Fig. 3.6

Given a program âŠ¢ ğ‘ƒ : R, the reduction relation â†’I al-
ğ‘ƒ : TI â†’

lows us to define the interval weight function (wtI
I
ğ‘ƒ : TI â†’ I) by:
IRâ‰¥0âˆª{âˆ}) and interval value function (val
if (ğ‘ƒ, ğ’•, 1) â†’âˆ—
otherwise,

I
ğ‘ƒ (ğ’•) :=
wt

I (ğ¼, âŸ¨âŸ©, ğ‘¤)

I
ğ‘ƒ (ğ’•) :=
val

if (ğ‘ƒ, ğ’•, 1) â†’âˆ—
otherwise.

I (ğ¼, âŸ¨âŸ©, ğ‘¤)

It is not difficult to prove the following relationship be-

tween standard and interval reduction.

Lemma 3.1. Let âŠ¢ ğ‘ƒ : R be a program. For any interval trace
ğ’• and concrete trace ğ’” âŠ³ ğ’•, we have wtğ‘ƒ (ğ’”) âˆˆ wtI
ğ‘ƒ (ğ’•) and
valğ‘ƒ (ğ’”) âˆˆ val

I
ğ‘ƒ (ğ’•) (provided valğ‘ƒ (ğ’”) is defined).

3.3 Bounds from Interval Traces

Lower bounds. How can we use this interval trace seman-
tics to obtain lower bounds on
? We need a few defini-
tions. Two intervals [ğ‘1, ğ‘1], [ğ‘2, ğ‘2] âˆˆ I are called almost
disjoint if ğ‘1 â‰¤ ğ‘2 or ğ‘2 â‰¤ ğ‘1. Interval traces âŸ¨ğ¼1, . . . , ğ¼ğ‘šâŸ© and
âŸ¨ğ½1, . . . , ğ½ğ‘›âŸ© âˆˆ TI are called compatible if there is an index
ğ‘– âˆˆ {1, . . . , min(ğ‘š, ğ‘›)} such that ğ¼ğ‘– and ğ½ğ‘– are almost disjoint.

ğ‘ƒ
(cid:74)

(cid:75)

6For conditionals, the interval bound is not always precise enough to decide
which branch to take, so the reduction can get stuck if ğ‘ â‰¤ 0 < ğ‘. We could
include additional rules to overapproximate the branching behaviour (see
Appendix A.4). But the rules given here simplify the presentation and are
sufficient to prove soundness and completeness.

(cid:40)ğ‘¤
[0, âˆ]
(cid:40)ğ¼
[âˆ’âˆ, âˆ]

A set of interval traces is called compatible if its elements are
pairwise compatible. We define the volume of an interval
trace ğ’• = âŸ¨[ğ‘1, ğ‘1], . . . , [ğ‘ğ‘›, ğ‘ğ‘›]âŸ© as vol(ğ’•) := (cid:206)ğ‘›
ğ‘–=1 (ğ‘ğ‘– âˆ’ ğ‘ğ‘– ).
Let T âŠ† TI be a countable and compatible set of interval

traces. Define the lower bound on

by
(cid:75)
ğ‘ƒ (ğ’•)) Â· (cid:2)val
I
vol(ğ’•) Â· (min wt

ğ‘ƒ
(cid:74)

I

ğ‘ƒ (ğ’•) âŠ† ğ‘ˆ (cid:3)

lowerBdT

ğ‘ƒ (ğ‘ˆ ) :=

âˆ‘ï¸

ğ’• âˆˆ T

for ğ‘ˆ âˆˆ Î£R. That is, we sum over each interval trace in
T whose value is guaranteed to be in ğ‘ˆ , weighted by its
volume and the lower bound of its weight interval. Note
that, in general, lowerBdT
ğ‘ƒ is not a measure, but merely a
superadditive measure.7

Upper bounds. For upper bounds, we require the notion
of a set of interval traces being exhaustive, which is easiest
to express in terms of infinite traces. Let Tâˆ := [0, 1]ğœ” be
the set of infinite traces. Every interval trace ğ’• covers the set
of infinite traces with a prefix contained in ğ’•, i.e. cover (ğ’•) :=
Ã— Tâˆ (where the Cartesian product Ã— can be viewed
ğ’•
(cid:76)
as trace concatenation). A countable set of (finite) interval
traces T âŠ† TI is called exhaustive if (cid:208)
ğ’• âˆˆ T cover (ğ’•) covers
ğ’• âˆˆ T cover (ğ’•)) = 0.8 Phrased
almost all of Tâˆ, i.e. ğœ‡Tâˆ (Tâˆ \ (cid:208)
differently, almost all concrete traces must have a finite prefix
that is contained in some interval trace in T . Therefore, the
analysis in the interval semantics on T covers the behaviour
on almost all concrete traces (in the original semantics).

(cid:77)

2, 1]...ğ‘›, [0, 1

Example 3.1. (i) The singleton set {âŸ¨[0, 1], [0, 0.6]âŸ©} is not
exhaustive as, e.g. all infinite traces âŸ¨ğ‘Ÿ1, ğ‘Ÿ2, . . . âŸ© with ğ‘Ÿ2 > 0.6
are not covered. (ii) The set {âŸ¨[0, 0.6]âŸ©, âŸ¨[0.3, 1]âŸ©} is exhaus-
tive, but not compatible. (iii) Define T1 := {âŸ¨[ 1
3 ]âŸ© |
ğ‘› âˆˆ N} and T2 := {âŸ¨[ 1
2 ]âŸ© | ğ‘› âˆˆ N} where ğ‘¥ ...ğ‘› de-
notes ğ‘›-fold repetition of ğ‘¥. T1 is compatible but not exhaus-
tive. For example, it doesnâ€™t cover the set [ 1
2 ) Ã— Tâˆ,
3, 1
i.e. all traces âŸ¨ğ‘Ÿ1, ğ‘Ÿ2, . . . âŸ© where ğ‘Ÿ1 âˆˆ [ 1
2 ). T2
is compatible and exhaustive (the set of non-covered traces
( 1
2, 1]ğœ” has measure 0).
Let T âŠ† TI be a countable and exhaustive set of interval

2, 1] Ã— ( 1
3, 1
2, 1] and ğ‘Ÿ2 âˆˆ ( 1

2, 1]...ğ‘›, [0, 1

traces. Define the upper bound on
by
ğ‘ƒ
(cid:74)
(cid:75)
âˆ‘ï¸
ğ‘ƒ (ğ’•)) Â· (cid:2)val
I
upperBdT
vol(ğ’•) Â· (sup wt

ğ‘ƒ (ğ‘ˆ ) :=

I

ğ‘ƒ (ğ’•) âˆ© ğ‘ˆ â‰  âˆ…(cid:3)

ğ’• âˆˆ T

for ğ‘ˆ âˆˆ Î£R. That is, we sum over each interval trace in T
whose value may be in ğ‘ˆ , weighted by its volume and the
upper bound of its weight interval. Note that upperBdT
ğ‘ƒ is
not a measure but only a subadditive measure.9
7A superadditive measure ğœ‡ on (Î©, Î£Î©) is a measure, except that ğœ-additivity
is replaced by ğœ-superadditivity: ğœ‡ ((cid:208)ğ‘–âˆˆN ğ‘ˆğ‘– ) â‰¥ (cid:205)ğ‘–âˆˆN ğœ‡ (ğ‘ˆğ‘– ) for a countable,
pairwise disjoint family (ğ‘ˆğ‘– )ğ‘–âˆˆN âˆˆ Î£Î©.
8The ğœ-algebra on Tâˆ is defined as the smallest ğœ-algebra that contains all
sets ğ‘ˆ Ã— Tâˆ where ğ‘ˆ âˆˆ Î£ [0,1]ğ‘› for some ğ‘› âˆˆ N. The measure ğœ‡Tâˆ
is the
unique measure with ğœ‡Tâˆ (ğ‘ˆ Ã— Tâˆ) = ğœ†ğ‘› (ğ‘ˆ ) when ğ‘ˆ âˆˆ Î£ [0,1]ğ‘› .
9A subadditive measure ğœ‡ on (Î©, Î£Î©) is a measure, except that ğœ-additivity
is replaced by ğœ-subadditivity: ğœ‡ ((cid:208)ğ‘–âˆˆN ğ‘ˆğ‘– ) â‰¤ (cid:205)ğ‘–âˆˆN ğœ‡ (ğ‘ˆğ‘– ) for a countable,
pairwise disjoint family (ğ‘ˆğ‘– )ğ‘–âˆˆN âˆˆ Î£Î©.

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

4 Soundness and Completeness
4.1 Soundness
We show that the two bounds described above are sound, in
the following sense.

Theorem 4.1 (Sound lower bounds). Let T be a countable
and compatible set of interval traces and âŠ¢ ğ‘ƒ : R a program.
Then lowerBdT
ğ‘ƒ â‰¤
Proof. For any ğ‘ˆ âˆˆ Î£R, we have:

ğ‘ƒ
(cid:74)

(cid:75)

.

lowerBdT

ğ‘ƒ (ğ‘ˆ ) =

âˆ‘ï¸

I
vol(ğ’•)(min wt

ğ‘ƒ (ğ’•)) (cid:2)val

I

ğ‘ƒ (ğ’•) âŠ† ğ‘ˆ (cid:3)

ğ’• âˆˆT
âˆ‘ï¸

âˆ«

I
(min wt

ğ‘ƒ (ğ’•)) (cid:2)val

I

ğ‘ƒ (ğ’•) âŠ† ğ‘ˆ (cid:3) dğ’”

ğ’•

(cid:77)

(cid:76)
âˆ«

ğ’• âˆˆT
âˆ‘ï¸

ğ’•

(cid:76)

(cid:77)

ğ’• âˆˆT
âˆ«

wtğ‘ƒ (ğ’”) (cid:2)valğ‘ƒ (ğ’”) âˆˆ ğ‘ˆ (cid:3) dğ’”

wtğ‘ƒ (ğ’”) (cid:2)valğ‘ƒ (ğ’”) âˆˆ ğ‘ˆ (cid:3) dğ’”

ğ’• âˆˆT

ğ’•

(cid:76)

(cid:77)

wtğ‘ƒ (ğ’”) (cid:2)valğ‘ƒ (ğ’”) âˆˆ ğ‘ˆ (cid:3) dğ’” =

(cid:208)
âˆ«

T

ğ‘ƒ
(cid:74)

(cid:75)

(1)

(2)

(ğ‘ˆ )

(3)

=

â‰¤

=

â‰¤

ğ’• âˆˆT

where Eq. (1) follows from Lemma 3.1, Eq. (2) from compati-
bility, and Eq. (3) from (cid:208)
â–¡
ğ’•

âŠ† T.

ğ‘ƒ
(cid:74)

â‰¤ upperBdT
ğ‘ƒ .

(cid:76)
(cid:77)
Theorem 4.2 (Sound upper bounds). Let T be a countable
and exhaustive set of interval traces and âŠ¢ ğ‘ƒ : R a program.
Then
Proof sketch. The formal proof is similar to the soundness
proof for the lower bound in Theorem 4.1, but needs an in-
finite trace semantics [16] for probabilistic programs and
is given in Appendix C.1. The idea is that each interval
trace ğ’• summarises all infinite traces starting with
, i.e. all
(cid:77)
traces in cover (ğ’•). Exhaustivity ensures that almost all infi-
â–¡
nite traces are â€œcoveredâ€.

(cid:75)

(cid:76)

ğ’•

4.2 Completeness
The soundness results for upper and lower bounds allow us
to derive bounds on the denotation of a program. One would
expect that a finer partition of interval traces will yield more
precise bounds. In this section, we show that for a program
ğ‘ƒ and an interval ğ¼ âˆˆ I, the approximations lowerBdT
ğ‘ƒ (ğ¼ )
and upperBdT
(ğ¼ )
ğ‘ƒ
(cid:74)
for suitable T . However, this is only possible under certain
assumptions.

ğ‘ƒ (ğ¼ ) can in fact come arbitrarily close to

(cid:75)

Assumption 1: use of sampled values. Interval arith-
metic is imprecise if the same value is used more than once:
consider, for instance, let ğ‘  = sample in if (ğ‘  âˆ’ ğ‘ , 0, 1) which
deterministically evaluates to 0. However, in interval arith-
metic, if ğ‘¥ is approximated by an interval [ğ‘, ğ‘] with ğ‘ < ğ‘,
the difference ğ‘¥ âˆ’ ğ‘¥ is approximated as [ğ‘ âˆ’ ğ‘, ğ‘ âˆ’ ğ‘], which
always contains both positive and negative values. So no
non-trivial interval trace can separate the two branches.

To avoid this, we could consider a call-by-name semantics
(as done in [4]) where sample values can only be used once
by definition. However, many of our examples cannot be
expressed in the call-by-name setting, so we instead propose
a less restrictive criterion to guarantee completeness for
call-by-value: we allow sample values to be used more than
once, but at most once in the guard of each conditional, at
most once in each score expression, and at most once in the
return value. While this prohibits terms like the one above, it
allows, e.g. let ğ‘  = sample in if (ğ‘ , ğ‘“ (ğ‘ ), ğ‘”(ğ‘ )). This sufficient
condition is formalised in Appendix C.3. Most examples we
encountered in the literature satisfy this assumption.

Assumption 2: primitive functions. In addition, we re-
quire mild assumptions on the primitive functions, called
boxwise continuity and interval separability.

We need to be able to approximate a programâ€™s weight
function by step functions in order to obtain tight bounds on
its integral. A function ğ‘“ : Rğ‘› â†’ R is boxwise continuous
if it can be written as the countable union of continuous
functions on boxes, i.e. if there is a countable union of pair-
wise almost disjoint boxes ğµğ‘– such that (cid:208) ğµğ‘– = Rğ‘› and the
restriction ğ‘“ |ğµğ‘– is continuous for each ğµğ‘– .

Furthermore, we need to approximate preimages. For-
mally, we say that ğ´ is a tight subset of ğµ (written ğ´ â‹ ğµ) if
ğ´ âŠ† ğµ and ğµ \ ğ´ is a null set. A function ğ‘“ : Rğ‘› â†’ R is called
interval separable if for every interval [ğ‘, ğ‘] âˆˆ I, there is
a countable set B of boxes in Rğ‘› that tightly approximates
the preimage, i.e. (cid:208) B â‹ ğ‘“ âˆ’1([ğ‘, ğ‘]). A sufficient condition
for checking this is the following. If ğ‘“ is boxwise continuous
and preimages of points have measure zero, then ğ‘“ is already
interval separable (cf. Lemma C.4).

We assume the set F of primitive functions is closed under
composition and each ğ‘“ âˆˆ F is boxwise continuous and
interval separable.

The completeness theorem. Using these two assumptions,

we can state completeness of our interval semantics.

Theorem 4.3 (Completeness of interval approximations).
Let ğ¼ âˆˆ I and âŠ¢ ğ‘ƒ : R be an almost surely terminating program
satisfying the two assumptions discussed above. Then, for all
ğœ– > 0, there is a countable set of interval traces T âŠ† TI that is
compatible and exhaustive such that

ğ‘ƒ
(cid:74)

upperBdT

ğ‘ƒ (ğ¼ ) âˆ’ ğœ– â‰¤

(ğ¼ ) â‰¤ lowerBdT

ğ‘ƒ (ğ¼ ) + ğœ–.

(cid:75)
Proof sketch. We consider each branching path through the
program separately. The set of relevant traces for a given
path is a preimage of intervals under compositions of interval
separable functions, hence can essentially be partitioned into
boxes. By boxwise continuity, we can refine this partition
such that the weight function is continuous on each box. To
approximate the integral, we pass to a refined partition again,
essentially computing Riemann sums. The latter converge

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

to the Riemann integral, which agrees with the Lebesgue
â–¡
integral under our conditions, as desired.

For the lower bound, we can actually derive ğœ–-close bounds

using only finitely many interval traces:

ğ‘ƒ
(cid:74)

(cid:75)

Corollary 4.4. Let ğ¼ âˆˆ I and âŠ¢ ğ‘ƒ : R be as in Theorem 4.3.
There is a sequence of finite, compatible sets of interval traces
T1, T2, . . . âŠ† TI s.t. limğ‘›â†’âˆ lowerBdTğ‘›

ğ‘ƒ (ğ¼ ) =

(ğ¼ ).

For the upper bound, a restriction to finite sets T of in-
terval traces is, in general, not possible: if the weight func-
tion for a program is unbounded, it is also unbounded on
some ğ’• âˆˆ T . Then wtI
ğ‘ƒ (ğ’•) is an infinite interval, implying
upperBdT
ğ‘ƒ (ğ¼ ) = âˆ (see Example C.3 for details). Despite the
(theoretical) need for countably infinite many interval traces,
we can, in many cases, compute finite upper bounds by mak-
ing use of an interval-based static approximation, formalised
as a type system in the next section.

5 Weight-aware Interval Type System
To obtain sound bounds on the denotation with only finitely
many interval traces, we present an interval-based type sys-
tem that can derive static bounds on a program. Crucially,
our type-system is weight-aware: we bound not only the re-
turn value of a program but also the weight of an execution.
Our analyzer GuBPI uses it for two purposes. First, it allows
us to derive upper bounds even for areas of the sample space
not covered with interval traces. Second, we can use our
analysis to derive a finite (and sound) approximation of the
infinite number of symbolic execution paths of a program
(more details are given in Section 6). Note that the bounds
inferred by our system are interval bounds, which allow for
seamless integration with our interval trace semantics. In
this section, we present the interval type system and sketch
a constraint-based type inference method.

5.1 Interval Types
We define interval types by the following grammar:

ğœ := ğ¼ | ğœ â†’ A

A :=

(cid:27)

(cid:26)ğœ
ğ¼

where ğ¼ âˆˆ I is an interval. For readers familiar with refine-
ment types, it is easiest to view the type ğœ = ğ¼ as the refine-
ment type {ğ‘¥ : R | ğ‘¥ âˆˆ ğ¼ }. The definition of the syntactic
category A by mutual recursion with ğœ gives a bound on the
weight of the execution. We call a type ğœ weightless and a
type A weighted. The following examples should give some
intuition about the types.

Example 5.1. Consider the example term

(cid:0)ğœ‡ğœ‘

ğ‘¥ . 5 Ã— ğ‘¥ âŠ•0.5 sigm(ğœ‘ ğ‘¥ + score sample)(cid:1) (4 Ã— sample)
where sigm : R â†’ [0, 1] is the sigmoid function. In our type
system, this term can be typed with the weighted type (cid:26)[0, 20]
(cid:27),
[0, 1]
which indicates that any terminating execution of the term

ğ‘¥ : ğœ âˆˆ Î“
(cid:27)
(cid:26)ğœ
1

Î“ âŠ¢ ğ‘¥ :

Î“ âŠ¢ ğ‘€ : A A âŠ‘A B
Î“ âŠ¢ ğ‘€ : B

Î“; ğœ‘ : ğœ â†’ A; ğ‘¥ : ğœ âŠ¢ ğ‘€ : A

Î“ âŠ¢ ğœ‡ğœ‘

ğ‘¥ . ğ‘€ :

(cid:27)

(cid:26)ğœ â†’ A
1

Î“; ğ‘¥ : ğœ âŠ¢ ğ‘€ : A
(cid:26)ğœ â†’ A
1

Î“ âŠ¢ ğœ†ğ‘¥ .ğ‘€ :

(cid:27)

Î“ âŠ¢ ğ‘€ :

(cid:27)

(cid:26) ğœ2
[ğ‘’, ğ‘“ ]

ğœ1 â†’

ï£±ï£´ï£´ï£²
ï£´ï£´
ï£³
Î“ âŠ¢ ğ‘€ğ‘ :

[ğ‘, ğ‘ ]
(cid:26)

ï£¼ï£´ï£´ï£½
ï£´ï£´
ï£¾

ğœ2
[ğ‘, ğ‘ ] Ã—I [ğ‘, ğ‘‘ ] Ã—I [ğ‘’, ğ‘“ ]

(cid:27)

Î“ âŠ¢ ğ‘ :

(cid:27)

(cid:26) ğœ1
[ğ‘, ğ‘‘ ]

Î“ âŠ¢ ğ‘€ :

(cid:27)

(cid:26) [_, _]
[ğ‘, ğ‘ ]

Î“ âŠ¢ ğ‘ :

(cid:27)

(cid:26) ğœ
[ğ‘, ğ‘‘ ]

Î“ âŠ¢ ğ‘ƒ :

(cid:27)

(cid:26) ğœ
[ğ‘, ğ‘‘ ]

Î“ âŠ¢ ğ‘Ÿ :

(cid:27)

(cid:26) [ğ‘Ÿ, ğ‘Ÿ ]
1

Î“ âŠ¢ if (ğ‘€, ğ‘ , ğ‘ƒ ) :

(cid:26)

ğœ
[ğ‘, ğ‘ ] Ã—I [ğ‘, ğ‘‘ ]

(cid:27)

Î“ âŠ¢ ğ‘€ :

(cid:27)

(cid:26) [ğ‘, ğ‘ ]
[ğ‘, ğ‘‘ ]

Î“ âŠ¢ sample :

(cid:27)

(cid:26) [0, 1]
1

Î“ âŠ¢ score(ğ‘€) :

(cid:26)

[ğ‘, ğ‘ ] âŠ“ [0, âˆ]
[ğ‘, ğ‘‘ ] Ã—I (cid:0) [ğ‘, ğ‘ ] âŠ“ [0, âˆ](cid:1)

(cid:27)

Î“ âŠ¢ ğ‘€1 :

(cid:27)

(cid:26) [ğ‘1, ğ‘1 ]
[ğ‘1, ğ‘‘1 ]

Î“ âŠ¢ ğ‘“ (ğ‘€1, . . . , ğ‘€|ğ‘“ |) :

(cid:27)

Â· Â· Â·

Î“ âŠ¢ ğ‘€|ğ‘“ | :

(cid:26) [ğ‘|ğ‘“ |, ğ‘|ğ‘“ | ]
[ğ‘ |ğ‘“ |, ğ‘‘|ğ‘“ | ]
(cid:41)
(cid:40)ğ‘“ I ( [ğ‘1, ğ‘1 ], . . . , [ğ‘|ğ‘“ |, ğ‘|ğ‘“ | ])

(Ã—I) |ğ‘“ |

ğ‘–=1 [ğ‘ğ‘–, ğ‘‘ğ‘– ]

Figure 4. Weight-aware interval type system for SPCF. We
abbreviate 1 := [1, 1].

reduces to a value (a number) within [0, 20] and the weight
of any such execution lies within [0, 1].

Example 5.2. We consider the fixpoint subexpression of
the pedestrian example in Example 1.1 which is
ğœ‡ğœ‘
ğ‘¥ .if (ğ‘¥, 0, (cid:0)ğœ†step.step + ğœ‘ ((ğ‘¥ +step) âŠ•0.5 (ğ‘¥ âˆ’step))(cid:1)sample).

(cid:27)

ï£¼ï£´ï£´ï£½
ï£´ï£´
ï£¾

[1, 1]

[ğ‘, ğ‘] â†’

(cid:26)[0, âˆ]
[1, 1]

Using the typing rules (defined below), we can infer the
for any ğ‘, ğ‘. This type indicates that any
type ï£±ï£´ï£´ï£²
ï£´ï£´
ï£³

terminating execution reduces to a function value (of simple
type R â†’ R) with weight within [1, 1]. If this function
value is then called on a value within [ğ‘, ğ‘], any terminating
execution reduces to a value within [0, âˆ] with a weight
within [1, 1].

Subtyping. The partial order on intervals naturally ex-
tends to our type system. For base types ğ¼1 and ğ¼2, we define
ğ¼1 âŠ‘ğœ ğ¼2 just if ğ¼1 âŠ‘ ğ¼2, where âŠ‘ is interval inclusion. We then
extend this via:

ğœ2 âŠ‘ğœ ğœ1
A1 âŠ‘A A2
ğœ1 â†’ A1 âŠ‘ğœ ğœ2 â†’ A2

ğœ1 âŠ‘ğœ ğœ2
(cid:26)ğœ1
(cid:27)
ğ¼1

âŠ‘A

ğ¼1 âŠ‘ ğ¼2
(cid:26)ğœ2
(cid:27)
ğ¼2

Note that in the case of weighted types, the subtyping re-
quires not only that the weightless types be subtype-related
(ğœ1 âŠ‘ğœ ğœ2) but also that the weight bound be refined ğ¼1 âŠ‘ ğ¼2.
It is easy to see that both âŠ‘A and âŠ‘ğœ are partial orders on
types with the same underlying base type.

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

5.2 Type System
As for the interval-based semantics, we assume that every
primitive operation ğ‘“ : Rğ‘› â†’ R has an overapproximating
interval abstraction ğ‘“ I : Iğ‘› â†’ I (cf. Section 3.1). Interval
typing judgments have the form Î“ âŠ¢ ğ‘€ : A where Î“ is a
typing context mapping variables to types ğœ. They are given
via the rules in Fig. 4. Our system is sound in the following
sense (which we here only state for first-order programs).

Theorem 5.1. Let âŠ¢ ğ‘ƒ : R be a simply-typed program. If
âŠ¢ ğ‘ƒ : (cid:26)[ğ‘, ğ‘]
and (ğ‘ƒ, ğ’”, 1) â†’âˆ— (ğ‘Ÿ, âŸ¨âŸ©, ğ‘¤) for some ğ’” âˆˆ T and
[ğ‘, ğ‘‘]
ğ‘Ÿ, ğ‘¤ âˆˆ R, then ğ‘Ÿ âˆˆ [ğ‘, ğ‘] and ğ‘¤ âˆˆ [ğ‘, ğ‘‘].

(cid:27)

Note that the bounds derived by our type system only
refer to terminating executions, i.e. they are partial correct-
ness statements. Theorem 5.1 formalises the intuition of an
interval type, i.e. every type derivation in our system bounds
both the returned value (in typical refinement-type fashion
[24]) and the weight of this derivation. Our type system also
comes with a weak completeness statement: for each term,
we can derive some bounds in our system.

Proposition 5.2. Let âŠ¢ ğ‘ƒ : ğ›¼ be a simply-typed program.
There exists a weighted interval type A such that âŠ¢ ğ‘ƒ : A.

5.3 Constraint-based Type Inference
In this section, we briefly discuss the automated type infer-
ence in our system, as needed in our tool GuBPI. For space
reasons, we restrict ourselves to an informal overview (see
Appendix D for a full account).

Given a program ğ‘ƒ, we can derive the symbolic skeleton
of a type derivation (the structure of which is determined by
ğ‘ƒ), where each concrete interval is replaced by a placeholder
variable. The validity of a typing judgment within this skele-
ton can then be encoded as constraints. Crucially, as we work
in the fixed interval domain and the subtyping structure âŠ‘A
is compositional, they are simple constraints over the place-
holder variables in the abstract interval domain. Solving the
resulting constraints naÃ¯vely might not terminate since the
interval abstract domain is not chain-complete. Instead, we
approximate the least fixpoint (where the fixpoint denotes a
solution to the constraints) using widening, a standard ap-
proach to ensure termination of static analysis on domains
with infinite chains [13, 14]. This is computationally much
cheaper compared to, say, types with general first-order re-
finements where constraints are typically phrased as con-
strained Horn clauses (see e.g. [11]). This gain in efficiency
is crucial to making our GuBPI tool practical.

6.1 Symbolic Execution
The starting point of our analysis is a symbolic exploration of
the term in question [10, 28, 41]. For space reasons we only
give an informal overview of the approach. A detailed and
formal discussion can be found in Appendix B.

The idea of symbolic execution is to treat outcomes of
sample expressions fully symbolically: each sample evalu-
ates to a fresh variable (ğ›¼1, ğ›¼2, . . . ), called sample variable.
The result of symbolic execution is thus a symbolic value: a
term consisting of sample variables and delayed primitive
function applications. We postpone branching decisions and
the weighting with score expressions because the value in
question is symbolic. During execution, we therefore ex-
plore both branches of a conditional and keep track of the
(symbolic) conditions on the sample variables that need to
hold in the current branch. Similarly, we record the (sym-
bolic) values of score expressions. Formally, our symbolic
execution operates on symbolic configurations of the form
ğœ“ = (M, ğ‘›, Î”, Î) where M is a symbolic term containing
sample variables instead of sample outcomes; ğ‘› âˆˆ N is a
natural number used to obtain fresh sample variables; Î” is a
list of symbolic constraints of the form V âŠ²âŠ³ ğ‘Ÿ , where V is
a symbolic value, ğ‘Ÿ âˆˆ R and âŠ²âŠ³ âˆˆ {â‰¤, <, >, â‰¥}, to keep track
of the conditions for the current execution path; and Î is
a set of values that records all symbolic values of score ex-
pressions encountered along the current path. The symbolic
reduction relation (cid:123) includes the following key rules.

(sample, ğ‘›, Î”, Î) (cid:123) (ğ›¼ğ‘›+1, ğ‘› + 1, Î”, Î)
(if (V, N, P)), ğ‘›, Î”, Î) (cid:123) (N, ğ‘›, Î” âˆª {V â‰¤ 0}, Î)
(if (V, N, P)), ğ‘›, Î”, Î) (cid:123) (P, ğ‘›, Î” âˆª {V > 0}, Î)
(score(V), ğ‘›, Î”, Î) (cid:123) (V, ğ‘›, Î” âˆª {V â‰¥ 0}, Î âˆª {V})
That is, we replace sample outcomes with fresh sample vari-
ables (first rule), explore both paths of a conditional (second
and third rule), and record all score values (fourth rule).

Example 6.1. Consider the symbolic execution of Exam-
ple 1.1 where the first step moves the pedestrian towards
their home (taking the right branch of âŠ•0.5) and the second
step moves away from their home (the left branch of âŠ•0.5).
We reach a configuration (M, 5, Î”, Î) where M is
score(cid:0) pdf Normal(1.1,0.1)
Here ğ›¼1 is the initial sample for start; ğ›¼2, ğ›¼4 the two samples
of step; and ğ›¼3, ğ›¼5 the samples involved in the âŠ•0.5 operator.
The fixpoint ğœ‡ğœ‘
ğ‘¥ .N is already given in Example 5.2, Î = âˆ…
and Î” = {3ğ›¼1 > 0, ğ›¼3 > 1

ğ‘¥ .N )(3ğ›¼1 âˆ’ğ›¼2 +ğ›¼4)(cid:1)(cid:1); 3ğ›¼1.

2, 3ğ›¼1 âˆ’ğ›¼2 > 0, ğ›¼5 â‰¤ 1

(cid:0)ğ›¼2 +ğ›¼4 + (ğœ‡ğœ‘

2 }.

6 Symbolic Execution and GuBPI
In this section, we describe the overall structure of our tool
GuBPI (gubpi-tool.github.io), which builds upon symbolic
execution. We also outline how the interval-based semantics
can be accelerated for programs containing linear subexpres-
sions.

For a symbolic value V using sample variables ğ›¼ = ğ›¼1,
. . . , ğ›¼ğ‘› and ğ’” âˆˆ [0, 1]ğ‘›, we write V [ğ’”/ğ›¼] âˆˆ R for the substi-
tution of concrete values in ğ’” for the sample variables. Call
a symbolic configuration of the form Î¨ = (V, ğ‘›, Î”, Î) (i.e. a
configuration that has reached a symbolic value V) a sym-
bolic path. We write symPaths(ğœ“ ) for the (countable) set of

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Algorithm 1 Symbolic Analysis in GuBPI.

1: Input: Program âŠ¢ ğ‘ƒ : R, depth limit ğ· âˆˆ N, and ğ¼ âˆˆ I
2: ğœ“init := (ğ‘ƒ, 0, âˆ…, âˆ…); ğ‘† := {(ğœ“init, 0)};ğ‘‡ := âˆ…
3: while âˆƒ(ğœ“, depth) âˆˆ ğ‘† do
4:

if ğœ“ has terminated then

ğ‘‡ := ğ‘‡ âˆª {ğœ“ }; ğ‘† := ğ‘† \ {(ğœ“, depth)}

else if ğœ“ contains no fixpoints or depth â‰¤ ğ· then

ğ‘† := ğ‘† \ {(ğœ“, depth)}
for ğœ“ â€² with ğœ“ (cid:123) ğœ“ â€² do

ğ‘† := ğ‘† âˆª {(ğœ“ â€², depth + 1)}

5:
6:
7:
8:
9:
10:
11:
12: return (cid:2) (cid:205)Î¨âˆˆğ‘‡

else

ğ‘† := (ğ‘† \ {(ğœ“, depth)}) âˆª {(approxFix (ğœ“ ), depth)}

lb (ğ¼ ), (cid:205)Î¨âˆˆğ‘‡

Î¨

(cid:74)

(cid:75)

ub (ğ¼ )(cid:3)

Î¨

(cid:74)

(cid:75)

symbolic paths reached when evaluating from configuration
ğœ“ . Given a symbolic path Î¨ = (V, ğ‘›, Î”, Î) and a set ğ‘ˆ âˆˆ Î£R,
we define the denotation along Î¨, written

(ğ‘ˆ ), as

âˆ«

[0,1]ğ‘›

(cid:2)V [ğ’”/ğ›¼] âˆˆ ğ‘ˆ (cid:3) (cid:214)
CâŠ²âŠ³ğ‘Ÿ âˆˆÎ”

Î¨
(cid:74)
(cid:2)C [ğ’”/ğ›¼] âŠ²âŠ³ ğ‘Ÿ (cid:3) (cid:214)
W âˆˆÎ

(cid:75)
W [ğ’”/ğ›¼] dğ’”,

i.e. the integral of the product of the score weights Î over the
traces of length ğ‘› where the result value is in ğ‘ˆ and all the
constraints Î” are satisfied. We can recover the denotation of
a program ğ‘ƒ (as defined in Section 2) from all its symbolic
paths starting from the configuration (ğ‘ƒ, 0, âˆ…, âˆ…).

Theorem 6.1. Let âŠ¢ ğ‘ƒ : R be a program and ğ‘ˆ âˆˆ Î£R. Then

ğ‘ƒ
(cid:74)

(cid:75)

(ğ‘ˆ ) = (cid:205)Î¨âˆˆsymPaths (ğ‘ƒ,0,âˆ…,âˆ…)

Î¨

(ğ‘ˆ ).

(cid:74)

(cid:75)

Analogously to interval SPCF (Section 3), we define sym-
bolic interval terms as symbolic terms that may contain
intervals (and similarly for symbolic interval values, sym-
bolic interval configurations, and symbolic interval paths).

6.2 GuBPI
With symbolic execution at hand, we can outline the struc-
ture of our analysis tool GuBPI (sketched in Algorithm 1).
GuBPIâ€™s analysis begins with symbolic execution of the in-
put term to accumulate a set of symbolic interval paths ğ‘‡ . If
a symbolic configuration ğœ“ has exceeded the user-defined
depth limit ğ· and still contains a fixpoint, we overapproxi-
mate all paths that extend ğœ“ to ensure a finite set ğ‘‡ . We ac-
complish this by using the interval type system (Section 5) to
overapproximate all fixpoint subexpressions, thereby obtain-
ing strongly normalizing terms (in line 11). Formally, given
a symbolic configuration ğœ“ = (M, ğ‘›, Î”, Î) we derive a typ-
ing judgment for the term M in the system from Section 5.
Each first-order fixpoint subterm is thus given a (weight-
(cid:27). We replace this fixpoint
(cid:26) [ğ‘, ğ‘‘]
less) type of the form [ğ‘, ğ‘] â†’
[ğ‘’, ğ‘“ ]
with ğœ†_.(cid:0)score([ğ‘’, ğ‘“ ]) ; [ğ‘, ğ‘‘](cid:1). We denote this operation on
configurations by approxFix (ğœ“ ) (it extends to higher-order
fixpoints as expected). Note that approxFix (ğœ“ ) is a symbolic
interval configuration.

(cid:26)[0, âˆ]
[1, 1]

(cid:27). The function approxFix replaces ğœ‡ğœ‘

Example 6.2. Consider the symbolic configuration given in
Example 6.1. As in Example 5.2 we infer the type of ğœ‡ğœ‘
ğ‘¥ .N to
be [âˆ’1, 4] â†’
ğ‘¥ .N with
ğœ†_.score([1, 1]); [0, âˆ]. By evaluating the resulting symbolic
interval configuration further, we obtain the symbolic in-
terval path (3ğ›¼1, 5, Î”, Î) where Î” is as in Example 6.1 and
Î = {pdf Normal(1.1,0.1) (ğ›¼2 +ğ›¼4 + [0, âˆ])}. Note that, in general,
the further evaluation of approxFix (ğœ“ ) can result in multiple
symbolic interval paths.

Afterwards, weâ€™re left with a finite set ğ‘‡ of symbolic in-
terval paths. Due to the presence of intervals, we cannot
define a denotation of such paths directly and instead define
lower and upper bounds. For a symbolic interval value V
that contains no sample variables, we define âŒœVâŒ âŠ† R as
the set of all values that the term can evaluate to by replac-
ing every interval [ğ‘, ğ‘] with some value ğ‘Ÿ âˆˆ [ğ‘, ğ‘]. Given
a symbolic interval path Î¨ = (V, ğ‘›, Î”, Î) and ğ‘ˆ âˆˆ Î£R we
define
lb (ğ‘ˆ ) by considering only those concrete traces
that fulfill the constraints in Î¨ for all concrete values in the
intervals and take the infimum over all scoring expressions:
âˆ«

Î¨

(cid:74)

(cid:75)

(cid:2)âŒœV [ğ’”/ğ›¼]âŒ âŠ† ğ‘ˆ (cid:3)(cid:214)
CâŠ²âŠ³ğ‘Ÿ âˆˆÎ”

(cid:2)âˆ€ğ‘¡ âˆˆ âŒœC [ğ’”/ğ›¼]âŒ.ğ‘¡ âŠ²âŠ³ ğ‘Ÿ (cid:3) (cid:214)
W âˆˆÎ

inf âŒœW [ğ’”/ğ›¼]âŒ dğ’”.

Î¨

Similarly, we define
âˆ«

(cid:74)
(cid:2)âŒœV [ğ’”/ğ›¼]âŒ âˆ© ğ‘ˆ â‰  âˆ…(cid:3)(cid:214)
CâŠ²âŠ³ğ‘Ÿ âˆˆÎ”

ub (ğ‘ˆ ) as
(cid:75)
(cid:2)âˆƒğ‘¡ âˆˆ âŒœC [ğ’”/ğ›¼]âŒ.ğ‘¡ âŠ²âŠ³ ğ‘Ÿ (cid:3) (cid:214)
W âˆˆÎ
Î¨

Î¨

We note that, if Î¨ contains no intervals,
is defined and we
(cid:75)
have
. We can now state the following
ub =
theorem that formalises the observation that approxFix (ğœ“ )
soundly approximates all symbolic paths that result from ğœ“ .

lb =

Î¨

Î¨

(cid:74)

(cid:74)

(cid:75)

(cid:74)

(cid:74)

(cid:75)

(cid:75)

supâŒœW [ğ’”/ğ›¼]âŒ dğ’”.

Theorem 6.2. Let ğœ“ be a symbolic (interval-free) configura-
tion and ğ‘ˆ âˆˆ Î£R. Define ğ´ = symPaths(ğœ“ ) as the (possibly
infinite) set of all symbolic paths reached when evaluating ğœ“
and ğµ = symPaths(approxFix (ğœ“ )) as the (finite) set of sym-
bolic interval paths reached when evaluating approxFix (ğœ“ ).
Then

Î¨

(cid:205)Î¨âˆˆğµ
(cid:75)
The correctness of Algorithm 1 is then a direct conse-

lb (ğ‘ˆ ) â‰¤ (cid:205)Î¨âˆˆğ´

(ğ‘ˆ ) â‰¤ (cid:205)Î¨âˆˆğµ

ub (ğ‘ˆ ).

Î¨

Î¨

(cid:74)

(cid:74)

(cid:75)

(cid:74)

(cid:75)

quence of Theorems 6.1 and 6.2:

Corollary 6.3. Let ğ‘‡ be the set of symbolic interval paths
computed when at line 12 of Algorithm 1 and ğ‘ˆ âˆˆ Î£R. Then

(cid:75)

(cid:74)

(cid:75)

Î¨

Î¨

(cid:205)Î¨âˆˆğ‘‡

lb (ğ‘ˆ ) â‰¤

(ğ‘ˆ ) â‰¤ (cid:205)Î¨âˆˆğ‘‡

ğ‘ƒ
(cid:74)
What remains is to compute (lower bounds on)

lb (ğ¼ )
(cid:75)
ub (ğ¼ ) for a symbolic interval path
and (upper bounds on)
Î¨ âˆˆ ğ‘‡ and ğ¼ âˆˆ I. We first present the standard interval trace
semantics (Section 6.3) and then a more efficient analysis for
the case that Î¨ contains only linear functions (Section 6.4).

ub (ğ‘ˆ ).

Î¨

Î¨

(cid:75)

(cid:74)

(cid:75)

(cid:74)

(cid:74)

6.3 Standard Interval Trace Semantics
For any symbolic interval path Î¨, we can employ the se-
mantics as introduced in Section 3. Instead of applying the

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

analysis to the entire program, we can restrict to the current
path Î¨ (intuitively, by adding a score(0) to all other program
paths). The interval traces split the domain of each sample
variable in Î¨ into intervals. It is easy to see that for any
compatible and exhaustive set of interval traces T , we have
lowerBdT
Î¨ (ğ‘ˆ )
for any ğ‘ˆ âˆˆ Î£R (see Theorem 4.1 and 4.2). Applying the
interval-based semantics on the level of symbolic interval
paths maintains the attractive features, namely soundness
and completeness (relative to the current path) of the se-
mantics. Note that the intervals occurring in Î¨ seamlessly
integrate with our interval-based semantics.

ub (ğ‘ˆ ) â‰¤ upperBdT

lb (ğ‘ˆ ) and

Î¨ (ğ‘ˆ ) â‰¤

Î¨

Î¨

(cid:75)

(cid:74)

(cid:75)

(cid:74)

6.4 Linear Interval Trace Semantics
In case the score values and the guards of all conditionals
are linear, we can improve and speed up the interval-based
semantics.

Assume all symbolic interval values appearing in Î¨ are
interval linear functions of ğ›¼ (i.e. functions ğ›¼ â†¦â†’ wâŠºğ›¼ +I [ğ‘, ğ‘]
for some w âˆˆ Rğ‘› and [ğ‘, ğ‘] âˆˆ I). We assume, for now, that
each symbolic value W âˆˆ Î denotes an interval-free linear
function (i.e. a function ğ›¼ â†¦â†’ wâŠºğ›¼ + ğ‘Ÿ ). Fix some interval
ğ¼ âˆˆ I. We first note that both
ub (ğ¼ ) are the
(cid:75)
integral of a polynomial over a convex polytope: define

lb (ğ¼ ) and

Î¨

Î¨

(cid:75)

(cid:74)

(cid:74)

ğ”“lb := (cid:8)ğ’” âˆˆ Rğ‘› | âŒœV [ğ’”/ğ›¼]âŒ âŠ† ğ¼ âˆ§

(cid:219)

âˆ€ğ‘¡ âˆˆ âŒœC [ğ’”/ğ›¼]âŒ.ğ‘¡ âŠ²âŠ³ ğ‘Ÿ (cid:9)

Î¨

CâŠ²âŠ³ğ‘Ÿ âˆˆÎ”
which is a polytope.10 Then
lb (ğ¼ ) is the integral of the
polynomial ğ›¼ â†¦â†’ (cid:206)
(cid:75)
W âˆˆÎ W over ğ”“lb. The definition of ğ”“ub
(as the region of integration for
ub (ğ¼ )) is similar. Such
integrals can be computed exactly [2], e.g. with the LattE
tool [20]. Unfortunately, our experiments showed that this
does not scale to interesting probabilistic programs.

Î¨

(cid:75)

(cid:74)

(cid:74)

Instead, we derive guaranteed bounds on the denotation
by means of iterated volume computations. This has the
additional benefit that we can handle non-uniform sam-
ples and non-liner expressions in Î. We follow an approach
similar to that of the interval-based semantics in Section 4
but do not split/bound individual sample variables and in-
stead directly bound linear functions over the sample vari-
ables. Let Î = {W1, . . . , Wğ‘˜ }. We define a box (by abuse of
language) as an element ğ’• = âŸ¨[ğ‘1, ğ‘1], . . . , [ğ‘ğ‘˜, ğ‘ğ‘˜ ]âŸ©, where
[ğ‘ğ‘–, ğ‘ğ‘– ] gives a bound on Wğ‘– .11 We define lb(ğ’•) := (cid:206)ğ‘˜
ğ‘–=1 ğ‘ğ‘–
and ub(ğ’•) := (cid:206)ğ‘˜
ğ‘–=1 ğ‘ğ‘– . The box ğ’• naturally defines a subset
= (cid:8)ğ’” âˆˆ ğ”“lb | (cid:211)ğ‘˜
ğ‘–=1 Wğ‘– [ğ’”/ğ›¼] âˆˆ [ğ‘ğ‘–, ğ‘ğ‘– ](cid:9).
of ğ”“lb given by ğ”“ğ’•
lb
Then ğ”“ğ’•
) for its
is again a polytope and we write vol(ğ”“ğ’•
lb
lb
) is analogous. As
volume. The definition of ğ”“ğ’•
ub
for interval traces, we call two boxes ğ’• 1, ğ’• 2 compatible if the
intervals are almost disjoint in at least one position. A set

and vol(ğ”“ğ’•
ub

10For example, if C denotes the function ğ›¼ â†¦â†’ wâŠºğ›¼+[ğ‘, ğ‘ ] we can transform
a constraint âˆ€ğ‘¡ âˆˆ âŒœ C [ğ’”/ğ›¼ ]âŒ.ğ‘¡ â‰¤ ğ‘Ÿ into the linear constraint wâŠºğ›¼ + ğ‘ â‰¤ ğ‘Ÿ .
11Note the similarity to the interval trace semantics. While the ğ‘–th position
in an interval trace bounds the value of the ğ‘–th sample variable, the ğ‘–th
entry of a box bounds the ğ‘–th score value.

of boxes ğµ is compatible if its elements are pairwise compat-
ible and exhaustive if (cid:208)
= ğ”“ub
(cf. Section 3.3).

= ğ”“lb and (cid:208)

ğ’• âˆˆğµ ğ”“ğ’•
ub

ğ’• âˆˆğµ ğ”“ğ’•
lb

lb

(cid:74)

(cid:75)

(cid:74)

ub

Î¨

Î¨

(cid:1) â‰¤

lb (ğ¼ ) and

ğ’• âˆˆğµ lb(ğ’•) Â· vol (cid:0)ğ”“ğ’•
(cid:1).

Proposition 6.4. Let ğµ be a compatible and exhaustive set of
boxes. Then (cid:205)
ub (ğ¼ ) â‰¤
(cid:75)
(cid:205)

ğ’• âˆˆğµ ub(ğ’•) Â· vol (cid:0)ğ”“ğ’•
As in the standard interval semantics, a finer partition into
boxes yields more precise bounds. While the volume com-
putation involved in Proposition 6.4 is expensive [22], the
number of splits on the linear functions is much smaller than
that needed in the standard interval-based semantics. Our
experiments empirically demonstrate that the direct splitting
of linear functions (if applicable) is usually superior to the
standard splitting. In GuBPI we compute a set of exhaustive
boxes by first computing a lower and upper bound on each
Wğ‘– âˆˆ Î over ğ”“lb (or ğ”“ub) by solving a linear program (LP)
and splitting the resulting range in evenly sized chunks.

Beyond uniform samples and linear scores. We can ex-
tend our linear optimization to non-uniform samples and
arbitrary symbolic values in Î. We accomplish the former
by combining the optimised semantics (where we bound lin-
ear expressions) with the standard interval-trace semantics
(where we bound individual sample variables). For the latter,
we can identify linear sub-expressions of the expressions in
Î, use boxes to bound each linear sub-expression, and use
interval arithmetic to infer bounds on the entire expression
from bounds on its linear sub-expressions. More details can
be found in Appendix E.1.

Example 6.3. Consider the path Î¨ = (3ğ›¼1, 5, Î”, Î) derived
in Example 6.2. We use 1-dimensional boxes to bound ğ›¼2 +
ğ›¼4 (the single linear sub-expression of the symbolic values
in Î). To obtain a lower bound on
lb (ğ¼ ), we sum over
(cid:1)
all boxes ğ’• = âŸ¨[ğ‘1, ğ‘1]âŸ© and take the product of vol (cid:0)ğ”“ğ’•
lb
with the lower interval bound of pdf Normal(1.1,0.1) ([ğ‘1, ğ‘1] +
[0, âˆ]) (evaluated in interval arithmetic). Analogously, for
(cid:1) with the
the upper bound we take the product of vol (cid:0)ğ”“ğ’•
ub
upper interval bound of pdf Normal(1.1,0.1) ([ğ‘1, ğ‘1] + [0, âˆ]).

Î¨

(cid:75)

(cid:74)

7 Practical Evaluation
We have implemented our semantics in the prototype GuBPI
(gubpi-tool.github.io), written in F#. In cases where we apply
the linear optimisation of our semantics, we use Vinci [8] to
discharge volume computations of convex polytopes. We set
out to answer the following questions:

1. How does GuBPI perform on instances that could al-

ready be solved (e.g. by PSI [26])?

2. Is GuBPI able to infer useful bounds on recursive pro-
grams that could not be handled rigorously before?

7.1 Probability Estimation
We collected a suite of 18 benchmarks from [56]. Each bench-
mark consists of a program ğ‘ƒ and a query ğœ™ over the variables

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Table 1. Evaluation on selected benchmarks from [56]. We
give the times (in seconds) and bounds computed by [56]
and GuBPI. Details on the exact queries (the Q column) can
be found in Table 4 in the appendix.

Tool from [56]

GuBPI

Program

tug-of-war

tug-of-war

beauquier-3

ex-book-s

ex-book-s

ex-cart

ex-cart

Q

Q1

Q2

Q1

ğ’•

1.29

1.09

1.15

Q1
8.48
Q2â˜… 10.3
2.41
Q1

Q2

2.40

Q3

ex-cart
0.15
ex-ckd-epi-s Q1â˜… 0.15
ex-ckd-epi-s Q2â˜… 0.08
1.31
ex-fig6

Q1

ex-fig6

ex-fig6

ex-fig6

ex-fig7

example4

example5

herman-3

Q2

Q3

Q4

Q1

Q1

Q1

Q1

1.80

1.51

3.96

0.04

0.02

0.06

0.47

Result

[0.6126, 0.6227]
[0.5973, 0.6266]
[0.5000, 0.5261]
[0.6633, 0.7234]
[0.3365, 0.3848]
[0.8980, 1.1573]
[0.8897, 1.1573]
[0.0000, 0.1150]
[0.5515, 0.5632]
[0.3019, 0.3149]
[0.1619, 0.7956]
[0.2916, 1.0571]
[0.4314, 2.0155]
[0.4400, 3.0956]
[0.9921, 1.0000]
[0.1910, 0.1966]
[0.4478, 0.4708]
[0.3750, 0.4091]

ğ’•

0.72

0.79

22.5

6.52

8.01

67.3

68.5

67.4

0.86

0.84

21.2

21.4

24.7

27.4

0.18

0.31

0.27

124

Result

[0.6134, 0.6135]
[0.6134, 0.6135]
[0.4999, 0.5001]
[0.7417, 0.7418]
[0.4137, 0.4138]
[0.9999, 1.0001]
[0.9999, 1.0001]
[0.0000, 0.0001]
[0.0003, 0.0004]
[0.0003, 0.0004]
[0.1899, 0.1903]
[0.3705, 0.3720]
[0.7438, 0.7668]
[0.8682, 0.9666]
[0.9980, 0.9981]
[0.1918, 0.1919]
[0.4540, 0.4541]
[0.3749, 0.3751]

Table 2. Probabilistic programs with discrete domains from
PSI [26]. The times for PSI and GuBPI are given in seconds.

Instance

ğ’• PSI
burglarAlarm 0.06
0.04
twoCoins
0.06
grass
0.14
noisyOr
0.04
bertrand
0.04
coinPattern

ğ’• GuBPI
0.21
0.21
0.37
0.72
0.22
0.19

Instance

ğ’• PSI
0.04
coins
0.04
ev-model1
ev-model2
0.04
murderMystery 0.04
0.13
coinBiasSmall
0.08
gossip

ğ’• GuBPI
0.18
0.21
0.20
0.19
1.92
0.24

(a) coinBias example from [26].
The program samples a beta
prior on the bias of a coin and
observes repeated coin flips (26
seconds).

(b) max example from [26]. The
program compute the maximum
of two i.i.d. normal samples (31
seconds).

of ğ‘ƒ. We bound the probability of the event described by ğœ™
using the tool from [56] and GuBPI (Table 1). While our
tool is generally slower than the one in [56], the comple-
tion times are still reasonable. Moreover, in many cases, the
bounds returned by GuBPI are tighter than those of [56]. In
addition, for benchmarks marked with a â˜…, the two pairs
of bounds contradict each other.12 We should also remark
that GuBPI cannot handle all benchmarks proposed in [56]
because the heavy use of conditionals causes our precise
symbolic analysis to suffer from the well-documented path
explosion problem [6, 9, 30]. Perhaps unsurprisingly, [56]
can handle such examples much better, as one of their core
contributions is a stochastic method to reduce the number
of paths considered (see Section 8). Also note that [56] is
restricted to uniform samples, linear guards and score-free
programs, whereas we tackle a much more general problem.

7.2 Exact Inference
To evaluate our tool on instances that can be solved exactly,
we compared it with PSI [26, 27], a symbolic solver which
can, in certain cases, compute a closed-form solution of the
posterior. We note that whenever exact inference is possi-
ble, exact solutions will always be superior to mere bounds
and, due to the overhead of our semantics, will often be

12A stochastic simulation using 106 samples in Anglican [61] yielded results
that fall within GuBPIâ€™s bounds but violate those computed by [56].

(c) Binary Gaussian Mixture
Model from [65] (39 seconds).
MCMC methods usually find
only one mode.

(d) Nealâ€™s funnel from [34, 48]
(2.8 seconds). HMC misses some
probability mass around 0.

Figure 5. Guaranteed Bounds computed by GuBPI for a
selection of non-recursive models from [26, 27, 48, 65].

found faster. Because of the different output formats (i.e. ex-
act results vs. bounds), a direct comparison between exact
methods and GuBPI is challenging. As a consistency check,
we collected benchmarks from the PSI repository where the
output domain is finite and GuBPI can therefore compute
exact results (tight bounds). They agree with PSI in all cases,
which includes 8 of the 21 benchmarks from [26]. We report
the computation times in Table 2.

We then considered examples where GuBPI computes
non-tight bounds. For space reasons, we can only include a
selection of examples in this paper. The bounds computed by
GuBPI and a short description of each example are shown in
Fig. 5. We can see that, despite the relatively loose bounds,
they are still useful and provide the user with a roughâ€”
and most importantly, guaranteed to be correctâ€”idea of the
denotation.

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

(a) cav-example-7. Program taken from
the PSI repository. PSI bounds the depth
resulting in a spike at 10, whereas GuBPI
can compute bounds on the denotation of
the unbounded program (112 seconds).

(b) cav-example-5. Program taken from
the PSI repository. PSI cannot handle this
program due to the unbounded loops (192
seconds).

(c) add_uniform_with_counter_large.
Program taken from the PSI repository.
GuBPI can handle the unbounded loop,
whereas PSI unrolls to a fixed depth (21
seconds).

(d) random-box-walk. The program mod-
els the cumulative distance traveled by a
biased random walk. If a uniformly sam-
pled step ğ‘  has length less than 1
2 , we move
ğ‘  to the left, otherwise ğ‘  to the right. The
walk stops when it crosses a threshold (167
seconds).

(e) growing-walk. The program models a
geometric random walk where (with in-
creasing distance) the step size of the walk
is increased. The cumulative distance is
observed from a normal distribution cen-
tered at 3 (67 seconds).

(f) param-estimation-recursive. We
sample a uniform prior ğ‘ and (in each step)
travel to the left with probability ğ‘ and to
the right with probability (1 âˆ’ ğ‘). We ob-
serve the walk to come to a halt at location
1 (observed from a normal) and wish to
find the posterior on ğ‘ (162 seconds).

Figure 6. Guaranteed bounds computed by GuBPI for a selection of recursive models.

The success of exact solvers such as PSI depends on the
underlying symbolic solver (and the optimisations imple-
mented). Consequently, there are instances where the sym-
bolic solver cannot compute a closed-form (integral-free)
solution. Conversely, while our method is (theoretically)
applicable to a very broad class of programs, there exist
programs where the symbolic solver finds solutions but the
analysis in GuBPI becomes infeasible due to the large number
of interval traces required.

7.3 Recursive Models
We also evaluated our tool on complex models that can-
not be handled by any of the existing methods. For space
reasons, we only give an overview of some examples. Unex-
pectedly, we found recursive models in the PSI repository:
there are examples that are created by unrolling loops to a
fixed depth. This fixed unrolling changes the posterior of
the model. Using our method we can handle those examples
without bounding the loop. Three such examples are shown
in Figs. 6a to 6c. In Fig. 6a, PSI bounds the iterations resulting
in a spike at 10 (the unrolling bound). For Fig. 6b, PSI does not
provide any solution whereas GuBPI provides useful bounds.
For Fig. 6c, PSI bounds the loop to compute results (displayed

in blue) whereas GuBPI computes the green bounds on the
unbounded program. It is obvious that the bounds differ sig-
nificantly, highlighting the impact that unrolling to a fixed
depth can have on the denotation. This again strengthens
the claim that rigorous methods that can handle unbounded
loops/recursion are needed. There also exist unbounded dis-
crete examples where PSI computes results for the bounded
version that differ from the denotation of the unbounded
program. Figs. 6d to 6f depict further recursive examples
(alongside a small description).

Lastly, as a very challenging example, we consider the
pedestrian example (Example 1.1) again. The bounds com-
puted by GuBPI are given in Fig. 7 together with the two
stochastic results from Fig. 1. The bounds are clearly precise
enough to rule out the HMC samples. Since this example
has infinite expected running time, it is very challenging
and GuBPI takes about 1.5h (84 min).13 In fact, guaranteed
bounds are the only method to recognise the wrong samples
with certainty (see the next section for statistical methods).

13While the running time seems high, we note that Pyro HMC took about an
hour to generate 104 samples and produce the (wrong) histogram. Diagnostic
methods like simulation-based calibration took even longer (>30h) and
delivered inconclusive results (see Section 7.4 for details).

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

7.5 Limitations and Future Improvements
The theoretical foundations of our interval-based semantics
ensure that GuBPI is applicable to a very broad class of pro-
grams (cf. Section 4). In practice, as usual for exact methods,
GuBPI does not handle all examples equally well.

Firstly, as we already saw in Section 7.1, the symbolic
executionâ€”which forms the entry point of the analysisâ€”
suffers from path explosion. On some extreme loop/recursion-
free programs (such as example-ckd-epi from [56]), our tool
cannot compute all (finitely many) symbolic paths in reason-
able time, let alone analyse them in our semantics. Extending
the approach from [56], to sample representative program
paths (in the presence of conditioning), is an interesting fu-
ture direction that we can combine with the rigorous analysis
provided by our interval type system.

Secondly, our interval-based semantics imposes bounds on
each sampled variable and thus scales exponentially with the
dimension of the model; this is amplified in the case where
the optimised semantics (Section 6.4) is not applicable. It
would be interesting to explore whether this can be alleviated
using different trace splitting techniques.

(cid:26)[âˆ’âˆ, âˆ]
[1, 1]

Lastly, the bounds inferred by our interval type system
take the form of a single interval with no information about
the exact distribution on that interval. For example, the most
precise bound derivable for the term ğœ‡ğœ‘
ğ‘¥ .ğ‘¥ âŠ• (cid:2)ğœ‘ (ğ‘¥ +sample) âŠ•
ğœ‘ (ğ‘¥ âˆ’sample)(cid:3) is [ğ‘, ğ‘] â†’
(cid:27) for any ğ‘, ğ‘. After unrolling to
a fixed depth, the approximation of the paths not terminating
within the fixed depth is therefore imprecise. For future work,
it would be interesting to improve the bounds in our type
system to provide more information about the distribution
by means of rigorous approximations of the denotation of
the fixpoint in question (i.e. a probabilistic summary of the
fixpoint [46, 50, 63]).

8 Related Work

Interval trace semantics and Interval SPCF. Our inter-
val trace semantics to compute bounds on the denotation is
similar to the semantics introduced by Beutner and Ong [4],
who study an interval approximation to obtain lower bounds
on the termination probability. By contrast, we study the
more challenging problem of bounding the program denota-
tion which requires us to track the weight of an execution,
and to prove that the denotation approximates a Lebesgue in-
tegral, which requires novel proof ideas. Moreover, whereas
the termination probability of a program is always upper
bounded by 1, here we derive both lower and upper bounds.

Probability estimation. Sankaranarayanan et al. [56] in-
troduced a static analysis framework to infer bounds on a
class of definable events in (score-free) probabilistic programs.
The idea of their approach is that if we find a finite set T of
symbolic traces with cumulative probability at least 1 âˆ’ ğ‘,
and a given event ğœ™ occurs with probability at most ğ‘ on the

Figure 7. Bounds for the pedestrian example (Example 1.1).

Table 3. Running times of GuBPI and SBC for (Pyroâ€™s) HMC.
Times are given in seconds (s) and hours (h).

Instance

Binary GMM (1-dimensional) (Fig. 5c)
Binary GMM (2-dimensional)
Pedestrian Example (Fig. 7)

ğ’• GuBPI
39s
4h
1.5h

ğ’• SBC
1h
1.5h
>300h

7.4 Comparison with Statistical Validation
A general approach to validating inference algorithms for
a generative Bayesian model is simulation-based calibration
(SBC) [12, 60]. SBC draws a sample ğœƒ from the prior distribu-
tion of the parameters, generates data ğ‘¦ for these parameters,
and runs the inference algorithm to produce posterior sam-
ples ğœƒ1, . . . , ğœƒğ¿ given ğ‘¦. If the posterior samples follow the
true posterior distribution, the rank statistic of the prior
sample ğœƒ relative to the posterior samples will be uniformly
distributed. If the empirical distribution of the rank statistic
after many such simulations is non-uniform, this indicates a
problem with the inference. While SBC is very general, it is
computationally expensive because it performs inference in
every simulation. Moreover, as SBC is a stochastic validation
approach, any fixed number of samples may fail to diagnose
inference errors that only occur on a very low probability
region.

We compare the running times of GuBPI and SBC for three
examples where Pyroâ€™s HMC yields wrong results (Table 3).
Running SBC on the pedestrian example (with a reduced
sample size and using the parameters recommended in [60])
took 32 hours and was still inconclusive because of strong au-
tocorrelation. Reducing the latter via thinning requires more
samples, and would increase the running time to >300 hours.
Similarly, GuBPI diagnoses the problem with the mixture
model in Fig. 5c in significantly less time than SBC. How-
ever, for higher-dimensional versions of this mixture model,
SBC clearly outperforms GuBPI. We give a more detailed
discussion of SBC for these examples in Appendix F.3.

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

traces in T , then ğœ™ occurs with probability at most ğ‘ + ğ‘ on
the entire program. In the presence of conditioning, the prob-
lem becomes vastly more difficult, as the aggregate weight
on the unexplored paths can be unbounded, giving âˆ as the
only derivable upper bound (and therefore also âˆ as the best
upper bound on the normalising constant). In order to infer
guaranteed bounds, it is necessary to analyse all paths in
the program, which we accomplish via static analysis and
in particular our interval type system. The approach from
[56] was extended by Albarghouthi et al. [1] to compute the
probability of events defined by arbitrary SMT constraints
but is restricted to score-free and non-recursive programs.
Our interval-based approach, which may be seen as a variant
of theirs, is founded on a complete semantics (Theorem 4.3),
can handle recursive program with (soft) scoring, and is
applicable to a broad class of primitive functions.

Note that we consider programs with soft conditioning
in which scoring cannot be reduced to volume computation
directly.14 Intuitively, soft conditioning performs a (global)
re-weighting of the set of traces, which cannot be captured by
(local) volume computations. In our interval trace semantics,
we instead track an approximation of the weight along each
interval trace.

Exact inference. There are numerous approaches to infer-
ring the exact denotation of a probabilistic program. Holtzen
et al. [38] introduced an inference method to efficiently com-
pute the denotation of programs with discrete distributions.
By exploiting program structure to factorise inference, their
system Dice can perform exact inference on programs with
hundreds of thousands of random variables. Gehr et al. [26]
introduced PSI, an exact inference system that uses sym-
bolic manipulation and integration. A later extension, ğœ†PSI
[27], adds support for higher-order functions and nested
inference. The PPL Hakaru [47] supports a variety of infer-
ence algorithms on programs with both discrete and con-
tinuous distributions. Using program transformation and
partial evaluation, Hakaru can perform exact inference via
symbolic disintegration [57] on a limited class of programs.
Saad et al. [55] introduced SPPL, a system that can compute
exact answers to a range of probabilistic inference queries,
by translating a restricted class of programs to sum-product
expressions, which are highly effective representations for
inference.

While exact results are obviously desirable, this kind of in-
ference only works for a restricted family of programs: none
of the above exact inference systems allow (unbounded) re-
cursion. Unlike our tool, they are therefore unable to handle,
for instance, the challenging Example 1.1 or the programs in
Fig. 6.

14For programs including only hard-conditioning (i.e. scoring is only possi-
ble with 0 or 1), the posterior probability of an event ğœ‘ can be computed by
dividing the probability of all traces with weight 1 on which ğœ‘ holds by the
probability of all traces with weight 1.

Abstract interpretation. There are various approaches
to probabilistic abstract interpretation, so we can only dis-
cuss a selection. Monniaux [44, 45] developed an abstract
domain for (score-free) probabilistic programs given by a
weighted sum of abstract regions. Smith [58] considered
truncated normal distributions as an abstract domain and de-
veloped analyses restricted to score-free programs with only
linear expressions. Extending both approaches to support
soft conditioning is non-trivial as it requires the computation
of integrals on the abstract regions. In our interval-based
semantics, we abstract the concrete traces (by means of inter-
val traces) and not the denotation. This allows us to derive
bounds on the weight along the abstracted paths.

Huang et al. [39] discretise the domain of continuous sam-
ples into interval cubes and derive posterior approximations
on each cube. The resulting approximation converges to the
true posterior (similarly to approximate/stochastic methods)
but does not provide exact/guaranteed bounds and is not
applicable to recursive programs.

Refinement types. Our interval type system (Section 5)
may be viewed as a type system that refines not just the value
of an expression but also its weight [24]. To our knowledge,
no existing type refinement system can bound the weight
of program executions. Moreover, the seamless integration
with our interval trace semantics by design allows for much
cheaper type inference, without resorting to an SMT or Horn
constraint solver. This is a crucial advantage since a typical
GuBPI execution queries the analysis numerous times.

Stochastic methods. A general approach to validating
inference algorithms for a generative Bayesian model is
simulation-based calibration (SBC) [12, 60], discussed in Sec-
tion 7.4. Grosse et al. [36] introduced a method to estimate
the log marginal likelihood of a model by constructing sto-
chastic lower/upper bounds. They show that the true value
can be sandwiched between these two stochastic bounds
with high probability. In closely related work [17, 35], this
was applied to measure the accuracy of approximate proba-
bilistic inference algorithms on a specified dataset. By con-
trast, our bounds are non-stochastic and our method is ap-
plicable to arbitrary programs of a universal PPL.

9 Conclusion
We have studied the problem of inferring guaranteed bounds
on the posterior of programs written in a universal PPL. Our
work is based on the interval trace semantics, and our weight-
aware interval type system gives rise to a tool that can in-
fer useful bounds on the posterior of interesting recursive
programs. This is a capability beyond the reach of existing
methods, such as exact inference. As a method of Bayesian
inference for statistical probabilistic programs, we can view
our framework as occupying a useful middle ground between
approximate stochastic inference and exact inference.

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

References
[1] Aws Albarghouthi, Loris Dâ€™Antoni, Samuel Drews, and Aditya V. Nori.
2017. FairSquare: probabilistic verification of program fairness. Pro-
ceedings of the ACM on Programming Languages 1, OOPSLA (2017).
https://doi.org/10.1145/3133904

[2] Velleda Baldoni, Nicole Berline, Jesus De Loera, Matthias KÃ¶ppe, and
MichÃ¨le Vergne. 2011. How to integrate a polynomial over a simplex.
Math. Comp. 80, 273 (2011). https://doi.org/10.1090/S0025-5718-2010-
02378-6

[3] Atilim GÃ¼nes Baydin, Lei Shao, Wahid Bhimji, Lukas Alexander Hein-
rich, Lawrence Meadows, Jialin Liu, Andreas Munk, Saeid Naderi-
parizi, Bradley Gram-Hansen, Gilles Louppe, Mingfei Ma, Xiaohui
Zhao, Philip H. S. Torr, Victor W. Lee, Kyle Cranmer, Prabhat, and
Frank Wood. 2019. Etalumis: bringing probabilistic programming to
scientific simulators at scale. In International Conference for High Per-
formance Computing, Networking, Storage and Analysis, SC 2019. ACM.
https://doi.org/10.1145/3295500.3356180

[4] Raven Beutner and Luke Ong. 2021. On probabilistic termination of
functional programs with continuous distributions. In ACM SIGPLAN
International Conference on Programming Language Design and Imple-
mentation, PLDI 2021. ACM. https://doi.org/10.1145/3453483.3454111
[5] Eli Bingham, Jonathan P. Chen, Martin Jankowiak, Fritz Obermeyer,
Neeraj Pradhan, Theofanis Karaletsos, Rohit Singh, Paul A. Szerlip,
Paul Horsfall, and Noah D. Goodman. 2019. Pyro: Deep Universal
Probabilistic Programming. Journal of Machine Learning Research 20
(2019). http://jmlr.org/papers/v20/18-403.html

[6] Peter Boonstoppel, Cristian Cadar, and Dawson R. Engler. 2008. RWset:
Attacking Path Explosion in Constraint-Based Test Generation. In
International Conference on Tools and Algorithms for the Construction
and Analysis of Systems, TACAS 2008. Springer. https://doi.org/10.
1007/978-3-540-78800-3_27

[7] Johannes BorgstrÃ¶m, Ugo Dal Lago, Andrew D. Gordon, and Marcin
Szymczak. 2016. A lambda-calculus foundation for universal proba-
bilistic programming. In ACM SIGPLAN International Conference on
Functional Programming, ICFP 2016. ACM. https://doi.org/10.1145/
2951913.2951942

[8] Benno BÃ¼eler, Andreas Enge, and Komei Fukuda. 2000. Exact Vol-
ume Computation for Polytopes: A Practical Study.
In Polytopesâ€”
combinatorics and computation. DMV Sem., Vol. 29. BirkhÃ¤user, Basel.
https://doi.org/10.1007/978-3-0348-8438-9_6

[9] Cristian Cadar, Vijay Ganesh, Peter M. Pawlowski, David L. Dill, and
Dawson R. Engler. 2008. EXE: Automatically Generating Inputs of
Death. ACM Transactions on Information and System Security 12, 2
(2008). https://doi.org/10.1145/1455518.1455522

[10] Arun Tejasvi Chaganty, Aditya V. Nori, and Sriram K. Rajamani. 2013.
Efficiently Sampling Probabilistic Programs via Program Analysis. In
International Conference on Artificial Intelligence and Statistics, AISTATS
2013 (JMLR, Vol. 31). http://proceedings.mlr.press/v31/chaganty13a.
html

[11] Adrien Champion, Tomoya Chiba, Naoki Kobayashi, and Ryosuke
Sato. 2020. ICE-Based Refinement Type Discovery for Higher-Order
Functional Programs. Journal of Automated Reasoning 64, 7 (2020).
https://doi.org/10.1007/s10817-020-09571-y

[12] Samantha R Cook, Andrew Gelman, and Donald B Rubin. 2006. Val-
idation of software for Bayesian models using posterior quantiles.
Journal of Computational and Graphical Statistics 15, 3 (2006). https:
//doi.org/10.1198/106186006X136976

[13] Patrick Cousot and Radhia Cousot. 1976. Static determination of
dynamic properties of programs. In International Symposium on Pro-
gramming. Dunod.

[14] Patrick Cousot and Radhia Cousot. 1977. Abstract Interpretation: A
Unified Lattice Model for Static Analysis of Programs by Construction
or Approximation of Fixpoints. In ACM Symposium on Principles of
Programming Languages, POPL 1977. ACM. https://doi.org/10.1145/
512950.512973

[15] Patrick Cousot and Radhia Cousot. 2002. Modular Static Program
Analysis. In International Conference on Compiler Construction, CC 2002
(LNCS, Vol. 2304). Springer. https://doi.org/10.1007/3-540-45937-5_13
[16] Ryan Culpepper and Andrew Cobb. 2017. Contextual Equivalence
for Probabilistic Programs with Continuous Random Variables and
Scoring. In European Symposium on Programming, ESOP 2017 (LNCS,
Vol. 10201). Springer. https://doi.org/10.1007/978-3-662-54434-1_14
[17] Marco F. Cusumano-Towner and Vikash K. Mansinghka. 2017. AIDE:
An algorithm for measuring the accuracy of probabilistic inference
algorithms. In Annual Conference on Neural Information Processing
Systems, NIPS 2017. https://proceedings.neurips.cc/paper/2017/hash/
acab0116c354964a558e65bdd07ff047-Abstract.html

[18] Marco F. Cusumano-Towner, Feras A. Saad, Alexander K. Lew, and
Vikash K. Mansinghka. 2019. Gen: a general-purpose probabilistic
programming system with programmable inference. In ACM SIGPLAN
International Conference on Programming Language Design and Imple-
mentation, PLDI 2019. ACM. https://doi.org/10.1145/3314221.3314642
[19] Hend Dawood. 2011. Theories of Interval Arithmetic: Mathematical
Foundations and Applications. LAP Lambert Academic Publishing.
[20] JesÃºs A De Loera, Brandon Dutra, Matthias Koeppe, Stanislav Moreinis,
Gregory Pinto, and Jianqiu Wu. 2013. Software for exact integration
of polynomials over polyhedra. Computational Geometry 46, 3 (2013).
https://doi.org/10.1016/j.comgeo.2012.09.001

[21] Simon Duane, Anthony D Kennedy, Brian J Pendleton, and Duncan
Roweth. 1987. Hybrid Monte Carlo. Physics letters B 195, 2 (1987).
https://doi.org/10.1016/0370-2693(87)91197-X

[22] Martin E. Dyer and Alan M. Frieze. 1988. On the Complexity of
Computing the Volume of a Polyhedron. SIAM J. Comput. 17, 5 (1988).
https://doi.org/10.1137/0217060

[23] Christian Fecht and Helmut Seidl. 1999. A Faster Solver for General
Systems of Equations. Science of Computer Programming 35, 2 (1999).
https://doi.org/10.1016/S0167-6423(99)00009-X

[24] Timothy S. Freeman and Frank Pfenning. 1991. Refinement Types
for ML. In ACM SIGPLAN International Conference on Programming
Language Design and Implementation, PLDI 1991. ACM. https://doi.
org/10.1145/113445.113468

[25] Hong Ge, Kai Xu, and Zoubin Ghahramani. 2018. Turing: A Lan-
guage for Flexible Probabilistic Inference. In International Conference
on Artificial Intelligence and Statistics, AISTATS 2018 (PMLR, Vol. 84).
https://proceedings.mlr.press/v84/ge18b.html

[26] Timon Gehr, Sasa Misailovic, and Martin T. Vechev. 2016. PSI: Exact
Symbolic Inference for Probabilistic Programs. In International Con-
ference on Computer Aided Verification, CAV 2016 (LNCS, Vol. 9779).
Springer. https://doi.org/10.1007/978-3-319-41528-4_4

[27] Timon Gehr, Samuel Steffen, and Martin T. Vechev. 2020. ğœ†PSI: exact
inference for higher-order probabilistic programs. In ACM SIGPLAN
International Conference on Programming Language Design and Imple-
mentation, PLDI 2020. ACM. https://doi.org/10.1145/3385412.3386006
[28] Jaco Geldenhuys, Matthew B. Dwyer, and Willem Visser. 2012. Proba-
bilistic symbolic execution. In International Symposium on Software
Testing and Analysis, ISSTA 2012. ACM.
https://doi.org/10.1145/
2338965.2336773

[29] Zoubin Ghahramani. 2013. Bayesian non-parametrics and the proba-
bilistic approach to modelling. Philosophical Transactions of the Royal
Society A 371 (2013). https://doi.org/10.1098/rsta.2011.0553

[30] Patrice Godefroid. 2007. Compositional dynamic test generation. In
ACM SIGPLAN Symposium on Principles of Programming Languages,
POPL 2007. ACM. https://doi.org/10.1145/1190216.1190226

[31] Noah D. Goodman, Vikash K. Mansinghka, Daniel M. Roy, Keith
Bonawitz, and Joshua B. Tenenbaum. 2008. Church: a language for gen-
erative models. In Conference on Uncertainty in Artificial Intelligence,
UAI 2008. AUAI Press.

[32] Noah D. Goodman and Andreas StuhlmÃ¼ller. 2014. The Design and

Implementation of Probabilistic Programming Languages.

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

[33] Andrew D. Gordon, Thomas A. Henzinger, Aditya V. Nori, and Sri-
ram K. Rajamani. 2014. Probabilistic programming. In Future of Soft-
ware Engineering, FOSE 2014. ACM. https://doi.org/10.1145/2593882.
2593900

[34] Maria I. Gorinova, Dave Moore, and Matthew D. Hoffman. 2020. Au-
tomatic Reparameterisation of Probabilistic Programs. In Interna-
tional Conference on Machine Learning, ICML 2020 (PMLR, Vol. 119).
http://proceedings.mlr.press/v119/gorinova20a.html

[35] Roger B. Grosse, Siddharth Ancha, and Daniel M. Roy. 2016. Mea-
suring the reliability of MCMC inference with bidirectional Monte
Carlo. In Annual Conference on Neural Information Processing Sys-
tems, NIPS 2016.
https://proceedings.neurips.cc/paper/2016/hash/
0e9fa1f3e9e66792401a6972d477dcc3-Abstract.html

[36] Roger B. Grosse, Zoubin Ghahramani, and Ryan P. Adams. 2015. Sand-
wiching the marginal likelihood using bidirectional Monte Carlo. CoRR
abs/1511.02543 (2015). https://doi.org/10.48550/arXiv.1511.02543
[37] N. L. Hjort, Chris Homes, Peter Muller, and Stephen G. Walker. 2010.
Bayesian Nonparametrics. Cambridge University Press. https://doi.
org/10.1017/CBO9780511802478

[38] Steven Holtzen, Guy Van den Broeck, and Todd D. Millstein. 2020.
Scaling exact inference for discrete probabilistic programs. Proceedings
of the ACM on Programming Languages 4, OOPSLA (2020). https:
//doi.org/10.1145/3428208

[39] Zixin Huang, Saikat Dutta, and Sasa Misailovic. 2021. AQUA: Auto-
mated Quantized Inference for Probabilistic Programs. In International
Symposium on Automated Technology for Verification and Analysis,
ATVA 2021 (LNCS, Vol. 12971). Springer. https://doi.org/10.1007/978-3-
030-88885-5_16

[40] Andrew Kenyon-Roberts and C.-H. Luke Ong. 2021. Supermartin-
gales, Ranking Functions and Probabilistic Lambda Calculus. In Annual
ACM/IEEE Symposium on Logic in Computer Science, LICS 2021. IEEE.
https://doi.org/10.1109/LICS52264.2021.9470550

[41] Carol Mak, C.-H. Luke Ong, Hugo Paquet, and Dominik Wagner.
2021. Densities of Almost Surely Terminating Probabilistic Pro-
grams are Differentiable Almost Everywhere. In European Sympo-
sium on Programming, ESOP 2021 (LNCS, Vol. 12648). Springer. https:
//doi.org/10.1007/978-3-030-72019-3_16

[42] Carol Mak, Fabian Zaiser, and Luke Ong. 2021. Nonparametric Hamil-
tonian Monte Carlo. In International Conference on Machine Learning,
ICML 2021 (PMLR, Vol. 139). http://proceedings.mlr.press/v139/mak21a.
html

[43] Chris Manning and Hinrich SchÃ¼tze. 1999. Foundations of Statistical

Natural Language Processing. MIT Press. Cambridge, MA.

[44] David Monniaux. 2000. Abstract Interpretation of Probabilistic Seman-
tics. In International Symposium on Static Analysis, SAS 2000 (LNCS,
Vol. 1824). Springer. https://doi.org/10.1007/978-3-540-45099-3_17
[45] David Monniaux. 2001. An abstract Monte-Carlo method for the
analysis of probabilistic programs. In ACM SIGPLAN Symposium on
Principles of Programming Languages, POPL 2001. ACM. https://doi.
org/10.1145/360204.360211

[46] Markus MÃ¼ller-Olm and Helmut Seidl. 2004. Precise interprocedu-
ral analysis through linear algebra. In ACM SIGPLAN Symposium
on Principles of Programming Languages, POPL 2004. ACM. https:
//doi.org/10.1145/964001.964029

[47] Praveen Narayanan, Jacques Carette, Wren Romano, Chung-chieh
Shan, and Robert Zinkov. 2016. Probabilistic Inference by Program
Transformation in Hakaru (System Description). In International Sym-
posium on Functional and Logic Programming, FLOPS 2016 (LNCS,
Vol. 9613). Springer. https://doi.org/10.1007/978-3-319-29604-3_5
[48] Radford M Neal. 2003. Slice sampling. The annals of statistics 31, 3

(2003). https://doi.org/10.1214/aos/1056562461

[49] Art B. Owen. 2013. Monte Carlo theory, methods and examples.
[50] Andreas Podelski, Ina Schaefer, and Silke Wagner. 2005. Summaries
for While Programs with Recursion. In European Symposium on Pro-
gramming, ESOP 2005 (LNCS, Vol. 3444). Springer. https://doi.org/10.
1007/978-3-540-31987-0_8

[51] David Pollard. 2002. A Userâ€™s Guide to Measure-Theoretic Prob-
https://doi.org/10.1017/

Cambridge University Press.

ability.
CBO9780511811555

[52] Fredrik Ronquist, Jan Kudlicka, Viktor Senderov, Johannes BorgstrÃ¶m,
Nicolas Lartillot, Daniel LundÃ©n, Lawrence Murray, Thomas B SchÃ¶n,
and David Broman. 2021. Universal probabilistic programming offers
a powerful approach to statistical phylogenetics. Communications
biology 4, 1 (2021). https://doi.org/10.1038/s42003-021-01753-7
[53] Vivekananda Roy. 2020. Convergence Diagnostics for Markov Chain
Monte Carlo. Annual Review of Statistics and Its Application 7 (2020).
https://doi.org/10.1146/annurev-statistics-031219-041300

[54] Reuven Y. Rubinstein and Dirk P. Kroese. 2017.

Simulation and
the Monte Carlo Method (3rd ed.). Wiley. https://doi.org/10.1002/
9781118631980

[55] Feras A. Saad, Martin C. Rinard, and Vikash K. Mansinghka. 2021.
SPPL: probabilistic programming with fast exact symbolic inference.
In ACM SIGPLAN International Conference on Programming Language
Design and Implementation, PLDI 2021. ACM. https://doi.org/10.1145/
3453483.3454078

[56] Sriram Sankaranarayanan, Aleksandar Chakarov, and Sumit Gulwani.
2013. Static analysis for probabilistic programs: inferring whole pro-
gram properties from finitely many paths. In ACM SIGPLAN Interna-
tional Conference on Programming Language Design and Implementa-
tion, PLDI 2013. ACM. https://doi.org/10.1145/2491956.2462179
[57] Chung-chieh Shan and Norman Ramsey. 2017. Exact Bayesian in-
ference by symbolic disintegration. In ACM SIGPLAN Symposium
on Principles of Programming Languages, POPL 2017. ACM. https:
//doi.org/10.1145/3009837.3009852

[58] Michael J. A. Smith. 2008. Probabilistic Abstract Interpretation of
Imperative Programs using Truncated Normal Distributions. Electronic
Notes in Theoretical Computer Science 220, 3 (2008). https://doi.org/10.
1016/j.entcs.2008.11.018

[59] Sam Staton. 2017. Commutative Semantics for Probabilistic Program-
ming. In European Symposium on Programming, ESOP 2017 (LNCS,
Vol. 10201). Springer. https://doi.org/10.1007/978-3-662-54434-1_32
[60] Sean Talts, Michael Betancourta, Daniel Simpson, Aki Vehtari, and
Andrew Gelman. 2018. Validating Bayesian Inference Algorithms
with Simulation-Based Calibration. arXiv 1804.06788 (2018). https:
//doi.org/10.48550/arXiv.1804.06788

[61] David Tolpin, Jan-Willem van de Meent, and Frank D. Wood. 2015.
Probabilistic Programming in Anglican. In European Conference on
Machine Learning and Knowledge Discovery in Databases, ECML PKDD
2015 (LNCS, Vol. 9286). Springer. https://doi.org/10.1007/978-3-319-
23461-8_36

[62] Jan-Willem van de Meent, Brooks Paige, Hongseok Yang, and Frank
Wood. 2018. An Introduction to Probabilistic Programming. CoRR
abs/1809.10756 (2018). https://doi.org/10.48550/arXiv.1809.10756
[63] Di Wang, Jan Hoffmann, and Thomas W. Reps. 2018. PMAF: an alge-
braic framework for static analysis of probabilistic programs. In ACM
SIGPLAN International Conference on Programming Language Design
and Implementation, PLDI 2018. ACM. https://doi.org/10.1145/3192366.
3192408

[64] Cheng Zhang, Judith BÃ¼tepage, Hedvig KjellstrÃ¶m, and Stephan Mandt.
2019. Advances in Variational Inference. IEEE Transactions on Pattern
Analysis and Machine Intelligence 41, 8 (2019). https://doi.org/10.1109/
TPAMI.2018.2889774

[65] Yuan Zhou, Bradley J. Gram-Hansen, Tobias Kohn, Tom Rainforth,
Hongseok Yang, and Frank Wood. 2019. LF-PPL: A Low-Level First
Order Probabilistic Programming Language for Non-Differentiable
Models. In International Conference on Artificial Intelligence and Statis-
tics, AISTATS 2019 (PMLR, Vol. 89). http://proceedings.mlr.press/v89/
zhou19b.html

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

A Supplementary Material for Section 3
A.1 Intervals as a lattice
Intervals I form a partially ordered set under interval in-
clusion (âŠ‘). We will sometimes need the meet âŠ“ and join
âŠ” operations, corresponding to the greatest lower bound
and the least upper bound of two intervals. Note that the
meet of two intervals does not exist if the two intervals
are disjoint. Concretely, these two operations are given by
[ğ‘, ğ‘] âŠ“ [ğ‘, ğ‘‘] := [max(ğ‘, ğ‘), min(ğ‘, ğ‘‘)] (if the two intervals
overlap) and [ğ‘, ğ‘] âŠ” [ğ‘, ğ‘‘] := [min(ğ‘, ğ‘), max(ğ‘, ğ‘‘)].

For some applications (e.g. the interval type system), we
need the interval domain to be a true lattice. To turn I into
a lattice, we add a bottom element âŠ¥ (signifying an empty
interval). The definition of the meet âŠ“ and join âŠ” is extended
in the natural way. The meet âŠ“ is extended by defining ğ¼1 âŠ“
âŠ¥ = âŠ¥ âŠ“ ğ¼2 = âŠ¥ and ğ¼1 âŠ“ ğ¼2 = âŠ¥ if the two intervals ğ¼1, ğ¼2 âˆˆ I
are disjoint. The join âŠ” satisfies ğ¼ âŠ” âŠ¥ = âŠ¥ âŠ” ğ¼ = ğ¼ .

A.2 Lifting Functions to Intervals
For constants ğ‘ âˆˆ R (i.e. nullary functions), for common func-
tions like +, âˆ’, Ã—, | Â· |, min, max, for monotonically increasing
functions ğ‘“â†— : R â†’ R, and for monotonically decreasing
functions ğ‘“â†˜ : R â†’ R, it is easy to describe the interval-
lifted functions +I, âˆ’I, Ã—I, | Â· |I, minI, maxI, ğ‘“ I
â†—

, and ğ‘“ I
â†˜

:

ğ‘I = [ğ‘, ğ‘]
âˆ’I [ğ‘¥1, ğ‘¦1] = [âˆ’ğ‘¦1, âˆ’ğ‘¥1]

(cid:40)

|[ğ‘¥1, ğ‘¦1]|I =

[0, max(|ğ‘¥1|, |ğ‘¦1|)] if ğ‘¥1 â‰¤ 0 â‰¤ ğ‘¦1
[min(|ğ‘¥1|, |ğ‘¦1|), max(|ğ‘¥1|, |ğ‘¦1|)] else

[ğ‘¥1, ğ‘¦1] +I [ğ‘¥2, ğ‘¦2] = [ğ‘¥1 + ğ‘¥2, ğ‘¦1 + ğ‘¦2]
[ğ‘¥1, ğ‘¦1] âˆ’I [ğ‘¥2, ğ‘¦2] = [ğ‘¥1 âˆ’ ğ‘¦2, ğ‘¦1 âˆ’ ğ‘¥2]
[ğ‘¥1, ğ‘¦1] Ã—I [ğ‘¥2, ğ‘¦2] = [min(ğ‘¥1ğ‘¥2, ğ‘¥1ğ‘¦2, ğ‘¦1ğ‘¥2, ğ‘¦1ğ‘¦2),

max(ğ‘¥1ğ‘¥2, ğ‘¥1ğ‘¦2, ğ‘¦1ğ‘¥2, ğ‘¦1ğ‘¦2)]

minI([ğ‘¥1, ğ‘¦1], [ğ‘¥2, ğ‘¦2]) = [min(ğ‘¥1, ğ‘¥2), min(ğ‘¦1, ğ‘¦2)]
maxI([ğ‘¥1, ğ‘¦1], [ğ‘¥ğ‘›, ğ‘¦ğ‘›]) = [max(ğ‘¥1, ğ‘¥2), max(ğ‘¦1, ğ‘¦2)]
ğ‘“ I
â†— ([ğ‘¥1, ğ‘¦1]) = [ğ‘“â†— (ğ‘¥1), ğ‘“â†— (ğ‘¦1)]
ğ‘“ I
â†˜ ([ğ‘¥1, ğ‘¦1]) = [ğ‘“â†˜ (ğ‘¦1), ğ‘“â†˜(ğ‘¥1)]

where we write ğ‘“ (Â±âˆ) for limğ‘¥â†’Â±âˆ ğ‘“ (ğ‘¥) âˆˆ Râˆ, respec-
tively.

A.3 Properties of Interval Reduction
We can define a refinement relation ğ‘€ âŠ³ ğ‘€ â€² (â€œğ‘€ refines ğ‘€ â€²â€)
between a standard term ğ‘€ and an interval term ğ‘€ â€², if ğ‘€
is obtained from ğ‘€ â€² by replacing every occurrence of [ğ‘, ğ‘]
with some ğ‘Ÿ âˆˆ [ğ‘, ğ‘].

Lemma 3.1. Let âŠ¢ ğ‘ƒ : R be a program. For any interval trace
ğ’• and concrete trace ğ’” âŠ³ ğ’•, we have wtğ‘ƒ (ğ’”) âˆˆ wtI
ğ‘ƒ (ğ’•) and
valğ‘ƒ (ğ’”) âˆˆ val

I
ğ‘ƒ (ğ’•) (provided valğ‘ƒ (ğ’”) is defined).

Proof. If the interval reduction â†’I gets stuck, wtI
ğ‘ƒ is [0, âˆ]
I
ğ‘ƒ is [âˆ’âˆ, âˆ], so the claim is certainly true. Otherwise,
and val
I ) reduction step, we can do
for each (ğ‘€I, ğ’•, ğ‘¤I) â†’I (ğ‘€ â€²
a reduction step (ğ‘€, ğ’”, ğ‘¤) â†’ (ğ‘€ â€², ğ’” â€², ğ‘¤ â€²) where ğ‘€ â€² âŠ³ ğ‘€ â€²
I and
I , and ğ’” â€² âŠ³ ğ’• â€² if ğ‘€ âŠ³ ğ‘€I, ğ‘¤ âˆˆ ğ‘¤I, and ğ’” âŠ³ ğ’•. Since the
ğ‘¤ â€² âˆˆ ğ‘¤ â€²
reduction doesnâ€™t get stuck, we end up with a value ğ‘Ÿ âŠ³ [ğ‘, ğ‘],
I
â–¡
ğ‘ƒ (ğ’•).
so valğ‘ƒ (ğ’”) = ğ‘Ÿ âˆˆ [ğ‘, ğ‘] = val

I , ğ’• â€², ğ‘¤ â€²

A.4 Additional Possible Reduction Rules
The interval semantics as presented has the unfortunate
property that even a simple program like

if (sample, score(0), score(1))
requires infinitely many interval traces to achieve a finite
upper bound. The reason is that the right branch score(1) is
taken if the sampled value is in the open interval (0, 1]. To ap-
proximate this using closed intervals [ğ‘, ğ‘] that our analysis
supports, we need infinitely many intervals, e.g. {[2âˆ’ğ‘›âˆ’1, 2âˆ’ğ‘›] |
ğ‘› âˆˆ N}. Adding (half-)open intervals to the semantics would
solve this specific problem, but not more general ones, where
the guard condition is for example

sample âˆ’ sample â‰¤ 0.
In that case, we have to approximate the set {(ğ‘¥, ğ‘¦) âˆˆ [0, 1]2 |
ğ‘¥ â‰¤ ğ‘¦}. For the lower bounds, that is not an issue, but for the
upper bounds, we need an infinite number of interval traces
again. We would like to use the interval traces âŸ¨[0, 1
2 ]âŸ©
and âŸ¨[ 1
2, 1], [0, 1]âŸ© to cover this set, but the reduction gets
stuck on them because it is not clear which branch should
be taken.

2 ], [0, 1

To remedy this, we could add the following two rules.

ğ‘ â‰¤ 0 < ğ‘
(if([ğ‘, ğ‘], ğ‘ , ğ‘ƒ), ğ’•, ğ‘¤) â†’I (ğ‘ , ğ’•, ğ‘¤ Ã—I [0, 1])

ğ‘ â‰¤ 0 < ğ‘
(if ([ğ‘, ğ‘], ğ‘ , ğ‘ƒ), ğ’•, ğ‘¤) â†’I (ğ‘ƒ, ğ’•, ğ‘¤ Ã—I [0, 1])
They basically express that if the interval bounds are not
precise enough to decide what branch to take, we can take
both, but have to allow the weight to be zero because itâ€™s not
guaranteed that the taken branch can actually happen. This
change can only improve the upper bounds, not the lower
bounds because the lower bound on each weight is zero if
the additional rules are used. Then the definition of upper
bound can be modified in the following way:

upperBdT

ğ‘ƒ (ğ‘ˆ ) :=

âˆ‘ï¸

ğ’• âˆˆT

âˆ‘ï¸

vol(ğ’•) Â· ğ‘¤2 Â· (cid:2)[ğ‘, ğ‘] âˆ© ğ‘ˆ â‰  âˆ…(cid:3)

(ğ‘ƒ,ğ’•, [1,1])â†’I
( [ğ‘,ğ‘ ], âŸ¨âŸ©, [ğ‘¤1,ğ‘¤2 ])

This is the strategy we use for our implementation and
is a natural extension of the existing semantics: it requires
very few changes to the soundness and completeness proofs.
A downside of the previous approach is that the bounds
are not always very tight: for the term if (. . . ) score(50)

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

((ğœ†ğ‘¥ .M)V, ğ‘›, Î”, Î) (cid:123) (M [V/ğ‘¥], ğ‘›, Î”, Î)

(score(V), ğ‘›, Î”, Î) (cid:123) (V, ğ‘›, Î” âˆª {V â‰¥ 0}, Î âˆª {V})

((ğœ‡ğœ‘

ğ‘¥ . M)V, ğ‘›, Î”, Î) (cid:123) (M [V/ğ‘¥, (ğœ‡ğœ‘

ğ‘¥ . M)/ğœ‘], ğ‘›, Î”, Î)

(sample, ğ‘›, Î”, Î) (cid:123) (ğ›¼ğ‘›+1, ğ‘› + 1, Î”, Î)

(if(V, N, P)), ğ‘›, Î”, Î) (cid:123) (N, ğ‘›, Î” âˆª {V â‰¤ 0}, Î)

(if (V, N, P)), ğ‘›, Î”, Î) (cid:123) (P, ğ‘›, Î” âˆª {V > 0}, Î)
(R, ğ‘›, Î”, Î) (cid:123) (M, ğ‘›â€², Î”â€², Îâ€²)
(E [R], ğ‘›, Î”, Î) (cid:123) (E [M], ğ‘›â€², Î”â€², Îâ€²)

Figure 8. Reduction rules for symbolic execution

else score(100), it returns bounds [0, 150] instead of [50, 100].
To improve this, we could omit the multiplication with [0, 1].
ğ‘ â‰¤ 0 < ğ‘
(if ([ğ‘, ğ‘], ğ‘ , ğ‘ƒ), ğ’•, ğ‘¤) â†’I (ğ‘ , ğ’•, ğ‘¤)
ğ‘ â‰¤ 0 < ğ‘
(if ([ğ‘, ğ‘], ğ‘ , ğ‘ƒ), ğ’•, ğ‘¤) â†’I (ğ‘ƒ, ğ’•, ğ‘¤)
However, this complicates the equations of our bounds. With
this semantics, we have to compute minima and suprema
instead of a simple sum:

lowerBdT

ğ‘ƒ (ğ‘ˆ ) :=

upperBdT

ğ‘ƒ (ğ‘ˆ ) :=

âˆ‘ï¸

ğ’• âˆˆT

âˆ‘ï¸

ğ’• âˆˆT

min
(ğ‘ƒ,ğ’•, [1,1])â†’I
( [ğ‘,ğ‘ ], âŸ¨âŸ©, [ğ‘¤1,ğ‘¤2 ])

vol(ğ’•) Â· ğ‘¤1 Â· (cid:2)[ğ‘, ğ‘] âŠ† ğ‘ˆ (cid:3)

vol(ğ’•) Â· ğ‘¤2 Â· (cid:2)[ğ‘, ğ‘] âˆ© ğ‘ˆ â‰  âˆ…(cid:3)

sup
(ğ‘ƒ,ğ’•, [1,1])â†’I
( [ğ‘,ğ‘ ], âŸ¨âŸ©, [ğ‘¤1,ğ‘¤2 ])

This is harder to implement because the sums cannot be
computed incrementally, but many temporary results have
to be kept in memory to compute the minima and suprema.
Proving soundness and completeness for this would require
more substantial changes to the proofs.

B Symbolic Execution
In this section we formally introduce stochastic symbolic
execution. We make use of this form of symbolic execution
in two separate ways. First, our completeness proof hinges
on guarantees provided by the symbolic execution in order
to identify a suitable set of interval traces. Second, our tool
GuBPI relies on the symbolic execution as a first step in the
program analysis, in order to identify relevant paths and in-
dependent subexpressions, and to avoid repeated evaluation
in a small-step semantics.

High-level idea. The overarching idea of symbolic execu-
tion is to postpone the evaluation of sample expressions and
instead use a sample variable to symbolically represent its
outcome. As a consequence, branching and scoring steps can-
not be executed concretely, so we record them symbolically
instead.

Symbolic terms. To postpone concrete sample decisions
we introduce sample variables ğ›¼1, ğ›¼2, . . . into our language.
We then define symbolic terms and symbolic values by extend-
ing interval terms and values by adding two new constructs:
every sample variable ğ›¼ ğ‘— is a symbolic value and for every
primitive function ğ‘“ and symbolic values V1, . . . , V|ğ‘“ |, the
symbolic term ğ‘“ (V1, . . . , V|ğ‘“ |) is a symbolic value, denoting
a function application that is postponed until all sample vari-
ables are instantiated. We denote symbolic terms by M, N, P
and symbolic values by V, W. Formally we define

V := ğ‘¥ | ğ‘Ÿ | ğœ†ğ‘¥ .M | ğœ‡ğœ‘

ğ‘¥ . M | ğ›¼ğ‘– | ğ‘“ (V1, . . . , V|ğ‘“ |)
M, N, P := V | MN | if (M, N, P) | ğ‘“ (M1, . . . , M |ğ‘“ |)

| sample | score(M)

The definition of redex and evaluation context extends natu-
rally (recall that we regard ğ›¼ ğ‘— as a value).

Symbolic execution. A symbolic constraint is a pair (V âŠ²âŠ³
ğ‘Ÿ ) where V is a symbolic value, âŠ²âŠ³ âˆˆ {â‰¤, <, â‰¥, >} and ğ‘Ÿ âˆˆ R.
A symbolic configuration has the form ğœ“ = (M, ğ‘›, Î”, Î)
where M is a symbolic term, ğ‘› âˆˆ N a natural number (used to
obtain fresh sample variables), Î” a set of symbolic constraints
(which track the symbolic conditions on the current execu-
tion path), and Î is a set of symbolic values (which records
all symbolic values scored on the current path). When exe-
cuting symbolically: (1) we evaluate each sample to a fresh
sample variable, (2) we postpone function application, (3) for
each conditional, we explore both branches (our reduction
is nondeterministic) and record the symbolic inequalities
that must hold along the current path, and (4) we record the
symbolic values that we scored with. We give the reduction
rules in Fig. 8.

We call a tuple Î¨ = (V, ğ‘›, Î”, Î) (a symbolic configuration
where the symbolic term is a value) a symbolic path. For
a symbolic configuration ğœ“ , we write symPaths(ğœ“ ) for the
set of symbolic paths reached when evaluating from ğœ“ . Note
that symPaths(ğœ“ ) is countable.

Let V be a symbolic value of type R (no ğœ†-abstraction
or fixed point) with sample variables within {ğ›¼1, . . . , ğ›¼ğ‘› }.
For a trace ğ’” = âŸ¨ğ‘Ÿ1, . . . , ğ‘Ÿğ‘›âŸ© âˆˆ [0, 1]ğ‘›, we define V [ğ’”/ğ›¼] as
the value (in R) obtained by replacing the sample variables
in ğ›¼ with ğ’” and evaluate the postponed primitive function
applications. For a symbolic path Î¨ = (V, ğ‘›, Î”, Î), we define
Î¨
(cid:75)
âˆ«

(ğ‘ˆ ) as

(cid:74)

(cid:2)V [ğ’”/ğ›¼] âˆˆ ğ‘ˆ (cid:3) (cid:214)
CâŠ²âŠ³ğ‘Ÿ âˆˆÎ”

(cid:2)C [ğ’”/ğ›¼] âŠ²âŠ³ ğ‘Ÿ (cid:3) (cid:214)
W âˆˆÎ

[0,1]ğ‘›

W [ğ’”/ğ›¼] dğ’”.

Solution to symbolic constraints. To simplify notation
(and avoid extensive use of Iverson brackets) we introduce
notation for the set of traces that satisfy a set of symbolic con-
straints. Given a set of symbolic constraints Î” with sample

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

variables contained in {ğ›¼1, . . . , ğ›¼ğ‘› } we define
(cid:217)

Satğ‘› (Î”) :=

{ğ’” âˆˆ [0, 1]ğ‘› | V [ğ’”/ğ›¼] âŠ²âŠ³ ğ‘Ÿ }

( VâŠ²âŠ³ğ‘Ÿ ) âˆˆÎ”

as the set of actual values for the sample variables that satisfy
all constraints. It follows immediately from the definitions
Î¨
that we can replace the Iverson brackets in
by directly
(cid:75)
restricting the integral to the traces in Satğ‘› (Î”).
Lemma B.1. For any symbolic path (V, ğ‘›, Î”, Î) and any
ğ‘ˆ âˆˆ Î£R we have

(cid:74)

(V, ğ‘›, Î”, Î)

(ğ‘ˆ ) =

(cid:75)

(cid:74)

âˆ«

Satğ‘› (Î”)

[V [ğ’”/ğ›¼] âˆˆ ğ‘ˆ ]

(cid:214)

W âˆˆÎ

W [ğ’”/ğ›¼] dğ’”.

Correctness of symbolic execution. We can now estab-
lish a correspondence between symbolic execution and the
ordinary reduction. If we wish to symbolically analyse a
term ğ‘ƒ, we consider the (symbolic) reductions starting from
(ğ‘ƒ, 0, âˆ…, âˆ…), resulting in the symbolic paths symPaths(ğ‘ƒ, 0, âˆ…, âˆ…).
Lemma B.2. Let âŠ¢ ğ‘ƒ : R and suppose we have (V, ğ‘›, Î”, Î) âˆˆ
symPaths(ğ‘ƒ, 0, âˆ…, âˆ…), where ğ‘ƒ is interpreted as a symbolic term.
Then for any ğ’” âˆˆ ğ‘†ğ‘ğ‘¡ğ‘› (Î”), we have

(ğ‘ƒ, ğ’”, 1) â†’âˆ— (V [ğ’”/ğ›¼], âŸ¨âŸ©, (cid:214)
W âˆˆÎ

W [ğ’”/ğ›¼]).

Proof. A similar proof can be found in [41, Theorem 1]. â–¡
Lemma B.3. Let âŠ¢ ğ‘ƒ : R and suppose (ğ‘ƒ, ğ’”, 1) â†’âˆ— (ğ‘Ÿ, âŸ¨âŸ©, ğ‘¤)
for some ğ‘Ÿ âˆˆ R. Then there exists a unique (V, ğ‘›, Î”, Î) âˆˆ
symPaths(ğ‘ƒ, 0, âˆ…, âˆ…) such that ğ’” âˆˆ ğ‘†ğ‘ğ‘¡ğ‘› (Î”). For this unique
symbolic path we have ğ‘¤ = (cid:206)
W âˆˆÎ W [ğ’”/ğ›¼] and ğ‘Ÿ = V [ğ’”/ğ›¼].
Proof sketch. Choose the same branches in the (cid:123)-reduction
of ğ‘ƒ as in its â†’-reduction. Then it is straightforward to see
that this correspondence holds at every symbolic reduction
step: if (ğ‘ƒ, 0, âˆ…, âˆ…) (cid:123)âˆ— (P â€², ğ‘›, Î”, Î) then the corresponding
â†’-reduction steps yield (ğ‘ƒ, ğ’”ğ’” â€², 1) â†’âˆ— (ğ‘ƒ â€², ğ’” â€², ğ‘¤) where ğ’” has
length ğ‘›, ğ‘ƒ â€² is P â€²[ğ’”/ğ›¼] (after evaluating delayed primitve
function applications), Î” records the guards C [ğ’”/ğ›¼] â‰¤ 0 or
C [ğ’”/ğ›¼] > 0 that need to hold for the trace ğ’”, and finally, the
weight ğ‘¤ is given by (cid:206)
â–¡

W âˆˆÎ W [ğ’”/ğ›¼] at any point.

Theorem 6.1. Let âŠ¢ ğ‘ƒ : R be a program and ğ‘ˆ âˆˆ Î£R. Then

(ğ‘ˆ ) = (cid:205)Î¨âˆˆsymPaths (ğ‘ƒ,0,âˆ…,âˆ…)

ğ‘ƒ
(cid:74)

(cid:75)

Î¨

(ğ‘ˆ ).

(cid:74)

(cid:75)

âˆ«

âˆ‘ï¸

ğ‘› âˆˆN
âˆ‘ï¸

âˆ«

ğ‘› âˆˆN
(cid:32)

Proof.

(ğ‘ˆ ) =

ğ‘ƒ
(cid:74)

(cid:75)

=

=

[valğ‘ƒ (ğ’”) âˆˆ ğ‘ˆ ]wtğ‘ƒ (ğ’”) dğ’”

[0,1]ğ‘›

âˆ‘ï¸

[0,1]ğ‘›

( V,ğ‘›,Î”,Î)

[ğ’” âˆˆ Satğ‘› (Î”)] [V [ğ’”/ğ›¼] âˆˆ ğ‘ˆ ]

(cid:214)

W [ğ’”/ğ›¼] dğ’”

(cid:33)

âˆ‘ï¸

âˆ«

( V,ğ‘›,Î”,Î)

Satğ‘› (Î”)

[V [ğ’”/ğ›¼] âˆˆ ğ‘ˆ ]

W âˆˆÎ
(cid:214)

W [ğ’”/ğ›¼] dğ’”

W âˆˆÎ

=

âˆ‘ï¸
( V,ğ‘›,Î”,Î)(cid:74)

(V, ğ‘›, Î”, Î)

(ğ‘ˆ )

(cid:75)

where the sum ranges over symbolic paths (V, ğ‘›, Î”, Î) âˆˆ
symPaths(ğ‘ƒ, 0, âˆ…, âˆ…). The first equality is by definition, the
second one by Lemmas B.2 and B.3, the third by noting that
Satğ‘› (Î”) âŠ† [0, 1]ğ‘› and exchanging the infinite sum and inte-
gral (which is allowed because everything is nonnegative)
â–¡
and the fourth by Lemma B.1.

C Supplementary Material for Section 4
C.1 Infinite Trace Semantics
A convenient alternative to the (finite) trace semantics is
using infinite traces Tâˆ := [0, 1]N with a suitable ğœ-algebra
[16, 40]. The ğœ-algebra on Tâˆ is defined as
and measure ğœ‡Tâˆ
the smallest ğœ-algebra that contains all sets ğ‘ˆ Ã— Tâˆ where
ğ‘ˆ âˆˆ Î£ [0,1]ğ‘› for some ğ‘› âˆˆ N. The measure ğœ‡Tâˆ
is the unique
measure with ğœ‡Tâˆ (ğ‘ˆ Ã— Tâˆ) = ğœ†ğ‘› (ğ‘ˆ ) for ğ‘ˆ âˆˆ Î£ [0,1]ğ‘› . We use
the symbol ğ’– for an infinite trace in Tâˆ. For a finite trace ğ’”
and infinite trace ğ’– we write ğ’”ğ’– âˆˆ Tâˆ for their concatenation.
For any infinite trace ğ’– âˆˆ Tâˆ, there is at most one prefix
ğ’” âˆˆ T with wtğ‘ƒ (ğ’”) > 0 since the reduction is deterministic.
ğ‘ƒ (ğ’–) :=
We can therefore define wtâˆ
valğ‘ƒ (ğ’”) if such a prefix ğ’” exists, and wtâˆ
ğ‘ƒ (ğ’–)
is undefined otherwise. The infinite trace semantics of a term
is then defined as

ğ‘ƒ (ğ’–) := wtğ‘ƒ (ğ’”) and valâˆ

ğ‘ƒ (ğ’–) := 0 and valâˆ

âˆ«

(ğ‘ˆ ) :=

ğ‘ƒ
(cid:74)

(cid:75)

(valâˆ

ğ‘ƒ ) âˆ’1 (ğ‘ˆ )

wtâˆ

ğ‘ƒ (ğ’–) ğœ‡Tâˆ (dğ’–).

Lemma C.1. The finite and infinite trace semantics agree,
that is:

wtğ‘ƒ (ğ’”) ğœ‡T (dğ’”) =

âˆ«

wtâˆ

ğ‘ƒ (ğ’–) ğœ‡Tâˆ (dğ’–).

(valğ‘ƒ ) âˆ’1 (ğ‘ˆ )

Proof. Observe that valâˆ
wtğ‘ƒ (ğ’”) for all ğ’– âˆˆ Tâˆ if wtğ‘ƒ (ğ’”) > 0. Then we get:

(valâˆ

ğ‘ƒ ) âˆ’1 (ğ‘ˆ )
ğ‘ƒ (ğ’”ğ’–) = valğ‘ƒ (ğ’”) and wtâˆ

ğ‘ƒ (ğ’”ğ’–) =

wtğ‘ƒ (ğ’”) ğœ‡T (dğ’”)

(valğ‘ƒ ) âˆ’1 (ğ‘ˆ )

[valğ‘ƒ (ğ’”) âˆˆ ğ‘ˆ ]wtğ‘ƒ (ğ’”)

âˆ«

Tâˆ

ğœ‡Tâˆ (dğ’–)ğœ‡T (dğ’”)

[valâˆ

ğ‘ƒ (ğ’”ğ’–) âˆˆ ğ‘ˆ ]wtâˆ

ğ‘ƒ (ğ’”ğ’–)ğœ‡Tâˆ (dğ’–)ğœ‡T (dğ’”)

(wtğ‘ƒ ) âˆ’1 (R>0)

âˆ«

(wtğ‘ƒ ) âˆ’1 (R>0)

Tâˆ

(wtğ‘ƒ ) âˆ’1 (R>0)Ã—Tâˆ

[valâˆ

ğ‘ƒ (ğ’–) âˆˆ ğ‘ˆ ]wtâˆ

ğ‘ƒ (ğ’–)ğœ‡Tâˆ (dğ’–)

wtâˆ

ğ‘ƒ (ğ’–)ğœ‡Tâˆ (dğ’–)

(valâˆ

ğ‘ƒ ) âˆ’1 (ğ‘ˆ )

where we used the fact that the sets {ğ’”} Ã— Tâˆ are disjoint
for different ğ’” âˆˆ wtâˆ’1
ğ‘ƒ (R>0) because otherwise we would
be able to find a trace ğ’” as a prefix of ğ’” â€² and both having
positive weight, which is impossible due to the deterministic
ğ‘ƒ )âˆ’1(R>0)
reduction. Therefore (wtğ‘ƒ )âˆ’1(R>0) Ã— Tâˆ = (wtâˆ

âˆ«

âˆ«

âˆ«

âˆ«

âˆ«

âˆ«

=

=

=

=

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

and everything works as desired. Note that the second to
last equality follows from Fubiniâ€™s theorem and the fact that
â–¡
the product measure of ğœ‡T and ğœ‡Tâˆ

is ğœ‡Tâˆ

again.

C.2 Exhaustivity and Soundness
Example C.1 (more examples of exhaustive sets). Here are
more examples and counterexamples for exhaustivity.

(i) {âŸ¨âŸ©} is an (uninteresting) exhaustive set and only use-

ful for deterministic programs.

(ii) {âŸ¨[2âˆ’ğ‘›âˆ’1, 2âˆ’ğ‘›]âŸ© | ğ‘› âˆˆ N} is exhaustive because only

the trace âŸ¨0âŸ© (with measure 0) is not covered.

(iii) Let ğ‘ğ‘› â‰¥ 0 be a converging series, i.e. (cid:205)ğ‘›

ğ‘–=1 ğ‘ğ‘› < âˆ,

for example ğ‘ğ‘› = ğ‘›âˆ’2. Define

T := {âŸ¨[0, ğ‘’âˆ’ğ‘1], . . . , [0, ğ‘’âˆ’ğ‘ğ‘› ], [ğ‘’âˆ’ğ‘ğ‘›+1, 1]âŸ© | ğ‘› âˆˆ N}.
This is not an exhaustive set since it doesnâ€™t cover any of the
traces in

which has measure (cid:206)âˆ

[0, ğ‘’âˆ’ğ‘1) Ã— [0, ğ‘’âˆ’ğ‘2, 1) Ã— Â· Â· Â·
ğ‘–=1 ğ‘’âˆ’ğ‘ğ‘– = exp (cid:0)âˆ’ (cid:205)âˆ
We also note that exhaustivity can be expressed just in
terms of finite traces as well, at the cost of a more complicated
definition.

ğ‘–=1 ğ‘ğ‘– (cid:1) > 0.

Lemma C.2. A set of interval traces T is exhaustive if and
only if

ğœ‡T (cid:169)
(cid:173)
(cid:171)

[0, 1]ğ‘› \ (cid:169)
(cid:173)
(cid:171)

(cid:216)

âŸ¨ğ¼1,...,ğ¼ğ‘š âŸ© âˆˆT,ğ‘š â‰¤ğ‘›

as ğ‘› â†’ âˆ.
Proof. Let ğ‘† := Tâˆ \ (cid:208)
haustivity, ğœ‡Tâˆ (ğ‘†) = 0. Let

ğ¼1 Ã— Â· Â· Â· Ã— ğ¼ğ‘š Ã— [0, 1]ğ‘›âˆ’ğ‘š(cid:170)
(cid:174)
(cid:172)

(cid:170)
(cid:174)
(cid:172)

â†’ 0

ğ’• âˆˆT cover (ğ’•). By the definition of ex-

ğ‘†ğ‘› = [0, 1]ğ‘› \ (cid:169)
(cid:173)
(cid:171)

(cid:216)

âŸ¨ğ¼1,...,ğ¼ğ‘š âŸ© âˆˆT,ğ‘š â‰¤ğ‘›

ğ¼1 Ã— Â· Â· Â· Ã— ğ¼ğ‘š Ã— [0, 1]ğ‘›âˆ’ğ‘š(cid:170)
(cid:174)
(cid:172)

.

Itâ€™s easy to see that ğ‘† = (cid:209)âˆ
ğ‘›=0 ğ‘†ğ‘› Ã— Tâˆ where ğ‘†ğ‘› Ã— Tâˆ is a de-
creasing sequence of sets: ğ‘†1Ã—Tâˆ âŠ‡ ğ‘†2Ã—Tâˆ âŠ‡ Â· Â· Â· . Since mea-
sures are continuous from above, we have limğ‘›â†’âˆ ğœ‡T (ğ‘†ğ‘›) =
â–¡
limğ‘›â†’âˆ ğœ‡Tâˆ (ğ‘†ğ‘› Ã— Tâˆ) = ğœ‡Tâˆ (ğ‘†) = 0, as desired.

The following lemma establishes a correspondence be-
tween infinite trace semantics and interval trace semantics.

Lemma C.3. For any interval trace ğ’• and infinite trace ğ’”âˆ
with a prefix ğ’” such that ğ’” âŠ³ ğ’•, we have wtâˆ
ğ‘ƒ (ğ’•)
I
and valâˆ
ğ‘ƒ (ğ’”âˆ) âˆˆ val
ğ‘ƒ (ğ’•).
Proof. Follows directly from the definition of infinite trace
â–¡
semantics and Lemma 3.1.

ğ‘ƒ (ğ’”âˆ) âˆˆ wtI

Using the previous results, we can prove soundness of

upper bounds.

=

=

â‰¥

â‰¥

â‰¥

=

ğ’•

(cid:77)

(cid:76)
âˆ«

âˆ«

Tâˆ

ğ’•

(cid:76)

(cid:77)

ğ’• âˆˆ T
âˆ‘ï¸

ğ’• âˆˆ T
âˆ«

(cid:208)

âˆ«

Tâˆ
ğ‘ƒ
(cid:74)

(cid:75)

(ğ‘ˆ )

Theorem 4.2 (Sound upper bounds). Let T be a countable
and exhaustive set of interval traces and âŠ¢ ğ‘ƒ : R a program.
â‰¤ upperBdT
ğ‘ƒ .
Then
Proof. For any ğ‘ˆ âˆˆ Î£R, we have

ğ‘ƒ
(cid:74)

(cid:75)

upperBdT
âˆ‘ï¸

ğ‘ƒ (ğ‘ˆ )

vol(ğ’•)(sup wt

I
ğ‘ƒ (ğ’•)) [val

I
ğ‘ƒ (ğ’•) âˆ© ğ‘ˆ â‰  âˆ…]

ğ’• âˆˆ T
âˆ‘ï¸

âˆ«

I
I
ğ‘ƒ (ğ’•) âˆ© ğ‘ˆ â‰  âˆ…] dğ’”
(sup wt
ğ‘ƒ (ğ’•)) [val

wtâˆ

ğ‘ƒ (ğ’”ğ’–) [valâˆ

ğ‘ƒ (ğ’”ğ’–) âˆˆ ğ‘ˆ ] dğ’– dğ’”

wtâˆ

ğ‘ƒ (ğ’–) [valâˆ

ğ‘ƒ (ğ’–) âˆˆ ğ‘ˆ ] dğ’”

ğ’•

Ã—Tâˆ

ğ’• âˆˆT

(cid:77)
(cid:76)
ğ‘ƒ (ğ’–) [valâˆ
wtâˆ

ğ‘ƒ (ğ’–) âˆˆ ğ‘ˆ ] dğ’–

(4)

(5)

(6)

where Eq. (4) follows from Lemma C.3, Eq. (5) from exhaus-
â–¡
tivity and Eq. (6) from Lemma C.1.

C.3 Assumptions for Completeness

Remarks on Assumption 1. We can formally express
Assumption 1 from Section 4 about a given program âŠ¢ ğ‘ƒ : R
as follows. For each symbolic path Î¨ = (V, ğ‘›, Î”, Î), we
require that V, each C with C âŠ²âŠ³ 0 âˆˆ Î”, and each W âˆˆ Î
contain each sample variable ğ›¼ğ‘– at most once.

Example C.2. The pedestrian example (Example 1.1) satis-
fies Assumption 1 because the symbolic paths have the form
Î¨ = (V, ğ‘›, Î”, Î) with:
V = 3ğ›¼1
ğ‘› = 2ğ‘˜ + 1
Î” = {ğ›¼3 âˆ’ 1

2 âŠ²âŠ³ 0, . . . , ğ›¼2ğ‘˜+1 âˆ’ 1

2 âŠ²âŠ³ 0, ğ›¼5 âˆ’ 1

2 âŠ²âŠ³ 0}

âˆª {3ğ›¼1 > 0,

3ğ›¼1 Â± ğ›¼2 > 0,
. . . ,
3ğ›¼1 Â± ğ›¼2 Â± ğ›¼4 Â· Â· Â· Â± ğ›¼2ğ‘˜âˆ’2 > 0,
3ğ›¼1 Â± ğ›¼2 Â± ğ›¼4 Â· Â· Â· Â± ğ›¼2ğ‘˜ â‰¤ 0}
Î = {pdf Normal(1.1,0.1) (ğ›¼2 + ğ›¼4 + Â· Â· Â· + ğ›¼2ğ‘˜ )}

As we can see, none of the symbolic values contains a sample
variable twice, so the assumption is satisfied.

Remarks on Assumption 2. We first prove the sufficient

condition for interval separability from Section 4.2.

Lemma C.4. If a function ğ‘“ : Rğ‘› â†’ R is boxwise contin-
uous and preimages of points are null sets then ğ‘“ is interval
separable.

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Proof. We decompose ğ‘“ âˆ’1([ğ‘, ğ‘]) = ğ‘“ âˆ’1((ğ‘, ğ‘)) âˆª ğ‘“ âˆ’1({ğ‘, ğ‘})
and deal with the former set first. By boxwise continuity,
ğ‘“ = (cid:208)ğ‘– ğ‘“ |ğµğ‘– where (cid:208)ğ‘– ğµğ‘– = Rğ‘› and each ğ‘“ |ğµğ‘– is continuous
on ğµğ‘– . To show that the preimage ğ‘“ âˆ’1((ğ‘, ğ‘)) can be tightly
approximated by a countable set of boxes, it suffices to show
this for each (ğ‘“ |ğµğ‘– )âˆ’1((ğ‘, ğ‘)). This set is open in ğµğ‘– by con-
tinuity of ğ‘“ |ğµğ‘– , so it can be written as a countable union of
boxes (e.g. by taking a box within ğµğ‘– around each rational
point, which exists because itâ€™s an open set). By the assump-
tion, the preimage ğ‘“ âˆ’1({ğ‘, ğ‘}) is a null set. Hence ğ‘“ âˆ’1([ğ‘, ğ‘])
â–¡
can be approximated by a null set.

Note that a composition of interval separable functions
need not be interval separable. This is an incorrect assump-
tion made in the completeness proof of [4]. (To fix their
Theorem 3.8, one needs to make the additional assumption
that the set of primitive functions be closed under compo-
sition.) To see this, let ğ‘“ , ğ‘” : R â†’ R be interval separable
functions and ğ¼ an interval. By definition, there are intervals
ğµğ‘– such that (cid:208)ğ‘– ğµğ‘– âˆªğ‘ = ğ‘“ âˆ’1(ğ¼ ) where ğ‘ is a null set. Then by
interval separability, the preimage ğ‘”âˆ’1((cid:208)ğ‘– ğµğ‘– ) can be tightly
ğ‘— , but the preimage ğ‘”âˆ’1(ğ‘ ) need
approximated by interals ğµ â€²
not be a null set. It is also not clear at all whether one can
approximate the preimage (ğ‘“ â—¦ğ‘”)âˆ’1(ğ¼ ) tightly using intervals
without further restrictions on ğ‘“ and ğ‘”. For this reason, we
require the assumption that the set of primitive functions be
closed under composition.

It is not immediately obvious that such a set of functions
exists. One example is given by the following. A function
: Rğ‘› â†’ R is called a submersion if it is continuously
ğ‘“
differentiable and its gradient is nonzero everywhere.

Lemma C.5. The set Fsubm of submersions is closed under
composition and each of its functions is boxwise continuous
and interval separable.
Proof. Boxwise continuity is obvious given that the functions
are even continuously differentiable. For interval separabil-
ity, we use Lemma C.4. Let ğ‘“ : Rğ‘› â†’ R âˆˆ Fsubm. Since ğ‘“
is a submersion, the preimage ğ‘“ âˆ’1(ğ‘¥) of any point ğ‘¥ âˆˆ R
is an (ğ‘› âˆ’ 1)-dimensional submanifold of Rğ‘› by the preim-
age theorem (a variation of the implicit function theorem).
Submanifolds of codimension > 1 have measure zero. (This
well-known fact can be shown by writing the submanifold as
a countable union of graphs and applying Fubiniâ€™s theorem
to each of them.) Therefore, the lemma applies.

For closure under composition, let ğ‘“ : Rğ‘š â†’ R and ğ‘“ğ‘– :
Rğ‘›ğ‘– â†’ R for ğ‘– âˆˆ {1, . . . , ğ‘š}, all in Fsubm. The composition
ğ‘” := ğ‘“ â—¦ (ğ‘“1 Ã— Â· Â· Â· Ã— ğ‘“ğ‘š) is clearly ğ¶1 again, so we just have to
check the submersion property. By the chain rule, we find
that the gradient of the composition

âˆ‡ğ‘”(ğ‘¥1, . . . , ğ‘¥ğ‘š) = (cid:169)
(cid:173)
(cid:173)
(cid:171)

ğœ•1ğ‘“ (ğ‘“1(ğ‘¥1), . . . , ğ‘“ğ‘š (ğ‘¥ğ‘š)) Â· âˆ‡ğ‘“1(ğ‘¥1)
...
ğœ•ğ‘š ğ‘“ (ğ‘“1(ğ‘¥1), . . . , ğ‘“ğ‘š (ğ‘¥ğ‘š)) Â· âˆ‡ğ‘“ğ‘š (ğ‘¥ğ‘š)

(cid:170)
(cid:174)
(cid:174)
(cid:172)

is nonzero because at least one of the ğœ•ğ‘– ğ‘“ is nonzero and
âˆ‡ğ‘“ğ‘– (ğ‘¥ğ‘– ) â‰  0 by assumption. Hence the composition is a
â–¡
submersion again.

Unfortunately, the set of submersions does not contain
constant functions. This is a problem because then it is not
guaranteed that partially applying a primitive function to a
constant is still an admissible primitive function. (For exam-
ple, this would break Lemma C.8.) Hence we need to assume
that all constant functions be primitive functions. Luckily, the
set Fsubm of submersions can be easily extended to accom-
modate this.

subm be the set of functions ğ‘“ : Rğ‘› â†’ R (for
Lemma C.6. Let F âˆ—
all ğ‘› âˆˆ N) such that whenever the partial derivative ğœ•ğ‘– ğ‘“ (ğ‘¥) is
zero for some ğ‘– âˆˆ {1, . . . , ğ‘›} and ğ‘¥ âˆˆ Rğ‘› then ğ‘“ is constant in its
ğ‘–-th argument, i.e. there is a function ğ‘“ âˆ— : Rğ‘›âˆ’1 â†’ R such that
ğ‘“ (ğ‘¥1, . . . , ğ‘¥ğ‘›) = ğ‘“ âˆ— (ğ‘¥1, . . . , ğ‘¥ğ‘–âˆ’1, ğ‘¥ğ‘–+1, . . . ğ‘¥ğ‘›). This set satisfies
all the assumptions about sets of primitive functions: it is closed
under composition, contains all constant functions, and all its
functions are boxwise continuous and interval separable.
Proof. Boxwise continuity is obvious given that the functions
are even continuously differentiable. Similarly, it is clear that
F âˆ—

contains all constant functions.

subm
For interval separability, let ğ‘“ : Rğ‘› â†’ R âˆˆ F âˆ—

and ğ½ âŠ†
{1, . . . , ğ‘›} be the set of indices in which ğ‘“ is not constant, and
: R|ğ½ | â†’ R
ğ½ â€² its complement. Hence there is a submersion ğ‘“ğ½
such that ğ‘“ (ğ‘¥) = ğ‘“ğ½ (ğ‘¥ ğ½ ) where ğ‘¥ ğ½ stands for the vector of
coordinates of ğ‘¥ with index in ğ½ . The preimage of ğ‘“ âˆ’1(ğ‘ˆ ) âŠ†
R |ğ½ | of any set ğ‘ˆ âŠ† R can be tightly approximated by boxes
(ğ‘ˆ ) can because ğ‘“ âˆ’1(ğ‘ˆ ) is a Cartesian
if and only if ğ‘“ âˆ’1
(ğ‘ˆ ) and R |ğ½ â€² |. Since ğ‘“ğ½ is interval separable by
product of ğ‘“ âˆ’1
the previous lemma, this shows that ğ‘“ is as well.

subm

ğ½

ğ½

For closure under composition, let ğ‘“ : Rğ‘š â†’ R and ğ‘“ğ‘– :
Rğ‘›ğ‘– â†’ R for ğ‘– âˆˆ {1, . . . , ğ‘š}, all in F âˆ—
. The composition
ğ‘” := ğ‘“ â—¦ (ğ‘“1 Ã— Â· Â· Â· Ã— ğ‘“ğ‘š) is clearly ğ¶1 again, so we just have
to check the property of the partial derivatives. By the chain
rule, the partial derivatives of the composition are

subm

ğœ•ğ‘–ğ‘”(ğ‘¥1, . . . , ğ‘¥ğ‘š) = ğœ•ğ‘— ğ‘“ (ğ‘“1 (ğ‘¥1), . . . , ğ‘“ğ‘š (ğ‘¥ğ‘š))ğœ•ğ‘˜ ğ‘“ğ‘— (ğ‘¥ ğ‘—1, . . . , ğ‘¥ ğ‘—ğ‘› ğ‘— )
for some ğ‘— âˆˆ {1, . . . ğ‘š} and ğ‘˜ âˆˆ {1, . . . ğ‘› ğ‘— }, and for all ğ‘¥1 âˆˆ
Rğ‘›1, . . . , ğ‘¥ğ‘š âˆˆ Rğ‘›ğ‘š . So if this partial derivative is zero, there
are two cases. First, if ğœ•ğ‘— ğ‘“ (ğ‘“1(ğ‘¥1), . . . , ğ‘“ğ‘š (ğ‘¥ğ‘š)) = 0 then ğ‘“
must be constant in its ğ‘—-th argument (because ğ‘“ âˆˆ F âˆ—
)
subm
and thus ğ‘” is constant in ğ‘¥ ğ‘— , and in particular the ğ‘–-th argu-
ment (which is an entry of ğ‘¥ ğ‘— ). Second, if ğœ•ğ‘˜ ğ‘“ğ‘— (ğ‘¥ ğ‘—1, . . . , ğ‘¥ ğ‘—ğ‘› ğ‘— ) =
0 then ğ‘“ğ‘— must be constant in its ğ‘˜-th argument (because
) and thus ğ‘” is constant in its corresponding ğ‘–-th
ğ‘“ğ‘— âˆˆ F âˆ—
â–¡
argument as well. This proves ğ‘” âˆˆ F âˆ—

, as desired.

subm

subm

Note that exp, sinh, arctan, ğ‘›-th roots for ğ‘› odd, and all
. So this is a useful set of prim-
linear functions are in F âˆ—
itive functions already. Unfortunately, it does not include

subm

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

multiplication because the gradient of (ğ‘¥, ğ‘¦) â†¦â†’ ğ‘¥ğ‘¦ is zero at
(0, 0). To fix this issue, we need to restrict the domain.15

For simplicity, we required primitive functions to be de-
fined on all of Rğ‘›. Suppose we allow for primitive func-
tions to be defined only on an open subset of Rğ‘›, and ap-
plying them to a value outside their domain is disallowed
in SPCF programs. Then we can also include multiplication
(on R2 \ {(0, 0)}), logarithms (on (0, âˆ)), non-constant uni-
variate polynomials (on the complement of their stationary
points), quantile functions of continuous distributions with
nonzero density (on (0, 1)), and probability density functions
(on the complement of their stationary points). The fact that
some points in the domain are missing is inconvenient for
functions that can be continuously extended to the these
points, but one can work around this in a program by check-
ing for the points that are not in the domain and returning
the function values as constants for those cases.

C.4 Completeness Proof
This section uses the definitions of boxwise continuity and
interval separability from Section 4.2. As discussed there, we
assume that for each symbolic path Î¨ = (V, ğ‘›, Î”, Î), we
have that V, each C with C âŠ²âŠ³ 0 âˆˆ Î”, and each W âˆˆ Î
contains each sample variable ğ›¼ğ‘– at most once (Assumption
1). We also assume that the primitive functions are boxwise
continuous, interval separable and closed under composition
(Assumption 2). Furthermore, we say that T is a subdivision
of ğ’• if T is compatible and (cid:208)
ğ’• â€² âˆˆT
Theorem 4.3 (Completeness of interval approximations).
Let ğ¼ âˆˆ I and âŠ¢ ğ‘ƒ : R be an almost surely terminating program
satisfying the two assumptions discussed above. Then, for all
ğœ– > 0, there is a countable set of interval traces T âŠ† TI that is
compatible and exhaustive such that

.
(cid:77)

ğ’• â€²

=

(cid:77)

(cid:76)

(cid:76)

ğ’•

ğ‘ƒ
(cid:74)

upperBdT

ğ‘ƒ (ğ¼ ) âˆ’ ğœ– â‰¤

(ğ¼ ) â‰¤ lowerBdT

ğ‘ƒ (ğ¼ ) + ğœ–.

(cid:75)
Proof. First, we give a brief outline of how the proof works.
The idea is to cover {ğ’” âˆˆ T | valğ‘ƒ (ğ’”) âˆˆ ğ¼ } using boxes
(interval traces). We can achieve this using symbolic execu-
tion: for a fixed path through the program, the result value
is just a composition of primitive functions applied to the
samples. Similarly, the weight function is a product of such
functions, hence boxwise continuous. By passing to smaller
boxes, we can assume that it is continuous on each box. In
order to approximate the integral of the weight function, we
use Riemann sums (as used in the definition of the Riemann

15Handling these issues at the level of primitive functions directly (without
restricting the domain) seems challenging: even if a function has only
one point with zero gradient, e.g. multiplication, its preimage under other
primitive functions can become very complicated. We tried to handle this by
allowing the primitive functions to be submersions except on a null set given
by a union of lower-dimensional manifolds. However, the preimages of such
manifolds need not be manifolds again. Hence it seems difficult to come
up with a broader class of primitive functions satisfying the assumptions
without restricting the domain.

integral). We partition the domain into smaller and smaller
boxes such that the lower bound and the upper bound of the
weight function come arbitrarily close (by continuity). Then
by properties of the Riemann integral, the bounds arising
from the interval traces representing the boxes in this parti-
tion converge to the desired integral of the weight function.
The details of the proof are as follows.

ğ’•

(cid:76)

(cid:77)

ğ’• âˆˆ TÎ¨

Step 1: approximating the branching inequalities. Let
Î¨ = (V, ğ‘›, Î”, Î) a symbolic path of ğ‘ƒ. To find a countable set
TÎ¨ âŠ† TI such that (cid:208)
â‹ Satğ‘› (Î”). Note that Satğ‘› (Î”)
is a finite intersection of sets of the form {ğ’” âˆˆ [0, 1]ğ‘› |
C [ğ’”/ğ›¼] âŠ²âŠ³ 0} where âŠ²âŠ³âˆˆ {â‰¤, >}. In the â‰¤ case, we can write
this constraint as C [ğ’”/ğ›¼] âˆˆ (cid:208)ğ‘› âˆˆN [âˆ’ğ‘›, 0] and in the > case
as C [ğ’”/ğ›¼] âˆˆ (cid:208)ğ‘› âˆˆN [1/ğ‘›, ğ‘›]. By applying Lemma C.8 to each
of the compact intervals in these unions, we obtain a count-
able union of boxes that is a tight subset of {ğ’” âˆˆ [0, 1]ğ‘› |
C [ğ’”/ğ›¼] âŠ²âŠ³ 0}. Since the intersection of two boxes is a box
and since Satğ‘› (Î”) is a finite intersection of such countable
unions of boxes, it can be rewritten as a countable union of
boxes. This yields TÎ¨, such that (cid:208)

â‹ Satğ‘› (Î”).

ğ’•

ğ’•

ğ’•

Î¨,ğ¼ğ‘

ğ’• âˆˆTâ€²

ğ’• âˆˆ Tâ€²

Î¨,ğ¼ âŠ† TI such that (cid:208)

Step 2: handling the result value. By applying Lemma C.8
and intersecting the obtained interval traces with TÎ¨, we
â‹
obtain a countable set T â€²
Î¨,ğ¼ (cid:76)
(cid:77)
{ğ’” âˆˆ Sat(Î”) | V [ğ’”/ğ›¼] âˆˆ ğ¼ }. By the same lemma, we find
Î¨,ğ¼ ğ‘ âŠ† TI such that (cid:208)
â‹ {ğ’” âˆˆ
a countable set T â€²
Sat(Î”) | V [ğ’”/ğ›¼] âˆ‰ ğ¼ } because the complement of ğ¼ can be
written as a countable union of intervals. By Lemma C.10, we
find subdivisions TÎ¨,ğ¼ and TÎ¨,ğ¼ ğ‘ that even satisfy (cid:208)
â‹
ğ’• âˆˆTÎ¨,ğ¼
valâˆ’1
ğ‘ƒ (R \ ğ¼ ) âˆ© Sat(Î”).
By Lemma C.7, we can assume that the interval traces TÎ¨,ğ¼
are almost disjoint. Because of the almost sure termination
assumption, the set of traces (cid:208)
ğ‘ƒ (R)
where the union ranges over all symbolic paths of ğ‘ƒ has
measure 1. As a consequence, (cid:208)Î¨âˆˆsymPaths (ğ‘ƒ,0,âˆ…,âˆ…) (TÎ¨,ğ¼ âˆªTÎ¨,ğ¼ ğ‘ )
is a compatible and exhaustive set of interval traces. Now

( V,ğ‘›,Î”,Î) Sat(Î”) = valâˆ’1

ğ‘ƒ (ğ¼ ) âˆ© Sat(Î”) and (cid:208)

â‹ valâˆ’1

ğ’• âˆˆ TÎ¨,ğ¼ğ‘

(cid:77)

(cid:77)

(cid:77)

(cid:76)

(cid:76)

(cid:76)

ğ’•

ğ’•

ğ’• âˆˆ TÎ¨

(cid:76)

(cid:77)

(ğ¼ ) =

ğ‘ƒ
(cid:74)

(cid:75)

=

=

âˆ‘ï¸
( V,ğ‘›,Î”,Î) (cid:74)
âˆ«
âˆ‘ï¸

( V,ğ‘›,Î”,Î)
âˆ‘ï¸

(V, ğ‘›, Î”, Î)

(ğ¼ )

(cid:75)

[V [ğ’”/ğ›¼] âˆˆ ğ¼ ]

(cid:214)

W âˆˆÎ

W [ğ’”/ğ›¼] dğ’”

Satğ‘› (Î”)

âˆ‘ï¸

âˆ«

(cid:214)

W [ğ’”/ğ›¼] dğ’”

( V,ğ‘›,Î”,Î)

ğ’• âˆˆ T(V,ğ‘›,Î”,Î),ğ¼

ğ’•

(cid:76)

(cid:77)

W âˆˆÎ

where the outer sum ranges over the symbolic paths (V,
ğ‘›, Î”, Î) âˆˆ symPaths(ğ‘ƒ, 0, âˆ…, âˆ…). The first equality holds by
Theorem 6.1, the second one by Lemma B.1 and the last one
by the construction of T( V,ğ‘›,Î”,Î),ğ¼ .

Step 3: approximating the weight function. Let

T â€² := (cid:208)Î¨âˆˆsymPaths (ğ‘ƒ,0,âˆ…,âˆ…) TÎ¨,ğ¼ .

For each ğ’• âˆˆ T â€², fix some ğœ–ğ’• > 0, such that (cid:205)
ğ’• âˆˆTâ€² ğœ–ğ’• = ğœ–.
This can be achieved, for example, by enumerating T â€² as
ğ’• (1), ğ’• (2), . . . and choosing ğœ–
ğ’• (ğ‘– ) = 2âˆ’ğ‘–ğœ–. By Lemma C.9, we

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

can find for each ğ’• âˆˆ T â€² a countable set Sğ’• of interval traces
such that:

âˆ‘ï¸

ğ’• â€² âˆˆSğ’•
âˆ«

â‰¤

(cid:214)

W [ğ’”/ğ›¼] âˆ’ ğœ–ğ’• /2

vol(ğ’• â€²) sup
ğ’• â€²

ğ’” âˆˆ

W âˆˆÎ

(cid:76)

(cid:77)
W [ğ’”/ğ›¼] dğ’”

(cid:214)

ğ’•
(cid:76)
(cid:77)
âˆ‘ï¸

â‰¤

W âˆˆÎ
vol(ğ’• â€²) min
ğ’• â€²
(cid:77)

(cid:76)

(cid:214)

W [ğ’”/ğ›¼] + ğœ–ğ’• /2

ğ’• â€² âˆˆSğ’•

ğ’” âˆˆ
Next, choose ğœ–ğ’• â€² > 0 for each ğ’• â€² in such a way that (cid:205)
ğœ–ğ’• â€² <
ğœ–ğ’• /2. By Lemma C.11, we can find for each ğ’• â€² a finite subdi-
vision S â€²

ğ’• â€² âˆˆSâ€²
ğ’•

W âˆˆÎ

ğ’• â€² such that for all ğ’• â€²â€² âˆˆ S â€²
wtğ‘ƒ (ğ’”) = sup
ğ’• â€²â€²

ğ’• â€², we have
I
ğ‘ƒ (ğ’• â€²â€²) âˆ’ ğœ–ğ’• â€²
W [ğ’”/ğ›¼] â‰¥ sup wt

sup
ğ’• â€²â€²
ğ’” âˆˆ

(cid:214)

ğ’” âˆˆ

(cid:76)
(cid:77)
min
ğ’• â€²â€²
ğ’” âˆˆ

(cid:76)

(cid:77)

(cid:76)

(cid:77)
wtğ‘ƒ (ğ’”) = min
ğ’• â€²â€²
(cid:77)

ğ’” âˆˆ

(cid:76)

W âˆˆÎ
(cid:214)

W âˆˆÎ

I
ğ‘ƒ (ğ’• â€²â€²) + ğœ–ğ’• â€².
W [ğ’”/ğ›¼] â‰¤ min wt

Multiplying by vol(ğ’• â€²â€²) and summing over all ğ’• â€²â€², we find
together with the previous inequality

âˆ‘ï¸

âˆ‘ï¸

vol(ğ’• â€²â€²) sup wt

I
ğ‘ƒ (ğ’• â€²â€²) âˆ’ ğœ–ğ’•

ğ’• â€² âˆˆSğ’•

ğ’• â€²â€² âˆˆSâ€²
ğ’•â€²
âˆ‘ï¸

âˆ‘ï¸

â‰¤

â‰¤

â‰¤

â‰¤

vol(ğ’• â€²â€²)(sup wt

I
ğ‘ƒ (ğ’• â€²â€²) âˆ’ ğœ–ğ’• â€²) âˆ’ ğœ–ğ’• /2

ğ’• â€² âˆˆSğ’•
âˆ«

ğ’• â€²â€² âˆˆSâ€²
ğ’•â€²

(cid:214)

W [ğ’”/ğ›¼] dğ’”

ğ’•
(cid:76)
(cid:77)
âˆ‘ï¸

W âˆˆÎ
âˆ‘ï¸

ğ’• â€² âˆˆSğ’•
âˆ‘ï¸

ğ’• â€²â€² âˆˆSâ€²
ğ’•â€²
âˆ‘ï¸

ğ’• â€² âˆˆSğ’•

ğ’• â€²â€² âˆˆSâ€²
ğ’•â€²

vol(ğ’• â€²â€²)(min wt

I
ğ‘ƒ (ğ’• â€²â€²) + ğœ–ğ’• â€²) + ğœ–ğ’• /2

I
ğ‘ƒ (ğ’• â€²â€²) + ğœ–ğ’•
vol(ğ’• â€²â€²) min wt

vol(ğ’• â€²â€²) â‰¤ 1 and thus the contribution of all

because (cid:205)
the ğœ–ğ’• â€² is at most ğœ–ğ’• /2.

ğ’• â€²â€² âˆˆSâ€²
ğ’•â€²

Overall, the desired trace set is given by

T :=

(cid:216)

Î¨=( V,ğ‘›,Î”,Î)

TÎ¨,ğ¼ ğ‘ âˆª

(cid:216)

(cid:216)

ğ’• âˆˆTÎ¨,ğ¼

ğ’• â€² âˆˆSğ’•

(cid:169)
(cid:173)
(cid:171)

,

S â€²
ğ’• â€²(cid:170)
(cid:174)
(cid:172)

is compatible and exhaustive because it is a subdivision of
I
TÎ¨,ğ¼ ğ‘ and TÎ¨,ğ¼ . By construction, we have val
ğ‘ƒ (ğ’•) âŠ† ğ¼ for
I
ğ’• âˆˆ TÎ¨,ğ¼ and val
ğ‘ƒ (ğ’•) âˆ© ğ¼ = âˆ… for ğ’• âˆˆ TÎ¨,ğ¼ ğ‘ . Hence the TÎ¨,ğ¼ ğ‘ -
summands vanish in the sum for the bounds and we obtain

upperBdT
âˆ‘ï¸

ğ‘ƒ (ğ¼ ) âˆ’ ğœ–
I
I
vol(ğ’•)(sup wt
ğ‘ƒ (ğ’•) âˆ© ğ¼ â‰  âˆ…] âˆ’ ğœ–
ğ‘ƒ (ğ’•)) [val

=

ğ’• âˆˆT

=

âˆ‘ï¸

âˆ‘ï¸

Î¨=( V,ğ‘›,Î”,Î)

ğ’• âˆˆTÎ¨,ğ¼

(cid:169)
(cid:173)
(cid:171)

â‰¤

âˆ‘ï¸

âˆ‘ï¸

ğ’• â€² âˆˆSğ’•
âˆ‘ï¸

ğ’• â€²â€² âˆˆSâ€²
ğ’•â€²
âˆ‘ï¸

I
ğ‘ƒ (ğ’• â€²â€²) âˆ’ ğœ–ğ’• (cid:170)
vol(ğ’• â€²â€²) sup wt
(cid:174)
(cid:172)

âˆ«

(cid:214)

W [ğ’”/ğ›¼] dğ’”

Î¨=( V,ğ‘›,Î”,Î)
(cid:124)

(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)

ğ’• âˆˆTÎ¨,ğ¼

ğ’•

W âˆˆÎ
(cid:77)
(cid:76)
(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)
(cid:123)(cid:122)
(ğ¼ )
ğ‘ƒ
(cid:74)

(cid:75)

=

(cid:125)

â‰¤

=

âˆ‘ï¸

âˆ‘ï¸

Î¨=( V,ğ‘›,Î”,Î)

ğ’• âˆˆ TÎ¨,ğ¼

âˆ‘ï¸

âˆ‘ï¸

vol(ğ’• â€²â€²) min wt

I
ğ‘ƒ (ğ’• â€²â€²) + ğœ–ğ’• (cid:170)
(cid:174)
ğ’• â€² âˆˆSğ’•
(cid:172)
I
I
vol(ğ’•)(min wt
ğ‘ƒ (ğ’•) âŠ† ğ¼ ] + ğœ–
ğ‘ƒ (ğ’•)) [val

ğ’• â€²â€² âˆˆSâ€²
ğ’•â€²

(cid:169)
(cid:173)
(cid:171)
âˆ‘ï¸

ğ’• âˆˆ T

= lowerBdT

ğ‘ƒ (ğ¼ ) + ğœ–.

â–¡

Lemma C.7. Given a countable set of interval traces T âŠ† Iğ‘›,
there is a countable set of interval traces T â€² âŠ† Iğ‘› that is
compatible and satisfies (cid:208)
ğ’•
(cid:76)
Proof. Let ğ´ : N â†’ T be an enumeration. Define ğ´â€² : N â†’
Î£Rğ‘› by ğ‘š â†¦â†’ ğ´(ğ‘š) \ (cid:208)ğ‘šâˆ’1
ğ‘–=0 ğ´(ğ‘–) where ğ‘† denotes the closure
of ğ‘†. Then the collection {ğ´â€²(ğ‘š) | ğ‘š âˆˆ N} is pairwise almost
disjoint, and each ğ´â€²(ğ‘š) can be written as a finite union of
â–¡
boxes, proving the claim.

= (cid:208)

ğ’• âˆˆ Tâ€²

.
(cid:77)

ğ’• âˆˆ T

(cid:76)

(cid:77)

ğ’•

Lemma C.8. Let V a symbolic value of ground type contain-
ing each sample variable ğ›¼1, . . . , ğ›¼ğ‘› at most once and [ğ‘¥, ğ‘¦]
an interval. Then there is a countable set of pairwise disjoint
interval traces T âŠ‚ Iğ‘›
(cid:216)
ğ’• âˆˆ T(cid:76)

â‹ {ğ’” âˆˆ [0, 1]ğ‘› | V [ğ’”/ğ›¼] âˆˆ [ğ‘¥, ğ‘¦]}.

[0,1] such that

(cid:77)

ğ’•

Proof. If V is of ground type, then it is simply a composi-
tion of primitive functions applied to sample variables and
literals. Since the set of primitive functions is closed un-
der composition and since no sample variable occurs twice,
this composition is still an interval separable function ğ‘“
of the sample variables. By definition of interval separabil-
ity, there is a countable set of interval traces J such that
(cid:208)
â–¡

â‹ ğ‘“ âˆ’1([ğ‘¥, ğ‘¦]), as desired.

Lemma C.9. Let ğ’• âˆˆ Iğ‘› be an interval trace and Î a set of
symbolic values with sample variables from ğ›¼ = ğ›¼1, . . . , ğ›¼ğ‘›.
Then for any ğœ– > 0, there is a countable subdivision T of ğ’•
such that

ğ’• âˆˆ J

ğ’•

(cid:76)

(cid:77)

(cid:214)

W [ğ’”/ğ›¼] âˆ’ ğœ–

âˆ‘ï¸

ğ’• â€² âˆˆ T
âˆ«

â‰¤

vol(ğ’• â€²) sup
ğ’• â€²

ğ’” âˆˆ

(cid:214)

W âˆˆÎ

(cid:77)

(cid:76)
W [ğ’”/ğ›¼] dğ’”

ğ’•
(cid:77)
(cid:76)
âˆ‘ï¸

â‰¤

(cid:214)

W âˆˆÎ
vol(ğ’• â€²) min
ğ’• â€²
(cid:77)
Proof. Values are simply boxwise continuous functions ap-
plied to the sample variables. Intersecting the boxes for each
W âˆˆ Î, we see that the function

W [ğ’”/ğ›¼] + ğœ–.

W âˆˆÎ

ğ’• â€² âˆˆ T

ğ’” âˆˆ

(cid:76)

â†’ R,

ğ’” â†¦â†’

ğ‘“ :

ğ’•

(cid:76)

(cid:77)

(cid:214)

W âˆˆÎ

W [ğ’”/ğ›¼]

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

(cid:77)

(cid:76)

(cid:77)

ğ’• â€²

ğ’• â€²

is boxwise continuous. We can thus find a countable subdi-
vision Tcont of ğ’• such that ğ‘“ is continuous on each ğ’• â€² âˆˆ Tcont.
Since we can sum over the ğ’• â€² âˆˆ Tcont, it suffices to prove
that each integral âˆ«
ğ‘“ (ğ’”) dğ’” can be approximated arbitrar-
ily closely. Note that each such integral is finite because a
(cid:76)
continuous function is bounded on a compact set and the
measure of
is finite. But then such approximations are
given by Riemann sums, i.e. the sums that are used to de-
fine the Riemann integral. As a concrete example, one can
consider the subdivision Tğ‘š of ğ’• â€² in ğ‘š equidistant sections
in each dimension (consisting of ğ‘šğ‘› parts overall). Then
(cid:205)
ğ‘“ (ğ’”) converges to the Riemann in-
ğ’• â€²â€² âˆˆTğ‘š
tegral âˆ«
ğ‘“ (ğ’”) dğ’” as ğ‘š â†’ âˆ (and similarly for the supre-
mum). Since it is known that the Riemann integral and the
(cid:76)
Lebesgue integral have the same value for continuous func-
tions on a Cartesian product of compact intervals, the claim
â–¡
follows immediately.

vol(ğ’• â€²â€²) minğ’” âˆˆ

ğ’• â€²â€²

ğ’• â€²

(cid:77)

(cid:76)

(cid:77)

Lemma C.10 (Relationship between symbolic execution and
interval semantics). Let Î¨ = (V, ğ‘›, Î”, Î) be a symbolic path
âŠ† Satğ‘› (Î”). Suppose
of ğ‘ƒ and ğ’• an interval trace with
furthermore that all the symbolic values contain each of the
sample variables ğ›¼ = ğ›¼1, . . . , ğ›¼ğ‘› at most once. Then there is
a subdivision T of ğ’• such that for all ğ’• â€² âˆˆ T , the interval
semantics for the value is precise:

(cid:76)

(cid:77)

ğ’•

val

I
ğ‘ƒ (ğ’• â€²) = {valğ‘ƒ (ğ’”) | ğ’” âˆˆ

ğ’• â€²

}.

For each symbolic score value W âˆˆ Î, let [Wâˆ’

its interval approximation, i.e. Wâˆ’
W+

ğ’• â€² = sup

ğ’” âˆˆ

ğ’• â€²

W [ğ’”/ğ›¼]. Then
(cid:34)

(cid:76)

(cid:77)
I
ğ‘ƒ (ğ’• â€²) =
wt

(cid:214)

Wâˆ’

ğ’• â€² , (cid:214)

W+
ğ’• â€²

.

(cid:76)

ğ’• â€²

(cid:77)

(cid:35)

(cid:76)

(cid:77)
ğ’• â€² = minğ’” âˆˆ

ğ’• â€² , W+
ğ’• â€² ] be
W [ğ’”/ğ›¼] and

W âˆˆÎ

W âˆˆÎ

Proof. The symbolic value V is a composition of primitive
functions applied to ğ›¼â€™s. Hence the are boxwise continuous
functions of the ğ›¼â€™s. We pick a suitable subdivision T such
that all these functions are continuous when restricted to
any ğ’• â€² âˆˆ T . For any such function ğ‘“ , we have

ğ‘“I([ğ‘¥1, ğ‘¦1], . . . , [ğ‘¥ğ‘š, ğ‘¦ğ‘š]) = [inf ğ¹, sup ğ¹ ]
where ğ¹ := ğ‘“ ([ğ‘¥1, ğ‘¦1] Ã— Â· Â· Â· Ã— [ğ‘¥ğ‘š, ğ‘¦ğ‘š]) âŠ† R, by definition.
Then continuity implies that the image of any box is a com-
pact and path-connected subset of R, i.e. an interval. Hence
we even have ğ‘“I([ğ‘¥1, ğ‘¦1], . . . , [ğ‘¥ğ‘š, ğ‘¦ğ‘š]) = ğ¹ , i.e. the image of
any box equals its interval approximation, proving the claim
about the value semantics.

For the interval semantics of the weight, note that the
previous argument applies to every symbolic score value
W âˆˆ Î, proving that

{W [ğ’”/ğ›¼] | ğ’” âˆˆ

ğ’• â€²
(cid:77)
Since the interval semantics multiplies the interval approxi-
mation of each score value in interval arithmetic, this implies
â–¡
the claim.

ğ’• â€² , W+
ğ’• â€² ].

} = [Wâˆ’

(cid:76)

Note that the interval approximation of the weight is im-

precise in the following sense:

I
ğ‘ƒ (ğ’• â€²) â‰ 
wt

(cid:40)

(cid:214)

W âˆˆÎ

W [ğ’”/ğ›¼]

(cid:41)

.

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

ğ’” âˆˆ

ğ’• â€²

(cid:76)

(cid:77)

As an example, if Î = {ğ›¼1, 1 âˆ’ ğ›¼1} and ğ’• â€²â€² = âŸ¨[0, 1]âŸ© then
the left-hand side is [0, 1] because each of the weights is
approximated by [0, 1], but the right-hand side is [0, 1/4]
because the function ğ›¼1(1 âˆ’ ğ›¼1) attains its maximum at 1/4,
not 1.

ğ‘ƒ (ğ’• â€²) + ğœ– and sup

wtğ‘ƒ (ğ’”) â‰¤ min wtI

Lemma C.11. Let Î¨ = (V, ğ‘›, Î”, Î) be a symbolic path of ğ‘ƒ
âŠ† Satğ‘› (Î”). Suppose further-
and ğ’• an interval trace with
ğ’•
(cid:77)
(cid:76)
more that all the symbolic values contain each of the sample
variables ğ›¼ = ğ›¼1, . . . , ğ›¼ğ‘› at most once. Then for all ğœ– > 0,
there is a subdivision T of ğ’• such that for all ğ’• â€² âˆˆ T , we have
minğ’” âˆˆ
wtğ‘ƒ (ğ’”) â‰¥
ğ’• â€²
(cid:76)
(cid:77)
sup wtI
ğ‘ƒ (ğ’• â€²) âˆ’ ğœ–.
Proof. Since for each W âˆˆ Î, the function ğ‘“ :
â†’ R, ğ’” â†¦â†’
W [ğ’”/ğ›¼] is boxwise continuous (a property of primitive func-
tions), we can find a countable subdivision T â€² of ğ’•, such that
. Hence it suffices to
for all ğ’• â€² âˆˆ T â€², ğ‘“ is continuous on
prove the statement for each ğ’• â€².

(cid:76)
is compact (because itâ€™s closed and bounded),
ğ‘“ attains a maximum ğ‘Š < âˆ on
and is even uniformly
ğ’• â€²
continuous on ğ’• â€². Hence there is a ğ›¿ > 0 such that whenever
||ğ’” âˆ’ ğ’” â€²|| < ğ›¿ then |ğ‘“ (ğ’”) âˆ’ ğ‘“ (ğ’” â€²)| < ğœ– â€² :=

Since

ğ’• â€²

ğ’• â€²

ğ’” âˆˆ

ğ’• â€²

(cid:77)

(cid:76)

(cid:76)

(cid:77)

(cid:76)

(cid:77)

(cid:77)

ğ’•

(cid:76)

(cid:77)

ğœ–
ğ‘Š |Î|âˆ’1 .

:= minğ’” âˆˆ

Let T be a subdivision where each interval trace ğ’• âˆˆ
T has diameter less than ğ›¿. For ğ’• âˆˆ T and W âˆˆ Î, let
W [ğ’”/ğ›¼]. By
Wâˆ’
ğ’•
ğ’•
ğ’• + ğœ– â€² for ğ’• âˆˆ T . By
the choice of T , we have W+
(cid:76)
(cid:77)
(cid:77)
Lemma C.10, we find that sup wtI
ğ‘ƒ (ğ’•) = (cid:206)
and
W âˆˆÎ W+
ğ’•
min wtI
ğ‘ƒ (ğ’•) = (cid:206)
. As a consequence, we have
W âˆˆÎ Wâˆ’
ğ’•
I
I
ğ‘ƒ (ğ’•) âˆ’ min wt
sup wt
ğ‘ƒ (ğ’•) =

W [ğ’”/ğ›¼] and W+
ğ’•
ğ’• â‰¤ Wâˆ’

:= sup

W+

(cid:214)

(cid:214)

ğ’” âˆˆ

(cid:76)

ğ’•

Wâˆ’
ğ’•

ğ’• âˆ’

W âˆˆÎ
< (cid:214)
W âˆˆÎ

W âˆˆÎ
ğ’• + ğœ– â€²) âˆ’

(Wâˆ’

(cid:214)

W âˆˆÎ

Wâˆ’
ğ’•

< ğœ– â€²ğ‘Š |Î |âˆ’1 = ğœ–

So the interval wtI
interval {wtğ‘ƒ (ğ’”) | ğ’” âˆˆ
the claim follows.

ğ‘ƒ (ğ’•) has diameter less than ğœ–. Since the
} is contained in it (by soundness),
â–¡

ğ’• â€²

(cid:77)

(cid:76)

ğ‘ƒ (ğ¼ ) =

Corollary 4.4. Let ğ¼ âˆˆ I and âŠ¢ ğ‘ƒ : R be as in Theorem 4.3.
There is a sequence of finite, compatible sets of interval traces
T1, T2, . . . âŠ† TI s.t. limğ‘›â†’âˆ lowerBdTğ‘›
Proof. By Theorem 4.3, we can find for each ğ‘› âˆˆ N a set
of interval traces T â€²
ğ‘› such that lowerBd
(ğ¼ ) âˆ’
1/ğ‘›. Since the lower bound is defined as a sum over T â€²
ğ‘› ,
there is a finite subset Tğ‘› such that lowerBdTğ‘›
(ğ¼ ) âˆ’
ğ‘› is still compatible, the soundness result yields
2/ğ‘›. Since T â€²
lowerBdTğ‘›
â–¡

(ğ¼ ), implying the claim.

Tâ€²
ğ‘ƒ (ğ¼ ) >
ğ‘›

(cid:75)
ğ‘ƒ
(cid:74)

ğ‘ƒ (ğ¼ ) >

ğ‘ƒ
(cid:74)

ğ‘ƒ
(cid:74)

(ğ¼ ).

ğ‘ƒ (ğ¼ ) â‰¤

(cid:75)

(cid:75)

ğ‘ƒ
(cid:74)

(cid:75)

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Finitely many interval traces are not enough for complete
upper bounds, if the weight function is unbounded. This
issue arises even if we can compute the tightest possible
bounds on the weight function, as the following program
illustrates.

Example C.3. Consider the following probabilistic program
expressed in pseudocode.
threshold := 1
while (sample â‰¤ threshold) do

threshold := threshold
score(2)

2

The program only requires addition and scalar multiplica-
tion. It can even be implemented using call-by-name (CbN)
semantics (which allows each sampled value to be used at
most once). For example in SPCF we can write

ğ‘ƒ â‰¡ (cid:0)ğœ‡ğœ‘

ğ‘  . if (sample âˆ’ ğ‘ , score(2); ğœ‘ (ğ‘ /2), 1)(cid:1) 1

The program ğ‘ƒ has the weight function

wtğ‘ƒ (âŸ¨ğ‘¡0, . . . , ğ‘¡ğ‘›âŸ©) =

2ğ‘›

if ğ‘¡ğ‘› > 2âˆ’ğ‘›âˆ§

âˆ€ğ‘– âˆˆ {0, . . . , ğ‘› âˆ’ 1} : ğ‘¡ğ‘– â‰¤ 2âˆ’ğ‘–

0

otherwise.

ï£±ï£´ï£´ï£´ï£²
ï£´ï£´ï£´
ï£³

ğ‘ƒ is integrable because the normalizing constant is

ğ‘ =

âˆ«

T

wtğ‘ƒ (ğ’”) dğ’” =

âˆ
âˆ‘ï¸

ğ‘›=1

2ğ‘› Ã— (1 âˆ’ 2âˆ’ğ‘›)

ğ‘›âˆ’1
(cid:214)

ğ‘–=0

2âˆ’ğ‘–

=

âˆ
âˆ‘ï¸

ğ‘›=1

2ğ‘› (1 âˆ’ 2âˆ’ğ‘›)2âˆ’ğ‘› (ğ‘›âˆ’1)/2 < âˆ.

We claim that ğ‘ƒ requires infinitely many interval traces for
the upper bound to converge to the true denotation. Define
the sets of traces ğ‘‡ğ‘› for ğ‘› â‰¥ 1 by

ğ‘‡ğ‘› = [0, 20] Ã— [0, 2âˆ’1] Ã— Â· Â· Â· Ã— [0, 2âˆ’ğ‘›+1] Ã— (2âˆ’ğ‘›, 1].
Suppose we are given an arbitrary finite exhaustive set of
interval traces. This set needs to cover all of the ğ‘‡ğ‘›â€™s, so
one interval trace, say ğ’•, must cover infinitely many ğ‘‡ğ‘›â€™s.
Since wtğ‘ƒ (ğ’”) = 2ğ‘› for ğ’” âˆˆ ğ‘‡ğ‘›, the weight function on ğ’• is
unbounded. Therefore, the only possible upper bound for ğ’•
is âˆ, even if our semantics could compute the set {wtğ‘ƒ (ğ’”) |
} exactly. Hence any finite exhaustive interval trace
ğ’” âˆˆ
has upper bound âˆ, while the true denotation is finite. As
we have seen, this is not because of imprecision of interval
analysis, but an inherent problem if the weight function is
unbounded. So we cannot hope for complete upper bounds
with finitely many interval traces.

(cid:76)

(cid:77)

ğ’•

D Supplementary Material for Section 5
We provide additional proofs and material for Section 5. To
have access to named rules, we give the type system in Fig. 9
which agrees with the one in Fig. 4 in everything but the
labels.

D.1 Soundness
To show soundness (Theorem 5.1), we establish a (weight-
aware) subject reduction property for our type system as
follows. For an interval [ğ‘, ğ‘] âˆˆ I and ğ‘Ÿ âˆˆ Râ‰¥0, we define
ğ‘Ÿ Â· [ğ‘, ğ‘] := [ğ‘Ÿ Â· ğ‘, ğ‘Ÿ Â· ğ‘]. To simplify notation, we use a
modified transition relation that omits the concrete trace
(which is irrelevant in Theorem 5.1). We write ğ‘ƒ â†’ğ‘¤ ğ‘ƒ â€² if
(ğ‘ƒ, ğ’”, 1) â†’ (ğ‘ƒ â€², ğ’” â€², ğ‘¤) for some ğ‘¤ âˆˆ R and ğ’”, ğ’” â€² âˆˆ T. Note
that we could define â†’ğ‘¤ as a dedicated reduction system by
adapting the rules from â†’ in Fig. 2.

ğ‘–=1 : A.

: ğœğ‘– }ğ‘›
ğ‘–=1 âŠ¢ ğ‘ƒ : A for
(cid:27)
for all ğ‘– âˆˆ {1, . . . , ğ‘›}

Lemma D.1 (Substitution). If Î“; {ğ‘¥ğ‘–
(cid:26)ğœğ‘–
distinct variables ğ‘¥ğ‘– and if Î“ âŠ¢ ğ‘€ğ‘– :
1
then Î“ âŠ¢ ğ‘ƒ [ğ‘€ğ‘– /ğ‘¥ğ‘– ]ğ‘›
Proof. By a standard induction on ğ‘€.
Lemma D.2 (Weighted Subject Reduction). Let ğ‘ƒ be any
and ğ‘ƒ â†’ğ‘¤ ğ‘ƒ â€² for some ğ‘¤ > 0.
program such that âŠ¢ ğ‘ƒ :
(cid:26) ğœ
1
ğ‘¤ Â· ğ½

Then âŠ¢ ğ‘ƒ â€² :

(cid:26)ğœ
ğ½

â–¡

(cid:27)

(cid:27)

.

Proof. We prove this by induction on the structure of ğ‘ƒ.

Case ğ‘ƒ = sample: then ğ‘ƒ â†’1 ğ‘Ÿ for some ğ‘Ÿ âˆˆ [0, 1]. As
multiple consecutive application of (Sub) can be replaced
by a single one since (as âŠ‘A is transitive), we can assume
w.l.o.g. that the last step in âŠ¢ ğ‘ƒ :

was:

(cid:27)

(cid:26)ğœ
ğ½

(Sample)

(cid:27)

(Sub)

âŠ¢ sample :

âŠ¢ sample :

(cid:26)[0, 1]
1
(cid:26)ğ¼
ğ½

(cid:27)

By subtyping we have [0, 1] âŠ‘ ğ¼ and 1 âŠ‘ ğ½ . So [ğ‘Ÿ, ğ‘Ÿ ] âŠ‘ ğ¼ and
we can type âŠ¢ ğ‘Ÿ :

using (Lit) and (Sub) as required.

(cid:27)

(cid:26)ğ¼
ğ½

Case ğ‘ƒ = ğ‘“ (ğ‘Ÿ1, . . . , ğ‘Ÿ |ğ‘“ |): then ğ‘ƒ â†’1 ğ‘“ (ğ‘Ÿ1, . . . , ğ‘Ÿ |ğ‘“ |). W.l.o.g.,

we can assume that the last step in âŠ¢ ğ‘ƒ :

(cid:27)

(cid:26)ğœ
ğ½

was

âŠ¢ ğ‘Ÿ1 :

âŠ¢ ğ‘Ÿ1 :

(Lit)

(cid:27)

(Sub)

Â· Â· Â·

(cid:26)[ğ‘Ÿ1, ğ‘Ÿ1]
1
(cid:26)ğ¼1
ğ½1

(cid:27)

âŠ¢ ğ‘“ (ğ‘Ÿ1, . . . , ğ‘Ÿ |ğ‘“ |) :

(Lit)

(cid:27)

(Sub)

(Prim)

(cid:26)[ğ‘Ÿ |ğ‘“ |, ğ‘Ÿ |ğ‘“ |]
1
(cid:26)ğ¼ |ğ‘“ |
ğ½ |ğ‘“ |

(cid:27)

(cid:27)

(Sub)

âŠ¢ ğ‘Ÿ |ğ‘“ | :

âŠ¢ ğ‘Ÿ |ğ‘“ | :

(cid:26)ğ‘“ I(ğ¼1, . . . , ğ¼ |ğ‘“ |)
(Ã—I) |ğ‘“ |
ğ‘–=1ğ½ğ‘–
(cid:26)ğ¼
(cid:27)
ğ½

âŠ¢ ğ‘“ (ğ‘Ÿ1, . . . , ğ‘Ÿ |ğ‘“ |) :

So by subtyping ğ‘Ÿğ‘– âˆˆ ğ¼ğ‘– and 1 âˆˆ ğ½ğ‘– for all ğ‘–. By definition of
ğ‘“ I we thus have ğ‘“ (ğ‘Ÿ1, . . . , ğ‘Ÿ |ğ‘“ |) âˆˆ ğ‘“ I (ğ¼1, . . . , ğ¼ |ğ‘“ |) and (again
by subtyping) we have ğ‘“ (ğ‘Ÿ1, . . . , ğ‘Ÿ |ğ‘“ |) âˆˆ ğ¼ . Similarly, by def-
inition of Ã—I we have 1 âˆˆ (Ã—I) |ğ‘“ |
ğ‘–=1ğ½ğ‘– and thus 1 âˆˆ ğ½ . We can
using (Lit) and (Sub) as required.
type âŠ¢ ğ‘“ (ğ‘Ÿ1, . . . , ğ‘Ÿ |ğ‘“ |) :
Case ğ‘ƒ = if (ğ‘Ÿ, ğ‘€, ğ‘ ) and ğ‘Ÿ â‰¤ 0: then ğ‘ƒ â†’1 ğ‘€. W.l.o.g.,

(cid:26)ğ¼
ğ½

(cid:27)

we can assume that the last step in âŠ¢ ğ‘ƒ :

(cid:27)

(cid:26)ğœ
ğ½

is

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

(Var)

ğ‘¥ : ğœ âˆˆ Î“
(cid:26)ğœ
1

Î“ âŠ¢ ğ‘¥ :

(cid:27)

Î“ âŠ¢ ğ‘€ : A A âŠ‘A B
Î“ âŠ¢ ğ‘€ : B

(Sub)

(Sample)

Î“ âŠ¢ sample :

(cid:27)

(cid:26)[0, 1]
1

(Lit)

Î“ âŠ¢ ğ‘Ÿ :

(cid:27)

(cid:26)[ğ‘Ÿ, ğ‘Ÿ ]
1

Î“ âŠ¢ ğœ†ğ‘¥ .ğ‘€ :

(cid:27)

Î“; ğ‘¥ : ğœ âŠ¢ ğ‘€ : A (Abs)
(cid:26)ğœ â†’ A
1
(cid:26) ğœ2
[ğ‘’, ğ‘“ ]

ğœ1 â†’

(cid:27)

Î“ âŠ¢ ğ‘€ :

ï£±ï£´ï£´ï£²
ï£´ï£´
ï£³
Î“ âŠ¢ ğ‘€ğ‘ :

[ğ‘, ğ‘]
(cid:26)

ï£¼ï£´ï£´ï£½
ï£´ï£´
ï£¾

Î“; ğœ‘ : ğœ â†’ A; ğ‘¥ : ğœ âŠ¢ ğ‘€ : A

Î“ âŠ¢ ğœ‡ğœ‘

ğ‘¥ . ğ‘€ :

(cid:27)

(cid:26)ğœ â†’ A
1

(Fix)

Î“ âŠ¢ ğ‘ :

(cid:27)

(cid:26) ğœ1
[ğ‘, ğ‘‘]

Î“ âŠ¢ ğ‘€ :

(cid:27)

(cid:26)[_, _]
[ğ‘, ğ‘]

ğœ2
[ğ‘, ğ‘] Ã—I [ğ‘, ğ‘‘] Ã—I [ğ‘’, ğ‘“ ]
(cid:26) ğœ
[ğ‘, ğ‘‘]

Î“ âŠ¢ ğ‘ :

(cid:27)

Î“ âŠ¢ ğ‘ƒ :

(App)

(cid:27)

(cid:27)

(cid:26) ğœ
[ğ‘, ğ‘‘]

(If)

Î“ âŠ¢ if(ğ‘€, ğ‘ , ğ‘ƒ) :

(cid:26)

ğœ
[ğ‘, ğ‘] Ã—I [ğ‘, ğ‘‘]

(cid:27)

Î“ âŠ¢ ğ‘€ :

(cid:27)

(cid:26)[ğ‘, ğ‘]
[ğ‘, ğ‘‘]
[ğ‘, ğ‘] âŠ“ [0, âˆ]
[ğ‘, ğ‘‘] Ã—I (cid:0)[ğ‘, ğ‘] âŠ“ [0, âˆ](cid:1)

Î“ âŠ¢ score(ğ‘€) :

(cid:26)

(Score)

(cid:27)

Î“ âŠ¢ ğ‘€1 :

(cid:27)

(cid:26)[ğ‘1, ğ‘1]
[ğ‘1, ğ‘‘1]

Î“ âŠ¢ ğ‘“ (ğ‘€1, . . . , ğ‘€ |ğ‘“ |) :

Â· Â· Â·

(cid:26)[ğ‘ |ğ‘“ |, ğ‘ |ğ‘“ |]
Î“ âŠ¢ ğ‘€ |ğ‘“ | :
[ğ‘ |ğ‘“ |, ğ‘‘ |ğ‘“ |]
(cid:41)
(cid:40)ğ‘“ I ([ğ‘1, ğ‘1], . . . , [ğ‘ |ğ‘“ |, ğ‘ |ğ‘“ |])

(Ã—I) |ğ‘“ |

ğ‘–=1 [ğ‘ğ‘–, ğ‘‘ğ‘– ]

(cid:27)

(Prim)

Figure 9. Weight-aware interval type system for SPCF with typing rule names. The rules agree with those in Fig. 4.

(cid:26)[ğ‘Ÿ, ğ‘Ÿ ]
1
(cid:26) ğ¼
ğ½ â€²â€²

(cid:27)

(Lit)

(cid:27)

(Sub)

âŠ¢ ğ‘€ :

(cid:27)

(cid:26)ğœ â€²
ğ½ â€²

âŠ¢ ğ‘ :

(cid:27)

(cid:26)ğœ â€²
ğ½ â€²

âŠ¢ ğ‘Ÿ :

âŠ¢ ğ‘Ÿ :

âŠ¢ if (ğ‘Ÿ, ğ‘€, ğ‘ ) :

(cid:26)

âŠ¢ if (ğ‘Ÿ, ğ‘€, ğ‘ ) :

(cid:27)

(Sub)

ğœ â€²
ğ½ â€² Ã—I ğ½ â€²â€²
(cid:27)
(cid:26)ğœ
ğ½

(If)

and we have 1 âˆˆ ğ½ â€²â€², ğœ â€² âŠ‘ğœ ğœ and ğ½ â€² Ã—I ğ½ â€²â€² âŠ‘ ğ½ by subtyping.
As 1 âˆˆ ğ½ â€²â€², we get ğ½ â€² âŠ‘ ğ½ â€² Ã—I ğ½ â€²â€². Thus we obtain ğ½ â€² âŠ‘ ğ½ and
ğœ â€² âŠ‘ğœ ğœ, and we can type âŠ¢ ğ‘€ :

using (Sub).

(cid:27)

(cid:26)ğœ
ğ½

Case ğ‘ƒ = if (ğ‘Ÿ, ğ‘€, ğ‘ ) and ğ‘Ÿ > 0: then ğ‘ƒ â†’1 ğ‘ . Analogous

to the previous case.

Case ğ‘ƒ = score(ğ‘Ÿ ) and ğ‘Ÿ â‰¥ 0: then ğ‘ƒ â†’ğ‘Ÿ ğ‘Ÿ . W.l.o.g., we

can assume that the last step in âŠ¢ ğ‘ƒ :

(cid:27)

(cid:26)ğœ
ğ½

is

(Lit)

(cid:27)

(Sub)

âŠ¢ ğ‘Ÿ :

âŠ¢ ğ‘Ÿ :

(cid:26)[ğ‘Ÿ, ğ‘Ÿ ]
1
(cid:26)ğ¼ â€²
ğ½ â€²

(cid:27)

âŠ¢ score(ğ‘Ÿ ) :

(cid:26)

ğ¼ â€² âŠ“ [0, âˆ]
ğ½ â€² Ã—I (ğ¼ â€² âŠ“ [0, âˆ])
(cid:27)
(cid:26)ğ¼
ğ½

âŠ¢ score(ğ‘Ÿ ) :

(Score)

(cid:27)

(Sub)

By subtyping we have ğ‘Ÿ âˆˆ ğ¼ â€² and even ğ‘Ÿ âˆˆ ğ¼ â€² âŠ“ [0, âˆ] because
ğ‘Ÿ â‰¥ 0. Thus ğ‘Ÿ âˆˆ ğ¼ , again by subtyping. Similarly, 1 âˆˆ ğ½ â€² and
by definition of Ã—I, we have ğ‘Ÿ âˆˆ ğ½ â€² Ã—I (ğ¼ â€² âŠ“ [0, âˆ]). Thus
ğ‘Ÿ âˆˆ ğ½ by subtyping. This already implies 1 âˆˆ 1
ğ‘Ÿ Â· ğ½ and we
(cid:27)
can thus type âŠ¢ ğ‘Ÿ :

by using (Lit) and (Sub).

(cid:26) ğ¼
1
ğ‘Ÿ Â· ğ½

Case ğ‘ƒ = (ğœ†ğ‘¥ .ğ‘€)ğ‘‰ : then ğ‘ƒ â†’1 ğ‘€ [ğ‘‰ /ğ‘¥]. W.l.o.g., the last

step in âŠ¢ ğ‘ƒ :

(cid:27)

(cid:26)ğœ
ğ½

is

{ğ‘¥ : Ëœğœ â€²} âŠ¢ ğ‘€ :

(cid:27)

(cid:26) Ëœğœ â€²â€²
Ëœğ½ â€²â€²

âŠ¢ ğœ†ğ‘¥ .ğ‘€ :

âŠ¢ ğœ†ğ‘¥ .ğ‘€ :

(cid:27)

(cid:41)

(cid:26) Ëœğœ â€²â€²
Ëœğ½ â€²â€²

(cid:27)

(cid:41)

(cid:26)ğœ â€²â€²
ğ½ â€²â€²

(cid:40) Ëœğœ â€² â†’
1
(cid:40)ğœ â€² â†’
ğ½ â€²

âŠ¢ (ğœ†ğ‘¥ .ğ‘€)ğ‘‰ :

(cid:26)

(Abs)

(Sub)

âŠ¢ ğ‘‰ :

(cid:27)

(cid:26) ğœ â€²
ğ½ â€²â€²â€²

ğœ â€²â€²
ğ½ â€² Ã—I ğ½ â€²â€² Ã—I ğ½ â€²â€²â€²
(cid:27)
(cid:26)ğœ
ğ½

âŠ¢ (ğœ†ğ‘¥ .ğ‘€)ğ‘‰ :

(App)

(cid:27)

(Sub)

By subtyping we get that ğœ â€² âŠ‘ğœ Ëœğœ â€². It is easy to see that we
because ğ‘‰ is a value and we get
can also type âŠ¢ ğ‘‰ :
(cid:27)

by (Sub). Using Lemma D.1, we can thus type

(cid:26)ğœ â€²
1

(cid:27)

âŠ¢ ğ‘‰ :

(cid:26) Ëœğœ â€²
1

âŠ¢ ğ‘€ [ğ‘‰ /ğ‘¥] :

(cid:27)

.

(cid:26) Ëœğœ â€²â€²
Ëœğ½ â€²â€²

We have 1 âˆˆ ğ½ â€² by subyptying and as ğ‘‰ is a value, it
is easy to see that 1 âˆˆ ğ½ â€²â€²â€². Hence ğ½ â€²â€² âŠ‘ ğ½ â€² Ã—I ğ½ â€²â€² Ã—I ğ½ â€²â€²â€².
Also by subtyping, we find Ëœğœ â€²â€² âŠ‘ğœ ğœ â€²â€² âŠ‘ğœ ğœ, Ëœğ½ â€²â€² âŠ‘ ğ½ â€²â€², and
ğ½ â€² Ã—I ğ½ â€²â€² Ã—I ğ½ â€²â€²â€² âŠ‘ ğ½ . This implies Ëœğœ â€²â€² âŠ‘ğœ ğœ and Ëœğ½ â€²â€² âŠ‘ ğ½ . By
subtyping âŠ¢ ğ‘€ [ğ‘‰ /ğ‘¥] :

, as required.

(cid:27)

(cid:26)ğœ
ğ½

Case ğ‘ƒ = (ğœ‡ğœ‘

ğ‘¥ .ğ‘€)ğ‘‰ : then ğ‘ƒ â†’1 ğ‘€ [ğ‘‰ /ğ‘¥, (ğœ‡ğœ‘

ğ‘¥ .ğ‘€)/ğœ‘]. Anal-

ogous to the previous case for abstractions.

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Case ğ‘ƒ = ğ¸ [ğ‘ƒ â€²] for an evaluation context ğ¸ â‰  [Â·]: then
ğ‘ƒ â€² â†’ğ‘Ÿ ğ‘ƒ â€²â€² and ğ‘ƒ â†’ğ‘Ÿ ğ¸ [ğ‘ƒ â€²â€²]. All such cases follow easily
by case analysis on ğ¸. As an example, consider the context
ğ¸ = [Â·]ğ‘ . In this situation, we have ğ‘ƒ = ğ¸ [ğ‘ƒ â€²] = ğ‘ƒ â€²ğ‘ with
(cid:27)
(cid:26)ğœ
ğ‘ƒ â€² â†’ğ‘Ÿ ğ‘ƒ â€²â€², so ğ‘ƒ â†’ğ‘Ÿ ğ‘ƒ â€²â€²ğ‘ . W.l.o.g., the last step in âŠ¢ ğ‘ƒ :
ğ½
is

âŠ¢ ğ‘ƒ â€² :

(cid:27)

(cid:41)

(cid:26)ğœ â€²â€²
ğ½ â€²â€²

(cid:40)ğœ â€² â†’
ğ½ â€²

âŠ¢ ğ‘ :

(cid:27)

(cid:26) ğœ â€²
ğ½ â€²â€²â€²

(cid:26)

âŠ¢ ğ‘ƒ â€²ğ‘ :

ğœ â€²â€²
ğ½ â€² Ã—I ğ½ â€²â€² Ã—I ğ½ â€²â€²â€²
(cid:27)
(cid:26)ğœ
ğ½

âŠ¢ ğ‘ƒ â€²ğ‘ :

(App)

(cid:27)

(Sub)

By the inductive assumption for ğ‘ƒ â€² â†’ğ‘Ÿ ğ‘ƒ â€²â€², we get âŠ¢ ğ‘ƒ â€²â€² :
(cid:40)ğœ â€² â†’

(cid:41)

(cid:27)

and can then type

(cid:26)ğœ â€²â€²
ğ½ â€²â€²
1
ğ‘Ÿ Â· ğ½ â€²

âŠ¢ ğ‘ƒ â€²â€² :

(cid:40)ğœ â€² â†’

(cid:26)ğœ â€²â€²
ğ½ â€²â€²
1
ğ‘Ÿ Â· ğ½ â€²
(cid:26)

âŠ¢ ğ‘ƒ â€²ğ‘ :

(cid:27)

(cid:41)

âŠ¢ ğ‘ :

(cid:27)

(cid:26) ğœ â€²
ğ½ â€²â€²â€²

(App)

(cid:27)

(Sub)

ğœ â€²â€²
1
ğ‘Ÿ Â· ğ½ â€² Ã—I ğ½ â€²â€² Ã—I ğ½ â€²â€²â€²
(cid:26) ğœ
1
ğ‘Ÿ Â· ğ½

(cid:27)

âŠ¢ ğ‘ƒ â€²ğ‘ :

because if ğ½ â€² Ã—I ğ½ â€²â€² Ã—I ğ½ â€²â€²â€² âŠ‘ ğ½ then 1

ğ‘Ÿ Â· ğ½ .
The proof for the other evaluation contexts, i.e., where ğ‘ƒ =
if (ğ‘ƒ â€², ğ‘€, ğ‘ ), ğ‘ƒ = ğ‘‰ ğ‘ƒ â€², ğ‘ƒ = score(ğ‘ƒ â€²), or ğ‘ƒ = ğ‘“ (ğ‘Ÿ1, . . . , ğ‘Ÿğ‘–âˆ’1,
ğ‘ƒ â€², ğ‘ğ‘–+1, . . . , ğ‘ |ğ‘“ |) for some ğ‘ƒ â€² â†’ğ‘Ÿ ğ‘ƒ â€²â€², are all analogous to
â–¡
the above.

ğ‘Ÿ Â· ğ½ â€² Ã—I ğ½ â€²â€² Ã—I ğ½ â€²â€²â€² âŠ‘ 1

Lemma D.3 (Zero-Weighted Subject Reduction). Let ğ‘ƒ be
(cid:27)
(cid:26)ğœ
any program such that âŠ¢ ğ‘ƒ :
ğ½
(cid:27)
(cid:26) ğœ
ğ½ â€²

and ğ‘ƒ â†’0 ğ‘ƒ â€². Then

for some ğ½ â€², and

1. âŠ¢ ğ‘ƒ â€² :
2. 0 âˆˆ ğ½

(cid:27)

for some ğ½ â€² is analogous to

(cid:26) ğœ
Proof. The proof that âŠ¢ ğ‘ƒ â€² :
ğ½ â€²
the proof of Lemma D.2 with fewer restrictions on the weight.
The claim 0 âˆˆ ğ½ follows by observing that ğ‘ƒ â†’0 ğ‘ƒ â€² is only
possible if the redex in ğ‘ƒ is score(0). In case ğ‘ƒ = score(0),
the claim follows directly from (Score). If ğ‘ƒ = ğ¸ [score(0)],
it is a simple induction on the structure of the evaluation
â–¡
context ğ¸.

(cid:27)

Theorem 5.1. Let âŠ¢ ğ‘ƒ : R be a simply-typed program. If
âŠ¢ ğ‘ƒ : (cid:26)[ğ‘, ğ‘]
and (ğ‘ƒ, ğ’”, 1) â†’âˆ— (ğ‘Ÿ, âŸ¨âŸ©, ğ‘¤) for some ğ’” âˆˆ T and
[ğ‘, ğ‘‘]
ğ‘Ÿ, ğ‘¤ âˆˆ R, then ğ‘Ÿ âˆˆ [ğ‘, ğ‘] and ğ‘¤ âˆˆ [ğ‘, ğ‘‘].
Proof. Let

(ğ‘ƒ, ğ’”, 1) = (ğ‘ƒ0, ğ’”0, ğ‘¤0) â†’ Â· Â· Â· â†’ (ğ‘ƒğ‘›, ğ’”ğ‘›, ğ‘¤ğ‘›) = (ğ‘Ÿ, âŸ¨âŸ©, ğ‘¤)
be the reduction sequence of (ğ‘ƒ, ğ’”, 1). By definition of â†’ğ‘¤ it
is easy to see that we get

ğ‘ƒ = ğ‘ƒ0 â†’ Ëœğ‘¤1 ğ‘ƒ1 â†’ Ëœğ‘¤2 Â· Â· Â· â†’ Ëœğ‘¤ğ‘› ğ‘ƒğ‘› = ğ‘Ÿ

for unique Ëœğ‘¤1, . . . , Ëœğ‘¤ğ‘›. Note that ğ‘¤ğ‘– = (cid:206)ğ‘–

ğ‘—=1 Ëœğ‘¤ ğ‘— .

We first assume that ğ‘¤ â‰  0 (so Ëœğ‘¤ğ‘– â‰  0 for all ğ‘–). We claim

that for each 0 â‰¤ ğ‘– â‰¤ ğ‘›, we can type
[ğ‘, ğ‘]
Â· [ğ‘, ğ‘‘]

âŠ¢ ğ‘ƒğ‘– :

(cid:26)

(cid:27)

1
ğ‘¤ğ‘–
Equation (7) follows by simple induction: the base case ğ‘– = 0
and because ğ‘¤0 = 1.
holds by the assumption âŠ¢ ğ‘ƒ0 :
[ğ‘, ğ‘]
Â· [ğ‘, ğ‘‘]

For the inductive case, we assume that âŠ¢ ğ‘ƒğ‘– :
. We
apply Lemma D.2 to ğ‘ƒğ‘– â†’ Ëœğ‘¤ğ‘– ğ‘ƒğ‘–+1 and finish the induction
step using ğ‘¤ğ‘–+1 = ğ‘¤ğ‘– Ëœğ‘¤ğ‘–+1:

(cid:26)[ğ‘, ğ‘]
[ğ‘, ğ‘‘]

1
ğ‘¤ğ‘–

(cid:26)

(cid:27)

(cid:27)

(7)

âŠ¢ ğ‘ƒğ‘–+1 :

(cid:26)

[ğ‘, ğ‘]
Â· 1
ğ‘¤ğ‘–

Â· [ğ‘, ğ‘‘]

1
Ëœğ‘¤ğ‘–+1

Equation (7) thus implies âŠ¢ ğ‘Ÿ :

[ğ‘, ğ‘]

(cid:27)

Â· [ğ‘, ğ‘‘]

(cid:27)

(cid:26)

=

1
ğ‘¤ğ‘–+1
(cid:26) [ğ‘, ğ‘]
1
ğ‘¤ Â· [ğ‘, ğ‘‘]

assume that this type judgment has the form

(cid:27)

. W.l.o.g., we can

(Const)

(cid:27)

âŠ¢ ğ‘Ÿ :

(cid:26)[ğ‘Ÿ, ğ‘Ÿ ]
1
(cid:26) [ğ‘, ğ‘]
1
ğ‘¤ Â· [ğ‘, ğ‘‘]
This implies ğ‘Ÿ âˆˆ [ğ‘, ğ‘] and ğ‘¤ âˆˆ [ğ‘, ğ‘‘] (because 1 âˆˆ 1

âŠ¢ ğ‘Ÿ :

(Sub)

(cid:27)

ğ‘¤ Â·

[ğ‘, ğ‘‘]), as required.

Now consider the case ğ‘¤ = 0, so at least one Ëœğ‘¤ğ‘– = 0.
The claim that ğ‘Ÿ âˆˆ [ğ‘, ğ‘] follows easily as above (now using
Item 1 of Lemma D.3 to handle the weight 0 reduction steps).
Let ğ‘–âˆ— be the smallest index such that Ëœğ‘¤ğ‘–âˆ— = 0. Using the
same argument as above on the (possibly empty) prefix up
to index ğ‘–âˆ— âˆ’ 1 (where all Ëœğ‘¤ ğ‘— are non-zero) we find

(cid:26)

[ğ‘, ğ‘]

(cid:27)

âŠ¢ ğ‘ƒğ‘–âˆ—âˆ’1 :

1
ğ‘¤ğ‘–âˆ—âˆ’1
Note that this is well defined because Ëœğ‘¤ ğ‘— > 0 for ğ‘— < ğ‘–âˆ—.
Â· [ğ‘, ğ‘‘], which already
Item 2 of Lemma D.3 shows 0 âˆˆ
â–¡
implies ğ‘¤ = 0 âˆˆ [ğ‘, ğ‘‘], as required.

Â· [ğ‘, ğ‘‘]

1
ğ‘¤ğ‘–âˆ—âˆ’1

D.2 Weak Completeness
Proposition 5.2. Let âŠ¢ ğ‘ƒ : ğ›¼ be a simply-typed program.
There exists a weighted interval type A such that âŠ¢ ğ‘ƒ : A.
Proof. For every simple type ğ›¼, we define a weighted type
Ağ›¼ and weightless type ğœğ›¼ by mutual recursion as follows.
ğœR := [âˆ’âˆ, âˆ]
ğœğ›¼â†’ğ›½ := ğœğ›¼ â†’ Ağ›½

Ağ›¼ :=

(cid:27)

(cid:26) ğœğ›¼
[0, âˆ]

That is, we insert [âˆ’âˆ, âˆ] for values and [0, âˆ] for weights
in all locations. We claim that if âŠ¢ ğ‘ƒ : ğ›¼ in the simple type
system, then âŠ¢ ğ‘ƒ : Ağ›¼ in the weight-aware interval type
system.

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

For the proof, we strengthen the induction hypothesis
by claiming: if Î“ âŠ¢ ğ‘ƒ : ğ›¼ in the simple type system then
Î“â†‘ğœ âŠ¢ ğ‘ƒ : Ağ›¼ where

Î“â†‘ğœ := {ğ‘¥ : ğœğ›¼ | ğ‘¥ : ğ›¼ âˆˆ Î“}.
The claim can be proved by simple induction on the deriva-
tion of Î“ âŠ¢ ğ‘ƒ : ğ›¼ using the respective typing rule for the
interval type system possibly followed by (Sub) for typing
rules that yield proper subtypes of Ağ›¼ .

Note that this typing derivation does not contain any
â–¡

useful information to improve the precision of GuBPI.

D.3 Constraint-based Type Inference
In this section we formalize the constraint-based type infer-
ence algorithm and sketch our constraints-solving method
based on worklist and widening. The overarching idea is
to substitute intervals with variables ğœˆğ‘– , called interval vari-
ables, and to encode typability as a constraint system. As
we work in the restricted interval domain (as opposed to
e.g. full first-order refinements), the resulting constraints
can be solved very efficiently, which is crucial to the practi-
cality of our tool.

Symbolic types. Symbolic types are defined by the fol-

lowing grammar:

ğœ… := ğœˆğ‘– | ğœ… â†’ ğ’œ

ğ’œ :=

(cid:27)

(cid:26) ğœ…
ğœˆ ğ‘—

where ğœˆğ‘–, ğœˆ ğ‘— are interval variables. Symbolic types are iden-
tical to interval types but use interval variables instead of
intervals as first-order types and in the weight bound.

Constraints. Constraints on interval variables come in

three forms:

ğ‘ := ğœˆğ‘› â‰¡ [ğ‘, ğ‘]

(cid:12)
(cid:12)
(cid:12)

ğœ…1 âŠ‘ ğœ…2

(cid:12)
(cid:12)
(cid:12)

ğœˆğ‘› â‰¡ ğ‘“ (ğœˆğ‘›1, . . . , ğœˆğ‘›|ğ‘“ | )

where ğ‘“ is a primitive function and [ğ‘, ğ‘] an interval. That
is, a constraint can either equate an interval variable to a
particular interval, require a symbolic type ğœ…1 to be a sub-
type of a type ğœ…2, or equate an interval variable to the result
of a function applied to interval variables. Note that due to
the compositional nature of our subtype relation âŠ‘ (which
extends to symbolic types) we can restrict ourself to con-
straints of the form ğœˆ1 âŠ‘ ğœˆ2 because each constraint of the
form ğœ…1 âŠ‘ ğœ…2 or ğ’œ1 âŠ‘ ğ’œ2 (with identical base types) can
be reduced to an equivalent set of constraints on interval
variables by the definition of the subtype relation.

Symbolic type system. In the presentation of our sym-
bolic type inference system, we aim to stay as close as possi-
ble to the implementation. Thus we describe it as an impure
type system, meaning that our typing rules have side effects.
In our case, typing rules can generate fresh interval variables.
For a simple type ğ›¼, we write fresh(ğ›¼) for the symbolic
weightless type obtained by replacing every base type R
with a fresh interval variable ğœˆğ‘› (and adding weights given

by fresh interval variables where needed). We write fresh()
for fresh(R). For a symbolic type ğœ… we write base(ğœ…) for the
underlying simple type (defined in the obvious way).

Our constraint generation system is given in Fig. 10. Judg-
ments have the form Î“ âŠ¢ ğ‘€ : ğ’œ, C where Î“ maps variables
to weightless symbolic types, ğ’œ is a weighted symbolic type
and C a list of constraints on the interval variables. The
rules follow the structure of the system in Fig. 4 but replace
all operations on intervals with interval variables and con-
straints. The term structure directly determines the symbolic
typing derivation; there are no choices to be made, contrary
to Fig. 4, which requires â€œclevernessâ€, for example to find a
suitable interval for an argument in the fixpoint rule. Note
that in our system, we assume that the simple types of argu-
ments of abstractions and fixpoints are given. These types
can be determined by a simple prior run of any standard
type inference algorithm.

From symbolic to concrete types. An assignment ğ´ is a
mapping from interval variables to concrete intervals. Given
a symbolic type ğœ…, we define the interval type ğœ…ğ´ by replac-
ing every interval variable in ğœ… with the concrete interval
assigned to it in ğ´. For a weighted symbolic type ğ’œ, we
define ğ’œğ´ in the same way. Given a set of constraints C, we
say that ğ´ satisfies C, written ğ´ |= C if all constraints in C
are satisfied (defined in the obvious way).

Theorem D.4. If âŠ¢ ğ‘€ : ğ’œ, C and ğ´ |= C then âŠ¢ ğ‘€ : ğ’œğ´.
Proof. This can be shown by induction on the structure of
the term, which also determines the symbolic typing deriva-
tion. From this, we obtain a valid interval typing derivation
by replacing interval variables in the derivation with the
concrete intervals assigned to them in ğ´, and by applying
the (Sub) rule in places where subtyping constraints are
â–¡
introduced.

This theorem states that solutions to our constraints di-
rectly give us valid judgments in our interval type system,
which allows us to invoke Theorem 5.1.

Solving Constraints. To solve the resulting constraints,
we employ known techniques from abstract interpretation
[14]. Again, note that due to the simplicity of our constraints,
our approach avoids expensive calls to a theorem prover.
When solving a set of constraints C, we are interested in the
smallest solution, i.e. an assignment ğ´ with ğ´ |= C where
the intervals in A are smallest possible w.r.t. âŠ‘.

NaÃ¯ve algorithm. A naÃ¯ve attempt to find a satisfying
assignment for a set of constraints would be to iterate over
the constraints and to extend the current assignment (ini-
tially chosen to map all elements to the bottom element
âŠ¥ in the interval domain, i.e. an empty interval) whenever
needed. For example, if ğœˆğ‘– âŠ‘ ğœˆ ğ‘— is not satisfied by assign-
ment ğ´, we can update ğ´ by mapping ğœˆ ğ‘— to ğ´(ğœˆ ğ‘— ) âŠ” ğ´(ğœˆğ‘– ).
As is well known from abstract interpretation, this naÃ¯ve

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Î“ âŠ¢ score(ğ‘€) :

(cid:27)

(cid:26)ğœˆ1
ğœˆ2

, C

ğœˆ = fresh()

(cid:26)ğœˆ1
ğœˆ
(cid:26)ğœ…1
ğœˆ1

(cid:27)

(cid:27)

, C âˆª {ğœˆ â‰¡ ğœˆ1 Ã— ğœˆ2}

; ğ‘¥ : ğœ… âŠ¢ ğ‘€ :

(cid:27)

(cid:26)ğœ…2
ğœˆ2

, C

ğ‘¥ : ğœ… âˆˆ Î“

ğœˆ = fresh()

ğœ… = fresh(ğ›¼)

Î“; ğ‘¥ : ğœ… âŠ¢ ğ‘€ : ğ’œ, C

Î“ âŠ¢ ğ‘€ :

Î“ âŠ¢ ğ‘¥ :

(cid:27)

(cid:26)ğœ…
ğœˆ

, {ğœˆ â‰¡ 1}

ğœˆ = fresh()
(cid:26)ğœ… â†’ ğ’œ
ğœˆ

Î“ âŠ¢ ğœ†ğ‘¥ğ›¼ .ğ‘€ :

(cid:27)

, C âˆª {ğœˆ â‰¡ 1}

ğœˆ2 = fresh()

ğœ… = fresh(ğ›¼)

ğœ…1 = fresh(ğ›½)

ğœˆ, ğœˆ1 = fresh()

Î“; ğœ‘ : ğœ… â†’

ğœˆ1 = fresh()
(cid:26)ğœˆ1
ğœˆ2

Î“ âŠ¢ ğ‘Ÿ :

(cid:27)

, {ğœˆ1 â‰¡ [ğ‘Ÿ, ğ‘Ÿ ], ğœˆ2 â‰¡ 1}

ğœˆ, ğœˆ â€² = fresh()
(cid:26) ğœˆ
ğœˆ â€²

(cid:27)

Î“ âŠ¢ sample :

, {ğœˆ â‰¡ [0, 1], ğœˆ â€² â‰¡ 1}

Î“ âŠ¢ ğ‘€ :

(cid:27)

(cid:26)ğœˆ1
ğœˆ2

, Cğ‘€

Î“ âŠ¢ ğ‘ :

Î“ âŠ¢ if (ğ‘€, ğ‘ , ğ‘ƒ) :

(cid:26)ğœ…
ğœˆ

(cid:26)ğœ…1
ğœˆ3
(cid:27)

Î“ âŠ¢ ğœ‡ğœ‘:ğ›¼â†’ğ›½
ğ‘¥

. ğ‘€ :

, C âˆª {ğœˆ â‰¡ 1, ğœ…2 âŠ‘ ğœ…1, ğœˆ2 âŠ‘ ğœˆ1}

ï£¼ï£´ï£´ï£½
ï£´ï£´
ï£¾

(cid:27)

(cid:26)ğœ…2
ğœˆ2

ğœˆ

ï£±ï£´ï£´ï£²
ğœ… â†’
ï£´ï£´
ï£³
(cid:26)ğœ…2
ğœˆ2

(cid:27)

Î“ âŠ¢ ğ‘€ :

ï£±ï£´ï£´ï£²
ğœ…1 â†’
ï£´ï£´
ï£³

ğœˆ1

Î“ âŠ¢ ğ‘€ğ‘ :

(cid:27)

(cid:26)ğœ…2
ğœˆ

(cid:27)

, C1

Î“ âŠ¢ ğ‘ :

(cid:26)ğœ…3
ğœˆ3

ï£¼ï£´ï£´ï£½
ï£´ï£´
ï£¾
, C1 âˆª C2 âˆª {ğœ…3 âŠ‘ ğœ…1, ğœˆ â‰¡ ğœˆ1 Ã— ğœˆ2 Ã— ğœˆ3}

, C2

ğœˆ = fresh()

(cid:27)

, Cğ‘

Î“ âŠ¢ ğ‘ƒ :

(cid:27)

(cid:26)ğœ…2
ğœˆ4

, Cğ‘ƒ

ğœ… = fresh(base(ğœ…1))

ğœˆ, ğœˆ â€² = fresh()

, Cğ‘€ âˆª Cğ‘ âˆª Cğ‘ƒ âˆª {ğœ…1 âŠ‘ ğœ…, ğœ…2 âŠ‘ ğœ…, ğœˆ â‰¡ ğœˆ2 Ã— ğœˆ â€², ğœˆ3 âŠ‘ ğœˆ â€², ğœˆ4 âŠ‘ ğœˆ â€²}

Î“ âŠ¢ ğ‘€1 :

(cid:27)

(cid:26)ğœˆ1
ğœˆ â€²
1

, C1

Î“ âŠ¢ ğ‘“ (ğ‘€1, . . . , ğ‘€ |ğ‘“ |) :

Â· Â· Â·

(cid:27)

(cid:26) ğœˆ
ğœˆ â€²

Î“ âŠ¢ ğ‘€ |ğ‘“ | :

(cid:41)

(cid:40)ğœˆ |ğ‘“ |
ğœˆ â€²
|ğ‘“ |

, C|ğ‘“ |

ğœˆ, ğœˆ â€² = fresh()

, (cid:208)|ğ‘“ |

ğ‘–=1 Cğ‘– âˆª {ğœˆ â‰¡ ğ‘“ (ğœˆ1, . . . , ğœˆ |ğ‘“ |), ğœˆ â€² â‰¡ (cid:206)|ğ‘“ |

ğ‘–=1 ğœˆ â€²
ğ‘– }

Figure 10. Symbolic weight-aware type system.

approach may not terminate because the interval domain is
not chain-complete. For instance, consider the constraints
C = {ğœˆ1 = [0, 0], ğœˆ2 = [1, 1], ğœˆ1 âŠ‘ ğœˆ3, ğœˆ3 â‰¡ ğœˆ3 + ğœˆ2}. The
minimal solution is {ğœˆ1 â†¦â†’ [0, 0], ğœˆ2 â†¦â†’ [1, 1], ğœˆ3 â†¦â†’ [0, âˆ]},
but the algorithm never terminates and instead assigns the
ascending chain [0, 0], [0, 1], [0, 2], . . . to ğœˆ3.

Widening. To remedy the above problem, we use widen-
ing, a standard approach to ensure termination of abstract
interpretation on domains with infinite chains [14]. Let âˆ‡ be
a widening operator for intervals. This means that ğ¼1 âŠ” ğ¼2 âŠ‘
ğ¼1âˆ‡ğ¼2 for all intervals ğ¼1, ğ¼2 and for every chain ğ¼0 âŠ‘ ğ¼1 âŠ‘ ğ¼2 âŠ‘
Â· Â· Â· , the chain (ğ¼ âˆ‡
ğ‘–âˆ’1âˆ‡ğ¼ğ‘–
for ğ‘– â‰¥ 1 stabilises eventually. A trivial widening operator is
given by only allowing intervals to extend to infinity, defined
as follows:

ğ‘– )ğ‘– âˆˆN defined by ğ¼ âˆ‡

0 := ğ¼0 and ğ¼ âˆ‡
ğ‘–

:= ğ¼ âˆ‡

âŠ¥âˆ‡ğ¼ := ğ¼ âˆ‡âŠ¥ := ğ¼

[ğ‘, ğ‘]âˆ‡[ğ‘, ğ‘‘] := [ğ‘, ğ‘]
[ğ‘, ğ‘]âˆ‡[ğ‘, ğ‘‘] := [ğ‘, âˆ]
[ğ‘, ğ‘]âˆ‡[ğ‘, ğ‘‘] := [âˆ’âˆ, ğ‘]
[ğ‘, ğ‘]âˆ‡[ğ‘, ğ‘‘] := [âˆ’âˆ, âˆ]

if ğ‘ â‰¤ ğ‘ âˆ§ ğ‘‘ â‰¤ ğ‘
if ğ‘ â‰¤ ğ‘ âˆ§ ğ‘‘ > ğ‘
if ğ‘‘ â‰¤ ğ‘ âˆ§ ğ‘ < ğ‘
if ğ‘ < ğ‘ âˆ§ ğ‘‘ > ğ‘

As soon as the upper bound increases or lower bound de-
creases, the bound is directly set to = âˆ or âˆ’âˆ respectively.

By using the widening operator in each update step of our
naÃ¯ve algorithm, we break infinite increasing chains and the
resulting algorithm is guaranteed to converge to a satisfying
assignment (if one exists).

GuBPI solves constraints by using a standard worklist
algorithm [15, 23], combined with the previous widening
operator.

E Supplementary Material for Section 6
E.1 Extensions to Linear Splitting
In this section we give additional information about how
our linear optimisation of the interval-trace semantics can
be extended to non-uniform samples and non-linear scoring
values.

Beyond uniform samples. To allow for non-uniform sam-
ples, we can combine the standard interval trace semantics
with the linear optimisation. That is, in addition to bounding
linear score functions, we also split and bound each non-
uniform sample (as in the standard interval trace semantics).
Suppose that ğ›¼ğ‘– is sampled from some continuous distribu-
tion ğ·. We then split the real line into chunks (the size and
number of which is selected by a heuristic depending on
ğ·). For each such chunk [ğ‘, ğ‘], we compute the volume and
multiply by the lower and upper bounds of the pdf of ğ· on
[ğ‘, ğ‘]. In this way, we can even approximate integrals where

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

not all variables are sampled from a uniform distribution
(without needing to resort to inverse cumulative distribution
functions). Our experiments show, that as long as the guards
are still linear, this approach is advantageous compared to
the naive interval-based semantics.

ğ‘–

ğ‘– , . . . , Zğ‘šğ‘–

Beyond linear functions. While guards on conditionals
are often linear, this is rarely the case for score expressions
(as one usually observes values from some non-uniform dis-
tribution with a non-linear pdf). Consider the pedestrian
example again. While all guards are linear, the score expres-
sion has the form pdf Normal(1.1,0.1) (V). We can handle such
non-linear score values by applying linear optimisation to
the linear subexpressions and interval arithmetic for the
nonlinear parts. Formally, we assume that each Wğ‘– âˆˆ Î
(each symbolic value we score with) has the form Wğ‘– =
ğ‘—
ğ‘“ğ‘– (Z1
ğ‘– for 1 â‰¤ ğ‘— â‰¤ ğ‘šğ‘– denote linear
) where Z
: Rğ‘šğ‘– â†’ R is a
functions of the sample variables and ğ‘“
possibly non-linear function. Every score expression can be
written in this way. For instance, in the pedestrian example,
.
we have ğ‘“ = pdf Normal(1.1,0.1)
ğ‘—
Let Îâ€² = {Z
ğ‘–

| ğ‘– âˆˆ {1, . . . , ğ‘›}, ğ‘— âˆˆ {1, . . . , ğ‘šğ‘– }} be the set of
all such linear functions. We bound each linear function in Îâ€²
using linear optimisation as before. We obtain a box ğ‘ (which
now has dimension |Îâ€²| instead of |Î|) and define the weight
weight (ğ‘) by applying the interval liftings ğ‘“ I
ğ‘– of the non-
linear functions ğ‘“ğ‘– to the bounds for each argument. Formally,
weight (ğ‘) = (cid:206)ğ‘˜
ğ‘– is the interval
ğ‘—
bound on Z
ğ‘– . Note that this strictly generalizes the approach
outlined before since we can choose ğ‘“ğ‘– as the identity if Wğ‘–
is already linear. The definition of approx (ğ‘) with the new
weight definition still satisfies Proposition 6.4. This way, we
can even approximate integrals over non-linear functions by
means of simple volume computations. As our experiments
(e.g. on the pedestrian example) show, this approximation is
precise enough to obtain useful bounds on the posterior. It
is important to note that while we can deal with non-linear
score values, we cannot handle non-linear guards and instead
use the standard semantics for such cases.

) where ğ‘ ğ‘—

ğ‘– , . . . , ğ‘ğ‘šğ‘–

ğ‘–=1 ğ‘“ I

ğ‘– (ğ‘1

ğ‘–

F Supplementary Material for Section 7
Our experiments were performed on a server running Ubuntu
18.04 with an 8core Intel(R) Xeon(R) CPU E3-1271 v3 @
3.60GHz CPU with 32Gbp of RAM. The current version of
GuBPI is not parallelised and makes no use of the additional
cores. The running times on a Macbook Pro with Apple M1
were comparable, and sometimes even faster.

F.1 Pyroâ€™s HMC samples for the pedestrian example
The HMC samples plotted in Figs. 1 and 7 were generated
with the probabilistic programming system Pyro [5]. Since
the original pedestrian program has infinite expected run-
ning time, we introduced a stopping condition in the ran-
dom walk: if the distance traveled exceeded 10, the loop

was exited. (This has a negligible effect on the posterior
distribution because the weight of such a trace is at most
pdf Normal(1.1,0.1) (10) < 10âˆ’1700.)

We used Pyroâ€™s HMC sampler to compute 10 Markov
chains with 1000 samples each for this program. We set
the hyperparamaters to 0.1 for the step size and 50 for the
number of steps. We also tried the NUTS sampler, which
aims to automatically estimate good values for the hyperpa-
rameters, but it performed worse than the manually chosen
values. The running time for the chains varied significantly:
some took around one minute, others almost an hour. This
depended on whether the Markov chain got â€œstuckâ€ in a long
trace. (The length of the traces varied between 2 and about
200.)

We discarded chains with very low acceptance rates (under
1%), aggregated the remaining chains, which had acceptance
rates of over 50%, and used their histogram in Figs. 1 and 7.

F.2 Details on Probability Estimation
In Table 1 (results of our tool for the probability estima-
tion benchmark), we omitted the query for space reasons.
Complete information including the query can be found in
Table 4.

F.3 Simulation-based Calibration
We implemented SBC for both likelihood-weighted impor-
tance sampling and Pyroâ€™s HMC. As hyperparameters for
SBC, we picked ğ¿ = 63 samples per simulation (following
the suggestion in [60] to take one less than a power of two)
and ğ‘ simulations with ğ‘ = 10ğ¿ (also following the paperâ€™s
suggestion). Note that the number of samples is much less
than the 10000 samples used for Figs. 1 and 7 (10 chains with
1000 samples each). But setting ğ¿ = 1000 would be at least
100 times slower because ğ‘ has to increase proportionally
to ğ¿. Also note that for Pyro, we ran HMC with ğ¿ warmup
steps before generating ğ¿ samples. Both importance samples
and HMC samples exhibited significant autocorrelation. As
suggested in [60], we applied thinning to reduce its effect,
choosing a thinning factor of around ğ¿
where ğ¿eff is the
ğ¿eff
effective sample size.

Pedestrian example. For importance sampling, the rank
histogram looks fairly uniform (Fig. 11a), which means that
SBC does not detect an issue with the inference and thus
increases the confidence in the validity of the importance
samples. For Pyroâ€™s HMC, simulation-based calibration is
very slow: the rank histogram (Fig. 11b) took 32 hours (!) to
produce. (Note that only 332 simulations could be used, the
rest were discarded because the acceptance rate was too low.)
The spikes at the boundary indicate that the samples have
high autocorrelation and in fact, the effective sample size ğ¿eff
was at most ğ¿
10 , often much lower (depending on the chain).
The suggestion in [60] is thus to apply thinning, with a factor
of ğ¿
, which is at least 10 in our case. This would increase
ğ¿eff

Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming

PLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Table 4. Evaluation on selected benchmarks from [56]. We give the times (in seconds) and bounds computed by [56] and
GuBPI. The table agrees with Table 1 but spells out the full problem name and the exact query.

Program

tug-of-war

tug-of-war

beauquier-etal-3

example-book-simple

example-book-simple

example-cart

example-cart

Q

Q1

Q2

Q1

Q1
Q2â˜…
Q1

Q2

example-cart
Q3
example-ckd-epi-simple Q1â˜…
example-ckd-epi-simple Q2â˜…
Q1
example-fig6

example-fig6

example-fig6

example-fig6

example-fig7

example4

example5

herman-3

Q2

Q3

Q4

Q1

Q1

Q1

Q1

Query

total_ğ‘_ğ‘ < total_ğ‘¡_ğ‘ 
total_ğ‘_ğ‘  < total_ğ‘_ğ‘¡
count < 1
count â‰¥ 2
count â‰¥ 4
count â‰¥ 1
count â‰¥ 2
count â‰¥ 4
ğ‘“1 â‰¤ 4.4 âˆ§ ğ‘“ â‰¥ 4.6
ğ‘“1 â‰¥ 4.6 âˆ§ ğ‘“ â‰¤ 4.4
ğ‘ â‰¤ 1
ğ‘ â‰¤ 2
ğ‘ â‰¤ 5
ğ‘ â‰¤ 8
ğ‘¥ â‰¤ 1000
ğ‘¥ + ğ‘¦ > 10
ğ‘¥ + ğ‘¦ > ğ‘§ + 10
count < 1

Tool from [56]

GuBPI

ğ’•

1.29

1.09

1.15

8.48

10.3

2.41

2.40

0.15

0.15

0.08

1.31

1.80

1.51

3.96

0.04

0.02

0.06

0.47

Result

[0.6126, 0.6227]
[0.5973, 0.6266]
[0.5000, 0.5261]
[0.6633, 0.7234]
[0.3365, 0.3848]
[0.8980, 1.1573]
[0.8897, 1.1573]
[0.0000, 0.1150]
[0.5515, 0.5632]
[0.3019, 0.3149]
[0.1619, 0.7956]
[0.2916, 1.0571]
[0.4314, 2.0155]
[0.4400, 3.0956]
[0.9921, 1.0000]
[0.1910, 0.1966]
[0.4478, 0.4708]
[0.3750, 0.4091]

ğ’•

0.72

0.79

22.5

6.52

8.01

67.3

68.5

67.4

0.86

0.84

21.2

21.4

24.7

27.4

0.18

0.31

0.27

124

Result

[0.6134, 0.6135]
[0.6134, 0.6135]
[0.4999, 0.5001]
[0.7417, 0.7418]
[0.4137, 0.4138]
[0.9999, 1.0001]
[0.9999, 1.0001]
[0.0000, 0.0001]
[0.0003, 0.0004]
[0.0003, 0.0004]
[0.1899, 0.1903]
[0.3705, 0.3720]
[0.7438, 0.7668]
[0.8682, 0.9666]
[0.9980, 0.9981]
[0.1918, 0.1919]
[0.4540, 0.4541]
[0.3749, 0.3751]

(a) Importance sampling for the
pedestrian example, thinning fac-
tor 100.

(b) HMC for the pedestrian exam-
ple, no thinning. (Only 332 simu-
lations were used because the rest
had too low acceptance rates.)

(c) NUTS for the binary Gaussian
mixture model, thinning factor 10.

(d) NUTS for the two-dimensional
binary Gaussian mixture model,
thinning factor 10.

Figure 11. Simulation-based calibration: rank histogram plots (630 simulations with 63 samples each).

the running time of SBC by the same factor, to at least 300
hours, but probably 600 or more. We did not consider it a
good use of resources to carry out this experiment.

Binary Gaussian Mixture Model. We also considered
the binary GMM (Fig. 5c) and a two-dimensional version of
the same model. The spikes at the boundary could again be
a sign of high autocorrelation, but in this case, we already
applied thinning with a factor of 10 (again based on the effec-
tive sample size). Instead, as discussed in [60], this symmetric

U-shape indicates that the computed data-averaged poste-
rior is underdispersed relative to the prior distribution. This
interpretation is consistent with our knowledge about the
model: HMC only finds one mode in the posterior distribu-
tion and misses the others. Hence SBC successfully detects
the issue, and in the case of the higher-dimensional model,
it does so in less time than GuBPI (cf. Table 3). For the other
models, including the pedestrian example, GuBPI is faster.

0102030405060Rank051015202530Count0102030405060Rank020406080100120140160Count0102030405060Rank020406080100Count0102030405060Rank020406080100CountPLDI â€™22, June 13â€“17, 2022, San Diego, CA, USA

Raven Beutner, C.-H. Luke Ong, and Fabian Zaiser

Contents

Introduction

Guaranteed Bounds
Contributions
Scope and Limitations

Background

Basic Probability Theory and Notation
Statistical PCF (SPCF)
Trace Semantics

Interval Trace Semantics
Interval Arithmetic
Interval Traces and Interval SPCF
Bounds from Interval Traces

Soundness and Completeness

Soundness
Completeness

Weight-aware Interval Type System

Interval Types
Type System
Constraint-based Type Inference

Symbolic Execution and GuBPI

Symbolic Execution
GuBPI
Standard Interval Trace Semantics
Linear Interval Trace Semantics

Practical Evaluation

Probability Estimation
Exact Inference
Recursive Models

Abstract
1
1.1
1.2
1.3
2
2.1
2.2
2.3
3
3.1
3.2
3.3
4
4.1
4.2
5
5.1
5.2
5.3
6
6.1
6.2
6.3
6.4
7
7.1
7.2
7.3

Comparison with Statistical Validation
Limitations and Future Improvements

Related Work
Conclusion

Supplementary Material for Section 3

Intervals as a lattice
Lifting Functions to Intervals
Properties of Interval Reduction
Additional Possible Reduction Rules

Symbolic Execution
Supplementary Material for Section 4

Infinite Trace Semantics
Exhaustivity and Soundness
Assumptions for Completeness
Completeness Proof

Supplementary Material for Section 5

Soundness
Weak Completeness
Constraint-based Type Inference
Supplementary Material for Section 6
Extensions to Linear Splitting
Supplementary Material for Section 7

Pyroâ€™s HMC samples for the pedestrian
example
Details on Probability Estimation
Simulation-based Calibration

7.4
7.5
8
9
References
A
A.1
A.2
A.3
A.4
B
C
C.1
C.2
C.3
C.4
D
D.1
D.2
D.3
E
E.1
F
F.1

F.2
F.3
Contents

13
13
13
14
15
17
17
17
17
17
18
19
19
20
20
22
25
25
27
28
29
29
30

30
30
30
32

1
1
2
2
3
3
3
3
4
4
4
4
5
6
6
6
7
7
8
8
8
8
9
9
10
10
10
11
12

