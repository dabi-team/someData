0
2
0
2

v
o
N
8
1

]

G
L
.
s
c
[

3
v
8
6
9
1
1
.
6
0
0
2
:
v
i
X
r
a

A SPARSE CODE INCREASES THE SPEED AND EFFICIENCY OF
NEURO-DYNAMIC PROGRAMMING FOR OPTIMAL CONTROL
TASKS WITH CORRELATED INPUTS

A POSTPRINT

Peter N. Loxley
School of Science and Technology,
University of New England,
Armidale 2351, NSW, Australia.

ABSTRACT

Sparse codes in neuroscience have been suggested to offer certain computational advantages over
other neural representations of sensory data. To explore this viewpoint, a sparse code is used to
represent natural images in an optimal control task solved with neuro-dynamic programming, and
its computational properties are investigated. The central ﬁnding is that when feature inputs to a
linear network are correlated, an over-complete sparse code increases the memory capacity of the
network in an efﬁcient manner beyond that possible for any complete code with the same-sized
input, and also increases the speed of learning the network weights. A complete sparse code is
found to maximise the memory capacity of a linear network by decorrelating its feature inputs to
transform the design matrix of the least-squares problem to one of full rank.
It also conditions
the Hessian matrix of the least-squares problem, thereby increasing the rate of convergence to the
optimal network weights. Other types of decorrelating codes would also achieve this. However, an
over-complete sparse code is found to be approximately decorrelated, extracting a larger number
of approximately decorrelated features from the same-sized input, allowing it to efﬁciently increase
memory capacity beyond that possible for any complete code: a 2.25 times over-complete sparse
code is shown to at least double memory capacity compared with a complete sparse code using the
same input. This is used in sequential learning to store a potentially large number of optimal control
tasks in the network, while catastrophic forgetting is avoided using a partitioned representation,
yielding a cost-to-go function approximator that generalizes over the states in each partition. Sparse
code advantages over dense codes and local codes are also discussed.

1 Introduction

Sparse codes have traditionally been viewed as efﬁcient, low bit-rate representations of sensory data such as nat-
ural images (Barlow, 1961; Daugman, 1989; Field, 1994; Hyv¨arinen et. al., 2009). Evidence also exists that the
mammalian visual cortex makes use of a sparse code for visual stimuli such as natural images (Vinje & Gallant,
2000). It has long been known that pixel representations of images are highly redundant (see historical references
in Petrov and Li (2003), and Eichhorn et. al. (2009), for example). Spatial correlations mean the value of a pixel at
one point often leads to a reasonable prediction for the value of a pixel at a nearby point, and higher-order statis-
tical dependencies are also present. Daugman showed it is possible to transform an image to a new representation
with fewer statistical dependencies and a lower entropy which he termed a sparse code (Daugman, 1989). This
was originally done using a complete, discrete, two-dimensional Gabor transform (Daugman, 1988). A well-known
property of the two-dimensional (2D) Gabor function is that its parametric form also describes neural receptive ﬁeld
proﬁles (Daugman, 1985; Jones and Palmer, 1987). Olshausen and Field later demonstrated the converse of Daug-
mans’ work, namely that learning a sparse code for natural images leads to proﬁles similar to those of neural receptive
ﬁelds (Olshausen and Field, 1996, 1997). More recent work relates to ﬁnding highly over-complete sparse codes
(Rehn and Sommer, 2007; Olshausen, 2013), and the role of homeostasis during the process of learning a sparse code
(Perrinet, 2010, 2019).

 
 
 
 
 
 
A sparse code increases the speed and efﬁciency of neuro-dynamic programming for optimal
control tasks with correlated inputs

A POSTPRINT

If sparse coding is a neural coding principle then it should have computational advantages over other coding ap-
proaches. F¨oldi´ak originally compared sparse codes with local codes and dense codes (natural images correspond to
dense codes in this work). Suggested advantages included a high memory capacity, a fast speed of learning, controlled
interference between different stored patterns, high fault tolerance (relative to local codes), and a high representa-
tional capacity (F¨oldi´ak, 2002). These suggestions drew from work on associative memories and neural networks
(Hertz et. al., 1991), rather than from information theory. In addition to the possibility of sparse coding as a neural
coding principle , recent successes in the ﬁeld of deep reinforcement learning (Mnih et al., 2015) make these sugges-
tions worth re-visiting. The reason is the success of deep learning could very well be due to sparse codes, as suggested
recently by Papyan et al. (2018). It is therefore worthwhile establishing the fundamental computational properties of
a sparse code.

The aim of this work is to investigate the computational properties of a sparse code starting with F¨oldi´ak’s suggestions,
and to determine what advantages a sparse code may have for solving optimal control tasks using neuro-dynamic
programming. The central ﬁnding is that the combination of decorrelation and over-completeness gives a sparse
code a computational advantage over other codes in optimal control tasks solved with neuro-dynamic programming.
In this respect, the present work both clariﬁes and extends F¨oldi´ak’s suggestions for the computational advantages
of a sparse code. The optimal control task considered here involves tracking a target object, given by a dragonﬂy,
over a sequence of temporally-correlated natural images. Each image in the sequence can be represented as a sparse
code and used in a linear network as a function approximator. Neuro-dynamic programming can then be applied to
solve the optimal control task. The sparse code is generated using a recently developed method for constructing a
suitable basis of 2D Gabor functions that is scale-invariant and adapted to natural image statistics (Loxley, 2017). The
advantage of this approach is that all computational problems addressed in this paper can then be solved using either
dynamic programming (Bertsekas, 2017), or convex optimization (Boyd & Vandenberghe, 2004). The primary aim of
this work is to investigate sparse code properties that generalize to any optimal control task, not just speciﬁc tracking
tasks. However, a proposed non-greedy online tracking algorithm is brieﬂy discussed in Section 4.

The structure of the paper is as follows. Section 2 introduces the dynamic programming model and describes how
the sparse codes are generated. Details of the optimal control task are given in Section 3, and results are presented
for memory capacity, speed of learning, sequential learning of multiple tasks, representational capacity, and fault
tolerance. A summary of the main ﬁndings appears in Section 4, and possible extensions are suggested.

2 Model

Consider the optimal control problem of tracking a target over a temporal sequence of N images. Rather than detecting
the location of the target in each image, the task is to follow the known location of the target as closely as possible by
applying a restricted set of discrete controls. The tracking task is therefore a combinatorial optimization problem, and
suboptimal solutions will generally be present.

Let the state xk be a pair of coordinates giving the location of a small region Rk(xk) within the kth image of the image
sequence, and let wk be the known location of the target region Rk(wk). To be precise; xk, wk ∈ Z2, and let Rk be an
a × a pixel region represented by the vector Rk ∈ Rq (where q = a2). The parameter a is chosen according to some
relevant lengthscale of the target object, such as its maximum length in pixels in the sequence of images. The tracking
dynamics is assumed to be deterministic, and is given by the discrete-time dynamical equation:

xk+1 = xk + uk,

(1)

where uk is the control applied at each stage to update the state in the next image in the sequence. The key feature of
this model is that the set of controls {uk}N

k=1 is restricted: each uk ∈ U is taken from the set

U = {(−a, 0), (a, 0), (0, a), (0, −a), (0, 0)},

(2)

corresponding to a shift of a pixels either left, right, up, down, or no shift if uk = (0, 0). Restricting controls makes
the tracking problem more interesting, but also more difﬁcult to solve, than for the case of continuous controls. In
some tracking situations it might be practically relevant to consider controls that are restricted in certain ways. The
dynamical equation (1) implies the maximum distance travelled by the target from one image to the next must be
a pixels. Targets moving faster than this will outrun the tracker unless image sequences are resampled at a higher
frequency. The total cost for the tracking problem is assumed to take the simple form:

N

|xk − wk|2,

(3)

penalizing all deviations from the target location accumulated over the N -image sequence.

Xk=1

2

A sparse code increases the speed and efﬁciency of neuro-dynamic programming for optimal
control tasks with correlated inputs

A POSTPRINT

Minimizing the total cost given by (3) will result in an optimal tracking solution. This can be done exactly using the
Dynamic Programming (DP) algorithm (Bertsekas, 2017). Assuming a terminal cost of JN +1(xN +1) = 0, the DP
algorithm involves iterating backwards from JN (xN ) to J1(x1) using the following equation:

Jk(xk) = min
uk∈U

|xk − wk|2 + Jk+1(xk + uk)

,

(4)

where Jk(xk) is the cost-to-go: giving the tail portion of the cost remaining when going from state xk and image k,
to state xN and image N , using the optimal control sequence. The minimum total cost is then given by the value of
J1(x1), and the corresponding choice for each uk gives the set of optimal controls {u∗
k=1 (Bertsekas, 2017). Using
these optimal controls in equation (1) returns the optimal tracking solution for a given temporal sequence of images. A
simple one-dimensional tracking problem is solved in the appendix following this approach, and solutions are shown
in Figures 1 and 3 for the more complicated tracking task described in Section 3.

k}N

(cid:2)

(cid:3)

2.1 Neuro-dynamic programming

There are two immediate problems with the exact DP approach outlined above. The ﬁrst is that when dealing with
images it is often the case that choosing a suitable representation can make a task easier to solve. The second is that
the table of cost-to-gos Jk(xk) may become prohibitively large, especially if the number of states increases exponen-
tially with problem size. Both issues can be addressed by replacing Jk(xk) with a parametric function approximator
˜Jk(xk, rk). The function approximator could be given by a neural network, for example. The parameters rk are
usually called weights and can be found using ﬁtted value iteration (Bertsekas, 2017; Bertsekas & Tsitsiklis, 1996) as
follows. Given some sample states x0
N , rN )
to ˜J1(xs

k, ... for each k, this algorithm involves iterating backwards from ˜JN (xs

1, r1) using the following pair of expressions:

k, x1

βs
k = min
uk∈U

|xs

k − wk|2 + ˜Jk+1(xs

h
| ˜Jk(xs

k, rk) − βs

k|2.

k + uk, rk+1)
i

,

(5)

(6)

min
rk

s
X

The equation (5) performs a DP iteration similar to equation (4) to ﬁnd the cost βs
k) is then used in (6) as a training sample to ﬁt ˜Jk(xs
This state-cost sample pair (xs
adjusting the weights rk. A simple form for ˜Jk(xk, rk) is given by a linear network:

k, βs

k corresponding to sample xs
k.
k, rk) to its target value βs
k by

˜Jk(xk, rk) = rT

k vk(xk),

(7)

where rk ∈ Rp is a vector of weights, and vk(xk) ∈ Rp is a vector of network inputs given by features extracted
from image region Rk(xk) ∈ Rq. In the case of natural images, the raw image pixels are features that are strongly
correlated. Alternative feature vectors (image representations) may make an optimal control task easier to solve. Image
representations may either be complete: p = q, over-complete: p > q, or under-complete: p < q. With this choice
of function approximator, equation (6) reduces to linear regression and the corresponding minimization of a convex
quadratic function (Bertsekas & Tsitsiklis, 1996; Boyd & Vandenberghe, 2004). One approach to solving equation
(6) that is easy to implement is the incremental gradient method (Bertsekas & Tsitsiklis, 1996). For the kth image
in the sequence, solving equations (6) and (7) with the incremental gradient method requires updating the weights rk
according to

r(t+1)
k

= r(t)

k − η

vk(xs
(cid:16)

k)T r(t)

k

k − βs
k, βs

(cid:17)

vk(xs

k).

(8)

This update is performed for each pair of state-cost samples (xs
k). By cycling through all sample pairs for the
kth image, and then repeating a number of times, convergence is guaranteed provided the learning rate η is chosen
carefully. The algorithm for incremental value iteration (Bertsekas & Tsitsiklis, 1996) combines equations (5) and (7)
with (8), and is the algorithm of choice for neuro-dynamic programming (neuro-DP) in this investigation. When the
number of states of a problem is small enough to compute the exact cost-to-go Jk(xk), this can be compared with
˜Jk(xk, rk) from neuro-DP to determine the quality of the approximation.

2.2 A sparse code for natural images

It now remains to choose a suitable image representation to approximate the cost-to-go in equation (7). This represen-
tation should help make the tracking task easier to solve in some way, and it is the purpose of the present investigation
to determine how this might be done using sparse codes.

3

A sparse code increases the speed and efﬁciency of neuro-dynamic programming for optimal
control tasks with correlated inputs

A POSTPRINT

y, λ′

Gabor Parameter(s)
σ′
x, σ′
σx
σy
λ

x, σ′

Sample Transformation
(σ′
y, λ′) = (1, 1, ρ)z
σx = PCDF −1(N CDF (σ′
σy = PCDF −1(N CDF (σ′
λ = PCDF −1(N CDF (λ′|0, 1)|α3, β3)

x|0, 1)|α1, β1)
y|0, 1)|α2, β2)

Table 1: Sampling scheme for the three spatial Gabor function parameters: sample z ∼ N (0, 1) from the standard
normal distribution, then apply the parameter transformations listed in the table. Here, ρ, αi, and βi are the model
parameters, PCDF −1(x|α, β) =
(1−x)1/α is the inverse CDF for the Pareto distribution, and N CDF (x|0, 1) denotes
the CDF for the standard normal distribution (Loxley, 2017).

β

A simple generative model described in Loxley (2017) will now be used to ﬁnd a sparse code for natural images. A
sampling scheme approximating the joint probability density of parameter values of the 2D Gabor function adapted
to natural image statistics is reproduced in Table 1. The three spatial Gabor parameters σx, σy, and λ are strongly
correlated and have heavy-tailed distributions which can be modelled using a Gaussian copula with Pareto marginal
distributions. Other Gabor parameters are sampled uniformly over their respective ranges and are not shown in Table
1.In the ﬁrst step, a sample is collected for each of the seven Gabor parameters: (φ, ϕ, σx, σy, λ, x0, y0), and a real-
valued 2D Gabor function is constructed from these samples using the following equations:

and

G(r, r′) = A exp

−

(cid:20)

˜i2
σx(r′)2 +

˜j2
σy(r′)2

1
2

(cid:18)

(cid:19)(cid:21)

(˜i, ˜j) =

(cid:18)

cos φ(r′) − sin φ(r′)
cos φ(r′)
sin φ(r′)

(cid:19) (cid:18)

cos

k(r′)˜j + ϕ(r′)

,

(cid:3)

(cid:2)
i − x0(r′)
j − y0(r′)

,

(cid:19)

(9)

(10)

with k(r′) = 2π/λ(r′). One set of seven parameter samples corresponds to a single 2D Gabor function, which is
indexed by a single value of r′ in equations (9) and (10). Repeating this step m times leads to m Gabor functions
m
(and m values of r′), which are now summed together to give the image model: ˆI(r) =
r′=1 G(r, r′)a(r′). Here,
r = (i, j) are pixel coordinates of the generated image, and r′ = (i′, j′) are discrete coordinates of the sparse code
formed by the coefﬁcients a(r′), each one corresponding to a particular 2D Gabor function. The sampling scheme in
Table 1 is length-scale invariant due to the Pareto marginal distributions. Scale invariance is a key property of natural
images (Ruderman and Bialek, 1994; Ruderman, 1997; Mumford and Gidas, 2001), and also of the underlying joint
probability density approximated using Table 1 (Loxley, 2017). The set of randomly generated Gabor functions are
therefore self-similar and multiscale in a manner comparable to a self-similar multiresolution wavelet scheme.

P

Two-dimensional Gabor functions are not orthogonal. However, given an image I(r), it is possible to ﬁnd its sparse
code a(r′) using a least-squares approximation (Daugman, 1988). Due to algorithm efﬁciency issues it is easiest to
divide each image region Rk(xk) into a number of smaller regions I ∈ Rd with d ≪ q. Letting G ∈ Rd×m be a
matrix with elements G(r, r′), and a ∈ Rm be a vector of the sparse code coefﬁcients a(r′), the sparse code is found
by solving the least-squares problem,

min
a

|Ga − I|2.

(11)

This problem is convex and can be efﬁciently solved with standard solvers. An l1 regularization term can also be
added to Equation (11) as shown in the Appendix. However, for the 2D Gabor function basis used here this did not
lead to any increase in sparse code performance.

3 Results

The model developed in the previous section is now applied to the optimal control task of tracking a dragonﬂy over a
temporal sequence of natural images taken from video. The problem formulation allows for easy detection of failure
in either the DP method or the approximation method. Failure in the DP method occurs when the optimal solution
cannot be found. As previously discussed, applying a restricted set of discrete controls during tracking leads to a
combinatorial optimization problem with suboptimal solutions. The existence of suboptimal solutions is demonstrated
in the appendix for a simpliﬁed problem, and similar ideas generalize to the present case. These suboptimal solutions
can usually be found with a greedy algorithm. Failure of the DP method can therefore be detected when the DP solution
matches the greedy solution (unless the greedy solution also happens to be optimal). Failure in the approximation

4

A sparse code increases the speed and efﬁciency of neuro-dynamic programming for optimal
control tasks with correlated inputs

A POSTPRINT

Figure 1: A solved dragonﬂy tracking task. The image sequence starts with the top-left image, and ends with the
bottom-right image. The DP tracker (blue squares) uses the restricted controls available to follow the dragonﬂy as
closely as possible over the whole image sequence. The greedy tracker (red squares) tries to get as close as possible to
the dragonﬂy in each image.

method can be detected by comparing neuro-DP with exact DP though either the costs, or the cost-to-gos. The problem
formulation also renders the use of state-space models such as the Kalman ﬁlter (often used in tracking) unnecessary.
The reason is the position of the target is already known precisely, rather than having to be inferred from a noisy
observation.

An image sequence and a solved tracking task is shown in Figure 1. Image sequences were sampled from video taken
at Karrawirra Parri (the Torrens River) in South Australia. In this case a dragonﬂy moves from the right edge of the
ﬁrst image, to the top edge of the last image (going from top-left to bottom-right). For each image, the target location
wk was found, and the image converted to double-precision grayscale to allow for numerical calculations: no further
pre-processing was done. In Figure 1, states corresponding to small image regions (shown as black squares) were
generated as follows. The initial state x1 in Image 1 (top-left image) is the target location w1. Applying equation (1)
for each of the ﬁve controls generates the states x2 shown in Image 2 (top-second-from-left). Instead of ﬁve additional
states, there are only three states that ﬁt within the image: the tracker can either move up, move left, or stay where
it is. This process is repeated for each subsequent image and state; until by Image 5, eleven unique states have been
generated. To solve the tracking problem with exact DP requires starting at the last image (Image 5) and working
backwards. First, J5(x5) is evaluated for each of the eleven states in Image 5 using equation (4) with J6(x6) = 0.
Then, J4(x4) is evaluated for each of the nine states in Image 4 using equation (4) with J5(x5). Continuing in this
manner, and iterating equation (4) backwards in time, eventually leads to the initial state in Image 1 and returns the set
of optimal controls. It is now possible to proceed forwards in time from Image 1 to Image 5 and solve the tracking task
using the optimal controls in equation (1). This (DP) solution is given by the sequence of blue squares in Figure 1 and
is guaranteed to minimize the total cost given by (3). The greedy solution is given by the sequence of red squares and
minimizes the cost of the current stage only. Following the greedy policy allows the target to get ahead of the tracker,
which is then never able to catch up using the restricted set of controls. By contrast, a tracker following the DP policy
pays a small initial cost to get ahead of the target, and is then able to keep up at later stages.

In Figure 2, the cost-to-go of the states in Image 2 (Figure 1) are shown. The decision made at this stage completely
distinguishes the DP policy from the greedy policy. From Figure 2, it is clear that State 3 has the largest cost-to-go. On
the other hand, State 3 is closest to the target and minimizes the single-stage cost |x2 −w2|2 for Image 2. Therefore, the
greedy tracker selects State 3, while the DP tracker chooses either States 1 or 2: either state can achieve the subsequent
DP state shown in Image 3, and therefore minimizes the total cost given by equation (3).

5

A sparse code increases the speed and efﬁciency of neuro-dynamic programming for optimal
control tasks with correlated inputs

A POSTPRINT

1
1
?
?
1

3
?
?
?
3

2
?
?
?
2

o
G
-
o
T
-
t
s
o
C

Figure 2: The cost-to-go of states in Image 2 of Figure 1. State 3 is closest to the target dragonﬂy but has the largest
cost-to-go.

1

2

State

3

Figure 3: Another solved dragonﬂy tracking task. The DP tracker (blue squares) and greedy tracker (red squares) both
choose the same ﬁrst control (second image), but different second controls (third image) as the greedy tracker stays
closest to the dragonﬂy in the third image.

Another image sequence and solved tracking task is shown in Figure 3. In this example, the DP and greedy trackers
both choose the same ﬁrst control in Image 2 (shown by the red square). In Image 3, the DP and greedy trackers
diverge: the greedy tracker moves to the state closest to the target (red square) to minimize the single-stage cost for
Image 3, while the DP tracker moves to a different state to minimize the total cost given by (3). The cost-to-go for
Image 3 is shown in Figure 4. From the thirteen possible states, State 4 has the smallest cost-to-go and is chosen by
DP. However, State 9 minimizes the single-stage cost |x3 − w3|2 for Image 3 and is therefore the greedy choice. From
Figure 3 it is clear the DP solution, rather than the greedy solution, tracks the dragonﬂy most closely over the whole
image sequence.

6

A sparse code increases the speed and efﬁciency of neuro-dynamic programming for optimal
control tasks with correlated inputs

A POSTPRINT

1

3

7

4

8

9

2

6

5

10

11

12

13

o
G
-
o
T
-
t
s
o
C

Figure 4: The cost-to-go of states in Image 3 of Figure 3. State 9 is closest to the target dragonﬂy, while State 4 has
the lowest cost-to-go.

1 2 3 4 5 6 7 8 9 10 11 12 13
State

Image representations are included using the neuro-DP framework with incremental value iteration. Choosing vk(xs
k)
in equation (7) to be a sparse code representation of image region Rk(xs
k), and applying equations (5), (7), and
(8), leads directly to the cost-to-gos and optimal controls shown in Figures 1–4. The function used for cost-to-go
approximation is a linear network, so performance on optimal control tasks like tracking will strongly depend on
network properties such as memory capacity, speed of learning, the ability of the network to store multiple tasks with
minimal interference between different tasks, the degree of fault tolerance within the network, as well as the capacity
of the network to represent different states. These network properties are now investigated.

3.1 Memory capacity

A memory can be considered as the learned association between each pair of state-cost samples (xs
k) in the least-
squares regression in equation (6). Given a state sample, memory retrieval then requires accurate recall of the best
approximation of the corresponding cost sample. This does not include associations due to generalization (interpolat-
ing between learned state-cost samples). Memory capacity is deﬁned here to be the maximum number of state-cost
sample associations that can be directly stored in a linear network. Once memory capacity is reached no new tasks can
be learned without losing previously learned tasks. It has been suggested that memory capacity increases going from a
less-sparse (dense) code to a sparser code (F¨oldi´ak, 2002). I will now demonstrate this for the case of a linear network
storing state-cost sample associations. It might be expected that a linear network with p weights could reliably store p
cost samples, giving memory capacity nmax = p. However, this is generally not the case, and therefore a more careful
analysis is required.

k, βs

Making use of equation (7) and dropping the k-dependence, the objective in equation (6) can be re-written as

min
rk

n

s=1
X

where V is the design matrix:

| ˜Jk(xs

k, rk) − βs

k|2 = min
r

|V r − β|2,

v1(x1)
...
v1(xn)

. . .

. . .

vp(x1)
...
vp(xn)

,






V = 




r = (r1, ..., rp) is a vector of network weights, and β = (β1, ..., βn) is a vector of cost samples. Each row of V
corresponds to one of n samples, and each column of V corresponds to one of p measurements performed on each
sample. So row “s” gives the vector v(xs) corresponding to the representation of image region R(xs) for state sample
xs. In the present case, each column corresponds to a different pixel value, or a different Gabor coefﬁcient value (there
are p columns for an image region of p pixels or a sparse code of p Gabor coefﬁcients). The columns of V span a

7

A sparse code increases the speed and efﬁciency of neuro-dynamic programming for optimal
control tasks with correlated inputs

A POSTPRINT

Figure 5: Scatter plots of v1 and v2 samples taken from natural images (a), and their sparse code representations (b). In
(a), neighboring pixels in a natural image show strongly correlated behaviour. In (b), neighboring Gabor coefﬁcients
in the sparse code show uncorrelated and symmetrical behaviour.

vector subspace (the column space of V ), and a vector in this subspace can be represented as

V r = r1 

+ · · · + rp 

v1(x1)
...
v1(xn)









vp(x1)
...
vp(xn)

.









Minimizing the objective in equation (6) with respect to r corresponds to projecting the vector β onto the closest
vector in the column space of V : ˆβ = V ˆr, called the best approximation to β. According to the deﬁnition of memory
capacity, nmax is equal to the dimension of the column space (the rank) of V . If the columns of V are orthogonal,
then V has full rank, and nmax = p. However, if any of these columns are linearly dependent it must be the case that
nmax < p. To investigate further, consider the expression for the normalized inner product of any two column vectors
of V ,

hvi, vji
|vi||vj|

=

s vi(xs)vj(xs)

s vi(xs)2
P

s vj (xs)2

,

and the expression for the sample correlation between two random variables vi and vj ,

pP

pP

corr(vi, vj) =

s(vi(xs) − ¯vi)(vj (xs) − ¯vj)

s(vi(xs) − ¯vi)2
P

s(vj(xs) − ¯vj)2

,

where ¯vi is the mean of vi. In the limit of vanishing mean and constant |vi|, it is clear that hvi, vji ∝ corr(vi, vj).
s vi(xs)vj (xs) to be
This correspondence between hvi, vji and corr(vi, vj ) allows the orthogonality expression
qualitatively investigated using sample scatter plots, and shows that the memory capacity of a linear network only
depends on the second-order statistics of a representation.

P

pP

pP

Memory capacity of a linear network for the tracking task described here depends on whether the network inputs are
raw grayscale natural images extracted from video, or sparse-code representations of those images. In Figure 5(a), a
scatterplot of neighboring pixel values given by v1(xs) and v2(xs) is shown for n samples (s = 1, .., n) taken from
grayscale natural images. Neighboring pixels are highly correlated in natural images, so all samples fall into the ﬁrst
quadrant of the (v1, v2) coordinate plane. This means the product v1(xs)v2(xs) is always positive, and therefore
s v1(xs)v2(xs) > 0. The same conclusion is also true for correlated data with zero mean, as all samples then fall
into quadrants one or three, and it is still the case that v1(xs)v2(xs) > 0. Therefore, the columns of V must be
P
non-orthogonal for grayscale natural image pixels, and nmax < p is possible (linear dependence has not been proven,
though in the examples presented here it is always the case). In Figure 5(b), a scatterplot of neighboring Gabor coefﬁ-
cient values given by v1(xs) and v2(xs) is shown for n samples taken from the sparse code of these images. It can be
seen that 2D Gabor function coefﬁcients are uncorrelated and symmetrically distributed in the (v1, v2) plane. Samples
s v1(xs)v2(xs), while samples falling into
falling into the ﬁrst or third quadrants contribute positive or zero terms to
the second or fourth quadrants contribute negative or zero terms. As the samples are distributed symmetrically, the

P

8

A sparse code increases the speed and efﬁciency of neuro-dynamic programming for optimal
control tasks with correlated inputs

A POSTPRINT

Image
Sparse Code
 n

 = p

max

s
t
h
g
e
W

i

f
o

r
e
b
m
u
N

1800

1600

1400

1200

1000

800

600

400

200

20

40

60

80

100

Number of Non-Zero Singular Values of V

Figure 6: Memory capacity of a linear network using network inputs given by natural images (triangles) or a sparse
code (circles). The value of p, corresponding to the number of weights, must increase rapidly with increase in nmax,
the number of non-zero singular values of the design matrix V . This happens more rapidly for a natural image input
than for a sparse code, with the sparse code achieving the maximum memory capacity of a linear network, nmax = p.

P

s v1(xs)v2(xs) ≈ 0. The columns of V are there-
positive and negative contributions cancel due to symmetry, and
fore orthogonal for the sparse code, or close to orthogonal, and nmax = p. In summary, correlations between each
pair of measurements vi(xs) and vj(xs) allow for nmax < p, while the sparse code decorrelates these measurements
and approaches nmax = p.
To determine how large the effect of correlated measurements is in practice, memory capacity is now investigated
quantitatively by ﬁnding the rank of V . The rank of V is given by the number of non-zero singular values of V ,
which is approximated here by the number of singular values of V ≥ 0.1. In Figure 6, curves for nmax versus p are
generated by increasing p (corresponding to the number of weights in the linear network) for each value of nmax, until
achieving nmax singular values of V ≥ 0.1. It can be seen from Figure 6 that the sparse code achieves nmax = p,
reaching the maximum memory capacity of a linear network. It can also be seen that using a natural image input leads
to nmax < p, in agreement with the qualitative analysis presented above. Further, in Figure 6, it is also seen that using
a natural image input requires up to 40 times the number of weights to store the same number of cost samples as using
the sparse code. While this number is sensitive to the size of the cutoff chosen for the non-zero singular values, the
qualitative behaviour of the ﬁgure is robust: correlated measurements have a noticeable effect on the memory capacity
of a linear network.

3.2 Speed of learning

The speed of learning for the linear network is given by the rate of convergence of the incremental gradient method
in equation (8). The converged solution yields the cost-to-go approximation in equation (7) used for selecting optimal
controls. A fast speed of learning implies a rapid rate of convergence, and requires less computational effort to arrive
at a cost-to-go approximation.

The rate of convergence of gradient methods often depends on the condition number of the Hessian matrix
(Bertsekas & Tsitsiklis, 1996; Boyd & Vandenberghe, 2004). This is given by the ratio of the largest and smallest
eigenvalues of the Hessian matrix, and provides a measure of the eccentricity of level sets of expression (6) close to an
optimal solution. Problems with a large condition number tend to have very elongated level sets, and gradient methods
will often converge more slowly than for problems with a small condition number. In the present case, the Hessian
s vi(xs)vj(xs) which, as discussed in the previous section, depends
matrix elements are proportional to the term
only on the second-order statistics of a representation. From the qualitative analysis given in the previous section, the
s vi(xs)vj (xs) ≈ 0 for i 6= j; leading to an approximately diagonal Hessian with eigenvalues
sparse code satisﬁes
s vi(xs)2, which are proportional to the variance of vi for zero mean. Gabor coefﬁcients of a sparse code
λi ≈ 2

P

P

P

9

 
 
A sparse code increases the speed and efﬁciency of neuro-dynamic programming for optimal
control tasks with correlated inputs

A POSTPRINT

r
o
r
r

E
e
g
a
r
e
v
A

104

102

100

10-2

10-4

Image
Sparse Code (Complete)
Sparse Code (Over-Complete)

0

1

2

3

4

5

Number of Iterations 

7

6
 104

Figure 7: Rate of convergence of the incremental gradient method for different image representations shown using a
log-linear plot of average error versus number of iterations. The rate of convergence is at least an order of magnitude
faster for the complete sparse code (circles) and the ×2.25 over-complete sparse code (squares), than for the natural
image input (triangles).

tend to have similar variances (as seen in Figure 5(b)), and the condition number is therefore expected to be relatively
small. When correlations are present in the network input, the variance along each principal axis of the input data may
vary greatly. In Figure 5(a), the length of the elongated ellipse corresponds to the variance along one principal axis,
and the width, to the variance along another principal axis. The diagonalized Hessian matrix will therefore have some
eigenvalues that are much larger than others when strong correlations are present. For the natural image pixels shown
in Figure 5(a), the condition number would therefore be expected to be relatively large.

In Figure 7, the rate of convergence of the incremental gradient method is given by a log-linear plot of |V ˆr − β|
averaged over 6 tracking tasks (giving the average error) versus number of iterations. Data is shown for both complete
(p = q) and over-complete (p = 2.25q) sparse codes, as well as for natural image inputs. Solid lines represent
straight-line ﬁts to data, indicating that average error decreases exponentially with the number of iterations. Assuming
“average error” ∝ e−t/δ, time constants for the rates of convergence estimated from the data in Figure 7 give δ = 4000
for natural image inputs, δ = 132 for the complete sparse code, and δ = 36 for the over-complete sparse code. Natural
image inputs therefore require approximately 30 times the number of iterations of the complete sparse code to reach
convergence. These results are in agreement with the qualitative discussion on condition numbers: poorly conditioned
problems can take orders of magnitude longer to converge. The over-complete sparse code requires fewer iterations
than the complete sparse code, however, the vector multiplication in equations (7) and (8) takes longer for an over-
complete code as the vectors are longer.

3.3 An over-complete sparse code for sequential learning

Results for memory capacity and speed of learning only depend on the second-order statistics of image representations.
On the other hand, a sparse code is distinguished from other decorrelated codes by (1) its higher-order statistics, and
(2) its ability to form over-complete representations. Over-complete sparse codes turn out to be very useful for learning
a large number of tasks sequentially, as will now be shown. An over-complete sparse code corresponds to m > d in
Equation (11), so the number of 2D Gabor functions used in a representation is larger than the number of pixels in the
underlying image. In this work, a ×2.25 over-complete sparse code is used. In the language of neural networks this
corresponds to doubling the number of inputs to a neural network or, more precisely, doubling the number of features
extracted from a ﬁxed-sized image input. These features live in a larger space than those of a complete sparse code,
and yet remain approximately decorrelated by the sparse coding, as shown in Figure 8. The memory capacity of a
linear network therefore at least doubles in size using a ×2.25 over-complete sparse code. An over-complete code

10

 
A sparse code increases the speed and efﬁciency of neuro-dynamic programming for optimal
control tasks with correlated inputs

A POSTPRINT

200

150

100

50

s
t
h
g
e
W

i

f
o

r
e
b
m
u
N

Sparse Code (Complete)
Sparse Code (Over-Complete)
 n

 = p

max

Over-Complete Code only

Complete and Over-Complete Codes

Maximum memory capacity of a linear network

50

100

150

200

Number of Non-Zero Singular Values of V

Figure 8: Memory capacity of a linear network using an over-complete sparse code. Input images are 10 × 10 pixels,
giving up to p = q = 100 weights for a complete sparse code (circles), and p = 2.25q = 225 weights for a ×2.25
over-complete sparse code (squares). The over-complete sparse code closely follows the maximum memory capacity
of a linear network (blue line) as the number of weights are increased, and complete codes become no longer possible
(above dashed line). A linear network using this over-complete sparse code can efﬁciently store over 200 cost values
for a 10 × 10 input image. Non-zero singular values of V are singular values of V ≥ 0.1, as in Figure 6.

with correlated features would require a much larger degree of over-completeness, and correspondingly many more
network weights, in order to achieve a similar increase in memory capacity.

Neuro-dynamic programming allows multiple tracking tasks to be learned sequentially when a gradient method is used
to update network weights. Optimal control of multiple tracking tasks is then possible, and new tracking tasks can
be learned as soon as the data become available. However, as each new task is learned and the network is updated,
it becomes more likely that previously trained tasks are “forgotten”. This likelihood increases as the representations
of different tasks begin to overlap and interfere (as in the case of two very similar tasks with very different costs), or
when memory capacity is exceeded. In the ﬁrst case, overlap between a new task and a previously trained task would
result in un-learning the earlier task during the process of learning the new task, even when below memory capacity.
In the neural network community this is known as “catastrophic forgetting” (Kirkpatrick et. al., 2017). One possible
solution is to re-train on the entire past sequence of tracking tasks. This can be done either by joint optimization of all
tracking tasks as a single batch, or by repeating the sequence of tracking tasks many times during sequential learning.
Both methods require access to past tracking tasks, which is often not available; and both methods must re-process
past tracking tasks each time a new task is learned, which is computationally inefﬁcient. Instead, a new approach to
sequential multitask learning is proposed that circumvents the need for past data and additional processing.

Catastrophic forgetting is now investigated for the case of multiple tracking tasks.
In Figure 9, performance on
four tracking tasks is shown using either natural image pixels as input, a decorrelated code that is not sparse, or
a sparse code. The decorrelated code that is not sparse is found using ﬁlter-based decorrelation, as described in
Olshausen and Field (1996, 1997), and Hyv¨arinen et. al. (2009). Filtering with the discrete Fourier transform means
a ﬁlter-based decorrelated code has the same dimensionality (i.e., number of pixels) as the underlying image, and
therefore cannot be made into an over-complete code. The same is true for alternative decorrelation methods such as
patch-based decorrelation using PCA (Hyv¨arinen et. al., 2009). By contrast, a sparse code is decorrelated and can be
made over-complete due to the fact it is a solution to a least-squares problem.

Each tracking task in Figure 9 was learned sequentially by iterating the neuro-DP equations until convergence, then
transferring the weight values rk to the next task in the sequence, and repeating. Tracking tasks were learned in
ascending order of task number; i.e., task 1 ﬁrst, etc. The performance measure is given by “cost ratio”, which is the

11

 
 
A sparse code increases the speed and efﬁciency of neuro-dynamic programming for optimal
control tasks with correlated inputs

A POSTPRINT

2.5

2

1.5

1

0.5

0

o
i
t
a
R

t
s
o
C

Image
Decorrelated Code
Sparse Code (Complete)
Optimal

1

2

3

4

Tracking Task

Figure 9: Sequential learning of multiple tracking tasks leading to catastrophic forgetting. Tracking tasks were learned
in ascending order of task number, and cost ratio is the ratio of neuro-DP cost to greedy cost. Tracking performance
is optimal for tracking task 4 (the most recently learned task), with performance declining for earlier tasks. Data
represent an average of 200 random combinations of 4 tracking tasks taken from a total of 8.

total cost of the neuro-DP solution divided by the total cost of the greedy solution. When “cost ratio” is less than
one this means neuro-DP has found a lower cost solution than the greedy solution: otherwise, the solution is either of
equal cost, or higher cost. The optimal solution found by applying exact DP to each tracking task without sequential
learning is also shown for comparison. It is seen that tracking performance is only optimal for tracking task four:
the most recently learned task, with performance declining rapidly for earlier tasks due to catastrophic forgetting.
Tracking performance is seen to decline most rapidly for network inputs given by natural images, where it is worse
than greedy for all tracking tasks other than tracking task four. Tracking performance for the decorrelated code, and
the complete sparse code, is substantially better. The reason is that natural images, sparse codes, and decorrelated
codes are all distributed representations, so different tracking tasks are likely to overlap to some extent. Overlap of
different tasks in a representation can sometimes lead to desirable generalization if the state-cost pairs have similar
values for the different tasks, or more often, to unwanted interference if they do not. On average, the sparse code and
the decorrelated code have less overlap between different tasks than do natural images (see next section for details).
This reduces the chance of unwanted interference during sequential learning, and leads to slightly better tracking
performance, as seen in Figure 9. Filter-based decorrelation will not be considered any further in this work.

k) then becomes vk(xs

k, i): where i is the partition index, and vk(xs

To avoid catastrophic forgetting the approach taken here is to divide each representation into equal non-overlapping
regions called partitions, and then solve each tracking task on a unique partition. These partitioned representations
exclude the possibility of interference between different tracking tasks, allowing for generalization within tasks but
not between different tasks. Tasks that do generalize well without detrimental interference can be placed on the same
partition. The vector vk(xs
k, i) is a vector of all
zeros except for a small region of sparse code or natural image forming the partition. This approach works by limiting
the updates of rk in equation (8) to the region of non-zero support in vk(xs
k, i). A simple memory capacity argument
can now be used to establish the maximum number of useful partitions for each type of representation. Using an
estimate of 30 states per stage of a tracking task from the last panel of Figure 3 (every state is used as a training sample
in this case) leads to n = 30, giving p = 1200 from Figure 6 when the network input is a natural image. For an image
region of size 110 × 110 pixels, q = 12100, and memory capacity for a natural image partition would be achieved
after q/1200 = 10.1 partitions. This means up to ten tracking tasks could be learned sequentially and stored in the
network at any one time, returning optimal tracking performance for any of these tasks at a later point in time. For a
complete sparse code, n = p gives p = 30, and memory capacity would be reached after q/30 = 403 partitions. For a
×2.25 over-complete sparse code, memory capacity would be reached after 403 × 2.25 = 907 partitions. This simple
argument shows the large improvements possible from decorrelation and over-completeness.

In practice, the maximum number of partitions is difﬁcult to achieve in numerical experiments with equation (8)
because sensible values for the learning rate become difﬁcult to determine when approaching memory capacity. This
is the case in Figures 10 and 11; where the results are easy to achieve, but fall short of reaching the maximum number

12

 
A sparse code increases the speed and efﬁciency of neuro-dynamic programming for optimal
control tasks with correlated inputs

A POSTPRINT

Figure 10: Sequential learning of multiple tracking tasks using partitioned representations. In (a), 4 partitions lead
to optimal tracking performance on 4 tracking tasks for all representations. In (b), 32 partitions (of which only 4
are used) lead to suboptimal tracking performance for natural image inputs. In (c), 256 partitions lead to suboptimal
tracking performance for the complete sparse code. In (d), 512 partitions lead to suboptimal tracking performance for
the over-complete sparse code.

of partitions. Nevertheless, the general principle can easily be demonstrated. Figure 10 is a repeat of the calculation
done in Figure 9 using a varying number of partitions. In Figure 10(a), four partitions give optimal performance for
all representations on four tracking tasks. In Figure 10(b), each representation is divided into 32 partitions and four
of these are used to solve four tracking tasks. It is seen that tracking is no longer optimal for natural image partitions.
In Figure 10(c), each representation is divided into 256 partitions and tracking becomes suboptimal for the complete
sparse code partitions. Finally, in Figure 10(d), each representation is divided into 512 partitions and tracking becomes
suboptimal for the over-complete sparse code partitions as well.

The results in Figure 10 are summarized in Figure 11. Cost ratio is averaged over the four tracking tasks in Figure 10
to give “average cost ratio” in Figure 11. The horizontal axis in Figure 11 is log base 2 of the number of partitions;
starting at 23 = 8, then doubling in number until reaching 29 = 512. The blue curve shows that natural images are
optimal at 23 = 8 partitions, and are suboptimal by 24 = 16 partitions. The red and green curves show that the
complete sparse code is still optimal at 27 = 128 partitions, and the over-complete sparse code, at 28 = 256 partitions.
These results fall short of the maximum number of partitions for the reason previously discussed. However, memory
capacity could be further increased in the case of the over-complete sparse code simply by increasing its degree of
over-completeness.

Dividing the sparse code into partitions has clear advantages for avoiding catastrophic forgetting in sequential multitask
learning. The over-complete sparse code offers an additional advantage of being able to further increase memory
capacity through over-completeness. In this work, a ×2.25 over-complete sparse code was used. However, the degree
of over-completeness can be increased well beyond this range (Rehn and Sommer, 2007; Olshausen, 2013), potentially
allowing many more tasks to be learned sequentially. Further, each partition can be accessed with a key that depends
on some unique aspect of a tracking task. For example, a key could be implemented as a hash function f of the initial
location of the target (i.e., k = 1, s = Target): giving i = f (xTarget
), or of the image region associated with the initial
location of the target: giving i = f (v(xTarget
)). It is also important to remember that each partition yields a function
approximator for the cost-to-go. Compared with using a table of cost-to-go values as in exact DP, this approach has
the advantage of scaling up to arbitrarily large problems where the number of states can be much larger than either the

1

1

13

A sparse code increases the speed and efﬁciency of neuro-dynamic programming for optimal
control tasks with correlated inputs

A POSTPRINT

o
i
t
a
R

t
s
o
C
e
g
a
r
e
v
A

1.4

1.2

1

0.8

0.6

3

Image
Sparse Code (Complete)
Sparse Code (Over-Complete)
Optimal

4

5

6

7

8

9

log

2

(Number of Partitions)

Figure 11: Effect of increasing the number of partitions from 8 to 512 on the average performance of partitioned
representations for multiple tracking tasks. Natural image partitions (triangles) remain optimal at 23 = 8 partitions,
but are suboptimal by 24 = 16. Complete sparse code partitions (circles) remain optimal at 27 = 128 partitions, and
×2.25 over-complete sparse code partitions (squares) remain optimal at 28 = 256 partitions.

number of network weights in any partition, or the number of training samples available. In other words, within each
partition, the function approximator can generalize over states at the expense of possibly becoming suboptimal, while
a method based on tables cannot.

3.4 Sparse code representational capacity, redundancy, and fault tolerance

A distributed representation makes combinatorial use of its primitive elements to represent the different states of a
system. An example is the binary representation of integers, where each primitive element is a single binary digit with
2 possible levels given by 0 or 1, and N binary digits combine together to represent 2N possible integers. When all
integers occur with equal probability, the average information content of each binary digit is 1 bit (as given by the
x∈ImX p(x) log2 1/p(x)), and the number of “typical” states (MacKay, 2003) of N independent
entropy: H(X) =
binary digits becomes 2N H = 2N . In this case the number of “typical” states equals the total number of states and no
compression is possible.

P

In the present case, grayscale natural images and complete sparse codes are both distributed representations. Firstly,
consider an 8-bit grayscale image with i.i.d. pixel values chosen uniformly at random. Each pixel has an entropy
of 8 bits, and the number of “typical” random images with N pixels is 2N H = 256N . Now consider a grayscale
natural image with a histogram of pixel values as shown in Figure 12(a). As all pixel values are not used with uniform
frequency, each pixel has a slightly lower entropy of 6.5 bits. Applying the formula 2N H to ﬁnd the number of
“typical” grayscale natural images with N pixels gives 2N H ≈ 91N for sufﬁciently large N . However, as seen in
Figure 5(a), these pixel values are not i.i.d. because they are strongly correlated, so this formula is not valid and the
real number must be less than this value.

Applying a QP solver to solve equation (11) leads to a set of double-precision ﬂoating-point numbers for the Gabor
coefﬁcients a(r′). To compare entropies with grayscale images, these coefﬁcients are quantized to 8-bit integers by
applying the method of uniform scalar quantization (Gallager , 2008). The histogram in Figure 12(b) was constructed
by binning all coefﬁcient values over the range -128.5 to 127.5 into 256 bins, leading to an entropy of 2.5 bits per
quantized Gabor coefﬁcient. This construction slightly overestimates the entropy as coefﬁcient values in this example
run from -137.2 to 140.8: sparse distributions are heavy tailed and strongly peaked about zero. Entropy estimates for
decorrelated codes that are not sparse codes turn out to be quite similar to those for sparse codes: see, for example,
PCA versus ICA in Eichhorn et. al. (2009). Although quantization of real-valued Gabor coefﬁcients results in some
distortion of reconstructed images, as does the least squares approximation in (11), it also leads to an estimate of
representational capacity. Since Gabor coefﬁcients are closer to being i.i.d. as seen by the reduced dependency exhib-

14

 
 
A sparse code increases the speed and efﬁciency of neuro-dynamic programming for optimal
control tasks with correlated inputs

A POSTPRINT

(a)

0.03

0.025

0.02

0.015

0.01

0.005

y
t
i
l
i

b
a
b
o
r
P

0

0

50

100

150

200

250

0.5

0.4

0.3

0.2

0.1

0

(b)

-100

-50

0

50

100

Pixel Value

Quantized Coefficient Value

Figure 12: In (a), a histogram of pixel values taken from a grayscale natural image. In (b), a histogram of quantized
Gabor coefﬁcient values taken from the (complete) sparse code of the image used in (a).

ited in Figure 5(b), the number of “typical” sparse codes of N quantized Gabor coefﬁcients can be approximated by
2N H = 22.5N ≈ 6N for sufﬁciently large N . This is a better estimate of the number of “typical” grayscale natural
images, however, some statistical dependency will still be present (see Hyv¨arinen et. al. (2009)). An image model that
removes all statistical dependencies in its coefﬁcients and can reconstruct images with zero distortion would give a
precise value. Unfortunately, no such model is currently known.

It is now helpful to distinguish between statistical redundancy, due to the presence of statistical dependency in a
representation, and redundancy in a representation’s capacity to represent different states. The key point is that the
number of different images that can be represented using either grayscale natural images or a complete sparse code
grows exponentially with N , so both representations are highly redundant: more images can be represented than would
ever be experienced (i.e., for a 10 × 10 image, N = 100, and 6N = 1077). This shows that a sparse code has low
statistical redundancy, but high redundancy in its representational capacity.

Another form of redundancy in a sparse code is seen in Figure 12(b): the value of a Gabor coefﬁcient is more likely to
be zero than any other value. Statistical dependency has been reduced but redundancy is now present in the coefﬁcient
frequencies. This form of redundancy can be removed using the technique of arithmetic coding (MacKay, 2003),
allowing Gabor coefﬁcient values to be written to a binary ﬁle whose size is within N H + 2 bits. However, this form
of redundancy turns out to be useful for encoding multiple tasks using a linear network, since the chance of overlap
between different tasks is reduced. In Figure 12(b), 20% of the Gabor coefﬁcients have values in the range (−0.1, 0.1)
before quantization. In Figure 12(a), only 0.05% of the grayscale image pixels have values in the range (0, 0.1) after
converting to double precision ﬂoating-point numbers between 0 and 1 for use in neuro-DP. The larger relative number
of Gabor coefﬁcients close to zero decreases the chance that two or more “sparse” representations will overlap in a
sparse code, compared with using grayscale natural images. This results in less unwanted interference when learning
multiple tasks sequentially. It can also be interpreted from Figure 9 that there is less interference between tasks in
the sparse code and the decorrelated code than there is in grayscale natural images. At the other extreme, local codes
(codes that use N elements to represent N states) have no overlap and do not suffer from unwanted interference.
However, the representational capacity of a local code is too limited for most purposes.

Distributed representations are tolerant to faults and can continue to function even when a network is badly damaged.
In the present case, randomly corrupting some of the weights of the linear network will reduce its tracking perfor-
mance but not completely destroy its tracking ability. The fault tolerance of a linear network is directly related to the
redundancy in its weights. From the previous discussion of memory capacity, a grayscale natural image (which is an
example of a dense code, since it is not sparse) requires many times more network weights than a complete sparse code
to store the same number of target values in a linear network. This redundancy means a network trained on natural
image inputs will have a higher fault tolerance than one trained on sparse codes: changing one of the weights of the
network is less likely to have an effect on the output of the network.

4 Conclusion

In this investigation, an optimal control approach to coding was taken, connecting representations of sensory data
to the computational problem-solving tasks at hand. The central ﬁnding was that the combination of decorrelation

15

A sparse code increases the speed and efﬁciency of neuro-dynamic programming for optimal
control tasks with correlated inputs

A POSTPRINT

and over-completeness gives a sparse code a computational advantage over other codes for optimal control tasks with
correlated feature inputs. The main conclusions of this work are the following.

A complete sparse code was shown to maximise the memory capacity of a linear network by transforming the design
matrix of the least-squares problem to be one of full rank. Neighboring pixels in natural images represent strongly
correlated measurements of natural scenes, leading to a design matrix that is below full rank and therefore unable to
store the maximum number of target values. A sparse code was shown to decorrelate these measurements and form an
orthogonal basis for the design matrix.

A sparse code was also shown to increase the speed of learning the network weights by conditioning the Hessian
matrix of the associated least-squares problem. Large covariances in natural images lead to a poorly conditioned
Hessian matrix describing highly elongated level sets, and decreasing the rate of convergence to the optimal solution
for the network weights. A sparse code increases this rate of convergence by virtue of a well-conditioned Hessian
matrix.

The central result of this work was that an over-complete sparse code was found to increase the memory capacity of a
linear network beyond that possible for a complete code with the same-sized input, while still providing a basis for the
design matrix that is close to orthogonal (i.e., the resulting matrix is close to full rank). This was demonstrated for a
×2.25 over-complete sparse code, where the memory capacity at least doubles compared with a complete sparse code
using the same input. It was also shown how to use an over-complete sparse code to sequentially learn a potentially
large number of optimal control tasks while avoiding catastrophic forgetting.

An investigation of the representational capacity and redundancy of a sparse code showed it to be a highly redundant
representation capable of representing more images than would ever be experienced, while also being biased towards
values close to zero, thereby decreasing the chance that representations of two or more optimal control tasks will
overlap and interfere during sequential learning.

4.1 Future work

In practical applications, sparse codes could be used for solving Markov decision processes or optimal control tasks
with an inﬁnite horizon and a large number of states. A key question then becomes how over-complete can a sparse
code be made while still providing a useful representation as a function approximator? It is clear that highly over-
complete sparse codes are possible (Rehn and Sommer, 2007; Olshausen, 2013). It can be seen in Figure 8 that going
from a complete sparse code, to a ×2.25 over-complete sparse code leads to a slight loss of memory capacity. This
might be rectiﬁed using a highly over-complete sparse code. Increasing the sparsity of a code may also help further
reduce interference between tasks during sequential learning.

It is clear the neuro-dynamic programming model proposed here is not useful as an online tracking algorithm in its
current form. Nonetheless, a straightforward extension allows it to be used for online re-planning. Firstly, it should be
noted that a large class of popular online object tracking algorithms would not be capable of ﬁnding optimal solutions to
the type of tracking tasks considered here. For example, kernal-based object tracking employs a mean-shift procedure
to locate the local maxima of a function measuring similarity between target and candidate probability distribution
functions (Comaniciu et al., 2003). However, this is a greedy approach, and in the case of restricted controls will
generally lead to suboptimal solutions. To ﬁnd optimal solutions the neuro-dynamic programming model requires
each tracking task to be processed off-line. These pre-trained tasks can then be modiﬁed online using the rollout
algorithm (Bertsekas, 2017) by making use of the learned function approximator from neuro-dynamic programming
to generate a base policy, which is then improved online in a one-step lookahead by rollout. The improved policy is
a sequence of controls that have been updated for the current task. This does require a model for the updated parts
of the target trajectory in order to simulate roll out of the base policy. Provided a pre-trained task contributes enough
information about the non-greedy stages of the online task (for example, stages where the restricted set of controls may
lead to a bottleneck when following a target trajectory), this extension should be better suited to ﬁnding an optimal
tracking solution online when suboptimal solutions are also present.

Partitioning representations to avoid catastrophic forgetting might be useful for competitive reinforcement learning
(McKenzie et al., 2017). Distributed representations are strongly susceptible to overlap between different tasks, and
if these tasks do not generalize well this will lead to unwanted interference during sequential learning. Using over-
complete sparse codes, and specializing different regions of a network to different tasks, should help eliminate catas-
trophic forgetting while making most efﬁcient use of the resources available. Similar tasks that generalize well can
share network regions, while tasks that compete strongly during learning would make use of seperate network regions.

16

A sparse code increases the speed and efﬁciency of neuro-dynamic programming for optimal
control tasks with correlated inputs

A POSTPRINT

Acknowledgements

I thank John Daugman and Bruno Olshausen for useful discussions related to this work. I thank Steven Wiederman
for supplying the video used in this study. Part of this work was completed on sabbatical at the Redwood Center for
Theoretical Neuroscience, University of California, Berkeley.

Appendix

A1: A one-dimensional target tracking problem

Consider a one-dimensional target tracking problem with restricted controls over a ﬁnite horizon. At time k, the state
xk, and the target location wk, only take values given by the non-negative integers 0, 1, 2, ..., and the controls are
restricted to be either uk = 0 or uk = 1. The DP algorithm corresponding to equation (4) is given by JN (xN ) = 0,
and

Jk(xk) = min

E [|xk − wk| + Jk+1(xk + uk)] ,

uk∈{0,1}

= min [Jk+1(xk), Jk+1(xk + 1)] + E [|xk − wk|] .

(12)

In the deterministic version of this problem, a simple way to include suboptimal greedy solutions is to consider the
horizon to be at N = 4 and set the target location to the following values:

w0 = 0, w1 = 0,

w2 = 2,

w3 = 3.

The total cost to be minimized is then given by

3

|xk − wk| = |x0| + |x1| + |x2 − 2| + |x3 − 3|.

Applying backward iteration to the DP algorithm (12) leads to the following equations:

Xk=0

J4(x4) = 0,
J3(x3) = |x3 − w3| = |x3 − 3|,
J2(x2) = min [J3(x2), J3(x2 + 1)] + |x2 − 2|,
J1(x1) = min [J2(x1), J2(x1 + 1)] + |x1|,
J0(x0) = min [J1(x0), J1(x0 + 1)] + |x0|.

We can now ﬁll out the ﬁrst row of the table of cost values:

J3(0) = 3, J3(1) = 2,

J3(2) = 1,

J3(3) = 0.

These cost values decrease with increase in state, so that in the second row of the table: min [J3(x2), J3(x2 + 1)] =
J3(x2 + 1), and u∗

2 = 1. The second row of the table now becomes
J2(0) = 4, J2(1) = 2,

J2(2) = 0,

with u∗

2 = 1.

Following this general pattern for the other rows gives,

0 = 1.
The total cost of the DP solution is therefore J0(0) = 1, and the optimal controls u∗ = (1, 1, 1) lead to the optimal
tracking trajectory x∗ = (0, 1, 2, 3).

J1(0) = 2, J1(1) = 1,
J0(0) = 1, with u∗

with u∗

1 = 1,

Let’s compare this result with the greedy policy. A greedy policy would return the control leading to the lowest cost at
the next time period without regard for future times. This policy corresponds to minimizing only the expectation term
in equation (12). A greedy tracker would therefore select the controls u = (0, 1, 1) leading to the tracking trajectory
x = (0, 0, 1, 2), and a total cost of 2. The greedy solution is therefore suboptimal, while the DP solution is optimal.
The nature of the optimal solution is that it requires the optimal controls u∗ = (1, 1, 1) to prevent the tracker being
outrun by the target. The greedy tracker, by contrast, takes the controls u = (0, 1, 1), allowing the target to get ahead
of the tracker, which is never able to catch up. This optimality is a function of the horizon. Putting the horizon at
N = 3, the greedy and DP solutions are both optimal. For N > 3, the greedy solution has a cost of N − 3 greater
than the DP solution if the target continues moving towards the horizon.

17

A sparse code increases the speed and efﬁciency of neuro-dynamic programming for optimal
control tasks with correlated inputs

A POSTPRINT

In the stochastic version of this problem, suboptimal greedy solutions can be included by putting the horizon at N = 3,
and allowing the target location to take random values from a non-stationary probability distribution given by
p(w0 = 1) = 0,

p(w0 = 0) = 1,
p(w1 = 0) = p1, p(w1 = 1) = 1 − p1,
p(w2 = 1) = 1 − p2,
p(w2 = 0) = 0,

p(w0 = 2) = 0,
p(w1 = 2) = 0,
p(w2 = 2) = p2.

Importantly, we assume pk > 1 − pk at each time k, so that pk > 1/2. The total cost to be minimized is now

2

E

"

Xk=0

|xk − wk|

#

= |x0| + p1|x1| + (1 − p1)|x1 − 1|

+ (1 − p2)|x2 − 1| + p2|x2 − 2|.

Applying backward iteration to the DP algorithm (12) leads to the following equations:

J3(x3) = 0,
J2(x2) = E [|x2 − w2|] = (1 − p2)|x2 − 1| + p2|x2 − 2|,
J1(x1) = min [J2(x1), J2(x1 + 1)] + (1 − p1)|x1 − 1| + p1|x1|,
J0(x0) = min [J1(x0), J1(x0 + 1)] + |x0|.

We can now ﬁll out the ﬁrst row of the table of cost values:

J2(0) = 1 + p2, J2(1) = p2,

J2(2) = 1 − p2.

Following our assumption p2 > 1 − p2, we see the cost values decrease with increase in state, so that in the second
row of the table: min [J2(x1), J2(x1 + 1)] = J2(x1 + 1) and u∗

1 = 1. The second row of the table now becomes

The ﬁnal row of the table depends on the relative values of p1 and p2. For p2 > p1,

J1(0) = 1 − (p1 − p2), J1(1) = 1 − (p2 − p1),

with u∗

1 = 1.

While for p2 < p1,

J0(0) = 1 − (p2 − p1), with u∗

0 = 1.

J0(0) = 1 − (p1 − p2), with u∗

0 = 0.

To gain more insight into this solution let’s compare it with the greedy policy. A greedy tracker would take controls
u0 = 0 (we assumed p1 > 1 − p1), and u1 = 1 (u1 = 2 is not a control), corresponding to the trajectory x = (0, 0, 1).
The corresponding cost is: 1 − (p1 − p2). Therefore, the cost of the greedy solution matches the cost of the DP solution
J0(0) = 1 − (p1 − p2) when p2 < p1. However, when p2 > p1, the cost of the DP solution is J0(0) = 1 − (p2 − p1).
This is 2(p2 −p1) less than the cost of the greedy solution: making the greedy solution suboptimal, and the DP solution
optimal.

A2: Sparse coding as a quadratic program

Adding an ℓ1 regularization term to the least-squares approximation in equation (11) gives
min
a

kGa − Ik2

2 + λkak1.

(13)

This is an unconstrained optimization with a non-differentiable objective. However, as discussed in Tibshirani (1996),
it can be transformed to a constrained optimization with a differentiable objective and solved as a quadratic program
(QP). This is done by expressing the variable a as the difference of two nonnegative variables a+ and a−, such that:
a = a+ − a−, kak1 = a+ + a−, and a+, a− ≥ 0 (for a ∈ R it is easy to conﬁrm the unique solution to these equations
gives: |a| = a for a ≥ 0, and |a| = −a for a < 0, as expected). Eq.(13) then becomes

kG(a+ − a−) − Ik2

minimize
subject to a+ ≥ 0, a− ≥ 0,

2 + λ(a+ + a−),

(14)

which can be written in the form of a QP:

where y = (a+, a−), l = (0, 0), q = (λ − 2GT I, λ + 2GT I), and

minimize

subject to

yT P y + qT y

1
2
y ≥ l,

However, the number of variables to solve for has now doubled from a, to a+ and a−.

P =

(cid:20)

2GT G −2GT G
2GT G

−2GT G

.

(cid:21)

18

A sparse code increases the speed and efﬁciency of neuro-dynamic programming for optimal
control tasks with correlated inputs

A POSTPRINT

References

Barlow, H. B. (1961). Possible principles underlying the transformation of sensory messages. Sensory Communication,

217–234.

Bertsekas, D. P. (2017). Dynamic programming and optimal control vol 1, 4th ed. Athena Scientiﬁc.

Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-dynamic programming. Athena Scientiﬁc.

Boyd, S., & Vandenberghe, L. (2004). Convex Optimization. Cambridge University Press.

Comaniciu, D., Ramesh, V., & Meer, P. (2003). Kernel-based object tracking. IEEE Trans. Pattern. Anal. and Mach.

Intell., 25, 564–577.

Daugman, J. G. (1985). Uncertainty relation for resolution in space, spatial frequency, and orientation optimized by

two-dimensional visual cortical ﬁlters. J. Opt. Soc. Am. A, 2, 1160 – 1169.

Daugman, J. G. (1988). Complete discrete 2-D Gabor transforms by neural networks for image analysis and compres-

sion. IEEE Trans. Acoustics, Speech, Sig. Proc., 36, 1169 – 1179.

Daugman, J. G. (1989). Entropy reduction and decorrelation in visual coding by oriented neural receptive ﬁelds. IEEE

Trans. Biomed. Eng., 36, 107 – 114.

Eichhorn, J., Sinz, F., Bethge, M. (2009). Natural Image Coding in V1: How Much Use Is Orientation Selectivity?

PLOS Comp. Biol., 5, e1000336.

Field, D. J. (1994). What is the goal of sensory coding? Neural Comp., 6, 559 – 601.

F¨oldi´ak, P. (2002). Sparse coding in the primate cortex. The Handbook of Brain Theory and Neural Networks . 2nd

edn. M A Arbib (ed.), MIT Press, 1064–1068.

Gallager, R. G. (2008). Principles of digital communication. Cambridge University Press.

Hertz, J., Krogh, A., Palmer, R. G. (1991).

Introduction to the theory of neural computation. Addison-Wesley

Publishing Company.

Hyv¨arinen, A., Hurri, J., & Hoyer, P. O. (2009). Natural Image Statistics, Springer-Verlag, London.

Jones, J. P. & Palmer, L. A. (1987). An evaluation of the two-dimensional Gabor ﬁlter model of simple receptive ﬁelds

in cat striate cortex. J. Neurophys., 58, 1233 – 1258.

Kirkpatrick, J., et. al. (2017). Overcoming catastrophic forgetting in neural networks. PNAS, 114, 3521 – 3526.

Loxley, P. N. (2017). The two-dimensional gabor function adapted to natural image statistics: a model of simple-cell

receptive ﬁelds and sparse structure in images. Neural Comp., 29, 2769–2799.

MacKay, D. J. C. (2003). Information theory, inference, and learning algorithms. Cambridge University Press.

McKenzie, M., Loxley, P., Billingsley, W., & Wong, S. (2017). Competitive reinforcement learning in Atari games.
Peng W., Alahakoon D., Li X. (eds) AI 2017: Advances in Artiﬁcial Intelligence. AI 2017. Lecture Notes in Computer
Science, 10400, Springer.

Mnih, V., et al. (2015). Human-level control through deep reinforcement learning. Nature, 518, 529–533.

Mumford, D., & Gidas, B. (2001). Stochastic models for generic images. Quarterly Appl. Math., 59, 85–111.

Olshausen, B. A. (2013). Highly overcomplete sparse coding. Proc. SPIE 8651, Human Vision and Electronic Imaging

XVIII, doi:10.1117/12.2013504.

Olshausen, B. A., & Field, D. J. (1996). Emergence of simple-cell receptive ﬁeld properties by learning a sparse code

for natural images. Nature, 381, 607 – 609.

Olshausen, B. A., & Field, D. J. (1997). Sparse coding with an overcomplete basis set: a strategy employed by V1?

Vision Res., 37, 3311–3325.

Papyan, V., Romano, Y., Sulam, J., & Elad, M. (2018). Theoretical foundations of deep learning via sparse represen-
tations: a multilayer sparse model and its connection to convolutional neural networks. IEEE Signal Proc Mag., 35,
72–89.

Perrinet, L. U., (2010). Role of homeostasis in learning sparse representations. Neural Comp., 22, 1812–1836.

Perrinet, L. U., (2019). An Adaptive Homeostatic Algorithm for the Unsupervised Learning of Visual Features. Vision,

3, 47.

Petrov, Y., & Li, Z. (2003). Local correlations, information redundancy, and sufﬁcient pixel depth in natural images.

J. Opt. Soc. Am. A, 20, 56 – 66.

19

A sparse code increases the speed and efﬁciency of neuro-dynamic programming for optimal
control tasks with correlated inputs

A POSTPRINT

Rehn, M., & Sommer, T. (2007). A network that uses few active neurones to code visual input predicts the diverse

shapes of cortical receptive ﬁelds. J. Comput. Neurosci., 22, 135 – 146.

Ruderman, D. L., & Bialek, W. (1994). Statistics of natural images: scaling in the woods. Phys. Rev. Lett., 73,

814–817.

Ruderman, D. L. (1997). Origins of Scaling in Natural Images. Vision Res., 37, 3385–3398.
Tibshirani, R. (1996). Regression shrinkage and selection via the lasso. J. R. Statist. Soc. B, 58, 267–288.
Vinje, W. E., & Gallant, J. L. (2000). Sparse coding and decorrelation in primary visual cortex during natural vision.

Science, 287, 1273–1276.

20

