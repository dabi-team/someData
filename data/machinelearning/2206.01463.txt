2
2
0
2

n
u
J

3

]

Y
S
.
s
s
e
e
[

1
v
3
6
4
1
0
.
6
0
2
2
:
v
i
X
r
a

Safety Certiﬁcation for Stochastic Systems via Neural
Barrier Functions

Frederik Baymler Mathiesen
Delft Center for Systems & Control
Delft University of Technology
f.b.mathiesen@tudelft.nl

Simeon Calvert
Department for Transport & Planning
Delft University of Technology
s.c.calvert@tudelft.nl

Luca Laurenti
Delft Center for Systems & Control
Delft University of Technology
l.laurenti@tudelft.nl

Abstract

Providing non-trivial certiﬁcates of safety for non-linear stochastic systems is an
important open problem that limits the wider adoption of autonomous systems
in safety-critical applications. One promising solution to address this problem is
barrier functions. The composition of a barrier function with a stochastic system
forms a supermartingale, thus enabling the computation of the probability that the
system stays in a safe set over a ﬁnite time horizon via martingale inequalities.
However, existing approaches to ﬁnd barrier functions for stochastic systems
generally rely on convex optimization programs that restrict the search of a barrier
to a small class of functions such as low degree SoS polynomials and can be
computationally expensive. In this paper, we parameterize a barrier function as a
neural network and show that techniques for robust training of neural networks
can be successfully employed to ﬁnd neural barrier functions. Speciﬁcally, we
leverage bound propagation techniques to certify that a neural network satisﬁes the
conditions to be a barrier function via linear programming and then employ the
resulting bounds at training time to enforce the satisfaction of these conditions. We
also present a branch-and-bound scheme that makes the certiﬁcation framework
scalable. We show that our approach outperforms existing methods in several case
studies and often returns certiﬁcates of safety that are orders of magnitude larger.

1

Introduction

Modern autonomous systems are inherently non-linear, incorporate feedback controllers often trained
with machine learning techniques, and are subject to uncertainty due to unmodelled dynamics or
exogenous disturbances [1]. Despite these complexities, autonomous systems are often employed
in safety-critical applications, such as autonomous cars [2] or air trafﬁc control [3], where a failure
of the system can have catastrophic consequences [3], [4]. For these applications, computation
of probabilistic safety, deﬁned as the probability that the system cannot evolve over time to an
unsafe region of the state space, is of paramount importance. Despite the recent efforts [5], [6],
computing certiﬁcates that guarantee that probabilistic safety is above a certain threshold still remains
a particularly challenging problem, mainly due to the complexity of these system.

A promising approach for safety veriﬁcation is the employment of barrier functions [7]. Similar to
the Lyapunov function approach for proving stability [8], barrier functions aims to prove temporal
properties of a system without the need to explicitly analyze the ﬂow of the system [7]. In the

Preprint. Under review.

 
 
 
 
 
 
(a)

(b)

(c)

(d)

(e)

(f)

Figure 1: Polynomial system with additive Gaussian noise adapted from [14] and corresponding
Neural Barrier Function analyzed using bound propagation. (a) Plot of the nominal system, i.e. of
the vector ﬁeld without noise, and of initial set and unsafe region. (b) Neural Barrier Function (NBF)
as synthesized by our framework relative to initial and unsafe sets. The composition of the NBF with
the system forms a c−martingale. (c) Linear relaxation of the Neural Barrier Function for a single
hyperrectangular region using CROWN [16]. (d, e) Bounds of our Neural Barrier Function computed
partitioning the state space in a 320 × 320 grid and using linear bound propagation in each partition.
(f) The gap between the upper and lower bounds. We will use this gap to drive our partitioning.

stochastic setting, a barrier function is a function that when composed with the system forms a
non-negative supermartingale or a c-martingale [9]. Then, martingale inequalities can be employed
to compute (a lower bound on) the probability that the system remains safe over time [10]. The main
challenge with this approach is to ﬁnd a barrier function for a speciﬁc system maximizing the certiﬁed
lower bound of safety. Existing approaches generally formulate the search of a barrier function
for a stochastic system as a convex optimization problem by restricting the search of a barrier over
a limited class of functions, generally exponential [11] or relatively low-degree SOS polynomials
[12], which often leads to overly conservative safety estimates. In this context, neural networks hold
great potential due to their universal approximation power and their training ﬂexibility. However,
while neural network barrier functions, or simply Neural Barrier Function (NBF), have already been
considered for deterministic systems [13]–[15], still no work has explored the potential of neural
networks to provide safety certiﬁcates for stochastic systems.

In this paper, we consider non-linear stochastic systems with additive noise and propose an algorithmic
framework to train NBFs for these systems. In order to do so, by relying on recent techniques for
linear relaxation of neural networks [16] and the linearity of the expectation operator, we show that
the problem of certifying that a neural network is a barrier function, and computing the resulting
safety probability, can be relaxed to the solution of a set of linear programs. Speciﬁcally, we partition
the state space and leverage linear bound propagation techniques [16], [17] to ﬁnd local linear lower
and upper bounds of a neural network. For each region in the partition, we use these bounds prove
that the composition of the neural network and the system forms a c-martingale. A branch-and-bound
approach is then proposed to improve the scalability of our framework and adaptively reﬁne the
partition of the state space. At training time, as common in adversarial training of neural networks
[18], we rely on the resulting linear bounds obtained by our certiﬁcation framework to train a neural
network that satisﬁes the c-martingale conditions, while also minimizing the conservatives of the
resulting safety certiﬁcation. An example of our framework is reported in Figure 1.

2

321012x2.01.51.00.50.00.51.0yPolynomial system & initial and unsafe setsInitial setUnsafe setx202y2101B(x,y)510Barrier function & initial and unsafe setsInitial setUnsafe setx0.250.30y0.260.280.300.32B(x,y)012Bound propagationCROWNBarrier function202x2.01.51.00.50.00.51.0yLower bound of B(x,y)0.02.55.07.510.012.5202x2.01.51.00.50.00.51.0yUpper bound of B(x,y)0.02.55.07.510.012.5202x2.01.51.00.50.00.51.0yGap between upper and lower bound0.00.10.20.30.4We experimentally investigate the suitability of our framework on several challenging non-linear
models including a non-linear vehicle dynamics model. We ﬁnd that our framework consistently
outperforms existing state-of-the-art approaches based on Sum-of-Squares (SoS) optimization [12].
For instance the experiments on the vehicle dynamics model show that, while the SoS approach
returns a lower bound of safety of 0% or fails due to computational constraints, our method is able to
returns a certiﬁcate of safety of 87% for the system by employing a neural network barrier function
of 3 hidden layers and 128 neurons per layer.

In summary, this paper makes the following main contributions: (i) We introduce a novel framework
to train NBFs for a given non-linear stochastic system, (ii) we present a branch-and-bound scheme for
the computation of a lower bound on the safety probability via NBFs based on the solution of linear
programs, and (iii) on multiple benchmarks we show that our framework can train and certify NBFs
with multiple hidden layers of hundreds of neurons and substantially outperforms state-of-the-art
competitive methods.

1.1 Related works

Safety certiﬁcation of dynamical systems Safety guarantees for dynamical systems can be gener-
ally obtained with two different approaches: abstraction-based methods where the system is abstracted
into a transition system, and veriﬁed using model checking [5], [19], [20], and barrier function-based
methods where certiﬁcation proceeds by ﬁnding an energy-like function to avoid the need for ﬁnding
an analytical solution to differential or difference equation [7], [21]. In the stochastic setting sum-of-
squares optimization is the state-of-the-art method for ﬁnding polynomial stochastic barrier functions,
and they have been already applied to discrete time [11], [12], continuous time [12], hybrid systems
[9], and also for LTL speciﬁcations [22].

Neural certiﬁcates Neural networks for representing barrier functions or Lyapunov function are
collectively called neural certiﬁcates [13]. Neural Lyapunov functions were ﬁrst proposed in [23], but
has later been rediscovered and seen a surge [14], [15], [24]. Lyapunov functions are designed to
certify stability [13], [14], [24], [25], while barrier functions are intended to certify safety [13]–[15].
The condition required to check that a given neural network is a barrier function differs according to
the class of systems considered; for deterministic systems [14], [15], [26], it is common to use zeroing
barriers while supermartingale-based barriers are common for stochastic systems [27]. The majority
of literature on neural certiﬁcates are for deterministic systems, where both continuous-time [14],
[15], [25], [26], [28], [29], and discrete-time systems have been studied [24], [27]. To the best of our
knowledge, the only paper that focuses on neural certiﬁcates for stochastic systems is [27]. However,
[27] only considers almost sure asymptotic stability, which is a different, and arguably simpler,
problem than the one considered in this paper. Furthermore, in order to certify that the composition
of a neural network with a non-linear system gives a valid Lyapunov function, [27] relies on the
Lipschitz constant of the underlying system. In contrast, our approach based on branch-and-bound
and linear relaxations is different and may lead to less conservative bounds, as already observed in
veriﬁcation of NNs when comparing these different certiﬁcation approaches [16].

A major challenge for neural certiﬁcates is the veriﬁcation that the neural network candidate is indeed
a valid barrier or Lyapunov function. For this reason a plethora of certiﬁcation methods have been
developed, including Satisﬁability Modulo Theory (SMT)-based certiﬁcation for feed-forward neural
networks with general action functions [13]–[15], [26], Mixed-Integer Linear Programming (MILP)-
based certiﬁcation for piecewise afﬁne functions [13], [30], [31], ﬁnding Lipschitz constants over a
grid mesh for the state space [24], [25], [27], and lastly sampling-based methods for validation of
certiﬁcate conditions but not certiﬁcation [29]. SMT- and MILP-based certiﬁcation suffers from lack
of scalability, restricting network sizes to 20-30 neurons in 2-3 hidden layers [14], [30]. On the other
hand, the Lipschitz method is computationally scalable to large neural networks, but generally very
conservative [32]. We address scalability with bound propagation, while ameliorating conservativity
with a branch-and-bound partitioning scheme. As shown in Section 5 our resulting framework can
scale to neural networks with multiple hidden layers and hundreds of neurons per layer.

3

2 Problem formulation

We consider a stochastic discrete-time system described by the following stochastic difference
equation:

x[k + 1] = F (x[k]) + v[k]
(1)
where x[k] ∈ Rn is the state of the system at time k, and v[k] is an independent random variable
distributed according to p(v) over an uncertainty space V ⊆ Rn. The function F : Rn × U → X
is a continuous function representing the one-step dynamics of System (1). System (1) represents
a general model of non-linear stochastic system with additive noise, a class of stochastic systems
widely used in many areas [33], [34], which also includes non-linear systems in closed loop with
feedback controllers synthesized with standard control theory methods (e.g. LQR [35]) as well as
neural networks [36].
We denote by X ⊂ Rn the state space of System (1), which is assumed to be a compact set. However,
since in general x[k] is not guaranteed to always lie inside a compact set (e.g. if the noise distribution
p(v) has unbounded support), as common in the literature [9], [12], we consider the stopped process
˜x[k] deﬁned as follows.
Deﬁnition 1. (Stopped Process) Let ˜k be the ﬁrst exit time of x from X. Then, the stopped process

˜x[k] is deﬁned as ˜x[k] =

(cid:26)x[k]

if k < ˜k
x[˜k] otherwise

.

For a given initial condition x0, ˜x[k] is a Markov process with a well deﬁned probability measure P
generated by the noise distribution p(v) [37, Proposition 7.45] such that for sets X0, Xk+1 ⊆ X it
holds that

P (˜x[0] ∈ X0) = 1X0 (x0)

P (˜x[k + 1] ∈ Xk+1 | ˜x[k] = xk) =

(cid:90)

V

1Xk+1(F (xk) + vk) · p(vk) dvk,

(2)

where 1Xk (xk) =

(cid:26)1

if xk ∈ Xk
0 otherwise

is the indicator function for set Xk.

In this paper we focus on verifying the safety of System (1) deﬁned as the probability that for a
given ﬁnite time horizon H ∈ N, ˜x[k] remains within a safe set Xs ⊆ X, which we assume to be a
measurable set.
Problem 1 (Probabilistic Safety). Given a safe set Xs ⊆ X, a ﬁnite time horizon H, and an initial
set of states X0 ⊆ Xs, compute

Psaf e(Xs, X0, H) = inf

x0∈X0

P (∀k ∈ [0, H], ˜x[k] ∈ Xs | x[0] = x0)

Note that the assumption of a ﬁnite time horizon is not limiting. In fact, if p(v) has unbounded support,
the probability of entering any unsafe region over an unbounded horizon is trivially 1. Furthermore,
we should stess that the distribution of ˜x[k] is analytically intractable, because ˜x[k] is the result of
iterative predictions over a non-linear function F with additive noise, which is analytically intractable
even if p(v) is Gaussian [33]. Consequently, the computation of Psaf e(Xs, X0, H) is particularly
challenging and requires approximations. Our approach is to rely on barrier functions parameterized
as neural networks to compute a sound lower bound of Psaf e.

3 Background on Local Relaxations of Neural Networks

Neural Networks (NNs) are highly non-linear and more importantly non-convex functions [38].
Hence, in order to prove that a neural network satisﬁes the conditions to be a barrier function we rely
on local upper and lower approximations of the NN, also known as relaxations. The simplest type of
relaxation is interval bounds where given a hyperrectangular input set, the bounds are an interval that
contains all the outputs of the NN for the points in the input set [39].
Deﬁnition 2 (Interval relaxation). An interval relaxation of a continuous function f : Rn → Rm
over a set X ⊆ Rn are two vectors1 b⊥, b(cid:62) ∈ Rm such that b⊥ ≤ f (x) ≤ b(cid:62),

∀x ∈ X.

1The two symbols ⊥, (cid:62) are called bottom and top respectively.

4

An alternative relaxation that often produce tighter bounds are linear relaxations.
Deﬁnition 3 (Linear relaxation). A linear relaxation of a continuous function f : Rn → Rm over
a set X ⊆ Rn are two linear functions A⊥x + b⊥ and A(cid:62)x + b(cid:62) with A⊥, A(cid:62) ∈ Rm×n and
b⊥, b(cid:62) ∈ Rm such that A⊥x + b⊥ ≤ f (x) ≤ A(cid:62)x + b(cid:62),

∀x ∈ X.

If a linear relaxation of a function f is deﬁned over a hyperrectangular set X, then it is possible to
ﬁnd an interval relaxation from the linear relaxation [40]. Let X = {x ∈ Rn | x⊥ ≤ x ≤ x(cid:62)} be
a hyperrectangle and A⊥x + b⊥ ≤ f (x) ≤ A(cid:62)x + b(cid:62) denote a linear relaxation. Then an interval
relaxation b⊥

interval, b(cid:62)

interval = A⊥
b⊥

interval can be computed as
(cid:18) x(cid:62) + x⊥
(cid:19)
2
(cid:18) x(cid:62) + x⊥
2

interval = A(cid:62)
b(cid:62)

(cid:19)

− |A⊥|

+ |A(cid:62)|

(cid:18) x(cid:62) − X ⊥
2
(cid:18) x(cid:62) − x⊥
2

(cid:19)

(cid:19)

+ b⊥

+ b(cid:62)

(3)

(4)

In order to ﬁnd a linear relaxation of a neural network with general activation functions (assumed
to be continuous) we employ CROWN [16], where linear lower and upper bounds are propagated
backwards through the neural network architecture. We note that if a NN is composed with a
continuous function, then CROWN-like techniques can still be applied on the composite computation
graph to derive linear relaxations of the composed function. In particular, we can treat the continuous
function as the ﬁrst layer of neural network and perform backwards bound propagation [17].

4 Probabilistic Safety via Neural Barrier Functions

Our framework to compute probabilistic safety for System (1) is based on stochastic barrier functions,
which we parameterize as neural networks. Since this paper only focuses on stochastic barrier
functions, we sometimes refer to them as just barrier functions. In what follows, we ﬁrst introduce
stochastic barrier functions (Section 4.1) and then show in Section 4.2 how to verify that a neural
network is a barrier function for System (1) using the relaxation methods introduced in Section 3.
Section 4.2.1 improves the veriﬁcation by introducing a branch-and-bound partitioning method to
ﬁnd tighter bounds for Psaf e, while keeping under control the required computational cost. Finally,
in Section 4.3 we show how techniques commonly used for robust training of NNs can be used to
train neural barrier functions (NBFs) for System (1).

4.1 Stochastic barrier functions

Similar to Lyapunov functions for proving stability [11], the main idea of stochastic barrier function is
to study the time properties of a system without the need to compute its ﬂow explicitly. In particular,
stochastic barrier functions rely on the theory of c-martingales2 to show that a stochastic process does
not exit a given safe set with high probability.
Deﬁnition 4 (Stochastic Barrier Function). Let Xs ⊆ X, X0 ⊆ Xs and Xu = X \Xs be respectively
safe set, set of initial states, and unsafe set. Then, we say that a non-negative continuous almost
everywhere function B : Rn → R≥0 is a stochastic barrier function for a stochastic discrete-time
system ˜x[k] as deﬁned in Section 2 if there exists β ≥ 0 and γ ≥ 0 such that

∀x ∈ X
∀x ∈ Xu

B(x) ≥ 0
B(x) ≥ 1

(5c)
(5d)
Proposition 1. ([11]) Let B be a barrier function for ˜x[k] and H ∈ N be a time horizon. Then, for
ε = γ + β · H it holds that Psaf e(Xs, X0, H) ≥ 1 − ε.

B(x) ≤ γ
E[B(F (x) + v)] ≤ B(x) + β

∀x ∈ X0
∀x ∈ Xs.

(5a)
(5b)

An intuition behind Conditions 5a-5d is given in Fig. 1b. Intuitively, these conditions guarantee that
the expectation of the composition of B with the one step dynamics of ˜x does not grow by more than
β in Xs, i.e. it forms a β−martingale. This allows us to use non-negative martingale inequalities to
compute Psaf e(Xs, X0, H) [12]. Critically, these are static conditions that do not require to evolve
˜x[k] to study its behavior over time.

2In the rest of the paper we will use β instead of c as is custom for stochastic barrier functions.

5

Figure 2: A barrier function B is a non-negative function that is greater than 1 in the unsafe region.
β is an upper bound on the expected increase in value of the barrier function when composed with
System (1) after one time step for any starting state xk. If the the expected value is decreasing β is
taken to be zero. γ is an upper bound of B(x) for x ∈ X0.

4.2 Neural Stochastic Barrier Functions

Given a feed-forward NN Bθ with arbitrarily many layers and continuous activation functions,
where θ represents the vector of the parameters (weights and biases), we want to verify if Bθ is a
valid stochastic barrier function for System (1), i.e. if it satisﬁes Conditions 5a-5d, thus forming a
neural barrier function (NBF). Our approach is based on employing the local relaxation techniques
introduced in Section 3 to build piece-wise linear functions that under- and over-approximate Bθ.
In particular, we partition X to a ﬁnite set of regions Q = {q1, ..., q|Q|} and, using the techniques
q ∈ R such
introduced in Section 3, for each q ∈ Q we can ﬁnd matrices A⊥
that

q ∈ R1×n and b⊥

q , A(cid:62)

q , b(cid:62)

A⊥

q x + b⊥

q ≤ Bθ(x) ≤ A(cid:62)

q x + b(cid:62)
q ,

∀x ∈ q.

Then, the following lemma follows trivially.
Lemma 2. Let QXu ⊆ Q and QX0 ⊆ Q be such that Xu ⊆ ∪q∈QXu
γ = maxq∈QX0

maxx∈q A(cid:62)

q . Then, if

q x + b(cid:62)

q and X0 ⊆ ∪q∈QX0

q. Choose

min
q∈Q

min
x∈q

A⊥

q x + b⊥

q ≥ 0

min
q∈QXu

min
x∈q

A⊥

q x + b⊥

q ≥ 1,

(6)

Conditions 5a-5c are satisﬁed.

Note that under the assumption that q is a convex polytope, which can always be enforced by
the partition strategy, then Lemma 2 reduces to the solution of linear programs. Furthermore, as
discussed in Section 3, we remark that if interval relaxation techniques are employed, then ∀q ∈ Q
A⊥
q = 01×n. As a consequence, checking Conditions 5a-5c reduces to simply the evaluation
q = A(cid:62)
of vectors b⊥

q at the price of possibly more conservative bounds.

q , b(cid:62)

We now turn our attention to β, and consequently to the computation of the martingale condition
(Condition 5d). Unfortunately, due to the non-linearity of the functions involved, for x ∈ X
E[Bθ(F (x) + v)] is analytically intractable. As a consequence, we again rely on computing local
under- and over-approximations. In particular, consider ﬁnite partitions Q and QV respectively of the
state space X and of the uncertainty space V , and let ˜Q = Q × Qv. Then, as discussed in Section 3
for each q ∈ Q and ˜q = (qx, qv) ∈ ˜Q we can ﬁnd row vectors A⊥
∈ R1×n
˜q ∈ R such that
and scalars b⊥

q , A⊥
qx

q , A(cid:62)
qx

q , b(cid:62)

˜q , b(cid:62)

q , b⊥

, A(cid:62)
qv

, A⊥
qv

, A(cid:62)

∀x ∈ q,
∀(x(cid:48), v(cid:48)) ∈ ˜q,

A⊥
A⊥
qx

q x + b⊥

q ≤ Bθ(x) ≤ A(cid:62)
v(cid:48) + b⊥

q x + b(cid:62)
q
˜q ≤ Bθ(F (x(cid:48)) + v(cid:48)) ≤ A(cid:62)
qx

x(cid:48) + A⊥
qv

x(cid:48) + A(cid:62)
qv

v(cid:48) + b(cid:62)
˜q .

(7)

(8)

The following theorem uses the above relaxations to bound E[B(F (x) + v)] and consequently ﬁnd a
lower bound on β.

6

γxkx[k+1]x[k+1]xkB(xk)E[B(x[k+1])|x[k]=xk]β=0xB(x)B(xk)E[B(x[k+1])|x[k]=xk]β>01X0Xu0Theorem 3. Let Q and QV respectively be partitions of X and V . Let QXs ⊆ Q be such that
∪q∈QXs

q ⊆ Xs. For ˜q = (qx, qv) ∈ Q × QV deﬁne

A(qx,qv) = A(cid:62)
qx

(cid:90)

qv

p(v) dv,

b(qx,qv) = b(cid:62)
˜q

(cid:90)

qv

p(v) dv + A(cid:62)
qv

(cid:90)

qv

vp(v) dv,

and assume

β ≥ max
q∈QXs

max
x∈q





(cid:0) (cid:88)

A(q,qv) − A⊥
q

(cid:1)x + (cid:0) (cid:88)

b(q,qv) − b⊥
q

(cid:1)

 .

(9)



qv∈QV
Then, for any x ∈ Xs it holds that E[Bθ(F (x) + v)] − Bθ(x) ≤ β.

qv∈QV

qv

qv

The proof of Theorem 3 is reported in the Appendix and relies on the under and over approximations
introduced in Eqns (7) and (8). In particular, by relying on the additive nature the noise and on
the linearity of the expectation, we can compute exactly how these linear functions are propagated
through the expectation.
The computation of A(qx,qv) and b(qx,qv) in Theorem 3 requires the evaluation of integrals (cid:82)
p(v) dv
and (cid:82)
vp(v) dv, which are the probability of the noise being in qv and the partial expectation of the
noise restricted to qv respectively. For various classes of distributions, such as Gaussian with diagonal
covariance matrix, uniform, or ﬁnite support distributions, these integrals can be computed in closed
forms. Otherwise, numerical approximations may be required. One additional challenge is that if
the noise has unbounded support as is the case with Gaussian noise, then some qv are inﬁnite in size.
For these partitions, linear relaxations may not exist, hence we cannot compute A(qx,qv) and b(qx,qv).
However, this problem can be solved by noticing that ˜x is a stopped process outside X, which allows
one to set Bθ(x) = 0 for all x (cid:54)∈ X. With this assumption Bθ is still continuous almost everywhere
(assuming that the boundary of X has measure zero). This guarantees the conditions of Proposition
1 are satisﬁed. Furthermore, since X is bounded, such an assumption can simplify the partitioning
as we can ﬁnd the bounded subset of V such that Bθ(F (x) + v) (cid:54)= 0. In particular, for any x ∈ X,
Bθ(F (x) + v) (cid:54)= 0 only for v ∈ V (cid:48) = {v | x⊥ − x(cid:62) ≤ v ≤ x(cid:62) − x⊥} where x⊥, x(cid:62) ∈ Rn are two
vectors such that X = {x | x⊥ ≤ x ≤ x(cid:62)}.
Remark 1. We remark that the results of this Section, and Theorem 3 in particular, can also be applied
to systems with non-additive noise at the price of increased conservativeness. Speciﬁcally, given
x[k + 1] = F (x[k], v[k]) for F : Rn × V → Rn continuous in both inputs, we can employ the linear
relaxation techniques described in Section 3 to ﬁnd lower and upper bounds of the system dynamics
that are linear in x and v locally to each partition. Then, the results in this Section can be applied.

We stress that, similarly to Lemma 2, Theorem 3 allows us to ﬁnd β by solving linear programs that
reduces to evaluation of constants if interval relaxation techniques are employed.

4.2.1 A Branch and Bound Scheme for Veriﬁcation

In order to guarantee scalability to our veriﬁcation framework, we develop a branch-and-bound
partitioning scheme inspired by [41], [42] that starting from a coarse partitioning of X gradually
reﬁnes it by splitting regions and pruning those that already satisfy the barrier conditions. For
convenience, we assume that all regions q be hyperrectangles. We perform the branch-and-bound
independently for each of the conditions in Deﬁnition 4 (Conditions 5a-5d). In what follows, we
explain the partitioning scheme for Condition 5b, the others follow analogously.
We start with a coarse initial partition QXu of Xu. Then, as shown in Lemma 2, for Xu ⊆ ∪q∈QXu
q
minx∈q A⊥
Condition 5b reduces to check if minq∈QXu
q ≥ 1. As we start with a coarse partition
initially our bounds may be very conservative. Consequently, we gradually reﬁne QXu . First of all,
we identify which regions to prune and which to split. This is decided based on the error introduced by
the linear bounds in each partition. Speciﬁcally, at each iteration we split all regions in QXu , whereas
we prune region q if either q ∩ Xu = ∅ or minx∈q A⊥
q . In
fact, if the minimum value of B in q is greater than the smallest upper bound in another region
q(cid:48) ∈ QXu , then q does not inﬂuence the satisfaction of Condition 5b and can be discarded.
One iteration of splitting and pruning is shown in Fig. 3. For each region q we only split in half the
dimension d that introduces the highest source of uncertainty, that is, we split dimension d at the

q ≥ minq∈QXu

minx∈q A(cid:62)

q x + b(cid:62)

q x + b⊥

q x+b⊥

7

Figure 3: One iteration of the automatic partitioning scheme with splitting and pruning for Condition
5b. The set Xu is shown as a black blob, and hyperrectangles q ∈ QXu are split and pruned.
LU B = minq∈QXu

q denotes the least upper bound.

minx∈q A(cid:62)

q x + b(cid:62)

(cid:0)(|A⊥

q |)T (cid:12) (q(cid:62) − q⊥)(cid:1)

q | + |A(cid:62)

midpoint such that d = arg max1≤i≤n
where (cid:12) is the elementwise
product and q⊥, q(cid:62) denote the lower and upper bounds of q and (·)i represents the ith component of
a vector. Then, we prune regions that do not inﬂuence the ﬁnal result of the minimization problem
according to the conditions described above. Finally, we stop the partitioning when the barrier
q ≥ 1, or the gap between upper and lower
condition is satisﬁed, i.e., minq∈QXu
bound for minx∈Xu Bθ(x) is less than a threshold tgap > 0, that is if minq∈QXu
q x +
b(cid:62)
q − minq∈QXu

minx∈q A⊥

minx∈q A⊥

minx∈q A(cid:62)

q < tgap.

q x + b⊥

q x + b⊥

i

4.3 Training Stochastic Neural Barrier Functions

We now describe the neural network training procedure, which is the key piece to obtain a valid
stochastic barrier function Bθ. As Conditions 5a-5d needs to hold over regions in the state space, the
rationale behind our approach is to adapt techniques commonly employed in certiﬁed adversarial
training of NN [18], [40] to our setting. Our training procedure starts by sampling independently m
training points from each set X, X0, Xs, and Xu. We denote each of the resulting training sets by
Q(m)
X . Furthermore, we independently sample l vectors v1, . . . , vl from the noise
Xs
distribution p(v). Then, for training parameters 0 ≤ κ ≤ 1 and (cid:15) > 0, and a time horizon H ∈ N,
the robust training loss L(cid:15) is deﬁned as follows

, Q(m)
Xu

, Q(m)
X0

, Q(m)

L(cid:15) = (1 − κ)Lviolation + κ(γ(m) + β(m) · H)

Lviolation =


1
2m




(cid:88)

x∈Q(m)

X

max(0, −

min
x(cid:48):||x−x(cid:48)||∞≤(cid:15)

Bθ(x(cid:48))) +

(cid:88)

max(0, 1 −

x∈Q(m)
Xu

min
x(cid:48):||x−x(cid:48)||∞≤(cid:15)

Bθ(x(cid:48)))






γ(m) = max
x∈Q(m)
X0

max
x(cid:48):||x−x(cid:48)||∞≤(cid:15)

Bθ(x(cid:48))

β(m) = max
x∈Q(m)
X0

max
x(cid:48):||x−x(cid:48)||∞≤(cid:15)

(cid:0) 1
l

l
(cid:88)

j=1

Bθ(F (x(cid:48)) + vj) − Bθ(x(cid:48))(cid:1).

Intuitively, Lviolation penalizes parameters θ that violates Conditions 5a and 5b, while minimizing
γ(m) + β(m) · H maximizes the safety probability according to Proposition 1. Consequently, κ
weights between having a valid stochastic barrier function and achieving tight probability bounds.
min and max of Bθ over an (cid:15)−ball around each training point are computed similarly to in Lemma 2
and Theorem 3 by employing the linear and interval relaxation techniques introduced in Section 3.

8

PartitioningtorefineSplit(redlines)Pruneifq∩Xu=∅RefinedpartitioningPruneKeep(touchingXu)LeastupperboundMinMaxPruneifminx∈qA⊥qx+b⊥q≥LUBLUBThis also explains the role of (cid:15): small values of (cid:15) guarantee tighter approximations of Bθ, while for
larger values we obtain potentially looser bounds but that cover a larger portion of the state space.

5 Experimental Evaluation

We evaluate our framework on three benchmarks: a 2-D linear system taken from [12], the 2-D
polynomial system shown in Figure 1 from [14], and a 3-D discrete-time Dubin’s car model [14],
which is a non-polynomial system. In order to show the ﬂexibility of our framework, for all systems
we consider the same neural barrier function architecture: a feed-forward neural network with 3
hidden layers, 128 neurons per hidden layer, and ReLU activation functions. For computing linear
relaxations, we use CROWN-IBP [40] during training and CROWN [16] for veriﬁcation. We employ
a batch size m = 250 and train the neural network for 150 epochs with 400 iterations per epoch. To
gradually switch from maximizing probability of safety to prioritizing a valid barrier, we start with
κ = 1.0 and exponentially decay with multiplicative factor of 0.97 for each epoch. We implemented
our method in Python. For the SoS comparision, we have reimplemented the algorithm in [12] in
Julia (1.7.2) with SumOfSquares.jl (0.5.0), and use Mosek (9.3.11). Experiments are conducted on an
Intel i7 6700K CPU with 16GB RAM and Nvidia GTX1060 GPU with 6GB VRAM. Further details
can be found in the Supplementary Material including an analysis on the effect of (cid:15)3.

Linear

Method

2-D polynomial Dubin’s car

Table 1: Certiﬁed lower bound for Psaf e. Higher is better,
and the best result for each system is highlighted in bold.
NBF stands for Neural Barrier Function (our approach),
while SoS is sum-of-square optimization. Cells with ”-”
denotes that SoS failed to compute a barrier.

Certiﬁcation Results To illustrate
the efﬁcacy of our framework, in Ta-
ble 1 we compare the lower bound
of Psaf e obtained with our model
with a sum-of-squares optimization
based approach [12], which arguably
is the state-of-the-art for ﬁnding bar-
rier functions for stochastic systems.
For all the benchmarks we consider
SoS polynomials of order up to 15. In
all cases it is possible to observe that
our approach based on neural barrier
functions (NBF) outperforms SoS op-
timization in terms of the tightness of
the bounds. For instance, in the Du-
bin’s car model, arguably the hardest
example we consider due to its non-polynomial nature, SoS either fails due to excessive memory
requirements or return a trivial lower bound on 0, while our framework obtains a lower bound of
0.87. In contrast, in the linear system both SoS and our approach obtain a similar certiﬁed level of
safety, but SoS is substantially faster (orders of minutes for the linear system), as our framework still
requires to ﬁrst train a neural network and then certify it (orders of few hours for all benchmarks as
we used the same neural network architecture). To understand the difference in certiﬁed safety, we
study contour plots of the barrier function with the initial and unsafe sets for the 2-D polynomial
(see Figure 4). Note that the certiﬁed lower bound for Psaf e via Proposition 1 can be non-zero
only in regions where B(x) < 1. Interestingly, we observe this region is signiﬁcantly smaller for
SoS compared NBF, which is attributed to the reduced expressivity of the SoS polynomial. The
differences in region sizes and the distances to the initial sets explain the certiﬁcation result for the
2-D polynomial system we see in Table 1.

0.000000
0.232710
0.681383
-
0.991664

0.690906
0.975079
0.998405
0.999761
0.999969

-
-
-
-
0.870272

SoS (4)
SoS (8)
SoS (13)
SoS (15)
NBF

6 Conclusion

We studied probabilistic safety certiﬁcation of stochastic systems using Neural Barrier Function
(NBF). We presented algorithms to train NBFs and show that the problem of certifying that a neural
network is a NBF for a given stocahstic system reduces to the solution of a set of linear programs.
The scalability of our framework is guaranteed by a branch-and-bound approach. We evaluated our
method on linear, polynomial, and non-linear and non-polynomial systems, beating state-of-the-art

3Code for both NBF and SoS is available under GNU GPLv3 license at https://github.com/

DAI-Lab-HERALD/neural-barrier-functions.

9

(a) NBF

(b) SoS

Figure 4: Levelset for Bθ (a) and BSoS,8, an 8−th order SoS barrier function (b) for the 2-D
polynomial system. The neural network is more ﬂexible to capture complex shapes of the unsafe set
and less sharply increasing in value.

methods on all systems, thus certifying previously intractable non-linear systems. Hence, this works
make a clear step towards the safe adoption of autonoumous systems in safety-critical settings. Future
work may address scalability with probabilistic veriﬁcation of barrier conditions and extend NBFs to
deterministic and continuous-time systems.

References

[1] T. Duriez, S. L. Brunton, and B. R. Noack, Machine learning control-taming nonlinear

dynamics and turbulence. Springer, 2017.

[2] T. Gordon and M. Lidberg, “Automated driving and autonomous functions on road vehicles,”
Vehicle System Dynamics, vol. 53, no. 7, pp. 958–994, 2015. DOI: 10.1080/00423114.2015.
1037774.
J. A. Wise, V. D. Hopkin, and M. L. Smith, Eds., Automation and Systems Issues in Air Trafﬁc
Control. Springer Berlin Heidelberg, 1991. DOI: 10.1007/978-3-642-76556-8.

[3]

[4] W. Schwarting, J. Alonso-Mora, and D. Rus, “Planning and decision-making for autonomous
vehicles,” Annual Review of Control, Robotics, and Autonomous Systems, vol. 1, no. 1, pp. 187–
210, 2018. DOI: 10.1146/annurev-control-060117-105157.

[5] L. Laurenti, M. Lahijanian, A. Abate, L. Cardelli, and M. Kwiatkowska, “Formal and efﬁcient
synthesis for continuous-time linear stochastic hybrid processes,” IEEE Transactions on
Automatic Control, vol. 66, no. 1, pp. 17–32, 2020.

[6] C. Belta and S. Sadraddini, “Formal methods for control synthesis: An optimization perspec-
tive,” Annual Review of Control, Robotics, and Autonomous Systems, vol. 2, no. 1, pp. 115–140,
2019. DOI: 10.1146/annurev-control-053018-023717.

[7] A. D. Ames, S. Coogan, M. Egerstedt, G. Notomista, K. Sreenath, and P. Tabuada, “Control
barrier functions: Theory and applications,” in 2019 18th European Control Conference (ECC),
2019, pp. 3420–3431. DOI: 10.23919/ECC.2019.8796030.

[8] Z. Jarvis-Wloszek, R. Feeley, W. Tan, K. Sun, and A. Packard, “Some controls applications
of sum of squares programming,” in 42nd IEEE International Conference on Decision and
Control, vol. 5, 2003, 4676–4681 Vol.5. DOI: 10.1109/CDC.2003.1272309.

[9] S. Prajna, A. Jadbabaie, and G. J. Pappas, “A framework for worst-case and stochastic safety
veriﬁcation using barrier certiﬁcates,” IEEE Transactions on Automatic Control, vol. 52, no. 8,
pp. 1415–1428, 2007.

[10] H. J. Kushner, “Stochastic stability and control,” Brown Univ Providence RI, Tech. Rep., 1967.
J. Steinhardt and R. Tedrake, “Finite-time regional veriﬁcation of stochastic non-linear systems,”
[11]
The International Journal of Robotics Research, vol. 31, no. 7, pp. 901–923, 2012.

[12] C. Santoyo, M. Dutreix, and S. Coogan, “A barrier function approach to ﬁnite-time stochastic
system veriﬁcation and control,” Automatica, vol. 125, p. 109 439, 2021, ISSN: 0005-1098.
DOI: 10.1016/j.automatica.2020.109439.

10

321012x2.01.51.00.50.00.51.0y11333555779Initial setUnsafe set321012x2.01.51.00.50.00.51.0y151020205050Initial setUnsafe set[13] C. Dawson, S. Gao, and C. Fan, Safe control with learned certiﬁcates: A survey of neural

lyapunov, barrier, and contraction methods, 2022. DOI: 10.48550/ARXIV.2202.11762.

[14] A. Abate, D. Ahmed, A. Edwards, M. Giacobbe, and A. Peruffo, “Fossil: A software tool
for the formal synthesis of lyapunov functions and barrier certiﬁcates using neural networks,”
in Proceedings of the 24th International Conference on Hybrid Systems: Computation and
Control, ser. HSCC ’21, Nashville, Tennessee: Association for Computing Machinery, 2021,
ISBN: 9781450383394. DOI: 10.1145/3447928.3456646.

[15] H. Zhao, X. Zeng, T. Chen, and Z. Liu, “Synthesizing barrier certiﬁcates using neural networks,”
in Proceedings of the 23rd International Conference on Hybrid Systems: Computation and
Control, ser. HSCC ’20. New York, NY, USA: Association for Computing Machinery, 2020,
ISBN: 9781450370189. DOI: 10.1145/3365365.3382222.

[16] H. Zhang, T.-W. Weng, P.-Y. Chen, C.-J. Hsieh, and L. Daniel, “Efﬁcient neural network
robustness certiﬁcation with general activation functions,” in Advances in Neural Information
Processing Systems (NuerIPS), Dec. 2018.

[17] K. Xu, Z. Shi, H. Zhang, Y. Wang, K.-W. Chang, M. Huang, B. Kailkhura, X. Lin, and C.-J.
Hsieh, “Automatic perturbation analysis for scalable certiﬁed robustness and beyond,” in
NeurIPS, 2020.

[18] M. Wicker, L. Laurenti, A. Patane, Z. Chen, Z. Zhang, and M. Kwiatkowska, “Bayesian
inference with certiﬁable adversarial robustness,” in International Conference on Artiﬁcial
Intelligence and Statistics, PMLR, 2021, pp. 2431–2439.

[19] N. Cauchi, L. Laurenti, M. Lahijanian, A. Abate, M. Kwiatkowska, and L. Cardelli, “Efﬁciency
through uncertainty: Scalable formal synthesis for stochastic hybrid systems,” in Proceedings
of the 22nd ACM International Conference on Hybrid Systems: Computation and Control,
ser. HSCC ’19, Montreal, Quebec, Canada: Association for Computing Machinery, 2019,
pp. 240–251, ISBN: 9781450362825. DOI: 10.1145/3302504.3311805.

[20] P. Prabhakar and M. Garcia Soto, “Abstraction based model-checking of stability of hybrid
systems,” in Computer Aided Veriﬁcation, N. Sharygina and H. Veith, Eds., Berlin, Heidelberg:
Springer Berlin Heidelberg, 2013, pp. 280–295, ISBN: 978-3-642-39799-8.

[21] A. Agrawal and K. Sreenath, “Discrete control barrier functions for safety-critical control
of discrete systems with application to bipedal robot navigation,” in Robotics: Science and
Systems, 2017.

[22] P. Jagtap, S. Soudjani, and M. Zamani, “Formal synthesis of stochastic systems via control
barrier certiﬁcates,” IEEE Transactions on Automatic Control, vol. 66, no. 7, pp. 3097–3110,
2021. DOI: 10.1109/TAC.2020.3013916.

[23] G. Serpen, “Empirical approximation for lyapunov functions with artiﬁcial neural nets,” in
Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005., vol. 2,
2005, 735–740 vol. 2. DOI: 10.1109/IJCNN.2005.1555943.

[24] S. M. Richards, F. Berkenkamp, and A. Krause, “The lyapunov neural network: Adaptive
stability certiﬁcation for safe learning of dynamic systems,” ArXiv, vol. abs/1808.00924, 2018.
[25] W. Jin, Z. Wang, Z. Yang, and S. Mou, Neural certiﬁcates for safe control policies, 2020. DOI:
10.48550/ARXIV.2006.08465. [Online]. Available: https://arxiv.org/abs/2006.
08465.

[26] Y.-C. Chang, N. Roohi, and S. Gao, “Neural lyapunov control,” Advances in neural information

processing systems, vol. 32, 2019.

[27] M. Lechner, Ð. Žikeli´c, K. Chatterjee, and T. A. Henzinger, Stability veriﬁcation in stochastic
control systems via neural network supermartingales, 2021. DOI: 10.48550/ARXIV.2112.
09495. [Online]. Available: https://arxiv.org/abs/2112.09495.

[28] A. Robey, H. Hu, L. Lindemann, H. Zhang, D. V. Dimarogonas, S. Tu, and N. Matni, “Learning
control barrier functions from expert demonstrations,” 2020 59th IEEE Conference on Decision
and Control (CDC), pp. 3717–3724, 2020.

[29] C. Dawson, Z. Qin, S. Gao, and C. Fan, “Safe nonlinear control using robust neural lyapunov-

barrier functions,” in 5th Annual Conference on Robot Learning, 2021.

[30] H. Dai, B. Landry, L. Yang, M. Pavone, and R. Tedrake, Lyapunov-stable neural-network
control, 2021. DOI: 10.48550/ARXIV.2109.14152. [Online]. Available: https://arxiv.
org/abs/2109.14152.

11

[31] H. Dai, B. Landry, M. Pavone, and R. Tedrake, “Counter-example guided synthesis of neural
network lyapunov functions for piecewise linear systems,” in 2020 59th IEEE Conference
on Decision and Control (CDC), 2020, pp. 1274–1281. DOI: 10.1109/CDC42340.2020.
9304201.

[32] M. Fazlyab, A. Robey, H. Hassani, M. Morari, and G. J. Pappas, “Efﬁcient and accurate
estimation of lipschitz constants for deep neural networks,” in Proceedings of the 33rd Interna-
tional Conference on Neural Information Processing Systems. Red Hook, NY, USA: Curran
Associates Inc., 2019.

[33] A. Girard, C. Rasmussen, J. Q. Candela, and R. Murray-Smith, “Gaussian process priors with
uncertain inputs application to multiple-step ahead time series forecasting,” Advances in neural
information processing systems, vol. 15, 2002.
J. Jackson, L. Laurenti, E. Frew, and M. Lahijanian, “Strategy synthesis for partially-known
switched stochastic systems,” in Proceedings of the 24th International Conference on Hybrid
Systems: Computation and Control, 2021, pp. 1–11.

[34]

[35] K. J. Åström and R. M. Murray, “Feedback systems,” in Feedback Systems, Princeton university

press, 2010.

[36] B. Recht, “A tour of reinforcement learning: The view from continuous control,” Annual

Review of Control, Robotics, and Autonomous Systems, vol. 2, pp. 253–279, 2019.

[37] D. P. Bertsekas and S. E. Shreve, Stochastic optimal control: the discrete-time case. Athena

Scientiﬁc, 2004, vol. 5.

[38] H. Li, Z. Xu, G. Taylor, C. Studer, and T. Goldstein, “Visualizing the loss landscape of neural

nets,” Advances in neural information processing systems, vol. 31, 2018.

[39] M. Wicker, L. Laurenti, A. Patane, and M. Kwiatkowska, “Probabilistic safety for bayesian neu-
ral networks,” in Conference on Uncertainty in Artiﬁcial Intelligence, PMLR, 2020, pp. 1198–
1207.

[40] H. Zhang, H. Chen, C. Xiao, S. Gowal, R. Stanforth, B. Li, D. Boning, and C.-J. Hsieh,
“Towards stable and efﬁcient training of veriﬁably robust neural networks,” in International
Conference on Learning Representations, 2020.

[41] R. Bunel, I. Turkaslan, P. H. Torr, P. Kohli, and M. P. Kumar, “A uniﬁed view of piecewise
linear neural network veriﬁcation,” in Proceedings of the 32nd International Conference on
Neural Information Processing Systems, ser. NIPS’18, Montréal, Canada: Curran Associates
Inc., 2018, pp. 4795–4804.

[42] K. Xu, H. Zhang, S. Wang, Y. Wang, S. Jana, X. Lin, and C.-J. Hsieh, “Fast and complete:
Enabling complete neural network veriﬁcation with rapid and massively parallel incomplete
veriﬁers,” in International Conference on Learning Representations, 2021.

[43] M. Iannelli and A. Pugliese, An Introduction to Mathematical Population Dynamics, en,
2014th ed., ser. UNITEXT. Basel, Switzerland: Springer International Publishing, Jul. 2014.
[44] D. Balkcom, A. Furtuna, and W. Wang, “The dubins car and other arm-like mobile robots,” in
2018 IEEE International Conference on Robotics and Automation (ICRA), 2018, pp. 380–386.
DOI: 10.1109/ICRA.2018.8461017.

[45] M. Putinar, “Positive polynomials on compact semi-algebraic sets,” Indiana University Mathe-

matics Journal, vol. 42, no. 3, pp. 969–984, 1993, ISSN: 00222518, 19435258.

12

A Appendix

A.1 Proof of Lemma 2

Lemma 2. Let QXu ⊆ Q and QX0 ⊆ Q be such that Xu ⊆ ∪q∈QXu
γ = maxq∈QX0

maxx∈q A(cid:62)

q . Then, if

q x + b(cid:62)

q and X0 ⊆ ∪q∈QX0

q. Choose

min
q∈Q

min
x∈q

A⊥

q x + b⊥

q ≥ 0

min
q∈QXu

min
x∈q

A⊥

q x + b⊥

q ≥ 1,

(10)

Conditions 5a-5c are satisﬁed.

q x + b⊥

q x + b⊥
q ≤ Bθ(x) for all x ∈ q. Then minx∈q A⊥

Proof. Condition 5a. Let A⊥
q be a linear lower bound of Bθ(x) local to a region q, i.e.
A⊥
q ≤ minx∈q Bθ(x), and therefore
minq∈Q minx∈q A⊥
q ≤ minq∈Q minx∈q Bθ(x) where Q is a set of regions partitioning X.
Since Q is a partition of X, minq∈Q minx∈q Bθ(x) = minx∈X Bθ(x). Therefore, we can conclude
if minq∈Q minx∈q A⊥

q ≥ 0 then Bθ(x) ≥ 0 for all x ∈ X (Condition 5a) is satisﬁed.

q x + b⊥

q x + b⊥

q x + b⊥

Condition 5b. Following the same proof structure, let A⊥
q x + b⊥
Bθ(x) local to a region q. Then minq∈QXu
QXu ⊆ Q is a set of regions covering Xu, i.e. Xu ⊆ ∪q∈QXu
Xu, minimum of Bθ of all regions in QXu is a lower bound for Bθ in Xu,

q x + b⊥
q be a linear lower bound of
q ≤ minq∈QXu
minx∈q Bθ(x) where
q. Since QXu is a partition covering

minx∈q A⊥

min
q∈QXu

min
x∈q

Bθ(x) ≤ min
x∈Xu

Bθ(x).

Therefore, if minq∈QXu
satisﬁed.

minx∈q A⊥

q x + b⊥

q ≥ 1 then Bθ(x) ≥ 1 for all x ∈ Xu (Condition 5b) is

Condition 5c. Once again following the same proof structure except for proving an upper bound, let
A(cid:62)
q x+b(cid:62)
maxx∈q A(cid:62)
q ≥
q. Since QX0 is a partition
maxq∈QX0
covering X0,

q be a linear upper bound of Bθ(x) local to a region q. Then maxq∈QX0

minx∈q Bθ(x) where QX0 ⊆ Q such that X0 ⊆ ∪q∈QX0

q x+b(cid:62)

max
q∈QX0

max
x∈q

Bθ(x) ≥ max
x∈X0

Bθ(x).

Therefore, choosing γ = maxq∈QX0
Bθ(x) ≤ γ for all x ∈ X0 (Condition 5c) is satisﬁed.

maxx∈q A(cid:62)

q x + b(cid:62)

q yields γ ≥ maxx∈X0 Bθ(x). We conclude

A.2 Proof of Theorem 3

We restate Theorem 3 and then prove it. Recall that for each q ∈ Q and ˜q = (qx, qv) ∈ ˜Q we let row
(qx,qv) ∈ R be such that
∈ R1×n and scalars b⊥
vectors A⊥

(qx,qv), b(cid:62)

q , A⊥
qx

q , A(cid:62)
qx

q , b(cid:62)

q , b⊥

, A⊥
qv

, A(cid:62)
qv

, A(cid:62)

∀x ∈ q,
∀(x(cid:48), v(cid:48)) ∈ ˜q,

A⊥
A⊥
qx

q x + b⊥

q ≤ Bθ(x) ≤ A(cid:62)
v(cid:48) + b⊥

x(cid:48) + A⊥
qv

q x + b(cid:62)
q

(qx,qv) ≤ Bθ(F (x(cid:48)) + v(cid:48)) ≤ A(cid:62)
qx

x(cid:48) + A(cid:62)
qv

v(cid:48) + b(cid:62)

(qx,qv).

Theorem 3. Let Q and QV respectively be partitions of X and V . Let QXs ⊆ Q be such that
∪q∈QXs

q ⊆ Xs. For ˜q = (qx, qv) ∈ Q × QV deﬁne

A(qx,qv) = A(cid:62)
qx

(cid:90)

qv

p(v) dv,

b(qx,qv) = b(cid:62)

(qx,qv)

(cid:90)

qv

p(v) dv + A(cid:62)
qv

(cid:90)

qv

vp(v) dv,

and assume

β ≥ max
q∈QXs

max
x∈q





(cid:0) (cid:88)

A(q,qv) − A⊥
q

(cid:1)x + (cid:0) (cid:88)

b(q,qv) − b⊥
q

(cid:1)

 .

(11)

qv∈QV

qv∈QV



Then, for any x ∈ Xs it holds that E[Bθ(F (x) + v)] − Bθ(x) ≤ β.

13

Proof. By assumption it holds that for each partition ˜q = (qx, qv)

Bθ(F (x) + v) ≤ A(cid:62)
qx

x + A(cid:62)
qv

v + b(cid:62)

(qx,qv)

∀(x, v) ∈ ˜q = (qx, qv)

(12)

Hence, for x ∈ qx it holds that

E[Bθ(F (x) + v) | x] =

(cid:90)

(cid:88)

Bθ(F (x) + v)p(v) dv

qv

(cid:90)

qv

(cid:16)

A(cid:62)
qx

x + A(cid:62)
qv

v + b(cid:62)

(qx,qv)

(cid:17)

p(v) dv

(13)

A(qx,qv)x + b(qx,qv).

qv∈QV
(cid:88)

qv∈QV
(cid:88)

qv∈QV

≤

=

q x + b⊥

q , the lower bound of Bθ(x). It then follows

We can now combine the above bound with A⊥
that
(cid:0)E[Bθ(F (x) + v)] − Bθ(x)(cid:1) ≤


max
x∈Xs

max
q∈QXs

max
x∈q



(cid:0) (cid:88)

A(q,qv) − A⊥
q

(cid:1)x + (cid:0) (cid:88)

b(q,qv) − b⊥
q

qv∈QV

qv∈QV





(cid:1)

(14)

Therefore, if we pick β such that

max
q∈QXs

max
x∈q



(cid:0) (cid:88)



qv∈QV

A(q,qv) − A⊥
q

(cid:1)x + (cid:0) (cid:88)

b(q,qv) − b⊥
q

(cid:1)

 ≤ β

(15)

qv∈QV



it holds that E[Bθ(F (x) + v)] − Bθ(x) ≤ β.

A.3 Branch-and-bound algorithm

Similarly to Section 4.2.1, we only show the partitioning algorithm for verifying B(x) ≥ 1 for
all x ∈ Xu. The partitioning for the remaining barrier conditions (Condition 5a, 5c, 5d) follow
analogously. The algorithm starts from a coarse initial partition of Xu called Qinit. A possible initial
partition is a single hyperrectangle encompassing X, which will always exist since X is bounded.
Next, we ﬁnd linear relaxations of Bθ for each region q in the partition (Line 3-5), which we use
for proving if Bθ(x) ≥ 1 for all x ∈ Xu. This is the case if minq∈Q minx∈q A⊥
q ≥ 1,
meaning that we stop partitioning if this condition is satisﬁed (Line 7). The other stop condition
minq∈Q minx∈q A(cid:62)
q ≤ tgap is to stop the partitioning if the
found lower bound is within tgap of the true minimum (Line 6). If neither of the two stop conditions
are satisﬁed, we reﬁne the partition by splitting all regions (Line 8). To select the split axis, we
pick the one with the largest linear coefﬁcients, because that maximizes tightening of both upper
and lower bounds, weighted by the width of the region along the given axis to avoid elongated
regions because that empirically yields loose bounds (Line 21-22) Finally, to combat the exponential
growth of splitting, we prune regions that cannot contain minx∈Xu B(x), based on two conditions:
q ∩ Xu = ∅ meaning that a region has been split such that q no longer overlaps with Xu, and the
lower bound minx∈q A⊥

q is larger than an upper bound for minx∈Xu B(x) (Line 12-13).

q − minq∈Q minx∈q A⊥

q x + b⊥

q x + b⊥

q x + b(cid:62)

q x + b⊥

A.4 Experiment details

In this section, we describe the dynamics of each experimental system and the associated safe/unsafe
and initial regions. For all systems, we deﬁne a step horizon H = 10 and the number for samples to
approximate the expectation during training l = 500.

Linear dynamics We adopt the linear, discrete-time system from [12], which represents juve-
nile/adult population dynamics [43]. The system is governed following stochastic difference equation
(cid:20) 0 m3
m1 m2

x[k] + v[k]

x[k + 1] =

(16)

(cid:21)

14

q , b⊥

q , b⊥

q , A(cid:62)

q , A(cid:62)

q x + b⊥

q ≥ tgap and

q x + b(cid:62)
q x + b⊥

q ← CROWN(B, q)

q ← CROWN(B, q)

q − minq∈Q minx∈q A⊥
q ≤ 1 do

Q ← Qinit
for Region q in Q do
q , b(cid:62)

Q ← SPLIT(Q, f )
for Region q in Q do
q , b(cid:62)

A⊥
end for
while minq∈Q minx∈q A(cid:62)
minq∈Q minx∈q A⊥

A⊥
end for
blub ← minqi∈Q minx∈q A(cid:62)
Q ← {q ∈ Q | minx∈q A⊥

Algorithm 1 Partitioning of unsafe set Xu based on local linear relaxations of B(x) to ﬁnd
minx∈Xu B(x) given an initial partition Qinit of Xu.
1: function PARTITIONING-UNSAFE(Qinit, tgap)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16: end function
17: function SPLIT(Q, f )
Qnew ← ∅
18:
for Region q in Q do
19:
q , b(cid:62)
20:
q | + |A(cid:62)
21:
22:
23:
24:
25:
26:
27: end function

q , A(cid:62)
q , b⊥
A⊥
Aq ← (|A⊥
d ← arg max1≤i≤n Aq,i
q1, q2 ← SPLIT-MID(q, d)
Qnew ← Qnew ∪ {q1, q2}

(cid:46) Find axis with largest inﬂuence on bounds
(cid:46) Select axis to split
(cid:46) Split hyperrectangle at midpoint along axis d

q ← CROWN(B, q)
q |) (cid:12) (q(cid:62) − q⊥)

end while
return minx∈q A⊥

q ≤ blub and q ∩ Xu (cid:54)= ∅}

end for
return Qnew

(cid:46) Least upper bound

q x + b⊥

q x + b(cid:62)
q

q x + b⊥
q

We choose parameters m1 = 0.3, m2 = 0.8, and m3 = 0.4, and v[k] ∼ N (· | [0, 0]T , [0, 0.1]T ),
which we remark are different from [12]. The parameters in [12] are unstable since the basic
reproduction number R = m1m3
1−0.95 = 5 > 1, meaning the origin is an unstable equilibrium
1−m2
[43]. We believe the results reported [12] are the result of a discrepancy in the associated code
compared to the stochastic difference equation in the paper. More speciﬁcally, the columns in the
top row of the dynamics matrix are swapped, resulting in one-way interaction rather than two-way
interaction. We deﬁne the state space, initial and safe set as follows with Xu = X\Xs

is 0.5·0.5

X = {x ∈ R2 | −3 ≤ x1 ≤ 3 and − 3 ≤ x2 ≤ 3}

X0 = {x ∈ X | x2

1 + x2

2 ≤ 1.52},

Xs = {x ∈ X | x2

1 + x2

2 ≤ 22}

(17)

Polynomial model For a polynomial system, we adapt 2-D system barr3 from [14] by discretizing
time using an Euler integrator and adding noise. Due to the discretization, letting h denote the step
size, the time horizon is H · h with a step horizon H. Particular for this system is that both the initial
and unsafe sets consist of two disjoint regions, which is shown in Fig. 4. A polynomial system can
be directly encoded SoS optimization.

x[k + 1]1 = x[k]1 + h · x[k]2 + v[k]1

x[k + 1]2 = x[k]2 + h ·

x[k]3

1 − x[k]1 − x[k]2

(cid:19)

+ v[k]2

(cid:18) 1
3

(18)

where vk ∼ N (· | [0, 0]T , [0.01, 0]T ). The state space, initial and unsafe set (also shown in Figure 4)
are deﬁned as follows with Xs = X\Xu

X = {x ∈ R2 | −3.5 ≤ x1 ≤ 2 and − 2 ≤ x2 ≤ 1}
X0 = circ(−1.5, 0, 0.5) ∪ rect(−1.8, −0.1, 0.6, 0.2) ∪ rect(−1.4, −0.5, 0.2, 0.6)
Xu = circ(−1, −1, 0.4) ∪ rect(0.4, 0.1, 0.2, 0.4) ∪ rect(0.4, 0.1, 0.4, 0.2)

(19)

15

where circ(a, b, r) = {x ∈ R2 | (x1 − a)2 + (x2 − b)2 ≤ r2} is a circle with radius r centered at
(a, b) and rect(a, b, c, d) = {x ∈ R2 | a ≤ x1 ≤ a + c and b ≤ x2 ≤ b + d} is a rectangle with the
lower corner at (a, b) with width c and height d. We choose a step size h = 0.1.

Dubin’s car System barr4 from [14], also known as Dubin’s car [44], is our non-polynomial
experimental system. The state of system is the position in a plane and the heading of the vehicle,
and the steering angle is bounded. We adapt the system from continuous-time deterministic to
discrete-time stochastic by discretizing time with an Euler integrator and adding noise to steering
angle. To encode the system into a polynomial suitable for SoS, we partition the state space into a grid,
compute linear bounds of the nominal dynamics with CROWN, and use Putinar’s Positivstellensatz
[45].

Let h denote the step size, i.e. H · h is the time horizon. Then, dynamics are governed by

x[k + 1]1 = x[k]1 + h · v sin(x[k]3) + v[k]1
x[k + 1]2 = x[k]2 + h · v cos(x[k]3) + v[k]2
x[k + 1]3 = x[k]3 + h · u + v[k]3

(20)

where v[k] ∼ N (· | [0, 0, 0]T , [0, 0, 0.01]T ), v is the velocity, and u denotes the steering angle.
We choose a steering angle u = 1 / 0.95 such that the vehicle drives in a clockwise circle with a
radius corresponding to distance between the origin and the starting position. We additionally choose
velocity v = 1 and step size h = 0.1. The state space, initial and unsafe set are deﬁned as follows
with Xu = X\Xs

X = {x ∈ R3 | −2 ≤ x1 ≤ 2 and − 2 ≤ x2 ≤ 2 and − π/2 ≤ x2 ≤ π/2}

X0 = {(−0.95, 0, 0)},

Xs = {x ∈ X | −1.9 ≤ x1 ≤ 1.9 and − 1.9 ≤ x2 ≤ 1.9}

(21)

A.5 Study of (cid:15)-hyperrectangles for training

We analyze the impact of the varying (cid:15); half the width of the input hyperrectangle during training.
The analysis is conducted on the polynomial system as described in Sec. A.4 because it has complex
dynamics but is 2-D, so we may easily plot levelsets to study the impact. Figure 5 shows contour
plots of different Bθ(x) learned with various (cid:15) in increasing order. The obvious change is that the
increasing in barrier value over the state space is less for larger (cid:15), which is intuitive as the larger (cid:15)
yields looser bounds hence the adversarial training promotes a ﬂatter surface. While a ﬂat surface is
good for a smaller β, it is a trade-off as it requires a larger γ to ensure that the Bθ(x) ≥ 1 for x ∈ Xu.
Hence tuning (cid:15) is a trade-off between small β and γ.

16

(a) (cid:15) = 0.00001

(b) (cid:15) = 0.0001

(c) (cid:15) = 0.001

(d) (cid:15) = 0.01

Figure 5: Contour plots showcasing the impact of increasing (cid:15), the half width of the input hyperrect-
angle during training. Larger (cid:15) results in a ﬂatter surface, yielding a smaller β at the expense of a
larger γ.

17

321012x2.01.51.00.50.00.51.0y11335557779Initial setUnsafe set321012x2.01.51.00.50.00.51.0y1133355579Initial setUnsafe set321012x2.01.51.00.50.00.51.0y113Initial setUnsafe set321012x2.01.51.00.50.00.51.0y113Initial setUnsafe set