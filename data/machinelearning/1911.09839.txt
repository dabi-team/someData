Differentiable Algorithm for Marginalising Changepoints

Hyoungjin Lim, Gwonsoo Che, Wonyeol Lee, Hongseok Yang
School of Computing
KAIST, South Korea

@kaist.ac.kr
lmkmkr, gche, wonyeol, hongseok.yang
}

{

9
1
0
2

v
o
N
2
2

]

G
L
.
s
c
[

1
v
9
3
8
9
0
.
1
1
9
1
:
v
i
X
r
a

Abstract

We present an algorithm for marginalising changepoints in
time-series models that assume a Ô¨Åxed number of unknown
changepoints. Our algorithm is differentiable with respect to
its inputs, which are the values of latent random variables
other than changepoints. Also, it runs in time O(mn) where
n is the number of time steps and m the number of change-
points, an improvement over a naive marginalisation method
with O(nm) time complexity. We derive the algorithm by
identifying quantities related to this marginalisation problem,
showing that these quantities satisfy recursive relationships,
and transforming the relationships to an algorithm via dy-
namic programming. Since our algorithm is differentiable,
it can be applied to convert a model non-differentiable due
to changepoints to a differentiable one, so that the resulting
models can be analysed using gradient-based inference or
learning techniques. We empirically show the effectiveness
of our algorithm in this application by tackling the posterior
inference problem on synthetic and real-world data.

1

Introduction

Time-series data from, for instance, econometrics, medi-
cal science, and political science (Erdman and Emerson
2008; Lio and Vannucci 2000; Spokoiny and others 2009;
Haynes, Eckley, and Fearnhead 2017; Reeves et al. 2007;
Lung-Yut-Fong, L¬¥evy-Leduc, and Capp¬¥e 2012) often show
abrupt regime shifts, so that analysing those data commonly
requires reasoning about the moments of these shifts, called
changepoints. Two popular reasoning tasks are inferring the
number of changepoints and detecting the speciÔ¨Åc values or
distributions of the changepoints. Information found from
these tasks enables the use of different statistical models for
different segments of the data, identiÔ¨Åed by changepoints,
which leads to accurate analysis of the data. However, due
to the discrete nature of changepoints, developing efÔ¨Åcient
algorithms for the tasks is tricky, and often requires an in-
sight into the structure of a class of models used.

In the paper, we study the problem of marginalising
changepoints, which has been under-explored compared
with the two tasks mentioned above. We present a differen-
tiable algorithm for marginalising changepoints for a class

Copyright c(cid:13) 2020, Association for the Advancement of ArtiÔ¨Åcial
Intelligence (www.aaai.org). All rights reserved.

of time-series models that assume a Ô¨Åxed number of change-
points. Our algorithm runs in
(mn) time where m is the
number of changepoints and n the number of time steps.
We do not know of any
(mn)-time algorithm that directly
solves this changepoint-marginalisation problem. The class
of models handled by our algorithm is broad, including non-
Markovian time-series models.

O

O

Our marginalisation algorithm is differentiable with re-
spect to its inputs, which enables the use of gradient-based
algorithms for posterior inference and parameter learn-
ing on changepoint models. Since changepoints are dis-
crete, gradient-based algorithms cannot be applied to these
models, unless changepoints are marginalised out. In fact,
marginalising discrete variables, such as changepoints, is
a trick commonly adopted by the users of the Hamilto-
nian Monte Carlo algorithm or its variant (Stan Develop-
ment Team 2018). Our algorithm makes the trick a viable
(mn) time complex-
option for changepoint models. Its
ity ensures low marginalisation overhead. Its differentiabil-
ity implies that the gradients of marginalised terms can be
computed by off-the-shelf automated differentiation tools
(Paszke et al. 2017; Abadi et al. 2016). In the paper, we
demonstrate these beneÔ¨Åts of our algorithm for posterior in-
ference.

O

The key insight of our algorithm is that the likelihood of
latent variables with changepoints marginalised out can be
expressed in terms of quantities that satisfy recursive rela-
tionships. The algorithm employs dynamic programming to
compute these quantities efÔ¨Åciently. Its
(mn) time com-
plexity comes from this dynamic programming scheme, and
its differentiability comes from the fact that dynamic pro-
gramming uses only differentiable operations. In our experi-
ments with an inference problem, the algorithm outperforms
existing alternatives.

O

The rest of the paper is organised as follows. In

2, we de-
¬ß
3,
scribe our algorithm and its theoretical properties, and in
we explain how this algorithm can be used to learn model
parameters from given data. In
4, we describe our experi-
ments where we apply the algorithm to a posterior-inference
5, we put our results in the context of existing
problem. In
¬ß
work on changepoint models and differentiable algorithms,
and conclude the paper.

¬ß

¬ß

 
 
 
 
 
 
2 Marginalisation Algorithm

m, and R+ be the set
Let n, m be positive integers with n
of positive real numbers. We consider a probabilistic model
for n-step time-series data with m+1 changepoints, which
has the following form. Let

Rk and

Rl.

‚â•

x1:n
w1:n

Rn

‚àà X
‚àà

Z ‚äÜ
X ‚äÜ
n ‚Äî data points over n time steps.
+ ‚Äî wt expresses a relative chance of the

step t becoming a changepoint. wn = 1.

z1:m

‚àà Z

m ‚Äî latent parameters deciding the distribution

of the data points x1:n.

œÑ0:m

‚àà

Nm+1 ‚Äî changepoints. 0 = œÑ0 < œÑ1 <

< œÑm = n.

¬∑ ¬∑ ¬∑

P (œÑ0:m

|

w1:n) (cid:44) 1
W

P (x1:n, z1:m, œÑ0:m

|

m‚àí1

m‚àí1

wœÑi where W =

wœÑi,

i=1
(cid:89)
w1:n) (cid:44)
m

œÑ0:m
(cid:88)

i=1
(cid:89)

œÑi

P (z1:m)P (œÑ0:m

w1:n)

|

P (xj

|

x1:j‚àí1, zi).

i=1
(cid:89)

(cid:89)(j=œÑi‚àí1+1)

For simplicity, we assume for now that w1:n is Ô¨Åxed and
its normalising constant W is known. In
2.1, we will show
¬ß
how the assumption can be removed safely.

Our goal is to Ô¨Ånd an efÔ¨Åcient algorithm for computing the
likelihood of the data x1:n for the latent z1:m, which involves
marginalising the changepoints œÑ0:m as shown below:

P (x1:n

|

z1:m, w1:n) =

P (x1:n, œÑ0:m

œÑ0:m
(cid:88)

z1:m, w1:n). (1)

|

Note that summing the terms in (1) naively is not a viable
option because the number of the terms grows exponentially
in the number of changepoints (i.e.,

(nm‚àí1)).

Our algorithm computes the sum in (1) in

(mn) time.
Two key ideas behind the algorithm are to rewrite the sum in
terms of recursively expressible quantities, and to compute
these quantities efÔ¨Åciently using dynamic programming.

O

O

For integers k, t with 1

k < m and m

1

‚àí

‚â§

t < n, let

‚â§

Tk,t (cid:44)

œÑ0:m

{

|

L0,t (cid:44) 0,

Rm,t (cid:44) 1,

Rk,t (cid:44)

m‚àí1

j=k
(cid:89)

œÑ0:m changepoints, œÑm‚àí1 = t, and
1 + œÑi = œÑi+1 for all i with k
Lk,t (cid:44)

P (x1:n, œÑ0:m

1
}
‚â§
z1:m, w1:n),

i < m

‚àí

,

|

œÑ0:m‚ààTk,t
(cid:88)

b(k, t) (cid:44) t
P (xb(j,t)+1 |
P (xb(j,t)+1 |

((m

1)

‚àí

‚àí

‚àí
x1:b(j,t), zj)
√ó
x1:b(j,t), zj+1)

k),

wb(j,t)+1
wb(j,t)

√ó

.

The Ô¨Årst Tk,t consists of changepoints œÑ0:m such that œÑm‚àí1
ends at t and (œÑk, œÑk+1, . . . , œÑm‚àí1) are consecutive. The next
Lk,t selects the summands in (1) whose changepoints œÑ0:m
are in Tk,t. It then sums the selected terms. The b(k, t) com-
putes the value of the k-th changepoint for 1
k < m
when the changepoints œÑk, œÑk+1, . . . , œÑm‚àí1 are consecu-
tive and the value of œÑm‚àí1 is t. The last Rk,t is the ra-
tio of the probabilities of the segment xb(k,t)+1:b(m‚àí1,t)+1

‚â§

Figure 1: Visualisation of a case split used in Theorem 2.

(= xb(k,t)+1:t+1) and the changepoints œÑk:m‚àí1 under two
different assumptions. The numerator assumes that œÑj =
b(j, t) + 1 for all k
j < m, whereas the denominator
assumes that œÑj = b(j, t) for all those j. A good heuristic
is to view Rk,t as the change in the probability of the seg-
ment xb(k,t)+1:t+1 and the changepoints œÑk:m‚àí1 when those
changepoints are shifted one step to the right.

‚â§

The next

three results formally state what we have
promised: the Lk,t can be used to express the sum in (1),
and the Lk,t and the Rk,t satisfy recursive relationships.
Proposition 1.
œÑ0:m P (x1:n, œÑ0:m
n‚àí1
equal to
t=m‚àí1 Lm‚àí1,t.
(cid:80)

z1:m, w1:n) in (1) is

|

(cid:80)

Proof. Because
Tm‚àí1,t
‚àí
{
the set of all changepoints œÑ0:m.

m

|

1

t < n
}

‚â§

is a partition of

Thus, we can marginalise changepoints by computing
n‚àí1
t=m‚àí1 Lm‚àí1,t. This begs the question of how to compute

the Lm‚àí1,t‚Äôs. The next two results give an answer.
(cid:80)
Theorem 2. For all k, t with 1

k < m and m

‚â§
z1:m, œÑ0:m=(0, 1, . . . , m
P (œÑ0:m=(0, 1, . . . , m

|
√ó

t < n,

‚â§
1, n))

‚àí
1, n)

‚àí

w1:n) ,

|

Lk,m‚àí1 = P (x1:n

Lk,t = Lk‚àí1,t + Lk,t‚àí1 √ó

Rk,t‚àí1 .

Figure 1 visualises a case split used in the second equa-
tion. Lk,t is the quantity about changepoints with œÑk:m‚àí1 =
(b(k, t), . . . , t). The Ô¨Ågure shows that such changepoints can
be partitioned into those with œÑk‚àí1 = b(k
1, t) and the rest.
The Ô¨Årst summand Lk‚àí1,t computes the contribution of the
changepoints in the Ô¨Årst partition, and the other summand of
the equation that of the changepoints in the second partition.

‚àí

Proof. By deÔ¨Ånition, Tk,m‚àí1 is the singleton set
|
. The Ô¨Årst equality in the theo-
1, n)
œÑ0:m = (0, 1, . . . , m
}
rem follows from this and the deÔ¨Ånition of Lk,m‚àí1. For the
second equality, consider k, t that satisfy the condition in the
theorem. We will prove the following two equations:

œÑ0:m
{

‚àí

Lk,t‚àí1 √ó

Rk,t‚àí1 =

P (x1:n, œÑ0:m

œÑ0:m‚ààTk,t
(cid:88)
œÑk‚àí1(cid:54)=b(k‚àí1,t)

z1:m, w1:n) ,

(2)

|

ùëõùë°ùëèùëò,ùë°ùëèùëò‚àí1,ùë°ùúèùëöùúèùëö‚àí1ùúèùëò‚ãØ0ùúè0:ùëò‚àí1ùêøùëò,ùë°‚à∂0ùúè0:ùëò‚àí2ùúèùëò‚àí1ùúèùëòùêøùëò‚àí1,ùë°‚à∂ùëõùë°ùúèùëöùúèùëö‚àí1‚ãØùëèùëò‚àí1,ùë°ùëèùëò,ùë°0ùúè0:ùëò‚àí1ùúèùëòùêøùëò,ùë°‚àí1√óùëÖùëò,ùë°‚àí1‚à∂ùëõùë°ùúèùëöùúèùëö‚àí1‚ãØùëèùëò‚àí1,ùë°ùëèùëò,ùë°Lk‚àí1,t =

œÑ0:m‚ààTk,t
(cid:88)
œÑk‚àí1=b(k‚àí1,t)

P (x1:n, œÑ0:m

|

z1:m, w1:n) .

(3)

The desired conclusion follows from these two equations:

Lk‚àí1,t + Lk,t‚àí1 √ó

Rk,t‚àí1

=

œÑ0:m‚ààTk,t
(cid:88)

P (x1:n, œÑ0:m

|

z1:m, w1:n) = Lk,t .

Equation (3) holds since Tk‚àí1,t =

Tk,t
. Equation (2) is proved as follows. Let

œÑ0:m

‚àà

{

|

}

‚àà
z1:m, w1:n)
z1:m, w1:n)

(cid:98)

1, t)
}
Tk,t

{

‚àà

œÑ0:m

œÑk‚àí1 = b(k
Tk,t (cid:44)
œÑ (cid:48)
0:m
(cid:98)
Then,

‚àí
œÑ0:m
{
(cid:44) (œÑ0:k‚àí1, œÑk
œÑ (cid:48)
0:m|
P (x1:n, œÑ0:m
P (x1:n, œÑ (cid:48)
P (œÑ0:m
P (œÑ (cid:48)
m‚àí1

|
0:m|
|
0:m|
wœÑi
wœÑ (cid:48)

=

i √ó

w1:n)
w1:n) √ó
m‚àí1

i=k
(cid:89)
m‚àí1

i=k
(cid:89)

wb(i,t)
wb(i,t)‚àí1 √ó

=

=

i=k
(cid:89)
= Rk,t‚àí1.

œÑk‚àí1 (cid:54)
= b(k
|
‚àí
1, ..., œÑm‚àí1 ‚àí
‚àí
Tk,t

,
1, t)
}

1, n) for œÑ0:m

= Tk,t‚àí1. For every œÑ0:m

Tk,t.

Tk,t,
(cid:98)

‚àà

‚àà

(cid:98)

œÑ0:m, z1:m)
P (x1:n
|
œÑ (cid:48)
P (x1:n
0:m, z1:m)
|
x1:œÑi‚àí1, zi)
P (xœÑi|
i , zi+1)
x1:œÑ (cid:48)
P (xœÑ (cid:48)
i +1|
P (xb(i,t)|
P (xb(i,t)|

m‚àí1

i=k
(cid:89)

x1:b(i,t)‚àí1, zi)
x1:b(i,t)‚àí1, zi+1)

Therefore,

(cid:88)œÑ0:m‚àà (cid:98)Tk,t
=

P (x1:n, œÑ0:m

z1:m, w1:n)

|

P (x1:n, œÑ (cid:48)

0:m |

z1:m, w1:n)

Rk,t‚àí1

√ó

P (x1:n, œÑ0:m

z1:m, w1:n)

Rk,t‚àí1

√ó

|

(cid:88)œÑ0:m‚àà (cid:98)Tk,t

=

œÑ0:m‚ààTk,t‚àí1
(cid:88)
= Lk,t‚àí1 √ó

Rk,t‚àí1.

Proposition 3. For all k, t with 1
t < n,

‚â§

k < m and m

1

‚àí

‚â§

Rk,t = Rk+1,t

√ó

P (xb(k,t)+1 |
P (xb(k,t)+1 |

x1:b(k,t), zk)
√ó
x1:b(k,t), zk+1)

wb(k,t)+1
wb(k,t)

√ó

.

Proof. Immediate from the deÔ¨Ånition of Rk,t.

When combined with the idea of dynamic programming,
the recursive formulas in the propositions and the theorem
give rise to an
(mn) algorithm for marginalising change-
points. We spell out this algorithm in Algorithm 1.
Theorem 4. Algorithm 1 computes P (x1:n
z1:m, w1:n),
where m is the number of changepoints and n is the num-
ber of steps in given data. Moreover, the algorithm runs in

O

|

(mn) time, if computing P (xj

x1:j‚àí1, zi) for all 1

O
m and 2
‚â§
can be computed in

‚â§

j

n takes

(mn) time (i.e., P (xj

|
(1) amortised time).

O

|

‚â§
‚â§
x1:j‚àí1, zi)

i

O

Algorithm 1 Algorithm for marginalising changepoints.
Input: (i) integer m; (ii) weights w1:n with wn = 1; (iii)
w1:n); (iv) latent
n
z1:m, w1:n) where change-

normalising constant W for P (œÑ0:m
variables z1:m; (v) time-series data x1:n with 1

Output: likelihood P (x1:n

m

‚â§

‚â§

|

‚àí
‚Üê
z1:m, œÑ0:m=(0, 1, . . . , m
|
1 do
‚àí
L1,m‚àí1

P (œÑ0:m=(0, 1, . . . , m

‚àí

1, n))
‚àí
w1:n)
1, n)
|

m and 2

i

‚â§

j

‚â§

‚â§

n

|
points œÑ0:m are marginalised
1 do
1

m

1 to n
‚àí
0; Rm,t
P (x1:n

1: for t
‚Üê
L0,t
2:
‚Üê
3: L1,m‚àí1 ‚Üê
4: for k
5:
6: Pi,j
7: for t
8:
9:

√ó
2 to m
‚Üê
Lk,m‚àí1 ‚Üê
x1:j‚àí1, zi) for 1
P (xj
|
‚Üê
1 to n
m
‚Üê
for k
m

‚â§
1 do
1 downto 1 do

‚àí

‚àí
‚Üê
Rk,t

‚Üê
m to n

‚àí
Rk+1,t

√ó

1 do

‚Üê
Lk,t

‚Üê
for k

10: for t
11:
12:
13: L
‚Üê
14: for t
‚Üê
L
15:
‚Üê
return L

0

‚àí

‚àí
1 do
1 to m
Lk‚àí1,t + Lk,t‚àí1 √ó
1 do
1 to n

‚Üê

m
‚àí
L + Lm‚àí1,t

‚àí

Pb(k,t)+1,k √ó wb(k,t)+1
Pb(k,t)+1,k+1 √ó wb(k,t)

Rk,t‚àí1

Proof. The correctness follows from Propositions 1 and 3
and Theorem 2. We analyse the run time as follows. The line
(mn) by
3 computes the RHS in
the assumption. In the rest of the algorithm, nested loops and
other loops iterate
(mn) times, and each line inside the
loops runs in

(1). So, the algorithm runs in

(n). The line 6 runs in

(mn).

O

O

O

O

O

x1:j‚àí1, zi) is differentiable with
Theorem 5. When P (xj
respect to x1:j and zi, the result of Algorithm 1 is also differ-
entiable with respect to x1:n and z1:m, and can be computed
by applying automated differentiation to the algorithm.

|

Proof. When P (xj
x1:j‚àí1, zi) is differentiable with re-
|
spect to x1:j and zi, the likelihood P (x1:n
z1:m, w1:n) is
differentiable with respect to x1:n and z1:m. So, the correct-
ness of Algorithm 1 in Theorem 4 implies the claimed dif-
ferentiability. The other claim about the use of automated
differentiation holds because Algorithm 1 does not use any
non-differentiable operations such as if statements.

|

2.1 Computation of normalising constant W
So far we have assumed that weights w1:n are Ô¨Åxed and the
normalising constant W for P (œÑ0:m
w1:n) is known. We
now discharge the assumption. We present an algorithm for
computing W for given w1:n. The algorithm uses dynamic
(mn) time, and is differentiable: the
programming, runs in
gradient of W with respect to w1:n can be computed by ap-
plying automated differentiation to the algorithm.

O

|

For all k and t with 1
k

t < n,
‚â§
i=1 wœÑi and S0,t (cid:44) 1. Note that
let Sk,t (cid:44)
W = Sm‚àí1,n‚àí1. So, it sufÔ¨Åces to design an algorithm for
computing Sk,t. The next proposition describes how to do it.

k < m and 0

œÑ0:k, œÑk‚â§t

(cid:80)

(cid:81)

‚â§

k < m and k
wt and Sk,k‚àí1 = 0.

Proposition 6. For all k, t with 1
‚â§
we have Sk,t = Sk,t‚àí1 + Sk‚àí1,t‚àí1 √ó
The recurrence relation for Sk,t in Proposition 6 yields
a dynamic-programming algorithm for computing W that
runs in
(mn) time. The standard implementation of the al-
gorithm does not use any non-differentiable operations. So,
its gradient can be computed by automated differentiation.

t < n,

O

‚â§

|

With this result at hand, we remove the assumption that
weights w1:n are Ô¨Åxed and the normalising constant W for
w1:n) is known a priori. Algorithm 1 no longer re-
P (œÑ0:m
ceives W as its input. It instead uses the algorithm described
above and computes W from given w1:n before starting
line 1. Since the computation of W takes
(mn) time and
can be differentiated by automated differentiation, all the
aforementioned results on Algorithm 1 (Theorems 4 and 5)
still hold, and can be extended to cover the differentiability
of Algorithm 1 with respect to w1:n.

O

3 Learning Model Parameters
Our algorithm can extend the scope of gradient-based
methods for posterior inference and model learning such
that they apply to changepoint models despite their non-
differentiability. In this section, we explain the model-
learning application. We consider state-space models with
changepoints that use neural networks. The goal is to learn
appropriate neural-network parameters from given data.
We consider a special case of the model described in

2

that satisÔ¨Åes the following conditions.
1. The latent parameter zi at i

has the Ô¨Åxed
1, . . . , m
m that has 1 at the i-th position and
value ei in
}
0 everywhere else. Formally, this means that the prior
P (z1:m) is the Dirac distribution at (e1, e2, . . . , em).

0, 1
{

‚àà {

}

¬ß

2. The random variable xj at j

parts, xS
observed value. Thus, xj = (xS
j , xO
3. The probability distribution PœÜ(xj

consists of two
}
S for the latent state and xO
O for the
j ‚àà X
O.
j ) and
=
X
X
x1:j‚àí1, zi) is param-

j ‚àà X

1, . . . , n

√ó X

‚àà {

S

‚àà

eterised by œÜ

Rp for some p, and has the form
xS
j , zi)PœÜ(xS
xS
x1:j‚àí1, zi) = PœÜ(xO
PœÜ(xj
1:j‚àí1, zi).
j |
j |
Typically, PœÜ is deÔ¨Åned using a neural network, and œÜ
denotes the weights of the network.

|

|

When the model satisÔ¨Åes these conditions, we have

PœÜ(x1:n

|

w1:n) =

PœÜ(x1:n, z1:m

z1:m
(cid:88)

w1:n)

|

=

P (z1:m)PœÜ(x1:n

z1:m, w1:n)

|

z1:m
(cid:88)
= PœÜ(x1:n

(z1:m = e1:m), w1:n).

(4)

|
By the learning of model parameters, we mean the prob-
lem of Ô¨Ånding œÜ for given observations xO
1:n that makes the
log probability of the observations log PœÜ(xO
w1:n) large.
A popular approach (Kingma and Welling 2014) is to max-
imise a lower bound of this log probability, called ELBO,
approximately using a version of gradient ascent:

1:n |

ELBOœÜ,Œ∏ (cid:44) E

QŒ∏(xS

1:n|xO

1:n)

log

(cid:20)

PœÜ(xS

1:n, xO
1:n|

QŒ∏(xS

w1:n)
1:n|
xO
1:n)

(5)

(cid:21)

where QŒ∏ is an approximating distribution for the posterior
Rq denotes the parameters of
PœÜ(xS
‚àà
this distribution, typically the weights of a neural network
used to implement QŒ∏.

xO
1:n, w1:n) and Œ∏

1:n |

1:n, xO

Our marginalisation algorithm makes it possible to op-
timise ELBOŒ∏,œÜ in (5) by an efÔ¨Åcient stochastic gradient-
ascent method based on the so called reparameterisation
trick (Kingma and Welling 2014; Rezende, Mohamed, and
Wierstra 2014; Kucukelbir et al. 2017). Here we use our al-
gorithm with Ô¨Åxed m, w1:n after setting z1:m to e1:m.1 So,
only the x1:n = (xS
1:n) part of its input may vary. To
emphasise this, we write ALG(œÜ, xS
1:n) for the result
of the algorithm. Also, we make the usual assumption of
the reparameterisation trick: there are a Œ∏-independent dis-
tribution Q((cid:15)) and a differentiable function TŒ∏((cid:15), xO
1:n) such
that TŒ∏((cid:15), xO
Q((cid:15)) is distributed according to
1:n) for (cid:15)
QŒ∏(xS
xO
1:n). The next theorem shows that the gradient of
1:n |
ELBO can be estimated by computing the gradient through
the execution of our algorithm via automated differentiation.
x1:j‚àí1, zi) is differentiable with re-
Theorem 7. If PœÜ(xj
spect to x1:j and œÜ, so is ALG(œÜ, xS
1:n). In that case,
the gradient can be computed by automated differentiation.

1:n, xO

1:n, xO

‚àº

|

Proof. When PœÜ(xj
x1:j‚àí1, zi) is differentiable with re-
|
z1:m, w1:n) is
spect to x1:j and œÜ, the likelihood PœÜ(x1:n
differentiable with respect to x1:n and œÜ. Thus, the correct-
ness of Algorithm 1 in Theorem 4 implies the claimed dif-
ferentiability. The other claim about the use of automated
differentiation comes from the fact that Algorithm 1 does
not use any non-differentiable operations.

|

Theorem 8. When PœÜ(xj
respect to x1:j and œÜ for all j and i,

|

x1:j‚àí1, zi) is differentiable with

(cid:92)MRep (cid:44)

œÜ,Œ∏ log

‚àá

ALG(œÜ, TŒ∏((cid:15), xO
QŒ∏(TŒ∏((cid:15), xO
1:n)

1:n), xO
xO
1:n)

1:n)

|

for (cid:15)

‚àº

Q((cid:15))

is an unbiased estimate for
puted via automated differentiation.

‚àá

œÜ,Œ∏ELBOœÜ,Œ∏, and can be com-

1:n|

1:n, xO

w1:n) = PœÜ(x1:n

Proof. PœÜ(xS
(z1:m=e1:m), w1:n)
|
by (4). The RHS of the equation equals ALG(œÜ, xS
1:n)
by Theorem 4 and the deÔ¨Ånition of ALG. So, ELBOœÜ,Œ∏ =
1:n,xO
E
. The usual unbiased-
1:n | xO
1:n)
ness argument of the reparameterisation trick and the dif-
(cid:104)
1:n, xO
ferentiability of ALG(œÜ, xS
1:n) with respect to x1:n and
œÜ (Theorem 7) give the claimed conclusion.

ALG(œÜ,xS
QŒ∏(xS

1:n, xO

1:n|xO

QŒ∏(xS

log

1:n)

1:n)

(cid:105)

4 Experimental Evaluation
As mentioned, another important application of our al-
gorithm is posterior inference. In this section, we report
the Ô¨Åndings from our experiments with this application,
which show the beneÔ¨Åts of having an efÔ¨Åcient differentiable
marginalisation algorithm for posterior inference.

1W is computed by the extension of our algorithm in ¬ß2.1. In
fact, using the same extension, we can even treat w1:n as a part of
œÜ, and learn appropriate values for w1:n.

(a) Time per sample vs. m
when n = 50.

(b) Time per sample vs. n
when m = 2.

Figure 2: Computation time of HMCnaive and HMCours for
different m and n. The x- and y-axes are in log-scale.

Hamiltonian Monte Carlo (HMC) (Duane et al. 1987;
Neal 2011) is one of the most effective algorithms for sam-
pling from posterior distributions, especially on high dimen-
sional spaces. However, it cannot be applied to models with
changepoints directly. This is because HMC requires that a
model have a differentiable density, but changepoint models
do not meet this requirement due to discrete changepoints.

One way of addressing this non-differentiability issue is to
use our algorithm and marginalise changepoints. Since our
algorithm is differentiable, the resulting models have differ-
entiable densities, and we can analyse their posteriors using
HMC. We tested this approach experimentally, aiming at an-
swering the following questions:

‚Ä¢

‚Ä¢

RQ1 (Speed): How fast is our marginalisation algorithm
when used for HMC?

RQ2 (Sample quality): Is HMC with our marginalisation
algorithm better at generating good posterior samples than
other Markov Chain Monte Carlo (MCMC) algorithms
that do not use gradients nor marginalisation?

|

X

Z

‚â§

= R

i‚àí1 < j

√ó
5, 10)
|

n) in the i-th segment (i.e., œÑ ‚àó

We evaluated different inference algorithms on synthetic
= R. The synthetic data were
1:m‚àó ,

and real-world data for
generated as follows: we Ô¨Åxed parameters (n, m‚àó, ¬µ‚àó
œÉ‚àó
1:m‚àó , œÑ ‚àó
0:m‚àó ), and then sampled each data point xj (1
‚â§
œÑ ‚àó
i ) in-
j
‚â§
dependently from a Gaussian distribution with mean ¬µ‚àó
i
and standard deviation œÉ‚àó
i . The changepoint model for
R+,
analysing the synthetic data is: m = m‚àó,
w1:n = (1, . . . , 1), P (zi = (¬µi, œÉi)) = Normal(¬µi
√ó
0, 2), and P (xj
LogNormal(œÉi
x1:j‚àí1, zi = (¬µi, œÉi)) =
|
Normal(xj
¬µi, œÉi). For the real-world application, we used
|
well-log data (Fearnhead 2006), whose data points repre-
sent some physical quantity measured by a probe diving in
a wellbore. We took a part of the well-log data by remov-
ing outliers and choosing 1000 consecutive data points (Fig-
ure 3b). The changepoint model for the well-log data is the
same as the above except: m = 13 and P (zi = (¬µi, œÉi)) =
Normal(¬µi

√ó
Our goal is to infer the posterior distribution of latent
parameters z1:m and changepoints œÑ0:m. For this task, we
compared four posterior-inference algorithms: HMCnaive,
HMCours, IPMCMC, and LMH. HMCnaive (resp. HMCours)
generates samples as follows: it forms a probabilistic model
w1:n) where œÑ0:m are marginalised out by
P (x1:n, z1:m
a naive marginalisation scheme (resp. by our marginali-

120000, 20000)
|

8.5, 0.5).
|

LogNormal(œÉi

|

(a) Synthetic data.

(b) Part of well-log data.

Figure 3: Synthetic and real-world data for RQ2. The x-axis
represents time steps.

|

|

sation algorithm); samples z1:m from P (z1:m
w1:n, x1,n)
|
w1:n); Ô¨Ånally samples
by running HMC on P (x1:n, z1:m
w1:n, x1:n, z1:m) using dynamic pro-
œÑ0:m from P (œÑ0:m
gramming. IPMCMC and LMH jointly sample z1:m and
œÑ0:m from P (z1:m, œÑ0:m
w1:n, x1:n) by running the vari-
ants of the Metropolis-Hastings algorithm called interact-
ing particle MCMC (IPMCMC) (Rainforth et al. 2016)
(Wingate,
and lightweight Metropolis-Hastings (LMH)
Stuhlm¬®uller, and Goodman 2011), respectively. IPMCMC
and LMH are applicable to models with discrete or non-
differentiable random variables. They neither exploit gradi-
ents nor marginalise out any random variables.

|

For HMCnaive and HMCours, we used the No-U-Turn
Sampler (NUTS) (Hoffman and Gelman 2014) in PyStan
(Carpenter et al. 2017) with default hyper-parameters, ex-
cept for adapt delta = 0.95. For IPMCMC and LMH, we
used the implementations in Anglican (Wood, van de Meent,
and Mansinghka 2014; Tolpin et al. 2016) with default
hyper-parameters, except for the following IPMCMC setup:
number-of-nodes = 8 for both the synthetic and well-log
data, and pool = 8 for the well-log data.

For RQ1, we compared the time taken to generate a single
posterior sample by HMCnaive and HMCours. For RQ2, we
compared the quality of posterior samples from HMCours,
IPMCMC, and LMH, by means of the following quanti-
ties: estimates of the Ô¨Årst and second moments, the Gelman-
Rubin convergence statistic (
R) (Gelman, Rubin, and others
1992; Brooks and Gelman 1998), and effective sample size
(ESS). The experiments were performed on a Ubuntu 16.04
(cid:98)
machine with Intel i7-7700 CPU with 16GB of memory.

Results for RQ1. We measured the average time per sam-
ple taken by HMCnaive and HMCours for different numbers
of changepoints and time steps: for Ô¨Åxed n = 50, we varied
m‚àó = m from 1 to 5, and for Ô¨Åxed m‚àó = m = 2, we var-
. The details of the parameter
ied n
}
values we used appear in the Appendix. We ran Ô¨Åve inde-
pendent runs of the NUTS algorithm, and averaged the time
spent without burn-in samples.

200, 400, 600, 800

‚àà {

Figures 2a and 2b show how the time depends on m and
n, respectively, in the two approaches. In the log-log plots,
log(time) of HMCours is linear in both log m and log n, due

5.0E-52.0E-38.0E-23.2E+0124Sec / sampleNumber of changepointsHMC-naiveHMC-ours8.0E-41.6E-23.2E-16.4E+0200400800Sec / sampleNumber of time stepsHMC-naiveHMC-ours-5515050100150200250300Data1.0E+51.2E+51.4E+502004006008001000DataTable 1: The ranges of the time (sec) taken by the three ap-
proaches and the ranges of the estimates computed by them,
for synthetic data. For the estimated sum of the Ô¨Årst/second
moments (i.e., the third/fourth row), we computed the val-
ues at 510.8 sec (the minimum time taken among all the
runs) from each Markov chain, assuming that generating
each sample (in a chain) took an equal amount of time.

Time
1st

2nd

HMCours
[510.8, 1043.9]
[746.9, 794.2]
[1.28E+05,
1.39E+05]

IPMCMC
[1053.2, 1170.6]
[651.3, 993.8]
[1.12E+05,
1.89E+05]

LMH
[1092.2, 1105.2]
[415.4, 1164.0]
[3.56E+04,
2.62E+05]

tained similar results for the sum of the second moments
(see the Appendix). Table 1 shows the ranges of the time
taken by the Markov chains in Figure 6, and the ranges of
the estimates from the chains.

Figure 4: Convergence plots for estimating the sum of
the Ô¨Årst moments for synthetic data, with HMCours (red),
IPMCMC (blue), and LMH (green). Each x-axis represents
the number of samples generated by the corresponding pro-
cedure, and the y-axis denotes estimated values. Each darker
line shows the mean value at each point, and the correspond-
ing error band around it shows the standard deviation.

O

to its time complexity
(mn). On the other hand, log(time)
of HMCnaive is exponential in log m, and linear in log n yet
with a slope nearly two times larger than that for HMCours,
(nm). Overall, the results
because of its time complexity
show that HMCnaive quickly becomes infeasible as the num-
ber of changepoints or time steps grows, but HMCours avoids
such an upsurge by virtue of having the linear relationship
between the two varying factors and the time per sample.

O

Results for RQ2. Figure 3 shows the synthetic and real-
world data used in answering RQ2. The synthetic data was
generated with parameters n = 300, m‚àó = 6, ¬µ‚àó
1:m‚àó = (10,
2, 10, 2, 10, 2), œÉ‚àó
1:m‚àó = (1.8, 1.1, 1.7, 1.5, 1.2, 1.3), and
œÑ ‚àó
0:m‚àó = (0, 50, 100, 150, 200, 250, 300).
For each chain of HMCours, we generated 30K samples
with random initialisation (when possible) after burning in
R and ESS for each latent pa-
1K samples. We computed
rameter and changepoint using three chains, and repeated
this Ô¨Åve times as the
R and ESS results varied across dif-
(cid:98)
ferent runs. We also estimated the sum of the Ô¨Årst moments
of (z1:m, œÑ1:m‚àí1) and that of the second moments of them
using the same 15 chains.2 The same setup was applied to
IPMCMC and LMH except the following: since they sam-
ple faster than HMCours, we let IPMCMC and LMH gener-
ate 270K (resp. 1855K) and 200K (resp. 1750K) samples,
respectively, for synthetic data (resp. well-log data) so that
every run of them spends more time than the corresponding
slowest HMCours run.

(cid:98)

We Ô¨Årst discuss results on synthetic data. Figure 4 shows
the estimates for the sum of the Ô¨Årst moments by HMCours,
IPMCMC, and LMH. HMCours shows a gradual trend to-
wards convergence, while IPMCMC and LMH exhibit sub-
stantial variation across runs without convergence. We ob-

2Concretely, we estimated EP (z1:m,œÑ1:m | x1:n)

œÉi +œÑi

(cid:1)‚àín(cid:3) and EP (z1:m,œÑ1:m | x1:n)

(cid:2)(cid:0) (cid:80)m

i=1 ¬µ2

i +œÉ2

(cid:2)(cid:0) (cid:80)m
i=1 ¬µi +
(cid:1)‚àín2(cid:3).
i +œÑ 2
i

(cid:98)

Figure 5a shows the

R values from HMCours, IPMCMC,
and LMH. Three out of Ô¨Åve experiments with HMCours were
R statistics for all the la-
satisfactory in the sense that the
tent (z1:m, œÑ1:m‚àí1) were between 0.9 and 1.1. Though the
R
statistics for some of the latent were over 1.1 in the other two
experiments, most of the
R values were less than or close
(cid:98)
to 1.1. On the other hand, none of the IPMCMC and LMH
experiments placed
R values for all the latent, within the in-
(cid:98)
terval. Also the values were farther from the interval.

(cid:98)

(cid:98)

Figure 5b shows ln(ESS) from HMCours, IPMCMC, and
LMH in a similar manner. HMCours produced signiÔ¨Åcantly
higher ESS values than LMH, demonstrating that HMCours
draws samples more effectively than LMH within a Ô¨Åxed
amount of time. However, HMCours was not superior in ESS
to IPMCMC despite the excellence in
R. We conjecture that
this is due to IPMCMC running eight parallel nodes inde-
pendently, each with two particles to propose samples.

(cid:98)

R, and ESS;

For well-log data, HMCours similarly outperformed the
R for all the
other two in terms of convergence,
latent (z1:m, œÑ1:m‚àí1) were between 0.9 and 1.1 in all Ô¨Åve
experiments. One exception is that IPMCMC showed much
higher ESS than HMCours, although it failed to converge
(Figure 6). We think that this is again due to IPMCMC‚Äôs
tendency of generating independent samples. The full results
are in the Appendix.

(cid:98)

(cid:98)

We remark that HMCours performed poorly on well-log
data with the same model but smaller m (e.g., 6 instead
of 13). According to our manual inspection, this was be-
cause HMCours in this case got stuck at some modes, fail-
ing to generate samples from other modes. We think that in-
creasing m (up to some point) lessens the barriers between
modes in the marginal space; for large enough m, only a
small amount of P (z1:m
x1:n, w1:n) should be reduced to
change some of z1:m. One practical lesson is that having
enough changepoints may help analyse real-world data us-
ing Bayesian inference and changepoint models.

|

0600012000180002400030000Numberofsamples(HMCours)6008001000Estimation050000100000150000200000250000Numberofsamples(IPMCMC)04000080000120000160000200000Numberofsamples(LMH)(a) (cid:98)R.

(b) ln(ESS).

Figure 5:
The x-axis denotes the latent parameters and changepoints, and the y-axis

R and ESS from HMCours (red), IPMCMC (blue), and LMH (green) for synthetic data.
R or ln(ESS) values.

(cid:98)

(cid:98)

1998), whose properties, such as sensitivity on chosen pa-
rameters, is analysed by Bauwens and Rombouts (2012).
The technique is based on Gibbs sampling, and it is unclear
whether the technique leads to a differentiable algorithmic
component that can be used in the context of gradient-based
algorithms.

The observation that the summation version of dynamic
programming is differentiable is a folklore. For instance,
Eisner (2016) points out the differentiability of the inside
algorithm, which is a classic dynamic-programming-based
algorithm in natural language processing (NLP). He then ex-
plains how to derive several well-known NLP algorithms by
differentiating the inside algorithm or its variants. However,
we do not know of existing work that uses such dynamic pro-
gramming algorithms for the type of application we consider
in the paper: converting non-differentiable models to differ-
entiable models via marginalisation in the context of poste-
rior inference and model learning. The optimisation version
of dynamic programming is not differentiable, and its dif-
ferentiable relaxation has been studied recently (Corro and
Titov 2019; Mensch and Blondel 2018).

O

Conclusion. We presented a differentiable
(mn)-time al-
gorithm for marginalising changepoints in time-series mod-
els, where m is the number of changepoints and n the num-
ber of time steps. The algorithm can be used to convert a
class of non-differentiable time-series models to differen-
tiable ones, so that the resulting models can be analysed by
gradient-based techniques. We described two applications of
this conversion, posterior inference with HMC and model-
parameter learning with reparameterisation gradient estima-
tor, and experimentally showed the beneÔ¨Åts of using the al-
gorithm in the former posterior-inference application.

Acknowledgements. The authors were supported by the En-
gineering Research Center Program through the National
Research Foundation of Korea (NRF) funded by the Ko-
rean Government MSIT (NRF-2018R1A5A1059921), and

Figure 6: Convergence plots for estimating the sum of the
Ô¨Årst moments for well-log data. See the caption of Figure 4
for details.

5 Related Work and Conclusion

Related work. Modelling and reasoning about time-series
data with changepoints is a well-established topic in statis-
tics and machine learning (Eckley, Fearnhead, and Killick
2011; Truong, Oudre, and Vayatis 2018). We discuss two
lines of research most relevant to ours. The Ô¨Årst is the
work by Fearnhead and his colleagues (Fearnhead 2006;
Fearnhead 2005; Fearnhead and Liu 2007), which is fur-
ther extended to multi-dimensional time-series data (Xuan
(n2)-time algorithm
2007). Fearnhead (2006) proposed an
for generating changepoint positions from the posterior of
a given changepoint model in a particular form, where n
is the number of time steps. Their algorithm also uses a
form of dynamic programming on certain recursive formu-
las, but it does not target at marginalisation. Its conversion
(n2) time
for marginalisation is possible, but inherits this
complexity. The other work is Chib (1995)‚Äôs technique for
estimating the model evidence of changepoint models (Chib

O

O

¬µ1¬µ2¬µ3¬µ4¬µ5¬µ6œÉ1œÉ2œÉ3œÉ4œÉ5œÉ6œÑ1œÑ2œÑ3œÑ4œÑ5123bRHMCoursIPMCMCLMH¬µ1¬µ2¬µ3¬µ4¬µ5¬µ6œÉ1œÉ2œÉ3œÉ4œÉ5œÉ6œÑ1œÑ2œÑ3œÑ4œÑ5510ln(ESS)HMCoursIPMCMCLMH0600012000180002400030000Numberofsamples(HMCours)16500001700000Estimation040000080000012000001600000Numberofsamples(IPMCMC)040000080000012000001600000Numberofsamples(LMH)also by Next-Generation Information Computing Develop-
ment Program through the National Research Foundation
of Korea (NRF) funded by the Ministry of Science, ICT
(2017M3C4A7068177).

References
[Abadi et al. 2016] Abadi, M.; Barham, P.; Chen, J.; Chen,
Z.; Davis, A.; Dean, J.; Devin, M.; Ghemawat, S.; Irving,
G.; Isard, M.; Kudlur, M.; Levenberg, J.; Monga, R.; Moore,
S.; Murray, D. G.; Steiner, B.; Tucker, P. A.; Vasudevan, V.;
Warden, P.; Wicke, M.; Yu, Y.; and Zheng, X. 2016. Tensor-
Ô¨Çow: A system for large-scale machine learning. In OSDI,
265‚Äì283.
[Bauwens and Rombouts 2012] Bauwens, L., and Rom-
bouts, J. V. 2012. On marginal likelihood computation
in change-point models. Computational Statistics & Data
Analysis 56(11):3415‚Äì3429.
[Brooks and Gelman 1998] Brooks, S. P., and Gelman, A.
1998. General methods for monitoring convergence of it-
erative simulations. J. Comput. Graph. Stat. 7(4):434‚Äì455.
[Carpenter et al. 2017] Carpenter, B.; Gelman, A.; Hoffman,
M. D.; Lee, D.; Goodrich, B.; Betancourt, M.; Brubaker, M.;
Guo, J.; Li, P.; and Riddell, A. 2017. Stan: A probabilis-
tic programming language. Journal of Statistical Software
76(1).
[Chib 1995] Chib, S. 1995. Marginal likelihood from the
gibbs output. J. Am. Stat. Assoc. 90(432):1313‚Äì1321.
[Chib 1998] Chib, S. 1998. Estimation and comparison of
multiple change-point models. J. Econometrics. 86(2):221‚Äì
241.
[Corro and Titov 2019] Corro, C., and Titov, I. 2019. Differ-
entiable perturb-and-parse: Semi-supervised parsing with a
structured variational autoencoder. In ICLR.
[Duane et al. 1987] Duane, S.; Kennedy, A. D.; Pendleton,
B. J.; and Roweth, D. 1987. Hybrid Monte Carlo. Physics
Letters B 195:216‚Äì222.
[Eckley, Fearnhead, and Killick 2011] Eckley, I. A.; Fearn-
head, P.; and Killick, R. 2011. Analysis of changepoint
models. In Barber, D.; Cemgil, A. T.; and Chiappa, S., eds.,
Bayesian Time Series Models. Cambridge University Press.
chapter 10, 205‚Äì224.
[Eisner 2016] Eisner, J. 2016. Inside-outside and forward-
backward algorithms are just backprop (tutorial paper). In
Workshop on Structured Prediction for NLP@EMNLP, 1‚Äì
17.
[Erdman and Emerson 2008] Erdman, C., and Emerson,
J. W.
2008. A fast bayesian change point analysis
for the segmentation of microarray data. Bioinformatics
24(19):2143‚Äì2148.
[Fearnhead and Liu 2007] Fearnhead, P., and Liu, Z. 2007.
On-line inference for multiple changepoint problems. Jour-
nal of the Royal Statistical Society: Series B (Statistical
Methodology) 69(4):589‚Äì605.
[Fearnhead 2005] Fearnhead, P. 2005. Exact bayesian curve
Ô¨Åtting and signal segmentation. IEEE Transactions on Sig-
nal Processing 53(6):2160‚Äì2166.

A.;

2006.

[Fearnhead 2006] Fearnhead, P.
Exact and efÔ¨Å-
cient bayesian inference for multiple changepoint problems.
Statistics and Computing 16(2):203‚Äì213.
[Gelman, Rubin, and others 1992] Gelman,
Rubin,
D. B.; et al. 1992. Inference from iterative simulation using
multiple sequences. Statistical Science 7(4):457‚Äì472.
[Haynes, Eckley, and Fearnhead 2017] Haynes, K.; Eckley,
I. A.; and Fearnhead, P. 2017. Computationally efÔ¨Åcient
changepoint detection for a range of penalties. J. Comput.
Graph. Stat. 26(1):134‚Äì143.
[Hoffman and Gelman 2014] Hoffman, M. D., and Gelman,
A. 2014. The no-u-turn sampler: adaptively setting path
JMLR 15(1):1593‚Äì
lengths in hamiltonian monte carlo.
1623.
[Kingma and Welling 2014] Kingma, D. P., and Welling, M.
2014. Auto-Encoding Variational Bayes. In ICLR.
[Kucukelbir et al. 2017] Kucukelbir, A.; Tran, D.; Ran-
ganath, R.; Gelman, A.; and Blei, D. M. 2017. Automatic
differentiation variational inference. JMLR 18(1):430‚Äì474.
[Lio and Vannucci 2000] Lio, P., and Vannucci, M. 2000.
Wavelet change-point prediction of transmembrane proteins.
Bioinformatics 16(4):376‚Äì382.
[Lung-Yut-Fong, L¬¥evy-Leduc, and Capp¬¥e 2012] Lung-
Yut-Fong, A.; L¬¥evy-Leduc, C.; and Capp¬¥e, O.
2012.
Distributed detection/localization of change-points in high-
dimensional network trafÔ¨Åc data. Statistics and Computing
22(2):485‚Äì496.
[Mensch and Blondel 2018] Mensch, A., and Blondel, M.
2018. Differentiable dynamic programming for structured
prediction and attention. In ICML, 3459‚Äì3468.
[Neal 2011] Neal, R. M.
2011. MCMC using Hamilto-
nian dynamics. Handbook of Markov Chain Monte Carlo
2(11):2.
[Paszke et al. 2017] Paszke, A.; Gross, S.; Chintala, S.;
Chanan, G.; Yang, E.; DeVito, Z.; Lin, Z.; Desmaison, A.;
Antiga, L.; and Lerer, A. 2017. Automatic differentiation in
PyTorch. In NIPS Autodiff Workshop.
[Rainforth et al. 2016] Rainforth, T.; Naesseth, C.; Lindsten,
F.; Paige, B.; Vandemeent, J.-W.; Doucet, A.; and Wood, F.
2016.
In
ICML, 2616‚Äì2625.
[Reeves et al. 2007] Reeves, J.; Chen, J.; Wang, X. L.; Lund,
R.; and Lu, Q. Q. 2007. A review and comparison of change-
point detection techniques for climate data. Journal of Ap-
plied Meteorology and Climatology 46(6):900‚Äì915.
[Rezende, Mohamed, and Wierstra 2014] Rezende, D.
J.;
Mohamed, S.; and Wierstra, D. 2014. Stochastic Back-
propagation and Approximate Inference in Deep Generative
Models. In ICML, 1278‚Äì1286.
[Spokoiny and others 2009] Spokoiny, V., et al. 2009. Multi-
scale local change point detection with applications to value-
at-risk. The Annals of Statistics 37(3):1405‚Äì1436.
[Stan Development Team 2018] Stan Development Team.
2018. Stan Modeling Language Users Guide and Reference
Manual. Version 2.18.0.

Interacting particle markov chain monte carlo.

[Tolpin et al. 2016] Tolpin, D.; van de Meent, J.-W.; Yang,
H.; and Wood, F. 2016. Design and implementation of prob-
abilistic programming language anglican. In IFL, 6:1‚Äì6:12.
[Truong, Oudre, and Vayatis 2018] Truong, C.; Oudre, L.;
and Vayatis, N. 2018. Selective review of ofÔ¨Çine change
point detection methods. ArXiv abs/1801.00718.
[Wingate, Stuhlm¬®uller, and Goodman 2011] Wingate,
D.;
Stuhlm¬®uller, A.; and Goodman, N.
2011. Lightweight
implementations of probabilistic programming languages
via transformational compilation. In AISTATS.
F.;
[Wood, van de Meent, and Mansinghka 2014] Wood,
van de Meent, J. W.; and Mansinghka, V. 2014. A new
approach to probabilistic programming inference.
In
AISTATS, 1024‚Äì1032.
[Xuan 2007] Xuan, X. 2007. Bayesian inference on change
point problems. Master‚Äôs thesis, The University of British
Columbia, Vancouver, Canada.

A Appendix

A.1 Proof of Proposition 6
Proposition 6. For all k, t with 1
‚â§
we have Sk,t = Sk,t‚àí1 + Sk‚àí1,t‚àí1 √ó
Proof. We focus on the Ô¨Årst equality.

k < m and k

t < n,

wt and Sk,k‚àí1 = 0.

‚â§

Sk,t =

k

wœÑi +

k

wœÑi

(a) Synthetic data.

œÑ0:k, œÑk<t
(cid:88)

i=1
(cid:89)
k

=

œÑ0:k, œÑk<t
i=1
(cid:89)
(cid:88)
= Sk,t‚àí1 + wt

œÑ0:k, œÑk=t
(cid:88)

i=1
(cid:89)

wœÑi + wt

√ó

Sk‚àí1,t‚àí1 .

√ó

œÑ0:k‚àí1, œÑk‚àí1<t
(cid:88)

wœÑi

k‚àí1

i=1
(cid:89)

A.2 Setup for data generation for RQ1 (
¬ß
See Table 2.

4)

A.3 Full results for RQ2 (
4)
¬ß
See Figures 7 and 8.

(b) Well-log data.

Figure 7: Convergence plots for estimating the sum of the
second moments. See the caption of Figure 4 for details.

0600012000180002400030000Numberofsamples(HMCours)100000150000200000Estimation050000100000150000200000250000Numberofsamples(IPMCMC)04000080000120000160000200000Numberofsamples(LMH)0600012000180002400030000Numberofsamples(HMCours)1.71.81.9Estimation√ó1011040000080000012000001600000Numberofsamples(IPMCMC)040000080000012000001600000Numberofsamples(LMH)Table 2: Parameter values used in data generation for RQ1.

n m‚àó
1
50
2
50
3
50
4
50
5
50
2
200
2
400
2
600
2
800

Varying m‚àó

Varying n

¬µ‚àó

1:m‚àó

(9.0, 2.0)
(9.0, 2.0, 9.0)
(9.0, 2.0, 9.0, 2.0)
(9.0, 2.0, 9.0, 2.0, 9.0)
(9.0, 2.0, 9.0, 2.0, 9.0, 2.0)
(8.8, 2.0, 7.3)
(8.8, 2.0, 7.3)
(8.8, 2.0, 7.3)
(8.8, 2.0, 7.3)

œÉ‚àó
1:m‚àó

(1.5, 1.5)
(1.5, 1.5, 1.5)
(1.5, 1.5, 1.5, 1.5)
(1.5, 1.5, 1.5, 1.5, 1.5)
(1.5, 1.5, 1.5, 1.5, 1.5, 1.5)
(1.8, 1.1, 1.7)
(1.8, 1.1, 1.7)
(1.8, 1.1, 1.7)
(1.8, 1.1, 1.7)

œÑ ‚àó
0:m‚àó

(0, 8, 50)
(0, 8, 16, 50)
(0, 8, 16, 24, 50)
(0, 8, 16, 24, 32, 50)
(0, 8, 16, 24, 32, 40, 50)
(0, 27, 80, 200)
(0, 27, 80, 400)
(0, 27, 80, 600)
(0, 27, 80, 800)

(a) (cid:98)R.

(b) ln(ESS).

Figure 8:
The x-axis denotes the latent parameters and changepoints, and the y-axis

R and ESS from HMCours (red), IPMCMC (blue), and LMH (green) for well-log data.
R or ln(ESS) values.

(cid:98)

(cid:98)

¬µ1¬µ2¬µ3¬µ4¬µ5¬µ6¬µ7¬µ8¬µ9¬µ10¬µ11¬µ12¬µ13œÉ1œÉ2œÉ3œÉ4œÉ5œÉ6œÉ7œÉ8œÉ9œÉ10œÉ11œÉ12œÉ13œÑ1œÑ2œÑ3œÑ4œÑ5œÑ6œÑ7œÑ8œÑ9œÑ10œÑ11œÑ1212bRHMCoursIPMCMCLMH¬µ1¬µ2¬µ3¬µ4¬µ5¬µ6¬µ7¬µ8¬µ9¬µ10¬µ11¬µ12¬µ13œÉ1œÉ2œÉ3œÉ4œÉ5œÉ6œÉ7œÉ8œÉ9œÉ10œÉ11œÉ12œÉ13œÑ1œÑ2œÑ3œÑ4œÑ5œÑ6œÑ7œÑ8œÑ9œÑ10œÑ11œÑ1251015ln(ESS)HMCoursIPMCMCLMH