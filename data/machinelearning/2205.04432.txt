Static Analysis for AWS Best Practices in Python
Code

Rajdeep Mukherjee !
Amazon Web Services

Omer Tripp !
Amazon Web Services

Ben Liblit !
Amazon Web Services

Michael Wilson !
Amazon Web Services

Abstract

2
2
0
2

y
a
M
9

]
L
P
.
s
c
[

1
v
2
3
4
4
0
.
5
0
2
2
:
v
i
X
r
a

Amazon Web Services (AWS) is a comprehensive and broadly adopted cloud provider, oﬀering
over 200 fully featured services, including compute, database, storage, networking and content
delivery, machine learning, Internet of Things and many others. AWS SDKs provide access to AWS
services through API endpoints. However, incorrect use of these APIs can lead to code defects,
crashes, performance issues, and other problems. AWS best practices are a set of guidelines for
correct and secure use of these APIs to access cloud services, allowing conformant clients to fully
reap the beneﬁts of cloud computing.

This paper presents automated static analysis rules, developed in the context of a commercial
service for detection of code defects and security vulnerabilities, to identify deviations from AWS
best practices in Python applications that use the AWS SDK. Such applications use the AWS SDK
for Python, called “Boto3”, to access AWS cloud services. However, precise static analysis of Python
applications that use cloud SDKs requires robust type inference for inferring the types of cloud
service clients. The dynamic style of Boto3 APIs poses unique challenges for type resolution, as does
the interprocedural style in which service clients are used in practice. In support of our best-practices
goal, we present a layered strategy for type inference that combines multiple type-resolution and
tracking strategies in a staged manner: (i) general-purpose type inference augmented by type
annotations, (ii) interprocedural dataﬂow analysis expressed in a domain-speciﬁc language, and (iii)
name-based resolution as a low-conﬁdence fallback. From our experiments across >3,000 popular
Python GitHub repos that make use of the AWS SDK, our layered type inference system achieves
85% precision and 100% recall in inferring Boto3 clients in Python client code.

Additionally, we present a representative sample of eight AWS best-practice rules that detect
a wide range of issues including pagination, polling, and batch operations. We have assessed the
eﬃcacy of these rules based on real-world developer feedback. Developers have accepted more
than 85% of the recommendations made by ﬁve out of eight Python rules, and almost 83% of all
recommendations.

2012 ACM Subject Classiﬁcation Theory of Computation, Program Analysis

Keywords and phrases Python, Type Inference, AWS, Cloud, Best practices, Static Analysis

Digital Object Identiﬁer 10.4230/LIPIcs...

1

Introduction

Python is a widely used language due to its simpliﬁed syntax and vast ecosystem of libraries
and frameworks, which save programmers time and eﬀort. Python is the language of choice
for many developers in a wide range of application domains, in particular in the cloud
setting, including Internet-of-Things (IoT), analytics, streaming, machine learning (ML),
image processing, serverless applications, and many more. Amazon Web Services (AWS) is

© Rajdeep Mukherjee, Omer Tripp, Ben Liblit, and Michael Wilson;
licensed under Creative Commons License CC-BY 4.0
Leibniz International Proceedings in Informatics
Schloss Dagstuhl – Leibniz-Zentrum für Informatik, Dagstuhl Publishing, Germany

 
 
 
 
 
 
XX:2

Static Analysis for AWS Best Practices in Python Code

GitHub

BitBucket

programs

type inference

programs annotated
with Boto3 client types

static analyzers

bugs found

no bugs found

type annotation from Boto3
type stubs combined with
Pyright’s type inference

interprocedural dataﬂow
analysis expressed in a
custom query language

Figure 1 High-level overview of CodeGuru

a comprehensive and broadly adopted cloud provider. Python is used extensively to build
applications on top of the AWS cloud. This is done through the AWS SDK for Python,
called Boto3, which mediates the interaction between Python applications and AWS services.
Cloud SDKs enable access to rich functionality, spanning hundreds of services and
thousands (if not more) of API endpoints, but at the same time, the API contains subtleties
and complexities that might lead to unexpected errors or performance issues. AWS best
practices are a set of guidelines that specify correct and secure usage of the AWS cloud SDK.
It is imperative that applications follow AWS best practices to embrace the many beneﬁts
that the cloud oﬀers.

We report here on our experience in developing automated static analysis rules to enforce
AWS best practices in Python applications. These rules are evaluated as part of a commercial
cloud service, Amazon CodeGuru Reviewer (henceforth, CodeGuru), 1 that runs static
analysis on customer code to detect security vulnerabilities, optimization opportunities, and
various other types of defects. The CodeGuru architecture is shown in Figure 1.

CodeGuru supports Java and Python, and integrates with diﬀerent code hosting platforms

including GitHub and BitBucket. CodeGuru supports three code scanning modes:

Incremental: A code review is created automatically when a pull request is raised.
Full: The entire codebase is analyzed.
CI/CD: The entire codebase is analyzed as part of CI/CD workﬂows.

1.1

Importance of AWS Best Practices Rules

In this section, we draw closely on real-world scenarios that were experienced by CodeGuru
customers. For conﬁdentiality reasons, our description is of hypothetical scenarios, though
these are inspired and motivated by real-world events. We emphasize that all of these cases
can be detected, and prevented, by applying static analysis to clients of the AWS SDK.
Further, these scenarios are within the scope of the AWS best practices rules that we have
developed, which alert the user to such risks already during code review.

We focus on large-scale operational failures. Previously, such failures would have to
be discovered by manual inspection or testing. Such failures could result in critical issues

1 https://docs.aws.amazon.com/codeguru/latest/reviewer-ug/welcome.html

R. Mukherjee, O. Tripp, B. Liblit, and M. Wilson

XX:3

such as race conditions leading to service outage or auto-ticketing errors; authorization
and authentication errors; broken throttling mechanisms that impose unexpected loads on
services, thereby leading to high latency or timeouts; missing or incorrect error handling, the
impact being billing errors; and many other high-severity situations.

Speciﬁcally:

A service that uses a paginated API that can retrieve a maximum of 1 MB of data or
1000 stream records, whichever comes ﬁrst. The best practice for using paginated APIs
is to check for additional results from the paginated API by iterating over the response
object until no further pages can be retrieved. The service in question did not check for
additional results from the paginated API, which eventually resulted in its availability
rate dropping, and the service returning non-descriptive 5xx server errors to customers.
A service used to ingest, buﬀer, and process streaming data in real-time utilizes the
PutRecords operation to send data into the stream for ingestion and processing. Each
PutRecords request can support up to 500 records. The response includes an array of
Records, including both successfully and unsuccessfully processed records. A single record
failure does not block the processing of subsequent records. The service in question did
not check for failed records and erroneously treated all records as processed successfully,
which resulted in data loss. The best practice in this case is to check the error code
and message on the returned Records, and re-attempt processing of failed records in a
subsequent request.
A fully managed messaging service for application-to-application communication provides
topics for high-throughput, push-based, many-to-many messaging between distributed
systems, microservices, and event-driven serverless applications. Consider an application
utilizing this distributed messaging service that creates resources then immediately
publishes to them. Due to the distributed nature of the service, information might take
some time to propagate, thus causing some of the published messages to be dropped.
The best practice is to sequence topic creation/subscription and message publishing to
mitigate such failures.

To give an idea of CodeGuru’s throughput in a given week, we provide lower-bound metrics.
On average, CodeGuru analyzes (cid:29) 10, 000 Pull Requests (PRs) containing (cid:29) 1, 000, 000 lines
of code across (cid:29) 100, 000 ﬁles, and provides (cid:29) 1, 000 AWS best practices recommendations
due to (cid:29) 100 diﬀerent static analysis detectors.

1.2 Scope

Though CodeGuru supports AWS best practices also for Java, we focus on Python in
particular given its dynamic nature and lack of static type annotations. To enforce AWS best
practices with high precision, it is essential to identify whether a given function call is made
against the AWS SDK, and if so, which service in particular is invoked. Unlike Java, where
such information is provided through the type system, in Python this information is not
available by default, which is the starting point for the research we report on in this paper.
We share details and results on several on-demand type resolution approaches, as well as

combinations thereof. We have experimented with the following core approaches:

Type inference augmented with Boto3 type stubs: Boto3 type stubs, in combination with
general purpose type inference, to resolve types when processing the Python AST.
Dataﬂow tracking : On-demand interprocedural tracking, in both the forward and the
backward directions, to check whether the receiver of a function call corresponds to a
given AWS service.

XX:4

Static Analysis for AWS Best Practices in Python Code

API name based resolution: An over-approximate yet lightweight strategy that simply checks
whether the called function’s name is compatible with a given AWS service’s API.
We present not only the approaches themselves, and more advanced algorithms that combine
these approaches, but also the underlying infrastructure that enabled us to implement these
approaches. Speciﬁcally, we provide technical details on the CodeGuru code representation
and language for rule speciﬁcation.

1.3 Main Contributions

To summarize, this paper makes the following principal contributions:

1. Our main contribution is an on-demand type resolution strategy, which we demonstrate

as eﬀective in the case of Python clients of the AWS SDK.

2. In support of the above-mentioned strategy, we present the Intermediate Representation

(IR) and query language used by the CodeGuru service.

3. We describe a representative sample of the AWS best practices rule suite running as part

of the CodeGuru service.

4. We share the details of the experiments we ran on 86,000 GitHub repositories, and
real-world feedback we received from developers, to validate our type resolution strategy
and the rules we built on top of it.

1.4 Paper Structure

The rest of the paper is organized as follows. Section 2 sets the stage for our contributions
in discussing related work. In Section 3, we establish the context for the speciﬁc problem
that this paper addresses. We explain the design of the Boto3 library, and the information
it provides on AWS services through type annotations and API models. Building on this
background, we present in Section 4 several code examples that motivate the need for
advanced type inference, which is our main contribution in this paper. Sections 5 and 6
lay down the technical infrastructure for our approach in describing, respectively, the code
representation and query language that we use to express Python AWS best practices
rules, and as part of these rules, also the data-ﬂow tracking mechanisms for improved type
inference. Section 7 connects between earlier sections in describing the diﬀerent capabilities
that we have developed, based both on Boto3 type stubs and data-ﬂow tracking, to resolve
types in a wide range of scenarios. We then present a layered approach that integrates
between the diﬀerent type resolution strategies. With the supporting infrastructure and
inference algorithm explained, we present in Section 8 eight representative Python AWS best
practices rules. Section 9 is dedicated to our research hypotheses and experiments to validate
the eﬃcacy of our type inference algorithm. We conclude, and outline future research, in
Section 10.

2

Related Work

Diﬀerent approaches have been taken to infer Python type annotations, and formalize Python
semantics more generally. We review approaches based on program analysis as well as
machine learning, and compare these approaches with CodeGuru.

R. Mukherjee, O. Tripp, B. Liblit, and M. Wilson

XX:5

2.1 Classical Program Analysis

Widely used Python type checkers include mypy [18], Pyre [9], pytype [13], and Pyright [19].
These tools rely on manual type annotations provided by developers, augmented with
varying forms of type inference. However, retroﬁtting type annotations onto large libraries or
applications can be tedious and error-prone. Other prior work places more emphasis on static
analysis [4, 10, 11, 15, 20, 24] or dynamic analysis [26] to reduce reliance on human-authored
annotations. Our initial search for supporting infrastructure found that many published tools
have failed to keep up with recent Python releases, or omit support for key Python features
such as exceptions [10] or recursion [20]. We opted to use Pyright as our baseline, as Pyright
is both actively maintained and has a rather advanced inference engine (see Section 7.1).
In spite of these advantages, Pyright alone proved unsatisfactory for our cloud application
domain. The details, as conveyed in Section 9, may serve to highlight challenges for other
developers of general-purpose type inference engines.

When writing type annotations, Python developers often focus on function signatures:
arguments and return values. Some research tools mirror this bias, such as TypeWriter [22].
Xu et al. [28] present a probabilistic type inference system, but the accuracy of probabilistically
inferred types for Python variables is limited. Our work requires accurate types for variables,
making these two approaches unsuitable.

Any attempt to statically analyze Python code must contend with the intricacies of the
Python language. Notable eﬀorts to formalize Python semantics include those by Smeding [25],
Politz et al. [21] and Köhl [17]. Smeding’s work predates Python type annotations, while
neither Politz et al. nor Köhl mention them in any way. These omissions are not surprising,
as type annotations have only limited eﬀects on runtime behavior. Thus, these codiﬁcations
of Python semantics oﬀer little insight regarding the type-inference challenges addressed here.
Our approach is neither sound nor complete (see Section 5.4), so a standard type-soundness
theorem relating static types to runtime semantics does not apply.

In the specialized domain of machine learning, where Python is perhaps the most popular
language, WALA Ariadne [7] analyzes Python speciﬁcally to infer the dimensions and types
of tensors. Like Ariadne, our work is motivated by a speciﬁc application domain, and even a
speciﬁc framework: Ariadne focuses on machine learning using TensorFlow [1]; CodeGuru
focuses on cloud computing using Boto3. Ariadne’s solution entails both a custom type
system and an analysis to infer it. Our approach builds upon standard Python types and
type annotations. While we crafted our analysis strategy to match idiomatic Boto3 use,
these idioms are not exclusive to Boto3 client code. Therefore our layered approach may be
more broadly applicable.

2.2 Machine Learning

PYInfer [6] uses deep learning to generate type annotations for Python. PYInfer fuses
deep learning with static analysis such as PySonar2 to infer types for variables as well as
function-level types in Python. All of these techniques either require labelled type annotations
or employ a static analyzer to generate the initial annotations from Python repositories in
order to train the deep neural network. However, type resolution for Boto3 service clients is
non-trivial due to the reasons mentioned above.

JSNice [23], DeepTyper [16], and LambdaNet [27] use deep learning to generate type
annotations for JavaScript and/or TypeScript. LambdaNet’s authors note that TypeScript
is an inviting target because “plenty of training data is available in terms of type-annotated
programs.” In principle, similar strategies may be applicable to Python. However, it is

XX:6

Static Analysis for AWS Best Practices in Python Code

unclear whether the available corpus of type-annotated Python Boto3 client programs is
large enough for eﬀective training in practice.

3

Background on Boto3: the AWS SDK for Python

This section describes the AWS service clients in the AWS SDK for Python, also called
“Boto3”.2

3.1 Clients and Resources: Low- and High-Level APIs

Boto3 has two distinct levels of APIs:

Client (or “low-level”) APIs provide one-to-one mappings to the underlying HTTP API

operations.

Resource APIs hide explicit network calls but instead provide resource objects and collections
to access attributes and perform actions. Resources represent an object-oriented interface
to AWS. They provide a higher-level abstraction than the raw, low-level calls made by
service clients.

A low-level service client can be created by passing the name of service as an argument to
the boto3.client method.3 For example, the Python statement, s3_client = boto3.client('s3'),
creates a low-level client for the Amazon Simple Storage Service (S3). Conversely, a
service resource can be created by passing the name of service as an argument to the SDK
boto3.resource method.4 For example, the Python statement, s3_client = boto3.resource('s3'),
creates an Amazon S3 service resource. It is also possible to access the low-level client from
an existing resource, as in:

s3_resource = boto3.resource('s3')
s3_client = s3_resource.meta.client

Alternatively, to use service resources, one can invoke the resource() method of a Session and
pass in a service name. For example, one can create an Amazon S3 service resource using:

session = boto3.session.Session()
s3_resource = session.resource('s3')

Service clients give access to service operations by calling methods on a client. For example,
suppose s3_client is an S3 client. Then one can create an S3 bucket, with the bucket name
passed via an argument, using:

response = s3_client.create_bucket(Bucket=bucket_name)

2 https://aws.amazon.com/sdk-for-python/
3 https://boto3.amazonaws.com/v1/documentation/api/latest/guide/clients.html
4 https://boto3.amazonaws.com/v1/documentation/api/latest/guide/resources.html

R. Mukherjee, O. Tripp, B. Liblit, and M. Wilson

XX:7

3.2 Boto3 Type Stubs

Boto3-stubs provides full type annotations for Boto3.5 In particular, Boto3-stubs provides
annotations for a Client type, ServiceResource, and Resource type for each AWS service. It
also provides annotations for a Waiter type, and a Paginator type for each service. With help
from Boto3-stubs, several Python type-checking tools can discover types for multiple ﬂavors of
client construction calls such as boto3.client, boto3.session, session.client, and session.session.

3.3 API Speciﬁcations From Boto3

Some of the AWS best practice rules that are presented in this paper use an external
conﬁguration that provides a speciﬁcation of some service-speciﬁc fragment of the complete
Boto3 API. This speciﬁcation includes an API name, type, the service name the API
belongs to, and few other attributes that are relevant for the rule. We refer to these external
conﬁgurations as API speciﬁcations. One such example is presented in Section 9. API
speciﬁcations are automatically extracted from Boto3 API models.6 These API models have
speciﬁc traits, such as, Pagination, Batch, Deprecated, Waiters, or mutual-exclusion, which
help determine the characteristics of the API. We extract relevant API traits from API
models across Boto3 services to construct the complete API speciﬁcation to enforce. These
API speciﬁcations are then used by the best practice rules for analyzing client code.

4 Motivating Examples

This section presents a few examples that motivate the need for sophisticated type inference
to recover the types of AWS service clients in real-world Python applications. The type
annotations in Figures 2 and 3 are obtained from Pyright with Boto3 type stubs, which are
on lines with the preﬁx “#→”.

Example 1: Consider the Python code snippet in Figure 2. The type annotation for
the variable, self._client, in method M1, is shown in bold. This type, Optional[S3Client],
suggests that self._client might be a Boto3 client for the Amazon S3 service. The method
M1 performs a sequence of API calls on this S3 client object: put_bucket_lifecycle(), then
get_bucket_lifecycle(), then delete_bucket_lifecycle(). If the type of self._client could not be
inferred in this example, then it would have been diﬃcult to guarantee the correctness of the
API calls invoked on that client. Hence, good type inference for self._client is crucial.

Example 2: Consider the Python code snippet in Figure 3. Here, the Boto3 client is
returned by get_sns_client(). Its type is SNSServiceResource, marked in bold in method M2.
This type correctly identiﬁes client as a client for the Amazon Simple Notiﬁcation Service
(SNS). In contrast to the previous example, Figure 3 creates client using the boto3.resource()
API which gives an object-oriented interface to SNS.7. The client ﬂows into M3 via a function
parameter. M3 uses client directly or indirectly to make a sequence of API calls: topic(),
then subscription(), then delete(). Unfortunately, Pyright was unable to assign client a precise
type, leaving it typed simply as the generic Any inside M3. Inference falls short here because
Pyright cannot guarantee that client must always be an SNSServiceResource in every possible

5 https://pypi.org/project/boto3-stubs/
6 https://github.com/boto/boto3
7 https://boto3.amazonaws.com/v1/documentation/api/latest/guide/resources.html

XX:8

Static Analysis for AWS Best Practices in Python Code

import boto3

class S3(object):

def __init__(self, ∗∗kwargs):

self._client = None

@property
def client(self)

if self._client is None:

self._client = boto3.client('s3')

return self._client

def M1(self):

try:

client = self._client
#→ client: Optional[S3Client]
# put lifecycle
response = client.put_bucket_lifecycle(

Bucket=test_bucket, LifecycleConﬁguration=conﬁg)

time.sleep(4)
response = client.get_bucket_lifecycle(Bucket=test_bucket)
assert response
response = client.delete_bucket_lifecycle(Bucket=test_bucket)

except CosServiceError as e:

if e.get_status_code() < 500:

raise e

Figure 2 Example of Python application code using Boto3

call to M3. This is safe but, for our purposes, unfortunate: an untyped client cascades into
untyped topic and subscription, leaving us with nothing useful to analyze for any of the API
calls in M3.

Type resolution of the variable client requires sophisticated type inference coupled with a
domain-aware preference for ﬁnding Boto3 clients wherever they might arise and be used for
API interaction. In this paper, we present a technique that combines Pyright’s type inference
with a custom interprocedural dataﬂow analysis to infer types in such cases.

Furthermore, these API names are exactly the same in Google’s pubsub cloud service,8
and AWS SNS service. Our study shows that the names of some cloud service APIs are
exactly the same for cloud services from diﬀerent commercial cloud vendors (AWS, Google,
Tencent, etc.). Thus, precise resolution of service clients’ types is extremely important for
static analysis of Python applications that use these cloud SDKs.

CodeGuru is speciﬁcally developed to detect best-practice violations in Python application
code that use the AWS Python SDK. Detection of APIs from other cloud vendors can be
considered as a side-eﬀect of the type inference strategy when it resorts to using the API
name-based resolution as a fallback strategy. In such cases, our best-practice detectors can

8 https://cloud.google.com/pubsub/docs

R. Mukherjee, O. Tripp, B. Liblit, and M. Wilson

XX:9

import boto3

class Skunky(object):

def get_sns_client():

return boto3.resource("sns")

def M2():

sns_arn = os.environ['PUBLISH']
client = get_sns_client()
#→ client: SNSServiceResource
M3(client, topic, subscription)
return client.Topic(sns_arn)

def M3(client, topic, subscription):

topic = client.topic(topic)
#→ (variable) client: Any
subscription = topic.subscription(subscription)
subscription.delete()

Figure 3 Example of a Python application code using Boto3

detect APIs that match names across diﬀerent cloud vendors without any knowledge about
the underlying type of cloud service clients.

However, it would be possible to use the same program representation (see MU graph
in Section 5) and the Query Language engine (see Section 6) that are presented in this
paper, to codify best-practice recommendations for other cloud vendors as well. In terms
of extensibility of our detectors to other cloud vendors, there are two aspects: (1) the
type inference system, and (2) detector logic. The type inference system needs to be built
for each speciﬁc cloud vendors and SDKs due to diﬀerent styles and idiomatic ways of
representing cloud service clients. The detector logic implementation can be reused for
general purpose checkers such as missing pagination, deprecated APIs, batch APIs, mutually
exclusive parameters, ineﬃcient API chains, and few others. All these detectors depend on
externally provided API speciﬁcations (see Section 3.3) that are extracted from API models.
Reusability of the detector implementation depends on the availability of these API models
for other cloud vendors.

5

Program Representation

Our analysis represents each program as a collection of per-function graphs called MU
graphs.9 A MU graph roughly corresponds to a data-dependence graph overlaid with a
control-ﬂow (not control-dependence) graph (CFG). As in prior work that used similar
representations [2, 3], we ﬁnd this representation useful for ﬁnding API misuse defects where
both the data ﬂowing into an operation and the order of operations are important.

9 “MU” originally stood for “misuse”, and is pronounced as the name of the Greek letter µ.

XX:10 Static Analysis for AWS Best Practices in Python Code

5.1 MU-Graph Nodes

MU graphs contain the following kinds of nodes:

Entry nodes represent the start of a function’s execution. Each MU graph has exactly one

entry node.

Exit nodes represent the end of a function’s execution. Each MU graph has exactly one exit

node.

Control nodes represent branched control ﬂow among multiple possible successors, such as

at a conditional statement or loop.

Action nodes represent individual execution steps, such as multiplying two values or calling

a function.

Data nodes represent local variables, whether originally present in the source or added as

temporaries during MU-graph construction.

Per-node metadata identiﬁes speciﬁc uses of these general categories. For example, we
distinguish a binary-multiplication action from a function-call action, or an if-statement
control node from a while-statement control node.

Multiple assignments to the same local variable use multiple data nodes, as in static
single assignment (SSA) form. φ action nodes are added as needed to represent converging
data ﬂows, such as when both branches of an if statement modify the same variable.

5.2 MU-Graph Edges

MU-graph edges represent control and data ﬂow:

Control edges order execution among entry, exit, control, and action nodes. No data node
is ever the source or target of a control edge. Thus, discarding all data nodes and
non-control edges would reduce a MU graph to a traditional CFG.

Data edges represent movement of data among control and action nodes, and are further

categorized as follows:

Condition edges ﬂow from data nodes into control nodes. The source of a condition
edge determines the control-ﬂow path taken by the target of that edge. For example, a
condition edge ﬂows from the value of an if statement’s predicate to the control node
for the statement itself.

Deﬁnition edges ﬂow from an action to a data node deﬁned by that action. For example,
a deﬁnition edge from a binary multiplication action to a data node d indicates that d
holds the result of that multiplication.

Parameter edges ﬂow from a data node into an argument position in an action node.
For example, a binary multiplication action is the target of two parameter edges, one
for each operand. A function call action is the target of one parameter edge for each
actual argument.

Receiver edges ﬂow from a data node into the receiver position in a call action node.
These are similar to parameter edges, but highlight the special role of the implicit self
or this argument in method calls.

Callee edges ﬂow from a data node into the callee position in a call action node, showing
what calculations identiﬁed the function to be called. For example, in handlers[event](),
an indexing action to fetch handlers[event] would deﬁne some temporary data node
holding the function to call. A callee edge would then ﬂow from that data node to the
call action.

R. Mukherjee, O. Tripp, B. Liblit, and M. Wilson

XX:11

x1

p

param1

a

r

a

entry

m

1

-

*

exit

2

para m

d

e
f

2

param

d

e
f

1

temp

x2

Figure 4 The MU-graph representation of x ∗= x − 1. Entry and exit nodes are trapezoidal;
action nodes are rectangular; data nodes are elliptic. Control edges are solid; data edges are dashed.

Edges carry additional metadata speciﬁc to their roles. For example, the two control
edges that depart from an if statement’s control node are marked to distinguish the true
and false branches. Multiple parameter edges leading to the same action node are ordered,
thereby distinguishing an action’s ﬁrst parameter from its second, and so on.

5.3 Overall Properties

A key invariant in the MU representation is that data can only ﬂow from data nodes to
control/action nodes, and vice versa. Data edges never connect pairs of data nodes directly,
and every data edge has a data node as exactly one of its endpoints. Informally, each action
node receives zero or more data nodes as inputs (ﬂowing across parameter, receiver, or
callee edges), and may provide an output that ﬂows across a deﬁnition edge into some other
data node. In a compound expression like x + y ∗ z, the multiplication action deﬁnes an
anonymous data node, which in turn ﬂows into the addition action as its second argument.
Figure 4 illustrates several MU-graph features in the representation of x ∗= x − 1, or
equivalently x = x ∗ (x − 1). Solid control edges establish evaluation order as in a CFG:
subtraction before multiplication, each represented as a rectangular action node. Elliptic
data nodes represent two versions of x: x1 before the assignment and x2 after. Additional
data nodes represent the literal 1 and a temporary value. The initial value of x (x1) is a
parameter (operand) to both mathematical operations, and is distinct from the ﬁnal value of
x (x2). The temporary data node is deﬁned by the subtraction action and is also a parameter
to the multiplication action. Notice that data and non-data nodes strictly alternate along
data paths: data nodes provide inputs to action or control nodes, and action nodes’ outputs
deﬁne data nodes.

5.4 Using Pyright for Best-Eﬀort Graph Construction

Pyright is “a fast type checker meant for large Python source bases.” [19] Pyright is primarily
used behind-the-scenes to support Python IDEs, or as a command-line linter/checker.
However, Pyright’s sophisticated type inference and robust handling of incomplete or incorrect
programs make it ideally suited for our purposes as well.

MU graph construction begins with a parsed abstract syntax tree (AST) provided by
Pyright. We traverse the AST, synthesizing and combining MU graph fragments in a
roughly bottom-up manner. For example, the MU graph representation of an if statement

XX:12 Static Analysis for AWS Best Practices in Python Code

incorporates smaller MU subgraphs representing the statement’s conditional expression, true
branch, and optional false (else) branch.

For data nodes, we also rely on Pyright to provide static type information and name
resolution. Given Python’s dynamic nature, these are both best-eﬀort. Inferred static types
can be imprecise, absent, or wrong; names can be aliased or accessed covertly via reﬂection.
We attempt no alias analysis or points-to analysis beyond that implicitly performed by
Pyright’s during type inference and name resolution. Types are available on data nodes
that represent named variables as well as those that represent intermediate subexpressions,
such as the “temp” node in Figure 4, all subject to practical limits on Pyright’s ability to
statically type Python code.

We ﬂatten data node types to their string representations, such as "int" or "MyClass"
or "(int, str) −> tuple[int, str]". Stringiﬁcation discards internal structure, but allows MU
graphs to accommodate essentially any type grammar, even from non-Python languages.
Types as strings are also forgiving of incomplete programs: we might know that a piece of
data is an instance of MyClass even if we know nothing about MyClass’s internal structure or
provenance.

The entire process of building MU graphs is best-eﬀort, and proceeds even when confronted
with imports of missing modules, calls to unknown functions, instantiations of unknown
types, reads of unknown variables, etc. We represent each questionable operation as some
reasonable fallback (e.g., as an empty statement), and move on. Python also contains
syntactically ambiguous constructs, such as overloaded operators or the myriad uses of “.”.
We disambiguate these using types whenever possible, or heuristics when necessary. These
approximations mean that we cannot, in general, claim to be sound or complete. However,
these same approximations allow us to provide a representation that is useful for many
practical applications where absolute guarantees are not required.

5.5 From Functions to Programs

The construction process described in Section 5.4 yields one MU graph for each function.
Beyond named functions (def), we also create a MU graph for each unnamed function
(lambda). For each top-level script, we create a synthetic function that represents execution
of that script’s top-level statements, and build a corresponding MU graph.

We organize these per-function MU graphs into larger assemblages that reﬂect static
program structure. Each Python class contains a dictionary of named methods; each script
contains a dictionary of named top-level classes and functions; and so on. We do not build a
static call graph at this time, since not all downstream consumers of MU graphs require one.
However, we organize and manage the MU graph collection in such a way as to facilitate
best-eﬀort callee resolution later, if needed.

6 Query Language

Working directly atop the MU representation in authoring analysis rules misses important
reuse opportunities. We have therefore designed and implemented an API, dubbed the
Golden Query Language (GQL), to enable encapsulation, optimization and reuse of a wide
variety of analysis constructs. GQL is implemented as a Java library whose main interface
with the analysis builder is the CustomRule class. CustomRule instances are created using
the ﬂuent builder pattern [12], where builder calls correspond to reasoning steps in the rule.
A rule object can be evaluated at diﬀerent scopes, from entire code bases to single functions.
This is an important source of ﬂexibility, which owes to the MU representation and its

R. Mukherjee, O. Tripp, B. Liblit, and M. Wilson

XX:13

CustomRule rule = new CustomRule.Builder()

.withName("MathExp")
.withComment("For small ﬂoats `x`, the subtraction in "

+ "`exp(x) − 1` can result in a loss of precision.")

.withAllOf(
b −> b

.withMethodCallFilter(".∗math\\.exp")
.withDeﬁnitionTransform()
.as("MathExpResult"),

b −> b

.withConstantDataFilter("1")
.as("ConstantOne")

)
.check()
.withActionFilter("\\−")
.withDirectDataFromIdFilter("MathExpResult")
.withDirectDataFromIdFilter("ConstantOne")
.build();

Figure 5 GQL rule for identifying suboptimal use of the math.exp function.

support for partial programs. (See Section 5.4.) Rule evaluation yields a RuleEvaluationResult
for every type and function that the rule visits, which includes rich information on whether,
and if relevant where and how, rule evaluation has failed.

As an illustration of GQL syntax, we refer the reader to Figure 5, where a rule that
identiﬁes suboptimal use of the math.exp function is shown. Here is a simple example of
what the rule checks for:

def foo():

import math
return math.exp(1e−10) − 1

Rule deﬁnition begins by setting the rule’s name and user-facing comment text. The
following steps, up to the check statement, are preconditions that the rule checks for.
Speciﬁcally, the withAllOf statement ensures that all the subrules nested within it evaluate
successfully, where these check for math.exp calls as well as the presence of the constant value
1. The matches are stored into variables (or IDs), to enable downstream reuse thereof, using
the as operation. The actual check, or postcondition, is the rule section after the check step.
It establishes whether there is a subtraction operation that the node deﬁned by math.exp,
along with the constant 1, ﬂow into directly (that is, without the mediation of any other
action).

6.1 Rule Evaluation

In what follows, we use standard notation, G = (V, E), when referring to MU graphs. Unless
stated otherwise, the graphs we mention are speciﬁcally MU graphs.

As illustrated above, a GQL rule is an implication relation, pre =⇒ post. As such, rule
evaluation is satisﬁed either when pre is not satisﬁed or when both pre and post are satisﬁed.

XX:14 Static Analysis for AWS Best Practices in Python Code

pre and post are both sequences [op] of operations.

An operation op : P(V) 7→ P(V) is a function whose domain and codomain are both node
sets: V = {n : ∃G = (V, E). n ∈ V }. As an example, a ﬁlter operation that matches against
calls to a function named “foo” evaluates to foo call nodes within the incoming node set, if
any, or else ∅.

Given node n, let Gn denote the graph containing n, and Gn.V the complete set of nodes

that Gn contains. Operations op satisfy the following two invariants:
1. ∀N ⊆ V. op(N ) ⊆ S

n∈N Gn.V . That is, application of an operation to a node set N

cannot “exceed” the set of nodes due to the graphs containing the nodes in N .

2. op(∅) = ∅. That is, application of an operation to the empty node set yields the empty

node set.
Given rule r = [op1, . . . , opk] =⇒ [opk+1, . . . , opn] and input graph G = (V, E), we

denote the node set ﬂowing into opj as σj−1. The node sets are deﬁned as follows:

σi =






V

∅

V

if i = 0

if i = k ∧ opk(σk−1) = ∅
if i = k ∧ opk(σk−1) 6= ∅

opi(σi−1) otherwise

Per the ﬁrst case, precondition evaluation starts from the complete set of graph nodes
(V ). Per the second and third cases, the transition from precondition to postcondition is
either trivial if the precondition has not been satisﬁed (second case), or — analogously to
precondition evaluation — postcondition evaluation starts from V (third case). Any other
transition along the operation sequence is simply an application of the operation to its
incoming node set.

Rule evaluation is successful if and only if (i) a preﬁx of pre evaluates to ∅ (in which case
the precondition is not satisﬁed); or (ii) both pre and post evaluate to non-empty node sets
(in which case the precondition and postcondition are both satisﬁed).

To add color to the formal description so far, rule evaluation is essentially a process of
matching against a pattern, or semantic property, where a non-empty node set is a match
frontier that feeds into the next reasoning step. Failure to maintain a non-empty match
frontier means that the given (pre or post) condition is not satisﬁed by the input function.

6.2 Rule Structure

While our formal presentation above of GQL rules is as logical implication relationships,
in practice a rule object has additional information and structure. A GQL rule consists
of four sections, as follows: (i) setup: the rule’s name, and the comment (or description)
associated with the rule; (ii) function matcher: a rule can optionally deﬁne criteria when to
be evaluated, for example based on function name, attributes, annotations, containing type,
parameter types, and so on; (iii) precondition: the sequence of operations up to the check
builder step; and (iv) postcondition: the sequence of operations following the check builder
step.

Since GQL rules follow the ﬂuent builder pattern, there is risk that users would miss,
misuse, or misorder rule constructs or sections. For example, the user might build a rule
lacking a check step; forget to set the rule’s name; or try to apply incompatible ﬁlters in
succession. To ensure rule integrity, we employ a hybrid solution that combines metadata
contributed by operations with runtime checking. Operations expose a “signature”, as

R. Mukherjee, O. Tripp, B. Liblit, and M. Wilson

XX:15

explained in Section 6.4, such that improper compositions can be detected and localized
ahead of rule evaluation.

6.3 Language- and Domain-speciﬁc Rule Constructs

Beyond the core GQL constructs, which are applicable across diﬀerent programming languages
and problem domains, there are reusable albeit language- or domain-speciﬁc constructs. As an
example, constructs like withNamedArgumentsTransform or withUnpackedArgumentsTransform
are useful for Python rules, but do not apply to Java. GQL enables such constructs to
be organized into subclasses of CustomRule, such as PythonCustomRule, while containing
CustomRule to the core analysis constructs.

This approach has several important advantages. First, we avoid API bloat by distributing
analysis constructs across more than just CustomRule. Second, we avoid misuse errors due to
a construct being used outside its intended context, for example a Python analysis construct
used in a rule that targets Java programs. Finally, GQL extensions sometimes introduce
dependencies. We have implemented, for example, a CustomRule extension in the domain of
data leaks, where some of the analysis constructs rely on an ML model to predict whether
a given data access is retrieving sensitive information. These dependencies should not be
forced on GQL users outside the given domain.

6.4 GQL Operations

We now take a closer look at the diﬀerent operations that comprise GQL rules. These divide
into 4 categories, discussed below in turn. Beyond the description and examples in this
section, we refer the reader to Appendix A for more examples of GQL operations.

For safety and fault localization, GQL requires that operations be annotated with their
signature, which states the types of nodes that they accept as input and yield as output.
(See Section 5.) The withReceiverTransform operation, for example, accepts as input action
(and more speciﬁcally, call) nodes, and outputs data nodes. If a user attempts to compose
operations incorrectly, for example by routing the output of a withDataByNameFilter operation
to withReceiverTransform, then GQL identiﬁes the violation at runtime and generates a
meaningful failure message that localizes it and explains why rule evaluation has been
terminated. We are currently in the process of shifting the failure left to rule building time,
and as a longer-term objective, compile time.

6.4.1 Core Operations

Core operations apply to all rules, regardless of their scope and logic. Some of the core
operations, in particular check and as, have already been explained in the context of
Figure 5. Additional core operations include the ability to reset the match frontier, interleave
instrumentation (for example, for debugging or proﬁling purposes), read and write mutable
auxiliary state, and so on. See Appendix A.1 for more examples.

6.4.2 Filter Operations

A ﬁlter operation f satisﬁes the invariant: ∀V ∈ V. f (V ) ⊆ V . That is, a ﬁlter operation
selects a subset of the input node set. Its result cannot exceed the incoming set.

GQL oﬀers a wide selection of built-in ﬁlters. Beyond withActionFilter, withMethodCallFilter,
withConstantDataFilter and withDirectDataFromIdFilter that are used in Figure 5, there are

XX:16 Static Analysis for AWS Best Practices in Python Code

ﬁlters for matching against control structures, constants, actions with speciﬁc arguments (like
constants or null/None), and so on. See Appendix A.2 for several additional ﬁlter examples.
The GQL ﬁlter operations — almost without exception — are deﬁned using a unary
predicate ranging over nodes, and as such, ﬁltering is done point-wise. As an example,
withMethodCallFilter is instantiated through a predicate that accepts action (and speciﬁcally,
call) nodes where the callee matches the provided regex speciﬁcation. One of the few
exceptions to point-wise predicate application is the withMethodCallGroupFilter operation,
which evaluates sets of function calls and the relationships that hold between them (for
example, if they all share the same receiver) against a user-provided speciﬁcation.

A common practice with ﬁlter operations is to compose them, which enables reﬁnement

in pattern matching. The rule in Figure 5 contains examples of that, like:

.withActionFilter("\\−")
.withDirectDataFromIdFilter("MathExpResult")
.withDirectDataFromIdFilter("ConstantOne")

Here we ﬁrst select subtraction actions then reﬁne further by demanding unmediated incoming
data ﬂow from nodes mapped to variables "MathExpResult" and "ConstantOne".

6.4.3 Transform Operations

Transform operations enable the transition from a given match frontier to another frontier
that derives from it. For example, a frontier that consists of function calls can be transformed
to the respective arguments or receivers, or the values deﬁned by the calls, as illustrated
with withDeﬁnitionTransform in Figure 5.

There are many built-in GQL transform operations. Examples include withArgumentsTransform,

which transforms an action node to its respective arguments; withControlDependenciesTransform,
which transforms a node to its set of control dependencies; withDataDependenciesTransform
(resp. withDataDependentsTransform), which transforms a node to its set of (transitive) data
dependencies (resp. dependents); and withReceiverTransform, which transforms a call node
to the receiver (if available). See Appendix A.3.

6.4.4 Second-order Operations

Logical structures and operators are necessary to express certain rule logic in a precise and
concise manner. As a simple example, the user may wish to check if a given function call
"zoo" has a receiver of type either Foo or Bar. Another use case, illustrated in Figure 5, is
the need to check that several conditions are all met through withAllOf.

To enable such control and logical structures, GQL exposes second-order operations.
These are operations that are themselves parameterized by one or more rules, which we refer
to as subrules.

As an illustration, here is the GQL syntax for the above example:

.withMethodCallFilter("zoo")
.withOneOf(

b −> b.withReceiverByTypeFilter("Foo"),
b −> b.withReceiverByTypeFilter("Bar"))

The withOneOf construct evaluates to the ﬁrst subrule that yields a non-empty result, or
else it evaluates to ∅.

R. Mukherjee, O. Tripp, B. Liblit, and M. Wilson

XX:17

Most of the computational complexity and analysis power of GQL is attributable to
this category of operations, which includes support for interprocedural analysis through
withInterproceduralMatch, described in Section 6.5, and variants thereof like withInterproceduralDataDependenciesTransform
or withInterproceduralDataDependentsTransform; diﬀerent forms of aggregation of subrule
evaluation results, like withOneOf, withAllOf or withAnyOf (collecting all non-empty subrule
evaluation results); withLanguageSpeciﬁc (which enable language-speciﬁc subrule logic, for
example to resolve types diﬀerently in Java versus Python); and so on. For more examples
of second-order operations, see Appendix A.4.

6.5 Interprocedural Analysis

As noted above, GQL provides the ability to perform interprocedural analysis through
the withInterproceduralMatch construct and several specializations thereof. The underlying
call-graph representation resolves call sites on demand, per the CHA call-graph construction
algorithm [14], based on the (i) name of the callee, (ii) number of arguments, and (iii)
argument types. Though the CHA algorithm is known to be imprecise [5], we have rarely
seen cases where that was the cause of imprecision in GQL rule evaluation. We hypothesize
that this is because (i) interprocedural analysis is run at ﬁle or package scope, but not
beyond, so there is less room for error, plus (ii) imprecision in interprocedural analysis is
potentially mitigated by other rule steps.

A pseudocode description of the GQL support for interprocedural tracking is shown in
Algorithm 1. Interprocedural tracking takes a subrule r, along with a pair hG0, mr0i of
seeding function graph and matched nodes within it, and a speciﬁcation whether to track
forward or backward. The algorithm computes a ﬁxpoint solution mapping visited functions
to matched nodes therein.

At each iteration of the ﬁxpoint loop, the rule is applied to the current worklist item
hG, mri, computing additional matches mr0 beyond the seeding matches mr. In addition, mr
and mr0 are used to derive “summaries” at call sites c dispatching to G, which is shown in
Algorithm 1 as the propagateAtCallerSites step. In the forward direction, we check whether
there are matched c arguments that are compatible with mr, and if so, we track additional
arguments and/or the node deﬁned by c, if exists, if these are supported by mr0 (that is,
if mr0 contains formal parameters of G and/or nodes returned by G). In the backward
direction, we check whether mr contains nodes returned by G and mr0 contains formal
parameters, and if so, then we start tracking corresponding c arguments.

We then proceed to additional propagation steps. In the forward direction, we extend
the worklist by (i) propagating from call arguments to respective callee parameters, and
(ii) propagating from return statements to nodes deﬁned by compatible call sites. In the
backward direction, we extend the worklist by (i) propagating from formal parameters to
compatible call-site arguments, and (ii) propagating from nodes deﬁned by call sites to
returned nodes of compatible callee.

6.6 Dataﬂow Analysis

Beyond its interprocedural capabilities, GQL also has built-in support for several ﬂavors
of dataﬂow analysis, including slicing and taint tracking.10 These build directly on top of

10 GQL additionally features ﬁnite state machine (FSM) and typestate analysis, though these involve not
just dataﬂow but also control-ﬂow reasoning. These capabilities are not consumed by the rules that we
discuss later in the paper, so we suﬃce by noting them here.

XX:18 Static Analysis for AWS Best Practices in Python Code

Algorithm 1 Interprocedural matching algorithm

Data: hG0, mr0i: function graph and matched nodes therein
Data: rule: intraprocedural matching rule
Data: isF wdElseBack: analysis direction
Result: {. . . , G 7→ mr, . . .}: ﬁxpoint matching solution
worklist = {hG0, mr0i};
result = ∅;
while ¬worklist.isEmpty() do

hG, mri = worklist.selectAny();
if already processed hG, mri then

continue;

mr0 = rule.evaluate(G, mr);
result = result[G 7→ mr ∪ mr0];
{. . . , Gclri, . . .} = resolveCallers(G);
foreach caller Gclri do

propagateAtCallerSites(Gclri, G, mr, mr0, isF wdElseBack)

if isF wdElseBack then

foreach call c with matched args in mr0 do
{. . . , Gtgti, . . .} = resolveCallees(c);
foreach callee Gtgti do

mrtgti = argsT oF ormals(c, mr0, Gtgti);
worklist.add(hGtgti, mrtgtii);

foreach return statement ret with matched arg in mr0 do

foreach caller Gclri do

mrdef s = toCallerSiteDef s(ret, G, Gclri);
worklist.add(hGclri, mrdef si);

else

foreach parameter p in mr0 do
foreach caller Gclri do

mrclri = f ormalT oCallerSiteArgs(p, G, Gclri);
worklist.add(hGclri, mrclrii);

foreach call c whose deﬁnition is in mr0 do
{. . . , Gtgti, . . .} = resolveCallees(c);
foreach callee Gtgti do

mrtgti = returned(Gtgti);
worklist.add(hGtgti, mrtgtii);

return result;

R. Mukherjee, O. Tripp, B. Liblit, and M. Wilson

XX:19

the data edges exposed by the MU representation, in conjunction with the interprocedural
matching algorithm described above.

The main feature that the GQL dataﬂow analysis provides beyond a standard ﬁxpoint
algorithm over the dataﬂow relation is the ability to specify matchers on graph edges to tag
them with unique roles: passthrough (data ﬂows across the call site), blocking (an edge being
either a sanitizer or a validator), side eﬀecting (data ﬂows into the receiver of a call), or
reading (data ﬂows from the receiver to the deﬁnition). The user-provided speciﬁcation is
then enforced as part of the ﬁxpoint algorithm.

7

Type Inference for Boto3 Clients

As explained in Section 3.1, a Python AWS application creates an AWS service client by
passing the name of the service as an argument to one of two distinct levels of APIs. The
use of these multiple API ﬂavors, the interactions between them, and the use of strings as
service selectors, all pose challenges for type inference.

Regardless of which API is used, AWS service clients are ultimately just data values. Like
any other data, service clients can be stored in class variables, assigned into global variables,
returned from functions, and so on. Code might use a service client locally within a single
function or globally within or even across the ﬁles that comprise the complete application.
The complexity of these deﬁnition–use chains (DU chains) further complicates type inference.
In this section, we present diﬀerent type inference strategies that can be used in this

challenging application domain.

7.1 Pyright’s Type Inference With Boto3-Stubs

Pyright supports type inference for function return values, instance variables, class variables,
local variables, and global variables. Pyright’s inference engine uses several advanced type
inference techniques, such as:

a ﬂexible model of “type assignability”;
inferred types for self and cls;
parameterized generic types, including both polymorphic container types as well as
optional types;
union types representing arbitrary sets of possible types;
overloaded function types as a special case of union types for ad hoc polymorphic functions;
literal types, such Literal["str"] as a subtype of str that represents only the string literal
"s3".
type narrowing based on code ﬂow, which naturally makes Pyright’s types ﬂow-sensitive;
type guards that recover implicit type constraints from a wide variety of common Python
idioms;
constrained type variables and conditional types; and
bidirectional type inference that infers the “expected type” of the right-hand side of an
assignment if the left-hand side already has a known type.

A full discussion of these capabilities is outside of the scope of this paper, and in any
case Pyright is not our contribution. We treat Pyright’s type inference engine as a powerful,
featureful, but opaque black box.

XX:20 Static Analysis for AWS Best Practices in Python Code

If Pyright cannot infer the type of some symbol, then that symbol’s type is set to
Any. This fallback type is a useful warning marker that lets inference consumers (such as
CodeGuru) recognize cases where Pyright type inference fell short.

Type inference can incur signiﬁcant computation overhead for large code bases. Also,
Pyright cannot always infer correct types without some outside help. Hence, type annotations
are a practical requirement for building a robust type inference system. We use third-party
type stubs, called Boto3-stubs [8], that provide full type annotations for Boto3. Pyright
ingests type annotations provided by Boto3-stubs to further enhance and constrain its type
inference.

Examples of Pyright’s Type Inference: Figures 2 and 3 give the variable- or function-level
type annotations from Pyright with Boto3-stubs (denoted by the preﬁx “#→”), where Boto3
clients are stored in instance ﬁelds, or returned from methods, respectively. However, in
Figure 9, Pyright fails to infer a precise type for s3_client in the method load_df_from_s3,
instead giving it the fallback Any type.

7.2 Type Inference Using Custom Dataﬂow Rules

As an alternative to Pyright, we have used GQL to implement custom inference rules based
on dataﬂow analysis. These rules do not provide universal, generic type inference. Instead,
they focus on idiomatic, interprocedural Boto3 usage patterns that Pyright’s general-purpose
engine fails to address. There are a total of ten GQL-based custom dataﬂow rules, among
which only one is intraprocedural rule and rest nine are interprocedural rules. For illustration
purpose, we select few representative interprocedural GQL rules that have low to medium
complexity (in terms of number of operations in the rules) and that performs dataﬂow
analysis at ﬁle-scope or package-scope.

7.2.1 Representative Examples of Interprocedural Rules

Each GQL rule in Figures 6–8 implements some form of interprocedural dataﬂow analysis.
Each operates on a function graph and matching API nodes along with the receiver nodes
of calls to the corresponding APIs. For example, in Figure 9, one relevant API node is
get_object, for which the corresponding receiver node is s3_client. Our strategy for resolving
call actions to callees is name-based: we match the name of the API entry point (callee) in
the code against API speciﬁcations that are extracted from Boto3.

Figure 6 shows one such rule. The scope of this rule’s interprocedural match operation is
FILE_FORWARD_REACHABLE, which directs GQL to track dataﬂow forward using a “data
dependents” transform operation that transforms from incoming nodes to nodes that are
data dependent on them, including in other functions. The result of this interprocedural
tracking is then checked to determine if it matches one of the known ﬂavors of Boto3 clients
(low-level or object-oriented), by calling the utility methods inside the withOneOf operation.
The rule in Figure 7 implements interprocedural backward dataﬂow analysis, complementary

to the forward analysis of Figure 6. For the backward version, tracking is speciﬁed as
FILE_BACKWARD_REACHABLE. This scope directs the interprocedural analysis to perform
backward dataﬂow tracking using a “data dependencies” transformer that transforms from
incoming nodes to nodes that are data dependent on them, including in other functions.
Similar to the previous rule, this rule’s withOneOf clause then checks whether the result of
backward interprocedural tracking matches one of the known ﬂavors of Boto3 clients.

R. Mukherjee, O. Tripp, B. Liblit, and M. Wilson

XX:21

builder −> builder

.withInterproceduralMatch(

new InterproceduralMatchOperation.InterproceduralMatchSpec(

/∗ scope = ∗/ InterproceduralMatchOperation.Scope.FILE_FORWARD_REACHABLE,
/∗ stopOnFirstMatch = ∗/ false,
/∗ visitAllNodes = ∗/ false

),
bb −> bb.withDataDependentsTransform(

/∗ isTransitive = ∗/ true,
/∗ isInterprocedural = ∗/ true

)

)
.withOneOf(

bc −> getBoto3Client(bc, service),
bc −> resourceMethodCallFilter(bc, service),
BotoClientUtils::Boto3SessionMethodCallFilter

)

Figure 6 Rule example using forward, interprocedural dataﬂow

builder −> builder

.withInterproceduralMatch(

new InterproceduralMatchOperation.InterproceduralMatchSpec(

/∗ scope = ∗/ InterproceduralMatchOperation.Scope.FILE_BACKWARD_REACHABLE,
/∗ stopOnFirstMatch = ∗/ false,
/∗ visitAllNodes = ∗/ false

),
bb −> bb.withDataDependenciesTransform(

/∗ isTransitive = ∗/ true,
/∗ isInterprocedural = ∗/ true

)

)
.withOneOf(

bc −> getBoto3Client(bc, service),
bc −> resourceMethodCallFilter(bc, service),
BotoClientUtils::Boto3SessionMethodCallFilter

)

Figure 7 Rule example using backward, interprocedural dataﬂow

XX:22 Static Analysis for AWS Best Practices in Python Code

builder

.withId(idToMatch)
.withNodeFilter(EGroumNode::isFieldAccess)
.as(PYTHON_AWS_CLIENT_FIELD_ACCESS)
.withInterproceduralDataDependentsTransform(

InterproceduralMatchOperation.Scope.PACKAGE,
/∗ methodFilter = ∗/ g −> true, /∗ isIntraprocedural = ∗/ false)

.withNodeFilter(EGroumNode::isFieldAccess)
.as(ALL_FIELD_ACCESSES)
.withId(PYTHON_AWS_CLIENT_FIELD_ACCESS)
.withNodeTransform(

n −> CustomRule.withId(ALL_FIELD_ACCESSES).toSet().stream()

.ﬁlter(r −> r.getName().equals(n.getName())

&& "__init__".equals(r.getGraph().getName()))
.collect(Collectors.toSet())

)
// Returns all the backward−reachable data nodes
.withInterproceduralDataDependenciesTransform(

InterproceduralMatchOperation.Scope.PACKAGE_BACKWARD_REACHABLE,
/∗ methodFilter = ∗/ g −> true, /∗ isIntraprocedural = ∗/ false)

.as(PACKAGE_BACKWARD_REACHABLE_DATA)
.withDeﬁnedByTransform()
.withOneOf(

bc −> getBoto3Client(bc, service),
bc −> resourceMethodCallFilter(bc, service),
BotoClientUtils::Boto3SessionMethodCallFilter

)

Figure 8 Rule example using backward, interprocedural dataﬂow for receivers in instance ﬁelds

R. Mukherjee, O. Tripp, B. Liblit, and M. Wilson

XX:23

def write_df_to_s3_location(ﬁle_path, bucket_name, \

metadata_material_set, sep=None):

s3_client = create_s3_client()
#→ s3_client: S3Client
df = load_df_from_s3(s3_client, bucket=bucket_name, path="")
#→ df: DataFrame
s3_client.put_object(Body=ﬁle_path, Bucket=bucket_name)

def create_s3_client():

return Boto3.client("s3")
#→ create_s3_client: () −> S3Client

def load_df_from_s3(s3_client, bucket, path):

#→ load_df_from_s3: (s3_client, bucket, path) −> DataFrame
raw_date = None
try:

raw_data = s3_client.get_object(

Bucket=bucket_name, Key=object_path)

#→ s3_client: Any
#→ s3_client: Any
except ClientError as e:

logging.info("Bucket: {}, error {}", bucket_name, str(e))

io_data = StringIO(raw_data)
df = pd.read_csv(io_data)
return df

Figure 9 Type annotation for AWS client passed by input parameter

Figure 8 gives an interprocedural rule for tracking Boto3 clients when the client is initially
stored in an instance ﬁeld by a constructor (“__init__”), then later retrieved from the same
ﬁeld and used as the receiver node of a matching API call. This rule uses a withNodeTransform
operator that transforms all ﬁeld accesses within the package scope to only those nodes that
match with the receiver node. An interprocedural query on this matching set retrieves all
data nodes that are backward-reachable within the package scope. The resultant set of nodes
is passed to the withDeﬁnedTransform that transforms from incoming data nodes to their
respective deﬁning actions. Lastly, this rule checks that the resultant set of action nodes
match one of the known ﬂavors of Boto3 clients.

7.2.2 Example of Type Inference Using Custom Dataﬂow Rules

Figure 9 shows a Python code snippet with variable- and function-level type annotations
from Pyright. The type of s3_client in the method write_df_to_s3_location is correctly
inferred as S3Client: an Amazon S3 service client. This client is passed via input parameter
to the method load_df_from_s3. In absence of the type annotation for the input parameter,
Pyright could not infer the type of s3_client (denoted by Any), inside the method load_df_from_s3.
However, another of our custom dataﬂow rules can resolve the type of s3_client in method
load_df_from_s3. The applicable rule starts from a matching API node, s3_client.get_object,
where the type of the receiver node s3_client needs to be determined. Recall that the matching

XX:24 Static Analysis for AWS Best Practices in Python Code

Python programs

Type inference by Pyright type with Boto3-stubs

Python MU graphs with types annotated for Boto3 clients

Identiﬁcation and analysis of matching API nodes by custom GQL dataﬂow rules

Boto3 clients identiﬁed in MU graphs

Figure 10 Layered type inference

API node is obtained by matching the name of the API against the API speciﬁcation extracted
from Boto3. Starting from a matching API node, the rule uses a “parameter transform”
operation that transforms incoming nodes to the parameters of the respective functions. This
rule then uses a “backward data dependencies” transform that transforms from incoming
nodes to their data dependencies, including in other functions. The rule’s result includes the
node s3_client in the method write_df_to_s3_location, whose type is already known to be
S3Client. It is worth noting that the type of s3_client could also be inferred by a stand-alone
custom dataﬂow rule (in absence of type annotations from Pyright). However, the rule
speciﬁcation would be more complex. We prefer to augment Pyright’s capabilities rather
than replace them.

7.3 Layered Type Inference

The example in Figure 9 shows that a hybrid approach for type inference can combine custom
dataﬂow rules with Pyright’s type inference to resolve types that Pyright cannot resolve by
itself. Each of these type inference approaches have complementary strengths. This quality
suggests a layered approach for type inference that combines these strategies in a staged
manner, as shown in Figure 10.

Our layered approach ﬁrst uses Pyright’s type inference with Boto3 stubs to infer type
annotations for at least some Boto3 clients. Per Section 5.4, data nodes in MU graphs
carry type metadata reﬂecting Pyright’s inference results. If the type of an API call of
interest is already known, then that may be suﬃcient to recognize that the API belongs to
Boto3. If the type of the API call of interest is unknown, then our layered approach deploys
custom dataﬂow rules to infer client types. Section 9 presents our empirical evaluation of the
strengths and limitations of this layered approach.

8

AWS Best Practices Rules

In this section, we describe a representative sample of eight rules that detect diﬀerent
types of defects related to usage of the Boto3 API. These rules cover approximately 200
public-facing AWS services. All Python AWS best practices rules (as well as most other
CodeGuru rules) are implemented atop GQL (see Section 6), and follow the same rule
evaluation mechanism that is discussed in Figure 5. Of the eight rules discussed in this
section, we focus in particular on two rules — concerning pagination and batchable APIs —
to enable thorough discussion of rule syntax and sample detections.

R. Mukherjee, O. Tripp, B. Liblit, and M. Wilson

XX:25

def sync_ddb_table(source_ddb, destination_ddb):

response = source_ddb.scan(TableName="table1")
for item in response['Items']:

destination_ddb.put_item(TableName="table2", Item=item)

Figure 11 Non-compliant Pagination Example

def sync_ddb_table(source_ddb, destination_ddb):

response = source_ddb.scan(TableName=="table1")
for item in response['Items']:

destination_ddb.put_item(TableName="table2", Item=item)

# Keeps scanning util LastEvaluatedKey is null
while "LastEvaluatedKey" in response:
response = source_ddb.scan(
TableName="table1",
ExclusiveStartKey=response["LastEvaluatedKey"]

)
for item in response['Items']:

destination_ddb.put_item(TableName="table2", Item=item)

Figure 12 Correct Pagination Example

8.1 Detecting Misuse of Paginated APIs

The pagination trait is implemented by over 1,000 APIs belonging to >150 AWS services.
This trait is commonly used when the result set due to a query is too large to ﬁt within
a single response. For the complete set of results, a pagination token is used to perform
iterative requests and receive the response in parts. Developers who are not aware of this trait
might mistakenly suﬃce with a single request/response result, as illustrated in Figure 11.

Here the scan call is used to read items from an Amazon DynamoDB table, where
put_item saves those items to another DynamoDB table. The scan API implements the
pagination trait. However, the code neglects to check for additional results beyond the initial
batch, which is clearly wrong. Our pagination rule detects the missing pagination in this
example, and generates a recommendation to iterate on the complete result set through
the LastEvaluatedKey token available through response. A compliant version of the code,
consistent with this recommendation is shown in Figure 12.

8.2 Error Handling for Batch Operations

More than 20 AWS services expose batch APIs, which enable bulk request processing. Batch
operations can succeed without throwing an exception even if processing fails for some items.
Therefore, a recommended best practice is to explicitly check for failures in the response due
to the batch API call.

We illustrate incorrect and correct usages of batch APIs in Figures 14 and 15, respectively.

The MU representation for these programs is provided in Figure 13.

The rule for detection of batch operations where failures are not checked is shown in
Figure 16. Like many other CodeGuru rules, in particular in the AWS best practices category,
this rule is parameterized by a conﬁguration. (See Section 9 for an example.)

XX:26 Static Analysis for AWS Best Practices in Python Code

Figure 13 Complete MU Graph (left) for the non-compliant code and partial MU Graph (right)

for the compliant code of Figures 14 and 15, respectively

def noncompliant():

sqs = boto3.client('sqs', 'us−west−2')
sqs.send_message_batch()

Figure 14 Incorrect Error handling for Batch Operation example

def compliant():

sqs = boto3.client('sqs', 'us−west−2')
response = sqs.send_message_batch()
if "Failed" in response:

raise SendMessageToSQSFailure("Failed")

Figure 15 Correct Error handling for Batch Operation example

R. Mukherjee, O. Tripp, B. Liblit, and M. Wilson

XX:27

PythonCustomRule.Builder()

.withName(ERROR_HANDLING_BATCH_OPERATION_RULE)
.withComment(ERROR_HANDLING_BATCH_OPERATION_RULE_COMMENT)
.withMethodCallFilter(conﬁg.api)
.as(BATCH_API_CALL)
.withReceiverTransform()
.as(PYTHON_AWS_CLIENT_RECEIVER)
.reset()
.withClosure(

/∗ Pre−condition: Match that the type of API is a Boto3 client ∗/
b −>

getBoto3Client(

(PythonCustomRule) b,
BotoServiceName.fromString(conﬁg.serviceId),
PYTHON_AWS_CLIENT_RECEIVER))

/∗ CHECK ∗/
.check()
/∗ Post−condition: Check that the output of Boto3 API is ignored ∗/
.withId(BATCH_API_CALL)
.withOutputIgnoredFilter()
.build();

Figure 16 Rule to check for batch API calls sans failure checking.

The rule’s precondition searches for batch API calls per the conﬁguration, then transforms

from the calls to their respective receivers, which are stored into variable PYTHON_AWS_CLIENT_RECEIVER.
Backward propagation, in an attempt to relate these receiver nodes to applicable Boto3
services, then takes place through the getBoto3 call.

The postcondition loads the batch API call, stored as variable BATCH_API_CALL, then
checks whether the result of the call is ignored through withOutputIgnoredFilter. This ﬁlter
checks whether the call node(s) ﬂowing into it deﬁne(s) a node that has no outgoing edges.

8.3 Other Representative Rules

We now switch to additional rules in the AWS best practices category, and provide an
explanation of what they each check for.

Use waiters in place of polling API: Waiters are utility methods that make it easy to wait
for a resource to transition into a desired state by abstracting out the polling logic into a
simple API call. The waiters interface provides a custom delay strategy to control the
sleep time between retries, as well as a custom condition on whether polling of a resource
should be retried. Our rules detect code that appears to be waiting for a resource before
it runs. In such cases, it recommends using the waiters feature to help improve eﬃciency.

Detect missing None check on cached response metadata: Response metadata represents additional

metadata included with a response from AWS. Response metadata varies by service,
but all services return an AWS request ID that can be used in the event a service
call isn’t working as expected. If the code attempts to access the response metadata,
ResponseMetadata, without performing a None check on the response object, then this

XX:28 Static Analysis for AWS Best Practices in Python Code

might cause a NoneType error. To prevent this, our rule recommends adding a None
check on the response object before accessing the response metadata.

Detect failed records in Kinesis PutRecords: The put_records operation in AWS Kinesis service
might fail, thereby causing loss of records. This rule detects if the code handles the
failed records from the put_records operation. In the absence of such handling of failed
records, the rule recommends checking the FailedRecordCount in the put_records response
to see if there are failed records in the response. A failed record includes ErrorCode and
ErrorMessage values. If failed records are found, the rule recommends adding them into
the next request.

Detect deprecated APIs: This rule detects usage of deprecated APIs in Python application
code. A total of 107 deprecated API speciﬁcations are extracted from Boto3. The
deprecated APIs are identiﬁed from the use of deprecated trait in the API models. These
API speciﬁcations are fed into the rule for detecting deprecated APIs in real world Python
code.

Detect ineﬃcient/redundant API chains: The rule for ineﬃcient/redundant API chains detects
usage of less performant APIs or outdated APIs, an API call chain that could be replaced
with a single API call, a manual pagination operation where the SDK provide a Paginator
API to automatically perform the pagination, and much more.

Detect expensive client object construction in Lambda handler: This rule detects a Boto3
client that is initialized from a Lambda handler.
In order to speed up Boto3 client
initialization and minimize the operational cost of the Lambda function, the rule
recommends creating the client at the level of the module that contains the handler, and
then reusing it between invocations. This is stated in the best practices for the lambda
handler.11

8.4 Engagement with the AWS SDK Team

Beyond their core value in alerting developers to bugs and improvement opportunities, the
AWS best practices rules enable unique collaboration between the CodeGuru and AWS SDK
teams.

From our side, we provide frequent feedback to the SDK team. Examples include developer
input that indicates a missing API feature or an API’s contract being unclear; pushback or
confusion in response to our suggested ﬁx for a best-practice violation; or customer demand
for a new rule.

The AWS SDK team has also contacted us. A recent example is the SDK V2 pagination
feature, where the SDK team wanted to promote awareness of this feature, and as part of
that (i) made sure that we have a corresponding rule, and (ii) took interest in the rule’s
messaging and performance in the ﬁeld.

9

Experimental Results

In this section, we report on experiments to validate our approach for on-demand resolution

of Python types. Our experiments are guided by the following research hypotheses:

Hypothesis 1: Skipping type inference, instead relying solely on function names and
arguments, is insuﬃcient since that might lead to excessively many false positive detections.

11 https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html#function-code)

R. Mukherjee, O. Tripp, B. Liblit, and M. Wilson

XX:29

Hypothesis 2: The dataﬂow-based and Pyright-with-stub-based resolution strategies have

complementary strengths.

Hypothesis 3: A staged approach, combining dataﬂow and stubs with name-based resolution

as a low-conﬁdence fallback, is eﬀective.

Hypothesis 4: The AWS best practices rules, running atop the staged algorithm, are

suﬃciently precise, eﬃcient and actionable to provide value during code review.

We note that beyond type inference, once a function call is conﬁrmed to invoke a given
AWS service, most of the rules are straightforward and do not require complex and/or
interprocedural analysis to detect incorrect or suboptimal use of the AWS API. There are
few exceptions, where the actual rule’s logic can be imprecise, but overall the correctness of
type inference is a good proxy for the correctness of a rule ﬁnding.

We illustrate rule dependence on identiﬁcation of the Boto3 service being invoked using the
JSON snippet below, which is taken from our service’s production conﬁguration. The “Missing
Pagination” rule, whose speciﬁcation is described in the snippet, searches for paginated
functions like list_dataset_groups in the speciﬁc context of the forecast AWS service. Recall
that these API speciﬁcations are automatically extracted from the API models in Boto3.

{

}

"expectedPaginationMethods": [

"IsTruncated",
"NextToken"

],
"paginatedMethod": "list_dataset_groups",
"resultKeys": [

"DatasetGroups"

],
"serviceId": "forecast"

9.1 Dataset

We have evaluated the strategies described in Section 7 using a dataset consisting of 3,027
public GitHub repositories. These repositories were selected based on the following criteria:

The repository contains Python source ﬁles (at least 3, and with a total of at least 100
lines of code).
The repository has an MIT or Apache license.
The repository has a rating of 3 stars or more.
The repository makes use of the AWS SDK.

We note that the overall number of repositories meeting the ﬁrst three criteria is 86,000.

Approximately 3.5% of these repositories either use or import the Boto3 library.

9.2 Performance of Resolution Strategies in Isolation

To examine the ﬁrst two hypotheses laid out above, we begin by computing precision and
recall for the diﬀerent type resolution strategies in isolation. Precision is measured as the
proportion of correct (TP) versus incorrect (FP) type resolutions, and recall is measured as
the proportion of correct (TP) versus missed (FN) type resolutions. In what follows, we use
the notation t[s] to refer to the type of SDK service client s.

XX:30 Static Analysis for AWS Best Practices in Python Code

Description

Conﬁdence Type Resolution Count Precision

Pyright with Boto3 type stubs
Dataﬂow tracking
API name based resolution

1
1
0.5

2,293
3,065
5,403

1
1
0.54

Table 1 Number of type resolutions due to each of the resolution strategies.

9.2.1 Type-Resolution Strategies

We consider 3 diﬀerent strategies for resolution of t[s]:

Strategy 1: Use Pyright’s type inference in conjunction with third-party Boto3 type stubs.
This strategy potentially recover types beyond the boundaries of a single function.
Strategy 2: Use interprocedural dataﬂow analysis, combining backward and forward queries.
Strategy 3: Match against the API name without attempting to resolve the type of the

receiver, which is an over-approximate yet cheap approach.

9.2.2 Results

Table 1 shows the number of resolutions due to each of the strategies when applied to the
GitHub dataset. To gain qualitative insight into the results, and how many of the type
resolutions are accurate, we manually reviewed 50 Boto3 client detections, selected at random,
for each of the three strategies for a total of 150 detections. Reviewers consisted of ﬁve senior
engineers and scientists, all expert users of the Boto3 library.

Our qualitative analysis suggests that strategies 1 and 2 are highly precise, as reported in
the “Precision” column of Table 1. All 50 cases sampled for manual review were judged as
correct. By contrast, for strategy 3, only 54% of the samples (27 out of 50) were correct.
By deﬁnition, strategy 3 achieves 100% recall and thus establishes an upper bound on the
number of false negatives due to strategies 1 and 2.

The set of detections obtained from strategy 1 and strategy 2 are not exactly the same,
and they do not subsume each other: some strategy-1 detections are omitted by strategy 2,
and vice versa. Out of 27 true positive detections from strategy 3, 19 detections are also
obtained from strategy 1 and strategy 2 combined. The remaining 8 detections ( 30%) are
exclusive to strategy 3.

9.2.3 Discussion

We consider the pros and cons of the three strategies in light of these results.

Strategy 1 uses third-party Boto3 type stubs, together with Pyright’s type inference
to resolve AWS SDK clients. Unlike strategy 2, where type resolution occurs during rule
evaluation, strategy 1’s Pyright-derived types are available before rule evaluation, during MU
graph construction. This allows type resolution to run once rather than on every application
of every rule: a major performance boost.

On the negative side, strategy 1 suﬀers from low recall, as shown in the “Type Resolution
Count” column of Table 1. This is due to the diﬀerent ways in which AWS SDK clients
are obtained, and in particular, the common case of passing them as function parameters.
Pyright does not search for callers of the function, thus assigning Any as the type of the
parameters unless annotations are explicitly provided.

R. Mukherjee, O. Tripp, B. Liblit, and M. Wilson

XX:31

Moving to strategy 2, the ability to perform backward dataﬂow tracking addresses the
challenge of passing AWS SDK clients as function parameters. Duplication of work on type
resolution is mitigated by a staged algorithm that ﬁrst attempts intraprocedural resolution,
then performs tracking at the ﬁle level, and ﬁnally at the level of the entire codebase. From
our experience, and performance measurements, the staged algorithm is quite eﬀective. Like
strategy 1, strategy 2 retains full precision, yet has much higher recall as shown in the “Type
Resolution Count” column of Table 1.

In spite of its overall eﬀectiveness, strategy 2 — which tracks dataﬂow through local
variables — can miss cases where the client is stored as a ﬁeld or global variable. These cases
are handled by strategy 1.

Our analysis of the gaps between strategies 1 and 2 is conﬁrmed experimentally. In line
with hypothesis 2, we have found 60 detections that are exclusive to strategy 1 and 832
detections that are exclusive to strategy 2.

Finally, the low precision of strategy 3 (just over 50%) conﬁrms hypothesis 1. At the
same time, the computational cost of strategy 3 is virtually zero, and thanks to its simplicity,
it is able to sometimes completely bypass complex tracking scenarios that are beyond the
power of strategies 1 and 2. An example is given in Figure 17, where neither strategy 1
nor strategy 2 is able to recognize that self._ec2_client is a Boto3 client in the body of
the ec2_client.describe_snapshots(∗∗kwargs) method. Strategy 3 succeeds here simply by
recognizing describe_snapshots as the name of an AWS SDK client API method.

To make use of strategy 3 in spite of its approximate nature, we “penalize” detections
due to this strategy by assigning a conﬁdence score of 0.5 to those detections compared
to 1.0 if the detection is due to strategies 1 or 2, as shown in the “Conﬁdence” column of
Table 1. The exact value of 0.5 is arbitrary, but serves to distinguish the lower-conﬁdence
detections of strategy 3 from the higher-conﬁdence detections of strategies 1 or 2. This is in
line with our earlier comment that the correctness of type resolution is a good proxy for the
correctness of a detection.

9.3 Performance of Combined Resolution Strategies

The results in Section 9.2.1 suggest that there is beneﬁt in combining the diﬀerent strategies
in light of their complementary strengths. Starting from this motivation, we report here on
experiments with “hybrid” resolution strategies, which we refer to as conﬁgurations.

9.3.1 Type Resolution Conﬁgurations

We consider two conﬁgurations:

High Conﬁdence (HC) runs strategy 1, then strategy 2 where needed to complement

strategy 1.

Mixed Conﬁdence (MC) runs strategies 1 and 2 in the same fashion as HC, but rather than
giving up if both fail, proceeds to strategy 3 in an attempt to generate a low-conﬁdence
detection.

CodeGuru uses the conﬁdence score to rank the detections as per the “Conﬁdence” column
in Table 1. Detections from strategy 1 and strategy 2 rank higher than detections from
strategy 3 thanks to their higher conﬁdence score. CodeGuru imposes diﬀerent restrictions and
limitations on detectors, in particular with regard to the overall number of detections, which
means that in the presence of suﬃciently many high-conﬁdence detections, low-conﬁdence

XX:32 Static Analysis for AWS Best Practices in Python Code

class AwsClient(object):

def __init__(self, ∗args, ∗∗kwargs):

self._boto3client = None
super(AwsClient, self).__init__(∗args, ∗∗kwargs)

def create_ec2_client(self, context=None):
#→ (method) create_ec2_client:

(self: Self@AwsClient, context=None) −> Any

access_key = CONF.aws.aws_access_key
secret_key = CONF.aws.aws_secret_key
region_name = CONF.aws.aws_region
kwargs = {}
kwargs['aws_access_key_id'] = access_key
kwargs['aws_secret_access_key'] = secret_key
kwargs['region_name'] = region_name

return boto3.client('ec2', ∗∗kwargs)

def get_aws_client(self, context):
if not self._boto3client:

try:

ec2_client = self.create_ec2_client(context)
#→ (variable) ec2_client: Any
self._boto3client = AwsClientPlugin(ec2_client)
#→ (variable) _boto3client: Any

except Exception as e:

LOG.error(_LE('Create aws client failed: \%s'), e)
raise exception_ex.OsAwsConnectFailed

return self._boto3client

def describe_snapshots(self, ∗∗kwargs):

response = self._ec2_client.describe_snapshots(∗∗kwargs)
#→ (variable) _ec2_client: Any
snapshots = response.get('Snapshots', [])
return snapshots

Figure 17 Detections from Strategy 3 that strategies 1 and 2 miss

R. Mukherjee, O. Tripp, B. Liblit, and M. Wilson

XX:33

Conﬁguration

Strategies Description

Number of Detections

HC
MC

1, 2
1, 2, 3
Table 2 Type Inference Conﬁgurations

Pyright with stubs followed by dataﬂow
All layers

3,125
5,403

detections are suppressed. By implication, low-conﬁdence MC detections are not always
reported to the user.

9.3.2 Results

Table 2 reports results for both conﬁgurations, running against the dataset of 3,027 GitHub
repositories. The total time for running each conﬁguration is close to 5 hours.

In line with hypothesis 2, the HC conﬁguration generates more detections than strategies
1 or 2 in isolation. The total number of detections due to the HC conﬁguration is 60 more
than strategy 2: exactly the number of detections that are exclusive to strategy 1.

Moving to the MC conﬁguration, the number of detections that it generates is identical
to strategy 3 in isolation, which is expected. The important diﬀerence, however, is that most
(that is, 3,125) of the detections have high conﬁdence, with only 2,278 detections relying on
strategy 3.

Projecting from the detections we sampled and triaged, we estimate that the MC
conﬁguration has a precision score of 0.85 along with perfect recall, whereas the HC
conﬁguration has perfect precision but a recall score of roughly 0.72 (with the assumption
that 54% of the ﬁndings found by MC but not HC are true positives). This analysis supports
hypothesis 3, which favors use of strategy 3 as part of the combined strategy rather than
relying only on the high-conﬁdence strategies.

9.4 Real-world Feedback on the Rules

Beyond our oﬄine study, we also report on data from the ﬁeld driven by comments that
CodeGuru has left on code reviews in production. In this use case, CodeGuru posts comments
on code reviews just as a human reviewer would. We have augmented the comment UI with a
feedback menu, so that a developer can optionally rate a detection as “Useful”, “Not Useful”
or “Not Sure” and/or provide free-form textual feedback. These feedback mechanisms give
the CodeGuru team insight into the performance of diﬀerent detectors and enable detector
tuning over time.

For AWS best practices, each CodeGuru comment contains two key ﬁelds:

1. One or two paragraphs explain what the issue is, and why ﬁxing it is important. For
example, in the case of a batch operation whose output is ignored, the explanation states
that even if some items are not processed successfully, the batch operation might still
complete successfully without raising an exception.

2. A “Learn More” hyperlink directs the user to the appropriate section in the Boto3 online

documentation for complete information on the API in question.

We provide lower-bound metrics to give a sense of the size of CodeGuru’s input funnel.
In the studied time period of 10 weeks, CodeGuru analyzed (cid:29) 1, 000, 000 lines of code. We
applied (cid:29) 10 detectors, yielding (cid:29) 10, 000 AWS best practice recommendations, which we
reported to (cid:29) 1, 000 developers.

XX:34 Static Analysis for AWS Best Practices in Python Code

Rule

Acceptance Rate

Detect missing Pagination
Data loss in Batch APIs
Use Waiters instead of Polling APIs
Detect failed Records in Kinesis PutRecords
Detect deprecated APIs
Detect usage of ineﬃcient/redundant API chains
Missing None check on cached response metadata
Detect expensive client object construction in Lambda handler

0.75
1
0.52
1
0.89
0.86
0.86
0.76

Table 3 Acceptance rate per rule from developer feedback during code review

Detection Group High Conﬁdence Detections Proportion

Low Conﬁdence Detections Proportion

All
Accepted
Not Accepted

0.88
0.93
0.84

0.12
7 · 10−2
0.16

Table 4 Breakdown of the detections from Table 3 by conﬁdence level

We note that by deﬁnition, the codebases involved in this study are all live (undergoing
code reviews and modiﬁcations). These are Python cloud services and applications that
make use of Boto3, where the developers are industry practitioners with Python and cloud
background. Hence we assign high weight to their feedback on CodeGuru detections.

In CodeGuru, we measure acceptance as an indication of whether or not developers have
found a given rule’s review comments useful. Given a set of “Useful” (U ), “Not Useful” (NU )
and “Not Sure” (NS) ratings, we compute acceptance as the ratio

|U |
|U | + |NU | + |NS|

where by |U | we mean the number of “Useful” feedback points, and analogously for NU and
NS. Note, importantly, that we conservatively treat “Not Sure” the same as “Not Useful”.
Table 3 shows the acceptance data for eight of the Python AWS best practices rules for a
time period of 10 weeks. We obtained (cid:29) 100 feedback points from a population of (cid:29) 100
developers through the feedback UI described above. As reported in Table 3, developers
accepted over 85% of the recommendations made by ﬁve out of the eight rules, and almost
83% of the overall recommendations.

Only one of the eight rules, “Use Waiters instead of Polling APIs”, has an acceptance rate
below 75%. Our analysis of this rule’s performance, including communication with some of
the developers who left feedback on its detections, suggests that the gap between acceptance
and correctness is important. Developers often acknowledge the detection as correct, but
push back for one or more of the following reasons:

The intent of the PR is diﬀerent, and they prefer not to merge multiple unrelated changes
into the same PR.
The change is applicable, but requires upgrading the codebase to use the latest AWS
Python SDK, which again exceeds the scope of the PR.
The change is not applicable, since the code in question is test code or there is no concern
about polling in the given context.

R. Mukherjee, O. Tripp, B. Liblit, and M. Wilson

XX:35

It is worth adding that outside the time period reported here, we have seen multiple weeks
where acceptance rate for “Use Waiters instead of Polling APIs” was high.

Overall, acceptance data from the ﬁeld supports hypothesis 3 in showing that developers
mostly ﬁnd the detections by to the Python AWS best practices rules useful. These are made
using the MC conﬁguration, which integrates all three of the resolution strategies described
in Section 9.2.1.

From our conversations with developers, the textual feedback they provided, and our own
review of some of the detections and their corresponding feedback, we have identiﬁed two
main factors that contribute to the usefulness of our rules:

Missed features: SDK changes across versions, in particular new features, are sometimes
missed by developers. Pagination, retry and error handling are examples of such features,
where developers not familiar with these built-in capabilities sometimes implement
“manual” mechanisms instead. Another example is manual polling versus the recommended
use of the waiter utility.
Missed expectations: Developers sometimes assume, rather than verify, the functionality of
a given API or the role of a given parameter. An example is the QueryResponse::hasItems
method, whose (boolean) return value is sometimes incorrectly interpreted to mean that
the response contains a non-empty collection of items, where what is in fact meant is
that response deﬁnes an Items property. To make sure whether any items are contained
in the response, the developer needs to also check Items::isEmpty. Mistakes like this can
lead to large-scale operational failures.

Table 4 reports the breakdown, by conﬁdence level (high versus low), for the detections in
Table 3. In sharp contrast to the distribution due to strategy 3 from the oﬄine study, where
approximately 45% of the detections had a low conﬁdence score, the hybrid inference strategy
leans heavily towards high-conﬁdence detections (88% of all detections). This is consistent
with the suppression policy described above, in Section 9.3.1, for low-conﬁdence detections.
The tradeoﬀ that the hybrid strategy oﬀers in the presence of conﬁdence-based suppression
is appealing, in that low-conﬁdence detections are typically shadowed by high-conﬁdence
detections, which limits the impact of such detections on precision and allows them to play an
important role in pushing coverage upwards when high-conﬁdence detections are absent. Also
note, from Table 4, that the proportion of low-conﬁdence detections among “Not Accepted”
detections is higher compared to “Accepted” detections (16% versus 7%), which is consistent
with the data from the oﬄine study.

Overall, our analysis of detections from the ﬁeld, and how these map back to the hybrid
strategy, are in support of hypothesis 4. Developers tend to view our AWS best practices
recommendations as useful. Most of the recommendations build on high-conﬁdence type
inference, with some remaining cases beneﬁtting from the low-conﬁdence resolution strategy.

10

Conclusion and Future Work

We have presented an industrial-strength framework for precise static analysis of Python
applications that use AWS cloud services. In support of this goal, we have developed a
novel type inference system for identifying and tracking AWS service clients in real-world
Python applications. Our Python MU graph IR is suitable for building a wide range of static
analyses or best-practice rules for Python applications. Furthermore, the Golden Query
Language provides the right level of abstraction with its encapsulation, optimization and
reuse features to develop static analysis rules that can be evaluated at diﬀerent scopes, from
single functions to entire applications.

XX:36 Static Analysis for AWS Best Practices in Python Code

Builder API

Description

as

check

reset

Stores the current match frontier as the speciﬁed variable.

Transitions from precondition to postcondition evaluation.

Resets the match frontier to all graph nodes.

withAuxiliaryState

Sets arbitrary mutable state to be consulted, and manipulated,
during rule evaluation.

withComment

Sets the rule’s comment (or description).
withCommentOverride Overrides the current rule comment while optionally taking the
current evaluation context into account.

withGraphics

withId

withInstrumentation

Outputs a visual representation of the target code that highlights
matched nodes (useful for debugging purposes).

Loads the node set mapped to the provided id.

Enables (read-only) inspection of the current match frontier, for
example to debug a rule or compute metrics.

withName

Sets the rule’s name.

Table 5 Representative collection of GQL core operations

Experiments on 86K open-source Python GitHub repositories show that individual
inference strategies have complementary strengths. The most eﬀective solution, then, is
a layered approach that combines Pyright with Boto3 stubs, custom dataﬂow analysis in
GQL, and name-based resolution as a low-conﬁdence fallback. Our layered strategy achieves
85% precision and 100% recall in typing relevant Boto3 values in Python client code. The
ultimate authorities on the value of our approach are real-world developers, with no ties to
the authors. Those developers accepted more than 85% of the recommendations made by
ﬁve out of eight rules, and roughly 83% of the recommendations on average.

In the future, we plan to extend and generalize our type inference infrastructure to other
rule suites and properties that apply to Python programs. We are also examining ways to
reuse our work on Python on-demand type inference when adding support for other languages
sans static typing.

A

Additional GQL Operations

Section 6.4 walked the reader through four categories of GQL operations: core, ﬁlter,
transform, and second-order operations. We revisit these categories here, and provide
additional representative examples of operations from each of these categories. These are not
exhaustive, and are shared with the purpose of conveying a more complete illustration of the
capabilities that GQL oﬀers.

A.1 Representative Core Operations

Table 5 lists a representative subset of the GQL core operations. Some have already been
explained. We explain a few more below.

withInstrumentation allows access to intermediate match frontiers throughout rule evaluation.

Consider for example the below rule snippet:

R. Mukherjee, O. Tripp, B. Liblit, and M. Wilson

XX:37

.withMethodCallFilter("foo")
.withInstrumentation(mr −> System.out.println(mr))

Here mr denotes the match frontier post the function-call ﬁlter. Given a function that
contains one or more such calls, those matches would be printed using println. This is a
simple illustration of how withInstrumentation can help with debugging tasks, or other use
cases such as proﬁling or analytics.

Another handy construct is reset. A common use for this construct is sequencing of

independent operations. Here is an example:

.withMethodCallFilter("foo")
.as("fooCalls")
.reset()
.withMethodCallFilter("bar")

The rule ﬁrst scans for “foo” calls and stores these as variable "fooCalls", then performs an
unrelated search for "bar" calls.

A.2 Representative Filter Operations

Table 6 describes representative GQL ﬁlter operations.

Note that some of these operations operate on IDs, as managed through the as and withId
constructs. As an example, withReceiverByIdFilter takes the ID of a stored match frontier as
input, and allows through incoming function calls that have as their receiver a node belonging
in that match frontier.

We also note that the ﬁlters perform analysis of varying depth behind the scenes.
withActionFilter is an example of a basic ﬁlter that simply pattern matches against action
nodes in the incoming match frontier, whereas withConstantArgumentFilter is an advanced
ﬁlter that performs constant propagation, and even a limited form of string analysis, to track
and compute constant values.

Table 6: Representative collection of GQL ﬁlter operations

Builder API
withActionFilter

withArgumentByTypeFilter

withArgumentContextFilter

withArgumentValueFilter

withCatchClauseFilter

withCaughtExceptionFilter

Description

Accepts actions matching the provided regex.

Accepts action and control nodes with an
argument whose type matches the provided regex.

Accepts action nodes having an argument deﬁned
in the provided syntactic context (for example,
loop, conditional or switch statement).

Accepts action nodes with a matching argument
(multiple overloads).

Accepts action nodes with a corresponding catch
clause.

Accepts action nodes with a target catch clause
whose exception matches the provided regex.

Continued on next page

XX:38 Static Analysis for AWS Best Practices in Python Code

Table 6: Representative collection of GQL ﬁlter operations (Continued)

Builder API
withConstantArgumentFilter

withContextFilter

withControlUserFilter

withDataByNameFilter

withDataByTypeFilter

withDataFromIdFilter

withDataFromParameterFilter

withDataFromResultFilter

withDeclaringTypeFilter

Description

Accepts action nodes with a constant argument
matching the provided regex.

Accepts nodes that reside within the provided
control context.

Accepts nodes used by the speciﬁed control
constructs (like do, while, and so on).

Accepts data nodes whose name matches the
provided regex.

Accepts data nodes whose type matches the
provided regex.

Accepts nodes that receive data (transitively)
from nodes mapped to the provided id.

Accepts nodes that receive data (transitively)
from function parameters.

Accepts nodes that receive data (transitively)
from a node (possibly) returned by the function.

Accepts function calls whose enclosing type
matches the provided regex.

withDownstreamConditionalCheckFilter Accepts nodes whose data ﬂows (transitively)

withLocalDataFromIdFilter

withLowerCaseArgumentFilter

withMethodCallFilter

withMethodCallGroupFilter

withNodeByTypeFilter

withNumberOfArgumentsFilter

withReceiverByIdFilter

withReceiverByTypeFilter

into a conditional check (including loop tests).

Same as above, but with the restriction to local
data ﬂow (blocking ﬂow across function calls).

Accepts action nodes with a constant lower-case
string argument.

Accepts function calls matching the provided
regex.

Accepts a group of calls if their names, and how
they relate to each other, meet the spec (for
example, if they share the same receiver or are
ordered as speciﬁed).

nodes

whose

corresponding
Accepts
AST node
provided
the
type matches
speciﬁcation (for example, ARRAY_ACCESS or
CAST_EXPRESSION).

Accepts action nodes with the provided number
of arguments.

Accepts action nodes whose receiver is mapped
to the provided id.

Accepts action nodes with a receiver whose type
matches the provided regex.

Continued on next page

R. Mukherjee, O. Tripp, B. Liblit, and M. Wilson

XX:39

Builder API

Description

withArgumentsTransform

Transforms an action node to its
arguments.

respective

withCatchClauseTransform

Transforms an action node to its target catch nodes.
withControlDependenciesTransform Transforms a node to its set of control dependencies.
withDataDependenciesTransform

Transforms a node to its set of (transitive) data
dependencies.

withDataDependentsTransform

withDeﬁnitionTransform

withTaintFlowFromTransform

withTaintFlowToTransform

withReceiverTransform

withThenTransform

Transforms a node to the set of nodes that are data
dependent on it.

Transforms data nodes to their deﬁning action node
(if exists).

Transforms a node treated as a “sink” to the “source”
nodes that reach it, where the taint speciﬁcation is
provided through this API’s arguments.

Transforms a node treated as a “source” to the “sink”
nodes that it reaches, where the taint speciﬁcation is
provided through this API’s arguments.

Transforms an action node with a receiver to the
receiver, or else ∅ for actions sans receiver.

Transforms nodes to the nodes that occur after them
per the control-ﬂow relation.

withUsersTransform

Transforms a data node to its users.

Table 7 Representative collection of GQL transform operations

Table 6: Representative collection of GQL ﬁlter operations (Continued)

Builder API
withReturnValueFilter

withUpperCaseArgumentFilter

withUserFilter

Description

Accepts data nodes that are (possibly) returned
by the function.

Accepts action nodes with a constant upper-case
string argument.

Accepts data nodes that have users matching the
provided regex.

A.3 Representative Transform Operations

Table 7 presents a small subset of the GQL transform operations. Notice in particular the
data-ﬂow and taint constructs. These are used extensively across GQL rules, especially in
the security category, and enable advanced tracking features (like rule-speciﬁc combinations
of forward and backward tracking, or use of diﬀerent taint conﬁgurations within and across
rules).

XX:40 Static Analysis for AWS Best Practices in Python Code

Builder API

withAllOf

withAdditional

withAllOf

withAnyOf

withClosure

Description

Evaluates to a relational mapping from subrules to their
respective result node sets if all are successful, or else ∅.

Evaluates to the union of the result due to the subrule provided
as argument and the incoming match frontier.

Evaluates to a relational mapping from subrules to their
respective result node sets if all evaluate successfully, or else ∅.

Evaluates to a relational mapping from subrules to their
respective result node sets.

Evaluates to the result of the subrule provided as argument,
which is the recommended way to integrate helper functions
into a GQL rule.

withIndependent

Evaluates to the result of the subrule provided as argument.
withInterproceduralMatch Applies the provided subrule to an interprocedural scope. The

withLanguageSpeciﬁc

withNegationOf

withOneOf

scope, and how to traverse it, are speciﬁed by the user.

Contains language-speciﬁc subrules. The appropriate subrule
is selected per the program’s source language.

Evaluates to the negation of the subrule provided as argument:
∅ if the subrule has a non-empty result, or else the input node
set.

Evaluates to the ﬁrst successful subrule if exists, or else
evaluates to ∅.

Table 8 Representative collection of GQL second-order operations

A.4 Representative Second-order Operations

Table 8 shows a subset of GQL’s second-order operations. We discuss several additional
constructs beyond those already described.

The withNegationOf construct accepts a single subrule, and checks for the negation of
its evaluation. That is, withNegationOperation evaluates to the input match frontier if the
subrule evaluates to ∅, or else it evaluates to ∅. Here is an example:

.withNegationOf(b −> b.withMethodCallFilter("foo"))

If the incoming frontier contains a foo call, then the negation operation fails. Otherwise, the
incoming frontier is propagated through withNegationOf.

A useful construct in the case of multi-language rules is withLanguageSpeciﬁc. Loosely,
this construct acts like a switch statement, enabling the user to provide per-language subrules
to implement certain rule steps (whereas other steps are shared across diﬀerent languages).
If for example the rule enforces correct use of a paginated DynamoDB API, the ﬁrst step
being to ensure that the call is against a DynamoDB client, then withLanguageSpeciﬁc helps
with this task by allowing the user to check (i) the type of the receiver in the case of Java,
and (ii) the deﬁnition of the receiver — using our staged type inference algorithm — in the
case of Python.

R. Mukherjee, O. Tripp, B. Liblit, and M. Wilson

XX:41

References

1 Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeﬀrey Dean, Matthieu
Devin, Sanjay Ghemawat, Geoﬀrey Irving, Michael Isard, Manjunath Kudlur, Josh Levenberg,
Rajat Monga, Sherry Moore, Derek Gordon Murray, Benoit Steiner, Paul A. Tucker, Vijay
Vasudevan, Pete Warden, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. Tensorﬂow: A
system for large-scale machine learning. In Kimberly Keeton and Timothy Roscoe, editors,
12th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2016,
Savannah, GA, USA, November 2-4, 2016, pages 265–283. USENIX Association, 2016. URL:
https://www.usenix.org/conference/osdi16/technical-sessions/presentation/abadi.
Sven Amann, Hoan Anh Nguyen, Sarah Nadi, Tien N. Nguyen, and Mira Mezini. Investigating
next steps in static API-misuse detection. In Margaret-Anne D. Storey, Bram Adams, and
Sonia Haiduc, editors, Proceedings of the 16th International Conference on Mining Software
Repositories, MSR 2019, 26-27 May 2019, Montreal, Canada, pages 265–275. IEEE / ACM,
2019. doi:10.1109/MSR.2019.00053.
Sven Amann, Hoan Anh Nguyen, Sarah Nadi, Tien N. Nguyen, and Mira Mezini. A systematic
evaluation of static API-misuse detectors. IEEE Trans. Software Eng., 45(12):1170–1188, 2019.
doi:10.1109/TSE.2018.2827384.

2

3

4 Davide Ancona, Massimo Ancona, Antonio Cuni, and Nicholas D. Matsakis. RPython: a
step towards reconciling dynamically and statically typed OO languages. In Pascal Costanza
and Robert Hirschfeld, editors, Proceedings of the 2007 Symposium on Dynamic Languages,
DLS 2007, October 22, 2007, Montreal, Quebec, Canada, pages 53–64. ACM, 2007. doi:
10.1145/1297081.1297091.

6

5 David F. Bacon and Peter F. Sweeney. Fast static analysis of C++ virtual function calls.
In Lougie Anderson and James Coplien, editors, Proceedings of the 1996 ACM SIGPLAN
Conference on Object-Oriented Programming Systems, Languages & Applications (OOPSLA
’96), San Jose, California, USA, October 6-10, 1996, pages 324–341. ACM, 1996. doi:
10.1145/236337.236371.
Siwei Cui, Gang Zhao, Zeyu Dai, Luochao Wang, Ruihong Huang, and Jeﬀ Huang. PYInfer:
Deep learning semantic type inference for Python variables. CoRR, abs/2106.14316, 2021.
URL: https://arxiv.org/abs/2106.14316, arXiv:2106.14316.
Julian Dolby, Avraham Shinnar, Allison Allain, and Jenna M. Reinen. Ariadne: analysis for
machine learning programs. In Justin Gottschlich and Alvin Cheung, editors, Proceedings
of the 2nd ACM SIGPLAN International Workshop on Machine Learning and Programming
Languages, MAPL@PLDI 2018, Philadelphia, PA, USA, June 18-22, 2018, pages 1–10. ACM,
2018. doi:10.1145/3211346.3211349.

7

9
10

8 Vlad Emelianov. mypy_boto3_builder: Type annotations builder for boto3 compatible
with VSCode, PyCharm, Emacs, Sublime Text, pyright and mypy [online]. URL: https:
//vemel.github.io/mypy_boto3_builder/ [cited 2021-12-01].
Facebook. Pyre [online]. URL: https://pyre-check.org/ [cited 2021-11-30].
Levin Fritz and Jurriaan Hage. Cost versus precision for approximate typing for Python.
In Ulrik Pagh Schultz and Jeremy Yallop, editors, Proceedings of the 2017 ACM SIGPLAN
Workshop on Partial Evaluation and Program Manipulation, PEPM 2017, Paris, France,
January 18-20, 2017, pages 89–98. ACM, 2017. doi:10.1145/3018882.3018888.

11 Aymeric Fromherz, Abdelraouf Ouadjaout, and Antoine Miné. Static value analysis of Python
programs by abstract interpretation. In Aaron Dutle, César A. Muñoz, and Anthony Narkawicz,
editors, NASA Formal Methods - 10th International Symposium, NFM 2018, Newport News,
VA, USA, April 17-19, 2018, Proceedings, volume 10811 of Lecture Notes in Computer Science,
pages 185–202. Springer, 2018. doi:10.1007/978-3-319-77935-5\_14.
Erich Gamma, Richard Helm, Ralph E. Johnson, and John M. Vlissides. Design patterns:
Abstraction and reuse of object-oriented design. In Oscar Nierstrasz, editor, ECOOP’93 -
Object-Oriented Programming, 7th European Conference, Kaiserslautern, Germany, July 26-30,

12

XX:42 Static Analysis for AWS Best Practices in Python Code

1993, Proceedings, volume 707 of Lecture Notes in Computer Science, pages 406–431. Springer,
1993. doi:10.1007/3-540-47910-4\_21.

13 Google. pytype [online]. URL: https://google.github.io/pytype/ [cited 2021-11-30].
14 David Grove and Craig Chambers. A framework for call graph construction algorithms. ACM

Trans. Program. Lang. Syst., 23(6):685–746, 2001. doi:10.1145/506315.506316.

15 Mostafa Hassan, Caterina Urban, Marco Eilers, and Peter Müller. MaxSMT-based type
In Hana Chockler and Georg Weissenbacher, editors, Computer
inference for Python 3.
Aided Veriﬁcation - 30th International Conference, CAV 2018, Held as Part of the Federated
Logic Conference, FloC 2018, Oxford, UK, July 14-17, 2018, Proceedings, Part II, volume
10982 of Lecture Notes in Computer Science, pages 12–19. Springer, 2018. doi:10.1007/
978-3-319-96142-2\_2.

16 Vincent J. Hellendoorn, Christian Bird, Earl T. Barr, and Miltiadis Allamanis. Deep learning
type inference. In Gary T. Leavens, Alessandro Garcia, and Corina S. Pasareanu, editors,
Proceedings of the 2018 ACM Joint Meeting on European Software Engineering Conference
and Symposium on the Foundations of Software Engineering, ESEC/SIGSOFT FSE 2018,
Lake Buena Vista, FL, USA, November 04-09, 2018, pages 152–162. ACM, 2018. doi:
10.1145/3236024.3236051.

17 Maximilian A. Köhl. An executable structural operational formal semantics for Python.
Master’s thesis, Saarland University, December 2020. URL: https://arxiv.org/abs/2109.
03139.
Jukka Lehtosalo, Guido van Rossum, Ivan Levkivskyi, and Michael J. Sullivan. mypy - optional
static typing for Python [online]. URL: http://mypy-lang.org/ [cited 2021-11-30].

18

19 Microsoft. Pyright: Static type checker for Python [online]. URL: https://github.com/

microsoft/pyright [cited 2021-11-30].

21

20 Raphaël Monat, Abdelraouf Ouadjaout, and Antoine Miné. Static type analysis by abstract
interpretation of Python programs. In Robert Hirschfeld and Tobias Pape, editors, 34th
European Conference on Object-Oriented Programming, ECOOP 2020, November 15-17, 2020,
Berlin, Germany (Virtual Conference), volume 166 of LIPIcs, pages 17:1–17:29. Schloss
Dagstuhl - Leibniz-Zentrum für Informatik, 2020. doi:10.4230/LIPIcs.ECOOP.2020.17.
Joe Gibbs Politz, Alejandro Martinez, Matthew Milano, Sumner Warren, Daniel Patterson,
Junsong Li, Anand Chitipothu, and Shriram Krishnamurthi. Python: the full monty. In
Antony L. Hosking, Patrick Th. Eugster, and Cristina V. Lopes, editors, Proceedings of the
2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems
Languages & Applications, OOPSLA 2013, part of SPLASH 2013, Indianapolis, IN, USA,
October 26-31, 2013, pages 217–232. ACM, 2013. doi:10.1145/2509136.2509536.

22 Michael Pradel, Georgios Gousios, Jason Liu, and Satish Chandra. TypeWriter: neural type
prediction with search-based validation. In Prem Devanbu, Myra B. Cohen, and Thomas
Zimmermann, editors, ESEC/FSE ’20: 28th ACM Joint European Software Engineering
Conference and Symposium on the Foundations of Software Engineering, Virtual Event, USA,
November 8-13, 2020, pages 209–220. ACM, 2020. doi:10.1145/3368089.3409715.

23 Veselin Raychev, Martin T. Vechev, and Andreas Krause. Predicting program properties from
"big code". In Sriram K. Rajamani and David Walker, editors, Proceedings of the 42nd Annual
ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL 2015,
Mumbai, India, January 15-17, 2015, pages 111–124. ACM, 2015. doi:10.1145/2676726.
2677009.

24 Michael Salib. Starkiller : a static type inferencer and compiler for Python. PhD thesis,

Massachusetts Institute of Technology, May 2004.

25 Gideon Joachim Smeding. An executable operational semantics for Python. Master’s thesis,
Universiteit Utrecht, 2008. URL: http://www.cs.uu.nl/education/scripties/scriptie.
php?SID=INF/SCR-2008-029.

26 Michael M. Vitousek, Andrew M. Kent, Jeremy G. Siek, and Jim Baker. Design and evaluation
of gradual typing for python. In Andrew P. Black and Laurence Tratt, editors, DLS’14,

R. Mukherjee, O. Tripp, B. Liblit, and M. Wilson

XX:43

27

28

Proceedings of the 10th ACM Symposium on Dynamic Languages, part of SLASH 2014,
Portland, OR, USA, October 20-24, 2014, pages 45–56. ACM, 2014. doi:10.1145/2661088.
2661101.
Jiayi Wei, Maruth Goyal, Greg Durrett, and Isil Dillig. LambdaNet: Probabilistic type inference
using graph neural networks. In 8th International Conference on Learning Representations,
ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net, 2020. URL: https:
//openreview.net/forum?id=Hkx6hANtwH.
Zhaogui Xu, Xiangyu Zhang, Lin Chen, Kexin Pei, and Baowen Xu. Python probabilistic type
inference with natural language support. In Thomas Zimmermann, Jane Cleland-Huang, and
Zhendong Su, editors, Proceedings of the 24th ACM SIGSOFT International Symposium on
Foundations of Software Engineering, FSE 2016, Seattle, WA, USA, November 13-18, 2016,
pages 607–618. ACM, 2016. doi:10.1145/2950290.2950343.

