0
2
0
2

g
u
A
3
2

]

C
O
.
h
t
a
m

[

2
v
7
0
1
0
0
.
5
0
9
1
:
v
i
X
r
a

STATISTICAL LEARNING FOR PROBABILITY-CONSTRAINED STOCHASTIC

OPTIMAL CONTROL

ALESSANDRO BALATA∗, MICHAEL LUDKOVSKI† , ADITYA MAHESHWARI† , AND JAN PALCZEWSKI∗

Abstract. We investigate Monte Carlo based algorithms for solving stochastic control problems with local probabilistic
constraints. Our motivation comes from microgrid management, where the controller tries to optimally dispatch a diesel
generator while maintaining low probability of blackouts at each step. The key question we investigate are empirical
simulation procedures for learning the state-dependent admissible control set that is speciﬁed implicitly through a probability
constraint on the system state. We propose a variety of relevant statistical tools including logistic regression, Gaussian
process regression, quantile regression and support vector machines, which we then incorporate into an overall Regression
Monte Carlo (RMC) framework for approximate dynamic programming. Our results indicate that using logistic or Gaussian
process regression to estimate the admissibility probability outperforms the other options. Our algorithms oﬀer an eﬃcient
and reliable extension of RMC to probability-constrained control. We illustrate our ﬁndings with two case studies for the
microgrid problem.

Key words. Machine learning, stochastic optimal control, probabilistic constraints, regression Monte Carlo, microgrid

control

AMS subject classiﬁcations. 93E20, 93E35, 49L20

1. Introduction. Stochastic control with probabilistic constraints is a natural relaxation of deter-

ministic restrictions which tend to generate high costs forcing the avoidance of extreme events no matter

their likelihood of occurrence. In contrast, with probabilistic constraints, constraint violation is toler-

ated up to a certain level oﬀering a better trade-oﬀ between admissibility and cost. We refer to [16]

for an overview of probability-constrained problems and list below some of our motivating settings and

references:

1. Microgrid management: An electric power microgrid is a collection of intermittent renewable

generator units, a conventional dispatchable diesel generator (or grid interconnection), and a

battery energy storage system. The microgrid supplies electricity to a community in islanded

mode, balancing ﬂuctuating demand and supply. The operator achieves this by optimizing the

use of the battery storage and the back-up dispatchable generator. Since perfect balancing is

very expensive, it is common to allow for a small frequency of blackouts, i.e. occurrences where

demand outstrips supply. Mixed-integer linear programming approaches to this problem through

approximating with more conservative convex constraints appear in [23, 34].

2. Hydropower optimization: control of a hydropower dam with probabilistic constraints was dis-

cussed in [2]. Within this setup, the controller observes random inﬂows from precipitation, as

well as ﬂuctuating electricity prices. His objective is to control the downstream outﬂow from the
dam to maximize proﬁt from power sales, while ensuring a minimum dam capacity with high

∗School of Mathematics, University of Leeds, Woodhouse Lane, Leeds LS2 9JT, United Kingdom (alessan-

dro.balata@live.com; J.Palczewski@leeds.ac.uk).

†Department of Statistics and Applied Probability, University of California, Santa Barbara, CA 93106 USA (lud-

kovski@pstat.ucsb.edu; maditya0310@gmail.com).

Funding: Michael Ludkovski and Aditya Maheshwari were supported in part by NSF grant DMS-1736439. Alessandro

Balata was supported by the Natural Environment Research Council Doctoral training partnership Leeds-York

Corresponding Author: Aditya Maheshwari

1

 
 
 
 
 
 
2

A. BALATA, M. LUDKOVSKI, A. MAHESHWARI AND J. PALCZEWSKI

probability. Other related works are [3, 32, 37].

3. Motion planning: ﬁnding the minimum-cost path for a robot from one location to another while

avoiding colliding with objects that obstruct its path. Stochasticity in the environment implies

that the robot motion is only partially controlled. Robust optimization that guarantees obstacle

avoidance might be infeasible, making probabilistic constraints a viable alternative. Dynamic

programming methods for unmanned aerial vehicles were introduced in [33] and the probabilistic-

constrained motion of a robot was solved in [18].

Contribution. We consider state-dependent probabilistic constraints that are expressed through

an expectation constraint at each system state. Our setup involves a continuous-state, continuous-time

model with a discrete-step control, where the constraints are imposed step-by-step. Therefore, at each

step and at each state, the controller must estimate which controls are admissible and then optimize

over the latter. While this setting is simpler than global probabilistic constraints, it is much harder

than unconstrained control, because a secondary numerical procedure is needed as part of dynamic

programming to repeatedly compute the admissibility sets. The canonical setup involves ﬁnite-horizon

control of a stochastic process described through a stochastic diﬀerential equation of Itˆo type. The solution

paradigm involves the Bellman or Dynamic Programming equation (DPE), which works with discretized

time-steps, but with a smooth spatial variable. In this context, we develop algorithms to solve stochastic

optimal control problems with probabilistic constraints using regression Monte Carlo (RMC). To make this
highly nontrivial extension to RMC, we investigate tools from machine learning (including support vector

machines (SVM), Gaussian process (GP) regression, parametric density estimation, logistic regression and

quantile regression) to statistically estimate the admissible set as a function of the system state. Our

algorithm handles the two parts of the problem—the constraint estimation and the approximation of the

conditional expectation—in parallel and with signiﬁcantly lower simulation budget compared to a naive

implementation.

After benchmarking the proposed approaches on two practical case-studies from energy battery man-

agement, our main ﬁnding is to recommend logistic regression and GP-smoothed probability estimation

as the best procedures. These methods are stable, relatively fast and allow for a variety of further

adjustments and speed-ups.

In contrast, despite theoretical appeal, quantile regression and SVM are

not well-suited for this task. On a higher level, our main take-away is that DPE-based stochastic con-

trol with probabilistic constraints (SCPC) is well within reach of cutting-edge RMC methods. Thus, it

is now computationally feasible to tackle such problems, opening the door for new SCPC models and

applications.

Related Models for Probabilistic Constraints. There is an extensive literature on one-period

optimization with chance constraints and on global multi-period probabilistic constraints. For the one-

period formulations, the most popular approach is to transform the problem into linear or non-linear

programs over a set of scenarios [11, 12, 28, 31]. In particular, Monte Carlo scenarios as employed below

are very common, but the typical setup involves a single optimization problem, while we face an inﬁnite

family of them indexed by the system state x and the time-step n. Global probabilistic constraints in

multi-period settings are tackled from multiple perspectives. The dynamic programming method [30]

incorporates the constraint into the objective function via a Lagrange multiplier. The solution is then

obtained by iteratively solving for the optimal control and the Lagrange multiplier. However, the solution

is sub-optimal due to the duality gap. Mixed-integer linear programming [1] works by linearizing the

STATISTICAL LEARNING FOR PROBABILITY-CONSTRAINED STOCHASTIC OPTIMAL CONTROL

3

constraints and requires to discretize the state space. An alternative [6, 7] is to transform into a static

problem which is however computationally feasible only under strict assumptions on the system dynamics

and noise distribution. Yet another option is the stochastic viability approach [2, 15] that focuses on

maximizing the probability of being admissible, which is deﬁned both in terms of proﬁt targets and

satisfying constraints at every time step.

Compared to above, our model of a multi-period optimization with one-step probabilistic constraints

applied at each time step is new in the literature. To our knowledge, the closest setup is studied recently

in [19] to compute the hedging price of a portfolio whose risk is deﬁned in terms of its future value

with respect to a set of stochastic benchmarks. Besides a local probabilistic constraint, the authors also

provide dynamic programming equations for multi-period constraints. However, their solution is driven

by very speciﬁc loss functions and state processes. In contrast, we develop general purpose numerical

schemes using statistical learning methods.

2. Problem formulation. We study numerical resolution of stochastic control problems on ﬁ-

nite horizon [0, T ] with local implicit constraints, speciﬁcally we work with constraints deﬁned through
probabilistic conditions on the controlled state. Let (X(t))t≥0 ∈ X ⊂ Rd be a continuous time con-
trolled Markov process adapted to a given ﬁltration (Ft). The control is an (Ft)-adapted process
(u(t))t≥0, taking values in W ⊂ R. We further assume that control decisions are made at discrete
epochs {t0, t1, . . . , tN = T }; between time-steps the value of u(t) remains constant. Thus, the control
process is piecewise-wise constant and c`adl`ag (right-continuous with left limits), and will be alternatively
represented as u(t) = (cid:80)N −1

n=0 un1[tn,tn+1)(t).

Our setup is essentially discrete-time as far as control is concerned, but we introduce the continuous-

time system state because admissibility of actions depends on the trajectory of X(t) between control

points. In our motivating examples, the dynamics of the system is described by a stochastic diﬀerential

equation:

dX(t) = b(t, X(t), u(t))dt + σ(t, X(t), u(t))dB(t),

where (B(t)) is a m−dimensional Brownian motion generating the ﬁltration (Ft) and b : R+×X ×W → Rd
and σ : R+ × X × W → Rd×m are measurable functions, such that a unique (weak) solution exists for
admissible controls deﬁned below and takes values in X . For the convenience of notation, we will write
Xn for X(tn), n = 0, . . . , N , and will not indicate explicitly the dependence on the control (u(t)) if the
latter is clear from the context.

Admissibility is deﬁned in feedback form via

(2.1)

Un:N (Xn) =

(cid:110)

(uk)N

k=n : Pk(Xk, uk) ∈ Ak ∀k ∈ {n, . . . , N − 1}

(cid:111)
,

for deterministic functions Pk : X × W → R and given subsets Ak ⊂ R. For the rest of the article we
assume Pn(Xn, un) and An to be of the form

(2.2)

(cid:16)
Pn(Xn, un) ≡ pn(Xn, un) := P

Gn((X(s))s∈[tn,tn+1)) > 0(cid:12)

(cid:12) Xn, un

(cid:17)

and An := [0, p),

where Gn is a functional deﬁned on trajectories of (X(s)) over the time interval s ∈ [tn, tn+1). In other
words, we target the set of controls such that the conditional probability of the “failure” functional Gn(·)
of X being greater than zero is bounded by a threshold p, i.e.

(2.3)

Un(Xn) :=

u ∈ W : pn(Xn, un) < p

(cid:110)

(cid:111)
.

4

A. BALATA, M. LUDKOVSKI, A. MAHESHWARI AND J. PALCZEWSKI

The threshold p in equation (2.3) is interpreted as relaxing the strong constraint Gn(·) ≤ 0 which may
not be appropriate in a stochastic environment. Typical values of p would generally be small (p ≈ 0.05).

We assume in the following that at least one admissible control exists at any state and at any time, hence
Un:N is determined by Uk(x) = Uk:k(x), k = n, . . . , N − 1, the non-empty sets of admissible controls
satisfying the constraints at decision epochs tk conditional on Xk = x.

The controller must optimize as well as evaluate the feasibility of proposed actions, with the perfor-

mance criterion of the form

(2.4)

Vn(Xn) =

inf

(us)N

s=n∈Un:N (Xn)

(cid:104) N −1
(cid:88)

(cid:110)

E

(cid:90) tk+1

k=n

tk

πs(X(s), uk)ds + W (X(tN ))

(cid:12)
(cid:12)
(cid:12) Xn

(cid:105)(cid:111)
,

where W (·) represents the terminal penalty and πt(·, ·) the running cost. We re-write (2.4) in terms of
the corresponding dynamic programming equation at step n:

(2.5)

Vn(Xn) = inf

u∈Un(Xn)

(cid:110)

Cn(Xn, u)

(cid:111)
,

where

Cn(Xn, u) = E

(cid:20)(cid:90) tn+1

tn

πs(X(s), u)ds + Vn+1(X(tn+1))

(cid:21)
(cid:12)
(cid:12)
(cid:12) Xn, u

.

Above Cn(Xn, u) is the continuation value, i.e. reward-to-go plus expectation of future rewards, from
using the control u over [tn, tn+1). Moreover, given the state Xn, we say that u∗ ∈ Un(Xn) is an optimal
control if Vn(Xn) = Cn(Xn, u∗). Since the admissible set Un(Xn) is both time and state dependent, we
need to estimate the continuation value Cn(·, ·) and the admissible control set Un(·) at every time step.
This is the major distinction from the standard scenario approach [28] in chance-constrained optimization

where there is only a single problem to optimize over a ﬁxed U, but no further indexing by x and by n.

The latter require a combination interpolation and optimization as part of the solution.

Alternative Formulation of Admissibility. We denote by Gn(Xn, un) as the regular conditional

distribution [20] of the functional Gn(·) given (Xn, un):

(2.6)

Gn(Xn, un) := L

(cid:16)

(cid:12)
(cid:12)
(cid:12) Xn, un
Gn((X(s))s∈[tn,tn+1))

(cid:17)

,

where L(·|Xn, un) stands for a conditional law. When writing P(cid:0)Gn(Xn, un) > z(cid:1) or E(cid:2)g(cid:0)Gn(Xn, un)(cid:1)(cid:3)
we mean the probability or the expectation with respect to this conditional distribution.

We may rewrite equation (2.2) through the corresponding (1−p)th quantile q(Xn, un) of Gn(Xn, un):
(cid:110)

(cid:17)

(cid:16)

P

Gn(Xn, un) > z

(cid:111)
.

≤ p

(2.7)

qn(Xn, un) : (Xn, un) (cid:55)→ arg inf
z

Then using

(2.8)

Un(Xn) := {u : pn(Xn, u) < p} = {u : qn(Xn, u) ≤ 0} ,

we can set P (cid:48)
methods (Section 4) for the admissible set.

n := qn and ˜A = (−∞, 0] in (2.1). We will exploit this equivalence to propose quantile-based

Remark 2.1. Assuming a one dimensional control un ∈ W ⊂ R, and the probability pn(Xn, un)
monotonically decreasing in un, estimating the admissible set Un(Xn) is equivalent to estimating the
minimum admissible control

umin
n (Xn) := inf
u∈W

(cid:110)

u : pn(Xn, u) < p

(cid:111)
.

The corresponding admissible set is Un(Xn) = {u ∈ W : u ≥ umin

n (Xn)}.

STATISTICAL LEARNING FOR PROBABILITY-CONSTRAINED STOCHASTIC OPTIMAL CONTROL

5

Remark 2.2. A more general version are implicit constraints of the form

(cid:110)

(cid:104)
u ∈ W : E
g

(cid:16)

Gn(Xn, u)

(cid:17)(cid:105)

(cid:111)
,

≤ p

for a function g : R → R. Even more abstractly, we can think of a generic implicit map Pk(·, ·) in (2.1)
that deﬁnes Un:N (Xn), with the idea that inverting this map is numerically nontrivial (i.e. Pk is expensive
to evaluate) and hence a priori it is not clear which controls satisfy constraints and which do not.

Remark 2.3. Equation (2.8) describes admissible controls u for a given state x. The “dual” perspec-

tive is to consider the set of states X a

n (u) ⊂ X for which a given control u is admissible:

(2.9)

X a

n (u) :=

x ∈ X : pn(x, u) < p

(cid:110)

(cid:111)
.

Often the cardinality of X is inﬁnite, while the control space W is ﬁnite, so that enumerating (2.9) over
u ∈ W is considerably easier than enumerating the uncountable family of sets x (cid:55)→ Un(x) in equation (2.3).
Furthermore, if u (cid:55)→ pn(x, u) is decreasing for all x ∈ X , then we obtain an ordering X a
n (u2)
for u1 ≤ u2. The latter nesting feature corresponds to ranking the controls in terms of their “riskiness”
with respect to Gn, so that the safest control will have a very large X a
n (u) (possibly all of X ), while the
riskiest control will have a very small admissibility domain.

n (u1) ⊆ X a

2.1. Regression Monte Carlo. In this article we focus on simulation-based techniques to solve

(2.4). The overall framework is based on solving equation (2.5) through backward induction on n = N −
1, N − 2, . . ., replacing the true Vn(x) with an estimate ˆVn(x). Since neither the conditional expectation,
nor the admissibility constraint are generally available explicitly, those terms must also be replaced with

their estimated counterparts. As a result, we work with the approximate Dynamic Programming recursion
(cid:111)
(cid:110) ˆCn(Xn, un)
,

ˆVn(Xn) =

inf
un∈ ˆUn(Xn)

(2.10)

where

ˆCn(Xn, un) := ˆE

(cid:20)(cid:90) tn+1

tn

πs(X(s), un)ds + ˆVn+1(X(tn+1))

(cid:12)
(cid:12)
(cid:12)Xn, un

(cid:21)

.

Above, ˆE is the approximate projection operator and the set of admissible controls ˆUn is also approximated
via either ˆpn(·, ·), i.e., ˆUn(Xn) := (cid:8)u : ˆpn(Xn, u) < p(cid:9), or ˆqn(·, ·), i.e., ˆUn(Xn) = (cid:8)u : ˆqn(Xn, u) ≤ 0(cid:9), see
(2.8). The estimated optimal control ˆun ∈ ˆUn(Xn) satisﬁes ˆVn(Xn) = ˆCn(Xn, ˆun).

The key idea underlying our algorithm and deﬁning the Regression Monte Carlo paradigm is that

ˆE and ˆU are implemented through empirical regressions based on Monte Carlo simulations.
words, we construct random, probabilistically deﬁned approximations based on realized paths of X. This

In other

philosophy allows to simultaneously handle the numerical integration (against the stochastic shocks in
X) and the numerical interpolation (deﬁning ˆVn(x) for arbitrary x) necessary to solve (2.10).

To understand RMC, recall that specifying ˆE is equivalent to approximating the conditional expec-

tation map (x, u) (cid:55)→ E[ψ(cid:0)(X(s))s∈[tn,tn+1]

(cid:1)|Xn = x, un = u] =: f (x, u) where we speciﬁcally substitute

ψ(cid:0)(X(s))s∈[tn,tn+1]

(cid:1) =

(cid:90) tn+1

tn

πs(X(s), un)ds + ˆVn+1(X(tn+1)).

To do so, we consider a dataset consisting of inputs (x1
pathwise realizations y1, . . . , yMc with yj = ψ(cid:0)(x(s))j
dent draw from the distribution of the process (X(s))s∈[tn,tn+1]|(xj
{xj

j=1 to compute ˆf , an estimator of f , via regression.

n, yj}Mc

s∈[tn,tn+1]

n, u1

n, uj

n), . . . , (xMc

n , uMc
(cid:1), where (x(s))j

n ) and the corresponding
s∈[tn,tn+1] is an indepen-
n). Then we use the training set

n, uj

6

A. BALATA, M. LUDKOVSKI, A. MAHESHWARI AND J. PALCZEWSKI

Similarly, estimating Un is equivalent to learning the conditional probability map pn(x, u) (or the con-
ditional quantile map qn(x, u) in (2.3)) and then comparing to the threshold value p (zero, respectively).
This statistical task, whose marriage with RMC is our central contribution, is discussed in Section 4.

The technique of using regressions for the approximation of the continuation value was developed in

the celebrated works by [24] and [36] in the context of American option pricing and further enhanced

in [10, 25]. This was extended for storage problems and controlled state process in [4, 8, 9, 13, 26]. Among

the approaches for approximating f we mention [39] and [26] who exploit the structure of the problem

to reduce the dimensionality of the regressions, [4, 5] who harness the distribution of process to reduce
the variance of ˆf and [21, 26, 39] who use non-parametric regression methods for ˆf . Regression based
approach has also been discussed in the context of stochastic dual dynamic programming for solving high

dimensional storage problems in [38].

In contrast to the above well-developed literature, very little exists about estimating the set of
admissible controls ˆUn(Xn), which requires approximating p(x, u) (or q(x, u)) in equation (2.3). There
are results about learning a single global admissibility set ˆU in a one-period setup, but those approaches
do not transfer to our context of state- and time-dependent admissibility constraints. A naive approach is
to estimate ˆUn(Xn) for every state realized during the backward induction through nested Monte Carlo.
Namely for each pair (x, u) encountered, we may estimate the probability of violating the constraint
by simulating Mb samples from the conditional distribution Gn(x, u) as {gb
b=1. We then set
u ∈ ˆUn(x) if ¯pn(x, u) < p, where

n(x, u)}Mb

(2.11)

¯pn(x, u) :=

Mb(cid:88)

b=1

1gb

n(x,u)>0
Mb

is the empirical probability. Although simple to implement, this Nested Monte Carlo (NMC) method is

computationally intractable for even the easiest problems. As an example, a typical RMC scheme employs
Mc ≈ 100, 000 and assuming Mb = 1000 for inner simulations, which is necessary for good estimates of
small probabilities p ≤ 0.1, would require 108 simulation budget at every time-step to implement NMC.
Note furthermore that NMC returns only the local estimates ¯p(x, u); no functional estimate of Un(x) or
X a
n (u) is provided for an arbitrary x or u, respectively. As a result, any out-of-sample evaluation (i.e. on
a future sample path of X) requires further inner simulations, making this implementation even more

computationally prohibitive.

An important challenge in using ˆU is verifying admissibility. Since we are employing Monte Carlo
samples to decide whether u is admissible at x, this is a probabilistic statement and admissibility can

never be guaranteed 100%. We may use statistical theories to quantify the accuracy of estimators of U,

for example, by applying Central Limit Theorem tools for the estimator ¯p(x, u) of the true p(x, u). In

particular, we develop tools based on conﬁdence intervals in order to make statements (with asymptotic

guarantee) such as “u ∈ U with 95% conﬁdence” (equivalent to p(x, u) < p with 95% probability condi-

tional on the data collected). Achieving reasonable conﬁdence levels calls for “conservative” estimators
of ˆU. As we show, not doing so can make learning U highly unreliable, frequently causing decisions that
are inadmissible with respect the imposed probability constraint. Thus, the related construction of ˆU (ρ)
with speciﬁed conﬁdence level ρ is a running theme in Section 4.

2.2. Motivation: controlling blackout probability in a microgrid. To make our presentation

concrete, we illustrate the framework of (2.5) by formalizing the motivating application from microgrid

STATISTICAL LEARNING FOR PROBABILITY-CONSTRAINED STOCHASTIC OPTIMAL CONTROL

7

management. A microgrid comprises renewable and traditional generation sources, along with a medium

of storage, designed and managed to provide electrical power to a community in a decentralized way. We

consider a system composed of a dispatchable diesel generator, a renewable energy source and an electric

battery storage. The microgrid topology is illustrated in the left panel of Figure 1 and is same as the

example discussed in [26].

Fig. 1: Left panel: Microgrid topology: the load, the diesel generator, the battery and the renewables. Right: Contour
plot for minimum admissible diesel output (L, I, C) (cid:55)→ umin
n (L, I, C) (see Remark 2.1). For L < 0, the constraint is not
binding and umin
n (L, I, C) increases
in L. Red curve represents a path of the controlled demand-inventory pair (Lu∗
n ) following a myopic strategy
choosing the minimum admissible control un(Ln, In, Cn) = umin
n (Ln, In, Cn). The regime C can be visualised by observing
when the red line crosses on the R.H.S. of the ﬁrst contour line, indicating the the diesel generator should be turned on.

n (L, I, C) = 0. As demand increases, the constraint becomes more stringent, i.e. umin

n , Cu∗

n , I u∗

In this context, the state variables are X(t) = (L(t), I(t), C(t)), where L(t) is the net demand
(demand net of renewable generation), I(t) ∈ [0, Imax] is the state of charge of the battery, referred to
as “the inventory”, and C(t) ∈ {0, 1} is the state of the diesel generator. C(t) = 0 refers to diesel being

OFF and C(t) = 1 implies ON. The controller is in charge of the diesel through the control u(t), which

indicates the power output of the unit. We assume, for clarity of exposition, that the net demand L(t) is

an exogenous process, while I(t) is controlled. We reiterate that the control decisions are made at discrete
epochs {t0, t1, . . . , tN −1}, however these decisions aﬀect the state of the system continuously. The choice
of u(tn) ≡ un at time tn is based on minimizing the cost of running the microgrid, as well as controlling
the probability of a blackout (i.e. failing to match the net demand) during [tn, tn+1). The blackout is
described through the imbalance process S(s) := L(s) − un − B(s), ∀s ∈ [tn, tn+1), representing the
diﬀerence between the demand and supply, while the diesel output is held constant over the time step.

The power output from the battery is a deterministic function of net demand, inventory and the control,
B(s) = ϕ(L(s), I(s), un) constrained by the physical limitations of the battery. B(s) > 0 implies supply
of power from the battery and B(s) < 0 implies battery charging. The set of admissible controls is thus:

(2.12)

Un(Ln, In, Cn) :=

(cid:40)

(cid:16)

u : P

sup
s∈[tn,tn+1)

S(s) > 0

(cid:12)
(cid:17)
(cid:12)
(cid:12)(Ln, In, Cn, u)

(cid:41)

< p

.

Thus in the context of microgrid, the conditional distribution Gn of equation (2.6) and the corresponding
pn(Ln, In, Cn) are:

(2.13)

Gn(Ln, In, Cn, un) = L

(cid:16)

sup
s∈[tn,tn+1)

(cid:12)
(cid:12)
(cid:12)(Ln, In, Cn, un)
S(s)

(cid:17)

,

pn(Ln, In, Cn, un) = P(Gn(Ln, In, Cn, un) > 0).

8

A. BALATA, M. LUDKOVSKI, A. MAHESHWARI AND J. PALCZEWSKI

Because pn is not (in general) available analytically, the admissibility condition pn(Ln, In, Cn) < p is
implicit. Recall that we denote by W = 0 ∪ [u, ¯u] the unconstrained control set. We assume that u(t) = 0

means that the diesel is OFF, while u(t) > 0 means that it is ON, and at output level u(t). Thus, we
deﬁne C(s) = 1{un>0} ∀s ∈ (tn, tn+1] with the time interval left-open in order to allow for identiﬁcation
of switching on and oﬀ of the diesel generator at times tn. Notice also that the process C(t) does not
satisfy the controlled diﬀusive dynamics, but this slight extension of the framework does not impact on

the methods and results presented. We then look at the following formulation of the general problem:

(2.14)

Vn(Ln, In, Cn) = min

{uk}N −1
k=n

(cid:40)

E

(cid:34)N −1
(cid:88)

(cid:16)

k=n

1{Ck=0,uk>0}K + ρ(uk)∆tk

(cid:17)

(cid:12)
(cid:12)
(cid:12)(Ln, In, Cn)
+ W (LN , IN , CN )

(cid:35)(cid:41)

,

subject to

(cid:16)

P

sup
s∈[tk,tk+1)

(cid:12)
(cid:12)
(cid:12)(Lk, Ik, Ck, uk)
S(s) > 0

(cid:17)

< p,

k = n, . . . , N − 1,

where ∆tk = tk+1 − tk, ρ(uk) is the instantaneous cost of running the diesel generator with power
output uk and K is the cost of switching it ON. We assume zero cost to turn the generator oﬀ. The
DPE corresponding to (2.14) is the same as in (2.5) with the integral running cost (cid:82) tn+1
πs(X(s), un)ds
replaced by

tn

1{Cn=0,un>0}K + ρ(un)∆tn.

Remark 2.4. The admissible set U ⊆ W for this problem has the special structure: if u ∈ U(x), then
n (x), ¯u] ∩ W in terms of the minimal
n (x). Conversely, the admissibility domains for a ﬁxed u ∈ W are nested: if
n (u2). This suggests to compute X a
n (u) sequentially as u is increased and then

∀ W (cid:51) ˜u > u, ˜u ∈ U(x). Hence, we may represent U(x) = [umin
admissible diesel output umin
u1 ≤ u2 then X a
invert to get U(x).

n (u1) ⊆ X a

To visualize the minimum admissible control umin

n (x), the right panel of Figure 1 presents the
map x → umin
n (x) under a constraint of p = 0.01 probability of blackout. We also present a path
for (L(t), I(t), C(t))t≥0 using a myopic strategy where the controller employs the minimum admissible
control at each point, un := umin
n (·) = 0 so that
Un(·) = W and the blackout constraint is not binding. This is not surprising, as blackouts are only
possible when L(t) (cid:29) 0 is strongly positive and the battery is close to empty, I(t) (cid:39) 0. Thus, except

n (Ln, In, Cn) ∀n. Notice how for the most part, umin

for the lower-right corner, any control is admissible. As a result, only a small subset of the domain X

actually requires additional eﬀort to estimate the admissible set U(x). In our experience this structure,
where the constraint is not necessarily binding and where we mostly perform unconstrained optimization,

is quite common.

3. Dynamic emulation algorithm. In this section we present our Dynamic emulation algorithm
which provides approximation for the admissible set ˆUn(·) and the continuation value function ˆCn(·, ·).
The crux of the algorithm are the following two steps, implemented in parallel at every time-step:

(3.1)

Generate design → Generate 1-step paths & admissibility statistic → Estimate admissible set

Generate design → Generate 1-step paths & pathwise proﬁts → Estimate continuation function

STATISTICAL LEARNING FOR PROBABILITY-CONSTRAINED STOCHASTIC OPTIMAL CONTROL

9

To estimate ˆCn(·, ·)’s and ˆUn(·)’s, we proceed iteratively backward in time starting with known terminal
condition W (X) and sequentially estimate ˆUn and ˆCn for n = N − 1, . . . , 0. Assuming we have estimated
ˆUn+1, . . . , ˆUN −1 and ˆCn+1, . . . , ˆCN −1, we ﬁrst explain the estimation procedure for ˆUn and ˆCn. This
corresponds to a fit task. In the subsequent backward recursion at step n − 1 we also need the predict
task to actually evaluate ˆVn(Xn) which requires evaluating ˆCn(·) at new (“out-of-sample”) inputs Xn, un
which of course do not coincide with the training inputs (x1

n), . . . , (xMc

n , uMc

n, u1

n ).

3.1. Estimating the set of admissible controls. To estimate the set of admissible controls
n, i = 1, . . . , Ma) and simulate trajectories of the
n. To evaluate the
(cid:1), we discretize the time interval [tn, tn+1) into K ﬁner sub-steps with
, xi
. We then record
n1

ˆUn(·) at time-step n, we choose design Da
state process (X(s))i
functional G(cid:0)(X(s))i
∆nk := tn(k+1) − tnk and deﬁne the discrete trajectory xi

s∈[tn,tn+1) starting from Xi(tn) = xi

n and driven by control ui

n := (xi

n = xi
n0

, . . . , xi

s∈[tn,tn+1)

n, ui

, xi

nK

n(K−1)

(3.2)

wi

n := 1

(cid:16)

G((xi

nk

)k∈{0,...,K−1}) > 0

(cid:17)

,

i = 1, . . . , Ma,

where, formally, we extend (xi

nk

)k∈{0,...,K−1} to a piecewise constant trajectory on [tn, tn+1).

Analogous to standard RMC, we now select an approximation space Ha

n to estimate the probability

ˆpn or the quantile ˆqn, using the loss function La

n and apply empirical projection:

(3.3)

ˆpn := arg min
n ∈Ha
f a
n

Ma(cid:88)

i=1

La

n(f a

n, wi

n; xi

n, ui

n).

See Section 4 for concrete examples of Ha and La. Note that the approximations ˆpn and ˆqn must be
n}Ma
trained on joint state-control datasets {xi
n dependent on the method of choice and
moreover yield random estimators (ˆpn is a random variable).

i=1 with wi

n, wi

n, ui

Using the distribution of ˆpn(x, u) we may obtain a more conservative estimator that provides better
guarantees on the ultimate admissibility of (x, u). As a motivation, recall the NMC estimator ¯pn(x, u)
from (2.11); for reasonably large Mb (cid:29) 20, the distribution of ¯pn(x, u) is approximately Gaussian with
mean pn(x, u) and variance pn(x,u)(1−pn(x,u))

. Deﬁning

Mb

(3.4)

(3.5)

n (x, u) := ¯pn(x, u) + ξ(ρ)
ˆp(ρ)
n (x, u)
(cid:115)

:= ¯pn(x, u) + zρ

¯pn(x, u)(1 − ¯pn(x, u))
Mb

,

where zρ is the standard normal quantile at level ρ and ξ(ρ)
¯pn at conﬁdence level ρ. The corresponding approximate admissible set with conﬁdence ρ is

n (x, u) represents a “safe” margin of error for

(3.6)

n (x) := ˆU ξ(ρ)
ˆU (ρ)

n

(x) =

u : ˆpn(x, u) + ξ(ρ)

n (x, u) < p

(cid:110)

(cid:111)

.

More generally, we set the admissible set for a site x ∈ X to

(3.7)

ˆU ξ
n(x) = {u : ˆpn(x, u) + ξn(x, u) < p} ,

where ξn(x, u) ensures “stronger” guarantee for the admissibility of u at x. The margin of estimation
error can also be ﬁxed, ξn(x, u) = c ∀(x, u) ∈ X ×W, which can be applied when the sampling distribution
of ˆpn(x, u) is unknown. The corresponding admissible set

(3.8)

ˆU ξ=c
n

(x) = {u : ˆpn(x, u) + c < p} .

10

A. BALATA, M. LUDKOVSKI, A. MAHESHWARI AND J. PALCZEWSKI

is equivalent to estimating ˆU ξ=0
tion, we use ˆUn(x) to denote the unadjusted admissible set, ˆUn(x) := ˆU ξ=0
(x) in the context of NMC.
Analogously, we can adjust equations (3.2)-(3.3) based on learning the quantile qn(x, u) to add a margin
of error, ˆU ξ

(x) with a shifted lower probability threshold p − c. To simplify nota-

n(x) = {u : ˆqn(x, u) + ξn(x, u) ≤ 0}.

n

n

Remark 3.1. In the context of one-step static optimization, conservative estimates for the admissible

set were explored in [12]. The idea is to consider u to be admissible iﬀ p(x, u) = 0, i.e. there are no
failures observed in all of the simulated samples. The choice of the sample size Mb is then determined
using Chebyshev inequality that provides a theoretical guarantee on P(p(x, u) > 0 | p(x, u; Mb) = 0). This
approach is similar in our setup to a violation margin c = p in (3.8). However, the guarantee on p(x, u) is

only applicable locally at the design sites. We are not aware of any tools that would allow non-parametric

guarantee for any x ∈ X . The regression based approach oﬀers a model-based guarantee for admissibility

of u at any x by setting the parameter ρ in (3.6) or c in (3.8).

3.2. Estimating the continuation value. To estimate the continuation value Cn(·, ·), we choose
n) and
n and driven by
(in principle the sub-steps

n := (xj
a simulation design Dc
generate one-step paths for the state process (X(s))j
s∈[tn,tn+1) starting from Xj(tn) = xj
n = xj
control uj
n0
could diﬀer from the time discretization for ˆUn). Next, we compute the pathwise cost yj
n:

n, j = 1 . . . , Mc) (which could be independent or equivalent to Da

n, comprising again ﬁner sub-steps xj

, . . . , xj

, xj
n1

n, uj

n(K−1)

, xj

nK

(3.9)

yj
n =

K−1
(cid:88)

k=0

πnk (xj
nk

, uj

n)∆nk + vj

n+1,

where vj

n+1 =

inf

u∈ ˆUn+1(xj

nK )

ˆCn+1(xj

nK

, u),

j = 1 . . . Mc,

and we replace the time integral in (2.5) with a discrete sum over tnk ’s. At the key step, we project
{yj

n to evaluate the continuation value Cn(·, ·):

j=1 onto an approximation space Hc

n}Mc

(3.10)

ˆCn(·, ·) := arg min
n∈Hc
f c
n

Mc(cid:88)

n=1

|f c

n(xj

n, uj

n) − yj

n|2.

The design sites {xj
in the previous subsection. Two standard approximation spaces Hc
polynomial approximation and piecewise continuous approximation.

j=1 could be same or diﬀerent from those used for learning the admissible sets
n used in this context are: global

n, uj

n}Mc

Remark 3.2. In the microgrid example of Section 2.2 the running cost over [n, n + 1) is known once
the control un is chosen. Thus it can be taken outside the conditional expectation and the data to be
regressed is simply yj = vj

n+1.

Global polynomial approximation:. This is a classical regression framework with polynomial bases

φk(·, ·) and ˆCα

n (x, u) := (cid:80)

(3.11)

k αkφk(x, u). The coeﬃcients α are ﬁtted via
αkφk(xj, uj) − yj(cid:12)
(cid:12)
(cid:12)

ˆα := arg min

Mc(cid:88)

(cid:88)

(cid:12)
(cid:12)
(cid:12)

2

.

α

j=1

k

As an illustration, for the microgrid example of Section 2.2 we construct a quadratic polynomial
approximation when diesel generator is ON, u > 0, using 10 bases {1, L, I, u, L2, I 2, u2, LI, Iu, LI} and a
separate quadratic approximation with the 6 basis functions {1, L, I, L2, I 2, LI, LI} when diesel generator
is OFF, u = 0. Polynomial approximation is easy to implement but typically requires many degrees of

freedom (lots of φ’s) to properly capture the shape of C and can be empirically unstable, especially if

there are sharp changes in the underlying function (see for example [21, 26]).

STATISTICAL LEARNING FOR PROBABILITY-CONSTRAINED STOCHASTIC OPTIMAL CONTROL

11

Piecewise continuous approximation:. This is a state-of-art tool in low dimensions, d ≤ 3. The

main idea is to employ polynomial regression in a single dimension and extend to the other dimensions

via linear interpolation. As an example, for the microgrid with diesel generator ON, we have three
dimensions (L, I, u). We discretize inventory I as {I 0, I 1, . . . , I MI } and control u as {u1, u2, . . . , uMu } and
ﬁt independent cubic polynomials in L for each pair (I l, ue) with l ∈ {0, 1, . . . , MI } and e ∈ {1, . . . , Mu},
k φk(L). For any (I, u) ∈ [I l, I l+1] × [ue, ue+1] we then provide the interpolated
i.e., f l,e
approximation ˆCn(L, I, u) as

n (L) = (cid:80)

k αl,e

(3.12)

ˆCn(L, I, u) =

(cid:104)
I l+1 − I

(cid:34)

I − I l(cid:105)

f l,e
f l,e+1
n (L)
n
f l+1,e+1
f l+1,e
(L)
n
n
(ue+1 − ue)(I l+1 − I l)

(L)

(L)

(cid:35) (cid:34)

ue+1 − u
u − ue

(cid:35)

.

Nonparametric approximation:. Further alternatives for Hc

n can be found in [26] who used Gaussian
process regression and [21,22] who used local polynomial regression. For semi-parametric approximation,

[10] developed piecewise multivariate linear regression.

There are several possibilities for choosing the designs Da

· and Dc

· , see [26] for a detailed discussion

of diﬀerent regression designs Dc

· and their impact on the quality of the ﬁnal solution.

3.3. Evaluation. We analyze the quality of the solution by computing three quantities on the

out-of-sample dataset:

• estimate of the value function V0(x0) at t = 0 and state x0;
• empirical frequency of inadmissible decisions on the controlled trajectories xˆu
· ;
• statistical test for the realized number of constraint violations (blackouts for the microgrid).

Good solutions should minimize costs and not apply inadmissible controls. However, since we employ

empirical estimators, U is never known with certainty and we must handle the possibility that constraints

are violated with probability more than p. In turn this leads to the trade-oﬀ between complying with (2.1)

and optimizing costs. Similar treatment of constraints in the context of sample average approximation of

probabilistic constrained optimization problems have been discussed in [27,29]. Moreover, our framework
implies that the whole algorithm is stochastic: multiple runs will lead to diﬀerent results since both ˆpn
and ˆCn are impacted by the random samples yj
n and wi
n.
Estimate of the value function: We evaluate the value function ˆV0(x0) at time t0 = 0 and state x0
using M (cid:48) out-of-sample paths (xˆu,m(cid:48)
0:N ), m(cid:48) = 1, . . . , M (cid:48). Each trajectory (xˆu,m(cid:48)
0:N ) is generated by applying
the estimated optimal control ˆu0:N −1 based on the continuation value and admissible sets ( ˆCn, ˆUn)N −1
n=0
leading to the realized pathwise cost

v0(xˆu,m(cid:48)

0:N ) :=

N −1
(cid:88)

K−1
(cid:88)

n=0

k=0

πnk (xˆu,m(cid:48)

nk

, ˆum(cid:48)

n )∆nk + W (xˆu,m(cid:48)
N ).

The resulting empirical Monte Carlo estimate is

(3.13)

ˆV0(x0) (cid:39)

1
M (cid:48)

M (cid:48)
(cid:88)

m(cid:48)=1

v0(xˆu,m(cid:48)
0:N )

and represents an unbiased estimation of the value of the control policy and an asymptotic upper bound

estimation of the value function, provided all controls used are admissible.

12

A. BALATA, M. LUDKOVSKI, A. MAHESHWARI AND J. PALCZEWSKI

Empirical frequency of inadmissible decisions on the controlled trajectories: For the M (cid:48)
n=m=1 against the minimum
n
n=m=1 assumed for a second to be known. Namely, for each path we
0:N ) and the respective empirical frequency wf req as:

out-of-sample paths, we compare the estimated optimal control {ˆun(xˆu,m(cid:48)
)}N −1,M (cid:48)
n (xˆu,m(cid:48)
admissible control {umin
compute the number of inadmissible decisions w0(xˆu,m(cid:48)

)}N −1,M (cid:48)

n

(3.14)

w0(xˆu,m(cid:48)

0:N ) :=

(cid:88)

1

n

ˆun(x ˆu,m(cid:48)

n

)<umin

n (x ˆu,m(cid:48)

n

and wf req :=

)

1
N · M (cid:48)

M (cid:48)
(cid:88)

m(cid:48)=1

w0(xˆu,m(cid:48)

0:N ),

respectively. We employ these metrics in Section 5, where a “gold standard” {umin
n=m=1 is
obtained by brute force, utilizing a simulation budget 105 larger than for the actual methods we are
comparing. Empirical gold standard is a common technique when analytical benchmark is unavailable,
see e.g. [14]. A good estimation method should yield wf req (cid:39) 0. However, if wf req > 0, a controller can
choose margin of error ξn (Equation (3.7)) to reduce wf req at the expense of higher cost v0(xˆu,m(cid:48)

n (xˆu,m(cid:48)

n

)}N −1,M (cid:48)

0:N ).

Remark 3.3. In Equation (3.14) we exploit the structure of the admissible set for the microgrid
control (cf. Remark 2.4). Generally, w0(xˆu,m(cid:48)
, where Un(xn) is either known
in closed form or computed via empirical gold standard. The general setting, without any assumptions
on the structure of Un(xn), is computationally very expensive and beyond the scope of this work.

0:N ) := (cid:80)

ˆun(x ˆu,m(cid:48)

) /∈Un(xn)

1

n

n

Statistical test: Next we propose statistical tests using the controlled trajectories to validate dif-

ferent methods for admissible set estimation. Such a test is essential to aﬃrm the use of a numerical
scheme for Un in the absence of a benchmark. As an example, in the context of microgrid we want to test
the null hypothesis H0 that the realized probability of blackouts is bounded to the required level against
the alternative H1 that their probability is too high. Let

(3.15)

(cid:16)

Bm(cid:48)

n = 1

G(xˆu,m(cid:48)

s∈[tn,tn+1)) > 0

(cid:17)

, n = 0, . . . , N − 1 and m(cid:48) = 1, . . . , M (cid:48).

Ignoring the correlation due to the temporal dependence in xn, we assume that Bm(cid:48)
are i.i.d. and ˜p represents the true (unknown) probability of blackout. We want to test:

n ∼ Bernoulli(˜p)

(3.16)

H0 : ˜p ≤ p

vs. H0 : ˜p > p.

A common approach to such composite null hypothesis is to replace H0 with a more conservative hy-
pothesis ˜p = p leading to the test statistic

(3.17)

T :=

(cid:80)

m(cid:48),n(Bm(cid:48)
(cid:112)M (cid:48) · N · p · (1 − p)

n − p)

∼ N (0, 1).

Hence, H0 is rejected at a conﬁdence level α if T > zα with zα = Φ−1(α), e.g. zα = 1.65 for α = 95%.

Remark 3.4. The above test assumes independence and identical distribution of Bm(cid:48)

n ’s. In the context
of the microgrid example, neither of the two assumptions are valid; Bm(cid:48)
n has a diﬀerent distribution
because the state of the system aﬀects the probability of a blackout, thus ˜p varies with n, m(cid:48). Furthermore,
Bm(cid:48)

n are not independent as they are derived from a single, sequentially controlled trajectory.

Remark 3.5. In the microgrid setup, the blackout constraint is frequently not binding (the net de-

mand is negative half of the time). Therefore, T as deﬁned in equation (3.17) is most likely negative
leading to accept the H0 even when the method fails to choose the admissible control when the constraint

STATISTICAL LEARNING FOR PROBABILITY-CONSTRAINED STOCHASTIC OPTIMAL CONTROL

13

is binding. We ﬁx this by evaluating the sum only when the constraint is binding, i.e.

(3.18)

˜T :=

(cid:80)
m(cid:48),n(Bm(cid:48)
n − p)1
(cid:112)p · (1 − p) · M (cid:48) · N · wbind

n (x ˆu,m(cid:48)
ˆumin

n

)>0

where wbind =

(cid:80)

m(cid:48),n

1

n (x ˆu,m(cid:48)
umin
M (cid:48) · N

n

)>0

,

where ˆumin

n (xˆu,m(cid:48)

n

) represents model estimate of the true minimum admissible control umin

n (xˆu,m(cid:48)

n

).

To wrap up this section, Algorithm 3.1 (dubbed Dynamic Emulation due to similarities with a related

algorithm for unconstrained stochastic control from [26]) summarizes the overall sequence of steps. Lines

1-2 contain the parameters to the algorithm, Lines 3-8 (and 14-19) yield the stochastic simulator which
generates designs and corresponding one-step paths. Line 10 (and again Line 20) computes pathwise

one-step costs. Line 12 is the admissible set estimation. Line 13 is the estimation of the continuation

value.

Algorithm 3.1 carries several advantages. First and foremost it is very general, and does not make any
restrictions on the distribution Gn(Xn, u) deﬁning Un or the form of the payoﬀs π(x, u). Hence it can be
generically applied across a wide spectrum of SCPC problems. Second, the same template (in particular

based on having two independent sub-modules) accommodates a slew of techniques for learning C and

U bringing plug-and-play functionality, such as straightforward switching from probability to quantile

estimation. Third, it allows for computational savings through parallelizing the estimation of U and C,
n ≡ Dc
or by re-using the same design and simulations Da

n for the computation of the two sub-modules.

Remark 3.6. The challenge of RMC methods is that the errors recursively propagate backward. As

a result, poor estimation at one step can aﬀect the overall quality of the solution. In our algorithm, the

errors at every step occur due to:

• Approximation architecture Ha
• Approximation architecture Hc
n and Dc
• Designs Da

n for ˆUn ⇒ Projection error in admissible control set estimation;
n for ˆCn ⇒ Projection error in estimating continuation value;

n ⇒ Finite-sample Monte Carlo errors (diﬀerence between empirical estimates

and theoretical projection-based ones)

• Discretization of the time interval [tn, tn+1) using ∆nk ⇒ Integration error in approximating the

integral (cid:82) tn+1

tn

πs(X(s), u)ds and the admissible set Un.

• Numerical approximation of the solution of the controlled dynamics of X(t).
• Optimization errors in maximizing for ˆu over ˆU, especially when the control set W is continuous.

4. Admissible set estimation. In this section we propose two diﬀerent approaches to estimate

the admissible set of controls Un in equation (2.3):

• Probability estimation: Given a state Xn = x and u ∈ W, we estimate, via simulation, the

probability of violating the constraint

ˆpn(x, u) (cid:39) P

(cid:16)

Gn(x, u) > 0

(cid:17)

.

It follows that u ∈ ˆUn(x) ⇔ ˆpn(x, u) < p. Particularly, to compute ˆpn(x, u) we consider
Gaussian process smoothing of empirical probabilities, logistic regression and parametric density

ﬁtting.

• Quantile estimation: We approximate the quantile qn(x, u) of Gn(x, u) via empirical ranking,
support vector machines and quantile regression methods. The admissible sets Un(x) and X a
n (u)

14

A. BALATA, M. LUDKOVSKI, A. MAHESHWARI AND J. PALCZEWSKI

Algorithm 3.1 Dynamic Emulation Algorithm

1: N (time steps), Mc (simulation budget for conditional expectation),
2: Ma (simulation budget for admissible set estimation)
3: Generate designs:
Da
Dc

Da
N −1 ) of size Ma for estimating ˆU.
Dc
N −1 ) of size Mc for estimating ˆC.

N −1 := (x
N −1 := (x

Da
N −1 , u
Dc
N −1 , u

N −1

N −1

N −1

N −1

4:

5:

7:

6: Generate one-step paths:
i,Da
N −1
N −1
j,Dc
N −1

i,Da
N
j,Dc
N

(cid:55)→ x

(cid:55)→ x

N −1

N −1

x

x

8:

N −1

using u

using u

N −1

Da
N −1
Dc
N −1

N −1

for i = 1, . . . , Ma
for j = 1, . . . , Mc

9: Terminal condition:
N −1 ← (cid:80)K−1
yj
11: for n = N − 1, . . . , 1 do

10:

k=0 π(N −1)k (x

j,Dc
N −1
(N −1)k

, u

j,Dc
N −1
(N −1)k

)∆nk + W (x

j,Dc
N

N −1

) for j = 1, . . . , Mc

13:

12:

(cid:80)Mc

Estimate ˆUn(·) using methods in Section 4 and paths xi,Da
ˆCn(·, ·) ← arg min
fn∈Hc
n
14: Generate designs:
n−1 := (x
n−1 := (x

Da
n−1 ) of size Ma for estimating ˆU.
Dc
n−1 ) of size Mc for estimating ˆC.

j=1 |fn(xj,Dc

, uj,Dc

) − yj

n|2

16:

15:

n−1

n−1

n

n

n

n

n

n

(cid:55)→ xi,Da

n
n+1

n−1

n−1

Da
Da
n−1 , u
Dc
Dc
n−1 , u
17: Generate one-step paths:
i,Da
n−1
n−1
j,Dc
n−1

i,Da
n
j,Dc
(cid:55)→ x
n
k=0 π(n−1)k (x

x
n−1 ← (cid:80)K−1
yj

(cid:55)→ x

20:

19:

18:

n−1

n−1

n−1

x

using u

using u

j,Dc
n−1
(n−1)k

, u

n−1

n−1

Da
n−1
Dc
n−1
j,Dc
n−1
(n−1)k

for i = 1, . . . , Ma
for j = 1, . . . , Mc
max
)∆nk +
j,Dc
u∈ ˆUn(x
n

(cid:110) ˆC(n, x

j,Dc
n

n−1

(cid:111)

, u)

∀j

)

n−1

21: end for
22: return { ˆCn(·, ·), ˆUn(·)}N −1
n=1

are then deﬁned as:

ˆUn(x) :=

(cid:110)

u : ˆqn(x, u) ≤ 0

(cid:111)

and

ˆX a

n (u) :=

(cid:110)

x : ˆqn(x, u) ≤ 0

(cid:111)
.

To implement all of the above techniques we use Monte Carlo simulation, specifying ﬁrst the simula-

tion design and then sampling (independently across draws) the G’s or Y ’s to be used as training data.
We work in a ﬂexible framework where samples of Gn(x, u) are generated in batches of Mb simulations
from each design site {xi, ui}Ma
i=1. The case of Mb = 1 corresponds to a classical regression approach,
while large Mb (cid:29) 1 can be interpreted as nested Monte Carlo averaging along Mb inner samples.

Remark 4.1. In section 3.2, we parameterized the elements of the approximation space Hc

mation of the continuation value function ˆC(·, ·) via vectors α i.e. f c
(3.11). To distinguish, in the following sections we use β to parameterize the approximators in Ha
estimating the admissible set: f a
vary from method to method.

n for esti-
n(x, u; α), cf. (3.10) and
n for
n(x, u; β) in eq. (3.3). The meaning and dimension of β will

n(x, u) ≡ f a

n(x, u) ≡ f c

4.1. Probability estimation.

4.1.1. Interpolated nested Monte Carlo (INMC). Recall the NMC method from Section 2.1
where we select Ma design sites of state-action pairs and simulate multiple paths from each site to locally

STATISTICAL LEARNING FOR PROBABILITY-CONSTRAINED STOCHASTIC OPTIMAL CONTROL

15

assess the probability of Gn(x, u) > 0 (in what follows, we suppress in the notation the dependence on
n). Speciﬁcally, for each design site (xi, ui), i = 1, . . . , Ma, we simulate Mb batched samples from the
distribution G(xi, ui) as {gb(xi, ui)}Mb

b=1. The unbiased point estimator of p(xi, ui) is:

(4.1)

¯p(xi, ui) :=

Mb(cid:88)

b=1

1gb(xi,ui)>0
Mb

.

Since (4.1) only yields Mb local estimates ¯p(xi, ui), for Algorithm 3.1 we have to extend them to an
arbitrary state-action (x, u) (cid:55)→ ˆpINMC(x, u). This is achieved by interpolating ¯p(xi, ui)’s, e.g. linearly.
The admissible set with conﬁdence level ρ becomes:

ˆU (ρ)
INMC(x) :=






u : ˆpINMC(x, u) ≤ p − zρ

(cid:115)

ˆpINMC(x, u)(1 − ˆpINMC(x, u))
Mb






.

However, especially for Mb small, interpolation performs poorly because the underlying point estimates
¯p(xi, ui) are noisy. Therefore, smoothing should be applied via a statistical regression model. Regression
borrows information cross-sectionally to mitigate the estimation noise, reducing the variance of ¯p.

4.1.2. Gaussian process regression (GPR). GPR is a ﬂexible non-parametric regression method

that views the map (x, u) → p(x, u) as a realization of a Gaussian random ﬁeld so that any ﬁnite collection
of {p(x, u)}, (x, u) ∈ X × W is multivariate Gaussian. For any n design sites {(xi, ui)}n
i=1, GPR posits
that

p(x1, u1), . . . , p(xn, un) ∼ N (

#»
mn, Kn)

#»
mn := [m(x1, u1; β), . . . , m(xn, un; β)] and n × n covariance matrix Kn comprised of

; β), for 1 ≤ i, i(cid:48) ≤ n. The vector β represents all the hyperparameters for this model.

with mean vector
κ(xi, ui, xi(cid:48)

, ui(cid:48)

Given the training dataset {(xi, ui), ¯pi}Ma

i=1 (where ¯pi is a shorthand for ¯p(xi, ui)), GPR infers the
posterior of p(·, ·) by assuming an observation model of the form ¯p(x, u) = p(x, u) + (cid:15) with a Gaussian
noise term (cid:15) ∼ N (0, σ2
(cid:15) ). Conditioning equations for multivariate normal vectors imply that the poste-
rior predictive distribution p(x, u)|{(xi, ui), ¯pi}Ma
i=1 at any arbitrary site (x, u) is also Gaussian with the
posterior mean ˆpGPR(x, u) that is the proposed estimator of p(x, u):

(4.2)

ˆpGPR(x, u) := m(x, u) + K T (K + σ2I)−1(

#»
p −

where

#»
x = [x1, . . . , xMa ]T ,

#»
u = [u1, . . . , uMa ]T ,

p(x, u)(cid:12)
(cid:12)

(cid:104)
#»
m) = E
#»
p = [¯p1, . . . , ¯pMa ]T ,

#»
x ,

#»
u ,

#»
p

(cid:105)

(4.3)

K T = [κ(x, u, x1, u1; β), . . . , κ(x, u, xMa , uMa ; β)],
#»
m = [m(x1, u1; β), . . . , m(xMa , uMa ; β)],

and K is Ma × Ma covariance matrix described through the kernel function κ(·, ·; β).

The mean function is often assumed to be constant m(x, u; β) = β0 or described using a linear
k=1 βkφ(xi, ui) with φ(·, ·) representing a polynomial basis. A popular choice
k=1, βlen,u} termed the

model m(x, u; β) = (cid:80)K
for the kernel κ(·, ·, ·, ·) is squared exponential (see equation (4.4)) with {{βlen,k}d
lengthscales and σ2

p the process variance of p(·, ·):

(4.4)

κ(xi, ui, xi(cid:48)

, ui(cid:48)

) = σ2

p exp

(cid:16)

−

d
(cid:88)

k=1

(xi,k − xi(cid:48),k)2
βlen,k

−

(ui − ui(cid:48)
βlen,u

)2

(cid:17)

.

16

A. BALATA, M. LUDKOVSKI, A. MAHESHWARI AND J. PALCZEWSKI

p, σ2

k=1, {βlen,k}d

k=1, βlen,u, σ2

(cid:15) ) represent diﬀerent attributes of ˆpGPR(·, ·).

k=1 determine the trend of ˆp(·, ·) over the input domain. The lengthscales {βlen,k}d

The hyperparameters β := ({βk}K
The parameters {βk}K
k=1
and βlen,u determine spatial smoothness or how quickly the function changes. Small lengthscales make ˆp
to be “bumpy”, while large lengthscales make ˆp close to linear. The process variance σ2
p determines the
amplitude of ﬂuctuations in ˆpGPR and σ2
(cid:15) represents the sampling noise variance. These hyperparameters
are estimated by maximizing the log-likelihood function based on the dataset {(xi, ui), ¯pi}Ma
i=1. Besides
squared exponential kernel (Equation 4.4), other popular kernels include Mat´ern-3/2 and Mat´ern-5/2 [35].
GPR(x, u) at conﬁdence level ρ is obtained by explicitly incorporating the
(estimated) standard error of ¯p(xi, ui) into the GPR smoothing. Namely, we adjust the training dataset
ρ}Ma
to {(xi, ui), ¯pi
terpart of (4.2) using {(xi, ui), ¯pi

(cid:113) ¯p(xi,ui)(1− ¯p(xi,ui))
Mb

A conservative estimate ˆp(ρ)

ρ := ¯p(xi, ui) + zρ
ρ}Ma
i=1.

GPR(x, u) is the coun-

. The resulting ˆp(ρ)

i=1, where ¯pi

In Figure 2b we present the dataset {Li, I i, 0, ¯pi}Ma

i=1 (background colormap) for the microgrid case
study. The thick red line indicates the contour {ˆpGP R = 5%}, dividing the state space X for u = 0 into
admissible X a(0) (left of red line) and inadmissible region (X a(0))c (right of red line).

4.1.3. Logistic regression (LR). In the previous section, we created local batches to estimate
p(xi, ui) pointwise and then regressed these estimates to build a global approximator. A classical al-
ternative is to learn the probability of G(x, u) > 0 using a logistic regression model. This setup uses a
single sample g(xi, ui) from G(xi, ui) from each design site (xi, ui) and transforms it to a binary response
yi = 1g(xi,ui)>0. The probability ˆp(x, u) is then modeled as a generalized linear model with a logit link
function

(cid:16)

(4.5)

1
1 + e−βT φ(x,u)
The basis functions φ(x, u) could be polynomials, e.g. quadratic or cubic in coordinates of (x, u). The
regression coeﬃcients β are ﬁtted using the dataset {xi, ui, yi}Ms

=: ˆpLR(x, u; β).

Y = 1|x, u

i=1, as the solution to

=

P

(cid:17)

(4.6)

arg maxβ

Ms(cid:88)

i=1

(cid:8)yi log pLR(xi, ui; β) + (1 − yi) log(1 − pLR(xi, ui; β))(cid:9) .

We may again create a more conservative estimate ˆU (ρ)

LR(x) of ˆULR(x) at conﬁdence level ρ by utilizing

the standard error for ˆpLR using the Delta method [40]:

(cid:26)

ˆU (ρ)
LR(x) :=

u : ˆpLR(x, u, β) ≤ p − zρ

(cid:113)

ˆpLR(x, u)(1 − ˆpLR(x, u))φT Var(β)φ

(cid:27)

.

In Figure 2a, we present the original realizations yi ∈ {0, 1} (in blue) for a design in the input
subspace (L, I, u = 0) of the microgrid case study. The ﬁgure indicates the resulting logistic regression ﬁt
ˆpLR(L, I, 0) at levels 1%, 5% and 10% (i.e. contour lines of ˆpLR( ˆβ) ∈ {0.01, 0.05, 0.1}). The admissibility
set for u = 0, X a

n (0) is the region to the left of the thick red contour.

Remark 4.2. Similar to Section 4.1, we can simulate batched samples from each design site for the

logistic regression, leading to “binomial” observation likelihood instead of (4.6).

Remark 4.3. A non-parametric variant of equation (4.5) is kernel logistic regression, where the basis
functions are φj(x, u) = κ(x, u, xj, uj) for a kernel function κ centered at (xj, uj). One common choice is
radial basis functions (RBF) where κ(x, u, xj, uj) = exp (−γ1(cid:107)x − xj(cid:107)2
2). RBF can be in-
terpreted as the squared-exponential kernel for a logistic Gaussian Process model, with a ﬁxed bandwidth
parameter γi. In contrast, in GPR the bandwidths are estimated through MLE.

2 − γ2(cid:107)u − uj(cid:107)2

STATISTICAL LEARNING FOR PROBABILITY-CONSTRAINED STOCHASTIC OPTIMAL CONTROL

17

4.1.4. Parametric density ﬁtting (PF). This approach ﬁts the distribution G(x, u), and then an-

alytically infers the probability P
This is done by proposing a parametric family {f (·; Θ)} of densities, ﬁtting the underlying parame-

from the corresponding cumulative distribution function.

G(x, u) > 0

(cid:16)

(cid:17)

ters Θ based on an empirical sample from G and then evaluating the resulting analytical probability
¯pP F (x, u) := (cid:82) ∞
0 fG(x,u)(z| ˆΘ(x, u))dz. PF yields a “universal” solution across a range of constraint
levels p.

At a design site (x, u), the probability p(x, u) is estimated in a two-step procedure: ﬁrst estimated
locally over a design Da = {xi, ui} and then regressed over the full input domain X × W. For the ﬁrst
step, we apply nested Monte Carlo to generate a collection of realized {gb(xi, ui)}Mb
b=1 that is used to
construct a parametric density via the maximum likelihood estimate:

(4.7)

ˆΘi := arg max

Θ

Mb(cid:88)

b=1

log fG(gb(xi, ui)|Θ).

In the second step, we evaluate ˜pP F (xi, ui) := (cid:82) ∞
based on the computed {xi, ui, ˜pP F (xi, ui)}Ma

i=1 using L2 projection:

0 fG(z| ˆΘ(xi, ui)) and extend it to the full domain X ×W

(4.8)

ˆpP F = arg min
ˆp∈MT

(cid:107)ˆp(xi, ui) − ˜pP F (xi, ui)(cid:107)2,

where MT is an approximation space chosen for regression. The admissible set U(x) is estimated as:

ˆUP F (x) := {u : ˆpP F (x, u) ≤ p} .

A transformation of the distribution G(x, u) might be important for above distribution ﬁtting. For
example, in the context of microgrid, in Section 2.2, G = L(cid:0) sups∈[tn,tn+1) S(s)(cid:1) has a point mass at 0
and thus, any continuous distribution will lead to poor statistical estimation. Using a transformation

that preserves the probability of the target event,

(4.9)

(cid:16)

P

sup
s∈[tn,tn+1)

S(s) > 0|Fn

(cid:17)

= P

(cid:32)

sup
s∈[tn,tn+1)

[L(s) − un −

I(s)
δs

∧ Bmax] > 0 (cid:12)

(cid:12)Fn

(cid:33)

,

δs ∧ Bmax](cid:1).

we work with G(cid:48)(Ln, In, un) := L(cid:0) sups∈[tn,tn+1)[L(s) − un − I(s)
In Figure 2c we present
the empirical and estimated probability z (cid:55)→ P(G(cid:48)(Ln, In, un) > z) when Ln = 5.5, In = 1.48 and
un ∈ {0, 1} for the microgrid example. We model the distribution G(cid:48) using a truncated normal dis-
tribution, P(G(cid:48) ≤ g) = Φ( g−θ2
)1g≥θ1, with parameters Θ = (θ1, θ2, θ3) representing the location of
θ3
censoring, the mean and the standard deviation respectively. At Ln = 5.5, In = 1.48, un = 1.0 and inner
simulation budget Mb = 100, the estimated parameters (ˆθ1, ˆθ2, ˆθ3) = (−1.5, −1.12, 0.53) result in prob-
ability ˜pP F (5.5, 1.48, 1.0) = 0.016. The corresponding probability after L2 projection (equation (4.8))
is ˆpP F (5.5, 1.48, 1.0) = 0.017. Thus at p = 0.05, the control u = 1.0 ∈ ˆUn is admissible. However, at
un = 0, (ˆθ1, ˆθ2, ˆθ3) = (−0.5, −0.12, 0.55), ˜pP F (5.5, 1.48, 0.0) = 0.414 and ˆpP F (5.5, 1.48, 0.0) = 0.429, thus
the control u = 0 /∈ ˆUn is inadmissible.

4.2. Quantile estimation. In this section we consider methods for modeling and estimating q(xi, ui),

the (1 − p)-th quantile of the distribution G(xi, ui). Admissibility corresponds to the quantile being neg-
ative.

18

A. BALATA, M. LUDKOVSKI, A. MAHESHWARI AND J. PALCZEWSKI

(a) LR (Ma = 10000, Mb = 1)

(b) GPR (Ma = 2000, Mb = 50)

(c) PF (Mb = 100)

(d) SVM (Ma = 2000, Mb = 50)

(e) EP (Ma = 1000, Mb = 100)

(f) QR (Ma = 10000, Mb = 1)

Fig. 2: Training data and ﬁtted models for the methods of Section 4 at u = 0. Top row: probability estimation schemes,
bottom row: quantile estimation schemes. Top/left panel: Training set {Li, I i, yi}Ma
i=1 for the LR model, color-coded
according to the value of yi ∈ {0, 1}, along with the estimated contours for ˆpLR(L, I) at levels {1%, 5%, 10%}. Top/center:
Training set {Li, I i, ¯pi}Ma
i=1 color-coded according to ¯pi for GPR along with the contour {ˆpGP R(L, I) = 5%}. Top/right:
parametric density ﬁtting at L0 = 5.5, I0 = 1.48 and u ∈ {0, 1}. We show the empirical and ﬁtted inverse cdf P(G(cid:48) > g)
based on a truncated Gaussian distribution. Bottom/left: Training set {Li, I i, yi}Ma
i=1 for SVM (color-coded according to
yi ∈ {−1, 1}) and the decision boundary in red. Bottom/center: Training set {Li, I i, ¯qi}Ma
i=1 color-coded according to ¯qi for
EP and the contour {ˆq = 0}. Bottom/right: Training set {Li, I i, gi}Ma
i=1 color-coded according to gi for QR along with the
contour {ˆqQR(L, I) = 0}. All models share the same ground truth, so the red contours are identical up to model-speciﬁc
estimation errors.

action pairs and generate batched samples {gb(xi, ui)}Mb
estimate of q(xi, ui) is simply the (1 − p)th percentile of the realized {gb}Mb

4.2.1. Empirical percentiles (EP). As before, we start by choosing Ma design sites of state-
b=1 from each design site (xi, ui). The empirical
b=1 (which requires Mb > p−1):
(cid:17)

(cid:16)

¯q(xi, ui) = percentile

{gb}Mb

b=1, 100(1 − p)%

.

Similar to previous methods, we extend to arbitrary (x, u) (cid:55)→ ˆq(x, u) using regression on the dataset
i=1 and an approximation space Mq. The set of admissible controls for x is: ˆUEP (x) :=
{xi, ui, ¯q(xi, ui)}Ma
(cid:111)
(cid:110)
. In Figure 2e we show the estimated ˆq(·, ·, 0) indicated via the background colormap.
u : ˆq(x, u) ≤ 0
n (0), is the

The thick red line indicates the zero-contour ˆq = 0, so that the admissibility set for u = 0, X a
region to the left of the contour.

Remark 4.4. This approach is similar to the INMC approach discussed in Section 4.1, however,

here we model the quantile rather than the probability of exceeding zero. Furthermore, we can use the
regression standard error of ˆq(·, ·) to construct a more conservative estimate of the admissible set UEP (x).

-202468Net demand0246810Inventory1%5%10%-202468Net demand0246810Inventory00.10.20.30.40.50.60.70.80.91-1.5-1-0.500.511.52g00.20.40.60.81P(G' > g)emp. distribution u=0emp. distribution u=1est. distribution u=0est. distribution u = 1-202468Net demand0246810Inventory-202468Net demand0246810Inventory-6-4-202468-202468Net demand0246810Inventory-6-4-202468STATISTICAL LEARNING FOR PROBABILITY-CONSTRAINED STOCHASTIC OPTIMAL CONTROL

19

A popular alternative to adjusting ¯q’s via regression standard errors is to replace the empirical

percentile with the empirical conditional tail expectation (CTE):

CTE(xi, ui) :=

(cid:80)Mb

b=1 gb1gb≥¯q(xi,ui)
(cid:80)Mb
1gb≥¯q(xi,ui)
b=1

,

and then running a regression on the training set (xi, ui, CTE(xi, ui)) to obtain the ﬁtted CTE surface
(cid:91)CTE(x, u) and ﬁnally ˆUCT E(x) := (cid:8)u : (cid:91)CTE(x, u) ≤ 0(cid:9). This idea is similar to regularizing the Value-
at-Risk estimation with the Conditional VaR.

4.2.2. Support Vector Machines (SVM). For a ﬁxed control u, ﬁnding the admissible set X a

n (u)
in (2.9) can be interpreted as classifying each input x as being in X a
n (u) or not. Therefore, we consider
the use of classiﬁcation techniques, speciﬁcally support vector machines (SVM). This approach does not

estimate the (1 − p)-quantile q(x, u), but rather its 0-level set with respect to (x, u). The starting point
is to use the nested Monte Carlo simulations to compute ¯p(xi, ui) with much smaller batch size Mb
compared to Section 4.1. Next, we construct a binary classiﬁcation objective with a training dataset
{xi, ui, yi}Ma

i=1 where the ±1-labels are

(4.10)




1,

yi :=

if ¯p(xi, ui) < p;



−1, otherwise.

The boundary separating the two classes is evaluated by solving the optimization problem:

(4.11)

min
β∈RK

(cid:110) Ma(cid:88)

i=1

(cid:16)

(cid:17)
1 − yi[βT φ(xi, ui) + β0]

+

+

C
2 · Ma

||β||2(cid:111)
,

where φ(x, u) = (cid:2)φ1(x, u), φ2(x, u), . . . , φK(x, u)(cid:3)T
rameter. We estimate the set of admissible controls corresponding to x as:

are the K basis functions and C is the penalty pa-

ˆUSV M (x) :=

(cid:111)
(cid:110)
u : ˆβT φ(x, u) + ˆβ0 ≥ 0
.

Figure 2d displays the estimated ˆX a

n (u) and the corresponding dataset (Li, I i, 0, yi) (u = 0 is ﬁxed).

The region where u = 0 is admissible is to the left of the (thick red) decision boundary.

Remark 4.5. A conservative estimate ˆU (ρ)
by re-labeling the training points in (4.10) via:

SV M is obtained by biasing the decision boundary to the left

(4.12)




1,

yi =

if ¯p(xi, ui) + zρ

(cid:113) ¯p(xi,ui)(1− ¯p(xi,ui))
Mb

< p



−1, otherwise.

4.2.3. Quantile Regression (QR). QR directly constructs a parametric model for q(x, u):

ˆq(x, u; β) :=

(cid:88)

k

βkφk(x, u).

To estimate the coeﬃcients β ∈ RK, we use the dataset {xi, ui, gi}Ma
distribution G(xi, ui)) to maximize the negative log likelihood:

i=1 (where gi is a sample from the

ˆβ = arg min
β∈RK

(cid:26) Ma(cid:88)

L(p)(cid:16)

gi −

i=1

K
(cid:88)

k=1

βkφk(xi, ui)

(cid:17)(cid:27)

,

20

A. BALATA, M. LUDKOVSKI, A. MAHESHWARI AND J. PALCZEWSKI

where L(p)(y) = y(p − 1{y<0}) = py+ + (1 − p)y−. As for the parametric density ﬁtting, a transfor-
mation of G(x, u) might be beneﬁcial when applying quantile regression. Figure 2f presents the dataset
i=1 (background colormap) and the estimated admissible set ˆX a(0) which is the region to
{Li, I i, 0, gi}Ma
the left of the contour {ˆqQR(L, I) = 0} (thick red line).

Relying on the Delta method again to compute the variance of the estimated quantile ˆq(x, u; ˆβ) as

φ(x, u)(cid:48)V ar( ˆβ)φ(x, u), the admissible set at x at conﬁdence level ρ is:

(cid:98)U (ρ)
QR(x) :=

(cid:110)
u : ˆq(x, u; ˆβ) + zρ

(cid:113)

φ(x, u)T V ar( ˆβ)φ(x, u) ≤ 0

(cid:111)
.

5. Case Studies. Recall the problem introduced in Section 2.2 where we control the operation

of a diesel generator in order to match demand at minimal cost while maintaining the probability of

blackout between each decision epoch below a given threshold p. In this section, we discuss two variants

of such microgrid control.

In the ﬁrst example, we assume a time-homogeneous net-demand process

which reduces the problem of estimating admissible set to a pre-processing step. In the second example,

we use time-dependent net demand process calibrated to data obtained from a microgrid in Huatacondo,

Chile. Time-inhomogeneity requires to estimate the admissible set at every step. The microgrid features a
perfectly eﬃcient battery, so that the respective power output at tnk (recall tnk is a generic time instance
on the ﬁnely discretized time grid) is given by:

Bnk = max

(cid:16)

(cid:16)

min

Lnk − un,

Ink
∆nk

(cid:17)

, −

Imax − Ink
∆nk

(cid:17)

.

Table 1 lists other microgrid parameters, i.e. capacity of the battery Imax, maximum charging rate Bmin,
maximum discharging rate Bmax and diesel switching cost K.

Table 1: Parameters for the Microgrid example.

Imax = 10 (kWh), Bmin = −6, Bmax = 6 (kW), K = 5
T = 48 (hours), ∆t = 0.25 (hours)

5.1. Implementation details. Numerical Gold Standard: In the absence of analytic bench-

mark, we use a high-budget gold standard to compare the output from the models discussed in Section 4.
For each ﬁxed time-step tn we discretize the domain X = (L, I) into 10, 000 design sites over a grid of
100 × 100. For each design site (Li, I j), i, j ∈ {1, . . . , 100} and uk ∈ 0 ∪ {1 = u1, . . . , u101 = 10}, we
evaluate ˆp(Li, I j, uk) using (4.1) with batch size Mb = 10, 000. Thus, the total simulation budget is
100 × 100 × 102 × 10000 ≈ 1010. We then evaluate the local minimal admissible control

n (Li, I j) = min (cid:8)u : ˆp(Li, I j, u) < p(cid:9) .
umin

To evaluate umin

n (L, I) at new sites we employ linear interpolation on the dataset {Li, I j, umin

i,j=1.
To estimate the continuation function, we use the piecewise continuous approximation of Section 3.2
with MI = 15, Mu = 15 and ML = 1500 sites in L. The design Dc is constructed as the Cartesian product
{L1, L2, . . . , LML}×{I 0, I 1, . . . , I MI }×{u0, u1, . . . , uMu }, where Li, i = 1, . . . , ML are sampled uniformly
from the interval [Lmin, Lmax] = [−8, 8]. The inventory {I 0, I 1, . . . , I MI } and control {u1, . . . , uMu }
discretizations are equispaced in [0, Imax] and [u, u] respectively.

n (Li, I j)}100

STATISTICAL LEARNING FOR PROBABILITY-CONSTRAINED STOCHASTIC OPTIMAL CONTROL

21

Low budget policies: We approximate the continuation value function C using a piecewise contin-
uous approximation with degree-3 in L combined with interpolation in other dimensions. The design Dc
is the same as for the numerical gold standard with discretization levels ML = 1000, MI = 10, Mu = 10.
We approximate the admissible set U using the methods described in Section 4 and compare the
performance of each method by using a ﬁxed set of M (cid:48) = 20, 000 out-of-sample simulations. To address
the discontinuity in W = 0 ∪ [u, u], we implement two separate statistical models to learn Un(·). As an
example, with logistic regression of Section 4.1.3 we estimate two sets of parameters in equation (4.5):
the ﬁrst one uses one-step paths generated with u = 0 and a two-dimensional regression of yi,(1) against
(Li, I i). The second one uses design sites in the three-dimensional space (L, I, u) where u ∈ [1, 10] and
a 3-D regression of yi,(2) against (Li, I i, ui). For both regressions we choose a Sobol sequence space-
ﬁlling experimental design: Da = (Li, I i) ∈ [−2, 8] × [0, 10] when u = 0, and Da = (Li, I i, ui) ∈
[−2, 8] × [0, 10] × [1, 10] otherwise. The control space [1, 10] is discretized into 51 levels.

Additional parameters used for each method are speciﬁed in Table 2. We found that Matern-3/2

kernels work better than (4.4) for smoothing ¯p(L, I, u) (GPR) and ˜p(L, I, u) (PF) because the respec-

tive input-output maps feature steep transitions as a function of (L, i, u). It is known that “rougher”
kernels are better suited for such learning tasks compared to the C∞-smooth squared exponential kernel
(4.4) by allowing the ﬁtted ˆp to have more “wiggle room”. On the other hand, in the context of EP
and CTE the input observations of ˆq(L, I, u) and CTE(L, I, u) are quite smooth in (L, i, u) and both
GP kernel families perform equally well. The algorithms are implemented in python 2.7. We used
“GaussianProcessRegressor” and “SVM.SVC” functions from sklearn library for GPR and SVM re-
spectively. For LR and QR we used “Logit” and “quantile regression” functions from statsmodels
library.

Table 2: Parameters for the estimation of the admissible sets for each method. We use total simulation budget of 105 for
all models except the Gold Standard.

Method

Budget (Ma × Mb)

Further parameters

Gaussian Process (GPR)

Logistic Regression (LR)

Parametric Density Fitting (PF)

Empirical Percentile (EP)

Conditional Tail Expectation (CTE)

Quantile Regression (QR)

Support Vector Machine (SVM)

Gold Standard (GS)

2000 × 50
105 × 1
2000 × 50

1000 × 100

1000 × 100
105 × 1
2000 × 50
106 × 104

Matern-3/2 kernel

Degree-2 polynomials

Truncated Gaussian, Matern-3/2 kernel

Squared exponential kernel

Squared exponential kernel

Degree-4 polynomials

C =1, RBF kernel
budget = 1010

5.2. Example 1: Microgrid with Stationary Net Demand. In this subsection, we assume

time-homogeneous Ornstein-Uhlenbeck dynamics of the net demand process

(5.1)

dL(t) = −λL(t)dt + σdB(t) =⇒ L(t) = L(0)e−λt + σ

(cid:90) t

0

e−λ(t−s)dB(s),

where (B(t)) is a standard Brownian motion. This scenario reduces the complexity of learning the
probability constraints since we need to estimate the admissible set U0(·) only once as a pre-processing

22

A. BALATA, M. LUDKOVSKI, A. MAHESHWARI AND J. PALCZEWSKI

step before starting the approximate dynamic programming scheme for the continuation values. The

simpliﬁed setting oﬀers a good testbed to evaluate the performance of diﬀerent admissible set estimation

methods of Section 4; we show that the relative performance remains similar as we extend to more

realistic dynamics in Section 5.3. For this example, we assume the mean reversion parameter λ = 0.5

and volatility σ = 2.

Figure 3a plots the resulting costs ˆV0(0, 5) versus the frequency of inadmissible decisions wf req for
diﬀerent methods of Section 4. We show the results both for p = 0.05 (dark blue), and p = 0.01

(light grey) and benchmark both cases against the numerical gold standard. Since the probabilistic
constraints form the crux of the problem, we require schemes to maintain ˆu ∈ Un as much as possible,
i.e., wf req ≈ 0. At p = 5%, we observe 0.09% , 0.54% and 1.36% frequency of inadmissible decisions
with logistic regression (LR), Gaussian process regression (GPR) and parametric density ﬁtting (PF),
respectively. Such accuracy might be deemed acceptable. However wf req is much worse (as high as 8.4%
with EP) for the other methods. While all the methods are a priori consistent, admissible set estimation

via probability-based methods clearly seems to outperform quantile-based ones. Our experiments suggest

that at low simulation budget, estimators of p(x, u) have signiﬁcantly lower bias compared to estimators

of q(x, u), thus partially explaining the diﬀerence. For a more stringent threshold p = 1%, we ﬁnd

the cost of all the methods to increase, without signiﬁcant diﬀerence in the frequency of inadmissible
decisions wf req. Indeed, Figure 3 illustrates the trade-oﬀ between lower costs and lower wf req (i.e. more
conservative estimate of the constraints).

Table 3 expands Figure 3 by also reporting the corresponding ˜T statistic, the average inadmissibility

margin wavm and realized frequency of violations (i.e. blackouts) wrlzd deﬁned as:

(5.2)

(5.3)

wavm :=

wrlzd :=

(cid:80)

n,m(cid:48) |ˆun(xˆu,m(cid:48)
n
(cid:80)

) − umin
n,m(cid:48) 1

n (xˆu,m(cid:48)

n

)|1

ˆun(x ˆu,m(cid:48)

n

ˆun(x ˆu,m(cid:48)

n

)−umin

n (x ˆu,m(cid:48)

n

)<0

n (x ˆu,m(cid:48)

n

)<0

)−umin
;

1
N · M (cid:48)

(cid:88)

1

n,m(cid:48)

sups∈[tn,tn+1) Sm(cid:48) (s)>0.

We ﬁnd the realized frequency of violations wrlzd to be lowest for LR, GPR and PF. The average
inadmissibility margin wavm is also lowest for GPR and PF (the large value of wavm for LR is attained in
very small region as evident from wf req ≈ 0). The ˜T statistic is negative for LR, GPR and PF and positive
for the rest, meaning that all other methods fail to statistically respect the probability constraints when
binding. Due to small frequency of inadmissible decisions wf req, cost ˆV0(0, 5) similar to the numerical
gold standard and negative test statistic ˜T , we recommend LR, GP and PF methods for the problem at
hand.

Next, we test the sensitivity of the cost in terms of the probability threshold p (employing logistic
regression ˆULR) in Figure 3b. Increasing p decreases V as the set of admissible controls U monotonically
increases in p. For example, any admissible control at p = 1% threshold is also feasible for p > 1%, thus

the respective cost at 1% will be at least as much as at, say, 10% threshold.

As previously discussed, the constraint is binding for only approximately 10% of time-steps.
In
fact, that probability varies across the methods since the estimate of ˆU aﬀects the choice of ˆun and
ultimately the distribution of ˆXn. Intuitively, the realized system states are driven by the estimates of
the probabilistic constraints. Typically, more conservative estimates of U will push ˆX0:N away from the
“risky” regions. This is also conﬁrmed in Figure 3 where as p → 1, wrlzd → 20% = wbind while in Table 3
wbind (cid:39) 10%.

STATISTICAL LEARNING FOR PROBABILITY-CONSTRAINED STOCHASTIC OPTIMAL CONTROL

23

The metrics wf req (3.14), wbind (3.18), wrlzd (5.3) are closely linked. As the inadmissible decisions
can occur only when the constraint is binding, umin > 0, we expect wf req ≤ wbind and wf req ≈ wbind
for a method with a bias in overestimating the admissible set (e.g. X a,EP (u) ⊃ X a,GS(u) ∀u ∈ W). The
realized violations (blackouts) wrlzd can be represented as a sum of three:

wrlzd = p1wf req + p2(wbind − wf req) + p3(1 − wbind),

p1 + p2 + p3 = 1,

where the weights p1, p2, p3 depend on the distribution of the controlled trajectories. The ﬁrst term
represents the instances when the constraint is binding but the controller chooses an inadmissible control
(i.e. mis-estimates ˆU). The second term represents instances when the constraint is binding and correctly
estimated, but due to random shocks violations take place (with a conditional frequency below the

speciﬁed p = 0.05). The last term represents instances when the constraint is not binding but some

violations still occur with the intrinsic conditional frequency strictly less than p. Note that due to
wbind (cid:28) 1, most of the violations are of the latter type, i.e. take place when u∗ = 0 and the conditional
violation probability is below p. We illustrate these scenarios in Figure 3c using the LR model. Thus, the

ﬁrst term counts the instances when violations occur at the same time as controller makes an inadmissible

decision (circle encircling triangle), the second term counts the triangles when I ≈ 0, and the third term
the triangles in the grey region where the constraint is not binding (violations when umin = 0).

Although we observed poor performance of quantile based methods, asymptotically (with respect

to the simulation budget) we expect them to perform similar to the probability based methods. As an

example, in Appendix A Table 6, we present the performance of SVM for thresholds p = 5% and p = 1%
with increasing budget. For p = 5% and by increasing the simulation budget from 105 to 108, we ﬁnd the
frequency of inadmissible decisions wf req to drop from 5.93% to 1.5%, average inadmissibility amount
wavm from 0.78 kW to 0.27 kW, frequency of realized blackouts wrlzd from 2.80% to 0.30% and the test
statistic which rejected the method at 105 simulation budget (T (cid:29) 0) suggests to accept it (T (cid:28) 0)
at 108 simulation budget. We observe similar behavior at p = 1%. The main challenge with quantile-
based methods is the underlying bias in learning q(x, u). This bias is known to converge to zero slowly,
necessitating a relatively large Mb. A glimpse of this can be observed in Appendix A where SVM does
not perform adequately all the way up to total budget of 108. Increasing Mb with Ma ﬁxed oﬀers only
a limited improvement that tapers oﬀ quickly, as was observed previously in [26]. Keeping a constant
budget, a high Mb forces a low Ma which oﬀsets these performance gains as the regression is not able to
properly explore the space.

There are many techniques to improve ¯q, for example variance reduction tools. We have experimented

with variance reduction for the SVM method by using antithetic variables. Although the results were

marginally better, they were not meaningfully diﬀerent from those reported in Appendix A. A completely
diﬀerent way to improve EP and SVM could be to judiciously choose the simulation design Da. Paper [26]
explores various approaches to build simulation designs for estimating the continuation value function
and documents their strong impact on performance. We anticipate that a similar strategy for Da may
improve convergence.

Conservative estimators for U. Algorithms for SCPC are expected to respect the probabilistic

constraints, so that it is critical to minimize the occurrence of inadmissible decisions. As discussed in
Section 4, one way to raise the statistical guarantee for admissibility of ˆU is by adding a margin of error
ξ(x, u). This yields a more conservative (i.e. smaller) ˆU and hence lowers wf req. In Table 4 we examine
three scenarios for ξ(x, u) sorted from least to most conservative (in all cases we maintain p = 5%):

24

A. BALATA, M. LUDKOVSKI, A. MAHESHWARI AND J. PALCZEWSKI

(a)

(b)

(c)

Fig. 3:

Left panel: Trade-oﬀ between cost ˆV0(0, 5) and frequency of inadmissible decisions wf req for the stationary

model. Dark blue points correspond to p = 5% probability constraint threshold and light grey ones to p = 1%. Center:
Total cost ˆV0(0, 5) (left axis, blue stars) and realized frequency of violations wrlzd (right axis, red circles) as functions
of p employing the LR model. Right: Locations (L, I) of realized violations sups∈[tn,tn+1) Sm(cid:48)
inadmissible decisions ˆu(n, xˆu,m(cid:48)

) < 0 (circles with color representing the inadmissibility margin) on 5000

(s) > 0 (red triangles),

) − umin

n (xˆu,m(cid:48)

n

n

out-of-sample simulations using LR model. The constraint is binding in the white region and is not binding in the grey

region.

Table 3: Cost of running the microgrid ˆV0(0, 5), frequency of inadmissible decisions wf req, average inadmissibility margin
wavm, realized frequency of violations (i.e. blackouts) wrlzd, test statistic ˜T and frequency of binding constraint wbind for
the example in Section 5.2.

Method

ˆV0(0, 5) ($) wf req (%) wavm (kW) wrlzd (%)

GS

LR

GPR

PF

SVM

QR

CTE

EP

26.79

26.83

26.89

26.79

26.68

27.04

26.99

26.36

0.00

0.09

0.53

1.36

5.26

5.95

7.79

8.39

0.00

0.82

0.16

0.27

0.55

0.33

0.43

0.49

0.37

0.03

0.11

0.21

1.83

0.98

1.63

1.98

˜T

-

-125

-98

-69

388

145

320

403

wbind (%)

-

8.69

8.10

8.51

9.67

9.49

9.93

10.45

• Scenario 1: unadjusted ξ = 0% (same as Table 3);
• Scenario 2: ξ(ρ)(x, u) at 95% conﬁdence level, zρ = 1.96;
• Scenario 3: ﬁxed ξ = 4%, which is equivalent to lowering the violation threshold to p − ξ = 1%.
Table 4 conﬁrms the intuition that the frequency of inadmissible decisions wf req should be decreasing
from scenario 1 to 3. This is illustrated in Figure 4 that shows how the minimum admissible control is
aﬀected by ξ(x, u). Although adding a margin of error does lower wf req, this mechanism does not really
alter the relative performance of the diﬀerent methods. Thus, for all three scenarios, we ﬁnd SVM, CTE
and EP to give unreliable estimates of U (since ˜T (cid:29) 0). An exception is QR which yields high wf req
for ξ = 0 but does become acceptable ( ˜T < 0) in scenario 3. In contrast, LR, GPR and PF perform

02468Frequency of inadmissible decisions wfreq (%)2626.52727.52828.52929.5Total CostLRGPRSVMQRPFCTEEPGSLRGPRSVMQRPFCTEEPGS10-310-210-1100probability threshold051015202530Total Cost10-510-410-310-210-1100Realized frequency of violations-202468Net demand0246810Inventory00.20.40.60.81STATISTICAL LEARNING FOR PROBABILITY-CONSTRAINED STOCHASTIC OPTIMAL CONTROL

25

well throughout. Table 7 in Appendix B provides additional results as we vary the conﬁdence level to
ρ = 90%, 99% and 99.95%, with the same general conclusions. (Observe that a wf req very close to zero
likely implies that ˆU ⊂ U is strictly smaller and the controller is so conservative as to rule out some
admissible actions.)

We generally expect the ultimate cost ˆV0(0, 5) to increase as ˆU becomes more conservative, see the
estimated ˆV ’s across each row of Table 4. The increase in costs arises due to two factors: when the
diesel generator is started sooner (due to u = 0 becoming inadmissible as ξ is raised), and the higher

level of ˆu once the diesel is ON. This can be seen in Figure 4 where in Scenarios 2 and 3 the controller

switches the generator at a lower net demand and once the diesel is running picks a higher power output
(ˆumin(·, I; p = 5%, ξ) − ˆumin(·, I; p = 5%, ξ = 0) > 0). We stress that the link between ˆU and ˆV is
complicated by the fact that as ˆU changes, so does the distribution of the controlled paths. So for
example in Table 4 the cost for QR falls in Scenario 2, although it remains within two Monte Carlo

standard errors.

Table 4: Impact of margin of error ξ on the estimated cost of running the microgrid ˆV0(0, 5), frequency of inadmissible
decisions wf req, and test statistic ˜T from (3.17). The probabilistic constraint is p = 5%.

ξ = 0%

ξ(0.95)(x, u)

ξ = 4%

Method

ˆV0(0, 5) wf req

GS

LR

GPR

PF

SVM

QR

CTE

ER

26.79

26.83

26.89

26.79

26.68

27.04

26.99

26.36

0.00

0.09

0.53

1.36

5.26

5.95

7.79

8.39

˜T

-

-125

-98

-69

388

145

320

403

ˆV0(0, 5) wf req

-

26.95

28.00

-

29.65

26.89

27.36

26.97

-

0.08

0.01

-

3.41

5.17

7.52

7.78

˜T

-

-124

-110

-

225

72

274

225

ˆV0(0, 5) wf req

-

27.86

28.12

27.91

29.60

28.61

28.44

28.13

-

0.04

0.00

0.44

3.41

0.00

6.83

7.08

˜T

-

-112

-107

-96

225

-117

248

283

Take-aways. Our experiments demonstrate the following: (i) To accurately estimate admissible sets

of the form (2.3) we recommend to use LR, GPR or PF which all model the underlying probability of

violations p(x, u). Although asymptotically equivalent, the approach of quantile estimation leads to poor
estimates ˆUn for practical budgets. (ii) Frequency of inadmissible decisions can be partly controlled by
n at the expense of higher costs. However, even a conservative ˆU ξ fails
using conservative estimates ˆU ξ
to make quantile-based methods acceptable, except for QR. (iii) For a new application, our suggested
approach is to ﬁrst evaluate the test statistic ˜T at ξ = 0% using one of the recommended methods.
Depending on how close is ˜T to zero, one can then adjust ˆU’ via ξ to improve the statistical guarantees
on the frequency of inadmissible decisions wf req.

5.3. Example 2: Microgrid with seasonal demand. Unlike the previous example, where we

assumed time-homogeneous net demand, in practice there is seasonality: during the day renewable gener-

ation is high and net demand is often negative; during morning/evening demand exceeds supply making

L(t) > 0. To incorporate this seasonality we use time-dependent Ornstein Uhlenbeck process (see [17]

26

A. BALATA, M. LUDKOVSKI, A. MAHESHWARI AND J. PALCZEWSKI

(a) LR

(b) QR

Fig. 4: Impact of the margin of error ξ(·, ·) on minimum admissible control ˆumin. We plot the diﬀerence between
minimum admissible control for scenario 2 (ˆumin(·, I; ξ(0.95)(L, I))) and scenario 3 (ˆumin(·, I; ξ = 4%)) with respect
to scenario 1 (ˆumin(·, I; ξ = 0%)) using LR (left panel) and QR (right panel) models.

for a similar microgrid control problem):

(5.4)

dL(t) =

(cid:20) ∂µ
∂t

(t) + λ(cid:0)µ(t) − L(t)(cid:1)

(cid:21)

dt + σ(t)dB(t).

Here, λ represents the speed of mean reversion towards the seasonal mean µ(t), while σ(t) represents the

time-varying volatility. Using Itˆo’s lemma and integration by parts one can prove that

L(t) = µ(t) + e−λt(cid:0)L(0) − µ(0)(cid:1) +

(cid:90) t

0

e−λ(t−s)σ(s)dB(s).

Thus,

E[L(t)] = µ(t) + e−λt(L(0) − µ(0)).

We calibrate µ(t) and σ(t) in (5.4) using iterative methodology described in [17] and the data from
a solar-powered microgrid in Huatacondo, Chile1. Speciﬁcally, we compute the mean and variance of
the residual demand over 24 hours at 15-minute intervals using data from Spring 2014, i.e. compute
{µ1, µ2, . . . , µ96} and {σ1, σ2, . . . , σ96}. The estimated µ(t) can be seen in the left panel of Figure 5 that
plots the empirical average of L(t). As expected, during the day, i.e., t ∈ [12, 20] (noon-8:00 pm), the

expected net-demand is negative (µ(t) < 0) while it is positive (µ(t) > 0) in the morning and during the

night. The volatility σ(t) is higher during the day due to the intermittent and unpredictable nature of

solar irradiance. The mean reversion parameter was estimated to be λ = 0.3416.

To visualize the interplay of the net demand, inventory and optimal control, the left panel of Figure 5

presents the average trajectories of the three processes over 48 hours. During the morning hours when

the demand L(t) is high and the battery is empty, the controller uses the diesel generator. During

the day when the renewable output is high and L(t) is negative, the controller switches oﬀ the diesel

and the battery charges itself. However, the non-trivial region is when the average net-demand changes

1https://microgrid-symposiums.org/microgrid-examples-and-demonstrations/huatacondo-microgrid/

-6-4-20246Net demand00.511.5umin(,0 ; p=5%,)- umin(,0 ; p=5%,=0) = 4%(0.95)(L,I=0)-6-4-202468Net demand00.511.5umin(,0 ; p=5%,)- umin(,0 ; p=5%,=0) = 4%(0.95)(L,I=0)STATISTICAL LEARNING FOR PROBABILITY-CONSTRAINED STOCHASTIC OPTIMAL CONTROL

27

sign, either from positive to negative around noon or negative to positive in the evening. During the

former time interval, the optimal control process is in {0, 1} (recall that minimum diesel output is 1).

Similarly, during the evening when the net demand becomes positive (as the renewable output declines),

the controller quickly ramps up the diesel to match L(t) (cid:29) 0. The right panel of Figure 5 repeats the

average control and inventory curves, also showing their 2-standard deviation bands (in terms of the
out-of-sample trajectories of ˆLˆu
0:T ). As expected, the time periods around ramp-up or ramp-down of the
diesel generator is when ˆun experiences the greatest path-dependency and dispersion and diﬀers most
from the demand curve.

Fig. 5: Model parameters, average trajectory of the state variables, control and their variance. Left panel: Average values
m(cid:48)=1 ˆum(cid:48)
of net demand 1
n processes using
M (cid:48)
the gold standard strategy. Right panel: 95% conﬁdence bands for net demand Lˆu
n and realized optimal diesel control ˆun.
Net demand and diesel output is measured in kW and Inventory in kWh.

and optimal control (diesel)

, inventory 1
M (cid:48)

m(cid:48)=1 Lˆu,m(cid:48)

m(cid:48)=1 I ˆu,m(cid:48)

(cid:80)M (cid:48)

(cid:80)M (cid:48)

(cid:80)M (cid:48)

1
M (cid:48)

n

n

Comparing Table 5, which lists the estimated cost ˆV0(µ(0), 5) along with related statistics, with
Figure 3 indicates that incorporating seasonal net-demand process does not change the relative order of

performance between the methods. The cost goes up as the diesel generator has to be used throughout

the mornings and the evenings to match demand.

As in the previous example, the performance of LR, GPR and PF almost matches the gold standard

despite signiﬁcantly lower simulation budget. In this setting the constraint is binding approximately 45%

of the time (except for GPR and PF where it is 30% and 25% of the time). Frequency of inadmissible
decisions wf req is 0.03% for LR, 1.17% for GPR, and 0.02% for PF. In contrast wf req is 43% for QR,
22% for EP, 43% for SVM and 22% for CTE, implying that all these schemes are highly unreliable for
learning ˆU. The average inadmissibility margin wavm is also signiﬁcantly lower for GPR (0.14 kW) and
PF (0.26 kW) compared to the rest of the methods. Here again we observe larger inadmissibility margin

and very low frequency of inadmissible decisions for logistic regression. Similar behavior is also evident
for the test statistic ˜T and realized frequency of violations wrlzd.

m=1 ˆun(xˆu,m(cid:48)
n
n ) := 1
M (cid:48)

To illustrate the typical behavior over a trajectory, Figure 6 plots the average control Ave(ˆun) :=
(cid:80)M (cid:48)
) corresponding to diﬀerent methods and the average minimum admissible control
(cid:80)M (cid:48)
m(cid:48)=1 umin

) computed using the gold standard. Notice that the latter is de-
n ) across methods. We expect
n ) if a given method does not violate the constraint most of the time. This is true

1
M (cid:48)
Ave(umin
pendent upon the controlled trajectories xˆu
Ave(ˆun) above Ave(umin

n, resulting in diﬀerent Ave(umin

n (xˆu,m(cid:48)

n

010203040time (hours)-3-2-101234Net demand/Diesel012345678910InventoryNet demandDieselInventory010203040time (hours)-4-3-2-10123456Net demand/DieselNet demandDiesel28

A. BALATA, M. LUDKOVSKI, A. MAHESHWARI AND J. PALCZEWSKI

Table 5: Cost of running the microgrid ˆV0(µ(0), 5), frequency of inadmissible decisions wf req, average inadmis-
sibility margin wavm, realized frequency of violations wrlzd and frequency of the constraint being binding wbind
for the case study in Section 5.3.

Method

ˆV0(µ(0), 5) wf req (%) wavm (kW) wrlzd (%)

GS

LR

GPR

PF

SVM

QR

CTE

EP

53.38

53.78

54.04

54.55

40.52

52.56

53.02

52.82

0

0.03

1.17

0.02

43.37

42.87

21.62

21.91

0

0.79

0.14

0.26

0.91

0.28

0.21

0.23

0.30

0.01

0.19

0.01

43.37

38.41

10.43

11.57

˜T

-

-301

-220

-226

5,306

4,772

1,079

1,227

wbind (%)

-

45.2

31.0

25.7

46.4

46.3

46.0

46.1

Fig. 6: Average control Ave(ˆun) for LR, GPR and SVM and the average minimum admissible control Ave(umin
n )
using Gold Standard across forward controlled trajectories.

for LR and GPR, but SVM quite obviously fails, as the dashed line in the leftmost panel of Figure 6 is

signiﬁcantly higher than the solid line at numerous time steps. Furthermore, the conservative nature of

GPR is reﬂected in the large diﬀerence between the average minimum admissible control and the average
optimal control. This is also evident through wbind ≈ 30% for GPR compared to approximately 45% for
the rest of the methods.

6. Conclusion. We developed a statistical learning framework to solve stochastic optimal control

problems with local probabilistic constraints. The key objective of our algorithm is to eﬃciently estimate

the set of admissible controls U(·) and the continuation value function C(·, ·) covering a general formulation

of the state process dynamics and rewards. Since SCPC problems require estimating the admissible set

repeatedly during the backward induction, we use regression based functional representation of x (cid:55)→

U(x). This perspective also provides a natural way of uncertainty quantiﬁcation for admissibility, in
particular oﬀering conservative estimates that bring statistical guarantees regarding ˆU. At the same time,
our dynamic emulation algorithm allows parallel computation of U and C for additional computational

eﬃciency.

Thanks to the plug-and-play functionality of the dynamic emulation algorithm, it was straightforward

010203040time (hours)00.511.522.533.5average controlLogisticminimum admissible GS010203040time (hours)00.511.522.533.5average controlGPRminimum admissible GS010203040time (hours)00.511.522.533.5average controlSVMminimum admissible GSSTATISTICAL LEARNING FOR PROBABILITY-CONSTRAINED STOCHASTIC OPTIMAL CONTROL

29

to test a large variety of schemes for learning U. Our numerical results suggest that estimating probabilis-

tic constraints via logistic regression, Gaussian process smoothing and parametric density ﬁtting is more

accurate than estimating the corresponding quantile (empirical ranking, SVM or quantile regression). A

future line of research would be to additionally parametrize (e.g. using another GP model) the optimal
control map x (cid:55)→ ˆun(x) [14] which would speed-up the algorithm in the context of continuous action
spaces. Another direction would be to extend the one-dimensional control framework described in this

paper to a multi-dimensional setting. In reference to the microgrid example, multi-dimensional control

will allow us to control the diesel output and the demand response or to control output from multiple

dispatchable generators.

Appendix A. Eﬀect of Simulation Budget (Mb × Ma).

Table 6: Impact of simulation budget on performance of SVM for the case study in Section 5.2 and probability thresholds
p = 5% and p = 1%. The reported values are averages over 10 runs of each scheme. The total simulation budget is
divided into batch size Mb and number of design sites Ma. For total budget 105: (Mb, Ma) = (100, 1000); for 106:
(Mb, Ma) = (500, 2000); for 107: (Mb, Ma) = (2000, 5000); for 108: (Mb, Ma) = (10000, 10000).

p

Budget

ˆV0(0, 5) ($) wf req (%) wavm (kW) wrlzd (%)

5%

1%

105
106
107
108

105
106
107
108

26.38

26.55

26.68

26.79

28.32

28.26

28.52

28.41

5.93

5.28

4.96

1.50

6.63

5.17

0.55

0.15

0.78

0.55

0.53

0.27

0.93

0.66

0.24

0.22

2.80

1.84

1.64

0.30

2.43

1.09

0.03

0.01

˜T

665

386

330

-51

1,460

631

-39

-51

wbind (%)

9.73

9.77

9.75

9.22

9.87

9.56

8.78

8.82

Appendix B. Eﬀect of Adaptive Margin of Error Level ρ.

Table 7: Impact of conservative U (ρ) estimators for the case study in Section 5.2. The probabilistic constraint is set at
p = 5%.

ρ = 90%

ρ = 99%

ρ = 99.95%

Method

ˆV0(0, 5) wf req wrlzd

ˆV0(0, 5) wf req wrlzd

ˆV0(0, 5) wf req wrlzd

LR

GPR

SVM

QR

CTE

EP

26.74

27.34

27.35

27.20

27.93

26.78

0.090

0.012

4.975

5.373

7.158

7.990

0.034

0.055

1.732

0.793

1.153

1.497

26.87

28.06

29.20

27.18

28.31

27.17

0.085

0.007

3.481

4.880

6.766

7.629

0.032

0.037

1.117

0.676

0.888

1.183

27.04

28.06

29.72

27.04

28.61

27.96

0.085

0.005

3.395

4.409

6.163

7.102

0.026

0.029

1.088

0.591

0.714

0.956

30

A. BALATA, M. LUDKOVSKI, A. MAHESHWARI AND J. PALCZEWSKI

REFERENCES

[1] S. Ahmed and A. Shapiro, Solving chance-constrained stochastic programs via sampling and integer programming, in
INFORMS TutORials in Operations Research, Z.-L. Chen and S. Raghavan, eds., INFORMS, 2014, pp. 261–269.
[2] J.-C. Alais, P. Carpentier, and M. De Lara, Multi-usage hydropower single dam management: chance-constrained

optimization and stochastic viability, Energy Systems, 8 (2017), pp. 7–30.

[3] L. Andrieu, R. Henrion, and W. R¨omisch, A model for dynamic chance constraints in hydro power reservoir

management, European Journal of Operational Research, 207 (2010), pp. 579–589.

[4] A. Balata and J. Palczewski, Regress-Later Monte Carlo for Optimal Inventory Control with applications in energy,

arXiv:1703.06461, (2017).

[5] A. Balata and J. Palczewski, Regress-Later Monte Carlo for optimal control of Markov processes, arXiv:1703.09705,

(2018).

[6] L. Blackmore, M. Ono, A. Bektassov, and B. C. Williams, A probabilistic particle-control approximation of
chance-constrained stochastic predictive control, IEEE Transactions on Robotics, 26 (2010), pp. 502–517.
[7] L. Blackmore, M. Ono, and B. C. Williams, Chance-constrained optimal path planning with obstacles, IEEE

Transactions on Robotics, 27 (2011), pp. 1080–1094.

[8] A. Boogert and C. de Jong, Gas storage valuation using a Monte Carlo method, The Journal of Derivatives, 15

(2008), pp. 81–98.

[9] A. Boogert and C. de Jong, Gas storage valuation using a multi-factor price process, Journal of Energy Markets,

4 (2011), pp. 29–52.

[10] B. Bouchard and X. Warin, Monte Carlo valuation of American options: Facts and new algorithms to improve
existing methods, in Numerical Methods in Finance: Bordeaux, June 2010, R. A. Carmona, P. Del Moral, P. Hu,
and N. Oudjane, eds., Springer Berlin Heidelberg, Berlin, Heidelberg, 2012, pp. 215–255.

[11] G. C. Calafiore and M. C. Campi, The scenario approach to robust control design, IEEE Transactions on Automatic

Control, 51 (2006), pp. 742–753.

[12] M. C. Campi and G. C. Calafiore, Notes on the scenario design approach, IEEE Transactions on Automatic Control,

54 (2009), pp. 382–385.

[13] R. Carmona and M. Ludkovski, Valuation of energy storage: an optimal switching approach, Quantitative Finance,

10 (2010), pp. 359–374.

[14] M. P. Deisenroth, C. E. Rasmussen, and J. Peters, Gaussian process dynamic programming, Neurocomputing,

72 (2009), pp. 1508 – 1524.

[15] L. Doyen and M. D. Lara, Stochastic viability and dynamic programming, Systems & Control Letters, 59 (2010),

pp. 629 – 634.

[16] A. Geletu, M. Klppel, H. Zhang, and P. Li, Advances and applications of chance-constrained approaches to systems

optimisation under uncertainty, International Journal of Systems Science, 44 (2013), pp. 1209–1232.

[17] B. Heymann, J. F. Bonnans, F. Silva, and G. Jimenez, A stochastic continuous time model for microgrid energy

management, in 2016 European Control Conference (ECC), June 2016, pp. 2084–2089.

[18] L. Janson, E. Schmerling, and M. Pavone, Monte Carlo motion planning for robot trajectory optimization under
uncertainty, in Robotics Research: Volume 2, A. Bicchi and W. Burgard, eds., Springer International Publishing,
Cham, 2017, pp. 343–361.

[19] Y. Jiao, O. Klopfenstein, and P. Tankov, Hedging under multiple risk constraints, Finance and Stochastics, 21

(2017), pp. 361–396.

[20] I. Karatzas and S. E. Shreve, Brownian Motion, Springer New York, New York, NY, 1998.
[21] N. Langren´e, T. Tarnopolskaya, W. Chen, Z. Zhu, and M. Cooksey, New regression Monte Carlo methods for
high-dimensional real options problems in minerals industry, in 21st International Congress on Modelling and
Simulation, 2015.

[22] N. Langren´e and X. Warin, Fast and stable multivariate kernel density estimation by fast sum updating, Journal

of Computational and Graphical Statistics, 28 (2019), pp. 596–608.

[23] C. Liu, X. Wang, Y. Zou, H. Zhang, and W. Zhang, A probabilistic chance-constrained day-ahead scheduling model

for grid-connected microgrid, in 2017 North American Power Symposium (NAPS), 2017, pp. 1–6.

[24] F. A. Longstaff and E. S. Schwartz, Valuing American options by simulation: A simple least-squares approach,

The Review of Financial Studies, 14 (2001), pp. 113–147.

[25] M. Ludkovski, Kriging metamodels and experimental design for Bermudan option pricing, Journal of Computational

STATISTICAL LEARNING FOR PROBABILITY-CONSTRAINED STOCHASTIC OPTIMAL CONTROL

31

Finance, 22 (2018), pp. 37–77.

[26] M. Ludkovski and A. Maheshwari, Simulation methods for stochastic storage problems: A statistical learning

perspective, Energy Systems, 11 (2020), pp. 377–415.

[27] J. Luedtke and S. Ahmed, A sample approximation approach for optimization with probabilistic constraints, SIAM

Journal on Optimization, 19 (2008), pp. 674–699.

[28] A. Nemirovski and A. Shapiro, Scenario approximations of chance constraints, in Probabilistic and Randomized
Methods for Design under Uncertainty, G. Calaﬁore and F. Dabbene, eds., Springer London, London, 2006,
pp. 3–47.

[29] A. Nemirovski and A. Shapiro, Convex approximations of chance constrained programs, SIAM Journal on Opti-

mization, 17 (2007), pp. 969–996.

[30] M. Ono, M. Pavone, Y. Kuwata, and J. Balaram, Chance-constrained dynamic programming with application to

risk-aware robotic space exploration, Autonomous Robots, 39 (2015), pp. 555–571.

[31] A. Pea-Ordieres, J. R. Luedtke, and A. Wchter, Solving chance-constrained problems via a smooth sample-based

nonlinear approximation, arXiv:1905.07377, (2019).

[32] A. Pr´ekopa and T. Sz´antai, Flood control reservoir system design using stochastic programming, in Mathematical
Programming in Use, M. L. Balinski and C. Lemarechal, eds., Springer Berlin Heidelberg, Berlin, Heidelberg,
1978, pp. 138–151.

[33] S. A. P. Quintero, M. Ludkovski, and J. P. Hespanha, Stochastic optimal coordination of small UAVs for tar-
get tracking using regression-based dynamic programming, Journal of Intelligent & Robotic Systems, 82 (2016),
pp. 135–162.

[34] A. Ravichandran, S. Sirouspour, P. Malysz, and A. Emadi, A chance-constraints-based control strategy for micro-
grids with energy storage and integrated electric vehicles, IEEE Transactions on Smart Grid, 9 (2018), pp. 346–359.
[35] O. Roustant, D. Ginsbourger, and Y. Deville, DiceKriging, DiceOptim: Two R packages for the analysis of
computer experiments by kriging-based metamodeling and optimization, Journal of Statistical Software, 51 (2012),
pp. 1–55.

[36] J. N. Tsitsiklis and B. van Roy, Regression methods for pricing complex American-style options, IEEE Transactions

on Neural Networks, 12 (2001), pp. 694–703.

[37] W. van Ackooij, R. Henrion, A. M¨oller, and R. Zorgati, Joint chance constrained programming for hydro

reservoir management, Optimization and Engineering, 15 (2014), pp. 509–531.

[38] W. Van-Ackooij and X. Warin, On conditional cuts for Stochastic Dual Dynamic Programming, ArXiv e-prints,

(2017).

[39] X. Warin, Gas storage hedging, in Numerical Methods in Finance: Bordeaux, June 2010, R. A. Carmona, P. Del Moral,

P. Hu, and N. Oudjane, eds., Springer, Berlin, Heidelberg, 2012, pp. 421–445.

[40] J. Xu and J. S. Long, Conﬁdence intervals for predicted outcomes in regression models for categorical outcomes,

Stata Journal, 5 (2005), pp. 537–559.

