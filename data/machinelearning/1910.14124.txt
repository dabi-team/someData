9
1
0
2

t
c
O
0
3

]
I

A
.
s
c
[

1
v
4
2
1
4
1
.
0
1
9
1
:
v
i
X
r
a

Bayesian causal inference via
probabilistic program synthesis

Sam Witty∗
University of Massachusetts
Amherst, MA 01002
switty@cs.umass.edu

David Jensen
University of Massachusetts
Amherst, MA 01002
jensen@cs.umass.edu

Alexander Lew∗
Massachusetts Institute of Technology
Cambridge, MA 02139
alexlew@mit.edu

Vikash Mansinghka
Massachusetts Institute of Technology
Cambridge, MA 02139
vkm@mit.edu

Abstract

Causal inference can be formalized as Bayesian inference that combines a prior
distribution over causal models and likelihoods that account for both observa-
tions and interventions. We show that it is possible to implement this approach
using a sufﬁciently expressive probabilistic programming language. Priors are
represented using probabilistic programs that generate source code in a domain
speciﬁc language. Interventions are represented using probabilistic programs that
edit this source code to modify the original generative process. This approach
makes it straightforward to incorporate data from atomic interventions, as well
as shift interventions, variance-scaling interventions, and other interventions that
modify causal structure. This approach also enables the use of general-purpose
inference machinery for probabilistic programs to infer probable causal structures
and parameters from data. This abstract describes a prototype of this approach in
the Gen probabilistic programming language.

1

Introduction

Bayesian formulations of causal inference enable practitioners to explicitly reason about uncertainty
when answering structural questions (e.g., “What is the probability that X causes Y ?”) as well as
questions about the effects of a speciﬁc intervention (e.g., “How much will intervening to make
X = x(cid:48) increase the probability that Y = y(cid:48)?”). Bayesian formulations have been developed for
both the potential outcomes framework [17] and the causal graphical models framework [7, 9, 11]. In
principle, Bayesian approaches make it possible to incorporate prior knowledge and make efﬁcient
use of limited data [16, 18].

In this paper, we explore a new approach to implementing Bayesian causal inference based on
probabilistic programming, inspired by Bayesian synthesis [22]. Probabilistic programming languages
enable users to compactly specify probabilistic models in code. Some languages, like Stan [2], have
syntax that closely resembles the statistical notation often used in the literature to deﬁne probabilistic
models: a list of equations of the form x ∼ . . . . Others, like Gen [3], allow users to include
arbitrary program control ﬂow in their models; a model is represented by a program that simulates
stochastically from a distribution. In this paper, we represent hypothesized causal models explaining
some phenomenon as programs in MiniStan, a simple probabilistic programming language designed

∗Contributed equally.

Preprint. Under review.

 
 
 
 
 
 
to resemble Stan (Figure 1). Then, we use a more expressive probabilistic programming language,
Gen, to encode a prior and likelihood over MiniStan programs, and to do inference. The Gen model
(i) stochastically generates MiniStan programs to encode a prior distribution over causal model
structures and parameters, (ii) programmatically edits the generated MiniStan programs to reﬂect
interventions and experimental conditions, then (iii) interprets the MiniStan programs to generate
observational and experimental data. We can then use Gen’s inference programming and conditioning
features to condition the entire process on actual observational and experimental data, and to obtain
posterior samples of the MiniStan code deﬁning the original observational model—that is, to perform
both structure learning and parameter estimation.

Causal models are typically structured as a set of autonomous components [1, 10, 20], such that
interventions in the system can be accurately represented in the model as an alteration of a small
number of model components, and all other model components (and the causal relationships among
them) remain unchanged. In the formalism of causal graphical models, interventions are typically
expressed using the do-operator [20], which ﬁxes the value of one random variable and removes
the inﬂuence of its parents. However, many realistic interventions are not accurately represented
by this particular variety of model alteration [6, 13, 23]. For example, realistic interventions might
best be represented by altering the functional form of a particular dependence, enabling or disabling
speciﬁc causes, or enacting complex combinations of these interventions. This paper demonstrates
interventions represented as modiﬁcations of probabilistic program source code and shows how this
representation enables the Bayesian synthesis approach to handle a broad class of experimental data.

1.1 A conceptual example

Consider the task of inferring whether a student’s belief in her ability is causal for success at a
research project. Observational data on student belief and student success alone are insufﬁcient to
answer this question, due to the confounding effect of skill (see Figures 2a & 2b).

We can imagine multiple types of experiments that would enable effective causal inference despite
the confounding effect of skill. For example, an advisor could encourage a student, shifting her belief
in her ability (but not increasing her skill). An advisor could also administer an assessment on the
key skills needed for the project, before the student attempts it, and look at the results. Unfortunately,
although this might reveal the true skill level to the advisor, this might also change the student’s belief
in her own ability to succeed. Hypothetically, one can imagine a miracle pill that modiﬁes one’s
conﬁdence to a ﬁxed value, without changing anything else. Each of these experiments corresponds to
a different modiﬁcation to the source code from Figures 2c and 2d. Examples of these modiﬁcations
are shown in Figures 3a-f.

This paper shows how to formalize this example, using probabilistic programs that generate, edit, and
interpret the source code of causal models. It also presents results from an implementation in the Gen
probabilistic programming language, demonstrating the utility of incorporating diverse sources of
experimental data.

2 Priors on Causal Models

To compute the posterior distribution over the two candidate causal models, we ﬁrst specify a prior
distribution over a set of global latent variables. One of these variables, edge, determines whether
Belief inﬂuences Outcome.

P → S | S; P
S → x = E | x ∼ D
D → normal(E, E) | uniform(E, E) | bernoulli(E)
E ∈ deterministic Julia expressions
x ∈ Julia variable identiﬁers

Programs
Statements
Distributions

Figure 1: Grammar of MiniStan

2

(a) “Belief and skill matter” CGM.

(b) “Only skill matters” CGM.

quote

s ∼ normal(mu_s, sigma_s)
b ∼ normal(s, sigma_b)
logit_o = s * lambda_so + b * lambda_bo
o ∼ bernoulli(1/(1+exp(-logit_o)))

end

quote

s ∼ normal(mu_s, sigma_s)
b ∼ normal(s, sigma_b)
logit_o = s * lambda_so
o ∼ bernoulli(1/(1+exp(-logit_o)))

end

(c) “Belief and skill matter” model as source code.

(d) “Only skill matters” model as source code.

Figure 2: A conceptual example combining structure learning and parameter estimation.

µs ∼ N ormal(0, 1)
λso ∼ U nif orm(0, 1)

σs ∼ U nif orm(0, 1)
λbo ∼ U nif orm(0, 1)

σb ∼ U nif orm(0, 1)
edge ∼ Bernoulli(0.5)

In the Bayesian synthesis framework, a prior distribution over causal models is a stochastic procedure
generating programs in a domain speciﬁc language (Figure 5). The grammar for our simple domain
speciﬁc language, MiniStan, is presented in Figure 1.

3 Likelihoods for Experiments

To incorporate experimental evidence of various forms, the Bayesian synthesis approach requires
an intervention library which consists of a set of code-editing functions that modify causal model

quote

s ∼ normal(mu_s, sigma_s)
b = 5
logit_o = s * lambda_so + b * lambda_bo
o ∼ bernoulli(1/(1+exp(-logit_o)))

end

quote

s ∼ normal(mu_s, sigma_s)
b = 5
logit_o = s * lambda_so
o ∼ bernoulli(1/(1+exp(-logit_o)))

end

(a) “Belief and skill matter” with belief pill.

(b) “Only skill matters” with belief pill.

quote

s ∼ normal(mu_s, sigma_s)
b ∼ normal(s + 3, sigma_b)
logit_o = s * lambda_so + b * lambda_bo
o ∼ bernoulli(1/(1+exp(-logit_o)))

end

quote

s ∼ normal(mu_s, sigma_s)
b ∼ normal(s + 3, sigma_b)
logit_o = s * lambda_so
o ∼ bernoulli(1/(1+exp(-logit_o)))

end

(c) “Belief and skill matter” with encouragement de-
sign.

(d) “Only skill matters” with encouragement design.

quote

s ∼ normal(mu_s + 2, sigma_s)
b ∼ normal(s, sigma_b / 100)
logit_o = s * lambda_so + b * lambda_bo
o ∼ bernoulli(1/(1+exp(-logit_o)))

end

quote

s ∼ normal(mu_s + 2, sigma_s)
b ∼ normal(s, sigma_b / 100)
logit_o = s * lambda_so
o ∼ bernoulli(1/(1+exp(-logit_o)))

end

(e) “Belief and skill matter” with assessment.

(f) “Only skill matters” with assessment.

Figure 3: Various interventions expressed as modiﬁcations of MiniStan source code.

3

Figure 4: Graphical meta-model for the Bayesian synthesis approach to causal structure and parameter
learning. A set of global parameters θ determine the source code of the observational causal
program Pobs, which is modiﬁed via code-editing intervention functions to induce experimental
causal programs for the belief-pill (Pbp) encouragement design (Pe), and the assessment (Pa)
interventions. The code for each program is run through an interpreter, which generates (observational
or experimental) data. The likelihoods of the various kinds of data under the different interpreted
programs can be used to infer the posterior distribution over θ, and therefore over the observational
causal program Pobs.

logit_o_expr = quote s * $so_weight + b * $bo_weight end

else

if edge

mu_s = @trace(normal(0, 1), :mu_s)
sigma_s = @trace(uniform(0, 1), :sigma_s)
sigma_b = @trace(uniform(0, 1), :sigma_b)
lambda_so = @trace(uniform(0, 1), :so_weight)
lambda_bo = @trace(uniform(0, 1), :bo_weight)
edge = @trace(bernoulli(0.5), :edge)

1 @gen function generate_causal_model()
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22 end

s ∼ normal($mu_s, $sigma_s)
b ∼ normal(s, $sigma_b)
logit_o = $logit_o_expr
o ∼ bernoulli(1/(1+exp(-logit_o)))

end
return causal_model

logit_o_expr = quote s * $so_weight end

causal_model = quote

end

quote

s ∼ normal(0.237, 0.449)
b ∼ normal(s, 0.913)
logit_o = s * 0.137 + b * 0.852
o ∼ bernoulli(1/(1 + exp(-logit_o)))

end

quote

s ∼ normal(-0.592, 0.302)
b ∼ normal(s, 0.724)
logit_o = s * 0.503 + b * 0.491
o ∼ bernoulli(1/(1 + exp(-logit_o)))

end

quote

s ∼ normal(1.892, 0.108)
b ∼ normal(s, 0.301)
logit_o = s * 0.542
o ∼ bernoulli(1/(1 + exp(-logit_o)))

end

(a)

(b)

observational_model = @trace(generate_causal_model())
belief_pill_model = applyDoIntervention(observational_model, :b, 5)
encouragement_model = applyShiftIntervention(observational_model, :b, 3)
assessment_model = applyVarianceScalingIntervention(applyShiftIntervention(observational_model, :s, 2),

1 @gen function generate_data(NObs, NBeliefPill, NEncouragement, NAssessment)
2
3
4
5
6
7
8
9
10
11
12 end

observational_data = @trace(interpretMiniStan(observational_model, n_runs=NObs), :obs)
belief_pill_data = @trace(interpretMiniStan(belief_pill_model, n_runs=NBeliefPill), :belief_pill)
encouragement_data = @trace(interpretMiniStan(encouragement_model, n_runs=NEncouragement), :encouragement)
assessment_data = @trace(interpretMiniStan(assessment_model, n_runs=NAssessment, :assessment)

:b, 1/100)

(c)

Gen implementation of causal

Figure 5:
The
generate_causal_model Gen program (a) encodes a prior distribution over MiniStan models;
(b) shows three samples from this prior. The generate_data Gen program (c) encodes the likeli-
hood: it samples a possible causal model from the prior (line 2), modiﬁes it to obtain MiniStan code
representing experimental conditions (lines 3-6), then simulates observational and experimental data
by running the MiniStan programs (lines 8-11). The interpreter is itself a Gen probabilistic program.

inference via Bayesian synthesis.

4

walk(program) do expr
@match expr begin
:($x = $val)
&& if x == var end => :($var = $newValue)
:($x ∼ $dist) && if x == var end => :($var = $newValue)
_ => expr

1 function applyDoIntervention(program, var, newValue)
2
3
4
5
6
7
8
9 end

end

end

walk(program) do expr
@match expr begin

1 function applyShiftIntervention(program, var, shiftValue)
2
3
4
5
6
7
8
9
10 end

end

end

:($x ∼ normal($mean, $std)) && if x == var end => :($x ∼ normal($mean + $shiftValue, $std))
:($x ∼ uniform($a, $b)) && if x == var end => :($x ∼ uniform($a + $shiftValue, $b + $shiftValue))
:($x = $value) && if x == var end => :($x = $value + $shiftValue)
_ => expr

Figure 6: Julia implementation of the atomic (“do”) intervention and the shift intervention. Rather
than perform graph operations such as removing edges, an atomic intervention on a program walks the
program’s code and replaces any expression that assigns var with a new expression, implementing
the intervention (var = newValue). The shift intervention walks the program’s code and adds
shiftvalue to the mean argument for the normal distribution, the lower and upper bound arguments
for the uniform distribution, and the value of any deterministic assignment.

programs in the domain speciﬁc language. For the conceptual example, our intervention library
contains three interventions: (i) an atomic intervention, which applies the do-operator; (ii) a shift
intervention, which changes the mean of a distribution by a ﬁxed increment; and (iii) a variance-
scaling intervention, which modiﬁes the variance of a random variable assumed to be drawn from a
normal distribution. In principle, an intervention library could contain arbitrary rules for modifying
causal model source code, including changing the underlying distribution for a random variable or
adding variables (latent or observed) that didn’t exist in the observational model.

These interventions can be freely composed to represent a diverse set of experimental scenarios. We
demonstrate this compositionality in the “assessment” experiment, which is composed of a shift
intervention (a student’s skill may improve if she has to take a test) and a variance-scaling intervention
(a student’s belief in her ability has less noise after taking a test).

When interpreted, a causal program in MiniStan represents a likelihood function over observational
data. To compute the likelihood of experimental data, we simply modify the causal program using
the intervention library before subsequently interpretting the modiﬁed program.

4

Inference

We demonstrate the utility of this approach by performing approximate posterior inference over
synthesized causal model programs from our conceptual example. In this example we: (i) generate a
MiniStan program from the prior, (ii) generate a set of observational and experimental data from the
interpreted MiniStan program, and (iii) perform approximate posterior inference over synthesized
causal models using sequential Monte Carlo [4] with Metropolis Hastings rejuvination. We generated
ten individuals’ skill, belief, and outcome for each of the four observational and experimental settings
from a single causal model where µs = −0.013, σs = 0.776, σb = 0.646, λso = 0.734, λbo =
0.717, and edge = T rue.

Using only observational data, the posterior probability of the edge variable is low. This may
be because the data can be explained only by appealing to skill, and this simpler model could
lead to a higher marginal probability than one which introduces a new parameter (lambda_bo).
(This phenomenon is sometimes called “Bayesian Ockham’s Razor”.) However, as we incorporate
additional experimental evidence the posterior probability of the edge increases. Similarly, the
posterior distribution over λbo, the effect of belief on outcome, concentrates around the true value as
we leverage experimental evidence.

5

Figure 7: Posterior probability of the existence and strength of causal dependence between a student’s
belief and her subsequent outcome. The vertical gray line is the actual value for lambda_bo

.

5 Discussion

The Bayesian synthesis approach we have outlined in this paper provides several advantages over
alternative approaches to structure discovery and parameter estimation in causal modeling: (i) an
explicit characterization of uncertainty over model structures; (ii) a principled way to model diverse
interventions; and (iii) a formalization that can be re-used in diverse problems, with varying degrees
of prior knowledge, without requiring practitioners to design custom inferences for each use case.

Although this example uses parametric causal models, it is conceptually straightforward to use
Gaussian processes and/or Dirichlet process mixture models for the functional forms of causal
relationships [22]. It may thus be fruitful to develop Bayesian variants of existing non-parametric
techniques for causal inference [12, 15].

The results reported here were obtained using vanilla sequential Monte Carlo over the joint space
of model structure, parameters, and the latent variables in each observation or experiment.
In
order for this approach to scale to complex models, hierarchical priors over models, and large
datasets, we expect more powerful techniques will be necessary. However, the Gen platform provides
programmable inference constructs [3], including hybrids of Hamiltonian Monte Carlo [5] and
Metropolis-Adjusted Langevin [21] approaches with sequential Monte Carlo [4], that could potentially
address some of these scaling challenges.

6 Related Work

Probabilistic programs are often used to represent causal processes [8]. Some languages, such as
Omega [24], make this causal interpretation explicit, including a semantics for interventional and
counterfactual reasoning. It would be interesting to consider whether the framework we present here,
which considers interventions to be arbitrary code-editing procedures, could also be usefully applied
to counterfactual reasoning problems.

Incorporating experimental evidence for structure learning and parameter estimation can be thought
of as the inner loop of an optimal experimental design procedure. Probabilistic programs have been
used to automate this search over experiments [19], seeking to maximize the expected information
gain over some query given new evidence. In that work, experiments are modeled as arguments to a
probabilistic program. Our approach instead describes an experiment as a modiﬁcation of MiniStan
programs, enabling a clean abstraction between the speciﬁcation of causal models (or distributions
over causal models) and interventions that modify those models.

Improving methodology for combining observational and experimental evidence has far-reaching
implications for a wide variety of scientiﬁc disciplines, and has received signiﬁcant attention in
the graph-based causal inference literature. For example, extensions of the do-calculus have been
developed to incorporate experiments expressed as atomic interventions given a known causal
graphical model structure [14]. Recent extensions of existing graph-based structure discovery
algorithms have been made to incorporate atomic interventions [25] and imperfect interventions [26].
Our work proposes characterizing imperfect interventions as code-editors acting on probabilistic

6

programs; this representation enables us to perform posterior inference (with uncertainty estimates)
over both structure and model parameters.

Acknowledgements

We thank Javier Burroni, Dan Garant, Zenna Tavares, and Reilly Grant for thoughtful discussion.

References

[1] ALDRICH, J. Autonomy. Oxford Economic Papers 41, 1 (1989), 15–34.

[2] CARPENTER, B., GELMAN, A., HOFFMAN, M. D., LEE, D., GOODRICH, B., BETANCOURT,
M., BRUBAKER, M., GUO, J., LI, P., AND RIDDELL, A. Stan: A probabilistic programming
language. Journal of statistical software 76, 1 (2017).

[3] CUSUMANO-TOWNER, M. F., SAAD, F. A., LEW, A. K., AND MANSINGHKA, V. K. Gen:
A general-purpose probabilistic programming system with programmable inference. In Pro-
ceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and
Implementation (New York, NY, USA, 2019), PLDI 2019, ACM, pp. 221–236.

[4] DOUCET, A., GODSILL, S., AND ANDRIEU, C. On sequential monte carlo sampling methods

for bayesian ﬁltering. Statistics and computing 10, 3 (2000), 197–208.

[5] DUANE, S., KENNEDY, A. D., PENDLETON, B. J., AND ROWETH, D. Hybrid monte carlo.

Physics letters B 195, 2 (1987), 216–222.

[6] EBERHARDT, F., AND SCHEINES, R. Interventions and causal inference. Philosophy of Science

74, 5 (2007), 981–995.

[7] FRIEDMAN, N., AND KOLLER, D. Being bayesian about network structure. In Proceedings of
the Sixteenth conference on Uncertainty in artiﬁcial intelligence (2000), Morgan Kaufmann
Publishers Inc., pp. 201–210.

[8] GOODMAN, N., MANSINGHKA, V., ROY, D. M., BONAWITZ, K., AND TENENBAUM, J. B.

Church: a language for generative models. arXiv preprint arXiv:1206.3255 (2012).

[9] GRIFFITHS, T. L., AND TENENBAUM, J. B. Theory-based causal induction. Psychological

review 116, 4 (2009), 661.

[10] HAAVELMO, T. The probability approach in econometrics. Econometrica: Journal of the

Econometric Society (1944), iii–115.

[11] HECKERMAN, D., GEIGER, D., AND CHICKERING, D. M. Learning bayesian networks: The
combination of knowledge and statistical data. Machine learning 20, 3 (1995), 197–243.

[12] IMBENS, G. W. Nonparametric estimation of average treatment effects under exogeneity: A

review. Review of Economics and statistics 86, 1 (2004), 4–29.

[13] KORB, K. B., HOPE, L. R., NICHOLSON, A. E., AND AXNICK, K. Varieties of causal
intervention. In Paciﬁc Rim International Conference on Artiﬁcial Intelligence (2004), Springer,
pp. 322–331.

[14] LEE, S., CORREA, J. D., AND BAREINBOIM, E. General identiﬁability with arbitrary surrogate

experiments.

[15] LOUIZOS, C., SHALIT, U., MOOIJ, J. M., SONTAG, D., ZEMEL, R., AND WELLING, M.
Causal effect inference with deep latent-variable models. In Advances in Neural Information
Processing Systems (2017), pp. 6446–6456.

[16] MANSINGHKA, V., KEMP, C., TENENBAUM, J., AND GRIFFITHS, T. Structured priors for
structure learning. In Proceedings of the Twenty-Second Conference on Uncertainty in Artiﬁcial
Intelligence (UAI 2006) (2006).

7

[17] MCCANDLESS, L. C., GUSTAFSON, P., AND AUSTIN, P. C. Bayesian propensity score

analysis for observational data. Statistics in medicine 28, 1 (2009), 94–112.

[18] MURPHY, K. P. Machine learning: a probabilistic perspective. MIT Press, 2012.

[19] OUYANG, L., TESSLER, M. H., LY, D., AND GOODMAN, N. Practical optimal experiment

design with probabilistic programs. arXiv preprint arXiv:1608.05046 (2016).

[20] PEARL, J. Causality: models, reasoning and inference, vol. 29. Springer, 2000.

[21] ROBERTS, G. O., TWEEDIE, R. L., ET AL. Exponential convergence of langevin distributions

and their discrete approximations. Bernoulli 2, 4 (1996), 341–363.

[22] SAAD, F. A., CUSUMANO-TOWNER, M. F., SCHAECHTLE, U., RINARD, M. C., AND
MANSINGHKA, V. K. Bayesian synthesis of probabilistic programs for automatic data modeling.
Proceedings of the ACM on Programming Languages 3, POPL (2019), 37.

[23] SHERMAN, E., AND SHPITSER, I.

Intervening on network ties.

In Proceedings of the

International Conference on Uncertainty in Artiﬁcial Intelligence (2019).

[24] TAVARES, Z., ZHANG, X., KOPPEL, J., AND LEZAMA, A. S. Soft constraints for inference

with declarative knowledge.

[25] WANG, Y., SOLUS, L., YANG, K., AND UHLER, C. Permutation-based causal inference
algorithms with interventions. In Advances in Neural Information Processing Systems (2017),
pp. 5822–5831.

[26] YANG, K. D., KATCOFF, A., AND UHLER, C. Characterizing and learning equivalence classes

of causal dags under interventions. arXiv preprint arXiv:1802.06310 (2018).

8

