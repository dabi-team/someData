0
2
0
2

l
u
J

1
2

]
S
D
.
s
c
[

2
v
5
1
5
7
0
.
7
0
0
2
:
v
i
X
r
a

Improved algorithms for online load balancing⋆

{

Yaxiong Liu1,3, Kohei Hatano2,3, and Eiji Takimoto1
@inf.kyushu-u.ac.jp123
yaxiong.liu,hatano,eiji
}
1 Department of Informatics, Kyushu University, Japan
2 Faculty of Arts and Science, Kyushu University, Japan
3 RIKEN AIP, Japan

Abstract. We consider an online load balancing problem and its ex-
tensions in the framework of repeated games. On each round, the player
chooses a distribution (task allocation) over K servers, and then the
environment reveals the load of each server, which determines the com-
putation time of each server for processing the task assigned. After all
rounds, the cost of the player is measured by some norm of the cumu-
lative computation-time vector. The cost is the makespan if the norm is
L∞-norm. The goal is to minimize the regret, i.e., minimizing the player’s
cost relative to the cost of the best ﬁxed distribution in hindsight. We
propose algorithms for general norms and prove their regret bounds.
In particular, for L∞-norm, our regret bound matches the best known
bound and the proposed algorithm runs in polynomial time per trial in-
volving linear programming and second order programming, whereas no
polynomial time algorithm was previously known to achieve the bound.

Keywords: online learning · blackwell approachability · online load bal-
ancing · makespan · second order cone programming.

1

Introduction

We consider an online load balancing problem deﬁned as follows. There are K
parallel servers and the protocol is deﬁned as a game between the player and the
environment. On each round t = 1, . . . , T , (i) the player selects a distribution
αt over K servers, which can be viewed as an allocation of data, (ii) then the
environment assigns a loaded condition lt,i for each server i and the loss of server
i is given as αt,ilt,i. The goal of the player is to minimize the makespan of the
T
t=1 αt,ilt,i,
cumulative loss vector of all servers after T rounds, i.e., maxi=1,...,K
compared relatively to the makespan obtained by the optimal static allocation
α∗ in hindsight. More precisely, the goal is to minimize the regret, the diﬀerence
between the player’s makespan and the static optimal makespan. The makespan
cost can be viewed as L∞-norm of the vector of cumulative loss of each server
(we will give a formal deﬁnition of the problem in the next section).

P

In traditional literature the measurement of an algorithm is always competi-
tive ratio(e.g.,[2] [10]). In our paper we utilize another well-known measurement

⋆ Supported by organization x.

 
 
 
 
 
 
2

Yaxiong Liu, Kohei Hatano, Eiji Takimoto

as “Regret” deﬁned in later section. Even-Dar et al.[5] gave an algorithm based
on the regret minimum framework by involving an extra concept, the Blackwell
approachability [3] with respect to L2-norm, to a target set, which is deﬁned
in the following section. This algorithm achieves the regret bound as O(√KT ).
Simultaneously another algorithm, DIFF, achieves the regret upper bound as
O((ln K)√T ). Rahklin et al. [11] gave a theoretical result for the online load
balancing problem, that the upper bound to regret can achieve O(
(ln K)T ),
rather than O((ln K)√T ). However there is no eﬃcient algorithm given in this
paper to obtain the regret.

p

In following years, there were some new explorations about the equivalence
between the Blackwell approachability and online linear optimization(OLO) [1],
in addition and online convex optimization(OCO) by involving a support func-
tion [13].

These work [1] [13] implied that the Blackwell approachability can be given
by general norm by reducing Blackwell approaching game to an OCO problem.
Moreover due to this result we give an eﬃcient algorithm to online load balancing
problem, achieving the best known regret.

More speciﬁcally speaking, we propose algorithms for online load balancing
for arbitrary norms under a natural assumption. And our technical contributions
are the following:

– 1. We propose a new reduction technique from online load balancing to a
Blackwell approaching game. This reduction enables us to use more general
norms than L2-norm or L∞-norm used in the previous work. Then, by using
the reduction technique of Shimkin [13] from Blackwell games to online linear
optimization, we reduce online load balancing to online linear optimization.
– 2. Especially we give an eﬃcient algorithm for online load balancing w.r.t. L∞-
norm, achieving the best known O(√T ln K) regret. The algorithm involves
linear programming and the second order cone programming and runs in
polynomial time per trial. This is the ﬁrst polynomial time algorithm achiev-
ing O(√T ln K) regret.

This paper is organized as follows. In section 2 we introduce the basic deﬁni-
tions in this paper like online load balancing problem, Blackwell approachability
game and online convex optimization. Next in section 3 we give a meta algorithm
for online load balancing with respect to any norm under a natural assumption.
Then in section 4 we give some details in implementation of the algorithm for
L∞-norm.

2 Preliminaries

First we give some notations. We use
speciﬁcally, for a vector x = (x1, x2, . . . , xd)

k·k

to denote a norm of a vector. More
1, the

Rd and a real number p

Lp-norm of x is denoted by
of x is

k∞ = maxi |

xi|

x

k

∈
p
xi|
. Moreover, for a norm

d
i=1 |

kp =

x
k

(cid:16)P

1/p

,
(cid:17)
k·k

≥

. In particular, the L∞-norm
k∗ denotes the dual norm

x
k

Improved algorithms for online load balancing

3

x
k
x
k

of
if
monotone for any p

, where
k
k ≤ k

x
k∗ = sup
k
whenever
|
1.

y

k

x, z
{h
xi| ≤ |

i | k
yi|

1

z
for every 1

k ≤

}

. A norm

i

≤

≤

≥

over Rd is monotone
k·k
d. Note that Lp-norm is

2.1 Online load balancing

Firstly we begin with a standard (oﬄine) load balancing problem. Suppose that
we have K servers to do a simple task with a large amount of data. The task
can be easily parallelized in such a way that we can break down the data into
K pieces and assign them to the servers, and then each server processes the
subtask in time proportional to the size of data assigned. An example is to
ﬁnd blacklisted IP addresses in an access log data. Each server is associated
with loaded condition, expressed in terms of “the computation time per unit
data”. The goal is to ﬁnd a data assignment to the servers so as to equalize
the computation time for all servers. In other words, we want to minimize the
makespan, deﬁned as the maximum of the computation time over all servers.

∈

RK

Formally, the problem is described as follows: The input is a K-dimensional
vector l = (l1, l2, . . . , lK)
+ , where each li represents the loaded condi-
tion of the i-th server. The output is a K-dimensional probability vector α =
(α1, α2, . . . , αK)
, where each αi repre-
{
∈
sents the fraction of data assigned to the i-th server. The goal is to minimize
l = (α1l1, α2l2, . . . , αKlK). Note that it is
k∞, where α
the makespan
clear that the optimal solution is given by αi = l−1
j=1 l−1
, which equalizes
i /
the computation time of every server as

K
i=1 αi = 1

∆(K) =

[0, 1]K

α
k

P

⊙

⊙

α

∈

}

K

l

|

j

∞(l) def= min
C∗

α∈∆(K) k

α

l

k∞ =

⊙

P
1
K
j=1 1/lj

.

Note also that the objective is generalized to the Lp-norm for any p in the
literature.

P

In this paper, we consider a more general objective

for an arbitrary
norm that satisﬁes certain assumptions stated below. In the general case, the
optimal value is denoted by

⊙

α
k

k

l

C∗(l) def= min

α∈∆(K) k

α

.

l

k

⊙

Assumption 1 Throughout the paper, we put the following assumptions on the
norm.

1. The norm
k·k
2. The function C∗ is concave.

is monotone, and

Note that the ﬁrst assumption is natural for load balancing and the both as-
sumptions are satisﬁed by Lp-norm for p > 1.

Now we proceed to the online load balancing problem with respect to a norm
that satisﬁes Assumption 1. The problem is described as a repeated game

k·k

4

Yaxiong Liu, Kohei Hatano, Eiji Takimoto

between the learner and the environment who may behave adversarially. In each
round t = 1, 2, . . . , T , the learner chooses an assignment vector αt ∈
∆(K), and
[0, 1]K, which
then receives from the environment a loaded condition vector lt ∈
may vary from round to round. After the ﬁnal round is over, the performance
of the learner is naturally measured by
. We want to make the
learner perform nearly as well as the performance of the best ﬁxed assignment in
T
hindsight (oﬄine optimal solution), which is given by C∗(
t=1 lt). To be more
speciﬁc, the goal is to minimize the following regret :

t=1 αt ⊙

(cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:13)
(cid:13)

P

lt

T

P

Regret(T ) =

αt ⊙

lt

T

t=1
X

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

C∗

−

T

t=1
X

lt

.

!

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

2.2 Repeated game with vector payoﬀs and approachability

We brieﬂy review the notion of Blackwell’s approachability, which is deﬁned
for a repeated game with vector payoﬀs. The game is speciﬁed by a tuple
Rd is
(A, B, r, S, dist), where A and B are convex and compact sets, r : A
Rd is a convex and closed set called the tar-
a vector-valued payoﬀ function, S
R+ is a metric. The protocol proceeds in trials: In
get set, and dist : Rd
×
each round t = 1, 2, . . . , T , the learner chooses a vector at ∈
A, the environment
Rd,
B, and then the learner obtains a vector payoﬀ rt ∈
chooses a vector bt ∈
given by rt = r(at, bt). The goal of the learner is to make the average payoﬀ
vector arbitrarily close to the target set S.

Rd

→

→

×

⊆

B

Deﬁnition 1 (Approachability). For a game (A, B, r, S, dist), the target set
S is approachable with convergence rate γ(T ) if there exists an algorithm for the
learner such that the average payoﬀ ¯rT = (1/T )

T
t=1 rt satisﬁes

dist(¯rT , S) def= min
s∈S

P
dist(¯rT , s)

γ(T )

≤

against any environment. In particular, we simply say that S is approachable if
it is approachable with convergence rate o(T ).

Blackwell characterizes the approachability in terms of the support function

as stated in the proposition below.

Deﬁnition 2. For a set S
deﬁned as

⊆

Rd, the support function hS : Rd

R

→

is

∪ {∞}

hS(w) = sup
s∈Sh

s, w

.
i

It is clear from deﬁnition that hS is convex whenever S is convex.

Deﬁnition 3 (Blackwell [3]). A game (A, B, r, S, dist) satisﬁes Blackwell Con-
dition, if and only if

Rd

w

∀

∈

min
a∈A

(cid:18)

min
b∈Bh

w, r(a, b)

i ≤

hS(w)

.

(cid:19)

(1)

 
Improved algorithms for online load balancing

5

Remark 1. In [3], Blackwell characterized the approachability of a target set for
L2-norm metric in terms of the Blackwell condition.

In what follows, we only consider a norm metric, i.e, dist(r, s) =

over Rd. The following proposition is useful.

some norm

k·k

r

k

s
k

−

for

Proposition 1. For any w
hS(w) at w.

Rd, s∗ = arg maxs∈Sh

s, w

i

∈

is a sub-gradient of

Proof. For any w, u
s∗, u
Since
h

Rd, let s∗ = arg maxs∈Sh
∈
su, u
, we have
i

s, w

and su = arg maxs∈Sh

s, u

.
i

i

i ≤ h
hS(w)

−

s, w

hS(u) = sup
s∈Sh
s∗, w

≤ h

−

s, u

sup
s∈Sh

=

s∗, w
h

i

su, u

i − h

i

i −
u

,
i

which implies the proposition.

2.3 Online convex optimization

⊓⊔

In this subsection we brieﬂy review online convex optimization with some known
results. See, e.g., [12,6] for more details.

An online convex optimization (OCO) problem is speciﬁed by (W, F ), where

}

Rd is a compact convex set called the decision set and F

W
⊆
→
R
is a set of convex functions over W called the loss function set. The OCO
problem (W, F ) is described by the following protocol between the learner and
the adversarial environment. For each round t = 1, 2, . . . , T , the learner chooses
a decision vector wt ∈
W and then receives from the environment a loss function
F . In this round, the learner incurs the loss given by ft(wt). The goal is to
ft ∈
make the cumulative loss of the learner nearly as small as the cumulative loss of
the best ﬁxed decision. To be more speciﬁc, The goal is to minimize the following
regret:

f : W

⊆ {

Regret(W,F )(T ) =

T

t=1
X

ft(wt)

min
w∈W

−

ft(w).

T

t=1
X

Here we add the subscript (W, F ) to distinguish from the regret for online load
balancing.

Any OCO problem can be reduced to an online linear optimization (OLO)
problem, which is an OCO problem with linear loss functions. More precisely,
Rd is the set of cost vectors
an OLO problem is speciﬁed by (W, G), where G
such that the loss function at round t is
G. For
the OLO problem (W, G), the regret of the learner is thus given by

for some cost vector gt ∈

gt,
h

⊆

·i

Regret(W,G)(T ) =

T

t=1
X

gt, wti −
h

min
w∈W

T

t=1
X

gt, w
h

.
i

6

Yaxiong Liu, Kohei Hatano, Eiji Takimoto

The reduction from OCO to OLO is simple. Run any algorithm for OLO (W, G)
with gt ∈
Regret(W,G)(T ), pro-
vided that G is large enough, i.e., G

∂ft(wt), and then it achieves Regret(W,F )(T )

≤
f ∈F,w∈W ∂f (w).

A standard FTRL (follow-the-regularized-leader) strategy for the OLO prob-

⊇

lem (W, G) is to choose wt as

S

wt = arg min

w∈W  

t−1

s=1
X

gs, w
h

i

+ ηtR(w)

!

,

(2)

R is a strongly convex function called the regularizer and
R+ is a parameter. Using the strategy (2) the following regret bound is

→

where R : W
ηt ∈
known.

Proposition 2 ([12]). Suppose that the regularizer R : W
convex w.r.t. some norm
R(u)
w
z, u
R(w) +
−
h
the regret of the strategy (2) satisﬁes

R is σ-strongly
→
∂R(w),
W , for any z
2. Then, for the OLO problem (W, G),

, i.e., for any w, u

k · k
+ σ
i

2 k

w

≥

−

u

∈

∈

k

Regret(W,G)(T ) = O(DRLG

T /σ),

where DR =

maxw∈W R(w), LG = maxg∈G k

g

p
∗ and ηt = (LG/DR)
k

T /σ.

p

Note however that the strategy does not consider the computational feasibil-
ity at all. For eﬃcient reduction, we need an eﬃcient algorithm that computes
a sub-gradient g
∂f (w) when given (a representation of) f
W ,
∈
and an eﬃcient algorithm for solving the convex optimization problem (2).
For a particular OLO problem (W, G) with L1 ball decision set W =

Rd
solution of (2) with an entropic regularizer and achieves the following regret.

∈
, an algorithm called EG± [7] ﬁnds in linear time the optimal

F and w

k1 ≤

| k

w

w

∈

∈

}

{

1

p

Theorem 2 ([8]). For the OLO problem (W, G) with W =
1

, EG± achieves

and G =

Rd

M

g

g

}

{

∈

| k

k∞ ≤

}

Rd

w

{

∈

w

| k

k1 ≤

Regret(W,G)(T )

≤

M

2T ln(2d).

p

3 Main result

In this section, we propose a meta-algorithm for online load balancing, which is
obtained by combining a reduction to two independent OLO problems and an
OLO algorithm (as an oracle) for the reduced problems. Note that the reduced
OLO problems depend on the choice of norm for online load balancing, and the
OLO problems are further reduced to some optimization problems deﬁned in
terms of the norm. For eﬃcient implementation, we assume that the optimization
problems are eﬃciently solved.

Now we consider the online load balancing problem on K servers with respect
deﬁned over RK that satisﬁes Assumption 1. The reduction we

to a norm

k·k

Improved algorithms for online load balancing

7

show consists of three reductions, the ﬁrst reduction is to a repeated game with
vector payoﬀs, the second one is to an OCO problem, and the last one is to
two OLO problems. In the subsequent subsections, we give these reductions,
respectively.

3.1 Reduction to a vector payoﬀ game

We will show that the online load balancing problem can be reduced to the
following repeated game with vector payoﬀs, denoted by P = (A, B, r, S, dist),
where

RK

– A = ∆(K), B = [0, 1]K,
– r : A
B
→
×
(x, y)
– S =
{
– dist is the metric over RK
is the norm over RK

×
[0, 1]K

×

∈

×

RK is the payoﬀ function deﬁned as r(α, l) = (α

[0, 1]K

x

C∗(y)
}
RK deﬁned as dist(r, s) =

, and

| k
k ≤
RK deﬁned as

×

r

k

s
k

−

⊙
+, where

l, l),

+

k·k

(x, y)
k

+ =

+

x

k

.

y
k

k

k
Here we use the convention that R2K = RK
convex since
it is easy to verify that

k·k

+ is a norm whenever

×

k

RK. Note that the target set S is
is convex and C∗ is concave by our assumption. Note also that

is a norm, and its dual is

k·k

k·k

+
(x, y)
∗ = max
k

k

x

{k

k∗ ,

y
k

k∗}

.

(3)

The reduction is similar to that in [5], but they consider a ﬁxed norm
to deﬁne the metric, no matter what norm is used for online load balancing.

k·k2

Proposition 3. Assume that we have an algorithm for the repeated game P
that achieves convergence rate γ(T ). Then, the algorithm, when directly applied
to the online load balancing problem, achieves

Regret(T )

T γ(T ).

≤

denote an algorithm for the repeated game P with convergence
against the environment of online load
[0, 1]K

∆(K) output from

A

A

Proof. Let
rate γ(T ). Assume that when running
balancing, we observe, in each round t, αt ∈
output from the environment.
(x, y)
k

Let (x, y) = arg min(x,y)∈S k

¯rT −

A
+, where ¯rT = (1/T )

and lt ∈

is the average payoﬀ. Note that by the assumption of
γ(T ). For simplicity, let

, we have

A

¯rT −
P
k

T
t=1 r(αt, lt)
+
(x, y)
k

≤

LA

T = (1/T )

T

t=1
X

αt ⊙

lt

and

LT = (1/T )

lt.

T

t=1
X

8

Yaxiong Liu, Kohei Hatano, Eiji Takimoto

Then, we have

(1/T )Regret(T ) =

LA
T

C∗(LT ) =

C∗(y)

+

LA
T

y

k −

⊙

y

⊙

k − k

(cid:13)
α
(cid:13)

(cid:2)(cid:13)
(cid:3)
min
(cid:13)
α∈∆(K) k
α
LT k

⊙

(y

LT )
k

−

⊙

(cid:3)

x

k

k −
α

−
x

(cid:13)
LA
(cid:13)

(cid:13)
(cid:13)
T −

(cid:13)
LA
(cid:13)

T −

(cid:13)
LA
(cid:13)

T −

x

x

(cid:13)
(cid:13)

(cid:13)
(cid:13)

x

+

(cid:13)
(cid:13)

(cid:13)
LA
(cid:13)
(LA
(cid:13)
(cid:13)
¯rT −
(cid:13)
k
(cid:13)
γ(T ),

T −
T , LT )
(cid:13)
(cid:13)
−
(x, y)
k

+

(cid:2)
min
α∈∆(K) k
α
k

(cid:20)
+ max

α∈∆(K)

α

+ max

(cid:2)
α∈∆(K) k
LT k

y

+

k
−
(x, y)
+

(cid:13)
(cid:13)

≤

≤

≤

≤
=

=

≤

+

C∗(y)

C∗(LT )

−

(cid:2)

(cid:3)

− k

⊙

x

k
(cid:3)
LT k

(cid:21)

where the ﬁrst inequality is from the deﬁnition of S and the triangle inequality,
the third inequality is from the triangle inequality, and the fourth inequality is
from the monotonicity of the norm.

⊓⊔

3.2 Reduction to an OCO problem

Next we give the second sub-reduction from the repeated game P to an OCO
problem. We just follow a general reduction technique of Shimkin [13] as given
in the next theorem.

k

r

−

s
k

for some norm

Theorem 3 ([13]). Let (A, B, r, S, dist) be a repeated game with vector payoﬀs,
over Rd. Assume that we have an
where dist(r, s) =
algorithm
A
ﬁnds a
A such that
we have an algorithm

that witnesses the Blackwell condition, i.e., when given w

{
|
∈
. Then, we
k
can construct an algorithm for the repeated game such that its convergence rate
γ(T ) satisﬁes

for the OCO problem (W, F ), where W =
B

w, r(a, b)
h
B
f : w

A
B. Assume further that

hS(w) for any b

r(a, b), w

+ hS(w)

and F =

k∗ ≤

7→ h−

Rd,

A, b

i ≤

k·k

Rd

w

w

∈

∈

∈

∈

∈

a

}

{

1

}

i

|

γ(T )

Regret(W,F )(T )
T

.

≤

Moreover, the algorithm runs in polynomial time (per round) if
polynomial time algorithms.

A

and

are

B

For completeness, we give the reduction algorithm in Appendix.

The rest to show in this subsection is to ensure the existence of algorithm
A
required for the reduction as stated in the theorem above. In other words, we
show that the Blackwell condition holds for our game P = (∆(K), [0, 1]K, r, S, dist),
RK, S =
where r(α, l) = (α
C∗(y)
}

, l, l)
, and dist(r, s) =

RK
s
k

[0, 1]K

[0, 1]K

∈
r
k

(x, y)

k ≤

×
+.

| k

−

⊙

×

∈

x

{

Improved algorithms for online load balancing

Lemma 1. The Blackwell condition holds for game P . That is, for any w
RK

RK, we have

×

9

∈

min
α∈∆(K)

max
l∈[0,1]Kh

w, r(α, l)

hS(w).

i ≤

Before we give the proof of Lemma, we need to involve a theorem as follow.

Theorem 4 ([4]). Let f (x, y) denote a bounded real-valued function deﬁned on
X
, y)
Y , where X and Y are convex sets and X is compact. Suppose that f (
·
is convex and continuous for each ﬁxed y
) is concave for each
ﬁxed x

Y and f (x,

X. Then

×

∈

·

∈

inf
x∈X

sup
y∈Y

f (x, y) = sup
y∈Y

inf
x∈X

f (x, y).

RK. By the deﬁnition of
Proof (Proof of Lemma 1). Let w = (w1, w2)
r, the inner product in the Blackwell condition can be rewritten as a bilinear
function

RK

×

∈

f (α, l) =

w, r(α, l)
i
h

=

w1,iαili +

w2,ili

K

i=1
X

K

i=1
X

[0, 1]K. Therefore, f meets the condition of Theorem 4. and we

over ∆(K)
have

×

min
α∈∆(K)

max
l∈[0,1]K

f (α, l) = max
l∈[0,1]K

min
α∈∆(K)

f (α, l).

Let l∗ = arg maxl∈[0,1]K minα∈∆(K) f (α, l) and α∗ = arg minα∈∆(K) k
α
Note that by the deﬁnition of S, we have (α∗
S. Hence we get

l∗, l∗)

l∗

.

k

⊙

min
α∈∆(K)

max
l∈[0,1]K

∈

min
α∈∆(K)

f (α, l)

l∗), l∗)
i

⊙

⊙
f (α, l) = max
l∈[0,1]K
= f (α∗, l∗)
w, ((α∗
=
h
w, s
sup
i
s∈Sh
≤
= hS(w),

which completes the lemma.

This lemma ensures the existence of algorithm

⊓⊔
. On the other hand, for an
we need to consider the OCO problem (W, F ), where the decision

A

algorithm
set is

B

W =

and the loss function set is

w

{

∈

RK

RK

w

| k

+
∗ ≤

k

1

,

}

×

F =

f : w

{

7→ h−

r(α, l), w

i

+ hS(w)

α

|

∈

∆(K), l

[0, 1]K

.

}

∈

Since W is a compact and convex set and F consists of convex functions, we could
apply a number of existing OCO algorithms to obtain Regret(W,F )(T ) = O(√T ).
In the next subsection, we show that the problem can be simpliﬁed to two OLO
problems.

(4)

(5)

10

Yaxiong Liu, Kohei Hatano, Eiji Takimoto

3.3 Reduction to two OLO problems

Consider the OCO problem (W, F ) given by (4) and (5). Following the standard
reduction technique from OCO to OLO stated in Section 2.3, we obtain an OLO
RK is any set of cost vectors
problem (W, G) to cope with, where G
that satisﬁes

RK

⊆

×

(cid:12)
(cid:12)
(cid:12)

G

⊇

[f ∈F,w∈W

∂f (w) =

−

n

r(α, l) + s

α

∆(K), l

∈

∈

[0, 1]K, s

∈

w∈W ∂hS(w)

.

S

o

{

∈

×

w

w

| k

k∗ ≤

B∗(K), [

∆(K) and l

Thus, (B∗(K)

∈
1, 1]K

(6)
B∗(K) where
is the K-dimensional unit ball with respect to
∂hS(w) is in the target set S,

By (3), the decision set W can be rewritten as W = B∗(K)
RK
1
B∗(K) =
}
∈
k·k∗. By Proposition 1, any s
the dual norm
∈
[0, 1]K. Moreover, r(α, l) = (α
which is a subset of [0, 1]K
×
[0, 1]K. Therefore, G = [
[0, 1]K for any α
satisﬁes (6).

l, l)
⊙
1, 1]K
−
1, 1]K) is a suitable OLO problem re-
[
−
duced from the OCO problem (W, F ). Furthermore, we can break the OLO
1, 1]K) in the straight-
problem into two independent OLO problems (B∗(K), [
1, 1]K),
forward way: Make two copies of an OLO algorithm
for (B∗(K), [
C1 and
denoted by
C2, and use them for predicting the ﬁrst half and second
half decision vectors, respectively. More precisely, for each trial t, (1) receive
B∗(K) and wt,2 ∈
predictions wt,1 ∈
C2, respectively, (2)
C1 and
output their concatenation wt = (wt,1, wt,2)
W , (3) receive a cost vector
[0, 1]K from the environment, (4) feed gt,1 and gt,2
[0, 1]K
gt = (gt,1, gt,2)
C1 and
to
It is clear that the procedure above ensures the following lemma.

∈
C2, respectively, to make them proceed.

[0, 1]K
[

B∗(K) from

×
1, 1]K

∈
×

−
C

−

−

×

×

−

×

∈

Lemma 2. The OCO problem (W, F ) deﬁned as (4) and (5) can be reduced to
the OLO problem (B∗(K), [0, 1]K), and

Regret(W,F )(T )

≤

2Regret(B∗(K),[0,1]K)(T ).

3.4 Putting all the pieces together

Combining all reductions stated in the previous subsections, we get an all-in-one
algorithm as described in Algorithm 1.

It is clear that combining Proposition 3, Theorem 3 and Lemma 2, we get

the following regret bound of Algorithm 1.

Theorem 5. Algorithm 1 achieves

Regret(T )

≤

2Regret(B∗(K),[−1,1]K)(T ),

where the regret in the right hand side is the regret of algorithm
well). Moreover, if
in polynomial time (per round).

C2 as
C1 runs in polynomial time, then Algorithm 1 runs

C1 (and

,
A

and

B

Improved algorithms for online load balancing

11

Algorithm 1 An OLO-based online load balancing algorithm
Require: An algorithm A that, when given w, ﬁnds α = arg min

α∈∆(K)

max
l∈[0,1]K

hw, (α ⊙

l, l)i.

Require: An algorithm B that, when given w, ﬁnds s ∈ ∂hS(w).
Require: Two copies of an algorithm, C1 and C2,

for

the OLO problem

(B∗(K), [−1, 1]K ).
for t = 1, 2, . . . , T do

1. Obtain wt,1 and wt,2 from C1 and C2, respectively, and let wt = (wt,1, wt,2).
2. Run A(wt) and obtain αt ∈ ∆(K).
3. Output αt and observe lt ∈ [0, 1]K .
4. Run B(wt) and obtain st = (st,1, st,2).
5. Let gt,1 = −αt ⊙ lt + st,1 and gt,2 = −lt + st,2.
6. Feed gt,1 and gt,2 to C1 and C2, respectively.

end for

When applying the FTRL strategy as in (2) to the OLO problem (B∗(K), [
with a strongly convex regularizer R, Proposition 2 implies the following regret
bound.

−

1, 1]K)

R that is
Corollary 1. Assume that there exists a regularizer R : B∗(K)
σ-strongly convex w.r.t. L1-norm. Then, there exists an algorithm for the online
load balancing problem that achieves

→

Regret(T ) = O(DR

T /σ),

where DR =

maxw∈B∗(K) R(w).

p

p

In particular, for the OLO problem (B1(K), [

1, 1]K), algorithm EG± achieves
√2T ln 4K regret bound as shown in Theorem 2. Thus we have O(√T ln K)
regret bound for online load balancing with respect to L∞-norm (i.e., w.r.t.
makespan), which improves the bound of [5] by a factor of √ln K. Moreover, for
L∞-norm, it turns out that we have polynomial time algorithms for
,
B
which we will give in the next section. We thus obtain the following corollary.

and

A

−

Corollary 2. There exists a polynomial time (per round) algorithm for the on-
line load balancing problem with respect to L∞-norm that achieves

Regret(T )

≤

2√2T ln 4K.

4 Algorithmic details for L∞-norm

In this section we give details of Algorithm 1 for the makespan problem, i.e., for
L∞-norm.

12

Yaxiong Liu, Kohei Hatano, Eiji Takimoto

4.1 Computing αt

First, we give details of implementation of
in Algorithm 1. Speciﬁcally, on the
round t, we need to choose αt, which is the optimal solution of the problem in
Lemma 1. That is,

A

min
α∈∆(K)

max
l∈[0,1]Kh

w1, (α

l)
i

+

w2, l
h

,
i

⊙

(7)

where we set that w = (w1, w2) and w1 and w2 are K-dimensional vectors,
respectively. We see that the optimization of this objective function is deﬁned
0, otherwise we let li = 1. Hence we can convert
αi + w2,i ≤
by li = 0 if w1,i ·
our problem to choose α as

min
α∈∆(K)

max
l∈[0,1]Kh

w1, (α

l)
i

+

w2, l
h

i

⊙

= min

α∈∆(K)

which is equivalent to

K

i=1
X

max

0, αiw1,i + w2,i}
{

,

min
α∈∆(K),β≥0

K

βi

i=1
X

s.t. βi ≥

w1,iαi + w2,i ∀
The above problem is a linear program with O(K) variables and O(K) linear
constraints. Thus, computing αt in the problem (7) can be solved in polynomial
time.

i = 1, . . . , K.

4.2 Computing subgradients gt for the ∞-norm

The second component of Algorithm 1 is the algorithm
gradients st ∈
Recall that S =
condition that

[0, 1]K
[0, 1]K
∈
≤
C∗
∞(y) can be represented as

∂hS(wt). By Proposition 1, we have st = arg maxs∈Sh
x
(x, y)
{
| k
x
∞
k
≤
xi ≤

, which computes sub-
s, wti
.
. In particular, the

min
α∈∆(K) k

∞(y)
}

xi ≤

max
i

⇐⇒

C∗

×

⊙

α

B

i.

y

∞

∞

∀

k

k

k

,

1
K
j=1

1
yj

Therefore, the computation of the subgradient st is formulated as

P

max
x,y∈[0,1]Kh

w1, x

+

w2, y
h

i

i

s.t. xi ≤

1

j

,

1
yj

i = 1, . . . , K.

∀

(8)

Now we show that there exists an equivalent second order cone program-

P

ming(SOCP) formulation (e.g., [9]) for this problem.

First we give the deﬁnition of the second order cone programming, and then
we give a proposition, which states that our optimization problem is equivalent
to the second order cone programming.

Improved algorithms for online load balancing

13

Deﬁnition 4. The standard form for the second order conic programming(SOCP)
model is as follows:

c, x

min
x h

i

s.t. Ax = b,

Cix + dik2 ≤

k

e⊤
i x + fi

for i = 1,

where the problem parameters are c
Rp×n, and b
fi ∈

Rp. x

R, A

∈

∈

∈

Rn, Ci ∈

Rni×n, di ∈

Rn is the optimization variable.

∈

Rn,

∈

Then we obtain the following proposition.

, m,

· · ·
Rni, e

0 and yi ≥

≥

0 is equivalent to x2

yizi,

≤

k
i=1

x
yi ≤

1. By setting

2

x
x, x
yi ≤
K
i=1 zi = x.

K
i=1

Proposition 4.
where yi, zi ≥
Proof. On the direction “
k
i=1

0 and
P

From

2

x
yi ≤

”
P
x we obtain that

⇒

P

we can have that x2

On the other direction “

≤

that

P

zi = x

·

1
yi

1
yi

i

,

yizi, and

P
k
i=1 zi = x.

” Due to x2

P

≤

⇐

k

i=1
X

x2
yi ≤

k

i=1
X

zi = x.

yizi, we have x

zi. So we have

2

yi ≤

Again in our case we need ﬁnd to the optimal vector s

⊓⊔
S, which satisﬁes
wt, s
. Then we can reduce our problem in following
i

∈

that st = arg maxs∈Sh
theorem.

Theorem 6. The optimization problem (8) can be solved by the second order
cone programming.

Proof. To prove this theorem we only need to represent the original problem (8)
as a standard form of the SOCP problem. Note that we only consider the case
= 0 for all i = 1, . . . , K. The case where yi = 0 for some i is trivial. To
that yi 6
see this, by deﬁnition of S, we know that for all i, xi = 0. Then, the resulting
problem is a linear program, which is a special case of the SOCP. Now we assume
that yi 6
, we multiply xi on both sides and
rearrange the inequality:

= 0 for i = 1, . . . , K. For xi ≤

1
Pj

1
yj

By Proposition 4, this is equivalent with

x2
i
yj ≤

xi.

K

j=1
X

yjzi,j ≥

x2
i ,

yj, zi,j ≥

0,

zi,j = xi.

K

j=1
X

14

Yaxiong Liu, Kohei Hatano, Eiji Takimoto

By [9], we may rewrite it as follows: For each i,

x2
i ≤

yjzi,j;

yj, zi,j ≥

0

⇐⇒ k

(2xi, yj −

zi,j)

k2 ≤

yj + zi,j ∀

j = 1, . . . , K. (9)

The above equivalence is trivial. On the other hand, since xi ≤
[0, 1], naturally we have xi ∈
yi ∈
We can apply the face that if yi is positive so
Therefore we may give a (K 2 + 2K)
×
variable vector is composed as follows:

[0, 1]. So we need only constrain that yi ∈
|

[0, 1].
1.
= yi, and if yi ≤
(K 2 + 2K)-matrix Ci in SOCP, and the

yi| ≤

1
Pj

1
yj

, and

1, so

yi|

|

˜x = (x1,

, xK , y1,

, yK, z1,1,

· · ·
where for zi,j, i is corresponding to xi.

· · ·

, z1,K,

, zK,1 · · ·

· · ·

· · ·

, zK,K),

(10)

Now we may give the second order cone programming of our target problem

as follows:

min

˜x h−
Ci ˜x
s.t.
k
A˜x = b.

(w1, w2, 0,

, 0), ˜x
i
i = 1,

· · ·
e⊤
i ˜x + di ∀

k2 ≤

, K 2 + 2K,

· · ·

(11)

where Ci, ei, A and b are deﬁned as follows:

{

∈

1,

· · ·

, K

in matrix Ci, where i

Firstly the matrix C for hyperbolic constraints are given as: For a ﬁxed
1)K, sK] we let
[K], where [K] =
1, and others

s
−
}
(Ci)1,s = 2, (Ci)K+i,K+i = 1, (Ci)2K+(s−1)K+i,2K+(s−1)K+i =
are 0. ei is deﬁned as (ei)K+i = 1 and (ei)2K+(s−1)K+i = 1, others are 0.

−
[K 2, K 2 + K]
we let that (Ci)K+i,K+i = 1 and others are 0. And we let that ei is a zero
[K 2 + K, K 2 + 2K], we set
vector and di = 1. It means that
yik ≤
(Ci)K+i,K+i = 1 eK+i = 1, and di = 0
At last we need to constrain that

Next we need to constrain that yi is less than 1. For i

K
j=1 zj = xi in equation 9: Let A

1. For i

[(s

∈

∈

∈

k

2

) for each row vector Aj , where j

RK×(3K+K
(Aj )2K+(j−1)j+m =
by the row vectors Aj. and b is a zero vector.

1, for all m = 1,

P
· · ·

−

∈
[K], we have that (Aj)j = 1 and
, K. No w the matrix A is composed

∈

⊓⊔

5 Conclusion

In this paper we give a framework for online load balancing problem by reducing
it to two OLO problems. Moreover, for online load balancing problem with re-
spect to L∞-norm we achieve the best known regret bound in polynomial time.
Firstly, we reduce online load balancing with
norm to a vector payoﬀ game
+. Next due to [13] this vector payoﬀ game
measured by combination norm
is reduced to an OCO problem. At last, we can reduce this OCO problem to two
independent OLO problems. Especially, for makespan, we give an eﬃcient algo-
rithm, which achieves the best known regret bound O(√T ln K), by processing
linear programming and second order cone programming in each trial.

k · k

k · k

Improved algorithms for online load balancing

15

There are some open problems left in this topic. For instance, an eﬃcient
algorithm for online load balancing with respect to general norm or p-norm is
still an open problem. Furthermore, the lower bound of online load balancing is
still unknown.

References

1. Abernethy, J., Bartlett, P.L., Hazan, E.: Blackwell approachability and no-regret
learning are equivalent. In: Proceedings of the 24th Annual Conference on Learning
Theory. pp. 27–46 (2011)

(eds.)
2. Azar, Y.: On-line load balancing.
Online Algorithms: The State of
the Art, pp. 178–195. Springer Berlin
Heidelberg, Berlin, Heidelberg (1998). https://doi.org/10.1007/BFb0029569,
https://doi.org/10.1007/BFb0029569

In: Fiat, A., Woeginger, G.J.

3. Blackwell, D., et al.: An analog of the minimax theorem for vector payoﬀs. Paciﬁc

Journal of Mathematics 6(1), 1–8 (1956)

4. Cesa-Bianchi, N., Lugosi, G.: Prediction, learning, and games. Cambridge univer-

sity press (2006)

5. Even-Dar, E., Kleinberg, R., Mannor, S., Mansour, Y.: Online learning for global

cost functions. In: COLT (2009)

6. Hazan, E.: Introduction to Online Convex Optimization. Foundations and Trends
in Optimization 2(3-4), 157–325 (2016), http://ocobool.cs.prinston.edu/
7. Hoeven, D., Erven, T., Kot lowski, W.: The many faces of exponential weights in

online learning. In: Conference On Learning Theory. pp. 2067–2092 (2018)

8. Kivinen, J., Warmuth, M.K.: Exponentiated gradient versus gradient descent for

linear predictors. information and computation 132(1), 1–63 (1997)

9. Lobo, M.S., Vandenberghe, L., Boyd, S., Lebret, H.: Applications of second-order
cone programming. Linear algebra and its applications 284(1-3), 193–228 (1998)
10. Molinaro, M.: Online and random-order load balancing simultaneously. In: Pro-
ceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algo-
rithms. pp. 1638–1650. Society for Industrial and Applied Mathematics (2017)
11. Rakhlin, A., Sridharan, K., Tewari, A.: Online learning: Beyond regret (2011)
12. Shalev-Shwartz, S.: Online learning and online convex optimization. Foundations

and Trends R(cid:13) in Machine Learning 4(2), 107–194 (2012)

13. Shimkin, N.: An online convex optimization approach to blackwell’s approachabil-

ity. The Journal of Machine Learning Research 17(1), 4434–4456 (2016)

6 Appendix

6.1 A general reduction algorithm from a repeated game to an

OCO problem

For completeness, we give in Algorithm 2 a general reduction algorithm of
Shimkin [13] from a repeated game with vector payoﬀs to an OCO problem.

16

Yaxiong Liu, Kohei Hatano, Eiji Takimoto

Algorithm 2 Reduction from game (A, B, r, S, dist) with dist(a, b) =
to OCO [13]
Require: An algorithm A that, when given w, ﬁnds a ∈ A such that hw, r(a, b)i ≤

a
k

b
k

−

hS(w) for any b ∈ B.

Require: An algorithm B for the OCO problem (W, F ), where W = {w | kwk∗ ≤ 1}

and F = {f : w 7→ h−r(a, b), wi + hS(w) | a ∈ A, b ∈ B}.
for t = 1, 2, . . . , T do

1. Obtain wt ∈ W from B.
2. Run A(wt) and obtain at ∈ A.
3. Output at ∈ A and observe bt ∈ B.
4. Construct the loss function ft : w 7→ h−r(at, bt), wi + hS(w) and feed it to B.

end for

