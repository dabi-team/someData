0
2
0
2

y
a
M
9
1

]
h
p
-
t
n
a
u
q
[

2
v
6
1
3
1
0
.
5
0
9
1
:
v
i
X
r
a

Convex optimization of programmable quantum computers

Leonardo Banchi,1, 2,

∗ Jason Pereira,3 Seth Lloyd,4, 5 and Stefano Pirandola3, 5

1Department of Physics and Astronomy, University of Florence,
via G. Sansone 1, I-50019 Sesto Fiorentino (FI), Italy
2INFN Sezione di Firenze, via G.Sansone 1, I-50019 Sesto Fiorentino (FI), Italy
3Department of Computer Science, University of York, York YO10 5GH, UK
4Department of Mechanical Engineering, Massachusetts Institute of Technology (MIT), Cambridge MA 02139, USA
5Research Laboratory of Electronics, Massachusetts Institute of Technology (MIT), Cambridge MA 02139, USA

A fundamental model of quantum computation is the programmable quantum gate array. This
is a quantum processor which is fed by a “program” state that induces a corresponding quantum
operation on input states. While being programmable, any ﬁnite-dimensional design of this model
is known to be non-universal, meaning that the processor cannot perfectly simulate an arbitrary
quantum channel over the input. Characterizing how close the simulation is and ﬁnding the optimal
program state have been open questions for the last 20 years. Here we answer these questions by
showing that the search for the optimal program state is a convex optimization problem that can be
solved via semideﬁnite programming and gradient-based methods commonly employed for machine
learning. We apply this general result to diﬀerent types of processors, from a shallow design based
on quantum teleportation, to deeper schemes relying on port-based teleportation and parametric
quantum circuits.

INTRODUCTION

Back in 1997 a seminal work by Nielsen and Chuang [1]
proposed a quantum version of the programmable gate
array that has become a fundamental model for quan-
tum computation [2]. This is a quantum processor where
a ﬁxed quantum operation is applied to an input state
together with a program state. The aim of the program
state is to induce the processor to apply some target
quantum gate or channel [3] to the input state. Such a de-
sired feature of quantum programmability comes with a
cost: The model cannot be universal, unless the program
state is allowed to have an inﬁnite dimension, i.e., inﬁ-
nite qubits [1, 4]. Even though this limitation has been
known for many years, there is still no exact character-
ization on how well a ﬁnite-dimensional programmable
quantum processor can generate or simulate an arbitrary
quantum channel. Also there is no literature on how to
ﬁnd the corresponding optimal program state or even to
show that this state can indeed be found by some opti-
mization procedure. Here we show the solutions to these
long-standing open problems.

Here we show that the optimization of programmable
quantum computers is a convex problem for which the so-
lution can always be found by means of classical semidef-
inite programming (SDP) and classical gradient-based
methods that are commonly employed for machine learn-
ing applications. Machine learning (ML) methods have
found wide applicability across many disciplines [5], and
we are currently witnessing the development of new hy-
brid areas of investigation where ML methods are in-
terconnected with quantum information theory, such as
quantum-enhanced machine learning [6–10] (e.g., quan-
tum neural networks, quantum annealing etc.), protocols

∗ leonardo.banchi@uniﬁ.it

of quantum-inspired machine learning (e.g., for recom-
mendation systems [11] or component analysis and su-
pervised clustering [12]) and classical learning methods
applied to quantum computers, as explored here in this
manuscript.

In our work, we quantify the error between an arbi-
trary target channel and its programmable simulation in
terms of the diamond distance [3, 13] and other suitable
cost functions, including the trace distance and the quan-
tum ﬁdelity. For all the considered cost functions, we
are able to show that the minimization of the simulation
error is a convex optimization problem in the space of
the program states. This already solves an outstanding
problem which aﬀects various models of quantum com-
puters (e.g., variational quantum circuits) where the op-
timization over classical parameters is non-convex and
therefore not guaranteed to converge to a global opti-
mum. By contrast, because our problem is proven to
be convex, we can use SDP to minimize the diamond
distance and always ﬁnd the optimal program state for
the simulation of a target channel, therefore optimiz-
ing the programmable quantum processor. Similarly, we
may ﬁnd suboptimal solutions by minimizing the trace
distance or the quantum ﬁdelity by means of gradient-
based techniques adapted from the ML literature, such
as the projected subgradient method [14] and the conju-
gate gradient method [15, 16]. We note indeed that the
minimization of the (cid:96)1-norm, mathematically related to
the quantum trace distance, is widely employed in many
ML tasks [17, 18], so many of those techniques can be
adapted for learning program states.

With these general results in our hands, we ﬁrst discuss
the optimal learning of arbitrary unitaries with a generic
programmable quantum processor. Then, we consider
speciﬁc designs of the processor, from a shallow scheme
based on the teleportation protocol, to higher-depth de-
signs based on port-based teleportation (PBT) [19–21]

 
 
 
 
 
 
and parametric quantum circuits (PQCs) [22], introduc-
ing a suitable convex reformulation of the latter. In the
various cases, we benchmark the processors for the simu-
lation of basic unitary gates (qubit rotations) and var-
ious basic channels,
including the amplitude damping
channel which is known to be the most diﬃcult to sim-
ulate [23, 24]. For the deeper designs, we ﬁnd that the
optimal program states do not correspond to the Choi
matrices of the target channels, which is rather counter-
intuitive and unexpected.

RESULTS

We ﬁrst present our main theoretical results on how
to train the program state of programmable quantum
processors, either via convex optimization or ﬁrst-order
gradient based algorithms. We then apply our general
methods to study the learning of arbitrary unitaries, and
the simulation of diﬀerent channels via processors built
either from quantum teleportation and its generalization,
or from parametric quantum circuits.

Programmable quantum computing

2

FIG. 1. Quantum processor Q with program state π which
simulates a quantum channel Eπ from input to output. We
also show the CPTP map Λ of the processor, from the pro-
gram state π to the output Choi matrix χπ (generated by
partial transmission of the maximally-entangled state Φ).

E

= 0 for arbitrary

From theory [1, 4] we know that we cannot achieve
C
unless π and Q have inﬁnite
(cid:5)
dimensions. As a result, for any ﬁnite-dimensional re-
alistic design of the quantum processor, ﬁnding the op-
timal program state ˜π is an open problem. Recall
that the diamond distance is deﬁned by
:=
(cid:107)E − Eπ(cid:107)(cid:5)
is the identity
− I ⊗ Eπ(ϕ)
maxϕ (cid:107)I ⊗ E
O
map and
(cid:107)

(ϕ)
(cid:107)1 := Tr√O†O is the trace norm [2].
It is important to note that this problem can be re-
duced to a simpler one by introducing the channel’s Choi
matrix

(cid:107)1, where

I

E

Let us consider an arbitrary mapping from d-
input states into d(cid:48)-dimensional output
dimensional
= d in the general case. This is described
states, where d(cid:48)
by a quantum channel
that may represent the overall
action of a quantum computation and does not need to
be a unitary transformation. Any channel
can be sim-
ulated by means of a programmable quantum processor,
which is modeled in general by a ﬁxed completely pos-
itive trace-preserving (CPTP) map Q which is applied
to both the input state and a variable program state π.
In this way, the processor transforms the input state by
means of an approximate channel

E

Eπ as
π)] ,

Eπ(ρ) = Tr

2

[Q(ρ

⊗

(1)

E

where Tr2 is the partial trace over the program state. A
fundamental result [1] is that there is no ﬁxed quantum
“processor” Q that is able to exactly simulate any quan-
tum channel
, we cannot ﬁnd
. In other terms, given
E
E ≡ Eπ. Yet sim-
the corresponding program π such that
ulation can be achieved in an approximate sense, where
the quality of the simulation may increase for larger pro-
gram dimension. In general, the open problem is to de-
termine the optimal program state ˜π that minimizes the
simulation error, that can be quantiﬁed by the cost func-
tion

(π) :=

C

(cid:5)

(cid:107)E − Eπ(cid:107)(cid:5)

,

(2)

namely the diamond distance [3, 13] between the target
channel

and its simulation

E

Find ˜π such that C
(cid:5)

Eπ. In other words,
(π).
(˜π) = min

C
(cid:5)

π

(3)

χ

π =
E

I ⊗ Eπ(Φ)
1(cid:80)
i
ij |
(cid:105)(cid:104)

= d−

j

i
Tr2 [Q(
|

(cid:105)(cid:104)

j

| ⊗

| ⊗

π)] ,

(4)

|

Φ

(cid:105)(cid:104)

Φ
|

where Φ :=
is a d-dimensional maximally-
entangled state. From this expression, it is clear that
π is linear in the program state π.
the Choi matrix χ
E
More precisely, the Choi matrix χ
π at the output of the
E
processor Q can be directly written as a CPTP linear
map Λ acting on the space of the program states π, i.e.,

χπ := χ

π = Λ(π).
E

(5)

This map is also depicted in Fig. 1 and fully describes
the action of the processor Q. Then, using results from
Refs. [3, 25, 26], we may write

(π)

C
(cid:5)

≤

d C1(π)

≤

(cid:112)

2d

CF (π),

where

C1(π) :=

χ

E −

(cid:107)

χπ(cid:107)1 ,

(6)

(7)

is the trace distance [2] between target and simulated
Choi matrices, and

CF (π) = 1

F (π)2,

−

(8)

where F (π) is Bures’ ﬁdelity between the two Choi ma-
trices χ
E

and χπ, i.e.,

F (π) :=

√χ
(cid:107)
E

√χπ(cid:107)1 = Tr

(cid:113)

√χ

χπ√χ
E

.

E

(9)

Q  Φ ℰ𝜋 𝜒𝜋 Λ Processor Program Choi 𝜌 ℰ(𝜌) Input Output (cid:54)
Another possible upper bound can be written using the
quantum Pinsker’s inequality [27, 28]. In fact, we may
write C1(π)

CR(π), where

(2 ln √2)

(cid:112)

≤

CR(π) := min

S(χ
{

χ
χπ), S(χπ||

,

)
}

σ) := Tr[ρ(log2 ρ
||

E ||
E
and S(ρ
log2 σ)] is the quantum rela-
−
tive entropy between ρ and σ. In Supplementary Note 1.3
we also introduce a cost function Cp(π) based on the
Schatten p-norm.

(10)

Convex optimization

One of the main problems in the optimization of recon-
ﬁgurable quantum chips is that the relevant cost func-
tions are not convex in the set of classical parameters.
This problem is completely solved here thanks to the fact
that the optimization of a programmable quantum pro-
cessor is done with respect to a quantum state. In fact,
in the methods section we prove the following

E

Theorem 1. Consider the simulation of a target quan-
by means of a programmable quantum pro-
tum channel
, C1,
cessor Q. The optimization of the cost functions C
(cid:5)
CF , CR or Cp is a convex problem in the space of pro-
gram states π. In particular, the global minimum ˜π for
C

can always be found as a local minimum.

(cid:5)
This convexity result is generally valid for any cost
function which is convex in π. This is the case for any de-
sired norm, not only the trace norm, but also the Frobe-
nius norm, or any Schatten p-norm.
It also applies to
the relative entropy. Furthermore, the result can also be
extended to any convex parametrization of the program
states.

When dealing with convex optimization with respect
to positive operators, the standard approach is to map
the problem to a form that is solvable via semi-deﬁnite
programming (SDP) [29, 30]. Since the optimal program
is the one minimizing the cost function, it is important
to write the computation of the cost function itself as
a minimization. For the case of the diamond distance,
this can be achieved by using the dual formulation [29].
More precisely, consider the linear map Ωπ :=
E − Eπ
Λ(π), and the
with Choi matrix χΩπ = χ
E −
Cd,
spectral norm
,
1
}
{(cid:107)
which is the maximum eigenvalue of √O†O. Then, by
the strong duality of the diamond norm, C
Ωπ(cid:107)(cid:5)
(cid:107)
(cid:5)
is given by the SDP [31]

χπ = χ
: u
Ou
(cid:107)

E −
∈

:= max

(π) =

u
(cid:107)

(cid:107) ≤

(cid:107)∞

O

(cid:107)

Subject to Z

≥

Minimize 2

Tr2Z
(cid:107)
0 and Z

d(χ

(cid:107)∞

,

≥

E −

Λ(π)).

(11)

3

In the methods section we show that other cost func-
tions such as C1 and CF can also be written as SDPs.
Correspondingly, the optimal programs ˜π can be ob-
tained by numerical SDP solvers. Most numerical pack-
ages implement second-order algorithms such as the inte-
rior point method [32]. However, second order methods
tend to be computationally heavy for large problem sizes
[33, 34], namely when ˜π contains many qudits. In the fol-
lowing section we introduce ﬁrst order methods, that are
better suited for larger program states. It is important to
remark that there also exist zeroth-order (derivative-free)
methods, such as the simultaneous perturbation stochas-
tic approximation method [35], which was utilized for
a quantum problem in [36]. However, it is known that
zeroth-order methods normally have slower convergence
times [37] compared to ﬁrst-order methods.

Gradient based optimization

In machine learning applications, where a large amount
of data is commonly available, there have been several
works that study the minimization of suitable matrix
norms for diﬀerent purposes [17, 18, 38, 39]. First-order
methods, are preferred for large dimensional problems,
as they are less computationally intensive and require
less memory. Here we show how to apply ﬁrst-order
(gradient-based) algorithms, which are widely employed
in machine learning applications, to ﬁnd the optimal
quantum program.

For this purpose, we need to introduce the subgradient
, which is the

of the cost function C at any point π
set

∈ S

∀

σ

−

−

≥

π)],

C(π)

Tr[Z(σ

∂C(π) =

its gradient

Z : C(σ)
{

,
∈ S}
(12)
where Z is Hermitian [40, 41]. If C is diﬀerentiable, then
C(π).
∂C(π) contains a single element:
We explicitly compute this gradient for an arbitrary pro-
grammable quantum processor (1) whose Choi matrix
χ
χπ = Λ(π), can be written as a quantum channel
E
Λ that maps a generic program state to the processor’s
Choi matrix. This map can be deﬁned by its Kraus de-
composition Λ(π) = (cid:80)
k AkπA†k for some operators Ak.
In fact, let us call Λ∗(ρ) = (cid:80)
k A†kρAk the dual map, then
in the methods section we prove the following

π ≡

∇

Theorem 2. Consider an arbitrary quantum channel
E
with Choi matrix χ
which is simulated by a quantum
processor Q with map Λ(π) = χπ (and dual map Λ∗).
Then, we may write the following gradients for the trace
distance cost C1(π) and the inﬁdelity cost CF (π)

E

The importance of the above dual formulation is that
the diamond distance is a minimization, rather than a
maximization over a set of matrices. In order to ﬁnd the
optimal program ˜π we apply the unique minimization of
Eq. (11) where π is variable and satisﬁes the additional
constraints π

0 and Tr(π) = 1.

≥

C1(π) =

∇

CF (π) =

∇

F (π) =

∇

(cid:88)

k

sign(λk)Λ∗(Pk),

(cid:112)
2

Λ∗

1
(cid:104)

−
√χ

−
1
2

CF (π)

(√χ
E

E

F (π),

∇
Λ(π) √χ
E

(13)

(14)

1

2 √χ

)−

(cid:105)

E

,

(15)

where λk (Pk) are the eigenvalues (eigenprojectors) of the
. When C1(π) or CF (π) are
Hermitian operator χπ −
E
not diﬀerentiable in π, then the above expressions provide
an element of the subgradient ∂C(π).

χ

C, we can solve the optimization minπ
the projected subgradient method [14, 40]. Let
the projection onto the set of program states
X

Once we have the (sub)gradient of the cost function
C(π) using
be
PS
, namely
(cid:107)2, that we show to be com-
π
PS
putable from the spectral decomposition of any Hermi-
tian X (see Theorem 3 in the methods section). Then,
we iteratively apply the steps

(X) = argminπ

S(cid:107)
∈

−

∈S

S

1) Select an operator gi from ∂C(πi),
2) πi+1 =

αigi) ,

(πi −

PS

(16)

where i is the iteration index, αi is what is called “learn-
ing rate”, and Theorem 2 can be employed to ﬁnd gi at
each step. It is simple to show that πi converges to the
2) steps, for any desired
optimal program state ˜π in
precision (cid:15) such that
(cid:15). Another ap-
C(π)
proach is the conjugate gradient method [15, 40], some-
times called Frank-Wolfe algorithm. Here, we apply

O
−

C(˜π)

| ≤

((cid:15)−

|

|

of

i+2 |

σi(cid:105)

C(πi),

1) Find the smallest eigenvalue
2) πi+1 = i
i+2 πi + 2
.
σi|

σi(cid:105) (cid:104)
When the gradient of f is Lipschitz continuous with con-
(L/(cid:15)) steps [16, 42].
stant L, the method converges after
To justify the applicability of this method a suitable
smoothening of the cost function must be employed [43].

(17)

∇

O

4

designs, over which we will test the optimization pro-
cedure. One possible (shallow) design for the quantum
processor Q is a generalized teleportation protocol [48]
over an arbitrary program state π. In dimension d, the
protocol involves a basis of d2 maximally-entangled states
of teleportation unitaries such that
Φi(cid:105)
|
Tr(U †i Uj) = dδij [49]. An input d-dimensional state ρ
and the A part of the program πAB are subject to the
. The classical outcome i is communi-
projector
cated to the B part of πAB where the correction U −
is
i
applied.

and a basis

Φi(cid:105) (cid:104)
|

Ui}

Φi|

{

1

The above procedure deﬁnes the teleportation channel

Eπ over ρ

tele
π (ρ) =
E

(cid:88)

i

U B
i (cid:104)

ΦSA
i

ρS

|

⊗

πAB

ΦSA
i
|

(cid:105)

U B
†i

.

(19)

Its Choi matrix can be written as χπ = Λtele(π), where
the map of the teleportation processor is equal to

Λtele(π) = d−

2 (cid:88)

i

(U ∗i ⊗

Ui) π (U ∗i ⊗

Ui)† ,

(20)

E

which is clearly self-dual Λ∗ = Λ. Given a target quan-
tum channel
which is teleportation-covariant [23, 24],
Ui] = 0, then we know that that
namely when [π, U ∗i ⊗
its simulation is perfect and the optimal program ˜π is the
channel’s Choi matrix, i.e., one of the ﬁxed points of the
map Λtele. For a general channel, the optimal program ˜π
can be approximated by using the cost functions in our
Theorem 2 with Λ being given in Eq. (20), or directly
found by optimizing C
(cid:5)

(π).

Learning of arbitrary unitaries

Port-based teleportation

One speciﬁc application is the simulation of quantum
gates or, more generally, unitary transformations [22, 44–
47]. Here, the inﬁdelity provides the most convenient cost
function, as the optimal program can be found analyti-
cally. In fact, suppose we use a quantum processor with
map Λ to simulate a target unitary U . Because the Choi
, we ﬁrst note that F (π)2 =
matrix of U is pure
χU |
χU (cid:105)(cid:104)
|
and then we see that Eq. (15) drastically
χU (cid:105)
Λ(π)
χU |
(cid:104)
|
4F (π)2. As a
simpliﬁes to
χU |
F (π) = Λ∗ (
|
∇
result, we ﬁnd

χU (cid:105)(cid:104)

) /

(cid:112)

CF (π) =

Λ∗ [
|

χU (cid:105)(cid:104)

] ,
χU |

−

∇

(18)

where there is no dependence on π. Therefore, using the
conjugate gradient method in Eq. (17), we see that the
optimal program state ˜π for the inﬁdelity cost function
CF is a ﬁxed point of the iteration and is equal to the
maximum eigenvector of Λ∗ [
|

].
χU |

χU (cid:105)(cid:104)

A1, . . . , AN }
{

A deeper design is provided by a PBT processor,
is illustrated in Fig. 2. Here
whose overall protocol
we consider a more general formulation of the original
PBT protocol [19, 20] where the resource entangled pairs
are replaced by an arbitrary program state π.
In a
PBT processor, each party has N systems (or ‘ports’),
A =
B1, . . . , BN }
{
for Bob. These are prepared in a program state πAB.
To teleport an input state ρC, Alice performs a joint
positive operator-value measurement (POVM)
[19]
on system C and the A-ports. She then communicates
the outcome i to Bob, who discards all ports except Bi
which is the output Bout. The resulting PBT channel
Pπ :

for Alice and B =

Πi}

{

Πi(πAB

(cid:112)

ρC)

Πi

⊗

(cid:105)

Bi

Bout

→

HC (cid:55)→ HBout is then
(cid:104)(cid:112)

N
(cid:88)

Pπ(ρ) =

Tr
A ¯BiC

i=1

N
(cid:88)

i=1

Teleportation processor

=

Tr
A ¯BiC

[Πi(πAB

ρC)]Bi

Bout ,

→

⊗

(21)

Once we have shown how to optimize a generic pro-
grammable quantum processor, we discuss some speciﬁc

where ¯Bi = B
\

Bi =

Bk : k
{

= i

.
}

(cid:54)
5

E

I

with its PBT simulation

is the identity channel. This is done by replacing the
I
IN , and then
identity channel
to Bi. However, since Bob does not perform
applying
any post-processing on his systems B, aside from dis-
= i, he can also apply ﬁrst
carding all ports Bk with k
N to all his ports and then discard all the
the channel
⊗
= i. In doing so, he changes the program
ports Bk with k
state to

E

πAB = 11A ⊗ E

⊗
B

(cid:34) N
(cid:79)

N

k=1

(cid:35)

ΦAkBk

=

N
(cid:79)

k=1

χAkBk
E

.

(25)

In other terms, any channel
by N copies of its Choi matrix χ
E
PBT-simulation can be decomposed as
error C N
(cid:5)
satisﬁes

can be PBT-approximated
as program state. Since
E ◦ IN , the
E ≡ E ◦I

in simulating the channel

(cid:107)E −Eπ(cid:107)(cid:5)

Eπ =

=

E

C N
(cid:5)

=

(cid:107)E◦I−E◦IN (cid:107) ≤ (cid:107)I−IN (cid:107)(cid:5) ≤

2d(d

−

1)N −

1 . (26)

where we used the data processing inequality and an up-
per bound from [50]. While the channel’s Choi matrix
assures that C N
0 for large N , for any ﬁnite N it does
not represent the optimal program state. In general, for
any ﬁnite N , ﬁnding the optimal program state πAB sim-
with PBT is an open problem, and
ulating a channel
no explicit solutions or procedures are known.

(cid:5) →

E

|

(cid:5)

of A

ei
j(cid:105)

B
\
{

and a basis

Λ(π) = (cid:80)

→
ijKijπK †ij, Kij :=

We employ our convex optimization procedures to ﬁnd
the optimal program state. This can be done either ex-
actly by minimizing the diamond distance cost function
C
via SDP, or approximately, by determining the op-
timal program state via the minimization of the trace
distance cost function C1 via either SDP or the gradient-
based techniques discussed above. For this second ap-
proach, we need to derive the map Λ of the PBT proces-
sor, between the program state π to output Choi matrix
as in Eq. (5). To compute the Choi matrix and CP-
map Λ, we consider an input maximally-entangled state
C. Then, by using
Bi}
ΦDC(cid:105)
|
Eq. 21 and the deﬁnition Λ(π) = χ
π = 11D ⊗ Pπ[ΦDC]
P
we ﬁnd the map ΛAB
DBout of a PBT processor
(cid:112)

.
ΦDC(cid:105)
(27)
Note that a general program state for PBT consists
of 2N qudits, and hence the parameter space has expo-
nential size d4N . However, because the PBT protocol
is symmetric under permutation of port labels, we show
in Supplementary Note 6 that one can exploit this sym-
metry and reduce the number of free parameters to the
binomial coeﬀﬁcient (cid:0)N +d4
(cid:1), which is polynomial in
−
d4
1
the number of ports N . Despite this exponential reduc-
tion, the scaling in the number of parameters still repre-
sents a practical limiting factor, even for qubits for which
(cid:0)N 15(cid:1). A sub-optimal strategy consists in reducing the
O
space of program states to a convex set that we call the
“Choi space”
. Consider an arbitrary probability distri-
pk}
bution
π : π = (cid:80)
{

C
and then deﬁne

AB , TrB(ρk

AB) = d−

11BD|

Πi ⊗

kpkρk

ei
j|

(28)

.
}

111

=

C

{

N

−

⊗

(cid:104)

1

FIG. 2. PBT scheme. Two distant parties, Alice and Bob,
share N maximally entangled pairs {Ak, Bk}N
k=1. Alice also
has another system C in the state |ψ(cid:105). To teleport C, Al-
ice performs the POVM {ΠAC
} on all her local systems
A = {Ak}N
k=1 and C. She then communicates the outcome i
to Bob. Bob discards all his systems B = {Bk}N
k=1 with the
exception of Bi. After these steps, the state |ψ(cid:105) is approx-
imately teleported to Bi. Similarly, an arbitrary channel E
is simulated with N copies of the Choi matrix χAkBk
. The
ﬁgure shows an example with N = 5, where i = 4 is selected.

E

i

In the standard PBT protocol [19, 20], the program
are

state is ﬁxed as πAB = (cid:78)N
k=1 ΦAkBk , where
|
Bell states, and the following POVM is used

ΦAkBk (cid:105)

Πi = ˜Πi +

(cid:32)

11

−

1
N

(cid:88)

k

(cid:33)

˜Πk

,

where

1/2

˜Πi = σ−
AC ΦAiCσ−
N
(cid:88)

1/2
AC ,

σAC :=

ΦAiC,

i=1

(22)

(23)

(24)

≥

1/2 is an operator deﬁned only on the support of
and σ−
2 ports.
σ. The PBT protocol is formulated for N
However, we also include here the trivial case for N = 1,
corresponding to the process where Alice’s input is traced
out and the output is the reduced state of Bob’s port,
, the
i.e., a maximally mixed state. In the limit N
standard PBT protocol approximates an identity chan-
(cid:1), so
nel
ρ, with ﬁdelity [19, 21] Fπ = 1
perfect simulation is possible only in the limit N
.
→ ∞
Since the standard PBT-protocol provides an approxi-
mation to the identity channel, we call it

IN .
possible to approximate any general channel
ing that

From the PBT-simulation of the identity channel it is
by not-
, where

can be written as a composition

→ ∞
(cid:0) 1
N

Pπ(ρ)

− O

≈

E
E ◦ I

E

AliceBobdiscardBkk6=i|ψiC≈|ψiA1B1A2B2A3B3A4B4A5B5(cid:7)iΠACi(cid:54)
(cid:54)
C

One can show (see Supplementary Note 6) that a global
minimum in
is a global minimum in the extremal
(non-convex) subspace for pk = δk,1 consisting of tensor-
products of Choi matrices ρ⊗
AB . Among these states,
there is the N -copy Choi matrix of the target channel
N which is not necessarily the
χ⊗
Φ
(cid:105) (cid:104)
E
optimal program, as we show below.

)]⊗
|

I ⊗ E

= [

(
|

Φ

N

N

Parametric quantum circuits

Another deep design of quantum processor is based
on PQCs [22, 51]. A PQC is a sequence of unitary ma-
trices U (t) = UN (tN ) . . . U2(t2)U1(t1), where Uj(tj) =
exp(itjHj) for some Hamiltonian Hj and time interval
tj. The problem with PQCs is that the cost functions in
the classical parameters [44] are not convex, so that nu-
merical algorithms are not guaranteed to converge to the
global optimum. Here we ﬁx this issue by introducing a
convex formulation of PQCs where classical parameters
are replaced by a quantum program. This results in a
programmable PQC processor which is optimizable by
our methods.

(ρA) = TrR0[U (ρA⊗

The universality of PQCs can be employed for univer-
sal channel simulation. Indeed, thanks to Stinespring’s
dilation theorem, any channel can be written as a unitary
evolution on a bigger space,
θ0)U †],
E
where the system is paired to an extra register R0 and θ0
belongs to R0. In the Stinespring representation U acts
on system A and register R0.
In Ref. [51] it has been
shown that sequences of two unitaries, U0 and U1, are
almost universal for simulation, i.e., any target unitary
U can be approximated as U
for
≈ · · ·
some integers mj. Under suitable conditions, it takes
d) steps to approximate U up to precision (cid:15). The
O
choice between U0 and U1 is done by measuring a classi-
cal bit. We may introduce a quantum version, where the
two diﬀerent unitaries U0 = eiH0 or U1 = eiH1 are chosen
depending on the state of qubit Rj. This results in the
conditional gate

U m4
1 U m3

0 U m2

1 U m1

(d2(cid:15)−

0

(29)

ˆUj = exp (iH0 ⊗ |

0
0
(cid:105)j j(cid:104)

+ iH1 ⊗ |

1

1
(cid:105)j j(cid:104)

) .
|

|
Channel simulation is then obtained by replacing the uni-
tary evolution U in the Stinespring dilation via its sim-
ulation. The result is illustrated in Fig. 3, where the
program state π is deﬁned over R = (R0, . . . , RN ) and
each ˆHj acts on the input system A and two ancillary
qubits R0 and Rj. Following the universality construc-
tion of Ref. [51] we show in the Supplementary Note 3.4
that the channel shown in Fig. 3 provides a universal pro-
cessor. Moreover, the channel Λ that maps any program
π to the processor’s Choi matrix is obtained as

Λ(π) = TrR

where ˆUAR = 11B ⊗
identify the optimal program

j=1

(cid:81)N

(cid:104)
ˆUAR (ΦBA ⊗
ˆUj A,R0,Rj
˜π
|

(cid:105)

πR) ˆU †AR

(cid:105)

,

(30)

, from which we can

via our methods.

6

FIG. 3. Simulation of a quantum channel via Stinespring
decomposition together with unitary simulation as in Fig. 14.

|

|

⊗ |

+ 0

2
(cid:105)j j(cid:104)

0
0
(cid:105)j j(cid:104)

1
1
(cid:105)j j(cid:104)

PQCs are not inherently monotonic. A deeper (higher
N ) design may simulate a given channel worse than a
more shallow design. We can design a modiﬁed PQC that
is monotonic by design, which we designate a “monotonic
PQC”, by replacing the qubits in our program state with
qutrits, and modifying Eq. 29 to read
ˆUj = exp (iH0 ⊗ |
) ,
2
+ iH1 ⊗ |
|
(31)
where 0 is a zero operator, so that gate j enacts the
identity channel if program qutrit j is in the state
.
2
|
Then, if it were the case that a PQC with N program
qubits could simulate a given channel better than one
with N + m, a monotonic PQC with N + m qutrits in the
program state could perform at least as well as the PQC
with N program qubits by setting the ﬁrst m qutrits to
. This processor design is both universal and mono-
2
|
|
tonic. More precisely, let C(PQCN ) denote the value of
a cost function C for simulating a channel
with an
N -gate PQC, using the optimal program state, and let
with
C(mPQCN ) denote the value of C for simulating
an N -gate monotonic PQC, again using the optimal pro-
gram state. We are then guaranteed that

2
(cid:105)(cid:104)

2
(cid:105)(cid:104)

E

E

|

C(mPQCN )

min
N
M
≤

≤

C(PQCM ).

(32)

Processor benchmarking

In order to show the performance of the various ar-
chitectures, we consider the simulation of an amplitude
damping channel with probability p. The reason is be-
cause this is the most diﬃcult channel to simulate, with
a perfect simulation only known for inﬁnite dimension,
e.g., using continuous-variable quantum operations [23].
In Figs. 4-5 we compare teleportation-based, PBT, PQC
and “monotonic PQC” (mPQC) programmable proces-
sors whose program states have been optimized according
to the cost functions C
and C1. For the PBT proces-
(cid:5)
sor the trace distance cost C1 is remarkably close to C
(cid:5)
and allows us to easily explore high depths. Note that

|ψiUθ1Uθ2Uθ3Uθ4|θ0i|θ1i•|θ2i•|θ3i•|θ4i•7

least as well as any shallower design. In Fig. 5 perfect
simulation is achievable at speciﬁc values of p because of
our choice of the universal gates U0 and U1. More details
are provided in the Supplementary Note 3.

Many other numerical simulations are performed in the
Supplementary Note 3 where we study the convergence
rate in learning a unitary operation, the exact simulation
of Pauli channels, and approximate simulation of both
dephasing and amplitude damping channels. In particu-
lar, we study the performance of the approximate solu-
tion when optimizing over larger, but easier to compute,
cost functions such as the trace distance or the inﬁdelity.

DISCUSSION

In this work we have considered a general ﬁnite-
dimensional model of a programmable quantum proces-
sor, which is a fundamental scheme for quantum com-
puting and also a primitive tool for other areas of quan-
tum information. By introducing suitable cost functions,
based on the diamond distance, trace distance and quan-
tum ﬁdelity, we have shown how to characterize the op-
timal performance of this processor in the simulation of
an arbitrary quantum gate or channel. In fact, we have
shown that the minimization of these cost functions is a
convex optimization problem that can always be solved.
In particular, by minimizing the diamond distance via
SDP, we can always determine the optimal program state
for the simulation of an arbitrary channel. Alternatively,
we may minimize the simpler but larger cost functions in
terms of trace distance and quantum ﬁdelity via gradient-
based methods adapted from ML, so as to provide a
very good approximation of the optimal program state.
This other approach can also provide closed analytical
solutions, as is the case for the simulation of arbitrary
unitaries, for which the minimization of the ﬁdelity cost
function corresponds to computing an eigenvector.

We have then applied our results to various de-
from a
signs of programmable quantum processor,
shallow teleportation-based scheme
to deeper and
asymptotically-universal designs that are based on PBT
and PQCs. We have explicitly benchmarked the perfor-
mances of these quantum processors by considering the
simulation of unitary gates, depolarizing and amplitude
damping channels, showing that the optimal program
states may diﬀer from the naive choice based on the Choi
matrix of the target channel. Moreover, our results can
be applied also for universal quantum measurements [53].
A potential application of our work may be the devel-
opment of “programmable” model of cloud-based quan-
tum computation, where a client has an input state to be
processed by an online quantum server which is equipped
with a programmable quantum processor. The client
classically informs the server about what type of compu-
tation it needs (e.g., some speciﬁed quantum algorithm)
and the server generates an optimal program state which
closely approximates the overall quantum channel to be

FIG. 4. Diamond-distance error C(cid:5) in simulating an ampli-
tude damping channel Ep at various damping rates p. We
compare the performance of diﬀerent designs for the pro-
grammable quantum processor: Standard teleportation and
port-based teleportation with N ports (PBTN ). The opti-
mal program ˜π is obtained by either minimizing directly the
diamond distance C(cid:5) (solid lines), or the trace distance C1
(dashed lines) via the projected subgradient iteration. In both
cases, from ˜π we then compute C(cid:5)(˜π). The lowest curves are
obtained by optimizing π over the Choi space in Eq. (28).
For comparison, we also show the (non-optimal) performance
when the program is the channel’s Choi matrix (dotted lines).

FIG. 5. Diamond-distance error C(cid:5) in simulating an ampli-
tude damping channel Ep at various damping rates p. We
compare the performance of two diﬀerent designs for the pro-
grammable quantum processor: parametric quantum circuits
with N +1 registers (PQCN ) and monotonic parametric quan-
tum circuits with N +1 registers (mPQCN ). In both cases the
optimal program |˜π(cid:105) is obtained by minimizing the diamond
distance C(cid:5).

the optimal program states diﬀer from the naive choice
of the Choi matrix of the target channel. Note too that
PQC processors display non-monotonic behaviour when
simulating amplitude damping channels, meaning that
shallow PQC processors (e.g., for N = 4) may perform
better than deeper processors [52]. Monotonic PQC pro-
cessors guarantee that deeper designs always perform at

0.00.20.40.60.81.01.21.4kE−Eπk(cid:5)0.00.20.40.60.81.0pPBT2PBT3PBT4PBT20Telep.0.00.20.40.60.81.01.21.4kE−Eπk(cid:5)0.20.40.60.81.0pPQC1PQC2PQC3PQC4PQC5PQC60.20.40.60.81.0pmPQC1mPQC2mPQC3mPQC4applied to the input. The server then accepts the input
from the client, processes it, and returns the output to-
gether with the value of a cost function quantifying how
close the computation was with respect to the client’s
request.

Our results may also be useful in areas beyond quan-
tum computing, wherever channel simulation is a basic
problem. For instance, this is the case when we investi-
gate the ultimate limits of quantum communications [24],
design optimal Hamiltonians for one-way quantum re-
peaters, and for all those areas of quantum sensing, hy-
pothesis testing and metrology which are based on quan-
tum channel simulations [54]. Indeed the study of adap-
tive protocols of quantum channel discrimination (or esti-
mation) is notoriously diﬃcult, and their optimal perfor-
mance is not completely understood. Nonetheless, these
protocols can be analyzed by using simulation techniques
[50, 54] where the channel, encoding the unknown param-
eter, is replaced by an approximate simulating channel,
and its parameter is mapped into the label of a program
state (therefore reducing the problem from channel to
state discrimination/estimation). In this regard, our the-
ory provides the optimal solution to this basic problem,
by determining the best simulating channel and the cor-
responding program state.

METHODS

Convexity proofs

(cid:5)

In this section we provide a proof of Theorem 1, namely
we show that the minimization of the main cost functions
C
, C1 and CF is a convex optimization problem in the
space of the program states π. This means that we can
ﬁnd the optimal program state ˜π by minimizing C
or,
(cid:5)
alternatively, sub-optimal program states can be found
by minimizing either C1 or CF . For the sake of generality,
we prove the result for all of the cost functions discussed
in the previous sections. We restate Theorem 1 below for
completeness:

Theorem. The minimization of the generic cost func-
tion C = C
, C1, CF , CR or Cp for any p > 1 is a convex
optimization problem in the space of program states.

(cid:5)

Proof. Let us start to show the result for the diamond
distance C

. In this case, we can write the following

(cid:5)

p)π(cid:48)]

(cid:5)

−

[pπ + (1

C
:= (cid:13)
(cid:13)
E − Epπ+(1
−
(p+1
(cid:107)

(1)
=

p)

E −

−

p

p)π(cid:48)

(cid:13)
(cid:13)
(cid:5)
Eπ −
(1
(cid:107)

−

p)

(1

−

(cid:107)(cid:5)

Eπ(cid:48)
(1

(2)

≤ (cid:107)
(3)

p
≤
= pC

p

p

Eπ(cid:107)(cid:5)

+

E −

p)

E −

p)

Eπ(cid:48)

(cid:107)(cid:5)

−

(cid:107)E − Eπ(cid:107)(cid:5)
(π) + (1
(cid:5)

+ (1

−
p)C

(cid:5)

−

(cid:107)E − Eπ(cid:48)

p)
(π(cid:48)),

(cid:107)(cid:5)

(33)

8

x

A

where we use (1) the linearity of
, (2)
E
inequality and (3) the property
(cid:107)1 =
xA
(cid:107)
for any operator A and coeﬃcient x.
For any Schatten p-norm Cp with p

the triangle
(cid:107)1, valid
1, we may prove
convexity following a similar reasoning. Since for any
combination ¯π := p0π0 + p1π1, with p0 + p1 = 1, we
have Λ(¯π) = p0Λ(π0) + p1Λ(π1), then by exploiting the
triangle inequality, and the property
(cid:107)p,
we can show that

(cid:107)p =

xA
(cid:107)

x
|

|(cid:107)

|(cid:107)

≥

A

|

Cp(p0π0 + p1π1) :=

χ
E −
(cid:107)
χ
p0(cid:107)

Λ(p0π0 + p1π1)
(cid:107)p
χ
(cid:107)p + p1(cid:107)
≤
= p0Cp(π0) + p1Cp(π1) .

Λ(π0)

E −

(34)

Λ(π1)

(cid:107)p

E −

To show the convexity of CF , deﬁned in Eq. (8), we note
that the ﬁdelity function F (ρ, σ) satisﬁes the following
concavity relation [55]

(cid:32)

(cid:88)

F

k

(cid:33)2

pkρk, σ

(cid:88)

≥

k

pkF (ρk, σ)2 .

(35)

Due to the linearity of χπ = Λ(π), the ﬁdelity in Eq. (9)
πk for ¯π := (cid:80)
satisﬁes F 2
k pkπk. Accordingly,
we get the following convexity result

k pkF 2

¯π ≥

(cid:80)

CF

(cid:33)

pkπk

(cid:32)

(cid:88)

k

(cid:88)

≤

k

pkCF (πk) .

(36)

For the cost function CR, the result comes from the lin-
earity of Λ(π) and the joint convexity of the relative en-
tropy. In fact, for ¯π := p0π0 + p1π1, we may write

S[Λ(¯π)

χ
E

||

] = S[p0Λ(π0) + p1Λ(π1)
= S[p0Λ(π0) + p1Λ(π1)

χ
]
E
p0χ
E

||
||
] + p1S[Λ(π1), χ
E

+ p1χ
E
],

]
(37)

p0S[Λ(π0), χ
E

≤

with a symmetric proof for S[χ
E ||
convexity of CR(π) in Eq. (10). (cid:4)

Λ(¯π)]. This implies the

Convex classical parametrizations

The result of the theorem 1 can certainly be extended
to any convex parametrization of program states. For
instance, assume that π = π(λ), where λ =
is a
λi}
{
probability distribution. This means that, for 0
1
p
≤
≤
and any two parametrizations, λ and λ(cid:48), we may write

π[pλ + (1

−

p)λ(cid:48)] = pπ(λ) + (1

−

p)π(λ(cid:48)).

(38)

Then the problem remains convex in λ and we may there-
fore ﬁnd the global minimum in these parameters. It is
clear that this global minimum ˜λ identiﬁes a program
state π(˜λ) which is not generally the optimal state ˜π in
the entire program space
, even though the solution may
be a convenient solution for experimental applications.

S

Note that a possible classical parametrization consists

of using classical program states, of the form

π(λ) =

(cid:88)

i

λi |

ϕi(cid:105) (cid:104)

ϕi|

,

(39)

ϕi(cid:105)}

where
is an orthonormal basis in the program
space. Convex combinations of probability distributions
therefore deﬁne a convex set of classical program states

{|

Sclass =

{

π : π =

(cid:88)

i

λi |

ϕi(cid:105) (cid:104)

ϕi|

,

ϕi|

(cid:104)

ϕj(cid:105)

= δij}

. (40)

Optimizing over this speciﬁc subspace corresponds to op-
timizing the programmable quantum processor over clas-
sical programs. It is clear that global minima in
Sclass
are expected to be very diﬀerent. For instance,
and
Sclass cannot certainly include Choi matrices which are
usually very good quantum programs.

S

Gradient-based optimization

As discussed in the main text, the SDP formulation
allows the use of powerful and accurate numerical meth-
ods, such as the interior point method. However, these
algorithms are not suitable for high dimensional prob-
lems, due to their higher computational and memory re-
quirements. Therefore, an alternative approach (useful
for larger program states) consists of the optimization of
the larger but easier-to-compute cost function C = C1
(trace distance) or CF (inﬁdelity), for which we can use
ﬁrst order methods. Indeed, according to Theorem 1, all
R are convex
of the proposed cost functions C :
over the program space
and, therefore, we can solve
S
the optimization minπ
C(π) by using gradient-based
algorithms.

S →

∈S

Gradient-based convex optimization is at the heart of
many popular ML techniques such as online learning in
a high-dimensional feature space [17], missing value esti-
mation problems [18], text classiﬁcation, image ranking,
and optical character recognition [56], to name a few. In
all of the above applications, “learning” corresponds to
the following minimization problem: minx
f (x), where
f (x) is a convex function and
is a convex set. Quan-
tum learning falls into this category, as the space of pro-
gram states is convex due to the linearity of quantum
mechanics and the fact that cost functions are typically
convex in this space (see Theorem 1). Gradient-based ap-
proaches are among the most applied methods for convex
optimization of non-linear, possibly non-smooth func-
tions [40].

∈S

S

When the cost function is not diﬀerentiable we cannot
formally deﬁne its gradient. Nonetheless, we can always
deﬁne the subgradient ∂C of C as in Eq. (12), which in
principle contains many points. When C is not only con-
vex but also diﬀerentiable, then ∂C(π) =
, i.e.
the subgradient contains a single element, the gradient
C, that can be obtained via the Fr´echet derivative of C

C(π)
}

{∇

∇

9

(for more details see Supplementary Note 4). When C is
not diﬀerentiable, the gradient still provides an element
of the subgradient that can be used in the minimization
algorithm.

In order to compute the gradient

C, it is convenient
to consider the Kraus decomposition of the processor
map Λ. Let us write

∇

Λ(π) =

(cid:88)

k

AkπA†k,

(41)

with Kraus operators Ak. We then deﬁne the dual
map Λ∗ of the processor as the one (generally non-trace-
preserving) which is given by the following decomposition

Λ∗(ρ) =

(cid:88)

k

A†kρAk.

(42)

With these deﬁnitions in hands, we can now prove The-
orem 2, which we rewrite here for convenience.

Theorem. Suppose we use a quantum processor Q with
map Λ(π) = χπ in order to approximate the Choi matrix
. Then, the gradients of the
χ
E
E
trace distance C1(π) and the inﬁdelity CF (π) are given
by the following analytical formulas

of an arbitrary channel

C1(π) =

∇

CF (π) =

∇

F (π) =

∇

(cid:88)

k

sign(λk)Λ∗(Pk),

(cid:112)
2

Λ∗

1
(cid:104)

−
√χ

−
1
2

CF (π)

(√χ
E

E

F (π),

∇
Λ(π) √χ
E

(43)

(44)

1

2 √χ

)−

(cid:105)

E

,

(45)

where λk (Pk) are the eigenvalues (eigenprojectors) of the
. When C1(π) or CF (π) are
Hermitian operator χπ −
E
not diﬀerentiable at π, then the above expressions provide
an element of the subgradient ∂C(π).

χ

Proof. We prove the above theorem assuming that the
functions are diﬀerentiable for program π. For non-
diﬀerentiable points, the only diﬀerence is that the above
analytical expressions are not unique and provide only
one of the possibly inﬁnite elements of the subgradient.
Further details of this mathematical proof are given in
Supplementary Note 4. Following matrix diﬀerentiation,
for any function f (A) = Tr[g(A)] of a matrix A, we may
write

dTr[g(A)] = Tr[g(cid:48)(A)dA],

(46)

and the gradient is
f (A) = g(cid:48)(A). Both the trace-
distance and ﬁdelity cost functions can be written in this
form. To ﬁnd the explicit gradient of the ﬁdelity function,
we ﬁrst note that, by linearity, we may write

∇

Λ(π + δπ) = Λ(π) + Λ(δπ) ,

(47)

and therefore the following expansion

√χ
E
Λ(π)√χ
E

Λ(π + δπ)√χ
+ √χ

=
Λ(δπ)√χ

E

E

√χ

E

.

E

(48)

From this equation and diﬀerential calculations of the
ﬁdelity (see Supplementary Note 4.2 for details), we ﬁnd

dF =

(cid:104)

Tr

1
2

(√χ

Λ(π)√χ
E

E

)−

1

2 √χ

E

Λ(δπ)√χ

(cid:105)

E

,

(49)

Projected subgradient method

10

Given the space
onto

projection

PS

of program states, let us deﬁne the
as

S
S

where dF = F (π + δπ)
property of the trace, we get

−

F (π). Then, using the cyclic

dF =

(cid:104)

Λ∗

(cid:104)
√χ

Tr

1
2

(√χ
E

E

Λ(π)√χ

E

)−

1

2 √χ

E

(cid:105)

(cid:105)

δπ

. (50)

Exploiting this expression in Eq. (46) we get the gradient
F (π) as in Eq. (45). The other Eq. (44) simply follows

∇
from applying the deﬁnition in Eq. (8).

For the trace distance, let us write the eigenvalue de-

composition

χπ −

χ
E

=

(cid:88)

k

λkPk .

(51)

Then using the linearity of Eq. (47), the deﬁnition of
a processor map of Eq. (5) and diﬀerential calculations
of the trace distance (see Supplementary Note 4.3 for
details), we can write

dC1(π) =

=

(cid:88)

k
(cid:88)

sign(λk)Tr[PkΛ(dπ)]

sign(λk)Tr[Λ∗(Pk)dπ]

k
= Tr

Λ∗[sign(χπ −
{
From the deﬁnition of the gradient in Eq. (46), we ﬁnally
get

(52)

)]dπ

χ

}

E

.

E
which leads to the result in Eq. (43). (cid:4)

C1(π) = Λ∗[sign(χπ −

∇

χ

)],

(53)

The above results in Eqs. (44) and (43) can be used
together with the projected subgradient method [14]
or conjugate gradient algorithm [15, 16] to iteratively
ﬁnd the optimal program state in the minimization of
minπ
In the following sec-
tions we present two algorithms, the projected subgra-
dient method and the conjugate gradient method, and
show how they can be adapted to our problem.

C(π) for C = C1 or CF .

∈S

(cid:0)(cid:15)−

Projected subgradient methods have the advantage of
simplicity and the ability to optimize non-smooth func-
2(cid:1)
tions, but can be slower, with a convergence rate
O
for a desired accuracy (cid:15). Conjugate gradient meth-
1(cid:1), pro-
(cid:0)(cid:15)−
ods [15, 16] have a faster convergence rate
vided that the cost function is smooth. This conver-
1/2(cid:1)
gence rate can be improved even further to
for strongly convex functions [57] or using Nesterov’s ac-
celerated gradient method [42]. The technical diﬃculty
in the adaptation of these methods for learning program
states comes because the latter is a constrained optimiza-
tion problem, namely at each iteration step the optimal
program must be a proper quantum state, and the cost
functions coming from quantum information theory are,
generally, non-smooth.

(cid:0)(cid:15)−

O

O

PS

(X) = argmin

X

S (cid:107)

π

∈

π

(cid:107)2 ,

−

(54)

where argmin is the argument of the minimum, namely
to the operator X. Then, a
the closest state π
ﬁrst order algorithm to solve minπ
C(π) is to apply the
projected subgradient method [14, 40], which iteratively
applies the iteration (16), which we rewrite below for
convenience

∈ S

∈S

1) Select an operator gi from ∂C(πi),
2) Update πi+1 =

αigi) ,

(πi −

PS

(55)

where i is the iteration index and αi a learning rate.

The above algorithm diﬀers from standard gradient
i) the update rule is based on
methods in two aspects:
the subgradient, which is deﬁned even for non-smooth
αigi is generally not a
functions; ii) the operator πi −
quantum state, so the algorithm ﬁxes this issue by pro-
jecting that operator back to the closest quantum state,
via Eq. (54). The algorithm converges to the optimal so-
(approximating the optimal program ˜π) as [14]
lution π
∗

C(πi)

C(π

)

∗

−

≤

e1 + G (cid:80)i
2 (cid:80)i

k=1 αk

k=1 α2
k

=: (cid:15),

(56)

π

∈

2
2 is the initial error (in Frobenius
where e1 =
π1 −
∗(cid:107)
(cid:107)
2
norm) and G is such that
∂C. Pop-
G for any g
g
2 ≤
(cid:107)
(cid:107)
ular choices for the learning rate that assure convergence
1/√k and αk = a/(b + k) for some a, b > 0.
are αk ∝
In general, the projection step is the major drawback,
which often limits the applicability of the projected sub-
gradient method to practical problems. Indeed, projec-
tions like Eq. (54) require another full optimization at
each iteration that might be computationally intensive.
Nonetheless, we show in the following theorem that this
issue does not occur in learning quantum states, because
the resulting optimization can be solved analytically.

Theorem 3. Let X be a Hermitian operator in a d-
dimensional Hilbert space with spectral decomposition
X = U xU †, where the eigenvalues xj are ordered in de-
creasing order. Then

(X) of Eq. (54) is given by

PS
where θ = 1
s

PS
(X) = U λU †, λi = max
{

(cid:80)s

j=1 (xj −

1) and

xi −

θ, 0

,
}

(57)

s = max




k



∈

[1, ..., d] : xk >

1
k

k
(cid:88)

j=1

(xj −




1)



.

(58)

Proof. Any quantum (program) state can be written
in the diagonal form π = V λV † where V is a unitary
matrix, and λ is the vector of eigenvalues in decreasing

0 and (cid:80)

j λj = 1. To ﬁnd the optimal
order, with λj ≥
state, it is required to ﬁnd both the optimal unitary V
and the optimal eigenvalues λ with the above property,
i.e.,

(X) = argmin

V,λ

X
(cid:107)

−

V λV †

(cid:107)2 .

PS

(59)

For any unitarily-invariant norm, the following inequality
holds [58, Eq. IV.64]

(cid:107)

π

λ

−

−

X

(60)

(cid:107)2 ,

x
(cid:107)2 ≥ (cid:107)
with equality when U = V , where X = U xU † is a spec-
tral decomposition of X such that the xj’s are in de-
creasing order. This shows that the optimal unitary in
Eq. (59) is the diagonalization matrix of the operator X.
The eigenvalues of any density operator form a probabil-
ity simplex. The optimal eigenvalues λ are then obtained
thanks to Algorithm 1 from Ref. [17]. (cid:4)

In the following section we present an alternative al-
gorithm with faster convergence rates, but stronger re-
quirements on the function to be optimized.

Conjugate gradient method

The conjugate gradient method [15, 40], sometimes
called the Frank-Wolfe algorithm, has been developed to
provide a better convergence speed and to avoid the pro-
jection step at each iteration. Although the latter can be
explicitly computed for quantum states (thanks to our
Theorem 3), having a faster convergence rate is impor-
tant, especially with higher dimensional Hilbert spaces.
The downside of this method is that it necessarily re-
C.
quires a diﬀerentiable cost function C, with gradient
In its standard form, the conjugate gradient method to
C(π) is deﬁned by

approximate the solution of argminπ
the following iterative rule

∇

∈S

1) Find argminσ
2) πi+1 = πi + 2

∈S
i+2 (σ

Tr[σ

C(πi)],
∇
πi) = i

i+2 πi + 2

i+2 σ.

−

(61)

|

(cid:105)

of

of

∇

∇

σ
|

C(πi),

1) Find the smallest eigenvalue
2) πi+1 = i
i+2 πi + 2
.
σi|

The ﬁrst step in the above iteration rule is solved by
C(πi). Indeed,
ﬁnding the smallest eigenvector
since π is an operator and C(π) a scalar, the gradient
C
is an operator with the same dimension as π. Therefore,
for learning quantum programs we ﬁnd the iteration (17),
that we rewrite below for convenience
σi(cid:105)

σi(cid:105) (cid:104)
When the gradient of C is Lipschitz continuous with con-
stant L, the conjugate gradient method converges after
(L/(cid:15)) steps [16, 42]. The following iteration with adap-
O
tive learning rate αi has even faster convergence rates,
provided that C is strongly convex [57]:
1) Find the smallest eigenvalue
of
σi(cid:105)
|
C(πi)
τi,
2) Find αi = argminα
(cid:104)
∇
2
σi| −
πi,
σi(cid:105)(cid:104)
C, for τi =
|
.
σi|
σi(cid:105) (cid:104)
αi)πi + αi |

+ α2 βC
2 (cid:107)
3) πi+1 = (1

[0,1] α
∈

τi(cid:107)
−

C(πi),

i+2 |

∇
(cid:105)

(63)

(62)

∇

11

∇

where the constant βC and norm

(cid:107) · (cid:107)C depend on C [57].
In spite of the faster convergence rate, conjugate gra-
dient methods require smooth cost functions (so that the
gradient
C is well deﬁned at every point). However,
cost functions based on trace distance (7) are not smooth.
For instance, the trace distance in one-dimensional spaces
that is non-
reduces to the absolute value function
analytic at x = 0. When some eigenvalues are close
to zero, conjugate gradient methods may display unex-
pected behaviors, though we have numerically observed
that convergence is always obtained with a careful choice
In the next section we show how
of the learning rate.
to formally justify the applicability of the conjugate gra-
dient method, following Nesterov’s smoothing prescrip-
tion [42].

x

|

|

Smoothing: smooth trace distance

O

(cid:0) L
(cid:15)

The conjugate gradient method converges to the global
(cid:1) steps, provided that the gradient
optimum after
of C is L-Lipschitz continuous [42]. However, the con-
stant L can diverge for non-smooth functions like the
trace distance (7) so the convergence of the algorithm
cannot be formally stated, although it may still be ob-
served in numerical simulations. To solidify the conver-
gence proof (see also Supplementary Note 5.2), we intro-
duce a smooth approximation to the trace distance. This
is deﬁned by the following cost function that is diﬀeren-
tiable at every point

Cµ(π) = Tr [hµ (χπ −

χ

E

)] =

(cid:88)

j

hµ(λj) ,

(64)

where λj are the eigenvalues of χπ −
so-called Huber penalty function

χ
E

and hµ is the

hµ(x) :=

(cid:40) x2
2µ
x
|

| −

µ
2

if
if

x
|
x
|

< µ ,
µ .

|
| ≤

(65)

The previous deﬁnition of the trace distance, C1 in
Eq. (7), is recovered for µ
0 and, for any non-zero
→
µ, the Cµ bounds C1 as follows

Cµ(π)

C1(π)

≤

≤

Cµ(π) +

µd
2

,

(66)

where d is the dimension of the program state π. In Sup-
plementary Note 5.2 we then prove the following result

Theorem 4. The smooth cost function Cµ(π) is a convex
function over program states and its gradient is given by

Cµ(π) = Λ∗[h(cid:48)µ(χπ −
where h(cid:48)µ is the derivative of hµ. Moreover, the gradient
is L-Lipschitz continuous with

(67)

)],

∇

χ

E

L =

d
µ

,

(68)

where d is the dimension of the program state.

O

Being Lipschitz continuous, the conjugate gradient al-
gorithm and its variants [42, 57] converge up to an ac-
(L/(cid:15)) steps. In some applications, it is
curacy (cid:15) after
desirable to analyze the convergence in trace distance in
the limit of large program states, namely for d
.
→ ∞
The parameter µ can be chosen such that the smooth
trace distance converges to the trace distance, namely
. Indeed, given the inequality (66),
Cµ →
(1+η)) for some η > 0 so
a possibility is to set µ =
O
that, from Eq. (68), the convergence to the trace norm is

C1 for d

→ ∞

(d−

12

achieved after

(d2+η) steps.

O

Acknowledgements.
L.B. acknowledges support
by the program “Rita Levi Montalcini” for young re-
searchers. S.P. and J.P. acknowledge support by the
EPSRC via the ‘UK Quantum Communications Hub’
(Grants EP/M013472/1 and EP/T001011/1) and S.P.
acknowledges support by the European Union via the
project ‘Continuous Variable Quantum Communications’
(CiViQ, no 820466).

[1] M. A. Nielsen and I. L. Chuang, “Programmable quan-
tum gate arrays,” Phys. Rev. Lett. 79, 321 (1997).
[2] M. A. Nielsen and I. L. Chuang, Quantum Computation
and Quantum Information (Cambridge University Press,
Cambridge, 2000).

[3] J. Watrous, The theory of quantum information (Cam-
bridge Univ. Press, 2018) freely available at https://cs.
uwaterloo.ca/~watrous/TQI/.

[4] E. Knill, R. Laﬂamme, and G. J Milburn, “A scheme
for eﬃcient quantum computation with linear optics,”
Nature 409, 46 (2001).

[5] C. M. Bishop, Pattern Recognition and Machine Learning

(Springer, 2006).

[6] P. Wittek, Quantum Machine Learning: What Quantum
Computing Means to Data Mining (Academic Press, El-
sevier, 2014).

[7] J Biamonte, P. Wittek, N. Pancotti, P. Rebentrost,
N. Wiebe, and S. Lloyd, “Quantum machine learning,”
Nature (London) 549, 195 (2017).

[8] V. Dunjko and H. J. Briegel, “Machine learning & ar-
tiﬁcial intelligence in the quantum domain: a review
of recent progress,” Reports on Progress in Physics 81,
074001 (2018).

[9] M. Schuld, I. Sinayskiy, and F. Petruccione, “An intro-
duction to quantum machine learning,” Contemporary
Physics 56, 172–185 (2015).

[10] C. Ciliberto, M. Herbster, Alessandro D.

Ialongo,
M. Pontil, A. Rocchetto, S. Severini, and L. Wossnig,
“Quantum machine learning: a classical perspective,”
Proceedings of the Royal Society A: Mathematical, Phys-
ical and Engineering Sciences 474, 20170551 (2018).
[11] E Tang, “A quantum-inspired classical algorithm for rec-
ommendation systems,” arXiv preprint arXiv:1807.04271
(2018).

[12] E Tang, “Quantum-inspired classical algorithms for prin-
cipal component analysis and supervised clustering,”
arXiv preprint arXiv:1811.00414 (2018).

[13] A. Y. Kitaev, A. Shen, and M. N. Vyalyi, Classical and
quantum computation, 47 (American Mathematical Soci-
ety, Providence, Rhode Island, 2002) sec. 11.

[14] S. Boyd, L. Xiao, and A. Mutapcic, Subgradient methods

(2003).

[15] M. Jaggi, “Convex optimization without projection

steps,” arXiv preprint arXiv:1108.1170 (2011).

[16] M. Jaggi, “Revisiting frank-wolfe: projection-free sparse
convex optimization,” in Proceedings of the 30th Inter-
national Conference on International Conference on Ma-

chine Learning-Volume 28 (JMLR. org, 2013) pp. I–427.
[17] J. Duchi, S. Shalev-Shwartz, Y. Singer, and T. Chan-
dra, “Eﬃcient projections onto the l 1-ball for learning
in high dimensions,” in Proceedings of the 25th interna-
tional conference on Machine learning (ACM, 2008) pp.
272–279.

[18] J. Liu, P. Musialski, P. Wonka,

and J. Ye, “Tensor
completion for estimating missing values in visual data,”
IEEE transactions on pattern analysis and machine in-
telligence 35, 208–220 (2013).

[19] S. Ishizaka and T. Hiroshima, “Asymptotic teleportation
scheme as a universal programmable quantum proces-
sor,” Phys. Rev. Lett. 101, 240501 (2008).

[20] S. Ishizaka and T. Hiroshima, “Quantum teleportation
scheme by selecting one of multiple output ports,” Phys.
Rev. A 79, 042306 (2009).

[21] S. Ishizaka, “Some remarks on port-based teleportation,”

arXiv preprint arXiv:1506.01555 (2015).

[22] S Lloyd, “Universal quantum simulators,” Science , 1073–

1078 (1996).

[23] S. Pirandola, R. Laurenza, C. Ottaviani, and L. Banchi,
“Fundamental limits of repeaterless quantum communi-
cations,” Nat. Commun. 8, 15043 (2017).

[24] S. Pirandola, S. L. Braunstein, R. Laurenza, C. Otta-
and L. Banchi,
viani, T. P. W. Cope, G. Spedalieri,
“Theory of channel simulation and bounds for private
communication,” Quant. Sci. Tech. 3, 035009 (2018).

[25] I. Nechita, Z. Pucha(cid:32)la, (cid:32)L. Pawela, and K.

˙Zyczkowski,
“Almost all quantum channels are equidistant,” J. Math.
Phys. 59, 052201 (2018).

[26] C. A. Fuchs and J. van de Graaf, “Cryptographic distin-
guishability measures for quantum-mechanical states,”
IEEE Trans. Info. Theory 45, 1216–1227 (1999).

[27] M. S. Pinsker, Information and information stability of
random variables and processes (Holden-Day, San Fran-
cisco, 1964).

[28] E. A. Carlen and E. H. Lieb, “Bounds for entanglement
via an extension of strong subadditivity of entropy,” Lett.
Math. Phys. 101, 1–11 (2012).

[29] John Watrous, “Semideﬁnite programs for completely
bounded norms,” Theory OF Computing 5, 217–238
(2009).

[30] John Watrous, “Simpler semideﬁnite programs for com-
pletely bounded norms,” Chicago Journal OF Theoreti-
cal Computer Science 8, 1–19 (2013).

[31] J. Watrous, “Simpler semideﬁnite programs for com-
pletely bounded norms,” Chicago Journal of Theoretical

Computer Science 8, 1–19 (2013).

[32] Lieven Vandenberghe and Stephen Boyd, “Semideﬁnite

programming,” SIAM review 38, 49–95 (1996).

[33] Hsiao-Han Chao, First-Order Methods for Trace Norm
Minimization, Master’s thesis, University of California,
Los Angeles (2013).

[34] Renato DC Monteiro, “First-and second-order methods
for semideﬁnite programming,” Mathematical Program-
ming 97, 209–244 (2003).

[35] James C Spall, “Adaptive stochastic approximation by
the simultaneous perturbation method,” IEEE transac-
tions on automatic control 45, 1839–1853 (2000).

[36] Quntao Zhuang and Zheshen Zhang, “Physical-layer su-
pervised learning assisted by an entangled sensor net-
work,” Physical Review X 9, 041023 (2019).

[37] Aram Harrow and John Napp, “Low-depth gradient
measurements can improve convergence in variational
hybrid quantum-classical algorithms,” arXiv preprint
arXiv:1901.05374 (2019).

[38] Jian-Feng Cai, Emmanuel J Cand`es, and Zuowei Shen,
“A singular value thresholding algorithm for matrix com-
pletion,” SIAM Journal on optimization 20, 1956–1982
(2010).

[39] Benjamin Recht, Maryam Fazel, and Pablo A Parrilo,
“Guaranteed minimum-rank solutions of linear matrix
equations via nuclear norm minimization,” SIAM review
52, 471–501 (2010).

[40] Y. Nesterov, Introductory lectures on convex optimiza-
tion: A basic course, Vol. 87 (Springer Science & Busi-
ness Media, New York, 2013).

[41] B. Coutts, M. Girard, and J. Watrous, “Certifying op-
timality for convex quantum channel optimization prob-
lems,” arXiv preprint arXiv:1810.13295 (2018).

[42] Y. Nesterov, “Smooth minimization of non-smooth func-
tions,” Mathematical programming 103, 127–152 (2005).
[43] The downside of the conjugate gradient method is that
it necessarily requires a diﬀerentiable cost function C,
with gradient ∇C. Speciﬁcally, this may create prob-
lems for the trace distance cost C1 which is generally
non-smooth. A solution to this problem is to deﬁne
the cost function in terms of the smooth trace distance
Cµ(π) = Tr [hµ (χπ − χE )] where hµ is the so-called Hu-
ber penalty function hµ(x) := x2/(2µ) if |x| < µ and
|x| − µ/2 if |x| ≥ µ. This quantity satisﬁes Cµ(π) ≤
C1(π) ≤ Cµ(π) + µd/2 and is a convex function over pro-
gram states, with gradient ∇Cµ(π) = Λ∗[h(cid:48)
µ(χπ − χE )].
[44] N. Khaneja, T. Reiss, C. Kehlet, T. Schulte-Herbr¨uggen,
and S. J. Glaser, “Optimal control of coupled spin dy-
namics: design of nmr pulse sequences by gradient ascent
algorithms,” Journal of magnetic resonance 172, 296–305
(2005).

[45] L. Banchi, N. Pancotti, and S. Bose, “Quantum gate
learning in qubit networks: Toﬀoli gate without time-
dependent control,” npj Quantum Information 2, 16019
(2016).

[46] L.

Innocenti, L. Banchi, A. Ferraro,

S. Bose,
and M. Paternostro, “Supervised learning of time-
independent hamiltonians
for gate design,” arXiv
preprint arXiv:1803.07119 (2018).
[47] K. Mitarai, M. Negoro, M. Kitagawa,

and K. Fu-
jii, “Quantum circuit learning,” Physical Review A 98,
032309 (2018).

13

quantum state via dual classical and einstein-podolsky-
rosen channels,” Phys. Rev. Lett. 70, 1895 (1993).
[49] S. Pirandola, J. Eisert, C. Weedbrook, A. Furusawa, and
S. L. Braunstein, “Advances in quantum teleportation,”
Nat. Photon. 9, 641–652 (2015).

[50] Stefano Pirandola, Riccardo Laurenza, Cosmo Lupo,
and Jason L Pereira, “Fundamental limits to quantum
channel discrimination,” npj Quantum Information 5, 1–
8 (2019).

[51] S. Lloyd, “Almost any quantum logic gate is universal,”

Phys. Rev. Lett. 75, 346 (1995).

[52] For the PQC processor we use the universal Hamil-
2(X ⊗ Y − Y ⊗ X) and H1 =
2Z), where X, Y , and Z

5X) ⊗ (Y +

2Z+

√

√

tonians H0 =
√
√
√
(
are Pauli operators.

3Y +

[53] Giacomo Mauro DAriano and Paolo Perinotti, “Eﬃcient
universal programmable quantum measurements,” Phys-
ical review letters 94, 090401 (2005).

[54] S. Pirandola, B. R. Bardhan, T. Gehring, C. Weedbrook,
and S. Lloyd, “Advances in photonic quantum sensing,”
Nat. Photon. 12, 724–733 (2018).

[55] A. Uhlmann, “The transition probability...” Rep. Math.

Phys. 9, 273–279 (1976).

[56] J. Duchi, E. Hazan, and Y. Singer, “Adaptive subgradi-
ent methods for online learning and stochastic optimiza-
tion,” Journal of Machine Learning Research 12, 2121–
2159 (2011).

[57] D. Garber and E. Hazan, “Faster rates for the frank-wolfe
method over strongly-convex sets,” in Proceedings of the
32nd International Conference on International Confer-
ence on Machine Learning-Volume 37 (JMLR. org, 2015)
pp. 541–549.

[58] R. Bhatia, Matrix analysis, Vol. 169 (Springer Science &

Business Media, New York, 2013).

[59] G. Bowen and S. Bose, “Teleportation as a depolarizing
quantum channel, relative entropy, and classical capac-
ity,” Phys. Rev. Lett. 87, 267901 (2001).

[60] T. P. W. Cope, L. Hetzel, L. Banchi, and S. Pirandola,
“Simulation of non-pauli channels,” Phys. Rev. A 96,
022323 (2017).

[61] C. H. Bennett, D. P. DiVincenzo, J. A. Smolin, and
W. K. Wootters, “Mixed-state entanglement and quan-
tum error correction,” Phys. Rev. A 58, 3824 (1996).
[62] S. Boixo, S. V. Isakov, V. N. Smelyanskiy, R. Babbush,
N. Ding, Z. Jiang, M. J. Bremner, J. M. Martinis, and
H. Neven, “Characterizing quantum supremacy in near-
term devices,” Nat. Phys. 14, 595 (2018).

[63] Seth Lloyd, Masoud Mohseni,

and Patrick Reben-
trost, “Quantum principal component analysis,” Nature
Physics 10, 631 (2014).

[64] E. Stickel, “On the fr´echet derivative of matrix func-
tions,” Linear Algebra and its Applications 91, 83–88
(1987).

[65] S. N. Ravi, M. D. Collins, and V. Singh, “A determinis-
tic nonsmooth frank wolfe algorithm with coreset guar-
antees,” arXiv preprint arXiv:1708.06714 (2017).

[66] F. Youseﬁan, A. Nedi´c,

and U. V. Shanbhag, “On
stochastic gradient and subgradient methods with adap-
tive steplength sequences,” Automatica 48, 56–67 (2012).
[67] G. Lan, “The complexity of large-scale convex program-
ming under a linear optimization oracle,” arXiv preprint
arXiv:1309.5550 (2013).

[48] C. H. Bennett, G. Brassard, C. Cr´epeau, R. Jozsa,
A. Peres, and W. K. Wootters, “Teleporting an unknown

[68] M. Christandl, F. Leditzky, C. Majenz, G. Smith,
and M. Walter, “Asymptotic perfor-

F. Speelman,

mance of port-based teleportation,” arXiv preprint
arXiv:1809.10751 (2018).

14

Supplementary Materials

15

1. MORE ON PROGRAMMABLE SIMULATION

E

As discussed in the main text, the task we are inter-
ested in is the simulation of a channel
using a pro-
grammable quantum processor [1] that we simply call a
“quantum processor” (see Fig. 6). This is represented by
a completely positive trace-preserving (CPTP) universal
map Q as in Eq. (1). Our goal is to ﬁnd the program
state π according to (3), namely the state for which the
simulation
. The most appropriate
deﬁnition of “closeness” between two quantum channels
is via the diamond norm C
2. Re-
(cid:5)
call that the diamond distance is deﬁned by the following
maximization

Eπ is the closest to

(cid:107)E − Eπ(cid:107)(cid:5) ≤

(π) :=

E

(cid:107)E − Eπ(cid:107)(cid:5)

= max

ϕ (cid:107)I ⊗ E

(ϕ)

− I ⊗ Eπ(ϕ)

(cid:107)1 ,

(S1)

(cid:107)

O

(cid:107)1 := Tr√O†O is the trace norm [3]. Because
where
the trace norm is convex over mixed states, one may
reduce the maximization in Eq. (S1) to bipartite pure
states ϕ =
. In general, we therefore need to con-
ϕ
|
sider a min-max optimization, i.e., ﬁnd ˜π and (pure) ˜ϕ
such that

ϕ
|

(cid:105) (cid:104)

(cid:107)I ⊗ E
= min

π

( ˜ϕ)
max

− I ⊗ E˜π( ˜ϕ)
(ϕ)

ϕ (cid:107)I ⊗ E

(cid:107)1
− I ⊗ Eπ(ϕ)

(cid:107)1 .

(S2)

the input state ρ and the program π. We may asso-
ciate to these measurement devices two measurement
channels
is
j
(cid:105)(cid:104)
the probability of getting the outcome j, and similarly

, where pj = Tr[ρΠj]

(ρ) = (cid:80)

j

|

Eπ(ρ) = (cid:80)

j pj|
, where

E
j pπ
j
j |
|
pπ
j = Tr[ρΠπ

(cid:105)(cid:104)

j

j ] = Tr
2

[Qj(ρ

π)] ,

⊗

(S3)

is the probability of getting the outcome j using the
programmable measurement Ππ
j . The above discussion
shows that programmable quantum measurements rep-
resent a particular instance of the general case that we
consider for arbitrary channels, so we may optimize the
program state π with the techniques presented in our
paper.

Note that we may also consider a diﬀerent cost func-
tion, namely the worst-case distance between the two
probability distributions given by

CM (π) = max

ρ

(cid:88)

j

pj −

|

pπ
j |

.

(S4)

Qj}
{

such that Ππ

It was shown in [53] that there exist (ﬁxed) universal
POVMs
j approximates any arbitrary
measurement Πj with an optimal program π. The error
in the approximation, as quantiﬁed by CM , decreases
with the dimension of the program. Via the measurement
channels deﬁned above, it is easy to see that

1.1. Programmable quantum measurements

Programmable quantum measurements [53] represent
a particular instance of the general channel approxima-
tion problem, where the channel approximates a mea-
surement device. Consider a POVM
and a pro-
Πj}
{
Ππ
with program π which is ob-
grammable POVM
j }
{
tained by performing a ﬁxed joint POVM
on both

Qj}
{

CM (π) = max

ρ (cid:107)E

(ρ)

− Eπ(ρ)

(cid:107)1 ≤

C
(cid:5)

(π) ,

(S5)

so that our theory includes the results of [53] as a special
case.

1.2. SDP minimization

We show that some of the convex cost functions that
we have introduced can be explicitly evaluated via semi-
deﬁnite programming (SDP). This allows us to use stan-
dard SDP algorithms for ﬁnding the optimal program.

We ﬁrst ﬁx the program state π and show how for
ﬁxed π it is possible to compute C
(π) via semideﬁnite
(cid:5)
programming. Let us introduce the linear map Ωπ :=
E − Eπ with corresponding Choi matrix
χΩπ = χ

χπ = χ

Λ(π).

(S6)

E −

E −

FIG. 6. Arbitrary quantum channel E and its simulation Eπ
via a quantum processor Q applied to a program state π.

Thanks to the property of strong duality of the diamond
norm, for any program π we can compute the cost func-

Qππ (cid:1)tion C
(cid:5)

(π) =

Ωπ(cid:107)(cid:5)
(cid:107)
1
2

Minimize

via the following SDP [29]

(

Tr2M0(cid:107)∞
(cid:107)
(cid:18) M0

+

Tr2M1(cid:107)∞
(cid:19)

(cid:107)
d χΩπ

) ,

Subject to

−

0,

(S7)

d χ†Ωπ M1
d(cid:48)
0 in Cd

−
0 and M1 ≥
equals the maximum singular value of O.

, and the spectral

≥

×

where M0 ≥
O
norm
(cid:107)∞
(cid:107)

Moreover, because χΩπ is Hermitian, the above SDP

can be simpliﬁed into

Minimize 2

Subject to Z

≥

Tr2Z
(cid:107)
0 and Z

(cid:107)∞
≥

,
d χΩπ .

(S8)

(π),

[25].

does

In fact,

procedure

χ
Tr2 |
(cid:107)

compute C
(cid:5)
(π)

Ωπ , where χ+ = (χ +

Not
only
this
the upper bound C
but
it also provides
≤
(cid:5)
it is suﬃcient to
d
χπ|(cid:107)∞
E −
choose Z = d χ+
)/2 is the
|
positive part of χ. Using Tr2χΩπ = 0, we may write
.
χΩπ |
Tr2Z
The SDP form in Eq. (S8) is particularly convenient for
ﬁnding the optimal program. In fact, suppose now that
π is not ﬁxed but we want to optimize on this state too,
so as to compute the optimal program state ˜π such that
(π). The problem is therefore mapped
˜π = argminπ
into the following unique minimization

Ωπ = d

dTr2χ+

2 Tr2|

χ
|

≤

∈S

C

(cid:5)

Subject to Z

≥

Minimize 2
0, π

Tr2Z
(cid:107)
0, Tr(π) = 1, Z

(cid:107)∞

,

≥

d χΩπ . (S9)

≥

Unlike the min-max optimization of Eq. (S2), the above
SDP is much simpler as it contains a unique minimiza-
tion. Therefore, this algorithm can be used to optimize
the performance of any programmable quantum proces-
sor.

Using a similar argument, and exploiting known con-
vex programming formulations for the trace norm and
the ﬁdelity cost [30, 39], we can also compute the op-
timal program states ˜π as ˜π1 = argminπ
SC1(π) and
˜πF = argmaxπ
SF (π). Note indeed that, clearly, the ﬁ-
∈
delity has to be maximized, rather than minimized. The
optimal program ˜π1 and its associated cost C1(˜π1) can
be computed with the following minimization

∈

minimize Tr[P + Q] ,

(S10)
0, Tr[π] = 1 .

subject to χΩπ = P

Q, P

0, Q

0, π

≥
The optimal program ˜πF and its associated cost F (˜πF )
can be computed with the following maximization

−

≥

≥

(cid:18)χ

maximize
(cid:19)

X
X † χΩπ

E

Tr[X + X †]
2

,

0, π

≥

≥

0, Tr[π] = 1 .

(S11)

subject to

16

per. For example, we may connect the minimization of
the diamond distance C
(π) to the minimization of the
(cid:5)
trace distance C1(π) via the sandwich relation [3]

C1(π)

(π)

C
(cid:5)

≤

≤

d C1(π).

(S12)

While the lower bound is immediate from the deﬁnition
of Eq. (S1), the upper bound can be proven using the
following equivalent form of the diamond distance

d

E −

11)(χ

= sup
ρ0,ρ1

(cid:107)E − Eπ(cid:107)(cid:5)

(√ρ0 ⊗
(cid:107)

χπ)(√ρ1 ⊗

(cid:107)1,
(S13)
where the optimization is carried out over the density
matrices ρ0 and ρ1 [31, Theorem 3.1]. In fact, consider
the Frobenius norm
Tr[A†A] and the spectral
norm

(cid:107)2 :=

A
(cid:107)

11)

(cid:112)

A
(cid:107)

:= max

Au

: u

(cid:107)∞

{(cid:107)
which satisfy the following properties [3]

∈

(cid:107)

(cid:107) ≤

Cd,

u
(cid:107)

ABC
(cid:107)
11
A
(cid:107)

A
(cid:107)1 ≤ (cid:107)
A
=
(cid:107)
(cid:107)∞

⊗

B

(cid:107)1(cid:107)
A

(cid:107)∞(cid:107)
(cid:107)∞ ≤ (cid:107)

C
(cid:107)2.

(cid:107)∞

1

,
}

,

(S14)

(S15)
(S16)

Then, from Eqs. (S13), (S15) and (S16), one gets

(cid:112)

d

E −

E −

(S17)

χπ(cid:107)1

(cid:107)E − Eπ(cid:107)(cid:5) ≤

sup
ρ0,ρ1
χ
= d
(cid:107)

Trρ0Trρ1(cid:107)
χ
χπ(cid:107)1.
Thanks to Eq. (S12), we may avoid the maximization
step in the deﬁnition of the diamond distance and sim-
plify the original problem to approximating the Choi ma-
of the channel by varying the program state π.
trix χ
E
This is a process of learning Choi matrices as depicted
in Fig. 7. Because the simpler cost function C1(π) is
an upper bound, its minimization generally provides a
sub-optimal solution for the program state.

Finally we may consider other cost functions in terms
of any Shatten p-norm Cp(π) :=
χπ(cid:107)p, even
though this option provides lower bounds instead of up-
per bounds for the trace distance. Recall that, given an
operator O and a real number p
1, we may deﬁne its
Schatten p-norm as [3]

χ
(cid:107)

E −

≥

(S18)

O

(cid:107)p = (Tr

O
|

(cid:107)

|
= √O†O. For any 1

p)1/p,

|

where
O
|
has the monotony
O
(cid:107)
of operators A and B, and each pair of parameters p, q
[1,

O
≤
(cid:107)1. An important property is duality. For each pair
∈

p
≤
≤
(cid:107)q, so that
(cid:107)

1 = 1, we may write [3]

≤ ∞
(cid:107)∞ ≤

] such that p−

, one
. . .

(cid:107)p ≥ (cid:107)

1 + q−

q
O

O

(cid:107)

∞

1.3. Cost functions and their relative dependence

A

(cid:107)

(cid:107)p = sup

B

(cid:107)

(cid:107)q≤

1 |(cid:104)

B, A

(cid:105)| ≡

sup
B
(cid:107)q≤

(cid:107)

B, A
(cid:105)

,

1 (cid:104)

(S19)

For completeness, we report here some inequalities be-
tween the diﬀerent cost functions introduced in the pa-

B, A
(cid:105)
(cid:104)

where
= Tr(B†A) is the Hilbert-Schmidt product,
and the second inequality follows since we can arbitrarily
change the sign of B.

17

O

((cid:15)−

1/2). On the other hand, there are no obvi-
rate
ous simpliﬁcations for the optimization of the trace dis-
tance, since the latter still requires the diagonalization of
Eq. (51). For the trace distance, or its smooth version,
only numerical approaches are feasible.

3. APPLICATIONS

3.1. Learning a unitary with the teleportation
processor

Here we consider the following example. Assume that
the target channel is a unitary U , so that its Choi matrix
is χU :=
Φ
χU (cid:105)
χU (cid:105)(cid:104)
(cid:105)
|
|
|
is maximally entangled. By using Eq. (20), the fact that
Λtele = Λ∗tele and U ∗
, we may write
Φ
|
⊗
the dual processor map

and where

χU |

with

= 11

= 11

Φ
|

Φ
|

U †

⊗

⊗

U

11

(cid:105)

(cid:105)

(cid:105)

Λ∗tele[
|
1
d2

=

]
χU |
χU (cid:105)(cid:104)
(cid:88)
(cid:0)11

i

(cid:1)

V U
i

Φ
|

Φ

(cid:105)(cid:104)

|

(cid:0)11

⊗

V U
i

(cid:1)† ,

(S22)

⊗

χU |

where V U
i = UiU U †i . The maximum eigenvector of
] represents the optimal program state ˜πF
χU (cid:105)(cid:104)
Λ∗tele[
|
for simulating the unitary U via the teleportation pro-
cessor (according to the ﬁdelity cost function). In some
cases, the solution is immediate. For instance, this hap-
pens when V U
U is independent of i. This is the case
when U is a teleportation unitary, because it satisﬁes the
Weyl-Heisenberg algebra [23]. For a teleportation uni-
tary U , we simply have
χU (cid:105)(cid:104)
|
so that the unique optimal program is ˜πF =

χU (cid:105)(cid:104)

χU |

χU |

i ∝

Λ∗[

] =

,

|

In Fig. 8 we show the convergence of the projected
subgradient algorithm using the teleportation processor
and target unitaries R(θ) = eiθX , for diﬀerent values of
θ. When θ is a multiple of π/2, then the above unitary
is teleportation covariant and the Frank-Wolfe algorithm
converges to zero trace distance. For other values of θ
perfect simulation is impossible, and we notice that the
algorithm converges to a non zero value of the trace dis-
tance (7). For comparison, in Fig. 8 we also plot the
]2,
value of the ﬁdelity upper bound
where ˜πF is the optimal program that maximizes the ﬁ-
delity of Eq. (9), namely the eigenvector of Eq. (S22) with
the maximum eigenvalue. We note that for θ = π/2(cid:96),
the trace distance decreases for larger θ. The limit case
(cid:96)
is perfectly simulable as R(0) is teleportation
→ ∞
covariant.

F [Λ(˜πF ), χ
E

(cid:112)
1

−

(S23)
.
χU |

χU (cid:105)(cid:104)

|

3.2. Pauli channel simulation

Pauli channels are deﬁned as [2]

(ρ) =

P

(cid:88)

i

piUiρU †i

,

(S24)

FIG. 7. Map of the processor and learning of Choi matri-
ces. Consider an arbitrary (but known) quantum channel E
and its associated Choi matrix χE , generated by propagat-
ing part of a maximally-entangled state Φ. Then, consider a
quantum processor Q with program state π which generates
the simulated channel Eπ and, therefore, the corresponding
Choi matrix χπ := χEπ upon propagating part of Φ as the
input state. The map of the processor is the CPTP map
Λ from the program state π to the output Choi matrix χπ.
In a simpliﬁed version of our problem, we may optimize the
program π in such a way as to minimize the trace distance
C1(π) := (cid:107)χE − χπ(cid:107)1.

2. CONVERGENCE IN LEARNING
ARBITRARY UNITARIES

The simulation of quantum gates or, more generally,
unitary transformations is crucial for quantum comput-
ing applications [22] so ML techniques have been devel-
oped for this purpose [45–47]. In the main text we have
shown that, for learning arbitrary unitaries, the ﬁdelity
cost function provides a convenient choice for which the
optimal program can be found analytically. Indeed, the
optimal program is always a pure state and is given by
χU (cid:105)(cid:104)
the eigenstate of Λ∗ [
] with the maximum eigen-
χU |
|
value. Here we consider the convergence of the Frank-
Wolfe iteration Eq. (17) towards that state.

Let π1 be the initial guess for the program state. After
k iterations of Eq. (17), we ﬁnd the following approxima-
tion to the optimal program state

πk =

2

k + k2 π1 +

(cid:18)

2
k + k2

1

−

(cid:19)

˜πF ,

(S20)

where
πk →

2

k+k2 = (cid:81)k
˜πF for k

1
−
j=1

→ ∞

j
j+2 . The above equation shows that
, with error in trace distance

πk −

(cid:107)

˜πF (cid:107)1 =

2
k + k2 (cid:107)

π1 −

˜πF (cid:107)1 =

O

(k−

2) .

(S21)

This example shows that the convergence rate

1)
of the conjugate method provides a worst case instance
that can be beaten in some applications with some suit-
2
able cost functions. From Eq. (S21) we see that (cid:15) = k−
for learning arbitrary unitaries via the minimization of
CF , meaning that convergence is obtained with the faster

((cid:15)−

O

Q  Φ ℰ𝜋 Φ 𝜒ℰ 𝜒𝜋 ℰ Λ 18

FIG. 9. PBT Simulation of the amplitude damping channel
EAD for various damping rates p. Minimization of the trace
distance C1(EAD, π) = (cid:107)χEAD −χπ(cid:107)1 between the target chan-
nel’s Choi matrix and its PBT simulation with program state
π, for diﬀerent number of ports N . We consider N = 1, 2, 3
and two kinds of programs: copies of the channel’s Choi ma-
trix χ⊗N
and the state ˜π1 obtained from the minimization
EAD
of C1 via the projected subgradient (PS) method after 200
iterations. Note that the simulation error C1 is maximized
for the identity channel (p = 0) and goes to zero for p → 1.

From theory [59–61] we know that only Pauli chan-
nels can be perfectly simulated in this way. No mat-
ter how much more general we make the states π, it is
proven [59, 60] that these are the only channels we can
perfectly simulate. This is true even if we apply the Pauli
corrections in a probabilistic way, i.e., we assume a classi-
cal channel from the Bell outcomes to the corresponding
label of the Pauli correction operator [60].

3.3. PBT: Numerical examples

FIG. 8. Optimization of program states for simulating
the rotation R(θ) = eiθX with a teleportation processor.
The optimization is via the minimization of trace distance
C1 of Eq. (7) with the projected subgradient method in
Eq. (16). The dashed lines correspond to the upper bound
(cid:112)1 − F [Λ(˜πF ), χE ]2 of the trace distance, where ˜πF is the op-
timal program that maximizes the ﬁdelity, namely the eigen-
vector of Λ∗[|χU (cid:105)(cid:104)χU |] with the maximum eigenvalue.

where Ui are generalized Pauli operators and pi are some
probabilities. For d = 2 the Pauli operators are the four
Pauli matrices I, X, Y, Z and in any dimension they form
the Weyl-Heisenberg group [2]. These operators are ex-
actly the teleportation unitaries Uj deﬁned in the previ-
ous section. The Choi matrix χ
is
diagonal in the Bell basis, i.e., we have

of a Pauli channel

P

P

=

χ

P

(cid:88)

i

pi|

Φi(cid:105)(cid:104)

Φi|

,

(S25)

and

Φ
Ui|

where Φi = 11

Φ
(cid:105)
|
We now consider the simulation of a Pauli channel with
the teleportation quantum processor introduced in the
previous section. Let

j=1 |

jj

⊗

(cid:105)

(cid:105)

/√d.

= (cid:80)d

π =

(cid:88)

ij

πij|

Φi(cid:105)(cid:104)

Φj|

,

(S26)

We ﬁrst consider the simulation of an amplitude damp-
i K AD
, which is deﬁned

i ρK AD

ing channel
by the Kraus operators

EAD(ρ) = (cid:80)

†

i

be an arbitrary program state expanded in the Bell ba-
sis. For any program state, the Choi matrix of the
teleportation-simulated channel is given by Eq. (20). Us-
ing standard properties of the Pauli matrices, we ﬁnd

K AD

0 =

(cid:18)1

0
0 √1

−

(cid:19)

p

, K AD

1 =

(cid:19)

(cid:18)0 √p
0
0

.

(S29)

χπ ≡

Λ(π) =

(cid:88)

i

πii|

Φi(cid:105)(cid:104)

Φi|

,

(S27)

namely a generic state is transformed into a Bell diagonal
state. Therefore, the cost function

C Pauli
1

=

χP −
can be minimized analytically for any Pauli channel by
choosing πij = piδij. With this choice we ﬁnd C Pauli
= 0,
meaning that the simulation is perfect.

χπ(cid:107)1 ,

(S28)

(cid:107)

1

In Fig. 9 we study the performance of the PBT simula-
tion of the amplitude damping channel
EAD for diﬀerent
choices of p. For p = 0 the amplitude damping channel
is equal to the identity channel, while for p = 1 it is a
“reset” channel sending all states to
. We compare the
(cid:105)
simulation error with program states π either made by
N
AD as in Eq. (25)
products of the channel’s Choi matrix χ⊗
E
or obtained from the minimization of the trace distance
cost function of Eq. (7) with the projected subgradient
iteration in Eq. (16). Alternative methods, such as the
conjugated gradient algorithm, perform similarly for this

0
|

0.00.20.40.60.8C1(EAD,π)0.00.20.40.60.81.0pChoiN=1ChoiN=2ChoiN=3PS200N=1PS200N=2PS200N=319

FIG. 11. PBT Simulation of the qubit depolarizing chan-
nel versus probability of depolarizing p. Trace distance
C1(Edep, π) = (cid:107)χEdep − χπ(cid:107)1 between the target channel’s
Choi matrix and its PBT simulation with program state π,
for diﬀerent number of ports N . We consider N = 1, 2, 3
and two kinds of programs: copies of the channel’s Choi ma-
trix π = χ⊗N
and the optimal program state ˜π1 obtained
Edep
from the minimization of C1 via the conjugate gradient (CG)
method after 200 iterations. Note that the simulation error
C1 is maximized for the identity channel (p = 0) and even-
tually goes to zero for a ﬁnite value of p that decreases for
increasing N .

≥

≥

pth (cid:39)

p
pth. In Fig. 11 we study the performance of PBT
simulation of the depolarizing channel in terms of p. Per-
0.71 for N = 2
fect simulation is possible for p
≥
and p
pth = 0.5 for N = 3, where the explicit values of
pth are taken from Ref. [50]. For p = 0 the depolarizing
channel is equal to the identity channel, while for p = 1 it
sends all states to the maximally mixed state. Again we
compare the simulation error with program states either
N
composed of copies of the channel’s Choi matrix χ⊗
dep or
E
obtained from the minimization of C1 with the conjugate
gradient method of Eq. (17), which performs signiﬁcantly
better than the projected subgradient for this channel.
Also for the depolarizing channel we observe that, for
any ﬁnite N , we obtain a lower error by optimizing over
N
dep .
the program states instead of the naive choice χ⊗
E

Finally, in Fig. 12 we study the PBT simulation of a
unitary gate Uθ = eiθX for diﬀerent values of θ. Unlike
the previous non-unitary channels, in Fig. 12 we observe
a ﬂat error where diﬀerent unitaries have the same sim-
ulation error of the identity channel θ = 0. This is ex-
pected because both the trace distance and the diamond
distance are invariant under unitary transformations. In
general, we have the following.

Proposition 5. Given a unitary
PBT simulation

U

Uπ with program π we may write

(ρ) = U ρU † and its

min
π ||U − Uπ||(cid:5)

= min

π ||I − Iπ||(cid:5)

,

(S31)

FIG. 10. PBT Simulation of the amplitude damping channel
EAD for various damping rates p. We plot the diamond dis-
tance cost function C(cid:5)(EAD, π) = (cid:107)EAD −EAD,π(cid:107)(cid:5) between the
target channel EAD and its PBT simulation EAD,π with pro-
gram state π. In particular, for the program state we compare
the naive choice of the channel’s Choi matrix π = χ⊗N
(dot-
EAD
ted lines) with the SDP minimization over the set of generic
Choi matrices π = χ⊗N (solid lines). Diﬀerent values of
N = 2, . . . , 6 and N = 20 are shown.

×

N
AD.

channel. We observe that, surprisingly, the optimal pro-
gram ˜π1 obtained by minimizing the trace distance C1 is
always better than the natural choice χ⊗
E

In Fig. 10 we study the PBT simulation of the ampli-
tude damping channel by considering the subset of pro-
N which is made of tensor products of
gram states π = χ⊗
the 4
4 generic Choi matrices χ (satisfying Tr2χ = 11/2).
As discussed in Sec. 6, this is equivalent to optimizing
over the Choi set
CN and it practically reduces to the
convex optimization of the channel ˜Λ over the generic
single-copy Choi matrix χ. Moreover, ˜Λ itself can be
simpliﬁed, as shown in Appendix 6, so that all of the op-
erations depend polynomially on the number N of ports.
This allows us to numerically explore much larger val-
In Fig. 10
.
ues of N , even for the minimization of C
the dotted lines correspond to the value of C
when the
AD is the chan-
program π = χ⊗
E
E
nel’s Choi matrix. As Fig. 10 shows, the cost C
may
be signiﬁcantly smaller with an optimal χ, thus show-
ing that the optimal program may be diﬀerent from the
channel’s Choi matrix, especially when p is far from the
two boundaries p = 0 and p = 1.

N
AD is employed, where χ

(cid:5)

(cid:5)

(cid:5)

As an other example, we consider the simulation of the

depolarizing channel deﬁned by

Edep(ρ) = (1

−

p)ρ +

p
d

11.

(S30)

It was shown in [20, 50] that PBT generates a depolariz-
ing channel, whose depolarizing probability pth depends
on N . This implies that a quantum processor based on
PBT can perfectly simulate a depolarizing channel when

0.00.20.40.60.81.01.2C(cid:5)(EAD,χ⊗N)0.00.20.40.60.81.0pN=2N=3N=4N=5N=6N=200.00.20.40.60.8C1(EDepo,π)0.00.20.40.60.81.0pChoiN=1ChoiN=2ChoiN=3CG200N=1CG200N=2CG200N=320

FIG. 13. PBT Simulation of the identity channel for diﬀerent
number of ports N . For the identity channel the optimal Choi
matrix coincides with the channel’s Choi matrix χI ≡ Φ. The
optimal π has been obtained by minimising C(cid:5) via SDP. The
upper bound corresponds to Eq. (26).

A convenient choice is Uj(θj) = exp(iθjHj), where each
elementary gate corresponds to a Schr¨odinger evolution
with Hamiltonian Hj for a certain time interval θj. For
certain choices of Hj and suitably large N the above cir-
cuit is universal [22], namely any unitary can be obtained
with U (θ) and a suitable choice of θj. The optimal pa-
rameters can be found via numerical algorithms [44], e.g.
.
Tr[U †targetU (θ)]
by minimizing the cost function C(θ) =
|
However, the above cost function is not convex, so the nu-
merical algorithms are not guaranteed to converge to the
global optimum.

|

As a ﬁrst step, we show that the task of learning the
optimal parameters in a PQC can be transformed into
a convex optimization problem by using a quantum pro-
gram. This allows us to use SDP and gradient-based ML
methods to ﬁnd the global optimum solution.

1. Convex reformulation

FIG. 12. PBT Simulation of the unitary gate Uθ = eiθX for
diﬀerent angles θ, where X is the bit-ﬂip Pauli matrix. Trace
distance C1(Uθ, π) = (cid:107)χUθ − χπ(cid:107)1 between the target Choi
matrix of the unitary and its PBT simulation with program
state π, for diﬀerent number of ports N . We consider N =
1, 2, 3 and two kinds of programs: copies of the Choi matrix
of the unitary χ⊗N
and the program state ˜π1 obtained from
Uθ
the minimization of C1 via the projected subgradient (PS)
method after 200 iterations.

where

Iπ is the PBT simulation of the identity channel.

Proof. In fact, we simultaneously prove

min
π ||I − Iπ||(cid:5)

(1)

≤

min
π ||U − Uπ||(cid:5)

(2)

≤

min
π ||I − Iπ||(cid:5)

,

(S32)
1

1

1

−

−

−

−

−

I

U

=

=

1)⊗

Uπ||(cid:5)

Uπ||(cid:5)
(

where (1) comes from the fact that
and

||I − U
U
PBT simulation of the identity
N (π) once

||U −Uπ||(cid:5)
||U
U −
1
Uπ is a possible
−
U
with program state
1 is swapped with the ﬁlter-
I ⊗
ing of the ports; then (2) comes from the fact that the
composition
U ◦ Iπ is a possible simulation of the uni-
N (π) and we have the
tary
U
inequality

. (cid:4)
for diﬀerent values of N is
plotted in Fig. 13 where numerical values are obtained
from SDP, while the upper bound is given by Eq. (26).

||U ◦ I − U ◦ Iπ||(cid:5) ≤ ||I − Iπ||(cid:5)

with program state

The scaling of

||I − Iπ||(cid:5)

I ⊗ U

U

⊗

3.4. Parametric quantum circuits

We now study another design of universal quantum
processor that can simulate any target quantum channel
in the asymptotic limit of an arbitrarily large program
state. This is based on a suitable reformulation of the
PQCs, which are known to simulate any quantum com-
putation with a limited set of quantum gates [22, 51].

A PQC is composed of a sequence of unitary matrices
Uj(θj), each depending on a classical parameter θ. The
resulting unitary operation is then

U (θ) = UN (θN ) . . . U2(θ2)U1(θ1).

(S33)

Consider a program state

composed
θ1, . . . , θN (cid:105)
|
of N registers Rj, each in a separable state
. We
θj(cid:105)
can transform the classical parameters in Eq. (S33) into
quantum parameters via the conditional gates

=

π

(cid:105)

|

|

ˆUj = exp


iHj ⊗

(cid:88)

θj



θj|

θj(cid:105)(cid:104)

 ,

θj|

(S34)

that act non-trivially on systems and registers Rj. If the
parameters θj are continuous, then we can replace the
sum with an integral. With the above gates, we deﬁne

0.00.20.40.60.8C1(Uθ,π)0π2π3π22πθChoiN=1ChoiN=2ChoiN=3PS200N=1PS200N=2PS200N=30.00.40.81.21.62.0C(cid:5)(I,π)48121620Nπ=χ⊗NIbound2d(d−1)N−1optimalπ21

theorem:

(ρA) = TrR0 [U (ρA ⊗

E

θ0)U †],

(S38)

where θ0 belongs to R0, and U acts on system A and
register R0. In Ref. [51] it was shown that two quantum
gates are universal for quantum computation. Speciﬁ-
cally, given U0 = eit0H0 and UB = eit1H1 for ﬁxed times
ti and Hamiltonians Hj, it is possible to write any uni-
tary as

U

≈ · · ·

1 U m3
U m4

0 U m2

1 U m1

0

,

(S39)

for some integers mj. Under suitable conditions, it was
shown that with M = (cid:80)
d) it is possible
j mj =
to approximate any unitary U with a precision (cid:15). More
precisely, the conditions are the following

(d2(cid:15)−

O

FIG. 14. Convex reformulation of a PQC as a coherent pro-
grammable quantum processor that applies a sequence of con-
ditional gates, as in Eq. (S34), depending on the program
state |π(cid:105) = |θ1, . . . , θN (cid:105). The program state is not destroyed
and can be reused.

the parametric quantum channel

Qπ(ρ) = TrR





N
(cid:89)

j=1

ˆUj (ρ

π)

⊗



ˆUj

†

 ,

N
(cid:89)

j=1

i) The Hamiltonians H0 and H1 are generators of the
full Lie algebra, namely H0, H1 and their repeated
commutators generate all the elements of su(d).

(S35)

ii) The eigenvalues of U0 and U1 have phases that are

irrationally related to π.

ψ
whose action on a generic state
(cid:105)
|
=
π
For a pure separable program
(cid:105)
|
tain the standard result, i.e.,

is shown in Fig. 14.
, we ob-
θ1, . . . , θN (cid:105)
|

Q
θ1,...,θN
|

(cid:105)

(ρ) = U (θ)ρU (θ)†,

(S36)

where U (θ) is deﬁned in Eq. (S33). The parametric quan-
tum processor Qπ in Eq. (S35) is capable of simulating
any parametric quantum channel, but it is more general,
as it allows entangled quantum parameters and also pa-
rameters in quantum superposition.

An equivalent measurement-based protocol is obtained
by performing the trace in Eq. (S36) over the basis
θ1, . . . , θN (cid:105)
|
Qπ(θ) =

U (θ)ρU (θ)†

, so that

(cid:88)

π
θ1, . . . , θN |
(cid:104)

,
θ1, . . . , θN (cid:105)
|

(S37)
where U (θ) is deﬁned in Eq. (S33). In this alternative
yet equivalent formulation, at a certain iteration j, the
processor measures the qubit register Rj. Depending
on the measurement outcome θj, the processor then ap-
plies a diﬀerent unitary U (θj) on the system. However,
is destroyed
in this formulation the program state
after each channel use. From Eq. (S37) we note that
Qπ depends on π only via the probability distribution
. As such, any advantage in us-
π
θ1, . . . , θN |
(cid:104)
ing quantum states can only come from the capability of
quantum systems to model computationally hard proba-
bility distributions [62].

θ1, . . . , θN (cid:105)
|

π

(cid:105)

|

θj

{

}

2. Universal channel simulation via PQCs

The decomposition in Eq. (S39) is a particular case of
Eq. (S33) where θj can only take binary values θj = 0, 1.
As such we can write the conditional gates of Eq. (S34)
as in Eq. 29, which is rewritten below

0
(cid:105)j j(cid:104)

+ it1H1 ⊗ |

ˆUj = exp (it0H0 ⊗ |

0
|
for some times tj. Channel simulation is then obtained
by replacing the unitary evolution U of Eq. (S38) with
the approximate form in Eq. (S39) and its simulation in
Eq. (S41). The result is illustrated in Fig. 3 and described
by the following channel

1
(cid:105)j j(cid:104)

) ,
1
|

(S40)

Qπ(ρ) = TrR





N
(cid:89)

j=1

ˆUj A,R0,Rj

(ρA ⊗

π)



ˆUj

†
A,R0,Rj

 ,

N
(cid:89)

j=1

(S41)
where the program state π is deﬁned over R =
(R0, . . . , RN ) and each ˆHj acts on the input system A
and two ancillary qubits R0 and Rj. The decomposition
of Eq. (S39) assures that, with the program

=

π
|

(cid:105)

θ0(cid:105) ⊗ · · · ⊗ |
|

1
(cid:105)

m2

⊗

0

⊗
(cid:105)

⊗ |

m1 ,

(S42)

the product of unitaries approximates U in Eq. (S38)
with precision (cid:15). This is possible in general, provided that
d). However, the
the program state has dimension
channel (S41) is more general, as it allows both quantum
superposition and entanglement.

(d2(cid:15)−

O

The processor map Λ, written in Eq. (30) easily follows
from this construction , while the (non-trace-preserving)
dual channel may be written as
ˆU †AR (XBA ⊗

11R) ˆUAR

.
ΦBA(cid:105)

ΦBA|
(cid:104)

Λ∗(X) =

(S43)

|

The universality of PQCs can be employed for univer-
sal channel simulation, thanks to Stinespring’s dilation

This channel requires 2N quantum gates at each itera-
tion and can be employed for the calculation of gradients,

|ψ(cid:105)U(θ1)U(θ2)U(θ3)U(θ4)U(θ5)|θ1(cid:105)•|θ2(cid:105)•|θ3(cid:105)•|θ4(cid:105)•|θ5(cid:105)•following Theorem 2. When we are interested in simu-
lating a unitary channel U via the quantum ﬁdelity, then
following the results of Section 2, the corresponding op-
]
timal program ˜πF is simply the eigenvector Λ∗[
χU |
χU (cid:105)(cid:104)
|
with the maximum eigenvalue, where
.
Φ
U
= 11
(cid:105)
|
⊗
Note also that Λ∗[

χU (cid:105)(cid:104)
|
χU |BA ⊗

χU |
11R) ˆUAR (

χU (cid:105)
|
] = Z †Z where
ΦBA(cid:105) ⊗
|

Z = (
(cid:104)

(S44)

11R) ,

so the optimal program ˜πF is the principal component of
Z. Since there are quantum algorithms for principal com-
ponent analysis [63], the optimization may be eﬃciently
performed on a quantum computer.

3. Monotonicity by design

Two unitaries are suﬃcient for universality, however
such a design may not be monotonic as a function of N
when simulating a given channel. By adding the iden-
tity as a third possible unitary, as in Eq. (31), we get
a processor that is monotonic by design. Note that the
identity cannot be one of the initial choices of unitaries,
due to the condition that the eigenvalues of U0 and U1
have phases that are irrationally related to π. Because
we want a single program qudit to control the applica-
tion of one of three unitaries, we use qutrits to control
the gates.

Such a design is more powerful than the original de-
sign, because it is guaranteed to both be monotonic as
a function of N , where N is the number of controlled
gates, but also to be able to simulate any channel at
least as well as the original M -gate processor can, for
any M
N . This is because a valid program state for
M ), where
2
the monotonic processor is πM ⊗ |
πM is any program state for the original M -gate proces-
sor. Such a program state would result in the same cost
function that the original processor obtains using πM .

2
(cid:105)(cid:104)

⊗
|

≤

(N

−

Due to having a larger program state space, and more
unitaries to choose from, the N -gate monotonic design
can also potentially perform not just as well as but bet-
ter than any M -gate processor using the original design,
when simulating many channels. This comes at the cost
of higher dimensionality. The number of parameters to
(32N ) for the monotonic
optimise over scales with order
(22N ) for the orig-
processor, whilst it scales with order
inal design.

O

O

3.5. PQC: Numerical examples

As an example we study the simulation of an amplitude
damping channel, with Kraus operators in Eq. (S29). A
possible Stinespring dilation for this channel is obtained
with

=

θ0(cid:105)
|

U =

and

0
(cid:105)
|

0
1
0 √1


0
0

−

0
p √p

−
√p √1
−
0
0


0
0

 = eiHAD,
p 0
1

(S45)

22

FIG. 15. PQC simulation of the amplitude damping channel.
Trace distance C1(EAD, π) = (cid:107)χEAD −χπ(cid:107)1 between the target
channel’s Choi matrix and its PQC simulation with program
state π, for diﬀerent numbers of register qubits N . The opti-
mal program is obtained from the minimization of C1 via the
projected subgradient (PS) method after 200 iterations.

where the Hamiltonian is given by

HAD =

arcsin(√p)
2

(Y

X

X

−

⊗

⊗

Y ),

(S46)

with X and Y being Pauli operators. We may construct
a PQC simulation by taking

U0 = eiα(Y

X

X

Y ),

⊗

−

⊗

(S47)

for some α and taking U1 to be a diﬀerent unitary that
makes the pair U0, U1 universal. Here we may choose
α = √2 and U1 = eiH1 with

H1 = (√2Z + √3Y + √5X)

(Y + √2Z).

(S48)

⊗

Results are shown in Fig. 15. Compared with the sim-
ilar PBT simulation of Fig. 9, we observe that the PQC
simulation (using the non-monotonic design) displays a
non-monotonic behavior as a function of N . PBT with
N pairs requires a register of 2N qubits, while PQC re-
quires N + 1 qubits, namely N qubits for the conditional
gates and an extra auxiliary qubit coming from the Stine-
spring decomposition (see Fig. 3). We observe that, with
a comparable yet ﬁnite register size, PQC can outperform
PBT in simulating the amplitude damping channel. In
Fig. 16 we also study the PQC simulation of the depolar-
izing channel for diﬀerent values of p. Although the gates
U0 and U1 were chosen with inspiration from the Stine-
spring decomposition of the amplitude damping channel,
those gates are universal and capable of simulating other
channels. Indeed, we observe in Fig. 16 that a depolariz-
ing channel is already well simulated with N = 4 for all
values of p.

0.00.20.40.60.8C1(EAD,π)0.00.20.40.60.81.0pPS200N=1PS200N=2PS200N=3PS200N=4PS200N=5PS200N=64.2. Diﬀerential of the quantum ﬁdelity

The quantum ﬁdelity can be expanded as

(cid:113)

√XY √X
(cid:90)

F (X, Y ) = Tr
1
2πi

=

dλ √λTr[(λ11

√XY √X)−

1] ,

−

Γ

23

(S53)

where in the second line we have applied Eq. (S49). Tak-
ing the diﬀerential with respect to Y and using the cyclic
property of the trace we get

F (X, Y )

−

dλ √λTr[(λ11

√XY √X)−

2√XdY √X]

−

Tr[(√XY √X)−

1

2 √XdY √X]

(cid:90)

(1)
=

dY F := F (X, Y + dY )
1
2πi
1
2
1
2

(3)
=

(2)
=

Γ

Tr[√X(√XY √X)−

1

2 √X dY ] ,

(S54)

where in (1) we use Eq. (S51) and the cyclic property of
the trace; in (2) we use Eq. (S50) with f (λ) = √λ, so
f (cid:48)(λ) = 1
1/2; and in (3) we use the cyclic property of
the trace. See also Lemma 11 in [41].

2 λ−

FIG. 16. PQC simulation of the depolarizing channel. Trace
distance C1(EDep, π) = (cid:107)χEDep − χπ(cid:107)1 between the target
channel’s Choi matrix and its PQC simulation with program
state π, for diﬀerent numbers of register qubits N . The opti-
mal program is obtained from the minimization of C1 via the
projected subgradient (PS) method after 200 iterations.

4. MATRIX CALCULUS

4.1. Matrix diﬀerentiation

4.3. Diﬀerential of the trace distance

For a general overview of these techniques, the reader
may consult Ref. [64]. Thanks to Cauchy’s theorem, a
matrix function can be written as

as

f (A) =

1
2πi

(cid:90)

Γ

dλ f (λ)(λ11

A)−

1 .

−

(S49)

The trace norm for a Hermitian operator X is deﬁned

t(X) =

=

X
(cid:107)
1
2πi

Γ

(cid:107)1 := Tr√X †X = Tr[√X 2]
(cid:90)
1] ,
XX)−

dλ √λTr[(λ11

−

(S55)

For the same reason

f (cid:48)(A) =

1
2πi

(cid:90)

Γ

dλ f (λ)(λ11

A)−

2 .

−

(S50)

Applying a basic rule of matrix diﬀerentiation, d(A−

1) =

A−

1(dA)A−

1 we obtain

−

df (A) =

1
2πi

(cid:90)

Γ

dλ f (λ)(λ11

−

A)−

1dA(λ11

−

A)−

1 . (S51)

Clearly, df (A) = f (cid:48)(A)dA only when [A, dA] = 0.
In
general df (A) is a superoperator that depends on A and
is applied to dA. The explicit form is easily computed
using the eigenvalue decomposition or other techniques
[64]. Note that in some cases the expressions are simple.
Indeed, using the cyclic invariance of the trace, we have

dTr[f (A)] = Tr[f (cid:48)(A)dA],

(S52)

j |

λj|

where in the second line we applied Eq. (S49). From
the spectral decomposition X = U λU †, we ﬁnd t(X) =
(cid:80)
, so the trace distance reduces to the absolute
value function for one-dimensional Hilbert spaces. The
is diﬀerentiable at every point,
absolute value function
except λ = 0. Therefore, for any λ
= 0, the subgradient
of the absolute value function is composed of only its
gradient, i.e.

λ
|

|

∂

λ
|

|

=

sign(λ)
}
{

for λ

= 0 .

(S56)

For λ = 0 we can use the deﬁnition (12) to write

z :
{
1

σ
|
z

∂

|λ=0 =
λ

|

zσ for all σ

,

}

| ≥

(S57)

which is true iﬀ

1. Therefore,

|

−

1, 1] .

≤
≤
|λ=0 = [
λ
∂
−
The sign function in (S56) can be extended to λ = 0 in
multiple ways (common choices are sign(0) =
1, 0, 1).
From the above equation, it appears that for any exten-
sion of the sign function, provided that sign(0)
1, 1]
we may write the general form

(S58)

[
−

−

∈

while in general dTr[Bf (A)]

=Tr[Bf (cid:48)(A)dA].

sign(λ)

,

∂

λ
|

|

∈

(S59)

0.00.20.40.60.8C1(EDep,π)0.00.20.40.60.81.0pPS200N=1PS200N=2PS200N=3PS200N=4PS200N=5PS200N=6(cid:54)
(cid:54)
(cid:54)
which is true for any value of λ.

With the same spirit we extend the above argument to
any matrix dimension, starting from the case where X is
an invertible operator (no zero eigenvalues). Taking the
diﬀerential with respect to X we ﬁnd

dt(X) := t(X + dX)

t(X) =

−
dλ √λTr[(λ11

(cid:90)

Γ

(1)
=

(2)
=

1
2πi
1
2

Tr[(X 2)−

1
2 (X(dX) + (dX)X)]

X 2)−

2(X(dX) + (dX)X)]

−

(3)
= Tr[(X 2)−

1
2 X (dX)]

(S60)

where in (1) we use Eq. (S51), the cyclic property of the
trace and the identity dX 2 = X(dX) + (dX)X; in (2)
we use Eq. (S50) with f (λ) = √λ, so f (cid:48)(λ) = 1
1/2;
and in (3) we use the cyclic property of the trace and the
commutation of X and √X 2. Let

2 λ−

X =

(cid:88)

k

λkPk ,

(S61)

be the eigenvalue decomposition of X with eigenvalues
λk and eigenprojectors Pk. For non-zero eigenvalues we
may write

(X 2)−

1
2 X =

(cid:88)

k

and accordingly

sign(λk)Pk =: sign(X) ,

(S62)

dt(X) :=

X + dX
(cid:107)
(cid:88)

(cid:107)1 − (cid:107)
sign(λk)Tr[Pk dX] .

(cid:107)1

X

=

(S63)

k

Therefore, for invertible operators we may write

∂t(X) =

t(X)

,

∇

}

{∇

t(X) = sign(X) .

We now consider the general case where some eigenvalues
of X may be zero. We do this by generalizing Eq. (S59),
namely we show that even if ∂t(X) may contain multiple
∂t, provided that
elements, it is always true that
∈
11. Following (12) we may write, for

sign(X)

∇

11

t

−
ﬁxed X and arbitrary Y ,

≤

≤

Tr[

t(X)(Y

X)]

∇
Tr[

−
t(X)Y ] + t(X)

t(Y )

t(X)

−

−

(1)
= t(Y )

(2)

≥

t(Y )

−

t(X)

−

Tr[Y ] =

−
(cid:88)
(

∇
λj| −
|

j

λj)

0 ,

≥

(S64)

where in (1) we use the property
X
(cid:107)1 = Tr[sign(X)X]
(cid:107)
and in (2) we use the assumption
11.
sign(X)
11
−
From the deﬁnition of the subgradient (12), the above
equation shows that sign(X)
∂t(X), so we may always
∈
use
t(X) = sign(X) in the projected subgradient algo-
∇
rithm (16).

≤

≤

24

5. SMOOTHING TECHNIQUES

5.1. Stochastic smoothing

The conjugate gradient algorithm converges after
(c/(cid:15)) steps [15, 16], where (cid:15) is the desired precision and
O
c is a curvature constant that depends on the function.
However, it is known that c could diverge for non-smooth
functions. This is the case for the trace norm, as shown
in Example 0.1 in [65].

A general solution, valid for arbitrary functions,

is
In this approach the non-

stochastic smoothing [66].
smooth function C(π) is replaced by the average

Cη(π) = Eσ[C(π + ησ)] .

(S65)

where σ is such that
M

, then

x

y

(cid:107)

−

(cid:107)∞

σ
(cid:107)

(cid:107)∞ ≤

1.

If

C(x)
|

−

C(y)

| ≤

(S66)

C(π)

Cη(π)

C(π) + M η ,

≤

≤
so that Cη(π) provides a good approximation for C(π).
Moreover, Cη is diﬀerentiable at any point, so we may
apply the conjugate gradient algorithm. A modiﬁed con-
jugate gradient algorithm with adaptive stochastic ap-
proximation was presented in Ref. [67]. At each iteration
k the algorithm reads

k−

(cid:80)k

1/2,

k+2 |

of ¯gk,

j=1 g(πk + ηkσj) for ηk ∝
σk(cid:105)
|
.

1) Sample some operators σ1, . . . , σk,
2) Evaluate ¯gk = 1
k
3) Find the smallest eigenvalue
k+2 πk + 2
4) πk+1 = k
σk|
σk(cid:105) (cid:104)
where g denotes any element of the subgradient ∂C. The
((cid:15)2) iterations. Since
above algorithm converges after
Eqs. (45) and (43) provide an element of the subgradi-
ent, the above algorithm can be applied to both ﬁdelity
and trace distance. However, this algorithm requires k
evaluations of the subgradient to perform the averages,
so it may be impractical when the number of iterations
get larger. In the following we study an alternative that
does not require any average.

O

5.2. Nesterov’s smoothing

An alternative smoothing scheme is based on Nes-
terov’s dual formulation [42]. Suppose that the non-
smooth objective function f admits a dual representation
as follows

[
f (x) = sup

y

x, y
(cid:104)

(cid:105) −

g(y)],

(S67)

for some inner product
. Nesterov’s approximation
·(cid:105)
consists of adding a strongly convex function d to the
dual

,
(cid:104)·

fµ(x) =

(cid:88)
[

y

x, y
(cid:104)

(cid:105) −

g(y)

−

µd(y)].

(S68)

(cid:104)

Y, X
(cid:104)

(cid:105) −

(cid:105)

µ
2 (cid:107)

Y

2
2
(cid:107)

∇

tµ(X) = argmax
1
(cid:107)
≤
= argmin
Y

∞

Y

(cid:107)

∞

(cid:107)

(cid:107)

≤

µY

1 (cid:107)

X

2
2 = U ΣµV †,
(cid:107)

−

showing the convexity. (cid:4)

The resulting µ-approximation is smooth and satisﬁes

fµ(x)

f (x)

≤

≤

fµ(x) + µ sup

y

d(y).

(S69)

The trace norm admits the dual representation [3]

t(X) =

X
(cid:107)

(cid:107)1 = sup

Y

∞

1(cid:104)

Y, X

,
(cid:105)

(S70)

(cid:107)

(cid:107)

Y, X
(cid:104)

≤
where
is the Hilbert Schmidt product. This can
be regularized with any strongly convex function d. A
convenient choice [18] that enables an analytic solution
is d(X) = 1

X, X

X

(cid:105)

2 := 1
2
2 (cid:104)

(cid:107)

2 (cid:107)

, so
(cid:105)

(cid:104)

tµ(X) = max
≤

∞

Y

(cid:107)

(cid:107)

1

Y, X
(cid:104)

(cid:105) −

µ
2 (cid:107)

Y

2
2
(cid:107)

(cid:105)

.

(S71)

This function is smooth and its gradient is given by [18]

where X = U ΣV † is the singular value decomposition
of X and Σµ is a diagonal matrix with diagonal entries
. Plugging this into Eq. (S71) we
(Σµ)i = min
}
get

Σi/µ, 1
{

tµ(X) = Tr

(cid:104)

Σµ

(cid:16)

Σ

(cid:17)(cid:105)

.

Σµ

µ
2

−

(S72)

For a diagonalizable matrix X with spectral decompo-
sition X = U λU †, the singular value decomposition is
obtained with Σ =
Inserting
these expressions in (S72) we ﬁnd

and V = U sign(λ).

λ
|

|

tµ(X) =

(cid:88)

j

hµ(λj) = Tr[hµ(X)],

(S73)

hµ(x) =

where hµ is the so called Huber penalty function
(cid:40) x2
2µ
x
|
tµ is then h(cid:48)µ(X)
(cid:40) x
µ
sign(x)

x
|
x
|
U h(cid:48)(λ)U †, where

The gradient

< µ,
µ.

< µ,
µ.

h(cid:48)µ(x) =

|
| ≥

if
if

if
if

| −

∇

≡

µ
2

x
|
x
|

|
| ≥

(S74)

(S75)

We then ﬁnd that, via the smooth trace norm tµ, we
can deﬁne the smooth trace distance of Eq. (64) that is
diﬀerentiable at every point

Cµ(π) = Tr [hµ (χπ −

χ
E

)] .

(S76)

Thanks to the inequalities in (S69), the smooth trace
distance bounds the cost C1 as

Cµ(π)

C1(π)

≤

≤

Cµ(π) +

µd
2

,

(S77)

where we employed the identity sup
get the upper bound. Moreover, we ﬁnd the following

Y
1 (cid:107)

(cid:107)

≤

∞

Y

(cid:107)

(cid:107)

2
2 ≤

d to

25

Lemma 6. The smooth trace distance, deﬁned in
Eq. (64), is a convex function of π.

Proof. From the deﬁnition and Eq. (S71) we ﬁnd

Cµ(π) = tµ [Λ(π)
−
(cid:104)

= max
Y
∞
≤

(cid:107)

(cid:107)

1

]

χ
E
Y, Λ(π)
(cid:104)

χ

E (cid:105) −

−

µ
2 (cid:107)

Y

2
2

(cid:107)

(cid:105)

.

(S78)

Now for ¯π = pπ1 + (1
χ
Y, Λ(¯π)
(cid:104)

E (cid:105)

−

= pf (π1) + (1

−

−

p)π2 linearity implies f (¯π) :=
p)f (π2). Therefore

(cid:104)

pf (π1) + (1

Y, Λ(π1)
(cid:104)

1

Y

∞

(cid:104)

Cµ(¯π) = max
(cid:107)
(cid:107)
≤
p max
Y
∞
(cid:107)
≤
p) max
Z
∞
≤
(cid:107)
= pCµ(π1) + (1

(cid:107)
+ (1

−

≤

(cid:107)

1

(cid:104)
Z, Λ(π2)
(cid:104)
p)Cµ(π2),

1

−

p)f (π2)

−

−

χ

−

E (cid:105) −

µ
2 (cid:107)

Y

χ

−

E (cid:105) −

Y

(cid:105)

2
2
(cid:107)

µ
2 (cid:107)
(cid:105)

2
2
(cid:107)
µ
2 (cid:107)

Z

(cid:105)

2
2
(cid:107)
(S79)

Then, using the deﬁnitions from [42], the following the-

orem bounds the growth of the gradient

Theorem 7. The gradient of the smooth trace norm is
Lipschitz continuous with Lipschitz constant

L =

d
µ

.

(S80)

In particular, if the gradient is Lipschitz continuous,
the smooth trace norm satisﬁes the following inequality
for any state π, σ

Cµ(σ)

≤

Cµ(π) +

Cµ(π), σ

(cid:104)∇

π

(cid:105)

−

+

L
2 (cid:107)

σ

π

2
2. (S81)
(cid:107)

−

Proof. Given the linearity of the quantum channel Λ, we
can apply theorem 1 from [42] to ﬁnd

L =

1
µ

x

(cid:107)

(cid:107)

sup
y

2=1,

(cid:107)

y, Λ(x)
(cid:105)

.

2=1(cid:104)

(cid:107)

(S82)

Since all eigenvalues of y are less than or equal to 1, we
can write y

1 and as such

≤

L

≤

1
µ

(cid:107)

sup
x

2=1

(cid:107)

Tr[Λ(x)] =

1
µ

(cid:107)

sup
x

2=1

(cid:107)

Tr[x]

d
µ

.

≤

(S83)

(cid:4)

6. PBT: PROGRAM STATE COMPRESSION

The dimension of the program state grows exponen-
tially with the number of ports N as d2N where d is
the dimension of the Hilbert space. However, as also
discussed in the original proposal [19, 20] and more re-
cently in Ref. [68], the resource state of PBT can be cho-
sen with extra symmetries, so as to reduce the number

of free parameters. In particular, we may consider the
set of program states that are symmetric under the ex-
change of ports, i.e., such that rearranging any A modes
and the corresponding B modes leaves the program state
unchanged.

Let Ps be the permutation operator swapping labels 1
to N for the labels in the sequence s, which contains all
the numbers 1 to N once each in some permuted order.
Namely Ps exchanges all ports according to the rule i
(cid:55)→
si. Since PBT is symmetric under exchange of ports, we
may write

PPsπP †

s

(ρ) =

Pπ (ρ) for any s.

(S84)

Consider then an arbitrary permutation-symmetric re-
source state πsym as

πsym =

1
N !

(cid:88)

s

PsπP †s ,

where the sum is over all possible sequences s that deﬁne
independent permutations and N ! is the total number
of possible permutations. Clearly
Pπ, so any
program state gives the same PBT channel as some sym-
metric program state. It therefore suﬃces to consider the
set of symmetric program states. This is a convex set:
any linear combination of symmetric states is a symmet-
ric state.

Pπsym =

|

x

To construct a basis of the symmetric space, we note
that each element of a density matrix is the coeﬃcient
of a dyadic (of the form
). If permutation of labels
y
|
(cid:105) (cid:104)
maps one dyadic to another, the coeﬃcients must be the
same. This allows us to constrain our density matrix
using fewer global parameters. For instance, for d = 2 we
can deﬁne the 16 parameters n00,00, n00,01, n00,10, etc.,
corresponding to the number of ports in the dyadic of the
form
, etc.
Each element of a symmetric density matrix can then
be deﬁned solely in terms of these parameters, i.e., all
elements corresponding to dyadics with the same values
of these parameters have the same value.

0A0B(cid:105) (cid:104)
|

0A0B(cid:105) (cid:104)
|

0A0B(cid:105) (cid:104)

,
0A0B|

1A0B|

0A1B|

,

|

cA, dB|

aA, bB(cid:105)(cid:104)
|

For the general qudit case, in which our program state
consists of N ports, each composed of two d-dimensional
qudits, we can ﬁnd the number of independent parame-
ters from the number of independent dyadics. Each port
in a dyadic can be written as
where the
extra indices A and B describe whether those states are
modeling either qudit A or B. There are d4 diﬀerent
combinations of
, so we can place each qudit
a, b, c, d
}
{
into one of d4 categories based on these values. If two el-
ements in the density matrix correspond to dyadics with
the same number of ports in each category, they must
take the same value. Hence, the number of independent
coeﬃcients is given by the number of ways of placing
N (identical) ports into d4 (distinguishable) categories.
This is exactly the binomial coeﬃcient

26

Consequently, exploiting permutation symmetry of the
PBT protocol, we can exponentially reduce the number
of parameters for the optimization over program states.
The number of parameters can be reduced even further
by considering products of Choi matrices. We may focus
indeed on the Choi set, ﬁrst deﬁned in Eq. (28),

(cid:40)

CN =

π : π =

(cid:41)

N

pkχ⊗
k

,

(cid:88)

k

(S86)

where each χk = χk
AB is a generic Choi matrix, therefore
111, and pk form a probability dis-
satisfying TrBχk = d−
tribution. Clearly
is a convex set. We now show that
this set can be further reduced to just considering N = 1.
N is directly used in

When the program state π = χ⊗

C

the PBT protocol we ﬁnd

Λ(π) =

N
(cid:88)

i=1

TrA ¯BiC

(cid:2)Πi

(cid:0)χ⊗

N
AB ⊗

ΦDC

(cid:1)(cid:3)

Bi

Bout

→

(S87)

=

1
dN

−

1

N
(cid:88)

i=1

:= ˜Λ(χ) ,

TrAiC [Πi (χAiBout ⊗

ΦDC)]

(S88)

(S89)

namely that the optimization can be reduced to the
(d4) dimensional space of Choi matrices χ. Note that,

O
in the above equation, we used the identity

N

Tr ¯Biχ⊗

AB = χAiBi ⊗

11 ¯Ai
dN

−

1 ,

(S90)

where ¯Ai = A

Ai.

\

Now let π be a linear combination of tensor products
, each with probability pk as

of Choi matrix states, χ⊗
k
in Eq. (S86). Then we can write

N

Tr ¯BiπAB = Tr ¯Bi

(cid:88)

N

pkχ⊗
k

k
(cid:18)

χk

AiBi ⊗

(cid:88)

=

pk

k

(S91)

(S92)

(cid:19)

.

11 ¯Ai
1
dN

−

N of some other Choi matrix χ(cid:48) = (cid:80)

However, this is precisely the partial trace over the tensor
k pkχk.
product χ(cid:48)⊗
Hence, the program state π = (cid:80)
simulates the
same channel as the resource state π(cid:48) = ((cid:80)
k pkχk)⊗

N .
CN can
be reduced to the optimization over products of Choi ma-
N . From Eq. (S89) this can be further reduced
trices χ⊗
to the optimization of the quantum channel ˜Λ over the
convex set of single-copy Choi matrices χ

Therefore, the optimization over the convex set

k pkχ⊗
k

N

C1 =

π : π = χAB, TrBχAB = 11/2
}

{

,

(S93)

(d4). Using

which is
C1 drastically reduces the diﬃculty
of numerical simulations, thus allowing the exploration of
signiﬁcantly larger values of N .

O

(cid:19)
1

(cid:18)N + d4
d4

−

−
1

(N d4

1) .

−

=

O

(S85)

Finally, we provide an explicit expression for the re-
duced map ˜Λ of Eq. (S89) in the case of qubits. For d = 2

we can rewrite PBT in a language that can be more easily
formulated from representations of SU(2). For simplicity
of notation, here we do not use bold letters for vectorial
quantities. Let us modify the POVM in Eq. (21) as

Substituting the deﬁnition of Stot, we ﬁnd two classes

of eigenvalues

λ+(sA) =

2sA

N

−
4

, λ−(sA) =

N + 2sA + 2
4

,

(S102)

27

1/2

˜Πi = σ−
AC Ψ−AiCσ−
N
(cid:88)

1/2
AC ,

σAC =

Ψ−AiC,

i=1
Πi = ˜Πi + ∆,

∆ =



11

1
N

(cid:88)

−

j



˜Πj

 ,

(S94)

with corresponding eigenvectors

(cid:88)

1

(cid:105)

=

, sA, M, α

ΓM,m,k
sA
|±
±
N +1
2 , α = 1, . . . , g[N ](s) describes
where
the degeneracy, g[N ](s) is the size of the degenerate sub-
space, and

k
2 ,sA |

sA, m, α

(S103)

(cid:105)A ,

2 ≤

(cid:105)C|

N +1

k,m

M

≤

−

(S95)

(S96)

(S97)

ΓM,m,k
S,s

=

(cid:104)
are Clebsch-Gordan coeﬃcients.

S, M ; s, 1/2
|

1/2, 1/2

k; s, m
(cid:105)

−

(S104)

Note that

the Clebsch-Gordan coeﬃcients deﬁne
two bases
. From the orthogonal-

a unitary transformation between the
S, M ; s1, s2(cid:105)
s1, m1; s2; m2(cid:105)
|
|
ity relations, of these coeﬃcients we ﬁnd the equalities

and

)/√2 is a singlet state. For
Ψ−
where
(cid:105)
|
n the quantum channel is simpliﬁed.
π = χ⊗
In fact,
since TrB χ = 11/2, we may write

01
= (
|

(cid:105) − |

10

(cid:105)

Pπ =

=

N
(cid:88)

i=1
(cid:88)

(cid:96)

1
2N

−

1 TrAC

(cid:104)(cid:112)

Πi

K 0
(cid:96) (ρC ⊗

χ)K 0

(cid:96) † +

(cid:0)ρC ⊗
χAiB ⊗
K 1
(cid:96) (ρC ⊗

(cid:88)

(cid:96)(cid:48)

(cid:1) (cid:112)

(cid:105)

Πi

11 ¯Ai

χ)K 1

(cid:96) †, (S98)

(cid:88)

S,s ΓM,m(cid:48),i(cid:48)
ΓM,m,i

S,s

= δi,i(cid:48)δm,m(cid:48),

S,M
(cid:88)

m,i

S,s ΓM (cid:48),m,i
ΓM,m,i

S(cid:48),s = δM,M (cid:48)δ(S, S(cid:48), s),

(S105)

(S106)

where (cid:96) and (cid:96)(cid:48) are multi-indices and,
in deﬁning the
Kraus operators, we have separated the contributions
from ˜Πi and ∆ (see below).

In order to express these operators, we write

ψ−CAi(cid:105)(cid:104)
|

ψ−CAi|

=

11

−

(cid:126)σC ·
4

(cid:126)σAi

,

(S99)

so that

σAC =

N
(cid:88)

i=1

ψ−CAi(cid:105)(cid:104)
|
(cid:126)S2
tot −

ψ−CAi|
(cid:126)S2
C −
2

=

N
4 −

=

N
4 −

(cid:126)SC ·

(cid:126)SA

(cid:126)S2
A

,

(S100)

where (cid:126)S = (cid:126)σ/2 is a vector of spin operators, (cid:126)SA =
(cid:80)
(cid:126)SAj and (cid:126)Stot = (cid:126)SC + (cid:126)SA. The eigenvalues of σAC
j
are then obtained from the eigenvalues of the three com-
muting Casimir operators

λ(sA) =

N
4 −

Stot(Stot + 1)

−

sA(sA + 1)
2

−

3/4

,

(S101)

where Stot = sA ±

1/2.

where δ(S, S(cid:48), s) = 1 iﬀ S = S(cid:48) and
≤
s + 1/2. The eigenvalues in Eq. (S102) are zero iﬀ
Stot = SA + 1/2 and SA = N/2. These eigenvalues have
degeneracy 2Stot + 1 = N + 2 and the corresponding
eigenvectors are

| ≤

1/2

s
|

−

S

+, N/2, M, α
|
Thus, the operator ∆ from Eq. (S97) may be written as

, M, α

(S107)

| ⊥

=

(cid:105)

(cid:105)

.

∆ =

1
N

N +1

2(cid:88)

(cid:88)

M =

−

N +1
2

α

, M, α

| ⊥

, M, α

.

|

(cid:105)(cid:104)⊥

(S108)

To ﬁnish the calculation we need to perform the partial
trace over all spins except those in port i. We use s ¯Ai,
m ¯Ai and αi to model the state of the total spin in ports
Aj with j
= i. These refer to the value of total spin and
the projection along the z axis, as well as the degeneracy.
A and Sz
Moreover, since S ¯Ai commutes with both S2
A,
we may select a basis for the degeneracy that explicitly
contains s ¯Ai. We may write then α = (s ¯Ai, ˜αi) where ˜αi
represents some other degrees of freedom.

With the above deﬁnitions, when we insert several res-
olutions of the identity in Eq. (S98), we may write the
Kraus operators as

(cid:54)
K 0

i,s ¯Ai

,m ¯Ai

,αi,s(cid:48)

¯Ai

,m(cid:48)

¯Ai

,α(cid:48)
i

= 2−

N −1
2

= 2−

N −1
2

s ¯Ai , m ¯Ai, αi| ⊗ (cid:104)
(cid:104)
(cid:88)
(sA)−
λ

,sA,M,α

±

ψ−AiC|

1/2

(cid:104)

1/2
σ−
AC |
ψ−AiC|(cid:104)

s(cid:48)¯Ai

, m(cid:48)¯Ai

, α(cid:48)i(cid:105)
s ¯Ai, m ¯Ai, αi|±

, sA, M, α

K 1

i,M,α,s(cid:48)

,m(cid:48)

¯Ai

,α(cid:48)
i

= 2−

¯Ai

1/2

+, N/2, M, α
(cid:104)

|

s(cid:48)¯Ai

, m(cid:48)¯Ai

,
, α(cid:48)i(cid:105)

N −1

±
2 N −

28

, sA, M, α

s(cid:48)¯Ai
|

, m(cid:48)¯Ai

,
, α(cid:48)i(cid:105)

(cid:105)(cid:104)±

(S109)

where each set of states
s ¯Ai , m ¯Ai, αi(cid:105)
|
of the space corresponding to all ports j with j
simplify the Kraus operators we study the overlap

represents a basis
= i. To

provide exactly the same operation and, accordingly, we
can sum over these equivalent Kraus operators to reduce
the number of indices. After this process, we get

s¯ı, m¯ı, αi|±
(cid:104)
(cid:88)
k
=
(cid:105)C(cid:104)
|

, S, M, α
(cid:105)
s¯ı, m¯ı, αi|

ΓM,m,k
2 ,S|
S
±

1

S, m, α

k,m
(cid:88)

k,m
(cid:88)

k,(cid:96),m

=

=

k
|

(cid:105)C(cid:104)

k
|

(cid:105)C|

s¯ı, m¯ı, αi|
(cid:105)AiΓM,m,k
(cid:96)

S

1

±

ΓM,m,k
1
2 ,S
S
±

(cid:88)

|

(cid:96)

2 ,SΓm,m¯ı,(cid:96)

S,s¯ı ≡

(cid:96)
(cid:105)i|

(cid:105)A
s(cid:48)¯ı, m(cid:48)¯ı, α(cid:48)i(cid:105)¯ıΓm,m(cid:48)
ˆQs¯ı,m¯ı
±

,s,M .

S,s(cid:48)
¯ı

¯ı,k

(S110)

(cid:113)

(sA)−

1/2

λ

±

g[N

1](s¯ı)

−

×

,sA,M

±
ˆQs¯ı,m¯ı
±

,sA,M

ˆQs¯ı,m(cid:48)

¯ı
,sA,M †

±

(cid:17)

11B,

⊗

K 0

(cid:96) ≡

K 0

s¯ı,m¯ı,m(cid:48)
¯ı

= 2−

N −1

2 √N

(cid:88)

(cid:16)

ψ−AC|
(cid:104)
K 1
(cid:114)

g[N

M,s¯ı,m¯ı

×

K 1

(cid:96) ≡

=

1](s¯ı)
1

−

−
2N

ˆQs¯ı,m(cid:48)

¯ı
+,N/2,M †

11B.

⊗

(S111)

(S112)

In the last line we ﬁnd that the overlap is independent
of α and αi, though with constraints α = (s¯ı, αi), which
requires αi = α(cid:48)i. Therefore, diﬀerent Kraus operators

The Kraus operators of the reduced channel ˜Λ are ob-
tained as (K u
11AB). It is simple to check
that the above operators deﬁne a CPTP-map.

Ψ−CD(cid:105) ⊗
|

11D)(

(cid:96) ⊗

(cid:54)
