0
2
0
2

y
a
M
9
1

]
h
p
-
t
n
a
u
q
[

2
v
6
1
3
1
0
.
5
0
9
1
:
v
i
X
r
a

Convex optimization of programmable quantum computers

Leonardo Banchi,1, 2,

âˆ— Jason Pereira,3 Seth Lloyd,4, 5 and Stefano Pirandola3, 5

1Department of Physics and Astronomy, University of Florence,
via G. Sansone 1, I-50019 Sesto Fiorentino (FI), Italy
2INFN Sezione di Firenze, via G.Sansone 1, I-50019 Sesto Fiorentino (FI), Italy
3Department of Computer Science, University of York, York YO10 5GH, UK
4Department of Mechanical Engineering, Massachusetts Institute of Technology (MIT), Cambridge MA 02139, USA
5Research Laboratory of Electronics, Massachusetts Institute of Technology (MIT), Cambridge MA 02139, USA

A fundamental model of quantum computation is the programmable quantum gate array. This
is a quantum processor which is fed by a â€œprogramâ€ state that induces a corresponding quantum
operation on input states. While being programmable, any ï¬nite-dimensional design of this model
is known to be non-universal, meaning that the processor cannot perfectly simulate an arbitrary
quantum channel over the input. Characterizing how close the simulation is and ï¬nding the optimal
program state have been open questions for the last 20 years. Here we answer these questions by
showing that the search for the optimal program state is a convex optimization problem that can be
solved via semideï¬nite programming and gradient-based methods commonly employed for machine
learning. We apply this general result to diï¬€erent types of processors, from a shallow design based
on quantum teleportation, to deeper schemes relying on port-based teleportation and parametric
quantum circuits.

INTRODUCTION

Back in 1997 a seminal work by Nielsen and Chuang [1]
proposed a quantum version of the programmable gate
array that has become a fundamental model for quan-
tum computation [2]. This is a quantum processor where
a ï¬xed quantum operation is applied to an input state
together with a program state. The aim of the program
state is to induce the processor to apply some target
quantum gate or channel [3] to the input state. Such a de-
sired feature of quantum programmability comes with a
cost: The model cannot be universal, unless the program
state is allowed to have an inï¬nite dimension, i.e., inï¬-
nite qubits [1, 4]. Even though this limitation has been
known for many years, there is still no exact character-
ization on how well a ï¬nite-dimensional programmable
quantum processor can generate or simulate an arbitrary
quantum channel. Also there is no literature on how to
ï¬nd the corresponding optimal program state or even to
show that this state can indeed be found by some opti-
mization procedure. Here we show the solutions to these
long-standing open problems.

Here we show that the optimization of programmable
quantum computers is a convex problem for which the so-
lution can always be found by means of classical semidef-
inite programming (SDP) and classical gradient-based
methods that are commonly employed for machine learn-
ing applications. Machine learning (ML) methods have
found wide applicability across many disciplines [5], and
we are currently witnessing the development of new hy-
brid areas of investigation where ML methods are in-
terconnected with quantum information theory, such as
quantum-enhanced machine learning [6â€“10] (e.g., quan-
tum neural networks, quantum annealing etc.), protocols

âˆ— leonardo.banchi@uniï¬.it

of quantum-inspired machine learning (e.g., for recom-
mendation systems [11] or component analysis and su-
pervised clustering [12]) and classical learning methods
applied to quantum computers, as explored here in this
manuscript.

In our work, we quantify the error between an arbi-
trary target channel and its programmable simulation in
terms of the diamond distance [3, 13] and other suitable
cost functions, including the trace distance and the quan-
tum ï¬delity. For all the considered cost functions, we
are able to show that the minimization of the simulation
error is a convex optimization problem in the space of
the program states. This already solves an outstanding
problem which aï¬€ects various models of quantum com-
puters (e.g., variational quantum circuits) where the op-
timization over classical parameters is non-convex and
therefore not guaranteed to converge to a global opti-
mum. By contrast, because our problem is proven to
be convex, we can use SDP to minimize the diamond
distance and always ï¬nd the optimal program state for
the simulation of a target channel, therefore optimiz-
ing the programmable quantum processor. Similarly, we
may ï¬nd suboptimal solutions by minimizing the trace
distance or the quantum ï¬delity by means of gradient-
based techniques adapted from the ML literature, such
as the projected subgradient method [14] and the conju-
gate gradient method [15, 16]. We note indeed that the
minimization of the (cid:96)1-norm, mathematically related to
the quantum trace distance, is widely employed in many
ML tasks [17, 18], so many of those techniques can be
adapted for learning program states.

With these general results in our hands, we ï¬rst discuss
the optimal learning of arbitrary unitaries with a generic
programmable quantum processor. Then, we consider
speciï¬c designs of the processor, from a shallow scheme
based on the teleportation protocol, to higher-depth de-
signs based on port-based teleportation (PBT) [19â€“21]

 
 
 
 
 
 
and parametric quantum circuits (PQCs) [22], introduc-
ing a suitable convex reformulation of the latter. In the
various cases, we benchmark the processors for the simu-
lation of basic unitary gates (qubit rotations) and var-
ious basic channels,
including the amplitude damping
channel which is known to be the most diï¬ƒcult to sim-
ulate [23, 24]. For the deeper designs, we ï¬nd that the
optimal program states do not correspond to the Choi
matrices of the target channels, which is rather counter-
intuitive and unexpected.

RESULTS

We ï¬rst present our main theoretical results on how
to train the program state of programmable quantum
processors, either via convex optimization or ï¬rst-order
gradient based algorithms. We then apply our general
methods to study the learning of arbitrary unitaries, and
the simulation of diï¬€erent channels via processors built
either from quantum teleportation and its generalization,
or from parametric quantum circuits.

Programmable quantum computing

2

FIG. 1. Quantum processor Q with program state Ï€ which
simulates a quantum channel EÏ€ from input to output. We
also show the CPTP map Î› of the processor, from the pro-
gram state Ï€ to the output Choi matrix Ï‡Ï€ (generated by
partial transmission of the maximally-entangled state Î¦).

E

= 0 for arbitrary

From theory [1, 4] we know that we cannot achieve
C
unless Ï€ and Q have inï¬nite
(cid:5)
dimensions. As a result, for any ï¬nite-dimensional re-
alistic design of the quantum processor, ï¬nding the op-
timal program state ËœÏ€ is an open problem. Recall
that the diamond distance is deï¬ned by
:=
(cid:107)E âˆ’ EÏ€(cid:107)(cid:5)
is the identity
âˆ’ I âŠ— EÏ€(Ï•)
maxÏ• (cid:107)I âŠ— E
O
map and
(cid:107)

(Ï•)
(cid:107)1 := TrâˆšOâ€ O is the trace norm [2].
It is important to note that this problem can be re-
duced to a simpler one by introducing the channelâ€™s Choi
matrix

(cid:107)1, where

I

E

Let us consider an arbitrary mapping from d-
input states into d(cid:48)-dimensional output
dimensional
= d in the general case. This is described
states, where d(cid:48)
by a quantum channel
that may represent the overall
action of a quantum computation and does not need to
be a unitary transformation. Any channel
can be sim-
ulated by means of a programmable quantum processor,
which is modeled in general by a ï¬xed completely pos-
itive trace-preserving (CPTP) map Q which is applied
to both the input state and a variable program state Ï€.
In this way, the processor transforms the input state by
means of an approximate channel

E

EÏ€ as
Ï€)] ,

EÏ€(Ï) = Tr

2

[Q(Ï

âŠ—

(1)

E

where Tr2 is the partial trace over the program state. A
fundamental result [1] is that there is no ï¬xed quantum
â€œprocessorâ€ Q that is able to exactly simulate any quan-
tum channel
, we cannot ï¬nd
. In other terms, given
E
E â‰¡ EÏ€. Yet sim-
the corresponding program Ï€ such that
ulation can be achieved in an approximate sense, where
the quality of the simulation may increase for larger pro-
gram dimension. In general, the open problem is to de-
termine the optimal program state ËœÏ€ that minimizes the
simulation error, that can be quantiï¬ed by the cost func-
tion

(Ï€) :=

C

(cid:5)

(cid:107)E âˆ’ EÏ€(cid:107)(cid:5)

,

(2)

namely the diamond distance [3, 13] between the target
channel

and its simulation

E

Find ËœÏ€ such that C
(cid:5)

EÏ€. In other words,
(Ï€).
(ËœÏ€) = min

C
(cid:5)

Ï€

(3)

Ï‡

Ï€ =
E

I âŠ— EÏ€(Î¦)
1(cid:80)
i
ij |
(cid:105)(cid:104)

= dâˆ’

j

i
Tr2 [Q(
|

(cid:105)(cid:104)

j

| âŠ—

| âŠ—

Ï€)] ,

(4)

|

Î¦

(cid:105)(cid:104)

Î¦
|

where Î¦ :=
is a d-dimensional maximally-
entangled state. From this expression, it is clear that
Ï€ is linear in the program state Ï€.
the Choi matrix Ï‡
E
More precisely, the Choi matrix Ï‡
Ï€ at the output of the
E
processor Q can be directly written as a CPTP linear
map Î› acting on the space of the program states Ï€, i.e.,

Ï‡Ï€ := Ï‡

Ï€ = Î›(Ï€).
E

(5)

This map is also depicted in Fig. 1 and fully describes
the action of the processor Q. Then, using results from
Refs. [3, 25, 26], we may write

(Ï€)

C
(cid:5)

â‰¤

d C1(Ï€)

â‰¤

(cid:112)

2d

CF (Ï€),

where

C1(Ï€) :=

Ï‡

E âˆ’

(cid:107)

Ï‡Ï€(cid:107)1 ,

(6)

(7)

is the trace distance [2] between target and simulated
Choi matrices, and

CF (Ï€) = 1

F (Ï€)2,

âˆ’

(8)

where F (Ï€) is Buresâ€™ ï¬delity between the two Choi ma-
trices Ï‡
E

and Ï‡Ï€, i.e.,

F (Ï€) :=

âˆšÏ‡
(cid:107)
E

âˆšÏ‡Ï€(cid:107)1 = Tr

(cid:113)

âˆšÏ‡

Ï‡Ï€âˆšÏ‡
E

.

E

(9)

Q ï° Î¦ â„°ğœ‹ ğœ’ğœ‹ Î› Processor Program Choi ğœŒ â„°ï°(ğœŒ) Input Output (cid:54)
Another possible upper bound can be written using the
quantum Pinskerâ€™s inequality [27, 28]. In fact, we may
write C1(Ï€)

CR(Ï€), where

(2 ln âˆš2)

(cid:112)

â‰¤

CR(Ï€) := min

S(Ï‡
{

Ï‡
Ï‡Ï€), S(Ï‡Ï€||

,

)
}

Ïƒ) := Tr[Ï(log2 Ï
||

E ||
E
and S(Ï
log2 Ïƒ)] is the quantum rela-
âˆ’
tive entropy between Ï and Ïƒ. In Supplementary Note 1.3
we also introduce a cost function Cp(Ï€) based on the
Schatten p-norm.

(10)

Convex optimization

One of the main problems in the optimization of recon-
ï¬gurable quantum chips is that the relevant cost func-
tions are not convex in the set of classical parameters.
This problem is completely solved here thanks to the fact
that the optimization of a programmable quantum pro-
cessor is done with respect to a quantum state. In fact,
in the methods section we prove the following

E

Theorem 1. Consider the simulation of a target quan-
by means of a programmable quantum pro-
tum channel
, C1,
cessor Q. The optimization of the cost functions C
(cid:5)
CF , CR or Cp is a convex problem in the space of pro-
gram states Ï€. In particular, the global minimum ËœÏ€ for
C

can always be found as a local minimum.

(cid:5)
This convexity result is generally valid for any cost
function which is convex in Ï€. This is the case for any de-
sired norm, not only the trace norm, but also the Frobe-
nius norm, or any Schatten p-norm.
It also applies to
the relative entropy. Furthermore, the result can also be
extended to any convex parametrization of the program
states.

When dealing with convex optimization with respect
to positive operators, the standard approach is to map
the problem to a form that is solvable via semi-deï¬nite
programming (SDP) [29, 30]. Since the optimal program
is the one minimizing the cost function, it is important
to write the computation of the cost function itself as
a minimization. For the case of the diamond distance,
this can be achieved by using the dual formulation [29].
More precisely, consider the linear map â„¦Ï€ :=
E âˆ’ EÏ€
Î›(Ï€), and the
with Choi matrix Ï‡â„¦Ï€ = Ï‡
E âˆ’
Cd,
spectral norm
,
1
}
{(cid:107)
which is the maximum eigenvalue of âˆšOâ€ O. Then, by
the strong duality of the diamond norm, C
â„¦Ï€(cid:107)(cid:5)
(cid:107)
(cid:5)
is given by the SDP [31]

Ï‡Ï€ = Ï‡
: u
Ou
(cid:107)

E âˆ’
âˆˆ

:= max

(Ï€) =

u
(cid:107)

(cid:107) â‰¤

(cid:107)âˆ

O

(cid:107)

Subject to Z

â‰¥

Minimize 2

Tr2Z
(cid:107)
0 and Z

d(Ï‡

(cid:107)âˆ

,

â‰¥

E âˆ’

Î›(Ï€)).

(11)

3

In the methods section we show that other cost func-
tions such as C1 and CF can also be written as SDPs.
Correspondingly, the optimal programs ËœÏ€ can be ob-
tained by numerical SDP solvers. Most numerical pack-
ages implement second-order algorithms such as the inte-
rior point method [32]. However, second order methods
tend to be computationally heavy for large problem sizes
[33, 34], namely when ËœÏ€ contains many qudits. In the fol-
lowing section we introduce ï¬rst order methods, that are
better suited for larger program states. It is important to
remark that there also exist zeroth-order (derivative-free)
methods, such as the simultaneous perturbation stochas-
tic approximation method [35], which was utilized for
a quantum problem in [36]. However, it is known that
zeroth-order methods normally have slower convergence
times [37] compared to ï¬rst-order methods.

Gradient based optimization

In machine learning applications, where a large amount
of data is commonly available, there have been several
works that study the minimization of suitable matrix
norms for diï¬€erent purposes [17, 18, 38, 39]. First-order
methods, are preferred for large dimensional problems,
as they are less computationally intensive and require
less memory. Here we show how to apply ï¬rst-order
(gradient-based) algorithms, which are widely employed
in machine learning applications, to ï¬nd the optimal
quantum program.

For this purpose, we need to introduce the subgradient
, which is the

of the cost function C at any point Ï€
set

âˆˆ S

âˆ€

Ïƒ

âˆ’

âˆ’

â‰¥

Ï€)],

C(Ï€)

Tr[Z(Ïƒ

âˆ‚C(Ï€) =

its gradient

Z : C(Ïƒ)
{

,
âˆˆ S}
(12)
where Z is Hermitian [40, 41]. If C is diï¬€erentiable, then
C(Ï€).
âˆ‚C(Ï€) contains a single element:
We explicitly compute this gradient for an arbitrary pro-
grammable quantum processor (1) whose Choi matrix
Ï‡
Ï‡Ï€ = Î›(Ï€), can be written as a quantum channel
E
Î› that maps a generic program state to the processorâ€™s
Choi matrix. This map can be deï¬ned by its Kraus de-
composition Î›(Ï€) = (cid:80)
k AkÏ€Aâ€ k for some operators Ak.
In fact, let us call Î›âˆ—(Ï) = (cid:80)
k Aâ€ kÏAk the dual map, then
in the methods section we prove the following

Ï€ â‰¡

âˆ‡

Theorem 2. Consider an arbitrary quantum channel
E
with Choi matrix Ï‡
which is simulated by a quantum
processor Q with map Î›(Ï€) = Ï‡Ï€ (and dual map Î›âˆ—).
Then, we may write the following gradients for the trace
distance cost C1(Ï€) and the inï¬delity cost CF (Ï€)

E

The importance of the above dual formulation is that
the diamond distance is a minimization, rather than a
maximization over a set of matrices. In order to ï¬nd the
optimal program ËœÏ€ we apply the unique minimization of
Eq. (11) where Ï€ is variable and satisï¬es the additional
constraints Ï€

0 and Tr(Ï€) = 1.

â‰¥

C1(Ï€) =

âˆ‡

CF (Ï€) =

âˆ‡

F (Ï€) =

âˆ‡

(cid:88)

k

sign(Î»k)Î›âˆ—(Pk),

(cid:112)
2

Î›âˆ—

1
(cid:104)

âˆ’
âˆšÏ‡

âˆ’
1
2

CF (Ï€)

(âˆšÏ‡
E

E

F (Ï€),

âˆ‡
Î›(Ï€) âˆšÏ‡
E

(13)

(14)

1

2 âˆšÏ‡

)âˆ’

(cid:105)

E

,

(15)

where Î»k (Pk) are the eigenvalues (eigenprojectors) of the
. When C1(Ï€) or CF (Ï€) are
Hermitian operator Ï‡Ï€ âˆ’
E
not diï¬€erentiable in Ï€, then the above expressions provide
an element of the subgradient âˆ‚C(Ï€).

Ï‡

C, we can solve the optimization minÏ€
the projected subgradient method [14, 40]. Let
the projection onto the set of program states
X

Once we have the (sub)gradient of the cost function
C(Ï€) using
be
PS
, namely
(cid:107)2, that we show to be com-
Ï€
PS
putable from the spectral decomposition of any Hermi-
tian X (see Theorem 3 in the methods section). Then,
we iteratively apply the steps

(X) = argminÏ€

S(cid:107)
âˆˆ

âˆ’

âˆˆS

S

1) Select an operator gi from âˆ‚C(Ï€i),
2) Ï€i+1 =

Î±igi) ,

(Ï€i âˆ’

PS

(16)

where i is the iteration index, Î±i is what is called â€œlearn-
ing rateâ€, and Theorem 2 can be employed to ï¬nd gi at
each step. It is simple to show that Ï€i converges to the
2) steps, for any desired
optimal program state ËœÏ€ in
precision (cid:15) such that
(cid:15). Another ap-
C(Ï€)
proach is the conjugate gradient method [15, 40], some-
times called Frank-Wolfe algorithm. Here, we apply

O
âˆ’

C(ËœÏ€)

| â‰¤

((cid:15)âˆ’

|

|

of

i+2 |

Ïƒi(cid:105)

C(Ï€i),

1) Find the smallest eigenvalue
2) Ï€i+1 = i
i+2 Ï€i + 2
.
Ïƒi|

Ïƒi(cid:105) (cid:104)
When the gradient of f is Lipschitz continuous with con-
(L/(cid:15)) steps [16, 42].
stant L, the method converges after
To justify the applicability of this method a suitable
smoothening of the cost function must be employed [43].

(17)

âˆ‡

O

4

designs, over which we will test the optimization pro-
cedure. One possible (shallow) design for the quantum
processor Q is a generalized teleportation protocol [48]
over an arbitrary program state Ï€. In dimension d, the
protocol involves a basis of d2 maximally-entangled states
of teleportation unitaries such that
Î¦i(cid:105)
|
Tr(U â€ i Uj) = dÎ´ij [49]. An input d-dimensional state Ï
and the A part of the program Ï€AB are subject to the
. The classical outcome i is communi-
projector
cated to the B part of Ï€AB where the correction U âˆ’
is
i
applied.

and a basis

Î¦i(cid:105) (cid:104)
|

Ui}

Î¦i|

{

1

The above procedure deï¬nes the teleportation channel

EÏ€ over Ï

tele
Ï€ (Ï) =
E

(cid:88)

i

U B
i (cid:104)

Î¦SA
i

ÏS

|

âŠ—

Ï€AB

Î¦SA
i
|

(cid:105)

U B
â€ i

.

(19)

Its Choi matrix can be written as Ï‡Ï€ = Î›tele(Ï€), where
the map of the teleportation processor is equal to

Î›tele(Ï€) = dâˆ’

2 (cid:88)

i

(U âˆ—i âŠ—

Ui) Ï€ (U âˆ—i âŠ—

Ui)â€  ,

(20)

E

which is clearly self-dual Î›âˆ— = Î›. Given a target quan-
tum channel
which is teleportation-covariant [23, 24],
Ui] = 0, then we know that that
namely when [Ï€, U âˆ—i âŠ—
its simulation is perfect and the optimal program ËœÏ€ is the
channelâ€™s Choi matrix, i.e., one of the ï¬xed points of the
map Î›tele. For a general channel, the optimal program ËœÏ€
can be approximated by using the cost functions in our
Theorem 2 with Î› being given in Eq. (20), or directly
found by optimizing C
(cid:5)

(Ï€).

Learning of arbitrary unitaries

Port-based teleportation

One speciï¬c application is the simulation of quantum
gates or, more generally, unitary transformations [22, 44â€“
47]. Here, the inï¬delity provides the most convenient cost
function, as the optimal program can be found analyti-
cally. In fact, suppose we use a quantum processor with
map Î› to simulate a target unitary U . Because the Choi
, we ï¬rst note that F (Ï€)2 =
matrix of U is pure
Ï‡U |
Ï‡U (cid:105)(cid:104)
|
and then we see that Eq. (15) drastically
Ï‡U (cid:105)
Î›(Ï€)
Ï‡U |
(cid:104)
|
4F (Ï€)2. As a
simpliï¬es to
Ï‡U |
F (Ï€) = Î›âˆ— (
|
âˆ‡
result, we ï¬nd

Ï‡U (cid:105)(cid:104)

) /

(cid:112)

CF (Ï€) =

Î›âˆ— [
|

Ï‡U (cid:105)(cid:104)

] ,
Ï‡U |

âˆ’

âˆ‡

(18)

where there is no dependence on Ï€. Therefore, using the
conjugate gradient method in Eq. (17), we see that the
optimal program state ËœÏ€ for the inï¬delity cost function
CF is a ï¬xed point of the iteration and is equal to the
maximum eigenvector of Î›âˆ— [
|

].
Ï‡U |

Ï‡U (cid:105)(cid:104)

A1, . . . , AN }
{

A deeper design is provided by a PBT processor,
is illustrated in Fig. 2. Here
whose overall protocol
we consider a more general formulation of the original
PBT protocol [19, 20] where the resource entangled pairs
are replaced by an arbitrary program state Ï€.
In a
PBT processor, each party has N systems (or â€˜portsâ€™),
A =
B1, . . . , BN }
{
for Bob. These are prepared in a program state Ï€AB.
To teleport an input state ÏC, Alice performs a joint
positive operator-value measurement (POVM)
[19]
on system C and the A-ports. She then communicates
the outcome i to Bob, who discards all ports except Bi
which is the output Bout. The resulting PBT channel
PÏ€ :

for Alice and B =

Î i}

{

Î i(Ï€AB

(cid:112)

ÏC)

Î i

âŠ—

(cid:105)

Bi

Bout

â†’

HC (cid:55)â†’ HBout is then
(cid:104)(cid:112)

N
(cid:88)

PÏ€(Ï) =

Tr
A Â¯BiC

i=1

N
(cid:88)

i=1

Teleportation processor

=

Tr
A Â¯BiC

[Î i(Ï€AB

ÏC)]Bi

Bout ,

â†’

âŠ—

(21)

Once we have shown how to optimize a generic pro-
grammable quantum processor, we discuss some speciï¬c

where Â¯Bi = B
\

Bi =

Bk : k
{

= i

.
}

(cid:54)
5

E

I

with its PBT simulation

is the identity channel. This is done by replacing the
I
IN , and then
identity channel
to Bi. However, since Bob does not perform
applying
any post-processing on his systems B, aside from dis-
= i, he can also apply ï¬rst
carding all ports Bk with k
N to all his ports and then discard all the
the channel
âŠ—
= i. In doing so, he changes the program
ports Bk with k
state to

E

Ï€AB = 11A âŠ— E

âŠ—
B

(cid:34) N
(cid:79)

N

k=1

(cid:35)

Î¦AkBk

=

N
(cid:79)

k=1

Ï‡AkBk
E

.

(25)

In other terms, any channel
by N copies of its Choi matrix Ï‡
E
PBT-simulation can be decomposed as
error C N
(cid:5)
satisï¬es

can be PBT-approximated
as program state. Since
E â—¦ IN , the
E â‰¡ E â—¦I

in simulating the channel

(cid:107)E âˆ’EÏ€(cid:107)(cid:5)

EÏ€ =

=

E

C N
(cid:5)

=

(cid:107)Eâ—¦Iâˆ’Eâ—¦IN (cid:107) â‰¤ (cid:107)Iâˆ’IN (cid:107)(cid:5) â‰¤

2d(d

âˆ’

1)N âˆ’

1 . (26)

where we used the data processing inequality and an up-
per bound from [50]. While the channelâ€™s Choi matrix
assures that C N
0 for large N , for any ï¬nite N it does
not represent the optimal program state. In general, for
any ï¬nite N , ï¬nding the optimal program state Ï€AB sim-
with PBT is an open problem, and
ulating a channel
no explicit solutions or procedures are known.

(cid:5) â†’

E

|

(cid:5)

of A

ei
j(cid:105)

B
\
{

and a basis

Î›(Ï€) = (cid:80)

â†’
ijKijÏ€K â€ ij, Kij :=

We employ our convex optimization procedures to ï¬nd
the optimal program state. This can be done either ex-
actly by minimizing the diamond distance cost function
C
via SDP, or approximately, by determining the op-
timal program state via the minimization of the trace
distance cost function C1 via either SDP or the gradient-
based techniques discussed above. For this second ap-
proach, we need to derive the map Î› of the PBT proces-
sor, between the program state Ï€ to output Choi matrix
as in Eq. (5). To compute the Choi matrix and CP-
map Î›, we consider an input maximally-entangled state
C. Then, by using
Bi}
Î¦DC(cid:105)
|
Eq. 21 and the deï¬nition Î›(Ï€) = Ï‡
Ï€ = 11D âŠ— PÏ€[Î¦DC]
P
we ï¬nd the map Î›AB
DBout of a PBT processor
(cid:112)

.
Î¦DC(cid:105)
(27)
Note that a general program state for PBT consists
of 2N qudits, and hence the parameter space has expo-
nential size d4N . However, because the PBT protocol
is symmetric under permutation of port labels, we show
in Supplementary Note 6 that one can exploit this sym-
metry and reduce the number of free parameters to the
binomial coeï¬€ï¬cient (cid:0)N +d4
(cid:1), which is polynomial in
âˆ’
d4
1
the number of ports N . Despite this exponential reduc-
tion, the scaling in the number of parameters still repre-
sents a practical limiting factor, even for qubits for which
(cid:0)N 15(cid:1). A sub-optimal strategy consists in reducing the
O
space of program states to a convex set that we call the
â€œChoi spaceâ€
. Consider an arbitrary probability distri-
pk}
bution
Ï€ : Ï€ = (cid:80)
{

C
and then deï¬ne

AB , TrB(Ïk

AB) = dâˆ’

11BD|

Î i âŠ—

kpkÏk

ei
j|

(28)

.
}

111

=

C

{

N

âˆ’

âŠ—

(cid:104)

1

FIG. 2. PBT scheme. Two distant parties, Alice and Bob,
share N maximally entangled pairs {Ak, Bk}N
k=1. Alice also
has another system C in the state |Ïˆ(cid:105). To teleport C, Al-
ice performs the POVM {Î AC
} on all her local systems
A = {Ak}N
k=1 and C. She then communicates the outcome i
to Bob. Bob discards all his systems B = {Bk}N
k=1 with the
exception of Bi. After these steps, the state |Ïˆ(cid:105) is approx-
imately teleported to Bi. Similarly, an arbitrary channel E
is simulated with N copies of the Choi matrix Ï‡AkBk
. The
ï¬gure shows an example with N = 5, where i = 4 is selected.

E

i

In the standard PBT protocol [19, 20], the program
are

state is ï¬xed as Ï€AB = (cid:78)N
k=1 Î¦AkBk , where
|
Bell states, and the following POVM is used

Î¦AkBk (cid:105)

Î i = ËœÎ i +

(cid:32)

11

âˆ’

1
N

(cid:88)

k

(cid:33)

ËœÎ k

,

where

1/2

ËœÎ i = Ïƒâˆ’
AC Î¦AiCÏƒâˆ’
N
(cid:88)

1/2
AC ,

ÏƒAC :=

Î¦AiC,

i=1

(22)

(23)

(24)

â‰¥

1/2 is an operator deï¬ned only on the support of
and Ïƒâˆ’
2 ports.
Ïƒ. The PBT protocol is formulated for N
However, we also include here the trivial case for N = 1,
corresponding to the process where Aliceâ€™s input is traced
out and the output is the reduced state of Bobâ€™s port,
, the
i.e., a maximally mixed state. In the limit N
standard PBT protocol approximates an identity chan-
(cid:1), so
nel
Ï, with ï¬delity [19, 21] FÏ€ = 1
perfect simulation is possible only in the limit N
.
â†’ âˆ
Since the standard PBT-protocol provides an approxi-
mation to the identity channel, we call it

IN .
possible to approximate any general channel
ing that

From the PBT-simulation of the identity channel it is
by not-
, where

can be written as a composition

â†’ âˆ
(cid:0) 1
N

PÏ€(Ï)

âˆ’ O

â‰ˆ

E
E â—¦ I

E

AliceBobdiscardBkk6=i|ÏˆiCâ‰ˆ|ÏˆiA1B1A2B2A3B3A4B4A5B5(cid:7)iÎ ACi(cid:54)
(cid:54)
C

One can show (see Supplementary Note 6) that a global
minimum in
is a global minimum in the extremal
(non-convex) subspace for pk = Î´k,1 consisting of tensor-
products of Choi matrices ÏâŠ—
AB . Among these states,
there is the N -copy Choi matrix of the target channel
N which is not necessarily the
Ï‡âŠ—
Î¦
(cid:105) (cid:104)
E
optimal program, as we show below.

)]âŠ—
|

I âŠ— E

= [

(
|

Î¦

N

N

Parametric quantum circuits

Another deep design of quantum processor is based
on PQCs [22, 51]. A PQC is a sequence of unitary ma-
trices U (t) = UN (tN ) . . . U2(t2)U1(t1), where Uj(tj) =
exp(itjHj) for some Hamiltonian Hj and time interval
tj. The problem with PQCs is that the cost functions in
the classical parameters [44] are not convex, so that nu-
merical algorithms are not guaranteed to converge to the
global optimum. Here we ï¬x this issue by introducing a
convex formulation of PQCs where classical parameters
are replaced by a quantum program. This results in a
programmable PQC processor which is optimizable by
our methods.

(ÏA) = TrR0[U (ÏAâŠ—

The universality of PQCs can be employed for univer-
sal channel simulation. Indeed, thanks to Stinespringâ€™s
dilation theorem, any channel can be written as a unitary
evolution on a bigger space,
Î¸0)U â€ ],
E
where the system is paired to an extra register R0 and Î¸0
belongs to R0. In the Stinespring representation U acts
on system A and register R0.
In Ref. [51] it has been
shown that sequences of two unitaries, U0 and U1, are
almost universal for simulation, i.e., any target unitary
U can be approximated as U
for
â‰ˆ Â· Â· Â·
some integers mj. Under suitable conditions, it takes
d) steps to approximate U up to precision (cid:15). The
O
choice between U0 and U1 is done by measuring a classi-
cal bit. We may introduce a quantum version, where the
two diï¬€erent unitaries U0 = eiH0 or U1 = eiH1 are chosen
depending on the state of qubit Rj. This results in the
conditional gate

U m4
1 U m3

0 U m2

1 U m1

(d2(cid:15)âˆ’

0

(29)

Ë†Uj = exp (iH0 âŠ— |

0
0
(cid:105)j j(cid:104)

+ iH1 âŠ— |

1

1
(cid:105)j j(cid:104)

) .
|

|
Channel simulation is then obtained by replacing the uni-
tary evolution U in the Stinespring dilation via its sim-
ulation. The result is illustrated in Fig. 3, where the
program state Ï€ is deï¬ned over R = (R0, . . . , RN ) and
each Ë†Hj acts on the input system A and two ancillary
qubits R0 and Rj. Following the universality construc-
tion of Ref. [51] we show in the Supplementary Note 3.4
that the channel shown in Fig. 3 provides a universal pro-
cessor. Moreover, the channel Î› that maps any program
Ï€ to the processorâ€™s Choi matrix is obtained as

Î›(Ï€) = TrR

where Ë†UAR = 11B âŠ—
identify the optimal program

j=1

(cid:81)N

(cid:104)
Ë†UAR (Î¦BA âŠ—
Ë†Uj A,R0,Rj
ËœÏ€
|

(cid:105)

Ï€R) Ë†U â€ AR

(cid:105)

,

(30)

, from which we can

via our methods.

6

FIG. 3. Simulation of a quantum channel via Stinespring
decomposition together with unitary simulation as in Fig. 14.

|

|

âŠ— |

+ 0

2
(cid:105)j j(cid:104)

0
0
(cid:105)j j(cid:104)

1
1
(cid:105)j j(cid:104)

PQCs are not inherently monotonic. A deeper (higher
N ) design may simulate a given channel worse than a
more shallow design. We can design a modiï¬ed PQC that
is monotonic by design, which we designate a â€œmonotonic
PQCâ€, by replacing the qubits in our program state with
qutrits, and modifying Eq. 29 to read
Ë†Uj = exp (iH0 âŠ— |
) ,
2
+ iH1 âŠ— |
|
(31)
where 0 is a zero operator, so that gate j enacts the
identity channel if program qutrit j is in the state
.
2
|
Then, if it were the case that a PQC with N program
qubits could simulate a given channel better than one
with N + m, a monotonic PQC with N + m qutrits in the
program state could perform at least as well as the PQC
with N program qubits by setting the ï¬rst m qutrits to
. This processor design is both universal and mono-
2
|
|
tonic. More precisely, let C(PQCN ) denote the value of
a cost function C for simulating a channel
with an
N -gate PQC, using the optimal program state, and let
with
C(mPQCN ) denote the value of C for simulating
an N -gate monotonic PQC, again using the optimal pro-
gram state. We are then guaranteed that

2
(cid:105)(cid:104)

2
(cid:105)(cid:104)

E

E

|

C(mPQCN )

min
N
M
â‰¤

â‰¤

C(PQCM ).

(32)

Processor benchmarking

In order to show the performance of the various ar-
chitectures, we consider the simulation of an amplitude
damping channel with probability p. The reason is be-
cause this is the most diï¬ƒcult channel to simulate, with
a perfect simulation only known for inï¬nite dimension,
e.g., using continuous-variable quantum operations [23].
In Figs. 4-5 we compare teleportation-based, PBT, PQC
and â€œmonotonic PQCâ€ (mPQC) programmable proces-
sors whose program states have been optimized according
to the cost functions C
and C1. For the PBT proces-
(cid:5)
sor the trace distance cost C1 is remarkably close to C
(cid:5)
and allows us to easily explore high depths. Note that

|ÏˆiUÎ¸1UÎ¸2UÎ¸3UÎ¸4|Î¸0i|Î¸1iâ€¢|Î¸2iâ€¢|Î¸3iâ€¢|Î¸4iâ€¢7

least as well as any shallower design. In Fig. 5 perfect
simulation is achievable at speciï¬c values of p because of
our choice of the universal gates U0 and U1. More details
are provided in the Supplementary Note 3.

Many other numerical simulations are performed in the
Supplementary Note 3 where we study the convergence
rate in learning a unitary operation, the exact simulation
of Pauli channels, and approximate simulation of both
dephasing and amplitude damping channels. In particu-
lar, we study the performance of the approximate solu-
tion when optimizing over larger, but easier to compute,
cost functions such as the trace distance or the inï¬delity.

DISCUSSION

In this work we have considered a general ï¬nite-
dimensional model of a programmable quantum proces-
sor, which is a fundamental scheme for quantum com-
puting and also a primitive tool for other areas of quan-
tum information. By introducing suitable cost functions,
based on the diamond distance, trace distance and quan-
tum ï¬delity, we have shown how to characterize the op-
timal performance of this processor in the simulation of
an arbitrary quantum gate or channel. In fact, we have
shown that the minimization of these cost functions is a
convex optimization problem that can always be solved.
In particular, by minimizing the diamond distance via
SDP, we can always determine the optimal program state
for the simulation of an arbitrary channel. Alternatively,
we may minimize the simpler but larger cost functions in
terms of trace distance and quantum ï¬delity via gradient-
based methods adapted from ML, so as to provide a
very good approximation of the optimal program state.
This other approach can also provide closed analytical
solutions, as is the case for the simulation of arbitrary
unitaries, for which the minimization of the ï¬delity cost
function corresponds to computing an eigenvector.

We have then applied our results to various de-
from a
signs of programmable quantum processor,
shallow teleportation-based scheme
to deeper and
asymptotically-universal designs that are based on PBT
and PQCs. We have explicitly benchmarked the perfor-
mances of these quantum processors by considering the
simulation of unitary gates, depolarizing and amplitude
damping channels, showing that the optimal program
states may diï¬€er from the naive choice based on the Choi
matrix of the target channel. Moreover, our results can
be applied also for universal quantum measurements [53].
A potential application of our work may be the devel-
opment of â€œprogrammableâ€ model of cloud-based quan-
tum computation, where a client has an input state to be
processed by an online quantum server which is equipped
with a programmable quantum processor. The client
classically informs the server about what type of compu-
tation it needs (e.g., some speciï¬ed quantum algorithm)
and the server generates an optimal program state which
closely approximates the overall quantum channel to be

FIG. 4. Diamond-distance error C(cid:5) in simulating an ampli-
tude damping channel Ep at various damping rates p. We
compare the performance of diï¬€erent designs for the pro-
grammable quantum processor: Standard teleportation and
port-based teleportation with N ports (PBTN ). The opti-
mal program ËœÏ€ is obtained by either minimizing directly the
diamond distance C(cid:5) (solid lines), or the trace distance C1
(dashed lines) via the projected subgradient iteration. In both
cases, from ËœÏ€ we then compute C(cid:5)(ËœÏ€). The lowest curves are
obtained by optimizing Ï€ over the Choi space in Eq. (28).
For comparison, we also show the (non-optimal) performance
when the program is the channelâ€™s Choi matrix (dotted lines).

FIG. 5. Diamond-distance error C(cid:5) in simulating an ampli-
tude damping channel Ep at various damping rates p. We
compare the performance of two diï¬€erent designs for the pro-
grammable quantum processor: parametric quantum circuits
with N +1 registers (PQCN ) and monotonic parametric quan-
tum circuits with N +1 registers (mPQCN ). In both cases the
optimal program |ËœÏ€(cid:105) is obtained by minimizing the diamond
distance C(cid:5).

the optimal program states diï¬€er from the naive choice
of the Choi matrix of the target channel. Note too that
PQC processors display non-monotonic behaviour when
simulating amplitude damping channels, meaning that
shallow PQC processors (e.g., for N = 4) may perform
better than deeper processors [52]. Monotonic PQC pro-
cessors guarantee that deeper designs always perform at

0.00.20.40.60.81.01.21.4kEâˆ’EÏ€k(cid:5)0.00.20.40.60.81.0pPBT2PBT3PBT4PBT20Telep.0.00.20.40.60.81.01.21.4kEâˆ’EÏ€k(cid:5)0.20.40.60.81.0pPQC1PQC2PQC3PQC4PQC5PQC60.20.40.60.81.0pmPQC1mPQC2mPQC3mPQC4applied to the input. The server then accepts the input
from the client, processes it, and returns the output to-
gether with the value of a cost function quantifying how
close the computation was with respect to the clientâ€™s
request.

Our results may also be useful in areas beyond quan-
tum computing, wherever channel simulation is a basic
problem. For instance, this is the case when we investi-
gate the ultimate limits of quantum communications [24],
design optimal Hamiltonians for one-way quantum re-
peaters, and for all those areas of quantum sensing, hy-
pothesis testing and metrology which are based on quan-
tum channel simulations [54]. Indeed the study of adap-
tive protocols of quantum channel discrimination (or esti-
mation) is notoriously diï¬ƒcult, and their optimal perfor-
mance is not completely understood. Nonetheless, these
protocols can be analyzed by using simulation techniques
[50, 54] where the channel, encoding the unknown param-
eter, is replaced by an approximate simulating channel,
and its parameter is mapped into the label of a program
state (therefore reducing the problem from channel to
state discrimination/estimation). In this regard, our the-
ory provides the optimal solution to this basic problem,
by determining the best simulating channel and the cor-
responding program state.

METHODS

Convexity proofs

(cid:5)

In this section we provide a proof of Theorem 1, namely
we show that the minimization of the main cost functions
C
, C1 and CF is a convex optimization problem in the
space of the program states Ï€. This means that we can
ï¬nd the optimal program state ËœÏ€ by minimizing C
or,
(cid:5)
alternatively, sub-optimal program states can be found
by minimizing either C1 or CF . For the sake of generality,
we prove the result for all of the cost functions discussed
in the previous sections. We restate Theorem 1 below for
completeness:

Theorem. The minimization of the generic cost func-
tion C = C
, C1, CF , CR or Cp for any p > 1 is a convex
optimization problem in the space of program states.

(cid:5)

Proof. Let us start to show the result for the diamond
distance C

. In this case, we can write the following

(cid:5)

p)Ï€(cid:48)]

(cid:5)

âˆ’

[pÏ€ + (1

C
:= (cid:13)
(cid:13)
E âˆ’ EpÏ€+(1
âˆ’
(p+1
(cid:107)

(1)
=

p)

E âˆ’

âˆ’

p

p)Ï€(cid:48)

(cid:13)
(cid:13)
(cid:5)
EÏ€ âˆ’
(1
(cid:107)

âˆ’

p)

(1

âˆ’

(cid:107)(cid:5)

EÏ€(cid:48)
(1

(2)

â‰¤ (cid:107)
(3)

p
â‰¤
= pC

p

p

EÏ€(cid:107)(cid:5)

+

E âˆ’

p)

E âˆ’

p)

EÏ€(cid:48)

(cid:107)(cid:5)

âˆ’

(cid:107)E âˆ’ EÏ€(cid:107)(cid:5)
(Ï€) + (1
(cid:5)

+ (1

âˆ’
p)C

(cid:5)

âˆ’

(cid:107)E âˆ’ EÏ€(cid:48)

p)
(Ï€(cid:48)),

(cid:107)(cid:5)

(33)

8

x

A

where we use (1) the linearity of
, (2)
E
inequality and (3) the property
(cid:107)1 =
xA
(cid:107)
for any operator A and coeï¬ƒcient x.
For any Schatten p-norm Cp with p

the triangle
(cid:107)1, valid
1, we may prove
convexity following a similar reasoning. Since for any
combination Â¯Ï€ := p0Ï€0 + p1Ï€1, with p0 + p1 = 1, we
have Î›(Â¯Ï€) = p0Î›(Ï€0) + p1Î›(Ï€1), then by exploiting the
triangle inequality, and the property
(cid:107)p,
we can show that

(cid:107)p =

xA
(cid:107)

x
|

|(cid:107)

|(cid:107)

â‰¥

A

|

Cp(p0Ï€0 + p1Ï€1) :=

Ï‡
E âˆ’
(cid:107)
Ï‡
p0(cid:107)

Î›(p0Ï€0 + p1Ï€1)
(cid:107)p
Ï‡
(cid:107)p + p1(cid:107)
â‰¤
= p0Cp(Ï€0) + p1Cp(Ï€1) .

Î›(Ï€0)

E âˆ’

(34)

Î›(Ï€1)

(cid:107)p

E âˆ’

To show the convexity of CF , deï¬ned in Eq. (8), we note
that the ï¬delity function F (Ï, Ïƒ) satisï¬es the following
concavity relation [55]

(cid:32)

(cid:88)

F

k

(cid:33)2

pkÏk, Ïƒ

(cid:88)

â‰¥

k

pkF (Ïk, Ïƒ)2 .

(35)

Due to the linearity of Ï‡Ï€ = Î›(Ï€), the ï¬delity in Eq. (9)
Ï€k for Â¯Ï€ := (cid:80)
satisï¬es F 2
k pkÏ€k. Accordingly,
we get the following convexity result

k pkF 2

Â¯Ï€ â‰¥

(cid:80)

CF

(cid:33)

pkÏ€k

(cid:32)

(cid:88)

k

(cid:88)

â‰¤

k

pkCF (Ï€k) .

(36)

For the cost function CR, the result comes from the lin-
earity of Î›(Ï€) and the joint convexity of the relative en-
tropy. In fact, for Â¯Ï€ := p0Ï€0 + p1Ï€1, we may write

S[Î›(Â¯Ï€)

Ï‡
E

||

] = S[p0Î›(Ï€0) + p1Î›(Ï€1)
= S[p0Î›(Ï€0) + p1Î›(Ï€1)

Ï‡
]
E
p0Ï‡
E

||
||
] + p1S[Î›(Ï€1), Ï‡
E

+ p1Ï‡
E
],

]
(37)

p0S[Î›(Ï€0), Ï‡
E

â‰¤

with a symmetric proof for S[Ï‡
E ||
convexity of CR(Ï€) in Eq. (10). (cid:4)

Î›(Â¯Ï€)]. This implies the

Convex classical parametrizations

The result of the theorem 1 can certainly be extended
to any convex parametrization of program states. For
instance, assume that Ï€ = Ï€(Î»), where Î» =
is a
Î»i}
{
probability distribution. This means that, for 0
1
p
â‰¤
â‰¤
and any two parametrizations, Î» and Î»(cid:48), we may write

Ï€[pÎ» + (1

âˆ’

p)Î»(cid:48)] = pÏ€(Î») + (1

âˆ’

p)Ï€(Î»(cid:48)).

(38)

Then the problem remains convex in Î» and we may there-
fore ï¬nd the global minimum in these parameters. It is
clear that this global minimum ËœÎ» identiï¬es a program
state Ï€(ËœÎ») which is not generally the optimal state ËœÏ€ in
the entire program space
, even though the solution may
be a convenient solution for experimental applications.

S

Note that a possible classical parametrization consists

of using classical program states, of the form

Ï€(Î») =

(cid:88)

i

Î»i |

Ï•i(cid:105) (cid:104)

Ï•i|

,

(39)

Ï•i(cid:105)}

where
is an orthonormal basis in the program
space. Convex combinations of probability distributions
therefore deï¬ne a convex set of classical program states

{|

Sclass =

{

Ï€ : Ï€ =

(cid:88)

i

Î»i |

Ï•i(cid:105) (cid:104)

Ï•i|

,

Ï•i|

(cid:104)

Ï•j(cid:105)

= Î´ij}

. (40)

Optimizing over this speciï¬c subspace corresponds to op-
timizing the programmable quantum processor over clas-
sical programs. It is clear that global minima in
Sclass
are expected to be very diï¬€erent. For instance,
and
Sclass cannot certainly include Choi matrices which are
usually very good quantum programs.

S

Gradient-based optimization

As discussed in the main text, the SDP formulation
allows the use of powerful and accurate numerical meth-
ods, such as the interior point method. However, these
algorithms are not suitable for high dimensional prob-
lems, due to their higher computational and memory re-
quirements. Therefore, an alternative approach (useful
for larger program states) consists of the optimization of
the larger but easier-to-compute cost function C = C1
(trace distance) or CF (inï¬delity), for which we can use
ï¬rst order methods. Indeed, according to Theorem 1, all
R are convex
of the proposed cost functions C :
over the program space
and, therefore, we can solve
S
the optimization minÏ€
C(Ï€) by using gradient-based
algorithms.

S â†’

âˆˆS

Gradient-based convex optimization is at the heart of
many popular ML techniques such as online learning in
a high-dimensional feature space [17], missing value esti-
mation problems [18], text classiï¬cation, image ranking,
and optical character recognition [56], to name a few. In
all of the above applications, â€œlearningâ€ corresponds to
the following minimization problem: minx
f (x), where
f (x) is a convex function and
is a convex set. Quan-
tum learning falls into this category, as the space of pro-
gram states is convex due to the linearity of quantum
mechanics and the fact that cost functions are typically
convex in this space (see Theorem 1). Gradient-based ap-
proaches are among the most applied methods for convex
optimization of non-linear, possibly non-smooth func-
tions [40].

âˆˆS

S

When the cost function is not diï¬€erentiable we cannot
formally deï¬ne its gradient. Nonetheless, we can always
deï¬ne the subgradient âˆ‚C of C as in Eq. (12), which in
principle contains many points. When C is not only con-
vex but also diï¬€erentiable, then âˆ‚C(Ï€) =
, i.e.
the subgradient contains a single element, the gradient
C, that can be obtained via the FrÂ´echet derivative of C

C(Ï€)
}

{âˆ‡

âˆ‡

9

(for more details see Supplementary Note 4). When C is
not diï¬€erentiable, the gradient still provides an element
of the subgradient that can be used in the minimization
algorithm.

In order to compute the gradient

C, it is convenient
to consider the Kraus decomposition of the processor
map Î›. Let us write

âˆ‡

Î›(Ï€) =

(cid:88)

k

AkÏ€Aâ€ k,

(41)

with Kraus operators Ak. We then deï¬ne the dual
map Î›âˆ— of the processor as the one (generally non-trace-
preserving) which is given by the following decomposition

Î›âˆ—(Ï) =

(cid:88)

k

Aâ€ kÏAk.

(42)

With these deï¬nitions in hands, we can now prove The-
orem 2, which we rewrite here for convenience.

Theorem. Suppose we use a quantum processor Q with
map Î›(Ï€) = Ï‡Ï€ in order to approximate the Choi matrix
. Then, the gradients of the
Ï‡
E
E
trace distance C1(Ï€) and the inï¬delity CF (Ï€) are given
by the following analytical formulas

of an arbitrary channel

C1(Ï€) =

âˆ‡

CF (Ï€) =

âˆ‡

F (Ï€) =

âˆ‡

(cid:88)

k

sign(Î»k)Î›âˆ—(Pk),

(cid:112)
2

Î›âˆ—

1
(cid:104)

âˆ’
âˆšÏ‡

âˆ’
1
2

CF (Ï€)

(âˆšÏ‡
E

E

F (Ï€),

âˆ‡
Î›(Ï€) âˆšÏ‡
E

(43)

(44)

1

2 âˆšÏ‡

)âˆ’

(cid:105)

E

,

(45)

where Î»k (Pk) are the eigenvalues (eigenprojectors) of the
. When C1(Ï€) or CF (Ï€) are
Hermitian operator Ï‡Ï€ âˆ’
E
not diï¬€erentiable at Ï€, then the above expressions provide
an element of the subgradient âˆ‚C(Ï€).

Ï‡

Proof. We prove the above theorem assuming that the
functions are diï¬€erentiable for program Ï€. For non-
diï¬€erentiable points, the only diï¬€erence is that the above
analytical expressions are not unique and provide only
one of the possibly inï¬nite elements of the subgradient.
Further details of this mathematical proof are given in
Supplementary Note 4. Following matrix diï¬€erentiation,
for any function f (A) = Tr[g(A)] of a matrix A, we may
write

dTr[g(A)] = Tr[g(cid:48)(A)dA],

(46)

and the gradient is
f (A) = g(cid:48)(A). Both the trace-
distance and ï¬delity cost functions can be written in this
form. To ï¬nd the explicit gradient of the ï¬delity function,
we ï¬rst note that, by linearity, we may write

âˆ‡

Î›(Ï€ + Î´Ï€) = Î›(Ï€) + Î›(Î´Ï€) ,

(47)

and therefore the following expansion

âˆšÏ‡
E
Î›(Ï€)âˆšÏ‡
E

Î›(Ï€ + Î´Ï€)âˆšÏ‡
+ âˆšÏ‡

=
Î›(Î´Ï€)âˆšÏ‡

E

E

âˆšÏ‡

E

.

E

(48)

From this equation and diï¬€erential calculations of the
ï¬delity (see Supplementary Note 4.2 for details), we ï¬nd

dF =

(cid:104)

Tr

1
2

(âˆšÏ‡

Î›(Ï€)âˆšÏ‡
E

E

)âˆ’

1

2 âˆšÏ‡

E

Î›(Î´Ï€)âˆšÏ‡

(cid:105)

E

,

(49)

Projected subgradient method

10

Given the space
onto

projection

PS

of program states, let us deï¬ne the
as

S
S

where dF = F (Ï€ + Î´Ï€)
property of the trace, we get

âˆ’

F (Ï€). Then, using the cyclic

dF =

(cid:104)

Î›âˆ—

(cid:104)
âˆšÏ‡

Tr

1
2

(âˆšÏ‡
E

E

Î›(Ï€)âˆšÏ‡

E

)âˆ’

1

2 âˆšÏ‡

E

(cid:105)

(cid:105)

Î´Ï€

. (50)

Exploiting this expression in Eq. (46) we get the gradient
F (Ï€) as in Eq. (45). The other Eq. (44) simply follows

âˆ‡
from applying the deï¬nition in Eq. (8).

For the trace distance, let us write the eigenvalue de-

composition

Ï‡Ï€ âˆ’

Ï‡
E

=

(cid:88)

k

Î»kPk .

(51)

Then using the linearity of Eq. (47), the deï¬nition of
a processor map of Eq. (5) and diï¬€erential calculations
of the trace distance (see Supplementary Note 4.3 for
details), we can write

dC1(Ï€) =

=

(cid:88)

k
(cid:88)

sign(Î»k)Tr[PkÎ›(dÏ€)]

sign(Î»k)Tr[Î›âˆ—(Pk)dÏ€]

k
= Tr

Î›âˆ—[sign(Ï‡Ï€ âˆ’
{
From the deï¬nition of the gradient in Eq. (46), we ï¬nally
get

(52)

)]dÏ€

Ï‡

}

E

.

E
which leads to the result in Eq. (43). (cid:4)

C1(Ï€) = Î›âˆ—[sign(Ï‡Ï€ âˆ’

âˆ‡

Ï‡

)],

(53)

The above results in Eqs. (44) and (43) can be used
together with the projected subgradient method [14]
or conjugate gradient algorithm [15, 16] to iteratively
ï¬nd the optimal program state in the minimization of
minÏ€
In the following sec-
tions we present two algorithms, the projected subgra-
dient method and the conjugate gradient method, and
show how they can be adapted to our problem.

C(Ï€) for C = C1 or CF .

âˆˆS

(cid:0)(cid:15)âˆ’

Projected subgradient methods have the advantage of
simplicity and the ability to optimize non-smooth func-
2(cid:1)
tions, but can be slower, with a convergence rate
O
for a desired accuracy (cid:15). Conjugate gradient meth-
1(cid:1), pro-
(cid:0)(cid:15)âˆ’
ods [15, 16] have a faster convergence rate
vided that the cost function is smooth. This conver-
1/2(cid:1)
gence rate can be improved even further to
for strongly convex functions [57] or using Nesterovâ€™s ac-
celerated gradient method [42]. The technical diï¬ƒculty
in the adaptation of these methods for learning program
states comes because the latter is a constrained optimiza-
tion problem, namely at each iteration step the optimal
program must be a proper quantum state, and the cost
functions coming from quantum information theory are,
generally, non-smooth.

(cid:0)(cid:15)âˆ’

O

O

PS

(X) = argmin

X

S (cid:107)

Ï€

âˆˆ

Ï€

(cid:107)2 ,

âˆ’

(54)

where argmin is the argument of the minimum, namely
to the operator X. Then, a
the closest state Ï€
ï¬rst order algorithm to solve minÏ€
C(Ï€) is to apply the
projected subgradient method [14, 40], which iteratively
applies the iteration (16), which we rewrite below for
convenience

âˆˆ S

âˆˆS

1) Select an operator gi from âˆ‚C(Ï€i),
2) Update Ï€i+1 =

Î±igi) ,

(Ï€i âˆ’

PS

(55)

where i is the iteration index and Î±i a learning rate.

The above algorithm diï¬€ers from standard gradient
i) the update rule is based on
methods in two aspects:
the subgradient, which is deï¬ned even for non-smooth
Î±igi is generally not a
functions; ii) the operator Ï€i âˆ’
quantum state, so the algorithm ï¬xes this issue by pro-
jecting that operator back to the closest quantum state,
via Eq. (54). The algorithm converges to the optimal so-
(approximating the optimal program ËœÏ€) as [14]
lution Ï€
âˆ—

C(Ï€i)

C(Ï€

)

âˆ—

âˆ’

â‰¤

e1 + G (cid:80)i
2 (cid:80)i

k=1 Î±k

k=1 Î±2
k

=: (cid:15),

(56)

Ï€

âˆˆ

2
2 is the initial error (in Frobenius
where e1 =
Ï€1 âˆ’
âˆ—(cid:107)
(cid:107)
2
norm) and G is such that
âˆ‚C. Pop-
G for any g
g
2 â‰¤
(cid:107)
(cid:107)
ular choices for the learning rate that assure convergence
1/âˆšk and Î±k = a/(b + k) for some a, b > 0.
are Î±k âˆ
In general, the projection step is the major drawback,
which often limits the applicability of the projected sub-
gradient method to practical problems. Indeed, projec-
tions like Eq. (54) require another full optimization at
each iteration that might be computationally intensive.
Nonetheless, we show in the following theorem that this
issue does not occur in learning quantum states, because
the resulting optimization can be solved analytically.

Theorem 3. Let X be a Hermitian operator in a d-
dimensional Hilbert space with spectral decomposition
X = U xU â€ , where the eigenvalues xj are ordered in de-
creasing order. Then

(X) of Eq. (54) is given by

PS
where Î¸ = 1
s

PS
(X) = U Î»U â€ , Î»i = max
{

(cid:80)s

j=1 (xj âˆ’

1) and

xi âˆ’

Î¸, 0

,
}

(57)

s = max

ï£±
ï£²

k

ï£³

âˆˆ

[1, ..., d] : xk >

1
k

k
(cid:88)

j=1

(xj âˆ’

ï£¼
ï£½

1)

ï£¾

.

(58)

Proof. Any quantum (program) state can be written
in the diagonal form Ï€ = V Î»V â€  where V is a unitary
matrix, and Î» is the vector of eigenvalues in decreasing

0 and (cid:80)

j Î»j = 1. To ï¬nd the optimal
order, with Î»j â‰¥
state, it is required to ï¬nd both the optimal unitary V
and the optimal eigenvalues Î» with the above property,
i.e.,

(X) = argmin

V,Î»

X
(cid:107)

âˆ’

V Î»V â€ 

(cid:107)2 .

PS

(59)

For any unitarily-invariant norm, the following inequality
holds [58, Eq. IV.64]

(cid:107)

Ï€

Î»

âˆ’

âˆ’

X

(60)

(cid:107)2 ,

x
(cid:107)2 â‰¥ (cid:107)
with equality when U = V , where X = U xU â€  is a spec-
tral decomposition of X such that the xjâ€™s are in de-
creasing order. This shows that the optimal unitary in
Eq. (59) is the diagonalization matrix of the operator X.
The eigenvalues of any density operator form a probabil-
ity simplex. The optimal eigenvalues Î» are then obtained
thanks to Algorithm 1 from Ref. [17]. (cid:4)

In the following section we present an alternative al-
gorithm with faster convergence rates, but stronger re-
quirements on the function to be optimized.

Conjugate gradient method

The conjugate gradient method [15, 40], sometimes
called the Frank-Wolfe algorithm, has been developed to
provide a better convergence speed and to avoid the pro-
jection step at each iteration. Although the latter can be
explicitly computed for quantum states (thanks to our
Theorem 3), having a faster convergence rate is impor-
tant, especially with higher dimensional Hilbert spaces.
The downside of this method is that it necessarily re-
C.
quires a diï¬€erentiable cost function C, with gradient
In its standard form, the conjugate gradient method to
C(Ï€) is deï¬ned by

approximate the solution of argminÏ€
the following iterative rule

âˆ‡

âˆˆS

1) Find argminÏƒ
2) Ï€i+1 = Ï€i + 2

âˆˆS
i+2 (Ïƒ

Tr[Ïƒ

C(Ï€i)],
âˆ‡
Ï€i) = i

i+2 Ï€i + 2

i+2 Ïƒ.

âˆ’

(61)

|

(cid:105)

of

of

âˆ‡

âˆ‡

Ïƒ
|

C(Ï€i),

1) Find the smallest eigenvalue
2) Ï€i+1 = i
i+2 Ï€i + 2
.
Ïƒi|

The ï¬rst step in the above iteration rule is solved by
C(Ï€i). Indeed,
ï¬nding the smallest eigenvector
since Ï€ is an operator and C(Ï€) a scalar, the gradient
C
is an operator with the same dimension as Ï€. Therefore,
for learning quantum programs we ï¬nd the iteration (17),
that we rewrite below for convenience
Ïƒi(cid:105)

Ïƒi(cid:105) (cid:104)
When the gradient of C is Lipschitz continuous with con-
stant L, the conjugate gradient method converges after
(L/(cid:15)) steps [16, 42]. The following iteration with adap-
O
tive learning rate Î±i has even faster convergence rates,
provided that C is strongly convex [57]:
1) Find the smallest eigenvalue
of
Ïƒi(cid:105)
|
C(Ï€i)
Ï„i,
2) Find Î±i = argminÎ±
(cid:104)
âˆ‡
2
Ïƒi| âˆ’
Ï€i,
Ïƒi(cid:105)(cid:104)
C, for Ï„i =
|
.
Ïƒi|
Ïƒi(cid:105) (cid:104)
Î±i)Ï€i + Î±i |

+ Î±2 Î²C
2 (cid:107)
3) Ï€i+1 = (1

[0,1] Î±
âˆˆ

Ï„i(cid:107)
âˆ’

C(Ï€i),

i+2 |

âˆ‡
(cid:105)

(63)

(62)

âˆ‡

11

âˆ‡

where the constant Î²C and norm

(cid:107) Â· (cid:107)C depend on C [57].
In spite of the faster convergence rate, conjugate gra-
dient methods require smooth cost functions (so that the
gradient
C is well deï¬ned at every point). However,
cost functions based on trace distance (7) are not smooth.
For instance, the trace distance in one-dimensional spaces
that is non-
reduces to the absolute value function
analytic at x = 0. When some eigenvalues are close
to zero, conjugate gradient methods may display unex-
pected behaviors, though we have numerically observed
that convergence is always obtained with a careful choice
In the next section we show how
of the learning rate.
to formally justify the applicability of the conjugate gra-
dient method, following Nesterovâ€™s smoothing prescrip-
tion [42].

x

|

|

Smoothing: smooth trace distance

O

(cid:0) L
(cid:15)

The conjugate gradient method converges to the global
(cid:1) steps, provided that the gradient
optimum after
of C is L-Lipschitz continuous [42]. However, the con-
stant L can diverge for non-smooth functions like the
trace distance (7) so the convergence of the algorithm
cannot be formally stated, although it may still be ob-
served in numerical simulations. To solidify the conver-
gence proof (see also Supplementary Note 5.2), we intro-
duce a smooth approximation to the trace distance. This
is deï¬ned by the following cost function that is diï¬€eren-
tiable at every point

CÂµ(Ï€) = Tr [hÂµ (Ï‡Ï€ âˆ’

Ï‡

E

)] =

(cid:88)

j

hÂµ(Î»j) ,

(64)

where Î»j are the eigenvalues of Ï‡Ï€ âˆ’
so-called Huber penalty function

Ï‡
E

and hÂµ is the

hÂµ(x) :=

(cid:40) x2
2Âµ
x
|

| âˆ’

Âµ
2

if
if

x
|
x
|

< Âµ ,
Âµ .

|
| â‰¤

(65)

The previous deï¬nition of the trace distance, C1 in
Eq. (7), is recovered for Âµ
0 and, for any non-zero
â†’
Âµ, the CÂµ bounds C1 as follows

CÂµ(Ï€)

C1(Ï€)

â‰¤

â‰¤

CÂµ(Ï€) +

Âµd
2

,

(66)

where d is the dimension of the program state Ï€. In Sup-
plementary Note 5.2 we then prove the following result

Theorem 4. The smooth cost function CÂµ(Ï€) is a convex
function over program states and its gradient is given by

CÂµ(Ï€) = Î›âˆ—[h(cid:48)Âµ(Ï‡Ï€ âˆ’
where h(cid:48)Âµ is the derivative of hÂµ. Moreover, the gradient
is L-Lipschitz continuous with

(67)

)],

âˆ‡

Ï‡

E

L =

d
Âµ

,

(68)

where d is the dimension of the program state.

O

Being Lipschitz continuous, the conjugate gradient al-
gorithm and its variants [42, 57] converge up to an ac-
(L/(cid:15)) steps. In some applications, it is
curacy (cid:15) after
desirable to analyze the convergence in trace distance in
the limit of large program states, namely for d
.
â†’ âˆ
The parameter Âµ can be chosen such that the smooth
trace distance converges to the trace distance, namely
. Indeed, given the inequality (66),
CÂµ â†’
(1+Î·)) for some Î· > 0 so
a possibility is to set Âµ =
O
that, from Eq. (68), the convergence to the trace norm is

C1 for d

â†’ âˆ

(dâˆ’

12

achieved after

(d2+Î·) steps.

O

Acknowledgements.
L.B. acknowledges support
by the program â€œRita Levi Montalciniâ€ for young re-
searchers. S.P. and J.P. acknowledge support by the
EPSRC via the â€˜UK Quantum Communications Hubâ€™
(Grants EP/M013472/1 and EP/T001011/1) and S.P.
acknowledges support by the European Union via the
project â€˜Continuous Variable Quantum Communicationsâ€™
(CiViQ, no 820466).

[1] M. A. Nielsen and I. L. Chuang, â€œProgrammable quan-
tum gate arrays,â€ Phys. Rev. Lett. 79, 321 (1997).
[2] M. A. Nielsen and I. L. Chuang, Quantum Computation
and Quantum Information (Cambridge University Press,
Cambridge, 2000).

[3] J. Watrous, The theory of quantum information (Cam-
bridge Univ. Press, 2018) freely available at https://cs.
uwaterloo.ca/~watrous/TQI/.

[4] E. Knill, R. Laï¬‚amme, and G. J Milburn, â€œA scheme
for eï¬ƒcient quantum computation with linear optics,â€
Nature 409, 46 (2001).

[5] C. M. Bishop, Pattern Recognition and Machine Learning

(Springer, 2006).

[6] P. Wittek, Quantum Machine Learning: What Quantum
Computing Means to Data Mining (Academic Press, El-
sevier, 2014).

[7] J Biamonte, P. Wittek, N. Pancotti, P. Rebentrost,
N. Wiebe, and S. Lloyd, â€œQuantum machine learning,â€
Nature (London) 549, 195 (2017).

[8] V. Dunjko and H. J. Briegel, â€œMachine learning & ar-
tiï¬cial intelligence in the quantum domain: a review
of recent progress,â€ Reports on Progress in Physics 81,
074001 (2018).

[9] M. Schuld, I. Sinayskiy, and F. Petruccione, â€œAn intro-
duction to quantum machine learning,â€ Contemporary
Physics 56, 172â€“185 (2015).

[10] C. Ciliberto, M. Herbster, Alessandro D.

Ialongo,
M. Pontil, A. Rocchetto, S. Severini, and L. Wossnig,
â€œQuantum machine learning: a classical perspective,â€
Proceedings of the Royal Society A: Mathematical, Phys-
ical and Engineering Sciences 474, 20170551 (2018).
[11] E Tang, â€œA quantum-inspired classical algorithm for rec-
ommendation systems,â€ arXiv preprint arXiv:1807.04271
(2018).

[12] E Tang, â€œQuantum-inspired classical algorithms for prin-
cipal component analysis and supervised clustering,â€
arXiv preprint arXiv:1811.00414 (2018).

[13] A. Y. Kitaev, A. Shen, and M. N. Vyalyi, Classical and
quantum computation, 47 (American Mathematical Soci-
ety, Providence, Rhode Island, 2002) sec. 11.

[14] S. Boyd, L. Xiao, and A. Mutapcic, Subgradient methods

(2003).

[15] M. Jaggi, â€œConvex optimization without projection

steps,â€ arXiv preprint arXiv:1108.1170 (2011).

[16] M. Jaggi, â€œRevisiting frank-wolfe: projection-free sparse
convex optimization,â€ in Proceedings of the 30th Inter-
national Conference on International Conference on Ma-

chine Learning-Volume 28 (JMLR. org, 2013) pp. Iâ€“427.
[17] J. Duchi, S. Shalev-Shwartz, Y. Singer, and T. Chan-
dra, â€œEï¬ƒcient projections onto the l 1-ball for learning
in high dimensions,â€ in Proceedings of the 25th interna-
tional conference on Machine learning (ACM, 2008) pp.
272â€“279.

[18] J. Liu, P. Musialski, P. Wonka,

and J. Ye, â€œTensor
completion for estimating missing values in visual data,â€
IEEE transactions on pattern analysis and machine in-
telligence 35, 208â€“220 (2013).

[19] S. Ishizaka and T. Hiroshima, â€œAsymptotic teleportation
scheme as a universal programmable quantum proces-
sor,â€ Phys. Rev. Lett. 101, 240501 (2008).

[20] S. Ishizaka and T. Hiroshima, â€œQuantum teleportation
scheme by selecting one of multiple output ports,â€ Phys.
Rev. A 79, 042306 (2009).

[21] S. Ishizaka, â€œSome remarks on port-based teleportation,â€

arXiv preprint arXiv:1506.01555 (2015).

[22] S Lloyd, â€œUniversal quantum simulators,â€ Science , 1073â€“

1078 (1996).

[23] S. Pirandola, R. Laurenza, C. Ottaviani, and L. Banchi,
â€œFundamental limits of repeaterless quantum communi-
cations,â€ Nat. Commun. 8, 15043 (2017).

[24] S. Pirandola, S. L. Braunstein, R. Laurenza, C. Otta-
and L. Banchi,
viani, T. P. W. Cope, G. Spedalieri,
â€œTheory of channel simulation and bounds for private
communication,â€ Quant. Sci. Tech. 3, 035009 (2018).

[25] I. Nechita, Z. Pucha(cid:32)la, (cid:32)L. Pawela, and K.

Ë™Zyczkowski,
â€œAlmost all quantum channels are equidistant,â€ J. Math.
Phys. 59, 052201 (2018).

[26] C. A. Fuchs and J. van de Graaf, â€œCryptographic distin-
guishability measures for quantum-mechanical states,â€
IEEE Trans. Info. Theory 45, 1216â€“1227 (1999).

[27] M. S. Pinsker, Information and information stability of
random variables and processes (Holden-Day, San Fran-
cisco, 1964).

[28] E. A. Carlen and E. H. Lieb, â€œBounds for entanglement
via an extension of strong subadditivity of entropy,â€ Lett.
Math. Phys. 101, 1â€“11 (2012).

[29] John Watrous, â€œSemideï¬nite programs for completely
bounded norms,â€ Theory OF Computing 5, 217â€“238
(2009).

[30] John Watrous, â€œSimpler semideï¬nite programs for com-
pletely bounded norms,â€ Chicago Journal OF Theoreti-
cal Computer Science 8, 1â€“19 (2013).

[31] J. Watrous, â€œSimpler semideï¬nite programs for com-
pletely bounded norms,â€ Chicago Journal of Theoretical

Computer Science 8, 1â€“19 (2013).

[32] Lieven Vandenberghe and Stephen Boyd, â€œSemideï¬nite

programming,â€ SIAM review 38, 49â€“95 (1996).

[33] Hsiao-Han Chao, First-Order Methods for Trace Norm
Minimization, Masterâ€™s thesis, University of California,
Los Angeles (2013).

[34] Renato DC Monteiro, â€œFirst-and second-order methods
for semideï¬nite programming,â€ Mathematical Program-
ming 97, 209â€“244 (2003).

[35] James C Spall, â€œAdaptive stochastic approximation by
the simultaneous perturbation method,â€ IEEE transac-
tions on automatic control 45, 1839â€“1853 (2000).

[36] Quntao Zhuang and Zheshen Zhang, â€œPhysical-layer su-
pervised learning assisted by an entangled sensor net-
work,â€ Physical Review X 9, 041023 (2019).

[37] Aram Harrow and John Napp, â€œLow-depth gradient
measurements can improve convergence in variational
hybrid quantum-classical algorithms,â€ arXiv preprint
arXiv:1901.05374 (2019).

[38] Jian-Feng Cai, Emmanuel J Cand`es, and Zuowei Shen,
â€œA singular value thresholding algorithm for matrix com-
pletion,â€ SIAM Journal on optimization 20, 1956â€“1982
(2010).

[39] Benjamin Recht, Maryam Fazel, and Pablo A Parrilo,
â€œGuaranteed minimum-rank solutions of linear matrix
equations via nuclear norm minimization,â€ SIAM review
52, 471â€“501 (2010).

[40] Y. Nesterov, Introductory lectures on convex optimiza-
tion: A basic course, Vol. 87 (Springer Science & Busi-
ness Media, New York, 2013).

[41] B. Coutts, M. Girard, and J. Watrous, â€œCertifying op-
timality for convex quantum channel optimization prob-
lems,â€ arXiv preprint arXiv:1810.13295 (2018).

[42] Y. Nesterov, â€œSmooth minimization of non-smooth func-
tions,â€ Mathematical programming 103, 127â€“152 (2005).
[43] The downside of the conjugate gradient method is that
it necessarily requires a diï¬€erentiable cost function C,
with gradient âˆ‡C. Speciï¬cally, this may create prob-
lems for the trace distance cost C1 which is generally
non-smooth. A solution to this problem is to deï¬ne
the cost function in terms of the smooth trace distance
CÂµ(Ï€) = Tr [hÂµ (Ï‡Ï€ âˆ’ Ï‡E )] where hÂµ is the so-called Hu-
ber penalty function hÂµ(x) := x2/(2Âµ) if |x| < Âµ and
|x| âˆ’ Âµ/2 if |x| â‰¥ Âµ. This quantity satisï¬es CÂµ(Ï€) â‰¤
C1(Ï€) â‰¤ CÂµ(Ï€) + Âµd/2 and is a convex function over pro-
gram states, with gradient âˆ‡CÂµ(Ï€) = Î›âˆ—[h(cid:48)
Âµ(Ï‡Ï€ âˆ’ Ï‡E )].
[44] N. Khaneja, T. Reiss, C. Kehlet, T. Schulte-HerbrÂ¨uggen,
and S. J. Glaser, â€œOptimal control of coupled spin dy-
namics: design of nmr pulse sequences by gradient ascent
algorithms,â€ Journal of magnetic resonance 172, 296â€“305
(2005).

[45] L. Banchi, N. Pancotti, and S. Bose, â€œQuantum gate
learning in qubit networks: Toï¬€oli gate without time-
dependent control,â€ npj Quantum Information 2, 16019
(2016).

[46] L.

Innocenti, L. Banchi, A. Ferraro,

S. Bose,
and M. Paternostro, â€œSupervised learning of time-
independent hamiltonians
for gate design,â€ arXiv
preprint arXiv:1803.07119 (2018).
[47] K. Mitarai, M. Negoro, M. Kitagawa,

and K. Fu-
jii, â€œQuantum circuit learning,â€ Physical Review A 98,
032309 (2018).

13

quantum state via dual classical and einstein-podolsky-
rosen channels,â€ Phys. Rev. Lett. 70, 1895 (1993).
[49] S. Pirandola, J. Eisert, C. Weedbrook, A. Furusawa, and
S. L. Braunstein, â€œAdvances in quantum teleportation,â€
Nat. Photon. 9, 641â€“652 (2015).

[50] Stefano Pirandola, Riccardo Laurenza, Cosmo Lupo,
and Jason L Pereira, â€œFundamental limits to quantum
channel discrimination,â€ npj Quantum Information 5, 1â€“
8 (2019).

[51] S. Lloyd, â€œAlmost any quantum logic gate is universal,â€

Phys. Rev. Lett. 75, 346 (1995).

[52] For the PQC processor we use the universal Hamil-
2(X âŠ— Y âˆ’ Y âŠ— X) and H1 =
2Z), where X, Y , and Z

5X) âŠ— (Y +

2Z+

âˆš

âˆš

tonians H0 =
âˆš
âˆš
âˆš
(
are Pauli operators.

3Y +

[53] Giacomo Mauro DAriano and Paolo Perinotti, â€œEï¬ƒcient
universal programmable quantum measurements,â€ Phys-
ical review letters 94, 090401 (2005).

[54] S. Pirandola, B. R. Bardhan, T. Gehring, C. Weedbrook,
and S. Lloyd, â€œAdvances in photonic quantum sensing,â€
Nat. Photon. 12, 724â€“733 (2018).

[55] A. Uhlmann, â€œThe transition probability...â€ Rep. Math.

Phys. 9, 273â€“279 (1976).

[56] J. Duchi, E. Hazan, and Y. Singer, â€œAdaptive subgradi-
ent methods for online learning and stochastic optimiza-
tion,â€ Journal of Machine Learning Research 12, 2121â€“
2159 (2011).

[57] D. Garber and E. Hazan, â€œFaster rates for the frank-wolfe
method over strongly-convex sets,â€ in Proceedings of the
32nd International Conference on International Confer-
ence on Machine Learning-Volume 37 (JMLR. org, 2015)
pp. 541â€“549.

[58] R. Bhatia, Matrix analysis, Vol. 169 (Springer Science &

Business Media, New York, 2013).

[59] G. Bowen and S. Bose, â€œTeleportation as a depolarizing
quantum channel, relative entropy, and classical capac-
ity,â€ Phys. Rev. Lett. 87, 267901 (2001).

[60] T. P. W. Cope, L. Hetzel, L. Banchi, and S. Pirandola,
â€œSimulation of non-pauli channels,â€ Phys. Rev. A 96,
022323 (2017).

[61] C. H. Bennett, D. P. DiVincenzo, J. A. Smolin, and
W. K. Wootters, â€œMixed-state entanglement and quan-
tum error correction,â€ Phys. Rev. A 58, 3824 (1996).
[62] S. Boixo, S. V. Isakov, V. N. Smelyanskiy, R. Babbush,
N. Ding, Z. Jiang, M. J. Bremner, J. M. Martinis, and
H. Neven, â€œCharacterizing quantum supremacy in near-
term devices,â€ Nat. Phys. 14, 595 (2018).

[63] Seth Lloyd, Masoud Mohseni,

and Patrick Reben-
trost, â€œQuantum principal component analysis,â€ Nature
Physics 10, 631 (2014).

[64] E. Stickel, â€œOn the frÂ´echet derivative of matrix func-
tions,â€ Linear Algebra and its Applications 91, 83â€“88
(1987).

[65] S. N. Ravi, M. D. Collins, and V. Singh, â€œA determinis-
tic nonsmooth frank wolfe algorithm with coreset guar-
antees,â€ arXiv preprint arXiv:1708.06714 (2017).

[66] F. Youseï¬an, A. NediÂ´c,

and U. V. Shanbhag, â€œOn
stochastic gradient and subgradient methods with adap-
tive steplength sequences,â€ Automatica 48, 56â€“67 (2012).
[67] G. Lan, â€œThe complexity of large-scale convex program-
ming under a linear optimization oracle,â€ arXiv preprint
arXiv:1309.5550 (2013).

[48] C. H. Bennett, G. Brassard, C. CrÂ´epeau, R. Jozsa,
A. Peres, and W. K. Wootters, â€œTeleporting an unknown

[68] M. Christandl, F. Leditzky, C. Majenz, G. Smith,
and M. Walter, â€œAsymptotic perfor-

F. Speelman,

mance of port-based teleportation,â€ arXiv preprint
arXiv:1809.10751 (2018).

14

Supplementary Materials

15

1. MORE ON PROGRAMMABLE SIMULATION

E

As discussed in the main text, the task we are inter-
ested in is the simulation of a channel
using a pro-
grammable quantum processor [1] that we simply call a
â€œquantum processorâ€ (see Fig. 6). This is represented by
a completely positive trace-preserving (CPTP) universal
map Q as in Eq. (1). Our goal is to ï¬nd the program
state Ï€ according to (3), namely the state for which the
simulation
. The most appropriate
deï¬nition of â€œclosenessâ€ between two quantum channels
is via the diamond norm C
2. Re-
(cid:5)
call that the diamond distance is deï¬ned by the following
maximization

EÏ€ is the closest to

(cid:107)E âˆ’ EÏ€(cid:107)(cid:5) â‰¤

(Ï€) :=

E

(cid:107)E âˆ’ EÏ€(cid:107)(cid:5)

= max

Ï• (cid:107)I âŠ— E

(Ï•)

âˆ’ I âŠ— EÏ€(Ï•)

(cid:107)1 ,

(S1)

(cid:107)

O

(cid:107)1 := TrâˆšOâ€ O is the trace norm [3]. Because
where
the trace norm is convex over mixed states, one may
reduce the maximization in Eq. (S1) to bipartite pure
states Ï• =
. In general, we therefore need to con-
Ï•
|
sider a min-max optimization, i.e., ï¬nd ËœÏ€ and (pure) ËœÏ•
such that

Ï•
|

(cid:105) (cid:104)

(cid:107)I âŠ— E
= min

Ï€

( ËœÏ•)
max

âˆ’ I âŠ— EËœÏ€( ËœÏ•)
(Ï•)

Ï• (cid:107)I âŠ— E

(cid:107)1
âˆ’ I âŠ— EÏ€(Ï•)

(cid:107)1 .

(S2)

the input state Ï and the program Ï€. We may asso-
ciate to these measurement devices two measurement
channels
is
j
(cid:105)(cid:104)
the probability of getting the outcome j, and similarly

, where pj = Tr[ÏÎ j]

(Ï) = (cid:80)

j

|

EÏ€(Ï) = (cid:80)

j pj|
, where

E
j pÏ€
j
j |
|
pÏ€
j = Tr[ÏÎ Ï€

(cid:105)(cid:104)

j

j ] = Tr
2

[Qj(Ï

Ï€)] ,

âŠ—

(S3)

is the probability of getting the outcome j using the
programmable measurement Î Ï€
j . The above discussion
shows that programmable quantum measurements rep-
resent a particular instance of the general case that we
consider for arbitrary channels, so we may optimize the
program state Ï€ with the techniques presented in our
paper.

Note that we may also consider a diï¬€erent cost func-
tion, namely the worst-case distance between the two
probability distributions given by

CM (Ï€) = max

Ï

(cid:88)

j

pj âˆ’

|

pÏ€
j |

.

(S4)

Qj}
{

such that Î Ï€

It was shown in [53] that there exist (ï¬xed) universal
POVMs
j approximates any arbitrary
measurement Î j with an optimal program Ï€. The error
in the approximation, as quantiï¬ed by CM , decreases
with the dimension of the program. Via the measurement
channels deï¬ned above, it is easy to see that

1.1. Programmable quantum measurements

Programmable quantum measurements [53] represent
a particular instance of the general channel approxima-
tion problem, where the channel approximates a mea-
surement device. Consider a POVM
and a pro-
Î j}
{
Î Ï€
with program Ï€ which is ob-
grammable POVM
j }
{
tained by performing a ï¬xed joint POVM
on both

Qj}
{

CM (Ï€) = max

Ï (cid:107)E

(Ï)

âˆ’ EÏ€(Ï)

(cid:107)1 â‰¤

C
(cid:5)

(Ï€) ,

(S5)

so that our theory includes the results of [53] as a special
case.

1.2. SDP minimization

We show that some of the convex cost functions that
we have introduced can be explicitly evaluated via semi-
deï¬nite programming (SDP). This allows us to use stan-
dard SDP algorithms for ï¬nding the optimal program.

We ï¬rst ï¬x the program state Ï€ and show how for
ï¬xed Ï€ it is possible to compute C
(Ï€) via semideï¬nite
(cid:5)
programming. Let us introduce the linear map â„¦Ï€ :=
E âˆ’ EÏ€ with corresponding Choi matrix
Ï‡â„¦Ï€ = Ï‡

Ï‡Ï€ = Ï‡

Î›(Ï€).

(S6)

E âˆ’

E âˆ’

FIG. 6. Arbitrary quantum channel E and its simulation EÏ€
via a quantum processor Q applied to a program state Ï€.

Thanks to the property of strong duality of the diamond
norm, for any program Ï€ we can compute the cost func-

QÏ€Ï€ (cid:1)tion C
(cid:5)

(Ï€) =

â„¦Ï€(cid:107)(cid:5)
(cid:107)
1
2

Minimize

via the following SDP [29]

(

Tr2M0(cid:107)âˆ
(cid:107)
(cid:18) M0

+

Tr2M1(cid:107)âˆ
(cid:19)

(cid:107)
d Ï‡â„¦Ï€

) ,

Subject to

âˆ’

0,

(S7)

d Ï‡â€ â„¦Ï€ M1
d(cid:48)
0 in Cd

âˆ’
0 and M1 â‰¥
equals the maximum singular value of O.

, and the spectral

â‰¥

Ã—

where M0 â‰¥
O
norm
(cid:107)âˆ
(cid:107)

Moreover, because Ï‡â„¦Ï€ is Hermitian, the above SDP

can be simpliï¬ed into

Minimize 2

Subject to Z

â‰¥

Tr2Z
(cid:107)
0 and Z

(cid:107)âˆ
â‰¥

,
d Ï‡â„¦Ï€ .

(S8)

(Ï€),

[25].

does

In fact,

procedure

Ï‡
Tr2 |
(cid:107)

compute C
(cid:5)
(Ï€)

â„¦Ï€ , where Ï‡+ = (Ï‡ +

Not
only
this
the upper bound C
but
it also provides
â‰¤
(cid:5)
it is suï¬ƒcient to
d
Ï‡Ï€|(cid:107)âˆ
E âˆ’
choose Z = d Ï‡+
)/2 is the
|
positive part of Ï‡. Using Tr2Ï‡â„¦Ï€ = 0, we may write
.
Ï‡â„¦Ï€ |
Tr2Z
The SDP form in Eq. (S8) is particularly convenient for
ï¬nding the optimal program. In fact, suppose now that
Ï€ is not ï¬xed but we want to optimize on this state too,
so as to compute the optimal program state ËœÏ€ such that
(Ï€). The problem is therefore mapped
ËœÏ€ = argminÏ€
into the following unique minimization

â„¦Ï€ = d

dTr2Ï‡+

2 Tr2|

Ï‡
|

â‰¤

âˆˆS

C

(cid:5)

Subject to Z

â‰¥

Minimize 2
0, Ï€

Tr2Z
(cid:107)
0, Tr(Ï€) = 1, Z

(cid:107)âˆ

,

â‰¥

d Ï‡â„¦Ï€ . (S9)

â‰¥

Unlike the min-max optimization of Eq. (S2), the above
SDP is much simpler as it contains a unique minimiza-
tion. Therefore, this algorithm can be used to optimize
the performance of any programmable quantum proces-
sor.

Using a similar argument, and exploiting known con-
vex programming formulations for the trace norm and
the ï¬delity cost [30, 39], we can also compute the op-
timal program states ËœÏ€ as ËœÏ€1 = argminÏ€
SC1(Ï€) and
ËœÏ€F = argmaxÏ€
SF (Ï€). Note indeed that, clearly, the ï¬-
âˆˆ
delity has to be maximized, rather than minimized. The
optimal program ËœÏ€1 and its associated cost C1(ËœÏ€1) can
be computed with the following minimization

âˆˆ

minimize Tr[P + Q] ,

(S10)
0, Tr[Ï€] = 1 .

subject to Ï‡â„¦Ï€ = P

Q, P

0, Q

0, Ï€

â‰¥
The optimal program ËœÏ€F and its associated cost F (ËœÏ€F )
can be computed with the following maximization

âˆ’

â‰¥

â‰¥

(cid:18)Ï‡

maximize
(cid:19)

X
X â€  Ï‡â„¦Ï€

E

Tr[X + X â€ ]
2

,

0, Ï€

â‰¥

â‰¥

0, Tr[Ï€] = 1 .

(S11)

subject to

16

per. For example, we may connect the minimization of
the diamond distance C
(Ï€) to the minimization of the
(cid:5)
trace distance C1(Ï€) via the sandwich relation [3]

C1(Ï€)

(Ï€)

C
(cid:5)

â‰¤

â‰¤

d C1(Ï€).

(S12)

While the lower bound is immediate from the deï¬nition
of Eq. (S1), the upper bound can be proven using the
following equivalent form of the diamond distance

d

E âˆ’

11)(Ï‡

= sup
Ï0,Ï1

(cid:107)E âˆ’ EÏ€(cid:107)(cid:5)

(âˆšÏ0 âŠ—
(cid:107)

Ï‡Ï€)(âˆšÏ1 âŠ—

(cid:107)1,
(S13)
where the optimization is carried out over the density
matrices Ï0 and Ï1 [31, Theorem 3.1]. In fact, consider
the Frobenius norm
Tr[Aâ€ A] and the spectral
norm

(cid:107)2 :=

A
(cid:107)

11)

(cid:112)

A
(cid:107)

:= max

Au

: u

(cid:107)âˆ

{(cid:107)
which satisfy the following properties [3]

âˆˆ

(cid:107)

(cid:107) â‰¤

Cd,

u
(cid:107)

ABC
(cid:107)
11
A
(cid:107)

A
(cid:107)1 â‰¤ (cid:107)
A
=
(cid:107)
(cid:107)âˆ

âŠ—

B

(cid:107)1(cid:107)
A

(cid:107)âˆ(cid:107)
(cid:107)âˆ â‰¤ (cid:107)

C
(cid:107)2.

(cid:107)âˆ

1

,
}

,

(S14)

(S15)
(S16)

Then, from Eqs. (S13), (S15) and (S16), one gets

(cid:112)

d

E âˆ’

E âˆ’

(S17)

Ï‡Ï€(cid:107)1

(cid:107)E âˆ’ EÏ€(cid:107)(cid:5) â‰¤

sup
Ï0,Ï1
Ï‡
= d
(cid:107)

TrÏ0TrÏ1(cid:107)
Ï‡
Ï‡Ï€(cid:107)1.
Thanks to Eq. (S12), we may avoid the maximization
step in the deï¬nition of the diamond distance and sim-
plify the original problem to approximating the Choi ma-
of the channel by varying the program state Ï€.
trix Ï‡
E
This is a process of learning Choi matrices as depicted
in Fig. 7. Because the simpler cost function C1(Ï€) is
an upper bound, its minimization generally provides a
sub-optimal solution for the program state.

Finally we may consider other cost functions in terms
of any Shatten p-norm Cp(Ï€) :=
Ï‡Ï€(cid:107)p, even
though this option provides lower bounds instead of up-
per bounds for the trace distance. Recall that, given an
operator O and a real number p
1, we may deï¬ne its
Schatten p-norm as [3]

Ï‡
(cid:107)

E âˆ’

â‰¥

(S18)

O

(cid:107)p = (Tr

O
|

(cid:107)

|
= âˆšOâ€ O. For any 1

p)1/p,

|

where
O
|
has the monotony
O
(cid:107)
of operators A and B, and each pair of parameters p, q
[1,

O
â‰¤
(cid:107)1. An important property is duality. For each pair
âˆˆ

p
â‰¤
â‰¤
(cid:107)q, so that
(cid:107)

1 = 1, we may write [3]

â‰¤ âˆ
(cid:107)âˆ â‰¤

] such that pâˆ’

, one
. . .

(cid:107)p â‰¥ (cid:107)

1 + qâˆ’

q
O

O

(cid:107)

âˆ

1.3. Cost functions and their relative dependence

A

(cid:107)

(cid:107)p = sup

B

(cid:107)

(cid:107)qâ‰¤

1 |(cid:104)

B, A

(cid:105)| â‰¡

sup
B
(cid:107)qâ‰¤

(cid:107)

B, A
(cid:105)

,

1 (cid:104)

(S19)

For completeness, we report here some inequalities be-
tween the diï¬€erent cost functions introduced in the pa-

B, A
(cid:105)
(cid:104)

where
= Tr(Bâ€ A) is the Hilbert-Schmidt product,
and the second inequality follows since we can arbitrarily
change the sign of B.

17

O

((cid:15)âˆ’

1/2). On the other hand, there are no obvi-
rate
ous simpliï¬cations for the optimization of the trace dis-
tance, since the latter still requires the diagonalization of
Eq. (51). For the trace distance, or its smooth version,
only numerical approaches are feasible.

3. APPLICATIONS

3.1. Learning a unitary with the teleportation
processor

Here we consider the following example. Assume that
the target channel is a unitary U , so that its Choi matrix
is Ï‡U :=
Î¦
Ï‡U (cid:105)
Ï‡U (cid:105)(cid:104)
(cid:105)
|
|
|
is maximally entangled. By using Eq. (20), the fact that
Î›tele = Î›âˆ—tele and U âˆ—
, we may write
Î¦
|
âŠ—
the dual processor map

and where

Ï‡U |

with

= 11

= 11

Î¦
|

Î¦
|

U â€ 

âŠ—

âŠ—

U

11

(cid:105)

(cid:105)

(cid:105)

Î›âˆ—tele[
|
1
d2

=

]
Ï‡U |
Ï‡U (cid:105)(cid:104)
(cid:88)
(cid:0)11

i

(cid:1)

V U
i

Î¦
|

Î¦

(cid:105)(cid:104)

|

(cid:0)11

âŠ—

V U
i

(cid:1)â€  ,

(S22)

âŠ—

Ï‡U |

where V U
i = UiU U â€ i . The maximum eigenvector of
] represents the optimal program state ËœÏ€F
Ï‡U (cid:105)(cid:104)
Î›âˆ—tele[
|
for simulating the unitary U via the teleportation pro-
cessor (according to the ï¬delity cost function). In some
cases, the solution is immediate. For instance, this hap-
pens when V U
U is independent of i. This is the case
when U is a teleportation unitary, because it satisï¬es the
Weyl-Heisenberg algebra [23]. For a teleportation uni-
tary U , we simply have
Ï‡U (cid:105)(cid:104)
|
so that the unique optimal program is ËœÏ€F =

Ï‡U (cid:105)(cid:104)

Ï‡U |

Ï‡U |

i âˆ

Î›âˆ—[

] =

,

|

In Fig. 8 we show the convergence of the projected
subgradient algorithm using the teleportation processor
and target unitaries R(Î¸) = eiÎ¸X , for diï¬€erent values of
Î¸. When Î¸ is a multiple of Ï€/2, then the above unitary
is teleportation covariant and the Frank-Wolfe algorithm
converges to zero trace distance. For other values of Î¸
perfect simulation is impossible, and we notice that the
algorithm converges to a non zero value of the trace dis-
tance (7). For comparison, in Fig. 8 we also plot the
]2,
value of the ï¬delity upper bound
where ËœÏ€F is the optimal program that maximizes the ï¬-
delity of Eq. (9), namely the eigenvector of Eq. (S22) with
the maximum eigenvalue. We note that for Î¸ = Ï€/2(cid:96),
the trace distance decreases for larger Î¸. The limit case
(cid:96)
is perfectly simulable as R(0) is teleportation
â†’ âˆ
covariant.

F [Î›(ËœÏ€F ), Ï‡
E

(cid:112)
1

âˆ’

(S23)
.
Ï‡U |

Ï‡U (cid:105)(cid:104)

|

3.2. Pauli channel simulation

Pauli channels are deï¬ned as [2]

(Ï) =

P

(cid:88)

i

piUiÏU â€ i

,

(S24)

FIG. 7. Map of the processor and learning of Choi matri-
ces. Consider an arbitrary (but known) quantum channel E
and its associated Choi matrix Ï‡E , generated by propagat-
ing part of a maximally-entangled state Î¦. Then, consider a
quantum processor Q with program state Ï€ which generates
the simulated channel EÏ€ and, therefore, the corresponding
Choi matrix Ï‡Ï€ := Ï‡EÏ€ upon propagating part of Î¦ as the
input state. The map of the processor is the CPTP map
Î› from the program state Ï€ to the output Choi matrix Ï‡Ï€.
In a simpliï¬ed version of our problem, we may optimize the
program Ï€ in such a way as to minimize the trace distance
C1(Ï€) := (cid:107)Ï‡E âˆ’ Ï‡Ï€(cid:107)1.

2. CONVERGENCE IN LEARNING
ARBITRARY UNITARIES

The simulation of quantum gates or, more generally,
unitary transformations is crucial for quantum comput-
ing applications [22] so ML techniques have been devel-
oped for this purpose [45â€“47]. In the main text we have
shown that, for learning arbitrary unitaries, the ï¬delity
cost function provides a convenient choice for which the
optimal program can be found analytically. Indeed, the
optimal program is always a pure state and is given by
Ï‡U (cid:105)(cid:104)
the eigenstate of Î›âˆ— [
] with the maximum eigen-
Ï‡U |
|
value. Here we consider the convergence of the Frank-
Wolfe iteration Eq. (17) towards that state.

Let Ï€1 be the initial guess for the program state. After
k iterations of Eq. (17), we ï¬nd the following approxima-
tion to the optimal program state

Ï€k =

2

k + k2 Ï€1 +

(cid:18)

2
k + k2

1

âˆ’

(cid:19)

ËœÏ€F ,

(S20)

where
Ï€k â†’

2

k+k2 = (cid:81)k
ËœÏ€F for k

1
âˆ’
j=1

â†’ âˆ

j
j+2 . The above equation shows that
, with error in trace distance

Ï€k âˆ’

(cid:107)

ËœÏ€F (cid:107)1 =

2
k + k2 (cid:107)

Ï€1 âˆ’

ËœÏ€F (cid:107)1 =

O

(kâˆ’

2) .

(S21)

This example shows that the convergence rate

1)
of the conjugate method provides a worst case instance
that can be beaten in some applications with some suit-
2
able cost functions. From Eq. (S21) we see that (cid:15) = kâˆ’
for learning arbitrary unitaries via the minimization of
CF , meaning that convergence is obtained with the faster

((cid:15)âˆ’

O

Q ï° Î¦ â„°ğœ‹ Î¦ ğœ’â„° ğœ’ğœ‹ â„° Î› 18

FIG. 9. PBT Simulation of the amplitude damping channel
EAD for various damping rates p. Minimization of the trace
distance C1(EAD, Ï€) = (cid:107)Ï‡EAD âˆ’Ï‡Ï€(cid:107)1 between the target chan-
nelâ€™s Choi matrix and its PBT simulation with program state
Ï€, for diï¬€erent number of ports N . We consider N = 1, 2, 3
and two kinds of programs: copies of the channelâ€™s Choi ma-
trix Ï‡âŠ—N
and the state ËœÏ€1 obtained from the minimization
EAD
of C1 via the projected subgradient (PS) method after 200
iterations. Note that the simulation error C1 is maximized
for the identity channel (p = 0) and goes to zero for p â†’ 1.

From theory [59â€“61] we know that only Pauli chan-
nels can be perfectly simulated in this way. No mat-
ter how much more general we make the states Ï€, it is
proven [59, 60] that these are the only channels we can
perfectly simulate. This is true even if we apply the Pauli
corrections in a probabilistic way, i.e., we assume a classi-
cal channel from the Bell outcomes to the corresponding
label of the Pauli correction operator [60].

3.3. PBT: Numerical examples

FIG. 8. Optimization of program states for simulating
the rotation R(Î¸) = eiÎ¸X with a teleportation processor.
The optimization is via the minimization of trace distance
C1 of Eq. (7) with the projected subgradient method in
Eq. (16). The dashed lines correspond to the upper bound
(cid:112)1 âˆ’ F [Î›(ËœÏ€F ), Ï‡E ]2 of the trace distance, where ËœÏ€F is the op-
timal program that maximizes the ï¬delity, namely the eigen-
vector of Î›âˆ—[|Ï‡U (cid:105)(cid:104)Ï‡U |] with the maximum eigenvalue.

where Ui are generalized Pauli operators and pi are some
probabilities. For d = 2 the Pauli operators are the four
Pauli matrices I, X, Y, Z and in any dimension they form
the Weyl-Heisenberg group [2]. These operators are ex-
actly the teleportation unitaries Uj deï¬ned in the previ-
ous section. The Choi matrix Ï‡
is
diagonal in the Bell basis, i.e., we have

of a Pauli channel

P

P

=

Ï‡

P

(cid:88)

i

pi|

Î¦i(cid:105)(cid:104)

Î¦i|

,

(S25)

and

Î¦
Ui|

where Î¦i = 11

Î¦
(cid:105)
|
We now consider the simulation of a Pauli channel with
the teleportation quantum processor introduced in the
previous section. Let

j=1 |

jj

âŠ—

(cid:105)

(cid:105)

/âˆšd.

= (cid:80)d

Ï€ =

(cid:88)

ij

Ï€ij|

Î¦i(cid:105)(cid:104)

Î¦j|

,

(S26)

We ï¬rst consider the simulation of an amplitude damp-
i K AD
, which is deï¬ned

i ÏK AD

ing channel
by the Kraus operators

EAD(Ï) = (cid:80)

â€ 

i

be an arbitrary program state expanded in the Bell ba-
sis. For any program state, the Choi matrix of the
teleportation-simulated channel is given by Eq. (20). Us-
ing standard properties of the Pauli matrices, we ï¬nd

K AD

0 =

(cid:18)1

0
0 âˆš1

âˆ’

(cid:19)

p

, K AD

1 =

(cid:19)

(cid:18)0 âˆšp
0
0

.

(S29)

Ï‡Ï€ â‰¡

Î›(Ï€) =

(cid:88)

i

Ï€ii|

Î¦i(cid:105)(cid:104)

Î¦i|

,

(S27)

namely a generic state is transformed into a Bell diagonal
state. Therefore, the cost function

C Pauli
1

=

Ï‡P âˆ’
can be minimized analytically for any Pauli channel by
choosing Ï€ij = piÎ´ij. With this choice we ï¬nd C Pauli
= 0,
meaning that the simulation is perfect.

Ï‡Ï€(cid:107)1 ,

(S28)

(cid:107)

1

In Fig. 9 we study the performance of the PBT simula-
tion of the amplitude damping channel
EAD for diï¬€erent
choices of p. For p = 0 the amplitude damping channel
is equal to the identity channel, while for p = 1 it is a
â€œresetâ€ channel sending all states to
. We compare the
(cid:105)
simulation error with program states Ï€ either made by
N
AD as in Eq. (25)
products of the channelâ€™s Choi matrix Ï‡âŠ—
E
or obtained from the minimization of the trace distance
cost function of Eq. (7) with the projected subgradient
iteration in Eq. (16). Alternative methods, such as the
conjugated gradient algorithm, perform similarly for this

0
|

0.00.20.40.60.8C1(EAD,Ï€)0.00.20.40.60.81.0pChoiN=1ChoiN=2ChoiN=3PS200N=1PS200N=2PS200N=319

FIG. 11. PBT Simulation of the qubit depolarizing chan-
nel versus probability of depolarizing p. Trace distance
C1(Edep, Ï€) = (cid:107)Ï‡Edep âˆ’ Ï‡Ï€(cid:107)1 between the target channelâ€™s
Choi matrix and its PBT simulation with program state Ï€,
for diï¬€erent number of ports N . We consider N = 1, 2, 3
and two kinds of programs: copies of the channelâ€™s Choi ma-
trix Ï€ = Ï‡âŠ—N
and the optimal program state ËœÏ€1 obtained
Edep
from the minimization of C1 via the conjugate gradient (CG)
method after 200 iterations. Note that the simulation error
C1 is maximized for the identity channel (p = 0) and even-
tually goes to zero for a ï¬nite value of p that decreases for
increasing N .

â‰¥

â‰¥

pth (cid:39)

p
pth. In Fig. 11 we study the performance of PBT
simulation of the depolarizing channel in terms of p. Per-
0.71 for N = 2
fect simulation is possible for p
â‰¥
and p
pth = 0.5 for N = 3, where the explicit values of
pth are taken from Ref. [50]. For p = 0 the depolarizing
channel is equal to the identity channel, while for p = 1 it
sends all states to the maximally mixed state. Again we
compare the simulation error with program states either
N
composed of copies of the channelâ€™s Choi matrix Ï‡âŠ—
dep or
E
obtained from the minimization of C1 with the conjugate
gradient method of Eq. (17), which performs signiï¬cantly
better than the projected subgradient for this channel.
Also for the depolarizing channel we observe that, for
any ï¬nite N , we obtain a lower error by optimizing over
N
dep .
the program states instead of the naive choice Ï‡âŠ—
E

Finally, in Fig. 12 we study the PBT simulation of a
unitary gate UÎ¸ = eiÎ¸X for diï¬€erent values of Î¸. Unlike
the previous non-unitary channels, in Fig. 12 we observe
a ï¬‚at error where diï¬€erent unitaries have the same sim-
ulation error of the identity channel Î¸ = 0. This is ex-
pected because both the trace distance and the diamond
distance are invariant under unitary transformations. In
general, we have the following.

Proposition 5. Given a unitary
PBT simulation

U

UÏ€ with program Ï€ we may write

(Ï) = U ÏU â€  and its

min
Ï€ ||U âˆ’ UÏ€||(cid:5)

= min

Ï€ ||I âˆ’ IÏ€||(cid:5)

,

(S31)

FIG. 10. PBT Simulation of the amplitude damping channel
EAD for various damping rates p. We plot the diamond dis-
tance cost function C(cid:5)(EAD, Ï€) = (cid:107)EAD âˆ’EAD,Ï€(cid:107)(cid:5) between the
target channel EAD and its PBT simulation EAD,Ï€ with pro-
gram state Ï€. In particular, for the program state we compare
the naive choice of the channelâ€™s Choi matrix Ï€ = Ï‡âŠ—N
(dot-
EAD
ted lines) with the SDP minimization over the set of generic
Choi matrices Ï€ = Ï‡âŠ—N (solid lines). Diï¬€erent values of
N = 2, . . . , 6 and N = 20 are shown.

Ã—

N
AD.

channel. We observe that, surprisingly, the optimal pro-
gram ËœÏ€1 obtained by minimizing the trace distance C1 is
always better than the natural choice Ï‡âŠ—
E

In Fig. 10 we study the PBT simulation of the ampli-
tude damping channel by considering the subset of pro-
N which is made of tensor products of
gram states Ï€ = Ï‡âŠ—
the 4
4 generic Choi matrices Ï‡ (satisfying Tr2Ï‡ = 11/2).
As discussed in Sec. 6, this is equivalent to optimizing
over the Choi set
CN and it practically reduces to the
convex optimization of the channel ËœÎ› over the generic
single-copy Choi matrix Ï‡. Moreover, ËœÎ› itself can be
simpliï¬ed, as shown in Appendix 6, so that all of the op-
erations depend polynomially on the number N of ports.
This allows us to numerically explore much larger val-
In Fig. 10
.
ues of N , even for the minimization of C
the dotted lines correspond to the value of C
when the
AD is the chan-
program Ï€ = Ï‡âŠ—
E
E
nelâ€™s Choi matrix. As Fig. 10 shows, the cost C
may
be signiï¬cantly smaller with an optimal Ï‡, thus show-
ing that the optimal program may be diï¬€erent from the
channelâ€™s Choi matrix, especially when p is far from the
two boundaries p = 0 and p = 1.

N
AD is employed, where Ï‡

(cid:5)

(cid:5)

(cid:5)

As an other example, we consider the simulation of the

depolarizing channel deï¬ned by

Edep(Ï) = (1

âˆ’

p)Ï +

p
d

11.

(S30)

It was shown in [20, 50] that PBT generates a depolariz-
ing channel, whose depolarizing probability pth depends
on N . This implies that a quantum processor based on
PBT can perfectly simulate a depolarizing channel when

0.00.20.40.60.81.01.2C(cid:5)(EAD,Ï‡âŠ—N)0.00.20.40.60.81.0pN=2N=3N=4N=5N=6N=200.00.20.40.60.8C1(EDepo,Ï€)0.00.20.40.60.81.0pChoiN=1ChoiN=2ChoiN=3CG200N=1CG200N=2CG200N=320

FIG. 13. PBT Simulation of the identity channel for diï¬€erent
number of ports N . For the identity channel the optimal Choi
matrix coincides with the channelâ€™s Choi matrix Ï‡I â‰¡ Î¦. The
optimal Ï€ has been obtained by minimising C(cid:5) via SDP. The
upper bound corresponds to Eq. (26).

A convenient choice is Uj(Î¸j) = exp(iÎ¸jHj), where each
elementary gate corresponds to a SchrÂ¨odinger evolution
with Hamiltonian Hj for a certain time interval Î¸j. For
certain choices of Hj and suitably large N the above cir-
cuit is universal [22], namely any unitary can be obtained
with U (Î¸) and a suitable choice of Î¸j. The optimal pa-
rameters can be found via numerical algorithms [44], e.g.
.
Tr[U â€ targetU (Î¸)]
by minimizing the cost function C(Î¸) =
|
However, the above cost function is not convex, so the nu-
merical algorithms are not guaranteed to converge to the
global optimum.

|

As a ï¬rst step, we show that the task of learning the
optimal parameters in a PQC can be transformed into
a convex optimization problem by using a quantum pro-
gram. This allows us to use SDP and gradient-based ML
methods to ï¬nd the global optimum solution.

1. Convex reformulation

FIG. 12. PBT Simulation of the unitary gate UÎ¸ = eiÎ¸X for
diï¬€erent angles Î¸, where X is the bit-ï¬‚ip Pauli matrix. Trace
distance C1(UÎ¸, Ï€) = (cid:107)Ï‡UÎ¸ âˆ’ Ï‡Ï€(cid:107)1 between the target Choi
matrix of the unitary and its PBT simulation with program
state Ï€, for diï¬€erent number of ports N . We consider N =
1, 2, 3 and two kinds of programs: copies of the Choi matrix
of the unitary Ï‡âŠ—N
and the program state ËœÏ€1 obtained from
UÎ¸
the minimization of C1 via the projected subgradient (PS)
method after 200 iterations.

where

IÏ€ is the PBT simulation of the identity channel.

Proof. In fact, we simultaneously prove

min
Ï€ ||I âˆ’ IÏ€||(cid:5)

(1)

â‰¤

min
Ï€ ||U âˆ’ UÏ€||(cid:5)

(2)

â‰¤

min
Ï€ ||I âˆ’ IÏ€||(cid:5)

,

(S32)
1

1

1

âˆ’

âˆ’

âˆ’

âˆ’

âˆ’

I

U

=

=

1)âŠ—

UÏ€||(cid:5)

UÏ€||(cid:5)
(

where (1) comes from the fact that
and

||I âˆ’ U
U
PBT simulation of the identity
N (Ï€) once

||U âˆ’UÏ€||(cid:5)
||U
U âˆ’
1
UÏ€ is a possible
âˆ’
U
with program state
1 is swapped with the ï¬lter-
I âŠ—
ing of the ports; then (2) comes from the fact that the
composition
U â—¦ IÏ€ is a possible simulation of the uni-
N (Ï€) and we have the
tary
U
inequality

. (cid:4)
for diï¬€erent values of N is
plotted in Fig. 13 where numerical values are obtained
from SDP, while the upper bound is given by Eq. (26).

||U â—¦ I âˆ’ U â—¦ IÏ€||(cid:5) â‰¤ ||I âˆ’ IÏ€||(cid:5)

with program state

The scaling of

||I âˆ’ IÏ€||(cid:5)

I âŠ— U

U

âŠ—

3.4. Parametric quantum circuits

We now study another design of universal quantum
processor that can simulate any target quantum channel
in the asymptotic limit of an arbitrarily large program
state. This is based on a suitable reformulation of the
PQCs, which are known to simulate any quantum com-
putation with a limited set of quantum gates [22, 51].

A PQC is composed of a sequence of unitary matrices
Uj(Î¸j), each depending on a classical parameter Î¸. The
resulting unitary operation is then

U (Î¸) = UN (Î¸N ) . . . U2(Î¸2)U1(Î¸1).

(S33)

Consider a program state

composed
Î¸1, . . . , Î¸N (cid:105)
|
of N registers Rj, each in a separable state
. We
Î¸j(cid:105)
can transform the classical parameters in Eq. (S33) into
quantum parameters via the conditional gates

=

Ï€

(cid:105)

|

|

Ë†Uj = exp

ï£«
ï£­iHj âŠ—

(cid:88)

Î¸j

ï£¶

Î¸j|

Î¸j(cid:105)(cid:104)

ï£¸ ,

Î¸j|

(S34)

that act non-trivially on systems and registers Rj. If the
parameters Î¸j are continuous, then we can replace the
sum with an integral. With the above gates, we deï¬ne

0.00.20.40.60.8C1(UÎ¸,Ï€)0Ï€2Ï€3Ï€22Ï€Î¸ChoiN=1ChoiN=2ChoiN=3PS200N=1PS200N=2PS200N=30.00.40.81.21.62.0C(cid:5)(I,Ï€)48121620NÏ€=Ï‡âŠ—NIbound2d(dâˆ’1)Nâˆ’1optimalÏ€21

theorem:

(ÏA) = TrR0 [U (ÏA âŠ—

E

Î¸0)U â€ ],

(S38)

where Î¸0 belongs to R0, and U acts on system A and
register R0. In Ref. [51] it was shown that two quantum
gates are universal for quantum computation. Speciï¬-
cally, given U0 = eit0H0 and UB = eit1H1 for ï¬xed times
ti and Hamiltonians Hj, it is possible to write any uni-
tary as

U

â‰ˆ Â· Â· Â·

1 U m3
U m4

0 U m2

1 U m1

0

,

(S39)

for some integers mj. Under suitable conditions, it was
shown that with M = (cid:80)
d) it is possible
j mj =
to approximate any unitary U with a precision (cid:15). More
precisely, the conditions are the following

(d2(cid:15)âˆ’

O

FIG. 14. Convex reformulation of a PQC as a coherent pro-
grammable quantum processor that applies a sequence of con-
ditional gates, as in Eq. (S34), depending on the program
state |Ï€(cid:105) = |Î¸1, . . . , Î¸N (cid:105). The program state is not destroyed
and can be reused.

the parametric quantum channel

QÏ€(Ï) = TrR

ï£®

ï£°

N
(cid:89)

j=1

Ë†Uj (Ï

Ï€)

âŠ—

ï£¹

Ë†Uj

â€ 

ï£» ,

N
(cid:89)

j=1

i) The Hamiltonians H0 and H1 are generators of the
full Lie algebra, namely H0, H1 and their repeated
commutators generate all the elements of su(d).

(S35)

ii) The eigenvalues of U0 and U1 have phases that are

irrationally related to Ï€.

Ïˆ
whose action on a generic state
(cid:105)
|
=
Ï€
For a pure separable program
(cid:105)
|
tain the standard result, i.e.,

is shown in Fig. 14.
, we ob-
Î¸1, . . . , Î¸N (cid:105)
|

Q
Î¸1,...,Î¸N
|

(cid:105)

(Ï) = U (Î¸)ÏU (Î¸)â€ ,

(S36)

where U (Î¸) is deï¬ned in Eq. (S33). The parametric quan-
tum processor QÏ€ in Eq. (S35) is capable of simulating
any parametric quantum channel, but it is more general,
as it allows entangled quantum parameters and also pa-
rameters in quantum superposition.

An equivalent measurement-based protocol is obtained
by performing the trace in Eq. (S36) over the basis
Î¸1, . . . , Î¸N (cid:105)
|
QÏ€(Î¸) =

U (Î¸)ÏU (Î¸)â€ 

, so that

(cid:88)

Ï€
Î¸1, . . . , Î¸N |
(cid:104)

,
Î¸1, . . . , Î¸N (cid:105)
|

(S37)
where U (Î¸) is deï¬ned in Eq. (S33). In this alternative
yet equivalent formulation, at a certain iteration j, the
processor measures the qubit register Rj. Depending
on the measurement outcome Î¸j, the processor then ap-
plies a diï¬€erent unitary U (Î¸j) on the system. However,
is destroyed
in this formulation the program state
after each channel use. From Eq. (S37) we note that
QÏ€ depends on Ï€ only via the probability distribution
. As such, any advantage in us-
Ï€
Î¸1, . . . , Î¸N |
(cid:104)
ing quantum states can only come from the capability of
quantum systems to model computationally hard proba-
bility distributions [62].

Î¸1, . . . , Î¸N (cid:105)
|

Ï€

(cid:105)

|

Î¸j

{

}

2. Universal channel simulation via PQCs

The decomposition in Eq. (S39) is a particular case of
Eq. (S33) where Î¸j can only take binary values Î¸j = 0, 1.
As such we can write the conditional gates of Eq. (S34)
as in Eq. 29, which is rewritten below

0
(cid:105)j j(cid:104)

+ it1H1 âŠ— |

Ë†Uj = exp (it0H0 âŠ— |

0
|
for some times tj. Channel simulation is then obtained
by replacing the unitary evolution U of Eq. (S38) with
the approximate form in Eq. (S39) and its simulation in
Eq. (S41). The result is illustrated in Fig. 3 and described
by the following channel

1
(cid:105)j j(cid:104)

) ,
1
|

(S40)

QÏ€(Ï) = TrR

ï£®

ï£°

N
(cid:89)

j=1

Ë†Uj A,R0,Rj

(ÏA âŠ—

Ï€)

ï£¹

Ë†Uj

â€ 
A,R0,Rj

ï£» ,

N
(cid:89)

j=1

(S41)
where the program state Ï€ is deï¬ned over R =
(R0, . . . , RN ) and each Ë†Hj acts on the input system A
and two ancillary qubits R0 and Rj. The decomposition
of Eq. (S39) assures that, with the program

=

Ï€
|

(cid:105)

Î¸0(cid:105) âŠ— Â· Â· Â· âŠ— |
|

1
(cid:105)

m2

âŠ—

0

âŠ—
(cid:105)

âŠ— |

m1 ,

(S42)

the product of unitaries approximates U in Eq. (S38)
with precision (cid:15). This is possible in general, provided that
d). However, the
the program state has dimension
channel (S41) is more general, as it allows both quantum
superposition and entanglement.

(d2(cid:15)âˆ’

O

The processor map Î›, written in Eq. (30) easily follows
from this construction , while the (non-trace-preserving)
dual channel may be written as
Ë†U â€ AR (XBA âŠ—

11R) Ë†UAR

.
Î¦BA(cid:105)

Î¦BA|
(cid:104)

Î›âˆ—(X) =

(S43)

|

The universality of PQCs can be employed for univer-
sal channel simulation, thanks to Stinespringâ€™s dilation

This channel requires 2N quantum gates at each itera-
tion and can be employed for the calculation of gradients,

|Ïˆ(cid:105)U(Î¸1)U(Î¸2)U(Î¸3)U(Î¸4)U(Î¸5)|Î¸1(cid:105)â€¢|Î¸2(cid:105)â€¢|Î¸3(cid:105)â€¢|Î¸4(cid:105)â€¢|Î¸5(cid:105)â€¢following Theorem 2. When we are interested in simu-
lating a unitary channel U via the quantum ï¬delity, then
following the results of Section 2, the corresponding op-
]
timal program ËœÏ€F is simply the eigenvector Î›âˆ—[
Ï‡U |
Ï‡U (cid:105)(cid:104)
|
with the maximum eigenvalue, where
.
Î¦
U
= 11
(cid:105)
|
âŠ—
Note also that Î›âˆ—[

Ï‡U (cid:105)(cid:104)
|
Ï‡U |BA âŠ—

Ï‡U |
11R) Ë†UAR (

Ï‡U (cid:105)
|
] = Z â€ Z where
Î¦BA(cid:105) âŠ—
|

Z = (
(cid:104)

(S44)

11R) ,

so the optimal program ËœÏ€F is the principal component of
Z. Since there are quantum algorithms for principal com-
ponent analysis [63], the optimization may be eï¬ƒciently
performed on a quantum computer.

3. Monotonicity by design

Two unitaries are suï¬ƒcient for universality, however
such a design may not be monotonic as a function of N
when simulating a given channel. By adding the iden-
tity as a third possible unitary, as in Eq. (31), we get
a processor that is monotonic by design. Note that the
identity cannot be one of the initial choices of unitaries,
due to the condition that the eigenvalues of U0 and U1
have phases that are irrationally related to Ï€. Because
we want a single program qudit to control the applica-
tion of one of three unitaries, we use qutrits to control
the gates.

Such a design is more powerful than the original de-
sign, because it is guaranteed to both be monotonic as
a function of N , where N is the number of controlled
gates, but also to be able to simulate any channel at
least as well as the original M -gate processor can, for
any M
N . This is because a valid program state for
M ), where
2
the monotonic processor is Ï€M âŠ— |
Ï€M is any program state for the original M -gate proces-
sor. Such a program state would result in the same cost
function that the original processor obtains using Ï€M .

2
(cid:105)(cid:104)

âŠ—
|

â‰¤

(N

âˆ’

Due to having a larger program state space, and more
unitaries to choose from, the N -gate monotonic design
can also potentially perform not just as well as but bet-
ter than any M -gate processor using the original design,
when simulating many channels. This comes at the cost
of higher dimensionality. The number of parameters to
(32N ) for the monotonic
optimise over scales with order
(22N ) for the orig-
processor, whilst it scales with order
inal design.

O

O

3.5. PQC: Numerical examples

As an example we study the simulation of an amplitude
damping channel, with Kraus operators in Eq. (S29). A
possible Stinespring dilation for this channel is obtained
with

=

Î¸0(cid:105)
|

U =

and

0
(cid:105)
|
ï£«
0
1
0 âˆš1
ï£¬
ï£­
0
0

âˆ’

0
p âˆšp

âˆ’
âˆšp âˆš1
âˆ’
0
0

ï£¶
0
0
ï£·
ï£¸ = eiHAD,
p 0
1

(S45)

22

FIG. 15. PQC simulation of the amplitude damping channel.
Trace distance C1(EAD, Ï€) = (cid:107)Ï‡EAD âˆ’Ï‡Ï€(cid:107)1 between the target
channelâ€™s Choi matrix and its PQC simulation with program
state Ï€, for diï¬€erent numbers of register qubits N . The opti-
mal program is obtained from the minimization of C1 via the
projected subgradient (PS) method after 200 iterations.

where the Hamiltonian is given by

HAD =

arcsin(âˆšp)
2

(Y

X

X

âˆ’

âŠ—

âŠ—

Y ),

(S46)

with X and Y being Pauli operators. We may construct
a PQC simulation by taking

U0 = eiÎ±(Y

X

X

Y ),

âŠ—

âˆ’

âŠ—

(S47)

for some Î± and taking U1 to be a diï¬€erent unitary that
makes the pair U0, U1 universal. Here we may choose
Î± = âˆš2 and U1 = eiH1 with

H1 = (âˆš2Z + âˆš3Y + âˆš5X)

(Y + âˆš2Z).

(S48)

âŠ—

Results are shown in Fig. 15. Compared with the sim-
ilar PBT simulation of Fig. 9, we observe that the PQC
simulation (using the non-monotonic design) displays a
non-monotonic behavior as a function of N . PBT with
N pairs requires a register of 2N qubits, while PQC re-
quires N + 1 qubits, namely N qubits for the conditional
gates and an extra auxiliary qubit coming from the Stine-
spring decomposition (see Fig. 3). We observe that, with
a comparable yet ï¬nite register size, PQC can outperform
PBT in simulating the amplitude damping channel. In
Fig. 16 we also study the PQC simulation of the depolar-
izing channel for diï¬€erent values of p. Although the gates
U0 and U1 were chosen with inspiration from the Stine-
spring decomposition of the amplitude damping channel,
those gates are universal and capable of simulating other
channels. Indeed, we observe in Fig. 16 that a depolariz-
ing channel is already well simulated with N = 4 for all
values of p.

0.00.20.40.60.8C1(EAD,Ï€)0.00.20.40.60.81.0pPS200N=1PS200N=2PS200N=3PS200N=4PS200N=5PS200N=64.2. Diï¬€erential of the quantum ï¬delity

The quantum ï¬delity can be expanded as

(cid:113)

âˆšXY âˆšX
(cid:90)

F (X, Y ) = Tr
1
2Ï€i

=

dÎ» âˆšÎ»Tr[(Î»11

âˆšXY âˆšX)âˆ’

1] ,

âˆ’

Î“

23

(S53)

where in the second line we have applied Eq. (S49). Tak-
ing the diï¬€erential with respect to Y and using the cyclic
property of the trace we get

F (X, Y )

âˆ’

dÎ» âˆšÎ»Tr[(Î»11

âˆšXY âˆšX)âˆ’

2âˆšXdY âˆšX]

âˆ’

Tr[(âˆšXY âˆšX)âˆ’

1

2 âˆšXdY âˆšX]

(cid:90)

(1)
=

dY F := F (X, Y + dY )
1
2Ï€i
1
2
1
2

(3)
=

(2)
=

Î“

Tr[âˆšX(âˆšXY âˆšX)âˆ’

1

2 âˆšX dY ] ,

(S54)

where in (1) we use Eq. (S51) and the cyclic property of
the trace; in (2) we use Eq. (S50) with f (Î») = âˆšÎ», so
f (cid:48)(Î») = 1
1/2; and in (3) we use the cyclic property of
the trace. See also Lemma 11 in [41].

2 Î»âˆ’

FIG. 16. PQC simulation of the depolarizing channel. Trace
distance C1(EDep, Ï€) = (cid:107)Ï‡EDep âˆ’ Ï‡Ï€(cid:107)1 between the target
channelâ€™s Choi matrix and its PQC simulation with program
state Ï€, for diï¬€erent numbers of register qubits N . The opti-
mal program is obtained from the minimization of C1 via the
projected subgradient (PS) method after 200 iterations.

4. MATRIX CALCULUS

4.1. Matrix diï¬€erentiation

4.3. Diï¬€erential of the trace distance

For a general overview of these techniques, the reader
may consult Ref. [64]. Thanks to Cauchyâ€™s theorem, a
matrix function can be written as

as

f (A) =

1
2Ï€i

(cid:90)

Î“

dÎ» f (Î»)(Î»11

A)âˆ’

1 .

âˆ’

(S49)

The trace norm for a Hermitian operator X is deï¬ned

t(X) =

=

X
(cid:107)
1
2Ï€i

Î“

(cid:107)1 := TrâˆšX â€ X = Tr[âˆšX 2]
(cid:90)
1] ,
XX)âˆ’

dÎ» âˆšÎ»Tr[(Î»11

âˆ’

(S55)

For the same reason

f (cid:48)(A) =

1
2Ï€i

(cid:90)

Î“

dÎ» f (Î»)(Î»11

A)âˆ’

2 .

âˆ’

(S50)

Applying a basic rule of matrix diï¬€erentiation, d(Aâˆ’

1) =

Aâˆ’

1(dA)Aâˆ’

1 we obtain

âˆ’

df (A) =

1
2Ï€i

(cid:90)

Î“

dÎ» f (Î»)(Î»11

âˆ’

A)âˆ’

1dA(Î»11

âˆ’

A)âˆ’

1 . (S51)

Clearly, df (A) = f (cid:48)(A)dA only when [A, dA] = 0.
In
general df (A) is a superoperator that depends on A and
is applied to dA. The explicit form is easily computed
using the eigenvalue decomposition or other techniques
[64]. Note that in some cases the expressions are simple.
Indeed, using the cyclic invariance of the trace, we have

dTr[f (A)] = Tr[f (cid:48)(A)dA],

(S52)

j |

Î»j|

where in the second line we applied Eq. (S49). From
the spectral decomposition X = U Î»U â€ , we ï¬nd t(X) =
(cid:80)
, so the trace distance reduces to the absolute
value function for one-dimensional Hilbert spaces. The
is diï¬€erentiable at every point,
absolute value function
except Î» = 0. Therefore, for any Î»
= 0, the subgradient
of the absolute value function is composed of only its
gradient, i.e.

Î»
|

|

âˆ‚

Î»
|

|

=

sign(Î»)
}
{

for Î»

= 0 .

(S56)

For Î» = 0 we can use the deï¬nition (12) to write

z :
{
1

Ïƒ
|
z

âˆ‚

|Î»=0 =
Î»

|

zÏƒ for all Ïƒ

,

}

| â‰¥

(S57)

which is true iï¬€

1. Therefore,

|

âˆ’

1, 1] .

â‰¤
â‰¤
|Î»=0 = [
Î»
âˆ‚
âˆ’
The sign function in (S56) can be extended to Î» = 0 in
multiple ways (common choices are sign(0) =
1, 0, 1).
From the above equation, it appears that for any exten-
sion of the sign function, provided that sign(0)
1, 1]
we may write the general form

(S58)

[
âˆ’

âˆ’

âˆˆ

while in general dTr[Bf (A)]

=Tr[Bf (cid:48)(A)dA].

sign(Î»)

,

âˆ‚

Î»
|

|

âˆˆ

(S59)

0.00.20.40.60.8C1(EDep,Ï€)0.00.20.40.60.81.0pPS200N=1PS200N=2PS200N=3PS200N=4PS200N=5PS200N=6(cid:54)
(cid:54)
(cid:54)
which is true for any value of Î».

With the same spirit we extend the above argument to
any matrix dimension, starting from the case where X is
an invertible operator (no zero eigenvalues). Taking the
diï¬€erential with respect to X we ï¬nd

dt(X) := t(X + dX)

t(X) =

âˆ’
dÎ» âˆšÎ»Tr[(Î»11

(cid:90)

Î“

(1)
=

(2)
=

1
2Ï€i
1
2

Tr[(X 2)âˆ’

1
2 (X(dX) + (dX)X)]

X 2)âˆ’

2(X(dX) + (dX)X)]

âˆ’

(3)
= Tr[(X 2)âˆ’

1
2 X (dX)]

(S60)

where in (1) we use Eq. (S51), the cyclic property of the
trace and the identity dX 2 = X(dX) + (dX)X; in (2)
we use Eq. (S50) with f (Î») = âˆšÎ», so f (cid:48)(Î») = 1
1/2;
and in (3) we use the cyclic property of the trace and the
commutation of X and âˆšX 2. Let

2 Î»âˆ’

X =

(cid:88)

k

Î»kPk ,

(S61)

be the eigenvalue decomposition of X with eigenvalues
Î»k and eigenprojectors Pk. For non-zero eigenvalues we
may write

(X 2)âˆ’

1
2 X =

(cid:88)

k

and accordingly

sign(Î»k)Pk =: sign(X) ,

(S62)

dt(X) :=

X + dX
(cid:107)
(cid:88)

(cid:107)1 âˆ’ (cid:107)
sign(Î»k)Tr[Pk dX] .

(cid:107)1

X

=

(S63)

k

Therefore, for invertible operators we may write

âˆ‚t(X) =

t(X)

,

âˆ‡

}

{âˆ‡

t(X) = sign(X) .

We now consider the general case where some eigenvalues
of X may be zero. We do this by generalizing Eq. (S59),
namely we show that even if âˆ‚t(X) may contain multiple
âˆ‚t, provided that
elements, it is always true that
âˆˆ
11. Following (12) we may write, for

sign(X)

âˆ‡

11

t

âˆ’
ï¬xed X and arbitrary Y ,

â‰¤

â‰¤

Tr[

t(X)(Y

X)]

âˆ‡
Tr[

âˆ’
t(X)Y ] + t(X)

t(Y )

t(X)

âˆ’

âˆ’

(1)
= t(Y )

(2)

â‰¥

t(Y )

âˆ’

t(X)

âˆ’

Tr[Y ] =

âˆ’
(cid:88)
(

âˆ‡
Î»j| âˆ’
|

j

Î»j)

0 ,

â‰¥

(S64)

where in (1) we use the property
X
(cid:107)1 = Tr[sign(X)X]
(cid:107)
and in (2) we use the assumption
11.
sign(X)
11
âˆ’
From the deï¬nition of the subgradient (12), the above
equation shows that sign(X)
âˆ‚t(X), so we may always
âˆˆ
use
t(X) = sign(X) in the projected subgradient algo-
âˆ‡
rithm (16).

â‰¤

â‰¤

24

5. SMOOTHING TECHNIQUES

5.1. Stochastic smoothing

The conjugate gradient algorithm converges after
(c/(cid:15)) steps [15, 16], where (cid:15) is the desired precision and
O
c is a curvature constant that depends on the function.
However, it is known that c could diverge for non-smooth
functions. This is the case for the trace norm, as shown
in Example 0.1 in [65].

A general solution, valid for arbitrary functions,

is
In this approach the non-

stochastic smoothing [66].
smooth function C(Ï€) is replaced by the average

CÎ·(Ï€) = EÏƒ[C(Ï€ + Î·Ïƒ)] .

(S65)

where Ïƒ is such that
M

, then

x

y

(cid:107)

âˆ’

(cid:107)âˆ

Ïƒ
(cid:107)

(cid:107)âˆ â‰¤

1.

If

C(x)
|

âˆ’

C(y)

| â‰¤

(S66)

C(Ï€)

CÎ·(Ï€)

C(Ï€) + M Î· ,

â‰¤

â‰¤
so that CÎ·(Ï€) provides a good approximation for C(Ï€).
Moreover, CÎ· is diï¬€erentiable at any point, so we may
apply the conjugate gradient algorithm. A modiï¬ed con-
jugate gradient algorithm with adaptive stochastic ap-
proximation was presented in Ref. [67]. At each iteration
k the algorithm reads

kâˆ’

(cid:80)k

1/2,

k+2 |

of Â¯gk,

j=1 g(Ï€k + Î·kÏƒj) for Î·k âˆ
Ïƒk(cid:105)
|
.

1) Sample some operators Ïƒ1, . . . , Ïƒk,
2) Evaluate Â¯gk = 1
k
3) Find the smallest eigenvalue
k+2 Ï€k + 2
4) Ï€k+1 = k
Ïƒk|
Ïƒk(cid:105) (cid:104)
where g denotes any element of the subgradient âˆ‚C. The
((cid:15)2) iterations. Since
above algorithm converges after
Eqs. (45) and (43) provide an element of the subgradi-
ent, the above algorithm can be applied to both ï¬delity
and trace distance. However, this algorithm requires k
evaluations of the subgradient to perform the averages,
so it may be impractical when the number of iterations
get larger. In the following we study an alternative that
does not require any average.

O

5.2. Nesterovâ€™s smoothing

An alternative smoothing scheme is based on Nes-
terovâ€™s dual formulation [42]. Suppose that the non-
smooth objective function f admits a dual representation
as follows

[
f (x) = sup

y

x, y
(cid:104)

(cid:105) âˆ’

g(y)],

(S67)

for some inner product
. Nesterovâ€™s approximation
Â·(cid:105)
consists of adding a strongly convex function d to the
dual

,
(cid:104)Â·

fÂµ(x) =

(cid:88)
[

y

x, y
(cid:104)

(cid:105) âˆ’

g(y)

âˆ’

Âµd(y)].

(S68)

(cid:104)

Y, X
(cid:104)

(cid:105) âˆ’

(cid:105)

Âµ
2 (cid:107)

Y

2
2
(cid:107)

âˆ‡

tÂµ(X) = argmax
1
(cid:107)
â‰¤
= argmin
Y

âˆ

Y

(cid:107)

âˆ

(cid:107)

(cid:107)

â‰¤

ÂµY

1 (cid:107)

X

2
2 = U Î£ÂµV â€ ,
(cid:107)

âˆ’

showing the convexity. (cid:4)

The resulting Âµ-approximation is smooth and satisï¬es

fÂµ(x)

f (x)

â‰¤

â‰¤

fÂµ(x) + Âµ sup

y

d(y).

(S69)

The trace norm admits the dual representation [3]

t(X) =

X
(cid:107)

(cid:107)1 = sup

Y

âˆ

1(cid:104)

Y, X

,
(cid:105)

(S70)

(cid:107)

(cid:107)

Y, X
(cid:104)

â‰¤
where
is the Hilbert Schmidt product. This can
be regularized with any strongly convex function d. A
convenient choice [18] that enables an analytic solution
is d(X) = 1

X, X

X

(cid:105)

2 := 1
2
2 (cid:104)

(cid:107)

2 (cid:107)

, so
(cid:105)

(cid:104)

tÂµ(X) = max
â‰¤

âˆ

Y

(cid:107)

(cid:107)

1

Y, X
(cid:104)

(cid:105) âˆ’

Âµ
2 (cid:107)

Y

2
2
(cid:107)

(cid:105)

.

(S71)

This function is smooth and its gradient is given by [18]

where X = U Î£V â€  is the singular value decomposition
of X and Î£Âµ is a diagonal matrix with diagonal entries
. Plugging this into Eq. (S71) we
(Î£Âµ)i = min
}
get

Î£i/Âµ, 1
{

tÂµ(X) = Tr

(cid:104)

Î£Âµ

(cid:16)

Î£

(cid:17)(cid:105)

.

Î£Âµ

Âµ
2

âˆ’

(S72)

For a diagonalizable matrix X with spectral decompo-
sition X = U Î»U â€ , the singular value decomposition is
obtained with Î£ =
Inserting
these expressions in (S72) we ï¬nd

and V = U sign(Î»).

Î»
|

|

tÂµ(X) =

(cid:88)

j

hÂµ(Î»j) = Tr[hÂµ(X)],

(S73)

hÂµ(x) =

where hÂµ is the so called Huber penalty function
(cid:40) x2
2Âµ
x
|
tÂµ is then h(cid:48)Âµ(X)
(cid:40) x
Âµ
sign(x)

x
|
x
|
U h(cid:48)(Î»)U â€ , where

The gradient

< Âµ,
Âµ.

< Âµ,
Âµ.

h(cid:48)Âµ(x) =

|
| â‰¥

if
if

if
if

| âˆ’

âˆ‡

â‰¡

Âµ
2

x
|
x
|

|
| â‰¥

(S74)

(S75)

We then ï¬nd that, via the smooth trace norm tÂµ, we
can deï¬ne the smooth trace distance of Eq. (64) that is
diï¬€erentiable at every point

CÂµ(Ï€) = Tr [hÂµ (Ï‡Ï€ âˆ’

Ï‡
E

)] .

(S76)

Thanks to the inequalities in (S69), the smooth trace
distance bounds the cost C1 as

CÂµ(Ï€)

C1(Ï€)

â‰¤

â‰¤

CÂµ(Ï€) +

Âµd
2

,

(S77)

where we employed the identity sup
get the upper bound. Moreover, we ï¬nd the following

Y
1 (cid:107)

(cid:107)

â‰¤

âˆ

Y

(cid:107)

(cid:107)

2
2 â‰¤

d to

25

Lemma 6. The smooth trace distance, deï¬ned in
Eq. (64), is a convex function of Ï€.

Proof. From the deï¬nition and Eq. (S71) we ï¬nd

CÂµ(Ï€) = tÂµ [Î›(Ï€)
âˆ’
(cid:104)

= max
Y
âˆ
â‰¤

(cid:107)

(cid:107)

1

]

Ï‡
E
Y, Î›(Ï€)
(cid:104)

Ï‡

E (cid:105) âˆ’

âˆ’

Âµ
2 (cid:107)

Y

2
2

(cid:107)

(cid:105)

.

(S78)

Now for Â¯Ï€ = pÏ€1 + (1
Ï‡
Y, Î›(Â¯Ï€)
(cid:104)

E (cid:105)

âˆ’

= pf (Ï€1) + (1

âˆ’

âˆ’

p)Ï€2 linearity implies f (Â¯Ï€) :=
p)f (Ï€2). Therefore

(cid:104)

pf (Ï€1) + (1

Y, Î›(Ï€1)
(cid:104)

1

Y

âˆ

(cid:104)

CÂµ(Â¯Ï€) = max
(cid:107)
(cid:107)
â‰¤
p max
Y
âˆ
(cid:107)
â‰¤
p) max
Z
âˆ
â‰¤
(cid:107)
= pCÂµ(Ï€1) + (1

(cid:107)
+ (1

âˆ’

â‰¤

(cid:107)

1

(cid:104)
Z, Î›(Ï€2)
(cid:104)
p)CÂµ(Ï€2),

1

âˆ’

p)f (Ï€2)

âˆ’

âˆ’

Ï‡

âˆ’

E (cid:105) âˆ’

Âµ
2 (cid:107)

Y

Ï‡

âˆ’

E (cid:105) âˆ’

Y

(cid:105)

2
2
(cid:107)

Âµ
2 (cid:107)
(cid:105)

2
2
(cid:107)
Âµ
2 (cid:107)

Z

(cid:105)

2
2
(cid:107)
(S79)

Then, using the deï¬nitions from [42], the following the-

orem bounds the growth of the gradient

Theorem 7. The gradient of the smooth trace norm is
Lipschitz continuous with Lipschitz constant

L =

d
Âµ

.

(S80)

In particular, if the gradient is Lipschitz continuous,
the smooth trace norm satisï¬es the following inequality
for any state Ï€, Ïƒ

CÂµ(Ïƒ)

â‰¤

CÂµ(Ï€) +

CÂµ(Ï€), Ïƒ

(cid:104)âˆ‡

Ï€

(cid:105)

âˆ’

+

L
2 (cid:107)

Ïƒ

Ï€

2
2. (S81)
(cid:107)

âˆ’

Proof. Given the linearity of the quantum channel Î›, we
can apply theorem 1 from [42] to ï¬nd

L =

1
Âµ

x

(cid:107)

(cid:107)

sup
y

2=1,

(cid:107)

y, Î›(x)
(cid:105)

.

2=1(cid:104)

(cid:107)

(S82)

Since all eigenvalues of y are less than or equal to 1, we
can write y

1 and as such

â‰¤

L

â‰¤

1
Âµ

(cid:107)

sup
x

2=1

(cid:107)

Tr[Î›(x)] =

1
Âµ

(cid:107)

sup
x

2=1

(cid:107)

Tr[x]

d
Âµ

.

â‰¤

(S83)

(cid:4)

6. PBT: PROGRAM STATE COMPRESSION

The dimension of the program state grows exponen-
tially with the number of ports N as d2N where d is
the dimension of the Hilbert space. However, as also
discussed in the original proposal [19, 20] and more re-
cently in Ref. [68], the resource state of PBT can be cho-
sen with extra symmetries, so as to reduce the number

of free parameters. In particular, we may consider the
set of program states that are symmetric under the ex-
change of ports, i.e., such that rearranging any A modes
and the corresponding B modes leaves the program state
unchanged.

Let Ps be the permutation operator swapping labels 1
to N for the labels in the sequence s, which contains all
the numbers 1 to N once each in some permuted order.
Namely Ps exchanges all ports according to the rule i
(cid:55)â†’
si. Since PBT is symmetric under exchange of ports, we
may write

PPsÏ€P â€ 

s

(Ï) =

PÏ€ (Ï) for any s.

(S84)

Consider then an arbitrary permutation-symmetric re-
source state Ï€sym as

Ï€sym =

1
N !

(cid:88)

s

PsÏ€P â€ s ,

where the sum is over all possible sequences s that deï¬ne
independent permutations and N ! is the total number
of possible permutations. Clearly
PÏ€, so any
program state gives the same PBT channel as some sym-
metric program state. It therefore suï¬ƒces to consider the
set of symmetric program states. This is a convex set:
any linear combination of symmetric states is a symmet-
ric state.

PÏ€sym =

|

x

To construct a basis of the symmetric space, we note
that each element of a density matrix is the coeï¬ƒcient
of a dyadic (of the form
). If permutation of labels
y
|
(cid:105) (cid:104)
maps one dyadic to another, the coeï¬ƒcients must be the
same. This allows us to constrain our density matrix
using fewer global parameters. For instance, for d = 2 we
can deï¬ne the 16 parameters n00,00, n00,01, n00,10, etc.,
corresponding to the number of ports in the dyadic of the
form
, etc.
Each element of a symmetric density matrix can then
be deï¬ned solely in terms of these parameters, i.e., all
elements corresponding to dyadics with the same values
of these parameters have the same value.

0A0B(cid:105) (cid:104)
|

0A0B(cid:105) (cid:104)
|

0A0B(cid:105) (cid:104)

,
0A0B|

1A0B|

0A1B|

,

|

cA, dB|

aA, bB(cid:105)(cid:104)
|

For the general qudit case, in which our program state
consists of N ports, each composed of two d-dimensional
qudits, we can ï¬nd the number of independent parame-
ters from the number of independent dyadics. Each port
in a dyadic can be written as
where the
extra indices A and B describe whether those states are
modeling either qudit A or B. There are d4 diï¬€erent
combinations of
, so we can place each qudit
a, b, c, d
}
{
into one of d4 categories based on these values. If two el-
ements in the density matrix correspond to dyadics with
the same number of ports in each category, they must
take the same value. Hence, the number of independent
coeï¬ƒcients is given by the number of ways of placing
N (identical) ports into d4 (distinguishable) categories.
This is exactly the binomial coeï¬ƒcient

26

Consequently, exploiting permutation symmetry of the
PBT protocol, we can exponentially reduce the number
of parameters for the optimization over program states.
The number of parameters can be reduced even further
by considering products of Choi matrices. We may focus
indeed on the Choi set, ï¬rst deï¬ned in Eq. (28),

(cid:40)

CN =

Ï€ : Ï€ =

(cid:41)

N

pkÏ‡âŠ—
k

,

(cid:88)

k

(S86)

where each Ï‡k = Ï‡k
AB is a generic Choi matrix, therefore
111, and pk form a probability dis-
satisfying TrBÏ‡k = dâˆ’
tribution. Clearly
is a convex set. We now show that
this set can be further reduced to just considering N = 1.
N is directly used in

When the program state Ï€ = Ï‡âŠ—

C

the PBT protocol we ï¬nd

Î›(Ï€) =

N
(cid:88)

i=1

TrA Â¯BiC

(cid:2)Î i

(cid:0)Ï‡âŠ—

N
AB âŠ—

Î¦DC

(cid:1)(cid:3)

Bi

Bout

â†’

(S87)

=

1
dN

âˆ’

1

N
(cid:88)

i=1

:= ËœÎ›(Ï‡) ,

TrAiC [Î i (Ï‡AiBout âŠ—

Î¦DC)]

(S88)

(S89)

namely that the optimization can be reduced to the
(d4) dimensional space of Choi matrices Ï‡. Note that,

O
in the above equation, we used the identity

N

Tr Â¯BiÏ‡âŠ—

AB = Ï‡AiBi âŠ—

11 Â¯Ai
dN

âˆ’

1 ,

(S90)

where Â¯Ai = A

Ai.

\

Now let Ï€ be a linear combination of tensor products
, each with probability pk as

of Choi matrix states, Ï‡âŠ—
k
in Eq. (S86). Then we can write

N

Tr Â¯BiÏ€AB = Tr Â¯Bi

(cid:88)

N

pkÏ‡âŠ—
k

k
(cid:18)

Ï‡k

AiBi âŠ—

(cid:88)

=

pk

k

(S91)

(S92)

(cid:19)

.

11 Â¯Ai
1
dN

âˆ’

N of some other Choi matrix Ï‡(cid:48) = (cid:80)

However, this is precisely the partial trace over the tensor
k pkÏ‡k.
product Ï‡(cid:48)âŠ—
Hence, the program state Ï€ = (cid:80)
simulates the
same channel as the resource state Ï€(cid:48) = ((cid:80)
k pkÏ‡k)âŠ—

N .
CN can
be reduced to the optimization over products of Choi ma-
N . From Eq. (S89) this can be further reduced
trices Ï‡âŠ—
to the optimization of the quantum channel ËœÎ› over the
convex set of single-copy Choi matrices Ï‡

Therefore, the optimization over the convex set

k pkÏ‡âŠ—
k

N

C1 =

Ï€ : Ï€ = Ï‡AB, TrBÏ‡AB = 11/2
}

{

,

(S93)

(d4). Using

which is
C1 drastically reduces the diï¬ƒculty
of numerical simulations, thus allowing the exploration of
signiï¬cantly larger values of N .

O

(cid:19)
1

(cid:18)N + d4
d4

âˆ’

âˆ’
1

(N d4

1) .

âˆ’

=

O

(S85)

Finally, we provide an explicit expression for the re-
duced map ËœÎ› of Eq. (S89) in the case of qubits. For d = 2

we can rewrite PBT in a language that can be more easily
formulated from representations of SU(2). For simplicity
of notation, here we do not use bold letters for vectorial
quantities. Let us modify the POVM in Eq. (21) as

Substituting the deï¬nition of Stot, we ï¬nd two classes

of eigenvalues

Î»+(sA) =

2sA

N

âˆ’
4

, Î»âˆ’(sA) =

N + 2sA + 2
4

,

(S102)

27

1/2

ËœÎ i = Ïƒâˆ’
AC Î¨âˆ’AiCÏƒâˆ’
N
(cid:88)

1/2
AC ,

ÏƒAC =

Î¨âˆ’AiC,

i=1
Î i = ËœÎ i + âˆ†,

âˆ† =

ï£«

ï£­11

1
N

(cid:88)

âˆ’

j

ï£¶

ËœÎ j

ï£¸ ,

(S94)

with corresponding eigenvectors

(cid:88)

1

(cid:105)

=

, sA, M, Î±

Î“M,m,k
sA
|Â±
Â±
N +1
2 , Î± = 1, . . . , g[N ](s) describes
where
the degeneracy, g[N ](s) is the size of the degenerate sub-
space, and

k
2 ,sA |

sA, m, Î±

(S103)

(cid:105)A ,

2 â‰¤

(cid:105)C|

N +1

k,m

M

â‰¤

âˆ’

(S95)

(S96)

(S97)

Î“M,m,k
S,s

=

(cid:104)
are Clebsch-Gordan coeï¬ƒcients.

S, M ; s, 1/2
|

1/2, 1/2

k; s, m
(cid:105)

âˆ’

(S104)

Note that

the Clebsch-Gordan coeï¬ƒcients deï¬ne
two bases
. From the orthogonal-

a unitary transformation between the
S, M ; s1, s2(cid:105)
s1, m1; s2; m2(cid:105)
|
|
ity relations, of these coeï¬ƒcients we ï¬nd the equalities

and

)/âˆš2 is a singlet state. For
Î¨âˆ’
where
(cid:105)
|
n the quantum channel is simpliï¬ed.
Ï€ = Ï‡âŠ—
In fact,
since TrB Ï‡ = 11/2, we may write

01
= (
|

(cid:105) âˆ’ |

10

(cid:105)

PÏ€ =

=

N
(cid:88)

i=1
(cid:88)

(cid:96)

1
2N

âˆ’

1 TrAC

(cid:104)(cid:112)

Î i

K 0
(cid:96) (ÏC âŠ—

Ï‡)K 0

(cid:96) â€  +

(cid:0)ÏC âŠ—
Ï‡AiB âŠ—
K 1
(cid:96) (ÏC âŠ—

(cid:88)

(cid:96)(cid:48)

(cid:1) (cid:112)

(cid:105)

Î i

11 Â¯Ai

Ï‡)K 1

(cid:96) â€ , (S98)

(cid:88)

S,s Î“M,m(cid:48),i(cid:48)
Î“M,m,i

S,s

= Î´i,i(cid:48)Î´m,m(cid:48),

S,M
(cid:88)

m,i

S,s Î“M (cid:48),m,i
Î“M,m,i

S(cid:48),s = Î´M,M (cid:48)Î´(S, S(cid:48), s),

(S105)

(S106)

where (cid:96) and (cid:96)(cid:48) are multi-indices and,
in deï¬ning the
Kraus operators, we have separated the contributions
from ËœÎ i and âˆ† (see below).

In order to express these operators, we write

Ïˆâˆ’CAi(cid:105)(cid:104)
|

Ïˆâˆ’CAi|

=

11

âˆ’

(cid:126)ÏƒC Â·
4

(cid:126)ÏƒAi

,

(S99)

so that

ÏƒAC =

N
(cid:88)

i=1

Ïˆâˆ’CAi(cid:105)(cid:104)
|
(cid:126)S2
tot âˆ’

Ïˆâˆ’CAi|
(cid:126)S2
C âˆ’
2

=

N
4 âˆ’

=

N
4 âˆ’

(cid:126)SC Â·

(cid:126)SA

(cid:126)S2
A

,

(S100)

where (cid:126)S = (cid:126)Ïƒ/2 is a vector of spin operators, (cid:126)SA =
(cid:80)
(cid:126)SAj and (cid:126)Stot = (cid:126)SC + (cid:126)SA. The eigenvalues of ÏƒAC
j
are then obtained from the eigenvalues of the three com-
muting Casimir operators

Î»(sA) =

N
4 âˆ’

Stot(Stot + 1)

âˆ’

sA(sA + 1)
2

âˆ’

3/4

,

(S101)

where Stot = sA Â±

1/2.

where Î´(S, S(cid:48), s) = 1 iï¬€ S = S(cid:48) and
â‰¤
s + 1/2. The eigenvalues in Eq. (S102) are zero iï¬€
Stot = SA + 1/2 and SA = N/2. These eigenvalues have
degeneracy 2Stot + 1 = N + 2 and the corresponding
eigenvectors are

| â‰¤

1/2

s
|

âˆ’

S

+, N/2, M, Î±
|
Thus, the operator âˆ† from Eq. (S97) may be written as

, M, Î±

(S107)

| âŠ¥

=

(cid:105)

(cid:105)

.

âˆ† =

1
N

N +1

2(cid:88)

(cid:88)

M =

âˆ’

N +1
2

Î±

, M, Î±

| âŠ¥

, M, Î±

.

|

(cid:105)(cid:104)âŠ¥

(S108)

To ï¬nish the calculation we need to perform the partial
trace over all spins except those in port i. We use s Â¯Ai,
m Â¯Ai and Î±i to model the state of the total spin in ports
Aj with j
= i. These refer to the value of total spin and
the projection along the z axis, as well as the degeneracy.
A and Sz
Moreover, since S Â¯Ai commutes with both S2
A,
we may select a basis for the degeneracy that explicitly
contains s Â¯Ai. We may write then Î± = (s Â¯Ai, ËœÎ±i) where ËœÎ±i
represents some other degrees of freedom.

With the above deï¬nitions, when we insert several res-
olutions of the identity in Eq. (S98), we may write the
Kraus operators as

(cid:54)
K 0

i,s Â¯Ai

,m Â¯Ai

,Î±i,s(cid:48)

Â¯Ai

,m(cid:48)

Â¯Ai

,Î±(cid:48)
i

= 2âˆ’

N âˆ’1
2

= 2âˆ’

N âˆ’1
2

s Â¯Ai , m Â¯Ai, Î±i| âŠ— (cid:104)
(cid:104)
(cid:88)
(sA)âˆ’
Î»

,sA,M,Î±

Â±

Ïˆâˆ’AiC|

1/2

(cid:104)

1/2
Ïƒâˆ’
AC |
Ïˆâˆ’AiC|(cid:104)

s(cid:48)Â¯Ai

, m(cid:48)Â¯Ai

, Î±(cid:48)i(cid:105)
s Â¯Ai, m Â¯Ai, Î±i|Â±

, sA, M, Î±

K 1

i,M,Î±,s(cid:48)

,m(cid:48)

Â¯Ai

,Î±(cid:48)
i

= 2âˆ’

Â¯Ai

1/2

+, N/2, M, Î±
(cid:104)

|

s(cid:48)Â¯Ai

, m(cid:48)Â¯Ai

,
, Î±(cid:48)i(cid:105)

N âˆ’1

Â±
2 N âˆ’

28

, sA, M, Î±

s(cid:48)Â¯Ai
|

, m(cid:48)Â¯Ai

,
, Î±(cid:48)i(cid:105)

(cid:105)(cid:104)Â±

(S109)

where each set of states
s Â¯Ai , m Â¯Ai, Î±i(cid:105)
|
of the space corresponding to all ports j with j
simplify the Kraus operators we study the overlap

represents a basis
= i. To

provide exactly the same operation and, accordingly, we
can sum over these equivalent Kraus operators to reduce
the number of indices. After this process, we get

sÂ¯Ä±, mÂ¯Ä±, Î±i|Â±
(cid:104)
(cid:88)
k
=
(cid:105)C(cid:104)
|

, S, M, Î±
(cid:105)
sÂ¯Ä±, mÂ¯Ä±, Î±i|

Î“M,m,k
2 ,S|
S
Â±

1

S, m, Î±

k,m
(cid:88)

k,m
(cid:88)

k,(cid:96),m

=

=

k
|

(cid:105)C(cid:104)

k
|

(cid:105)C|

sÂ¯Ä±, mÂ¯Ä±, Î±i|
(cid:105)AiÎ“M,m,k
(cid:96)

S

1

Â±

Î“M,m,k
1
2 ,S
S
Â±

(cid:88)

|

(cid:96)

2 ,SÎ“m,mÂ¯Ä±,(cid:96)

S,sÂ¯Ä± â‰¡

(cid:96)
(cid:105)i|

(cid:105)A
s(cid:48)Â¯Ä±, m(cid:48)Â¯Ä±, Î±(cid:48)i(cid:105)Â¯Ä±Î“m,m(cid:48)
Ë†QsÂ¯Ä±,mÂ¯Ä±
Â±

,s,M .

S,s(cid:48)
Â¯Ä±

Â¯Ä±,k

(S110)

(cid:113)

(sA)âˆ’

1/2

Î»

Â±

g[N

1](sÂ¯Ä±)

âˆ’

Ã—

,sA,M

Â±
Ë†QsÂ¯Ä±,mÂ¯Ä±
Â±

,sA,M

Ë†QsÂ¯Ä±,m(cid:48)

Â¯Ä±
,sA,M â€ 

Â±

(cid:17)

11B,

âŠ—

K 0

(cid:96) â‰¡

K 0

sÂ¯Ä±,mÂ¯Ä±,m(cid:48)
Â¯Ä±

= 2âˆ’

N âˆ’1

2 âˆšN

(cid:88)

(cid:16)

Ïˆâˆ’AC|
(cid:104)
K 1
(cid:114)

g[N

M,sÂ¯Ä±,mÂ¯Ä±

Ã—

K 1

(cid:96) â‰¡

=

1](sÂ¯Ä±)
1

âˆ’

âˆ’
2N

Ë†QsÂ¯Ä±,m(cid:48)

Â¯Ä±
+,N/2,M â€ 

11B.

âŠ—

(S111)

(S112)

In the last line we ï¬nd that the overlap is independent
of Î± and Î±i, though with constraints Î± = (sÂ¯Ä±, Î±i), which
requires Î±i = Î±(cid:48)i. Therefore, diï¬€erent Kraus operators

The Kraus operators of the reduced channel ËœÎ› are ob-
tained as (K u
11AB). It is simple to check
that the above operators deï¬ne a CPTP-map.

Î¨âˆ’CD(cid:105) âŠ—
|

11D)(

(cid:96) âŠ—

(cid:54)
