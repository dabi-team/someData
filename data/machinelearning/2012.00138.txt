1
2
0
2

r
p
A
7
2

]

G
L
.
s
c
[

2
v
8
3
1
0
0
.
2
1
0
2
:
v
i
X
r
a

Proceedings of Machine Learning Research vol xxx:1–18, 2021

Robust error bounds for quantised and pruned neural networks

Jiaqi Li
JIAQI.LI@ST-HUGHS.OX.AC.UK
Ross Drummond
ROSS.DRUMMOND@ENG.OX.AC.UK
Stephen R. Duncan
STEPHEN.DUNCAN@ENG.OX.AC.UK
Department of Engineering Science, University of Oxford, 17 Parks Road, OX1 3PJ, Oxford, United Kingdom

Abstract
With the rise of smartphones and the internet-of-things, data is increasingly getting generated
at the edge on local, personal devices. For privacy, latency and energy saving reasons, this shift is
causing machine learning algorithms to move towards decentralisation with the data and algorithms
stored, and even trained, locally on devices. The device hardware becomes the main bottleneck for
model capability in this set-up, creating a need for slimmed down, more efﬁcient neural networks.
Neural network pruning and quantisation are two methods that have been developed for this, with
both approaches demonstrating impressive results in reducing the computational cost without sac-
riﬁcing signiﬁcantly on model performance. However, the understanding behind these reduction
methods remains underdeveloped. To address this issue, a semi-deﬁnite program is introduced to
bound the worst-case error caused by pruning or quantising a neural network. The method can
be applied to many neural network structures and nonlinear activation functions with the bounds
holding robustly for all inputs in speciﬁed sets. It is hoped that the computed bounds will provide
certainty to the performance of these algorithms when deployed on safety-critical systems.
Keywords: Robustness; quantised neural networks; error bounds.

1. Introduction

The way we generate data is rapidly changing in response to the rise of the internet-of-things and the
widespread use of smartphones (Zhou et al., 2019). In terms of data sources, there is an accelerating
shift away from big data, like e-commerce records, stored on mega-scale cloud data centres towards
more localised data sources generated by users interacting with their personal devices (Zhang et al.,
2019). This evolving data landscape is causing a rethink to how machine learning algorithms are
trained and implemented.

The most intuitive way to train and implement these algorithms within this new data landscape
remains centralised learning where the data is sent to a central data centre in the cloud where the
algorithm is then trained and run (Zhou et al., 2019). This approach should give the best model
performance and is a natural extension of existing algorithm training frameworks but has several
ﬂaws (Zhou et al., 2019; G¨und¨uz et al., 2019). These include: (i) Concerns around user privacy
since the data is stored in a data centre which could be owned by a third party, (ii) The increased
latency of centralised algorithms in responding to new data, and (iii.) As the algorithms get ever
larger in response to the growing availability of data, they are requiring signiﬁcantly more compute
power, memory storage and energy.

These ﬂaws are inherent to centralised learning and motivate growing efforts to direct machine
learning towards a more decentralised approach. With decentralised learning (Zhang et al., 2019;
Zhou et al., 2019) (often known as edge intelligence (Zhou et al., 2019; Deng et al., 2020; Shi et al.,
2020) and falling under the umbrella of distributed learning (Zhang et al., 2019) amongst other
labels), there is a greater emphasis on implementing and even training the algorithms locally on

© 2021 J. Li, R. Drummond & S.R. Duncan.

 
 
 
 
 
 
ROBUST PRUNING AND QUANTISATION BOUNDS

devices. In this way, decentralised learning aims to generate smaller, more personalised algorithms
that can help circumnavigate the above-mentioned issues with centralised learning- albeit typically
doing so at the expense of model performance (Zhang et al., 2019). Running the algorithms locally
on the devices means that hardware constraints (e.g. memory availability, compute power and en-
ergy consumption) become important. Managing these constraints whilst still delivering reasonable
model performance is one of the main bottlenecks that decentralised learning needs to overcome
and has led to a push for slimmed-down, efﬁcient algorithms (typically neural networks (NNs)-
the class of model focussed on in this work). As such, there has been increased interest in pruned
neural networks which sparsify the weights and biases (Blalock et al., 2020) and quantised neural
networks (e.g. (Shin et al., 2016; Courbariaux et al., 2014; Sung et al., 2015)) which use a coarse
ﬁxed-point representation of the algorithm’s parameters. However, a full and robust understanding
of how modiﬁcations like network pruning and quantisation affect the neural networks outputs, that
goes beyond sensitivity studies like (Shin et al., 2016) for instance, is as yet still not fully developed.
To address these issues, this paper introduces a formal framework to compute performance guar-
antees for neural networks implemented on low-cost and memory-limited hardware. Speciﬁcally,
we address the problem of determining how the output of a neural network is corrupted by either
quantising its parameters and/or data after storing them using ﬁxed-point arithmetic or from prun-
ing it. In other words, a method to compute bounds for quantised and pruned neural networks is
introduced. The main contributions are:

• A semi-deﬁnite program (SDP) to bound the worst-case error from neural network pruning

or from quantising its weights, biases and input using ﬁxed-point arithmetic.

• The computed bounds hold robustly for all input data in speciﬁed sets and account for the

neural network’s nonlinearities.

• The neural network quantisation and pruning bounds are shown to be special cases of a more
general problem, called the neural network similarity problem, which bounds the worst-case
error of two different neural networks outputs for all inputs in speciﬁc sets.

The neural network similarity problem (Problem 1) connects to the notion of incremental stability
in dynamical systems (Zames, 1966), with the second neural network of the problem being either
the quantised or pruned version.

Related work: Many results have demonstrated the potential of both quantised and pruned neural
networks to realise machine learning on limited hardware. For example, Gong et al. (2014) achieved
a 16-24× network compression for the 1000-category classiﬁcation on ImageNet with only a 1%
loss of classiﬁcation accuracy and Lin et al. (2016) showed no loss in accuracy by reducing a model
trained on the CIFAR-10 benchmark by > 20%. More extreme levels of quantisation have also been
explored, for example binarised neural networks (where the weights and/or activation functions are
restricted to be binary) have also demonstrated rapid compute speeds and large memory savings
without signiﬁcant accuracy losses (Hubara et al. (2016) and Rastegari et al. (2016)).

The quantisation error bounds presented in this work are closely related to the semi-deﬁnite pro-
grammes for certifying neural network robustness developed in Fazlyab et al. (2019); Raghunathan et al.
(2018); Dathathri et al. (2020). These SDPs guarantee that small perturbations in the input will not
lead to large variations in the NN output and can help prevent against adversarial attacks and make
the NNs more reliable to out-of-sample data. Recently, there has been a focus on improving the

2

ROBUST PRUNING AND QUANTISATION BOUNDS

scalability of these SDP robustness certiﬁcates (Dathathri et al., 2020) (since they scale by O(n6)
in runtime and O(n4) in memory requirements, where n is the number of neurons in the network
(Dathathri et al., 2020)), a particularly exciting direction for this paper as it could help make the
presented bounds applicable to larger NNs.

+

+ and Rn×n

Acronyms, Notations and Preliminaries
R+, Rn
denote real non-negative numbers, non-negative real vectors of dimension n and
real non-negative matrices of size n × n respectively. Positive diagonal matrices of size n × n are
denoted Dn
+. Z+ (Z−) is the set of positive (negative) integers. The set of natural numbers (non-
negative integers) is N. The matrix of zeros of dimension n × m is 0n×m and 0n is the vector of
zeros of dimension n. The matrix of ones of dimension N × M is 1N ×M and 1N is the vector of
ones of dimension N . The identity matrix of dimension N is IN . The blkdiag{a} function takes
an array as input and returns a block diagonal matrix with elements of a on its main diagonal as
ordered in a. Strict and elementwise LMIs are posed as F (x) > 0 while non-strict and elementwise
LMIs are written as F (x) > 0. A positive (negative) deﬁnite matrix Ω is denoted Ω ≻ (≺) 0,
and a positive (negative) semi-deﬁnite Γ matrix is written Γ < (4) 0. The p-norm is displayed by
|| · ||p : Rn → R+, p ∈ N. Where acronyms are used, “NN” stands for “artiﬁcial neural network”,
“QC” stands for quadratic constraint, “LMI” stands for “linear matrix inequality”, and “SDP” stands
for “semi-deﬁnite programme”.

2. Neural Networks: Representation in state-space form

Consider two functions f1(x1) : X → F and f2(x2) : X → F acting upon input data x1, x2 ∈ X .
These functions are assumed to be deﬁned by feed-forward NNs composed of ℓ hidden layers, with
l
the kth layer composed of nk neurons and the total number of neurons being N =
k=1 nk. Both
the ﬁrst and second neural network (i ∈ {1, 2}) can be expanded out in a state-space-like form

P

x0
i = xi,
xk+1
i = φ(W k
i xℓ
fi(xi) = W ℓ

i ),

i xk
i + bk
i + bℓ
i.

k = 0, 1, . . . , ℓ − 1,

(1a)

(1b)

(1c)

i ∈ Xi ⊆ Rnx represents the input data, W k

i ∈ Rnk+1×nk
Here, for neural network i ∈ {1, 2}, x0
i ∈ Rnk+1 the biases, k = 0, . . . , ℓ − 1, deﬁnes the network layers, nx and nf
the weights, bk
are, respectively, the network’s input and output dimensions and φ(·) are the activation functions-
typically a rectiﬁed Linear Unit (ReLU), sigmoid or tanh- which in this paper can be any function
satisfying some of the properties of Deﬁnition 4 in Appendix 4. The activation functions are taken
to act elementwise on their vector arguments.

3

ROBUST PRUNING AND QUANTISATION BOUNDS

2.1. Compact neural network representation

For the ith ∈ {1, 2} neural network, deﬁne the arguments of the activation functions φ(·) as



ξ1
i
ξ2
i
...
ξℓ
i

W 0
i
0n2×n2
...
0nl×nx

= 






ξi = 





0n1×n1
. . .
. . .
. . .

. . .
. . .
. . .
0n1×nl−2

0n1×nl−1
...
0nℓ−1×nℓ−2
W ℓ−1
i







x0
i
x1
i
...
xℓ−1
i





These vectors allow the ith NN of (1) be written in the more compact form

















ξk+1
i xi + bk
i = W k
i ,
i = φ(ξk+1
xk+1
),
i
i ) + bℓ
i φ(ξℓ
fi(xi) = W ℓ
i.

k = 0, 1, . . . , ℓ − 1,

k = 0, 1, . . . , ℓ − 1,

b0
i
b1
i
...
bℓ−1
i

+ 







∈ RM .

(2)






(3a)

(3b)

(3c)

The vectors

µ =

T ,

ξ1

ξ2

h

T , φ(ξ1)T , φ(ξ2)T , 1
i

h

T

, η =

x1

T , x2

T , φ(ξ1)T , φ(ξ2)T , 1

T

,

(4)

i

will also be used throughout the paper to build the various inequalities. These two vectors are
linearly related through a matrix E ∈ R2(nx+M )+1×4M +1 by η = Eµ.

2.2. The neural network similarity problem: Bounding the worst-case error between two

neural networks

The neural network similarity problem is now introduced to bound the worst-case error between the
outputs of two neural networks for all input data in pre-deﬁned sets (e.g. hypercubes). Solutions to
this problem indicate how similar two NNs are to each other.

Problem 1 Given the two neural networks f1(x1) : X → F and f (x2) : X → F from (1),
minimise the worst-case output error bound

||f1(x1) − f2(x2)||2

2 ≤ γ + γx1kx1k2

2 + γx2kx2k2

2 + γxkx1 − x2k2
2,

∀x1, x2 ∈ X ,

(5)

subject to (γx, γx1, γx2, γ) ∈ R+.

The above problem establishes the general framework to address the speciﬁc problem of interest
to this paper- that of bounding the worst-case error of a pruned or quantised neural network. To
specialise Problem 1 to the computation of this NN quantisation bound, the second neural network
in Problem 1 set to be the quantised one, as in

W k

2 = q(W k

1 ),

2 = q(bk
bk

1),

x2 = q(x1),

(6)

where q(·) is the quantisation function deﬁned in Section 3.2. Likewise, upon considering pruned
2 = p(W k
networks, Problem 1 is adapted by setting the second NN to be the pruned one, as in W k
1 )
where p(·) is a pruning operator, see Section 4.

4

ROBUST PRUNING AND QUANTISATION BOUNDS

3. Quantised neural networks

This section outlines a mathematical representation of quantisation when applied to neural network
elements. With this representation, network quantisation can be incorporated into the neural net-
work similarity problem of Problem 1, to bound the effect of additionally quantising the network
input and neuron parameters.

3.1. Fixed-point arithmetic

It will be assumed that the quantised neural network’s weights, biases and data are stored using
ﬁxed-point arithmetic, detailed in Yates (2009); Barrois and Sentieys (2017). The hIB,FBi for-
mat for ﬁxed-point representations adopted in Gupta et al. (2015); Holi and Hwang (1993) is used,
whereby IB and FB respectively denote the number of bits allocated for the integer and fractional
parts of the number. As an example, the number 31.4592 is represented as

sign

mantissa

error = 0.3342

31.4592

0 1 1 1 1 1 1 1

= 31.125

integer bits

fractional bits

In this work, saturation of the representation is neglected. This is an important issue but could
be avoided with the introduction of “temporary ﬁxed-point registers with enough number of bits”
(Gupta et al. (2015)).

3.2. Quantisation function

The piece-wise constant quantisation function q(·) acting element-wise on vector and matrix ar-
guments can be used to capture the ﬁxed-point representation of the quantised neural network’s
weights, biases and data.

Given a real number s ∈ R, the quantisation function is deﬁned as

q(s) ,

sgn(s)⌊|s| · ∆⌋
∆

, ∆ = 2−FB, FB ∈ Z+,

(7)

where ⌊·⌋ is the “ﬂoor” operator and ∆ is the binary quantisation step, with the word length FB
setting the numerical precision of the quantisation. For the robustness analysis of the following
sections, this function will be upper and lower bounded by

q(s)

)-q(s)   0
(s+ (cid:2)

)    0
q(s)-(s- (cid:1)

(cid:3)

(cid:0)

s

Decreasing FB causes a coarse ﬁxed-point representation, resulting in information being lost
because of the quantisation and the neural network’s output being corrupted, inducing an error.

5

ROBUST PRUNING AND QUANTISATION BOUNDS

Given a binary number (BN ) represented in ﬁxed-point format, the original decimal format (DN )
can be recovered from

DN =

IB−1

i=1
X

FB−1

BNhIii ∗ 2i +

BNhF ij ∗ 2−j,

j=1
X

(8)

with hIi and hF i denoting the integer and fractional parts of BN .

Note in this work the ﬂoor rounding scheme was used, i.e. q(·) maps an input value to the
largest integer multiple of ∆ smaller than the input value. Other rounding schemes exist and may
be adapted into the proposed framework, e.g. round-to-nearest (Gupta et al. (2015)) and various
piece-wise-linear and stochastic rounding methods.

As ReLU activation functions were adopted for the numerical results of this paper, the effect of
additionally quantising the activation functions was ignored. However, this effect could be incorpo-
rated into the analysis as long as the quantised activation functions satisfy the quadratic constraints.

4. Pruned neural networks

Neural network pruning involves setting the weights or neurons considered to be the least important
to zero, with the purpose of making the network structure sparse and so improve its computational
and memory efﬁciency (Hooker et al. (2019)). A state-of-the-art pruning method is presented in
Han et al. (2015) where a three-step framework is applied to train, prune and reﬁne neural network
parameters. Using this framework both AlexNet and VGG-16 have been successfully and effectively
downsized with no loss in accuracy (Han et al. (2015)). In this paper, the operator p(·) denotes the
pruning action implemented with a magnitude based approach, although other pruning approaches
may also be implemented. By setting the second NN in (1) to be the pruned version, Problem 1 can
be solved to compute the pruning error bounds.

5. Abstracting the nonlinearities and sets using quadratic constraints

In general, solving Problem 1 is intractable because of: (i) the potentially non-convex mapping of
each NN with nonlinear activation functions, and (ii) the bounds are required to hold robustly for
all inputs in the pre-deﬁned set (x1, x2) ∈ X with X allowed to be inﬁnite dimensional. Using
quadratic constraints, this paper is able to provide an upper bound for the error from neural network
pruning and quantisation by producing an algebraic, convex outer approximation of the various sets
and nonlinearities of the problem. This allows solutions to Problem 1 to be computed via a SDP,
with the conservatism of the approach coming from the fact that it only implicitly characterises
the various nonlinearities and sets of the analysis. The remaining part of this section details the
quadratic constraints for the input set, the nonlinear activation functions, the quantisation and the
error bound (14).

5.1. Abstraction of the input set

The various quadratic constraints satisﬁed when the NN inputs are contained to the set (x1, x2) ∈ X
are detailed in Appendix 3. When the inputs are constrained to this set, there exists a matrix PX ∈
R2(nx+M )+1×2(nx+M )+1 built from the matrix variables (the lambdas of Deﬁnition 3 in Appendix

6

ROBUST PRUNING AND QUANTISATION BOUNDS

3) such that

MX (PX ) = ηT PX η ≥ 0,

∀(x1, x2) ∈ X .

(9)

5.2. Abstraction of the activation functions

Dealing with the nonlinear activation functions is the main source of difﬁculty in generating robust
solutions to Problem 1. Thankfully, most of the commonly used NN activation functions (e.g.
those mentioned in Table 1 of Appendix 3 have properties that allow them to be characterised by
quadratic constraints. The mathematical deﬁnitions of these properties can be found in Deﬁnition.
4 of Appendix 4 and the associated quadratic constraints are given in Lemma 5 of Appendix 4.

Using the compact NN representation of (3), the various quadratic constraints satisﬁed by the
activation functions of Lemma 5 in Appendix 4 can be collected together and represented as a
single inequality

Mφ(Λ) = µT Λµ = ηT

ET ΛE

η ≥ 0,

∀(x1, x2) ∈ X .

(10)

Here, the matrix

(cid:0)

(cid:1)

T

0N ×N 0N ×N Λ13
0N ×N 0N ×N Λ23
T
Λ23
Λ13
Λ33
T Λ34
Λ24
Λ14
T Λ35
Λ25
Λ15

T

T

Λ14 Λ15
Λ24 Λ25
Λ34 Λ35
T Λ44 Λ45
T Λ55
T Λ45









Λ =









(11)

is composed of elements Λi,j, {i, j} ∈ {1, 2, 3, 4, 5} being linear combinations of the scaling vari-
ables of the various quadratic constraints of φ(·), e.g. the lambdas of Lemma 5 in Appendix 4.

Note that information on the quantisation and pruning of the NN parameters (weights and biases),
or any other alteration in value or structure to the parameters in general, is introduced a priori into
the SDP problems’ constraints via the abstractions just deﬁned, and therefore, does not require extra
QCs.

5.3. Abstraction of the quantisation function

Besides the activation functions φ(·), for quantised NNs the quantisation function q(xi) from (7)
acting on the input data is another nonlinearity that will have to to be accounted for in the analysis if
error bounds are to be obtained. Thankfully, this nonlinear function also satisﬁes certain quadratic
constraints as deﬁned in Lemma 7 of Appendix 5. These quadratic constraints can be combined into
the single inequality

Mq(Pq) = ηT Pq η ≥ 0,

∀(x1, x2) ∈ X ,

(12)

for some matrix variable Pq built from the various lambdas of Lemma 7 of Appendix 5.

5.4. Abstraction of the error bound

The bound for the worst-case error between the two neural networks

||f1(x1) − f2(x2)||2

2 − (γ + γx1kx1k2

2 + γx2kx2k2

2 + γxkx1 − x2k2

2) ≤ 0,

∀(x1, x2) ∈ X (13)

7

ROBUST PRUNING AND QUANTISATION BOUNDS

can also be expressed as a quadratic

Mkf −gk2(Γ) = ηT V T Γ(γx1 γx2, γx, γ) V η ≤ 0,

∀(x1, x2) ∈ X ,

(14)

where

and

V =

Γ = −

(γx1 + γx)Inx1
−γxInx2

0nf1 ×nx1
0nf2
0nx1

T








−γxInx1
(γx2 + γx)Inx2
0nf1 ×nx2
0nf2 ×nx2
0nx2

T

0nx1 ×nf1
0nx2 ×nf1
Inf1
−Inf2
0nf1

T

0nx1 ×nf2
0nx2 ×nf2
−Inf1
Inf2
01×nf2

T

0nx1
0nx2
0nf1
0nf2
γ

,










(15)

Inx1
0nx2 ×nx1
0nf1 ×nx1
0nf2 ×nx1
0nx1

T

0nx1 ×nx2
Inx2
0nf1 ×nx2
0nf2 ×nx2
0nx2

T

0nx1 ×M
0nx2 ×M
0nf1 ×M −nℓ1
0nf2 ×M
0M

T

(cid:2)

W ℓ
1

(cid:3)

(cid:2)

0nx1 ×M
0nx2 ×M
0nf1 ×M
0nf2 ×M −nℓ2

0M

T

0nx1
0nx2
bℓ
1
bℓ
2
1

W ℓ
2

(cid:3)










.

(16)










Here, for a fair comparison, nx1 = nx2 and nf1 = nf2, as in both NNs have the same number of
inputs and outputs.

6. Neural network error bounds as a semideﬁnite programme

With the QCs deﬁned for each feature of the problem, upper bounds to (5) in Problem 1 can be
computed from the SDP of Theorem 1. Worst-case error bounds for pruned neural networks can be
obtained directly upon setting the second network of the problem to be the pruned one. The spe-
cialisation to quantised neural networks has the quantisation quadratic constraints of (12) included
within the linear matrix inequality (17b).

Theorem 1 Consider the two neural networks deﬁned in (1) satisfying the quadratic constraints
of (9), (10) and (12). Set the weights (wx1, wx2, wx, waff) ∈ R+ scaling the relative importance of
the quadratic and afﬁne terms in the error bound (13). If there exists a solution to

min wx1γx1 + wx2γx2 + wxγx + wafﬁneγ,

subject to PX (·) + Pq(·) + ET Λ(·)E + Γ(·) ≺ 0,

γx1 > 0, γx2 > 0, γx > 0, γ > 0.

(17a)

(17b)

(17c)

with the matrix variables PX (·), Pq(·), Λ(·) and Γ(·) deﬁned in (9), (12), (10) and (14), then the
error between the two neural networks is bounded from above by

kf1(x1) − f2(x2)k2

2 ≤ γ + γx1kx1k2

2 + γx2kx2k2

2 + γxkx1 − x2k2
2,

(x1, x2) ∈ X .

(18)

Proof See Appendix 6.

8

ROBUST PRUNING AND QUANTISATION BOUNDS

7. Numerical examples and discussion

In this section, the effectiveness of the obtained bounds was explored with several numerical ex-
amples. The ﬁrst subsection presents examples for bounding the error between two generic neural
networks, and the second is focused on quantised and pruned networks.

In all the examples, the input was constrained to the hyper-cube (x1, x2) ∈ X = {x1, x2 ∈
Rnx | |x1|, |x2| ≤ x}, where x = 1 and the ReLU was chosen as the activation function. For
all examples, the SDP of Theorem 1 was solved with the MOSEK (ApS, 2019) solver implemented
through the YALMIP (L¨ofberg, 2004) interface of MATLAB. The code and the various models used
in the examples can be found at: https://github.com/ElrondL/Robust-Quantisation-Bounds.

7.1. Neural network similarity bounds

For the ﬁrst experiment, the performance of the framework deﬁned in Theorem 1 was checked by
comparing randomly generated neural networks with nx = 1 as the input dimension, nf = 1 as
the output dimension and ℓ = 1, 2, 3, 4 hidden layers, each with nk = 10 neurons. The two
neural networks were fed with randomly generated signals {x1, x2} ∈ X . For each NN layer
dimension (ℓ), 100 random neural networks were generated and the average γx1, γx2, γx, γ, mean
bound tightness, maximum bound tightness, minimum bound tightness, and runtime were recorded.
Tightness of the bound was deﬁned as the natural log of the error between the output difference
norm and the over approximation bound

T = ln((f (x1) − f (x2))2) − ln(γx1x2

1 + γx2x2

2 + γx(x1 − x2)2 + γ),

(19)

with the results given in Table 2 of Appendix 7.

(a) The error (coloured) and bound (grey)

(b) The tightness surface T of the bound

surfaces.

and error surfaces in Fig.1(a)

Figure 1: Example neural network error bound with ℓ = 2.

A bounding surface holding robustly for all inputs generated was obtained for each test case, an
example of which can be found in Figure 1. When nx = 1 and nf = 1, the bound follows the error
surface with T ≤ 2 for the majority of the input space. The singularity of the log function at zero
means that points in the input space generating small errors between the two neural networks are
associated with the deep valleys in the ﬁgure. The average distance between the bound and the error
surface became larger with an increasing number of neurons and for multi-dimensional input and
output vectors, as reﬂected in Table 2’s data.

9

ROBUST PRUNING AND QUANTISATION BOUNDS

7.2. Quantisation error bound

Error bounds were also computed for quantised NNs where W2 = q(W1), b2 = q(b1) and x2 =
q(x1). Here, the output dimension was nf = 1, the input dimension was nx = 1 with the input
set for x1 consisting of 100 evenly spaced values in [−1, 1]. The quantisation step was ∆ = 2−2,
as in two bits were used to store each number. Figure 3 in Appendix 7 contains example error
bound curves for the various models considered and also an example in 3D (where the condition
x2 = q(x1) was relaxed, giving a looser bound as the input space was less restricted).

Bounds were then computed for 100 randomly generated NNs with ℓ = 4 hidden layers, with the
corresponding results shown in Table 3 of Appendix 7. Bound tightness was deﬁned as the error
between the original and quantised networks’ output difference norm and the over-approximation
bound of (19).

A bounded curve holding for all inputs was generated for each test case, with the step patterns of
the error curves following from the quantisation. It was also observed that the bound loosened with
an increasing number of neurons, as seen in Table 3 of Appendix 7.

Worst-case quantisation error bound

The worst-case quantisation error and bound values were also recorded and averaged for 100 random
neural networks of ℓ = 2 layers for quantisation levels ∆ = 2i, i ∈ {1, 2, 3, 4, 5}. Note that
the bound and error values come in pairs, so there exists a bound value corresponding with the
maximum error as well as an error value corresponding to the maximum bound value. These results
where then plotted in Figure 4 of Appendix 7 where the maximum bound values tended to be close
to the observed maximum error, however the gap between the corresponding maximum error and
the bound tended to be quite large. It was also observed that both the error and the bound decreased
at similar rates with an increasing level of quantisation.

Pruned neural networks

Figure 5 in Appendix 7 shows the results for bounding the error between a randomly-generated 20
neuron neural network and its pruned version (with f2(x2) in Problem 1 being the pruned one), with
the weights of the eight hidden neurons with smallest 2-norms set to zero (Blalock et al. (2020)).
Note, that by setting the second neural network to be identical to the ﬁrst, the framework could also
bound the behaviour of a neural network within its input space. Pruning that removes neurons rather
than setting weights to zero could also be bounded with this framework.

Conclusions

A method to generate uppers bounds for the worst-case error induced by either quantising or pruning
a trained neural network was introduced. The bounds hold robustly for all inputs in pre-speciﬁed
sets, account for nonlinear activation functions and are generated from the solution of a semi-deﬁnite
programme. Several numerical examples graphically illustrated the tightness of the bounds. Future
work will explore reducing the conservatism of the bounds, improving the scalability of the semi-
deﬁnite programming solvers and applying the method to other problems of interest where the
similarity of two neural networks is to be evaluated.

10

ROBUST PRUNING AND QUANTISATION BOUNDS

Acknowledgments

Ross Drummond would like to thank the Royal Academy of Engineering for funding this research
through a UKIC Fellowship as well as the Nextrode project of the Faraday Institution. Jiaqi Li
would like to thank the Department of Engineering, University of Oxford for funding through the
UROP scheme.

References

MOSEK ApS. The MOSEK optimization toolbox for MATLAB manual. Version 9.0., 2019. URL

http://docs.mosek.com/9.0/toolbox/index.html.

B. Barrois and O. Sentieys. Customizing ﬁxed-point and ﬂoating-point arithmetic — A case study
in K-means clustering. In International Workshop on Signal Processing Systems (SiPS), pages
1–6, 2017. doi: 10.1109/SiPS.2017.8109980.

Davis Blalock, Jose Javier Gonzalez Ortiz, Jonathan Frankle, and John Guttag. What is the state of

neural network pruning? arXiv preprint arXiv:2003.03033, 2020.

Matthieu Courbariaux, Yoshua Bengio, and Jean-Pierre David. Training deep neural networks with

low precision multiplications. arXiv preprint arXiv:1412.7024, 2014.

Sumanth Dathathri, Krishnamurthy Dvijotham, Alexey Kurakin, Aditi Raghunathan, Jonathan Ue-
sato, Rudy R Bunel, Shreya Shankar, Jacob Steinhardt, Ian Goodfellow, Percy S Liang, et al.
Enabling certiﬁcation of veriﬁcation-agnostic networks via memory-efﬁcient semideﬁnite pro-
gramming. Advances in Neural Information Processing Systems, 33, 2020.

Shuiguang Deng, Hailiang Zhao, Weijia Fang, Jianwei Yin, Schahram Dustdar, and Albert Y
Zomaya. Edge intelligence: the conﬂuence of edge computing and artiﬁcial intelligence. IEEE
Internet of Things Journal, 2020.

Ross Drummond, Mathew C Turner, and Stephen R Duncan. Reduced-order neural network syn-

thesis with robustness guarantees. arXiv preprint arXiv:2102.09284, 2021.

Mahyar Fazlyab, Manfred Morari, and George J Pappas. Safety veriﬁcation and robustness anal-
ysis of neural networks via quadratic constraints and semideﬁnite programming. arXiv preprint
arXiv:1903.01287, 2019.

Yunchao Gong, Liu Liu, Ming Yang, and Lubomir Bourdev. Compressing deep convolutional net-

works using vector quantization. arXiv preprint arXiv:1412.6115, 2014.

Deniz G¨und¨uz, Paul de Kerret, Nicholas D Sidiropoulos, David Gesbert, Chandra R Murthy, and
Mihaela van der Schaar. Machine learning in the air. IEEE Journal on Selected Areas in Com-
munications, 37(10):2184–2199, 2019.

Suyog Gupta, Ankur Agrawal, Kailash Gopalakrishnan, and Pritish Narayanan. Deep learning with
In International Conference on Machine Learning, pages 1737–

limited numerical precision.
1746. PMLR, 2015.

11

ROBUST PRUNING AND QUANTISATION BOUNDS

Song Han, Jeff Pool, John Tran, and William J Dally. Learning both weights and connections for

efﬁcient neural networks. arXiv preprint arXiv:1506.02626, 2015.

J. L. Holi and J. . Hwang. Finite precision error analysis of neural network hardware implementa-

tions. IEEE Transactions on Computers, 42(3):281–290, 1993. doi: 10.1109/12.210171.

Sara Hooker, Aaron Courville, Gregory Clark, Yann Dauphin, and Andrea Frome. What do com-

pressed deep neural networks forget? arXiv preprint arXiv:1911.05248, 2019.

Itay Hubara, Matthieu Courbariaux, Daniel Soudry, Ran El-Yaniv, and Yoshua Bengio. Binarized
In Advances in Neural Information Processing Systems, pages 4107–4115,

neural networks.
2016.

Ulf J¨onsson. Lecture notes on integral quadratic constraints. 2001.

Darryl Lin, Sachin Talathi, and Sreekanth Annapureddy. Fixed point quantization of deep convolu-
tional networks. In International Conference on Machine Learning, pages 2849–2858, 2016.

J. L¨ofberg. Yalmip : A toolbox for modelling and optimization in matlab. In In Proceedings of the

CACSD Conference, Taipei, Taiwan, 2004.

Aditi Raghunathan, Jacob Steinhardt, and Percy S Liang. Semideﬁnite relaxations for certifying
In Advances in Neural Information Processing Systems,

robustness to adversarial examples.
pages 10877–10887, 2018.

Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, and Ali Farhadi. Xnor-net: Imagenet
classiﬁcation using binary convolutional neural networks. In European Conference on Computer
Vision, pages 525–542. Springer, 2016.

Yuanming Shi, Kai Yang, Tao Jiang, Jun Zhang, and Khaled B Letaief. Communication-efﬁcient

edge AI: Algorithms and systems. arXiv preprint arXiv:2002.09668, 2020.

Sungho Shin, Kyuyeon Hwang, and Wonyong Sung. Fixed-point performance analysis of recur-
rent neural networks. In International Conference on Acoustics, Speech and Signal Processing
(ICASSP), pages 976–980. IEEE, 2016.

Wonyong Sung, Sungho Shin, and Kyuyeon Hwang. Resiliency of deep neural networks under

quantization. arXiv preprint arXiv:1511.06488, 2015.

Sophie Tarbouriech, Germain Garcia, Jo˜ao Manoel Gomes da Silva Jr, and Isabelle Queinnec. Sta-
bility and stabilization of linear systems with saturating actuators. Springer Science & Business
Media, 2011.

Randy Yates. Fixed-point arithmetic: An introduction. Digital Signal Labs, 81(83):198, 2009.

George Zames. On the input-output stability of time-varying nonlinear feedback systems part one:
Conditions derived using concepts of loop gain, conicity, and positivity. IEEE Transactions on
Automatic Control, 11(2):228–238, 1966.

Chaoyun Zhang, Paul Patras, and Hamed Haddadi. Deep learning in mobile and wireless network-

ing: A survey. IEEE Communications Surveys & Tutorials, 21(3):2224–2287, 2019.

12

ROBUST PRUNING AND QUANTISATION BOUNDS

Bin Zhou, Guang-Ren Duan, and James Lam. On the absolute stability approach to quantized

feedback control. Automatica, 46(2):337–346, 2010.

Zhi Zhou, Xu Chen, En Li, Liekang Zeng, Ke Luo, and Junshan Zhang. Edge intelligence: Paving
the last mile of artiﬁcial intelligence with edge computing. Proceedings of the IEEE, 107(8):
1738–1762, 2019.

Appendices

Appendix 1: Illustration of the neural network similarity problem

Figure 2: Illustration of the similarity problem which bounds the worst case error between the
outputs of two neural networks for all inputs in some set (x1, x2) ∈ X . By setting the second
neural network in this set-up to be the quantised or pruned one, the desired error bounds can be
computed.

Appendix 2: Quadratic constraints overview

As suggested by their name, a quadratic constraint is simply a non-negative quadratic algebraic
expression capturing dependencies between its arguments. For instance, the following is satisﬁed
by the ReLU nonlinearity

pi(s, σ) = (s − ReLU(s))σ ≥ 0,

∀(s, σ) ∈ R.

(20)

Now, consider the case where we have N quadratic constraints pi(·) ≥ 0 for i = 1, . . . , N mapping
Rn → R+ but want to show the negativity of another p0(s, σ) < 0. This is obviously true if there
exists λi ≥ 0, i = 1, . . . , N such that

N

p0(·) +

λipi(·) < 0.

i=1
X

(21)

The above is a version of the S-procedure (J¨onsson, 2001) but simpliﬁed to static systems- and it is
this feature that is utilised in this work to compute the bonds. The beneﬁt of working with (21) is that
it is a linear matrix inequality (LMI) (J¨onsson, 2001), a class of well-understood convex problems.

13

ROBUST PRUNING AND QUANTISATION BOUNDS

For the particular problem considered in the paper, the quantity to be checked p0(s, σ) < 0 relates
to the error bound whilst the speciﬁed non-negative quadratic constraints characterise properties of
the activation functions, inputs sets and quantisation.

Quadratic constraints have a long history in control theory to encode information about un-
known nonlinear disturbances (e.g. control saturation (Tarbouriech et al., 2011) and quantisation
(Zhou et al., 2010)) within a robustness analysis. For the speciﬁc problem considered in this paper,
they bring the beneﬁts of: (i) a common framework for describing the many features of the prob-
lem, including the various nonlinearities and sets, (ii) verifying a quadratic constraint can be cast
as a LMI- a class of well-studied convex optimisation problems. The two main drawbacks are: (i)
they can lead to conservative bounds as the bounds must hold for all terms satisfying the quadratic
algebraic expressions, and (ii) even though a LMI is a convex problem, its complexity scales poorly
(O(n6) in runtime and O(n4) in memory requirements, where n is the number of neurons in the
network (Dathathri et al., 2020)). However, the ability to compute worst-case bounds justiﬁed its
consideration here.

Appendix 3: LMI quadratic constraints for input hyper-rectangle

Each neural network’s input (x1, x2) ∈ X is assumed to lie within hyper-rectangles.

Deﬁnition 2 For the ith neural network with i ∈ {1, 2}, deﬁne the hyper-rectangle containing the
input xi as Xi = {xi : xi ≤ xi ≤ xi}. Within these hyper-rectangles, the combined input data for
both NNs is constrained to (x1, x2) ∈ X , with X potentially capturing cross-conditions relating
the two inputs (for example the input of the second NN being the quantised version of the ﬁrst,
x2 = q(x1)).

The hyper-rectangles Xi, i ∈ {1, 2} are represented by the following quadratic constraints.

Deﬁnition 3 For i ∈ {1, 2}, if xi ∈ Xi then

T

xi

1

PXi

xi
1

(cid:20)

≥ 0, where

(cid:21)

PXi =

−λx∞
(xi + xi) λx∞

2

"

(cid:2)
λx∞
2
−xT

(cid:3)
(xi + xi)
i λx∞xi #

, λx∞ ∈ Dnx
+ .

(22a)

In addition, if x1 = x2 = x and x1 = x2 = x, then the two inputs (x1, x2) also the satisfy joint
quadratic constraints of the form

(2x − (x1 + x2))
(x − x) − (x2 − x1)

(cid:20)

T

(cid:21)

PXjoint

(cid:20)

(x1 + x2) − 2x
(x2 − x1) + x − x

≥ 0,

(cid:21)

(23a)

where

PXjoint =

λx1+x2
0

(cid:20)

0
λx1−x2(cid:21)

,

(λx1+x2, λx1−x2) ∈ Dnx
+ .

(23b)

Other joint conditions may also be satisﬁed by (x1, x2) ∈ X , for instance when the input is quan-
tised x2 = q(x1).

14

ROBUST PRUNING AND QUANTISATION BOUNDS

φ(·) property
Sector bounded
Slope restricted
Bounded
Positive
Positive complement
Complementarity condition
Afﬁne lower bound
Afﬁne upper bound

Sigmoid- 1
2
X
X
X
×
×
×
×
×

tanh ReLU ELU Quantisation
X
X
X
X
X
×
×
×
×
×
×
×
×
×
×
×

X
X
×
X
X
X
×
×

X
X
×
×
×
×
X
X

Saturation
X
X
X
×
×
×
×
×

Table 1: Properties of commonly used activation functions, including the sigmoid, tanh, rectiﬁed
linear unit ReLU and exponential linear unit (ELU).

Appendix 4: LMI quadratic constraints for the activation functions
Deﬁnition 4 (Drummond et al. (2021)) Consider a function φ(s) : S ⊆ R → R satisfying
φ(0) = 0. This function is said to be sector bounded if

slope restricted if

φ(s)
s

∈ [0, δ] ∀s ∈ S,

dφ(s)
ds

∈ [β, β],

∀s ∈ S,

β > 0,

(24a)

(24b)

and monotonic if β = 0. If φ(s) is slope restricted, then it is also sector bounded. The nonlinearity
φ(s) is bounded if

positive if

its complement is positive if

φ(s) ∈ [c, c],

∀s ∈ S,

φ(s) ≥ 0,

∀s ∈ S,

φ(s) − s ≥ 0,

∀s ∈ S,

and it satisﬁes the complementarity condition if

(φ(s) − s)φ(s) = 0,

∀s ∈ S.

(24c)

(24d)

(24e)

(24f)

Lemma 5 Consider ξ1, ξ2 ∈ RM , where ξ1, ξ2 are the arguments of the network activation func-
tions φ(·) deﬁned in (2). If φ(ξ) : RM → RM is a sector-bounded nonlinearity then

(ξi − φ(ξi))T λsec

i φ(ξi) > 0, λsec

i ∈ DM

+ , ∀i ∈ {1, 2}.

(25)

If φ(·) is slope-restricted, then for any (k1, k2) ∈ {1, . . . , M } and (i, j) ∈ {1, 2}
i,j,k1,k2(φ(ξk1

j ) − β(ξk1

j ))T λslope

i ) − φ(ξk2

i ) − φ(ξk2

j )−(φ(ξk1

i − ξk2

i − ξk2

j )) > 0, λslope

(β(ξk1

i,j,k1,k2 ∈ R2M
+ ,

15

(26)

ROBUST PRUNING AND QUANTISATION BOUNDS

and if instead it is just monotonic then

(β(ξk1

i − ξk2

j )−(φ(ξk1

i ) − φ(ξk2

j ))T λmon

i,j,k1,k2(φ(ξk1

i ) − φ(ξk2

j )) > 0, λmon

i,j,k1,k2 ∈ R2M
+ .

If φ(·) is positive, then

λpos
i φ(ξi) > 0,

λpos
i ∈ R1×M

+

, ∀i ∈ {1, 2}.

If φ(·) satisﬁes the complimentary condition, then

(φ(ξi) − ξi)T λcpos

i

φ(ξi) = 0,

λcpos
i

∈ DM ∀i ∈ {1, 2}.

(27)

(28)

(29)

Note that (29) is a strict equality condition and that the positivity of the scaling terms λcpos
can
be relaxed. If both φ(·) and its complement are positive, then the following cross terms are also
obtained

i

φ(ξi)T λcrx

i,j (φ(ξj) − ξj) > 0,
i,j φ(ξj) > 0,

φ(ξi)T λcrx,φ

i,j ∈ RM
λcrx
λcrx, φ
i,j ∈ RM

+ , ∀(i, j) ∈ {1, 2},
+ , ∀(i, j) ∈ {1, 2}.

Deﬁnition 6 (QC for ReLU)

If φ(·) = ReLU (·) then the matrix Λ in (10) is deﬁned by

1

[Λ13, Λ14, Λ15] = [λcomp
[Λ23, Λ24, Λ25] = [−λcrx
[Λ33, Λ34, Λ35] = [−λcomp
[Λ44, Λ45, Λ55] = [−λcomp

, −λcpos
, − λcrx
],
2
2
, −λcpos
, λcomp
],
2
2
, λcrx,φ + λcrx
2 + λcpos
, λpos

2

2

1

1

2 + λcrx
, 0],

1

, λpos

1 + λcpos

1

],

(30a)

(30b)

(31a)

(31b)

(31c)

(31d)

with the scaling terms λcrx,φ, λpos

i

, λcpos
i

, λcrx

i ∈ RN ×N

+

, λcomp
i

∀i ∈ {1, 2} deﬁned in Lemma 5.

Appendix 5: LMI quadratic constraints for quantisation function

Lemma 7 The quantisation function of (7) satisﬁes the following quadratic constraints: it is sector
bounded

(xi − q(xi))T λq,sec

i

(q(xi) ≥ 0,

∀xi ∈ X , i ∈ {1, 2}, λq,sec

i

∈ Dnxi
+ ,

and can be both lower and upper bounded

λq,low
i

q(xi) − (xi − ∆)) ≥ 0, λq,up
i
, λq,up
i

∀xi ∈ X , i ∈ {1, 2}, (λq,low

i

(xi + ∆ − q(xi)) ≥ 0,
) ∈ R1×nxi
+

,

(32)

(33)

with these linear bounds implying the following quadratic for all (xi, xj) ∈ X

(q(xi) − (xi − ∆))T λq,quad

i,j

((xj + ∆) − q(xj)) ≥ 0, , (i, j) ∈ {1, 2}, λq,quad

i,j

∈ Dnxi
+ .

(34)

Proof Follows from deﬁnition of the quantisation function (7). These quadratics could be collected
into the form Pq

16

ROBUST PRUNING AND QUANTISATION BOUNDS

102

100
10-1

10-3

10-5

-1

-0.5

0

0.5

1

(a) Quantisation

bound with
error
∆ = 2−2 and ℓ = 2 with marked
quantisation steps on the x-axis.

(b) Quantisation error bound illustrated in

3D with ∆ = 2−2 and ℓ = 2.

Figure 3: Error bounds of the quantised neural networks.

Appendix 6: Proof of Theorem 1

Proof Multiplying (17b) on the right by η (deﬁned in (4)) and on the left by ηT gives

MX (PX ) + Mq(Pq) + Mφ(Λ) + Mkf −gk2(Γ) < 0,

(35)

where MX (PX ), Mq(Pq) and Mφ(Λ) are the non-negative inequalities deﬁned in (9), (12), (10)
and where Mkf −gk2 (Γ) is the performance metric deﬁned in (14). Since Min(PX ), Mq(Pq) and
Mφ(Λ) are non-negative whenever x ∈ X , then for (35) to hold, it must be that Mkf −gk2 (Γ) < 0,
giving the bound of (18).

Appendix 7: Numerical experiment tables and ﬁgures

ℓ
1
2
3
4

γx
14.9723
181.1923
1432.4
16532

γx1
0.3027
18.6963
351.5557
7309.7

γx2
0.0829
11.9055
259.4226
5344.7

γ
1.7490
52.5948
613.1431
6775.3

mean(T ) max(T ) min(T ) Run time (s)
3.3721
5.0755
6.0144
7.1827

20.0648
21.7170
22.6888
24.2606

1.1667
2.9527
18.7965
78.6121

1.0332
2.3473
3.3431
4.2432

Table 2: Average values (over 100 runs) of the neural network error bounds from Theorem 1 with
T = ln(f1(x1) − f2(x2))2) − ln(γx(x1 − x2)2 + γx1x1

2 + γx2x2

2 + γ).

17

ROBUST PRUNING AND QUANTISATION BOUNDS

ℓ
1
2
3
4

γx
0.0000
0.0000
0.0006
0.00870

γx1
1.0730
19.9720
190.4040
1065.9

γx2
0.0705
0.5333
5.9258
61.1359

γ
2.3730
27.7495
558.7039
10893

mean(T ) max(T ) min(T ) Run time (s)
2.7206
3.9042
4.6004
6.0101

8.7061
10.3077
10.2126
11.5699

0.8629
3.4178
19.8407
87.7687

0.8257
1.8512
2.6929
3.8971

Table 3: Average values (over 100 runs) of the error bounds for the quantised neural network with
T = ln(f1(x1) − f2(x2))2) − ln(γx(x1 − x2)2 + γx1x1
2 + γ) with increasing number of
neurons.

2 + γx2x2

5

0

)
g
o
l

l
a
r
u
t
a
n

n
i
(

s
e
u
l
a
v

r
o
r
r
e

d
n
a

d
n
u
o
B

mean worst case bound
mean worst case error
mean error at worst bound
mean bound at worst error

-5

1

3
Fixed-point binary precision (Number of fractional bits)

5

4

2

Figure 4: Progression of average (over 100 runs) worst case bound and error with quantisation level
for randomly generated neural networks with 20 neurons and ℓ = 2 layers.

(a) The error (coloured) and bound (grey)

surfaces.

(b) The tightness surface T of the bound and
error surfaces in Fig. 5(a), viewed from
another angle.

Figure 5: Error surface of the pruned neural network with ℓ = 4.

18

 
 
 
 
 
 
