0
2
0
2

r
p
A
3

]
E
N
.
s
c
[

1
v
0
8
6
1
0
.
4
0
0
2
:
v
i
X
r
a

The data-driven physical-based equations
discovery using evolutionary approach

Alexander Hvatov and Mikhail Maslyaev

ITMO University, Kronsersky pr. 49, 197101, St. Petersburg, Russia
alex hvatov@itmo.ru

Abstract. The modern machine learning methods allow one to obtain
the data-driven models in various ways. However, the more complex the
model is, the harder it is to interpret. In the paper, we describe the
algorithm for the mathematical equations discovery from the given ob-
servations data. The algorithm combines genetic programming with the
sparse regression.
This algorithm allows obtaining diﬀerent forms of the resulting mod-
els. As an example, it could be used for governing analytical equation
discovery as well as for partial diﬀerential equations (PDE) discovery.
The main idea is to collect a bag of the building blocks (it may be simple
functions or their derivatives of arbitrary order) and consequently take
them from the bag to create combinations, which will represent terms of
the ﬁnal equation. The selected terms pass to the evolutionary algorithm,
which is used to evolve the selection. The evolutionary steps are combined
with the sparse regression to pick only the signiﬁcant terms. As a result,
we obtain a short and interpretable expression that describes the physical
process that lies beyond the data.
In the paper, two examples of the algorithm application are described:
the PDE discovery for the metocean processes and the function discovery
for the acoustics.

Keywords: generic programming · equation discovery · PDE discovery
· data-driven models · sparse regression

1

Introduction

The modern machine learning methods utilize data-driven models for various
purposes. It could be sophisticated surrogate-assisted models [8] as well as the
complex model identiﬁcation using evolutionary-based approaches [5].

Nevertheless, the question of the interpretability of the models arises in the
applications. Generally, we follow the extensive deﬁnition of the model inter-
pretation provided [6]. Unfortunately, the complexity of the model and inter-
pretability of it, in most cases, require trade-oﬀ to obtain good quality and the
understanding of how the given model works [7]. However, we know the good
examples of simple linear regression interpretation [15] and inversion of the con-
volution neural work recognition result [9]. This kind of interpretation, however,

 
 
 
 
 
 
2

A. Hvatov, M. Maslyaev

has a drawback, since the interpretability appears only if the obtained result is
somehow compared with the human’s cognition.

Physics-based models could be the good examples of the interpretable models
[10]. The physics principles provide interpretable basic blocks for the system and
mathematics the way of the, possibly, most human-readable form of the model
record. However, physical laws are mostly obtained manually by an expert in the
ﬁeld. We could try to derive them automatically in the closed form of the function
[13], ordinary diﬀerential equation (ODE) [4], as well as the partial diﬀerential
equations (PDE) [1,12]. However, actual realizations require much preliminary
work, such as a library of possible terms collection for symbolic regression [11].
Such an approach also adds restrictions to the form of the obtained equations
mainly because the set of the possible terms is chosen manually [2].

In the paper, we propose the method that, in our opinion, allows us to com-
bine the transparency of the physical-based models and ﬂexibility of genetic
programming. Moreover, the utility of the sparse regression makes the resulting
model form as concise as possible. The method is also similar to the symbolic
regression. However, genetic programming allows us to build a ﬂexible library of
terms for regression.

On the other hand, such an approach could be considered as an extension to
the AutoML methods [3]. Whereas the last allows obtaining a neural network
with the ”best possible” conﬁguration, the proposed method is used to obtain a
model in an extended form. It means that not only the neural network models
could be obtained.

The paper is organized as follows in Sec. 2 the proposed algorithm is described
in general. In Sec. 3, two implementation examples are provided: Sec. 3.1 con-
tains the example of PDE discovery for the sea surface height data and Sec. 3.2
contains the Floquet polynomial discovery for the periodic structure. Sec. 4 out-
lines the main ﬁndings of the work and some ideas for future development.

2 The algorithm description

Generally, the problem can be summarized as follows: we need to derive a mathe-
matical model (on the current level of framework development, it can be a single
equation only) for a physical system. The input is the set of elementary tokens
T = {t1, t2, ..., tnt}, where nt is the number of all possible elementary tokens,
suﬃcient for the model creation.

The main goal of the proposed algorithm is the detection of token combina-
tions set (which can be denoted as C = {cm = t1 · t2 · ... · tk| ti ∈ T, m = 1, M }
and belongs to the class of all possible token combination sets C, where k is the
number number of tokens in the combination and M is the maximum number
of terms in the equation), that is able to form the nontrivial linear combination
with the minimum absolute value. This approach represents the task to detect
structure of function or equation, which can be viewed as the minimization of
functional | (cid:80)M
i=0 aici| → 0 : ∃j : aj (cid:54)= 0, where ci take roles of the the equation
terms, and ai - weights of the terms.

Physical-based equations discovery using evolutionary approach

3

The algorithm consists of three main elements: the building blocks, which we
will call tokens below, selection, the evolutionary step, and the sparse regression
step. We describe them consequently in this section. The general workﬂow of the
algorithm is presented in Fig. 1.

Fig. 1. The scheme of the method workﬂow: from the declaration of evolutionary al-
gorithm population to the reception of the resulting equation

2.1 The tokens selection

The tokens could be chosen arbitrary and do not have any restrictions on their
nature. However, we stop on the applications of the homogeneous (in terms of
the origin) set of the tokens. It means that we take only basic functions or only
single derivative terms for evolution.

As an example, it can be all derivatives of the ﬁeld up to the order k. An

example of the ﬁrst derivative token is shown in Eq. 1.

c(x, 1) =

∂u
∂x

(1)

As seen token encodes the atomic expression. The form of the expression, as

we said above, could be chosen arbitrarily.

From the set of tokens T , we compose the words of the length k, which is the
ﬁrst hyperparameter of the algorithm. We assume that every token in the word
has the weighting coeﬃcient and could be replaced with another one without
model corruption.

2.2 The evolutionary part

The evolutionary optimization in the algorithm is aimed at the discovery of token
combinations set that is able to create the ”best” equation. In terms of previ-
ously introduced denotation, with this mechanism, we select the set C, a linear

4

A. Hvatov, M. Maslyaev

combination of elements from that can take the least value among its counter-
parts from the class of sets C. The possibility of extremely high dimensionality
of the search space (in usual cases ndim = C k
n tokens+k−1; coordinate in each
dimension is deﬁned by the weight of terms, corresponding to the dimension, in
the ﬁnal equation) limits the application of other optimization techniques, while
the evolutionary methods provide suﬃcient toolkit for the search.

The initialization of the evolutionary algorithm is done with the creation of
the population P (Eq. 2), in that each of the individual solutions will represent a
single equation/model. In each of these individuals, M - random token combina-
tions (in a typical case, unordered and with repetitions) are taken as the genes.
From each set of combinations, one element is selected as the right part of the
equation, while others are assumed to form its left part. Such division excludes
the possibility of trivial equation cases, where all of the term weights are equal
to 0.

P = {C 1, C 2, ... , C n pop | C i = {ci

1, ci

2, ci

3, ... , ci

n}}

(2)

For the quality of individual solution evaluation, we shall deﬁne the ﬁtness
function. The calculation of the ﬁtness function requires the equation’s weights:
we calculate it as the inverse norm of the diﬀerence between the sum of esti-
mated values of token combinations in the left part, and the evaluation of the
right part, as shown in Eq. 3, where α stands for the sparse vector of equation
weights, Ftarget is the estimation of the designated as the right part token com-
bination, and F is comprised of left part token combination. The norm, used in
this calculation, is selected according to the speciﬁcs of the task. Therefore, the
main objective of the algorithm is the detection of such set C (cid:48), which has the
highest possible ﬁtness function value.

ff itness =

1
(cid:107)F · α − Ftarget(cid:107)

(3)

The evolutionary search, performed during the algorithm operation, utilizes
both mutation and crossover, which are introduced for the alteration of the set
of token combinations to create the best one.

The crossover operation is deﬁned as the gene exchange between two indi-
viduals. In the algorithm, it is represented as the swap of token combination
between the models. The scheme of the crossover between two individuals C 1
and C 2, resulting in oﬀsprings C (cid:48)1 and C (cid:48)2, is depicted on Fig 2. The selec-
tion of parents for the procreation is performed via tournament selection, where
the appropriate number of tournaments is held to select aproc × 100 % of the
population. Such an approach creates the possibility for the drift of genes from
candidates with mediocre ﬁtness values to the next generations. After the oﬀ-
spring creation, the target and the features are also selected in its token sets.
The crossover parameter rcrossover determines the probability of a single swap
during the gene exchange between selected individuals.

The mutation operator can be deﬁned in two ways: as the possible change of
one token in the gene of the existing individual, or as a random swap of the entire

Physical-based equations discovery using evolutionary approach

5

Fig. 2. Scheme of the crossover

gene to the randomly created one. The examples of the implemented mutation
operator operations are shown in Fig. 3 for the gene swap and Fig. 4 for the
alteration of a token in the token combination. The type of mutation, applied
to the individual is selected randomly in each of the operator application. In
order to preserve the currently best individuals, the mutation is forbidden for
the speciﬁed top percentage of the population aelite, according to their ﬁtness
value. The mutation rate rmutation deﬁnes the probability of each gene in the
individual to mutate.

Fig. 3. Scheme of the mutation, which involves change of gene to the randomly created
new one

2.3 The regression part

While the previously discussed evolutionary part of the algorithm was devel-
oped to discover the best set of token combinations, which will represent the
desired structure of the model, the regression methods are utilized to calculate

6

A. Hvatov, M. Maslyaev

Fig. 4. Scheme of the mutation, that operated by random change of selected token
inside genes

the weights for these terms. Not only the best but also some redundant token
combinations may be present in the best discovered set C (cid:48). Therefore, the task of
set ﬁltering is also bestowed to the regression element of the algorithm. The pri-
mary method that can perform these jobs is the sparse (regularized) regression,
performed with LASSO operator, which is presented in the Eq. 4.

(cid:107)F α − Ftarget(cid:107)2 + λ(cid:107)α(cid:107)1 → min
α

(4)

In a typical application, sparse regression involves minimization of the func-
tional, comprised of the sum of the squared L2 norm of the diﬀerence between
the vector of the target variable and the vector, which is the result of the dot
product of the features matrix and the weights vector. While in the majority
of cases, the problem can be interpreted in terms of vector operations, sparse
regression operator can be extended to the broader class of tasks: for the target,
we can use the estimation of the corresponding combination of tokens, and for
the features the vector of estimations for other elements in token combinations
set. The norm of the diﬀerence is also selected according to the type of token
representation.

While multiple experiments have proved, that the values of parameters, deﬁn-
ing the evolutionary element of the algorithm, have less impact on the resulting
equations, alternating mainly the time to achieve the desired solution, the spar-
sity constant can determine the structure of the ﬁnal result. Therefore, the task
of selecting the optimal value of sparsity constant can be vital for the success-
ful operation of the algorithm. One of the possible solutions to this problem is
to initialize the algorithm on the grid of λ values and select the best-obtained
solution.

We put the material of the section in a short form of the pseudo-code in

Alg. 1.

Physical-based equations discovery using evolutionary approach

7

Input: set of elementary tokens T
Parameters : M - number of token combinations in a single individual; k -

number of elementary tokens in a combination; n pop - number
of candidate solutions in the population; evolutionary algorithm
parameters: number of epochs nepochs, mutation rmutation &
crossover rates rcrossover, part of the population, allowed for
procreation aproc, number of individuals, refrained from
mutation (elitism) aelite; sparse regression parameter - sparsity
constant λ

Result: set of token combinations C best (if required, with accompanying
weights), representing best model/equation for the data

Generate population P of individuals of size n pop, with M - random
permutations of k tokens to form sets C j;
for epoch = 1 to nepochs do

for individual in population do

Apply sparse regression to individual to calculate weights;
Calculate ﬁtness function to individual;

end
Hold tournament selection and crossover;
for individual in population except n pop × aelite ”elite” ones do

Mutate individual;

end

end
Select the individual with highest ﬁtness function value as the ﬁnal solution to

the problem;

Algorithm 1: The pseudo-code of the algorithm operation

8

3

A. Hvatov, M. Maslyaev

Implementation examples

In this section, we provide two diﬀerent examples of algorithm implementation.
In Sec.3.1 the data-driven PDE discovery is shown in application to the metocean
data. In particular, we use sea surface height data obtained from the NEMO
ocean model [14]. In Sec. 3.2 the data-driven polynomial Floquet polynomial
discovery is considered.

3.1 Diﬀerential equation discovery for the metocean process

The data-driven derivation of equations, which describe metocean processes,
is one of the suggested applications of the proposed algorithm. The governing
equations for the diﬀerent metocean processes often do not have a closed-form
equation. Various parameterizations are used to compensate, for example, the
inﬂuence of vertical mixing [14]. Thus, for the applications, it may be useful to
step forward and obtain the data-driven PDE to approximate the process. The
approximation could be used either as an advanced parameterization or as a clue
to deduce an additional term for the existing equations.

Problem statement The proposed algorithm is suggested to the class of prob-
lems, that involve derivation of the equation for process, that involves variable
f and takes place is the speciﬁed area Ω for a period T . According to our
hypothesis, it can be described with unknown partial diﬀerential equation 5.
The input data for the equation discovery algorithm is presented by sets of
... , fn}. In the most appropriate and the most
measurements S = {f1, f2,
common approach, samples are taken on the grid, which can be introduced as
γ = {(x1, x2, ... xk, t)|(x1, x2, ... , xk) ∈ Ω; t ∈ [0, T ]}, making sample take form
of fj = f ((xj

2, ... xj

1, xj

k, tj)).

(cid:40)

, ∂2f
F (f, ∂f
∂x2
∂x1
2
G(f ) = 0, f ∈ Γ (Ω) × [0, T ];

∂t , ∂2f

, ..., ∂f

, ∂f
∂x2

∂x2
1

, ... , ∂2f

∂t2 , ... ) = 0;

(5)

The main reason for the introduction of the grid is the simplicity of the
derivative calculations. In this case, various robust to the noise in input data
methods can be used. The best trade-oﬀ between the computational simplicity
and resistance to the noise can be achieved with the analytical diﬀerentiation of
polynomials that are ﬁt over the values in sets of points on the grid. These poly-
nomials are constructed with the least-squares method, ﬁnding the coeﬃcients
by minimizing the error between the weighted sum of terms and the values in
points. Otherwise, in case of non-regular measurements, less conventional meth-
ods shall be utilized, such as in situ estimations of the derivatives.

The tokens for the evolutionary algorithm that will comprise the terms of
the resulting equations are composed of various derivatives, taken up to selected
order (usually second or third) and along all axis.

Physical-based equations discovery using evolutionary approach

9

Experiments The conducted experiments were based on the discovery of the
governing equation for the dynamics of sea surface height (SSH), obtained from
the NEMO Arctic seas model conﬁguration. The datasets included hourly sam-
ples on the regular spatial grid on 50 × 50 nodes with 5 km steps for 24 hours
intervals. The main dynamics that could be derived with data of this time resolu-
tion is connected to the tides, which tend to be oscillations with ﬁxed amplitudes
and main periods of roughly 12 hours.

Preliminary SSH ﬁeld smoothing is required in the ocean (and, possibly,
in the other physical measurement ﬁelds) data cases. It is done to reduce the
inﬂuence of high-frequency noise on derivatives ﬁelds. The initial data ﬁltering
is performed with a Gaussian smoothing kernel. This results in the improvement
of the quality of the derivative ﬁelds, that are susceptible to the statistical errors
in the initial function ﬁeld.

The parameters of the evolutionary algorithm during the experiments were
set as follows: the crossover rcrossover and mutation rmutation rates had values of
0.4; for procreation, 20% of the population were selected, and 40% were excluded
from the mutation. The n pop - the size of the population was ten individual
solutions; each equation could have up to 8 terms altogether in the left and right
part, and three tokens can be present in each term.

In order to validate the performance of the algorithm, the quality of the
discovered equations shall be evaluated. We have selected one day with the gov-
erning equation in form Eq. 6. It was solved, and the results were compared with
the initial ﬁeld. In Fig. 5, examples of the sea surface height ﬁelds, acquired from
the data and equation solution, are presented: the left column represents three
consequent frames from the framework input data, while their right counterparts
are the ﬁelds, obtained from the partial diﬀerential equation, for the same time
steps.

∂f
∂x

= −0.05153

∂2f
∂t2 + 8.508

∂2f
∂x2

(6)

The example of a comparison of the initial ﬁeld and the reconstruction for a
single point is presented in Fig. 6, which represents the time-series, situated in the
center of the simulated area. In can be noticed, that the quality of the simulation
with the equations is high: the oscillations, that represent tidal dynamics are well
preserved, using only the inﬂuence of the boundary conditions. It is possible
to introduce the metrics of the error, applied to the entire studied area, to
prove the eﬀectiveness of the simulation. Root mean square error (RMSE) and
mean absolute error (MAE) have values of 0.064 and 0.048 correspondingly. In
comparison with the average value of the ﬁeld (0.625 m), the error values are
close to 10%, which can be relatively good in the tasks of ocean simulation.

To understand the spatial distribution of the errors in the ﬁeld reconstruction,
we shall examine the ﬁelds of root mean square error (RMSE), presented in Fig. 8
and mean absolute errors, which is shown in Fig. 7, calculated over the time-
series for each of the grid points. It can be noticed that the error is close to
0 both in the left and right parts of the area. It appears since the boundary
conditions for the model were set there. Additionally, the distribution of error is

10

A. Hvatov, M. Maslyaev

Fig. 5. Examples of the SSH ﬁelds for consequent time frames; initial data and matrix
obtained from the equation solution

asymmetrical in the central area. Such a diﬀerence can be a result of the eﬀect
that the amplitudes of tides are higher in the right part (around 2.3), while in
the leftmost area, the values are close to 1.0.

In order to analyze the convergence of the algorithm, ten independent runs
of the algorithm were held. Results of this experiment are presented in the box
plot in Fig. 9, where for the speciﬁed epoch, the distributions of ﬁtness values
of the best candidates are plotted. The majority of the launches have converged
to the form of Eq. 6 in approximately 100 epochs. It can be noticed that one of
the individuals had the best possible structure since the beginning.

Physical-based equations discovery using evolutionary approach

11

Fig. 6. Comparison of the SSH ﬁeld simulation results with the input ﬁeld for the area
center

Fig. 7. Heat map of mean absolute error (MAE) for time-series in each of the grid
nodes

12

A. Hvatov, M. Maslyaev

Fig. 8. Heat map of mean absolute error (MAE) for time-series in each of the grid
nodes

3.2 Polynomial discovery for a periodic structure

Floquet polynomial is an acoustical marker of pass- and stop-bands. The last are
zones in a periodic structure, where the waves are propagating free (pass-bands),
or the wave propagation is blocked (stop-bands) by the wave interference. Usu-
ally, the problem of the zones identiﬁcation is solved analytically. However, for
the complex acoustical models, the analytical solution includes the symbolic
determinant computation of order ≥ 100, which may be computationally expen-
sive.

The simple idea is to replace the determinant computation with the simple
numerical algebraic system solution to obtain the data. The obtained data is
then used for the polynomial discovery algorithm to approximate the symbolic
solution.

Mathematical problem description For this problem, we consider periodic
structure, which consists of two periodically repeating blocks of length 1 and γ
respectively. The general form of the solution of the axial rod vibration operator
(which is the simple one-dimensional wave equation) is shown in Eq. 7

ui(x) = bi,1 exp iΩx + bi,2 exp iΩx(i mod 2 = 1)
ui(x) = bi,1 exp i Ω
σ x + bi,2 exp i Ω
σ x(i mod 2 = 0)
fi(x) = d
dx ui(x)

(7)

Physical-based equations discovery using evolutionary approach

13

Fig. 9. Distributions of the best solution ﬁtness values for 10 independent launches of
the algorithm

Variable Ω is the dimensionless frequency and considered as the problem
parameter, and σ is the material diﬀerence of two blocks, also considered as
the problem parameter. The data for the algorithm is taken from the forcing
problem (Eq. 8).

u1(1) = u2(1)
f1(1) = f2(1)
...
un−1(ln−1) = un(ln−1)
fn−1(ln−1) = fn(ln−1)
f1(0) = 1
bn,2 = 0

(8)

System Eq. 8 has a unique solution. After it is found, the solution is used to

obtain the Floquet periodicity coeﬃcient approximation in form Eq. 9.

Fn(x, Ω) =

Dn(x, Ω)
Dn(x + (1 + γ), Ω)

(9)

In Eq. 9 with Dn(x, Ω) displacement of the structure with the unknown

constants found from forcing problem Eq. 8 is designated.

14

A. Hvatov, M. Maslyaev

The solution obtained with the algorithm is compared with the analytical

solution, that may be obtained as the determinant of the system Eq. 10

u1(1) = u2(1)
f1(1) = f2(1)
u1(0) = Λu2(1 + γ)
f1(0) = Λf2(1 + γ)

(10)

Thus, we try to discover Floquet polynomial in form Eq. 11 with algorithm
described in Sec. 2. We consider it as the polynomial of degree 2 in variable Λ
it could be written as

D(Ω) = a2(Ω)Λ2 + a1(Ω)Λ + a0(Ω) = 0

(11)

To be brief, main properties of the roots of the Floquet polynomial are stated
without any proofs. They could be either complex with property abs(Λi) =
1 (that corresponds to a pass-band) or pure real with property abs(Λj) >
1 , abs(Λk) < 1 , Λj ∗ Λk = 1 (stop-band).
For the parameter set γ = 1 , σ = 1

5 the analytical solution has the form

Eq. 12

Λ2 + (

169
60

cos (6Ω) −

49
60

cos (4Ω))Λ + 1

(12)

Algorithm quality assessment After analytical solution is found, the next
step is to compare it with the one, discovered by the algorithm. Following Sec. 2,
the set of the tokens is deﬁned ﬁrst. From form of the analytical solution Eq. 12,
we deduce that tokens for this case have the form Eq. 13.

Tj(A, B) = (A cos(BΩ))Λj

(13)

Token in the equation has three parameters A, B, j, we evolve parameter B
and allow to appear new tokens in the polynomial during the evolution. Since
we want only to illustrate the approach, we allow only the degrees j = 0, 1, 2 to
appear. The sparse regression is done with respect to the parameter A.

Second step is to deﬁne evolutionary operators. The evolution is done in the
same way as in the Sec. 3.1. The mutation allows a new term to appear. However,
the maximal number of terms in the sum is restricted. The multiplication of the
terms is forbidden sine we know the resulting form of the analytical solution.
The algorithm’s convergence rate diﬀers insigniﬁcantly from the Sec. 3.1. Thus,
we do not stop on the evolutionary part and show only the quality of the result
compared to the analytical solution.

An example of data in Fig. 10 shown n = 35 uniformly taken points, found

from Eq. 9 in the range Ω = [0, 2].

Straight lines in analythical solution in Fig. 10 corresponds to a pass-bands
and vice versa eliptical curves are stop-bands. The discovered polynomial for the
data, shown in Fig. 10 is shown in Fig. 11.

Physical-based equations discovery using evolutionary approach

15

Fig. 10. The data (dots) and the analythical solution for n = 35 data points

Fig. 11. The discovered polynomial (dashed) and the analythical solution for n = 35
data points

It is seen, that discovered polynomial can ﬁlter out the data and show ap-
proximately the picture of the stop- and pass-bands. It means that the algorithm
is able to reproduce this physical process correctly.

The quality of the algorithm is measured as the RMSE between roots of the
polynomial Eq. 12 and the resulting one at the points in the range Ω = [0, 2]
with discrete steps taken with ∆ = 0.001. Distribution of the log(RMSE) for the

16

A. Hvatov, M. Maslyaev

one hundred consecutive runs with a diﬀerent number npts of data points are
shown in Fig. 12.

Fig. 12. Distribution of the log(RMSE) for the one hundred consecutive runs with a
diﬀerent number npts of data points

It is seen that the algorithm also converges to an analytical solution with an
increase in the data points amount. This result gives the reason to believe that
in more complex cases, i.e., when the operator is more complex, the algorithm
may also give an approximation to the stop- and pass-bands picture.

4 Conclusion

In the paper, we describe the algorithm for the physical-based equations discov-
ery. We want to outline the following properties of it:

* It does not depend on the form of the equation: it could be a polynomial,
diﬀerential equation, and potentially the other models. However, additional
work for the adaptation for each type of the equation is required;

* The genetic programming can be used to obtain an optimal bag of the terms
from the small set of the building blocks and preliminary deﬁned mutation
and crossover rules;

Physical-based equations discovery using evolutionary approach

17

* The sparse regression step allows one to ﬁlter out the non-descriptive terms
that lead to a robust model. As an additional advantage the resulting model
has the short form of the expression, which makes the interpretation process
easier;

* PDE discovery implementation is noise stable even for multi-dimensional
data cases. The overall performance of the algorithm implementation allows
reproducing tempo-spatial physic ﬁelds correctly.

In the future, we plan to combine diﬀerent types of terms in the co-evolution
step that will make it possible to discover models like non-homogeneous PDE.
The second development direction is the systems of the generation of the expres-
sion.

Acknowledgments

This research is ﬁnancially supported by The Russian Scientiﬁc Foundation,
Agreement #19-11-00326.

References

1. Berg, J., Nystr¨om, K.: Data-driven discovery of pdes in complex datasets. Journal

of Computational Physics 384, 239–252 (2019)

2. Brunton, S.L., Proctor, J.L., Kutz, J.N.: Discovering governing equations from
data by sparse identiﬁcation of nonlinear dynamical systems. Proceedings of the
National Academy of Sciences p. 201517384 (2016)

3. Guyon, I., Sun-Hosoya, L., Boull´e, M., Escalante, H.J., Escalera, S., Liu, Z., Jajetic,
D., Ray, B., Saeed, M., Sebag, M., et al.: Analysis of the automl challenge series
2015–2018. In: Automated Machine Learning, pp. 177–219. Springer (2019)

4. Kondrashov, D., Chekroun, M.D., Ghil, M.: Data-driven non-markovian closure

models. Physica D: Nonlinear Phenomena 297, 33–55 (2015)

5. Kovalchuk, S.V., Metsker, O.G., Funkner, A.A., Kisliakovskii, I.O., Nikitin, N.O.,
Kalyuzhnaya, A.V., Vaganov, D.A., Bochenina, K.O.: A conceptual approach to
complex model management with generalized modelling patterns and evolutionary
identiﬁcation. Complexity 2018 (2018)

6. Lipton, Z.C.: The mythos

of model

interpretability.

arXiv

preprint

arXiv:1606.03490 (2016)

7. Molnar, C.: Interpretable machine learning. Lulu. com (2019)
8. Nikitin, N.O., Vychuzhanin, P., Hvatov, A., Deeva, I., Kalyuzhnaya, A.V., Ko-
valchuk, S.V.: Deadline-driven approach for multi-ﬁdelity surrogate-assisted envi-
ronmental model calibration: Swan wind wave model case study. In: Proceedings of
the Genetic and Evolutionary Computation Conference Companion. pp. 1583–1591
(2019)

9. Olah, C., Satyanarayan, A., Johnson,

K., Mordvintsev, A.: The building blocks of
https://doi.org/10.23915/distill.00010, https://distill.pub/2018/building-blocks
10. Raissim, M.: Deep hidden physics models: Deep learning of nonlinear partial dif-

I., Carter, S., Schubert, L., Ye,
interpretability. Distill (2018).

ferential equations (2018), https://arxiv.org/abs/1801.06637

18

A. Hvatov, M. Maslyaev

11. Rudy, S.H., Brunton, S.L., Proctor, J.L., Kutz, J.N.: Data-driven discovery of

partial diﬀerential equations. Science Advances 3(4), e1602614 (2017)

12. Schaeﬀer, H., Caﬂisch, R., Hauck, C.D., Osher, S.: Learning partial diﬀerential
equations via data discovery and sparse optimization. Proceedings of the Royal
Society A: Mathematical, Physical and Engineering Science 473(2197), 20160446
(2017). https://doi.org/473(2197):20160446

13. Schmidt, M., Lipson, H.: Distilling free-form natural laws from experimental data.

science 324(5923), 81–85 (2009)

14. Team, N.S.: NEMO ocean engine. https://doi.org/10.5281/zenodo.1464816
15. Tibshirani, R.: Regression shrinkage and selection via the lasso. Journal of the

Royal Statistical Society: Series B (Methodological) 58(1), 267–288 (1996)

