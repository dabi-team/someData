2
2
0
2

t
c
O
2
1

]
T
I
.
s
c
[

2
v
9
7
6
6
0
.
6
0
2
2
:
v
i
X
r
a

Matching Pursuit Based Scheduling for

Over-the-Air Federated Learning

1

Ali Bereyhi, Member IEEE, Adela Vagollari, Student Member IEEE, Saba Asaad,

Member IEEE, Ralf R. Müller, Senior Member IEEE, Wolfgang Gerstacker,

Senior Member IEEE, and H. Vincent Poor, Life Fellow IEEE

Abstract

This paper develops a class of low-complexity device scheduling algorithms for over-the-air fed-

erated learning via the method of matching pursuit. The proposed scheme tracks closely the close-to-

optimal performance achieved by difference-of-convex programming, and outperforms signiﬁcantly the

well-known benchmark algorithms based on convex relaxation. Compared to the state-of-the-art, the

proposed scheme poses a drastically lower computational load on the system: For K devices and N
+ N 6 while the

antennas at the parameter server, the benchmark complexity scales with

N 2 + K

3

complexity of the proposed scheme scales with K pN q for some 0 < p, q
(cid:0)

2. The efﬁciency of the

(cid:1)

≤

proposed scheme is conﬁrmed via numerical experiments on the CIFAR-10 dataset.

I. INTRODUCTION

In the light of dramatically increasing numbers of mobile devices and data trafﬁc in the

Internet-of-Things era, the need for a paradigm-shift in wireless networks from traditional

centralized cloud computing architectures to distributed ones is growing [1]–[5]. By performing

data processing at the edge of networks, several shortcomings of cloud computing, such as long

latency and network congestion, can be effectively addressed [6]–[8]. Notably, edge computing

is an appealing technology to perform real-time tasks and make real-time decisions by exploiting

the abundant computational resources of the edge servers [9]–[11]. Nevertheless, the bandwidth

Ali Bereyhi, Adela Vagollari, Saba Asaad, Ralf R. Müller and Wolfgang Gerstacker are with the Institute for Digital Communi-

cations (IDC) at Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU); email: {ali.bereyhi, adela.vagollari,

saba.asaad, ralf.r.mueller, wolfgang.gerstacker}@fau.de. H. Vincent Poor is with the Department of

Electrical and Computer Engineering at the Princeton University; email: poor@princeton.edu.

 
 
 
 
 
 
2

limitations and resource constraints of the wireless channels can pose signiﬁcant challenges to

realizing fast learning [12]–[14]. One way of overcoming these challenges is to integrate the

edge-intelligent network within wireless networks and leverage the superposition property of

wireless multiple-access channels [15].

Recently, a new paradigm of distributed machine learning, referred to as federated learning

(FL) has been introduced, in which distributed devices jointly train a shared global machine

learning model without sharing their raw data explicitly [16]–[18]. In essence, FL is a collab-

orative machine learning framework that enables distributed model training from decentralized

data under coordination of a parameter server (PS) [17]. In principle FL is performed over a

decentralized network as follows:

1) A PS ﬁrst shares a global model with participating devices in the network.

2) Each device performs local model training using its own local dataset to determine the

model parameters. It then transmits its trained model parameters to the PS while keeping

its private data locally within its own device.

3) Once the PS aggregates the locally trained models, it updates the global model parameters

using the aggregated models and broadcasts updated parameters to all edge devices.

These steps are alternated until the global model parameters converge [16], [18], [19]. Further

illustrations can be found through the comprehensive example of FL given in Appendix A.

Compared to the extreme cases of centralized and individual learning, FL provides a tractable

approach to handle a joint learning task over a distributed network. Nevertheless, this tractability

comes with some costs which can be roughly categorized into three major forms:

1) The statistical inference problem in FL is more challenging. This follows from the fact that

the local datasets in the decentralized setting are not independent and identically distributed

(i.i.d.). Some related discussions in this respect can be found in [20]–[24] and the references

therein.

2) Although local datasets are not shared in FL, this approach is still vulnerable against

adversarial attacks in the network. In fact, due to the multiple rounds of model updates

over the network, malicious terminals have access to a large list of local models from which

they can learn the local datasets via model inversion attacks; see [25] for an instance of

such attacks, and also discussions in [26], [27] and references therein regarding the privacy

challenges in FL.

3

3) To achieve convergence of the global model, an FL algorithm needs to iterate for a rather

large number of rounds. This leads to a high communication cost in the network which can

result in excessive overhead to the system or even congest it; see for instance [28] and the

references therein.

These challenges are often addressed separately in the literature. This follows from the fact

that they result from different sources of imperfection. In this work, we mainly focus on the third

class of challenges, i.e., communication-related challenges, as this class is the key hindrance for

FL in wireless networks.

A. Over-the-Air Federated Learning

As mentioned, the key practical challenges in FL over wireless networks, often called over-

the-air federated learning (OTA-FL), are the communication-related ones. This comes from the

facts that wireless networks are signiﬁcantly restricted in resources and the communication links

are severely impacted by fading. As a result, direct implementation of FL in these networks can

lead to large communication overhead in the system and high latency; see [29] and the references

therein for further discussion of these issues. Consequently, developing communication-efﬁcient

strategies to mitigate communication cost and guarantee satisfactory learning performance is

of paramount importance [30]. The proposed solutions in the literature often lie in one of the

following three approaches:

1) One approach is to minimize the total number of communication rounds between the edge

devices and PS. With this approach, the main design task is to achieve satisfactory learning

accuracy with a minimum number of communication rounds [31]–[33].

2) Another approach is to reduce the communication overhead per round by exploiting lossy

compression techniques such as quantization and pruning [34]–[36].

3) The third approach suggests to accelerate the model aggregation process by leveraging the

principles of over-the-air computation [37]–[40].

The ﬁrst two approaches treat communication and computation separately via the transmission-

then-aggregation policy. The latter approach however invokes the idea of analog function com-

putation in sensor networks [41] to address both tasks simultaneously; see Appendix A for an

illustrative example.

4

B. Device Scheduling for Over-the-Air Federated Learning

From the inference point of view, we are interested in increasing the number of devices that

share their model parameters. This is in particular of a great interest, as the accuracy of the

learned model strongly depends on the size of the aggregated dataset on which the FL algorithm

is running. The more devices that share their local model parameters, the more reliable the learned

model becomes. Although this statement is in general valid for any network, it is not always

straightforward in OTA-FL to improve the reliability of the learned model by increasing the

number of participating devices. This comes from the wireless channel effects, i.e., fading. The

optimal solution to this issue is to design the model transmission and the FL algorithm jointly.

By this approach, the share of each local model can be designed such that it contributes in the

global model learning constructively. This joint approach is however not in general tractable, as

the statistical model of the local model parameters in FL is not trivial. An alternative sub-optimal

solution to this issue is given by device scheduling in which some of the devices with potentially

less contribution in the global model learning are set off. In this case, performing FL and model

transmission separately leads to minimal performance degradation compared to the case with all

devices being active1.

Device scheduling has been widely accepted as an efﬁcient sub-optimal solution in OTA-FL

which avoids performance degradation due to imperfect model aggregation2. The efﬁciency of

this approach has been shown analytically and experimentally through a large set of studies in

the literature; see for instance the studies in [29], [42]–[44]. In general, a scheduling policy tries

to ﬁnd the largest collection of local datasets in each communication round while keeping the

overall aggregation cost, for a predeﬁned aggregation strategy3, below a tolerable threshold. In its

generic form, device scheduling reduces to an integer programming problem and hence is a non-

deterministic polynomial-time (NP)-hard problem. Consequently, various sub-optimal algorithms

for scheduling are proposed in the literature [38] and [45]–[47]. These algorithms often either

offer good performance at the expense of high computational complexity, e.g., [38], or perform

1It is worth mentioning that scheduling is in general sub-optimal. To illustrate this point, one can think of a real-valued weight

for each device representing its share in the global model learning. The joint design of the FL algorithm and transmission scheme

determines the optimal choice of these real-valued coefﬁcients while device scheduling restricts them to be either zero or one.

2Another root of interest on device scheduling in OTA-FL comes from network limitations, such as the total communication

overhead, latency and the required bandwidth. We however do not discuss this aspect of device scheduling in this paper.

3This strategy is designed independent of the channel information. This separation is in fact the root of sub-optimality.

5

poorly while gaining in terms of complexity, e.g., random scheduling [29]. This work ﬁlls the gap

between these two types of scheduling policies by introducing a class of scheduling algorithms

with a fair complexity-performance trade-off based on the method of matching pursuit.

C. Contributions

The device scheduling task is mathematically formulated in the form of a constrained opti-

mization problem: In this problem, the number of active devices is maximized, subject to an

inequality constraint on the aggregation cost; see for instance the formulations in [38] and [47].

The explicit form of the problem is given by deﬁning a metric for the aggregation cost in the

network which depends on the chosen approach for OTA-FL. The key feature of the aggregation

cost metric is that it grows with the number of devices and describes the dominant source of

error arising in the model aggregation step.

A device scheduling mechanism proposed for a particular aggregation cost metric often extends

straightforwardly to other metrics. This follows from the fact that the target optimization problem

is of the same NP-hard form with only the cost metric being different. We hence focus in this

work on a recent OTA-FL approach; namely, the approach based on over-the-air computation4

initially proposed in [38]. As the main contribution, we develop a class of low-complexity

scheduling algorithms based on the method of matching pursuit [48] which incurs a signiﬁcantly

lower computational complexity compared to a benchmark algorithm based on the difference of

convex (DC) programming [38], while degrading the scheduling performance only slightly. In

particular, the contributions of this paper can be brieﬂy described as follows:

• We formulate the device scheduling task as a sparse support selection problem whose

constraint is given by a weighted combination of individual cost constraints. For this

problem, we develop a class of greedy algorithms based on the method of matching pursuit.

We show that with K devices in the network and an array antenna of size N at the PS, the

computational complexity of the proposed scheme scales with K pN q for some p, q

2.

≤

This is a signiﬁcant complexity reduction compared to the benchmark scheme in [38] which
scales with K (N 2 + K)3 + KN 6.

• The proposed scheduling scheme is parametrized by a set of device weights which need to

be tuned. To this end, we invoke the intuitive connection between the original scheduling

4Nevertheless, as mentioned through the introductory part, the proposed scheduling scheme is generic and can be extended

straightforwardly to other approaches for OTA-FL.

6

task and the weighted sparse support selection problem and propose a subset-cutting strategy

for weighting. Our investigations show that the proposed strategy is robust against variation

of design parameters and performs very closely to optimized approaches for weighting.

• We numerically investigate the proposed scheme through a comprehensive set of simulations

over the CIFAR-10 dataset and compare the performance with the benchmark. Our inves-

tigations demonstrate that the learning performance in this case closely track the close-to-

optimal performance achieved by DC programming. This ﬁnding along with the signiﬁcantly

lower computational complexity implies the efﬁciency of our proposed scheme for OTA-FL.

D. Related Work

The efﬁciency of device scheduling for OTA-FL is discussed in [29]. In this study, a standard

setting for OTA-FL, i.e., without invoking analog function computation, is considered and the

learning performance of three basic schemes for device scheduling are discussed; namely, the

random scheduling, the round robin scheme and the so-called proportional fair strategy. The

investigations in this work reveal a key ﬁnding: with links that require high signal-to-interference-

and-noise ratio (SINR) thresholds to correctly decode received packets, an optimized scheduling

algorithm, e.g., the proportional fair strategy, outperforms other schemes while at low SINR

thresholds, random selection of active devices performs efﬁciently. There exists further a very low

required SINR threshold under which device scheduling does not enhance the FL convergence

rate. This observation agrees with intuition: At very low SINR thresholds, virtually all packets

are received correctly at the model aggregator, and thus scheduling mechanism is not important.

This further agrees with our earlier discussions on the sub-optimality of device scheduling:

In the most extreme case of noise-less transmission, the model aggregation strategy and the

transmission scheme are designed separately without any performance degradation. As a result,

ignoring some local models can only degrade the FL performance.

Following the discussions in [29], several studies have developed scheduling schemes consid-

ering various approaches for OTA-FL; see for instance [38]–[40], [44], [46], [47], [49] and [50]

. The most relevant line of work to our study in this paper is the one given in [38]. In this work,

a novel aggregation approach for OTA-FL based on the idea of analog function computation,

often called over-the-air computation (AirComp), is proposed; see [41] and [51]–[55]. Unlike the

earlier approaches, in this approach the PS utilizes the linear superposition in the uplink multiple

7

access channel5 and determines the updated global model in each communication round directly

from its received signal via a linear receiver.

Since its proposal, OTA-FL via AirComp has been investigated in various network settings. The

studies in [47] and [49] extend the idea to intelligent reﬂecting surface (IRS)-aided multiple-input

multiple-output (MIMO) networks concluding that by leveraging large IRSs, data aggregation in

AirComp-based OTA-FL can be signiﬁcantly fastened. The study in [56] further considers this

approach and develops a novel power-control policy to enhance the learning performance. In [57],

the authors propose an algorithm for OTA-FL via AirComp, considering a risk-minimization task

as the target learning problem. The developed algorithm is shown to approach the convergence

rate of the centralized gradient-descent, when the network dimensions grow large.

Similar to other approaches for OTA-FL, OTA-FL via AirComp requires a joint design of

aggregation strategy and the transmission scheme, in order to perform efﬁciently. As a result,

device scheduling6 is often used to achieve a satisfactory learning performance. For device

scheduling in OTA-FL via AirComp, the aggregation cost can be determined via the mean

squared error (MSE) between the model aggregated by the linear receiver at the PS and the

target aggregation speciﬁed by the predeﬁned aggregation strategy. Considering this cost metric,

the authors in [38] develop a mechanism for joint scheduling and receiver design based on DC

programming. The proposed mechanism in [38] has been further extended to other network

settings; see for instance [47] and [49] for device scheduling in IRS-aided MIMO networks.

E. Notation and Organization

Scalars, vectors and matrices are represented with non-bold, bold lower-case, and bold upper-
case letters, respectively. The transposed and the transposed conjugate of H are denoted by HT
and HH, respectively, and IN is an N

N identity matrix. Trace and rank of the matrix H

×

are shown by tr

H

and rank (H), respectively. The ℓp-norm of x is denoted by

{

}

particular case of the ℓ2-norm, the subscript is dropped, i.e.,

refer to the real axis and the complex plane, respectively. The notation

complex Gaussian distribution with mean η and variance σ2. For the sake of brevity,

x
p. For the
k
k
x
k2. The sets R and C
(η, σ2) represents the

x
k

k

=

k

CN

1, . . . , N
{

}

is shortened to [N].

5It is worth mentioning that AirComp is only used to implement the model aggregation over the air. The aggregation strategy,

i.e., the weights for local models, is still designed individually.

6As an analytically-tractable, but generally sub-optimal, solution.

8

The rest of this manuscript is organized as follows: The problem under study is formulated

in Section II. Section III presents the proposed scheduling scheme along with discussions of its

performance and complexity. The detailed derivation of the scheme is then given in Section IV.

Section V provides several numerical experiments. Finally, the manuscript is concluded in

Section VI.

II. PROBLEM FORMULATION

Consider a decentralized setting with K single-antenna edge devices and a single PS. The

PS is equipped with an antenna array of size N. The dataset D is distributed among the edge

devices. This means that device k for k

[K] has access to a local dataset Dk from which

it determines its local vector of model parameters θk

D. The model parameters are shared

∈

∈ R

with the PS over the uplink multiple access channel. The PS aims to determine an update for

the global model based on the shared local models.

We assume that the network operates in the time division duplexing (TDD) mode. As a

result, the uplink and downlink channels are assumed to be reciprocal. Prior to sharing the local

datasets, the devices send pilot sequences over the uplink channels. The PS utilizes its received

signal to acquire the channel state information (CSI) of the devices. As a result, the CSI of all

devices is available at the PS, and each edge device has access to its own CSI. For the sake of

compactness, we assume that the CSI acquisition is carried out perfectly, i.e., we assume that

the pilot sequences are mutually orthogonal and that the channel estimation error is negligible.

The coherence time interval, in which the CSI remains unchanged, is further assumed to include

multiple symbol time intervals. Using the acquired CSI, the PS schedules a subset of devices to

be active in model sharing. Our main goal in this work is to design the scheduling protocol.

A. System Model

We now focus on a particular communication round and assume that the PS performs device

scheduling. Let S ⊆
the current communication round. Considering the federated averaging algorithm for FL7 [58],

[K] denote the subset of devices that are scheduled to share their model in

the ultimate goal of the PS is to determine an updated global model θ as

θ (S) =

φkθk,

k∈S
X

(1)

7This is the most classical approach for FL; see also Appendix A.

9

for some predeﬁned positive weights φk which are proportional to the size of the local datasets.

The selected device k uploads its local model parameters in D symbol intervals after applying

a linear operation on them. More precisely, it transmits in the d-th symbol interval

where θk,d denotes the d-th entry of θk, and ψk is a scalar that satisﬁes the per-device transmit

xk (d) = ψkθk,d,

(2)

power constraint

ψk

|

2

|

≤

P .

In the sequel, we drop the time interval index, and focus on a single transmission time interval.

In this case, the signal received by the PS is given by

where ξ is a complex zero-mean additive white Gaussian noise (AWGN) process with variance

k∈S
X

y =

xkhk + ξ

(3)

σ2, i.e., ξ

∼ CN

(0, σ2IN ), and hk

∈ C

N denotes the channel coefﬁcient vector between device

k and the PS.

The PS ultimately intends to compute the global model parameter according to the aggregation

strategy in (1). This means that in a particular symbol time interval, its target function is

Due to noise and fading processes in uplink channels, the aggregation of the selected local model

k∈S
X

θ (S) =

φkθk.

(4)

parameters is noisy, and hence the PS can only determine an estimate of θ (S). To this end, the

PS invokes the idea of analog function computation and utilizes the linear superposition of the

multiple access channel by determining the target function directly from the received signal via

a linear receiver. This means that it calculates the estimate

ˆθ (c, S, η, ψ) =

cHy
√η

=

ψkθk
√η

cHhk +

cHξ
√η

k∈S
X

for some linear receiver c

∈ C

N and the power factor η. In (5), we deﬁne the vector ψ as

T
ψ = [ψ1, . . . , ψK]

.

(5)

(6)

The estimate in (5) incurs some error compared to the target function. This error describes the

distortion imposed through model aggregation in this OTA-FL approach.

10

B. Uplink Coordination via Zero-Forcing

As mentioned, each edge device only knows its own CSI. The PS hence coordinates the

devices with respect to their weights in the aggregation strategy, i.e., the φk’s, using the zero-

forcing strategy: Let the receiver and the subset of active devices be set to c and S, respectively.

The PS, at the beginning of the communication round, sets the power factor to η = ηZF, where

ηZF = P min
k∈S

2

hH
k c
φ2
k

|

|

,

(7)

and broadcasts it, along with c in the network over a rate-limited noiseless feedback channel.

Upon the reception of ηZF and c, each selected device sets its transmit weight as

ψZF,k = √ηZFφk

2 .

(8)

hH
k c
hH
k c

|

|

It is straightforward to show that the above choices of η and ψk satisfy the power constraints at

the devices and also construct the desired superposition over the air in the absence of noise in

the uplink transmission. This coordination approach can be observed as zero-forcing, since the

PS determines the transmit weights of the devices and the receiver power factor, such that the

uplink channel is inverted.

From the signal processing point of view, it is well-known that with respect to the MSE

between the target function and its estimate, zero-forcing coordination is sub-optimal. The opti-

mal approach is to derive the minimum mean squared error (MMSE) coordination strategy that
minimizes the MSE between θ (S) and ˆθ (c, S, η, ψ). Analytical derivation of the MMSE strategy

is however intractable, due to the nontrivial statistical model of the local model parameters. This

point is discussed in greater detail in Appendix B.

Remark 1: In [38], the zero-forcing approach for coordination is considered as the optimal

strategy, while the MSE between the target function and its estimate is considered as the design

metric. Although this consideration does not impact the correctness of the main results, we

believe it is due to a misconception. We address this point in Appendix B.

C. Aggregation Cost Metric

As mentioned in the introduction, the design of a device scheduling scheme requires deﬁning a

metric for the aggregation cost in the network. To this end, we follow the proposed strategy in the

literature, e.g., [38], [47], and model the aggregation cost via the computation error. Considering

zero-forcing coordination at the PS, we deﬁne the computation error to be the MSE between

the estimated computation and the target function, i.e.,

11

(c, S) = E

E

ˆθ (c, S, ηZF, ψZF)

θ (S)

2

|

−

.

(9)

|
n

o

By replacing ηZF from (7) into the deﬁnition of the computation error, it is straightforwardly

shown that

(c, S) =

E

σ2
P

max
k∈S

φ2

2

c
k k
k
hH
k c
|

|

2 .

(10)

This error serves as the metric for the aggregation cost in the network in the sequel.

Proposition 1 shows that the computation error has the generic property exhibited by a metric

of aggregation cost. This means that it either increases or remains unchanged, as the number of

active devices increases. Consequently, we design the scheduling protocol and the linear receiver,

such that the above design metric does not exceed a maximum tolerable value.

Proposition 1: Consider subsets Si

[K] for i

⊆

minimized with respect to the linear receiver by

1, 2

. Denote the computation error that is
}
, i.e.,

∈ {
min
i

E

min
i = min
c∈C

N E

E

(c, Si) .

(11)

If S1 ⊆ S2; then, we have
Proof. The proof is straightforwardly derived from (10). By deﬁnition, we can write for any

min
1 ≤ E

min
2

E

.

linear operator c

(c, S2) =

E

σ2
P

max
k∈S2

2

2

c
φ2
k k
k
hH
k c
|
max
k∈S1

σ2
P

= max

(cid:26)

= max

(c, S1) ,

{E
(c, S1) .

≥ E

2

2 ,

σ2
P

|
c
φ2
k
k k
hH
k c
|
|
(c, S2 − S1)

E

}

max
k∈S2−S1

2

c
φ2
k
k k
hH
k c
|

2

|

(cid:27)

(12a)

(12b)

(12c)

(12d)

Considering the functions

(c, Si) : C

N

7→ R for i

1, 2

, we use the fact that above inequality
}

∈ {

is valid for all c

E
N and write

∈ C

which concludes the proof.

min
c∈C

N E

(c, S2)

min
c∈C

N E

≥

(c, S1)

(13)

12

D. Scheduling Problem

Proposition 1 veriﬁes that the deﬁned computation error increases as the number of selected

terminals grows in the network. This is in contrast to a reliability metric for FL, which improves

as the size of the collected dataset grows. In this respect, device scheduling ﬁnds a fair trade-

off by solving a joint optimization: It tries to maximize the number of selected edge devices8,

subject to the constraint that the computation error is kept below a maximum tolerable level.

Mathematically, we can represent this problem as

max
c∈C

N ,S |S|

subject to max

S

(c, S)

E
[K]

(14)

ǫ

≤

.

S ⊆
for some positive real ǫ representing the maximum tolerable computation error. By substituting

(10) into the optimization, the scheduling problem reduces to

max
c∈C

N ,S |S|

subject to φ2
kk

γ

|

hH
k c

2

|

0

≤

k

∀

∈ S

.

(15)

2

c

k
−
[K]

where we deﬁne γ = P ǫ/σ2.

S ⊆

The optimization problem in (15) reduces to an NP hard problem, and hence its solution cannot

generally be found within a feasible time. As a result, sub-optimal schemes are developed to

approximate the optimal scheduling in polynomial time. An example of such approaches is given

below in Example II.1. This example is of particular interest, as it describes the close-to-optimal

and benchmark scheduling policies which are considered as the references in this work.

Example II.1: The classical approach is to convert the scheduling task into a sparse recovery

problem with concave constraints. To this end, the authors in [38] show that solving the original

8One may initially propose to maximize the size of the aggregated dataset, i.e., Pk∈S

Dk, instead of the number of selected

devices. Nevertheless, one should note that the weights φk are chosen with respect to the size of local datasets. This means that

the impact of different dataset sizes is directly considered in the predeﬁned model aggregation strategy, and hence is not further

addressed in scheduling.

problem in (15) is equivalent to solving the following optimization:

min
N×N ,s∈R

C∈C

s
k0

K

+ k

13

(16)

subject to

hH
k Chk

sk

≤

k

∀

∈

[K]

γ
φ2
} −
k
0N ×N

.

C

tr

{
C

(cid:23)
C

tr

1

{

} ≥
rank (C) = 1

The solution of this equivalent form is then approximated by different approaches. In this paper,

we focus on two techniques; namely, the benchmark and the close-to-optimal approach.

In the benchmark, the ℓ0-norm is replaced by the ℓ1-norm and the rank constraint is dropped.

The resulting problem is then solved using alternating optimization, and the resulting C is

approximated by a rank-one matrix using a low-rank approximation technique [59].

The close-to-optimal approach replaces the ℓ0-norm objective and the rank-one constraint via

DC expressions. It then uses tools from DC programming [60], [61] to approximate the solution

of the determined alternative form. We call this approach close-to-optimal, as the numerical

investigations in [38] show that for small dimensions, where exponential search is feasible, the

DC programming-based approach is consistent with the optimal solution.

In this work, we deviate from the benchmark and close-to-optimal approaches described in

Example II.1 and propose a low-complexity and highly efﬁcient algorithm that directly applies

matching pursuit to address the scheduling task in (15).

III. SCHEDULING VIA MATCHING PURSUIT

The scheduling problem in (15) can be considered to be a sparse recovery problem with an

unconventional constraint. We intend to ﬁnd the smallest subset of devices, such that by setting

them off, the minimum computation error9 falls below the maximum tolerable error. Deﬁning
∈ S, one can
observe the scheduling task as the problem of ﬁnding the sparsest ¯s = [¯s1, . . . , ¯sK], such that

¯sk to be the inactivity of device k, i.e., ¯sk = 0 when k

∈ S and ¯sk = 1 if k /

the computation error constraint is satisﬁed. Although the scheduling constraint is different from

the conventional least-squares constraint in sparse recovery, similar greedy approaches can be

developed for this problem.

9That is minimized over all linear receivers c.

14

The most common greedy approach for sparse recovery is matching pursuit which is widely

used in the context of compressive sensing; see for instance [62]–[69]. Intuitively, matching

pursuit follows a step-wise greedy approach to solve a regression problem: it starts with the

sparsest vector of regression coefﬁcients, i.e., the all-zero vector, and gradually add new indices

to the support, such that the residual sum-of-squares10 is maximally suppressed. For linear

regression, it is shown that to this end, the selected indices in each iteration should be those that

have maximal correlation with the regression error achieved in the previous iteration11.

For the scheduling problem in (15), we can develop the same framework. As the initial

choice for S, we let all the devices be active. We then iteratively remove elements from S and

update c in each iteration such that the computation error is maximally decreased. The resulting

algorithm is presented in Algorithm 1. We skip the detailed derivation at this stage and leave

it for Section IV. For notational compactness, we denote the relation between the inputs and

outputs of this algorithm as

where φ is the vector of device coefﬁcients, i.e.,

(c, S) =

A1 (H, φ) ,

T
φ = [φ1, . . . , φK]

,

and H is the uplink channel matrix, i.e.,

H = [h1, . . . , hK] .

10More precisely, an upper-bound on the residual sum-of-squares.

11This is where the appellation comes from.

(17)

(18)

(19)

Algorithm 1 Matching Pursuit Based Scheduling

Input: The updating strategy Π (

Initialization: Set S

(0) = [K], i(1) =

)

A1 (
·
), and the real positive scalars φk for k
and F (1)

, W(1) = IK, ∆(1) = +

·

[K].

∈

k = 1 for k

∅

∞

while ∆(t) > 0 do
(t−1)

Set S

(t) = S

i(t)

−

Update W(t) by setting

(cid:8)

W(t)

(cid:9)

(cid:2)

i(t),i(t) = 0 and
(cid:3)

W(t)

k,k = Π
(cid:3)

F (t)
k
(cid:16)

(cid:17)

(t).

for all k

∈ S
Find the SVD

(cid:2)

H√W(t) = V(t)Σ(t)U(t)H

and let n(t) be the index of the largest singular value.
Let c(t) = v(t)
Update the constraint indicator F (t)
k

n(t), i.e., the n(t)-th column of V(t).
for device k

(t) as

∈ S
hH
k c(t)

2.

|

F (t)
k = φ2

k −

γ

|

Find the next device index as

Update the maximal constraint as

i(t+1) = argmax
(t)

k∈S

F (t)
k .

∆(t+1) = max
(t)

k∈S

F (t)
k .

t + 1.

Let t

←
end while

Output: c(T ) and S

(T ) with T being the last iteration.

15

[K].

∈

(20)

(21)

(22)

(23)

(24)

The key components of Algorithm 1 are the weighting matrix W(t)

strategy Π (

) : R 7→ R. The weighting matrix W(t)

·

∈ R

K×K and the updating
K×K is a diagonal matrix whose k-th

∈ R

diagonal entries weights the contribution of device k into the average achieved computation

) moreover uses the contribution of device k into the

16

error12 in iteration t. The mapping Π (
·

average computation error and updates its weight for the next iteration. This latter mapping

is the main degree of freedom in Algorithm 1. By ﬁxing the updating strategy Π (
·

), one can

run the algorithm by iterating for a few number of iterations till the algorithm converges to

a feasible point. Noting that the algorithm in each iteration calculates only a single singular

value decomposition (SVD), one can readily conclude that the proposed algorithm signiﬁcantly

reduces the complexity compared to the benchmark and close-to-optimal approaches illustrated

in Example II.1. We discuss the updating strategy and complexity of the algorithm in greater

detail in the forthcoming subsections.

A. Weight Updating via Subset-Cutting

In general, the weight of device k, i.e.,

W(t)

kk, in each iteration should be tuned such

that the algorithm converges as fast as possible. Nevertheless, an extensive search for

kk
leads to high complexity. To avoid this unnecessary complexity, we apply a simple binary tuning

(cid:3)

(cid:2)

W(t)

(cid:2)

(cid:3)

W(t)

strategy to which we refer as subset-cutting. For the sake of compactness, we deﬁne the notation
w(t)

k =
Let us cut the subset of selected devices in iteration t into two subsets:

kk and assume that 0 < w(t)
(cid:3)

(cid:2)
(t)
+ which contains those selected devices whose corresponding constraint indicator, i.e.,
F (t)
k deﬁned in (22), is positive.
(t)
− which includes the remaining devices.

k < 1 for k

∈ S

(t).

• S

• S

Considering the optimization in (10), our ultimate goal is to update the weights, such that the

subset13

(t+1)
+

S

contains as few devices as possible. The simplest strategy to achieve this goal is

for k

to weight the two subsets inversely proportional. We apply this idea, by modeling the sign of
F (t)
∈ S as i.i.d. Bernoulli random variables and letting the weight of each device be its
k
δ
−
) in Algorithm 1 is set to

(0, 1), respectively. This means that the mapping Π (

probability. More precisely, we set the devices in S

(t)
− to be weighted by δ and 1

(t)
+ and S

for some δ

∈

·

δ
Π (x) = 
1


x > 0

δ x

0

≤

−

(25)

12This point becomes clear as the reader goes through Section IV.



13The subset of devices in iteration t + 1 whose corresponding computation error constraint is violated.

17

log γ = 5 dB
log γ = 0 dB

}
|
S
|
{
E

20

15

10

5

0

0

0.5
δ

1

Fig. 1: Average

against δ.

|S|

for some of 0 < δ < 1. The value of δ is then tuned for a given channel model, based on the

statistics of the channel.

Numerical experiments show that the tuning of δ is rather robust. A particular case is observed

in Fig. 1 which shows the average

against δ. Here, we set K = 20 and N = 6 and calculate

|S|

the average numerically over 2000 realizations of i.i.d. complex Gaussian channels with zero

mean and unit variance. The ﬁgure is given for two different values of the parameter γ. As we

can see, the optimal choice of δ changes with γ. Nevertheless, the algorithm performs almost

identically for small enough choices of δ. This indicates that in practice, it is enough to keep δ

small, and an update of its value in each iteration is not necessary. Consequently, in the rest of

this paper, we use this subset-cutting strategy with a ﬁxed choice of δ to update the weight of

the devices, and leave further discussions on more efﬁcient update strategies as a direction for

future work.

18

B. Efﬁciency of Scheduling via Matching Pursuit

The matching pursuit approach reduces the computational complexity of scheduling at the cost

of performance degradation. We now apply some initial numerical investigations to quantify the

scale of this complexity-performance trade-off. To this end, the same setting as the one in Fig. 1

is considered, i.e., N = 6, K = 20 and φk = 1 for k

[K]. The uplink channels are further

∈

generated i.i.d. Gaussian with zero mean and unit variance. For this setting, the matching pursuit

approach, as well as the benchmark and close-to-optimal scheduling policies [38], are used to

perform scheduling for various choices of γ and the performance is averaged over 2000 channel

realizations. The results are then represented in Fig. 2, where the average number of selected

devices is plotted against γ.

As the ﬁgure shows, the proposed algorithm performs rather close to the close-to-optimal

scheduling and outperforms considerably the state-of-the-art; see [38] for more details on the

close-to-optimal and the benchmark. It however is of a signiﬁcantly lower computational com-

plexity compared to the benchmark, as we show in the forthcoming subsection. This observation14

implies that the proposed approach based on matching pursuit is highly efﬁcient for scheduling.

The step-wise nature of Algorithm 1 brings this question into mind whether by using com-

mon extensions of step-wise regression techniques, the performance of this algorithm can be

dominantly enhanced. To ﬁnd an answer to this question, we consider the particular instance

of extending Algorithm 1 via a bidirectional search. To this end, we note that the search in

Algorithm 1 is performed in a backward fashion. A standard extension to this approach is to

add one further step of forward selection after the backward search is over. By doing so, wrongly-

removed devices can be added again to the support. We hence extend the basic algorithm by

revisiting the subset of removed devices once again at the end of each iteration, and place back

to S those removed devices whose updated constraint indicator is not positive. As observed in

Fig. 2, this extension is practically of no gain and only increases the complexity15. This implies

that Algorithm 1 is efﬁcient from both performance and complexity viewpoints.

14Along with the complexity analysis in the next sub-section.

15Note that the corresponding algorithm still has signiﬁcantly lower computational complexity compared to the benchmark

and close-to-optimal policies.

}
|
S
|
{
E

20

15

10

5

0

19

Algorithm 1
Extension
Close-to-optimal
Benchmark

10

−

5
−

0

5

10
γ

15

20

25

30

Fig. 2: Average

|S|

against γ for the proposed algorithm as well as the benchmark and close-to-optimal approach.

C. Complexity of Scheduling via Matching Pursuit

The key property of Algorithm 1 is its signiﬁcant low-complexity. We illustrate this point by

comparing its complexity to that of the benchmark and close-to-optimal scheduling policies. The

benchmark approach solves the scheduling problem iteratively with a ﬁxed number of iterations;

see the algorithms based on semideﬁnite relaxation in [38]. In each iteration, the algorithm

performs two steps of updates, where the ﬁrst step is of the complexity order

(cid:17)
(N 6). We can hence conclude that the benchmark

O

(N 2 + K)3
(cid:16)

,

and the second step is of the complexity order

complexity for scheduling is

O

The close-to-optimal approach that uses DC programming also runs iteratively a two-step

N 2 + K

3 + N 6

(26)

CB =

O

(cid:16)(cid:0)

(cid:1)

(cid:17)

update with the same order of complexity. It runs the update in each iteration for all available

K devices; see [38]. As a result, the complexity of the close-to-optimal approach is

CDCP =

O

K

N 2 + K

3

+ KN 6

.

(cid:16)

(cid:0)

(cid:1)

(cid:17)

(27)

We now consider the proposed algorithm based on matching pursuit. This algorithm runs for

20

T

K iterations. In iteration t, an SVD decomposition of a matrix of size N

≤

required16 whose complexity is

(t)
SVD =
C

O

(K

−

t + 1) N 2

≤ O

KN 2

.

The algorithm is hence of the complexity order of

(cid:0)

(cid:1)

(cid:0)

(cid:1)

CMP =

O

(K

−

T ) KN 2

≤ O

K 2N 2

(K

×

−

t + 1) is

(28)

(29)

which is drastically less than the complexity of the benchmark and close-to-optimal policies. It

(cid:0)

(cid:1)

(cid:0)

(cid:1)

is worth mentioning that the complexity of Algorithm 1 can be even further reduced. In fact, in

each iteration, we only need the singular-vector which corresponds to the largest singular-value

of the weighted channel matrix; see line 5 in the algorithm. A complete SVD determination is

hence unnecessary and one can use alternative algorithms to ﬁnd only the desired singular-vector.

An example is the Lanczos algorithm whose complexity, though not explicitly derived, is known

to be smaller than SVD calculation [70]. Further discussions on such algorithms can be found in

[71], [72]. One can hence conclude that the complexity of the proposed algorithm is in general

of the order of

CMP =

O

(K pN q)

(30)

for some 0 < p, q < 2. This is a huge complexity reduction at the expense of a minor performance

degradation which as we see later in Section V can be neglected in most practical scenarios.

Fig. 3 compares the average run-time of Algorithm 1 with the one of the close-to-optimal

approach for the setting considered in Fig. 2. Here, the time axis is shown in logarithmic scale, in

order to enable comparison. The results clearly show the drastic complexity reduction achieved

by the matching pursuit approach. These results along with those represented in the previous

subsection imply that the proposed algorithm is a suitable candidate for scheduling in real-time

applications of OTA-FL.

Remark 2: As Fig. 3, the complexity of both algorithms drops considerably as γ, i.e., the error

tolerance level, increases. This is due to the fact that both algorithms select more devices at

higher choices of γ, and hence terminate faster in this regime. Considering the step-wise nature

16Remember that W(t) has t − 1 all-zero columns.

21

101

100

10−1

10−2

e
m

i
t
n
u
R

10−3

10−4

10−5

Algorithm 1
Close-to-optimal

10

−

5
−

0

5
10
γ in [dB]

15

20

25

Fig. 3: Runtime in seconds against γ.

of Algorithm 1, we can further ﬂatten the complexity curve by switching from backward selection

to forward selection at lower tolerances. More precisely, for small choices of γ, one can start

from the empty set S =

and add active devices in each iteration. The derivations for this

complementary algorithm follows the exact steps as in Algorithm 1. We hence skip it at this

∅

point and leave it as a natural extension of this work.

IV. DERIVATION OF THE ALGORITHM

In this section, we give the detailed derivations for Algorithm 1. Starting with an initialization,

let the selected support and the linear receiver updated in iteration t be denoted by S

(t) and c(t),

respectively. Given that S

(t) and c(t) do not lead to a feasible point for (10), in this iteration,

i.e., iteration t, we intend to select a device to be eliminated from S

(t) and update the linear

receiver.

Let us denote the index of the device that has been selected at the end of iteration t

1 for

−

this iteration by i(t). Considering Algorithm 1, at the beginning of the iteration, we update the

support by removing device i(t), i.e.,

(t) = S

S

(t−1)

i(t)

.

−

22

(31)

In the sequel, we derive the update rule for the linear receiver c(t) and the new index i(t+1).

(cid:8)

(cid:9)

A. Updating the Linear Receiver

We ﬁrst update the linear receiver for the given support, i.e., we ﬁnd c(t). To this end, let us

deﬁne the constraint function for device k

(t) as

∈ S

fk (c) = φ2
kk
(t), we have fk (c)

c

2

k

−

hH
k c

2.

|

γ

|

(32)

We desire that for all k

≤
this objective is that a weighted sum of these constraint functions with positive coefﬁcients be

∈ S

0. A necessary, but not sufﬁcient, condition for

negative. We use this fact, and deﬁne an average constraint function in iteration t as

F (t) (c) =

w(t)

k fk (c)

(t)

Xk∈S

(33)

for some w(t)

k > 0 for all k

∈ S (t).

From a probabilistic viewpoint, a desired behavior is to have F (t) (c) be as negative as

possible17. We hence update c(t) as

c(t) = argmin

c

F (t) (c)

= argmin

c

= argmin

c

w(t)
k

2

c

φ2
kk

k

γ

|

−

hH
k c

2

|

(t)

Xk∈S
cH

(cid:0)
Φ(t)IN

(cid:1)

γHW(t)HH

c

−

where we deﬁne the weighted average of global weights as

(cid:0)

(cid:1)

and the diagonal matrix W(t)

K×K
+

as

∈ R

(t)

Xk∈S

Φ(t) =

w(t)

k φ2
k,

W(t) = 


0

w(t)
k

k /
∈ S (t)
∈ S (t)

k

.

17Note that these statements only follow from necessary conditions and hence are heuristic.



(34)

(35)

(36)

(37)

(38)

The solution to this latter optimization is readily given by the SVD considering the known

23

bounds on the Rayleigh quotient [73]. In fact, F (t) (c) is simply minimized by setting c to be the
γHW(t)HH. Let us denote

eigenvector corresponding to the minimum eigenvalue of Φ(t)IN
the SVD of H√W(t) as

−

where V(t)

N ×N and U(t)

∈ C

of singular values, i.e.,

H√W(t) = V(t)Σ(t)U(t)H

(39)

K×K are unitary matrices and Σ(t)

∈ C

N ×K
+

∈ R

denotes the matrix

Σ(t) =

Diag

σ(t)
1 , . . . ,

σ(t)
N

0N ×(N −K)

(40)

q
n denoting the squared singular value of H√W(t). Deﬁne the index of the maximum

(cid:12)
(cid:12)

(cid:26)q

(cid:27)

(cid:21)

(cid:20)

with σ(t)
squared singular value of H√W(t) as

and let the maximum value be

n(t) = argmax

n∈[N ]

σ(t)
n

ρ(t) = max
n∈[N ]

σ(t)
n .

(41)

(42)

Moreover, let v(t) and u(t) be the n(t)-th columns of V(t) and U(t), respectively. We then have

min
c

cH

Φ(t)IN

−

γHW(t)HH

c = Φ(t)

γρ(t)

−

which is given by setting

(cid:0)

(cid:1)

We therefore update the linear receiver c(t) as c(t) = v(t).

c = v(t).

(43)

(44)

B. Finding the New Index

After updating the linear receiver, we check whether the updated c(t) results in satisﬁed

constraints for all the devices or not. To this end, we determine the following maximal constraint

function over the selected subset of devices:

Noting that

c(t)

k

k

2 = 1, we can conclude that

(cid:0)

(cid:1)

∆(t) = max
(t)

k∈S

fk

c(t)

.

∆(t) = max
(t)

k∈S

φ2
k −

γ

|

hH
k c(t)

2.

|

(45)

(46)

24

0, we

≤

This metric decides whether further iterations are needed or not. Namely, when ∆(t)

can conclude that the computation error lies below the maximum tolerable limit and hence the

algorithm will stop. With ∆(t) > 0, the constraint on the computation error is not yet satisﬁed

and a further iteration is required.

In the case of ∆(t) > 0, we start the next iteration by removing device i(t+1), where

i(t+1) = argmax

k∈S

(t)

fk

c(t)

= argmax
k∈S

(t)

(cid:0)
φ2
k −

γ

(cid:1)
hH
k c(t)

|

2

|

= argmin
(t)
k∈S

|

hH
k c(t)

2.

|

(47)

(48)

(49)

From the update rule, one can observe that the selected device is the one whose relative inner

product of its uplink channel with the current receiver is minimal. This describes in fact a

matching pursuit strategy, and hence is the reason behind the appellation.

V. NUMERICAL EXPERIMENTS

In this section, we investigate the performance of the proposed algorithm through several

numerical experiments. In this respect, we consider a simple multiuser network in which multiple

edge devices are to learn the classiﬁcation of images from a shared dataset via FL. Using

the standard dataset released by the Canadian Institute for Advanced Research [74], known as

CIFAR-10, we investigate the performance of the proposed algorithm, and compare it with the

benchmark, as well as the close-to-optimal algorithm.

A. Network Setting

We consider a typical OTA-FL setting consisting of a PS and K single-antenna wireless

devices. The PS is equipped with N antenna elements arranged on a uniform linear array (ULA).

We use a two-dimensional Cartesian coordinate system to describe the layout of the network18,

which is depicted in Fig. 4. The PS is located at the origin while the wireless devices are

uniformly placed within a ring with inner radius Rin and outer radius Rout around the PS.

The channel model accounts for both large-scale and small-scale fading. Assuming that a direct

line-of-sight (LoS) path exists between the PS and the wireless devices, a Rician distribution is

18This is a rather accurate approximation assuming that the heights of the edge devices change within a relatively small range

compared to the height of the PS.

25

t
u
o
R

R

i

n

h k

PS

Device k

Fig. 4: Layout of the FL system with one PS and K randomly distributed wireless devices.

used to model the small-scale fading. More speciﬁcally, the vector of uplink channel coefﬁcients

between device k and the PS is described by

where PL(lk) denotes the large-scale path-loss of device k and is a function of its distance from

p

hk =

PL(lk)gk,

(50)

the PS, i.e., lk, and gk

∈ C

by

N describes the small-scale fading process in the channel and is given

gk =

κk
1 + κk

¯gk +

1
1 + κk

˜gk.

r

r

(51)

In (51), the non-negative scalar κk is the Rician factor, and ¯gk and ˜gk denote the LoS and non-

line-of-sight (NLoS) component, respectively. Considering isotropic radiation in a rich scattering

26

environment, the LoS term can be written in terms of the specular array response at the PS by

[75, Chapter 1]

¯gk =

1, u (θk) , u2 (θk) . . . , uN −1 (θk)

where u (θk) is deﬁned as

(cid:2)

T

,

(cid:3)

u (θk) = exp

j2πd sin (θk)

}

{

(52)

(53)

with θk being the (azimuth) angle of arrival (AoA) at the PS from the k-th device, and d being the

distance between two neighboring antenna elements on the ULA normalized by the wavelength.

The NLoS component follows the Rayleigh fading model: ¯gk is modeled by an i.i.d. complex

Gaussian process with zero mean and covariance matrix Rk

N ×N , i.e., ˜gk

∈ C

(0, Rk).

∼ CN

Assuming the number of impinging plane waves superposed at the PS to be large, we set the

elements of the covariance matrix to be [75, Chapter 2]

[Rk]n,m = un−m (θk) ̺(k)

n,m (θk) ,

(54)

where ̺n,m (θk) accounts for the angular spread of the AoA at the PS from device k, and is

given by

̺(k)
n,m (θk) = exp

2ς 2

k [π (n

−

m) d cos (θk)]2

−

(55)

with ςk denoting the angular standard deviation of device k. Throughout the simulations, the

(cid:8)

(cid:9)

nominal AoAs of the devices are determined geometrically from the randomly-generated location

of the devices. The angular standard deviation of each device is further chosen uniformly at

random from the interval [12, 15].

The distance-dependent path loss model is further given by

PL (lk) = PL0

−α

lk
l0 (cid:19)

,

(cid:18)

(56)

where lk denotes the distance between the PS and the k-th user, PL0 denotes the path loss

value at the reference distance l0, and α is the path loss exponent. Without loss of generality,

throughout the simulations, we set l0 = lmin, i.e., the distance of the closest device to the PS,

and PL0 = 1.

Throughout the simulations, we set the numerical values of the communication network

parameters as presented in Table I.

27

Parameter

Inner radius Rin in meters

Outer radius Rout in meters

log κk in [dB]

Value

10

100

3

Antenna elements spacing d (per wavelength)

0.5

Path loss exponent α

3

TABLE I: Simulation parameters for the communication network.

B. Learning Setup

We consider a 10-class image classiﬁcation task on the standard CIFAR-10 dataset. This

dataset contains 60000 images, from which L = 50000 are used as the training data and the

remaining 10000 images as the test data. The overall dataset is partitioned into K subsets and

shared among the edge devices. The training data points are heterogeneously distributed among

the edge devices according to the following asymmetric approach: for a randomly-selected half
of devices, ˜Lk is uniformly drawn from the interval

[L/K, L/K + ǫ1] .

(57)

for some non-negative real-valued ǫ1. For the remaining half, ˜Lk is uniformly drawn from the
interval [ǫ0, ǫ1] for some ǫ0 < ǫ1. The number of training images at device k is then set to

1
K  
This allows for a high variation among the local datasets sizes, i.e., quantity skew. The local

Lk = ˜Lk +

k=1
X

(58)

!%

˜Lk

−

L

$

K

datasets are further collected by an asymmetric sampling scheme, such that we observe label

skew across the local datasets [76].

To learn the image classiﬁcation task, a convolutional neural network (CNN) is locally trained

at each of the selected wireless devices. The employed CNN is designed as a simpliﬁed version

of the widely known VGG13 network19 [77]. Speciﬁcally, its architecture consists of eight

convolutional blocks and two subsequent fully-connected layers. A convolutional block refers

to the collection of a convolutional layer, a batch-normalization layer, and a rectiﬁed linear unit

19Named after the visual geometry group at University of Oxford.

28

Parameter

Number of train images D

Number of test images

Number of epochs

Number of communication rounds T

Dropout probability

Learning rate β

Batch size

Momentum

Value

50 000

10 000

60

6

0.5

0.005

32

0.9

TABLE II: Simulation parameters for the learning setting.

activation function. The convolutional ﬁlter size is ﬁxed to 3

3, whereas the number of ﬁlters

×

for the eight convolutional layers are set to 32, 32, 64, 64, 128, 128, 256, and 256, respectively.

Moreover, a max-pooling operation with a ﬁlter size of 2 and stride of 2 is performed after each

two convolutional blocks. Finally, we set the number of output nodes for the ﬁrst fully-connected

layer to 512, which is followed by a dropout layer in order to avoid overﬁtting during training.

All local CNN models are trained using the stochastic gradient descent (SGD) with momentum

algorithm to minimize a cross-entropy loss function. The training starts with an initial learning

rate of 0.005. The learning rate is eventually adjusted according to a reduce on plateau strategy,

which halves the learning rate if the test loss has not been improving over the last ten epochs.

Throughout the simulations of the FL process, we consider a time-varying Rician fading

channel. We assume that the channel changes from one communication round to another, but

it remains constant during the learning epochs within one round. We set the number of epochs

per round to 10 and the total number of communication rounds to T = 6. The scalars ǫ0 and ǫ1

are further set to ǫ0 = 300 and ǫ1 = 500. Other relevant parameters for training the CNN image

classiﬁer are shown in Table II.

C. Simulation Results

We start the numerical investigations by giving the learning performance ﬁgures for Algo-

rithm 1, as well as the closed-to-optimal and benchmark policies, in Figs. 5, 6 and 7. For these

29

Algorithm 1
Close-to-optimal
Benchmark
Perfect FL

s
s
o
L

g
n
i
n
i
a
r
T

2

1.5

1

0.5

10

20

30
epoch

40

50

60

Fig. 5: Training loss against the number of training epochs.

ﬁgures, we set the number of devices to K = 20 and the size of the PS ULA to N = 6. Fig. 5

shows the training loss versus the number of epochs averaged over multiple channel realizations

considering both approaches. The test loss over the test dataset is further shown in Fig. 6. As a

reference, we further plot the test loss achieved by perfect federated averaging. The simulation

results for this case is denoted as perfect FL in the ﬁgures representing the scenario in which

all the devices are participating in the learning and communicate over a noiseless network.

Perfect FL hence gives a lower bound for training and test loss, and an upper bound for learning

accuracy. The remaining parameters in the setting are selected from Tables I and II and the

internal parameters of the algorithms are numerically optimized.

As Fig. 6 shows, the test losses incurred by both the algorithms closely track the loss achieved

by perfect FL over a noise-less network while the benchmark algorithm performs considerably

degraded. For this ﬁgure, the tolerable computation error is set such that log γ = 15 dB.

Compared with the close-to-optimal policy, the minor degradation observed in the performance

of the proposed scheme is compensated for in terms of complexity.

Fig. 7 shows the accuracy of the trained machines in classifying the test dataset. As expected

30

Algorithm 1
Close-to-optimal
Benchmark
Perfect FL

10

20

30
epoch

40

50

60

Fig. 6: Test loss against the number of training epochs.

Algorithm 1
Close-to-optimal
Benchmark
Perfect FL

s
s
o
L

t
s
e
T

2

1.5

1

0.5

%
n
i

y
c
a
r
u
c
c
A

80

60

40

20

10

20

30
epoch

40

50

60

Fig. 7: Accuracy of classiﬁcation over the test dataset against the number of training epochs.

20

15

}
|
S
|
{
E

10

5

0

31

Algorithm 1
Close-to-optimal
Benchmark

10

−

0

10

20
log γ in [dB]

30

40

50

Fig. 8: Average

|S|

versus computation error tolerance for the simulated network.

from the behavior of the test loss, the matching pursuit scheme and the close-to-optimal policy

closely track the upper-bound achieved by perfect FL while the benchmark algorithm signiﬁcantly

performs degraded. This observation can be illustrated as follows: While the close-to-optimal

approach schedules almost optimally with high computational complexity, the matching pursuit

strategy reduces the complexity signiﬁcantly at the expense of a sub-optimal performance. This

degradation is however negligible, since the matching pursuit technique drops only few devices

with minimal effect in the overall learning performance. The benchmark algorithm however fails

to schedule dominant devices, and hence performs considerably degraded.

To specify the scheduling performance, we repeat the experiment in Fig. 2 for the simulated

channels20 and compare the proposed scheduling algorithm with the close-to-optimal and the

benchmark in Fig. 8. As the ﬁgure shows, the close-to-optimal algorithm outperforms Algo-

rithm 1 while both outperform the benchmark. As mentioned, this degradation in performance

results in a signiﬁcant complexity reduction which is demonstrated in Fig. 9. In this ﬁgure,

20Remember that in Fig. 2 the channels are generated i.i.d. Gaussian.

32

Algorithm 1
Close-to-optimal
Benchmark

e
m

i
t
n
u
R

103

102

101

100

10−1

10−2

10−3

5

10

(a)

N

15

20

20

25

30

35

40

45

K

(b)

Fig. 9: Runtime in seconds against network dimensions.

we plot the runtime of each algorithm against the number of devices K and the receiver

dimension N while considering low error tolerance, i.e., log γ = 0 dB. To be able to compare

the ﬁgures, we represent the vertical axis in the logarithmic scale. As the ﬁgure shows, using the

proposed scheme, the complexity reduces signiﬁcantly compared with both the close-to-optimal

and benchmark while performing in between the two schemes. This shows a clear enhancement

with respect to the complexity-performance trade-off.

To evaluate the impact of over-the-air computation on the performance of FL, we deﬁne a

new efﬁciency metric. Namely, we deﬁne the over-the-air efﬁciency as

ζota =

Accuracyota
Accuracyﬂ

(59)

where Accuracyota and Accuracyﬂ represent the classiﬁcation accuracy achieved by over-the-
air computation and perfect FL, respectively. In general, 0
1 and characterizes the

ζota ≤

≤

loss imposed on federated averaging, due to the imperfection of OTA-FL. Fig. 10 shows the

over-the-air efﬁciency as a function of the error tolerance γ for K = 20 devices and N = 6

33

antennas when we train the model with 60 epochs, i.e., after six communication rounds, using the

proposed scheduling scheme. Interestingly, the ﬁgure shows a clear trend: there exists a tolerance

level at which the algorithm results in best efﬁciency. This behavior can be clariﬁed in light of

the contradiction between the learning performance enhancement and the degradation caused

by imperfect aggregation: For small choices of γ, few devices are selected. In this case, the

gain achieved by restricting the aggregation error is inferior to the loss imposed on the inference

performance, due to training over a small dataset. As a result, the over-the-air efﬁciency improves

by loosening the constraint on the aggregation error, i.e., allowing more devices to participate.

This improvement continues until an optimal point is reached, where increasing the level of

tolerable aggregation error21 severely degrades the overall learning performance, such that the

enhancement achieved by learning over a larger dataset is not dominant anymore. By going

above this optimal point, the over-the-air efﬁciency only decreases.

As the ﬁgure shows, by properly choosing the tolerance level, we can achieve up to 98% of

over-the-air efﬁciency. This follows from the fact that some of devices have small local datasets,

and their contribution in the learning task is rather minor. It is worth mentioning that 98% of

the over-the-air efﬁciency in this case is achieved by Algorithm 1 which signiﬁcantly reduces

the scheduling complexity.

VI. CONCLUSIONS

Considering the limited computational capacity of communication devices in wireless net-

works, the proposed scheme should be an efﬁcient approach to perform OTA-FL in various

recently-proposed network architectures. An example is the concept of ultra-dense networks in

which a very large number of devices with limited power and storage are to be connected with a

single access point [78]–[83]. The limited storage at edge devices in such networks leads to poor

learning performance, when it is performed individually. On the other hand, the large number of

devices can lead to high aggregation cost at the access point, if it applies an FL algorithm on the

complete dataset via a separately-designed aggregation strategy. In such scenarios, the matching-

pursuit-based scheduling scheme allows a fair trade-off between the learning performance and

the aggregation cost with a manageable complexity.

The numerical results imply that the over-the-air learning-aggregation trade-off shows a trend:

With a predeﬁned scheme for OTA-FL, there exists an optimal operating point. By deviating from

21Due to imperfect aggregation.

34

1
0.98

a
t
o
ζ

0.8

0

10

20
log γ in [dB]

30

40

Fig. 10: Over-the-air efﬁciency against the computation error tolerance.

this point via hardening or loosening the constraint on the aggregation cost, the overall learning

performance is degraded. This behavior further conﬁrms our initial statement: Device scheduling

is in general sub-optimal; however, with a predeﬁned setting and a restricted complexity budget,

it can efﬁciently address the challenges in OTA-FL. Although design of the optimal joint OTA-FL

strategy seems to be analytically intractable, our intuition based on properties of multiple access

channels suggests that the performance of optimal AirComp-based OTA-FL can be characterized

in the asymptotic regime. This is an interesting direction for future work.

The presented work can be extended in various directions. One natural direction is to extend

the proposed scheme to networks with parametrized channels, e.g., IRS-aided networks [84].

This direction is brieﬂy discussed in Appendix C. Investigating the robustness of the proposed

scheme under various imperfections, e.g., imperfect CSI acquisition, is another direction for

further study.

35

APPENDIX A

BACKGROUND ON OVER-THE-AIR FEDERATED LEARNING

The concept of OTA-FL via AirComp can be clearly illustrated through an example. In this

appendix, we give a simple comprehensive example of FL. Using this example, we then clarify

the concept of AirComp-based OTA-FL.

A. An Illustrative Example of Federated Learning

Consider a basic training task in a machine learning problem: We intend to ﬁt a given dataset

onto a linear model; namely, a set of data pairs D =

(βi, ai) :

is available with βi

{
D. We intend to learn the following linear model:

∈

i
∀

[I]
}

being a real scalar and ai

∈ R

from the dataset, i.e., we aim to ﬁnd θ

∈ R

error.

β = θTa

(60)

D such that (60) describes the dataset with minimum

A classical approach to address this learning task is to ﬁnd the model parameters, i.e., the

entries of θ, via the method of least-squares (LS). This is a trivial task when the dataset is

centralized at the PS. In this case, the PS sets the residual sum of squares (RSS) as a loss

function, i.e.,

I

F (θ) =

and ﬁnds the model parameters by solving the following optimization problem

βi

|

−

θTai

2,

|

i=1
X

min
θ∈R

D

F (θ) .

(61)

(62)

The above task is trivial due to the centralized nature of the setting; however, in decentralized

settings it becomes more challenging: Assume that the dataset D is partitioned into sub-sets

Dk for k

∈

[K] and shared among K devices. In this case, ﬁnding the model parameters

through a joint optimization, i.e., like the one given in (62), requires that the devices send their

local datasets, i.e., Dk, into a central node. This is however not feasible for a wide variety

of applications. The key issues that prevent using such a centralized setting are privacy and

communication. In fact, by sending the local datasets to a central dataset, we increase the risk of

local information being revealed to untrustworthy parties. Moreover, in many applications, the

36

aggregate of the local datasets is large and sharing the complete local datasets leads to network

overload.

To deal with decentralized settings, we mainly have two options:

• Either let each device learn its own model parameters independently, i.e., device k solves

(62) for an RSS term determined by the data points in Dk.

• Or, use an FL algorithm to learn a common model from the local model parameters.

The FL approach is of great interest in various applications, as it enables a trade-off between

the intractability of centralized learning and the inefﬁciency of independent distributed learning.

Let us now get back to the considered example assuming that the datasets is distributed among

K devices. We consider the federated averaging algorithm [58]: Each device ﬁnds its own model

parameter θk by solving

where Fk (θ) denotes the locally-calculated RSS of device k, i.e.,

min
θ∈R

D

Fk (θ) ,

Fk (θ) =

β

|

−

θTa
|

2.

X(β,a)∈Dk
It then sends θk to the PS in the network. After collecting all the local model parameters, the

PS sets the global model parameter to be

K

¯θ =

φkθk,

(65)

and shares it with the devices. Here, 0
[K] are weighting coefﬁcients chosen
with respect to the reliability of the local datasets22. In this algorithm, one can observe ¯θ as a

1 for k

φk

≤

≤

∈

k=1
X

simple approximation of the optimal model parameter derived intuitively from this observation

that

K

F (θ) =

Fk (θ) .

(66)

k=1
X
In general, one can think of a more generic computational setting in which each device

uploads a function of its mode parameters and the PS applies FL by determining a function of

the aggregated model parameters. In this respect, the federated averaging algorithm is seen as a

special case in which all functions are set to be linear.

22For instance, φk is chosen proportional to the size of the local dataset at device k.

(63)

(64)

37

B. OTA-FL via AirComp

In the above example, we assumed that the upload of local model parameters to the PS and

download of global model from the PS are performed noiselessly through orthogonal channels.

This is however not the case in a wireless network. In wireless networks, multiple devices

usually communicate with the PS through a multiple access channel (MAC). In the ﬁrst glance,

this seems to increase the computational load of the PS: The PS needs to ﬁrst estimate individual

local parameters and then combine them. Nevertheless, it is straightforward to see that this is

a wrong conclusion. To clarify this point, consider the following simple setting: All devices

transmit their local parameters over a static linear MAC in D consequent transmission time

slots. Assume that each device has a single antenna, and the PS is equipped with an antenna

array of size N. Hence, after D time slots, the PS receives

Y = HΘT + Ξ,

(67)

where Ξ denotes the noise process, H

N ×K is the channel matrix whose entry (n, k)

represents the channel coefﬁcient between device k and antenna n,

∈ C

Θ = [θ1, . . . , θK] ,

(68)

and Y

∈ C

N ×D is the matrix of received signals whose column d represents the signal received

by the PS array antenna in the d-th channel use.

From the channel model, it is observed that the received signals are already combined versions
of the local parameters. Hence, a proper linear receiver can estimate ¯θ directly from Y without

recovering the individual local parameters. To further clarify this latter point, let us ignore the

noise process in the channel. Using a linear receiver c
∈ C
antennas of the PS can be combined into a single vector ˆθ

D as

∈ C

N , the signals received over multiple

By designing c such that

we have

T

ˆθ

= cTY = cTHΘT.

cTH = [φ1, . . . , φK] ,

T
ˆθ = Θ [φ1, . . . , φK]

= ¯θ.

(69)

(70)

(71)

38

This means that the PS can directly apply federated averaging by ﬁnding a c which satisﬁes

(70) and no further parameter estimation is required. With a large-enough antenna array, such a

task is easily fulﬁlled via zero forcing (ZF).

In practice, the exact calculation of ¯θ is not possible at the PS, as the received signals are noisy.
Thus, in this case, we should determine the linear receiver c such that ˆθ estimates ¯θ, properly.

A common approach is to ﬁnd the receiver by applying an MMSE estimator to determine the
target model parameters ¯θ. This means that we ﬁnd c as

c = argmin

YTx

¯θ

2

.

(72)

k
(cid:8)
Here, the expectation is taken with respect to all random quantities in the channel, as well as the
distribution of ¯θ which is determined through assuming a stochastic model for either the local

x∈R

−

(cid:9)

k

N

E

datasets or the local model parameters.

APPENDIX B

MMSE VS. ZERO-FORCING COORDINATION

As indicated in Section II-B, zero forcing is a sub-optimal, yet efﬁcient, approach for coordi-

nation. The optimal approach in this case is to ﬁnd MMSE estimate: We ﬁnd the minimizer of

the following objective function:

(c, S, η, ψ) = E

E

with respect to all design parameters, i.e., c, S, η, and ψ, subject to the power constraint, i.e.,

ˆθ (c, S, η, ψ)

|

θ (S)

2

|

−

n

o

.

(73)

ψ

k

∞

k

≤

√P

(74)

∞ denotes the ℓ∞-norm.

where

k·k

Unlike zero forcing coordination, the MMSE coordination does not necessarily cancel the

local parameters in the objective function. Hence, the exact derivation of the metric in this

case requires an explicit statistical model for the local model parameters. This leads to a more

complicated expression for the aggregation cost metric. It is worth mentioning that, even for the

unrealistic model of i.i.d. model parameters, a closed-form expression for the objective function

is not straightforwardly derived for an arbitrary noise variance. It is however straightforward to

show that for small enough noise variances, the MMSE and zero forcing coordination approaches

meet.

39

APPENDIX C

EXTENSIONS TO PARAMETRIZED CHANNELS

In various recent technologies, the wireless channel is parametrized by tunable variables.

One of the most well-known examples is IRS-aided networks in which the end-to-end channels

between the PS and the edge devices are modiﬁed by IRSs [47]. The efﬁcient approach in

these networks is to tune the channel parameters jointly with user scheduling. For the particular

example of IRS-aided networks, a DC programming-based algorithm for joint scheduling and

channel tuning is proposed in [47]. Considering the wide scope of recent technologies that enable

the parametrization of wireless channels, in this section, we extend our proposed scheduling

scheme to a more generic form by which joint scheduling and channel tuning is performed.

A. Networks with Parametrized Channels

A parametrized channel between edge device k and the PS is in general denoted by hk (µ)

for some vector of tunable parameters

µ = [µ1, . . . , µM ]

T

(75)

with support U, i.e., µ

channel matrix as

∈ U. These parametrized channels can be collected into a parametrized

H (µ) = [h1 (µ) , . . . , hK (µ)] .

(76)

A well-known example of parametrized channels is a wireless network equipped with IRSs.

This example is illustrated below:

Example C.1 (IRS-aided Networks): Consider the same setting presented throughout the prob-

lem formulation in Section II. We further assume that a passive IRS is located at a ﬁxed distance

from the PS. The IRS consists of M reﬂecting elements that reﬂect their received signals after

applying tunable phase-shifts. Let gm,k denote the channel coefﬁcient between device k and the

m-th reﬂecting element on the IRS. Moreover, denote the channel vector between IRS element

m and the PS by tm

∈ C

N . The end-to-end channel between device k and the PS is given by

hk (µ) = h0

k + TGkµ

(77)

40

where h0

k denotes the direct link between the PS and device k, the matrix T represents the

channel matrix between the IRS and the PS, i.e., T = [t1, . . . , tM ], and

Gk = Diag

g1,k, . . . , gM,k

.

}

{

(78)

The parameter vector µ is deﬁned as in (75) with µm denoting the tunable phase-shift applied

by IRS element m, i.e., µm

∈ U1 with U1 denoting the unit circle on the complex plane.

B. Joint Scheduling and Tuning via Matching Pursuit

In a network with parametrized channels, the computation error directly depends on the channel

parameters: For a given µ, the parametrized computation error is given by

As a result, the scheduling and channel tuning are mutually coupled: For a given subset of

(µ, c, S) =

E

σ2
P

max
k∈S

φ2
k

2

c
k
k
hH
k (µ) c

|

|

2 .

(79)

devices, the channel tuning task aims to ﬁnd µ, such that the parametrized computation error is

minimized. For a given set of channel parameters, scheduling tries to ﬁnd the largest subset of

devices that results in a bounded computation error.

The joint scheduling and channel tuning task can be mathematically formulated as

max
M ,c∈C

µ∈U

N ,S |S|

subject to φ2
kk

2

c

k
−
[K]

S ⊆

hH

k (µ) c

γ

|

2

|

≤

0

k

∀

∈ S

.

(80)

Similar to the basic case with non-parametrized channels, the direct joint solution to (80) is

computationally intractable, as the scheduling task reduces to integer programming. We hence

extend the matching pursuit approach to this case while tuning the channel parameters via the

alternating optimization technique.

We start the extension, by focusing on iteration t in which the subset S

(t) is determined after
(t−1) in the previous iteration. Denote the channel parameters updated
omitting index i(t) from S
in the last iteration by µ(t−1). Following the similar weighting approach as in Algorithm 1, the

linear operator c and the channel parameters µ are jointly updated as

µ(t), c(t)

= argmin

µ,c

cH

Φ(t)IN

−

γH (µ) W(t)HH (µ)

c.

(81)

The global solution to this optimization problem is in general intractable. We hence invoke the

(cid:0)

(cid:1)

(cid:0)

(cid:1)

alternating optimization technique to approximate the solution.

The alternating optimization approach approximates the solution as follows: It starts by setting

41

µ0 = µ(t−1) and ﬁnds cj for alternation j

0 as

≥
Φ(t)IN

cj+1 = argmin

c

cH

= vj

γH

µj

W(t)HH

µj

c

−

(cid:0)

(cid:0)

(cid:1)

(cid:0)

(cid:1)(cid:1)

(82a)

(82b)

where vj is the column corresponding to the largest singular value of H
n⋆-th column of Vj with

µj

√W(t), i.e., the

(cid:0)

(cid:1)

H

µj

√W(t) = VjΣjUH

j

(83)

and n⋆ denotes the index of the column of Σj which includes the largest non-zero entry. It then

(cid:0)

(cid:1)

alternates the optimization variable, i.e., it solves

µj+1 = argmin

µ∈U

M

= argmax
µ∈U

M

cH
j+1

Φ(t)IN

γH (µ) W(t)HH (µ)

−
j+1H (µ) W(t)HH (µ) cj+1,
cH

(cid:0)

cj+1,

(cid:1)

(84a)

(84b)

which is a norm minimization and can be solved by various algorithms depending on the exact

form of H (µ). For many forms of H (µ), the solution to this optimization cannot be determined

explicitly ans is approximated via some algorithm. We hence denote it as

where

(

·

P

) denotes the algorithm which ﬁnds (or approximates)

(cid:0)

(cid:1)

µj+1 =

cj+1|

P

H, W(t)

µ⋆

j+1 = argmax

µ∈U

M

j+1H (µ) W(t)HH (µ) cj+1.
cH

(85)

(86)

We call this algorithm the channel update policy which should be adapted to the application.

The solution to (81) is ﬁnally approximated by alternating between (85) and (82b) for a ﬁnite

number of alternations. The receiver and channel parameters in iteration t of the main loop, i.e.,

c(t) and µ(t), are set to be the converging solutions determined by alternating optimization.

We ﬁnally ﬁnd the most dominant root of the computation error and remove it from the

selected support, i.e., we set

i(t+1) = argmax

k∈S

(t)

φ2
k −

γ

|

hH
k

µ(t)

c(t)

2,

|

(87)

and terminate the algorithm, when the computation error falls below the desired threshold. The

(cid:0)

(cid:1)

pseudo-code for this process is given in Algorithm 2.

Algorithm 2 Matching Pursuit Based Joint Tuning and Scheduling

Input: The updating strategy Π (

Initialization: Set S

(0) = [K], i(1) =

µ(0) to some feasible point in U

M .

A2 (
)
·
), and the real positive scalars φk for k
and F (1)

, W(1) = IK, ∆(1) = +

·

[K].

∈

k = 1 for k

∅

∞

42

[K]. Set

∈

while ∆(t) > 0 do
(t−1)

Set S

(t) = S

i(t)

.

−

W(t)

(cid:8)

Update W(t) by setting
Set µ0 = µ(t−1) and j = 0.
while It converges do

(cid:9)

(cid:2)

i(t),i(t) = 0 and
(cid:3)

W(t)

k,k = Π

(cid:2)

(cid:3)

F (t)
k
(cid:16)

(cid:17)

for all k

(t).

∈ S

Find the SVD H

µj

√W(t) = VjΣjUH

j and let nj be the index of the largest singular

value.

(cid:0)

(cid:1)

Let cj+1 be the nj-th column of Vj and update the channel parameters as

µj+1 =

cj+1|

P

H, W(t)

(cid:0)

(cid:1)

j + 1.

Let j

←
end while

Set µ(t) = µJ and c(t) = cJ with J denoting the ﬁnal alternation.
Update the constraint indicator F (t)
k

for device k

(t) as

F (t)
k = φ2

k −

hH
k

γ

|

∈ S
µ(t)

c(t)

2.

|

Find the next device index and the maximal constraint as

(cid:0)

(cid:1)

i(t+1) = argmax
(t)

k∈S

F (t)
k ,

∆(t+1) = max
(t)

k∈S

F (t)
k .

t + 1.

Let t

←
end while

Output: c(T ), µ(T ) and S

(T ) with T being the last iteration.

(88)

(89)

(90a)

(90b)

C. Example: OTA-FL via AirComp in IRS-Aided Wireless Networks

The joint scheduling and tuning algorithm considers a general setting with parametrized

43

channels. Nevertheless, for a given application, the channel update policy

(

) should be adapted

P

·

due to the parametrization model H (µ). In this section, we consider the particular example of

IRS-aided wireless networks and develop a channel update policy for the joint scheduling and

channel tuning algorithm.

Consider the IRS-aided network described in Example C.1. For this setting, the marginal

channel tuning problem reduces to

µ⋆

j+1 = argmax

µ∈U

M
1

µHQ(t)

j µ + 2

ℜ

µHa(t)
j

n

o

where Q(t)
j

and a(t)
j

are given by

K

k=1
X
K

Q(t)

j =

a(t)
j =

k GH
w(t)

k Tcj+1cH

j+1TGk,

k GH
w(t)

k Tcj+1cH

j+1h0
k.

(91)

(92a)

(92b)

This is a unit-modulus problem which reduces in general to an NP-hard problem. Classical

k=1
X

approaches to estimate the solutions in polynomial time are to use the block coordinate descent

(BCD) method or majorization-maximization (MM) technique.

REFERENCES

[1] L. Lyu, H. Yu, and Q. Yang, “Threats to federated learning: A survey,” 2020, arXiv preprint arXiv:2003.02133.

[2] M. Aledhari, R. Razzak, R. M. Parizi, and F. Saeed, “Federated learning: A survey on enabling technologies, protocols,

and applications,” IEEE Access, vol. 8, pp. 140 699–140 725, 2020.

[3] P. P. Liang, T. Liu, L. Ziyin, N. B. Allen, R. P. Auerbach, D. Brent, R. Salakhutdinov, and L.-P. Morency, “Think locally,

act globally: Federated learning with local and global representations,” 2020, arXiv preprint arXiv:2001.01523.

[4] Z. Yang, M. Chen, K.-K. Wong, H. V. Poor, and S. Cui, “Federated learning for 6G: Applications, challenges, and

opportunities,” Engineering, 2021.

[5] D. C. Nguyen, M. Ding, P. N. Pathirana, A. Seneviratne, J. Li, and H. V. Poor, “Federated learning for internet of things:

A comprehensive survey,” IEEE Communications Surveys & Tutorials, 2021.

[6] G. Ananthanarayanan, P. Bahl, P. Bodík, K. Chintalapudi, M. Philipose, L. Ravindranath, and S. Sinha, “Real-time video

analytics: The killer app for edge computing,” Computer, vol. 50, no. 10, pp. 58–67, Oct. 2017.

[7] C.-C. Hung, G. Ananthanarayanan, P. Bodik, L. Golubchik, M. Yu, P. Bahl, and M. Philipose, “Videoedge: Processing

camera streams using hierarchical clusters,” in Proc. IEEE/ACM Symposium on Edge Computing (SEC), Seattle, WA,USA,

Oct. 2018, pp. 115–131.

44

[8] Z. Zhou, X. Chen, E. Li, L. Zeng, K. Luo, and J. Zhang, “Edge intelligence: Paving the last mile of artiﬁcial intelligence

with edge computing,” Proceedings of the IEEE, vol. 107, no. 8, pp. 1738–1762, 2019.

[9] W. Shi, J. Cao, Q. Zhang, Y. Li, and L. Xu, “Edge computing: Vision and challenges,” IEEE Internet of Things Journal,

vol. 3, no. 5, pp. 637–646, 2016.

[10] W. Shi and S. Dustdar, “The promise of edge computing,” Computer, vol. 49, no. 5, pp. 78–81, 2016.

[11] N. Abbas, Y. Zhang, A. Taherkordi, and T. Skeie, “Mobile edge computing: A survey,” IEEE Internet of Things Journal,

vol. 5, no. 1, pp. 450–465, 2017.

[12] M. I. Jordan, J. D. Lee, and Y. Yang, “Communication-efﬁcient distributed statistical inference,” Journal of the American

Statistical Association, vol. 114, no. 526, pp. 668–681, 2019.

[13] T. Chen, G. Giannakis, T. Sun, and W. Yin, “LAG: Lazily aggregated gradient for communication-efﬁcient distributed

learning,” Advances in Neural Information Processing Systems, vol. 31, 2018.

[14] A. Elgabli, J. Park, A. S. Bedi, M. Bennis, and V. Aggarwal, “GADMM: Fast and communication efﬁcient framework for

distributed machine learning.” Journal of Machine Learning Research, vol. 21, no. 76, pp. 1–39, 2020.

[15] W. Liu, X. Zang, Y. Li, and B. Vucetic, “Over-the-air computation systems: Optimization, analysis and scaling laws,” IEEE

Transactions on Wireless Communications, vol. 19, no. 8, pp. 5488–5502, 2020.

[16] T. Li, A. K. Sahu, A. Talwalkar, and V. Smith, “Federated learning: Challenges, methods, and future directions,” IEEE

Signal Processing Magazine, vol. 37, no. 3, pp. 50–60, 2020.

[17] J. Koneˇcn`y, H. B. McMahan, D. Ramage, and P. Richtárik, “Federated optimization: Distributed machine learning for

on-device intelligence,” 2016, arXiv preprint arXiv:1610.02527.

[18] K. Bonawitz, H. Eichner, W. Grieskamp, D. Huba, A. Ingerman, V. Ivanov, C. Kiddon, J. Koneˇcn`y, S. Mazzocchi,

B. McMahan et al., “Towards federated learning at scale: System design,” Proceedings of Machine Learning and Systems,

vol. 1, pp. 374–388, 2019.

[19] Q. Yang, Y. Liu, Y. Cheng, Y. Kang, T. Chen, and H. Yu, “Federated learning,” Synthesis Lectures on Artiﬁcial Intelligence

and Machine Learning, vol. 13, no. 3, pp. 1–207, 2019.

[20] F. Sattler, S. Wiedemann, K.-R. Müller, and W. Samek, “Robust and communication-efﬁcient federated learning from

non-iid data,” IEEE Transactions on Neural Networks and Learning Systems, vol. 31, no. 9, pp. 3400–3413, 2019.

[21] N. Shoham, T. Avidor, A. Keren, N. Israel, D. Benditkis, L. Mor-Yosef, and I. Zeitak, “Overcoming forgetting in federated

learning on non-iid data,” 2019, arXiv preprint arXiv:1910.07796.

[22] S. Lee, C. Park, S.-N. Hong, Y. C. Eldar, and N. Lee, “Bayesian federated learning over wireless networks,” 2020, arXiv

preprint arXiv:2012.15486.

[23] M. Luo, F. Chen, D. Hu, Y. Zhang, J. Liang, and J. Feng, “No fear of heterogeneity: Classiﬁer calibration for federated

learning with non-iid data,” Advances in Neural Information Processing Systems, vol. 34, 2021.

[24] T. Gafni, N. Shlezinger, K. Cohen, Y. C. Eldar, and H. V. Poor, “Federated learning: A signal processing perspective,”

IEEE Signal Processing Magazine, vol. 39, no. 3, pp. 14–41, 2022.

[25] M. Fredrikson, S. Jha, and T. Ristenpart, “Model

inversion attacks that exploit conﬁdence information and basic

countermeasures,” in Proc. of the 22nd ACM SIGSAC Conference on Computer and Communications Security, 2015,

pp. 1322–1333.

[26] K. Wei, J. Li, M. Ding, C. Ma, H. H. Yang, F. Farokhi, S. Jin, T. Q. S. Quek, and H. V. Poor, “Federated learning with

differential privacy: Algorithms and performance analysis,” IEEE Transactions on Information Forensics and Security,

vol. 15, pp. 3454–3469, 2020.

[27] M. Kim, O. Günlü, and R. F. Schaefer, “Federated learning with local differential privacy: Trade-offs between privacy,

45

utility, and communication,” in Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),

2021, pp. 2650–2654.

[28] Y. Shi, K. Yang, T. Jiang, J. Zhang, and K. B. Letaief, “Communication-efﬁcient edge AI: Algorithms and systems,” IEEE

Communications Surveys & Tutorials, vol. 22, no. 4, pp. 2167–2191, 2020.

[29] H. H. Yang, Z. Liu, T. Q. S. Quek, and H. V. Poor, “Scheduling policies for federated learning in wireless networks,”

IEEE Transactions on Communications, vol. 68, no. 1, pp. 317–333, 2020.

[30] M. Chen, N. Shlezinger, H. V. Poor, Y. C. Eldar, and S. Cui, “Communication-efﬁcient federated learning,” Proceedings

of the National Academy of Sciences, vol. 118, no. 17, 2021.

[31] R. Crane and F. Roosta, “DINGO: Distributed Newton-type method for gradient-norm optimization,” Advances in Neural

Information Processing Systems, vol. 32, 2019.

[32] H. Gao and H. Huang, “Can stochastic zeroth-order frank-wolfe method converge faster for non-convex problems?” in

Proc. International Conference on Machine Learning. PMLR, 2020, pp. 3377–3386.

[33] H. T. Nguyen, V. Sehwag, S. Hosseinalipour, C. G. Brinton, M. Chiang, and H. V. Poor, “Fast-convergent federated

learning,” IEEE Journal on Selected Areas in Communications, vol. 39, no. 1, pp. 201–218, 2020.

[34] Y. Lin, S. Han, H. Mao, Y. Wang, and B. Dally, “Deep gradient compression: Reducing the communication bandwidth for

distributed training,” in Proc. International Conference on Learning Representations, Feb. 2018.

[35] K. Yuan, B. Ying, J. Liu, and A. H. Sayed, “Variance-reduced stochastic learning by networked agents under random

reshufﬂing,” IEEE Transactions on Signal Processing, vol. 67, no. 2, pp. 351–366, Sep. 2018.

[36] N. Shlezinger, M. Chen, Y. C. Eldar, H. V. Poor, and S. Cui, “UVeQFed: Universal vector quantization for federated

learning,” IEEE Transactions on Signal Processing, vol. 69, pp. 500–514, 2020.

[37] G. Zhu, Y. Wang, and K. Huang, “Broadband analog aggregation for low-latency federated edge learning,” IEEE

Transactions on Wireless Communications, vol. 19, no. 1, pp. 491–506, Oct. 2019.

[38] K. Yang, T. Jiang, Y. Shi, and Z. Ding, “Federated learning via over-the-air computation,” IEEE Transactions on Wireless

Communications, vol. 19, no. 3, pp. 2022–2035, Jan. 2020.

[39] M. M. Amiri and D. Gündüz, “Machine learning at the wireless edge: Distributed stochastic gradient descent over-the-air,”

IEEE Transactions on Signal Processing, vol. 68, pp. 2155–2169, 2020.

[40] C. Xu, S. Liu, Z. Yang, Y. Huang, and K.-K. Wong, “Learning rate optimization for federated learning exploiting over-

the-air computation,” IEEE Journal on Selected Areas in Communications, vol. 39, no. 12, pp. 3742–3756, 2021.

[41] B. Nazer and M. Gastpar, “Computation over multiple-access channels,” IEEE Transactions on Information Theory, vol. 53,

no. 10, pp. 3498–3516, 2007.

[42] W. Shi, S. Zhou, Z. Niu, M. Jiang, and L. Geng, “Joint device scheduling and resource allocation for latency constrained

wireless federated learning,” IEEE Transactions on Wireless Communications, vol. 20, no. 1, pp. 453–467, 2021.

[43] W. Xia, W. Wen, K.-K. Wong, T. Q. Quek, J. Zhang, and H. Zhu, “Federated-learning-based client scheduling for low-

latency wireless communications,” IEEE Wireless Communications, vol. 28, no. 2, pp. 32–38, 2021.

[44] M. M. Amiri, D. Gündüz, S. R. Kulkarni, and H. V. Poor, “Update aware device scheduling for federated learning at the

wireless edge,” in Proc. IEEE International Symposium on Information Theory (ISIT).

IEEE, 2020, pp. 2598–2603.

[45] M. Chen, H. V. Poor, W. Saad, and S. Cui, “Wireless communications for collaborative federated learning,” IEEE

Communications Magazine, vol. 58, no. 12, pp. 48–54, 2020.

[46] Z. Yang, M. Chen, W. Saad, C. S. Hong, and M. Shikh-Bahaei, “Energy efﬁcient federated learning over wireless

communication networks,” IEEE Transactions on Wireless Communications, vol. 20, no. 3, pp. 1935–1949, 2020.

[47] Z. Wang, J. Qiu, Y. Zhou, Y. Shi, L. Fu, W. Chen, and K. B. Letaief, “Federated learning via intelligent reﬂecting surface,”

IEEE Transactions on Wireless Communications, vol. 21, no. 2, pp. 808–822, Feb. 2022.

46

[48] S. G. Mallat and Z. Zhang, “Matching pursuits with time-frequency dictionaries,” IEEE Transactions on Signal Processing,

vol. 41, no. 12, pp. 3397–3415, 1993.

[49] H. Liu, X. Yuan, and Y.-J. A. Zhang, “Reconﬁgurable intelligent surface enabled federated learning: A uniﬁed

communication-learning design approach,” IEEE Transactions on Wireless Communications, vol. 20, no. 11, pp. 7595–7609,

2021.

[50] M. M. Wadu, S. Samarakoon, and M. Bennis, “Federated learning under channel uncertainty: Joint client scheduling and

resource allocation,” in Proc. IEEE Wireless Communications and Networking Conference (WCNC), 2020, pp. 1–6.

[51] M. Goldenbaum and S. Stanczak, “Robust analog function computation via wireless multiple-access channels,” IEEE

Transactions on Communications, vol. 61, no. 9, pp. 3863–3877, 2013.

[52] M. Goldenbaum, H. Boche, and S. Sta´nczak, “Harnessing interference for analog function computation in wireless sensor

networks,” IEEE Transactions on Signal Processing, vol. 61, no. 20, pp. 4893–4906, 2013.

[53] L. Chen, X. Qin, and G. Wei, “A uniform-forcing transceiver design for over-the-air function computation,” IEEE Wireless

Communications Letters, vol. 7, no. 6, pp. 942–945, 2018.

[54] G. Zhu and K. Huang, “MIMO over-the-air computation for high-mobility multimodal sensing,” IEEE Internet of Things

Journal, vol. 6, no. 4, pp. 6089–6103, 2018.

[55] X. Zhai, X. Chen, J. Xu, and D. W. K. Ng, “Hybrid beamforming for massive MIMO over-the-air computation,” IEEE

Transactions on Communications, vol. 69, no. 4, pp. 2737–2751, 2021.

[56] X. Cao, G. Zhu, J. Xu, Z. Wang, and S. Cui, “Optimized power control design for over-the-air federated edge learning,”

IEEE Journal on Selected Areas in Communications, vol. 40, no. 1, pp. 342–358, 2021.

[57] T. Sery and K. Cohen, “On analog gradient descent learning over multiple access fading channels,” IEEE Transactions on

Signal Processing, vol. 68, pp. 2897–2911, 2020.

[58] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas, “Communication-efﬁcient learning of deep networks

from decentralized data,” in Proc. PMLR Artiﬁcial Intelligence and Statistics. PMLR, 2017, USA, pp. 1273–1282.

[59] J. A. Tropp, A. Yurtsever, M. Udell, and V. Cevher, “Practical sketching algorithms for low-rank matrix approximation,”

SIAM Journal on Matrix Analysis and Applications, vol. 38, no. 4, pp. 1454–1485, 2017.

[60] P. D. Tao and L. T. H. An, “Convex analysis approach to DC programming: theory, algorithms and applications,” Acta

Mathematica Vietnamica, vol. 22, no. 1, pp. 289–355, 1997.

[61] T. H. Le An and P. Dinh Tao, “Solving a class of linearly constrained indeﬁnite quadratic problems by DC algorithms,”

Journal of Global Optimization, vol. 11, no. 3, pp. 253–285, 1997.

[62] S. Foucart and H. Rauhut, A Mathematical Introduction to Compressive Sensing. Springer, 2013.

[63] D. L. Donoho, “Compressed sensing,” IEEE Transactions on Information Theory, vol. 52, no. 4, pp. 1289–1306, Apr.

2006.

[64] E. J. Candès, J. Romberg, and T. Tao, “Robust uncertainty principles: Exact signal reconstruction from highly incomplete

frequency information,” IEEE Transactions on Information Theory, vol. 52, no. 2, pp. 489–509, Jan. 2006.

[65] J. A. Tropp and A. C. Gilbert, “Signal recovery from random measurements via orthogonal matching pursuit,” IEEE

Transactions on Information Theory, vol. 53, no. 12, pp. 4655–4666, Dec. 2007.

[66] L. Rebollo-Neira and D. Lowe, “Optimized orthogonal matching pursuit approach,” IEEE Signal Processing Letters, vol. 9,

no. 4, pp. 137–140, Apr. 2002.

[67] J. Wang, S. Kwon, and B. Shim, “Generalized orthogonal matching pursuit,” IEEE Transactions on Signal Processing,

vol. 60, no. 12, pp. 6202–6216, Sep. 2012.

[68] T. T. Cai and L. Wang, “Orthogonal matching pursuit for sparse signal recovery with noise,” IEEE Transactions on

Information theory, vol. 57, no. 7, pp. 4680–4688, Jun. 2011.

47

[69] D. Needell and J. A. Tropp, “CoSaMP: Iterative signal recovery from incomplete and inaccurate samples,” Applied and

Computational Harmonic Analysis, vol. 26, no. 3, pp. 301–321, 2009.

[70] B. N. Parlett, H. Simon, and L. Stringer, “On estimating the largest eigenvalue with the Lanczos algorithm,” Mathematics

of Computation, vol. 38, no. 157, pp. 153–165, 1982.

[71] H. Schwetlick and U. Schnabel, “Iterative computation of

the smallest singular value and the corresponding

singular vectors of a matrix,” Linear Algebra and its Applications, vol. 371, pp. 1–30, 2003. [Online]. Available:

https://www.sciencedirect.com/science/article/pii/S0024379503004907

[72] Q. Liang and Q. Ye, “Computing singular values of large matrices with an inverse-free preconditioned Krylov subspace

method,” Electronic Transactions on Numerical Analysis, vol. 42, p. 197, 2014.

[73] R. A. Horn and C. R. Johnson, Matrix Analysis, 2nd ed. Cambridge University Press, 2013.

[74] A. Krizhevsky, G. Hinton et al., “Learning multiple layers of features from tiny images,” 2009, technical report, University

of Toronto.

[75] E. Björnson, J. Hoydis, and L. Sanguinetti, “Massive MIMO networks: Spectral, energy, and hardware efﬁciency,”

Foundations and Trends® in Signal Processing, vol. 11, no. 3-4, pp. 154–655, 2017.

[76] Q. Li, Y. Diao, Q. Chen, and B. He, “Federated learning on non-iid data silos: An experimental study,” in Proc. IEEE

38th International Conference on Data Engineering (ICDE), 2022, pp. 965–978.

[77] K. Simonyan and A. Zisserman, “Very deep convolutional networks for large-scale image recognition,” in Proc.

International Conference on Learning Representations (ICLR), 2015, pp. 1–14, preprint at arXiv:1409.1556.

[78]

I. Hwang, B. Song, and S. S. Soliman, “A holistic view on hyper-dense heterogeneous and small cell networks,” IEEE

Communications Magazine, vol. 51, no. 6, pp. 20–27, 2013.

[79] N. Bhushan, J. Li, D. Malladi, R. Gilmore, D. Brenner, A. Damnjanovic, R. T. Sukhavasi, C. Patel, and S. Geirhofer,

“Network densiﬁcation: the dominant theme for wireless evolution into 5G,” IEEE Communications Magazine, vol. 52,

no. 2, pp. 82–89, 2014.

[80] J. G. Andrews, X. Zhang, G. D. Durgin, and A. K. Gupta, “Are we approaching the fundamental limits of wireless network

densiﬁcation?” IEEE Communications Magazine, vol. 54, no. 10, pp. 184–190, 2016.

[81] M. Kamel, W. Hamouda, and A. Youssef, “Ultra-dense networks: A survey,” IEEE Communications Surveys & Tutorials,

vol. 18, no. 4, pp. 2522–2545, May 2016.

[82] M. A. Adedoyin and O. E. Falowo, “Combination of ultra-dense networks and other 5G enabling technologies: A survey,”

IEEE Access, vol. 8, pp. 22 893–22 932, 2020.

[83] S. Kim, J. Son, and B. Shim, “Energy-efﬁcient ultra-dense network using LSTM-based deep neural networks,” IEEE

Transactions on Wireless Communications, vol. 20, no. 7, pp. 4702–4715, 2021.

[84] Q. Wu and R. Zhang, “Towards smart and reconﬁgurable environment: Intelligent reﬂecting surface aided wireless network,”

IEEE Communications Magazine, vol. 58, no. 1, pp. 106–112, 2019.

