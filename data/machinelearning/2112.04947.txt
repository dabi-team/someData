1
2
0
2

c
e
D
0
1

]

R
C
.
s
c
[

2
v
7
4
9
4
0
.
2
1
1
2
:
v
i
X
r
a

Automated Side Channel Analysis of Media Software with Manifold Learning ∗

Yuanyuan Yuan, Qi Pang, Shuai Wang†
The Hong Kong University of Science and Technology
{yyuanaq, qpangaa, shuaiw}@cse.ust.hk

Abstract

The prosperous development of cloud computing and ma-
chine learning as a service has led to the widespread use of
media software to process conﬁdential media data. This paper
explores an adversary’s ability to launch side channel analy-
ses (SCA) against media software to reconstruct conﬁdential
media inputs. Recent advances in representation learning and
perceptual learning inspired us to consider the reconstruction
of media inputs from side channel traces as a cross-modality
manifold learning task that can be addressed in a uniﬁed
manner with an autoencoder framework trained to learn the
mapping between media inputs and side channel observations.
We further enhance the autoencoder with attention to local-
ize the program points that make the primary contribution
to SCA, thus automatically pinpointing information-leakage
points in media software. We also propose a novel and highly
effective defensive technique called perception blinding that
can perturb media inputs with perception masks and mitigate
manifold learning-based SCA.

Our evaluation exploits three popular media software to re-
construct inputs in image, audio, and text formats. We analyze
three common side channels — cache bank, cache line, and
page tables — and userspace-only cache set accesses logged
by standard Prime+Probe. Our framework successfully re-
constructs high-quality conﬁdential inputs from the assessed
media software and automatically pinpoint their vulnerable
program points, many of which are unknown to the public. We
further show that perception blinding can mitigate manifold
learning-based SCA with negligible extra cost.

1 Introduction

Side channel analysis (SCA) infers program secrets by analyz-
ing the target software’s inﬂuence on physical computational
characteristics, such as the execution time, accessed cache
units, and power consumption. Practical SCA attacks have

∗The extended version of the USENIX Security 2022 paper [122].
†Corresponding author.

been launched on real-world crypto systems [74, 116, 121] to
recover crypto keys. With the adoption of cloud computing
and machine learning as a service (MLaaS), media software,
a type of application software used for processing media
ﬁles like images and text, is commonly involved in process-
ing private data uploaded to cloud (e.g., for medical diag-
nosis). Existing works have exploited media software with
extensive manual efforts or reconstruct only certain media
data [45, 117, 123]. However, the community lacks a system-
atic and thorough understanding of SCA attack vectors for
media software and of the ways that private user inputs of
various types (e.g., images or text) can be reconstructed in a
uniﬁed and automated manner. Hence, this is the ﬁrst study
toward media software of various input formats to assess how
their inputs, which represent private user data, can be leaked
via SCA in a fully automatic way.

Recent advances in representation learning and perceptual
learning [15, 125] inspired us to recast SCA of media soft-
ware as a cross-modality manifold learning task in which an
autoencoder [50] is used to learn the mapping between conﬁ-
dential media inputs and the derived side channel traces in an
end-to-end manner. The autoencoder framework can learn a
low-dimensional joint manifold of media data and side chan-
nel observations to capture a highly expressive representation
that is generally immune to noise.

Our proposed autoencoder framework is highly ﬂexible. It
converts side channel traces into latent representations with
an encoder module φθ, and the media data in image, audio
and text formats can be reconstructed by assembling decoders
ψθ that correspond to various media data formats to φθ. Fur-
thermore, by enhancing encoder φθ with attention [114], the
autoencoder framework can automatically localize program
points that make primary contributions to the reconstruction
of media inputs. That is, the attention mechanism delivers a
“bug detector” to locate program points at which information
can leak.

Further, the observation that manifold learning captures key
perceptions of high-dimensional data in a low-dimensional
space [125] inspired us to propose the use of perception

1

 
 
 
 
 
 
blinding to mitigate manifold learning–based SCA. Well-
designed perception blinding “dominates” the projected low-
dimensional perceptions and thus conﬁnes adversaries to only
generate media data perceptually bounded to the mask. In
contrast, media software that is typically used to process data
bytes of media data experiences no extra difﬁculty in process-
ing the blinded data and recovering the original outputs.

Our evaluation exploits media software,

including
libjpeg [69], FFmpeg [1], and Hunspell [2], widely used
to process media data in image, audio, and text formats. We
assess these media software with regard to a common threat
model in which trace-based attackers [20, 36, 54, 105] can log
a trace of CPU cache banks, cache lines, or OS page-table en-
tries accessed during the execution of media software. More-
over, we also launch standard Prime+Probe attack [102] in
userspace-only scenarios and use the logged cache side chan-
nels to reconstruct media data. We conduct qualitative and
quantitative evaluations of six datasets that represent daily
media data whose user privacy can be violated if leaked to
adversaries. Our ﬁndings show that user inputs can be recon-
structed automatically and that the recovered media content,
such as images or text, shows considerable (visual) similar-
ity to user inputs. The attention modules facilitate localizing
program points that incur input leakage; some have been
disclosed before [45, 117, 123], but many, to the best of our
knowledge, were previously unknown. Further, we ﬁnd that
perception blinding is highly effective in mitigation of man-
ifold learning–based SCA. We also demonstrate the noise
resiliency of our attack, and how oblivious RAM [42, 97] can
mitigate our attack, though it incurs high cost and becomes
impractical in real-life usage. In summary, this thorough study
makes the following contributions:

• Advances in cross-modality manifold learning inspired
us to advocate SCA of media software as a supervised
task that learns a joint manifold of media data and side
channel traces. High-quality media data can be recon-
structed from side channel traces in a noise-resilient
manner without knowledge of the underlying media soft-
ware implementation or media data formats.

• We enhance autoencoder with attention to localize pro-
gram points that make notable contributions to infor-
mation leakage. Furthermore, we design a low-cost
perception-blinding technique that effectively mitigates
the proposed SCA exploitation.

• Our evaluation subsumes widely used media software
used to process images, audio, and text. We demonstrate
that high-quality user inputs in various formats can be re-
constructed and that perception blinding predominantly
impedes our SCA. Our attention-based error-localization
technique conﬁrms some program points that have been
reported as vulnerable and ﬂags many previously un-
known problems in media software.

To facilitate result veriﬁcation and future research, we re-

leased all code and data generated in this research at [3].

2 Background

◦

I.

∈

∈

∈

→

→

P)−

1 : O

I can be modeled as P : I

We introduce the high-level procedure of launching SCA in
which program inputs are assumed conﬁdential. Let a deter-
ministic and terminating program be P. Executing an input
R, where R denotes the pro-
i
→
gram behavior during the runtime. Although modern com-
puter architectures prohibit attackers from directly recording
R and inferring input i
I, attackers can leverage various
side channels, which map the runtime behavior of R into an
adversarial observation O of certain properties (e.g., cache
status) in the execution context of P. The attacker’s view can
be represented as view : R
O, where given side channel ob-
servation O, the attackers leverage composite inverse function
(view

I to map O back to input i
Promising progress has been made by logging (high-
resolution) side channels such as accessed cache line, cache
bank, or page table entries in an automated manner [29, 45,
74, 116, 117]. Nevertheless, reconstruction of i from logged
side channels requires attackers to infer the composite inverse
function (view
I. Recovery of such mappings re-
quires an in-depth understanding of how program secrets are
propagated (i.e., secret information ﬂow), which could require
considerable manual efforts [45, 117] or conducting formal
analysis [19, 36, 105]. Note that high-resolution side channels
(e.g., cache line access) usually contain millions of records,
but only a tiny portion o∗ is indeed input-dependent [104].
SCA on Media Software. Despite the widespread adoption
of MLaaS to process users’ private data, the SCA of media
software has not been thoroughly examined. For instance,
media software is commonly used to process X-ray images
because it allows cost-efﬁcient disease diagnosis with cloud
resources. However, the leakage of such images on the cloud
(e.g., via cache-based side channels [73]) involves a high risk
of violating patient privacy. An immense demand exists to
gain insights into the extent of privacy problems in media
software, given its pervasive use in processing private data.
Therefore, we examine real-world media software used to
process media data such as photos and daily conversations.

1 : O

P)−

→

◦

Threat Model and Attack Scenarios. This study recon-
structs conﬁdential inputs of media software from side chan-
nels. We thus reasonably assume that different inputs of tar-
geted media software can induce distinguishable memory
access traces. Otherwise, no information regarding inputs
would be leaked.

Proﬁled SCA [23, 47–49, 54, 77] commonly assumes that
side channel logs have been prepared for training and data
reconstruction. For our scenario, we generally assume a stan-
dard trace-based attacker. We assume that a trace of system
side channel accesses made by the victim software has been

2

prepared for use. Our evaluated system side channels include
cache line, cache bank, and page table entries. The feasibility
of logging such ﬁne-grained information has been demon-
strated in real-world scenarios [34, 45, 117, 121], and this
assumption has been consistently made by many previous
works [20, 37, 53, 104, 105, 113]. In this study, we use Intel
Pin [76] to log memory access traces and convert them into
corresponding side channel traces (see Sec. 5).

We also benchmark userspace-only scenarios where attack-
ers can launch Prime+Probe attack [102] to log cache activ-
ities when media software is processing a secret input. We
use Mastik [119], a micro-architectural side channel toolkit,
to launch “out-of-the-box” Prime+Probe and log victim’s
L1I and L1D cache activities. We pin victim process and spy
process on the same CPU core; see attack details in Sec. 6.4.
Exploiting new side channels is not our focus. We demon-
strate our attack over commonly-used side channels. This way,
our attack is shown as practically approachable, indicating
its high impact and threats under real-world scenarios. Un-
like previous SCA on media software [45, 117] or on crypto
libraries [124], we do not require a “white-box” view (i.e.,
source code) of victim software. We automatically analyze
media software executables with different input types. As
will be discussed in Sec. 6, we launch manifold learning to
reconstruct media data with excellent (visual) similarity to
user inputs. Many studies have only ﬂagged program points of
information leakage with (unscalable) abstract interpretation
or symbolic execution [20, 36, 105]. Direct reconstruction of
media data is beyond the scope of such formal method-based
techniques, and these studies did not propose SCA mitigation.

3 A Manifold View on SCA of Media Software

This study recasts the SCA of media software as a cross-
modality manifold learning task that can be well addressed
with supervised learning. We train an autoencoder [50] that
maps side channel observations O to the media inputs I of me-
dia software. Our threat model (Sec. 2) assumes that attackers
can proﬁle the target media software and collect side channel
traces derived from many inputs. Therefore, our autoencoder
framework is trained to learn from historical data and im-
plicitly forms a low-dimensional joint manifold between the
side channel logs and media inputs. We ﬁrst introduce the
concept of manifold, which will help to clarify critical design
decisions of our framework (see Sec. 4).

Manifold Learning. The use of manifold underlies the fea-
sibility of dimensionality reduction [65]. The key premise of
manifold is the manifold hypothesis, which states that real-
world data in high-dimensional space are concentrated near a
low-dimensional manifold [39]. That is, real-world data often
of much lower dimensionality d, which
lie in a manifold
is embedded in its high-dimensional space
of dimension-
D). Manifold learning aims to ﬁnd a projection
ality D (d

M

R

(cid:28)

∈ M
.
R

R → M

that converts data x

f :
coordinate system of
M
representation x in the high-dimensional space

∈ R
1 projects f (x)

.1 f −

into y in an intrinsic
back onto

M

PCA [7] is a linear manifold learning algorithm that aims
by extracting “principal components” of data
to ﬁnd
points [15]. However, most real-world manifolds are non-
linear, and manifold learning algorithms (e.g., ISOMAP) are
proposed to project data x onto nonlinear

[12].

M

∈ R

Manifold learning views high-dimensional media data
x
as a composite of perceptually meaningful contents
that are shown as robust to noise or other input perturba-
tions [40, 125, 126]. Manifold learning algorithms extract ex-
pressive representations of high-dimensional data such as im-
ages, audio, and text [25, 46], which explains why AI models
can make accurate predictions pertaining to high-dimensional
data [15]. It is shown that data of the same class (e.g., face
photos) generally lie in the same manifold, whereas data of
different classes (face vs. vehicle photos) are concentrated
on separate manifolds in low-dimensional space [100]. man-
ifold learning clariﬁes the inherent difﬁculty of designing
universal encoding and generative models applicable to high-
dimensional data from different manifolds. The manifold
hypothesis has been veriﬁed theoretically and empirically in
a comprehensive manner [40, 125, 126]. Appx. A presents our
exploration on the validity of manifold hypothesis.

onto

Parametric Manifold. Most manifold learning schemes
adopt non-parametric approaches. Despite the simplicity, non-
parametric approaches cannot be used to project new data
points in
. Recent advances in deep neural net-
works, particularly autoencoders, have enabled a paramet-
ric nonlinear manifold projection fθ :
[125]. Mani-
fold learning can thus process unknown data points of high-
dimensional media data [15, 41, 51, 67, 125, 126] and facilitate
downstream tasks like face recognition [39].

R → M

M

R

Figure 1: Mapping between side channels and images via a
low-dimensional joint manifold

.

=

MI

,
O

I × O

1“Intrinsic coordinate” denotes the coordinate system of the low-
dimensional manifold space for each high-dimensional data sample [32, 70].

3

SidechanneldomainImagedomain<latexit sha1_base64="ykdvCVRmGh8YoWvBQy20gGU5rrE=">AAAB+HicbVDLSsNAFL3xWeujUZduBovgqiSi6LLoxp0V7APaECbTSTt0MgkzE6GGfIkbF4q49VPc+TdO2iy09cDA4Zx7uWdOkHCmtON8Wyura+sbm5Wt6vbO7l7N3j/oqDiVhLZJzGPZC7CinAna1kxz2kskxVHAaTeY3BR+95FKxWLxoKcJ9SI8EixkBGsj+XYt9LNBhPWYYJ7d5blv152GMwNaJm5J6lCi5dtfg2FM0ogKTThWqu86ifYyLDUjnObVQapogskEj2jfUIEjqrxsFjxHJ0YZojCW5gmNZurvjQxHSk2jwEwWGdWiV4j/ef1Uh1dexkSSairI/FCYcqRjVLSAhkxSovnUEEwkM1kRGWOJiTZdVU0J7uKXl0nnrOFeNJz783rzuqyjAkdwDKfgwiU04RZa0AYCKTzDK7xZT9aL9W59zEdXrHLnEP7A+vwBSd+Tfw==</latexit>fO<latexit sha1_base64="jS9JgzDjTqe+wa75JcQXRSE+7lo=">AAAB6HicbVBNS8NAEJ34WetX1aOXxSJ4Kokoeix68diC/YA2lM120q7dbMLuRqihv8CLB0W8+pO8+W/ctjlo64OBx3szzMwLEsG1cd1vZ2V1bX1js7BV3N7Z3dsvHRw2dZwqhg0Wi1i1A6pRcIkNw43AdqKQRoHAVjC6nfqtR1Sax/LejBP0IzqQPOSMGivVn3qlsltxZyDLxMtJGXLUeqWvbj9maYTSMEG17nhuYvyMKsOZwEmxm2pMKBvRAXYslTRC7WezQyfk1Cp9EsbKljRkpv6eyGik9TgKbGdEzVAvelPxP6+TmvDaz7hMUoOSzReFqSAmJtOvSZ8rZEaMLaFMcXsrYUOqKDM2m6INwVt8eZk0zyveZcWtX5SrN3kcBTiGEzgDD66gCndQgwYwQHiGV3hzHpwX5935mLeuOPnMEfyB8/kD6pONAg==</latexit>z<latexit sha1_base64="qmqxvw54qUUoUaz9MnxwYmJpOwM=">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0WPRi8cW7Ae0oWy2k3btZhN2N0IJ/QVePCji1Z/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4bua3n1BpHssHM0nQj+hQ8pAzaqzUGPbLFbfqzkFWiZeTCuSo98tfvUHM0gilYYJq3fXcxPgZVYYzgdNSL9WYUDamQ+xaKmmE2s/mh07JmVUGJIyVLWnIXP09kdFI60kU2M6ImpFe9mbif143NeGNn3GZpAYlWywKU0FMTGZfkwFXyIyYWEKZ4vZWwkZUUWZsNiUbgrf88ippXVS9q6rbuKzUbvM4inACp3AOHlxDDe6hDk1ggPAMr/DmPDovzrvzsWgtOPnMMfyB8/kDzceM7w==</latexit>g<latexit sha1_base64="cBNxOmE9EBdCaT4cWzAH6E6iQDA=">AAAB63icbVBNSwMxEJ2tX7V+VT16CRahXsquVPRY9OKxgv2AdinZNNuGJtklyQp16V/w4kERr/4hb/4bs+0etPXBwOO9GWbmBTFn2rjut1NYW9/Y3Cpul3Z29/YPyodHbR0litAWiXikugHWlDNJW4YZTruxolgEnHaCyW3mdx6p0iySD2YaU1/gkWQhI9hk0qj6dD4oV9yaOwdaJV5OKpCjOSh/9YcRSQSVhnCsdc9zY+OnWBlGOJ2V+ommMSYTPKI9SyUWVPvp/NYZOrPKEIWRsiUNmqu/J1IstJ6KwHYKbMZ62cvE/7xeYsJrP2UyTgyVZLEoTDgyEcoeR0OmKDF8agkmitlbERljhYmx8ZRsCN7yy6ukfVHzLmvufb3SuMnjKMIJnEIVPLiCBtxBE1pAYAzP8ApvjnBenHfnY9FacPKZY/gD5/MHckKN2A==</latexit>g(z)<latexit sha1_base64="FE1kQfFWyXFtVLM077UfmUU/BP0=">AAAB/XicbVDLSsNAFL2pr1pf8bFzEyyCG0siii6LbnRXwT6gjWEynbRDJ5MwMxFqCP6KGxeKuPU/3Pk3TtostPXAwOGce7lnjh8zKpVtfxulhcWl5ZXyamVtfWNzy9zeackoEZg0ccQi0fGRJIxy0lRUMdKJBUGhz0jbH13lfvuBCEkjfqfGMXFDNOA0oBgpLXnmXnCfHjuZl/ZCpIYYsfQmyzyzatfsCax54hSkCgUanvnV60c4CQlXmCEpu44dKzdFQlHMSFbpJZLECI/QgHQ15Sgk0k0n6TPrUCt9K4iEflxZE/X3RopCKcehryfzjHLWy8X/vG6iggs3pTxOFOF4eihImKUiK6/C6lNBsGJjTRAWVGe18BAJhJUurKJLcGa/PE9aJzXnrGbfnlbrl0UdZdiHAzgCB86hDtfQgCZgeIRneIU348l4Md6Nj+loySh2duEPjM8frLGVXw==</latexit>f 1IFigure 2: Reconstructing media data of different types with a uniﬁed autoencoder framework.

High-Level Research Overview

Processing media data has an observable inﬂuence on the
underlying computing environment; it thus induces side chan-
nel traces that can be logged by attackers to infer private in-
puts. Previous SCA studies, from a holistic view, attempted to
(manually) map side channel logs to data bytes in media data
(similar to how media software treats media data) [45, 117];
reconstruction of media data in a per-pixel manner is thus
error-prone and likely requires expertise and manual efforts.
The success of manifold learning in tasks like image edit-
ing and cross-modality reconstruction [125, 126] led us to
construct a joint, perception-level connection between side
channel logs and high-dimensional media inputs.2 Therefore,
instead of deciding value of each byte, reconstructing media
data is recast into exploring the manifold of media data that
satisﬁes the perception-level combinatory constraints.

Overall, we view SCA as a cross-modality high-
dimensional data reconstruction task that is addressed with
joint manifold learning in this work [125]. Aligned with the
notations in Sec. 2, let the media software inputs be I; the
I can be
attacker’s observation on executing each input i
represented as (view
O denotes the
P) : I
→
observation of side channel traces. Let F be the composite
P. According to the manifold hypothesis, we
function view
assume that I and O also lie in the unknown manifolds
and
, respectively. As mentioned in our threat model (Sec. 2), we
O
assume that side channel observations depend on the inputs
of media software; therefore, the entire joint dataset

O, where o

∈

∈

I

◦

◦

ii, oi
{

}

2Perception-level connection means constraints on data bytes formed by
perceptual contents (e.g., gender, hair style) in media data are extracted from
side channels.

4

formed by the ith media input ii
observation oi

O lies in a joint manifold

∈

I and the corresponding ith

∈

{

I

=

O

,
O

,
O

∈ I

and

MI

MI

∈ O}

, F(i)

, the data points in

i
(i, F(i))
|
where (i, F(i)) is described with the regular high-dimensional
coordinate system. Since I and O also lie in the correspond-
ing manifolds
should
be equivalently described using an intrinsic coordinate sys-
tem (z, g(z)). Hence, we assume the existence of a homo-
morphic mapping ( f
(o)
F −
and g(z) = f
maps side channel observation
maps high-
O
dimensional media data I onto g(z). Note that g denotes the
diffeomorphism (i.e., an isomorphism of two manifolds) be-
manifolds [125]. Hence, instead of com-
tween the
puting F −
I to map the side channel
observation back onto the media inputs, we leverage the joint
manifold to constitute the following composite function:

onto the intrinsic coordinate z, whereas f

) over (z, g(z)) such that z = f

and
I
O
1 = (view

, f
I
O
1(o). f

1 : O

P)−

I ◦

→

◦

O

O

I

F −

1
1(o) = f −
I ◦

g

◦

(o)

f

O

(1)

i

∈

I can thus be reconstructed using the inverse composite
1
function f −
. Fig. 1
over the joint manifold
I ◦
provides a summary and presents a schematic view of how I
and O of high-dimensional data are mapped via

MI

,
O

g

◦

O

f

.

The feasibility of using neural networks, especially autoen-
coders, to facilitate parametric manifold learning has been
discussed [51, 78, 125, 126]. Accordingly, we train an autoen-
coder by encoding side channel traces O onto the latent space
with encoder φθ and by generating media data I with decoder
ψθ from the latent space. Therefore, Eq. 1 can be learned in
an end-to-end manner [15, 125]. Holistically, φθ and ψθ cor-

MI

,
O

HWCC ×1 ×11 ×H ×WF0F2F0F1F1F2LatentRepresentationDecoderEncoder<SOS>Word1Word2<EOS>ReconstructedMediaDataMetricMediaSoftwareSideChannelLoggedMediaInputOutputImplicit(Discriminator)Explicit(MSELoss)...real/fake?privacy1preserved?privacynpreserved?MediaInput=Minimize DistanceMaximize Similarity+CrossEntropy=ordiscretecontinuous(a) Attention Enhanced Encoder(b) Discrete/Continuous Decoder(c) Discriminator & Privacy IndicatorsChannel-AttentionSpatial-AttentionConv2D BlockIntermediateoutputdiscretecontinuousor1
respond to f
and f −
I
constructed in the encoded latent space.

O

, respectively, whereas g is implicitly

4 Framework Design

We describe the design of our autoencoder in Sec. 4.1. Sec. 4.2
clariﬁes the usage of attention to localize code fragments
inducing information leakage. Sec. 4.3 introduces perception
blinding to mitigate our SCA.

4.1 SCA with Autoencoder

We propose a general and highly-ﬂexible design in which an
autoencoder is used to facilitate SCA of various media data,
including images, audio and text. The autoencoder frame-
work [50] deﬁnes a parametric feature-extracting function fθ,
named encoder, that enables the projection of the input x onto
a latent vector h = φθ(x). Similarly, autoencoder frameworks
also use ψθ as a decoder that reconstructs input ˆx from a
latent vector ˆx = ψθ(h). A well-trained autoencoder frame-
work gradually identiﬁes a parameter vector θ to minimize
the reconstruction error as follows:

L(θ) = ∑
t

L(xt , ψθ

φθ(xt ))

◦

where xt is a training sample. Minimal errors can be found
with statistical methods like stochastic gradient descent.

∈

θ, ψt

θ, ψa

The ﬁrst row of Fig. 2 depicts the workﬂow. We clarify
that our focus is not to propose novel model architectures;
rather, we show that high-quality inputs can be synthesized
by assembling standard models, which indicates severity and
effectiveness of our attack. We now discuss the high-level
workﬂow and present the model structures and training details
O, encoder
in Sec. 5.1. Given a logged side channel trace o
φθ(o) converts o into the corresponding latent representation.
We prepare three decoders ψi
θ to reconstruct these
types of media data (i.e., image, audio, and text) from the
encoded latent representation. We pair encoder φθ(o) with
each ψ∗θ and train the assembled pipeline for our customized
objective functions L(θ). Our proposed framework is task-
agnostic. Generating media data of various types requires only
assembling corresponding decoders to the uniﬁed encoder φθ.
Encoder φθ. A logged side channel trace will ﬁrst be folded
into a K
N matrix (see Table 3 for the detailed conﬁg-
uration of each trace). We then feed this matrix as the input
of encoder φθ. The encoder φθ comprises several stacked 2D
convolutional neural networks (CNNs). For the current im-
plementation, φθ converts the high-dimensional inputs into
latent vectors of 128 dimensions, given that the dimensions
of our media inputs are all over 10K. See Appx. F for clari-
ﬁcation on how side channels, including both Intel Pin- and
Prime+Probe-logged records, are represented and processed
by φθ. Moreover, we ﬁnd that increasing the dimension of

×

×

N

latent vectors (i.e., from 128 to 256) does not make an ob-
servable improvement. This observation is consistent with the
manifold hypothesis [65], such that only limited “perceptions”
exist in normal media data. In contrast, reducing the number
of dimensions (e.g., 32) makes the outputs (visually) much
worse. However, users who strive to recover media data of
lower-dimensions can conﬁgure our framework with smaller
latent vectors (e.g., 32 dimensions).

Fig. 2(a) shows that we enhance encoder φθ with attention.
Indeed, we insert one attention module between every two
stacked CNN layers in the encoder. Attention generally im-
proves output quality of autoencoder [103]. More importantly,
attention facilitates localizing program points of information
leakage. We elaborate on Fig. 2(a) in Sec. 4.2.
Decoder ψ∗θ. We categorize the media data exploited by this
study into two types: continuous and discrete. Image and au-
dio data are represented as a continuous ﬂoating-point matrix
and reconstructed by ψi
θ in a continuous manner. In
contrast, textual data comprise word sequences, and because
there is no “intermediate word,” textual data are regarded as
sequences of discrete values and handled by ψt
θ.

θ and ψa

As shown in Fig. 2(b), we use a common approach to
stacking 2D CNNs to design ψi
θ. A 2D CNN has several
convolutional kernels; each kernel focuses on one feature
dimension of its input and captures the spatial information
of this feature dimension. Images can thus be reconstructed
from vectors in the low-dimensional latent space with stacked
2D CNNs, as each 2D CNN upsamples from the output of
the previous layer. For audio data, we ﬁrst convert raw audio
into the log-amplitude of Mel spectrum (LMS), a common
2D representation of audio data. As will be shown in Fig. 20,
audio data are represented as 2D images, in which the x-axis
denotes time and the y-axis denotes the log scale of ampli-
tudes at different frequencies. Herein, like ψi
θ uses stacked
2D CNNs to process each converted 2D image, gradually up-
samples from the latent representation, and reconstruct the
LMSs of the audio data. Because the LMSs usually are not in
square-shape, we append a fully connected layer to transform
the shape of the reconstructed LMSs. These LMSs are then
converted to raw audio losslessly.

θ, ψa

Textual data, however, are reconstructed sequentially “word
by word” due to their discrete nature. As shown in Fig. 2(b),
to reconstruct a sentence from the latent space of a side chan-
nel trace o, a single word is gradually inferred based on words
already inferred from sentence i. Following a common prac-
tice of training sequence-to-sequence autoencoders, we add
a start-of-sequence (SOS) token before each sentence i and
an end-of-sequence (EOS) token after i. Then, given a side
channel trace o that corresponds to unknown text i, the trained
decoder ψt
θ starts from the SOS token and predicts a word
i sequentially until it yields the EOS token. From a holis-
w
tic perspective, the trained model projects a sentence i into a
low-dimensional manifold space of word dependency, which
facilitates the gradual inference of each word w on i.

∈

5

Table 1: Privacy-aware indicators. Table 3 introduces each
dataset.

Dataset
CelebA
ChestX-ray
SC09
Sub-URMP

Indicator
Is the celebrity’s identity preserved?
Is the disease information preserved?
Is the speaker’s identity preserved?
Is the musical instrument’s type preserved?

Designing Objective Functions. As depicted in the ﬁrst row
of Fig. 2, for discrete data (i.e., text), each decode step is a
multi-class classiﬁcation task where the output is classiﬁed as
one element in a pre-deﬁned dictionary. Thus, we use cross
entropy as the training objective. For continuous data, we
design the training objective Lθ composing both explicit and
implicit metrics. We now introduce each component in detail.

Explicit Metrics A common practice in training an autoen-
coder is to explicitly assess the point-wise distance between
the reconstructed media input i(cid:48) and reference input i with
metrics such as MSE loss, L1 loss, and KL divergence [28,60].
The autoencoder will be guided to gradually minimize the
φθ(o)) during training. Never-
point-wise distance Lθ(i, ψθ
◦
theless, a major drawback of such explicit metrics is that the
loss of each data point is calculated independently and con-
tributes equally to update θ and minimize Lθ. Our preliminary
study (see Fig. 25 in Appx. G) shows that such explicit metrics
suffer from “over-smoothing” [90], a well-known problem
that leads to quality degradation of the reconstructed data.

Implicit Metrics Another popular approach is to assess the
“distributed similarity” [90] of reconstructed i(cid:48) and reference
input i. Viewing the general difﬁculty of extracting the distri-
bution of arbitrary media data, a common practice is to lever-
age a neural discriminator D. Discriminator D and decoder
ψθ play a zero-sum game, in which D aims to distinguish the
reconstructed input i(cid:48) from normal media data i. In contrast,
decoder ψθ tries to make its output i(cid:48) indistinguishable with
i to fool D. Although this paradigm generally alleviates the
obstacle of “over-smoothing” [90], it creates the new chal-
lenge of mode collapse; that is, ψθ generates realistic (albeit
very limited) i(cid:48) from any inference inputs. From a holistic
perspective, the use of a discriminator mainly ensures that the
reconstructed i(cid:48) is near i from a distribution perspective; no
guarantee is provided from the view of a single data point.

Privacy-Aware Indicators In addition to the two standard ob-
jective functions mentioned above, we further take into ac-
count a set of privacy-aware indicators. As shown in Fig. 2(c),
we extend discriminator D such that it checks whether the
reconstructed outputs preserve the “privacy” in an explicit
manner. Table 1 lists the privacy indicators used in our frame-
work, which correspond to exploited media data of different
types. For instance, for face photos (CelebA), we specify
checking the identity. Hence, the enhanced discriminator D
serves as a classiﬁer to check whether the identity of the per-
son is preserved, which thus forces decoder ψθ to decode

the identity information in the zero-sum game. A speciﬁc
fully connected layer is appended to the discriminator D in
accordance with each privacy indicator.

with

Generative

Comparison
Model-Based
SCA [123]. One contemporary study [123] uses gen-
erative models (e.g., GANs [44]) to conduct SCA towards
image libraries by capturing image distribution from side
channels. Nevertheless, their work is particularly designed
to recover images instead of proposing a general and
ﬂexible framework to exploit media software of various
input types. In addition, we explicitly use privacy indicators
when designing objective functions, while [123] focuses on
polishing the visual appearance of the reconstructed images.

Figure 3: Denoising corrupted data during manifold learning.

Noisy Side Channel. Reconstructing media data from noisy
side channels is of particular importance, because adversaries
often face considerable noise in real-world attack scenarios.
Manifold learning features denoising by design, the schematic
view of which is presented in Fig. 3. Overall, manifold learn-
ing forces side channel traces O to concentrate near the
, where a corrupted high-
learned low-dimensional manifold
dimensional data point ˜o (
in Fig. 3) should typically remain
•
orthogonal to the manifold
[15]. Thus, when the decoder
ψθ learns to reconstruct media data i
I from the representa-
tions lying on the joint manifold, corrupted ˜o can be ﬁxed by
ﬁrst being projected onto the ∆ in the manifold for denoising;
and i can then be reconstructed from the ∆ [51].

O

O

∈

4.2 Fault Localization with Neural Attention

Some studies have detected software vulnerabilities that lead
to side channel attacks [19, 36, 104, 105]. However, we note
that such studies typically use heavyweight program-analysis
techniques, such as abstract interpretation, symbolic execu-
tion, and constraint solving. Thus, performing scalable pro-
gram analysis of real-world media software could prove a
great challenge, given that such media software usually con-
tains complex program structures (e.g., nested loops) and a
large code base. Furthermore, the primary focus of previous
studies has been crypto libraries (e.g., OpenSSL [82]), whose
“sensitive data” are private key bytes or random numbers. In
contrast, modeling potentially lengthy media data with various
strictly deﬁned formats could impose a further challenge (e.g.,
symbolizing such complex input formats) that may require
the incorporation of domain-speciﬁc knowledge.

6

high-dimensionaldataclosetomanifoldcorrupteddatacleandata<latexit sha1_base64="KqQqnuXiz3QQK1ahNaelJfbo3xw=">AAAB8nicbVBNS8NAFHypX7V+VT16WSyCp5KIoseiF29WsLaQhrLZbtulm03YfRFK6M/w4kERr/4ab/4bN20O2jqwMMy8x86bMJHCoOt+O6WV1bX1jfJmZWt7Z3evun/waOJUM95isYx1J6SGS6F4CwVK3kk0p1EoeTsc3+R++4lrI2L1gJOEBxEdKjEQjKKV/G5EccSozO6mvWrNrbszkGXiFaQGBZq96le3H7M04gqZpMb4nptgkFGNgkk+rXRTwxPKxnTIfUsVjbgJslnkKTmxSp8MYm2fQjJTf29kNDJmEoV2Mo9oFr1c/M/zUxxcBZlQSYpcsflHg1QSjEl+P+kLzRnKiSWUaWGzEjaimjK0LVVsCd7iycvk8azuXdTd+/Na47qoowxHcAyn4MElNOAWmtACBjE8wyu8Oei8OO/Ox3y05BQ7h/AHzucPhuaRaQ==</latexit>OInspired by advances in program neural smoothing [94, 95]
and SCA based on neural networks [54, 85, 118, 123], we
seek to overcome question “which program point leaks side
channel information” by answering the following question:

“Which records on a logged side channel trace con-
tribute most to the reconstruction of media data?”3

Although answering the former question often requires rig-
orous and unscalable static analysis, the second question can
be addressed smoothly by extending the encoder φθ with at-
tention [114], a well-established mechanism that improves the
representation of interest by telling the neural network where
and upon what to focus. In particular, by enhancing the au-
toencoder with attention, our framework automatically ﬂags
side channel logs that make a primary contribution to input
reconstruction. These logs are automatically mapped to the
corresponding memory access instructions. We can then man-
ually identify the corresponding “buggy” source code. For the
last step, our current experiments rely on symbol information
in the assembly programs to ﬁrst identify corresponding func-
tions in source code, and then narrow down to code fragments
inducing input leakage.

Despite attention being a standard mechanism to boost deep
learning models [103, 114], attention in our new scenario acts
like a “bug detector” to principally ease localizing vulner-
able program points. In contrast to program analysis-based
approaches [19, 36, 104, 105], our solution is highly scalable
and incurs no extra cost during exploitation. Moreover, it ana-
lyzes software in a black-box setting that is agnostic to media
software implementation details or input formats.

fault-localization, mitigation is also agnostic to particular me-
dia software and input types. We only need perturb the media
input I with pre-deﬁned perception blinding masks.

We ﬁrst introduce blinding images of the human face, and
then explain how to extend perception blinding toward other
input types. Appx. B presents the workﬂow of perception
blinding in real systems and discusses application scope.

A Working Example. As introduced in Sec. 2, manifold
learning casts images of the human face into a set of per-
ceptually meaningful representations; typical representations
include hair style, age, and skin color. Hence, we deﬁne a
universal mask imask of human face, such that by perturbing
arbitrary images i of human face with imask, the produced out-
put iblinded will be primarily projected to the same intrinsic
coordinates zmask in the manifold space
. To use perception
blinding, users only need to pick one mask imask to blind all
input images i. Consequently, adversaries are restricted to
the generation of media data perceptually correlated to zmask.
Particularly, to perturb i, we add imask as follows:

M

iblinded = α

i

×

⊕

β

×

imask

(cid:29)

where we require β
α and α + β = 1. Perceptual contents
of imask thus “dominates” the projected low-dimensional per-
. Let P(iblinded) be the output of media software
ceptions in
after processing iblinded, and the user can recover the desired
output by subtracting P(imask) from the output as follows:

M

P(iprivate) =

1
α ×

(P(iblinded)

β

(cid:9)

×

P(imask))

H

×

×

Fig. 2(a) depicts the enhanced trace encoder with attention.
An attention module (we follow the design in [114] given its
simplicity and efﬁciency) is inserted within every two stacked
CNN layers. Let the intermediate input of a CNN layer as
W , the “Channel-Attention” module Achannel pro-
C
W data points from C chan-
H
cesses each segment of 1
×
nels and tells the encoder “where” to focus on by assigning
different weights to each segment. The “Spatial-Attention”
module Aspatial processes each segment of C
1 records
and advises the encoder “what to locate” by assigning dif-
ferent weight on each record. From a holistic perspective,
attention module Achannel projects a coarse-grained focus on
potentially interesting segments, while Aspatial further identi-
ﬁes interesting side channel records in a segment.4

×

×

×

1

4.3 Mitigation with Perception Blinding

This section presents mitigation against manifold learn-
ing–enabled SCA (Sec. 4.1). Consistent with our attack and

3See Appx. F for trace representation.
4It

is well accepted that a CNN is organized in the form of
height. Therefore, we name two attention com-

num_channels
ponents as Achannel and Aspatial , which are aligned with the convention.

width

×

×

⊕

(cid:9)

and

directly operate i

where P(iprivate) is the desired output, and P(imask) can be pre-
I of various formats,
computed.
as will be deﬁned later in this section. Because typical opera-
tions of media software (e.g., compression) are independent
of the perceptual meaning of media inputs, the proposed blind-
ing scheme introduces no extra hurdle for media software.
In contrast, as shown in Sec. 6.3, SCA based on manifold
learning can be mitigated in a highly effective manner.

∈

Requirement of imask. Comparable to how RSA blinding
is used to mitigate timing channels [21], perception blind-
ing is speciﬁcally designed to mitigate manifold learning-
based SCA. We require that imask must lie in the same low-
dimensional manifold with the private data. Thus, imask must
manifest high perception correlation with media software
inputs iprivate
I. This shall generally ensure two properties:
1) the privacy (in terms of certain perceptions, such as gen-
der and skin color) in iprivate can be successfully “covered”
by imask, and 2) imask imposes nearly no information loss
on recovering P(iprivate) from P(iblinded) except a mild com-
putational cost due to mask operations. Considering Fig. 3,
when violating this requirement of perception correlation, for
instance, such as by using random noise to craft imask, the
intrinsic coordinate of the original input (∆) can likely drift to

∈

7

Table 2: Side channels derived from a memory access made by victim media software using address addr.

Side Channel Name
CPU Cache Bank Index [121]
CPU Cache Line Index
OS Page Table Index [45, 120]

Side Channel Record Calculation
addr
(cid:29)
addr
(cid:29)
addr & (

L where L, denoting cache bank size, is usually 2 on modern computer architectures.
L where L, denoting cache line size, is usually 6 on modern computer architectures.

M) where M, denoting PAGE_MASK, is usually 4095 on modern computer architectures.

∼

Table 3: Statistics of side channel traces and media software. There is no overlapping between training and testing data.
Media Software
libjpeg (ver. 2.0.6)
LOC: 103,273
ffmpeg (ver. 4.3)
LOC: 1,236,079
hunspell (vers. 1.7.0)
LOC: 39,096

Information
Large-scale celebrity face photos
Hospital-scale chest X-ray images
Human voice of saying number 0–9
Sound clips of 13 instruments
Image captions
Sentences of daily chats

Dataset
CelebA [75]
ChestX-ray [106]
SC09 [111]
Sub-URMP [66]
COCO [71]
DailyDialog [68]

338, 123
329, 155
1, 835, 067
1, 678, 485
77, 796
77, 799

14, 264
10, 186
103, 328
36, 122
14
102

19,962
25,596
2,552
9,575
202,654
1,000

162,770
86,524
18,620
71,230
414,113
11,118

Training Split Testing Split

256
256
512
512
128
128

256
256
512
512
128
128

Matrix Encoding

Trace Length

6
6
8
8
6
6

×
×
×
×
×
×

×
×
×
×
×
×

±
±
±
±
±
±

•

a “corrupted input” (
) that is mostly orthogonal to the mani-
fold of I. As explained in Sec. 4.1, due to the inherent noise
resilience of manifold learning, crafting such a corrupted in-
put can cause less challenge to attackers when recovering i
from the low-level manifold space. Although iprivate is of low
weight in iblinded, it can still be reconstructed to some extent,
as will be shown in Fig. 7 of Sec. 6.3.

∈

Extension to other data types. For image and audio data,
we recommend using a normal image i
I as the mask imask.
Intuitively, by amplifying imask with a large coefﬁcient β in
generating iblinded, imask is presumed to dominate the percep-
tual features in iprivate. Hence, we stealthily hide the private
perceptual features of iprivate in iblinded, whose contents are
difﬁcult for adversaries to disentangle without knowing imask.
For textual data, we recommend inserting notional words of
high frequency to blind iprivate. We present empirical results
on how various choices of imask can inﬂuence the mitigation
effectiveness in Sec. 6.3.

⊕

⊕

(cid:9)

(cid:9)

and

And

. For image and
Implementation of Operators
audio data, we use ﬂoating-point number addition and sub-
traction to implement
. Textual data are discrete:
considering that media software often manipulates textual
data at the word level, simply “adding” or altering words in
the input text will likely trigger some error handling routines
of the corresponding media software, which is not desirable.
Sec. 4.1 clariﬁes that our autoencoder framework essentially
captures the “word dependency” between words in a sentence;
operation as inserting words in a
accordingly, we deﬁne the
sentence, whereas the
operation is implemented to remove
previously inserted words. As shown in Sec. 6.3, this strategy
effectively breaks the word dependency in the original text.

(cid:9)

⊕

5 Attack Setup

We leverage three high-resolution side channels, as shown
in Table 2. As clariﬁed in our threat model (Sec. 2), these
side channel are commonly adopted in previous works. See
Appx. C for detailed setup of these side channels. We clarify

8

that exploiting new side channels is not our focus. We use
common side channels in the era of cloud computing, imply-
ing the severity and effectiveness of our proposed attack. The
resolution when performing attacks on those side channels
are 4B, 64B, and 4096B, respectively. Higher-resolution side
channels should enable recovering media data with more vivid
details. Media data of better quality, however, does not nec-
essarily enhance privacy stealing (e.g., determining whether
chest X-Ray images indicate pneumonia). See quantitative
evaluation of privacy inference in Sec. 6.1.2.

For evaluation in Sec. 6, we use Pin [76] to collect mem-
ory access traces and map each trace into three side channel
traces following mapping rules in Table 2. Sec. 6.4 further
demonstrates attack in an userspace-only scenario, i.e., we
collect cache side channels via Prime+Probe [102].

Media Software and Media Dataset. Table 3 reports evalu-
ated media software and statistics of side channel traces. We
pick media software consistent with previous works [45, 117,
123]. All media software are complex real-world software,
e.g., FFmpeg contains 1M LOC. In contrast, crypto libraries
are usually much succinct, e.g., x86 core implementation of
AES in recent OpenSSL has about 3K LOC. We prepare two
common datasets for each media software to comprehensively
evaluate our attack. All datasets contain daily media data that,
once exposed to adversaries, would result in privacy leakage.
We compile all three media software into 64-bit binary code
using gcc on a 64-bit Ubuntu 18.04 machine. See Appx. C
for details of these software and datasets.

5.1

Implementation

We implement our framework in Pytorch (ver. 1.4.0). We
use the Adam optimizer with learning rate as 0.0002 for all
models. Batch size is 64. For continuous decoders, we set the
loss function as λLexlicit + Limplicit + ∑n
i=1 Lprivacy, where λ =
50 and n is the number of privacy-aware indicators. We ran
experiments on Intel Xeon CPU E5-2683 with 256 GB RAM
and one Nvidia GeForce RTX 2080 GPU. For experiments
based on Prime+Probe-logged traces (Table 3), the training

Table 4: CelebA face image matching evaluation.

same face
non-face

Cache bank Cache line Page table
43.5%
2.0%

44.5%
2.1%

45.4%
2.0%

Table 5: SC09 human voice matching evaluation.
Cache bank Cache line Page table
28.8%
24.2%

ID accuracy
Content accuracy

23.2%
22.6%

29.1%
21.6%

is completed at 100 epochs and takes less than 24 hours. For
experiments using Prime+Probe-logged traces, training and
takes shorter time (see Running Time in Appx. D). Table 3
reports the dataset size and training/testing splits. See our
released codebase [3] for result veriﬁcation.

6 Evaluation

We present the SCA exploitation toward media software in
Sec. 6.1. We discuss program points that induce informa-
tion leakage in Sec. 6.2, and demonstrate the effectiveness of
perception blinding in Sec. 6.3.

6.1 Side Channel Attack

This section reports evaluation results of our attack. Due to
the limited space, some setups are reported in Appx. C. We
present more evaluation results in Appx. G.

6.1.1 Qualitative Evaluation

This section presents and compares the reconstructed media
data with the reference inputs in terms of various settings.
Fig. 5 demonstrates that the reconstructed images and the
references show highly aligned visual appearances, including
gender, eyebrow shapes, skin color, and hair styles. Images
constructed from different side channels manifest comparable
visual quality. Fig. 4 further reports the text reconstruction
results of daily dialogs by comparison with the reference
inputs. The reconstructed sentences, although are not fully
aligned with the reference, still retain considerable correct
contents and the original intents.

We interpret the overall qualitative evaluation results, in
terms of images and text, as highly encouraging. We present
reconstructed chest X-ray images, sub-URMP/SC09 audio
data, and COCO text in Appx. G. Promising results can be
consistently observed.

6.1.2 Quantitative Evaluation

Image Data. For CelebA, we leverage commercial face recog-
nition APIs, Face++ [5], to decide whether a reconstructed
face and its reference input can be considered as from the

9

Table 6: Text data inference evaluation.

Dataset
COCO Caption
Daily Diolgue

Cache bank Cache line Page table Baseline
0.0000%
0.0183%

42.6%
37.4%

42.1%
37.6%

43.4%
38.1%

same person with over 99.9% conﬁdence scores. We thus
launch a de-anonymization attack of user identity with recon-
structed images. Table 4 reports the evaluation results; for
all three exploited side channels, more than 43% of the re-
constructed faces can be correctly matched to their reference
inputs, showing a high success rate of face matching. Only
2% of the reconstructed images are deemed as “non-face,”
which indicates the negligible chance of generating corrupted
faces. Due to the limited space, we report the quantitative
evaluation of chest X-ray in Appx. G.

Our attack achieves plausible accuracy. The quantitative
results are not noticeably affected by differences in side chan-
nels, which indicates that face matching evaluation extracts
representative attributes from images for matching. As men-
tioned in Sec. 5, the three side channels manifest different
resolutions: although higher-resolution side channels enable
reconstruction of more vivid images, this does not necessar-
ily promote privacy stealing. However, enabled by manifold
learning-based autoencoder and our objective functions which
explicitly account for privacy indicators (Table 1), privacy-
related factors are extracted in the reconstructed images across
side channels of various resolutions. Similar observations are
made for media data of other formats; our discussion follows.

Audio Data. Table 5 reports the voice matching results for
SC09. Using the reconstructed voice commands (number 0–
9), we train two classiﬁers for speaker identity and command
0–9 classiﬁcation.5 The evaluation results largely outperform
the baseline (i.e., random guessing). With a total of 184 speak-
ers, we achieve greater than 20% accuracy in matching correct
speaker identities across all settings. We also exceed 20% ac-
curacy in content matching (0–9). We observed decreasing
accuracy in speaker identity matching, which is reasonable
given that the cache bank side channel only “kicks off” two
least signiﬁcant bits, while cache line and page table side
channels retain less amount of information. Appx. G reports
the matching rate of musical instruments in Table 16, which
yields mostly consistent and promising ﬁndings.

Text Data. To reconstruct text data, we gradually predict each
word based on previously-predicted words in the sentence.
Hence, for the quantitative evaluation, we adopt an attack
strategy mostly aligned with [24] to measure the average
accuracy of word-level prediction accuracy. Table 6 reports
the evaluation results for the COCO and Dailydialog datasets.
To prepare a baseline for comparison, we feed a random input
to the decoder ψθ instead of using the latent vector of an
input side channel trace. As expected, our exploitation of both

5Please refer to Appx. C for details of these classiﬁers.

Figure 4: Qualitative evaluation of DailyDialog. We mark inconsistent reconstructions.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

static void idct32(int ∗coeffs, int col_limit) {

int limit = min(H, col_limit + 4);
for (int i = 0; i < H; i++)

TR_32(src, src, H, H, limit);

}
static void TR_32(int ∗dst, int ∗src, int dstep,

int sstep, int end) {

int o_32[16] = { 0 };
for (int i = 0; i < 16; i++)

// loading pre−calculated matrix ‘‘transform’’
for (int j = 1; j < end; j += 2)

o_32[i] += transform[j][i] * src[j * sstep];

// TR_16 calls TR_8, and TR_8 calls TR_4.
TR_16(e_32, src, 1, 2 * sstep, SET, end/2);

}

Figure 5: Qualitative evaluation of CelebA.

Figure 6: Vulnerable code components in FFmpeg. We mark
variables depending on FFmpeg’s input in red, and bold input-
dependent memory accesses (line 12).

Module

MCU

Transform

IDCT

Upsample

1

2

5866

7,060

#Functions Frequency

Table 7: Localized program points in libjpeg.
Sample Func. Names
encode_mcu_huff
decode_mcu
jtransform_execute_transform
jpeg_idct_15x15
jsimd_idct_ifas
h2v1_merged_upsample
h2v1_fancy_upsample
tjDecompress2
tjDecompressHeader3
write_bmp_header
start_input_bmp

1,352

2,033

4,027

8,23

13

15

6

4

Dump

Decompress

Table 8: Localized program points in FFmpeg.

Module
Encode
Decode
Filter

IDCT

Dump

#Functions Frequency

50+
50+
50+

10+

10+

10K+
10K+
10K+

5K+

5K+

Sample Func. Names
encode_frame
decode_frame
filter_frame
idct_idct_32x32_add_ce
iadst_idct_16x16_add_c
wav_write_trailer
wav_write_header

datasets achieves much greater accuracy than the baseline
regarding all side channels.

6.2 Program Point Localization

We now discuss the localized buggy code of each media soft-
ware using attention. We present a representative buggy code
fragment of FFmpeg in Fig. 6. We further present represen-
tative buggy code fragments of libjpeg and Hunspell in
Appx. G. We also list all localized program points in term of
assembly code in [3].
libjpeg. We analyze 2,000 media inputs from the CelebA
and Chest X-ray datasets. Table 7 reports the localization re-
sults of libjpeg. For instance, we identify 7,060 side channel
points from 4,000 traces, which can be mapped back to two

functions (encode_mcu_huff and decode_mcu) performing
minimum coded unit (MCU)-related operations. Similarly,
we ﬁnd information leakage points in modules related to de-
compression, IDCT, and also output dumping.

Table 3 shows that one trace has approximately 400K data
points. In other words, Table 7 reveals that a tiny portion of
“informative” points on a side channel trace make a primary
contribution to information reconstruction. Given an image
compressed in JPEG, libjpeg decompresses the image into a
bitmap. It is pointed out that the decompression process intro-
duces side channels. IDCT-related functions that were noted
by [117] are automatically re-discovered by us. In addition,
we identify functions in other image transformation routines
(e.g., MCU, unsampling) and output dumping routines that
leak inputs. We manually inspected the corresponding im-
plementation of libjpeg and conﬁrmed our ﬁndings. Note

10

Reconstructed TextReference InputI think it 'be better for finda good babysitter here . It ' be cost , anor three days .I think it would be better to have a good babysitter here . It might even be for two or three days .She isa singlecold , and itdon ' t want to take care tous . But we don ' t like howcan stay with our .She has a bad cold , and we don ' t want to take her with us . But we don ' t know who can stay with her .I ' m sorry , say that. What ' s wrong with her ?I ' m sorry to hear it . What ' s wrong with her ?Reference inputsCache bankCache linePage tableFigure 7: Qualitative evaluation results of perception blinding.

Module
Interface

Parser

Look up

1

1,333

#Functions Frequency

Table 9: Localized program points in Hunspell.
Sample Func. Names
pipe_interface
next_token, alloc_token
get_parser, TextParser::init
check, insertion_sort
putdic, allocate_string
chenc, allocate_char_vector

1,076

1,230

213

2

5

4

Insert

that our approach is automated and treats the entire libjpeg
software as a blackbox, whereas previous studies [45,64,117]
could rely on expert knowledge to ﬁrst localize the vulnerable
program points before launching SCA.
FFmpeg. We use 2,000 inputs from SC09 and Sub-URMP
as the inputs of FFmpeg. Our ﬁndings, as reported in Table 8,
can be mapped to ﬁve modules of FFmpeg, each of which
contains many functions. FFmpeg processes audio inputs with
audio sampling (the sampling frequency is set as 4,000 in our
experiments). Fig. 6 presents a vulnerable program compo-
nent in the IDCT module of FFmpeg where the input “taints”
certain variables (marked in red) and eventually inﬂuences
the memory accesses at line 12. Given different input val-
ues, different memory cells are visited at line 12, resulting in
access to different cache units or page table entries. In addi-
tion, TR_32, TR_8 and TR_4 also suffer from similar patterns
(line 14). To the best of our knowledge, side channel issues
on FFmpeg are rarely studied, but the ﬁndings in FFmpeg are
conceptually similar to other media software; for example,
IDCT algorithms and output dumping in both FFmpeg and
libjpeg are ﬂagged as vulnerable by us.
Hunspell. We use 2,000 inputs from each dataset (i.e., Dai-
lyDialog and COCO) to run Hunspell and analyze the logged
side channels. Table 9 reports the results, where information
leakage points are found from the interface, parser, and also
spell checking . In fact, previous works [64,117] have pointed

11

out side channel issues of Hunspell. Hunspell performs
spell check, where a dictionary of words is maintained as a
hash table. Hunspell iterates each word w in the input sen-
tence to check if w is in the hash table, thus deciding the
correctness of its spelling. When checking each w, Hunspell
computes the hash value of w and looks up the correspond-
ing hash bucket of words. This would lead to a sequence
of memory accesses, which can be potentially used to map
back to word w. Note that while previous works attacking
Hunspell assumes the knowledge of the dictionary [64, 117]
before attack, such pre-knowledge is not needed for our attack.
Instead, we use side channel traces and their corresponding
sentences fed to Hunspell as the training data to implic-
itly learn a mapping in the low-dimensional joint manifold
space. [64, 117] reports that functions lookup and add_word
primarily leak inputs. Our manual conﬁrmation shows that
our ﬁndings (e.g., putdic, chenc, check, insertion_sort)
indeed invoke lookup and add_word functions. We also ﬁnd
that the parser and interface (we use Linux utility echo to
feed Hunspell) of Hunspell also inﬂuence side channels,
both of which are not disclosed by previous works.

Conﬁrmation with the Developers. We have reported our
localized program points to the developers. By the time of
writing, the FFmpeg developers conﬁrmed our ﬁndings. Nev-
ertheless, they mentioned that software-level ﬁxing is undesir-
able, given the difﬁculty of writing side channel-free code and
the incurred extra performance penalty. From his perspective,
OS-level or hardware-level ﬁxing seems more practical.

6.3 Mitigation with Perception Blinding

We benchmark the mitigation effectiveness in terms of quanti-
tative and qualitative analysis. We also discuss how different
masks can inﬂuence the mitigation.

OriginalMaskMaskedRecoveredReconstructedMaskedRecoveredReconstructedMaskedRecoveredReconstructedα= 0.05α= 0.10α= 0.30NoiseMaskNon-faceMaskFace #1MaskFace #2MaskTable 10: Face matching results after blinding in terms of
(cache bank/cache line/page table).

Mask
Noise
Non-face
Face#1
Face#2

α = 0.05

α = 0.1
27.5/28.6/27.8% 25.2/26.9/28.2% 26.6/27.5/29.0%
28.8/28.8/26.5% 26.2/27.6/27.4% 28.7/31.4/26.2%
1.8/1.4/2.7%
0.7/1.7/1.9%

2.0/1.5/3.1%
1.2/1.6/2.2%

1.4/1.2/2.4%
0.6/1.3/1.6%

α = 0.3

Table 11: Mitigating COCO text inference attack in terms
of (cache bank/cache line/page table). α = 0.05, α = 0.1,
α = 0.3 denote each word are appended with 19, 9, and 2
masks, respectively.

Mask
“man”
“sitting”

α = 0.05

α = 0.1
0.39/0.40/0.36% 0.68/0.69/0.67% 2.46/2.45/2.13%
0.16/0.16/0.22% 0.30/0.30/0.39% 1.36/1.40/1.39%

α = 0.3

6.3.1 Qualitative Evaluation

We report qualitative evaluation by comparing the reference
inputs with the reconstructed inputs after applying blinding.
Due to the limited space, Fig. 7 only reports the perception
blinding over a private face image iprivate in terms of different
settings. The original image iprivate is presented in the “Orig-
inal” column, and applied perception masks are presented
in the “Mask” column. For each masked image iblinded, the
adversarial recovered images are presented in the “Recon-
structed” columns, and the ﬁnal media software outputs after
unblinding are given in the “Recovered” columns.

“Noise mask” (the ﬁrst row) and “non-face mask” (the
second row) do not seem helpful in blinding iprivate because
features such as face orientation are still preserved in the re-
constructed images. However, the use of real face images as
the mask, as shown in the third and fourth columns, gives
promising results to blind key perceptual-level contents like
hair color and skin color. Overall, after blinding, the adversary-
reconstructed images seem to show a correlation with imask
instead of iprivate. This is intuitive; as clariﬁed in Sec. 4.3, a
large coefﬁcient β is assigned to imask such that the perception
contents of imask largely determine the projected intrinsic co-
ordinate in the manifold. This way, the reconstructed images
incline to manifest the perception of imask.

Additionally, although a small α value (e.g., 0.05) intro-
duces a non-trivial amount of noise in the ﬁnal output, outputs
of much better quality can be recovered when α is set to 0.10
or even higher. We thus recommend that users adopt a rea-
sonably high α when constituting iblinded. More reconstructed
cases are given in Appx. H.

6.3.2 Quantitative Evaluation

We launch quantitative evaluation following the procedures in
Sec. 6.1. The perception blinding of “Noise” and “Non-face”
masks, as shown in Table 10, reduces the average success
rates of face matching from approximately 44% (Table 4)

12

to 27.4%, but still has non-negligible privacy leakage. Com-
pared with “Face#1” and “Face#2”, Fig. 7 shows that images
reconstructed from “Noise”- and “Non-face”-blinded images
manifest better visual similarity with the reference inputs. In
addition, Table 10 reports that “Face#1” and “Face#2” exhibit
much better mitigation (less than 3.1% matching rates) in
terms of quantitative metrics. We ﬁnd that the value of α does
not notably inﬂuence the results but is still positively corre-
lated with privacy leakage. Overall, for images, we mask the
perception contents using blinding. However, the privacy indi-
cator for this scenario, i.e., celebrity’s identity, is not simply a
linear sum of all perception contents. Overall, identity recog-
nition depends on subtle features of a human face: changing
α not necessarily impedes capturing informative features.

α −

Table 11 reports the mitigation results of Hunspell using
COCO. We use two notional words of high frequency, “man”
and “sitting”, for blinding. We insert N notional words after
each word in an input sentence, where N ( 1
1) is 19, 9, and
2 given different α. When more notional words are used, we
observe a higher decrease in inference accuracy. However,
with blinding, the inference accuracy decreases from more
than 40.0% (see Table 6) to less than 2.5% (close to baseline;
see Table 6) even two notional words are inserted after each
normal word. Different from masking images, the privacy of
text is assessed by word dependency (introduced in Sec. 6.1.2).
α decides #notional words inserted to break word dependency.
Therefore, the results changes notably w.r.t. values of α.

In sum, our quantitative evaluation demonstrates the ef-
fectiveness of our proposed mitigation despite differences in
the media data formats or exploited side channels. See Ap-
pendix H for more results; for instance, blinding chest X-ray
images can drastically reduce the disease diagnosis F1 score
from an average of 0.73 (see Table 17) to less than 0.1.

6.4 Real-World Attack with Prime+Probe

This section explores collecting cache access traces via a prac-
tical cache attack, Prime+Probe [102,124], in userspace-only
scenarios. To do so, we conduct an end-to-end experiment,
by leveraging Mastik [119], a micro-architectural side chan-
nel toolkit, to perform Prime+Probe and log victim’s access
toward L1D and L1I cache. We use Linux taskset to pin
the victim software and the spy process on the same CPU
core. We launch experiments on both Intel Xeon CPU and
AMD Ryzen CPU. See Appx. D for setup details of this end-
to-end attack. We also clarify how cache side channels are
represented and processed by our encoder in Appx. F.

The quantitative evaluation results, as reported in Table 12,
are generally encouraging. Attacks toward libjpeg and
Hunspell manifest high accuracy comparable with attacks
over Pin-logged traces (Sec. 6.1.2). While Prime+Probe
logs relatively noisier cache side channels, our attack shows
promising noise resilience, as trace encoder (and manifold
learning by design) is noise resilient. Further, the logged

Table 12: Quantitative evaluation results using cache side channels logged by Prime+Probe. We also provide the processing
with Prime+Probe).
time (ms) when launching Prime+Probe (normal
libjpeg & CelebA face matching/non-face

Hunspell & DDialog text matching

FFmpeg & SC09 voice matching

→

Intel

AMD

L1I Cache
L1D Cache

12.6% (36
81.8% (36

580)
590)

11.6% (10
15.7% (10

420)
420)

→
→

→
→

Intel
38.0/0.85% (5
36.9/0.80% (5

18)
20)

→
→

AMD
35.9/1.2% (2
33.9/0.90% (2

22)
24)

→
→

Intel

33.9% (60
32.2% (60

→
→

AMD

130)
130)

33.2% (23
31.8% (23

60)
60)

→
→

side channels are sparse; given only a few records are secret-
dependent, noise introduced by Prime+Probe and other work-
loads do not primarily impede our attack. See further discus-
sion on noise resilience in Appx. F.

FFmpeg reports high attack accuracy (over 80%) on Intel
L1D cache but lower accuracy for other settings. As will be
reported in Table 15 (Appx. D), the logged side channel traces
are unstable (and challenging to comprehend), where stddev
is about half of the average trace length. To verify the high
attack accuracy on Intel L1D cache, we manually checked all
the reconstructed 2,552 audio clips (also uploaded at [3] for
the reference). The reconstructed audio clips on Intel L1D
cache manifest high quality. However, while the original au-
dio clips of the same class are produced by different persons
(and sound very different), all reconstructed audio clips of
the same class sound indistinguishable. This indicates that
the trained model stealthily simpliﬁes the task of reconstruc-
tion into a task of ten class-conditional generation (recall this
dataset has “0–9” labels). We then manually checked the col-
lected traces: we ﬁnd that for this particular case, Intel L1D
cache “ampliﬁes” the distance of inter-class traces while re-
duces the distance of intra-class traces. As a result, intra-class
differences are not well learned using training data. However,
since our quantitative metrics only check if the reconstructed
audio can be classiﬁed correctly, the attack accuracy is high,
indicating privacy leakage. We use attention (Sec. 4.2) and
compared all the localized code components contributing side
channels: we report that localized functions are the same on
Intel/AMD CPUs. However, they manifest different frequen-
cies, which result in this subtle model decaying. We conﬁrm
that this stealthy issue only occurs for this case. To solve this
issue (and therefore reconstruct diverse outputs within the
same class), users can opt for more complex models or larger
training data, if needed.

Overall, inspired by recent work [112] exploring timing-
based microarchitectural side channels, we deem it an in-
teresting future work to benchmark the microarchitectural
side channel differences. Our tool can automatically check
whether side channels are informative enough to reconstruct
secrets, when it largely outperforms the baseline.

We report the slowdown incurred by Prime+Probe attack
in Table 12. Overall, media software are highly complex,
and processing media data can usually induce a large vol-
ume of cache accesses. This way, frequent cache misses
due to Prime+Probe can cause a reasonably high slowdown.
Appx. D gives further discussion regarding this point. We also

Table 13: Attack PathOHeap.

IDCT

Function
w/o ORAM 40.3% 38.0%
0.2%
with ORAM 0.2%

MCU

present qualitative evaluation results in Appx. D. In short, the
reconstructed media data (e.g., images) manifest fairly high
visual quality. For instance, the reconstructed CelebA face
photos retain many correct perception features, such as face
orientation, skin color, hair color and hair styles.

6.5 Mitigation Using ORAM

Besides perception blinding, this section assesses other mitiga-
tions. Existing mitigations aim at adding randomness, making
it constant, or directly masking inputs. Nearly all of them are
particularly designed to protect crypto software [21, 31, 101].
Raccoon [87] proposes general mitigation using software ob-
fuscation; however, its implementation is not available. That
said, oblivious RAM (ORAM) [42] conceal memory access
sequences of a program by continuously shufﬂing data as
they are accessed. We study whether a representative ORAM,
PathOHeap [97], can mitigate our attack. Due to the limited
space, we report the key evaluation results in Table 13. PathO-
Heap takes several hours to process one memory access made
by libjpeg. We thus focus on two critical functions localized
by our framework (see Sec. 6.2), IDCT and MCU, separately.6
We measure attack success rates with and w/o ﬁrst converting
memory traces using PathOHeap.

Cache line side channels derived from either IDCT or MCU
are sufﬁcient for attack. Nevertheless, ORAM eliminates in-
formation leak: memory access traces, after processed by
PathOHeap, do not depend on input images. We report that
our autoencoder does not even reach convergence during train-
ing, and the reconstructed images (using poorly trained au-
toencoder) show indistinguishable and meaningless visual
appearances. The non-zero result (i.e., 0.2%) is because that
many face photos look like an “average” face. In other words,
0.2% implies the baseline of face matching.
Comparison. PathOHeap is very costly: while libjpeg can
process an image within 100ms, PathOHeap takes several
hours to convert the corresponding memory trace. The ob-
. In
fuscator, Racoon [87], has an average overhead of 16.1

×

6Focusing on functions with known information leakage (i.e., IDCT) [45,

117] demonstrates a “white-box” attacker using our technique.

13

Table 14: Quantitative evaluation results (same face/non-face)
of face images reconstructed from noisy side channels.

Setting

Pin
logged
trace

Prime+Probe
logged trace

Workload under
Prime+Probe

Noise
Insertion Scheme
Gaussian
Shifting
Removal
Leave out
False hit/miss
Wrong order
Bzip2
Victim1
Victim2

NA

Low

High

43.5/2.0% 33.8/2.1% 28.0/1.5%
43.5/2.0% 42.9/1.7% 39.1/1.8%
43.5/2.0% 30.0/1.9% 29.3/4.3%
36.9/0.8% 36.8/1.1% 36.8/1.1%
36.9/0.8% 36.4/1.2% 36.1/1.2%
36.9/0.8% 36.8/1.0% 36.7/1.0%
36.9/0.8%
36.9/0.8%
36.9/0.8%

27.6/1.0%
30.7/1.1%
29.0/1.0%

contrast, perception-blinding delivers negligible extra cost
(i.e., processing masked data using media software once) al-
beit its mitigation is speciﬁc for manifold learning-based SCA.
This underlines the key novelty of our technique.

6.6 Noise Resilience

We have discussed the general immunity to noise of manifold
learning in Fig. 3. This section empirically assesses our at-
tacks under various scenarios where noise is introduced in
side channels. We summarize our noise insertion schemes in
Table 14. The ﬁrst three schemes are launched to mutate cache
line access traces logged by Pin, whereas the latter three mu-
tate the cache set hit/miss records logged via Prime+Probe.
NA means no noise is inserted, whereas Low/High denote to
what extent side channel logs are perturbed (see Appx. I for
details). We also benchmark how real-world workload, i.e., by
launching bzip2 or another victim software (e.g., libjpeg)
on the same CPU core, can undermine our attack. Victim1
and Victim2 represent launching another victim software on
the same core and processing the same or different inputs.

Due to the limited space, we only report the quantitative
evaluation results of libjpeg on CelebA in Table 14. See
Appx. I for other quantitative and qualitative results: despite
the applied noise, many perceptual features are still retained
in the reconstructed data (e.g., face photos), illustrating capa-
bility of privacy stealing under noisy scenarios.

The reconstructed images are more resilient toward Shift-
ing. Removal and Gaussian noise, by extensively leaving
out or perturbing data points on the logged trace (e.g., Re-
moval/High removes half records on a trace), show greater
inﬂuence on data reconstruction. As for noise inserted in
Prime+Probe logged side channel records, none of them pri-
marily affect the attack accuracy. We note that Prime+Probe
logged side channel traces, even without applying these noise
insertion schemes, are of high stddev. That is, our autoencoder
will be trained with more “diverse” side channel logs, which
enhance the robustness but undermines accuracy. Similar ﬁnd-
ings are obtained in launching extra real-world workloads.
Please refer to Appx. I for further evaluation on noise re-

silience, and our analysis on noise resilience from the trace
encoder structure perspective and training data perspective.

7 Related Work

Side Channel Analysis. Kocher proposes to use timing side
channel to exploit crypto systems [55]. To date, side chan-
nels have been used to exploit crypto systems under different
scenarios [9, 13, 35, 116], including trusted computing envi-
ronments like Intel SGX [16, 64, 79, 93]. [22] demonstrates
that timing side channel can be launched remotely through
network. The CPU cache are particularly exploited given
its indispensable role in boosting modern computing plat-
forms [45, 74, 83, 121]. Controlled side channel assumes an
adversarial-controlled OS to log page table access of victim
software [117]. DNNs have been used to infer secret keys
from crypto libraries [48, 49, 77]. These works, usually re-
ferred to as “proﬁled SCA”, share the same assumption with
our research that models are trained using historical data.
Most existing DNN-based SCA focuses on attacking crypto
systems; they typically perform low-level bit-wise classiﬁ-
cation to gradually infer key bits. In contrast, we show that
attackers in black-box scenarios can use manifold learning
to reconstruct media data of various types in an end-to-end
manner. [61,115] also use autoencoders in the context of SCA.
However, they use autoencoder to denoise side channel traces
as a preprocessing step for SCA of crypto software.

Countermeasures. Software-based techniques
include
constant-time techniques which ensure that software behavior
is independent with its conﬁdential data [30, 56, 80, 86, 92].
Techniques have also been proposed to blind secrets or
randomize side channel access patterns [11, 17, 33, 52, 58, 87].
ORAM [43,72,97,98] translates memory access into identical
or indistinguishable traces, which can provably eliminate
many side channels but incur high performance penalty.
Program analysis methods such as information ﬂow track-
ing [62,81], model checking [10], type system [8,89], abstract
interpretation [36, 57, 104], and constraint solving [19, 105]
are used to check crypto software and detect side channels. In
contrast, our study delivers a neural attention-based approach
to detecting code fragments inducing information leakage.
include randomizing
Hardware-based countermeasures
side channel access or enforcing ﬁne-grained resource
isolation [73, 84, 107–109]. Compared with system- and
hardware-based countermeasures, software-based approaches
usually do not require to modify the underlying hardware
design. Nevertheless, software-based countermeasures are
generally high cost and low scalable in analyzing real-world
software.

14

8 Conclusion

This research proposes SCA for media software. We perform
cross-modality manifold learning to reconstruct media data
from side channel traces. We also use attention to localize pro-
gram points leading information leakage. We design percep-
tion blinding to mitigate the proposed SCA. Our evaluation
on real-world media software reports promising results.

References

[1] FFMPEG. https://ffmpeg.org/.
[2] hunspell. http://hunspell.github.io/.
[3] Research

artifact.
Yuanyuan-Yuan/Manifold-SCA.

https://github.com/

[4] Chest

x-ray

competition.
stanfordmlgroup.github.io/competitions/
chexpert/, 2020.

https://

[5] Face attributes analysis service.

https://www.

faceplusplus.com/attributes/, 2020.

[6] PAGE MASK.

https://elixir.bootlin.com/
linux/v5.6.10/source/arch/x86/include/asm/
page_types.h, 2020.

[7] Hervé Abdi and Lynne J Williams. Principal compo-
nent analysis. Wiley interdisciplinary reviews: compu-
tational statistics, 2(4):433–459, 2010.

[8] Johan Agat. Transforming out timing leaks. In Pro-
ceedings of the 27th ACM SIGPLAN-SIGACT sympo-
sium on Principles of programming languages, pages
40–53, 2000.

[9] Nadhem J Al Fardan and Kenneth G Paterson. Lucky
thirteen: Breaking the tls and dtls record protocols. In
2013 IEEE Symposium on Security and Privacy, pages
526–540. IEEE, 2013.

[10] José Bacelar Almeida, Manuel Barbosa, Gilles Barthe,
François Dupressoir, and Michael Emmi. Verifying
constant-time implementations. In USENIX Sec., 2016.
[11] Aslan Askarov, Danfeng Zhang, and Andrew C Myers.
Predictive black-box mitigation of timing channels. In
Proceedings of the 17th ACM conference on Computer
and communications security, pages 297–307, 2010.
[12] Mukund Balasubramanian, Eric L Schwartz, Joshua B
Tenenbaum, Vin de Silva, and John C Langford. The
ISOMAP algorithm and topological stability. Science,
295(5552):7–7, 2002.

[13] Lucas Bang, Abdulbaki Aydin, Quoc-Sang Phan, Co-
rina S P˘as˘areanu, and Tevﬁk Bultan. String analysis
for side channels with segmented oracles. In Proceed-
ings of the 2016 24th ACM SIGSOFT International
Symposium on Foundations of Software Engineering,
pages 193–204, 2016.

[14] Mikhail Belkin and Partha Niyogi. Laplacian eigen-
maps and spectral techniques for embedding and clus-
tering. In Nips, volume 14, pages 585–591, 2001.

15

[15] Yoshua Bengio, Aaron Courville, and Pascal Vincent.
Representation learning: A review and new perspec-
tives. IEEE transactions on pattern analysis and ma-
chine intelligence, 35(8):1798–1828, 2013.

[16] Ferdinand Brasser, Urs Müller, Alexandra Dmitrienko,
Kari Kostiainen, Srdjan Capkun, and Ahmad-Reza
Sadeghi. Software grand exposure: SGX cache attacks
are practical. In Proceedings of the 11th USENIX Work-
shop on Offensive Technologies (WOOT’ 17), 2017.

[17] Benjamin A Braun, Suman Jana, and Dan Boneh. Ro-
bust and efﬁcient elimination of cache and timing side
channels. arXiv preprint arXiv:1506.00189, 2015.
[18] Andrew Brock, Jeff Donahue, and Karen Simonyan.
Large scale GAN training for high ﬁdelity natural im-
age synthesis. In International Conference on Learning
Representations, 2019.

[19] Robert Brotzman, Shen Liu, Danfeng Zhang, Gang
Tan, and Mahmut Kandemir. CaSym: Cache aware
symbolic execution for side channel detection and mit-
igation. In IEEE SP, 2018.

[20] Robert Brotzman, Shen Liu, Danfeng Zhang, Gang
Tan, and Mahmut Kandemir. CaSym: Cache aware
symbolic execution for side channel detection and mit-
igation. In 2019 IEEE Symposium on Security and
Privacy (SP), pages 505–521. IEEE, 2019.

[21] David Brumley and Dan Boneh. Remote timing at-
tacks are practical. Computer Networks, 48(5):701–
716, 2005.

[22] David Brumley and Dan Boneh. Remote timing attacks
are practical. Computer Networks, January 2005.
[23] Eleonora Cagli, Cécile Dumas, and Emmanuel Prouff.
Convolutional neural networks with data augmentation
against jitter-based countermeasures. In International
Conference on Cryptographic Hardware and Embed-
ded Systems, pages 45–68. Springer, 2017.

[24] Nicholas Carlini, Chang Liu, Úlfar Erlingsson, Jernej
Kos, and Dawn Song. The secret sharer: Evaluat-
ing and testing unintended memorization in neural
Security Symposium
USENIX
In 28th
networks.
}
{
Security 19), pages 267–284, 2019.
USENIX
(
}
{

[25] Ya Chang, Changbo Hu, and Matthew Turk. Manifold

of facial expression. In AMFG, pages 28–35, 2003.

[26] Ya-Liang Chang, Kuan-Ying Lee, Po-Yu Wu, Hung-yi
Lee, and Winston Hsu. Deep long audio inpainting.
arXiv preprint arXiv:1911.06476, 2019.

[27] Lele Chen, Sudhanshu Srivastava, Zhiyao Duan, and
Chenliang Xu. Deep cross-modal audio-visual genera-
tion. In Proceedings of the on Thematic Workshops of
ACM Multimedia 2017, pages 349–357, 2017.
[28] Mikhail Chernov and Eric Ghysels. A study towards
a uniﬁed approach to the joint estimation of objective
and risk neutral measures for the purpose of options
valuation. Journal of ﬁnancial economics, 56(3):407–
458, 2000.

[29] R. C. Chiang, S. Rajasekaran, N. Zhang, and H. H.
Huang. Swiper: Exploiting virtual machine vulner-
ability in third-party clouds with competition for i/o
IEEE Transactions on Parallel and Dis-
resources.
tributed Systems, 26(6):1732–1742, June 2015.
[30] Bart Coppens, Ingrid Verbauwhede, Koen De Boss-
chere, and Bjorn De Sutter. Practical mitigations for
timing-based side-channel attacks on modern x86 pro-
cessors. In IEEE SP, 2009.

[31] Jean-Sébastien Coron and Ilya Kizhvatov. An efﬁ-
cient method for random delay generation in embed-
In International Workshop on Cryp-
ded software.
tographic Hardware and Embedded Systems, pages
156–170. Springer, 2009.

[32] Jose A Costa and Alfred O Hero. Geodesic entropic
graphs for dimension and entropy estimation in mani-
fold learning. IEEE Transactions on Signal Processing,
52(8):2210–2221, 2004.

[33] Stephen Crane, Andrei Homescu, Stefan Brunthaler,
Per Larsen, and Michael Franz. Thwarting cache side-
channel attacks through dynamic software diversity.
NDSS, 2015.

[34] Craig Disselkoen, David Kohlbrenner, Leo Porter, and
Dean Tullsen.
Prime+Abort: A timer-free high-
precision L3 cache attack using Intel TSX. In USENIX
Sec., 2017.

[35] Xiaowan Dong, Zhuojia Shen, John Criswell, Alan L
Cox, and Sandhya Dwarkadas. Shielding software
from privileged side-channel attacks. In 27th USENIX
Security Symposium, pages 1441–1458, 2018.
[36] Goran Doychev, Dominik Feld, Boris Kopf, Laurent
Mauborgne, and Jan Reineke. CacheAudit: A tool for
the static analysis of cache side channels. In USENIX
Sec., 2013.

[37] Goran Doychev and Boris Köpf. Rigorous analysis
of software countermeasures against cache attacks. In
Proceedings of the 38th ACM Conference on Program-
ming Language Design and Implementation (PLDI),
2017.

[38] Bin Duan, Wei Wang, Hao Tang, Hugo Latapie, and
Yan Yan. Cascade attention guided residue learn-
ing gan for cross-modal translation. arXiv preprint
arXiv:1907.01826, 2019.

[39] Xing Fan, Wei Jiang, Hao Luo, and Mengjuan Fei.
Spherereid: Deep hypersphere manifold embedding
for person re-identiﬁcation. Journal of Visual Commu-
nication and Image Representation, 60:51–58, 2019.
[40] Charles Fefferman, Sanjoy Mitter, and Hariharan
Narayanan. Testing the manifold hypothesis. Jour-
nal of the American Mathematical Society, 29(4):983–
1049, 2016.

[41] Zhenyong Fu, Tao Xiang, Elyor Kodirov, and Shao-
gang Gong. Zero-shot object recognition by semantic
manifold distance. In Proceedings of the IEEE con-

16

ference on computer vision and pattern recognition,
pages 2635–2644, 2015.

[42] Oded Goldreich. Towards a theory of software protec-
tion and simulation by oblivious rams. In Proceedings
of the nineteenth annual ACM symposium on Theory
of computing, pages 182–194, 1987.

[43] Oded Goldreich and Rafail Ostrovsky. Software pro-
tection and simulation on oblivious rams. Journal of
the ACM (JACM), 43(3):431–473, 1996.

[44] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,
Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. Generative adversarial
nets. In Advances in neural information processing
systems, pages 2672–2680, 2014.

[45] Marcus Hähnel, Weidong Cui, and Marcus Peinado.
High-resolution side channels for untrusted operating
systems. In 2017 USENIX Annual Technical Confer-
ence, pages 299–312, 2017.

[46] Xiaofei He, Shuicheng Yan, Yuxiao Hu, Partha Niyogi,
and Hong-Jiang Zhang. Face recognition using lapla-
cianfaces. IEEE transactions on pattern analysis and
machine intelligence, 27(3):328–340, 2005.

[47] Benjamin Hettwer, Stefan Gehrer, and Tim Güneysu.
Proﬁled power analysis attacks using convolutional
neural networks with domain knowledge. In Interna-
tional Conference on Selected Areas in Cryptography,
pages 479–498. Springer, 2018.

[48] Benjamin Hettwer, Tobias Horn, Stefan Gehrer, and
Tim Güneysu. Encoding power traces as images
arXiv preprint
for efﬁcient side-channel analysis.
arXiv:2004.11015, 2020.

[49] Annelie Heuser and Michael Zohner. Intelligent ma-
chine homicide. In International Workshop on Con-
structive Side-Channel Analysis and Secure Design,
pages 249–264. Springer, 2012.

[50] Geoffrey E Hinton and Richard S Zemel. Autoen-
coders, minimum description length, and helmholtz
free energy. Advances in neural information process-
ing systems, 6:3–10, 1994.

[51] Daniel Holden, Jun Saito, Taku Komura, and Thomas
Joyce. Learning motion manifolds with convolutional
In SIGGRAPH Asia 2015 Technical
autoencoders.
Briefs, pages 1–4. 2015.

[52] Wei-Ming Hu. Reducing timing channels with fuzzy
time. Journal of computer security, 1(3-4):233–254,
1992.

[53] Gorka Irazoqui, Kai Cong, Xiaofei Guo, Hareesh Khat-
tri, Arun K. Kanuparthi, Thomas Eisenbarth, and Berk
Sunar. Did we learn from LLC side channel attacks? A
cache leakage detection tool for crypto libraries. CoRR,
2017.

[54] Jaehun Kim, Stjepan Picek, Annelie Heuser, Shivam
Bhasin, and Alan Hanjalic. Make some noise. un-
leashing the power of convolutional neural networks

for proﬁled side-channel analysis. IACR Transactions
on Cryptographic Hardware and Embedded Systems,
pages 148–179, 2019.

[55] Paul C. Kocher. Timing attacks on implementations of
Difﬁe-Hellman, RSA, DSS, and other systems. In Pro-
ceedings of the 16th Annual International Cryptology
Conference on Advances in Cryptology, CRYPTO ’96.
Springer-Verlag, 1996.

[56] Boris Köpf and Heiko Mantel. Transformational typing
and uniﬁcation for automatically correcting insecure
programs. International Journal of Information Secu-
rity, 6(2-3):107–131, 2007.

[57] Boris Köpf, Laurent Mauborgne, and Martín Ochoa.
Automatic quantiﬁcation of cache side-channels. In
International Conference on Computer Aided Veriﬁca-
tion, pages 564–580. Springer, 2012.

[58] Boris Köpf and Geoffrey Smith. Vulnerability bounds
and leakage resilience of blinded cryptography under
timing attacks. In 2010 23rd IEEE Computer Security
Foundations Symposium, pages 44–56. IEEE, 2010.

[59] Alex Krizhevsky, Geoffrey Hinton, et al. Learning

multiple layers of features from tiny images. 2009.
[60] Solomon Kullback and Richard A Leibler. On infor-
mation and sufﬁciency. The annals of mathematical
statistics, 22(1):79–86, 1951.

[61] Donggeun Kwon, HeeSeok Kim, and Seokhie Hong.
Improving non-proﬁled side-channel attacks using au-
toencoder based preprocessing. IACR Cryptol. ePrint
Arch., 2020:396, 2020.

[62] Adam Langley. ctgrind. https://github.com/agl/

ctgrind.

[63] Yann LeCun, Fu Jie Huang, and Leon Bottou. Learning
methods for generic object recognition with invariance
to pose and lighting. In Proceedings of the 2004 IEEE
Computer Society Conference on Computer Vision and
Pattern Recognition, 2004. CVPR 2004., volume 2,
pages II–104. IEEE, 2004.

[64] Dayeol Lee, Dongha Jung, Ian T Fang, Chia-Che Tsai,
and Raluca Ada Popa. An off-chip attack on hardware
enclaves via the memory bus.
USENIX
Security Symposium (
}
{

In 29th
USENIX
}
{
Security 20), 2020.

[65] John A Lee and Michel Verleysen. Nonlinear dimen-
sionality reduction. Springer Science & Business Me-
dia, 2007.

[66] Bochen Li, Xinzhao Liu, Karthik Dinesh, Zhiyao Duan,
and Gaurav Sharma. Creating a multitrack classical mu-
sic performance dataset for multimodal music analysis:
Challenges, insights, and applications. IEEE Transac-
tions on Multimedia, 21(2):522–535, 2018.

[67] Haoqi Li, Brian Baucom, and Panayiotis Georgiou.
Unsupervised latent behavior manifold learning from
acoustic features: Audio2behavior. In 2017 IEEE in-
ternational conference on acoustics, speech and signal
processing (ICASSP), pages 5620–5624. IEEE, 2017.

17

[68] Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang
Cao, and Shuzi Niu. Dailydialog: A manually la-
belled multi-turn dialogue dataset. arXiv preprint
arXiv:1710.03957, 2017.

[69] libjpeg. Main libjpeg-turbo repository, 2020.
[70] Tong Lin and Hongbin Zha. Riemannian manifold
learning. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 30(5):796–809, 2008.

[71] Tsung-Yi Lin, Michael Maire, Serge Belongie, James
Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and
C Lawrence Zitnick. Microsoft COCO: Common ob-
jects in context. In European conference on computer
vision, pages 740–755. Springer, 2014.

[72] Chang Liu, Austin Harris, Martin Maas, Michael Hicks,
Mohit Tiwari, and Elaine Shi. Ghostrider: A hardware-
software system for memory trace oblivious computa-
tion. ACM SIGPLAN Notices, 50(4):87–101, 2015.

[73] F. Liu, Q. Ge, Y. Yarom, F. Mckeen, C. Rozas,
G. Heiser, and R. B. Lee. Catalyst: Defeating last-
level cache side channel attacks in cloud computing.
In HPCA, 2016.

[74] Fangfei Liu, Y. Yarom, Qian Ge, G. Heiser, and R.B.
Lee. Last-level cache side-channel attacks are practical.
In 2015 IEEE Symposium on Security and Privacy,
pages 605–622, May 2015.

[75] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou
Tang. Deep learning face attributes in the wild. In
Proceedings of International Conference on Computer
Vision (ICCV), December 2015.

[76] Chi-Keung Luk, Robert Cohn, Robert Muth, Harish
Patil, Artur Klauser, Geoff Lowney, Steven Wallace,
Vijay Janapa Reddi, and Kim Hazelwood. Pin: build-
ing customized program analysis tools with dynamic
instrumentation. In Proceedings of the 2005 ACM SIG-
PLAN conference on Programming language design
and implementation (PLDI’05), 2005.

[77] Houssem Maghrebi, Thibault Portigliatti, and Em-
manuel Prouff. Breaking cryptographic implementa-
tions using deep learning techniques. In International
Conference on Security, Privacy, and Applied Cryptog-
raphy Engineering, pages 3–26. Springer, 2016.
[78] Francisco J Martinez-Murcia, Andres Ortiz, Juan-
Manuel Gorriz, Javier Ramirez, and Diego Castillo-
Barnes. Studying the manifold structure of alzheimer’s
disease: A deep learning approach using convolutional
autoencoders. IEEE journal of biomedical and health
informatics, 24(1):17–26, 2019.

[79] Ahmad Moghimi, Gorka Irazoqui, and Thomas Eisen-
barth. CacheZoom: How sgx ampliﬁes the power of
cache attacks. In International Conference on Cryp-
tographic Hardware and Embedded Systems (CHES’
17), 2017.

[80] David Molnar, Matt Piotrowski, David Schultz, and
David Wagner. The program counter security model:

Automatic detection and removal of control-ﬂow side
channel attacks. In ICISC, 2005.

[81] Andrew C Myers. JFlow: Practical mostly-static in-
In Proceedings of the 26th
formation ﬂow control.
ACM SIGPLAN-SIGACT symposium on Principles of
programming languages, pages 228–241, 1999.

[82] Openssl. https://www.openssl.org/.
[83] Yossef Oren, Vasileios P Kemerlis, Simha Sethumadha-
van, and Angelos D Keromytis. The spy in the sandbox:
Practical cache attacks in javascript and their implica-
tions. In Proceedings of the 22nd ACM SIGSAC Con-
ference on Computer and Communications Security,
pages 1406–1418, 2015.

[84] D Page. Partitioned cache architecture as a ˙eide-

channel defence mechanism. 2005.

[85] Stjepan Picek, Ioannis Petros Samiotis, Jaehun Kim,
Annelie Heuser, Shivam Bhasin, and Axel Legay. On
the performance of convolutional neural networks for
side-channel analysis. In International Conference on
Security, Privacy, and Applied Cryptography Engineer-
ing, pages 157–176. Springer, 2018.

[86] Himanshu Raj, Ripal Nathuji, Abhishek Singh, and
Paul England. Resource management for isolation
enhanced cloud services. In CCSW, 2009.

[87] Ashay Rane, Calvin Lin, and Mohit Tiwari. Rac-
coon: Closing digital side-channels through obfuscated
Security Symposium
USENIX
execution.
{
USENIX
(
}
{

In 24th
}
Security 15), pages 431–446, 2015.

[88] Sam T Roweis and Lawrence K Saul. Nonlinear di-
mensionality reduction by locally linear embedding.
science, 290(5500):2323–2326, 2000.

[89] Andrei Sabelfeld and Andrew C Myers. Language-
IEEE Journal on
based information-ﬂow security.
selected areas in communications, 21(1):5–19, 2003.
[90] Yuki Saito, Shinnosuke Takamichi, and Hiroshi
Saruwatari.
Statistical parametric speech synthe-
sis incorporating generative adversarial networks.
IEEE/ACM Transactions on Audio, Speech, and Lan-
guage Processing, 26(1):84–96, 2017.

[91] Florian Schroff, Dmitry Kalenichenko, and James
Philbin. Facenet: A uniﬁed embedding for face recog-
nition and clustering. In Proceedings of the IEEE con-
ference on computer vision and pattern recognition,
pages 815–823, 2015.

[92] Michael Schwarz, Moritz Lipp, Daniel Gruss, Samuel
Weiser, Clémentine Maurice, Raphael Spreitzer, and
Stefan Mangard. KeyDrown: Eliminating software-
based keystroke timing side-channel attacks. In NDSS,
2018.

[93] Michael Schwarz, Samuel Weiser, Daniel Gruss, Clé-
mentine Maurice, and Stefan Mangard. Malware guard
extension: Using sgx to conceal cache attacks. arXiv
preprint arXiv:1702.08719, 2017.

18

[94] Dongdong She, Yizheng Chen, Abhishek Shah,
Baishakhi Ray, and Suman Jana. Neutaint: Efﬁcient
dynamic taint analysis with neural networks. In 2020
IEEE Symposium on Security and Privacy (SP), pages
1527–1543. IEEE, 2020.

[95] Dongdong She, Kexin Pei, Dave Epstein, Junfeng Yang,
Baishakhi Ray, and Suman Jana. NEUZZ: Efﬁcient
fuzzing with neural program smoothing. In Proceed-
ings of the 40th IEEE Symposium on Security and
Privacy (S&P ’19), 2019.

[96] Yujun Shen, Jinjin Gu, Xiaoou Tang, and Bolei Zhou.
Interpreting the latent space of gans for semantic face
editing. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition, pages
9243–9252, 2020.

[97] Elaine Shi. Path oblivious heap: Optimal and practical
oblivious priority queue. In 2020 IEEE Symposium
on Security and Privacy (SP), pages 842–858. IEEE,
2020.

[98] Emil Stefanov, Marten Van Dijk, Elaine Shi, Christo-
pher Fletcher, Ling Ren, Xiangyao Yu, and Srinivas
Devadas. Path ORAM: an extremely simple oblivi-
ous ram protocol. In Proceedings of the 2013 ACM
SIGSAC conference on Computer & communications
security, pages 299–310, 2013.

[99] Joshua B Tenenbaum, Vin De Silva, and John C Lang-
ford. A global geometric framework for nonlinear
dimensionality reduction. science, 290(5500):2319–
2323, 2000.

[100] Nicolas Thorstensen. Manifold learning and applica-
tions to shape and image processing. PhD thesis, Ecole
des Ponts ParisTech, 2009.

[101] Kris Tiri and Ingrid Verbauwhede. Securing encryption
algorithms against dpa at the logic level: Next genera-
tion smart card technology. In International Workshop
on Cryptographic Hardware and Embedded Systems,
pages 125–136. Springer, 2003.

[102] Eran Tromer, DagArne Osvik, and Adi Shamir. Ef-
ﬁcient cache attacks on AES, and countermeasures.
Journal of Cryptology, 23(1):37–71, 2010.

[103] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz
Kaiser, and Illia Polosukhin. Attention is all you need.
arXiv preprint arXiv:1706.03762, 2017.

[104] Shuai Wang, Yuyan Bao, Xiao Liu, Pei Wang, Dan-
feng Zhang, and Dinghao Wu. Identifying cache-based
side channels through secret-augmented abstract in-
terpretation. In 28th
Security Symposium
USENIX
{
(
{

Security 19), pages 657–674, 2019.

[105] Shuai Wang, Pei Wang, Xiao Liu, Danfeng Zhang, and
Dinghao Wu. CacheD: Identifying cache-based timing
In 26th USENIX
channels in production software.
Security Symposium, pages 235–252, 2017.

USENIX
}

}

[106] Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu,
Mohammadhadi Bagheri, and Ronald M Summers.
Chestx-ray8: Hospital-scale chest x-ray database and
benchmarks on weakly-supervised classiﬁcation and
localization of common thorax diseases. In Proceed-
ings of the IEEE conference on computer vision and
pattern recognition, pages 2097–2106, 2017.
[107] Zhenghong Wang and Ruby B. Lee. Covert and side
In ACSAC,

channels due to processor architecture.
2006.

[108] Zhenghong Wang and Ruby B. Lee. New cache de-
signs for thwarting software cache-based side channel
attacks. In ISCA, 2007.

[109] Zhenghong Wang and Ruby B Lee. A novel cache
architecture with enhanced performance and security.
In MICRO, 2008.

[110] Zhou Wang, Alan C Bovik, Hamid R Sheikh, and
Eero P Simoncelli. Image quality assessment: from er-
ror visibility to structural similarity. IEEE transactions
on image processing, 13(4):600–612, 2004.

[111] Pete Warden.

Speech commands: A dataset for
limited-vocabulary speech recognition. arXiv preprint
arXiv:1804.03209, 2018.

[112] Daniel Weber, Ahmad Ibrahim, Hamed Nemati,
Michael Schwarz, and Christian Rossow. Osiris: Auto-
matic Discovery of Microarchitectural Side Channels.
In USENIX Security Symposium, 2021.

[113] Jan Wichelmann, Ahmad Moghimi, Thomas Eisen-
barth, and Berk Sunar. MicroWalk: A framework for
ﬁnding side channels in binaries. In ACSAC, 2018.

[114] Sanghyun Woo, Jongchan Park, Joon-Young Lee, and
In So Kweon. Cbam: Convolutional block attention
module. In Proceedings of the European conference
on computer vision (ECCV), pages 3–19, 2018.
[115] Lichao Wu and Stjepan Picek. Remove some noise:
On pre-processing of side-channel measurements with
autoencoders. IACR Transactions on Cryptographic
Hardware and Embedded Systems, pages 389–415,
2020.

[116] Zhenyu Wu, Zhang Xu, and Haining Wang. Whispers
in the hyper-space: High-speed covert channel attacks
in the cloud. In Presented as part of the 21st USENIX
Security Symposium (USENIX Security 12), pages 159–
173, 2012.

[117] Yuanzhong Xu, Weidong Cui, and Marcus Peinado.
Controlled-channel attacks: Deterministic side chan-
nels for untrusted operating systems. In 2015 IEEE
Symposium on Security and Privacy, pages 640–656.
IEEE, 2015.

[118] Guang Yang, Huizhong Li, Jingdian Ming, and Yong-
bin Zhou. Convolutional neural network based side-
channel attacks in time-frequency representations. In
International Conference on Smart Card Research and
Advanced Applications, pages 1–17. Springer, 2018.

[119] Yuval Yarom. Mastik: A micro-architectural side-
channel toolkit. Retrieved from School of Computer Sci-
ence Adelaide: http://cs.adelaide.edu.au/yval/Mastik,
16, 2016.

[120] Yuval Yarom and Katrina Falkner. FLUSH+RELOAD:
A high resolution, low noise, L3 cache side-channel
attack. In Proceedings of the 23rd USENIX Conference
on Security Symposium, pages 719–732, 2014.
[121] Yuval Yarom, Daniel Genkin, and Nadia Heninger.
Cachebleed: a timing attack on openssl constant-time
rsa. Journal of Cryptographic Engineering, 7(2):99–
112, 2017.

[122] Yuanyuan Yuan, Qi Pang, and Shuai Wang. Auto-
mated side channel analysis of media software with
manifold learning. In 31st USENIX Security Sympo-
sium (USENIX Security 22), Boston, MA, August 2022.
USENIX Association.

[123] Yuanyuan Yuan, Shuai Wang, and Junping Zhang. Pri-
vate image reconstruction from system side channels
using generative models. In International Conference
on Learning Representations, 2021.

[124] Yinqian Zhang, Ari Juels, Michael K. Reiter, and
Thomas Ristenpart. Cross-VM side channels and their
use to extract private keys. In Proceedings of the 2012
ACM Conference on Computer and Communications
Security, pages 305–316, 2012.

[125] Bo Zhu, Jeremiah Z Liu, Stephen F Cauley, Bruce R
Rosen, and Matthew S Rosen.
Image reconstruc-
tion by domain-transform manifold learning. Nature,
555(7697):487–492, 2018.

[126] Jun-Yan Zhu, Philipp Krähenbühl, Eli Shechtman, and
Alexei A Efros. Generative visual manipulation on the
natural image manifold. In European conference on
computer vision, pages 597–613. Springer, 2016.

Figure 8: Project face photos to a two-dimensional manifold.

19

-0.9-0.8-0.7-0.6-0.5-0.4-0.3-0.2-0.10-1-0.8-0.6-0.4-0.200.20.40.60.81as shown in Fig. 9, after launching dimensionality reduction
with manifold learning, two classes of MNIST images are
well separated into distinct groups.

B Discussion about Perception Blinding

Sec. 4.3 introduces perception blinding, as an effective miti-
gation to defeat our proposed SCA. In this appendix section,
we further clarify the usage of perception blinding by dis-
cussing the workﬂow of applying perception blinding in real
systems. We then give discussions about its usage and other
considerations.

(cid:9)

Workﬂow. Fig. 10 depicts the detailed workﬂow. As already
clariﬁed in Sec. 4.3, to use perception blinding, users only
need to pick one mask imask to blind all input data. (cid:182) A user
ﬁrst picks this universal mask imask and processes it with the
to-be-protected media software P to pre-compute P(imask). (cid:183)
Then, before processing any private input iprivate with P, a user
” it with imask locally to get iblinded, and then feed
should “
iblinded to P. (cid:184) As introduced in Sec. 4.3, irecons reconstructed
by the attacker will mostly retain perception contents of imask.
(cid:185) In contrast, to get the desired output P(iprivate), a user only
needs to “

” the pre-computed P(imask) from P(iblinded).

⊕

Application Scope. By masking media data, perception blind-
ing is designed to effectively mitigate manifold learning-based
SCA (see evaluation in Sec. 6.3). We notice some existing side
channel attacks toward media software [45, 117] which exten-
sively relies on manual efforts. Perception blinding may not
be effective to mitigate those works, given those attacks gen-
erally conduct data byte-level inference. If data bytes can be
losslessly recovered, privacy leakage could still occur, though
such data byte-level reconstruction generally involves consid-
erable manual efforts [45,117]. In contrast, as will be reported
in Appx. D, our well-trained framework takes less than 10
seconds to reconstruct 2,000 media inputs. Also, our pro-
posed perception blinding is not applicable to protect crypto
libraries. Unlike media data, the feasibility of deﬁning and
extracting “perceptions” over private keys is unclear. Standard
blinding techniques (e.g., RSA blinding [21]) should be used
to prevent crypto systems from SCA.

“White-Box” Attackers. Readers may wonder what if a
“white-box” attacker trains autoencoder with the dataset that
includes imask. We clarify that the mitigation should still be
effective, whose reasons are threefold. First, since users ran-
domly choose masks, it’s impossible for attackers to guess
what the mask is. Second, if attackers use a training dataset
containing imask but don’t know which one it is, our percep-
tion blinding still works. Third, suppose this particular imask
is known, attackers will need to mask all training data and
”
re-train another model, leading to a high cost. Note that “
(cid:9)
imask from irecons will not get iprivate, because “
” operates
on byte-level rather than perception-level. To understand this,
suppose iprivate is a human face photo toward left, whereas the

(cid:9)

20

Figure 9: Applying PCA on two classes of images from
MNIST dataset.

A Empirical Exploration of Manifold Hypoth-

esis

M

This section empirically explores the validity of the manifold
hypothesis. In Fig. 8, a set of real-world face images is pro-
jected onto manifold
img of two dimensions. To draw this
projection, we adjust our autoencoder framework (see Sec. 4)
to convert each face image into a latent representation of two
dimensions. We observe that the images are generally dis-
tinguished by skin and hair colors, and face orientations are
roughly decomposed into two orthogonal directions (green
and red lines). For instance, the photos at the bottom right
and bottom left are grouped together with similar hair col-
ors but are further differentiated due to differences in skin
colors and face directions. Overall, we interpret that Fig. 8
provides clear evidence that our autoencoder frameworks can
capture key perception features of complex high-dimensional
media data. In addition, because 2D projections are highly
condensed for real-world large datasets, we expect to ﬁnd
greater discrimination for higher dimensions (e.g., 64).

In fact, recent studies have shown the effectiveness of con-
ducting image editing by ﬁrst projecting image samples into
the manifold space [96, 126]. Editing images in the high-
dimensional space involves a large search space [0, 255] for
each pixel; the random selection of pixel values in the range
[0, 255] struggles to create realistic images because arbitrary
editing could “fall off” the manifold of natural images. In
contrast, manifold learning facilitates sampling within
,
M
conﬁne the
and the perceptually meaningful contents in
manipulations to generate mostly realistic images [96, 126].
Furthermore, as introduced in Sec. 3, the manifold learning
hypothesis also assumes that after casting high-dimensional
data into their low-dimensional space (i.e., manifolds), data
of different classes can be well separated whereas data of
the same class generally lies in the same manifold [100].
Accordingly, our preliminary study conﬁrmed this hypothesis:

M

Figure 10: Workﬂow of perception blinding.

human face in imask is toward right. As a result, face recovered
in irecons should be toward right as well. It’s easy to see that
“
(cid:9)

” imask from irecons will not ﬂip the face direction.

C Attack Setup

We give a general introduction of each side channel adopted
in our attack as follows:

(cid:29)

Cache Bank. Cache bank generally denotes the minimal stor-
age unit of modern CPU caches and has been exploited by
real-world attacks [121]. Assume a program memory address
L bits map a mem-
has N bits, then typically the upper N
ory access to its corresponding cache bank access. In this
research, we adopt a common setting for most CPUs on the
market where L is 2. That is, given a memory address addr,
its cache bank index can be computed as addr

−

2.

Cache Line. Similar to cache bank, attackers can also log
all the accessed cache line indexes for exploitation [45, 120].
For modern CPUs whose cache-line size is usually 64, the
cache line index of a memory address addr can be computed
as addr

6.

(cid:29)

Page Table. Program virtual memory accesses are converted
into corresponding physical memory accesses by querying the
OS page table. Given an adversarial-controlled OS, a practical
high-resolution side channel is to keep track of all accessed
page table entries made by the media software [117]. Given
a memory access with address addr, the induced page table
index can be calculated by masking addr with PAGE_MASK m:
addr & (
Media Software and Inputs. We use libjpeg, a widely-
used image processing library, to process two image datasets
CelebA and Chest X-ray. CelebA comprises 10,000 different
celebrities, with 20 images of each. Chest X-ray comprises
real-life X-ray images that are used for screening and diag-
nosis of many lung diseases. In addition, we use a popular

m), where m set as 4095 [6].

∼

media software, FFmpeg, to process two audio datasets, SC09
and Sub-URMP. Both datasets are commonly-used in bench-
marking audio synthesis and analysis research [26, 27, 38].
SC09 denotes real-world “speech commands.” It contains
single spoken words from 0—9 by various speakers in real-
life scenarios. Sub-URMP consists of audio recordings of
13 musical instruments, such as double bass, viola, and vio-
lin. Hunspell, a popular spell checker used by commercial
software, such as Google Chrome, OpenOfﬁce, and LibreOf-
ﬁce, is also exploited in this research. We use two datasets,
COCO and DailyDialog, as the inputs of Hunspell. COCO
is a popular large-scale dataset that contains images and text
descriptions. Each image is associated with three to eight
manually-annotated sentences. Each sentence contains a num-
ber of object and attribute names that denote how humans
would describe a photograph of a real-world scenario. The
DailyDialog dataset contains real-life multi-turn dialogues,
which reﬂect daily communication and cover various topics.

Tools Used in Evaluations. We leverage Face++ [5], a com-
mercial face recognition API, to calculate the similarity score
between reconstructed face photos and reference inputs. We
clarify that the implementation details of Face++ is not dis-
closed. To decide the diseases of reconstructed X-ray images
and reference images, we reuse the tool provided by the cham-
pion of CheXpert competition [4]. This tool can categorize the
disease of X-ray images and localize corresponding lesions.

When launching quantitative evaluation to measure the
privacy leakage of reconstructed audio data, we launch an
experiment to train two classiﬁers for speaker identity and
command 0–9 matching. This denotes a typical setup of iden-
tity de-anonymization attack [123]. We now report the details
of two classiﬁers. To classify the content of each human voice,
we reuse the architecture of our “Privacy-Aware Indicator” in
Sec. 4.1. The classiﬁer is trained on reference audio record-
ings to achieve over 98% testing accuracy. We then use the
trained classiﬁer to classify the reconstructed audio. Note that

21

i1privateinprivatei1blindedinblindedimaskP(i1blinded)P(i1private)P(imask)MediaSoftwarePP(inblinded)P(inprivate)imaskP(imask)MediaSoftwarePinreconsi1reconsthe identities of training and testing splits are not overlapped,
and we modify the training objective based on a face recogni-
tion model [91]. When evaluating, the accuracy is calculated
as how many reconstructed audio recordings yield a similarity
score that is higher than 50% with its reference audio (i.e.,
the correct match).

In addition, when quantitatively evaluating the musical
instrument types of reconstructed audio using the Sub-URMP
dataset, we also reuse the architecture of “Privacy-Aware
Indicator” and train the classiﬁer on reference audio to achieve
a testing accuracy higher than 98%. Then, the trained classiﬁer
is used to classify the reconstructed audio clips.

D Prime+Probe Attack Details

In this section, we clarify the detailed setup of our
Prime+Probe attack. We consistently assume that attackers
can ﬁrst train the autoencoder framework with cache side
channel locally collected via Prime+Probe toward victim
software, but do not need the source code. Then, the attacker
launches Prime+Probe toward the target media software to
log cache side channels when it is processing an unknown in-
put. The unknown input will be reconstructed from the logged
cache side channels.

Probing the L1I and L1D Caches. We use Mastik [119]
to launch Prime+Probe attack towards L1D cache and L1I
cache on Intel Xeon and AMD Ryzen CPU. We use Linux
taskset to pin the victim software and a spy process to the
same CPU core. We take a common assumption [102] that
attackers know when the victim media software begins and
ends to process an unknown input. The spy process primes
and probes the cache. Technically, there is another “coor-
dinator” process on the same core which computes victim
process’s cache activities and logs the cache side channels to
disk. Nevertheless, according to our observation, this coordi-
nator process has generally consistent cache access patterns,
and therefore, its mostly ﬁxed cache access does not interfere
with our well-trained autoencoder.

The thresholds of deciding cache hit and cache miss are 120
CPU cycles on Intel Xeon CPU and 100 CPU cycles on AMD
Ryzen CPU. Prime+Probe is performed in the following
manner:

PRIME: The spy process ﬁlls all cache sets.
IDLE: The attacker logs the access time of all cache sets
for the previous Prime+Probe iteration. As a result, the idle
phase interval equals the duration of performing one ﬁle I/O
operation. Meanwhile, the cache is utilized by the victim.

PROBE: The spy process reﬁlls all cache sets and times
the duration to reﬁll the same cache sets to learn how victim
accesses cache sets.

For a cache set, the logged cache status ﬂip, from hit to
miss, indicates at least one cache access of victim. We are
thus particularly interested in logging such status ﬂip. We

name such cache status ﬂips as “cache activity” in the rest of
this paper. Whenever a cache activity is observed, we record
the cache activities of the all cache sets into a vector V , whose
length equals to the number of cache sets. V [i] = 1 indicates
there is a cache activity in i-th cache set. In other words, the
i-th cache set is accessed at least one time by the victim. If
no cache activity is observed from any cache set, we omit to
generate a new V .

Cache Set Activities Logged by Prime+Probe. Fig. 11
presents a recorded sequence of vectors V on L1D cache of
Intel Xeon CPU when FFmpeg is processing an audio input.
Here, each row represents a cache set and each column is a
recorded V . The color block indicates there is a cache activity.
Consequently, the logged side channel trace of L1 cache is in
the format of a binary matrix, where bit 1 represents a cache
activity. The binary matrix is taken as the input of our frame-
work in an end-to-end manner. See Appx. F for clariﬁcation
on representation of side channel traces and how they are
fed into the encoding step. Furthermore, the code of launch-
ing Prime+Probe is released at [3] for result veriﬁcation and
beneﬁting future research.

Statistics of Logged Cache Side Channels. Table 15
presents the mean, the standard deviation and the matrix en-
coding of logged side channel traces under different settings.
Overall, the standard deviation of trace length is seen as high.
This indicates the difﬁculty of exploiting real-world media
software. In general, different inputs can lead to the execution
of different code paths, which further induce unaligned cache
accesses. To ease the deviation of Prime+Probe, we take a
simple but effective trick to repeatedly execute media software
with the same input for t times and concatenate the logged
side channels as one input of our framework. The value of t
is set to 8 for libjpeg and Hunspell, and 4 for FFmpeg. In
particular, when benchmarking FFmpeg, the stddev can grow
to half of the average trace length. We view this explains
the relatively low attack accuracy of attacking FFmpeg using
cache side channels recovered by Prime+Probe: as shown
in Table 12, attack accuracies toward FFmpeg are generally
below 15% except the Intel CPU & L1D Cache setting.

Workload. We have reported the workload in Table 12, where
the incurred execution slowdown is generally within 2 to
10 times compared with the normal execution. Overall, all
three media software benchmarked in this study is much
complex than crypto libraries like AES. With more cache
accesses occurring during execution, cache misses incurred
by Prime+Probe attack can presumably slowdown the ex-
ecution of victim software in an effective way. In particu-
lar, our attack on FFmpeg incurs relatively larger slowdown.
This is reasonable: FFmpeg, as the most complex software
among these three, produce a large volume of cache ac-
cesses, which, accordingly increase the slowdown due to nu-
merous cache misses. Nevertheless, we still point out that
even for the FFmpeg case, the average slowdown incurred by

22

Figure 11: Cache set activities of FFmpeg logged by Prime+Probe on Intel CPU L1D cache. Colored blocks denote cache access
activities, i.e., “hit” ﬂips to “miss”. We use different colors to differentiate different cache sets.

stddev) and matrix encoding of cache side channel traces logged by Prime+Probe. Each trace is
Table 15: Statistics (mean
a sequence of vector with length 64. Note that the #training and #test splits in each of the evaluation setting are the same as
statistics reported in Table 3.

±

libjpeg(

×

8)
AMD

L1I Cache

L1D Cache

1

1

Intel

2719

745

±
256

256

×
780

×
137

±
256

×

×

256

1114

290

±
256

256

×
5750

×
931

±
256

256

1

4

×

×

Intel

44315
8
×
8837
2

×

±
512

±
512

23374
512
×
3050
512

×

FFmpeg(

4)

×

AMD

Intel

Hunspell(

×

8)
AMD

7013
2
×
46698
8

×

±
512

±
512

2540
512
×
35163
512

×

4834
4

±
256

1788
256

×
3739

×
164

±
256

256

4

×

×

1865

432

±
256

2
×
9732
8

±
256

256
×
1498
256

×

×

Prime+Probe is about 500 milliseconds. We have demon-
strated the highly effective Prime+Probe attack results to-
ward these media software in Sec. 6.4. To reduce the slow-
down and deliver more stealthy attacks, attackers can prolong
the idle phase of Prime+Probe.

Running Time. In general, running time primarily includes
two aspects: 1) online side channel logging and 2) ofﬂine
model training. To collect side channels for training, we spend
54 hours for libjpeg, 36 hours for FFmpeg, and 100 hours
for Hunspell on one CPU core. We note that processing and
converting the logged lengthy traces into “Tensor”, the le-
gitimate input format of PyTorch, takes several extra hours.
After excluding those ﬁle processing cost, the logging du-
ration is 9 hours, 12 hours, 27 hours for libjpeg, FFmpeg
and Hunspell, respectively. As a research prototype, we use
Python for those tedious ﬁle processing task. To speed up,
users can re-write those codes in C, if needed. The ofﬂine
model training takes 10 hours.

The “training phases” using cache side channels collected
by Prime+Probe can likely take several hours to several
days: for instance, Zhang et al. [124] spend six to 46 hours
for the training phase when launching Prime+Probe to ex-
tract crypto keys. Media software is generally more complex
than crypto libraries. We attribute our promising training cost
(comparable to [124]) to: 1) recent advances in neural net-

works and the underlying high-quality deep learning frame-
work PyTorch, and 2) better hardware acceleration since we
use one Nvidia GeForce RTX 2080 GPU for training. The
“testing phase” of Prime+Probe, i.e., reconstructing the un-
known input by using a cache side channel trace logged by
Prime+Probe, takes less than 10 seconds to reconstruct in
total 2,000 media inputs.

Qualitative Evaluation Results. We have presented quanti-
tative evaluation results using Prime+Probe-recovered cache
side channels in Table 12. Most extra (qualitative) evaluation
results for attacks based on Pin-logged traces are reported
in Appx. G. For the seek of readability, we discuss the qual-
itative results, in terms of reconstructed media data using
Prime+Probe attack, in this section. Particularly, Fig. 12 and
Fig. 13 report reconstructing CelebA face photos on different
CPUs. We interpret the reconstruction results as generally
promising: a considerable number of visual perceptions are
faithfully retained in the reconstructed images, which include
gender, face orientation, skin color, nose shape, and hair styles.
There is a bit quality degradation on some images, for in-
stance, facial details (e.g., the appearance of teeth) are not
always precisely aligned with reference inputs. However, we
emphasize that images reconstructed under four settings all
manifest comparable visual quality, indicating high feasibility
of applying our framework on the basis of commonly-used

23

063CachesetnumbersAdjacentcachesetactivitiesFigure 12: Reconstructed images on L1 cache of Intel Xeon CPU. We can observe highly correlated visual appearances, including
gender, face orientation, skin color, nose shape, and hair styles.

Table 16: Musical instrument type matching evaluation re-
sults.

Content accuracy

Cache bank Cache line Page table
32.8%

32.7%

33.4%

side channels. The qualitative results are also consistent with
results reported in Table 12 — though the attack is launched
on different CPUs and different caches, privacy leakage is
steadily notable.

E PathOHeap Setup

Sec. 6.5 explored using PathOHeap to mitigate our proposed
SCA. PathOHeap, as a popular ORAM protocol, enforces
probabilistic memory trace obliviousness, such that it converts
input-dependent memory access traces into indistinguishable
traces that provably hide input-dependent memory access
behavior and information leakage.

We study how ORAM can mitigate our SCA exploitation
on libjpeg. Our tentative study shows that it takes over one
hour to process the entire memory trace using PathOHeap
but cannot ﬁnish. Hence, we separately extract two key func-
tions from localized vulnerable modules, IDCT and MCU, that
primarily contribute to attacking libjpeg (see Table 7). We
thus collect much shorter memory access traces correspond-
ing to each function. We then pad all traces to the same length
(which is required by ORAM protocols) and use PathOHeap
to convert each logged memory access trace into an indis-
tinguishable memory trace, which takes about one minute to
process. We then convert the original memory traces and their
corresponding ORAM outputs into cache line access traces,

and re-launch our SCA exploitation to recover libjpeg input
images.

F Side Channel Representation & Encoder

Design

This section clariﬁes the representations of input side chan-
nels. We also provide empirical results to explain why the
representations work well in our research context.

As aforementioned in the evaluation, we launch attacks
using side channel traces logged by Pin; this can mimic pre-
vious attacks where privileged system software, e.g., OS ker-
nels, are controlled by adversaries [45, 117]. We also launch
standard Prime+Probe attack to benchmark userspace-only
scenarios [102, 124]. As shown in Fig. 14, each side channel
trace collected by Pin contains a sequence of records, and
each record denotes one accessed cache unit or page table
entry index. Fig. 14 further shows how side channel logs
are collected and organized using Prime+Probe attack. Here,
each trace composes a sequence of binary vectors V , where
the cardinality
of each vector equals the number of cache
sets (the value is 64 in our CPU). V [i] = 1 indicates the i-th
cache set is accessed by victim.

V
|

|

Encoder Design & Clariﬁcation on Its Noise Resiliency

Our autoencoder framework is shown as effective to compre-
hend even lengthy side channel records logged by either Pin
or Prime+Probe: side channel traces are lengthy albeit highly
sparse, where only a few elements are secret-dependent. Also,
the secret-dependent records are not always aligned, given

24

Reference inputsReconstructed onIntelL1 IcacheReconstructed onIntelL1 DcacheFigure 13: Reconstructed images on L1 cache of AMD Ryzen CPU. Again, visual appearances in the reconstructed images are
correlated with reference inputs, including gender, face orientation, skin color, nose shape, and hair styles.

that inputs of different values may lead to executing differ-
ent paths. Hence, the secret-dependent records may appear
at different (relative) locations on a trace in accordance with
different inputs. In addition, our noise resilience evaluation
in Sec. 6.6 illustrates highly encouraging robustness and re-
silience of our autoencoder framework toward perturbations
on side channel traces.

×

×

×

In Sec. 4.1, we have clariﬁed that manifold learning itself
manifests high capability of denoising. In this section, we
further analyze the noise resilience from the encoder model
structure perspective. Overall, before feeding a trace (logged
by Pin or Prime+Probe) to our framework, each trace is
ﬁrst folded into a squared matrix with zero-paddings. Fig. 14
depicts how a 2D CNN block of trace encoder φθ operates on
the folded matrix. A Conv2D block has C kernels with each
K (K > 1) and the input is a matrix of shape
of shape K
H. Each kernel has its own parameters and operates
C
H
×
H section of the input. As the standard operation
on one H
(see Fig. 14), the kernel moves on the H
H section step
K regions in a section share
by step, and therefore, all K
×
the same kernel. In general, this classic design ensures an
important property named translation-invariance [63]. As
shown in Fig. 14, suppose the secret-dependent records in the
training traces only appear at the blue locations, the φθ can
still capture secret-dependent records at the red locations in
a testing trace. Therefore, even noise is introduced, the trace is
still sufﬁciently informative unless all privacy-related records
are vanished. In short, the well-known translation-invariance
property enforced by our encoder can properly improve the
generalization and simultaneously guarantee the robustness
towards noise.

×

Table 17: Disease diagnosis matching rates of reconstructed
chest X-ray images w.r.t. (cache bank/cache line/page table)
side channels.

Disease
Precision
Recall
F1 Score

Cardiomegaly Consolidation
0.75/0.76/0.75
0.74/0.74/0.74
0.91/0.91/0.91
0.55/0.55/0.54
0.82/0.82/0.82
0.63/0.63/0.62

Atelectasis
0.83/0.83/0.83
0.67/0.67/0.67
0.74/0.75/0.74

We are not claiming credits from the model design; noise
resilience derived from translation-invariance is well studied
in the AI community [63, 123]. Nevertheless, we spend ef-
forts to explore other possible model structures at this step,
which are seen to manifest lower robustness toward noise. For
instance, each record can be attached to a unique weight (e.g.,
using a fully connected layer or a RNN to process the trace).
Consequently, any small perturbation, potentially due to false
cache hit or wrong orders, is seen to induce notable change in
outputs.

G SCA Results

This Appendix presents more reconstructed media data and
compares them with the reference inputs in Fig. 15, Fig. 16,
Fig. 18, Fig. 19, Fig. 22, and Fig. 23. We also report the quan-
titative evaluation results of Sub-URMP dataset in Table 16.
Similar to the promising results in reconstructing face im-
ages reported in the evaluation section (Sec. 6.3.1), Fig. 15
and Fig. 16 show highly encouraging ﬁndings of recover-
ing chest X-ray images from side channel traces. Overall,
we note that the recovered X-ray images all manifest high

25

Reference inputsReconstructed onAMDL1 IcacheReconstructed onAMDL1 DcacheFigure 14: Representation and processing of side channel traces. Traces collected by Pin and Prime+Probe are marked in
green and yellow , respectively. Two types of traces are processed by trace encoder of the same model structure. In general,
our encoder enforces an important property named translation-invariance. Suppose the secret-dependent records in the training
traces only appear at the blue locations, the φθ can still capture secret-dependent records at the red locations in a testing
trace. Therefore, even noise is introduced, the trace should still be reasonably informative unless all privacy-related records are
completely vanished.

Figure 15: Qualitative evaluation results of Chest X-ray.

Figure 16: Qualitative evaluation results of Chest X-ray.

26

123M[1,0,0,1,…1,0]!123N-2NN-1anaccessed“address”(e.g.,cachelinenumber)foldedfolded1243HH×HC×H×HCKmovemove(a) Fold a trace into a matrix(b) A folded matrix operatedby 2D CNNReconstructed imagesReference inputsReconstructedimagesReferenceinputsFigure 17: Localized lesions of Chest X-ray.

Figure 18: Qualitative evaluation of CelebA.

visual quality and plausible similarity with the reference in-
puts. Chest X-ray images contain generally less perceptual
features compared with CelebA, indicating an easier task for
manifold learning-based dimension reduction. On the other
hand, we note that X-ray images are of high resolution. To get
the best results in disease diagnosis, it is generally required

that the recovered X-ray images preserve original details in
the reference inputs. Table 17 reports the quantitative eval-
uation of chest X-ray images. We check whether the same
kinds of diseases can be diagnosed from the reference and
reconstructed inputs, which would indicate serious privacy
leakage. Considering three diseases listed in Table 17, we

27

Reconstructed(Consolidation)Reference(Consolidation)Reconstructed(Cardiomegaly)Reference(Cardiomegaly)Reconstructed(Atelectasis)Reference(Atelectasis)ReconstructedimagesReferenceinputs ReconstructedimagesReferenceinputs Figure 19: Qualitative evaluation of Sub-URMP. The horizontal axis of each LMS ﬁgure represents time from 0s to 0.5s, while
the vertical axis represents frequency from 0Hz to 8192Hz.

Figure 20: Qualitative evaluation of SC09. The horizontal axis of each LMS ﬁgure represents time from 0s to 1s, while the
vertical axis represents frequency from 0Hz to 8192Hz. The ﬁrst row is LMS ﬁgure of speaking “one”, whereas the second row
is speaking “zero.”

ﬁrst train a disease classiﬁer C (see Appx. C) that achieves
an F1 score above 98.0% over the reference inputs. Then, let
true positive T P be the diagnosis of the same disease d by C
from both reference and reconstructed X-ray images. False
positive FP of a disease d implies that d is diagnosed from
the reconstructed chest X-ray image but not diagnosed from
the input. Similarly, false negative FN indicates that a disease
is diagnosed from the reference input but it does not from
the reconstructed image. We can thus compute the precision
(
T P+FN ), and F1 score (harmonic mean of the
T P+FP ), recall (
precision and recall), respectively. Overall, Table 17 indicates
that accurate disease information can be inferred from the
reconstructed X-ray images.

T P

T P

The high accuracy in conducting disease diagnosis over
reconstructed images in Table 17 indicates a serious leakage

28

of patient’s conﬁdential information. We also localize lesions
(see Appx. C clarifying attack setup at this step) of recon-
structed X-ray images and corresponding reference inputs in
Fig. 17: lesions in reconstructed images and reference inputs
are highly consistent.

Fig. 20 reports the evaluation results of reconstructing au-
dio data in LMS graphs, whose x-axis represents time and
y-axis denotes log-amplitude of frequencies. The references
and reconstructed recordings have mostly consistent LMS
graphs in all cases. As mentioned in Table 3 and Appendix C,
SC09 includes real-world “speech commands”; hence, recov-
ering quality voice recording indicates a strong likelihood
of violating user privacy, such as voice commands. Given
that the LMS graphs of audio clips are usually too dense
to read on paper, we have also released reconstructed audio

DoublebassViolaViolinBassoonBassoonCelloReconstructedaudiosReferenceinputsReference inputsCache bankCache linePage tableFigure 21: Qualitative evaluation of SC09. The horizontal axis of each LMS ﬁgure represents time from 0s to 1s, while the
vertical axis represents frequency from 0Hz to 8192Hz.

Figure 22: Qualitative evaluation of DailyDialog. We mark inconsistent reconstructions.

recordings [3]; interested readers can easily verify that the
reconstructed audio clips exhibit high quality with negligible
noise.

Neglecting Non-Privacy Factors. Our manual inspection on
the reconstructed images also reveal several interesting cases
in As presented in Fig. 24, while the reconstructed images
of celebrity faces are of good quality and highly similar to
the reference inputs, the reconstructed images do not contain
glasses. On one hand, we emphasize that the reconstructed im-
ages can be matched to the reference inputs with above 99.9%
conﬁdence score using the commercial face recognition APIs

provided by Face++. This indicates that the “privacy” re-
lated features that can uniquely recognize human identities
are successfully preserved in the reconstructed photos. More
importantly, we interpret this evaluation has shown the effec-
tiveness of our customized objective functions which aim to
retain speciﬁc privacy indicators. Recall as deﬁned in Table 1,
we enforce our autoencoder framework to particularly retain
human privacy related contents like gender. As a result, our
autoencoder framework narrows the focus to critical features
and facilitates commercial APIs extracting key perceptual

29

ThreeFiveSixSevenEightNineReconstructedaudiosReferenceinputsReconstructed TextReference Input<UNK> I supposed to do now?What am I supposed to do then ?I have, the sunshine and beautiful upme to thehoneymoon . The island , the sound of the <UNK> , the salty styleair and the sunshine  .  .  .You know , the sunshine and wind remind me of our honeymoon . The island , the sound of the waves , the salty sea air and the sunshine  .  .  .Mam , another minute , could I ?Mam , another minute , could I ?It ' slike a good idea . That sounds like a good idea .I <UNK>' t want to insult Jill or her brother. I think Jill ,could be it . But I ' llrather have some tolittle older .I don ' t want to insult Jill or her mother . I think Jill maybe could do it . But I ' d rather have someone a little older .I think it 'be better for finda good babysitter here . It ' be cost , anor three days .I think it would be better to have a good babysitter here . It might even be for two or three days .She isa singlecold , and itdon ' t want to take care tous . But we don ' t like howcan stay with our .She has a bad cold , and we don ' t want to take her with us . But we don ' t know who can stay with her .This is very<UNK>,I have. But Hank and I are leaving tonight .This is short notice , I know . But Hank and I are leaving tonight .I ' m sorry , say that. What ' s wrong with her ?I ' m sorry to hear it . What ' s wrong with her ?Have you ever beena parking ticket ?Have you ever gotten a parking ticket ?Figure 23: Qualitative evaluation results of COCO. We mark consistent reconstructions .

Figure 25: Reconstructed images suffering from over-
smoothing.

Figure 24: Reconstructed images with no glass attached.

contents. Non-privacy factors (e.g., glasses) are generally dis-
couraged to distract the attention of our attack framework.
Ablation Evaluations. Recall in designing objective func-
tions, we explain that using only pairwise distance metrics
can likely generate “over-smoothing” images, thus clarify-
ing the necessity of composing the objective function with
discriminator to implicitly capture the “semantics similarity”
among reference and reconstructed images. Fig. 25 presents
several reconstructed images by only using the pairwise dis-
tance. It is easy to see that the reconstructed images exhibit
low quality compared with sample cases shown in Fig. 15 and
Fig. 20. In particular, it suffers from over-smoothing, where
the details in the LMS images and chest X-ray photos be-
come much blur, comparing with the reference inputs. We
view the results empirically demonstrate the necessity and

strength of adopting hybrid objective functions as the learning
goal of our autoencoder framework. Also, mode collapse may
be potentially introduced by the implicit objective function.
Nevertheless, we clarify that high discriminability of the re-
constructed media data empirically demonstrates that mode
collapse is not a major concern of our framework.

Vulnerable Code. In addition to vulnerable code localized in
FFmpeg and reported in Sec. 6.2, we further report vulnerable
code in libjpeg and Hunspell in Fig. 26 and Fig. 27, respec-
tively. Both code fragments contain obvious input-dependent
memory accesses (we mark program variables derived from
inputs in red). These input-dependent memory accesses fur-
ther lead to the accesses of different cache units or page ta-
ble entries, thus enabling side channel exploitations. To the
best of our knowledge, MCU and putdic, as vulnerable code
fragments of libjpeg and Hunspell, were not pointed out
by existing works [45, 117]. In addition, we identify these

30

Reconstructed TextReference Inputchild withatoiletandsinkbathtub.Small bathroom withatoiletanda sinkA bus take offintothesky.A passenger plane taking offintothesky.A man issitting apictureof <UNK> inabathroom mirror.A woman istaking apictureof herself inabathroom mirror.A <UNK> parked isparkedon the side ofa street.A motorcycle that isparkedon the side ofthe road.A computer sitting and adesktop computeronawooden desk.A laptop computer and adesktop computeronawhite desk.A manin awhite uniformin a base in front ofacrowd.A man in auniformstanding on a motorcycle in front ofacrowd.Fourpeople standing agrassyfield withtreesin the background.Fourgiraffes in agrassyplain withtreesin the background.A manis onacouch talking onacell phone.A mansitting onapost talking onacell phone.A woman standing akitchenpreparingameal.A chef in akitchenpreparingameal.This isapicture ofakitchenwithastove stove.This isapicture ofakitchenwithachrome stove.ReconstructedimagesReferenceinputsReconstructedaudiosReferenceinputsReconstructedimagesReferenceinputs1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28

int HUFF_EXTEND(int x, int s) {

// ‘‘ex_test’’ and ‘‘ex_offset’’ are
// pre−calculated arrays

if (x < ex_test[s])

return x + ex_offset[s];

else

return x;

}

boolean decode_mcu_fast(j_decompress_ptr cinfo,

JBLOCKROW ∗MCU_data) {
huff_entropy_ptr entropy =

(huff_entropy_ptr)cinfo->entropy;

/∗ preprocessing ∗/
for (int i = 0; i < cinfo->blocks_in_MCU; i++)

d_derived_tbl *dctbl = entropy->dc_cur_tbls[i];
int s, k, r, l;
/∗ get index ‘‘idx’’ based on ‘‘s’’ ∗/
/∗ update ‘‘r’’ ∗/

s = dctbl->lookup[idx];
// ‘‘lookup’’ is pre−calculated array
if (s)

s = HUFF_EXTEND(r, s);

}
/∗ do something ∗/

}
/∗ do something and return ∗/

}

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27

boolean check(Hunspell∗∗ pMS, int∗ d, string& token) {
// checking and transforming encoding of ‘‘token’’

if pMs[*d]->spell(token)

return true;

return false;
// ‘‘pMs’’ is a hash table storing the dictionary
// spell() performs spell checking

}

int putdic(const std::string& word, Hunspell∗ pMS) {
// checking and transforming encoding of ‘‘word’’
size_t w = word.find(‘/‘, 1);
if (w == std::string::npos) {

if (word[0] == ‘∗‘)

ret = pMS->remove(word.substr(1));

else

ret = pMS->add(word);

} else {

std::string affix = word.substr(w + 1);
word.resize(w);
if (!affix.empty() && affix[0] == ‘/‘)

affix.erase(0, 1);

ret = pMS->add_with_affix(word, affix);

}
// ‘‘pMs’’ is a hash table storing the dictionary
return ret;

}

Figure 26: Vulnerable code components in libjpeg. We
mark variables depending on libjpeg’s input in red, and
bold input-dependent memory accesses (e.g., line 4).

Figure 27: Vulnerable code components in Hunspell. We
mark variables depending on Hunspell’s input in red, and
bold input-dependent memory accesses (e.g., line 3).

Table 18: Generalization evaluation.

(k, N)
libjpeg
Baseline

(1, 100)
5.7%
1%

(5, 100)
20.3%
5%

(20, 100)
44.1%
20%

stealthy code fragments fully automatically using neural at-
tention mechanisms. This highlights the strength of our neural
approach. And to conﬁrm our ﬁndings, we manually analyzed
how inputs are propagated into certain program variables, and
how those program variables are used to access memory (and
further lead to side channels).

Also, we report all the localized assembly instructions that
primarily contribute to the reconstruction of private inputs.
The corresponding line number of localized assembly instruc-
tions are reported in [3]. We use the default conﬁguration
to compile each media software, whose compiled executable
ﬁle can also be found in our released repository [3]. Hence,
developers can use our reported information and released
executable ﬁles to further localize and patch relevant code
fragments.

Generalization. As explained in Sec. 3, different types of
media data (e.g., human face vs. vehicle photos) are generally
projected toward distinct manifold spaces [14, 88, 99]. Hence,
training a uniﬁed model to recover media data of different
classes are beyond the scope of our SCA.

Figure 28: Reconstructed images on CIFAR-100.

nel traces logged when using libjpeg to process a general
dataset, CIFAR-100 [59]. These side channel traces are used
to train our autoencoder framework and to reconstruct un-
known images in CIFAR-100 from their induced side channel
traces. The CIFAR-100 dataset comprises 60K images of 100
classes. Each class of 600 images is divided into 500 training
images and 100 testing images.

To thoroughly explore the potential limitations, this sec-
tion provides an empirical assessment of the generalization
of our SCA framework. To this end, we collect side chan-

Fig. 28 reports the qualitative evaluation results, by com-
paring the inference inputs with their reconstructed images. In
general, we observed that the reconstructed images manifest

31

Reference inputsReconstructed imagesmuch worse visual quality than those synthesized from spe-
ciﬁc datasets (e.g., CelebA and Chest X-ray). Nevertheless,
we still observed that some expressive features, particularly
sketch and color, are retained in the reconstructed images.

For quantitative evaluation, we use SSIM [110] to assess
similarity between reconstructed images and reference in-
puts. Table 18 reports the evaluation results of determining
whether the reference input appears in the top-k of N (e.g.,
top-5 out of randomly selected 100) images matched with the
reconstructed images. The overall matching rates are high
and greatly outperform the baseline — random guess. These
ﬁndings indicate the promising potential of our approach to
exploit arbitrary datasets and recover conﬁdential user inputs.
Though the reconstructed media data was not visually vivid,
it still notably facilities privacy stealth.

Note that a conventional approach in AI community is to
provide the class label of each image [18]. In short, the model
can switch to proper manifold according to image labels. Our
experiment does not provide class labels and mix all images
together to faithfully explore model’s generalization capabil-
ity. We leave it as one future work to enhance generalization
with labeled data and more advanced models.

H Mitigation

In accordance with Sec. 6.3, Fig. 29 further reports qualitative
evaluation results of perception blinding-based mitigation. In
short, Fig. 29 manifests results and ﬁndings mostly compa-
rable with evaluations launched in Sec. 6.3. That is, “noise
mask” (the ﬁrst row) and “non-face mask” (the second row)
are generally not effective in blinding iprivate; perceptual fea-
tures can be seen in the reconstructed images (e.g., face poses,
hair style). Using real face images from the CelebA dataset
as the masks manifest highly encouraging results to blind key
perceptual-level features. In addition, to recover ﬁnal outputs
(i.e., the “Recovered” columns), a larger α, at least greater
than 0.10, should be desirable.

Regarding quantitative evaluation, Table 19 reports the ad-
versary disease diagnosis results after applying three blinding
masks toward the Chest X-ray dataset. Consistent with our
ﬁndings from the CelebA dataset, using “X-ray#1” image
to blind chest X-ray images can achieve a much better re-
sult to reduce the disease diagnosis accuracy. We also report
the quantitative evaluation results of mitigating DailyDialog
datasets in Table 21, which manifest mostly consistent results
with Table 11.

I Noise Resiliency Evaluation Setup

This section elaborates on the setup of noise resiliency evalua-
tion launched in Sec. 6.6. In sum, we evaluate adding noise to
cache line access traces logged by Pin and cache set access
traces logged via Prime+Probe on Intel L1D cache. First,

.
}

∈ {

given a Pin logged side channel trace, we leverage the fol-
lowing schemes to insert noise into the trace.
Gaussian noise. We perturb every record d on a side channel
trace using d = x
. n is
x)
randomly generated noise following Gaussian distribution.
Removal. We randomly remove x% of the data points on the
side channel, where x
Round shifting. We round shift a side channel trace for x steps,
where x

0.2, 0.5
}

20, 50
}

d, where x

n + (1

10, 100

∈ {

∈ {

×

×

−

.

Note that each noise insertion scheme has two conﬁgura-
tions. For the ease of presentation, we use Low and High to
denote two conﬁgurations, respectively. For instance, Gaus-
sian/High denotes an intensive setting such that we apply
Gaussian noise to perturb side channel traces when x = 0.5.
As for the cache set access traces logged via Prime+Probe,
we also launch the following three perturbation schemes:
Leave cache hit/miss out. We randomly drop x% of the cache
set hit/miss records on the logged trace, where x
.
20, 50
}
False cache hit/miss. We randomly ﬂip x% of records in the
logged cache set access trace, where x
. This way,
}
we create false cache hits/misses.
Wrong order of cache hit/miss. We randomly select x non-
repetitive cache set hit/miss records and compose x/2 pairs of
records, where x
. We then exchange records in
}
each pair.

100, 500

20, 50

∈ {

∈ {

∈ {

Again, each noise insertion scheme has two conﬁgurations,
and we use Low and High to denote the intensity of two con-
ﬁgurations. In addition, we also mimic real-world noise, by
introducing extra workload over the CPU core when launch-
ing Prime+Probe. Particularly, in our exploitation launched
Sec. 6.4, only victim, spy, and coordinator processes occupy
the CPU core. At this step, however, we launch extra processes
on the same CPU core, which can likely introduce a consider-
able amount of noise on the trace. Particularly, we consider
the following three scenarios to systematically explore noise
introduced by real-world workload.
Bzip2. We pick the bzip2 software from SPEC CPU 2006
testsuite to compress a large ﬁle (100MB) simultaneously
when the spy is launching Prime+Probe attack toward victim.
SPEC CPU 2006 is a standard CPU-intensive benchmark suite
that is frequently used in security research.
Victim1. We launch another victim software (e.g., another
libjpeg) on the same core. This victim software will process
the same input simultaneously when the spy is launching
Prime+Probe attack toward victim.
Victim2. We launch another victim software (e.g., another
libjpeg) on the same core. This victim software will process
different inputs simultaneously when the spy is launching
Prime+Probe attack toward victim.

To certain extent, noise introduced by these three work-
loads could have been subsumed by our inserted noise (e.g.,
Gaussian or false cache hits/misses). Nevertheless, we still
launch this evaluation to thoroughly benchmark the noise
resiliency of our SCA.

32

Figure 29: Qualitative evaluation results of perception blinding.

Table 19: Mitigating adversary disease diagnosis attack on Chest X-ray dataset. We report text data inference accuracy in terms
of cache bank/cache line/page table. We use three blinding masks as “Noise” “Non-X-Ray” and a real X-ray photo “X-Ray #1”.

Mask
Noise

Disease
Cardiomegaly
Consolidation
Atelectasis

Non-X-Ray Cardiomegaly
Consolidation
Atelectasis
Cardiomegaly
Consolidation
Atelectasis

X-Ray #1

α = 0.05
0.61/0.55/0.54
0.82/0.82/0.81
0.60/0.60/0.57
0.61/0.54/0.58
0.81/0.81/0.82
0.61/0.55/0.58
0.15/0.19/0.14
0.73/0.83/0.79
0.08/0.07/0.08

α = 0.1
0.61/0.54/0.53
0.82/0.81/0.81
0.60/0.56/0.57
0.63/0.55/0.56
0.82/0.82/0.82
0.65/0.55/0.58
0.20/0.21/0.19
0.74/0.82/0.80
0.12/0.11/0.15

α = 0.3
0.63/0.58/0.53
0.82/0.81/0.81
0.61/0.57/0.55
0.63/0.52/0.51
0.81/0.81/0.81
0.61/0.57/0.54
0.20/0.27/0.20
0.74/0.85/0.83
0.19/0.12/0.14

Table 20: Mitigating human voice matching attack on SC09
dataset with blinding. We report text data inference accuracy
in terms of cache bank/cache line/page table. We use three
blinding masks as “Noise” “Non-Voice” and a real data sam-
ple “Voice”.

Mask
Noise
Non-voice
Voice

α = 0.05

α = 0.1
13.1/12.8/12.9% 15.2/15.3/15.1% 20.3/19.9/20.1%
14.2/13.9/14.1% 17.1/17.0/17.3% 20.2/20.0/19.8%
7.1/7.8/7.6%

7.2/7.0/7.0%

8.7/8.5/9.1%

α = 0.3

Table 21: Mitigating DailyDialog text inference attack. We
report text data inference accuracy in terms of cache bank/-
cache line/page table. α = 0.05 denotes word appended with
total 19 masks. α = 0.1 denotes word appended with total
9 masks, while α = 0.3 denotes word appended with total 2
masks.
Mask
“I”
“you”

α = 0.1
0.19/0.32/0.18% 0.18/0.34/0.19% 0.50/0.88/0.38%
0.22/0.33/0.22% 0.24/0.34/0.26% 0.45/0.72/0.53%

α = 0.05

α = 0.3

We have reported key results in Sec. 6.6 on exploiting
libjpeg and reconstructing CelebA face photos. Fig. 31 re-
ports the corresponding qualitative evaluation results. The
ﬁrst column is the reference input and the second column has
images reconstructed from Pin-logged side channel traces
and Prime+Probe-logged cache side channels with no noise

inserted. Each row represents several conﬁgurations with
the same intensity. Despite the challenging noise insertion
schemes, visually consistent contents (e.g., gender, face ori-
entation, eyes, mouth) between the reconstructed images and
reference inputs can still be observed. When perturbing Pin-
logged traces, reconstructed images under the Round shift-

33

OriginalMaskMaskedRecoveredReconstructedMaskedRecoveredReconstructedMaskedRecoveredReconstructedα= 0.05α= 0.10α= 0.30NoiseMaskNon-faceMaskFace #1MaskFace #3MaskFace #4MaskFace #2MaskFigure 30: Qualitative evaluation results of perception blinding.

Table 22: Quantitative evaluation results of human voice re-
constructed from noisy side channels.

Noise
Gaussian
Shift
Removal
Leave hit/miss out
False hit/miss
Wrong order
Bzip2
Victim1
Victim2

NA

High
Low
28.8% 20.4% 17.0%
28.8% 28.6% 26.3%
28.8% 25.0% 24.5%
81.8% 80.7% 80.0%
81.8% 78.5% 3.4%
81.8% 82.1% 79.9%
81.8%
81.8%
81.8%

66.0%
67.5%
55.8%

Table 23: Quantitative evaluation results of dialog text recon-
structed from noisy side channels.
NA

Noise
Gaussian
Shift
Removal
Leave hit/miss out
False hit/miss
Wrong order
Bzip2
Victim1
Victim2

High
Low
37.4% 35.5% 30.8%
37.4% 25.6% 27.0%
37.4% 32.8% 32.6%
32.2% 32.1% 32.1%
32.2% 32.2% 32.2%
32.2% 32.0% 32.2%
32.2%
32.2%
32.2%

26.4%
26.2%
25.9%

ing scheme retain better visual appearances, indicating bet-
ter noise resilience capability. The Removal scheme, which
extensively removes records in a trace, triggers obvious qual-
ity degradation — some perceptual contents become un-
aligned. Similarly, Gaussian noise, particularly when x = 0.5,
changes the visual appearances. Nevertheless, as we clari-
ﬁed in the paper, visual appearances change do not necessar-
ily indicate attack accuracy degradation: as reported in Ta-
ble 14, we still achieve a reasonably high attack success rates
even in front of Guarantee noise insertion. After introducing
noise into cache side channels collected by Prime+Probe
(with three schemes presented in the third and fourth rows
of Fig. 31), features (e.g., hair style) in reconstructed face
images are still primarily aligned with images reconstructed
without manual noise. Moreover, increasing noise intensity
only leads to negligible changes of facial features. We inter-

pret that these evaluations demonstrate the high resilience of
our autoencoder framework toward noisy settings. See our
discussion below in Noise Resilience Analysis. In addition,
it is shown that stressing Prime+Probe with extra workload
can induce noticeable effect on the reconstructed images. Nev-
ertheless, many perceptual features are still retained in the
reconstructed images. Again, we view the results are generally
consistent with our quantitative evaluation results in Table 14.
See Noise Resilience Analysis below for further discussion.
Table 22 and Table 23 further present evaluation results
on exploiting FFmpeg and Hunspell. Round shifting is more
effective in mitigating SCA toward text data. We note that
round shifting (especially with the High scheme) can pre-
sumably change the “preceding words” of a to-be-predicted
word and is thus more effective in disturbing our decoder
of discrete data (see Fig. 2). In contrast, the reconstructed

34

OriginalMaskMaskedRecoveredReconstructedMaskedRecoveredReconstructedMaskedRecoveredReconstructedα= 0.05α= 0.10α= 0.30NoiseMaskNon-faceMaskFace #1MaskFace #3MaskFace #4MaskFace #2Maskchannel traces are lengthy and highly sparse, where only a
few elements are informative and secret-dependent. Therefore,
the inserted noise does not necessarily break informative data
points. We also report promising results that noise on trace
collected by Prime+Probe (i.e., the middle three rows) im-
poses small inﬂuence in undermining our exploitation, except
the scheme False hit/miss & High on FFmpeg. The similar
encouraging observations can be found from noise introduced
by three real-world workload schemes as well.

→

Noise Resilience Analysis In line with our discussion
on noise resilience offered by manifold learning concept
(Sec. 4.1) and neural trace encoder (Appx. F), Sec. 6.6 and this
appendix section empirically demonstrate the noise resilience
of our attack. We now discuss the noise resilience from the
empirical perspective. First, trace collected by Prime+Probe
is very noisy with high stddev; when training with such
noisy traces, the autoencoder framework is “enforced” to
obtain higher generalization, but may sacriﬁce some accu-
racy. That is, the robustness and noise resilience is indeed
improved when training with side channel records logged via
Prime+Probe. Second, as discussed in Appx. F, the logged
side channel trace is generally sparse. Suppose only “1”, de-
noting a cache hit
miss ﬂip, in a logged trace (collected
by Prime+Probe) contributes to reconstructing media data,
“Leave out” only drops a small portion of 1. For “Wrong
order”, since CNN is translation-invariant (as we have intro-
duced in Appx. F), suppose all parameters in a kernel are 1,
and two exchanged records are in a K
K region, then the out-
put will not change, because “convolution” is element-wise
multiplication followed by a sum function. Third, the results
of FFmpeg increase a lot on Prime+Probe but libjpeg and
Hunspell decrease; this indicates that traces collected using
Prime+Probe toward FFmpeg is more informative. Therefore,
ﬂipping 50% of the records (the High scheme) will more
likely violate patterns learned by our autoencoder framework
despite the translation-invariance. This explains the accu-
racy drop for noise insertion scheme False hit/miss & High.
Again, suppose all parameters in a kernel are 1, since in most
of the cases, the number of 0 is way larger than 1, ﬂipping
records will induce a noticeable impact on the output of con-
volution operations.

×

Figure 31: Evaluation results of CelebA dataset in terms of 9
different noise settings.

image and audio data are more resilient toward round shifting.
Similar to the libjpeg evaluation reported in Table 14, attack
on FFmpeg is notably undermined in front of the Removal
and Gaussian noise schemes. As clariﬁed in Sec. 6.6, these
two schemes extensively leave out or perturb data points on
the logged trace (e.g., Removal/High removes 50% of the
records on a trace), show greater inﬂuence on data reconstruc-
tion. Nevertheless, reasonably high attack accuracy can still
be achieved in the presence of perturbed side channel traces.
Manifold learning shows encouraging resilience toward noisy
inputs. In addition, as clariﬁed in Appx. F, the logged side

35

Gaussian noise𝑥=0.2ReferenceReconstructedPin(cache line)Gaussian noise𝑥=0.5ReferenceReconstructedPin(cache line)Round shifting𝑥=10Round shifting𝑥=100Removal𝑥=20Removal𝑥=50ReferenceReferenceReconstructedPrime+ProbeReconstructedPrime+ProbeLeave out𝑥=20Leave out𝑥=50False hit/miss𝑥=20False hit/miss𝑥=50Wrong order𝑥=100Wrong order𝑥=500ReferenceReconstructedPrime+ProbeBzip2Victim1Victim2