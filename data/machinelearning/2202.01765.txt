2
2
0
2

r
a

M
7

]

G
L
.
s
c
[

3
v
5
6
7
1
0
.
2
0
2
2
:
v
i
X
r
a

Who will Leave a Pediatric Weight Management Program and When? -
A machine learning approach for predicting attrition patterns

Hamed Fayyaza,∗, Thao-Ly T. Phanb, H. Timothy Bunnellb and Rahmatollah Beheshtia

A R T I C L E I N F O

A B S T R A C T

Keywords:
Pediatric obesity
Attrition
Transfer learning
Multi-task learning
Deep learning

1. Introduction

Childhood obesity is a major public health concern. Multidisciplinary pediatric weight management
programs are considered standard treatment for children with obesity and severe obesity who are not
able to be successfully managed in the primary care setting; however, high dropout rates (referred to
as attrition) are a major hurdle in delivering successful interventions. Predicting attrition patterns can
help providers reduce the attrition rates. Previous work has mainly focused on ﬁnding static predictors
of attrition using statistical analysis methods. In this study, we present a machine learning model to
predict (a) the likelihood of attrition, and (b) the change in body-mass index (BMI) percentile of
children, at diﬀerent time points after joining a weight management program. We use a ﬁve-year
dataset containing information about 4,550 children of diverse backgrounds receiving treatment at
four pediatric weight management programs in geographically diﬀerent regions of the country. Our
models show strong prediction performance as determined by high AUROC scores across diﬀerent
tasks (average AUROC of 0.75 for predicting attrition, and 0.73 for predicting weight outcomes).
Additionally, we report the top features that can predict attrition and weight outcomes at diﬀerent
times after joining the weight management program.

and eﬃcient utilization of their often limited resources.

Childhood obesity is a major public health concern across
the world. The prevalence of overweight and obesity among
children and adolescents aged 2-19 has risen dramatically
from 29% in 2000 to just over 32% in 2012 in the United
States (Skinner and Skelton, 2014). Childhood obesity in-
creases the risk of diabetes, cardiovascular disease, and can-
cer, predominantly as a result of a substantially greater risk
of adult obesity (Ogden, Carroll, Kit and Flegal, 2014), but
also causes signiﬁcant morbidity in childhood. Multi-disciplinary
clinical weight management programs (WMPs) are recom-
mended for children with obesity who fail to improve with
management in the primary care setting but these programs
often require a moderate to high intervention dose deliv-
ered over an extended period (Ball, Sebastianski, Wijesun-
dera, Keto-Lambert, Ho, Zenlea, Perez, Nobles and Skelton,
2021). Children and their families who attend more inter-
vention sessions and remain enrolled in care for longer peri-
ods achieve the greatest improvements in weight and health
(Wilﬂey, Saelens, Stein, Best, Kolko, Schechtman, Wallen-
dorf, Welch, Perri and Epstein, 2017). However, due to a va-
riety of reasons, such as dissatisfaction with the intervention
progress or logistical issues with attending the programs,
many families (as much as 80% (Ball et al., 2021)) discon-
tinue attending WMPs prematurely (a phenomenon referred
to as “attrition”). Besides not treating the disease eﬀectively,
a failed weight loss attempt may also lead to frustration, dis-
couragement, and learned helplessness (Ponzo, Scumaci, Goitre,
Beccuti, Benso, Belcastro, Crespi, De Michieli, Pellegrini,
Scuntero, Marzola, Abbate-Daga, Ghigo, Broglio and Bo,
2020). Attrition can also be challenging for healthcare sys-
tems needing to ensure eﬀective delivery of their services

∗Corresponding author

fayyaz@udel.edu (H. Fayyaz)

ORCID(s): 0000-0003-0053-5112 (H. Fayyaz)

Prior studies have explored reasons for and predictors
of attrition (Ball et al., 2021; Jiandani, Wharton, Rotondi,
Ardern and Kuk, 2016; Moran, Noakes, Clifton, Buckley,
Brinkworth, Thomson and Norman, 2019; Ponzo et al., 2020;
Altamura, Porcelli, Fairﬁeld, Malerba, Carnevale, Balzotti,
Rossi, Vendemiale and Bellomo, 2018). These studies have
found several predictors of attrition from WMPs, such as sex,
age, ethnicity, psychosocial factors (Phan, Chen, Pinto, Cox,
Robbins and Kazak, 2018), and initial weight loss (Batter-
ham, Tapsell, Charlton, O’Shea and Thorne, 2017; Jiandani
et al., 2016; Moroshko, Brennan and O’Brien, 2011). How-
ever, there is no consensus on how these various factors con-
tribute to attrition, and what strategies can be employed to re-
duce attrition. Another limitation of prior work relates to us-
ing only static features (exposures) to study attrition, without
explicitly considering temporal features, such as weight tra-
jectories. Considering weight trajectories is pivotal in study-
ing obesity patterns and also may be helpful in predicting
attrition (Kushner, Batsis, Butsch, Davis, Golden, Halperin,
Kidambi, Machineni, Novick, Port, Rubino, Saunders, Shapiro Man-
ning, Soleymani and Kahan, 2020).

In this study, we present a machine learning model to
address the current limitations and gaps in the ﬁeld and ap-
ply our method to a large dataset, representing four pedi-
atric WMP sites within the Nemours Children’s Health Sys-
tem (a large pediatric health system in the US). Speciﬁcally,
we present a deep (neural network) model with two separate
components for analyzing the static and dynamic input fea-
tures, extracted from the electronic health records (EHRs)
of children attending the WMPs. To improve the overall
predictive performance of our models, we use a "multi-task
learning" approach by combining the two prediction tasks
(i.e., predicting attrition and weight outcomes) such that one
In our study,
model generates two values for these tasks.

Hamed Fayyaz et al.: Preprint submitted to Elsevier

Page 1 of 9

 
 
 
 
 
 
A machine learning approach for predicting attrition patterns

attrition prediction refers to predicting the time (number of
weeks after the baseline visit) of the last visit, and the weight
outcome prediction task refers to predicting the change in
BMI percentile (BMI%) of patients at their last visit to the
WMP (classiﬁed as a decrease in BMI% or not). Besides
multi-task learning, our model also follows a "transfer learn-
ing" design, by training our model on various lengths of ob-
servation and prediction windows (Ball et al., 2021). Fol-
lowing the initial training of the model on these diﬀerent
settings, it is then ﬁne-tuned (retrained) on a ﬁnal target task
to report the desired outcomes. Speciﬁcally, the main con-
tributions of our study are:

• We have collected one of the largest and most com-
prehensive datasets dedicated to study attrition. The
dataset represents 4,550 children from four WMP sites
within a large pediatric healthcare system, The dataset
includes standard items from the EHR (e.g. medical
diagnoses) and additional lifestyle and psychosocial
factors collected by the WMPs in the EHR as part of
routine clinical care. The dataset also includes tempo-
ral factors that may be important such as time between
visits and BMI% trajectories.

• We present a deep model for predicting when attrition
occurs and patients’ BMI% change at that time. We
use a multi-task and transfer learning approach for im-
proving the performance of our model, facilitating its
deployment in real settings without large training data.

• We compare our model against the commonly used
logistic regression and a state of the art survival anal-
ysis method and show that it achieves better results in
predicting attrition.

• We study the role of various input features in predict-
ing attrition and successful BMI% change. This in-
creases the interpretability of our model and makes
our ﬁndings more actionable.

2. Related Work

Studying attrition is similar to studying other healthcare
problems such as visit attendance and treatment adherence
in clinical settings. Attendance prediction generally aims to
predict whether a patient will show up for a scheduled ap-
pointment or not. Attendance prediction has been used to
identify the important factors predicting visit attendance in
various ﬁelds such as rehabilitation (Sabit, Griﬃths, Watkins,
Evans, Bolton, Shale and Lewis, 2008; Hayton, Clark, Olive,
Browne, Galey, Knights, Staunton, Jones, Coombes and Wil-
son, 2013), psychiatric care (Mitchell and Selmes, 2007),
and primary care (Giunta, Briatore, Baum, Luna, Waisman
and de Quiros, 2013; Kheirkhah, Feng, Travis, Tavakoli-
Tabasi and Sharafkhaneh, 2015). On the other hand, ad-
herence prediction aims to predict whether a patient will be
compliant with their treatment plan (e.g. taking prescribed
medicines). Treatment and medication adherence have been
studied for conditions such as tuberculosis (Killian, Wilder,

Sharma, Choudhary, Dilkina and Tambe, 2019), heart fail-
ure (Son, Kim, Kim, Choi and Lee, 2010), and schizophre-
nia (Son et al., 2010). There are also other studies outside
the healthcare domain that relate to our work. Among these
related studies, one is "churn" prediction often used in eco-
nomic domains to predict engagement patterns of individu-
als (such as customers and employees) to increase their re-
tention. Churn prediction has been also well researched in
the ﬁelds of banking (Ali and Arıtürk, 2014), video games
(Kawale, Pal and Srivastava, 2009; Hadiji, Sifa, Drachen,
Thurau, Kersting and Bauckhage, 2014), and telecommuni-
cation (Huang, Kechadi and Buckley, 2012).

While the studies discussed so far closely relate to the
ﬁeld of attrition, a major distinguishing aspect of attrition
studies is the chronicity of the conditions being treated and
the commitment to an intervention or treatment required for
success. Examples of conditions where attrition patterns
have been studied include mental health conditions (Linar-
don and Fuller-Tyszkiewicz, 2020), sleep disorders (Hebert,
Vincent, Lewycky and Walsh, 2010), and addiction disor-
ders (Murray, White, Varagunam, Godfrey, Khadjesari and
McCambridge, 2013). Attrition from WMPs, in particular,
has been studied in diﬀerent settings, mainly using tradi-
tional methods such as linear and logistic regression (Jian-
dani et al., 2016; Altamura et al., 2018; Ponzo et al., 2020;
Perna, Spadaccini, Riva, Allegrini, Edera, Faliva, Peroni,
Naso, Nichetti, Gozzer et al., 2018). Linear and logistic re-
gression assume that the relationship between the indepen-
dent and the dependent variables are linear, which may not
be correct. Using these standard methods, researchers have
proposed various predictors of attrition, such as psycholog-
ical (Altamura et al., 2018), (Jiandani et al., 2016), sociode-
mographic, and anthropometric (Ponzo et al., 2020) factors,
and initial weight-loss (Perna et al., 2018). Among this fam-
ily of studies, Batterham et al. (Batterham et al., 2017) were
the only group who used shallow decision trees to predict
attrition in dietary weight loss trials using demographic and
early weight change characteristics. Their approach, how-
ever, did not use weight trajectories or other temporal pat-
terns.

3. Dataset

Our dataset includes all children 0-21 years of age who
visited one of the four WMPs of the Nemours Children’s
Health system between 2007 and 2021. The four WMPs
serve patients in the US states of Delaware, Florida, Mary-
land, New Jersey, and Pennsylvania. For each patient, data
from an internal dataset collected by the providers inside
the WMPs were linked to EHR data, capturing their health
records when interacting with the entire healthcare system.
The internal dataset collected at the WMPs was speciﬁcally
designed to capture important covariates generally missing
in EHRs, such as psychosocial determinants of health and
lifestyle behaviours (see Table 1). The EHR dataset was the
Nemours portion of the large PEDSnet data repository and
included rigorously validated EHR variables including med-
ical conditions, anthropometrics, visits, and demographics

Hamed Fayyaz et al.: Preprint submitted to Elsevier

Page 2 of 9

A machine learning approach for predicting attrition patterns

Table 1
Characteristics of the study cohort.

Description
Variable
Male(2,122), Female(2,428)
Sex
Range=(1–19), Mean=10.5
Age
Asian(57), White(1,767), Black(1,219), Other(1,462)
Race
Hispanic(1,680), Non-Hispanic(2,844)
Ethnicity
Mean=7 weeks
Time btw visits
Mean BMI-for-age percentile at baseline visit=98
BMI% (per visit)
Medicaid(1,998), Private(1,570)
Insurance type
Food insecurity*
Often or Sometimes true Mean item-1(646), item-2(427)
Lifestyle score†
Range=(3–47), Mean=38.95
PSC-17‡
Range=(3–33), Mean=9
Nutrition(4,293), medical(12,927), psychology(1,734), exercise(3,028)
WMP visit type
Diagnosis codes
24 most commonly reported conditions (e.g., diabetes)
* as measured by the validated 2-item Hunger Vital Sign(Hager, Quigg, Black, Coleman, Heeren, Rose-Jacobs, Cook, de Cuba, Casey,
Chilton, Cutts, Meyers and Frank, 2010). † based on 12 evidence-based items about diet, activity, sleep, and hunger (each scored on a
4-point Likert scale with a total score of 12-48). ‡ Pediatric Symptom Checklist (Y-PSC, 1994), a validated 17-item screening tool (total
score 0-34).

(Forrest, Margolis, Bailey, Marsolo, Del Beccaro, Finkel-
stein, Milov, Vieland, Wolf, Yu and Kahn, 2014). PEDSnet
is a multi-speciality network that conducts observational re-
search and clinical trials across multiple children’s hospital
health systems. The ﬁnal dataset was anonymized, and our
study was approved by the Nemours Institutional Review
Board.

The ﬁnal cohort included 4,550 children (with 26,895
total WMP visits) of diverse backgrounds (27% Black, 37%
Hispanic, 48% with Medicaid) with a mean BMI% (BMI per-
centile) of 98. For the BMIs, we use age- and sex-adjusted
BMI% above the 95th percentile as deﬁned by the Centers
for Disease Control and Prevention (CDC) (Centers for Dis-
ease Control and Prevention, 2017). BMI% is recorded and
fed to the model whenever available (for the baseline visit
and the majority of the follow-up visits) and the sequence of
BMI%s from baseline to the end time point of the particular
prediction window is included as a dynamic variable. For
each child, we included 18 features capturing demographic,
psychosocial, lifestyle, anthropometric, medical comorbid-
ity, and visit variables. Table 1 shows a list of these variables
and their values. Our variables include two risk scores, cap-
turing evidence-based lifestyle (diet, sleep, physical activ-
ity, sedentary activity, and hunger) and psychosocial (men-
tal health and behavioural) factors. In our dataset, 28% of
the children had only one WMP visit, and 15% had more
than ten visits. Figure 1 shows the overall distributions of
the number of visits and the duration of WMP attendance in
months.

To bucketize the longitudinal EHR data, we combined
visits over 15-days time periods. We examined medical di-
agnoses codes and medication tables, from the available EHR
data. Any condition observed at least once during the time
window was denoted by 1 in the new sequence, and the mea-
surements were averaged over the time window.
If there
were no visits for a patient in a time window, the correspond-
ing vector for that period was set to all zeros. We also ex-
cluded rare diagnosis codes (i.e., the codes that appeared in

less than 2% of patients), which reduced the total number
of diagnosis codes from 435 to 24. We used one-hot encod-
ing for the categorical values and normalized the continuous
values by performing a min-max scaling on all features.

4. Method

As discussed earlier, in this study we considered two re-
lated predictive tasks, i.e., attrition prediction and weight
outcome prediction. We considered these two prediction
tasks in a binary classiﬁcation framework. In the attrition
prediction task, patients who dropped out before the pre-
diction window were considered positive cases. In the out-
come prediction task, any decrease in the child’s BMI% was
considered a success. Accordingly, we deﬁned the patients
whose BMI% in the prediction window was lower than their
BMI% at the time of their baseline visit to the WMP as neg-
ative cases. The rest of the patients (i.e., those whose BMI%
remained the same or increased during the observation win-
dow) were considered as positive cases.

We used ﬂexible observation and prediction windows for
both tasks, where the start of the observation window was
always ﬁxed at the ﬁrst WMP visit with a rolling end con-
sidered for the end of the window. The start of the prediction
window was considered as the end of the observation win-
dow with a ﬂexible end. We note that this type of ﬂexibility
in deﬁning observation and prediction windows makes our
models more practical in clinical settings, where a provider
needs to know which child will leave at what time following
the start of the program.

For implementing the two prediction tasks, we propose
a deep neural network architecture, speciﬁcally designed to
address our problem’s needs.
In order to fully utilize the
static (e.g., demographics) and temporal features (e.g., mea-
surements) in our data, our architecture is designed with the
following four components as shown in Figure 2. Two initial
components are shared between the two tasks of attrition and
outcome predictions and the other two are task-speciﬁc com-

Hamed Fayyaz et al.: Preprint submitted to Elsevier

Page 3 of 9

A machine learning approach for predicting attrition patterns

Figure 1: The distribution of (a) the number of visits and (b) the number of months
staying in the WMP across the patients in our cohort.

1
𝑁

𝑁
∑

𝑖=1

−(𝑦𝑖 ∗ 𝑙𝑜𝑔(𝑝𝑖) + (1 − 𝑦𝑖) ∗ 𝑙𝑜𝑔(1 − 𝑝𝑖)),

is the ground
where, N is the total number of samples, 𝑦𝑖
truth for the 𝑖th sample, 𝑝𝑖
is the probability of belonging to
the positive class , and (1−𝑝𝑖) is the probability of belonging
to the negative class. In the attrition task, we train a model
to discriminate between the patients who dropped out and
patients who stayed in the WMP. In the outcome task, we
train a model to discriminate between patients who success-
fully decreased their BMI% and those who had no change or
a BMI% increase.

To improve the overall performance of our models and
accommodate the relatively small size of our training data,
we use a "multi-task learning" approach for designing our
model. In our design, we use a hard parameter sharing ap-
proach, which is a common multi-task learning method (Caru-
ana, 1993), by sharing the ﬁrst two components between the
two tasks. This way, sharing the parameters of the two initial
parts of the model can improve the performance for both pre-
dictions tasks. Additionally, following a “transfer learning”
theme, we iteratively train our model on all sliding observa-
tion and prediction windows, and then ﬁne-tune the model
for each speciﬁc window settings. Figure 3 shows the train-
ing process and the way that the four components are in-
volved in our multi-task and transfer learning themes. Ad-
ditionally, Algorithm 1 presents a high-level pseudocode of
our customized model training process. In this algorithm,
each model is trained using the data from a speciﬁc observa-
tion and prediction window, initialized by the weights from
the previous window settings. The procedure in this algo-
rithm receives the input data (𝑋), labels for the attrition and
outcome tasks (𝑌𝐴
), and the list of observation and
prediction windows. It returns a list of ﬁne-tuned models.

and 𝑌𝑂

Figure 2: The proposed architecture for our model. The model
receives static and temporal features and predicts the time of
last visit (attrition) and the BMI% change outcome at that
time (Weight outcome).

ponents. The ﬁrst component is a two-layer fully-connected
network for processing the static features. The second is a
two-layer bi-directional long short-term memory (Bi-LSTM)
network for processing the temporal features. Bi-LSTM struc-
tures are similar to the common LSTMs, but they consist of
two LSTMs units: one taking the input in a forward direc-
tion (e.g., left to right), and the other in a backwards direction
(e.g., right to left), thus improving the available context for
the model (Schuster and Paliwal, 1997). The third compo-
nent is a three-layer fully connected network for combining
the extracted feature vectors from the ﬁrst two parts and pre-
dicting the attrition time. Finally, the fourth component is
a three-layer fully-connected network for combining the ex-
tracted feature vectors from the ﬁrst two parts and predicting
the outcome. We used dropout and batch normalization lay-
ers after all of the layers mentioned above. For training the
model, we used binary cross-entropy as the loss function,
deﬁned as:

Hamed Fayyaz et al.: Preprint submitted to Elsevier

Page 4 of 9

020040060080010001200140016001800200002-56 - 1011 - 2020 - 30> 30Number of PatientsNumber of visits21Only initial visit020040060080010001200140000 - 33 - 66 - 99 - 1212 - 1515 - 1818 - 2121 -24> 24Number of PatientsNumber of months staying in the program(a)(b)Dense layer (16)Bi-LSTM (16)Bi-LSTM (32)Dense layer (32)Dense layer (64)Static featuresTemporal featuresDense layer (32)Dense layer (1)AttritionDense layer (64)Dense layer (32)Dense layer (1)OutcomeAttrition NetworkOutcome NetworkStatic NetworkTemporalNetworkA machine learning approach for predicting attrition patterns

Figure 3: Proposed training process using the multi-task and transfer learning themes.
𝑊 𝑆 , 𝑊 𝐴, 𝑊 𝑇 , and 𝑊 𝑂 are the weights of the static, attrition, temporal, and outcome
sub-networks, respectively. We extract the features and the corresponding labels for each
patient based on the rolling observation and prediction windows and feed them to the
network. After the pretraining of a general model, we then initialize the weights of the
specialized models with the weights from the general model. For each speciﬁc observation
and prediction window setting, the model is then ﬁne-tuned using only the relevant samples.
𝑊𝑗 shows the 𝑗th ﬁne-tuned conﬁguration.

The model presented in this paper was implemented using
Keras (Chollet et al., 2015) inside the TensorFlow (Abadi,
Barham, Chen, Chen, Davis, Dean, Devin, Ghemawat, Irv-
ing, Isard et al., 2016) framework. Our code is publicly avail-
able on GitHub1.

, Observation-Prediction window list

, 𝑌𝑂

Algorithm 1 Training pseudocode
1: Input: X, 𝑌𝐴
2: Output: Trained models list
3: Preprocess X
4: PM = random (PM)
pretrained model

⊳ Random initialization of the

5: for Every observation-prediction window pair do
𝑋′ = Select cohort based on the windows
6:
M = PM ⊳ Load weights from the previous PM to

7:

model M

Pretrain M with 𝑋′
PM = M ⊳ Save M as the current pretrained model

8:
9:

10:

PM

Freeze the ﬁrst two components in M
Fine tune the rest of M
Add M to trained models list

11:
12:
13: return Trained models list

5. Experiments and Discussion

To measure the prediction performance of our model, we
report accuracy, precision, recall, area under the receiver op-
erating characteristic (AUROC), area under the precision-
recall curve (AUPRC), and baseline AUPRC. The last mea-
sure (baseline AUPRC) is the proportion of positive exam-

1

https://github.com/healthylaife/WM_attrition

ples in our data. The performance of the proposed model
in the outcome and attrition prediction tasks for a series of
observation and prediction windows (observation window =
1, 2, 3, 4, 6, and 9 months; and prediction window = 1.5, 3,
4.5, 6, 9, 13.5 months) are shown in Table 2 and Table 3.
This speciﬁc set of observations and windows were selected
based on prediction windows used in prior studies (Moran
et al., 2019; Jiandani et al., 2016) and based on the distribu-
tion of our data. The results show that the performance of
the models has a direct relationship with the length of the
observation window, i.e., as we expand the observation win-
dow through diﬀerent tasks, the model’s performance also
increases.

We compare our model against two separate baselines.
The ﬁrst is a general logistic regression (LR) method, which
is a frequently used method in the literature (Shipe, Deppen,
Farjah and Grogan, 2019). Similar to the common practice
in the ﬁeld, we aggregate the temporal variables by calculat-
ing the average values during a corresponding period. We
train an LR model with L2 penalty and BFGS solver us-
ing the scikit-learn library (Pedregosa, Varoquaux, Gram-
fort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss,
Dubourg et al., 2011) in Python.

For the second baseline, we use another popular method
for studying similar problems in biomedical domains, which
takes a survival analysis approach. Survival analysis (time-
to-event analysis) is widely used in many engineering, eco-
nomics, and medicine (Clark, Bradburn, Love and Altman,
2003) applications to estimate the expected duration until a
desired event occurs (e.g., drop out or death). We use a state
of the art method for studying survival analysis, called Dy-
namic DeepHit (Lee, Yoon and Schaar, 2020), which presents
a deep neural network to learn the distribution of survival

Hamed Fayyaz et al.: Preprint submitted to Elsevier

Page 5 of 9

Attrition NetworkOutcome NetworkStatic NetworkTemporal NetworkIterate over different observation-prediction window pairsPre-training𝑊𝑇𝑊𝑆𝑊𝑖𝐴𝑊𝑖𝑂Attrition NetworkOutcome NetworkStatic NetworkTemporal NetworkFine-tuning𝑊𝑆𝑊𝑇FreezeFreeze𝑊𝑖′𝐴𝑊𝑖′𝑂DatasetObservation periodPrediction period…A machine learning approach for predicting attrition patterns

Table 2
Results for the attrition prediction task using our proposed method. Observation and
prediction windows are shown in months.

Observation
1
2
3
4
6
9

Predication
1.5
3
4.5
6
9
13.5

Precision
0.48
0.65
0.76
0.81
0.87
0.91

Recall AUROC AUPRC B.AUPRC
0.74
0.63
0.69
0.68
0.70
0.78

0.62
0.68
0.75
0.78
0.80
0.84

0.49
0.64
0.76
0.84
0.89
0.94

0.40
0.50
0.58
0.63
0.69
0.76

Table 3
Results for the outcome prediction task using our proposed method. Observation and
prediction windows are shown in months.

Observation
1
2
3
4
6
9

Predication
1.5
3
4.5
6
9
13.5

Precision
0.21
0.52
0.44
0.59
0.42
0.54

Recall AUROC AUPRC B.AUPRC
0.65
0.62
0.68
0.78
0.64
0.60

0.54
0.77
0.74
0.84
0.71
0.75

0.23
0.64
0.58
0.71
0.59
0.66

0.19
0.27
0.28
0.31
0.31
0.33

times. Dynamic DeepHit utilizes the available temporal data
to issue dynamically updated survival predictions. This sur-
vival analysis method only ﬁts our attrition prediction task
(and not the weight outcome prediction task). In an ablation
analysis, we also study the role of the multi-task and trans-
fer learning themes used in our design. To this end, we re-
port the results of our method without (a) multi-task learning
implementation (i.e., the two shared sub-networks and only
one of the latter sub-networks for each task), and (b) transfer
learning implementation (i.e., ﬁne-tuning the models on the
corresponding data to each observation-prediction window
setting without pretraining). Figure 4 shows how the results
obtained from our method compares to the two baselines and
the ablated version of our model.

Moreover, to study to what degree each input feature
contributes to predicting the ﬁnal outputs in each task, we
used the popular Shapley additive explanations (SHAP) method
implemented by the SHAP toolbox (Lundberg and Lee, 2017b,a).
Inspired by the Shapley values, this toolbox is a uniﬁed frame-
work that assigns each input feature an importance value in-
dicating its importance in the prediction task. A SHAP value
indicates the degree to which a feature contributes to push-
ing the output from the base value (average model output)
to the actual predicted value, so the higher value means the
higher importance and contribution toward the outcome of
the model. Here, we report the importance values (as indi-
cated by SHAP) for the top 5 features predicting each out-
come and for each prediction/observation window. These
are shown in tables 4 and 5. Not surprisingly, the top features
did vary some by the outcome and prediction/observation
window, which demonstrates the importance of targeting dif-
ferent risk factors at diﬀerent points in treatment. However,
age, the average time between the visits, and patient’s BMI%
trajectory were important features for determining both at-
trition and weight outcomes, which is consistent with previ-

ous studies (Batterham et al., 2017; Batterham, Tapsell and
Charlton, 2016). Speciﬁcally, a patients’ early weight loss
is predictive of overall weight loss progress and the patients
who have success with early weight loss seem to have a lower
risk of attrition. Similar to our study, other studies (Jian-
dani et al., 2016; Batterham et al., 2016) have also found
that age is an important predictor of both attrition and weight
outcomes, with children of younger ages having more suc-
cess in WMPs. We have also found that the average time
between WMP visits is a primary predictor for both tasks,
with worse outcomes and higher attrition rates for patients
who had a prolonged time between visits. This is consistent
with the literature and current guidelines recommending a
certain number of contact hours and frequency of contact for
success in WMPs. Finally, sociodemographics like race and
ethnicity and sex, as well as food security and insurance sta-
tus, are important predictors of both attrition and weight out-
comes, consistent with previous studies demonstrating in-
equities in health outcomes between subgroups (Martin and
Ferris, 2007). Interestingly, other factors like medical diag-
noses, medications, and lifestyle scores were less predictive
of attrition and weight outcomes, which highlights the im-
portance of identifying and supporting key groups based on
sociodemographics, as well as ensuring frequent visits and
early success with weight outcomes during treatment regard-
less of a patient’s underlying conditions or lifestyle behav-
iors. We note that while we report the average SHAP values
across all of the samples (children), our model is most help-
ful when individual children are considered separately, and
a provider can see the predictors that can be targeted for a
particular child to prevent attrition or increase success with
weight outcomes.

The current study is limited in several ways. First, our
dataset only includes the patients from one healthcare sys-
tem. Still, our dataset is larger than similar ones used to

Hamed Fayyaz et al.: Preprint submitted to Elsevier

Page 6 of 9

A machine learning approach for predicting attrition patterns

Figure 4: Performance of our method versus the logistic regression and Dynamic DeepHit
(Lee et al., 2020) baselines as determined by precision in predicting (A) attrition, and (B)
weight outcome (without the Dynamic DeepHit).

Table 4
The top ﬁve features predict attrition in various observation and prediction window set-
tings, as determined by the SHAP values shown in parentheses. BMI% shows the BMI%
trajectory recorded during the observation window. Food ins:Food insecurity. Visits int:
Visits intervals.

1/1.5
Age (0.041)
Ethnicity(0.006)
Food ins.(0.005)
Sex(0.005)
Insurance(0.003)

2/3
Insurance(0.015)
BMI %(0.006)
Race(0.005)
Age(0.005)
Sex(0.004)

Observation/Prediction window (in months)
3/4.5
Visits int.(0.023)
BMI %(0.020)
Age(0.010)
Food ins.(0.007)
Insurance(0.005)

4/6
Visits int.(0.020)
Age(0.012)
BMI %(0.012)
Insurance(0.007)
Sex(0.006)

6/9
Age(0.063)
Insurance(0.009)
Visits int.(0.003)
Sex(0.002)
BMI %(0.002)

9/13.5
Age(0.012)
Visits int.(0.005)
BMI %(0.002)
Insurance(0.0002)
Lifestyle
score(0.0002)

study attrition and spans four geographically distinct sites in
the Mid-Atlantic (Delaware, Pennsylvania, Maryland, New
Jersey) and Southern (Florida) regions of the US. Addition-
ally, our approach relies on discretizing future time into two-
week windows. Considering attrition prediction as a regres-
sion task was an alternative natural choice. In our experi-
ments, we have noticed that formulating our problem as a
classiﬁcation task yields better results. Additionally, as most
follow-up visits are not scheduled in shorter than two-weeks

intervals, one can still use our approach for continuous (any
time in future) predictions. While our study focuses primar-
ily on attrition from pediatric WMPs, our method should
be applicable to adult obesity WMPs and other compara-
ble problems such as mental health and addiction recovery
programs. As part of our future work, we plan to expand
our model by including additional information from chil-
dren’s historical (before joining a WMP) records and also
by including new data from other pediatric health systems.

Table 5
The top ﬁve features predict the weight outcome in various observation and prediction
window settings, as determined by the SHAP values shown in parentheses. BMI% shows
the BMI% trajectory recorded during the observation window. Food ins:Food insecurity.
Visits int: Visits intervals.

1/1.5
Age (0.010)
Race(0.005)
Insurance(0.004)
Lifestyle Score(0.003) Sex(0.008)
Food ins.(0.003)

2/3
Age(0.058)
Visits int.(0.014)
Insurance(0.014)

BMI %(0.006)

Observation/Prediction window (in months)
3/4.5
Insurance(0.020)
Age(0.018)
Ethnicity(0.012)
Race(0.011)
visits int.(0.010)

4/6
Age(0.043)
BMI %(0.029)
Visits int.(0.019)
Race(0.006)
Sex(0.005)

6/9
Age(0.021)
Visits int.(0.008)
Food ins.(0.007)
BMI %(0.005)
Sex(0.005)

Hamed Fayyaz et al.: Preprint submitted to Elsevier

9/13.5
Age(0.014)
BMI %(0.006)
Visits int.(0.003)
Race(0.0004)
Sex(0.0003)

Page 7 of 9

00.10.20.30.40.50.60.70.80.911/1.52/33/4.54/66/99/13.5PrecisionObservation/Prediction window (months)Dynamic DeepHitLogistic regressionOur methodOur method, w/o transfer learningOur method, w/o multitask learning00.10.20.30.40.50.60.70.80.911/1.52/33/4.54/66/99/13.5Observation/Prediction window (months)Logistic regressionOur methodOur method - w/o transfer learningOur method - w/o multitask learning(A)(B)A machine learning approach for predicting attrition patterns

On the technical side, we plan to use a transformer-based
architecture (Vaswani, Shazeer, Parmar, Uszkoreit, Jones,
Gomez, Kaiser and Polosukhin, 2017), which oﬀers state of
the art sequence-to-sequence predictive modelling to check
whether it improves our model’s performance further. More-
over, we aim to explicitly identify the temporal patterns (such
as distinct shapes of the body-weight trajectory) that can pre-
dict (or stratify) attrition or outcome patterns.

6. Conclusion

In this study, we presented a deep neural network that
includes Bi-LSTM elements for predicting attrition patterns
and weight outcomes in pediatric weight management pro-
grams. We trained our model with a large electronic health
records dataset collected from the Nemours Children’s Health.
Our model showed strong prediction performance as deter-
mined by AUROC scores across diﬀerent tasks and superior-
ity against other baseline methods, including logistic regres-
sion and a survival analysis method. Finally, we explored
the importance of individual variables in predicting attrition
and weight outcomes and found that sociodemographic vari-
ables as well as early weight trajectory and visit timing were
important across both outcomes.

References
Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M.,
Ghemawat, S., Irving, G., Isard, M., et al., 2016. Tensorﬂow: A sys-
tem for large-scale machine learning, in: 12th {USENIX} symposium
on operating systems design and implementation ({OSDI} 16), ACM,
Savannah, GA, USA. pp. 265–283.

Ali, Ö.G., Arıtürk, U., 2014. Dynamic churn prediction framework with
more eﬀective use of rare event data: The case of private banking. Expert
Systems with Applications 41, 7889–7903.

Altamura, M., Porcelli, P., Fairﬁeld, B., Malerba, S., Carnevale, R., Bal-
zotti, A., Rossi, G., Vendemiale, G., Bellomo, A., 2018. Alexithymia
predicts attrition and outcome in weight-loss obesity treatment. Fron-
tiers in Psychology 9, 2432.

Ball, G.D.C., Sebastianski, M., Wijesundera, J., Keto-Lambert, D., Ho, J.,
Zenlea, I., Perez, A., Nobles, J., Skelton, J.A., 2021. Strategies to reduce
attrition in managing paediatric obesity: A systematic review. Pediatric
Obesity 16, e12733.

Batterham, M., Tapsell, L., Charlton, K., O’Shea, J., Thorne, R., 2017.
Using data mining to predict success in a weight loss trial. Journal of
Human Nutrition and Dietetics 30, 471–478.

Batterham, M., Tapsell, L.C., Charlton, K.E., 2016. Predicting dropout
in dietary weight loss trials using demographic and early weight change
characteristics: implications for trial design. Obesity research & clinical
practice 10, 189–196.

Caruana, R., 1993. Multitask learning: A knowledge-based source of in-
ductive bias, in: Proceedings of the Tenth International Conference on
Machine Learning, Morgan Kaufmann. pp. 41–48.

Centers for Disease Control and Prevention, 2017. Growth charts - clin-
ical growth charts. URL: https://www.cdc.gov/growthcharts/clinical_
charts.htm. Accessed: Feb 2022.

Chollet, F., et al., 2015. Keras. https://github.com/fchollet/keras.
Clark, T.G., Bradburn, M.J., Love, S.B., Altman, D.G., 2003. Survival
analysis part i: basic concepts and ﬁrst analyses. British journal of cancer
89, 232–238.

Forrest, C.B., Margolis, P.A., Bailey, L.C., Marsolo, K., Del Beccaro, M.A.,
Finkelstein, J.A., Milov, D.E., Vieland, V.J., Wolf, B.A., Yu, F.B., Kahn,
M.G., 2014. Pedsnet: a national pediatric learning health system. Jour-
nal of the American Medical Informatics Association 21, 602–606.

Giunta, D., Briatore, A., Baum, A., Luna, D., Waisman, G., de Quiros,
F.G.B., 2013. Factors associated with nonattendance at clinical medicine
scheduled outpatient appointments in a university general hospital. Pa-
tient preference and adherence 7, 1163.

Hadiji, F., Sifa, R., Drachen, A., Thurau, C., Kersting, K., Bauckhage, C.,
2014. Predicting player churn in the wild, in: 2014 IEEE Conference
on Computational Intelligence and Games, IEEE, Dortmund, Germany.
pp. 1–8.

Hager, E.R., Quigg, A.M., Black, M.M., Coleman, S.M., Heeren, T., Rose-
Jacobs, R., Cook, J.T., de Cuba, S.A.E., Casey, P.H., Chilton, M., Cutts,
D.B., Meyers, A.F., Frank, D.A., 2010. Development and Validity of a 2-
Item Screen to Identify Families at Risk for Food Insecurity. Pediatrics
126, e26–e32. URL: https://doi.org/10.1542/peds.2009-3146, doi:10.
1542/peds.2009-3146.

Hayton, C., Clark, A., Olive, S., Browne, P., Galey, P., Knights, E.,
Staunton, L., Jones, A., Coombes, E., Wilson, A.M., 2013. Barriers to
pulmonary rehabilitation: Characteristics that predict patient attendance
and adherence. Respiratory Medicine 107, 401–407.

Hebert, E.A., Vincent, N., Lewycky, S., Walsh, K., 2010. Attrition and
adherence in the online treatment of chronic insomnia. Behavioral Sleep
Medicine 8, 141–150.

Huang, B., Kechadi, M.T., Buckley, B., 2012. Customer churn prediction in
telecommunications. Expert Systems with Applications 39, 1414–1425.
Jiandani, D., Wharton, S., Rotondi, M.A., Ardern, C.I., Kuk, J.L., 2016.
Predictors of early attrition and successful weight loss in patients attend-
ing an obesity management program. BMC Obesity 3, 1–9.

Kawale, J., Pal, A., Srivastava, J., 2009. Churn prediction in mmorpgs: A
social inﬂuence based approach, in: 2009 International Conference on
Computational Science and Engineering, IEEE. IEEE, Vancouver, BC,
Canada. pp. 423–428.

Kheirkhah, P., Feng, Q., Travis, L.M., Tavakoli-Tabasi, S., Sharafkhaneh,
A., 2015. Prevalence, predictors and economic consequences of no-
shows. BMC health services research 16, 1–6.

Killian, J.A., Wilder, B., Sharma, A., Choudhary, V., Dilkina, B., Tambe,
M., 2019. Learning to prescribe interventions for tuberculosis pa-
tients using digital adherence data, in: Proceedings of the 25th ACM
SIGKDD International Conference on Knowledge Discovery & Data
Mining, ACM, Anchorage, AK, USA. pp. 2430–2438.

Kushner, R.F., Batsis, J.A., Butsch, W.S., Davis, N., Golden, A., Halperin,
F., Kidambi, S., Machineni, S., Novick, M., Port, A., Rubino, D.M.,
Saunders, K.H., Shapiro Manning, L., Soleymani, T., Kahan, S., 2020.
Weight history in clinical practice: The state of the science and future
directions. Obesity 28, 9–17.

Lee, C., Yoon, J., Schaar, M.v.d., 2020. Dynamic-deephit: A deep learning
approach for dynamic survival analysis with competing risks based on
longitudinal data.
IEEE Transactions on Biomedical Engineering 67,
122–133.

Linardon, J., Fuller-Tyszkiewicz, M., 2020. Attrition and adherence in
smartphone-delivered interventions for mental health problems: A sys-
tematic and meta-analytic review. Journal of consulting and clinical psy-
chology 88, 1.

Lundberg, S., Lee, S.I., 2017a. A uniﬁed approach to interpreting model

predictions. arXiv:1705.07874.

Lundberg, S.M., Lee, S.I., 2017b. A uniﬁed approach to interpreting model
predictions, in: Guyon, I., Luxburg, U.V., Bengio, S., Wallach, H., Fer-
gus, R., Vishwanathan, S., Garnett, R. (Eds.), Advances in Neural Infor-
mation Processing Systems 30. Curran Associates, Inc., pp. 4765–4774.
Martin, K.S., Ferris, A.M., 2007. Food insecurity and gender are risk fac-
tors for obesity. Journal of Nutrition Education and Behavior 39, 31–36.
Mitchell, A.J., Selmes, T., 2007. Why don’t patients attend their appoint-
ments? maintaining engagement with psychiatric services. Advances in
Psychiatric Treatment 13, 423–434.

Moran, L., Noakes, M., Clifton, P., Buckley, J., Brinkworth, G., Thomson,
R., Norman, R., 2019. Predictors of lifestyle intervention attrition or
weight loss success in women with polycystic ovary syndrome who are
overweight or obese. Nutrients 11, 492.

Moroshko, I., Brennan, L., O’Brien, P., 2011. Predictors of dropout in
weight loss interventions: a systematic review of the literature. Obesity

Hamed Fayyaz et al.: Preprint submitted to Elsevier

Page 8 of 9

A machine learning approach for predicting attrition patterns

Reviews 12, 912–934.

Murray, E., White, I.R., Varagunam, M., Godfrey, C., Khadjesari, Z., Mc-
Cambridge, J., 2013. Attrition revisited: Adherence and retention in a
web-based alcohol trial. J Med Internet Res 15, e162.

Ogden, C.L., Carroll, M.D., Kit, B.K., Flegal, K.M., 2014. Prevalence of
Childhood and Adult Obesity in the United States, 2011-2012. JAMA
311, 806–814.

Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel,
O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., et al., 2011.
Scikit-learn: Machine learning in python. the Journal of machine Learn-
ing research 12, 2825–2830.

Perna, S., Spadaccini, D., Riva, A., Allegrini, P., Edera, C., Faliva, M.A.,
Peroni, G., Naso, M., Nichetti, M., Gozzer, C., et al., 2018. A path model
analysis on predictors of dropout (at 6 and 12 months) during the weight
loss interventions in endocrinology outpatient division. Endocrine 61,
447–461.

Phan, T.L.T., Chen, F.F., Pinto, A.T., Cox, C., Robbins, J., Kazak, A.E.,
2018. Impact of psychosocial risk on outcomes among families seeking
treatment for obesity. The Journal of pediatrics 198, 110–116.

Ponzo, V., Scumaci, E., Goitre, I., Beccuti, G., Benso, A., Belcastro, S.,
Crespi, C., De Michieli, F., Pellegrini, M., Scuntero, P., Marzola, E.,
Abbate-Daga, G., Ghigo, E., Broglio, F., Bo, S., 2020. Predictors of
attrition from a weight loss program. a study of adult patients with obe-
sity in a community setting. Eating and Weight Disorders - Studies on
Anorexia, Bulimia and Obesity 25, 1–8.

Sabit, R., Griﬃths, T.L., Watkins, A.J., Evans, W., Bolton, C.E., Shale,
D.J., Lewis, K.E., 2008. Predictors of poor attendance at an outpatient
pulmonary rehabilitation programme. Respiratory Medicine 102, 819–
824.

Schuster, M., Paliwal, K.K., 1997. Bidirectional recurrent neural networks.

IEEE transactions on Signal Processing 45, 2673–2681.

Shipe, M.E., Deppen, S.A., Farjah, F., Grogan, E.L., 2019. Developing
prediction models for clinical use using logistic regression: an overview.
Journal of thoracic disease 11, S574.

Skinner, A.C., Skelton, J.A., 2014. Prevalence and trends in obesity and
severe obesity among children in the united states, 1999-2012. JAMA
pediatrics 168, 561–566.

Son, Y.J., Kim, H.G., Kim, E.H., Choi, S., Lee, S.K., 2010. Application of
support vector machine for prediction of medication adherence in heart
failure patients. Healthcare informatics research 16, 253–259.

Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N.,
Kaiser, L., Polosukhin, I., 2017. Attention is all you need. arXiv preprint
arXiv:1706.03762 .

Wilﬂey, D.E., Saelens, B.E., Stein, R.I., Best, J.R., Kolko, R.P., Schecht-
man, K.B., Wallendorf, M., Welch, R.R., Perri, M.G., Epstein, L.H.,
2017. Dose, Content, and Mediators of Family-Based Treatment for
Childhood Obesity: A Multisite Randomized Clinical Trial. JAMA Pe-
diatrics 171, 1151–1159.

Y-PSC, P., 1994. Pediatric symptom checklist. Journal of Developmental

and Behavioral Pediatrics 15, 191–197.

Hamed Fayyaz et al.: Preprint submitted to Elsevier

Page 9 of 9

