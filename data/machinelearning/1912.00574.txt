9
1
0
2

c
e
D
2

]

G
L
.
s
c
[

1
v
4
7
5
0
0
.
2
1
9
1
:
v
i
X
r
a

Fastened CROWN: Tightened Neural Network Robustness Certiﬁcates

Zhaoyang Lyu,1∗ Ching-Yun Ko,2∗ Zhifeng Kong,3 Ngai Wong,4 Dahua Lin,1 Luca Daniel2
1The Chinese University of Hong Kong, Hong Kong, China
2Massachusetts Institute of Technology, Cambridge, MA 02139, USA
3University of California San Diego, La Jolla, CA 92093, USA
4The University of Hong Kong, Hong Kong, China
lyuzhaoyang@link.cuhk.edu.hk, cyko@mit.edu, z4kong@eng.ucsd.edu
nwong@eee.hku.hk, dhlin@ie.cuhk.edu.hk, luca@mit.edu

Abstract

The rapid growth of deep learning applications in real life
is accompanied by severe safety concerns. To mitigate this
uneasy phenomenon, much research has been done providing
reliable evaluations of the fragility level in different deep neu-
ral networks. Apart from devising adversarial attacks, quanti-
ﬁers that certify safeguarded regions have also been designed
in the past ﬁve years. The summarizing work of Salman et al.
uniﬁes a family of existing veriﬁers under a convex relaxation
framework. We draw inspiration from such work and further
demonstrate the optimality of deterministic CROWN (Zhang
et al. 2018) solutions in a given linear programming problem
under mild constraints. Given this theoretical result, the com-
putationally expensive linear programming based method is
shown to be unnecessary. We then propose an optimization-
based approach FROWN (Fastened CROWN): a general al-
gorithm to tighten robustness certiﬁcates for neural networks.
Extensive experiments on various networks trained individ-
ually verify the effectiveness of FROWN in safeguarding
larger robust regions.

Introduction
The vulnerability of deep neural networks remains an un-
revealed snare in the beginning years of the deep learn-
ing resurgence. In 2014, Szegedy et al. uncovered the dis-
covery of hardly-perceptible adversarial perturbations that
could fool image classiﬁers. This discovery agonized the fast
development of accuracy-oriented deep learning and shifted
community’s attentions to the fragility of trained models. Es-
pecially with the increasing adoption of machine learning
and artiﬁcial intelligence in safety-critical applications, the
vulnerability of machine learning models to adversarial at-
tacks has become a vital issue (Sharif et al. 2016; Kurakin,
Goodfellow, and Bengio 2017; Carlini and Wagner 2017;
Wong and Kolter 2018). Addressing this urging issue re-
quires reliable ways to evaluate the robustness of a neural
network, namely by studying the safety region around a data
point where no adversarial example exists. This understand-
ing of machine learning models’ vulnerability will, on the

∗Equal contribution. Source code and the appendix are available

at https://github.com/ZhaoyangLyu/FROWN.
Copyright c(cid:13) 2020, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

other hand, help industries build more robust intelligent sys-
tems.

Disparate ways of reasoning and quantifying vulnerabil-
ity (or robustness) of neural networks have been exploited
to approach this dilemma, among which attack-based meth-
ods have long been in a dominating position. In these years,
a sequel of adversarial attack algorithms have been pro-
posed to mislead networks’ predictions in tasks such as
object detection (Goodfellow, Shlens, and Szegedy 2015;
Moosavi-Dezfooli, Fawzi, and Frossard 2016), visual ques-
tion answering (Mudrakarta et al. 2018; Zeng et al. 2019;
Gao et al. 2019b; Gao et al. 2019a), text classiﬁcation (Pa-
pernot et al. 2016), speech recognition (Cisse et al. 2017;
Gong and Poellabauer 2017), and audio systems (Carlini
and Wagner 2018), where the level of model vulnerability is
quantiﬁed by the distortion between successful adversaries
and the original data points. Notably, the magnitudes of dis-
tortions suggested by attack-based methods are essentially
upper bounds of the minimum adversarial distortion.

In contrast to attack-based approaches, attack-agnostic
veriﬁcation-based methods evaluate the level of network
vulnerability by either directly estimating (Szegedy et al.
2014; Weng et al. 2018b) or lower bounding (Hein and
Andriushchenko 2017; Raghunathan, Steinhardt, and Liang
2018; Dvijotham et al. 2018; Zhang et al. 2018; Singh et al.
2018; Weng et al. 2019) the minimum distortion networks
can bear for a speciﬁc input sample. As an iconic robustness
estimation, CLEVER (Weng et al. 2018a) converts the ro-
bustness evaluation task into the estimation of the local Lip-
schitz constant, which essentially associates with the max-
imum norm of the local gradients w.r.t. the original exam-
ple. Extensions of CLEVER (Weng et al. 2018c) focuses on
twice differentiable classiﬁers and works on ﬁrst-order Tay-
lor polynomial with Lagrange remainder.

A number of veriﬁcation-based methods have been pro-
posed in literature to compute a lower bound of the safe-
guarded region around a given input, i.e. a region where
the network is guaranteed to make consistent predictions de-
spite any input perturbations. A pioneering work in provid-
ing certiﬁable robustness veriﬁcation (Szegedy et al. 2014)
computes the product of weight matrix operator norms in
ReLU networks to give a lower-bounding metric of the

 
 
 
 
 
 
Notation
Deﬁnition
F : Rn → Rt
neural network classiﬁer
n
input size
nk
number of neurons in layer k
j (x) : Rn → R linear lower bound of Fj(x)
F L
j (x) : Rn → R linear upper bound of Fj(x)
F U
s[k−1]U
s[k−1]L
a[k]

set {s(1)U , . . . , s(k−1)U }
set {s(1)L, . . . , s(k−1)L}
set {a(1), , a(2), ..., a(k)}

Table 1: List of Notations

Notation Deﬁnition
x0 ∈ Rn
a(k)
[K]
γ(k)L
j
γ(k)U
j
t[k−1]U
t[k−1]L
z[k]

original input
the hidden state of the k-th layer
set {1, 2, · · · , K}
global lower bound of z(k)
global upper bound of z(k)
j
set {t(1)U , . . . , t(k−1)U }
set {t(1)L, . . . , t(k−1)L}
set {z(1), , z(2), ..., z(k)}

j

Notation
x ∈ Rn
z(k)
Bp(x0, (cid:15))

l (cid:52) z (cid:52) u

neg(x) =

σ

Deﬁnition
perturbed input
the pre-activation of the k-th layer
{x | (cid:107)x − x0(cid:107)p ≤ (cid:15)}
lr ≤ zr ≤ ur,
∀ r ∈ [s], l, z, u ∈ Rs
x, if x ≤ 0;
0, otherwise.
ReLU/ Sigmoid/ Tanh activation

minimum distortion. However, this certiﬁcate method was
shown to be generally too conservative to be useful (Hein
and Andriushchenko 2017; Weng et al. 2018b). Later,
tighter bounds have also been provided for continuously-
differentiable shallow networks by utilizing local Lipschitz
constants of the network (Hein and Andriushchenko 2017).
Then, for the ﬁrst time, the formal veriﬁcation problem is
reduced from a mixed integer linear programming (MILP)
problem to a linear programming (LP) problem when deal-
ing with l∞-norm box constraints (Wong and Kolter 2018).
Its concurrent works include Fast-Lin (Weng et al. 2018b),
which analytically calculates bounds for perturbed sam-
ples in given regions and ﬁnds the largest certiﬁable re-
gion for ReLU networks through binary search. Fast-Lin is
further generalized for multilayer perceptrons with general
activation functions in CROWN (Zhang et al. 2018). Re-
cently, Salman et al. conclude a general framework for a
genre of convex relaxed optimization problems and demon-
strate existing approaches to be special cases of their pro-
posal. Notably, although Wong and Kolter propose to verify
the robustness for ReLU network by the use of LP, a feasible
dual solution is instead used in practice to avoid any actual
use of LP solvers. Comparatively, Salman et al. experiment
with more than one linear function to bound nonlinear acti-
vations (e.g. 2 lower-bounding functions for ReLU act.) and
stick to LP solvers.

Certiﬁable robustness lower bounds are especially vital in
safety-critical scenarios (e.g. autonomous driving car) since
any miss-classiﬁcation can be lethal. However, albeit be-
ing useful, new challenges with these certiﬁable quantiﬁers
arise. There are, in most cases, non-negligible gaps between
the certiﬁed lower and upper bounds of the minimum distor-
tion. This inconsistency in the quantiﬁcation questions di-
minishes the use of these state-of-the-art robustness evalua-
tion approaches.

In this article, we stay in line with the previous sequel of
works that focus on linear bounds and provide two major
contributions:

1. We prove that if we limit the constraint relaxation to be
exactly one linear bound in each direction (upper and
lower) in the LP-based method, the results provided by
CROWN are optimal. Therefore the costly LP solving
process is unnecessary under this relaxation.

2. We propose a general optimization framework that we
name FROWN (Fastened CROWN) for tightening the
certiﬁable regions guaranteed by CROWN, which is also

theoretically applicable to tighten convolutional neural
network certiﬁcate CNN-Cert (Boopathy et al. 2019) and
recurrent neural network certiﬁcate POPQORN (Ko et al.
2019).

Backgrounds
This section summarizes the most relevant backgrounds of
our proposals. Speciﬁcally, LP formulation (Salman et al.
2019) is summarized, together with the seminal work of
Fast-Lin (Weng et al. 2018b) and CROWN (Zhang et al.
2018) (generalized Fast-Lin). We ﬁrst begin by giving the
deﬁnition of an m-layer neural network:

Deﬁnitions. Given a trained m-layer perceptron F , we de-
note the hidden unit, weight matrix, bias, and pre-activation
unit of the k-th layer (k ∈ [m]) as a(k), W(k), b(k), and z(k),
respectively. Hence, z(k) = W(k)a(k−1) + b(k), a(k) =
σ(z(k)), where a0 = x0 ∈ Rn is the original input
and F (x) = z(m) is the network output. Denoting the
number of neurons as nk for the k-th layer, implies that
a(k), z(k), b(k) ∈ Rnk and W(k) ∈ Rnk×nk−1, for k ∈ [m].
Furthermore, we use square brackets in the superscripts to
group a set of variables (e.g. a[m] denotes the set of variables
{a(1), , a(2), ..., a(m)} and z[m] denotes the set of variables
{z(1), , z(2), ..., z(m)}). Table 1 summarizes all the notations
we use in this paper.

When quantifying the robustness of the m-layer neural
network, one essentially wants to know 1) how far the net-
work output will deviate when the input is perturbed with
distortions of a certain magnitude and 2) the critical point in
terms of distortion magnitudes, beyond which the deviation
might alter the model prediction. If we let x ∈ Rn denote
the perturbed input of x0 (class i) within an (cid:15)-bounded lp-
ball (i.e., x ∈ Bp(x0, (cid:15)), or(cid:107)x − x0(cid:107)p ≤ (cid:15)), the task of ro-
bustness analysis for this network intrinsically involves the
comparison between the i-th network output Fi(x) and other
outputs Fj(cid:54)=i(x). In practice, one can translate the original
problem to the problem of deriving a lower bound of Fi(x)
and upper bounds of Fj(cid:54)=i(x) for perturbed inputs within the
lp-norm ball. With such quantiﬁer, network F is guaranteed
to make consistent predictions within the lp-norm ball if the
lower bound of the original class output is always larger than
the upper bounds of all other classes’ outputs.

We summarize below the LP problem (Salman et al. 2019)
to solve the lower bound of Fi(x). The LP problem for the

upper bound of Fj(cid:54)=i(x) can be similarly derived.

The LP problem. The optimization problem for solving
the lower bound of Fi(x) = z(m)
i,: a(m−1) + b(m)
reads:

i = W(m)

i

min
a(0)∈Bp(x0,(cid:15)),a[m−1],z[m−1]
(cid:26)z(k) = W(k)a(k−1) + b(k), ∀ k ∈ [m − 1],

i,: a(m−1) + b(m)

W(m)

i

(1)

a(k) = σ(z(k)), ∀ k ∈ [m − 1].

s.t.

The optimization problem for upper bounds can be read-
ily obtained by replacing the “min” operation by “max”.
Then, the nonlinear constraint in (1) is lifted with linear re-
laxations. Speciﬁcally, suppose the lower and upper bounds
of the pre-activation units z[m−1] are known, namely, for k
from 1 to m − 1, as a result l(k) and u(k) satisfy

l(k) (cid:52) z(k) (cid:52) u(k),

(2)

and therefore every element σ(z(k)
) of the nonlinear acti-
vation σ(z(k)) in constraint (1) can be bounded by linear
functions:
(z(k)
h(k)L
i
i

i ∈ [l(k)

) ≤ h(k)U
i

) ≤ σ(z(k)

), ∀z(k)

, u(k)
i

(z(k)
i

i

i

i

],
(3)

i

for i ∈ [nk]. The existence of linear bounding func-
tions in (3) is guaranteed since z(k)
is bounded and
compactness is a continuous invariant within any inter-
val. For example, the following are bounding functions:
h(k)L
(z(k)
) =
,u(k)
i
i
i
)). h(k)L
maxz(k)
can also be
i
taken as the pointwise supremum and inﬁmum of several
linear functions, respectively, which is equivalent to using
multiple linear constraints. In practice, Salman et al. use lin-
ear functions characterized by slopes and intercepts:

) = minz(k)
](σ(z(k)

)), h(k)U
i
and h(k)U
i

](σ(z(k)

i ∈[l(k)

i ∈[l(k)

(z(k)
i

,u(k)
i

i

i

i

i

h(k)L
i
h(k)U
i

(z(k)
i
(z(k)
i

) = s(k)L
i
) = s(k)U
i

z(k)
i + t(k)L
i + t(k)U
z(k)

i

i

,

.

(4)

The optimization problem can therefore be relaxed to an LP-
alike problem1:

min
a(0)∈Bp(x0,(cid:15)),a[m−1],z[m−1]

W(m)

i,: a(m−1) + b(m)

i

(5)

s.t.






z(k) = W(k)a(k−1) + b(k), ∀ k ∈ [m − 1],
h(k)L(z(k)) (cid:52) a(k) (cid:52) h(k)U (z(k)), ∀ k ∈ [m − 1],
l(k) (cid:52) zk (cid:52) u(k), ∀ k ∈ [m − 1].

Recalling that with the optimization formed as in Prob-
lem (5), one is essentially optimizing for the lower (or upper)
output bounds of the network (the pre-activation of the m-th

1The optimization problem turns to a strict LP problem only
when we have p = ∞ or 1 that makes the feasible set a polyhe-
dron. However we coarsely denote all the cases in general as LP
problems since all the constraints are now linear in the variables.

layer), whereas these build upon the assumption that the pre-
activation bounds are known as Equation (2). To satisfy this
assumption, one actually only needs to substitute the layer
index m in Problem (5) with the corresponding intermedi-
ate layer’s index. In practice, one can recursively solve LP
problems from the second layer to the m-th layer to obtain
the pre-activation bounds for all layers. In this process, the
pre-activation bounds computed in a layer also constitute the
optimization constraint for the next to-be-solved optimiza-
tion problem for the next layer’s pre-activation. See details
of this LP-based method in Appendix Section A.3.

CROWN Solutions. Here we brieﬂy walk through
the derivation of Fast-Lin (Weng et al. 2018b) and
CROWN (Zhang et al. 2018), whose procedures are essen-
tially the same except for activation-speciﬁc bounding rules
adopted. The ﬁrst steps include bounding z(k)

, k ∈ [m] 2.

i

z(k)
i =

≥

nk−1
(cid:88)

j=1

nk−2
(cid:88)

j=1

W(k)

i,j σ(z(k−1)

j

) + b(k)

i

,

˜W(k−1)
i,j

σ(z(k−2)
j

) + ˜b(k−1)
i

,

(6)

(7)

,

:,j

=

= [relu(W(k)

i,: )t(k−1)L + neg(W(k)

i,: ) (cid:12) (s(k−1)L)(cid:62) + neg(W(k)
[relu(W(k)

where neg(x) = x, if x ≤ 0; neg(x) = 0, otherwise. And
˜W(k−1)
i,: ) (cid:12)
i,j
˜b(k−1)
(s(k−1)U )(cid:62)]W(k−1)
i,: ) (cid:12)
i
(s(k−1)L)(cid:62) + neg(W(k)
i,: ) (cid:12) (s(k−1)U )(cid:62)]b(k−1) +
i,: )t(k−1)U + b(k)
relu(W(k)
, where
(cid:12) denotes element-wise products. As Equations (6) and (7)
are in similar forms, the above procedures can be repeated
until all the nonlinearities in k − 1 layers are unwrapped
by linear bounding functions and z(k)
is upper bounded by
i
(cid:80)n
, where ˜W(1)
are similarly
deﬁned as shown above. Taking the dual form of the bound
then yields the closed-form bound γL

i,j xj + ˜b(1)

i,j and ˜b(1)

˜W(1)

j=1

i

i

i

i ≥ γ(k)L
z(k)

i

:= ˜W(1)

i,: x0 − (cid:15)(cid:107) ˜W(1)

,

(8)

i

∀ x ∈ Bp(x0, (cid:15)), where 1/p + 1/q = 1. Although the
steps above are used to derive the closed-form lower bound,
the closed-form upper bound γ(k)U
can be similarly de-
rived. To quantify the robustness for an m-layer neural net-
work, one needs to recursively adopt formulas in Equa-
tion (8) to calculate the bounds of pre-activation3 z(k),
for k = 2, . . . , m. These bounds, as will be explained
in more details later, conﬁne the feasible set for choosing
bounding linear functions in Equation (4). Notably, lower
bound γ(k)L
are implicitly reliant
to slopes of bounding lines in previous layers s[k−1]U =

and upper bound γ(k)U

i

i

2Similar to the discussion in the LP-based method above, the
bounds computed are exactly network output bounds when k =
m; whereas k (cid:54)= m gives the pre-activation bounds to fulﬁll the
assumption in Inequality (2).

3z(1) is deterministically computed by the input and z(m) =

F (x) is the output bound.

j that satisﬁes
i,: (cid:107)q + ˜b(1)

i

{s(1)U , . . . , s(k−1)U }, s[k−1]L = {s(1)L, . . . , s(k−1)L} and
their intercepts t[k−1]U = {t(1)U , . . . , t(k−1)U }, t[k−1]L =
{t(1)L, . . . , t(k−1)L}. A major difference that distinguishes
CROWN from our contributions in the following sections
is its deterministic rules of choosing upper/lower-bounding
lines. The readers are referred to the literature (Zhang et al.
2018) or Sections A.2 and A.4 in the appendix for more de-
tails of CROWN.

Relation Between the LP Problem and
CROWN Solutions
Now we discuss the relationship between the LP prob-
lem formulation and CROWN. A key conclusion is that:
CROWN is not only a dual feasible solution of the presented
LP problem as discussed by Salman et al., it gives the opti-
mal solution under mild constraints.

i

, then the following condition holds,

Before introducing the optimality of CROWN solutions
under the LP framework, we deﬁne an important condition
in the computation process of CROWN as below:
Condition 1 Self-consistency. Suppose {˜s[v−1]U , ˜s[v−1]L,
˜t[v−1]U , ˜t[v−1]L} are used to calculate γ(v)L
and γ(v)U
,
i
{ˆs[k−1]U , ˆs[k−1]L, ˆt[k−1]U , ˆt[k−1]L} are used to calculate
γ(k)L
j

and γ(k)U
j
˜s[v−1]U = ˆs[v−1]U , ˜s[v−1]L = ˆs[v−1]L,
˜t[v−1]U = ˆt[v−1]U , ˜t[v−1]L = ˆt[v−1]L,
for ∀ i ∈ [nv], ∀j ∈ [nk], 2 ≤ v ≤ k ≤ m and two sets
equal to each other is deﬁned as their corresponding ele-
ments equal to each other.
A similar condition can also be deﬁned in the LP-based
method and is supplemented in Section A.3 in the appendix.
The self-consistency condition guarantees the same set of
bounding lines is used when computing bounds for different
neurons in the process of CROWN or the LP-based method.
We note that both the original CROWN and the LP-based
method satisfy the self-consistency condition.
Theorem 1 The lower bound obtained by Equation (8) is
the optimal solution to Problem (5) when the following three
conditions are met:
• Each of the h(k)L(zk) and h(k)U (zk) in Problem (5) is
chosen to be one linear function4 as in Equation (4).
• The LP problem shares the same bounding lines with

Figure 1: The process of CROWN using different bounding
lines to compute the closed-form bounds for different neu-
rons. The blue curves are the ReLU activation. The orange
and green lines are the upper and lower bounding lines, re-
spectively. When computing closed-form bounds of the pre-
activation of neurons in the second layer, different neurons
can choose different bounding lines in the previous layers to
yield the tightest closed-form bounds for themselves.

Fastened CROWN
Recognizing the dependency of lower bounds and upper
bounds to slopes and intercepts in the original CROWN
method, a consistent use of these parameters is enforced
through the self-consistency condition. In fact, we argue
that this constraint can be lifted in general (we visualize
this relaxation in Figure 1). The aim of this section stems
from this relaxation and focuses on optimizing the pre-
activation/output bounds over these tunable bounding pa-
rameters to achieve tighter bounds. In that merit, we pro-
pose an optimization framework called FROWN (Fastened
CROWN) for tightening robustness certiﬁcates in CROWN.
Moreover, FROWN is versatile and can be widely ap-
plied to tighten previously-proposed CNN-Cert (Boopa-
thy et al. 2019) for convolutional neural networks and
POPQORN (Ko et al. 2019) for recurrent neural networks.
We formalize the objective as the following two optimiza-
tion problems:

γ(k)L
i

(9)

max
s[k−1]L,s[k−1]U ,t[k−1]L,t[k−1]U
s.t. s(v)L
i
∀ z(v)

i + t(v)L
z(v)
i
, u(v)
i ∈ [l(v)
i

i

≤ σ(z(v)

i

) ≤ s(v)U
i

i + t(v)U
z(v)

i

,

], i ∈ [nv], v ∈ [k − 1],

CROWN.

and

• The self-consistency conditions for both CROWN and the

LP-based method hold.

We refer readers to Section A.5 in the appendix for the proof.
We emphasize the cruciality of the self-consistency condi-
tions in Theorem 1: We do observe CROWN and the LP-
based method can give different bounds when Condition 1 is
not met, even though the two use the same bounding lines. In
essence, Theorem 1 allows one to compute bounds analyti-
cally and efﬁciently following steps in CROWN instead of
solving the expensive LP problems under certain conditions.

4Theoretically one can use multiple linear functions to bound

the nonlinearity in Problem (5) to obtain tighter bounds.

γ(k)U
i

(10)

min
s[k−1]L,s[k−1]U ,t[k−1]L,t[k−1]U
s.t. s(v)L
i
∀ z(v)

z(v)
i + t(v)L
i
, u(v)
i ∈ [l(v)
i

i

≤ σ(z(v)

i

) ≤ s(v)U
i

i + t(v)U
z(v)

i

,

], i ∈ [nv], v ∈ [k − 1].

However, we stress that Problems (9) and (10) are gener-
ally non-convex optimization problems when there are more
than two layers in the target network. We enclose the proof
as Section A.7 in the appendix. Therefore, optimizing for
a non-convex objective function over parameters in large
search spaces with inﬁnite number of constraints is imprac-
tical. To this end, our ideas are to limit the search space to

Table 2: Search space of bounding lines for ReLU, Sigmoid, and Tanh functions. “Variable” is the optimization variable that
characterizes the bounding line. “Range” is the feasible region of the variable. “-” indicates the case when the tightest bounding
line is unique and chosen. The slope and intercept of ReLU upper-bounding line are always set to be s0 and t(s0, l), respectively.
Sigmoid & Tanh (Upper bnd.)

ReLU (Lower bnd.)

l < u ≤ 0

l < 0 < u

0 ≤ l < u

l < u ≤ 0

0 ≤ l < u

l < u ≤ 0

0 ≤ l < u

-
-
s0
t(s0, l)

-
-
s0
t(s0, l)
Notes: Case 1 refers to σ(cid:48)(u)l + t(σ(cid:48)(u), u) ≥ σ(l); and case 2, otherwise. Case 3 refers to σ(cid:48)(l)u + t(σ(cid:48)(l), l) ≤ σ(u); and case 4, otherwise. s0 = [σ(u) − σ(l)]/
(u − l), t(s, y) = σ(y) − sy. ld and ud are deﬁned as the abscissas of the points at which the tangent passes the left endpoint (l, σ(l)) and the right endpoint (u, σ(u)),
respectively. d1 and d2 are the abscissas of the points of tangency. See Figure 2 for the visualization of ld, ud, d1 and d2.

d1
[l, u]
σ(cid:48)(d1)
t(σ(cid:48)(d1), d1)

d2
[l, u]
σ(cid:48)(d2)
t(σ(cid:48)(d2), d2)

-
-
s0
t(s0, l)

-
-
s0
t(s0, l)

s
[0, 1]
s
0

l < 0 < u

case 1
d1
[ld, u]
σ(cid:48)(d1)
t(σ(cid:48)(d1), d1)

case 2
-
-
s0
t(s0, l)

Sigmoid & Tanh (Lower bnd.)
l < 0 < u

case 3
d2
[l, ud]
σ(cid:48)(d2)
t(σ(cid:48)(d2), d2)

case 4
-
-
s0
t(s0, l)

Nonlinearity
Pre-activation
Bounds
Variable
Range
Slope
Intercept

adopt one of the tightest bounding lines in every layer for
generally tighter closed-form pre-activation/output bounds.
However, the proposition:

tighter bounding lines ⇒ tighter closed-form bounds
is not always true. We observe tighter bounding lines can
sometimes lead to looser bounds. However, if we roll back
to Condition 1, we can prove that it constitutes a sufﬁcient
condition for the proposition.
Theorem 2 If
net-
robustness
work is evaluated by CROWN on two trials with
two
character-
and
ized
{ˆs[k−1]U , ˆs[k−1]L, ˆt[k−1]U , ˆt[k−1]L}, and in both of which
the self-consistency condition is met, then the closed-form
bounds obtained via CROWN satisfy

bounding
{˜s[k−1]U , ˜s[k−1]L, ˜t[k−1]U , ˜t[k−1]L}

different
by

neural

lines

sets

the

of

of

a

γ(k)L
i
γ(k)L
i
γ(k)U
i
γ(k)U
i

(˜s[k−1]U , ˜s[k−1]L, ˜t[k−1]U , ˜t[k−1]L) ≥
(ˆs[k−1]U , ˆs[k−1]L, ˆt[k−1]U , ˆt[k−1]L),
(˜s[k−1]U , ˜s[k−1]L, ˜t[k−1]U , ˜t[k−1]L) ≤
(ˆs[k−1]U , ˆs[k−1]L, ˆt[k−1]U , ˆt[k−1]L),

for ∀ i ∈ [nk], when bounding lines determined
by {˜s[k−1]U , ˜s[k−1]L, ˜t[k−1]U , ˜t[k−1]L} are the same as
or tighter than those determined by {ˆs[k−1]U , ˆs[k−1]L,
ˆt[k−1]U , ˆt[k−1]L}.
Proof: The self-consistency guarantees the optimality of
bounds given by CROWN to the corresponding LP prob-
lem (5) according to Theorem 1. As the use of tighter bound-
ing lines in Problem (5) narrows the feasible set, the optimal
value of Problem (5) (lower pre-activation/output bound)
will stay or grow larger, which means the lower bound given
by CROWN will stay or grow larger. Similar arguments ex-
(cid:3)
tend to tightened upper bounds.
Till now, we have conﬁrmed the connection between
the tightest bounding lines and the tightest CROWN pre-
activation/output bound under Condition 1. In addition, we
manage to prove Theorem 2 under a weaker condition (see
its proof in Section A.6 in the appendix).

Condition 1 is too strong a condition for our proposed op-
timization framework to be practical. Actually we propose
to improve CROWN by breaking Condition 1. Our prob-
lem can be eased by only considering the dependency of
closed-form pre-activation/output bounds on the intercepts
(with the slopes ﬁxed). We provide the following theorem:

(a) 0 ≤ l < u

(b) l < 0 < u

(c) l < u ≤ 0

(d) l < 0 < u

Figure 2: Illustration of the search space of bounding
lines for Sigmoid and ReLU activation. See deﬁnitions of
d1, d2, ud, ld in Table 2.

i

i

i

)

), ∀ z(k)

) = ˆs(k)L

) = ˜s(k)L
i

, u(k)
i
]

i + ˜t(k)L
z(k)

(z(k)
i
i
i + ˆt(k)L
z(k)

and
are two lower-bounding

) > ˆh(k)L
(z(k)
i
i
(z(k)
), ∀ z(k)
i
) = ˜s(k)L
(z(k)
i

i ∈ (l(k)
i
i ∈ [l(k)
, u(k)
i
i + ˜t(k)L
z(k)
i
) = ˆs(k)L
i

smaller ones. We present our solutions by ﬁrst introducing
the ideas of “tighter” bounding lines.
Deﬁnition 1 Suppose ˜h(k)L
ˆh(k)L
(z(k)
i
i
lines that satisfy
(cid:40)˜h(k)L
(z(k)
i
i
) ≥ ˜h(k)L
σ(z(k)
i
i
then we say ˜h(k)L
i
i
lower-bounding line than ˆh(k)L
for the nonlinear activation σ in the interval [l(k)
Similarly, we deﬁne a tighter upper-bounding line. Accord-
ingly, the tightest bounding line refers to the ˆh(k)L
when
there is, by deﬁnition, no tighter bounding line than itself.
Note that the tightest bounding line may not be unique. For
example, any line passing through the origin with a slope be-
tween 0 and 1 is a tightest lower-bounding line for the ReLU
activation in an interval across the origin (l(v)
i < 0 < u(v)
).
With the notion of tightness, a straightforward idea is to

is a tighter
i + ˆt(k)L
z(k)
i
, u(k)
].
i

(z(k)
i

i

i

i

i

i

Theorem 3 If the robustness of a neural network is eval-
uated by CROWN on two trials with bounding lines
characterized by {s[k−1]U , s[k−1]L, ˜t[k−1]U , ˜t[k−1]L} and
{s[k−1]U , s[k−1]L, ˆt[k−1]U , ˆt[k−1]L},
then the closed-form
bounds obtained via CROWN satisfy

γ(k)L
i
γ(k)L
i
γ(k)U
i
γ(k)U
i

(s[k−1]U , s[k−1]L, ˜t[k−1]U , ˜t[k−1]L) ≥
(s[k−1]U , s[k−1]L, ˆt[k−1]U , ˆt[k−1]L),
(s[k−1]U , s[k−1]L, ˜t[k−1]U , ˜t[k−1]L) ≤
(s[k−1]U , s[k−1]L, ˆt[k−1]U , ˆt[k−1]L),

for ∀ i ∈ [nk], when ˜t(v−1)L (cid:60) ˆt(v−1)L and ˜t(v−1)U (cid:52)
ˆt(v−1)U , ∀v ∈ [k − 1].

This theoretical guarantee limits the freedom in choosing the
intercepts: we should always choose upper-bounding lines
with smaller intercepts and lower-bounding lines with larger
intercepts if different bounding lines are allowed for differ-
ent network neurons. Note that this conclusion holds under
no assumptions on the choice of bounding lines and hence
can be used to instruct how to choose bounding lines in
FROWN. We demonstrate Theorem 3 can be used to reduce
the search space of the upper (or lower) bounding line to
one that can be characterized by a single variable continu-
ously in Appendix Section A.8. This enables the usage of
gradient-based method to search over candidate bounding
lines to obtain tighter bounds. We further limit the search
space to the tightest bounding lines (which is a subset of
the search space narrowed only by Theorem 3) as demon-
strated in Table 2 and exempliﬁed in Figure 2 in order to
simplify implementation. We emphasize that this limit is not
necessary. FROWN can be readily generalized to the case
in which the search space is reduced only by Theorem 3,
and the obtained bounds should be even tighter as the search
space is larger. Since the tightest bounding lines deﬁned in
Table 2 automatically satisfy the optimization constraints in
Problems (9) and (10), the constrained optimization prob-
lems are then converted to unconstrained ones. Furthermore,
notice that the objective functions in the two problems are
differentiable to bounding line parameters. This allows us to
solve the problems by projected gradient descent (Nesterov
2014) (see details in Appendix Section A.9).

By and large, given an m-layer network F , input sample
x0 ∈ Rn, lp ball parameters p ≥ 1, and (cid:15) ≥ 0, for ∀ j ∈
[nm], 1/q = 1 − 1/p, we can compute two ﬁxed values
j such that ∀x ∈ Bp(x0, (cid:15)), the inequality γL
j and γU
γL
j ≤
Fj(x) ≤ γU
j holds. Suppose the label of the input sequence
is i, the largest possible lower bound (cid:15)i of untargeted and
targeted (target class j) attacks is found by solving:

Untargeted:

(cid:15)i = max

(cid:15)

Targeted:

ˆ(cid:15)(i, j) = max

(cid:15)

(cid:15), s.t. γL

(cid:15), s.t. γL

i ((cid:15)) ≥ γU
i ((cid:15)) ≥ γU

j ((cid:15)).

j ((cid:15)), ∀j (cid:54)= i.

We conduct binary search procedures to compute the largest
possible (cid:15)i (or ˆ(cid:15)).

Experimental Results

Overview.
In this section, we aim at comparing the LP-
based method5 and FROWN as two approaches to improve
CROWN. We allow the LP-based method to use more than
one bounding lines (which also increases computation cost)
in order to make improvement on CROWN. Speciﬁcally,
two lower-bounding lines are considered for ReLU networks
while up to three upper/lower-bounding lines are adopted for
Sigmoid (or Tanh) networks in the LP-based method (more
details supplemented as Section A.4 in the appendix). On
the other hand, FROWN improves CROWN solutions by
optimizing over the bounding lines to give tighter bounds.
These two approaches are evaluated and compared herein
by both the safeguarded regions they certify and their time
complexity. We run the LP-based method on a single Intel
Xeon E5-2640 v3 (2.60GHz) CPU. We implement our pro-
posed method FROWN using PyTorch to enable the use of
an NVIDIA GeForce GTX TITAN X GPU. However, we
time FROWN on a single Intel Xeon E5-2640 v3 (2.60GHz)
CPU when comparing with the LP-based method for fair
comparisons. We leave the detailed experimental set-ups and
complete experimental results to Appendix Section A.9.

Experiment I.
In the ﬁrst experiment, we compare the
improvements of FROWN and the LP-based method over
CROWN on sensorless drive diagnosis networks 6 and
MNIST classiﬁers. We present their results in Table 3. As
shown in the table, we consider ReLU and Sigmoid (results
of Tanh networks are included in Appendix Section A.9) net-
works that are trained independently on two datasets. The
size of the networks ranges from 3 layers to 20 layers and 20
neurons to 100 neurons. We remark that even on networks
with only 100 neurons, the LP-based method scales badly
and is unable to provide results in 100 minutes for only one
image. The improved bounds in Table 3 verify the effective-
ness of both FROWN and LP-based approach in tightening
CROWN results. Speciﬁcally, an up to 93% improvement
in the magnitude of bounds is witnessed on sensorless drive
diagnosis networks. And in general, the deeper the target
network is, the greater improvement can be achieved. When
comparing FROWN to the LP-based method, it is demon-
strated that FROWN computes bounds up to two orders of
magnitudes faster than the LP-based method and is espe-
cially advantageous when certifying l1-norm regions. On the
other hand, while the LP-based method gives larger certiﬁed
bounds for ReLU networks in most cases, FROWN certiﬁes
larger bounds for Sigmoid and Tanh networks.

Experiment II.
In our second experiment, we compute the
robustness certiﬁcate on CIFAR10 networks that have 2048
neurons in each layer. With the width of neural networks, the
LP-based method is unusable due to its high computational-
complexity. Therefore, we only show the improvements
FROWN has brought to the original CROWN solutions. In

5The highly-efﬁcient Gurobi LP solver is adopted here.
6https://archive.ics.uci.edu/ml/datasets/Dataset+for+

Sensorless+Drive+Diagnosis

Table 3: (Experiment I) Averaged certiﬁed l∞ bounds and lp bounds (p = 1, 2, ∞) of Sensorless Drive Diagnosis classiﬁers
and MNIST classiﬁers, respectively. ”N/A” indicates no results can be obtained in the given runtime. The up arrow “↑” means
“ more than”. “m × [N ] σ” means an m-layer network with N neurons and σ activation.

Sensorless Drive Diagnosis classiﬁers

Network

4 × [20] ReLU
8 × [20] ReLU
12 × [20] ReLU
4 × [20] Sigmoid
8 × [20] Sigmoid
12 × [20] Sigmoid

p

∞

∞

Certiﬁed Bounds

CROWN FROWN
0.2247
0.2019
0.2365
0.2094
0.2496
0.1996
0.1418
0.1019
0.1618
0.0858
0.1510
0.0782

LP
0.2269
0.2526
0.2740
0.1388
0.1626
0.1081

Improvement
LP

FROWN
11.27% 12.38%
12.95% 20.66%
25.05% 37.28%
39.08% 36.21%
88.62% 89.59%
93.06% 38.22%

Avg. Time per Image (s)
FROWN
0.35
1.81
4.39
0.74
4.15
8.71

LP
0.96
4.19
9.46
2.11
32.15
152.91

Speedups of
FROWN over LP
2.8 X
2.3 X
2.2 X
2.8 X
7.7 X
17.6 X

5 × [20]
ReLU

20 × [20]
ReLU

5 × [20]
Sigmoid

20 × [20]
Sigmoid

5 × [100]
ReLU

7 × [100]
ReLU

5 × [100]
Sigmoid

7 × [100]
Sigmoid

3.8018
1
0.5346
2
∞ 0.0261
2.3853
1
0.3656
2
∞ 0.0183
1.8009
1
0.3100
2
∞ 0.0153
1.5348
1
0.2524
2
∞ 0.0131
3.8928
1
0.5499
2
∞ 0.0261
3.5509
1
0.4997
2
∞ 0.0241
2.0998
1
0.3233
2
∞ 0.0156
1.7294
1
0.2833
2
∞ 0.0140

4.0835
0.5710
0.0278
3.1062
0.4925
0.0240
2.1340
0.3581
0.0174
1.9779
0.3261
0.0166
4.2343
0.5789
0.0276
3.9907
0.5347
0.0258
2.5184
0.3774
0.0186
2.2380
0.3427
0.0168

MNIST classiﬁers

4.2215
0.5587
0.0287
3.1735
0.5074
0.0245
2.1126
0.3417
0.0170
1.9730
0.2657
0.0153
N/A
0.5934
0.0278
N/A
N/A
N/A
N/A
0.2494
0.0177
N/A
N/A
N/A

1.69
7.41% 11.04%
1.12
6.81% 4.52%
1.26
6.52%
9.89%
30.22% 33.04% 35.53
34.71% 38.78% 31.10
30.84% 33.75% 43.31
1.75
18.49% 17.31%
1.23
15.51% 10.20%
1.39
13.94% 11.11%
31.80
28.87% 28.55%
31.77
29.21% 5.28%
44.86
27.01% 17.12%
13.11
N/A
7.91% 10.90
6.57% 10.42
55.07
49.49
44.94
13.64
12.38
13.09
48.96
42.04
42.00

8.77%
5.28%
5.85%
12.38%
N/A
7.01%
N/A
7.09%
N/A
19.93%
N/A
16.74% −22.84%
18.76% 13.10%
29.40%
N/A
20.96%
N/A
19.96%
N/A

195.07
41.63
11.93
1301.11
229.87
199.40
310.27
44.00
17.19
4904.99
1354.54
1859.68
6000.00↑
826.79
446.07
10000.00↑
10000.00↑
10000.00↑
10000.00↑
9368.58
1319.25
10000.00↑
10000.00↑
10000.00↑

115.5 X
37.1 X
9.5 X
36.6 X
7.4 X
4.6 X
177.2 X
35.9 X
12.4 X
154.3 X
42.6 X
41.5 X
457.8 X↑
75.9 X
42.8 X
181.6 X↑
202.1 X↑
222.5 X↑
733.0 X↑
757.1 X
100.8 X
204.3 X↑
237.9 X↑
238.1 X↑

Network

4 × [2048]
ReLU

4 × [2048]
Sigmoid

Table 4: (Experiment II) Averaged certiﬁed lp bounds of different classiﬁers on CIFAR10 Networks.
Certiﬁed Bounds
p
CROWN FROWN
4.9416
0.3809
0.0094
1.6862
0.1295
0.0033

Improve-
Certiﬁed Bounds
ment
CROWN FROWN
4.7241
2.72%
0.3723 −0.60%
0.95%
0.0093
22.11%
1.8430
22.71%
0.1448
21.03%
0.0035

Certiﬁed Bounds
CROWN FROWN
7.5989
7.5460
1
0.6303
0.6175
2
0.0157
∞ 0.0151
4.4726
3.6558
1
0.3353
0.2847
2
0.0082
∞ 0.0069

4.5990
1
0.3745
2
∞ 0.0092
1.5093
1
0.1180
2
∞ 0.0029

4.2349
1
0.3476
2
∞ 0.0087
1.2875
1
0.1006
2
∞ 0.0024

Improve-
ment
0.70%
2.09%
4.14%
22.34%
17.77%
18.33%

8 × [2048]
ReLU

8 × [2048]
Sigmoid

6 × [2048]
ReLU

6 × [2048]
Sigmoid

Network

Network

p

p

Improve-
ment
16.69%
9.59%
8.83%
30.97%
28.65%
37.65%

this experiment, we further speed up FROWN by optimizing
neurons in a layer group by group, instead of one by one,
and we provide a parameter to balance the trade-off between
tightness of bounds and time cost in FROWN(see details in
Appendix Section A.10). We observe consistent trends on
CIFAR10 networks: the deeper the neural network is, the
more signiﬁcant improvement can be made by FROWN in
tightening CROWN solutions. Notably, an up to 38% im-
provement in certiﬁed bounds is achieved when considering
l∞-norm balls in Sigmoid networks.

Discussion

ever, the LP-based approach suffers poor scalability and
soon becomes computationally infeasible as the network
grows deeper or wider. In contrast, FROWN manages to in-
crease the certiﬁed region of CROWN much more efﬁciently
and wins over the LP-based approach in almost all Sig-
moid/Tanh networks. Notably, in some cases, the LP-based
method gives even worse result than CROWN (those with
negative improvements). We conclude two possible reasons:
i) the Gurobi LP solver is not guaranteed to converge to
the optimal solution and ii) statistical ﬂuctuations caused by
random sample selections. More discussions on this are in-
cluded in Appendix Section A.9.

Overall, we have shown the trade-off between the computa-
tional costs and certiﬁed adversarial distortions in ReLU net-
works: the LP-based approach certiﬁes larger bounds than
FROWN at the cost of 2 to 178 times longer runtime. How-

Conclusion

In this paper, we have proved the optimality of CROWN in
the relaxed LP framework under mild conditions. Further-

more, we have proposed a general and versatile optimization
framework named FROWN for optimizing state-of-the-art
formal robustness veriﬁers including CROWN, CNN-Cert,
and POPQORN. Experiments on various networks have ver-
iﬁed the usefulness of FROWN in providing tightened ro-
bustness certiﬁcates at a signiﬁcantly lower cost than the
LP-based method.

Acknowledgement
This work is partially supported by the General Research
Fund (Project 14236516) of the Hong Kong Research Grants
Council, and MIT-Quest program.

References
[Boopathy et al. 2019] Boopathy, A.; Weng, T.-W.; Chen, P.-
Y.; Liu, S.; and Daniel, L. 2019. Cnn-cert: An efﬁcient
framework for certifying robustness of convolutional neural
networks. In AAAI.
[Carlini and Wagner 2017] Carlini, N., and Wagner, D. 2017.
Towards evaluating the robustness of neural networks. In SP.
[Carlini and Wagner 2018] Carlini, N., and Wagner, D. A.
2018. Audio adversarial examples: Targeted attacks on
speech-to-text. CoRR abs/1801.01944.
[Cisse et al. 2017] Cisse, M. M.; Adi, Y.; Neverova, N.; and
Keshet, J. 2017. Houdini: Fooling deep structured visual
and speech recognition models with adversarial examples.
In NeurIPS.
Stanforth, R.;
[Dvijotham et al. 2018] Dvijotham, K.;
Gowal, S.; Mann, T.; and Kohli, P. 2018. A dual approach
to scalable veriﬁcation of deep networks. UAI.
[Gao et al. 2019a] Gao, P.; Jiang, Z.; You, H.; Lu, P.; Hoi, S.
C. H.; Wang, X.; and Li, H. 2019a. Dynamic fusion with
intra- and inter-modality attention ﬂow for visual question
In The IEEE Conference on Computer Vision
answering.
and Pattern Recognition (CVPR).
[Gao et al. 2019b] Gao, P.; You, H.; Zhang, Z.; Wang, X.;
and Li, H. 2019b. Multi-modality latent interaction network
In The IEEE International
for visual question answering.
Conference on Computer Vision (ICCV).
[Gong and Poellabauer 2017] Gong, Y., and Poellabauer, C.
2017. Crafting adversarial examples for speech paralinguis-
tics applications. CoRR abs/1711.03280.
[Goodfellow, Shlens, and Szegedy 2015] Goodfellow,
I.;
Shlens, J.; and Szegedy, C. 2015. Explaining and harnessing
adversarial examples. In ICLR.
and An-
[Hein and Andriushchenko 2017] Hein, M.,
driushchenko, M.
Formal guarantees on the
robustness of a classiﬁer against adversarial manipulation.
In NeurIPS.
[Ko et al. 2019] Ko, C.-Y.; Lyu, Z.; Weng, L.; Daniel, L.;
Wong, N.; and Lin, D. 2019. POPQORN: Quantifying ro-
bustness of recurrent neural networks. In ICML.
A.;
[Kurakin, Goodfellow, and Bengio 2017] Kurakin,
Goodfellow, I.; and Bengio, S. 2017. Adversarial examples
in the physical world. ICLR Workshop.

2017.

[Moosavi-Dezfooli, Fawzi, and Frossard 2016] Moosavi-
Dezfooli, S.-M.; Fawzi, A.; and Frossard, P.
2016.
Deepfool: a simple and accurate method to fool deep neural
networks. In CVPR.
[Mudrakarta et al. 2018] Mudrakarta, P. K.; Taly, A.; Sun-
dararajan, M.; and Dhamdhere, K. 2018. Did the model
understand the question?
[Nesterov 2014] Nesterov, Y. 2014. Introductory Lectures on
Convex Optimization: A Basic Course. Springer Publishing
Company, Incorporated, 1 edition.
[Papernot et al. 2016] Papernot, N.; McDaniel, P. D.; Swami,
A.; and Harang, R. E. 2016. Crafting adversarial input se-
quences for recurrent neural networks. MILCOM.
[Raghunathan, Steinhardt, and Liang 2018] Raghunathan,
A.; Steinhardt, J.; and Liang, P. 2018. Certiﬁed defenses
against adversarial examples. ICLR.
[Salman et al. 2019] Salman, H.; Yang, G.; Zhang, H.;
Hsieh, C.; and Zhang, P. 2019. A convex relaxation barrier
to tight robustness veriﬁcation of neural networks. CoRR
abs/1902.08722.
[Sharif et al. 2016] Sharif, M.; Bhagavatula, S.; Bauer, L.;
and Reiter, M. K. 2016. Accessorize to a crime: Real
and stealthy attacks on state-of-the-art face recognition. In
Proceedings of the 2016 ACM SIGSAC Conference on Com-
puter and Communications Security, 1528–1540.
[Singh et al. 2018] Singh, G.; Gehr, T.; Mirman, M.;
P¨uschel, M.; and Vechev, M. 2018. Fast and effective ro-
bustness certiﬁcation. In NeurIPS. 10825–10836.
[Szegedy et al. 2014] Szegedy, C.; Zaremba, W.; Sutskever,
I.; Bruna, J.; Erhan, D.; Goodfellow, I.; and Fergus, R. 2014.
Intriguing properties of neural networks. ICLR.
[Weng et al. 2018a] Weng, T.-W.; Zhang, H.; Chen, P.-Y.; Yi,
J.; Su, D.; Gao, Y.; Hsieh, C.-J.; and Daniel, L. 2018a. Eval-
uating the robustness of neural networks: An extreme value
theory approach. In ICLR.
[Weng et al. 2018b] Weng, T.-W.; Zhang, H.; Chen, H.;
Song, Z.; Hsieh, C.-J.; Boning, D.; Dhillon, I. S.; and Daniel,
L. 2018b. Towards fast computation of certiﬁed robustness
for relu networks. ICML.
[Weng et al. 2018c] Weng, T.-W.; Zhang, H.; Chen, P.-Y.;
Lozano, A.; Hsieh, C.-J.; and Daniel, L. 2018c. On ex-
tensions of clever: A neural network robustness evaluation
algorithm. In GlobalSIP.
[Weng et al. 2019] Weng, L.; Chen, P.-Y.; Nguyen, L.; Squil-
lante, M.; Boopathy, A.; Oseledets, I.; and Daniel, L. 2019.
PROVEN: Verifying robustness of neural networks with a
probabilistic approach. In ICML.
[Wong and Kolter 2018] Wong, E., and Kolter, Z.
2018.
Provable defenses against adversarial examples via the con-
vex outer adversarial polytope. In ICML, volume 80, 5286–
5295.
[Zeng et al. 2019] Zeng, X.; Liu, C.; Wang, Y.-S.; Qiu, W.;
Xie, L.; Tai, Y.-W.; Tang, C.-K.; and Yuille, A. L. 2019.
Adversarial attacks beyond the image space. In The IEEE
Conference on Computer Vision and Pattern Recognition
(CVPR).

[Zhang et al. 2018] Zhang, H.; Weng, T.-W.; Chen, P.-Y.;
Hsieh, C.-J.; and Daniel, L. 2018. Efﬁcient neural network
robustness certiﬁcation with general activation functions. In
NeurIPS. 4944–4953.

