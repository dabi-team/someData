2
2
0
2

r
p
A
1
2

]

C
O
.
h
t
a
m

[

2
v
7
5
3
1
1
.
6
0
9
1
:
v
i
X
r
a

An Inexact Augmented Lagrangian Framework for
Nonconvex Optimization with Nonlinear Constraints

Mehmet Fatih Sahin
mehmet.sahin@epfl.ch

Armin Eftekhari
armin.eftekhari@epfl.ch

Ahmet Alacaoglu
ahmet.alacaoglu@epfl.ch

Fabian Latorre
fabian.latorre@epfl.ch

Volkan Cevher
volkan.cevher@epfl.ch

LIONS, Ecole Polytechnique Fédérale de Lausanne, Switzerland

Abstract

We propose a practical inexact augmented Lagrangian method (iALM) for noncon-
vex problems with nonlinear constraints. We characterize the total computational
complexity of our method subject to a veriﬁable geometric condition, which is
closely related to the Polyak-Lojasiewicz and Mangasarian-Fromowitz conditions.

In particular, when a ﬁrst-order solver is used for the inner iterates, we prove that
iALM ﬁnds a ﬁrst-order stationary point with ˜O(1/(cid:15)4) calls to the ﬁrst-order oracle.
If, in addition, the problem is smooth and a second-order solver is used for the
inner iterates, iALM ﬁnds a second-order stationary point with ˜O(1/(cid:15)5) calls to
the second-order oracle, which matches the known theoretical complexity result in
the literature.

We also provide strong numerical evidence on large-scale machine learning prob-
lems, including the Burer-Monteiro factorization of semideﬁnite programs, and
a novel nonconvex relaxation of the standard basis pursuit template. For these
examples, we also show how to verify our geometric condition.
This paper was updated on April 21, 2022, due to an error in the proof of Corollary
(4.2). The gradient complexity for obtaining a ﬁrst order stationary point is now
˜O(1/(cid:15)4) instead of ˜O(1/(cid:15)3). The error was due to an order mistake while using
the complexity result of APGM from [27].

Introduction

1
We study the nonconvex optimization problem

min
x∈Rd

f (x) + g(x)

s.t. A(x) = 0,

(1)

where f : Rd → R is a continuously-differentiable nonconvex function and A : Rd → Rm is a
nonlinear operator. We assume that g : Rd → R ∪ {∞} is a proximal-friendly convex function [47].

A host of problems in computer science [33, 37, 70], machine learning [40, 59], and signal pro-
cessing [57, 58] naturally fall under the template (1), including max-cut, clustering, generalized
eigenvalue decomposition, as well as the quadratic assignment problem (QAP) [70].

To solve (1), we propose an intuitive and easy-to-implement augmented Lagrangian algorithm, and
provide its total iteration complexity under an interpretable geometric condition. Before we elaborate
on the results, let us ﬁrst motivate (1) with an application to semideﬁnite programming (SDP):

33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.

 
 
 
 
 
 
Vignette: Burer-Monteiro splitting. A powerful convex relaxation for max-cut, clustering, and
many others is provided by the trace-constrained SDP

min
X∈Sd×d

(cid:104)C, X(cid:105)

s.t. B(X) = b, tr(X) ≤ α, X (cid:23) 0,

(2)

where C ∈ Rd×d, X is a positive semideﬁnite d × d matrix, and B : Sd×d → Rm is a linear operator.
If the unique-games conjecture is true, the SDP (2) obtains the best possible approximation for the
underlying discrete problem [53].

Since d is often large, many ﬁrst- and second-order methods for solving such SDP’s are immedi-
ately ruled out, not only due to their high computational complexity, but also due to their storage
requirements, which are O(d2).

A contemporary challenge in optimization is therefore to solve SDPs using little space and in a
scalable fashion. The recent homotopy conditional gradient method, which is based on linear
minimization oracles (LMOs), can solve (2) in a small space via sketching [69]. However, such
LMO-based methods are extremely slow in obtaining accurate solutions.

A different approach for solving (2), dating back to [14, 15], is the so-called Burer-Monteiro (BM)
factorization X = U U (cid:62), where U ∈ Rd×r and r is selected according to the guidelines in [49, 1],
which is tight [63]. The BM factorization leads to the following nonconvex problem in the template (1):

min
U ∈Rd×r

(cid:104)C, U U (cid:62)(cid:105)

s.t. B(U U (cid:62)) = b, (cid:107)U (cid:107)2

F ≤ α,

(3)

The BM factorization does not introduce any extraneous local minima [15]. Moreover, [13] establishes
the connection between the local minimizers of the factorized problem (3) and the global minimizers
for (2). To solve (3), the inexact Augmented Lagrangian method (iALM) is widely used [14, 15, 35],
due to its cheap per iteration cost and its empirical success.

Every (outer) iteration of iALM calls a solver to solve an intermediate augmented Lagrangian
subproblem to near stationarity. The choices include ﬁrst-order methods, such as the proximal
gradient descent [47], or second-order methods, such as the trust region method and BFGS [44].1

Unlike its convex counterpart [41, 36, 65], the convergence rate and the complexity of iALM for (3)
are not well-understood, see Section 5 for a review of the related literature. Indeed, addressing this
important theoretical gap is one of the contributions of our work. In addition,

(cid:46) We derive the convergence rate of iALM to ﬁrst-order optimality for solving (1) or second-order
optimality for solving (1) with g = 0, and ﬁnd the total iteration complexity of iALM using different
solvers for the augmented Lagrangian subproblems. We provide an extensive comparison with the
existing complexity results in optimization, see Section 5.

(cid:46) Our iALM framework is future-proof in the sense that different subsolvers can be substituted.

(cid:46) We propose a geometric condition that simpliﬁes the algorithmic analysis for iALM, and clarify its
connection to well-known Polyak-Lojasiewicz [32] and Mangasarian-Fromovitz [3] conditions. We
also verify this condition for key problems in Appendices D and E.
2 Preliminaries
Notation. We use the notation (cid:104)·, ·(cid:105) and (cid:107) · (cid:107) for the standard inner product and the norm on Rd. For
matrices, (cid:107) · (cid:107) and (cid:107) · (cid:107)F denote the spectral and the Frobenius norms, respectively. For the convex
function g : Rd → R, the subdifferential set at x ∈ Rd is denoted by ∂g(x) and we will occasionally
use the notation ∂g(x)/β = {z/β : z ∈ ∂g(x)}. When presenting iteration complexity results, we
often use (cid:101)O(·) which suppresses the logarithmic dependencies.
We denote δX : Rd → R as the indicator function of a set X ⊂ Rd. The distance function from
a point x to X is denoted by dist(x, X ) = minz∈X (cid:107)x − z(cid:107). For integers k0 ≤ k1, we use the
notation [k0 : k1] = {k0, . . . , k1}. For an operator A : Rd → Rm with components {Ai}m
i=1,
DA(x) ∈ Rm×d denotes the Jacobian of A, where the ith row of DA(x) is the vector ∇Ai(x) ∈ Rd.

Smoothness. We assume smooth f : Rd → R and A : Rd → Rm; i.e., there exist λf , λA ≥ 0 s.t.

(cid:107)∇f (x) − ∇f (x(cid:48))(cid:107) ≤ λf (cid:107)x − x(cid:48)(cid:107),
1BFGS is in fact a quasi-Newton method that emulates second-order information.

(cid:107)DA(x) − DA(x(cid:48))(cid:107) ≤ λA(cid:107)x − x(cid:48)(cid:107),

∀x, x(cid:48) ∈ Rd.

(4)

2

Augmented Lagrangian method (ALM). ALM is a classical algorithm, which ﬁrst appeared
in [29, 51] and extensively studied afterwards in [3, 8]. For solving (1), ALM suggests solving the
problem

where, for penalty weight β > 0, Lβ is the corresponding augmented Lagrangian, deﬁned as

min
x

max
y

Lβ(x, y) + g(x),

Lβ(x, y) := f (x) + (cid:104)A(x), y(cid:105) +

β
2

(cid:107)A(x)(cid:107)2.

The minimax formulation in (5) naturally suggests the following algorithm for solving (1):

xk+1 ∈ argmin

x

Lβ(x, yk) + g(x),

(5)

(6)

(7)

yk+1 = yk + σkA(xk+1),
where the dual step sizes are denoted as {σk}k. However, computing xk+1 above requires solving
the nonconvex problem (7) to optimality, which is typically intractable. Instead, it is often easier to
ﬁnd an approximate ﬁrst- or second-order stationary point of (7).

Hence, we argue that by gradually improving the stationarity precision and increasing the penalty
weight β above, we can reach a stationary point of the main problem in (5), as detailed in Section 3.

Optimality conditions. First-order necessary optimality conditions for (1) are well-studied. Indeed,
x ∈ Rd is a ﬁrst-order stationary point of (1) if there exists y ∈ Rm such that

−∇xLβ(x, y) ∈ ∂g(x),

A(x) = 0,

(8)

which is in turn the necessary optimality condition for (5). Inspired by this, we say that x is an ((cid:15)f , β)
ﬁrst-order stationary point of (5) if there exists a y ∈ Rm such that

dist(−∇xLβ(x, y), ∂g(x)) ≤ (cid:15)f ,

(cid:107)A(x)(cid:107) ≤ (cid:15)f ,

(9)

for (cid:15)f ≥ 0. In light of (9), a metric for evaluating the stationarity of a pair (x, y) ∈ Rd × Rm is

dist (−∇xLβ(x, y), ∂g(x)) + (cid:107)A(x)(cid:107),
(10)
which we use as the ﬁrst-order stopping criterion. As an example, for a convex set X ⊂ Rd, suppose
that g = δX is the indicator function on X . Let also TX (x) ⊆ Rd denote the tangent cone to X at x,
and with PTX (x) : Rd → Rd we denote the orthogonal projection onto this tangent cone. Then, for
u ∈ Rd, it is not difﬁcult to verify that

dist (u, ∂g(x)) = (cid:107)PTX (x)(u)(cid:107).

(11)

When g = 0, a ﬁrst-order stationary point x ∈ Rd of (1) is also second-order stationary if

λmin(∇xxLβ(x, y)) ≥ 0,
where ∇xxLβ is the Hessian of Lβ with respect to x, and λmin(·) returns the smallest eigenvalue of
its argument. Analogously, x is an ((cid:15)f , (cid:15)s, β) second-order stationary point if, in addition to (9), it
holds that

(12)

λmin(∇xxLβ(x, y)) ≥ −(cid:15)s,
(13)
for (cid:15)s ≥ 0. Naturally, for second-order stationarity, we use λmin(∇xxLβ(x, y)) as the stopping
criterion.

Smoothness lemma. This next result controls the smoothness of Lβ(·, y) for a ﬁxed y. The proof
is standard but nevertheless is included in Appendix C for completeness.
Lemma 2.1 (smoothness). For ﬁxed y ∈ Rm and ρ, ρ(cid:48) ≥ 0, it holds that
(cid:107)∇xLβ(x, y) − ∇xLβ(x(cid:48), y)(cid:107) ≤ λβ(cid:107)x − x(cid:48)(cid:107),

(14)

for every x, x(cid:48) ∈ {x(cid:48)(cid:48) : (cid:107)x(cid:48)(cid:48)(cid:107) ≤ ρ, (cid:107)A(x(cid:48)(cid:48))(cid:107) ≤ ρ(cid:48)}, where

λβ ≤ λf +

mλA(cid:107)y(cid:107) + (

mλAρ(cid:48) + dλ(cid:48)2

A)β =: λf +

√

√

√

mλA(cid:107)y(cid:107) + λ(cid:48)(cid:48)(A, ρ, ρ(cid:48))β.

(15)

Above, λf , λA were deﬁned in (4) and

λ(cid:48)
A := max
(cid:107)x(cid:107)≤ρ

(cid:107)DA(x)(cid:107).

(16)

3

3 Algorithm

To solve the equivalent formulation of (1) presented in (5), we propose the inexact ALM (iALM),
detailed in Algorithm 1. At the kth iteration, Step 2 of Algorithm 1 calls a solver that ﬁnds an
approximate stationary point of the augmented Lagrangian Lβk (·, yk) with the accuracy of (cid:15)k+1, and
this accuracy gradually increases in a controlled fashion. The increasing sequence of penalty weights
{βk}k and the dual update (Steps 4 and 5) are responsible for continuously enforcing the constraints
in (1). The appropriate choice for {βk}k will be speciﬁed in Corrollary Sections A.1 and A.2.

The particular choice of the dual step sizes {σk}k in Algorithm 1 ensures that the dual variable yk
remains bounded.

Algorithm 1 Inexact ALM

Input: Non-decreasing, positive, unbounded sequence {βk}k≥1, stopping thresholds τf , τs > 0.
Initialization: Primal variable x1 ∈ Rd, dual variable y0 ∈ Rm, dual step size σ1 > 0.
for k = 1, 2, . . . do

1.
2.

(Update tolerance) (cid:15)k+1 = 1/βk.
(Inexact primal solution) Obtain xk+1 ∈ Rd such that

dist(−∇xLβk (xk+1, yk), ∂g(xk+1)) ≤ (cid:15)k+1

for ﬁrst-order stationarity

λmin(∇xxLβk (xk+1, yk)) ≥ −(cid:15)k+1

for second-order-stationarity, if g = 0 in (1).
(Update dual step size)

σk+1 = σ1 min

(cid:16)

(cid:107)A(x1)(cid:107) log2 2
(cid:107)A(xk+1)(cid:107)(k + 1) log2(k + 2)

(cid:17)

, 1

.

(Dual ascent) yk+1 = yk + σk+1A(xk+1).
(Stopping criterion) If

dist(−∇xLβk (xk+1), ∂g(xk+1)) + (cid:107)A(xk+1)(cid:107) ≤ τf ,

for ﬁrst-order stationarity and if also λmin(∇xxLβk (xk+1, yk)) ≥ −τs for second-order
stationarity, then quit and return xk+1 as an (approximate) stationary point of (5).

3.

4.
5.

end for

4 Convergence Rate

This section presents the total iteration complexity of Algorithm 1 for ﬁnding ﬁrst and second-order
stationary points of problem (5). All the proofs are deferred to Appendix B. Theorem 4.1 characterizes
the convergence rate of Algorithm 1 for ﬁnding stationary points in the number of outer iterations.
Theorem 4.1. (convergence rate) For integers 2 ≤ k0 ≤ k1, consider the interval K = [k0 :
k1], and let {xk}k∈K be the output sequence of Algorithm 1 on the interval K.2 Let also ρ :=
supk∈[K] (cid:107)xk(cid:107).3 Suppose that f and A satisfy (4) and let

λ(cid:48)
f = max
(cid:107)x(cid:107)≤ρ

(cid:107)∇f (x)(cid:107),

λ(cid:48)
A = max
(cid:107)x(cid:107)≤ρ

(cid:107)DA(x)(cid:107),

be the (restricted) Lipschitz constants of f and A, respectively. With ν > 0, assume that
(cid:18)

(cid:19)

ν(cid:107)A(xk)(cid:107) ≤ dist

for every k ∈ K. We consider two cases:

−DA(xk)(cid:62)A(xk),

∂g(xk)
βk−1

,

(17)

(18)

2The choice of k1 = ∞ is valid here too.
3If necessary, to ensure that ρ < ∞, one can add a small factor of (cid:107)x(cid:107)2 to Lβ in (6). Then it is easy to verify
that the iterates of Algorithm 1 remain bounded, provided that the initial penalty weight β0 is large enough,
supx (cid:107)∇f (x)(cid:107)/(cid:107)x(cid:107) < ∞, supx (cid:107)A(x)(cid:107) < ∞, and supx (cid:107)DA(x)(cid:107) < ∞.

4

• If a ﬁrst-order solver is used in Step 2, then xk is an ((cid:15)k,f , βk) ﬁrst-order stationary point of (5)

with

(cid:15)k,f =

1
βk−1

(cid:18) 2(λ(cid:48)

f + λ(cid:48)

Aymax)(1 + λ(cid:48)

Aσk)

ν

(cid:19)

+ 1

=:

Q(f, g, A, σ1)
βk−1

,

(19)

for every k ∈ K, where ymax(x1, y0, σ1) := (cid:107)y0(cid:107) + c(cid:107)A(x1)(cid:107).

• If a second-order solver is used in Step 2, then xk is an ((cid:15)k,f , (cid:15)k,s, βk) second-order stationary

point of (5) with (cid:15)k,s speciﬁed above and with

(cid:15)k,s = (cid:15)k−1 + σk

√

mλA

2λ(cid:48)

f + 2λ(cid:48)
νβk−1

Aymax

√

ν + σk

=

f + 2λ(cid:48)

Aymax

mλA2λ(cid:48)
νβk−1

=:

Q(cid:48)(f, g, A, σ1)
βk−1

.

(20)

Theorem 4.1 states that Algorithm 1 converges to a (ﬁrst- or second-) order stationary point of (5)
at the rate of 1/βk, further speciﬁed in Corollary 4.2 and Corollary 4.3. A few remarks are in order
about Theorem 4.1.

Regularity. The key geometric condition in Theorem 4.1 is (18) which, broadly speaking, ensures
that the primal updates of Algorithm 1 reduce the feasibility gap as the penalty weight βk grows. We
will verify this condition for several examples in Appendices D and E.

This condition in (18) is closely related to those in the existing literature. In the special case where
g = 0 in (1), (18) reduces to;

(cid:107)DA(x)(cid:62)A(x)(cid:107) ≥ ν(cid:107)A(x)(cid:107).

(21)

Polyak-Lojasiewicz (PL) condition [32]. Consider the problem with λ ˜f -smooth objective,

˜f (x) satisﬁes the PL inequality if the following holds for some µ > 0,

˜f (x).

min
x∈Rd

(cid:107)∇ ˜f (x)(cid:107)2 ≥ µ( ˜f (x) − ˜f ∗),

∀x

(PL inequality)

1
2

This inequality implies that gradient is growing faster than a quadratic as we move away from the
optimal. Assuming that the feasible set {x : A(x) = 0} is non-empty, it is easy to verify that 21 is
equivalent to the PL condition for minimizing ˜f (x) = 1
PL condition itself is a special case of Kurdyka-Lojasiewicz with θ = 1/2, see [66, Deﬁnition 1.1].
When g = 0, it is also easy to see that (18) is weaker than the Mangasarian-Fromovitz (MF) condition
in nonlinear optimization [10, Assumption 1]. Moreover, when g is the indicator on a convex set,
(18) is a consequence of the basic constraint qualiﬁcation in [55], which itself generalizes the MF
condition to the case when g is an indicator function of a convex set.

2 (cid:107)A(x)(cid:107)2 with ν =

2µ [32].

√

We may think of (18) as a local condition, which should hold within a neighborhood of the constraint
set {x : A(x) = 0} rather than everywhere in Rd. Indeed, the iteration count k appears in (18) to
reﬂect this local nature of the condition. Similar kind of arguments on the regularity condition also
appear in [10]. There is also a constant complexity algorithm in [10] to reach so-called “information
zone”, which supplements Theorem 4.1.

Penalty method. A classical algorithm to solve (1) is the penalty method, which is characterized by
the absence of the dual variable (y = 0) in (6). Indeed, ALM can be interpreted as an adaptive penalty
or smoothing method with a variable center determined by the dual variable. It is worth noting that,
with the same proof technique, one can establish the same convergence rate of Theorem 4.1 for the
penalty method. However, while both methods have the same convergence rate in theory, we ignore
the uncompetitive penalty method since it is signiﬁcantly outperformed by iALM in practice.

Computational complexity. Theorem 4.1 speciﬁes the number of (outer) iterations that Algo-
rithm 1 requires to reach a near-stationary point of problem (6) with a prescribed precision and, in
particular, speciﬁes the number of calls made to the solver in Step 2. In this sense, Theorem 4.1 does

5

not fully capture the computational complexity of Algorithm 1, as it does not take into account the
computational cost of the solver in Step 2.

To better understand the total iteration complexity of Algorithm 1, we consider two scenarios in the
following. In the ﬁrst scenario, we take the solver in Step 2 to be the Accelerated Proximal Gradient
Method (APGM), a well-known ﬁrst-order algorithm [27]. In the second scenario, we will use the
second-order trust region method developed in [17]. We have the following two corollaries showing
the total complexity of our algorithm to reach ﬁrst and second-order stationary points. Appendix A
contains the proofs and more detailed discussion for the complexity results.
Corollary 4.2 (First-order optimality). For b > 1, let βk = bk for every k. If we use APGM from [27]
for Step 2 of Algorithm 1, the algorithm ﬁnds an ((cid:15)f , βk) ﬁrst-order stationary point of (5), after T
calls to the ﬁrst-order oracle, where

T = O

(cid:18) Q3ρ2
(cid:15)4

logb

(cid:19)(cid:19)

(cid:18) Q
(cid:15)

= ˜O

(cid:18) Q3ρ2
(cid:15)4

(cid:19)

.

(22)

For Algorithm 1 to reach a near-stationary point with an accuracy of (cid:15)f in the sense of (9) and with
the lowest computational cost, we therefore need to perform only one iteration of Algorithm 1, with
β1 speciﬁed as a function of (cid:15)f by (19) in Theorem 4.1. In general, however, the constants in (19) are
unknown and this approach is thus not feasible. Instead, the homotopy approach taken by Algorithm 1
ensures achieving the desired accuracy by gradually increasing the penalty weight. This homotopy
approach increases the computational cost of Algorithm 1 only by a factor logarithmic in the (cid:15)f , as
detailed in the proof of Corollary 4.2.
Corollary 4.3 (Second-order optimality). For b > 1, let βk = bk for every k. We assume that

Lβ(x1, y) − min

x

Lβ(x, y) ≤ Lu,

∀β.

(23)

If we use the trust region method from [17] for Step 2 of Algorithm 1, the algorithm ﬁnds an
(cid:15)-second-order stationary point of (5) in T calls to the second-order oracle where

T = O

(cid:18) LuQ(cid:48)5
(cid:15)5

logb

(cid:19)(cid:19)

(cid:18) Q(cid:48)
(cid:15)

= (cid:101)O

(cid:18) LuQ(cid:48)5
(cid:15)5

(cid:19)

.

(24)

Remark. These complexity results for ﬁrst and second-order are stationarity with respect to (6).
We note that second order complexity result matches [18] and [7]. However, the stationarity criteria
and the deﬁnition of dual variable in these papers differ from ours. We include more discussion on
this in the Appendix.

Effect of βk in 18. We consider two cases, when g is the indicator of a convex set (or 0), the
subdifferential set will be a cone (or 0), thus βk will not have an effect. On the other hand, when g is
a convex and Lipschitz contiunous function deﬁned on the whole space, subdifferential set will be
bounded [54, Theorem 23.4]. This will introduce an error term in 18 that is of the order (1/βk). One
can see that bk choice for βk causes a linear decrease in this error term. In fact, all the examples in
this paper fall into the ﬁrst case.

5 Related Work

ALM has a long history in the optimization literature, dating back to [29, 51]. In the special case
of (1) with a convex function f and a linear operator A, standard, inexact, and linearized versions of
ALM have been extensively studied [36, 41, 61, 65].

Classical works on ALM focused on the general template of (1) with nonconvex f and nonlinear A,
with arguably stronger assumptions and required exact solutions to the subproblems of the form (7),
which appear in Step 2 of Algorithm 1, see for instance [4].

A similar analysis was conducted in [22] for the general template of (1). The authors considered
inexact ALM and proved convergence rates for the outer iterates, under speciﬁc assumptions on the
initialization of the dual variable. However, in contrast, the authors did not analyze how to solve the
subproblems inexactly and did not provide total complexity results with veriﬁable conditions.

6

Problem (1) with similar assumptions to us is also studied in [7] and [18] for ﬁrst-order and second-
order stationarity, respectively, with explicit iteration complexity analysis. As we have mentioned in
Section 4, our second order iteration complexity result matches these theoretical algorithms with a
simpler algorithm and a simpler analysis. In addition, these algorithms require setting ﬁnal accuracies
since they utilize this information in the algorithm while our Algorithm 1 does not set accuracies a
priori.

[16] also considers the same template (1) for ﬁrst-order stationarity with a penalty-type method
instead of ALM. Even though the authors show O(1/(cid:15)2) complexity, this result is obtained by
assuming that the penalty parameter remains bounded. We note that such an assumption can also be
used to improve our complexity results to match theirs.

[10] studies the general template (1) with speciﬁc assumptions involving local error bound conditions
for the (1). These conditions are studied in detail in [9], but their validity for general SDPs (2) has
never been established. This work also lacks the total iteration complexity analysis presented here.

Another work [20] focused on solving (1) by adapting the primal-dual method of Chambolle and
Pock [19]. The authors proved the convergence of the method and provided convergence rate by
imposing error bound conditions on the objective function that do not hold for standard SDPs.
[14, 15] is the ﬁrst work that proposes the splitting X = U U (cid:62) for solving SDPs of the form (2).
Following these works, the literature on Burer-Monteiro (BM) splitting for the large part focused on
using ALM for solving the reformulated problem (3). However, this proposal has a few drawbacks:
First, it requires exact solutions in Step 2 of Algorithm 1 in theory, which in practice is replaced with
inexact solutions. Second, their results only establish convergence without providing the rates. In this
sense, our work provides a theoretical understanding of the BM splitting with inexact solutions to
Step 2 of Algorithm 1 and complete iteration complexities.

[6, 48] are among the earliest efforts to show convergence rates for BM splitting, focusing on
the special case of SDPs without any linear constraints. For these speciﬁc problems, they prove
the convergence of gradient descent to global optima with convergence rates, assuming favorable
initialization. These results, however, do not apply to general SDPs of the form (2) where the difﬁculty
arises due to the linear constraints.

Another popular method for solving SDPs are due to [12, 11, 13], focusing on the case where the
constraints in (1) can be written as a Riemannian manifold after BM splitting. In this case, the authors
apply the Riemannian gradient descent and Riemannian trust region methods for obtaining ﬁrst- and
second-order stationary points, respectively. They obtain O(1/(cid:15)2) complexity for ﬁnding ﬁrst-order
stationary points and O(1/(cid:15)3) complexity for ﬁnding second-order stationary points.

While these complexities appear better than ours, the smooth manifold requirement in these works
is indeed restrictive. In particular, this requirement holds for max-cut and generalized eigenvalue
problems, but it is not satisﬁed for other important SDPs such as quadratic programming (QAP),
optimal power ﬂow and clustering with general afﬁne constraints. In addition, as noted in [11], per
iteration cost of their method for max-cut problem is an astronomical O(d6).

Lastly, there also exists a line of work for solving SDPs in their original convex formulation, in a
storage efﬁcient way [42, 68, 69]. These works have global optimality guarantees by their virtue of
directly solving the convex formulation. On the downside, these works require the use of eigenvalue
routines and exhibit signiﬁcantly slower convergence as compared to nonconvex approaches [31].
6 Numerical Evidence

We ﬁrst begin with a caveat: It is known that quasi-Newton methods, such as BFGS and lBFGS,
might not converge for nonconvex problems [21, 38]. For this reason, we have used the trust region
method as the second-order solver in our analysis in Section 4, which is well-studied for nonconvex
problems [17]. Empirically, however, BFGS and lBGFS are extremely successful and we have
therefore opted for those solvers in this section since the subroutine does not affect Theorem 4.1 as
long as the subsolver performs well in practice.

6.1 Clustering

i=1, the entries of the corresponding Euclidean distance matrix D ∈ Rn×n
Given data points {zi}n
are Di,j = (cid:107)zi − zj(cid:107)2. Clustering is then the problem of ﬁnding a co-association matrix Y ∈ Rn×n

7

Figure 1: Clustering running time comparison.

such that Yij = 1 if points zi and zj are within the same cluster and Yij = 0 otherwise. In [50], the
authors provide a SDP relaxation of the clustering problem, speciﬁed as

min
Y ∈Rnxn

tr(DY )

s.t. Y 1 = 1, tr(Y ) = s, Y (cid:23) 0, Y ≥ 0,

(25)

where s is the number of clusters and Y is both positive semideﬁnite and has nonnegative entries.
Standard SDP solvers do not scale well with the number of data points n, since they often require
projection onto the semideﬁnite cone with the complexity of O(n3). We instead use the BM
factorization to solve (25), sacriﬁcing convexity to reduce the computational complexity. More
speciﬁcally, we solve the program

min
V ∈Rn×r

tr(DV V (cid:62))

s.t. V V (cid:62)1 = 1, (cid:107)V (cid:107)2

F ≤ s, V ≥ 0,

(26)

where 1 ∈ Rn is the vector of all ones. Note that Y ≥ 0 in (25) is replaced above by the much
stronger but easier-to-enforce constraint V ≥ 0 in (26), see [35] for the reasoning behind this
relaxation. Now, we can cast (26) as an instance of (1). Indeed, for every i ≤ n, let xi ∈ Rr denote
the ith row of V . We next form x ∈ Rd with d = nr by expanding the factorized variable V , namely,
x := [x(cid:62)

n ](cid:62) ∈ Rd, and then set

1 , · · · , x(cid:62)
n
(cid:88)

i,j=1

f (x) =

Di,j (cid:104)xi, xj(cid:105) ,

g = δC,

A(x) = [x(cid:62)
1

n
(cid:88)

j=1

xj − 1, · · · , x(cid:62)
n

n
(cid:88)

j=1

xj − 1](cid:62),

where C is the intersection of the positive orthant in Rd with the Euclidean ball of radius
Appendix D, we verify that Theorem 4.1 applies to (1) with f, g, A speciﬁed above.

√

s. In

In our simulations, we use two different solvers for Step 2 of Algorithm 1, namely, APGM and
lBFGS. APGM is a solver for nonconvex problems of the form (7) with convergence guarantees
to ﬁrst-order stationarity, as discussed in Section 4. lBFGS is a limited-memory version of BFGS
algorithm in [24] that approximately leverages the second-order information of the problem. We
compare our approach against the following convex methods:

• HCGM: Homotopy-based Conditional Gradient Method in [69] which directly solves (25).
• SDPNAL+: A second-order augmented Lagrangian method for solving SDP’s with nonneg-

ativity constraints [67].

As for the dataset, our experimental setup is similar to that described by [39]. We use the publicly-
available fashion-MNIST data in [64], which is released as a possible replacement for the MNIST
handwritten digits. Each data point is a 28 × 28 gray-scale image, associated with a label from ten
classes, labeled from 0 to 9. First, we extract the meaningful features from this dataset using a simple
two-layer neural network with a sigmoid activation function. Then, we apply this neural network to
1000 test samples from the same dataset, which gives us a vector of length 10 for each data point,
where each entry represents the posterior probability for each class. Then, we form the (cid:96)2 distance
matrix D from these probability vectors. The solution rank for the template (25) is known and it is
equal to number of clusters k [35, Theorem 1]. As discussed in [60], setting rank r > k leads more
accurate reconstruction in expense of speed. Therefore, we set the rank to 20. For iAL lBFGS, we

8

10010110210-1010-510010110210310-1010-810-610-410-2100used β1 = 1 and σ1 = 10 as the initial penalty weight and dual step size, respectively. For HCGM,
we used β0 = 1 as the initial smoothness parameter. We have run SDPNAL+ solver with 10−12
tolerance. The results are depicted in Figure 1. We implemented 3 algorithms on MATLAB and used
the software package for SDPNAL+ which contains mex ﬁles. It is predictable that the performance
of our nonconvex approach would even improve by using mex ﬁles.

6.2 Additional demonstrations

We provide several additional experiments in Appendix E. Section E.1 discusses a novel nonconvex
relaxation of the standard basis pursuit template which performs comparable to the state of the art
convex solvers. In Section E.2, we provide fast numerical solutions to the generalized eigenvalue
problem. In Section E.3, we give a contemporary application example that our template applies,
namely, denoising with generative adversarial networks. Finally, we provide improved bounds for
sparse quadratic assignment problem instances in Section E.4.

7 Conclusions

In this work, we have proposed and analyzed an inexact augmented Lagrangian method for solving
nonconvex optimization problems with nonlinear constraints. We prove convergence to the ﬁrst
and second order stationary points of the augmented Lagrangian function, with explicit complexity
estimates. Even though the relation of stationary points and global optima is not well-understood in
the literature, we ﬁnd out that the algorithm has fast convergence behavior to either global minima or
local minima in a wide variety of numerical experiments.

Acknowledgements

The authors would like to thank Nicolas Boumal and Nadav Hallak for the helpful suggestions.

This project has received funding from the European Research Council (ERC) under the
European Union’s Horizon 2020 research and innovation programme (grant agreement n◦ 725594 -
time-data) and was supported by the Swiss National Science Foundation (SNSF) under grant number
200021_178865/1. This project was also sponsored by the Department of the Navy, Ofﬁce of Naval
Research (ONR) under a grant number N62909-17-1-2111 and was supported by Hasler Foundation
Program: Cyber Human Systems (project number 16066). This research was supported by the PhD
fellowship program of the Swiss Data Science Center (SDSC) under grant lD number P18-07.

References

[1] A. I. Barvinok. Problems of distance geometry and convex properties of quadratic maps.

Discrete & Computational Geometry, 13(2):189–202, 1995.

[2] D. P. Bertsekas. On penalty and multiplier methods for constrained minimization. SIAM Journal

on Control and Optimization, 14(2):216–235, 1976.

[3] D. P. Bertsekas. Constrained optimization and lagrange multiplier methods. Computer Science

and Applied Mathematics, Boston: Academic Press, 1982, 1982.

[4] D. P. Bertsekas. Constrained optimization and Lagrange multiplier methods. Academic press,

2014.

[5] S. Bhojanapalli, N. Boumal, P. Jain, and P. Netrapalli. Smoothed analysis for low-rank solutions

to semideﬁnite programs in quadratic penalty form. arXiv preprint arXiv:1803.00186, 2018.

[6] S. Bhojanapalli, A. Kyrillidis, and S. Sanghavi. Dropping convexity for faster semi-deﬁnite

optimization. In Conference on Learning Theory, pages 530–582, 2016.

[7] E. G. Birgin, J. Gardenghi, J. M. Martinez, S. Santos, and P. L. Toint. Evaluation complexity
for nonlinear constrained optimization using unscaled kkt conditions and high-order models.
SIAM Journal on Optimization, 26(2):951–967, 2016.

[8] E. G. Birgin and J. M. Mart_nez. Practical augmented Lagrangian methods for constrained

optimization, volume 10. SIAM, 2014.

9

[9] J. Bolte, T. P. Nguyen, J. Peypouquet, and B. W. Suter. From error bounds to the complexity of
ﬁrst-order descent methods for convex functions. Mathematical Programming, 165(2):471–507,
2017.

[10] J. Bolte, S. Sabach, and M. Teboulle. Nonconvex lagrangian-based optimization: monitoring

schemes and global convergence. Mathematics of Operations Research, 2018.

[11] N. Boumal, P.-A. Absil, and C. Cartis. Global rates of convergence for nonconvex optimization

on manifolds. arXiv preprint arXiv:1605.08101, 2016.

[12] N. Boumal, B. Mishra, P.-A. Absil, and R. Sepulchre. Manopt, a matlab toolbox for optimization

on manifolds. The Journal of Machine Learning Research, 15(1):1455–1459, 2014.

[13] N. Boumal, V. Voroninski, and A. Bandeira. The non-convex burer-monteiro approach works on
smooth semideﬁnite programs. In Advances in Neural Information Processing Systems, pages
2757–2765, 2016.

[14] S. Burer and R. D. Monteiro. A nonlinear programming algorithm for solving semideﬁnite
programs via low-rank factorization. Mathematical Programming, 95(2):329–357, 2003.
[15] S. Burer and R. D. Monteiro. Local minima and convergence in low-rank semideﬁnite program-

ming. Mathematical Programming, 103(3):427–444, 2005.

[16] C. Cartis, N. I. Gould, and P. L. Toint. On the evaluation complexity of composite func-
tion minimization with applications to nonconvex nonlinear programming. SIAM Journal on
Optimization, 21(4):1721–1739, 2011.

[17] C. Cartis, N. I. Gould, and P. L. Toint. Complexity bounds for second-order optimality in

unconstrained optimization. Journal of Complexity, 28(1):93–108, 2012.

[18] C. Cartis, N. I. Gould, and P. L. Toint. Optimality of orders one to three and beyond: characteri-
zation and evaluation complexity in constrained nonconvex optimization. Journal of Complexity,
2018.

[19] A. Chambolle and T. Pock. A ﬁrst-order primal-dual algorithm for convex problems with

applications to imaging. Journal of mathematical imaging and vision, 40(1):120–145, 2011.

[20] C. Clason, S. Mazurenko, and T. Valkonen. Acceleration and global convergence of a ﬁrst-order
primal–dual method for nonconvex problems. arXiv preprint arXiv:1802.03347, 2018.
[21] Y.-H. Dai. Convergence properties of the bfgs algoritm. SIAM Journal on Optimization,

13(3):693–701, 2002.

[22] D. Fernandez and M. V. Solodov. Local convergence of exact and inexact augmented lagrangian
methods under the second-order sufﬁcient optimality condition. SIAM Journal on Optimization,
22(2):384–407, 2012.

[23] J. F. B. Ferreira, Y. Khoo, and A. Singer. Semideﬁnite programming approach for the quadratic
assignment problem with a sparse graph. Computational Optimization and Applications,
69(3):677–712, 2018.

[24] R. Fletcher. Practical methods of optimization. John Wiley & Sons, 2013.
[25] F. Flores-Bazán, F. Flores-Bazán, and C. Vera. A complete characterization of strong duality in
nonconvex optimization with a single constraint. Journal of Global Optimization, 53(2):185–
201, 2012.

[26] R. Ge, C. Jin, P. Netrapalli, A. Sidford, et al. Efﬁcient algorithms for large-scale generalized
eigenvector computation and canonical correlation analysis. In International Conference on
Machine Learning, pages 2741–2750, 2016.

[27] S. Ghadimi and G. Lan. Accelerated gradient methods for nonconvex nonlinear and stochastic

programming. Mathematical Programming, 156(1-2):59–99, 2016.

[28] I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville,

and Y. Bengio. Generative Adversarial Networks. ArXiv e-prints, June 2014.

[29] M. R. Hestenes. Multiplier and gradient methods. Journal of optimization theory and applica-

tions, 4(5):303–320, 1969.

[30] A. Ilyas, A. Jalal, E. Asteri, C. Daskalakis, and A. G. Dimakis. The Robust Manifold Defense:
Adversarial Training using Generative Models. arXiv e-prints, page arXiv:1712.09196, Dec.
2017.

10

[31] M. Jaggi. Revisiting frank-wolfe: Projection-free sparse convex optimization. In ICML (1),

pages 427–435, 2013.

[32] H. Karimi, J. Nutini, and M. Schmidt. Linear convergence of gradient and proximal-gradient
methods under the polyak-łojasiewicz condition. In Joint European Conference on Machine
Learning and Knowledge Discovery in Databases, pages 795–811. Springer, 2016.

[33] S. Khot and A. Naor. Grothendieck-type inequalities in combinatorial optimization. arXiv

preprint arXiv:1108.2464, 2011.

[34] D. P. Kingma and J. Ba. Adam: A Method for Stochastic Optimization. arXiv e-prints, page

arXiv:1412.6980, Dec. 2014.

[35] B. Kulis, A. C. Surendran, and J. C. Platt. Fast low-rank semideﬁnite programming for
embedding and clustering. In Artiﬁcial Intelligence and Statistics, pages 235–242, 2007.
[36] G. Lan and R. D. Monteiro. Iteration-complexity of ﬁrst-order augmented lagrangian methods

for convex programming. Mathematical Programming, 155(1-2):511–547, 2016.

[37] L. Lovász. Semideﬁnite programs and combinatorial optimization. In Recent advances in

algorithms and combinatorics, pages 137–194. Springer, 2003.

[38] W. F. Mascarenhas. The bfgs method with exact line searches fails for non-convex objective

functions. Mathematical Programming, 99(1):49–61, 2004.

[39] D. G. Mixon, S. Villar, and R. Ward. Clustering subgaussian mixtures by semideﬁnite program-

ming. arXiv preprint arXiv:1602.06612, 2016.

[40] E. Mossel, J. Neeman, and A. Sly. Consistency thresholds for the planted bisection model. In
Proceedings of the forty-seventh annual ACM symposium on Theory of computing, pages 69–75.
ACM, 2015.

[41] V. Nedelcu, I. Necoara, and Q. Tran-Dinh. Computational complexity of inexact gradient
augmented lagrangian methods: application to constrained mpc. SIAM Journal on Control and
Optimization, 52(5):3109–3134, 2014.

[42] Y. Nesterov. Primal-dual subgradient methods for convex problems. Mathematical programming,

120(1):221–259, 2009.

[43] Y. E. Nesterov. A method for solving the convex programming problem with convergence rate

o (1/kˆ 2). In Dokl. Akad. Nauk SSSR, volume 269, pages 543–547, 1983.

[44] J. Nocedal and S. Wright. Numerical Optimization. Springer Series in Operations Research and

Financial Engineering. Springer New York, 2006.

[45] M. Nouiehed, J. D. Lee, and M. Razaviyayn. Convergence to second-order stationarity for

constrained non-convex optimization. arXiv preprint arXiv:1810.02024, 2018.

[46] G. Obozinski, L. Jacob, and J.-P. Vert. Group lasso with overlaps: the latent group lasso

approach. arXiv preprint arXiv:1110.0413, 2011.

[47] N. Parikh, S. Boyd, et al. Proximal algorithms. Foundations and Trends in Optimization,

1(3):127–239, 2014.

[48] D. Park, A. Kyrillidis, S. Bhojanapalli, C. Caramanis, and S. Sanghavi. Provable burer-monteiro
factorization for a class of norm-constrained matrix problems. arXiv preprint arXiv:1606.01316,
2016.

[49] G. Pataki. On the rank of extreme matrices in semideﬁnite programs and the multiplicity of

optimal eigenvalues. Mathematics of operations research, 23(2):339–358, 1998.

[50] J. Peng and Y. Wei. Approximating K–means–type clustering via semideﬁnite programming.

SIAM J. Optim., 18(1):186–205, 2007.

[51] M. J. Powell. A method for nonlinear constraints in minimization problems. Optimization,

pages 283–298, 1969.

[52] A. Radford, L. Metz, and S. Chintala. Unsupervised Representation Learning with Deep

Convolutional Generative Adversarial Networks. ArXiv e-prints, Nov. 2015.

[53] P. Raghavendra. Optimal algorithms and inapproximability results for every csp? In Proceedings
of the fortieth annual ACM symposium on Theory of computing, pages 245–254. ACM, 2008.

[54] R. T. Rockafellar. Convex analysis, volume 28. Princeton university press, 1970.

11

[55] R. T. Rockafellar. Lagrange multipliers and optimality. SIAM review, 35(2):183–238, 1993.
[56] P. Samangouei, M. Kabkab, and R. Chellappa. Defense-GAN: Protecting classiﬁers against
adversarial attacks using generative models. In International Conference on Learning Represen-
tations, 2018.

[57] A. Singer. Angular synchronization by eigenvectors and semideﬁnite programming. Applied

and computational harmonic analysis, 30(1):20, 2011.

[58] A. Singer and Y. Shkolnisky. Three-dimensional structure determination from common lines in
cryo-em by eigenvectors and semideﬁnite programming. SIAM journal on imaging sciences,
4(2):543–572, 2011.

[59] L. Song, A. Smola, A. Gretton, and K. M. Borgwardt. A dependence maximization view of
clustering. In Proceedings of the 24th international conference on Machine learning, pages
815–822. ACM, 2007.

[60] M. Tepper, A. M. Sengupta, and D. Chklovskii. Clustering is semideﬁnitely not that hard:
Nonnegative sdp for manifold disentangling. Journal of Machine Learning Research, 19(82),
2018.

[61] Q. Tran-Dinh, A. Alacaoglu, O. Fercoq, and V. Cevher. An adaptive primal-dual framework for

nonsmooth convex minimization. arXiv preprint arXiv:1808.04648, 2018.

[62] Q. Tran-Dinh, O. Fercoq, and V. Cevher. A smooth primal-dual optimization framework for
nonsmooth composite convex minimization. SIAM Journal on Optimization, 28(1):96–134,
2018.

[63] I. Waldspurger and A. Waters. Rank optimality for the burer-monteiro factorization. arXiv

preprint arXiv:1812.03046, 2018.

[64] H. Xiao, K. Rasul, and R. Vollgraf. Fashion-mnist: a novel image dataset for benchmarking

machine learning algorithms, 2017.

[65] Y. Xu. Iteration complexity of inexact augmented lagrangian methods for constrained convex

programming. arXiv preprint arXiv:1711.05812v2, 2017.

[66] Y. Xu and W. Yin. A globally convergent algorithm for nonconvex optimization based on block

coordinate update. Journal of Scientiﬁc Computing, 72(2):700–734, 2017.

[67] L. Yang, D. Sun, and K.-C. Toh. Sdpnal+: a majorized semismooth newton-cg augmented
lagrangian method for semideﬁnite programming with nonnegative constraints. Mathematical
Programming Computation, 7(3):331–366, 2015.

[68] A. Yurtsever, Q. T. Dinh, and V. Cevher. A universal primal-dual convex optimization framework.

In Advances in Neural Information Processing Systems, pages 3150–3158, 2015.

[69] A. Yurtsever, O. Fercoq, F. Locatello, and V. Cevher. A conditional gradient framework for
composite convex minimization with applications to semideﬁnite programming. arXiv preprint
arXiv:1804.08544, 2018.

[70] Q. Zhao, S. E. Karisch, F. Rendl, and H. Wolkowicz. Semideﬁnite programming relaxations for
the quadratic assignment problem. Journal of Combinatorial Optimization, 2(1):71–109, 1998.

12

A Complexity Results

A.1 First-Order Optimality

Let us ﬁrst consider the case where the solver in Step 2 is is the ﬁrst-order algorithm APGM, described
in detail in [27]. At a high level, APGM makes use of ∇xLβ(x, y) in (6), the proximal operator
proxg, and the classical Nesterov acceleration [43] to reach ﬁrst-order stationarity for the subproblem
in (7). Suppose that g = δX is the indicator function on a bounded convex set X ⊂ Rd and let

be the radius of a ball centered at the origin that includes X . Then, adapting the results in [27] to our
setup, APGM reaches xk in Step 2 of Algorithm 1 after

ρ = max
x∈X

(cid:107)x(cid:107),

(27)

(cid:33)

ρ2

(cid:32) λ2
βk
(cid:15)2
k+1

O

(28)

(inner) iterations, where λβk denotes the Lipschitz constant of ∇xLβk (x, y), bounded in (15). For
the clarity of the presentation, we have used a looser bound in (28) compared to [27]. Using (28), we
derive the following corollary, describing the total iteration complexity of Algorithm 1 in terms of the
number calls made to the ﬁrst-order oracle in APGM.
Corollary A.1. For b > 1, let βk = bk for every k. If we use APGM from [27] for Step 2 of
Algorithm 1, the algorithm ﬁnds an ((cid:15)f , βk) ﬁrst-order stationary point, after T calls to the ﬁrst-order
oracle, where

T = O

(cid:18) Q3ρ2
(cid:15)4

logb

(cid:19)(cid:19)

(cid:18) Q
(cid:15)

= ˜O

(cid:18) Q3ρ2
(cid:15)4

(cid:19)

.

(29)

Proof. Let K denote the number of (outer) iterations of Algorithm 1 and let (cid:15)f denote the desired
accuracy of Algorithm 1, see (9). Recalling Theorem 4.1, we can then write that

(cid:15)f =

Q
βK

,

(30)

or, equivalently, βK = Q/(cid:15)f . We now count the number of total (inner) iterations T of Algorithm 1
to reach the accuracy (cid:15)f . From (15) and for sufﬁciently large k, recall that λβk ≤ λ(cid:48)(cid:48)βk is the
smoothness parameter of the augmented Lagrangian. Then, from (28) ad by summing over the outer
iterations, we bound the total number of (inner) iterations of Algorithm 1 as

(cid:33)

ρ2

(cid:32) λ2

βk−1
(cid:15)2
k

O

O (cid:0)β4

k−1ρ2(cid:1)

(Step 1 of Algorithm 1)

T =

=

K
(cid:88)

k=1

K
(cid:88)

k=1

≤ O (cid:0)Kβ4
(cid:32)

K−1ρ2(cid:1)
(cid:33)

KQ3ρ2
(cid:15)4
f

≤ O

.

(see (30))

({βk}k is increasing)

In addition, if we specify βk = bk for all k, we can further reﬁne T . Indeed,

βK = bK =⇒ K = logb

(cid:19)

,

(cid:18) Q
(cid:15)f

which, after substituting into (31) gives the ﬁnal bound in Corollary 4.2.

13

(31)

(32)

A.2 Second-Order Optimality

Let us now consider the second-order optimality case where the solver in Step 2 is the the trust region
method developed in [17]. Trust region method minimizes a quadratic approximation of the function
within a dynamically updated trust-region radius. Second-order trust region method that we consider
in this section makes use of Hessian (or an approximation of Hessian) of the augmented Lagrangian
in addition to ﬁrst order oracles.

As shown in [45], ﬁnding approximate second-order stationary points of convex-constrained problems
is in general NP-hard. For this reason, we focus in this section on the special case of (1) with g = 0.

(cid:32) λ2

Let us compute the total computational complexity of Algorithm 1 with the trust region method in
Step 2, in terms of the number of calls made to the second-order oracle. By adapting the result in [17]
to our setup, we ﬁnd that the number of (inner) iterations required in Step 2 of Algorithm 1 to produce
xk+1 is

O

βk,H (Lβk (x1, y) − minx Lβk (x, y))
(cid:15)3
k
where λβ,H is the Lipschitz constant of the Hessian of the augmented Lagrangian, which is of the
order of β, as can be proven similar to Lemma 2.1 and x1 is the initial iterate of the given outer loop.
In [17], the term Lβ(x1, y) − minx Lβ(x, y) is bounded by a constant independent of (cid:15). We assume
a uniform bound for this quantity for every βk, instead of for one value of βk as in [17]. Using (33)
and Theorem 4.1, we arrive at the following:
Corollary A.2. For b > 1, let βk = bk for every k. We assume that

(33)

,

(cid:33)

Lβ(x1, y) − min

x

Lβ(x, y) ≤ Lu,

∀β.

(34)

If we use the trust region method from [17] for Step 2 of Algorithm 1, the algorithm ﬁnds an
(cid:15)-second-order stationary point of (1) in T calls to the second-order oracle where

T = O

(cid:18) LuQ(cid:48)5
(cid:15)5

logb

(cid:19)(cid:19)

(cid:18) Q(cid:48)
(cid:15)

= (cid:101)O

(cid:18) LuQ(cid:48)5
(cid:15)5

(cid:19)

.

(35)

Before closing this section, we note that the remark after Corollary 4.2 applies here as well.

A.3 Approximate optimality of (1).

Corollary 4.2 establishes the iteration complexity of Algorithm 1 to reach approximate ﬁrst-order
stationarity for the equivalent formulation of (1) presented in (5). Unlike the exact case, approximate
ﬁrst-order stationarity in (5) does not immediately lend itself to approximate stationarity in (1), and
the study of approximate stationarity for the penalized problem (special case of our setting with dual
variable set to 0) has also precedent in [5]. For a precedent in convex optimization for relating the
convergence in augmented Lagrangian to the constrained problem using duality, see [62]. For the
second-order case, it is in general not possible to establish approximate second-order optimality for
(5) from Corollary 4.3, with the exception of linear constraints. [45] provides an hardness result by
showing that checking an approximate second-order stationarity is NP-hard.

B Proof of Theorem 4.1

For every k ≥ 2, recall from (6) and Step 2 of Algorithm 1 that xk satisﬁes

dist(−∇f (xk) − DA(xk)(cid:62)yk−1

− βk−1DA(xk)(cid:62)A(xk), ∂g(xk))
= dist(−∇xLβk−1(xk, yk−1), ∂g(xk)) ≤ (cid:15)k.

With an application of the triangle inequality, it follows that

dist(−βk−1DA(xk)(cid:62)A(xk), ∂g(xk))

≤ (cid:107)∇f (xk)(cid:107) + (cid:107)DA(xk)(cid:62)yk−1(cid:107) + (cid:15)k,

14

(36)

(37)

(39)

(40)

which in turn implies that

dist(−DA(xk)(cid:62)A(xk), ∂g(xk)/βk−1)

+

(cid:107)DA(xk)(cid:62)yk−1(cid:107)
βk−1

+

(cid:15)k
βk−1

(cid:107)∇f (xk)(cid:107)
βk−1
f + λ(cid:48)
λ(cid:48)

≤

≤

A(cid:107)yk−1(cid:107) + (cid:15)k
βk−1

,

(38)

f , λ(cid:48)

A were deﬁned in (17). We next translate (38) into a bound on the feasibility gap (cid:107)A(xk)(cid:107).

where λ(cid:48)
Using the regularity condition (18), the left-hand side of (38) can be bounded below as
dist(−DA(xk)(cid:62)A(xk), ∂g(xk)/βk−1) ≥ ν(cid:107)A(xk)(cid:107).

(see (18))

By substituting (39) back into (38), we ﬁnd that
f + λ(cid:48)
λ(cid:48)

(cid:107)A(xk)(cid:107) ≤

A(cid:107)yk−1(cid:107) + (cid:15)k
νβk−1

.

In words, the feasibility gap is directly controlled by the dual sequence {yk}k. We next establish that
the dual sequence is bounded. Indeed, for every k ∈ K, note that

(cid:107)yk(cid:107) = (cid:107)y0 +

k
(cid:88)

i=1

σiA(xi)(cid:107)

(Step 5 of Algorithm 1)

≤ (cid:107)y0(cid:107) +

≤ (cid:107)y0(cid:107) +

k
(cid:88)

i=1

k
(cid:88)

i=1

σi(cid:107)A(xi)(cid:107)

(triangle inequality)

(cid:107)A(x1)(cid:107) log2 2
k log2(k + 1)

(Step 4)

≤ (cid:107)y0(cid:107) + c(cid:107)A(x1)(cid:107) log2 2 =: ymax,

where

c ≥

∞
(cid:88)

i=1

1
k log2(k + 1)

.

Substituting (41) back into (40), we reach

(cid:107)A(xk)(cid:107) ≤

f + λ(cid:48)
λ(cid:48)

Aymax + (cid:15)k
νβk−1

≤

2λ(cid:48)

f + 2λ(cid:48)
νβk−1

Aymax

,

(41)

(42)

(43)

where the second line above holds if k0 is large enough, which would in turn guarantees that
(cid:15)k = 1/βk−1 is sufﬁciently small since {βk}k is increasing and unbounded. It remains to control
the ﬁrst term in (10). To that end, after recalling Step 2 of Algorithm 1 and applying the triangle
inequality, we can write that

dist(−∇xLβk−1 (xk, yk), ∂g(xk))
≤ dist(−∇xLβk−1 (xk, yk−1), ∂g(xk))
+ (cid:107)∇xLβk−1 (xk, yk) − ∇xLβk−1 (xk, yk−1)(cid:107).
(44)
The ﬁrst term on the right-hand side above is bounded by (cid:15)k, by Step 5 of Algorithm 1. For the
second term on the right-hand side of (44), we write that

(cid:107)∇xLβk−1(xk, yk) − ∇xLβk−1(xk, yk−1)(cid:107)
= (cid:107)DA(xk)(cid:62)(yk − yk−1)(cid:107)
≤ λ(cid:48)
= λ(cid:48)

(see (17))

(see (6))

(see Step 5 of Algorithm 1)

A(cid:107)yk − yk−1(cid:107)
Aσk(cid:107)A(xk)(cid:107)
2λ(cid:48)
Aσk
νβk−1

f + λ(cid:48)

(λ(cid:48)

≤

Aymax).

(see (43))

(45)

15

By combining (44,45), we ﬁnd that

dist(∇xLβk−1(xk, yk), ∂g(xk))

≤

2λ(cid:48)
Aσk
νβk−1

By combining (43,46), we ﬁnd that

(λ(cid:48)

f + λ(cid:48)

Aymax) + (cid:15)k.

dist(−∇xLβk−1(xk, yk), ∂g(xk)) + (cid:107)A(xk)(cid:107)

≤

(cid:18) 2λ(cid:48)

Aσk
νβk−1

(λ(cid:48)

f + λ(cid:48)

Aymax) + (cid:15)k

(cid:19)

+ 2

Applying σk ≤ σ1, we ﬁnd that

(cid:18) λ(cid:48)

f + λ(cid:48)

Aymax

νβk−1

(cid:19)

.

dist(−∇xLβk−1(xk, yk), ∂g(xk)) + (cid:107)A(xk)(cid:107)

≤

2λ(cid:48)

Aσ1 + 2
νβk−1

(λ(cid:48)

f + λ(cid:48)

Aymax) + (cid:15)k.

(46)

(47)

(48)

For the second part of the theorem, we use the Weyl’s inequality and Step 5 of Algorithm 1 to write

λmin(∇xxLβk−1(xk, yk−1)) ≥ λmin(∇xxLβk−1 (xk, yk))

− σk(cid:107)

m
(cid:88)

i=1

Ai(xk)∇2Ai(xk)(cid:107).

(49)

The ﬁrst term on the right-hand side is lower bounded by −(cid:15)k−1 by Step 2 of Algorithm 1. We next
bound the second term on the right-hand side above as

Ai(xk)∇2Ai(xk)(cid:107)

m
(cid:88)

σk(cid:107)

i=1
√

≤ σk

m max

i

√

mλA

≤ σk

2λ(cid:48)

(cid:107)Ai(xk)(cid:107)(cid:107)∇2Ai(xk)(cid:107)
f + 2λ(cid:48)
νβk−1

Aymax

,

where the last inequality is due to (4,43). Plugging into (49) gives

λmin(∇xxLβk−1 (xk, yk−1))
2λ(cid:48)

√

≥ −(cid:15)k−1 − σk

mλA

f + 2λ(cid:48)
νβk−1

Aymax

,

which completes the proof of Theorem 4.1.

C Proof of Lemma 2.1

Proof. Note that

which implies that

Lβ(x, y) = f (x) +

m
(cid:88)

i=1

yiAi(x) +

β
2

m
(cid:88)

(Ai(x))2,

i=1

(50)

∇xLβ(x, y)

= ∇f (x) +

m
(cid:88)

i=1

yi∇Ai(x) +

β
2

m
(cid:88)

i=1

Ai(x)∇Ai(x)

= ∇f (x) + DA(x)(cid:62)y + βDA(x)(cid:62)A(x),

(51)

16

where DA(x) is the Jacobian of A at x. By taking another derivative with respect to x, we reach

∇2

xLβ(x, y) = ∇2f (x) +

m
(cid:88)

i=1

(yi + βAi(x)) ∇2Ai(x)

+ β

m
(cid:88)

i=1

∇Ai(x)∇Ai(x)(cid:62).

It follows that

xLβ(x, y)(cid:107)

(cid:107)∇2
≤ (cid:107)∇2f (x)(cid:107) + max

i

(cid:107)∇2Ai(x)(cid:107) ((cid:107)y(cid:107)1 + β(cid:107)A(x)(cid:107)1)

m
(cid:88)

+ β

(cid:107)∇Ai(x)(cid:107)2

≤ λh +

i=1
√
mλA ((cid:107)y(cid:107) + β(cid:107)A(x)(cid:107)) + β(cid:107)DA(x)(cid:107)2
F .

For every x such that (cid:107)x(cid:107) ≤ ρ and (cid:107)A(x)(cid:107) ≤ ρ, we conclude that

(cid:107)∇2

xLβ(x, y)(cid:107) ≤ λf +

√

mλA ((cid:107)y(cid:107) + βρ(cid:48)) + β max
(cid:107)x(cid:107)≤ρ

(cid:107)DA(x)(cid:107)2
F ,

which completes the proof of Lemma 2.1.

D Clustering

We only verify the condition in (18) here. Note that

A(x) = V V (cid:62)1 − 1,

DA(x) =






w1,1x(cid:62)
1
...
wn,1x(cid:62)
n






· · ·

w1,nx(cid:62)
1

· · · wn,n1x(cid:62)
n


x(cid:62)
1

= [ V

· · ·

V ] +







 ,

. . .

x(cid:62)
n

(52)

(53)

(54)

(55)

(56)

where wi.i = 2 and wi,j = 1 for i (cid:54)= j. In the last line above, n copies of V appear and the last
matrix above is block-diagonal. For xk, deﬁne Vk accordingly and let xk,i be the ith row of Vk.
Consequently,

DA(xk)(cid:62)A(xk) =











(V (cid:62)

k Vk − In)V (cid:62)
k 1
...
k Vk − In)V (cid:62)
(V (cid:62)
k 1

xk,1(VkV (cid:62)
k 1 − 1)1
...
xk,n(VkV (cid:62)
k 1 − 1)n




+




 ,

(57)

√

where In ∈ Rn×n is the identity matrix. Let us make a number of simplifying assumptions. First, we
assume that (cid:107)xk(cid:107) <
s (which can be enforced in the iterates by replacing C with (1 − (cid:15))C for a
small positive (cid:15) in the subproblems). Under this assumption, it follows that
(cid:26)0

i ≤ d.

(58)

(∂g(xk))i =

{a : a ≤ 0}

(xk)i > 0
(xk)i = 0,

Second, we assume that Vk has nearly orthonormal columns, namely, V (cid:62)
k Vk ≈ In. This can also be
enforced in each iterate of Algorithm 1 and naturally corresponds to well-separated clusters. While a

17

more ﬁne-tuned argument can remove these assumptions, they will help us simplify the presentation
here. Under these assumptions, the (squared) right-hand side of (18) becomes

∂g(xk)
βk−1
(cid:13)
2
(cid:13)
(cid:13)

(cid:19)2

(a+ = max(a, 0))

(xk ∈ C ⇒ xk ≥ 0)

(cid:18)

dist

−DA(xk)(cid:62)A(xk),

+

(cid:13)
(cid:0)−DA(xk)(cid:62)A(xk)(cid:1)
(cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
n
(cid:88)

xk,1(VkV (cid:62)
k 1 − 1)1
...
xk,n(VkV (cid:62)
k 1 − 1)n

(cid:107)xk,i(cid:107)2(VkV (cid:62)




=

=

=

k 1 − 1)2
i






(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

i=1

≥ min

i

(cid:107)xk,i(cid:107)2 ·

n
(cid:88)

i=1

(VkV (cid:62)

k 1 − 1)2
i

= min

i

(cid:107)xk,i(cid:107)2 · (cid:107)VkV (cid:62)

k 1 − 1(cid:107)2.

(59)

Therefore, given a prescribed ν, ensuring mini (cid:107)xk,i(cid:107) ≥ ν guarantees (18). When the algorithm
is initialized close enough to the constraint set, there is indeed no need to separately enforce (59).
In practice, often n exceeds the number of true clusters and a more intricate analysis is required to
establish (18) by restricting the argument to a particular subspace of Rn.

E Additional Experiments

E.1 Basis Pursuit

Basis Pursuit (BP) ﬁnds sparsest solutions of an under-determined system of linear equations by
solving

min
z

(cid:107)z(cid:107)1

s.t. Bz = b,

(60)

where B ∈ Rn×d and b ∈ Rn. Various primal-dual convex optimization algorithms are available
in the literature to solve BP, including [61, 19]. We compare our algorithm against state-of-the-art
primal-dual convex methods for solving (60), namely, Chambole-Pock [19], ASGARD [62] and
ASGARD-DL [61].
Here, we take a different approach and cast (60) as an instance of (1). Note that any z ∈ Rd
can be decomposed as z = z+ − z−, where z+, z− ∈ Rd are the positive and negative parts of
2 ∈ Rd, where ◦
z, respectively. Then consider the change of variables z+ = u◦2
2 ](cid:62) ∈ R2d and deﬁne
denotes element-wise power. Next, we concatenate u1 and u2 as x := [u(cid:62)
B := [B, −B] ∈ Rn×2d. Then, (60) is equivalent to (1) with

1 and z− = u◦2

1 , u(cid:62)

f (x) =(cid:107)x(cid:107)2,

g(x) = 0,

s.t. A(x) = Bx◦2 − b.

(61)

We draw the entries of B independently from a zero-mean and unit-variance Gaussian distribution.
For a ﬁxed sparsity level k, the support of z∗ ∈ Rd and its nonzero amplitudes are also drawn from
the standard Gaussian distribution. Then the measurement vector is created as b = Bz + (cid:15), where (cid:15)
is the noise vector with entries drawn independently from the zero-mean Gaussian distribution with
variance σ2 = 10−6.

The results are compiled in Figure 2. Clearly, the performance of Algorithm 1 with a second-order
solver for BP is comparable to the rest. It is, indeed, interesting to see that these type of nonconvex
relaxations gives the solution of convex one and ﬁrst order methods succeed.

Discussion: The true potential of our reformulation is in dealing with more structured norms rather
than (cid:96)1, where computing the proximal operator is often intractable. One such case is the latent group

18

lasso norm [46], deﬁned as

Figure 2: Basis Pursuit

(cid:107)z(cid:107)Ω =

I
(cid:88)

i=1

(cid:107)zΩi(cid:107),

where {Ωi}I
i=1 are (not necessarily disjoint) index sets of {1, · · · , d}. Although not studied here, we
believe that the nonconvex framework presented in this paper can serve to solve more complicated
problems, such as the latent group lasso. We leave this research direction for future work.

Condition veriﬁcation:
above f, A, g. Note that

In the sequel, we verify that Theorem 4.1 indeed applies to (1) with the

where diag(x) ∈ R2d×2d is the diagonal matrix formed by x. The left-hand side of (18) then reads as

DA(x) = 2Bdiag(x),

(62)

(cid:18)

dist

−DA(xk)(cid:62)A(xk),

∂g(xk)
βk−1
= dist (cid:0)−DA(xk)(cid:62)A(xk), {0}(cid:1)
= (cid:107)DA(xk)(cid:62)A(xk)(cid:107)

(cid:19)

(g ≡ 0)

= 2(cid:107)diag(xk)B

(cid:62)

(Bx◦2

k − b)(cid:107).

(see (62))

(63)

To bound the last line above, let x∗ be a solution of (1) and note that Bx◦2
∗ = b by deﬁnition. Let also
zk, z∗ ∈ Rd denote the vectors corresponding to xk, x∗. Corresponding to xk, also deﬁne uk,1, uk,2
k,2 ∈ Rd be the vector of amplitudes of zk. To simplify matters, let
naturally and let |zk| = u◦2
us assume also that B is full-rank. We then rewrite the norm in the last line of (63) as

k,1 + u◦2

(cid:107)diag(xk)B

(cid:62)

(Bx◦2
(cid:62)

k − b)(cid:107)2
B(x◦2

= (cid:107)diag(xk)B

k − x◦2
B(xk − x∗)(cid:107)2
= (cid:107)diag(xk)B
= (cid:107)diag(uk,1)B(cid:62)B(zk − z∗)(cid:107)2

∗ )(cid:107)2

(cid:62)

(Bx◦2

∗ = b)

+ (cid:107)diag(uk,2)B(cid:62)B(zk − z∗)(cid:107)2

k,2)B(cid:62)B(zk − z∗)(cid:107)2

= (cid:107)diag(u◦2
k,1 + u◦2
= (cid:107)diag(|zk|)B(cid:62)B(zk − z∗)(cid:107)2
≥ ηn(Bdiag(|zk|))2(cid:107)B(zk − z∗)(cid:107)2
= ηn(Bdiag(|zk|))2(cid:107)Bzk − b(cid:107)2
≥ min
|T |=n

ηn(BT ) · |zk,(n)|2(cid:107)Bzk − b(cid:107)2,

(Bz∗ = Bx◦2

∗ = b)

19

(64)

10010110210310410-1210-810-410010110210310410-1210-810-4100where ηn(·) returns the nth largest singular value of its argument. In the last line above, BT is the
restriction of B to the columns indexed by T of size n. Moreover, zk,(n) is the nth largest entry of z
in magnitude. Given a prescribed ν, (18) therefore holds if

|zk,(n)| ≥

ν
2(cid:112)min|T |=n ηn(BT )

,

(65)

for every iteration k. If Algorithm 1 is initialized close enough to the solution z∗ and the entries of
z∗ are sufﬁciently large in magnitude, there will be no need to directly enforce (65).

E.2 Generalized Eigenvalue Problem

(i) C : Gaussian iid

(ii) C : Polynomial decay

(iii) C : Exponential decay

(iv)

(v)

(vi)

Figure 3: (Top) Objective convergence for calculating top generalized eigenvalue and eigenvector of B
and C. (Bottom) Eigenvalue structure of the matrices. For (i),(ii) and (iii), C is positive semideﬁnite;
for (iv), (v) and (vi), C contains negative eigenvalues. [(i): Generated by taking symmetric part of
iid Gaussian matrix. (ii): Generated by randomly rotating diag(1−p, 2−p, · · · , 1000−p)(p = 1). (iii):
Generated by randomly rotating diag(10−p, 10−2p, · · · , 10−1000p)(p = 0.0025).]

Generalized eigenvalue problem has extensive applications in machine learning, statistics and data
analysis [26]. The well-known nonconvex formulation of the problem is [13] given by
(cid:40) min
x∈Rn
x(cid:62)Bx = 1,

x(cid:62)Cx

(66)

20

10-110010110-1010-510010-110010110-1010-510010-110010110-1010-5100020040060080010000.010.0150.020.0250.030.0350.040.0450.050.0550200400600800100000.10.20.30.40.50.60.70.80200400600800100000.020.040.060.080.10.1210-110010110-1510-1010-510010-110010110-1010-510010-110010110210-1010-510002004006008001000-0.0500.050.102004006008001000-0.06-0.04-0.0200.020.040.0602004006008001000-0.06-0.04-0.0200.020.040.06where B, C ∈ Rn×n are symmetric matrices and B is positive deﬁnite, namely, B (cid:31) 0. The
generalized eigenvector computation is equivalent to performing principal component analysis (PCA)
of C in the norm B. It is also equivalent to computing the top eigenvector of symmetric matrix
S = B−1/2CB1/2 and multiplying the resulting vector by B−1/2. However, for large values of n,
computing B−1/2 is extremely expensive. The natural convex SDP relaxation for (66) involves lifting
Y = xx(cid:62) and removing the nonconvex rank(Y ) = 1 constraint, namely,

tr(CY )

(cid:40) min
Y ∈Rn×n
tr(BY ) = 1, X (cid:23) 0.

Here, however, we opt to directly solve (66) because it ﬁts into our template with

f (x) =x(cid:62)Cx,
A(x) =x(cid:62)Bx − 1.

g(x) = 0,

(67)

(68)

We compare our approach against three different methods: manifold based Riemannian gradient
descent and Riemannian trust region methods in [11] and the linear system solver in [26], abbrevated
as GenELin. We have used Manopt software package in [12] for the manifold based methods. For
GenELin, we have utilized Matlab’s backslash operator as the linear solver. The results are compiled
in Figure 3.

Condition veriﬁcation: Here, we verify the regularity condition in (18) for problem (66). Note
that

DA(x) = (2Bx)(cid:62).

(69)

Therefore,

(cid:18)

−DA(xk)(cid:62)A(xk),

dist

(cid:19)2

∂g(xk)
βk−1

= dist (cid:0)−DA(xk)(cid:62)A(xk), {0}(cid:1)2

(g ≡ 0)

k Bxk − 1)(cid:107)2
k Bxk − 1)2(cid:107)Bxk(cid:107)2

= (cid:107)DA(xk)(cid:62)A(xk)(cid:107)2
= (cid:107)2Bxk(x(cid:62)
= 4(x(cid:62)
= 4(cid:107)Bxk(cid:107)2(cid:107)A(xk)(cid:107)2
≥ ηmin(B)2(cid:107)xk(cid:107)2(cid:107)A(xk)(cid:107)2,

(see (69))

(see (68))

(70)

where ηmin(B) is the smallest eigenvalue of the positive deﬁnite matrix B. Therefore, for a prescribed
ν, the regularity condition in (18) holds with (cid:107)xk(cid:107) ≥ ν/ηmin for every k. If the algorithm is initialized
close enough to the constraint set, there will be again no need to directly enforce this latter condition.

E.3

(cid:96)∞ Denoising with a Generative Prior

The authors of [56, 30] have proposed to project onto the range of a Generative Adversarial network
(GAN) [28], as a way to defend against adversarial examples. For a given noisy observation x∗ + η,
they consider a projection in the (cid:96)2 norm. We instead propose to use our augmented Lagrangian
method to denoise in the (cid:96)∞ norm, a much harder task:

min
x,z
s.t.

(cid:107)x∗ + η − x(cid:107)∞
x = G(z).

(71)

We use a pretrained generator for the MNIST dataset, given by a standard deconvolutional neural
network architecture [52]. We compare the succesful optimizer Adam [34] and gradient Descent
against our method. Our algorithm involves two forward and one backward pass through the network,
as oposed to Adam that requires only one forward/backward pass. For this reason we let our algorithm
run for 2000 iterations, and Adam and GD for 3000 iterations. Both Adam and gradient descent
generate a sequence of feasible iterates xt = G(zt). For this reason we plot the objective evaluated at
the point G(zt) vs iteration count in ﬁgure 4. Our method successfully minimizes the objective value,
while Adam and GD do not.

21

Figure 4: Augmented Lagrangian vs Adam and Gradient descent for (cid:96)∞ denoising

E.4 Quadratic assginment problem

Let K, L be n × n symmetric metrices. QAP in its simplest form can be written as

max tr(KP LP ),

subject to P be a permutation matrix

(72)

A direct approach for solving (72) involves a combinatorial search. To get the SDP relaxation of (72),
we will ﬁrst lift the QAP to a problem involving a larger matrix. Observe that the objective function
takes the form

where ⊗ denotes the Kronecker product. Therefore, we can recast (72) as

tr((K ⊗ L)(vec(P )vec(P (cid:62)))),

tr((K ⊗ L)Y ) subject to Y = vec(P )vec(P (cid:62)),

(73)

where P is a permutation matrix. We can relax the equality constraint in (73) to a semideﬁnite
constraint and write it in an equivalent form as

X =

(cid:20)

1
vec(P )

(cid:21)

vec(P )(cid:62)
Y

(cid:23) 0 for a symmetricX ∈ S(n2+1)×(n2+1)

We now introduce the following constraints such that

Bk(X) = bk, bk ∈ Rmk
to make sure X has a proper structure. Here, Bk is a linear operator on X and the total number of
constraints is m = (cid:80)
k mk. Hence, SDP relaxation of the quadratic assignment problem takes the
form,

(74)

max (cid:104)C, X(cid:105)

subject to P 1 = 1, 1(cid:62)P = 1, P ≥ 0

trace1(Y ) = I trace2(Y ) = I
vec(P ) = diag(Y )

trace(Y ) = n

(cid:20)

1
vec(P )

(cid:21)

vec(P )(cid:62)
Y

(cid:23) 0,

(75)

where trace1(.) and trace2(.) are partial traces satisfying,

trace1(K ⊗ L) = trace(K)L and trace2(K ⊗ L) = Ktrace(L)

22

altrace∗

1(T ) = I ⊗ T and trace∗

2(T ) = T ⊗ I

1st set of equalities are due to the fact that permutation matrices are doubly stochastic. 2nd set of
equalities are to ensure permutation matrices are orthogonal, i.e., P P (cid:62) = P (cid:62)P = I. 3rd set of
equalities are to enforce every individual entry of the permutation matrix takes either 0 or 1, i.e.,
X1,i = Xi,i ∀i ∈ [1, n2 + 1]. . Trace constraint in the last line is to bound the problem domain. By
concatenating the Bk’s in (74), we can rewrite (75) in standard SDP form as

max (cid:104)C, X(cid:105)

subject to B(X) = b, b ∈ Rm

trace(X) = n + 1
Xij ≥ 0,
i, j G
X (cid:23) 0,

(76)

where G represents the index set for which we introduce the nonnegativities. When G covers the
wholes set of indices, we get the best approximation to the original problem. However, it becomes
computationally undesirable as the problem dimension increases. Hence, we remove the redundant
nonnegativity constraints and enforce it for the indices where Kronecker product between K and L is
nonzero.

We penalize the non-negativity constraints and add it to the augmented Lagrangian objective since a
projection to the positive orthant approach in the low rank space as we did for the clustering does not
work here.

We take [23] as the baseline. This is an SDP based approach for solving QAP problems containing
a sparse graph. We compare against the best feasible upper bounds reported in [23] for the given
instances. Here, optimality gap is deﬁned as

%Gap =

|bound − optimal|
optimal

× 100

We used a (relatively) sparse graph data set from the QAP library. We run our low rank algorithm for
different rank values. rm in each instance corresponds to the smallest integer satisfying the Pataki
bound [49, 1]. Results are shown in Table 1. Primal feasibility values except for the last instance
esc128 is less than 10−5 and we obtained bounds at least as good as the ones reported in [23] for
these problems.
For esc128, the primal feasibility is ≈ 10−1, hence, we could not manage to obtain a good optimality
gap.

23

Data

Optimal Value

Sparse QAP [23]

esc16a
esc16b
esc16c
esc16d
esc16e
esc16g
esc16h
esc16i
esc16j
esc32a
esc32b
esc32c
esc32d
esc32e
esc32g
esc32h
esc64a
esc128

68
292
160
16
28
26
996
14
8
130
168
642
200
2
6
438
116
64

8.8
0
5
12.5
7.1
0
0
0
0
93.8
88.1
7.8
21
0
0
18.3
53.4
175

Optimality Gap (%)

r = 10
11.8
0
5.0
37.5
7.1
23.1
0
0
0
129.2
111.9
15.6
28.0
0
33.3
25.1
62.1
256.3

r = 25
0
0
5.0
0
0
7.7
0
0
0
109.2
92.9
14.0
28.0
0
0
19.6
51.7
193.8

iAL
r = 50
0
0
2.5
0
14.3
0
0
14.3
0
104.6
97.6
15.0
29.0
0
0
25.1
58.6
243.8

r = rm rm
157
5.9
0
224
177
3.8
126
25.0
126
7.1
0
126
0
224
0
113
0
106
83.1
433
69.0
508
4.0
552
17.0
470
0
220
0
234
13.2
570
34.5
899
2045
215.6

Table 1: Comparison between upper bounds on the problems from the QAP library with (relatively)
sparse L.

24

