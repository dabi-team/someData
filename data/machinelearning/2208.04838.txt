2
2
0
2

g
u
A
9

]

R
C
.
s
c
[

1
v
8
3
8
4
0
.
8
0
2
2
:
v
i
X
r
a

Robust Machine Learning for Malware Detection over Time

Daniele Angioni1, Luca Demetrio1,2, Maura Pintor1,2, and Battista Biggio1,2

1 University of Cagliari, Cagliari, Italy
{daniele.angioni, luca.demetrio93, maura.pintor, battista.biggio}@unica.it
2 Pluribus One S.r.l., Cagliari, Italy
{name.surname}@pluribus-one.it

Abstract

The presence and persistence of Android malware is an on-going threat that plagues
this information era, and machine learning technologies are now extensively used to deploy
more eﬀective detectors that can block the majority of these malicious programs. However,
these algorithms have not been developed to pursue the natural evolution of malware, and
their performances signiﬁcantly degrade over time because of such concept-drift.

Currently, state-of-the-art techniques only focus on detecting the presence of such drift,
or they address it by relying on frequent updates of models. Hence, there is a lack of
knowledge regarding the cause of the concept drift, and ad-hoc solutions that can counter
the passing of time are still under-investigated.

In this work, we commence to address these issues as we propose (i) a drift-analysis
framework to identify which characteristics of data are causing the drift, and (ii) SVM-CB,
a time-aware classiﬁer that leverages the drift-analysis information to slow down the per-
formance drop. We highlight the eﬃcacy of our contribution by comparing its degradation
over time with a state-of-the-art classiﬁer, and we show that SVM-CB better withstands
the distribution changes that naturally characterize the malware domain. We conclude by
discussing the limitations of our approach and how our contribution can be taken as a ﬁrst
step towards more time-resistant classiﬁers that not only tackle, but also understand the
concept drift that aﬀects data.

1

Introduction

In this information era, we are experiencing tremendous growth in mobile technology, both in
its eﬃcacy and pervasiveness. One of the most common operating systems for mobile devices is
Android, 1 and, because of its popularity, it became particularly attractive to cyber-attackers
eyes, who exploit Android vulnerabilities creating malicious applications, also known as mal-
ware, targeted speciﬁcally for these systems 2. Luckily, the technological development of this
era brings enough power to machine learning algorithms, considered the standard for many
domains, including cyber-security and, speciﬁcally, malware detection, which has shown to be
very eﬀective also against never-seen malware families [1, 2, 3, 4, 5, 6].

However, real-world data experience a phenomenon known as concept drift, i.e. their tem-
poral evolution [7]. In particular, Android applications naturally change over time since at-
tackers keep adjusting malware to bypass detection, and legitimate applications embrace new
frameworks and programming patterns while abandoning deprecated technologies. Recent work
highlighted how concept drift worryingly aﬀects the performance of state-of-the-art Android
malware detectors, revealing how much it drops over time, contradicting the results achieved
by their original analysis since they were inﬂated by wrong evaluation settings [8]. On top of this
issue, the only proposals to counter the concept drift rely on continuous update or retraining

1https://www.idc.com/promo/smartphone-market-share
2https://securelist.com/mobile-malware-evolution-2021/105876/

 
 
 
 
 
 
Robust Machine Learning for Malware Detection over Time

Angioni, Demetrio, Pintor, Biggio

of machine learning models [9, 10, 11, 12, 13], instead of tracking which are the characteristics
of data that mainly change over time.

Hence, we start bridging the gaps left in the state-of-the-art by proposing novel techniques
that understand the concept drift and take advantage of it. The contribution of this work are
summarized as follows: (i) we propose a drift-analysis framework that investigates the reasons
causing the concept drift inside data, highlighting which features are more prone to have a
negative contribution to the performance decay; and (ii) we propose SVM-CB, a novel classiﬁer
that leverages our drift-analysis information to bound the selected unstable features, reducing
the overall performance drop.

We show the eﬀectiveness of SVM-CB, by comparing its performance over time with Drebin [1],

a state-of-the-art linear classiﬁer. To obtain a fair comparison, we train both classiﬁers on the
same dataset, and we show how SVM-CB better withstand the passing of time, thanks to the
domain knowledge acquired through the results of our drift-analysis framework, thus allowing
SVM-CB to be updated less often compared to Drebin.

We conclude by discussing future directions of this work considering fewer heuristic rules to

tune SVM-CB, and extensions of our methodology to non-linear classiﬁers.

2 Android Malware Detection over Time

Before delving into the details of the proposed methods, we ﬁrstly describe the structure of
Android applications to lay a foundation for understanding the classiﬁer that we consider in
this work, and we discuss the problem and proposed solutions to the concept drift problem.
Android Applications. These are programs that run on the Android Operating System.
They are distributed as an Android Application Package (APK), an archive ﬁle with the .apk
extension. An APK contains diﬀerent ﬁles: (i) the AndroidManifest.xml, that stores all the
required information needed by the operating system to correctly handle the application at run-
time;3 (ii) the classes.dex, that stores the compiled source code and all user-implemented
methods and classes; and (iii) additional .xml and resource ﬁles that are used to deﬁne the
application user interface, along with additional functionality or multimedia content.
Malware Detection with Machine Learning. We select a popular binary detector named
Drebin [1] as a baseline for our proposals, for which we show the architecture in Fig .whose ar-
chitecture is described in Fig. 1. This classiﬁer relies on a Support Vector Machine (SVM) [14]
trained on top of hand-crafted features extracted from APKs provided at training time, and
they consider: (i) features extracted from AndroidManifest.xml, like hardware components, re-
quested permissions, app components, and ﬁltered intents; (ii) features extracted from classess.dex,
including restricted API calls, used permissions, suspicious API calls, and network addresses.
All this knowledge is encoded inside d-dimensional feature vectors, whose entries are 0 or 1
depending on the absence or presence of a particular characteristic. Since Drebin relies on an
SVM, it can be used to investigate its decision-making process since each feature is already
correlated with a weight that describes its orientation toward one of the two prediction classes,
namely legit and malicious.
Performance over Time. Even though Drebin registered impressive performance in detecting
malware, it was not properly tested inside a time-aware environment. I ts training relies on the
Independent and Identical Distribution (I.I.D.) assumption, which takes for granted that both
training and testing samples are drawn from the same distribution. While this property might
hold for the image classiﬁcation domain, it can not be satisﬁed for the rapidly-growing domain

3https://developer.android.com/guide/topics/manifest/manifest-intro

2

Robust Machine Learning for Malware Detection over Time

Angioni, Demetrio, Pintor, Biggio

Figure 1: A schematic representation of Drebin [1]. First, applications are represented as binary
vectors in a d-dimensional feature space, and this corpus of data is used to train an SVM. At
test time, unseen applications are fed into a linear classiﬁer, and they are classiﬁed as malware
if their score f (x) ≥ 0.

of programs, where training samples diﬀer from future test data as new updates, frameworks,
and techniques are introduced while others are deprecated. The classic evaluation setting injects
artifacts inside the learning process, like the presence of samples coming from mixed periods,
allowing the classiﬁer to rely on future knowledge at training time. Such has been demonstrated
by Pendlebury et al. [8], that show how selected state-of-the-art detectors are characterized by
worrying performance drops when evaluated with a more realistic time-aware approach.

3 Analysing and Improving Robustness to Time

We now introduce the two contributions of our work: (i) the drift-analysis framework to either
understand the causes of the concept drift by inspecting the features extracted from data at
diﬀerent time intervals and quantifying their contribution to the overall performance drop;
and (ii) the time-aware learning algorithm SVM-CB (i.e. SVM with Custom Bounds), that
uses drift-analysis information to select and bound the weights of a chosen number of features
considered unstable to reduce their contribution to the performance decay caused by time.
Drift-analysis framework. Our ﬁrst contribution tackles the open problem of explaining the
concept drift, and we propose the temporal feature stability (T-stability), a novel metric mea-
suring the single feature contribution to the performance decay, designed for linear classiﬁers.
This metric captures two distinct characteristics of each single feature when dealing with time:
their relevance in the classiﬁer prediction and their temporal evolution. These are quantiﬁed
by the product between (i) the weight wj corresponding to the j-th feature, learned at training
time by the classiﬁer; and (ii) the slope mj that approximates the temporal evolution of the
values of the feature.

To compute our metric, we start with the hypothesis that a decrement in the detection rate of
malware is strictly related to a decaying score assigned to malware samples as time passes. Such
behavior corresponds to a shift of the malware class distribution towards the decision boundary
learned at training time, thus increasing the number of misclassiﬁed samples. To quantify
our intuitions, we analyze the variation of the malware score over time, and we compute the
conditional expectation of the score over all malware samples (identiﬁed with the label y = 1)
at time t as:

E[wT x + b|y = 1, t] = E 






d

X
j=0

wj · xi,j





+ b|y = 1, t


d

= 


X
j=0

wj · E[xi,j |y = 1, t]


+ b

(1)

3

Robust Machine Learning for Malware Detection over Time

Angioni, Demetrio, Pintor, Biggio

Algorithm 1 Drift Analysis
Input : The input timestamped and labeled dataset D = {xi, yi, ti}n

i=1; the time window ∆t;

the weights w of the reference classiﬁer g′.

Output: the T-stability vector δ

⊲ Compute number of time slots
⊲ Initialize utility matrix

Dk ← {(xi, yi, ti) ∈ D : yi = 1, ti ∈ [k∆t, (k + 1)∆t]}
M∗,k ← 1

⊲ Obtain data in time slot k
⊲ Compute mean feature value in time slot k

5

|Dk| Pxi∈Dk xi,∗

1 T ← ⌈(tmax − tmin)/∆t⌉
2 M ← zeros(d, T )
3 for k ∈ [0, T − 1] do
4

6 m ← zeros(d)
7 for j ∈ [0, d − 1] do
mj ← f it(Mj,∗)
8

9 δ ← w ◦ m
10 return δ

⊲ Compute slope of the regression line

⊲ Compute the T-stability vector
⊲ Return T-stability vector

where the score is computed as the scalar product between w, the vector containing the weights
of the linear classiﬁer with bias b, and xi the d-dimensional feature vector representation of an
input Android application.

Since we want to quantify how the features contribute to the score expectation evolution,
we consider the derivative of Eq. 1, being the summation over the products between weights
and the derivatives of the feature expectation w.r.t. time.

dE[wT x + b|y, t]
dt

=

d−1

X
j=1

wj ·

dE[xj |y, t]
dt

≈

d−1

X
j=0

wj · mj =

d−1

X
j=1

δj

(2)

Since we are interested in capturing the overall trend of the score decay, we approximate each
derivative of the j-th feature with the slope mj of the regression line that best ﬁts the single
feature expectation over time. Here, we compress the product wj · mj in a single value δj,
that is how we compute the T-stability of the feature j. Intuitively, the larger and negative
the T-stability metric is for a feature, the more such feature accelerates the degradation of the
classiﬁer.

Since expectations are not computable for a speciﬁc time instant t, we quantize the time
variable considering time slots with length ∆t, where the k-th slot indicate the subset Dk of
malware samples registered at time t ∈ [k∆t, (k + 1)∆t], being k an integer variable. Thus,
we use Alg. 1 to obtain the vector δ containing the T-stability of each feature. After having
computed the number of available time slots T based on the timestamps in D, and the chosen
time window ∆t (line 1), we initialize a utility matrix MdxT that will contain the mean feature
values (line 2). Then we iterate through the time slots (line 3) and select, for each one, the
subset Dk (line 4) needed to compute the mean feature value at time k∆t storing it in the k-th
column of M (line 5). After this step, we loop over the number of features (line 7) to compute
the slope mj of the j-th feature over time, i.e.
the j-th row of M (line 8), to eventually
return the Hadamard product between the classiﬁer trained weights w and the feature slopes
m (line 9), i.e. the T-stability vector δ.
Robustness to Future Changes. As our second contribution, we show how to exploit the
information obtained with the drift-analysis inside the optimization process to train SVM-CB,
an SVM classiﬁer hardened against the passing of time. To train SVM-CB, we consider a

4

Robust Machine Learning for Malware Detection over Time

Angioni, Demetrio, Pintor, Biggio

Algorithm 2 SVM-CB learning algorithm
Input : D = {xi, yi}n

i=1, the training data; r, the absolute value of the bound that must be
applied to the weights; δ, the T-stability vector; nf , the number of weights that must
be bounded; N , the number of iterations; η(0), the initial gradient step size ; s(t) a
decaying function of t.

Output: w, b, the trained classiﬁer’s parameters.

1 J ← argsort(δ)
2 Jf ← {jk : k = 0, ..., nf }, jk ∈ J .
3 Initialize Wf = {wj : j ∈ Jf }
4 (w(0), b(0)) ← (0, 0)
5 for t ∈ [1, N ] do
η(t) ← η(0)s(t)
6
w(t) ← w(t−1) − η(t)∇wL
b(t) ← b(t−1) − η(t)∇bL
w(t) ← Clip(w(t); Wf , r)

7

8

9

10 return w(t), b(t)

⊲ Initialize feature indexes ordered w.r.t. δ
⊲ Select first nf indexes
⊲ Select corresponding nf weights
⊲ Initialize parameters

⊲ Update learning rate
⊲ Update weights
⊲ Update bias
⊲ Clip weights based on Eq. 4 criteria

⊲ Return the learned parameters

reference temporally unstable classiﬁer to compute the T-stability for each feature. Then, we
select the unstable features, that are the nf of them that have the most negative δj values.
Our goal is to train a new classiﬁer that relies less on these unstable features, thus we bound
the absolute value of the correspondent weights to directly reduce their contribution in Eq. 2.
This can be formalized as the constrained optimization problem in Eq. 3, where the hinge
loss is minimized subject to a constrained on the subset of weights Wf , i.e. the nf weights
correspondent to the unstable features, that are forced to be lower than a speciﬁc bound r in
their absolute value.

n

arg min
w,b

s.t.

max(0, 1 − yif (xi; w, b)),

X
i=1
|wj | < r, ∀wj ∈ Wf .

(3)

(4)

We show in Alg. 2 the time-aware training algorithm for SVM-CB that minimize this objec-
tive through a gradient descent procedure. The algorithm is initialized by ﬁrstly identifying the
subset Wf of weights corresponding to the nf unstable features (lines 1-3). Then, for each iter-
ation, we ﬁrstly modulate the learning rate with the function s(t) to improve convergence (line
6), we update the parameters of the classiﬁer to train by applying gradient descent (lines 7-8),
to eventually clip the weights contained in Wf to the bound r if their absolute value exceed it
(line 9), as described in Eq. 4. After N iterations, the algorithm returns the learned parameters
w and b.

4 Experiments

We now apply our methodology to quantify how it explains and hardens a classiﬁer against
the performance decay compared with the time-agnostic classiﬁer Drebin [1].
Dataset. We leverage the dataset provided by Pendlebury et al. [8], composed of 116,993
legitimate and 12,735 malicious Android applications sampled from the AndroZoo dataset [15],
spanning from January 2014 to December 2016. We replicate their temporal train-test split as

5

Robust Machine Learning for Malware Detection over Time

Angioni, Demetrio, Pintor, Biggio

11000

10500

10000

9500

9000

8500

8000

7500

7000

6500

6000

5500

5000

4500

4000

3500

3000

2500

2000

1500

1000

500

0

Training  Testing

2
7
0
1

/

5
4
7
8

4
2
7

/

6
6
0
6

8
0
6

/

1
8
0
5

5
8
4

/

1
0
1
4

1
9
5

/

5
4
3
6

9
9
4

/

8
8
7
4

9
9
3

/

6
7
1
4

1
8
3

/

5
8
4
3

3
8
3

/

0
4
4
3

3
6
2

/

7
6
0
3

5
1
2

/

8
8
8
1

3
8
1

/

8
3
8
1

1
2
2

/

3
5
9
1

6
1
2

/

8
9
0
2

4
4
1

/

4
6
5
1

7
4
1

/

4
4
4
1

5
4
1

/

5
0
3
1

9
2
1

/

1
3
2
1

2
1
6

/

8
6
3
6

5
3
6

/

8
1
8
5

4
6
5

/

1
8
8
4

2
5
4

/

2
5
0
4

2
5
3

/

7
2
0
3

8
7
2

/

6
0
8
2

6
7
4

/

9
5
9
3

4
4
3

/

8
7
4
3

9
6
3

/

9
8
2
3

4
5
3

/

7
7
0
3

3
1
3

/

2
3
9
2

4
7
3

/

0
1
0
3

2
7
2

/

8
6
7
2

5
7
2

/

1
2
5
2

8
4
1

/

7
7
3
1

1
8

/

8
5
7

3
2

/

0
9
1

8

/
7
6

J
a

F

e

M

A

M

J
u

J
u

n

-

2

b

-

2

a

p

a

r
-

2

r
-

2

y

-

2

n

-

2

0

1

4

0

0

1

1

0

1

4

4

4

0

0

1

4

1

4

A

S

O

N

D

l-

2

u

e

g

-

2

p

-

2

0

c

t

-

2

o

e

v

-

2

c

-

2

J
a

F

e

M

A

M

J
u

J
u

n

-

2

b

-

2

0

a

p

a

r
-

2

r
-

2

y

-

2

n

-

2

A

S

O

N

D

l-

2

u

e

g

-

2

p

-

2

0

c

t

-

2

o

e

v

-

2

c

-

2

J
a

F

e

M

A

M

J
u

J
u

n

-

2

b

-

2

0

a

p

a

r
-

2

r
-

2

y

-

2

n

-

2

A

S

O

N

D

l-

2

u

e

g

-

2

p

-

2

0

c

t

-

2

o

e

v

-

2

c

-

2

1

0

0

4

1

1

0

1

0

0

1

1

4

4

4

4

4

1

5

0

0

0

1

1

5

5

1

5

0

1

5

0

1

5

1

0

0

5

1

1

0

1

0

0

1

1

5

5

5

5

5

1

6

0

0

0

1

1

6

6

1

6

0

1

6

0

1

6

1

0

0

6

1

1

0

1

0

0

1

1

6

6

6

6

6

Figure 2: Stack histogram with the monthly distribution of apps, spanning from Jan 2014 to
Dec 2016. The dashed vertical lines determine the considered time-aware temporal split.

shown in Fig. 2, by dividing them between December 2014 and January 2015, and we set the
time slot ∆t equal to 1 month to ensure suﬃcient statistics for each. We hence extract 465,608
from the training set to match the original formulation of Drebin [1].

Models. We consider Drebin as the baseline classiﬁer, trained with the C parameter set to 1,
and we compare it with two versions of SVM-CB by considering diﬀerent bounds on the unstable
features detected by the drift-analysis framework. We will refer to the baseline classiﬁer as SVM
since the underlying feature extractor and the feature embedding module are the same for all
the classiﬁers under analysis.

Drift Analysis Results. To identify the features responsible for the performance decay over
time in our baseline SVM, we ﬁrstly show in Fig. 3 the trend of the mean score assigned
respectively to malicious (Fig. 3a) and benign samples (Fig. 3b) over all the testing periods.
While the classiﬁer assigns, on average, an almost constant negative score to the goodware
class, the mean score assigned to malware gradually approaches to zero to eventually become
negative after 10 months, thus validating the hypothesis claimed in Sect. 3.

We compute the T-stability vector δ through Alg. 1 for the learned weights of the SVM
w.r.t. the timestamped training set, and we show the ﬁrst 104 T-stability values in increasing
order along with the corresponding features in Fig. 3c. The latter highlights that most of the
contribution to the performance decay is caused by roughly 100 features among all the feature
set, while all the remaining ones do not substantially compromise the detection rate over time
since their T-stability is very close to zero.

We report a subset of the selected unstable features (i.e. features presenting large negative
T-stability values) in Table 1. The ﬁrst 10 rows show features that the SVM associates with
the goodware class and are becoming more likely to be found in malware (wj < 0, mj > 0),
while the last 10 rows show features that the SVM associates with the malware class but they
are disappearing from data (wj > 0, mj < 0). For simplicity, we will refer to the features in
the ﬁrst and second table, respectively, as the ﬁrst and the second group of features.

We can recognize in the ﬁrst group features mostly related to commonly-used URLs. For

6

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Robust Machine Learning for Malware Detection over Time

Angioni, Demetrio, Pintor, Biggio

]
t

,
e
r
a
w
l
a
m
=
y
|
s
[
E

4
3
2
1
0
−1
−2
−3
−4

0

5

10

15
test month

20

]
t

,
e
r
a
w
d
o
o
g
=
y
|
s
[
E

4
3
2
1
0
−1
−2
−3
−4

0.000

−0.005

−0.010

−0.015

−0.020

y
t
i
l
i
b
a
t
s
-
T

0

5

10

15
test month

20

100

101

102
feature

103

104

(a)

(b)

(c)

Figure 3: The mean score over the testing periods assigned by the SVM to malware (a) and
goodware samples (b) of the test set, along with their standard deviation (colored thick lines)
and min-max range(thin grey lines). Lastly, the 104 T-stability values in increasing order,
computed through Alg. 1 (c).

instance, among them, we ﬁnd “www.google.com”, “www.youtube.com”, and websites under
the “facebook.com” domain, which are all legitimate URLs to browse, and the classiﬁer links
them to the goodware class by assigning them a positive weight. The second group is mostly
characterized by features related to intents and activities. For instance, we ﬁnd the presence
of a cipher algorithm (“interesting calls::Cipher(DES)”), reported to be used to obfuscate and
encrypt part of the malicious application.4 However, this feature has a decreasing trend (mj <
0), meaning that malware relies less on this method as time passes, probably because it would
ease the detection of the malware under manual inspection.

From this analysis, we can deduce that the unstable features can be grouped into two types
of features: (i) goodware-related features that malware creators are starting to inject in their
malicious code to increase the probability of it being recognized as goodware, and (ii) malware-
related features that malware creators are starting to deprecate to reduce the probability of it
being recognized as malware.
Improving Robustness. We now leverage the results of our drift-analysis framework per-
formed on the SVM by training SVM-CB using Alg. 2, running it for 2000 iterations, with
the initial learning rate η(0) set to 7 · 10−5 and we use the cosine annealing function as s(t)
to modulate it over the iterations. We heuristically choose the number of features to bound
nf = 102, since these are the ones the most contribute to the performance decay (Fig. 3c). We
train two versions of SVM-CB, referred as (i) SVM-CB(H) the classiﬁer with r = 0.8 and (ii)
SVM-CB(L) the classiﬁer with r = 0.2. These two diﬀerent bounds allow us to better under-
stand how the robustness against the concept drift changes when we apply softer (r = 0.8) or
harder (r = 0.2) constraints to the correspondent weights. We report the performance analysis
of these classiﬁers in Fig. 4, where we show the evolution over the testing periods of the recall
(red) and the precision (blue) for the SVM (Fig. 4a) and SVM-CB (L-H) (Fig. 4c and 4b). We
will focus mainly on the discussion of the recall curves, as our primary concern is the detection
rate of the malware samples over time, which is computed in the same way. Also, we will not
discuss the results concerning the last two months, as the number of samples is not suﬃciently
large for a proper evaluation (as highlighted by Fig. 2).

We correctly replicated the results obtained by Pendlebury et al. [8] for the SVM, which
presents the highest recall among the tested classiﬁers in the ﬁrst testing periods, starting from

4https://www.virusbulletin.com/virusbulletin/2014/07/obfuscation-android-malware-and-how-fight-back

7

Robust Machine Learning for Malware Detection over Time

Angioni, Demetrio, Pintor, Biggio

Table 1: List of 20 features taken from the set of unstable features. The ﬁrst column contains
the considered features, the second column represents their T-stability measure δj, the third
column the weight wj assigned by the SVM, and the fourth column is the estimated angular
coeﬃcient mj. The ﬁrst 10 rows show goodware-related features which are becoming more
frequent in malware as time passes, while the last 10 rows show malware-related features which
are disappearing from this class.

Feature name
urls::https://graph.facebook.com/%1$s?...&accessToken=%2$s
intents::android intent action VIEW
urls::http://www.google.com
activities::com revmob ads fullscreen FullscreenActivity
activities::com feiwo view IA
urls::http://i.ytimg.com/vi/
api calls::android/content/ContentResolver;→openInputStream
urls::https://m.facebook.com/dialog/
urls::http://market.android.com/details?id=
urls::http://www.youtube.com/embed/
api calls::android/net/wiﬁ/WiﬁManager;→getConnectionInfo
app permissions::name=’android permission MOUNT UNMOUNT FILESYSTEMS’
urls::http://e.admob.com/clk?...
activities::com feiwothree coverscreen SA
interesting calls::Cipher(DES)
intents::android intent action PACKAGE ADDED
activities::com ﬁvefeiwo coverscreen SA
intents::android intent action CREATE SHORTCUT
intents::android intent action USER PRESENT
activities::com feiwoone coverscreen SA

δj
-0.008753
-0.010168
-0.021320
-0.006204
-0.004435
-0.005245
-0.003749
-0.004955
-0.004041
-0.004289
-0.003469
-0.004508
-0.006713
-0.003564
-0.008910
-0.022435
-0.003813
-0.012456
-0.021155
-0.010022

wj
-0.596730
-0.462059
-0.436577
-0.348884
-0.347665
-0.319063
-0.302131
-0.285100
-0.260522
-0.259927
0.148022
0.296193
0.427714
0.443662
0.489497
0.702801
0.743198
0.748091
0.803000
1.141652

mj
0.014669
0.022005
0.048835
0.017782
0.012758
0.016438
0.012410
0.017379
0.015510
0.016502
-0.023438
-0.015220
-0.015695
-0.008034
-0.018202
-0.031922
-0.005131
-0.016650
-0.026344
-0.008778

76.4%, dropping fast towards a 28.8% recall at 16-th month to eventually rise to 45.3% at 21-th
month. Although the initial detection rate of SVM-CB(L) is lower than 70% it ﬂuctuates less
w.r.t. to the baseline by maintaining the performance around 50-60% with a ﬁnal drop to 35.8%
at the third to last month. SVM-CB(H) presents an initial recall of 69.4%, while it decays to
43.2% once it reaches the 22-th month. Coherently to the results obtained by Pendlebury
et al. [8], we observe that the baseline SVM is characterized by the fastest performance decay,
while the other classiﬁers start between 60% and 70% recall. The peak of temporal robustness is
reached by SVM-CB(L) where the recall curve seems to be almost ﬂattened, while SVM-CB(H)
has indeed a slower decay w.r.t. the SVM but faster than SVM-CB(L). Lastly, Fig. 4d shows the
Area Under the Receiving Operating Curve (ROC) curve for each testing period, computed up
to 5% FPR. Here we indirectly discuss the correlation between precision and recall considering
the performance when we ﬁx a constant percentage of goodware misclassiﬁed as malware for
each month in order to better measure and compare the data separation capabilities of the
three classiﬁers. The AUC curves reﬂect what we have discussed for the recall: the SVM starts
as usual with the highest AUC and decays rapidly below all the other AUC curves, while the
other classiﬁers start with a lower AUC that reveals to be higher than SVM when approaching
the 10-th month. SVM-CB(L) has been conﬁrmed to be the more stable classiﬁer even in this
constrained evaluation setting with low FPR.

5 Related Work

We now oﬀer an overview of state-of-the-art techniques similar to our proposal. Pendlebury
et al. [8] proposes Tesseract, a test-time evaluation framework to determine the faultiness of

8

Robust Machine Learning for Malware Detection over Time

Angioni, Demetrio, Pintor, Biggio

1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0

SVM

0

3

6

12 15 18 21

9
Month

1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0

Sec-SVM-CB(H)

0

3

6

12 15 18 21

9
Month

1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0

Sec-SVM-CB(L)

0

3

6

12 15 18 21

9
Month

0.95
0.90
0.85
0.80
0.75
0.70
0.65
0.60
0.55
0.50

AUC at 5.00% FPR

0

3

6

12 15 18 21

9
Month

(a)

(b)

(c)

(d)

Figure 4: The precision (orange) and recall (blue) of SVM (a), SVM-CB (H) (b) and SVM-CB
(L) (c), and the Area Under the ROC curves (AUC) at 5% (d) for the three classiﬁers over the
2-years testing periods (from Jan-2015 to Dec-2016).

classiﬁers in the presence of the concept-drift. The authors show that evaluations are aﬀected by
misleading biases that inject artifacts inside the trained machine learning model, thus causing
a performance decay once the model faces real-world data. Tesseract highlights how diﬀerent
proposed models do not cope with the concept drift of Android applications and that faulty
training settings inﬂated their original evaluations. While Tesseract is a consistent method to
include concept drift in the evaluation, it is not designed to either ﬁx or mitigate its presence.
Jordaney et al. [10], propose Transcend, a framework that signals the premature aging of
classiﬁers before their performance starts to degrade consistently by analyzing the diﬀerence
between samples observed at training at test time. On top of this methodology, Barbero et
al. [11] propose Transcendent, which improves Transcend to include the rejection of out-of-
distribution samples that cause the performance drops. However, they do not propose methods
to harden a classiﬁer against concept drift, rather they focus on protection systems exploiting
samples encountered during deployment, such as a notiﬁcation when data start diﬀering from
the training one [10], or directly rejecting a sample coming from a drifted data distribution [11].
In contrast to previous work, we consider the presence of faulty evaluations, and we extend
it with a methodology that quantiﬁes which features of the data distributions are changing and
how. Such contribution not only explains the performance decay, but also helps understanding
the reasons behind the concept drift. Instead of rejecting samples or just signaling the worsening
of the performances of a model, we build a time-aware classiﬁer that takes into account the
acquired knowledge of the data distribution changes, and we show how our methodology can
better withstand the passing of time.

6 Conclusions and Future Work

In this work, we propose a preliminary methodology that understands and provide an initial
hardening against the concept drift that plagues the performance of Android malware detection.
In particular, we develop a drift-analysis framework that highlights which features contribute
more to the performance decay of a classiﬁer over time, and we leverage these results to propose
SVM-CB, a linear classiﬁer hardened against the passing of time.

We show the eﬃcacy of our proposals by applying our drift-analysis framework to Drebin, a
linear Android malware detector, and we compare its performances over time against its hard-
ened version computed through our proposed methodology. From our experimental analysis,
we can precisely detect which features worsen the detection rate of Drebin and how the trained
SVM-CB better withstand the passing of time. In particular, we highlight the eﬃcacy of the

9

Robust Machine Learning for Malware Detection over Time

Angioni, Demetrio, Pintor, Biggio

bounding of these unstable features, reducing the performance drop of SVM-CB w.r.t.
baseline Drebin.

the

Although the obtained results are promising, this work presents the following limitations.
First, the experimental setup does not guarantee that the provided solution against performance
decay can be applied to other types of detectors, as this work addresses the problem of analyzing
the eﬀect of the concept drift only for linear classiﬁers that work only on static features [1, 16].
Also, the T-stability might not reﬂect the actual concept drift that aﬀects Android applications,
as it is computed on a classiﬁer trained on a speciﬁc dataset, which approximates the real
data distribution. Hence, we should also study the Android malware domain more to provide
suﬃcient and reliable evidence of why the features chosen by the drift-analysis framework are
actually causing the decay. Lastly, we heuristically tuned the bounds for the selected weights
of SVM-CB, but these choices could be improved with an automatic algorithm that computes
the ones that lead to better robustness against time.

However, we anyhow believe that our work can suggest a promising research direction that
will provide more insight on the usage of each contribution. We ﬁrst intend to explore more
advanced methods based on the drift-analysis framework, including an automatic bound selec-
tion for the weights inside the learning algorithm, by adopting a regularization term tailored
speciﬁcally for temporal performance stability. Secondly, we intend to generalize this method
to address deep learning algorithms, where the feature extractor and the feature representation
of the last linear layer evolve during training.

Moreover, we will explore other research directions, such as (i) the quantiﬁcation and preven-
tion of machine learning malware detectors from forgetting old threats when updated with new
data, and (ii) the inclusion of research ﬁelds such as Continual Learning, 5 which model data
as a continuous stream, thus enabling the development of techniques for updating classiﬁers
constantly and eﬀortlessly.

Acknowledgments

This work has been partly supported by the PRIN 2017 project RexLearn, funded by the Italian
Ministry of Education, University and Research (grant no. 2017TWNMH2); and by the project
TESTABLE (grant no. 101019206), under the EU’s H2020 research and innovation programme.

References

[1] Daniel Arp, Michael Spreitzenbarth, Malte Hubner, Hugo Gascon, Konrad Rieck, and CERT
Siemens. Drebin: Eﬀective and explainable detection of android malware in your pocket. In Ndss,
volume 14, pages 23–26, 2014.

[2] Enrico Mariconti, Lucky Onwuzurike, Panagiotis Andriotis, Emiliano De Cristofaro, Gordon Ross,
and Gianluca Stringhini. Mamadroid: Detecting android malware by building markov chains of
behavioral models, 2017.

[3] Kathrin Grosse, Nicolas Papernot, Praveen Manoharan, Michael Backes, and Patrick McDaniel.
In European symposium on research in computer

Adversarial examples for malware detection.
security, pages 62–79. Springer, 2017.

[4] Milad Taleby Ahvanooey, Qianmu Li, Mahdi Rabbani, and Ahmed Raza Rajput. A sur-
software vulnerabilities, malware, and attacks. arXiv preprint

vey on smartphones security:
arXiv:2001.09406, 2020.

5https://www.continualai.org/

10

Robust Machine Learning for Malware Detection over Time

Angioni, Demetrio, Pintor, Biggio

[5] Alireza Souri and Rahil Hosseini. A state-of-the-art survey of malware detection approaches using
data mining techniques. Human-centric Computing and Information Sciences, 8(1):1–22, 2018.
[6] Abdelfattah Amamra, Chamseddine Talhi, and Jean-Marc Robert. Smartphone malware detec-
tion: From a survey towards taxonomy. In 2012 7th International Conference on Malicious and
Unwanted Software, pages 79–86. IEEE, 2012.

[7] Geoﬀrey I Webb, Roy Hyde, Hong Cao, Hai Long Nguyen, and Francois Petitjean. Characterizing

concept drift. Data Mining and Knowledge Discovery, 30(4):964–994, 2016.

[8] Feargus Pendlebury, Fabio Pierazzi, Roberto Jordaney, Johannes Kinder, and Lorenzo Cavallaro.
TESSERACT: Eliminating experimental bias in malware classiﬁcation across space and time. In
28th USENIX Security Symposium (USENIX Sec. 19), pages 729–746, 2019.

[9] Anshuman Singh, Andrew Walenstein, and Arun Lakhotia. Tracking concept drift in malware
In Proceedings of the 5th ACM workshop on Security and artiﬁcial intelligence, pages

families.
81–92, 2012.

[10] Roberto Jordaney, Kumar Sharad, Santanu K Dash, Zhi Wang, Davide Papini, Ilia Nouretdinov,
and Lorenzo Cavallaro. Transcend: Detecting concept drift in malware classiﬁcation models. In
26th USENIX Security Symposium (USENIX Sec. 17), pages 625–642, 2017.

[11] Federico Barbero, Feargus Pendlebury, Fabio Pierazzi, and Lorenzo Cavallaro. Transcending
transcend: Revisiting malware classiﬁcation in the presence of concept drift. arXiv preprint
arXiv:2010.03856, 2020.

[12] Donghui Hu, Zhongjin Ma, Xiaotian Zhang, Peipei Li, Dengpan Ye, and Baohong Ling. The
concept drift problem in android malware detection and its solution. Security and Communication
Networks, 2017, 2017.

[13] Annamalai Narayanan, Liu Yang, Lihui Chen, and Liu Jinliang. Adaptive and scalable android
In 2016 International Joint Conference on Neural

malware detection through online learning.
Networks (IJCNN), pages 2484–2491. IEEE, 2016.

[14] Corinna Cortes and Vladimir Vapnik. Support-vector networks. Machine learning, 20(3):273–297,

1995.

[15] Kevin Allix, Tegawend´e F Bissyand´e, Jacques Klein, and Yves Le Traon. Androzoo: Collecting
millions of android apps for the research community. In 2016 IEEE/ACM 13th Working Conference
on Mining Software Repositories (MSR), pages 468–471. IEEE, 2016.

[16] Ambra Demontis, Marco Melis, Battista Biggio, Davide Maiorca, Daniel Arp, Konrad Rieck,
Igino Corona, Giorgio Giacinto, and Fabio Roli. Yes, machine learning can be more secure! a case
study on android malware detection. IEEE Transactions on Dependable and Secure Computing,
16(4):711–724, 2017.

11

