A Value-Function-based Interior-point Method
for Non-convex Bi-level Optimization

Risheng Liu 1 2 3 Xuan Liu 1 2 Xiaoming Yuan 4 Shangzhi Zeng 4 Jin Zhang 5 6

1
2
0
2

n
u
J

5
1

]

C
O
.
h
t
a
m

[

1
v
1
9
9
7
0
.
6
0
1
2
:
v
i
X
r
a

Abstract
Bi-level optimization model is able to capture a
wide range of complex learning tasks with prac-
tical interest. Due to the witnessed efﬁciency in
solving bi-level programs, gradient-based meth-
ods have gained popularity in the machine learn-
ing community. In this work, we propose a new
gradient-based solution scheme, namely, the Bi-
level Value-Function-based Interior-point Method
(BVFIM). Following the main idea of the log-
barrier interior-point scheme, we penalize the reg-
ularized value function of the lower level problem
into the upper level objective. By further solving a
sequence of differentiable unconstrained approx-
imation problems, we consequently derive a se-
quential programming scheme. The numerical ad-
vantage of our scheme relies on the fact that, when
gradient methods are applied to solve the approxi-
mation problem, we successfully avoid computing
any expensive Hessian-vector or Jacobian-vector
product. We prove the convergence without re-
quiring any convexity assumption on either the
upper level or the lower level objective. Experi-
ments demonstrate the efﬁciency of the proposed
BVFIM on non-convex bi-level problems.

1. Introduction

In recent years, with the rapid growth of complexity of
machine learning tasks, an increasing number of mod-
els with hierarchical structures have arisen from vari-
In these
ous ﬁelds (Dempe, 2018; Liu et al., 2021).
models, according to different hierarchies, parameters

1DUT-RU International School of Information Science and En-
gineering, Dalian University of Technology. 2Key Laboratory for
Ubiquitous Network and Service Software of Liaoning Province.
3Pazhou Lab, Guangzhou.
4Department of Mathematics, The
University of Hong Kong. 5Department of Mathematics, South-
ern University of Science and Technology. 6National Center for
Applied Mathematics Shenzhen.. Correspondence to: Jin Zhang
<zhangj9@sustech.edu.cn>.

Proceedings of the 38 th International Conference on Machine
Learning, PMLR 139, 2021. Copyright 2021 by the author(s).

are mainly divided into two types, for instance, hyper-
parameters and model parameters in hyper-parameter op-
timization (Franceschi et al., 2017; Okuno et al., 2018;
Mackay et al., 2018), network structures and weights in
neural architecture search (Liu et al., 2019a; Liang et al.,
2019; Chen et al., 2019), meta learners and base learners
in meta learning (Franceschi et al., 2018; Rajeswaran et al.,
2019; Z¨ugner & G¨unnemann, 2019), generators and dis-
criminators in adversarial learning (Pfau & Vinyals, 2016),
actors and critics in reinforcement learning (Yang et al.,
2019), different components in image processing (Liu et al.,
2019b; 2020a;b;c), etc.

Bi-Level Optimizations (BLOs) have been recognized as
important tools to capture these machine learning applica-
tions with hierarchical structures. Mathematically, BLOs
can be formulated as the following optimization problem:

min
x∈X ,y∈Rn

F (x, y), s.t. y ∈ S(x),

(1)

where S(x) := arg miny f (x, y), the UL constraint X ⊂
Rm is a compact set, and the Upper-Level (UL) objective
F : X × Rn → R and the Lower-Level (LL) objective
f : Rm × Rn → R are continuously differentiable and
jointly continuous functions. Indeed, BLOs are by nature
a class of hierarchical problem with optimization problems
in the constraints. Speciﬁcally, aiming to optimize the UL
objective F , LL variable y is selected from the optimal so-
lution set S(x) of the LL problem governed by UL variable
x. Due to the hierarchical structure and nested relation-
ship between UL and LL problems, BLOs are challenging
both theoretically and numerically, especially when the LL
solution set S(x) is not singleton (Jeroslow, 1985).

1.1. Related Work

BLOs in Eq. (1) are generalizations of several well-known
optimization problems as well-noted. Since BLOs can
model highly complicated learning tasks as aforementioned,
it is not surprising that they are hard to solve.
In early
works, the standard methods for solving BLOs are the ran-
dom search (Bergstra & Bengio, 2012) which evaluates the
learning models through randomly sampled parameter val-
ues, or the more sophisticated Bayesian optimization (Hutter
et al., 2011). Unfortunately, these gradient-free methods

 
 
 
 
 
 
A Value-Function-based Interior-point Method for Non-convex Bi-level Optimization

Table 1. Comparing the theoretical results among BVFIM and existing gradient-based methods. C 1(X × Rn) denotes the set of all
continuously differentiable functions on X × Rn.

Category

Methods

LLC LLS

EGBM

FHG/RHG

TRHG

BDA

IGBM

CG/Neumann

w/

w/

w/

w/

w/

w/

w/o

w/

IPM

BVFIM

w/o

w/o

UL
LL
UL
LL
UL
LL
UL
LL

UL
LL

Required Conditions
F (x, y) ∈ C 1(X × Rn).
f (x, y) ∈ C 1(Rm × Rn).
F (x, y) ∈ C 1(X × Rn) is bounded below.
f (x, y) ∈ C 1(Rm × Rn) is Lf -smooth and strongly convex.
F (x, y) ∈ C 1(X × Rn) is strongly convex.
f (x, y) ∈ C 1(Rm × Rn) is level-bounded in y.
F (x, y) ∈ C 1(X × Rn).
f (x, y) ∈ C 1(Rm × Rn), and ∂2f (x,y)
F (x, y) ∈ C 1(X × Rn).
f (x, y) ∈ C 1(Rm × Rn).

is invertible.

∂y2

are only capable of handling more than twenty or so hyper-
parameters. Gradient-based optimization methods, on the
other hand, can handle up to hundreds of hyper-parameters.
Speciﬁcally, the gradient-based approaches transform the
BLO into a Single-Level Optimization (SLO) problem and
solve it by using gradient-type methods. To reformulate the
BLO into an SLO problem and calculate the gradients, one
can replace the LL with a dynamics iteration and derive the
gradient by Automatic Differentiation (AD), or apply the
implicit function theorem to the optimality conditions of
the LL problem. According to such different features of
calculations, these gradient-based methods for BLOs can
be classiﬁed into two main categories: explicit and implicit.
For theoretical support, they both rely on the singleton of
LL solution set S(x) (a.k.a. LLS), which is restrictive in ap-
plications. For numerical implementation, they both require
repeated products of vectors and matrices, which are extraor-
dinarily costly in computation power. In response to these
two limitations, by reformulating the BLO into an SLO prob-
lem via value function approach (Outrata, 1990; Ye & Zhu,
1995), using the smoothing technique on value function via
regularization, and penalizing the smoothed value function
to the UL objective via the log-barrier penalty, this paper
proposes a value-function-based interior-point gradient-type
method.

Explicit Gradient-Based Methods (EGBMs). The key
idea underlying this type of approaches is to hierarchically
calculate gradients of UL and LL objectives. Speciﬁcally,
under the LLS and Lower Level Convexity (LLC), the works
in (Franceschi et al., 2017; 2018) ﬁrst calculate gradient rep-
resentations of the LL objective and then perform either
reverse or forward gradient computations (termed as Re-
verse Hyper-Gradient (RHG) and Forward Hyper-Gradient
(FHG)) for the UL sub-problem. In order to address the
LLS restriction, under the LLC, (Liu et al., 2020d) proposes
Bilevel Descent Aggregation (BDA) which characterizes an
aggregation of both the LL and the UL descent information.

However, since the EGBMs method requires calculating
AD for the entire trajectory of the dynamic iteration of
LL, the computation load is heavy to calculate the gradient
with reasonable preciseness. In order to reduce the amount
of computation, (Shaban et al., 2019) proposes Truncated
Reverse Hyper-Gradient (TRHG) to truncate the gradient
trajectory. However, the efﬁciency of TRHG is sensitive to
the truncated path length. Small truncated path length may
deteriorate the accuracy of the calculated gradient and large
truncated path length cannot reduce the computation cost.
Although (Liu et al., 2019a) uses the difference of vectors
to approximate gradient, there is no theoretical justiﬁcation
for such type of approximation.

Implicit Gradient-Based Methods (IGBMs). To reduce
the computational burden, another method is to decouple the
calculation process of the UL gradient from the dynamic sys-
tem. For this purpose, IGBMs, which people also refer to as
implicit differentiation (Pedregosa, 2016; Rajeswaran et al.,
2019; Lorraine et al., 2020), replace the LL sub-problem
with an implicit equation. Speciﬁcally, when the LL prob-
lem is strongly convex (of course in this case the LLS is
met), taking advantage of the celebrated implicit function
theorem, the gradient of the UL objective is calculated by
implicit differential equations. However, this scheme needs
to repeatedly compute the inverse of the Hessian matrix. Al-
though in practice, the Conjugate Gradient (CG) method or
Neumann method are involved for fast inverse computation,
however, repeated products of vectors and matrices are still
in the core. Therefore, it is still expensive to compute and
leads to numerical instabilities, especially when the system
is ill-conditioned. Although, (Rajeswaran et al., 2019) pro-
poses adding a large quadratic term on the LL objective to
eliminate the ill-conditionedness, this approach may change
the solution set of the BLO problem and cannot generate
solutions with desired properties.

Mathematical requirements for the mentioned methods are

A Value-Function-based Interior-point Method for Non-convex Bi-level Optimization

listed in Table 1.
Indeed, as shown in Table 1, for the
theoretical guarantee, except BDA, the LLS and LLC as-
sumptions are required by both of the two classes, which
are actually too tough to be satisﬁed in real-world complex
tasks. Recently, (Ji et al., 2020; Ji & Liang, 2021) give
a comprehensive study on the nonasymptotic convergence
properties of both implicit and explicit gradient-based meth-
ods. Speciﬁcally, in (Ji & Liang, 2021), the authors provide
lower complexity bounds for gradient-type methods and pro-
pose accelerated bi-level algorithms to achieve such optimal
complexity.

1.2. Our Contributions

In this paper, to address the issues shared by both the ex-
plicit and implicit methods, i.e., restrictive LLS and LLC
assumptions in theory and repeated Hessian- and Jacobian-
vector products in numerical calculation, we initialize a new
BLOs solution scheme called Bi-level Value-Function-based
Interior-point Method (BVFIM). Our starting point is that
the inner Simple Bi-level Optimization (SBO) sub-problem
in Eq. (3) can be approximated by more straightforward
strategies, i.e., value function approach, a smoothing tech-
nique based on regularization and the log-barrier penaliza-
tion. In particular, we begin with a reformulation of the
inner SBO sub-problem by transforming the LL problem so-
lution set constraint into an inequality constraint, using the
value function of the regularized LL problem. Motivated by
an idea behind the Interior-point Penalty Method (IPM), we
consider a log-barrier function to penalize the value function
constraint to the objective of the inner SBO sub-problem.
The log-barrier penalty together with regularization further
results in a series of SLO problems, thereby approximating
the inner SBO sub-problem. Note that thanks to the regu-
larizations, the approximation sub-problems are standard
unconstrained differentiable optimization problems, which
are therefore numerically trackable by popular gradient-type
methods. In the absence of the LLS and LLC assumptions,
we prove that BVFIM converges to a true solution of the
original BLO. Table 1 compares the convergence results
of BVFIM and the existing methods. It can be seen that,
for the LL sub-problem, assumptions required in previous
methods are essentially more restrictive than that in BV-
FIM. More importantly, when solving BLOs without LLS
and LLC, no theoretical results can be obtained for these
classical methods while BVFIM can still obtain the same
convergence properties as that in LLS and LLC scenario.
Now, we brieﬂy streamline the novelty of our approach and
contributions.

1. By penalizing the value function of the LL problem
through the log-barrier penalty, together with a regu-
larization smoothing technique, BVFIM constructs a
series of unconstrained smooth approximated SLO sub-

problems which are numerically trackable by gradient-
type optimization methods.

2. Compared with the existing gradient-based schemes,
the theoretical validity of the proposed BVFIM does
not rely on the restrictive LLS and LLC assumptions,
thereby capturing a much wider range of bi-level learn-
ing tasks.

3. The proposed BVFIM avoids the computationally ex-
pensive Hessian-vector and Jacobian-vector products
computation. Therefore, BVFIM can effectively re-
duce the numerical cost, especially when the LL prob-
lem is of large scale.

2. Gradient-based Methods for BLOs

In this section, from the optimistic bi-level viewpoint, we
offer a uniﬁed framework that contains existing implicit and
explicit gradient methods as special cases. The framework
is also used to analyze our BVFIM later on. Due to the
unities of algorithmic forms, the superiority of the proposed
BVFIM is clearly observed.

To address the LLS restriction, we regard BLOs from an
optimistic bi-level perspective. Speciﬁcally, we transform
BLOs in Eq. (1) into the following form:

min
x∈X

ϕ(x),

(2)

where ϕ(x) is the value function of the inner SBO sub-
problem, i.e.,

ϕ(x) := inf

y∈S(x)

F (x, y) with S(x) := arg min

f (x, y).

y

(3)

However, ϕ(x) is a value function of the inner SBO problem,
by nature it is very ill-conditioned, namely, non-smooth,
non-convex and usually with jumps. We next present
existing several types of approximations for the gradient
(grad. for short) of ϕ(x) in a uniﬁed manner, i.e.,

grad. of x
(cid:122) (cid:125)(cid:124) (cid:123)
∂ϕ(x)
∂x

direct grad. of x
(cid:122)
(cid:123)
(cid:125)(cid:124)
∂F (x, y)
∂x

=

indirect grad. of x
(cid:122) (cid:125)(cid:124) (cid:123)
G(x).

+

(4)

Gradient-based methods, either implicit or explicit, access
the gradient of ϕ(x) by approximation with Hessian- and
Jacobian-vector products, which results in additional the-
oretical and computational burdens. Based on the differ-
ent calculation methods for G(x), we classify the existing
gradient-based methods into EGBMs and IGBMs.

EGBMs. With an initialization point y0, a sequence
{yt(x)}T

t=0 parameterized by x is generated as

yt+1(x) = Φt(x, yt), t = 0, · · · , T − 1,

(5)

A Value-Function-based Interior-point Method for Non-convex Bi-level Optimization

where Φt(x, yt(x)) is a smooth mapping that represents
the operation performed by the t-th step of an optimiza-
tion algorithm for solving the LL problem. For exam-
ple, when the gradient descent method is considered,
Φ(x, yt(x)) = yt(x) − s ∂f
∂y (x, yt−1(x)) where s > 0
denoted the corresponding step size. Approximating ϕ(x)
by ϕT (x) := F (x, yT (x)), an approximation of ∂ϕ(x)
is
∂x
∂x + ∂F (x,yT )
given by ∂ϕT (x)
∂x . Speciﬁcally,
in this setting, the indirect gradient G(x) is specialized as:

∂x = ∂F (x,y)

∂yT (x)

∂y

G(x) =

(cid:18) ∂yT (x)
∂x

(cid:19)(cid:62) ∂F (x, yT )

∂y

,

(6)

where

∂yt(x)
∂x

=

(cid:18) ∂yt−1(x)
∂x

(cid:19)(cid:62) ∂Φ(x, yt−1)

∂y

+

∂Φ(x, yt−1)
∂x

. (7)

To ensure the quality of the estimation of G(x), EGBMs
need LLC, most of them need LLS (except BDA), and
the number of iterations T should be large enough. Note
that Eq. (7) contains Hessian- and Jacobian-vector prod-
ucts when Φ denotes the gradient descent operator. Thus
computing G(x) is time-consuming due to Eq. (7).

IGBMs. Under LLS assumption, ϕ(x) = F (x, y∗(x))
with unique y∗(x) ∈ S(x). When y∗(x) is a differen-
tiable function with respect to x, the gradient ∂ϕ(x)
can
∂x
be calculated through chain rule as ∂ϕ(x)
∂x +
∂F (x,y∗(x))
∂x , assuming that ∂2f
∂y2
∂y
is invertible, implicit function theorem is applied on the
optimality condition of the LL problem (namely, 0 =
∂f (x,y∗(x))
∂y

∂x . To obtain ∂y∗(x)
∂y∗(x)

∂x = ∂F (x,y)

), i.e.,

∂y∗(x)
∂x

= −

(cid:18) ∂2f (x, y∗(x))
∂y2

(cid:19)−1 ∂2f (x, y∗(x))

∂y∂x

.

(8)

Then G(x) is specialized as

G(x) = −

(cid:18) ∂2f (x, y∗(x))
∂y∂x

(cid:19)(cid:62) (cid:18) ∂2f (x, y∗(x))

(cid:19)−1

∂y2
∂F (x, y∗(x))
∂y

.

(9)
Note that for the sake of approximation quality, the LL
objective f must be strongly convex (or ∂2f (x,y∗(x))
is in-
vertible). In practice, the calculation of G(x) given in Eq.
(9) is based on numerical approximations. In particular, CG
or Neumann methods which involve Hessian-vector product
computations are applied. Thus, the computation of G(x)
is numerically expensive and the accuracy of the approxi-
mation heavily depends on the condition number of Hessian
or the strong convexity constant of f (Grazzi et al., 2020).

∂y2

In general, both EGBMs and IGBMs require LLC and LLS
(except BDA) for theoretical convergence. From a com-
putational point of view, the implementation of IGBMs in-
volve repeating productions of Hessian-vector and Jacobian-
vector.

3. Bi-level Value-Function-based

Interior-point Method

In this section, we propose a new algorithm that penalizes
the regularized value function of the LL problem into the
UL objective, and thus approximates the value function of
the inner SBO sub-problem ϕ(x), called Bi-level Value-
Function-based Interior-point Method (BVFIM).

Focusing on ϕ(x) which is in general non-smooth, to apply
gradient-type methods, we will design a series of differ-
entiable functions to approximate ϕ(x). Recall that ϕ(x)
denotes the value function of the following parameterized
SBO:

min
y∈Rn

F (x, y), s.t. y ∈ arg min

y

f (x, y).

(10)

We can equivalently reformulate Eq. (10) into an SLO prob-
lem by using the value function of its LL problem, i.e.,
f ∗(x) = miny f (x, y). As a consequence, instead of
Eq. (10), we study the following parameterized SLO:

F (x, y), s.t. f (x, y) ≤ f ∗(x).

(11)

min
y∈Rn

However, the inequality constraint f (x, y) ≤ f ∗(x) is ill-
posed, in the sense that f ∗(x) is non-smooth and the con-
straint does not satisfy any standard regularity condition. To
circumvent such difﬁculty, inspired by (Borges et al., 2020),
we relax such constraint by replacing f ∗(x) with the value
function of the regularized LL problem, i.e.,

f ∗
µ(x) = min
y∈Rn

f (x, y) +

µ1
2

(cid:107)y(cid:107)2 + µ2,

(12)

where µ = (µ1, µ2), and µ1, µ2 are two positive constants.
µ1
2 (cid:107)y(cid:107)2 is introduced for guaranteeing the smoothness of
f ∗
µ(x) and µ2 is for ensuring the feasibility of the relaxed
inequality constraint f (x, y) < f ∗
µ(x). In the following, f ∗
µ
is shown to be differentiable under mild conditions. Now,
penalizing the relax inequality constraint f (x, y) ≤ f ∗
µ(x)
to the objective by the log-barrier penalty gives us the fol-
lowing smooth approximation of ϕ(x):

ϕµ,θ,τ (x) = min
y∈Rn

F (x, y) +

θ
2

(cid:107)y(cid:107)2 − τ ln(f ∗

µ(x) − f (x, y)),

(13)
where (µ, θ, τ ) > 0. The additional regularized term
θ
2 (cid:107)y(cid:107)2 is for ensuring the smoothness of ϕµ,θ,τ (x). It will
be shown in the next section that ϕµ,θ,τ (x) → ϕ(x) as
(µ, θ, τ ) → 0 and τ ln µ2 → 0. Now, we show the differen-
tiability of ϕµ,θ,τ (x) and give the formula of its gradient.

A Value-Function-based Interior-point Method for Non-convex Bi-level Optimization

Proposition 1. Suppose F (x, y) and f (x, y) are continu-
ously differentiable. Given x ∈ X and µ, θ, τ > 0, when

zTz
k,l represents the output returned from Tz-step gradient
descent in Eq. (18).

y∗

µ,θ,τ (x)

= argmin

y∈Rn

F (x, y) +

θ
2

and

Following Eqs. (16) and (17), we eventually obtain ∂ϕk(xl)
by

∂x

(cid:107)y(cid:107)2 − τ ln(f ∗

µ(x) − f (x, y)),

(14)

with

∂ϕk(xl)
∂x

≈

∂F (xl, yTy
k,l)
∂x

+ Gk,l,

(20)

z∗
µ(x) = argmin
y∈Rn

f (x, y) +

µ1
2

(cid:107)y(cid:107)2 + µ2,

(15)

are unique, then ϕµ,θ,τ is differentiable and

∂ϕµ,θ,τ
∂x

(x) =

∂F (x, y∗
µ,θ,τ (x))
∂x

+ G(x),

(16)

where

τ

G(x) =

(cid:16) ∂f (x,y∗
µ,θ,τ (x))
∂x

−
µ(x) − f (x, y∗
f ∗

∂f (x,z∗
∂x

µ(x))

µ,θ,τ (x))

(cid:17)

,

(17)

and f ∗

µ(x) = f (x, z∗

µ(x)) + µ1

2 (cid:107)z∗

µ(x)(cid:107)2 + µ2.

The decreasing proximity from Eq. (13) to the original
BLOs leans at the core of our convergence theory, as the
regularization sequence {(µk, θk, τk)} is tending to zero. In
particular, the solutions returned by solving approximate
sub-problems minx∈X ϕk(x), where ϕk denotes ϕµk,θk,τk ,
converge to the true solution of BLOs, as {(µk, θk, τk)}
vanishes with τk ln µk,2 → 0; see Theorem 1 in Section 4.
Naturally, to execute this computing process, we need to cal-
culate the gradient ∂ϕk
∂x , thereby solving each approximate
sub-problem efﬁciently.
We next illustrate the calculation of ∂ϕk
∂x at xl as a guide for
implementation. Indeed, for a user-friendly purpose, this
procedure is divided into three steps, according to Proposi-
tion 1. First, we calculate z∗
(xl) by solving the regularized
µk
LL problem Eq. (12), which can be easily done by gradient
descent as

k,l = zt−1
zt

k,l − s1

(cid:32) ∂f (xl, zt−1
k,l )
∂y

(cid:33)

+ µk,1zt−1
k,l

,

(18)

where s1 > 0 is an appropriately chosen step size. To
calculate y∗
(xl) returned by solving Eq. (13), the
gradient descent scheme reads as

µk,θk,τk

k,l = yt−1
yt
k,l

(cid:32) ∂F (xl, yt−1
k,l )
∂y

− s2

+ θkyt−1

k,l +

∂f (xl,yt−1
k,l )
∂y

τk
f Tz
k,l − f (xl, yt−1
k,l )

(cid:33)
,

where s2 > 0 is an appropriately chosen step size.
particular, f Tz

k,l = f (xl, zTz

k,l) + µk,1

2 (cid:107)zTz

(19)
In
k,l(cid:107)2 + µk,2 , where

(cid:18) ∂f (xl,y
∂x

Ty
k,l )

τk

−

∂f (xl,zTz
k,l)
∂x

(cid:19)

Gk,l =

k,l − f (xl, yTy
f Tz
k,l)

,

(21)

where yTy
dient descent in Eq. (19), and zTz
step.

k,l represnts the output returned from Ty-step gra-
k,l, f Tz
k,l are stored in the last

Algorithm 1 Our Solution Strategy for Eq. (13)
Require: (µk, θk, τk), step size α, s1, s2 > 0
1: for l = 0 → L do
2:

(xl) by Tz-step gradient descent in

3:

4:

µk,θk,τk

Calculate z∗
µk
Eq. (18).
Calculate y∗
in Eq. (19).
Calculate an approximation of ∂ϕk(xl)
denoted by gl.
xl+1 = xl − αgl.

∂x

5:
6: end for

(xl) by Ty-step gradient descent

by Eq. (20),

The algorithm to solve approximate sub-problems Eq. (13)
is outlined in Algorithm 1. Then, as {(µk, θk, τk)} vanishes,
the solution of Algorithm 1 converges to the true solution
of Eq. (10).

4. Theoretical Investigations

In this section, we will give the convergence analysis the
proposed method. Please notice that all the proofs of our
theoretical results are stated in the Supplemental Material.

We ﬁrst recall an equivalent deﬁnition of epiconvergence
given in (Bonnans & Shapiro, 2013)[page 41].

Deﬁnition 1. ϕk
two conditions hold:

e−→ ϕ iff for all x ∈ Rm the following

1. For any sequence {xk} converging to x,

lim inf
k→∞

ϕk(xk) ≥ ϕ(x).

(22)

2. There is a sequence {xk} converging to x such that

lim sup
k→∞

ϕk(xk) ≤ ϕ(x).

(23)

A Value-Function-based Interior-point Method for Non-convex Bi-level Optimization

For a given function f (x, y), we state the property that it
is level-bounded in y locally uniformly in x ∈ X in the
following deﬁnition.
Deﬁnition 2. Given a function f (x, y) : Rm × Rn → R. If
for a point ¯x ∈ X ⊆ Rm, for any c ∈ R, there exists δ > 0
along with a bounded set B ∈ Rm, such that

{y ∈ Rn|f (x, y) ≤ c} ⊆ B, ∀x ∈ Bδ(¯x) ∩ X ,

(24)

then we call f (x, y) is level-bounded in y locally uniformly
in ¯x ∈ X . If the above property holds for each ¯x ∈ X , we
further call f (x, y) is level-bounded in y locally uniformly
in x ∈ X .

We will give the convergence result of the proposed algo-
rithm under the following standing assumptions:
Assumption 1. We take the following as our blanket as-
sumption

1. S(x) is nonempty for x ∈ X .
2. Both F (x, y) and f (x, y) are jointly continuous and

continuously differentiable.

3. Either F (x, y) or f (x, y) is level-bounded in y locally

uniformly in x ∈ X .

To prove the convergence result, we show that ϕk(x) +
e−→ ϕ(x) + δX (x), where δX (x) denotes the in-
δX (x)
dicator function of set X , i.e., δX (x) = 0 if x ∈ X and
δX (x) = +∞ if x /∈ X . To do this, we need to verify two
conditions given in Deﬁnition 1.

First, to show the condition 1 in Deﬁnition 1, we introduce
the value function ψµ(x) of the relaxed problem of Eq. (11):

ψµ(x) = min
y∈Rn

F (x, y), s.t. − 1 ≤ f (x, y) − f ∗

µ(x) ≤ 0.
(25)

And we propose the following two lemmas.
Lemma 1. Let {µk} be a positive sequence such that µk →
0. Then for any sequence {xk} converging to ¯x,

lim sup
k→∞

f ∗
µk

(xk) ≤ f ∗(¯x).

Lemma 2. Given x ∈ X , suppose either F (x, y) or
f (x, y) is level-bounded in y locally uniformly in x. Let
{µk} be a positive sequence such that µk → 0, and then for
any sequence {xk} converging to x,

lim inf
k→∞

ψµk (xk) ≥ ϕ(x).

(26)

Next, we verify condition 2 in Deﬁnition 1.
Lemma 3. Let {(µk, θk, τk)} be a positive sequence such
that (µk, θk, τk) → 0 and τk ln µk,2 → 0. Then for any
x ∈ X ,

lim sup
k→∞

ϕk(x) ≤ ϕ(x).

Now, by combining the results obtained above, we can
obtain the desired epiconvergence result.

Proposition 2. Suppose either F (x, y) or f (x, y) is level-
bounded in y locally uniformly in x ∈ X . Let {(µk, θk, τk)}
be a positive sequence such that (µk, θk, τk) → 0 and
τk ln µk,2 → 0, and then

ϕk(x) + δX (x)

e−→ ϕ(x) + δX (x).

(27)

In summary, we can get the following convergence result:

Theorem 1. Suppose either F (x, y) or f (x, y) is level-
bounded in y locally uniformly in x ∈ X . Let {(µk, θk, τk)}
be a positive sequence such that (µk, θk, τk) → 0 and
τk ln µk,2 → 0. Then

1. We have the following inequality

(cid:18)

(cid:19)

lim sup
k→∞

inf
x∈X

ϕk(x)

≤ inf
x∈X

ϕ(x).

(28)

2. If x(cid:96) ∈ argminx∈X ϕ(cid:96)(x), for some sequence {(cid:96)} ⊂ N
and x(cid:96) converges to ˜x, then ˜x ∈ argminx∈X ϕ(x) and

(cid:18)

(cid:19)

lim
(cid:96)→∞

inf
x∈X

ϕ(cid:96)(x)

= inf
x∈X

ϕ(x).

(29)

5. Complexity Analysis

∂y2 q and Jacobian-vector product ∂2f

In this part, we compare the time and space complexity
of Algorithms 1 in computing the direction for updating
variable x with EGBMs (i.e.,FHG and RHG) and IGBMs
(i.e.,CG and Neumann). Our complexity analysis is based
on the basic step. We suppose the gradients of F , f , Hessian-
vector product ∂2f
∂x∂y q
can be evaluated in time c = c(m, n) for any vector q ∈ Rn.
For all existing methods, we assume the optimal solution of
the LL problem is calculated by a T -step gradient descent,
and the transition function in FHG and RHG, also the Φ in
Eq. (5), is gradient descent. In practice, it has been shown
in (Rajeswaran et al., 2019) that the time and space cost
for computing ∂2f
∂x∂y q via AD is no more than a
(universal) constant (e.g., usually 2-5 times) order over the
cost for computing gradient of F and f .

∂y2 q and ∂2f

EGBMs. As discussed in (Franceschi et al., 2017; Sha-
ban et al., 2019), FHG for forward calculation of Hessian-
matrix product can be evaluated in time O(cmT ) and space
O(mn), and RHG for reverse calculation of Hessian- and
Jacobian-vector products can be evaluated in time O(cT )
and space O(m + nT ). The time complexity for EGBMs
to calculate the UL gradient is proportional to the number
of iterations T of the LL problem, and thus EGBMs take a
large amount of time to ensure convergence.

A Value-Function-based Interior-point Method for Non-convex Bi-level Optimization

Table 2. Complexity analysis of various bi-level methods on unconstrained problems in calculating ∂ϕ(x)
∂x . We show the key update steps.
p ∈ Rn and q ∈ Rm are intermediate variables and Z ∈ Rm×n is intermediate matrix. I is the identity matrix. FHG and RHG calculate
Eq. (6) by forward or reverse AD. CG calculates Hessian inverse by solving linear equation, while Neumann approximates Hessian
inverse by calculating the limit of the sequence. Please see (Franceschi et al., 2017; Pedregosa, 2016; Lorraine et al., 2020) for more
calculation details. Note that our method avoid calculating the Hessian- and Jacobian-vector products.

Method

FHG

RHG

CG

Neumann

BVFIM

G(x)

Z(cid:62)
T

∂F (x,yT )
∂y

with Zt = ∂2f

∂y2 Zt−1 + ∂2f

q−1 with qt−1 = qt +
(cid:16) ∂2f (x,yT )
∂y∂x
(cid:17)(cid:62)

−
(cid:16) ∂2f (x,yT )
∂y∂x

−

pt, pt−1 =

∂y∂x
(cid:16) ∂2f
∂y2

(cid:17)(cid:62)

(cid:16) ∂2f
∂x∂y
(cid:17)(cid:62)

q with ∂2f

∂y2 q = ∂F

∂y

q ∂F

∂y with q = (cid:80)J

j=0

(cid:16)

I − ∂2f
∂y2

(cid:17)j

τk
f Tz
k,l −f (xl,y

Ty
k,l )

(cid:18) ∂f (xl,y

Ty
k,l )

∂x

∂f (xl,zTz
k,l)
∂x

−

(cid:19)

Time

Space

O(cmT )

O(mn)

(cid:17)(cid:62)

pt

O(cT )

O(m + nT )

O(c(T + J))

O(m + n)

O(c(T + J))

O(m + n)

O(c(Tz + Ty))

O(m + n)

IGBMs. After implementing a T -step gradient descent for
the LL problem, IGBMs approximate matrix inverse by
solving J steps of a linear system. As each step contains a
Hessian-vector product, this part required O(cJ) time and
O(m + n) space. So IGBMs run in time O(c(T + J)) and
space O(m + n). The iteration number J always relies on
the properties of the Hessian-matrix, and thus in some cases,
J can be much larger than T .

∂x and ∂F

BVFIM. In our algorithm, Tz steps of gradient descent
in Eq. (18) for the LL problem solution zTz requires time
O(cTz) and space O(n). Then Ty gradient descent steps
in Eq. (19) are used calculate yTy , which requires time
O(cTy) and space O(n). Lastly, the direction can be ob-
tained according to the formula given in Eq. (20) by sev-
eral computations of the gradient ∂f
∂x without any
intermediate update, which requires time O(c) and space
O(m + n), so BVFIM runs in time O(c(Tz + Ty)) and
space O(m + n), respectively. Note that although BVFIM
has similar complexity to existing methods, it does not need
any computation of Hessian- or Jacobian-vector products
and all the complexity comes from calculating the gradients
of F and f . And because calculating the gradient is much
faster than calculating Hessian- and Jacobian-vector prod-
ucts (even by AD) when the dimension of LL variable is
large, the proposed BVFIM is more efﬁcient than existing
methods when the LL problem is high-dimensional, for ex-
ample, in applications with a large-scale network. We will
illustrate this advantage in the next section.

6. Experimental Results

In this section, we present numerical simulations with the
proposed methods and demonstrate application in hyper-
parameter optimization for non-convex LL problems.

6.1. Toy Examples

In this section, our goal is to use a simple numerical sample
to verify the superiority of BVFIM over existing methods in
the case of non-convex LL problems. We use the following
numerical examples 1

min
x∈R,y∈R

(cid:107)x − a(cid:107)2 + (cid:107)y − a(cid:107)2, s.t. y ∈ argmin

y∈R

sin(x + y),

(30)
where a is an adjustable parameter which will be set as a =
0 and 2 in following experiments. By simple calculation,
we know that the optimal solution of Eq. (30) is x∗
a=0 =
y∗
a=0 = π2/8 and x∗
a=0 = −π/4, F ∗
a=2 = 3π/4,
F ∗
a=3 = 3π2/16 − 9π/2 + 9. This example satisﬁes all the
assumptions of BVFIM, but not LLS and LLC assumptions
in (Pedregosa, 2016; Rajeswaran et al., 2019; Lorraine et al.,
2020), which makes it be a good example to validate the
advantages of BVFIM.

a=2 = y∗

In Figure 1, we show the comparison of BVFIM with the ex-
plicit method RHG and the implicit method CG for solving
different bi-level optimization problems at different initial
points. It can be observed that RHG and CG converge to the
optimal point only when the initial point is near the optimal
point, but different initial points only slightly affect the con-
vergence of BVFIM. From the second column in Figure 1,
we can see that the effectiveness of the BVFIM method
in solving non-convex problems comes at the expense of
slowing down the convergence rate of the LL problem f .

To further illustrate the differences between the BVFIM
methods and existing methods on the LL problem, we
plot the convergence behavior of the LL iteration (i.e.,
||yt(x0) − y∗|| and ||yt(x500) − S(x500)||) with given UL

1Since variables are one-dimensional real numbers in numerical
experiments, we do not use bold letters which represent vectors.

A Value-Function-based Interior-point Method for Non-convex Bi-level Optimization

Figure 1. Comparison of the existing explicit method (RHG) and implicit method (CG) with BVFIM on different metrics and different
initial points. We set a = 0 in the ﬁrst row and a = 2 in the second row. The solid line represents (x0, y0) = (0, 0), and the dotted line
represents (x0, y0) = (3, 3). The legend is only plotted in the ﬁrst subﬁgure of the second line.

Figure 4. Comparison of convergence rates under different L set-
tings. We set a = 0 and (x0, y0) = (3, 3). The iterations are the
number of gradient descents of x, which is K × L.

variable x in Figure 2. Note that x0 and x500 refer to the
x at the 0th and 500th iteration of the UL problem, respec-
tively. From the ﬁrst row in Figure 2, it can be observed
that RHG and CG converge quickly to the solution set of
the LL problem, while BVFIM does not because yt(x) in
BVFIM is solving problem Eq. (13). However, the second
row of Figure 2 shows that BVFIM can converge to the
global optimal solution while RHG and CG cannot.

Figure 3 shows the convergence behavior of BVFIM with
different regularization parameter settings. It can be seen
that by setting the regularization parameter to 0, our method
degenerates to optimize UL and LL problems separately
without regard to their relevance, thus it is difﬁcult to obtain
an appropriate feasible solution. Choosing a ﬁxed nonzero
regularization parameter can improve convergence on y and
achieve the same convergence behavior on x as adaptive
(µ, θ, τ ) at the early stage. However, due to the inﬂuence of
the regular term, it does not converge to the optimal solution
on x. When the regularization term takes a decreasing value,
the best results are obtained.

Figure 4 shows the effect of different iteration number L

Figure 2. LL iterative curves with explicit and implicit methods
(RHG and CG) in x0 and x500. S(x) is the solution set of the LL
problem with given x, and y∗ is the global optimal solution. We
set a = 0 and (x0, y0) = (3, 3).

Figure 3. Convergence curves under different (µk, θk, τk) settings.
The legend is only plotted in the second subﬁgure. We set a = 0
and (x0, y0) = (3, 3). The adaptive (µ, θ, τ ) means to follow the
default setting which can be found in Supplementary Materials.

0100200300400500Iterations510150100200300400500Iterations0.511.50100200300400500Iterations12340100200300400500Iterations123450100200300400500Iterations510150100200300400500Iterations0.511.50100200300400500Iterations120100200300400500Iterations120510152025Iterations23450510152025Iterations123450510152025Iterations24680510152025Iterations10100200300400500Iterations0.511.522.50100200300400500Iterations0.511.520100200300400500Iterations0.511.522.50100200300400500Iterations0.20.40.60.8A Value-Function-based Interior-point Method for Non-convex Bi-level Optimization

Table 3. Comparison of the results of existing methods for solving data hyper-cleaning tasks on MNIST, FashionMNIST and CIFAR10.
The F1 score denotes the harmonic mean of the precision and recall.

Method

RHG
TRHG
CG
Neumann
BDA
BVFIM

Acc.

87.90
88.57
89.19
87.54
87.15
90.41

MNIST
F1 score

Time(s)

Acc.

FashionMNIST
F1 score

Time(s)

89.36
89.77
85.96
89.58
90.38
91.19

0.4131
0.2623
0.1799
0.1723
0.6694
0.1480

81.91
81.85
83.15
81.37
79.97
84.31

87.12
86.76
85.13
87.28
88.24
88.35

0.4589
0.2840
0.2041
0.1958
0.8571
0.1612

Acc.

34.95
35.42
34.16
33.45
36.41
38.19

CIFAR10
F1 score

68.27
68.06
69.10
68.87
67.33
69.55

Time/s

1.3374
0.8409
0.4796
0.4694
1.4869
0.4092

on convergence behavior. We can ﬁnd that smaller L can
accelerate the convergence of variable x, while larger L can
improve the convergence of variable y. These preliminary
results indicate that in situations where optimal solution x∗
is needed, BVFIM with small L (e.g. L = 1) is a better
choice.

6.2. Hyper-parameter Optimization

In this section, we use a special case of hyper-parameter
optimization, called data hyper-cleaning, to evaluate the
performance of our method when the LL problem is non-
convex. Assuming that some of the labels in our datasets are
contaminated, the goal of data hyper-cleaning is to reduce
the impact of incorrect samples by adding hyper-parameters
to the contaminated samples.
In the experiment, we set y ∈ R10×301 × R300×d as the
parameters of 2-layer linear network classiﬁer where d is
the data dimension and x ∈ R|Dtr| as the weight of each
sample in the training set. Therefore, the LL problem is to
learn a classiﬁer y on cross-entropy training loss weighted
with given x

f (x, y) =

(cid:88)

σ(xi)CE(y, ui, vi),

(31)

(ui,vi)∈Dtr

where (ui, vi) are the training examples, σ(x) denotes the
sigmoid function on x to constrain the weights in the range
[0, 1] and CE is the cross entropy loss. The UL problem is
to ﬁnd a weight x which can reduce the cross-entropy loss
of y on a cleanly labeled validation set

F (x, y) =

(cid:88)

CE(y, ui, vi).

(32)

Figure 5. F (x, y) and F1 score between existing methods and
BVFIM. The curves are based on the FashionMNIST experiment
in Table 3. The legend is only plotted in the ﬁrst subﬁgure.

be seen that BVFIM achieves the most competitive results
on all three datasets. Furthermore, BVFIM is faster than
EGBMs and IGBMs, and this advantage is more evident
in CIFAR10 datasets with larger LL parameters, consistent
with the complexity analysis given above. The UL objective
and F1 scores of BVFIM and compared methods on the
FashionMNIST dataset are plotted in Figure 5.

7. Conclusions

In this paper, we present a new bi-level optimization algo-
rithm BVFIM. By penalizing the regularized LL problem
into the UL problem, we approximate the BLO problem by
a series of unconstrained smooth SLO sub-problems. We
prove the convergence without requiring any convexity as-
sumption on either the UL or the LL objectives. Extensive
evaluations show the superiority of BVFIM for different
applications.

(ui,vi)∈Dval

Acknowledgements

Our experiment is based on MNIST, FashionMNIST (Xiao
et al., 2017) and CIFAR10 datasets. For each dataset, we
randomly select 5000 samples as the training set Dtr, 5000
samples as the validation set Dval, and 10000 samples as
the test set Dtest. Then, we contaminated half of the labels
in Dtr.

Table 3 shows the results and calculation time of the com-
pared methods and BVFIM on three different datasets. It can

This work is partially supported by the National Natural
Science Foundation of China (Nos. 61922019, 61733002
and 11971220), LiaoNing Revitalization Talents Program
(No. XLYC1807088), the Fundamental Research Funds for
the Central Universities, Shenzhen Science and Technology
Program (No. RCYX20200714114700072), and Guang-
dong Basic and Applied Basic Research Foundation (No.
2019A1515011152).

0100200300400500Iterations0.60.811.20100200300400500Iterations808590A Value-Function-based Interior-point Method for Non-convex Bi-level Optimization

References

Bergstra, J. and Bengio, Y. Random search for hyper-

parameter optimization. JMLR, 2012.

Bonnans, J. F. and Shapiro, A. Perturbation analysis of
optimization problems. Springer Science & Business
Media, 2013.

Borges, P., Sagastiz´abal, C., and Solodov, M. A regular-
ized smoothing method for fully parameterized convex
problems with applications to convex and nonconvex two-
stage stochastic programming. Mathematical Program-
ming, 2020.

Chen, X., Xie, L., Wu, J., and Tian, Q. Progressive dif-
ferentiable architecture search: Bridging the depth gap
between search and evaluation. In ICCV, 2019.

Dempe, S. Bilevel optimization: theory, algorithms and
applications. TU Bergakademie Freiberg, Fakult¨at f¨ur
Mathematik und Informatik, 2018.

Deng, J., Dong, W., Socher, R., Li, L., Li, K., and Li, F.
Imagenet: A large-scale hierarchical image database. In
CVPR, 2009.

Franceschi, L., Donini, M., Frasconi, P., and Pontil, M.
Forward and reverse gradient-based hyperparameter opti-
mization. In ICML, 2017.

Franceschi, L., Frasconi, P., Salzo, S., Grazzi, R., and Pontil,
M. Bilevel programming for hyperparameter optimization
and meta-learning. In ICML, 2018.

Grazzi, R., Franceschi, L., Pontil, M., and Salzo, S. On the
iteration complexity of hypergradient computation. In
ICML, 2020.

Grefenstette, E., Amos, B., Yarats, D., Htut, P. M.,
Molchanov, A., Meier, F., Kiela, D., Cho, K., and Chin-
tala, S. Generalized inner loop meta-learning. arXiv
preprint arXiv:1910.01727, 2019.

Hutter, F., Hoos, H. H., and Leyton-Brown, K. Sequential
model-based optimization for general algorithm conﬁg-
In International conference on learning and
uration.
intelligent optimization, 2011.

Jeroslow, R. G. The polynomial hierarchy and a simple
model for competitive analysis. Mathematical program-
ming, 1985.

Ji, K. and Liang, Y. Lower bounds and accelerated
arXiv preprint

algorithms for bilevel optimization.
arXiv:2102.03926v2, 2021.

Lake, B. M., Salakhutdinov, R., and Tenenbaum, J. B.
Human-level concept learning through probabilistic pro-
gram induction. Science, 2015.

Liang, H., Zhang, S., Sun, J., He, X., Huang, W., Zhuang,
Improved differentiable ar-
K., and Li, Z. Darts+:
chitecture search with early stopping. arXiv preprint
arXiv:1909.06035, 2019.

Liu, H., Simonyan, K., and Yang, Y. DARTS: differentiable

architecture search. In ICLR, 2019a.

Liu, R., Cheng, S., He, Y., Fan, X., Lin, Z., and Luo, Z. On
the convergence of learning-based iterative methods for
nonconvex inverse problems. IEEE TPAMI, 2019b.

Liu, R., Li, Z., Zhang, Y., Fan, X., and Luo, Z. Bi-level
probabilistic feature learning for deformable image regis-
tration. In IJCAI, 2020a.

Liu, R., Liu, J., Jiang, Z., Fan, X., and Luo, Z. A bilevel
integrated model with data-driven layer ensemble for
multi-modality image fusion. IEEE TIP, 2020b.

Liu, R., Mu, P., Chen, J., Fan, X., and Luo, Z.

Investi-
gating task-driven latent feasibility for nonconvex image
modeling. IEEE TIP, 2020c.

Liu, R., Mu, P., Yuan, X., Zeng, S., and Zhang, J. A generic
ﬁrst-order algorithmic framework for bi-level program-
ming beyond lower-level singleton. In ICML, 2020d.

Liu, R., Gao, J., Zhang, J., Meng, D., and Lin, Z. Investigat-
ing bi-level optimization for learning and vision from a
uniﬁed perspective: A survey and beyond. arXiv preprint
arXiv:2101.11517, 2021.

Lorraine, J., Vicol, P., and Duvenaud, D. Optimizing mil-
lions of hyperparameters by implicit differentiation. In
AISTATS, 2020.

Mackay, M., Vicol, P., Lorraine, J., Duvenaud, D., and
Grosse, R. Self-tuning networks: Bilevel optimization of
hyperparameters using structured best-response functions.
In ICLR, 2018.

Okuno, T., Takeda, A., and Kawana, A. Hyperparame-
ter learning via bilevel nonsmooth optimization. arXiv
preprint arXiv:1806.01520, 2018.

Outrata, J. V. On the numerical solution of a class of stackel-
berg problems. ZOR-Methods and Models of Operations
Research, 1990.

Pedregosa, F. Hyperparameter optimization with approxi-

mate gradient. In ICML, 2016.

Ji, K., Yang, J., and Liang, Y. Bilevel optimization:
Nonasymptotic analysis and faster algorithms. arXiv
preprint arXiv:2010.07962v2, 2020.

Pfau, D. and Vinyals, O. Connecting generative adversar-
ial networks and actor-critic methods. arXiv preprint
arXiv:1610.01945, 2016.

A Value-Function-based Interior-point Method for Non-convex Bi-level Optimization

Rajeswaran, A., Finn, C., Kakade, S. M., and Levine, S.
Meta-learning with implicit gradients. In NeurIPS, 2019.

Shaban, A., Cheng, C., Hatch, N., and Boots, B. Truncated
back-propagation for bilevel optimization. In AISTATS,
2019.

Vinyals, O., Blundell, C., Lillicrap, T., Kavukcuoglu, K.,
and Wierstra, D. Matching networks for one shot learning.
In NeurIPS, 2016.

Xiao, H., Rasul, K., and Vollgraf, R. Fashion-mnist: a
novel image dataset for benchmarking machine learning
algorithms. arXiv preprint arXiv:1708.07747, 2017.

Yang, Z., Chen, Y., Hong, M., and Wang, Z. Provably global
convergence of actor-critic: A case for linear quadratic
regulator with ergodic cost. In NeurIPS, 2019.

Ye, J. J. and Zhu, D. L. Optimality conditions for bilevel

programming problems. Optimization, 1995.

Z¨ugner, D. and G¨unnemann, S. Adversarial attacks on graph

neural networks via meta learning. In ICLR, 2019.

Appendix

This supplementary material is organized as follows. In
Section A and Section B, we present the detailed proof of
Section 3 and subsection 4, respectively. Section C presents
the further details of the experiments in Section 6. Section
D presents some additional results.

A. Proof of Section 3

A.1. Proof of Proposition 1
Proof. Since argminy∈Rn f (x, y) + µ1
2 (cid:107)y(cid:107)2 + µ2 is a sin-
gleton, it follows from (Bonnans & Shapiro, 2013)[Theorem
4.13, Remark 4.14] that

∂f ∗
µ(x)
∂x

=

=

∂ (cid:0)f (x, y) + µ1
∂x

2 (cid:107)y(cid:107)2 + µ2

(cid:1)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)y=z∗

µ(x)

(33)

µ(x))

∂f (x, z∗
∂x

.

2 (cid:107)y(cid:107)2 − τ ln (cid:0)f ∗
∂x

µ(x) − f (x, y)(cid:1)(cid:1)

(cid:16) ∂f (x,y∗
µ,θ,τ (x))
−
∂x
µ(x) − f (x, y∗
f ∗
(cid:16) ∂f (x,y∗
µ,θ,τ (x))
∂x

−
µ(x) − f (x, y∗
f ∗

µ,θ,τ (x)

|y=y∗
(cid:17)

∂f ∗
µ (x)
∂x

µ,θ,τ (x))
∂f (x,z∗
∂x

µ(x))

µ,θ,τ (x))

(cid:17)

.

(34)

Remark 4.14] shows that

∂ϕµ,θ,τ (x)
∂x

=
∂ (cid:0)F (x, y) + θ

=

=

∂F (x, y∗
µ,θ,τ (x))
∂x

∂F (x, y∗
µ,θ,τ (x))
∂x

τ

τ

+

+

B. Proof of Section 4

B.1. Proof of Lemma 1

Proof. For any (cid:15) > 0, there exists ¯y ∈ Rn such that
f (¯x, ¯y) ≤ f ∗(¯x) + (cid:15). And as µk → 0, we can ﬁnd k1 > 0
such that

f (¯x, ¯y) +

µk,1
2

(cid:107)¯y(cid:107)2 + µk,2 ≤ f ∗(x) + 2(cid:15)

(35)

for all k ≥ k1. Next, as {xk} converging to ¯x, it follows
from the continuity of f (x, y) that there exists k2 ≥ k1
such that f (xk, ¯y) ≤ f (¯x, ¯y) + (cid:15) for any k ≥ k2 and thus

f ∗
µk

(xk) ≤ f (xk, ¯y) +

µk,1
2

(cid:107)¯y(cid:107)2 + µk,2 ≤ f ∗(x) + 3(cid:15)
(36)

for all k ≥ k2. By letting k → ∞, we obtain

lim sup
k→∞

f ∗
µk

(xk) ≤ f ∗(¯x) + 3(cid:15),

(37)

and taking (cid:15) → 0 in the above inequality yields the conclu-
sion.

B.2. Proof of Lemma 2

Proof. We assume to arrive a contradiction that there exists
¯x ∈ Rm satisfying xk → ¯x as k → ∞ with following
inequality

lim inf
k→∞

ψµk (xk) < ϕ(¯x).

Then, there exist (cid:15) > 0 and sequences xk → ¯x and {yk}
satisfying

−1 ≤ f (xk, yk) − f ∗
µk
F (xk, yk) ≤ ψµk (xk) + (cid:15) < ϕ(¯x) − (cid:15).

(xk) ≤ 0

(38)

(39)

Then it follows from Lemma 1 that

lim sup
k→∞

f (xk, yk) ≤ lim sup
k→∞

f ∗
µk

(xk) ≤ f ∗(¯x).

(40)

µ(x) − f (x, y)(cid:1)
As argminy∈Rn F (x, y)+ θ
is a singleton, (Bonnans & Shapiro, 2013)[Theorem 4.13,

2 (cid:107)y(cid:107)2−τ ln (cid:0)f ∗

Since either F (x, y) or f (x, y) is level-bounded in y lo-
cally uniformly in ¯x, we have that {yk} is bounded. Take a

A Value-Function-based Interior-point Method for Non-convex Bi-level Optimization

subsequence {yt} of {yk} such that yt → ˆy. Then, it fol-
lows from Eq. (38), Eq. (40) and the continuity of f (x, y)
that

f (¯x, ˆy) ≤ lim sup

t→∞

f (xt, yt) ≤ f ∗(¯x),

(41)

We have lim inf k→∞ ϕk(xk) + δX (xk) = +∞ when ¯x /∈
X , as X is closed. And thus condition 1 in Deﬁnition 2 is
satisﬁed. Next, for any x ∈ Rm, if x ∈ X , then it follows
from Lemma 3 that

and thus

ˆy ∈ S(¯x).

(42)

Then, Eq. (39) yields that

ϕ(¯x) ≤ F (¯x, ˆy) ≤ lim sup

k→∞

F (xk, yk) ≤ ϕ(¯x) − (cid:15),

lim sup
k→∞

ϕk(x) + δX (x) ≤ ϕ(x) + δX (x).

(48)

When x /∈ X , we have ϕ(x) + δX (x) = +∞. Thus con-
dition 2 in Deﬁnition 1 is satisﬁed. Therefore, we get the
conclusion immediately from Deﬁnition 1.

which implies a contradiction. Thus we get the conclusion.

B.5. Proof of Theorem 1

B.3. Proof of Lemma 3

Proof. Given any x ∈ X , for any (cid:15) > 0, there exists ¯y ∈
Rn satisfying f (x, ¯y) ≤ f ∗(x) and F (x, ¯y) ≤ ϕ(x) + (cid:15).
As f ∗(x) + µk,2 ≤ f ∗
(x), and by the deﬁnition of ϕk, we
µk
have

ϕk(x) ≤ F (x, ¯y) +

≤ ϕ(x) + (cid:15) +

θk
(cid:107)¯y(cid:107)2 − τk ln (cid:0)f ∗
µk
2
θk
2

(cid:107)¯y(cid:107)2 − τk ln µk,2.

(x) − f (x, ¯y)(cid:1)

(43)

By taking k → ∞ in above inequality, as θk → 0 and
τk ln µk,2 → 0, we have

lim sup
k→∞

ϕk(x) ≤ ϕ(x) + (cid:15).

(44)

Then, we get the conclusion by letting (cid:15) → 0.

B.4. Proof of Proposition 2

Proof. To prove the epiconvergence of ϕk to ϕ, we just
need to verify that sequence {ϕk} satisﬁes the two condi-
tions given in Deﬁnition 1. Considering any sequence {xk}
converging to ¯x, since

θk
2

F (x, y) ≤ F (x, y)+

(cid:107)y(cid:107)2 −τk ln (cid:0)f ∗
µk

(x) − f (x, y)(cid:1) ,
(45)
for any (x, y) ∈ Rm × Rn satisfying −1 ≤ f (x, y) −
f ∗
µ(x) < 0, then we have

ψµk (xk) ≤ ϕk(xk),

∀k.

(46)

By taking k → ∞ in above inequality, we obtain from
Lemma 2 that when ¯x ∈ X ,

ϕ(¯x) + δX (¯x) = ϕ(¯x)

≤ lim inf
k→∞
≤ lim inf
k→∞
≤ lim inf
k→∞

ψµk (xk)

ϕk(xk)

ϕk(xk) + δX (xk).

(47)

Proof. According to Proposition 2, we know that

ϕk(x) + δX (x) e−→ ϕ(x) + δX (x).

(49)

Then the conclusion follows from (Bonnans & Shapiro,
2013)[Proposition 4.6].

C. Details of Experiments

We use PyTorch 1.6 as our computational framework and
base our implementation on (Grefenstette et al., 2019;
Grazzi et al., 2020). In all the experiments, we use the
Adam method for accelerating the gradient descent of x.
We conducted these experiments on a PC with Intel Core
i7-9700F CPU, 32GB RAM and an NVIDIA RTX 2060S
8GB GPU.

C.1. Toy Examples

In numerical experiment, we set T = 100 for ex-
plicit method RHG, T = 100, J = 20 for implicit
method CG, and µ2 = f (x, y) + 1, (µk,1, θk, τk) =
(1.0, 1.0, 1.0)/1.01k, step sizes s1, s2 and α all equal to
0.01, Tz = 50, Ty = 25, and L = 1 in BVFIM.

C.2. Hyperparameter Optimization

In hyperparameter optimization, we set T = 100 for ex-
plicit method RHG, TRHG and BDA, T = 100, J = 20
for implicit method CG and Neumann, and µ2 = f (x, y),
(µk,1, θk, τk) = (1.0, 1.0, 1.0)/1.01k, step sizes s1, s2 and
α all equal to 0.01, Tz = 50, Ty = 25, and L = 1 for BV-
FIM. We let TRHG truncate at T /2 and αk = 0.5 × 0.999k
in BDA.

We set the training set, validation set, and test set as class bal-
anced. For each contaminated training sample, we randomly
replace its label with a label different from the original one
with equal probability. In the calculation of F1 score, if
xi ≤ 0, we marks the sample ui as contaminated. In the
CIFAR10 experiment, we used an early stop strategy to
avoid over-ﬁtting and report the best results achieved. Since
Ty gradient descent require ∂F
∂y separately, we set

∂y and ∂f

A Value-Function-based Interior-point Method for Non-convex Bi-level Optimization

Figure 6. Convergence results for different regularization coefﬁ-
cients in different initialization settings.

Figure 8. Comparison of calculation time of IGBMs and BVFIM
under different LL parameter quantities.

D.2. Hyperparameter Optimization

The UL objective and F1 scores of BVFIM and compared
methods on the MNIST and CIFAR10 dataset are plotted in
Figure 7.

In addition, we verify the computation time variation of
BVFIM and existing gradient-based methods under differ-
ent LL variable dimensions on the FashionMNIST and CI-
FAR10 dataset. In order to show the comparison results
more clearly, we compared with IGBMs which are faster
in the existing gradient-based methods. Figure 8 shows the
computation time with different LL variable parameter quan-
tities. It can be seen that BVFIM is faster than IGBMs at
different parameter quantities, and this advantage becomes
more signiﬁcant as the number of LL parameters increases.

D.3. Additional LLC Experiments

To verify the validity of the BVFIM method in conventional
LLC problems, we supplemented a meta-learning experi-
ment. The goal of meta-learning is to learn an algorithm
that can handle new tasks well. In particular, we consider
the few-shot learning problem, where each task is a N-way
classiﬁcation and it aim to learn the hyperparameter x so
that each task can be solved by only M training samples.
(i.e. N-way M-shot)

Similar to recent work (Franceschi et al., 2018; Liu et al.,
2020d), we modeled the network in two parts: a four-layer
convolution network x as a common feature extraction layer
between different tasks, and logical regression layer y = yi
as separate classiﬁer for each task. We also set dataset as
D = {Di}, where Di = Di
tr∪Di
val is for the i-th task. Then
we set the loss function of the j-th task to CE(x, yi; Di
tr)
for the LL problem, thus the LL objective can be deﬁned as

f (x, y) =

(cid:88)

i

CE(x, yi; Di

tr)

As for the UL objective, we also utilize cross-entropy func-
tion but deﬁne it based on {Di

val} as

F (x, y) =

(cid:88)

i

CE(x, yi; Di

val)

Figure 7. F (x, y) and F1 score between existing methods and
BVFIM. The curves are based on the MNIST and CIFAR10 exper-
iment. The legend is only plotted in the second subﬁgure.

Tz + 2 × Ty = T to fairly compare the time consumed by
the algorithm.

D. Additional Results

D.1. Toy Examples

We can see that our method has a weaker convergence in LL
problem than the existing method under proper initialization
(i.e., the initial point is within a locally convex neighbor-
hood of the global optimal point). This is because the main
purpose of our experiment is to compare the convergence
behavior between different methods and scenarios, so we
have not carefully adjusted the regularization coefﬁcients of
our methods in order to better show the differences. To ver-
ify that our method can also converge as well as the existing
methods under proper initialization, we show how to obtain
better convergence performance by adjusting τ in Figure 6.
It can be seen that an appropriate τ can greatly improve the
convergence behavior. In addition, we validate this with a
larger LLC problem in the section D.3.

10-210010200.511.5210-210010200.511.520100200300400500Iterations0.40.60.810100200300400500Iterations75808590050100Iterations1.922.12.22.3050100Iterations4050600.811.2LL Parameters1060.40.50.60.7123LL Parameters1050.150.20.25A Value-Function-based Interior-point Method for Non-convex Bi-level Optimization

Table 4. The averaged few-shot classiﬁcation accuracy on Om-
niglot and MiniImageNet (M=1)

Method

Omniglot

5-way

20-way

MiniImagenet
5-way

98.60
RHG
98.74
TRHG
99.04
BDA
BVFIM 98.85

95.50
95.82
96.50
95.55

48.89
47.67
49.08
49.28

Our experiment was performed on two widely used bench-
mark datasets: Omniglot (Lake et al., 2015), which contains
examples of 1623 different handwritten characters from 50
alphabets and MiniImagenet (Vinyals et al., 2016), which
is a subset of ImageNet (Deng et al., 2009) that contains
60000 downsampled images from 100 different classes. We
compared our BVFIM to several approaches, such as RHG,
TRHG and BDA (Liu et al., 2020d).

For RHG, TRHG and BDA, we follow the settings in (Liu
et al., 2020d). For BVFIM, we set Tz = 5, Ty = 10,
µ2 = f (x, y), (µk,1, θk, τk) = (1, 0.1, 10)/k, step sizes
(s1, s2, α) = (0.01, 0.01, 0.001), L = 1 and K = 50000.
We set meta-batch size of 16 episodes for Omniglot dataset
and of 4 episodes for Miniimagenet dataset. We set y0
k,l =
zTz
k,l to warm up.
It can be seen in Table 4 that BVFIM can get slightly poorer
performance than existing methods on Omniglot dataset and
get the best performance on MiniimageNet dataset, which
proves that our method can also obtain competitive results
for LLC problems.

