Learning Large Logic Programs By Going Beyond Entailment

Andrew Cropper1 and Sebastijan Dumanˇci´c2
1University of Oxford
2KU Leuven
andrew.cropper@cs.ox.ac.uk, sebastijan.dumancic@cs.kuleuven.be

0
2
0
2

r
p
A
2
2

]
I

A
.
s
c
[

2
v
5
5
8
9
0
.
4
0
0
2
:
v
i
X
r
a

Abstract

A major challenge in inductive logic program-
ming (ILP) is learning large programs. We ar-
gue that a key limitation of existing systems is
that they use entailment to guide the hypothe-
sis search. This approach is limited because en-
tailment is a binary decision: a hypothesis ei-
ther entails an example or does not, and there is
no intermediate position. To address this limita-
tion, we go beyond entailment and use example-
dependent loss functions to guide the search,
where a hypothesis can partially cover an exam-
ple. We implement our idea in Brute, a new
ILP system which uses best-ﬁrst search, guided
by an example-dependent loss function, to incre-
mentally build programs. Our experiments on
three diverse program synthesis domains (robot
planning, string transformations, and ASCII art),
show that Brute can substantially outperform ex-
isting ILP systems, both in terms of predictive ac-
curacies and learning times, and can learn pro-
grams 20 times larger than state-of-the-art sys-
tems.

1 Introduction
A major challenge in inductive logic programming (ILP) is
learning large programs [Cropper et al., 2019a]. We argue
that a key limitation of existing systems is that they use en-
tailment to guide the hypothesis search [Muggleton, 1995;
Srinivasan, 2001;
Blockeel and De Raedt, 1998;
Law et al., 2014; Cropper and Muggleton, 2016].
This
approach is limited because entailment is a binary decision:
a hypothesis either entails an example or does not, and
there is no intermediate position.
To illustrate this limitation,

imagine learning image
transformation programs from input/output examples. Fig-
ure 1 shows a scenario where the goal is to learn a program
to transform the corner squares from red to white. Suppose
that an entailment-guided ILP system is evaluating two hy-
potheses h1 and h2 which generate the outputs o1 and o2
respectively shown in Figure 2. Although o1 is clearly closer
to the example output than o2 (because only 1 pixel needs
to change compared to 7 in o2), the ILP system would deem

the two hypotheses equal because neither entails the exam-
ple, and would thus have no reason to prefer h1 to h2 during
the search.

Example input

Example output

Figure 1: Image transformation example.

Output o1

Output o2

Figure 2: Outputs o1 and o2 from hypotheses h1 and h2 respec-
tively.

To address this limitation, we take inspiration from how
humans write programs. To paraphrase Ellis et al. (2019),
writing code is often a process of trial and error: write code,
execute it, evaluate the output, and revise the code if nec-
essary. Our approach allows an ILP system to perform simi-
larly: build a program, execute it on example input to gen-
erate output, compare the output with the expected output,
and revise the program if necessary.

To allow an ILP system to evaluate a program (i.e.
to
compare the generated output with the expected output),
we give it domain-speciﬁc knowledge. Speciﬁcally, we use
example-dependent loss functions: loss functions that con-
sider information about the examples, other than whether
they are entailed. For instance, in the image transforma-
tion problem, we could use Hamming distance to measure
how close an output is to the desired one (how many pixels
differ), which would allow an ILP system to prefer h1 to h2.
We claim that our approach can improve learning perfor-
mance, especially when the target hypothesis is large. To
support this claim, we make the following contributions:

• We describe Brute, a new ILP system (Section 3) which
combines techniques from search (best-ﬁrst search)
and answer set programming (ASP) [Lifschitz, 2008]

 
 
 
 
 
 
to learn programs with recursion and predicate inven-
tion [Muggleton et al., 2015].

• We evaluate Brute on three diverse program synthesis
domains: robot planning, real-world string transfor-
mations, and a new problem of drawing ASCII art (Sec-
tion 4). Our experiments show that Brute can substan-
tially outperform existing ILP systems both in terms
of predictive accuracies and learning times, and can
learn programs 20 times larger than state-of-the-art
systems.

2 Related Work

The goal of program synthesis
to automatically
generate computer programs from input/output exam-
The topic is considered the holy grail of AI
ples.
[Gulwani et al., 2017; Singh and Kohli, 2017].

is

For

times

training

typically need lots of

Neural approaches
and large

training
[Balog et al., 2017;
data
Devlin et al., 2017; Ellis et al., 2018].
instance,
REPL [Ellis et al., 2019] combines an interpreter with
AlphaGo [Silver et al., 2017] approach to learn programs.
However, REPL takes multiple days to train on a single
domain using one P100 GPU. By contrast, Brute can learn
programs in under 60 seconds using a standard single-core
computer. Another disadvantage of neural approaches is
that they often require hand-crafted neural architectures
for each domain. For instance, REPL needs a hand-crafted
interpreter, and neural architecture for each
grammar,
By contrast, Brute uses logic programming
domain.
as a uniform representation for examples, background
knowledge, hypotheses, and for itself (i.e. Brute is written
in Prolog), so can be applied to arbitrary domains.

ILP

such

Classical

systems,
Progol

as
FOIL
[Muggleton, 1995],
[Quinlan, 1990],
and
Aleph
TILDE
[Srinivasan, 2001],
learn recur-
sive programs and so often struggle on synthesis problems.
By contrast, Brute can learn recursive programs, so can
learn programs that generalise to arbitrary sized inputs.

[Blockeel and De Raedt, 1998],
cannot

(in general)

Most

ILP systems use entailment-based loss

func-
tions (also called cost or scoring functions) to guide
the hypothesis search, often in combination with the
[Quinlan, 1990; Muggleton, 1995;
size
hypothesis
Blockeel and De Raedt, 1998;
Srinivasan, 2001;
Cropper and Muggleton, 2016;
Law et al., 2014;
Kaminski et al., 2018].
For instance, Aleph’s default
loss function is p − n, where p and n are the number
of positive (p) and negative (n) examples entailed by a
clause. However, as our introductory image transforma-
tion example shows, entailment-based loss functions can
be uninformative because entailment is a binary decision.
Metaopt [Cropper and Muggleton, 2019] and FastLAS
[Law et al., 2020] both use domain-speciﬁc loss functions to
ﬁnd optimal hypotheses, such as the most efﬁcient program
[Cropper and Muggleton, 2019]. Brute also uses domain-
speciﬁc loss functions (speciﬁcally example-dependent),
not to learn optimal programs, but to instead search efﬁ-
ciently.

Most authors measure the size of a logic program
literals [Law et al., 2014] or
as either the number of
clauses [Cropper et al., 2019b] in it. What deﬁnes a
large program is unclear. Given n examples, ILP sys-
tems can learn programs with n clauses by simply mem-
orising the examples.
ILP systems can also learn clauses
with many literals when the variable depth is small
[Muggleton, 1995]. In contrast to most ILP systems, which
focus on concept learning (i.e.
classiﬁcation), Brute fo-
cuses on learning recursive programs that compute some-
thing, i.e. program synthesis [Flener and Yilmaz, 1999].
In this area, Metagol [Cropper and Muggleton, 2016] is
a state-of-the-art system, yet struggles to learn programs
with more than 8 clauses (or approximately 24 literals)
[Cropper et al., 2019a]. Our experiments show that Brute
can learn programs 20 times larger than Metagol, whilst
still maintaining the ability to generalise.
in
ILASP

and
∂ ILP
search.
[Evans and Grefenstette, 2018] also work in two stages.
Both precompute a set of clauses and then ﬁnd a subset
of the clauses, where ILASP uses ASP and ∂ ILP uses a
neural network. Brute also ﬁnds a subset of clauses, but
additionally ﬁnds how to compose the clauses to build
new clauses.

two
[Law et al., 2014]

Brute works

invent
and

stages:

3 Brute
Brute is a new ILP system which we intentionally designed
to be simple to clearly demonstrate our idea. Given:

• positive (e+) and negative (e−) examples formed of
sets of dyadic atoms p(xi , yi) where p is the target
predicate symbol and xi and yi are terms denoting in-
put and output values respectively

• background knowledge bk described as a deﬁnite

logic program

• an example-dependent loss function L : C × C → R
where C is the constant signature of e+ ∪ e− ∪ bk
Brute searches for a hypothesis (a deﬁnite logic program)
h such that ∀e ∈ e+, h ∪ bk |= e and ∀e ∈ e−, h ∪ bk 6|= e.

Brute works in two stages: invent and search. In the in-
vent stage, Brute invents library predicates, which it later
In the search stage, Brute
uses to build a hypothesis.
searches to ﬁnd which library predicates to add to a hypoth-
esis and in which sequence to execute them. Algorithm 1
sketches the Brute algorithm1. We describe the two stages
in detail.

3.1 Invent
Brute takes as input background knowledge which deﬁnes
primitive predicates.
In the invent stage, Brute uses the
primitive predicates to invent library predicates. A library
predicate is set of deﬁnite clauses deﬁned by the same
predicate symbol, similar to a predicate in a Prolog library,
e.g. max_list/2. We call the set of library predicates the
library.

1Brute is implemented in Prolog.

queue = empty_priority_queue()
initial_spec = {(x, y) | p(x, y) ∈ e+}
initial_hypothesis = []
initial_state = ( initial_spec , initial_hypothesis )
initial_loss =
(x, y)∈ini tial_spec L (x, y)
queue.push( initial_loss , initial_state )

Algorithm 1 Brute

P

1 def brute(e+,e−,bk,L ):
library = invent(bk)
2
prog = search(e+,e−,bk,L ,library)
3
return prog
4
5
6 def search(e+,e−,bk,L ,library):
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27

loss , state = queue.pop()
(spec,hypothesis) = state

while not queue.empty():

return []

for library_predicate in library :

new_spec = apply(library_predicate,bk,spec)
new_hypothesis = hypothesis + library_predicate
new_loss =
(x, y)∈new_spec L (x, y)
new_state = (new_spec,new_hypothesis)
P
q.push(new_loss,new_state)

if loss == 0 and consistent(hypothesis,e−,bk):
return hypothesis + induce_target(hypothesis)

To invent library predicates, Brute uses an ASP encod-
ing to generate programs that compose the primitive pred-
icates, and assigns each program a unique new predi-
cate symbol. Because the set of such programs is inﬁ-
nite, Brute follows common convention [Srinivasan, 2001;
Law et al., 2014; Cropper and Muggleton, 2016] and re-
stricts the maximum number of (1) clauses, (2) distinct
variables in a clause, and (3) body literals in a clause.

right/2,
Example 1. Given the primitive predicates
draw_black/2, draw_white/2, at_end/1 and suitable restric-
tions on the number of clauses, distinct variables, and body
literals, Brute would invent the predicate:

f1(A,B) ← at_end(A), draw_white(A,B)

Brute would also invent recursive predicates, such as:

f2(A,B) ← at_end(A), draw_black(A,B)
f2(A,B) ← draw_white(A,C), right(C,D), f2(D,B)

Brute uses ASP constraints to eliminate pointless pred-
icates. These constraints are important because they im-
prove efﬁciency in the search stage by reducing the branch-
ing factor of the search tree. Due to space restrictions we
cannot detail these constraints but instead give a few exam-
ples.

Example 2. Given the same input as in Example 1, Brute
does not invent the following predicate (due to pruning
constraints) because the literal at_start(C) is not connected
to the rest of the clause.

f3(A,B) ← at_start(B), at_start(C)

Brute does not invent the following predicate because the
variable A is in the head but not in the body (a Datalog-like
constraint):

f4(A,B) ← at_start(B)

Brute does not invent the following predicate because it has
a recursive clause without a base clause:

f5(A,B) ← right(A,C), f5(C,B)

3.2 Search

In the search stage, Brute tries to build a hypothesis using
the library predicates. To do so, Brute performs a best-ﬁrst
search [Russell and Norvig, 2010] guided by a given loss
function.

A speciﬁcation is a set of (x, y) pairs denoting input
(x) and output ( y) values. Given n positive examples
{p(x1, y1), . . . , p(xn, yn)}, the initial speciﬁcation (line 8) is
{(x1, y1), . . . , (xn, yn)}. The initial hypothesis is an empty
list, denoted as [] (line 9). A state is a 〈 speciﬁcation, hy-
pothesis 〉 pair. The initial state (line 10) is a pair of the
initial speciﬁcation and the initial hypothesis. The initial
loss is the sum of the losses of the initial speciﬁcation (line
11). Brute adds the initial loss and the initial state to a pri-
ority queue (line 12) and then performs a best-ﬁrst search.

Example 3. Suppose we have the positive examples f(1,4)
and f(7,10), the loss function L (x, y) = |x − y|, and four
library predicates:

f1(A,B) ← succ(A,B)
f2(A,B) ← double(A,B)
f3(A,B) ← double(A,C),double(C,B)
f4(A,B) ← succ(A,C),succ(C,B)

The initial speciﬁcation s is {(1, 4), (7, 10)}, the initial state
is 〈s, []〉 and the initial loss is |1 − 4| + |7 − 10| = 6. Because
the loss is not zero, Brute searches for a better state.

To search for a better state, Brute applies each library
predicate to every pair in the current speciﬁcation to gen-
erate a new speciﬁcation (line 22). For instance, applying
the library predicate f1(A,B) ← succ(A,B) to the speciﬁca-
tion pair (1, 4) means to call f1(1,B) to deduce a value for
B (i.e. 2) to form the new speciﬁcation pair (2, 4). For-
mally2:

Deﬁnition 1 (Application). Given background knowledge
bk, a library l, a library predicate p/2, and a speciﬁcation
pair (x, y), an application forms a new speciﬁcation pair
(z, y) where z is the computed answer for B in an SLD-
refutation of bk ∪ l ∪ {← p(x, B)}.

Example 4. Applying the library predicate f4(A,B) ←
succ(A,C),succ(C,B) to the speciﬁcation {(1, 4), (7, 10)} gen-
erates the new speciﬁcation {(3, 4), (9, 10)} from the com-
puted answers of the SLD-refutations of bk ∪ l ∪ {←
f 4(1, B1)} and bk ∪ l ∪ {← f 4(7, B2)} respectively.

2We assume reader familiarity with logic programming espe-
cially the concepts of an answer substitution and a computed an-
swer [Lloyd, 2012].

After generating a new speciﬁcation, Brute adds the li-
brary predicate to the hypothesis (line 23), calculates the
loss of the new speciﬁcation (line 24), and adds the new
state with the new loss to the priority queue (line 25).
Example 5. Continuing our running example, the state
is 〈{(1, 4), (7, 10)}, []〉 and the loss is |1 − 4| + |7 − 10| =
Brute can apply the library predicate f4(A,B) ←
6.
succ(A,C),succ(C,B) to generate the new state:

〈{(3, 4), (9, 10)}, [f4(A,B) ← succ(A,C), succ(C,B)]〉

The loss of this new state is |3 − 4| + |9 − 10| = 2, so Brute
again searches for a better state.

The search continues until either (1) there are no more
states to consider, or (2) the loss at the current state is
0 and the hypothesis does not entail any negative exam-
ples (line 18). When the search ﬁnishes, Brute induces a
target-clause from the sequence of used library predicates
and adds it to the hypothesis, which it returns (line 19).
A target clause deﬁnes the target predicate p and is of the
form p(S1, Sm+1) ← p1(S1, S2), p2(S2, S3), . . . , pm(Sm, Sm+1)
where each pi is the ith clause in the hypothesis and each
Si is a variable.
Example 6. To ﬁnish our running example, our state is:

〈{(3, 4), (9, 10)}, [f4(A,B) ← succ(A,C), succ(C,B)]〉

And our loss is |3 − 4| + |9 − 10| = 2. Brute can apply the
predicate f1(A,B) ← succ(A,B) to generate the new state:

〈{(4, 4), (10, 10)}, [(f4(A,B) ← succ(A,C), succ(C,B)),

(f1(A,B) ← succ(A,B))] 〉

The loss is now 0, so the search stops. Brute then induces
a target clause from the sequence of library predicates and
adds it to the hypothesis to form:

f(A,B) ← f4(A,C), f1(C,B)
f4(A,B) ← succ(A,C), succ(C,B)
f1(A,B) ← succ(A,B)

4 Experiments
We claim that example-dependent loss functions can im-
prove improve learning performance. Our experiments
therefore aim to answer the question:

Q1 Can example-dependent

loss functions outperform

entailment-based loss functions?

To answer Q1, we compare Brute against Brute|=, a variant
which mimics an entailment-based approach using the loss
function:

L (x, y) =

0
1

(cid:26)

if x = y
otherwise

In other words, if the output from the hypothesis exactly
matches the desired output then there is no loss; otherwise
the loss is 1.

We also claim that Brute can outperform existing ILP sys-
tems, especially when the target hypothesis is large, be-
cause it uses example-dependent loss functions to guide the
search. Our experiments therefore aim to answer the ques-
tion:

Q2 Can Brute outperform state-of-the-art ILP systems?

To answer Q2, we compare Brute against Metagol, a state-
of-the-art ILP system, which can learn recursive programs.
To answer questions Q1 and Q2, we consider three di-
verse domains: robot planning, string transformations, and
drawing ASCII art.

Experimental Settings
In each experiment, we enforce a learning timeout of 60
seconds per task. We repeat each experiment 10 times and
plot 95% conﬁdence intervals. We use only positive train-
ing examples. We describe below the system settings used
in the experiments.

Brute We restrict Brute to only invent library predicates
with at most two clauses, where each clause has at most
three variables and at most two body literals.

uses

Metagol Metagol
metarules
[Muggleton et al., 2015],
higher-order Horn clauses,
to guide the proof search. We provide Metagol with
the ident, precon, postcon, chain, and tailrec metarules,
which are commonly used in the Metagol literature. We
also force Metagol to learn functional
logic programs
[Lin et al., 2014], which ensures that for any induced
program and for any input value there is exactly one
output value. This constraint helps Metagol when learning
from only positive examples because otherwise it tends to
learn overly general recursive programs.

4.1 Experiment 1 - Robot Planning
Our ﬁrst experiment is on learning robot plans, a do-
main often used to evaluate Metagol [Cropper, 2019;
Cropper and Muggleton, 2019].

Materials
A robot and a ball are in a n2 grid. An example is an atom
f (x, y), where f
is the target predicate and x and y are
initial and ﬁnal states respectively. A state describes the
positions of the robot and the ball, and whether the robot
is holding the ball. The task is to learn to transform the
initial state to the ﬁnal state. We provide as background
knowledge the dyadic predicates up, down, right, left, grab,
drop, and the monadic predicates at_top, at_bottom, at_left,
at_right. Brute uses a Manhattan distance loss function.

Method
For each n in {2, 4, 6, .., 10}, we generate a single training
example for a n2 world, i.e. this is a one-shot learning task.
As the grid size grows, so should the size of the target hy-
pothesis. We measure the percentage of tasks solved (i.e.
where an induced hypothesis entails all the positive and no
negative examples) and learning times.

Results
Figure 3 shows that for a 22 grid, all three systems solve
100% of the tasks. However, as the grid size grows, the
performance of Metagol quickly degrades. For a 62 grid,
Metagol only solves 8% of the tasks. By contrast, for a 102
grid, Brute solves 67% of the tasks. Figure 3 also shows that
Brute learns programs substantially quicker than Metagol.

Figure 3 shows that Brute outperforms Brute|= for a 62 grid
or bigger, both in terms of learning times and percentage
of tasks solved. These results suggest that the answers to
Q1 and Q2 are both yes.

Metagol struggles on larger grids because it must learn
larger programs. The biggest program learned by Metagol
has 5 clauses and 15 literals. By contrast, the biggest pro-
gram learned by Brute has 18 clauses and 69 literals. Brute
starts to struggle on larger grids because of local optima.
For instance, suppose that the robot starts at position 1/1,
the ball at position 3/1, and the goal is to move the ball
to position 1/3. In this scenario, Brute ﬁrst tries to ﬁnd a
program to move the robot to position 1/3 to minimise the
loss function (Manhattan distance). Brute then explores
the space around 1/3, before eventually ﬁnding the ball at
position 3/1, at which point it quickly ﬁnds the target hy-
pothesis. Despite occasional local optima, Brute substan-
tially outperforms both Brute|= and Metagol.

Brute
Brute|=
Metagol

100

)

%

(

d
e
v
l
o
s

s
k
s
a
T

80

60

40

20

Brute
Brute|=
Metagol

0

2

4

6

8

10

Grid size

60

40

20

)
s
d
n
o
c
e
s
(

e
m

i
t

i

g
n
n
r
a
e
L

0

2

is_number, at_start, at_end. The predicates right, at_start,
and at_end all manipulate the cursor. The rest manipulate
the string. Brute uses a Levenshtein distance loss function.

Method
For each task and for each n in {1, 3, 5, 7, 9}, we sample uni-
formly without replacement n examples as training exam-
ples and use the other 10 − n examples as testing examples.
We measure predictive accuracies and learning times.

Results
Figure 5 shows that Brute|= slightly outperforms Brute in
all cases, which contradicts the results from Experiment
1. Figure 5 also shows that Brute signiﬁcantly outperforms
Metagol in all cases, which again suggests that the answer
to Q2 is yes.

100

)

%

(

y
c
a
r
u
c
c
a

e
v
i
t
c
i
d
e
r
P

80

60

40

20

0

1

40

35

30

25

20

15

)
s
d
n
o
c
e
s
(

e
m

i
t

i

g
n
n
r
a
e
L

Brute
Brute|=
Metagol

Brute
Brute|=
Metagol

3

5

7

9

1

3

5

7

9

No. examples

No. examples

4

6

8

10

Grid size

(a) Predictive accuracy

(b) Mean learning time

Figure 5: String experimental results.

(a) Percentage of tasks solved

(b) Mean learning time

Figure 3: Robot experimental results.

4.2 Experiment 2 - String Transformations
Our second experiment
is on real-world string trans-
formations, a domain often used to evaluate program
[Lin et al., 2014; Balog et al., 2017;
synthesis
Ellis et al., 2019].

systems

tasks

transformation

Materials
string
from
We
130
use
[Cropper, 2019].
Each task has 10 examples. An ex-
ample is an atom f (x, y) where f is the task name and x
and y are input and output states respectively. A state is a
(s, p) pair, where s is the string and p is a cursor pointing
to a speciﬁc position in the string. Figure 4 shows a task
with three examples, where the goal is to extract the ﬁrst
three letters of the month and make them uppercase.

Input
Output
JUL
22 July,1983 (35 years old)
OCT
30 October,1955 (63 years old)
2 November,1954 (64 years old) NOV

Figure 4: Example string transformation task.

We provide as background knowledge the dyadic
predicates drop, right, mk_uppercase, mk_lowercase, and
is_space,
the monadic predicates is_letter,

is_uppercase,

Brute sometimes performs worse than Brute|= because
of local optima. For instance, when trying to learn a pro-
gram that takes a string and returns the ﬁrst letter made
uppercase, e.g. “james” 7→ “J”, Brute ﬁrst uses an invented
recursive predicate to delete all but the last character from
the input to minimise the loss (edit distance), e.g. “james”
7→ “s” (where the loss is only 1). Brute then searches in this
region of the search space, but is unable to ﬁnd the target
hypothesis in the allocated time (60 seconds).

Brute typically outperforms Brute|= and Metagol on tasks
that require larger programs. For instance, consider trying
to learn a program to extract the number of logical infer-
ences per second (Lips) from the output of time/1 in Prolog,
e.g. “16,079 inferences, 0.003 CPU in 0.003 seconds (95%
CPU, 5842660 Lips)” 7→ “5842660”. For this task, Brute
learns the general program shown in Figure 6, which con-
tains four invented recursive predicates. Figure 7 shows
the execution trace of this program on the aforementioned
example.

4.3 Experiment 3 - ASCII Art
Our third experiment is on a new problem of learning to
draw ASCII art.

Materials
An image is the pixel representation of an ASCII string ac-
cording to the text2art3 library with the font 3x5. Figure 8
shows an example image for the string “IJCAI”. An example

3https://pypi.org/project/text2art/

f(A,B):-f0(A,C),f1(C,D),f0(D,E),
f2(E,F),f3(F,G),f2(G,B).

f0(A,B):-is_uppercase(A),drop(A,B).
f0(A,B):-drop(A,C),f0(C,B).
f1(A,B):-is_number(A),drop(A,B).
f1(A,B):-drop(A,C),f1(C,B).
f2(A,B):-is_space(A),drop(A,B).
f2(A,B):-drop(A,C),f2(C,B).
f3(A,B):-at_end(A),drop(A,B).
f3(A,B):-right(A,C),f3(C,B).

Figure 6: Program learned by Brute for task p49.

“16,079 inferences, 0.003 CPU in 0.003 seconds (95%
CPU, 5842660 Lips)”
↓ f0
“PU in 0.003 seconds (95% CPU, 5842660 Lips)”
↓ f1
“.003 seconds (95% CPU, 5842660 Lips)”
↓ f0
“PU, 5842660 Lips)”
↓ f2
“5842660 Lips)”
↓ f3
“5842660 Lips”
↓ f2
“5842660”

Figure 7: Execution trace of the program from Figure 6 on the ex-
ample “16,079 inferences, 0.003 CPU in 0.003 seconds (95% CPU,
5842660 Lips)” 7→ “5842660”.

is an atom f (x, y), where f is the target predicate and x
and y are input and output states respectively. A state is a
(i, p) pair, where i is the image, represented as a list, and
p is a cursor pointing to a speciﬁc pixel in the image. We
provide as background knowledge the dyadic predicates up,
down, right, left, draw1, draw0, and the monadic predicates
at_top, at_bottom, at_left, at_right. The predicates draw0
and draw1 manipulate the image. The rest manipulate the
cursor. Brute uses a Hamming distance loss function.

Figure 8: Example ASCII image.

Method
For each n in {1, 2, . . . , 5}, we sample uniformly at random
with replacement an ASCII string of length n. As the string
grows, so should the size of the target hypothesis. We use
the text2art library to transform a string to a pixel repre-
sentation which forms our output image. We use the empty
image as the input image. We measure the percentage of
tasks solved and learning times.

the images with 3 characters, and still manages to learn pro-
grams for 25% of the images with 5 characters. The largest
program learned by Brute has 79 clauses and 294 literals.
These results again suggest that the answer to questions Q1
and Q2 is yes.

100

)

%

(

d
e
v
l
o
s

s
k
s
a
T

80

60

40

20

Brute
Brute|=
Metagol

0

1

2

3

4

5

No. symbols

60

40

20

)
s
d
n
o
c
e
s
(

e
m

i
t

i

g
n
n
r
a
e
L

0

1

Brute
Brute|=
Metagol

2

3

4

5

No. symbols

(a) Percentage of tasks solved

(b) Mean learning time

Figure 9: ASCII art experimental results.

5 Conclusions and Limitations

A major challenge in ILP (and program synthesis in gen-
eral) is learning large programs. To tackle this problem,
we have proposed an approach inspired by how humans
write programs. In our approach, an ILP system builds a
program, executes it on some example input to generate
output, compares the output with the expected output, and
revises the program if needed. To evaluate a hypothesis, we
use example-dependent loss functions. We implemented our
idea in Brute, a new ILP which ﬁrst invents a library of pred-
icates, including recursive predicates, and then performs a
best-ﬁrst search informed by a given loss function to build
a hypothesis using the library predicates.

Our experiments on three diverse program synthesis
domains (robot planning, real-world string transforma-
tions, and a new problem of drawing ASCII art), show
that (1) example-dependent loss functions can outperform
entailment-based loss functions, and (2) Brute can outper-
form Metagol, a state-of-the-art ILP system.
In our ex-
periments, given only 60 seconds to learn a program, the
largest program learned by Metagol had 5 clauses and 15
literals. By contrast, the largest program learned by Brute
had 79 clauses and 294 literals.

Limitations and Future Work

Generality In contrast to classical ILP systems, which
classiﬁcation), Brute
focus on concept learning (i.e.
focuses on learning recursive programs from input/out-
Brute cannot therefore currently solve
put examples.
some classical
such as Mutagenesis
ILP problems,
[Srinivasan et al., 1994], because the examples in these
domains are not dyadic. To address this limitation, we
could represent classiﬁcation tasks as program synthesis
tasks, where the output is the label.

Results
Figure 9 shows that Metagol and Brute|= cannot learn any
solutions. By contrast, Brute learns programs for 86% of

Search To clearly demonstrate our idea, we intention-
ally designed Brute to be simple in two ways (1) brute-
force inventing library predicates, and (2) using simple

best-ﬁrst search. As our experiments show, our intention-
ally simple approach can drastically outperform existing
systems. To further improve performance, we want to (1)
dynamically invent library predicates during the search to
reduce the branching factor, and (2) use better search tech-
niques, such as A* or iterative budgeted exponential search
[Helmert et al., 2019].

Loss functions Brute uses example-dependent (domain-
speciﬁc) loss functions to guide the search, which our ex-
periments show are important for high performance. By
contrast, most ILP systems use general entailment-based
loss functions. An important direction for future work is to
bridge the gap between the two approaches. An exciting
idea is to learn suitable loss functions for a given problem
through meta-learning [Thrun and Pratt, 2012].

Summary
To conclude, we think that Brute is an important contribu-
tion to ILP and program synthesis, and that the ideas in-
troduced in this paper open up new and exciting research
opportunities for learning large programs.

References
[Balog et al., 2017] Matej Balog, Alexander L. Gaunt,
Marc Brockschmidt, Sebastian Nowozin, and Daniel Tar-
low. Deepcoder: Learning to write programs. In ICLR.
OpenReview.net, 2017.

[Blockeel and De Raedt, 1998] Hendrik Blockeel and Luc
De Raedt. Top-down induction of ﬁrst-order logical de-
cision trees. Artif. Intell., 101(1-2):285–297, 1998.

Cropper
system.

[Cropper and Muggleton, 2016] Andrew

and Stephen H. Muggleton.
https://github.com/metagol/metagol, 2016.
[Cropper and Muggleton, 2019] Andrew Cropper

Metagol

and
Learning efﬁcient logic pro-

Stephen H. Muggleton.
grams. Machine Learning, 108(7):1063–1083, 2019.
[Cropper et al., 2019a] Andrew Cropper, Richard Evans,
Inductive general game playing. Ma-

and Mark Law.
chine Learning, Nov 2019.

[Cropper et al., 2019b] Andrew Cropper, Rolf Morel, and
Stephen Muggleton. Learning higher-order logic pro-
grams. Machine Learning, Dec 2019.

[Cropper, 2019] Andrew Cropper. Playgol: Learning pro-
In IJCAI 2019, pages 6074–6080.

grams through play.
ijcai.org, 2019.

[Devlin et al., 2017] Jacob Devlin, Rudy Bunel, Rishabh
Singh, Matthew J. Hausknecht, and Pushmeet Kohli.
In NIPS 2017, pages
Neural program meta-induction.
2080–2088, 2017.

[Ellis et al., 2018] Kevin Ellis, Lucas Morales, Mathias
Sablé-Meyer, Armando Solar-Lezama, and Josh Tenen-
baum. Learning libraries of subroutines for neurally-
guided bayesian program induction.
In NeurIPS 2018,
pages 7816–7826, 2018.

[Ellis et al., 2019] Kevin Ellis, Maxwell

I. Nye, Yewen
Pu, Felix Sosa, Josh Tenenbaum, and Armando Solar-
Lezama. Write, execute, assess: Program synthesis with
a REPL. CoRR, abs/1906.04604, 2019.

[Evans and Grefenstette, 2018] Richard Evans and Ed-
Learning explanatory rules from

ward Grefenstette.
noisy data. J. Artif. Intell. Res., 61:1–64, 2018.

[Flener and Yilmaz, 1999] Pierre Flener and Serap Yil-
Inductive synthesis of recursive logic programs:
J. Log. Program., 41(2-

maz.
Achievements and prospects.
3):141–195, 1999.

[Gulwani et al., 2017] Sumit Gulwani, Oleksandr Polozov,
and Rishabh Singh. Program synthesis. Foundations and
Trends in Programming Languages, 4(1-2):1–119, 2017.
[Helmert et al., 2019] Malte Helmert, Tor Lattimore, Levi
H. S. Lelis, Laurent Orseau, and Nathan R. Sturtevant.
Iterative budgeted exponential search. In IJCAI, pages
1249–1257. ijcai.org, 2019.

[Kaminski et al., 2018] Tobias Kaminski, Thomas Eiter,
and Katsumi Inoue. Exploiting answer set program-
ming with external sources for meta-interpretive learn-
ing. TPLP, 18(3-4):571–588, 2018.

[Law et al., 2014] Mark Law, Alessandra Russo, and Krysia
In

Inductive learning of answer set programs.

Broda.
JELIA 2014, pages 311–325, 2014.

[Law et al., 2020] Mark Law, Alessandra Russo, Elisa
Bertino, Krysia Broda, and Jorge Lobo. Fastlas: scalable
inductive logic programming incorporating domain-
speciﬁc optimisation criteria. In AAAI. AAAI Press, 2020.
[Lifschitz, 2008] Vladimir Lifschitz. What is answer set
programming? In AAAI 2008, pages 1594–1597. AAAI
Press, 2008.

[Lin et al., 2014] Dianhuan Lin, Eyal Dechter, Kevin Ellis,
Joshua B. Tenenbaum, and Stephen Muggleton. Bias
reformulation for one-shot function induction. In ECAI
2014, pages 525–530, 2014.

[Lloyd, 2012] John W Lloyd. Foundations of logic program-

ming. Springer Science & Business Media, 2012.

[Muggleton et al., 2015] Stephen H. Muggleton, Dian-
huan Lin, and Alireza Tamaddoni-Nezhad. Meta-
interpretive learning of higher-order dyadic datalog:
predicate invention revisited.
Machine Learning,
100(1):49–73, 2015.

[Muggleton, 1995] Stephen Muggleton.

Inverse en-
New Generation Comput.,

tailment and progol.
13(3&4):245–286, 1995.

[Quinlan, 1990] J. Ross Quinlan. Learning logical deﬁ-
nitions from relations. Machine Learning, 5:239–266,
1990.

[Russell and Norvig, 2010] S.J. Russell and P. Norvig. Ar-
tiﬁcial Intelligence: A Modern Approach. Pearson, New
Jersey, 2010. Third Edition.
[Silver et al., 2017] David Silver,

Julian Schrittwieser,
Ioannis Antonoglou, Aja Huang,

Karen Simonyan,

Arthur Guez, Thomas Hubert, Lucas Baker, Matthew
Lai, Adrian Bolton, et al. Mastering the game of go with-
out human knowledge. nature, 550(7676):354–359,
2017.

[Singh and Kohli, 2017] Rishabh Singh and Pushmeet
Kohli. AP: artiﬁcial programming.
In 2nd Summit on
Advances in Programming Languages, SNAPL 2017, vol-
ume 71 of LIPIcs, pages 16:1–16:12. Schloss Dagstuhl -
Leibniz-Zentrum fuer Informatik, 2017.

[Srinivasan et al., 1994] Ashwin Srinivasan, Stephen Mug-
gleton, Ross D King, and Micheal JE Sternberg. Mutage-
nesis: Ilp experiments in a non-determinate biological
domain. In Proceedings of the 4th international workshop
on inductive logic programming, volume 237, pages 217–
232. Citeseer, 1994.

[Srinivasan, 2001] A. Srinivasan. The ALEPH manual. Ma-
chine Learning at the Computing Laboratory, Oxford Uni-
versity, 2001.

[Thrun and Pratt, 2012] Sebastian Thrun and Lorien Pratt.
Learning to learn. Springer Science & Business Media,
2012.

