Unsupervised Domain Adaptation of Black-Box Source Models

Haojian Zhang1, Yabin Zhang2, Kui Jia1, Lei Zhang2

1South China University of Technology

2The Hong Kong Polytechnic University

eehjzhang@mail.scut.edu.cn,csybzhang@comp.polyu.edu.hk,

kuijia@scut.edu.cn,cslzhang@comp.polyu.edu.hk

1
2
0
2

r
a

M
8
2

]

G
L
.
s
c
[

2
v
9
3
8
2
0
.
1
0
1
2
:
v
i
X
r
a

Abstract

Unsupervised domain adaptation (UDA) aims to learn
models for a target domain of unlabeled data by transfer-
ring knowledge from a labeled source domain. In the tra-
ditional UDA setting, labeled source data are assumed to
be available for adaptation. Due to increasing concerns
for data privacy, source-free UDA is highly appreciated as
a new UDA setting, where only a trained source model is
assumed to be available, while labeled source data remain
private. However, trained source models may also be un-
available in practice since source models may have com-
mercial values and exposing source models brings risks
to the source domain, e.g., problems of model misuse and
white-box attacks. In this work, we study a subtly differ-
ent setting, named Black-Box Unsupervised Domain Adap-
tation (B2UDA), where only the application programming
interface of source model is accessible to the target domain;
in other words, the source model itself is kept as a black-
box one. To tackle B2UDA, we propose a simple yet effec-
tive method, termed Iterative Learning with Noisy Labels
(IterLNL). With black-box models as tools of noisy labeling,
IterLNL conducts noisy labeling and learning with noisy la-
bels (LNL), iteratively. To facilitate the implementation of
LNL in B2UDA, we estimate the noise rate from model pre-
dictions of unlabeled target data and propose category-wise
sampling to tackle the unbalanced label noise among cate-
gories. Experiments on benchmark datasets show the efﬁ-
cacy of IterLNL. Given neither source data nor source mod-
els, IterLNL performs comparably with traditional UDA
methods that make full use of labeled source data.

1. Introduction

Although deep models have achieved success on various
tasks, it is difﬁcult to generalize the model learned from
labeled training data to a target domain of slightly shifted
data distribution. At the same time, it is expensive to col-
lect a new target dataset with a large number of labeled
training data. Therefore, unsupervised domain adaptation

(UDA) [30, 24, 5] is introduced to learn the target model
by transferring knowledge from the labeled source domain
to the unlabeled target domain. Motivated by seminal the-
ories [3, 49], popular UDA methods [24, 5, 36, 25, 50]
target at learning domain invariant feature representations.
The underlying motivation is that the source classiﬁer could
be safely applied to the target domain once domain invari-
ant feature representations are achieved. In UDA, labeled
source data are assumed to be available for target domain.

Although remarkable success has been achieved in UDA,
increasing concerns for data privacy post new challenges to
this task. Speciﬁcally, data of source and target domains are
typically captured and stored on different devices and con-
tain private information. Thus it is risky to expose source
data to the target domain and vice versa. In other words,
labeled source data may be not available for the target do-
main, impeding the application of popular UDA methods
[24, 5, 36, 25, 50]. For this reason, a novel task, source-free
UDA, is introduced [45, 13, 23] to facilitate the model adap-
tation and protect the source data privacy simultaneously.

Unlike the vanilla UDA, a well-trained source model, in-
stead of labeled source data, is provided to unlabeled target
domain in the source-free UDA [45, 23]. Speciﬁcally, a
white-box source model is available for the target domain;
thus, we term this task as white-box unsupervised domain
adaptation (WBUDA) to distinguish it from our investi-
gated one in later paragraphs. In WBUDA, the adaptation
could be achieved by ﬁne-tuning the source model on unla-
beled target data with well-designed objectives [45, 23].

However,

the white-box source model is not always
given in practice. Most valuable models on cloud services
(e.g., Google Cloud) are sealed as application programming
interface (API), where only the input-output interface of a
model is available and the model itself is kept as a black-
box one. As stated in [29], releasing an API instead of a
white-box model could commercialize the technology, re-
duce model misuse and make the model use conveniently
for the public; the white-box attacks [38, 39] may be also
avoided. Due to all reasons mentioned above, white-box
source models are probably unavailable in practice, which

 
 
 
 
 
 
hinders the application of WBUDA methods.

In this work, we study a subtly different setting of
source-free UDA, where only the API of the source model
is accessible for the target domain.
In other words, the
source model itself is kept as a black-box one; thus, we
term this task as black-box unsupervised domain adaptation
(B2UDA). A few recent attempts [46, 4, 27] have been made
to tackle the B2UDA problem, but achieving less satisfac-
tory results. In this work, we propose a simple yet effec-
tive algorithmic framework, termed Iterative Learning with
Noisy Labels (IterLNL). With black-box models as tools of
noisy labeling, IterLNL conducts noisy labeling and LNL
iteratively. Speciﬁcally, we ﬁrst get model predictions of
target data based on the black-box model and obtain their
noisy labels as the category with the maximum prediction
probability. We note that the label noise via the black-box
model is highly unbalanced among categories (cf. Figure
2(c)), which is signiﬁcantly different from the simulated
and balanced ones in LNL [40, 10]; such unbalanced label
noise hinders the application of state-of-the-art LNL meth-
ods [15, 10], inspiring the category-wise sampling strategy.
To facilitate the implementation of LNL in B2UDA, we also
estimate the noise rate from model predictions of unlabeled
target data. Experiments on benchmark datasets conﬁrm
the efﬁcacy of our method. Notably, our IterLNL performs
comparably with methods of traditional UDA setting where
labeled source data are fully available.

2. Related Work

Source Free UDA. Traditional UDA [24, 5] assumes that
labeled source data are available for the target domain. Due
to increasing concerns for data privacy, source-free UDA
[23, 22, 13, 17, 18, 45] is highly appreciated as a new
UDA setting, where only a source model is available for
the target domain while labeled source data remain pri-
vate. Source free UDA methods typically ﬁne-tune the
source model for the target domain with unlabeled target
data [23, 17, 45, 22]. Speciﬁcally, Liang et al. [23] ﬁne-
tune the source model with pseudo-labeling and informa-
tion maximization between target data and their predictions;
a weight constraint is adopted in [22] to encourage simi-
larity between the source model and adapted target model.
Additionally, source data and source-style target data are
respectively generated in [18] and [13] using the statistics
information stored in source model. The white-box source
model is required in the methods above, but it may be un-
available due to the commercial and/or safety consideration
[29]. To this end, we study a subtly different B2UDA set-
ting, where only the API of source model is accessible for
the target domain; in other words, the source model itself
is kept as a black-box one. We note that several attempts
have been made on the B2UDA problem recently. Based on
pre-trained features, a denoising auto-encoder is used for

prediction of target labels in [4] and an encoder-decoder
framework is used in [46] where encoded target features
are aligned to reference Gaussian distributions; however,
both of the two methods obtain less satisfactory results on
benchmark datasets. Morerio et al. [27] ﬁrst train a con-
ditional Generative Adversarial Network (cGAN) with un-
labeled target data and their source predictions, and then
learn the target model with samples generated by cGAN;
its performance is conditioned on the high-quality samples
generated by cGAN, thus limiting its general usage in UDA
tasks. In general, the B2UDA problem is not well addressed
yet.
In the present work, we propose IterLNL and con-
duct thorough experiments on popular UDA benchmarks;
results show that our proposed method works successfully
for B2UDA.
Learning with Noisy Labels (LNL). LNL aims to learn
models with noisy labeled data robustly. Seminal LNL
methods include estimating noise transition matrix to trans-
fer observed noisy labels to latent clean ones [37, 41], reﬁn-
ing the objective function [7, 51], and avoiding overﬁtting
noisy labels with memorization effects of neuron networks
[15, 10], as summarized in [9]. Although we also adopt
LNL technical tools for the B2UDA problem, the task di-
vergence between LNL and B2UDA raises new problems.
Speciﬁcally, as predictions of black-box models are adopted
as noisy labels, the noise rate is unknown and the label
noise is unbalanced among categories in B2UDA (cf. Fig-
ure 2(c)), while simulated and balanced noisy labels with
known noise rate are typically adopted in LNL [40, 8, 10].
Besides, noisy labels are given and ﬁxed in LNL, while we
obtain noisy labels from predictions of black-box models
and could update noisy labels via updating models, inspir-
ing the iterative learning strategy.
Hypothesis Transfer Learning (HTL). HTL [19] utilizes
source hypotheses (i.e., source models) to assist learning in
the target domain. Different from the B2UDA task, at least
a small number of labeled target samples are demanded and
source hypotheses are typically required to be white-box
ones in HTL methods [19, 47, 1], hindering their applica-
tions in B2UDA tasks.

3. Problems and the proposed Method

i}nt

(cid:80)nt

i), yt

i=1[L(F (xt

Given unlabeled target data T = {xt

i=1 sampled
from a distribution Q, our problem of interest is to learn
a model F : X t → [0, 1]K such that the empirical target
risk 1
i )] (or ideally, the expected risk
nt
E(xt,yt)∈Q[L(F (xt), yt)]) could be minimized, where K is
the category number, L is the loss function of the task, and
yt
i ∈ {1, . . . , K}, i = 1, . . . , nt, is the target label to be
estimated. Depending on how much knowledge one may
have from a source domain, the problem can fall in differ-
ent established realms of unsupervised learning [42], unsu-

Figure 1. An illustration of different UDA settings. Source data and source model are respectively required in the traditional UDA and
WBUDA settings. In contrast, B2UDA requires a black-box access to the source model only, which is the least restrictive condition to
apply domain adaptation to the unsupervised target data.

pervised domain adaptation (UDA) [24, 5], and source-free
UDA [45, 23]. While the ﬁrst one assumes no the source
knowledge and is of machine learning foundations, in this
work, we focus on different problem settings of UDA.
Unsupervised Domain Adaptation. Labeled source data
S = {xs
i=1 sampled from a distribution P are as-
sumed to be available to help the learning with unlabeled
target data T in UDA, leading to the following objective:

i }ns

i , ys

F t ⇐ OUDA(T , S),

(1)

where F t is the expected target model. The most popular
methods [24, 5] for UDA (1) are to learn domain invariant
feature representations, then the classiﬁer learned from la-
beled source data S could be safely applied to target data.
White-box Unsupervised Domain Adaptation. Source-
free UDA [22, 23] is proposed recently due to increasing
concerns for data privacy. Indeed, we are in an era of cloud
computing, and source and target data are usually captured
and privately stored on different devices; it is thus risky to
expose source data for transferable use to the target domain.
Source-free UDA typically proposes to use a trained white-
box source model F s, instead of the labeled source data S,
to accomplish the UDA objective, which is formalized as:

F t ⇐ OWBUDA(T , F s),

(2)

where F s = arg minF Ltask(F, S) and the task loss Ltask
is typically instantiated as:

Ltask(F, S) =

1
ns

ns
(cid:88)

i=1

− log(Fys

i

(xs

i )),

(3)

where Fk(x) stands for the kth entry of F (x). Since white-
box source model F s is required in (2), we term it as white-
box unsupervised domain adaptation (WBUDA) to distin-
guish it from our investigated one in follow paragraphs. In
WBUDA, the target model is typically achieved by ﬁne-
tuning the white-box source model F s on unlabeled target
data T using proper objectives, e.g., the pseudo labeling and
information maximization losses in [23].
Black-box Unsupervised Domain Adaptation. Although
source data remain private in the WBUDA mentioned above
[22, 23], the required white-box source model may be not
available in practice. Most valuable models on cloud ser-
vices (e.g., Google Cloud) are sealed as APIs, where only
input-output interfaces are available. As stated in [29], re-
leasing an API instead of a white-box model could commer-
cialize the technology, reduce model misuse and make the
model use conveniently for the public; white-box attacks
[38, 39] could also be avoided.

Considering above advantages of releasing APIs, we
investigate a subtly different setting of source-free UDA,
where only the API of a source model is accessible for the
target domain and the source model itself is kept as a black-
box one. We denote this task as black-box unsupervised
domain adaptation (B2UDA), which is formulated as:

F t ⇐ OB2UDA(T , (cid:98)F s),

(4)

where (cid:98)F s is the API of F s; speciﬁcally, we could get the
output of F s(x) with respect to any sample x via (cid:98)F s(x)
and the source model F s itself is kept as a black-box one.
As there are many model APIs on cloud services, B2UDA is

UDAWBUDAB2UDATargetDataSourceDataSourceModelSourceModelSourceModelSourceModelTrainSource DomainTarget DomainTargetDataTargetDataSealSourceDataBlack BoxBlack Box(a) Pair ((cid:15)=0.45)

(b) Symmetry ((cid:15)=0.5)

(c) VisDA-2017

(d) Rescale curve (9)

Figure 2. (a)-(c): Transition matrices [31, 34] of different noise types, where the simulated (a) pair ﬂipping [10] and (b) symmetry ﬂipping
[40] are widely adopted in LNL works [10, 44], and (c) presents the realistic noise matrix in the VisDA-2017 dataset based on the black-box
source model (cid:98)F s. The value in row r, column c represents the probability with which samples of category r are assigned with label c. In
all ﬁgures, deeper colour indicates a larger value and all values are rounded to the level of 0.01. (Zoom in to see the exact values.). The
label noise in (c) VisDA-2017 is signiﬁcantly unbalanced among categories, where the noise rates of 4-th, 7-th and 9-th categories are less
than 0.2 while the noise rates of 6-th and 12-th categories are more than 0.96. (d) Illustration of the rescale curve (9) with different κ.

a promising way to improve their adaptabilities, presenting
broad practical values.

Labeled source data S and white-box source model F s
are respectively required in UDA and WBUDA methods,
impeding their applications in the B2UDA task. To tackle
the challenging B2UDA, we propose an Iterative Learn-
ing with Noisy Labels (IterLNL) framework by conducting
noisy labeling and LNL iteratively, which are introduced as
follows.

3.1. Noisy Labeling

Given a black-box model (cid:98)F (e.g., the black-box source
model (cid:98)F s) in B2UDA, we could get label predictions of
target data {xt

i=1 with (cid:98)F as:

i}nt

(cid:98)Y = { (cid:98)F (xt

i)}nt

i=1.

(5)

i }nt

i = arg maxk (cid:98)Fk(xt

The corresponding pseudo label of target sample xt
i is de-
i }nt
i). The pseudo labels {(cid:98)yt
ﬁned as (cid:98)yt
i=1
could be highly noisy due to the divergence across source
and target domains. Furthermore, we emphasize that the
label noise in {(cid:98)yt
i=1 could be signiﬁcantly unbalanced
among categories; for example, the noise rate could be ex-
tremely high for some categories and extremely low for the
others, as illustrated in Figure 2(c). Such unbalanced la-
bel noise via domain shift is substantially different from the
simulated ones [40, 10] in many LNL works, as compared
in Figure 2.
In addition, the noise rate, which is usually
required in LNL algorithms, is unknown in B2UDA, while
it is usually assumed to be given in LNL [40, 10]. In the
next paragraph, we propose strategies to estimate the noise
rate and tackle unbalanced label noise, which support the
successful target model learning with noisy labels.

3.2. Learning with Noisy Labels

Give noisy target label predictions (cid:98)Y in Section 3.1, we
resort to LNL to learn the target model. State-of-the-art
LNL methods [15, 10, 12] usually combat noisy labels by
selecting ‘clean’ samples from each mini-batch for training,
which is achieved by utilizing the memorization effects of
neuron networks [2]. Before going into detail, we denote
R(n) as the percentage of instances selected for training in
the mini-batch of n-th iteration. LNL methods [15, 10, 12]
typically keep more instances in the mini-batch (i.e., R(n)
is large) at the beginning, and then gradually drop noisy
samples (i.e., R(n) becomes smaller) as training proceeds;
by using more training instances at the beginning, a rela-
tively reliable model could be achieved since deep models
learn clean and easy patterns at the beginning [2]; with the
reliable model, noisy instances could be ﬁltered out by grad-
ually dropping instances with larger losses.

We also adopt the aforementioned LNL strategy in our
method since it presents high robustness even with ex-
tremely noisy labels [10]. In LNL [10, 44], the selecting
percentage R(n) is depending on the noise rate, which is ei-
ther assumed to be known in advance [10] or estimated with
few labeled clean data [48, 33]. However, realistic noisy la-
bels are introduced by domain shift in B2UDA, where the
unavailable of labeled target data and unknown noise rate
impede the design of R(n).

To this end, we propose a simple yet efﬁcient strategy to
estimate noise rate. We ﬁrst follow [10] to deﬁne R(n) as:

R(n) = 1 − min (

n
nk

(cid:15), (cid:15)),

(6)

where nk is a hyperparameter and (cid:15) is the noise rate.
Noise rate Estimation. We ﬁrst present the empirical noise

0.550.450.000.000.000.000.000.000.000.000.000.000.000.550.450.000.000.000.000.000.000.000.000.000.000.000.550.450.000.000.000.000.000.000.000.000.000.000.000.550.450.000.000.000.000.000.000.000.000.000.000.000.550.450.000.000.000.000.000.000.000.000.000.000.000.550.450.000.000.000.000.000.000.000.000.000.000.000.550.450.000.000.000.000.000.000.000.000.000.000.000.550.450.000.000.000.000.000.000.000.000.000.000.000.550.450.000.000.000.000.000.000.000.000.000.000.000.550.450.000.000.000.000.000.000.000.000.000.000.000.550.450.450.000.000.000.000.000.000.000.000.000.000.550.500.050.050.050.050.050.050.050.050.050.050.050.050.500.050.050.050.050.050.050.050.050.050.050.050.050.500.050.050.050.050.050.050.050.050.050.050.050.050.500.050.050.050.050.050.050.050.050.050.050.050.050.500.050.050.050.050.050.050.050.050.050.050.050.050.500.050.050.050.050.050.050.050.050.050.050.050.050.500.050.050.050.050.050.050.050.050.050.050.050.050.500.050.050.050.050.050.050.050.050.050.050.050.050.500.050.050.050.050.050.050.050.050.050.050.050.050.500.050.050.050.050.050.050.050.050.050.050.050.050.500.050.050.050.050.050.050.050.050.050.050.050.050.500.760.000.030.090.000.000.060.000.010.010.030.000.000.260.010.060.000.000.530.000.090.000.040.000.000.000.600.280.000.000.030.000.010.000.090.000.000.000.030.800.010.000.100.000.030.000.030.000.000.000.000.020.740.000.150.000.070.000.020.000.070.000.010.280.020.020.150.000.190.230.020.000.000.000.000.050.000.000.890.000.040.000.010.000.010.000.020.240.060.000.410.080.150.020.020.000.000.000.040.060.000.000.020.000.800.010.070.000.090.000.010.160.010.000.360.010.090.260.020.000.000.000.150.110.000.000.010.000.020.000.690.000.000.000.120.620.010.000.050.000.020.000.150.040.00.20.40.60.81.000.00.20.40.60.81.0=1=2=3Figure 3. Framework of our proposed Iterative Learning with Noisy Labels (IterLNL), where we conduct noisy labeling and LNL iteratively.
Note that we introduce noisy labels based on predictions of the black-box model.

rate (cid:15) as:

(cid:15) = 1 −

1
nt

nt
(cid:88)

I[xt

i, (cid:98)yt
i ],

degenerates to ρ = ρ(cid:48) if κ = 1, as illustrated in Figure 2(d).
The design of (9) is further investigated in Section 4.1. We
ﬁnally approximate noise rate (cid:15) as:

(7)

i, (cid:98)yt

i, (cid:98)yt

i=1
i ] ∈ {0, 1} is a binary indicator; I[xt

i is the correct label of xt

where I[xt
i ] = 1
if (cid:98)yt
i and 0 otherwise. It is obvi-
ous that the empirical noise rate (cid:15) (7) is close correlated to
the classiﬁcation accuracy of the black-box model (cid:98)F . In the
meantime, there is a correlation between the classiﬁcation
accuracy and maximum prediction probability, as observed
in [21, 52, 12]. Although the prediction probability may be
overconﬁdent and misleading viewed in isolation, the prob-
ability statistics is often sufﬁcient to reﬂect on the overall
classiﬁcation accuracy [12, 6], and also the noise rate (cid:15).

To estimate the noise rate (cid:15), we calculate the proportion

of target data T with high prediction probability as:

ρ(cid:48) =

1
nt

nt
(cid:88)

i=1

I[max( (cid:98)F (xt

i)) > γ],

(8)

where γ ∈ [0, 1]
(cid:40)

1,
var = T rue
0, Otherwise

is the threshold and I[var] =

. One may opt for approximating noise

rate (cid:15) with 1 − ρ(cid:48). However, considering that deep models
are prone to make over-conﬁdent predictions [6], we rescale
ρ(cid:48) ∈ [0, 1] → ρ ∈ [0, 1] as:
(cid:40)

ρ =

0.5(2ρ(cid:48))1/κ,
−0.5(2 − 2ρ(cid:48))1/κ + 1, Otherwise.

ρ(cid:48) < 0.5

(9)

Although the equation (9) seems complicated, there is only
one hyperparameter κ controlling the curve degree and it

(cid:15) = 1 − ρ.

(10)

Although the estimated noise rate (cid:15) (10) is not precise, we
ﬁnd that our method is robust to the noise rate (cid:15); such an
estimation of noise rate works well and achieves good re-
sults close to that using the grounding truth noise rate, as
presented in Section 4.1.

Category-wise Sampling. Given the estimated noise rate (cid:15)
(10), we could conduct LNL by selecting R(n) (6) percent
samples with smaller loss for training in the mini-batch of
n-th iteration. However, as we state in Section 3.1, the label
noise is unbalanced among categories in B2UDA (cf. Fig-
ure 2(c)); thus samples in categories with higher noise rate
are prone to present larger loss and be rejected for training,
leading to worse results for these categories, as presented in
Table 1.

To this end, we propose to individually sample the R(n)
(6) percent samples with smaller loss for each category.
Technically, we introduce a probability queue buffer uk ∈
[0, 1]h for category k ∈ [1, . . . , K], where uk is initialized
as a vector ﬁlled with positive inﬁnity values and h is the
buffer length. For any instance xt in the n-th iteration, we
obtain its corresponding noisy label (cid:98)yt = arg maxk (cid:98)Fk(xt)
(cid:98)yt(xt)), where F is
and loss L(F (xt), (cid:98)yt) = − log(F
the current model in learning. We propose an indicator
(cid:98)yt, n) to decide whether xt should be
I(L(F (xt), (cid:98)yt), u

SourceDataBlack Box ModelSourceModelTrainSource DomainSourceModelBlack BoxSealTargetModelTarget DomainLearning with Noisy LabelsNoisy LabelingInitializeTargetDataUpdateModel PredictionsNoise rate Noisy labels Black Boxadopted in training, which is formulated as:

I(L(F (xt), (cid:98)yt), u

(cid:98)yt, n) =

(cid:40)

1, L(F (xt), (cid:98)y) ≤ LR(n)(u
0, Otherwise,

(cid:98)yt)

(11)
where LR(n)(u
(cid:98)yt. We
utilize the loss L(F (xt), (cid:98)yt) to update current model F if
I(L(F (xt), (cid:98)yt), u

(cid:98)yt) is the R(n)-th largest value in u

(cid:98)yt, n) = 1 and drop it otherwise.

We also update the queue buffers {uk}K

k=1 with all sam-
ples in the n-th iteration. Speciﬁcally, given an instance xt
and its corresponding noisy label (cid:98)yt and loss L(F (xt), (cid:98)yt)
deﬁned above, we push L(F (xt), (cid:98)yt) into the queue buffer
(cid:98)yt and pop the oldest value from u
u
(cid:98)yt simultaneously. In
this way, we adopt samples with the R(n) percent smallest
losses in each category for training in n-th iteration.

Remarks. Note that our method is fundamentally different
from existing DA methods based on pseudo labels [26, 53].
Although we also adopt the categories with maximum pre-
diction probability on the black-box model as noisy labels,
we do not use them directly as accurate ones. We only
use samples with noisy labels to update the model if these
samples present small losses based on the current model;
in other words, we treat noisy labels as accurate ones only
if they are consistent with the current model’s predictions.
Moreover, source data are not involved in model training,
avoiding the misleading of source data on target predictions.

3.3. Iternative Learning Strategy

With the noisy labeling in Section 3.1 and LNL in Sec-
tion 3.2, we could get a more reliable target model over
the original black-box one (i.e., the one introduces noisy
labels), as illustrated in Figure 4(a).
In other words, the
achieved target model could produce improved noisy labels
over the original noisy labels. It is a natural idea to con-
duct noisy labeling with the achieved target model (or the
black-box counterpart of the achieved target model), and
conduct LNL on the new noisy labels again. Finally, we
deﬁne our algorithmic framework by conducting noisy la-
beling and LNL iteratively, leading to the Iterative Learn-
ing with Noisy Labels (IterLNL). We summarize IterLNL
in Algorithm 1 and illustrate its framework in Figure 3.

Remarks. The black-box source model and noisy labels
are introduced respectively in B2UDA and LNL tasks to
help the learning with unlabeled data, making the two tasks
fundamentally different. Although we utilize the black-box
source model to assign noisy labels and learn the target
model in a LNL manner, there are three differences. First,
the noise rate is unknown and to be estimated in B2UDA
and no labeled target data are provided for the noise rate es-
timation. Second, the label noise is quite unbalanced among
categories in B2UDA. Third, different from the given and
ﬁxed noisy labels in LNL, the noisy labels in B2UDA are

introduced by black-box models and could be updated as
the model update, inspiring the iterative learning strategy.

(cid:46) For each iterative step

Algorithm 1 Iterative Learning with Noisy Labels.
Input: Black-box source model (cid:98)F s, target data T
Output: Target model F
1: Initialize (cid:98)F with (cid:98)F s
2: for m = 1 to M do
3:
4:
5:
6:
7:

Acquire noisy labels (cid:98)Y with T and (cid:98)F using (5)
Estimate noise rate (cid:15) with (8), (9) and (10)
Initialize target model F and buffers {uk}K
for n = 1 to N do

k=1

Acquire R(n) with (6)
Update model F using data selected with (11)
Update buffers {uk}K

k=1

end for
Update (cid:98)F as the API (i.e., black-box model) of F

8:
9:
10:
11:
12: end for

(cid:46) For each iteration

4. Experiment

Ofﬁce-31 [35] is the most popular benchmark dataset for
UDA. There are 4, 110 samples shared by three domains:
amazon (A), webcam (W), and dslr (D). VisDA-2017 [32]
aims to transfer knowledge from synthetic images to real-
world ones, which is a challenging task with signiﬁcant do-
main divergence. There are 152K synthetic images and
55K real-world images shared by 12 classes. Datasets of
MNIST [20], Street View House Numbers (SVHN) [28],
and USPS [14] constitute the Digits task, which includes 10
classes. There are 50, 000 training samples, 10, 000 valida-
tion samples and 10, 000 test samples in the MNIST dataset
(M), where all images are black-and-white handwritten dig-
its; the SVHN dataset (S) contains 73, 257 training and
26, 032 test images with colored backgrounds; the USPS
dataset (U) contains 7, 291 training and 2, 007 test images
with black backgrounds.
Implementation Details.
For experiments on datasets
of Ofﬁce-31 and VisDA-2017, we employ the pre-trained
ResNet model [11] as the backbone and replace the last
fully connected (FC) layer with a task-speciﬁc FC classiﬁer
following [24, 5, 23]. We introduce the source model F s
by ﬁne-tuning the constructed model on source data follow-
ing [16] and then seal F s as the black-box (cid:98)F s, i.e., only the
input-output interface of F s is available. For experiments
on Digits dataset, we follow [36] to introduce the source
model F s with convolutional layers and FC layers. Follow-
ing [5], we utilize the SGD optimizer and adopt the learning
(1+10ζ)0.75 , where η0 = 0.01 and ζ
rate strategy as ηn =
is the process of training iterations linearly changing from
0 to 1. We set the batch size as 64, κ = 2 in (9), γ = 0.9 in
(8), buffer length h = 100, and nk = 0.5N (N is the total

η0

Methods
Source Model [16]
IterLNL (w/o Iter)
IterLNL (w/o CateS)
IterLNL (w/o Rescale)
IterLNL
IterLNL (with Val)

horse
73.5
88.0
96.7
79.4
92.1
87.7
Table 1. Ablation study on VisDA-2017 dataset, where all experiments are based on a ResNet-101 model. Please refer to the main text for
deﬁnitions.

knife mcycl person plant
79.7
2.3
93.1
25.1
96.0
0.0
90.1
77.9
89.1
74.1
88.1
87.1

sktbrd train
69.4
25.6
83.3
59.1
84.8
93.3
88.2
89.1
84.5
91.7
96.9
78.8

truck Avg
49.6
3.8
67.0
16.3
73.1
0.0
79.7
40.5
80.1
49.4
80.9
67.0

plane
76.4
91.4
96.7
91.7
77.0
89.0

bcycl
26.4
68.9
88.3
84.8
84.6
79.5

bus
60.2
69.6
89.0
86.6
85.1
84.3

car
80.2
89.9
94.1
88.7
92.0
81.0

8.2
26.1
48.4
46.3
49.1
38.7

89.4
92.8
89.4
92.8
92.6
92.5

Settings Methods

B2UDA

WBUDA

UDA

U→M
82.0
83.4
91.8

M→U
79.4
81.2
89.3

S→M
69.4
69.9
97.3
96.7±0.3 98.0±0.7 97.4±0.1
75.5
99.3±0.1 99.4±0.1 97.3±0.2
98.9
86.3±0.3 85.5±0.4 84.9±0.6
96.2±0.4 96.5±0.3

Source Model
sMDA [4]
PLR [27]
IterLNL
SDDA [18]
3C-GAN [22]
SHOT [23]
DANN [5]
MCD [36]
CDAN [25]
RWOT [43]
Table 2. Results on Digits dataset.

89.2
97.5±0.2 98.8±0.1 98.5±0.2

–
98.0

98.0

89.9

98.4

95.6

–

IterLNL (w/o CateS) and IterLNL (w/o Iter) signiﬁcantly,
justifying the efﬁcacy of category-wise sampling (11)
and iterative learning strategy. Speciﬁcally, without the
category-wise sampling (11), the accuracy of samples in
the knife and truck categories drops to zero due to the ini-
tial high noise rate (i.e., low accuracy) in Source Model.
We also intuitively visualize the accuracy improvement of
model F in the iterative learning process (i.e., with different
m ∈ [1, M ]). As illustrated in Figure 4(a), the accuracy of
F via LNL indeed improves over that of initial noisy labels
in the beginning; the improvement is gradually reduced as
the iterative step m increases, leading to the ﬁnal conver-
gence. Additionally, IterLNL improves over IterLNL (w/o
Rescale) and approximate to results of IterLNL (with Val);
this is intuitively explained in Figure 4(b), where IterLNL
(with Val) presents the most accurate noise rate estima-
tion, and IterLNL achieves more accurate estimation than
IterLNL (w/o Rescale) in most cases. The source model
(i.e., m=1) tends to make un-conﬁdent predictions on target
data due to the domain divergence while target models (i.e.,
m>1) are prone to make over-conﬁdent predictions, moti-
vating us to introduce the rescale curve (9) in Figure 2(d).

4.2. Analysis

Analyses on γ and κ. We investigate the hyper-parameters
γ (8) and κ (9) on the Digits datasets considering the exper-
imental speed. As illustrated in Figure 5, IterLNL performs
robustly under a wide range of values. We adopt γ = 0.9

(a) Acc. in iterative process

(b) Noise rate (cid:15)

i }nt
Figure 4. Illustration of (a) the accuracy of noisy labels {(cid:98)yt
i=1
and target model F via LNL, and (b) the estimated noise rate
in different iterative steps. ‘GT’, ‘with Val’, ‘IterLNL’ and ‘w/o
Rescale’ indicate the noise rate calculated by all labeled target
data (7), labeled validation data, our strategy (10), and 1 − ρ(cid:48),
respectively. Note that the noise rate estimation and accuracy of
noisy labels with m = 1 are based on predictions of the black-box
source model (cid:98)F s.

number of training iterations deﬁned in Algorithm 1) in (6)
for all experiments; these hyperparameters are analyzed in
Section 4.2.

4.1. Ablation Study

We introduce several variants of IterLNL to investigate
the individual components in IterLNL. Speciﬁcally, follow-
ing [10], we replace the category-wise sampling (11) by
simply using the R(n) percent samples with smaller losses
in the n-th iteration for model learning, leading to ‘IterLNL
(w/o CateS)’. We also present the results of IterLNL by
conducting noisy labeling and learning with noisy labels
only once (i.e., setting M = 1 in Algorithm 1), resulting
in ‘IterLNL (w/o Iter)’. To investigate the noise rate esti-
mation strategy, we remove the rescale strategy (9) and set
(cid:15) = 1 − ρ(cid:48), leading to ‘IterLNL (w/o Rescale)’; we also in-
troduce a labeled target validation set by randomly selecting
30 samples per class (less than 1% of the entire target data
in VisDA-2017); we estimate the noise rate (cid:15) by calculating
the classiﬁcation accuracy α of (cid:98)F on the validation set and
approximating the noise rate (cid:15) as 1 − α, which is termed as
‘IterLNL (with Val)’.

As illustrated in Table 1, IterLNL improves over the

12345678910Iterative step m0.500.550.600.650.700.750.80Acc (%)Noisy labelsTarget model12345678910Iterative step m0.10.20.30.40.50.6Noise rateGTwith ValIterLNLw/o RescaleTasks

B2UDA

WBUDA

UDA

Method
Source Model [16]
sMDA [4]
IterLNL
SDDA [18]
SHOT [23]
3C-GAN [22]
DANN [5]
CDAN [25]
SymNets [50]
RWOT [43]

A→D
79.7
80.5
91.3±0.1
85.3
94.0
92.7±0.4
79.7±0.4
92.9±0.2
93.9±0.5
94.5±0.2

A→W
78.1
79.3
89.8±0.7
82.5
90.1
93.7±0.2
82.0±0.4
94.1±0.1
90.8±0.1
95.1±0.2

D→A
64.9
65.7
74.3±0.8
66.4
74.7
75.3±0.5
68.2±0.4
71.0±0.3
74.6±0.6
77.5±0.1

D→W
96.0
96.3
98.7±0.2
99.0
98.4
98.5±0.1
96.9±0.2
98.6±0.1
98.8±0.3
99.5±0.2

W→A
65.4
67.3
73.7±0.1
67.7
74.3
77.8±0.1
67.4±0.5
69.3±0.3
72.5±0.5
77.9±0.3

W→D
99.2
99.2
99.3±0.3
99.8
99.9
99.8±0.2
99.1±0.1
100.0±.0
100.0±.0
100.0±.0

Avg
80.1
81.4
87.9
83.5
88.6
89.6
82.2
87.7
88.4
90.8

Table 3. Results on Ofﬁce31 dataset, where all methods are based on a ResNet-50 model.

Tasks

A

D

U

2

B

A

D

U

W B

A

D

U

Methods
Source Model [16]
sMDA [4]
SoFA [46]
IterLNL
3C-GAN [22]
SHOT [23]
DANN [5]
MCD [36]
RWOT [43]

plane

76.4
77.8
–
77.0
94.8
94.3
81.9
87.0
95.1

bcycl

26.4
39.3
–
84.6
73.4
88.5
77.7
60.9
80.3

bus
60.2
66.1
–
85.1
68.8
80.1
82.8
83.7
83.7

car
80.2
73.7
–
92.0
74.8
57.3
44.3
64.0
90.0

horse

73.5
74.3
–
92.1
93.1
93.1
81.2
88.9
92.4

knife

2.3
4.2
–
74.1
95.4
94.9
29.5
79.6
68.0

mcycl

89.4
87.9
–
92.6
88.6
80.7
65.1
84.7
92.5

person

8.2
16.7
–
49.1
84.7
80.3
28.6
76.9
82.2

plant

79.7
79.8
–
89.1
89.1
91.5
51.9
88.6
87.9

sktbrd

25.6
36.9
–
91.7
84.7
89.1
54.6
40.3
78.4

train

69.4
71.4
–
84.5
83.5
86.3
82.8
83.0
90.4

truck

3.8
9.8
–
49.4
48.1
58.2
7.8
25.8
68.2

Avg
49.6
53.1
60.4
80.1
81.6
82.9
57.4
71.9
84.0

Table 4. Results on VisDA-2017 dataset, where all methods are based on a ResNet-101 model.

ble 4, respectively. Most comparable results are directly re-
ported from their original papers, except the Source Model
[16] and sMDA [4], which are implemented by ourselves.
Taking advantages of feature learning, our IterLNL im-
proves over existing methods of B2UDA [4, 46] signiﬁ-
cantly; for example, IterLNL improves over sMDA [4] and
SoFA [46] by 27.0% and 19.7% on the VisDA-2017 dataset
respectively; our IterLNL also improves over [27] by pre-
senting good generalization on various benchmark datasets.
Although we only use the black-box source model for the
transfer use in target domain, IterLNL achieves compara-
ble results to methods of WBUDA, where the white-box
source model is required, and traditional UDA, where la-
beled source data are required.

5. Conclusion and Broader Impact

Considering that the source model itself may not be
available due to commercial and/or safety considerations
[29], we investigate the B2UDA task, and propose a base-
line algorithm of IterLNL. We verify its efﬁcacy on popular
DA benchmarks with thorough experiments. The B2UDA
task is of broad practical value since it could further im-
prove the utilities of APIs as cloud services, pushing the
DA research closer to practical applications.

(a) Results with various γ

(b) Results with various κ

Figure 5. IterLNL’s results with various values of γ (8) and κ (9).

and κ = 2.0 in all experiments; such simple settings work
well but not necessarily lead to the best results. Similar re-
sults are also observed in the study of buffer length h in
Section 3.2 and nk (6), as presented in the appendices.
Comparison with LNL Method. We conduct the LNL
method Co-teaching [10] with our estimated noise rate (cid:15)
(10) and noisy labels {(cid:98)yt
i=1 introduced by the black-box
source model (cid:98)F s on the S→M task. The result of 91.0%
with Co-teaching is lower than 98.0% with IterLNL, justi-
fying the advantage of IterLNL over vanilla LNL method
on B2UDA.

i }nt

4.3. Results

The results of IterLNL on datasets of Digits, Ofﬁce31,
and VisDA-2017 are illustrated in Table 2, Table 3, and Ta-

0.50.70.80.90.950.99Values of 80.082.585.087.590.092.595.097.5100.0Acc (%)SMUMMU1.01.52.03.05.0Values of 80.082.585.087.590.092.595.097.5100.0Acc (%)SMUMMUReferences

[1] Sk Miraj Ahmed, Aske R Lejbolle, Rameswar Panda, and
Amit K Roy-Chowdhury. Camera on-boarding for person
re-identiﬁcation using hypothesis transfer learning. In Pro-
ceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition, pages 12144–12153, 2020. 2
[2] Devansh Arpit, Stanisław Jastrz˛ebski, Nicolas Ballas, David
Krueger, Emmanuel Bengio, Maxinder S Kanwal, Tegan
Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio,
et al. A closer look at memorization in deep networks. arXiv
preprint arXiv:1706.05394, 2017. 4

[3] Shai Ben-David,

John Blitzer, Koby Crammer, Alex
Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan.
A theory of learning from different domains. Machine learn-
ing, 79(1-2):151–175, 2010. 1

[4] Boris Chidlovskii, Stephane Clinchant, and Gabriela Csurka.
Domain adaptation in the absence of source domain data. In
Proceedings of the 22nd ACM SIGKDD International Con-
ference on Knowledge Discovery and Data Mining, pages
451–460, 2016. 2, 7, 8

[5] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pas-
cal Germain, Hugo Larochelle, François Laviolette, Mario
Marchand, and Victor Lempitsky. Domain-adversarial train-
ing of neural networks. The Journal of Machine Learning
Research, 17(1):2096–2030, 2016. 1, 2, 3, 6, 7, 8

[6] Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger.
On calibration of modern neural networks. arXiv preprint
arXiv:1706.04599, 2017. 5

[7] Bo Han, Gang Niu, Xingrui Yu, Quanming Yao, Miao Xu,
Ivor Tsang, and Masashi Sugiyama. Sigua: Forgetting may
In Interna-
make learning with noisy labels more robust.
tional Conference on Machine Learning, pages 4006–4016.
PMLR, 2020. 2

[8] Bo Han, Jiangchao Yao, Gang Niu, Mingyuan Zhou, Ivor
Tsang, Ya Zhang, and Masashi Sugiyama. Masking: A new
perspective of noisy supervision. NIPS, 2018. 2

[9] Bo Han, Quanming Yao, Tongliang Liu, Gang Niu, Ivor W
Tsang, James T Kwok, and Masashi Sugiyama. A survey of
label-noise representation learning: Past, present and future.
arXiv preprint arXiv:2011.04406, 2020. 2

[10] Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao
Xu, Weihua Hu, Ivor Tsang, and Masashi Sugiyama. Co-
teaching: Robust training of deep neural networks with ex-
tremely noisy labels. In Advances in neural information pro-
cessing systems, pages 8527–8537, 2018. 2, 4, 7, 8

[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
Deep residual learning for image recognition. In Proceed-
ings of the IEEE conference on computer vision and pattern
recognition, pages 770–778, 2016. 6

[12] Dan Hendrycks and Kevin Gimpel. A baseline for detect-
ing misclassiﬁed and out-of-distribution examples in neural
networks. ICLR, 2017. 4, 5

[13] Yunzhong Hou and Liang Zheng.

main adaptation with image translation.
arXiv:2008.07514, 2020. 1, 2

Source free do-
arXiv preprint

[14] Jonathan J. Hull. A database for handwritten text recogni-
IEEE Transactions on pattern analysis and

tion research.
machine intelligence, 16(5):550–554, 1994. 6

[15] Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and
Li Fei-Fei. Mentornet: Learning data-driven curriculum for
very deep neural networks on corrupted labels. In Interna-
tional Conference on Machine Learning, pages 2304–2313.
PMLR, 2018. 2, 4

[16] Mingsheng Long Junguang Jiang, Bo Fu.

Transfer-
https://github.com/thuml/

learning-library.
Transfer-Learning-Library, 2020. 6, 7, 8

[17] Youngeun Kim, Sungeun Hong, Donghyeon Cho, Hy-
oungseob Park, and Priyadarshini Panda. Domain adaptation
without source data. arXiv preprint arXiv:2007.01524, 2020.
2

[18] Vinod K Kurmi, Venkatesh K Subramanian, and Vinay P
Namboodiri. Domain impression: A source data free domain
adaptation method. In Proceedings of the IEEE/CVF Winter
Conference on Applications of Computer Vision, pages 615–
625, 2021. 2, 7, 8

[19] Ilja Kuzborskij and Francesco Orabona. Stability and hy-
In International Conference on

pothesis transfer learning.
Machine Learning, pages 942–950. PMLR, 2013. 2

[20] Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick
Haffner. Gradient-based learning applied to document recog-
nition. Proceedings of the IEEE, 86(11):2278–2324, 1998.
6

[21] Dong-Hyun Lee.

Pseudo-label: The simple and efﬁ-
cient semi-supervised learning method for deep neural net-
works. In Workshop on challenges in representation learn-
ing, ICML, volume 3, page 2, 2013. 5

[22] Rui Li, Qianfen Jiao, Wenming Cao, Hau-San Wong, and
Si Wu. Model adaptation: Unsupervised domain adapta-
tion without source data. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition
(CVPR), June 2020. 2, 3, 7, 8

[23] Jian Liang, Dapeng Hu, and Jiashi Feng. Do we really
need to access the source data? source hypothesis trans-
arXiv preprint
fer for unsupervised domain adaptation.
arXiv:2002.08546, 2020. 1, 2, 3, 6, 7, 8

[24] Mingsheng Long, Yue Cao, Jianmin Wang, and Michael I.
Jordan. Learning transferable features with deep adaptation
In Proceedings of the 32Nd International Con-
networks.
ference on International Conference on Machine Learning -
Volume 37, ICML’15, pages 97–105. JMLR.org, 2015. 1, 2,
3, 6

[25] Mingsheng Long, Zhangjie Cao,

Jianmin Wang, and
Michael I Jordan. Conditional adversarial domain adapta-
tion. In Advances in Neural Information Processing Systems,
pages 1640–1650, 2018. 1, 7, 8

[26] Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I
Jordan. Deep transfer learning with joint adaptation net-
works. arXiv preprint arXiv:1605.06636, 2016. 6

[27] Pietro Morerio, Riccardo Volpi, Ruggero Ragonesi, and
Vittorio Murino. Generative pseudo-label reﬁnement for
In Proceedings of the
unsupervised domain adaptation.
IEEE/CVF Winter Conference on Applications of Computer
Vision, pages 3130–3139, 2020. 2, 7, 8

[43] Renjun Xu, Pelen Liu, Liyan Wang, Chao Chen, and Jindong
Wang. Reliable weighted optimal transport for unsupervised
domain adaptation. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition, pages
4394–4403, 2020. 7, 8

[44] Hansi Yang, Quanming Yao, Bo Han, and Gang Niu. Search-
ing to exploit memorization effect in learning from corrupted
labels. arXiv preprint arXiv:1911.02377, 2019. 4

[45] Shiqi Yang, Yaxing Wang, Joost van de Weijer, and Luis Her-
ranz. Unsupervised domain adaptation without source data
by casting a bait. arXiv preprint arXiv:2010.12427, 2020. 1,
2, 3

[46] Hao-Wei Yeh, Baoyao Yang, Pong C Yuen, and Tatsuya
Harada.
Sofa: Source-data-free feature alignment for
In Proceedings of the
unsupervised domain adaptation.
IEEE/CVF Winter Conference on Applications of Computer
Vision, pages 474–483, 2021. 2, 8

[47] Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lip-
son. How transferable are features in deep neural networks?
arXiv preprint arXiv:1411.1792, 2014. 2

[48] Xiyu Yu, Tongliang Liu, Mingming Gong, Kayhan Bat-
manghelich, and Dacheng Tao. An efﬁcient and provable
approach for mixture proportion estimation using linear in-
dependence assumption. In Proceedings of the IEEE Con-
ference on Computer Vision and Pattern Recognition, pages
4480–4489, 2018. 4

[49] Yuchen Zhang, Tianle Liu, Mingsheng Long, and Michael
Jordan. Bridging theory and algorithm for domain adap-
In International Conference on Machine Learning,
tation.
pages 7404–7413, 2019. 1

[50] Yabin Zhang, Hui Tang, Kui Jia, and Mingkui Tan. Domain-
symmetric networks for adversarial domain adaptation.
In
Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, pages 5031–5040, 2019. 1, 8
[51] Zhilu Zhang and Mert R Sabuncu. Generalized cross en-
tropy loss for training deep neural networks with noisy la-
bels. arXiv preprint arXiv:1805.07836, 2018. 2
[52] Tianyi Zhou, Shengjie Wang, and Jeff Bilmes.

Time-
consistent self-supervision for semi-supervised learning. In
International Conference on Machine Learning (ICML),
2020. 5

[53] Yang Zou, Zhiding Yu, BVK Kumar, and Jinsong Wang.
Unsupervised domain adaptation for semantic segmentation
via class-balanced self-training. In Proceedings of the Eu-
ropean conference on computer vision (ECCV), pages 289–
305, 2018. 6

[28] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bis-
sacco, Bo Wu, and Andrew Y Ng. Reading digits in natural
images with unsupervised feature learning. 2011. 6

[29] OpenAI. Why did openai choose to release an api instead of
open-sourcing the models? [EB/OL]. https://openai.
com/blog/openai-api/ Accessed March 4, 2021. 1,
2, 3, 8

[30] Sinno Jialin Pan, Qiang Yang, et al. A survey on transfer
learning. IEEE Transactions on knowledge and data engi-
neering, 22(10):1345–1359, 2010. 1

[31] Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon,
Richard Nock, and Lizhen Qu. Making deep neural networks
In Pro-
robust to label noise: A loss correction approach.
ceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pages 1944–1952, 2017. 4

[32] Xingchao Peng, Ben Usman, Neela Kaushik, Judy Hoffman,
Dequan Wang, and Kate Saenko. Visda: The visual domain
arXiv preprint arXiv:1710.06924,
adaptation challenge.
2017. 6

[33] Harish Ramaswamy, Clayton Scott, and Ambuj Tewari. Mix-
ture proportion estimation via kernel embeddings of distri-
In International conference on machine learning,
butions.
pages 2052–2060. PMLR, 2016. 4

[34] Scott Reed, Honglak Lee, Dragomir Anguelov, Christian
Szegedy, Dumitru Erhan, and Andrew Rabinovich. Train-
ing deep neural networks on noisy labels with bootstrapping.
arXiv preprint arXiv:1412.6596, 2014. 4

[35] Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Dar-
rell. Adapting visual category models to new domains. In
European conference on computer vision, pages 213–226.
Springer, 2010. 6

[36] Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tat-
suya Harada. Maximum classiﬁer discrepancy for unsuper-
vised domain adaptation. In Proceedings of the IEEE Con-
ference on Computer Vision and Pattern Recognition, pages
3723–3732, 2018. 1, 6, 7, 8

[37] Sainbayar Sukhbaatar,

Joan Bruna, Manohar Paluri,
Lubomir Bourdev, and Rob Fergus. Training convolutional
networks with noisy labels. ICLRW, 2015. 2

[38] Simen Thys, Wiebe Van Ranst, and Toon Goedemé. Fooling
automated surveillance cameras: adversarial patches to at-
tack person detection. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition Work-
shops, pages 0–0, 2019. 1, 3

[39] Florian Tramèr, Alexey Kurakin, Nicolas Papernot, Ian
Goodfellow, Dan Boneh, and Patrick McDaniel. Ensemble
adversarial training: Attacks and defenses. arXiv preprint
arXiv:1705.07204, 2017. 1, 3

[40] Brendan Van Rooyen, Aditya Krishna Menon, and Robert C
Williamson. Learning with symmetric label noise: The im-
portance of being unhinged. NIPS, 2015. 2, 4

[41] Brendan Van Rooyen and Robert C Williamson. A theory
J. Mach. Learn. Res.,

of learning with corrupted labels.
18(1):8501–8550, 2017. 2

[42] Markus Weber, Max Welling, and Pietro Perona. Unsuper-
vised learning of models for recognition. In European con-
ference on computer vision, pages 18–32. Springer, 2000. 2

