Boosting on the shoulders of giants in quantum device calibration

Alex Wozniakowski,1, 2,

∗ Jayne Thompson,3 Mile Gu,1, 2, 3,

† and Felix Binder4
1School of Physical and Mathematical Sciences, Nanyang Technological University
2Complexity Institute, Nanyang Technological University
3Centre for Quantum Technologies, National University of Singapore
4Institute for Quantum Optics and Quantum Information – IQOQI Vienna,
Austrian Academy of Sciences, Boltzmanngasse 3, 1090 Vienna, Austria
(Dated: May 14, 2020)

0
2
0
2

y
a
M
3
1

]
h
p
-
t
n
a
u
q
[

1
v
4
9
1
6
0
.
5
0
0
2
:
v
i
X
r
a

Traditional machine learning applications, such as optical character recognition, arose from the
In this context, learning
inability to explicitly program a computer to perform a routine task.
algorithms usually derive a model exclusively from the evidence present in a massive dataset. Yet in
some scientiﬁc disciplines, obtaining an abundance of data is an impractical luxury, however; there is
an explicit model of the domain based upon previous scientiﬁc discoveries. Here we introduce a new
approach to machine learning that is able to leverage prior scientiﬁc discoveries in order to improve
generalizability over a scientiﬁc model. We show its eﬃcacy in predicting the entire energy spectrum
of a Hamiltonian on a superconducting quantum device, a key task in present quantum computer
calibration. Our accuracy surpasses the current state-of-the-art by over 20%. Our approach thus
demonstrates how artiﬁcial intelligence can be further enhanced by “standing on the shoulders of
giants.”

Keywords: Multi-target Regression, Machine Learning, Quantum Computing

Prediction is paramount in almost every branch of sci-
In studying and designing learning systems, we
ence.
are interested in prediction performance on examples un-
encountered during training. As machines learn induc-
tively, generalizing training examples into an accurate
model requires some restriction on the search space of hy-
potheses, based upon prior knowledge [1–4]. The choice
of hypothesis space constitutes the problem of inductive
bias [2–6], which is of broad signiﬁcance in scientiﬁc ap-
plications.

Some scientiﬁc applications, such as quantum exper-
iments, provide a paucity of data due to experimental
cost, but compensate with an explicit model based upon
previous discoveries [7–11].
In prior work, this prior
knowledge has been disregarded, and research has fo-
cused on entirely data-driven approaches that reproduce
major scientiﬁc achievements or learn from toy data [12–
19]. This leads us to ask if a machine learner can leverage
prior scientiﬁc knowledge in order to outperform con-
temporary researchers? Particularly in scenarios with a
shortage of experimental data.

Here, we introduce a new framework that restricts a
learning algorithm’s search space of hypotheses. It does
so by leveraging prior knowledge contained in predictions
generated by a scientiﬁc model (see Fig. 1). In contrast
to conventional supervised learning, we focus on the si-
multaneous prediction of multiple real variables, which is
known as multi-target regression [5, 20–22]. This enables
the learning algorithm to improve generalizability over
the scientiﬁc model by discovering relationships among
the targets, which the model did not envisage. In prin-

∗wozn0001@e.ntu.edu.sg
†mgu@quantumcomplexity.org

ciple, this approach shares similarities with neuroplas-
ticity, whereby the nervous system is able to adapt and
optimize its limited resources in response to sensory ex-
periences [23].

To test our learning system, we establish a proxy of ex-
pert human-level performance on the calibration bench-
mark task of simultaneously predicting the entire energy
spectrum of a Hamiltonian on a superconducting quan-
tum device [8, 10, 11, 24].
In this scenario, there is a
shortage of data due to operational cost of the exper-
iment [8]. The explicit scientiﬁc model of the device’s
quantum behavior is state-of-the-art [8, 10, 11]. We
demonstrate that our learning system surpasses this base-
line of expert human-level performance by over 20% (see
Fig. 2). Consequently, we advance the current ability
to precisely generate Hamiltonians with programmable
parameters for a variety of quantum simulation applica-
tions. Our result complements other recent applications
of machine learning in scientiﬁc settings, and more specif-
ically quantum systems [7, 9, 12–19, 25–31]. To interpret
our results we use techniques from explainable machine
learning [32, 33] to uncover parameter dependencies in
the original scientiﬁc model.

Results

Benchmark task – In order to establish a proxy of
expert human-level performance for the analysis of our
learning system, we study a superconducting qubit archi-
tecture [24]. The quantum device is a nearest-neighbor
coupled linear chain of superconducting qubits with tun-
able qubit frequencies and tunable inter-qubit interac-
tions [8, 10, 11, 24]. Each qubit is embedded in the
subspace spanned by the ground state and ﬁrst excited
state of a nonlinear photonic resonator in the microwave

 
 
 
 
 
 
2

FIG. 1: Conceptual representation of the learning framework.
Given a base regressor’s initial multi-target predictions and
the multi-target observations, we wrangle this data for multi-
target supervised learning [20, 21]. Next, the boosting algo-
rithm receives the training examples and acquires an induc-
tive bias from the initial predictions. This compensates for
a shortage of training examples, and the boosting algorithm
improves generalizability over the base regressor. Given a new
example, the boosting algorithm’s returned regressor predicts
a real vector.

FIG. 2: Benchmark task. Using the learning framework in
Fig. 1, our learning system surpasses the state-of-the-art [8,
10, 11] by over 20% on the calibration task of simultaneously
predicting the entire energy spectrum of a Hamiltonian Eq. 1
on a nearest-neighbor coupled linear chain of superconducting
qubits. Moreover, our learning system outperforms the state-
of-the-art on each individual prediction task, i.e., Yj, where
j

1, 2, . . . , 5

.

∈ {

}

regime. The total Hamiltonian of the device is approxi-
mately described by the Bose-Hubbard model truncated
at two local excitations

present context of machine learning, we refer to these
variables as single-targets and to their collection as a
multi-target (details in Methods).

=

H

+

n

j=1
(cid:88)
1
n
−

j=1
(cid:88)

δj ˆa†j ˆaj +

L
2

ˆa†j ˆaj(ˆa†j ˆaj −

1)

gj,j+1(ˆa†j ˆaj+1 + ˆaj ˆa†j+1),

(1)

where n > 1 is the number of qubits, ˆa† (ˆa) is the bosonic
creation (annihilation) operator, δj is the random on-site
detuning, L is the on-site Hubbard interaction, and gj,j+1
is the hopping rate between nearest neighbor lattice sites.
Quantum evolution is typically realized by allowing the
entire system to interact at once, which also admits trans-
lation into the prototypical quantum circuit model [10].
In the benchmark task, the device contains 9 qubits.
The n = 5 rightmost qubits and 4 interleaving cou-
plers were utilized during experimentation, while the 4
leftmost qubits and couplers were left idle. The de-
vice is being calibrated for a many-body localization
experiment [8, 11], where diﬀerent relaxation dynam-
ics are observed, depending on the extent of random
disorder in the system. Probing this quantum phe-
nomenon requires study of the entire energy spectrum,
which be achieved experimentally through many-body
Ramsey spectroscopy [8].

Here, we focus on the identiﬁcation of 5 eigenenergies
belonging to Eq. 1, when it describes hopping of a single
photon in a disordered potential. The energy eigenstates
are generally not local and each instance of the many-
body Ramsey spectroscopy technique sorts the measured
eigenenergies in ascending order: Y1, Y2, . . . , Y5. In the

The calibration is performed in two steps [8, 10, 11],
where the benchmark dataset pertains to the second step.
In the ﬁrst step, the room temperature time-dependent
pulses that orchestrate the computation are calibrated
to arrive at the device: orthogonally, synchronously, and
without pulse-distortion [10]. In the second step, the con-
trol pulses are converted to matrix elements of the Hamil-
tonian Eq. 1. Underlying this conversion is a ﬁnitely
parameterized model of the device’s electronic circuitry,
which is directly encoded in the classical control pro-
gram [8, 10, 11].

Inferring the physical parameters of the control model
entails ﬁtting the two lowest transition energies of each
qubit as a function of qubit and coupler ﬂux-biases [10].
Next, the many-body Ramsey spectroscopy technique
benchmarks the collective dynamics of the device, where
all of the qubits are coupled and near resonance with each
other [8, 11]. Then, minimization of the absolute error
loss function, which compares the multi-targets with the
multi-target predictions generated by the classical control
program, numerically optimizes the physical parameters
(see Eq. 5 in Methods). Lastly, the updated classical con-
trol program generates 136 multi-target predictions for
the 136 multi-targets in the benchmark task. Using 41 of
these multi-targets and the corresponding predictions, we
compute the mean absolute errors for the single-targets
and the average mean absolute error for the multi-targets
(see Eq. 8 and Eq. 9 in Methods). We refer to the 1.34
MHz average mean absolute error as the benchmark er-
ror in Fig. 2. Using this benchmark error, we establish a
proxy of expert human-level performance on the bench-

mark task. As the estimated optimal error rate, set by
the coherence time of the device, is 1MHz [8], we ask the
algorithm design question: can we do better?

Using the classical control program, this would re-
quire us to directly write the higher order terms in
the Hamiltonian, environmental interactions, manufac-
turing or operational errors, etc., for every recalibration.
Clearly this strategy is impractical within recalibration
timescales [34, 35]. Therefore, we propose a paradigm
shift, whereby we incorporate the prior knowledge in the
classical control program into a boosting algorithm whose
primary goal is to discover a more accurate model of the
domain (see Fig. 2). In this way, we can feedback im-
proved multi-target predictions to the optimization step
in the calibration process and update the physical pa-
rameters in the control model [10]. Thus, enhancing the
ability to generate Hamiltonians with programmable pa-
rameters for a variety of quantum simulation applica-
tions.

Learning Framework – Multi-target regression aims
to simultaneously predict multiple real variables, and re-
search in this direction is intensifying [20, 21]. Here, we
introduce a two-step stacking [20, 21, 36–38] framework
that supplies a boosting algorithm with an inductive bias
contained in the initial multi-target predictions generated
by a base regressor (details in Methods). In essence, the
base regressor acts as data preprocessor and the boosting
algorithm assays to improve generalization performance
by discovering relationships among the single-targets.
This approach is related to multi-target regularization,
which reduces the problem of overﬁtting [20, 21, 38], as
well as methods in deep learning, such as pre-training [39]
and weight sharing [5].

In applying the learning framework to the benchmark
dataset, the ﬁrst step wrangles the data for multi-target
supervised learning [20, 21]. Namely, we regard a multi-
target prediction generated by the classical control pro-
gram [8, 10, 11] as an example and the associated instance
of the many-body Ramsey spectroscopy technique [8] as
the label. Under the distribution-free setting [40–45],
we split the labeled examples into mtrain = 95 and
mtest = 41 ordered pairs for training and test data,
respectively, where the choice of splitting fraction is a
heuristic [45, 46].
In the second step, a boosting algo-
rithm receives the training examples with pairwise cor-
relations shown in Fig. 3, and we request a multi-target
regressor ˆh as output. The boosting algorithm proceeds
by reducing the multi-target regression task to 5 inde-
pendent single-target regression subtasks [20, 21]. For
the jth single-target regression subtask, the jth single-
target boosting algorithm induces the single-target re-
gressor ˆhj on the jth slice of the training examples, where
j =
(see Eq. 11 in Methods). Subsequently,
the boosting algorithm concatenates the single-target re-
gressors into a multi-target regressor. Given a new exam-
ple X, the multi-target regressor predicts a 5-dimensional
real vector ˆY = ˆh(X).

1, 2, . . . , 5
}
{

Gradient boosting prior knowledge – Boosting

3

FIG. 3: Pairwise correlations in the training examples. We
denote the features in each example by Xj, and the single-
targets in each multi-target by Yj, where j
is
the number of superconducting qubits utilized in the bench-
mark task [8, 10, 11].

1, 2, . . . , 5

∈ {

}

is an algorithmic paradigm for improving the perfor-
mance of any given learning algorithm, interconnecting
machine learning [47–58], statistics [43–45, 59, 60] and
signal processing [61–63] through the study of additive
expansions [43, 45, 49, 60]. Gradient boosting is a generic
version of boosting, which is widely used in practice [43–
45, 57, 58, 64], and the additive expansion is designed
to ﬁnesse the curse of dimensionality and provide ﬂex-
ibility over linear models [43–45, 49, 60]. Nonetheless,
the standard form of gradient boosting does not allow
for the direct incorporation of prior knowledge, which is
essential in the benchmark task.

Here, we propose a modiﬁcation of the standard addi-
tive expansion [43–45, 57, 58, 64] for the jth single-target
regression subtask

hj(X;

αj, θj}
{

) = Xj +

Kj

(cid:88)k=1

αj,kb(X; θj,k)),

(2)

{

sets θj,k

is given by

αj, θj}
, and Kj denotes

where the collection of expansion coeﬃcients αj,k
and parameter
=
the
αj,1, . . . , αj,Kj , θj,1, . . . , θj,Kj }
{
number of real-valued basis functions b(X; θj,k) of the
example X (details in Methods). In the standard addi-
tive expansion, the ﬁrst term is a constant oﬀset value
that does not depend upon the example, and it is usu-
ally determined by maximum likelihood estimation [43–
45, 49, 60]. In the work of Schapire et al, prior knowledge
was incorporated into the G¨odel prize winning AdaBoost
algorithm by modifying the loss function for single-target
classiﬁcation tasks [56]. In machine learning, the basis
function is called a weak learner [48, 50–54, 56], and
the predominant choice is a shallow decision tree [43–
45, 57, 58, 64]. Taking a reroughing viewpoint [59], Eq. 2
decomposes the jth single-target into a smooth term,
i.e., the ﬁrst term, and a noise term, i.e., the linear sum

of basis functions. In the application, the classical con-
trol program [8, 10, 11] generates the smooth term and
the noise term adaptively models the relationships be-
tween the single-targets in Fig. 3 without overwhelming
the prior knowledge (see Supplementary Information).

In practice, ﬁtting an additive expansion by mini-
mizing the data-based estimate of the jth single-target
expected loss is usually infeasible [43–45, 60–63] (see
Eq. 6 in Methods). Here, we employ a greedy stage-
wise algorithm to approximate this optimization prob-
lem, whereby the stagewise algorithm sequentially ap-
pends basis functions to the additive expansion without
adjusting the previously learned expansion coeﬃcients or
parameter sets, as opposed to a stepwise algorithm [43–
45, 60–63] (see Alg. 1 in Methods). As a result of modi-
fying the standard additive expansion in Eq. 2, the learn-
ing framework directly incorporates prior knowledge into
gradient boosting [43–45, 57, 58, 64] by changing the ini-
tialization step (details in Methods). As an aside, this
idea can be applied in compressed sensing by similarly
changing the initialization step in matching pursuit and
its extensions [61–63].

Inbuilt model selection – The greedy stagewise al-
gorithm does not always improve performance over the
smooth term. Hence, we introduce an augmented version
with inbuilt model selection, which scores the incum-
bent smooth term and the candidate greedy stagewise
algorithm with a modiﬁcation of k-fold cross-validation
(details in Methods). If the incumbent performs better
or equally well, then the augmented version returns the
smooth term as the induced single-target regressor. Oth-
erwise, the augmented version calls the candidate (see
Alg. 2 in Methods).

In Fig. 4, we illustrate the model selection step with
an augmented learning curve for the single-target regres-
sion subtask Y3 with training sizes varying between 23
to 95 ordered pairs. Here, the augmented learning curve
shows the incumbent error (red) in addition to the train-
ing and cross-validation errors (blue and yellow) shown
in a prototypical learning curve [22, 45, 46]. The incum-
bent error bounds the cross-validation error from above.
As the training size increases, the training error tends to
increase, the cross-validation error tends to decrease, and
both errors exhibit random ﬂuctuations, which typically
occur with less than 100 ordered pairs [46]. When there
are less than 51 ordered pairs, the incumbent usually per-
forms better, whereas the candidate always outperforms
the incumbent with 51, or more, ordered pairs.

For the single-target regression subtasks Y1, Y2, and
Y5, the candidate always performs better, and in general
the candidate always performs better with 60, or more,
ordered pairs (see Supplementary Information). Thus,
the boosting algorithm used the greedy stagewise algo-
rithm in each single-target regression subtask in Fig. 2,
where the boosting algorithm outperforms the baseline of
expert human-level performance [8, 10, 11] by over 20%.
Examining the prior knowledge – Data prepro-
cessing can signiﬁcantly impact generalization perfor-

4

FIG. 4: Augmented learning curve for the single-target Y3.
We show the training, cross-validation, and incumbent errors
for varying amounts of training examples in blue, orange, and
red, respectively. As a consequence of the inbuilt model se-
lection step, the cross-validation error is bounded from above
by 0.87 MHz. With 51, or more, ordered pairs the candidate
greedy stagewise algorithm always outperforms the incum-
bent smooth term [8, 10, 11].

mance, especially if there is a shortage of training ex-
amples [22, 39]. Here, we examine the classical control
program [8, 10, 11] as a data preprocessor for the down-
stream boosting algorithm, whereby the classical control
program transforms 5 qubit and 4 coupler bias features
from an instance of the spectroscopy protocol [8] into an
initial multi-target prediction (see Supplementary Infor-
mation). Namely, we regard a collection of 5 qubit and
4 coupler bias features as an example, and we induce a
fully-connected neural network [22] for each single-target.
Next, we apply the SHAP framework to approximate
each induced neural network with a simpler linear ex-
planation model [32] (see Eq. 12 in Methods). The linear
coeﬃcients, known as SHAP values, allocate the impor-
tance of each feature for each single-target training data
prediction [32, 33].

In Fig. 5, we acquire an overview of each feature’s im-
portance and eﬀect in the single-target regression subtask
Y1 [32, 33] (see Eq. 13 in Methods; see Supplementary
Information for additional SHAP summary plots). The
features are ascendingly ordered from bottom to top ac-
cording to their importance, a point represents a SHAP
value, and the coloring represents the bias value, e.g., a
reddish point for the coupler 5/6 bias feature illustrates
strong coupling at the coupler between the 5th and 6th
qubit sites. As can be clearly seen in Fig. 5, the qubit
8 bias is the most important feature, which corresponds
to an interior qubit site near the physical boundary of
the linear chain. The coupler 5/6 bias is the only coupler
bias in the top 4 features.

In comparison, the coupler 5/6 bias is the most im-
portant feature in the single-target regression subtasks
Y3 and Y4, and the coupler 8/9 bias is the most impor-
tant feature in the single-target regression subtasks Y2
and Y5 (see Supplementary Information). The former

5

Discussion

While entirely data-driven approaches are successful
in machine learning applications with an abundance of
data, these machine learning methods break down in sce-
narios with a shortage of data. Overcoming this obstacle
requires some resource that compensates for the lack of
data [56].
In quantum device calibration applications,
data accumulation is low [8], but there is an analytical
model of the domain based upon prior scientiﬁc discov-
eries. Our result demonstrates that a machine learner
can reﬁne and enhance such discoveries with a minus-
cule amount of real experimental data. Using this ap-
proach, our learning system surpassed its scientiﬁc con-
temporaries [8, 10, 11] by over 20% on the supercon-
ducting quantum device calibration task, thereby pro-
viding a pathway for the successful interface of artiﬁ-
cial intelligence and physics. Moreover, we have demon-
strated the robustness of our approach by incorporating
inbuilt model selection and we have established a diag-
nostic method to examine the underlying scientiﬁc model
with SHAP learning techniques [32, 33].

Although we have focused on a quantum device cali-
bration application, the presented machine learning ap-
proach can have signiﬁcant impact further aﬁeld. We
have introduced an additive expansion in Eq. 2 that is
a modiﬁcation of a model at the heart of several func-
tion approximation methods in engineering [47], ma-
chine learning [47, 50, 52–55, 57, 58], statistics [43–
45, 49, 59, 60] and signal processing [61–63]. Gradient
boosting is one of the most popular learning algorithms in
data science and machine learning competitions [57, 58],
and also in real-world production pipelines [64]. Our ap-
proach enables it to take advantage of prior knowledge,
especially when data is scarce. Other potential appli-
cations include compressed sensing, where prior knowl-
edge about sparsity has resulted in an advantage over
the Nyquist-Shannon sampling theorem [61–63]. Indeed,
physical manifestations of Occam’s razor, symmetry and
complexity have already signiﬁcantly inﬂuenced the de-
velopment of learning and prediction [26, 31, 65, 66] – and
thus a systematic approach to incorporating prior scien-
tiﬁc knowledge into a machine learner provides a natural
advancement of the mutualistic relationship between hu-
man researchers and artiﬁcial intelligence.

Acknowledgements

We are grateful to Benjamin Chiaro, who ran the ex-
periment, collected the data, and shared it with us during
his time as a graduate student at UC Santa Barbara, and
to Pedram Roushan for helpful discussions. This work is
supported by the Singapore Ministry of Education Tier
1 grant RG162/19, Singapore National Research Foun-
dation Fellowship NRF-NRFF2016-02 and NRF-ANR
grant NRF2017-NRF-ANR004 VanQuTe, and the FQXi
large grants: the role of quantum eﬀects in simplifying

FIG. 5: SHAP summary plot [32] for the single-target Y1.
Using the collection of 9 qubit and coupler bias features as
an example, we induce a fully connected neural network [22]
to predict Y1. The horizontal axis is centered at the average
training example prediction, and the vertical axis ascendingly
orders the features according to their importance. Each point
is a SHAP value for a particular example, the coloring rep-
resents the bias value, and overlapping points are randomly
jittered along the vertical axis to avoid collisions [32, 33].

feature corresponds to a coupler near the experimentally
imposed boundary of the linear chain, and the latter fea-
ture corresponds to a coupler near the physical boundary
of the linear chain. Whereas the qubit biases, which cor-
respond to interior qubit sites, are 3 out of the 4 most
important features in the single-target regression subtask
Y1, the only other single-target regression subtask with a
qubit bias in the top 4 features is Y2.

This feature dependence merits some discussion. As
each instance of the spectroscopy protocol [8] ascendingly
orders the eigenenergies, one might expect that on aver-
age over all runs the feature dependence would be qual-
itatively the same for each single-target. Indeed, under
independent and identically distributed sampling of the
input parameters we would expect the data to exhibit a
symmetry under permutation among the local bias and
In line with this intu-
coupling parameters in Eq. 1.
ition, we observe a noticeably marked dependence on the
coupler bias features closest to the physical boundaries
for all single-targets. However, more generally, the per-
mutation symmetry is broken in the benchmark dataset,
not least because the model consists of few sites and
is patently not well approximated by closed boundary
conditions. Some of the individual single-targets, for in-
stance, have a stronger dependence on speciﬁc on-site
biases than others. This suggest that diﬀerent sites cor-
relate more strongly with larger or smaller eigenenergies.
An example is the aforementioned strong dependence of
the most negative eigenenergy Y 1 on the on-site bias at
site 8. We attribute this to the geometry of the physi-
cal conﬁguration and note that this asymmetric feature
dependence is already present in the initial multi-target
predictions generated by the data preprocessor.

adaptive agents and are quantum agents more energet-
ically eﬃcient at making predictions? A.W. was par-
tially supported by the Grant TRT 0159 on mathemati-
cal picture language from the Templeton Religion Trust
and thanks the Academy of Mathematics and Systems
Science (AMSS) of the Chinese Academy of Sciences
for their hospitality, where part of this work was done.
F.C.B. acknowledges funding from the European Unions
Horizon 2020 research and innovation programme under
the Marie Skodowska-Curie Grant Agreement No. 801110
and the Austrian Federal Ministry of Education, Science
and Research (BMBWF).

Methods

X
as examples. Let

Multi-target regression background – In the set-
be the domain,
ting of our learning framework, let
Rn
where we refer to points in
X
be the target space of multi-target observations, where
we refer to vectors in
as multi-targets and to compo-
nents of vectors as single-targets. We refer to an ordered
pair in the product of the domain and the target space
(X, Y )
as a labeled example. Moreover, we are
given a ﬁnite sequence of labeled examples

∈ X × Y

Y ⊆

Y

X × Y

S =

(X (i), Y (i))

m
i=1 ∈
}
which is supposed random so that there is an unknown
probability distribution on

[40–42].

X × Y

)m,

(3)

{

(

≥

R

∈ X × Y

Y × Y →

We wish to ﬁnd some simple pattern in the labeled
examples, namely a multi-target regressor h :
.
X → Y
However, there may be no functional relationship be-
tween the domain and the target space in this agnos-
tic setting [41, 42].
In order to measure the predic-
tive prowess of a multi-target regressor, we introduce
the decision theoretic concept of a loss function [40–45],
where we denote a non-negative multi-target loss func-
tion by (cid:96) :
0. Given a labeled example
(X, Y )
, the loss of some multi-target regres-
sor h on the labeled example is denoted by (cid:96)(Y, h(X)).
The multi-target loss function measures the magnitude
of error in predicting h(X), when the multi-target is Y.
Here, we study loss functions that are decompos-
able over the targets, which provides a joint target
view [20, 21]. Let
R be the single-target space of the
Yj ⊆
jth single-target observations. We denote a single-target
X → Yj. We denote a nonnegative
regressor by hj :
single-target loss function by (cid:96)j :
0. Given
Yj × Yj →
a labeled example in the product of the domain and the
∈ X × Yj, the loss of some
single-target space (X, Yj)
single-target regressor hj on the labeled example is de-
noted (cid:96)j(Yj, hj(X)). The single-target loss function mea-
sures the magnitude of error in predicting hj(X), when
the single-target is Yj. We deﬁne a loss function that is
decomposable over the targets by

R

≥

n

(cid:96)(Y, h(X)) =

(cid:96)j(Yj, hj(X)),

(4)

j=1
(cid:88)

in accord with [20, 21]. In the application, we study the
absolute error loss function, which is decomposable over
the targets. Namely,

6

(cid:96)(Y, h(X)) =

=

=

Y
||
n

j=1
(cid:88)
n

j=1
(cid:88)

h(X)

||1

−
Yj −
|

hj(X)
|

(5)

(cid:96)j(Yj, hj(X)),

|| · ||p denotes the Lp norm. Using the joint view,
where
the multi-target regression task reduces to n independent
single-target regression subtasks

EX,Y [(cid:96)(Y, h(X))] = EX,Y [

(cid:96)j(Yj, hj(X))]

n

j=1
(cid:88)

n

=

EX,Yj [(cid:96)j(Yj, hj(X))],

(6)

j=1
(cid:88)
where the ﬁrst line follows from the choice of a loss func-
tion that is decomposable over the targets, and the sec-
ond line follows from linearity [20, 21]. In this case, the
optimal jth single-target regressor is the one that mini-
mizes the jth single-target expected loss

h∗j = argmin

hj

EX,Yj [(cid:96)j(Yj, hj(X))].

(7)

Under the distribution-free setting, the jth single-
target expected loss is not available [40–45]. Conse-
quently, we split Eq. 3 into training, validation, and test
data, if there is suﬃcient data for an explicit validation
stage. Otherwise, we forgo the validation split. Here, we
focus on the case of splitting Eq. 3 into mtrain and mtest
ordered pairs for training and test data, respectively, as
there is a shortage of labeled examples in the applica-
tion. Moreover, we isolate the test data from the training
data, whereby training data is recyclable and test data is
single-use. Using the test data, we approximate the jth
single-target expected loss with the mean absolute error

1
mtest

mtest

i=1
(cid:88)

Y (i)
j −
|

hj(X (i))

.
|

(8)

Then, we approximate the expected loss with the average
mean absolute error

1
n

n

j=1
(cid:88)

1
mtest

mtest

i=1
(cid:88)

Y (i)
j −
|

hj(X (i))

,
|

(9)

and we refer to this error as the benchmark error in Fig. 2.
Two-step stacking framework – In the learning
Rn be the domain of initial multi-
framework, let
target predictions generated by a base regressor. We as-
sume the availability of these predictions as well as the
In this way, the
associated multi-target observations.

X ⊆

learning framework can be applied in tandem with sci-
entiﬁc models (see the Supplementary Information for
a brief review of the traditional two-step stacking ap-
proach).

In the ﬁrst step, we wrangle the labeled examples Eq. 3,

and we represent them with an m

2n design matrix

×

7



,






X (1)
X (2)
...
X (m)

Y (1)
Y (2)
...
Y (m)








(10)
where m denotes the number of multi-targets and n de-
notes the number of single-targets. Next, we split Eq. 10
into mtrain and mtest rows for training and test data,
respectively. In the second step, the boosting algorithm
2n,
receives the training data, which has shape mtrain ×
and we request a multi-target regressor as output. In the
jth single-target regression subtask, the boosting algo-
rithm slices the jth single-target from the training data

X (1)
X (2)
...
X (mtrain)









Y (1)
j
Y (2)
j
...
Y (mtrain)
j

,









(11)

where the matrix has shape mtrain ×
(n + 1). Next,
the single-target boosting algorithm detailed in Alg. 2
induces the jth single-target regressor ˆhj on Eq. 11.
After completion of each single-target regression sub-
task, the boosting algorithm concatenates the induced
single-target regressors into the multi-target regressor
ˆh = (ˆh1, ˆh2, . . . , ˆhn)T . Given a new example X
,
∈ X
the multi-target regressor predicts an n-dimensional real
vector ˆY = ˆh(X) (see Fig. 1).

Model selection – As the test data is single-use,
we need to simultaneously select the best performing
single-target boosting algorithm detailed in Alg. 1 for
the jth single-target regression subtask and estimate the
.
jth mean absolute error Eq. 8, where j
}
Moreover, we need to ensure that the selected jth
single-target boosting algorithm is able to choose the
smooth term, if the noise term in Eq. 2 degrades per-
formance (see Fig. 4). For this objective, we review
nested cross-validation [22, 45, 67], and we describe the
modiﬁcation of k-fold cross-validation utilized in Alg. 2,
which is similar to learning algorithms with inbuilt cross-
validation [22].

1, 2, . . . , n

∈ {

In Fig. 6, we illustrate k-fold cross-validation, e.g.,
k = 5, which is a precursor for nested cross-validation [22,
45, 67] and the inbuilt model selection step in Alg. 2. The
method begins by randomly partitioning Eq. 11 into k
non-overlapping folds, and k is typically a natural num-
ber between 5 and 10, inclusive. Next, we repeat the
following two steps k times with each of the withheld
folds used exactly once as the validation data:

FIG. 6: k-fold cross-validation. We represent the training
data as a light grey rectangle, and we illustrate 5-fold cross-
validation on the training data. In each iteration, the with-
held fold is colored light green and the 4 training folds are
colored light blue. We note that each of the withheld folds is
used exactly once as the validation data.

•

•

Of the k folds, we withhold one for validation.
A single-target boosting algorithm receives the re-
maining k
1 folds as training data, and we request
a single-target regressor as output.

−

We evaluate the induced single-target regressor on
the withheld fold from the previous step by com-
puting the average loss of the single-target regres-
sor.

Then, we average the k results from the second step,
and we refer to this average as cross-validation error.
This completes a single loop of the k-fold cross-validation
method.
In best practices of machine learning, this
method is preferred over leave-one-out cross-validation,
wherein k = mtrain [22, 45, 67].

In nested cross-validation, the estimation method uti-
lizes an outer loop of k non-overlapping folds and an inner
loop of l non-overlapping folds. The outer loop is utilized
to estimate the jth mean absolute error Eq. 8 and the
inner loop is utilized to select the (hyper)parameters in
Alg. 1, such as the choice of basis function or value of
Kj in Eq. 2. The method begins by randomly partition-
ing Eq. 11 into k non-overlapping folds. Next, we repeat
the following two steps k times with each of the withheld
folds in the outer loop used exactly once as the validation
data:

•

•

Of the k folds, we withhold a fold for valida-
In the inner loop, we apply l-fold cross-
tion.
validation to the remaining k
1 folds for mul-
tiple single-target boosting algorithms with diﬀer-
ing (hyper)parameters. After completing the inner
loop, we select the best performing single-target
boosting algorithm based on the minimum inner
loop cross-validation error.

−

The selected single-target boosting algorithm re-
1 folds from the previous step as train-
ceives the k
ing data, and we request a single-target regressor as
output. We evaluate the induced single-target re-
gressor on the withheld fold from the previous step

−

by computing the average loss of the single-target
regressor.

Then, we average the k results from the second step, and
we use this average to approximate the jth mean absolute
error Eq. 8. In practice, we usually execute nested cross-
validation within an exhaustive hyperparameter search
tool, such as GridSearchCV by scikit-learn [22] (see Sup-
plementary Information for implementation details).

After completing nested cross-validation, we repeat the
second step in the learning framework. In the jth single-
target regression subtask, Alg. 2 utilizes Eq. 11 in a
modiﬁed k-fold cross-validation procedure to select ei-
ther the incumbent smooth term from the base regressor
or the candidate additive expansion Eq. 2 as the induced
single-target regressor. This entails modifying the second
step in the aforedescribed k-fold cross-validation method,
namely

•

We independently evaluate the smooth term and
the induced single-target regressor on the withheld
fold from the previous step by computing the av-
erage loss of the smooth term and the single-target
regressor. We note that the smooth term always
predicts the jth feature, given an example from the
withheld fold.

Then, we independently average their k results, and we
refer to these averages as the incumbent error and the
cross-validation error, respectively. The inbuilt model se-
lection step in Alg. 2 selects the better algorithm based
on the minimum error. Subsequently, the boosting al-
gorithm completes each single-target regression subtask,
and the boosting algorithm returns the induced multi-
target regressor for evaluation on the test data.

(cid:96)j, ˜(cid:96)j}
{

Single-target gradient boosting – For the jth
single-target regression subtask, the single-target boost-
ing algorithm Alg. 1 takes as input training examples
Eq. 11, number of iterations Kj, single-target loss func-
tions
, and basis function b characterized by pa-
rameter set θ. For instance, the parameter set would en-
code the split features, split locations, and the terminal
node means of the individual trees, if the choice of ba-
sis function were a shallow decision tree; see for exam-
ple [43–45, 57, 58]. In the application, we choose a stack-
ing regressor [22, 36, 37] as the basis function, which is
a two layer ensemble of single-target regressors (see Sup-
plementary Information).

In Alg. 1, the ﬁrst line initializes to the smooth term for
each example in Eq. 11. In the for loop, line (a) computes
the pseudo-residuals with single-target loss function (cid:96)j,
whereby the term pseudo-residual emanates from the
term residual in least squares ﬁtting and reroughing [43–
45, 59]. Line (b) enables the boosting algorithm to work
for any given single-target learning algorithm [43–45],
whereby the labels are the pseudo-residuals from line (a).
Line (c) computes the one-dimensional line search with
single-target loss function ˜(cid:96)j. Line (d) sequentially ap-
pends the basis function to the additive expansion. The
output is the induced single-target regressor ˆhj.

8

In the application, we modify line (c) in Alg. 1 to in-
clude L1 regularization (see the Supplementary Informa-
tion). In relation to previous work, the initialization step
in Alg. 1 depends upon the examples, whereas the stan-
dard form of gradient boosting initializes to the opti-
, c); see ref-
mal constant model: argminc
erences [43–45]. In matching pursuit and its extensions,
the greedy stagewise algorithms initialize to the zero vec-
tor, and they sequentially transform the signal into a neg-
ligible residual; see references [61–63] for the algorithmic
body diﬀerences and further details.

(cid:96)j(Y (i)
j

mtrain
i=1

(cid:80)

For the jth single-target regression subtask, the aug-
mented version of the single-target boosting algorithm
Alg. 2 takes as input training examples Eq. 11, num-
(cid:96)j, ˜(cid:96)j}
,
ber of iterations Kj, single-target loss functions
{
basis function b characterized by parameter set θ, num-
ber of cross-validation folds k, and k-fold cross-validation
single-target loss function. The inbuilt model selection
step in Alg. 2 selects the incumbent smooth term as the
induced single-target regressor, if the incumbent error is
less than or equal to the cross-validation error, otherwise
Alg. 2 calls Alg. 1 (k-fold cross-validation details in pre-
vious section). The output is the induced single-target
regressor ˆhj.

Explainable machine learning – In machine learn-
ing competitions and products, complex models, such
as ensemble and deep learning models, are omnipresent.
Understanding why these models make certain predic-
tions is the focus of explainable machine learning [32, 33].
The SHAP framework uniﬁes several approaches in ex-
plainable machine learning to replicate individual pre-
dictions generated by a single-target regressor with a
simpler linear explanation model whose coeﬃcients mea-
sure feature importance [32]. In the work of ˘Strumbelj
and Kononenko, these coeﬃcients, known as SHAP val-
ues [32], were shown to be equivalent to the Shapley value
in cooperative game theory [68]. The explanation model
is deﬁned as a linear function of binary variables

M

g(z(cid:48)) = φ0 +

φkz(cid:48)k

(12)

(cid:88)k=1

∈ {

0, 1
}

M is a set of binary variables, M is
where z(cid:48)
the number of features under consideration, and φk is a
real-valued feature attribution, known as a SHAP value,
for the kth feature. As the computation of Shapley val-
ues has an exponential time complexity [68], the SHAP
software approximates the coeﬃcients with insights from
additive feature attribution methods; see [32].

In the application, we utilize the model-agnostic ap-
proximation method, known as Kernel SHAP, to com-
pute the SHAP values [32]. This enables us to ascer-
tain a simpler explanation model to approximate each
training data prediction generated by the induced fully-
connected neural networks [22], where M = 9 in Eq. 12
for the control voltage features (see the Supplementary
Information). The importance I of each feature is deﬁned

Input: training examples

Algorithm 1: BaseBoost

9

number of iterations Kj
single-target loss functions
basis function b characterized by parameter set θ

(cid:96)j, ˜(cid:96)j

}

{

Initialize: hj,0(X) = Xj for each example
for k = 1 to Kj do

(a) for i = 1 to mtrain do

Compute pseudo-residuals

r(i)
j,k =

−

(i)
∂(cid:96)j (Y
j
∂hj (X(i))

,hj (X(i)))

end

(cid:12)
(cid:12)
(cid:12)
(cid:12)hj (X(i))=hj,k

1(X(i))

−

(b) Induce a basis function on

{

X (i), r(i)

mtrain
i=1

j,k}

to learn the parameter set θj,k

(c) Solve the one-dimensional optimization problem to learn the expansion coeﬃcient

αj,k = argminα

(cid:80)mtrain
i=1

˜(cid:96)j(Y (i)
j

, hj,k

1(X (i)) + αb(X (i); θj,k))

−

(d) Sequentially append the induced basis function to the additive expansion

hj,k(X) = hj,k

1(X) + αj,kb(X; θj,k)

−

end
Output: Single-target regressor ˆhj = hj,Kj

Input: training examples

Algorithm 2: BaseBoostCV

number of iterations Kj
single-target loss functions
basis function b characterized by parameter set θ
number of cross-validation folds k
k-fold cross-validation single-target loss function

(cid:96)j, ˜(cid:96)j

{

}

Model selection: Perform modiﬁed k-fold cross-validation for the incumbent smooth term and the candidate

BaseBoost. If the incumbent error is less than or equal to the cross-validation error, then break
ˆhj(X) = Xj. Otherwise, call BaseBoost.

Output: Single-target regressor ˆhj

as the sum of absolute SHAP values

request.

mtrain

Ik =

φ(i)
,
k |
|

(13)

i=1
(cid:88)
which enables an ordering to be deﬁned. The features
are sorted in ascending order from bottom to top in each
summary plot [32, 33].

Author Contributions

Data Availability

All data, relevant to the information and ﬁgures pre-
sented in this manuscript, are available upon reasonable

A.W. designed the learning approach, implemented the
learning system, and performed the data analysis. All
authors contributed to the interpretation of the data and
to writing the manuscript.

[1] David Hume. A Treatise of Human Nature. Clarendon

Press, 1739.

[2] David Haussler. Quantifying inductive bias: AI learning
algorithms and Valiant’s learning framework. Artiﬁcial
Intelligence, 36:177–221, 1988.

[3] Tom Mitchell. The need for biases in learning generali-
sation. In Jude Shavlik and Thomas Dietterich, editors,
Readings in Machine Learning. Morgan Kaufmann, 1991.
[4] David Wolpert and William Macready. No free lunch
theorems for optimization. IEEE Transactions on Evo-

lutionary Computation, 1(1), 1997.

[5] Rich Caruana. Multitask learning. Machine Learning,

28:41–75, 1997.

[6] Jonathan Baxter. A model of inductive bias learning.
Journal of Artiﬁcial Intelligence Research, 12:149–198,
2000.

[7] Steven Brunton, Joshua Proctor, and Jos´e Nathan Kutz.
Discovering governing equations from data by sparse
identiﬁcation of nonlinear dynamical systems. Proceed-
ings of the National Academy of Sciences of the United
States of America, 113(15):3932–3937, 2016.

[8] Pedram Roushan et al. Spectroscopic signatures of lo-
calization with interacting photons in superconducting
qubits. Science, 358:1175–1179, 2017.

[9] Keith Butler et al. Machine learning for molecular and

materials science. Nature, 559:547–555, 2018.

[10] Charles Neill et al. A blueprint for demonstrating quan-
tum supremacy with superconducting qubits. Science,
360:195–199, 2018.

[11] Benjamin Chiaro et al.

of entanglement
arXiv:1910.06024, 2019.

Growth and preservation
in a many-body localized system.

[12] Michael Schmidt and Hod Lipson. Distilling free-form
natural laws from experimental data. Science, 324:81–
85, 2009.

[13] Juan Carrasquilla and Roger Melko. Machine learning
phases of matter. Nature Physics, 13:431–434, 2017.
[14] Alexey Melnikov et al. Active learning machine learns to
create new quantum experiments. Proceedings of the Na-
tional Academy of Sciences of the United States of Amer-
ica, 115(6):1221–1226, 2018.

[15] Maciej Koch-Janusz and Zohar Ringel. Mutual infor-
mation, neural networks and the renormalization group.
Nature Physics, 14:578–582, 2018.

[16] Giacomo Torlai et al. Neural-network quantum state to-

mography. Nature Physics, 14:447–450, 2018.

[17] Tailin Wu and Max Tegmark. Toward an artiﬁcial in-
telligence physicist for unsupervised learning. Physical
Review E, 100:033311, 2019.

[18] Raban Iten et al. Discovering physical concepts with
neural networks. Physical Review Letters, 124:010508,
2020.

[19] Sebastian Wetzel et al. Discovering symmetry invariants
and conserved quantities by interpreting siamese neural
networks. arXiv:2003.04299, 2020.

[20] Hanen Borchani et al. A survey on multi-output regres-
sion. Wiley Interdisciplinary Reviews: Data Mining and
Knowledge Discovery, 2015.

[21] Willem Waegeman, Krzysztof Dembczy´nski, and Eyke
H¨ullermeier. Multi-target prediction: A unifying view
on problems and methods. Data Mining and Knowledge
Discovery, 33:293–324, 2019.

[22] Fabian Pedregosa et al. Scikit-learn: machine learning in
python. Journal of Machine Learning Research, 12:2825–
2830, 2011.

[23] Alvaro Pascual-Leone et al. The plastic human brain cor-

tex. Annual Review of Neuroscience, 28:377–401, 2005.

[24] Yu Chen et al. Qubit architecture with high coher-
ence and fast tunable coupling. Physical Review Letters,
113:220502, 2014.

[25] Ehsan Zahedinejad, Joydip Ghosh, and Barry Sanders.
Designing high-ﬁdelity single-shot three-qubit gates: a
machine-learning approach. Physical Review Applied,
6:054005, 2016.

10

[26] Henry Lin, Max Tegmark, and David Rolnick. Why does
deep and cheap learning work so well? Journal of Sta-
tistical Physics, 168(6):1223–1247, 2017.

[27] Jacob Biamonte et al. Quantum machine learning. Na-

ture, 549:195–202, 2017.

[28] Vedran Dunjko and Hans Briegel. Machine Learning &
Artiﬁcial Intelligence in the Quantum Domain: A Re-
view of Recent Progress. Reports on Progress in Physics,
81(7), 2018.

[29] Giuseppe Carleo et al. Machine learning and the physical

sciences. Reviews of Modern Physics, 91:045002, 2019.

[30] Pankaj Mehta et al. A high-bias, low-variance introduc-
tion to Machine Learning for physicists. Physics Reports,
810:1–124, 2019.

[31] Silviu-Marian Udrescu and Max Tegmark. AI Feynman:
A physics-inspired method for symbolic regression. Sci-
ence Advances, 6(16), 2020.

[32] Scott Lundberg and Su-In Lee. A uniﬁed approach to in-
terpreting model predictions. In Advances in Neural In-
formation Processing Systems 30, pages 4765–4774. Cur-
ran Associates, Inc., 2017.

[33] Christoph Molnar.

Interpretable machine learning:
a guide for making black box models explainable.
christophm.github.io/interpretable-ml-book, 2020.
[34] Norbert Linke et al. Experimental comparison of two
quantum computing architectures. Proceedings of the Na-
tional Academy of Sciences of the United States of Amer-
ica, 114(13):3305–3310, 2017.

[35] Julian Kelly et al. Physical qubit calibration on a directed

acyclic graph. arXiv:1803.03226, 2018.

[36] David Wolpert. Stacked generalization. Neural Networks,

5:241–259, 1992.

[37] Leo Breiman. Stacked regressions. Machine Learning,

24:49–64, 1996.

[38] Leo Breiman and Jerome Friedman. Predicting multivari-
ate responses in multiple linear regression. Royal Statis-
tical Society Series B, 59:3–54, 1997.

[39] Dumitru Erhan et al. Why does unsupervised pre-
training help deep learning? Journal of Machine Learn-
ing Research, 11:625–660, 2010.

[41] Michael Kearns and Robert Schapire.

[40] David Haussler. Decision theoretic generalizations of the
PAC model for neural net and other learning applica-
tions. Information and Computation, 100:78–150, 1992.
Eﬃcient
distribution-free learning of probabilistic concepts. Jour-
nal of Computer and Systems Science, 48:464–497, 1994.
[42] Michael Kearns, Robert Schapire, and Linda Sellie. To-
ward eﬃcient agnostic learning. Machine Learning,
17:115–141, 1994.

[43] Jerome Friedman.

Greedy function approximation:
A gradient boosting machine. Annals of Statistics,
29(5):1189–1232, 2001.

[44] Jerome Friedman and Bogdan Popescu. Importance sam-
pled learning ensembles. Technical report, Stanford Uni-
versity, Department of Statistics, 2003.

[45] Trevor Hastie, Robert Tibshirani, and Jerome Friedman.
The Elements of Statistical Learning. Springer, 2009.
[46] Andrew Ng. Machine learning yearning. deeplearning.ai

project, 2020.

[47] Michael Powell. Radial basis functions for multivariable
interpolation: a review. In Algorithms for Approximation.
Clarendon Press, 1987.

[48] Michael Kearns and Leslie Valiant. Learning boolean for-
mulae or ﬁnite automata is as hard as factoring. Techni-

11

[68] Erik ˘Strumbelj and Igor Kononenko. Explaining predic-
tion models and individual predictions with feature con-
tributions. Knowledge and Information Systems, 41:647–
665, 2014.

cal Report TR-14-88, Harvard University Aiken Compu-
tation Laboratory, 1988.

[49] Trevor Hastie and Robert Tibshirani. Generalized Addi-

tive Models. Chapman and Hall, London, 1990.

[50] Robert Schapire. The strength of weak learnability. Ma-

chine Learning, 5:197–227, 1990.

[51] Michael Kearns and Leslie Valiant. Cryptographic limita-
tions on learning boolean formulae and ﬁnite automata.
Journal of the Association for Computing Machinery,
41:67–95, 1994.

[52] Yoav Freund. Boosting a weak learning algorithm by
Information and Computation, 121:256–285,

majority.
1995.

[53] Yoav Freund and Robert Schapire. A decision-theoretic
generalization of on-line learning and an application to
boosting. Journal of Computer and System Sciences,
55:119–139, 1997.

[54] Leo Breiman. Arcing the edge. Technical report, Stanford

University, Department of Statistics, 1997.

[55] Llew Mason et al. Boosting algorithms as gradient de-
scent.
In NIPS: Proceedings of the 12th International
Conference on Neural Information Processing, pages
512–518, 1999.

[56] Robert Schapire et al. Incorporating prior knowledge into
boosting. In ICML’02: Proceedings of the Nineteenth In-
ternational Conference on Machine Learning, pages 538–
545, 2002.

[57] Tianqi Chen and Carlos Guestrin. XGBoost: a scalable
tree boosting system. In KDD’16: Proceedings of the 22nd
ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, pages 785–794, 2016.
[58] Guolin ke et al. LightGBM: a highly eﬃcient gradient
boosting decision tree. In Advances in Neural Informa-
tion Processing Systems 30, pages 3149–3157. Curran As-
sociates, Inc., 2017.

[59] John Tukey. Exploratory Data Analysis. Addison-Wesley,

1977.

[60] Jerome Friedman, Trevor Hastie, and Robert Tibshirani.
Additive logistic regression: A statistical view of boost-
ing. The Annals of Statistics, 28(2):337–407, 2000.
[61] St´ephane Mallat and Zhifeng Zhang. Matching pursuits
with time-frequency dictionaries. IEEE Transactions on
Signal Processing, 41(12):3397–3415, 1993.

[62] Pascal Vincent and Yoshua Bengio. Kernel matching pur-

suit. Machine Learning, 48:165–187, 2002.

[63] David Donoho et al.

Sparse solution of underdeter-
mined systems of linear equations by stagewise orthogo-
nal matching pursuit. IEEE Transactions on Information
Theory, 58(2):1094–1121, 2012.

[64] Xinran He et al. Practical lessons from predicting clicks
on ads at facebook. In ADKDD’14: Proceedings of the
Eighth International Workshop on Data Mining for On-
line Advertising, 2014.

[65] Cosma Shalizi and James Crutchﬁeld. Computational
mechanics: Pattern and prediction, structure and sim-
plicity. Journal of Statistical Physics, 104(3-4):817–879,
2001.

[66] Mile Gu et al. Quantum mechanics can reduce the
complexity of classical models. Nature communications,
3(1):1–5, 2012.

[67] Gavin Cawley and Nicola Talbot. On over-ﬁtting in
model selection and subsequent selection bias in per-
formance evaluation. Journal of Machine Learning Re-
search, 11:2079–2107, 2010.

SupplementaryInformation:BoostingontheshouldersofgiantsinquantumdevicecalibrationAlexWozniakowski,1,2,∗JayneThompson,3MileGu,1,2,†andFelixBinder41SchoolofPhysicalandMathematicalSciences,NanyangTechnologicalUniversity2ComplexityInstitute,NanyangTechnologicalUniversity3CentreforQuantumTechnologies,NationalUniversityofSingapore4InstituteforQuantumOpticsandQuantumInformation–IQOQIVienna,AustrianAcademyofSciences,Boltzmanngasse3,1090Vienna,AustriaS1.BENCHMARKDATASETInthissection,webrieﬂyreviewthequantumdeviceandtheclassicalcontrolprogramutilizedinthebench-marktask,andwedescribethecontentsinthebench-markdataset.Foradetailedintroductiontothemany-bodyRamseyspectroscopytechnique,theclassicalcon-trolprogram,calibrationmethodologies,andthesuper-conductingquantumdevice,seeforexample[S1–S5].Thequantumdeviceisanearest-neighborcoupledlinearchainof9superconductingqubits,whereinthe5rightmostqubitsand4intercedingcouplingswereutilizedduringthebenchmarkdatasetacquisition[S1–S3,S5];seethemainbodyofreference[S2]foranopticalmicrographofthedeviceandseetheSupplementaryMa-terialsofreference[S3]forthecorrespondingelectroniccircuitdiagram.Eachqubitisexplicitlymodeledasacapacitor,inductor,andtunablejunction,allinseries(seetheSupplementaryMaterialsofreference[S3]forthephysicalparametersutilizedintheclassicalcontrolprogram.Forthedevicearchitecture,thereare26con-trollinesusedtodrivethemicrowaverotations,setthequbitfrequencies,andbiasthecouplers[S3].Toobtaineachmulti-targetinthebenchmarkdataset,aninstanceofthemany-bodyRamseyspectroscopytech-nique[S2]beginsbysettingtheparametersinEq.1suchthattheon-sitedetuningissampleduniformlyin[−100,100]MHz,thehoppingrateissampleduniformlyin[0,50]MHz,andtheon-siteHubbardinteractionisﬁxedat0.Next,thetime-domainspectroscopycircuitinFig.S1isrun5timeswiththeseparameters,andwedenotethechoiceofsuperpositionqubitandreadoutres-onatorbytheindexk,wherek∈{1,2,...,5}.Inthekthrunofthetime-domainspectroscopycir-cuit,eachqubitstartsintheﬁducialstate|0i,andnophotonispresentinthesystem.Next,amicrowavepulseisappliedtothekthqubit,e.g.,k=1inFig.S1,whichplacesthequbitinasuperpositionofthecom-putationalbasisanditinitializesasingle-photoninthesystem.Then,thesystemevolvesaccordingtothetime-independentHamiltonianEq.1.Aftertheevolution,amicrowavepulseisappliedtothekthqubittomeasure∗wozn0001@e.ntu.edu.sg†mgu@quantumcomplexity.org|0iπ2Hπ2|0i|0i|0i|0iFIG.S1.Time-domainspectroscopycircuit.Initially,eachqubitisintheﬁducialstate|0i.Usingamicrowavepulse,thekthspeciﬁedqubit,e.g.,k=1,isplacedinasuperpositionofthecomputationalbasis.Next,thesystemevolvesaccordingtothetime-independentHamiltonianEq.1withrandomlyprogrammedparameters.Aftertheevolution,amicrowavepulseisappliedtomeasureeitherhσXiorhσYi,whereσXandσYdenotePaulioperators.eitherhσXiorhσYi.Fromthemeasurementoftheseob-servables,theobservablehσXi+ihσYiisinstantiated;andtheenergyspectrumisfullyresolvedbycompletingall5runs[S2].Wenotethatthechoiceoftheoperatorisdesignedtoisolatethesingle-photonmanifold,soalloftheeigenenergieshavethesamesign(seetheSupplemen-taryMaterialsinreference[S2]).Lastly,thepeaksinthefastFouriertransformoftheobservablehσXi+ihσYiareidentiﬁedastheeigenenergiesoftheHamiltonian[S2,S5],andtheseeigenenergiesaresortedintoascendingorder,asdescribedinthemainbody.Toobtaineachmulti-targetpredictioninthebench-markdataset,theclassicalcontrolprogram[S2,S3,S5]mapsacollectionof5qubitand4couplerbiasfeaturestothe5×5single-photonblockmatrixintherepresen-tationofEq.1.Next,anumericaleigensolverproduces5eigenenergyapproximations,andtheyaresortedinas-cendingorder.Inthebenchmarkdataset,therearem=136ofeach:qubitandcouplerbiasexamples,multi-targetpredictionsgeneratedbythecontrolprogram,andmulti-targetsre-trievedbythemany-bodyRamseyspectroscopytech-nique[S2].Insplittingthisdataformachinelearning,wewanttopreservetheexperimentalassociation,i.e.,theexamplesformatripleconsistingof5qubitbiasfea-tures,4couplerbiasfeatures,5single-targetpredictions,and5single-targets.Moreover,wesplittheseexamplesintomtrain=95andmtest=41indicesfortrainingand2FIG.S2.Qubitandcouplerbiasfeatureboxplots.Wede-pictthequbitbiasfeaturesutilizedinthetrainingdatasplit(top),wherebythelabelQubitjdenotesthequbitbiascorre-spondingtoqubitsitej.Wedepictthecouplerbiasfeaturesutilizedinthetrainingdatasplit(bottom),wherebythelabelCouplerj/j+1denotesthecouplerbiascorrespondingtothenearestneighborcouplerforqubitsitesjandj+1.FIG.S3.Jointsingle-targetpredictionfeatureandsingle-targetobservationboxplot.Wejointlydepictthesingle-targetpredictionsandthesingle-targetobservationsutilizedinthetrainingdatasplit.testdata,respectively.IntheboxplotsinFig.S2,wede-pictthequbitbiasfeaturesutilizedinthetrainingdatasplit(top),andwedepictthecouplerbiasfeaturesuti-lizedinthetrainingdatasplit(bottom).IntheboxplotinFig.S3,wejointlydepictthesingle-targetpredictionsandthesingle-targetobservationsutilizedinthetrainingdatasplit.FIG.S4.Usingthesquarederrorlossfunctionasthecrite-rion,ourlearningsystemsurpassesthepreviousstate-of-the-art[S2,S3,S5]byover47%onthemulti-targetregressiontask.Moreover,ourlearningsystemoutperformstheprevi-ousstate-of-the-art[S2,S3,S5]oneachsingle-targetregres-sionsubtask.S2.TESTERRORIntheapplication,thejthsingle-targettesterrorismeanabsoluteerrorEq.8,andthemulti-targettesterrorisaveragemeanabsoluteerrorEq.9,wheren=5andmtest=41.Inthemainbody,weplotthemeanabsoluteerrorsandaveragemeanabsoluteerrorofthepreviousstate-of-the-art[S2,S3,S5]andourlearningsysteminFig.2.Intherealworldapplicationofmachinelearning,mul-tiplemeasuresofpredictionperformanceshouldbestud-iedandreported[S6–S8].Here,weutilizethesquareder-rorlossfunctiontomeasurethepredictionperformanceintheapplication,aswehavealreadygeneratedthetestexamplepredictions.Importantly,thesquarederrorlossfunctionisdecomposableoverthetargets,namely‘(Y,h(X))=||Y−h(X)||22=nXj=1(Yj−hj(X))2=nXj=1‘j(Yj,hj(X)).(S1)Thejthsingle-targettesterrorismeansquarederror1mtestmtestXi=1(Y(i)j−hj(X(i)))2,(S2)andthemulti-targettesterroristheaveragemeansquarederror1nnXj=11mtestmtestXi=1(Y(i)j−hj(X(i)))2.(S3)FromlefttorightinFig.S4,weshowthemeansquarederrorsEq.S2andtheaveragemeansquarederrorEq.S2ofthepreviousstate-of-the-art[S2,S3,S5]andourlearningsystem,inblueandorange,respectively.Our3learningsystemoutperformsthepreviousstate-of-the-art[S2,S3,S5]oneachsingle-targetregressionsub-taskandthemulti-targetregressiontask.Moreover,ourlearningsystemsurpassesthepreviousstate-of-the-art[S2,S3,S5]byover47%onthemulti-targetregressiontask.S3.MULTI-TARGETSTACKINGMulti-targetregressionapplicationsposenovelre-searchquestionsandthereisademandfornewmethods,whichconsidernotonlytheunderlyingrelationshipsbe-tweenthefeaturesandtheassociatedsingle-targetsbutalsotherelationshipsbetweenthesingle-targets[S9,S10].Here,wereviewthesingle-targetapproach,whichdoesnotconsidertherelationshipbetweenthesingle-targets,aswellastheprototypicaltwo-stepstackingapproach,whichaddendsasecondlayertothesingle-targetap-proachinordertoexploitdependenciesamongthesingle-targets.Inthesingle-targetapproach,alearningalgorithmre-ceivestrainingexamplesandwerequestamulti-targetregressorasoutput.Foreachsingle-targetregressionsubtask,thelearningalgorithmindependentlyinducesasingle-targetregressoronanappropriatesliceofthetrainingdata[S9,S10].Afterﬁnishingthesubtasks,thelearningalgorithmconcatenateseachsingle-targetre-gressorintoamulti-targetregressor.Givenanexample,themulti-targetregressorpredictsarealvector.Asmanylearningalgorithmsdonotnativelysupportmulti-targetprediction,thisapproachiswidelyappliedinmulti-targetregressionapplications[S8–S10].However,thisapproachdoesnotimplysimplersingle-targetregressorsthananapproachwhichconsiderstherelationshipbetweenthesingle-targets[S9,S10].Thisleadstothealgorithmde-signquestion:canwedobetterbyexploitingdependen-ciesamongthesingle-targets?Initiallyintroducedinsingle-targetclassiﬁcation[S11]andregressiontasks[S12],stackingisageneralensem-blelearningtechniqueforcombiningsingle-targetclassi-ﬁersorregressorstoreducetheirbiases.Inthemulti-targetregressionsetting,thetwo-stepstackingapproachenforcestheideathatsingle-targetregressorsshouldbe-havesimilarlyinordertooutperformtheindependentsingle-targetapproach[S9,S10,S13].Inthetwo-stepstackingapproach,alearningalgorithmreceivestrainingexamplesandwerequestamulti-targetregressorasoutput.Intheﬁrststep,thelearningal-gorithmappliesthesingle-targetapproach,anditusestheinducedmulti-targetregressortogeneratetrainingexamplepredictions.Inthesecondstep,thelearningal-gorithmregardsthesepredictionsasnewexampleswhileretainingtheinitiallabels.Insomevariations,thelearn-ingalgorithmregardsaconcatenationoftheoriginalex-ampleswiththesepredictionsasnewexampleswhilere-tainingtheinitiallabels[S9,S10].Next,thelearningalgorithmappliesthesingle-targetapproachtoinduceasecondlayerofsingle-targetregressors,andthelearningalgorithmreturnsacompositionoftheﬁrstandsecondlayermulti-targetregressors.Inotherwords,givenanexamplefromthedomain,theﬁrstlayermulti-targetre-gressorgeneratesaninitialprediction,thenthesecondlayermulti-targetregressorregularizesthisprediction,whichreducestheproblemofoverﬁtting[S9,S10,S13].Thistechniqueisrelatedtomethodsindeeplearning,suchaspre-training[S14]andweightsharing[S10,S15].Ourlearningframeworkismotivatedbythistwo-stepstackingapproach[S9–S13],aswellasmultitasklearn-ing[S15](detailsinMethods).S4.BOOSTINGTHEBASEREGRESSORTheideaofimprovingabaseregressorbyexamin-ingtheresidualsoriginatedinTukey’sworkonrerough-ing[S16].Inthisapproach,weassumethatanobservedsingle-targetcanbedecomposedintoasumofanunder-lyingprocessthatevolvessmoothly,calledthesmoothterm,andofanunsystematicnoisecomponent,calledthenoiseterm.Inthecontextoftheapplication,thesmoothterminEq.2isgeneratedbytheimplementedapproximationoftheHamiltonianmodelEq.1,andthenoiseterminEq.2aimstocapturegeneralizablephys-icaleﬀectsmissedbytheclassicalcontrolprogram(seeFig.3).ThealgorithmicparadigmofboostingoriginatedfromaquestionofKearnsandValiant,aboutwhetheraweaklearningalgorithmthatperformsslightlybetterthanrandomguessing,canbeimprovedintoanarbi-trarilyaccuratestronglearningalgorithm,whilework-ingintheprobablyapproximatelycorrect(PAC)learn-ingmodel[S17,S18].Intheaﬃrmative,Schapirepro-posedtheﬁrstprovablepolynomial-timeboostingalgo-rithm[S19],andFreunddevelopedamoreeﬃcientboost-ingalgorithm[S20].Next,FreundandSchapireintro-ducedAdaBoost[S21],whichsurmountedmanyofthepracticaldiﬃcultiesoftheearlierboostingalgorithms.Then,Schapireetal.devisedawaytoincorporatepriorknowledgeintoAdaBoostforsingle-targetclassiﬁcationtasks,wherebypriorknowledgeisreﬁnedandnoten-tirelyoverwhelmedbytheprocessoflearningfromexam-ples[S22].ThemodiﬁcationofthelogisticlossfunctioninAdaBoostaroseinthedevelopmentofspoken-dialoguesystemsatAT&T[S22].TheworkofFriedman,Hastie,andTibshiranilinkedtheoriginalformulationofAdaBoost[S21]withadditiveexpansions[S23],whicharetypicallyﬁtwithabackﬁttingalgorithmoragreedystagewisealgorithm[S6,S24,S25].Later,Breimanshowedthatboostingcanbeinterpretedasaformofgradientdescentinfunctionspace[S26].Friedmanextendedthisideatothegradientboostingmachine,whichadvantageouslyallowsanychoiceofdif-ferentiablelossfunction[S27].Simultaneously,Masonetal.developedanabstractcharacterizationofboostingalgorithmsasgradientdescentonempiricallossfunc-4tionalsinaninner-productfunctionspace[S28].FurtherconnectionswithstatisticswereestablishedintheworkofB¨uhlmannandHothorn[S29].Inpractice,theseal-gorithmictechniquesareusuallyimplementedinscikit-learn[S8],XGBoost[S30],orLightGBM[S31].A.GradientboostingInthemainbody,wedevisedawaytoincorpo-ratepriorknowledgeintothegradientboostingmachineAlg.1(detailsinMethods).Inthissection,weex-panduponthisdiscussionbyderivingagenericver-sionofboostingforthejthsingle-targetregressionsub-task,whichfollowsfromsimilarworkintheoriginalgradientboostingmachineforsingle-targetregressiontasks[S6,S26–S29].LetusbeginbyconsideringthejthempiricallossfunctionalLj(hj)=mtrainXi=1‘j(Y(i)j,hj(X(i))),(S4)whereLjisafunctionofthejthsingle-targetregressorhj.Inthisabstractcharacterizationofboosting,thegoalofaboostingalgorithmistominimizeEq.S4.AsLjisafunctional,thisminimizationproblemcanbeviewedasnumericaloptimizationinfunctionspaceh∗j=argminhjLj(hj),(S5)wheretheparametervectorhj∈Rmtraincomponentsarethevaluesofthejthsingle-targetapproximatingre-gressorhj(X(i))ateachofthemtrainexamplesinthetrainingdata.Namely,hj=hj(X(1))hj(X(2))...hj(X(mtrain)).(S6)Typically,numericaloptimizationproceduressolveEq.S5bymakinganinitialguesshj,0=bj,0∈Rmtrain,theniterativelyupdatingeachsuccessiveparametervec-torhj,kbasedonthecurrentparametervectorhj,k−1,wherewedenotethenumberofiterationsbyKjandthesubscriptinhj,kdenotesthejthsingletargetregressionsubtaskandthekthiteration,respectively.Namely,wepositthesolutionofEq.S5asanadditiveexpansionofparametervectorshj,Kj=KjXk=0bj,k,bj,k∈Rmtrain.(S7)Here,wechoosethestagewiseﬁst-orderfunctionalsteepestdescentasthenumericaloptimizationproce-dure.Wehavethateachparametervectorisgivenbybj,k=−ρj,kgj,k,(S8)whereρj,k∈Risthesteplengthandgj,k∈RmtrainisthegradientoftheempiricalriskfunctionalEq.S4eval-uatedathj=hj,k−1;seereference[S32]foraderivationwiththesecond-orderfunctionalNewton-Raphsonup-date.Next,wecomputeeachcomponentofthegradientg(i)j,k=∂‘j(Y(i)j,hj(X(i)))∂hj(X(i))(cid:12)(cid:12)(cid:12)(cid:12)hj(X(i))=hj,k−1(X(i)),(S9)aswellasthesteplengthρj,k=argminρLj(hj,k−1−ρgj,k).(S10)Then,wemaketheupdatehj,k=hj,k−1−ρj,kgj,k,(S11)andwerepeatthisprocessiteratively.Werefertothisprocessasfunctionalgradientdescent[S6,S26–S29,S32].Initscurrentform,functionalgradientdescentdoesnotaddressthegeneralizationobjectiveofamachinelearningalgorithm,asthegradientisonlydeﬁnedataﬁxedsetofmtrainexamplesanditcannotbegeneralizedtootherexamplesinthedomain.Inaccordwiththeorig-inalgradientboostingmachine[S6,S25,S27,S28],were-solvethisdilemmabyinducingabasisfunctionb(X;θ),suchasashallowdecisiontree[S6,S27,S30,S31],atthekthiteration,whichapproximatesthenegativegradientsignal.Herebylearningtheparametersetθj,k.Wenotethattheparametersetθj,kwouldencodethesplitfea-tures,splitlocations,andtheterminalnodemeansoftheindividualtreesforthejthsingle-targetregressiontaskatthekthiteration,ifthechoiceofbasisfunctionwereashallowdecisiontree;seeforexample[S6,S27,S30,S31].Next,weperformaone-dimensionallinesearchαj,k=argminαmtrainXi=1‘j(Y(i)j,hj,k−1(X(i))+αb(X(i);θj,k)),(S12)whereα∈R;seereference[S29]foranargumentaboutthepossibleomissionofthisstep.Then,wesequentiallyappendtheinducedbasisfunctiontotheadditiveexpan-sionhj,k(X)=hj,k−1(X)+αj,kb(X;θj,k).(S13)Thisleadsustothegenericversionofthejthsingle-targetgradientboostingalgorithmAlg.1.S5.IMPLEMENTATIONWeusethemachinelearningapproachdescribedinthemainbody,aswellasthescikit-physlearnrepositoryde-velopedbyAlexWozniakowski.ThePythonbasedrepos-itorywillbemadepubliclyavailableatthecitedGitHublink[S33].Foreachsingle-targetregressionsubtask,thetrainingprocesstakesafewsecondsonastandardlaptop,5andthehyperparameterscanbeaccessedinthereposi-tory.InobtainingthetesterrorresultsinFig.2andinFig.S4,weevaluatealloperationsencompassingtrain-ingdatathroughnestedcross-validation,whichisexe-cutedinGridSearchCVwithparameterscv=5andscoring=“negmeanabsoluteerror”[S8].Foreachsingle-targetregressionsubtask,weindependentlypre-processtheexamplesinEq.11withanormaldistribu-tionquantiletransformer[S8],andthetransformerishandledbyamodiﬁedpipelineobject,whichinheritsfromthepipelineobjectinreference[S8].Themodi-ﬁedpipelineobjectinducessingle-targetregressorswithAlg.2,whichtakesasinputthetransformedtrainingex-amplesEq.11,numberofiterationsKj=1,squareder-rorandabsoluteerrorsingle-targetlossfunctions{‘j,˜‘j},respectively,stackingregressor[S8,S11,S12]basisfunc-tionb,numberofcross-validationfoldsk=5,and5-foldcross-validationsingle-targetabsoluteerrorlossfunction.Inthestackingregressor[S8]withparameterscv=5andpassthrough=True,theﬁrststackinglayerconsistsofagradientboosteddecisiontree[S31]andafully-connectedneuralnetwork[S8],andthesecondstackinglayercon-sistsofafully-connectedneuralnetwork[S8].Thegradi-entboosteddecisiontree[S31]optimizesabsoluteerrorEq.5andtheneuralnetworksoptimizesquarederrorEq.S1.Moreover,werestricttheneuralnetworkstoonehiddenlayerinordertoavoidoverﬁtting,theactivationfunctionisthehyperbolictangentfunction,andtheopti-mizationalgorithmisthelimited-memoryvariantoftheBroyden-Fletcher-Goldfarb-Shannoalgorithm.Asnotedinthemainbody,Alg.1winsthemodelselec-tionstepinAlg.2,soAlg.2makesacalltoAlg.1,whichtakesasinputtransformedtrainingexamplesEq.11,numberofiterationsKj=1,squarederrorandab-soluteerrorsingle-targetlossfunctions{‘j,˜‘j},respec-tively,stackingregressor[S8,S11,S12]basisfunctionb.Inline(a)squarederror‘jisused.Inline(b)thepa-rametersetsareinducedwiththestackingregressor[S8].Inline(c),weappendedanL1regularizationtermtotheoptimizationproblemargminαmtrainXi=1‘j(Y(i)j,hj,k−1(X(i))+αb(X(i);θj,k))+λ|α|.WesolvetheoptimizationproblemwiththeNelder-Meadmethod,whereλ=0.1.Infutureapplications,severalmodiﬁcationsofAlg.1maybeofinterest:inclusionofotherregularizationterms,earlystopping,out-of-bag-errorestimates,orsamplingtechniquesforvariancere-duction;seereferences[S6,S8,S25,S27].InplottingtheaugmentedlearningcurvesinFig.4andinFig.S5,wemodifythesourcecodeinref-erence[S8]tousethesamewithheldfoldsforthecross-validationerrorandtheincumbenterror.Thetrainingsizesintheplotsfromlefttorightare23,25,27,29,31,32,34,36,38,40,42,43,45,47,49,51,52,54,56,58,60,62,63,65,67,69,71,73,74,76,78,80,82,84,85,87,89,91,93,95,respectively.Inplottingthesum-maryplotsinFig.5andinFig.S8,weutilizetheSHAPframework[S34].Foreachsummaryplot,weinduceafully-connectedneuralnetwork[S8].Werestricttheneuralnetworktoonehiddenlayer,theactivationfunctionistherectiﬁedlinearunit,andtheoptimizationalgorithmisthelimited-memoryvariantoftheBroyden-Fletcher-Goldfarb-Shannoalgorithm.WecomputetheSHAPvalueswithKernelSHAP[S34].S6.AUGMENTEDLEARNINGCURVESInthemainbody,weillustratedtheinbuiltmodelse-lectionstepinAlg.2withanaugmentedlearningcurveforthesingle-targetregressionsubtaskY3withtrainingsizesvaryingbetween23to95orderedpairsinFig.4.Here,weillustratetheinbuiltmodelselectionstepinAlg.2withaugmentedlearningcurvesforthesingle-targetregressionsubtasksY1(top),Y2(topmiddle),Y4(bottommiddle),andY5(bottom)withtrainingsizesvaryingbetween23to95orderedpairsinFig.S5.Forthesingle-targetregressionsubtasksY1(top),Y2(topmiddle),andY5(bottom),thecandidatealwaysper-formsbetterthantheincumbent.Forthesingle-targetregressionsubtaskY4(bottommiddle),whentherearelessthan60orderedpairs,theincumbentusuallyper-formsbetter,whereasthecandidatealwaysoutperformstheincumbentwith60,ormore,orderedpairs.TheseaugmentedlearningcurveshighlighttheimportanceoftheinbuiltmodelselectionstepinAlg.2,astheincor-porationofpriorknowledgeintoAlg.1doesnotalwaysimproveperformanceoverthebaseregressor.S7.UTILITYOFTHEDATAPREPROCESSORInthissection,wedescribethetabularasalearningofthemulti-targets[S15,S35–S39],whichenablesourutil-itystudyoftheclassicalcontrolprogram[S2,S3,S5]asadatapreprocessorforthedownstreamboostingalgo-rithminthelearningframework(seeFig.1).Moreover,weshowthesummaryplots[S34]forthesingle-targetregressionsubtasksYj,wherej∈{2,3,4,5}.Inthissetting,letX⊆R9bethedomainofqubitandcouplerbiases[S1–S3,S5]inaninstanceofthemany-bodyRamseyspectroscopytechnique[S2].LetY⊆R5bethetargetspaceofmulti-targetobservations,asinthemainbody.WearegivenaﬁnitesequenceoflabeledexamplesEq.3,whereweregardacollectionof5qubitand4couplerbiasfeaturesasanexample,andtheasso-ciatedmulti-targetobservationasthelabel.Further,weretainthesamedatasplitasinthemainbody,sotherearemtrain=95trainingexamplesandmtest=41testexamples.Werepresentthetrainingdatawitha95×14design6FIG.S5.Augmentedlearningcurvesforthesingle-targetregressionsubtasksY1,Y2,Y4,andY5,fromtop-to-bottomrespectively.Weshowthetraining,cross-validation,andin-cumbenterrorsforvaryingamountsoftrainingexamplesinblue,orange,andred,respectively.FIG.S6.Usingtheabsoluteerrorlossfunctionasthecri-terion,wecomparethebestperformingsingle-targetregres-sorswithoutpriorknowledgeagainstourlearningsystemwithpriorknowledgeinblueandorange,respectively.Disregard-ingthepriorknowledgedegradesperformancebyover729%onthebenchmarktask.matrixX(1)Y(1)X(2)Y(2)......X(mtrain)Y(mtrain).(S14)Next,wesliceEq.S14intosingle-targettrainingdataEq.11foreachsingle-targetregressionsubtaskYj,wherej∈{1,2,...,5}andtheshapeofeachmatrixis95×10.Weemploymodelselectiontochoosethebestperformingsingle-targetregressorforeachsingle-targetregressionsubtask,whilerestrictingthesearchtoasinglecomplexmodel(detailsinMethods).Weﬁndafully-connectedneuralnetwork[S8]withasingle-hiddenlayerasthebestperformingsingle-targetregressorforeachsingle-targetregressionsubtask.Afterinducingeachfully-connectedneuralnetworkonEq.11,weevaluatethetesterrorusingtheabsoluteerrorlossfunctioninFig.S6.Disregardingthepriorknowledgedegradesperformancebyover729%onthebenchmarktask.Aswehavealreadygeneratedthetestexamplepredictions,weutilizethesquarederrorlossfunctiontomeasurethepredictionperformanceinFig.S7.Disregardingthepriorknowledgedegradesper-formancebyover5426%onthemulti-targetregressiontask.Inthemainbody,weattainedanoverviewofthemostimportantqubitandcouplerbiasfeaturesforthesingle-targetregressionsubtaskY1inFig.5.Here,weshowtheSHAPsummaryplotsfortheremainingsingle-targetregressionsubtasksinFig.S8,whereY2(top),Y3(topmiddle),Y4(topbottom),andY5(bottom).7FIG.S7.Usingthesquarederrorlossfunctionasthecriterion,wecomparethebestperformingsingle-targetregressorswith-outpriorknowledgeagainstourlearningsystemwithpriorknowledgeinblueandorange,respectively.Disregardingthepriorknowledgedegradesperformancebyover5426%onthemulti-targetregressiontask.FIG.S8.SHAPsummaryplots[S34]forsingle-targetsY2,Y3,Y4,andY5,fromtop-to-bottomrespectively.Ineachplot,weusethecollectionof9qubitandcouplerbiasfeaturesasanexample,andweinduceafullyconnectedneuralnetwork[S8]topredictYj,wherej∈{2,3,4,5}.Thehorizontalaxisiscenteredattheaveragetrainingexampleprediction,andtheverticalaxisascendinglyordersthefeaturesaccordingtotheirimportance.EachpointisaSHAPvalueforaparticularex-ample,thecoloringrepresentsthebiasvalue,andoverlappingpointsarerandomlyjitteredalongtheverticalaxistoavoidcollisions[S34,S40].8[S1]YuChenetal.Qubitarchitecturewithhighcoher-enceandfasttunablecoupling.PhysicalReviewLetters,113:220502,2014.[S2]PedramRoushanetal.Spectroscopicsignaturesoflo-calizationwithinteractingphotonsinsuperconductingqubits.Science,358:1175–1179,2017.[S3]CharlesNeilletal.Ablueprintfordemonstratingquan-tumsupremacywithsuperconductingqubits.Science,360:195–199,2018.[S4]JulianKellyetal.Physicalqubitcalibrationonadi-rectedacyclicgraph.arXiv:1803.03226,2018.[S5]BenjaminChiaroetal.Growthandpreservationofentanglementinamany-bodylocalizedsystem.arXiv:1910.06024,2019.[S6]TrevorHastie,RobertTibshirani,andJeromeFried-man.TheElementsofStatisticalLearning.Springer,2009.[S7]GavinCawleyandNicolaTalbot.Onover-ﬁttinginmodelselectionandsubsequentselectionbiasinper-formanceevaluation.JournalofMachineLearningRe-search,11:2079–2107,2010.[S8]FabianPedregosaetal.Scikit-learn:machinelearn-inginpython.JournalofMachineLearningResearch,12:2825–2830,2011.[S9]HanenBorchanietal.Asurveyonmulti-outputregres-sion.WileyInterdisciplinaryReviews:DataMiningandKnowledgeDiscovery,2015.[S10]WillemWaegeman,KrzysztofDembczy´nski,andEykeH¨ullermeier.Multi-targetprediction:Aunifyingviewonproblemsandmethods.DataMiningandKnowledgeDiscovery,33:293–324,2019.[S11]DavidWolpert.Stackedgeneralization.NeuralNet-works,5:241–259,1992.[S12]LeoBreiman.Stackedregressions.MachineLearning,24:49–64,1996.[S13]LeoBreimanandJeromeFriedman.Predictingmulti-variateresponsesinmultiplelinearregression.RoyalStatisticalSocietySeriesB,59:3–54,1997.[S14]DumitruErhanetal.Whydoesunsupervisedpre-traininghelpdeeplearning?JournalofMachineLearn-ingResearch,11:625–660,2010.[S15]RichCaruana.Multitasklearning.MachineLearning,28:41–75,1997.[S16]JohnTukey.ExploratoryDataAnalysis.Addison-Wesley,1977.[S17]MichaelKearnsandLeslieValiant.Learningbooleanformulaeorﬁniteautomataisashardasfactoring.TechnicalReportTR-14-88,HarvardUniversityAikenComputationLaboratory,1988.[S18]MichaelKearnsandLeslieValiant.Cryptographiclim-itationsonlearningbooleanformulaeandﬁniteau-tomata.JournaloftheAssociationforComputingMa-chinery,41:67–95,1994.[S19]RobertSchapire.Thestrengthofweaklearnability.Ma-chineLearning,5:197–227,1990.[S20]YoavFreund.Boostingaweaklearningalgorithmbymajority.InformationandComputation,121:256–285,1995.[S21]YoavFreundandRobertSchapire.Adecision-theoreticgeneralizationofon-linelearningandanapplicationtoboosting.JournalofComputerandSystemSciences,55:119–139,1997.[S22]RobertSchapireetal.Incorporatingpriorknowledgeintoboosting.InICML’02:ProceedingsoftheNine-teenthInternationalConferenceonMachineLearning,pages538–545,2002.[S23]TrevorHastieandRobertTibshirani.GeneralizedAd-ditiveModels.ChapmanandHall,London,1990.[S24]JeromeFriedman,TrevorHastie,andRobertTibshi-rani.Additivelogisticregression:Astatisticalviewofboosting.TheAnnalsofStatistics,28(2):337–407,2000.[S25]JeromeFriedmanandBogdanPopescu.Importancesampledlearningensembles.Technicalreport,StanfordUniversity,DepartmentofStatistics,2003.[S26]LeoBreiman.Arcingtheedge.Technicalreport,Stan-fordUniversity,DepartmentofStatistics,1997.[S27]JeromeFriedman.Greedyfunctionapproximation:Agradientboostingmachine.AnnalsofStatistics,29(5):1189–1232,2001.[S28]LlewMasonetal.Boostingalgorithmsasgradientde-scent.InNIPS:Proceedingsofthe12thInternationalConferenceonNeuralInformationProcessing,pages512––518,1999.[S29]PeterB¨uhlmannandTorstenHothorn.Boostingalgo-rithms:Regularization,predictionandmodelﬁtting.StatisticalScience,22(4):477–505,2007.[S30]TianqiChenandCarlosGuestrin.XGBoost:ascal-abletreeboostingsystem.InKDD’16:Proceedingsofthe22ndACMSIGKDDInternationalConferenceonKnowledgeDiscoveryandDataMining,pages785–794,2016.[S31]Guolinkeetal.LightGBM:ahighlyeﬃcientgradientboostingdecisiontree.InAdvancesinNeuralInforma-tionProcessingSystems30,pages3149–3157.CurranAssociates,Inc.,2017.[S32]FabioSigrist.Gradientandnewtonboostingforclassi-ﬁcationandregression.arXiv:1808.03064,2018.[S33]AlexWozniakowski.Scikit-physlearn.github.com/a-wozniakowski/scikit-physlearn,2020.[S34]ScottLundbergandSu-InLee.Auniﬁedapproachtointerpretingmodelpredictions.InAdvancesinNeuralInformationProcessingSystems30,pages4765–4774.CurranAssociates,Inc.,2017.[S35]DavidHume.ATreatiseofHumanNature.ClarendonPress,1739.[S36]DavidHaussler.Quantifyinginductivebias:AIlearningalgorithmsandValiant’slearningframework.ArtiﬁcialIntelligence,36:177–221,1988.[S37]TomMitchell.Theneedforbiasesinlearninggen-eralisation.InJudeShavlikandThomasDietterich,editors,ReadingsinMachineLearning.MorganKauf-mann,1991.[S38]DavidWolpertandWilliamMacready.Nofreelunchtheoremsforoptimization.IEEETransactionsonEvo-lutionaryComputation,1(1),1997.[S39]JonathanBaxter.Amodelofinductivebiaslearning.JournalofArtiﬁcialIntelligenceResearch,12:149–198,2000.[S40]ChristophMolnar.Interpretablemachinelearning:aguideformakingblackboxmodelsexplainable.christophm.github.io/interpretable-ml-book,2020.