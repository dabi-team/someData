9
1
0
2
c
e
D
0
2

]

V
C
.
s
c
[

1
v
1
0
6
9
0
.
2
1
9
1
:
v
i
X
r
a

Divide and Conquer: an Accurate Machine Learning
Algorithm to Process Split Videos on a Parallel
Processing Infrastructure

Walter Mayor Toro
Department of Automatics and Electronics
Universidad Autónoma de Occidente
wmmayor@uao.edu.co

Juan C. Perafan Villota
Department of Automatics and Electronics
Universidad Autónoma de Occidente
jcperafan@uao.edu.co

Oscar H. Mondragon
Department of Automatics and Electronics
Universidad Autónoma de Occidente
ohmondragon@uao.edu.co

Johan S. Obando-Ceron
Department of Automatics and Electronics
Universidad Autónoma de Occidente
jsobando@uao.edu.co

Abstract

Every day the number of trafﬁc cameras in cities rapidly increase and huge amount
of video data are generated. Parallel processing infrastructure, such as Hadoop,
and programming models, such as MapReduce, are being used to promptly process
that amount of data. The common approach for video processing by using Hadoop
MapReduce is to process an entire video on only one node, however, in order to
avoid parallelization problems, such as load imbalance, we propose to process
videos by splitting it into equal parts and processing each resulting chunk on a
different node. We used some machine learning techniques to detect and track the
vehicles. However, video division may produce inaccurate results. To solve this
problem we proposed a heuristic algorithm to avoid process a vehicle in more than
one chunk.

1 Research problem and motivation

According to [1], by 2020 one billion cameras will be installed throughout cities. More cameras
implicate a generation of huge amount of video data. Fortunately, parallel processing ecosystem
based on distributed environments have permitted to face computational complexity and big datasets.
Few intelligent trafﬁc management systems (ITMS) approaches have been developed using parallel
processing infrastructure. Some of those solutions have used the Hadoop MapReduce ecosystem
which allows parallelization of multiple jobs by using several computers or multiple processors in
one computer[2].

In ITMS, researches have used Hadoop MapReduce to sequentially analyze multiple videos by using
batch processing, where each entire video ﬁle is only processed by a unique node [3][4]. In this
case, when the videos are reasonably long, it can arise a problem known as load imbalance. On
the other hand, this way of processing videos only allows to take the maximum advantage of the
parallel ecosystem when the dataset contains a big number of videos [5]. To avoid these problems we
have divided each video to process them by chunks in different nodes. Unfortunately, this approach
brings some problems. For example, if we divide a video, we could ﬁnd a vehicle in different video
chunks, possibly affecting the precision of the analysis algorithm. For the case of a counting vehicles
system, classical algorithms would detect more vehicles in video chunks that when an unsplit video
is analyzed.

Preprint. Under review.

 
 
 
 
 
 
Motivated by the idea of processing chunk videos within a parallel processing ecosystem without
obtaining wrong results, we propose an intelligent video processing algorithm to process the chunks
and avoiding to take the same vehicle into account many times. In the framework we propose, it does
not matter the number and size of chunks in which the video is divided. Machine learning techniques
are used to process videos and detect vehicles. The considerations above motivate the formulation of
the following research question: How to process chunks of video using Hadoop MapReduce in order
to decrease the computational time and reach accurate results?

2 Technical contribution

Our proposed algorithm takes as input datasets of videos from trafﬁc cameras. Some of the videos
we used were taken from YouTube and other videos from trafﬁc cameras of Cali (Colombia) city. We
developed a software platform that allows a user to select a street from a video, where the vehicle
counting will be performed. By drawing lines, the user is able to specify the target counting area.
This conﬁguration is saved in a dataset to be used in futures videos. In the master node, a partitioning
algorithm divides the video in chunks, taking into account the number of data nodes. Each chunk
video is sent to a Hadoop data node, where 3 algorithms are applied: ﬁrst, we detect the vehicles in
the chunk by using the deep learning algorithm YOLO; then, we track each vehicle detected by using
kalman ﬁlters and the hungarian algorithm; and ﬁnally, we ﬁlter the vehicles that were registered
in others chunk videos. The videos are analyzed and the result is saved in a database than can be
continuously accessed for probabilistic analysis in vehicular trafﬁc tasks (see Figure 1).

Figure 1: Framework proposed.

The ﬁltering algorithm uses the initial street conﬁguration (see ﬁgure 2-a ) to deﬁne what vehicles to
track, avoiding to follow the vehicles out of the select street and the vehicles that are part of other
chunks. To identify the vehicles that are in more than one chunk we consider the direction of the
vehicle and the street. Then, we examine if the vehicle was detected before and after the red line
or if the vehicle only was detected after the line some few frames ago. If one of these conditions is
satisﬁed, the vehicle is considered into the chunk, in any other case it is ﬁltered using our heuristic
algorithm. In the experiment of the ﬁgure 2, we counted the number of vehicles that pass by a speciﬁc
place (red line) using two different ways: in a ﬁrst approach we processed the whole video in only
one Hadoop DadaNode (see ﬁgure 2-b), a second experiment consisted on dividing the video into 4
chunks (see ﬁgures 2-c to 2-f) and processing each of them on a different data node. We clearly show
that the ﬁnal result (i.e., the vehicle frequency count) for both experiments was the same, revealing
the accuracy of our approach.

2

(a)

(b)

(c)

(d)

(e)

(f)

Figure 2: Experiment results. (a) Street conﬁguration; (b) entire video processed; (c),(d),(e) and (f)
video processed by chunks

References

[1] Wei, Y., Song, N., Ke, L., Chang, M. C. and Lyu, S. (2017) Street object detection/tracking for AI city trafﬁc
analysis. In 2017 IEEE SmartWorld, Ubiquitous Intelligence & Computing Advanced & Trusted Computed,
Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City
Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI) (pp. 1-5). IEEE.

[2] Triguero, I., Figueredo, G. P., Mesgarpour, M., Garibaldi, J. M. and John, R. I. (2017). Vehicle incident hot
spots identiﬁcation: An approach for big data. In 2017 IEEE Trustcom/BigDataSE/ICESS (pp. 901-908). IEEE.

[3] Rathore, M. M., Son, H., Ahmad, A. and Paul, A. (2018) Real-time video processing for trafﬁc control in
smart city using Hadoop ecosystem with GPUs, Soft Computing 22(5): 1533-1544

[4] Natarajan, V. A., Jothilakshmi, S. and Gudivada, V. N. (2015) Scalable trafﬁc video analytics using hadoop
MapReduce, ALLDATA p 18.

[5] Yoon, I., Yi, S., Oh, C., Jung, H. and Yi, Y. (2018) Distributed Video Decoding on Hadoop, IEICE
TRANSACTIONS on Information and Systems 101(12):2933-2941.

3

