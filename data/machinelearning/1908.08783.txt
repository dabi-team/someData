LEARNING FITNESS FUNCTIONS FOR MACHINE PROGRAMMING

1
2
0
2

n
a
J

3
2

]
E
N
.
s
c
[

5
v
3
8
7
8
0
.
8
0
9
1
:
v
i
X
r
a

Shantanu Mandal 1 Todd Anderson 2 Javier Turek 2 Justin Gottschlich 2 Shengtian Zhou 2 Abdullah Muzahid 1

ABSTRACT
The problem of automatic software generation has been referred to as machine programming. In this work,
we propose a framework based on genetic algorithms to help make progress in this domain. Although genetic
algorithms (GAs) have been successfully used for many problems, one criticism is that hand-crafting GAs ﬁtness
function, the test that aims to effectively guide its evolution, can be notably challenging. Our framework presents
a novel approach to learn the ﬁtness function using neural networks to predict values of ideal ﬁtness functions.
We also augment the evolutionary process with a minimally intrusive search heuristic. This heuristic improves
the framework’s ability to discover correct programs from ones that are approximately correct and does so with
negligible computational overhead. We compare our approach with several state-of-the-art program synthesis
methods and demonstrate that it ﬁnds more correct programs with fewer candidate program generations.

1

INTRODUCTION

In recent years, there has been notable progress in the space
of automatic software generation, also known as machine
programming (MP) (Gottschlich et al., 2018; Ratner et al.,
2019). An MP system produces a program as output that
satisﬁes some input speciﬁcation to the system, often in the
form of input-output examples. The previous approaches
to this problem have ranged from formal program synthe-
sis (Alur et al., 2015; Gulwani et al., 2012) to machine
learning (ML) (Balog et al., 2017a; Devlin et al., 2017;
Reed & de Freitas, 2016; Zohar & Wolf, 2018) as well as
their combinations (Feng et al., 2018). Genetic algorithms
(GAs) have also been shown to have signiﬁcant promise for
MP (Becker & Gottschlich, 2017; Brameier, 2007; Langdon
& Poli, 2010; Perkis, 1994). GA is a simple and intuitive ap-
proach and demonstrates competitive performance in many
challenging domains (Korns, 2011; Real et al., 2018; Such
et al., 2017). Therefore, in this paper, we focus on GA -
more speciﬁcally, a fundamental aspect of GA in the context
of MP.

A genetic algorithm (GA) is a machine learning technique
that attempts to solve a problem from a pool of candidate so-
lutions. These generated candidates are iteratively evolved
and mutated and selected for survival based on a grading
criteria, called the ﬁtness function. Fitness functions are
usually hand-crafted heuristics that grade the approximate
correctness of candidate solutions such that those that are

1Department of Computer Science and Engineering, Texas
A&M University 2Intel Labs. Correspondence to: Abdullah Muza-
hid <abdullah.muzahid@tamu.edu>.

closer to being correct are more likely to appear in subse-
quent generations.

In the context of MP, candidate solutions are programs,
initially random but evolving over time to get closer to a
program satisfying the input speciﬁcation. Yet, to guide that
evolution, it is particularly difﬁcult to design an effective
ﬁtness function for a GA-based MP system. The ﬁtness
function is given a candidate program and the input speciﬁ-
cation (e.g., input-output examples) and from those, must
estimate how close that candidate program is to satisfying
the speciﬁcation. However, we know that a program having
only a single mistake may produce output that in no obvious
way resembles the correct output. That is why, one of the
most frequently used ﬁtness functions (i.e., edit-distance be-
tween outputs) in this domain (Becker & Gottschlich, 2017;
Brameier, 2007; Langdon & Poli, 2010; Perkis, 1994) will
in many cases give wildly wrong estimates of candidate pro-
gram correctness. Thus, it is clear that designing effective
ﬁtness functions for MP are difﬁcult.

Designing simple and effective ﬁtness functions is a unique
challenge for GA. Despite many successful applications
of GA, it still remains an open challenge to automate the
generation of such ﬁtness functions. An impediment to this
goal is that ﬁtness function complexity tends to increase
proportionally with the problem being solved, with MP
being particularly complex. In this paper, we explore an
approach to automatically generate these ﬁtness functions by
representing their structure with a neural network. While we
investigate this technique in the context of MP, we believe
the technique to be applicable and generalizable to other
domains. We make the following technical contributions:

• Fitness Function: Our fundamental contribution is in

 
 
 
 
 
 
Learning Fitness Functions for Machine Programming

the automation of ﬁtness functions for genetic algo-
rithms. We propose to do so by mapping ﬁtness func-
tion generation as a big data learning problem. To the
best of our knowledge, our work is the ﬁrst of its kind
to use a neural network as a genetic algorithm’s ﬁtness
function for the purpose of MP.

• Convergence: A secondary contribution is in our uti-
lization of local neighborhood search to improve the
convergence of approximately correct candidate solu-
tions. We demonstrate its efﬁcacy empirically.

• Generality: We demonstrate that our approach can
support different neural network ﬁtness functions, uni-
formly. We develop a neural network model to predict
the ﬁtness score based on the given speciﬁcation and
program trace.

• Metric: We contribute a new metric suitable for MP
domain. The metric, “search space” size (i.e., how
many candidate programs have been searched), is an
alternative to program generation time, and is designed
to emphasize the algorithmic efﬁciency as opposed to
the implementation efﬁciency of an MP approach.

2 RELATED WORK

Machine programming can be achieved in many ways. One
way is by using formal program synthesis, a technique that
uses formal methods and rules to generate programs (Manna
& Waldinger, 1975). Formal program synthesis usually
guarantees some program properties by evaluating a gener-
ated program’s semantics against a corresponding speciﬁ-
cation (Alur et al., 2015; Gulwani et al., 2012). Although
useful, such formal synthesis techniques can often be lim-
ited by exponentially increasing computational overhead
that grows with the program’s instruction size (Bodík &
Jobstmann, 2013; Cheung et al., 2012; Heule et al., 2016;
Loncaric et al., 2018; Solar-Lezama et al., 2006).

An alternative to formal methods for MP is to use machine
learning (ML). Machine learning differs from traditional for-
mal program synthesis in that it generally does not provide
correctness guarantees. Instead, ML-driven MP approaches
are usually only probabilistically correct, i.e., their results
are derived from sample data relying on statistical signiﬁ-
cance (Murphy, 2012). Such ML approaches tend to explore
software program generation using an objective function.
Objective functions are used to guide an ML system’s ex-
ploration of a problem space to ﬁnd a solution.

Raychev et al. (Raychev et al., 2014) take a different ap-
proach and use an n-gram model to predict the functions
that are most likely to complete a partially constructed pro-
gram. Robustﬁll (Devlin et al., 2017) encodes input-output
examples using a series of recurrent neural networks (RNN),
and generates the the program using another RNN one token
at a time. Bunel et al. (Bunel et al., 2018) explore a unique
approach that combines reinforcement learning (RL) with
a supervised model to ﬁnd semantically correct programs.
These are only a few of the works in the MP space using
neural networks (Cai et al., 2017; Chen et al., 2018; Reed &
de Freitas, 2016).

Signiﬁcant research has been done in the ﬁeld of genetic pro-
gramming (Brameier, 2007; Langdon & Poli, 2010; Perkis,
1994) whose goal is to ﬁnd a solution in the form of a com-
plete or partial program for a given speciﬁcation. Prior work
in this ﬁeld has tended to focus on either the representation
of programs or operators during the evolution process. Real
et al. (Real et al., 2019) recently demonstrated that genetic
algorithms can generate accurate image classiﬁers. Their
approach produced a state-of-the-art classiﬁer for CIFAR-
10 (Krizhevsky, 2009) and ImageNet (Deng et al., 2009)
datasets. Moreover, genetic algorithms have been exploited
to successfully automate the neural architecture optimiza-
tion process (Labs; Liu et al., 2017; Real et al., 2020; Sali-
mans et al., 2017; Such et al., 2017). Even with this notable
progress, genetic algorithms can be challenging to use due
to the complexity of hand-crafting ﬁtness functions that
guide the search. We claim that our proposed approach is
the ﬁrst of its kind to automate the generation of ﬁtness
functions.

3 BACKGROUND

Let St = {(Ij, Ot
j)}m
j=1 be a set of m input-output pairs,
such that the output Ot
j is obtained by executing the program
P t on the input Ij. Inherently, the set St of input-output
examples describes the behavior of the program P t. One
would like to synthesize a program P t(cid:48)
that recovers the
same functionality of P t. However, P t is usually unknown,
and we are left with the set St, which was obtained by run-
ning P t. Based on this assumption, we deﬁne equivalency
between two programs as follows:

Deﬁnition 3.1 (Program Equivalency). Programs P a and
P b are equivalent under the set S = {(Ij, Oj)}m
j=1 of input-
output examples if and only if P a(Ij) = P b(Ij) = Oj, for
1 ≤ j ≤ m. We denote the equivalency by P a ≡S P b.

More recently, there has been a surge of research exploring
ML-based MP using neural networks (NNs). For example,
in (Balog et al., 2017b), the authors train a neural network
with input-output examples to predict the probabilities of
the functions that are most likely to be used in a program.

Deﬁnition 3.1 suggests that to obtain a program equivalent
to P t, we need to synthesize a program that is consistent
with the set St. Therefore, our goal is ﬁnd a program P t(cid:48)
that is equivalent to the target program P t (which was used
to generate St), i.e., P t(cid:48)
≡St P t. This task is known as

Learning Fitness Functions for Machine Programming

Figure 1. Overview of NetSyn. Phase 1 automates the ﬁtness function generation by training a neural network on a corpus of example
programs and their inputs and outputs. Phase 2 ﬁnds the target program for a given input-output example using the trained neural network
as a ﬁtness function in a genetic algorithm.

Inductive Program Synthesis (IPS). As suggested by (Balog
et al., 2017b), a machine learning based solution to the IPS
problem requires the deﬁnition of some components. First,
we need a programming language that deﬁnes the domain of
valid programs. Second, we need a method to search over
the program domain. The search method sweeps over the
program domain to ﬁnd P t(cid:48)
that satisﬁes the equivalency
property. Optionally, we may want to deﬁne a ranking
function to rank all the solutions found and choose the best
ones. Last, as we plan to base our solution on machine
learning techniques, we will need data to train models.

4 NETSYN

Here, we describe our solution to IPS in more detail, in-
cluding the choices and novelties for each of the proposed
components. We name our solution NetSyn as it is based on
neural networks for program synthesis.

4.1 Domain Speciﬁc Language

As NetSyn’s programming language, we choose a domain
speciﬁc language (DSL) constructed speciﬁcally for it. This
choice allows us to constrain the program space by restrict-
ing the operations used by our solution. NetSyn’s DSL
follows the DeepCoder’s DSL (Balog et al., 2017b), which
was inspired by SQL and LINQ (Dinesh et al., 2007). The
only data types in the language are (i) integers and (ii) lists
of integers. The DSL contains 41 functions, each taking one
or two arguments and returning one output. Many of these
functions include operations for list manipulation. Likewise,
some operations also require lambda functions. There is no

explicit control ﬂow (conditionals or looping) in the DSL.
However, several of the operations are high-level functions
and are implemented using such control ﬂow structures. A
full description of the DSL can be found in the supplemen-
tary material. With these data types and operations, we
deﬁne a program P as a sequence of functions. Table 1
presents an example of a program of 4 instructions with an
input and respective output.

Arguments to functions are not speciﬁed via named vari-
ables. Instead, each function uses the output of the previ-
ously executed function that produces the type of output that
is used as the input to the next function. The ﬁrst function
of each program uses the provided input I. If I has a type
mismatch, default values are used (i.e., 0 for integers and
an empty list for a list of integers). The ﬁnal output of a
programs is the output of its last function.

Table 1. An example program of length 4 with an input and corre-
sponding output.
[int]
FILTER (>0)
MAP (*2)
SORT
REVERSE

Input:
[-2, 10, 3, -4, 5, 2]

Output:
[20, 10, 6, 4]

As a whole, NetSyn’s DSL is novel and amenable to genetic
algorithms. The language is deﬁned such that all possible
programs are valid by construction. This makes the whole
program space valid and is important to facilitate the search
of programs by any learning method. In particular, this is
very useful in evolutionary process in genetic algorithms.

SolutionEvolve : Crossover and MutateGenetic AlgorithmCandidate genesRestricted Local Neighborhood SearchLocal proximity searchTop N candidate genesSolution found?Generate output on target inputNo, InferenceYesSearchNoSearch or evolve?NN fitness functionx2x1h1h2h3yStartYesCandidate output matches targetoutput?Target inputTarget outputRandom initializationTraining set Generate input-outputInput-output examplesTrainEmbed input and output, train neural network (NN)Phase 1: Fitness Function GenerationGenerated fitness function as NNx2x1h1h2h3yPhase 2: Program GenerationLearning Fitness Functions for Machine Programming

When genetic crossover occurs between two programs or
mutation occurs within a single program, the resulting pro-
gram will always be valid. This eliminates the need for
pruning to identify valid programs.

4.2 Search Process

NetSyn synthesizes a program by searching the program
space with a genetic algorithm-based method (Thomas,
It does this by creating a population of random
2009).
genes (i.e., candidate programs) of a given length L and
uses a learned neural network-based ﬁtness function (NN-
FF) to estimate the ﬁtness of each gene. Higher graded
genes are preferentially selected for crossover and mutation
to produce the next generation of genes. In general, NetSyn
uses this process to evolve the genes from one generation
to the next until it discovers a correct candidate program as
veriﬁed by the input-output examples. From time to time,
NetSyn takes the top N scoring genes from the population,
determines their neighborhoods, and looks for the target
program using a local proximity search. If a correctly gen-
erated program is not found within the neighborhoods, the
evolutionary process resumes. Figure 1 summarizes the
NetSyn’s search process.

We use a value encoding approach for each gene. A gene
ζ is represented as a sequence of values from ΣDSL, the
set of functions. Formally, a gene ζ = (f1, . . . , fi, . . . , fL),
where fi ∈ ΣDSL. Practically, each fi contains an identi-
ﬁer (or index) corresponding to one of the DSL functions.
The encoding scheme satisﬁes a one-to-one match between
programs and genes.

The search process begins with a set Φ0 of |Φ0| = T ran-
domly generated programs. If a program equivalent to the
target program P t is found, the search process stops. Other-
wise, the genes are ranked using a learned NN-FF. A small
percentage (e.g., 20%) of the top graded genes in Φj are
passed in an unmodiﬁed fashion to the next generation Φj+1
for the next evolutionary phase. This guarantees that some
of the top graded genes are identically preserved, aiding in
forward progress guarantees. The remaining genes of the
new generation Φj+1 are created through crossover or mu-
tation with some probability. For crossover, two genes from
Φj are selected using the Roulette Wheel algorithm with
the crossover point selected randomly (Goldberg, 1989).
For mutation, one gene is Roulette Wheel selected and the
mutation point k in that gene is selected based on the same
learned NN-FF. The selected value zk is mutated to some
other random value z(cid:48) such that z(cid:48) ∈ ΣDSL and z(cid:48) (cid:54)= zk.

Crossovers and mutations can occasionally lead to a new
gene with dead code. To address this issue, we eliminate
dead code. Dead code elimination (DCE) is a classic com-
piler technique to remove code from a program that has no
effect on the program’s output (Debray et al., 2000). Dead

code is possible in our list DSL if the output of a statement
is never used. We implemented DCE in NetSyn by track-
ing the input/output dependencies between statements and
eliminating those statements whose outputs are never used.
NetSyn uses DCE during candidate program generation and
during crossover/mutation to ensure that the effective length
of the program is not less than the target program length
due to the presence of dead code. If dead code is present,
we repeat crossover and mutation until a gene without dead
code is produced.

4.2.1 Learning the Fitness Function

Evolving the population of genes in a genetic algorithm
requires a ﬁtness function to rank the ﬁtness (quality) of
genes based on the problem being solved. Ideally, a ﬁtness
function should measure how close a gene is to the solution.
Namely, it should measure how close a candidate program
is to an equivalent of P t under St. Finding a good ﬁtness
function is of great importance to reduce the number of
steps in reaching the solution and directing the algorithm in
the right direction so that genetic algorithm are more likely
to ﬁnd P t.

Intuition: A ﬁtness function, often, is handcrafted to ap-
proximate some ideal function that is impossible (due to
incomplete knowledge about the solution) or too computa-
tionally intensive to implement in practice. For example, if
we knew P t beforehand, we could have designed an ideal
ﬁtness function that compares a candidate program with
P t and calculates some metric of closeness (e.g., edit dis-
tance, the number of common functions etc.) as the ﬁtness
score. Since we do not know P t, we cannot implement the
ideal ﬁtness function. Instead, in this work, we propose to
approximate the ideal ﬁtness function by learning it from
training data (generated from a number of known programs).
For this purpose, we use a neural network model. We train
it with the goal of predicting the values of an ideal ﬁtness
function. We call such an ideal ﬁtness function (that would
always give the correct answer with respect to the actual
solution) the oracle ﬁtness function as it is impossible to
achieve in practice merely by examining input-output exam-
ples. In this case, our models will not be able to approach the
100% accuracy of the oracle but rather will still have sufﬁ-
ciently high enough accuracy to allow the genetic algorithm
to make forward progress. Also, we note that the trained
model needs to generalize to predict for any unavailable
solution and not a single speciﬁc target case.

We follow ideas from works that have explored the au-
tomation of ﬁtness functions using neural networks for
approximating a known mathematical model. For exam-
ple, Matos Dias et al. (Matos Dias et al., 2014) automated
them for IMRT beam angle optimization, while Khuntia
et al. (Khuntia et al., 2005) used them for rectangular mi-

Learning Fitness Functions for Machine Programming

Figure 2. Neural network ﬁtness function for (a) single and (b) multiple IO examples. In each ﬁgure, layers of LSTM encoders are used to
combine multiple inputs into hidden vectors for the next layer. Final ﬁtness score is produced by the fully connected layer.

crostrip antenna design automation. In contrast, our work
is fundamentally different in that we use a large corpus
of program metadata to train our models to predict how
close a given, incorrect solution could be from an unknown
correct solution (that will generate the correct output). In
other words, we propose to automate the generation of ﬁt-
ness functions using big data learning. To the best of our
knowledge, NetSyn is the ﬁrst proposal for automation of
ﬁtness functions in genetic algorithms. In this paper, we
demonstrate this idea using MP as the use case.
Given the input-output samples St = (cid:8)(cid:0)Ij, Ot
of the
target program P t and an ideal ﬁtness function f it(·), we
would like a model that predicts the ﬁtness value f it(ζ, P t)
for a gene ζ. In practice, our model predicts the values of
f it(·) from input-output samples in St and from execution
traces of the program P ζ (corresponding to ζ) by running
with those inputs. Intuitively, execution traces provide in-
sights of whether the program P ζ is on the right track.

(cid:1)(cid:9)

j

j

In NetSyn, we use a neural network to model the ﬁtness
function, referred to as NN-FF. This task requires us to
generate a training dataset of programs with respective input-
output samples. To train the NN-FF, we randomly generate
a set of example programs, E = {P ej }, along with a set
of random inputs I j = {I ej
i } per program P ej . We then
execute each program P ej in E with its corresponding input
set I j to calculate the output set Oj. Additionally, for each
P ej in E, we randomly generate another program P rj =
2 , ..., f rj
1 , f rj
(f rj
k is a function from the DSL
i.e., f rj
k ∈ ΣDSL. We apply the previously generated input
I ej
i1 , trj
i2 , ..., trj
to P r
in),
i
i ) and trj
where trj
in =
i ). Thus, the input set I j = {I ej
n (trj
f rj
i }
of the program P ej produces a set of traces T j = {T rj
i }

j to get an execution trace, T rj
ik = f rj

i(n−1)) = P rj (I ej

i = (trj
1 (I ej

i(k−1)) with trj

n ), where f rj

i1 = f rj

k (trj

from the program P rj . We then compare the programs
P rj and P ej to calculate the ﬁtness value and use it as an
example to train the neural network.

i

, Oej

k , trj

In NetSyn, the inputs of NN-FF consist of input-output
examples, generated programs, and their execution traces.
Let us consider the case of a single input-output example,
(I ej
i ). Let us assume that P ej is the target program
i
that NetSyn attempts to generate and in the process, it gener-
ates P rj as a potential equivalent. NN-FF uses (I ej
, Oej
i ),
i
and {(f rj
, Oej
ik)} as the inputs. Each of (I ej
i ), and
trj
ik are passed through an embedding layer followed by an
LSTM encoder. f rj
k is passed as a one-hot-encoding vec-
tor. Figure 2(a) shows the NN-FF architecture for a single
input-output example. Two layers of LSTM encoders com-
bines the vectors to produce a single vector, H j
i , which is
then processed through fully connected layers to predict the
ﬁtness value. In order to handle a set of input-output exam-
ples, {(I ej
i )}, a set of execution traces, T j = {T rj
i },
i
is collected from a single generated program, P rj . Each
input-output example along with the corresponding execu-
tion trace produces a single vector, H j
i . An LSTM encoder
combines such vectors to produce a single vector, which
is then processed by fully connected layers to predict the
ﬁtness value (Figure 2(b)).

, Oej

Example: To illustrate, suppose the program in Table 1 is
in E. Let us assume that P rj is another program {[INT],
FILTER (>0), MAP (*2), REVERSE, DROP (2)}. If we use
the input in Table 1 (i.e., [-2, 10, 3, -4, 5, 2]) with P rj , the
execution trace is {[10, 3, 5, 2], [20, 6, 10, 4], [4, 10, 6, 20],
[6, 20]}. So, the input of NN-FF is {[-2, 10, 3, -4, 5, 2],
[20, 10, 6, 4], F ilterv, [10, 3, 5, 2], M apv, [20, 6, 10, 4],
Reversev, [4, 10, 6, 20], Dropv, [6, 20]}. fv indicates the
value corresponding to the function f .

There are different ways to quantify how close two programs

Input1Output1EmbeddingEmbeddingLSTMLSTMf1t1One-hot-encodingEmbeddingLSTMfntnOne-hot-encodingEmbeddingLSTMLSTMLSTMLSTMLSTMHidden Vector (H1)Fully Connected Fully Connected Fitness ValueIO Example1Program, Trace1IO Example1, Program, Trace1IO Examplem, Program, TracemLSTM LayersLSTM LayersHidden Vector (Hm)Hidden Vector (H1)LSTMLSTMFully Connected Fully Connected Fitness Value(a)(b)……Learning Fitness Functions for Machine Programming

are to one another. Each of these different methods then has
an associated metric and ideal ﬁtness value. We investigated
three such metrics – common functions, longest common
subsequence, and function probability – which we use as
the expected predicted output for the NN-FF.

Common Functions: NetSyn can use the number of
common functions (CF) between P ζ and P t as a ﬁtness
value for ζ.
In other words, the ﬁtness value of ζ is
P t (ζ) = |elems(P ζ) ∩ elems(P t)|. For the earlier
f CF
example, f CF will be 3. Since the output of the neural
network will be an integer from 0 to len(Pt), the neural
network can be designed as a multiclass classiﬁer with a
softmax layer as the ﬁnal layer.

Longest Common Subsequence: As an alternative to
CF, we can use longest common subsequence (LCS) be-
tween P ζ and P t. The ﬁtness score of ζ is f LCS
(ζ) =
len(LCS (P ζ, P t)). Similar to CF, training data can be
constructed from E which is then fed into a neural network-
based multiclass classiﬁer. For the earlier example, f LCS
will be 2.

P t

j)}m

Function Probability: The work (Balog et al., 2017b) pro-
posed a probability map for the functions in the DSL. Let
us assume that the probability map p is deﬁned as the prob-
ability of each DSL operation to be in P t given the input-
output samples. Namely, p = (p1, . . . , pk, . . . , p|ΣDSL|)
such that pk = P rob(opk ∈ elems(P t)|{(Ij, Ot
j=1),
where opk is the kth operation in the DSL. Then, a mul-
ticlass, multilabel neural network classiﬁer with sigmoid
activation functions used in the output of the last layer can
be used to predict the probability map. Training data can
be constructed for the neural network using E. We can
use the probability map to calculate the ﬁtness score of ζ
as f F P
k:opk∈elems(P ζ ) pk. NetSyn also uses the
probability map to guide the mutation process. For example,
instead of mutating a function zk with z(cid:48) that is selected ran-
domly, NetSyn can select z(cid:48) using Roulette Wheel algorithm
using the probability map.

P t (ζ) = (cid:80)

4.2.2 Local Neighborhood Search

Neighborhood search (NS) checks some candidate genes
in the neighborhood of the N top scoring genes from the
genetic algorithm. The intuition behind NS is that if the
target program P t is in that neighborhood, NetSyn may
be able to ﬁnd it without relying on the genetic algorithm,
which would likely result in a faster synthesis time.

Let us assume that NetSyn has completed l generations.
Then, let µl−w+1,l denote the average ﬁtness score of genes
for the last w generations (i.e., from l − w + 1 to l) and
µ1,l−w will denote the average ﬁtness score before the last
w generations (i.e., from 1 to l − w). Here, w is the sliding
window. NetSyn invokes NS if µl−w+1,l ≤ µ1,l−w. The

(a) BFS-based

(b) DFS-based

Figure 3. Examples of neighborhood using (a) BFS- and (b) DFS-
based approach. Each neighborhood constructs a set of close-by
genes by systematically changing one function at a time.

rationale is that under these conditions, the search procedure
has not produced improved genes for the last w generations
(i.e., saturating). Therefore, it should check if the neighbor-
hood contains any program equivalent to P t.

Algorithm 1 Deﬁnes and searches neighborhood based on
BFS principle
Input: A set G of top N scoring genes
Output: P t(cid:48)

, if found, or Not found otherwise

1 for Each ζ ∈ G do
N H ← ∅
2
for i ← 1 to len(ζ) do

3

4

5

6

7

8

for j ← 1 to|ΣDSL| do

ζn ← ζ with ζi
such that ζi (cid:54)= opj
N H ← N H ∪ {ζn}

replaced with opj

if there is P t(cid:48)
return P t(cid:48)

∈ N H such that P t(cid:48)

≡St P t then

9 return Not found

Neighborhood Deﬁnition: Algorithm 1 shows how to de-
ﬁne and search a neighborhood. The algorithm is inspired
by the breadth ﬁrst search (BFS) method. For each top scor-
ing gene ζ, NetSyn considers one function at a time starting
from the ﬁrst operation of the gene to the last one. Each
selected operation is replaced with all other operations from
ΣDSL, and inserts the resultant genes into the neighborhood
set N H. If a program P t(cid:48)
equivalent to P t is found in N H,
NetSyn stops there and returns the solution. Otherwise, it
continues the search and returns to the genetic algorithm.
The complexity of the search is O(N · len(ζ) · |ΣDSL|),
which is signiﬁcantly smaller than the exponential search
space used by a traditional BFS algorithm. Similar to BFS,
NetSyn can deﬁne and search the neighborhood using an

............i=1i=lenj=1j=|f|(c).........i=1i=lenj=1...(d)j=|f|............i=1i=lenj=1j=|f|(c).........i=1i=lenj=1...(d)j=|f|Learning Fitness Functions for Machine Programming

approach similar to depth ﬁrst search (DFS). It is similar
to Algorithm 1 except i keeps track of depth here. After
the loop in line 4 ﬁnishes, NetSyn picks the best scoring
gene from N H to replace ζ before going to the next level
of depth. The algorithmic complexity remains the same.
Figure 3(a) and (b) show examples of neighborhood using
BFS- and DFS-based approach.

5 EXPERIMENTAL RESULTS

We implemented NetSyn in Python with a TensorFlow back-
end (Abadi et al., 2015). We developed an interpreter for
NetSyn’s DSL to evaluate the generated programs. We used
4,200,000 randomly generated unique example programs
of length 5 to train the neural networks. We used 5 input-
output examples for each program to generate the training
data. To allow our model to predict equally well across all
possible CF/LCS values, we generate these programs such
that each of the 0-5 possible CF/LCS values for 5 length
programs are equally represented in the dataset. To test
NetSyn, we randomly generated a total of 100 programs for
each program length from 5 to 10. For each program length,
50 of the generated programs produce a singleton integer as
the output; the rest produce a list of integers. We therefore
refer to the ﬁrst 50 programs as singleton programs and the
rest as list programs. We collected m = 5 input-output
examples for each testing program. When synthesizing a
program using NetSyn, we execute it K = 10 times and
average the results to eliminate any noise.

5.1 Demonstration of Synthesis Ability

We ran three variants of NetSyn - NetSynCF , NetSynLCS ,
and NetSynFP , each predicting f CF , f LCS , and f FP ﬁt-
ness functions, respectively. Each used N SBF S and FP-
based mutation operation. We ran the publicly available
best performing implementations of DeepCoder (Balog
et al., 2017b), PCCoder (Zohar & Wolf, 2018), and Robust-
Fill (Devlin et al., 2017). We also implemented a genetic
programming-based approach, PushGP (Perkis, 1994). For
comparison, we also tested two other ﬁtness functions: 1)
edit-distance between outputs (f Edit ), and 2) the oracle
(f Oracle ). For every approach, we set the maximum search
space size to 3,000,000 candidate programs. If an approach
does not ﬁnd the solution before reaching that threshold, we
conclude the experiment marking it as “solution not found”.

Figure 4(a) - (c) show comparative results using the pro-
posed metric: search space used. For each test program, we
count the number of candidate programs searched before
the experiment has concluded by either ﬁnding a correct
program or exceeding the threshold. The number of can-
didate programs searched is expressed as a percentage of
the maximum search space threshold, i.e., 3,000,000 and
shown in y-axis. We sort the time taken to synthesize the

programs. A position N on the X-axis corresponds to the
program synthesized in the Nth longest percentile time of
all the programs. Lines terminate at the point at which the
approach fails to synthesize the corresponding program. For
all approaches, except for f Edit-based NetSyn and PushGP,
up to 30% of the programs can be synthesized by searching
less than 2% of the maximum search space. Search space
use increases when an approach tries to synthesize more
programs. In general, DeepCoder, PCCoder, and RobustFill
search more candidate programs than f CF , f LCS or f FP -
based NetSyn. For example, for synthesizing programs of
length 5, DeepCoder, PCCoder and RobustFill use 37%,
33%, and 47% search space to synthesize 40%, 50%, and
60% programs, respectively. In comparison, NetSyn can
synthesize upwards of 90% programs by using less than
60% search space. NetSyn synthesizes programs at per-
centages ranging from 65% (in case of NetSynFP for 10
length programs) to as high as 97% (in case of NetSynLCS
for 5 length programs). In other words, NetSyn is more
efﬁcient in generating and searching likely target programs.
Even for length 10 programs, NetSyn can generate 65% of
the programs using less than 45% of the maximum search
space. In contrast, DeepCoder, PCCoder, and RobustFill
cannot synthesize more than 60% of the programs even
if they use the maximum search space. PushGP and edit
distance-based approaches always use more search space
than f CF or f LCS .

Figure 4(d) - (f) show the distribution of synthesis rate (i.e.,
what percentage of K = 10 runs synthesizes a particular
program) in violin plots. A violin plot shows interquartile
range (i.e., middle 50% range) as a vertical black bar with
the median as a white dot. Moreover, wider section of the
plot indicates more data points in that section. For 5 length
programs, NetSyn has a high synthesis rate (close to 100%)
for almost every program (as indicated by one wide section).
On the other hand, DeepCoder, PCCoder, RobustFill, and
PushGP have bimodal distributions as indicated by two wide
sections. At higher lengths, NetSyn synthesizes around 65%
to 75% programs and therefore, the distribution becomes
bimodal with two wide sections. However, the section at the
top is wider indicating that NetSyn maintains high synthesis
rate for the successful cases. DeepCoder, PCCoder, Robust-
Fill, and PushGP have more unsuccessful cases than the
successful ones. However, for the successful cases, these
approaches also have high synthesis rates.

Figure 4(g) - (i) show comparative results using synthesis
time as the metric. In general, DeepCoder, PCCoder, Ro-
bustFill and NetSyn can synthesize up to 20% programs
within a few seconds for all program lengths we tested. As
expected, synthesis time increases as an approach attempts
to synthesize more difﬁcult programs. DeepCoder, PCCoder,
and RobustFill usually ﬁnd solutions faster than NetSyn. It
should be noted that the goal of NetSyn is to synthesize a

Learning Fitness Functions for Machine Programming

(a) Program length = 5

(b) Program length = 7

(c) Program length = 10

(d) Program length = 5

(e) Program length = 7

(f) Program length = 10

(g) Program length = 5

(h) Program length = 7

(i) Program length = 10

Figure 4. NetSyn’s synthesis ability with respect to different ﬁtness functions and schemes. When limited by a maximum search space,
NetSyn synthesizes more programs than DeepCoder, PCCoder, RobustFill, and PushGP. Moreover for each program, NetSyn synthesizes
a higher percentage of runs than other approaches.

program with as few tries as possible. Therefore, the imple-
mentation of NetSyn is not streamlined to take advantage of
various parallelization and performance enhancement tech-
niques such as GPUs, hardware accelerators, data parallel
models etc. The synthesis time tends to increase for longer
length programs.

5.2 Characterization of NetSyn

Next, we characterize the effect of different components
of NetSyn. We show the results in this section based on
programs of length 5. However, we found our general ob-
servations to be true for longer length programs also.

Table 2 shows how many unique programs of length = 5
(out of a total of 100 programs) that the different approaches
were able to synthesize. It also shows the average genera-

Table 2. Programs synthesized for different settings of NetSyn. GA
stands for genetic algorithm.

Approach

Programs

Avg Syn.
Synthesized Generation Rate (%)

Avg

GA + f CF
GA + f CF + N SBF S
GA + f CF + N SDF S
GA + f CF + M utationF P
GA + f CF + N SBF S + M utationF P

92
94
94
93
94

3273
2953
3026
2726
2275

74
77
76
83
85

tions and synthesis rate for each program. NetSyn synthe-
sized the most number of programs in the lowest number of
generations and at the highest rate of synthesis when both
the NS and improved mutation based on function probabil-
ity (M utationF P ) are used in addition to the the NN-FF.
We note that BFS-based NS performs slightly better than
DFS-based NS. Moreover, M utationF P has some measur-

Learning Fitness Functions for Machine Programming

(a) N etSynCF

(b) N etSynLCS

(c) N etSynF P

Figure 5. NetSyn’s synthesis ability with respect to ﬁtness functions and DSL function types. Programs producing a single integer output
are harder to synthesize in all three variants of NetSyn.

centage for a function is at least 40% for the fCF -based
approach, whereas for the fFP -based approach, four func-
tions cannot be synthesized at all. Details of functions are
in the appendix.

5.3 Characterization of Neural Networks

Figure 7(a), (b), and (c) show the prediction ability of our
proposed neural network ﬁtness functions on validation data.
Figure 7(a) & (b) show the confusion matrix for f CF and
f LCS neural network ﬁtness functions. The confusion ma-
trix is a two dimensional matrix where (i, j) entry indicates
the probability of predicting the value i when the actual
value is j. Thus, each row of the matrix sums up to 1.0. We
can see that when a candidate program is close to the solu-
tion (i.e., the ﬁtness score is 4 or above), each of f CF and
f LCS-based model predicts a ﬁtness score of 4 or higher
with a probability of 0.7 or higher.
In other words, the
models are very accurate in identifying potentially close-
enough solutions. Similar is the case when the candidate
program is mostly mistaken (i.e., a ﬁtness score is 1 or less).
Thus, the neural networks are good at identifying both close-
enough solutions and mostly wrong solutions. If a candidate
program is some what correct (i.e., the candidate program
has few correct functions but the rest of the functions are
incorrect), it is difﬁcult to identify them by the proposed
models.

f F P model predicts probability of different functions given
the IO examples. We assume a function probability to be
correct if the function is in the target program and the neural
network predicts its probability as 0.5 or higher. Figure 7(c)
shows the accuracy of f F P model. With enough epochs, it
reaches close to 90% accuracy on the validation data set.

5.3.1 Additional Models and Fitness Functions

We tried several other models for neural networks and ﬁtness
functions. For example, instead of a classiﬁcation problem,

Figure 6. Synthesis percentage across different functions. Func-
tions 1 to 12 tend to have a lower synthesis rate because they
produce a single integer output. Moreover, f CF has a higher
synthesis rate.

able impact on NetSyn. Figure 7(a) - (c) show the synthe-
sis percentage for different programs and ﬁtness functions.
Program 1 to 50 are singleton programs and have lower
synthesis percentage in all three ﬁtness function choices.
Particularly, the f FP -based approach has a low synthesis
percentage for singleton programs. Functions 1 to 12 pro-
duce singleton integer and tend to cause lower synthesis
percentage for any program that contains them. This implies
that singleton programs are relatively harder to synthesize.

To shed more light on this issue, Figure 6 shows synthesis
percentage across different functions. The synthesis per-

(a) CF(b) FP0204060801001357911131517192123252729313335373941Synthesis Rate(%)Function0204060801001357911131517192123252729313335373941Synthesis Rate(%)FunctionLearning Fitness Functions for Machine Programming

(a) f CF

(b) f LCS

(c) f F P

Figure 7. Confusion matrix of (a) f CF (b) f LCS neural network ﬁtness functions. (c) shows accuracy of f F P over epochs. All graphs
are based on the validation data. Overall, f CF and f LCS are capable identifying of close-enough solutions as well as mostly mistaken
solutions. f F P reaches close to 90% accuracy after 40 epochs.

we treated ﬁtness scores as a regression problem. We found
that the neural networks produced higher prediction error as
the networks had a tendency to predict values close to the
median of the values in the training set. With the higher pre-
diction errors of the ﬁtness function, the genetic algorithm
performance degraded.

We also experimented with training a network to predict a
correctness ordering among a set of genes. We note that
the ultimate goal of the ﬁtness score is to provide an order
among genes for the Roulette Wheel algorithm. Rather than
getting this ordering indirectly via a ﬁtness score for each
gene, we attempted to have the neural network predict this
ordering directly. However, we were not able to train a
network to predict this relative ordering whose accuracy
was higher than the one for absolute ﬁtness scores. We
believe that there are other potential implementations for
this relative ordering and that it may be possible for it to be
made to work in the future.

Additionally, we tried a two-tier ﬁtness function. The ﬁrst
tier was a neural network to predict whether a gene has
a ﬁtness score of 0 or not. In the event the ﬁtness score
was predicted to be non-zero, we used a second neural
network to predict the actual non-zero value. This idea
came from the intuition that since many genes have a ﬁtness
score of 0 (at least for initial generations), we can do a
better job predicting those if we use a separate predictor for
that purpose. Unfortunately, mispredictions in the ﬁrst tier
caused enough good genes to be eliminated that NetSyn’s
synthesis rate was reduced.

Finally, we explored training a bigram model (i.e., predict-
ing pairs of functions appearing one after the other). This
approach is complicated by the fact that over 99% of the
41 × 41 (i.e., number of DSL functions squared) bigram
matrix are zeros. We tried a two-tiered neural network and
principle component analysis to reduce the dimensionality

of this matrix (Li & Wang, 2014). Our results using this
bigram model in NetSyn were similar to that of DeepCoder,
with up to 90% reduction in synthesis rate for singleton
programs.

6 CONCLUSION

In this paper, we presented a genetic algorithm-based frame-
work for program synthesis called NetSyn. To the best of
our knowledge, it is the ﬁrst work that uses a neural network
to automatically generate an genetic algorithm’s ﬁtness func-
tion in the context of machine programming. We proposed
three neural network-based ﬁtness functions. NetSyn is also
novel in that it uses neighborhood search to expedite the con-
vergence process of a genetic algorithm. We compared our
approach against several state-of-the art program synthesis
systems - DeepCoder (Balog et al., 2017b), PCCoder (Zo-
har & Wolf, 2018), RobustFill (Devlin et al., 2017), and
PushGP (Perkis, 1994). NetSyn synthesizes more programs
than each of those prior approaches with fewer candidate
program generations. We believe that our proposed work
could open up a new direction of research by automating ﬁt-
ness function generations for genetic algorithms by mapping
the problem as a big data learning problem. This has the
potential to improve any application of genetic algorithms.

REFERENCES

Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen,
Z., Citro, C., Corrado, G., Davis, A., Dean, J., Devin,
M., Ghemawat, S., Goodfellow, I., Harp, A., Irv-
ing, G., Isard, M., Jia, Y., Jozefowicz, R., Kaiser,
L., Kudlur, M., Levenberg, J., Mané, D., Monga, R.,
Moore, S., Murray, D., Olah, C., Schuster, M., Shlens,
J., Steiner, B., Sutskever, I., Talwar, K., Tucker, P.,
Vanhoucke, V., Vasudevan, V., Viégas, F., Vinyals,

Learning Fitness Functions for Machine Programming

O., Warden, P., Wattenberg, M., Wicke, M., Yu,
TensorFlow: Large-Scale Ma-
Y., and Zheng, X.
chine Learning on Heterogeneous Distributed Systems,
URL http://download.tensorflow.
2015.
org/paper/whitepaper2015.pdf.

International Conference on Learning Representations,
ICLR 2018, Vancouver, BC, Canada, April 30 - May 3,
2018, Conference Track Proceedings. OpenReview.net,
2018. URL https://openreview.net/forum?
id=Skp1ESxRZ.

Alur, R., Bodík, R., Dallal, E., Fisman, D., Garg, P., Ju-
niwal, G., Kress-Gazit, H., Madhusudan, P., Martin, M.
M. K., Raghothaman, M., Saha, S., Seshia, S. A., Singh,
R., Solar-Lezama, A., Torlak, E., and Udupa, A. Syntax-
Guided Synthesis.
In Irlbeck, M., Peled, D. A., and
Pretschner, A. (eds.), Dependable Software Systems Engi-
neering, volume 40 of NATO Science for Peace and Secu-
rity Series, D: Information and Communication Security,
pp. 1–25. IOS Press, 2015. ISBN 978-1-61499-494-7.
doi: 10.3233/978-1-61499-495-4-1. URL https://
doi.org/10.3233/978-1-61499-495-4-1.

Balog, M., Gaunt, A. L., Brockschmidt, M.,
DeepCoder.
and Tarlow, D.

Nowozin,
https://github.com/dkamm/deepcoder, 2017a.

S.,

Balog, M., Gaunt, A. L., Brockschmidt, M., Nowozin, S.,
and Tarlow, D. DeepCoder: Learning to Write Programs.
In International Conference on Learning Representations,
April 2017b.

Becker, K. and Gottschlich, J. AI Programmer: Au-
tonomously Creating Software Programs Using Genetic
Algorithms. CoRR, abs/1709.05703, 2017. URL http:
//arxiv.org/abs/1709.05703.

Bodík, R. and Jobstmann, B. Algorithmic Program Syn-
thesis: Introduction. International Journal on Software
Tools for Technology Transfer, 15:397–411, 2013.

Brameier, M. On Linear Genetic Programming. PhD thesis,

Dortmund, Germany, 2007.

Bunel, R., Hausknecht, M. J., Devlin, J., Singh, R., and
Kohli, P. Leveraging Grammar and Reinforcement
In 6th In-
Learning for Neural Program Synthesis.
ternational Conference on Learning Representations,
ICLR 2018, Vancouver, BC, Canada, April 30 - May
3, 2018, Conference Track Proceedings. OpenReview.net,
2018. URL https://openreview.net/forum?
id=H1Xw62kRZ.

Cai, J., Shin, R., and Song, D. Making Neural Programming
Architectures Generalize via Recursion. In 5th Interna-
tional Conference on Learning Representations, ICLR
2017, Toulon, France, April 24-26, 2017, Conference
Track Proceedings. OpenReview.net, 2017. URL https:
//openreview.net/forum?id=BkbY4psgg.

Chen, X., Liu, C., and Song, D. Towards synthesizing
complex programs from input-output examples. In 6th

Cheung, A., Solar-Lezama, A., and Madden, S. Using
Program Synthesis for Social Recommendations. ArXiv,
abs/1208.2925, 2012.

Debray, S. K., Evans, W., Muth, R., and De Sutter, B. Com-
piler Techniques for Code Compaction. ACM Trans. Pro-
gram. Lang. Syst., 22(2):378–415, March 2000. ISSN
0164-0925. doi: 10.1145/349214.349233. URL http:
//doi.acm.org/10.1145/349214.349233.

Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-
Fei, L. ImageNet: A Large-Scale Hierarchical Image
Database. In CVPR09, 2009.

Devlin, J., Uesato, J., Bhupatiraju, S., Singh, R., Mohamed,
A., and Kohli, P. RobustFill: Neural Program Learning
In Proceedings of the 34th Interna-
under Noisy I/O.
tional Conference on Machine Learning, ICML 2017,
Sydney, NSW, Australia, 6-11 August 2017, pp. 990–998,
2017. URL http://proceedings.mlr.press/
v70/devlin17a.html.

Dinesh, K., Luca, B., Matt, W., Anders, H.,
and Kit, G.
.NET Language-
LINQ to SQL:
Integrated Query for Relational Data, 2007. URL
https://docs.microsoft.com/en-us/
previous-versions/dotnet/articles/
bb425822(v=msdn.10).

Feng, Y., Martins, R., Bastani, O., and Dillig, I. Pro-
gram Synthesis Using Conﬂict-driven Learning. In Pro-
ceedings of the 39th ACM SIGPLAN Conference on
Programming Language Design and Implementation,
PLDI 2018, pp. 420–435, New York, NY, USA, 2018.
ACM. ISBN 978-1-4503-5698-5. doi: 10.1145/3192366.
3192382. URL http://doi.acm.org/10.1145/
3192366.3192382.

Goldberg, D. E. Genetic Algorithms in Search, Optimiza-
tion and Machine Learning. Addison-Wesley Longman
Publishing Co., Inc., Boston, MA, USA, 1st edition, 1989.
ISBN 0201157675.

Gottschlich, J., Solar-Lezama, A., Tatbul, N., Carbin, M.,
Rinard, M., Barzilay, R., Amarasinghe, S., Tenenbaum,
J. B., and Mattson, T. The Three Pillars of Machine
In Proceedings of the 2nd ACM SIG-
Programming.
PLAN International Workshop on Machine Learning
and Programming Languages, MAPL 2018, pp. 69–80,
New York, NY, USA, 2018. ACM. ISBN 978-1-4503-
5834-7. doi: 10.1145/3211346.3211355. URL http:
//doi.acm.org/10.1145/3211346.3211355.

Learning Fitness Functions for Machine Programming

Gulwani, S., Harris, W. R., and Singh, R. Spreadsheet
Data Manipulation Using Examples. Commun. ACM,
55(8):97–105, August 2012.
ISSN 0001-0782. doi:
10.1145/2240236.2240260. URL http://doi.acm.
org/10.1145/2240236.2240260.

Matos Dias, J., Rocha, H., Ferreira, B., and Lopes, M. d. C.
A genetic algorithm with neural network ﬁtness function
evaluation for IMRT beam angle optimization. Central
European Journal of Operations Research, 22, 09 2014.
doi: 10.1007/s10100-013-0289-4.

Heule, S., Schkufza, E., Sharma, R., and Aiken, A. Stratiﬁed
Synthesis: Automatically Learning the x86-64 Instruction
Set. SIGPLAN Not., 51(6):237–250, June 2016. ISSN
0362-1340. doi: 10.1145/2980983.2908121. URL http:
//doi.acm.org/10.1145/2980983.2908121.

Khuntia, B., Pattnaik, S., Panda, D., Neog, D., Devi, S.,
and Dutta, M. Genetic algorithm with artiﬁcial neural
networks as its ﬁtness function to design rectangular mi-
crostrip antenna on thick substrate. Microwave and Op-
tical Technology Letters, 44:144 – 146, 01 2005. doi:
10.1002/mop.20570.

Accuracy in Symbolic Regression, pp.
Korns, M. F.
Springer New York, New York, NY,
129–151.
2011.
doi: 10.1007/
978-1-4614-1770-5_8. URL https://doi.org/10.
1007/978-1-4614-1770-5_8.

ISBN 978-1-4614-1770-5.

Krizhevsky, A. Learning Multiple Layers of Features from

Tiny Images. Technical report, 2009.

Labs, S. Evolv Delivers Autonomous Optimization Across

Web & Mobile. https://www.evolv.ai/.

Langdon, W. B. and Poli, R. Foundations of Genetic Pro-
gramming. Springer Publishing Company, Incorporated,
1st edition, 2010. ISBN 3642076327.

Li, C. and Wang, B. Principal Components Analysis, 2014.
http://www.ccs.neu.edu/home/vip/
URL
teach/MLcourse/5_features_dimensions/
lecture_notes/PCA/PCA.pdf.

Liu, H., Simonyan, K., Vinyals, O., Fernando, C., and
Kavukcuoglu, K. Hierarchical Representations for Efﬁ-
cient Architecture Search. CoRR, abs/1711.00436, 2017.
URL http://arxiv.org/abs/1711.00436.

Loncaric, C., Ernst, M. D., and Torlak, E. General-
In Proceedings of the
ized Data Structure Synthesis.
40th International Conference on Software Engineering,
ICSE 2018, pp. 958–968, New York, NY, USA, 2018.
ACM. ISBN 978-1-4503-5638-1. doi: 10.1145/3180155.
3180211. URL http://doi.acm.org/10.1145/
3180155.3180211.

Murphy, K. P. Machine Learning: A Probabilistic Per-
ISBN 0262018020,

spective. The MIT Press, 2012.
9780262018029.

Perkis, T. Stack-based genetic programming. In Proceed-
ings of the First IEEE Conference on Evolutionary Com-
putation. IEEE World Congress on Computational Intelli-
gence, pp. 148–153 vol.1, 1994.

Ratner, A., Alistarh, D., Alonso, G., Andersen, D. G., Bailis,
P., Bird, S., Carlini, N., Catanzaro, B., Chung, E., Dally,
B., Dean, J., Dhillon, I. S., Dimakis, A. G., Dubey, P.,
Elkan, C., Fursin, G., Ganger, G. R., Getoor, L., Gibbons,
P. B., Gibson, G. A., Gonzalez, J. E., Gottschlich, J., Han,
S., Hazelwood, K. M., Huang, F., Jaggi, M., Jamieson,
K. G., Jordan, M. I., Joshi, G., Khalaf, R., Knight, J.,
Konecný, J., Kraska, T., Kumar, A., Kyrillidis, A., Li, J.,
Madden, S., McMahan, H. B., Meijer, E., Mitliagkas, I.,
Monga, R., Murray, D. G., Papailiopoulos, D. S., Pekhi-
menko, G., Rekatsinas, T., Rostamizadeh, A., Ré, C., Sa,
C. D., Sedghi, H., Sen, S., Smith, V., Smola, A., Song,
D., Sparks, E. R., Stoica, I., Sze, V., Udell, M., Van-
schoren, J., Venkataraman, S., Vinayak, R., Weimer, M.,
Wilson, A. G., Xing, E. P., Zaharia, M., Zhang, C., and
Talwalkar, A. SysML: The New Frontier of Machine
Learning Systems. CoRR, abs/1904.03257, 2019. URL
http://arxiv.org/abs/1904.03257.

Raychev, V., Vechev, M., and Yahav, E. Code Com-
In Pro-
pletion with Statistical Language Models.
ceedings of the 35th ACM SIGPLAN Conference on
Programming Language Design and Implementation,
PLDI ’14, pp. 419–428, New York, NY, USA, 2014.
ACM. ISBN 978-1-4503-2784-8. doi: 10.1145/2594291.
2594321. URL http://doi.acm.org/10.1145/
2594291.2594321.

Real, E., Aggarwal, A., Huang, Y., and Le, Q. V. Regular-
ized Evolution for Image Classiﬁer Architecture Search.
CoRR, abs/1802.01548, 2018. URL http://arxiv.
org/abs/1802.01548.

Real, E., Aggarwal, A., Huang, Y., and Le, Q. V. Regular-
ized Evolution for Image Classiﬁer Architecture Search.
In Thirty-Third AAAI Conference on Artiﬁcial Intelli-
gence, February 2019.

Manna, Z. and Waldinger, R. Knowledge and Reasoning
in Program Synthesis. Artiﬁcial Intelligence, 6(2):175 –
208, 1975. ISSN 0004-3702.

Real, E., Liang, C., So, D. R., and Le, Q. V. Automl-
zero: Evolving machine learning algorithms from scratch,
2020.

Learning Fitness Functions for Machine Programming

Reed, S. E. and de Freitas, N. Neural Programmer-
Interpreters. In Bengio, Y. and LeCun, Y. (eds.), 4th Inter-
national Conference on Learning Representations, ICLR
2016, San Juan, Puerto Rico, May 2-4, 2016, Conference
Track Proceedings, 2016. URL http://arxiv.org/
abs/1511.06279.

Salimans, T., Ho, J., Chen, X., Sidor, S., and Sutskever, I.
Evolution Strategies as a Scalable Alternative to Rein-
forcement Learning. CoRR, abs/1703.03864, 2017. URL
https://arxiv.org/abs/1703.03864.

Solar-Lezama, A., Tancau, L., Bodik, R., Seshia, S., and
Saraswat, V. Combinatorial Sketching for Finite Pro-
grams. SIGOPS Oper. Syst. Rev., 40(5):404–415, Oc-
tober 2006. ISSN 0163-5980. doi: 10.1145/1168917.
1168907. URL http://doi.acm.org/10.1145/
1168917.1168907.

Such, F. P., Madhavan, V., Conti, E., Lehman, J., Stanley,
K. O., and Clune, J. Deep Neuroevolution: Genetic Algo-
rithms Are a Competitive Alternative for Training Deep
Neural Networks for Reinforcement Learning. CoRR,
abs/1712.06567, 2017. URL http://arxiv.org/
abs/1712.06567.

Thomas. Global Optimization Algorithms-Theory and
Application. 2009. http://www.it-weise.de/
projects/book.pdf.

Zohar, A. and Wolf, L. Automatic Program Synthesis of
Long Programs with a Learned Garbage Collector. CoRR,
abs/1809.04682, 2018. URL http://arxiv.org/
abs/1809.04682.

A APPENDIX A: NETSYN’S DSL

In this appendix, we provide more details about the list DSL
that NetSyn uses to generate programs. Our list DSL has
only two implicit data types, integer and list of integer. A
program in this DSL is a sequence of statements, each of
which is a call to one of the 41 functions deﬁned in the DSL.
There are no explicit variables, nor conditionals, nor explicit
control ﬂow operations in the DSL, although many of the
functions in the DSL are high-level and contain implicit
conditionals and control ﬂow within them. Each of the
41 functions in the DSL takes one or two arguments, each
being of integer or list of integer type, and returns exactly
one output, also of integer or list of integer type. Given these
rules, there are 10 possible function signatures. However,
only 5 of these signatures occur for the functions we chose
to be part of the DSL. The following sections are broken
down by the function signature, wherein all the functions in
the DSL having that signature are described.

Instead of named variables, each time a function call re-
quires an argument of a particular type, our DSL’s runtime
searches backwards and ﬁnds the most recently executed
function that returns an output of the required type and then
uses that output as the current function’s input. Thus, for
the ﬁrst statement in the program, there will be no previous
function’s output from which to draw the arguments for
the ﬁrst function. When there is no previous output of the
correct type, then our DSL’s runtime looks at the arguments
to the program itself to provide those values. Moreover, it
is possible for the program’s inputs to not provide a value
of the requested type. In such cases, the runtime provides
a default value for missing inputs, 0 in the case of integer
and an empty list in the case of list of integer. For example,
let us say that a program is given a list of integer as input
and that the ﬁrst three functions called in the program each
consume and produce a list of integer. Now, let us assume
that the fourth function called takes an integer and a list of
integer as input. The list of integer input will use the list
of integer output from the previous function call. The DSL
runtime will search backwards and ﬁnd that none of the
previous function calls produced integer output and that no
integer input is present in the program’s inputs either. Thus,
the runtime would provide the value 0 as the integer input
to this fourth function call. The ﬁnal output of a program is
the output of the last function called.

Thus, our language is deﬁned in such a way that so long as
the program consists only of calls to one of the 41 functions
provided by the DSL, that these programs are valid by con-
struction. Each of the 41 functions is guaranteed to ﬁnish
in a ﬁnite time and there are no looping constructs in the
DSL, and thus, programs in our DSL are guaranteed to ﬁn-
ish. This property allows our system to not have to monitor
the programs that they execute to detect potentially inﬁnite

Learning Fitness Functions for Machine Programming

loops. Moreover, so long as the implementations of those
41 functions are secure and have no potential for memory
corruption then programs in our DSL are similarly guaran-
teed to be secure and not crash and thus we do not require
any sand-boxing techniques. When our system performs
crossover between two candidate programs, any arbitrary
cut points in both of the parent programs will result in a
child program that is also valid by construction. Thus, our
system need not test that programs created via crossover or
mutation are valid.

In the following sections, [] is used to indicate the type list
of integer whereas int is used to indicate the integer type.
The type after the arrow is used to indicate the output type
of the function.

A.1 Functions with the Signature [] → int

There are 9 functions in our DSL that take a list of integer
as input and return an integer as output.

A.1.1 HEAD (Function 6)

This function returns the ﬁrst item in the input list. If the
list is empty, a 0 is returned.

A.1.2 LAST (Function 7)

A.2.1 REVERSE (Function 29)

This function returns a list containing all the elements of the
input list but in reverse order.

A.2.2

SORT (Function 35)

This function returns a list containing all the elements of the
input list in sorted order.

A.2.3 MAP (Function 19-28)

This function applies a lambda to each element of the input
list and creates the output list from the outputs of those
lambdas. Let In be the nth element of the input list to MAP
and let On be the nth element of the output list from Map.
MAP produces an output list such that On=lambda(In) for
all n. There are 10 MAP functions corresponding to the
following lambdas: +1,-1,*2,*3,*4,/2,/3,/4,*(-1),ˆ2.

A.2.4 FILTER (Function 14-17)

This function returns a list containing only those elements in
the input list satisfying the criteria speciﬁed by the additional
lambda. Ordering is maintained in the output list relative to
the input list for those elements satisfying the criteria. There
are 4 FILTER functions having the lambdas: >0, <0, odd,
even.

This function returns the last item in the input list. If the list
is empty, a 0 is returned.

A.2.5

SCANL1 (Function 30-34)

A.1.3 MINIMUM (Function 8)

This function returns the smallest integer in the input list. If
the list is empty, a 0 is returned.

A.1.4 MAXIMUM (Function 9)

This function returns the largest integer in the input list. If
the list is empty, a 0 is returned.

A.1.5 SUM (Function 11)

This functions returns the sum of all the integers in the input
list. If the list is empty, a 0 is returned.

A.1.6 COUNT (Function 2-5)

This function returns the number of items in the list that
satisfy the criteria speciﬁed by the additional lambda. Each
possible lambda is counted as a different function. Thus,
there are 4 COUNT functions having lambdas: >0, <0, odd,
even.

A.2 Functions with the Signature [] → []

There are 21 functions in our DSL that take a list of integer
as input and produce a list of integer as output.

Let In be the nth element of the input list to SCANL1 and
let On be the nth element of the output list from SCANL1.
This function produces an output list as follows:

(cid:40)

On = In & n == 0
On = lambda(In, On−1) & n > 0

There are 5 SCANL1 functions corresponding to the follow-
ing lambdas: +, -, *, min, max.

A.3 Functions with the Signature int,[] → []

There are 4 functions in our DSL that take an integer and a
list of integer as input and produce a list of integer as output.

A.3.1 TAKE (Function 36)

This function returns a list consisting of the ﬁrst N items of
the input list where N is the smaller of the integer argument
to this function and the size of the input list.

A.3.2 DROP (Function 13)

This function returns a list in which the ﬁrst N items of the
input list are omitted, where N is the integer argument to
this function.

A.3.3 DELETE (Function 12)

C ADDITIONAL RESULTS

Learning Fitness Functions for Machine Programming

Table 3 shows detailed numerical results using synthesis
time as the metric. Columns 10% to 100% show the duration
of time (in seconds) it takes to synthesize the corresponding
percentage of programs.

This function returns a list in which all the elements of the
input list having value X are omitted where X is the integer
argument to this function.

A.3.4 INSERT (Function 18)

This function returns a list where the value X is appended
to the end of the input list, where X is the integer argument
to this function.

A.4 Functions with the Signature [],[] → []

There is only one function in our DSL that takes two lists of
integers and returns another list of integers.

A.4.1 ZIPWITH (Function 37-41)

This function returns a list whose length is equal to the
length of the smaller input list. Let On be the nth element
of the output list from ZIPWITH. Moreover, let I 1
n and I 2
n
be the nth elements of the ﬁrst and second input lists re-
spectively. This function creates the output list such that
On=lambda(I 1
n). There are 5 ZIPWITH functions corre-
sponding to the following lambdas: +, -, *, min, max.

n, I 2

A.5 Functions with the Signature int,[] → int

There are two functions in our DSL that take an integer and
list of integer and return an integer.

A.5.1 ACCESS (Function 1)

This function returns the Nth element of the input list, where
N is the integer argument to this function. If N is less than 0
or greater than the length of the input list then 0 is returned.

A.5.2 SEARCH (Function 10)

This function return the position in the input list where the
value X is ﬁrst found, where X is the integer argument to
this function. If no such value is present in the list, then -1
is returned.

B APPENDIX B: SYSTEM DETAILS

B.1 Hyper-parameters for the Models and Genetic

Algorithm

• Evolutionary Algorithm:

– Gene pool size: 100
– Number of reserve gene in each generation: 5
– Maximum number of generation: 30,000
– Crossover rate: 40%
– Mutation rate: 30%

Learning Fitness Functions for Machine Programming

Table 3. Comparison with DeepCoder and PCCoder in synthesizing different length programs. All experiments are done with the
maximum search space set to 3,000,000 candidate programs.

7

5

PROGRAM METHOD
LENGTH
PushGP
Edit
DeepCoder
PCCoder
RobustFill
NetSynFP
NetSynLCS
NetSynCF
OracleLCS |CF
PushGP
Edit
DeepCoder
PCCoder
RobustFill
NetSynFP
NetSynLCS
NetSynCF
OracleLCS |CF
PushGP
Edit
DeepCoder
PCCoder
RobustFill
NetSynFP
NetSynCF
NetSynLCS
OracleLCS |CF

10

SYNTHESIS
PERCENTAGE 10% 20% 30% 40% 50% 60%

TIME REQUIRED TO SYNTHESIZE (IN SECONDS)

70% 80% 90% 100%

45%
72%
40%
51%
63%
94%
97%
94%
100%
38%
51%
45%
52%
56%
72%
72%
76%
100%
32%
43%
42%
48%
45%
64%
66%
66%
100%

-

-

-

-

-

-
-

-
-
-
-
-

2S
6S
8S
19S
19S
17S

116S 288S 365S 395S

-
492S
-
-
-

65S 372S 456S
1S
1S
7S
<1S <1S
126S
66S 357S
1S
1S
83S 472S 1321S
1S
1S
61S 172S 691S
13S 13S
57S 175S 957S
13S 13S
12S 12S
31S 172S 1038S
<1S <1S <1S <1S <1S <1S
1S
1S
1S
1S
<1S <1S <1S
2S
1S
1S
3S
1S
1S
16S
13S 13S
16S
13S 13S
12S 12S
15S
<1S <1S <1S <1S <1S <1S
1S
1S 1454S
1S 205S 437S 591S
<1S <1S <1S
67S
1011S
4S
1S
1S
856S
14S
1S
2S
74S 763S 29206S
13S
13S 13S
63S 701S 9016S
13S
13S 13S
13S 13S
60S 521S 17384S
13S
<1S <1S <1S <1S <1S <1S

-
-
694S
-
254S 367S 433S
-
13S
-
11S 635S
27S 535S
-
51S 424S 6506S 109659S
58S 433S 10363S 100728S
56S 489S 6862S 81037S

-
-
-
-
-
1671S 6311S 30712S
1880S 4130S 20580S
2825S 7864S 42648S
1S
-
-
-
-
-
-
-
-
1S
-
-
-
-
-
-
-
-
1S

1S
-
-
-
-
-
-
-
-
1S
-
-
-
-
-
-
-
-
1S

1S
-
-
-
-
-
-
-
-
1S

1S
-
-
-
-
-

-
-
-
-
-

-
-
-
-
-

-

-
-
-
-
-
-
-
-
1S
-
-
-
-
-
-
-
-
1S
-
-
-
-
-
-
-
-
1S

Learning Fitness Functions for Machine Programming

Table 4. Comparison with DeepCoder and PCCoder in terms of search space use. All experiments are done with the maximum search
space set to 3,000,000 candidate programs.

-

-

-

-

5

7

-
-

-
-
-

-
-
-
-
-

-
-
-
-
-

-
-
-
-
-
-
-
-

7% 33%
8% 35% 47%

SEARCH SPACE USED TO SYNTHESIZE
10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
<1% 9% 60% 67%
<1% <1% 17% 43% 54% 60% 73%
<1% 1%
1% 37%
<1% 1%
1%
<1% 1%
1%
<1% <1% <1% <1% 1%
4% 13% 30% 55%
<1% <1% <1% <1% 1%
8% 17% 25% 48%
<1% <1% <1% <1% 1% 10% 22% 40% 58%

PROGRAM METHOD
LENGTH
PushGP
Edit
DeepCoder
PCCoder
RobustFill
NetSynFP
NetSynLCS
NetSynCF
OracleLCS |CF <1% <1% <1% <1% <1% <1% <1% <1% <1% <1%
PushGP
Edit
DeepCoder
PCCoder
RobustFill
NetSynFP
NetSynLCS
NetSynCF
OracleLCS |CF <1% <1% <1% <1% <1% <1% <1% <1% <1% <1%
PushGP
Edit
DeepCoder
PCCoder
RobustFill
NetSynFP
NetSynCF
NetSynLCS
OracleLCS |CF <1% <1% <1% <1% <1% <1% <1% <1% <1% <1%

<1% <1% 82%
<1% <1% 34% 48% 69%
<1% <1% 1%
<1% <1% 1%
<1% <1% 1%
<1% <1% <1% <1% 3% 31% 47%
<1% <1% <1% <1% 3% 26% 59%
<1% <1% <1% <1% 4% 31% 56%

<1% <1% 90%
<1% 20% 43% 56%
<1% <1% 1%
9%
<1% <1% 1% 61%
<1% 1%
4% 58%
<1% <1% <1% <1% 5% 34%
<1% <1% <1% <1% 4% 36%
<1% <1% <1% <1% 4% 40%

3%
1% 38%
2% 35%

-
-
-
-
-
-
-
-

-
-
-
-
-
-
-
-

-
-
-
-
-
-
-
-

-
-
-
-
-
-
-
-

-
-
-
-
-
-
-
-

-
-
-
-
-
-
-
-

-
-
-
-
-
-
-
-

-
-
-
-
-

-
-
-
-
-

-
-
-
-
-

-
-
-
-
-

10

-

-

-

-

