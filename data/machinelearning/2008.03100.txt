0
2
0
2

g
u
A
7

]
I

A
.
s
c
[

1
v
0
0
1
3
0
.
8
0
0
2
:
v
i
X
r
a

Under consideration for publication in Theory and Practice of Logic Programming

1

Conﬂict Generalisation in ASP: Learning Correct and
Effective Non-Ground Constraints

RICHARD TAUPE1,2, ANTONIUS WEINZIERL3, and GERHARD FRIEDRICH2
1 Siemens AG sterreich,
(e-mail: richard.taupe@siemens.com)
2 Alpen-Adria-Universitt, Klagenfurt, Austria,
(e-mail: gerhard.friedrich@aau.at)
3 TU Wien (Vienna University of Technology), Austria,
(e-mail: antonius.weinzierl@kr.tuwien.ac.at)

submitted TBD; revised TBD; accepted TBD

Abstract

Generalising and re-using knowledge learned while solving one problem instance has been neglected by
state-of-the-art answer set solvers. We suggest a new approach that generalises learned nogoods for re-
use to speed-up the solving of future problem instances. Our solution combines well-known ASP solving
techniques with deductive logic-based machine learning. Solving performance can be improved by adding
learned non-ground constraints to the original program. We demonstrate the effects of our method by means
of realistic examples, showing that our approach requires low computational cost to learn constraints that
yield signiﬁcant performance beneﬁts in our test cases. These beneﬁts can be seen with ground-and-solve
systems as well as lazy-grounding systems. However, ground-and-solve systems suffer from additional
grounding overheads, induced by the additional constraints in some cases. By means of conﬂict minimiza-
tion, non-minimal learned constraints can be reduced. This can result in signiﬁcant reductions of grounding
and solving efforts, as our experiments show. (Under consideration for acceptance in TPLP.)

KEYWORDS: Answer Set Programming, Deductive Learning, Non-Ground Nogood Learning

1 Introduction

Conﬂict-Driven Nogood Learning (CDNL) is a major success factor for high-performance state-
of-the-art ASP systems (Gebser et al. 2012). When a conﬂict occurs, new propositional nogoods
are learned that prevent the same conﬂict from re-occurring, which improves search performance.
Previous work has failed to address the question whether learned nogoods can be generalised
and re-used to speed up the solving of different instances of the same problem. This paper aims
to ﬁll this gap. We present an extension of CDNL that learns non-ground constraints. The idea is
that whole parts of the search tree can be pruned when these learned constraints are added to the
original program. We presume the common distinction between an unvarying problem encoding
and separate inputs consisting only of facts. A problem instance is speciﬁed by the problem
encoding and a set of input facts. We aim to derive non-ground constraints from the problem
encoding that are valid for all possible inputs and which can be employed to speed up solving
new instances. In practice, instances are often not random but share some similarities that are
reﬂected by nogoods learned during solving. This led us to assume the existence of non-ground
nogoods capable of signiﬁcantly speeding up solving of practical problem instances.

 
 
 
 
 
 
2

R. Taupe, A. Weinzierl, G. Friedrich

CDNL and Explanation-Based Learning (EBL) (Mitchell et al. 1986; DeJong and Mooney 1986;

Hirsh 1987) are our starting point. EBL is a well-known logic-based machine learning technique
which learns ﬁrst-order rules that are entailed by the background knowledge (in our case, the
problem encoding). We combine CDNL with EBL to learn non-ground nogoods while solv-
ing prior problem instances. Since the number of generalised nogoods can be overwhelming,
choosing those that will actually pay off is particularly challenging. Our basic idea is to gener-
alise those non-ground conﬂicts that occur most often, i.e., we generalise propositional nogoods
learned from frequently violated nogoods. The underlying assumption is that nogoods learned
from frequent conﬂicts will also be able to prevent many conﬂicts.

A realistic hardware conﬁguration example and a graph colouring problem are used for demon-
stration and experimentation purposes. Results show that both lazy-grounding and ground-and-
solve systems beneﬁt from our approach. By adding learned constraints to the problem encod-
ings, up to 64% more conﬁguration instances can be solved and graph colouring instances can
be solved much faster. Learning itself requires low computational resources.

We believe that we have developed an innovative tool supporting the design of efﬁcient answer-
set programs. This view is supported by encouraging experimental results. Our main contribu-
tions can be summarized as follows:

– We present a motivating practical example and describe how some redundant constraints can
be derived from a given encoding. We also sketch how non-minimal nogoods can be reduced.
– Next, we introduce a novel approach combining CDNL and EBL to automatically learn correct
non-ground nogoods while solving an answer-set program. A pseudo-code algorithm is given.
– We suggest techniques to make learned nogoods use only predicates from the input program,
the means to choose from the wide range of possible generalisations, and methods to quickly
conduct learning under limited resources.

– Finally, we experimentally compare the effects of various learned constraints on two domains.

Results demonstrate the practical beneﬁts of our approach.

2 Preliminaries

2.1 Answer Set Programming

An answer-set program P is a ﬁnite set of non-ground rules of the form

h ← b1, . . . , bm, not bm+1, . . . , not bn.

h1i

where h and b1, . . . , bn are atoms. A classical atom is an expression p(t1, . . . ,tn) where p is an n-
ary predicate and t1, . . . ,tn are terms. A term is a variable, a constant, or a complex term involving
arithmetics. A NaF-literal is either an atom a or its negation not a. Negation as failure (NaF) refers
to the absence of information, i.e., an atom is assumed to be false as long as it is not proven to be
true. If l is a literal, then l denotes its complement (i.e., not a = a and a = not a).

Given a rule r, H(r) = {h} is called the head of r, and B(r) = {b1, . . . , bm, not bm+1, . . .,
not bn} is called the body of r. A rule r where the head is absent (H(r) = {}), e.g., ← b., is called
constraint. A rule r where the body is absent (B(r) = {}), e.g., h ← ., is called fact. Given an
answer-set program P, the universe of P, denoted by UP, is the set of constants appearing in P.
By A we denote the set of classical atoms constructible from predicates of P with constants in
UP. The set of all literals is denoted by L = A ∪ {not a | a ∈ A }. The facts function maps a
program P to all ground atoms deﬁned by facts in P, i.e., facts(P) = {H(r) | r ∈ P and B(r) = /0}.

Conﬂict Generalisation in ASP

3

The vars function maps any structure containing variables to the set of variables it contains,
e.g., for a rule r1 : a(X) ← b(X,Y )., vars(r1) = {X,Y }. The set V ⊃ vars(P) includes all vari-
ables from a program and also variables that can additionally be used by a solver, it is usually
inﬁnite. A literal l or rule r is ground if vars(l) = /0 or vars(r) = /0, respectively. A program P
is ground if all its rules r ∈ P are. A substitution σ: V → V ∪ UP is a mapping from variables
to variables or constants. A substitution is called grounding for a set of variables V ⊆ V if for
every v ∈ V there exists a constant c ∈ UP s.t. ς(v) = c. The function νA : A → {T, M, F, U} for
a (partial) assignment A maps an atom to the truth value the atom is currently assigned in the
given assignment (M stands for must-be-true and U for currently unassigned).

A nogood is a set of Boolean signed literals {T a1, . . . , T an, . . . , F an+1, . . . , F am} which means
that an answer set may not satisfy all the literals in the nogood. A literal in a nogood differs from
a NaF-literal in a rule semantically: In a nogood, negation as failure has no role. A nogood
is violated by an assignment A if νA(ai) ∈ {T, M} for all i ∈ {1, . . . , n} and νA(a j) = F for
all j ∈ {n + 1, . . . , m}. Sometimes, we will represent nogoods not by sets but by ﬁxed-order
multisets, because we need the possibility of duplicates and of ﬁxed positions to be able to map
literals between ground and non-ground nogoods. When this is the case, ω[i] denotes the literal
at position i in nogood ω.

For ASP semantics, we refer to Faber et al. (2011).
Aggregates and choice rules are common extensions to the input language of ASP (Calimeri et al. 2020).

Aggregate atoms are used to express arithmetic constraints on sets of atoms (e.g., cardinality con-
straints). A choice rule expresses that a subset of a set of atoms will be included in an answer
set. This does not clash with the subset-minimality of answer sets because choice rules are trans-
lated to normal rules involving additional atoms whose predicates we call choice predicates. For
simplicity, we only consider choice rules without bounds (which are the only ones currently sup-
ported by ALPHA). A choice rule is of the form h1i, but the head h is not a classical atom but a
choice atom of the form {C1; . . . ;Cn}, where for n > 0 and 0 ≤ i ≤ n each Ci is a choice element.
A choice element has the form a : l1, . . . , lk, where a is a classical atom and l1, . . . , lk are literals
for k ≥ 0. If the body of a choice rule is satisﬁed, it means that for each Ci where the literals
l1, . . . , lk are satisﬁed, the atom a may or may not be true in an answer set. A choice rule r can be
translated to 2n rules, two for each choice element a : l1, . . . , lk:
a ← B(r), l1, . . . , lk, not ba.

ba ← B(r), l1, . . . , lk, not a.

For both aggregates and choice rules, see Calimeri et al. (2020) for details.

The goal of our method is to generate non-ground nogoods which can be re-used for solv-
ing further problem instances. More formally, let PE be an ASP problem encoding. InPred and
OutPred are sets of predicate symbols with deﬁned arities. The input for PE is speciﬁed by a set
of ground facts InA containing only predicate symbols from InPred. The output of a problem
instance PE ∪ InA is the set of atoms of a stable model whose predicate symbols are in OutPred.
A conﬂict for an ASP program P is a constraint C s.t. P |=S C where |=S refers to the skeptical

ASP semantic, i.e., C must be true in all stable models of P.

Deﬁnition 2.1
A generalized conﬂict of (PE, InPred) is a constraint GC s.t. PE ∪ InA |=S GC for all ﬁnite sets
of ground facts InA whose predicate symbols are in InPred.

Let |=F be the implication relation based on standard FOL semantic. Since every stable model
of an ASP program P is also a model for P if P is interpreted as an FOL program, it follows
that if P |=F C then P |=S C. It is well known that every stable-model of P is also a model of

4

R. Taupe, A. Weinzierl, G. Friedrich

P∪comp(P), i.e., the extension of P by the axioms of the Clark completion. Note that for problem
instances PE ∪ InA the Clark completion changes depending on InA. Since we are interested in
conﬂicts which are independent of the input, we consider only the completion of the head literals
which appear in PE but not in InPred. We denote this restricted Clark completion for a program
P and input predicates InPred as rComp(P, InPred). It holds that rComp(P, InPred) ⊆ comp(P)
and PE ∪ rComp(PE ∪ InA, InPred) is the same for all problem instances PE ∪ InA.

Corollary 2.1
Let a problem be deﬁned by (PE, InPred) and C is a conﬂict. If PE ∪ rComp(P, InPred) |=F C
then C is a generalized conﬂict of (PE, InPred).

Proof sketch: Since rComp(P, InPred) depends only on P, it holds that if PE ∪ rComp(P, InPred)
|=F C then PE ∪ rComp(P, InPred) ∪ InA |=F C where InA is a ﬁnite set of ground facts whose
predicate symbols are in InPred. Because every stable model of PE ∪ InA is also a model for
PE ∪ rComp(P, InPred) ∪ InA under FOL semantic and C is true in these models it follows that
PE ∪ InA |=S C.

Consequently, adding a generalized conﬂict GC to PE does not change the set of outputs of

(PE, InPred) for any input.

2.2 Conﬂict-Driven Nogood Learning (CDNL)

Conﬂict-Driven Clause Learning (CDCL) (Silva et al. 2009; Lintao Zhang et al. 2001) is a SAT
solving technique that extends DPLL by conﬂict analysis and enables the solver to learn new
clauses and to do non-chronological backtracking (“backjumping”). While the original deﬁni-
tions of CDCL are based on clauses, i.e., disjunctions of literals, we use the notion of nogoods
and speak of Conﬂict-Driven Nogood Learning (CDNL) (Gebser et al. 2012). The two variants
are equivalent since the conjunction of classically negated nogoods can be directly transformed
to an equivalent conjunction of clauses by applying De Morgan’s laws.

CDCL- and CDNL-based solvers usually characterize each atom a ∈ A by the following
properties: its truth value, its antecedent clause, and its decision level, denoted respectively by
ν(a) ∈ {T, F, M, U}, α(a) ∈ 2L ∪ {NIL}, and δ(a) ∈ {−1, 0, 1, . . ., |A |}. The truth value of an
atom is the value currently assigned to it. By the antecedent clause of an atom we mean the cause
of its current truth value. The antecedent clause of an atom whose current truth value has been
implied is the nogood that was unit at the time the implication happened and thus forced the atom
to assume its current value. The value NIL is used instead if the current truth value of an atom
results from a heuristic decision. The decision level of an atom denotes the depth of the decision
tree at which it has been assigned, and −1 if the atom is unassigned. The decision level of a
literal is the same as the literal’s atom’s decision level (δ(not a) = δ(a)), and the antecedent of
a literal is the one of its atom (α(not a) = α(a)). An assignment’s decision level is the decision
level of the atom most recently assigned (Silva et al. 2009; Lintao Zhang et al. 2001).

When a nogood is violated during solving (i.e., all literals in the nogood are satisﬁed), the con-
ﬂict is analysed and a new nogood may be learned. Learning starts with the violated nogood and
resolves one literal assigned at the current (most recent) decision level with its antecedent. This
is repeated with the nogood resulting from resolution (the “resolvent”) as long as it is possible.
Resolution stops when the only literal in the resolvent that has been assigned at the current deci-
sion level is a decision literal, i.e., its antecedent is NIL. The resulting nogood is then “learned”,
i.e., added to the set of known nogoods, and the solver executes a backjump (Silva et al. 2009).

Conﬂict Generalisation in ASP

5

First UIP clause learning is a modiﬁcation of this algorithm that already stops resolution when
only one literal from the current decision level remains in the nogood, even if its antecedent is
not NIL. This is correct because this literal is a unique implication point (UIP), a node in the
implication graph that lies on every path from the last decision to the conﬂict. Each UIP could
be used to learn a new nogood, but modern SAT solvers stop already at the ﬁrst UIP, i.e., the one
nearest to the conﬂict (Silva et al. 2009).

2.3 Explanation-Based Learning

Explanation-Based Learning (EBL), a.k.a. Explanation-Based Generalization (EBG), is a logic-
based learning technique that, in contrast to Inductive Logic Programming (ILP), learns only
general rules that are entailed by background knowledge alone (and not by background knowl-
edge together with some new hypotheses). Therefore, in EBL nothing factually new is learned
from the example. In EBL, two proof trees are created simultaneously (one for the concrete
example and one with variables instead of constants). Then, new rules can be obtained from
the non-ground proof tree. The operationality criterion is a restriction which predicates can be
used to express the learned rules. The purpose of operationality is to use only predicates that are
easy to solve. A trade-off between operationality and generality is usually an issue in EBL. By
choosing adequate general rules, EBL makes a knowledge base more efﬁcient for the kind of
problems that one would reasonably anticipate (Mitchell et al. 1986; DeJong and Mooney 1986;
Hirsh 1987; Mitchell 1997; Russell and Norvig 2010).

Van Harmelen and Bundy (1988) show that EBL/EBG and Partial Evaluation (PE) are equiv-
alent to each other in the context of logic programming. PE is a program optimisation method
that reformulates an input program in an equivalent but more efﬁcient way. Weinzierl (2013) em-
ploys PE (and terms it “unfolding” of rules) in lazy-grounding answer set solving to learn new
rules during solving. Learning is triggered by conﬂicts to prevent future occurrences of similar
conﬂicts. Learned rules are constructed from constraints that are almost violated and in which
atoms have been replaced by their deﬁnitions: The single literal in the constraint’s body that is
not yet satisﬁed must not be satisﬁed. Learned rules are created and used online during solving.

3 A Motivating Example

The House Conﬁguration Problem (HCP) serves as a motivating example. It is an abstraction
of real-world hardware conﬁguration problems and deﬁned as follows:1 Given an association of
things to the persons they belong to, a domain of cabinet IDs, and a domain of room IDs, the
task is to assign things to cabinets and cabinets to rooms such that there are at most ﬁve things
in each cabinet and at most four cabinets in each room, and each room only contains things that
belong to the same person. The problem encoding stays the same for all problem instances. Input
facts of predicates personTOthing/2, cabinetDomain/1, and roomDomain/1 vary from instance
to instance. Each answer set speciﬁes one valid conﬁguration.

We are guided by the original deﬁnition of HCP by Friedrich et al. (2011) and limit ourselves
to the conﬁguration aspects of the problem, neglecting reconﬁguration for presentation purposes.
The complete encoding is given in Listing 1.2

1 See

https://sites.google.com/view/aspcomp2019/problem-domains ,

Friedrich et al. (2011),

and

Ryabokon (2015) for more complete descriptions of the problem.

2 Compared to Ryabokon (2015), variables have been renamed for this paper and some simpliﬁcations have been made.

6

1
2
3
4
5
6
7
8
9

10
11
12
13
14
15

16
17
18
19
20
21
22
23
24
25

R. Taupe, A. Weinzierl, G. Friedrich

{ c a b i n e t (C) } :− c a b i n e t D o m a i n (C) .
{ room (R ) } :− roomDomain ( R) .
room ( R1 )
c a b i n e t ( C1 )

:− roomDomain ( R1 ) ,

:− c a b i n e t D o m a i n ( C1 ) , c a b i n e t D o m a i n ( C2 ) , c a b i n e t ( C2 ) , C1 < C2 .

roomDomain ( R2 ) ,

room ( R2 ) , R1 < R2 .

{ c a b i n e t T O t h i n g (C , T ) } :− c a b i n e t D o m a i n ( C) ,
t h i n g H a s C a b i n e t ( T )
:− t h i n g ( T ) , no t
:− t h i n g ( T ) , c a b i n e t D o m a i n ( C1 ) , c a b i n e t T O t h i n g ( C1 , T ) , c a b i n e t D o m a i n ( C2 ) ,

:− c a b i n e t T O t h i n g ( C , T ) .

t h i n g H a s C a b i n e t ( T ) .

t h i n g ( T ) .

c a b i n e t T O t h i n g ( C2 , T ) , C1 < C2 .

:− 6 <= # c o u n t { T :

c a b i n e t T O t h i n g ( C , T ) ,

t h i n g ( T ) } , c a b i n e t (C) .

{ ro o mT O c a b i n e t ( R , C) } :− roomDomain (R ) , c a b i n e t ( C) .
c a b i n e t H a s R o o m (C )
:− c a b i n e t ( C) , no t c a b i n e t H a s R o o m ( C) .
:− c a b i n e t ( C) ,

:− ro o mT O c a b i n e t ( R , C ) .

ro o mT O c a b i n e t ( R1 , C) ,

roomDomain ( R1 ) ,

ro o mT O c a b i n e t ( R2 , C) , R1 < R2 .

roomDomain ( R2 ) ,

:− 5 <= # c o u n t { C :

ro o mT O c a b i n e t ( R , C ) , c a b i n e t D o m a i n (C) } ,

room (R ) .

personTOroom ( P , R )
:− personTOroom ( P1 , R) , personTOroom ( P2 , R) , P1 < P2 .

:− p e r s o n T O t h i n g ( P , T ) , c a b i n e t T O t h i n g (C , T ) ,

ro o mT O c a b i n e t ( R , C) .

room (R )
room (R )
c a b i n e t (C )
c a b i n e t (C )
t h i n g ( T )

:− ro o mT O c a b i n e t (R , C ) .
:− personTOroom ( P , R) .

:− c a b i n e t T O t h i n g ( C , T ) .
:− ro o mT O c a b i n e t ( R , C ) .

:− p e r s o n T O t h i n g ( P , T ) .

Listing 1. An encoding for the House Conﬁguration Problem

Ryabokon (2015) added the following redundant constraint to the problem:

← cabinetTOthing(C, T1), personTOthing(P1, T1),

cabinetTOthing(C, T2), personTOthing(P2, T2), P1 < P2.

h2i

However, this constraint can be learned automatically. Using ALPHA (Weinzierl 2017) to solve
the smallest instance, the nogood that is violated most often and thus leads to the highest number
of conﬂicts is {T personTOroom(P1, R), T personTOroom(P2, R), P1 < P2} which corresponds
to the constraint in Line 19 of Listing 1. This constraint forbids things of two different persons
P1 and P2 from ending up in the same room R. Using our method, the following non-ground
constraint can be learned at the ﬁrst UIP of the implication graphs of all these conﬂicts:

← roomTOcabinet(R,C), cabinetTOthing(C, T1), personTOthing(P1, T1),

cabinetTOthing(C, T2), personTOthing(P2, T2), P1 < P2.

h3i

This constraint can also be easily generated by applying the rule in Line 18 to the constraint
in Line 19 of Listing 1 and by factorizing different literals of predicate roomTOcabinet/2. The
automatically learned constraint h3i is almost identical to the human-created one h2i. However,
it includes one additional literal roomTOcabinet(R,C).

Learned non-ground constraints can be minimized by employing axioms of the Clark comple-
tion (Shepherdson 1984). The Clark completion of a logic program is computed by completing
the head literals of the clauses of the program, including the completion of facts. Every stable
model of a program P must also satisfy the Clark completion comp(P). For example, the comple-
tion of cabinetHasRoom(C) is ∃R : roomTOcabinet(R, C) ← cabinetHasRoom(C). To minimize
the learned nogood by resolution we substitute the existential quantiﬁer by a Skolem function
resulting in the rule roomTOcabinet(r(C), C) ← cabinetHasRoom(C).

To minimize the conﬂict, we have to prove that constraint h2i is entailed. This is achieved by
showing that the program in Listing 1 becomes unsatisﬁable when the negation of constraint h2i

Conﬂict Generalisation in ASP

7

is added to this program. Consequently, it is sufﬁcient to show that the program becomes un-
satisﬁable when the facts cabinetTOthing(c, t1), personTOthing(p1, t1), cabinetTOthing(c, t2),
personTOthing(p2, t2), p1 < p2 are added, where c, t1, t2, p1, and p2 are Skolem constants.

Every stable model of an ASP program is also a model of the program interpreted under the
standard ﬁrst-order logic (FOL) semantic. Consequently, if a program is unsatisﬁable under FOL
semantics, it is also unsatisﬁable skeptical ASP semantics. From cabinetTOthing(c, t1) and the
rule in Line 23 we can deduce cabinet(c). From the constraint in Line 14 of Listing 1, we can
deduce cabinetHasRoom(c) interpreting the sentences in Listing 1 as FOL clauses. Exploiting the
rule provided by the Clark completion of cabinetHasRoom(C) as shown above, we can deduce
roomTOcabinet(r(c), c). Finally, using all the deduced and given facts, constraint h3i is violated.
Since this constraint is implied by the program and we have shown that it is violated if the
negation of constraint h2i is added, constraint h2i is implied. As a result, we have shown that
indeed the learned non-ground constraint can be reduced by dropping roomTOcabinet(R,C).

4 Conﬂict Generalisation

We propose to combine CDNL with EBL to facilitate the learning of general (i.e., non-ground)
constraints. This can be done online (during solving), or ofﬂine. In the latter case, learned con-
straints are computed and recorded. A selection can then be made, for example either automati-
cally based on metrics or by a human, and useful constraints can be added to the original program
to improve solving performance in the future. In this section, we describe how ofﬂine conﬂict
generalisation can be implemented in an ASP solver and exemplify this by means of a proto-
typical implementation in the lazy-grounding system ALPHA (Weinzierl 2017). The constraints
learned by this method can be used by any ASP system, not only by the system employed for
the learning task, because they are stated in pure ASP-Core-2 (Calimeri et al. 2020), using only
predicates from the original program.

Parallelly conducting CDNL on the ground level and on the non-ground level when a conﬂict
is encountered is the basic idea of combining CDNL with EBL to generalise learned nogoods.
A key requirement for this is that for each ground nogood, a corresponding non-ground nogood
is known that can be used for non-ground resolution. We will now describe how non-ground
nogoods are maintained in ALPHA. This can be implemented similarly in any other ASP system.

In ALPHA, there are ﬁve types of nogoods:

• static nogoods that represent ground rules and are generated by the grounder;
• support nogoods that encode the situation that the body-representing atom of a rule must

be true if the head of the rule is true;

• learned nogoods originating from CDNL;
• justiﬁcation nogoods learned by justiﬁcation analysis (Bogaerts and Weinzierl 2018);
• and internal nogoods containing solver-internal atoms.

Non-ground nogoods for static and support nogoods are produced by the grounder as described in
the following paragraphs. Non-ground nogoods for learned nogoods are produced by the conﬂict
generalisation procedure that is the main contribution of this paper. Non-ground nogoods are not
maintained for justiﬁcation nogoods (because these nogoods depend too heavily on the speciﬁc
problem instance) and for internal nogoods (because these are irrelevant to CDNL).

We now describe how non-ground nogoods for static and support nogoods are produced by the
grounder. Let r be a rule of the form h1i and σ be a substitution that is grounding for vars(r). The

8

R. Taupe, A. Weinzierl, G. Friedrich

grounder produces a ground rule rσ from r if no fact and no ﬁxed-interpretation literal makes the
body of rσ false. Because of this, facts and ﬁxed-interpretation literals are actually omitted from
the ground rule produced by the grounder.3 For simplicity of presentation, however, we assume
here that the grounder does not eliminate any atoms known to be true from generated nogoods.
This ensures a one-to-one relationship between literals in ground nogoods and literals in non-
ground nogoods. Additional effort is necessary to map from ground literals to non-ground literals
if true literals are eliminated from ground nogoods, but this is purely a matter of implementation.
Not eliminating any literals from non-ground nogoods, however, is crucial.

A body-representing atom β(r,σ) is created for every ground rule rσ. Similarly, β(r, vars(r))
is a ﬁctitious atom representing the body of a non-ground rule r. The latter atom contains a
term that lists all the variables that occur in the rule r, so that they can affect uniﬁcation when a
body-representing literal is used for resolution. This will become crucial in Section 4.1.

The following static nogoods are produced by the grounder from a rule r and a grounding

substitution σ (Leutgeb and Weinzierl 2017):

{F β(r,σ), T b1σ, . . . , T bmσ, F bm+1σ, . . . , F bnσ}
{F hσ, T β(r,σ)}
{T β(r,σ), F b1σ}, . . . , {T β(r,σ), F bmσ}
{T β(r,σ), T bm+1σ}, . . . , {T β(r,σ), T bnσ}
{T hσ, F β(r,σ)}

h4i
h5i
h6i
h7i
h8i

Nogood h8i is a so-called support nogood and is produced by ALPHA currently only when an
atom occurs in the head of just a single rule. If r is a constraint, only one nogood is created,
which consists of the whole body of rσ.

As a prerequisite for conﬂict generalisation, a solver must associate each ground nogood with
a non-ground nogood. This non-ground nogood is obtained from a non-ground rule the same way
as a ground nogood is obtained from a ground rule. This means that the non-ground nogoods are
exactly the same ones as given above, except the substitution σ does not appear anywhere: The
atom β(r,σ) becomes β(r, vars(r)), and any other ground atom aσ becomes just a.

4.1 Non-ground CDNL

In this section, we describe how we extend CDNL to learn non-ground nogoods. The non-ground
nogoods learned that way can then just be used as constraints and be added to the original pro-
gram. When learning only constraints and no other kinds of rules, F in nogoods can just be
replaced by negation as failure.

Our main conﬂict generalisation algorithm is shown in Algorithm 1. We represent nogoods by
ﬁxed-order multisets to be able to map between literals in ground and non-ground nogoods. The
algorithm takes as input a violated ground nogood ω and the current assignment A. If the conﬂict
occurred at decision level 0, UNSAT is returned in Line 2, otherwise two lists of learned nogoods
are returned in Line 14. The ﬁrst list contains ground nogoods and the second list contains non-
ground nogoods. Each element of both lists corresponds to one UIP and both lists are ordered by
distance from the conﬂict, i.e., the ﬁrst element of both lists is a nogood learned at the ﬁrst UIP
and the last element of both lists is a nogood learned at the last UIP.

3 A more sophisticated grounder would even use the set of atoms derived by a stratiﬁed component of the program

depending only on facts instead of facts(P) to make generated rules more compact.

Conﬂict Generalisation in ASP

9

Algorithm 1 CDNL and conﬂict generalisation
Input: ω: the violated antecedent, A: current assignment
Output: a list of learned ground nogoods and a list of learned non-ground nogoods, or UNSAT

return UNSAT

1: if δ(A) = 0 then
2:
3: end if
4: LearnedNoGoods ← empty list
5: LearnedNonGroundNoGoods ← empty list
6: Ω ← non-ground nogood associated with ω
7: while (l ← FINDNEXTLITERALFORRESOLUTION(ω, A)) 6= NIL do
8:

ω, Ω ← RESOLVE(ω, Ω, l)
if ∃! l′ ∈ ω: δ(ω) = δ(A) then

append ω to LearnedNoGoods
append Ω to LearnedNonGroundNoGoods

end if
12:
13: end while
14: return LearnedNoGoods, LearnedNonGroundNoGoods

15: procedure FINDNEXTLITERALFORRESOLUTION(ω, A)
16:

return the literal l most recently assigned in A that appears in ω
and for which it holds that δ(l) = δ(A) and α(l) 6= NIL,
or NIL if no such literal exists

17: end procedure

18: procedure RESOLVE(ω, Ω, l)
19:

ω′ ← (ω\ {l}) ∪ (α(l) \ {l})
L ← non-ground literal s.t. ω[i] = l and Ω[i] = L for some i
¯L ← non-ground literal s.t. α(l)[ j] = ¯l and Ω[ j] = ¯L for some j
Ω′ ← the non-ground nogood associated with α(l), standardised apart from Ω
σ ← unify(L, ¯L)
σ ← σ ◦ UNIFYDUPLICATELITERALS(Ωσ, Ω′σ,ω,α(l))
Ω′ ← (Ω \ {L})σ∪ (Ω′ \ {L})σ
return ω′, Ω′

26:
27: end procedure

28: procedure UNIFYDUPLICATELITERALS(Ω, Ω′,ω,ω′)
29:

γ ← ω∩ ω′
σ ← empty uniﬁer
for l′ ∈ γ do

L ← non-ground literal s.t. ω[i] = l′ and Ω[i] = L for some i
L′ ← non-ground literal s.t. ω′[ j] = l′ and Ω′[ j] = L′ for some j
σ ← σ ◦ unify(Lσ, L′σ)

end for
return σ

36:
37: end procedure

9:

10:

11:

20:

21:

22:

23:

24:

25:

30:

31:

32:

33:

34:

35:

10

R. Taupe, A. Weinzierl, G. Friedrich

As long as the current nogood contains a literal from the current decision level4 with non-NIL
antecedent (Line 7), it is resolved with the antecedent of such a literal to produce a new current
nogood ω (the resolvent, Line 8). If ω contains exactly one literal on the current decision level
(Line 9), we have found a UIP and remember the current nogood (both ground and non-ground).
Resolution of ground nogoods is straightforward and well-known (Line 19): The resolvent is
the union of two input nogoods (ω and the antecedent of l, α(l)), minus l that occurs in the ﬁrst
input nogood and its complement ¯l that occurs in the second input nogood.

Following the resolution on the non-ground level is more complex, however, and several spe-
cial cases have to be considered. First, the non-ground nogood corresponding to α(l) is identiﬁed
and standardised apart from the current nogood (i.e., variables are renamed to avoid overlaps;
Line 22).5 Then, two steps of uniﬁcation are necessary: First, in Line 23, the two complemen-
tary resolution literals are uniﬁed s.t. variable occurrences are correctly updated in the resolvent.
Then, an additional step is necessary only on the non-ground level: If the two ground input no-
goods share some literals, duplicates are just removed during resolution, because a nogood is a
set of literals. On the non-ground level, however, for each ground literal that occurs in both input
nogoods, the corresponding non-ground literals must be uniﬁed before one of them can be re-
moved (Line 24). This is a restricted form of factoring that is guided by ground resolution. Note
that in the context of CDNL, it is not possible for two input nogoods to contain complementary
literals apart from the resolution literal, because all antecedents must be unit to entail a literal.
Finally, after applying the computed uniﬁer to both non-ground nogoods, the resolution step is
the same as on the ground level (Line 25).

The connection between our suggestion of non-ground CDNL and EBL becomes apparent
when viewing the violated nogood as the training instance. The implication graph utilised by
CDNL constitutes a proof that the nogood is violated by giving a derivation for each literal in the
nogood. Each arc in the implication graph that originates from unit propagation can be seen as a
deﬁnite Horn clause that derives the literal assigned by the propagation step. Operationality in our
setting is speciﬁed by demanding that nogoods are only learned at UIPs. The set of predicates
allowed in learned nogoods is not restricted, because in ASP there are no predicates that are
“easier to solve” than others. In lazy grounding, rules are even grounded only when (part of)
their body is already satisﬁed (Taupe et al. 2019), which alleviates the overhead of additional
rules. Currently, facts from the ASP program are not regarded by our approach because they
are not included in nogoods generated by state-of-the-art answer-set solvers. This ensures that
learned constraints depend only on the rules from the problem encoding.

Algorithm 1 is correct because it derives constraints that are implied when the input program P
is interpreted as an FOL program, and because such constraints are also true in all stable models
of P, as has been discussed in Section 2.1.

Replacing internal atoms in learned constraints. Learned constraints may contain literals of
solver-internal predicates. Literals of two kinds of such predicates, namely body-representing
and choice predicates, can easily be replaced by equivalent (sets of) literals of predicates from the
problem encoding. Only then can resulting constraints be correctly added to the input program.

4 It would also be correct to choose a literal from a lower decision level for resolution, even though this is not done in

CDNL. We will use such an extension of Algorithm 1 for parts of our experiments reported on in Section 5.

5 If no non-ground nogood is available for α(l), conﬂict generalisation can continue with another literal from the current

decision level or just learn the current resolvent.

Conﬂict Generalisation in ASP

11

A body-representing atom such as β(r, vars(r)) represents the body of non-ground rule r. If a
nogood contains a positive literal of such an atom, by deﬁnition this literal can just be replaced by
the body of r. This is equivalent to resolving with nogood h4i above. If the head of r is the head
of no other rule, β(r, vars(r)) can also be replaced by H(r) by resolving with the support nogood
h8i. If a nogood contains a negative literal of a body-representing atom, it can be replaced by the
negated head of r (which is equivalent to resolving with nogood h5i above) or by an arbitrary
negated body literal of r (equivalent to resolving with any of the nogoods in h6i or h7i).

For choice rules, internal literals of a different kind are created, as has been described in
Section 2.1. Because of this, atoms ba may occur in learned nogoods. Due to the way choice rules
are translated to normal rules, the literal F ba is equivalent to T a and can simply be replaced.
Similarly, T ba is equivalent to F a.

Choosing effective constraints. Since the number of learnt constraints might be overwhelming,
strategies to choose effective ones are of vital importance. Our approach is simple but effective:
We count how many conﬂicts could be avoided if the additional non-ground constraints were
already included in the input program.

Each ground nogood that is violated during a run of CDNL belongs to a class of nogoods that
share the same non-ground nogood. When running Algorithm 1 upon such a nogood violation,
the lists of learned non-ground nogoods are associated with this class. When conﬂict generalisa-
tion terminates, the learned nogoods are printed together with the number of violations of their
associated non-ground nogood, s.t. a (human) user can then select the most useful constraints.
Since learned constraints can of course be equivalent to each other when variables are renamed,
only one unique representation of each nogood is remembered. For example, the class of ground
nogoods violated most often while ALPHA solves the HCP (Section 3) is identiﬁed by the non-
ground nogood {T personTOroom(P1, R), T personTOroom(P2, R), P1 < P2}.

Every UIP provides the opportunity to learn a constraint.We focused on the ﬁrst and last UIP
in our experiments, because ground CDNL very successfully learns only from the ﬁrst UIP, and
because we expect constraints from the last UIP also to be useful since they contain the decision
from the current decision level. Investigating the usefulness of other UIPs, and ﬁnding other
quality criteria to discriminate among learned constraints, belong to future work.

If no limit is imposed on the conﬂict generalisation algorithm, it runs until the problem is
solved (one or more answer sets are found, or unsatisﬁability is proven). To increase efﬁciency,
resource consumption may be limited by stopping after a certain time or number of conﬂicts and
then collecting results as if the problem had been solved. In our experiments, conﬂict general-
isation was very effective even if resources were heavily limited, because the class of nogoods
violated most often emerged at the very beginning of the solving process.

4.2 Continuation of the motivating example

The House Conﬁguration Problem (HCP) was presented as a motivating example in Section 3.
We have already presented the constraint h3i that can automatically be learned at the ﬁrst UIP.

When continuing along the implication graph until the last UIP, two different non-ground

12

R. Taupe, A. Weinzierl, G. Friedrich

nogoods can be learned: namely, Ωmin ∪ {β(rr2c, vars(rr2c))} and Ωmin ∪ B(rr2c), where:

Ωmin = {T cabinetTOthing(C, T1), T personTOthing(P1, T1),

T cabinetTOthing(C, T2), T personTOthing(P2, T2), P1 < P2}

rr2c : roomTOcabinet(R,C) ← roomDomain(R), cabinet(C), not

\
roomTOcabinet(R,C).

In both nogoods, internal atoms can be replaced by ordinary atoms as described above to yield
the following unique non-ground nogood6 learned at the last UIP:

← roomTOcabinet(R,C), roomDomain(R), cabinet(C),
cabinetTOthing(C, T1), personTOthing(P1, T1),
cabinetTOthing(C, T2), personTOthing(P2, T2), P1 < P2.

h9i

This nogood contains additional literals of domain predicates (underlined for emphasis), which
is the only difference to the nogood h3i learned at the ﬁrst UIP.

Reduction of the non-minimal learned nogood as described in Section 3 has not yet been
implemented in our system. An implementation based on ﬁrst-order theorem proving is conceiv-
able, in which undecidability could be avoided by imposing a bound on the number of constants,
e.g., a maximal number of entities in a conﬁguration.

5 Experimental Results

We conducted a set of experiments on encodings of the House Reconﬁguration Problem (HRP)
and on a Graph Colouring problem (Listing 2) to demonstrate the feasibility of our approach.
HRP extends HCP from Section 3, which has disregarded reconﬁguration. All encodings and
instances used for our experiments are available on our website.7 The HRP encoding was closely
based on the encoding by Ryabokon (2015), except that the redundant constraint h2i has been
removed, as described in Section 3, and due to syntactic restrictions of ALPHA some aggregates
had to be rewritten and optimization statements were not used at all. Note that for reasons of
a fair comparison, all solvers used the same encodings in our experiments, even though solvers
supporting aggregates could have proﬁted from a more sophisticated encoding.

Graph Colouring problems are an abstraction to which many real-world problems can be
mapped. We have designed 100 satisﬁable and 100 unsatisﬁable graph instances (“3CC” for “3-
colourable chains”) containing repeated patterns that force some pairs of nodes to have the same
colour. On 3CC, our approach was able to learn constraints that represent this pattern. This was
only possible by adapting procedure FINDNEXTLITERALFORRESOLUTION in Algorithm 1 to
also use literals from the next-lower decision level (δ(l) ≥ δ(A) − 1) for resolution. The question
how many decision levels to consider is an interesting topic for future work. From the constraints
learned from the conﬂicts occurring most often, one from the ﬁrst UIP and one from the last UIP
were chosen manually for the experiments. Since these constraints represent only the conﬂict for
one speciﬁc combination of the three colours, they were multiplied manually to cover all possi-
ble combinations.8 The constraints learned at the ﬁrst UIP were then reduced manually, similarly
as has been described in Section 3, yielding the following ﬁnal constraint h10i for red (and two

6 We use nogood notation and constraint notation interchangeably for learned nogoods.
7 http://ainf.aau.at/dynacon
8 Each colour is represented by a predicate in our encoding. Depending on the actual conﬂicts during a speciﬁc solver

run, constraints representing other colour combinations may be produced automatically.

Conﬂict Generalisation in ASP

13

1
2
3
4
5
6

:− node (N) , no t

r e d (N) , no t g r e e n (N) .
:− node (N) , no t b l u e (N) , no t g r e e n (N) .
r e d (N) , no t b l u e (N) .

b l u e (N)
r e d (N)
g r e e n (N)
:− l i n k ( N1 , N2 ) , b l u e ( N1 ) , b l u e ( N2 ) .
:− l i n k ( N1 , N2 ) ,
:− l i n k ( N1 , N2 ) , g r e e n ( N1 ) , g r e e n ( N2 ) .

:− node (N) , no t

r e d ( N1 ) ,

r e d ( N2 ) .

Listing 2. An encoding for our Graph Colouring Problem

Table 1. Number of HRP instances solved by CLINGO (#) per encoding; grounding and solving
times in seconds (1st, 2nd, 3rd quartile)

Encoding

#

original

1st UIP

last UIP

reduced

34

22

22

38

grounding time
Q3

Q2

Q1

solving time
Q2

Q1

6.787

39.738

32.150

34.833

—

—

—

—

—

4.315

66.580

1.030

0.940

—

—

Q3

—

—

—

7.850

52.026

244.256

1.070

9.270

90.575

more constraints for the other colours):

← red(N12), not red(N22),

link(N12, N11), link(N12, N21), link(N11, N21), link(N11, N22), link(N21, N22).

h10i

The ASP solvers ALPHA9 v0.5.0 (Weinzierl 2017), DLV 2.0 (Alviano et al. 2017), and CLINGO
5.4.0 (Gebser et al. 2014) were used. ALPHA was conﬁgured to ground rules strictly lazily and
constraints permissively, as recommended by Taupe et al. (2019). The JVM was called with pa-
rameters -Xms1G -Xmx32G. For each problem instance, solvers searched for 10 answer sets.10

Experiments were run on machines each with two Intel R(cid:13) Xeon R(cid:13) CPU E5-2650 v4 @ 2.20GHz
with 12 cores each, 252 GB of memory, and Ubuntu 16.04.1 LTS Linux. Benchmarks were sched-
uled with ABC Benchmarking System (Redl 2016) and HTCondorTM.11 PYRUNLIM12 was used
to measure time and memory consumption and to limit time consumption to 10 minutes per in-
stance, memory to 40 GiB and swapping to 0. Care was taken to avoid interference between
CPUs, e.g., by not running different benchmarks concurrently on the same machine.

To compare solving performance using encodings with and without learned constraints, cactus
plots (Figs. 1 to 6) have been created in the usual way. The x axis gives the number of instances
solved within real (i.e., wall-clock) time which is given on the y axis. Time is accumulated
over all solved instances. Since we are investigating the effects of constraints on each solver
and not comparing solvers against each other, maximum axis values vary between solvers. One

9 https://github.com/alpha-asp/Alpha
10 Obtaining more than one (maybe trivial) answer set is often desirable. The number 10 has been chosen arbitrarily.
11 https://github.com/credl/abcbenchmarking, http://research.cs.wisc.edu/htcondor
12 https://alviano.com/software/pyrunlim/

original encoding
learned at ﬁrst UIP
learned at last UIP
reduced constraint

14

)
s
e
t
u
n
i
m

(

n
o
i
t
p
m
u
s
n
o
c

e
m

i
t

l
a
e
R

24

21

18

15

12

9

6

3

0

R. Taupe, A. Weinzierl, G. Friedrich

original encoding
learned at ﬁrst UIP
learned at last UIP
reduced constraint

400

350

300

250

200

150

100

50

0

)
s
e
t
u
n
i
m

(

n
o
i
t
p
m
u
s
n
o
c

e
m

i
t

l
a
e
R

2

4

8

6
Number of instances

12

10

14

16

18

0

25

50

75

100
Number of instances

125

150

175

200

Fig. 1. HRP results with ALPHA

Fig. 2. 3CC results with ALPHA

original encoding
learned at ﬁrst UIP
learned at last UIP
reduced constraint

)
s
e
t
u
n
i
m

(

n
o
i
t
p
m
u
s
n
o
c

e
m

i
t

l
a
e
R

40

35

30

25

20

15

10

5

0

original encoding
learned at ﬁrst UIP
learned at last UIP
reduced constraint

)
s
e
t
u
n
i
m

(

n
o
i
t
p
m
u
s
n
o
c

e
m

i
t

l
a
e
R

360

320

280

240

200

160

120

80

40

0

0

4

8

12

16
Number of instances

20

24

28

32

0

25

50

75

100
Number of instances

125

Fig. 3. HRP results with DLV2

Fig. 4. 3CC results with DLV2

original encoding
learned at ﬁrst UIP
learned at last UIP
reduced constraint

)
s
e
t
u
n
i
m

(

n
o
i
t
p
m
u
s
n
o
c

e
m

i
t

l
a
e
R

64

56

48

40

32

24

16

8

0

original encoding
learned at ﬁrst UIP
learned at last UIP
reduced constraint

)
s
e
t
u
n
i
m

(

n
o
i
t
p
m
u
s
n
o
c

e
m

i
t

l
a
e
R

240

210

180

150

120

90

60

30

0

0

5

10

15

20
Number of instances

25

30

35

0

25

50

75

100
Number of instances

125

150

175

200

150

175

200

Fig. 5. HRP results with CLINGO

Fig. 6. 3CC results with CLINGO

curve has been drawn for each encoding: the original encoding, one encoding each with the
additional constraint(s) learned automatically at the ﬁrst/last UIP (h3i/h9i for HRP), and one
encoding in which only the reduced constraint(s) (h2i for HRP, h10i for 3CC) are added to the
original encoding.

Learned constraints improved solving performance in many cases. For HRP, ALPHA beneﬁted
especially from the reduced constraint, but also from the constraint learned automatically at
the ﬁrst UIP. DLV2 proﬁted most from the ﬁrst-UIP constraint, but the reduced one was not

Conﬂict Generalisation in ASP

15

far behind. The last-UIP constraint affected DLV2’s performance negatively, however. CLINGO
proﬁted only from the reduced constraint, while automatically learned constraints caused overall
solving time to increase. Detailed analysis of grounding and solving times as reported by CLINGO
(Table 1) shows that this was due to additional grounding effort induced by learned constraints.
With automatically learned constraints, more than half of the instances could not be solved within
10 minutes, therefore no median times (second quartiles) can be shown. In almost all time-out
cases, CLINGO did not manage to ﬁnish grounding and start solving. For 3CC, all solvers perform
best with the reduced constraints, while the 1st-UIP constraints also improve performance.

Learning itself is cheap: On the ﬁrst author’s computer, the relevant HRP constraints are
learned using the easiest instance in less than 6 seconds if search is stopped after 50 conﬂicts
and in less than 14 seconds if search is carried out until the ﬁrst answer set is found (our im-
plementation has not yet been tuned for optimal performance). Performance for 3CC is similar.
Computational complexity has not yet been analysed and could be addressed in future work.

The results show that our approach is able to improve ASP solving using both lazy-grounding
and ground-and-solve systems. While effects vary between types of learned constraints and
solver implementations, every system under investigation has proﬁted from at least one learned
constraint in both domains.

6 Conclusions

We have proposed an extension of CDNL that, while solving one problem instance, learns non-
ground nogoods that can be used to speed up the solving of other problem instances. As far as
we know, this is the ﬁrst attempt to generalise and re-use knowledge learned during ASP solv-
ing. Experimental results showed compelling beneﬁts of our approach: Both ground-and-solve
systems and lazy-grounding systems performed signiﬁcantly better on instances of a practical
conﬁguration problem and a graph colouring problem when using constraints learned by our
method, solving more instances and/or solving the problems faster.

So far, we have been experimenting with encodings for two problem domains: a graph colour-
ing problem, and an important part of many conﬁguration domains (those where systems are
composed hierarchically). However, it seems natural to assume that many domains feature re-
dundant constraints that may not be obvious to a human modeller. We therefore see our approach
mainly as a tool to support the design of efﬁcient answer-set programs.

It remains to be clariﬁed whether our approach could improve encodings used by the ASP
competitions (Gebser et al. 2020), which generally are already heavily optimised, or whether it
would prove more useful when applied to encodings devised by inexperienced modellers.

Acknowledgments. This work has been conducted in the scope of the research project DynaCon
(FFG-PNr.: 861263), which is funded by the Austrian Federal Ministry of Transport, Innovation
and Technology (BMVIT) under the program “ICT of the Future” between 2017 and 2020,13 and
in the scope of the research project Productive4.0, which is funded by EU-ECSEL under grant
agreement no737459.

13 See https://iktderzukunft.at/en/ for more information.

16

R. Taupe, A. Weinzierl, G. Friedrich

References

ALVIANO, M., CALIMERI, F., DODARO, C., FUSC `A, D., LEONE, N., PERRI, S., RICCA, F., VELTRI, P.,
AND ZANGARI, J. 2017. The ASP system DLV2. In LPNMR. LNCS, vol. 10377. Springer, 215–221.
BOGAERTS, B. AND WEINZIERL, A. 2018. Exploiting justiﬁcations for lazy grounding of answer set

programs. In IJCAI. ijcai.org, 1737–1745.

CALIMERI, F., FABER, W., GEBSER, M., IANNI, G., KAMINSKI, R., KRENNWALLNER, T., LEONE, N.,
MARATEA, M., RICCA, F., AND SCHAUB, T. 2020. ASP-Core-2 input language format. Theory Pract.
Log. Program. 20, 2, 294–309.

DEJONG, G. AND MOONEY, R. J. 1986. Explanation-based learning: An alternative view. Mach.

Learn. 1, 2, 145–176.

FABER, W., PFEIFER, G., AND LEONE, N. 2011. Semantics and complexity of recursive aggregates in

answer set programming. Artif. Intell. 175, 1, 278–298.

FRIEDRICH, G., RYABOKON, A., FALKNER, A. A., HASELB ¨OCK, A., SCHENNER, G., AND SCHREINER,
H. 2011. (Re)conﬁguration using answer set programming. In Conﬁguration Workshop. CEUR-WS.org.
GEBSER, M., KAMINSKI, R., KAUFMANN, B., AND SCHAUB, T. 2014. Clingo = ASP + control: Prelim-

inary report. CoRR abs/1405.3694.

GEBSER, M., KAUFMANN, B., AND SCHAUB, T. 2012. Conﬂict-driven answer set solving: From theory

to practice. Artif. Intell. 187, 52–89.

GEBSER, M., MARATEA, M., AND RICCA, F. 2020. The seventh answer set programming competition:

Design and results. Theory Pract. Log. Program. 20, 2, 176–204.

VAN HARMELEN, F. AND BUNDY, A. 1988. Explanation-based generalisation = partial evaluation. Artif.

Intell. 36, 3, 401–412.

HIRSH, H. 1987. Explanation-based generalization in a logic-programming environment. In IJCAI. Morgan

Kaufmann, 221–227.

LEUTGEB, L. AND WEINZIERL, A. 2017. Techniques for efﬁcient lazy-grounding ASP solving. In DE-

CLARE. LNCS, vol. 10997. Springer, 132–148.

LINTAO ZHANG, MADIGAN, C. F., MOSKEWICZ, M. H., AND MALIK, S. 2001. Efﬁcient conﬂict driven

learning in a boolean satisﬁability solver. In ICCAD. IEEE, 279–285.

MITCHELL, T. M. 1997. Machine learning, International Edition. McGraw-Hill Series in Computer

Science. McGraw-Hill.

MITCHELL, T. M., KELLER, R. M., AND KEDAR-CABELLI, S. T. 1986. Explanation-based generaliza-

tion: A unifying view. Mach. Learn. 1, 1, 47–80.

REDL, C. 2016. Automated benchmarking of KR-systems. In RCRA@AI*IA. CEUR Workshop Proceed-

ings, vol. 1745. CEUR-WS.org, 45–56.

RUSSELL, S. J. AND NORVIG, P. 2010. Artiﬁcial Intelligence – A Modern Approach, Third International

Edition. Pearson Education.

RYABOKON, A. 2015. Knowledge-based (re)conﬁguration of complex products and services. Ph.D. thesis,

Alpen-Adria-Universitt Klagenfurt.

SHEPHERDSON, J. C. 1984. Negation as failure: A comparison of clark’s completed data base and reiter’s

closed world assumption. J. Log. Program. 1, 1, 51–79.

SILVA, J. P. M., LYNCE, I., AND MALIK, S. 2009. Conﬂict-driven clause learning SAT solvers.

In

Handbook of Satisﬁability. IOS Press, 131–153.

TAUPE, R., WEINZIERL, A., AND FRIEDRICH, G. 2019. Degrees of laziness in grounding – effects of

lazy-grounding strategies on ASP solving. In LPNMR. LNCS, vol. 11481. Springer, 298–311.

WEINZIERL, A. 2013. Learning non-ground rules for answer-set solving. In 2nd Workshop on Grounding

and Transformations for Theories With Variables. 25–37.

WEINZIERL, A. 2017. Blending lazy-grounding and CDNL search for answer-set solving. In LPNMR.

LNCS, vol. 10377. Springer, 191–204.

