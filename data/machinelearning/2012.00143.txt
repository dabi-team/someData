0
2
0
2

c
e
D
4

]

G
L
.
s
c
[

2
v
3
4
1
0
0
.
2
1
0
2
:
v
i
X
r
a

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

1

Task Allocation for Asynchronous Mobile Edge
Learning with Delay and Energy Constraints

Umair Mohammad, Student Member, IEEE, Sameh Sorour, Senior Member, IEEE, and
Mohamed Hefeida, Senior Member, IEEE

Abstract—This paper extends the paradigm of “mobile edge learning (MEL)” by designing an optimal task allocation scheme for
training a machine learning model in an asynchronous manner across mutiple edge nodes or learners connected via a
resource-constrained wireless edge network. The optimization is done such that the portion of the task allotted to each learner is
completed within a given global delay constraint and a local maximum energy consumption limit. The time and energy consumed are
related directly to the heterogeneous communication and computational capabilities of the learners; i.e. the proposed model is
heterogeneity aware (HA). Because the resulting optimization is an NP-hard quadratically-constrained integer linear program (QCILP),
a two-step suggest-and-improve (SAI) solution is proposed based on using the solution of the relaxed synchronous problem to obtain
the solution to the asynchronous problem. The proposed HA asynchronous (HA-Asyn) approach is compared against the HA
synchronous (HA-Sync) scheme and the heterogeneity unaware (HU) equal batch allocation scheme. Results from a system of 20
learners tested for various completion time and energy consumption constraints show that the proposed HA-Asyn method works better
than the HU synchronous/asynchronous (HU-Sync/Asyn) approach and can provide gains of up-to 25% compared to the HA-Sync
scheme.

Index Terms—Mobile Edge Learning, Dynamic Task Allocation, Distributed Machine Learning, Mobile Edge Computing.

(cid:70)

1 INTRODUCTION

Mobile edge computing (MEC) is proving to be a successful
paradigm for dealing with the computational challenges
raised by the era of the internet of everything (IoE). With the
world embracing smart architecture including smart cities,
smart grids, smart homes, etc., 41 billion internet of things
(IoT) devices are expected be connected to the internet by
2022 [1]. Examples of end user devices/edge nodes include
smart phones, trafﬁc cameras, autonomous connected ve-
hicles, unmanned aerial vehicles (UAVs), etc. Furthermore,
Cisco estimates that this equipment will generate up-to 800
zettabytes (∼ 1021) of data [1].

To serve a useful purpose, this data needs to be analyzed.
Transferring these monumental amounts of data generated
on devices mostly connected via wireless edge networks
spread across vast geographical regions to cloud servers
for analysis via multiple backhaul links is time-consuming,
costly, and raises security and privacy concerns [2]. There-
fore, it is expected that 90% of data analytics will be done
on either edge processors using MEC or on the end devices
themselves using hierarchical MEC (H-MEC) [3].

This paradigm of task computation at the edge is supported
by the latest works in MEC/H-MEC [4], [5], [6], [7]. It is
expected that machine learning (ML) tasks will comprise a

• U. Mohammad is with the School of Computing and Information Science,

•

Florida International University, Miami, FL, USA, 33172.
E-mail: umair.mohammad@ﬁu.edu
S. Sorour is with the School of Computing, Queen’s University,
Kingston,ON, Canada, K7L 3N6.
E-mail: sameh.sorour@queensu.ca

• M. Hefeida is with the Department of Computer Science and Electrical
Engineering, West Virginia University, Morgantown, WV, USA, 26506.
E-mail: mohamed.hefeida@mail.wvu.edu

large part of H-MEC computations because ML has shown
to provide superior performance in many data analytics
applications such as predictive modeling, object recognition
and image segmentation. Such applications are expected to
form the basis of Edge Artiﬁcial Intelligence (Edge AI).

Many ML techniques, including regression, support vec-
tor machine (SVM) and neural networks (NN) are built
on gradient-based learning. This usually involves iterative
updates of the ML model parameters based on the gradient
of a loss function that is deﬁned according to the ML model.
Because such iterative approaches can be exhaustive for a
single device, distributed learning (DL) has been proposed
to training ML algorithms over multiple learners. There are
two approaches possible: training an ML model on a large
dataset in a distributed manner where subsets of the data are
located across multiple learners (data parallelism) or to train
very large models distributedly on a single dataset located
at each learner (model parallelism). Although both options
apply to the wireless edge and our work does support MP,
most of the discussion focuses on the DP scenario. However,
MP support will be highlighted whenever appropriate.

DL has been widely investigated over wired/non-
heterogeneous computing and communication environ-
ments [8], [9], [10], [11]. Recently, researchers have turned
their attention to deploying DL models for training on
nodes or learners connected via the wireless edge [12], [13],
[14], [15], [16], [17], [18], [19], [20], [21], [22], [23]. DL over
the wireless edge, or mobile edge learning (MEL) as we
term it, is motivated by two distinct yet practical scenarios:
federated learning (FL) and parallelized learning (PL).

In FL, the learners own their local dataset. A central hub

 
 
 
 
 
 
JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

2

Fig. 1. Illustration of the two distinct approaches of FL and PL.

called an orchestrator initiates the learning process by
sending the global model parameter set to each learner,
where each learner, in parallel, performs the updates on
the ML model locally using its private dataset, and sends
back the locally updated model. The orchestrator collects
the local ML models from each learner, does the global
update/aggregation, and sends back the optimal ML model
to each learner for the next cycle until a stopping criteria is
reached. We refer to one such cycle as the global update cy-
cle. Typically, FL has been proposed in literature to preserve
data privacy [24], [25].

On the other hand, PL usually involves an orchestrator
that parallelizes the learning process on its locally owned
dataset over multiple learners. The difference in PL is that
at the start of each global cycle, the orchestrator also sends
a subset of the data on which to learn along with the
model parameters. This scenario is mainly useful for cases
where the orchestrator may have enough data but not the
processing capability to learn on such a large dataset. It can
leverage the communication and computation capacity of
other learners to train the ML model distributedly. The two
distinct approaches are summarized in Figure 1.

Deploying ML models for MEL presents unique challenges
because the wireless edge is resource-constrained from var-
ious aspects. For example, communication resources are
limited in terms of bandwidth and available channels. Most
end devices are battery operated and therefore limited in
energy. Simultaneously, the tasks may need to be completed
within very short times. In contrast to multicore processor
platforms connected via wired networks such as high per-
formance computing (HPC) systems, the different nodes in
edge networks have widely varying computing and com-
munication capabilities. Therefore, it is vital to study the
impact of these constraints and heterogeneous resources on
MEL. Some of the factors affecting the loss or accuracy of
the ML model in MEL include the number of total updates
(including cycles at which global aggregation occurs), fre-
quency of global updates, and the data distribution at each
learner. These parameters are constrained by the available
resources.

Although FL has been extensively studied in literature [12],
[13], [14], [15], [19], [20], PL in particular or in general, MEL
which comprises both, have been sparsely studied [16], [17],
[18]. Some works have proposed algorithms for edge DL
without speciﬁcally focusing on the resource allocation is-
sues [22], [23]. Most works on edge FL that consider resource
consumption only do so in generic terms [12], [13], [14],
[15] without considering the heterogeneities, i.e. they are
heterogeneity unaware (HU). Although the works of [19],

[20] are heterogeneity aware (HA), they ignore the aspect
of batch allocation and the PL scenario. The implications
of wireless computation/communication heterogeneity on
optimizing batch allocation to different learners for max-
imizing accuracy while satisfying a delay constraint were
studied in [16] and dual time and energy constraints in [18].

Typically in MEL, the orchestrator waits for all learners to
complete an equal number of iterations of the ML training
algorithm and hence, we call this the synchronous approach.
The above referenced works mainly deal with the syn-
chronous approaches such as the adaptive control algorithm
of [12] and the HA-Sync scheme of [16]. Recently, some
work has been carried out on the asynchronous scenario
by allowing some staleness between the local model param-
eters and the locally calculated gradients so that powerful
devices with good communication links may actually pro-
vide a faster validation accuracy progression. This has been
proposed for wired networks [9] and for training over the
wireless edge [17], [21]. However, the work in [21] does not
cover the impact of the physical layer whereas [17] does not
include the impact of energy constraints.

To the best of the authors’ knowledge, this work is the
ﬁrst attempt to have a staleness aware algorithm for asyn-
chronous MEL with both, time and energy constraints. Here,
we emphasize that our model is different than the models
in [9], [21] such that the system in our proposed asyn-
chronous scheme, learner performs still reports back the
local model parameters within a pre-set duration. However,
individually ,the learners may have performed a different
number of local updates within this duration and therefore,
the system is asynchronous in terms of the number of
updates. This approach will make sure that the aggregation
is done uniformly for all learners without being affected by
stragglers or bad-performing learners. The novelty is in the
fact that the number of local updates and the local dataset
size on which a learner trains the local model are jointly
optimized. Furthermore, it is guaranteed that the task will
complete within a given duration without exceeding local
energy consumption limits for each learner.

To this end, the problem for MEL is ﬁrst formulated as
quadratically-constrained integer linear problem (QCILP),
which is an NP-hard problem. It is shown that FL is just a
subset of the PL approach with the component of batch re-
transmission from the orchestrator to each learner removed.
Thus, the MEL model discussion focuses on the more gen-
eral PL scenario but all variations for the FL scenario will
be clariﬁed whenever needed. A two-step solution is then
proposed based on a relaxation and suggest and improve
(SAI) approach. The merits of the proposed solution are
shown by comparing its performances to both,the HA-Sync
and the HU equal task allocation approach of [13], [14].

1.1 Contributions

This paper extends the work on MEL in the following ways:

1)

In contrast to the work on asynchronous MEL in [17]
and the work on dual time and energy constraints
for synchronous MEL [18], this paper provides solu-

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

3

tions to facilitate asynchronous MEL with dual time
and energy constraints while being HA.

2) A new way to model the problem for asynchronous
MEL is proposed in Section 3. In contrast to [17], the
objective is now to maximize local updates while
controlling staleness. A comprehensive proof on the
beneﬁts of maximizing the average number of local
updates while controlling the staleness is provided.
3) A novel two-step solution is proposed in Section 4
where the loose upper bounds on the solution to the
synchronous problem are used as initial conditions
to the asynchronous problem (HA-Asyn).

4) Through extensive simulations under varying time
and energy constraints, the impact of different levels
of staleness is studied and the gains achieved com-
pared to the HA-Sync scheme of [18] are quantiﬁed
in Section 5. Moreover, it is shown that in some
cases, the proposed HA-Asyn provides a better
solution to the HA-Sync problem, and that HA
schemes in general work better than the HU scheme.
Section 5 also summarizes the results by providing
recommendations on the best scheme for different
scenarios and more importantly, suggestions are
given on selecting the best staleness level for the
HA-Asyn scheme.

5)

The rest of the paper is organized as follows: Section 2
presents system model including the general DL followed
by a transition to MEL. The problem of interest in this paper
is formulated in Section 3 and our proposed solution for
this problem is detailed in Section 4. Section 5 illustrates the
testing results and Section 6 concludes the paper.

2 SYSTEM MODEL FOR MEL

2.1 Gradient-based DL Preliminaries
Consider a dataset D that consists of d samples which can
be used to train an ML model where each sample n for
n = 1, . . . , d has a set of F features denoted by xn and
a target yn. In ML, the objective is to ﬁnd the relationship
between xn and yn using a set of parameters w such that
a loss function, F (xn, yn, w), or Fn (w) for short because
xn and yn are known, is minimized. Because it is generally
difﬁcult to ﬁnd an analytical solution, typically an iterative
gradient descent approach is used to optimize the set of
model parameters such that w[l + 1] = w[l] − η∇F (w[l])
where l represents the time step or iteration and η is the
learning rate typically set on the interval (0, 1). In deter-
ministic gradient descent (DGD), the ML model goes over
each sample one-by-one, or more commonly, batch-by-batch
using a mini-batch approach, until it reaches sample # d;
completing one epoch. If data is re-shufﬂed randomly in
between epochs, this method is known as stochastic GD
(SGD). A total of L epochs may be performed depending
on the stopping criteria.

Consider the case where there exists one centralized con-
troller or orchestrator that trains an ML model to solve a
speciﬁc problem (classiﬁcation, prediction, image segmen-
. . . , K} learners.
tation, etc.) on a set of K = {1,
In DL with DP, a batch of the data Dk of size dk is present

. . . , k,

Fig. 2. Illustration of the DL process with DP

at each individual learner k which may be locally owned or
supplied by the orchestrator. The orchestrator initiates the
learning process by sending a global model w and possibly
dk samples to each learner k. Each learner k applies the
gradient descent approach to the local model wk in parallel
as shown in (1), and sends back the local models to the
orchestrator for global aggregation. One such cycle is can be
called the global update cycle.

wk[l + 1] = wk[l] − η∇Fk(wk[l])

(1)

The local model parameter at learner k is given by wk, the
local loss is given by Fk, and η is the learning rate. At time-
step l + 1, the local model wk[l + 1] depends on the model
wk[l] at previous step l and the gradient of the local loss
∇Fk(w). The local loss Fk ∀ k ∈ K can be calculated using
the local dataset Dk of size dk in the following way [12]:

Fk(w) =

1
dk

dk(cid:88)

n=1

Fn(w)

(2)

However, the global optimal model parameter set w will
only be visible to the learners after a global aggregation
which may occur at any arbitrary time-step l for l =
. . . , L. In the synchronous case, at all learners k, a
1,
global aggregation occurs after τ time-steps; at that instant,
wk = w ∀ k ∈ K. In the asynchronous case, the global
aggregations will occur after potentially different τk updates
for each learner k ∀ k ∈ K. The globally optimal model
parameter set can be obtained by applying the following

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

4

Given the above descriptions of the learning process, the
orchestrator requires tS
k seconds to transmit the model pa-
rameters and/or the batch dk for learner k. Please note that
the energy consumed by the orchestrator during transmis-
sion is ignored because we are concerned with the energy
consumption of the learners only. Learner k consumes tC
k
seconds and energy eC
k to perform one learning iteration
over it’s allotted dataset dk. It then consumes a further time
tR
k and energy eR
k to send back the updated local model
parameters wk. Therefore, for each learner, the time taken
and the energy consumed for the local learning process is
given by (5) and (6), respectively.
k + τktC

k + tR
k

tk = tS

(5)

ek = τkeC

k + eR
k

(6)

Fig. 3. System model of a MEL setting

aggregation mechanism [12]:

w =

1
d

K
(cid:88)

k=1

dkwk

(3)

The orchestrator may perform multiple global cycles until a
stopping criteria is reached such as an accuracy threshold or
resource depletion. This process is summarized in Fig. 2.

2.2 Transition to MEL

An MEL system consists of an orchestrator and K learners
where dk data samples allocated to learner k, k ∈ κ =
{1, 2, . . . , K} so that it performs τk learning iterations. Each
learner has a computational capacity of fk in Hz, an asso-
ciated communication channel hk0 to the orchestrator. An
example of an MEL system is illustrated in ﬁg. 3.

In MEL, one approach is to have all K learners do τk = τ
local updates of the model parameters wk ∀k ∈ K; this
is the synchronous approach presented in [18]. The other
approach is to optimize τk for each learner while controlling
the difference among the number of local updates done
by different learners. Here, we deﬁne staleness sk,l as the
difference between the number of updates done by two
arbitrary learners k and l in the following way:

sk,l = τk − τl

if

(cid:40)

k & l ∈ K | l (cid:54)= k
τk ≥ τl

(4)

Furthermore, as described in section 1, there are two possi-
bilities for MEL. In FL, the orchestrator and each learner
k exchange model parameters only whereas in PL, the
orchestrator also sends dk data samples along with the
global model w at the beginning of each global cycle. It
can be noted here that FL is a subset of PL where the
orchestrator only sends model parameters instead of both,
data and model parameters. The remaining steps are the
same as described in Fig. 2.

k

The size of the model parameter set wk is given by Bmodel
=
Pm (dkSd + Sm), where Pm is the model bit precision. Pm
and Pd may include compression ratio for efﬁcient storage.
Sm represents the constant model size in terms of the ML
model parameters whereas the term dkSd is to support MP
where Sd is used to relate the model to the batch-size. Each
learner k sends its locally updated model of size Bmodel
to
the orchestrator with power Pko over a wireless channel of
bandwidth W and gain hko. Assuming that an ML model of
computational complexity Cm, Xk = dkCm computations
occur per local update. The time taken for learner k to
transmit the latest model parameters is given by:

k

eR
k =

Pk0Bmodel
k
Rk

=

Pm (dkSd + Sm)
1 + Pkohko

(cid:16)

W log2

N0

(cid:17) , k ∈ K

(7)

Let us represent learner k’s processing power by fk in GHz.
The energy consumed by learner k in each iteration of the
learning iteration on a sample size of dk is given by:
ζ−1, k ∈ K [7]

ν−1 = µdkCmfk
where µ is the on-board chip capacitance (typically 10−11 F)
and ν = 2.

eC
k = µXkfk

(8)

The total energy consumed by learner k in one global update
cycle can be given by:

ek = τkeC

k + eR
k

=

Pk0Pm (dkSd + Sm)
W log2

1 + Pkohko

(cid:16)

N0

(cid:17) + τ dkµCmfk

ζ−1

(9)

The total energy used by learner k can be expressed as:

the
Pk0PmSd

where
(cid:16)
1+ Pko hko

W log2

N0

coefﬁcients G2
(cid:17) , and G0

k =

ek = G2

kτkdk + G1

kdk + G0
k
ζ−1, G1
k = µCmfk
Pk0PmSm
(cid:17) .
(cid:16)
1+ Pko hko

W log2

N0

(10)

k =

k

The size of local dataset dk can be given by Bdata
=
dkFPd ∀ k where F is the feature vector size and Pd is
the bit precision. At every global update step, each learner
k and the orchestrator will exchange Bmodel
bits and the
orchestrator may send an additional and Bdata
bits for
PL. The total time taken tk can then be written as shown
in (11). The coefﬁcients are given by C 2
k, re-
spectively, where, C 2
(cid:17) , and

k, C 1
F Pd+2PmSd

, C 1

k and C 0
1+ Pko hko

k = Cm
fk

k =

(cid:16)

k

k

W log2

N0

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

5

C 0

W log2

k =

2PmSm
(cid:16)
1+ Pko hko

k is speciﬁc to
PL. For more details on the formulation of tk, the readers
are referred to [16].

(cid:17) . The ﬁrst term in C 1

N0

for any iteration l within an interval g, for l = 1, . . . , L and
g = 0, 1, 2, . . ., can bounded by:

(cid:107)w[l + 1] − ˆwg[l + 1](cid:107) ≤ (cid:107)w[l] − ˆwg[l](cid:107) +

tk = C 2

kτ dk + C 1

kdk + C 0
k

(11)

ηβ
d

K
(cid:88)

k=1

fk [l − gτm]

(13)

3 PROBLEM FORMULATION

It has been previously shown that maximizing the local
iterations per global cycle can lead to a faster progression of
the learning process [16], [18]. On the other hand, for asyn-
chronous approaches, it has been shown that accuracy can
be optimized by controlling the staleness [9], [21]. Although
our model is different, [9], [21], we can still demonstrate that
a joint approach be employed to obtain the best accuracy.

Lemma 1. Jointly controlling the staleness sk,l ∀ k ∈ K & l ∈
{K | l (cid:54)= k} while maximizing the minimum number of
updates min(τk)k ∈ K will minimize the global loss of the
proposed HA-Asyn MEL.

Proof: Let’s assume the orchestrator will train the MEL
model for a total of L epochs where a global aggregation
can occur at any update step l for l = 1,
. . . , L. Local
updates occur at each step l. In the synchronous model of
[12], [16], [18], between any two global updates, each learner
k performs τ updates whereas it performs τk updates in
the proposed asynchronous version. Let us assume, to fa-
cilitate the analysis, that the global aggregations occur at
integer multiples of the τm = max(τk); which represents
the maximum possible updates that would be done by the
highest performing learner. We can now deﬁne the interval
[g] deﬁned over [gτm, (g + 1)τm] for g = 0, 1, 2, . . ..

Assuming a global aggregation were to occur at each itera-
tion l, let us deﬁne an auxiliary set of global model param-
eters denoted by ˆw[g] for any interval [g] which would be
calculated if a global update step took place. (Note that at
the beginning of any interval [g], a global aggregation does
occur.) Then, the update rule for this auxiliary set can be
given by:

ˆw[g][l + 1] = ˆw[g][l] − η∇F ( ˆw[g][l])

(12)

We assume that the local loss function at learner k given by
Fk(w) is:

1)
2)
3)

convex
ρ-Lipschitz (cid:107)Fk(w) − Fk( ¯w)| ≤ ρ|w − ¯w|
β-smooth (cid:107)∇Fk(w) − ∇Fk( ¯w)| ≤ β|w − ¯w|

These assumptions will hold for ML models with convex
loss function such as linear regression and SVM. By sim-
ulations, we will show that the proposed solutions work
for non-convex models such as DNN with ReLU activation.
It has been shown that for such a model, the difference
between the global optimal model and the auxiliary model

The function fk(t) = δk
β [(ηβ + 1)t − 1] which relates the
local model wk ∀ k ∈ K to the auxiliary model set ˆwg[l] as
follows:

(cid:107)wk[l] − ˆwg[l](cid:107) ≤ fk(l − gτm)

(14)

Assume that each learner performs τk updates and for a
particular interval, l ∈ [gτk, (g + 1)τk] ∀ k ∈ K where l is
the progression of the index of the best performing learner.
Then, the upper bound on the model divergence can be
given by the following expression:

(cid:107)w[l + 1] − ˆw[l + 1](cid:107) ≤ (cid:107)w[l] − ˆw[l](cid:107) +

ηβ
d

K
(cid:88)

k=1

fk(l − gτk)

(15)

The learning rate η can be selected such that 0 ≤ ηβ ≤ 1
which is necessary to satisfy the assumptions in [12]. In that
case 1 ≤ ηβ + 1 ≤ 2 and because tk = l − [g − 1]τk ≥ 0, the
function fk(tk) grows exponentially greater as t increases
because the dominating term is (ηβ + 1)tk . So, as the
staleness sk,l = τk − τl k, l ∈ K | l (cid:54)= k increases, fk(tk)
will be higher for more learners which will result in a higher
bound on the divergence. Therefore, as the auxiliary model
diverges further from the globally optimal model, the loss
will increase and hence, it can be expected that the accuracy
will decrease.

The learning will progress faster as l is higher which can be
done maximizing the τm. Alternatively, if we want to keep
tk ∀ k low, we can maximize the min(τk) while controlling
(cid:4)
staleness sk,l.

Therefore, the objective is to allocate batches dk such that
we maximize min(τk) for k ∈ K while minimizing sk,l ∀ k.
However, this problem will be non-tractable and difﬁcult
to solve. A more tractable way to achieve these objectives
is to maximize the average of the local updates τk while
controlling the staleness sk,l ∀ k. In this way, we can increase
the number of local updates by the worst performing learner
while controlling the model staleness. Based on this, the
optimization variables are τk and dk, and we can study
the impact of different values of staleness by an additional
constraint sk,l ≤ c.

In addition to this, the optimization needs to be done such
that the global cycle is completed before time T and does
not violate the energy consumption limit E0
k (J) per global
cycle of any learner k. It is observable that the relationship
between the optimization variables in the global cycle time
and local energy consumption constraints will be quadratic
in τk and dk. Moreover, due to τk and dk ∀ k being non-
negative integers, the resulting problem is a quadratically

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

6

constrained integer linear program (QCILP) as shown:

4.1 Problem Relaxation

max
τk,dk ∀ k

1
K

K
(cid:88)

k=1

τk

s.t.

k ≤ T,
k ≤ E0
k,

kdk + C 0
kdk + G0

kdkτk + C 1
C 2
G2
kdkτk + G1
|τk − τl| ≤ c ∀k, l ∈ K | l (cid:54)= k
K
(cid:88)

dk = d

∀ k ∈ K

∀ k ∈ K

k=1
τk ∈ Z+,
dk ∈ Z+,
dk > dl ∀ k ∈ K

∀ k ∈ K
∀ k ∈ K

(16)

(16a)

(16b)

(16c)

(16d)

(16e)

(16f)

(16g)

Constraint (16a) and (16b) guarantee that all learners k
satisfy the global cycle time constraint T and the their en-
ergy consumption limit constraint E0
k ∀ k ∈ K, respectively.
Constraint (16c) ensures that the staleness does not exceed
a desired amount c. We will test for multiple values of
the staleness and report the results later in section 5. The
assurance that the orchestrator will learn on the complete
dataset D is given by (16d). Lastly, constraints (16e) and (16f)
ensure that both optimization variables are non-negative
integers whereas constraint (16g) is a lower bound dk to
ensure all learners are allocated a reasonable batch size.
Note that the a lower bound of zero represents the case
where dk can take any positive value. Solutions of (16)
where τk or dk is zero for any k represents a setting where
learner k cannot participate in the learning process and MEL
may be suboptimal.

Thus, the program in 16b is a quadratically-constrained inte-
ger linear program (QCILP) which is well-known to be NP-
hard [26]. This problem can be solved numerically with in-
terior point methods using commercially available solvers.
However, in the next section, we propose an analytical-
numerical solution based on a combined relaxation and
suggest-and-improve (SAI) approach.

4 PROPOSED SOLUTION

Instead of applying the SAI technique directly on the asyn-
chronous problem in (16), we ﬁrst propose to solve the
problem by getting candidate solutions for dk and τk from
the synchronous problem in [18] by setting τk = τ ∀ k ∈ K.
In the next step, we obtain the solution to (16) by applying
the improve step using the candidate solutions as the initial
values. The reason for doing this is because a system of
K learners would produce at least
constraints. For
example, an MEL system of 100 learners will result in 4950
mutual staleness bounds. It was found that applying SAI
directly to (16) does not work but applying the suggest step
to the synchronous problem in [18] and the improve step
to our problem provides solutions that converge. In the last
step, the real values of the obtained τk’s and dk’s are ﬂoored
to get the integer values.

(cid:0)K
2

(cid:1)

The problem can be simpliﬁed by replacing τk’s with the
optimization variable τ and relaxing the integer constraints
in (16e) and (16f) as follows:

max
τ,dk ∀ k

τ

s.t.

kdk + C 0
kdk + G0

k ≤ T,
k ≤ E0
k,

kdkτ + C 1
C 2
kdkτ + G1
G2
K
(cid:88)

dk = d

k=1
τ ≥ 0
dk ≥ dl,

∀ k ∈ K

∀ k ∈ K

∀ k ∈ K

(17)

(17a)

(17b)

(17c)

(17d)

(17e)

(cid:80)K

1
K

k=1 τk = τ when τk = τ ∀ k ∈ K.
Note that
The non-negative integer (16f) constraint on dk’s has been
relaxed this and can be covered by (17e). Constraint (16f)
has been eliminated after relaxation because dl ≥ 0 in (17e).
Analytically, the matrices associated with the quadratic time
and energy constraints in (17a) and (17b), respectively, will
not be positive semi-deﬁnite due to them being sparse with
two non-negative values each, which results in them having
one positive and one negative eigenvalue.

4.2 Upper Bounds using Lagrangian Relaxation

We can re-write the equality constraint in 17c as two inequal-
ity constraints: (cid:80)K
k=1 dk − d ≤ 0 and − (cid:80)K
k=1 dk + d ≤ 0.
Hence, the relaxed problem’s Lagrangian function can be
written as:

L (x, λ, γ, α, ¯α, ω, ν) = −τ +

K
(cid:88)

λk

(cid:0)C 2

kτ dk + C 1

kdk + C 0

k − T (cid:1) +

k=1
K
(cid:88)

γk

(cid:0)G2

kτ dk + G1

kdk + G0

k − E0
k

(cid:1) +

k=1

(cid:32) K
(cid:88)

α

k=1

(cid:33)

dk − d

− ¯α

(cid:33)

dk − d

−

(cid:32) K
(cid:88)

k=1

ωτ −

K
(cid:88)

k=1

νkdk

(18)

The Lagrange multipliers associated with the global cycle
time and local energy constraints are given by λk and γk,
respectively, ∀ k ∈ {1, . . . , K}. The Lagrange multipliers
related to the two total task size constraint inequalities are
given by α/¯α, and ω/νk k ∈ {1, . . . , K} are the Lagrangian
multipliers associated with the non-negative constraints of
both sets of optimization variables τ and dk, respectively.

Let the set of optimization variables be denoted by x =
[τ d1 d2 . . . dk . . . dK]T
and the set of Lagrange multipli-
ers by Γ = [λ, γ, α, ¯α, ω, ν]T
, where λ = [λ1 . . . λk . . . λK]T ,
γ = [γ1 . . . γk . . . γK]T , and ν = [ν1 . . . νk . . . νK]T .

Theorem 1. The set of optimal Lagrange multipliers can be

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

obtained by solving the dual problem in the following semi-
deﬁnite program (SDP):

s.t.

max
Γ
(cid:20) F2 (Γ)
2 f 1 (Γ)

1

Γ (cid:60) 0

ζ

(19)

1

2 f 1 (Γ)
f0 (Γ) − ζ

(cid:21)

(cid:60) 0

Proof: The optimization variables be denoted by x
where x = [τ d1 d2 . . . dk . . . dK]T
. Then, the relaxed
program in (17) for the synchronous case can be re-written
in the form of a QCQP as shown below:

s.t.

k ≤ 0,
k ≤ 0,

xT Fx + f T x + f0
k x + p0
k x + q0

min
x
xT Pkx + pT
xT Qkx + qT
xT Ax + aT x + a0 ≤ 0
xT ¯Ax + ¯aT x + ¯a0 ≤ 0
xT Ux + UT x + u0 ≤ 0
xT Vkx + vT
k ≤ 0,

k x + v0

∀k ∈ K

∀k ∈ K

∀k ∈ K

(20a)

(20b)

(20c)

(20d)

(20e)

(20f)

(20g)

Constraints (20b) and (20c) represent the time and energy
constraints, respectively, and constraints (20d) and (20e)
represent the total batch size constraint as two inequalities.
The non-negative constraints on τ and dk are given in (20f)
and (20g), respectively. The constants associated with the
time and energy constraints can be deﬁned as p0
k − T
k = G0
and q0
k, respectively, ∀ k. The variables a0 = −d,
¯ao = d and v0

k − E0
k = dl, ∀ k whereas u0 = 0 and f0 = 0.

k = C 0

The coefﬁcients associated with the linear terms in the
objective and constraints (f and pk, qk, a, ¯a, u, and vk,
respectively) are given in (21)as column vectors.
f = (cid:2)−1 0 0 . . . C 1
pk = (cid:2)0 0 0 . . . C 1
qk = (cid:2)0 0 0 . . . G1
a = [0 1 1 . . . 1 . . . 1]T
¯a = [0 − 1 − 1 . . . − 1 . . . − 1]T
u = [−1 0 0 . . . 0 . . . 0]T
vk = [0 0 0 . . . − 1 . . . 0]T , ∀ k

k . . . 0(cid:3)T
k . . . 0(cid:3)T
k . . . 0(cid:3)T

, ∀ k

, ∀ k

(21)

The quadratic matrices associated with the time and energy
constraints, Pk and Qk, respectively, are given in (22) and
(23).

Pk(i, j) =

Qk(i, j) =




0.5C 2

k, if



0,




0.5G2

k, if



0,

i = 1 & j = k + 1
i = k + 1 & j = 1

otherwise

i = 1 & j = k + 1
i = k + 1 & j = 1

otherwise

Algorithm 1 Process at the Orchestrator
Input: T , d, dl, K
Output: w

Initialize w and set the ﬂag STOP ← FALSE

7

1: while not STOP do
2:
3:

In Parallel: Send w to each learner k ∈ K
In Parallel: Receive PkO, hkO, fk, and e0
Solve (27) to obtain ˆτ , ˆdk
Transform (16) by setting τk > 0 ∀ k ∈ K in (16e) and
removing (16f)

k from k ∈ K

4:
5:

6: Get τk and dk by applying CD to (16) using ˆτ , ˆdk
In Parallel: Send (cid:98)τk(cid:99), (cid:98)dk(cid:99) to each learner k ∈ K1
7:
In Parallel: After τk local updates, receive wk ∀ k ∈ K
8:
9: Obtain w using (3)
10:
11:
12:
13: end while
14: return w

if STOPPING CRITERIA REACHED then

Set STOP ← TRUE

end if

The remaining quadratic matrices F, A, ¯A, U and Vk are
all 0(K+1)×(K+1).
The functions F2(Γ), f 1(Γ) and f0(Γ) can now be deﬁned
as [27]:

F2(Γ) =

K
(cid:88)

λkPk + γkQk

(24)

k=1

f 1(Γ) =

K
(cid:88)

k=1

(λkpk + γkqk + νkvk) + αa + ¯α¯a + ωu (25)

f0(Γ) =

K
(cid:88)

k=1

(cid:0)λkp0

k + γkq0

k + νkv0
k

(cid:1) + αa0 + ¯α¯a0

A candidate solution to the SDP in (19) is given by:

ˆx = −

1
4

F2 (Γ)−1 f 1 (Γ)

(26)

(cid:4)

(27)

The candidate solution will be the optimal solution in case
of a convex QCQP. In the case of a non-convex QCQP,
there is an expected duality gap and an improve step is
needed. Hence, for the synchronous approach, we apply this
step to the problem in (17). For the proposed asynchronous
approach, the optimal solution can be obtained by applying
the local optimizer coordinate descent (CD) to the problem
in (16) with the relaxed constraints in (17d) and (17e) with
τk replacing τ in (17d) and the additional constraint in
(16c). The complete steps followed by the orchestrator over
multiple global cycles are summarized in Algorithm 1.

5 SIMULATION RESULTS
5.1 Simulation Environment

(22)

(23)

It is assumed that the learners comprise a combination of the
following: laptops with multi-core processors, smart phones
simple processors, advanced micro-controllers such as the
Raspberry Pi, and very simple micro-controllers such as the
Arduino. The learners are co-located within 500 meters in a
cellular type environment and may be mobile. The channel

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

8

TABLE 1
List of simulation parameters

Parameter
Cell Attenuation Model
Channel Bandwidth (W )
Device proximity (R)
Transmission Power (Pk)
Noise Power Density (N0)
Computation Capability (fk) ∼ {6.0, 2.4, 1.4, 0.7} GHz
MNIST Dataset size (d)
MNIST Dataset Features (F)

Value
128 + 37.1 log(R) dB [7]
5 MHz
500m
23 dBm
-174 dBm/Hz

60,000 images
784 ( 28 × 28 ) pixels

Fig. 4. Final validation accuracy achieved after a total of 12 global
epochs with various training times for an average device energy con-
sumption of 10J.

parameters and other specs are listed in table 1. To test
our proposed MEL paradigm, a fully-connected deep neural
network consisting of 300, 124, and 60 neurons is used to
train on the MNIST dataset [28]. For detailed descriptions on
how to obtain the model size and computational complexity,
the readers are referred to [16].

The two major additional contributions of this paper are the
study of different levels of caps on the energy consumed
per global cycle per learner k and the impact of different
values of staleness capped by c. We plot the validation
accuracy related metrics for values of staleness of up-to
c = 5, because it was found that having a higher c > 5
does offer any improvements.

As for the constraint on the local energy consumption
E0
k ∀ k ∈ K, it is possible that devices will have wildly vary-
ing consumption limits. However, to quantify the impact of
these limits, we deﬁne an average energy consumption per
global cycle across all learners E (J) and E0
k (J) in any global
cycle varies by σ0
k = E ±σkU ∀ k ∈ K where
U ∼ U(0, 1) (J). To put these numbers into perspective,
modern batteries are rated in terms of voltage (V) and
milliampere-hours (mAH). An average consumption of 20J

k (J) such that E0

1In PL, the orchestrator sends dk samples after randomly shuf-
ﬂing its dataset whereas it sends dk in FL and the learner chooses
min(dk, dmax
k

) data points where dmax

is learner k’s dataset size.

k

per global cycle for 10 cycles would imply a total consump-
tion of 200J. For a battery rated at 5V, this represents a
consumption of 11.1 mAH which for a 2000 mAH battery,
represents 0.36% of the maximum load.

In the following sub-sections, we present results for an
MEL system comprising K = 20 learners tested for global
cycle times of T = 5s to T = 40s in steps of 5 seconds
and for average energy values of E = {10, 20, 30}J with
σ0
k = 2.5 (J). The results are discussed for our proposed HA
asynchronous (HA-Asyn) scheme with PL and compared to
the HA synchronous (HA-Sync) scheme in [16] and the per-
formance that would have been achieved if the HU random
equal task allocation approach was used (HU-Sync/Asyn)
such as the one described in [12].

5.1.1 Convergence Proof

Figure 4 shows the plots for learning accuracy for the
synchronous case only where HA-Sync represents solution
obtained using the approach in [18] and HA-Asyn rep-
resents solutions to problem (17) with c set to zero. The
HU-Sync/Asyn plots represent the HU solution for both
approaches. As observable, we have conﬁrmed that our
solution in this paper converges to the synchronous case.
Moreover, for extremely low values of energy and time (10J
and 10s, respectively), the proposed approach works better
than the approach to solve the synchronous problem. Last
but not least, for the synchronous case (c = 0), the HA
scheme always works better than the HU scheme where the
HU scheme fails to converge on several occasions.

Figure 4 plots the learning accuracy progression for different
values of staleness (including the synchronous case with
c = 0) with varying values of T and E for both, the HA and
HU schemes. The purpose of these ﬁgures is to demonstrate
the importance of utilizing HA schemes, especially when
the resources are limited. Observe that the HA schemes
generally converge faster and reach a higher level of ﬁnal
validation accuracy. The plots also demonstrate the useful-
ness of having a staleness aware asynchronous scheme.

For example, as we can see from Fig. 5a that when T = 10s
and E = 10J, the HA-Asyn with c = 1 and c = 2 requires
5 global updates to reach a 94% accuracy whereas the HA-
Sync requires 7 updates, a reduction in time of 29%. Simi-
larly, 6 updates are required to achieve a 95% accuracy with
c = 1 whereas the HA-Sync needs 8 updates representing
a reduction of 25%. Because this is not clear from Fig. 5 in
general, the next subsection demonstrates these gains more
clearly using bar charts.

5.1.2 Validation Accuracy

In this part, we focus on some speciﬁc metrics such as ﬁnal
validation accuracy after a set number of global updates
or the number of updates required to reach an accuracy
threshold. These results are presented for all schemes for
the case where the devices have a low average energy
consumption of about 10J and a higher consumption of 20J
per global cycle for each learner for all global cycle times.
This study is important because less number of updates for
a given global cycle time constraint results in lower total
training time for a given time constraint.

24681012Global Update Index(a) T = 10s, E = 10J020406080100Accuracy (%)24681012Global Update Index (b) T = 10s, E = 20J20406080100Accuracy (%)24681012Global Update Index (c) T = 10s, E = 30J20406080100Accuracy (%)HA-AsynHA-SyncHU-AsynHU-Sync24681012Global Update Index (d) T = 20s, E = 10J020406080100Accuracy (%)24681012Global Update Index (a) T = 20s, E = 20J60708090100Accuracy (%)24681012Global Update Index (f) T = 20s, E = 30J60708090100Accuracy (%)JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

9

Fig. 5. Accuracy progression for the cases when T = 10s and 20s and for average energy values of E = {10, 20, 30}J.

Fig. 6. Final validation accuracy values after 6 and 12 global updates, respectively, for various training times for average energy consumption limits
E = 10J and E = 20J, respectively.

Figs. 6a and 6b present
the ﬁnal validation accuracy
achieved after a total of 6 global updates with different
total training times for the case when the average energy
consumption limit per cycle per learner E = 10J and
E = 20J, respectively. The ﬁnal validation accuracies for
those two settings after 12 global cycles is given in Fig. 6c
and Fig. 6d, respectively. The case when c = 0 implies the
HA/HU-Sync scheme and cases when c > 0 represent the
HA/HU-Asyn schemes.

Overall, it can be seen that the HA schemes provide a better
performance compared to the best performance of the HU
schemes. In most regions, the best performance is provided
by the HA-Asyn schemes. For example, in the low resource
region with T = 15 and 20s and E = 10J, after 6 global
updates the HA-Asyn with c = 1 provides a best accuracy of
94.4% and 95.4%, respectively, whereas the HA-Sync fails to
reach 94%. The HA-Asyn with c = 2 crosses 94.5% for T =
20s. For a higher energy of 20J, the HA-Asyn scheme with

24681012Global Update Index                           (a) T = 10s, E = 10J   80828486889092949698Accuracy (%)HAHUSyncc=1c=2c=3c=4c=524681012Global Update Index                           (b) T = 10s, E = 20J   80828486889092949698Accuracy (%)24681012Global Update Index                        (c) T = 10s, E = 30J80828486889092949698Accuracy (%)24681012Global Update Index                           (d) T = 20s, E = 10J   80828486889092949698Accuracy (%)24681012Global Update Index                           (e) T = 20s, E = 20J   80828486889092949698Accuracy (%)24681012Global Update Index                           (d) T = 20s, E = 30J   80828486889092949698Accuracy (%)JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

10

Fig. 7. Final validation accuracy values after 6 and 12 global updates, respectively, for various training times for average energy consumption limits
E = 10J and E = 20J, respectively.

Fig. 8. Results for an MEL system with average energy E = 30J. Final validation after (a) 6 global updates and (b) 12 global updates, and number
of global updates to reach an accuracy threshold of (a) 95.5% and (b) 97.3%.

c = 1-3 is able to provide an accuracy of 97% when T = 20s
and for c values of 2-4 for T = 35s. After 12 global cycles,
for E = 10J and T = 10s and 20s, the HA-Async schemes
with c = 1 and c = {1, 2}, respectively, are able to provide a
signiﬁcantly higher ﬁnal accuracy with a difference of more
than 0.4%. Similarly when E = 20J, for global cycle times
of T={5, , 10, 15, 20, 25}s, the HA-Asyn scheme provides
the best validation accuracy with corresponding staleness
c = {5, 2, 2, 4, 4}. with the difference ranging from 0.1-0.3%.

Fig. 7 displays these differences clearly by showing the
number of updates required to reach a 95.5% accuracy for
various global cycle times T for E = 10J (Fig. 7a) and
E = 20J (Fig. 7b). For the same settings, the number of
updates required to achieve an accuracy of 97.3% are plotted
in Figs. 7c and Fig 7d, respectively. For example, when
E = 10J and T = 10s, a ﬁnal accuracy of 95% can be
achieved in 7 global updates with HA-Asyn as opposed to
9 updates with the HA-Sync, representing a reduction of

510152025303540Global Cycle Time (s) (a) E = 10J 0246810# of global updates510152025303540Global Cycle Time (s)(b) E = 20J 0246810# of global updates510152025303540Global Cycle Time (s)(c) E = 10J 051015# of global updatesSyncc = 1c = 2c = 3c = 4c = 5510152025303540Global Cycle Time (s)(d) E = 20J 02468101214# of global updates22.2%22.2%16.7%20%20%25%12.5%11.1%10%8.3%9.1%LegendJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

22.2%. This means that the MEL system needs to train for
20s less to reach the same accuracy. Similarly, after 12 global
update cycles, an MEL system with E = 10J can reach an
accuracy of 97.3% with HA-Asyn (c = 1, 2, 3) whereas the
HA-Sync cannot reach that level of accuracy. Moreover, for
T = 25s, the HA-Asyn (c = 3, 4) can 97.3% in 10 updates as
compared to 11, representing a reduction of 9.1% or 25s.

change Fig. 8 presents the results for the high energy region
of E = 30J. Figs. 8a and 8b show the ﬁnal validation
accuracy achieved by the HA

5.2 Discussions

Despite these gains, it can be seen that in some situations,
the HA-Sync approach provides the best results. For exam-
ple, when T = 25s and E = 20J, the least time to reach an
accuracy of 97.2% is by the HA-Sync scheme. It also reaches
an accuracy of 95.5% and 97% with the same number of
updates for values T in the range 25 − 35s for E = 10J
and 20J. Moreover, the best ﬁnal validation accuracy after
12 global cycles is provided by HA-Sync for E = 10J when
T = 30s and also for E = 20J when T = 30s and T = 40s.

Although it is difﬁcult to see a concrete trend, we may
conclude that the HA-Asyn works best when the resources
are at their lowest and the synchronous approach may fail,
It can also provide gains when one resource is low and
the other high, especially, when energy is abundant and
time is low. This works for the scenarios where FL has
been proposed for devices that are charging and not on
battery power. In the medium range of both resources, time
and energy, the HA-Sync works best but this not typical of
the edge environment. When both resources are abundant,
also not typical but may happen for example, if the main
objective is privacy and not minimal delay, where learning
takes place on devices that are charging.

To conclude, we suggest the following two-step process to
select the best scheme out of the HA-Sync and HA-Asyn:

1)

2)

If either resource, time or energy is low, choose
the HA-Asyn approach. If both resources are in the
medium range, then go for the HA-Sync. If both
resources are high, choose the HA-Asyn approach.
If the HA-Sync is chosen, simply do cross-validation
on the ML model and associated hyper-parameters
such as model size, learning rate, regularization, etc.
On the other hand, when HA-Asyn is used, the
parameter c should be added to the cross-validation.
In the very low resource region, checking with c = 1
c = 2 may sufﬁce whereas in case when one or more
of the resources are abundant, a set from the range
c ≥ 3 may be used.

6 CONCLUSION

This paper extends the research efforts towards establishing
the novel MEL paradigm by proposing a HA asynchronous
(HA-Asyn) approach. It was shown that for an MEL sys-
tem with learners performing an asynchronous number of
updates, maximizing the average number of updates while
controlling the maximum mutual staleness can improve

11

accuracy. A two-step solution based on the SAI method
was designed and through extensive simulations using the
well-known MNIST dataset, it was shown that the proposed
HA-Asyn scheme provides better validation accuracy and
a faster progression than the HU scheme and for many
scenarios, provides a better performance than the HA-Sync
scheme with gains of up-to 25%. Finally, strategies were
proposed to select between the HA-Sync and HA-Asyn
schemes with recommendations on cap the staleness.

REFERENCES

[1] K. Gyarmathy, “Comprehensive Guide to IoT Statistics You
[Online]. Available: https:

Need to Know in 2020,” 2020.
//www.vxchnge.com/blog/iot-statistics

[2] M. Chiang and T. Zhang, “Fog and IoT: An Overview
of Research Opportunities,” IEEE Internet of Things Journal,
vol. 3, no. 6, pp. 854–864, dec 2016.
[Online]. Available:
http://ieeexplore.ieee.org/document/7498684/

[3] Rhea

Kelly,

“Internet

To
Top
[Online].
Available: https://campustechnology.com/articles/2015/04/15/
internet-of-things-data-to-top-1-6-zettabytes-by-2020.aspx

Zettabytes

Things

2020,”

2015.

Data

1.6

by

of

[4] Y. Mao, C. You, J. Zhang, K. Huang, and K. B. Letaief, “A Survey
on Mobile Edge Computing: The Communication Perspective,”
IEEE Communications Surveys & Tutorials, vol. 19, no. 4, pp. 2322–
2358, 2017. [Online]. Available: http://arxiv.org/abs/1701.01090

[5] C. You and K. Huang, “Exploiting Non-Causal CPU-State
Information for Energy-Efﬁcient Mobile Cooperative Computing,”
IEEE Transactions on Wireless Communications, vol. 17, no. 6, pp.
4104 – 4117, 2019. [Online]. Available: https://ieeexplore.ieee.
org/document/8330749https://arxiv.org/abs/1704.04595

[6] M. Liu and Y. Liu, “Price-Based Distributed Ofﬂoading for Mobile-
Edge Computing with Computation Capacity Constraints,” IEEE
Wireless Communications Letters, pp. 1–4, 2017.

[7] U. Y. Mohammad and S. Sorour, “Multi-Objective Resource
Optimization for Hierarchical Mobile Edge Computing,” in
2018 IEEE Global Communications Conference: Mobile and Wireless
(Globecom2018 MWN), Abu Dhabi, United Arab
Networks
Emirates, dec
[Online]. Available: https:
//ieeexplore.ieee.org/document/8648109

2018, pp.

1–6.

[8]

J. Dean, G. S. Corrado, R. Monga, K. Chen, M. Devin, Q. V.
Le, M. Z. Mao, M. A. Ranzato, A. Senior, P. Tucker, K. Yang,
and A. Y. Ng, “Large Scale Distributed Deep Networks,” in
Advances in Neural Information Processing Systems 25, 2012, pp.
[Online]. Available: https://papers.nips.cc/paper/
1223–1231.
4687-large-scale-distributed-deep-networks

[9] Z. Wei, S. Gupta, X. Lian, and J. Liu, “Staleness-Aware Async-SGD
for distributed deep learning,” IJCAI International Joint Conference
on Artiﬁcial Intelligence, vol. 2016-Janua, pp. 2350–2356, 2016.

[10] Y. You, J. Demmel, K. Czechowski, L. Song, and R. Vuduc,
“Design and Implementation of a Communication-Optimal
Classiﬁer for Distributed Kernel Support Vector Machines,”
IEEE Transactions on Parallel and Distributed Systems, vol. 28,
[Online]. Available: http:
no. 4, pp. 974–988, apr 2017.
//ieeexplore.ieee.org/document/7565530/

[11] M. Langer, A. Hall, Z. He, and W. Rahayu, “MPCA SGD-A
Method for Distributed Training of Deep Learning Models on
Spark,” IEEE Transactions on Parallel and Distributed Systems,
vol. 29, no. 11, pp. 2540–2556, nov 2018. [Online]. Available:
https://ieeexplore.ieee.org/document/8354695/

[12] S. Wang, T. Tuor, T. Salonidis, K. K. Leung, C. Makaya,
T. He, and K. Chan, “Adaptive Federated Learning in Resource
Constrained Edge Computing Systems,” IEEE Journal on Selected
Areas in Communications, no. Early Access, pp. 1–1, 2019. [Online].
Available: https://ieeexplore.ieee.org/document/8664630/

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

12

[13] ——,

“When Edge Meets Learning : Adaptive Control
for Resource-Constrained Distributed Machine Learning,” in
INFOCOM, 2018. [Online]. Available: https://ieeexplore.ieee.org/
document/8486403

[14] T. Tuor, S. Wang, T. Salonidis, B. J. Ko, and K. K. Leung, “Demo
abstract: Distributed machine learning at resource-limited edge
nodes,” INFOCOM 2018 - IEEE Conference on Computer Commu-
nications Workshops, pp. 1–2, 2018.

[15] D. Conway-Jones, T. Tuor, S. Wang, and K. K. Leung, “Demonstra-
tion of Federated Learning in a Resource-Constrained Networked
Environment,” in 2019 IEEE International Conference on Smart Com-
puting (SMARTCOMP), 2019.

[16] U. Mohammad and S. Sorour, “Adaptive Task Allocation for
Mobile Edge Learning,” in 2019 IEEE Wireless Communications and
Networking Conference Workshop (WCNCW).
IEEE, apr 2019, pp.
1–6. [Online]. Available: https://ieeexplore.ieee.org/document/
8902527/

[17] ——, “Adaptive Task Allocation for Asynchronous Federated
and Parallelized Mobile Edge Learning,” arXiv preprint, p.
arXiv:1905.01656, may 2020. [Online]. Available: https://arxiv.
org/abs/1905.01656

[18] Umair Mohammad, S. Sorour, and M. S. Hefeida, “Task Allocation
for Mobile Federated and Ofﬂoaded Learning with Energy and
Delay Constraints,” in IEEE ICC 2020 Workshop on Edge Machine
Learning for 5G Mobile Networks and Beyond (IEEE ICC’20 Workshop
- EML5G), Dublin, Ireland, jun 2020, pp. 1–6.

[19] M. Chen, Z. Yang, W. Saad, C. Yin, H. V. Poor, and
S. Cui, “A Joint Learning and Communications Framework
for Federated Learning over Wireless Networks,” arXiv e-
prints, p. arXiv:1909.07972,
[Online]. Available:
https://arxiv.org/abs/1909.07972

sep 2019.

[20] Z. Yang, M. Chen, W. Saad, C. S. Hong, and M. Shikh-
Bahaei, “Energy Efﬁcient Federated Learning Over Wireless
Communication Networks,” arXiv e-prints, p. arXiv:1911.02417,
nov 2019. [Online]. Available: https://arxiv.org/abs/1911.02417v1

[21] C. Xie, O. Koyejo, and I. Gupta, “Asynchronous Federated
Optimization,” 2019. [Online]. Available: https://arxiv.org/abs/
1903.03934

[22] R. R. Karn, P. Kudva, and I. A. M. Elfadel, “Dynamic Autoselection
and Autotuning of Machine Learning Models for Cloud Network
Analytics,” IEEE Transactions on Parallel and Distributed Systems,
vol. 30, no. 5, pp. 1052–1064, may 2019. [Online]. Available:
https://ieeexplore.ieee.org/document/8500348/

[23] J. Dass, V. Sarin, and R. N. Mahapatra, “Fast and Communication-
Efﬁcient Algorithm for Distributed Support Vector Machine
Training,” IEEE Transactions on Parallel and Distributed Systems,
vol. 30, no. 5, pp. 1065–1076, may 2019. [Online]. Available:
https://ieeexplore.ieee.org/document/8526323/

[24] S. Teerapittayanon, B. McDanel, and H. T. Kung, “Distributed
Deep Neural Networks over the Cloud, the Edge and End De-
vices,” Proceedings - International Conference on Distributed Comput-
ing Systems, pp. 328–339, 2017.

[25] Q. Jia, L. Guo, Z. Jin, and Y. Fang, “Preserving Model Privacy for
Machine Learning in Distributed Systems,” IEEE Transactions on
Parallel and Distributed Systems, vol. 29, no. 8, pp. 1808–1822, aug
2018. [Online]. Available: https://ieeexplore.ieee.org/document/
8302601/

[26] A. D. Pia, S. S. Dey, and M. Molinaro, “Mixed-integer Quadratic
Programming is in NP,” Mathematical Programming, vol. 162, no. 1,
pp. 225–240, 2017.

[27] J. Park and S. Boyd, “General Heuristics for Nonconvex
Quadratically Constrained Quadratic Programming,” arXiv e-
prints, mar 2017. [Online]. Available: http://arxiv.org/abs/1703.
07870

[28] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based
Learning Applied to Document Recognition,” Proceedings of IEEE,
[Online]. Available:
vol. 86, no. 11, pp. 2278 – 2324, 1998.
https://ieeexplore.ieee.org/document/726791

Umair Mohammad (S ’12) Umair Mohammad
received his Bachelor’s degree in Electrical En-
gineering and Master’s degree in Telecommu-
nication Engineering from the King Fahd Uni-
versity of Petroleum and Minerals (KFUPM) in
2013 and 2016, respectively. Currently, Umair is
a PhD candidate in the department of Electrical
and Computer Engineering at the University of
Idaho (UI) and a research assistant (RA) for the
National Institute for Advanced Transportation
Technology (NIATT). Umair’s areas of interest
include wireless communication, edge computing, machine learning
(ML) and distributed ML for wireless edge networks.

Sameh Sorour (S ’98, M ’11, SM’16) is an Assis-
tant Professor at University of Idaho, USA. He re-
ceived his B.Sc. and M.Sc. degrees from Alexan-
dria University in 2002 and 2006, respectively,
and his PhD from University of Toronto in 2011.
His PhD thesis was nominated for the Governor
General’s Gold Medal Award. After his gradua-
tion, he held a MITACS industrial postdoctoral
fellowship with Siradel Canada and University of
Toronto. Prior to moving to University of Idaho
in 2016, he held another postdoctoral fellowship
at King Abdullah University of Science and Technology (KAUST), and
an assistant professor position at King Fahd University of Petroleum
and Minerals (KFUPM). During his PhD and postdoctoral fellowships,
he led several research projects with industrial partners and govern-
ment agencies, such as LG Korea, the European Space Agency, the
Canadian National Institute for the Blind (CNIB), and Siradel France.
Dr. Sorour is currently a senior IEEE member and an Editor for IEEE
Communications Letters. His research and educational
interests lie
in the broad areas of advanced computing, learning, and networking
technologies for cyber-physical and autonomous systems. Topics of par-
ticular interest include cloud/edge/IoT networking, computing, learning,
and their applications in multimodal/coordinated autonomous driving,
autonomous/electric mobility on demand systems, layered/virtualized
management of future transportation networks, cyber-physical systems,
and smart energy and healthcare systems.

Mohamed Hefeida is a clinical assistant profes-
sor with the ECE department at the University
of Idaho. He received his doctorate in electrical
and computer engineering from the University of
Illinois at Chicago in 2013, where he also worked
as a visiting assistant professor for one year. Be-
fore joining the ECE department at the University
of Idaho, Dr. Hefeida was an assistant professor
of electrical engineering at the American Univer-
sity of the Middle East in Kuwait. His research
interests span a wide spectrum of networking
and communication techniques, with particular interest in Wireless Sen-
sor Networks, Internet of Things (IoT), Cross-Layer Design, and Data
Management.

