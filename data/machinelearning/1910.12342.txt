9
1
0
2

t
c
O
9
2

]

C
O
.
h
t
a
m

[

2
v
2
4
3
2
1
.
0
1
9
1
:
v
i
X
r
a

Minimizing a Sum of Clipped Convex Functions

Shane Barratt

Guillermo Angeris

Stephen Boyd

October 31, 2019

Abstract

We consider the problem of minimizing a sum of clipped convex functions; ap-
plications include clipped empirical risk minimization and clipped control. While the
problem of minimizing the sum of clipped convex functions is NP-hard, we present some
heuristics for approximately solving instances of these problems. These heuristics can
be used to ﬁnd good, if not global, solutions and appear to work well in practice.
We also describe an alternative formulation, based on the perspective transformation,
which makes the problem amenable to mixed-integer convex programming and yields
computationally tractable lower bounds. We illustrate one of our heuristic methods by
applying it to various examples and use the perspective transformation to certify that
the solutions are relatively close to the global optimum. This paper is accompanied by
an open-source implementation.

1

Introduction

Suppose f : Rn
}
as a clipped convex function. In this paper we consider the problem of minimizing a sum of
clipped convex functions,

R. We refer to the function min

R is a convex function, and α

f (x), α
{

→

∈

minimize f0(x) + (cid:80)m

fi(x), αi
i=1 min
{
and fi : Rn

+

}

,

∈

Rn, where f0 : Rn

R for i = 1, . . . , m
with variable x
R
→
R for i = 1, . . . , m. We use inﬁnite values
are closed proper convex functions, and αi
we let
for a closed convex set
of f0 to encode constraints on x, i.e., to constrain x
f0(x) = +
. When fi(x) > αi, the value of the ith term in the sum is clipped
to αi, which limits how large each term in the objective can be. Many practical problems
can be formulated as instances of (1); we describe a few in

∪ {
∈

for all x

∈ X

(cid:54)∈ X

∞}

→

∞

2.

X

§

(1)

NP-hardness.
In general, problem (1) is nonconvex and as a result can be very diﬃcult
to solve. Indeed, (1) is NP-hard. We show this by giving a reduction of the subset sum
problem to an instance of (1).

1

 
 
 
 
 
 
The subset sum problem involves determining whether or not there exists a subset of a

given set of integers a1, . . . , an that sum to zero. The optimal value of the problem

minimize

(aT x)2

subject to 1T x

≥

−
1,

n/4 + (cid:80)n

i=1 min
{

x2
i , 1/4
}

+ min

(xi
{

−

1)2, 1/4
}

, at least one of xi = 1, and aT x = 0;
0, 1
which has the form (1), is zero if and only if xi
}
in other words, the set
sums to zero. Since the subset sum problem can be
reduced to an instance of (1), we conclude that in general our problem is at least as hard as
diﬃcult problems like the subset sum problem.

xi = 1

∈ {

ai

{

}

|

Global solution. There is a simple (exhaustive) method to solve (1) globally: for each
subset Ω of

, we solve the convex problem

1, . . . , m
{

}

minimize

f0(x) + (cid:80)

subject to fi(x)

≤

αi,

∈

i∈Ω fi(x) + (cid:80)
Ω,

i

i(cid:54)∈Ω αi

(2)

Rn. The solution to (2) with the lowest optimal value is the solution
with variable x
to (1). This general method is not practical unless m is quite small, since it requires the
solution of 2m convex optimization problems.

∈

In some speciﬁc instances of problem (1), we can cut down the search space if we know

that a speciﬁc choice of Ω

1, . . . , m

implies

⊆ {

}
fi(x)

x
{

|

αi, i

Ω
}

∈

=

,

∅

≤

which means that the optimal value of (2) is +
. In this case, we do not have to solve
problem (2) for this choice of Ω, as we know it will be infeasible. One simple example where
this happens is when the αi-sublevel sets of fi are pairwise disjoint, which implies that we
only have to solve m convex problems (as opposed to 2m) to ﬁnd the global solution. This
idea is used in [11] to guide their proposed search algorithm.

∞

Related work. The general problem of minimizing a sum of clipped convex functions was
recently considered in [11]. In their paper, they also show that the problem is NP-hard via
a reduction to 3-SAT and give a global solution method in a few special cases whenever n is
small. They also provide a heuristic method based on cyclic coordinate descent, leveraging
the fact that one-dimensional problems are easy to solve.

The idea of using clipped convex functions has appeared in multiple application areas,
the most prominent being statistics. For example, the sum of clipped absolute values (often
referred to as the capped (cid:96)1-norm) has been used as a sparsity-inducing regularizer [25, 26, 13].
In particular, [25, 13] make use of the fact that problem (1) can be written as a diﬀerence-of-
convex (DC) problem and can be approximately minimized via the convex-concave procedure
[10] (see Appendix A). The clipped square function (also known as the skipped-mean loss) was

2

also used in [21] to estimate view relations, and in [14] to perform robust image restoration.
Similar approaches have been taken for clipped loss functions, where they have been used for
robust feature selection [9], regression [23, 17], classiﬁcation [19, 16, 22], and robust principal
component analysis [18].

§

Summary. We begin by presenting some applications of minimizing a sum of clipped
2 to empirical risk minimization and control. We then provide some
convex functions in
3, which we have found to work well in
simple heuristics for approximately solving (1) in
practice. In
4, we describe a method for converting (1) into a mixed-integer convex program,
which is amenable to solvers for mixed-integer convex programs. Finally, we describe an
5 and apply our
open-source Python implementation of the ideas described in this paper in
implementation to a few illustrative examples in

6.

§

§

§

§

2 Applications

In this section we describe some possible applications of minimizing a sum of clipped convex
functions.

2.1 Clipped empirical risk minimization

Suppose we have data

x1, . . . , xN

Rn,

y1, . . . , yN

.

∈ Y

∈

Here xi is the ith feature vector, yi is its corresponding output (or label), and
space.

is the output

Y

We ﬁnd parameters θ
minimization (ERM) problem

∈

Rn of a linear model given the data by solving the empirical risk

minimize

1
N

(cid:80)N

i=1 l(xT

i θ, yi) + r(θ),

(3)

R is the loss function, and r : Rn

with variable θ, where l : R
R is the regularization
function. Here the objective is composed of two parts: the loss function, which measures the
accuracy of the predictions, and the regularization function, which measures the complexity
of θ. We assume that l is convex in its ﬁrst argument and that r is convex, so the problem (3)
is a convex optimization problem.

×Y →

→

For a given x

∈

Rn, our prediction of y is

ˆy = argmin

l(xT θ(cid:63), y),

y∈Y

where θ(cid:63) is optimal for (3). For example, in linear regression,
ˆy = xT θ(cid:63); in logistic regression,
where sign(z) is equal to 1 if z

=
{−
0 and

1 otherwise.

1, 1
}

w)2, and
, l(z, w) = log(1 + e−wz), and ˆy = sign(xT θ(cid:63)),

= R, l(z, w) = (z

−

Y

Y
≥

−

3

While ERM often works well in practice, it can perform poorly when there are outliers
R,

in the data. One way of ﬁxing this is to clip the loss for each data point to a value α
leading to the clipped ERM problem,

∈

minimize

1
N

(cid:80)N

l(xT
i=1 min
{

i θ, yi), α

+ r(θ).

}

(4)

i θ(cid:63), yi)

After solving (or approximately solving) the clipped problem, we can label data points (xi, yi)
where l(xT
α as outliers. The clipped ERM problem is an instance of what is referred
4.8], since the derivative of the clipped
to in statistics as a redescending M-estimator [8,
loss goes to 0 as the magnitude of its input goes to inﬁnity. In this terminology, the clip
value α is referred to as the minimum rejection point.

≥

§

In

6.1, we show an example where the normal empirical risk minimization problem fails,

§

while its clipped variant has good performance.

2.2 Clipped control

Suppose we have a linear system with dynamics given by

xt+1 = Axt + But,

t = 0, . . . , T

1,

−

where xt
time period t. The dynamics matrix A

Rn is the state of the system and ut

∈

We are given stage cost functions gt : Rn

Rn×n and the input matrix B

Rp denotes the input to the system, at
Rn×m are given.
Rn. The

R, and an initial state xinit

∈

∈

∈

Rp

×

→

∈

standard optimal control problem is

minimize (cid:80)T

t=0 gt(xt, ut)

subject to xt+1 = Atxt + Btut,

t = 0, . . . , T

1,

−

xt

t,

∈ X
x0 = xinit,

ut

t,

∈ U

t = 0, . . . , T,

Rm is the convex
Rn is the convex set of allowable states and
where, at time t,
set of allowable inputs. The variables in this problem are the states and inputs, xt and ut. If
the stage cost function gt are convex, the optimal control problem is a convex optimization
problem.

t
X

⊆

⊆

U

t

We deﬁne a clipped optimal control problem as an optimal control problem in which the

stage costs can be expressed as sums of clipped convex functions, i.e.,

gt(x, u) = g0

t (x, u) +

K
(cid:88)

min
{

t(x, u), αi
gi
,
t}

i=1
t : Rn
where, for all t and i = 1, . . . , K, the functions gi
This gives another instance of our general problem (1).

Rm

×

→

R are convex and αi

t ∈

R.

A simple but practical example of a clipped control problem is described in

6.3. The
problem is to design a lane change trajectory for a vehicle; the stage cost is small when the
vehicle is centered in either lane, which we express as a sum of two clipped convex functions.

§

4

3 Heuristic methods

There are many methods for approximately solving (1). In this section we describe a few
heuristic methods that we have observed to work well in practice.

Bi-convex formulation. Throughout this section, we will make use of a simple reformu-
lation of (1) as the bi-convex problem

minimize L(x, λ) = f0(x) + (cid:80)m

i=1 λifi(x) + (1

λi)αi

−

(5)

subject to 0

λ

1,

with variables λ
in [23,

∈

Rm and x

∈

§

3].) The equivalence follows immediately from the fact that

≤

≤
Rn. (We note that this reformulation was also pointed out

a, b
min
}
{

= min
0≤λ≤1

(λa + (1

λ)b) .

−

Nonlinear programming. When fi are all smooth functions and dom f0 is representable
as the sublevel set of a smooth function, it is possible to use general nonlinear solvers to
(approximately) solve (5).

Alternating minimization. Another possibility is to perform alternating minimization
on (5), since each respective minimization is a convex optimization problem. In alternating
minimization, at iteration k, we solve (5) while ﬁxing λ = λk−1, resulting in xk. We then
solve (5) while ﬁxing x = xk, resulting in λk. It can be shown that

(λk)i =

(cid:40)

1 fi(xk)
αi
0 otherwise,

≤

(6)

is a solution for minimization over λ with ﬁxed x = xk.

Inexact alternating minimization. Although alternating minimization often works well,
we have found that inexact minimization over λ works better in practice. Instead of fully
minimizing over λ, we instead compute the gradient of the objective with respect to λ,

gi = (

λL(xk, λ))i = fi(xk)

∇

αi.

−

We then perform a signed projected gradient step on λ with a ﬁxed step size β > 0 (we have
found β = 0.1 works well in practice, though a range of values all appear to work equally as
well). This results in the update

λk = Π[0,1]m(λk

βsign(g)),

−

5

where sign is applied elementwise to g, and Π[0,1]m denotes the projection onto the unit box,
given by

(Π[0,1]m(z))i =






1
zi
0

≥

zi
1,
0 < zi < 1,
otherwise.

The ﬁnal algorithm is described below.

Algorithm 3.1 Inexact alternating minimization.

given initial λ0 = (1/2)1, step size β = 0.1, and tolerance (cid:15) > 0.
for k = 1, . . . , niter

1. Minimize over x. Set xk to the solution of the problem
minimize f0(x) + (cid:80)m
2. Compute the gradient. Set gi = fi(xk)
2. Update λ. Set λk = Π[0,1]m(λk−1
3. Check stopping criterion. Terminate if

−
βsign(g)).
λk

i=1 λk−1
i
αi.

fi(x) + (1

λk−1

−

−

(cid:107)

−

(cid:15).

1

(cid:107)

≤

end for

λk−1
i

)αi.

Algorithm 3.1 is a descent algorithm in the sense that the objective function of (5) decreases
after every iteration. It is also guaranteed to terminate in a ﬁnite amount of time, since
there is a ﬁnite number of possible values of λ. We also note that alternating minimization
can be thought of as a special case of algorithm 3.1 where β
1. In practice, we have found
that algorithm 3.1 often ﬁnds the global optimum in simple problems and appears to work
well on more complicated cases. We use algorithm 3.1 in our generic cvxpy implementation
(see

5).

≥

§

4 Perspective formulation

In this section we describe the perspective formulation of (1). The perspective formulation
is a mixed-integer convex program (MICP), for which specialized solvers with reasonable
practical performance exist. The perspective formulation can also be used to compute a
lower bound on the original objective by relaxing the integral constraints, as in [12], as well
to obtain good initializations for any of the procedures described in

3.

§

Perspective. Following [15,
convex function f with 0

8], we deﬁne the perspective (or recession) of the closed

∈

§
dom f as1



f p(x, t) =

tf (x/t)
limγ↓0 γf0(x/γ)
+



t > 0,
t = 0,
otherwise,

(7)

∞

1If 0
details.

(cid:54)∈

dom f , replace γf0(x/γ) with γf0(y + x/γ) for any y

dom f . See [15, Thm. 8.3] for more

∈

6

for (x, t)

Rn

×

∈

R+. We will use the fact that the resulting function f p is convex [3,

3.2.6].

§

Superlinearity assumption.

If f is superlinear, i.e., if for all x

Rn

∈

, we have
0
}

\ {

then

lim
t→∞

f (tx)
t

= +

,
∞

f p(x, t) =






tf (x/t)
0
+

∞

t > 0
t = 0, x = 0,
otherwise,

(8)

(9)

since the limit in (7) is equal to the limit in (8) unless x = 0.

There are many convex functions that satisfy this superlinearity property. Some examples
are the sum of squares function and the indicator function of a compact convex set. Since
we will make heavy use of property (9) in this section, we will assume that f0 is superlinear
for the remainder of this section. If f0 is not superlinear, then it can be made superlinear
by adding, e.g., a small positive multiple of the sum of squares function.

Conic representation of the perspective. We note that representing the epigraph of
the perspective of a function is often simple if the function has a conic representation [6].
More speciﬁcally, if f has a conic representation

f (x)

v

≤

⇐⇒

Ax + bv + c

,

∈ K

for some closed convex cone

, then the perspective of f has a conic representation given by

K
f p(x, t)

v

≤

⇐⇒

Ax + bv + tc

.

∈ K

This fact allows us to use a conic representation of the perspective and avoid issues of
non-diﬀerentiability and division-by-zero that we might encounter with direct numerical
implementations of the perspective [12,

2].

§

Perspective formulation. We deﬁne the perspective formulation of (1) as the following
MICP:

i (zi, ti) + (1

ti)αi + 1

m (f p

0 (zi, ti) + f p

0 (x

−

zi, 1

ti))

−

−

(10)

minimize (cid:80)m

subject to t

i=1 f p
m,
0, 1
}

with variables x, zi
the functions f p
i

∈

for i = 0, . . . , m can be used to solve (10).

∈

∈ {
Rn for i = 1, . . . , m and t

Rm. Any MICP solver that can handle

7

Proof of equivalence. To show that (10) is equivalent to the original problem (1), ﬁrst
take (x, t, zi) that are feasible for (10). Since t is Boolean, for each i we have ti = 0 or ti = 1.
Since f p
0 (zi, ti) must be ﬁnite (as this point is feasible), then ti = 0 implies that zi = 0 (due
to (9)). Similarly, when ti = 1 we must have zi = x. Therefore the ith term in the sum
becomes

tifi(x) + (1

ti)αi +

−

1
m

f0(x).

Summing over the index i yields that problem (10) is equivalent to

minimize

subject to t

f0(x) + (cid:80)m
i=1 tifi(x) + (1
m.

0, 1
}

∈ {

ti)αi

−

(11)

Partially minimizing (11) over t, we ﬁnd that x is a feasible point for (1) with the same
objective value.

Now take x feasible for (1). Let
(cid:40)

ti =

1 fi(x)
αi
0 otherwise,

≤

i = 1, . . . , m,

and zi = tix. Then (x, t, zi) is feasible for (10) and has the same objective value, and the
problems are equivalent.

Lower bound via relaxation. Since the perspective formulation is equivalent to the
original problem, relaxing the Boolean constraint in (10) and solving the resulting convex
optimization problem

minimize (cid:80)m

subject to 0

i=1 f p
t

≤

≤

1,

i (zi, ti) + (1

ti)αi + 1

m (f p

0 (zi, ti) + f p

0 (x

−

zi, 1

ti))

−

−

(12)

with variables zi, t, and x, yields a lower bound on the objective value of (1). That is, given
any approximate solution of (1) with objective value p, the optimal value q(cid:63) of (12) yields
q(cid:63).
a certiﬁcate guaranteeing that the approximate solution is suboptimal by at most p
Additionally, a solution of the relaxed problem can be used as an initial point for any of the
heuristic methods described in

−

3.

§

Eﬃciently solving the relaxed problem. We note that (12) has m + 1 times as many
variables as the original problem, so it is worth considering faster solution methods. To do
so, we can convert the problem to consensus form [2,
7.1]; i.e., we introduce additional
Rn for i = 1, . . . , m, and constrain yi = x, resulting in the equivalent problem
variables yi

§

∈

minimize (cid:80)m

i=1 f p
subject to yi = x,

i (zi, ti) + (1

−
i = 1, . . . , m,

ti)αi + 1

m (f p

0 (zi, ti) + f p

0 (yi

zi, 1

ti))

−

−

(13)

0

t

≤

≤

1.

8

Since the objective is separable in (yi, zi, ti) over i, there exist many eﬃcient distributed
algorithms for solving this problem, e.g., the alternating direction method of multipliers
(ADMM) [2, 5, 4].

5

Implementation

Our Python package sccf approximately solves generic problems of the form (1) provided
all fi can be represented as valid cvxpy expressions and constraints. It is available at:

https://www.github.com/cvxgrp/sccf.

We provide a method sccf.minimum, which can be applied to a cvxpy Expression and a
scalar to create a sccf.MinExpression. The user then forms an objective as a sum of
sccf.MinExpressions, passes this objective and (possibly) constraints to a sccf.Problem
object, and then calls the solve method, which implements algorithm 3.1. We take advan-
tage of the fact that the only parameter changing between problems is λ by caching the
canonicalization procedure [1]. Here is an example of using sccf to solve a clipped least
squares problem:

import cvxpy as cp
import sccf

A, b = get_data(m, n)

x = cp.Variable(n)
objective = 0.0
for i in range(m):

objective += sccf.minimum(cp.square(A[i]@x-b[i]), 1.0)

objective += 0.01 * cp.sum_squares(x)

prob = sccf.Problem(objective)
prob.solve()

6 Examples

All experiments were conducted on a single core of an Intel i7-8700K CPU clocked at 3.7
GHz.

6.1 Clipped regression

In this example we compare clipped regression (
2.1) with standard linear regression and
§
Huber regression [7] (a well known technique for robust regression) on a one-dimensional

9

Figure 1: Clipped regression, linear regression, and Huber regression on a one-dimensional
dataset with outliers. The outliers aﬀect the linear regression and Huber regression models,
while the clipped regression model appears to be minimally aﬀected.

dataset with outliers. We generated data by sampling 20 data points (xi, yi) according to

xi

∼ N

(0, 1),

yi = xi + (0.1)zi,

zi

(0, 1),

i = 1, . . . , 20.

∼ N

We introduced outliers in our data by ﬂipping the sign of yi for 5 random data points.

The problems all have the form

minimize L(θ) = (cid:80)20

i=1 φ(xiθ

yi) + (0.2)θ2,

−

where φ : R
regression, φ(z) = z2. In Huber regression,

→

R is a penalty function. In clipped regression, φ(z) = min

(14)

z2, 0.5
. In linear
}

{

φ(z) =

(cid:40)

z2
z
0.5(2
|

| −

z
|
0.5) otherwise.

| ≤

0.5

Let θclip be the clipped regression model; we deem points where (xiθclip

0.5 as
outliers and the remaining points as inliers. In ﬁgure 1 we visualize the data points and the
resulting models along with the outliers/inliers identiﬁed by the clipped regression model. In
this ﬁgure, the clipped regression model clearly outperforms the linear and Huber regression
models since it is able to fully ignore the outliers. Algorithm 3.1 terminated in 0.13 seconds
and took 8 iterations on this instance.

yi)2

−

≥

Lower bound. The relaxed version of the perspective formulation (12) can be used to
eﬃciently ﬁnd a lower bound on the objective value for the clipped version of (14). The
objective value of (14) for clipped regression was 1.147, while the lower bound we calculated
was 0.533, meaning our approximate solution is suboptimal by at most 0.614.

10

−3−2−10123x−3−2−10123yclippedlstsqhuberoutlierinlierFigure 2: The clipped regression loss and its perspective relaxation.

In ﬁgure 2 we plot the clipped objective (14) for various values of θ; note that the function
is highly nonconvex and that θclip is the (global) solution. We also plot the objective of the
perspective relaxation as a function of θ, found by partially minimizing (12) over zi and t;
note that the function is convex and a surprisingly good approximation of the true convex
envelope. We note that the minimum of the perspective relaxation and the true minimum
are surprisingly close, leading us to believe that the solution to the perspective relaxation
could be a good initialization for heuristic methods.

6.2 Clipped logistic regression

2.1) to a dataset with outliers. We
In this example we apply clipped logistic regression (
§
generated data by sampling 1000 data points (xi, yi) from a mixture of two Gaussian distri-
butions in R5. We randomly partitioned the data into 100 training data points and 900 test
data points and introduced outliers by ﬂipping the sign of yi for 20 random training data
points.

We (approximately) solved the clipped logistic regression problem

(cid:80)1000

1
1000

minimize

θ
+ (0.1)
(cid:107)
[10−1, 101]. We also solved the problem
, i.e., the standard logistic regression problem. Over the α values we tried, on

with variables θ and b, for various values of α
for α = +
average, algorithm 3.1 took 6.37 seconds and terminated in 9.64 iterations.

log(1 + e−yi(xT
i=1 min
{

i θ+b)), α

2
2,
(cid:107)

∞

∈

}

11

−4−2024θ01234567L(θ)perspectivelowerboundθclipFigure 3: Test accuracy of clipped logistic regression (solid), test accuracy of standard logistic
regression (gray), and fraction of outliers (dotted dashed) for varying clip values α. Note
that the fraction of detected outliers goes down as α goes up. Between roughly α = 10−.5
and α = 100.05, the test accuracy of clipped logistic regression is higher than standard logistic
.
regression. Clipped logistic regression converges to standard logistic regression as α
→ ∞

Figure 4: A plot of λ throughout the course of algorithm 3.1 for the clipped logistic regression
example. Note that at some of the iterations (e.g., k = 1, 2, or 3), the gradient of the loss
with respect to a certain λi changes sign, causing λi to be updated in the opposite direction.

12

10−1100101α0.500.520.540.560.580.60testaccuracystandardclippedoutliers0.00.20.40.60.81.0fractionofoutliers024681012k0.00.20.40.60.81.0λiFigure 5: Left: histogram of log logistic loss for each data point in standard logistic regres-
sion; right: histogram of log logistic loss for each data point in clipped logistic regression.
Note that standard logistic regression attempts to make the loss small for all data points,
while its clipped counterpart allows the loss to be high for some of the data points.

Figure 3 displays the test loss and fraction of outliers over the range of values of α we
approximately minimized. Figure 4 shows the trajectory of the entries of λ during each step
of the execution of algorithm 3.1 for the α with the highest test accuracy, while ﬁgure 4 plots
the histogram of the logistic loss for each of the available data points for this same α.

6.3 Lane changing

In this example, we consider a control problem where a vehicle traveling down a road at a
ﬁxed speed must avoid obstacles, stay in one of two lanes, and provide a comfortable ride.
R denote the lateral position of the vehicle at time t = 0, . . . , T (T is the time
We let xt
horizon).

∈

The obstacle avoidance constraints are given as vectors xmin, xmax

lower and upper bounds on xt at time t.

RT that represent

∈

We can split the objective into the sum of two functions described below.

Lane cost. Suppose the two lanes are centered at x =

1 and x = 1. The lane cost is

−

•

13

−6−4−20loglogisticloss0510152025count−6−4−20loglogisticloss0123456countFigure 6: Trajectory of a vehicle looking to avoid obstacles (represented by boxes) while
optimizing for comfort and lane position.

given by

glane(x) =

T
(cid:88)

t=0

min
{

(xt

−

1)2, 1
}

+ min

(xt + 1)2, 1
}

.

{

The lane cost incentivizes the vehicle to be in the center of one of the two lanes. The
lane cost is evidently a sum of clipped convex functions.

Comfort cost. The comfort cost is given by

•

gcomfort(x) = ρ1

Dx

(cid:107)

(cid:107)

2
2 + ρ2

D2x

2
2 + ρ3
(cid:107)

(cid:107)

D3x

2
2,

(cid:107)

(cid:107)

where D is the diﬀerence operator and ρ1, ρ2, ρ3 > 0 are weights to be chosen. The
comfort cost is a weighted sum of the squared lateral velocity, acceleration, and jerk.

To ﬁnd the optimal lateral trajectory we solve the problem

minimize

glane(x) + gcomfort(x)

subject to x0 = xstart,

xT = xend,

xmin

x

≤

≤

xmax,

(15)

where xstart, xend

∈

R are given starting and ending points of the trajectory.

Numerical example. We use T = 100, ρ1 = 10, ρ2 = 1, ρ3 = .1, xstart = 1, and xend =
1.
In ﬁgure 6 we show the trajectory resulting from an approximate solution to (15) with three
obstacles. For this example, algorithm 3.1 terminated in 1.2 seconds and took 4 iterations.
We are able to ﬁnd a comfortable trajectory that avoid the obstacles and spends as little
time as possible in between the lanes.

−

14

020406080100−2−1012Lower bound. Using the relaxed version of the perspective formulation (12), we can
compute a lower bound on the objective value of the clipped control problem (15). We
found a lower bound value of around 103.55, while the approximate solution we found had
an objective value of 119.07, indicating that our approximate solution is no more than 15%
suboptimal.

Acknowledgments

S. Barratt is supported by the National Science Foundation Graduate Research Fellowship
under Grant No. DGE-1656518.

References

[1] A. Agrawal, B. Amos, S. Barratt, S. Boyd, S. Diamond, and Z. Kolter. Diﬀerentiable
In Advances in Neural Information Processing Systems,

convex optimization layers.
2019.

[2] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein. Distributed optimization and
statistical learning via the alternating direction method of multipliers. Foundations and
Trends R
(cid:13)

in Machine Learning, 3(1):1–122, 2011.

[3] S. Boyd and L. Vandenberghe. Convex optimization. Cambridge University Press, 2004.

[4] D. Gabay and B. Mercier. A dual algorithm for the solution of nonlinear variational
problems via ﬁnite element approximation. Computers & Mathematics with Applica-
tions, 2(1):17–40, 1976.

[5] R. Glowinski and A. Marroco. Sur l’approximation, par ´el´ements ﬁnis d’ordre un, et la
r´esolution, par p´enalisation-dualit´e d’une classe de probl`emes de dirichlet non lin´eaires.
ESAIM: Mathematical Modelling and Numerical Analysis - Mod´elisation Math´ematique
et Analyse Num´erique, 9(R2):41–76, 1975.

[6] M. Grant and S. Boyd. Graph implementations for nonsmooth convex programs. In

Recent Advances in Learning and Control, pages 95–110. Springer, 2008.

[7] P. Huber. Robust regression: asymptotics, conjectures and monte carlo. The Annals of

Statistics, 1(5):799–821, 1973.

[8] P. Huber and E. Ronchetti. Robust Statistics. John Wiley & Sons, 2009.

[9] G. Lan, C. Hou, and D. Yi. Robust feature selection via simultaneous capped 2-norm
and 2, 1-norm minimization. In IEEE Intl. Conf. on Big Data Analysis (ICBDA), pages
1–5. IEEE, 2016.

15

[10] T. Lipp and S. Boyd. Variations and extension of the convex–concave procedure. Op-

timization and Engineering, 17(2):263–287, 2016.

[11] T. Liu and H. Jiang. Minimizing sum of truncated convex functions and its applications.

Journal of Computational and Graphical Statistics, 28(1):1–10, 2019.

[12] N. Moehle and S. Boyd. A perspective–based convex relaxation for switched-aﬃne

optimal control. Systems & Control Letters, 86:34–40, 2015.

[13] C. Ong and L. An. Learning sparse classiﬁers with diﬀerence of convex functions algo-

rithms. Optimization Methods and Software, 28(4):830–854, 2013.

[14] J. Portilla, A. Tristan-Vega, and I. Selesnick. Eﬃcient and robust image restoration
using multiple-feature l2-relaxed sparse analysis priors. IEEE Transactions on Image
Processing, 24(12):5046–5059, 2015.

[15] T. Rockafellar. Convex analysis. Princeton University Press, 1970.

[16] A. Safari. An e–E–insensitive support vector regression machine. Computational Statis-

tics, 29(6):1447–1468, 2014.

[17] Y. She and A. Owen. Outlier detection using nonconvex penalized regression. Journal

of the American Statistical Association, 106(494):626–639, 2011.

[18] Q. Sun, S. Xiang, and J. Ye. Robust principal component analysis via capped norms.
In Proc. Intl. Conf. on Knowledge Discovery and Data Mining, pages 311–319. ACM,
2013.

[19] S. Suzumura, K. Ogawa, M. Sugiyama, and I. Takeuchi. Outlier path: A homotopy
algorithm for robust SVM. In Intl. Conf. on Machine Learning, pages 1098–1106, 2014.

[20] P. Tao and L. An. Convex analysis approach to DC programming: Theory, algorithms

and applications. Acta Mathematica Vietnamica, 22(1):289–355, 1997.

[21] P. Torr and A. Zisserman. Robust computation and parametrization of multiple view

relations. In Intl. Conf. on Computer Vision, pages 727–732. IEEE, 1998.

[22] G. Xu, B.-G. Hu, and J. Principe. Robust C-loss kernel classiﬁers. IEEE Transactions

on Neural Networks and Learning Systems, 29(3):510–522, 2016.

[23] Y.-l. Yu, M. Yang, L. Xu, M. White, and D. Schuurmans. Relaxed clipping: A global
training method for robust regression and classiﬁcation. In Advances in Neural Infor-
mation Processing Systems, pages 2532–2540, 2010.

[24] A. Yuille and A. Rangarajan. The concave–convex procedure. Neural Computation,

15(4):915–936, 2003.

16

[25] T. Zhang. Multi-stage convex relaxation for learning with sparse regularization.
Advances in Neural Information Processing Systems, pages 1929–1936, 2009.

In

[26] T. Zhang. Analysis of multi-stage convex relaxation for sparse regularization. Journal

of Machine Learning Research, 11(Mar):1081–1107, 2010.

A Diﬀerence of convex formulation

In this section we make the observation that (1) can be expressed as a diﬀerence of convex
(DC) programming problem.
Let hi(x) = max(fi(x)

αi, 0). This (convex) function measures how far fi(x) is above

αi. We can express the ith term in the sum as

−

since when fi(x)
Since fi and hi are convex, (1) can be expressed as the DC programming problem

−
αi, we have hi(x) = 0, and when fi(x) > α, we have hi(x) = fi(x)

≤

}

fi(x), αi
min
{

= fi(x)

hi(x),

minimize f0(x) + (cid:80)m

i=1 fi(x)

(cid:80)m

i=1 hi(x),

−

αi.

−

(16)

with variable x. We can apply then well-known algorithms like the convex-concave proce-
dure [20, 24] to (approximately) solve (16).

B Minimal convex extension

If we replace each fi with any function ˜fi such that ˜fi(x) = fi(x) when fi(x)
αi, we get
an equivalent problem. One such ˜fi is the minimal convex extension of fi, which is given by

≤

˜fi(x) := sup
{

fi(z) + gT (x

z)

g

∂fi(z), fi(z)

αi, z

|
In general, the minimal convex extension of a function is often hard to compute, but it can be
b)2,
represented analytically in some (important) special cases. For example, if fi(x) = (aT x
the minimal convex extension is the Huber penalty function, or

−

−

≤

∈

∈

Rn

.
}

(cid:40)

˜fi(x) =

b)2

(aT x
αi(2

−
aT x
|

b

aT x
|
αi) otherwise.

−

b

| ≤

αi

| −
Using the minimal convex extension leads to an equivalent problem, but, depending on the
algorithm, replacing fi with ˜fi can lead to better numerical performance.

−

17

