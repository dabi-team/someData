1
2
0
2

p
e
S
6

]

G
L
.
s
c
[

2
v
2
2
7
5
0
.
2
1
0
2
:
v
i
X
r
a

Using Diﬀerentiable Programming for Flexible
Statistical Modeling

Maren Hackenberg, Marlon Grodd, Clemens Kreutz
Institute of Medical Biometry and Statistics,
Faculty of Medicine and Medical Center, University of Freiburg, Germany
and
Martina Fischer, Janina Esins, Linus Grabenhenrich
Robert-Koch-Institut, Berlin, Germany
and
Christian Karagiannidis
Department of Pneumology and Critical Care Medicine, Cologne-Merheim Hospital,
ARDS and ECMO Center, Kliniken der Stadt Köln,
Witten/Herdecke University Hospital, Cologne, Germany
and
Harald Binder
Institute of Medical Biometry and Statistics,
Faculty of Medicine and Medical Center, University of Freiburg, Germany

September 7, 2021

MH acknowledges funding by the DFG (German Research Foundation) – 322977937/GRK2344.

The authors thank Gerta Rücker for her thoughtful comments on the manuscript.

Abstract

Diﬀerentiable programming has recently received much interest as a paradigm that
facilitates taking gradients of computer programs. While the corresponding ﬂexible
gradient-based optimization approaches so far have been used predominantly for deep
learning or enriching the latter with modeling components, we want to demonstrate
that they can also be useful for statistical modeling per se, e.g., for quick prototyping
when classical maximum likelihood approaches are challenging or not feasible.

In an application from a COVID-19 setting, we utilize diﬀerentiable programming
to quickly build and optimize a ﬂexible prediction model adapted to the data quality
challenges at hand. Speciﬁcally, we develop a regression model, inspired by delay diﬀer-
ential equations, that can bridge temporal gaps of observations in the central German
registry of COVID-19 intensive care cases for predicting future demand. With this ex-
emplary modeling challenge, we illustrate how diﬀerentiable programming can enable
simple gradient-based optimization of the model by automatic diﬀerentiation. This
allowed us to quickly prototype a model under time pressure that outperforms sim-
pler benchmark models. We thus exemplify the potential of diﬀerentiable programming
also outside deep learning applications, to provide more options for ﬂexible applied
statistical modeling.

Keywords: Diﬀerential Equations; Machine Learning; Optimization; Workﬂow

1

 
 
 
 
 
 
1

Introduction

Recently, diﬀerentiable programming (e.g., Innes et al. 2019) has become a prominent con-
cept in the machine learning community, in particular for deep neural networks. Parameter
estimation for the latter has long been conceptualized via backpropagation of gradients
through a chain of matrix operations. The paradigm of diﬀerentiable programming now
allows to view artiﬁcial neural networks more generally as non-linear functions speciﬁed via
computer programs, while still providing gradients for parameter estimation via automatic
diﬀerentiation. For example, this has allowed to incorporate other modeling approaches,
such as diﬀerential equations, that can better reﬂect the problem structure in the task at
hand (Rackauckas et al. 2020a). Given that diﬀerentiable programming now enables such
a shift of neural networks towards modeling, we conjecture that it might also be useful for
enhancing statistical modeling per se. In the following, we describe a modeling challenge,
where diﬀerentiable programming allowed us to quickly prototype a prediction model for
COVID-19 intensive care unit (ICU) data from the central German registry, and also more
generally introduce and illustrate diﬀerentiable programming for statistical modeling.

While statistical modeling is sometimes considered as distinct from black box algorith-
mic modeling in machine learning (Breiman 2001), there are many examples where both
ﬁelds could beneﬁt from the exchange and joint development of techniques (e.g., Friedman
In particular, Efron (2020) provides a compelling perspective on how pure
et al. 2000).
prediction algorithms relate to traditional methods with respect to the central statistical
tasks of prediction, estimation and attribution, and points out directions for combining their
respective advantages and thus enriching statistical methods development. In this spirit,
we present an illustrative example that integrates concepts of diﬀerential equations and
diﬀerentiable programming with regression modeling.

Traditional regression-based methods assume a "surface plus noise" formulation (Efron
2020): an underlying structural component describes the true process we are interested in
but can only be accessed by noisy observations. Parameter estimation in such models typi-
cally is based on maximum likelihood techniques, e.g., using Fisher scoring as an iterative
approach. An overview on many diﬀerent types of corresponding regression modeling ap-
proaches is provided, for example, in Fahrmeir & Tutz (2001). Machine learning approaches,
such as deep neural networks, typically rely on some loss function, which can be based on a
likelihood but does not have to. Optimization then is typically performed using a gradient-
descent algorithm. In contrast to Fisher scoring, this does not require speciﬁcation of second
derivatives, which makes it more diﬃcult to determine step sizes and quantify uncertainty,
but is more generally applicable. In particular, this enables the paradigm of diﬀerentiable
programming, where loss functions can be speciﬁed as computer programs and optimized
via automatic diﬀerentiation. While it is a well-established tool in scientiﬁc computing (see,
e.g., Griewank 1989), the ﬁeld of deep learning has only recently more broadly embraced
the applicability of automatic diﬀerentiation tools to any prediction model that relies on the
gradient-based optimization of a diﬀerentiable loss function. Furthermore, such frameworks
enable to diﬀerentiate through computer programs, supporting control ﬂow and recursion
(Baydin et al. 2017, Innes et al. 2019), e.g., allowing to incorporate solvers of diﬀerential
equations into neural networks to reﬂect structural assumptions (Chen et al. 2018). Dif-
ferentiable programming emerged as a descriptive term for this resulting new paradigm
(LeCun 2018). Its core idea is to use automatic diﬀerentiation to allow for ﬂexible models
that seamlessly integrate elements of deep learning and modeling (Rackauckas et al. 2020a).

2

We are convinced that diﬀerentiable programming can also be useful for applied statisti-
cal modeling, e.g., for quick prototyping when other parameter optimization techniques like
maximum likelihood Fisher scoring are challenging. Such an approach also more generally
has the potential for combining the two optimization paradigms of machine learning and
regression-based modeling and thereby opens up new routes for model building. To exem-
plify this potential, we employ diﬀerentiable programming to predict prevalent COVID-19
cases in ICUs with regression models, ﬂexibly adapted to handle temporal gaps in longitudi-
nal observations. In particular, we design a statistical model that is inspired by diﬀerential
equations, introducing dependence of the model on its own past (similar to delay diﬀeren-
tial equations), and show how diﬀerentiable programming allows to solve the corresponding
non-linear optimization problem. Note that we use this particular application merely as an
example to illustrate why diﬀerentiable programming in general provides a useful tool for
statistical modeling, without putting too much emphasis on the speciﬁc model.

In the following, we give a brief overview of exemplary applications of diﬀerentiable
programming in statistical ﬁelds and beyond, before outlining the scenario of our speciﬁc
application. Next, we develop our modeling approach and give an introduction to diﬀeren-
tiable programming as a paradigm for optimizing our model and its relation to automatic
diﬀerentiation and neural networks. We present results on prediction performance, the
model sensitivity with respect to time intervals and diﬀerent model variants, exemplifying
the ﬂexibility of such a model ﬁtting process. The closing discussion provides further re-
marks on the more general applicability of diﬀerential programming in statistical modeling.

2 Exemplary applications

2.1 Diﬀerentiable programming in statistics and beyond

To illustrate how diﬀerentiable programming can be applied in more general settings, we
brieﬂy present examples both with a statistical focus and from a broader range of ﬁelds.

A key application example of diﬀerentiable programming is the integration of diﬀeren-
tial equations and neural networks to incorporate structural assumptions (Chen et al. 2018,
Rackauckas et al. 2020a). For example, such neural diﬀerential equations have been used as
a ﬂexible alternative for estimating multi-state survival models (Groha et al. 2021). Further,
the authors embed neural diﬀerential equations into a variational inference framework to
quantify the uncertainty of individual cause-speciﬁc hazard rates, with gradients for param-
eter estimation provided by diﬀerential programming. More generally, neural ODEs have
been integrated into a Bayesian learning framework (Dandekar et al. 2020) for uncertainty
quantiﬁcation. This has further been incorporated into non-linear mixed eﬀects model for
pharmacometric modeling (Rackauckas et al. 2020c), where diﬀerentiable programming al-
lows for jointly optimizing the diﬀerent model components in an end-to-end framework.

More broadly, diﬀerentiable programming has been applied in, e.g., agriculture and en-
vironmental science for modeling spread of banana plant disease incorporating climate data
(Wang et al. 2020) or forecasting reservoir inﬂows for water ecology management (Zhou &
Li 2021). In ﬁnance, it enables integration of neural networks and stochastic diﬀerential
equations, e.g., for an European options book model (Cohen et al. 2021). Further, data-
eﬃcient machine learning methods for scientiﬁc applications such as physics-informed neural
networks (Rackauckas et al. 2020b) have been used to bridge the gap between scientiﬁc com-
puting and machine learning. More generally, modeling and simulation can be composed

3

by, e.g., diﬀerentiable simulation engines for physics (de Avila Belbute-Peres et al. 2018),
robotics (Degrave et al. 2018) and quantum computing (Luo et al. 2020). Finally, diﬀer-
entiable programming has been proposed for integrating machine learning-based surrogate
models with modeling and simulation in engineering applications (Rackauckas et al. 2021)
as well as for image processing and rendering (Li et al. 2018a,b). While covering a diverse
range of ﬁelds and application scenarios, all these examples share the core element of being
built on a diﬀerentiable programming framework to obtain gradients for model optimization
and parameter estimation, illustrating the broad applicability of this paradigm.

2.2 A modeling challenge: predicting COVID-19 ICU demand

In the following, we focus on a statistical modeling challenge in a COVID-19 context as an
illustrative example of how diﬀerentiable programming can be used to estimate parameters
of a statistical model for prediction in a setting where quality issues in the data make
straightforward regression modeling challenging.

At the onset of the pandemic, we had been asked by the Federal Ministry of Health on
a short notice to provide a prediction tool for future ICU demand in German hospitals to
serve as basis for critical decisions such as transfer of patients between states, or admissions
of patients from neighboring countries to German hospitals in the border regions, together
with the Robert Koch Institute (RKI).1 Hence, we had to quickly prototype a model of ICU
capacities with prognostic power, based on past daily reports of prevalent cases in hospitals
and numbers of new infections in the population.

During this ﬁrst wave of COVID-19 infections in Germany, however, many hospitals did
not yet report prevalent cases daily, such that the data is characterized by a large amount
of missing values, often also over longer periods of time. Any prediction modeling approach
will have to deal with these missing values. While these could potentially be imputed, any
imputation scheme should ideally incorporate typical temporal patterns, which in turn only
are obtained after modeling. As a further challenge for modeling, in particular during the
ﬁrst wave of infections, the pandemic dynamics diﬀered widely between regions as well as
between larger and smaller hospitals, requiring individual models for each hospital. Yet, as
data collections had only just been set up, not many time points were available, implying
restrictions on the number of parameter that can be estimated in hospital-speciﬁc models.
Speciﬁcally, our model is based on data from the DIVI intensive care registry, a joint
project of the German Interdisciplinary Association for Intensive and Emergency Medicine
(DIVI) and the RKI that documents capacities for intensive care and records numbers of
COVID-19 cases currently treated in ICUs of participating hospitals. We consider data
from April 16, 2020, onwards, when a regulation came into eﬀect that made daily reporting
compulsory for all German acute care hospitals with ICUs. However, many hospitals joined
the registry later or did not report on a regular basis, leading to a substantial amount of
time intervals without reports: Until June 24, 2020, 1281 hospitals have been participating
in the registry with a total of 6.41% missing daily reports for prevalent COVID-19 cases.
For 463 (36.14%) hospitals, all daily reports are available, while for 187 (14.60%) hospitals,
more than 10% of the daily reports are missing. Additionally, some hospitals have large gaps
in their reporting, with e.g. 7.11% of hospitals having more than 25% missing reports, and

1https://www.rki.de/DE/Content/InfAZ/N/Neuartiges_Coronavirus/Projekte_RKI/

SPoCK.html

4

Figure 1: Exemplary daily numbers of prevalent ICU cases of a hospital from the DIVI
registry between April 16, 2020, and June 24, 2020. Reported values are shown in blue.

10% of hospitals having gaps of ﬁve or more consecutive missing reports. As an example,
Figure 1 depicts the daily reports of prevalent COVID-19 ICU cases in a DIVI hospital.

We observed that larger gaps of consecutive missing reports tend to be associated with a
sudden increase or decrease in the numbers of cases after the gap, such that in particular such
dynamic phases of increase or decrease tend to be poorly reﬂected in the data. This shows
again that using an imputation approach to capture these missing dynamics is problematic,
as, e.g., any form of interpolation will require knowledge of the next report after the gap.
However, this is not available when making predictions, which is our primary focus.

Nonetheless, an approach to explicitly model the course of the prevalent ICU cases over
time and to make day-to-day predictions for future demand was urgently needed in the
situation outlined above, also as a basis for clinical and political decision making. Thus, we
developed a model that can ﬂexibly deal with the missingness patterns in the data without
requiring imputation, and that can predict future ICU demand by modeling the increments
of prevalent ICU cases over time individually for each hospital. As we will elaborate further
in the next section, here the paradigm of diﬀerentiable programming enabled us to quickly
prototype a ﬂexible prediction model and estimate its parameters, even though classical
maximum likelihood techniques were problematic due to the speciﬁc data scenario.

As further input for predicting the future number of prevalent ICU cases individually for
each hospital, we incorporate predicted COVID-19 incidence based on data from the RKI.
For these predictions, an ordinary diﬀerential equation (ODE) model is employed to describe
the temporal changes of the number of susceptible, exposed, infected and removed (SEIR)
people (Allen et al. 2008). To account for containment measures, a time dependent infection
rate is assumed that is described by a smoothing spline (Schelker et al. 2012). All model
parameters are estimated by maximum likelihood at the level of the 16 German federal
states. The local dynamics at the level of the 412 counties are then estimated by ﬁtting
a scaling parameter and an observation error parameter to the reported new infections in
each county (see Reﬁsch et al. (2021) for details). The resulting model predictions provide
daily information on the local pressure of new cases that could potentially turn into ICU
cases. We investigate sensitivity of our ICU prediction model to these ﬁtted incidences
by comparing results based on the maximum likelihood estimate and the upper and lower
bounds of its 95% conﬁdence interval in Section 4.4.

5

Apr19Apr26May03May10May17May24May31Jun07Jun14Jun21Date012345NumberofprevalentCOVID-19cases3 Methods

3.1 Developing a ﬂexible regression model to predict the increments of

prevalent COVID-19 ICU cases

Numbers of COVID-19 patients vary between hospitals due to regional diﬀerences in infec-
tion rates and regulating mechanisms of hospitals within one area (e.g., COVID-19 patients
tend to be transferred to larger centers), meaning that predicted county-level COVID-19
incidences translates into a diﬀerent number of ICU cases for each hospital. Therefore, we
ﬁt an individual model for each of the 1281 participating hospitals from the DIVI register.
We denote with y = (y1, . . . , yT )(cid:62) ∈ RT the numbers of prevalent ICU cases, where T ∈ N
is the number of observations days in the registry from April 16, 2020 onwards, and aim at
modeling the increments (yt − yt−1) for t = 2, . . . , T .

For each hospital, we employ a simple linear regression model with the absolute numbers
of prevalent COVID-19 ICU cases y and the incident county-level COVID-19 cases z =
(z1, . . . , zT )(cid:62) ∈ RT in the county of the hospital as covariates, representing the potential
for decrease (e.g., due to discharge) and increase (through conversion to ICU cases) with
respect to the future number of prevalent ICU cases in a hospital, respectively:

(yt − yt−1) = β1(t) + β2(t) · yt−1 + β3(t) · zt−1,

t = 2, . . . , T.

(1)

To avoid the diﬃculty of estimating time-dependent parameters in a setting where not
many time points were available yet, we decided to model the parameters as constant, i.e.,
βi(t) = βi for i = 1, 2, 3, as a pragmatic solution.

If the numbers of prevalent cases y were a smooth function y(t) ∈ C([t0, T ]; R) deﬁned on
the observed time interval, the increments of the prevalent ICU cases could be viewed as a
crude approximation to its derivative. Including the absolute numbers of the prevalent ICU
cases yt−1 at the previous day t − 1 as a covariate in (1) then resembles a dependence of the
approximate derivate on the history of the function itself, like in delay diﬀerential equations.
Note that this is to be understood as a loose analogy for motivating our approach.

As a consequence, we model continuous-valued increments. While this limits inter-
pretability of predictions as exact discrete ICU utilization numbers, it implies practical
beneﬁts: When predicting several days into the future, discretizing our predictions would
potentially lead to larger errors and less informative results. If we predict increments of,
e.g., 0.4 for 3 consecutive days, carrying forwards a continuous prediction model results in
a predicted increment of 1.2, while discretizing predictions to counts would result in pre-
dicting 0 new cases. Thus, continuous predictions better allow for gaining tendencies on the
upcoming development, which is especially helpful for making decisions on a larger scale,
e.g., on transferring patients between states, as was required in our application setting.

In the following, we describe how this model formulation allows to account for missing
daily reports when deﬁning a squared-error loss function for subsequently estimating the
model parameters by gradient descent. We encode the information of whether a speciﬁc
hospital reported their number of prevalent ICU cases at a given time point as a binary vector
r ∈ {0, 1}T , where rt = 1 if yt is reported, and rt = 0 otherwise, for t = 1, . . . , T . Whenever
the prevalent ICU cases at a certain day have actually been reported, this observation
contributes to the loss function, by including the squared diﬀerence between the model
prediction with the current parameter estimates and the true observed value. However, if
a daily report is missing, there is no true value to compare a prediction to, so we use the

6

current state of the model to predict a value for the respective day and move on to the next
time point, where the procedure is repeated. In this way, we carry the model prediction
forward in time (like a diﬀerential equation), until a new observation becomes available.

More formally, deﬁning dyt := yt − yt−1, the predicted increments of prevalent ICU cases

for a speciﬁc hospital are given by

(cid:99)dyt+1 = β1 + β2 · (cid:101)yt + β3 · zt, where (cid:101)yt =

(cid:40)

yt,
(cid:101)yt−1 + (cid:99)dyt,

if rt = 1,
else.

(2)

We can thus deﬁne a loss function that includes only the predictions for those time points
where a report is available:

L(y, z, r, β) =

1
(cid:80)T
t=2 rt

T
(cid:88)

t=2

rt · ((cid:99)dyt − ((cid:101)yt − (cid:101)yt−1))2

(3)

Finding optimal model parameters then amounts to minimizing the loss function with re-
spect to the regression coeﬃcients.

If there are missing daily reports at the beginning of the time interval, i.e., r1, . . . , rs =
0 for some s < T , those values are skipped and the ﬁrst non-missing value ytstart =
(cid:101)ytstart, tstart = mint∈{1,...,T }{rt | rt = 1} is used to calculate the ﬁrst prediction dytstart+1.

3.2 Diﬀerentiable programming

Diﬀerentiable programming provides a ﬂexible way to automatically diﬀerentiate through
any computer program and obtain gradients of the program and its outputs with respect
to its parameters. Such a program can consist of any kind of model, e.g., a statistical
regression model, a system of diﬀerential equations, or a neural network, and a loss function
that computes some form of error between the model output and data that the model
should be ﬁtted to. If the loss is diﬀerentiable as a function of the model parameters, these
can be optimized via gradient descent. Here, diﬀerentiable programming can be used to
calculate these gradients of the loss function with respect to any model parameter in an
automated way. The key advantage is that if any model loss function can be written down
as a computer program, diﬀerentiable programming will allow for estimating the model
parameters regardless of how complex the code is (as long as it is diﬀerentiable). This
allows to build complex models that can be large and complex, or comprise several distinct
building blocks, such as diﬀerential equations and neural networks. All these building blocks
can then be jointly optimized by combining their outputs into one diﬀerentiable loss function
and applying automatic diﬀerentiation to obtain gradients, using the chain rule to propagate
the sensitivities with respect to the parameters backwards through the model components.
’Diﬀerentiable programming’ is the term used to describe this new paradigm of model
building, where a model can be any computer program that can be conceptualized as a
composition of diﬀerentiable functions. Exact gradients of the program output with respect
to any of its parameters are provided by automatic diﬀerentiation, ensuring maximal ﬂex-
ibility and expressivity of the model to be optimized. In contrast, manually working out
analytical derivatives is time-consuming, prone to errors and not always feasible. Similarly,
symbolic diﬀerentiation quickly results in long, complex expressions, while also requiring a
closed-form expression. Numerical diﬀerentiation by ﬁnite diﬀerence approximations is easy
to implement but can incur rounding and truncation errors (Baydin et al. 2017).

7

Automatic diﬀerentiation overcomes theses limitations by augmenting each variable of
the program with the derivative of the program at this variable, and extending all arithmetic
operators to this augmented space (Innes 2018a). In practice, this is realized by a diﬀerential
operator J (f ) := x (cid:55)→ (f (x), z (cid:55)→ Jf (x) · z) that maps any function f to a tuple of the
value of f at some value x, and the evaluation of the Jacobian Jf (x) at some z (Innes
et al. 2019). I.e., it transforms a function to a tuple consisting of the evaluation of both
the function and its gradient. With this deﬁnition, the gradient of a scalar function g at
some x can be obtained by selecting the second element of the tuple J (g)(x), i.e., the
function z (cid:55)→ Jg(x) · z, and evaluating it at z = 1, yielding ∇g(x). Speciﬁcally, we can
use this operator to implement the chain rule. Then, it can be hard coded how J operates
on a set of primitive functions (such as polynomials, exp, log, sin, etc.) and subsequently,
diﬀerentials of all other functions and complex function compositions can be generated by
repeatedly applying the chain rule.

For example, this strategy is used for ﬁtting neural networks with backpropagation
(Rumelhart et al. 1986). Essentially, a neural network is a potentially complex composition
of nonlinear functions parameterized by a set of weights and biases, which can be optimized
via gradient descent by writing down the model and a loss function as a program, and using
automatic diﬀerentiation to propagate the gradients of the loss function with respect to all
weights and biases backwards through the network.

For our application, we use the automatic diﬀerentiation system implemented in the
Zygote.jl package (Innes et al. 2019) for the Julia programming language (Bezanson
et al. 2017). A key advantage of Julia with respect to other dynamic languages, such as
Python or R, is the broad ecosystem of packages written entirely in Julia itself, making them
accessible for automatic diﬀerentiation. Further, Zygote.jl diﬀers from the majority of
state-of-the-art automatic diﬀerentiation tools by its use of source-to-source transformation
(Innes 2018a, Innes et al. 2019) instead of tracing-based mechanisms to evaluate gradients
(as in, e.g., Johnson et al. 2018, Abadi et al. 2016, Innes et al. 2018). While its core idea
represents a more general strategy (e.g., Bischof et al. 1996, Pearlmutter & Siskind 2008,
Wang et al. 2018), the main novelty of Zygote.jl is its adaptation for a full, high level
dynamic language such as Julia (Innes et al. 2019). The speciﬁc characteristics of the Julia
implementation are described in detail in Innes (2018a).

As an example, for handling control ﬂow in diﬀerentiation many automatic diﬀerentia-
tion systems use a tracing approach based on operator overloading: Inputs to the program
are wrapped in a new objects, on which any function call does not only produce the re-
sult, but also records the operation itself and its inputs. This complete recording includes
unrolling all control ﬂow operations. For diﬀerentiation, this list is then passed through in
reverse order, propagating the gradients backwards through the set of recorded operations.
This also limits expressiveness, as it requires re-compilation for every new input value. In
contrast, in Zygote.jl, a derivative function is generated directly from the original source
code that uses goto instructions to keep control ﬂow intact (see Innes (2018a) for details
and examples). With this source-to-source transformation Zygote.jl can compile, opti-
mize and re-use a single derivative deﬁnition for all input values. It supports control ﬂow,
recursion and user deﬁned data types and seamlessly integrates with existing Julia packages.

8

3.3 Fitting the model

In the following, we illustrate how the parameters of the increment model introduced in
Section 3.1 can be optimized by diﬀerentiable programming.

Note that the model covariate (cid:101)y from (2) depends on the model prediction from previous

time steps, such that for any rt = 0, it holds that

(cid:99)dyt+1 = β1 + β2 · (cid:101)yt + β3 · zt

= β1 + β2 · ((cid:101)yt−1 + (cid:99)dyt) + β3 · zt
= β1 + β2 · ((cid:101)yt−1 + (β1 + β2 · (cid:101)yt−1 + β3 · zt−1)) + β3 · zt,

(4)

introducing higher order terms β2β1, β2
2, β2β3 of the parameters. Thus, we cannot apply
Fisher scoring to iteratively obtain a maximum likelihood estimate. Yet, we can ﬁnd opti-
mal values for the model parameters by using gradient descent on the loss functions, with
gradients provided by diﬀerential programming, by initializing β(0) = 0 and updating

β(s) = β(s−1) − η · ∇βL(y, z, r, β(s−1)),

s = 1, . . . , S,

(5)

where the number of steps S ∈ N and the stepsize η ∈ R3 are hyperparameters. Equation (4)
shows that the loss as a function of the parameters β is essentially a higher-order polynomial,
which ensures a suﬃciently smooth surface for gradient-based optimization. On the other
hand, the higher-order terms in (4) imply that the loss is not necessarily convex, such that
gradient descent is only guaranteed to ﬁnd a local optimum. However, by initializing the
parameters at 0 we implicitly use domain knowledge on the generally low numbers of cases.
Further, using parameter estimates obtained from past models on less time points as priors
for the initialization has been shown to further stabilize and improve the optimization.

To illustrate how even rather complex functions can be straightforwardly optimized with
diﬀerentiable programming as long as they can be written as computer code, we provide
the Julia source code of the loss function, including a loop and control ﬂow elements, in the
Supplementary Material, Section 1.

The gradient descent algorithm with the parameter update from (5) can then be im-
plemented in just a few lines (see Supplementary Section 1). Here, the exact gradient
∇βL is obtained as the second element of the output tuple of J from Section 3.2, i.e.,
the Jacobian-vector product z (cid:55)→ JL(β) · z, evaluated at z = 1. The loss function can
thus be automatically diﬀerentiated with respect to the parameters via the Zygote.jl
source-to-source diﬀerentiable programming framework, without requiring any refactoring.
This ﬂexible optimization of a customized loss function also allows to easily integrate
additional constraints and to adapt the model. For example, to prevent overﬁtting with a
smaller number of time points, a L2 regularization term can be added by replacing (5) with

β(s) = β(s−1) − η · ∇β(L(y, z, r, β(s−1)) + λ · (cid:107)β(s−1)(cid:107)2

2),

s = 1, . . . , S

(6)

and automatically diﬀerentiate through the new loss function for optimization.

Yet, due to the form of the model predictions (4), estimating the curvature of the
loss function is not straightforward, and we cannot use the Fisher information matrix to
determine an optimal step size, making the choice of η a critical one.

9

4 Results

4.1

Implementation

We implement the model in the Julia programming language (v1.5.3), using the diﬀeren-
tiable programming framework provided by the Zygote.jl package (v0.6.12). Despite our
customized, problem-speciﬁc model, this implementation allows us to quickly explore model
variations and extensions. The complete code to run all analyses and reproduce all tables and
ﬁgures together with an illustrative Jupyter notebook are available at https://github.
com/maren-ha/DifferentiableProgrammingForStatisticalModeling.

In our gradient-descent algorithm, we set the step size for the update of β3 corresponding
to the predicted incidences an order of magnitude smaller than the others. By scaling down
the incidences, we account for the fact that they are predicted at the level of states which
are considerably larger than individual hospital catchment areas, such that only a fraction
of new infections in the state will be responsible for potential new cases at one speciﬁc
hospital in that state. On the other hand, the Zygote.jl diﬀerentiable programming
framework is tightly integrated with the Julia machine learning package Flux.jl (Innes
2018b), which provides a full stack of optimizers for gradient-based learning that determine
an optimal step size purely data-based. While some optimizers, in particular versions of
the ADAM optimizer (Kingma & Ba 2015), also yield better predictions than baseline
models, the simple gradient-descent algorithm with manually chosen step size worked well
in the present application. We thus decided to incorporate this domain knowledge on
inherently diﬀerent orders of magnitude in the data into our choice of step size, but to
otherwise keep the optimization as simple as possible, in a scenario where we were under
time pressure to develop a working prototype yet did not have test data available to guide
hyperparameter optimization. Rather, with the presented model we aim to showcase an
exemplary application scenario where we can beneﬁt from diﬀerentiable programming for
quick prototyping of a robust statistical prediction model, when no suﬃcient data or time
is available to extensively ﬁne-tune it.

4.2

Individual models

To evaluate the model, we separately optimize the parameters for each hospital k = 1, . . . , K =
1291, based on all time points available for that hospital except for the last. The prediction
for this withheld last time point is then compared to four benchmark models across all
hospital in the DIVI registry.

As a ﬁrst benchmark, we consider the zero model

zero
k,T := 0,

(cid:99)dy

k = 1, . . . , K.

This benchmark model is motivated by the knowledge that the numbers of COVID-19
infections towards the end of the considered time interval, when the ﬁrst wave of infections
is over, are consistently low. As a second benchmark, we consider a mean model

mean
k,T

(cid:99)dy

:=

1
T − 2

T −1
(cid:88)

t=2

(yk,t − yk,t−1),

k = 1, . . . , K,

where missing observations are imputed using a last-observation-carried-forward principle.

10

Third, we evaluate a modiﬁed version of the mean model

modmean
k,T

(cid:99)dy

:=

(cid:40)

0,
(cid:99)dy

mean
k,T ,

if (yk,T −1 − yk,T −2) = 0,
else,

k = 1, . . . , K.

To account for the parametric complexity of our proposed increment model, as a ﬁnal
benchmark we consider a standard linear regression model with the same covariates, where
we impute missing values with a last-observation-carried forward scheme, such that the
model can be ﬁtted with standard maximum-likelihood estimation:

(cid:99)dy

linreg
t+1 = β1 + β2 · (cid:101)yt + β3 · zt, where (cid:101)yt =

(cid:40)

yt,
(cid:101)yt−1,

if rt = 1,
else.

(7)

When calculating predictions from our proposed model, we have to take hospitals into
account where estimation does not converge. For the 85 (6.6%) hospitals where this occurs,
we use the mean model for prediction. Anticipating that the zero models will perform better
than the mean models, as they incorporate additional knowledge, this is a conservative choice
for evaluating our approach.

For each of the four models, we sum the squared prediction errors, i.e., the diﬀerences
to the true increments at the last time point, over all hospitals where the observation at T
is not missing, i.e., for all k with rk,T = 1:

errmodel =

K
(cid:88)

k=1

rk,T · ((cid:99)dy

model
k,T − (yk,T − yk,T −1))2,

(8)

model ∈ {zero, mean, modmean, linreg, increment}.

The results are summarized in Table 1, showing that the increment model optimized
via diﬀerentiable programming provides the best prediction performance. As expected,
the models incorporating knowledge on the large number of zeros perform better than the
mean model. Still, our proposal, which uses the mean model as a fallback in cases of
non-convergence, outperforms the zero-based benchmark models.

4.3 Global vs. individual parameters

Additionally, we investigate whether an improvement over individual prediction models for
each hospital in the DIVI registry, as presented in Section 3.1, can be achieved by sharing
some of the parameters globally, i.e., using the same parameters values for all hospitals.

To this end, we implement several versions of the model that consider all possible com-
binations of local and global estimation of individual parameters. Technically, we use an
approach where in each step individual parameters are ﬁtted for every hospital, but the
mean of those individual parameters is taken as a global parameter before proceeding to
the next step, such that in step s,

β(s,k) = β(s−1,mean) − η · ∇L(yk, zk, rk, β(s−1,mean)),

k = 2, . . . , K,

(9)

with β(s,k) (cid:54)= β(s,l) for k, l ∈ {1, . . . , K}, k (cid:54)= l. After obtaining parameters β(s,k) for all
k = 1, . . . , K, we update the global parameter

β(s,mean) =

1
K

K
(cid:88)

k=1

β(s,k)

11

(10)

Table 1: Prediction performance of benchmark models and the proposed increment model
with diﬀerent combinations of global and individual parameters.

Squared error
Sum
86.0
89.239
84.342
181.068

Mean 1st Quartile Median 3rd Quartile
0.07
0.072
0.069
0.147

0.0
0.002
0.0
0.015

0.0
0.0
0.0
0.001

Prediction model

0.0
Zero model
0.0
Mean model
0.0
Modiﬁed mean model
Linear regression
0.0
Increment model with global β2 for prevalent cases
0.0
global β1; individual β3
0.0
individual β1; individual β3
0.0
global β1; global β3
individual β1; global β3
0.0
Increment model with individual β2 for prevalent cases
78.976
global β1; global β3
77.652
individual β1; global β3
global β1; individual β3
75.712
individual β1; individual β3 74.746

98.833
94.566
90.406
88.154

0.064
0.063
0.062
0.061

0.08
0.077
0.073
0.072

0.0
0.0
0.0
0.0

0.0
0.0
0.0
0.0

0.0
0.0
0.0
0.0

0.001
0.001
0.0
0.0

0.0
0.0
0.002
0.001

and proceed to the next step s + 1.

I

(cid:80)K

while for all j /∈ I, β(s,k)

To explore diﬀerent combinations of local and global parameters, the update (10) can be
=

applied only in speciﬁed dimensions such that for any given subset I ⊂ {1, 2, 3}, β(s,mean)
1
K

k=1 β(s,k)
From the results summarized in Table 1, it can be seen that the model with all individual
parameters still performs best. However, individual estimation of the parameter for the
prevalent cases, which reﬂects internal processes of the hospital, more strongly improves
the prediction performance than individual estimation of the intercept parameter or of the
parameter for the incidences, representing an external pressure.

remains unchanged.

I

j

The distribution of the squared errors across hospitals is highly skewed, with a prediction
error of close to zero for many hospitals, but some hospitals with very large errors. However,
these hospitals are not systematically mis-predicted by a speciﬁc model, but have high errors
across all prediction models. For example, sudden jumps in the number of cases on the day
held out for prediction cannot be captured based on the previous data seen by the models.
Notably, imputing missing reports with last observation carried forward and using stan-
dard maximum likelihood estimation performs worse than the simpler baselines. Further,
exemplary analyses for individual hospitals show that the our proposal of ﬂexibly bridg-
ing gaps of missing reports provides lower minima of the corresponding loss function (see
Supplementary Figure 1).

4.4 Sensitivity Analysis

To investigate the sensitivity of the model with respect to the predicted incidence data
used as a covariate, we repeated the analysis presented in the previous Section 4.3 with the
lower and upper bound of the conﬁdence interval of the maximum likelihood estimate for

12

Table 2: Quantiles of improvement in prediction error of the proposed increment model over
the mean model, obtained across all time intervals half as long as the entire time period.
Larger values imply a smaller error of the increment model compared to the mean model
and thus better prediction performance.

Increment model parameters

Diﬀerences of squared error
(mean model - increment model)
1st quartile median 3rd quartile

global parameter β2 for prevalent cases
global β1; global β3
individual β1; global β3
global β1; individual β3
individual β1; individual β3;
individual parameter β2 for prevalent cases
global β1; global β3
individual β1; global β3
global β1; individual β3
individual β1; individual β3;

1.997
5.720
-14.627
1.346

7.399
7.869
0.760
1.997

8.940
12.349
4.050
7.431

14.182
15.112
11.590
10.921

15.292
16.649
10.132
14.669

18.106
22.147
19.399
19.666

the predicted incidences (see Reﬁsch et al. (2021) for details on the underlying model and
estimation). We found similar results to those based on the maximum likelihood presented
in Table 1 above, with the upper bound yielding slightly worse and the lower bound yielding
slightly better predictions (see Supplementary Material, Section 3.1 for details).

The proposed increment model is based on the assumption that the parameters for a
hospital are constant in the course of time. To investigate how critical this assumption
is, we perform a sensitivity analysis by using diﬀerent temporal subsets of the data for
model ﬁtting, which is also useful for judging variability and potential bias more generally.
Speciﬁcally, we construct time intervals that are only half as long as the available observation
interval of length 70, starting at each day tstart = 1, . . . , 36 one after another, and deﬁning
the intervals Itstart = [tstart, tstart + 34], such that I1 = [1, 35], I2 = [2, 36], . . . , I36 = [36, 70].
On each interval, we evaluate the prediction of the baseline models deﬁned in Section 4.2
and ﬁt models for all combinations of individual and global parameters, as in Section 4.3.
Since at the beginning of the observation period, numbers of prevalent cases are globally
higher and then decrease until mainly zeros dominate the dataset, the prediction errors for
the earlier time intervals are also generally higher. Thus, the absolute values of prediction
errors are not directly comparable between diﬀerent time intervals. For a ﬁrst overview
of the model behavior across diﬀerent time intervals, we therefore evaluate the relative
improvement of the model over the mean model, i.e., the diﬀerence in prediction error
(errmean − errincrement). Larger values correspond a smaller error of the proposed model
compared to the mean model and thus better prediction performance. In Table 2, we report
the ﬁrst and third quartile as well as the median of the results over all 36 time intervals.
While we present the relative improvement over the mean model as the best benchmark
that does not incorporate knowledge on the large number of zeros, the relative improvement
over all other benchmark models is presented in the Supplementary Tables 3, 4 and 5.

For most combinations, the proposed increment model yields a better prediction per-

13

Figure 2: Prevalent cases of one DIVI hospital with observed values shown in blue and
model predictions for the missing observations shown in green. The panels depict four
combinations of global and individual parameters of the proposed model. In each panel,
in addition to the observed values (blue dots connected with blue line), we show both the
predicted values based on the respective model optimized on the entire dataset (dark green
dots connected with blue line) and the predictions based on all 36 data subsets obtained
from the shorter time intervals (lighter green dots).

formance than the simple mean model on the majority of data subsets, with only one
combination with a large negative 1st quartile. As in Section 4.3, we also generally observe
a better prediction performance of the increment model compared to the mean model for
all model versions with an individual estimation of the parameter for the prevalent cases.
Overall, the results from the previous sections generalize to models ﬁtted only on subsets of
the data, indicating general robustness of our model and optimization method.

Additionally, we take a look at exemplary predictions of the proposed model for larger
gaps of missing daily reports that originally motivated our method development. Again,
we evaluate these predictions based on the data from the entire time span and all data
subsets from the 36 shorter time intervals and for diﬀerent combinations of individual and
global parameters. We exemplarily illustrate the results for the hospital in the DIVI register
depicted in Figure 1 from Section 2.2 with its larger gaps in daily reporting.

In Figure 2, we show exemplary predictions for missing reports of prevalent COVID-19
cases obtained from the increment model with diﬀerent combinations of individual and global
parameters. In the models corresponding to panels A-C, the intercept parameter is estimated
globally. Panel A represents the all-global model, while in panel B, only the parameter
for the absolute value of the prevalent cases is estimated individually, thus corresponding
to a model with individually estimated internal processes and globally estimated external
pressure. In panel C, only the intercept parameter is estimated globally.

Note that the model is developed for a prediction setting, i.e., linearly interpolating
between reported data is not feasible for our purpose, as we do not know a priori what the
next value after a gap of missing reports will be when making predictions after one or more
days of missing reports.

As a ﬁrst observation, the variance of the predictions based on the data subsets (indicated

14

Apr19Thu23Mon27MayTue05Sat09Wed13May17Thu21Mon25Fri29JuneFri05Tue09Sat13Wed17Jun21Date0.00.51.01.52.02.53.03.54.04.55.0NumberofprevalentCOVID-19casespredictedreportedPrevalentcases...DApr19Thu23Mon27MayTue05Sat09Wed13May17Thu21Mon25Fri29JuneFri05Tue09Sat13Wed17Jun21Date0.00.51.01.52.02.53.03.54.04.55.0NumberofprevalentCOVID-19casespredictedreportedPrevalentcases...CApr19Thu23Mon27MayTue05Sat09Wed13May17Thu21Mon25Fri29JuneFri05Tue09Sat13Wed17Jun21Date0.00.51.01.52.02.53.03.54.04.55.0NumberofprevalentCOVID-19casespredictedreportedPrevalentcases...BApr19Thu23Mon27MayTue05Sat09Wed13May17Thu21Mon25Fri29JuneFri05Tue09Sat13Wed17Jun21Date0.00.51.01.52.02.53.03.54.04.55.0NumberofprevalentCOVID-19casespredictedreportedPrevalentcases...Aby how wide the light green dots spread out) increases when parameters are estimated
individually, as would be expected. On the other hand, global estimation can introduce
a bias, as can, e.g., be seen from the predictions for missing values between May, 20 and
May, 25: Based on the observations before and after that gap, the true development in
this period has to be an increase in prevalent cases. Increases are related to higher external
pressure due to more incident cases in the population and are thus modeled by the parameter
β3. During that particular period, numbers of cases are however globally falling, and the
increase in prevalent cases is speciﬁc to the considered hospital. Thus, global estimation of
the corresponding parameter fails to model that development, introducing a bias in panels
A and B. When estimating that parameter individually, however, the increase in prevalent
cases is captured, as can be seen in panels C and D.

Finally, the trajectory of the exemplary hospital exhibits distinct phases of rising and
falling numbers of cases. This more generally applies to the overall development across
hospitals, implying that our modeling assumption of constant parameters may be (overly)
simplifying and time-dependent parameters would be better suited to capture these phases.
As there is no ground truth for the missing reports of the hospital in Figure 2, we further
evaluate the capability of our proposed model to bridge gaps of missing reports by randomly
censoring reports from hospitals with complete reporting, and assessing how well they are
recovered. Speciﬁcally, we consider all hospitals with no missing reports (463 in total) and
evaluate the performance of all models in recovering reports that were censored at random
at rater of 10%, 25%, 50% and 75%. In all scenarios the increment model provides the lowest
median recovery error across hospitals, and the gap in prediction performance increases for
higher proportions of censoring, indicating that our proposed model is particularly suited
to deal with larger gaps in reporting (for details, see Supplementary Table 6).

5 Discussion

Diﬀerentiable programming is part of a current paradigm shift in the ﬁeld of deep neural
networks towards incorporating model components, such as diﬀerential equations, that bet-
ter formalize knowledge on the problem at hand. We described an exemplary application of
diﬀerentiable programming for statistical modeling per se, to illustrate how such techniques
could also be useful in applied statistical work, e.g., for quick prototyping. In an exem-
plary scenario in a COVID-19 setting, characterized by a substantial amount of missing
daily reports, we have adapted a regression model for the increments of prevalent ICU cases
to ﬂexibly handle missing observations in the data, inspired by diﬀerential equations. Us-
ing a diﬀerentiable programming framework allowed for tailoring the model to the speciﬁc
requirements of the data, yet optimizing it eﬃciently.

Speciﬁcally, we have shown that our modeling strategy allows for more accurate predic-
tions on the given dataset compared to simple benchmark models. Moreover, the diﬀeren-
tiable programming framework provided a convenient tool to quickly explore variations of
the model with respect to global vs. individual estimation of parameters and to investigate
factors predominantly inﬂuencing prediction performance. It thus facilitated exploring the
eﬀect of model components and ultimately a more in-depth understanding of the problem.
Using data subsets deﬁned by sliding time intervals for model ﬁtting, we have investi-
gated the robustness of our method and optimization procedure and have found our results
individual parameter estimation to
with respect to prediction performance and global vs.

15

roughly generalize across subsets. Additionally, we have exemplarily illustrated the ability
of the model to bridge gaps of missing observations and have discussed the eﬀect of diﬀerent
global and individual parameters estimates on the prediction bias and variance.

With respect to the application setting of the ﬁrst COVID-19 wave, the dynamic sit-
uation of the pandemic exempliﬁes a scenario where we can beneﬁt from diﬀerentiable
programming as it allowed us to quickly prototype a model under time pressure and ﬂexibly
adapt it to the challenging data scenario with many missing values. Such an approach can
be more generally useful in future epidemic scenarios, when data collection is still ongoing
and incomplete, yet interpretable models with predictive capabilities that can be ﬂexibly
adapted to the challenge at hand are urgently needed.

While our models with diﬀerent combinations of global and individual parameters gen-
erally allow for an intuitive interpretation and the identiﬁcation of external pressure and
internal processes for individual hospitals, time-dependent parameters could be more suit-
able to accurately capture distinct phases of development in the data, which yet has to be
addressed in future research. In its current form, the assumption of time-constant parame-
ters can introduce bias that may lead to underestimation of overall less prominent trends.
Subsetting the data with a sliding window approach as in Section 4.4 and interpolating the
resulting parameters would be a ﬁrst step in that direction. Furthermore, the discussed
mixtures of individual and global parameters currently rely on a coarse procedure of taking
a global mean across all hospitals after each step. For further model reﬁnement, groups
of hospitals could be modeled together to uncover cluster structures within the dataset
and identify groups of hospitals sharing common developments. Such similarity could be
determined either based on the regression parameters or the predicted trajectories, and po-
tentially also take into account structural characteristics of hospitals. Despite these present
limitations, our method could also be more broadly applicable to general time-series data
with missing values from an incomplete data collection.

Yet, our main aim was to provide an example of how diﬀerentiable programming allows
to ﬂexibly combine diﬀerent tools and modeling strategies led by the requirements of a chal-
lenging modeling task, and to showcase model optimization with a gradient-based approach
in an easy-to-implement and eﬃcient way, rather than the speciﬁc modeling example. Diﬀer-
entiable programming can thus aid statistical modeling where established approaches, such
as maximum likelihood Fisher scoring, are not applicable and prove beneﬁcial particularly
in application-driven settings with a focus on prediction performance.

In short, integrating diﬀerentiable programming into statistical modeling can enrich the
statistician’s toolbox and be a step towards uniting the estimation-focused data modeling
and the prediction-oriented algorithmic culture and their respective tools, allowing the ﬁelds
to interact and mutually inspire each other.

References

Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Ghemawat, S.,
Irving, G., Isard, M., Kudlur, M., Levenberg, J., Monga, R., Moore, S., Murray, D. G.,
Steiner, B., Tucker, P., Vasudevan, V., Warden, P., Wicke, M., Yu, Y. & Zheng, X. (2016),
Tensorﬂow: A system for large-scale machine learning, in ‘12th USENIX Symposium
on Operating Systems Design and Implementation (OSDI 16)’, USENIX Association,
Savannah, GA, pp. 265–283.

16

Allen, L. J., Brauer, F., Van den Driessche, P. & Wu, J. (2008), Mathematical epidemiology,

Vol. 1945, Springer.

Baydin, A. G., Pearlmutter, B. A., Radul, A. A. & Siskind, J. M. (2017), ‘Automatic
diﬀerentiation in machine learning: A survey’, J. Mach. Learn. Res. 18(1), 5595–5637.

Bezanson, J., Edelman, A., Karpinski, S. & Shah, V. B. (2017), ‘Julia: A fresh approach to

numerical computing’, SIAM Review 59(1), 65–98.

Bischof, C., Khademi, P., Mauer, A. & Carle, A. (1996), ‘Adifor 2.0: automatic diﬀerentia-
tion of Fortran 77 programs’, IEEE Computational Science and Engineering 3(3), 18–32.

Breiman, L. (2001), ‘Statistical modeling: The two cultures (with comments and a rejoinder

by the author)’, Statistical Science 16(3), 199–231.

Chen, T. Q., Rubanova, Y., Bettencourt, J. & Duvenaud, D. (2018), Neural ordinary dif-

ferential equations, in ‘Advances in Neural Information Processing Systems’.

Cohen, S. N., Reisinger, C. & Wang, S. (2021), ‘Arbitrage-free neural-SDE market models’.

arXiv preprint: https://arxiv.org/abs/2105.11053.

Dandekar, R., Rackauckas, C. & Barbastathis, G. (2020), ‘A machine learning-aided global
diagnostic and comparative tool to assess eﬀect of quarantine control in COVID-19
spread’, Patterns 1(9), 100145.

de Avila Belbute-Peres, F., Smith, K., Allen, K., Tenenbaum, J. & Kolter, J. Z. (2018),
End-to-end diﬀerentiable physics for learning and control, in S. Bengio, H. Wallach,
H. Larochelle, K. Grauman, N. Cesa-Bianchi & R. Garnett, eds, ‘Advances in Neural
Information Processing Systems’, Vol. 31.

Degrave, J., Hermans, M., Dambre, J. & wyﬀels, F. (2018), ‘A diﬀerentiable physics engine

for deep learning in robotics’. arXiv preprint: https://arxiv.org/abs/1611.01652.

Efron, B. (2020), ‘Prediction, estimation, and attribution’, Journal of the American Statis-

tical Association 115(530), 636–655.

Fahrmeir, L. & Tutz, G. (2001), Multivariate Statistical Modelling Based on Generalized

Linear Models, Springer Series in Statistics, 2 edn, Springer-Verlag New York.

Friedman, J., Hastie, T. & Tibshirani, R. (2000), ‘Additive logistic regression: a statis-
tical view of boosting (with discussion and a rejoinder by the authors)’, Ann. Statist.
28(2), 337–407.

Griewank, A. (1989), On automatic diﬀerentiation, in ‘Mathematical Programming: Recent

Developments and Applications’, M. Iri and K. Tanabe, pp. 83–108.

Groha, S., Schmon, S. M. & Gusev, A. (2021), ‘A general framework for survival analysis

and multi-state modelling’. arXiv preprint: https://arxiv.org/abs/2006.04893.

Innes, M. (2018a),

‘Don’t unroll adjoint: Diﬀerentiating SSA-form programs’.

arXiv

preprint: https://arxiv.org/abs/1810.07951.

17

Innes, M. (2018b), ‘Flux: Elegant machine learning with Julia’, Journal of Open Source

Software 3(25), 602.

Innes, M., Edelman, A., Fischer, K., Rackauckas, C., Saba, E., Shah, V. B. & Tebbutt, W.
(2019), ‘A diﬀerentiable programming system to bridge machine learning and scientiﬁc
computing’. arXiv preprint: https://arxiv.org/abs/1907.07587.

Innes, M., Saba, E., Fischer, K., Gandhi, D., Rudilosso, M. C., Joy, N. M., Karmali,
T., Pal, A. & Shah, V. B. (2018), ‘Fashionable modelling with Flux’. arXiv preprint:
https://arxiv.org/abs/1811.01457.

Johnson, M., Frostig, R., Maclaurin, D. & Leary, C. (2018), ‘JAX; autograd and xla’,

https://github.com/google/jax. Accessed on December 4, 2020.

Kingma, D. P. & Ba, J. (2015), Adam: A method for stochastic optimization, in Y. Bengio
& Y. LeCun, eds, ‘3rd International Conference on Learning Representations, ICLR 2015,
San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings’.

LeCun, Y.

(2018),

‘Deep Learning est mort. Vive Diﬀerentiable Programming!’,
https://www.facebook.com/yann.lecun/posts/10155003011462143. Accessed on Decem-
ber 4, 2020.

Li, T.-M., Aittala, M., Durand, F. & Lehtinen, J. (2018b), ‘Diﬀerentiable Monte Carlo ray

tracing through edge sampling’, ACM Trans. Graph. 37(6), 222.

Li, T.-M., Gharbi, M., Adams, A., Durand, F. & Ragan-Kelley, J. (2018a), ‘Diﬀerentiable
programming for image processing and deep learning in Halide’, ACM Trans. Graph.
37(4), 139.

Luo, X.-Z., Liu, J.-G., Zhang, P. & Wang, L. (2020), ‘Yao.jl: Extensible, Eﬃcient Frame-

work for Quantum Algorithm Design’, Quantum 4, 341.

Pearlmutter, B. A. & Siskind, J. M. (2008), ‘Reverse-mode ad in a functional framework:

Lambda the ultimate backpropagator’, ACM Trans. Program. Lang. Syst. 30(2).

Rackauckas, C., Anantharaman, R., Edelman, A., Gowda, S., Gwozdz, M., Jain, A., Laugh-
man, C., Ma, Y., Martinuzzi, F., Pal, A., Rajput, U., Saba, E. & Shah, V. B. (2021),
‘Composing modeling and simulation with machine learning in Julia’. arXiv preprint:
https://arxiv.org/abs/2105.05946.

Rackauckas, C., Edelman, A., Fischer, K., Innes, M., Saba, E., Shah, V. B. & Tebbutt,
W. (2020b), ‘Generalized physics-informed learning through language-wide diﬀerentiable
programming’, AAAI Spring Symposium: MLPS 2020 .

Rackauckas, C., Ma, Y., Martensen, J., Warner, C., Zubov, K., Supekar, R., Skinner, D. &
Ramadhan, A. (2020a), ‘Universal diﬀerential equations for scientiﬁc machine learning’.
arXiv preprint: https://arxiv.org/abs/2001.04385.

Rackauckas, C., Ma, Y., Noack, A., Dixit, V., Mogensen, P. K., Byrne, S., Mad-
dhashiya, S., Santiago Calderón, J. B., Nyberg, J., Gobburu, J. V. & Ivaturi,

18

V. (2020c),
formance pharmaceutical modeling and simulation platform’.
https://www.biorxiv.org/content/10.1101/2020.11.28.402297v1.

‘Accelerated predictive healthcare analytics with Pumas, a high per-
bioRxiv preprint:

Reﬁsch, L., Lorenz, F., Riedlinger, T., Taubenböck, H., Fischer, M., Graben-
‘Data-driven pre-
medRxiv preprint:

henrich, L., Wolkewitz, M., Binder, H. & Kreutz, C. (2021),
diction of covid-19 cases in germany for decision making’.
https://www.medrxiv.org/content/early/2021/06/25/2021.06.21.21257586.

Rumelhart, D., Hinton, G. & Williams, R. (1986),

‘Learning representations by back-

propagating errors’, Nature 323, 533–536.

Schelker, M., Raue, A., Timmer, J. & Kreutz, C. (2012), ‘Comprehensive estimation of input
signals and dynamics in biochemical reaction networks’, Bioinformatics 28(18), i529–i534.

Wang, F., Wu, X., Essertel, G. M., Decker, J. M. & Rompf, T. (2018), ‘Demystifying
diﬀerentiable programming: Shift/reset the penultimate backpropagator’. arXiv preprint:
https://arxiv.org/abs/1803.10228.

Wang, Y., Chee, M. C., Edher, Z., Hoang, M. D., Fujimori, S., Kathirgamanathan, S.
& Bettencourt, J. (2020), ‘Forecasting black sigatoka infection risks with latent neural
ODEs’. arXiv preprint: https://arxiv.org/abs/2012.00752.

Zhou, F. & Li, L. (2021), ‘Forecasting reservoir inﬂow via recurrent neural ODEs’, Proceed-

ings of the AAAI Conference on Artiﬁcial Intelligence 35(17), 15025–15032.

19

Supplementary Tables and Figures for the Manuscript
Using Diﬀerentiable Programming for Flexible Statistical
Modeling

S1 Original Julia code of the increment model loss function

and gradient descent optimization

Original Julia implementation of the loss function of our proposed model, including a loop
and control ﬂow elements.

function loss (y, z, r, beta)

sqerror = 0.0 # squared error
firstseen = false # set to true after skipping potential missings
last_y = 0.0 # prevalent cases from previous time point
contribno = 0.0 # number of non-missing observations
for t = 1:(length(y))

# skip missings at the start until first reported value
if !firstseen

if r[t] == 1

firstseen = true
last_y = y[t]

else

continue

end

else # make a prediction for the current increment

pred_dy = beta[1] + beta[2] * last_y + beta[3] * z[t-1]
if r[t] == 1

dy = y[t] - last_y
sqerror += (dy - pred_dy)ˆ2
contribno += 1.0
last_y = y[t]

else

last_y += pred_dy

end

end

end
return sqerror/contribno # return MSE over all reported time points

end

The gradient descent algorithm with the parameter update from Equation (5) can then

be implemented in just a few lines:

beta = [0.0; 0.0; 0.0]
for steps = 1:nsteps

gradloss = gradient(arg -> loss(y, z, r, arg), beta)[1]
beta .-= eta .* gradloss

end

1

S2 Comparison of loss curves based on last observation car-

ried forward vs. bridging gaps without imputation

Figure S1: Loss curves for a least-squares loss from a classical linear regression model (cor-
responding to standard maximum likelihood estimation) based on last-observation-carried-
forward imputation (shown in orange) versus our proposal of ﬂexibly bridging gaps of missing
reports without imputation and a diﬀerentiable-programming-based optimization (shown in
blue) for one exemplary hospital from the DIVI registry. In each panel, the x-axis corre-
sponds to one of the three coeﬃcients to be estimated and the y-axis to the corresponding
loss values.

2

−0.4−0.3−0.2−0.10.0Parameterforprevalentcases0.20.40.60.81.0Loss−0.3−0.2−0.10.00.1Interceptparameter0.20.40.60.81.0LossIncrementmodelLinearregressionModel−0.2−0.10.00.10.20.3Parameterforpredictedincidences0.20.40.60.81.0LossS3 Sensitivity Analysis

S3.1 Using the upper and lower bound of the conﬁdence interval for the
maximum likelihood estimate of the predicted incidences used as a
covariate

Table 1: Prediction performance of benchmark models and the proposed increment model
with diﬀerent combinations of global and individual parameters, where the upper bound of
the conﬁdence interval for the maximum likelihood estimate of the predicted incidences was
used as a covariate in the model.

Prediction model

Squared error
Sum
86.0
89.239
84.342
173.980

Zero model
Mean model
Modiﬁed mean model
Linear regression
Increment model with global β2 for prevalent cases
global β1; individual β3
individual β1; individual β3
global β1; global β3
individual β1; global β3
Increment model with individual β2 for prevalent cases
individual β1; global β3
individual β1; individual β3
global β1; individual β3
global β1; global β3

79.310
76.940
76.046
75.839

97.836
96.349
90.629
88.308

0.079
0.078
0.074
0.072

0.064
0.063
0.062
0.062

Mean 1st Quartile Median 3rd Quartile
0.07
0.072
0.069
0.141

0.0
0.002
0.0
0.016

0.0
0.0
0.0
0.001

0.0
0.0
0.0
0.0

0.0
0.0
0.0
0.0

0.0
0.0
0.0
0.0

0.0
0.0
0.0
0.0

0.0
0.0
0.0
0.0

0.001
0.001
0.0
0.0

0.0
0.002
0.003
0.0

3

Table 2: Prediction performance of benchmark models and the proposed increment model
with diﬀerent combinations of global and individual parameters, where the lower bound of
the conﬁdence interval for the maximum likelihood estimate of the predicted incidences was
used as a covariate in the model.

Prediction model

Squared error
Sum
89.239
84.342
86.0
177.554

Mean model
Modiﬁed mean model
Zero model
Linear regression
Increment model with global β2 for prevalent cases
global β1; individual β3
global β1; global β3
individual β1; individual β3
individual β1; global β3
Increment model with individual β2 for prevalent cases
individual β1; global β3
global β1; global β3
global β1; individual β3
individual β1; individual β3

77.447
74.714
72.835
72.751

93.414
89.979
89.866
87.715

0.063
0.061
0.059
0.059

0.076
0.073
0.073
0.071

Mean 1st Quartile Median 3rd Quartile
0.072
0.069
0.07
0.144

0.002
0.0
0.0
0.013

0.0
0.0
0.0
0.001

0.0
0.0
0.0
0.0

0.0
0.0
0.0
0.0

0.0
0.0
0.0
0.0

0.0
0.0
0.0
0.0

0.0
0.0
0.0
0.0

0.0
0.0
0.0
0.0

0.0
0.0
0.0
0.0

S3.2 Relative improvement of the increment model over benchmark mod-

els across subsets based on shorter time intervals

S3.2.1 Relative improvement over the zero model

Table 3: Quantiles of improvement in prediction error of the proposed increment model over
the modiﬁed mean model, obtained across all time intervals half as long as the entire time
period.

Increment model parameters

Diﬀerences of squared error
(modiﬁed mean model - increment model)
1st Quartile Median

3rd Quartile

global parameter β2 for prevalent cases
-18.677
global β1; individual β3
-2.609
individual β1; individual β3
-0.307
global β1; global
individual β1; global
2.619
individual parameter β2 for prevalent cases
global β1; global β3
global β1; individual β3
individual β1; individual β3
individual β1; global β3

3.077
-3.15
-3.66
4.443

0.364
3.825
4.116
6.289

8.706
6.741
5.456
10.593

3.982
8.489
8.985
10.211

12.263
13.938
14.516
16.281

4

S3.2.2 Relative improvement over the modiﬁed mean model

Table 4: Quantiles of improvement in prediction error of the proposed increment model over
the zero model, obtained across all time intervals half as long as the entire time period.

Increment model parameter

Diﬀerences of squared error
(zero model - increment model)
1st Quartile Median 3rd Quartile

global parameter β2 for prevalent cases
-18.295
global β1; individual β3
-0.467
individual β1; global β3
-2.436
global β1; global β3
individual β1; individual β3
-4.197
individual parameter β2 for prevalent cases
global β1; global β3
individual β1; global β3
global β1; individual β3
individual β1; individual β3

0.24
1.987
-5.496
-4.635

-1.368
3.545
1.294
2.283

4.592
7.742
3.419
3.164

4.112
6.599
7.5
8.006

10.704
12.08
12.292
12.843

S3.2.3 Relative improvement over the linear regression model based on last-

observation-carried-forward

Table 5: Quantiles of improvement in prediction error of the proposed increment model over
the linear regression model based on last-observation-carried-forward imputation, obtained
across all time intervals half as long as the entire time period.

Increment model parameter

Diﬀerences of squared error
(linear regression - increment model
3rd Quartile
1st Quartile Median

global parameter β2 for prevalent cases
99.001
global β1; individual β3
111.08
individual β1; individual β3
108.934
global β1; global β3
111.081
individual β1; global β3
individual parameter β2 for prevalent cases
global β1; global β3
global β1; individual β3
individual β1; individual β3
individual β1; global β3

112.318
100.857
103.263
116.576

158.224
166.88
167.659
168.264

172.188
152.108
155.078
171.549

256.425
258.755
273.855
276.345

244.426
251.917
255.066
259.935

5

S4 Validation: Recovering censored values

Prediction model

Squared error

Mean

1st Quartile Median 3rd Quartile

0.042
0.042
0.043
0.06
0.043

0.116
0.115
0.117
0.179
0.13

10% of all reports censored at random
0.002
Mean model
0.002
Modiﬁed mean model
0.002
Zero model
0.003
Linear regression
Increment model
0.002
25% of all reports censored at random
0.006
Mean model
0.006
Modiﬁed mean model
0.006
Zero model
0.007
Linear regression
Increment model
0.004
50% of all reports censored at random
0.016
Mean model
0.016
Modiﬁed mean model
0.016
Zero model
0.027
Linear regression
0.011
Increment model
75% of all reports censored at random
0.039
Mean model
0.039
Modiﬁed mean model
0.04
Zero model
0.156
Linear regression
0.017
Increment model

0.825
0.823
0.846
24582.387
0.766

0.334
0.333
0.341
1.009
0.315

0.011
0.011
0.011
0.015
0.009

0.031
0.03
0.032
0.046
0.024

0.088
0.087
0.089
0.179
0.062

0.205
0.205
0.209
1.499
0.129

0.035
0.035
0.035
0.049
0.03

0.097
0.094
0.098
0.144
0.085

0.274
0.273
0.281
0.549
0.219

0.631
0.63
0.654
7.024
0.474

Table 6: Performance of the increment model with all parameters individually estimated
and the benchmark models on recovering censored reports that were deleted at random
at ﬁxed rates of 10%, 25%, 50% and 75% in all 463 DIVI hospitals with no missing data.
For each hospital and each rate, the speciﬁc proportion of reports was randomly censored.
All models were ﬁt on the resulting data as described in Section 4.4 of the main text
(i.e., censored observations were imputed with last-observation carried forward for the
benchmark models and the same optimization was used for the increment model). We then
calculated the mean squared squared error between the predicted and the true trajectory
across the entire time interval. We repeated the censoring and ﬁtting process 10 times for
each hospital and scenario and averaged the error. Here, we report the mean, median and
1st and 3rd quartile of these errors across all 463 hospitals.

6

