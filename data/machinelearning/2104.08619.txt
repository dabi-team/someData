1
2
0
2

y
a
M
9

]

G
L
.
s
c
[

2
v
9
1
6
8
0
.
4
0
1
2
:
v
i
X
r
a

Optimal Counterfactual Explanations for Scorecard modelling

Guillermo Navas-Palencia1

1g.navas.palencia@gmail.com

May 11, 2021

Abstract

Counterfactual explanations is one of the post-hoc methods used to provide explainability to
machine learning models that have been attracting attention in recent years. Most examples in
the literature, address the problem of generating post-hoc explanations for black-box machine
learning models after the rejection of a loan application. In contrast, in this work, we investi-
gate mathematical programming formulations for scorecard models, a type of interpretable model
predominant within the banking industry for lending. The proposed mixed-integer programming
formulations combine objective functions to ensure close, realistic and sparse counterfactuals using
multi-objective optimization techniques for a binary, probability or continuous outcome. More-
over, we extend these formulations to generate multiple optimal counterfactuals simultaneously
while guaranteeing diversity. Experiments on two real-world datasets conﬁrm that the presented
approach can generate optimal diverse counterfactuals addressing desired properties with assum-
able CPU times for practice use.

1 Introduction

The use of interpretable machine learning models and the application of explainability methods to
enhance the understanding of algorithmic decisions from black-box models have become crucial due
to the widespread use of machine learning for decisions impacting society. Among the available
explainability methods, counterfactual explanations [16] is one of the most promising for explain-
ing predictions of black-box machine learning models by generating human-understandable post-hoc
explanations. Counterfactual explanations provide information valuable to determine the changes re-
quired to the input variables to modify the outcome of a decision-making system without revealing
the underlying algorithmic details. The changes, although possibly drastic, are more realizable when
only a few variables require minor modiﬁcations. Thus, a practical counterfactual should be simple
and as close as possible to the input data while obtaining a change on the desired outcome.

An important assumption for counterfactual explanations to be useful is that the underlying model
does not diﬀer when a user enters the system after a ﬁrst unsatisfactory outcome. If this assumption
holds, a counterfactual guarantees the desired outcome upon altering the input variables appropriately.
From a fairness perspective, counterfactuals might be useful as a fairness evaluator to provide

evidence that decisions generated by a system may be discriminatory.

Explainable machine learning has been of interest to the healthcare (e.g., medical diagnosis) and
ﬁnance (e.g., lending) communities. Most examples in the literature, address the problem of generating
post-hoc explanations after the rejection of a loan application. These examples tend to use black-
box machine learning models, while in practice, decision-making systems for consumer ﬁnance in the
banking industry employ globally interpretable scorecard models approved by banking regulators.

1.1 Related work

Existing optimization-based approaches for generating counterfactual explanations starts with the
seminal work by Watcher et al. [16]. We focus on this type of methods and refer to [15] for a complete

1

 
 
 
 
 
 
and comprehensive review of alternative approaches. The work in [16] solves the Lagrangian relaxation
of the general optimization problem using gradient-based methods, whereas other approaches [13, 14]
solve the problem while providing a certiﬁcate of optimality or infeasibility when the underlying
estimator is expressible in mathematical modelling terms, thus solvable by classical optimization
algorithms. Furthermore, the latter two works develop procedures to generate diverse counterfactuals
by iteratively adding new constraints. A more general approach generating diverse counterfactuals
using gradient-based methods is studied in [10]. To generate realistic counterfactuals, the authors in
[6] include new terms in the objective function to account for the empirical data distribution. Finally,
in the context of multi-objective optimization for counterfactual explanations, we note the work in
[2], where an evolutionary strategy is proposed to generate multiple counterfactuals while devising the
Pareto frontier.

1.2 Contributions

In this work, we develop several mathematical optimization formulations to generating a single or
multiple counterfactual explanations for a binary, probability and continuous desired outcome. These
mixed-integer programming formulations incorporate constraints to address the desired properties re-
quired by a reliable and eﬃcient counterfactual. Furthermore, we discuss multi-objective optimization
strategies to managing the various objectives involved in the counterfactual generation.

The remainder of the paper is organized as follows. Section 2 introduces the mathematical pro-
gramming framework specialized for scorecard modelling and the mixed-integer programming formu-
lation for each outcome type. In addition, the extended formulation to impose diversity constraints is
presented as well as several techniques to handle multiple objectives. Section 3 describes implemen-
tation details and includes experiments on real-world datasets to assess the quality of the generated
counterfactuals and the performance of the presented approach. Finally, in Section 4, we present our
conclusions.

2 Mathematical programming framework

In the following Section, we ﬁrst introduce the general optimization framework to generating coun-
terfactual explanations for scorecard modelling, and some properties deﬁning a good counterfactual
explanation. Secondly, we focus on mathematical programming formulations considering a scoring
model taking into account the properties previously discussed.

We start considering a dataset with n samples and p features, where each xi = [xi1, xi2, . . . , xip],
and a discrete or continuous target yi ∈ R. We denote the desired outcome as y′ and x′ the counter-
factual explanation. Also, we deﬁne a model f , with predicted outcome deﬁned as f (x). The objective
is to search for a counterfactual x′ the closest to the data point x such that the desired outcome y′ is
achieved. In [16], it is deﬁned the problem of ﬁnding counterfactual explanations as an optimization
problem. The optimization problem (1) aims to minimize the distance function, d(x, x′), between the
input data point x and the counterfactual x′ subject to the satisﬁability of the constraint f (x′) = y′.

min
x′
s.t.

d(x, x′)

f (x′) = y′

(1a)

(1b)

The equality constraint in (1) might be replaced by a l-norm constraint given a user-deﬁned
tolerance ǫ. This formulation is more adequate when the desired outcome is continuous or a class
label probability.

min
x′
s.t.

d(x, x′)

|f (x′) − y′|l ≤ ǫ

2

Several methods solve the constrained problem (1) by reformulating it as an unconstrained problem,
adding the equality constraint as a penalty in the objective function,

min
x′ max

λ

λ (f (x′) − y′)2 + d(x, x′).

(2)

The bilevel unconstrained problem (2) might be solved iteratively by increasing the penalty parameter
λ to ensure the desired outcome satisﬁes, within the tolerance ǫ, the constraint while minimizing the
distance function.

The consensus, within the machine learning explainability ﬁeld, about desired properties of an

eﬀective counterfactual explanation, encompasses:

• Validity: a counterfactual explanation producing the desired outcome y′. For classiﬁcation mod-
els, some methods relax this constraint by searching for a counterfactual explanation attaining
an outcome as closely as possible to y′. This relaxation might not be appropriate to determine if
a problem is infeasible, i.e., to certify that a model cannot provide a counterfactual x′ to change
the outcome of x. For fairness studies, this information can be as relevant as the generated
counterfactuals.

• Proximity: a counterfactual explanation should be as close as possible to the original instance
with respect to feature values. Intuitively, x′ becomes more doable as it approaches x since fewer
considerable changes are required.

• Sparsity: a counterfactual explanation ideally should change as few features as possible to

increase its understanding and eﬀectiveness.

• Actionability: a counterfactual must exclude value changes on non-actionable features.

• Diversity: it is desired to generate multiple diverse counterfactual explanations to provide several
alternatives to obtaining the desired outcome. This is convenient since not all individual might
be equally capable of modifying the same features.

• Data Manifold closeness or connectedness: a counterfactual explanation should be plausible,
considering changes in feature values that are likely with the empirical data and correlations
among variables.

• Generation time: fast generation of one or multiple counterfactual explanations. This property

is especially relevant for some applications where immediate response is required.

2.1 Scorecard modelling

Scorecard modelling comprises the use of simple interpretable linear models to make predictions.
Scorecard models are widely employed in sectors such as the ﬁnancial industry (primarily credit risk
modelling) or healthcare, requiring interpretable models with a small number of variables satisfying
multiple behavioural and operational constraints. The common pipeline to develop scorecard models
involves the following steps:

• Data processing: use of binning techniques such as optimal binning [11] to discretize variables.
Subsequently, apply a data transformation, generally Weight-of-Evidence (WoE) for a binary
target or mean transformation for a continuous target. This step transforms the input data into
binned numerical data without missing and outlier data.

• Linear model: ﬁt a linear model using the transformed data. Some constraints are usually
incorporated, e.g., sparsity constraints are included to select only a small set of predictive features
to be part of the scorecard.

3

• Scorecard: the score points are calculated using the coeﬃcients of the linear model and the data
transformation assigned to each bin and variable. For example, given a feature i with Bi bins,
j = 1, . . . , Bi, and linear model coeﬃcient ci the corresponding score point sij is given by

sij = citij ,

where tij is the data transformation depending on the target type. Finally, scaling methods are
applied to convert score points to a common scale system.

We provide an example of a scorecard in Table 1. The discrete nature, simplicity and relatively
small size of the scorecard model make it adequate to eﬃciently extract optimal counterfactual expla-
nations using combinatorial optimization techniques.

Feature
ExternalRiskEstimate
ExternalRiskEstimate
ExternalRiskEstimate
ExternalRiskEstimate

Bin
[-∞, 59.5)
[59.5, 63.5)
[63.5, 65.5)
[65.5, ∞)

Points
5.43
11.62
18.15
25.44

Table 1: Example of scorecard for the feature ExternalRiskEstimate.

2.2 Counterfactual explanation

In this section, we present the addressed main themes of research and desired properties of counterfac-
tual explanations, described in the recent review [15], from a mathematical programming perspective.
Then, we deﬁne three mixed-integer programming formulations for a single counterfactual explanation
depending on the output type (binary, probability and continuous).

Proximity. The proximity metric d(x, x′), measures the distance of a counterfactual x′ from the
input data point x. The intuition behind this metric is that x′ is more realizable as it approaches x.
Formally, it can be deﬁned using the l-norm of two vectors (x, x′).

d(x, x′) = kx − x′kl .

The metric d(x, x′) with l = 1 or l = 2 are generally used, but other distances such as the Huber
loss can also be considered.
If l = 1, the proximity metric can be linearized obtaining a linear
programming (LP) formulation. For l = 2 and Huber loss, the proximity metric is representable using
second-order cone programming (SOCP) and can be reformulated as a quadratic programming (QP).
To standardize the variability of diﬀerent features, the distance metric can be weighted by the inverse
median absolute deviation (MAD) or the inverse range. For l = 1 and inverse range scaling,

p

d(x, x′|w) =

wi |xi − x′

i| ,

i=1
X

where wi is the inverse of the value range of feature i, extracted from the observed data.

Sparsity. Counterfactual explanations with a small number of changed features are preferred. Sparse
counterfactuals are easier to understand and more achievable. The sparsity requirement can be incor-
porated to the objective function utilizing the term kx − x′k0 as in [2], or added to the formulation as a
constraint. Given the maximum number of changed features Θ, and the binary variables ai, i = 1, . . . , p
indicating whether a feature changed, we have

p

p

kx − x′k0 =

ai,

ai ≤ Θ.

i=1
X

i=1
X

4

Actionability. Not all model features are mutable (e.g., age, sex) or should be considered actionable
(e.g., marital status). To exclude changes on these sensitive features, we add the following constraint

ai = 0,

i /∈ A,

where the set A contains the indices of the actionable features. The recent work in [14] also considers
features that are conditionally immutable. An example of this type of feature is the achieved education
level, being a non-decreasing feature.

Data Manifold closeness. Several existing methods extract counterfactual explanations that might
be considered unrealistic due to omitting the empirical data distribution such us the correlations
among features. Therefore, to determine plausible counterfactuals, the empirical data distribution
must be included in the objective function, so that the counterfactual are close to the training data
and incorporate the observed correlations among features.

In [6], the previous considerations are tackled by adding a new term in the objective function based

on the Mahalanobis distance. The Mahalanobis distance is deﬁned for x′ ∈ Rp as

dM (x′ | µ, Σ) =

(x′ − µ)T Σ−1(x′ − µ),

where µ is the estimated sample mean and Σ is the sample covariance matrix. Given Σ−1 < 0, Σ can
be decomposed using Cholesky decomposition as Σ−1 = F T F , where F is a lower triangular matrix,
thus the Malahanobis distance can be rewritten as

q

dM (x′ | µ, F ) = kF (x′ − µ)k2 .

In [6], the l1-norm is used instead of the l2-norm to linearize the objective function,

dM1 (x′ | µ, F ) = kF (x′ − µ)k1 .

We linearize dM1 using the variable splitting technique to handle the l1-norm, obtaining

min
x′

dM1 (x′ | µ, F )

=⇒

min
x′

p

m+

i + m−
i

i=1
X
s.t. m+

(cid:0)
i − m−

i =

m+

i , m−

i ≥ 0,

(cid:1)
p

j=i
X

Fij (x′

j − µj),

i = 1, . . . , p

i = 1, . . . , p

There exist other robust versions of the Mahalanobis distance which could be suitable, some
are discussed in [1]. Finally, other devised approaches to taking into account the relantionships
among features include the computation of the weighted average distance between x and the k nearest
observed data points [2, 6], which might be considered an empirical approximation of how likely x
originates from the distribution of the observed data.

Diversity Some proposed algorithms are capable of generating various counterfactual explanations
simultaneously for a given input data point x. A small set of diverse counterfactuals is useful to decide
which of them are more easily achievable. Diverse is generally incorporated as a term maximizing
the diﬀerence among counterfactual feature values and/or changed features [2, 10]. Other algorithms
[7, 14], based on mathematical optimization formulations, solve the same problem iteratively adding
constraints to impose diversity, i.e., ensuring that new counterfactuals are substantially diﬀerent from
the previous ones.

5

2.2.1 Formulation for counterfactual binary outcome

First, we consider the formulation for a binary classiﬁcation problem with desired outcome y′ ∈ {0, 1}.
As previously stated, for scoring modelling we focus on generalized linear models, which decision
function is deﬁned by

p

Note that if the model is ﬁtted with an intercept constant, then the decision function is given by

i=1
X

φ(x′|c) =

cix′
i.

p

φ(x′|c) = c0 +

cix′
i.

i=1
X

Let us deﬁne the parameters of the proposed mathematical programming formulation:

y′ ∈ {0, 1}
p ∈ N
x ∈ Rp
w ∈ Rp
Bi ∈ N
woeij ∈ R

F ∈ Rp×(p+1)
µ ∈ Rp
A ∈ Np
Θ ∈ N
M1, M2 ∈ R

λ1, λ2 ∈ R≥0
ǫ ∈ R>0

desired binary outcome.

number of features.
input data point.

weights to standardize feature space variability.
number of bins per feature.

Weight-of-Evidence per feature and bin.

Cholesky decomposition of the inverse sample covariance matrix.
estimated sample mean.

indices of actionable features.
maximum number of features to be modiﬁed.

minimum and maximum achievable score.
weights of the objective functions.

slack parameter.

As a part of the model data preparation, a preprocessing step is devised to exclude the values of

x from the set of WoE values woei∗ for each feature. Thus, woei∗ satisﬁes

Bi = |woei∗|,

xi /∈ woei∗,

i = 1, . . . , p.

This step simpliﬁes the formulation to detect those features that are modiﬁed, avoiding the use of
l0-norm terms in the objective function. The big-M parameters M1 and M2 represent the minimum
and maximum achievable score, respectively deﬁned by

M1 =

p

i=1
X

ci min

j=1...,Bi

{woeij }, M2 =

p

i=1
X

ci max

j=1...,Bi

{woeij}

i , t−

i , m+

i and m−

The proposed mixed-integer linear programming (MILP) formulation in detailed in (3). The vari-
ables t+
i , and constraints (3b) and (3d) are part of the variable splitting linearization
approach for the proximity and closeness objective function, respectively. The constraint (3c) imposes
that the counterfactual x′ must be composed by the input data point values if zij = 0 and actual
WoE values, otherwise. The constraint (3g) forces to ﬁx the input values for non-actionable features.
Since y′ is a parameter that changes the behaviour of the decision function φ(x′|c), the inequalities

in (3i) can be replaced by a single inequality depending on the value of y′. Hence,

φ(x′|c) > 0 ≈ φ(x′|c) ≥ ǫ,
φ(x′|c) ≤ 0,

y′ = 1,
y′ = 0,

(

6

and we use the parameter ǫ, close to relative tolerance (e.g., ǫ = 10−6), to avoid issues with classifying
the equality φ(x′|c) = 0.

The parameters λ1 and λ2 are the weights for the proximity and closeness objective function,
respectively. An objective function as a weighted sum of functions is a conventional approach to
handle more than one objective function due to its simplicity. However, this method is not necessarily
the most suitable for all cases. Various methods for handling multiple objective functions are discussed
in Section 2.4.

p

p

min λ1

wi

i + t−
t+
i

+ λ2

m+

i + m−
i

s.t.

i=1
X
i − t−
t+

(cid:0)

(cid:1)
i = xi − x′
i,
Bi

i=1
X

(cid:0)

(cid:1)

x′
i = xi +

(woeij − xi) zij ,

j=1
X

p

Fij (x′

j − µj),

j=i
X

m+

i − m−

i =

Bi

ai =

zij,

j=1
X

ai ≤ 1,
ai = 0,

p

ai ≤ Θ

i=1
X
(M1 − ǫ)(1 − y′) + ǫ ≤ φ(x′|c) ≤ M2y′
i ∈ R,
x′
zij ∈ {0, 1},
ai ∈ {0, 1},
i , t−
t+
i ≥ 0,
i , m−
m+

i ≥ 0,

(3a)

i = 1, . . . , p

(3b)

i = 1, . . . , p

(3c)

i = 1, . . . , p

(3d)

i = 1, . . . , p

(3e)

i = 1, . . . , p

i = 1, . . . , p : i /∈ A

i = 1, . . . , p
i = 1, . . . , p, j = 1, . . . , Bi
i = 1, . . . , p

i = 1, . . . , p

i = 1, . . . , p

(3f)

(3g)

(3h)

(3i)

(3j)
(3k)

(3l)

(3m)

(3n)

2.2.2 Formulation for counterfactual probability outcome

In this case, the problem consists of adjusting the probability output y′ ∈ [0, 1], e.g., determine the
changes required to reduce the probability of default from 0.6 to 0.4. The logistic regression and other
generalized linear models for classiﬁcation use the logistic function,

to model the probability of the event y′ = 1. The previous MILP formulation can be extended by
adding a new term in the objective function with the l-norm of the diﬀerence

f (x) =

1
1 + e−x ,

(4)

or enforcing a constraint of the form

l
(cid:13)
(cid:13)
(cid:13)
(cid:13)
1
1 + e−φ(x′|c) .
The incorporation of the non-convex function (4), leads to a non-convex mixed-integer nonlinear
programming (MINLP) formulation, which is signiﬁcantly more challenging to solve than the previous

(6)

S

1
1 + e−φ(x′|c)

y′ −
(cid:13)
(cid:13)
(cid:13)
(cid:13)
y′

(5)

7

MILP. A common approach to solving non-convex MINLP is to replace a non-convex function with a
continuous piecewise linear approximation, thus obtaining a tractable MILP, at the cost of enlarging
the resulting formulation. We approximate the logistic function using a continuous piecewise linear
function with R segments with coeﬃcients (βr, αr) for r = 1, . . . , R such that

f (x) ≈ ˜f (x) = αrx + βr,

x ∈ [br−1, br],

r = 1, . . . , R,

where the pair of break points [br−1, br], r = 1, . . . , R form the interval of each segment. The piecewise
linear approximation is obtained using R − 1 breakpoints in the interval [M1, M2] satisfying

max
x∈[M1,M2]

f (x) − ˜f (x)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

< ǫapprox.

Note that there is a trade-oﬀ between accuracy and the number of segments R since as R increases
the approximation improves, but the problem size increases, possibly worsening solution times. There
are several strategies to select the break points br. Common strategies are selecting break points
uniformly in a given interval, or a Greedy approach where the set of break points is incrementally
constructed by adding a new break point in the segment with the largest approximation error.

The resulting formulation after applying the discussed linearization is given by

p

p

min λ1

wi

i + t−
t+
i

+ λ2

m+

i + m−
i

(cid:0)
q+ + q−

i=1
X
+ λ3
(3b - 3h)

(cid:0)

(cid:1)

i=1
X

(cid:0)

(cid:1)

(cid:1)

s.t.

(7a)

(7b)

(7c)

R

hr = φ(x′|c)

r=1
X
br−1sr ≤ hr ≤ brsr,
R

(αrhr + βrsr) = f

r=1
X
R

sr = 1

r=1
X
q+ − q− = f − y′
i ∈ R,
x′
zij ∈ {0, 1},
ai ∈ {0, 1},
i , t−
t+
hr ∈ R,
sr ∈ {0, 1},
q+, q−, f ≥ 0

i ≥ 0,

r = 1, . . . , R

(7d)

(7e)

(7f)

(7g)
(7h)

(7i)
(7j)

(7k)

(7l)
(7m)

(7n)

i = 1, . . . , p
i = 1, . . . , p; j = 1, . . . , Bi
i = 1, . . . , p

i = 1, . . . , p

r = 1, . . . , R
r = 1, . . . , R

Now, we describe the main diﬀerences with respect to the formulation for a binary outcome. First,
the third term in (7a), λ3 (q+ + q−), and the constraint (7g) represent the linearization of (5) when
l = 1. Second, the constraints (7c - 7f) is the piecewise linear approximation of the logistic function
(4). Moreover, as previously discussed, the third term in the objective function can be replaced by
the constraint (6). This can be accomplished by adding the constraint f ≤ y′ or f ≥ y′ and removing
the third term from the objective. Also, using the previous modiﬁcation, the auxiliary variables q+
and q− and the constraint (7g) are no longer needed.

8

2.2.3 Formulation for counterfactual continuous outcome

In the case of a continuous target, the problem consists of approximating the desired output y′. Using
the linear model φ(x′|c), the following term is included in the objective function,

ky′ − φ(x′|c)kl,

l ∈ {1, 2}.

(8)

Besides, the formulation might be complemented with an additional constraint added to enforce a
minimum or maximum desired output,

y′ ≥ φ(x′|c),

y′ ≤ φ(x′|c).

Note that, as described in the probability outcome case, the l-norm term can also be replaced com-
pletely by one of the above constraints. Given the discrete search space of x′, the equality constraint
y′ = φ(x′|c) is not contemplated since it could often lead to an infeasible formulation.

We propose a MILP formulation of the form:

p

p

min λ1

wi

i + t−
t+
i

+ λ2

m+

i + m−
i

(cid:1)

i=1
X
(cid:0)
q+ + q−
+ λ3
i − t−
t+
i = xi − x′
i,
(cid:1)
(cid:0)
Bi

s.t.

i=1
X

(cid:0)

(cid:1)

x′
i = xi +

(meanij − xi) zij,

j=1
X

p

Fij (x′

j − µj),

j=i
X

m+

i − m−

i =

Bi

ai =

zij,

j=1
X

ai ≤ 1,
ai = 0,

p

ai ≤ Θ

i=1
X
q+ − q− = φ(x′|c) − y′
i ∈ R,
x′
zij ∈ {0, 1},
ai ∈ {0, 1},
i , t−
t+
m+
i , m−
i ≥ 0,
q+, q−, f ≥ 0

i ≥ 0,

(9a)

i = 1, . . . , p

(9b)

i = 1, . . . , p

(9c)

i = 1, . . . , p

(9d)

i = 1, . . . , p

(9e)

i = 1, . . . , p

i = 1, . . . , p : i /∈ A

i = 1, . . . , p
i = 1, . . . , p, j = 1, . . . , Bi
i = 1, . . . , p

i = 1, . . . , p

i = 1, . . . , p

(9f)

(9g)

(9h)

(9i)
(9j)

(9k)
(9l)

(9m)

(9n)

(9o)

Here, the WoE transformation woeij are replaced by the mean transformation meanij, and con-

straint (9i) expresses the linearization of the term (8) when selecting the l1-norm.

2.3 Multiple counterfactual explanations

In this section, we present a mathematical programming formulation to generating multiple counter-
factual explanations for a single data point simultaneously. In some recent works [14, 7], multiple
counterfactual explanations for a single data point have been computed iteratively. At each iteration,
these methods solve an optimization problem adding constraints to enforce diversity. Contrarily, we

9

aim to generate K counterfactual simultaneously, while maximizing or enforcing diversity regarding
the changed features and the values of the features, solving a single optimization problem.

In the following, we choose a binary desired outcome y′, but this approach is extensible to other
types of counterfactual outcomes. We start treating diversity as hard constraints. Then, we include
them in the objective function to avoid infeasibility issues when there are fewer features or sparsity
constraints are also imposed.

2.3.1 Diversity constraints

First, let us focus on the diversity of features to be changed. We consider the indicator variable ai,
and two counterfactuals k and l. The diﬀerence between aki and ali denoted as ukli can be calculated
using the absolute distance, equivalent to the XOR operator:

ukli = aki ⊕ ali = |aki − ali|.

(10)

The XOR in (10) can be linearized as follows:

ukli ≤ aki + ali
ukli ≥ aki − ali
ukli ≥ −aki + ali
ukli ≤ 2 − aki − ali

for k = 1, . . . , K; l = k + 1, . . . , K; i = 1, . . . , p. To enforce a diﬀerent combinations of features for all
counterfactual explanations we add the following constraint

ukli ≥ 1,

k = 1, . . . , K; l = k + 1, . . . , K.

(11)

p

i=1
X

The diversity of feature values can also be addressed by adding additional constraints. We consider
the indicator variable zij, indicating the new value index for feature j if changed, and two counterfac-
tuals k and l. The diﬀerence between the feature values between two counterfactuals can be expressed
as previously

dklij = zkij ⊕ zlij = |zkij − zlij|,

which can be linearized as (10)

dklij ≤ zkij + zlij
dklij ≥ zkij − zlij
dklij ≥ −zkij + zlij
dklij ≤ 2 − zkij − zlij

for k = 1, . . . , K; l = k + 1, . . . , K; i = 1, . . . , p; ∀j ∈ Bi. To ensure that counterfactual explanations
are generated without repeated values for a changed feature we use the constraint

dklij ≥ aki + ali − 1,

k = 1, . . . , K; l = k + 1, . . . , K; i = 1, . . . , p.

(12)

Bi

j=1
X

Note that this can be formulated using implication constraints. Only enforce if the counterfactual
explanations changed the same feature: aki = ali = 1:

Bi

Bi

aki ∧ ali ⇒

dklij ≥ 1 ⇐⇒

dklij ≥ aki + ali − 1.

j=1
X

j=1
X

10

The diversity constraints are incorporated to the formulation devised in (3), extended to generating

K counterfactuals, obtaining

K

p

p

λ1

wi

ki + t−
t+

ki

+ λ2

m+

i + m−
i

(cid:1)

i=1
X

(cid:0)

min

s.t.

k=1  
X
ki − t−
t+

i=1
X

(cid:0)
ki = xi − x′
Bi

ki,

!
(cid:1)

(13a)

k = 1, . . . , K; i = 1, . . . , p (13b)

x′
ki = xi +

(woeij − xki) zkij ,

k = 1, . . . , K; i = 1, . . . , p

(13c)

j=1
X

(m − ǫ)(1 − y′) + ǫ ≤

p

i=1
X

cix′

ki ≤ M y′,

Bi

cix′

ki,

p

i=1
X

aki =

zkij ,

j=1
X

aki ≤ 1,

p

aki ≤ Θ,

i=1
X
(11 − 12)
i ∈ R,
x′
zkij ∈ {0, 1},
aki ∈ {0, 1},
ki, t−
t+
ki ≥ 0,

k = 1, . . . , K (13d)

k = 1, . . . , K (13e)

k = 1, . . . , K; i = 1, . . . , p

(13f)

k = 1, . . . , K; i = 1, . . . , p (13g)

k = 1, . . . , K (13h)

k = 1, . . . , K; i = 1, . . . , p
k = 1, . . . , K; i = 1, . . . , p; ∀j ∈ Bi
k = 1, . . . , K; i = 1, . . . , p

(13i)
(13j)

(13k)
(13l)

k = 1, . . . , K; i = 1, . . . , p (13m)

2.3.2 Diversity objective

To compute the distance between two counterfactuals, we use the fact that the scorecard is discrete
and a counterfactual can be fully characterize by the binary decision variables zij. Given two binary
arrays, x, y ∈ {0, 1}p, their distance can be calculated using the Hamming distance given by

p

p

dH (x, y) =

1{xi6=yi} =

xi ⊕ yi.

Thus, we deﬁne the diversity of changed features as the sum of elements in the lower triangular

i=1
X

i=1
X

pairwise Hamming distance matrix among counterfactuals ai, i = 1, . . . , n:

K

K

p

DF =

ukli

l=k+1
X
Analogously, we deﬁne the diversity of feature values among counterfactuals using zij, i = 1, . . . , p; ∀j ∈
Bi as follows

k=1
X

i=1
X

DF V =

K

K

p

Bi

dklij .

Finally, the objective (13a) is updated taking into account that diversity objectives are maximized

k=1
X

l=k+1
X

i=1
X

j=1
X

and assigning their corresponding weights

K

p

p

K

p

K

p

Bi

min

k=1
X





λ1

wi

ki + t−
t+

ki

+ λ2

m+

i + m−
i

− λ3

ukli − λ4

i=1
X

(cid:0)

(cid:1)

i=1
X

(cid:0)

(cid:1)

l=k+1
X

i=1
X

l=k+1
X

i=1
X

j=1
X

dklij

.





11

2.4 Multi-objective counterfactual explanation

In all formulations from Sections 2.2 and 2.3, the various objectives functions are combined creating a
single objective as a linear combination with given weights λ. This is a widespread approach for multi-
objective optimization known as weighted or blended objective. However, assigning the appropriate
weights to balance various competing objectives is challenging. Also, objectives with diﬀerent scales
require a thoughtful selection of weights to choose the correct relative importance of each objective.
Another multi-objective strategy implemented in various commercial optimization solvers is the
hierarchical or lexicographic approach. This approach requires determining the priority order of the
objectives and optimizes sequentially in decreasing order. In practice, higher priority objectives are
allowed to be degradable by a small deviation. More precisely, objective degradations are handled by
adding extra constraints imposing a maximum absolute or relative deviation with respect to the opti-
mal solution using a particular objective. The main disadvantage compared to the blended approach,
is the computational cost of solving the optimization problem for each objective.

Recently, the counterfactual explanation algorithm described in [2], proposed the use of the evolu-
tionary strategy Nondominated Sorting Genetic Algorithm II (NSGA II) [3] to determine the Pareto
frontier, i.e., the boundary deﬁned by the feasible non-dominated solutions representing diﬀerent
trade-oﬀs among objectives.

Our focus is on extracting optimal or good feasible counterfactuals quickly, hence we primarily
investigate the performance of the blended and hierarchical approach in Section 3. Finally, we discard
genetic algorithms searching the Pareto frontier due to the computational cost.

3 Experiments

3.1

Implementation

The mathematical programming formulations are implemented using Google OR-Tools [9] with the
open-source MILP solver CBC [5] and Google’s CP-SAT solver. Furthermore, for solving multi-
objective optimization problems using Google OR-Tools, we implemented a custom hierarchical ap-
proach, thus supporting two strategies to generating counterfactual explanations. The scorecard
models are developed using the OptBinning library [11], freely available1. The logistic regression in
Scikit-learn [12] with l2 regularization is used as the estimator of the scorecard model. Finally, the
implementation of counterfactual explanations in OptBinning will be available in the release 0.11.0.

3.2 Experiment: binary target

To evaluate the performance and quality of the counterfactual explanations generated using the pre-
sented approach, we consider two datasets:

• FICO: This is an anonymized dataset from the FICO Explainable Machine Learning Challenge
[4]. This dataset contains real Home Equity Line of Credit (HELOC) applications. The task is
to predict whether individuals will repay their HELOC account within 2 years.

• Adult-Income: This dataset contains information based on 1994 Census database [8]. We
perform the data processing described in [10], selecting the same 8 features, namely, hours per
week, education level, occupation, work class, race, age, marital status, and sex. The task is to
classify whether an individual’s income exceeds $50K/year.

For both datasets, a scorecard model is developed using the Scorecard class in OptBinning2. The
experiments were run on an Intel(R) Core(TM) i5-3317 CPU at 1.70GHz running Linux. Both solvers,
CBC and CP-SAT, use 1 thread.

1https://github.com/guillermo-navas-palencia/optbinning
2Tutorial step by step: http://gnpalencia.org/optbinning/tutorials/tutorial scorecard binary target.html

12

3.2.1 Single counterfactual

In this ﬁrst set of experiments, we use the FICO dataset considering the 12 features selected by the
scorecard model. We ﬁrst compare the counterfactual explanations generated using the weighted and
hierarchical approach to handle several objectives. Table 2 reports generated counterfactuals using
the weighted approach with weights λ1 = λ2 = 1. For each counterfactual a diﬀerent sparsity limit is
set, Θ ∈ {1, 2, 3, 4}.

Feature
PercentTradesNeverDelq
PercentTradesNeverDelq
MSinceMostRecentInqexcl7days
PercentTradesNeverDelq
MSinceMostRecentInqexcl7days
NumBank2NatlTradesWHighUtilization
PercentTradesNeverDelq
MSinceMostRecentInqexcl7days
NetFractionRevolvingBurden
NumBank2NatlTradesWHighUtilization

Current value Required value

83
83
0
83
0
2
83
0
28
2

[97.50, ∞)
[91.50, 95.50)
[1.50, 10.50)
[91.50, 95.50)
[0.50, 1.50)
[0.50, 1.50)
[91.50, 95.50)
[0.50, 1.50)
[31.50, 37.50)
[0.50, 1.50)

Table 2: A single counterfactual explanation using Θ ∈ {1, 2, 3, 4} and the weighted approach.

Table 3 shows the generated counterfactuals using the hierarchical with maximum relative degra-
dation of the ﬁrst objective set to 0.1, and sparsity Θ = 2. The ﬁrst counterfactual prioritizes the prox-
imity objective, whereas the second prioritizes the closeness requirement. Note that when proximity
is prioritized, the feature AverageMInFile replaces MSinceMostRecentInqexcl7days since the relative
diﬀerence in MSinceMostRecentInqexcl7days is greater than the corresponding for AverageMInFile.

Feature
AverageMInFile
PercentTradesNeverDelq
PercentTradesNeverDelq
MSinceMostRecentInqexcl7days

Current value Required value

65
83
83
0

[97.50, 116.50)
[91.50, 95.50)
[88.50, 91.50)
[1.50, 10.50)

Table 3: A single counterfactual explanation using Θ = 2 and the hierarchical approach.

As mentioned in Section 2.4, solving a multi-objective optimization problem using the hierarchical
approach might increase the computation time. Table 4 compares both approaches in terms of the
objective functions and the CPU times using the CBC solver, conﬁrming that with two objectives
the CPU approximately doubles. Besides, given the probability of default (PD) for this particular
data point is 0.742, column PD shows the PD assigned by the scorecard model to the generated
counterfactual.

Θ Approach Proximity Closeness PD Time (s)
1
2
3
4
2
2

W
W
W
W
H(1, 0)
H(0, 1)

0.484
0.436
0.478
0.489
0.489
0.476

9.356
7.544
5.524
5.406
8.742
8.206

1.134
1.672
1.767
1.816
0.993
1.504

0.3
0.3
0.4
0.5
0.5
0.9

Table 4: Performance and counterfactual PD comparison weighted (W) vs hierarchical (H) approach.
H(1, 0) and H(0, 1) prioritize proximity and closeness, respectively.

13

3.2.2 Multiple counterfactuals

The experiments in this section serve to evaluate the quality of the generated counterfactuals when
incorporating diversity constraints. First, we use the same data point in Table 2 to generate three
counterfactuals using the diversity constraint regarding the values of the features in (12). Note that
the second counterfactual in Table 5 is the counterfactual in Table 2 when Θ = 2. We can observe that
the combination of features is not unique, but no feature value is repeated on the changed features.

Feature
PercentTradesNeverDelq
NumBank2NatlTradesWHighUtilization
PercentTradesNeverDelq
MSinceMostRecentInqexcl7days
PercentTradesNeverDelq
MSinceMostRecentInqexcl7days

Current value Required value

83
2
83
0
83
0

[97.50, ∞)
[0.50, 1.50)
[91.50, 95.50)
[1.50, 10.50)
[95.50, 97.50)
[0.50, 1.50)

Table 5: Three counterfactual explanations using Θ = 2 and the weighted approach. Feature values
as hard constraint. Feature changes not imposed.

The hierarchical approach can also be used to generate multiple counterfactuals. Table 6 compares
both approaches reporting the average proximity and closeness, and the diversity metrics DF and DF V .
In addition, the minimum and maximum PD among the generated counterfactuals is reported. These
result may vary considerably by modifying the weights λ and the maximum relative degradation.

K Θ Approach Proximity Closeness DF DF V PDmin PDmax
0.457
3
0.487
4
0.495
3
0.489
3

W
W
H(1, 0)
H(0, 1)

7.901
7.494
8.895
8.561

1.638
1.807
1.096
1.203

0.422
0.455
0.477
0.477

12
36
12
12

4
16
4
4

2
3
2
2

Table 6: Metrics of multiple counterfactual explanations for K ∈ {3, 4}, Θ ∈ {2, 3}, using the weighted
(W) and hierarchical (H) approach. H(1, 0) and H(0, 1) prioritize proximity and closeness, respectively.

For the remaining experiments we use the Adult-Income dataset. We take the data point chosen
in [10] to conduct experiments. Table 7 shows four counterfactuals generated with sparsity Θ = 4,
imposing both diversity constraints and using the weighted approach.

Feature
age
education
age
education
hours-per-week
age
education
marital-status
age
education
hours-per-week
occupation

Current value
22
HS-grad
22
HS-grad
45
22
HS-grad
Single
22
HS-grad
45
Service

Required value
[43.50, 49.50)
Bachelors
[35.50, 37.50)
[Masters, Prof-school, Doctorate]
[39.50, 41.50)
[49.50, 54.50)
Some-college
[Married-AF-spouse, Married-civ-spouse]
[40.50, 43.50)
[Assoc-acdm, Assoc-voc]
[55.50, ∞)
Exec-managerial

Table 7: Four counterfactual explanations using Θ = 4 and the weighted approach. Feature changes
and feature values as hard constraint.

We note that unlike the DiCE method in [10], our method includes both proximity and closeness

14

objectives. The main observations from Table 7 are that neither feature sex nor race is included, a
higher salary requires an advanced degree which in turn requires years of study, showing the under-
lying positive correlation among these features. Excluding the closeness objective, we got the four
counterfactuals in Table 8.

Feature
age
education
age
education
hours-per-week
age
education
marital-status
age
education
occupation

Current value
22
HS-grad
22
HS-grad
45
22
HS-grad
Single
22
HS-grad
Service

Required value
[31.50, 33.50)
[Masters, Prof-school, Doctorate]
[37.50, 40.50)
Bachelors
[55.50, inf)
[49.50, 54.50)
Some-college
[Married-AF-spouse, Married-civ-spouse]
[43.50, 49.50)
[Assoc-acdm, Assoc-voc]
Exec-managerial

Table 8: Four counterfactual explanations using Θ = 4 and the weighted approach. Closeness objective
not included. Feature changes and feature values as hard constraint.

Finally, we report CPU times using the CP-SAT solver in Table 9. In our experiments, CP-SAT is
signiﬁcantly faster than CBC as K increases, being more noticeable when both diversity constraints
are considered.

K Θ Diversity P[> 50K]min P[> 50K]max
3
3
3
4
5
5
5
5
5
5

F + FV
F + FV
F + FV
F + FV
F + FV
F + FV
F
F
F
F + NA

-
0.510
0.510
0.521
-
-
0.526
0.526
0.522
0.526

-
0.506
0.506
0.502
-
-
0.503
0.503
0.502
0.502

2
3
4
4
3
4
3
4
5
5

Time (s)
infeasible (0.1)
0.6
3.9
2.5
infeasible (0.8)
infeasible (0.4)
5.1
13.7
9.7
21.3

Table 9: Metrics of multiple counterfactual explanations for K ∈ {3, 4, 5}, Θ ∈ {2, 3, 4, 5}, using
the weighted approach and CP-SAT solver. F: feature changes. FV: feature values. NA: features
marital-status, sex and race are non-actionable.

Table 9 shows that multiple counterfactuals can be generated simultaneously for a single data point
in a few seconds. Besides, this approach is capable of providing a certiﬁcate of infeasibility quickly,
conﬁrming that no counterfactual can be generated by the scorecard model under these constraints.
If the number of actionable features is small and the number of bins is limited, one can easily reach
infeasible solutions if the diversity constraint regarding feature values is enforced. Therefore, a granular
scorecard is beneﬁcial to ﬁnd several diverse counterfactuals.

For very large problems, obtaining optimal solutions might take minutes, but we found that good
feasible solutions are generally achieved within seconds. Thus, a practical implementation would
require a time limit parameter.

4 Conclusions

We proposed several mathematical programming formulations to generating diverse counterfactual
explanations. The presented method demonstrates that optimal counterfactuals with diversity con-

15

straints are quickly generated for a scorecard model. Also, these formulations can easily incorporate
additional constraints such as causal relationships and allowed ranges for feature values.

Solving an optimization problem for each data point in the dataset can be time-consuming. A
reasonable extension of this work is the development of fast heuristic methods to generate feasible
counterfactuals, thus enabling a continuous assessment of the scorecard model biases. Furthermore,
this would allow performing a careful evaluation of a scorecard model before putting it into production.

References

[1] E. Cabana, R. E. Lillo, and H. Laniado. Multivariate outlier detection based on a robust Maha-

lanobis distance with shrinkage estimators. Statistical Papers, 2019.

[2] S. Dandl, C. Molnar, M. Binder, and B. Bischl. Multi-Objective Counterfactual Explanations.
In T. B¨ack, M. Preuss, A. Deutz, H. Wang, C. Doerr, M. Emmerich, and H. Trautmann, edi-
tors, Parallel Problem Solving from Nature – PPSN XVI, pages 448–469, Cham, 2020. Springer
International Publishing.

[3] K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan. A fast and elitist multiobjective genetic
algorithm: NSGA-II. IEEE Transactions on Evolutionary Computation, 6(2):182–197, 2002.

[4] FICO,

Google,

UC Irvine,
https://community.fico.com/s/explainable-machine-learning-challenge, 2018.

Imperial
and UC Berkeley.

College

London,
Explainable Machine

MIT,

University

Oxford,
Learning Challenge.

of

[5] J. Forrest, T. Ralphs, S. Vigerske, and et al. coin-or/cbc: Version 2.10. 2019.

[6] K. Kanamori, T. Takagi, K. Kobayashi, and H. Arimura. DACE: Distribution-Aware Counterfac-
tual Explanation by Mixed-Integer Linear Optimization. In Christian Bessiere, editor, Proceedings
of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence, IJCAI-20, pages
2855–2862. International Joint Conferences on Artiﬁcial Intelligence Organization, 2020.

[7] A.-H. Karimi, G. Barthe, B. Balle, and I. Valera. Model-Agnostic Counterfactual Explanations
for Consequential Decisions. In Proceedings of the 23rd International Conference on Artiﬁcial
Intelligence and Statistics (AISTATS), volume 108 of Proceedings of Machine Learning Research,
pages 895–905. PMLR, August 2020.

[8] R.

Kohavi

and

B.

Becker.

UCI

Machine

Learning

Repository.

https://archive.ics.uci.edu/ml/datasets/adult, 1996.

[9] P. Laurent and F. Vincent. Google OR-Tools 8.2. https://developers.google.com/optimization/,

2021.

[10] R. K. Mothilal, A. Sharma, and C. Tan. Explaining Machine Learning Classiﬁers through Diverse
Counterfactual Explanations. In Proceedings of the 2020 Conference on Fairness, Accountabil-
ity, and Transparency, FAT* ’20, pages 607—-617, New York, NY, USA, 2020. Association for
Computing Machinery.

[11] G. Navas-Palencia.

Optimal

binning:

mathematical

programming

formulation.

https://arxiv.org/abs/2001.08025, 2020.

[12] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Pret-
tenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Per-
rot, and E. Duchesnay. Scikit-learn: Machine Learning in Python . Journal of Machine Learning
Research, 12:2825–2830, 2011.

[13] C. Russell. Eﬃcient Search for Diverse Coherent Explanations. In Proceedings of the Conference
on Fairness, Accountability, and Transparency, FAT* ’19, pages 20–28, New York, NY, USA,
2019. Association for Computing Machinery.

16

[14] B. Ustun, A. Spangher, and Y. Liu. Actionable Recourse in Linear Classiﬁcation. In Proceedings
of the Conference on Fairness, Accountability, and Transparency, FAT* ’19, pages 10—-19, New
York, NY, USA, 2019. Association for Computing Machinery.

[15] S. Verma, J. Dickerson, and K. Hines. Counterfactual Explanations for Machine Learning: A

Review. 2020.

[16] S. Wachter, B. Mittelstadt, and C. Russell. Counterfactual Explanations without Opening
the Black Box: Automated Decisions and the GDPR. Harvard Journal of Law & Technology,
31(2):841—-887, 2018.

17

