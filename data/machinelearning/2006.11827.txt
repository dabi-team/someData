0
2
0
2
c
e
D
4
2

]
I

A
.
s
c
[

2
v
7
2
8
1
1
.
6
0
0
2
:
v
i
X
r
a

Reﬁned bounds for algorithm conﬁguration:
The knife-edge of dual class approximability

Ellen Vitercik
Carnegie Mellon University
vitercik@cs.cmu.edu

Maria-Florina Balcan
Carnegie Mellon University
ninamf@cs.cmu.edu

Tuomas Sandholm
Carnegie Mellon University
Optimized Markets, Inc.
Strategic Machine, Inc.
Strategy Robot, Inc.
sandholm@cs.cmu.edu

December 25, 2020

Abstract

Automating algorithm conﬁguration is growing increasingly necessary as algorithms come
with more and more tunable parameters.
It is common to tune parameters using machine
learning, optimizing performance metrics such as runtime and solution quality. The training
set consists of problem instances from the speciﬁc domain at hand. We investigate a funda-
mental question about these techniques: how large should the training set be to ensure that
a parameter’s average empirical performance over the training set is close to its expected, fu-
ture performance? We answer this question for algorithm conﬁguration problems that exhibit a
widely-applicable structure: the algorithm’s performance as a function of its parameters can be
approximated by a “simple” function. We show that if this approximation holds under the L∞-
norm, we can provide strong sample complexity bounds. On the ﬂip side, if the approximation
holds only under the Lp-norm for p < ∞, it is not possible to provide meaningful sample com-
plexity bounds in the worst case. We empirically evaluate our bounds in the context of integer
programming, one of the most powerful tools in computer science. Via experiments, we obtain
sample complexity bounds that are up to 700 times smaller than the previously best-known
bounds [7].

1

Introduction

Algorithms typically have tunable parameters that signiﬁcantly impact their performance, measured
in terms of runtime, solution quality, and so on. Machine learning is often used to automate
parameter tuning [20, 21, 23, 39]: given a training set of problem instances from the application
domain at hand, this automated procedure returns a parameter setting that will ideally perform
well on future, unseen instances.

It is important to be careful when using this automated approach: if the training set is too small,
a parameter setting with strong average empirical performance over the training set may have poor
future performance on unseen instances. Generalization bounds provide guidance when it comes
to selecting the training set size. They bound the diﬀerence between an algorithm’s performance
on average over the training set (drawn from an unknown, application-speciﬁc distribution) and
its expected performance on unseen instances. These bounds can be used to evaluate a parameter
setting returned by any black-box procedure: they bound the diﬀerence between that parameter’s
average performance on the training set and its expected performance.

1

 
 
 
 
 
 
(a)

(b)

(c)

Figure 1: Examples of dual functions f ∗
simpler functions g∗
x (dotted black lines).

x : R → R (solid blue lines) which are approximated by

At a high level, we provide generalization bounds that hold when an algorithm’s performance
as a function of its parameters exhibits a widely-applicable structure: it can be approximated by a
“simple” function. We prove that it is possible to provide strong generalization bounds when the
approximation holds under the L∞-norm. Meanwhile, it is not possible to provide strong guarantees
in the worst-case if the approximation only holds under the Lp-norm for p < ∞. Therefore, this
connection between learnability and approximability is balanced on a knife-edge.

Our analysis is based on structure exhibited by primal and dual functions [4], which we now
describe at a high level. To provide generalization bounds, a common strategy is to bound the
intrinsic complexity of the following function class F :
for every parameter vector r (such as a
CPLEX parameter setting) there is a function fr ∈ F that takes as input a problem instance
x (such as an integer program) and returns fr(x), the algorithm’s performance on input x when
parameterized by r. Performance is measured by runtime, solution quality, or some other metric.
The functions fr are called primal functions.

The class F is gnarly: in the case of integer programming algorithm conﬁguration, the domain
of every function in F consists of integer programs, so it is unclear how to visualize or plot these
functions, and there are no obvious notions of Lipschitzness or smoothness to rely on. Rather
than ﬁxing a parameter setting r and varying the input x (as under the function fr), it can be
enlightening to instead ﬁx the input x and analyze the algorithm’s performance as a function of
r. This dual function is denoted f ∗
x (r). The dual functions have a simple, Euclidean domain, they
are typically easy to plot, and they often have ample structure we can use to bound the intrinsic
complexity of the class F .

Our contributions. We observe that for many conﬁguration problems, the dual functions can be
closely approximated by “simple” functions, as in Figure 1. This raises the question: can we exploit
this structure to provide strong generalization guarantees? We show that if the dual functions are
approximated by simple functions under the L∞-norm (meaning the maximum distance between
the functions is small), then we can provide strong generalization guarantees. However, this is no
longer true when the approximation only holds under the Lp-norm for p < ∞: we present a set of
functions whose duals are well-approximated by the simple constant function g(x) = 1
2 under the
Lp-norm (meaning p

(cid:12)
p dr is small), but which are not learnable.
(cid:12)

(cid:113)(cid:82) (cid:12)

(cid:12)f ∗

x (r) − 1
2

We provide an algorithm that ﬁnds approximating simple functions in the following widely-
applicable setting: the dual functions are piecewise-constant with a large number of pieces, but can
be approximated by simpler piecewise-constant functions with few pieces, as in Figure 1(a). This
is the case in our integer programming experiments.

In our experiments, we demonstrate signiﬁcant practical implications of our analysis. We con-

2

ﬁgure CPLEX, one of the most widely-used integer programming solvers. Integer programming has
diverse applications throughout science. Prior research has shown that the dual functions associated
with various CPLEX parameters are piecewise constant and has provided generalization bounds
that grow with the number of pieces [7]. However, the number of pieces can be so large that these
bounds can be quite loose. We show that these dual functions can be approximated under the L∞-
norm by simple functions (as in Figure 1(a)), so our theoretical results imply strong generalization
guarantees. In our experiments, we demonstrate that in order to obtain the same generalization
bound, the training set size required under our analysis is up to 700 times smaller than that of
Balcan et al. [7]. Improved sample complexity guarantees imply faster learning algorithms, since
the learning algorithm needs to analyze fewer training instances.

In algorithm conﬁguration, several papers have provided generalization guar-
Related research.
antees for speciﬁc algorithm families, including greedy algorithms [8, 17], clustering algorithms [6,
9, 11], and integer programming algorithms [7]. In contrast, we provide general guarantees that
apply to any conﬁguration problem that satisﬁes a widely-applicable structure: the dual functions
are approximately simple. A strength of our results is that they are not tied to any speciﬁc al-
gorithm family, though we show that our guarantees can be empirically much stronger than the
best-known bounds. Balcan et al. [10] show that if the dual functions are simple—for example,
they are piecewise-constant with few pieces—then it is possible to provide strong generalization
bounds. We observe, however, that often the dual functions themselves are not particularly simple,
but can be approximated by simple functions. We exploit this structure to provide more general
guarantees. The analysis tools from prior research do not apply to this more general structure, so
we require new, reﬁned proof techniques.

Our guarantees are conﬁguration-procedure-agnostic: no matter how one tunes the param-
eters using the training set, we bound the diﬀerence between the resulting parameter setting’s
performance on average over the training set and its expected performance on unseen instances.
A related line of research has provided learning-based algorithm conﬁguration procedures with
provable guarantees [12, 26, 27, 41, 42]. Unlike the results in this paper, their guarantees are not
conﬁguration-procedure-agnostic: they apply to the speciﬁc conﬁguration procedures they propose.
Moreover, their procedures only apply to ﬁnding conﬁgurations that minimize computational re-
source usage, such as runtime, whereas the guarantees in this paper apply to more general measures
of algorithmic performance, such as solution quality.

A related line of research has studied integer programming algorithm conﬁguration [2, 5, 7, 15,
19, 21, 24, 25, 29, 33, 37, 39], as do we, though our results apply more generally. The results in
these papers are primarily empirical, with the exception of the paper by Balcan et al. [7], with
which we compare extensively in Section 4.2.

2 Notation and background

We study functions that map an abstract domain X to [0, 1]. We denote the set of all such functions
as [0, 1]X . The learning algorithms we analyze have sample access to an unknown distribution D
over examples x ∈ X and aim to ﬁnd a function f ∈ F with small expected value Ex∼D[f (x)].

2.1 Problem deﬁnition

We provide generalization guarantees, which bound the diﬀerence between the expected value
Ex∼D[f (x)] of any function f ∈ F and its empirical average value 1
i=1 f (xi) over a train-
N
ing set x1, . . . , xN ∼ D. We focus on functions that are parameterized by a set of vectors R ⊆ Rd.

(cid:80)N

3

Given a vector r ∈ R, we denote the corresponding function as fr : X → [0, 1], and we deﬁne
F = {fr | r ∈ R}.

Generalization guarantees are particularly useful for analyzing the expected performance of
empirical risk minimization learning algorithms for the following reason. Suppose we know that for
(cid:12)
(cid:12) ≤ (cid:15). Let ˆf be the function in F with smallest
(cid:12)
i=1 f (xi) − Ex∼D[f (x)]
any function f ∈ F ,
(cid:80)N
average value over the training set: ˆf = argminf ∈F
i=1 f (xi). Then ˆf has nearly optimal expected
value: Ex∼D

− minf ∈F Ex∼D[f (x)] ≤ 2(cid:15).

(cid:105)
(cid:104) ˆf (x)

(cid:80)N

1
N

(cid:12)
(cid:12)
(cid:12)

2.2 Integer programming algorithm conﬁguration

We use integer programming algorithm conﬁguration as a running example, though our results are
much more general. An integer program (IP) is deﬁned by a matrix A ∈ Rm×n, a constraint vector
b ∈ Rm, an objective vector c ∈ Rn, and a set of indices I ⊆ [n]. The goal is to ﬁnd a vector
z ∈ Rn such that c · z is maximized, subject to the constraints that Az ≤ b and for every index
i ∈ I, zi ∈ {0, 1}.

In our experiments, we tune the parameters of branch-and-bound (B&B) [30], the most widely-
used algorithm for solving IPs. It is used under the hood by commercial solvers such as CPLEX
and Gurobi. We provide a brief, high-level overview of B&B, and refer the reader to the textbook
by Nemhauser and Wolsey [36] for more details. B&B builds a search tree to solve an input IP x.
At the tree’s root is the original IP x. At each round, B&B chooses a leaf of the search tree, which
represents an IP x(cid:48). It does so using a node selection policy; common choices include depth- and
best-ﬁrst search. Then, it chooses an index i ∈ I using a variable selection policy. It next branches
it sets the left child of x(cid:48) to be that same integer program x(cid:48), but with the additional
on zi:
constraint that zi = 0, and it sets the right child of x(cid:48) to be that same integer program, but with
the additional constraint that zi = 1. It solves both LP relaxations, and if either solution satisﬁes
the integrality constraints of the original IP x, it constitutes a feasible solution to x. B&B fathoms
a leaf—which means that it never will branch on that leaf—if it can guarantee that the optimal
solution does not lie along that path. B&B terminates when it has fathomed every leaf. At that
point, we can guarantee that the best solution to x found so far is optimal. In our experiments, we
tune the parameters of the variable selection policy, which we describe in more detail in Section 4.2.
In this setting, X is a set of IPs and the functions in F are parameterized by CPLEX parameter
vectors r ∈ Rd, denoted F = (cid:8)fr | r ∈ Rd(cid:9) . In keeping with prior work [7], fr(x) equals the size
of the B&B tree CPLEX builds given the parameter setting r and input IP x, normalized to fall
in [0, 1]. The learning algorithms we study take as input a training set of IPs sampled from D and
return a parameter vector. Since our goal is to minimize tree size, ideally, the size of the trees
CPLEX builds using that parameter setting should be small in expectation over D.

3 Dual functions

Our goal is to provide generalization guarantees for the function class F = {fr | r ∈ R}. To
do so, we use structure exhibited by the dual function class. Every function in the dual class is
deﬁned by an element x ∈ X , denoted f ∗
x (r) = fr(x). The dual class
F ∗ = {f ∗

x : R → [0, 1]. Naturally, f ∗

x | x ∈ X } is the set of all dual functions.

The dual functions are intuitive in our integer programming example. For any IP x, the dual
function f ∗
x measures the size of the tree CPLEX builds (normalized to lie in the interval [0, 1])
when given x as input, as a function of the CPLEX parameters. Duals are also straightforward in
if X = Rd and F is the set of linear functions fr(x) = r · x, each dual
more abstract settings:

4

function f ∗
dual function is the identity function f ∗

x (r) = r.

x(r) = r · x is also linear. When F consists of the constant functions fr(x) = r, each

Prior research shows that when the dual functions are simple—for example, they are piecewise-
constant with a small number of pieces—it is possible to provide strong generalization bounds [10].
In many settings, however, we ﬁnd that the dual functions themselves are not simple, but are
approximated by simple functions, as in Figure 1. We formally deﬁne this concept as follows.

Deﬁnition 3.1 ((γ, p)-approximate). Let F = {fr | r ∈ R} and G = {gr | r ∈ R} be two sets of
functions mapping X to [0, 1]. We assume that all dual functions f ∗
x are integrable over the
domain R. We say that the dual class G∗ (γ, p)-approximates the dual class F ∗ if for every element
x is at most γ under the Lp-norm. For p ∈ [1, ∞),
x, the distance between the functions f ∗
x(r)|p dr ≤ γ and when p = ∞, this means that
this means that (cid:107)f ∗
R |f ∗
(cid:107)f ∗
x (r)| ≤ γ.

x − g∗
x(cid:107)∞ := supr∈R |f ∗

x and g∗
x (r) − g∗

x(cid:107)p := p
x (r) − g∗

x and g∗

x − g∗

(cid:113)(cid:82)

4 Learnability and approximability

In this section, we investigate the connection between learnability and approximability. In Sec-
tion 4.1, we prove that when the dual functions are approximable under the L∞-norm by simple
functions, we can provide strong generalization bounds. In Section 4.2, we empirically evaluate
these improved guarantees in the context of integer programming. Finally, in Section 4.3, we prove
that it is not possible to provide non-trivial generalization guarantees (in the worst case) when the
norm under which the dual functions are approximable is the Lp-norm for p < ∞.

4.1 Data-dependent generalization guarantees

We now show that if the dual class F ∗ is (γ, ∞)-approximated by the dual of a “simple” function
class G, we can provide strong generalization bounds for the class F . There are many diﬀerent
tools for measuring how “simple” a function class is. We use Rademacher complexity [28], which
intuitively measures the extent to which functions in F match random noise vectors σ ∈ {−1, 1}N .

Deﬁnition 4.1 (Rademacher complexity). The empirical Rademacher complexity of a function
class F = {fr | r ∈ R} given a set S = {x1, . . . , xN } ⊆ X is

(cid:98)RS (F ) =

1
N

(cid:34)

E
σ∼{−1,1}N

sup
r∈R

(cid:35)

σifr (xi)

,

N
(cid:88)

i=1

where each σi equals −1 or 1 with equal probability.

The summation (cid:80)N

i=1 σifr (xi) measures the correlation between the random noise vector σ
and the vector (fr (x1) , . . . , fr (xN )). By taking the supremum over all parameter vectors r ∈ R,
we measure how well functions in the class F correlate with σ over the sample S. Therefore,
(cid:98)RS (F ) measures how well functions in the class F correlate with random noise on average over S.
Rademacher complexity thus provides a way to measure the intrinsic complexity of F because the
more complex the class F is, the better its functions can correlate with random noise. For example,
if the class F consists of just a single function, (cid:98)RS (F ) = 0. At the other extreme, if X = [0, 1] and
F = [0, 1][0,1] consists of all functions mapping [0, 1] to [0, 1], (cid:98)RS (F ) = 1
2 .

Classic learning-theoretic results provide guarantees based on Rademacher complexity, such as

the following.

5

Theorem 4.2 (e.g., Mohri et al. [35]). For any δ ∈ (0, 1), with probability 1 − δ over the draw of
N samples S = {x1, . . . , xN } ∼ DN , for all functions fr ∈ F ,

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
N

N
(cid:88)

i=1

(cid:12)
(cid:12)
(cid:12)
fr (xi) − E [fr(x)]
(cid:12)
(cid:12)

(cid:32)

= O

(cid:98)RS (F ) +

(cid:114) 1
N

(cid:33)

.

1
δ

log

Theorem 4.2 is a generalization guarantee because it measures the extent to which a function’s

empirical average value over the samples generalizes to its expected value.

Ideally, (cid:98)RS (F ) converges to zero as the sample size N grows so the bound in Theorem 4.2 also
converges to zero. If the class F consists of just a single function, (cid:98)RS (F ) = 0, and Theorem 4.2
recovers Hoeﬀding’s bound. If, for example, X = [0, 1] and F = [0, 1][0,1], (cid:98)RS (F ) = 1
2 , and the
bound from Theorem 4.2 is meaningless.

We show that if the dual class F ∗ is (γ, ∞)-approximated by the dual of a class G with small
Rademacher complexity, then the Rademacher complexity of F is also small. The full proof of the
following theorem in Appendix B.1.

Theorem 4.3. Let F = {fr | r ∈ R} and G = {gr | r ∈ R} consist of functions mapping X to
[0, 1]. For any S ⊆ X , (cid:98)RS (F ) ≤ (cid:98)RS (G) + 1
|S|

x∈S (cid:107)f ∗

x − g∗

x(cid:107)∞ .

(cid:80)

Proof sketch. To prove this theorem, we use the fact that for any parameter vector r ∈ R, any
element x ∈ X , and any binary value σ ∈ {−1, 1}, σfr(x) = σf ∗
x(cid:107)∞ =
σgr(x) + (cid:107)f ∗

x (r) ≤ σg∗

x(r) + (cid:107)f ∗

x − g∗

x − g∗

x(cid:107)∞ .

(cid:80)

If the class G∗ (γ, ∞)-approximates the class F ∗, then 1
|S|

x(cid:107)∞ is at most γ. If
this term is smaller than γ for most sets S ∼ DN , then the bound on (cid:98)RS (F ) in Theorem 4.3 will
often be even better than (cid:98)RS (G) + γ.

x∈S (cid:107)f ∗

x − g∗

Theorems 4.2 and 4.3 imply that with probability 1 − δ over the draw of the set S ∼ DN , for all
parameter vectors r ∈ R, the diﬀerence between the empirical average value of fr over S and its
expected value is at most ˜O
. In our integer programming
experiments, we show that this data-dependent generalization guarantee can be much tighter than
the best-known worst-case guarantee.

x(cid:107)∞ + (cid:98)RS (G) +

x∈S (cid:107)f ∗

x − g∗

(cid:113) 1
N

(cid:16) 1
N

(cid:80)

(cid:17)

Algorithm for ﬁnding approximating functions. We provide a dynamic programming (DP)
algorithm (Algorithm 1 in Appendix B.2) for the widely-applicable case where the dual functions
f ∗
x are piecewise constant with a large number of pieces. Given an integer k, the algorithm returns
a piecewise-constant function g∗
x(cid:107)∞ is minimized, as
in Figure 1(a). Letting t be the number of pieces in the piecewise decomposition of f ∗
x , the DP
algorithm runs in O (cid:0)kt2(cid:1) time. As we describe in Section 4.2, when k and (cid:107)f ∗
x(cid:107)∞ are small,
Theorem 4.3 implies strong guarantees. We use this DP algorithm in our integer programming
experiments.

x with at most k pieces such that (cid:107)f ∗

x − g∗

x − g∗

Structural risk minimization. Theorem 4.3 illustrates a fundamental tradeoﬀ in machine learn-
ing. The simpler the class G, the smaller its Rademacher complexity, but—broadly speaking—the
worse functions from its dual will be at approximating functions in F ∗. In other words, the simpler
G is, the worse the approximation 1
x − g∗
x∈S (cid:107)f ∗
x(cid:107)∞ will likely be. Therefore, there is a tradeoﬀ
N
between generalizability and approximability.
It may not be a priori clear how to balance this
tradeoﬀ. Structural risk minimization (SRM) is a classic, well-studied approach for optimizing
tradeoﬀs between complexity and generalizability which we use in our experiments.

(cid:80)

6

Our SRM approach is based on the following corollary of Theorem 4.3. Let G1, G2, G3, . . . be a
countable sequence of function classes where each Gj = {gj,r | r ∈ R} is a set of functions mapping
X to [0, 1]. We use the notation g∗
j,x(r) = gj,r(x).

j,x to denote the duals of the functions in Gj, so g∗

Corollary 4.4. With probability 1 − δ over the draw of the set S ∼ DN , for all r ∈ R and all
j ≥ 1,

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
N

(cid:88)

x∈S

fr(x) − E
x∼D

(cid:12)
(cid:12)
(cid:12)
[fr(x)]
(cid:12)
(cid:12)

(cid:32)

= O

1
N

(cid:88)

x∈S

(cid:13)
(cid:13)f ∗

x − g∗
j,x

(cid:13)
(cid:13)∞

+ (cid:98)RS (Gj) +

(cid:114) 1
N

(cid:33)

.

j
δ

ln

(1)

The proof of this corollary is in Appendix B.1.
In our experiments, each dual class G∗

j consists of piecewise-constant functions with at most
j pieces. This means that as j grows, the class G∗
j becomes more complex, or in other words,
the Rademacher complexity (cid:98)RS (Gj) also grows. Meanwhile, the more pieces a piecewise-constant
function g∗
x . In other words, as j
grows, the approximation term 1
x − g∗
shrinks. SRM is the process of ﬁnding the
j,x
N
level j in the nested hierarchy that minimizes the sum of these two terms, and therefore obtains
the best generalization guarantee via Equation (1).

x has, the better it is able to approximate the dual function f ∗
(cid:13)
(cid:13)f ∗
(cid:13)

(cid:13)
(cid:13)
(cid:13)∞

x∈S

(cid:80)

Remark 4.5. We conclude by noting that the empirical average 1
N
(cid:105)
. See Corollary B.1 in Ap-

x − g∗
j,x

in Equa-

x∈S

tion (1) can be replaced by the expectation Ex∼D
pendix B.1 for the proof.

(cid:104)(cid:13)
(cid:13)f ∗
(cid:13)

x − g∗
j,x

(cid:13)
(cid:13)
(cid:13)∞

(cid:80)

(cid:13)
(cid:13)f ∗
(cid:13)

(cid:13)
(cid:13)
(cid:13)∞

4.2 Improved integer programming guarantees

In this section, we demonstrate that our data-dependent generalization guarantees from Section 4.1
can be much tighter than worst-case generalization guarantees provided in prior research. We
demonstrate these improvements in the context of integer programming algorithm conﬁguration,
which we introduced in Section 2.2. Our formal model is the same as that of Balcan et al. [7],
who studied worst-case generalization guarantees. Each element of the set X is an IP. The set R
consists of CPLEX parameter settings. We assume there is an upper bound κ on the size of the
largest tree we allow B&B to build before we terminate, as in prior research [7, 21, 26, 27]. In
Appendix B.2, we describe our methodology for choosing κ. Given a parameter setting r and an
IP x, we deﬁne fr(x) to be the size of the tree CPLEX builds, capped at κ, divided by κ (this way,
fr(x) ∈ [0, 1]). We deﬁne the set F = {fr | r ∈ R}.

We tune the parameter of B&B’s variable selection policy (VSP). We described the purpose
of VSPs in Section 2.2. We study score-based VSPs, deﬁned as follows. Let score be a function
that takes as input a partial B&B tree T , a leaf of T representing an IP x, and an index i ∈
[n], and returns a real-valued score(T , x, i). Let V be the set of variables that have not been
branched on along the path from the root of T to x. A score-based VSP branches on the variable
argmaxzi∈V {score(T , x, i)} at the node x.

We study how to learn a high-performing convex combination of any two scoring rules. We
focus on four scoring rules in our experiments. To deﬁne them, we ﬁrst introduce some notation.
For an IP x with objective function c · z, we denote an optimal solution to the LP relaxation of x
as ˘zx = (˘zx,1, . . . ˘zx,n). We also use the notation ˘cx = c · ˘zx. Finally, we use the notation x+
i (resp.,

7

x−
i ) to denote the IP x with the additional constraint that zi = 1 (resp., zi = 0).1

We study four scoring rules scoreL, scoreS, scoreA, and scoreP :

• scoreL(T , x, i) = max

˘cx − ˘cx+
leading to the Largest change in the LP objective value.

, ˘cx − ˘cx−

i

i

(cid:110)

(cid:111)

. Under scoreL, B&B branches on the variable

• scoreS(T , x, i) = min

˘cx − ˘cx+
i
leading to the Smallest change.

(cid:110)

, ˘cx − ˘cx−

i

(cid:111)

. Under scoreS, B&B branches on the variable

• scoreA(T , x, i) = 1

6 scoreS(T , x, i). This is a scoring rule that Achterberg
[1] recommended. It balances the optimistic approach to branching under scoreL with the
pessimistic approach under scoreS.

6 scoreL(T , x, i) + 5

(cid:110)

(cid:110)

, 10−6(cid:111)
and ˘cx − ˘cx+

• scoreP (T , x, i) = max

i

·max

˘cx − ˘cx+
scoring rule. Comparing ˘cx − ˘cx−
variables even if ˘cx − ˘cx−
i
(cid:16)
calculated the product
˘cx − ˘cx−
then the score equals 0, canceling out the value of ˘cx − ˘cx+
encoded by this diﬀerence.

= 0 or ˘cx − ˘cx+
(cid:17)
·

˘cx − ˘cx−
. This is known as the Product
to 10−6 allows the algorithm to compare two
= 0. After all, suppose the scoring rule simply
without comparing to 10−6. If ˘cx − ˘cx−

= 0,
and thus losing the information

˘cx − ˘cx+

(cid:17)

(cid:16)

i

i

i

i

i

i

i

i

, 10−6(cid:111)

Fix any two scoring rules score1 and score2. We deﬁne fr(x) to be the size of the tree B&B
builds (normalized to lie in [0, 1]) when it uses the score-based VSP deﬁned by (1 − r)score1 +
rscore2. Our goal is to learn the best convex combination of the two scoring rules. When score1 =
scoreL and score2 = scoreS, prior research has proposed several alternative settings for the
parameter r [1, 13, 14, 16, 32], though no one setting is optimal across all applications. Balcan
et al. [7] prove the following lemma about the structure of the functions f ∗
x .

Lemma 4.6. For any IP x with n variables, the dual function f ∗
most n2(κ+1) pieces.

x is piecewise-constant with at

Lemma 4.6 implies the following worst-case bound on (cid:98)RS (F ). See Lemma B.4 in Appendix B.2

for the proof.

Corollary 4.7. For any set S ⊆ X of integer programs, (cid:98)RS (F ) ≤

(cid:114)

2 ln(|S|(n2(κ+1)−1)+1)
|S|

.

This corollary and Theorem 4.2 imply the following worst-case generalization bound: with prob-
x∈S fr(x) − Ex∼D [fr(x)](cid:12)
(cid:12)

ability 1 − δ over the draw of N samples S ∼ DN , for all r ∈ [0, 1], (cid:12)
(cid:12) 1
N
is bounded above by

(cid:80)

(cid:115)

2

2 ln(N (cid:0)n2(κ+1) − 1(cid:1) + 1)
N

+ 3

(cid:114) 1
2N

ln

2
δ

.

(2)

This worst-case bound can be large when κ is large. We ﬁnd that although the duals f ∗
x are
piecewise-constant with many pieces, they can be approximated piecewise-constant functions with
few pieces, as in Figure 1(a). As a result, we improve over Equation (2) via Theorem 4.3, our
data-dependent bound.

To make use of Theorem 4.3, we now formally deﬁne the function class whose dual (γ, ∞)-
approximates F ∗. We ﬁrst deﬁne the dual class, then the primal class. To this end, ﬁx some

1If x+

i (resp., x−

i ) is infeasible, then we deﬁne ˘cx − ˘cx+

(resp., ˘cx − ˘cx−

i

) to be some large number greater than

i

||c||1.

8

integer j ≥ 1 and let Hj be the set of all piecewise-constant functions mapping [0, 1] to [0, 1] with
at most j pieces. For every IP x, we deﬁne g∗
x − h(cid:107)∞, breaking ties in some
ﬁxed but arbitrary manner. We deﬁne the dual class G∗
. Therefore, the dual class
G∗
j is consists of piecewise-constant functions with at most j pieces. In keeping with the deﬁnition
of primal and dual functions from Section 3, for every parameter r ∈ [0, 1] and IP x, we deﬁne
gj,r(x) = g∗

j,x(r). Finally, we deﬁne the primal class Gj = {gj,r | r ∈ [0, 1]} .

j,x ∈ argminh∈Hj (cid:107)f ∗
(cid:110)

g∗
j,x | x ∈ X

j =

To apply our results from Section 4.1, we must bound the Rademacher complexity of the set Gj.
j . The following lemma2 is a corollary

Doing so is simple due to the structure of the dual class G∗
of Lemma B.4 in Appendix B.2.

(cid:111)

Lemma 4.8. For any set S ⊆ X of integer programs, (cid:98)RS (Gj) ≤

(cid:113) 2 ln(|S|(j−1)+1)
|S|

.

This lemma together with Remark 4.5 and Corollary 4.4 imply that with probability 1 − δ over
S ∼ DN , for all parameters r ∈ [0, 1] and j ≥ 1, (cid:12)
(cid:12) 1
(cid:12) is upper-bounded
N
by the minimum of Equation (2) and

x∈S fr(x) − Ex∼D [fr(x)](cid:12)

(cid:80)

(cid:104)(cid:13)
(cid:13)f ∗

x − g∗
j,x

(cid:105)

(cid:13)
(cid:13)∞

+ 2

2 E
x∼D

(cid:114)

2 ln(N (j − 1) + 1)
N

+

(cid:114)

2
N

ln

2(πj)2
3δ

.

(3)

As j grows, (cid:98)RS (Gj) grows, but the dual class G∗
ments, we optimize this tradeoﬀ between generalizability and approximability.

j is better able to approximate F ∗. In our experi-

Experiments. We analyze distributions over IPs formulating the combinatorial auction winner
determination problem under the OR-bidding language [38], which we generate using the Combi-
natorial Auction Test Suite (CATS) [31]. We use the “arbitrary” generator with 200 bids and 100
goods, resulting in IPs with 200 about variables, and the “regions” generator with 400 bids and
200 goods, resulting in IPs with 400 about variables.

We use the algorithm described in Appendix D.1 of the paper by Balcan et al. [7] to compute
the functions f ∗
It overrides the default VSP of CPLEX 12.8.0.0 using the C API. We use
x .
Algorithm 1 in Appendix B.2 to compute the approximating duals. All experiments were run on a
64-core machine with 512 GB of RAM.

In Figure 2, we select score1, score2 ∈ {scoreL, scoreS, scoreA, scoreP } and compare the
worst-case and data-dependent bounds. First, we plot the worst-case bound from Equation (2),
with δ = 0.01, as a function of the number of training examples N . This is the black, dotted line
in Figure 2.

Next, we plot the data-dependent bound, which is the red, solid line in Figure 2. To calcu-
late the data-dependent bound in Equation (3), we have to estimate Ex∼D
for all
j ∈ [1600].3 To do so, we draw M = 6000 IPs x1, . . . , xM from the distribution D. We esti-
via the empirical average 1
mate Ex∼D
. A Hoeﬀding bound
M
guarantees that with probability 0.995, for all j ∈ [1600],

(cid:104)(cid:13)
(cid:13)f ∗
(cid:13)

(cid:104)(cid:13)
(cid:13)f ∗
(cid:13)

x − g∗
j,x

x − g∗
j,x

xi − g∗

(cid:13)
(cid:13)f ∗
(cid:13)

(cid:13)
(cid:13)
(cid:13)∞

(cid:13)
(cid:13)
(cid:13)∞

(cid:13)
(cid:13)
(cid:13)∞

(cid:80)M

j,xi

i=1

(cid:105)

(cid:105)

(cid:104)(cid:13)
(cid:13)f ∗

x − g∗
j,x

E

(cid:105)

(cid:13)
(cid:13)∞

≤

1
M

M
(cid:88)

i=1

(cid:13)
(cid:13)f ∗

xi − g∗

j,xi

(cid:13)
(cid:13)∞

+

1
40

.

(4)

2This bound on (cid:98)RS (Gj) could potentially be optimized even further using a data-dependent approach, such as

the one summarized by Theorem E.3 in the paper by Balcan et al. [7].

3We choose the range j ∈ [1600] because under these distributions, the functions f ∗

x generally have at most 1600

pieces.

9

(a) Results on the CATS “regions” generator with
score1 = scoreL and score2 = scoreS.

(b) Results on the CATS “arbitrary” generator with
score1 = scoreL and score2 = scoreS.

(c) Results on the CATS “arbitrary” generator with
score1 = scoreP and score2 = scoreA.

Figure 2: Experiments where we compare our generalization bound to the worst-case bound by Bal-
can et al. [7]. The red solid line is our generalization bound: the minimum of Equations (2) and
(5) as a function of the number of training examples N . The black dotted line is the worst-case
bound from Equation (2).

We prove this inequality in Lemma B.3. We thereby estimate our data-dependent bound Equa-
tion (3) using the following bound:

min
j∈[1600]

(cid:32)

(cid:40)
2

1
M

M
(cid:88)

i=1

(cid:13)
(cid:13)f ∗

xi − g∗

j,xi

(cid:33)

(cid:114)

+ 2

(cid:13)
(cid:13)∞

+

1
40

2 ln(N (j − 1) + 1)
N

+

(cid:114)

2
N

ln

(20πj)2
3

(cid:41)

.

(5)

The only diﬀerence between Equations (3) and (5) is that Equation (3) relies on the left-hand-side
of Equation (4) and Equation (5) relies on the right-hand-side of Equation (4) and sets δ = 0.005.4
In Figure 2, the red solid line equals the minimum of Equations (2) and (5) as a function of the
number of training examples N .

In Figure 2, we see that our bound signiﬁcantly beats the worst-case bound up until the point
there are approximately 100,000,000 training instances. At this point, the worst-case guarantee is

4Like the worst-case bound, Equation (5) holds with probability 0.99, because with probability 0.995, Equation (4)

holds, and with probability 0.995, the bound from Equation (3) holds.

10

Figure 3: The dual functions f ∗
under, for example, the L1-norm because the integrals (cid:82)
xi(r) = 1
2 . The approximation is not strong under the L∞-norm, since maxr∈R
f ∗
The function class F corresponding to these duals has a large Rademacher complexity.

x2 are well-approximated by the constant function r (cid:55)→ 1
2
(cid:12)
xi(r) − 1
(cid:12) dr are small; for most r,
2
(cid:12)
(cid:12) = 1
2 .

x1 and f ∗

xi(r) − 1
2

(cid:12)
(cid:12)f ∗

(cid:12)
(cid:12)f ∗

R

Figure 4: The dual functions f ∗
under the L∞-norm since maxr∈R
duals has a small Rademacher complexity.

x1 and f ∗
(cid:12)
(cid:12)f ∗

xi(r) − 1
2

x2 are well-approximated by the constant function r (cid:55)→ 1
2
(cid:12)
(cid:12) is small. The function class F corresponding to these

i=1

(cid:80)M

(cid:13)
(cid:13)f ∗
(cid:13)

xi − g∗

better than the data-dependent bound, which makes sense because it goes to zero as N goes to
+ 1
inﬁnity, whereas the term 1
40 in our bound (Equation (5)) is a constant.
M
Figure 2(a) also illustrates that even when there are only 105 training instances, our bound
provides a generalization guarantee of approximately 0.1. Meanwhile, 7 · 107 training instances
are necessary to provide a generalization guarantee of 0.1 under the worst-case bound, so the
sample complexity implied by our analysis is 700 times better. Similarly, in Figure 2(b), 500 times
fewer samples are required to obtain a generalization guarantee of 0.1 under our bound versus the
worst-case bound. In Figure 2(c), 250 times fewer samples are required.

(cid:13)
(cid:13)
(cid:13)∞

j,xi

In this section, we approximated the dual functions f ∗

x with piecewise constant functions that
have a small number of pieces — say, j pieces. We used SRM to ﬁnd the value for j which leads to
the strongest bounds, as in Equation (5). In Appendix B.2.1, we compare against another baseline
where we do not use SRM, but simply set j to be the maximum number of pieces we observe over
our training set. Of course, this bound is much tighter than the worst-case bound by Balcan et al.
[7], the baseline in Figure 2. However, we still observe that for a target generalization error, the
number of samples required according to our bound is up to four times smaller than the number
of samples required by this baseline.

4.3 Rademacher complexity lower bound

In this section, we show that (γ, p)-approximability with p < ∞ does not necessarily imply strong
generalization guarantees of the type we saw in Section 4.1. We show that it is possible for a dual
class F ∗ to be well-approximated by the dual of a class G with (cid:98)RS (G) = 0, yet for the primal F
to have high Rademacher complexity.

11

x(r) = gr(x) = 1

x1 (the blue solid line) and f ∗

for p < ∞. Figure 3 illustrates two dual functions f ∗
line). Let G be the extremely simple function class G = {gr : r ∈ R} where gr(x) = 1
x ∈ X . It is easy to see that (cid:98)RS (G) = 0 for any set S. Moreover, every dual function g∗
simple, because g∗
well approximated by the constant function g∗
(cid:12)
because the integrals (cid:82)
(cid:12)f ∗
the L∞-norm, since maxr∈R

Figures 3 and 4 help explain why there is this sharp constrast between the L∞- and Lp-norms
x2 (the grey dotted
2 for every
x is also
x2 are
2 under, for example, the L1-norm
(cid:12)
xi(r) − 1
(cid:12) dr are small. However, the approximation is not strong under
2
(cid:12)
xi(r) − 1
(cid:12)f ∗
2
Moreover, despite the fact that (cid:98)RS (G) = 0, we have that (cid:98)RS (F ) = 1

2 . From Figure 3, we can see that the functions f ∗
x2(r) = 1

2 when S = {x1, x2},
which makes Theorem 4.2 meaningless. At a high level, this is because when σ1 = 1, we can
ensure that σ1fr (x1) = σ1f ∗
x1 (r) = 1 by choosing r ∈ {r0, r1} and when σ1 = −1, we can ensure
In summary,
that σ1fr (x1) = 0 by choosing r ∈ {r2, r3}. A similar argument holds for σ2.
(γ, p)-approximability for p < ∞ does not guarantee low Rademacher complexity.

2 for i ∈ {1, 2}.

x1(r) = g∗

x1 and f ∗

(cid:12)
(cid:12) = 1

R

Meanwhile, in Figure 4, g∗

xi(r) are close for every parameter r. As a result,
x2(r)(cid:9). This
(cid:8)σ1g∗
x2(r)(cid:9) is close to supr∈R
for any noise vector σ, supr∈R
implies that the Rademacher complexities (cid:98)RS (G) and (cid:98)RS (F ) are close. This illustration exempliﬁes
Theorem 4.3: (γ, ∞)-approximability implies strong Rademacher bounds.

2 and f ∗
x1(r) + σ2f ∗

xi(r) = 1
(cid:8)σ1f ∗

x1(r) + σ2g∗

We now prove that (γ, p)-approximability by a simple class for p < ∞ does not guarantee low

Rademacher complexity.

Theorem 4.9. For any γ ∈ (0, 1/4) and any p ∈ [1, ∞), there exist function classes F , G ⊂ [0, 1]X
such that the dual class G∗ (γ, p)-approximates F ∗ and for any N ≥ 1, supS:|S|=N (cid:98)RS (G) = 0 and
supS:|S|=N (cid:98)RS (F ) = 1
2 .

Proof. We begin by deﬁning the classes F and G. Let R = (0, γp], and X = [γ−p/2, ∞). For
any r ∈ R and x ∈ X , let fr(x) = 1
2 (1 + cos(rx)) and F = {fr | r ∈ R}. These sinusoidal
functions are based on the intuition from Figure 3. As in Figure 3, for any r and x, let gr(x) = 1
2
and G = {gr | r ∈ R}. Since G consists of identical copies of a single function, (cid:98)RS (G) = 0 for
any set S ⊆ X . Meanwhile, in Lemma B.9 in Appendix B.3, we prove that for any N ≥ 1,
supS:|S|=N (cid:98)RS (F ) = 1
2 .

In Lemma B.8 in Appendix B.3, we prove that the dual class G∗ (γ, p)-approximates F ∗. To
x ≤ 2γ2, so
x(cid:107)2, H¨older’s inequality, and the log-

prove this, we ﬁrst show that (cid:107)f ∗
(cid:107)f ∗
convexity of the Lp-norm to prove that (cid:107)f ∗

2γp + 1
x(cid:107)2 < γ. Otherwise, we use our bound on (cid:107)f ∗
x(cid:107)p ≤ γ.

x . When p = 2, we know 1
x − g∗

x(cid:107)2 ≤ 1
4

x − g∗

x − g∗

x − g∗

(cid:113)

Remark 4.10. Suppose, for example, that R = [0, 1]d. Theorem 4.9 implies that even if

|f ∗

x (r) − g∗

x(r)|

is small for all x in expectation over r ∼ Uniform(R), the function class F may not have
Rademacher complexity close to G.

Statistical learnability.
In Appendix B.4, we connect our results to the literature on statistical
learnability [18]. At a high level, a function class F is statistically learnable (Deﬁnition A.2 in
Appendix A) if there exists a learning algorithm that returns a function whose expected value
converges—as the size of the training set grows—to the smallest expected value of any function in
F . We introduce a relaxation: a function class F is γ-statistically learnable (Deﬁnition A.3) if, at
a high level, there exists a learning algorithm with error at most γ in the limit as the training set

12

size grows. We prove that if the dual class F ∗ is (γ, ∞)-approximated by the dual of a statistically
learnable class G, then F is γ-statistically learnable. On the other hand, Theorem 4.9 implies that
there exists a class F that is not γ-statistically learnable, yet it is (γ, p)-approximated by the dual
of a statistically learnable class G.

5 Conclusions

We provided generalization guarantees for algorithm conﬁguration, which bound the diﬀerence be-
tween a parameterized algorithm’s average empirical performance over a set of sample problem
instances and its expected performance on future, unseen instances. We did so by exploiting struc-
ture exhibited by the dual functions which measure the algorithm’s performance as a function of its
parameters. We analyzed the widely-applicable setting where the dual functions are approximated
by “simple” functions. We showed that if this approximation holds under the L∞-norm, then it
is possible to provide strong generalization guarantees. If, however, the approximation only holds
under the Lp-norm for p < ∞, we showed that it is impossible in the worst-case to provide non-
trivial bounds. Via experiments in the context of integer programming algorithm conﬁguration,
we demonstrated that our bounds can be signiﬁcantly stronger than the best-known worst-case
guarantees [7], leading to a sample complexity improvement of 70,000%.

x (r) − g∗

We conclude with a direction for future research. Suppose, for some prior P over parameters,
Ex∼D,r∼P [|f ∗
x(r)|] is small. From Remark 4.10, we know strong generalization bounds
are not possible in the worst case, but what about under some realistic assumptions? This may
help us understand, for example, why random forests—which have a simple piecewise-constant
structure—are often able to accurately predict the runtime of SAT and MIP solvers [22].

Acknowledgments. We thank Kevin Leyton-Brown for a stimulating discussion that inspired
us to pursue this research direction.

This material is based on work supported by the National Science Foundation under grants
CCF-1535967, CCF-1733556, CCF-1910321, IIS-1617590, IIS-1618714, IIS-1718457, IIS-1901403,
and SES-1919453; the ARO under awards W911NF-17-1-0082 and W911NF2010081; a fellowship
from Carnegie Mellon University’s Center for Machine Learning and Health; the Defense Advanced
Research Projects Agency under cooperative agreement HR00112020003; an Amazon Research
Award; an AWS Machine Learning Research Award; an Amazon Research Award; a Bloomberg
Research Grant; and a Microsoft Research Faculty Fellowship.

References

[1] Tobias Achterberg. SCIP: solving constraint integer programs. Mathematical Programming

Computation, 1(1):1–41, 2009.

[2] Alejandro Marcos Alvarez, Quentin Louveaux, and Louis Wehenkel. A machine learning-based
approximation of strong branching. INFORMS Journal on Computing, 29(1):185–195, 2017.

[3] Martin Anthony and Peter Bartlett. Neural Network Learning: Theoretical Foundations. Cam-

bridge University Press, 2009.

[4] Patrick Assouad. Densit´e et dimension. Annales de l’Institut Fourier, 33(3):233–282, 1983.

13

[5] Amine Balafrej, Christian Bessiere, and Anastasia Paparrizou. Multi-armed bandits for adap-
tive constraint propagation. Proceedings of the International Joint Conference on Artiﬁcial
Intelligence (IJCAI), 2015.

[6] Maria-Florina Balcan, Vaishnavh Nagarajan, Ellen Vitercik, and Colin White. Learning-
theoretic foundations of algorithm conﬁguration for combinatorial partitioning problems. In
Conference on Learning Theory (COLT), 2017.

[7] Maria-Florina Balcan, Travis Dick, Tuomas Sandholm, and Ellen Vitercik. Learning to branch.

In International Conference on Machine Learning (ICML), 2018.

[8] Maria-Florina Balcan, Travis Dick, and Ellen Vitercik. Dispersion for data-driven algorithm
design, online learning, and private optimization. In Proceedings of the Annual Symposium on
Foundations of Computer Science (FOCS), 2018.

[9] Maria-Florina Balcan, Travis Dick, and Colin White. Data-driven clustering via parameterized
Lloyd’s families. In Proceedings of the Annual Conference on Neural Information Processing
Systems (NeurIPS), 2018.

[10] Maria-Florina Balcan, Dan DeBlasio, Travis Dick, Carl Kingsford, Tuomas Sandholm, and
arXiv

Ellen Vitercik. How much data is suﬃcient to learn high-performing algorithms?
preprint arXiv:1908.02894, 2019.

[11] Maria-Florina Balcan, Travis Dick, and Manuel Lang. Learning to link. Proceedings of the

International Conference on Learning Representations (ICLR), 2020.

[12] Maria-Florina Balcan, Tuomas Sandholm, and Ellen Vitercik. Learning to optimize compu-
tational resources: Frugal training with generalization guarantees. In AAAI Conference on
Artiﬁcial Intelligence, 2020.

[13] Evelyn Beale. Branch and bound methods for mathematical programming systems. Annals of

Discrete Mathematics, 5:201–219, 1979.

[14] Michel B´enichou, Jean-Michel Gauthier, Paul Girodet, Gerard Hentges, Gerard Ribi`ere, and
O Vincent. Experiments in mixed-integer linear programming. Mathematical Programming, 1
(1):76–94, 1971.

[15] Giovanni Di Liberto, Serdar Kadioglu, Kevin Leo, and Yuri Malitsky. Dash: Dynamic approach
for switching heuristics. European Journal of Operational Research, 248(3):943–953, 2016.

[16] J-M Gauthier and Gerard Ribi`ere. Experiments in mixed-integer linear programming using

pseudo-costs. Mathematical Programming, 12(1):26–47, 1977.

[17] Rishi Gupta and Tim Roughgarden. A PAC approach to application-speciﬁc algorithm selec-

tion. SIAM Journal on Computing, 46(3):992–1017, 2017.

[18] David Haussler. Decision theoretic generalizations of the PAC model for neural net and other

learning applications. Information and computation, 100(1):78–150, 1992.

[19] He He, Hal Daume III, and Jason M Eisner. Learning to search in branch and bound algo-
rithms. In Proceedings of the Annual Conference on Neural Information Processing Systems
(NeurIPS), 2014.

14

[20] Eric Horvitz, Yongshao Ruan, Carla Gomez, Henry Kautz, Bart Selman, and Max Chicker-
In Proceedings of the

ing. A Bayesian approach to tackling hard computational problems.
Conference on Uncertainty in Artiﬁcial Intelligence (UAI), 2001.

[21] Frank Hutter, Holger Hoos, Kevin Leyton-Brown, and Thomas St¨utzle. ParamILS: An auto-
matic algorithm conﬁguration framework. Journal of Artiﬁcial Intelligence Research, 36(1):
267–306, 2009. ISSN 1076-9757.

[22] Frank Hutter, Holger Hoos, and Kevin Leyton-Brown. Sequential model-based optimization
for general algorithm conﬁguration. In International Conference on Learning and Intelligent
Optimization (LION), pages 507–523, 2011.

[23] Serdar Kadioglu, Yuri Malitsky, Meinolf Sellmann, and Kevin Tierney. ISAC—instance-speciﬁc
algorithm conﬁguration. In Proceedings of the European Conference on Artiﬁcial Intelligence
(ECAI), 2010.

[24] Elias Boutros Khalil, Pierre Le Bodic, Le Song, George Nemhauser, and Bistra Dilkina. Learn-
ing to branch in mixed integer programming. In AAAI Conference on Artiﬁcial Intelligence,
2016.

[25] Elias Boutros Khalil, Bistra Dilkina, George Nemhauser, Shabbir Ahmed, and Yufen Shao.
Learning to run heuristics in tree search. In Proceedings of the International Joint Conference
on Artiﬁcial Intelligence (IJCAI), 2017.

[26] Robert Kleinberg, Kevin Leyton-Brown, and Brendan Lucier. Eﬃciency through procrastina-
tion: Approximately optimal algorithm conﬁguration with runtime guarantees. In Proceedings
of the International Joint Conference on Artiﬁcial Intelligence (IJCAI), 2017.

[27] Robert Kleinberg, Kevin Leyton-Brown, Brendan Lucier, and Devon Graham. Procrastinating
with conﬁdence: Near-optimal, anytime, adaptive algorithm conﬁguration. Proceedings of the
Annual Conference on Neural Information Processing Systems (NeurIPS), 2019.

[28] Vladimir Koltchinskii. Rademacher penalties and structural risk minimization. IEEE Trans-

actions on Information Theory, 47(5):1902–1914, 2001.

[29] Markus Kruber, Marco E L¨ubbecke, and Axel Parmentier. Learning when to use a decompo-
sition. In International Conference on AI and OR Techniques in Constraint Programming for
Combinatorial Optimization Problems, pages 202–210. Springer, 2017.

[30] Ailsa H Land and Alison G Doig. An automatic method of solving discrete programming

problems. Econometrica, pages 497–520, 1960.

[31] Kevin Leyton-Brown, Mark Pearson, and Yoav Shoham. Towards a universal test suite for
combinatorial auction algorithms. In Proceedings of the ACM Conference on Electronic Com-
merce (ACM-EC), pages 66–76, Minneapolis, MN, 2000.

[32] Jeﬀ Linderoth and Martin Savelsbergh. A computational study of search strategies for mixed

integer programming. INFORMS Journal of Computing, 11(2):173–187, 1999.

[33] Andrea Lodi and Giulia Zarpellon. On learning and branching: a survey. TOP: An Oﬃcial
Journal of the Spanish Society of Statistics and Operations Research, 25(2):207–236, 2017.

15

[34] Pascal Massart. Some applications of concentration inequalities to statistics. In Annales de la

Facult´e des sciences de Toulouse: Math´ematiques, volume 9, pages 245–303, 2000.

[35] Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. Foundations of Machine Learn-

ing. MIT Press, 2012.

[36] George Nemhauser and Laurence Wolsey. Integer and Combinatorial Optimization. John Wiley

& Sons, 1999.

[37] Ashish Sabharwal, Horst Samulowitz, and Chandra Reddy. Guiding combinatorial optimiza-
tion with UCT. In International Conference on AI and OR Techniques in Constraint Pro-
gramming for Combinatorial Optimization Problems. Springer, 2012.

[38] Tuomas Sandholm. Algorithm for optimal winner determination in combinatorial auctions.

Artiﬁcial Intelligence, 135:1–54, January 2002.

[39] Tuomas Sandholm. Very-large-scale generalized combinatorial multi-attribute auctions:
In Zvika Neeman, Alvin Roth, and Nir

Lessons from conducting $60 billion of sourcing.
Vulkan, editors, Handbook of Market Design. Oxford University Press, 2013.

[40] Karthik Sridharan. Learning from an optimization viewpoint. PhD thesis, Toyota Technological

Institute at Chicago, 2012.

[41] Gell´ert Weisz, Andr´as Gy¨orgy, and Csaba Szepesv´ari. LeapsAndBounds: A method for ap-
proximately optimal algorithm conﬁguration. In International Conference on Machine Learn-
ing (ICML), 2018.

[42] Gell´ert Weisz, Andr´es Gy¨orgy, and Csaba Szepesv´ari. CapsAndRuns: An improved method
International Conference on Machine

for approximately optimal algorithm conﬁguration.
Learning (ICML), 2019.

16

A Notation and learning theory background

In this appendix, we study a more general setting than in the main body where the learning
algorithms have access to examples x ∈ X that may be labeled by a real value y ∈ R. The learning
algorithms we analyze have sample access to an unknown distribution D over (labeled) examples
(x, y) ∈ X ×[0, 1]. The fact that the examples are labeled is without loss of generality; in our integer
programming algorithm conﬁguration example, there are no labels, or equivalently, for every tuple
(x, y) in the support of D, y = 0. We use the notation D|X to denote the marginal distribution of
D over X .

Given a set of functions F ⊆ [0, 1]X , the learning algorithms we study aim to ﬁnd a function
h : X → [0, 1] with expected absolute loss E(x,y)∼D[|h(x) − y|] that is nearly as small as the smallest
expected loss of any function in F , inf f ∈F E(x,y)∼D[|f (x) − y|]. (Though we focus on absolute loss
in this paper, we believe our results can be generalized to other loss functions, which we leave for
future research.) The function h may or may not be a member of the set F , depending on the
speciﬁc learning task at hand.

In the integer programming example from the main body, the functions in F are parameterized
by CPLEX parameter vectors r ∈ Rd, denoted F = (cid:8)fr | r ∈ Rd(cid:9) . As we described in the main
body, for any integer program x ∈ X and parameter vector r ∈ Rd, fr(x) equals the size of the
branch-and-bound tree CPLEX builds given the parameter setting r and input IP x, normalized
to fall within the interval [0, 1]. The learning algorithms we study take as input a training set of
integer programs x1, . . . , xN ∼ D|X and return a CPLEX parameter vector ˆr ∈ Rd, or equivalently,
a function f ˆr ∈ F . Since our goal is to minimize tree size, ideally, the size of the trees CPLEX
builds using the parameter setting ˆr should be small in expectation over D when compared with
the best choice of a parameter setting. In other words, E(x,y)∼D [f ˆr(x)] − inf fr∈F E(x,y)∼D [fr(x)]
should be small. (Recall that in this setting, for every tuple (x, y) in the support of D, y = 0.)

We denote absolute loss using the notation (cid:96)(x, y, f ) = |f (x) − y|. Given a set of samples S =
{(x1, y1) , . . . , (xN , yN )} ⊆ X × [0, 1], we use the standard notation LS (f ) = 1
i=1 |f (xi) − yi| to
N
denote the average empirical loss of a function f : X → [0, 1] and LD(f ) = E(x,y)∼D[|f (x) − y|] to
denote the expected loss of f . The absolute loss function can be naturally incorporated into the def-
inition of Rademacher complexity: (cid:98)RS ((cid:96) ◦ F ) = 1
. The
N
worst-case empirical Rademacher complexity of a class F is deﬁned as RN ((cid:96)◦F ) = supS:|S|=N (cid:98)RS ((cid:96)◦
F ).

(cid:105)
i=1 σi |f (xi) − yi|

Eσ∼{−1,1}N

supf ∈F

(cid:80)N

(cid:80)N

(cid:104)

We now review several standard deﬁnitions from learning theory, beginning with that of a

learning algorithm.

Deﬁnition A.1 (Learning algorithm). A learning algorithm A takes as input a set S ⊆ X × [0, 1]
of examples and returns a function AS : X → [0, 1].

As we described earlier in this section, in the integer programming example, we study learning

algorithms A where AS = f ˆr for some CPLEX parameter setting ˆr ∈ Rd.

A function class F ⊆ [0, 1]X is statistically learnable [18] if there exists some algorithm A whose
expected loss LD (AS ) converges to the loss of the best function in F , inf f ∈F LD(f ), even for a
worst-case distribution D. We formalize this notion below.

Deﬁnition A.2 (Statistical learnability). Let F be a set of functions mapping X to [0, 1] and
(cid:2)LD (AS ) − inf f ∈F LD(f )(cid:3) . The function class F is statistically
let VN (F ) = inf A supD ES∼DN
learnable if limN →∞ VN (F ) = 0.

In the integer programming example, suppose the class F = (cid:8)fr | r ∈ Rd(cid:9) is statistically learn-
able. Then there exists a learning algorithm A that returns a CPLEX parameter setting ˆr, or

17

equivalently, a function AS = f ˆr ∈ F , such that the size of the trees CPLEX builds using the pa-
rameter setting ˆr is small in expectation over D when compared with the best choice of a parameter
setting.

In this work, we study a relaxation of statistical learnability, which we refer to as γ-statistical
learnability. A function class F is γ-statistically-learnable if there exists an algorithm whose ex-
pected loss converges to the loss of the best function in F , plus an additive error term γ.

Deﬁnition A.3 (γ-statistically learnable). Let F be a class of functions mapping X to [0, 1]. The
class is γ-statistically learnable if limN →∞ VN (F ) ≤ γ.

Based on Theorem 4.2, it is well-known and easy-to-see that if the worst-case empirical Rademacher

complexity of the function class F converges to zero as the number of samples grows, then the class
F is statistically learnable. In other words, if limN →∞ RN ((cid:96) ◦ F ) = 0, then limN →∞ VN (F ) = 0.
In our integer programming example, suppose the Rademacher complexity of the class F is
small. Theorem 4.2 guarantees that with high probability over the draw a set of N IPs S =
X , for every choice of a CPLEX parameter vector r ∈ Rd, the size of the tree
{x1, . . . , xN } ∼ D|N
CPLEX builds when parameterized by r on average over the IPs in S is close to the size of the
tree CPLEX builds in expectation over the draw of an IP x ∼ D|X .

If a function class’s Rademacher complexity does not converge to zero, then the class is not

statistically learnable. We provide an example of one such negative result below.

Theorem A.4 (Sridharan [40]). For any N ≥ 1 and F ⊆ [0, 1]X , VN (F ) ≥ R2N ((cid:96) ◦ F ) − 1
2
F ).

RN ((cid:96) ◦

Theorem A.4 demonstrates that if RN ((cid:96) ◦ F ) does not converge to zero, then VN (F ) will not

converge to zero either.

B Additional details about learnability and approximability (Sec-

tion 4)

B.1 Proofs about data-dependent generalization guarantees (Section 4.1)

Theorem 4.3. Let F = {fr | r ∈ R} and G = {gr | r ∈ R} consist of functions mapping X to
[0, 1]. For any S ⊆ X , (cid:98)RS (F ) ≤ (cid:98)RS (G) + 1
|S|

x∈S (cid:107)f ∗

x − g∗

x(cid:107)∞ .

(cid:80)

xi(r) ≤ g∗

Proof. Let S = {x1, . . . , xN } be an arbitrary subset of X . Fix an arbitrary vector r ∈ R and index
xi(r) + (cid:13)
i ∈ [N ]. Suppose that σi = 1. Since f ∗
xi(r) + (cid:13)
(cid:13)f ∗
xi(r) − (cid:13)
(cid:13)
(cid:13)∞ = σig∗

(cid:13)
xi − g∗
(cid:13)∞, we have that
xi
(cid:13)
(cid:13)∞ .
(cid:13)
(cid:13)∞, we have that
xi(r) + (cid:13)

Meanwhile, suppose σi = −1. Since f ∗

xi(r) ≥ g∗
xi(r) + (cid:13)

xi(r) ≤ σig∗

xi(r) = −f ∗

xi(r) ≤ −g∗

xi − g∗
xi

xi − g∗
xi

xi − g∗
xi

xi − g∗
xi

(cid:13)
(cid:13)∞ .

σif ∗

σif ∗

(cid:13)f ∗

(cid:13)f ∗

(cid:13)f ∗

(cid:13)f ∗

(7)

(6)

Combining Equations (6) and (7), we have that

N
(cid:88)

i=1

sup
r∈R

σigr (xi) ≥

N
(cid:88)

i=1

σig∗

xi(r) ≥

N
(cid:88)

i=1

18

σif ∗

xi(r) − (cid:13)

(cid:13)f ∗

xi − g∗
xi

(cid:13)
(cid:13)∞ .

(8)

By deﬁnition of the supremum, Equation (8) implies that for every σ ∈ {−1, 1}N ,

N
(cid:88)

i=1

sup
r∈R

σigr (xi) ≥ sup
r∈R

N
(cid:88)

i=1

σifr (xi) −

N
(cid:88)

i=1

(cid:13)
(cid:13)f ∗

xi − g∗
xi

(cid:13)
(cid:13)∞ .

Therefore

(cid:34)

E
σ∼{−1,1}N

sup
r∈R

N
(cid:88)

i=1

(cid:35)

(cid:34)

σigr (xi)

≥

E
σ∼{−1,1}N

sup
r∈R

(cid:35)

σifr (xi)

−

N
(cid:88)

i=1

N
(cid:88)

i=1

(cid:13)
(cid:13)f ∗

xi − g∗
xi

(cid:13)
(cid:13)∞ ,

so the lemma statement holds.

Corollary 4.4. With probability 1 − δ over the draw of the set S ∼ DN , for all r ∈ R and all
j ≥ 1,

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
N

(cid:88)

x∈S

fr(x) − E
x∼D

(cid:12)
(cid:12)
(cid:12)
[fr(x)]
(cid:12)
(cid:12)

(cid:32)

= O

1
N

(cid:88)

x∈S

(cid:13)
(cid:13)f ∗

x − g∗
j,x

(cid:13)
(cid:13)∞

+ (cid:98)RS (Gj) +

(cid:114) 1
N

(cid:33)

.

j
δ

ln

(1)

Proof. We will prove that with probability at least 1 − δ over the draw of the training set S =
{(x1, y1) , . . . , (xN , yN )} ∼ DN , for all parameter vectors r ∈ R and all j ∈ N,

|LS (fr) − LD (fr)| ≤

2
N

N
(cid:88)

i=1

(cid:13)
(cid:13)f ∗

xi − g∗

j,xi

(cid:13)
(cid:13)∞

+ 2 (cid:98)RS ((cid:96) ◦ Gj) + 3

(cid:114)

1
2N

ln

(πj)2
3δ

.

For each integer j ≥ 1, let δj = 6δ

(πj)2 . From Theorems 4.2 and 4.3, we know that with probability
at least 1−δj over the draw of the training set S = {(x1, y1) , . . . , (xN , yN )} ∼ DN , for all parameter
vectors r ∈ R,

|LS (fr) − LD (fr)| ≤

=

2
N

2
N

N
(cid:88)

i=1
N
(cid:88)

i=1

(cid:13)
(cid:13)f ∗

xi − g∗

j,xi

(cid:13)
(cid:13)f ∗

xi − g∗

j,xi

(cid:13)
(cid:13)∞

(cid:13)
(cid:13)∞

+ 2 (cid:98)RS ((cid:96) ◦ Gj) + 3

+ 2 (cid:98)RS ((cid:96) ◦ Gj) + 3

(cid:115)

(cid:114)

1
2N

1
2N

ln

2
δj

ln

(πj)2
3δ

.

Since (cid:80)∞

i=1 δj = δ, the corollary follows from a union bound over all j ≥ 1.

Corollary B.1. Let F = {fr | r ∈ R} ⊆ [0, 1]X be a set of functions mapping X to [0, 1]. Let
G1, G2, G3, . . . be a countable sequence of function classes, where for each j ∈ N, Gj = {gj,r | r ∈ R} ⊆
[0, 1]X is a set of functions mapping X to [0, 1], parameterized by vectors r ∈ R. With probability
at least 1 − δ over the draw of the training set S = {(x1, y1) , . . . , (xN , yN )} ∼ DN , for all parameter
vectors r ∈ R and all j ∈ N,

|LS (fr) − LD (fr)| ≤ 2 (cid:98)RS ((cid:96) ◦ Gj) + 2 E

x∼D|X

(cid:104)(cid:13)
(cid:13)f ∗

x − g∗
j,x

(cid:105)

(cid:13)
(cid:13)∞

+

(cid:114)

2
N

ln

2(πj)2
3δ

.

Proof. From Theorem 4.3, we know that for every integer j ≥ 1,

(cid:104)

(cid:98)RS (cid:48)((cid:96) ◦ F )

(cid:105)

E
S (cid:48)∼DN

≤ E

S (cid:48)∼DN

(cid:104)
(cid:98)RS (cid:48) ((cid:96) ◦ Gj)

(cid:105)

+ E

x∼D|X

(cid:104)(cid:13)
(cid:13)f ∗

x − g∗
j,x

(cid:105)

.

(cid:13)
(cid:13)∞

19

For each integer j ≥ 1, let δj = 6δ
(πj)2 . From Theorem B.2 and Hoeﬀding bound, we know that with
probability at least 1 − δj over the draw of the training set S = {(x1, y1) , . . . , (xN , yN )} ∼ DN , for
all parameter vectors r ∈ R,

|LS (fr) − LD (fr)| ≤ 2 (cid:98)RS ((cid:96) ◦ Gj) + 2 E

x∼D|X

= 2 (cid:98)RS ((cid:96) ◦ Gj) + 2 E

x∼D|X

(cid:104)(cid:13)
(cid:13)f ∗

x − g∗
j,x

(cid:105)

(cid:13)
(cid:13)∞

+

(cid:104)(cid:13)
(cid:13)f ∗

x − g∗
j,x

(cid:105)

(cid:13)
(cid:13)∞

+

(cid:115)

(cid:114)

2
N

2
N

ln

4
δj

ln

2(πj)2
3δ

.

Since (cid:80)∞

i=1 δj = δ, the corollary follows from a union bound over all j ≥ 1.

Theorem B.2 (e.g., Mohri et al. [35]). Let F ⊆ [0, 1]X be a set of functions mapping a domain X to
[0, 1]. With probability at least 1−δ over the draw of N samples S = {(x1, y1) , . . . , (xN , yN )} ∼ DN ,
the following holds for all f ∈ F :

|LS (fr) − LD (fr)| ≤ 2 E

S (cid:48)∼DN

(cid:104)

(cid:98)RS (cid:48)((cid:96) ◦ F )

(cid:105)

+

(cid:114) 1
2N

ln

2
δ

.

In the following lemma, we show that for any function classes F = {fr | r ∈ R} ⊆ [0, 1]X and
x(cid:107)∞], which appears in the generalization

G = {gr | r ∈ R} ⊆ [0, 1]X , the value E(x,y)∼D [(cid:107)f ∗
guarantee in from Corollary B.1, can be estimated from samples.

x − g∗

Lemma B.3. Let F = {fr | r ∈ R} ⊆ [0, 1]X and G = {gr | r ∈ R} ⊆ [0, 1]X be two sets of
functions mapping a domain X to [0, 1]. With probability 1 − δ over the draw of N samples
(x1, y1) , . . . , (xN , yN ) ∼ D,

E
(x,y)∼D

[(cid:107)f ∗

x − g∗

x(cid:107)∞] ≤

1
N

N
(cid:88)

i=1

(cid:13)
(cid:13)f ∗

xi − g∗
xi

(cid:13)
(cid:13)∞ +

(cid:114) 1
2N

ln

1
δ

.

(9)

Proof. Let h : X × [0, 1] → [0, 1] be deﬁned such that h(x, y) = (cid:107)f ∗
x(cid:107)∞. From Hoeﬀding’s
inequality, we know that with probability 1 − δ over the draw of N samples (x1, y1) , . . . , (xN , yN ) ∼
D,

x − g∗

E
(x,y)∼D

[h(x, y)] ≤

1
N

N
(cid:88)

i=1

h (xi, yi) +

which implies that Equation (9) holds.

(cid:114) 1
2N

ln

1
δ

,

B.2 Additional details about improved integer programming guarantees (Sec-

tion 4.2)

Selecting a tree size upper bound. As we described earlier in this section, we assume there
is an upper bound κ on the size of the largest tree we allow branch-and-bound to build before we
terminate, as in prior research [7, 21, 26, 27]. Given a parameter setting r ∈ [0, 1] and an integer
program x ∈ X , we deﬁne fr(x) to be the size of the tree CPLEX builds, capped at κ, divided by
κ (this way, fr(x) is normalized, contained in the interval [0, 1]).

We use a data-dependent approach to select κ. For any parameter r ∈ [0, 1] and integer program
x ∈ X , let hr(x) be the size of the tree CPLEX builds (unnormalized). We draw N = 6000 integer
programs x1, . . . , xN from the underlying distribution D and set κ = maxr∈[0,1],i∈[N ] hr (xi). Classic
results from learning theory guarantee that with high probability, for at most 8% of the integer

20

programs sampled from D, CPLEX will build a tree of size larger than κ when parameterized by
some r ∈ [0, 1]. Speciﬁcally, since the VC dimension of threshold functions is 1, we have that with
probability at least 0.99 over the draw of the N samples, Prx∼D

(cid:2)maxr∈[0,1] fr(x) > κ(cid:3) < 0.08.

For the “arbitrary” distribution, when score1 = scoreL and score2 = scoreS, κ = 6341, and
when score1 = scoreP and score2 = scoreA, κ = 2931. For the “regions” distribution, when
score1 = scoreL and score2 = scoreS, κ = 7314.

Dynamic programming. For any k ∈ N, let Gk be the set of piecewise-constant functions with
k pieces mapping an interval R ⊆ R to R. In this section, we provide a dynamic programming
x : R → R and a value k ∈ N
algorithm which takes as input a piecewise-constant dual function f ∗
and returns the value ming∈Gk (cid:107)f ∗
x is piecewise-constant, the domain R can be
partitioned into intervals [a1, a2) , [a2, a3) . . . , [at, at+1) such that for any interval [ai, ai+1), there
exists a value ci ∈ R such that f ∗

x (r) = ci for all r ∈ [ai, ai+1).
We now provide an overview of the algorithm. See Algorithm 1 for the pseudo-code.

x − g(cid:107)∞. Since f ∗

Algorithm 1 Piecewise-constant function ﬁtting via dynamic programming

Input: Partition [a1, a2) , . . . , [at, at+1) of R, values c1, . . . , ct, and desired number of pieces
k ∈ N.
for i ∈ [t] do

Set ui,i = ci and (cid:96)i,i = ci.
for i(cid:48) ∈ {i + 1, . . . , t} do
if ci(cid:48) < (cid:96)i,i(cid:48)−1 then

Set (cid:96)i,i(cid:48) = ci(cid:48) and ui,i(cid:48) = ui,i(cid:48)−1.

else if ci(cid:48) > ui,i(cid:48)−1 then

Set (cid:96)i,i(cid:48) = (cid:96)i,i(cid:48)−1 and ui,i(cid:48) = ci(cid:48).

else

Set (cid:96)i,i(cid:48) = (cid:96)i,i(cid:48)−1 and ui,i(cid:48) = ui,i(cid:48)−1.

for i ∈ [t] do

Set C(i, 1) = u1,i−(cid:96)1,i

2
for j ∈ {2, . . . , k} do
for i ∈ [t] do

Set C(i, j) = min

Output: C(t, k).

(cid:110)

C(i, 1), mini(cid:48)∈[i−1]

(cid:110)

C(i(cid:48), j − 1) +

ui(cid:48)+1,i−(cid:96)i(cid:48)+1,i
2

(cid:111)(cid:111)

The algorithm takes as input the partition [a1, a2) , . . . , [at, at+1) of the parameter space R and
values c1, . . . , ct such that for any interval [ai, ai+1), f ∗
x (r) = ci for all r ∈ [ai, ai+1). The algorithm
begins by calculating upper and lower bounds on the value of the function f ∗
x across various subsets
of its domain. In particular, for each i, i(cid:48) ∈ [t] such that i ≤ i(cid:48), the algorithm calculates the lower
bound (cid:96)i,i(cid:48) = min {ci, ci+1, . . . , ci(cid:48)} and the upper bound ui,i(cid:48) = max {ci, ci+1, . . . , ci(cid:48)}. Algorithm 1
performs these calculations in O(t2) time.

Next, for each i ∈ [t] and j ∈ [k], the algorithm calculates a value C(i, j) which equals the
smallest (cid:96)∞ norm between any piecewise constant function with j pieces and the function f ∗
x when
restricted to the interval [a1, ai+1). Since R = [a1, at+1), we have that C(t, k)—the value our
algorithm returns—equals ming∈Gk (cid:107)f ∗
and for

x − g(cid:107)∞, as claimed. For all i ∈ [t], C(i, 1) = u1,i−(cid:96)1,i

2

21

all j ≥ 2,

(cid:26)

C(i, j) = min

C(i, 1), min

i(cid:48)∈[i−1]

(cid:26)

C(i(cid:48), j − 1) +

ui(cid:48)+1,i − (cid:96)i(cid:48)+1,i
2

(cid:27)(cid:27)

.

Algorithm 1 performs these calculations in O(kt2) time.

Additional lemmas.

Lemma B.4. Let G = {gr | r ∈ R} ⊆ [0, 1]X be a set of functions mapping a set X to [0, 1]
x ∈ G∗ ⊆ [0, 1]R is
parameterized by a single real value r ∈ R. Suppose that every function g∗
piecewise-constant with at most j pieces. Then for any set S = {x1, . . . , xN } ⊆ X ,

(cid:98)RS (G) =

1
N

(cid:34)

E
σ∼{−1,1}N

sup
r∈R

N
(cid:88)

i=1

(cid:35)

(cid:114)

σigr (xi)

≤

2 ln(N (j − 1) + 1)
N

.

Proof. We will use Massart’s lemma (Lemma B.5) to prove this lemma. Let A ⊆ [0, 1]N be the
following set of vectors:

By deﬁnition of the dual class,

A =

A =











gr (x1)
...
gr (xN )


 : r ∈ R







.











g∗
x1 (r)
...

g∗
xN

(r)


 : r ∈ R







.

Since each function g∗
statement therefore follows from Massart’s lemma.

xi is piecewise-constant with at most j pieces, |A| ≤ N (j − 1) + 1. The lemma

Lemma B.5 (Massart [34]). Let A ⊆ [0, 1]N be a ﬁnite set of vectors. Then

(cid:34)

E
σ∼{−1,1}N

sup
a∈A

1
N

(cid:35)

(cid:114)

σiai

≤

2 ln |A|
N

.

N
(cid:88)

i=1

B.2.1 Additional experiments

In our experiments from Section 4.2, we approximated the dual functions f ∗
x with piecewise constant
functions that have a small number of pieces — say, j pieces. We used SRM to ﬁnd the value for
j which leads to the strongest bounds, as in Equation (5). In this section, we compare against
another baseline where we do not use SRM, but simply set j to be the maximum number of pieces
we observe over our training set. Of course, this bound is much tighter than the worst-case bound
by Balcan et al. [7], the baseline in Figures 2(a)-2(c). However, we still observe that for a target
generalization error, the number of samples required according to our bound is up to 4.5 times
smaller than the number of samples required by this baseline.

For each of the three experimental setups from Figures 2(a)-2(c), we draw M = 6000 IPs

x1, . . . , f ∗
x1, . . . , xM from the distribution D. We compute the piecewise-constant dual functions f ∗
xM
and ﬁnd the maximum number of pieces j∗ across these M functions. We summarize our ﬁndings
below:

22

• When using the CATS “arbitrary” generator with score1 = scoreL and score2 = scoreS,

the maximum number of pieces is j∗ = 2214.

• When using the CATS “arbitrary” generator with score1 = scoreP and score2 = scoreA,

the maximum number of pieces is j∗ = 296.

• When using the CATS “regions” generator with score1 = scoreL and score2 = scoreS, the

maximum number of pieces is j∗ = 2224.

Since there is a piecewise-constant function g∗

j∗,xi

with at most j∗ pieces that exactly equals each

xi, a Hoeﬀding bound guarantees that with probability 0.995, Ex∼D

dual function f ∗
≤
0.023. Therefore, from Theorem 4.2, Theorem 4.3, Remark 4.5, and Theorem 4.8, we know that
with probability 0.99 over the draw of N samples S ∼ DN , for all r ∈ [0, 1],

x − g∗

j∗,x

(cid:104)(cid:13)
(cid:13)f ∗
(cid:13)

(cid:105)

(cid:13)
(cid:13)
(cid:13)∞

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
N

(cid:88)

x∈S

fr(x) − E
x∼D

(cid:12)
(cid:12)
(cid:12)
[fr(x)]
(cid:12)
(cid:12)

(cid:32)

(cid:114)

≤ 2

0.023 +

2 ln(N (j∗ − 1) + 1)
N

(cid:33)

+ 3

(cid:114) 1
2N

ln

2
0.005

.

(10)

This is the black dotted line in Figure 5. The red solid line is our generalization bound, as we
described in Section 4.2: the minimum of Equations (2) and (5).

In Figure 5, we see that our bound signiﬁcantly beats this simple baseline up until the point there
are approximately 10,000 training instances, at which point they are approximately equal. These
experiments demonstrate that for a target generalization error, the number of samples required
according to our bound is up to 4.5 times smaller than the number of samples required by this
In Figure 5(a), to get a generalization error of 0.25, 1500 samples are suﬃcient our
baseline.
approach and 6700 samples are suﬃcient using the baseline, so we see a 4.6x improvement.
In
Figure 5(b), to get a generalization error of 0.3, 1400 samples are suﬃcient our approach and 4300
samples are suﬃcient using the baseline, so we see a 3.07x improvement. Finally, in Figure 5(c), to
get a generalization error of 0.25, 1400 samples are suﬃcient our approach and 6100 samples are
suﬃcient using the baseline, so we see a 4.35x improvement.

B.3 Proofs about Rademacher complexity lower bound (Section 4.3)

Theorem B.6 (H¨older’s inequality). Let p0 and p1 be two values in [1, ∞] such that 1
p0
Then for all functions u and w, (cid:107)uw(cid:107)1 ≤ (cid:107)u(cid:107)p0

(cid:107)w(cid:107)p1

.

+ 1
p1

= 1.

Theorem B.7 (Interpolation). Let p and q be two values in (0, ∞] and let θ be a value in (0, 1).
Let pθ be deﬁned such that 1
pθ

= θ
p1
(cid:1) and p ∈ [1, ∞), let F and G be the function classes deﬁned in

Lemma B.8. For any γ ∈ (cid:0)0, 1
4
Theorem 4.9. The dual class G∗ (γ, p)-approximates the dual class F ∗.

. Then for all functions u, (cid:107)f (cid:107)pθ

≤ (cid:107)f (cid:107)θ
p1

(cid:107)f (cid:107)1−θ
p0

+ 1−θ
p0

.

Proof. For ease of notation, let t = γp, a = 1
proof, we will use the following inequality:

2γp , R = (0, t], and X =

(cid:104) 1
2γp , ∞

(cid:17)

. Throughout this

(cid:107)f ∗

x − g∗

x(cid:107)2 =

(cid:115)(cid:90) t

0

(f ∗

x (r) − g∗

x(r))2 dr =

(cid:115)

(cid:90) t

0

(cid:18) 1
2

(cid:19)2

cos(rx)

dr =

(cid:114)

2t +

1
4

sin(2tx)
x

≤

1
4

(cid:114)

First, suppose p = 2. Since t = γ2 and 1

x ≤ 2γ2, Equation (11) implies that (cid:107)f ∗

x − g∗

(cid:112)4γ2 < γ.

1
4

.

2t +

1
x
(11)
x(cid:107)2 ≤

23

(a) Results on the CATS “regions” generator with
score1 = scoreL and score2 = scoreS.

(b) Results on the CATS “arbitrary” generator with
score1 = scoreL and score2 = scoreS.

(c) Results on the CATS “arbitrary” generator with
score1 = scoreP and score2 = scoreA.

Figure 5: Experiments where we compare our generalization bound to a simple baseline described
in Section B.2.1. The red solid line is our generalization bound: the minimum of Equations (2)
and (5) as a function of the number of training examples N . The black dotted line is the simple
baseline from Equation (10).

Next, suppose p < 2. We know that

(cid:107)(f ∗

x − g∗

x)p(cid:107)1 =

(cid:90) t

0

|(f ∗

x (r) − g∗

x(r))p| dr =

(cid:90) t

0

|f ∗

x (r) − g∗

x(r)|p dr = (cid:107)f ∗

x − g∗

x(cid:107)p
p .

(12)

From Equation (12) and H¨older’s inequality (Theorem B.6) with u = (f ∗
function w : r (cid:55)→ 1, p0 = 2

2−p , we have that

p , and p1 = 2

x − g∗

x)p, w the constant

(cid:107)f ∗

x − g∗

x(cid:107)p

x − g∗

p = (cid:107)(f ∗
≤ (cid:107)w(cid:107) 2
2−p

x)p(cid:107)1
(cid:107)(f ∗

x − g∗

x)p(cid:107) 2

p

(cid:18)(cid:90) t

=

dr

(cid:19) 2−p

2

0
2−p
2 (cid:107)(f ∗

= t

x − g∗

x)p(cid:107) 2

p

(cid:107)(f ∗

x − g∗

x)p(cid:107) 2

p

24

(cid:18)(cid:90) t

2−p
2

= t

(f ∗

x (r) − g∗

x(r))2 dr

(cid:19) p

2

2−p

0
x − g∗
2 (cid:107)f ∗

x(cid:107)p
2 .

Therefore,

= t

(cid:107)f ∗

x − g∗

x(cid:107)p ≤ t

x − g∗

x(cid:107)2

1

p − 1

1

p − 1

2

2 (cid:107)f ∗
(cid:114)

2t +

4
(cid:114)

1
p

t
4
(cid:114)
γ
4

2 +

2 +

1
xt
1
xγp

t

≤

=

=

< γ,

1
x

(Equation (11))

(t = γp)

(cid:18)

x ≥

(cid:19)

1
2γp

Finally, suppose p > 2. Let θ = 1 − 2

p , p0 = 2, and p1 = ∞. By Theorem B.7,

(cid:107)f ∗

x − g∗

x(cid:107)p ≤ (cid:107)f ∗

x − g∗

x(cid:107)1−θ
2
2
x − g∗
p
x(cid:107)
2
1
16x
1
16x

+

≤ p

= (cid:107)f ∗
(cid:114) t
+
8
(cid:114) γp
8
(cid:114) γp
4

= p

≤ p

< γ.

(Equation (11))

(t = γp)

(cid:18)

x ≥

(cid:19)

1
2γp

Therefore, for all p ∈ [1, ∞) and all x ∈ X , (cid:107)f ∗
the dual class F ∗.
Lemma B.9. For any γ ∈ (cid:0)0, 1
4
(cid:104) 1
(cid:17)
with domain
2γp , ∞
every N ≥ 1, RN ((cid:96) ◦ F ) = 1
2 .

x − g∗

x(cid:107)p ≤ γ, so the dual class G∗ (γ, p)-approximates

(cid:1) and p ∈ [1, ∞), let F = {fr | r ∈ (0, γp]} be a class of functions
(cid:17)
(cid:104) 1
2 (1 + cos(rx)). For
2γp , ∞

, fr(x) = 1

such that for all r ∈ (0, γp] and x ∈

Proof. This proof is similar to the proof that the VC-dimension of the function class

{x (cid:55)→ sign(sin(rx)) | r ∈ R} ⊆ {−1, 1}R

is inﬁnite (see, for example, Lemma 7.2 in the textbook by Anthony and Bartlett [3]). To prove
this lemma, we will show that for every c ∈ (0, 1/2), RN ((cid:96) ◦ F ) ≥ c (Claim B.10). We also show
that RN ((cid:96) ◦ F ) ≤ 1
Claim B.10. For every c ∈ (0, 1/2), RN ((cid:96) ◦ F ) ≥ c.

2 (Claim B.11). Therefore, the lemma statement follows.

25

(cid:110) 1

2π+1 ,

arccos(2c)
π+arccos(2c)

Proof of Claim B.10. Let N be an arbitrary positive integer. We begin by deﬁning several variables
that we will use throughout this proof. Let R = (0, γp] and let α be any positive power of 1
2
arccos(2c)
smaller than min
π+arccos(2c) is well-deﬁned. Also, since
α ≤ arccos(2c)
π+arccos(2c) , we have that πα
2 . Finally, since the function cos is decreasing
on the interval [0, π/2], we have that 1
2γp and yi = 0 for i ∈ [N ]. Since
α < 1, we have that xi ≥ 1
of the functions in
F .

1−α ≤ arccos(2c) < π
2 cos πα

2γp , so each xi is an element of the domain

1−α ≥ c. Let xi = α−i

. Since 2c ∈ (0, 1),

(cid:17)
(cid:104) 1
2γp , ∞

(cid:111)

We will show that for every assignment of the variables σ1, . . . , σN ∈ {−1, 1}, there exists a

parameter r0 ∈ (0, γp] such that

1
N

sup
r∈(0,γp]

N
(cid:88)

i=1

σifr (xi) ≥

1
N

N
(cid:88)

i=1

σifr0 (xi) =

1
2N

N
(cid:88)

i=1

σi (1 + cos (r0xi)) ≥ c +

1
2

N
(cid:88)

i=1

σi.

This means that when S = {(x1, y1) , . . . , (xN , yN )},

RN ((cid:96) ◦ F ) ≥ (cid:98)RS ((cid:96) ◦ F )

=

=

=

1
N

1
N

1
N

(cid:34)

(cid:34)

(cid:34)

sup
r∈R

sup
r∈R

sup
r∈R

E
σ

E
σ

E
σ

N
(cid:88)

i=1
N
(cid:88)

i=1
N
(cid:88)

i=1

(cid:35)

σi |fr (xi) − yi|

(cid:35)

σi |fr (xi)|

(cid:35)

σifr (xi)

1
2

E
σ

(cid:34) N
(cid:88)

(cid:35)

σi

i=1

≥ c +

= c.

(yi = 0)

(fr (xi) ≥ 0)

To this end, given an assignment of the variables σ1, . . . , σN ∈ {−1, 1}, let (b1, . . . , bN ) ∈ {0, 1}N

be deﬁned such that

and let

bi =

(cid:40)
0
1

if σi = 1
otherwise

r0 = 2πγp





N
(cid:88)



αjbj + αN +1

 .

j=1

Since 0 < r0 < 2πγp (cid:80)∞
inequality 2πγpα

Next, we evaluate fr0(xi) = 1

1−α ≤ γp holds because α ≤ 1

2π+1 , so 2πα

1−α ≤ 1.

j=1 αj = 2πγpα

1−α ≤ γp, r0 is an element of the parameter space (0, γp]. The

1
2

(1 + cos(r0xi)) =

1
2

2 (1 + cos(r0xi)):


2πγp

cos



+

1
2

αjbj + αN +1









α−i
2γp

N
(cid:88)

j=1

26

=

=

=

1
2

1
2

1
2

+

+

+

1
2

1
2

1
2



cos

π





N
(cid:88)

αjbj + αN +1


 α−i





j=1



cos



i−1
(cid:88)

αj−iπbj + πbi +

j=1




cos

π

bi +

N −i
(cid:88)

j=1

αj−iπbj + αN +1−iπ





N
(cid:88)

j=i+1





αjbi+j + αN +1−i



 .

(13)

The ﬁnal equality holds because for every j < i, αj−i is a positive power of 2, so αj−iπbj is a
multiple of 2π. We will use the following fact: since

0 <

N −i
(cid:88)

j=1

αjbi+j + αN +1−i ≤

N −i+1
(cid:88)

j=1

αj <

∞
(cid:88)

j=1

αj =

α
1 − α

,

the argument of cos(·) in Equation (13) lies strictly between πbi and πbi + πα

1−α .

Suppose bi = 0. Since α ≤ 1

creasing on the interval
2 (1 + cos(r0xi)) ≥ 1
1
while, suppose bi = 1. The function cos(·) is monotone increasing on the interval

2 + c. Since bi = 0, it must be that σi = 1, so σifr0(xi) ≥ c + 1

1−α ≤ π. Therefore, cos(·) is monotone de-
1−α ≥ c. Therefore, fr0(xi) =
2 . Mean-
(cid:105)
.

2 , we know that πα
. Moreover, we know that 1

(cid:104)
0, πα
1−α

2 cos πα

(cid:105)

(cid:16)

(cid:17)

2 cos

π + πα
1−α

Moreover, 1
= − 1
Since bi = 1, it must be that σi = −1, so σifr0(xi) ≥ c − 1
i ∈ [N ], we have that

2 cos πα

1−α ≤ −c. Therefore, fr0(xi) = 1

2 = c + σi

2 = c + σi
(cid:104)
π, π + πα
1−α
2 (1 + cos(r0xi)) ≤ 1
2 − c.
2 . Since this is true for any

1
2N

N
(cid:88)

i=1

σi (1 + cos (r0xi)) ≥ c +

1
2

N
(cid:88)

i=1

σi,

as claimed.

We conclude this proof by showing that RN ((cid:96) ◦ F ) ≤ 1
2 .

Claim B.11. For any N ≥ 1, RN ((cid:96) ◦ F ) ≤ 1
2 .

Proof of Claim B.11. Let S = {(x1, y1) , . . . , (xN , yN )} ⊂
points. For any assignment of the variables σ1, . . . , σN ∈ {−1, 1}, since |fr (xi) − yi| ∈ [0, 1],

× [0, 1] be an arbitrary set of

(cid:104) 1
(cid:17)
2γp , ∞

sup
r∈(0,γp]

N
(cid:88)

i=1

σi |fr (xi) − yi| ≤

N
(cid:88)

i=1

1{σi=1}.

Therefore,

RN ((cid:96) ◦ F ) =

sup
(x1,y1),...,(xN ,yN )

1
N

E
σ

(cid:34)

sup
r∈(0,γp]

N
(cid:88)

i=1

(cid:35)

σi |fr (xi) − yi|

≤

1
N

E
σ

(cid:34) N
(cid:88)

i=1

(cid:35)

1{σi=1}

=

1
2

,

as claimed.

Together, Claims B.10 and B.11 imply that for every N ≥ 1, RN ((cid:96) ◦ F ) = 1
2 .

27

B.4 Connection to statistical learnability

Theorem B.12. Let F = {fr | r ∈ R} ⊆ [0, 1]X and G = {gr | r ∈ R} ⊆ [0, 1]X be two sets of
functions. Suppose the dual class G∗ (γ, ∞)-approximates the dual class F ∗. If G is statistically
learnable, then F is γ-statistically learnable.

Proof. We will prove that for all integers N ≥ 1,

VN (F ) = inf
A

sup
D

E
S∼DN

(cid:20)

LD(AS ) − inf
r∈R

LD (fr)

(cid:21)

≤ VN (G) + γ.

Since limN →∞ VN (G) = 0, this implies that limN →∞ VN (F ) ≤ γ.

To this end, ﬁx an arbitrary learning algorithm ¯A : (X × [0, 1])N → [0, 1]X , distribution ¯D
over X × [0, 1], element ¯x ∈ X , and parameter vector ¯r ∈ R. Since the dual class G∗ (γ, ∞)-
approximates the dual class F ∗, we know that |g∗
¯x (¯r)| = |g ¯r (¯x) − f ¯r (¯x)| ≤ γ. Since this
inequality holds for all ¯x ∈ X , we also have that

¯x (¯r) − f ∗

L ¯D (f ¯r) = E

(x,y)∼ ¯D

[|f ¯r(x) − y|]

= E

(x,y)∼ ¯D

[|g ¯r(x) − y − (g ¯r(x) − f ¯r(x))|]

[|g ¯r(x) − y| − |g ¯r(x) − f ¯r(x)|]

≥ E

(x,y)∼ ¯D
≥ L ¯D (g ¯r) − γ
≥ inf
r∈R

L ¯D (gr) − γ.

These inequalities holds for all parameter vectors ¯r ∈ R, which implies that inf r∈R L ¯D (fr) ≥
inf r∈R L ¯D (gr) − γ. Therefore,

(cid:20)

E
S∼ ¯DN

(cid:0) ¯AS

L ¯D

(cid:1) − inf
r∈R

L ¯D (fr)

(cid:21)

(cid:20)

≤ E

S∼ ¯DN

(cid:0) ¯AS
L ¯D
(cid:20)

(cid:1) − inf
r∈R

(cid:21)
L ¯D (gr)

+ γ

(cid:21)

≤ sup
D

E
S∼DN

LD

(cid:0) ¯AS

(cid:1) − inf
r∈R

LD (gr)

+ γ.

Since this inequality holds for every distribution D, we have that

sup
D

E
S∼DN

(cid:20)

LD

(cid:0) ¯AS

(cid:1) − inf
r∈R

(cid:21)
LD (fr)

≤ sup
D

E
S∼DN

(cid:20)
LD

(cid:0) ¯AS

(cid:1) − inf
r∈R

(cid:21)

LD (gr)

+ γ.

Therefore,

VN (F ) = inf
A

sup
D

E
S∼DN

(cid:20)

LD (AS ) − inf
r∈R

LD (fr)

(cid:21)

≤ sup
D

E
S∼DN

(cid:20)

LD

(cid:0) ¯AS

(cid:1) − inf
r∈R

(cid:21)

LD (gr)

+ γ.

Finally, since this inequality holds for every learning algorithm ¯A, we have that
(cid:20)

(cid:21)
LD (gr)

+ γ = VN (G) + γ,

VN (F ) ≤ inf
A

sup
D

E
S∼DN

LD (AS ) − inf
r∈R

as claimed.

However, this positive result, Theorem B.12, fails to hold when Lp-norm deﬁning the approxi-

mation guarantee is not the L∞-norm.

28

Theorem B.13. For any γ ∈ (0, 1/4) and any p ∈ [1, ∞), there exist function classes F , G ⊂ [0, 1]X
with the following properties:

1. The dual class G∗ (γ, p)-approximates the dual F ∗.

2. The class G is statistically learnable.

3. The class F is not γ-statistically learnable.

Proof. The function classes F and G are the same as those in Theorem 4.9. Let t = γp, a = γ−p/2,
R = (0, t], and X = [a, ∞). For any r ∈ R and x ∈ X , let fr(x) = 1
2 (1 + cos(rx)) and F =
{fr | r ∈ R}. For any r ∈ R and x ∈ X , let gr(x) = 1

2 and G = {gr | r ∈ R}.

In Lemma B.8, we prove that the dual class G∗ (γ, p)-approximates the dual class F ∗. From
2 . Therefore, by

Lemma B.9 in Appendix B, we know that for every N ≥ 1, RN ((cid:96) ◦ F ) = 1
Theorem A.4, VN (F ) ≥ 1

4 > γ, so F is not γ-statistically learnable.

Theorem B.13 implies, for example, that even if every function f ∗

x ∈ F ∗ is close to the corre-
x ∈ G∗ on average over the parameter vectors r ∈ R, the function class F still

sponding function g∗
may not be statistically learnable.

29

