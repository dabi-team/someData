2
2
0
2

n
a
J

7
2

]

C
O
.
h
t
a
m

[

4
v
4
3
7
2
0
.
8
0
9
1
:
v
i
X
r
a

Stochastic First-order Methods for Convex and
Nonconvex Functional Constrained Optimization ∗

Digvijay Boob †

Qi Deng ‡

Guanghui Lan §

Abstract

Functional constrained optimization is becoming more and more important in machine
learning and operations research. Such problems have potential applications in risk-averse
machine learning, semisupervised learning and robust optimization among others. In this
paper, we ﬁrst present a novel Constraint Extrapolation (ConEx) method for solving convex
functional constrained problems, which utilizes linear approximations of the constraint func-
tions to deﬁne the extrapolation (or acceleration) step. We show that this method is a uniﬁed
algorithm that achieves the best-known rate of convergence for solving diﬀerent functional
constrained convex composite problems, including convex or strongly convex, and smooth or
nonsmooth problems with stochastic objective and/or stochastic constraints. Many of these
rates of convergence were in fact obtained for the ﬁrst time in the literature. In addition,
ConEx is a single-loop algorithm that does not involve any penalty subproblems. Contrary
to existing primal-dual methods, it does not require the projection of Lagrangian multipli-
ers into a (possibly unknown) bounded set. Second, for nonconvex functional constrained
problems, we introduce a new proximal point method which transforms the initial nonconvex
problem into a sequence of convex problems by adding quadratic terms to both the objective
and constraints. Under certain MFCQ-type assumption, we establish the convergence and
rate of convergence of this method to KKT points when the convex subproblems are solved
exactly or inexactly. For large-scale and stochastic problems, we present a more practical
proximal point method in which the approximate solutions of the subproblems are computed
by the aforementioned ConEx method. Under a strong feasibility assumption, we establish
the total iteration complexity of ConEx required by this inexact proximal point method
for a variety of problem settings, including nonconvex smooth or nonsmooth problems with
stochastic objective and/or stochastic constraints. To the best of our knowledge, most of
these convergence and complexity results of the proximal point method for nonconvex prob-
lems also seem to be new in the literature.

Keywords: functional constrained optimization, stochastic algorithms, convex and noncon-
vex optimization, acceleration.

AMS 2000 subject classiﬁcation: 90C25, 90C06, 90C22, 49M37

1

Introduction

In this paper, we study the following composite optimization problem with functional constraints:

min
x
X
P
s.t.

ψ0
ψi

x
p
q
x
q
p

:

:

“

“

f0
fi

x
p
x
p

q `

q `

χ0
χi

x
p
q
x
p

0,

q ď
R and fi : X

i

1, . . . , m.

“

(1.1)

Ď

Rn is a convex compact set, f0 : X
1, . . . , m are continuous
Here, X
“
0, 1, . . . , m are convex and
functions which are not necessarily convex, and χi : X
continuous functions. Problem (1.1) covers diﬀerent convex and nonconvex settings depending
on the assumptions on fi and χi, i

0, . . . , m.

R, i

Ñ
R, i

Ñ

Ñ

“

In the convex setting, we assume that fi, i

0, . . . , m, are convex or strongly convex functions,

“
which can be either smooth, nonsmooth or the sum of smooth and nonsmooth components.

“

We also assume that χi, i

“
Rn and non-negative weight vector w

0, . . . , m, are “simple” functions in the sense that, for any given
Rm, a certain proximal operator associated

vector v

P

P

∗Boob and Lan was partially supported by the NSF grant CCF 1909298. Deng was partially supported by the

NSFC grant 11831002.

†digvijaybb40@gatech.edu, Industrial and Systems Engineering, Georgia Institute of Technology.
‡qideng@sufe.edu.cn, School of Information Management and Engineering, Shanghai University of Finance and

Economics.

§george.lan@isye.gatech.edu, Industrial and Systems Engineering, Georgia Institute of Technology.

1

 
 
 
 
 
 
with the function χ0
v, x
can be computed eﬃciently. For such problems,
y
Lipschitz smoothness properties of χi’s is of no consequence due to the simplicity of this proximal
operator.

1wiχi

q ` x

x
p

x
p

q `

ř

m
i
“

For the nonconvex case, we assume that fi, i

0, . . . , m, are smooth functions, which are
not necessarily convex, but satisfying a certain lower curvature condition (c.f. (1.3)). However,
we do not put the simplicity assumption about the proximal operator associated with convex
0, . . . , m, in order to cover a broad class of nonconvex problems, including those
functions χi, i
with non-diﬀerentiable objective functions or constraints.

“

“

Constrained optimization problems of the above form are prevalent in data science. One such
R models the loss for
example arises from risk averse machine learning. Let ℓ
q
a random data-point ξ
Ξ. Our goal is to minimize a certain risk measure [42, 43], e.g., the
so-called conditional value at risk that penalizes only the positive deviation of the loss function,
subject to the constraint that the expected loss is less than a threshold value. Therefore, one can
formulate this problem as

: Rn

Ñ

, ξ

ˆ

Ξ

p¨

P

min
x
X
P
s.t.

ℓ

CVaR
x, ω
r
p
x, ω
p

ℓ

qs
c,

(1.2)

E
r
where CVaR denotes conditional value at risk and c is the tolerance on the average loss that one
can consider as acceptable. In many practical situations, the loss function ℓ
is nonconvex
w.r.t. x. Other examples of problem (1.1) can also be found in semi-supervised learning, where
one would like to minimize the loss function deﬁned over the labeled samples, subject to certain
proximity type constraints for the unlabeled samples.

x, ω
p

qs ď

q

There exists a variety of literature on solving convex functional constrained optimization
problems (1.1). One research line focuses on primal methods, e.g., cooperative subgradient meth-
ods [39, 27] and level-set methods [28, 35, 30, 4, 29], which do not involve the Lagrange multipliers.
One possible limitation of these methods is the diﬃculty to directly achieve accelerated rate of
convergence when the objective or constraint functions are smooth. Constrained convex opti-
mization problems can also be solved by reformulating them as saddle point problems which will
then be solved by using primal-dual type algorithms (see [34, 19]). The main hurdle for existing
primal-dual methods exists in that they require the projection of dual multipliers onto a ball
whose diameter is usually unknown. Other approaches for constrained convex problems include
the classical exact penalty, quadratic penalty and augmented Lagrangian methods [6, 23, 24, 46].
These approaches however require the solutions of penalty subproblems and hence are more com-
plicated than primal and primal-dual methods. Recently, research eﬀort has also been directed to
stochastic optimization problems with functional constraints [27, 4]. In spite of many interesting
ﬁndings, existing methods for solving these problems are still limited: a) many primal methods
solve only stochastic problems with deterministic constraints [27], and the convergence for accel-
erated primal-dual methods [34, 19] has not been studied for stochastic functional constrained
problems; and b) a few algorithms for solving problems with expectation constraints require ei-
ther a constraint evaluation step [27], or stochastic lower bounds on the optimal value [4], thus
relying on a light-tail assumption for the stochastic noise and conservative sampling estimates
based on Bernstein inequality. Some other algorithms require even more restrictive assumptions
that the noise associated with stochastic constraints has to be bounded [47].

The past few years has also seen a resurgence of interest in the design of eﬃcient algorithms for
nonconvex stochastic optimization, especially for stochastic and ﬁnite-sum problems due to their
importance in machine learning. Most of these studies need to assume that the constraints are
convex, and focus on the analysis of iteration complexity, i.e., the number of iterations required
to ﬁnd an approximate stationary point, as well as possible ways to accelerate convergence to
such approximate solutions. If the nonconvex functional constraints do not appear, one approach
for solving (1.1) is to directly generalize stochastic gradient descent type methods (see [16, 17,
41, 1, 14, 48, 45, 36, 38, 21]) for solving problems with nonconvex objective functions. An
alternative approach is to indirectly utilize convex optimization methods within the framework
of proximal-point methods which transfer nonconvex optimization problems into a series of convex
ones (see [18, 7, 15, 11, 20, 25, 40, 37]). While direct methods are simpler and hence easier to
implement, indirect methods may provide stronger theoretical performance guarantees under
certain circumstances, e.g., when the problem has a large conditional number, many components
and/or multiple blocks [25]. However, if nonconvex functional constraints ψi
0 do appear
in (1.1), the study on its solution methods is scarce. While there is a large body of work on
the asymptotic analysis and the optimality conditions of penalty-based approaches for general

x
p

q ď

2

constrained nonlinear programming (for example, see [6, 33, 3, 2, 12]), only a few works discussed
the complexity of these methods for solving problems with nonconvex functional constraints
[8, 44, 13]. However, these techniques are not applicable to our setting because they cannot
guarantee the feasibility of the generated solutions, but certain local non-increasing properties
for the constraint functions. On the other hand, the feasibility of the nonconvex functional
constraints appear to be important in our problems of interest.

In this paper, we attempt to address some of the aforementioned signiﬁcant issues associated
with both convex and nonconvex functional constrained optimization. Our contributions mainly
exist in the following several aspects.

First, for solving convex functional constrained problems, we present a novel primal-dual type
method, referred to as the Constraint Extrapolation (ConEx) method. One distinctive feature
of this method from existing primal-dual methods is that it utilizes linear approximations of the
constraint functions to deﬁne the extrapolation (or acceleration/momentum) step. As a con-
sequence, contrary to the well-known Nemirovski’s mirror-prox method [34] and an interesting
primal-dual method recently developed by Hamedani and Aybat [19], ConEx does not require
the projection of Lagrangian multipliers onto a (possibly unknown) bounded set. In addition,
ConEx is a single-loop algorithm that does not involve any penalty subproblems. Due to the
built-in acceleration step, this method can explore problem structures and hence achieve better
rate of convergence than primal methods. In fact, we show that this method is a uniﬁed algo-
rithm that achieves the best-known rate of convergence for solving diﬀerent convex functional
constrained problems, including convex or strongly convex, and smooth or non-smooth problems
with stochastic objective and/or stochastic constraints.

Strongly convex (1.1)
Smooth* Nonsmooth
Cases
?ε
O
1
Deterministic
{
p
ε
O
1
Semi-stochastic
q
{
p
ε2
Fully-stochastic O
1
q
{
p

ε
{
q
ε
q
{
ε2
q
{

1
p
1
p
1
p

O
O
O

q

Convex (1.1)
Smooth* Nonsmooth
O
O
O

ε2
ε2
ε2

O
O
O

1
p
1
p
1
p

ε
q
{
ε2
q
{
ε2
q
{

1
p
1
p
1
p

{
{
{

q
q
q

Table 1: Diﬀerent convergence rates of the ConEx method for strongly convex/convex, and
smooth/nonsmooth objective and/or constraints. Deterministic means both objective and con-
straints are deterministic, semi-stochastic means objective is stochastic but constraints are de-
terministic, fully-stochastic means both objective and constraints are stochastic.
(*) Results for the smooth case hold if B
at the rate of nonsmooth problems.

1. Otherwise, the ConEx method converges

ky˚k2 `

ě

ε
p

Table 1 provides a brief summary for the iteration complexity of the ConEx method for
solving diﬀerent functional constrained problems. For the strongly convex case, ConEx can
obtain convergence to an ε-approximate solution (i.e., optimality gap and infeasibility are O
)
q
as well as convergence of the last iterate to the optimal solution. The complexity bounds provided
in Table 1 for the strongly convex case hold for both types of convergence criterions. For semi-
and fully-stochastic case, we use the notion of expected convergence instead of exact convergence
used in the deterministic case. It should be noted that in Table 1, we ignore the impact of various
Lipschitz constants and/or stochastic noises for the sake of simplicity. In fact, the ConEx method
achieves quite a few new complexity results by reducing the impact of these Lipschitz constants.
Moreover, to the best of our knowledge, it attains for the ﬁrst time the optimal iteration and
sampling complexity for solving general stochastic constrained problems without requiring the
boundedness or light-tail assumptions on the stochastic subgradients (see Theorems 2.1 and 2.3
and discussions afterwards). Even though ConEx is a primal-dual type method, we can show its
convergence irrespective of the knowledge of the optimal Lagrange multiplier y˚, as it does not
require the projection of multipliers onto the ball. In particular, convergence rates of the ConEx
method for nonsmooth cases (either convex or strongly convex) in Table 1 holds irrespective of
the knowledge of the optimal Lagrange multipliers. For smooth cases, if certain parameter B
is not big enough, i.e., B
1, then it converges at the rates for nonsmooth problems
of the respective case. As one can see from Table 1, such a change would cause a suboptimal
convergence rate in terms of ε only for the deterministic case, but complexity will be the same for
both semi- and fully-stochastic cases. It is worth mentioning that faster convergence rates for the
smooth deterministic case can still be attained by incorporating certain line search procedures.
To the best of our knowledge, this is the ﬁrst time in the literature that a simple single-loop

ky˚k2 `

ă

3

algorithm was developed for solving all diﬀerent types of convex functional constrained problems
in an optimal manner.

“

Second, we extend the ConEx method for the nonconvex setting and present a new framework
of proximal point method for solving the nonconvex functional constrained optimization problems,
which otherwise seem to be diﬃcult to solve by using direct approaches. The key component of
our method is to exploit the structure of the nonconvex objective and constraints ψi, i
0, . . . , m,
thereby turning the original problem into a sequence of functional constrained subproblems with
a strongly convex objective and strongly convex constraints. We show that if the proximal point
method has a strictly feasible initial solution and its subproblem is exactly solved, then the whole
generated sequence remains strictly feasible. Hence, Slater’s condition guarantees the existence
of Lagrange multipliers and strong duality for each subproblem. Moreover, we show that the
need of an exact optimal subproblem solution can be relaxed by a termination criterion based on
the distance to the optimal solution, leading to a more general inexact proximal point method
that still preserves the appealing property of strict feasibility. Under the Mangasarian-Fromovitz
constraint qualiﬁcation (MFCQ), we show that the inexact proximal point method converges
asymptotically to the KKT points, and provide the ﬁrst iteration complexity of such proximal
point method. More speciﬁc, we show that this method requires O
iterations to obtain an
appropriately deﬁned

-KKT point (see Theorem 3.10 and discussions afterwards).
q

For large-scale and stochastic optimization, we propose an inexact proximal point method
for which the subproblems are approximately solved by ﬁrst-order methods such as ConEx.
However, due to the optimization challenge in this setting, it is in general diﬃcult to obtain
highly accurate solutions such that the whole sequence remains strictly feasible. To overcome
this diﬃculty, we propose a new and veriﬁable strong feasibility assumption which alleviates the
need of generating strict feasible solutions. We develop the inexact proximal point method using
a termination criterion in terms of the functional optimality gap and the constraint violation,
showing that this method requires O
-KKT point solutions,
q
where ∆ depends on the inexactness errors summed over the iterations. When the proximal
point subproblems are solved by ConEx, we present the total iteration count of ConEx to achieve
the approximate solutions under diﬀerent smooth and nonsmooth settings (see Theorem 3.18,
Corollary 3.20 and discussions afterwards).

iterations to obtain some

ε, ε2
p

ε, ε
p

∆
{
p

1
p

ε

ε

{

q

q

Close to the completion of our paper, we notice that Ma et. al. [31] also worked independently
on the analysis of the proximal-point methods for nonconvex functional constrained problems.
In fact, the initial version of
[31] was released almost at the same time as ours. In spite of some
overlap, there exist a few essential diﬀerences between our work and [31]. First, we establish the
convergence/complexity of the proximal point method under a variety of constraint qualiﬁcation
conditions, including MFCQ, a stronger notion of MFCQ (Assumption 3.2), and strong feasi-
bility. Hence, our work covers a broader class of nonconvex problems, while [31] only consider
problems that satisfy a uniform Slater’s condition. Strong feasibility condition is stronger than
the uniform Slater’s condition but it is easier to verify. Second, [31] uses a diﬀerent deﬁnition of
subdiﬀerential than ours and the deﬁnition of the KKT conditions in [31] comes from convex op-
timization problems. While it is unclear under what constraint qualiﬁcation this KKT condition
is necessary for local optimality, it is possible to put their problem into our composite framework
in (1.1) and compute the subdiﬀerential that provably yields our KKT condition under the afore-
mentioned MFCQ. Third, for solving the convex subproblems we provide a uniﬁed algorithm,
i.e., ConEx, that can achieve the best-known rate of convergence for solving diﬀerent problem
classes, including deterministic, semi- and fully-stochastic, smooth and nonsmooth problems.
On the other hand, diﬀerent methods were suggested for solving diﬀerent types of problems in
[31]. In particular, a variant of the switching subgradient method, which was ﬁrstly presented
by Polyak in [39] for the general convex case, and later extended by [27] for the stochastic and
strongly convex cases, was suggested for solving deterministic problems. For the stochastic case
they directly apply the algorithm in [47] and hence require stochastic gradients to be bounded.
These subgradient methods do not necessarily yield the best possible rate of convergence if the
objective/constraint functions are smooth or contain certain smooth components.

Outline This paper is organized as follows. Section 1.1 describes notation and terminologies.
Section 2 exclusively deals with the ConEx method for solving problem (1.1) in the convex
setting. Section 2.1 states the main convergence results of the ConEx method and Section 2.2
shows the details of the convergence analysis. Section 3 presents exact and inexact proximal point
methods for solving problem (1.1) in the nonconvex setting. Section 3.1 and 3.2 establishes their

4

convergence behavior and iteration complexity under the MFCQ type assumptions. Section 3.3
investigates the inexact proximal point method under the strong feasibility assumption, and
shows an overall iteration complexity result when the subproblems are solved by the ConEx
method.

1.1 Notation and terminologies

:

:

:

:

:

u

qs

qs

k
¨

“ r

“ r

q ď

, ψ

x
p

x
p

T , f

x
q
p

x
q
p

1, . . . , m

T and χ

, . . . , ψm
x
q
p

denotes its dual norm deﬁned as kzk

Throughout the paper, we use the following notations. Let
χ1
, . . . , fm
x
f1
x
ψ1
q
r
p
qs
p
straints in (1.1) be expressed as ψ
x
p
the vector is left unspeciﬁed whenever it is clear from the context. k
and k
˚
we obtain the aT b
kakkbk
˚
r
is denoted as
q
p
origin. Non-negative orthant of this ball is denoted as B2
the normal cone at x
X as NX
interior as rint X. For a scalar valued function f and a scalar t, the notation
t
the set
u
refer to the distance between two sets A, B

x
m
“
q
p
s
r
“ t
T and the con-
, . . . , χm
x
q
p
0. Here bold 0 denotes the vector of elements 0. Size of
k denotes a general norm
¨
. From this deﬁnition,
1
ď
k2 and standard inner product
¨
be the Euclidean ball of radius r centered at
u
. For a convex set X, we denote
r
q
`p
, interior as int X and relative
x
and its dual cone as N ˚X p
q
f
stands for
” operation on sets denotes the Minkowski sum of the sets. We

˚
. Euclidean norm is denoted as k
r
:

x : kxk2 ď
x
q
p

ď
. Let B2

zT x : kxk

. The “

sup
t

max
t
application of the operator
explicitly speciﬁed a diﬀerent notation for certain special vectors.

for any x

Bka
´
x
as element-wise
s`
r
i
. The i-th element of vector x is denoted as xp
q unless otherwise

:
inf a
q
“
P
Rk, we deﬁne

R. For any vector x

Rn as d
A, B
p

x : f

,
x¨

x
p

“ t

x
r

r¨s`

x, 0

q ď

bk.

s`

A,b

Ă

ď

“

“

`

¨y

P

P

P

t

t

u

u

u

t

P

:

A function r
0

some λ

ě

is λ-Lipschitz smooth if the gradient ∇r

is a λ-Lipschitz function, i.e. for

x
q
p

p¨q

k∇r

x
p

q ´

∇r

y
p

k
q

˚ ď

λkx

´

yk,

x, y

@

P

dom r.

An equivalent form is:
λ
yk2
2 kx

λ
2 kx

yk2,

x, y

dom r.

r

x
p

r

y
p

∇r

y
p

, x
q

y

Ñ

´

ď

´

q ´

q ´ x

´
Note that in the above relation, the upper and lower curvatures need not be same. A reﬁned
version of the above property diﬀerentiates between negative and positive curvatures.
ν
2 kx

dom r.
y
(1.3)
P
Here, we say that r satisﬁes (1.3) with parameter ν with respect to k
k. In many cases, it is
¨
possible that a convex function r is a combination of Lipschitz smooth and nonsmooth functions.
R be continuously diﬀerentiable with Lω-Lipschitz continuous gradient and

Let ω : X

,
x
q
p

, x
q

q ` x

yk2

y
p

y
p

x, y

y ď

y ´

∇r

´

ď

´

´

@

@

P

r

r

:

ω

W

1-strongly convex with respect to k

k. We deﬁne the prox-function associated with ω
¨
,
q ´

, y
x
y, x
x, y
´
q
p
q
p
x
Based on the smoothness and strong convexity of ω
, we have the following relation
p
q
y, x
x, y
LωW
p
p
We deﬁne the diameter of the compact set X by
DX – max
X
P

x, y
p

Lω
2 }

q ´ x

x
y

x
p

y
p

∇ω

x, y

2W

q ď

,
q

X.

X.

W

ď

´

“

x,y

ω

x

@

@

P

P

y

}

2

p¨q

as

(1.4)

(1.5)

(1.6)

B

x

a

,
p¨

X. For a point x

It immediately follows from the strong convexity of ω
For any convex function h, we denote the subdiﬀerential as
relative interior of X,
x
of X
q
p
´
there exists xi
1, 2, . . . , with x
deﬁnition, it is well-known that, if a convex function h : X
constant M, with respect to a norm k
|

X.
h as follows: at a point x in the
h is comprised of all subgradients h1 of h at x which are in the linear span
consists of all vectors h1, if any, such that
h1i. With this
lim
lim
i
i
R is Lipschitz continuous, with
Ñ8
Ñ8

rint X, the set
xi
p

P
rint X and h1i P B

DX for any x, y

X and

P

Ñ
is nonempty for any x
,
lin
q

k, then the set
B
¨
Mkdk,
h1, d
@
y
x

x
h
q
p
d
P

xi, h1

X
p

, i
q

x
p

q ñ

} ď

P B

X

X

h1

ď

´

“

“

“

´

¨q

h

h

h

P

P

y

B

B

z

}

|

.
q
that

which also implies

q ñ
is the dual norm. See [5] for more details. We say that a function r

˚ ď

P B

h1

h

x
p

kh1k

M,

is β-strongly

p¨q

(1.7)

where k
convex with respect to W

k
¨

˚

,
p¨
r
q ě

r

x
p

if

r1

y
p

, x
q

´

y

y `

βW

x, y
p

,
q

q ` x

x, y

@

P

X.

¨q
y
p

5

2 Constraint Extrapolation for Convex Functional Con-

strained Optimization

Let

In this section, we present a novel constraint extrapolation (ConEx) method for solving prob-
lem (1.1) in the convex setting. To motivate our proposed method, consider the equivalent
Lagrangian saddle point problem:
max
0
y
ě

x, y
L
p
be a saddle point solution of (2.1), then it satisﬁes
ř
x, y˚
(2.2)
L
p
0. Moreover, we have that x˚ is the optimal solution of (1.1). Throughout

for all x
this section, we assume the existence of y˚ satisfying (2.2). Denote the optimal value ψ˚0 :
“
ψ0
. Then, the following deﬁnition describes a widely used optimality measure for the convex
q
problem (1.1).

x˚, y˚
L
p

x
q
p
(

x˚, y
L
p

x˚, y˚
p

i
qψi
1yp

min
X
x
P

x˚
p

(2.1)

m
i
“

X, y

x
p

q ď

q ď

q `

,
q

ψ0

“

ě

P

q

q

:

.

Deﬁnition 2.1. A point

A stochastic

δo, δc
p

x

P
ψ0

δo, δc
X is called a
-optimal solution of problem (1.1) if
q
p
ψ˚0 ď
x
δc.
δ0
and
p
qs`
-approximately optimal solution satisﬁes
q
ψ˚0 s ď
x
p

and E
r

x
s
q ´
p

k2s ď

k2 ď

s
ψ0

E
r

ψ
s
r

ψ
r

x
p

q ´

qs`

δc.

δ0

k

k

As mentioned earlier, for the convex composite case, we assume that χi, i
s
Rn and nonnegative w
functions in the sense that, for any vector v
compute the following prox operator

s

P

0, . . . , m, are “simple”
Rm, we can eﬃciently

“
P

prox

w, v,
p

x, η

:

“

q

argmin
X

x

χ0

x
p

q `

m
i
“

1wiχi

x
p

q ` x

v, x

y `

ηW

x

x,
p

.

(2.3)

The prox operator above uses Bregman divergence instead of Euclidean norm used in standard
prox operator.

ř

r

r

P

q
(

2.1 The ConEx method

ConEx is a single-loop primal-dual type method for functional constrained optimization.
It
evolves from the primal-dual methods for solving bilinear saddle point point problems (e.g.,
[9, 10, 26, 22, 21]). Recently Hamedani and Aybat [19] show that these methods can also han-
dle more general functional coupling term. However, as discussed earlier, existing primal-dual
methods [34, 19] for general saddle point problems, when applied to functional constrained prob-
lems, require the projection of dual multipliers onto a possibly unknown bounded set in order
to ensure the boundedness of the operators, as well as the proper selection of stepsizes. One
distinctive feature of ConEx is to use value of linearized constraint functions in place of exact
function values when deﬁning the extrapolation/momentum step. With this modiﬁcation, we
show that the ConEx method still converges even though the feasible set of y in problem (2.1)
is unbounded. In addition, we show that ConEx method is a uniﬁed algorithm for functional
constrained optimization in the following sense. First, we establish an explicit rate of convergence
of the ConEx method for solving functional constrained stochastic optimization problems where
either the objective and/or constraints are given in the form of expectation. Second, we con-
sider the composite constrained optimization problem in which the objective function f0 and/or
constraints fi, i
1, . . . , m can be nonsmooth. Third, we consider the two cases of convex or
strongly convex objective, f0. For the strongly convex objective, we also establish the rate of
convergence to the optimal solution x˚.

“

P

x2

0:
x2
p

Before proceeding to the algorithm, we introduce the problem setup in more details. First,
we assume that f0 satisﬁes the following Lipschitz smoothness and nonsmoothness condition for
some constants L0, H0

ě
f0
x1
f0
f 10p
q ´ x
p
q ´
x2
X and for all f 10p
q P B

x2
(2.4)
´
for all x1, x2
. For constraints, we make a similar assumption as
q
in (2.4). Moreover, we make an additional assumption that the constraint functions are Lipschitz
continuous. In particular, we have
fi
x1
fi
f 1ip
q ´ x
p
q ´
X and for all f 1ip
x2
q P B
x2
x1
p
q ´
p
x2
x1
p
q ´
p

, x1
x2
´
q
, i
x2
fi
q
p
Mf,ikx1
´
Mχ,ikx1
´

1, . . . , m, and
x1, x2
x1, x2

1, . . . , m,
1, . . . , m.

y ď
“
x2k,
x2k,

, x1
q
x2
f0
p

for all x1, x2

X, i
X, i

L0
2 kx1

Li
2 kx1

q ď
q ď

H0kx1

Hikx1

fi
χi

x2k2

x2k2

x2
p

fi
χi

(2.6)

(2.5)

x2k,

“
“

x2k

y ď

@
@

P
P

x2

´

`

´

´

´

`

P

6

 
 
s

s

m

P r

˚ ď

If fi, i

, are nonsmooth functions.

Note that the Lipschitz-continuity assumption in (2.6) is common in the literature when fi, i
P
m
, are Lipschitz smooth then their gradients are
r
bounded due to the compactness of X. Hence (2.6) is not a strong assumption for the given
setting. Also note that due to deﬁnition of subgradient for convex function deﬁned in Section 1.1,
x2k.
kx1
x1
we have kf 1ip¨q
k
p
Using this relation, (2.5) and (2.6), we have the following four relations:
x1
p
x1
p
T
x2
q
p
T
x2
p
q
f 11p¨q

Mf,i which implies |f 1ip
f

m and constants Mf , Mχ, Hf and Lf are

Mf kx1
Mχkx1
Lf
2 kx1
Mf kx1

x2k,
x2k,
x2k2
x2k,

X. Here f 1

Mf,ikx1

Hf kx1

kf 1ip

kf
kχ

x1
p

x2
p

(2.7)

x2k,

x2k

T
q

k
q

q ´

q ´

q ´

“ r

kf 1

|
q

x2

x2

x2

kf

f 1

´

´

´

´

´

´

ď

´

´

´

ď

`

χ

P

f

ˆ

˚

:

for all x1, x2
deﬁned as

x2
k2 ď
p
q
x2
k2 ď
q ´
p
q
x1
x2
k2 ď
p
q
x1
x2
k2 ď
p
´
q
Rn
, . . . , f 1mp¨qs P
1M 2
2, Mχ :
1
{
f,iq
2,
1
1H 2
{
i q

Lf :

p¨q
Mf :

Hf :

“ p

m
i
“
m
i
“

ř

ř

“ p

α1, . . . , αm

“ p
“ p
T as the vector of moduli of strong convexity for χi, i
q

We denote α
, and
α0 as the modulus of strong convexity for χ0. We say that convex problem (1.1) is a smooth
composite if (2.5) is satisﬁed with Hi
0.
Otherwise, (1.1) is a nonsmooth problem. To be succinct, problem (1.1) is composite smooth if
Hf

1, . . . , m and (2.4) is satisﬁed with H0

0, otherwise it is a nonsmooth problem.

“
We assume that we can access the ﬁrst-order information of functions f0, fi and zeroth-order
X, SO outputs

information of function fi using a stochastic oracle (SO). In particular, given x
G0

0 for all i

H0

P r

ř

m

“

“

“

“

P

s

x, ξ
p

, Gi
q

x, ξ
p

, and F
q

x, ξ
p

q

“ p

m
i
“
m
i
“

1M 2
2,
1
{
χ,iq
2.
1
1L2
{
i q

ř

(2.8)

qs “
qs “

x, ξ
p
x, ξ
p

such that
E
G0
r
E
Gi
r
E
F
x, ξ
p
r
k2
f 10p
x
q
˚
k2
x
f 1ip
‰
ď
q
˚
k2
x
f
‰
2s ď
q
p

qs “

q ´

q ´

q ´

ď

E

kG0
x, ξ
p
E
kGi
“
E
“
r

x, ξ
p
kF

x, ξ
p

f 10p
x
,
q
,
x
f 1ip
q
,
x
f
p
q
σ2
0,
σ2
i ,
σ2
f ,

1, . . . , m,

i

“

1, . . . , m,

i

“

(2.9)

Fi

such that E
2
qq
0, . . . , m, as stochastic subgradients of functions fi, i

where ξ is a random variable which models the source of uncertainty and is independent of the
search point x. Note that the last relation of (2.9) is satisﬁed if we have individual stochastic
oracles Fi
x, ξ
f,i.
p
0, . . . , m at point x,
We call Gi, i
xt, ξt
respectively. We use stochastic subgradients Gi
0, . . . , m, in the t-th iteration of
p
the ConEx method where ξt is a realization of random variable ξ which is independent of the
T a vector of standard deviation of stochastic
search point xt. We denote by σ :
“ r
subgradients of individual constraints.
1

f,i. In particular, we can set σ2
σ2

σ1, . . . , σm

x, ξ
p

, i
q

f “

1σ2

q
“

m
i
“

x
p

s ď

q ´

ř

fi

“

“

rp

s

a linear approximation of f

at point xt with

We denote ℓt
´
f

xt
p

q

1

xt
f 11p
q “ r
. We can do this, since for all t, we approximate f
xt
q
p

ℓt
f
xt
,
:
´
1
f
p
q
“
q
q `
xt
, . . . , f 1mp
as deﬁned earlier. For ease of notation, we denote
q
with linear function
1. We use a stochastic version of ℓf in our algorithm, which is denoted

xt
p
1
´

´
qs

xt
p

xt
p

T
q

xt

f 1

´

´

´

´

q

1

1

p¨q
xt
p

1

´

ξt

1,

1,

ℓF
:

xt
q
p
xt
G1
where G
1
p
“ r
´
independent (of ξt) realization of random variable ξ. In other words, Gi
xt
are conditionally independent estimates of f 1ip
ﬁxed. As we show later, independent samples of ξ are required to show that ℓF
estimator of ℓf

xt
1,
m. Here, we used
ξt as an
ξt
´
xt, ξt
xt,
and Gi
s
q
p
p
1, . . . , m under the condition that xt is
s
is an unbiased

ξt
1
q `
, . . . , Gm
q
s

xt
G
p
xt
p

T
xt
p
q
´
Rn
1
qs P

xt
F
p
ξt
1,

xt
s
p

for i

´
ˆ

s
“

,
q

´
1,

ξt

ξt

s

s

´

´

´

´

´

´

q

q

q

q

1

1

We are now ready to formally describe the constraint extrapolation method (see Algorithm 1).
xt
As mentioned earlier, the ℓF
.
q
p
xt
Moreover, the term χ
is an approximation to χ
ℓf
. Essentially,
p
q
q `
xt
ψ
Line 3 represents a stochastic approximation for the term ψ
which is
p
an extrapolation of the constraints, hence justifying the name of the algorithm. Line 4 is the
standard prox operator which has a closed-form solution: yt
. Line 5 also uses
a prox operator deﬁned in (2.3). The ﬁnal output of the algorithm in Line 7 is the weighted

term in Line 3 of Algorithm 1 is an unbiased estimator of ℓf
q
xt
p

xt
p
xt
p

q “
xt
p

xt
p
ψ
p

q `
q `

f
θt

xt
p

xt
p

q ´

1
τt

yt

st

`

“

qq

ψ

`

`

´

q

1

1

xt
p

.
q

“

‰

1

q

xt
p

xt
1
p
´
as ℓf

where f 1
ℓt
1
´
f
approximation taken at xt
as ℓF . In particular, we have
:
“
xt
p

´

7

Algorithm 1 Constraint Extrapolation (ConEx) Method

1

Input:
1: x
´
2: for t
st
3:
yt
xt
5:
6: end for

x0, y0
,
γt, τt, ηt, θt
0, T.
t
p
t
q
u
ě
x0, ℓF
x0
F
ξ0
x0,
q Ð
Ð
p
p
0, . . . , T
1 do
´
“
xt
χ
θt
1
q `
`
Ð p
p
qr
argminy
0
1
x´
Ð
`
ě
1, G0
yt
prox

ℓF
xt
s
p
st, y
y `
xt, ξt
p

Ð

4:

`

`

q

1

7: return

xT

`

T
1
0 γt
´
t
“

“

`ř

˘

s

T

´

1

´

t
0
“
ř

and ℓF

x
p

´

1

q Ð

ℓF

x0
p

.
q

θt
qs ´
τt
2 ky

χ

r
´
i
Pr

xt
1
p
´
ytk2
2.
Gi

m

s

q `
1

ř
γtxt

1.

`

ℓF

xt
p

´

1

qs

.

q `

xt, ξt
p

i
yp
qt
q
`

1, xt, ηt

.

˘

“

average of all primal iterates generated. If we choose standard deviations σf
0 for
1, . . . , m then we recover the deterministic gradients and function evaluation. Henceforth,
i
we assume general non-negative values for all such standard deviations and provide a combined
analysis for these settings. Later, we substitute appropriate values of standard deviations to
ﬁnish the analysis for the following three diﬀerent cases.

σ0

σi

“

“

“

a) Deterministic setting where both the objective and constraints are deterministic. Here

σ0

σi

“

“

σf

“

0 for all i

m

.

s

P r

b) Semi-stochastic setting where the constraints are deterministic but the objective is stochas-
. However, σ0

0 can take arbitrary values.

tic. Here, σf

0 for all i

σi

m

“

“

P r

s

ě

c) Fully-stochastic setting where both function and gradient evaluations are stochastic. Here,

all σf , σ0, σi

ě

0 can take arbitrary values.

Below, we specify a stepsize policy and state the convergence properties of Algorithm 1 for
solving problem (1.1) in the strongly convex setting where χ0 is α0-strongly convex. Note that
in the stochastic case, stepsize τt depends on the total number of iterations T which needs to be
ﬁxed beforehand. Similar policies are used in the stochastic approximation literature [21]. The
proof of this theorem is involved and will be deferred to Section 2.2.

Theorem 2.1. Suppose (2.4), (2.5), (2.6) and (2.9) are satisﬁed. Let B
2Mf , Mχ
t0 :
T

“ p
“
in Algorithm 1 according to the following:

4
p
`
α0
1 and

, and σX,f :

`
γt, θt, ηt, τt

σ2
f `

2, M :

max

Mf

D2

BLf

`

L0

t

u

q

1 be a constant,
ě
2. Set y0
1
Xkσk2
0,
{
2q

“

“
ě

t

u
t

γt
τt

“

“

t0
`
`
1
1 max

2,

2

32M
α0

, 384kσk
α0

t

2
2T

, σX,f T 3{2

B

t0

1{2

2
q

`

p

ηt
θt

,

u

t
`

Then, we have

E
r

ψ0

xT
p

ψ0

x˚
p

q ´

qs ď

α0

t0

p

`

1

t0
qp
T 2

2
q

`

D2
X

`

12BσX,f

t0
1
`
T 3{2

qp

p

t0

2
q

`

1{2

“

“

`

1
q

,

(2.10)

α0

p

t
`
t
`

t0
t
`
`
2
1
2 .

t0
t0

`
`

16
p

H2
0

ζ2
`
α0T

q

8B

t0

p

`

2
q
`
T 1{2

1{2σX,f

.
(2.11)

and

s
E(cid:13)
(cid:13)
r

ψ

xT
p

qs`

(cid:13)
(cid:13)2 ď

t0

192
p

`

2

ζ2

16
p

`

ky˚k2
qp
α0T 2
2
˚`

H

2

2

M

1
q

`

144
p

t0

2
`
α0T

qp

α0

t0

p

`

`
ky˚k2

2

1
q

`

1

t0
qp
T 2
2
kσk
2

q

D2
X

2
q

`

`

13BσX,f

t0
1
`
T 3{2

qp

p

t0

2
q

`

1{2

1{2

t0

6
p

2
q

`

ky˚k2
B

p

1
q

`

2σX,f

26B

t0

p

`

2
q
3

1{2σX,f

1
T 1{2 ,

`

(2.12)

s

`

`

where
H
˚

:

“

H0

ky˚k2 `
t0
t0
12
p
p
Moreover, we obtain the last iterate convergence

` p
σ2
0 `

`
kσk2
q

2ky˚k2

Hf
q

2 `

ζ :

96

2e

`

“

1

3

`

´

Lf DX

ky˚k2
r
2

1

B

s`

,

(

2

B2kσk2
q

2 `

`

2
˚

H
2 `

!“
x˚, XT
p

W

E
r

qs ď

t0

192
p

`

2

ζ2

16
p

`

ky˚k2
qp
α2
0T 2
2
˚`

H

2

2

M

1
q

`

t0

1

p

`

qp

t0
T 2

`

D2
X

2
q

`
ky˚k2

1
q

`

2

kσk

2
2

q

144
p

t0
2
`
α2
0T

qp

3α0BσX,f
p
2

t0

2
q

`

3{2

2
1
{

.

12BσX,f

t0
1
p
qp
`
α0T 3{2

t0

2
q

`

`

‰)

1{2

`

`

t0

2
q

`

p

1{2

ky˚k

2
2σX,f

Bα0

1
T 1{2

`

8B

p

1{2σX,f

t0

2
`
q
α0T 1{2

.

(2.13)

An immediate corollary of the above theorem is the following:

8

 
Corollary 2.2. We obtain an
D2
X

5α0

t0

t0

2

p

`

qp
ε

1
q

`

Tε

max

“

`

H

ζ2

!´
80
p

2
˚`
Moreover, we obtain E
r
t0
qp
ε

max

5
p

t0

`

2

144
p

t0

qp

2
`
α0ε
x˚, xT
p
D2
1
X
q

W

`

`
ky˚k2

ε, ε
p

-optimal solution of problem (1.1) in Tε iterations, where
q
960
p

65BσX,f

2
1
{

1
q

2
q

M

3,
2
{

3{2

t0

t0

qp

`

`

`

2

,

2

2

ky˚k2
α0ε

p
ε

2

2
kσk
2

1
q

`

q

,

30
p

¯
ky˚k2
`
B

1
q

2σX,f
`

t0
2
ε2 ,
`

130BσX,f
3

˘

2 t0

`
ε2

2

.

ε in at most

`

qs ď
t0
960
p

2

qp

`

2

2

M

1
q

`

2
1
{

,

˘
60BσX,f

t0
p
α0ε

`

3{2

2
q

`

3,
2
{

˘

)

(2.14)

(2.15)

!´
80
p

ζ2

H

2
˚`

144
p

`

t0

ky˚k2

2

1
q

`

5ky˚k

¯
2
2σX,f
Bα0

2 t0
`

2
ε2 ,
`

40BσX,f
α0

2 t0
˘

`
ε2

2

`
2
`
α2
0ε

qp

ky˚k2
α2
0ε
2
2

kσk

q

,

iterations.
Proof. Using (2.12) and (2.14), we have E(cid:13)
ψ
xT
(cid:13)
qs`
p
r
(2.11) and (2.14), it is easy to observe that E
xT
ψ0
p
r
have E
ε
s
5 `
r

x˚, xT
p

ε
5 “

ε
5 `

ε
5 `

ε
5 `

qs ď

W

`

˘

`

˘

)

ε
5 `
x˚
p
ε. Hence we conclude the proof.

ε
5 `
qs ď

(cid:13)
(cid:13)2 ď
ψ0
q ´

ε
5 `

ε
ε. Similarly, using
5 `
ε. Using (2.13) and (2.15), we

ε
5 “

Theorem 2.1 and Corollary 2.2 provide uniﬁed iteration complexity bounds for solving strongly
s
convex functional constrained optimization problems. These results will also be used later for
solving subproblems arising from the proximal point method for nonconvex problems in Section 3.
Below we derive from (2.14) the convergence rate of Algorithm 1 for both nonsmooth problems,
i.e., either Hf or H0 is strictly positive, and (composite) smooth problems, i.e., Hf
0.
“
Let us start with nonsmooth problems for which (2.4) is satisﬁed with H0
0 or (2.5) is
m

satisﬁed with Hi

0, H0

“

ą

ą

0 for at least one i
ky˚k2 `

H

1

P r
Hf
q

. In this case, we have
B

Lf DX

1

s

ky˚k2
r
2

`

´

s`

0

`
irrespective of the value of B. Then, using (2.14), we obtain the iteration complexity of

˚ “ p

`

ą

O

1
?ε

L0

p

`

BLf
?α0

q

DX

?L0

`

BLf BM
α0

H0

`

for the deterministic case. For the semi-stochastic case, the iteration complexity becomes

´

BLf
?α0
Similarly, for the fully-stochastic case, the iteration complexity is given by
σ2
0

¯
BLf

´
DX

?L0

1
?ε

BLf BM
α0

B2

DX

`

`

O

L0

L0

H

H

`

`

`

.

p

q

p

q

?L0

O

1
?ε

p

`

BLf
?α0

q

`

BLf BM
α0

ζ2
2
˚`
q
α0ε `

p

`

`

˘
1
ε2

p

`

qp
α0

D2

2
X kσk
2

`

q

.

`
L0

q

{

`

`

˘

´

?ε

1
p

Observe that, due to the built-in acceleration scheme of the ConEx method, the Lipschitz constant
˘¯
L0 will barely impact the convergence since it appears only in the O
term. Similarly, the
impact of the Lipschitz constant Lf will be minimized for a large enough B (i.e., B
1).
To the best of our knowledge, these complexity results with separate impact of Lipschitz constants
appear to be new for functional constrained optimization. Moreover, the iteration (and sampling)
complexity for the fully-stochastic case, i.e., general stochastic constrained problems requiring
only bounded second moments on nosies, has not been obtained before in the literature.
Now let us consider smooth problems for which (2.4) and (2.5) are satisﬁed with H0

0 and
“
1, . . . , m, respectively. We distinguish two diﬀerent scenarios depending on
“
ky˚k2 `
ky˚k2 `
ě
0 and the iteration complexity in (2.14) can be simpliﬁed as follows. For the
“

Hi
“
whether B
B
1
2
deterministic case, the iteration complexity in (2.14) reduces to
BLf BM
α0

BLf
?α0
Moreover, the complexity bounds for the semi- and fully-stochastic cases are given by

ky˚k2 `
p

ky˚k2 `

ky˚k2 `

1. First, if B

0 for all i

1, then H

Lf DX

?L0

˚ “

1
?ε

s`{

H0

Hf

q `

DX

`

`

ě

ě

´

O

L0

1

`

`

r

.

p

q

´

`

˘

2
H
˚
α0ε

¯
σ2
0

2
˚`
α0ε

`
L0

O

1
?ε

p

´

`
?L0

`

BLf
?α0

DX

q

`

?L0

`

BLf BM
α0

˘¯
σ2
0
α0ε

`

,

¯
σ2
0

q

p

`

`

L0

O

DX

1
?ε

BLf
?α0

BLf BM
α0

ζ2
α0ε `
´
`
respectively, where ζ2
kσk2
. It is worth noting that a similar bound
2{
q
q
to (2.16) has been obtained in [19] with a slightly diﬀerent termination criterion. On the other
hand, the complexity bounds in (2.17) and (2.18) for the semi-stochastic and fully-stochastic
cases seem to be new in the literature.

`
σ2
0 `
p

`
˘
BLf

L0
p

(2.18)

X kσk

˘¯

B2

BLf

α0

1
ε2

qp
α0

`

“

O

`

`

,

p

q

D2

2
2

B2

˘
L0
`

ă

Second, if B

ky˚k2 `

1 for the smooth case, then H

0 and the ConEx method converges
at the rate of nonsmooth problems in all these three settings described above. Hence, the ConEx
method still converges albeit at a slower rate without knowing exact bound on ky˚k2. On the
other hand, existing primal-dual methods require correct upper-bound estimation on ky˚k2 which
is used as a bound on y in order to deﬁne the projection operator and properly select stepsize. To

˚ ą

9

(2.16)

(2.17)

u

γt, ηt, τt, θt

obtain a faster convergence rate, one can possibly perform a line search for the right value of B
in the ConEx method, especially for the deterministic
when specifying the policy for
t
k2 can be measured precisely.
and semi-stochastic cases where the constraint violations k
It is worth mentioning that for the complexity results discussed above, we do not require the
constraints ψi, i
0 is
enough to ensure the selection of stepsize policy which yields accelerated convergence rates. In
(implying ψi’s are merely convex functions) then ηt in relation
particular, if αi
(2.29) is required to satisfy the following more stringent relation: γtηt
. Note
q
that our stepsize policy already satisﬁes this relation. Hence Algorithm 1 exhibits accelerated
convergence rates even if the constraints are merely convex.

1, . . . , m, to be strongly convex. From (2.10), we can see that α0

0 for all i

ηt
p

p¨qs`

ψ
r

P r

α0

γt

m

ą

ď

`

“

“

´

´

s

1

1

Now we provide another theorem which states the stepsize policy and the resulting conver-
gence properties of the ConEx method for solving problem (1.1) without any strong convexity
assumptions. The proof of this result can be found in Section 2.2.

Theorem 2.3. Suppose (2.4), (2.5), (2.6) and (2.9) are satisﬁed. Let B
M, σX,f and H
˚
according to the following:

be deﬁned as in Theorem 2.1. Set y0

0 and

“

t

ě
γt, θt, ηt, τt

1 be a given constant,
in Algorithm 1

u

where

γt
θt

1,
1,

“
“

ηt
τt

“
“

L0
τ,

`

BLf

η,

`

(2.19)

?2T

max

η :

τ :

“

“

H2
r

˚`

σ2
0 `
DX
?96T σX,f
B

48B2kσk2
2s

M,4kσk2
6B max
t
DX

,

u

`
M,4kσk2
, 2DX max
t
B

u

.

x˚
p

qs ď

L0

p

`

BLf

q

D2

X `

max
t
T

6M,24kσk2

BDX

u

`

?T

p

ζ2

?2
p
σ2
0 `

˚`

H2

H2
DX
0
`
q
48B2kσk2

2q`

(

Then, we have
E
r

xT
p

q ´

ψ0

ψ0

3BM `

?3BσX,f
?2T
(2.20)

and

s

E
r

k

ψ
r

xT
p

k2s ď

qs`

L0

p

`

BLf

q

D2

X `

max

t

6M,24kσk2
T

u

DX

B

`

ky˚k2
B

p

2

1
q

`

s

`

1
?T

12?6
p

ky˚k2
B

2

1
q

`

´`
?2DX?H2

˚`

σ2
0 `
?T

13B
4?6

`
48B2kσk2
2

`
σX,f

˘

where

` `

˘
`

?T

p

¯
H2

?2DX
σ2
0 `

˚`

H

ζ2

2
˚q
p
`
48B2kσk2

2q`

,

3BM

(2.21)

ζ :

2e

σ2
0 `

kσk2
2p

14ky˚k2

123B2

“

2 `
As a consequence, the number of iterations performed by Algorithm 1 to ﬁnd an
`
solution of problem (1.1) can be bounded by
D

q
˘

36M,144kσk2

ky˚k2

˚ `

q `

BLf

DX

L0

2

max

3
p

`

q

2
X `

max
t

σ2
X,f
ε2

,

36?6
p

ky˚k2
B

1
q

`

up

1
q

`

ε

2?3kσk2p

2BH

Bσ0

2.
1
{

13?3B
4?2

`

!

18
ε2

DX

b

`

H2

˚ `

σ2
0 `

48B2kσk2

2 `

DX

?H2

˚`

ζ2
2
H
˚q
`
p
σ2
48B2kσk2
0`
2

`

2

.

)

˘

ε, ε
p

-optimal
q

2,

˘

(2.22)

Theorem 2.3 provides uniﬁed iteration complexity bounds for solving convex functional con-
strained optimization problems. Below we derive from (2.22) the convergence rate of Algorithm
1 for solving both nonsmooth problems, i.e., either Hf or H0 is strictly positive, and (composite)
smooth problems, i.e., Hf

“
Let us start with the more general nonsmooth problems. Since Hi

0, . . . , m,
0. Then, the complexity bound in (2.22) for the deterministic, semi-stochastic

0 for some i

0, H0

0.

ą

“

“

we have H
and fully-stochastic cases, respectively, will reduce to
L0

˚ ą

D2

BDX

M

O

`

Lf DX
p
ε

`

q

O

`

L0

`

BDX

Lf DX
p
ε

M

q

`

2
˚

X H
ε2

,

D2

X p

2
H
˘
˚`
ε2

σ2
0

q

,

`

`

and

`

L0

BDX

Lf DX
p
ε

M

O

`

(2.23)
p
Similarly to the strongly convex case, the separate impact of the Lipschitz constants (L0 and
Lf ) on these complexity bounds have not been obtained before. Moreover, the iteration (and
sampling) complexity for the fully-stochastic case, i.e., general stochastic constrained problems
requiring only bounded second moments on nosies, appears to be new in the literature.

`

q`

˘

`

`

`

q

.

2

B

σ

2
f `

˘
2
X kσk

D

2
2
ε2

D

2
σ
0

2
X p

H

2
˚q

10

 
Now let us consider smooth problems for which Hf

0. We distinguish two diﬀerent
ky˚k2 `
scenarios depending on whether B
0 and
1, then H
the complexity bound in (2.22) for the deterministic, semi-stochastic and fully-stochastic cases,
respectively, will reduce to

H0
1. First, if B

ky˚k2 `

“
ě

˚ “

“

ě

L0

O

L0

O

`

`

`

BDX

BDX

Lf DX
p
ε
Lf DX
p
ε

`

`

M

M

q

q

,

˘
`

0 D2
σ2
ε2

X

,

(2.24)

(2.25)

and

`

˘
σ2
f `

`

L0

M

O

B2

BDX

Lf DX
p
ε

2
X kσk
2
(2.26)
`
ε2
where last bound is obtained from (2.22) by noting that ζ2
and replacing
σ2
2. Note that similar bound as in (2.24) has been obtained before by using
X,f “
more complicated algorithms (e.g., penalty method) or diﬀerent criterion. On the other hand
the complexity bounds in (2.25) and (2.26) appear to be new in the literature. Second, if B
ky˚k2 `
nonsmooth problems in all these three settings described above.

ă
0 and as a result, the ConEx method still converges but at the rate of

,
48B2kσk2
σ2
2q
0 `
˘
p

1, then H

σ2
f `

Xkσk2

q`
O

˚ ą

X σ2

D2

D2

D2

`

“

`

q

p

0

It should be noted that, diﬀerent from the strongly convex case (c.f. (2.10)), the stepsize
ky
scheme in (2.19) depends on H
k2 `
˚
˚
1. However, we can replace H
In this way,
˚
similar complexity bounds will be obtained for most cases, including nonsmooth deterministic,
nonsmooth semi-stochastic, nonsmooth fully-stochastic, as well as smooth semi-stochastic and
smooth fully-stochastic problems. In particular, with this modiﬁcation the last term in (2.22)
will change to

, implying that we need to estimate whether B
in the deﬁnition of η by HB :

BHf .

H0

“

`

ą

18
ε2

DX

´

b

H2

B `

σ2
0 `

48B2kσk2

2 `

DX

?H2

B `

ζ2
2
H
˚q
p
`
48B2kσk2
σ2
2
0 `

2

.

¯

˚ ą

0 but H

“
?T HB

The only exception that this modiﬁcation would not work is for smooth deterministic problems.
In this case, since HB
0, the stepsize scheme (2.19) set according to replacing H
˚
by HB does not yield convergence. In particular, the last term in the infeasibility bound (2.21)
would change to H2
BM
0. One possible solution for
0 in the deﬁnition of η to be some large positive number and forgo
this is to artiﬁcially set HB
ą
of the faster convergence of O
. After this change, we would obtain a convergence rate of
q
ε2
O
. An alternative approach would be to design a line search procedure on HB for the right
q
{
k2.
value of H
˚

, since there exists a veriﬁable condition based on the constraint violation k

which is a constant when HB

1
p

1
p

˚{p

“

`

ε

{

q

ψ
r

p¨qs`

2.2 Convergence analysis of the ConEx method

z,
p

q

In this section, we provide a combined analysis of Theorem 2.3 and Theorem 2.1. Note that
Algorithm 1 is essentially a dual type method. In order to analyze this algorithm, we deﬁne a
primal-dual gap function for the equivalent saddle point problem (2.1). In particular, given a
pair of feasible solutions z
y
of (2.1), we deﬁne the primal-dual gap function
Q

and

x, y

“ p

“ p

x,

z

z

q

q

as

:

s

Q

z,
p
One can easily see from (2.2) that Q
0 for all feasible z. We use the
gap function of the saddle point formulation (2.1) to bound the optimality and infeasibility of
the convex problem (1.1) separately, in terms of Deﬁnition 2.1. We ﬁrst develop an important
upper-bound on the gap function in terms of primal, dual variables and randomness. This bound
holds for all non-negative γt, ηt and τt. The precise statement is provided in Lemma 2.5.

x,
L
s
s
p
0 and Q
s

.
x, y
L
p
q
z˚, z
p
s

z
s
q
z, z˚
p
s

(2.27)

q ě

q ď

q ´

“

y

The following technical result provides a simple form of the Three-point theorem (see, e.g.,

Lemma 3.5 of [21]) and will be used in the proof of Lemma 2.5.

Lemma 2.4. Assume that g : S

R satisﬁes
x
, y
x
g1
q
p

´

g

g

y
p

Ñ
,
y, x
µW
q
p
q ` x
0, where S is closed convex set in Rn. If
W
x

x
p

q ě

y `

x

g

argmin
S t
x

“

x
p

q `

x,
p

qu

P

for some µ

ě

then

x, y

@

S

P

(2.28)

,

g

x

W

q `

x
p

x,
p
Proof. It follows from the deﬁnition of W that W
r
Using this relation, (2.28) and the optimality condition for
g

x
p
x

W
q

x,
p

x,
p

q “

q ď

q `

∇W

W

W

`

x

x

x

x

s

s

s

1

g

g

s
µ
q ` p

r
W

W

x
p

q `

x,
p

q “

x
p

q ` r

x,
p

x,
p

, x
q

x
r

´

y `

q ` x

∇W

x

,
q

x,
p
x
x,
q`x
p
r
x, we have
x
r

qs

x,
W
s
p
s

S.

x

@
x,
p

P
x

, x
q

x

y`

W

x,
p

x
.
q

´

s

r

s

s

r

s

r

s

r
11

s

s

g

, x
x
q
p
x
x,
p
s
Hence we conclude the proof.

x
p
x
p
s

g1
W

q ` x

q `

ě

ě

g

´

y `
µ
q ` p
s

`

x

x

µW

x,
p
W
q

x,
p

1

q ` r
.
x
q
s

W

x

x,
p

∇W

x,
p

, x
x
q

´

x

y `

W

x

x,
p

qs

q ` x

s

r

s

r

s

s

Lemma 2.5. Suppose (2.4), (2.5), (2.6) and (2.9) are satisﬁed. Let B
is a non-negative sequence satisfying for all t
assume that

γt, ηt, τt, θt

s

s

r

s

t

u

ě
1,

ě

0 be a constant and

γtθt
γtτt
γtηt

“

ď
ď

γt
γt
γt

´

´

´

1,
1τt
´
ηt
p

1

1,

1

`

α0,t

´

1

,
q

´

`

θt

Mf
p
Mf
p

Mχ

Mχ

ď

2
q
2
q
2 1
θt ď
q

ď

`
2Mf
p

τt

τt

τt

p

p

p

ηt´1

L0
12

´

´

BLf

,

q

ηt

´

L0
12

´

BLf

,

q

ηt´1

L0
12

´

´

BLf

,

q

2Mf
p

2 θt
θt´1 ď
q

ηt´2

τt

p

L0
12

´

´

BLf

,

q

(2.29a)

(2.29b)
(2.29c)

(2.30a)

(2.30b)

(2.30c)

(2.31)

0

ě

and, for all t

2,

ě

where α0,t :
and z

P tp

1 and Mf , Mχ, Lf are constants as deﬁned in (2.8). Then, for all t

ř
ď

0

αT yt
α0
“
`
`
x, y
X, y
: x
P
q
ě
u
t
zi
0γiQ
1, z
i
p
q `
`
“
x, x0
γ0η0W
p
t
i
“
t
ř
i
“
xt
ř
q ´
p
xt
ℓf
q
p
q ´

q ´
2γi
ηi
L0
´
´
3γiθ2
kqi
i
2τi
´
ℓF
xt
1
p
´
and δG
t

`
ℓF

`

1

0

BLf

“
xt
p

, we have
0γi

t
i
“
ηt
γt
ř
`
p
kδG
i k2

rx
α0,t

x

δG
i , xi
W
q

´
x, xt
p
H0

˚ ` p
3γt
2τt

“
qik2
2 `
χ
xt
q ´
p
xt, ξt
G0
p

q `
s
:
“

`

q `
Hf kyk2 `
1k2
2.
qt
`
qt :
ℓf
,
1
q
“
m
xt, ξt
1Gj
s
j
p
“
s
ytk2

´

`

´
´

kqt
1
`
xt
χ
p
q `
ř
τt
2 ky

δF
1, yi
1
i
`
`
γ0τ0
2 ky

y ´ x
1

´

y
ys
y0k2
2 ´
kyk2 ´

r

´
Lf DX
2

1k2
2

yt

`

´

γtτt
12 ky
2
B
s`q

xt
p
j
yp
qt
q
`

q ´
1 ´

ℓf
xt
p
xt
f 10p

1

´

q ´

‰

(2.32)
xt
χ
χ
xt
,
p
q ´
q `
p
q
´
j
m
yp
xt
1f 1jp
1.
qt
j
q
`

“

1

2. Hence, using Lemma 2.4, we have for all

ř

Here qt :
δF
ℓF
:
i

“

0,

y

ě

Proof. Note that yt

`

1

“

argmin

st, y

0 x´

y

ě

y `

st, yt

1

y

τt
2

ky

´x

´
`
j
“
yp
xt
1f 1jp
Let us denote vt :
xt
f 10p
qt
q
`
due to the strong convexity of χ0 and χj, j
X,
the deﬁnition of α0,t, we have for all x

y ď
m
j

q `

ř

´

“

“

ytk2

kyt

1

ytk2

ky

2 ´
`
1 and Vt :

2 ´
`
1Gj
xt, ξt
p
1, . . . , m, the optimality of xt

´
G0

q `

m
j

“

´

“

yt

1k2
2

.

(2.33)

j
‰
yp
xt, ξt
1. Then,
qt
p
q
`
1, Lemma 2.4 and
`

(2.34)

0, we have

ě

.
q
1
`

ř

χj

x
p
W
q

j
yp
qt
1
`
x, xt
p

P

1

χ0

“

x
p
W

χ0

xt
p
W

Vt, xt

1

x

χj

xt
p

1

m
j
1p
“
1, xt

r

x

`

´

ď

ηt

y `

vt, xt

q `
xt
p

q ´
`
x, xt
1
p
`
Due to the convexity of f0 and fi, (2.4), the deﬁnition of ℓf and the fact that yt
xt
f 1ip
` x
xt
f0
p
yt

´
xt
f 10p
xt
f0
@
p
yt

`
f0
q ´
1, ℓf

x
´
y
H0kxt

i
yp
qt
q
`
xt
f 1
p

xt
f 10p
´

y “ x
, xt
1
q

xt
ř
xt
p
f

xt
´
xtk2

´
`
1, xt

`
f0

q `
1

qs ´ p

D
q ´

α0,t

x
y

m
x

`
ηt

xtk

q ´

q ´

q `

i
Pr

ř
`

xt

xt

´

´

`

`

ě

“

qq

x

`

`

`

x

1

1

1

s

x
p
xt
p
f0

´
1
`
xt
p
ℓf

` x
f0

`
xt
p

`

1

“

q ´

`
x
p

q ´

q ` x

qy ` x
xt
1
p

`

q ´

`
f

1

1, xt
yt
q
`
L0
2 kxt
q ´
`
1, f
f
xt
p
, yt
x
q
p

q ´
1

y ´

`

1
´
x
qy
p
L0
2 kxt
`

`

L0
where Ot
H0kxt
2 kxt
`
Combining (2.34), (2.35), noting that δG

xtk2

1 :

´

`

“

`

1

ψ0

xt
1
p
`
ηtW

q ´
x, xt
p
Noting the deﬁnition of Q
1, z

Q

ď

1

ψ0

x
p

zt
p

`

ψ
q ´ x
τt
2

ď

q ´
,
¨q
p¨
, y
y ` x
q
ytk2
2 ´
x, xt
p

xt
p
`
ky
´
ηtW

“
`

In view of (2.5),

q ` x
ηtW

xtk is a ‘Lipschitz’-like term for the objective.
χ, we have

χ0, ψ

f0

1
´
`
Vt
t “
χ
1
q `
`
1, xt

vt and using ψ0
ψ

´
xt
p
ηt

1

`

ℓf
xt
p
xt
p

, yt
x
q
p
`
x, xt
W
p
q
in (2.27) and, adding (2.33) and (2.36), we obtain
δG
t , xt

q ´
α0,t

st, yt

q ´ p

q `

`

y

`

`

`

`

1

1

1

“
1
y ` x
1

`
δG
t , xt
1.
Ot

“
´

f
`
x
y

(2.36)

1

´

x
y

, yt
q

`

´

y ` x

`

`

1

`

ℓf

xt
p
kyt

χ
q `
ytk2
1
´
`
xt
ηtW
p

xt
p
2 ´
1, xt

`

q ´

`
ky

´
q ´ p

1
y ´ x
1k2
2
α0,t
‰

`

`

yt
ηt

W
q

x, xt
p

`

1

q `

Ot

`

1.

(2.37)

xtk2

1

´

`
Ot`1

H0kxt

xtk

,

(2.35)

1

´

`

˘

fi

xt
p

`

1

q ´

xt
ℓfi p

`

1

q ď

Li
2 kxt
`

1

´

xtk2

`

Hikxt

`

1

´

xtk.

12

Then, using Cauchy-Schwarz inequality and noting deﬁnitions of Lf , Hf , we have
,

y, f

Hf kxt

xtk2

xtk

ℓf

xt
p

1

`

q ´

xt
p

1

`

qy ď

kyk2

x

Lf
2 kxt
`

1

´

1

`

´

`
Ct`1

“
xtk is a ‘Lipschitz’-like term for the constraints. In

‰

1

`

“

Lf
2 kxt
`

1 :

xtk2
where Ct
view of the above relation and deﬁnitions of qt and δF
t
`
y
1
y
´
, y
1
y ´ x
q

xt
p
1
q `

xt
p
ě x

y ´ x
1

Hf kxt

1
`
χ

`
1

ℓf

´

´

`

χ

`

`

`

`

x

1

1

1, we have

1
`
ℓf
ℓf
ℓf

qt

q `
xt
p
xt
p
xt
p

1

`

1
`
1, yt

“ x
“ x

“ x

`

χ
χ

q `
q `
1

`

´

, yt
q
xt
p
xt
p
xt
p
y

`

`

y ´

ψ

xt
p
y ´ x
1

y ´ x
, yt
1
q
`
st, yt
`
xt
ℓF
p
qt, yt

q ´
q ´
θt

1

1

, y
1
q
`
xt
ℓf
p
y
χ

´
q ´
y

´

y ´

x

y ´
xt
p
θt

x

st, yt
`
xt
χ
q `
p
kyk2Ct

`
1
`
θtqt, yt

q ´
qt, yt

y

´

1

`
yt

1

`

´

y ´ x

y ´
δF
t
`

kyk2Ct
1, yt

1

1

`

y

Given the non-negative constant B and using the deﬁnition of Ct
`
xtk2
`
xtk2

xtk2
`
xtk2

kyk2Ct

kxt
q

´
1

´
1

“

B

B

`

1

1

1

Lf
kyk2 ´
2 p
Lf
kyk2 ´
2 r
BLf
2 kxt
´
`

ď

`
kxt
s`
xtk2

`

BLf
2 kxt
`
BLf
2 kxt
`
Lf DX
2

(2.39)
`
Recall the deﬁnition of DX from (1.6). By (2.37), (2.38), and (2.39), noting the deﬁnition of
Ot

s`

´

ď

`

˘

`

r

1

1

´
kyk2Hf

B

`

`

´
kyk2 ´
and replacing index t by i, we have
q
y

x

δG
i , xi

1, yi

y

1

´

y ` x

´

y ´ x

`

´

y

δF
i
`

´
y ´
`
1, we have

kyk2Ct

`

1.

(2.38)

1

kyk2Hf kxt
`
kyk2Hf kxt
kxt

`
xtk.

´
1

´

xtk

xtk

st, yt

`

y

1

´

y ´

kyk2Ct

`

1

1, using the relation 1
`
Q

qi

zi
p

`
θi

1, z
qi, yi

x
ηiW

ď

q ` x
1
´
`
x, xi
p

1, yi
`
yi

`

y ´ x
ηi

´
y

2 ka
1
´
δG
i , xi
α0,i

bk2
θi

`
a, b
W
p
qi, yi

ď

y ´
1

x
xi

y
´
`
x, xi
W
q
p
1, xi

1

`

´

`

´

ηi

L0

q `

´ p

q `

xi
p

`
H0

q ´ p
BLf

`
W
q
Multiplying (2.40) by γi, summing them up from i
we obtain
0γiQ
zi
p
t
0γi
i
“
t
i
“

γi
x
`
δF
1, yi
i
´
`
`
γiθi
yi

ys
qi, yi

1, yi

t
i
“

t
i
“

γiθi

´
y

ř
`

y ´

0r

1r

ř

yi

qi

´

`

ď

y

`

`

x

1

1

x

q `

x
ř
´
qi, yi

1, z
`
δG
i , xi
qi
´
γiτi
2 ky
´
s
x, xi
γiηiW
“
0r
p
γi
0

L0

ηi
p

0

rx
γiθi
t
i
“
t
i
“
t
i
“

´

y ´ x
1
´
`
yik2
2 ´

´

ř

`

`

´

ř

ř

y `
γiτi
2 ky
ηi
p
BLf

γi

`

q ´

W
q

xi
p

`

1
x
`
1k2
yi
2
´
´
`
s
x, xi
W
α0,i
‰
q
p
1, xi

γi

q ´

ř
1
`

qs
H0

ř

“

`

ky

τi
2
´
kyk2Hf

“

yik2

kyi

2 ´
Lf DX
2

`
0 to t with t

r

“

1

`

´
kyk2 ´
ě

yik2

ky

yi

1k2
2

`

2 ´
´
B
1
0 and noting that q0

xik.
‰

kxi

s`

´

`

˘

(2.40)
0,

“

qi, yi

y

ys

´

t
i
0x
“
γiτi
2 kyi
ř
`

ys `
t
i
“

0

γiδG

i , xi
´
yik2
2

1

´

xi

`

1

y

kyk2Hf

`

Lf DX
2

y,B

p

q

`
H

kyk2 ´

r

B

s`

kxi

`

1

´

xik

,

˘

‰

(2.41)

Lf DX
2

. Now we focus our attention to handle the

:

r

q

B

`

`

“

ℓf

H0

kℓf

y, B
p

kyk2Hf
where H
inner product terms of (2.41). Noting the deﬁnition of
qik2 “
k
ď

k2
q
xi
f
q ´
p
T
xi
2
1
p
q
´
kxi
Mχ
q
where the last relation follows due to (2.7). Using the above relation, we have for all i

kyk2 ´
xi
p
1

xi
p
xi
p
xi
kf
1
p
´
2Mf kxi

s
f 1
xi
p
q ´
k2 `
2
q
´
1k,

xi
p
xi
´
p
xi
f 1
p
Mf

´
xi
p
xi
p
xi

xi
p
xi
p

T
q
´
kf 1

qt, we have

q ´
` p

kχ
xi
k2 `
p
q
q ´
Mχkxi
xi
k2 `
q

xi
p
f 1

q `
T
1
q

´
xi
xi

´
xi
p

q ´
xi

q ´
1

´
´

2
´
2k

q ´
1

ď
ď

T
q

q `

kf

s`

xi

´

`

´

χ

χ

s

f

´

´

´

´

´

´

´

´

´

´

´

´

1

1

2

2

1

2

1

1

χ

xi
p

´
xi
´
(2.42)
1,

1

k2
q
1k

´

yik2

2 ´

γi´2

ηi´2

p

´
4

L0

´

BLf

W

q

xi
p

´

1, xi

´

2

q

ě

γiθi

qi, yi

1

´

ď

ď

p

´
L0

`
ηi´1

´
4
qik2kyi
ηi´2

x
γi´1
s
γiθik
γi´2
p
´
4
´
s
2Mf γiθikxi

yi

´

y ´
BLf

1

`
L0

´
BLf
´

q

1

γiτi
3 kyi
´
`
xi, xi
W
1
p
q
´
γiτi
3 kyi
yik2 ´
`
1, xi
xi
W
p
2kkyi

´

1

q

xi

´
Mχ

1

´
´
γiθikxi
q

`

´
1kkyi

xi

´

´

Mf

`

` p
0,

1

´

yik2
2
γi´1

2

´

q ´
yik2 ´
´

`

1

ηi´1

p

´
4

L0

´

BLf

q

yik2

1

γiτi
6 kyi
´
`
γiτi
6 kyi
yik2 ´
`

2 ´
1

´

W

xi, xi
p
´
ηi´2
γi´2

p

1

q
L0
´
4
γi´1

p

yik2

2 ´

ď
where the last inequality follows by applying the relation W
(2ab

b2) applied twice, once with

a2

x, y
p

q ě

1
2 kx

´

ď

`
a

γiτi
6

2
1
{

kyi

`

1

´

yik,

“

γi´2

ηi´2

p

´
8

L0

´

BLf

q

2
1
{

b

“

kxi

´

1

´

2k,

xi

´

`

˘

`
13

˘

BLf

q

´

W

ηi´1

L0

´
4

´

1, xi

xi
p
BLf

´

W

q

2

q
´
xi, xi
p

q
´
(2.43)
yk2, Young’s inequality

1

second time with

“
and the fact that
`
γiθi
2Mf
q
p
γiθi
q

Mf
p

Mχ

`

ď

ď

a

γiτi
6

2
1
{

kyi

`

1

´

yik,

b

“

γi´1

ηi´1

p

´
8

L0

´

BLf

q

2
1
{

kxi

1k,

xi

´

´

˘
γiγi´2τi

γiγi´1τi

p

p

ηi´2
12
ηi´1
12

´

´

L0

L0

´

´

BLf

BLf

2
1
{

2
1
{
(

q

q

`

ô

2Mf
p
Mf

`

˘
2 θi
θi´1 ď
q
2θi
Mχ
q

ď

ô p

ηi´2

ηi´1

τi

τi

p

p

L0
12
L0
12

´

´

BLf

BLf

´

´

,

,

q

q

where equivalences follow from (2.29a) and conditions follow from relations in (2.30a) and (2.31).
1 such that (2.43) is satisﬁed for i
In particular, we require (2.30a) and (2.31) for t
1.
Moreover, kxi
2.
Using Young’s inequality, Cauchy-Schwarz inequality and the relation uT v

ě
1. Hence, we require (2.31) for t

, we have

kukkvk

0 for i

2k

xi

ě

ě

“

“

´

(

´

´

1

qi

qi, yi

γiθi

x
i , xi

γiδG

´
xi

y ´

1
s
`
xik

´

“
qt

`

1

`

´

´

γiH

kxi
q

x
y, B
p
Using (2.43) and (2.44) for i
zi
1, z
γt
x
p
`
x, x0
γ0η0W
p
t
i
“
γt´1
ř

0γiQ

t
i
“

q `

ř

ď

1

q ´
3γiθ2
i
2τi
ηt´1

kqi

q

1

1

´

`

ηi

γi

γi

´

´

yi

BLf

kqi

2 ď

1, xi

yik2

´
ηi
p

3γiθ2
i
2τi

y ´
L0
´
4

γiτi
6 kyi
`
xi
W
p
xi
p

ď
qik2
2,
kδG
i k2
s
˚
y, B
1, xi
H
p
1, . . . , t inside (2.41) and noting (2.29), we have
δG
1, yt
i , xi
`
ηt
γt
p

t
0γi
i
“
x, xt
ř
p

´
α0,t

´
2γi
L0

W
q

2γi
L0

y ´ x

rx
1

q ď

q ď

L0
4

y `

q `

BLf

BLf

BLf

W

ηi

ηi

y

´

´

`

´

`

`

´

´

1

,

p

q

˚

(2.44)

2.
q

`

´
´
BLf
xt
q
p
s
`
where on the left hand side of the above relation, we use the fact that q0
χ

˚ `
W
q

“
1
´

L0
2

q ´

´

´
4

L0

γt

´

´

´

´

´

p

p

BLf
ηt

´
1, xt
,
q
x0
ℓF
p

“

‰
(2.45)
x
p

q `

´

1

ℓF

q ´

`
qik2

2 `
W

t
i
“
xt, xt
ř
p

2γi
L0

0

ηi

x
´
γ0τ0
2 ky
´
kδG
i k2
BLf

y

δF
i
`
y0k2
2 ´
2γi
L0

1, yi
1
´
`
γtτt
2 ky
H

BLf

ηi

ys
yt

1k2
2

´

`
y, B
p

2
q

1
q “
1, yt
`
ηt´1

0. Using (2.42), we have
γtτt
1k2
3 ky
2
γt
W

y ´
BLf
q

´
L0
´

yt

y

`

1

x0
p

q ´
´

´

χ
γt

x
p
qt
x
`
γt´1
´
s
Mf

p

`

Mχ

´
4
γtkxt
`
q
2Mf γtkxt
γtτt
12 kyt
`
γtτt
12 kyt
`

xt
´
yk2
2
yk2
2,

´

´

1

1

´

ď p

`

´

ď ´

ηt

p

´

BLf

W

q

´
xt, xt
p
xtkkyt

1

´

`

1

´

q ´

yk2 ´
γtτt
6 ky

1

`

´
yk2 ´

´

L0
2
γtτt
12 ky
yt

´

1

´
1kkyt

1, xt
γt

xt
p
`
1k2
2 ´
γt´1
p

`

q
ηt
p

´

L0
2
L0

yt
´
1k2

`

2 ´

ηt´1

´
4

BLf

W

q

´

BLf

q

´

W

1, xt

q

xt
p
`
xt, xt
p

´

where the last relation follows from (2.30b) and (2.30c), Young’s inequality and the fact that

2Mf
p
Mχ

γt
q
γt
q

ď

Mf
p

γt´1γtτt

p

γ2
t τt

ηt

p

L0
´
12

´

ηt´1
12

L0

´
BLf

2
1
{

q

BLf

q

´

2
1
{

ô

2Mf
p
Mf

2 1
θt ď
q
2
Mχ
ď
q

BLf

,

q

ηt´1

τt

p

τt

ηt

p

´

L0
´
12

L0
12

´

´
BLf

.

q

1

x

`

`

`

ď

´

`

´

`

qt

γt

(
1

1, yt

ô p

(
Finally, again using Young’s inequality and Cauchy-Schwarz inequality, we have
3γt
1k2
y
2.
(2.47)
2τt
0 and replacing the deﬁnition of

qt
yt
`
Using (2.46) and (2.47) in relation (2.45), noting that q0
, we obtain (2.32). Hence, we conclude the proof.
H
s
q

y, B
p
We now aim to convert the bound on the primal-dual gap function Q in Lemma 2.5 into
xT according to Deﬁnition 2.1.

bounds on the optimality and infeasibility of the ergodic solution
For proving this lemma, we need one more simple result which is stated below.
Lemma 2.6. Let ρ0, . . . , ρj be a sequence of elements in Rn and let S be a convex set in Rn.
Deﬁne the sequence vt, t

1k2
2 ď
q0
“

γtτt
6 ky

y ´

kqt

qt

´

´

´

´

s

s

s

`

`

1

Then for any x

P

S and t

“

1

vt

0, 1, . . . , as follows: v0
ρt, x

argmin
´
S x
x
0, the following inequalities hold
vtk2

S and
1
2 kx

P
y `

vt

“

x

`

P

1
2 kx

1
2 kx

´

2 ´

´

y ď

´

`

ě
ρt, vt

x

vtk2
2.

j
t
“

0x

ρt, vt

´

x

1
2 kx
, W

v0k2

2 `

´

y, x
p

q “

1
2
1
2 ky
ř

y ď
ρt, x
y

Proof. Using Lemma 2.4 with g
ř
due to the optimality of vt

x
p

q “ x

`

1,
x

x
is satisﬁed for all x

imply that

ρt, vt

1

`

´

1
2 kvt
´
`
S. The above relation and the fact
vtk2

1
2 kx

ρt, vt

2 `

vtk2

y `

vt

´

1

1

1

vt

`

P

1k2

2 ď

1
2 kx
r

1

2 kρtk2
2,

1
2 kvt
`

x

´

`

y ´

´

2 ď

1k2

1

2 kρtk2
2,

2 `
j
0kρtk2
2.
t
“
xk2
x
2,

´

(2.48)

(2.49)

vt and µ

“

0, we have,

vtk2
2,

“

´

1

q

(2.46)

ρt, vt

x

x

y ď

´

1
2 kx

vtk2

2 ´

1
2 kx

vt

`

1k2

2 `

´

´

1

2 kρtk2
2,

14

 
 
 
 
S. Summing up the above relations from t
for all x
k2
2, we obtain (2.49). Hence we conclude the proof.
k
¨
Now we are ready to prove the lemma converting bound on the primal-dual gap to infeasibility

0 to j and noting the nonnegativity of

“

P

and optimality gap.

Lemma 2.7. Suppose all assumptions in Lemma 2.5 are satisﬁed. Then, for T

γ0η0W

qs ď

ψ0

E

r

`

´

γT

xT
p

q ´
T
1
´
t
0
s
“
ηT
ř
1
p

´

1

ηt

`

ψ0

x˚
p
2γt
L0
´
´
α0,T

1
ΓT
E
r
W

x˚, x0
p
H 2
0

q `

γ0τ0

2 ky0k2
2
12γtθ2
t

BLf

1

´

E
`
r
q
T
1
´
t
1
“
T
1
`ř
´
t
0
“

ηt

˚s `

kδG
t k2
“
x˚, xT
p
12γtθ

2
t

τt `
2γt
L0

BLf

´

´

T
1
´
t
1
`
“
γ0τ0
2 ky˚
˘
`ř
σ2
f `
p
kδG
t k2
˘

´
D2

˚s ` p

qs ď
12γT ´1
τT ´1
E
r

y0k2

τt `
2 `
X kσk2
2q
ky˚k2Hf

H0

`

`

`

12γT ´1
τT ´1
γ0η0W

σ2
f `
p
x˚, x0
˘
p

q

and
E
k
r

ψ
r

xT
p

k2s ď

qs`

ř
1
ΓT

s

`

where ΓT :

“

`
T
1
0 γt.
´
t
“

`ř

3

γ0τ0ky0k2
”

2 `
2γt
ηt
L0
´
´
12γtθ2
t

T
1
´
t
0
“
T
1
´
t
1
“

τt `

BLf

ř

2γ0τ0
q

1

ky˚k2 `
p
E
kδG
t k2
r

˚s ` p

T
1
“
´
t
0
“

γt
τt `

12γT ´1
τT ´1

ř

`
H0

γ0η0W

x˚, x0
p
ky˚k2 `
` p
D2
σ2
f `
p
˘

q
Hf
q
Xkσk2
2q
ı

1

1, we have

ě

,

D2

X kσk2
2q
‰

(2.50)

(2.51)

ky˚k2 ´

B

2
s`q

` r

,

(

Lf DX

ky˚k2
r
2

1

´

`

`

B

s`

2
q
‰
(2.52)

.

ř

Proof. Notice that conditional random variables
properties of SO in (2.9) because xt is a constant when conditioned on random variables ξ
t
´
r
ξ
ξ0, . . . , ξt
1
t
2
p
´
s
´
r
on random variables ξ
t
´
r
E

ξ0, . . . ,
ξ
and
t
1
s
´
r
s
s
δG
x
t , xt
ys “
´
´
s
for any non-random x. This follows due to the following relation

2
´
. In particular, using (2.9), we have
0,

. Also, observe that, yt
q

“
1 is a constant when conditioned

0, . . . , m satisfy

xt, ξt
p

ξ
t
q|
´
r

“ p
1
s

δG
t s

ξ
t
´
r

(2.53)

E
x

ξrt´1s,

E
|

and

y “

, xt

2
ss

Gi

1
s

1
s

ξt

, i

“

rx

x

s

s

`

q

r

:

,

:

ξrt´1s r
s

E

|

δG
t s

ξrt´1s,
E
|

ξrt´1sr
s
ξrt´1s ,

“

xt, ξt
p
Similarly, using (2.9), we have
1, yt

ξrt´1sr
s

G0

E

rx
for any non-random y. Here, we note that

ys “

´

`

δF
t
`

δF
t
`

1

y

E
|

ř
E
ξrts,
|

E
r

@
F

xt,
p

ξrt´1s r
s
ξt

f

δF
t
`

1s

xt
p

E
|

ξrt´1s r
s
, yt

1

`

´

0,

s “

y

D

xt
f 10p

qs `

q ´

E

m
i
“

i
1yp
qt
1
`

E
|

ξrt´1s,

Gi

xt, ξt
p

q ´

xt
f 1ip

qs “

0.

T

`

`

ξrts,

qs ´

q
f 1

xt
p

xt
p

1s “

qs ´
ξt

xt,
G
s
p

ξrts,
E
|

ξrt´1s r
s

ξrt´1s r
s

ξrt´1s r
xt
s
ξrts,
where the ﬁrst term in RHS is 0 due to the third relation in (2.9) applied to
is 0 due to the second relation of (2.9) applied to
1 are constants for given ξ
that xt, xt
t
`
s
r
2E
kδF
t k2
xt
ξt
1,
xt
2s ď
p
q ´
p
r
m
2E
2σ2
xt
Gi
f `
i
1
s
p
p
r
“
m
2E
2σ2
1kGi
xt
ř
f `
i
p
r
“
Xkσk2
2D2
2σ2
2.
ř
f `
T . Then, in view of the above relation and deﬁnitions of qt,
σ1, . . . , σm

q “
ξt, the second term
s
ξt and the common fact for both the terms
. We note that
s
2E
1,
k
r
r
xt
f 1ip
xt
f 1
p

ξ
t
1
´
r
s
k2
1
2s `
q
´
s
ξt
1,
1
´
ξt
1,
s
´

q ´
1
q
´
1k2
(
s

(2.56)
qt, we

´
xt
p
kxt

T
qq
k2
q
˚

xt
f 1
p
2

xt
G
p

k2
2s
q

´
xt

xt
p

E
r

q
˘

q ´

q ´

kF

xt

xt

0,

s
´

ξt

´

´

´

ď

ď

qs

s

s

f

´

´

´

`

´

´

´

´

´

´

s

T

1

1

1

1

1

1

1

1

,

(2.54)

(2.55)

kℓF
xt
p
kδF
t k2

E
q ´
r
2E
σ2
f `
p
r
0, then taking expectation on both sides, and using relation

k2
xt
1
2s
p
q
´
X kσk2
D2
.
2q

xt
ℓf
q `
p
2E
kδF
t
r
´

xt
p
´
8
2s ď

q ´
2s `

ℓF
1k2

s
(2.57)

ℓf

1

s
In (2.32), choosing t
T
´
(2.53), (2.54) and (2.57), we have for all non-random1 z
E
r

T
1
0 γtQ
´
t
“

γ0η0W

y0k2

zt
p

2 `

qs ď

1, z

´

“

1

`

ď
ě

γ0τ0
2 ky
T
1
´
t
0
“

2γt
L0

E
r
1

BLf
α0,T
“

x, x0
p
kδG
t k2
E
W
r
q

`ř
`
,

ř

`

˚s ` p
x, xT
p
1This x, y is required to be non-random because we are dropping the inner product terms of the left hand side

(2.58)

γT
ř

`

`

´

qs

´

´

´

´

‰

1

1

ηt
´
ηT
p

: x
P
q
12γtθ2
t
τt `

x, y
P tp
T
1
´
t
1
“
kyk2Hf

q `
H0

X, y

,
u

0
ě
12γT ´1
τT ´1

Lf DX

σ2
f `
p
kyk2
B
˘
s`
´
r
2

D2

X kσk2
2q

2
q

ď
Recall that σ
have

“ r

s
qtk2

2s “

kqt

E
r

´

of (2.32).

15

 
 
where we dropped ky
ΓT , we have for all non-random y

yT k2

´

2. Using the convexity of ψ0
0 and x
x
ψ0
p

ě
xT
p

qy ´

y, ψ

X,

ΓT E

ψ0

xT
p

q ` x

Combining (2.58) and (2.59), then choosing x
the combined relation, observing that
noting that ψ

s
0 and

0

“

r

yT

x˚
p

ě
q ď
Now, we prove a bound on E
r

s
´
0 implies
x
W
x˚, xT
qs
p
0, . . . , T
s

ď

P
x
yT , ψ
p
q ´ x
x˚, y
“
“
B
0 for any B
s
s` “
x˚
yT , ψ
p
. Put z

‰

ě

“ p
“

that Q
of Q-terms and taking expectation on both sides, we obtain (2.51).

0 for all t
s

1, z˚

zt
p

q ě

´

“

`

Now, we focus our attention to the infeasibility bound. Let us deﬁne R :

and ψ

p¨q

, and noting the deﬁnition of

p¨q

E
r

T
1
0 γtQ
´
t
“

zt
(2.59)
qy
p
0 (which are non-random) throughout
term and

ř
0, ignoring W

1, z

qs

`

.

x, xT
p

q

0, we have (2.50).
x˚, y˚
z˚ :
1. Hence, using z

qy ď
“

in (2.58). Then we have
z˚ in (2.58), dropping summation

q

“
1, deﬁne

ky˚k2 `

1 and an

1 “
δF
t , y

y1 and for all t
ě
yv
t k2
1
2 ky
2,

y `

´

R, x

0

u

ě

. Then in view of Lemma 2.6, in

yv
t u

t

auxiliary sequence

in the following way: yv

P

`p

R

“

1 :

yv
t
`

argmin
B2
y
R

where we recall that B2
x
q “ t
particular relation (2.48), for all y
1
τt x

1
τt´1 x
Rn : kxk2 ď
P
B2
we have
`p
q
P
yv
1, yv
1k2
1
2 ky
t
t
2 ´
`
`
Multiplying (2.60) by γtτt, taking a sum from t
“
T
1
γ0τ0
0 γt
2 ky
´
t
“

1, yv
t
`

δF
t
`

1 ´

y ď

y ď

`p

´

R

y

q

for all y

x

y

´

2 `

2k2

1
2τ 2
t

1k2
2.

δF
t
`

(2.60)

ř
1, z

yv
kδF
1
2 ky
t
t
`
`
0 to T
1 and noting (2.29b), we obtain
´
yv
1 k2
1k2
2,
(2.61)
1 ´
2 `
. Replacing i and t in (2.32) by t and T
1 and summing with (2.61), we obtain
ř
q
´
δG
yv
1, yt
t , xt
1
t
´
`
`
3γtθ2
T
1
t
´
t
1
2τt
“
kyk2
Lf DX
ř
r
2
and

T
1
0 γt
´
t
rx
“
yv
1 k2
t k2
B2

3γT ´1
2τT ´1 kqT
kδF
2
1k2
t
2
u `
q
s
`
, we have yt
1
s

H0
. Note that given ξ
t
s
r

y ´ x
x, x0
p
kyk2Hf

(2.62)
1, xt

,
s
1, yv
‰
t
`
`

´
γ0η0W

2 `
γt
2τt

´
kδG

˚ ` p
R

kδF
t
`

1ys
kqt

T
1
´
t
0
“

ξ
t
´
r

qT k2
2

δF
t
`

`
y0k2

qtk2

γt
2τt

q `

q `

ky
ř

`

´

`

´

´

s`

x

´

`

B

1

R

zt
p
ky

B2
P
`p
T
1
0 γtQ
´
t
“
γ0τ0
2 r
T
1
´
t
0
ηt
“
x, y
“
p

ř
P

ř
ď

´

2s `

2 `
2γt
L0
`
´
´
for all z
: x
q
and xt are constants. Hence we have
(
E
1ys “

BLf t
X, y
P

`p

P

q

E

rx

´

1, yt

δF
t
`

yv
t
`

yv
δF
1
t
t
1ys “
1s
`
`
`
y
x˚,
where second equality follows from (2.55). Choosing z
“
q
“
ψ
ky˚k2`
, taking expectation on both sides and noting (2.63),
p
q
r
(2.56), (2.57), ﬁrst relation in (2.53), we have
E
y
r

in (2.62) where

p
γ0η0W

T
1
0 γtQ
´
t
“

(2.63)
y :

ξrt´1s r
s

s
1
´
“ p

, yt
`
z :

zt
s
p
`

xT
p

xT
p

2s `

E
r

k2´

qs`

qs`

B2

ξrts,

`p

q r

0,

1,

rx

R

ψ

p

p

P

k

1

1

E
|

z

y

k

k

ř

qs ď

y0k2

yv
1 k2

γ0τ0
x˚, x0
s
2
p
T
1
ky˚k2 `
´
t
0
` p
“
T
1
D2
σ2
´
f `
t
1
p
“
Noting the convexity of Q in the ﬁrst argument, we obtain
˘
T
1
E
0 γtQ
´
t
r
“

2 `
´
E
kδG
t k2
r
p
T
1
´
t
0
“

´
2γt
L0
ηt
p
´
´
12γtθ2
t

12γT ´1
`
τT ´1

γt
τt `

τt `

zT ,
p

zt
p

E
r

˚s `

qs ď

`ř

H0

1
ΓT

BLf

ř

ř

1,

Q

`

`

qs

p

z

z

`

.

q
1

Hf
q
Xkσk2
.
2q

Lf DX

ky˚k2
r
2

1

B

`

´

s`

2

(2.64)

˘

(

(2.65)

`

Now observe that

s
ψ0

p
xT
p

ñ

q ` x

q ´

x˚, y˚
L
p
x˚
ψ0
p

p
q ě

0
0,

q ě

qy ´

ř
xT , y˚
L
p
xT
y˚, ψ
p
s
xT
p

ψ

r

x

xT
p

s
qy ď x

y˚,

s
qs`y ď

ky˚k2k

ψ
r

xT
p

qs`

k2,

which in view of the relation
y˚, ψ

implies that

ψ0

xT
s
p

q `

ky˚k2k

xT
ψ
s
p
r

k2 ´

ψ0

x˚
p

s
q ě

0.

qs`

(2.66)

z

Moreover,
s
Q
yT
xT ,
zT ,
L
q ě
p
p
along with (2.66) implies that
s
s

x˚,
L
p

q “

q ´

y

p

s

p

xT
p
The above relation, (2.65) and (2.64) together yield
E
γ0τ0
yv
1 k2
2
r

z
zT ,
p
s
p

k2s ď

xT
p

y0k2

E
r

ψ
r

ψ
r

p
y
k

q ě

1
ΓT

qs`

Q

k

k

k

y

xT ,
L
p

y

q ´

s
x˚, y˚
L
p

ψ0

xT
p

ky˚k2 `

q ` p

1

k
q

ψ
r

xT
p

k2 ´

ψ0

x˚
p

,
q

qs`

q “

k2.

s

qs`

s

s
2 `
E
r

s
2s `
H0

”

ř

´
2γt
p
L0
ηt
´
´
12γtθ2
t

T
1
´
t
0
“
T
1
´
t
1
“
yv
1 k2 ď
“

BLf

γ0η0W

´
kδG
t k2
p
γt
τt `

q
Hf
q
T
1
X kσk2
.
´
2q
t
0
“
2R2 in the above
ky0k2
yk2
ı
y
2R and k
2k
ř
2 ď
ky˚k2 `
1, we obtain (2.52). Hence we conclude the proof. Note

x˚, x0
p
ky˚k2 `
` p
D2
σ2
f `
p
2ky0k2
˘
2 `

12γT ´1
`
τT ´1

ky˚k2
r
2

y0k2

2 ď

˚s `

2 `

Lf DX

`

´

s`

1

˘

´

`

B

2

1

(

τt `

s

`

`
y
Noting the bound k
`ř
´
relation and recalling that R

p

p

16

p

 
 
 
that we still need to bound E
r
such a bound.

kδG

t k2
˚s

. Below, we provide a simple lemma which is used to show

0 be a nonnegative sequence, m1, m2

0 be constants such that a0

m1

ď

ě

at
Lemma 2.8. Let
t
and the following relation holds for all t
at

t
ě

u

Then we have at

m1

1
p

`

ď

m2

t.
q

1:
m1

ě
ď

m2

`

1
0ak.

t
´
k
“

ř

Proof. We prove this lemma by induction. Clearly, it is true for t
Then, using inductive hypothesis on ak for k

0, . . . , t, we have

0. Suppose it is true for at.

“

at

`

1

ď

m1

m1

`
1

m2

t
k

m2
ř

`

“
0at
“
t
k

ď

m2

k
q

1
0p
`
“
t`1
m2
q
´
m2

kδG

t k2
˚s

.

(2.67)

1
m2 p
ř
`
Hence, we conclude the proof. Now, under some assumptions, we show a bound on E
r

t
`
q

m1
‰

1
p

m1

m2

1
“

1.

“

`

`

ď

“

‰

1

Lemma 2.9. Assume that

γt, τt, ηt

t

u

satisfy

τt
1 and there exist constants R1 and R2 satisfying

q ă

ηt

´

´

p

96kσk
L0

2
2
BLf

1,

´

T

1

for all t

ď

R1

ě

´

96kσk
L0

2
2
BLf

´

´

τt

p

ηt

´

1

´

q

¯

1 and

´

R2
t

ď

´

1 and i

´

for all t

for all t

ď

ď

T

T

for all t
E
kδG
t k2
r

ď
˚s ď

kδG
t k2
T
1. In particular, if kσk2 “
´
2σ2
0.

E
r

˚s ď

γ0τ0
2 ky˚

´
Lf DX

y0k2

2 `
ky˚k2
r
2

´

k2
2

˚

γtτt
12 ky
2
B

s`

,

˘

(2.68)

2σ2

2
2

48kσk
γtτt

γ0η0W

!
2γi
BLf
L0
ηi
´
´
12γiθ2
i

1

τi `

0 `
t
i
“
t
i
“

0

ř

`ř

”
`

`

1

96kσk
L0

2
2
BLf

τt
ě
´
p
1. Then, we have

´

ηt

´

´

x˚, x0
p
H0

q `
Hf ky˚k2 `
`
D2
σ2
X kσk2
2q
f `
p
˘

2
2γi

96kσk
L0
ηi

p

´

BLf

´

,

q

γtτt

1

´

12γt
`
τt

)ı

q

¯
1
p

R1

R2

t,
q

`

0, then we can set R1

2σ2

0 and R2

“

“

(2.69)

(2.70)
0 implying

x˚, y˚
. Choosing
q
x˚ and (2.54) with

“ p
“

ky˚k2
r
2

:

0

1

`

`

´

`

´

“

yt

ř

BLf

H0

q `

q ě

Lf DX

“
“

m
i
“

2 ď

zt
p

1, z˚

γtτt
12

y0k2
2

0, . . . , T

0 for all t

δG
t,0 `

γ0η0W
EkδG

`ř
i
1yp
qt
`
E
r

x˚, x0
p
i k2

1k2
`
2γi
ηi
L0
´
´
12γiθ2
i

Proof. Observe that Q
z
y

γ0τ0
2 ky˚
´
Hf ky˚k2 `
`
Xkσk2
.
2q
for i

1 where z˚
z˚ in (2.32) and taking expectation on both sides, using (2.53) with x
y˚ and noting (2.57), we have
Eky˚
t
i
˚ ` p
“
t
12γt
“
σ2
D2
f `
i
τi `
τt
p
“
Now, let us deﬁne δG
xt
f 1ip
xt, ξt
Gi
˘
t,i
q ´
p
“
1δG
δG
t,i. Then, we have
t “
E
kδG
t k2
r
2E
r
2E
r
σ2
0 `
σ2
0 `
σ2
0 `
σ2
2
0 `
p
2σ2
0 `

i
1δG
t,ik2
1yp
qt
˚s
`
i
m
2E
1δG
t,ik2
1yp
k
qt
i
˚
`
“
i
m
2E
1δG
1kyp
t,ik
“
ř
qt
i
p
`
“
m
1k2
1kδG
t,ik2
“
ř
2
i
˚
“
m
E
1k2
2
i
1
`
|
“
m
1k2
1σ2
`ř
i s
2
i
`
“
Ekyt
1k2
ř
2q
`
ky˚k2
2 `
bk2

t,0 `
kδG
t,0k2
t,0k2
E

E
“
kyt
r
kσk2
2
4kσk2
2

(
Ekyt
1
`
kak

˘‰(
ξrt´1s r
s

y˚k2
2
kbk

˚s `
kyt

ř
˚s `

2
‰
˚q

˚s “
(i)

kδG

kδG

kδG

ξrt´1s,

m
i
“

ď
(iv)

ď
(iii)

`ř

kyt

E
“

ď
(ii)

ř

“

ď

“

ď

2

2

2

t,ik2
˚s

`

‰

q

.

˘‰(

ď

(2.72)
2kbk2
Here, relation (i) follows from the fact that ka
, relation
`
˚
(ii) follows from Cauchy-Schwarz inequality, relation (iii) follows from the fact that yt
1, condi-
tioned on random variables ξ
, is a constant and relation (iv) follows from fourth and
t
´
r
ﬁfth relation in (2.9) and the fact that xt is a constant when conditioned on random variables
ξ
t
´
r

´
˚ `

2kak2

ξ
t
´
r

ξ
t
´
r

2
˘
˚q

˚ ď p

˚ `

1
s

1
s

1
s

1
s

`

ď

s

`

.

,

,

s

17

B

s`

´

2
q

(2.71)
0, . . . , m. As a consequence, we have

‰

 
 
 
2 to both sides of (2.71), then multiplying the resulting relation by 48kσk
γtτt

2
2

and

Adding γtτt
12 ky˚k2
observing (2.72), we have
kδG
t k2

2σ2

E
r

2
2

48kσk
γtτt

γ0η0W

x˚, x0
p

γ0τ0
2 ky˚
Lf DX

y0k2

γtτt
12 ky˚k2

2

0 `
t
i
“
t
i
“

0

ηi

`

ř

´
2
i

H0

˚s ď

2γi
L0

´
12γiθ

!
BLf p

q `
Hf ky˚k2 `
`
X kσk2
D2
σ2
f `
2q
p
´
In view of (2.67), we have that the coeﬃcient of the δG
)
t term on the right hand side of the above
˘
`ř
relation is strictly less than 1. Moving the δG
t term to the left hand side and noting the conditions
imposed on constants R1, R2, we have
t k2

1
0
1. Using Lemma 2.8 for the above relation, we have (2.70). Hence we conclude

2
q
96kσk
L0
ηi

´
ky˚k2
r
2

i k2
˚s

τi `

i k2
˚

EkδG

12γt
τt

E
r

E
r

kδG

˚s ď

kδG

t
´
i
“

t
i
“

R1

R2

BLf

2
2γi

γtτt

ř

`

`

`

´

´

0

1

,

.

q

p

2 `
B
s`

ř

for all t
ď
the proof.

T

´

kδG

for all t

t k2
˚s

Remark 2.10. Note that the bound in (2.70) is still a function of stepsize parameters since
R1 and R2 need to satisfy relations (2.68) and (2.69), respectively. Now, we need to show that
there exists a possible selection of stepsize parameters for which we can compute a uniform upper
bound on E
1, in particular, we can obtain constants R1 and R2 satisfying
r
(2.68) and (2.69), respectively. Moreover, the selected stepsize policy is meaningful in the sense
that it yields convergence according (2.50) and (2.52). Below, we show that the stepsize policy
in (2.10) of Theorem 2.1 and in (2.19) of Theorem 2.3 is speciﬁed in a way such that (2.29),
(2.30), (2.31) and (2.67) are satisﬁed. Moreover, a uniform upper bound according to (2.70) for
all t
1 can be obtained and it also leads to the convergence according to (2.50) and (2.52).
In particular, we show the proofs of Theorem 2.1 and Theorem 2.3 below.

´

ď

ď

´

T

T

First, we focus on the setting in which (1.1) is strongly convex, i.e., α0

proof of Theorem 2.1.

0 and show the

ą

set according to (2.10) satisfy (2.29). It is easy

Proof of Theorem 2.1. Note that
to verify (2.29a) and (2.29b). To verify (2.29c), note that
γt

γt, θt, ηt, τt

α0,t

γt

u

t

1

1

1

1

1

ηt
p

´

´

`

´

q ě

´

´

ηt
p
t0

α0
α0

`
1

q
t
`
p
2

t0

q

`

`

“

`

t0

ηt

α0

q
`

t
“ p
Note that all relations in (2.30) and (2.31) are satisﬁed if 4
from the fact that
t
the deﬁnition of M. Indeed we have,
2
32M
t
`

is an increasing sequence,

L0
t0
t
M
´
´
q
p
`
2
1
12
1
q ě
q
where the last inequality follows from t0
2 by deﬁnition. Also note that
`
ě
t0
t
α0
`
p
2

2
2T
384kσk
α0
1
´
´
q
p
0. Then the above relation implies that

τt
for all t

t0
4
`
q
t
1
`

2t
t0
`
t
3
`
p

BLf

q ě

96
p

12α0

L0

ηt´2

BLf

t
`

t0
4

t0
4

kσk

2
2T

2
q

1
q

2
p

1
q

2
q

t0

τt

“

“

´

ď

ě

´

α0

α0

α0

2t

τt

˘

˘

t

u

u

´

`

´

´

`

p

q

p

p

p

2

ηt
p
ě

`

96kσk
L0

2
2
BLf

˘

1
2 ,

4 ď

ă

2

4M

3 ,

192kσk2
2

ě

α0
t
2 p
`
3M2

2
`
`
q “
τt
BLf
. This follows
p
q
is a deacreasing sequence, 3
1 and

t
1
qp
ηt´2

`
L0
´
12

γtηt.

´

θt

for all t
(2.69), respectively. Using the fact that τt

(2.73)
q ď
0. Finally, we need to show the existence of constants R1 and R2 satisfying (2.68) and
2
2T
384kσk
α0
1
q
2
q

, we observe

ě

ηt

τt

´

´

p

p

(2.74)

2
96kσk
2γi
L0
ηi

t
α0
`
p
384kσk2
t
2p
`
0. Noting (2.73), (2.74) and (2.69), we can set

q ď

BLf

γtτt

p
`

i
`
t0

´

´

`

p

p

1
q
t0

ě
2
384kσk
2
2i
α0

t
`
t0
`
4
q

2
q

T ď

`

1
T ,

for all i

0, t

ě

ě

R2 :

“

2
T .

Noting (2.68) along with deﬁnition of H
˚
(2.73),(2.57), and applying the following relations

in the theorem statement, setting y0

ηi

0

t
i
“
t
i
1
“
we have for all t

ř

´

γi
L0
´
γiθ2
i
τi `
T
´
ď
48kσk2
2

ř
2σ2

2

0 `
12σ2

”
`

!`
X,f B
2
q
`
p
σX,f T 3{2

t0

1{2

γtτt

ě

max

2
384kσk
2T
α0

, σX,f T 3{2

B

t0

1{2

2
q

`

p

4
p

t
1
qα0
`

,

BLf ď
γt
τt ď
1, RHS of (2.68) is at most

1{2
B
`
p
σX,f T 3{2

t
1
`
q
3 `

2
q

t
`

t0

p

p

3

,

(

1
q

2

p
2

t0

2
q

`

`

t
`

p

1

qp

9t0
6

10
q

`

t0

´ p

`

t0

1
12

2
`
2 `
1{2
˘
t0
B
2
q
`
p
σX,f T 3{2

´

“
ky˚k2

2
˚

8T H
α0

T
t0

`

T

1

`

α0
384kσk2

2T

2 `

T 3
3 `

α0
384kσk2

2T

T 2

t0
2

p

2
q

`

T

9t0
`
6

p

10
q

`

t0

´ p

1

`

`

18

1

,

q
‰

.

q
˘¯)ı

(2.75)
0, using

“

 
Here we used the bound

s

ηt
´
γtθ2
T
1
t
´
t
1
τt `
“
Noting the bound on W
x˚, x0
q
p
the bounds in (2.78), we have
(cid:13)
(cid:13)2 ď

E(cid:13)
(cid:13)
r

xT
p

2
2t0

qs`

ř

ψ

T

T

3
q

s

`

Then, noting 1

1 and ignoring

t0

term, we can set

2

2σ2

R1 :
Then using Lemma 2.9 and noting (2.75), we have for all t

t0
p

t0
p

0 `

˚ `

48

`

ˆ

`

“

kσk2
q

3

2

4

”

1

q

´p
2ky˚k2
2 `

`
H2

T ď
24

kδG

t k2

E
r

˚s ď #

2σ2
0
R1

T

1

´

2
T

1

`

R1e2

ď

Noting the above relation, (2.76) and the deﬁnition of ζ, we have
E
1.
r
“

`
kδG
t k2
T
0 and using (2.77), we have
αh

So according to (2.50) with y0

˘
ζ2,

˚s ď

´

ď

@

t0

t0

t

E
r

ψ0

xT
p

ψ0

x˚
p

q ´

t0
p

`

2

2
3
{
q

. (2.76)

ı

B2kσk2
q

3α0BσX,f
2 `
T
1
ď
´
if kσk2 “
otherwise.

σf

0;

“

.

(2.77)

T

q

2
q

`

T 1{2

W

x˚, x0
p
T
p
3

2
q

`

`

ζ2

8
p

H2
0

`
α0
T ´1{2
2

q `
t0

p

1
q

`

T

3
q

`

p

.

(‰

qs ď

T

`

T

p
`
12B

γt
L0

´

2
2t0

p

`

qp

3
q

“
2
`

1
2
`
2σX,f
1
t0
{
p
q
4
α0 for all t
1{2
B
2
q
`
p
σX,f T 3{2

ě
T 2

0,

BLf ď
γT ´1
τT ´1 ď
`
in the earlier relation, we obtain (2.11). Using (2.52), (2.77) and

(2.78)

T
`
2

` p

2
q

3
q

t0

T
3

1

t0

`

q

T

.

p

p

“

‰

3

t0
p
W

2
“
q
`

p
α0

`
t0

p

`

`
t0

1
qp
2

8T
α0

ζ2

H0

2

ky˚k2 `
`
qp
13B
x˚, x0
q `
p
ky˚k2 `
1

Hf
q

2

32M
α0

1

2 max
q
t0
p

2

2σX,f
1
{
`
q
ky˚k2
Lf DX
r
2

3{2

1{2 , 384kσk
α0

2
2T

, σX,f T
B
t0
2
q
`
p
T 1{2
T
p
3

2
q

`

1

2

`

B

´

s`

`
.
, using the fact that T 1{2

t0

1
q

`

p

T ´1{2
(
2

T

3
q

`

p

(
(2.79)

2
q

`

T
p
3

ď

.

u

`

`
x˚, x0
Noting the bound on W
“
p
2 order terms, we obtain (2.12). From (2.51), we have
2 and combining the T 3
T 3
{
{
E
2
1
r

` p
in (2.79), the deﬁnition of H
˚

1{2 , 384kσk
α0

xT , x˚
p

ky˚k
2
q
2

32M
α0

max

qs ď

W

(‰

2
2T

`

α0

t0

t0

t0

`

‰

q

2
2

T

T

p

2

, σX,f T 3{2
2
`
q
T 1{2

t0

B

p
t0

p

`

`

qp

`
t0

2
q

`

`
W

1
qp
2

ζ2

H0

`

`

α0

8T
α0

`

`

2
`
q
“
x˚, x0
p
ky˚k2Hf

q `

`

12B

t0
p
Lf DX

p
2σX,f
1
2
{
`
q
ky˚k2
2
B
r
2

s`

´

T
p
3

2
q

`

`

t0

1
(
q
`

p

T ´1{2
2

T

3
q

`

p

(

With similar replacements in the above relation as in (2.79), we obtain (2.13). Hence we conclude
(cid:4)
the proof.

(‰

“

‰

Now, we show proof of Theorem 2.3.

Proof of Theorem 2.3.
isfy (2.29) with α0
L0
τt
´
´
12

ηt´2

BLf

“

q

p

non-increasing sequence, θt
τt

It is easy to verify that

γt, θt, ηt, τt

set according to (2.19) sat-

0. Note that all relations in (2.30) and (2.31) are satisﬁed if M2

. This follows due to the fact that

is an non-decreasing sequence,

0 and the deﬁnition of M. Then we have

ď
is a

τt

t

u

t

ηt

t

u

ě
BLf
q

“
p

ηt´2

´

´

1 for all t
L0
12
24Bkσk2
DX
τt

ě
and τt
L0

6MB
DX

2MDX

B ˆ
8DX kσk2
B

1
12 “
, we have

M2.

Also, since

L0

BLf

ηt
p

´

´

ě
BLf
0. In view of the above relation, we have

ηt
p

q ě

´

´

q ě

192kσk2
2

for all t

ě

96kσk
L0

2
2
BLf

1
2 ,

p

´

τt

ηt

(2.80)
´
hence (2.67) is satisﬁed. We also need to show the existence of R1 and R2 satisfying (2.68) and
96T σX,f kσk2
(2.69), respectively. Using the fact that γt, ηt and τt are constants for all t
DX
and noting (2.80), we obtain
96kσk
L0
where in the last relation, we used the fact that σX,f
and (2.69), we can set

2 96kσk
DX kσk2. In view of the above relation

2 kσk2DX

T σX,f ď

q ď
ě

96kσk
L0
ηi

τ η ď

2
2
BLf

0, τ η

q ď

2
T ,

BLf

2
2γi

γtτt

ě

ě

´

ηt

1

τt

`

˘

´

´

´

´

´

2
2

1

p

q

p

Noting (2.68) along with the fact that H
using (2.80), (2.57), γtτt

?96T σX,f ,

τ

˚ ě

t
i
1
“
2σ2

γiθ2
i
τi `

γt
τt “
48kσk2
2

0 `

ř
2

“

t
1
`
τ ď
12 ky˚k2

7

ě

“
T
τ for all t
η
τ D2

2 `

X `

T

ď

´
?2T DX H

2
˚
48B2kσk2
2

?H2

˚`

σ2
0 `

R2 :

2
T .
Hf ky˚k2 `
BLf “

γi
L0

´

´

“
H0
t
i
“

`
0
ηi

Lf DX

ky˚k2
r
2

B

´

, setting y0

t
1
`
η ď

H2
?2
r

˚`

48B2kσk2
2s

s`
?T DX
σ2
0 `

(2.81)

0,

“
, and

1, we can see that the RHS of (2.68) is at most

ř

B

?96T σX,f `

12σ2

X,f

T
τ 2

(‰

19

 
 
 
 
 
 
 
 
2

2

ď

ď

2σ2

0 `

48kσk2
2

7

12 ky˚k2

2 `

η

τ D2

X `

DX BH˚
?48σX,f `

12T σ2

X,f

B2
96T σ2

X,f

“
2σ2

2σ2
“

2

0 `

0 `

12 ky˚k2

7

48kσk2
2
2ky˚k2
28kσk2

2 `

H
r

2
˚`

σ2
0

B

DX
2 `
σX,f
b
75B2kσk2
?48kσk2r
`
2 `

48B2
`
48

kσk

2
2

s

2BH

(‰

BH˚
?48

`
Bσ0

6 max
t
2 max
t

`
?48B2kσk2qs
˘
`

“

ď
˚ ` p
where in the last inequality, we used the fact that kσk2DX
1. Note that the last term in the
‰
σX,f ď
above sequence of relations is a constant satisfying the requirement in (2.68). Hence we can set
(2.82)

75B2kσk2

28kσk2

2BH

2σ2

2

.

R1 :

2ky˚k2

M,4kσk2

BDX

u

M,4kσk2u

B
DX `

B2
8

(‰

2 `

?48kσk2r

2 `

Then using Lemma 2.9 and noting (2.81), we have for all t

“

0 `

“

Bσ0
˚ ` p
T
1
ď
´
if kσk2 “
otherwise.

σf

?48B2kσk2qs

`

‰

0;

.

“

kδG

t k2

E
r

˚s ď #

2σ2
0
R1

T

1

´

2
T

1

`

R1e2

ď

t

@

ď

´

ψ0

˚s ď

E
r

˘
ζ2,

xT
p

Using the bound W

So according to (2.50) with y0

`
kδG
t k2
T
0 and using (2.83), we have

Noting the above relation, (2.82) and the deﬁnition of ζ, we have
E
1.
r
“
1
ψ0
x˚
T
q `
q ´
p
qs ď
D2
X , we obtain (2.20). From (2.52) and (2.83), we have for T
x˚, x0
‰
p
q ď
13σ2
s
(cid:13)
X,f T
1
xT
ψ
ky˚k2 `
(cid:13)2 ď
T
τ
qs`
p
r
p
D2
x˚, x0
Using bounds W
“
q ď
p
E(cid:13)
(cid:13)
r

W
`
q
X , we obtain (2.21). Using (2.21) and (2.22), we have

ε
3 “
Similarly, using (2.20) and (2.22), it is easy to observe that E
r
conclude the proof.

η
p
“
1

x˚, x0
p

x˚, x0
p

(cid:13)
(cid:13)2 ď

ε,
ψ0

η
` p

H2
0
`
η

ε
3 `

ε
3 `

x˚
p

xT
p

xT
p

2τ
q

12σ2

W
q

H
`
η

BLf

BLf

E(cid:13)
(cid:13)

qs ď

q `

q ´

qs`

2
˚q

L0

L0

ψ0

X,f

2
p

2
p

`

`

`

`

`

ζ2

ζ2

T
τ

ψ

s

3

T

T

.

q

‰

s

(2.83)

1

ě

.

ε. Hence we
(cid:4)

s

3 Proximal Point Methods for Nonconvex Functional Con-

strained Porblems

Our goal in this section is to extend the ConEx method to the nonconvex setting by leveraging
the framework of proximal point method. To achieve this goal, we ﬁrst need to understand
the convergence properties of the proximal point method for nonconvex functional constrained
optimization. We ﬁrst recall the assumptions mentioned brieﬂy in Section 1 for the nonconvex
case.

R are nonconvex and Lipschitz-smooth functions satisfying the lower curvature

1. fi : X

Ñ

condition in (1.3) with parameters µi

0

, i
q

“

pą

0, . . . , m.

2. χi : X

R, i

“

Ñ

0, . . . , m are convex and continuous functions.

P

ψ0

X be a global optimal solution and ψ˚0 “

Let x˚
According to the above assumptions and compactness of X, we have ψ˚0 ą ´8
It should be noted, however, that solving nonconvex problem (1.1) to the optimality condition
in Deﬁnition 2.1 is generally diﬃcult. Due to the hardness of the problem, we focus on the
necessary condition for guaranteeing local optimality. For this purpose, we need to properly
generalize the subdiﬀerential for the objective function ψ0 and constraints ψi because they are
be the subdiﬀerentials of χ0 and
possibly nonconvex and nonsmooth. Let
χi. We deﬁne

be the optimal value of problem (1.1).

χ0 and

x˚
p

χi, i

P r

m

B

B

q

s

.

∇fi
Note that
when ψi is a nonsmooth convex function.

“ t

ψi

B

u

x
p

ψi
B
when ψ is a “purely” diﬀerentiable nonconvex function and

0, . . . , m.

,
x
q
p

qu ` B

q ” t

∇fi

x
p

χi

“

i

ψi

B

χi

“ B

Using these objects, we can deﬁne a Karush-Kuhn-Tucker (KKT) condition for the nonsmooth

nonconvex problem (1.1) as follows.

Deﬁnition 3.1. We say that x˚
y˚

1
q, . . . , y˚p
y˚p

0 s.t.

m

T

q

“ r

s

ě

X is a critical KKT point of (1.1) if ψi

x˚
p

q ď

0 and

D

P

d

ψ0

x˚
p

B

q `

1y˚p

i
q

m
i
“

ψi

x˚
p

B

q `

`

ř

20

y˚p
NX

i
qψi
x˚
p

x˚
p
, 0
q

q “
“

0,
0.

˘

i

m

,

s

P r

(3.1)

 
 
The parameters
t
1
q, . . . , y˚p
y˚p
and

i
y˚p
q
ui
T interchangeably.
m

m

Pr

s

q

are called Lagrange multipliers. For brevity, we use the notation y˚

s

r
To ensure that the KKT condition is necessary to achieve optimality, we need a con-
straint qualiﬁcation (CQ). A well-known CQ for smooth nonlinear optimization is the classical
Mangasarian-Fromovitz constraint qualiﬁcation (MFCQ, see [32]). A slightly extended MFCQ
to deal with nonsmooth functions is deﬁned as follows.

Deﬁnition 3.2 (MFCQ). Let x
that x satisﬁes MFCQ if there exists a direction z

P

X be a point such that ψi

x
p

0 for all i

m

s

P r

. We say

x
where A
q
p
say that x satisﬁes MFCQ.

ă
x
denotes the indicator set of all active constraints. Moreover, if A
p

v

q

q “ H

(3.2)

then we

vT z

0,

max
x
ψi
p
PB

P ´

q ď
x
N ˚Xp
such that
q
,
x
i
A
q
p
P

The following result ensures that the KKT condition in (3.1) is a ﬁrst-order necessary opti-
mality condition for the composite nonconvex optimization. The proof of this result is given in
the appendix.

Proposition 3.1. Let x˚ be a local optimal solution of the problem (1.1). If x˚ satisﬁes MFCQ
(Deﬁnition 3.2), then there exists y˚p

such that (3.1) holds.

0, i

m

i
q

ě

P r

s

In order to describe the stationary condition at the limit points of the solutions generated
by the algorithm, we assume that MFCQ holds on an enlarged domain containing all the limit
points of the algorithm.

Assumption 3.2 (Strong MFCQ). All the points in the feasible set of problem (1.1) satisfy
MFCQ.

Deﬁnition 3.3. We say that a point x
i.e., ψ

0, and there exists y

P
0 such that

x
p

q ď

ě

X is an ε-KKT point for problem (1.1) if it is feasible,

ψi
Moreover, we call x a stochastic ε-KKT point if x is a feasible random vector, and y is a random
vector such that (3.3) is satisﬁed under expectation w.r.t. the random variables involved in the
process generating x.

ř
q `

x
p

x
p

1yp

q `

ψ0

ř

˘‰

ď

d

B

B

`

“

ǫ

m
i
“

i
q

(3.3)

i
qψi

m
1|yp
x
|
i
q
p
“
2
, 0
x
NX
q
p

ǫ,

ď

Deﬁnition 3.3 describes a type of points which approximately satisfy the KKT condition to a
speciﬁc accuracy. Particularly, a 0-KKT point satisﬁes the KKT condition (3.1) exactly and
hence is a KKT point. However, as will be shown in our convergence analysis, often it is more
convenient to describe convergence in terms of the following measure.

Deﬁnition 3.4. We say that a point
exists a ǫ-KKT point x (ψ

x
0) and

x
p

q ď

X is an

ǫ, δ
p

-KKT point for problem (1.1) if there
q

P

Moreover,

x is a stochastic

ǫ, δ
p

p

3.1 Basic proximal point method

p

p

kx

xk2

δ.

ď

´

E

kx

xk2
p
´

“

δ.

ď

‰

-KKT point if x is a stochastic ǫ-KKT point and
q

(3.4)

(3.5)

The main idea of the proximal point method (see Algorithm 2) is to transform the nonconvex
problem into a sequence of convex subproblems by adding strongly convex terms to the objective
and to the constraints. Speciﬁcally, each step of the proximal point algorithm involves a convex
subproblem (3.7) with convex constraints. It can be observed that, by adding a strongly convex
is µi-strongly convex relative
proximal term, ψ0
to W
. Hence, if each subproblem is feasible, it must have a unique globally optimal solution.
One way to ensure the well-deﬁnedness of each subproblem is always keeping the solutions
feasible. Nevertheless, feasibility is insuﬃcient to guarantee that the KKT condition holds

is µ0-strongly convex and ψi

x; xk
p

x; xk
p

xk
t
for the original problem. For illustration, we consider the following example:
min
2,2
s
Pr´

,
p¨

x2

¨q

u

´

´

q

q

x

1

1

(3.6)

s.t.

1

´

2
q

ď

0.

x
1
2 p

´
x

21

x, y
p

Consider Algorithm 2 applied to the above problem with input x0
0 and
2. Clearly, x0 is the only feasible solution and also the output of the algorithm.
W
q
However, the main issue in this setting is that the KKT condition fails at x0, since there does
not exist a Lagrange multiplier y

0 such that the stationarity condition

1
x
2 p

1, µ0

2, µ1

q “

“

“

ě

´

y

ě

1

y

x
p

1

0

holds at x
xk

“

q “
1. Due to this issue, it is desired to generate a sequence of strictly feasible solutions

´

´

`

u

, which motivates the following strict feasibility assumption on the initial point.

t
Assumption 3.3. x0 is a strictly feasible solution to the nonlinear functional constraints of
problem (1.1), namely, ψ

0.

x0
p

q ă

Algorithm 2 Exact Constrained Proximal Point Algorithm
Input: Input x0
1: for k
Set
2:

1, . . . , K do
ψi

2µiW

ψi

“

:

1

1

q
3: Obtain xk as the optimal solution of the following problem

q `

“

´

´

x, xk
p

,
q

x; xk
p

x
p

0, . . . , m.

i

“

min
X
x
P
s.t.

xk then return xk.

1

If xk
4:
´
5: end for
6: return xK

“

ψ0
ψi

x; xk
p
x; xk
p

1

´
1

´

q
q ď

0,

i

m

.

s

P r

(3.7)

Strict feasibility of the generated solutions, as well as some other properties of Algorithm 2

are established by the following theorem.

Theorem 3.4. Suppose that Assumption 3.3 holds. Then,

a) all the generated points x1, x2, ..., xk... are strictly feasible for problem (1.1), and

is a monotonically decreasing sequence;

ψ0

xk
p

t

qu

b) either there exists a

k such that x

x
k

1 and x

k is a KKT point of (1.1), or

a strictly decreasing sequence that has a limit point

, and we have

ψ0

xk
p

qu

t

is

p

´

k “
p

p

lim
Ñ`8

k

kxk

xk

´

ψ0

p

´

1k
“
r

ą ´8
0.

1

´

´
xk

q ă
.
1
q

xk
p
´
; xk
p¨

0, then xk
If xk

1 is strictly feasible for the k-th subproblem (3.7) with ψ0

Proof. Part a). We prove the property of strict feasibility by induction. First, the strict
feasibility of x0 is by Assumption 3.3. Next, assume that our claim holds for xk
1, namely
ψi
and
1
ψ
1, the claim holds by the induction assumption. Otherwise, by the
feasibility of xk for (3.7), we have ψi
xk
To show the monotonicity of
p
optimality of xk for solving subproblem (3.7) and the strong convexity of objective ψ0
we have for all feasible x that
ψ0
xk; xk
p
xk

xk
p
, we establish some suﬃcient descent property. Due to the
qu
,
q

x; xk
p
q ě
In above, taking x

xk; xk
p

0 for all i

x, xk
p

xk
p

µ0W

µ0W

´
; xk

; xk

q ě

q ă

q ď

q `

q `

.
q

ψ0

ψ0

P r

ψi

m

“

p¨

p¨

t

´

´

´

´

´

q

s

1

1

1

1

.

´

ψ0

q `

x, xk
p
1 and using the strong convexity of ω
ψ0

kxk
xk
p
is a decreasing sequence.

2
3µ0 r

xk, xk
2µ0W
1
p
´
x
we have
p
q
xk
p

xkk2

q ´

ψ0

ď

´

qs

´

´

1

1

,

which implies that

xk
ψ0
p
Part b). Since we already show that x
k

qu

t

ψ0

k is a KKT point.

1 is strictly feasible, if x

from Slater’s condition that x
that
limk
xk

1, then we conclude
1 for all k, then (3.8) implies
If xk
is strictly decreasing. Since this sequence is lower-bounded, we conclude that

xk
p
t
ψ0
Ñ`8
1k
0.
“
Strict feasibility established in Theorem 3.4 along with Slater’s condition guarantees that there
satisﬁes the KKT condition of subproblem (3.7)

ψ˚0 . Taking limit k

in (3.8) we have limk

p
ψ0 for some

such that

k “
p

qu
xk
p

Ñ 8

kxk

q “

Ñ`8

x
k

ψ0

xk

‰

ě

´

r

r

´

´

´

´

p

p

yk

“

´

(3.8)

exist Lagrange multipliers
for each k
1.

t

u

ě

xk, yk
p

q

Lemma 3.5. Let

ψ0

x; xk
p

1

´

xk, yk
p
ψ0
q ´

be a KKT point of the subproblem (3.7). Then
x, xk
p

x; xk
p

µT yk

yk, ψ

q ` x

qy ě

q
xk; xk
p

µ0

W

`

´

´

1

1

,
q

X.

x

P

(3.9)

`

˘

22

1

´

and z˚

xk, xk
p

Proof. Due to the KKT condition, there exist ψ10p
NX
xk
ψi
satisfying the condition
q
p
B
m
ψ10p
xk, xk
i
“
; xk

q `
According to the strong convexity of ψ0
ψ0

1yp
1

yk, ψ

ψ0

P

´

q

1

1

1

i

x; xk
p

´

q ` x

x; xk
p

´

qy ě

xk, xk

1

´

q P B

ψ0

xk, xk
p

1

´

, ψ1ip
q

xk, xk

1

´

q P

1

“

0.

z˚

´
1

qk ψ1ip
, ψi
q
ψ10p
q ` x
1
qy ` x
ψ10p
x, xk
p

xk, xk
q `
, and the fact that yk
; xk
q
p¨
´
, x
x, xk
xk; xk
xk
1
p
q
´
´
m
, x
qk ψ1ip
1yp
i
q
´
“
xk; xk
xk; xk
qk ψ1ip
ř
q `
,
q

y `
xk; xk
i
m
i
“

µ0W

1yp

´

´

´

1

1

i

ě
q
xk

1

´

ř
p¨
xk; xk
p
yk, ψ

´
xk; xk
p
xk; xk
p
µ0

1
´
µT yk

` x
ψ0

(3.10)
0, we have

µT yk

W
q

x, xk
p

q

y ` p
, x
1
q

xk

q ` x
W
q
where the last equality follows from the complementary slackness part of the KKT condition.
Moreover, appealing to the deﬁnition of normal cone and property (3.10), we have that

` p

ř

´

`

“

´

y

qk ψ1ip
iyp
´
Putting the above two inequalities together, we arrive at relation (3.9).

y “ ´x

xk; xk

xk; xk

ψ10p

, x
q

z˚, x

q `

xk

´

´

´

x

1

1

xk

y ě

0,

In view of Lemma 3.5 and Theorem 3.4, we develop a boundedness condition on the sequence
.

yk

i

ř

u

t
Proposition 3.6. Suppose that Assumption 3.3 holds. Then, for all k
1
qk , . . . , yp
yp
0, and

T such that yk

m
qk

r

s

ě

ψ0

xk; xk
p

1

i
yp
qk B

ψi

xk; xk
p

1

m

i
Pr

´

B

q `
and we have the following boundedness condition:
ř
xk
p
q
xk´1
p

xk´1
p
min1ďiďm

q´
t´

ψ0
ψi

q `

yk

ď

ψ0

´

}

}

1

s

,

k

qu

“

1, 2, 3, . . .

i
qk ψi
yp

xk; xk
p

NX

1

´
xk
p

0,

0.

q “

q Q

1, . . . , m,

i

“

1, there exists yk

ě

“

(3.11)

(3.12)

Proof. Strict feasibility of x0 along with Theorem 3.4.a) imply that the subproblem (3.7) in
Algorithm 2 satisﬁes Slater’s condition for all k
1, which ensures that the KKT condition
(3.11) holds at optimality. In particular, the ﬁrst relation in (3.11) is a direct application of the
KKT complementary slackness and the second relation is an application of the KKT stationarity.
xk
Similarly, applying Lemma 3.5 and setting x
“
´
1, xk

µT yk

ψ0

ψ0

ě

1

1

1

1 in (3.9) yield
xk, xk
p

2µ0W

xk
p

´

q ´

xk
p

q ě p

1yp

i
qk ψi

m
i
“

xk
p

´

q

´

q ´

`

µ0
W
q
i
kyp
qk k1 min
i
1
ď

ď

mt´

xk
p

´
ψi

q `
.
1

qu

xk
p

´

ě

ř

Thus relation (3.12) immediately follows.

k

k

ě

ě

u

t

qu

tp

xk

xk, yk

We have two comments about the above results. First, in order to show that the KKT
1 are well-deﬁned, we need to ensure that Algorithm 2 generates a path of
solutions
0. However, to achieve this goal, Algorithm 2 requires an oracle
strictly feasible solutions
that solves the convex subproblem (3.7) exactly. Since computation of the optimal solution can be
impractical for large-scale or stochastic optimization, it is desirable to develop inexact variants of
the proximal point method which can deal with approximate solutions for the subproblem (3.7).
Second, we note that the bound on the optimal dual solution
1, as provided in Proposition 3.6,
depends on the algorithm. For some special cases, the bound is uniform for the whole sequence.
xk
For example, if the algorithm generates xk
1, then the stationary point
is interior to the inequality constraints and we have yk
0. However, (3.12) does not rule out
the possibility that kykk1 tends to inﬁnity when xk converges to boundary points. Therefore,
it is diﬃcult to claim that the KKT conditions of problem (1.1) will be satisﬁed at the limit
points of
. Due to the above two concerns, we turn our attention to inexact proximal point
methods which can deal with approximate solutions for the subproblem (3.7). In particular, we
will discuss additional constraint qualiﬁcations to ensure that the optimal dual solutions have a
uniform bound, and thus to allow us to establish the convergence of the inexact proximal point
method to the KKT solutions.

1 for some k

xk

yk

“

ą

“

u

t

´

}

}

3.2

Inexact proximal point method under MFCQ

In Algorithm 3, we present an inexact extension of the proximal point method, which generalizes
Algorithm 2 by allowing the subproblems to be solved approximately. To distinguish exact
solutions from approximate ones, we denote the exact solution as x˚k and the corresponding dual
solution as y˚k hereafter. Since each subproblem (3.7) is solved inexactly, the sequence generated
by Algorithm 3 can become infeasible with respect to the original problem. If xk
1 is infeasible

´

23

with respect to (1.1), then we can not guarantee feasibility of the subproblem (3.7) in general.
This also implies obtaining bounds on Lagrange multipliers is more challenging for inexact case.
However, we show that if the successive problems are solved accurately enough then both the
strict feasibility of the iterates and the boundedness of

can be ensured.

y˚k u

t

Algorithm 3 Inexact Constrained Proximal Point Algorithm
1: Input x0 is strictly feasible.
2: for k
“
xk
3:
Ð
4: end for
5:
“
6: return x

1, . . . , K do
an approximate solution of subproblem (3.7).

xk
p

xk
p

K ψ0

argmin1
k.

q ´

ψ0

.
q

k

ď

ď

´

k

1

p

p

Throughout the rest of this subsection, we assume that ψi

with constant Mi, i
if the subproblem (3.7) is solved accurately enough.

“

q
0, . . . , m. Proposition 3.7 shows that the sequence

´

x; xk
p

1

is Lipschitz continuous
is strictly feasible

xk

t

u

Proposition 3.7. In Algorithm 3, suppose that Assumption 3.3 holds and that the subproblem
(3.7), if solvable, is returned an approximate solution xk satisfying
x˚k }

x˚k } ` }
´
1) is the optimal solution, then the sequence

x˚k } ď

Mi
µi }

1
2 }

(3.13)

P r

, i

xk

xk

xk

xk

m

´

´

s

1

,

generated
0, 1, 2, 3, . . .. Moreover, there exists

t

u

´
b
where x˚k (which depends on xk
by Algorithm 3 is strictly feasible, i.e. ψ
subproblem solutions

x˚k , y˚k q
p
If we further assume that

´

xk
p

q ă

0, k

“

satisfying the KKT condition for (3.7).
xk
u
t
2M0
xk
µ0 }

x˚k } ` }
is monotonically decreasing and converges to a limit point

x˚k } ď }

satisﬁes:

x˚k }

xk

xk

b

´

´

´

´

1

,

ψ0, and

then

ψ0

xk
p

qu

t

(3.14)

(3.15)

lim
k
Ñ8

W

xk, xk
p

1

´

q “

lim
k
Ñ8

W

xk
p

1, x˚k q “

´

0.

r

Proof. Note that the strict feasibility of xk
We want to show that the strict feasibility of xk
feasibility of xk. Therefore, using ψ
sequence by induction.
Suppose that xk

x0
p

q ă

we have

´

1 is strictly feasible. From the deﬁnition of ψi

´

1 trivially implies that subproblem (3.7) is solvable.
1, along with condition (3.13), implies the strict
0, it is easy to prove the strict feasibility of the whole

´

x; xk
p

´

1

and feasibility of x˚k ,

q
x˚k } ď
´
. Using the triangle
q

x˚k }

Mi

xk

´

}

1

,

xk

x˚k }q

´

1

0. If xk

1,
1 is strictly feasible. Using the
. Moreover, the

q ď

xk

‰

xk

´

´

t

u

ψi

xk
p

2µiW

ψi
}
where the ﬁrst inequality follows from the Lipschitz continuity of ψi
inequality and (3.13), we have

x˚k ; xk
p

xk, xk
p

xk; xk
p

q ď

q “

q `

q `

Mi

ψi

´

´

´

1

1

1

xk

´
x; xk
p

1

}

´

a

xk

xk

q ě

?µi

2µiW

xk, xk
p

p}
Mi
b
xk
. Combining the above two results, we have ψi
p
0. Otherwise, xk

for i
then we have strict feasibility: ψi
induction we complete the proof of strict feasibility of the whole sequence
existence of

x˚k } ´ }
´
´
xk
,
x˚k }
´
3
xk, xk
2 µiW
p
xk

q`
“

xk
p

?µi

q ă

} ě

P r

xk

m

´

ě

2

´

´

}

s

1

1

x˚k , y˚k q
p
Applying Lemma 3.5 with x

immediately follows from Slater’s condition and the KKT condition.

xk

´

“

1 and replacing the saddle point

xk, yk
p

q

therein by

x˚k , y˚k q
,
p

we deduce
xk
ψ0
p

1

´

q “

1; xk

1

q

´

ψ0
ψ0
ψ0
ψ0

xk
p
´
x˚k ; xk
p
xk; xk
p
xk
p

1

´

ě

q ´ x

µT y˚k q
y˚k , ψ
µ0
xk
W
xk
`
p
p
´
µT y˚k q
.
1, x˚k q
xk
W
xk
M0
p
}
µT y˚k q
W
µ0
x˚k } ` p
xk, xk
´
p
where the second inequality follows from the Lipschitz continuity of ψ0
y˚k , ψ
property
x
´
beforehand, we have

1; xk
x˚k } ` p
M0
}
q ´

1
qy ` p
µ0
xk

1
q ´
´
2µ0W

y˚k , ψ

qy “ x

xk
p

xk
p

1; xk

qy ď

´
1

q `

`

`

ě

“

p¨

´

´

´

´

´

´

1

1

(3.16)
and the basic
0. Moreover, using (3.14) and similar argument

.
1, x˚k q
q

xk
p
; xk

´
1

´

1, x˚k q

2µ0W

xk, xk
p

1

´

q ě

a

2M0

b

xk

}

.

x˚k }

´

24

Putting this result in (3.16), we have
xk, xk
p
xk
p

ψ0
We immediately observe that ψ0
convergence limk ψ0
we have

´
q
ψ0 for some

xk
p

xk
p

µ0W

q “

q `

µ0

µT y˚k q
1, x˚k q ď
W
(3.17)
1
q ` p
is decreasing. Since ψ0 is bounded below, we have the
1, 2, ...,
. Summing up the above relation for k
ψ0

xk
p

xk
p

.
q

ψ0

`

´

´

1

ą ´8

“

8

µ0W

r

r
xk, xk
p

1

´

µ0

q ` p

r
`

µT y˚k q
W

xk
p

1, x˚k qs ď

´

ψ0

x0
p

q ´

ψ0

.

ă `8

(3.18)

k
1
ÿ
“

Therefore, the convergence results in (3.15) immediately follow.

r

Remark 3.8. It should be noted that the inexactness criteria include the subproblem optimality
criteria for the exact proximal point method (Algorithm 2) as a special case. Speciﬁcally, if we
set xk
x˚k , then (3.13) and (3.14) hold trivially. Hence all our convergence analysis applies to
the exact proximal point discussed in subsection 3.1.

“

The following theorem establishes the asymptotic convergence of the proposed inexact prox-

imal point method under some mild constraint qualiﬁcation.

Theorem 3.9. Suppose that all the assumptions in Proposition 3.7 hold, x˚ is a limit point of
is a subsequence converging to x˚, then the
the solution sequence and it satisﬁes MFCQ. If
dual sequence
satisﬁes
the KKT condition (3.1).

is bounded. Moreover, if y˚ is a limit point of

x˚, y˚
p

xjk u

y˚jk u

y˚jk u

,then

t

t

t

q

Proof. First, we establish the convergence of
xjk “
assumption limk
3.7 and the triangle inequality, we have

Ñ8

x˚ and Proposition 3.7 that limk

x˚jk u

t

to x˚.

Ñ8

It immediately follows from the
x˚. Applying Proposition
xjk

1

´

“

which implies that

lim
k
Ñ8

x˚jk ´

}

x˚

} ď

lim
k
Ñ8

x˚jk ´

xjk

1

´

} ` }

xjk

1

´

´

x˚

}

“

0,

}
“
lim
k
Ñ8

x˚jk “

x˚.

‰

(3.19)

We prove the boundedness of the dual subsequence by contradiction. Suppose that

unbounded. Passing to any subsequence if necessary, we have limk
KKT condition, we have

Ñ8

ψ0

ψ0

T ψ

T ψ

y˚jk q

x˚jk q ` p
p

y˚jk q
x˚jk q ď
p
X. Let vjk “

x
q ` p
p
`
for any x
ky˚jkk1, then kvjk k1 “
subsequence. Without loss of generality, we assume limk
of (3.20) by ky˚jk k1 and take k
v˚
p

. In view of (3.19) and limk
x˚jk q ď p
p

µT y˚jk qr
1, hence
t
vjk “

x
p
y˚jk {

Ñ 8
T ψ
q

µT v˚
p

Ñ8
W
q

T ψ
q

T ψ
q

µ0
p

q `

v˚

Ñ8

W

P

2

2

is
t
. In view of the

y˚jk u

1

ky˚jk k1 “ 8
W
x, xjk
1
qs
p
´
(3.20)
vjk u
must have a convergent
v˚. Let us divide both sides
1

x˚jk , xjk
p

0, we have

q ´

´

,

1

{}
x, x˚
p

y˚jk }
,
q

“
x

v˚
p

x˚
p

x
p
which means that x˚ is optimal for minimizing the right side of (3.21). Therefore, the ﬁrst-order
condition implies that

lim
k
Ñ8

(3.21)

q “

q `

X,

@

P

d

ψi

v˚p
q
be the set of active constraints at x˚. By this deﬁnition, for any i
x˚jk ´

, we have
q
2 converges to 0, there exists k0 such that for
0. Hence, according to the KKT complementary slackness

q
0. Since ψi is continuous and

x˚
A
p

(3.22)

x˚
p

x˚
p

, 0
q

NX

xjk

`ř

1B

0.

`

“

k0, we have ψi

R

˘

´

}

}

1

i
q

m
i
“

x˚
Let A
p
x˚
ψi
q ă
p
all k
ą

1
condition for the subproblem, y˚p
i

q ă
´
i
q
jk “

x˚jk ; xjk
p

x˚
A
p

. So we can rewrite the equation (3.22) as
q

R

0 for k

ą

k0. Taking k

we obtain v˚p

i
q

0 for any

“

Ñ 8

d
x˚
i
A
qB
P
p
´ř
and u
m
Let ψ1ip
P r
z be the direction vector deﬁned in MFCQ (3.2). Then,

v˚p
q
x˚
p

x˚
p
NX

x˚
p
¯
be such that u

x˚
p

, 0
q

q P B

for i

NX

x˚

ψi

ψi

`

q

q

s

i
q

0.

“

x˚

A
p

q

x˚

ψ1ip

i
q

v˚p
q

“

0. Let

i
P

0

zT u

i

v˚p

i
P

A
p

x˚

v˚p

i
P

A
p

x˚

q

`

“

ř

q ď

q
v˚p
ř
ψi
ă
ď
p
q
q
implies zT u
x˚
where the ﬁrst inequality follows since z
N ˚X p
and u
0, the
ř
ď
q
p
P
q
i
x˚
ψi
x˚
0 and ψ1ip
second inequality follows due to the fact that v˚p
and the last strict
q
p
q P B
x˚
0 for at least one i
inequality follows from MFCQ and v˚p
. Hence we obtain a
A
p
q
P
y˚jk u
y˚jk u
contradiction and conclude that
is bounded, it must
is a bounded sequence. Since
t
have a limit point y˚. Passing to any subsequence if necessary, we have limk

i
A
P
p
x˚

zT v

P ´

y˚.

0,

ą

ě

i
q

x˚

x˚

t

q

q

y˚jk “

Ñ8

i

`
ř
qzT ψ1ip
x˚
i
q maxv
PB
NX

P
qzT ψ1ip

x˚

25

To prove that

q
plementary slackness. Applying Lemma 3.5 with x
have

satisﬁes the KKT condition, we ﬁrst show that
1 and replacing

xk

x˚, y˚
p

“

´

ψ0

xk
p

1

´

q ´

ψ0

x˚k q ě
p

2µ0W

x˚k , xk
p

1

´

µ0

q ` p

µT y˚k q

W

xk
p

´

`

x˚, y˚
p
xk, yk
p

q
.
1, x˚k q

q
by

satisﬁes com-
x˚k , y˚k q
, we
p

(3.23)

Moreover, the KKT condition for the subproblem (3.7) and the assumption (1.5) imply that

x˚k , xk
p
Combining (3.23) and (3.24) and taking the limit k

x˚k q “
p

µT y˚k q
W
p

1y˚p

´

2

i
qk ψi

m
i
“

µT y˚k q
2Lω
p
, we have

1

q ď
´
Ñ 8

W

xk
p

.
1, x˚k q

´

(3.24)

ř
0

ď ´

i
qk ψi

1y˚p

m
i
“
ψ0

2Lω
ř

2Lω

2Lω

´

“
ψ0

xk
p
xk
p
“
M0

´
xk

x˚k q
p
ψ0

1

q ´
1, xk

}

1

´

´

lim
k
Ñ8
lim
k
Ñ8
lim
k
Ñ8
lim
k
Ñ8
0,

“

ď

ď

ď

“

x˚k q
p
‰
ψ0

1

´

q ´
x˚k } `

1

x˚k , xk
p
2µ0W

´
x˚k , xk
p

2µ0W

x˚k , xk
p

1

´

q `

q
‰

1

´

q
‰

where the last equality is implied by Proposition 3.7 and (1.5). Hence we have

Passing to the subsequence

that converges to

i
y˚p
qk ψi
lim
k
Ñ8
xjk , y˚jk q
p
i
x˚
qψi
y˚p
p

x˚k q “
p

0,

0,

q “

Next, we check the stationarity condition. Since

in (3.20) yields
ψ0

x
p
q ` p
implying that x˚ minimizes the function ψ0
In other words, we have

x˚
p

x˚
p

q ď

ψ0

y˚

T ψ
q

q ` p
x
p

0
q `
In view of (3.26) and (3.28), we complete the proof.

q ` B

x˚
p

x˚
p

NX

ψ0

P

i

1, 2, ..., m.

“
x˚, y˚
p
1, 2, ..., m.

, we conclude from (3.25) that
q

i
“
xjk , y˚jk q
p
T ψ
x
2
p
q
T ψ
y˚
q
q ` p

q `
x
p

y˚

converges to

x˚, y˚
p

, taking k
q

Ñ 8

µ0
p
2
q `

`
µ0
p

µT y˚

W
q
µT y˚

`

x, x˚
p
W
q

,
q
x, x˚
p

q

over x

(3.27)
X.

P

(3.25)

(3.26)

1y˚p

i
q

m
i
“

ψi

x˚
p

.
q

B

(3.28)

The following theorem shows the asymptotic convergence and the rate of convergence to
. An ingredient vital to the latter result is the uniform

stationarity of all the limit points of
boundedness of the dual variables under Strong MFCQ.

t

u

xk

ř

Theorem 3.10. Suppose that all the assumptions in Proposition 3.7 and Assumption 3.2 hold.
Then,

a) all the limit points of the sequence

xk

t

u

are critical KKT points;

b) the whole sequence
y˚k }

t
B, for k

that

ď

}

y˚k u
“

1

is uniformly bounded, namely, there exists some constant B
1, 2, 3, ..;

0

ą

c) after K iterations, the solution sequence contains an

εK

εK

max

“

2Lω, 8L2
ωp

µ0

ψ0

min

ψ˚0

x0
q ´
p
M 2K 2

µ

}8

` }
1
2µ0K

,

q
(
ψ0

x0
p

q ´

ψ˚0

.

εK,
p
B

εK

-KKT point with
q
x0
ψ0
p
s

q ´
K

ψ˚0

,

(3.29)

(3.30)

where
i.e., it is reduced to Algorithm 2, then the solution sequence contains an εK-KKT point.

) “
Mi. Moreover, if Algorithm 3 generates exact solutions xk

max0

m
i
s
ď

M

“

“

!

ď

‰

Ă

x˚k ,

“
µ0
µi

Ă

Proof. Part a): A natural consequence of Assumption 3.2 is that every limit point of
satisﬁes MFCQ (Deﬁnition 3.2). Then, applying Theorem 3.9, we immediately get part a).
y˚k u
jk
t
u
y˚jk } “ 8
}

Part b): We show the boundedness of
t
unbounded, then there exists a subsequence
lim
k
Ñ8

such that
,

by contradiction. Suppose that the sequence is

is bounded, there exists a limit point x˚ and a subsequence
xjk u
Since X is compact and
t
x˚. Due to Assumption 3.2, we obtain that x˚ satisﬁes MFCQ.
xik “
xjk u
xik u Ď t
t
Ñ8
However, according to Theorem 3.9, when x˚ satisﬁes MFCQ,
y˚ik }
1 must be bounded, thereby
leading to a contradiction to (3.31). This completes the proof of the existence of a constant
B

that limk

0 such that

(3.31)

xk

t

u

}

ą

y˚k }

}

1

ď

B

1, 2, ...

k

“

26

 
Part c): Next we establish the rate of convergence to KKT condition. Due to the optimality

of x˚k in subproblem (3.7), we have
d

1

`

B

B

B

d

Q

`

ř

, 0

ψ0

m
i
“

B
ψi

x˚k q
p

m
i
“
and

q `
m
s
∇ω

`
i
1y˚p
qk

q `
1
ř
q
´
µ0
2
p

x˚k ; xk
1
p
´
ψ0
; xk
Plugging the deﬁnition of
p
x˚k q `
ψ0
x˚k q `
p
p
It follows that

i
1y˚p
x˚k ; xk
ψi
qk
B
p
´
ψi
, i
; xk
1
q
B
p
P r
´
µT y˚k qp
x˚k q ´
∇ω
p
i
m
1y˚p
x˚k q `
ψi
qk
i
p
B
“
µT y˚k q
2k∇ω
x˚k q ´
ř
`
p
µT y˚k q
2W
µ0
xk
`
p
´
ψ0
B
µ
µ0
xk
}8
qr
p
where the second inequality uses the smoothness and strong convexity of ω
µT y˚k ď
inequality follows from (3.17) and µ0
slackness and (3.17) we have

x˚k q `
p
∇ω
xk
p
1, x˚k q
q ´

ψ0
pB
µ0
4
p
8L2
ωp
8L2
ωp

x˚k q
p
k2
q

˘
NX

xk
p

xk
p

qq `

NX

` }

2
q

` }

ψ0

}8

µ0

, 0

ď

ď

ď

µ

d

´

´

1

1

1

,

NX
0.
, into the above inequality yields
x˚k q
p

, 0

“

0. (3.32)

´

˘

qs

(3.33)
x
, and the last
q
p
B. In addition, by complementary

1|y˚p

i
qk ψi

m
i
“

x˚k q
|
p

“

ř

1
´
Furthermore, by the distance contraction property (3.13), (3.14) and relation (3.17), we have
x˚k }

x˚k }

1
4 }

xk
p

xk
p

q ´

q ´

ψ0

ψ0

xk

xk

´

ď

´

ď

qs

qs

´

´

}

2

2

1

1

,

(3.35)

(3.34)

x˚k , xk
p

2Lω
.

1
´
ψ0

q ď
xk
p

µT y˚k q
W
p

xk
p

1, x˚k q

´

and

`
µT y˚k q
W
2
p
xk
ψ0
2Lω
p
r

xk

}

x˚k } ď

´

min

ď

1
2µ0 r
µi
4Mi
µi
2µ0Mi

}
)

)

µ0
2M0
1
M0

, min
m
i
1
ď
ď
, min
m
i
1
ď
ď

!

xk
p

´

1

´

q ´

ψ0

.

xk
qs
p
, we have
q

1

q ´
ψ0

xk
p
K

min

ď

!
ψ0

1
M r
xk
p
Ă

ď
K ψ0

xk

1

´

´

2

x˚k }

ψ0

xk
p

1

´

r

q ´

ψ0

xk
p

qs

(3.36)

(3.37)

Noting that

k

argmin1

ď

k

ď

“

min
p
k
1
ď
ď

ψ0

xk
p

1

ψ0

xk
p

´

Kr

q ´

qs ď

1r
k
ÿ
“
Let xˆk be the desired approximate KKT point. Combining (3.33), (3.34) and (3.37) we obtain
(3.29), and combining (3.35), (3.36) and (3.37) gives (3.30). Finally, noting that an
-KKT
q
point is an ǫ-KKT point when δ
0, we immediately see that the exact proximal point method
generates an εK-KKT solution.

ǫ, δ
p

qs ď

q ´

“

´

ψ0

xk
p

1

ψ0

xk
p

ψ0

x0
p

q ´
K

ψ˚0

.

1
K

Remark 3.11. We leave several comments about the above convergence results. First, imposing
MFCQ type assumption is quite common in the traditional nonlinear optimization for justifying
the search of KKT solutions (see [6]). By means of MFCQ, we not only ensure asymptotic conver-
gence to the KKT solution but also obtain a non-asymptotic convergence rate result. To the best
of our knowledge, this appears to be the ﬁrst complexity result and eﬃciency analysis of proximal
point method under the MFCQ type assumption Second, while Assumption 3.2 requires MFCQ
on the whole feasible domain, we only need every limit point of
to satisfy MFCQ throughout
the proof. Strong MFCQ is an algorithm independent suﬃcient condition to achieve MFCQ on
every limit point. Third, it should be noted that while Algorithm 3 generates approximate KKT
points that are strictly feasible, feasibility is actually not essential for the underlying optimality
measure in Deﬁnition 3.1. The next subsection will describe inexact proximal point method with
possibly infeasible solution sequence. (Also see Remark 3.14).

xk

t

u

Remark 3.12. All the results in this section can be easily extended to the case when ψi, i
are convex functions.
subproblem (3.7) of Algorithm 2 becomes

In that case, we can replace µi

m
s
. As a result, the

0 for all i

P r

P r

m

“

s

min
X
x
P
s.t.

ψ0
ψi

x; xk
p
x
p

1
´
0,

q

i

m

.

(3.38)

q ď
Hence, constraints are ﬁxed for all iterations. This implies that we do not need (3.13) for ensuring
the strict feasibility of iterates for every subproblem (3.38). It is given for free provided that there
exists some (possibly unknown) strictly feasible solution for problem (3.38). However, we still
need (3.14) for ensuring the convergence result in (3.15). After this modiﬁcation in Proposition
3.7, it would be easy to obtain results similar to those in Theorem 3.9 and Theorem 3.10.

P r

s

27

Remark 3.13. It is interesting to compare the complexity of proximal point iterations in The-
[25]).
orem 3.10 with that of proximal point for unconstrained nonconvex optimization (e.g.
A quantitative diﬀerence is that for functional constrained problem the complexity bound has
an unknown parameter B which could possibly depend on the solution path, while for uncon-
strained problem, the parameters in the complexity bound usually globally depend on the initial
solution, optimality gap or distance to the optimal solutions, and hence are easier to estimate.
This distinction appears to indicate some substantial diﬃculty in developing complexity analysis
for nonconvex optimization with nonconvex constraints.

Remark 3.14. The inexactness criteria (3.13) and (3.14) describe convergence to the optimal
solution for each convex subproblem. These criteria can be satisﬁed eventually if we employ
ConEx for the subproblems, thanks to the last iterate convergence (2.13). However, it is still
diﬃcult to estimate the total complexity, since ConEx does not guarantee convergence purely
in terms of initial distance to the optimal solution. This diﬃculty holds for deterministic as
well as stochastic cases. Due to these issues, it is desirable to exploit more practical scenarios
where proximal point methods can be combined with ﬁrst order methods (such as ConEx) for
large-scale and stochastic optimization.

3.3

Inexact proximal point under the strong feasibility assumption

In this section, we present a variant of the inexact proximal point in which the subproblem
is approximately solved by ConEx (see Algorithm 4). To understand our motivation, consider
the case when the objective function is given in the form of f
x, ξ
q
p
is a stochastic function on some random variable ξ and is possibly nonconvex with respect to
the parameter x. Consequently, the objective function in the subproblem (3.7) is given by
Eξ
xk2. As discussed in the previous section, stochastic optimization algorithms
(such as ConEx) for solving this type of problem will exhibit a sublinear rate of convergence in
expectation, which does not ﬁt the inexactness criterion raised in Proposition 3.7. To alleviate
this issue, we propose a new assumption as follows.

, where F

x, ξ
p

x, ξ
p

µ0kx

F
r

x
p

qs `

q “

Eξ

´

qs

F

s

r

Assumption 3.15 (Strong feasibility). There exists
i

2µiD2
X,

ψi

x
p

q ď ´

where DX is deﬁned in (1.6).

x

X such that

P
1, . . . , m,
“
s

(3.39)

The following proposition states that the KKT condition in (3.1) is a ﬁrst-order necessary
optimality condition when Assumption 3.15 holds. This result is similar to Proposition 3.1 where
MFCQ is replaced by strong feasibility. We defer the proof of this result to the appendix.

s

Proposition 3.16. Let x˚ be a local optimal solution of the problem (1.1). If Assumption 3.15
is satisﬁed then there exists y˚p

such that (3.1) holds.

0, i

m

i
q

ě

P r

s

1, . . . , K do
a (stochastic) approximate solution of subproblem (3.7) by ConEx.

Algorithm 4 Inexact Constrained Proximal Point Algorithm with ConEx
1: Input x0
2: for k
“
xk
3:
Ð
4: end for
5: Choose
6: return x
p

k uniformly at random from

1, 2, ..., K

k.

u

t

.

p

Note that (3.39) is a local and a veriﬁable condition. Moreover, we will show in Lemma 3.17
that it provides a computable uniform bound B on the dual solutions. While it appears that
(3.39) is quite distinct from MFCQ (Deﬁnition 3.2), we would like to point out certain similarities
between these two conditions. To understand this connection better, let us assume that ψi is
X, we have
smooth function. Then, for all x
P
ψi
x
ψi
p
ψi
x
s

x
,
x
´
q
p
µi
x
2 k
s

∇ψi
q ` x
x
ψi
p

y ´
xk2,

, x
x
q
p

x
p
x
p

µi
2 k

∇ψi

xk2

ñ x

y ě

q ě

q ´

q ´

´

´

´

x

x

which implies that

s
2 µiD2

3

X u

.

(3.40)

∇ψi

, x
x
q
p

x
s
y ě

´

0,

x

X

x

@

s
P

X t

ψi
s

ě ´

s

28

(3.42)

(3.43)

(3.44)

Recall that the existence of a Minty solution,
∇ψi, is the following condition

x, for variational inequality problem on mapping

x

x

0,

∇ψi

, x
x
q
p

(3.41)
s
y ě
which is stronger than (3.40). Hence ψ satisfying (3.39) is not necessarily quasi-convex. However,
x, gives an ‘almost’ suﬃcient condition for ensuring (3.2) in the
existence of Minty solution,
x˚ satisﬁes (3.2) with strict
following way. Set x
inequality replaced by nonstrict inequality. Since there is no implication from (3.40) to (3.41) (in
fact, the implication is in the opposite direction), so a direct comparison for the weaker among
the two conditions (3.39) and (3.2), can not be made as such.

x˚ in (3.41). Then we obtain that z

X,

´

“

´

“

x

x

@

s

s

s

P

Now, we state an important lemma which allows us to obtain dual boundedness under the

strong feasibility assumption.

Lemma 3.17. Let ψi
x
ψi
p
proximal center. Then under Assumption 3.15, the convex problem:

x, ˆx
p

x; ˆx
p

, 0
q

2µiW

:
“

q `

ď

ď

q

i

m, where ˆx

X is an arbitrary

P

min
x
X
P
s.t.

ψi

ψ0

q

x; ˆx
p
x; ˆx
p
x`, y`
p

q ď
q

is always feasible, there exists a solution
y` is uniformly bounded by:

where µmin

min1

ď

m µi.

i
ď

“

y`

}

1

}

ď

B :

“

ψ0

x

p

s

µ0D

2
X

ψ˚
0 `
q´
µminD2
X

,

0,
satisfying the KKT-condition, and the variable

P r

m

i

s

.

x, ˆx
p

s

X `
x`, y`
q
p

Proof. Based on Assumption 3.15, we have from subproblem (3.42) that
0.

2µiD2

µiD2

ψi

q ď ´
Then the existence of KKT solution

2µiW
X ă
immediately follows from Slater’s condition.

x, ˆx
p

q ď ´

Moreover, notice that problem (3.42) diﬀers from problem (3.7) only at the choice of proximal

s

ψ0

center. Therefore, the same argument to prove Lemma 3.5 implies that
x, x`
p

ψ0
x, ˆx
,
x; ˆx
p
q
p
¯x in the above inequality. In view of the non-negativity of
Let us place x
“
x, ˆx
deﬁnition of ψ0
, one has
q
p
2µ0W
x
ψ0
p

Combining the result (3.44) and (3.46) together, we deduce

x`; ˆx
p

x`, ˆx
p

x, ˆx
p

µT y`

2µ0W

x`
p

qy ě p

y`, ψ

W
q

q ě x

q ` x

y`,

q ´

q ´

q ´

q `

ψ0

µ0

`

´

ψ

x
µ0
p

X.
µT y`

P
`

q

(3.45)
and the

x, ˆx
p

.

qy

(3.46)

s

µminky`k1D2
s

µT y`
m
i
“
x
ř
p
q `
s
Finally, since x` is feasible to (3.42) and the feasible region of (3.42) is a subset of the feasible
region of the original problem (1.1), we have ψ0
ψ˚0 . The result (3.43) immediately
s
follows.

D2
X
q
i
x, ˆx
qψi
1y`p
q
p
µ0D2
X .
x`
ψ0
p

ď ´
ψ0

X ď p

x`
p

q ě

q ´

ď

s

Note that in view of Lemma 3.17, the strong feasibility assumption ensures two key require-
ments for the analysis of the convergence rate of the inexact proximal point: 1) feasibility of
proximal point subproblems and 2) a uniform bound on the optimal dual variable y˚k . To see the
second part, placing xk

ˆx in (3.42), we immediately obtain the the bound

1

ψ0

x

µ0D2
X

ψ˚
0 `
q´
µminD2
X

(3.47)
In this case, we only need to assume that xk satisﬁes the functional optimality gap and constraint
violation given in Deﬁnition 2.1 as compared to (3.13) and (3.14) in the previous section.

1, 2, . . . .

“

“

B

k

,

s

p

We develop the convergence result of Algorithm 4 in the following theorem.

B and
Theorem 3.18. In Algorithm 4, suppose that Assumption 3.15 holds such that ky˚k k1 ď
B is given in Lemma 3.17. Moreover, assume that the deﬁnition of xk in Algorithm 4 is given
by

´

“
ky˚k k1 ď

-optimal solution (c.f. Deﬁnition 2.1) of (3.7).
q

xk

Then x

Ð
k is a stochastic

p
where µmax :
x0
p

qs`}

}r

ψ

εK
maxi
2 and ΩK

“

δk

εK,
p
max

δk,
a stochastic
p
εK
-KKT point of Problem (1.1) with
s
q
2Lω, 8L2
µ0
εK
ωp
`
s
ψ0
µi, ΓK :
∆ψ0 `
“
K
s
δk.
1δk
k

and
q
ΩK, ∆ψ0 :
(

µmaxB
B
∆0

“
m

ΓK
K ,

“
B

K
k

`

Pr

1

s

“

“

`

“

2
µ0K ΩK,

“
x0
p

minx

X ψ0

P

x
,
q
p

q ´

(3.48)

(3.49)
∆0

“

s

ř

ř

s

s

29

 
“
|∆k|

Proof. Let ∆k
2.1 we have E
r
; xk
ψ0
and ψ
1
p
´
x; xk
ψ0
p

q `

´

q

1

1

ψ0

xk; xk
p
q ´
´
δk and E
r
s ď
; xk
, we have
1
p
q
´
i
m
qk ψi
1y˚p
i
“

x; xk
p

´

s
1
q ě

ψ0
∆k

x˚k ; xk
p
s ď

ř

“

“

1

and

k2. Using Deﬁnition
δk. In view of Lemma 3.5 and the strong convexity of

xk; xk
p

ψ
r

qs`

∆k

“

k

´

´

q

1

s

s
x˚k ; xk
ψ0
p
xk; xk
p
xk
p

ψ0
ψ0

q `

1

´

q ` p

µ0

`

1
q ´
´
2µ0W

∆k

` p
xk, xk
p

µT y˚k q
W
x, x˚k q
p
µT y˚k q
x, x˚k q
W
µ0
p
`
µ0
∆k
`
` p

q ´

´

1

µT y˚k q

W

.
x, x˚k q
p
(3.50)

Setting x

Setting k
E
r

kx

“
x˚
k

k ´
p

“
ψ0

1

xk in (3.50) yields
µ0
xk; xk
xk; xk
p
p
k in the above relation and taking expectation, we have
k2
p

ř
k, x˚
x
p

x˚k ; xk
p

i
qk ψi

2E
r

k qs ď

1y˚p

2
µ0K

q ` p

m
i
“

q ě

s ď

q ´

q `

ψ0

ψ0

ψ0

K
k

W

“

´

´

´

´

1

1

1

1

p

p

p

ď

ď

E
r
E
r
E
r
δk

1p

xk; xk
p
xk; xk
p
∆k

ψ0

B

´
∆k

`
B

δk

.
s
q

2
µ0K

ř

2
µ0K

ř

2
µ0K

ř

1

1

K
k

K
k

K
k

“

“

q ´

1

s

µT y˚k q
W

xk, x˚k q
p

`

x˚k ; xk
p
x˚k ; xk
p

ψ0

1

1

´

´

q `

q `

m
i
“
m
i
“

ř

ř

1y˚p

i
qk ψi
i
1y˚p
qk

xk; xk
p
ψi

´
xk; xk
p

r

1

qs

1

qs`s

´

ď

`
where the third inequality above is due to the Cauchy-Schwarz inequality and the boundedness
ky˚k k1 ď
2: ky˚k k2 ď
of
Analogously, by setting x
“
ψ0
B
xk
∆k
p

y˚k }
ψ0

we have

xk
p

xk
p

1; xk

q “

q `

ψ0

ř

´

´

´

´

“

´

´

´

}

q

1

1

1

1

s

ě

1 in (3.50) and noticing ψ0
y˚k }
1; xk

B.
xk
´
xk
p
xk
p
´
x˚k ; xk
p
xk
p
q ` p
Here the second inequality use the following property: for k
m
i
“

∆k
´
i
xk
qk ψi
1y˚p
s
p
µT y˚k q
W
xk, xk
p

µ0
ř
`
2µ0W

ψ0
ψ0
ψ0

i
qk ψi
y˚p

i
qk ψi

´
xk
p

´
∆k

1y˚p

qs` ď

xk
p

xk
p

1; xk

1; xk

1; xk

q ` }

q ` p

m
i
“

m
i
“

q ď

q ´

q `

1r

`

ě

ě

ě

s

´

´

´

´

´

´

1

1

1

1

1

1

1

2

(3.51)

W

xk
p

.
1, x˚k q

´

1

´

1; xk
q
1, x˚k q
´
µ0
`
1,
ą
i
m
1y˚p
qk
i
“

r

µT y˚k q

1

2

´

“

ř

ř

ř

µ0

q `

q “

2µ0

1W

m
i
“

1y˚p

1y˚p

y˚1 }

i
q1 ψi

ř
m
i
“

ř
xk, xk
p

ř
i
x0
q1 ψi
x0; x0
and
p
p
Summing up the inequality (3.51) for k
K
k

∆0.
q ď }
1, . . . , K, we obtain
s
µT y˚k q
xk
W
`
p
K
xK
ψ0
k
q `
p
K
B
1∆k
ř
k
Furthermore, due to the KKT condition for (3.7), we have
ř
1
´
, i
q
x˚k q ´
p

x˚k ; xk
1
p
q `
´
ψ0
x; xk
Plugging the deﬁnition of
p
´
x˚k q `
x˚k q `
2
p
p

“
K
k
1p
“
ψ0
x0
ř
p
∆f

ř
i
m
ψi
1y˚p
x˚k ; xk
qk
i
B
p
“
ψi
x; xk
and
1
B
p
µT y˚k qp
0. (3.54)
∇ω
ψ0
B
k be the random index from 1, . . . , K. Then, in view of (3.54), (3.53) and bound on ky˚k k1,

, into the above inequality yields
x˚k q
p

B

K
k

“

∆k

1

1

´

ř

s

(3.53)

1, x˚k q
´
1∆k
`
1,
∆k

B
`
i
1y˚p
qk

q `
m
P r
∇ω

1
ř
q
µ0
p

q ´
K
k

s
xk
p

x˚k q
p

˘
NX

s
NX

B
ψi

m
i
“

qq `

ψ0

, 0

, 0

0.

`

`

`

“

“

ď

ď

d

d

B

“

“

´

´

´

“

1

1

˘

ř

ψi

xk
p

´

1; xk

1

´

qs` ď

1,

´

ky˚k k2

∆k
(3.52)
s

Let
`
we have
p

E

d

ψ0

“

B
`
“

x˚
p
E

k q `
K
k

1
K

p
!ř
E

4
K
!ř
8L2
µ0
ωp
`
K

K
k

m
i
“
ř
1d
“

1y˚p
k

ψ0
p

pB
µ0

1p
“
µmaxB

`
E

8L2
ωp

µ0

8L2
ωp

µ0

µmaxB

`
K

µmaxB

`
K

”
ΓK

q

q

q

i
q

ψi

x˚
B
p
x˚k q `
p
µT y˚k q

k q `
m
i
“
ř
2k∇ω

p

µ0

`

K
k

1p
“
∆0

`

!ř
∆f
`

2

, 0

NX

x˚
k q
p
ψi
p

i
1y˚p
qk

B
x˚k q ´
p
µT y˚k q
W
1δk

K
k

NX

˘
‰
x˚k q `
p
xk
∇ω
p
xk
p
B

x˚k q
p
k2
q
1, x˚k q
)
δk
1
´

´
K
k

)

´

1

2

`

“

“

s

ř

ř

s

ı

ď

ď

ď

ď

, 0

2
q

)

(3.55)

Moreover, using the complimentary slackness for the subproblem and the relation (3.53), we have

K
k

“

1

1|y˚p

i
qk ψi

m
i
“

x˚k q
|
p

ř

ř

“

ď

ď

2

K
k
2Lω
ř
2Lω

“

µT y˚k q
W
x˚k , xk
1p
p
K
µT y˚k q
xk
W
k
1p
p
1∆k

K
k

“
∆f
ř

1

´

q
1, x˚k q
´
B

K
k

1

`

“

`

“

ř

ř

“

30

(3.56)

∆k

1

´

.

‰

s

Therefore

E

m
i
“
”ř

1|y˚p
k

i
q

ψi

x˚
|
k q
p

“

ı

E

1
K

”ř

K
k

“

1

1|y˚p

i
qk ψi

m
i
“

x˚k q
|
p

ř

2Lω
K ΓK.

ď

ı

Hence we conclude the proof.

p

p

Remark 3.19. We should note that when ψi, i
m
, are convex functions then we can obtain
s
a variant of Algorithm 4 where xk is a (stochastic)
-optimal solution of (3.38). For
q
this variant of Algorithm 4, we can easily obtain the result of Theorem 3.18 under uniform
boundedness of the Lagrange multiplier. Moreover, since constraints remain the same in (3.38)
for all k
1, we just need Slater’s condition to ensure the uniform boundedness of

δk,
p

P r

δk

s

.

y˚k u

t

ě

In the following corollary, we state an immediate consequence of Theorem 3.18 as well as the
ﬁnal complexity when using the ConEx method as subroutine to solve subproblem 3.7. Before
proceeding to the details of the corollary, we need to properly redeﬁne B such that it satisﬁes
B
. This allows the use of B in the sense of Theorem 3.18 as well as in
1
the stepsize policy for the ConEx method in (2.10).

ky˚k k1, ky˚k k2 `

max
t

ě

u

c

δk for some c

Corollary 3.20. Under the assumptions of Theorem 3.18, suppose that in Algorithm 4, we set
δk
, where
q
2Lw, 8L2
wp

µmaxB

0, and

2c1c2

(3.57)

µ0

`

“

ą

s

Then after running at most K
-KKT point
q{
of Problem (1.1). In particular, if we run Algorithm 1 for subproblem (3.7), then we obtain an
ε, 2ε
p

iterations, where Tε is deﬁned in (2.14).

ε iterations, we obtain an

-KKT point in O

µ0c1 q

µ0c1 q

1
ε Tε

∆0

`

“

B

s

q

p

ε, 2ε
p

δk
c1
s
c2

ε
{p
“
max
“
c
“
2c1

B
`
∆f
p

q
(

Proof. Suppose δk and
have εK

c1ΓK

δk are constants throughout Algorithm 4. Then, according to (3.49), we
δk and K, we have

ď

{
εK
Moreover, we have

K. Choosing given values of δk,
∆f

∆0

c1

s
ΓK
K “

c1

ď

B
`
K

c
` p

`

”
εK

s
2
µ0K ΩK

c1

“

ε
2c1 `

c2

ε
2c1c2

ε.

“

ı

δK
B
q
s

ı
s
2
µ0K ΓK

”
2ε
µ0c1 .

Now noting that δk
-
q
approximate solution of subproblem (3.7) in Tε iterations. Noting the deﬁnition K in the state-
ment of the corollary, we conclude the proof.

ε
O
s
p

δk,
p

δk

δk

“

“

q

s

s

“
is a constant and using Corollary 2.2, we obtain

ď

ď

In the above corollary, we assume that the subproblem (3.7) is solved using the ConEx
ky˚k k1, we have an upper bound B on ky˚k k2 in (3.47). Consequently, we
method. Since ky˚k k2 ď
can set the parameter B of ConEx method, (call it BConEx to avoid confusion with B in (3.47))
in Theorem 2.1 appropriately. In particular, we can set BConEx
1 which gives accelerated
convergence for smooth problems. Moreover, if χi
is a simple function such that we can
1, . . . , m, eﬃciently,
compute prox operator in (2.3) for functions µiW
1, . . . , m are
then we solve each subproblem in the smooth strongly convex setting, since fi, i
“
smooth functions. Otherwise, we must include the nonsmooth convex function χi
x
in totality
q
p
(or part thereof) with fi, and then we can assume µiW
is a simple function. In this case,
we solve the subproblems in a nonsmooth strongly convex setting. We can derive from Corollary
3.20 and the deﬁnition of Tε in (2.14) the ﬁnal complexity bounds for diﬀerent problem settings.

x
p
q
x, xk
p

, i
x
q
p

x, xk
p

q `

χi

“

`

“

B

´

´

q

1

1

ε

1
p

• Smooth nonconvex case: In this case, Tε can be bounded O
in the semi-stochastic case and O

case, O
in view of Corollary 3.20, we can compute an
2
ε3
problem (1.1) in O
, and O
, O
{
q
q
semi-stochastic case and fully-stochastic cases, respectively.

ε2
1
{
p
ε, 2ε
p
ε3
1
{
p

in the deterministic
in the fully-stochastic case. Hence,
q
µ0c1
-KKT point of the nonconvex
{p
iterations for the deterministic case,

2
ε1
{

1
p

1
p

1
p

ε2

qq

{

{

{

{

q

q

q

• Nonsmooth nonconvex case: In this case, Tε can be bounded by O

ε

1
p

in the semi-stochastic case and O

ministic case, O
Hence, in view of Corollary 3.20, we can compute an
convex problem (1.1) in O
and O

q
iterations for the fully-stochastic case.

1
p

ε3

ε2

{

{

q

in the deter-
q
in the fully-stochastic case.
q
µ0c1
-KKT point of the non-
iterations for the deterministic and semi-stochastic cases,

1
{
p
ε, 2ε
{p
p

1
p

ε2

qq

{

ε

1
p

{

q

Note that the dependence of these complexity bounds on diﬀerent problem parameters can be
made more precise in view of the deﬁnition of Tε in (2.14).

31

 
4 Conclusion

This paper focuses on stochastic ﬁrst-order methods for solving both convex and nonconvex func-
tional constrained problems. For the convex case, we present a novel ConEx method which utilizes
linear approximations of constraint functions to deﬁne the extrapolation step. This method is
a simple and uniﬁed algorithm that can achieve the best-known convergence rates for solving
diﬀerent functional constrained convex composite problems. In particular, we show that ConEx
attains a few new complexity results especially for the stochastic constrained setting and/or when
the objective/constraint functions contains smooth components. For the nonconvex case, we
present new proximal point methods which successively generate strictly feasible solutions from
a sequence of strongly convex subproblems. Under some standard MFCQ type assumptions,
we establish both asymptotic convergence to the KKT condition and iteration complexities to
attain some approximate KKT points. Under a diﬀerent strong feasibility assumption, we estab-
lish the convergence of inexact proximal point methods without requiring feasible solutions. This
is particularly attractive for large-scale and stochastic optimization where high accuracy is un-
achievable. Eﬃciencies of the proximal point method which uses ConEx to solve the subproblems
are established under diﬀerent problem settings.

Acknowledgement. The authors would like to thank Dr. Qihang Lin for a few inspiring
discussions that help to improve the initial version of this work. The authors would also like
to thank an anonymous reviewer whose comments helped in a signiﬁcant streamlining of the
presentation of the paper.

References

[1] Allen-Zhu, Z., and Hazan, E. Variance reduction for faster non-convex optimization.

International Conference on Machine Learning (2016), 699–707.

[2] Andreani, R., Haeser, G., and Mart´ınez, J. M. On sequential optimality conditions

for smooth constrained optimization. Optimization 60, 5 (2011), 627–641.

[3] Andreani, R., Mart´ınez, J. M., Ramos, A., and Silva, P. J. S. Strict constraint qual-
iﬁcations and sequential optimality conditions for constrained optimization. Mathematics of
Operations Research 43 (2018), 693–717.

[4] Aravkin, A. Y., Burke, J. V., Drusvyatskiy, D., Friedlander, M. P., and Roy,
S. Level-set methods for convex optimization. Mathematical Programming (2018), 1–32.

[5] Ben-Tal, A., and Nemirovski, A. Non-euclidean restricted memory level method for

large-scale convex optimization. Mathematical Programming 102 (2005), 407–456.

[6] Bertsekas, D. P. Nonlinear programming. Athena Scientiﬁc, 1999.

[7] Bertsekas, D. P. Convex optimization algorithms. Athena Scientiﬁc Belmont, 2015.

[8] Cartis, C., Gould, N. I., and Toint, P. L. On the complexity of ﬁnding ﬁrst-order
critical points in constrained nonlinear optimization. Mathematical Programming 144, 1
(2014), 93–106.

[9] Chambolle, A., and Pock, T. A ﬁrst-order primal-dual algorithm for convex problems
with applications to imaging. Journal of Mathematical Imaging and Vision 40, 1 (2011),
120–145.

[10] Chen, Y., Lan, G., and Ouyang, Y. Optimal primal-dual methods for a class of saddle

point problems. SIAM Journal on Optimization 24, 4 (2014), 1779–1814.

[11] Davis, D., and Grimmer, B. Proximally guided stochastic subgradient method for nons-

mooth, nonconvex problems. arXiv preprint arXiv: 1707.03505v4 (2017).

[12] Dinh, Q. T., Gumussoy, S., Michiels, W., and Diehl, M. Combining convex-concave
decompositions and linearization approaches for solving bmis, with application to static
output feedback. arXiv preprint arXiv:1109.3320 (2011).

32

[13] Facchinei, F., Kungurtsev, V., Lampariello, L., and Scutari, G. Ghost penalties in
nonconvex constrained optimization: Diminishing stepsizes and iteration complexity. arXiv
preprint arXiv:1709.03384 (2017).

[14] Fang, C., Li, C. J., Lin, Z., and Zhang, T. Spider: Near-optimal non- convex optimiza-
tion via stochastic path-integrated diﬀerential estimator. Advances in Neural Information
Processing Systems (2018), 687–697.

[15] Frostig, R., Ge, R., Kakade, S., and Sidford, A. Un-regularizing: approximate prox-
imal point and faster stochastic algorithms for empirical risk minimization. In International
Conference on Machine Learning (2015), pp. 2540–2548.

[16] Ghadimi, S., and Lan, G. Stochastic ﬁrst- and zeroth-order methods for nonconvex

stochastic programming. SIAM Journal on Optimization 23(4) (2013), 2341–2368.

[17] Ghadimi, S., and Lan, G. Accelerated gradient methods for nonconvex nonlinear and

stochastic programming. Mathematical Programming 156, 1-2 (2016), 59–99.

[18] G¨uler, O. New proximal point algorithms for convex minimization. SIAM Journal on

Optimization 2, 4 (1992), 649–664.

[19] Hamedani, E. Y., and Aybat, N. S. A primal-dual algorithm for general convex-concave

saddle point problems. arXiv preprint arXiv:1803.01401 (2018).

[20] Kong, W., Melo, J. G., and Monteiro, R. D. Complexity of a quadratic penalty accel-
erated inexact proximal point method for solving linearly constrained nonconvex composite
programs. arXiv preprint arXiv:1802.03504 (2018).

[21] Lan, G. First-order and Stochastic Optimization Methods for Machine Learning. Springer-

Nature, 2020.

[22] Lan, G., Lee, S., and Zhou, Y. Communication-eﬃcient algorithms for decentralized

and stochastic optimization. Mathematical Programming (2018).

[23] Lan, G., and Monteiro, R. D. C. Iteration-complexity of ﬁrst-order penalty methods

for convex programming. Mathematical Programming 138 (2013), 115–139.

[24] Lan, G., and Monteiro, R. D. C.

Iteration-complexity of ﬁrst-order augmented la-
grangian methods for convex programming. Mathematical Programming 155(1-2) (2016),
511–547.

[25] Lan, G., and Yang, Y. Accelerated stochastic algorithms for nonconvex ﬁnite-sum and

multi-block optimization. arXiv preprint arXiv:1805.05411 (2018).

[26] Lan, G., and Zhou, Y. An optimal randomized incremental gradient method. Math.

Program. 171, 1-2 (2018), 167–215.

[27] Lan, G., and Zhou, Z. Algorithms for stochastic optimization with expectation con-

straints. arXiv preprint arXiv:1604.03887 (2016).

[28] Lemar´echal, C., Nemirovski, A. S., and Nesterov, Y. E. New variants of bundle

methods. Mathematical Programming 69 (1995), 111–148.

[29] Lin, Q., Ma, R., and Yang, T. Level-set methods for ﬁnite-sum constrained convex
In Proceedings of the 35th International Conference on Machine Learning

optimization.
(2018), vol. 80, pp. 3112–3121.

[30] Lin, Q., Nadarajah, S., and Soheili, N. A level-set method for convex optimization
with a feasible solution path. SIAM Journal on Optimization 28, 4 (2018), 3290–3311.

[31] Ma, R., Lin, Q., and Yang, T. Proximally constrained methods for weakly convex
optimization with weakly convex constraints. arXiv preprint arXiv:1908.01871 (2019).

[32] Mangasarian, O., and Fromovitz, S. The fritz john necessary optimality conditions in
the presence of equality and inequality constraints. Journal of Mathematical Analysis and
Applications 17 (1967), 37–47.

33

[33] Mart´ınez, J. M., and Svaiter, B. F. A practical optimality condition without constraint
qualiﬁcations for nonlinear programming. Journal of Optimization Theory and Applications
118, 1 (2003), 117–133.

[34] Nemirovski, A. Prox-method with rate of convergence o(1/t) for variational inequali-
ties with lipschitz continuous monotone operators and smooth convex-concave saddle point
problems. SIAM Journal on Optimization 15, 1 (2004), 229–251.

[35] Nesterov, Y. Lectures on convex optimization. Springer, 2018.

[36] Nguyen, L. M., Liu, J., Scheinberg, K., and c, M. T. A novel method for machine
learning problems using stochastic recursive gradient. Proceedings of the 34th International
Conference on Machine Learning 70 (2017), 2613–2621.

[37] Nouiehed, M., Sanjabi, M., Lee, J. D., and Razaviyayn, M. Solving a class of non-
convex min-max games using iterative ﬁrst order methods. arXiv preprint arXiv:1902.08297
(2019).

[38] Pham, N. H., Nguyen, L. M., Phan, D. T., and Tran-Dinh, Q. Proxsarah: An
eﬃcient algorithmic framework for stochastic composite nonconvex optimization. arXiv
preprint arXiv:1902.05679 (2019).

[39] Polyak, B. A general method of solving extremum problems. Soviet Mathematics Doklady

8(3) (1967), 593–597.

[40] Rafique, H., Liu, M., Lin, Q., and Yang, T. Non-convex min-max optimization:
Provable algorithms and applications in machine learning. arXiv preprint arXiv:1810.02060
(2018).

[41] Reddi, S. J., Hefny, A., Sra, S., P´ocz´os, B., and Smola, A. J. Stochastic vari-
ance reduction for nonconvex optimization. International Conference on Machine Learning
(2016), 314–323.

[42] Rockafellar, R. T., and Uryasev, S. Optimization of conditional value-at-risk. Journal

of Risk 2 (2000), 21–41.

[43] Shapiro, A., Dentcheva, D., and Ruszczynski, A. Lectures on Stochastic Program-
ming: Modeling and Theory, Second Edition. Society for Industrial and Applied Mathemat-
ics, Philadelphia, PA, USA, 2014.

[44] Wang, X., Ma, S., and Yuan, Y. Penalty methods with stochastic approximation for
stochastic nonlinear programming. Mathematics of Computation 86 (306) (2017), 1793–
1820.

[45] Wang, Z., Ji, K., Zhou, Y., Liang, Y., and Tarokh, V. Spiderboost: A class of faster
variance-reduced algorithms for nonconvex optimization. arXiv preprint arXiv:1810.10690
(2018).

[46] Xu, Y.

Iteration complexity of inexact augmented lagrangian methods for constrained

convex programming. Mathematical Programming (2019).

[47] Yu, H., Neely, M., and Wei, X. Online convex optimization with stochastic constraints.

Advances in Neural Information Processing Systems (2017), 1428–1438.

[48] Zhou, D., Xu, P., and Gu, Q. Stochastic nested variance reduction for nonconvex
optimization. In Proceedings of the 32Nd International Conference on Neural Information
Processing Systems (USA, 2018), NIPS’18, Curran Associates Inc., pp. 3925–3936.

34

A Proof of Proposition 3.1

Let us denote

ψi

ψ0

x
q
p
x
and
q
p
s

ψi
x
:
p
“
, i
x
ψi
It is easy to see that
q
p
subdiﬀerentials can be written as
s
x
,
χi
p
q
q “ t
where ∇W is the gradient in the ﬁrst variable. Note that ∇W
x˚, x˚
p
constrained convex optimization problem:

µiW
m

x, x˚
p

q`
P r

0, . . . , m.

µi∇W

qu ` B

∇fi

x
p

x
p

q `

,
q

ψi

“

s

s

B

s

x, x˚
(A.1)
p
, are convex functions. Moreover, their respective

i

0. Consider the

q “

lim inf
k
Ñ8

Ñ 8

min
X
x
P
s.t.

x
q
p
x
q ď
p
Note that x˚ is a feasible solution of this problem. For sake of this proof, deﬁne Ψk
k
ψ0
2
q `
that any x
s
This is well-deﬁned since Ψk is a strongly convex function. Note that
ψ0

m
i
1
“ t
´
“
S which is feasible for (A.2) satisﬁes

ψ0
ψi
s
s
2. Let S

x˚k2 ď
´
. Let xk :
x˚
q
p

X : kx
x
P
ψ0
x
ψ0
p

for some ε
argminx

x
q
p
‰

2
` `

lim sup

x˚k2

1
2 kx

x
p

q ě

ř
P

Ψk

Ψk

P r

ψi

m

0,

“

s

ε

u

“

s

i

P

.

,

xk
p

q ď

s
lim sup
k

s
x˚
Ψk
p

q “

x˚
p

q ă 8

xk
p

q ď

k

x
:
p
“
q
0 such
x
.
q
p

ą
S Ψk

(A.3)

(A.2)

S is a feasible point.

0.

q ď

P
xk
p

Ñ8
where second inequality follows from the fact that xk is optimal and x˚
Note that as k

, we have lim supk

lim supk

Ψk

Ñ8

ψ

s

xk
p

q ă 8 ñ
x : ψi

Ñ8
Ψk

Ñ8
0, i

m

x
p

Ñ8

Ñ8

q ď

Ψk
ψ0

q Ď t

. Also note that
since both sets contain x˚. Then, deﬁnition of set S im-

Moreover, note that dom
lim inf k
p
S
dom
lim inf k
‰ H
p
for all x
x
ψ0
plies
p
x˚
lim inf k
p
Ñ8
and xk
k, xk
S
int
s
P
Ñ
p
2
ψi
is a convex function):
write the following ﬁrst-order criterion for convex optimization (
s
r
`
x˚.
xk
´
q `
s

q X
x˚
q
q ě
p
ψ0
xk
ψ0
q ě
p
x˚. Hence, there exists
s
s
s
0

Ñ8
. This inequality with (A.3) implies that limk
q

q ě
Ñ8
xk
x˚
q
p
p
. So for such k we can
q

lim inf k
dom
p

k such that for all k

lim inf k
Ψk

xk
ψ
p
This implies that xk is also the optimal solution of
s
T
ψ
`

x

s
1
2 }

x˚

2
2.

}

´

S. Hence,

s
q ` B

s
xk
ψ
p

xk
p
ψ0

xk
p

xk
p

xk
p

qs`B

x
p

s
P r

NX

q X

q “

q `

¯ψ0

q `

Ψk

Ψk

ψ0

Ñ8

su

ą

qs

ψ

P

P

k

k

r

min
X
x
P
For simplicity, let us denote vk
we have

x
p
k

s
q `
ψ

r
xk
p

“

r

. Due to the optimality of xk of solving the above,

2

ď

xk

vT
k

vT
k

q `

¯ψ0

x
p

1
2 }

s
x˚
}

subsequence

xk
p
q `
We claim that

¯ψ
xk
(A.4)
q `
p
vk
is a bounded sequence. Indeed, if this is true, then we can ﬁnd a convergent
t
u
with limk
v˚
xik q `
p
x˚, we have ¯ψ0

k
Placing x
xik q
based on the
p
lower semicontinuity of ¯ψ0. In view of this discussion, x˚ optimizes the right side of (A.5). Thus,
applying the ﬁrst order criterion, we have

´
vik “
Ñ8
T ¯ψ
x˚
p
q ď
x˚
p

Ñ 8
T ¯ψ
1
x
2 }
p
q `
, thus limk

v˚. Taking k
¯ψ0

x
q `
p
lim sup ¯ψ0

2
2,
xik q “
p

in (A.4), we have

t
lim sup

P
x˚
p

ik
u
¯ψ0

¯ψ
x
p

Ñ8
“

}
¯ψ0

@
¯ψ0

(A.5)

1
2 }

q ě

q `

X.

X.

x˚

x˚

v˚

Ñ8

2
2,

´

´

x

x

x

x

@

P

}

q

s

s
qs`
¯ψ0

0

¯ψ0

x˚
p

P B

q `

vp

i
q˚

¯ψ
x˚
p

B

NX

x˚
p

.
q

q `

¯ψ0

x˚
p

ψ0

x˚
p

m
i
ÿ
Pr
and
B

s
¯ψi

x˚
p

ψi

x˚
p

.
q

It remains to apply

B

In addition, to prove complimentary slackness, it suﬃces to show when ¯ψi

q “ B
x˚
ψi
p
0. Since xk converges to x˚ and ¯ψi is continuous, there exists some
k0
0 when k

0,
0,
0 by its deﬁnition. Taking the limit, we have

q ă
ą

k0. Hence vp

x˚
p

q “ B

q “

D

q

˚

we must have vp
such that ¯ψi
vp

i
q˚
“
xik q ă
p

0.

i
q˚
It remains to show the missing piece, that

“

ą

i
qik

“

vk

vk

contradiction. If this is not true, we may assume limk
necessary. Moreover, deﬁne yk
assume limk
Ñ8
passing it to the subsequence
t
¯ψ0
1
xjk q{}
vjk } }
p
Taking k

yjk “
¯ψ
yT
xjk q`
jk
p
, we have

“
y˚ for a subsequence
jk
, we have
u
2
x˚
xjk ´
T ¯ψ
x˚
p

vjk }`
Ñ 8

T ¯ψ
,
x
q
p

u
¯ψ0

x
p

q ď

q{}

y˚

y˚

jk

2
}

{}

ď

t

}

}

any i

Since subsequence xjk converges to x˚ and
k0. This implies yjk “

x˚
A
p

for k

ě

R

q

vk

t

u

is a bounded sequence. We will prove by
, passing to a subsequence if
, since yk is a unit vector, it has some limit point, let us
and then

. Dividing both sides of (A.4) by

} “ 8

Ñ8 }

vk

vk

}

}

vjk }`

yT
jk

¯ψ
x
p

q`

1
vjk } }

2
}

x

´

x˚

2,

}

X.

x

@

P

X.

x

@

P

ψi is continuous, we see that
0 for all k

ψi

jk
s

“

s

xjk q
p
‰

` “

ψi

xjk q ă
0 for
p
k0 and for all

ě
s

35

R

i
x˚
. So we must have 0
A
q
p
x˚, x˚
that ∇W
p
ψi
x˚
and gi
q P B
p

x˚
NX
p
ψi
0, implying that
x˚
, i
A
p
q

q `
x˚
p
B
be such that

q “
x˚
p

P

P

q

i
A
P
p
ř
q “ B

i
q

y˚p
x˚
q
x˚
ψi
p

q

x˚
ψi
. Here, we have used the fact
B
q
p
x˚
for all i
p

0, . . . , m. Let u

NX

“

P

q

y˚p
Then we can derive a contradiction by using MFCQ (Deﬁnition 3.2). Assume that z satisﬁes
MFCQ (3.2). Therefore, we have

x˚
p

q “

A
p

ř

0.

`

x˚

u

q

s
i
P

i
qgi

zT u

0

“

`

i
P

A
p

x˚

q

y˚p

qzT gi
i

x˚
p

q ď

y˚p

i
P

A
p

x˚

q

ř

where ﬁrst inequality follows since z
inequality follows due to the fact that y˚p
follows since (3.2) and y˚p

ď
N ˚X p
ě
0 for at least one i

P ´
i
q

i
q

ř
i
P
x˚
ř
q
0 and gi

x˚
A
p
q
and u
x˚
p
x˚
.
A
q
p

P

ą

y˚p

q
ψi

qzT gi
i
x˚
p
i
q maxv
NX
ψi

PB
x˚
p
x˚
p

P
q P B

q
q

q

0,

zT v
x˚
ă
p
hence zT u
0, second
ď
and last strict inequality

B Proof of Proposition 3.16

Let us deﬁne

D

ñD

ε

ε

ε

ą

ą

0

0

0

ψi, i
“
s.t. ψ0
s.t. ψ0
ψ0
s.t.

s

q ě

0, . . . , m as in (A.1) where x˚ is a local solution of (1.1) then,
x
p
x
p
x
p

x˚
p
x˚
p
x˚
p

ψ0
ψ0
ψ0

for all x

for all x

for all x

x˚
p

q ě

q “

0, i

0, i

0, i

P t

P t

ψ0

P r

P r

m

m

m

x

x

P

P

q

q

q

s

s

ą

q ě

ñD
where the ﬁrst implication follows from the fact that
m
x
P r
t
second implication follows from the fact that

x
u Ď t
x
ψi
p
The last statement implies that x˚ is a local optimal solution for the convex problem (A.2).

P r
m
P r
, kx

, kx

s
x˚k

s
´

x
p

X :

q ď

s
0, i

P r

ψi

ă

ă

´

s

P

ε

u

s

x
P t
P
x
ψi
p
q ě
X : ψi
x
P
p
x
ψi
.
s
q
p
q ě

X : ψi
ψi
X :
ψi
s
x
p
q
s
0, i
q ď

X :
ψi

q ď

q ď

x
p
x
p
x
p
q ď
for all i
m

s

, kx

, kx

x˚k

x˚k

´

´

ă

ă

x˚k

, kx
s
ă
´
or equivalently
ε
x˚k
, and

ε

ε

ε

u

u

u

,

Hence, it is also a global optimal solution. Based on (3.39) from Assumption 3.15, we have,
s

ψi

ψi

q “

x
p

2µiD2
x
p
Hence, by Slater condition, we have that there exists y˚
KKT-condition for the convex problem (A.2). Thus, we have
s
x˚
p

s
i
yp
q˚

X `
ě

x, x˚
p

x˚
p

x˚
p

q ď ´

µiW

NX

¯ψ0

q `

q `

q `

¯ψi

s

s

B

B

q Q

0,

m
i
ÿ
Pr

s

µiD2
X “ ´
0 such that

µiD2

X ă
x˚, y˚
p

0.
satisfy ﬁrst order

q

It remains to apply
conclude the proof.

¯ψi

x˚
p

B

q “ B

ψi

x˚
p

q

and

ψi

s

ψi

x˚
p
ψi

i
y˚p
q
x˚
p

q “
s

q “
x˚
q
p

m

0,
i
P r
for all i

.

0, . . . , m. Hence, we

s
P

36

