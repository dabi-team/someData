Expectation Programming: Adapting Probabilistic Programming
Systems to Estimate Expectations Efﬁciently

Tim Reichelt1

Adam Goli ´nski1

Luke Ong1

Tom Rainforth1

1University of Oxford

2
2
0
2

n
u
J

1
2

]

G
L
.
s
c
[

2
v
3
5
9
4
0
.
6
0
1
2
:
v
i
X
r
a

Abstract

We show that the standard computational pipeline
of probabilistic programming systems (PPSs) can
be inefﬁcient for estimating expectations and in-
troduce the concept of expectation programming
to address this. In expectation programming, the
aim of the backend inference engine is to directly
estimate expected return values of programs, as
opposed to approximating their conditional distri-
butions. This distinction, while subtle, allows us
to achieve substantial performance improvements
over the standard PPS computational pipeline by
tailoring computation to the expectation we care
about. We realize a particular instance of our ex-
pectation programming concept, Expectation Pro-
gramming in Turing (EPT), by extending the PPS
Turing to allow so-called target-aware inference to
be run automatically. We then verify the statistical
soundness of EPT theoretically, and show that it
provides substantial empirical gains in practice.

1 INTRODUCTION

Estimating expectations is at the center of many scientiﬁc
workﬂows. For example, the decision theoretic foundations
of most statistical paradigms, e.g. Bayesian decision theory,
are rooted in calculating the expectation of a loss func-
tion [Robert and Casella, 2004].

Carrying out this estimation often requires approximate
inference to be performed: we may not be able to directly
draw samples of the random variable we wish to calculate
the expectation of, or a simple Monte Carlo estimate might
produce problematically high variance.

Probabilistic programming systems (PPSs) provide a pow-
erful basis for encoding such inference problems and then
assisting with, or even fully automating, the approximation

of their solution [Gordon et al., 2014, van de Meent et al.,
2018]. In a PPS, programs are typically speciﬁed (often
indirectly) through an unnormalized density γ(x). Assum-
ing analytic solutions are not available, the role of the sys-
tem’s inference engine is now to construct an approximation,
ˆπ(x), for the distribution speciﬁed by the normalized den-
sity π(x) = γ(x)/Z, where Z is an unknown normalizing
constant and π(x) typically represents a conditional distri-
bution, such as the posterior in a Bayesian modeling setting.
This approximation can then be used in turn for downstream
tasks, such as approximating one or more expectations.

Though ostensibly very general, our key insight is that this
standard PPS computational pipeline—which is implicitly
followed by all contemporary PPSs that conduct inference
approximately (e.g. Bingham et al. [2019], Carpenter et al.
[2017], Cusumano-Towner et al. [2019], Ge et al. [2018],
Salvatier et al. [2016], Tran et al. [2016], Wood et al. [2014],
Mansinghka et al. [2014], Goodman and Stuhlmüller [2014],
Murray and Schön [2018], Minka et al. [2018])—can be
highly suboptimal when our ultimate aim is to estimate a
particular expectation, Eπ(x)[f (x)]. This is because such a
pipeline fails to perform estimation in a target-aware fash-
ion: it does not allow information about f to be exploited by
the inference engine, thereby forgoing the substantial empir-
ical gains that using information about f can yield [Torrie
and Valleau, 1977, Hesterberg, 1988, Wolpert, 1991, Oh and
Berger, 1992, Evans et al., 1995, Meng and Wong, 1996,
Chen et al., 1997, Gelman and Meng, 1998, Lacoste-Julien
et al., 2011, Owen, 2013, Golinski et al., 2019, Rainforth
et al., 2020]. Note here that it is not generally possible to in-
corporate the required information about f by adjusting the
model deﬁnition; fundamental changes to the computational
pipeline itself are required.

To address this, we introduce, and formalize, the concept of
expectation programming. Here an expectation program is
analogous to a probabilistic program, but its target quantity
of interest is the expected value of the program’s return
values, rather than their conditional distribution. This subtle
distinction leads to changes in the requirements for the pro-

Accepted for the 38th Conference on Uncertainty in Artiﬁcial Intelligence (UAI 2022).

 
 
 
 
 
 
gram to be valid, and, critically, the estimation that must be
performed by the backend inference engine. This, in turn,
allows us to construct computational pipelines which are
target-aware, utilizing information in the program itself to
estimate expectations substantially more efﬁciently than can
be achieved by existing PPSs.

We realize our expectation programming concept through a
speciﬁc system we call EPT (Expectation Programming in
Turing), built upon the Turing PPS [Ge et al., 2018]. EPT
takes as input a Turing-style program and uses a combi-
nation of program transformations and existing inference
strategies to construct target-aware estimators via the TABI
approach of [Rainforth et al., 2020].

We formally demonstrate the statistical soundness of EPT,
proving that it produces consistent estimates under nominal
assumptions. We further show empirically that it can be
used to express and run effective inference for a number of
problems, ﬁnding that it produces estimates that are signiﬁ-
cantly more accurate than conventional usage of Turing. As
part of this, we also implement a new annealed importance
sampling (AnIS) [Neal, 2001] inference engine for Turing,
ﬁnding that this allows for effective marginal likelihood es-
timation in a much wider array of problems than Turing’s
previously supported inference strategies.

To summarize, our key contributions are: a) identifying
the shortfall of existing PPSs when estimating expectations
and introducing the concept of expectation programming to
address this; b) developing EPT as a particular realization
of the expectation programming concept; c) formalizing the
notion of an expectation program and demonstrating the
statistical correctness of EPT; d) introducing a new AnIS
inference engine to Turing; and e) showing that EPT can
provide substantial empirical beneﬁts over conventional use
of Turing on real problems.

2 BACKGROUND

2.1 TURING PROGRAMS AS DENSITIES

To provide a basis for introducing expectation programming,
we consider the PPS Turing (Ge et al. [2018], https://
turing.ml/dev/docs/using-turing/), but note that
the concepts introduced apply to PPSs in general. We pro-
vide a brief introduction to Turing here, along with our own
new formalism for the densities Turing program deﬁne by
extending the approach of Rainforth [2017, §4.3]. This is
necessitated by some technical intricacies of the expectation
programming approach. To assist with this, we will use the
following simple Turing program as a running example:

@model function model(y)
x ∼ Normal(0, 1)
@addlogprob!(0.1)
y ∼ Normal(x, 1)

end

A Turing program is deﬁned similarly to a normal Julia func-
tion [Bezanson et al., 2017]: the @model macro indicates
the deﬁnition of a Turing model, with tilde statements inside
the body, e.g. x ∼ Normal(0, 1), to denote probabilistic
model components. Observed data can be passed in as a
formal argument to the function. If the variable name on
the left-hand side of the tilde statement is not part of the
arguments of the functions then it is interpreted as a random
variable.

Let x1:n denote the set of direct outputs from sampling
statements and y1:m the observed data. We can view Turing
programs as deﬁning an unnormalized density γ(x1:n) (with
an implicit appropriate reference measure). To compute
the density for a given x1:n the program executes like a
normal Julia program, while keeping track of the density
of the current execution. Speciﬁcally, when Turing reaches
a tilde statement corresponding to a random variable, it
samples a value for xi, evaluates the density of this draw,
and factors this into the overall execution density. We denote
the density of the draw as gi(xi|ηi), where gi denotes the
form of the sampling statement and ηi its parameters. For
the tilde statements corresponding to the observed data, it
evaluates the density function hj(yj|φj)—where hj and φj
are analogous to gi and ηi respectively—and factors the
overall density accordingly.

Sometimes a user might want to add additional factors to
the density without using a tilde statement. For this, Turing
provides the @addlogprob!(log_p) primitive which mul-
tiplies the density of the current execution by an arbitrary
value exp(log_p). We use ψ1, . . . , ψK to denote all the
terms that are added to the density using @addlogprob!.

Putting these together, the unnormalized density deﬁned by
any valid program trace can be written as

γ(x1:n) =

n
(cid:89)

i=1

gi(xi|ηi)

m
(cid:89)

j=1

hj(yj|φj)

K
(cid:89)

k=1

exp(ψk).

(1)

=

the

deﬁnes

program thus

example
γ(x)

den-
Our
exp(0.1)N(x; 0, 1)N(y; x, 1), with
sity
a ﬁxed input y. Note here that everything (i.e.
n, x1:n, η1:n, g1:n, m, y1:m, φ1:m, h1:m, K, ψ1:K)
can
be a random variable because of potential stochasticity
in the program path. However, using the program itself,
everything is deterministically calculable from x1:n, which
can thus be thought of as the ‘raw’ random draws that
dictate all the randomness of the program; everything else
is a pushforward of these.

2.2 TARGET-AWARE INFERENCE

Consider the problem of estimating an expectation of the
form Eπ(x)[f (x)] where f (x) is known, but π(x) cannot
be directly evaluated or sampled from. Namely, π(x) =
γ(x)/Z where γ(x) is a known unnormalized density, but Z

is an unknown normalization constant (sometimes referred
to as the marginal likelihood or partition function).

The inference engines in PPSs like Turing are setup to ap-
proximate π(x) of this form. As such, the standard pipeline
to approximate an expectation using a PPS is to ﬁrst ap-
proximate π(x) (e.g. with samples) and then use this to
approximate the expectation in turn.

Unfortunately, this ignores information about f and is there-
fore suboptimal if f is known [Golinski et al., 2019]. While
one might initially expect that information about f can be
easily incorporated through simple model adjustments, this
is unfortunately not the case in practice: any adjustments we
make will mean we need to estimate an additional corrective
factor on top of performing inference for the new model.
Indeed, naive approaches to incorporating information about
f , like adding |f (x)| as a density factor to the model, have
been found to typically worsen, rather than improve, the
ﬁnal estimates [Rainforth et al., 2020].

Rainforth et al. [2020] recently showed that this issue
stems from fundamental limitations of the efﬁcacy of us-
ing a single Monte Carlo estimator for such expectations.
Namely, through their Target-Aware Bayesian Inference
(TABI) framework, they show that by breaking down the
expectation into three parts:

Eπ(x)[f (x)] = (Z +

1 − Z −

1 )/Z2,

(2)

1 = (cid:82) γ(x)f +(x)dx, Z −

1 = (cid:82) γ(x)f −(x)dx,
where Z +
Z2 = (cid:82) γ(x)dx, f +(x) = max(f (x), 0), and f −(x) =
− min(f (x), 0), and then estimating each term separately,
one can often achieve a substantially improved overall esti-
1 − ˆZ −
mator, Eπ(x)[f (x)] ≈ ( ˆZ +
The intuition here is that each individual term can often
be estimated more accurately in isolation than the original
expectation. To see this, ﬁrst note that the three subcompo-
nents can be seen as the respective normalization constants
of the three densities

1 )/ ˆZ2.

γ+
1 (x) ∝ γ(x)f +(x),
γ−
1 (x) ∝ γ(x)f −(x),
γ2(x) = γ(x).

(3)

The TABI framework now allows one to deﬁne a separate
estimator tailored to each of these problems. In general,
it allows one to repurpose any algorithm which provides
estimates of the normalization constant into a target-aware
inference algorithm by separately applying it to each of
γ+
1 (x), γ−
1 (x), and γ2(x). TABI can theoretically achieve
an arbitrarily low error for any ﬁxed sample budget (≥ 3),
unlike standard approaches such as self-normalized impor-
tance sampling or MCMC whose expected error is lower
bounded, even when using an optimal proposal/sampler. The
achievable gains increase, both theoretically and empirically,
with the degree of mismatch between π(x) and π(x)f (x).

3 EXPECTATION PROGRAMMING

At a high level, expectation programming adapts probabilis-
tic programming systems to automate the estimation of ex-
pectations in a target-aware manner. As we now explain, an
expectation program is analogous to a probabilistic program,
but where the quantity of interest is the expectation of its
return values under the program’s conditional distribution,
rather than the conditional distribution itself.

3.1 FORMALIZATION

To formalize the concept of an expectation program, we ﬁrst
statistically formalize probabilistic programs as follows.

Deﬁnition 1. A probabilistic program P in a probabilistic
programming language deﬁnes an unnormalized density
γ(x1:n) over the raw random draws x1:n ∈ X of the pro-
gram, which collectively we refer to as the program trace,
along with an implicitly deﬁned reference measure µ.

We let π(x1:n) = γ(x1:n)/Z denote the normalized den-
sity with Z = (cid:82)
X γ(x1:n)dµ(x1:n). Here π(x1:n) and
µ combined implicitly deﬁne the conditional probability
distribution speciﬁed by P, which we denote P(A) =
(cid:82)
A π(x1:n)dµ(x1:n).
To ensure that the induced probability measure of a program
is well-deﬁned, we require that γ(x1:n) corresponds to a
valid unnormalized density. This guarantees that there is a
valid probability distribution the inference algorithm of the
particular PPS can converge to. We use this to formalize the
concept of a valid probabilistic program as follows.

Deﬁnition 2. A probabilistic program, P, is valid (and
deﬁnes a valid unnormalized probabilistic program density
γ(x1:n)) if and only if both of the following hold: γ(x1:n) ≥
0, ∀x1:n ∈ X ; and 0 < (cid:82)

X γ(x1:n)dµ(x1:n) < ∞.

For Turing we have described how programs specify γ(x1:n)
in Section 2.1, but Deﬁnitions 1 and 2 apply more generally
and only require that we can derive an unnormalized density
function for a given program; a requirement that is satisﬁed
by most existing popular PPSs.

We can now formalize the concept of an expectation pro-
gram by associating return values to our program:

Deﬁnition 3. An expectation program, E, is a probabilistic
program (as per Deﬁnition 1) with an associated set of
return values F ∈ F ⊆ Rd that are a deterministic mapping
of the trace x1:n.

From this deﬁnition we see that expectation programs are
largely equivalent to probabilistic programs, indeed pro-
grams in any PPS that allows return values will also be
expectation programs provided their outputs are numeric
and ﬁxed dimensional. However, as their underlying quan-
tity of interest is the expectation of their return values, E[F ],

they require a slightly different set of assumptions to ensure
validity as follows.

Deﬁnition 4. An expectation program E is valid if and only
if it is a valid probabilistic program and F is integrable.

Here the additional requirement of the expectation pro-
gram’s outputs being integrable essentially equates to requir-
ing that the expectation E[F ] exists and E[|Fi|] < ∞ for
each dimension Fi of F . This is generally a very weak re-
quirement, and strictly weaker than an assumption typically
implicitly made by existing PPSs when conﬁrming the va-
lidity of their inference engines as discussed in Appendix B.

To link expectation programs back into our early expectation
notation, we now note that the requirement for the return val-
ues to be a deterministic mapping of the trace means that we
can write F = f (x1:n), such that E[F ] = Eπ(x1:n)[f (x1:n)].
Thus the formal deﬁnition of the function we are taking the
expectation of is that it is the full mapping from the raw
random draws to the returned values rather than what is lex-
ically written in any return statement(s). This is why, for
instance, it is still valid to have multiple different return
statements in a program; provided each return statement
deﬁnes the same number of return values. In practice, this is
not something we need to worry about when writing either
models or inference engines as the law of the unconscious
statistician relieves us from explicitly delineating the ran-
dom variable deﬁned by our function (the expectation of
this random variable does not vary if we change the pa-
rameterization of our model). However, the distinction is
important for ensuring validity and to identify the precise
target function we wish to extract information about when
making the inference target-aware.

3.2 TARGET-AWARE INFERENCE ENGINES

The key idea of our expectation programming paradigm is
to use the formalisms from the previous section to set up
inference engines that exploit information from f to perform
target-aware estimation. As explained in Section 2.2, this
can lead to estimators that provide substantial performance
improvements over the standard PPS approach of simply
approximating π(x1:n), ignoring f (x1:n) completely.

Note that the approximate computation we are performing
here is fundamentally different to that of conventional in-
ference engines: we are estimating an expectation, rather
than approximating a conditional distribution. This means
the form of the outputs from our engine will change, while
we will have to exploit additional information about the
program. As such, we will generally need to make changes
to how the program itself is processed, rather than just im-
plementing a new inference engine in the existing PPS struc-
ture. Thankfully though, it will still usually be possible to
repurpose existing inference engines as part of an overall
target-aware estimation scheme, as we now show.

@expectation function expt_prog(y)

x ∼ Normal(0, 1)
y ∼ Normal(x, 1)
return x^3

# x ∼ N (x; 0, 1)
# y ∼ N (y; x, 1)
# f (x) = x3

end
expct_estimate, diagnostics =

estimate_expectation(expt_prog(2),

TABI(marginal_likelihood_estimator =

TuringAlgorithm(AnIS(),num_samples=100)))

Figure 1: An example of estimating an expectation with EPT.
Here estimate_expectation is our “do estimation” call
which takes in expectation program expt_prog (with input
y = 2) and an estimation method to apply (here a TABI
estimator using annealed importance sampling), and returns
an estimate for the expected return value of expt_prog.

3.3 EXPECTATION PROGRAMMING IN TURING

We now introduce a particular realization of the expectation
programming concept which we call Expectation Program-
ming in Turing (EPT). EPT builds on the PPS Turing to
provide a highly effective, and surprisingly simple, mecha-
nism to perform expectation programming. It allows users
to specify γ(x) analogously to how they would using Tur-
ing’s @model macro, and uses Turing’s return semantics
to deﬁne F and thus f (x).

1 (x), γ−

The key component of the EPT is splitting up the estimation
of the desired expectation as per the TABI framework of
Section 2.2. To do so we use source-code transformations
to generate three different Turing programs, one for each of
the densities γ+
1 (x), and γ2(x) (as per Equation (3)).
We then estimate the expectation by individually estimating
the normalization constant of each of these densities and
then combining them as per Equation (2). Generating valid
Turing programs allows us to leverage any inference algo-
rithm in Turing that provides marginal likelihood estimates
to estimate the quantities Z +
1 , Z −
1 , and Z2. This modularity
means that we do not have to implement custom inference
algorithms that would only work with EPT.

Estimating expectations with EPT is done in two stages.
First, users deﬁne an expectation program with the
@expectation macro, which is a drop-in replacement for
@model, and an example for which is shown in Figure 1.
Using code transformations, @expectation automatically
generates the three Turing programs representing the den-
sities γ+
1 (x), and γ2(x). This happens behind the
scenes and the user does not need to deal with the trans-
formed programs directly.

1 (x), γ−

the user

then calls

To estimate the expectation,
estimate_expectation(expt_prog, method),
where method speciﬁes the estimation approach to be
used. At present, the only supported class of methods is
TABI, which implements the previously explained TABI
estimators, but the syntax is designed to allow for easy
addition of hypothetical alternative approaches.

@expectation function expt_prog(y)

@model function expt_prog(y)

x ∼ Normal(0, 1)
y ∼ Normal(x, 1)
return x^3

end

x ∼ Normal(0, 1)
y ∼ Normal(x, 1)
tmp = x^3
@addlogprob!(log(max(tmp, 0)))
return tmp

end

Figure 2: The results of one of the three program transformations applied to the EPT @expectation program from
Figure 1 [left]. Presented is the transformation into a valid Turing @model program [right] corresponding to the density
γ+
1 (x) ∝ γ(x)f +(x). The transformed code fragment is highlighted. The full transformation is slightly more complex due
to Turing’s internals. Appendix D shows the full source code transformation for this model.

EPT then estimates the normalization constants Z +
1 , Z −
1 ,
and Z2 by running a Turing inference algorithm on each
Turing program generated by @expectation and combin-
ing the normalization constant estimates to form an estimate
of the expectation. In the example in Figure 1, we use TABI
with annealed importance sampling AnIS, which is a new
Turing inference algorithm that we have added to the system
for the purposes of this paper. TuringAlgorithm is a thin-
wrapper object storing the necessary information that allows
TABI to use a Turing inference method. AnIS can be substi-
tuted with any other Turing inference algorithm that returns
a marginal likelihood estimate. Here AnIS() implies the
use of some arbitrary default AnIS parameters regarding the
Markov chain transition kernel, and the number and spacing
of intermediate potentials used.

3.4 PROGRAM TRANSFORMATIONS

We now consider how to generate the Turing programs cor-
responding to each of the TABI densities. Note that expecta-
tion programs in EPT are also valid Turing models, i.e., re-
placing @expectation with @model yields a valid Turing
program. Such a program corresponds to the unnormalized
density γ2(x) = γ(x) without requiring any transformation
of the source-code.
To create a Turing program corresponding to γ+
1 (x), we
need to multiply the unnormalized density of the unaltered
Turing program γ(x) by max(f (x), 0). This is achieved
using Turing’s aforementioned @addlogprob! primitive,
such that we can think of it as adding a new factor
max(f (x1:n), 0) to the program density deﬁnition in (1).
Our transformations are pattern matching procedures that
ﬁnd all the return expr statements in the function body
and then a) create a new local variable tmp = expr (where
tmp is a unique identiﬁer generated using gensym()), b)
insert a statement @addlogprob!(log(max(tmp, 0)))
before the return, and c) change the return state-
ment itself to return tmp. A concrete example of the
transformation is presented in Figure 2. The transfor-
mation for γ−
1 (x) is analogous but inserts a statement
@addlogprob!(log(-min(tmp, 0))) instead.

Users can deﬁne multiple expectations by specifying mul-
tiple return values, while each individual return value

needs to almost surely be a numerical scalar. This en-
sures that each target expectation is well deﬁned and
individually identiﬁed. For each return expression, we
apply our program transformation separately and derive
a corresponding TABI estimator for each. For exam-
ple, if we have return expr1, expr2, expr3, the
program transformation for {γ+
1 (x)}2 would add the
statement @addlogprob!(log(max(expr2, 0))). Ap-
pendix I shows a full example of this.

3.5 VALIDITY OF EPT

We now formalize and demonstrate the statistical correct-
ness of the EPT approach. For simplicity, we will assume
throughout that programs almost surely return a single scalar
value (i.e. the probability that the return value fails to be a
well-deﬁned scalar is 0). Generalization to programs with
multiple return values is straightforward (provided the num-
ber of return values is ﬁxed) by considering each return
value separately in isolation (as EPT does itself).

Theorem 1. Let E be a valid expectation program in
EPT with unnormalized density γ(x1:n), deﬁned on pos-
sible traces x1:n ∈ X , with return value F = f (x1:n).
Then γ+
1 (x1:n) := γ(x1:n) max(0, f (x1:n)), γ−
1 (x1:n) :=
−γ(x1:n) min(0, f (x1:n)), and γ2(x1:n) := γ(x1:n) are
all valid unnormalized probabilistic program densities. Fur-
1 }m, { ˆZ2}m are sequences of estima-
ther, if { ˆZ +
tors for m ∈ N+ such that
(cid:90)

1 }m, { ˆZ −

{ ˆZ ±

1 }m

p
→

γ±
1 (x1:n)dµ(x1:n),

{ ˆZ2}m

p
→

γ2(x1:n)dµ(x1:n)

X

(cid:90)

X

where
then ({ ˆZ +

p
→ means convergence in probability as m → ∞,

1 }m − { ˆZ −

1 }m)/{ ˆZ2}m

p
→ E[F ].

Theorem 1, which is proved in Appendix B, shows that if
we have programs with the desired densities and we use
consistent marginal likelihood estimators for each, then our
resulting expectation estimates will themselves be consis-
tent. The latter is covered by the consistency of Turing’s own
inference engines. The former requires that our transformed
programs are valid Turing programs with the intended den-
sities. We now show that this is indeed the case.

1 , P −

Given an input EPT program E, EPT applies transforma-
tions to get the three Turing programs P +
1 , and P2 with
γ+
1 (x1:n), γ−
1 (x1:n), and γ2(x1:n) as their respective den-
sities. To ensure that the transformations for γ+
1 (x1:n) and
γ−
1 (x1:n) are correct, we need to ensure that a) the inserted
code in our transformations is itself valid, b) the transfor-
mation does not have any unintended side effects, and c)
the new density terms add valid factors to the program den-
sity. The ﬁrst is true as the operation of the transformed
sections of code are identical to the originals except for the
new @addlogprob! terms, which themselves produce no
outputs and, by construction, use only the variables that
are in scope. The second is guaranteed by ensuring that the
tmp variables are given unique identiﬁers that cannot clash
with each other or any other variables in the program. The
third follows from the restriction that each return value must
almost surely be a numerical scalar, coupled with the fact
that the added density factors (namely max(tmp, 0) and
-min(tmp, 0)) are non-negative by construction.

Thus, we have shown that EPT will produce a consistent
estimation of program expectations, under the assumptions
of Deﬁnition 4 and the consistency of the base inference
algorithms implemented in Turing.

4 RELATED WORK

Our focus is explicitly on the case of estimating expecta-
tions. Though a few papers [Gordon et al., 2014, Zinkov and
Shan, 2017] have provided alternative formalizations for the
expectation deﬁned by a probabilistic program, none do this
from the perspective of directly targeting this expectation as
the quantity to estimate. Relatedly, a few languages provide
primitives to compute expectations analytically in the rare
situation where this is possible, such as Hakaru [Zinkov
and Shan, 2017] or λPSI [Gehr et al., 2020]. Unlike in our
setting, these do not require notable changes to the backend
computation from the standard inference setting because the
underlying problem remains the same: calculate an integral
analytically. The contributions of these works are thus some-
what tangential to our own, with our key message being
that estimating expectations efﬁciently requires a distinct
computational pipeline to that of modern PPSs.

Some PPSs also provide syntactic sugars for forming expec-
tation estimates from the samples produced by inference,
but these do not adjust the inference itself to exploit target
function information. For example, in Stan [Carpenter et al.,
2017] users can apply target functions to posterior samples
using the generated_quantities block. Similarly, in
Pyro [Bingham et al., 2019] the return values are stored
along with MCMC posterior samples, thus allowing expec-
tations to be estimated by taking empirical averages. PyMC3
[Salvatier et al., 2016] allows users to track deterministic
transformations of the latent variables. Turing itself also
provides a generated_quantities function, similar
to Stan (see Appendix C for an example).

5 EXPERIMENTS

We demonstrate the effectiveness of the EPT target-aware
inference methods on three problems: a synthetic numerical
example, an SIR epidemiology model, and a Bayesian hier-
archical model. Our EPT implementation and the code for
all experiments can be found at git.io/JZOqN.

The performance of EPT depends on the performance of the
chosen marginal likelihood estimator. At the time of writ-
ing, Turing provides implementations of Sequential Monte
Carlo [Del Moral et al., 2006] and Importance Sampling
(IS) as inference algorithms that provide marginal likeli-
hood estimates, but only allows using the prior as the pro-
posal which can never be target-aware. To address this issue,
we implemented a new Turing inference engine that uses
Annealed Importance Sampling (AnIS) [Neal, 2001] (see
Appendix A), chosen because of its ability to estimate nor-
malization constants in high dimensions [Wallach et al.,
2009, Salakhutdinov and Larochelle, 2010, Wu et al., 2017].

AnIS requires setting two hyperparameters: an anneal-
ing schedule and a transition kernel. Currently, users can
choose between two transition kernels: Metropolis-Hastings
(MH) implemented in AdvancedMH.jl [Turing Develop-
ment Team, 2020] and Hamiltonian Monte Carlo (HMC)
[Neal, 2011, Hoffman and Gelman, 2014, Betancourt, 2018]
in AdvancedHMC.jl [Xu et al., 2020]. To ensure a fair
comparison we use the same setup and hyperparameters for
both EPT’s backend and standard, non-target-aware AnIS.
We also compare directly to MCMC targeting the posterior
and using the same type of transition kernel as AnIS and
EPT. This transition kernel is MH in Section 5.1 and HMC
elsewhere. Detailed conﬁgurations are given in Appendix F.

To compare the performance of the estimators we look at
the effective sample size (ESS, see below) and the relative
squared error (RSE) ˆδ := (ˆµ − µ)2/µ2, where µ denotes the
ground-truth value and ˆµ is the estimate. All our experiments
correspond to target functions which are always positive, so
1 as Z −
we use Z1 to refer to Z +
1 = 0. Appendix E shows
how EPT can avoid computation for Z −

1 when possible.

two sets of

1:n}(cid:96)) = ((cid:80)
samples

Both EPT and AnIS produce weighted samples {w(cid:96), ˆx(cid:96)
1:n}(cid:96),
(cid:96) w(cid:96))2/ (cid:80)
(cid:96) w2
so we use ESS({w(cid:96), ˆx(cid:96)
(cid:96) .
(for Z1 and
EPT produces
Z2
respectively), so we take our overall ESS as
min(ESSZ1 , ESSZ2 ). For AnIS, we only produce one
set of samples (targeting Z2) but use them to estimate
both Z1 and Z2. Here ESSAnIS
can be calculated in
Z2
the normal way, but we have ESSAnIS
({w(cid:96), ˆx(cid:96)
1:n}(cid:96)) =
Z1
((cid:80)
1:n))2. As MCMC produces
unweighted samples, we cannot directly calculate analo-
gous ESSs. Instead, we calculate an upper bound on the
true ESS by assuming that the autocorrelation between sam-
ples is zero, i.e. that samples are independent. ESSMCMC
is
then just equal to the number of samples produced, while
ESSMCMC
(cid:96) f (ˆx(cid:96)
Z1

1:n}(cid:96)) = ((cid:80)

1:n))2/ (cid:80)

1:n))2/ (cid:80)

(cid:96)(w(cid:96)f (ˆx(cid:96)

(cid:96) w(cid:96)f (ˆx(cid:96)

(cid:96)(f (ˆx(cid:96)

1:n))2.

({ˆx(cid:96)

Z2

Figure 3: Relative squared error (RSE) and effective sample size (ESS) for the Gaussian posterior predictive experiment for
a given computational cost. This cost is normalized across approaches by using the same number of likelihood evaluations
and it has units of the combined number of samples used by EPT, which is equivalent to half the AnIS samples produced
or 1/(2n) of the number of MCMC samples produced, where n is the number of intermediary distributions used by AnIS.
The solid lines show the median of the estimator while the shaded region show the 25 % and 75 % quantiles. Medians and
quantiles are computed over 10 separate runs with different random seed for the posterior predictive problem. For the ESS
plot we are plotting min(ESSZ1, ESSZ2); note that our estimates are (quite loose) upper bounds for MCMC (see text).

Figure 4: RSE and ESS for the SIR experiment. Conventions as in Figure 3; results computed over 5 runs.

5.1 GAUSSIAN POSTERIOR PREDICTIVE

√

The ﬁrst problem considered is calculating the posterior
predictive distribution of a Gaussian model with an un-
known mean, where γ(x) = N (x; 0, I) N (y; x, I) and
f (x) = N (−y; x, 1
2 I) are the unnormalised density and
target function, respectively. We assume our observed data
10)1 where 1 is a 10-dimensional vector of
is y = (3.5/
ones. Using EPT we can express this expectation in just 5
lines of code—the full model is given in Appendix J. This
problem is amenable to an analytic solution so allows us to
compute the error of the estimates. Figure 3 compares the
performance of EPT, AnIS, and MCMC (here MH). We see
a clear beneﬁt to using the target-aware inference algorithm
to estimate the expectation. EPT achieves a lower RSE, and
the ESS highlights the advantage of using separate estima-
tors for Z1 and Z2. Note that the high apparent ESS of
MCMC for small sample sizes is likely due to the looseness
of the bound, rather than the true actual ESS being large.

5.2 SIR EPIDEMIOLOGICAL MODEL

Our second problem setting is a more applied example based
on the Susceptible-Infected-Recovered (SIR) model of Ker-

mack et al. [1927] from the ﬁeld of epidemiology. Assume
we face a disease outbreak. The government has provided
us with a function yielding the expected cost of the disease
which depends on the basic reproduction rate R0, which in-
dicates the expected number of people one infected person
will infect in a population where everyone is susceptible.
We seek to infer R0 and the expected cost of the outbreak.

The SIR model divides the population into three compart-
ments: people who are susceptible to the disease, those who
are currently infected, and those who have already recov-
ered. The dynamics of the outbreak are modelled by a set of
differential equations

dS
dt

= −βS

I
N

,

dI
dt

= βS

I
N

− γI,

dR
dt

= γI,

(4)

with parameters β and γ. S, I and R correspond to the
number of people susceptible, infected and recovered, re-
spectively. The size of the total population is N = S +I +R.
Roughly, β models the constant rate of infectious contact
between people, while γ is the constant recovery rate of in-
fected individuals. From these parameters we can calculate
the basic reproduction rate R0 = β/γ. We assume γ to be
known, and we want to infer β and the initial number of

Table 1: Final estimates for the Radon experiments. Mean
and standard deviation estimated over 10 runs.

METHOD

FINAL ESTIMATE

EPT
ANIS
MCMC

3.74e−8 ± 2.39e−9
1.15e−9 ± 3.02e−9
7.79e−18 ± 2.46e−17

We now want to ﬁnd out whether the radon level in all
households is below an acceptable level, taking this thresh-
old to be 4pCi/L. The probability of this event is equal to
the expectation under the posterior of a step function f (x).
However, to allow the use of HMC transition kernels we use
a logistic function as a continuous relaxation of this step
function. See Appendix H for more details.

This problem cannot be solved analytically and estimating
the ground-truth with sufﬁcient accuracy is computation-
ally infeasible. We, therefore, resort to comparing EPT and
AnIS based on their ESSs, noting that a low ESS almost
exclusively means a poor inference estimate, while a high
ESS is a strong (but not absolute) indicator of good perfor-
mance. As we can see in Figure 5, EPT outperforms standard
AnIS by several orders of magnitude. Additionally, Table 1
presents the ﬁnal expectation estimates for each method. All
methods differ in their estimates. However, EPT is the only
one where the standard deviation of the estimate is small
relative to its mean estimate, which, coupled with our ESS
results, provides strong evidence that it is signiﬁcantly out-
performing the baselines. In particular, it seems clear that
the MCMC (here HMC) estimate is very poor: the fact that
its estimate is many orders of magnitude smaller than the
others, coupled with its extremely low ESS (despite ignor-
ing sample correlations), shows that it is failing to produce
any samples in regions where f (x) is non-negligible.

6 CONCLUSION

We have introduced the concept of expectation program-
ming which describes the process of encoding expectations
programmatically and automating their estimation in an ef-
ﬁcient, target-aware manner. This concept is realized by
extending the PPS Turing to EPT using a combination of
program transformations and target-aware estimators. We
have shown that EPT estimates expectations effectively in
practice, while its modularity means that it can easily be
built on by others. Moreover, we believe the introduction of
the high-level expectation programming concept can pave
the way for exciting future advances. While EPT focuses
on the automation of TABI estimators, other implementa-
tions focusing on different approaches are conceivable—for
example, systems targeting the automatic synthesis of con-
trol variates for a given input program—just as there are
different PPSs focusing on distinct inference algorithms.

Figure 5: ESS plots for the Radon experiment. Conventions
as in Figure 3; estimates based on 10 runs/seeds.

infected people I0. The full statistical model and the cost
function (which is based on R0) is given in Appendix G.

This scenario is a good use case for EPT because we are
interested in estimating a speciﬁc expectation with high
accuracy. Our cost function has some outcomes which might
have low probability under the posterior but which incur
a very high cost. These outcomes are liable to be missed
by non-target-aware schemes, leading to extremely skew
estimators that almost always underestimate the expectation.

Figure 4 compares the performance of the estimators. Since
this problem is not amenable to an analytic solution, we esti-
mate the ground-truth using a customized IS estimator with
orders of magnitude more samples than estimates presented
in the plot (see Appendix F). EPT substantially improves
on the baselines, with MCMC (here HMC) failing to pro-
vide any meaningful estimate; it produces no samples where
f (x) is signiﬁcant. EPT is able to overcome this through
its use of a separate estimator for γ(x)f (x). The fact that
MCMC does far worse than AnIS, despite neither being
target-aware, stems from the latter producing a greater di-
versity of (weighted) samples, a small number of which
land in regions of high f (x) by chance. To conﬁrm that the
failure of MCMC is not due to the speciﬁc implementation
used we also computed results for this model in Stan, which
produced similar results, see Appendix L.

5.3 HIERARCHICAL CONCENTRATION MODEL

Our third problem setting is a Bayesian hierarchical model
for the radon concentration in households in different coun-
ties, adapted from Gelman and Hill [2006]. For the jth house
in county i, we would like to predict the log radon concentra-
tion yij inside the house. For each house we have a covariate
xij which is 0 if the house has a basement, and 1 if it does
not. With this setup, the model is deﬁned as

µα ∼ N (0, 10),
µβ ∼ N (0, 10),

(cid:15) ∼ HalfCauchy(0, 5),

αi ∼ N (µα, 0.12),
βi ∼ N (µβ, 0.22),
yij ∼ N (αi + βixij, (cid:15)).

(5)

(6)

(7)

Acknowledgements

We would like to thank Sheheryar Zaidi for helpful discus-
sions on conﬁguring Annealed Importance Sampling. Tim
Reichelt and Adam Golinski are supported by UK EPSRC
CDT in Autonomous Intelligent Machines and Systems with
the grants EP/S024050/1 (Tim Reichelt) and EP/L015897/1
(Adam Golinski). Luke Ong is funded by EPSRC.

References

Michael Betancourt. A Conceptual Introduction to Hamilto-

nian Monte Carlo, 2018.

Jeff Bezanson, Alan Edelman, Stefan Karpinski, and Viral B.
Shah. Julia: A Fresh Approach to Numerical Computing.
SIAM Review, 59(1):65–98, January 2017. ISSN 0036-
1445. doi: 10.1137/141000671.

Eli Bingham, Jonathan P. Chen, Martin Jankowiak, Fritz
Obermeyer, Neeraj Pradhan, Theofanis Karaletsos, Rohit
Singh, Paul Szerlip, Paul Horsfall, and Noah D. Good-
man. Pyro: Deep Universal Probabilistic Programming.
Journal of Machine Learning Research, 20(28):1–6, 2019.
ISSN 1533-7928.

Bob Carpenter, Andrew Gelman, Matthew D Hoffman,
Daniel Lee, Ben Goodrich, Michael Betancourt, Mar-
cus Brubaker, Jiqiang Guo, Peter Li, and Allen Riddell.
Stan: A probabilistic programming language. Journal of
statistical software, 76(1), 2017.

Ming-Hui Chen, Qi-Man Shao, et al. On Monte Carlo
Methods for Estimating Ratios of Normalizing Constants.
The Annals of Statistics, 25(4):1563–1594, 1997.

Marco F. Cusumano-Towner, Feras A. Saad, Alexander K.
Lew, and Vikash K. Mansinghka. Gen: A General-
Purpose Probabilistic Programming System with Pro-
grammable Inference. In Proceedings of the 40th ACM
SIGPLAN Conference on Programming Language De-
sign and Implementation, PLDI 2019, pages 221–236,
New York, NY, USA, June 2019. Association for Com-
puting Machinery.
doi:
10.1145/3314221.3314642.

ISBN 978-1-4503-6712-7.

Pierre Del Moral, Arnaud Doucet, and Ajay Jasra. Se-
quential Monte Carlo Samplers. Journal of the Royal
Statistical Society: Series B (Statistical Methodology), 68
(3):411–436, 2006.

Hong Ge, Kai Xu, and Zoubin Ghahramani. Turing: A
Language for Flexible Probabilistic Inference. In Interna-
tional Conference on Artiﬁcial Intelligence and Statistics
(AISTATS), pages 1682–1690. PMLR, March 2018.

Timon Gehr, Samuel Steffen, and Martin Vechev. λpsi:
Exact inference for higher-order probabilistic programs.
In Proceedings of the 41st ACM SIGPLAN Conference
on Programming Language Design and Implementation,
PLDI 2020, page 883–897, New York, NY, USA, 2020.
Association for Computing Machinery.

Andrew Gelman and Jennifer Hill. Data Analysis Using
Regression and Multilevel/Hierarchical Models. Analyti-
cal Methods for Social Research. Cambridge University
Press, 2006. doi: 10.1017/CBO9780511790942.

Andrew Gelman and Xiao-Li Meng. Simulating Normal-
izing Constants: From Importance Sampling to Bridge
Sampling to Path Sampling. Statistical science, pages
163–185, 1998.

Adam Golinski, Frank Wood, and Tom Rainforth. Amor-
tized Monte Carlo Integration. In International Confer-
ence on Machine Learning (ICML), pages 2309–2318.
PMLR, May 2019.

Noah D Goodman and Andreas Stuhlmüller. The Design and
Implementation of Probabilistic Programming Languages.
http://dippl.org, 2014. Accessed: 2021-5-21.

Andrew D. Gordon, Thomas A. Henzinger, Aditya V. Nori,
and Sriram K. Rajamani. Probabilistic Programming.
In Future of Software Engineering Proceedings, FOSE
2014, pages 167–181, New York, NY, USA, May 2014.
Association for Computing Machinery.
ISBN 978-1-
4503-2865-4. doi: 10.1145/2593882.2593900.

Leo Grinsztajn, Elizaveta Semenova, Charles C. Margos-
sian, and Julien Riou. Bayesian Workﬂow for Disease
Transmission Modeling in Stan, 2020.

Timothy Classen Hesterberg. Advances in Importance Sam-

pling. PhD thesis, Stanford University, 1988.

M. Hoffman and A. Gelman. The No-U-turn Sampler: Adap-
tively Setting Path Lengths in Hamiltonian Monte Carlo.
Journal of Machine Learning Research, 15:1593–1623,
2014.

William Ogilvy Kermack, A. G. McKendrick, and
Gilbert Thomas Walker. A Contribution to the Math-
ematical Theory of Epidemics. Proceedings of the Royal
Society of London. Series A, Containing Papers of a Math-
ematical and Physical Character, 115(772):700–721, Au-
gust 1927. doi: 10.1098/rspa.1927.0118.

Michael Evans, Tim Swartz, et al. Methods for Approxi-
mating Integrals in Statistics with Special Emphasis on
Bayesian Integration Problems. Statistical science, 10(3):
254–272, 1995.

Simon Lacoste-Julien, Ferenc Huszár, and Zoubin Ghahra-
mani. Approximate Inference for the Loss-Calibrated
Bayesian. In International Conference on Artiﬁcial Intel-
ligence and Statistics (AISTATS), pages 416–424, 2011.

G.M. Torrie and J.P. Valleau. Nonphysical Sampling Dis-
tributions in Monte Carlo Free-Energy Estimation: Um-
brella Sampling. Journal of Computational Physics, 23
(2):187 – 199, 1977.

Dustin Tran, Alp Kucukelbir, Adji B Dieng, Maja Rudolph,
Dawen Liang, and David M Blei. Edward: A Library for
Probabilistic Modeling, Inference, and Criticism. arXiv
preprint arXiv:1610.09787, 2016.

The

Turing

Development

Team.

Tur-
The Turing Language,
URL https://github.com/

ingLang/AdvancedMH.jl.
October 2020.
TuringLang/AdvancedMH.jl.

Jan-Willem van de Meent, Brooks Paige, Hongseok Yang,
and Frank Wood. An Introduction to Probabilistic Pro-
gramming. arXiv:1809.10756 [cs, stat], September 2018.

Hanna M. Wallach, Iain Murray, Ruslan Salakhutdinov, and
David Mimno. Evaluation Methods for Topic Models,
page 1105–1112. Association for Computing Machinery,
New York, NY, USA, 2009. ISBN 9781605585161.

Robert L Wolpert. Monte Carlo Integration in Bayesian
Statistical Analysis. Contemporary Mathematics, 115:
101–116, 1991.

Frank Wood, Jan Willem Meent, and Vikash Mansinghka. A
New Approach to Probabilistic Programming Inference.
In International Conference on Artiﬁcial Intelligence and
Statistics (AISTATS), pages 1024–1032. PMLR, April
2014.

Yuhuai Wu, Yuri Burda, R. Salakhutdinov, and Roger B.
Grosse. On the Quantitative Analysis of Decoder-Based
Generative Models. International Conference on Learn-
ing Representations (ICLR), 2017.

Kai Xu, Hong Ge, Will Tebbutt, Mohamed Tarek, Martin
Trapp, and Zoubin Ghahramani. AdvancedHMC.jl: A
Robust, Modular and Efﬁcient Implementation of Ad-
vanced HMC Algorithms. In Symposium on Advances
in Approximate Bayesian Inference (AABI), pages 1–10.
PMLR, February 2020.

Robert Zinkov and Chung-Chieh Shan. Composing In-
ference Algorithms as Program Transformations. Pro-
ceedings of Uncertainty in Artiﬁcial Intelligence (UAI),
page 10, 2017.

Vikash K. Mansinghka, Daniel Selsam, and Yura N.
Perov. Venture: a higher-order probabilistic program-
ming platform with programmable inference. CoRR,
abs/1404.0099, 2014. URL http://arxiv.org/
abs/1404.0099.

Xiao-Li Meng and Wing Hung Wong. Simulating Ratios
of Normalizing Constants via a Simple Identity: a The-
oretical Exploration. Statistica Sinica, pages 831–860,
1996.

Tom Minka, John M. Winn, John P. Guiver, Yordan
Zaykov, Dany Fabian, and John Bronskill.
/In-
fer.NET 0.3, 2018. Microsoft Research Cambridge.
http://dotnet.github.io/infer.

Lawrence M. Murray and Thomas B. Schön. Automated
learning with a probabilistic programming language:
Birch. Annual Reviews in Control, 2018.

Radford M. Neal. Annealed Importance Sampling. Statistics
and Computing, 11(2):125–139, April 2001. ISSN 0960-
3174. doi: 10.1023/A:1008923215028. URL https:
//doi.org/10.1023/A:1008923215028.

Radford M. Neal. MCMC Using Hamiltonian Dynamics. In
Handbook of Markov Chain Monte Carlo, pages 113–162.
Chapman & Hall / CRC Press, 2011.

Man-Suk Oh and James O Berger. Adaptive Importance
Sampling in Monte Carlo Integration. Journal of Sta-
tistical Computation and Simulation, 41(3-4):143–168,
1992.

Art B. Owen. Monte Carlo Theory, Methods and Examples.

2013.

Tom Rainforth.

Automating Inference, Learning,
and Design Using Probabilistic Programming.
http://purl.org/dc/dcmitype/Text, University of Ox-
ford, 2017.

Tom Rainforth, Adam Golinski, Frank Wood, and Sheheryar
Zaidi. Target–Aware Bayesian Inference: How to Beat
Optimal Conventional Estimators. Journal of Machine
Learning Research, 21(88):1–54, 2020.

Christian Robert and George Casella. Monte Carlo Statisti-
cal Methods. Springer Texts in Statistics. Springer-Verlag,
New York, second edition, 2004. ISBN 978-0-387-21239-
5. doi: 10.1007/978-1-4757-4145-2.

Ruslan Salakhutdinov and Hugo Larochelle. Efﬁcient Learn-
ing of Deep Boltzmann Machines. In International Con-
ference on Artiﬁcial Intelligence and Statistics (AISTATS),
pages 693–700, 2010.

John Salvatier, Thomas V Wiecki, and Christopher Fon-
nesbeck. Probabilistic Programming in Python Using
PyMC3. PeerJ Computer Science, 2:e55, 2016.

A ANNEALED IMPORTANCE SAMPLING

Annealed importance sampling (AnIS) [Neal, 2001] is an inference algorithm which was developed with the goal of
efﬁciently estimating the normalization constant Z of an unnormalized density γ(x). It works by deﬁning a sequence of
annealing distributions π0(x), . . . , πn(x) which interpolate between a simple base distribution π0(x) (typically the prior for
a Bayesian model) and the complex target density πn(x) = γ(x). The most common scheme is to take

πi(x) ∝ λi(x) = π0(x)1−βn γ(x)βn ,

(8)

with 0 = β0 < . . . < βn = 1. The algorithm further requires the deﬁnition of Markov chain transition kernels
τ1(x, x(cid:48)), . . . , τn−1(x, x(cid:48)) and proceed to generate the jth weighted sample as follows First, sample initial particle
j ∼ π0(x), then for i = 1, . . . , (n − 1), generate x(i+1)
x(1)
j with weight

j , ·) and, ﬁnally, return sample x(n)

∼ τi(x(i)

j

wj =

λ1(x(1)
π0(x(1)

j )λ2(x(2)
j )λ1(x(2)

j ) . . . λn(x(n)
)
j ) . . . λn−1(x(n)

j

j

)

(9)

We can estimate expectations with the weights and samples just as in importance sampling. Thus we can estimate the
expectation and the normalization constant as

Eπ(x)[f (x)] ≈

(cid:80)N

j=1 wjf (x(n)
(cid:80)N
j=1 wj

j

)

and Z ≈

1
N

N
(cid:88)

j=1

wj.

A.1

IMPLEMENTATION DETAILS OF TURING INFERENCE ENGINE

The implementation of our new Turing inference engine is available at https://github.com/treigerm/
AnnealedIS.jl. It is a stand-alone package that can be used completely independently from EPT and is therefore
useful for any Turing user who wishes to run AnIS on their model. Furthermore, our implementation leverages the modu-
larity of the Turing ecosystem by using existing MCMC transition kernels from the packages AdvancedMH.jl [Turing
Development Team, 2020] and AdvancedHMC.jl [Xu et al., 2020].

Keeping the same notation as above, given a Turing model the AnIS inference creates Julia functions for the prior density
π0(x) and the unnormalized density γ(x). The unnormalized density of the program is evaluated as described in Section 2.1
and the prior density is evaluated similarly but ignores all the ‘likelihood’ terms hj(yj | φj) and all the terms added with
@addlogprob primitive. Once we have Julia functions for π0(x) and γ(x) it is straightforward to create a function for the
intermediate targets λi(x) for a given βi. The Julia function for the intermediate targets λi(x) can then be used by one of
the MCMC samplers in AdvancedMH.jl or AdvancedHMC.jl to collect samples from the intermediate distributions.

B THEORETICAL DETAILS

B.1 ASSUMPTIONS IN DEFINITION 4

To ensure correctness most PPSs assume that a particular inference algorithm will converge to the distribution of F (i.e. the
distribution over return values). A standard PPS Monte Carlo inference engine will now produce a sequence of samples
Fn, n = 1, 2, . . . and consistency requires that Fn converges in distribution to F as n → ∞. This is equivalent to requiring
that for any integrable function h, E[h(Fn)] → E[h(F )]; and it presupposes that the distribution of F is a ﬁnite measure,
i.e., E[F ] is ﬁnite. We thus see our assumption is strictly weaker than that of standard PPSs that allow return values from
programs: we only need convergence in the case where h is the identity mapping, not all integrable functions.

B.2 PROOF FOR THEOREM 1

Theorem 2. Let E be a valid expectation program in EPT with unnormalized density γ(x1:n), deﬁned on possi-
ble traces x1:n ∈ X , with return value F = f (x1:n). Then γ+
1 (x1:n) :=
−γ(x1:n) min(0, f (x1:n)), and γ2(x1:n) := γ(x1:n) are all valid unnormalized probabilistic program densities. Further, if
{ ˆZ +

1 }m, { ˆZ2}m are sequences of estimators for m ∈ N+ such that

1 (x1:n) := γ(x1:n) max(0, f (x1:n)), γ−

1 }m, { ˆZ −

{ ˆZ ±

1 }m

p
→

{ ˆZ2}m

p
→

(cid:90)

X

(cid:90)

X

γ±
1 (x1:n)dµ(x1:n),

γ2(x1:n)dµ(x1:n)

where

p
→ means convergence in probability as m → ∞, then ({ ˆZ +

1 }m − { ˆZ −

1 }m)/{ ˆZ2}m

p
→ E[F ].

Proof. We start by noting that as γ2(x1:n) is identical to γ(x1:n), it is by assumption a valid unnormalized program
density. Meanwhile, by construction, γ(x1:n)+
1 ≥ 0, ∀x1:n ∈ X . Further, each can be written in the form of (1)
by taking the correspond deﬁnition of γ(x1:n) and adding in factors exp(ψK+1) = max(0, f (x1:n)) and exp(ψK+1) =
− min(0, f (x1:n)) for γ(x1:n)+
1 respectively. To ﬁnish the proof that γ±(x1:n) are valid densities, we show
that 0 < Z ±
1 < ∞.
Starting with the standard deﬁnition of an expectation for arbitrary random variables, we can express E[F ] as

1 and γ(x1:n)−

1 , γ(x1:n)−

(cid:90)

X

f (x1:n)dP(x1:n) =

(cid:90)

X

f +(x1:n)dP(x1:n) −

(cid:90)

X

f −(x1:n)dP(x1:n).

(10)

Noting that if F is integrable then by the deﬁnition of the Lebesgue integral (cid:82)
(cid:82)
X f −(x1:n)dP(x1:n) < ∞. Now inserting the distribution the program deﬁnes over x1:n,

X f +(x1:n)dP(x1:n) < ∞ and

(cid:90)

=

X

f +(x1:n)π(x1:n)dµ(x1:n) −

(cid:90)

X

f −(x1:n)π(x1:n)dµ(x1:n)

(11)

and noting that γ(x1:n) ≥ 0 for all x1:n ∈ X and 0 < (cid:82)

X γ(x1:n)dµ(x1:n) < ∞,

=

=

X f +(x1:n)γ(x1:n)dµ(x1:n) − (cid:82)
(cid:82)

X f −(x1:n)γ(x1:n)dµ(x1:n)

(cid:82)
X γ(x1:n)dµ(x1:n)

(cid:82)
X γ+

1 (x1:n)dµ(x1:n) − (cid:82)
(cid:82)

X γ2(x1:n)dµ(x1:n)

X γ−

1 (x1:n)dµ(x1:n)

=:

1 − Z −
Z +
1
Z2

.

(12)

(13)

In our theorem statement we have assumed that { ˆZ +
follows by Slutsky’s Theorem that

1 }m

p
→ Z +

1 , { ˆZ −

1 }m

p
→ Z −

1 , and { ˆZ2}m

p
→ Z2, from which it now

{ ˆZ +

1 }m − { ˆZ −
{ ˆZ2}m

1 }m

p
→

1 − Z −
Z +
1
Z2

= E[F ]

(14)

as required.

B.3 DETAILS ABOUT EQUATION (1)

Any probabilistic program deﬁnes a ‘density’ function in the form of Equation (1). This deﬁnition makes sense for a large
class of programs, permitting branching on random variables, higher-order functions, recursion, stochastic memoization,
and conditioning on internally sampled variables [Rainforth, 2017, §4.3]. However, for this function to correspond to a valid
unnormalized probability density we need to assume that a) the program halts with probability 1 and b) that the integral over
the entire domain of γ with respect to the implicitly deﬁned reference measure is ﬁnite, i.e. Z = (cid:82)
X γ(x1:n)dµ(x1:n) < ∞
where µ is the reference measure and X denotes the space of valid program traces.

We further need to clarify our usage of the term ‘density function.’ In general, probabilistic programs denote measures (or
kernels if there are free variables) [Kozen, 1979, Staton et al., 2016, Borgström et al., 2011]. When we talk about the density
function of a probabilistic program, formally we are referring to the Radon-Nikodym derivative of the measure denoted by
this program with respect to an appropriate reference measure, where this reference measure is itself implicitly deﬁned by
the program.

C ESTIMATING EXPECTATIONS IN TURING

C.1 STANDARD APPROACH

@model function model(y=2)
x ∼ Normal(0, 1)
y ∼ Normal(x, 1)

end

num_samples = 1000
posterior_samples = sample(model(), NUTS(0.65), num_samples)

f(x) = x^3
posterior_x = Array(posterior_samples[:x])
expectation_estimate = mean(map(f, posterior_x))

Full example of the estimation of an expectation with the Turing language. The user ﬁrst deﬁnes the model, then conditions
it on some observed data, computes posterior samples and then uses these samples to compute a Monte Carlo estimate of the
expectation.

C.2 USING GENERATED QUANTITIES FUNCTION

When we designed the API Turing largely ignored the return statements in the model deﬁnition. In the meantime Turing
introduced a convenience function generated_quantities. Given a model and N samples it returns a list of the N
return values generated by running the program on each sample. Note that generated_quantities reruns the entire
model function for each posterior sample to compute the return value. This means that for models which have an expensive
likelihood computation the use of generated_quantities might incur a signiﬁcant overhead.

It is important to note that generated_quantities is merely a convenience function and does not change how Turing
interprets model deﬁnitions. In fact, the generated_quantities function provides complimentary functionality and
Turing models generated with EPT can use this function without problems.

The example from Section C.1 can be rewritten to use generated_quantities:

@model function model(y=2)
x ∼ Normal(0, 1)
y ∼ Normal(x, 1)
return x^3

end

num_samples = 1000
posterior_samples = sample(model(), NUTS(0.65), num_samples)

expectation_estimate = mean(generated_quantities(model(), posterior_samples))

D FULL EXAMPLE OF MACRO TRANSFORMATION

The expectation

@expectation function expt_prog(y)

x ∼ Normal(0, 1)
y ∼ Normal(x, 1)
return x^3

end

gets transformed into

@model function gamma1_plus(y)

x ∼ Normal(0, 1)
y ∼ Normal(x, 1)
tmp = x^3
if _context isa Turing.DefaultContext
@addlogprob!(log(max(tmp, 0)))

end
return tmp

end

@model function gamma1_minus(y)

x ∼ Normal(0, 1)
y ∼ Normal(x, 1)
tmp = x^3
if _context isa Turing.DefaultContext

@addlogprob!(log(-min(tmp, 0)))

end
return tmp

end

@model function gamma2(y)
x ∼ Normal(0, 1)
y ∼ Normal(x, 1)
return x^3

end

expt_prog = Expectation(

gamma1_plus,
gamma1_minus,
gamma2

)

The type Expectation is simply used to have one common object which stores the three different Turing models. Notice
that for gamma2 the function body is identical to the original function.

For gamma1_plus and gamma1_minus we also have to check in what _context the model is executed in. Turing allows
to execute the model with different contexts which change the model behaviour. For example, there is a PriorContext
which essentially ignores the tilde statements which have observed data on the LHS. This is useful for evaluating the prior
probability of some parameters. However, by default the @addlogprob macro ignores the model context. As a consequence
if a Turing model includes an @addlogprob macro and is executed with a PriorContext then it no longer calculates the
log prior probability but instead the log prior probability plus whatever value was added with the @addlogprob statement.
Since we want to use the Turing model with Annealed Importance Sampling we need to be able to extract the prior from our
model and hence we need to ensure that we do not call @addlogprob when executed in a PriorContext. This is what the
added if clause ensures.

E DIFFERENT ESTIMATORS FOR Z +

1 , Z −

1 AND Z2

The target function f (x) = x2 in the following expectation is always positive:

@expectation function expt_prog(y)

x ∼ Normal(0, 1)
y ∼ Normal(x, 1)
return x^2

end

Therefore, we already know that Z −

1 = 0, so it would be wasteful to spend computational resources on estimating Z −

1 . EPT

allows users to specify the marginal likelihood estimator for each of the terms in TABI separately which means if the user
knows that the target function is always positive they can specify that 0 samples should be used to estimate Z −
1 :
expct_estimate, diagnostics = estimate_expectation(

expt_prog(2), TABI(

TuringAlgorithm(AnIS(), num_samples=1000), # Z +
1
# Z −
TuringAlgorithm(AnIS(), num_samples=0),
1
TuringAlgorithm(AnIS(), num_samples=1000)
# Z2

))
It is easy to see how this can be adapted to the case in which we have Z +
1 = 0. This interface is not just useful for avoiding
unnecessary computation, in some cases the user might also want to have different marginal likelihood estimators for each
term. This allows user to further tailor the inference algorithm for the given target function f (x).

F HYPERPARAMETERS FOR EXPERIMENTS

EPT runs standard annealed importance sampling twice: one time to estimate Z +
1 and the other time to estimate Z2. For
each of the problems we always use the same hyperparameters for the annealed importance sampling algorithm both to run
AnIS and for the two estimates in EPT.

F.1 POSTERIOR PREDICTIVE

For the annealed importance sampling, we use a MH transition kernel with an isotropic Gaussian with covariance 0.5I as
a proposal and 5 MH steps on each annealing distribution. We use 100 uniformly spaced annealing distributions. For the
MCMC, we collect 5 · 107 samples in total. To parallelise sampling we run 5 · 103 chains with 104 samples each in parallel,
discarding the ﬁrst 103 samples as burn-in. We use a MH transition kernel with standard normal proposal.

F.2 SIR MODEL

For the annealed importance sampling estimators we use HMC transition kernels with a step size of 0.05, 10 leapfrog steps
and 10 MCMC steps on each annealing distribution. We use 100 geometrically spaced annealing distributions.

For the MCMC model we collect 106 samples in total with Turing’s implementation of NUTS and a target acceptance rate
of 65%.1 We parallelise sampling over 102 chains with 104 samples and discard the ﬁrst 103 samples as burn-in.

The ground truth is computed using importance sampling with 108 samples and the prior as a proposal distribution. See
Equation (15) for the full SIR model including the priors. The observed data was generated from the model described in (15)
with β = 0.25, I0 = 100, N = 104 and φ = 10 as the overdispersion parameter of the SIR model. We generate data for 15
time steps.

F.3 RADON MODEL

We run EPT and AnIS with 200 intermediate distributions and one step of the dynamic HMC transition kernel [Betancourt,
2018, Hoffman and Gelman, 2014] on each intermediate distribution with a step size of 0.044. The step size was informed
by running adaptive MCMC on the target distribution.

G SIR EXPERIMENT

We assume we are given data in the form of observations yi, the number of observed newly infected people on day i. Fixing
γ = 0.25, this gives us the statistical model

β ∼ TruncatedNormal(2, 1.52, [0, ∞]),
S0 = 10000 − I0,
x = ODESolve(β, γ, S0, I0, R0),

I0 ∼ TruncatedNormal(100, 1002, [0, 10000]),
R0 = 0,
yi ∼ NegativeBinomial(µ = xi, φ = 0.5).

(15a)

(15b)

(15c)

1https://turing.ml/dev/docs/library/#Turing.Inference.NUTS

Here ODESolve indicates a call to a numerical ODE solver which solves the set of equations (4). It outputs xi, the predicted
number of newly infected people on day i. We assume the observation process is noisy and model it using a negative
binomial distribution, which is parametrised by a mean µ and an overdispersion coefﬁcient φ. For an in-depth discussion
about doing Bayesian parameter inference in the SIR model we refer the reader to the case study of Grinsztajn et al. [2020].

We are further given a cost function in terms of R0, cost(R0) = 1012 ∗ logistic(10R0 − 30). Intuitively, the cost initially
increases exponentially with R0. However, the total cost also saturates for very large R0 (as the entire population becomes
infected).

H HIERARCHICAL RADON MODEL

The data for this problem was taken from: https://github.com/pymc-devs/pymc-examples/blob/main/
examples/data/radon.csv (the repository uses an MIT license; the data contains no personally identiﬁable infor-
mation). The original data contains information about houses in 85 counties. In order to make estimating normalization
constants more tractable we reduce the number of counties to 20.

Our target function is a function of predicted radon levels yi for a typical house with a basement (i.e. xi = 0) in county i; yi
is calculated using the predictive equation given in (7). We apply the function

f (yi) =

1
1 + exp(5(yi − 4))

to all the predicted radon levels and then take the product of all the fi. Finally, to avoid ﬂoating point underﬂow we set a
minimum value of 1e−200.

I MULTIPLE EXPECTATIONS AND RESTRICTIONS ON f (·)

The user is not restricted to deﬁning only one expectation per model. By specifying multiple return values the user can specify
multiple expectations. The @exptectation macro can recognise multiple return values and generates an expectation for
each of them. The user can then estimate each expectation independently using estimate_expectation:

@expectation function expt_prog(y)

x ∼ Normal(0, 1)
y ∼ Normal(x, 1)
return x, x^2, x^3

end
y_observed = 3
expt_prog1, expr_prog2, expt_prog3 = expt_prog
expct1 = expt_prog1(y_observed)
expct1_estimate, diagnostics = estimate_expectation(

expct1, method=TABI(marginal_likelihood_estimator=TuringAlgorithm(

AnIS(), num_samples=1000)))

J POSTERIOR PREDICTIVE MODEL IN EPT

The expectation from Section 5.1 can be deﬁned in just 5 lines of code with EPT:

@expectation function expt_prog(y)

x ∼ MvNormal(zeros(length(y)), I)
y ∼ MvNormal(x, I)
return pdf(MvNormal(x, 0.5*I), -y)

end

# x ∼ N (x; 0, I)
# y ∼ N (y; x, I)
# f (x) = N (−y; x, 1

2 I)

K SYNTAX DESIGN

Prior works have considered two families of syntax design corresponding to the semantics required by EPT. Gordon et al.
[2014] deﬁne the semantics for expectation computation via the syntax of probabilistic program’s return expression, which

is the approach we adopted in the design of EPT. Zinkov and Shan [2017] take a different route and deﬁne the expectation
semantics via the use of syntax expect(m, f) where m is the program deﬁning a measure and f is the target function.

While designing the interface of EPT we considered two different design for deﬁning the target function: either letting users
specify the target function implicitly through the return values of the function or allowing users to specify a target function f
externally. The external function could then be passed to the estimate_expectation function explicitly.

For EPT, we decided to adopt the former of the two designs mainly due to the simplicity of the resulting user interface and
implementation. In particular, it allows for simple to execute program transformations of the @expectation macro into
valid Turing programs to represent the individual densities, and thus the ability to use native Turing inference algorithms.
Adopting the other approach would additionally require designing and specifying the interface between the function signature
f(.) and the values of the named random draws performed by the model m. This would result in a more complex user-facing
interface, at the slight advantage of improved compositionality of models and functions.

L SIR DISCUSSION

(a) MCMC samples.

(b) MCMC samples including burn-in samples (in black).

(c) AnIS samples.

(d) EPT samples for Z1.

Figure 6: Samples from the different algorithms for the SIR model. Note that for Figure 6b some burn-in samples lie outside
the boundaries of the plot but we adjusted the axis limits so that they are the same for all plots to allow for easier comparison.

In the SIR experiment AnIS achieved a signiﬁcantly lower RSE than MCMC even though both are non-target-aware. Figure 6
shows samples from the different algorithms. The EPT samples for Z1 visualise well in which regions of parameter space
both the posterior and the target function have sufﬁcient mass (β ∈ [0.5, 2.0]). The samples from AnIS and MCMC suggest
that most of the posterior mass is located in the interval β ∈ [0.3, 0.7]. However, AnIS also generates a signiﬁcant amount
of samples in the parameter region β ∈ [1.0, 1.5]. The samples in this second “mode” are directly in the region of the
target-aware samples. Further, the plots suggest that AnIS generates more samples in this regions than MCMC which is
what allows AnIS to achieve a lower RSE. However, it seems that the AnIS represents the second “mode” disproportionally.

Speciﬁcally looking at the burn-in samples from MCMC in Figure 6b shows that MCMC will converge to the parameter
space in β ∈ [0.3, 0.7] even if the initial parameter samples are around β ∈ [1.0, 1.5]. This indicates that this is not a failure
of MCMC to detect another mode but rather that there is negligible posterior mass in that parameter region. Therefore the
better performance of AnIS compared to MCMC seems to occur mostly because AnIS got lucky by accidentally generating
samples in the right parameter region.

L.1 A NOTE ON MCMC ESS

The SIR experiment provides a good example of how the MCMC ESS [Vehtari et al., 2020] is unreliable for our use
case. As detailed in Section F.2 for MCMC we run 100 chains with 10, 000 samples each. This is replicated 5 times to get
estimates on the variability in behaviour. After discarding the burn-in samples for each chain the 5 replications give us the
following ﬁnal ESS estimates: [631, 360; 805, 868; 873, 269; 665, 683; 5, 114]. We observe that all but one replication give
disproportionally high ESS estimates. We found that the replication which gives a more conservative ESS estimate of 5, 114
is the replication which generated samples in the parameter region β ∈ [1.0, 1.5] (see Figure 6a). More importantly, the
MCMC ESS estimates do not seem to show any correlation with the RSE values (see Figure 4) which is the more important
metric because it directly measures the error in our estimate. Therefore, we decided against using the MCMC ESS in our
evaluation because it can give the impression that MCMC is performing well when it is actually failing dramatically (in
terms of RSE).

L.2 ADDITIONAL STAN MCMC BASELINE

Table 2: Quantiles of the RSE for different methods (the same performance
metric as Figure 4, left); computed over 5 runs.

To validate our MCMC baseline we reim-
plemented the SIR model
in Stan and
used Stan’s built-in default MCMC sam-
pler. We expressed the expectation within the
generated_quantities block leverag-
ing the functionality described in Section 4.
We have picked Stan because its built-in
MCMC sampler can be reasonably consid-
ered the state-of-the-art in its domain and has
been extensively tested for correctness. As
shown in Table 2, Stan gives results that are
similar to our current MCMC baseline (and potentially even a little worse). This demonstrates that the differences between
existing PPSs are negligible compared to the effect of making inference target-aware.

EPT
ANIS
MCMC (TURING)
MCMC (STAN)

8.10e−6
0.13
0.97
1.00

2.92e−4
0.15
0.97
1.00

2.96e−6
0.02
0.96
1.00

25% QUANTILE MEDIAN

75% QUANTILE

METHOD

M EFFECTIVE SAMPLE SIZE

In Figure 7 we plot all the individual ESS values for EPT and the AnIS baseline. Plotting each ESS value separately shows
that the performance of AnIS is severely limited by its ability to generate samples in regions in which the target function
f (x) is large. This is indicated by the low values for ESSAnIS
Z1 .

(a) Gaussian Posterior Predictive.

(b) SIR.

(c) Radon.

Figure 7: Individual ESS values as deﬁned in Section 5 for the three different experiments. Instead of taking
min(ESSZ1 , ESSZ2 ) for EPT and min(ESSAnIS
Z1

) for AnIS we plot each value individually.

, ESSAnIS
Z2

N POSITIVE AND NEGATIVE TARGET FUNCTIONS

To demonstrate that EPT is also beneﬁcial for target functions which are positive and negative we provide a brief description
of a synthetic experiment. We assume the following model which gives us a banana shaped density (see Figure 8):

@expectation function banana()

x1 ∼ Normal(0, 4)
x2 ∼ Normal(0, 4)
@addlogprob!(banana_density(x1, x2))
return banana_f(x1, x2)

end

banana_density(x1, x2) = -0.5*(0.03*x1^2+(x2/2+0.03*(x1^2-100))^2)

Note that there is no observed data in this experiment which is why we chose to express the banana distribution as an
unnormalized density (i.e. use the @addlogprob! primitive). Our target function is given by

function banana_f(x1, x2)

cond = 1 / (1 + exp(50 * (x2 + 5)))
return cond * (x1 - 2)^3

end

Note that the target function can be positive and negative. Figure 8 shows the RSE for EPT and AnIS. We used an MH
transition kernel and 200 intermediate potentials for the Annealed Importance Sampling estimators. The RSE of AnIS does
not improve because it fails to generate samples in the regions in which the target f (x) is large. Rainforth et al. [2020]
provide a comparison to MCMC on a similar problem so we omit it here.

Figure 8: Banana experiment. [Left] Heatmap of the density of the model. [Right] Relative Squared Error for EPT and AnIS.

References

Michael Betancourt. A Conceptual Introduction to Hamiltonian Monte Carlo, 2018.

Johannes Borgström, Andrew D Gordon, Michael Greenberg, James Margetson, and Jurgen Van Gael. Measure transformer
semantics for bayesian machine learning. In European Symposium on Programming, pages 77–96. Springer, 2011.

M. Hoffman and A. Gelman. The No-U-turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo.

Journal of Machine Learning Research, 15:1593–1623, 2014.

Dexter Kozen. Semantics of probabilistic programs. In 20th Annual Symposium on Foundations of Computer Science (sfcs

1979), pages 101–114. IEEE, 1979.

Radford M. Neal. Annealed Importance Sampling. Statistics and Computing, 11(2):125–139, April 2001. ISSN 0960-3174.

doi: 10.1023/A:1008923215028. URL https://doi.org/10.1023/A:1008923215028.

Tom Rainforth.

Inference, Learning,
http://purl.org/dc/dcmitype/Text, University of Oxford, 2017.

Automating

and Design Using Probabilistic Programming.

Sam Staton, Frank Wood, Hongseok Yang, Chris Heunen, and Ohad Kammar. Semantics for Probabilistic Programming:
Higher-Order Functions, Continuous Distributions, and Soft Constraints. In 2016 31st annual acm/ieee symposium on
logic in computer science (lics), pages 1–10. IEEE, 2016.

The Turing Development Team. TuringLang/AdvancedMH.jl. The Turing Language, October 2020. URL https:

//github.com/TuringLang/AdvancedMH.jl.

Aki Vehtari, Andrew Gelman, Daniel Simpson, Bob Carpenter, and Paul-Christian Bürkner. Rank-Normalization, Folding,
and Localization: An Improved (cid:98)R for Assessing Convergence of MCMC. Bayesian Analysis, 2020. doi: 10.1214/
20-BA1221.

Kai Xu, Hong Ge, Will Tebbutt, Mohamed Tarek, Martin Trapp, and Zoubin Ghahramani. AdvancedHMC.jl: A Robust,
Modular and Efﬁcient Implementation of Advanced HMC Algorithms. In Symposium on Advances in Approximate
Bayesian Inference (AABI), pages 1–10. PMLR, February 2020.

