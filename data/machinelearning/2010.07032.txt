0
2
0
2

v
o
N
7
2

]

O
C
.
h
p
-
o
r
t
s
a
[

2
v
2
3
0
7
0
.
0
1
0
2
:
v
i
X
r
a

Targeted Likelihood-Free Inference of Dark Matter
Substructure in Strongly-Lensed Galaxies

Adam Coogan1
a.m.coogan@uva.nl

Konstantin Karchev1, 2
kkarchev@sissa.it

Christoph Weniger1
c.weniger@uva.nl

1Gravitation Astroparticle Physics Amsterdam (GRAPPA)
Institute for Theoretical Physics (ITFA)
University of Amsterdam, Science Park 904, 1098 XH Amsterdam, The Netherlands

2SISSA (Scuola Internazionale Superiore di Studi Avanzati)
via Bonomea 265, I-34136 Trieste, Italy.

Abstract

The analysis of optical images of galaxy-galaxy strong gravitational lensing sys-
tems can provide important information about the distribution of dark matter at
small scales. However, the modeling and statistical analysis of these images is
extraordinarily complex, bringing together source image and main lens recon-
struction, hyper-parameter optimization, and the marginalization over small-scale
structure realizations. We present here a new analysis pipeline that tackles these di-
verse challenges by bringing together many recent machine learning developments
in one coherent approach, including variational inference, Gaussian processes,
differentiable probabilistic programming, and neural likelihood-to-evidence ra-
tio estimation. Our pipeline enables: (a) fast reconstruction of the source image
and lens mass distribution, (b) variational estimation of uncertainties, (c) efﬁcient
optimization of source regularization and other hyperparameters, and (d) marginal-
ization over stochastic model components like the distribution of substructure. We
present here preliminary results that demonstrate the validity of our approach.

1

Introduction

The existence of dark matter, its overall abundance and its distribution at galactic scales are reason-
ably well-understood thanks to its gravitational interactions. However, determining the properties
of the fundamental constituents of dark matter remains one of the major unresolved issues in
physics [Bertone et al., 2005].

Detection of the smallest dark matter structures on subgalactic scales is a potential inroad. In the
standard ΛCDM model of cosmology, dark matter is cold and noninteracting. As a result, n-body
simulations predict that galactic dark matter halos should contain exponentially-many lower-mass
substructures called subhalos. The subhalo mass function dn/dm describing the number of subhalos
at a given mass can be different if dark matter is instead warm or has nongravitational interactions. In
these theories, overdensities below a particular threshold are unable to collapse into subhalos, and the
subhalo mass function drops to zero below some threshold (see e.g. Viel et al. [2013], Schneider et al.
[2012]).

Third Workshop on Machine Learning and the Physical Sciences (NeurIPS 2020), Vancouver, Canada.

 
 
 
 
 
 
Since star formation is suppressed in subhalos with mass below ∼ 109 M
, it is difﬁcult to detect light
from these halos directly. Instead, searching for their gravitational effects is a promising approach.
In this work we study strong galaxy-galaxy gravitational lenses, where a source galaxy’s light is
dramatically distorted and multiply imaged by an intervening lens galaxy. The gravitational inﬂuence
of subhalos imprints additional percent-level perturbations on the resulting observed image. To date,
analyses of these systems have yielded two subhalo detections [Vegetti et al., 2010, 2012]

(cid:12)

Fitting a lensing system and properly marginalizing over variations in the source, lens and subhalos
to constrain properties of substructure is an extremely difﬁcult problem. This is due to the dramatic
range of possible source galaxy light distributions and the large number of parameters that must
be marginalized over in realistic lensing models in order to perform substructure inference. On
one hand, methods such the one in Vegetti and Koopmans [2009] use Bayesian lensing models
to closely ﬁt lensing observations and conventional sampling methods to compute posteriors for
subhalo parameters. However, conventional sampling methods require sampling from the joint
posterior over all model parameters. These methods are thus restricted to searching for effects
from one or two subhalos. On the other hand, since many works have shown neural networks have
the capacity to measure main lens parameters [Hezaveh et al., 2017, Morningstar et al., 2019] and
detect subhalos [Diaz Rivero and Dvorkin, 2020, Ostdiek et al., 2020a,b], Brehmer et al. [2019]
leveraged them through likelihood-free inference to marginalize over large numbers of subhalos and
directly compute marginal posteriors for subhalo mass function parameters. However, this approach
is extremely data-hungry when applied to even toy problems, since it requires amortizing over all
possible variations in lensing systems.

In this work we merge the strengths of both approaches to perform targeted inference on individual
lensing systems. In the ﬁrst stage of our analysis, we introduce a new model for lensing systems
that describes the source light distribution using an approximate Gaussian process [Rasmussen and
Williams, 2006]. By implementing this in an automatically-differentiable manner and leveraging
variational inference [Saul et al., 1996, Jordan et al., 1999, Hoffman et al., 2013, Bishop, 2006], we
ﬁt approximate posteriors for all O(105) source and lens parameters to an observation using gradient
descent. By sampling from this approximate posterior, we generate training data that looks very
similar to the observation. In the second analysis step, we use this data to train neural networks using
the tools of likelihood-free inference to produce posterior distributions for substructure parameters.
Applying these networks to the observation of interest yields inference results.

In the remainder of this paper, we describe our new model for lensing systems, our inference proce-
dure, and present results from analyzing a mock lensing system. In upcoming work we will elaborate
on our new source model [Karchev et al., 2020] and substructure inference approach [Coogan et al.,
2020].

2 Modeling

Here we present a ﬂexible Bayesian lensing model that has the capacity to model complex, high-
resolution images and can be ﬁt using gradient descent. The base model has three components: a lens,
with parameters denoted zl, a source, parametrized by zs, and the instrument response, which here is
simply pixel noise assumed to be normally distributed with known standard deviation. Ultimately,
we consider all of the parameters of the base model as nuisance parameters that we will need to
marginalise out in order to infer an additional set of lens dark matter substructure parameters (e.g.
the position and mass of a single subhalo, as we present below), denoted zd.

The lens models the presence of gravitating mass along the line of sight which bends the path of light
(see ﬁg. 3). In the thin lens formalism this process is described by the lens equation (cid:126)p = (cid:126)ξ − (cid:126)α((cid:126)ξ),
which relates image plane coordinates (cid:126)ξ to source plane coordinates (cid:126)p via the displacement ﬁeld (cid:126)α.
These are all arrays of N 2-dimensional vectors, where N is the number of pixels in the analysed
image. The displacement (cid:126)α is a linear function of the overall projected mass distribution Σ((cid:126)ξ)
in the image plane, which means that different mass components can be freely superposed. The
displacement due to even a single component, however, can be a complex function of position, and in
images of interest leads to the projection of disjoint sections of the image onto the same region in the
source plane.

2

We include two smooth analytic components for the lens: a singular power-law ellipsoid (SPLE) for
the main lens galaxy and external shear (see e.g. Chianese et al. [2020] for the displacement ﬁelds).
This model has previously been used to model observational data and has been shown capable of
modeling the combined distribution of dark and baryonic matter in the inner regions of galaxies at
the percent level [Suyu et al., 2009]. It contains a total of eight parameters, which form zl.

We use a novel approach to modeling the sources in strongly lensed systems which has two main
aims: to have a regularising effect so that the lens parameters can be constrained, and to treat source
uncertainties so that they can be disentangled from the effect of lensing substructure. This is achieved
with a generative model inspired by Gaussian processes, brieﬂy described as:

f = T((cid:126)p, σ) y, with y ∼ N (0, α2).
Here y is an array of N ﬂux parameters associated to the image pixels and assumed to have a
Gaussian prior, while T is a transfer matrix, deﬁned below such that the true source ﬂuxes f have
a given covariance K = α2TTT . We use a Gaussian radial basis function to model the covariance
between ﬂuxes at two points in the source plane:

(1)

cov(f ((cid:126)p1), f ((cid:126)p2)) = k((cid:126)p1, (cid:126)p2) = α2 exp

−

(cid:32)

|(cid:126)p1 − (cid:126)p2|2
2σ2

(cid:33)
.

(2)

Its hyperparameters are α2 and σ, describing respectively the prior variance and the correlation scale
in the source plane.

However, we are interested in the covariance matrix of the light received in pixels, not at points.
This depends on the intrinsic covariance between different points in the source (captured by eq. (2))
as well as the covariance due to the overlap between pixels projected back into the source plane.
Accounting for this requires integrating eq. (2) over the overlap between each pair of back-projected
pixels. Since this is extremely slow to compute exactly, we approximate each back-projected pixel
using a 2D Gaussian (see ﬁg. 4): gi((cid:126)p) = G((cid:126)p − (cid:126)pi, Σi), with covariance matrix Σi derived to match
the shape and total area of the pixel. Then the covariance matrix becomes

cov(f )ij = Kij =

(cid:90) (cid:90)

k((cid:126)p1, (cid:126)p2) gi((cid:126)p1)gj((cid:126)p2) d2(cid:126)p2 d2(cid:126)p2 = 2πα2σ2G((cid:126)pi−(cid:126)pj, Σi+σ2I+Σj). (3)

Usually, one needs to calculate the transfer matrix T from K by e.g. matrix square root or Cholesky
decomposition, but due to the high dimensionality of the problem these operations are infeasible.
Instead, we realise that the outer product TTT is akin to a spatial convolution, and that the convolution
of a Gaussian with itself is a Gaussian with twice the variance, which allows us to approximate
Tik ∼ G((cid:126)pi − (cid:126)pk, Σi + σ2
2 I). The proper normalisation depends on the number density of pixels in
the source plane; we give a full derivation in Karchev et al. [2020].

Finally, instead of allowing the kernel size to vary, we consider a number of independent GP layers
with ﬁxed σ(k) ranging from galaxy- to pixel-size in order to model details on various scales. Each
layer thus has an independently-optimised array of ﬂux parameters y(k) and overall variance α2
(k). The
collection of all y(k) forms the source parameter array zs, which together with the hyperparameters
α2

(k) are optimized variationally.

We implement our lensing model using the pytorch and pykeops libraries, which ensures the model
output is automatically-differentiable with respect to all (hyper)parameters: zl, zs, α2
(k), and enables
us to perform all calculations on graphical processing units.

3 Statistical analysis

The overall analysis strategy splits in two steps.

1. Fit an approximate posterior qφ(zs, zl|x0) for the lens and source parameters zl and zs to
an observation x0 using variational inference, simultaneously optimizing the GP hyperpa-
rameters θ = {α2

(k)}.

2. Sample data from this constrained model to train an inference network to predict p(zd|x0),

the marginal posterior for substructure parameters zd for the observation.

3

Variational inference We approximate the posterior over the source and lens parameters with a
multivariate normal distribution over the lens parameters and a diagonal normal distribution over the
source parameters:

qφ(zl, zs|x0) = Gφl (zl) Nφs(zs),
(4)
where φ = {φl, φs} denote the distribution’s mean and covariance parameters. This approximation is
justiﬁed since all parameters are reasonably well-constrained. While it neglects source parameter
correlations, the diagonal normal guide for the O(105) source parameters is necessary since the
matrix inversion required for standard GP inference [Rasmussen and Williams, 2006] is prohibitively
expensive. Since close-by source parameters are in general anti-correlated, we ﬁnd that the neglect of
correlations increases the variance of the posterior predictive distribution, which is consistent with
the goal of using samples from the ﬁtted model for training targeted neural inference networks. We
leave a quantitative study of these effects to future work.

In order to optimize the above approximate posterior with respect to φ and also optimize the GP
hyperparameters, we use gradient descent to maximize the evidence lower bound (ELBO) [Saul
et al., 1996, Jordan et al., 1999, Bishop, 2006, Hoffman et al., 2013] for the observation,
Ez
x0) [ln pθ(x0, z) − ln qφ(z|x0)]. To this end, we use the probabilistic programming lan-
|
guage pyro, and the auto-differentiation capabilities of pytorch.

qφ(z

∼

Likelihood-free inference Next we seek the posterior p(zd|x0) for the substructure parameters,
marginalized over the lens and source parameters η ≡ {zl, zs}. The integral over η is intractible
since it is very high-dimensional and the integrand is a complex nonlinear function. Instead, we
approximate p(zd|x0) using neural likelihood-to-evidence ratio estimation techniques [Hermans
et al., 2019].

The strategy is to estimate the ratio r(x, zd) ≡ p(z|x)/p(z), from which the marginal posterior is
easily recovered. To do this we train a classiﬁcation network d(x, zd) ∈ [0, 1] to discriminate the
hypotheses. In the ﬁrst, the data and substructure parameters are drawn jointly from the parameter
priors and model: x, zd ∼ p(x, zd). In the second, the data and substructure parameters are sampled
marginally: x, zd ∼ p(x)p(zd). We adopt the binary cross-entropy loss function and optimize
the parameters of the classiﬁcation network using gradient descent. After this we can compute
r(x0, zd) = d(x0, zd)/(1 − d(x0, zd)) and obtain the substructure parameter posteriors for the
observation of interest.

Formally, marginalizing over the source and lens requires training the classiﬁcation network on all
observationally possible lensing images. Framing this in terms of our lensing model, generating this
training dataset requires sampling the lens, source and substructure parameters from their priors,
computing the lensed image µ, and generating an observation by adding Gaussian pixel noise with
standard deviation σn:

x ∼ N (x|µ(zl, zs, zd), σn) p(zl) p(zs) p(zd).

(5)

Since we eventually are interested in sub-percent variations in the images, this is an extraordinarily
complex endeavor, which would require a very large amount of training data as well as a network
with very high capacity.

Instead, we propose a much simpler and more tractable approach where we target the analysis on a
particular observation by constraining the sampling of the lens and source parameters. In particular,
we sample zl, zs ∼ qφ(zl, zs|x0) rather than from their priors. This training data generation
procedure excludes lensing systems incompatible with the observation being analyzed, dramatically
decreasing the amount of data required for the classiﬁcation network, allowing us to use simple
architectures and shorter training times.

4 Results and discussion

As a preliminary test of our analysis procedure, we construct a 400 × 400 mock observation based
on the Extremely Large Telescope’s [Observatory] capabilities that contains a single ∼ 109 M
(cid:12)
subhalo. The mock observation and source are shown in ﬁg. 1, along with the mean observation and
source reconstructed with a ﬁve-layer GP source model in our ﬁrst analysis step. The observation
reconstruction closely matches the mock observation, and captures very ﬁne details in the source. The
inferred values of the lens parameters are within ∼ 0.1 − 5% of the true parameter values. For the

4

second analysis step, we train simple neural networks built from convolutional and fully-connected
layers to give 2D and 1D posteriors for the subhalo’s position and mass, marginalized over the
174,458 source and lens parameters. The resulting posteriors, obtained with just 10,000 training
examples, are shown in ﬁg. 2. Our subhalo position reconstructions are accurate, with the true
position of the subhalo in the mock observation (right column) lying within the 68% containment
region. The mass posterior is centered close to the true subhalo mass, though it is reasonably broad.
The whole analysis runs in a few hours on a single Nvidia GTX TitanX GPU.

Applying our pipeline to real data will require extending the lensing model. A more realistic version
of our lensing system would contain ∼ 320 subhalos above 105 M
within the observation region.
Dark matter halos along the line of sight are additionally expected to contribute 3 − 10 times more
lensing distortions than subhalos [Despali et al., 2018]. Lastly, we have omitted the main lens’
light. All of these components are straightforward to incorporate in our framework. In upcoming
work we will apply this extended analysis to search for subhalos and set constraints on the subhalo
mass function using existing lensing observations in future work. More generally, we anticipate our
approximate Gaussian process model and targeted likelihood-free inference strategy will ﬁnd other
exciting applications to difﬁcult astrophysical imaging and data analysis problems.

(cid:12)

Figure 1: From left to right: the mock observation, ﬁt observation, true source and ﬁt source. The
displayed ﬁts are computed using the mean estimates of the source and lens parameters from the
approximate posterior qφ(z|x). The red curves show the critical curve and caustic of the main lens.
The yellow circles indicate the spatial scales of the ﬁve Gaussian process layers, the smallest of which
is not visible here.

Figure 2: Preliminary results from our pipeline: posteriors for the subhalo position and mass for a
systems from the training/validation set (left panel), a system from a held-out test set (middle), and
the observation being analyzed (right). The purple, teal and yellow contours in the ﬁrst row show the
99.7%, 95% and 68% containment regions. The red dots indicate the true subhalo position and the
red box is the area from which the subhalos were uniformly sampled. The red lines in the second row
mark the true subhalo masses. These were obtained with only 10,000 training examples.

5

21012x [00]21012y [00]True observation21012x [00]21012Fit observation0.60.40.20.00.20.40.6x [00]0.60.40.20.00.20.40.6y [00]True source0.60.40.20.00.20.40.6x [00]0.60.40.20.00.20.40.6Fit source05101520253005101520253005101520253005101520253021012x [00]21012y [00]Train/val21012x [00]21012Test21012x [00]21012Observation8.508.759.009.259.509.7510.0010.2510.50log10MM012345Posterior density8.508.759.009.259.509.7510.0010.2510.50log10MM012348.508.759.009.259.509.7510.0010.2510.50log10MM0.000.250.500.751.001.251.50Broader Impact

This work is focusing on the precision analysis of astronomical images based on forward models.
Variants of the presented approach could be applicable to other areas of the physical sciences.
Although we do not anticipate potential for misuse of the presented methods or the danger of grossly
biased results, the usual care has to be exercised when drawing scientiﬁc conclusions based on a
complex analysis machinery.

Acknowledgments and Disclosure of Funding

We thank Marco Chianese, Camila Correa, Gilles Louppe, Ben Miller and Simona Vegetti for useful
discussions.

This work uses numpy [Harris et al., 2020], scipy [Virtanen et al., 2020], matplotlib [Hunter,
2007], pyro [Bingham et al., 2018], pytorch [Paszke et al., 2019], pykeops [Charlier et al., 2020],
jupyter [Kluyver et al., 2016] and tqdm [da Costa-Luis et al., 2020]. Computations were carried
out on the DAS-5 [Bal et al., 2016] cluster, which is funded by the Netherlands Organization for
Scientiﬁc Research (NWO/NCF).

References

H. Bal, D. Epema, C. de Laat, R. van Nieuwpoort, J. Romein, F. Seinstra, C. Snoek, and H. Wijshoff. A
medium-scale distributed system for computer science research: Infrastructure for the long term. Computer,
49(05):54–63, may 2016. ISSN 1558-0814. doi: 10.1109/MC.2016.127.

Gianfranco Bertone, Dan Hooper, and Joseph Silk. Particle dark matter: Evidence, candidates and constraints.

Phys. Rept., 405:279–390, 2005. doi: 10.1016/j.physrep.2004.08.031.

Eli Bingham, Jonathan P. Chen, Martin Jankowiak, Fritz Obermeyer, Neeraj Pradhan, Theofanis Karaletsos,
Rohit Singh, Paul Szerlip, Paul Horsfall, and Noah D. Goodman. Pyro: Deep Universal Probabilistic
Programming. Journal of Machine Learning Research, 2018.

Christopher M. Bishop. Pattern Recognition and Machine Learning, chapter 10.1, pages 461–474. Springer Sci-
ence and Business Media LLC, 2006. URL https://www.microsoft.com/en-us/research/uploads/
prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf.

Johann Brehmer, Siddharth Mishra-Sharma, Joeri Hermans, Gilles Louppe, and Kyle Cranmer. Mining
for dark matter substructure: Inferring subhalo population properties from strong lenses with machine
learning. The Astrophysical Journal, 886(1):49, nov 2019. doi: 10.3847/1538-4357/ab4c41. URL https:
//doi.org/10.3847%2F1538-4357%2Fab4c41.

Benjamin Charlier, Jean Feydy, Joan Alexis Glaunès, François-David Collin, and Ghislain Durif. Kernel
operations on the GPU, with autodiff, without memory overﬂows. arXiv preprint arXiv:2004.11127, 2020.

Marco Chianese, Adam Coogan, Paul Hofma, Sydney Otten, and Christoph Weniger. Differentiable Strong
Lensing: Uniting Gravity and Neural Nets through Differentiable Probabilistic Programming. Mon. Not. Roy.
Astron. Soc., 496(1):381–393, 2020. doi: 10.1093/mnras/staa1477.

Adam Coogan, Konstantin Karchev, Benjamin Miller, and Christoph Weniger. Precision searches for subhalos

in strong lensing images with targeted inference networks. 2020.

Casper da Costa-Luis, Stephen Karl Larroque, Kyle Altendorf, Hadrien Mary, Mikhail Korobov, Noam Yorav-
Raphael, Ivan Ivanov, Marcel Bargull, Nishant Rodrigues, Guangshuo CHEN, Charles Newey, James, Martin
Zugnoni, Matthew D. Pagel, mjstevens777, Mikhail Dektyarev, Alex Rothberg, Alexander, Daniel Panteleit,
Fabian Dill, FichteFoll, HeoHeo, Hugo van Kemenade, Jack McCracken, Max Nordlund, Orivej Desh,
RedBug312, richardsheridan, Socialery, and Staffan Malmgren. tqdm: A fast, Extensible Progress Bar for
Python and CLI, September 2020. URL https://doi.org/10.5281/zenodo.4054194.

Giulia Despali, Simona Vegetti, Simon D. M. White, Carlo Giocoli, and Frank C. van den Bosch. Modelling the
line-of-sight contribution in substructure lensing. Mon. Not. Roy. Astron. Soc., 475(4):5424–5442, 2018. doi:
10.1093/mnras/sty159.

Ana Diaz Rivero and Cora Dvorkin. Direct Detection of Dark Matter Substructure in Strong Lens Images with
Convolutional Neural Networks. Phys. Rev. D, 101(2):023515, 2020. doi: 10.1103/PhysRevD.101.023515.

6

Charles R. Harris, K. Jarrod Millman, Stéfan J. van der Walt, Ralf Gommers, Pauli Virtanen, David Cournapeau,
Eric Wieser, Julian Taylor, Sebastian Berg, Nathaniel J. Smith, and et al. Array programming with numpy.
Nature, 585(7825):357–362, Sep 2020. ISSN 1476-4687. doi: 10.1038/s41586-020-2649-2. URL http:
//dx.doi.org/10.1038/s41586-020-2649-2.

Joeri Hermans, Volodimir Begy, and Gilles Louppe. Likelihood-free MCMC with Amortized Approximate

Ratio Estimators. 3 2019.

Yashar D. Hezaveh, Laurence Perreault Levasseur, and Philip J. Marshall. Fast Automated Analysis of Strong
Gravitational Lenses with Convolutional Neural Networks. Nature, 548:555–557, 2017. doi: 10.1038/
nature23463.

Matthew D. Hoffman, David M. Blei, Chong Wang, and John Paisley. Stochastic variational inference. Journal of
Machine Learning Research, 14(4):1303–1347, 2013. URL http://jmlr.org/papers/v14/hoffman13a.
html.

J. D. Hunter. Matplotlib: A 2d graphics environment. Computing in Science & Engineering, 9(3):90–95, 2007.

doi: 10.1109/MCSE.2007.55.

Michael I. Jordan, Zoubin Ghahramani, and et al. An introduction to variational methods for graphical models.

In MACHINE LEARNING, pages 183–233. MIT Press, 1999.

Konstantin Karchev, Adam Coogan, and Christoph Weniger. Strong-lensing source reconstruction with differen-

tiable probabilistic programming. 2020.

Thomas Kluyver, Benjamin Ragan-Kelley, Fernando Pérez, Brian Granger, Matthias Bussonnier, Jonathan
Frederic, Kyle Kelley, Jessica Hamrick, Jason Grout, Sylvain Corlay, Paul Ivanov, Damián Avila, Saﬁa
Abdalla, and Carol Willing.
Jupyter notebooks – a publishing format for reproducible computational
workﬂows. In F. Loizides and B. Schmidt, editors, Positioning and Power in Academic Publishing: Players,
Agents and Agendas, pages 87 – 90. IOS Press, 2016.

Warren R. Morningstar, Laurence Perreault Levasseur, Yashar D. Hezaveh, Roger Blandford, Phil Marshall,
Patrick Putzky, Thomas D. Rueter, Risa Wechsler, and Max Welling. Data-Driven Reconstruction of
Gravitationally Lensed Galaxies using Recurrent Inference Machines. 1 2019. doi: 10.3847/1538-4357/
ab35d7.

European Southern Observatory. Eso - e-elt instrumentation. https://www.eso.org/sci/facilities/

eelt/instrumentation/phaseA.html. Accessed 2020-09-30.

Bryan Ostdiek, Ana Diaz Rivero, and Cora Dvorkin. Detecting Subhalos in Strong Gravitational Lens Images

with Image Segmentation. 9 2020a.

Bryan Ostdiek, Ana Diaz Rivero, and Cora Dvorkin. Extracting the Subhalo Mass Function from Strong Lens

Images with Image Segmentation. 9 2020b.

Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen,
Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary De-
Vito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith
Chintala. Pytorch: An imperative style, high-performance deep learning library. In H. Wallach, H. Larochelle,
A. Beygelzimer, F. d’Alché Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing
Systems 32, pages 8024–8035. Curran Associates, Inc., 2019. URL http://papers.neurips.cc/paper/
9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf.

Carl Edward Rasmussen and Christopher K. I. Williams. Gaussian Processes for Machine Learning. MIT Press,

2006.

Lawrence K. Saul, Tommi S. Jaakkola, and Michael I. Jordan. Mean ﬁeld theory for sigmoid belief networks.

CoRR, cs.AI/9603102, 1996. URL https://arxiv.org/abs/cs/9603102.

Aurel Schneider, Robert E. Smith, Andrea V. Maccio, and Ben Moore. Nonlinear Evolution of Cosmological
Structures in Warm Dark Matter Models. Mon. Not. Roy. Astron. Soc., 424:684, 2012. doi: 10.1111/j.
1365-2966.2012.21252.x.

S.H. Suyu, P.J. Marshall, R.D. Blandford, C.D. Fassnacht, L.V.E. Koopmans, J.P. McKean, and T. Treu.
Dissecting the Gravitational Lens B1608+656: Lens Potential Reconstruction. Astrophys. J., 691:277–298,
2009. doi: 10.1088/0004-637X/691/1/277.

7

S. Vegetti and L.V.E. Koopmans. Bayesian Strong Gravitational-Lens Modelling on Adaptive Grids: Objective
Detection of Mass Substructure in Galaxies. Mon. Not. Roy. Astron. Soc., 392:945, 2009. doi: 10.1111/j.
1365-2966.2008.14005.x.

S. Vegetti, L.V.E. Koopmans, A. Bolton, T. Treu, and R. Gavazzi. Detection of a Dark Substructure through
Gravitational Imaging. Mon. Not. Roy. Astron. Soc., 408:1969, 2010. doi: 10.1111/j.1365-2966.2010.16865.x.

S. Vegetti, D.J. Lagattuta, J.P. McKean, M.W. Auger, C.D. Fassnacht, and L.V.E. Koopmans. Gravitational
detection of a low-mass dark satellite at cosmological distance. Nature, 481:341, 2012. doi: 10.1038/
nature10669.

Matteo Viel, George D. Becker, James S. Bolton, and Martin G. Haehnelt. Warm dark matter as a solution to the
small scale crisis: New constraints from high redshift Lyman-α forest data. Phys. Rev. D, 88:043502, 2013.
doi: 10.1103/PhysRevD.88.043502.

Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni
Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, Stéfan J. van der Walt, Matthew Brett, Joshua
Wilson, K. Jarrod Millman, Nikolay Mayorov, Andrew R. J. Nelson, Eric Jones, Robert Kern, Eric Larson,
C J Carey, ˙Ilhan Polat, Yu Feng, Eric W. Moore, Jake VanderPlas, Denis Laxalde, Josef Perktold, Robert
Cimrman, Ian Henriksen, E. A. Quintero, Charles R. Harris, Anne M. Archibald, Antônio H. Ribeiro, Fabian
Pedregosa, Paul van Mulbregt, and SciPy 1.0 Contributors. SciPy 1.0: Fundamental Algorithms for Scientiﬁc
Computing in Python. Nature Methods, 17:261–272, 2020. doi: 10.1038/s41592-019-0686-2.

8

Appendix

Figure 3: Geometry of strong lensing systems. The lensing mass M located at (cid:126)ξ(cid:48) bends the light
ray (thick line) emanating from the point (cid:126)x, so that to the observer it looks like it is coming from
the direction of (cid:126)ξ. General relativity predicts the deﬂection angle (cid:126)α(cid:48) as viewed from the image plane
based on the mass M and the distance (cid:126)ξ − (cid:126)ξ(cid:48). It then has to be rescaled by DLS/DS to obtain the
displacement ﬁeld (cid:126)α (as viewed by the observer). Angles are all assumed to be small enough that
they can be used for Euclidean calculations. The dashed line is the optical axis perpendicular to the
planes and connects the origins of the coordinate systems for each plane.

Figure 4: Our Gaussian approximation of pixels projected into the source plane. The projection
of two pixels onto the source plane (a). A full treatment should consider their exact shapes and
use an indicator function that is nonzero only inside the shaded areas. Instead, the projections are
approximated to ellipses deﬁned by the projections of their centers and the vectors AA(cid:48) and BB(cid:48) (b).
The indicator functions are Gaussians with covariances derived from those ellipses (c).

9

sourceplane~x~α0imageplane~ξ~α~ξ0MobserverDLDLSDSOAA0BB0