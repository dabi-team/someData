9
1
0
2

y
a
M
3
1

]
h
p
-
t
n
a
u
q
[

1
v
5
9
8
4
0
.
5
0
9
1
:
v
i
X
r
a

Data-driven inference and observational completeness of quantum devices

Michele Dall’Arno,1,

∗ Asaph Ho,1 Francesco Buscemi,2,

† and Valerio Scarani1, 3,

‡

1Centre for Quantum Technologies, National University of Singapore, 3 Science Drive 2, 117543, Singapore
2Graduate School of Informatics, Nagoya University, Chikusa-ku, 464-8601 Nagoya, Japan
3Department of Physics, National University of Singapore, 2 Science Drive 3, 117542, Singapore
(Dated: May 14, 2019)

Data-driven inference was recently introduced as a protocol that, upon the input of a set of
data, outputs a mathematical description for a physical device able to explain the data. The device
so inferred is automatically self-consistent, that is, capable of generating all given data, and least
committal, that is, consistent with a minimal superset of the given dataset. When applied to the
inference of an unknown device, data-driven inference has been shown to output always the “true”
device whenever the dataset has been produced by means of an observationally complete setup,
which plays here the same role played by informationally complete setups in conventional quantum
tomography.

In this paper we develop a uniﬁed formalism for the data-driven inference of states and measure-
ments. In the case of qubits, in particular, we provide an explicit implementation of the inference
protocol as a convex programming algorithm for the machine learning of states and measurements.
We also derive a complete characterization of observational completeness for general systems, from
which it follows that only spherical 2-designs achieve observational completeness for qubit systems.
This result provides symmetric informationally complete sets and mutually unbiased bases with a
new theoretical and operational justiﬁcation.

Introduction. — The state of a physical system is the
description of its properties, i. e., of the outcomes of ev-
ery possible measurement. Famously, for quantum sys-
tems, the outcome of most measurement is not determin-
istic, and so the state is statistical information. It is a
truism that physical properties depend on the degree of
freedom under study: measuring the polarisation of an
optical mode, the spin of a silver atom, or the energy
level of a bound electron in an atom, each requires its
own instrumentation. In the theoretical modelling, var-
ious degrees of freedom may be described by the same
Hilbert space: all of the above-mentioned could be “one
qubit”. The formalism of quantum state reconstruction,
or tomography, is then identical for all of them [1]. This
level of abstraction notwithstanding, tomography relies
on an accurate calibration of the devices:
in order to
interpret the data, one needs to know which setting of
the device is translated as (say) σx in the theory. Cali-
bration requires the usage of known, or trusted, devices,
thus introducing circularity and potential errors in the
assessment. Cartesians are doomed to remain in doubt
forever; most of us trust experienced experimentalists to
perform enough checks and calibrations to be conﬁdent
of their assessment.

Nevertheless, quantum devices are currently leaving
labs to enter the market. A potential buyer may not be
able, or simply not be allowed, to scrutinize the physics
of a commercial black box. All she may be allowed to do
is to query it and see how it responds. This is why the
recent years have witnessed a growth in interest about

∗ cqtmda@nus.edu.sg
† buscemi@i.nagoya-u.ac.jp
‡ physv@nus.edu.sg

assessing devices (source, measurement, channel...) us-
ing only observed statistics, the structure of the the-
ory, and possibly a few other statistical assumptions like
the fact that successive queries sample the same process
(independent-and-identically-distributed, or i.i.d.). Most
of this work has focused on devices that violate Bell’s
inequalities, and has been called device-independent cer-
tiﬁcation. This paper is in a diﬀerent line, which has
been called data-driven inference [2, 3]. The goal is to
produce the least committal mathematical description,
within the theory, of a device that could have generated
the observed statistics.

We ﬁrst present a uniﬁed formalisation of the data-
driven inference of states and eﬀects (measurement ele-
ments). This inference is explicitly implemented as a con-
vex optimization algorithm [4] for theories with (hyper)-
spherical state space, respectively (hyper)-conical eﬀect
space. For these same theories, we prove theorems
about observational completeness, the notion that plays
in data-driven inference a role analogous to that played
by informational completeness in conventional tomog-
raphy [2].
Speciﬁcally, we prove that only spherical
2-designs achieve observational completeness. For the
quantum case of the qubit, it follows that symmetric in-
formationally complete sets [5, 6] and mutually unbiased
bases are thus provided with a new operational inter-
pretation. We conjecture this to be true for quantum
systems of arbitrary dimension.

Formalization. — We consider a prepare-and-measure
scheme (Figure 1) described in a bilinear physical theory:
the probability of the outcome j
[1, ..., J] when measur-
j si,
[1, ..., I] is modelled by pij = ej ·
ing state i
where the states si and the eﬀects ej are (column) vectors
in a space Rℓ. Of course, quantum theory belongs to this
set of theories because of the Born rule pij = Tr[ρiEj],

si = eT

∈

∈

 
 
 
 
 
 
Ms

X

X

Me

Figure 1. Two ways of processing the same data. Top: in-
ference of states (2): the state preparator is interpreted as a
linear map M satisfying Eq. (4), while the eﬀects are repre-
sented by a set X of vectors. Bottom: inference of a mea-
surement (3): the measurement is interpreted as a linear map
M satisfying Eq. (5), while the states are represented by a
set X of vectors. In either case, M X is the set of probability
vectors collected after (ideally, inﬁnitely) many runs.

where ℓ = d2 with d the Hilbert space dimension.

For the sake of concreteness, let us provide a paradig-
matic example (detailed in Appendix A). The source can
produce I = 3 states and the measurement is described
by J = 4 eﬀects. The data are

p =

Tr

ρiEj

= 

h

(cid:2)

(cid:3)i

1
2 0
1
3
8
8
3
1
8
8

1
4
2+√3
8
√3
−
8

2

2

1
4
√3
−
8
2+√3
8

.



(1)






Since the rows are diﬀerent, we know trivially that the
states are diﬀerent and that the eﬀects are not trivial
(while a single row of data, i.e. the data obtained by
measuring a single state, could always come from Ej =
p1j 11). But with the techniques described in this paper,
Indeed, by looking at the
one can gather much more.
rows, one can make the following inference on the eﬀects:
if the system is a real qubit, the eﬀects are E1,2 = 1
±
σz) and E3,4 = 1
σx) up to the deﬁnition of these axes
in the plane. By looking at the columns, one can make
the following inference on the states: again for a real
qubit, the three states are pure and their Bloch vectors
point at the vertices of an equilateral triangle.

4 (11

4 (11

±

The two inferences have a very similar formalisation.
So we propose a formal language applicable to both;
when the two have to be diﬀerentiated, we shall use the
subscripts s for states and e for eﬀects. To make an in-
ference on the family of states, we shall study the family
of J vectors

xs,j =

p1j, p2j, ..., pnj

with n = I,

(2)

(cid:0)

indexed by the eﬀect, whose components are determined
by the states. Conversely, to make an inference on the
family of eﬀects (i. e., on the measurement), we shall
study the family of I vectors

(cid:1)

xe,i = (pi1, pi2, ..., pin) with n = J,

(3)

indexed by the state, whose components are determined
by the measurement. Compactly: a family of states (ef-
n from the
fects) is seen as a linear map Ms(e) ∈

Rℓ

→

2

un

Rn

Rℓ

uℓ

Ms

Me

0

0

Figure 2. The linear space Rℓ
on the left is the state/eﬀect
space, the vector uℓ representing the unit eﬀect and the hy-
perplane uℓ · s = 1 being the space of states. The linear space
Rn on the right is a probability space, the vector un being the
vector of all ones and the hyperplane un · p = 1 deﬁning prob-
ability distributions. A family of states acts as a linear map
Ms ∈ Rℓ→n
mapping uℓ into un [Eq. (4)]. A family of eﬀects
acts as a linear map Me ∈ Rℓ→n
mapping the hyperplane of
states into that of probability distributions [Eq. (5)]. In fact,
as noticed in the main text, the actual choice of coordinates
of vectors uℓ and un is immaterial for the problem at hand,
which can be formulated in a completely basis-independent
fashion.

space of eﬀects (states) to the space of probabilities. Such
a linear map is the object to be inferred from the dataset.
The two maps deﬁned by (2) and (3) diﬀer because
j pij = 1 for all i, while
i pij does not obey such a
constraint. This diﬀerence has a geometric interpretation
P
P
(Fig. 2). In Rℓ, let us deﬁne the unit eﬀect uℓ, which is
the eﬀect such that uℓ ·
s = 1 for all states s. On the
one hand, a family of n states maps the unit eﬀect onto
Rn whose entries are all ones. Thus, the
the vector un ∈
map Ms for the inference of states satisﬁes

Msuℓ = un .

(4)

On the other hand, a family of n eﬀects maps a state into
a normalised probability vector (3):
in other words, it
s = 1
maps the hyperplane orthogonal to uℓ deﬁned by uℓ·
p =
into the hyperplane orthogonal to un deﬁned by un ·
1. Thus, the map Me for the inference of eﬀects satisﬁes

M T

e un = uℓ .

(5)

In fact, the actual choice of coordinates for vectors uℓ
and un in Eqs. (4) and (5) is immaterial for the formula-
tion of the inference protocol. The only thing that mat-
ters is that a “special” vector, with respect to which the
arrow of causality is deﬁned, is ﬁxed in any real space.
Hence, the problem of inference considered here can be
formulated in a completely basis-independent fashion. In
other words, any linear transformation of the underlying
linear spaces does not aﬀect the inference protocol (while
of course non-linear transformations would not preserve
the structure of the underlying linear space).

→

Data-driven inference. — Let M

n be the lin-
∈
ear map corresponding to a family of states (eﬀects) of
a system with eﬀect (state) space X
Rℓ. We denote
Rn the image of X under M . Then, given the
by M X
Rn as a set of probability vectors, we say that
data
M is consistent with the data if
In words:
there exist elements of X that, acted upon by transfor-
. Among all
mation M , give the probability vectors

⊂
X ⊆

M X.

X ⊆

⊂

Rℓ

X

linear maps M consistent with the data, we are inter-
ested in the least committal ones. Here, we quantify the
“committal degree” of a linear map M by the Euclidean
volume of the set of probability vectors the map is con-
sistent with. This volume, denoted by vol(M X), coin-
cides with the volume of the range of the transformation
M [7–9], which is known to constitute a crucial statis-
tical property of measurements [10] and ensembles [11].
For example, the range of a pair of states coincides with
the Lorenz region (or testing region) of the pair [12, 13],
and the corresponding volume is just the area of region.
In order to avoid comparing volumes of sets with diﬀer-
ent dimensionalities, we minimize the volume over linear
transformations M such that M X

.
Presently we can deﬁne the main protocol:

span

⊆

X

Deﬁnition 1 (Data-driven inference). For any
and any X

Rℓ, we deﬁne

⊆
ddis/e

X

:= argmin

vol (M X) ,

M

X |
(cid:0)

(cid:1)

X ⊆

Rn

(6)

where the optimization is over the linear maps M that
satisfy

M X

span

(7)

⊆
and either Eq. (4) for states (s), or Eq. (5) for eﬀects
(e). A pictorial sketch is given as Fig. 3.

X ⊆

X

3

Rn

un

Rℓ

uℓ

Rn

un

Xℓ
e

ddis(X |Xℓ
e)

X

Rn

un

Rℓ

uℓ

Rn

un

ddie(X |Xℓ
s)

X

Xℓ
s

Figure 3. Top: taking as input a set X of probability vectors
(represented as dots) and some prior information X about the
eﬀect space (the cone Xℓ
e in the ﬁgure), the map ddis(X |X)
returns the minimum volume linear transformation of X that
contains X , as per Eq. (7), and that satisﬁes Eq. (4). Bot-
tom: taking as input a set X of probability distributions
(represented as dots) and some prior information X about the
state space (the sphere Xℓ
s in the ﬁgure), the map ddie(X |X)
returns the minimum volume linear transformation of X that
contains X , as per Eq. (7), and that satisﬁes Eq. (5).

uℓ

Rℓ

uℓ

Rℓ

supp M

supp M

This deﬁnition should clarify that our approach is
insensitive to linear transformations of the probability
space, as any such transformation would rescale the vol-
ume of any body by a constant that uniquely depends
on the transformation, thus not aﬀecting the output of
data-driven inference.

Machine learning of states and measurements. —
Given the convexity of the merit function vol(M X) and
of the constraints in Eqs. (4), (5), and (7), the data-
driven inference map corresponds to a convex program-
ming problem [4].

Figure 4. Left: conical eﬀect space around the unit eﬀect uℓ.
Any family of states acts as a linear map M whose support,
solely constrained by Eq. (4), does not necessarily contain uℓ.
Right: spherical state space on the plane orthogonal to uℓ.
Any measurement acts as a linear map M whose support, due
to Eq. (5), necessarily contains uℓ.

Notice that, in general, the linear space span

can
be of smaller dimension than the linear space span X.
In this case, the optimization over linear maps M that
satisfy Eq. (7) can be split into:

X

i) the optimization over a subspace of the same di-
, followed by

mension as span

X

ii) an optimization over linear maps M with such a

subspace as its support.

In the case when M satisﬁes Eq. (5), it is further clear
that uℓ belongs to the support of M . However, in the
case when M satisﬁes Eq. (4), uℓ does not necessarily
belong to the support of M , unless of course one has that
the dimension of span
equals ℓ, in which case the only
possible subspace is the space Rℓ itself. These situations
are depicted in Fig. 4.

X

Let us consider now the case when the state and eﬀect
Rℓ, are, respec-
spaces, denoted with Xℓ
tively, the (hyper)-sphere in the (hyper)-plane of states

Rℓ and Xℓ

s ⊂

e ⊂

orthogonal to uℓ, and the (hyper)-cone around uℓ. This
situation occurs in the case of classical and quantum bits,
with ℓ = 2 and ℓ = 4, respectively. Due to the (hyper)-
spherical symmetry, when inferring a measurement Me,
that is, when Eq. (5) is satisﬁed, the step i) above cor-
s with Xm
responds to replacing Xℓ
ℓ is the
s , where m
dimension of span
. In other words, it is enough to re-
duce the dimension of the state space, while keeping it
(hyper)-spherical. On the contrary, when inferring a set
of states Ms, that is, when Eq. (4) is satisﬁed, an equiv-
alent result does not hold: in this case, the optimization
over the support of Ms can break the (hyper)-conical
symmetry of Xe.

≤

X

For this reason, while conceptually equivalent, the
problem of inferring a measurement is formally diﬀer-
ent from the problem of inferring a set of states. As
a consequence, the machine learning algorithm that we
analytically develop and discuss in Appendix D, while

X

always valid in the case of measurement inference, can
be applied to states inference only when the dimension
of span

equals ℓ.

X

X

(we recall that

Observational completeness. — Let us now take a
step backward and consider the experiment in which the
dataset
is taken to be a set of proba-
bility vectors) is generated. Upon the input of a classical
variable i, for instance through the pressure of a button,
a state preparator prepares a state. The state is then
fed into a measurement, and the outcome j of the mea-
surement, which can be modeled as a light bulb lighting
up, is recorded. The experiment is repeated ideally in-
ﬁnitely many times, and the frequencies are estimated.
This setup is depicted in Fig. 1.

In the protocol of data-driven reconstruction of states,
Xe, thus
a family of states Ms acts on a set of eﬀects X
producing the dataset
= MsX. In this case, the exper-
imentalist’s aim is to choose the “probe” measurement X
in such a way that the data-driven inference applied to
correctly outputs the range of the
the corresponding
family of states Ms actually used in the experiment.

⊆

X

X

In complete analogy, in the protocol of data-driven re-
construction of measurements, the experimentalist’s aim
Xs, such
is to choose a family of “probe” states X
= MeX is
that, once measured through Me, a dataset
produced, for which the data-driven inference correctly
outputs the range of Me.

⊆
X

The property that such probes (states, in the case of
measurement inference; eﬀects, in the case of state infer-
ence) need to satisfy in order that the protocol of data-
driven inference always succeeds, is deﬁned as follows:

Deﬁnition 2 (Observational completeness). A set of ef-
Rℓ is observationally complete for a set
Xe ⊆
fects X
of states Ms whenever

⊆

ddis

MsX

Xe

|

=

.

MsXe}
{
Xs ⊆

(cid:1)
Analogoulsy, a set of states X
ally complete for a measurement Me whenever

⊆

(cid:0)

Rℓ is observation-

ddie

MeX

Xs

|

=

MeXs}
{

.

(cid:0)

(cid:1)
In other words, an observationally complete set of
states is such that, when fed through a measurement,
it provides the same amount of statistical information
(for the protocol of data-driven inference) as if the en-
tire state space was measured. An observationally com-
plete measurement plays the same role in the inference
of states. Observational completeness hence guarantees
that the maximum information is provided to the infer-
In this case, as shown in Ref. [2], the
ence protocol.
reconstruction of M X allows for the identiﬁcation of the
invertible linear map M up to gauge symmetries (the
case when M is not invertible, also discussed in Ref. [2],
involves more technicalities), that is, up to linear trans-
formations that preserve X. This is of course the max-
imum level of accuracy that one should expect from an
inference protocol that only relies on the bare coincidence
data.

Rℓ−1

M01

Rℓ−1

M12

X1

X0

X2

4

Rℓ−1

Figure 5. The set X of states is represented by a grey cir-
cle. Sets X0 and X1 are related by a gauge symmetry (a
π-rotation) hence either both of them or none of them is ob-
servationally complete (in this case, the former is the case as
shown in the main text, since regular simplices are spherical
2 designs). Sets X1 and X2 are related by a linear map which
is not a gauge symmetry, hence at most one among them is
observationally complete (in this case, X1).

X

Characterization of observational completeness. — Ac-
cording to its deﬁnition, the observational completeness
of a set
depends upon the linear map to be recon-
structed. However, as it had already been noticed in
Ref. [2], such a dependency turns out to be limited to
the support of the linear map, and we discuss here a few
important consequences of this fact. Let
X1 be
two subsets of Rℓ related by an invertible transformation,
that is M
X1. The following two facts follow im-
mediately. Whenever M is a gauge symmetry, if either
of the two sets is observationally complete for Rℓ, also
the other one is. If instead M is not a gauge symmetry,
then at most one between
X1 is observationally
complete for Rℓ, but not both. This situation is depicted
in Fig. 5.

X0 and

X0 and

X0 =

A closed-form characterization of observational com-
pleteness can be derived for the cases of (hyper)-conical
eﬀect space and (hyper)-spherical state space.
In this
case, by extending John’s theory [14] on extremum prob-
lems with inequalities as subsidiary conditions, we show
in Appendix D a relation between observational com-
pleteness and spherical designs.

{

{

such that

vk} ⊆

pk, ˜vk}

pk}
{
vk)−

1vk lie on the (hyper)-plane of states.

Operationally (for a formal deﬁnition of spherical de-
sign, see Appendix E), a spherical t-design is an ensemble
pk, vk}
(that is, a probability distribution px over states
{
vk) which is indistinguishable from the uniform ensem-
ble over states on the boundary of the (hyper)-sphere,
Rℓ
when t copies are given. We say that a set
supports a t-design whenever there exists a probability
distribution
is a t-design, where
˜vk := (uℓ ·
We have then the following closed-form characteri-
zation of observational completeness for systems with
(hyper)-conical eﬀect space or (hyper)-spherical state
Xℓ
space. Let
s
Xℓ
is observationally com-
or
plete for an invertible linear map M , then
supports a
spherical 2 design. The generalization of this statement
to the case of non-invertible linear map M involves some
technicalities, and is therefore deferred to Appendix D.
s, also the vice-
supports a spherical 2-design,
versa is true. That is, if
then
is observationally complete for any invertible lin-
ear map M . Again, the generalization to the case of

be a set of states or eﬀects, that is

is a set of states, that is

e, respectively. If set

X ⊆

X ⊆

X ⊆

Xℓ

X

X

X

X

X

X

If

non-invertible linear map M is deferred to Appendix D.
We conjecture a similar result to hold if
is a set of
Xℓ
e.
eﬀects, that is

X

X ⊆

The following two facts follow as immediate corollar-
ies. The minimum cardinality observationally complete
set for a qubit is the symmetric, informationally complete
set. As a further corollary, the minimum cardinality ob-
servationally complete set of basis for a qubit system are
the three mutually unbiased bases. These result provide
a new operational interpretation to these sets, based on
data-driven inference rather than on their purely math-
ematical deﬁnition in terms of equiangular vectors.

Conclusion. — Data-driven inference is a protocol
that, upon the input of a set of probability vectors, out-
puts the mathematical description for a physical device.
Such a description is self-consistent, that is, it can gen-
erate the given probability vectors. Moreover, it is mini-
mally committal, that is, it is consistent with the minimal
set of probability vectors.

In this work, we provided a uniﬁed formalism for the
data-driven inference in the cases where the mathemat-
ical description is in terms of states and measurements.
For systems with (hyper)-conical eﬀect space or (hyper)-
spherical state space, we provided a convex programming
algorithm for the machine learning of states and measure-
ments based on data-driven inference.

Observational completeness is the property of any ap-
paratus that, when applied to a target device, generates
probability vectors for which the output of data-driven
inference coincides with the range of the device itself.
Hence, observational completeness plays for data-driven
inference the same role played by informational complete-
ness for conventional tomography.

In this work, we provided a full characterization of
observational completeness. Our characterization is in
closed-form for systems with (hyper)-conical eﬀect space
or (hyper)-spherical state space, in which cases observa-
tional completeness for a set implies that such a set sup-
ports a spherical 2-design. We showed that the vice-versa
is true for sets of states, and we conjectured it to be the
case also for sets of eﬀects. Accordingly, symmetric in-
formationally complete sets and mutually unbiased bases
are minimal cardinality observationally complete sets of
vectors and bases, respectively. We conclude by con-
jecturing that for arbitrarily dimensional quantum sys-
tems, quantum 2-designs coincide with observationally
complete sets.

Acknowledgement. — This work is supported by the
National Research Fund and the Ministry of Educa-
tion, Singapore, under the Research Centres of Excel-
lence programme; and partly supported by the program
for FRIAS-Nagoya IAR Joint Project Group. F. B. ac-
knowledges partial support from the Japan Society for
the Promotion of Science (JSPS) KAKENHI, Grant No.
19H04066.

Appendix A: An Example

5

As an example, we consider a source that can produce

the three pure states of a real qubit

(11 + σz) ,

ρ1 =

ρ2 =

1
2
1
2  

11 +

ρ3 =

1
11
2  

−

√3
2

√3
2

σx −

σx −

1
2

1
2

,

,

σz

!

σz

!

and a measurement described by the eﬀects

E1 =

E2 =

E3 =

E4 =

1
4
1
4
1
4
1
4

(11 + σz) ,

(11

−

σz) ,

(11 + σx) ,

(11

−

σx) .

It is easy to check that this example gives rise to the data
given in Eq. (1) of the main text.

First let us consider the case of inference of measure-
ments. Each state ρi has associated with it the vector xi
where (xi)j = pij = P
. Therefore, we will have 3
ρi
points in R4:

Ej |
(cid:0)

(cid:1)

, 0,

1
4

,

1
4

T

,

x1 =

x2 =

x3 =

1
2

1
8

1
8

(cid:20)

"

"

,

,

3
8

3
8

,

,

(cid:21)
2 + √3
8

2

,

√3
−
8

2

√3
−
8

,

2 + √3
8

T

#
T

#

,

.

These points are in a 2-dimensional plane in R4. In this
plane, any measurement deﬁnes an ellipsoid as the set of
all the vectors it can produce. The measurement being
used must of course deﬁne an ellipsoid that contains the
three observed points, and ddi ﬁnds the consistent ellip-
soid with the smallest volume. The inferred range is then
inverted to give the eﬀects, up to symmetries.

Then we consider the case of inference of states. This
time, to each eﬀect one associates the vector xi where

(xj )i = pij . Thus, we will now have 4 points in R3:

x1 =

1
2

,

1
8

,

1
8

(cid:20)

T

,

(cid:21)
T

,

3
8

,

3
8

(cid:21)
2 + √3
8

x2 =

0,

(cid:20)

"

"

x3 =

x4 =

1
4

1
4

,

,

2

,

√3
−
8

2

√3
−
8

,

2 + √3
8

T

#
T

#

,

.

The next step now is to ﬁnd the linear transformation of
the space of eﬀects - that preserves the null and identity
eﬀects - that contains all four points and is of minimal
volume. This volume is then inverted to ﬁnd the states
(up to symmetries) that induce this linear transformation
of the space of eﬀects.

Appendix B: Formalization

In these appendices, for compactness the subscripts s
,

and e adopted in the main text are replaced by + and
respectively.
For any
volume of

Rn let us deﬁne vol(

. One immediately has

) as the Euclidean

on aﬀ

−

X

X ⊆
X

X

vol (M X) =

M T M

vol

M +M X

.

(B1)

Let us introduce a family
ℓ

n

two families

(cid:0)
un ∈
of linear transformations

Rn

}

(cid:1)

(cid:12)
(cid:12)
(cid:12)

of vectors and

→
±

M

1
2

+
(cid:12)
(cid:12)
(cid:12)
{

n

ℓ
→
+

:=

M

M

M

n

ℓ

→
−

(cid:26)

:=

M

∈

∈

Rℓ

n

→

M uℓ = un

,

(cid:12)
(cid:12)
(cid:12)

(cid:27)
M T un = uℓ

.

Rℓ

n

→

n

(cid:12)
(cid:12)
(cid:12)

(cid:26)

ℓ
→
+

Notice that if M
ℓ
M
∈ M
M0 ∈ M
→
±
Notice ﬁnally that if M
has M −

(cid:27)
one has M +M uℓ 6
= 0 and if
one has M +M uℓ = uℓ. Notice also that if
m
.
and M1 ∈ M
one has M1M0 ∈ M
and M is invertible one
.

±
∈ M

∈ M

→
−
ℓ

→
±

→
±

→
ℓ

m

n

n

n

n

ℓ

1
For any X

∈ M
⊆

ℓ
n
→
±
Rℓ and any

Rn let us deﬁne

X ⊆

X

:=

M

Rℓ

n

→

M X

span

⊆

|X ⊆

∈

L

X |
(cid:0)
and let
L±

(cid:1)
(
X |

n
X) :=

(
X |
L
Deﬁnition 1 (Data-driven inference). For any X
and any

Rn, let us deﬁne

∩ M

→
±

.

ℓ

n

X)

,

X

o

Rℓ

⊆

X ⊆
ddi

±

X

(cid:1)

X |
(cid:0)

:= argmin
±(X |

∈L

M

X)

vol (M X) .

6

Deﬁnition 2 (Observational completeness). Any given
Rℓ is OC with respect to X for any given
if and only if

X ⊆
L

X
ℓ

⊆
n

∈ M

→
±

ddi

±

X

=

L

X |

LX
{

}

.

(cid:0)

(cid:1)

Appendix C: General results

For any X

Rℓ and any

Π

±

⊆
X

X |
(cid:0)

(cid:1)

:= argmin

2

Π=Π
rank Π=m

X ⊆
vol

Rn, let us deﬁne

ddi

±

(cid:16)

X |
(cid:0)

ΠX

,

(cid:1)(cid:17)

LX

.

(cid:1)
⊆
X
X

X
L
X |
X
.

where m := dim span

X

. One immediately has

ddi

±

X

=

X |
(cid:0)

(cid:1)
By explicit computation, for any X

X |
(cid:0)
(cid:1)
Rℓ, any
such that L+LX = X one has

Π±(
[Π
∈

⊆

X)

X |

±

and any L

ddi

ΠX

.

∈ M±
ddi

X

= ddi
±

±

X |
(cid:0)
Lemma 1 (Commutativity). For any X
Rn, and any L
=

such that L+L

X |
(cid:0)

(cid:1)

∈ M±

Rn,

X ⊆

Rℓ, any

one has

X ⊆

X

X

= L+ ddi
ddi
±
±
= ddi
L ddi
L
±
±
(cid:1)
(cid:0)
Proof. By direct computation L+
X |
L±
X). Hence L+
and L
L±
X). Hence
(
X |

X)
(
L±
X |
X) and L

(cid:1)
(L
X |
X) =

X |
(cid:0)
X |
(cid:0)

(cid:0)
X |
(L

(cid:1)
X)

L±

L±

(L

(cid:1)

,

⊆ L±
(
X |
L±
X
= argmin

X |
f

ddi

±

X |
(cid:0)

M

±(L

X)

X |

∈L

(cid:1)

L+M X

.

(cid:0)

(cid:1)

(C1)

(C2)

X)
(
X |
X) =

⊆ L±
(L
X |

Since dim span X = ℓ, by Deﬁnition 1 for any
X) one has that M M +
LL+ is
(L+M )T L+M
. Hence
|+ =
|+. Hence by Deﬁnition 1

M
(L
∈ L±
the projector on span L
2
M
+|
|
|
one has

(L+M M +)T L+M M +

X |

≤

X

|

argmin
±(L

X |

∈L

M

f

L+M, X

X)

(cid:0)

= L+ ddi
±

X

.

L

X |

(cid:1)

(cid:0)

(cid:1)

Thus Eq. (C1) follows.

X), Eq. (C2) follows.

ddi

(
X |

±

Since L+L ddi
±

(
X |

X) =

Theorem 1 (Data-driven inference). Let X

Rℓ and

Rn and m := dim supp
m

X
such that supp
= Π
±
such that supp L = span
X

L

m

X ⊆
ℓ
→
M
±
n
M

±

→

⊆

. For any any
(
X |
, one has

X) and any L

M ⊆
∈

ddi

X

= L+

±

X |
(cid:0)

[M
∈M
Proof. The statement directly follows from the applica-
tion of Lemma 1.

(cid:1)

(cid:1)

(cid:0)

ddi

L

X |

±

M X

.

ℓ

Rℓ and m := dim supp

Theorem 2 (Observational completeness). Let
X
N
L
supp

X ⊆
is OC for
with respect to X if and only if there exists
with L+L = N +N and
with
X) such that
(
X |

⊆
→
∈ M
±
ℓ
→
∈ M
±
= Π
M

. One has that

M ⊆ M

→
±

X

X

m

m

±

n

ℓ

ddi

±

(L

X1|

M

X0) =

L
{

X0}

.

[M
∈M

Proof. The statement directly follows from the applica-
tion of Lemma 1.

Appendix D: (Hyper)-spherical case

For any v

∈

Rℓ, upon deﬁning

g (v) =

v

√2ˆuℓ ·

v,

|2 −

|
one has that the (hyper)-spherical state space Xℓ
−
the (hyper)-conical eﬀect space Xℓ

+ are given by

Xℓ
−

:=

v

g (v)

(cid:26)

0, uℓ ·

≤

v = 1

,

(cid:27)

Xℓ

+ :=

v

(cid:26)

g (v)

0, g (uℓ −

≤

v)

≤

0

.

(cid:27)

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

Corollary 1 (Data-driven inference). For any L

m

ℓ

→
±

M

such that supp L = span

, one has

X

ddi

±

Xℓ
±

X |

= L+ ddi
±

L

Xm
±

X |

,

(cid:16)

(cid:17)

where m := dim supp L, for any m in the
m = ℓ in the + case.

(cid:0)

(cid:1)
case and for

−

and

(D1)

(D2)

∈

2. g(M −

1v)

0, for any v

.

∈ X

≤

7

ℓ

1

Proof. Due to the invertibility of M one has that condi-
tion (1) is equivalent to M −
. Hence, implica-
X ∈
2 follows immediately from Eqs. (D1) and (D2).
tion 1
To prove implication 2
1, we need to distinguish two
cases.

Xℓ
±

⇒

⇒

Let us ﬁrst consider the case Xℓ
−

. Since by hypothesis
1
.
−
1v = 1. Hence the

M −

∈ M

∈ M

M
−
Hence for any v
implication remains proved.

, by explicit computation one has M −
one has ˆuℓ ·

∈ X−
Let us now consider the case Xℓ

1v)
by hypothesis one has g(M −
v
, also uℓ −
symmetry of
X
1(uℓ −
pothesis g(M −
0. Since g(M −
≤
1(uℓ −
v))
g(M −
≤
Hence, the implication remains proved.

+. For any v
∈ X
0. Due to the uℓ/2-
, from which by hy-
1v)
0 and
Xℓ
0, by Eq. (D2) one has M −
+.

≤
∈ X

≤
1v

v))

∈

ℓ

From Eq. (B1) one has vol(M Xℓ
±

)

∝

f (M ), where

f (M ) := log

M T M

.

p

The constraint M

∈ M
implemented by introducing the auxiliary functions:

X |

ℓ

(cid:12)
(cid:12)
ℓ
(cid:12)
→
±

(cid:12)
(cid:12)
in ddi(L
(cid:12)

Xℓ
±

) can be

h± (N ) = Π∓N Π± + ˆu⊗
ℓ

2

,

Π± := 11

1

±
2

1

ˆu⊗
ℓ

2

.

−

n. Hence for any

By direct inspection f (h±(N )) and g(h±(N )v) are
Rℓ
Rn
convex functions of N
→
one has that ddi
) is a convex programming prob-
±
lem, that can be eﬃciently solved in N . To this aim, one
needs the Jacobian and Hessian matrices (with respect to
vec(N )) of f and g. From the chain rule it immediately
follows that for any function g : Rℓ

R one has

∈
Xℓ
±

(
X |

X ⊆

ℓ
→

→

Proof. The statement directly follows from Theorem 1
and Eqs. (D1) and (D2).

J g

H g

◦

◦

h±(N ) = J g

h± (N ) = Π±

|h±(N ) Π±
Π∓ H g
⊗

Π∓,
⊗
|h±(N ) Π±

⊗

(D3)

Π∓.

(D4)

Corollary 2 (Observational completeness). Any
Xℓ
ℓ
→
±
±
L
→
∈ M
±
such that

with L+L = N +N such that LXℓ
±

X ⊆
if and only if there exists
= Xm
±

is OC for N
m

∈ M

n

ℓ

ddi

±

(L

Xm
±

X |

) =

Xm
±

,

where m := dim supp L.

(cid:8)

(cid:9)

Proof. The statement directly follows from Theorem 2
and Eqs. (D1) and (D2).

A set
X
one has uℓ −

X
symmetric.

is uℓ/2-symmetric if and only if for any v

. Clearly the set Xℓ

∈
+ is uℓ/2-

v

∈ X

Lemma 2. For any invertible M
X
or any uℓ/2-symmetric
equivalent conditions:

X ∈

−

1.

M Xℓ
±

,

X ⊆

ℓ

ℓ
→
±

and any
X ∈
+, the following are

∈ M
Xℓ

By explicit computation one has

J f

1

M −

(cid:16)

M −

(cid:17)

1

H f

(cid:16)

(cid:17)

=

2M T ,

−
= 2M T

M Sℓ2,

⊗

where Sℓ2 denotes the ℓ2-dimensional swap operator, and

J g

M −

1v

=

(cid:16)

(cid:17)

M −
M −

1v
1v
|2 −

|

√2ˆuℓ

v,

! ⊗

H g

M −

1v

=

M −

1v

(cid:16)

(cid:17)

(cid:12)
(cid:12)
(cid:12)

M −
M −

(cid:0)

|

2

⊗

1v
1v
|2 
(cid:1)


v⊗

2.

⊗

1

−
2 

11ℓ2

2

−



(cid:12)
(cid:12)
(cid:12)
X ⊆

Xℓ

Theorem 3. If a set

Xℓ
or a uℓ/2-symmetric set
−
n, then L
+ is OC for a given M
sup-
X
X ⊆
m
with m :=
ports a spherical 2-design, for any L
= Xm
dim supp M such that M +M = L+L and LXℓ
±
±

ℓ
∈ L

→
±

Rℓ

∈

→

.

 
Proof. Due to Corollary 2 one has that
is OC for M
if and only if ddi
Xm
Xm
(L
) =
. Due to Lemma 3
X |
±
±
0, vk ∈
such that Eq. F1 holds
L
λk ≥
there exists
when computed in 11m. By explicit computation one has

{
X }

± }

X

{

211m,

=

−

M=11m

J f

1

M −

(cid:16)

(cid:17)(cid:12)
(cid:12)
(cid:12)
(cid:12)

and

1
2 J g
−

v

|

|

=

1
2

2

˜v⊗

ˆum ⊗

−

˜v,

M=11m

M −

1v

(cid:16)

(cid:17)(cid:12)
(cid:12)
(cid:12)
vk)−
(cid:12)

where ˜vk = (um ·
vk|2λk by Eqs. (D3) and (D4) one has that
4)−
is a spherical 2-design, hence the implication follows.

1vk. By deﬁning pk := (4ℓ

−
pk, ˜vk}

{

1

|

Xℓ
Theorem 4. If a set
supports a
−
such that LXℓ
spherical 2-design, for some L
=
±
Xm
Rℓ
n such
X
±
that m := dim supp M such that M +M = L+L.

is such that L
m

for some m, then

is OC for any M

ℓ
∈ L

X ⊆

→
±

X

∈

→

Proof. Due to Corollary 2 one has that
if and only if ddi
(L
− }
±
there exixsts a probability distribution
pk, vk ∈ X }
{
linear map M such that M −

is OC for M
. By hypothesis,
such that
is a spherical 2 design. Hence, for any
X

X
pk}
one has

Xm
−

) =

Xm

X |

{

{

1

X ⊆

−
1vk

.

pkg

M −

0

≥

(cid:17)
By using Eq. (E1) one immediately has

(cid:16)

Xk

pkg

M −

1vk

Xk
Tr

(cid:16)
1M −

M −

1T

(cid:17)
+ (ℓ

=

h

i

−
By using Eq.(5) and the fact that

M −

1 ˆu

2)
−
uℓ|

|

(cid:16)(cid:12)
2
2 (ℓ
(cid:12)

2
2 −

2

2

−

(cid:17)

1T ˆu

2

2
(cid:12)
(cid:12)
(cid:12)

.

M −
(cid:12)
(cid:12)
(cid:12)

1 one has

1)

(cid:12)
(cid:12)
M −

|

1 ˆu
2
2 ≥
|
1T

1M −
2
2 (ℓ

i
1)

ℓ

.

−

pkg

M −

Tr

1vk

M −
uℓ|
0 one has Tr[X

≥

h

|

(cid:17)

Xk
(cid:16)
Since for any X
11]
equality if and only if X = 11, one has log
| ≤
0, with equality if and only if M is an orthogonal matrix.
Hence, the statement remains proved.

with
X
|
|
1T
1M −

≥
M −
|

log

−

≥

−

Appendix E: Spherical t-designs

Deﬁnition 3 (Spherical t-design). A probability distri-
Rℓ
vk ∈
bution
such
pk}
}
{
uℓ = 1 for any k, is a spherical t-design if and
that vk ·
only if

pk, vk}

over states

, that is

{

{

pkv⊗

t
k =

dO (Ov)⊗

t ,

Xk

Z

8

where dO denotes the Haar measure of the orthogonal
representation of the symmetries of X
and v is any vec-
tor on the boundary of X
vk ∈

Rℓ
}
exists a probability distribution
is a spherical t-design, where ˜vk := (uℓ ·
k.

supports a spherical t-design if there
pk, ˜vk}
1vk for any

such that
vk)−

pk}

A set

{

{

{

−

−

.

Here we consider spherical 2-designs. When working
Rℓ it is convenient
2 := vvT . Then, by explicit

with spherical 2-design, for any v
to adopt the convention v⊗
computation one has

∈

dO (Ov)⊗

2 =

2
2 (cid:18)
By multiplying both sides by uℓ on the right one has

−

(cid:19)

Z

1

ℓ

|

1

11ℓ +

2
1

ℓ
ℓ

−
−

2

ˆu⊗
ℓ

.

1
uℓ|

dO Ov =

.

uℓ
uℓ|

|

2
2

Hence, any
only if it satisﬁes

{

Z
pk, vk ∈

S
}

is a spherical 2-design if and

pkv⊗

2
k =

1

1
uℓ|

2
2 (cid:18)

ℓ

11ℓ +

1

2
1

ℓ
ℓ

−
−

Xk

−
in which case it is also a spherical 1-design, that is, it
satisﬁes

|

(cid:19)

2

ˆu⊗
ℓ

,

(E1)

pkvk =

Xk

|

uℓ
uℓ|

.

2
2

Appendix F: John’s extremality conditions

Let f (L) be some diﬀerentiable function, let

X :=

v

Rℓ

∈

(cid:26)

(cid:12)
(cid:12)
for some diﬀerentiable g : Rℓ
(cid:12)
λk ≥
any L
{
:= f (L) +

ℓ and any

Rℓ

L,

∈

h

→

g(v)

0

,

(cid:27)

≥
R and let
→
0, vk ∈ X }

X ⊆

let

λkg(Lvk).

Rℓ. For

λk, vk}
{
(cid:1)

(cid:0)

Lemma 3 (John’s necessary condition). For some L∗

∈
X) implies that

ℓ

ℓ
→
M
±
there exists

, one has that L∗X
λ∗k ≥

{

∈
0, v∗k ∈ X }
λ∗k, v∗k}
{
∂L

∂h(L,

Proof. Theorem I of Ref. [14].

Xk

ddi
(
X |
±
such that

L=L∗

(cid:12)
(cid:12)
(cid:12)
(cid:12)

)

= 0.

(F1)

Lemma 4 (John’s suﬃcient condition). If there exists
λ∗k ≥

such that Eq. (F1) holds and the set

{

0, v∗k ∈ X }
∂f (L)
∂L

(

dim span

,

∂g(Lvk)
∂L

for some L∗

, then L∗X
∈ M
Proof. Theorem II of Ref. [14].

ℓ

∈

L=L∗
(cid:12)
(cid:12)
(cid:12)
ℓ
(cid:12)
→
±

= ℓ (ℓ

1) ,

−

L=L∗)k
(cid:12)
(cid:12)
(cid:12)
ddi
(
(cid:12)
X |

±

X).

9

[1] A. Bisio, G. Chiribella, G. M. D’Ariano, S. Facchini, and
P. Perinotti, Optimal quantum tomography, IEEE Jour-
nal of Selected Topics in Quantum Electronics 15, 1646
(2009).

[2] M. Dall’Arno, F. Buscemi, A. Bisio, and A. Tosini, Data-
driven inference, reconstruction, and observational com-
pleteness of quantum devices, arXiv:1812.08470.

[3] F. Buscemi and M. Dall’Arno, Device-Independent Infer-
ence of Physical Devices: Theory and Implementation,
arXiv:1805.01159.

[4] S. Boyd and L. Vandenberghe, Convex Optimization,

Cambridge University Press.

[5] G. Zauner, Quantendesigns – Grundz¨uge einer nichtkom-
mutativen Designtheorie, PhD thesis, University of Wien,
(1999).

[6] J. M. Renes, R. Blume-Kohout, A. J. Scott, and C. M.
Caves, Symmetric Informationally Complete Quantum
Measurements, J. Math. Phys. 45, 2171 (2003).

[7] M. Dall’Arno, S. Brandsen, and F. Buscemi, Device-
independent tests of quantum channels, Proc. R. Soc. A
473, 20160721 (2017).

[8] M. Dall’Arno, S. Brandsen, F. Buscemi, and V. Ve-
dral, Device-independent tests of quantum measurements,
Phys. Rev. Lett. 118, 250501 (2017).
[9] M. Dall’Arno, Device-independent

tests of quantum

states, arXiv:1702.00575.

[10] F. Buscemi, G. M. D’Ariano, M. Keyl, P. Perinotti, and
R. Werner, Clean Positive Operator Valued Measures, J.
Math. Phys. 46, 082109 (2005).

[11] F. Buscemi, Comparison of quantum statistical models:
equivalent conditions for suﬃciency, Commun. Math.
Phys. 310, 625-647 (2012).

[12] J. M. Renes, Relative submajorization and its use in
quantum resource theories, Journal of Mathematical
Physics 57, 122202 (2016).

[13] F. Buscemi and G. Gour, Quantum relative Lorenz

curves, Phys. Rev. A 95, 012110 (2017).

[14] F. John, Extremum problems with inequalities as sub-
sidiary conditions, in Studies and Essays Presented to
R. Courant on his 60th Birthday, 187–204, (Interscience
Publishers, New York, 1948).

