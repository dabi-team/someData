Optimal Solutions for Joint Beamforming and
Antenna Selection: From Branch and Bound to
Machine Learning

Sagar Shrestha, Xiao Fu, and Mingyi Hong

1

2
2
0
2

n
u
J

1
1

]
P
S
.
s
s
e
e
[

1
v
6
7
5
5
0
.
6
0
2
2
:
v
i
X
r
a

Abstract—This work revisits the joint beamforming (BF) and
antenna selection (AS) problem, as well as its robust beamforming
(RBF) version under imperfect channel state information (CSI).
Such problems arise in scenarios where the number of the
radio frequency (RF) chains is smaller than that of the antenna
elements at the transmitter, which has become a critical con-
sideration in the era of large-scale arrays. The joint (R)BF&AS
problem is a mixed integer and nonlinear program, and thus
ﬁnding optimal solutions is often costly, if not outright impossible.
The vast majority of the prior works tackled these problems
using continuous optimization-based approximations—yet these
approximations do not ensure optimality or even feasibility of the
solutions. The main contribution of this work is threefold. First,
an effective branch and bound (B&B) framework for solving the
problems of interest is proposed. Leveraging existing BF and RBF
solvers, it is shown that the B&B framework guarantees global
optimality of the considered problems. Second, to expedite the
potentially costly B&B algorithm, a machine learning (ML)-based
scheme is proposed to help skip intermediate states of the B&B
search tree. The learning model features a graph neural network
(GNN)-based design that is resilient to a commonly encountered
challenge in wireless communications, namely, the change of
problem size (e.g., the number of users) across the training and
test stages. Third, comprehensive performance characterizations
are presented, showing that the GNN-based method retains the
global optimality of B&B with provably reduced complexity,
under reasonable conditions. Numerical simulations also show
that the ML-based acceleration can often achieve an order-of-
magnitude speedup relative to B&B.

Index Terms—Beamforming, Antenna Selection, Global Opti-

mum, Machine Learning, Graph Neural Networks

Beamforming lies at the heart of transmit signal design of
multiple antenna systems. In the past decade, a plethora of
beamforming algorithms have been proposed under various
scenarios; see, e.g., [1]–[7]. Among the most challenging
scenarios is the joint beamforming and antenna selection
(BF&AS) problem (see, e.g., [5]–[7]), which often arises for
practical considerations. For example, in downlink transmis-
sion, a base station (BS) may have a limited number of radio
frequency (RF) chains—due to the RF chain’s costly nature
[8]. The number of the RF chains may be (much) smaller than
that of the antennas. Since the RF chains are responsible for
encoding/modulating the transmit information, this limits the

S. Shrestha and X. Fu are with the School of EECS, Oregon State
University. M. Hong is with the ECE Department, University of Minnesota.
(Corresponding Author: Xiao Fu)

The work of S. Shrestha and X. Fu is supported by National Science
Foundation (NSF) under Project CNS-2003082. Their work is also supported
by a gift from Intel through the MLWiNS program. The work of M. Hong is
supported by NSF CNS-2003033. His work is also supported by a gift from
Intel through the MLWiNS program.

number of antennas that can be operated simultaneously in
practice. To avail the advantages of multi-antenna systems, a
proper antenna selection strategy is needed to be part of the
transmit waveform design. In addition, when using a subset of
the antennas can serve the users well, it may be more energy-
economical to not activate all the antenna elements—which
may be important for the sustainability and battery life of
moving base stations and relays, e.g., unmanned aerial vehicle
(UAV)-carried antenna arrays.

Jointly designing the beamformers and selecting antennas
is a mixed integer and nonlinear program, which is known
to be NP-hard [9]. The vast majority of the literature tackles
this problem using continuous programming-based approxima-
tions. For example, [5]–[7], [10] used convex and nonconvex
group sparsity-promoting regularization to encourage turning
off antenna elements. However, the continuous approximations
are often NP-hard problems as well (especially when the
sparsity promotion is done via nonconvex quasi-norms as in
[5]), and thus it is unclear if they can solve the problem of
interest optimally. In addition, works using greedy methods
to assist antenna selection also exist (see, e.g., [9], [11]–
[13]), which often offer better efﬁciency relative to continuous
optimization. But the optimality of joint (R)BF&AS is still not
addressed in these works.

In recent years, machine learning (ML) approaches are
employed to handle the joint BF and AS problem. In [14], a
supervised learning approach was proposed. The basic idea is
to use a continuous optimization algorithm to produce training
pairs (i.e., channel matrices and sparse beamformers), and
then learn a neural network-based regression function using
such pairs. Similar ideas were used in [15], [16] with various
settings. This type of approach in essence mimics the training
pair-generating algorithms at best, and thus the optimality of
their solutions is again not guaranteed.
Contributions. In this work, we revisit
the joint BF and
AS and its extension under imperfect CSI, namely, the joint
robust beamforming (RBF) and AS problem. We are interested
in the unicast BF and RBF formulations in [2] and [17],
respectively. The goal is to satisfy the users’ quality-of-service
(QoS) constraints while minimizing the power consumption,
with only a subset of the antenna elements activated. Our
detailed contributions are as follows:
• Optimal Joint (R)BF&AS via Branch and Bound. Our
ﬁrst contribution lies in an optimal computational framework
to attain the global optimal solutions to the joint (R)BF&AS
problems. To this end, we propose a Branch and Bound (B&B)

 
 
 
 
 
 
[18], [19] framework that
is tailored for the problems of
interest. Our design leverages problem structures of unicast BF
and RBF, which allows for branching only on a subset of the
optimization variables—thereby having reduced complexity
and being effective. Unlike continuous optimization-based
approximations in [5]–[7], [10] whose solutions are often sub-
optimal or infeasible, the proposed B&B is guaranteed to
return an optimal solution.
• An ML-based Acceleration Scheme. B&B is known for
its relatively weak scalability. To improve efﬁciency, an idea
from the ML community (see, e.g., [20], [21]) is to learn
a binary classiﬁer ofﬂine using multiple problem instances.
The classiﬁer determines whether or not any encountered
intermediate state of the B&B algorithm could be “skipped”,
as skipping these states saves computational resources and
expedites the B&B process. Generic ML learning functions
(e.g., support vector machines (SVM)) used in existing works
like [20], [22] do not reﬂect the problem structure in wireless
communications. In this work, we propose a graph neural
network (GNN) [23] based learning function designed to
exploit the physics of the (R)BF problem—which offers an
enhanced classiﬁcation accuracy. More importantly, the GNN
is agnostic to the change of scenarios (e.g., problem size)
during training and testing. This feature is designed to meet
the need of wireless communication systems, as the number of
users served by a base station could change quickly in practice.
• Theoretical Understanding. We present comprehensive
performance characterizations for the proposed approaches. In
particular, we show that the ML-based acceleration retains the
global optimality of the B&B procedure with high probability,
under reasonable conditions. ML-based B&B acceleration has
limited theoretical studies, and the results were developed
under often overly ideal settings (e.g., convex classiﬁer) [20],
[24]. There is a lack of understanding of the impacts of key
factors such as nonconvexity, limited training samples, and
the employed ML model’s structure. Our analysis takes into
consideration of key aspects such as the nonconvexity of the
GNN learning process, the GNN’s structure and complexity,
the GNN’s function approximation error, and the amount
of available samples. As a consequence, the analysis offers
insights to reveal key trade-offs in practice.

Related Works. B&B was proposed for beamforming prob-
lems in [25], [26], and antenna selection problems in [27]–
[29]. Particularly, the work in [25] considered single group
multicast beamforming problem, the work in [28] considered a
joint power allocation and antenna selection problem, the work
in [27] considered antenna selection-assisted rate maximiza-
tion in wiretap channels, and [29] considered receive antenna
selection for sum rate maximization. However these are differ-
ent from the QoS-constrained downlink transmit beamfroming
formulation considered in our work, which requires new B&B
designs. ML-based B&B acceleration so far has been mostly
used for mixed integer and linear programs (MILPs) in the
ML community, e.g., [20], [30], where the B&B design is
standard. Such methods have also been adopted in wireless
communications in [22], [31] where resource allocation tasks
are framed as mixed integer and nonlinear programs (MINPs).

2

However, the joint (R)BF&AS problem has not been consid-
ered. In addition, comprehensive theoretical understanding to
such ML-acceleration procedures has been elusive.

Notation: x, x and X denote a scalar, a vector, and a
matrix, respectively. xn denotes the nth column of X. We
use the matlab notation X(n, :) to denote the nth row of
X. [N ] denotes the set {1, 2, . . . , N }. (cid:107)x(cid:107)2, (cid:107)x(cid:107)∞, (cid:107)X(cid:107)2,
(cid:107)X(cid:107)F , (cid:107)X(cid:107)row−0 denote the vector (cid:96)2 norm, vector (cid:96)∞
norm, matrix spectral norm, matrix Frobenius norm, and the
number of non-zero rows in the matrix, respectively. Tr(X),
X H , and X(cid:62) denote the trace, hermitian, and transpose of
X. |X | denotes the cardinality of the set X . E[·] denotes
the expectation operator. X (cid:23) 0 denotes that X is positive
semi-deﬁnite matrix. X(S, :) with S ⊆ [N ] denotes the
submatrix of X ∈ CN ×M containing only the rows of X
contained in the set S. X−n denotes the submatrix of X with
the nth column removed. f (·) is C-Lipschitz continuous iff
(cid:107)f (x) − f (y)(cid:107)2 ≤ C(cid:107)x − y(cid:107)2.

I. BACKGROUND

Consider a classic single-cell downlink communication sce-
nario where the base station (BS) has N antennas [2], [17].
The BS serves M single antenna users. Suppose that the BS
has L RF chains where L < N . This limits the maximal
number of active antenna elements to L. Denote wm ∈ CN
as the beamforming vector for serving user m. The message
signal for user m is represented by sm(t). Given the channel
hm ∈ CN between the BS and user m, the signal received by
user m can be expressed as follows:

ym(t) = hH

mwmsm(t) +

(cid:88)

(cid:96)(cid:54)=m

hH

mw(cid:96)s(cid:96)(t) + nm,

m. Assume w.l.o.g. that {sm(t)}M

where nm is zero-mean circular symmetric white Gaussian
noise with variance σ2
m=1 are
mutually uncorrelated and temporally white with zero-mean
and unit-variance. Then, the total transmission power is given
by (cid:80)M
F, where W = [w1, . . . , wM ].
The signal to interference and noise ratio (SINR) at the mth
receiver is expressed as:

2 := (cid:107)W (cid:107)2

m=1 (cid:107)wm(cid:107)2

SINRm =

|wH
(cid:96)(cid:54)=m |wH

mhm|2
2
(cid:96) hm|2
2 + σ2
m

(cid:80)

.

(1)

A. Beamforming and SOCP

One of the most popular formulations for beamforming is
the so-called QoS formulation [32]–[34] that tries to maintain
a pre-speciﬁed SINR level for all users. When hm is known,
the BF problem can be formulated as follows:

minimize
W

(cid:107)W (cid:107)2
F

subject to

|wH
(cid:96)(cid:54)=m |wH

mhm|2
(cid:96) hm|2 + σ2
m

(cid:80)

(2a)

≥ γm, m ∈ [M ]. (2b)

Problem (2) appears to be nonconvex, but it can be recast as
a second-order cone program (SOCP):

Lemma 1 ( [35]). Eq. (2b) can be equivalently written as a
second-order cone constraint:

1
(cid:112)γmσ2

m

Re(wH

mhm) ≥

(cid:115)(cid:88)

(cid:96)(cid:54)=m

|wH

(cid:96) hm|2 + 1,

(3)

for all m ∈ [M ]. Therefore, any algorithm for solving SOCP
can be used to solve (2) optimally.

B. Robust Beamforming and SDR

When the BS only has imperfect CSI, the following worst-

case RBF formulation is often considered [17]:

minimize
W

(cid:107)W (cid:107)2
F

subject to min

hm∈Um

(cid:80)

|wH
(cid:96)(cid:54)=m |wH

mhm|2
(cid:96) hm|2 + σ2
m
∀m ∈ [M ],

≥ γm,

(4a)

(4b)

where Um := {hm + em | (cid:107)em(cid:107)2 ≤ εm}, hm is the
approximate channel vector available at the BS, and εm is
the bound on the approximation error. Problem 4 cannot be
directly converted to a convex program as in the perfect CSI
case (cf. Lemma 1). However, Problem (4) can be tackled by
a convex relaxation technique, namely, semidefnite relaxation
(SDR) [36]. Let Wm := wmwH
m. Then the SDR of (4) is
given by

minimize
{Wm∈CN ×N }M

m=1

M
(cid:88)

i=1

Tr(Wm)

subject to min

hm∈Um

(cid:80)

h

H
mWmhm
H
mWjhm + σ2
m

j(cid:54)=m h

(5a)

≥ γm,

(5b)

Wm (cid:23) 0,

∀m ∈ [M ].

Note that (5) and (4) are equivalent if the constraint Wm =
wmwH
m (or, rank(Wm) = 1) has not been relaxed. Problem
(5) can be further re-expressed as a standard semideﬁnite
program (SDP) using the S-Lemma; see details in [17].
Interestingly, this relaxation procedure turns out to be tight
under reasonable conditions:

Lemma 2 ( [17, Theorem 1]). Suppose that Problem (4) is
feasible. Let Πm := I − H−m(H H
−m be the
orthogonal complement projector of H−m. If

−mH−m)−1H H

(cid:107)Πmhm(cid:107)2
2
ε2
m

> 1 + M + (M −

1
M

)γm, ∀m,

(6)

then the optimal solution of (4) can be obtained using SDR.

The condition in (6) means that if the downlink channels
associated with different users are sufﬁciently different, then
the SDR is tight.

C. Joint (R)BF&AS: Existing Approaches

In this work, we consider the joint (R)BF&AS problem:

minimize
W

(cid:107)W (cid:107)2
F

subject to C(wm, hm, εm, σm) ≥ γm,
(cid:107)W (cid:107)row-0 ≤ L.

3

(7a)

(7b)

(7c)

where the row-0 function (cid:107) · (cid:107)row-0 counts the number of

nonzero rows in W and




C(wm, hm, εm, σm)
mhm|2
(cid:96) hm|2+σ2
m
|wH
(cid:96)(cid:54)=m |wH

|wH
(cid:96)(cid:54)=m |wH
minh∈Um

:=



(cid:80)

(cid:80)

,
mhm|2
(cid:96) hm|2+σ2
m

if BF is considered,

,

if RBF is considered.

Problem (7) is a non-convex combinatorial problem, and it is
NP-hard [37]. In the literature, Problem (7) and its variants
are often handled by continuous approximation. For example,
a representative continuous approximation technique was used
in [5] for handling the multicast BF&AS problem. Using the
same idea for (7), one can recast the problem as a regularized
formulation as follows:

minimize
W

(cid:107)W (cid:107)2

F + λ(cid:107)W (cid:107)row-0

(8)

subject to C(wm, hm, εm, σm) ≥ γm, m ∈ [M ].

Following the idea in [5], the row-0 function can be approx-
imated by a group sparsity-inducing norm, namely, the (cid:96)∞,1
norm, i.e., (cid:107)W (cid:107)row-0 ≈ (cid:80)N
n=1 (cid:107)W (n, :)(cid:107)∞ and its noncon-
vex counterpart (cid:107)W (cid:107)row-0 ≈ (cid:80)N
n=1 log ((cid:107)W (n, :)(cid:107)∞ + ε)
[38]. Similar ideas were used in [10]. Such continuous ap-
proximations allow the use of standard nonlinear program
techniques to tackle (8). However, as mentioned, these meth-
ods do not provide any optimality guarantees. In addition,
the feasiblity of (cid:107)W (cid:107)row-0 ≤ L is often not met by the
approximate solutions.

More recently, a number of learning-based approaches are
proposed to tackle the joint (R)BF&AS problem; see, e.g.,
[14], [39], [40]. In [14], a multicast version of (7) was con-
sidered. There, an existing joint multicast BF&AS algorithm
(e.g., the continuous approximation algorithm in [5]) was used
to generate “training pairs” by simulating a large number of
problem instances:

{Ht, (cid:99)Wt}T

t=1,

where t is the instance index, (cid:99)Wt is a (row-sparse) solution
produced by the training-pair generating algorithm. Then, a
deep neural network (DNN) fθ(·) is trained via

(cid:98)θ ← arg min

θ

1
T

T
(cid:88)

t=1

(cid:96)( (cid:99)Wt, fθ(Ht)),

(9)

where θ represents the parameters of the DNN and (cid:96)(x, y)
measures the divergence between x and y. When a new H
is seen in the test stage, one can use the learned DNN to
predict the solution, i.e., (cid:99)W = f
(cid:98)θ(H). Finally, antennas
corresponding to the L largest (cid:107) (cid:99)W (n, :)(cid:107)2’s are selected. This
“supervised learning” idea is similar to a line of work in deep
learning based wireless system design; see, e.g., [41], [42].
Notably, it cannot exceed the performance of the algorithm that
produces the training pairs or ensure producing a row sparse

solution in the test stage. Other deep learning-based ideas were
seen in [16], [39], [40], [43] using either supervised learning or
unsupervised learning variants, but similar challenges remain.

II. OPTIMAL JOINT (R)BF&AS VIA B&B
A natural idea for solving hard optimization problems is
to employ a global optimization technique, e.g., the B&B
procedure [18], [19], [44]. Designing a practically working
B&B algorithm is often an art—it normally involves judicious
exploitation of problem structures. That is, not every hard
problem enjoys an efﬁcient B&B algorithm. Nonetheless, as
we will see, the special properties of BF and RBF allows for
an effective B&B design.

A. Preliminaries of B&B

We follow the notations from the tutorial in [44] to give
a brief overview of B&B’s design principles. Consider a
nonconvex problem

minimize
x

f (x)

subject to x ∈ X .

(10a)

(10b)

where both the objective function and the constraint can be
nonconvex. Suppose that there is a partition of the space X =
X1 ∪ . . . ∪ XS, and that lower and upper bounds of f (x) over
each Xi is easier to ﬁnd (relative to directly solving (10)). Let
Φlb(Xi) and Φub(Xi) be the algorithms that return lower and
upper bounds of the optimal solution of (10) over the set Xi,
respectively. Then, the following holds:

min
1≤i≤S

Φlb(Xi) ≤ Φ(X ) ≤ min
1≤i≤S

Φub(Xi).

(11)

where Φ(X ) represents the optimal solution of (10) over the
feasible region X . A premise of the success of B&B is that
one could ﬁnd a partition Xi for i = 1, . . . , S and a pair of
functions Φlb and Φub which can make the following hold:

min
1≤i≤S

Φub(Xi) − min
1≤i≤S

Φlb(Xi) ≤ (cid:15)

(12)

where (cid:15) > 0 is a pre-speciﬁed error tolerance parameter.

The effectiveness of B&B relies on two key factors. First,
the design of the lower and upper bounding algorithms repre-
sented by Φlb(Xi) and Φub(Xi), respectively, plays a central
role. Second, the way of partitioning the space X also matters.
It often requires a problem-speciﬁc way to progressively and
judiciously partition the constraint set X (usually from rough
the difference in (12) could shrink
to ﬁne-grid), so that
quicker than exhaustive search. Meeting either of the design
requirements is not necessarily easy. Moreover, the key designs
in B&B algorithms (e.g., the X partition strategies) are highly
problem-dependent; that is, there is hardly a “standard recipe”
for B&B algorithm design.

B. Proposed B&B for Joint (R)BF&AS

Problem (7) involves optimization in discrete and contin-
uous spaces simultaneously. Designing a B&B algorithm for
such problems can be difﬁcult due to the large search space.
However, the special structure of (R)BF in (7) allows us to
bypass the continuous (beamforming) part when branching the
feasible space.

4

(7b), (7c)

W (n1, :) = 0

W (n1, :) ∈ CM

(7b), (7c),
W (n1, :) = 0

(7b), (7c),
W (n1, :) ∈ CM

W (n2, :) = 0

W (n2, :) ∈ CM

W (n3, :) = 0

W (n3, :) ∈ CM

(7b), (7c),
W (n1, :) = 0,
W (n2, :) = 0

(7b), (7c),
W (n1, :) = 0,
W (n2, :) ∈ CM

(7b), (7c),
W (n1, :) ∈ CM ,
W (n3, :) = 0

(7b), (7c),
W (n1, :) ∈ CM ,
W (n3, :) ∈ CM

Fig. 1.
branching variables selected at each node.

Illustration of B&B tree for problem (7). Here ni ∈ [N ] are the

1) B&B Tree Construction: We illustrate the idea of sys-
tematically partitioning the feasible region of Problem (7) in
Fig. 1. Here, N ((cid:96))
denotes the feasible region corresponding to
the ith node at the (cid:96)th level. In the sequel, we will use the term
“node” and the associated feasible region interchangeably. The
root is denoted as N (0), and we have

i

N (0) = {W | W satisﬁes (7b), (7c)}.

In the ﬁrst level, the region represented by the root node is
split into two regions represented by two child nodes, namely,

N (1)
N (1)

1 = {W | W (n1, :) = 0, W satisﬁes (7b), (7c)}
2 = {W | W (n1, :) ∈ CM , W satisﬁes (7b), (7c)}.

where n1 ∈ [N ] is an antenna index selected by a certain
criterion (e.g., via random sampling). Up to the ﬁrst level
of the tree, the status (“include (activate)” or “exclude (shut
down)”) of all antennas other than antenna n1 have not been
decided.

Note that the nodes in the B&B tree could constitute a
partition in various forms. For example, for nodes in the same
level, we have

N ((cid:96))

1 ∪ . . . ∪ N ((cid:96))
S(cid:96)

= N (0),

where S(cid:96) = 2(cid:96) is the number of nodes in the (cid:96)th level of the
tree. In addition, we have

N ((cid:96))

s = N ((cid:96)+1)

s1

∪ N ((cid:96)+1)
s2

,

(13)

s

s

s

where s1 := 2(s − 1) + 1 and s2 := 2(s − 1) + 2 represent
the left and right children developed from N ((cid:96))
in the full
tree. In fact, the children of N ((cid:96))
−s also
present a partition of the root node, where N ((cid:96))
−s is the union
with N ((cid:96))
of N ((cid:96))

in any level and N ((cid:96))

excluded.

1 , . . . , N ((cid:96))
S(cid:96)

The B&B algorithm starts from the ﬁrst level to compute
lower and upper bounds of (7) over the node-deﬁned regions.
Then, the B&B algorithm picks a node to “branch”, i.e., to
further partition, according to a certain heuristic-based metric;
see [18]. Going deeper in the tree towards the ﬁnal leaves will
allow us to progressively decide which antennas to activate or
shut off. Let t denote the iteration index of the B&B algorithm,
where an iteration corresponds to a branching (partitioning a
node) operation. Use P (t) to denote the collection of (s, (cid:96))

corresponding to the unbranched nodes. Then, the union of
N ((cid:96))
’s for (s, (cid:96)) ∈ P (t) represents a partitioning of the root in
s
iteration t. In each iteration t, the stopping criterion in (12) is
evaluated. It follows that the following two quantities need to
be evaluated:

l(t)
G = min

(s,(cid:96))∈P (t)

Φlb(N ((cid:96))

s

), u(t)

G = min

(s,(cid:96))∈P (t)

Φub(N ((cid:96))

s

),

G and u(t)

where l(t)
G are the global lower and upper bounds in
iteration t. In particular, the lower and upper bounds over the
newly created two child nodes need to be found—since other
nodes have been evaluated in a certain previous iteration. The
hope is that one would not need to visit all nodes of tree before
reaching the stopping criterion in (12).
2) Lower and Upper Bounds:
) and Φub(N ((cid:96))

to compute
Φlb(N ((cid:96))
s ⊆ [N ] and
B((cid:96))
s ⊆ [N ]\A((cid:96))
to be the index sets of the antennas that
s
have been activated and shut down at node s in level (cid:96),
s ∪ B((cid:96))
respectively. Note that A((cid:96))
s ⊆ [N ] constitute the set
of decided antennas at the node. Then, ﬁnding the upper and
lower bounds of (cid:107)W (cid:107)2
F at this node amounts to ﬁnding those
of the following optimization problem:

In order
), let us deﬁne A((cid:96))

s

s

minimize
W

(cid:107)W (cid:107)2
F

(14)

subject to C(wm, hm, εm, σm) ≥ γm, ∀m,

∀n ∈ B((cid:96))
s ,

W (n, :) = 0,
W (n, :) ∈ CM ,
∀n ∈ A((cid:96))
s ,
(cid:107)W (cid:107)row−0 ≤ L, n ∈ [N ].

For any given node N ((cid:96))
solving the following relaxation of (14):

s

, the lower bound can be obtained by

Φlb(N ((cid:96))

s

) = minimize

W

(cid:107)W (cid:107)2
F

subject to C(wm, hm, εm, σm) ≥ γm, ∀m,

W (n, :) = 0,

∀n ∈ B((cid:96))
s ,

(15a)

(15b)

where we have dropped (cid:107)W (cid:107)row−0 ≤ L.

In the following lemma, we show that (15) can be optimally
solved for all nodes in the B&B tree. It also helps derive a
procedure for Φub(·).

Lemma 3. Regarding (15), the following hold:

(a) Consider the BF case where perfect CSI is given. Then,

(15) can be optimally solved by using SOCP.

(b) Consider the RBF case where imperfect CSI is given.

Assume that

(cid:107)Πm(cid:101)hm(cid:107)2
2
ε2
m

> 1 + M + (M −

1
M

)γm, ∀m,

(16)

where Πm := I − (cid:102)H−m((cid:102)H H
−m, holds for
(cid:102)H ∈ {H(S, :)|∀S ∈ [N ], |S| ≥ L}. Then, Problem (15)
can be optimally solved using SDR.

−m (cid:102)H−m)−1 (cid:102)H H

5

(c) Under the same conditions of (a) and (b), solving the
following gives a valid upper bound of (14) under the
BF and RBF cases, respectively:

Φub(N ((cid:96))

s

) = minimize

W

(cid:107)W (cid:107)2
F

(17a)

subject to C(wm, hm, εm, σm) ≥ γm, ∀m,

(17b)

W (n, :) = 0,

∀n ∈ (cid:101)B((cid:96))
s ,

s ∪ B((cid:96))
s

s = C((cid:96))

where (cid:101)B((cid:96))
represents the set of N − L
antennas to be excluded, and C((cid:96))
s ∪ B((cid:96))
s )
is the index set of undecided antennas that have been
assigned the minimum power in the solution of (15).

s ⊆ [N ]\(A((cid:96))

The proof of Lemma 3 is relegated to Appendix B.
3) Node Selection and Branching: After (15) and (17) are
computed in iteration t, l(t+1)
are updated. If the
G
stopping criterion u(t)
G ≤ ε is not met, one needs to pick
a node in P (t) to further partition. To this end, we employ the
“lowest lower bound ﬁrst” principle that is often used in the
literature [18]. To be speciﬁc, we pick a non-leaf node N ((cid:96)(cid:63))
such that

and u(t+1)
G

G − l(t)

s(cid:63)

((cid:96)(cid:63), s(cid:63)) ∈ arg

min
(s,(cid:96))∈P (t)\Sleaf

Φlb(N ((cid:96))

s

),

(18)

s | = L, |B((cid:96))

where Sleaf := {((cid:96), s) : |A((cid:96))
s | = N − L} is the
set of leaf nodes. To partition the region N ((cid:96)(cid:63))
, we need to
pick an undecided antenna and decide whether to include or
exclude it in our solution. We select the antenna that has been
assigned the largest power among the undecided antennas in
iteration t, i.e.,

s(cid:63)

n(cid:63) = arg

max
i∈[N ]\(A((cid:96)(cid:63) )
s(cid:63) ∪B((cid:96)(cid:63) )
s(cid:63) )

(cid:107)W ((cid:96)(cid:63))
s(cid:63)

(i, :)(cid:107)2
2,

(19)

:= arg minW (15) at N ((cid:96)(cid:63))

where W ((cid:96)(cid:63))
. Then, n(cid:63) is used
s(cid:63)
s(cid:63)
to partition N ((cid:96)(cid:63))
into two child nodes (i.e., excluding and
including antenna n(cid:63) on top of the decided antennas in
N ((cid:96)(cid:63))
). The associated include/exclude sets in the child nodes,
s(cid:63)
N ((cid:96)(cid:63)+1)
s(cid:63)
i

, i ∈ {1, 2}, are updated as follows:

s(cid:63)

B((cid:96)+1)
s(cid:63)
1
A((cid:96)+1)
s(cid:63)
2

= B((cid:96))
= A((cid:96))

s(cid:63) ∪ {n(cid:63)}, A((cid:96)+1)
s(cid:63) ∪ {n(cid:63)}, B((cid:96)+1)

s(cid:63)
1

s(cid:63)
2

= A((cid:96))
s(cid:63) ,
= B((cid:96))
s(cid:63) .

Note that if any of the child nodes, have L included or N − L
excluded antennas, we apply the following update:

B((cid:96)(cid:63)+1)
s(cid:63)
i
A((cid:96)(cid:63)+1)
s(cid:63)
i

= [N ]\A((cid:96)(cid:63)+1)
= [N ]\B((cid:96)(cid:63)+1)

s(cid:63)
i

s(cid:63)
i

if |A((cid:96)(cid:63)+1)
s(cid:63)
i
if |B((cid:96)(cid:63)+1)
s(cid:63)
i

| = L

| = N − L.

(20)

This ensures that we do not generate any new nodes that do
not satisfy (7c). Finally, the two children replace N ((cid:96)(cid:63))
in P (t)
to form P (t+1).

s(cid:63)

Note during the process, some nodes in the B&B tree can
be simply discarded, or, “fathomed”—as in the standard ter-
minologies of B&B [18]. After iteration t, one can potentially
ﬁnd a set of (s(cid:48), (cid:96)(cid:48)) such that

Φlb(N ((cid:96)(cid:48))

s(cid:48)

) > u(t)
G .

The above means that N ((cid:96)(cid:48))
needs not to be further partitioned
in the next iteration. Hence, we can form a set F (t) in each
iteration, which only contains the nodes that need to be further
considered, i.e.,

s(cid:48)

F (t) =

(s(cid:48), (cid:96)(cid:48)) ∈ P (t) (cid:12)
(cid:110)
(cid:12)
(cid:12) Φlb

(cid:16)

N ((cid:96)(cid:48))
s(cid:48)

(cid:17)

≤u(t)
G

(cid:111)

This is arguably the most important for attaining efﬁciency
against exhaustive search. The B&B procedure can be found
in Appendix A.

4) An Alternative B&B Method: It is interesting to note
that there is often more than one way to come up with a B&B
procedure for a given problem. For example, a commonly
used approach for deriving B&B of mixed integer and linear
programs (MILPs), and more generally, subset selection prob-
lems (see, e.g., [22], [45]) can also be used for our problem
(7). The method is by introducing auxiliary Boolean variables.
Speciﬁcally, problem (7) can be expressed as follows:

minimize
W ,z

(cid:107)W (cid:107)2
F

subject to C(wm, hm, εm, σm) ≥ γm,
z ∈ {0, 1}N ,
z(cid:62)1 ≤ L,
(cid:107)W (n, :)(cid:107)2 ≤ Cz(n), ∀n ∈ [N ].

(21a)

(21b)

where C < ∞ is a large positive constant and z(n) = 0
means that the nth antenna is excluded whereas z(n) = 1
indicates the opposite. The constraint in (21b) can be relaxed
to be z ∈ [0, 1]N for ﬁnding the lower bound (see Appendix
C-B2 for details). In this procedure, the branching operations
are imposed on the new variable z [22], [45]. The reason
that we do not choose formulation
(21) to design B&B
for our joint (R)BF&AS problem is that this approach could
be computationally (much) less efﬁcient compared to the
proposed approach (see a proof in Theorem 1).

The computational efﬁciency of our method comes from
the fact that the computation of upper and lower bounds in
(15) and (17) can be reused for many nodes; see the proof
of Theorem 1. However, it is not obvious if such kind of
computation reduction is still possible for the formulation
in (21).

C. Optimality

We show that the proposed algorithm will produce optimal

solutions for the problem of interest:

Theorem 1. Regarding the proposed B&B procedure (see
Appendix A), the following statements hold:
(a) When BF is considered, the proposed B&B solves (7)

optimally.

(b) When RBF is considered, if the conditions in Lemma 3(b)
are satisﬁed, the proposed B&B solves (7) optimally.
(c) The total number of SOCPs/SDRs solved by the proposed

B&B is upper bounded by

QCompute =

(cid:19)

(cid:18)N
L

+

N −L+1
(cid:88)

i=2

(cid:19)

(cid:18)N − i
L − 1

.

6

L

L

(cid:1) − 1.

it feels a bit surprising that

The number of SOCPs/SDRs needed by the B&B asso-
ciated with the alternative formulation in Sec. II-B4 is
Compute = 2(cid:0)N
upper bounded by Q(cid:48)
The proof of Theorem 1 is in Appendix C. At the ﬁrst
the B&B algorithms
glance,
(cid:1) SOCP/SDRs to ﬁnd the optimal
could use more than (cid:0)N
solution, since this seems to be worse than exhaustive search.
This is because, in the worst case, B&B visits many more
intermediate states in the search tree—but exhaustive search
only visits the leaves. Nonetheless, in practice, B&B is often
much more efﬁcient than exhaustive search since B&B does
not really exhaust all the nodes. Theorem 1 (c) spells out
the advantage of our B&B design relative to the more classic
B&B idea as in (21) from the MILP literature. Note that the
reduction of complexity shown in (c) could be substantial. For
example, when (N, L) = (12, 8), QCompute =660, whereas
Q(cid:48)
Compute =989. Hence, there is a potential saving of 339
SOCPs/SDRs (reduction by 34%) in the worst case.

III. ACCELERATED JOINT (R)BF&AS VIA ML

The challenge of any B&B algorithm lies in the large
number of nodes in the tree. This means that in the worst
case, many SOCPs and SDRs need to be solved. An idea from
the ML community is to “train” a classiﬁer to recognize the
relevant nodes, i.e., nodes that lead to leaves containing the
optimal solution [20]. If a node is deemed to be “irrelevant”,
the B&B algorithm would simply skip branching on this node,
and thus could save a substantial amount of time. In this
section, we will show that a similar idea can be used for
accelerating our B&B based joint (R)BF&AS algorithm—with
carefully designed neural models to meet the requirements
arising in wireless communications. More importantly, we will
present comprehensive performance characterizations, includ-
ing sample complexity and global optimality retention, which
are currently lacking in the existing literature.

A. Preliminaries: Node Classiﬁcation and Imitation Learning

1) Node Classiﬁcation: Let us denote

πθ : RP → [0, 1]

as the node classiﬁer parameterized by θ, which returns the
probability of a node being relevant. Let

φ(N ((cid:96))

s

) ∈ RP

be the mapping from a node to its feature representation.
When πθ(φ(N ((cid:96))
)) < 0.5, then the node is deemed irrelevant.
s
Otherwise, the node is branched.

To train such a classiﬁer, denote {(Ns, ys)}T

s=1 as the (node,
label) training data, where we have removed the level indices
of the nodes for notation simplicity. To create the training
pairs, one could run random problem instances of (7) using the
B&B procedure. Note that the label ys is annotated according
to the following rule:

(cid:40)

ys =

1, As ⊆ A(cid:63) and Bs ⊆ [N ]\A(cid:63),
0,

otherwise,

(22)

where As and Bs are the index sets of included and excluded
antennas at node s, respectively, and A(cid:63) is the index set of
the active antennas of the optimal solution found by B&B of
the associated problem instance.

2) Imitation Learning: The simplest supervised learning
paradigm would learn πθ using the following risk minimiza-
tion criterion:

minimize
θ

1
T

T
(cid:88)

s=1

L (πθ (φs) , ys) + r(θ),

(23)

:= φ(Ns), L(x, y) is a certain loss function,
where φs
e.g., the logistic loss, and r(θ) is a regularization term, e.g.,
r(θ) = λ(cid:107)θ(cid:107)2
2. Unfortunately, such a supervised learning
approach often does not work well, since it ignores the fact that
the node generating process is sequential and interactive with
the node classiﬁer in the test stage. In ML-based MILP, the
remedy is to adopt the imitation learning (IL) [24] approach,
where πθ is integrated in the training data generating process
[20]. To be more speciﬁc, the training data generation process
is done in a batch-by-batch manner with online optimization.
The IL training criterion is as follows (see Section III-C for
data generation and training process):

θ(i+1) =

(24)

arg min

θ

1
i

i
(cid:88)

t=1

1
|Dt|

(cid:88)

(φs,ys)∈Dt

L (πθ(φs), ys) + r(θ),

where Dt is the tth batch of training pairs. The learned model
parameter (cid:98)θ is selected from θ(i)’s via the following:

(cid:98)θ = arg min
θ∈{θ(i)}I

i=1

E(φs,ys) [L (πθ(φs), ys)] ,

(25)

where I is the total number of batches generated during the
training process. In practice, one can use a validation set
to approximate the above expectation. In the test stage, the
proposed B&B algorithm is run with the assistance of π

(cid:98)θ.

The key of using IL to accelerate the proposed B&B for
joint (R)BF&AS is twofold, namely, a practical node classiﬁer
tailored for wireless communications and a convergent online
training algorithm. We will detail our designs to address the
two requirements in the next subsections.

B. GNN-based Node Classiﬁer for Joint (R)BF&AS

To design the node classiﬁer, a critical consideration in
wireless communications is that the number of users to serve
could drastically change from time to time. This requires us
to design an ML model that is agnostic to such changes, as
re-training a model when change happens is not affordable.
Towards this end, we design a GNN-based node classiﬁer [23].
Note that GNNs learn aggregation operators over a graph, and
thus is naturally robust to the change of entities on the graph.
We will leverage this property to design our node classiﬁer.

To describe the GNN-based node classiﬁer, we ﬁrst deﬁne
a graph to represent N ((cid:96))
. Fig. 2 illustrates the idea, where
the antennas and users represent the vertices, and the channel
represent the edge between the vertices. It is important to
design the features of the vertices and the edges, so that they

s

7

Fig. 2.

Illustration of the input graph representation for a node.

represent the essential information of the node N ((cid:96))
speciﬁc, We let

s

. To be

xn ∈ RVa , n ∈ [N ], xN +m ∈ RVu, m ∈ [M ], and
en,N +m ∈ RVe , n ∈ [N ], m ∈ [M ]

represent the feature vectors of antenna n (a vertex), user m
(a vertex), and the channel between the antenna n and the user
m (an edge), respectively. Layer d of the GNN “aggregates”
the embedding of graph neighbors to update the the uth vertex
for all u ∈ [M +N ]. The deﬁnition of such aggregation can be
ﬂexible. For example, in the message passing neural network
[46], the aggregation is done by the following:

u = ξ(Z1q(d−1)
q(d)

u

+

(cid:88)

v∈Eu

ξ(Z2q(d−1)
v

+ Z3eu,v)),

(26)

where q(0)
u = xu; Zi for i = 1, 2, 3 are the aggregation
operators of the GNN; ξ(·) represents the activation functions
of layer d; and Eu is the index set of all the one-hop neighbors
of vertex u on the graph. The output of the GNN is
(cid:16)

(cid:17)

(cid:88)

ζ

β(cid:62)q(D)
u

, φs = φ(Ns) ∈ RP

πθ(φs) =

1
U

u∈[U ]

N +M , e(cid:62)

1, . . . , x(cid:62)

1,N +1, . . . , e(cid:62)

where U = M + N is the total number of vertices;
φ(Ns) = [x(cid:62)
N,N +M ](cid:62); and ζ(·)
is a sigmoid function. Here, the parameter to be optimized is
given by θ := [vec(Z1)(cid:62), vec(Z2)(cid:62), vec(Z3)(cid:62), β(cid:62)](cid:62). Since θ
does not depend on (N, M, L), the learned model can naturally
work when the number of users changes, as long as Va, Vu,
and Ve remain the same.

Table I shows the detailed feature descriptions. We de-
sign two types of features, namely, problem size-dependent
(containing information of (N, M, L)) and problem size-
independent features; see Appendix G for detailed conversion
from these features to xn and eu,v. Note that the special
structure of GNN allows us to employ problem-size depen-
dent features, as the sizes of aggregation matrices Zi are
determined by the feature vector size, instead of the numbers
of vertices (N + M ) and edges. However, if one uses SVM
as in [20] or other types of neural networks (e.g., fully
connected network (FCN) and convolutional neural network
(CNN)), these features cannot be used. We should remark
that our feature design is not “optimal” in any sense, but
using problem size-dependant features arguably provides more
comprehensive information about the node and could often
enhance the node classiﬁcation accuracy.

Table II shows numerical evidence to support our postulate.
There, different classiﬁers are trained by IL using problem
instances as described in Sec. IV. The FCN has two hidden

TABLE I
FEATURE DESIGN FOR THE GNN BASED NODE CLASSIFIER.

Problem Size-Dependent
A((cid:96))
s
B((cid:96))
s

[(cid:107)W(cid:96),s(1, :)(cid:107)2

2, . . . , (cid:107)W(cid:96),s(N, :)(cid:107)2
2]

H
Wincumbent (see Algorithm 3)
W(cid:96),s
|W(cid:96),s(:, m)H hm|2
Aggregate Interference using W(cid:96),s

Problem Size-Independent
l(t)
G
u(t)
G
Φlb(N ((cid:96))
)
Φub(N ((cid:96))
)
s
(cid:96)
) − u(t)
1(Φub(N ((cid:96))

G < (cid:15))

s

s

TABLE II
CLASSIFICATION ERROR (%) ATTAINED BY SVM, FCN AND GNN BASED
CLASSIFIER FOR CLASSIFYING RELEVANCE OF THE NODES.
γm = σm = 1, ε = 0.1.

Problem sizes
(N, M, L)
SVM
FCN
GNN

Perfect CSI

Approximate CSI

(4,3,2)

(8,6,4)

(4,3,2)

(8,5,4)

8.49
6.93
7.26

16.67
13.95
12.23

7.17
26.95
6.62

11.67
10.18
8.49

layers with 32 hidden units in each layer, a sigmoid activation
funtion on the output layer, and ReLU activations on the
remaining layers. The architecture of the GNN is described
in Appendix F. The SVM and FCN could only use the
problem size-independent features. The GNN with both types
of features clearly offers a lower node classiﬁcation error.

C. Data Generation and Online Training

We use an IL framework to train the GNN, which is
summarized in Algorithm 1. The framework is based on
the online learning method in [24]. The work in [24] was
proposed for convex learning criteria. Necessary modiﬁcations
are made in Algorithm 1 to accommodate our nonconvex
learning problem.

Algorithm 1 consists of two steps in each iteration: data
collection and classiﬁer improvement. In the ith iteration, the
accumulated dataset Di is obtained by solving B&B on R
problem instances using the current classiﬁer learned from the
previous data batches, πθ(i) . Then, the classiﬁer is retrained
using ∪i

t=1Di and

(cid:98)θ(i+1) = arg min
θ∈Θ

gi(θ) + r(θ)

where Θ speciﬁes the constraints of the GNN parameters [cf.
Eq (28)]; the loss function gi(·) is deﬁned as follows:

gi(θ) :=

1
i

i
(cid:88)

t=1

1
|Dt|

(cid:88)

(φs,ys)∈Dt

L(πθ(φs), ys);

(27)

additionally, we select r(θ) = −ψ(cid:62)θ in which ψ is sampled
from exponential distribution in each iteration. This speciﬁc
choice of r(θ) plays an important role in our nonconvex
learning problem (where the nonconvexity arises due to the use
of GNN). To be more speciﬁc, such a random perturbation-
based r(θ) is advocated by recent developments from non-
convex online learning [47]. It was shown in [47] that using

8

Algorithm 1: Online GNN Learning
1 Input: I, R(number of training instances per batch), η;
2 D1 = {};
3 for i = 1 to I do
4

Sample ψ ∼ (Exp(η))B // Exp(η) is the

exponential distribution with pdf
p(x) = η exp(−ηx); θ(i) ∈ RB;

for r = 1 to R do

Generate problem instance Q;
if i=1 then

D(Q) ← run BB(Q) and label the nodes using optimal

solution;

else

D(Q) ← Algorithm_2(Q, πθ(i) );

end
Di ← Di ∪ D(Q);

1
i

(cid:80)i

t=1

1
|Dt|

(cid:80)

(φs,ys)∈Dt

L(πθ(φs), ys) −

end
θ(i+1) =

arg minθ∈Θ
ψ(cid:62)θ

15 end
16 Return (cid:98)θ =

1
arg minθ∈θ1:I
|Dvalid
i
// where Dvalid
by B&B with πθ(i)

i

(cid:80)

|

(φs,ys)∈Dvalid

i

[L(πθ(φs), ys)]

validation batch i generated

Algorithm 2: Training Data Generation
1 Input: Q, πθ;

// optimal solution and optimal selected

antenna subset to problem Q

2 (W (cid:63), A(cid:63)) = BB(Q); (see Algorithm 4 in Appendix A for BB)
3 Execute Line 2 to Line 7 in Algorithm 3; // Initialization
4 D ← {};
5 while B&B termination criteria is not met do
6

Execute Line 9 to Line 22 from Algorithm 3;
if N ((cid:96)(cid:63))
s(cid:63)
D ← D ∪ {φ((cid:96)(cid:63))

is relevant then

s(cid:63) , 0};

else

D ← D ∪ {φ((cid:96)(cid:63))

s(cid:63) , 1};

end

11
12 end
13 Return D;

5

6

7

8

9

10

11

12

13

14

7

8

9

10

r(θ) = −ψ(cid:62)θ ensures no-regret type convergence of non-
convex online learning. This property is a critical stepping
stone towards establishing learning guarantees of our GNN-
based framework. This will become clearer in the proofs of
Theorem 2.

The training data generation subroutine is given in Algo-
rithm 2. To generate Di, the algorithm ﬁrst runs B&B on
a given problem instance to ﬁnd the optimal solution. Next,
B&B is run again but with πθ(i)
to generate nodes. The
training pairs (φs, ys) are annotated by utilizing the optimal
solution obtained in the ﬁrst run.

The overall GNN-accelerated B&B procedure is summa-
rized in Algoirthm 3. The algorithm is termed as Machine
Learning-based fast Branch and Bound for JOint Beamform-
ing and antenna Selection (MLBB-JOBS). The node classiﬁer
is used in Line 11.

D. Performance Characterizations

Our goal is to characterize the performance of MLBB-JOBS,
the amount of training

e.g., under what conditions (e.g.,

;

where the expectation is taken w.r.t.
(φk, yk).

the distribution of

Algorithm 3: Main Algorithm: MLBB-JOBS
1 Input: Problem instance (hm, σm, γm, εm), ∀m, trained pruning

policy πθ, relative error (cid:15);

// Add the root node first
1 ← {};

1 ← {}, B(0)

2 A(0)
3 Select node using (18) for N (0)
;
4 Wincumbent ← solution to (17);
G ← (cid:107)W (0)
5 l(0)
1 (cid:107)2
6 F (0) ← {(0, 1)};
7 t ← 0;
8 while |F (t)| > 0 and
9

F , u(0)

(cid:12)
(cid:12)
(cid:12)/l

(cid:12)
(cid:12)
(cid:12)u

1

G ← (cid:107)Wincumbent(cid:107)2
F ;

(t)
G

(t)
G −l
Select a non-leaf node ((cid:96)(cid:63), s(cid:63)) using (18);
Remove the selected node F (t) ← F (t)\N ((cid:96)(cid:63))
if πθ

(t)
G > (cid:15) do

≥ 0.5 then

(cid:16)
φ((cid:96)(cid:63))
s(cid:63)

s(cid:63)

(cid:17)

;

using (13)

s(cid:63)
1

and N ((cid:96)(cid:63)+1)
s(cid:63)
2

Select variable n(cid:63) using (19);
Generate child nodes N ((cid:96)(cid:63)+1)
and append to F (t);
N ((cid:96)(cid:63)+1)
k ← arg mini∈{1,2} Φub
s(cid:63)
i
(cid:16)
N ((cid:96)(cid:63)+1)
≤ u(t)
G then
s(cid:63)
k
(cid:17)
(cid:16)
N ((cid:96)(cid:63)+1)
u(t+1)
G ← Φub
s(cid:63)
k
Wincumbent ← solution to (17) for N ((cid:96)(cid:63)+1)

if Φub

(cid:17)
;

(cid:16)

(cid:17)

;

s(cid:63)
k

end
l(t+1)
G ← min((cid:96),s)∈F (t) Φlb

(cid:16)
N ((cid:96))
s

(cid:17)

;

(cid:110)

(s(cid:48), (cid:96)(cid:48)) ∈ F (t) | Φlb

(cid:16)
N ((cid:96)(cid:48))
s(cid:48)

(cid:17)

≤ u(t+1)
G

(cid:111)

;

10

11

12

13

14

15

16

17

18

19

20

21

end
F (t+1) ←
t ← t + 1;

22
23 end
24 Return Wincumbent;

samples and the complexity of the GNN) MLBB-JOBS can
accelerate the proposed B&B without losing its optimality. To
our best knowledge, such performance characterization have
not been provided for ML-based B&B acceleration, even when
the learning problem is convex.

To proceed, we will use the following assumptions:

Assumption 1. Assume that the following statements about
the data features and the GNN in Sec. III-B hold:

(a) The input features are bounded, i.e., (cid:107)xu(cid:107)2, (cid:107)eu,v(cid:107)2 ≤

Bx, ∀u, v.

(b) The activation functions ξ(·) and ζ(·) are Cξ-Lipschitz
and Cζ-Lipschitz continuous, respectively. In addition,
ξ(0) = 0.

(c) Let L : R × R → [−BL, BL] be CL-Lipschitz in its ﬁrst
argument, i.e., |L(x, y) − L(x(cid:48), y)| ≤ CL|x − x(cid:48)|.
(d) The parameters of the GNN are bounded; i.e., (cid:107)Zi(cid:107)2 ≤

BZ, ∀i ∈ {1, 2, 3} and (cid:107)β(cid:107)2 ≤ Bβ.

Let us deﬁne the set of parameters Θ as follows:

Θ := (cid:8)θ = [vec(Z1)(cid:62), vec(Z2)(cid:62), vec(Z3)(cid:62), β(cid:62)](cid:62) |
(cid:107)Zi(cid:107)2 ≤ BZ, β ≤ Bβ, i ∈ {1, 2, 3}(cid:9).

(28)

Using the above, we ﬁrst characterize the generalization error
of the GNN with the following Lemma:

9

for θ ∈ Θ, the following holds with probability at least 1 − δ:

Gap(δ, K)

:= E[L(πθ(φ), y)] − 1/K

(cid:88)

(φk,yk)∈G

L(πθ(φk), yk)

(29)

≤

8CL
K

+

24CLBL√
K

(cid:112)(3E2 + E) log Λ + 3BL

(cid:114)

log (2/δ)
2K

,

where α = ((1 + U Cξ)CξBZ),
√

Λ = 1 + 12

EKBZmax{ΣZ1, ΣZ2 , ΣZ3, Bβ/BZΣβ},

ΣZ1 = CζBβU C 3

ξ BZBx

α(D+1) − 2α + 1
(α − 1)2

, ΣZ2 = U CξΣZ1 ,

ΣZ3 = CζBβU C 2

ξ BZBx

αD − 1
α − 1

,

Σβ = CζBxαD + CζU C 2

ξ BZBx

αD − 1
α − 1

,

Note that our GNN generalization error bound is rather
different from some existing results, e.g., [48], as edge features
(i.e., eu,v) were not considered in their work. Lemma 4
can be used to understand the GNN’s performance with a
single batch. To characterize the node classiﬁcation accuracy
of the GNN learned through the described imitation learning
algorithm, we need the following assumptions:

Assumption 2. Let supθ1,θ2∈Θ (cid:107)θ1 − θ2(cid:107)∞ ≤ H, for some
H < ∞. Let all the loss functions gi(·) [cf. Eq. (27)] for
i = 1, . . . , I are G-Lipschitz continuous with respect to the
(cid:96)1-norm, i.e.

|gi(θ1) − gi(θ2)| ≤ G(cid:107)θ1 − θ2(cid:107)1, ∀i.

Assumption 3. The minimal empirical loss over the aggre-
gated dataset is bounded by ν.

min
θ∈Θ

1
IJ

I
(cid:88)

(cid:88)

i=1

(φs,ys)∈Di

Eψ[L(πθ(φs), ys)] ≤ ν.

Assumption 2 is not hard to meet if the data features and the
network parameters are bounded. Assumption 3 characterizes
the expressiveness of the GNN.

To present our main theory, we compute the expected
number of nodes that will be visited (with the associated
SOCPs/SDRs solved) by Algorithm 3 when run with π
(cid:98)θ in the
testing stage. Let us denote ρ
(cid:98)θ as the probability with which
the classiﬁer accurately classiﬁes a node. Also denote S as the
set of all possible B&B trees that can be realized by Algorithm
3 under a given instance. Let Pr(s; (cid:98)θ), s ∈ S be the probability
with which a particular tree s is realized. Let Qs
denote the
(cid:98)θ
(cid:98)θ = E[Qs
] where
number of visited nodes in tree s. Let Q
(cid:98)θ
the expectation is taken over the probability mass function
Pr(s; (cid:98)θ), s ∈ S. In the following theorem, we characterize the
classiﬁcation accuracy, ρ

(cid:98)θ, and present a bound on Q

(cid:98)θ.

Lemma 4 (Generalization Error of GNN). Consider a GNN
πθ in Sec. III-B and G = {φk, yk}K
k=1 of i.i.d. samples. Then,

Theorem 2. Suppose that Assumptions 2-3 hold, and that the
GNN in MLBB-JOBS is prameterized by (cid:98)θ in (25). In addition,

assume that every single batch Di consists of i.i.d. samples,
and that Algorithm 1 is used for GNN learning. Then, we have

10

(cid:16)

2N

2ρ

(cid:98)θ − ρN
(cid:98)θ
(cid:98)θ − 1

2ρ

(cid:17)

+ 1.

Q

(cid:98)θ ≤

Further, when (cid:98)θ is selected using (25), with a probability at
least 1 − δ,

Ep

(cid:98)θ ,ψ

(cid:2)L (cid:0)π

(cid:16)

≤ ν + O

(cid:98)θ(φs), ys
1/I 1/3(cid:17)

(cid:1)(cid:3)

(30)

+ Gap

(cid:19) (cid:114)

(cid:18) δ
2

, J

2 log(2/δ)
I

.

Assume the logistic loss function L is employed. Then, the
node classiﬁcation accuracy
(cid:98)θ ≥ exp (cid:0)−Ep

(cid:98)θ(φs), ys

(cid:2)L (cid:0)π

(cid:1)(cid:3)(cid:1) .

(cid:98)θ ,ψ

ρ

In addition, MLBB-JOBS returns an optimal solution with
probability at least ρN
(cid:98)θ

.

The proof of Theorem 2 is relegated to Appendix E. This
result bounds the number of nodes visited by the proposed
algorithm under a given classiﬁcation accuracy. It also char-
acterizes the classiﬁcation accuracy that can be achieved by the
proposed training procedure. One can see that when the batch
size is large enough, Gap is close to zero. Additionally, when
the GNN is expressive (and thus ν is small) and the algorithm
is run for large enough iterations I, the accuracy of the clas-
siﬁer, i.e., ρ
(cid:98)θ, approaches 1 [cf. Eq. (30)]. Consequently, the
total number of nodes visited will be close to 2N + 1 at most.
This shows linear dependence of the computational complexity
of the proposed method on N , which is a signiﬁcant saving
(cid:1) for the exhaustive search.
compared to (cid:0)N

L

Remark 1. We should remark that the results in Theorem 2
has a couple of caveats. First, we assumed that the samples in
each Di are i.i.d. If every node created by πθ(i) in Algorithm 2
is used, then the samples in Di are likely not i.i.d., as the nodes
in the same B&B tree are generated in a sequential manner.
Nonetheless, simple remedies can assist creating an i.i.d. batch
Di—e.g., by taking only one random node from a B&B tree.
This is inevitably more costly, and seems not to be necessary
in practice—as using nodes from Algorithm 2 for training
works fairly well in our simulations. Second, the expectation
based criterion (25) is only approximated in practice, e.g., via
using empirical averaging. Characterizing the the empirical
version of (25) can be done via concentration theorems in
a straightforward manner. However, this would substantially
complicate the expressions yet reveals little to no additional
insight. Hence, we leave it out of this work.

IV. NUMERICAL RESULTS

In this section, we showcase the effectiveness of the pro-
posed B&B algorithm and its machine learning based accel-
eration using numerical simulations. We use CVXPY [49]
to solve the SOCPs/SDRs in (15) and (17). The elements
of Rayleigh fading channel vectors {hm}M
m=1 are sampled
independently from circularly symmetric zero mean Gaussian
distribution with unit variance. Throughout the experiments,

Fig. 3. Convergence of the global upper and lower bounds, computed by the
proposed B&B algorithm, to the optimal solution. Problem instance of size
(N, M, L) = (8, 4, 4).

we set the noise variance for all users to σ2
m = 1, ∀m ∈ [M ].
Similarly, we set εm = 0.1, ∀m ∈ [M ] unless otherwise
speciﬁed. Implementation of the proposed methods can be
found on the authors’ website1.

A. Evaluation of B&B for Joint (R)BF&AS

In Fig. 3, we verify the convergence of the proposed B&B
algorithm under both the perfect and the approximate CSI
cases. The ﬁgure shows the convergence of the global upper
and lower bounds (i.e., u(t)
G and l(t)
G ) computed by the proposed
B&B procedure for (N, M, L) = (8, 4, 4). One can see that
the global bounds converge to the optimal objective value in
both the perfect and approximate CSI case. This veriﬁes our
optimality claim in Theorem 1. Note that the B&B algorithm
for both cases converges in less than 24 iterations (i.e., visiting
≤ 48 nodes). This is much less than the worst-case complexity
of B&B, i.e., visiting 139 nodes. The empirical complexity
is also better than the worst-case complexity of exhaustive
search, which is 70 node visits in this case.

Table III gives a closer look at the effectiveness of the
proposed B&B framework. Speciﬁcally, Table III shows the
performance of the proposed B&B procedure for various
problem sizes, compared to the exhaustive search strategy
is averaged over 30
for the perfect CSI case. The result
the B&B algorithm
Monte Carlo trials. One can see that
can constantly attain reduced complexity,
in terms of the
number of nodes visited (i.e., the number of SOCPs solved).
In particular, when the number of users is relatively small,
the B&B can attain an around 8-fold acceleration (cf. the case
where (N, M, L) = (12, 2, 8)). Similar results can be seen in
Table IV, where the imperfect CSI case is considered.

Table V compares our B&B and the alternative B&B using
the formulation (21) in the perfect CSI case. One can see that
the proposed procedure consistently solves fewer SOCPs. This
supports Theorem 1 (c).

1https://github.com/XiaoFuLab/Antenna-Selection-and-Beamforming-with-

BandB-and-ML.git

0510152025iteration1.001.251.501.752.002.252.502.753.00objectivePerfect CSI Upper BoundPerfect CSI Lower BoundApproximate CSI Upper BoundApproximate CSI Lower BoundTABLE III
PERFORMANCE OF THE PROPOSED B&B ALGORITHM FOR VARIOUS
PROBLEM SIZES IN THE PERFECT CSI CASE COMPARED TO THE
EXHAUSTIVE SEARCH.

Problem size
(N, M, L)
(8, 2, 4)
(8, 3, 4)
(8, 4, 4)
(8, 5, 4)
(8, 6, 4)
(10, 2, 6)
(10, 4, 6)
(10, 6, 6)
(10, 8, 6)
(12, 2, 8)
(12, 4, 8)
(12, 6, 8)
(12, 8, 8)
(12, 10, 8)

Proposed B&B
SOCPs
Time
34.07
1.58
40.67
2.29
47.30
3.30
63.27
5.31
82.93
8.24
50.20
2.28
88.37
6.47
141.80
14.55
186.90
24.56
65.53
2.95
137.80
10.57
211.87
21.89
279.67
37.69
398.40
69.48

Exhaustive Search
SOCPs
Time
70
2.95
70
2.58
70
4.53
70
5.46
70
6.10
210
9.11
210
14.75
210
20.00
210
25.59
495
21.39
495
33.45
495
46.53
495
62.46
495
80.94

TABLE IV
PERFORMANCE OF THE PROPOSED B&B ALGORITHM FOR VARIOUS
PROBLEM SIZES IN THE APPROXIMATE CSI CASE COMPARED TO THE
EXHAUSTIVE SEARCH.

Problem size
(N, M, L)
(8, 2, 4)
(8, 3, 4)
(8, 4, 4)
(10, 2, 6)
(10, 4, 6)
(10, 6, 6)
(10, 8, 6)
(12, 2, 8)
(12, 4, 8)

Proposed B&B
SDPs
Time
31.60
7.09
39.37
15.09
49.00
28.39
65.27
19.49
85.73
80.47
137.37
236.26
180.13
520.81
62.80
26.83
122.13
175.45

Exhaustive Search
Time
12.71
21.25
32.58
51.38
133.38
262.10
452.76
157.62
471.54

SDPs
70
70
70
210
210
210
210
495
495

TABLE V
NUMBER OF SOCPS SOLVED BY TWO B&B STRATEGIES

Problem size)
(N, M, L)
Proposed B&B
Alternative Using (21)

(4,2,2)

(8,4,6)

(8,6,6)

(10,5,6)

6.86
8.06

16.73
24.66

22.63
33.8

117.67
159.6

B. Evaluation of ML-accelerated B&B for Joint (R)BF&AS

In this section, we demonstrate the efﬁcacy of MLBB-JOBS.
As a baseline, we use the continuous optimization-based idea
in [5] and modify it to solve the unitcast cases as in this work.
Although [5] did not explore their method for the approximate
CSI case, we note that the same idea can be used after proper
modiﬁcations to the subproblems (i.e., using the S-lemma
to come up with an SDR formulation of the subproblem).
We term this method iteratively reweighted convex relaxation-
based optimization (IrCvxOpt).

1) Baseline Setting: Following the implementation instruc-
tion of [5], we run IrCvxOpt for at most 30 iterations with its
bisection-based λ-tuning method for 30 iterations as well. The
algorithm is stopped if the relative change of the reweighting
matrix is smaller than 10−4 or a solution comprising of ≤ L
antennas is found. If the algorithm returns > L antennas, we
conclude that IrCvxOpt could not ﬁnd a feasible solution.
2) Training Details: We use a GNN tailored for our
beamforming setting (see details in Appendix F). We set

11

(R, I) = (30, 20) in Algorithms 1-2. The loss function L is
selected to be the binary cross-entropy loss, i.e., L(x, y) =
−y log(x) − (1 − y) log(1 − x). In batch i, the parameters
of the classiﬁer is initialized with θ(i), and updated using the
Adam algorithm [50] for 10 epochs, where the sample size of
Adam is set to be 128. The initial step size of Adam is set
to 0.001. As described in Section III-A2, we select (cid:98)θ from
θ(1), . . . , θ(I) using 30 validation problem instances using a
sample average version on (25).

In order to account for the class imbalance (number of
relevant nodes usually much smaller than number of irrelevant
nodes in the training set), we apply a larger positive weight on
the “positive” training pairs. Further, premature/early pruning
of the B&B tree (i.e., when (cid:96) is small) should be dis-
couraged as it is more risky. Hence, we weight each term
L(πθ(i) (φ((cid:96))
(cid:96) , where q ∈ R
offsets the imbalance ratio, and 1[·] denotes the indicator
function. We select q = 11 via trial and error, and use the
same q in all experiments.

s ) using (q1[y((cid:96))

s = 1] + 1) 1

s ), y((cid:96))

3) Evaluation Metrics: We deﬁne the optimality gap

(Ogap) as follows:

(cid:107) (cid:99)W (cid:107)2

Ogap :=

F − (cid:107)W (cid:63)(cid:107)2
F
(cid:107)W (cid:63)(cid:107)2
F
where W (cid:63) is the optimal solution provided by the B&B
algorithm and (cid:99)W is the solution provided by an algorithm
under test. We also deﬁne the runtime speedup as follows:

× 100%,

speedup :=

Run-time of B&B (seconds)
Run-time of method under test (seconds)

.

In addition, let µfeasible and µtotal denote the number of test
instances in which feasible solutions are obtained and the
total number of test instances, respectively. Then, we use the
following deﬁnition:

feasibility rate :=

µfeasible
µtotal

× 100%

as a measure of feasibility attaining.

4) Results: Table VI shows the performance of the al-
gorithms under γm = 1, σ2
m = 1, ∀m ∈ [M ]. Results are
averaged over 30 different random test instances. Note that
the Ogap is computed only on the set of problem instances
where a feasible solution is returned by the algorithm under
test. Several observations are made. First, MLBB-JOBS consis-
tently attains very small Ogap (< 2% for all cases and < 1%
in most cases), but IrCvxOpt often has a > 10% Ogap.
the speedup of MLBB-JOBS is comparable with
Second,
that of IrCvxOpt. MLBB-JOBS has an enhanced speedup
performance when the problem size increases—it achieves
more than 10× speedup for N ≥ 12 with virtually no loss
of optimality. Third, the proposed method consistently returns
feasible solutions, yet the feasibility rate of IrCvxOpt could
sometimes fall to a fairly low level (e.g., when (M, N, L) =
(8, 6, 4), IrCvxOpt’s feasibility rate is 43.33%).

Table VII shows the performance of the algorithms under
imperfect CSI using the RBF constraints. Similar to the perfect
CSI case, the Ogap attained by MLBB-JOBS is consistently
much smaller than that of IrCvxOpt—larger than an or-
der of magnitude improvement in most of the cases. The

12

TABLE VI
PERFORMANCE OF THE PROPOSED ACCELERATED B&B ALGORITHM FOR
VARIOUS PROBLEM SIZES WITH PERFECT CSI.

TABLE VII
PERFORMANCE OF THE PROPOSED ACCELERATED B&B ALGORITHM FOR
VARIOUS PROBLEM SIZES WITH APPROXIMATE CSI. ε = 0.1.

Problem Size
(N, M, L)

Metric

MLBB-JOBS

IrCvxOpt

Problem Size
(N, M, L)

Metric

MLBB-JOBS

IrCvxOpt

(4, 3, 2)

(8, 5, 4)

(8, 6, 4)

(10, 4, 6)

(10, 8, 6)

(12, 10, 8)

(16, 8, 10)

(16, 10, 8)

Ogap
speedup
feasibility rate
SOCPs
Ogap
speedup
feasibility rate
SOCPs
Ogap
speedup
feasibility rate
SOCPs
Ogap
speedup
feasibility rate
SOCPs
Ogap
speedup
feasibility rate
SOCPs
Ogap
speedup
feasibility rate
SOCPs
Ogap
speedup
feasibility rate
SOCPs
Ogap
speedup
feasibility rate
SOCPs

0.18
1.58
100
4.34
0.80
3.89
100
16.28
1.41
3.89
100
21.31
0.02
5.85
100
15.73
0.93
6.21
100
30.09
0.16
11.68
100
34.10
0.34
74.85
100
33.73
1.12
192.03
100
54.0

13.12
0.74
73.33
11.23
17.50
9.63
100
5.3
16.65
3.83
43.33
18.03
2.19
4.57
100
14.4
10.11
14.49
90
13.5
8.81
34.77
93.33
8.93
2.88
239.52
100
10.35
9.68
966.67
96.67
10.16

(4, 2, 2)

(4, 3, 2)

(8, 3, 4)

(8, 5, 4)

(10, 8, 6)

Ogap
speedup
feasibility rate
SDRs
Ogap
speedup
feasibility rate
SDRs
Ogap
speedup
feasibility rate
SDRs
Ogap
speedup
feasibility rate
SDRs
Ogap
speedup
feasibility rate
SDRs

0.0
1.54
100
6.06
2.27
1.69
100
6.8
0.04
3.57
100
12.13
0.81
4.26
100
15.66
0.19
5.92
100
32.8

4.33
1.04
96
8.86
10.26
0.52
43
14.06
2.01
1.58
100
27.3
4.85
1.70
70
30.56
4.80
4.72
80
41.06

TABLE VIII
GENERALIZATION ACROSS VARIOUS NUMBER OF USERS. MODEL
TRAINED ON (8, 4, 4).

Problem Size
(N, M, L)
(8,2,4)
(8,3,4)
(8,4,4)
(8,5,4)
(8,6,4)

Ogap (%)

Speedup

Feasibility Rate (%)

0.0
0.06
0.21
0.07
0.01

2.69
3.68
3.44
2.69
1.91

100
100
100
100
100

speedup compared to the B&B algorithm increases along
with the growth of N . In terms of speedup, one can see
that MLBB-JOBS even achieves better speedup relative to
IrCvxOpt, compared to the perfect CSI cases. The proposed
method also always ﬁnds a feasible solution with exact L
active antennas, yet IrCvxOpt fails to do so.

C. Performance under Training-Test Mismatch

In a wireless communication environment, the number of
users being served by a BS varies frequently. Hence, it is
highly likely that the node classiﬁer is trained using M users
but M (cid:48) users (where M (cid:48)
(cid:54)= M ) appear in the test stage.
Therefore, we evaluate the performance of MLBB-JOBS in
cases where there are such mismatches between in training
and test.

Table VIII shows the performance of the model trained
on problem instances of size (N, M, L) = (8, 4, 4). The test
stage uses various M ’s. One can see that the optimality gap
attained by MLBB-JOBS is consistently below 1% in all cases.
Similarly, there is no signiﬁcant degradation in the speedup.
Finally, the feasiblity rate is consistently 100% in all cases.
This shows that the proposed GNN based classiﬁer generalizes
well across unseen problem sizes, which is an important
consideration in any wireless communication systems.

V. CONCLUSION
In this work, we revisited the joint beamforming and
antenna selection problem under perfect and imperfect CSI
and proposed a machine learning-assisted B&B algorithm to
attain its optimal solution. Unlike the vast majority of existing
algorithms that rely on continuous optimization to approximate
the hard mixed integer and nonconvex optimization problem
without optimality guarantees, our B&B algorithm leverages
the special properties of joint (R)BF&AS to come up with
optimal solutions. More importantly, we proposed a GNN-
based machine learning method to help accelerate the B&B al-
gorithm. Our analysis showed that the design ensures provable
acceleration and retains optimality with high probability, under
proper GNN design and given a sufﬁciently enough sample
size. To our best knowledge, this is the ﬁrst comprehensive
characterization for ML-based B&B. Our GNN design also
easily handles a commonly seen challenge in communications,
namely, the problem size change across training and test sets,
without visible performance losses. Simulations corroborated
our design goals and theoretical analyses.

REFERENCES

[1] M.-H. Golbon-Haghighi, “Beamforming in wireless networks,” InTech

Open, pp. 163–192, 2016.

[2] N. D. Sidiropoulos, T. N. Davidson, and Z.-Q. Luo, “Transmit beam-
forming for physical-layer multicasting,” IEEE Trans. Signal Process.,
vol. 54, no. 6, pp. 2239–2251, 2006.

[3] A. B. Gershman, N. D. Sidiropoulos, S. Shahbazpanahi, M. Bengtsson,
and B. Ottersten, “Convex optimization-based beamforming,” IEEE
Signal Process. Mag., vol. 27, no. 3, pp. 62–75, 2010.

[4] K.-Y. Wang, A. M.-C. So, T.-H. Chang, W.-K. Ma, and C.-Y. Chi,
“Outage constrained robust transmit optimization for multiuser MISO
downlinks: Tractable approximations by conic optimization,” IEEE
Trans. Signal Process., vol. 62, no. 21, pp. 5690–5705, 2014.

[5] O. Mehanna, N. D. Sidiropoulos, and G. B. Giannakis, “Joint multicast
beamforming and antenna selection,” IEEE Trans. Signal Process.,
vol. 61, no. 10, pp. 2660–2674, 2013.

[6] Y. Shi, J. Zhang, and K. B. Letaief, “Group sparse beamforming for
green cloud-RAN,” IEEE Trans. Wireless Commun., vol. 13, no. 5, pp.
2809–2823, 2014.

[7] M. S. Ibrahim, A. Konar, and N. D. Sidiropoulos, “Fast algorithms for
joint multicast beamforming and antenna selection in massive MIMO,”
IEEE Trans. Signal Process., vol. 68, pp. 1897–1909, 2020.

[8] S. Sanayei and A. Nosratinia, “Antenna selection in MIMO systems,”

IEEE Commun. Mag., vol. 42, no. 10, pp. 68–73, 2004.

[9] A. Konar and N. D. Sidiropoulos, “A simple and effective approach
for transmit antenna selection in multiuser massive MIMO leveraging
submodularity,” IEEE Trans. Signal Process., vol. 66, no. 18, pp. 4869–
4883, 2018.

[10] A. Ahmed, S. Zhang, and Y. D. Zhang, “Antenna selection strategy for
transmit beamforming-based joint radar-communication system,” Digital
Signal Process., vol. 105, p. 102768, 2020.

[11] M. O. Mendonca, P. S. Diniz, T. N. Ferreira, and L. Lovisolo, “Antenna
selection in massive MIMO based on greedy algorithms,” IEEE Trans.
Wireless Commun., vol. 19, no. 3, pp. 1868–1881, 2019.

[12] M. Ding, S. Liu, H. Luo, and W. Chen, “MMSE based greedy antenna
selection scheme for AF MIMO relay systems,” IEEE Signal Process.
Lett., vol. 17, no. 5, pp. 433–436, 2010.

[13] H. F. Mahdi, A. T. Alheety, N. A. Hamid, and S. Kurnaz, “Quantization-
aware greedy antenna selection for multi-user massive MIMO systems,”
Progress in Electromagnetics Research C, pp. 15–24, 2021.

[14] M. S. Ibrahim, A. S. Zamzam, X. Fu, and N. D. Sidiropoulos, “Learning-
based antenna selection for multicasting,” in Proc. IEEE SPAWC, 2018,
pp. 1–5.

[15] T. X. Vu, S. Chatzinotas, V.-D. Nguyen, D. T. Hoang, D. N. Nguyen,
M. Di Renzo, and B. Ottersten, “Machine learning-enabled joint antenna
selection and precoding design: From ofﬂine complexity to online
performance,” IEEE Trans. Wireless Commun., vol. 20, no. 6, pp. 3710–
3722, 2021.

[16] A. M. Elbir and K. V. Mishra, “Joint antenna selection and hybrid
beamformer design using unquantized and quantized deep learning
networks,” IEEE Trans. Wireless Commun., vol. 19, no. 3, pp. 1677–
1688, 2019.

[17] W.-K. Ma, J. Pan, A. M.-C. So, and T.-H. Chang, “Unraveling the rank-
one solution mystery of robust MISO downlink transmit optimization:
A veriﬁable sufﬁcient condition via a new duality result,” IEEE Trans.
Signal Process., vol. 65, no. 7, pp. 1909–1924, 2017.

[18] J. Clausen, “Branch and bound algorithms-principles and examples,”
Depart. Comput. Sci., University of Copenhagen, pp. 1–30, 1999.
[Online]. Available: http://www2.imm.dtu.dk/courses/04232/TSPtext.pdf
[19] A. H. Land and A. G. Doig, “An automatic method of solving discrete
programming problems,” Econometrica, vol. 28, no. 3, pp. 497–520,
1960.

[20] H. He, H. Daume III, and J. M. Eisner, “Learning to search in branch
and bound algorithms,” in Proc. NeurIPS, vol. 27, 2014, pp. 3293–3301.
[21] V. Nair, S. Bartunov, F. Gimeno, I. von Glehn, P. Lichocki, I. Lobov,
B. O’Donoghue, N. Sonnerat, C. Tjandraatmadja, P. Wang et al.,
“Solving mixed integer programs using neural networks,” arXiv preprint
arXiv:2012.13349, 2020.

[22] M. Lee, G. Yu, and G. Y. Li, “Learning to branch: Accelerating resource
allocation in wireless networks,” IEEE Trans. Veh. Technol., vol. 69,
no. 1, pp. 958–970, 2019.

[23] F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, and G. Monfardini,
“The graph neural network model,” IEEE Trans. Neural Netw., vol. 20,
no. 1, pp. 61–80, 2008.

[24] S. Ross, G. Gordon, and D. Bagnell, “A reduction of imitation learning
and structured prediction to no-regret online learning,” in Proc. AISTATS,
2011, pp. 627–635.

[25] C. Lu and Y.-F. Liu, “An efﬁcient global algorithm for single-group
multicast beamforming,” IEEE Trans. Signal Process., vol. 65, no. 14,
pp. 3761–3774, 2017.

13

[26] C. Lu, Y.-F. Liu, and J. Zhou, “An enhanced SDR based global algorithm
for nonconvex complex quadratic programs with signal processing
applications,” IEEE Open J. Signal Process., vol. 1, pp. 120–134, 2020.
[27] C. Ouyang, Z. Ou, L. Zhang, and H. Yang, “Optimal transmit antenna
selection algorithm in massive MIMOME channels,” in Proc. IEEE
WCNC, 2019, pp. 1–6.

[28] Y. Li, M. Sheng, X. Wang, Y. Shi, and Y. Zhang, “Globally optimal an-
tenna selection and power allocation for energy efﬁciency maximization
in downlink distributed antenna systems,” in Proc. IEEE GLOBCOM,
2014, pp. 3856–3861.

[29] Y. Gao, W. Jiang, and T. Kaiser, “Bidirectional branch and bound based
antenna selection in massive MIMO systems,” in Proc. IEEE PIMRC,
2015, pp. 563–568.

[30] M. Gasse, D. Ch´etelat, N. Ferroni, L. Charlin, and A. Lodi, “Exact
combinatorial optimization with graph convolutional neural networks,”
in Proc. NeurIPS, vol. 32, 2019.

[31] Y. Shen, Y. Shi, J. Zhang, and K. B. Letaief, “LORM: Learning
to optimize for resource management in wireless networks with few
training samples,” IEEE Trans. Wireless Commun., vol. 19, no. 1, pp.
665–679, 2019.

[32] F. Rashid-Farrokhi, K. R. Liu, and L. Tassiulas, “Transmit beamforming
and power control for cellular wireless systems,” IEEE J. Sel. Areas
Commun., vol. 16, no. 8, pp. 1437–1450, 1998.

[33] E. Visotsky and U. Madhow, “Optimum beamforming using transmit
antenna arrays,” in Proc. IEEE VTC, vol. 1, 1999, pp. 851–856.
[34] E. Karipidis, N. D. Sidiropoulos, and Z.-Q. Luo, “Quality of service and
max-min fair transmit beamforming to multiple co-channel multicast
groups,” IEEE Trans. Signal Process., vol. 56, no. 3, pp. 1268–1279,
2008.

[35] E. Bj¨ornson, M. Bengtsson, and B. Ottersten, “Optimal multiuser trans-
mit beamforming: A difﬁcult problem with a simple solution structure
[lecture notes],” IEEE Signal Proc. Mag., vol. 31, no. 4, pp. 142–148,
2014.

[36] Z.-Q. Luo, W.-K. Ma, A. M.-C. So, Y. Ye, and S. Zhang, “Semideﬁnite
relaxation of quadratic optimization problems,” IEEE Signal Proc. Mag.,
vol. 27, no. 3, pp. 20–34, 2010.

[37] A. Civril and M. Magdon-Ismail, “On selecting a maximum volume sub-
matrix of a matrix and related problems,” Theoretical Computer Science,
vol. 410, no. 47-49, pp. 4801–4811, 2009.

[38] E. J. Candes, M. B. Wakin, and S. P. Boyd, “Enhancing sparsity by
reweighted (cid:96) 1 minimization,” J. Four. Analy. Appl., vol. 14, no. 5, pp.
877–905, 2008.

[39] J. Joung, “Machine learning-based antenna selection in wireless com-
munications,” IEEE Commun. Lett., vol. 20, no. 11, pp. 2241–2244,
2016.

[40] J. Chen, S. Chen, Y. Qi, and S. Fu, “Intelligent massive MIMO antenna
selection using monte carlo tree search,” IEEE Trans. Signal Process.,
vol. 67, no. 20, pp. 5380–5390, 2019.

[41] W. Lee, M. Kim, and D.-H. Cho, “Deep power control: Transmit power
control scheme based on convolutional neural network,” IEEE Commun.
Lett., vol. 22, no. 6, pp. 1276–1279, 2018.

[42] H. Sun, X. Chen, Q. Shi, M. Hong, X. Fu, and N. D. Sidiropoulos,
“Learning to optimize: Training deep neural networks for interference
management,” IEEE Trans. Signal Process., vol. 66, no. 20, pp. 5438–
5453, 2018.

[43] B. Lin, F. Gao, S. Zhang, T. Zhou, and A. Alkhateeb, “Deep learning-
based antenna selection and CSI extrapolation in massive MIMO sys-
tems,” IEEE Trans. Wireless Commun., vol. 20, no. 11, pp. 7669–7681,
2021.

[44] S. Boyd and J. Mattingley, “Branch and bound methods,” Notes for

EE364b, Stanford University, pp. 2006–07, 2007.

[45] D. Bertsimas, A. King, and R. Mazumder, “Best subset selection via a
modern optimization lens,” The Annals of Statistics, vol. 44, no. 2, pp.
813–852, 2016.

[46] J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, and G. E. Dahl,
“Neural message passing for quantum chemistry,” in Proc. ICML, 2017,
pp. 1263–1272.

[47] N. Agarwal, A. Gonen, and E. Hazan, “Learning in non-convex games
with an optimization oracle,” in Proc. COLT, 2019, pp. 18–29.
[48] V. Garg, S. Jegelka, and T. Jaakkola, “Generalization and representa-
tional limits of graph neural networks,” in Proc. ICML, 2020, pp. 3419–
3430.

[49] S. Diamond and S. Boyd, “CVXPY: A Python-embedded modeling
language for convex optimization,” JMLR, vol. 17, no. 83, pp. 1–5,
2016.

[50] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”

in Proc. ICLR, 2015.

[51] M. Mohri, A. Rostamizadeh, and A. Talwalkar, Foundations of machine

learning. MIT press, 2018.

[52] P. L. Bartlett, D. J. Foster, and M. J. Telgarsky, “Spectrally-normalized
margin bounds for neural networks,” in Proc. NeurIPS, vol. 30, 2017.
[53] M. Chen, X. Li, and T. Zhao, “On generalization bounds of a family of

recurrent neural networks,” in Proc. AISTATS, 2019.

[54] D. Pollard, “Empirical processes: Theory and applications,” NSF-CBMS

Reg. Conf. Ser. Prob. Stat., vol. 2, pp. i–86, 1990.

[55] M. Nassar, “Hierarchical bipartite graph convolution networks,” arXiv

preprint arXiv:1812.03813, 2018.

14

APPENDIX A
PROPOSED B&B PROCEDURE

The proposed B&B procedure is essentially Algorithm 3
without any pruning of the nodes based on node classiﬁer.
The B&B procedure is outlined in Algortihm 4

Algorithm 4: BB
1 Input: Problem instance (hm, σm, γm, εm), ∀m, trained

pruning policy πθ, relative error (cid:15);
// Add the root node first
1 ← {};

1 ← {}, B(0)

;

1

2 A(0)
3 Select node using (18) for N (0)
4 Wincumbent ← solution to (17);
G ← (cid:107)W (0)
5 l(t)
1 (cid:107)2
6 F (0) ← {(0, 1)};
7 t ← 0;
8 while |F (t)| > 0 and
9

F , u(0)

G −l(t)

G

G ← (cid:107)Wincumbent(cid:107)2
F ;

;

s(cid:63)

(cid:12)
(cid:12)
(cid:12)/l(t)

G > (cid:15) do

(cid:12)
(cid:12)u(t)
(cid:12)
Select a non-leaf node ((cid:96)(cid:63), s(cid:63)) using (18)
Remove the selected node F (t) ← F (t)\N ((cid:96)(cid:63))
Select variable n(cid:63) using (19);
Generate child nodes N ((cid:96)(cid:63)+1)
s(cid:63)
1
(13) and append to F (t);
(cid:16)
k ← arg mini∈{1,2} Φub
N ((cid:96)(cid:63)+1)
≤ u(t)
s(cid:63)
k
(cid:16)
N ((cid:96)(cid:63)+1)
u(t+1)
G ← Φub
s(cid:63)
k
Wincumbent ← solution to (17) for N ((cid:96)(cid:63)+1)

N ((cid:96)(cid:63)+1)
s(cid:63)
i
G then
(cid:17)
;

and N ((cid:96)(cid:63)+1)
s(cid:63)
2

if Φub

(cid:16)

(cid:17)

(cid:17)

;

s(cid:63)
k

;

using

end
l(t+1)
G ← min((cid:96),s)∈F (t)Φlb
F (t+1) ←
(cid:110)

(s(cid:48), (cid:96)(cid:48)) ∈ F (t) | Φlb

(cid:16)

N ((cid:96)(cid:48))
s(cid:48)

(cid:17)

≤ u(t+1)
G

(cid:111)

;

10

11

12

13

14

15

16

17

18

19

t ← t + 1;

20
21 end
22 Return Wincumbent;

APPENDIX B
POOF OF LEMMA 3

s

(a) The BF setting implies that C(wm, hm, εm, σm) is from
(2b). Then, the equivalence of (2b) and (3) implies that (15)
for any node N ((cid:96))
can be optimally solved using SOCP. Hence
Lemma 3(a) holds due to Lemma 1.

(b) Note that (15) with B((cid:96))
is equivalent to (4) with anten-
s
nas restricted to the set [N ]\B((cid:96))
s . Hence, when the condition
in (16) is satisﬁed for H([N ]\B((cid:96))
s , :), then (15) with B((cid:96))
can
s
be optimally solved using SDR due to Lemma 2. Further, the
B&B procedure ensures that |B((cid:96))
s | ≤ N − L, ∀(s, (cid:96)). Hence,
the set {H(S, :)|S ∈ [N ], |S| ≥ L} includes all possible
instances of (15) encountered during the B&B procedure.
Therefore, Lemma 3(b) holds.

(c) Note that | (cid:101)B((cid:96))

s | = N −L. Hence, the solution of Problem
(17) satisﬁes the constraint (7c). Further, due to Lemma 3 (a)
and (b), Problem (17) can be optimally solved using SOCP

15

and SDR for the BF and RBF cases, respectively. Hence,
Φub(N ((cid:96))
) is a valid upper bound on the optimal objective
value of (7).

s

APPENDIX C
PROOF OF THEOREM 1

A. Proof of (a) and (b)

Note that if the SOCP and SDR return optimal solutions
to every leaf node of the B&B tree under the BF and RBF
then the B&B procedure is ensured
settings, respectively,
to ﬁnd the optimal solutions of the the joint BF/RBF&AS
problems. The reason is that the B&B tree has a ﬁnite number
of leaves. Hence, there exists a leaf that must return the global
optimal solution, since the leaves represent
the situations
where exactly L antennas are activated.

For the BF setting with perfect CSI, the subproblem at a

leaf node ((cid:96), s) can be expressed as

minimize
W

(cid:107)W (cid:107)2
F

subject to

(cid:80)

|wH
(cid:96)(cid:54)=m |wH
W (n, :) = 0,

mhm|2
(cid:96) hm|2 + σ2
m
∀n ∈ B((cid:96))
s ,

≥ γm,

(31)

∀m ∈ [M ]

where |B((cid:96))
s | = N − L. Since the constraint (cid:107)W (cid:107)row−0 ≤ L
is automatically satisﬁed, it is omitted. Problem (31) can be
further rewritten as

minimize
W ((cid:96))
s

(cid:107)W ((cid:96))

s (cid:107)2
F

(32)

|wH
(cid:96)(cid:54)=m |wH

(cid:80)

≥ γm,

mhm|2
(cid:96) hm|2 + σ2
m
s , :), and we let wm = W ((cid:96))

s

∀m ∈ [M ]

s = W ([N ]\B((cid:96))

where W ((cid:96))
(:, m)
by slightly abusing the notation. Since Problem (32) can be
recast as a convex problem as detailed in (3), the solution to
the above is indeed optimal.

Similarly, under the RBF setting with imperfect CSI, the

subproblem at a leaf node can be written as

minimize
W

(cid:107)W (cid:107)2
F

subject to min

hm∈Um

(cid:80)

j(cid:54)=m h

h

H
mWmhm
H
mWjhm + σ2
m
∀n ∈ B((cid:96))
s ,

W (n, :) = 0,

(33)

≥ γm,

where |B((cid:96))
as

s | = N − L. Problem (33) can be further rewritten

minimize
W ((cid:96))
s

(cid:107)W ((cid:96))

s (cid:107)2
F

subject to min

hm∈Um

(cid:80)

h

H
mWmhm
H
mWjhm + σ2
m

j(cid:54)=m h

(34)

≥ γm,

s

s (:, m) with H ((cid:96))

where W ((cid:96))
and wm are deﬁned as in (32), and hm =
H ((cid:96))
s = H([N ]\B((cid:96))
s , :) (recall that Um :=
{hm + e|(cid:107)e(cid:107)2 ≤ εm}). Using the condition in Theorem 1 (b),
and invoking Lemma 3, one can see that (34) can be solved
optimally using SDR.

(cid:16)

N ((cid:96))
s

(cid:17)

;

subject to

16

antennas and fewer than or equal to N − L − 1 excluded
antennas. This implies that there can be fewer than or equal
to (L − 1) + (N − L − 1) = N − 2 decided antennas.
Hence, a right child leaf node is created whenever a node has
≤ N − 2 decided antennas, where L − 1 of them are included,
is branched. Therefore, we have the following holds:

Fig. 4.

Illustration of a B&B tree (where no nodes are fathomed).

QRightLeaf =

B. Proof of (c)

=

1) Amount of SOCPs/SDRs Solved by Proposed B&B: In
the given B&B procedure, (15) and (17) are equivalent for any
node and its right child node, i.e.,

i=2

Consequently,

(cid:19)

+

(cid:18)N − 2
L − 1
N −L+1
(cid:88)

(cid:18)N − 3
L − 1
(cid:19)

(cid:18)N − i
L − 1

.

(cid:19)

+ · · · +

(cid:19)

(cid:18)L − 1
L − 1

(cid:16)

Φlb

(cid:16)

Φub

(cid:17)

N ((cid:96))
s
(cid:17)

N ((cid:96))
s

= Φlb

= Φub

(cid:16)

N ((cid:96)+1)
s2

(cid:16)

N ((cid:96)+1)
s2

(cid:17)

(cid:17)

,

.

s = B((cid:96)+1)

The ﬁrst equation is because B((cid:96))
and the second
s2
equation is because (cid:101)B((cid:96))
s , ∀((cid:96), s) in (17) is determined using the
solution to (15). Hence, one can avoid redundant computations
in the nodes by storing and reusing the results of (15) and (17).
Using this observation, in the following, we derive an upper
bound of the number of SOCPs/SDRs that need to be solved
by the proposed B&B procedure.

L

Consider a B&B tree where none of the nodes are fathomed
(see illustration in Fig. 4). Note that there are QLeaf = (cid:0)N
(cid:1)
L
leaf nodes (squares in Fig. 4). Therefore, there are QTotal =
2(cid:0)N
(cid:1) − 1 nodes in total (all circles and squares). Each non-
leaf node (circles) is branched into a right child node and a
(cid:1) − 1 right child
left child node. Hence, there are QRight = (cid:0)N
nodes (shaded solid circles and squares) and QLeft = (cid:0)N
(cid:1) − 1
left child nodes (unshaded solid circles and squares).

L

L

The constraints of the SOCPs/SDRs corresponding to the
leaf nodes can be different from that of its parent even if they
correspond to a right child node, i.e., shaded squares. This
is because of the update step in (20) for the leaf nodes. To
explain, a right child node, N ((cid:96))
, is converted into a leaf node
if L of the decided antennas are included, i.e., |A((cid:96))
s | = L. For
this node,

s

s = [N ]\A((cid:96))
B((cid:96))
s ,
i.e., all remaining undecided antennas are excluded. Since B((cid:96))
s
will be different from that of its parent node, the solutions of
(15) and (17) can be different from that of its parent node.

Therefore, only the non-leaf right child nodes (shaded solid
circles) can reuse previously stored upper bound and lower
bound solutions from their parents. Let QRightLeaf denote the
number of right child leaf nodes (shaded squares). Then, the
total number of nodes whose associated SOCPs/SDRs that
need to be solved in the worst case is as follows:

QCompute = QTotal − QRight + QRightLeaf .

To count QRightLeaf , notice that the right and left child
nodes of a parent node correspond to ‘including’ and ‘exclud-
ing’ an antenna, respectively. A parent node is branched into
a right child leaf node if it contains exactly L − 1 included

QCompute =

(cid:19)

(cid:18)N
L

+

N −L+1
(cid:88)

i=2

(cid:19)

(cid:18)N − i
L − 1

.

Note that QCompute nodes may correspond to 2QCompute
SOCPs/SDRs (cf. (15) and (17) for each node). However, for
the leaf nodes (15) and (17) are identical. Hence there are only
(cid:1) instances of (15). Moreover, there can be at
QCompute − (cid:0)N
most (cid:0)N
(cid:1) correspond to selecting
L out of N antennas. Therefore, there are at most QCompute
SDRs/SOCPs solved by the B&B procedure.

(cid:1) instances of (17), since (cid:0)N

L

L

L

2) The SOCPS/SDRs Needed in B&B for Problem (21):

To complete the proof,
let us examine the number of
SOCPs/SDRs that are needed to exhaust the B&B tree of the
formulation in (21).

A node problem of (21), for the node N ((cid:96))

s

is as follows:

minimize
W ,z

(cid:107)W (cid:107)2
F

(35)

subject to C(wm, hm, εm, σm) ≥ γm,
z ∈ {0, 1}N ,
z(cid:62)1 ≤ L,
z(n) = 0, n ∈ B((cid:96))
s ,
z(n) = 1, n ∈ A((cid:96))
s ,
(cid:107)W (n, :)(cid:107)2 ≤ Cz(n), ∀n ∈ [N ].

and B((cid:96))
s

The lower bound is obtained by solving the convex relaxation
of the above, i.e., z ∈ {0, 1} is relaxed to z ∈ [0, 1]N . One can
see that the lower bounds obtained at the parent node and both
child nodes may be different. It is because (35) depends upon
both A((cid:96))
and each child node will differ from its
s
parent in one of the two sets, i.e, B((cid:96)+1)
(cid:54)=
A((cid:96))
s . The above implies that the number of SOCPs/SDRs with
(cid:1) − 1
B&B using (35) has an upper bound of Q(cid:48)
(specially, with (cid:0)N
(cid:1) − 1 instances
of (15)).

(cid:1) instances of (17) and (cid:0)N

Compute = 2(cid:0)N

and A((cid:96)+1)
s2

(cid:54)= B((cid:96))
s

s1

L

L

L

APPENDIX D
PROOF OF LEMMA 4

We use the empirical Rademacher complexity of the GNN
class to assist ﬁnding the expected risk’s error, which is a

classic way of establishing generalization bounds [51]–[53].
To proceed, let us deﬁne the sets
Xφ := (cid:8)φ = (cid:2)x(cid:62)

(cid:3)
(cid:12)
(cid:12) (cid:107)xu(cid:107)2, (cid:107)eu,v(cid:107)2 ≤ Bx, ∀u, v ∈ [U ](cid:9),

1,1, . . . , e(cid:62)

1, . . . , x(cid:62)

U , e(cid:62)

U,U

XZ := {Z ∈ RE×E|(cid:107)Z(cid:107)2 ≤ BZ}, and
Xβ := {a ∈ RE | (cid:107)a(cid:107)2 ≤ Bβ}.

First, consider the following lemma:

Lemma 5 ( [51, Theorem 3.1]). Let T be a family of functions
mapping from Xφ × {0, 1} to [−b, b]. Assume G consists of K
i.i.d. samples {φk, yk}K
k=1. With probability at least 1−δ over
the samples G, for any τ ∈ T ,

E[τ (φ, y)] −

1
K

(cid:88)

(φk,yk)∈G

τ (φk, yk) ≤ 2 (cid:98)RG(T ) + 3b

(cid:114)

log 2/δ
2K

,

where (cid:98)RG(T ) is the empirical Rademacher complexity [51]
of the set T with respect to the samples G.

Let us deﬁne the set T := {(φ, y) (cid:55)→ L(πθ(φ), y) | θ ∈
Θ}, a class of functions that maps from Xφ × {0, 1} to
[−BL, BL]. Then, applying Lemma 5 to T over the set G
ensures that with probability at least 1 − δ over G, ∀θ ∈ Θ,
1
K

E[L(πθ(φ), y)] −

L(πθ(φi), yi)

(cid:88)

i∈[K]

≤ 2 (cid:98)RG(T ) + 3BL

(cid:114)

log 2/δ
2K

,

(36)

In the following, we derive an upper bound on (cid:98)RG(T ). To
this end, we instead deﬁne a set Π := {φ (cid:55)→ πθ(φ)|θ ∈ Θ},
and derive (cid:98)RG(Π). With this, we can use Talagrand’s Lemma
[51, Lemma 4.2] to obtain (cid:98)RG(T ) as (cid:98)RG(T ) = CL (cid:98)RG(Π).
In order to derive (cid:98)RG(Π), we use Dudley’s entropy integral
[52, Lemma A.5], which provides an upper bound on the em-
pirical Rademacher complexity by using the covering number
of Π. To clarify, a µ-cover of Π is any set C ⊆ Π such that
∀πθ ∈ Π, ∃π

(cid:101)θ ∈ C such that
(cid:12)
(cid:12)πθ(φ) − π

max
φ∈Xφ

(cid:101)θ(φ)(cid:12)

(cid:12) ≤ µ.

Similarly, the covering number of the set Π at scale µ is
denoted by N(Π, µ) and deﬁned as the minimum cardinality
of a µ-cover set of Π. The following lemma summarizes the
Dudley’s entropy integral that uses the covering number of a
set to bound its empirical Rademacher complexity.

Lemma 6 ( [52, Lemma A.5]). Given samples G of size K, the
empirical Rademacher complexity of the set Π with respect to
the samples G is upperbounded as follows:

(cid:98)RG(Π) ≤ inf
a>0

(cid:32)

4a
√
K

+

12
K

√

K

(cid:90)

a

(cid:112)log N(Π, µ)dµ

(cid:33)

. (37)

To proceed with the derivation of log(N(Π, µ)), we ﬁrst
characterize the Lipschitz constants of the GNN with respect to
its parameters. Consider parameters θ and (cid:101)θ, which correspond
to (Z1, Z2, Z3, β) and ( (cid:101)Z1, (cid:101)Z2, (cid:101)Z3, (cid:101)β), respectively. Let q(d)
and (cid:101)q(d)
denote the embeddings learned for the uth vertex at

u

u

17

the end of dth layer of the GNN with parameters θ and (cid:101)θ,
respectively. Then, for any input φ, the absolute difference
between the outputs of the two GNNs can be written as

(cid:101)θ(φ)(cid:12)
(cid:12)
(cid:16)

(cid:12)
(cid:12)πθ(φ) − π

1
U

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
1
U

Cζ
U

=

≤

≤

(cid:88)

u∈[U ]
(cid:88)

Cζ

u∈[U ]
(cid:88)

u∈[U ]

ζ(β(cid:62)q(D)

u ) − ζ( (cid:101)β(cid:62)

(cid:101)q(D)
u )

(cid:17)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)β(cid:62)q(D)
(cid:12)

u − (cid:101)β(cid:62)q(D)

u + (cid:101)β(cid:62)q(D)

u + (cid:101)β(cid:62)

(cid:101)q(D)

u

(38)

(cid:12)
(cid:12)
(cid:12)

(cid:16)(cid:13)
(cid:13)q(D)
(cid:13)

u

(cid:13)
(cid:13)
(cid:13)2

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)β − (cid:101)β
(cid:13)2

+ Bβ

(cid:13)
(cid:13)q(D)
(cid:13)

u − (cid:101)q(D)

u

(cid:17)

.

(cid:13)
(cid:13)
(cid:13)2

First, we can bound (cid:107)q(D)

u (cid:107)2 as follows:

(cid:13)
(cid:13)
(cid:13)2

Z1q(D−1)
u

u

(cid:13)
(cid:13)q(D)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

=

ξ

≤ Cξ(cid:107)Z1(cid:107)2

(cid:88)

+ C 2
ξ

(cid:13)
(cid:13)q(D−1)
(cid:13)
(cid:18)

u

(cid:107)Z2(cid:107)2

(u,v)∈E
(cid:13)
(cid:13)
(cid:13)2
(cid:13)
(cid:13)q(D−1)
(cid:13)

v

(u,v)∈E
(cid:13)
(cid:13)q(D−1)
(cid:13)

u

≤ CξBZ

(cid:13)
(cid:13)
(cid:13)2

(cid:88)

(cid:16)

ξ

+

Z2q(D−1)
v

+ Z3eu,v

(cid:17)



(cid:13)
(cid:13)
(cid:13)
 − ξ(0)
(cid:13)
(cid:13)2

+ (cid:107)Z3(cid:107)2 (cid:107)eu,v(cid:107)2

(cid:19)

(cid:13)
(cid:13)
(cid:13)2

+ C 2

ξ U max

v

(cid:18)

BZ

(cid:13)
(cid:13)q(D−1)
(cid:13)

v

(cid:13)
(cid:13)
(cid:13)2

(cid:19)

+ BZBx

.

Solving the recursion from the ﬁnal inequality, we obtain

(cid:13)
(cid:13)q(D)
(cid:13)

u

(cid:13)
(cid:13)
(cid:13)2

≤ αDBx + U C 2

ξ BZBx

αD − 1
α − 1

,

(39)

where α = ((1 + U Cξ)CξBZ).
(cid:13)
(cid:13)q(D)
(cid:13)

Next, we bound Γ(D)

:=

u

u − (cid:101)q(D)

u

follows:

(cid:13)
(cid:13)
(cid:13)2

from (38) as

Γ(D)
u
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

=

ξ


Z1q(D−1)
u

+

(cid:88)

(cid:16)

ξ

Z2q(D−1)
v

+ Z3eu,v

(cid:17)






 (cid:101)Z1 (cid:101)q(D−1)

u

+

− ξ

(u,v)∈E

(cid:88)

(cid:16)

ξ

(u,v)∈E

(cid:101)Z2 (cid:101)q(D−1)

v

+ (cid:101)Z3eu,v

(cid:17)





(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)2

≤ Cξ

+ U C 2

≤ Cξ

+ U C2

v

u

u

− (cid:101)Z1 (cid:101)q(D−1)

(cid:13)
(cid:13)
(cid:13)2
− (cid:101)Z2 (cid:101)q(D−1)

(cid:13)
(cid:13)Z1q(D−1)
(cid:13)
u
(cid:16)(cid:13)
(cid:13)Z2q(D−1)
(cid:13)
ξ max
v
v
(cid:13)
(cid:13)
(cid:16)(cid:13)
(cid:13)q(D−1)
(cid:13)
(cid:13)
(cid:13)
(cid:13)Z1 − (cid:101)Z1
(cid:13)2
(cid:32)
(cid:13)
(cid:13)
(cid:13)
(cid:13)q(D−1)
(cid:13)
(cid:13)
(cid:13)
(cid:13)Z2 − (cid:101)Z2
(cid:13)2
(cid:33)
.

ξ max
v

(cid:13)
(cid:13)
(cid:13)Z3 − (cid:101)Z3

(cid:13)
(cid:13)
(cid:13)2

v

(cid:13)
(cid:13)
(cid:13)2

+ Bx

+

(cid:13)
(cid:13)
(cid:13)2
+ BZΓ(D−1)
u

(cid:13)
(cid:13)
(cid:13)Z3 − (cid:101)Z3
(cid:17)

(cid:17)

Bx

(cid:13)
(cid:13)
(cid:13)2

(cid:13)
(cid:13)
(cid:13)2

+ BZΓ(D−1)
v

Solving the recursion in the last inequality, and using Γ(0)

u =

To this end, we upper bound the integral on the right hand

0, ∀u, we get

side of (37) as follows:

18

Γ(D)

u ≤ (cid:101)ΣZ1

+ (cid:101)ΣZ3

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)Z1 − (cid:101)Z1
(cid:13)2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)Z3 − (cid:101)Z3
(cid:13)2

+ (cid:101)ΣZ2

(cid:13)
(cid:13)
(cid:13)Z2 − (cid:101)Z2

(cid:13)
(cid:13)
(cid:13)2

,

√

K

(cid:90)

a

(cid:112)log N(Π, µ)dµ ≤

√

K(cid:112)log N(Π, a).

The above inequality holds because (cid:112)log N(Π, µ) increases
monotonically with the decrease of µ. Taking a = 1/
K, we
get the following:

√

where

(cid:101)ΣZ1 = U C 3

ξ BZBx

(cid:101)ΣZ2 = U 2C 4

ξ BZBx

,

α(D+1) − 2α + 1
(α − 1)2
α(D+1) − 2α + 1
(α − 1)2

,

(cid:98)RG(Π) ≤
(cid:115)

(cid:18)

√

12

+

4
K

3E2 + E
√
K

×

(cid:101)ΣZ3 = U C 2

ξ BZBx

αD − 1
α − 1

.

in (38), we get

u

(cid:12)
(cid:12)πθ(φ) − π

Using the above bound on Γ(D)
(cid:101)θ(φ)(cid:12)
+ΣZ2

(cid:12) ≤ Σβ
(cid:13)
(cid:13)
(cid:13)Z2 − (cid:101)Z2

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)β − (cid:101)β
(cid:13)2
(cid:13)
(cid:13)
+ ΣZ3
(cid:13)2

(cid:13)
(cid:13)
(cid:13)Z1 − (cid:101)Z1
,

+ ΣZ1
(cid:13)
(cid:13)
(cid:13)Z3 − (cid:101)Z3

(cid:13)
(cid:13)
(cid:13)2

(cid:13)
(cid:13)
(cid:13)2

(40)

where Σβ = CζBxαD + CζU C 2
CζBβ (cid:101)ΣZ1, ΣZ2 = CζBβ (cid:101)ΣZ2, and ΣZ3 = CζBβ (cid:101)ΣZ3.

ξ BZBx

αD−1
α−1 , ΣZ1 =

Eq. (40) implies that for any θ ∈ Θ, the existence of (cid:101)θ in the
cover set such that |πθ(φ) − π
(cid:101)θ(φ)| ≤ µ can be satisﬁed by
ensuring the existence of ( (cid:101)β, (cid:101)Z1, (cid:101)Z2, (cid:101)Z3) such that the right
hand side of (40) ≤ µ. Hence, if we construct µ/4Σβ-cover
of Xβ, and µ/4ΣZi -cover of XZ, ∀i ∈ {1, 2, 3}, the Cartesian
product of the four sets correspond to a µ-cover of Π. Hence,
the covering number of Π at scale µ can be upper bounded
by the product of the covering numbers of the four sets as
follows:

(cid:18)

N (Π, µ) ≤ N

Xβ,

(cid:19)

×

µ
4Σβ

3
(cid:89)

i=1

(cid:18)

N

XZ,

(cid:19)

.

µ
4ΣZi

(41)

In addition, the covering number for XZ can be upper bounded
using [53, Lemma 8] as follows:

(cid:32)

N(XZ, µ) ≤

1 +

√
2

EBZ
µ

(cid:33)E2

.

Similarly, the covering number for Xβ can be upper bounded
as follows [54]:

N(Xβ, µ) ≤

(cid:18) 3Bβ
µ

(cid:19)E

.

Using the above bounds in (41), we get

N (Π, µ) ≤

(cid:19)E

(cid:18) 12BβΣβ
µ

×

3
(cid:89)

i=1

√
8

(cid:32)

1 +

EBZΣZi

µ

(cid:33)E2



≤

1 +

√

12

EBZmax

(cid:110) Bβ
BZ

Σβ, ΣZ1 , ΣZ2, ΣZ3
µ

(cid:111)

3E2+E





.

Finally, we can use Lemma 6 to obtain a bound on (cid:98)RG(Π).

log

1 + 12

√

EKBZmax

(cid:26) Bβ
BZ

Σβ, ΣZ1, ΣZ2 , ΣZ3

(cid:27)(cid:19)

.

Combining the above with (cid:98)RG(T ) ≤ CL (cid:98)RG(Π) and substi-
tuting in (36), we get the ﬁnal result.

APPENDIX E
PROOF OF THEOREM 2

Proof of Theorem 2 can be divided into two parts. In the ﬁrst
part we bound the expected loss under of the learned GNN. For
this we will use the proof idea from [24]. However, the proof
technique in [24] hinges on the convexity of their online learn-
ing problem. Hence, we make appropriate modiﬁcations to
accommodate our non-convex GNN-based learning problem.
In the second part, using the expected loss, we characterize
the number of nodes needed to be visited by Algorithm 3 for
solving a given problem instance optimally.

A. Expected Loss of Algorithm 1

Note that the online learning algorithm in Algorithm 1 is a

no-regret algorithm. The deﬁnition of regret is as follows:

Deﬁnition 1 (Regret). Regret of an online algorithm that
produces a sequence of policies θ1:I = {θ(1), θ(2), . . . , θ(I)}
is denoted by RegI . It is the average loss of all policies with
respect to the best policy in hindsight, i.e.,

RegI :=

1
I

I
(cid:88)

i=1

1
|Di|

(cid:88)

(Φs,ys)∈Di

[L(πθ(i) (φs), ys)]

− min
θ∈Θ

1
I

I
(cid:88)

i=1

1
|Di|

(cid:88)

[L(πθ(φs), ys)].

(Φs,ys)∈Di

Deﬁnition 2 (No-regret Algorithm). A no-regret algorithm is
an algorithm that produces a sequence of policies θ1:I such
that the average regret goes to 0 as N goes to ∞:

RegI ≤ γI

and

lim
I→∞

γI → 0.

For strongly convex L, the work in [24] shows that Algo-
rithm 1 is a no-regret algorithm with η = ∞, i.e., ψ = 0
(recall that η is the parameter of the exponential distribution,
i.e., ψ ∼ Exp(η), where Exp(η) := η(exp(−η))). However,
for non-convex L we cannot guarantee that Algorithm 1 is
a no-regret algorithm [47]. But with 0 < η < ∞, under
Assumption 2, Algorithm 1 was shown to be a no-regret
algorithm [47].

Lemma 7.
regret after N iterations can be bounded by:

[47, Theorem 1] When Assumption 2 holds, the

Eψ∼Exp(η)[RegI ] ≤ γI ≤ O(1/I 1/3).

Finally, the following lemma establishes the expected loss

of the policy returned by Algorithm 1.

Lemma 8. For Algorithm 1, with probability at least 1 − δ,

+ Gap

min
θ∈θ1:I

E(φs,ys)∼pθ ,ψ[L(πθ(φs), ys)]

≤ min
θ∈Θ

1
I

I
(cid:88)

i=1

1
J

+ γI + Gap

(cid:18) δ
2

(φs,ys)∈Di
(cid:115)

(cid:19)

, J

2 log( 2
δ )
I

(cid:88)

Eψ[L(πθ(φs), ys)]

.

(42)

entropy loss, i.e.,

19

Hence, with probability of at least 1 − δ, we have

min
θ∈θ1:I

Epθ ,ψ[L(πθ(φs), ys)]

(a)
≤ min
θ∈Θ

1
I

I
(cid:88)

i=1

1
J

(cid:88)

(φs,ys)∈Di

Eψ[L(πθ(φs), ys)] + O(1/I 1/3)

(cid:19) (cid:114)

(cid:18) δ
2

, J

2 log(2/δ)
I

(b)
≤ ν + O(1/I 1/3) + Gap

(cid:19) (cid:114)

(cid:18) δ
2

, J

2 log(2/δ)
I

,

where (a) is by Lemma 7 and (43), and (b) is obtained via
using Assumption 3.

When the loss function L is selected to be binary cross-

Proof: Deﬁne ωi, ∀i ∈ [I] as:

ωi :=Ep

−

θ(i) ,ψ[L(πθ(i) (φs), ys)]
1
J

(cid:88)

(φs,ys)∈Di

Eψ[L(πθ(i)(φs), ys)].

Next, we use Lemma 4 to obtain a bound on ωi, ∀i; i.e., with
probability at least 1 − δ/2, the following holds simultaneously
for ωi, ∀i ∈ [I] :

ωi ≤ Gap

(cid:19)

, J

.

(cid:18) δ
2

Consequently, Ωi := (cid:80)i
gale sequence, i.e.,

t=1 ωt, i = {1, . . . , I} forms a martin-

E[Ωi|Ω1, . . . , Ωi−1] = Ωi−1.

Also, we have |Ωi+1 − Ωi| ≤ Gap(δ/2, J), ∀i ∈ [I − 1] with
probability 1 − δ/2. Next, consider the following lemma:

Lemma 9 (Azuma-Hoeffding’s Inequality). Let X0, . . . , XI
be a martingale sequence and |Xi − Xi−1| ≤ ci. Then with
probability 1 − δ,

Pr(XI − X0 ≥ (cid:15)) ≤ exp

(cid:32)

(cid:33)

.

−(cid:15)2
i=1 c2
i

2 (cid:80)I

Using Lemma 9, we have the following holds with proba-

bility of at least (1 − δ/2)2 ≥ 1 − δ,

ΩI ≤ Gap

(cid:19)

, J

(cid:18) δ
2

(cid:112)2I log(2/δ).

(43)

Now, consider the following inequality:

min
θ∈θ1:I

Epθ ,ψ[L(πθ(φs), ys)]

≤

=

1
I

1
I

I
(cid:88)

i=1
I
(cid:88)

i=1

Epθi

Eψ[L(πθ(i) (φs), ys)]

1
J

(cid:88)

(φs,ys)∈Di

Eψ[L(πθ(i) (φs), ys)] +

1
I

I
(cid:88)

i=1

ωi.

L(x, y) = −y log(x) − (1 − y) log(1 − x),

1 − e−L(x,y) corresponds to the classiﬁcation error. Therefore,
classiﬁcation accuracy for any θ, i.e., ρθ is given by

ρθ = Epθ ,ψ[exp(−L(πθ(φs), ys))].

Note that (cid:98)θ = arg minθ∈θ1:I Epθ ,ψ[L(πθ(φs), ys)]. Next,
(cid:98)θ. To that end, the following follows from

we characterize ρ
Lemma 8.

exp(Epθ ,ψ[−L(πθ(φs), ys)])

(cid:32)

≥ exp

−ν − O(1/I 1/3) − Gap

(cid:19) (cid:114)

(cid:18) δ
2

, J

2 log(2/δ)
I

(cid:33)

=⇒ ρ

(cid:98)θ = Epθ ,ψ[exp(−L(πθ(φs), ys))]
(b)
≥ exp

−ν − O(1/I 1/3) − Gap

(cid:32)

(cid:18) δ
2

(cid:19) (cid:114)

, J

2 log(2/δ)
I

(cid:33)

,

where (b) follows from Jensen’s inequality.

B. B&B expected number of nodes and optimality

Let (cid:15)FP denote the false positive error rate, i.e., the proba-
bility of classifying an irrelevant node as relevant. Also deﬁne
(cid:15)FN denote the false negative error rate, i.e., the probability of
classifying a relevant node as irrelevant. Then the expected
number of branches generated by using pruning policy on
B&B was derived in [20]:

Lemma 10 ( [20, Theorem 1]). Assume that the node selec-
tion method in (18) ranks an irrelevant node higher than a
relevant node with probability (cid:15)r. Then the expected number
of branches (number of non-leaf nodes) is

Q

(cid:98)θ − 1
2

≤

(cid:18) (cid:18) 1 − (cid:15)FN
1 − 2(cid:15)r(cid:15)FP

+

(cid:15)FN
1 − 2(cid:15)FP

(cid:19)

N
(cid:88)

(cid:15)r(cid:15)FP

(1 − (cid:15)FN)n

n=0

+(1 − (cid:15)FN)N +1 (1 − (cid:15)r)(cid:15)FP
1 − 2(cid:15)FP

(cid:19)

+ 1

N,

Our node selection strategy is the lowest lower bound ﬁrst
as detailed in Section II. In the worst case scenario, (cid:15)r = 1.

Therefore, using Lemma 10, the expected number of branches
is

N
(cid:88)

n=0

(cid:33)

ρn
(cid:98)θ

+ 1

(cid:33)

+ 1

≤ N

(c)
= N

N (2ρ

=

(cid:32)

1 − ρ
2ρ

(cid:98)θ
(cid:98)θ − 1
(cid:32) 1 − ρN +1
(cid:98)θ
(cid:98)θ − 1
2ρ
(cid:98)θ − ρN
)
(cid:98)θ
(cid:98)θ − 1

2ρ

.

)

≤

2ρ

+ 1.

2N (2ρ

Since the expected number of branches correspond to the
expected number of non-leaf nodes, the total number of nodes
in the tree is

(cid:98)θ − ρN
(cid:98)θ
(cid:98)θ − 1
Next, we we characterize the probability that Algorithm
3 provides the optimal solution. To this end, observe that
there is only one relevant node at any depth n of the B&B
algorithm. The probability of not pruning a relevant node is
≥ ρ
(cid:98)θ. Therefore, the probability of not pruning a relevant node
at any depth of the branch and bound tree is ≥ ρN
(since N
(cid:98)θ
is the maximum depth of the tree). Hence, the probability of
obtaining an optimal solution is at least ρN
(cid:98)θ

.

APPENDIX F
GNN DESIGN IN SIMULATIONS
In this section, we detail the GNN architecture used in
the experiments. The GNN is designed to accommodate the
unequal input feature dimensions for antennas and users. We
enhance the expressiveness GNN by letting different layers to
have different aggregation matrices in our experiments. The
initial embeddings of a common size E are obtained using a
single layer fully connected neural network, i.e.,

q(0)
n = ReLU(Z1xn)
q(0)
N +m = ReLU(Z2xm)
eu,v = ReLU(Z3 (cid:101)eu,v).
where Z1 ∈ RE×Va , Z2 ∈ RE×Vu , Z3 ∈ RE×Ve , and ReLU :
RE → RE deontes elementwise nonlinear function such that
ReLU(x) = max{x, 0}.

The ﬁrst layer of GNN only updates the antenna vertices,

i.e., qn, n ∈ [N ], as follows

(cid:32)

(cid:32)

q(1)
n = Z9

ReLU

Z8q(0)

n +

M
(cid:88)

(cid:16)

Z7

ReLU

(cid:16)

Z6q(0)

n +

m=1
(cid:33)(cid:33)

(cid:17)(cid:17)

, ∀n ∈ [N ]

Z5q(0)

N +m + Z4en,N +m

N +m = q(0)
q(1)

N +m, ∀m ∈ [M ].

The second layer only updates the user vertices as follows

(cid:32)

(cid:32)

q(2)
N +m = Z15

ReLU

Z14q(1)

N +m +

N
(cid:88)

(cid:16)

Z13

(cid:16)

ReLU

Z12q(1)

N +m

n=1

(cid:17)(cid:17)(cid:17)(cid:17)

20

Such “split updating” of different nodes’ embeddings in two
layers has been advocated in [30] for the type of graph
structure used in this work (i.e., a bipartite graph). Moreover,
there is a potential saving in the computational cost in both
training and testing [55] compared to updating all nodes’
embeddings in each layer.

Finally, πθ(φ) is computed using the q(2)

N +m, ∀m ∈ [M ] as

follows:

(cid:32)

πθ(φ) = Sigmoid

M
(cid:88)

β(cid:62)ReLU(Z16q(2)

N +m)

,

(cid:33)

1
M

m=1
where Z4, . . . Z16 ∈ RE×E, β ∈ RE, and Sigmoid : R → R
is the sigmoid function, i.e., Sigmoid(x) =

1
1+exp(−x) .

APPENDIX G
CONSTRUCTION OF INPUT FEATURES (φ(N ((cid:96))

s

))

We assign the features tabulated in Table I among the
elements of the following sets: {xi | i ∈ [N ]}, {xN +i | i ∈
[M ]}, and {ei,N +j | i ∈ [N ], j ∈ [M ]}. Speciﬁcally, the
problem size-dependent features that can be represented with
s , and B((cid:96))
a vector of dimension N (i.e., A((cid:96))
s , [(cid:107)W(cid:96),s(1, :
)(cid:107)2
2, . . . , (cid:107)W(cid:96),s(N, :)(cid:107)2
2]) are assigned to the elements of
{xi | i ∈ [N ]} as follows:
(cid:40)

xi(1) =

(cid:40)

xi(2) =

1, if i ∈ A((cid:96))
s
0, otherwise,
1, if i ∈ B((cid:96))
s
0, otherwise, and

xi(3) = (cid:107)W(cid:96),s(i, :)(cid:107)2
2.

Similarly, the problem size-dependent features that can be
represented by a vector of dimension M (i.e., W(cid:96),s(:, m)H hm
and the aggregated interference under W(cid:96),s) are assigned to
be the elements of {xN +i | i ∈ [M ]} as follows:

xN +i(1) = (cid:12)
xN +i(2) =

(cid:12)
2
(cid:12)

(cid:12)W(cid:96),s(:, i)H hi
(cid:88)

(cid:12)
(cid:12)W(cid:96),s(:, j)H hi

and
(cid:12)
2
(cid:12)

.

j(cid:54)=i

The remaining problem size-dependent features can be repre-
sented by a vector of dimension N M , and are assigned to the
elements of {ei,N +j | i ∈ [N ], j ∈ [M ]} as follows:

(ei,N +j(1), ei,N +j(2), ei,N +j(3)) = (Re(H(i, j)),

Im(H(i, j)), |H(i, j)|)

(ei,N +j(4), ei,N +j(5), ei,N +j(6)) = (Re(Wincumbent(i, j)),

Im(Wincumbent(i, j)), |Wincumbent(i, j)|)
(ei,N +j(7), ei,N +j(8), ei,N +j(9)) = (Re(W(cid:96),s(i, j)),
Im(W(cid:96),s(i, j)), |W(cid:96),s(i, j)|),

where Re(·) and Im(·) returns the real and imaginary part of
the complex number.

Finally, the problem size-independent features are assigned

to the set {xN +i | i ∈ [M ]} as follows:

+ Z11q(1)

n + Z10en,N +m

n = q(1)
q(2)

n , ∀n ∈ [N ].

, ∀m ∈ [M ]

(xN +i(3), xN +i(4), . . . , xN +i(8))
= (l(t)
), Φub(N ((cid:96))
G , Φlb(N ((cid:96))

G , u(t)

s

s

), (cid:96), 1(Φub(N ((cid:96))

s

) − u(t)

G < (cid:15))).

APPENDIX H
SOLVING SDR IN (5)

The method for solving SDR in (5) is explained in [17]. We
detail the procedure below for the sake of completeness. The
constraint (5b) can be equivalently written as a linear matrix
inequality using the S-lemma. The equivalent optimization
problem is then expressed as follows:

21

minimize
{Wm,Ym}M

m=1,t

M
(cid:88)

m=1

tr(Wm)

subject to Ym =

(cid:20)Qm + tmI
rH
m

(cid:21)

rm
sm − tmε2
m

, m ∈ [M ]

Ym (cid:23) 0, Wm (cid:23) 0, tm ≥ 0 m ∈ [M ],

where,

Qm =

1
γm

Wi −

(cid:88)

j(cid:54)=i

Wj,

rm = Qmhm,
sm = hH

mQmhm − σ2
m.

When the conditions in Lemma 2 are satisﬁed, the optimal
beamforming matrix W (cid:63) = [w(cid:63)
1, w(cid:63)
M ] can be ob-
tained from optimal solution, W (cid:63)
m, ∀m, to the above problem
as follows:

2, . . . , w(cid:63)

(cid:113)

w(cid:63)

m =

1 v(m)
λ(m)
where λ1 and v1 are the principal eigenvalue and eigenvector
of W (cid:63)

, ∀m ∈ [M ],

m, respectively.

(44)

1

