0
2
0
2

t
c
O
0
3

]
T
S
.
n
i
f
-
q
[

2
v
2
9
8
3
1
.
0
1
0
2
:
v
i
X
r
a

Financial Data Analysis Using Expert Bayesian
Framework For Bankruptcy Prediction

Amir Mukeria,∗, Habibullah Shaikhb, Dr. D.P. Gaikwadc

aDepartment of Computer Engineering, AISSMS College of Engineering, No. 1, Kennedy
Road, Pune, Maharashtra, India 411001. amir_mukeri@acm.org
bCredit Risk Consultant, D-2, Herms Grace, Camp, Pune, Maharashtra, India 411001.
habib80@gmail.com
cHead of Department of Computer Engineering, AISSMS College of Engineering, No. 1,
Kennedy Road, Pune, Maharashtra, India 411001. dpgaikwad@aissmscoe.com

Abstract

In recent years, bankruptcy forecasting has gained lot of attention from re-
searchers as well as practitioners in the ﬁeld of ﬁnancial risk management. For
bankruptcy prediction, various approaches proposed in the past and currently
in practice relies on accounting ratios and using statistical modeling or machine
learning methods. These models have had varying degrees of successes. Mod-
els such as Linear Discriminant Analysis or Artiﬁcial Neural Network employ
discriminative classiﬁcation techniques. They lack explicit provision to include
prior expert knowledge. In this paper, we propose another route of generative
modeling using Expert Bayesian framework. The biggest advantage of the pro-
posed framework is an explicit inclusion of expert judgment in the modeling
process. Also the proposed methodology provides a way to quantify uncertainty
in prediction. As a result the model built using Bayesian framework is highly
ﬂexible, interpretable and intuitive in nature. The proposed approach is well
suited for highly regulated or safety critical applications such as in ﬁnance or
in medical diagnosis. In such cases accuracy in the prediction is not the only
concern for decision makers. Decision makers and other stakeholders are also in-
terested in uncertainty in the prediction as well as interpretability of the model.
We empirically demonstrate these beneﬁts of proposed framework on real world
dataset using Stan, a probabilistic programming language. We found that the
proposed model is either comparable or superior to the other existing methods.
Also resulting model has much less False Positive Rate compared to many ex-
isting state of the art methods. The corresponding R code for the experiments
is available at Github repository.

Keywords: Bayesian Data Analysis, Interpretable Machine Learning,
Uncertainty Quantiﬁcation, Financial Credit Risk, Bankruptcy prediction

∗Principal corresponding author
Email address: amir_mukeri@acm.org (Amir Mukeri)

Preprint submitted to Journal

 
 
 
 
 
 
1. Introduction

The adverse eﬀect of uncertainty across most of the global economies, aggra-
vated by the series of shocks to the ﬁnancial sector, will likely be felt increasingly
across most sectors with ongoing pandemic as outlined by Inetrnational Mone-
tory Fund (IMF, 2020). Worsening conditions in the capital markets, increasing
economic instability and declining consumer conﬁdence has meant that sound
liquidity positions, prudent treasury management and resilient cash ﬂows are
important for credit quality, particularly for speculative grade corporates.

Bankruptcy is a state wherein a corporation is unable to meet or repay its
statutory obligations from its operating activities. Financial ratio analysis helps
in identifying such types of bankrupt corporations or corporations headed for
bankruptcy in the near future.

Ratio Analysis is important for relevant stakeholders such as banks, ﬁnan-
cial institutions, investors, and others in order to analyze the ﬁnancial position,
liquidity, proﬁtability, risk, solvency, eﬃciency, and ultimately the health of any
corporation. These are quantitative metrics which help stakeholders in tak-
ing timely decisions as well as identifying corporations which will go bankrupt.
They are early warning indicators of credit risk and ﬁnancial distress. Broad
set of ﬁnancial ratios would include liquidity ratios, solvency ratios, proﬁtabil-
ity ratios, eﬃciency ratios, coverage ratios, and earnings ratios. The numerator
and denominator of the ratio to be calculated are taken from the ﬁnancial state-
ments. Financial ratios can be seen as a tool that can be used by every company
to determine the ﬁnancial liquidity, the debt burden, and the proﬁtability of the
company and whether it would be able to sustain and meet its obligations in
the near future. In fact, bond rating agencies like S&P, Moody’s and Fitch also
use ﬁnancial ratio analysis to rate corporate bonds. These ratios are critical
component of any statistical or machine learning model built to analyze and
forecast ﬁnancial distress.

There are various statistical techniques such as Linear Discriminant Anal-
ysis (LDA), Multi-discriminant Analysis(MDA) as well as machine learning
techniques such as Support Vector Machines (SVM), Artiﬁcial Neural Net-
works(ANN) used for bankruptcy prediction (Devi and Radhika, 2018). How-
ever none of these approaches allow quantiﬁcation of uncertainty in prediction
or intuitive interpretability of model. These are specially important in the
ﬁelds such as healthcare diagnosis or ﬁnance where the decision based on the
predictions of models have critical implications. On the other hand, Bayesian
framework provides capability to include expert judgement, uncertainty quan-
tiﬁcation as well as interpretability of model right out of the box. The proposed
model will help stakeholders to be more vigilant, alleviate the above risks and
in predicting bankruptcies. The methodology presented in this article helps
investors, banks, ﬁnancial institutions and other relevant stakeholders to take
corrective measures, timely decisions, strategic business planning in the funding
and investment process. In our knowledge this is the ﬁrst of it’s kind study to
apply Bayesian treatment to bankruptcy forecasting.

Reminder of the article is organized as follows. The second section presents

2

the literature survey covering some of the earlier work done in the area of
bankruptcy prediction, third section covers the dataset used for conducting
our experiments. Fourth section gives a brief introduction to Generalized Lin-
ear Modeling method with underlying mathematical underpinnings followed by
sections on experimental results, comparative performance with other methods
and conclusions.

2. Related Work

Altman’s Z-score (Altman, 1968) is a popular method to determine whether
a company would go bankrupt or not based on the selected ﬁnancial ratios.
Vast literature on the study of distressed companies relies on this method as
ﬁrst tool of choice available in their toolbox. However it was not able to perform
as expected as demonstrated later in the comparative study section.

On the other side of spectrum, machine learning techniques such as logistic
regression was used by Ohlson (Ohlson, 1980). Qi Yu et al. (Yu et al., 2014)
used Extreme Learning Machines for the prediction which relies on single layer
Artiﬁcial Neural Network which is evolved with the knowledge of ﬁnancial ratios
to discover the most optimum neural network structure. Arindam Chaudhary et
al. (Chaudhuri and Ghosh, 2017) proposed the soft computing approach using
fuzzy rough sets. Lahmiri, S et al. (Lahmiri and Bekiros, 2019) proposed the
Generalized Regression Topology as an eﬃcient method to arrive at optimized
neural architecture search. Barboza et al.
(Barboza et al., 2017) provides
detailed survey on the statical techniques such as Linear Discriminant Analysis
(LDA) as well as machine learning techniques such as Support Vector Machine
and their comparative analysis.

While each of the above methods have their merits and demerits none of
them provide uncertainty quantiﬁcation of the prediction. On top of that many
models including those based on Artiﬁcial Neural Networks (ANN) are black
box models. They provide no opportunity to interpret them and facilitate the
discussion between experts, business stakeholders even if they could perform
well on test data. Secondly, many of these models need the tuning of the
hyperparameters, for example, number of neurons or layers and learning rate
which is a time consuming and considered as black art (Snoek et al., 2012).

Many of these challenges can be overcome with Bayesian modeling tech-
niques. Bayesian modeling techniques allows us to provide uncertainty quan-
tiﬁcation in terms of posterior probability density (Gelman et al., 2013). While
in the past there have been challenges in sampling from this distribution due
to computational limitations however with the increased capacity and power
of modern computation sampling has become much more practical. Also ad-
vances in sampling algorithms such as Markov Chain Monte Carlo (MCMC)
have helped alleviate further the pain point in this regard when exact posterior
computation is intractable specially for multivariate data.

3

Table 1: Class distribution in training and test dataset

Dataset #Non-bankrupt #Bankrupt
Training
Test

5487
2105

113
47

3. Dataset

For this study, bankruptcy information of Polish companies (Kaggle, 2020)
is used which is based on dataset by Zeiba M et al. (Zięba et al., 2016) for
the period between year 2000-2012. This dataset consists of various accounting
rations such as diﬀerent types of assets to liabilities in both long and short
terms, and whether that company went bankrupt or not. Such 10,000 sample
data points are available. Dataset was divided into training and test dataset
with class label distribution as shown in Table 1

All the 64 ﬁnancial ratios available in the dataset are shown in Appendix in

the Table A.10

4. Methodology

Generalized Linear Model was chosen which is well known for its ﬂexibility.
To implement Bayesian GLM regression model we have used R package rstanarm
(Muth et al., 2018) that provides an abstraction over the underlying probabilistic
programming language compiler of Stan.

Data is preprocessed by using standard scaling method. Then the variables
to be included in the model are selected along with suitable prior distribution
for model’s priors. After building the models their predictive performance was
compared using K Fold cross validation. Once the model is selected their sig-
niﬁcance is assessed using Bayesian hypothesis testing methodology. in all the
phases of these process domain expertise was utilized.

This process is illustrated in the ﬂowchart in Figure 1

4.1. Generalized Linear Model

Generalized Linear Models (GLM) are similar to linear regression models.
Here instead of having a normally distributed output variable it could be made
constrained, for example, for a binary logistic regression, the output or response
variable can be restricted to be between 0 and 1 or positive values only.

More formally, for binary outcome yi, which is Bernoulli independent and

identically distributed (iid) given the probability of parameters as θi ,

f (yi|θi) ∼ Bernualli(θi), i = 1, 2, ...n

(1)

4

5

Figure 1: Methodology:In all the phases inputs from domain expert are vital

Bernoulli distribution is a special case of Binomial distribution where out of n
inputs we model the probability of k outputs being 1 (success) or zero (failure).
The expected value for discrete random variable X with a ﬁnite number
of outcomes x1, x2, ...xk occurring with probabilities θ1, θ2, ...θk respectively, is
given by:

E[X]=

k
(cid:88)

i=1

xiθi=x1θ1+x2θ2+...+xkθk

For a linear regression model, the expectation of θi is given by:

E(θi) = β0 + β1xi

However in order to constrain the value of θi to be between 0 and 1 we use
log-odds ratio as,

log(θ) = log(

θ
1 − θ

) = β0 + β1xi

(2)

(3)

(4)

This function, log of odds, is also called as logit-link function. It called as
Link since it helps to link given linear expression to valid probability between
0 and 1 of successful outcome.

Therefore the expected value for the linear expression with probability of

success as θi and probability of failure as (1 − θi) is given as :

E[θi] = 1 ∗ θi + 0 ∗ (1 − θi) =

e(β0+β1x)
1 + e(β0+β1x)

=

1
1 + e−(β0+β1x)

(5)

This model can be extended to multidimensional as well as multinomial

response variables by adding number of coeﬃcients accordingly.

In order to build Bayesian linear regression model, we can select priors on

intercept and coeﬃcient, for example, to be normally distributed as,

Intercept : β0 ∼ N ormal(a, b)

β1 ∼ N ormal(a, b)

6

(6)

(7)

In case of Hierarchical Bayesian models we can include the priors for a and b
as well.However in this study due to lack obvious population subgroups in data
such as sector or region hierarchical model were not utilized.

In order to compute the posterior distribution of parameter vector β using

Bayesian inference,

posterior =

likelihood ∗ prior
evidence

p(β|X) =

´

f (X|β) ∗ p(β)
f (X|β) ∗ p(β)dβ

(8)

(9)

In above equation, denominator i.e. the normalizing constant is most of the
times a multidimensional integral and is analytically intractable to compute.
Therefore we approximate the posterior distribution using Markov Chain Monte
Carlo (MCMC) sampling algorithm. Probabilistic programming language such
as Stan (Carpenter et al., 2017) helps in generating dependent samples from
such distribution as an approximation to the true posterior distribution in an
eﬃcient manner.

The posterior predictive distribution for a new example is given by,

ˆ

p(ynew|X, β) =

p(ynew|β) ∗ p(β|X)dβ

(10)

4.2. Variable Selection

In the dataset there are total of 64 ﬁnancial ratios that are explanatory
variables and a class variable indicating whether the company went bankrupt
or not indicated by 1 or 0 respectively. Expertise in credit risk management
available to us played a critical role in this phase. We started with including
variables in the model as shown in Table 2 In Model#1 with focus on ratios
involving total liabilities.

Table 2: Ratios in Model#1

Ratios
[(cash + short-term securities + receivables - short-term
liabilities) / (operating expenses - depreciation)] * 365
gross proﬁt (in 3 years) / total assets
(equity - share capital) / total assets
(net proﬁt + depreciation) / total liabilities
operating expenses / total liabilities

7

For the second model Model#2 we included mostly short term liability ratios

as shown in Table 3

Table 3: Ratios in Model#2

Ratios
book value of equity / total liabilities
equity / total assets
gross proﬁt / short-term liabilities
(inventory * 365) / sales
operating expenses / short-term liabilities
(current assets - inventory - receivables) / short-term liabilities
proﬁt on operating activities / sales
(current assets - inventory) / short-term liabilities
EBITDA (proﬁt on operating activities - depreciation) / sales
long-term liabilities / equity
sales / short-term liabilities
sales / ﬁxed assets

4.3. Choice of Priors

Since we believe that intercept as well coeﬃcient should be close to zero
however there is chance that they could be large. Therefore for both the mod-
els Student’s t-distribution was used as it provides fatter tails than a Normal
distribution as prior for all parameters with following hyperparameters:

priors ∼ Student_t(df = 7, location = 0, scale = 2.5)

(11)

4.4. Model Convergence

Once the model is setup up, it is ﬁtted on training data.

In this pro-
cess we draw samples from posterior distribution using Markov Chain Monte
Carlo(MCMC) sampling, speciﬁcally using No U Turn Sampler (NUTS) (Hoﬀ-
man and Gelman, 2014).

Both the models converged with 4000 total iterations with 2000 warmup
iterations with 4 chains. For all the coeﬃcients we got an (cid:98)R of less than 1.1. (cid:98)R
helps in analyzing the mixing of chains, value of less than 1.1 is an indication
of proper mixing of chains (Vehtari et al., 2020) .

Analysis of posterior samples is shown in Table B.11 for Model#1 and in

Table B.12 for Model#2.

8

4.5. Model Selection

Bayesian K Fold cross validation (Vehtari et al., 2017) is used to compare
both the models with 10 folds. The Expected Log Point wise Density (elpd)
diﬀerence between the two models is shown in Table 4. The elpd helps in
comparing the model and hence in model selection. From the diﬀerence in the
elpd values we see that Model#2, even though it has more number of variables
there is diﬀerence with high standard error. Therefore we choose Model#2 as
better amongst the two models.

Table 4: ELPD Diﬀerence

Model#2
Model#1

ELPD diﬀerence
0.0
-0.1

Std Error
0.0
13.6

Also Model#1 as well Model#2 was tested on unseen test dataset.Confusion
matrix from the predictions of Model#1 and Model#2 is shown in Table 5
and Table 6 respectively. Model#2 performs better than Model#1 for the test
data speciﬁcally in detecting with positive cases. Here threshold of 0.5 for
column means of the posterior predictive samples was used to map the real
values between 0 and 1 to discrete 0s and 1s.

Table 5: Model#1 Confusion Matrix

Predicted NO Predicted YES

True NO
True YES

2101
47

4
0

Table 6: Model#2 Confusion Matrix

Predicted NO Predicted YES

True NO
True YES

2087
39

18
8

From the test results clearly Model#2 performs better than Model#1 on all

measures.

4.6. Bayesian Insight

To determine if an attribute is signiﬁcant or not we used ROPE (Region of
Practical Equivalence) (Kruschke, 2014). ROPE value provides the percentage
of Credible Interval(CI) that is in the null region. With suﬃciently high value
of ROPE the null hypothesis is accepted otherwise rejected. The signiﬁcant
attributes are highlighted in Table B.11and B.12. Figure 2 shows posterior
density plot using the drawn samples with uncertainty intervals. We can see
that the attributes with signiﬁcant values are away from zero.

9

Figure 2: Posterior Density plot for Model#1

From this analysis we can see that ratios involving short-term liabilities are

the best predictors for bankruptcy based on our dataset.

We further analyze these ratios to get more insight using report (Makowski
and Lüdecke, 2019) R package. After generating report we can examine signif-
icance of an attribute. Following is the list of the analysis of the attributes in
Model#2. Signiﬁcant attributes in the below summary are underlined.

• The eﬀect of (Intercept) has a probability of 100% of being negative and
can be considered as large and signiﬁcant (median = -5.09, 89% CI [-
5.44, -4.72], 0% in ROPE, std. median = ). The algorithm successfully
converged (Rhat = 1.004) and the estimates can be considered as stable
(ESS = 1261).

• The eﬀect of Attr8 (book value of equity / total liabilities) has a probabil-
ity of 67.90% of being negative and can be considered as very small and
not signiﬁcant (median = -0.06, 89% CI [-0.32, 0.12], 76.15% in ROPE,
std. median = -0.06). The algorithm successfully converged (Rhat =
1.001) and the estimates can be considered as stable (ESS = 2197).

• The eﬀect of Attr10 (equity / total assets) has a probability of 63.68%
of being positive and can be considered as very small and not signiﬁcant
(median = 0.04, 89% CI [-0.12, 0.20], 90.33% in ROPE, std. median

10

= 0.04). The algorithm successfully converged (Rhat = 1.000) and the
estimates can be considered as stable (ESS = 3208).

• The eﬀect of Attr12 (gross proﬁt / short-term liabilities) has a probability
of 83.23% of being positive and can be considered as very small and not
signiﬁcant (median = 0.20, 89% CI [-0.11, 0.50], 43.60% in ROPE, std.
median = 0.20). The algorithm successfully converged (Rhat = 1.000)
and the estimates can be considered as stable (ESS = 3673).

• The eﬀect of Attr20 ((inventory * 365) / sales) has a probability of 91.50%
of being negative and can be considered as very small and not signiﬁcant
(median = -0.20, 89% CI [-0.54, 0.05], 45.88% in ROPE, std. median
= -0.20). The algorithm successfully converged (Rhat = 1.001) and the
estimates can be considered as stable (ESS = 3112).

• The eﬀect of Attr33 (operating expenses / short-term liabilities) has a
probability of 100% of being positive and can be considered as large and
signiﬁcant (median = 9.22, 89% CI [5.93, 12.31], 0% in ROPE, std. median
= 9.22). The algorithm successfully converged (Rhat = 1.001) and the
estimates can be considered as stable (ESS = 2182).

• The eﬀect of Attr40 ((current assets - inventory - receivables) / short-term
liabilities)) has a probability of 100% of being positive and can be consid-
ered as large and signiﬁcant (median = 2.71, 89% CI [1.81, 3.54], 0% in
ROPE, std. median = 2.71). The algorithm successfully converged (Rhat
= 1.001) and the estimates can be considered as stable (ESS = 2086).

• The eﬀect of Attr42 (proﬁt on operating activities / sales) has a probability
of 100% of being negative and can be considered as large and signiﬁcant
(median = -19.73, 89% CI [-31.69, -8.29], 0.03% in ROPE, std. median
= -19.73). The algorithm successfully converged (Rhat = 1.000) and the
estimates can be considered as stable (ESS = 2313).

• The eﬀect of Attr46 ((current assets - inventory) / short-term liabilities))
has a probability of 100% of being negative and can be considered as large
and signiﬁcant (median = -4.33, 89% CI [-5.56, -3.11], 0% in ROPE, std.
median = -4.33). The algorithm successfully converged (Rhat = 1.003)
and the estimates can be considered as stable (ESS = 1610).

• The eﬀect of Attr49 (EBITDA (proﬁt on operating activities - depreciation)
/ sales) has a probability of 100% of being positive and can be considered
as large and signiﬁcant (median = 20.25, 89% CI [9.48, 32.78], 0.03% in
ROPE, std. median = 20.25). The algorithm successfully converged (Rhat
= 1.000) and the estimates can be considered as stable (ESS = 2360).

• The eﬀect of Attr59 (long-term liabilities / equity) has a probability of
83.62% of being negative and can be considered as very small and not
signiﬁcant (median = -0.19, 89% CI [-0.52, 0.10], 49.45% in ROPE, std.

11

Figure 3: Equivalence Test Plot

median = -0.19). The algorithm successfully converged (Rhat = 1.005)
and the estimates can be considered as stable (ESS = 1727).

• The eﬀect of Attr63 (sales / short-term liabilities) has a probability of
100% of being negative and can be considered as large and signiﬁcant
(median = -10.33, 89% CI [-14.01, -7.09], 0% in ROPE, std. median =
-10.33). The algorithm successfully converged (Rhat = 1.001) and the
estimates can be considered as stable (ESS = 2019).

• The eﬀect of Attr64 (sales / ﬁxed assets) has a probability of 88.62% of
being positive and can be considered as very small and not signiﬁcant
(median = 0.10, 89% CI [-8.84e-03, 0.21], 93.80% in ROPE, std. median
= 0.10). The algorithm successfully converged (Rhat = 1.002) and the
estimates can be considered as stable (ESS = 1703).

Figure 3 shows the the plot of equivalence test that helps in deciding weather
the parameter should be accepted or rejected based on 89% Credible Interval
(CI).

From above analysis, we conclude that declining sales and disproportion-
ate short-term liabilities are the main predictors of credit default in near term
future.

12

Figure 4: Neural Network

5. Comparative Study

Using Altman’s Z-Score method (Altman, 1968) we found that it was inad-
equate and gave a very low accuracy of 21% on training data and 20% on test
data with high False Positive Rate (FPR).

We also conducted experiments using other machine learning methods such
as Support Vector Machines, Random Forest, Neural Network, and Logistic
Regression.

SVM classiﬁer with linear and radial basis kernels could not classify a single
true positive case from test data correctly. Random Forest was able to classify
one as true positive out of total 47 true positive cases from test data.

The experiments with neural network with 3 hidden layers were also carried
out. ANN is shown in Figure 4 . As shown in Table 7 it was able to classify 8
out of 47 true bankrupt cases.

On the other hand, non-Bayesian Generalized Linear Model with logit link

13

Table 7: Neural Network Confusion Matrix

Predicted NO Predicted YES

True NO
True YES

2087
39

18
8

Table 8: Non-Bayesian GLM Confusion Matrix

Predicted NO Predicted YES

True NO
True YES

2088
41

17
6

function, we found the results with the test data as shown in Table 8. Given
the ﬂexibility of the GLMs it was able to classify many more true positive
cases correctly. However it also ended up classifying more False positives in
the process.XGBOOST(Extreme Gradient Boosting Machine) was closest to the
proposed Bayesian GLM in detecting the positive cases. Performance metrics of
various methodologies that were tried against the proposed approach are listed
in Table 9. Graphical visualization of the same is shown in Figure 5 Also it was
found that oversampling the minority class i.e. records with bankruptcy class
did not improve their performance any further for any of the methods.

Critics of Bayesian methodology have objected to inclusion of prior knowl-
edge as being subjective however other method viz. frequentist do also use ex-
pert inputs without explicitly stating it (Brownstein et al., 2019). Frequnetist
models have no provision to explicitly include the same while building a model.
Bayesian framework allows the inclusion of prior judgment explicitly and up-
dating it based on the evidence as we proceed in our experiments. This helps
in directly driving decision making process using data as well as taking beneﬁt
of an expert judgement.

14

Table 9: Performance Comparison

Methodology

Accuracy

Precision

Recall

F1 Score

Train Test Train Test Train Test Train Test

Altman’s
Z-score
SVM-linear
kernel
SVM-RBF
kernel
XGBOOST
ANN
GLM
Proposed
Bayesian
GLM

5.6

6.0

97.16

100

3.75

4.0

7.22

7.7

97.98

97.81

97.98

97.81

100

100

98.98

98.89

97.79

97.81

97.79

97.81

100

100

98.98

98.89

100
99.05
97.44

97.86
86.01
97.3

100
99.04
98.19

98.12
97.92
98.07

100
100
99.21

99.71
87.55
99.19

100
99.51
98.7

98.91
92.45
98.63

97.98

97.25

97.98

98.16

100

99.0

98.98

98.60

(a) Accuracy

(b) Precision

(c) Recall

(d) F1 Score

Figure 5: Performance Comparison

6. Conclusion

With turbulent economic times ahead assessing and forecasting the ﬁnan-
cial well being of commercial entities will gain more and more traction. Most
of the conventional approaches including Artiﬁcial Neural Network are black

15

box in nature and provide no help in interpretation of model which is crucial
in decision making process. The proposed Bayesian GLM model and method-
ology meets the critical requirements of interpretability as well as inclusion of
expert judgement in all the phases of model building process. Secondly, the pro-
posed method do not need any hyperparameter tuning or neural architecture
search. In this research, we built and tested model with this approach on the
bankruptcy data of Polish companies. It was found that speciﬁcally looping in
expert reduced the time for the model building and model selection consider-
ably compared to other combinatorial and computationally intensive methods.
Expert in the loop approach also helped in interpreting the model and in com-
munication of results of analysis to the relevant stakeholders. At the end of the
analysis we found that the ratios involving short term liabilities were strong pre-
dictors of companies going bankrupt. We believe this study will help open new
avenues for further exploration of novel applications of Bayesian methodology
in the areas of credit risk management and in investment decision making along
with inclusion of domain expertise in the process.

16

17

Appendix A. Exploratory Variables

Table A.10: Complete list of variables

Variable
attr1 - net proﬁt / total assets

attr2 - total liabilities / total assets
attr3 - working capital / total assets
attr4 - current assets / short-term liabilities
attr5 - [(cash + short-term securities +
receivables - short-term liabilities) / (operating
expenses - depreciation)] * 365
attr6 - retained earnings / total assets
attr7 - EBIT / total assets
attr8 - book value of equity / total liabilities

attr9 - sales / total assets

attr10 - equity / total assets
attr11 - (gross proﬁt + extraordinary items +
ﬁnancial expenses) / total assets
attr12 - gross proﬁt / short-term liabilities
attr13 - (gross proﬁt + depreciation) / sales
attr14 - (gross proﬁt + interest) / total assets

attr15 - (total liabilities * 365) / (gross proﬁt
+ depreciation)
attr16 - (gross proﬁt + depreciation) / total
liabilities
attr17 - total assets / total liabilities

attr18 - gross proﬁt / total assets
attr19 - gross proﬁt / sales
attr20 - (inventory * 365) / sales

attr21 - sales (n) / sales (n-1)
attr22 - proﬁt on operating activities / total
assets
attr23 - net proﬁt / sales
attr24 - gross proﬁt (in 3 years) / total assets
attr25 - (equity - share capital) / total assets

attr26 - (net proﬁt + depreciation) / total
liabilities
attr27 - proﬁt on operating activities /
ﬁnancial expenses
attr28 - working capital / ﬁxed assets
attr29 - logarithm of total assets
attr30 - (total liabilities - cash) / sales
attr31 - (gross proﬁt + interest) / sales
attr32 - (current liabilities * 365) / cost of
products sold

18

Variable
attr33 - operating expenses / short-term
liabilities
attr34 - operating expenses / total liabilities
attr35 - proﬁt on sales / total assets
attr36 - total sales / total assets
attr37 - (current assets - inventories) /
long-term liabilities

attr38 - constant capital / total assets
attr39 - proﬁt on sales / sales
attr40 - (current assets - inventory -
receivables) / short-term liabilities
attr41 - total liabilities / ((proﬁt on operating
activities + depreciation) * (12/365))
attr42 - proﬁt on operating activities / sales
attr43 - rotation receivables + inventory
turnover in days
attr44 - (receivables * 365) / sales
attr45 - net proﬁt / inventory
attr46 - (current assets - inventory) /
short-term liabilities
attr47 - (inventory * 365) / cost of products
sold
attr48 - EBITDA (proﬁt on operating
activities - depreciation) / total assets
attr49 - EBITDA (proﬁt on operating
activities - depreciation) / sales
attr50 - current assets / total liabilities
attr51 - short-term liabilities / total assets
attr52 - (short-term liabilities * 365) / cost of
products sold)
attr53 - equity / ﬁxed assets
attr54 - constant capital / ﬁxed assets

attr55 - working capital
attr56 - (sales - cost of products sold) / sales
attr57 - (current assets - inventory - short-term
liabilities) / (sales - gross proﬁt - depreciation)
attr58 - total costs /total sales

attr59 - long-term liabilities / equity

attr60 - sales / inventory
attr61 - sales / receivables
attr62 - (short-term liabilities *365) / sales
attr63 - sales / short-term liabilities
attr64 - sales / ﬁxed assets

19

20

Appendix B. Posterior Description

2
9
9
.
0
5
1
1

5
1
8
.
9
7
7
1

1
0
0
.
1

2
0
0
.
1

S
S
E

t
a
h
R

n
i

%

E
P
O
R

0
0
0
.
0

5
4
6
.
4
6

1
#
l
e
d
o
M

r
o
f

r
o
i
r
e
t
s
o
P

:
1
1
.
B
e
l
b
a
T

E
P
O
R
%
9
8

d
p

I
C
%
9
8

n
a
i

d
e
M

r
e
t
e
m
a
r
a
P

]
1
8
1
.
0

,
1
8
1
.
0
-
[

]
1
8
1
.
0

,
1
8
1
.
0
-
[

0
0
0
.
1

5
1
9
.
0

]
0
9
3
.
4
-

,
1
5
9
.
4
-
[

]
1
1
3
.
0

,
3
3
0
.
0
-
[

0
7
6
.
4
-

0
5
1
.
0

)
t
p
e
c
r
e
t
n
I
(

/

)
s
r
a
e
y

3

n

i
(

t
ﬁ
o
r
p

s
s
o
r
g

s
t
e
s
s
a

l
a
t
o
t

8
3
1
.
1
2
4
6

9
9
9
.
0

9
1
3
.
5
6

]
1
8
1
.
0

,
1
8
1
.
0
-
[

9
8
9
.
0

]
3
4
0
.
0
-

,
3
6
2
.
0
-
[

0
6
1
.
0
-

/

)
l
a
t
i
p
a
c

e
r
a
h
s

-

y
t
i
u
q
e
(

0
4
5
.
7
4
8
1

0
0
0
.
1

0
0
0
.
0

]
1
8
1
.
0

,
1
8
1
.
0
-
[

0
0
0
.
1

1
6
6
.
0

/

s
e
s
n
e
p
x
e

g
n

i
t
a
r
e
p
o

s
e
i
t
i
l
i

b
a
i
l

l
a
t
o
t

9
0
5
.
3
5
3
1

2
0
0
.
1

9
3
7
.
9
2

]
1
8
1
.
0

,
1
8
1
.
0
-
[

0
5
9
.
0

]
2
0
8
.
0

,
1
1
5
.
0

[

0
8
3
.
0

m
r
e
t
-
t
r
o
h
s
+
h
s
a
c
(
[

7
0
7
.
5
3
2
2

0
0
0
.
1

0
0
0
.
0

]
1
8
1
.
0

,
1
8
1
.
0
-
[

0
0
0
.
1

]
8
8
6
.
0
-

,
2
6
2
.
1
-
[

1
6
9
.
0
-

s
t
e
s
s
a

l
a
t
o
t

+

t
ﬁ
o
r
p

t
e
n
(

l
a
t
o
t

/

)
n
o
i
t
a
i
c
e
r
p
e
d

s
e
i
t
i
l
i

b
a
i
l

21

1
3
3
.
9
3
2
1

1
0
0
.
1

0
0
0
.
0

]
1
8
1
.
0

,
1
8
1
.
0
-
[

0
0
0
.
1

]
7
9
8
.
0

,
8
3
0
.
0
-
[

3
6
1
.
2
-

-

s
t
e
s
s
a

t
n
e
r
r
u
c
(

m
r
e
t
-
t
r
o
h
s

/

)
y
r
o
t
n
e
v
n
i

s
e
i
t
i
l
i

b
a
i
l

-

s
e
l

b
a
v
i
e
c
e
r
+
s
e
i
t
i
r
u
c
e
s

/

)
s
e
i
t
i
l
i

b
a
i
l

m
r
e
t
-
t
r
o
h
s

-

s
e
s
n
e
p
x
e

g
n

i
t
a
r
e
p
o
(

5
6
3

*

]
)
n
o
i
t
a
i
c
e
r
p
e
d

Table B.12: Posterior for Model#2

Parameter

Median

89% CI

pd

(Intercept)

-5.078

book value of
equity / total
liabilities
equity / total
assets
gross proﬁt /
short-term
liabilities
(inventory * 365) /
sales
operating expenses
/ short-term
liabilities
(current assets -
inventory -
receivables) /
short-term
liabilities
proﬁt on operating
activities / sales
(current assets -
inventory) /
short-term
liabilities
EBITDA (proﬁt on
operating activities
- depreciation) /
sales
long-term liabilities
/ equity
sales / short-term
liabilities
sales / ﬁxed assets

-0.064

0.036

0.197

-0.197

9.176

2.720

[ -5.408,
-4.727]
[ -0.327,
0.122]

[ -0.121,
0.202]
[ -0.109,
0.501]

[ -0.549,
0.046]
[ 6.122,
12.508]

[ 1.818,
3.576]

1.000

0.692

0.692

0.835

0.918

1.000

1.000

89%
ROPE
[-0.181,
0.181]
[-0.181,
0.181]

[-0.181,
0.181]
[-0.181,
0.181]

[-0.181,
0.181]
[-0.181,
0.181]

[-0.181,
0.181]

% in
ROPE
0.000

Rhat

ESS

1.002

1273.642

81.606 1.001

2215.902

97.136 1.000

3249.143

45.970 1.000

3994.138

50.885 1.001

2686.980

0.000

1.000

2287.606

0.000

1.000

2260.580

-
18.648
-4.337

[-29.352,
-7.436]
[ -5.581,
-3.128]

1.000

1.000

[-0.181,
0.181]
[-0.181,
0.181]

0.000

1.000

2439.790

0.000

1.000

1772.371

19.113

[ 7.767,
29.850]

1.000

[-0.181,
0.181]

0.000

1.000

2455.714

-0.189

-
10.258
0.102

[ -0.562,
0.094]
[-13.981,
-6.939]
[ -0.011,
0.193]

0.840

1.000

0.898

[-0.181,
0.181]
[-0.181,
0.181]
[-0.181,
0.181]

52.457 1.003

1579.627

0.000

1.000

2111.063

96.855 1.002

1982.562

22

References

Altman, E. I. (1968). Financial ratios, discriminant analysis and the prediction

of corporate bankruptcy. The journal of ﬁnance, 23(4):589–609.

Barboza, F., Kimura, H., and Altman, E. (2017). Machine learning models and
bankruptcy prediction. Expert Systems with Applications, 83:405–417.

Brownstein, N. C., Louis, T. A., O’Hagan, A., and Pendergast, J. (2019). The
role of expert judgment in statistical inference and evidence-based decision-
making. The American Statistician, 73(sup1):56–68.

Carpenter, B., Gelman, A., Hoﬀman, M. D., Lee, D., Goodrich, B., Betan-
court, M., Brubaker, M., Guo, J., Li, P., and Riddell, A. (2017). Stan: A
probabilistic programming language. Journal of statistical software, 76(1).

Chaudhuri, A. and Ghosh, S. K. (2017). Bankruptcy prediction through soft

computing based deep learning technique. Springer.

Devi, S. S. and Radhika, Y. (2018). A survey on machine learning and statistical
International Journal of Machine

techniques in bankruptcy prediction.
Learning and Computing, 8(2):133–139.

Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., and Rubin,

D. B. (2013). Bayesian data analysis. CRC press.

Hoﬀman, M. D. and Gelman, A. (2014). The no-u-turn sampler: adaptively
setting path lengths in hamiltonian monte carlo. J. Mach. Learn. Res.,
15(1):1593–1623.

IMF (2020). World economic outlook:a long and diﬃcult ascent. World Eco-

nomic Outlook (WEO), Washington, DC, October.

Kaggle (2018 (accessed October 29, 2020)). Companies bankruptcy forecast.
https://www.kaggle.com/c/companies-bankruptcy-forecast/data.

Kruschke, J. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS,

and Stan. Academic Press.

Lahmiri, S. and Bekiros, S. (2019). Can machine learning approaches predict
corporate bankruptcy? evidence from a qualitative experimental design.
Quantitative Finance, 19(9):1569–1577.

Makowski, D. and Lüdecke, D. (2019). The report package for r: Ensuring the

use of best practices for results reporting. CRAN.

Muth, C., Oravecz, Z., and Gabry, J. (2018). User-friendly bayesian regression
modeling: A tutorial with rstanarm and shinystan. Quantitative Methods
for Psychology, 14(2):99–119.

23

Ohlson, J. A. (1980). Financial ratios and the probabilistic prediction of

bankruptcy. Journal of accounting research, pages 109–131.

Snoek, J., Larochelle, H., and Adams, R. P. (2012). Practical bayesian optimiza-
In Advances in neural information

tion of machine learning algorithms.
processing systems, pages 2951–2959.

Vehtari, A., Gelman, A., and Gabry, J. (2017). Practical bayesian model evalua-
tion using leave-one-out cross-validation and waic. Statistics and computing,
27(5):1413–1432.

Vehtari, A., Gelman, A., Simpson, D., Carpenter, B., Bürkner, P.-C., et al.
(2020). Rank-normalization, folding, and localization: An improved rhat
for assessing convergence of mcmc. Bayesian Analysis.

Yu, Q., Miche, Y., Séverin, E., and Lendasse, A. (2014). Bankruptcy prediction
using extreme learning machine and ﬁnancial expertise. Neurocomputing,
128:296–302.

Zięba, M., Tomczak, S. K., and Tomczak, J. M. (2016). Ensemble boosted trees
with synthetic features generation in application to bankruptcy prediction.
Expert systems with applications, 58:93–101.

24

