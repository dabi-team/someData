0
2
0
2

n
a
J

7
2

]

G
L
.
s
c
[

1
v
3
7
0
0
1
.
1
0
0
2
:
v
i
X
r
a

LIBTwinSVM: A Library for Twin Support Vector Machines

Amir M. Mir†‡
a.mir@iau-tnb.ac.ir
Mahdi Rahbar†‡
mehdi.rahbar@iau-tnb.ac.ir
Jalal A. Nasiri‡
j.nasiri@irandoc.ac.ir
†Faculty of Electrical and Computer Engineering, Islamic Azad University, North Tehran Branch,
Tehran, Iran
‡Iranian Research Institute for Information Science and Technology (IranDoc), Tehran, Iran

Abstract

This paper presents LIBTwinSVM, a free, eﬃcient, and open source library for Twin Sup-
port Vector Machines (TSVMs). Our library provides a set of useful functionalities such as
fast TSVMs estimators, model selection, visualization, a graphical user interface (GUI) ap-
plication, and a Python application programming interface (API). The benchmarks results
indicate the eﬀectiveness of the LIBTwinSVM library for large-scale classiﬁcation prob-
lems. The source code of LIBTwinSVM library, installation guide, documentation, and
usage examples are available at https://github.com/mir-am/LIBTwinSVM.
Keywords: TwinSVM, classiﬁcation, open source, GUI, API

1. Introduction

Twin Support Vector Machine (TSVM) is an extension of the Support Vector Machine
(SVM), which was proposed by Jayadeva et al. (2007). TSVM does binary classiﬁcation
using two non-parallel hyperplanes. Each of which is as close as possible to the samples of
its own class and far from the samples of the other class. The two non-parallel hyperplanes
are obtained by solving two smaller-sized Quadratic Programming Problems (QPPs). This
makes the learning speed of TSVM four times faster than that of SVM in theory (Jayadeva
et al., 2007). Over the past decade, new extensions of TSVM were introduced. For in-
stance, Kumar and Gopal (2009) proposed Least Squares Twin Support Vector Machine
(LSTSVM). Its central idea is similar to TSVM. However, LSTSVM solves two systems of
linear equations as opposed to solving two QPPs.

Aside from new research works on the theory of SVM, numerous free software pack-
ages and libraries have released for SVM, which include but not limited to, LIBLINEAR
(Fan et al., 2008), LIBSVM (Chang and Lin, 2011), and ThunderSVM (Wen et al., 2018).
However, there are not many free and open source software packages available for TSVM.
Recently, Mir and Nasiri (2019) released LightTwinSVM program which is a simple and
fast implementation of standard TSVM. It is a light-weight and small program that only
provides a command-line tool for classiﬁcation and model selection.

Motivated by the above discussion, we present LIBTwinSVM which is a free and open
source library for Twin Support Vector Machines. It is licensed under the terms of GNU
General Public License v3.0, which means this library can be used for both academic and
commercial purposes. Diﬀerent from other SVM and TSVM software packages, our library

c(cid:13) Amir M. Mir, Mahdi Rahbar, and Jalal A. Nasiri.

. .

 
 
 
 
 
 
Mir, Rahbar, Nasiri

has a simple Graphical User Interface (GUI) to help users employ the functionalities of
the library without writing code. In addition, a Python application programming interface
(API) was provided. The LIBTwinSVM library can be used on Linux, Windows, and Mac-
intosh operating systems. This library can be found on GitHub at https://github.com/mir-
am/LIBTwinSVM.

2. Twin Support Vector Machine

In this section, we brieﬂy review TSVM and its optimization problems. The linear TSVM
ﬁnds a pair of non-parallel hyperplanes which are represented by xT w1 + b1 = 0 and
xT w2 + b2 = 0, where x, w1, w2 ∈ Rd and b1, b2 ∈ R. Let the positive and negative
samples be denoted by matrix A ∈ Rn1×d and B ∈ Rn2×d, respectively. To obtain the two
non-parallel hyperplanes, TSVM solves two primal optimization problems with objective
function corresponding to one class and constrains corresponding to other class.

min
w1,b1
s.t.

min
w2,b2
s.t.

(cid:107)Aw1 + e1b1(cid:107)2 + c1eT
2 ξ

1
2
− (Bw1 + e2b1) + ξ ≥ e2 , ξ ≥ 0
1
2
(Aw2 + e1b2) + η ≥ e1 , η ≥ 0

(cid:107)Bw2 + e2b2(cid:107)2 + c2eT
1 η

(1)

(2)

where c1 and c2 are positive penalty parameters, ξ1 and ξ2 are slack vectors, e1 is the column
vectors of ones of n1 dimensions and e2 is the column vectors of ones of n2 dimensions.
Similar to SVM, the QPPs (1) and (2) are converted to dual problems, which are easier to
solve and has the advantage of bounded constraint. A new sample x ∈ Rd is assigned to
the class +1 or −1 depending on which of the two hyperplanes lies closest to the sample in
terms of perpendicular distance. TSVM was also extended to handle non-linear problems
by using two non-parallel kernel generated-surfaces (Jayadeva et al., 2007).

3. Library Description

In this section, we discuss the design and implementation of the LIBTwinSVM library. The
library was developed in a modular manner, which makes debugging, testing and mainte-
nance easier. Figure 1 shows the main components of the LIBTwinSVM library and their
relation. Most SVM and TSVM packages have a command-line interface including LIBSVM,
ThunderSVM, and LightTwinSVM. However, our library provides a user-friendly graphical
user interface (GUI) which makes usage of library functionalities easier. LIBTwinSVM also
consists of fast implementation of standard TSVM and LSTSVM classiﬁer. On the other
hand, LightTwinSVM program only provides an implementation of standard TSVM. To
solve multi-class classiﬁcation problems, popular multi-class schemes including One-vs-All
(OVA) and One-vs-One (OVO) are provided.

LIBTwinSVM library contains a visualization component, which can draw linear and
non-linear decision boundaries for both binary and multi-class TSVM-based estimators.
Figure 2 indicates a sample output of the visualization capabilities of LIBTwinSVM. More-

2

LIBTwinSVM: A Library for Twin Support Vector Machines

Figure 1: The main components of the LIBTwinSVM library and their relation.

Figure 2: A sample output of visualization capabilities of LIBTwinSVM.

over, the models component of our library allows users to save the best-ﬁtted estimator on
the disk. A pre-trained estimator can also be loaded and evaluated on test samples.

3.1 Implementation

In this subsection, we give the implementation details of the LIBTwinSVM library. Our
library is mostly written in Python 3. It relies completely on open source and free Python
packages which are explained as follows. We used Numerical Python (NumPy) for linear
algebra operations (Walt et al., 2011). For model selection and evaluation, scikit-learn was
employed (Pedregosa et al., 2011). Pandas package was used for reading and processing
datasets. Moreover, the visualization capabilities of our library were implemented using
Matplotlib package (Hunter, 2007). We developed the GUI application of the library using

3

Mir, Rahbar, Nasiri

PyQT, which is a powerful and cross-platform GUI package. For saving and loading pre-
trained models, we employed Joblib1 package.

The optimizer component is the performance-critical part of the LIBTwinSVM library.
Therefore, we implemented clipDCD optimizer (Peng et al., 2014) in C++ for solving dual
optimization problems eﬃciently. As suggested by Peng et al. (2014), we used a caching
technique to store the major computations with space cost O(n). Moreover, our imple-
mentation of clipDCD optimizer uses the Armadillo (Sanderson and Curtin, 2016), which
is a fast linear algebra library for C++. Since the optimizer component is entirely writ-
ten in C++, we used Cython (Behnel et al., 2011) to generate a C++ extension module
for Python. Diﬀerent from the LightTwinSVM program, the implementation of the opti-
mizer component avoids memory copies. This improves substantially the speed and memory
consumption of the TSVM estimator. Additionally, the peak memory consumption of the
TSVM estimator is further reduced by changing the order of computation in the training
stage. The decision function of TSVM-based estimators is evaluated in parallel by using
NumPy arrays rather than a for-loop.

3.2 API

This subsection describes the design of the Python API of the LIBTwinSVM library. The
main design goal of the API is simplicity and ease of use. Therefore, API functional-
ities can be used with the basic knowledge of the Python language. TSVM and LSTSVM
Inspired by the design of
are binary TSVM-based estimators in the API of our library.
the scikit-learn package, the interface of all the estimators provides fit() and predict()
methods. Similar to the scikit-learn’s interface, the library’s estimators accept both a
Python list and NumPy arrays. For ease of use, the estimators can be initialized with
default hyper-parameters. OneVsOneClassifier and OneVsAllClassifier are multi-class
classiﬁers which implemented as meta-estimators. They take as input a binary TSVM-
based estimator. Moreover, the optimizer component provides a clipdcd.optimize()
method for solving dual QPPs. The API reference and its usage examples can be found at
https://libtwinsvm.readthedocs.io.

4. Benchmarks

In this section, we conduct an experiment to show the computational eﬃciency of LIBTwinSVM
library for large-scale datasets. The experiment was carried out on a PC with Intel Core
i7 6700K CPU, 32.0 GB of RAM, and Ubuntu 16.04.6 LTS. For this experiment, we used
David Musicant’s NDC Data Generator (Musicant, 1998) to generate binary classiﬁcation
problems with 32 features. It should be noted that the multi-core version of LIBLINEAR
(v2.30)2 is tested on NDC datasets. The hyper-parameters of the estimators were set to
default values (i.e. c1 = 1, c2 = 1). The linear kernel was also used.

Table 1 shows the comparison of LIBTwinSVM with other implementations in terms of
learning and prediction speed. The learning and prediction speed of the LIBTwinSVM’s
TSVM estimator is much faster than that of LightTwinSVM. Because we improved the

1. https://joblib.readthedocs.io/en/latest/
2. https://www.csie.ntu.edu.tw/ cjlin/libsvmtools/multicore-liblinear/

4

LIBTwinSVM: A Library for Twin Support Vector Machines

implementation of the TSVM estimator (as discussed in Subsection 3.1). For instance,
the training speed of the library’s TSVM estimator is about 6 times faster than the TSVM
estimator of LightTwinSVM on NDC-50K dataset. Thanks to the Least Squares extension of
TSVM classiﬁer, our library can handle large-scale datasets with 5 million samples whereas
LightTwinSVM is not suitable for datasets with more than 50,000 samples. Moreover, the
learning speed of LIBTwinSVM with LSTSVM classiﬁer is signiﬁcantly faster than that of
LIBLINEAR, which is a state-of-the-art implementation of linear SVM.

Acknowledgments

This research work was carried out at the Machine Learning and Text Mining Lab of IranDoc
Institution. We would like to thank the Director of the IranDoc Institution for providing
us research facilities.

Appendix A. Additional Experiments

In this section, we further analyze the eﬃciency of the LIBTwinSVM library in comparison
with other popular implementations. First, we compare the classiﬁcation performance of
the library with other implementations on benchmark datasets. Second, we analyze the
memory consumption of the LIBTwinSVM library to validate the eﬀectiveness of our im-
plementation. These two experiments were carried out on a PC with Intel Core i7 6700K
CPU, 32.0 GB of RAM, and Ubuntu 16.04.6 LTS. The version of our software and the
baseline libraries are shown in Table 2.

LIBLINEAR LIBSVM ThunderSVM LightTwinSVM LIBTwinSVM

Version

v2.30

v3.23

v0.3.3

v0.6.0

v0.3.0

Table 2: The version of our software and the baseline libraries.

A.1 Benchmark datasets

To show the classiﬁcation performance of the LIBTwinSVM library, we conducted exper-
iments on benchmark datasets from the UCI3 machine learning repository. The feature
values of all the datasets were normalized in the range [0, 1]. For multi-classiﬁcation, we
chose One-vs-One scheme as it is often used in SVM packages. The characteristics of UCI
benchmark datasets are shown in the Table 3.

The classiﬁcation performance of SVM and TSVM classiﬁers depends heavily on the
choice of hyper-parameters. The optimal value of c1 and c2 parameters was selected from
the set {2i | i = −5, −4, . . . , 5}. In this experiment, the grid search method is used to ﬁnd
the optimal values of hyper-parameters. We evaluated the classiﬁcation performance of the
classiﬁers using 5-fold cross-validation. Moreover, a linear kernel is used and the stopping
criteria of the clipDCD optimizer is set to 10−5.

Table 4 shows the accuracy comparison of LIBTwinSVM and other implementations
with a linear kernel. From the Table 4, it can be seen that the LIBTwinSVM library

3. http://archive.ics.uci.edu/ml/datasets

5

Mir, Rahbar, Nasiri

M
V
S
T
S
L

M
V
S
T

e
m

i
t

t
s
e
T

e
m

i
t

n

i
a
r
T

y
c
a
r
u
c
c
A

e
m

i
t

t
s
e
T

e
m

i
t

n
i
a
r
T

y
c
a
r
u
c
c
A

e
m

i
t

t
s
e
T

e
m

i
t

n
i
a
r
T

y
c
a
r
u
c
c
A

e
m

i
t

t
s
e
T

e
m

i
t

n
i
a
r
T

y
c
a
r
u
c
c
A

i

M
V
S
n
w
T
B
I
L

M
V
S
n
i
w
T
t
h
g
i
L

R
A
E
N
I
L
B
I
L

2
1
0
0
0
.
0

6
1
0
0
0
.
0

5
0
0
0
.
0

1
9
0
0
0
.
0

6
1
0
0
.
0

6
0
0
.
0

7
1
1
0
.
0

2
3
2
0
.
0

8
2
1
.
0

1
3
0
0
.
0

5
5
0
0
.
0

7
3
1
0
.
0

8
9
2
0
.
0

2
1
5
0
.
0

6
5
3
2
.
0

7
5
4
4
.
0

0
3
6
8
.
0

5
7
9
1
.
2

7
5
.
6
8

9
9
.
6
8

5
3
.
6
8

0
2
.
6
8

4
9
.
5
8

2
9
.
5
8

5
2
.
6
8

2
0
.
6
8

5
0
.
6
8

5
1
0
0
0
.
0

7
1
0
0
0
.
0

6
3
0
0
0
.
0

9
5
0
0
0
.
0

0
1
0
0
.
0

a

a

a

a

7
1
7
1
.
0

7
9
8
4
.
0

9
5
5
.
2

7
9
9
.
0
1

9
0
6
.
4
5

a

a

a

a

7
7
.
6
8

9
0
.
7
8

7
4
.
6
8

8
2
.
6
8

5
7
.
5
8

a

a

a

a

5
0
0
.
0

1
0
.
0

7
0
1
0
.
0

4
1
2
0
.
0

3
8
6
.
0

9
5
6
.
2

4
4
4
.
6
1

1
7
2
4
.
7
6

a

a

a

a

a

a

a

a

a

a

7
7
.
6
8

9
0
.
7
8

7
4
.
6
8

8
2
.
6
8

a

a

a

a

a

3
0
0
.
0

4
0
0
.
0

8
0
0
.
0

7
1
0
.
0

3
3
0
.
0

5
1
.
0

5
9
2
.
0

7
9
5
.
0

4
9
4
.
1

9
2
0
.
0

2
5
0
.
0

9
1
1
.
0

5
3
2
.
0

6
6
4
.
0

5
7
2
.
2

7
4
5
.
4

4
7
2
.
9

9
9
8
.
2
2

4
.
7
8

3
.
6
8

6
7
.
5
8

4
2
.
6
8

2
0
.
6
8

3
9
.
5
8

0
2
.
6
8

8
9
.
5
8

0
0
.
6
8

)
s
e
l

p
m
a
s

.
o
n
(

s
t
e
s
a
t
a
D

)
0
0
0
,
5
(
K
5
-
C
D
N

)
0
0
0
,
0
1
(
K
0
1
-
C
D
N

)
0
0
0
,
5
2
(
K
5
2
-
C
D
N

)
0
0
0
,
0
5
(
K
0
5
-
C
D
N

)
0
0
0
,
0
0
1
(

l
1
-
C
D
N

)
0
0
0
,
0
0
5
(

l
5
-
C
D
N

)
0
0
0
,
0
0
0
,
1
(

m
1
-
C
D
N

)
0
0
0
,
0
0
0
,
2
(

m
2
-
C
D
N

)
0
0
0
,
0
0
0
,
5
(

m
5
-
C
D
N

6

.
y
r
o
m
e
m

f
o

t
u
o

n
a
r

t
n
e
m

i
r
e
p
x
e

e
h
T
a

n
o
i
t
c
i
d
e
r
p
d
n
a
g
n
i
n
r
a
e
l

f
o
s

m
r
e
t
n
i

M
V
S
n
i
w
T
B
I
L
d
n
a
,

M
V
S
n
i
w
T
t
h
g
i
L

,

R
A
E
N
I
L
B
I
L
n
e
e
w
t
e
b
n
o
s
i
r
a
p
m
o
c

e
c
n
a
m
r
o
f
r
e
p
A

:
1

e
l

b
a
T

.
s
d
n
o
c
e
s

n
i

d
e
r
u
s
a
e
m
e
m

i
t

t
s
e
t

d
n
a

n
i
a
r
T

.
d
e
e
p
s

LIBTwinSVM: A Library for Twin Support Vector Machines

Datasets
Iris
Hepatitis
Monk3
Australian
Vehicle
Optdigits
Landsat
Satimage
Mushrooms
Pendigits
w3a

#Samples #Features #Class

150
155
554
690
846
1797
2000
6435
8124
10992
49749

4
19
6
14
18
64
36
36
112
16
300

3
2
2
2
4
10
6
6
2
10
2

Table 3: The characteristics of UCI benchmark datasets

outperforms popular SVM packages (i.e. LIBLINEAR , LIBSVM and ThunderSVM). For
instance, the accuracy of the LIBTwinSVM (TSVM) is about 14% higher than that of
LIBLINEAR on Satimage dataset. On the mentioned dataset, the training time of the
LIBTwinSVM (TSVM) is 5.8 times faster than that of LIBLINEAR. The accuracy advan-
tage of TSVM is due to the fundamental diﬀerence in the central idea of SVM and TSVM.
As stated previously, TSVM classiﬁer does classiﬁcation by using two non-parallel hyper-
planes. Also, note that the accuracy of LightTwinSVM and LIBTwinSVM (TSVM) is the
same. Because they use the same classiﬁer for solving a classiﬁcation task. However, the
classiﬁcation accuracy of LIBTwinSVM (LSTSVM) is slightly better than LightTwinSVM
and LIBTwinSVM (TSVM) on some datasets. Even though the central idea of LSTSVM
estimator is the same as TSVM estimator, the solution of LSTSVM estimator may be
diﬀerent for a classiﬁcation problem.

In addition to the experiment with a linear kernel, we conducted an experiment on bench-
mark datasets with RBF kernel. Table 5 shows the accuracy comparison of LIBTwinSVM
and other implementations with RBF kernel. The parameter of RBF kernel was chosen
from the set {2i | i = −15, −4, . . . , 2}. The classiﬁcation results of LIBTwinSVM with
RBF kernel is comparable or slightly better then the implementations of SVM. Moreover,
the training and prediction speed of the LIBTwinSVM (TSVM) is substantially faster than
that of LightTwinSVM. For example, the training speed of the LIBTwinSVM (TSVM)
is about 12 times faster than LightTwinSVM for Pendigits dataset. This validates the
improvements in the implementation of LIBTwinSVM library.

In summary, the results on benchmark datasets indicate that the LIBTwinSVM library

is suitable for solving real-world classiﬁcation problems.

A.2 Analysis of memory consumption

Here, we analyze the memory consumption of the LIBTwinSVM library in comparison with
other implementations. For this experiment, the NDC datasets were used. To experiment
with LIBLINEAR, LIBSVM, and ThunderSVM, their Python bindings were employed. Our
procedure for measuring the peak memory consumption is (1) we load a dataset. (2) we
train an estimator using fit() method on the entire dataset. We note that the second step
of the procedure is considered for the analysis of memory consumption. Because the fit()

7

)

M
V
S
T
S
L
(

M
V
S
n
i
w
T
B
I
L

)

M
V
S
T
(

i

M
V
S
n
w
T
B
I
L

i

M
V
S
n
w
T
t
h
g
i
L

M
V
S
r
e
d
n
u
h
T

Mir, Rahbar, Nasiri

)
s
(

e
T
/
r
T

)
2
C

,
1
C
(

3
6
.
1
±
7
6
.
8
9

2
0
0
.
0
/
5
0
0
.
0

)
2
−
2
,
1
−
2
(

5
5
.
5
±
3
2
.
3
8

1
0
0
0
.
0
/
1
1
0
0
.
0

)
3
−
2
,
5
−
2
(

6
2
.
2
±
4
7
.
5
8

1
0
0
0
.
0
/
1
0
0
.
0

)
1
−
2
,
1
2
(

0
5
.
2
±
8
6
.
7
8

6
0
0
0
0
.
0
/
4
0
0
0
.
0

)
0
2
,
4
−
2
,
3
−
2
(

0
7
.
2
±
4
7
.
0
8

3
0
.
0
/
6
0
0
.
0

)
2
−
2
,
3
−
2
(

7
6
.
0
±
6
1
.
8
9

5
2
.
0
/
3
1
.
0

)
3
−
2
,
2
−
2
(

7
8
.
0
±
0
9
.
4
8

3
1
.
0
/
4
0
.
0

)
0
2
,
1
−
2
(

4
1
.
1
±
6
6
.
5
8

9
2
.
0
/
1
2
0
.
0

)
1
2
,
0
2
(

0
0
.
0
±
0
0
.
0
0
1

1
0
0
0
.
0
/
2
1
0
.
0

)
5
−
2
,
5
−
2
(

1
4
.
0
±
3
7
.
6
9

8
2
.
1
/
7
3
0
.
0

)
0
2
,
0
2
(

6
0
.
0
±
5
5
.
8
9

1
0
0
.
0
/
5
1
.
0

)
2
−
2
,
3
−
2
(

1
9
.
0
9

)
s
(

e
T
/
r
T

)
2
C

,
1
C
(

7
6
.
2
±
0
0
.
8
9

2
0
0
.
0
/
5
0
0
.
0

)
3
−
2
,
5
−
2
(

5
4
.
6
±
5
6
.
0
8

2
0
0
0
.
0
/
7
1
0
0
.
0

)
5
−
2
,
5
−
2
(

5
7
.
2
±
0
1
.
6
8

2
0
0
0
.
0
/
2
0
0
.
0

)
0
2
,
2
2
(

0
4
.
2
±
0
1
.
7
8

2
0
0
0
.
0
/
4
0
0
.
0

)
0
2
,
5
−
2
,
3
−
2
(

6
8
.
2
±
3
3
.
1
8

3
0
.
0
/
8
0
0
.
0

)
0
2
,
2
−
2
(

8
4
.
0
±
6
1
.
7
9

4
2
.
0
/
7
0
.
0

)
5
−
2
,
4
−
2
(

9
7
.
0
±
5
7
.
4
8

3
1
.
0
/
5
0
.
0

)
0
2
,
2
−
2
(

8
8
.
0
±
5
4
.
6
8

9
2
.
0
/
8
2
.
0

)
0
2
,
1
−
2
(

0
0
.
0
±
0
0
.
0
0
1

2
0
0
0
.
0
/
7
1
.
0

)
5
−
2
,
5
−
2
(

3
5
.
0
±
6
8
.
6
9

7
2
.
1
/
3
0
.
1

)
1
−
2
,
2
−
2
(

2
1
.
0
±
1
3
.
8
9

2
0
0
.
0
/
4
2
.
3
1

)
1
−
2
,
2
−
2
(

1
6
.
0
9

)
s
(

e
T
/
r
T

)
2
C

,
1
C
(

7
6
.
2
±
0
0
.
8
9

2
0
0
.
0
/
6
0
0
.
0

)
3
−
2
,
5
−
2
(

5
4
.
6
±
5
6
.
0
8

3
0
0
0
.
0
/
6
0
0
.
0

)
5
−
2
,
5
−
2
(

5
7
.
2
±
0
1
.
6
8

9
0
0
0
.
0
/
6
1
0
.
0

)
0
2
,
2
2
(

0
4
.
2
±
0
1
.
7
8

1
0
0
.
0
/
9
2
0
.
0

)
0
2
,
5
−
2
,
3
−
2
(

6
8
.
2
±
3
3
.
1
8

2
0
.
0
/
3
0
.
0

)
0
2
,
2
−
2
(

8
4
.
0
±
6
1
.
7
9

0
2
.
0
/
6
2
.
0

)
5
−
2
,
4
−
2
(

9
7
.
0
±
5
7
.
4
8

0
1
.
0
/
6
3
.
0

)
0
2
,
2
−
2
(

8
8
.
0
±
5
4
.
6
8

2
2
.
0
/
2
7
.
1

)
0
2
,
1
−
2
(

0
0
.
0
±
0
0
.
0
0
1

4
1
0
.
0
/
4
0
.
1

)
5
−
2
,
5
−
2
(

3
5
.
0
±
6
8
.
6
9

7
9
.
0
/
4
1
.
5

)
1
−
2
,
2
−
2
(

a

1
6
.
0
9

)
s
(

e
T
/
r
T

C

M
V
S
B
I
L

)
s
(

e
T
/
r
T

C

R
A
E
N
I
L
B
I
L

)
s
(

e
T
/
r
T

C

3
0
.
0
±
7
6
.
6
9

3
0
.
0
±
7
6
.
6
9

3
0
.
0
±
3
3
.
5
9

1
0
0
0
.
0
/
5
0
0
.
0

3
0
0
0
.
0
/
1
0
0
.
0

4
0
0
0
0
.
0
/
5
0
0
.
0

1
−
2

1
−
2

2
2

s
t
e
s
a
t
a
D

s
i
r
I

3
0
.
0
±
1
7
.
8
7

3
0
.
0
±
1
7
.
8
7

2
0
.
0
±
8
5
.
2
8

s
i
t
i
t
a
p
e
H

2
0
0
0
.
0
/
7
0
0
.
0

4
0
0
0
.
0
/
3
0
0
.
0

2
0
0
0
.
0
/
8
1
0
.
0

5
−
2

5
−
2

5
2

3
0
.
0
±
4
1
.
0
8

4
0
0
0
.
0
/
6
2
0
.
0

3
0
.
0
±
4
1
.
0
8

3
0
0
.
0
/
2
0
.
0

4
0
.
0
±
8
8
.
8
7

2
0
0
0
.
0
/
3
1
0
.
0

5
−
2

5
−
2

5
2

3
0
.
0
±
1
5
.
5
8

8
0
0
0
.
0
/
6
2
0
.
0

3
0
.
0
±
1
5
.
5
8

4
0
.
0
±
1
8
.
6
8

2
0
0
.
0
/
1
0
.
0

7
0
0
0
0
.
0
/
3
2
0
.
0

4
2

4
0
.
0
±
9
7
.
9
7

1
0
0
.
0
/
5
3
.
3

4
−
2

1
0
.
0
±
5
0
.
8
9

1
0
.
0
/
7
6
.
0

5
−
2

2
0
.
0
±
5
5
.
4
8

5
1
0
.
0
/
0
2
.
7
9

5
−
2

b

b

b

b

-

5
−
2

4
2

4
0
.
0
±
9
7
.
9
7

3
0
0
.
0
/
6
7
.
0

5
0
.
0
±
2
9
.
0
7

7
0
0
0
0
.
0
/
2
1
.
0

4
−
2

1
0
.
0
±
0
0
.
8
9

2
0
.
0
/
6
0
.
0

5
−
2

2
0
.
0
±
5
5
.
4
8

1
0
.
0
/
9
3
.
0

5
−
2

b

b

b

b

-

2
−
2

1
0
.
0
±
8
8
.
5
9

1
0
0
0
.
0
/
0
1
.
0

5
−
2

6
0
.
0
±
5
5
.
6
6

1
0
0
0
.
0
/
5
4
.
0

2
2

7
0
.
0
±
3
9
.
1
7

2
0
0
.
0
/
3
6
.
1

4
−
2

0
0
.
0
±
0
0
.
0
0
1

2
0
0
0
.
0
/
1
2
0
.
0

4
−
2

1
0
.
0
±
4
4
.
8
8

4
0
0
0
.
0
/
2
5
.
1

0
2

1
0
.
0
±
7
6
.
8
9

4
0
0
.
0
/
8
7
.
0

2
2

8
0
.
5
8

n
a
i
l
a
r
t
s
u
A

3
k
n
o
M

e
l
c
i
h
e
V

s
t
i
g
i
d
t
p
O

t
a
s
d
n
a
L

8

e
g
a
m

i
t
a
S

s

m
o
o
r
h
s
u
M

s
t
i
g
i
d
n
e
P

a
3
w

y
c
a
r
u
c
c
a

n
a
e
M

d
n
a

n
i
a
r
t

r
o
f

s
d
n
a
t
s

e
T
/
r
T

.
l
e
n
r
e
k

r
a
e
n
i
l

h
t
i
w

s
n
o
i
t
a
t
n
e
m
e
l
p
m

i

r
e
h
t
o

d
n
a
M
V
S
n
i
w
T
B
I
L

f
o

n
o
s
i
r
a
p
m
o
c

y
c
a
r
u
c
c
a

e
h
T

:
4

e
l

b
a
T

.
e
m

i
t

t
s
e
t

.

h
g
i

h

y
r
e
v

s
a
w
e
m

i
t

g
n

i
t
u
p
m
o
c

e
h
t

s
a

t
n
e
m

i
r
e
p
x
e

e
h
t

d
e
m
r
o
f
r
e
p

t
o
n

e
v
a
h

e

W

b

.
y
r
o
m
e
m

f
o

t
u
o

n
a
r

t
n
e
m

i
r
e
p
x
e

e
h
T
a

)

M
V
S
T
S
L
(

M
V
S
n
i
w
T
B
I
L

)

M
V
S
T
(

i

M
V
S
n
w
T
B
I
L

i

M
V
S
n
w
T
t
h
g
i
L

M
V
S
r
e
d
n
u
h
T

LIBTwinSVM: A Library for Twin Support Vector Machines

)
s
(

e
T
/
r
T

)
σ

,
2
C

,
1
C
(

3
6
.
1
±
7
6
.
8
9

4
0
0
.
0
/
3
1
.
0

)
4
−
2
,
2
2
,
2
2
(

8
5
.
2
±
1
8
.
5
8

3
0
0
0
.
0
/
7
0
0
.
0

)
7
−
2
,
0
2
,
5
−
2
(

6
3
.
0
±
8
3
.
8
9

6
0
0
.
0
/
2
1
.
0

)
3
−
2
,
2
−
2
,
5
−
2
(

9
9
.
2
±
9
3
.
7
8

5
0
0
.
0
/
3
1
.
0

)
7
−
2
,
5
−
2
,
5
−
2
(

9
2
.
2
±
9
9
.
4
8

7
0
.
0
/
1
1
.
0

)
6
−
2
,
4
−
2
,
5
−
2
(

9
5
.
0
±
0
5
.
9
9

7
4
.
1
/
5
6
.
0

)
2
1
−
2
,
2
−
2
,
0
2
(

2
5
.
1
±
5
7
.
8
8

4
6
.
0
/
2
6
.
0

)
5
−
2
,
3
2
,
3
2
(

9
6
.
0
±
8
7
.
0
9

2
9
.
1
/
9
6
.
0

)
5
−
2
,
4
−
2
,
4
−
2
(

2
0
.
0
±
9
9
.
9
9

7
1
.
0
/
4
7
.
0

)
2
−
2
,
1
−
2
,
5
−
2
(

3
1
.
0
±
9
4
.
9
9

0
2
.
4
/
5
0
.
2

)
5
−
2
,
3
−
2
,
3
−
2
(

6
0
.
0
±
7
5
.
8
9

1
9
.
0
/
6
3
.
3

)
4
1
−
2
,
3
−
2
,
5
−
2
(

4
8
.
3
9

)
s
(

e
T
/
r
T

)
σ

,
2
C

,
1
C
(

3
6
.
1
±
0
0
.
8
9

4
0
0
.
0
/
9
2
0
.
0

)
4
−
2
,
2
−
2
,
3
−
2
(

8
5
.
2
±
1
8
.
5
8

3
0
0
0
.
0
/
9
0
0
.
0

)
3
1
−
2
,
0
2
,
4
−
2
(

2
7
.
0
±
5
6
.
7
9

2
0
0
.
0
/
0
1
.
0

)
s
(

e
T
/
r
T

)
σ

,
2
C

,
1
C
(

3
6
.
1
±
0
0
.
8
9

4
0
0
.
0
/
3
1
.
0

)
4
−
2
,
2
−
2
,
3
−
2
(

8
5
.
2
±
1
8
.
5
8

1
0
0
.
0
/
8
0
0
.
0

)
3
1
−
2
,
0
2
,
4
−
2
(

2
7
.
0
±
5
6
.
7
9

7
0
0
.
0
/
9
0
.
0

)
3
−
2
,
5
−
2
,
5
−
2
(

)
3
−
2
,
5
−
2
,
5
−
2
(

8
9
.
2
±
4
5
.
7
8

5
0
0
.
0
/
7
1
.
0

)
9
−
2
,
1
−
2
,
2
2
(

6
8
.
2
±
6
4
.
3
8

7
0
.
0
/
1
1
.
0

8
9
.
2
±
4
5
.
7
8

1
0
.
0
/
7
2
.
0

)
9
−
2
,
1
−
2
,
2
2
(

6
8
.
2
±
6
4
.
3
8

7
0
.
0
/
4
2
.
0

)
5
−
2
,
3
−
2
,
3
−
2
(

)
5
−
2
,
3
−
2
,
3
−
2
(

0
0
.
1
±
9
8
.
8
9

8
4
.
1
/
8
8
.
0

0
0
.
1
±
9
8
.
8
9

1
3
.
1
/
4
6
.
1

)
3
1
−
2
,
4
−
2
,
4
−
2
(

)
3
1
−
2
,
4
−
2
,
4
−
2
(

8
4
.
1
±
5
0
.
8
8

3
6
.
0
/
2
6
.
0

8
4
.
1
±
5
0
.
8
8

8
5
.
0
/
7
9
.
0

)
7
−
2
,
1
−
2
,
2
−
2
(

)
7
−
2
,
1
−
2
,
2
−
2
(

1
5
.
0
±
5
9
.
9
8

1
9
.
1
/
6
0
0
.
1

1
5
.
0
±
5
9
.
9
8

8
4
.
3
/
6
7
.
2
1

)
5
−
2
,
3
−
2
,
3
−
2
(

)
5
−
2
,
3
−
2
,
3
−
2
(

)
s
(

e
T
/
r
T

)
σ

,

C
(

4
0
.
0
±
7
6
.
6
9

5
0
0
0
.
0
/
1
0
.
0

)
4
−
2
,
1
2
(

3
0
.
0
±
5
4
.
6
8

2
0
0
0
.
0
/
1
0
0
.
0

)
7
−
2
,
3
2
(

2
0
.
0
±
1
1
.
7
9

4
0
0
0
.
0
/
2
1
0
.
0

)
4
−
2
,
5
2
(

3
0
.
0
±
0
1
.
7
8

4
0
.
0
/
6
3
.
0

)
4
−
2
,
4
−
2
(

4
0
.
0
±
1
5
.
2
8

2
0
0
.
0
/
4
0
.
0

)
7
−
2
,
5
2
(

0
0
.
0
±
8
2
.
9
9

5
1
0
.
0
/
3
8
.
0

)
0
1
−
2
,
1
2
(

2
0
.
0
±
0
1
.
8
8

6
0
0
.
0
/
0
3
.
0

)
7
−
2
,
4
2
(

1
0
.
0
±
9
6
.
0
9

9
0
.
0
/
1
9
.
1

)
7
−
2
,
5
2
(

M
V
S
B
I
L

)
s
(

e
T
/
r
T

)
σ

,

C
(

4
0
.
0
±
7
6
.
6
9

1
0
0
0
.
0
/
8
0
0
0
.
0

)
4
−
2
,
1
2
(

3
0
.
0
±
5
4
.
6
8

8
0
0
0
.
0
/
4
0
0
.
0

)
7
−
2
,
3
2
(

2
0
.
0
±
1
1
.
7
9

1
0
0
.
0
/
5
1
0
.
0

)
4
−
2
,
5
2
(

3
0
.
0
±
0
1
.
7
8

4
0
0
.
0
/
2
0
.
0

)
4
−
2
,
4
−
2
(

4
0
.
0
±
1
5
.
2
8

8
0
0
.
0
/
4
0
.
0

)
7
−
2
,
5
2
(

0
0
.
0
±
8
2
.
9
9

5
4
0
.
0
/
6
3
.
0

)
0
1
−
2
,
1
2
(

2
0
.
0
±
0
1
.
8
8

4
0
.
0
/
4
3
.
0

)
7
−
2
,
4
2
(

1
0
.
0
±
9
6
.
0
9

2
4
.
0
/
2
2
.
3

)
7
−
2
,
5
2
(

)
b
(

s
t
e
s
a
t
a
D

s
i
r
I

s
i
t
i
t
a
p
e
H

3
k
n
o
M

n
a
i
l
a
r
t
s
u
A

e
l
c
i
h
e
V

s
t
i
g
i
d
t
p
O

t
a
s
d
n
a
L

)
5
2
.
0
(

e
g
a
m

i
t
a
S

9

8
0
.
0
±
9
7
.
9
9

6
1
.
0
/
1
7
.
1

)
2
−
2
,
5
−
2
,
5
−
2
(

4
2
.
0
±
8
1
.
9
9

6
2
.
4
/
9
8
.
2

)
6
−
2
,
2
−
2
,
3
−
2
(

0
1
.
0
±
6
5
.
8
9

0
9
.
0
/
7
0
.
7
4

)
4
1
−
2
,
1
−
2
,
1
−
2
(

2
3
.
3
9

8
0
.
0
±
9
7
.
9
9

6
2
.
0
/
3
4
.
2

)
2
−
2
,
5
−
2
,
5
−
2
(

4
2
.
0
±
8
1
.
9
9

4
8
2
4
1
6
.
7
1
/
5
0
.
5
3

)
6
−
2
,
2
−
2
,
3
−
2
(

0
0
.
0
±
0
0
.
0
0
1

0
0
.
0
±
0
0
.
0
0
1

)
5
2
.
0
(

s

m
o
o
r
h
s
u
M

3
4
0
.
0
/
9
5
.
0

)
4
−
2
,
0
2
(

1
0
.
0
±
7
4
.
9
9

2
2
.
0
/
2
0
.
4

)
7
−
2
,
5
2
(

5
1
.
0
/
9
6
.
0

)
4
−
2
,
0
2
(

1
0
.
0
±
7
4
.
9
9

9
0
0
.
1
/
0
7
.
7

)
7
−
2
,
5
2
(

)
5
2
.
0
(

s
t
i
g
i
d
n
e
P

a

-

8
2
.
1
/
9
3
.
0
2

)
0
1
−
2
,
3
2
(

9
2
.
3
9

7
8
.
1
/
3
1
.
9

)
0
1
−
2
,
3
2
(

9
2
.
3
9

y
c
a
r
u
c
c
a

n
a
e
M

1
0
.
0
±
0
9
.
8
9

1
0
.
0
±
0
9
.
8
9

)
5
0
.
0
(

a
3
w

.

i

M
V
S
n
w
T
B
I
L

d
n
a
M
V
S
n
w
T
t
h
g
i
L

i

r
o
f

l
e
n
r
e
k

r
a
l
u
g
n
a
t
c
e
r

e
h
t

f
o

e
u
l
a
v

.
y
r
o
m
e
m

f
o

t
u
o

n
a
r

t
n
e
m

i
r
e
p
x
e

e
h
T
a

e
h
T
b

l
e
n
r
e
k

F
B
R
h
t
i
w
s
n
o
i
t
a
t
n
e
m
e
l
p
m

i

r
e
h
t
o

d
n
a
M
V
S
n
i
w
T
B
I
L

f
o

n
o
s
i
r
a
p
m
o
c

y
c
a
r
u
c
c
a

e
h
T

:
5

e
l
b
a
T

Mir, Rahbar, Nasiri

LIBLINEAR LIBSVM ThunderSVM LightTwinSVM LIBTwinSVM (TSVM) LIBTwinSVM (LSTSVM)

135.85
164.625
218.71
308.75
b

Datasets
NDC-5K (5,000)
NDC-10K (10,000)
NDC-25K (25,000)
NDC-50K (50,000)
NDC-1l (100,000)
NDC-5l (500,000)
NDC-1m (1,000,000)
NDC-2m (2,000,000)
NDC-5m (5,000,000)
a The experiment ran out of memory.
b We have not performed the experiment as the computing time was very high.

47.09
64.33
117.83
206.86
384.34
1799.64
3571.56
7122.47
17727.84

170.41
392.96
1934.89
7387.24
29242.50
a

137.57
189.07
340.5
593.37
1097.46
b

343.20
982.62
6254.75
24659.29
a

b

b

b

b

b

b

b

a

a

a

a

a

a

a

96.51
102.03
117.66
141.80
191.87
591.40
1143.37
2193.11
5110.21

Table 6: The peak memory consumption of the LIBTwinSVM library and other implemen-

tations. The reported numbers are in megabytes.

method is the most resource-intensive part in the code. We used the Linux time command
to report the peak memory usage.

Table 6 shows the peak memory consumption of the LIBTwinSVM library and other im-
plementations with linear kernel4. Thanks to the improvements in the implementation of the
LIBTwinSVM, the memory consumption of the LIBTwinSVM estimators is much lower than
that of the LightTwinSVM program. However, the memory usage of the LIBTwinSVM’s
TSVM estimator is higher than the implementations of SVM. This is because TSVM needs
to store two matrices of size m1 × m1 and m2 × m2 in order to solve two dual optimization
problems (where m1 + m2 = m and m denotes the number of samples.). On the other
hand, the memory usage of the LIBTwinSVM’s LSTSVM estimator is signiﬁcantly lower
than LIBLINEAR for 50K samples and more.

References

Stefan Behnel, Robert Bradshaw, Craig Citro, Lisandro Dalcin, Dag Sverre Seljebotn, and
Kurt Smith. Cython: The best of both worlds. Computing in Science and Engineering,
13(2):31–39, 2011. ISSN 1521-9615.

Chih-Chung Chang and Chih-Jen Lin. Libsvm: A library for support vector machines.

ACM transactions on intelligent systems and technology (TIST), 2(3):27, 2011.

Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin. Lib-
linear: A library for large linear classiﬁcation. Journal of machine learning research, 9
(Aug):1871–1874, 2008.

J. D. Hunter. Matplotlib: A 2d graphics environment. Computing in Science Engineering,

9(3):90–95, May 2007.

Jayadeva, R Khemchandani, and Suresh Chandra. Twin support vector machines for pattern
classiﬁcation. IEEE Transactions on pattern analysis and machine intelligence, 29(5),
2007.

4. RBF kernel is computationally expensive and its memory usage is quite high. Therefore, we analyzed

the memory consumption with linear kernel.

10

LIBTwinSVM: A Library for Twin Support Vector Machines

M Arun Kumar and Madan Gopal. Least squares twin support vector machines for pattern
classiﬁcation. Expert Systems with Applications, 36(4):7535–7543, 2009. ISSN 0957-4174.

Amir M. Mir and Jalal A. Nasiri. Lighttwinsvm: A simple and fast implementation of
standard twin support vector machine classiﬁer. Journal of Open Source Software, 4:
1252, 2019. doi: 10.21105/joss.01252. URL https://doi.org/10.21105/joss.01252.

DR Musicant. Ndc: normally distributed clustered datasets. Computer Sciences Depart-

ment, University of Wisconsin, Madison, 1998.

Fabian Pedregosa, Gal Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion,
Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, and Vincent Dubourg.
Scikit-learn: Machine learning in python. Journal of machine learning research, 12(Oct):
2825–2830, 2011.

Xinjun Peng, Dongjing Chen, and Lingyan Kong. A clipping dual coordinate descent
algorithm for solving support vector machines. Knowledge-Based Systems, 71:266–278,
2014. ISSN 0950-7051.

Conrad Sanderson and Ryan R. Curtin. Armadillo: a template-based c++ library for linear

algebra. J. Open Source Software, 1:26, 2016.

Stfan van der Walt, S Chris Colbert, and Gael Varoquaux. The numpy array: a structure
for eﬃcient numerical computation. Computing in Science and Engineering, 13(2):22–30,
2011. ISSN 1521-9615.

Zeyi Wen, Jiashuai Shi, Qinbin Li, Bingsheng He, and Jian Chen. Thundersvm: A fast svm
library on gpus and cpus. The Journal of Machine Learning Research, 19(1):797–801,
2018.

11

