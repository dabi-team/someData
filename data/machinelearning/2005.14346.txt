Consistent Second-Order Conic Integer Programming for
Learning Bayesian Networks

Simge K¨u¸c¨ukyavuz∗†

Ali Shojaie† ‡

Hasan Manzour§

Linchuan Wei¶

Hao-Hsiang Wu ‖

May 10, 2022

Abstract

Bayesian Networks (BNs) represent conditional probability relations among a set of random
variables (nodes) in the form of a directed acyclic graph (DAG), and have found diverse appli-
cations in knowledge discovery. We study the problem of learning the sparse DAG structure
of a BN from continuous observational data. The central problem can be modeled as a mixed-
integer program with an objective function composed of a convex quadratic loss function and a
regularization penalty subject to linear constraints. The optimal solution to this mathematical
program is known to have desirable statistical properties under certain conditions. However,
the state-of-the-art optimization solvers are not able to obtain provably optimal solutions to the
existing mathematical formulations for medium-size problems within reasonable computational
times. To address this diﬃculty, we tackle the problem from both computational and statistical
perspectives. On the one hand, we propose a concrete early stopping criterion to terminate
the branch-and-bound process in order to obtain a near-optimal solution to the mixed-integer
program, and establish the consistency of this approximate solution. On the other hand, we
improve the existing formulations by replacing the linear “big-M ” constraints that represent
the relationship between the continuous and binary indicator variables with second-order conic
constraints. Our numerical results demonstrate the eﬀectiveness of the proposed approaches.
Keywords: Mixed-integer conic programming, Bayesian networks, directed acyclic graphs,

early stopping criterion, consistency.

1

Introduction

A Bayesian network (BN) is a probabilistic graphical model consisting of a labeled directed acyclic
graph (DAG) G = (V, E), in which the vertex set V = {V1, . . . , Vm} corresponds to m random
variables, and the edge set E prescribes a decomposition of the joint probability distribution of

∗Department

of

Industrial

Engineering

and Management

Sciences,

Northwestern University

2
2
0
2

y
a
M
6

]

C
O
.
h
t
a
m

[

3
v
6
4
3
4
1
.
5
0
0
2
:
v
i
X
r
a

(simge@northwestern.edu).

†These authors contributed equally to this work.
‡Department of Biostatistics, University of Washington (ashojaie@uw.edu).
§Department of Industrial and Systems Engineering, University of Washington (hmanzour@uw.edu).
¶Department of

Industrial Engineering and Management Sciences, Northwestern University (Linchuan-

Wei2022@u.northwestern.edu).

‖Department of Management Science, National Yang Ming Chiao Tung University (hhwu2@nycu.edu.tw).

1

 
 
 
 
 
 
the random variables based on their parents in G. The edge set E encodes Markov relations on
the nodes in the sense that each node is conditionally independent of its non-descendents given its
parents. BNs have been used in knowledge discovery [49, 9], classiﬁcation [1], feature selection [22],
latent variable discovery [29] and genetics [37]. They also play a vital part in causal inference [40].
In this paper, we propose reformulations of the mixed-integer quadratic programs (MIQP) for
learning the optimal DAG structure of BNs given n continuous observations from a system of linear
structural equation models (SEMs). While there exist exact integer-programming (IP) formulations
for learning DAG structure with discrete data [11, 12, 27, 50, 4, 34, 35, 5, 13, 14], the development
of tailored computational tools for learning the optimal DAG structure from continuous data has
received less attention. In principle, exact methods developed for discrete data can be applied to
continuous data. However, such methods result in exponentially sized formulations in terms of the
number of binary variables. A common practice to circumvent the exponential number of binary
variables is to limit the in-degree of each node [12, 14, 5]. But, this may result in sub-optimal
solutions. On the contrary, MIQP formulations for learning DAGs corresponding to linear SEMs
require a polynomial number of binary variables. This is because for BNs with linear SEMs, the
score function — i.e., the penalized negative log-likelihood (PNL) — can be explicitly written as
a function of the coeﬃcients of linear SEMs [45, 52, 38, 32]. In contrast to the existing MIQPs
[38, 32], our reformulations exploit the convex quadratic objective and the relationship between the
continuous and binary variables to improve the strength of the continuous relaxations.

Continuous BNs with linear SEMs have witnessed a growing interest in the statistics and com-
puter science communities [52, 43, 31, 23, 47]. In particular, it has been shown that the solution
obtained from solving the PNL augmented by (cid:96)0 regularization, which introduces a penalty on
the number of non-zero arc weights in the estimated DAG, achieves desirable statistical properties
[41, 52, 31]. Moreover, if the model is identiﬁable [41, 31], that is when the true causal graph can
be identiﬁed from the joint distribution, then such a solution is guaranteed to uncover the true
causal DAG when the sample size n is large enough. However, given the diﬃculty of obtaining
exact solutions, existing approaches for learning DAGs from linear SEMs have primarily relied on
heuristics, using techniques such as coordinate descent [21, 2, 26] and non-convex continuous opti-
mization [61]. Unfortunately, these heuristics are not guaranteed to achieve the desirable properties
of the global optimal solution. Moreover, it is diﬃcult to evaluate the statistical properties of a sub-
optimal solution with no optimality guarantees [28]. To bridge this gap, in this paper we develop
mathematical formulations for learning optimal BNs from linear SEMs using a PNL objective with
(cid:96)0 regularization. By connecting the optimality gap of the mixed-integer program to the statistical
properties of the solution, we also establish an early stopping criterion under which we can termi-
nate the branch-and-bound procedure and attain a solution which asymptotically recovers the true
parameters with high probability.

Our work is related to recent eﬀorts to develop exact tailored methods for DAG learning from
continuous data. [57] show that A∗-lasso algorithm tailored for DAG structure learning from con-
tinuous data with (cid:96)1-regularization, which introduces a penalty on the sum of absolute values of the
arc weights, is more eﬀective than the previous approaches based on dynamic programming [e.g.,
46] that are suitable for both discrete and continuous data. [38] develop a mathematical program
for DAG structure learning with (cid:96)1 regularization. [32] improve and extend the formulation by [38]
for DAG learning from continuous data with both (cid:96)0 and (cid:96)1 regularizations. The numerical experi-
ments by [32] demonstrate that as the number of nodes grows, their MIQP formulation outperforms
A∗-lasso and the existing IP methods; this improvement is both in terms of reducing the IP opti-
mality gap, when the algorithm is stopped due to a time limit, and in terms of computational time,

2

when the instances can be solved to optimality. In light of these recent eﬀorts, the current paper
makes important contributions to this problem at the intersection of statistics and optimization.

• The statistical properties of optimal PNL with (cid:96)0 regularization have been studied extensively
[31, 52]. However, it is often diﬃcult to obtain an optimal solution and no results have been
established on the statistical properties of approximate solutions. In this paper, we give an
early stopping criterion for the branch-and-bound process under which the approximate solu-
tion gives consistent estimates of the true coeﬃcients of the linear SEM. Our result leverages
the statistical consistency of the PNL estimate with (cid:96)0 regularization [52, 41] along with the
properties of the branch-and-bound method wherein both lower and upper bound values on
the objective function are available at each iteration. By connecting these two properties, we
obtain a concrete early stopping criterion, as well as a proof of consistency of the approximate
solution. To the best of our knowledge, this result is the ﬁrst of its kind for DAG learning.

• In spite of recent progress, a key challenge in learning DAGs from linear SEMs is enforcing
bounds on arc weights. This is commonly modeled using the standard “big-M constraint”
approach [38, 32]. As shown by [32], this strategy leads to poor continuous relaxations for
the problem, which in turn results in slow lower bound improvement in the branch-and-
bound tree.
In particular, [32] establish that all existing big-M formulations achieve the
same continuous relaxation objective function under a mild condition (see Proposition 4).
To circumvent this issue, we present a mixed-integer second-order cone program (MISOCP),
which gives a tighter continuous relaxation than existing big-M formulations under certain
conditions discussed in detail in Section 5.3. This formulation can be solved by powerful
state-of-the-art optimization packages. Our numerical results show the superior performance
of MISOCP compared to the existing big-M formulations in terms of improving the lower
bound and reducing the optimality gap. We also compare our method against the state-
of-the-art benchmarks [9, 24] both for identiﬁable and non-identiﬁable instances, and show
that our method provides the best estimation among all methods in most of the networks,
especially for the non-identiﬁable cases.

The rest of the paper is organized as follows. In Section 2, we deﬁne the DAG structure learning
problem corresponding to linear SEMs, and give a general framework for the problem. In Section 3,
we present our early stopping criterion and establish the asymptotic properties of the solution
obtained under this stopping rule. We review existing mathematical formulations in Section 4, and
present our proposed mathematical formulations in Section 5. Results of comprehensive numerical
studies are presented in Section 6. We end the paper with a summary in Section 7.

2 Problem setup: Penalized DAG estimation with linear

SEMs

Let M = (V, E) be an undirected and possibly cyclic super-structure graph with node set V =
−→
{1, 2, . . . , m} and edge set E ⊆ V × V ; let
E ) be the corresponding bi-directional graph
−→
with
E = {(j, k), (k, j)|(j, k) ∈ E}. We refer to undirected edges as edges and directed edges as
arcs.

−→
M = (V,

3

We assume that causal eﬀects of continuous random variables in a DAG G0 are represented by

m linear regressions of the form

Xk =

(cid:88)

j∈paG0
k

βjkXj + (cid:15)k,

k = 1, . . . , m,

(1)

where Xk is the random variable associated with node k, paG0
k represents the parents of node k in G0,
i.e., the set of nodes with arcs pointing to k; the latent random variable (cid:15)k denotes the unexplained
variation in node k; and BN parameter βjk speciﬁes the eﬀect of node j on k for j ∈ paG0
k . The
above model is known as a linear SEM [40].

Let X = (X1, . . . , Xm) be the n × m data matrix with n rows representing i.i.d. samples from
each random variable, and m columns representing random variables X1, . . . , Xm. The linear SEM
(1) can be compactly written in matrix form as X = X B + E, where B = [β] ∈ Rm×m is a matrix
with βkk = 0 for k = 1, . . . , m, βjk = 0 for all (j, k) /∈ E, and E is the n × m ‘noise’ matrix. Then,
G(B) denotes the directed graph on m nodes such that arc (j, k) appears in G(B) if and only if
βjk (cid:54)= 0. Throughout the paper, we will use B and β to denote the matrix of coeﬃcients and its
vectorized version.

A key challenge when estimating DAGs by minimizing the loss function (2) is that the true
DAG is generally not identiﬁable from observational data. However, for certain SEM distributions,
the true DAG is identiﬁable from observational data; that is when the true causal graph can be
identiﬁed from the joint distribution. Two important examples are linear SEMs with possibly non-
Gaussian homoscedastic noise variables [41], as well as linear SEMs with unequal noise variances
that are known up to a constant [31]. In these special cases, the true DAG can be identiﬁed from
observational data, without requiring the (strong) ‘faithfulness’ assumption, which is known to be
restrictive in high dimensions [51, 48]. Given these important implications, in this paper we focus
on learning Bayesian networks corresponding to the above identiﬁable linear SEMs, i.e., settings
where the error variances are either equal, or known up to a constant.

The negative log likelihood for an identiﬁable linear SEM (1) with equal noise variances is

proportional to

l(β; X ) = n tr

(cid:110)

(I − B)(I − B)(cid:62) (cid:98)Σ

(cid:111)

;

(2)

here (cid:98)Σ = n−1X (cid:62)X is the empirical covariance matrix, and I is the identity matrix [45, 52].

To learn sparse DAGs, van de Geer and B¨uhlmann [52] propose to augment the negative log
likelihood with an (cid:96)0 regularization term. Given a super-structure M, the optimization problem
corresponding to this penalized negative log-likelihood (PNLM) is given by

PNLM min

B∈Rm×m

L(β) := l(β; X ) + λn(cid:107)β(cid:107)0

s.t. G(B) induces a DAG from

−→
M,

(3a)

(3b)

where the tuning parameter λn controls the degree of the (cid:96)0 regularization

(cid:107)β(cid:107)0 :=

(cid:88)

1(βjk),

(j,k)∈

−→
E

where 1(βjk) is an indicator function with value one if βjk (cid:54)= 0, and 0 otherwise. The constraint (3b)
−→
M. When M corresponds
stipulates that the resulting directed subgraph is a DAG induced from
to a complete graph, PNLM reduces to the original PNL of van de Geer and B¨uhlmann [52].

4

The choice of (cid:96)0 regularization in (3) is deliberate. Although (cid:96)1 regularization has attractive
computational and statistical properties in high-dimensional regression [8], many of these advan-
tages disappear in the context of DAG structure learning [21, 2]. By considering (cid:96)0 regularization,
[52] establish the consistency of PNL under appropriate assumptions. More speciﬁcally, for a Gaus-
sian SEM, they show that the estimated DAG has (asymptotically) the same number of edges as the
DAG with minimal number of edges (minimal-edge I-MAP), and establish the consistency of PNL
for learning sparse DAGs. These results are formally stated in Proposition 1 in the next section.
Remark 1. A Tikhonov ((cid:96)2) regularization term, µ(cid:107)β(cid:107)2
the objective (3a) to obtain more stable solutions [7].

2, for a given µ > 0, can also be added to

In our earlier work [32], we observe that existing mathematical formulations are slow to converge
to a provably optimal solution, β(cid:63), of (3) using the state-of-the-art optimization solvers. Therefore,
the solution process needs to be terminated early to yield a feasible solution, ˆβ with a positive
optimality gap, i.e., a positive diﬀerence between the upper bound on L(β(cid:63)) provided by L( ˆβ) and a
lower bound on L(β(cid:63)) provided by the best continuous relaxation obtained by the branch-and-bound
algorithm upon termination. However, statistical properties of such a sub-optimal solution are not
well-understood. Therefore, there exists a gap between theory and computation: while the optimal
solution has nice statistical properties, the properties of the solutions obtained from approximate
computational algorithms are not known. Moreover, due to the non-convex and complex nature
of the problem, characterizing the properties of the solutions provided by heuristics is especially
challenging. In the next section, we bridge this gap by developing a concrete early stopping criterion
and establishing the consistency of the solution obtained using this criterion.

3 Early stopping criterion for DAG learning

In this section, we establish a suﬃcient condition for the approximate solution of PNLM, ˆβ to
2 = O (cid:0)s0 log(m)/n(cid:1), where s0 is the
be consistent for the true coeﬃcients, β0; that is (cid:107)β0 − ˆβ(cid:107)2
number of arcs in the true DAG, and x (cid:16) y means that x converges to y asymptotically. This
result is obtained by leveraging an important property of the branch-and-bound process for integer
programming that provides both lower and upper bounds on the objective function L(β(cid:63)) upon
early stopping, as well as the consistency results of the PNL estimate with (cid:96)0 regularization. Using
the insight from this new result, we then propose a concrete stopping criterion for terminating the
branch-and-bound process that results in consistent parameter estimates.

Let LB and UB, respectively, denote the lower and upper bounds on the optimal objective
function value (3a) obtained from solving (3) under an early stopping criterion (i.e., when the
obtained solution is not necessarily optimal). We deﬁne the diﬀerence between the upper and lower
bounds as the absolute optimality gap: GAP = UB − LB. Let ˆG and ˆβ denote the structure of the
DAG and coeﬃcients of the arcs from optimization model (3) under the early stopping condition
with sample size n and regularization parameter λn. Let G(cid:63) and β(cid:63) denote the DAG structure and
coeﬃcients of arcs obtained from the optimal solution of (3), and G0 and β0 denote the true DAG
structure and the coeﬃcient of arcs, respectively. We denote the number of arcs in ˆG, G0, and G(cid:63)
by ˆs, s0, and s(cid:63), respectively. The score value in (3a) of each solution is denoted by L(φ) where
φ ∈ {β(cid:63), ˆβ, β0}.

Next, we present our main result. Our result extends van de Geer and B¨uhlmann’s result
on consistency of PNLM for the optimal, but computationally unattainable, estimator, β(cid:63) to an
approximate estimator, ˆβ, obtained from early stopping. In the following (including the statement

5

of our main result, Proposition 2), we assume that the super-structure M is known a priori. The
setting where M is estimated from data is discussed at the end of the section. We begin by stating
the key result from [52] and the required assumptions. Throughout, we consider a Gaussian linear
SEM of the form (1). We denote the variance of error terms, (cid:15)j, by σ2
jj and the true covariance
matrix of the set of random variables, (X1, . . . , Xm) by the m × m matrix Σ.

Assumption 1. Suppose m < c0n/ log(n) for some constant c0 > 0 and for some constant σ2
holds that maxj=1,...,m σ2
κmax(Σ), satisfy

0, it
0. Moreover, the smallest and largest eigenvalues of Σ, κmin(Σ) and

jj ≤ σ2

(cid:18) c0

(cid:19)1/2

< κ ≤ κmin(Σ) < κmax(Σ) ≤ κ < ∞

for constants κ and κ.

log(n)

Assumption 2. Let, as in [52], (cid:101)Ω(π) be the precision matrix of the vector of noise variables for
an SEM given permutation π of nodes. Denoting the diagonal entries of this matrix by ˜ωjj, there
exists a constant ω0 > 0 such that if (cid:101)Ω(π) is not a multiple of the identity matrix, then

m−1

m
(cid:88)

j=1

(cid:0)(˜ωjj)2 − 1(cid:1)2

> 1/ω0.

Proposition 1. (Theorem 5.1 in [52]) Suppose Assumptions 1 and 2 hold and let α0 := min{ 4
Then for an (cid:96)0 regularization parameter λ (cid:16) log(m)/n, it holds with probability at least 1 − α0
that

m , 0.05}.

(cid:107)β(cid:63) − β0(cid:107)2

2 + λs(cid:63) = O (cid:0)λs0(cid:1) .

Here, λ = λn/n, because the loss function (2) is that of [52] scaled by the sample size n. The
next result establishes the consistency of the approximate estimator, ˆβ, obtained using our proposed
early stopping strategy.

Proposition 2. Suppose Assumptions 1 and 2 hold and let α0 = min{ 4
m , 0.05} and λ (cid:16) log(m)/n.
Then, the estimator ˆβ obtained from early stopping of the branch-and-bound process such that
GAP (cid:16) O (cid:0)nλs0(cid:1) = O (cid:0)log(m)s0(cid:1) satisﬁes

ˆβ − β0(cid:13)
(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
2

(cid:16) O

(cid:18) log(m)
n

(cid:19)

s0

with probability (1 − α0).

Proof. First, by the triangle inequality and the fact that 2ab ≤ a2 + b2, ∀a, b ∈ R,

(cid:107) ˆβ − β0(cid:107)2

2 ≤

(cid:16)

(cid:107) ˆβ − β(cid:63)(cid:107)2 + (cid:107)β(cid:63) − β0(cid:107)2

(cid:17)2

= (cid:107) ˆβ − β(cid:63)(cid:107)2
≤ 2(cid:107) ˆβ − β(cid:63)(cid:107)2

2 + (cid:107)β(cid:63) − β0(cid:107)2
2 + 2(cid:107)β(cid:63) − β0(cid:107)2
2.

2 + 2(cid:107) ˆβ − β(cid:63)(cid:107)2(cid:107)β(cid:63) − β0(cid:107)2

(4)

Recall that β denotes the vectorized coeﬃcient matrix B. Then, in a slight abuse of notation,
we denote by X both the vectorized and a block diagonal version of X and by E a vectorized version

6

of error E. Then (cid:96)(β; X ) can be written as (cid:96)(β; X ) = (cid:107)X − X β(cid:107)2
(cid:16) ˆβ; X
a Taylor series expansion of (cid:96)

around (cid:96) (β(cid:63); X ) to get

(cid:17)

2 (see Eq. 1). Then, we can write

(cid:107)X ( ˆβ − β(cid:63))(cid:107)2

2 = (cid:96)( ˆβ; X ) − (cid:96)(β(cid:63); X ) − 2( ˆβ − β(cid:63))(cid:62)X (cid:62)X (β(cid:63) − β0) + 2( ˆβ − β(cid:63))(cid:62)X (cid:62)E.

(5)

But, Proposition 2.1 in [53] states that for every 0 < ξ < 1,

(cid:13)
(cid:13)
(cid:13)(cid:98)Σ − Σ

(cid:13)
(cid:13)
(cid:13)2

≤

(cid:16) m
n

(cid:17)1/2

,

(6)

with probability 1 − ξ. Thus, letting ξ = α0, (6) holds in our setting with probability 1 − α0.

Since, by Assumption 1, κmin(Σ) ≥ κ > c0

log(n) , by Weyl’s theorem we have

κmin(X (cid:62)X ) = nκmin

(cid:16)

(cid:17)

(cid:98)Σ

> nκ − (mn)1/2 > nκ − n

(cid:18) c0

(cid:19)1/2

log(n)

(cid:32)

= n

κ −

(cid:18) c0

log(n)

(cid:19)1/2(cid:33)

,

which means that κmin(X (cid:62)X ) > 0 with probability 1 − α0.

Denoting c(cid:48)

n ≡

(cid:18)

κ −

(cid:16) c0

log(n)

(cid:17)1/2(cid:19)−1

, for large enough n, we have that, with probability 1 − α0,

(7)

(8)

Combining (5) and (7), and using triangle inequality again, we get

(cid:107) ˆβ − β(cid:63)(cid:107)2

2 ≤ n−1c(cid:48)

n(cid:107)X ( ˆβ − β(cid:63))(cid:107)2
2.

(cid:107) ˆβ−β(cid:63)(cid:107)2

2 ≤ n−1c(cid:48)
(cid:16)

n(cid:107)X ( ˆβ − β(cid:63))(cid:107)2

2

=n−1c(cid:48)
n

≤n−1c(cid:48)
n

≤n−1c(cid:48)
n

≤n−1c(cid:48)
n

(cid:96)( ˆβ; X ) − (cid:96)(β(cid:63); X ) − 2( ˆβ − β(cid:63))(cid:62)X (cid:62)X (β(cid:63) − β0) + 2( ˆβ − β(cid:63))(cid:62)X (cid:62)E
(cid:12)
(cid:12)
(cid:12)(cid:96)( ˆβ; X ) − (cid:96)(β(cid:63); X ) − 2( ˆβ − β(cid:63))(cid:62)X (cid:62)X (β(cid:63) − β0) + 2( ˆβ − β(cid:63))(cid:62)X (cid:62)E
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)(cid:96)( ˆβ; X ) − (cid:96)(β(cid:63); X )
(cid:12)( ˆβ − β(cid:63))(cid:62)X (cid:62)E
(cid:12)
(cid:12)
(cid:12)
(cid:12)(cid:96)( ˆβ; X ) − (cid:96)(β(cid:63); X )
(cid:12)

nκmax(X (cid:62)X )(cid:107) ˆβ − β(cid:63)(cid:107)2(cid:107)β(cid:63) − β0(cid:107)2 + 2n−1c(cid:48)

n( ˆβ − β(cid:63))(cid:62)X (cid:62)X (β(cid:63) − β0) + 2n−1c(cid:48)

(cid:12)
(cid:12) + 2n−1c(cid:48)
(cid:12)
(cid:12)
(cid:12) + 2n−1c(cid:48)
(cid:12)

n

(cid:12)
(cid:12)
(cid:12)
n(cid:107) ˆβ − β(cid:63)(cid:107)2(cid:107)X (cid:62)E(cid:107)2,

(cid:17)

where, as before, κmax denotes the maximum eigenvalue of the matrix.

Using a similar argument as the one used above for the minimum eigenvalue of X (cid:62)X , by (6) we

have that, with probability 1 − α0,

κmax(X (cid:62)X ) = nκmax

(cid:16)

(cid:17)

(cid:98)Σ

≤ nκmax(Σ) + n

(cid:18) c0

(cid:19)1/2

log(n)

(cid:32)

≤ n

κ +

(cid:18) c0

log(n)

(cid:19)1/2(cid:33)

.

Plugging the above bound into (8) we get

(cid:107) ˆβ − β(cid:63)(cid:107)2

2 ≤ n−1c(cid:48)
n
(cid:32)

(cid:12)
(cid:12)(cid:96)( ˆβ; X ) − (cid:96)(β(cid:63); X )
(cid:12)
(cid:19)1/2(cid:33)

(cid:18) c0

+ 2c(cid:48)
n

κ +

log(n)

(cid:12)
(cid:12)
(cid:12)

(9)

(cid:107) ˆβ − β(cid:63)(cid:107)2(cid:107)β(cid:63) − β0(cid:107)2 + 2n−1c(cid:48)

n(cid:107) ˆβ − β(cid:63)(cid:107)2(cid:107)X (cid:62)E(cid:107)2.

7

(cid:20)(cid:18)

(cid:17)1/2(cid:19)

Now, let Z =

ˆβ − β(cid:63)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)2
(cid:13)
(cid:12)
(cid:12)
(cid:12) . Then, the inequality in (9) can be written as Z 2 ≤ ΠZ + Γ. Solving
n−1c(cid:48)
n
for Z and noting that Z, Γ and Π are non-negative, in order to have Z 2 ≤ ΠZ + Γ, we must have
Z ≤ (cid:0)Π +

(cid:12)
(cid:12)(cid:96)( ˆβ; X ) − (cid:96)(β(cid:63); X )
(cid:12)

(cid:107)β(cid:63) − β0(cid:107)2 + n−1(cid:107)X (cid:62)E(cid:107)2

Π2 + 4Γ (cid:1) /2.

, Π = 2c(cid:48)
n

, and Γ =

(cid:16) c0

κ +

log(n)

√

(cid:21)

(cid:16)

o(1) + (cid:112)o(1) + 4Γ

(cid:17)

/2,

Next, let T be the event under which Π = o(1). Then, on this set, we have Z ≤

or, Z 2 ≤ Γ + o(1); that is

ˆβ − β(cid:63)(cid:13)
(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
2

≤ n−1c(cid:48)
n

(cid:12)
(cid:12)
(cid:12)(cid:96)( ˆβ; X ) − (cid:96)(β(cid:63); X )
(cid:12)
(cid:12)
(cid:12) + o(1).

Plugging (10) into (4), on the set T we have

(10)

(11)

(cid:107) ˆβ − β0(cid:107)2

(cid:12)
(cid:12)(cid:96)( ˆβ; X ) − (cid:96)(β(cid:63); X )
2 ≤ 2n−1c(cid:48)
(cid:12)
n
(cid:12)
(cid:12)
(cid:12)(cid:96)( ˆβ; X ) − (cid:96)(β(cid:63); X ) + (λˆs − λs(cid:63)) − (λˆs − λs(cid:63))
(cid:12) + 2(cid:107)β(cid:63) − β0(cid:107)2
(cid:12)
(cid:12)
(cid:12)(cid:96)( ˆβ; X ) − (cid:96)(β(cid:63); X ) + λˆs − λs(cid:63)(cid:12)
(cid:12)
n |λˆs − λs(cid:63)| + 2(cid:107)β(cid:63) − β0(cid:107)2
(cid:12)

(cid:12)
(cid:12) + 2(cid:107)β(cid:63) − β0(cid:107)2
(cid:12)

(cid:12) + 2n−1c(cid:48)
(cid:12)

= 2n−1c(cid:48)
n

≤ 2n−1c(cid:48)
n

2 + o(1)

2 + o(1)

2 + o(1).

Then, using the fact that (cid:96)( ˆβ; X ) − (cid:96)(β(cid:63); X ) + λˆs − λs(cid:63) = L( ˆβ) − L(β(cid:63)) ≤ GAP we can write

(11) as

(cid:107) ˆβ − β0(cid:107)2

(cid:12)
(cid:12)
(cid:12)L( ˆβ; X ) − L(β(cid:63); X )
(cid:12) + 2n−1c(cid:48)
2 ≤ 2n−1c(cid:48)
(cid:12)
(cid:12)
n
2 + 2n−1c(cid:48)
nGAP + 2(cid:107)β(cid:63) − β0(cid:107)2
≤ 2n−1c(cid:48)

nλs(cid:63) + 2(cid:107)β(cid:63) − β0(cid:107)2
nλs(cid:63) + o(1),

2 + o(1),

(12)

where, in the ﬁrst inequality, we also use the fact that the penalized estimation procedure chooses
at most n nonzero entries. Hence, since m < n by Assumption 1,

2n−1c(cid:48)

n |λˆs − λs(cid:63)| ≤ 2n−1c(cid:48)

nλs(cid:63) + 2c(cid:48)

nλ = 2n−1c(cid:48)

nλs(cid:63) + O

(cid:19)

(cid:18) log(m)
n

= 2n−1c(cid:48)

nλs(cid:63) + o(1).

2 = O (cid:0)s0 log(m)/n(cid:1),
Now, by Proposition 1, we know that with probability at least 1−α0, (cid:107)β(cid:63)−β0(cid:107)2
and λs(cid:63) = O (cid:0)s0 log(m)/n(cid:1). Moreover, using Gaussian concentration inequalities for n−1(cid:107)X (cid:62)E(cid:107)2
[e.g., Lemma 6.2 in 8], the probability of the set T is lower bounded by the probability that
2 = O (cid:0)s0 log(m)/n(cid:1), which is 1 − α0. Thus, if we stop the branch-and-bound algorithm
(cid:107)β(cid:63) − β0(cid:107)2
when

GAP = O (cid:0)nλs0(cid:1) = O (cid:0)log(m)s0(cid:1) ,
then the ﬁrst two terms in (12) would both be of order O (cid:0)s0 log(m)/n(cid:1), while the third term,
nλs(cid:63) would be of a smaller order (by an n−1 factor). This guarantees that, with probability
2n−1c(cid:48)
at least (1 − α0), (cid:107) ˆβ − β0(cid:107)2

2 = O (cid:0)s0 log(m)/n(cid:1), as desired.

Proposition 2 suggests that the branch-and-bound algorithm can be stopped by setting a thresh-
old c(cid:63)nλs0 on the value of GAP = |UB − LB| for a constant c(cid:63) > 0, say c(cid:63) = 1. Such a solution
will then achieve the same desirable statistical properties (in terms of parameter consistency) as
the optimal solution β(cid:63). While λ can be chosen data-adaptively (as discussed in Section 6), both of

8

these choices depend on the value of s0, which is not known in practice. However, one can ﬁnd an
upper bound for s0 based on the number of edges in the super-structure M. In particular, if M is
the moral graph [40] with sm edges, then s0 ≤ sm. However, while in many applications sm (cid:16) s0,
this is not always guaranteed. Thus, to ensure consistent estimation when replacing s0 with sm and
setting c(cid:63) = 1 in practice, we use the more conservative threshold of λs0 (cid:16) s0 log(m)/n. With this
choice the ﬁrst and third terms in (12) would be of the same (vanishing) order, and the consistency
rate would be driven by the convergence rate of (cid:107)β(cid:63) − β0(cid:107)2
2. We investigate the performance of this
choice in Section 6.4.

The above results, including the speciﬁc choice of early stopping criterion, are also valid if
the super-structure M corresponding to the moral graph is not known a priori. That is because
the moral graph can be consistently estimated from data using recent developments in graphical
modeling; see Drton and Maathuis [16] for a review of the literature. While some of the existing
algorithms based on (cid:96)1-penalty require an additional irrepresentability condition [33, 44], this as-
sumption can be relaxed by using instead an adaptive lasso penalty or by thresholding the initial
lasso estimates [8].

In light of Proposition 2, it is of great interest to develop algorithms that converge to a solution
with a small optimality gap expeditiously. To achieve this, one approach is to obtain better lower
bounds using the branch-and-bound process from strong mathematical formulations for (3). To
this end, we next review existing formulations of (3).

4 Existing Formulations of DAG Learning with Linear SEMs

In this section, we review known mathematical formulations for DAG learning with linear SEMs.
We ﬁrst outline the necessary notation below.

Index Sets
V = {1, 2, . . . , m}: index set of random variables;
D = {1, 2, . . . , n}: index set of samples.

−→
E ): the bi-directional graph corresponding to the undirected graph M;

Input
M = (V, E): an undirected super-structure graph (e.g., the moral graph);
−→
M = (V,
X = (X1, . . . , Xm), where Xv = (x1v, x2v, . . . , xnv)(cid:62) and xdv denotes dth sample (d ∈ D) of random
variable Xv; note X ∈ Rn×m;
λn : tuning parameter (penalty coeﬃcient for (cid:96)0 regularization).

Continuous optimization variables
βjk: weight of arc (j, k) representing the regression coeﬃcients ∀(j, k) ∈

−→
E .

Binary optimization variables
zjk = 1 if arc (j, k) exists in a DAG; otherwise 0, ∀(j, k) ∈
gjk = 1 if βjk (cid:54)= 0; otherwise 0, ∀(j, k) ∈
(cid:16)
xdk − (cid:80)

Let F (β, g) = (cid:80)

−→
E .

(cid:80)

(cid:17)2

k∈V

d∈D

E βjkxdj
−→

(j,k)∈

−→
E ,

+ λn

9

(cid:80)

(j,k)∈

E gjk. The PNLM problem
−→

can be cast as the following optimization model:

min
B∈Rm×m,g∈{0,1}|

−→
E |

F (β, g),

G(B) induces a DAG from

−→
M,

βjk(1 − gjk) = 0,

gjk ∈ {0, 1},

∀(j, k) ∈

∀(j, k) ∈

−→
E,
−→
E .

(13a)

(13b)

(13c)

(13d)

The objective function (13a) is an expanded version of L(β) in PNLM, where we use the indicator
variable gjk to encode the (cid:96)0 regularization. The constraints in (13b) rule out cycles. The constraints
in (13c) are non-linear and stipulate that βjk (cid:54)= 0 only if gjk = 1.

There are two sources of diﬃculty in solving (13a)-(13d): (i) the acyclic nature of DAG imposed
by the combinatorial constraints in (13b); (ii) the set of nonlinear constraints in (13c), which
stipulates that βjk (cid:54)= 0 only if there exists an arc (j, k) in G(B). In Section 4.1, we discuss related
studies to address the former, whereas in Section 4.2 we present relevant literature for the latter.

4.1 Linear encodings of the acyclicity constraints (13b)

There are several ways to ensure that the estimated graph does not contain any cycles. The ﬁrst
approach is to add a constraint for each cycle in the graph, so that at least one arc in this cycle
must not exist in G(B). A cutting plane (CP) method is used to solve such a formulation which
may require generating an exponential number of constraints. Another way to rule out cycles is by
imposing constraints such that the nodes follow a topological order [38]. A topological ordering is
a unique ordering of the nodes of a graph from 1 to m such that the graph contains an arc (j, k) if
node j appears before node k in the order. We refer to this formulation as topological ordering (TO).
−→
The TO formulation has O(m2) variables and O(|
E |) constraints. We give these formulations in
the Appendix, for completeness.

The layered network (LN) formulation for learning from continuous data proposed by [32] is
shown to perform better, empirically, than the TO formulation because it reduces the number
of binary variables and is proven to obtain the same continuous relaxation bounds. Therefore,
smaller quadratic programs are solved that provide the same relaxation bounds as larger quadratic
programs. This formulation is closely related to the generation number approach proposed in
[11] for discrete data. In this paper, we focus on the LN formulation and refer the reader to the
Appendix and [32] for comparisons of these formulations and their sizes in detail. Next, we give the
−→
E ,
LN encoding of the acyclicity constraints. Deﬁne decision variables zjk ∈ {0, 1} for all (j, k) ∈
where the variable zjk takes value 1 if there is an arc (j, k) in the network

LN gjk ≤ zjk

∀(j, k) ∈

zjk − (m − 1)zkj ≤ ψk − ψj ∀(j, k) ∈

−→
E ,
−→
E .

(14a)

(14b)

Let ψk be the layer value for node k. The set of constraints in (14b) ensures that if the layer of
node j appears before that of node k (i.e., there is a direct path from node j to node k), then
ψk ≥ ψj + 1. This rules out any cycles.
Constraint (14b) written for (k, i) ∈

−→
E imposes that if zij = 1 and zjk = 1, i.e., if ψk > ψi,
then zik = 1, even if βik = gik = 0 in an optimal solution. Thus, additional binary vector z along

10

with the set of constraints in (14a) is needed to correctly encode the (cid:96)0 regularization. The LN
−→
E | is much smaller than m2 for sparse
formulation has O(|
skeleton/moral graphs.

−→
E |) variables and constraints. Note that |

4.2 Linear encodings of the non-convex constraints (13c)

The nonconvexity of the set of constraints in (13c) causes challenges in obtaining provably optimal
solutions with existing optimization software. Therefore, we consider convex representations of this
set of constraints. First, we present a linear encoding of the constraints in (13c). Although the
existing compact (i.e., polynomial sized) TO and LN formulations discussed in Section 4.1 diﬀer in
their approach to ruling out cycles, one commonality among them is that they replace the non-linear
constraint (13c) by so called big-M constraints given by

−M gjk ≤ βjk ≤ M gjk, ∀(j, k) ∈

−→
E ,

(15)

for a large enough M . Unfortunately, these big-M constraints (15) are poor approximations of
(13c), especially in this problem, because no natural and tight value for M exists. Although a few
techniques have been proposed for obtaining the big-M parameter for sparse regression problem
[e.g., 7, 6, 25, 39], the resulting parameters are often too large in practice. Further, ﬁnding a tight
big-M parameter itself is a diﬃcult problem to solve for DAG structure learning.

Consider (13a)-(13d) by replacing (13c) with the linear big-M constraints (15) and writing the
objective function in a matrix form. We denote the resulting formulation, which has a convex
quadratic objective and linear constraints, by the following MIQP.

MIQP

min
B∈Rm×m,g∈{0,1}|

−→
E |

tr (cid:2)(I − B)(I − B)(cid:62)X (cid:62)X (cid:3) + λn

(cid:88)

gjk

(j,k)∈

−→
E

(13b), (15)

gjk ∈ {0, 1} ∀(j, k) ∈

−→
E .

(16a)

(16b)

(16c)

Depending on which types of constraints are used in lieu of (13b), as explained in Section 4.1,
MIQP (16) results in three diﬀerent formulations: MIQP+CP, which uses (23), MIQP+TO, which
uses (24), and MIQP+LN, which uses (14), respectively.

To discuss the challenges of the big-M approach, we give a deﬁnition followed by two proposi-

tions.

Deﬁnition 1. A formulation A is said to be stronger than formulation B if R(A) ⊂ R(B) where
R(A) and R(B) correspond to the feasible regions of continuous relaxations of A and B, respectively.

Proposition 3. (Proposition 3 in [32]) The MIQP+TO and MIQP+CP formulations are stronger
than the MIQP+LN formulation.

As a consequence of Deﬁnition 1, the optimal objective function value of the continuous relax-
ation of the stronger formulation provides a lower bound on the true optimal objective function
of the MIQP that is greater than or equal to the optimal objective function value of the contin-
uous relaxation of the weaker formulation due to the smaller set of feasible solutions. However,
next proposition shows that, perhaps surprisingly, the continuous relaxations of MIQP+TO and
MIQP+CP formulations, while stronger according to Deﬁnition 1, give the same optimal objective
function value (and the same lower bound on the true optimal objective).

11

Proposition 4. (Proposition 5 in [32]) Let β(cid:63)

jk denote the optimal coeﬃcient associated with an arc
−→
(j, k) ∈
E from problem (3). For the same variable branching in the branch-and-bound process, the
continuous relaxations of the MIQP+LN formulation for (cid:96)0 regularization attain the same optimal
objective function value as MIQP+TO and MIQP+CP, if M ≥ 2 max
−→
E
(j,k)∈

jk|.

|β(cid:63)

Proposition 3 implies that the MIQP+TO and MIQP+CP formulations are stronger than the
MIQP+LN formulation. Nonetheless, Proposition 4 establishes that for suﬃciently large values
of M , stronger formulations for the DAG learning problem attain the same continuous relaxation
objective function value as the weaker formulation throughout the branch-and-bound tree. The
optimal solution to the continuous relaxation of MIQP formulations of DAG structure learning
may not be at an extreme point of the convex hull of feasible points. Hence, stronger formulations
do not necessarily ensure better lower bounds for certain formulations of this problem involving the
nonlinear objective. This is in contrast to a mixed-integer program (MIP) with linear objective,
whose continuous relaxation is a linear program (LP). In that case, there exists an optimal solution
that is an extreme point of the corresponding feasible set. As a result, a better lower bound can
be obtained from a stronger formulation that better approximates the convex hull of the set of
solutions to a mixed-integer linear program; this generally leads to faster convergence. A prime
example is the traveling salesman problem (TSP), for which stronger formulations attain better
computational performance [36]. In contrast, the numerical results by [32] empirically show that
MIQP+LN has better computational performance because it is a compact formulation with the
fewest constraints and the same continuous relaxation bounds.

Our next result, which is adapted from [15] to the DAG structure learning problem, shows that
the continuous relaxation of MIQP is equivalent to the optimal solution to the problem where the
(cid:96)0-regularization term is replaced with an (cid:96)1-regularization term (i.e., (cid:107)β(cid:107)1 = (cid:80)
E |βjk|) with
−→
a particular choice of the (cid:96)1 penalty. This motivates us to consider tighter continuous relaxation
for MIQP. Let (βR, gR) be an optimal solution to the continuous relaxation of MIQP.

(j,k)∈

Proposition 5. For M ≥ 2 max
−→
E
(j,k)∈

|βR

jk|, a continuous relaxation of MIQP (16), where the binary

variables are relaxed, is equivalent to the problem where the (cid:96)0 regularization term is replaced with
an (cid:96)1-regularization term with penalty parameter ˜λ = λn
M .

Proof. For M ≥ 2 max
−→
E
(j,k)∈

|βR

jk|, the value gR

jk is

βR
jk
M in an optimal solution to the continuous re-

laxation of MIQP (16). Otherwise, we can reduce the value of the decision variable gR without
jk|,
violating any constraints while reducing the objective function. Note that since M ≥ 2 max
−→
E
(j,k)∈

|βR

we have
sider the set of CP constraints. In this case, the set of constraints (13b) holds, i.e., (cid:80)

−→
E . To show that the set of constraints in (13b) is satisﬁed, we con-

βR
jk
M ≤ 1, ∀(j, k) ∈

|CA|−1,

∀CA ∈ C, because M ≥ 2 max
−→
E
(j,k)∈
Thus, the objective function reduces to (cid:96)1 regularization with the coeﬃcient λn
M .

jk|. This implies that gR

jk =

|βR

Finally, Proposition 4 establishes that for M ≥ 2 max
−→
E
(j,k)∈

|β(cid:63)

jk|, the objective function value of

the continuous relaxations of MIQP+CP, MIQP+LN and MIQP+TO are equivalent. This implies
that the continuous relaxations of all formulations are equivalent, which completes the proof.

12

βR
jk
M ≤
βR
jk
M is the optimal solution.

(j,k)∈ CA

Despite the promising performance of MIQP+LN, its continuous relaxation objective function
value provides a weak lower bound due to the big-M constraints. To circumvent this issue, a natural
strategy is to improve the big-M value. Nonetheless, existing methods which ensure a valid big-M
value or heuristic techniques [38, 25] do not lead to tight big-M values. For instance, the heuristic
technique by [38] to obtain big-M values always satisﬁes the condition in Proposition 5 and exact
techniques are expected to produce even larger big-M values. Therefore, we directly develop tighter
approximations for (13c) next.

5 New Perspectives for Mathematical Formulations of DAG

Learning

In this section, we discuss improved mathematical formulations for learning DAG structure of a BN
based on convex (instead of linear) encodings of the constraints in (13c).

Problem (13) is an MIQP with non-convex complementarity constraints (13c), a class of prob-
lems which has received a fair amount of attention from the operations research community over
the last decade [17, 18, 19, 20, 25, 30, 55, 56]. There has also been recent interest in leveraging
these developments to solve sparse regression problems with (cid:96)0 regularization [42, 15, 58, 3, 54].

Next, we review applications of MIQPs with complementarity constraints of the form (13c) for
solving sparse regression with (cid:96)0 regularization. [20] develop a so-called projected perspective relax-
ation method, to solve the perspective relaxation of mixed-integer nonlinear programming problems
with a convex objective function and complementarity constraints. This reformulation requires that
the corresponding binary variables are not involved in other constraints. Therefore, it is suitable
for (cid:96)0 sparse regression, but cannot be applied for DAG structure learning. [42] show how a broad
class of (cid:96)0-regularized problems, including sparse regression as a special case, can be formulated
exactly as optimization problems. The authors use the Tikhonov regularization term µ(cid:107)β(cid:107)2
2 and
convex analysis to construct an improved convex relaxation using the reverse Huber penalty. In a
similar vein, [6] exploit the Tikhonov regularization and develop an eﬃcient algorithm by reformu-
lating the sparse regression mathematical formulation as a saddle-point optimization problem with
an outer linear integer optimization problem and an inner dual quadratic optimization problem
which is capable of solving high-dimensional sparse regressions. [58] apply the perspective formu-
lation of sparse regression optimization problem with both (cid:96)0 and the Tikhonov regularizations.
The authors establish that the continuous relaxation of the perspective formulation is equivalent to
the continuous relaxation of the formulation given by [6]. [15] propose perspective relaxation for (cid:96)0
sparse regression optimization formulation and establish that the popular sparsity-inducing concave
penalty function known as the minimax concave penalty [59] and the reverse Huber penalty [42]
can be obtained as special cases of the perspective relaxation – thus the relaxations of formulations
by [59, 42, 6, 58] are equivalent. The authors obtain an optimal perspective relaxation that is no
weaker than any perspective relaxation. Among the related approaches, the optimal perspective
relaxation by [15] is the only one that does not explicitly require the use of Tikhonov regularization.
The perspective formulation, which in essence is a fractional non-linear program, can be cast
either as a mixed-integer second-order cone program (MISOCP) or a semi-inﬁnite mixed-integer
linear program (SIMILP). Both formulations can be solved directly by state-of-the-art optimization
packages.
[15] and [3] solve the continuous relaxations and then use a heuristic approach (e.g.,
rounding techniques) to obtain a feasible solution (an upper bound). In this paper, we directly
solve the MISOCP and SIMILP formulations for learning sparse DAG structures.

13

Next, we present how perspective formulation can be suitably applied for DAG structure learning
with (cid:96)0 regularization. We further cast the problem as MISOCP and SIMILP. To this end, we
express the objective function (16a) in the following way:

tr[(I − B)(I − B)(cid:62)X (cid:62)X ] + λn

(cid:88)

gjk

(j,k)∈

−→
E

= tr[(I − B − B(cid:62))X (cid:62)X + 2BB(cid:62)X (cid:62)X ] + λn

(cid:88)

gjk.

(j,k)∈

−→
E

(17)

Let δ ∈ Rm
+ be a vector such that X (cid:62)X − Dδ (cid:23) 0, where Dδ = diag(δ1, . . . , δm) and A (cid:23) 0 means
that matrix A is positive semi-deﬁnite. By splitting the quadratic term X (cid:62)X = (X (cid:62)X − Dδ) + Dδ
in (17), the objective function can be expressed as

tr (cid:2)(I − B − B(cid:62))X (cid:62)X + BB(cid:62)(X (cid:62)X − Dδ)(cid:3) + tr (cid:0)BB(cid:62)Dδ

(cid:1) + λn

(cid:88)

gjk.

(j,k)∈

−→
E

(18)

Let Q = X (cid:62)X − Dδ. (In the presence of Tikhonov regularization with tuning parameter µ > 0,
we let Q = X (cid:62)X + µI − Dδ as described in Remark 1.) Then, Cholesky decomposition can
be applied to decompose Q as q(cid:62)q (note Q (cid:23) 0). As a result, tr (cid:0)BB(cid:62)Q(cid:1) = tr (cid:0)BB(cid:62)q(cid:62)q(cid:1) =
(cid:1) =
(cid:80)m

. The separable component can also be expressed as tr (cid:0)BB(cid:62)Dδ

(cid:16)(cid:80)

(cid:80)m

(cid:17)2

E β(cid:96)jqi(cid:96)
−→

i=1

j=1

(cid:80)m

(cid:80)

j=1

(j,k)∈

((cid:96),j)∈

−→

E δjβ2

jk. Using this notation, the objective (18) can be written as

tr (cid:2)(I − B − B(cid:62))X (cid:62)X + BB(cid:62)Q(cid:3) +

m
(cid:88)

(cid:88)

j=1

(j,k)∈

−→
E

δjβ2

jk + λn

(cid:88)

gjk.

(j,k)∈

−→
E

The Perspective Reformulation (PRef) of MIQP is then given by

PRef

min
B∈Rm×m,g∈{0,1}|

−→
E |

tr(cid:2)(I − B − B(cid:62))X (cid:62)X + BB(cid:62)Q(cid:3)+

(19a)

m
(cid:88)

(cid:88)

j=1

(j,k)∈

−→
E

δj

β2
jk
gjk

+ λn

(cid:88)

gjk,

(j,k)∈

−→
E

(16b) − (16c).

(19b)

β2
jk
gjk

= 0 when βjk = gjk = 0 and

The objective function (19a) is formally undeﬁned when some gjk = 0. More precisely, we use
the convention that
= +∞ when βjk (cid:54)= 0 and gjk = 0
[19]. The continuous relaxation of PRef, referred to as the perspective relaxation, is much stronger
than the continuous relaxation of MIQP under certain conditions discussed in detail in Section 5.3
[42]. However, an issue with PRef is that the objective function is nonlinear due to the fractional
term. There are two ways to reformulate PRef. One as a mixed-integer second-order conic program
(MISOCP) (see, Section 5.1) and the other as a semi-inﬁnite mixed-integer linear program (SIMILP)
(see, Section 5.2).

β2
jk
gjk

14

5.1 Mixed-integer second-order conic program

Let sjk be additional variables representing β2

jk. Then, the MISOCP formulation is given by

MISOCP

B∈Rm×m,s∈R|

min
−→
E |,g∈{0,1}|

−→
E |

tr (cid:2)(I − B − B(cid:62))X (cid:62)X + BB(cid:62)Q(cid:3) +

(20a)

m
(cid:88)

(cid:88)

δjsjk + λn

(cid:88)

gjk,

j=1

−→
(j,k)∈
E
sjkgjk ≥ β2
jk
0 ≤ sjk ≤ M 2gjk
(16b) − (16c).

(j, k) ∈

−→
E

(j,k)∈
−→
E ,

(j, k) ∈

−→
E ,

(20b)

(20c)

(20d)

(cid:113)

4β2

jk and g2

Here, the constraints in (20b) imply that βjk (cid:54)= 0 only when gjk = 1. The constraints in (20b) are
jk + (sjk − gjk)2 ≤
second-order conic representable because they can be written in the form of
sjk + gjk. The set of constraints in (20c) is valid since βjk ≤ M gjk implies β2
jk ≤ M 2g2
jk =
M 2g2
jk = gjk for gjk ∈ {0, 1}. The set of constraints in (20c) is not required, yet they
improve the computational eﬃciency especially when we restrict the big-M value.
[58] report
similar behavior for sparse regression. When we relax gjk ∈ {0, 1} and let gjk ∈ [0, 1], we obtain the
continuous relaxation of MISOCP (20). Let us denote the feasible region of continuous relaxation
of MISOCP (20) and MIQP (16) by RMISOCP and RMIQP, and the objective function values
by OFV(RMISOCP) and OFV(RMIQP), respectively. For a more general problem than ours, [10]
give a detailed proof establishing that the feasible region of the former is contained in the feasible
region of latter i.e., RMISOCP ⊂ RM IQP , and OFV(RMISOCP) ≥ OFV(RMIQP). Therefore,
we are able to obtain stronger lower bounds using MISOCP than MIQP under suitable choices for
Dδ as described in Section 5.3.

5.2 Mixed-integer semi-inﬁnite integer linear program

An alternative approach to reformulate PRef is via perspective cuts developed by [17, 18]. To apply
perspective cuts, we use the reformulation idea ﬁrst proposed in [17] by introducing dummy decision
matrix D to distinguish the separable and non-separable part of the objective function; we also add
the additional constraint d = β where djk is (j, k) element of matrix D and β is the decision variable

15

in the optimization problem. Following this approach, MIQP can be reformulated as an SIMILP:

SIMILP

B∈Rm×m,v∈R|

min
−→
E |,g∈{0,1}|

−→
E |

tr (cid:2)(I − B − B(cid:62))X (cid:62)X + DD(cid:62)Q(cid:3) +

(21a)

m
(cid:88)

(cid:88)

j=1

(j,k)∈

−→
E

δjvjk + λn

(cid:88)

gjk,

(j,k)∈

−→
E

djk = βjk
(j, k) ∈
vjk ≥ 2 ¯βjkβjk − ¯β2

−→
E ,

jkgjk ∀ ¯βjk ∈ [−M, M ] ∀(j, k) ∈

(16b) − (16c),

vjk ≥ 0,

(j, k) ∈

−→
E .

(21b)
−→
E ,
(21c)

(21d)

(21e)

The set of constraints in (21c) is known as perspective cuts. Note that there are inﬁnitely many
such constraints. Although this problem cannot be solved directly, it lends itself to a delayed cut
generation approach whereby a (small) ﬁnite subset of constraints in (21c) is kept, the current
solution (β(cid:63), g(cid:63), v(cid:63)) of the relaxation is obtained, and all the violated inequalities for the relaxation
solution are added for ¯βjk =
0 = 0). This process is repeated until termination
criteria are met. This procedure can be implemented using the cut callback function available by
oﬀ-the-shelf solvers such as Gurobi or CPLEX.

(assuming 0

β(cid:63)
jk
g(cid:63)
jk

5.3 Selecting δ

In the MISOCP and SIMILP formulations, one important question is how to identify a valid δ.
A natural choice is diag(δ) = λmine, where λmin is the minimum eigenvalue of X (cid:62)X and e is a
column vector of ones. The issue with this approach is that if λmin = 0, then diag(δ) becomes a
trivial 0 matrix. If diag(δ) turns out to be a zero matrix, then MISOCP formulation reduces to
the big-M formulation.
[18] present an eﬀective approach for obtaining a valid δ by solving the
following semideﬁnite program (SDP)

max
δ∈R|V |

(cid:40)

(cid:88)

i∈V

δi : X (cid:62)X − diag(δ) (cid:23) 0, δi ≥ 0

.

(22a)

(cid:41)

This formulation can attain a non-zero Dδ even if λmin = 0. Numerical results by [18] show that
[60] propose an SDP
this method compares favorably with the minimum eigenvalue approach.
approach, which obtains Dδ such that the continuous relaxation of MISOCP (20) is as tight as
possible.

Similar to [15], our formulation does not require adding a Tikhonov regularization. In this case,
PRef is eﬀective when X (cid:62)X is suﬃciently diagonally dominant. When n ≥ m and each row of X is
independent, then X (cid:62)X is guaranteed to be a positive semi-deﬁnite matrix [15]. On the other hand,
when n < m, X (cid:62)X is not full-rank. Therefore, a Tikhonov regularization term should be added
with suﬃciently large µ to make X (cid:62)X + µI (cid:23) 0 [15] in order to beneﬁt from the strengthening
provided by PRef.

16

6 Experiments

In this section, we report the results of our numerical experiments that compare diﬀerent for-
mulations and evaluate the eﬀect of diﬀerent tuning parameters and estimation strategies. Our
experiments are performed on a cluster operating on UNIX with Intel Xeon E5-2640v4 2.4GHz.
All formulations are implemented in the Python programming language. Gurobi 8.1 is used as the
solver. Unless otherwise stated, a time limit of 50m (in seconds), where m denotes the number
of nodes, and an MIQP relative optimality gap of 0.01 are imposed across all experiments after
which runs are aborted. The relative optimality gap is calculated by RGAP:= U B(X)−LB(X)
where
UB(X) denotes the objective value associated with the best feasible integer solution (incumbent)
and LB(X) represents the best obtained lower bound during the branch-and-bound process for the
formulation X ∈ {MIQP, SIMILP, MISOCP}.

U B(X)

Unless otherwise stated, we assume λn = log(n) which corresponds to the Bayesian information
criterion (BIC) score. To select the big-M parameter, M , in all formulations we use the proposal
of Park and Klabjan [38]. Speciﬁcally, given λn, we solve each problem without cycle prevention
constraints and obtain βR. We then use the upper bound M = 2 max
jk|. Although this value
−→
E
(j,k)∈

|βR

does not guarantee an upper bound for M , the results provided in [38] and [32] computationally
conﬁrm that this approach gives a large enough value of M .

The goals of our computational study are twofold. First, we compare the various mathematical
formulations to determine which gives us the best performance in Subsection 6.1, compare the
sensitivity to the model parameters in Subsection 6.2, and the choice of the regularization term in
Subsection 6.3. Second, in Subsection 6.4 we use the best-performing formulation to investigate the
implications of the early stopping condition on the quality of the solution with respect to the true
graph. To be able to perform such a study, we use synthetic data so that the true graph is available.
In Subsection 6.5, we compare our algorithm against two state-of-the-art benchmark algorithms on
publicly available datasets.

We use the package pcalg in R to generate random graphs. First, we create a DAG by randomDAG
function and assign random arc weights (i.e., β) from a uniform distribution, U[0.1, 1]. Next, the
resulting DAG and random coeﬃcients are fed into the rmvDAG function to generate multivariate
data based on linear SEMs (columns of matrix X ) with the standard normal error distribution.
We consider m ∈ {10, 20, 30, 40} nodes and n = 100 samples. The average outgoing degree of each
node, denoted by d, is set to two. We generate 10 random Erd˝os-R´enyi graphs for each setting (m,
n, d). We observe that in our instances, the minimum eigenvalue of X (cid:62)X across all instances is
3.26 and the maximum eigenvalue is 14.21.

Two types of problem instances are considered: (i) a set of instances with known moral graph
corresponding to the true DAG; (ii) a set of instances with a complete undirected graph, i.e.,
assuming no prior knowledge. We refer to the ﬁrst class of instances as moral instances and to the
second class as complete instances. The observational data, X , for both classes of instances are
the same. The function moralize(graph) in the pcalg R-package is used to generated the moral
graph from the true DAG. Although the moral graph can be consistently estimated from data using
penalized estimation procedures with polynomial complexity [e.g., 31], the quality of moral graph
aﬀects all optimization models. Therefore, we use the true moral graph in our experiments, unless
otherwise stated.

17

Table 1: Optimality gaps for MISOCP+TO and MISOCP+LN formulations

Moral

m MISOCP+TO MISOCP+LN
10
20
30
40

0.000
0.021
-
-

0.000
0.006
0.010
0.042

Complete
MISOCP+TO MISOCP+LN
0.009
0.272
-
-

0.008
0.195
0.195
0.436

“-” denotes that no feasible solution, i.e., UB, is obtained within the time limit, so optimality gap cannot be
computed.

6.1 Comparison of Mathematical Formulations

We use the following MIQP-based metrics to measure the quality of a solution: relative optimality
gap (RGAP), computation time in seconds (Time), Upper Bound (UB), Lower Bound (LB), objec-
tive function value (OFV) of the initial continuous relaxation, and the number of explored nodes
in the branch-and-bound tree (# BB). An in-depth analysis comparing the existing mathemati-
cal formulations that rely on linear encodings of the constraints in (13c) for MIQP formulations
is conducted by [32]. The authors conclude that MIQP+LN formulation outperforms the other
MIQP formulations, and the promising performance of MIQP+LN can be attributed to its size: (1)
MIQP+LN has fewer binary variables and constraints than MIQP+TO, (2) MIQP+LN is a com-
pact (polynomial-sized) formulation in contrast to MIQP+CP which has an exponential number of
constraints. Therefore, in this paper, we analyze the formulations based on the convex encodings
of the constraints in (13c).

6.1.1 Comparison of MISOCP formulations

We next experiment with MISOCP formulations. For the set of constraints in (13b), we use LN,
TO, and CP constraints discussed in Section 4.1 resulting in three formulations denoted as MIS-
OCP+LN, MISOCP+TO, MISOCP+CP, respectively. The MISOCP+TO formulation fails to ﬁnd
a feasible solution for instances with 30 and 40 nodes, see Table 1. For moral instances, the opti-
mality gaps for MISOCP+TO are 0.000 and 0.021 for instances with 10 and 20 nodes, respectively;
for complete instances, the optimality gap for MISOCP+TO formulation are 0.009 and 0.272 for
instances with 10 and 20 nodes, respectively. Moreover, Table 1 illustrates that MISOCP+LN
performs better than MISOCP+TO for even small instances (i.e., 10 and 20 nodes).

For MISOCP+CP, instead of incorporating all constraints given by (23), we begin with no
constraint of type (23). Given an integer solution with cycles, we detect a cycle and impose a new
cycle prevention constraint to remove the detected cycle. Depth First Search (DFS) can detect a
cycle in a directed graph with complexity O(|V | + |E|). Gurobi LazyCallback function is used,
which allows adding cycle prevention constraints in the branch-and-bound algorithm, whenever an
integer solution with cycles is found. The same approach is used by [38] to solve the corresponding
MIQP+CP. Note that Gurobi solver follows a branch-and-cut implementation and adds many
general-purpose and special-purpose cutting planes.

Figures 1a and 1b show that MISOCP+LN outperforms MISOCP+CP in terms of relative
optimality gap and computational time. In addition, MISOCP+LN attains better upper and lower
bounds than MISOCP+CP (see, Figures 1c and 1d). MISOCP+CP requires the solution of a
second-order cone program (SOCP) after each cut, which reduces its computational eﬃciency and
results in higher optimality gaps than MISOCP+LN. MISOCP+TO requires many binary variables

18

(a) RGAPs

(b) Time (in seconds)

(c) Best upper bounds

(d) Best lower bounds

Figure 1: Optimization-based measures for MISOCP+LN (left bar) and MISOCP+CP (right bar)
formulations for n = 100.

which makes the problem very ineﬃcient when the network becomes denser and larger as shown in
Table 1. Therefore, we do not illustrate the MISOCP+TO results in Figure 1.

6.1.2 Comparison of MISOCP versus SIMILP

Our computational experiments show that the SIMILP formulation generally performs poorly when
compared to MISOCP+LN and MIQP+LN in terms of optimality gap, upper bound, and compu-
tational time. We report the results for SIMILP+LN, MISOCP+LN, and MIQP+LN formulations
in Figure 2. We only consider the LN formulation because that is the best performing model among
the alternatives both for MISOCP and MIQP formulations.

Figures 2a and 2b show the relative optimality gaps and computational times for these three
formulations. Figures 2c and 2d demonstrate that SIMILP+LN attains lower bounds that are
comparable with other two formulations. In particular, for complete instances with large number
of nodes, SIMILP+LN attains better lower bounds than MIQP+LN. Nonetheless, SIMILP+LN
fails to obtain good upper bounds. Therefore, the relative optimality gap is considerably larger for
SIMILP+LN.

The poor performance of SIMILP+LN might be because state-of-the-art optimization packages

19

(a) RGAPs

(b) Time (in seconds)

(c) Best upper bounds

(d) Best lower bounds

Figure 2: Optimization-based measures for MISOCP+LN, MIQP+LN, and SIMILP+LN formula-
tions for n = 100.

(e.g., Gurobi, CPLEX) use many heuristics to obtain a good feasible solution (i.e., upper bound)
for a compact formulation. In contrast, SIMILP is not a compact formulation, and we build the
SIMILP gradually by adding violated constraints iteratively. Therefore, a feasible solution to the
original formulation is not available while solving the relaxations with a subset of the constraints
(21c). Moreover, the optimization solvers capable of solving MISOCP formulations have witnessed
noticeable improvement due to theoretical developments in this ﬁeld. In particular, Gurobi reports
20% and 38% improvement in solution time for versions 8 and 8.1, respectively.
In addition,
Gurobi v8.1 reports over four times faster solution times than CPLEX for solving MISOCP on
their benchmark instances.

6.1.3 Comparison of MISOCP versus MIQP formulations

In this section, we demonstrate the beneﬁt of using the second-order conic formulation MIS-
OCP+LN instead of the linear big-M formulation MIQP+LN. As before, we only consider the
LN formulation for this purpose. Figures 3a and 3b show that MISOCP+LN performs bet-
ter than MIQP+LN in terms of the average relative optimality gap across all number of nodes

20

(a) RGAPs

(b) Time (in seconds)

(c) Best upper bounds

(d) Best lower bounds

(e) Number of Branch and Bound nodes

(f) Continuous relaxation objective function

Figure 3: Optimization-based measures for MISOCP+LN, MIQP+LN formulations for n = 100.

m ∈ {10, 20, 30, 40}. The only exception is m = 40 for moral instances, for which MIQP+LN per-
forms better than MISOCP+LN. Nonetheless, we observe that MISOCP+LN clearly outperforms
MIQP+LN for complete instances which are more diﬃcult to solve.

21

Table 2: Computational results for diﬀerent values of λn = t log(n) for t ∈ {1, 2, 4}, * indicates that
the problem is solved to the optimality tolerance. Superscript i indicates that out of ten runs, i
instances ﬁnish before hitting the time limit. Time is averaged over instances that solve within the
time limit, RGAP is averaged over instances that reach the time limit. Better RGAPs are in bold.

Moral

Complete

Instances
m λn
10 4.6
10 9.2
10 18.4
20 4.6
20 9.2
20 18.4
30 4.6
30 9.2
30 18.4
40 4.6
40 9.2
40 18.4

Time

Time

RGAP

RGAP

# nodes

# nodes

Relaxation OFV

Relaxation OFV
MISOCP MIQP MISOCP MIQP MISOCP MIQP MISOCP MIQP MISOCP MIQP MISOCP MIQP MISOCP MIQP MISOCP MIQP
629.3
*
662.2
*
720.2
*
1144.5
*
1238.6
*
*
1395.0
.0108
1569.7
1741.5
*
2006.9
*
.0426
1946.3
.0248
2216.9
.0248
2633.1

3715
2936
2457
76261
31458
33788
514979
248190
57909
2565247
1347702
1137666

114433
55543
41197
238765
274514
277687
64240
71475
96586
49050
73917
60697

1306
1116
1269
46513
10695
9574
121358
33371
15649
664496
353256
434648

38850
15736
18223
101509
152206
159789
38474
59034
74952
23083
29279
31298

738.7
784.6
857.0
1474.2
1589.6
1763.7
2230.1
2392.4
2608.3
2979.3
3200.7
3521.8

664.9
693.5
747.5
1325.8
1406.8
1552.7
2037.7
2168.5
2383.8
2748.6
2923.5
3225.4

724.4
772.5
844.5
1404.9
1526.9
1697.1
2024.0
2217.5
2449.2
2582.0
2869.9
3240.1

*
*
*
*
*
*
0.0118
*
*
.0374
.0364
.0352

*
*
*
.195
.152
.1132
.298
.239
.215
.436
.397
.374

74
39
29
1000
1000
1000
1500
1500
1500
2000
2000
2000

3
4
3
69
26
24
378
104
48
1551
1125
1099

2
3
2
51
27
36
527
291
74
1615
1336
1375

65
31
26
1000
1000
944
1500
1500
1500
2000
2000
2000

*
*
*
.275
.250
.208
.441
.395
.318
.545
.473
.465

Figures 3c and 3d show the performance of both formulations in terms of the resulting upper
and lower bounds on the objective function. We observe that MISOCP+LN attains better lower
bounds especially for complete instances. However, MISOCP+LN cannot always obtain a better
upper bound. In other words, MISOCP+LN is more eﬀective in improving the lower bound instead
of the upper bound as expected.

Figures 3e and 3f show that MISOCP+LN uses fewer branch-and-bound nodes and achieves

better continuous relaxation values than MIQP+LN.

6.2 Analyzing the Choices of λn and M

We now experiment on diﬀerent values for λn and M to assess the eﬀects of these parame-
ters on the performance of MISOCP+LN and MIQP+LN. First, we consider multiple λ values,
jk|).
λn ∈ {log (n), 2 log(n), 4 log(n)}, while keeping the value of M the same (i.e., M = 2 max
−→
E
(j,k)∈

|β(cid:63)

Table 2 shows that as λn increases, MISOCP+LN consistently performs better than MIQP+LN in
terms of the relative optimality gap, computational time, the number of branch-and-bound nodes,
and continuous relaxation objective function value. Indeed, the diﬀerence becomes even more pro-
nounced for more diﬃcult cases (i.e., complete instances). For instance, for λn = 4 log(n) = 18.4,
the relative optimality gap reduces from 0.465 to 0.374, an over 24% improvement. In addition,
MISOCP+LN allows more instances to be solved to optimality within the time limit. For example,
for moral instances with m = 40, λn = 18.4, eight out of ten instances are solved to optimality
using MISOCP+LN while only two instances are solved to optimality by MIQP+LN.

Finally, we study the inﬂuence of the big-M parameter. Instead of a coeﬃcient γ = 2 in [38], we
jk| denotes the optimal

jk| for γ ∈ {2, 5, 10} in Table 3, where |βR

|βR

experiment with M = γ max
−→
E
(j,k)∈

solution of each optimization problem without the constraints to remove cycles. The larger the
big-M parameter, the worse the eﬀectiveness of both models. However, comparing the continuous
relaxation objective function values, we observe that MISOCP+LN tightens the formulation using

22

Table 3: Computational results for diﬀerent values of γ, * indicates that the problem is solved
to the optimality tolerance. Superscript i indicates that out of ten runs, i instances ﬁnish before
hitting the time limit. Time is averaged over instances that solve within the time limit, RGAP is
averaged over instances that reach the time limit. Better RGAPs are in bold.

Moral

Complete

Instances
m γ
10 2
10 5
10 10
20 2
20 5
20 10
30 2
30 5
30 10
40 2
40 5
40 10

Time

Time

RGAP

RGAP

# nodes

# nodes

Relaxation OFV

Relaxation OFV
MISOCP MIQP MISOCP MIQP MISOCP MIQP MISOCP MIQP MISOCP MIQP MISOCP MIQP MISOCP MIQP MISOCP MIQP
629.3
*
607.8
*
600.3
*
1144.5
*
1080.9
*
1058.2
*
.0108
1569.7
.0118
1448.4
.0248
1404.0
.0426
1946.3
.0456
1751.7
.0564
1679.6

3715
3026
2564
76261
209595
349335
514979
527847
585234
2565247
1347868
1584187

114433
130112
174085
238765
225050
257998
64240
64339
77100
49050
30858
30222

1306
1433
1523
46513
65951
150250
121358
164852
202635
664496
638323
599281

38850
42675
35576
101509
97940
90864
38474
33120
30579
23083
12076
11847

724.4
705.1
699.8
1404.9
1375.3
1366.3
2024.0
1969.4
1951.2
2582.0
2488.0
2456.1

664.9
647.1
641.1
1325.8
1274.2
1256.6
2037.7
1950.3
1919.6
2748.6
2635.0
2595.6

738.7
717.9
712.5
1474.2
1438.2
1427.7
2230.1
2173.9
2156.5
2979.3
2895.6
2869.2

*
*
*
*
*
*
.0118
.0148
.0148
.0374
.0472
.0572

*
*
*
.195
.211
.230
.298
.336
.349
.436
.579
.585

3
5
5
69
103
215
378
571
630
1551
1643
1639

2
2
2
51
156
207
527
620
638
1615
1634
1632

74
82
100
1000
1000
1000
1500
1500
1500
2000
2000
2000

65
81
74
1000
1000
1000
1500
1501
1500
2000
2000
2000

*
*
*
.275
.308
.310
.441
.474
.480
.545
.580
.594

the conic constraints whereas MIQP+LN does not have any means to tighten the formulation instead
of big-M constraints which have poor relaxation.
In most cases, the MISOCP+LN formulation
allows more instances to be solved to optimality than MIQP+LN. For larger m, because Gurobi
solves larger SOCP relaxations in each branch-and-bound node, the MISOCP+LN formulation
explores much fewer branch-and-bound nodes and stops with a similar RGAP at termination. For
M > 2 max
−→
E
(j,k)∈

jk|, MISOCP+LN outperforms MIQP+LN in all measures, in most cases.

|βR

6.3 The Eﬀect of Tikhonov Regularization

In this subsection, we consider the eﬀect of adding a Tikhonov regularization term to the objective
(see Remark 1) by considering µ ∈ {0, log(n), 2 log(n)} while keeping the values of λn = log(n)
and M the same as before. Table 4 demonstrates that for all instances with µ > 0, MISOCP+LN
outperforms MIQP+LN. For complete instances with m = 40 and µ = 9.2, MISOCP+LN im-
proves the optimality gap from 0.445 to 0.367, an improvement over 21%. The reason for this
improvement is that µ > 0 makes the matrix more diagonally dominant; therefore, it makes the
conic constraints more eﬀective in tightening the formulation and obtaining a better optimality gap.
Also, MISOCP+LN allows more instances to be solved to optimality than MIQP+LN.

6.4 Practical Implications of Early Stopping

In this subsection, we evaluate the quality of the estimated DAGs obtained from MISOCP+LN by
comparing them with the ground truth DAG. To this end, we use three measures: the average struc-
tural Hamming distance (SHD) which counts the number of arc diﬀerences (additions, deletions,
or reversals) required to transform the estimated DAG to the true DAG, the average false positive
rate (FPR) which is the proportion of edges appearing in the estimated DAG but not the true DAG
and the average true positive rate (TPR) which is the proportion of edges appearing in both the
true DAG and the estimated DAG. Since Gurobi sets a minimum relative gap RGAP= 1e−4, the

23

Table 4: Computational results for diﬀerent values of µ, * indicates that the problem is solved
to the optimality tolerance. Superscript i indicates that out of ten runs, i instances ﬁnish before
hitting the time limit. Time is averaged over instances that solve within the time limit, RGAP is
averaged over instances that reach the time limit. Better RGAPs are in bold.

Moral

Complete

Instances
m µ
10 0
10 4.6
10 9.2
20 0
20 4.6
20 9.2
30 0
30 4.6
30 9.2
40 0
40 4.6
40 9.2

Time

Time

RGAP

RGAP

# nodes

# nodes

Relaxation OFV

Relaxation OFV
MISOCP MIQP MISOCP MIQP MISOCP MIQP MISOCP MIQP MISOCP MIQP MISOCP MIQP MISOCP MIQP MISOCP MIQP
629.3
*
675.7
*
712.3
*
1144.5
*
1267.1
*
1355.1
*
.0108
1569.7
.0089
1788.5
.0099
1915.7
.0426
1946.3
.0278
2261.3
.0208
2468.7

3715
2758
2231
76261
55302
62297
514979
358544
320632
2565247
1303301
1762210

114433
119825
114383
238765
249490
258194
64240
69258
68661
49050
30995
54638

1306
1043
1067
46513
15111
15384
121358
76668
12410
664496
422654
239214

38850
38778
36326
101509
102467
94360
38474
45473
41241
23083
13209
13884

664.9
708.5
748.1
1325.8
1426.5
1515.7
2037.7
2187.7
2311.4
2748.6
2972.8
3165.3

724.4
789.3
843.2
1404.9
1551.7
1668.3
2024.0
2286.4
2484.3
2582.0
2985.4
3321.7

738.7
802.0
858.0
1474.2
1604.1
1716.8
2230.1
2432.5
2612.6
2979.3
3281.6
3575.4

*
*
*
*
*
*
.0118
.0118
.0108
.0374
.0294
.0286

*
*
*
.195
.167
.142
.298
.237
.209
.436
.354
.367

2
2
2
51
45
55
527
392
377
1615
1620
1507

3
4
4
69
45
43
378
310
67
1551
1331
870

65
69
72
1000
1000
1000
1500
1500
1500
2000
2000
2000

74
72
74
1000
1000
1000
1500
1500
1500
2000
2000
2000

*
*
*
.275
.242
.223
.441
.387
.367
.545
.471
.445

solution obtained within this relative gap is considered optimal. Finally, because the convergence
of the branch-and-bound process may be slow in some cases, we set a time limit of 100m.

To test the quality of the solution obtained with an early stopping criterion, we set the absolute
optimality gap parameter as GAP = log(m)
sm and the (cid:96)0 regularization parameter as λn = log m
as suggested by the discussion following Proposition 2 for achieving a consistent estimate. We
compare the resulting suboptimal solution to the solution obtained by setting GAP = UB − LB = 0
to obtain the truly optimal solution.

n

Table 5 shows the numerical results for the average solution time (in seconds) for instances that
are solved within the time limit, the number of instances that were not solved within the time limit,
the actual absolute optimality gap at termination, the average FPR, the average TPR, the average
SHD of the resulting DAGs, across 10 runs for moral instances. Table 5 indicates that the average
SHD for GAP = log(m)
sm is close to that of the truly optimal solution, and the average (FPR)
and (TPR) are the same between setting GAP = log(m)
sm and GAP = 0 except for m = 10. Note
that a lower GAP generally leads to a better SHD score. From a computational standpoint, we
observe that by using the early stopping criterion, we are able to obtain consistent solutions faster.
In particular, the average solution time reduces by 25% for m = 30. The number of instances which
are solved before hitting the 100m time limit are the same for GAP = 0 and GAP = log(m)
sm.
Furthermore, stopping early does not sacriﬁce too much from the quality of the resulting DAG as
can be seen from the SHD scores.

n

n

n

6.5 Comparison to Other Benchmarks

In this section, we compare the performance of MISOCP against the state-of-the-art benchmarks.
These experiments are executed on a laptop with a Windows 10 operating system, an Intel Core
i7-8750H 2.2-GHz CPU, 8-GB DRAM using Python 3.8 with Gurobi 9.1.1 Optimizer.

The benchmarks considered in this section include the top-down approach (EqVarDAG-TD)
and the high-dimensional top-down approach (EqVarDAG-HD-TD) of [9], as well as the high-

24

Table 5: Structural Hamming distances (SHD), False Positive Rate (FPR) and True Positive Rate
(TPR) for early stopping with n = 100, λn = log(m), GAP ≤ τ for moral instances. The su-
perscripts i indicate that out of ten runs, i instances ﬁnish before hitting the time limit. Time
is averaged over instances that solve within the time limit, GAP and RGAP are averaged over
instances that terminate early.

τ = 0

m sm
19
10
58
20
109
30
138
40

Time
1.2810
6.159
37.407
9352

GAP RGAP
0.000
0.00
0.000
0.71
0.004
13.96
0.131
63.06

SHD FPR TPR
1.00
0.04
0.75
1.00
0.01
1.50
1.00
0.00
1.67
1.00
0.01
5.00

Time
1.2810
6.049
27.637
640.152

τ = log(m)

n
GAP RGAP
0.000
0.06
0.001
1.44
0.005
15.80
0.132
66.34

sm
SHD FPR TPR
1.00
0.02
0.77
1.00
0.01
2.00
1.00
0.00
1.66
1.00
0.01
5.00

dimensional bottom-up approach (EqVarDAG-HD-BU) of [24]. By taking advantage of the condi-
tions for identiﬁability in linear SEM models, these benchmark procedures oﬀer polynomial-time
algorithms for learning DAGs by iteratively identifying a source (top-down) or sink (bottom-up)
node based on solving a series of covariance selection problems.

We compare the performance of the methods on twelve publicly available networks from [32]
and Bayesian Network Repository (bnlearn). The number of nodes in these networks ranges from
m = 6 to m = 70. We generate data from both identiﬁable and non-identiﬁable error distributions.
In the case of identiﬁable distributions (ID), we generate the data by using random arc weights
β from U[−1, −0.1] ∪ U[0.1, 1] and n = 500 samples standard normal errors. The data for the
non-identiﬁable (NID) error distributions was generated similarly, but from normal errors with
non-equal error variances chosen randomly from {0.5, 1, 1.5}.

As an input superstructure graph to MISOCP, other than the true moral graphs, we also consider
a superstructure estimate based on the empirical correlation matrix (CorEst). This estimate—which
is guaranteed to be a super set of the DAG skeleton under the faithfulness assumption—was obtained
by testing whether each correlation coeﬃcient is nonzero at 0.05 signiﬁcance level; the p-values
were obtained using the Fisher’s Z-transformation for correlation coeﬃcients. The MISOCP with
true and correlation matrix superstructures are denoted as MISOCP-True and MISOCP-CorEst,
respectively, in Table 6. A time limit of 50m (seconds), λ = 2 log(n) and the Gurobi RGAP of 0.01
are imposed across the experiments.

Measures of performance of the benchmark algorithms are summarized in columns EqVarDAG-
TD, EqVarDAG-HD-TD, and EqVarDAG-HD-BU of Table 6. The column Time reports the solution
time in seconds. For all datasets, the true networks can be used to evaluate the quality of the
estimated networks. We report SHD, TPR, and FPR for all the estimated networks. Given that
the true causal network cannot be recovered in the setting of non-identiﬁable data (NID), we also
report the structural SHD between the undirected skeleton of the true DAG and the corresponding
skeleton of estimated network; this is denoted as SHDs in Table 6.

We observe that most of the EqVarDAG methods solve the problem within a second. With
respect to the quality of the estimation, EqVarDAG-TD provides better performance in SHD com-
pared to EqVarDAG-HD-TD and EqVarDAG-HD-BU. The column RGAP reports the relative gap
at early termination. The symbol (*) denotes that the problem is solved to the optimality toler-
ance. Compared with the benchmarks, MISOCP with a CorEst or true superstructure requires
longer solution times; however, MISOCP consistently provides high SHD and SHDs scores in every
network. Moreover, MISOCP is able to provide the best estimation among all methods in most of

25

the networks.

Finally, we highlight that in the non-identiﬁable datasets (NID), MISOCP clearly outperforms
the benchmarks. This is, of course, not surprising, as the benchmark algorithms rely on the identi-
ﬁability assumption and are not guaranteed to work if this assumption is violated. In contrast, in
this case, MISOCP is guaranteed to ﬁnd a member of the Markov equivalence class.

7 Conclusion

In this paper, we study the problem of learning an optimal directed acyclic graph (DAG) from
continuous observational data, where the causal eﬀect among the random variables is linear. The
central problem is a quadratic optimization problem with regularization. We present a mixed-integer
second order conic program (MISOCP) which entails a tighter relaxation than existing formulations
with linear constraints. Our numerical results show that MISOCP can successfully improve the
lower bound and results in better optimality gap when compared with other formulations based
on big-M constraints, especially for dense and large instances. Moreover, we establish an early
stopping criterion under which we can terminate branch-and-bound and achieve a solution which
is asymptotically optimal. In addition, we show that our method outperforms two state-of-the-art
algorithms, especially on non-identiﬁable datasets.

Acknowledgments

We thank the AE and three anonymous reviewers for their detailed comments that improved the
paper. Simge K¨u¸c¨ukyavuz and Linchuan Wei were supported, in part, by ONR grant N00014-
19-1-2321 and NSF grant CIF-2007814. Ali Shojaie was supported by NSF grant DMS-1561814
and NIH grant R01GM114029. Hao-Hsiang Wu is supported, in part, by MOST Taiwan grant
109-2222-E-009-005-MY2.

A Alternative linear encodings of constraints (13b)

There are several ways to ensure that the estimated graph does not contain any cycles. The ﬁrst
approach is to add a constraint for each cycle in the graph, so that at least one arc in this cycle
must not exist in G(B). A cutting plane (CP) method is used to solve such a formulation which
may require generating an exponential number of constraints. In particular, let C be the set of all
possible directed cycles and CA ∈ C be the set of arcs deﬁning a cycle. The CP formulation removes
cycles by imposing the following constraints for (13b)

CP

(cid:88)

(j,k)∈ CA

gjk ≤ |CA| − 1,

∀CA ∈ C.

(23)

This formulation has exponentially many constraints.

Another way to rule out cycles is by imposing constraints such that the nodes follow a topological
order [38]. A topological ordering is a unique ordering of the nodes of a graph from 1 to m such
that the graph contains an arc (j, k) if node j appears before node k in the order. We refer to this
−→
E
formulation as topological ordering (TO). Deﬁne decision variables zjk ∈ {0, 1} for all (j, k) ∈
and ors ∈ {0, 1} for all r, s ∈ {1, . . . , m}. The variable zjk takes value 1 if there is an arc (j, k) in

26

the network, and ors takes value 1 if the topological order of node r equals s. The TO formulation
rules out cycles in the graph by the following constraints

−→
E ,
−→
E ,

TO gjk ≤ zjk,

∀(j, k) ∈

zjk − mzkj ≤

(cid:88)

s∈V

(cid:88)

s∈V
(cid:88)

r∈V

ors = 1

ors = 1

s (oks − ojs), ∀(j, k) ∈

∀r ∈ V,

∀s ∈ V.

(24a)

(24b)

(24c)

(24d)

This formulation has O(m2) variables and O(|

−→
E |) constraints.

References

[1] Constantin F Aliferis, Alexander Statnikov, Ioannis Tsamardinos, Subramani Mani, and Xeno-
fon D Koutsoukos. Local causal and Markov blanket induction for causal discovery and feature
selection for classiﬁcation part I: Algorithms and empirical evaluation. Journal of Machine
Learning Research, 11(Jan):171–234, 2010.

[2] Bryon Aragam and Qing Zhou. Concave penalized estimation of sparse Gaussian Bayesian

networks. Journal of Machine Learning Research, 16:2273–2328, 2015.

[3] Alper Atamt¨urk and Andres G´omez. Rank-one convexiﬁcation for sparse regression. arXiv

preprint arXiv:1901.10334, 2019.

[4] Mark Barlett and James Cussens. Advances in bayesian network learning using integer pro-
gramming. In Proceedings of the Twenty-Ninth Conference on Uncertainty in Artiﬁcial Intel-
ligence, UAI’13, pages 182–191, Arlington, Virginia, USA, 2013. AUAI Press.

[5] Mark Bartlett and James Cussens.

Integer linear programming for the Bayesian network

structure learning problem. Artiﬁcial Intelligence, 244:258–271, 2017.

[6] Dimitris Bertsimas and Bart Van Parys. Sparse high-dimensional regression: Exact scalable

algorithms and phase transitions. The Annals of Statistics, 48(1):300–323, 2020.

[7] Dimitris Bertsimas, Angela King, and Rahul Mazumder. Best subset selection via a modern

optimization lens. The Annals of Statistics, 44(2):813–852, 2016.

[8] Peter B¨uhlmann and Sara A van de Geer. Statistics for high-dimensional data: methods, theory

and applications. Springer, 2011.

[9] Wenyu Chen, Mathias Drton, and Y Samuel Wang. On causal discovery with an equal-variance

assumption. Biometrika, 106(4):973–980, 09 2019.

[10] XT Cui, XJ Zheng, SS Zhu, and XL Sun. Convex relaxations and MIQCQP reformulations for
a class of cardinality-constrained portfolio selection problems. Journal of Global Optimization,
56(4):1409–1423, 2013.

27

[11] James Cussens. Maximum likelihood pedigree reconstruction using integer programming. In

WCB@ ICLP, pages 8–19, 2010.

[12] James Cussens. Bayesian network learning with cutting planes. In Proceedings of the Twenty-
Seventh Conference on Uncertainty in Artiﬁcial Intelligence, UAI’11, pages 153–160, Arlington,
Virginia, USA, 2011. AUAI Press.

[13] James Cussens, David Haws, and Milan Studen`y. Polyhedral aspects of score equivalence in
Bayesian network structure learning. Mathematical Programming, 164(1-2):285–324, 2017.

[14] James Cussens, Matti J¨arvisalo, Janne H Korhonen, and Mark Bartlett. Bayesian network
structure learning with integer programming: Polytopes, facets and complexity. J. Artif.
Intell. Res.(JAIR), 58:185–229, 2017.

[15] Hongbo Dong, Kun Chen, and Jeﬀ Linderoth. Regularization vs. relaxation: A conic opti-

mization perspective of statistical variable selection. arXiv preprint arXiv:1510.06083, 2015.

[16] Mathias Drton and Marloes H Maathuis. Structure learning in graphical modeling. Annual

Review of Statistics and Its Application, 4:365–393, 2017.

[17] Antonio Frangioni and Claudio Gentile. Perspective cuts for a class of convex 0–1 mixed integer

programs. Mathematical Programming, 106(2):225–236, 2006.

[18] Antonio Frangioni and Claudio Gentile. SDP diagonalizations and perspective cuts for a class

of nonseparable MIQP. Operations Research Letters, 35(2):181–185, 2007.

[19] Antonio Frangioni and Claudio Gentile. A computational comparison of reformulations of the
perspective relaxation: SOCP vs. cutting planes. Operations Research Letters, 37(3):206–210,
2009.

[20] Antonio Frangioni, Claudio Gentile, Enrico Grande, and Andrea Paciﬁci. Projected perspective
reformulations with applications in design problems. Operations Research, 59(5):1225–1232,
2011.

[21] Fei Fu and Qing Zhou. Learning sparse causal Gaussian networks with experimental interven-
tion: regularization and coordinate descent. Journal of the American Statistical Association,
108(501):288–300, 2013.

[22] Tian Gao, Ziheng Wang, and Qiang Ji. Structured feature selection. In Proceedings of the

IEEE International Conference on Computer Vision, pages 4256–4264, 2015.

[23] Asish Ghoshal and Jean Honorio. Information-theoretic limits of Bayesian network structure
learning. In Aarti Singh and Jerry Zhu, editors, Proceedings of the 20th International Con-
ference on Artiﬁcial Intelligence and Statistics, volume 54 of Proceedings of Machine Learning
Research, pages 767–775, Fort Lauderdale, FL, USA, 20–22 Apr 2017. PMLR.

[24] Asish Ghoshal and Jean Honorio. Learning linear structural equation models in polynomial
time and sample complexity. In Amos Storkey and Fernando Perez-Cruz, editors, Proceedings of
the Twenty-First International Conference on Artiﬁcial Intelligence and Statistics, volume 84
of Proceedings of Machine Learning Research, pages 1466–1475. PMLR, 09–11 Apr 2018.

28

[25] Andr´es G´omez and O Prokopyev. A mixed-integer fractional optimization approach to best

subset selection. INFORMS Journal on Computing, 33(2):551–565, 2021.

[26] Sung Won Han, Gong Chen, Myun-Seok Cheon, and Hua Zhong. Estimation of directed acyclic
graphs through two-stage adaptive lasso for gene network inference. Journal of the American
Statistical Association, 111(515):1004–1019, 2016.

[27] Raymond Hemmecke, Silvia Lindner, and Milan Studen`y. Characteristic imsets for learning
International Journal of Approximate Reasoning, 53(9):1336–

Bayesian network structure.
1349, 2012.

[28] Mikko Koivisto. Advances in exact bayesian structure discovery in bayesian networks.

In
Proceedings of the Twenty-Second Conference on Uncertainty in Artiﬁcial Intelligence, UAI’06,
pages 241–248, Arlington, Virginia, USA, 2006. AUAI Press.

[29] Nevena Lazic, Christopher Bishop, and John Winn. Structural expectation propagation (SEP):
Bayesian structure learning for networks with latent variables. In Artiﬁcial Intelligence and
Statistics, pages 379–387, 2013.

[30] Peijing Liu, Salar Fattahi, Andr´es G´omez, and Simge K¨u¸c¨ukyavuz. A graph-based de-
arXiv preprint

composition method for convex quadratic optimization with indicators.
arXiv:2110.12547, 2021.

[31] Po-Ling Loh and Peter B¨uhlmann. High-dimensional learning of linear causal networks via
inverse covariance estimation. Journal of Machine Learning Research, 15(1):3065–3105, 2014.

[32] Hasan Manzour, Simge K¨u¸c¨ukyavuz, Hao-Hsiang Wu, and Ali Shojaie. Integer programming
for learning directed acyclic graphs from continuous data. INFORMS Journal on Optimization,
3(1):46–73, 2021.

[33] Nicolai Meinshausen and Peter B¨uhlmann. High-dimensional graphs and variable selection

with the lasso. The Annals of Statistics, 34(3):1436–1462, 2006.

[34] Chris. J. Oates, Jim Q. Smith, and Sach Mukherjee. Estimating causal structure using condi-

tional DAG models. Journal of Machine Learning Research, 17(54):1–23, 2016.

[35] Chris J Oates, Jim Q Smith, Sach Mukherjee, and James Cussens. Exact estimation of multiple

directed acyclic graphs. Statistics and Computing, 26(4):797–811, 2016.

[36] Temel ¨Oncan, ˙I Kuban Altınel, and Gilbert Laporte. A comparative analysis of several asym-
metric traveling salesman problem formulations. Computers & Operations Research, 36(3):
637–654, 2009.

[37] Sascha Ott, Seiya Imoto, and Satoru Miyano. Finding optimal models for small gene networks.
In Paciﬁc Symposium on Biocomputing, volume 9, pages 557–567. World Scientiﬁc, 2004.

[38] Young Woong Park and Diego Klabjan. Bayesian network learning via topological order.

Journal of Machine Learning Research, 18(99):1–32, 2017.

[39] Young Woong Park and Diego Klabjan. Subset selection for multiple linear regression via

optimization. Journal of Global Optimization, 77(3):543–574, Jul 2020.

29

[40] Judea Pearl. Causal inference in statistics: An overview. Statistics Surveys, 3:96–146, 2009.

[41] Jonas Peters and Peter B¨uhlmann. Identiﬁability of Gaussian structural equation models with

equal error variances. Biometrika, 101(1):219–228, 2013.

[42] Mert Pilanci, Martin J Wainwright, and Laurent El Ghaoui. Sparse learning via Boolean

relaxations. Mathematical Programming, 151(1):63–87, 2015.

[43] Garvesh Raskutti and Caroline Uhler. Learning directed acyclic graph models based on sparsest

permutations. Stat, 7(1):e183, 2018.

[44] Takumi Saegusa and Ali Shojaie. Joint estimation of precision matrices in heterogeneous

populations. Electronic Journal of Statistics, 10(1):1341–1392, 2016.

[45] Ali Shojaie and George Michailidis. Penalized likelihood methods for estimation of sparse

high-dimensional directed acyclic graphs. Biometrika, 97(3):519–538, 2010.

[46] Tomi Silander and Petri Myllym¨aki. A simple approach for ﬁnding the globally optimal
In Conference on Uncertainty in Artiﬁcial Intelligence, pages

bayesian network structure.
445–452, 2006.

[47] Liam Solus, Yuhao Wang, and Caroline Uhler. Consistency guarantees for greedy permutation-

based causal inference algorithms. Biometrika, 108(4):795–814.

[48] Arjun Sondhi and Ali Shojaie. The reduced PC-algorithm: Improved causal structure learning

in large random networks. Journal of Machine Learning Research, 20(164):1–31, 2019.

[49] Peter Spirtes, Clark N Glymour, and Richard Scheines. Causation, prediction, and search.

MIT press, 2000.

[50] Milan Studen`y and David C Haws. On polyhedral approximations of polytopes for learning

Bayesian networks. Journal of Algebraic Statistics, 4(1), 2013.

[51] Caroline Uhler, Garvesh Raskutti, Peter B¨uhlmann, and Bin Yu. Geometry of the faithfulness

assumption in causal inference. The Annals of Statistics, 41(2):436–463, 2013.

[52] Sara van de Geer and Peter B¨uhlmann. (cid:96)0-penalized maximum likelihood for sparse directed

acyclic graphs. The Annals of Statistics, 41(2):536–567, 2013.

[53] Roman Vershynin. How close is the sample covariance matrix to the actual covariance matrix?

Journal of Theoretical Probability, 25(3):655–686, 2012.

[54] Linchuan Wei, Andr´es G´omez, and Simge K¨u¸c¨ukyavuz. On the convexiﬁcation of constrained
quadratic optimization problems with indicator variables.
In Daniel Bienstock and Gia-
como Zambelli, editors, Integer Programming and Combinatorial Optimization, pages 433–447,
Cham, 2020. Springer International Publishing.

[55] Linchuan Wei, Alper Atamt¨urk, Andr´es G´omez, and Simge K¨u¸c¨ukyavuz. On the convex hull
of convex quadratic optimization problems with indicators. arXiv preprint arXiv:2201.00387,
2021.

30

[56] Linchuan Wei, Andr´es G´omez, and Simge K¨u¸c¨ukyavuz.

Ideal formulations for constrained
convex optimization problems with indicator variables. Mathematical Programming, 192(1):
57–88, 2022.

[57] Jing Xiang and Seyoung Kim. A* lasso for learning a sparse Bayesian network structure for
continuous variables. In Advances in Neural Information Processing Systems, pages 2418–2426,
2013.

[58] Weijun Xie and Xinwei Deng. Scalable algorithms for the sparse ridge regression. SIAM

Journal on Optimization, 30(4):3359–3386, 2020.

[59] Cun-Hui Zhang. Nearly unbiased variable selection under minimax concave penalty. The

Annals of Statistics, 38(2):894–942, 2010.

[60] Xiaojin Zheng, Xiaoling Sun, and Duan Li.

Improving the performance of MIQP solvers
for quadratic programs with cardinality and minimum threshold constraints: A semideﬁnite
program approach. INFORMS Journal on Computing, 26(4):690–703, 2014.

[61] Xun Zheng, Bryon Aragam, Pradeep Ravikumar, and Eric P. Xing. DAGs with NO TEARS:
continuous optimization for structure learning. In Proceedings of the 32nd International Con-
ference on Neural Information Processing Systems, NIPS’18, pages 9492–9503, Red Hook, NY,
USA, 2018. Curran Associates Inc.

31

.
]
4
2
[

d
n
a

]
9
[

f
o

s
d
o
h
t
e
m
G
A
D
r
a
V
q
E
t
r
a
-
e
h
t
-
f
o
-
e
t
a
t
s

e
h
t

d
n
a
P
C
O
S
I
M
n
e
e
w
t
e
b

n
o
s
i
r
a
p
m
o
c

e
h
T

:
6

e
l
b
a
T

R
P
F

R
P
T

s
D
H
S

D
H
S

P
A
G
R

e
m
T

i

R
P
F

R
P
T

s
D
H
S

D
H
S

P
A
G
R

e
m
T

i

R
P
F

R
P
T

s
D
H
S

D
H
S

e
m
T

i

-

e
u
r
T
P
C
O
S
I
M

-

t
s
E
r
o
C
P
C
O
S
I
M

-

D
T
G
A
D
r
a
V
q
E

0

0

0

0

0

0

0

0

0

0

0

0

0

2
0
0
.

1
0
0
.

1
0
0
.

1
0
0
.

3
0
0
.

2
0
0
.

2
0
0
.

6
0
0
.

6
0
0
.

4
1
0
.

0

1

1

1

1

1

1

1

1

1

1

1

1

3
3
8
.

5
7
8
.

9
0
9
.

4
4
9
.

7
4
9
.

4
4
9
.

5
5
9
.

2
6
9
.

8
6
8
.

5
8
9
.

6
9
.

6
9
.

0

0

0

0

0

0

0

0

0

0

0

0

1

3

2

1

1

2

1

3

4

0

0

0

0

0

0

0

0

0

0

0

0

1

6

4

2

4

8

1

6

6

6
1

8

8
1

2
2

5
1

6
3

*

*

*

*

*

*

*

*

*

1
≤

1
≤

1
≤

4

1

1
≤

1
≤

6
7
1

2

6
3
0
.

2
5
0
.

6
9
0
.

0
5
3
1
≥

0
0
8
2
≥

0
0
5
3
≥

*

*

*

*

*

*

*

*

1
≤

1
≤

1
≤

2
1

2

1
≤

1
≤

2

5
5
0
.

2
6
0
.

6
9
0
.

2
1
1
.

0
5
3
1
≥

0
5
3
1
≥

0
0
8
2
≥

0
0
5
3
≥

0

0

0

0

0

0

0

0

0

0

4
0
0
.

2
5
0
.

1
0
0
.

1
0
0
.

2
0
0
.

2
0
0
.

3
0
0
.

0

0

3
0
0
.

3
0
0
.

4
0
0
.

8
0
0
.

1
1
0
.

1

1

1

1

1

1

1

1

1

1

5
5
9
.

8
7
8
.

3
3
8
.

5
7
8
.

9
0
9
.

8
8
.

3
3
8
.

7
4
9
.

4
4
9
.

9
0
9
.

3
2
9
.

3
5
8
.

5
8
9
.

5
3
9
.

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

2
2
1

2
1

4
3
1

3
1

1

2

1

5

4

5

1

5

9

5
1

1
1

3
2

1

4

2

7

7

8

1

8

1
1

9
1

0
2

3
3

5
0
.

*

1
0
1
.

*

8
4
0
.

6
1
2
.

7
5
1
.

1
2
.

1
7
3
.

*

*

*

9
2
0
.

*

2
6
0
.

*

1
9
1
.

1
1
1
.

6
5
1
.

9
9
1
.

2
0
.

*

*

*

0
5
7
≥

5
5
1

0
0
8
≥

5

0
0
0
1
≥

0
5
3
1
≥

0
5
3
1
≥

0
0
8
2
≥

0
0
5
3
≥

1
≤

1
≤

1
≤

0
5
7
≥

3
4

0
0
8
≥

8

0
0
0
1
≥

0
5
3
1
≥

0
5
3
1
≥

0
0
8
2
≥

0
0
5
3
≥

1
≤

1
≤

1
≤

1
0
0
.

0

0

0

1
0
0
.

0

0

0

0

0

0

0

0

2
0
0
.

1
0
0
.

3
0
0
.

1
0
0
.

4
0
0
.

0

7
0
0
.

5
0
0
.

7
0
0
.

2
2
0
.

5
1
0
.

1

1

1

1

1

1

1

1

1

6
5
9
.

5
8
9
.

2
9
9
.

3
3
8
.

5
7
8
.

9
0
9
.

4
4
9
.

5
9
8
.

4
4
9
.

5
5
9
.

6
9
.

5
1
6
9
.

5
6
7
.

4
9
8
.

2
6
8
.

0

0

0

2

0

0

0

1

0

3

1

1

1

4

2

7

1

6

1

0
1

0
1

4
2

0
4

0
4

0

0

0

2

0

0

0

1

0

3

1

1

1

6

4

8

4

2
1

1

7
1

3
1

2
3

9
5

2
5

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

2

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

2

2

-

-

D
T
D
H
G
A
D
r
a
V
q
E

-

-

U
B
D
H
G
A
D
r
a
V
q
E

R
P
F

1
0
0
.

1
0
0
.

1
0
0
.

1
0
0
.

3
0
0
.

2
0
0
.

4
0
0
.

5
0
0
.

7
0
0
.

8
0
0
.

9
2
0
.

1
0
0
.

2
0
0
.

3
0
0
.

3
0
0
.

4
0
0
.

7
0
0
.

2
0
0
.

1
1
0
.

9
0
0
.

0
1
0
.

8
3
0
.

1
3
0
.

0

R
P
T

s
D
H
S

D
H
S

e
m
T

i

1

1

1

1

1

1

1

1

1

5
8
9
.

8
6
9
.

1

5
7
8
.

9
0
9
.

6
9
.

4
4
9
.

5
9
8
.

4
4
9
.

5
5
9
.

1
8
9
.

2
8
8
.

2
9
9
.

7
9
.

1

3

0

1

2

2

6

4

9

1
1

7
1

9
1

0
7

1

4

5

7

7

4
1

6

0
2

9
1

4
2

0
7

1
6

3

0

1

2

2

6

4

9

1
1

7
1

9
1

0
7

2

6

7

8

0
1

0
2

6

7
2

3
2

2
3

0
9

3
7

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

2

2

1
1

9
1

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

2

2

8

6
1

R
P
F

1
0
0
.

2
0
0
.

5
0
0
.

2
0
0
.

6
0
0
.

4
0
0
.

7
0
0
.

1
1
0
.

1
0
.

3
3
0
.

2
6
0
.

2
0
0
.

6
0
0
.

3
0
0
.

7
0
0
.

7
0
0
.

5
0
0
.

5
1
0
.

7
1
0
.

4
0
0
.

3
4
0
.

8
4
0
.

1
0
.

0

R
P
T

s
D
H
S

D
H
S

e
m
T

i

)

m
(
k
r
o
w
t
e
N

a
t
a
D

1

1

1

1

1

1

1

1

2
6
9
.

7
7
9
.

5
8
9
.

9
5
9
.

5
7
8
.

9
0
9
.

4
4
9
.

5
9
8
.

4
4
9
.

5
5
9
.

6
9
.

1

1

1
7
9
.

7
9
.

9
1
9
9
.

3

0

4

8

4

2
1

9

3
1

3
2

5
2

0
7

3

0

5

1
1

5

5
1

0
1

6
1

7
2

5
2

8
7

9
3
1

7
4
1

3
1

3

6

9
1

2
1

4
1

1
1

8
2

2
3

1
1

8
8

5
9

6
1

4

7

4
2

7
1

9
1

2
1

6
3

0
4

2
1

3
0
1

0
1
1

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

2

2

0
1

7
1

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

1
≤

2

2

8

4
1

)
5
1
(
l
l
a
m
S
s
n
I

)
9
(
g
n

i
l

w
o
B

)
6
1
(
d
u
o
l
C

)
4
1
(
n

i
a
R

)
8
1
(
l
e
n
n
u
F

)
0
2
(
y
x
a
l
a
G

)
7
2
(
e
c
n
a
r
u
s
n
I

)
7
2
(
s
r
o
t
c
a
F

)
6
5
(
r
e
d
n
ﬁ

l
i
a
H

)
0
7
(
2
r
a
p
e
H

)
6
(
p
e
s
D

)
8
(
a
i
s
A

)
5
1
(
l
l
a
m
S
s
n
I

)
9
(
g
n

i
l

w
o
B

)
6
1
(
d
u
o
l
C

)
4
1
(
n

i
a
R

)
8
1
(
l
e
n
n
u
F

)
0
2
(
y
x
a
l
a
G

)
7
2
(
e
c
n
a
r
u
s
n
I

)
7
2
(
s
r
o
t
c
a
F

)
6
5
(
r
e
d
n
ﬁ

l
i
a
H

)
0
7
(
2
r
a
p
e
H

)
6
(
p
e
s
D

)
8
(
a
i
s
A

D

I

D
N

I

32

