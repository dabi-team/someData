2
2
0
2

b
e
F
7
1

]
E
N
.
s
c
[

1
v
7
9
8
8
0
.
2
0
2
2
:
v
i
X
r
a

Implementing Spiking Neural Networks on
Neuromorphic Architectures: A Review

Phu Khanh Huynh, M. Lakshmi Varshika, Ankita Paul, Murat
Isik, Adarsha Balaji, Anup Das
Drexel University, Philadelphia, PA 19104, USA

E-mail: anup.das@drexel.edu

Abstract. Recently, both industry and academia have proposed several diﬀerent
neuromorphic systems to execute machine learning applications that are designed
using Spiking Neural Networks (SNNs). With the growing complexity on design and
technology fronts, programming such systems to admit and execute a machine learning
application is becoming increasingly challenging. Additionally, neuromorphic systems
are required to guarantee real-time performance, consume lower energy, and provide
tolerance to logic and memory failures. Consequently, there is a clear need for system
software frameworks that can implement machine learning applications on current and
emerging neuromorphic systems, and simultaneously address performance, energy, and
reliability. Here, we provide a comprehensive overview of such frameworks proposed for
both, platform-based design and hardware-software co-design. We highlight challenges
and opportunities that the future holds in the area of system software technology for
neuromorphic computing.

1. Introduction

Neuromorphic systems are integrated circuits designed to mimic the event-driven
computations in a mammalian brain [1]. They enable execution of Spiking Neural
Networks (SNNs), which are computation models designed using spiking neurons and
bio-inspired learning algorithms [2]. SNNs enable powerful computations due to their
spatio-temporal information encoding capabilities [3]. SNNs can implement diﬀerent
machine learning approaches such as supervised learning [4], unsupervised learning [5],
reinforcement learning [6], and lifelong learning [7].

In an SNN, neurons are connected via synapses. A neuron can be implemented
as an integrate-and-ﬁre (IF) logic [8], which is illustrated in Figure 1 (left). Here, an
input current spike U (t) from a pre-synaptic neuron raises the membrane voltage of a
post-synaptic neuron. When this voltage crosses a threshold Vth, the IF logic emits a
spike, which propagates to is post-synaptic neuron. Figure 1 (middle) illustrates the
membrane voltage due to input spike trains. Moments of threshold crossing, i.e., the
ﬁring times are illustrated in Figure 1 (right).

 
 
 
 
 
 
Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review

2

Figure 1: A leaky integrate-and-ﬁre (LIF) neuron with current input U (t) (left). The
membrane potential over time of the neuron (middle). The spike output of the neuron
representing its ﬁring times (right).

SNNs can be implemented on a CPU or a GPU. However, due to their limited
memory bandwidth, performance of SNNs on such devices is usually slow and the
power overhead is high. In SNNs, neural computations and synaptic storage are tightly
integrated. They present a highly-distributed computing paradigm which cannot be
leveraged by CPU and GPU devices. A neuromorphic hardware can eliminate the
performance and energy bottlenecks of CPUs and GPUs, thanks to their low-power
analog and digital neuron designs, distributed in-place neural computation and synaptic
storage architecture, and the use of Non-Volatile Memory (NVM) for high-density
synaptic storage [9, 10, 11, 12, 13, 14, 15]. Due to their low energy overhead, a
neuromorphic hardware can implement machine learning tasks on energy-constrained
embedded systems and edge devices of the Internet-of-Things (IoT) [16].

A neuromorphic hardware is implemented as a tiled-based architecture [17], where
tiles are interconnected via a shared interconnect. A tile may include 1) a neuromorphic
core, which implements neuron and synapse circuitries, 2) peripheral logic to encode and
decode spikes into Address Event Representation (AER), and 3) a network interface
to send and receive AER packets from the interconnect. Switches are place on the
interconnect to route AER packets to their destination tiles. Table 1 illustrates the
capacity of some recent neuromorphic hardware cores.

Table 1: Capacity of some recent neuromorphic systems [18].

ODIN µBrain DYNAPs BrainScaleS SpiNNaker Neurogrid Loihi TrueNorth

[19]

# Neurons/core

256

[20]

336

# Synapses/core

64K

38K

# Cores/chip

# Chips/board

# Neurons

# Synapses

1

1

256

256

1

1

336

336

[21]

256

16K

1

4

1K

65K

[22]

512

128K

1

352

4M

1B

[23]

36K

2.8M

144

56

2.5B

200B

[24]

65K

8M

128

16

1M

[25]

130K

[26]

1M

130M

256M

128

768

100M

4096

4096

4B

1T

16B

100B

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review

3

NVM devices present an attractive option for implementing synaptic storage due to
their demonstrated potential for low-power multilevel operations and high integration
densities [27, 28, 29, 30]. Recently, several NVMs are being explored for neuromorphic
computing: Oxide-based Resistive Random Access Memory (ReRAM) [31], Phase
Change Memory (PCM) [32], Ferroelectric RAM [33], and Spin-Transfer Torque
Magnetic or Spin-Orbit-Torque RAM (STT- and SoT-MRAM) [34]. Table 2 shows
some recent neuromorphic hardware demonstrations integrating NVMs.‡

Table 2: Neuromorphic hardware integrating NVMs.

NVM Technology References

PCM

ReRAM

FeRAM

STT-MRAM

[43]

[44]

[45]

[46]

Figure 2 shows a neuromorphic hardware with tiles (C) and switches (S). For
illustration purposes, we show each tile as a crossbar, where NVM cells are organized
in a two dimensional grid formed using horizontal wordlines and vertical bitlines.

Figure 2: A representative tile-based neuromorphic hardware [47].

The ﬁgure also illustrates a small example of implementing an SNN on a crossbar.
Synaptic weights w1 and w2 are programmed as conductance of NVM cells P1 and P2,
respectively. The output spike voltages, v1 from N1 and v2 from N2, inject currents into
the crossbar, which are obtained by multiplying a pre-synaptic neuron’s output spike
voltage with the NVM cell’s conductance (Ohm’s law). Current summations along

‡ Beside neuromorphic computing, NVMs are also used as main memory for conventional
computing [35, 36, 37, 38, 39, 40, 41, 42].

CSSSSSSSSSCCCCCCCCCrossbarNVMImplementing Spiking Neural Networks on Neuromorphic Architectures: A Review

4

columns are performed in parallel (Kirchhoﬀ’s current law), and they implement the
sum (cid:80)

j wivi (i.e., neuron excitations).

To cope with the growing complexity of neuromorphic systems, challenges in
integrating emerging NVM technologies, and faster time-to-market pressure, eﬃcient
design methodologies are needed. We highlight the following two key concepts that are
likely to address the design issues postulated above.

• Platform-based Design:

In this design methodology, a hardware platform
is abstracted from its system software, making the hardware and software
developments orthogonal to allow a more eﬀective exploration of alternative
solutions [48]. Platform-based design methodology facilitates the reuse of the
system software for many diﬀerent hardware platforms.

• Hardware-Software Co-design:

In this design methodology, a hardware
platform and its system software are concurrently designed to exploit their
synergism in order to achieve system-level design objectives [49]. The system
software in this case is tailored for the hardware platform.

In this paper, we provide a survey of these design methodologies for neuromorphic

computing, focusing mainly on the recent advances on the software technology front.

2. Platform-based Design

Platform-based design has emerged as an important design style for the electronics
industry [48, 50, 51, 52, 53, 54]. Platform-based design separates parts of the system
design process such that they can be independently optimized for diﬀerent metrics
such as performance, power, cost, and reliability. Platform-based design methodology
can also be adopted for neuromorphic system design [55], where the software can be
optimized independently from the underlying neuromorphic hardware platform.

As in a conventional computing system, the abstractions for a neuromorphic
system include 1) the application software, 2) the system software, and 3) the
hardware [56, 57, 58].
In the context of neuromorphic computing, the application
software includes applications designed using diﬀerent SNN topologies such as mult-layer
perceptron (MLP) [59], convolutional neural network (CNN) [60] and recurrent neural
network (RNN) [61], and bio-inspired learning algorithms such spike timing dependant
plasticity (STDP) [62], long-term plasticity (LTP) [63], and FORCE [64]. The system
software includes the equivalent of a compiler and a run-time manager to execute SNN
applications on the hardware. Finally, the hardware abstraction includes the platform,
which consists of a neuromorphic hardware.

We focus on the system software abstraction and highlight key optimization
In Section 2.1, we provide an overview of the

techniques proposed in literature.
uniqueness of system software concepts for neuromorphic computing.

For neuromorphic systems, performance, energy, and reliability are the driving
metrics for the system software optimization. Therefore, we categorize state-of-the-art

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review

5

approaches into 1) performance/energy-oriented software approaches (see Section 2.2)
and 2) thermal/reliability-oriented software approaches (see Section 2.3). Finally, we
highlight recent approaches that use high-level dataﬂow representations to estimate SNN
performance early in the platform design stage (see Section 2.4).

2.1. System Software Considerations for Neuromorphic Computing

In an SNN,
information is encoded in spikes that are communicated between
neurons [65]. We take the example of Inter Spike Interval (ISI) coding in SNNs. Let
{t1, t2, · · · , tK} denote a neuron’s ﬁring times in the time interval [0, T ], the average ISI of
this spike train is

K
(cid:88)

(ti − ti−1)/(K − 1).

I =

i=2

(1)

A change in ISI, called ISI distortion, impacts SNN performance. To illustrate
this, we use a small SNN in which three input neurons are connected to an output
neuron. Figure 3 illustrates the impact of ISI distortion on the output spike. In the top
sub-ﬁgure, a spike is generated at the output neuron at 22µs due to spikes from input
neurons. In the bottom sub-ﬁgure, the second spike from input 3 is delayed, i.e., it has
an ISI distortion. Due to this distortion, there is no output spike generated. Missing
spikes can impact inference quality, as spikes encode information in SNNs.

Figure 4 shows the impact of ISI distortion at the application level. We consider
an image smoothing application implemented with an SNN model using the CARLsim
simulator [67]. Figure 4a shows the input image, which is fed to the SNN. Figure 4b
shows the output of the image smoothing application with no ISI distortion. Peak
signal-to-noise ratio (PSNR) of the output with reference to the input is 20. Figure 4c
shows the output with ISI distortion. PSNR of this output is 19. A reduction in PSNR
indicates that the output image quality with ISI distortion is lower.

This background motivates the following. A system software for neuromorphic
hardware needs to consider application property, especially the spike timing and
their distortion to ensure that the SNN performance obtained on the hardware
implementation matches closely to what is simulated in an application-level simulator
such as CARLsim [67], NEST [68], Brian [69], and NEURON [70].

Implementation-wise, a system software for neuromorphic hardware must also
limited
incorporate hardware constraints, such as constrained neural architecture,
neuron and synapse capacities, and limited fanin per neuron. We take the architecture
of a crossbar [71, 72, 73, 74, 75, 76, 77, 78, 79], which is commonly used to implement
neuromorphic hardware platforms. In a crossbar, bitlines and wordlines are organized
in a grid with memory cells connected at their crosspoints to store synaptic weights.
Neuron circuitries are implemented along bitlines and wordlines. A crossbar can
accommodate only a limited number of pre-synaptic connections per post-synaptic
neuron. To illustrate this, Figure 5 shows three examples of implementing neurons
on a 4 × 4 crossbar. The left sub-ﬁgure shows the implementation of a 4-input neuron

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review

6

Figure 3: Impact of ISI distortion on accuracy. Top sub-ﬁgure shows a scenario where
an output spike is generated based on the spikes received from the three input neurons.
Bottom sub-ﬁgure shows a scenario where the second spike from neuron 3 is delayed.
There are no output spikes generated [66].

(a) Original Image.

(b) Output with no ISI
distortion (PSNR = 20).

(c) Output with ISI dis-
tortion (PSNR = 19).

Figure 4: Impact of ISI distortion on image smoothing.

on a crossbar. The neuron occupies all four input ports and one output port. The
middle sub-ﬁgure shows the implementation of a 3-input neuron, occupying three input
ports and one output port. Finally, the right sub-ﬁgure shows the implementation of

0510152530354020Time (us)OutputInput 3Input 2Input 1Neuron0510152530354020Time (us)OutputInput 3Input 2Input 1NeuronISI Distortionno output spikeImplementing Spiking Neural Networks on Neuromorphic Architectures: A Review

7

two two-input neurons, occupying four input ports and two output ports.

Figure 5: Implementation of a) one 4-input, b) one 3-input, and c) two 2-input neurons
on a 4 × 4 crossbar [80].

Crossbars are not the only type of neuromorphic architectures. The µBrain
architecture consists of three layers of neurons interconnected in a fully-connected
topology [20]. Both crossbars and µBrain suﬀer from limited fanin and fanout. Other
hardware architectures include decoupled design, where the processing logic is separated
from the synaptic storage [81, 82, 83, 84].

When an SNN needs to be implemented in hardware, the system software needs to

incorporate hardware constraints of the underlying platform.

2.2. System Software for Performance and Energy Optimization

We discuss key system software optimization approaches that address performance and
energy aspects of executing SNN applications on a neuromorphic hardware.

In [85], Varshika et al. propose a many-core hardware with fully-synthesizable
clockless µBrain cores [20]. In the proposed architecture cores are interconnected using
a segmented bus interconnect [86].
Internally, a µBrain core consists of three layers
of fully-connected neurons that can be programmed to implement operations such as
convolution, pooling, concatenation and addition, as well as irregular network topologies,
which are commonly found in many emerging spiking deep convolutional neural network
(SDCNN) models. To implement an SDCNN on the proposed many-core design, authors
propose SentryOS, a system software framework comprising of a compiler (SentryC)
and a run-time manager (SentryRT). SentryC is a clustering approach for SDCNNs
to generate sub-networks that can be implemented on diﬀerent cores of the hardware.
The sub-network generation works as follows. It sorts all neurons of an SDCNN model
based on their distances from output neurons. It groups all neurons with distance less

(a)(b)(c)Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review

8

than or equal to 2 into clusters considering the resource constraint of a neuromorphic
core. The constraint of 2 is due to the three-layered architecture of a µBrain core. In the
next iteration, it removes already clustered neurons from the model, recalculates neuron
distances, and groups remaining neurons to generate the next set of clusters. The process
is repeated until all neurons are clustered into sub-networks. By incorporating hardware
constraints, SentryC ensures that a sub-network can ﬁt onto the target core architecture.
The run-time manager (SentryRT) schedules these sub-networks onto cores. To do
so, it uses a real-time calculus to compute the execution end times of diﬀerent sub-
networks. Next, it discards execution times, retaining only the execution order of
sub-networks. Finally, it pipelines execution of sub-networks on cores and overlaps
execution of multiple input images on to hardware cores. By improving opportunities
for pipelining and exploiting data-level parallelism, SentryOS is shown to signiﬁcantly
improve the hardware throughput.

In [87], Amir et al. propose corelet, a programming paradigm for the TrueNorth
neuromorphic hardware [26]. This is developed to address the complexity associated
with designing neuromorphic algorithms that are consistent with the TrueNorth
architecture and programming them on hardware. The corelet paradigm is designed
using Corelet, an abstraction of a network of neurosynaptic cores that encapsulates
biological details and neuron connectivity, exposing only a network’s external inputs and
outputs to the programmer. Next, authors propose an object-oriented Corelet Language
for creating, composing, and decomposing corelets.
It consists of three fundamental
symbols – neuron, neurosynaptic core, and corelet. Connectors constitute the grammar
for composing the symbols into TrueNorth program. Authors show that using symbols
and grammar, it is possible to express any TrueNorth program. Next, authors introduce
the Corelet Library, a repository of more than 100 corelets to facilitate designing
TrueNorth programs. Finally, authors propose a Corelet Laboratory to implement
programs designed using corelet onto the TrueNorth hardware.

In [88], Lin et al. propose LCompiler, a compiler framework to map SNNs onto
Loihi neuromorphic hardware [25]. Authors show that the energy consumption in Loihi
is mostly due to updating the data structures used by local learning rules. Authors
report that the energy consumed due to on-chip learning is an order of magnitude
higher than the energy consumed in spike routing in Loihi. Authors show that the
energy cost associated in the learning updates is proportional to the number of data
structures allocated for an SNN instance, which depends on how an SNN is partitioned
into cores. Internally, LCompiler creates a dataﬂow graph consisting of logical entities
to describe an SNN instance. Such logical entities include compartments (main building
block of neurons), synapses, input maps, output axons, synaptic traces, and dendritic
accumulator. Overall, LCompiler operates in three steps. In the pre-processing step, it
validates SNN parameters, decomposes learning rules, transforms them into microcodes,
and translates the SNN topology (i.e., logical entities) into a connection matrix. In the
mapping step, it uses a greedy algorithm to map logical entities to hardware components
of Loihi cores, time-multiplexing the shared resources on a core. Finally, in the code

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review

9

generation step, it generates the binary bitstream for each Loihi core.

In [89], Galluppi et al. propose the PArtitioning and Conﬁguration MANager
(PACMAN), a framework to map SNNs to computational nodes on the SpiNNaker
system [23]. The key idea of PACMAN is to transform the high-level representation
of an SNN to a physical on-chip implementation. PACMAN holds three diﬀerent
representations of an SNN. In the Model-Level, an SNN is speciﬁed using a high-level
language such as PyNN [90] and Nengo [91].
In the System-Level, an SNN is split
into groups, where each group can ﬁt onto a SpiNNaker computational node. In the
Device-Level, a mapping is formed from groups to nodes of the SpiNNaker system. To
generate these representations, PACMAN performs four operations – 1) splitting, which
partitions an SNN into smaller sub-networks, 2) grouping, which combines sub-networks
to groups that can ﬁt onto a node of the hardware, 3) mapping, which allocates groups
to diﬀerent nodes, and 4) binary ﬁle generation, which creates the actual data binary
from a partitioned and mapped network.

In [92], Sugiarto et al. propose a framework to map general purpose applications
running as a task graph on to the SpiNNaker hardware, with the objective of reducing
the data traﬃc between diﬀerent SpiNNaker chips. The proposed framework uses the
task graph description given by XL-Stage program [93]. In mapping a task graph to the
hardware, each task is mapped to a SpiNNaker chip. To provide fault tolerance, multiple
copies of a task are generated and executed on diﬀerent SpiNNaker chips. Authors
propose to use an evolutionary algorithm to perform the mapping with the objective of
balancing the load on the system, while minimizing inter-chip data communication.

In [90], Davidson et al. propose a Python interface called PyNN to facilitate
faster application development and portability across diﬀerent research institutes.
PyNN provides a high-level abstraction of SNN models, promotes code sharing and
reuse, and provides a foundation for simulator-agnostic analysis, visualization and
data-management tools. Apart from serving as the Python front-end for diﬀerent
backend SNN simulators, PyNN supports mapping SNN models on the SpiNNaker [23],
BrainScaleS [22], and Loihi [25] neuromorphic hardware. To do this mapping, PyNN
ﬁrst partitions an SNN model into clusters and then executes them on diﬀerent cores of
the hardware. To do the partitioning, PyNN arbitrarily distributes neurons and synapses
of an SNN model while incorporating the resource constraint of a neuromorphic core.

In [91], Bekolay et al. propose Nengo, a Python framework for building, testing and
deploying SNNs to neuromorphic hardware. Nengo is based on the Neural Engineering
Framework (NEF) [94]. NEF uses three basic principles to construct large-scale neural
models. These principles are 1) representation, 2) transformation, and 3) dynamics. The
representation principle of NEF proposes that information is encoded by population
of neurons.
It represents information as time-varying vectors of real numbers. To
encode information, current is injected into neurons based on the vector being encoded.
The original encoded vector can be estimated using a decoding process, which involves
ﬁltering the spike trains using an exponentially decaying ﬁlter. Filtered spike trains
are summed together with weights that are determined by solving a least-square

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 10

minimization problem. The transformation principle of NEF proposes that the weight
matrix between two neural populations can be factored into two signiﬁcantly smaller
matrices that are computationally eﬃcient. Finally, the dynamics principle states that
with recurrent connections, vectors corresponding to neural populations are equivalent
to state variables in a dynamic system. Such a system can be analyzed using the
control theory and translated into neural circuitry using the principles of representation
and transformation. Nengo uses NEF to not only simulate a large-scale neural model
but also to map SNNs to custom FPGA (nengoFPGA) and on neuromorphic hardware
such as Loihi [25] and SpiNNaker [23].

In [95], Ji et al. propose a compiler to transform a trained SNN application to an
equivalent network that satisﬁes the hardware constraints. This compiler is targeted
for the TianJi [96] and PRIME [97] neuromorphic hardware platforms. There are four
steps to perform the compilation. In step 1, the compiler builds a dataﬂow graph based
on the given SNN information which includes trained parameters, network topology,
vertex information, and training dataset. In step 2, it transforms the dataﬂow graph
into an intermediate representation (IR) which consists of hardware-friendly operations.
In step 3, it performs graph tuning, which includes data re-encoding (to address the
hardware precision problem), expanding (where the IR is converted to operations
supported in the target hardware), and weight tuning (i.e., ﬁne tuning parameters to
minimize transformation errors). Finally in step 4, it maps the tuned graph to hardware,
exploiting a platform’s interconnection constraints. The mapping step assigns hardware
operations to physical cores of a hardware.

In [98], Gao et al. propose an approach to map neuronal models to a neuromorphic
hardware by exploiting dynamical system theory. Authors take a model-guided approach
to mapping neuronal models onto neuromorphic hardware. The overall approach is
as follows.
It starts from the ordinary diﬀerential equations (ODEs) that govern a
model’s state variables. Next it represents these state variables as currents. Next, the
current-mode subthreshold CMOS circuits are synthesized directly from these ODEs.
This approach yields combinations of circuit biases that are related to neural model
parameters through a set of hardware-speciﬁc mapping parameters. Finally, these
mapping parameters are translated into circuit parameters. Mapping parameters are
extracted using 1) a non-linear optimization using the model’s numerical simulation
as reference, and 2) an iterative approach to adjust the circuit’s operating current to
converge with the numerical simulation’s state variables. Authors demonstrate their
mapping strategy using quadratic and cubic Integrate and Fire neurons into the many-
core Neurogrid neuromorphic hardware [24].

In [99], Neftci et al. propose an approach to mapping SNNs on neuromorphic
hardware with imprecise and noisy neurons. To address this, authors propose to ﬁrst
transform an unreliable hardware layer of silicon neurons into an abstract computational
layer composed of reliable neurons, and then modeling the target dynamics as a soft state
machine running on this computational layer. The mapping idea is the following. An
SNN is realized on hardware by mapping a neuron’s circuit bias voltages to the model

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 11

parameters and calibrating them using a series of population activity measurements.
The abstract computational layer is formed by conﬁguring neural networks as generic
soft winner-take-all sub-networks. Finally, states and transitions of the desired high-
level behavior are embedded in the computational layer by introducing only sparse
connections between some neurons of the various sub-networks.

In [100], Das et al. propose Particle Swarm Optimization (PSO)-based SNN
PARTitioning (PSOPART), a technique to partition an SNN model into short-distance
local synapses and long-distance global synapses for eﬃcient mapping of the SNN to
the many-core DYNAPs neuromorphic hardware [21]. Local synapses are mapped
within diﬀerent neuromorphic cores, while the global synapses are mapped on the shared
interconnect. The mapping problem is solved using PSO. First, an optimization problem
is formulated. A set of neurons and a set of cores are assumed. A set of binary variables
xi,j ∈ {0, 1} is deﬁned, where xi,j assumes ‘1’ if neuron i is mapped to core j. Constraint
to the problem is that each neuron can be mapped to only one core. Total number of
variables generated is D = N × C, where N is the number of neurons and C is the number
of cores. Objective of the optimization problem is to minimize the number of spikes
communicated between diﬀerent cores. Next, the optimization problem is transformed
into PSO domain. To this end, PSOPART instantiates a population of swarms. The
position of each swarm is deﬁned in a D-dimensional space. PSOPART ﬁnds a solution
to the optimization problem by iteratively moving these swarms in the search space while
recording each swarm’s local best position in relation to the global best solution [101].
In [102], Balaji et al. propose SPIking Neural NEtwork MAPping (SpiNeMap),
a framework that ﬁrst partitions an SNN model into clusters and then places these
clusters on diﬀerent physical cores of a neuromorphic hardware. SpiNeMap uses a greedy
approach, roughly based on the Kernighan-Lin Graph Partitioning algorithm [103] to
partition an SNN into clusters, minimizing the inter-cluster spike communication. It
then uses an instance of the PSO to place each cluster on a physical core of the
neuromorphic hardware, where cores are arranged in a two-dimensional mesh. The
objective of the PSO is to minimize the number of hops on the shared interconnect that
spikes need to communicate before they reach their destination. In this way, the energy
consumption on the shared interconnect is reduced.

In [104], Urgese et al. propose SNN-PP, a partitioning and placement methodology
to map SNNs on SpiNNaker parallel neuromorphic platform. The objective of SNN-
PP is to improve on-chip and oﬀ-chip communication eﬃciency. The methodology is
developed in two phases. In the ﬁrst phase, SNN-PP proﬁles the hardware architecture of
SpiNNaker to detect bottlenecks in the communication system. Next, SNN-PP describes
an SNN application as a graph where each node represents a population, which is a
homogeneous group of neurons sharing the same model and parameters. Each edge is
called projection, which connects neurons of two diﬀerent populations using synaptic
connections. The graph partitioning step of SNN-PP minimizes communication between
two populations. Finally, populations are mapped to SpiNNaker cores using the Sammon
Mapping algorithm [105] to reduce inter-core spike communication.

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 12

In [106, 107], Barchi et al. propose a design methodology to map SNNs on globally
asynchronous and locally synchronous (GALS) multi-core neuromorphic hardware such
as SpiNNaker [23]. Authors propose a task placement pipeline to minimize the spike
communication between diﬀerent computing cores. The target is to reduce the distance
spikes communicate before reaching their destination. The methodology represents both
an SNN and the platform as separate directed graphs. On the application side, nodes are
neurons or population of neurons and edges are synaptic connections. On the platform
side, nodes are processing cores while edges represent physical communication channels
between them. The mapping problem is formulated as the allocation of application
nodes to the platform nodes with the objective of minimizing the inter-core spike
communication. To this end, authors propose to use simulated annealing (SA) [108] to
explore diﬀerent neuron-to-core mappings and evaluate the cost function.

In [109], Titirsha et al. propose an energy-aware mapping of SNN models to
crossbar-based neuromorphic hardware. The proposed approach ﬁrst models the total
energy consumption of a neuromorphic hardware, considering both static and dynamic
powers consumed by neurons and synapses of an SNN model on hardware, and the
energy consumed in communicating spikes on the shared interconnect. This is an
extension of the NCPower framework [110], which models only the dynamic energy
consumption of a neuromorphic hardware. Next, authors show that diﬀerent SNN
mapping strategies lead to a diﬀerence in the energy consumption on the hardware.
Finally, authors propose an iterative approach of mapping an SNN model to the
hardware with the objective of minimizing the total energy consumption. The iterative
approach ﬁrst partitions an SNN model into clusters, and then these clusters are
randomly placed on cores of a hardware. Thereafter, clusters are repeatedly swapped on
cores to see if there is any reduction in the energy consumption. The iterative approach
terminates when there is no energy reduction obtained during swapping.

In [66], Balaji et al. propose PyCARL, a Python frontend for the CARLsim-
based SNN simulator [67]. CARLsim facilitates parallel simulation of large SNNs
using CPUs and multi-GPUs, simulates multiple compartment models, 9-parameter
Izhikevich and leaky integrate-and-ﬁre (LIF) spiking neuron models, and integrates
the fourth order Runge Kutta (RK4) method for improved numerical precision.
CARLsim’s support for built-in biologically realistic neuron, synapse, current and
emerging learning models and continuous integration and testing, make it an easy-
to-use and powerful simulator of biologically-plausible SNN models. Benchmarking
results demonstrate simulation of 8.6 million neurons and 0.48 billion synapses using 4
GPUs and up to 60x speedup with multi-GPU implementations over a single-threaded
CPU implementation. PyCARL also integrates a cycle-accurate neuromorphic hardware
simulator, which facilitates simulating a machine learning model on crossbar-based
neuromorphic hardware platforms such as DYNAPs [21] and TrueNorth [26]. Internally,
PyCARL uses the SpiNeMap framework [102] to map applications to the hardware
simulator. PyCARL allows users to estimate the accuracy deviation from software
simulation that may result due to hardware latency.

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 13

In [111], Corradi et al.

propose to use the NEF framework [94] to perform
arbitrary mathematical computations using a mixed-signal analog/digital neuromorphic
hardware. Authors propose to translate these computations into the three basic
principles of NEF – 1) Representation, 2) Transformation, and 3) Dynamics. Through
representation, authors propose to encode a stimulus as spiking activity of a group
of neurons. Through transformation, authors propose to convert the stimulus using
a weighted connection between pools of neurons.Through dynamics, authors propose
to implement linear and non-linear dynamical models including attractor networks,
Kalman ﬁlters, and controllable harmonic oscillators.

In [112], Balaji et al. propose DecomposeSNN, an approach to decompose each
neuron of an SNN with many pre-synaptic connections to a sequence of homogeneous
neural units (called Fanin-of-Two or FIT units), where each FIT unit can have a
maximum of two pre-synaptic connections. This spatial decomposition technique is
proposed for crossbar-based neuromorphic hardware, where each crossbar can only
accommodate a limited number of pre-synaptic connections,
fanins per post-
is
synaptic neuron. The mapping framework works as follows. An SNN model
transformed into a representation consisting of FIT units. Next, FIT units are packed
into clusters incorporating a crossbar’s fanin constraint. In this way, a cluster can be
incorporated directly on a crossbar. Finally, clusters are mapped to crossbars of a
neuromorphic hardware using the SpiNeMap framework [102].

i.e.,

In [113], Yang et al. propose the CoreSet Method (CSM) to mitigate the limited
fanin/fanout constraints of a neuromorphic crossbar in mapping SNNs to hardware. The
idea is based on coreset, which consists of multiple cores of particular arrangements.
CSM allows ﬂexible aggregation of cores, allowing the chip to support diﬀerent network
models with improved resource eﬃciency. CSM also supports diﬀerent core sizes for
optimal silicon area usage. CSM is an end-to-end full-stack framework that includes
TensorFlow-based training, coreset-based compilation, and FPGA emulation. The
compilation step splits and merges coresets to optimize the silicon area.

In [114], Balaji et al. propose a run-time manager for neuromorphic hardware.
The key motivation is that many machine learning models enable continuous learning
where synaptic connections are updated during model execution. Compile time-based
mapping approaches such as SpiNeMap [102] is not eﬃcient for such dynamic scenarios.
To address this, authors propose a fast approach to adjust the mapping of a model
to the hardware at run-time once a synaptic update is made to the model. The
proposed approach is based on a Hill-Climbing heuristic [115], which quickly ﬁnds a
new mapping of neurons and synapses to diﬀerent cores of the hardware with the
objective of minimizing the inter-core spike communication. The algorithm is an
iterative approach, which starts with a random allocation of neurons and synapses to
the hardware. Subsequently, the algorithm iterates to ﬁnd a better local solution by
making an incremental change in the mapping such as relocating a neuron to a diﬀerent
core. The objective is to reduce inter-core spike communication.

In [116], Plank et al. propose TENNLab, an exploratory framework that provides

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 14

the interface and software support for the development and testing of neuromorphic
applications and devices.
The programming approach utilizes the Evolutionary
Optimization of Neuromorphic Systems (EONS) for application development. The
software architecture of the framework includes three libraries and two driver programs.
The ﬁrst library is the engine, which implements application-speciﬁc functions. This is
independent of neuromorphic devices. The second library is the driver, which manages
the interaction between the framework and neuromorphic devices. The third library
is the EONS library, it provides an interface between the graph representation of an
application and the network structure supported by the hardware. There are two
drivers – a standalone driver for executing the application and the EONS driver to
train a network for a given application and a neuromorphic device. Users can edit these
libraries and drivers of TENNLab to implement SNNs on a neuromorphic device.

In [117], Mitchell et al. propose an approach to improve the energy eﬃciency of
SNN training using neuromorphic cores implemented on Xilinx Zynq platform. To do
so, authors develop a system software using the TENNLab framework [116] targeted
for the Caspian neuromorphic platform [118]. Using this software framework, authors
accelerate and improve the energy eﬃciency of the evaluation step of an evolutionary
algorithm used to train SNNs. The framework works as follows. First, the dataset is
encoded into a sequence of spiking packets. For each epoch, the interface receives a
population of networks. These networks are processed using a pipeline of thread pools.
The ﬁrst thread pool maps a network into conﬁguration command. The second pool
sends conﬁguration packets and dataset. Finally, the third pool decodes the output.

In [119], Balaji et al.

propose a design methodology called ROXANN for
implementing artiﬁcial neural networks (ANNs) using processing elements (PEs)
designed with low-precision ﬁxed-point numbers and high performance and reduced-
area approximate multipliers in FPGAs. The design methodology is the following.
First, authors propose the design of a generic processing element that supports the use
of accurate/approximate arithmetic units, such as adders and multipliers, to compute
the partial weighted sum of neurons [120, 121, 122, 123]. Next, authors use quantized
activation and weights during training and implementation phases of a neural network.
Finally, authors propose a clustering-based approach, used after the training phase of the
neural network, to minimize the number of distinct weights on the network. Although
ROXANN is developed for ANNs, authors discuss the modiﬁcations needed to apply
ROXANN for SNNs.

In [74], Ankit et al. propose TraNNsformer, an integrated framework for training
and mapping SNNs to crossbar-based neuromorphic hardware. TraNNsformer works
on the fully-connected layer as follows. First, it performs size-constrained iterative
clustering to generate clusters from a connectivity matrix. The algorithm is based on
Spectral Clustering [124], a graph clustering algorithm that produces a set of disjoint
graph nodes such that intra-cluster associativity is maximized. The proposed iterative
spectral clustering minimizes the number of unclustered synapses while ensuring cluster
generation with high utilization. Finally, TraNNsformer retrains the network to ﬁne-

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 15

tune connections, while reinforcing the clustering.

In [125], Liu et al.

propose Neu-NoC, an eﬃcient interconnect to reduce
the redundant data traﬃc in a neuromorphic hardware. Authors ﬁrst perform
comprehensive evaluation of traditional Network-on-Chip (NoC) for neuromorphic
system to identify design bottlenecks. Next, authors propose a hierarchical NoC for
neuromorphic hardware. It consists of local rings for the layers of a machine learning
model and a global mesh to interconnect the local links. Next, authors propose an
eﬃcient mapping of machine learning models to the Neu-NoC-based neuromorphic
hardware. The mapping consists of placing the layers to local rings such that the
distance of data communication is reduced, which reduces data congestion. Finally, a
multicast transmission is proposed to reduce the amount of data communication and a
new type of ﬂit is introduced to further reduce the data congestion.

In [126], Balaji et al. propose a scalable neuromorphic design based on the DYNAPs
neuromorphic hardware [21] and using a Segmented Bus-based interconnect for spike
communication. Authors also propose mapping SNNs onto the target architecture.
Authors argue that mesh-based NoCs that are used to interconnect cores in recent
neuromorphic designs, have relatively long time-multiplexed connections that need
to be near-continuously powered up and down, reaching from the ports of data
producers/consumers (inside a core or between diﬀerent cores) up to the ports of
communication switches [127, 128, 129, 125, 130, 131]. To address this, authors propose
segmented bus. Here, a bus lane is partitioned into segments, where interconnections
between segments are bridged and controlled by switches [86]. Authors propose a
dynamic segmented bus architecture with multiple segmented bus lanes. An optimized
controller is designed to perform mapping of communication primitives to segments by
proﬁling the communication pattern between diﬀerent cores for a given SNN. Based on
this proﬁling and mapping, switches in the interconnect are programmed once at design-
time before admitting an application to the hardware. By avoiding run-time routing
decisions, the proposed design signiﬁcantly gains on energy and latency.

In [132], Catthoor et al. propose a scalable neuromorphic hardware design to
map large-scale SNN applications. The key idea is to design a segmented bus-based
interconnect with three way switches built using thin-ﬁlm transistors (TFTs). Authors
propose to integrate these TFT switches into the back-end-of-line (BEOL) fabric.
Authors propose to use the SpiNeMap framework [102] to map SNN applications to
the target architecture.

In [133], Balaji et al.

propose a design methodology to perform heartbeat
classiﬁcation on an event-driven neuromorphic hardware such as the DYNAPs [21].
The methodology starts with an optimized CNN implementation of the heartbeat
classiﬁcation task.
It then converts CNN operations, such as multiply-accumulate,
pooling and softmax, into spiking equivalent with a minimal loss of accuracy. Finally, it
performs power and accuracy tradeoﬀs by controlling the synaptic activity in the hidden
layers using normalization. Authors implement the converted CNN on DYNAPs [21]
using the SpiNeMap framewprok [102].

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 16

In [134], Wang et al. propose an end-to-end framework for mapping hybrid neural
networks involving ANN and SNN to the Tianjic neuromorphic hardware [135]. While
intensive data representation of ANNs makes them achieve higher accuracy, event-driven
spike trains of SNNs make them energy eﬃcient. Hybrid neural networks (HNNs) allow
to combine the best of both worlds. The proposed framework is used to implement
the ANN module, SNN module, and the signal conversion module between ANN and
SNN. The ANN computation module is mapped using [136]. The SNN computation
module is mapped using [95]. To implement the communication module, four diﬀerent
signal conversion methods are evaluated. A global timing adjustment mechanism is also
developed between these diﬀerent modules.

In [137], Nair et al. propose mapping of recurrent neural networks (RNNs) to
in-memory neuromorphic chips. The mapping procedure is the following. First, the
recurrent ANN cell is modiﬁed by replacing the RNN units with an adaptive spiking
neuron model that can be abstracted as a low-pass ﬁlter. Second, the modiﬁed network is
trained using Backprop [138]. This generates trained synaptic weights for the recurrent
SNN. Third, to ensure the spiking neurons do not saturate, the largest value attained
by state variables in the trained network is mapped to the input. Finally, inputs of the
SNN are re-scaled to suitable current or voltage levels.

In [139], Curzel et al.

propose an automated framework called SODASNN
to synthesize a hybrid neuromorphic architecture consisting of digital and analog
components. The framework consists of the software deﬁned architecture (SODA)
synthesizer [140], a novel no-human-in-the-loop hardware generator that automates
the creation of machine learning (ML) accelerators from high-level ML language.
Inside the SODA framework, authors implemented the machine learning intermediate
representation (MLIR) dialect [141], which allows mapping spiking neurons and
their computations to corresponding specialized hardware. Authors also discuss an
automated compilation trajectory for complex SNN applications to their custom hybrid
neuromorphic hardware. Additionally, this is the ﬁrst work that demonstrates the
concept of automatic mapping of SNN models to FPGA-based neuromorphic hardware.
In [142], Balaji et al. enumerate several key challenges in compiling SNNs to a
neuromorphic hardware. They show that hardware latency, especially on the shared
time-multiplexed interconnect can delay some spikes more than others when reaching
their destination cores. Such delay can cause inter-spike interval (ISI) distortion and
spike disorder, which lead to a signiﬁcantly lower accuracy on the hardware. Authors
recommend that any SNN mapping technique needs to incorporate these metrics to
ensure that the hardware accuracy is close to the accuracy that is analyzed using an
application-level simulators such as Nengo [91], CARLsim [67], and Brian [69].
Summary: Table 3 summarizes these approaches.

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 17

Table 3: Neuromorphic system software approaches targeting performance and energy
optimization for platform based design.

System Software

SentryOS[85]

Target
Platform

µBrain[20]

Throughput, Utilization

Optimization Metric

Other Comments

Corelet[87]
LCompiler[88]
PACMAN[89], [92]
SNN-PP[104], [106, 107]

TrueNorth[26]
Loihi[25]
SpiNNaker[23]
SpiNNaker[23]

Core Utilization
Core Utilization
Core Utilization
Spike Communication Energy

Core Utilization

Compiler and run-time
manager
Compiler framework
Compiler framework
Compiler framework
Compiler and run-time
manager
Compiler framework

PyNN[90]

Nengo[91]

[95]

[134]
DecomposeSNN[112],
Coreset[113],
TraNNsformer[74]
[98, 99, 111, 137],
ROXANN[119]

PSOPART[100]

SpiNeMap[102], PyCARL[66],
Neu-NoC[125], [126, 132, 142]

[109, 133]

SODASNN[139]

TENNLab[116], [117]

[114]

SpiNNaker[23],
BrainScaleS[22],
Loihi[25]

FPGA,
SpiNNaker[23],
Loihi[25]
Tianji[96],
PRIME[97]
Tianjic[135]
Crossbar-based
architecture

Application-
speciﬁc
architecture
Crossbar-based
architecture
Crossbar-based
architecture

Crossbar-based
architecture

FPGA-based
neuromorphic
hardware
Xilinx
Zynq-based
Caspian[118]
Crossbar-based
architecture

Core Utilization

Compiler framework

Core Utilization

Compiler framework

Core Utilization
Core Utilization

Compiler framework
Compiler framework

Dynamic Energy

Compiler framework

Spike Communication Energy

Compiler framework

Spike Communication Energy,
Interconnect Latency,
Application Accuracy
Energy

Compiler framework

Compiler framework

Energy

Compiler framework

Energy

Compiler and run-time
manager

Spike Communication Energy

Run-time manager

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 18

2.3. System Software for Thermal and Reliability Optimization

We discuss key system software optimization approaches that addresses thermal and
reliability aspects in executing SNN applications on a neuromorphic hardware.

In [143], Song et al. propose a detailed circuit-level aging model for the CMOS
transistors that are used to design the neurons in a neuromorphic crossbar with PCM
synapses [144]. High voltages required to operate PCM cells can accelerate the aging in
a neuron’s CMOS circuitries, thereby reducing the lifetime of a neuromorphic hardware.
Authors evaluate the long-term,
lifetime reliability impact of executing state-
of-the-art machine learning tasks on a PCM-based neuromorphic hardware. They
show that aging is strongly dependent on temperature. However, unlike temperature
which is a short-term eﬀect, lifetime reliability is a long-term circuit degradation and
can be budgeted over time. Therefore, maximizing the lifetime reliability via the
system software avoids over-constraining a neuromorphic design and helps to reduce
the reliability-related design budget. Subsequently, authors propose to extend the
SpiNeMap framework [102] to incorporate neuron aging during mapping exploration.

i.e.,

In [47], Song et al. propose a framework called RENEU to model the reliability
of a crossbar in a neuromorphic hardware, considering the aging in both neuron and
synapse circuitries. Crossbar-level reliability models are then integrated to the system-
level reliability model considering a Sum-of-Failure-Rates (SOFR) distribution [145].
RENEU incorporate three diﬀerent aging mechanisms – time-dependent dielectric
breakdown (TDDB), bias temperature instability (BTI) and hot carrier injection (HCI).
This system-wide reliability model is integrated in a design-space exploration (DSE)
framework involving mapping of neurons and synapses to hardware. The key idea of
RENEU is the following. First, it performs clustering of an SNN application using
SpiNeMap [102]. Next, it uses a Hill-Climbing heuristic to map clusters to cores of the
hardware incorporating the system-level reliability model. The key idea is to maximize
the minimum lifetime of all crossbars in the hardware.

In [146], Gebregirogis et al. propose a learning and mapping approach that utilizes
approximate computing for layer-wise pruning and fault-tolerant weight mapping of
CNNs. The proposed approach works as follows. First, authors propose an approximate
learning technique to remove less relevant (approximable) neurons and non-important
features (weights), iteratively. The network is trained for a few iterations to extract
layer-wise error contributions of the neurons. Subsequently, the network is retrained by
pruning the approximable neurons. Second, the pruned network is retrained to improve
accuracy by ﬁne-tuning the weights. Finally, the retrained network is mapped to the
hardware. To do so, a layer-wise fault tolerant memory operating voltage downscaling
technique is adopted to aggressively reduce the cache supply voltage when it stores the
weights of approximable layers and increase it back to the nominal value when storing
the weights of non-approximable layers. This reduces energy.

In [147], Xu et al. propose a fault-tolerant design methodology for mapping machine
learning workloads to a memristor-based neuromorphic hardware. Authors speciﬁcally

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 19

address stuck-at faults of memristive devices. The proposed design methodology
consists of the following two stages – a general design optimization and a chip-speciﬁc
design optimization. For the general design optimization, authors propose a reliability-
aware training scheme. Here, a dropout-inspired technique and a new weighted error
function are introduced to learn more robust features about stuck-at faults and their
variations. For the chip-speciﬁc design optimization, authors propose to implement the
reliability-aware trained model on diﬀerent ReRAM-based memristors of the hardware
by exploiting the sensitivity of model weights to stuck-at faults.

In [148], Balaji et al. propose a framework to compute the reliability of charge
pumps that are used to supply high voltages to a neuromorphic crossbar. Such high
voltages are needed to operate a crossbar’s PCM devices. Authors show that if a charge
pump is activated too frequently, its internal CMOS devices do not recover from stress,
accelerating their aging and leading to negative bias temperature instability (NBTI)
generated defects. On the other hand, forcefully discharging a stressed charge pump
can lower the aging rate of its CMOS devices, but makes the neuromorphic hardware
unavailable to perform computations while its charge pump is being discharged.
The proposed framework analyzes an SNN workload using training data to identify
precisely when neurons spike. Such spike information is then used to estimate the
degradation in diﬀerent charge pumps for a given mapping of neurons and synapses
to the hardware. The work proposes the integration of this workload-dependent aging
estimation framework in a design space exploration involving distributing neurons and
synapses to the hardware, thereby improving the aging in diﬀerent charge pumps.

In [149], Song et al. propose NCRTM, a run-time manager for improving the
lifetime reliability of neuromorphic computing using PCM crossbars. Due to continuous
use at elevated voltages, CMOS devices in the peripheral circuit of a crossbar suﬀer
from bias temperature instability (BTI)-induced aging [150, 151, 152, 153, 154, 39].
To improve reliability, it is necessary to periodically de-stress all neuron and synapse
It dynamically de-
circuits in the hardware. NCRTM is proposed to do exactly so.
stresses neuron and synapse circuits in response to the short-term aging in their CMOS
transistors, with the objective of meeting a reliability target. NCRTM tracks this aging
at run-time during the execution of a machine learning workload. It de-stresses neuron
and synapse circuits only when it is absolutely necessary to do so, otherwise it reduces
the performance impact by scheduling de-stress operations oﬀ the critical path.

In [155], Liu et al. propose a methodology to rescue bit failures in NVM-based
neuromorphic hardware in order to restore the computational accuracy. The design
methodology consists of three steps. First, authors propose to identify weights of a
machine learning model that have lower impact on accuracy. Essentially, model weights
are categorized into signiﬁcant and in-signiﬁcant weights. Next, authors propose a
retraining algorithm to compensate for single-bit failure by re-tuning the trainable
weights. Finally, during mapping step, a redundancy mapping scheme is used to further
improve the computation accuracy.

In [156], Titirsha et al. propose a framework to model the thermal interactions

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 20

in a crossbar, which is used to map SNN models. Using this framework, authors
propose to distribute neurons and synapses to diﬀerent crossbars of a hardware such
that the average temperature of diﬀerent crossbars is reduced, which in turn improves
reliability [157]. The thermal formulation incorporates both the temporal component,
resulting from self-heating of a PCM cell over time due to propagating spikes of a
machine learning workload and the spatial component, resulting from heat transfer
from nearby cells within a crossbar [158, 159, 160, 161, 162, 163, 164]. The thermal
formulation is integrated inside a Hill-Climbing heuristic, which is used to map neurons
and synapses to diﬀerent crossbars of a hardware. Authors also show how the thermal
formulation can be adapted for other NVM types.

In [165], Ahmed et al.

presents NeuroScrub, a mechanism to mitigate data
retention faults in NVM-based neuromorphic hardware. Scrubbing is a technique to
reprogram conﬁguration data on to devices. Scrubbing has been used extensively in the
context of FPGA to mitigate single-event upsets (SEUs) [166, 167, 168, 169, 170, 120].
NeuroScrub uses a scrubbing mechanism to counteract technology-dependent uni-
directional retention faults in NVM cells used in a neuromorphic hardware. Authors
show that not all retention failures in the hardware lead to accuracy impact of
inference. Therefore, NeuroScrub only addresses uni-directional retention faults and
only approximately restores intended weight matrices in the NVM memory. To this
end, authors propose to divide the weight matrix of the hidden layer into stable weights
and unstable weights. These are then mapped to separate crossbars. Finally, scrubbing
is enabled at diﬀerent intervals and the accuracy impact is evaluated.

In [171], Kundu et al. propose an overview of reliability issues in neuromorphic
hardware and their mitigation approaches. First,
it outlines the reliability issues
in a commercial systolic array-based machine learning accelerator in the presence of
faults engendering from device-level non-idealities in the DRAM. Next, it quantiﬁes the
accuracy impact of circuit-level faults in the MSB and LSB logic cones of the Multiply
and Accumulate (MAC) block of the machine learning accelerator. Finally, it presents
two key reliability issues – circuit aging and endurance in emerging neuromorphic
hardware and shows the potential of SNN mapping approaches in mitigating them.

In [172], Zhang et al. propose an approach to improve the lifetime of ReRAM-
based neuromorphic hardware considering thermal and aging eﬀects. Authors show
that during programming and online training, ReRAM cells experience aging caused
by high voltage operations. Additionally, ReRAM cells with large conductance values
generate large currents during programming, which change their internal and ambient
temperature and thus incur thermal issues. Thermal issues accelerate aging of ReRAM
cells causing lower inference accuracy. The proposed framework works as follows. First,
during training, aging stress on ReRAM cells is distributed relatively evenly by adjusting
weights according to the current aging status of ReRAM cells. Next, thermal eﬀects
are balanced by distributing large conductance weights across the crossbar. Finally, a
row-column swapping technique is introduced during hardware mapping to deal with
uneven aging and thermal eﬀects.

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 21

In [173], Beigi et al. propose a temperature-aware training and mapping of machine
learning models to ReRAM-based neuromorphic hardware. The framework operates in
the following steps. First, authors evaluate the impact of temperature on ReRAM cells
of a crossbar and show how temperature variations impact accuracy. Next, authors
propose a classiﬁcation approach that incorporates the temperature distribution to
identify weights that have higher impact on accuracy. Finally, a temperature-aware
training process is proposed to map model weights to the hardware such that eﬀective
weights (those that have higher accuracy impact) are not mapped to hot ReRAM cells,
i.e., those ReRAM cells that are more prone to generate incorrect outputs.

In [174], Zhang et al. propose an algorithm-software co-optimization for mapping
vector-matrix computations in deep neural networks to mitigate limited endurance
of memristors in a neuromorphic hardware. Authors show that during execution of
deep learning models on the hardware, memristors need to be repeatedly tuned, i.e.,
reprogrammed using a pulse of very high voltage. This high voltage may cause a change
in the ﬁlament inside a memristor, leading to a degradation of the valid range of its
conductance and thus the number of usable conductance levels. If trained weights are
mapped to the hardware assuming a fresh state of the memristor, the target conductance
might fall outside of the valid range and therefore, the programmed conductance may
deviate from the target conductance. The proposed mapping framework consists of the
following two steps. First, a skewed-weight training is used for deep learning models
to deal with such reliability issues. Essentially, the idea is to train deep learning
models using smaller weights only. This is because smaller weights require smaller
conductance and equivalently, larger resistance on the memristor cell. This reduces
the amount of current ﬂowing through the cell, which improves its reliability. Finally,
when mapping weights of a deep learning model to memristors, the current status of
the memristors are taken into account. This status is tracked using a representative
memristor. During mapping, if memristors are stressed, then they are programmed with
smaller conductance values. Otherwise, the original conductance value is programmed.
In [175], Titirsha et al. propose a tradeoﬀ analysis involved in mapping of SNNs
on a crossbar-based neuromorphic hardware where NVM cells are used for synaptic
storage. Authors show that a major source of voltage drop in a crossbar are the parasitic
components on bitlines and wordlines, which are deliberately made longer to achieve
lower cost-per-bit. When mapping SNNs to a crossbar, cells on shorter current paths
are faster to access (high performance) but have lower write endurance due to high
currents. On the other hand, cells on longer current paths are slower to access but have
higher endurance due to small currents. This reliability and performance formulation
is incorporated in an SNN mapping framework. The framework ﬁrst partitions an SNN
into clusters using SpiNeMap [102]. Subsequently, clusters are mapped to crossbars by
exploiting the endurance-performance tradeoﬀ. The overall objective is to balance the
endurance of NVM cells in a crossbar with the minimum performance degradation.

In [176], Titirsha et al. propose eSpine, an approach to mitigate the limited write
endurance of NVM cells of a neuromorphic crossbar using intelligent mapping of neurons

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 22

and synapses to the hardware. Authors show that due to large parasitic components on
bitlines and wordlines, there is a signiﬁcant variation of the current propagating through
diﬀerent NVM cells in a crossbar. Through a detailed circuit-level modeling using PCM
cells, authors show the endurance variation in a crossbar generated due to the current
variation. eSpine operates in two steps. First, it partitions an SNN into clusters of
neurons and synapses using the Kernighan-Lin Graph Partitioning algorithm ensuring
that a cluster can be mapped to a crossbar of the hardware. Next, it uses PSO to
map clusters to cores. Across diﬀerent PSO iterations, eSpine maximizes the minimum
write endurance of diﬀerent crossbars. Within each PSO iteration, eSpine intelligently
programs synaptic weights to diﬀerent PCM cells of a crossbar such that those synapses
that are activated too frequently (i.e., those that have more spikes) within a workload
In this
are mapped to PCM cells that have high write endurance, and vice verse.
way, eSpine balances the endurance within each crossbar of a neuromorphic hardware,
simultaneously maximizing the overall write endurance.

In [177], Song et al. propose an approach to mitigate read disturb issues of
ReRAM cells in a neuromorphic hardware using intelligent synapse mapping strategies.
Authors show that an ReRAM cell can switch its state after reading its content a
certain number of times. Such behavior challenges the integrity and program-once-read-
many-times philosophy of implementing machine learning inference on neuromorphic
systems, impacting the Quality-of-Service (QoS). To address read disturb issues, authors
ﬁrst characterize read disturb-related endurance of ReRAM cells in a neuromorphic
hardware. They categorize ReRAM cells into strong and weak cells, where the strength
of an ReRAM cell is measured as a function of its read endurance; higher the read
endurance, stronger is the cell. Authors then propose an intelligent synapse mapping
technique, which analyzes spikes propagating through each synapse of a machine
learning model during inference and uses such information to map the model’s synaptic
weights to the ReRAM cells of a crossbars considering the variation in their read
endurance values. The overall objective is the following: those synapses that propagate
more spikes are mapped on stronger ReRAM cells, i.e., cells that can sustain more read
operations. In this way, weaker cells are not overly stressed, which improves lifetime.

In [178], Paul et al. propose an extension of the read disturb mitigation approach
of [177]. Fist, the proposed framework models the performance overhead in periodically
reprogramming model parameters to the ReRAM cells of a neuromorphic hardware in
order to mitigate their read disturb issues. Second, it exploits machine learning model
characteristics to identify non-critical model parameters, i.e., those that have no impact
on accuracy and eliminate them from the critical path of deciding the reprogramming
interval. Third, it uses a convex optimization formulation of cluster mapping to crossbar
in order to reduce the system overhead.

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 23

Summary: Table 4 summarizes these approaches.

Table 4: Neuromorphic system software approaches targeting thermal and reliability
optimization for platform based design.

System Software

NVM
Technology

Reliability Issues

Other Comments

[143, 144, 148, 171],
RENEU[47], NCRTM[149]

PCM

Aging in CMOS transistors of
neuron circuitry

Time-Dependant Dielectric
Breakdown (TDDB), Bias
Temperature Instability (BTI)

[156]

PCM

Self-heating temperature of
PCM cells

Minimize the average
temperature of a
neuromorphic hardware

[175], eSpine[176]

PCM

Limited write endurance of
PCM cells

Incorporate bitline and
wordline parasitics

[147, 155, 172, 174],
NeuroScrub[165]

ReRAM

Soft and hard NVM
manufacturing issues

[173]

ReRAM

Temperature in a crossbar

[177, 178]

ReRAM

[146]

–

Read disturb issues in
ReRAM cells in a
neuromorphic crossbar

Voltage downscaling impact
on SRAM-based synaptic
memory

–

–

–

–

2.4. Application and Hardware Modeling for Predictable Performance Analysis

The design of a neuromorphic platform is getting more and more complex. To manage
the design complexity, a predictable design ﬂow is needed. The result should be a system
that guarantees that an SNN application can perform its operations within the strict
timing deadlines. This requires that the timing behavior of the hardware, the software,
as well as their interaction can be predicted. We discuss these design ﬂows.

In [179], Das et al. propose an approach called SDFSNN, which uses Synchronous
Dataﬂow Graphs (SDFGs) [180] for mapping SNNs to a neuromorphic hardware. SDFGs
are commonly used to model streaming applications that are implemented on a multi-
core system [181, 182, 54]. Both pipelined streaming and cyclic dependencies between
tasks can be easily modeled in SDFGs. These graphs are used to analyze a system in
terms of key performance properties such as throughput, execution time, communication
bandwidth, and buﬀer requirement [183, 184, 185]. Authors show that SDFSNN can be
used to model both feed-forward and recurrent neural networks. Using SDFG semantics,
authors model an SNN as an application graph and a many-core neuromorphic hardware
as a platform graph. Using the mapping framework of SDFG [186, 54], authors propose
to distribute neurons to cores and estimate the corresponding throughput.

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 24

In [187], Balaji et al. automated the generation of SDFG from an SNN using a
framework called SDFSNN++. Nodes of an SDFG are called actors, which are computed
by reading tokens from their input ports and writing the results of the computation
as tokens on output ports. Port rates are visualized as annotations on edges. Actor
execution is also called ﬁring, and it requires a ﬁxed amount of time to execute. Edges
in the graph are called channels and they represent dependencies among actors. An
actor is said to be ready when it has suﬃcient input tokens on all its input channels and
suﬃcient buﬀer space on all its output channels; an actor can only ﬁre when it is ready.
Table 5 shows the one-to-one mapping of an SNN to SDFG properties. SDFSNN++
uses a real-time calculus [188] to estimate the throughput of an SDFG representation
of an SNN mapped to a platform with unbounded resources.

Table 5: One -to-one mapping of SNN to SDFG terminology.

SDFG Terminology SNN Terminology

actor

channel

token

neuron

synapse

spike

In [80], Song et al. propose a framework called DFSynthesizer, which is used to
map SNN models to state-of-the-art neuromorphic hardware with a limited number of
cores. With such limitations, hardware resources such as the processing cores may need
to be shared (time-multiplexed) across the neurons and synapses of an SNN model,
especially when the model is large and cannot ﬁt on a single core of the hardware.
Time-multiplexing of hardware resources introduces delay, which may lead to violation
of real-time requirements. To address this, DFSynthesizer ﬁrst partitions an SNN model
into clusters, where each cluster can ﬁt onto a core of the hardware. Next, clusters are
mapped to cores, where each core may need to execute multiple clusters. To do this
mapping, authors propose to use Max-Plus Algebra [189], which determines the best
way clusters need to be distributed in order to maximize the throughput. Finally, a
schedule is constructed based on Self-Timed Execution [190] to sequence the execution
of clusters on each core.

In [191], Song et al. extended the DFSynthesizer framework of [80]. The proposed
framework called DFSynthesizer++ is an end-to-end framework for synthesizing
machine learning programs to the hardware, improving both throughput and energy
consumption. The framework ﬁrst generates a machine learning workload by analyzing
the training data. It then partitions the workload into clusters using a greedy graph
partitioning algorithm. Next, it distributes clusters to the hardware, time-multiplexing
hardware resources to maximize throughput. Finally, it sequences clusters that are
mapped to the same core such that the generated sequence guarantees performance.
DFSynthesizer++ introduces the following functionalities to allow for the conversion of

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 25

CNN architectures such as LeNet, AlexNet, and VGGNet to their spiking counterparts.

(i) 1-D Convolution: The 1-D convolution is implemented to extract patterns from
inputs in a single spatial dimension. A 1xn ﬁlter, called a kernel, slides over the
input while computing the element-wise dot-product between the input and the
kernel at each step.

(ii) Residual Connections: Residual connections are implemented to convert the
residual block used in CNN models such as ResNet. Typically, the residual
connection connects the input of the residual block directly to the output neurons
of the block, with a synaptic weight of ‘1’. This allows for the input to be
directly propagated to the output of the residual block while skipping the operations
performed within the block.

(iii) Flattening: The ﬂatten operation converts the 2-D output of the ﬁnal pooling
operation into a 1-D array. This allows for the output of the pooling operation to
be fed as individual features into the decision-making fully connected layers of the
CNN model.

(iv) Concatenation: The concatenation operation, also known as a merging operation,
is used as a channel-wise integration of the features extracted from 2 or more layers
into a single output.

In [192], Song et al. propose a complete design ﬂow (roughly based on the design
ﬂow proposed for embedded multiprocessor systems [193, 182, 194].)
for mapping
throughput-constrained SNN applications to a neuromorphic hardware. The design
ﬂow explores the tradeoﬀ between buﬀer size on each core and throughput. The design
ﬂow wors as follows. First, it uses Kernighan–Lin graph partitioning heuristic to create
SNN clusters such that each cluster can be mapped to a core of the hardware. The
partitioning approach minimizes inter-cluster spike communication, which improves
latency and reduces communication energy. Next, it maps clusters to cores using an
instance of the PSO algorithm, while exploring the design space of throughput and
buﬀer size. Speciﬁcally, for each unit of buﬀer size on hardware cores, it ﬁnds the best
throughput possible with the given buﬀer allocation using the DFSynthesizer-based
mapping framework [191]. The algorithm is iterated for every increment of buﬀer size
on cores. In this way, the entire design space of throughput and buﬀer size requirement
is explored. The proposed design ﬂow allows system developers to select a buﬀer size
conﬁgurations required to achieve a given throughput performance.

3. Hardware-Software Co-Design

Most electronics systems consists of a hardware platform which executes software
programs. Hardware-software co-design is a system design paradigm where system-
level objectives such as cost, performance, power, and reliability are met by
exploiting the synergism of hardware and software through their concurrent design and
optimization [195, 49, 196, 197]. Similar to many electronics system design [198, 151,

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 26

199, 200, 58], hardware-software co-design is also used for the design of neuromorphic
systems [201]. Here, we review the software technology for hardware-software co-design.§
In [223], Ji et al. propose NEUTRAM (Neural Network Transformation, Mapping,
and Simulation), a co-design methodology for two target neuromorphic hardware
platforms – Tianji [96] and PRIME [97]. The design methodology works in three steps.
In step 1, applications are represented using a high-level language such as PyNN [90]
and CARLsim [67]. In step 2, the SNN model is transformed to incorporate hardware
constraints. The transformation algorithm divides an existing SNN into a set of simple
In step 3, the transformed SNN is
network units and retrains each unit iteratively.
mapped to the hardware using a runtime tool. Using this co-design methodology,
authors show the tradeoﬀs between network error rates and hardware consumption.

In [55], Balaji et al.

In [224], Zhao et al.

propose a co-design methodology for designing a
neuromorphic hardware for optical neural networks (ONNs) [225, 226, 227, 228, 229].
Conventionally, an optical hardware is synthesized from a software-trained network. The
proposed methodology adopts a diﬀerent route: the optical hardware implementation
and the software training implementation are co-designed to reduce the hardware
implementation cost. Authors ﬁrst propose an area-eﬃcient architecture of ONN, which
includes a sparse tree network block, a single unitary block and a diagonal block for each
neural network layer. Next, authors propose the software embodiment of these hardware
structures. Finally, the hardware and software are co-optimized to reduce the area cost.
propose NeuroXplorer, a hardware-software co-design
methodology for implementing SNNs on a neuromorphic hardware. The key idea of
NeuroXplorer is to optimize the system software, e.g., the compilation framework,
cluster generation, and CNN conversion alongside the hardware architecture. Authors
show that NeuroXplorer can design the hardware, including the number of cores, number
of neurons per core, synaptic capacity of each core, interconnect conﬁguration, and
routing algorithm for a given SNN application. NeuroXplorer can also optimize the
architecture of each core, such as generating two-layer crossbar architecture, three-
layered µBrain architecture, and the decoupled architecture consisting of separate
synaptic memory. For each of these design choices, NeuroXplorer can simultaneously
optimize the cluster generation and the mapping technology.

In [230], Paul et al. propose a co-design methodology to implement respiratory
anomaly detection of newborn infants on neuromorphic systems. The methodology
works as follows. First, it optimizes the CNN architecture to optimize the classiﬁcation
accuracy. Next, it converts the CNN into spiking architecture using the conversion
framework proposed in [133]. Finally, it performs optimization of the system software
and hardware using the NeuroXplorer framework [55].

In [231], Plank et al. propose a hardware-software co-design framework similar to
NeuroXplorer [55]. In addition to architectural explorations, the proposed framework

§ Hardware-software co-design methodologies are also proposed for CNN accelerators [202, 203, 204,
205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222]. To keep the focus
on neuromorphic computing, we only review methodologies for spiking-based neuromorphic systems.

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 27

can also co-design the NVM cells that are used for synaptic storage. The design
framework is uniﬁed and therefore, new results on device can be applied to application
instantly and estimate the performance impact.

In [232], An et al. propose a hardware-software co-design methodology to design
three-dimensional (3D) neuromorphic hardware with two layers of memristive synapses.
The hardware-software co-design methodology combines SNN training algorithm,
Whetstone [233] with 3D integrated circuits (3D-ICs) [234, 235, 236]. The co-design
is performed in three steps. First, two neural networks (MLP and CNN) are trained
using Whetstone. Next, during the sharpening procedure, weights of the SNN are
stored and mapped to memristors (ReRAM) in the binary format. Finally, memristors
are ﬁne-tuned to the performance of the neuromorphic system using the NeuroSim
simulator [237]. The co-design framework optimizes for 1) the training accuracy by
ﬁne-tuning the weights of an SNN and 2) heat diﬀusion eﬀect in memristors by adding
heat dissipation layers. The objective is to co-optimize design area, power, and latency.
In [238], Shi et al. propose a co-design approach to design specialized hardware and
software for deep learning accelerators. The essential idea of the framework is a design
space exploration (DSE) framework that involves two exploration loops. The outer
loop optimizes the hardware architecture, while the inner loop optimizes the software
mapping to the architecture. These explorations are performed using a nested Bayesian
Optimizer that uses Bayesian models of hardware and software performance to guide
the search process. This is similar to the design space exploration frameworks proposed
for multi-core/multiprocessor designs [239, 184, 240, 241, 242, 243]. Through this DSE,
authors show a signiﬁcant opportunity to improve the energy-delay product. Although
targeted for ANN accelerators, the methodology can be applied also for SNN hardware.
propose EONS (Evolutionary Optimization for
Neuromorphic Systems) for rapid prototyping of SNN applications on neuromorphic
systems [245]. EONS operates in four steps – generation, evaluation, selection, and
reproduction. The initial population is randomly generated. Next, the network is
evaluated in population using a ﬁtness score. Next, a network is selected as parent
using an evolutionary algorithm. Finally, reproduction operations such as duplication,
crossover, and mutation are performed on the parent network. EONS can be applied to
any tasks such as classiﬁcation and control, without changing the underlying algorithm.
EONS can be used to map an SNN application to an existing neuromorphic platform
such as Caspian [118] by incorporating its hardware constraints, essentially a platform-
based design concept. EONS can also perform optimization of the hardware, e.g., a
reservoir in a liquid state machine for a given application. Therefore, EONS can co-
design both the hardware and software, exploring the design tradeoﬀs.

In [244], Schuman et al.

In [246], Li et al.

propose a co-design methodology to design an accurate
and communication-optimized Liquid State Machine (LSM) architecture. LSM works
on the principle of reservoir computing [247]. An LSM consists of a reservoir of
recurrently-connected spiking neurons and a supervised readout [248, 61]. The co-design
methodology consists of three engines. The ﬁrst is the multi-objective LSM architecture

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 28

search engine involving the exploration of the number of neurons in the liquid and their
connectivity. The second is the NoC architecture search engine involving the number
of nodes, NoC topology and routing. The third is the mapping engine, which maps the
LSM to the NoC nodes. The objective of the co-design is to eﬃciently implement LSM
architectures to a NoC-based neuromorphic hardware.

In [78], Gopalakrishnan et al. propose a co-design approach for CNN architecture
implemented on crossbar arrays by exploring the design space of diﬀerent hardware-
friendly convolution techniques and their software-based mapping approaches. The
target neuromorphic hardware consists of crossbars that are interconnected using a
shared interconnect. The iterative co-design methodology works in the following steps.
First it initiates the number of convolutional layers and the number of depthwise
separable convolution layers. Next, it decides on the number of feature maps per layer,
with the constraint of avoiding core matrix splitting. To do so, it puts a constraint on
the fan-in degree of a neuron. Finally, the optimized CNN (called HFNet) is mapped to
obtain the minimum number of cores and estimate the accuracy. The process is repeated
to explore the design space of accuracy and hardware area.

In [249], Fang et al. propose neuromorphic learning and hardware co-design for
temporal pattern learning. Authors ﬁrst propose an eﬃcient training algorithm for SNN
with LIF neurons to learn from temporal data. The learning algorithm allows to process
temporal data without using a recurrent structure, which reduces the design complexity.
Several design strategies are proposed to reduce the design complexity while achieving
comparable accuracy. Next, the learning algorithm is co-designed on a ReRAM-based
neuromorphic hardware.

In [250], Schuman et al. propose a software framework to evaluate the impact of
four SNN learning algorithms on three neuromorphic simulators and demonstrate the
same using four simple classiﬁcation tasks. The training algorithms evaluated for SNNs
include Decision Tree, EONS [245], Whetstone [233], and Reservoir Computing [247].
The neuromorphic platforms evaluated are Caspian [118], Generic Neuromorphic
Processor (GNP), and NEST [68]. Authors evaluate the hardware area and training
accuracy through these explorations. Authors demonstrate the importance of learning
algorithm and hardware co-design for neuromorphic computing.

In [251], Oltra-Oltra et al. propose a hardware-software co-design for distributed
SNN architectures. First, authors propose a Single Instruction Multiple Data (SIMD)-
based SNN architecture. Next, they develop a tool chain for mapping SNN models to the
target architecture. Through a co-design framework called HEENS (Hardware Emulator
of Evolvable Neural Spiking), authors propose to jointly optimize the architecture and
its tool chain to achieve maximum beneﬁt from the SIMD design and their use for
distributed neuromorphic computing.
In [252], Frenkel et al.

propose a co-design methodology for hardware
implementation of SNNs. First, authors propose analog, mixed-signal and digital circuit
design styles for neuromorphic hardware. They exploit the boundary between processing
and memory through the integration of time multiplexing, in-memory computation, and

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 29

novel devices. Next, they evaluate tradeoﬀs for two alternate implementation styles
– a bottom-up design style, where the hardware is designed ﬁrst and then used to
map an SNN application, and a top-down style, where an SNN application is ﬁrst
optimized and then implemented in hardware. The proposed co-design methodology
involves integrating the top-down and bottom-up design styles to jointly optimize both
application and hardware.

In [253], Ankit et al.

propose RESPARC, a reconﬁgurable platform for
neuromorphic hardware using memristive crossbars. RESPARC is a three-tiered
reconﬁgurable architecture. Tier 1 consists of the Macro Processing Engine, a
reconﬁgurable compute unit to map neurons with variable fanins. Tier 2 consists of
NeuroCell, a reconﬁgurable datapath to map SNNs with varying inter- and intra-layer
connections. Tier 3 consists of the RESPARC, the reconﬁgurable neuromorphic core
to map SNNs with varying sizes. Through co-design of these layers, authors show the
design space exploration opportunities and the signiﬁcant energy improvements possible
in implementing SNNs on a neuromorphic hardware.

In [254], Mallik et al. propose a design-technology tradeoﬀ analysis to implement
SNNs on ReRAM cells of a neuromorphic hardware. Authors show that the requirement
to have multiple distinct levels is the key bottleneck for using ReRAM as synaptic cells
in a neuromorphic hardware. Accordingly, authors propose a mixed-radix encoding for
multi-level ReRAM cells. Authors show the tradeoﬀ between single-level and multi-level
cells in terms of their design and technology using silicon data and also evaluate their
impact on classiﬁcation accuracy. Subsequently a design-technology co-optimization is
needed to implement SNN applications on ReRAM-based neuromorphic systems.

In [255], Paul et al. propose a design-technology co-optimization in implementing
SNNs on NVM-based neuromorphic hardware. Using circuit-level simulations with
ReRAM technology, authors show the negative impact of technology scaling on the
read endurance of ReRAM cells. Speciﬁcally, they show that at scaled technology
nodes, the value of parasitic components on bitlines and wordlines of a crossbar
increases, which create a signiﬁcant variation in the read endurance of ReRAM cells of a
crossbar. However, technology scaling oﬀers beneﬁts such as improvement of integration
density and cost-per-bit. Authors propose a design ﬂow that incorporates technological
characteristics in their software mapping ﬂow so that neurons and synapses can be
placed in a crossbar mitigating the negative impact of technology scaling.

In [256], Ku et al. propose a design-architecture co-optimization to improve the
area eﬃciency of LSM-based speech recognition with monolithic 3D technology. The
exploration involves 1) ASIC implementation of LSM in 2D and 3D-IC technologies and
their are area comparison, 2) comparison of synapse models and memory distribution
on power, performance, and area. The design is implemented in 28nm node. For 3D-IC
design, the co-optimization framework uses a hierarchical Shrunk-2D design ﬂow. In
this design ﬂow, a pseudo 3D design is built from 2D, by scaling down cell dimension,
√
2. Actual implementation-wise, individual
wire pitch, and wire width by a factor of
neuron and top-level cells are partitioned into two tiers. First, the design methodology

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 30

starts with a top-level ﬂoorplanning, which is based on the shrunk geometry and timing
budget. Then for each neuron, it builds a two-tier folded design using the Shrunk-2D
ﬂow. Finally, the tier-by-tier routing of the design is performed and netlist generated.
In [257], Chen et al. propose a technology-design co-optimization for resistive
crosspoint array-based neuromorphic hardware. Several key design and technological
enhancements are proposed including larger wire width to reduce IR drop, the use of
multiple cells for each synaptic element to mitigate device-to-device variations, and fully-
parallel read and write schemes of the weighted sum and weight updates in the crosspoint
array. Authors evaluate area, energy, and latency tradeoﬀs for these enhancements
involving array design and resistive technology (ReRAM) at 65nm technology node.

4. Outlook

Over the past decade, neuromorphic computing has seen signiﬁcant progress on
the silicon technology, hardware, and software fronts. This is primarily due to
the questionable future of Moore’s law and the growing demand for brain-like
functionality such as visual and auditory scene analysis and reasoning. However,
today’s neuromorphic hardware nodes can perform several diﬀerent types of scientiﬁc
It is unclear how such
computations and not just limited to machine learning.
scientiﬁc computations can be eﬃciently mapped to event-driven operations supported
on a neuromorphic hardware using existing software technologies. This is particularly
important if neuromorphic computing is to be integrated into the existing computing
workﬂows involving CPUs and GPUs.

In the future, neuromorphic systems are expected to aggregate multiple
heterogeneous neuromorphic hardware nodes to generate a massively parallel system
that can solve scientiﬁc computations that are far too complex for a single-node
neuromorphic hardware. However, despite the signiﬁcant technological advances made
it remained to be seen how portable are existing software
on the software front,
technologies to such large-scale systems. Finally, virtualization of neuromorphic systems
opens up a new avenue for research on software technologies.

Acknowledgement

This material is based upon work supported by the U.S. Department of Energy under
Award Number DE-SC0022014 and by the National Science Foundation under Grant
Nos. CCF-1942697 and CCF-1937419.

References

[1] C. Mead, “Neuromorphic electronic systems,” Proc. of the IEEE, 1990.
[2] W. Maass, “Networks of spiking neurons: The third generation of neural network models,” Neural

Networks, 1997.

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 31

[3] H. Paugam-Moisy and S. M. Bohte, “Computing with spiking neuron networks.” Handbook of

Natural Computing, 2012.

[4] A. Tavanaei, M. Ghodrati, S. R. Kheradpisheh, T. Masquelier, and A. Maida, “Deep learning in

spiking neural networks,” Neural Networks, 2019.

[5] Y. Dan and M.-m. Poo, “Spike timing-dependent plasticity of neural circuits,” Neuron, vol. 44,

no. 1, 2004.

[6] K. Lee and D.-S. Kwon, “Synaptic plasticity model of a spiking neural network for reinforcement

learning,” Neurocomputing, 2008.

[7] S. Schmidgall and J. Hays, “Stable lifelong learning: Spiking neurons as a solution to instability

in plastic neural networks,” arXiv preprint arXiv:2111.04113, 2021.

[8] A. N. Burkitt, “A review of the integrate-and-ﬁre neuron model: I. Homogeneous synaptic input,”

Biological Cybernetics, 2006.

[9] G. W. Burr, R. M. Shelby, A. Sebastian, S. Kim, S. Kim, S. Sidler, K. Virwani, M. Ishii,
P. Narayanan, A. Fumarola et al., “Neuromorphic computing using non-volatile memory,”
Advances in Physics: X, 2017.

[10] I. Chakraborty, A. Jaiswal, A. Saha, S. Gupta, and K. Roy, “Pathways to eﬃcient neuromorphic

computing with non-volatile memory technologies,” Applied Physics Reviews, 2020.

[11] V. Saxena, “Neuromorphic computing: From devices to integrated circuits,” Journal of
Vacuum Science & Technology B, Nanotechnology and Microelectronics: Materials, Processing,
Measurement, and Phenomena, 2021.

[12] M. Musisi-Nkambwe, S. Afshari, H. Barnaby, M. N. Kozicki, and I. S. Esqueda, “The viability of
analog-based accelerators for neuromorphic computing: A survey,” Neuromorphic Computing
and Engineering, 2021.

[13] C.-H. Kim, S. Lim, S. Y. Woo, W.-M. Kang, Y.-T. Seo, S.-T. Lee, S. Lee, D. Kwon, S. Oh,
Y. Noh et al., “Emerging memory technologies for neuromorphic computing,” Nanotechnology,
2018.

[14] G. S. Rose, M. S. A. Shawkat, A. Z. Foshie, J. J. Murray, and M. M. Adnan, “A system
design perspective on neuromorphic computer processors,” Neuromorphic Computing and
Engineering, 2021.

[15] P. Date, C. Schuman, B. Kay, and T. Potok, “Neuromorphic computing is Turing-complete,”

arXiv, 2021.

[16] H. Li, K. Ota, and M. Dong, “Learning IoT in edge: Deep learning for the Internet of Things

with edge computing,” IEEE network, 2018.

[17] B. Rajendran, A. Sebastian, M. Schmuker, N. Srinivasa, and E. Eleftheriou, “Low-power
neuromorphic hardware for signal processing applications: A review of architectural and
system-level design approaches,” Signal Processing Magazine, 2019.

[18] D. Christensen, R. Dittmann, B. Linares-Barranco, A. Sebastian, M. Gallo, A. Redaelli,
S. Slesazeck, T. Mikolajick, S. Spiga, S. Menzel et al., “Roadmap on neuromorphic computing
and engineering,” Neuromorphic Computing and Engineering, 2021.

[19] C. Frenkel, M. Lefebvre, J.-D. Legat, and D. Bol, “A 0.086-mm2 12.7-pj/sop 64k-synapse 256-
neuron online-learning digital spiking neuromorphic processor in 28-nm CMOS,” TBCAS, 2018.
[20] J. Stuijt, M. Sifalakis, A. Yousefzadeh, and F. Corradi, “µBrain: An event-driven and fully
synthesizable architecture for spiking neural networks,” Frontiers in Neuroscience, 2021.

[21] S. Moradi, N. Qiao, F. Stefanini, and G.

Indiveri, “A scalable multicore architecture
with heterogeneous memory structures for dynamic neuromorphic asynchronous processors
(DYNAPs),” TBCAS, 2017.

[22] J. Schemmel, A. Gr¨ubl, S. Hartmann, A. Kononov, C. Mayr, K. Meier, S. Millner, J. Partzsch,
S. Schiefer, S. Scholze et al., “Live demonstration: A scaled-down version of the brainscales
wafer-scale neuromorphic system,” in ISCAS, 2012.

[23] S. Furber, F. Galluppi, S. Temple, and L. A. Plana, “The SpiNNaker project,” Proc. of the IEEE,

2014.

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 32

[24] B. Benjamin, P. Gao, E. McQuinn, S. Choudhary, A. R. Chandrasekaran, J.-M. Bussat,
R. Alvarez-Icaza, J. V. Arthur, P. A. Merolla, and K. Boahen, “Neurogrid: A mixed-analog-
digital multichip system for large-scale neural simulations,” Proceedings of the IEEE, 2014.

[25] M. Davies, N. Srinivasa, T. H. Lin et al., “Loihi: A neuromorphic manycore processor with

on-chip learning,” IEEE Micro, 2018.

[26] M. V. Debole, B. Taba, A. Amir et al., “TrueNorth: Accelerating from zero to 64 million neurons

in 10 years,” Computer, 2019.

[27] H. Jeong and L. Shi, “Memristor devices for neural networks,” Journal of Physics D: Applied

Physics, 2018.

[28] R. Bez and A. Pirovano, “Non-volatile memory technologies:

emerging concepts and new

materials,” Materials Science in Semiconductor Processing, 2004.

[29] K. Suzuki and S. Swanson, “A survey of trends in non-volatile memory technologies: 2000-2014,”

in IMW, 2015.

[30] Y. Nishi, “Challenges and opportunities for future non-volatile memory technology,” Current

Applied Physics, 2011.

[31] H.-S. P. Wong, H.-Y. Lee, S. Yu, Y.-S. Chen, Y. Wu, P.-S. Chen, B. Lee, F. T. Chen, and M.-J.

Tsai, “Metal–oxide RRAM,” Proceedings of the IEEE, 2012.

[32] H.-S. P. Wong, S. Raoux, S. Kim, J. Liang, J. P. Reifenberg, B. Rajendran, M. Asheghi, and

K. E. Goodson, “Phase change memory,” Proceedings of the IEEE, 2010.

[33] Y. Arimoto and H. Ishiwara, “Current status of ferroelectric random-access memory,” Mrs

Bulletin, 2004.

[34] Y. Huai et al., “Spin-transfer torque MRAM (STT-MRAM): Challenges and prospects,” AAPPS

bulletin, 2008.

[35] B. C. Lee, E. Ipek, O. Mutlu, and D. Burger, “Phase change memory architecture and the quest

for scalability,” Communications of the ACM, 2010.

[36] S. Song, A. Das, O. Mutlu, and N. Kandasamy, “Enabling and exploiting partition-level

parallelism (PALP) in phase change memories,” TECS, 2019.

[37] ——, “Improving phase change memory performance with data content aware access,” in ISMM,

2020.

[38] S. Song, A. Das, and N. Kandasamy, “Exploiting inter- and intra-memory asymmetries for data

mapping in hybrid tiered-memories,” in ISMM, 2020.

[39] S. Song, A. Das, O. Mutlu, and N. Kandasamy, “Aging-aware request scheduling for non-volatile

main memory,” in ASP-DAC, 2021.

[40] E. K¨ult¨ursay, M. Kandemir, A. Sivasubramaniam, and O. Mutlu, “Evaluating STT-RAM as an

energy-eﬃcient main memory alternative,” in ISPASS, 2013.

[41] B. C. Lee, E. Ipek, O. Mutlu, and D. Burger, “Architecting phase change memory as a scalable

dram alternative,” in ISCA, 2009.

[42] M. K. Qureshi, V. Srinivasan, and J. A. Rivers, “Scalable high performance main memory system

using phase-change memory technology,” in ISCA, 2009.

[43] S. Nandakumar, M. Le Gallo, I. Boybat, B. Rajendran, A. Sebastian, and E. Eleftheriou, “A
phase-change memory model for neuromorphic computing,” Journal of Applied Physics, 2018.
[44] D. Garbin, E. Vianello, O. Bichler, Q. Rafhay, C. Gamrat, G. Ghibaudo, B. DeSalvo, and
L. Perniola, “HfO 2-based OxRAM devices as synapses for convolutional neural networks,”
TED, 2015.

[45] M. Jerry, P.-Y. Chen, J. Zhang, P. Sharma, K. Ni, S. Yu, and S. Datta, “Ferroelectric FET analog

synapse for acceleration of deep neural network training,” in IEDM, 2017.

[46] A. F. Vincent, J. Larroque, N. Locatelli, N. B. Romdhane, O. Bichler, C. Gamrat, W. S. Zhao,
J.-O. Klein, S. Galdin-Retailleau, and D. Querlioz, “Spin-transfer torque magnetic memory as
a stochastic memristive synapse for neuromorphic systems,” TBCAS, 2015.

[47] S. Song, A. Das, and N. Kandasamy, “Improving dependability of neuromorphic computing with

non-volatile memory,” in EDCC, 2020.

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 33

[48] K. Keutzer, A. R. Newton, J. M. Rabaey, and A. Sangiovanni-Vincentelli, “System-level design:

Orthogonalization of concerns and platform-based design,” TCAD, 2000.

[49] G. De Michell and R. K. Gupta, “Hardware/software co-design,” Proceedings of the IEEE, 1997.
[50] A. Sangiovanni-Vincentelli, L. Carloni, F. De Bernardinis, and M. Sgroi, “Beneﬁts and challenges

for platform-based design,” in DAC, 2004.

[51] A. Sangiovanni-Vincentelli and G. Martin, “Platform-based design and software design

methodology for embedded systems,” IEEE Design & Test, 2001.

[52] P. Nuzzo, A. L. Sangiovanni-Vincentelli, D. Bresolin, L. Geretti, and T. Villa, “A platform-based
design methodology with contracts and related tools for the design of cyber-physical systems,”
Proceedings of the IEEE, 2015.

[53] A. K. Singh, A. Das, and A. Kumar, “Energy optimization by exploiting execution slacks in

streaming applications on multiprocessor systems,” in DAC, 2013.

[54] A. K. Das, A. Kumar, B. Veeravalli, and F. Catthoor, Reliable and Energy Eﬃcient Streaming

Multiprocessor Systems. Springer, 2018.

[55] A. Balaji, S. Song, T. Titirsha, A. Das, J. Krichmar, N. Dutt, J. Shackleford, N. Kandasamy, and
F. Catthoor, “NeuroXplorer 1.0: An extensible framework for architectural exploration with
spiking neural networks,” in ICONS, 2021.

[56] A. A. Jerraya, A. Bouchhima, and F. P´etrot, “Programming models and HW-SW interfaces

abstraction for multi-processor SoC,” in DAC, 2006.

[57] D. A. Patterson and J. L. Hennessy, Computer organization and design ARM edition:

the

hardware software interface. Morgan kaufmann, 2016.

[58] A. Das, M. J. Walker, A. Hansson, B. M. Al-Hashimi, and G. V. Merrett, “Hardware-software
interaction for run-time power optimization: A case study of embedded linux on multicore
smartphones,” in ISLPED, 2015.

[59] A. Das, F. Catthoor, and S. Schaafsma, “Heartbeat classiﬁcation in wearables using multi-layer

perceptron and time-frequency joint distribution of ECG,” in CHASE, 2018.

[60] E. J. Moyer and A. Das, “Machine learning applications to DNA subsequence and restriction site

analysis,” in SPMB, 2020.

[61] A. Das, P. Pradhapan, W. Groenendaal, P. Adiraju, R. Rajan, F. Catthoor, S. Schaafsma,
J. Krichmar, N. Dutt, and C. Van Hoof, “Unsupervised heart-rate estimation in wearables
with Liquid states and a probabilistic readout,” Neural Networks, 2018.

[62] N. Caporale and Y. Dan, “Spike timing–dependent plasticity: a hebbian learning rule,” Annu.

Rev. Neurosci., 2008.

[63] G. Daoudal and D. Debanne, “Long-term plasticity of intrinsic excitability:

learning rules and

mechanisms,” Learning & Memory, 2003.

[64] W. Nicola and C. Clopath, “Supervised learning in spiking neural networks with FORCE

training,” Nature Communications, 2017.

[65] M. Kiselev, “Rate coding vs. temporal coding-is optimum between?” in IJCNN, 2016.
[66] A. Balaji, P. Adiraju, H. J. Kashyap, A. Das, J. L. Krichmar, N. D. Dutt, and F. Catthoor,
“PyCARL: A PyNN interface for hardware-software co-simulation of spiking neural network,”
in IJCNN, 2020.

[67] T. Chou, H. Kashyap, J. Xing, S. Listopad, E. Rounds, M. Beyeler, N. Dutt, and J. Krichmar,
“CARLsim 4: An open source library for large scale, biologically detailed spiking neural network
simulation using heterogeneous clusters,” in IJCNN, 2018.

[68] J. M. Eppler, M. Helias, E. Muller, M. Diesmann, and M.-O. Gewaltig, “Pynest: a convenient

interface to the nest simulator,” Frontiers in Neuroinformatics, 2009.

[69] D. Goodman and R. Brette, “The brian simulator,” Front. in Neuroscience, 2009.
[70] M. L. Hines and N. T. Carnevale, “The NEURON simulation environment,” Neural Computation,

1997.

[71] C. Liu, B. Yan, C. Yang, L. Song, Z. Li, B. Liu, Y. Chen, H. Li, Q. Wu, and H. Jiang, “A spiking

neuromorphic design with resistive crossbar,” in DAC, 2015.

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 34

[72] M. Hu, H. Li, Y. Chen, Q. Wu, G. S. Rose, and R. W. Linderman, “Memristor crossbar-based

neuromorphic computing system: A case study,” TNNLS, 2014.

[73] M. Hu, J. P. Strachan, Z. Li, E. M. Grafals, N. Davila, C. Graves, S. Lam, N. Ge, J. J. Yang,
and R. S. Williams, “Dot-product engine for neuromorphic computing: Programming 1T1M
crossbar to accelerate matrix-vector multiplication,” in DAC, 2016.

[74] A. Ankit, A. Sengupta, and K. Roy, “TraNNsformer: Neural network transformation for

memristive crossbar based neuromorphic system design,” in ICCAD, 2017.

[75] N. S. Nukala, N. Kulkarni, and S. Vrudhula, “Spintronic threshold logic array (STLA)—A

compact, low leakage, non-volatile gate array architecture,” JPDC, 2014.

[76] Y. Kim, Y. Zhang, and P. Li, “A digital neuromorphic VLSI architecture with memristor crossbar

synaptic array for machine learning,” in SOCC, 2012.

[77] X. Zhang, A. Huang, Q. Hu, Z. Xiao, and P. K. Chu, “Neuromorphic computing with memristor

crossbar,” Physica Status Solidi (a), 2018.

[78] R. Gopalakrishnan, Y. Chua, P. Sun, A. J. Sreejith Kumar, and A. Basu, “Hfnet: A CNN
architecture co-designed for neuromorphic hardware with a crossbar array of synapses,”
Frontiers in Neuroscience, 2020.

[79] B. R. Fernando, Y. Qi, C. Yakopcic, and T. M. Taha, “3D memristor crossbar architecture for a

multicore neuromorphic system,” in IJCNN, 2020.

[80] S. Song, A. Balaji, A. Das, N. Kandasamy, and J. Shackleford, “Compiling spiking neural networks

to neuromorphic hardware,” in LCTES, 2020.

[81] D. Liu, T. Chen, S. Liu, J. Zhou, S. Zhou, O. Teman, X. Feng, X. Zhou, and Y. Chen,

“PuDianNao: A polyvalent machine learning accelerator,” in ASPLOS, 2015.

[82] Y. Chen, T. Luo, S. Liu, S. Zhang, L. He, J. Wang, L. Li, T. Chen, Z. Xu, N. Sun et al.,

“Dadiannao: A machine-learning supercomputer,” in MICRO, 2014.

[83] Y.-H. Chen, T. Krishna, J. S. Emer, and V. Sze, “Eyeriss: An energy-eﬃcient reconﬁgurable

accelerator for deep convolutional neural networks,” IJSC, 2016.

[84] T. Chen, Z. Du, N. Sun, J. Wang, C. Wu, Y. Chen, and O. Temam, “DianNao: a small-footprint

high-throughput accelerator for ubiquitous machine-learning,” in ASPLOS, 2014.

[85] M. L. Varshika et al., “Design of many-core big little µBrains for energy-eﬃcient embedded

neuromorphic computing,” in DATE, 2022.

[86] J. Chen, W.-B. Jone, J.-S. Wang, H.-I. Lu, and T.-F. Chen, “Segmented bus design for low-power

systems,” TVLSI, 1999.

[87] A. Amir, P. Datta, W. P. Risk, A. S. Cassidy, J. A. Kusnitz, S. K. Esser, A. Andreopoulos, T. M.
Wong, M. Flickner, R. Alvarez-Icaza et al., “Cognitive computing programming paradigm: a
corelet language for composing networks of neurosynaptic cores,” in IJCNN, 2013.

[88] C.-K. Lin, A. Wild, G. N. Chinya, T.-H. Lin, M. Davies, and H. Wang, “Mapping spiking neural

networks onto a manycore neuromorphic architecture,” in PLDI, 2018.

[89] F. Galluppi, S. Davies, A. Rast, T. Sharp, L. A. Plana, and S. Furber, “A hierachical conﬁguration

system for a massively parallel neural hardware platform,” in CF, 2012.

[90] A. P. Davison, D. Br¨uderle, J. M. Eppler, J. Kremkow, E. Muller, D. Pecevski, L. Perrinet,
and P. Yger, “PyNN: a common interface for neuronal network simulators,” Frontiers in
Neuroinformatics, 2009.

[91] T. Bekolay, J. Bergstra, E. Hunsberger, T. DeWolf, T. C. Stewart, D. Rasmussen, X. Choo,
A. Voelker, and C. Eliasmith, “Nengo: a python tool for building large-scale functional brain
models,” Frontiers in Neuroinformatics, 2014.

[92] I. Sugiarto, P. Campos, N. Dahir, G. Tempesti, and S. Furber, “Optimized task graph mapping

on a many-core neuromorphic supercomputer,” in HPEC, 2017.

[93] P. Campos, N. Dahir, C. Bonney, M. Trefzer, A. Tyrrell, and G. Tempesti, “Xl-stage: A cross-

layer scalable tool for graph generation, evaluation and implementation,” in SAMOS, 2016.

[94] C. Eliasmith and C. H. Anderson, Neural engineering: Computation, representation, and

dynamics in neurobiological systems. MIT press, 2003.

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 35

[95] Y. Ji, Y. Zhang, W. Chen, and Y. Xie, “Bridge the gap between neural networks and neuromorphic

hardware with a neural network compiler,” in ASPLOS, 2018.

[96] L. Shi, J. Pei, N. Deng, D. Wang, L. Deng, Y. Wang, Y. Zhang, F. Chen, M. Zhao, S. Song et al.,

“Development of a neuromorphic computing system,” in IEDM, 2015.

[97] P. Chi, S. Li, C. Xu, T. Zhang, J. Zhao, Y. Liu, Y. Wang, and Y. Xie, “PRIME: A novel
processing-in-memory architecture for neural network computation in ReRAM-based main
memory,” in ISCA, 2016.

[98] P. Gao, B. V. Benjamin, and K. Boahen, “Dynamical system guided mapping of quantitative

neuronal models onto neuromorphic hardware,” TCAS I: Regular Papers, 2012.

[99] E. Neftci, J. Binas, U. Rutishauser, E. Chicca, G. Indiveri, and R. J. Douglas, “Synthesizing

cognition in neuromorphic electronic systems,” PNAS, 2013.

[100] A. Das, Y. Wu, K. Huynh, F. Dell’Anna, F. Catthoor, and S. Schaafsma, “Mapping of local and

global synapses on spiking neuromorphic hardware,” in DATE, 2018.
[101] J. Kennedy and R. Eberhart, “Particle swarm optimization,” in ICNN, 1995.
[102] A. Balaji, A. Das, Y. Wu, K. Huynh, F. G. Dell’anna, G. Indiveri, J. L. Krichmar, N. D. Dutt,
S. Schaafsma, and F. Catthoor, “Mapping spiking neural networks to neuromorphic hardware,”
TVLSI, 2020.

[103] B. W. Kernighan and S. Lin, “An eﬃcient heuristic procedure for partitioning graphs,” Bell

System Technical Journal, 1970.

[104] G. Urgese, F. Barchi, E. Macii, and A. Acquaviva, “Optimizing network traﬃc for spiking neural
network simulations on densely interconnected many-core neuromorphic platforms,” TETC,
2016.

[105] J. W. Sammon, “A nonlinear mapping for data structure analysis,” IEEE Transactions on

computers, 1969.

[106] F. Barchi, G. Urgese, A. Acquaviva, and E. Macii, “Directed graph placement for snn simulation

into a multi-core gals architecture,” in VLSI-SoC, 2018.

[107] F. Barchi, G. Urgese, E. Macii, and A. Acquaviva, “Mapping spiking neural networks on multi-
core neuromorphic platforms: Problem formulation and performance analysis,” in VLSI-SoC,
2018.

[108] P. J. Van Laarhoven and E. H. Aarts, “Simulated annealing,” in Simulated annealing: Theory

and Applications, 1987.

[109] T. Titirsha, S. Song, A. Balaji, and A. Das, “On the role of system software in energy management

of neuromorphic computing,” in CF, 2021.

[110] Z. Wang, H. Zhang, T. Luo, W.-F. Wong, A. T. Do, P. Vishnu, W. Zhang, and R. S. M. Goh,

“NCPower: Power modelling for NVM-based neuromorphic chip,” in ICONS, 2020.

[111] F. Corradi, C. Eliasmith, and G. Indiveri, “Mapping arbitrary mathematical functions and
dynamical systems to neuromorphic VLSI circuits for spike-based neural computation,” in
ISCAS, 2014.

[112] A. Balaji, S. Song, A. Das, J. Krichmar, N. Dutt, J. Shackleford, N. Kandasamy, and F. Catthoor,
“Enabling resource-aware mapping of spiking neural networks via spatial decomposition,” ESL,
2020.

[113] L. Yang, H. Zhang, T. Luo, C. Qu, M. T. L. Aung, Y. Cui, J. Zhou, M. M. Wong, J. Pu, A. T. Do
et al., “Coreset: Hierarchical neuromorphic computing supporting large-scale neural networks
with improved resource eﬃciency,” Neurocomputing, 2021.

[114] A. Balaji, T. Marty, A. Das, and F. Catthoor, “Run-time mapping of spiking neural networks to

neuromorphic hardware,” JSPS, 2020.

[115] B. Selman and C. P. Gomes, “Hill-climbing search,” Encyclopedia of Cognitive Science, 2006.
[116] J. S. Plank, C. D. Schuman, G. Bruer, M. E. Dean, and G. S. Rose, “The TENNLab exploratory
neuromorphic computing framework,” IEEE Letters of the Computer Society, 2018.
[117] J. P. Mitchell and C. Schuman, “Low power hardware-in-the-loop neuromorphic training

accelerator,” in ICONS, 2021.

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 36

[118] J. P. Mitchell, C. D. Schuman, R. M. Patton, and T. E. Potok, “Caspian: A neuromorphic

development platform,” in NICE Workshop, 2020.

[119] A. Balaji, S. Ullah, A. Das, and A. Kumar, “Design methodology for embedded approximate

artiﬁcial neural networks,” in GLSVLSI, 2019.

[120] A. Das, S. Venkataraman, and A. Kumar, “Improving autonomous soft-error tolerance of FPGA

through LUT conﬁguration bit manipulation,” in FPL, 2013.

[121] S. Ullah, S. S. Murthy, and A. Kumar, “SMApproxLib: Library of FPGA-based approximate

multipliers,” in DAC, 2018.

[122] B. S. Prabakaran, S. Rehman, M. A. Hanif, S. Ullah, G. Mazaheri, A. Kumar, and M. Shaﬁque,
“DeMAS: An eﬃcient design methodology for building approximate adders for FPGA-based
systems,” in DATE, 2018.

[123] S. Ullah, S. Rehman, B. S. Prabakaran, F. Kriebel, M. A. Hanif, M. Shaﬁque, and A. Kumar,
“Area-optimized low-latency approximate multipliers for FPGA-based hardware accelerators,”
in DAC, 2018.

[124] A. Y. Ng, M. I. Jordan, and Y. Weiss, “On spectral clustering: Analysis and an algorithm,” in

NeurIPS, 2002.

[125] X. Liu, W. Wen, X. Qian, H. Li, and Y. Chen, “Neu-NoC: A high-eﬃcient interconnection network

for accelerated neuromorphic systems,” in ASP-DAC, 2018.

[126] A. Balaji, Y. Wu, A. Das, F. Catthoor, and S. Schaafsma, “Exploration of segmented bus as

scalable global interconnect for neuromorphic computing,” in GLSVLSI, 2019.

[127] S. H. Wang, A. Das, A. Kumar, and H. Corporaal, “Minimizing power consumption of spatial

division based networks-on-chip using multi-path and frequency reduction,” in DSD, 2012.

[128] Y. S. Yang and Y. Kim, “Recent trend of neuromorphic computing hardware:

Intel’s

neuromorphic system perspective,” in ISOCC, 2020.

[129] S. A. Wasif, S. Hesham, D. Goehringer, K. Hofmann, and M. A. Abd El Ghany, “Energy eﬃcient

synchronous-asynchronous circuit-switched NoC,” in MOCAST, 2020.

[130] Y. J. Yoon, P. Mantovani, and L. P. Carloni, “System-level design of networks-on-chip for

heterogeneous systems-on-chip,” in NOCS, 2017.

[131] A. Das, A. Kumar, and B. Veeravalli, “Fault-tolerant network interface for spatial division

multiplexing based Network-on-Chip,” in ReCoSoC, 2012.

[132] F. Catthoor, S. Mitra, A. Das, and S. Schaafsma, “Very large-scale neuromorphic systems for

biological signal processing,” in CMOS Circuits for Biological Sensing and Processing, 2018.

[133] A. Balaji, F. Corradi, A. Das, S. Pande, S. Schaafsma, and F. Catthoor, “Power-accuracy trade-

oﬀs for heartbeat classiﬁcation on neural networks hardware,” JOLPE, 2018.

[134] G. Wang, S. Ma, Y. Wu, J. Pei, R. Zhao, and L. Shi, “End-to-end implementation of various
hybrid neural networks on a cross-paradigm neuromorphic chip,” Frontiers in Neuroscience,
2021.

[135] J. Pei, L. Deng, S. Song, M. Zhao, Y. Zhang, S. Wu, G. Wang, Z. Zou, Z. Wu, W. He et al.,

“Towards artiﬁcial general intelligence with hybrid Tianjic chip architecture,” Nature, 2019.

[136] S. K. Esser, A. Andreopoulos, R. Appuswamy, P. Datta, D. Barch, A. Amir, J. Arthur, A. Cassidy,
M. Flickner, P. Merolla et al., “Cognitive computing systems: Algorithms and applications for
networks of neurosynaptic cores,” in IJCNN, 2013.

[137] M. V. Nair and G. Indiveri, “Mapping high-performance RNNs to in-memory neuromorphic

chips,” arXiv, 2019.

[138] Y. A. LeCun, L. Bottou, G. B. Orr, and K.-R. M¨uller, “Eﬃcient backprop,” in Neural Networks:

Tricks of the trade, 2012.

[139] S. Curzel, N. B. Agostini, S. Song, I. Dagli, A. Limaye, C. Tan, M. Minutoli, V. G. Castellana,
V. Amatya, J. Manzano et al., “Automated generation of integrated digital and spiking
neuromorphic machine learning accelerators,” in ICCAD, 2021.

[140] M. Minutoli, V. G. Castellana, C. Tan, J. Manzano, V. Amatya, A. Tumeo, D. Brooks, and
G.-Y. Wei, “Soda: a new synthesis infrastructure for agile hardware design of machine learning

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 37

accelerators,” in ICCAD, 2020.

[141] C. Lattner, M. Amini, U. Bondhugula, A. Cohen, A. Davis, J. Pienaar, R. Riddle, T. Shpeisman,
N. Vasilache, and O. Zinenko, “MLIR: A compiler infrastructure for the end of Moore’s law,”
arXiv, 2020.

[142] A. Balaji and A. Das, “Compiling spiking neural networks to mitigate neuromorphic hardware

constraints”,” in IGSC Workshops, 2020.

[143] S. Song and A. Das, “A case for lifetime reliability-aware neuromorphic computing,” in MWSCAS,

2020.

[144] ——, “Design methodologies for reliable and energy-eﬃcient PCM systems,” in IGSC Workshops,

2020.

[145] S. V. Amari and R. B. Misra, “Closed-form expressions for distribution of sum of exponential

random variables,” TR, 1997.

[146] A. Gebregirogis and M. Tahoori, “Approximate learning and fault-tolerant mapping for energy-

eﬃcient neuromorphic systems,” TODAES, 2020.

[147] Q. Xu, J. Wang, H. Geng, S. Chen, and X. Wen, “Reliability-driven neuromorphic computing

systems design,” in DATE, 2021.

[148] A. Balaji, S. Song, A. Das, N. Dutt, J. Krichmar, N. Kandasamy, and F. Catthoor, “A framework
to explore workload-speciﬁc performance and lifetime trade-oﬀs in neuromorphic computing,”
CAL, 2019.

[149] S. Song, J. Hanamshet, A. Balaji, A. Das, J. Krichmar, N. Dutt, N. Kandasamy, and F. Catthoor,

“Dynamic reliability management in neuromorphic computing,” JETC, 2021.

[150] P. Weckx, B. Kaczer, H. Kukner, J. Roussel, P. Raghavan, F. Catthoor, and G. Groeseneken,
“Non-Monte-Carlo methodology for high-sigma simulations of circuits under workload-
dependent BTI degradation-application to 6T SRAM,” in IRPS, 2014.

[151] A. Das, A. Kumar, and B. Veeravalli, “Aging-aware hardware-software task partitioning for

reliable reconﬁgurable multiprocessor systems,” in CASES, 2013.

[152] D. Kraak, M. Taouil, I. Agbo, S. Hamdioui, P. Weckx, S. Cosemans, and F. Catthoor, “Parametric

and Functional Degradation Analysis of Complete 14-nm FinFET SRAM,” TVLSI, 2019.

[153] D. Kraak, I. Agbo, M. Taouil, S. Hamdioui, P. Weckx, S. Cosemans, and F. Catthoor,
“Degradation analysis of high performance 14nm FinFET SRAM,” in DATE, 2018.
[154] A. Das, A. Kumar, and B. Veeravalli, “Reliability-driven task mapping for lifetime extension of

networks-on-chip based multiprocessor systems,” in DATE, 2013.

[155] C. Liu, M. Hu, J. P. Strachan, and H. Li, “Rescuing memristor-based neuromorphic design with

high defects,” in DAC, 2017.

[156] T. Titirsha and A. Das, “Thermal-aware compilation of spiking neural networks to neuromorphic

hardware,” in LCPC, 2020.

[157] J. Srinivasan, S. V. Adve, P. Bose, and J. A. Rivers, “The case for lifetime reliability-aware

microprocessors,” in ISCA, 2004.

[158] A. Das, A. Kumar, and B. Veeravalli, “Reliability and energy-aware mapping and scheduling of

multimedia applications on multiprocessor systems,” TPDS, 2015.

[159] I. Ukhov, M. Bao, P. Eles, and Z. Peng, “Steady-state dynamic temperature analysis and

reliability optimization for embedded multiprocessor systems,” in DAC, 2012.

[160] A. Das, B. M. Al-Hashimi, and G. V. Merrett, “Adaptive and hierarchical runtime manager for

energy-aware thermal management of embedded systems,” TECS, 2016.

[161] I. Ukhov, P. Eles, and Z. Peng, “Probabilistic analysis of power and temperature under process

variation for electronic system design,” TCAD, 2014.

[162] A. Das, R. A. Shaﬁk, G. V. Merrett, B. M. Al-Hashimi, A. Kumar, and B. Veeravalli,
“Reinforcement learning-based inter-and intra-application thermal optimization for lifetime
improvement of multicore systems,” in DAC, 2014.

[163] A. Das, A. Kumar, and B. Veeravalli, “Temperature aware energy-reliability trade-oﬀs for

mapping of throughput-constrained applications on multimedia MPSoCs,” in DATE, 2014.

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 38

[164] A. Das, G. V. Merrett, M. Tribastone, and B. M. Al-Hashimi, “Workload change point detection

for runtime thermal management of embedded systems,” TCAD, 2015.

[165] S. T. Ahmed, M. Hefenbrock, C. M¨unch, and M. B. Tahoori, “Neuroscrub: Mitigating retention
failures using approximate scrubbing in neuromorphic fabric based on resistive memories,” in
ETS, 2021.

[166] A. Stoddard, A. Gruwell, P. Zabriskie, and M. J. Wirthlin, “A hybrid approach to FPGA

conﬁguration scrubbing,” TNS, 2016.

[167] R. Santos, S. Venkataraman, A. Das, and A. Kumar, “Criticality-aware scrubbing mechanism for

SRAM-based FPGAs,” in FPL, 2014.

[168] J. Heiner, B. Sellers, M. Wirthlin, and J. Kalb, “FPGA partial reconﬁguration via conﬁguration

scrubbing,” in FPL, 2009.

[169] S. Venkataraman, R. Santos, A. Das, and A. Kumar, “A bit-interleaved embedded hamming

scheme to correct single-bit and multi-bit upsets for SRAM-based FPGAs,” in FPL, 2014.

[170] A. Sari, M. Psarakis, and D. Gizopoulos, “Combining checkpointing and scrubbing in FPGA-

based real-time systems,” in VTS, 2013.

[171] S. Kundu, K. Basu, M. Sadi, T. Titirsha, S. Song, A. Das, and U. Guin, “Special session:

Reliability analysis for ML/AI hardware,” in VTS, 2021.

[172] S. Zhang, G. L. Zhang, B. Li, H. H. Li, and U. Schlichtmann, “Lifetime enhancement for RRAM-

based computing-in-memory engine considering aging and thermal eﬀects,” in AICAS, 2020.

[173] M. V. Beigi and G. Memik, “Thermal-aware optimizations of ReRAM-based neuromorphic

computing systems,” in DAC, 2018.

[174] S. Zhang, G. L. Zhang, B. Li, H. H. Li, and U. Schlichtmann, “Aging-aware lifetime enhancement

for memristor-based neuromorphic computing,” in DATE, 2019.

[175] T. Titirsha and A. Das, “Reliability-performance trade-oﬀs in neuromorphic computing,” in IGSC

Workshops, 2020.

[176] T. Titirsha, S. Song, A. Das, J. Krichmar, N. Dutt, N. Kandasamy, and F. Catthoor, “Endurance-
aware mapping of spiking neural networks to neuromorphic hardware,” TPDS, 2021.
[177] S. Song, T. Titirsha, and A. Das, “Improving inference lifetime of neuromorphic systems via

intelligent synapse mapping,” in ASAP, 2021.

[178] A. Paul, S. Song, T. Titirsha, and A. Das, “On the mitigation of read disturbances in

neuromorphic inference hardware,” IEEE Design & Test, 2022.

[179] A. Das and A. Kumar, “Dataﬂow-based mapping of spiking neural networks on neuromorphic

hardware,” in GLSVLSI, 2018.

[180] E. Lee and D. Messerschmitt, “Synchronous data ﬂow,” Proceedings of the IEEE, 1987.
[181] S. Sriram and S. Bhattacharyya, Embedded Multiprocessors; Scheduling and Synchronization,

2000.

[182] L. Jiashu, A. Das, and A. Kumar, “A design ﬂow for partially reconﬁgurable heterogeneous

multi-processor platforms,” in RSP, 2012.

[183] S. Stuijk, M. Geilen, and T. Basten, “Exploring trade-oﬀs in buﬀer requirements and throughput

constraints for synchronous dataﬂow graphs,” in DAC, 2006.

[184] A. K. Singh, A. Das, and A. Kumar, “RAPIDITAS: RAPId design-space-exploration

incorporating trace-based analysis and simulation,” in DSD, 2013.

[185] A. Das and A. Kumar, “Fault-aware task re-mapping for throughput constrained multimedia

applications on NoC-based MPSoCs,” in RSP, 2012.

[186] S. Stuijk, “Predictable mapping of streaming applications on multiprocessors,” 2007.
[187] A. Balaji and A. Das, “A framework for the analysis of throughput-constraints of SNNs on

neuromorphic hardware,” in ISVLSI, 2019.

[188] L. Thiele, S. Chakraborty, and M. Naedele, “Real-time calculus for scheduling hard real-time

systems,” in ISCAS, 2000.

[189] M. Akian, R. Bapat, and S. Gaubert, “Max-plus algebra,” Handbook of Linear Algebra, 2006.
[190] A. Das, A. Kumar, and B. Veeravalli, “Energy-aware task mapping and scheduling for reliable

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 39

embedded computing systems,” TECS, 2014.

[191] S. Song, H. Chong, A. Balaji, A. Das, J. Shackleford, and N. Kandasamy, “DFSynthesizer:
Dataﬂow-based synthesis of spiking neural networks to neuromorphic hardware,” TECS, 2021.
[192] S. Song, L. V. Mirtinti, A. Das, and N. Kandasamy, “A design ﬂow for mapping spiking neural

networks to many-core neuromorphic hardware,” in ICCAD, 2021.

[193] B. Clement, R. Hersemeule, E. Lantreibecq, B. Ramanadin, P. Coulomb, and F. Pogodalla, “Fast
prototyping: a system design ﬂow applied to a complex system-on-chip multiprocessor design,”
in DAC, 1999.

[194] S. Stuijk, M. Geilen, and T. Basten, “A predictable multiprocessor design ﬂow for streaming

applications with dynamic behaviour,” in DSD, 2010.

[195] W. H. Wolf, “Hardware-software co-design of embedded systems,” Proceedings of the IEEE, 1994.
Springer
[196] J. Staunstrup and W. Wolf, Hardware/software co-design: principles and practice.

Science & Business Media, 1997.

[197] G. De Micheli, R. Ernst, W. Wolf, and M. Wolf, Readings in hardware/software co-design.

Morgan Kaufmann, 2002.

[198] F. Balarin, P. Giusto, A. Jurecska, M. Chiodo, C. Passerone, E. Sentovich, H. Hsieh, L. Lavagno,
B. Tabbara, A. Sangiovanni-Vincentelli et al., Hardware-software co-design of embedded
systems: the POLIS approach. Springer Science & Business Media, 1997.

[199] Y. Li, T. Callahan, E. Darnell, R. Harr, U. Kurkure, and J. Stockwood, “Hardware-software

co-design of embedded reconﬁgurable architectures,” in DAC, 2000.

[200] I. Bolsens, H. J. De Man, B. Lin, K. Van Rompaey, S. Vercauteren, and D. Verkest,
“Hardware/software co-design of digital telecommunication systems,” Proceedings of the IEEE,
1997.

[201] B. Rajendran, A. Sebastian, and E. Eleftheriou, “Building next-generation AI systems: Co-

optimization of algorithms, architectures, and nanoscale memristive devices,” in IMW, 2019.

[202] D. Chae and P. Kapoor, “Centralized generic interfaces in hardware/software co-design for ai

accelerators,” in ICSE Workshops, 2020.

[203] S. Lee, S. Lee, J. Lee, J.-M. Choi, D.-W. Kwon, S.-K. Hong, and K.-W. Kwon, “Architecture-
accuracy co-optimization of ReRAM-based low-cost neural network processor,” in GLSVLSI,
2020.

[204] Y. Kim, S. Kim, C.-C. Yeh, V. Narayanan, and J. Choi, “Hardware and software co-optimization

for the initialization failure of the ReRAM-based crossbar array,” JETC, 2020.

[205] Q. Wu, L. Tao, H. Liang, W. Yuan, T. Tian, S. Xue, and X. Jin, “Software-hardware co-
optimization on partial-sum problem for PIM-based neural network accelerator,” in HPEC,
2021.

[206] F. Liu, C. Liu, and F. Bi, “A memristor based unsupervised neuromorphic system towards fast

and energy-eﬃcient GAN,” arXiv, 2018.

[207] Y. Li, R. Chen, B. Sensale-Rodriguez, W. Gao, and C. Yu, “Real-time multi-task diﬀractive deep

neural networks via hardware-software co-design,” Scientiﬁc Reports, 2021.

[208] H.-Y. Cheng, C. Hakert, K.-H. Chen, Y.-H. Chang, J.-J. Chen, C.-L. Yang, T.-W. Kuo et al.,
“Future computing platform design: A cross-layer design approach,” in DATE, 2021.
[209] F. Sunny, A. Mirza, M. Nikdast, and S. Pasricha, “CrossLight: A cross-layer optimized silicon

photonic neural network accelerator,” arXiv, 2021.

[210] M. A. Hanif and M. Shaﬁque, “A cross-layer approach towards developing eﬃcient embedded

deep learning systems,” Microprocessors and Microsystems, 2022.

[211] O. Bringmann, W. Ecker, I. Feldner, A. Frischknecht, C. Gerum, T. H¨am¨al¨ainen, M. A. Hanif,
M. J. Klaiber, D. Mueller-Gritschneder, P. P. Bernardo et al., “Automated hw/sw co-design
for edge ai: State, challenges and steps ahead: Special session paper,” in CODES+ ISSS, 2021.
[212] Y. Li, J. Park, M. Alian, Y. Yuan, Z. Qu, P. Pan, R. Wang, A. Schwing, H. Esmaeilzadeh, and
N. S. Kim, “A network-centric hardware/algorithm co-design to accelerate distributed training
of deep neural networks,” in MICRO, 2018.

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 40

[213] K. Kwon, A. Amid, A. Gholami, B. Wu, K. Asanovic, and K. Keutzer, “Co-design of deep neural

nets and neural net accelerators for embedded vision applications,” in DAC, 2018.

[214] M. Zhu, T. Zhang, Z. Gu, and Y. Xie, “Sparse tensor core: Algorithm and hardware co-design

for vector-wise sparse neural networks on modern GPUs,” in MICRO, 2019.

[215] M. Baharani, U. Sunil, K. Manohar, S. Furgurson, and H. Tabkhi, “Deepdive: An integrative
algorithm/architecture co-design for deep separable convolutional neural networks,” in
GLSVLSI, 2021.

[216] A. Amid, K. Kwon, A. Gholami, B. Wu, K. Asanovi´c, and K. Keutzer, “Co-design of deep neural
nets and neural net accelerators for embedded vision applications,” IBM Journal of Research
and Development, 2019.

[217] C. Hao and D. Chen, “Deep neural network model and FPGA accelerator co-design:

Opportunities and challenges,” in ICSICT, 2018.

[218] K. Guo, L. Sui, J. Qiu, S. Yao, S. Han, Y. Wang, and H. Yang, “From model to FPGA: Software-

hardware co-design for eﬃcient neural network acceleration,” in HCS, 2016.

[219] C. Hao, J. Dotzel, J. Xiong, L. Benini, Z. Zhang, and D. Chen, “Enabling design methodologies

and future trends for edge AI: Specialization and co-design,” D & T, 2021.

[220] C. Zhou, F. G. Redondo, J. B¨uchel, I. Boybat, X. T. Comas, S. Nandakumar, S. Das, A. Sebastian,
M. L. Gallo, and P. N. Whatmough, “AnalogNets: ML-HW co-design of noise-robust TinyML
models and always-on analog compute-in-memory accelerator,” arXiv, 2021.

[221] N. K. Jayakodi, J. R. Doppa, and P. P. Pande, “A general hardware and software co-design

framework for energy-eﬃcient edge AI,” in ICCAD, 2021.

[222] J. Ambrosi, A. Ankit, R. Antunes, S. R. Chalamalasetti, S. Chatterjee, I. El Hajj, G. Fachini,
P. Faraboschi, M. Foltin, S. Huang et al., “Hardware-software co-design for an analog-digital
accelerator for machine learning,” in ICRC, 2018.

[223] Y. Ji, Y. Zhang, S. Li, P. Chi, C. Jiang, P. Qu, Y. Xie, and W. Chen, “NEUTRAMS: Neural
network transformation and co-design under neuromorphic hardware constraints,” in MICRO,
2016.

[224] Z. Zhao, D. Liu, M. Li, Z. Ying, L. Zhang, B. Xu, B. Yu, R. T. Chen, and D. Z. Pan, “Hardware-

software co-design of slimmed optical neural networks,” in ASPDAC, 2019.

[225] X. Sui, Q. Wu, J. Liu, Q. Chen, and G. Gu, “A review of optical neural networks,” IEEE Access,

2020.

[226] T. Lu, S. Wu, X. Xu, and T. Francis, “Two-dimensional programmable optical neural network,”

Applied Optics, 1989.

[227] I. Shariv and A. Friesem, “All-optical neural network with inhibitory neurons,” Optics Letters,

1989.

[228] H. Stoll and L. Lee, “A continuous-time optical neural network.” in ICNN, 1988.
[229] T. Wang, S.-Y. Ma, L. G. Wright, T. Onodera, B. C. Richard, and P. L. McMahon, “An optical

neural network using less than 1 photon per multiplication,” Nature Communications, 2022.

[230] A. Paul, M. A. S. Tajin, A. Das, W. Mongan, and K. Dandekar, “Energy-eﬃcient respiratory

anomaly detection in premature newborn infants,” Electronics, 2022.

[231] J. S. Plank, G. S. Rose, M. E. Dean, C. D. Schuman, and N. C. Cady, “A uniﬁed
hardware/software co-design framework for neuromorphic computing devices and applications,”
in ICRC, 2017.

[232] H. An, M. S. Al-Mamun, M. K. Orlowski, L. Liu, and Y. Yi, “Three-dimensional neuromorphic

computing system with two-layer and low-variation memristive synapses,” TCAD, 2021.

[233] W. Severa, C. M. Vineyard, R. Dellana, S. J. Verzi, and J. B. Aimone, “Whetstone: A method
for training deep artiﬁcial neural networks for binary communication,” arXiv, 2018.
[234] M. M. Shulaker, T. F. Wu, M. M. Sabry, H. Wei, H.-S. P. Wong, and S. Mitra, “Monolithic 3D

integration: A path from concept to reality,” in DATE, 2015.

[235] K.-N. Tu, “Reliability challenges in 3D IC packaging technology,” Microelectronics Reliability,

2011.

Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review 41

[236] S.-Y. Lee and J. Park, “Architecture of 3D memory cell array on 3D IC,” in IMW, 2012.
[237] P.-Y. Chen, X. Peng, and S. Yu, “NeuroSim: A circuit-level macro model for benchmarking

neuro-inspired architectures in online learning,” TCAD, 2018.

[238] Z. Shi, C. Sakhuja, M. Hashemi, K. Swersky, and C. Lin, “Learned hardware/software co-design

of neural accelerators,” arXiv, 2020.

[239] A. D. Pimentel, “Exploring exploration: A tutorial introduction to embedded systems design

space exploration,” IEEE Design & Test, 2016.

[240] K. Lahiri, A. Raghunathan, and S. Dey, “Design space exploration for optimizing on-chip

communication architectures,” TCAD, 2004.

[241] R. Piscitelli and A. D. Pimentel, “Design space pruning through hybrid analysis in system-level

design space exploration,” in DATE, 2012.

[242] A. Das, A. Kumar, B. Veeravalli, C. Bolchini, and A. Miele, “Combined DVFS and mapping
exploration for lifetime and soft-error susceptibility improvement in MPSoCs,” in DATE, 2014.
[243] J. Lee, S. Kang, J. Lee, D. Shin, D. Han, and H.-J. Yoo, “The hardware and algorithm co-design

for energy-eﬃcient DNN processor on edge/mobile devices,” TCAS I: Regular Papers, 2020.

[244] C. D. Schuman, J. P. Mitchell, R. M. Patton, T. E. Potok, and J. S. Plank, “Evolutionary

optimization for neuromorphic systems,” in NICE Workshop, 2020.

[245] C. D. Schuman, J. S. Plank, A. Disney, and J. Reynolds, “An evolutionary optimization framework

for neural networks and neuromorphic architectures,” in IJCNN, 2016.

[246] S. Li, S. Tian, Z. Kang, L. Qu, S. Wang, L. Wang, and W. Xu, “A multi-objective LSM/NoC

architecture co-design framework,” JSA, 2021.

[247] M. Lukoˇseviˇcius and H. Jaeger, “Reservoir computing approaches to recurrent neural network

training,” Computer Science Review, 2009.

[248] W. Maass, “Liquid state machines: motivation, theory, and applications,” Computability in

Context: computation and logic in the real world, 2011.

[249] H. Fang, B. Taylor, Z. Li, Z. Mei, H. H. Li, and Q. Qiu, “Neuromorphic algorithm-hardware

codesign for temporal pattern learning,” in DAC, 2021.

[250] C. D. Schuman, J. S. Plank, M. Parsa, S. R. Kulkarni, N. Skuda, and J. P. Mitchell, “A software
framework for comparing training approaches for spiking neuromorphic systems,” in IJCNN,
2021.

[251] J. A. Oltra-Oltra, J. Madrenas, M. Zapata, B. Vallejo, D. Mata-Hernandez, and S. Sato,
“Hardware-software co-design for eﬃcient and scalable real-time emulation of SNNs on the
edge,” in ISCAS, 2021.

[252] C. Frenkel, D. Bol, and G. Indiveri, “Bottom-up and top-down neural processing systems design:
Neuromorphic intelligence as the convergence of natural and artiﬁcial intelligence,” arXiv, 2021.
[253] A. Ankit, A. Sengupta, P. Panda, and K. Roy, “RESPARC: A reconﬁgurable and energy-eﬃcient

architecture with memristive crossbars for deep spiking neural networks,” in DAC, 2017.

[254] A. Mallik, D. Garbin, A. Fantini, D. Rodopoulos, R. Degraeve, J. Stuijt, A. Das, S. Schaafsma,
P. Debacker, G. Donadio et al., “Design-technology co-optimization for OxRRAM-based
synaptic processing unit,” in VLSIT, 2017.

[255] A. Paul and A. Das, “Design technology co-optimization for neuromorphic computing,” in IGSC

Workshops, 2021.

[256] B. W. Ku, Y. Liu, Y. Jin, S. Samal, P. Li, and S. K. Lim, “Design and architectural co-
optimization of monolithic 3d liquid state machine-based neuromorphic processor,” in DAC,
2018.

[257] P.-Y. Chen, D. Kadetotad, Z. Xu, A. Mohanty, B. Lin, J. Ye, S. Vrudhula, J.-s. Seo, Y. Cao,
and S. Yu, “Technology-design co-optimization of resistive cross-point array for accelerating
learning algorithms on chip,” in DATE, 2015.

