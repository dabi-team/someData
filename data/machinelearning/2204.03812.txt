Exploring the Universality of Hadronic Jet Classiﬁcation

Kingman Cheung,1,5 Yi-Lun Chung,1 Shih-Chieh Hsu,2 and Benjamin Nachman3,4

1Department of Physics and Center for Theory and Computation, National Tsing Hua Uni-
versity, Hsinchu 300, Taiwan
2Department of Physics, University of Washington, Seattle, Washington 98195, USA
3Physics Division, Lawrence Berkeley National Laboratory, Berkeley, CA 94720, USA
4Berkeley Institute for Data Science, University of California, Berkeley, CA 94720, USA
5Division of Quantum Phases and Devices, School of Physics,Konkuk University, Seoul 143-
701, Republic of Korea

E-mail: cheung@phys.nthu.edu.tw, s107022801@m107.nthu.edu.tw,
schsu@uw.edu, bpnachman@lbl.gov

Abstract: The modeling of jet substructure signiﬁcantly diﬀers between Parton Shower
Monte Carlo (PSMC) programs. Despite this, we observe that machine learning classiﬁers
trained on diﬀerent PSMCs learn nearly the same function. This means that when these clas-
siﬁers are applied to the same PSMC for testing, they result in nearly the same performance.
This classiﬁer universality indicates that a machine learning model trained on one simulation
and tested on another simulation (or data) will likely be optimal. Our observations are based
on detailed studies of shallow and deep neural networks applied to simulated Lorentz boosted
Higgs jet tagging at the LHC.

2
2
0
2

r
p
A
8

]
h
p
-
p
e
h
[

1
v
2
1
8
3
0
.
4
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
Contents

1 Introduction

2 Numerical Examples

2.1 Monte Carlo Samples
2.2 High-level Features
2.3 Low-level Features

3 Classiﬁer Architectures

4 Results

5 Conclusions and Outlook

A Remaining Results

2

3
3
4
4

6

8

13

14

– 1 –

1 Introduction

Deep learning is becoming widely used for various classiﬁcation tasks in collider physics (see
e.g., Ref. [1–6]). One of the core beneﬁts of deep learning over traditional analysis techniques
is that it is able to identify patterns in very high-dimensional feature spaces. At the Large
Hadron Collider (LHC), such low-level inputs are dominated by hadronic activity. Most
machine learning approaches are trained using Parton Shower Monte Carlo (PSMC) simula-
tions that produce exclusive ﬁnal states with the same complexity as real data [7]. However,
there are signiﬁcant variations between PSMCs due to the large number of perturbative and
non-perturbative modeling assumptions.

These variations lead to potential biases and suboptimal sensitivity in data analyses [8].
A bias occurs when the simulation model used for inference (given an analysis strategy) is
not the same as nature. There is a large and growing literature on methods to reduce biases
from PSMC model variations through decorrelation [9–12] and other approaches [13–15]. A
key challenge with modeling uncertainties in contrast to experimental uncertainties is that
they are often estimated by comparing two simulations. This diﬀerence does not have a
statistical origin and may not be the full uncertainty, so caution is required to reduce the
uncertainty through automated approaches [16]. A general solution to estimating (and then
reducing) systematic uncertainties from PSMC variations is still an active area of research
and development1.

In principle, the same challenge exists when quantifying suboptimal performance due
to PSMC variations. Suboptimal performance occurs when the simulation model used for
training a machine learning model is diﬀerent than nature. While not directly a source
of systematic uncertainty, this suboptimality has important consequences for the physics
program of the LHC. To quantify the suboptimality, one could compare diﬀerent PSMC
models, as is done for determine the systematic uncertainty. This has the same unsatisfying
properties as described above.

However, there have been a number of hints in the literature that the suboptimality due
to PSMC variations may actually be small. For example, Ref. [19] observed that training a
quark versus gluon jet classiﬁer with the Herwig [20] PSMC and then applying it to jets
simulated with the Pythia [21] PSMC has nearly the same performance as training with
Pythia and also testing on Pythia (with a statistically identical, but independent dataset).
This small diﬀerence in performance is contrasted to the large diﬀerence in performance when
testing on jets from Herwig. From this observation, we conjecture that the deep learning
models are learning universal properties of quantum chromodynamics (QCD). We hypothesis
that the performance gaps present when the test sets diﬀer simply reﬂects variations in the
amount of QCD radiation, but not the type of information that is useful for discrimination.
To build intuition for this conjecture, consider the case of quark versus gluon jet tagging.
At leading logarithmic (LL) order and considering only infrared and collinear safe observables,
the optimal classiﬁer is simply the number of perturbative emissions inside the jet [22]. This

1See Ref. [17, 18] for the possibility of using machine learning to bound these uncertainties.

– 2 –

statement is true independent of the strong coupling constant, αs. However, common metrics
of performance such as the Area Under the Curve (AUC) depend on αs; when there are
more emissions (higher αs), the quark and gluon perturbative multiplicity distributions are
more separable. In particular, at LL, perturbative multiplicity is a Poisson random variable
with a mean that is proportional to a color factor multiplied by αs. As αs grows, the gluon
distribution grows signiﬁcantly faster than the quark one:

µg − µq
(cid:113)
g + σ2
σ2
q

∼

αs(CF − CA)
√
αsCF + αsCA

√

∝

αs ,

(1.1)

where CF = 4/3 (CA = 3) is the quark (gluon) color factor. Imagine that two PSMCs had the
same physics approximations, but diﬀerent values of αs. They would ﬁnd the same classiﬁer
and thus if the test set is the same, the performance would be the same.

Our goal is to test the universality hypothesis in detail using the important benchmark
problem of Lorentz boosted Higgs boson jet versus QCD jet tagging. We consider both
shallow and deep learning models as well as a variety of PSMC models.

This paper is organized as follows. A concrete example are introduced in Sec. 2. Archi-
tectures of deep-learning classiﬁers are in Sec. 3. The results are provided in Sec. 4. The
paper ends with conclusions and outlook in Sec. 5.

2 Numerical Examples

Lorenz-boosted Higgs tagging, focusing on the b¯b ﬁnal state, is the example in this study.
High-level features and low-level inputs are used to train shallow and deep-learning classiﬁers.

2.1 Monte Carlo Samples
This study considers Lorenz-boosted Higgs tagging, focusing on the b¯b ﬁnal state. The
signal is high pT Higgs bosons and the background is generic quark and gluon jets. The
hard-scatter reactions are common to all parton shower models and are generated with Mad-
Graph5 aMC@NLO 2.7.3 [23] for modeling pp collisions at
[24] parton distribution function and the NNPDF30 nlo as 0118 [25] parton distribution func-
tion are used for signal and background, respectively.

s = 14 TeV. The PDF4LHC15 nnlo mc

√

The hard-scattering events are passed to Pythia 8.303 [21] to simulate the parton shower
and hadronization, using three diﬀerent complete parton-shower frameworks. The ﬁrst one is
default setting, where evolution variable is virtuality of the oﬀ-shell propagator. The second
framework is Virtual Numerical Collider with Interleaved Antennae (Vincia) shower[26–28],
where the evolution variable is transverse momentum for QCD + EW/QED showers based
on the antenna formalism. The last framework is Dipole resummation (Dire), which is
a transverse-momentum ordered dipole shower. Herwig 7.2.2 [20] with angularly-ordered
showers is also used to model the parton shower and hadronization. Pyjet [29, 30] and the
anti-kt [31] algorithm with radius parameter R = 1.0 are used to deﬁne the jets.

– 3 –

An event preselection similar to Ref. [32] is used to reject most background events. The
Higgs-like jet is required to satisfy 300 GeV < pJ
T < 500 GeV, 110 GeV < invariant mass of
the jet (MJ ) < 160 GeV and to be double b-tagged. Jets are declared double b-tagged if they
have two or more ghosted-associated [33, 34] B hadrons. After the preselection, the high-level
jet features and low-level features are used to probe the universality of discriminating boosted
Higgs jets from QCD jets.

Since the goal of this paper is to investigate the universality of hadronic jet classiﬁcation,
there are a number of simplifying assumptions. The background in the study is only generic
quark and gluon jets. The relatively smaller t¯t background is ignored. For each PSMC setup,
the default parameters are used.

2.2 High-level Features

In order to distinguish Higgs jets via Gradient Tree Boosting (BDT) and a fully connected /
dense neural network, the following six commonly-used high-level features are considered:

1. MJ : invariant mass of the leading jet;

2. τ21 = τ2/τ1 : n-subjettiness ratio [35, 36];

3. D(β)

2 = e(β)

3 /(e(β)

2 )3 with β = 1, 2 : energy correlation function ratios [37];

4. C(β)

2 = e(β)

3 /(e(β)

2 )2 with β = 1, 2 : energy correlation function ratios [38];

where ei is the normalized sum over doublets (i = 2) or triplets (i = 3) of constituents inside
jets, weighted by the product of the constituent transverse momenta and pairwise angular
distances. For this analysis, β is considered to be 1 and 2.

The distributions of these six variables are shown in Fig. 1, in which the capability of
each observable to discriminate between signal and background is demonstrated. The salient
features of these histograms are described below.

The jet invariant mass distribution peaks near the Higgs boson mass of 125 GeV [39] for
the signal and has a broad distribution for the background. In the setup of this study, Herwig
7.2.2 with angularly-ordered showers leads to slightly higher and broader signal peak due to
diﬀerent underlying event structure compared to Pythia 8.303. Similarly, the distributions
of τ21, Dβ
2 show similar position and shape of the peak among the Pythia PSMC’s,
but somewhat diﬀerent for the Herwig Angular. The two-prong structure due to the decay
of massive objects into two hard QCD partons in the case of the signal jets results in low τ21,
D2 and C2.

2 , and Cβ

2.3 Low-level Features

The low-level inputs to the CNN are images of Higgs-like jet [40, 41]. The resolution is 40×40
pixels and in 1R×1R range, where R is the jet radius. The images consist of three channels,

– 4 –

Figure 1: The six high-level features used to distinguish boosted Higgs boson jets from QCD
jets events.

analogous to the Red-Green-Blue (RGB) channels of a color image [19]. The pixel intensity
for the three channels correspond to the sum of the charged particle pT , the sum of the neutral
particle pT , and the number of charged particles in a given region of the image. The Higgs-like

– 5 –

110115120125130135140145150MJ GeV0.000.020.040.060.080.100.120.141/N dN/dMJ / 2 GeV110 GeV < MJ < 160 GeV300 GeV < PJT < 500 GeVHerwig Angular(H)Pythia default(H)Pythia vincia(H)Pythia dipole(H)Herwig Angular(QCD)Pythia default(QCD)Pythia vincia(QCD)Pythia dipole(QCD)0.00.20.40.60.81.0=1210.000.010.020.030.040.050.060.070.081/N dN/d=121 / 0.02 110 GeV < MJ < 160 GeV300 GeV < PJT < 500 GeVHerwig Angular(H)Pythia default(H)Pythia vincia(H)Pythia dipole(H)Herwig Angular(QCD)Pythia default(QCD)Pythia vincia(QCD)Pythia dipole(QCD)0.00.51.01.52.02.53.03.54.0D=120.000.020.040.060.080.100.121/N dN/dD=12 / 0.1 110 GeV < MJ < 160 GeV300 GeV < PJT < 500 GeVHerwig Angular(H)Pythia default(H)Pythia vincia(H)Pythia dipole(H)Herwig Angular(QCD)Pythia default(QCD)Pythia vincia(QCD)Pythia dipole(QCD)012345D=220.000.010.020.030.040.050.061/N dN/dD=22 / 0.1 110 GeV < MJ < 160 GeV300 GeV < PJT < 500 GeVHerwig Angular(H)Pythia default(H)Pythia vincia(H)Pythia dipole(H)Herwig Angular(QCD)Pythia default(QCD)Pythia vincia(QCD)Pythia dipole(QCD)0.00.10.20.30.40.50.6C=120.000.010.020.030.040.050.060.070.080.091/N dN/dC=12 / 0.01 110 GeV < MJ < 160 GeV300 GeV < PJT < 500 GeVHerwig Angular(H)Pythia default(H)Pythia vincia(H)Pythia dipole(H)Herwig Angular(QCD)Pythia default(QCD)Pythia vincia(QCD)Pythia dipole(QCD)0.000.050.100.150.20C=120.000.020.040.060.080.100.121/N dN/dC=12 / 0.005 110 GeV < MJ < 160 GeV300 GeV < PJT < 500 GeVHerwig Angular(H)Pythia default(H)Pythia vincia(H)Pythia dipole(H)Herwig Angular(QCD)Pythia default(QCD)Pythia vincia(QCD)Pythia dipole(QCD)jet images are rotated to align along two-subject’s axis. The leading subjet is at the origin
and the subleading subjet is directly below the leading subjet.
If there is a third-leading
subjet, the image will be reﬂected.All images are normalized so that the intensities all sum to
unity2. After normalization, the pixel intensities are standardized so that their distribution
has mean zero and unit variance. Figure 2 shows the average Higgs-like jet images in the
charged pT channel. The patterns in the charged pT channel are similar to the other two
channels.

Figure 3 shows the diﬀerence between the four PSMC algorithms with respect to Pythia
8.303 default showering, referred to as the nominal simulation. The substructure in jets are
diﬀerent among the other three PSMC simulations with respect to the nominal sample due
to diﬀerent approximations made in the ﬁnal state radiation and other QCD eﬀects. This
diversity of the PSMC approaches may eﬀect the performance of jet classiﬁers trained on
low-level features. Therefore, we train a convolutional neural network-based jet classiﬁer to
explore this generator-dependence of classiﬁcation performance.

(a) Herwig angular

(b) Pythia Default

(c) Pythia VINCIA

(d) Pythia Dipole

Figure 2: Low-level features. The average of 40000 Higgs-like jet images in the charged pT
channel (left column and middle column). Q1 and Q2 denote the new axes after the jet’s
axis is centralized and rotated. The intensity in each pixel is the sum of the charged particle
pT . The total intensity in each image is normalized to unity. Images in right column are the
average diﬀerence between Higgs jet and QCD jet images.

3 Classiﬁer Architectures

The BDT has a ﬁxed number of estimators (1400) with maximum depth 5. The minimum
number of samples is ﬁxed at 5% as required to split an internal node and 1% as required
to be at a leaf node. This BDT model is trained on the high-level features of the jet using

2This may remove useful discriminating information; however, it signiﬁcantly improves the stability of the

machine learning training [42].

– 6 –

-101Q110-1Q2H jet-101Q1QCD jet-101Q1Herwig Angular(H-QCD)/(std. dev)0.000.020.000.020.30.20.10.00.10.2-101Q110-1Q2H jet-101Q1QCD jet-101Q1Pythia Default(H-QCD)/(std. dev)0.000.020.000.020.20.00.2-101Q110-1Q2H jet-101Q1QCD jet-101Q1Pythia Vincia(H-QCD)/(std. dev)0.000.020.000.020.20.00.2-101Q110-1Q2H jet-101Q1QCD jet-101Q1Pythia Dipole(H-QCD)/(std. dev)0.000.020.000.020.20.00.2(a) Higgs jet images comparison to Pythia Default samples.

(b) QCD jet images comparison to Pythia Default samples.

Figure 3: The average diﬀerence between the other generators and the Pythia Default
showering (a) Higgs-like jet images, and (b) QCD jet images. Q1 and Q2 denote the new axes
after the jet’s axis is centralized and rotated.

the scikit-learn library [43]. KerasTuner [44] is used to get the best conﬁguration of
hyperparameters.

The dense neural network has four full connected layers. There are 224, 928, 288 and 1024
neurons, respectively. Rectiﬁed linear unit (ReLU) activation functions are used for all layers
of this neural network. Before the output layer, Dropout [45] regularization is added to reduce
overﬁtting with a dropout rate = 0.01. For this two-class problem, the activation function of
the output layer is a sigmoid function. The binary cross entropy loss function is optimized
during the training. The Adam optimizer [46] with a learning rate of 6.5428×10−5 is used
to select the network weights. The KerasTuner [44] is used to get the best conﬁguration of
hyperparameters. The Keras-2.4.0 library is used to train the dense neural network models
with the TENSORFLOW-2.4.1 [47] backend, on a NVIDIA A100 SXM 80GB Graphical Processing
Unit (GPU).

Details of the CNN are as follows. The convolution ﬁlter is 5×5, the maximum pool-
ing layers are 2×2, and the stride length is 1. ReLU activation functions are used for all
intermediate layers of the neural network. The ﬁrst convolution layer has 96 ﬁlters and the

– 7 –

-101Q110-1Q2(Herwig Angular - Pythia Default)/(std. dev)-101Q1(Pythia Vincia - Pythia Default)/(std. dev)-101Q1(Pythia Dipole - Pythia Default)/(std. dev)0.020.010.000.010.020.020.010.000.010.020.020.010.000.010.02-101Q110-1Q2(Herwig Angular - Pythia Default)/(std. dev)-101Q1(Pythia Vincia - Pythia Default)/(std. dev)-101Q1(Pythia Dipole - Pythia Default)/(std. dev)0.080.060.040.020.000.020.020.010.000.010.020.020.000.02second convolution layer in each stream has 32 ﬁlters. A ﬂatten layer is used after the second
maximum pooling layer. Two dense layers are connected to the ﬂatten layer with 350 and
400 neurons, respectively. Before the output layer, Dropout regularization is added with a
dropout rate = 0.01. As for the dense network, the last activation is a sigmoid function and
binary cross entropy is optimized during training. The AdaDelta optimizer [48] with learning
rate 6.0216×10−3 is used to select the network weights. The KerasTuner [44] is used to get
the best conﬁguration of hyperparameters. The same setup as for the dense network is used
to run the CNN.

4 Results

In this study, the receiver operating characteristic curve (ROC), the area under the ROC
curve (AUC), the maximum signiﬁcance improvement characteristic (SIC) and rejection (in-
verse background eﬃciency) at 50% signal eﬃciency are used to be metrics to quantify the
universality. The AUC is between 0.5 (poor classiﬁcation performance) and 1 (maximum
classiﬁcation performance). The SIC is the signal eﬃciency divided by the square root of the
background eﬃciency and represents by how much (as a multiplicative factor) the signiﬁcance
would improve with a given threshold on the classiﬁer score. The maximum SIC is simply the
maximum SIC attained across all thresholds. In order to quantify the variation from classiﬁer
training itself, the performance is evaluated by k-fold cross-validation technique with k = 50.
In this procedure, the datasets are randomly partitioned into 50 parts and for each one, the
other 49 sets are used for constructing the classiﬁer. The mean and spread over the folds is
used to quantify the model performance.

Figure 4: The QCD rejection (inverse QCD eﬃciency) as a function of the Higgs jet eﬃciency
for classiﬁers applied to Herwig angular jet from four PSMC algorithms. The bottom panel
shows the relative uncertainties.

– 8 –

100101102QCD Jet RejectionBDT Test on Herwig angular sampleHerwig angular, AUC=0.81Pythia default, AUC=0.80Pythia vincia, AUC=0.80Pythia dipole, AUC=0.800.20.40.60.81.0Higgs Jet Efficiency 100101R.U. (%)1001011021/[QCD Jet Rejection]DNN Test on Herwig angular sampleHerwig angular, AUC=0.82Pythia default, AUC=0.81Pythia vincia, AUC=0.81Pythia dipole, AUC=0.810.20.40.60.81.0Higgs Jet Efficiency 100101R.U. (%)1001011021/[QCD Jet Rejection]CNN Test on Herwig angular sampleHerwig angular, AUC=0.90Pythia default, AUC=0.89Pythia vincia, AUC=0.89Pythia dipole, AUC=0.890.20.40.60.81.0Higgs Jet Efficiency 100101R.U. (%)Figure 4 shows four classiﬁers trained on various simulations and then tested on the same
Herwig dataset. Overall, the CNN has the best performance and the DNN is marginally
better than the BDT. The DNN and BDT are trained on the same features and given the
relatively low-dimensionality of the problem, it is unsurprising that the two models have a
similar performance. Overall, the performance is nearly identical for all training sets. This
is even true for the CNN, which has access to low-level substructure information inside the
jets. The insensitivity to the training set is in stark contrast to the sensitivity of the test set,
as summarized in detail below. Additional results can be found in Appendix A.

The performance of Fig. 4 for all combinations of train and test sets for the three machine
learning models are summarized in Fig. 5, 6, and 7. Starting with Fig. 5, we observe that there
is a signiﬁcant spread in performance across test sets (rows). The diﬀerence between Higgs
jets and QCD jets is smaller for Herwig compared with Pythia by almost 10%. However,
the spread in performance for a given test set is about 1%. Similar trends are present for
the rejection at a ﬁxed eﬃciency (Fig. 6) and maximum SIC (Fig. 7) plots, albeit with larger
sensitivities to the machine learning training.

– 9 –

Figure 5: The performance of classiﬁers as quantiﬁed by the AUC when training on a given
PSMC (color) and testing on the PSMC speciﬁed on the vertical axis. The symbols represent
the type of model (BDT, DNN, CNN). The error bars represent the standard deviation over
the k folds.

– 10 –

0.750.800.850.900.951.00AUCHerwig AngularPythia DefaultPythia VinciaPythia DipoleSampleHerwig Ang. ClassifierPythia Def. ClassifierPythia Vin. ClassifierPythia Dip. ClassifierBDTDNNCNNFigure 6: The performance of classiﬁers as quantiﬁed by the rejection at a ﬁxed signal
eﬃciency of 50% when training on a given PSMC (color) and testing on the PSMC speciﬁed
on the vertical axis. The symbols represent the type of model (BDT, DNN, CNN). The error
bars represent the standard deviation over the k folds.

– 11 –

01020304050Rejection at 50% Signal EfficiencyHerwig AngularPythia DefaultPythia VinciaPythia DipoleSampleHerwig Ang. ClassifierPythia Def. ClassifierPythia Vin. ClassifierPythia Dip. ClassifierBDTDNNCNNFigure 7: The performance of classiﬁers as quantiﬁed by the maximum signiﬁcance improve-
ment when training on a given PSMC (color) and testing on the PSMC speciﬁed on the
vertical axis. The symbols represent the type of model (BDT, DNN, CNN). The error bars
represent the standard deviation over the k folds.

– 12 –

012345678Max Significance ImprovementHerwig AngularPythia DefaultPythia VinciaPythia DipoleSampleHerwig Ang. ClassifierPythia Def. ClassifierPythia Vin. ClassifierPythia Dip. ClassifierBDTDNNCNN5 Conclusions and Outlook

We have explored the universality of classiﬁers trained on hadronic jet tagging. In particular,
we have studied the sensitivity of the learned classiﬁer to the Parton Shower Monte Carlo pro-
gram used during training. While the modeling of the hadronic structure diﬀers signiﬁcantly
among PSMCs, we ﬁnd that the actual function learned is nearly independent of the training
set. This gives us conﬁdence that a classiﬁer trained on one PSMC and tested on another
(or data) will likely still be optimal. Although it is not directly a source of uncertainty for
physics analysis, this observation has important implications for making the best use of our
data. The classiﬁer universality does not mean that the systematic uncertainty from hadronic
modeling is small as bias and optimality are separate concepts (see e.g., Ref. [8]).

The universality not only has important experimental implications, but also motivates
further theoretical studies. As in the quark versus gluon jet example referenced in Sec. 1, the
universality of the classiﬁers suggests that a theoretical explanation of the classiﬁcation per-
formance may be attainable as it should be insensitive to the detailed modeling assumptions
of a particular PSMC program. We look forward to studies in this direction.

Uncertainty quantiﬁcation is a critical component of any analysis at the LHC and this
task is particularly challenging for analysis strategies like machine learning that are sensitive
to low-level hadronic modeling. While determining systematic uncertainties on the potential
bias of a result from hadronic modeling is still an active area of research and development, we
have shown that at least the optimality of machine learning classiﬁers is relatively insensitive
to hadronic modeling. While we have observed this disconnect between bias and optimality
for Higgs jet tagging, we conjecture that this is a generic feature of QCD and it may also be
present in other systems at the LHC and beyond.

Acknowledgments

K. Cheung and Y.-L.Chung are supported by the Taiwan MoST with the grant number
MOST-110-2112-M-007-017-MY3. S.-C. Hsu is supported by the U.S. Department of En-
ergy, Oﬃce of Science, Oﬃce of Early Career Research Program under Award number DE-
SC0015971. B. Nachman is supported by the U.S. Department of Energy, Oﬃce of Science
under contract DE-AC02-05CH11231.

– 13 –

A Remaining Results

Varied trained classiﬁers, test on Herwig angular sample

Metric: Area Under the Curve

Trained Model

Classiﬁer Type

Herwig Angular
Pythia Default
Pythia Vincia
Pythia Dipole
Average ± Std.

BDT

dense neural network

CNN

0.82 ± 0.0058
0.80 ± 0.0056
0.80 ± 0.0050
0.81 ± 0.0049
0.81 ± 0.0064

0.82 ± 0.0056
0.81 ± 0.0069
0.81 ± 0.0062
0.81 ± 0.0043
0.81 ± 0.0054

0.90 ± 0.0039
0.89 ± 0.0043
0.89 ± 0.0044
0.89 ± 0.0044
0.89 ± 0.0047

Metric: Rejection at 50% Signal Eﬃciency

Trained Model

Classiﬁer Type

Herwig Angular
Pythia Default
Pythia Vincia
Pythia Dipole
Average ± Std.

BDT

dense neural network

CNN

10.91 ± 0.84
9.34 ± 0.57
9.48 ± 0.57
10.19 ± 0.64
9.98 ± 0.63

11.21 ± 0.83
9.81 ± 0.80
10.14 ± 0.85
10.60 ± 0.66
10.44 ± 0.52

19.91 ± 1.81
16.87 ± 1.43
17.70 ± 1.56
17.23 ± 1.55
17.93 ± 1.18

Metric: Max Signiﬁcance Improvement

Trained Model

Classiﬁer Type

Herwig Angular
Pythia Default
Pythia Vincia
Pythia Dipole
Average ± Std.

BDT

dense neural network

CNN

1.86 ± 0.31
1.86 ± 0.45
1.83 ± 0.30
1.90 ± 0.34
1.87 ± 0.03

1.92 ± 0.29
1.88 ± 0.46
1.89 ± 0.42
1.88 ± 0.40
1.89 ± 0.02

2.73 ± 0.72
2.37 ± 0.48
2.40 ± 0.41
2.43 ± 0.49
2.48 ± 0.14

Table 1: Area under the curve, rejection at 50% signal eﬃciency and maximum signiﬁcance
improvement when testing on Herwig for each trained classiﬁer. The last rows are the
average and standard deviation over the mean values from the other rows.

– 14 –

Figure 8: The QCD rejection (inverse QCD eﬃciency) as a function of the Higgs jet eﬃciency
for classiﬁers applied to Pythia default sample from four PSMC algorithms. The bottom
panel shows the relative uncertainties.

Figure 9: The QCD rejection (inverse QCD eﬃciency) as a function of the Higgs jet eﬃciency
for classiﬁers applied to Pythia VNICIA jet from four PSMC algorithms. The bottom panel
shows the relative uncertainties.

– 15 –

100101102QCD Jet RejectionBDT Test on Pythia default sampleHerwig angular, AUC=0.84Pythia default, AUC=0.85Pythia vincia, AUC=0.85Pythia dipole, AUC=0.850.20.40.60.81.0Higgs Jet Efficiency 100101R.U. (%)1001011021/[QCD Jet Rejection]DNN Test on Pythia default sampleHerwig angular, AUC=0.85Pythia default, AUC=0.86Pythia vincia, AUC=0.86Pythia dipole, AUC=0.860.20.40.60.81.0Higgs Jet Efficiency 100101R.U. (%)1001011021/[QCD Jet Rejection]CNN Test on Pythia default sampleHerwig angular, AUC=0.91Pythia default, AUC=0.92Pythia vincia, AUC=0.91Pythia dipole, AUC=0.910.20.40.60.81.0Higgs Jet Efficiency 100101R.U. (%)100101102QCD Jet RejectionBDT Test on Pythia vincia sampleHerwig angular, AUC=0.86Pythia default, AUC=0.87Pythia vincia, AUC=0.87Pythia dipole, AUC=0.870.20.40.60.81.0Higgs Jet Efficiency 100101R.U. (%)1001011021/[QCD Jet Rejection]DNN Test on Pythia vincia sampleHerwig angular, AUC=0.87Pythia default, AUC=0.87Pythia vincia, AUC=0.88Pythia dipole, AUC=0.870.20.40.60.81.0Higgs Jet Efficiency 100101R.U. (%)1001011021/[QCD Jet Rejection]CNN Test on Pythia vincia sampleHerwig angular, AUC=0.93Pythia default, AUC=0.93Pythia vincia, AUC=0.94Pythia dipole, AUC=0.930.20.40.60.81.0Higgs Jet Efficiency 100101R.U. (%)Varied trained classiﬁers, test on Pythia default sample

Metric: Area Under the Curve

Trained Model

Classiﬁer Type

Herwig Angular
Pythia Default
Pythia Vincia
Pythia Dipole
Average ± Std.

BDT

dense neural network

CNN

0.84 ± 0.0055
0.86 ± 0.0043
0.85 ± 0.0051
0.85 ± 0.0042
0.85 ± 0.0053

0.85 ± 0.0057
0.86 ± 0.0047
0.86 ± 0.0048
0.86 ± 0.0039
0.85 ± 0.0042

0.91 ± 0.0032
0.92 ± 0.0032
0.91 ± 0.0035
0.91 ± 0.0034
0.91 ± 0.0041

Metric: Rejection at 50% Signal Eﬃciency

Trained Model

Classiﬁer Type

Herwig Angular
Pythia Default
Pythia Vincia
Pythia Dipole
Average ± Std.

BDT

dense neural network

CNN

15.94 ± 1.25
19.11 ± 1.67
18.04 ± 1.57
18.03 ± 1.51
17.78 ± 1.15

16.80 ± 1.78
19.11 ± 1.51
18.48 ± 1.89
18.35 ± 1.52
18.18 ± 0.85

21.73 ± 1.55
28.23 ± 2.81
24.15 ± 1.75
24.07 ± 1.89
24.55 ± 2.34

Metric: Max Signiﬁcance Improvement

Trained Model

Classiﬁer Type

Herwig Angular
Pythia Default
Pythia Vincia
Pythia Dipole
Average ± Std.

BDT

dense neural network

CNN

2.46 ± 0.44
3.64 ± 0.94
3.12 ± 0.86
3.06 ± 0.78
3.07 ± 0.42

3.10 ± 0.73
3.56 ± 0.93
3.24 ± 0.77
3.36 ± 0.81
3.31 ± 0.17

2.87 ± 0.59
3.68 ± 0.88
3.12 ± 0.92
3.19 ± 0.91
3.21 ± 0.29

Table 2: Area under the curve, rejection at 50% signal eﬃciency and maximum signiﬁcance
improvement when testing on Pythia default for each trained classiﬁer. The last rows are
the average and standard deviation over the mean values from the other rows.

– 16 –

Varied trained classiﬁers, test on Pythia VINCIA sample

Metric: Area Under the Curve

Trained Model

Classiﬁer Type

Herwig Angular
Pythia Default
Pythia Vincia
Pythia Dipole
Average ± Std.

BDT

dense neural network

CNN

0.86 ± 0.0040
0.87 ± 0.0043
0.87 ± 0.0051
0.87 ± 0.0043
0.87 ± 0.0047

0.87 ± 0.0059
0.87 ± 0.0051
0.88 ± 0.0045
0.87 ± 0.0045
0.87 ± 0.0040

0.93 ± 0.0033
0.93 ± 0.0035
0.94 ± 0.0031
0.93 ± 0.0034
0.93 ± 0.0035

Metric: Rejection at 50% Signal Eﬃciency

Trained Model

Classiﬁer Type

Herwig Angular
Pythia Default
Pythia Vincia
Pythia Dipole
Average ± Std.

BDT

dense neural network

CNN

24.47 ± 2.55
27.80 ± 2.93
29.19 ± 3.05
28.01 ± 3.16
27.37 ± 1.76

25.94 ± 3.54
28.45 ± 3.35
30.16 ± 3.26
29.28 ± 3.72
28.46 ± 1.57

36.52 ± 3.84
39.58 ± 5.73
47.66 ± 6.29
41.25 ± 4.51
41.25 ± 4.07

Metric: Max Signiﬁcance Improvement

Trained Model

Classiﬁer Type

Herwig Angular
Pythia Default
Pythia Vincia
Pythia Dipole
Average ± Std.

BDT

dense neural network

CNN

4.45 ± 1.24
5.64 ± 1.48
6.00 ± 1.79
5.29 ± 1.30
5.34 ± 0.58

5.34 ± 1.27
5.62 ± 1.37
5.77 ± 1.45
5.82 ± 1.56
5.64 ± 0.19

5.11 ± 1.26
5.24 ± 1.57
5.81 ± 1.56
5.48 ± 1.46
5.41 ± 0.27

Table 3: Area under the curve, rejection at 50% signal eﬃciency and maximum signiﬁcance
improvement when testing on Pythia VINCIA for each trained classiﬁer. The last rows are
the average and standard deviation over the mean values from the other rows.

– 17 –

Figure 10: The QCD rejection (inverse QCD eﬃciency) as a function of the Higgs jet
eﬃciency for classiﬁers applied to Pythia dipole jet from four PSMC algorithms. The bottom
panel shows the relative uncertainties.

– 18 –

100101102QCD Jet RejectionBDT Test on Pythia dipole sampleHerwig angular, AUC=0.85Pythia default, AUC=0.86Pythia vincia, AUC=0.86Pythia dipole, AUC=0.860.20.40.60.81.0Higgs Jet Efficiency 100101R.U. (%)1001011021/[QCD Jet Rejection]DNN Test on Pythia dipole sampleHerwig angular, AUC=0.86Pythia default, AUC=0.87Pythia vincia, AUC=0.87Pythia dipole, AUC=0.870.20.40.60.81.0Higgs Jet Efficiency 100101R.U. (%)1001011021/[QCD Jet Rejection]CNN Test on Pythia dipole sampleHerwig angular, AUC=0.92Pythia default, AUC=0.92Pythia vincia, AUC=0.93Pythia dipole, AUC=0.930.20.40.60.81.0Higgs Jet Efficiency 100101R.U. (%)Varied trained classiﬁers, test on Pythia dipole sample

Metric: Area Under the Curve

Trained Model

Classiﬁer Type

Herwig Angular
Pythia Default
Pythia Vincia
Pythia Dipole
Average ± Std.

BDT

dense neural network

CNN

0.86 ± 0.0040
0.86 ± 0.0045
0.87 ± 0.0043
0.87 ± 0.0046
0.86 ± 0.0029

0.86 ± 0.0053
0.87 ± 0.0045
0.87 ± 0.0042
0.87 ± 0.0048
0.87 ± 0.0025

0.92 ± 0.0027
0.92 ± 0.0029
0.93 ± 0.0029
0.93 ± 0.0027
0.93 ± 0.0030

Metric: Rejection at 50% Signal Eﬃciency

Trained Model

Classiﬁer Type

Herwig Angular
Pythia Default
Pythia Vincia
Pythia Dipole
Average ± Std.

BDT

dense neural network

CNN

22.01 ± 2.52
22.73 ± 2.40
23.63 ± 2.58
24.56 ± 2.72
23.23 ± 0.96

22.96 ± 2.91
23.75 ± 2.48
24.19 ± 2.12
24.65 ± 2.31
23.89 ± 0.62

33.10 ± 3.97
35.18 ± 4.26
36.84 ± 4.86
41.11 ± 6.17
36.56 ± 2.94

Metric: Max Signiﬁcance Improvement

Trained Model

Classiﬁer Type

Herwig Angular
Pythia Default
Pythia Vincia
Pythia Dipole
Average ± Std.

BDT

dense neural network

CNN

3.83 ± 1.05
4.47 ± 1.14
4.29 ± 1.09
4.57 ± 1.10
4.29 ± 0.28

4.25 ± 1.10
4.69 ± 1.33
4.42 ± 1.20
4.61 ± 1.18
4.49 ± 0.17

4.60 ± 1.48
4.67 ± 1.28
4.85 ± 1.43
5.28 ± 1.62
4.85 ± 0.26

Table 4: Area under the curve, rejection at 50% signal eﬃciency and maximum signiﬁcance
improvement when testing on Pythia dipole for each trained classiﬁer. The last rows are the
average and standard deviation over the mean values from the other rows.

– 19 –

Varied trained BDT models test on ﬁxed sample

metric: area under the curve

Trained Model

Fixed Sample

Herwig Angular Pythia Default Pythia Vincia Pythia Dipole

Herwig Angular
Pythia Default
Pythia Vincia
Pythia Dipole
Average ± Std.

0.82 ± 0.0058
0.80 ± 0.0056
0.80 ± 0.0050
0.81 ± 0.0049
0.81 ± 0.0064

0.84 ± 0.0055
0.86 ± 0.0043
0.85 ± 0.0051
0.85 ± 0.0042
0.85 ± 0.0053

0.86 ± 0.0040
0.87 ± 0.0043
0.87 ± 0.0051
0.87 ± 0.0043
0.87 ± 0.0047

0.86 ± 0.0040
0.86 ± 0.0045
0.87 ± 0.0043
0.87 ± 0.0046
0.86 ± 0.0029

Trained Model

Fixed Sample

Herwig Angular Pythia Default Pythia Vincia Pythia Dipole

metric: rejection at 50% signal eﬃciency

Herwig Angular
Pythia Default
Pythia Vincia
Pythia Dipole
Average ± Std.

10.91 ± 0.84
9.34 ± 0.57
9.48 ± 0.57
10.19 ± 0.64
9.98 ± 0.63

15.94 ± 1.25
19.11 ± 1.67
18.04 ± 1.57
18.03 ± 1.51
17.78 ± 1.15

24.47 ± 2.55
27.80 ± 2.93
29.19 ± 3.05
28.01 ± 3.16
27.37 ± 1.76

22.01 ± 2.52
22.73 ± 2.40
23.63 ± 2.58
24.56 ± 2.72
23.23 ± 0.96

Trained Model

Fixed Sample

Herwig Angular Pythia Default Pythia Vincia Pythia Dipole

metric: Max Signiﬁcance Improvement

Herwig Angular
Pythia Default
Pythia Vincia
Pythia Dipole
Average ± Std.

1.86 ± 0.31
1.86 ± 0.45
1.83 ± 0.30
1.90 ± 0.34
1.87 ± 0.03

2.46 ± 0.44
3.64 ± 0.94
3.12 ± 0.86
3.06 ± 0.78
3.07 ± 0.42

4.45 ± 1.24
5.64 ± 1.48
6.00 ± 1.79
5.29 ± 1.30
5.34 ± 0.58

3.83 ± 1.05
4.47 ± 1.14
4.29 ± 1.09
4.57 ± 1.10
4.29 ± 0.28

Table 5: Area under the curve, rejection at 50% signal eﬃciency and maximum signiﬁcance
improvement for the BDT model. The last rows are the average and standard deviation over
the mean values from the other rows.

– 20 –

Varied trained DNN models test on ﬁxed sample

metric: area under the curve

Trained Model

Fixed Sample

Herwig Angular Pythia Default Pythia Vincia Pythia Dipole

Herwig Angular
Pythia Default
Pythia Vincia
Pythia Dipole
Average ± Std.

0.82 ± 0.0056
0.81 ± 0.0069
0.81 ± 0.0062
0.81 ± 0.0043
0.81 ± 0.0054

0.85 ± 0.0057
0.86 ± 0.0047
0.86 ± 0.0048
0.86 ± 0.0039
0.85 ± 0.0042

0.87 ± 0.0059
0.87 ± 0.0051
0.88 ± 0.0045
0.87 ± 0.0045
0.87 ± 0.0040

0.86 ± 0.0053
0.87 ± 0.0045
0.87 ± 0.0042
0.87 ± 0.0048
0.87 ± 0.0025

Trained Model

Fixed Sample

Herwig Angular Pythia Default Pythia Vincia Pythia Dipole

metric: rejection at 50% signal eﬃciency

Herwig Angular
Pythia Default
Pythia Vincia
Pythia Dipole
Average ± Std.

11.21 ± 0.83
9.81 ± 0.80
10.14 ± 0.85
10.60 ± 0.66
10.44 ± 0.52

16.80 ± 1.78
19.11 ± 1.51
18.48 ± 1.89
18.35 ± 1.52
18.18 ± 0.85

25.94 ± 3.54
28.45 ± 3.35
30.16 ± 3.26
29.28 ± 3.72
28.46 ± 1.57

22.96 ± 2.91
23.75 ± 2.48
24.19 ± 2.12
24.65 ± 2.31
23.89 ± 0.62

Trained Model

Fixed Sample

Herwig Angular Pythia Default Pythia Vincia Pythia Dipole

metric: Max Signiﬁcance Improvement

Herwig Angular
Pythia Default
Pythia Vincia
Pythia Dipole
Average ± Std.

1.92 ± 0.29
1.88 ± 0.46
1.89 ± 0.42
1.88 ± 0.40
1.89 ± 0.02

3.10 ± 0.73
3.56 ± 0.93
3.24 ± 0.77
3.36 ± 0.81
3.31 ± 0.17

5.34 ± 1.27
5.62 ± 1.37
5.77 ± 1.45
5.82 ± 1.56
5.64 ± 0.19

4.25 ± 1.10
4.69 ± 1.33
4.42 ± 1.20
4.61 ± 1.18
4.49 ± 0.17

Table 6: Area under the curve, rejection at 50% signal eﬃciency and maximum signiﬁcance
improvement for the DNN model. The last rows are the average and standard deviation over
the mean values from the other rows.

– 21 –

Varied trained CNN models test on ﬁxed sample

metric: area under the curve

Trained Model

Fixed Sample

Herwig Angular Pythia Default Pythia Vincia Pythia Dipole

Herwig Angular
Pythia Default
Pythia Vincia
Pythia Dipole
Average ± Std.

0.90 ± 0.0039
0.89 ± 0.0043
0.89 ± 0.0044
0.89 ± 0.0044
0.89 ± 0.0047

0.91 ± 0.0032
0.92 ± 0.0032
0.91 ± 0.0035
0.91 ± 0.0034
0.91 ± 0.0041

0.93 ± 0.0033
0.93 ± 0.0035
0.94 ± 0.0031
0.93 ± 0.0034
0.93 ± 0.0035

0.92 ± 0.0027
0.92 ± 0.0029
0.93 ± 0.0029
0.93 ± 0.0027
0.93 ± 0.0030

Trained Model

Fixed Sample

Herwig Angular Pythia Default Pythia Vincia Pythia Dipole

metric: rejection at 50% signal eﬃciency

Herwig Angular
Pythia Default
Pythia Vincia
Pythia Dipole
Average ± Std.

19.91 ± 1.81
16.87 ± 1.43
17.70 ± 1.56
17.23 ± 1.55
17.93 ± 1.18

21.73 ± 1.55
28.23 ± 2.81
24.15 ± 1.75
24.07 ± 1.89
24.55 ± 2.34

36.52 ± 3.84
39.58 ± 5.73
47.66 ± 6.29
41.25 ± 4.51
41.25 ± 4.07

33.10 ± 3.97
35.18 ± 4.26
36.84 ± 4.86
41.11 ± 6.17
36.56 ± 2.94

Trained Model

Fixed Sample

Herwig Angular Pythia Default Pythia Vincia Pythia Dipole

metric: Max Signiﬁcance Improvement

Herwig Angular
Pythia Default
Pythia Vincia
Pythia Dipole
Average ± Std.

2.73 ± 0.72
2.37 ± 0.48
2.40 ± 0.41
2.43 ± 0.49
2.48 ± 0.14

2.87 ± 0.59
3.68 ± 0.88
3.12 ± 0.92
3.19 ± 0.91
3.21 ± 0.29

5.11 ± 1.26
5.24 ± 1.57
5.81 ± 1.56
5.48 ± 1.46
5.41 ± 0.27

4.60 ± 1.48
4.67 ± 1.28
4.85 ± 1.43
5.28 ± 1.62
4.85 ± 0.26

Table 7: Area under the curve, rejection at 50% signal eﬃciency and maximum signiﬁcance
improvement for the CNN model. The last rows are the average and standard deviation over
the mean values from the other rows.

– 22 –

References

[1] M. Feickert and B. Nachman, A Living Review of Machine Learning for Particle Physics,

arXiv:2102.02770.

[2] A. J. Larkoski, I. Moult, and B. Nachman, Jet Substructure at the Large Hadron Collider: A

Review of Recent Advances in Theory and Machine Learning, Phys. Rept. 841 (2020) 1–63,
[arXiv:1709.04464].

[3] D. Guest, K. Cranmer, and D. Whiteson, Deep Learning and its Application to LHC Physics,

Ann. Rev. Nucl. Part. Sci. 68 (2018) 161–181, [arXiv:1806.11484].

[4] A. Radovic, M. Williams, D. Rousseau, M. Kagan, D. Bonacorsi, A. Himmel, A. Aurisano,

K. Terao, and T. Wongjirad, Machine learning at the energy and intensity frontiers of particle
physics, Nature 560 (2018), no. 7716 41–48.

[5] D. Bourilkov, Machine and Deep Learning Applications in Particle Physics, Int. J. Mod. Phys.

A 34 (2020), no. 35 1930019, [arXiv:1912.08245].

[6] G. Karagiorgi, G. Kasieczka, S. Kravitz, B. Nachman, and D. Shih, Machine Learning in the

Search for New Fundamental Physics, arXiv:2112.03769.

[7] A. Buckley et al., General-purpose event generators for LHC physics, Phys. Rept. 504 (2011)

145–233, [arXiv:1101.2599].

[8] B. Nachman, A guide for deploying Deep Learning in LHC searches: How to achieve optimality

and account for uncertainty, SciPost Phys. 8 (2020) 090, [arXiv:1909.03081].

[9] G. Louppe, M. Kagan, and K. Cranmer, Learning to Pivot with Adversarial Networks, in

Advances in Neural Information Processing Systems (I. Guyon, U. V. Luxburg, S. Bengio,
H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, eds.), vol. 30, Curran Associates,
Inc., 2017. arXiv:1611.01046.

[10] C. Englert, P. Galler, P. Harris, and M. Spannowsky, Machine Learning Uncertainties with
Adversarial Neural Networks, Eur. Phys. J. C79 (2019), no. 1 4, [arXiv:1807.08763].

[11] S. Wunsch, S. J´orger, R. Wolf, and G. Quast, Reducing the dependence of the neural network

function to systematic uncertainties in the input space, arXiv:1907.11674.

[12] J. M. Clavijo, P. Glaysher, and J. M. Katzy, Adversarial domain adaptation to reduce sample

bias of a high energy physics classiﬁer, arXiv:2005.00568.

[13] P. De Castro and T. Dorigo, INFERNO: Inference-Aware Neural Optimisation, Comput. Phys.

Commun. 244 (2019) 170–179, [arXiv:1806.04743].

[14] A. Ghosh, B. Nachman, and D. Whiteson, Uncertainty-aware machine learning for high energy

physics, Phys. Rev. D 104 (2021), no. 5 056026, [arXiv:2105.08742].

[15] N. Simp-

son and L. Heinrich, neos: End-to-End-Optimised Summary Statistics for High Energy Physics, in
20th International Workshop on Advanced Computing and Analysis Techniques in Physics Research:
AI Decoded - Towards Sustainable, Diverse, Performant and Eﬀective Scientiﬁc Computing, 3,
2022. arXiv:2203.05570.

[16] A. Ghosh and B. Nachman, A Cautionary Tale of Decorrelating Theory Uncertainties,

arXiv:2109.08159.

– 23 –

[17] B. Nachman and C. Shimmin, AI Safety for High Energy Physics, arXiv:1910.08606.

[18] A. Stein, X. Coubez, S. Mondal, A. Novak, and A. Schmidt, Improving robustness of jet tagging

algorithms with adversarial training, arXiv:2203.13890.

[19] P. T. Komiske, E. M. Metodiev, and M. D. Schwartz, Deep learning in color: towards
automated quark/gluon jet discrimination, JHEP 01 (2017) 110, [arXiv:1612.01551].

[20] J. Bellm et al., Herwig 7.0/Herwig++ 3.0 release note, Eur. Phys. J. C 76 (2016), no. 4 196,

[arXiv:1512.01178].

[21] T. Sjostrand, S. Mrenna, and P. Z. Skands, A Brief Introduction to PYTHIA 8.1, Comput.

Phys. Commun. 178 (2008) 852–867, [arXiv:0710.3820].

[22] C. Frye, A. J. Larkoski, J. Thaler, and K. Zhou, Casimir Meets Poisson: Improved
Quark/Gluon Discrimination with Counting Observables, JHEP 09 (2017) 083,
[arXiv:1704.06266].

[23] J. Alwall, R. Frederix, S. Frixione, V. Hirschi, F. Maltoni, O. Mattelaer, H. S. Shao, T. Stelzer,
P. Torrielli, and M. Zaro, The automated computation of tree-level and next-to-leading order
diﬀerential cross sections, and their matching to parton shower simulations, JHEP 07 (2014)
079, [arXiv:1405.0301].

[24] J. Butterworth et al., PDF4LHC recommendations for LHC Run II, J. Phys. G 43 (2016)

023001, [arXiv:1510.03865].

[25] NNPDF Collaboration, R. D. Ball et al., Parton distributions for the LHC Run II, JHEP 04

(2015) 040, [arXiv:1410.8849].

[26] P. Skands and R. Verheyen, Multipole photon radiation in the Vincia parton shower, Phys. Lett.

B 811 (2020) 135878, [arXiv:2002.04939].

[27] H. Brooks and C. T. Preuss, Eﬃcient multi-jet merging with the Vincia sector shower, Comput.

Phys. Commun. 264 (2021) 107985, [arXiv:2008.09468].

[28] N. Fischer, S. Prestel, M. Ritzmann, and P. Skands, Vincia for Hadron Colliders, Eur. Phys. J.

C 76 (2016), no. 11 589, [arXiv:1605.06142].

[29] N. Dawe, E. Rodrigues, H. Schreiner, B. Ostdiek, D. Kalinkin, M. R., S. Meehan, aryan26roy,

and domen13, scikit-hep/pyjet: Version 1.8.2, Jan., 2021.

[30] M. Cacciari, G. P. Salam, and G. Soyez, FastJet User Manual, Eur. Phys. J. C72 (2012) 1896,

[arXiv:1111.6097].

[31] M. Cacciari, G. P. Salam, and G. Soyez, The anti-kt jet clustering algorithm, JHEP 04 (2008)

063, [arXiv:0802.1189].

[32] J. Lin, M. Freytsis, I. Moult, and B. Nachman, Boosting H → b¯b with Machine Learning, JHEP

10 (2018) 101, [arXiv:1807.10768].

[33] M. Cacciari, G. P. Salam, and G. Soyez, The Catchment Area of Jets, JHEP 04 (2008) 005,

[arXiv:0802.1188].

[34] A. Buckley and C. Pollard, QCD-aware partonic jet clustering for truth-jet ﬂavour labelling,

Eur. Phys. J. C 76 (2016), no. 2 71, [arXiv:1507.00508].

– 24 –

[35] J. Thaler and K. Van Tilburg, Identifying Boosted Objects with N-subjettiness, JHEP 03 (2011)

015, [arXiv:1011.2268].

[36] J. Thaler and K. Van Tilburg, Maximizing Boosted Top Identiﬁcation by Minimizing

N-subjettiness, JHEP 02 (2012) 093, [arXiv:1108.2701].

[37] A. J. Larkoski, I. Moult, and D. Neill, Power Counting to Better Jet Observables, JHEP 12

(2014) 009, [arXiv:1409.6298].

[38] A. J. Larkoski, G. P. Salam, and J. Thaler, Energy Correlation Functions for Jet Substructure,

JHEP 06 (2013) 108, [arXiv:1305.0007].

[39] Particle Data Group, Review of Particle Physics, Progress of Theoretical and Experimental

Physics 2020 (08, 2020) 083C01.

[40] J. Cogan, M. Kagan, E. Strauss, and A. Schwarztman, Jet-Images: Computer Vision Inspired

Techniques for Jet Tagging, JHEP 02 (2015) 118, [arXiv:1407.5675].

[41] L. de Oliveira, M. Kagan, L. Mackey, B. Nachman, and A. Schwartzman, Jet-images — deep

learning edition, JHEP 07 (2016) 069, [arXiv:1511.05190].

[42] L. de Oliveira, M. Paganini, and B. Nachman, Learning Particle Physics by Example:

Location-Aware Generative Adversarial Networks for Physics Synthesis, arXiv:1701.05927.

[43] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel,

P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher,
M. Perrot, and E. Duchesnay, Scikit-learn: Machine learning in Python, Journal of Machine
Learning Research 12 (2011) 2825–2830.

[44] T. O’Malley, E. Bursztein, J. Long, F. Chollet, H. Jin, L. Invernizzi, et al., “Kerastuner.”

https://github.com/keras-team/keras-tuner, 2019.

[45] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov, Dropout: A simple
way to prevent neural networks from overﬁtting, Journal of Machine Learning Research 15
(2014), no. 56 1929–1958.

[46] D. P. Kingma and J. Ba, Adam: A method for stochastic optimization, 2017.

[47] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado, A. Davis,
J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Isard, Y. Jia,
R. Jozefowicz, L. Kaiser, M. Kudlur, J. Levenberg, D. Man´e, R. Monga, S. Moore, D. Murray,
C. Olah, M. Schuster, J. Shlens, B. Steiner, I. Sutskever, K. Talwar, P. Tucker, V. Vanhoucke,
V. Vasudevan, F. Vi´egas, O. Vinyals, P. Warden, M. Wattenberg, M. Wicke, Y. Yu, and
X. Zheng, TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. Software
available from tensorﬂow.org.

[48] M. D. Zeiler, ADADELTA: an adaptive learning rate method, CoRR abs/1212.5701 (2012)

[arXiv:1212.5701].

– 25 –

