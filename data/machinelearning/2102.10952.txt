1
2
0
2

b
e
F
2
2

]
L
C
.
s
c
[

1
v
2
5
9
0
1
.
2
0
1
2
:
v
i
X
r
a

ARXIV PREPRINT

1

A Relational Tsetlin Machine with Applications to
Natural Language Understanding

Rupsa Saha, Ole-Christoffer Granmo, Vladimir I. Zadorozhny, Morten Goodwin

Abstract—TMs are a pattern recognition approach that uses ﬁnite state machines for learning and propositional logic to represent
patterns. In addition to being natively interpretable, they have provided competitive accuracy for various tasks. In this paper, we
increase the computing power of TMs by proposing a ﬁrst-order logic-based framework with Herbrand semantics. The resulting TM is
relational and can take advantage of logical structures appearing in natural language, to learn rules that represent how actions and
consequences are related in the real world. The outcome is a logic program of Horn clauses, bringing in a structured view of
unstructured data. In closed-domain question-answering, the ﬁrst-order representation produces 10× more compact KBs, along with
an increase in answering accuracy from 94.83% to 99.48%. The approach is further robust towards erroneous, missing, and
superﬂuous information, distilling the aspects of a text that are important for real-world understanding.

(cid:70)

1 INTRODUCTION

U SING Artiﬁcial Intelligence (AI) to answer natural lan-

guage questions has long been an active research area,
considered as an essential aspect in machines ultimately
achieving human-level world understanding. Large-scale
structured knowledge bases (KBs), such as Freebase [1],
have been a driving force behind successes in this ﬁeld.
The KBs encompass massive ever-growing amounts of in-
formation, which enable easier handling of Open-Domain
Question-Answering (QA) [2] by organizing a large variety
of answers in a structured format. The difﬁculty arises in
successfully interpreting natural language by artiﬁcially in-
telligent agents, both to build the KBs from natural language
text resources and to interpret the questions asked.

Generalization beyond the information stored in a KB
further complicates the QA problem. Human-level world
understanding requires abstracting from speciﬁc examples
to build more general concepts and rules. When the infor-
mation stored in the KB is error-free and consistent, gener-
alization becomes a standard inductive reasoning problem.
However, abstracting world-knowledge entails dealing with
uncertainty, vagueness, exceptions, errors, and conﬂicting
information. This is particularly the case when relying on
AI approaches to extract and structure information, which
is notoriously error-prone.

This paper addresses the above QA challenges by
proposing a Relational TM that builds non-recursive ﬁrst-
order Horn clauses from speciﬁc examples, distilling general
concepts and rules.

Tsetlin Machines [3] are a pattern recognition approach
to constructing human-understandable patterns from given
data, founded on propositional logic. While the idea of
Tsetlin automaton (TA) [4] have been around since 1960s,
using them in pattern recognition is relatively new. TMs

• R. Saha, O. C. Granmo and M. Goodwin are with Centre for AI Research,

Department of IKT, University of Agder, Norway.

• V. I. Zadorozhny is with School of Computing and Information, Univer-
sity of Pittsburgh, USA, and Centre for AI Research, University of Agder,
Norway.

have successfully addressed several machine learning tasks,
including natural language understanding [5], [6], [7], [8],
[9], image analysis [10], classiﬁcation [11], regression [12],
and speech understanding [13]. The propositional clauses
constructed by a TM have high discriminative power and
constitute a global description of the task learnt [8], [14].
Apart from maintaining accuracy comparable to state-of-
the-art machine learning techniques, the method also has
provided a smaller memory footprint and faster inference
than more traditional neural network-based models [11],
[13], [15], [16]. Furthermore, [17] shows that TMs can be
fault-tolerant, able to mask stuck-at faults. However, al-
though TMs can express any propositional formula by using
disjunctive normal form, ﬁrst-order logic is required to ob-
tain the computing power equivalent to a universal Turing
machine. In this paper, we take the ﬁrst steps towards
increasing the computing power of TMs by introducing a
ﬁrst order TM framework with Herbrand semantics, referred
to as the Relational TM. Accordingly, we will in the following
denote the original approach as Propositional TMs.

Closed-Domain Question-Answering: As proof-of-
concept, we apply our proposed Relational TM to so-called
Closed-Domain QA. Closed-Domain QA assumes a text
(single or multiple sentences) followed by a question which
refers to some aspect of the preceding text. Accordingly, the
amount of information that must be navigated is less than
for open question-answering. Yet, answering closed-domain
questions poses a signiﬁcant natural language understand-
ing challenge.

Consider the following example of information, taken
from [18]: “The Black Death is thought to have originated
in the arid plains of Central Asia, where it then travelled
along the Silk Road, reaching Crimea by 1343. From there,
it was most likely carried by Oriental rat ﬂeas living on
the black rats that were regular passengers on merchant
ships.”One can then have questions such as “Where did the
black death originate?” or “How did the black death make it
to the Mediterranean and Europe?”. These questions can be
answered completely with just the information provided,
hence it is an example of closed-domain question answer-

 
 
 
 
 
 
ARXIV PREPRINT

2

ing. However, mapping the question to the answer requires
not only natural language processing, but also a fair bit of
language understanding.

Here is a much simpler example: “Bob went to the
garden. Sue went to the cafe. Bob walked to the ofﬁce.”
This information forms the basis for questions like “Where
is Bob?” or “Where is Sue?”. Taking it a step further, given
the previous information and questions, one can envision
a model that learns to answer similar questions based on
similar information, even though the model has never seen
the speciﬁcs of the information before (i.e., the names and
the locations).

With QA being such an essential area of Natural Lan-
guage Understanding, there has been a lot of different
approaches proposed. Common methods to QA include the
following:

• Linguistic techniques, such as tokenization, POS tag-
ging and parsing that transform questions into a precise
query that merely extracts the respective response from
a structured database;

• Statistical techniques such as Support Vector Machines,
Bayesian Classiﬁers, and maximum entropy models,
trained on large amount of data, specially for open QA;
• Pattern matching using surface text patterns with tem-

plates for response generation.

Many methods use a hybrid approach encompassing more
than one of these approaches for increased accuracy. Most
QA systems suffer from a lack of generality, and are tuned
for performance in restricted use cases. Lack of available
explainabilty also hinders researchers’ quest to identify pain
points and possible major improvements [19], [20].

Paper Contributions: Our main contributions in this

paper are as follows:

• We introduce a Relational TM, as opposed to a proposi-
tional one, founded on non-recursive Horn clauses and
capable of processing relations, variables and constants.
• We propose an accompanying relational framework
for efﬁcient representation and processing of the QA
problem.

• We provide empirical evidence uncovering that the
Relational TM produces at least one order of magnitude
more compact KBs than the Propositional TM. At the
same time, answering accuracy increases from 94.83%
to 99.48% because of more general rules.

• We provide a model-theoretical interpretation for the

proposed framework.

Overall, our Relational TM uniﬁes knowledge representa-
tion, learning, and reasoning in a single framework.

Paper Organization: The paper is organized as follows.
In Section 2, we present related work on Question Answer-
ing. Section 3 focuses on the background of the Proposi-
tional TM and the details of the new Relational TM. In
Sections 4 and 5, we describe how we employ Relational
TMs in QA and related experiments.

2 BACKGROUND AND RELATED WORK
The problem of QA is related to numerous aspects of Knowl-
edge Engineering and Data Management.

Knowledge engineering deals with constructing and
maintaining knowledge bases to store knowledge of the

real world in various domains. Automated reasoning tech-
niques use this knowledge to solve problems in domains
that ordinarily require human logical reasoning. Therefore,
the two key issues in knowledge engineering are how
to construct and maintain knowledge bases, and how to
derive new knowledge from existing knowledge effectively
and efﬁciently. Automated reasoning is concerned with the
building of computing systems that automate this process.
Although the overall goal is to automate different forms of
reasoning, the term has largely been identiﬁed with valid
deductive reasoning as conducted in logical systems. This is
done by combining known (yet possibly incomplete) infor-
mation with background knowledge and making inferences
regarding unknown or uncertain information.

Typically, such a system consists of subsystems like
knowledge acquisition system, the knowledge base itself,
inference engine, explanation subsystem and user interface.
The knowledge model has to represent the relations be-
tween multiple components in a symbolic, machine under-
standable form, and the inference engine has to manipulate
those symbols to be capable of reasoning. The “way to
reason” can range from earlier versions that were simple
rule-based systems to more complex and recent approaches
based on machine learning, especially on Deep Learning.
Typically, rule-based systems suffered from lack of gener-
ality, and the need for human experts to create rules in
the ﬁrst place. On the other hand most machine learning
based approaches have the disadvantage of not being able
to justify decisions taken by them in human understandable
form [21], [22].

While databases have long been a mechanism of choice
for storing information, they only had inbuilt capability
to identify relations between various components, and did
not have the ability to support reasoning based on such
relations. Efforts to combine formal
logic programming
with relational databases led to the advent of deductive
databases. In fact, the ﬁeld of QA is said to have arisen from
the initial goal of performing deductive reasoning on a set of
given facts [23]. In deductive databases, the semantics of the
information are represented in terms of mathematical logic.
Queries to deductive databases also follow the same logical
formulation [24]. One such example is ConceptBase [25],
which used the Prolog-inspired language O-Telos for logical
knowledge representation and querying using deductive
object-oriented database framework.

With the rise of the internet, there came a need for
uniﬁcation of information on the web. The Semantic Web
(SW) proposed by W3C is one of the approaches that
bridges the gap between the Knowledge Representation and
the Web Technology communities. However, reasoning and
consistency checking is still not very well developed, despite
the underlying formalism that accompanies the semantic
web. One way of introducing reasoning is via descriptive
logic. It involves concepts (unary predicates) and roles
(binary predicates) and the idea is that implicitly captured
knowledge can be inferred from the given descriptions of
concepts and roles [26], [27].

One of the major learning exercises is carried out by
the NELL mechanism proposed by [28], which aims to
learn many semantic categories from primarily unlabeled
data. At present, NELL uses simple frame-based knowledge

ARXIV PREPRINT

3

representation, augmented by the PRA reasoning system.
The reasoning system performs tractable, but limited types
of reasoning based on restricted Horn clauses. NELL’s capa-
bilities is already limited in part by its lack of more powerful
reasoning components; for example, it currently lacks meth-
ods for representing and reasoning about time and space.
Hence, core AI problems of representation and tractable
reasoning are also core research problems for never-ending
learning agents.

While other approaches such as neural networks are
considered to provide attribute-based learning, Inductive
Logic Programming (ILP) is an attempt to overcome their
limitations by moving the learning away from the attributes
themselves and more towards the level of ﬁrst-order pred-
icate logic. ILP builds upon the theoretical framework of
logic programming and looks to construct a predicate logic
given background knowledge, positive examples and neg-
ative examples. One of the main advantages of ILP over
attribute-based learning is ILP’s generality of representation
for background knowledge. This enables the user to pro-
vide, in a more natural way, domain-speciﬁc background
knowledge to be used in learning. The use of background
knowledge enables the user both to develop a suitable
problem representation and to introduce problem-speciﬁc
constraints into the learning process. Over the years, ILP
has evolved from depending on hand-crafted background
knowledge only, to employing different technologies in
order to learn the background knowledge as part of the
process. In contrast to typical machine learning, which uses
feature vectors, ILP requires the knowledge to be in terms of
facts and rules governing those facts. Predicates can either
be supplied or deducted, and one of the advantages of this
method is that newer information can be added easily, while
previously learnt information can be maintained as required
[29]. Probabilistic inductive logic programming is an exten-
sion of ILP, where logic rules, as learnt from the data, are
further enhanced by learning probabilities associated with
such rules [30], [31], [32].

To sum up, none of the above approaches can be ef-
ﬁciently and systematically applied to the QA problem,
especially in uncertain and noisy environments. In this
paper we propose a novel approach to tackle this problem.
Our approach is based on relational representation of QA,
and using a novel Relational TM technique for answering
questions. We elaborate on the proposed method in the next
two sections.

3 BUILDING A RELATIONAL TSETLIN MACHINE

3.1 Tsetlin Machine Foundation

A Tsetlin Automaton (TA) is a deterministic automaton that
learns the optimal action among the set of actions offered
by an environment. It performs the action associated with
its current state, which triggers a reward or penalty based
on the ground truth. The state is updated accordingly, so
that the TA progressively shifts focus towards the optimal
action [4]. A TM consists of a collection of such TAs, which
together create complex propositional formulas using con-
junctive clauses.

3.1.1 Classiﬁcation
A TM takes a vector X = (x1, . . . , xf ) of propositional
variables as input, to be classiﬁed into one of two classes,
y = 0 or y = 1. Together with their negated counter-
parts, ¯xk = ¬xk = 1 − xk, the features form a literal set
L = {x1, . . . , xf , ¯x1, . . . , ¯xf }. We refer to this “regular” TM
as a Propositional TM, due to the input it works with and
the output it produces.

A TM pattern is formulated as a conjunctive clause Cj,

formed by ANDing a subset Lj ⊆ L of the literal set:

Cj(X) = (cid:86)

lk = (cid:81)

lk∈Lj

lk.

lk∈Lj

(1)

E.g., the clause Cj(X) = x1 ∧ x2 = x1x2 consists of the
literals Lj = {x1, x2} and outputs 1 iff x1 = x2 = 1.

The number of clauses employed is a user set parame-
ter n. Half of the n clauses are assigned positive polarity
(C +
j ). The
clause outputs, in turn, are combined into a classiﬁcation
decision through summation:

j ). The other half is assigned negative polarity (C −

j (X).

j=1 C +

j=1 C −

v = (cid:80)n/2

j (X) − (cid:80)n/2
In effect, the positive clauses vote for y = 1 and the negative
for y = 0. Classiﬁcation is performed based on a majority
vote, using the unit step function: ˆy = u(v) = 1 if v ≥
0 else 0. The classiﬁer ˆy = u (x1 ¯x2 + ¯x1x2 − x1x2 − ¯x1 ¯x2),
for instance, captures the XOR-relation.

(2)

3.1.2 Learning

Alg. 1 encompasses the entire learning procedure. We ob-
serve that, learning is performed by a team of 2f TAs per
clause, one TA per literal lk (Alg. 1, Step 2). Each TA has
two actions – Include or Exclude – and decides whether to
include its designated literal lk in its clause.

TMs learn on-line, processing one training example
(X, y) at a time (Step 7). The TAs ﬁrst produce a new
conﬁguration of clauses (Step 8), C +
n/2, followed by
calculating a voting sum v (Step 9).

1 , . . . , C −

Feedback are then handed out stochastically to each TA
team. The difference (cid:15) between the clipped voting sum
vc and a user-set voting target T decides the probability
of each TA team receiving feedback (Steps 12-20). Note
that the voting sum is clipped to normalize the feedback
probability. The voting target for y = 1 is T and for y = 0
it is −T . Observe that for any input X, the probability of
reinforcing a clause gradually drops to zero as the voting
sum approaches the user-set target. This ensures that clauses
distribute themselves across the frequent patterns, rather
than missing some and over-concentrating on others.

Clauses receive two types of feedback. Type I feedback
produces frequent patterns, while Type II feedback increases
the discrimination power of the patterns.

Type I feedback is given stochastically to clauses with
positive polarity when y = 1 and to clauses with negative
polarity when y = 0. Each clause, in turn, reinforces its
TAs based on: (1) its output Cj(X); (2) the action of the
TA – Include or Exclude; and (3) the value of the literal lk
assigned to the TA. Two rules govern Type I feedback:

• Include is rewarded and Exclude is penalized with prob-
ability s−1
s whenever Cj(X) = 1 and lk = 1. This re-
inforcement is strong (triggered with high probability)

ARXIV PREPRINT

Algorithm 1 Propositional TM

input Tsetlin Machine TM, Example pool S, Training

for j ← 1, . . . , n/2 do

rounds e, Clauses n, Features f , Voting target T , Speciﬁcity s
1: procedure TRAIN(TM, S, e, n, f, T, s)
2:
3:
4:
5:
6:
7:
8:

j ← RandomlyInitializeClauseTATeam(2f )
j ← RandomlyInitializeClauseTATeam(2f )

TA+
TA−
end for
for i ← 1, . . . , e do

j=1 C −

j (Xi) − (cid:80)n/2

(Xi, yi) ← ObtainTrainingExample(S)
C +
n/2 ← ComposeClauses(TA+
1 , . . . , C −
vi ← (cid:80)n/2
j=1 C +
vc
i ← clip (vi, −T, T )
for j ← 1, . . . , n/2 do
if yi = 1 then
(cid:15) ← T − vc
i
TypeIFeedback(Xi, TA+
TypeIIFeedback(Xi, TA−

j (Xi)

1 , . . . , TA−

n/2)
(cid:46) Vote sum
(cid:46) Clipped vote sum
(cid:46) Update TA teams

(cid:46) Voting error

j , s) if rand() ≤ (cid:15)
j ) if rand() ≤ (cid:15)

2T

2T

(cid:15) ← T + vc
i
TypeIIFeedback(Xi, TA+
TypeIFeedback(Xi, TA−

j ) if rand() ≤ (cid:15)
j , s) if rand() ≤ (cid:15)

2T

2T

(cid:46) Voting error

9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23: end procedure

end for

end for

else

end if

Algorithm 2 Relational TM

input Convolutional Tsetlin Machine TM, Example pool S,

Number of training rounds e
1: procedure TRAIN(TM, S, e)
for i ← 1, . . . , e do
2:
3:
4:
5:
6:
7:
8:
9:
10: end procedure

end for

( ˜X , ˜Y) ← ObtainTrainingExample(S)
A(cid:48) ← ObtainConstants( ˜Y)
( ˜X (cid:48), ˜Y (cid:48)) ← VariablesReplaceConstants( ˜X , ˜Y, A(cid:48))
A(cid:48)(cid:48) ← ObtainConstants( ˜X (cid:48))
Q ← GenerateVariablePermutations( ˜X (cid:48), A(cid:48)(cid:48))
UpdateConvolutionalTM(TM, Q, ˜Y (cid:48))

and makes the clause remember and reﬁne the pattern
it recognizes in X.1

• Include is penalized and Exclude is rewarded with prob-
ability 1
s whenever Cj(X) = 0 or lk = 0. This rein-
forcement is weak (triggered with low probability) and
coarsens infrequent patterns, making them frequent.
Above, the user-conﬁgurable parameter s controls pattern
frequency, i.e., a higher s produces less frequent patterns.

Type II feedback is given stochastically to clauses with
positive polarity when y = 0 and to clauses with nega-
tive polarity when y = 1. It penalizes Exclude whenever
Cj(X) = 1 and lk = 0. Thus, this feedback produces literals
for discriminating between y = 0 and y = 1, by making the
clause evaluate to 0 when facing its competing class. Further
details can be found in [3].

3.2 Relational Tsetlin Machine

In this section, we introduce the Relational TM, which a
major contribution of this paper. It is designed to take

1. Note that the probability s−1
s

positives.

is replaced by 1 when boosting true

4

advantage of logical structures appearing in natural lan-
guage and process them in a way that leads to a compact,
logic-based representation, which can ultimately reduce
the gap between structured and unstructured data. While
the Propositional TM operates on propositional input vari-
ables X = (x1 . . . , xf ), building propositional conjunctive
clauses, the Relational TM processes relations, variables and
constants, building Horn clauses. Based on Fig. 1 and Alg. 2,
we here describe how the Relational TM builds upon the
original TM in three steps. First, we establish an approach
for dealing with relations and constants. This is done by
mapping the relations to propositional inputs, allowing the
use of a standard TM. We then introduce Horn clauses with
variables, showing how this representation detaches the TM
from the constants, allowing for a more compact represen-
tation compared to only using propositional clauses. We
ﬁnally introduce a novel convolution scheme that effectively
manages multiple possible mappings from constants to
variables. While the mechanism of convolution remains the
same as in the original [10], what we wish to attain from
using it in a Relational TM context is completely different,
as explained in the following.

3.2.1 Model-theoretical Interpretation

The concept of Relational TM can be grounded in the
model-theoretical interpretation of a logic program without
functional symbols and with a ﬁnite Herbrand model [33],
[34]. The ability to represent learning in the form of Horn
clauses is extremely useful due to the fact that Horn clauses
are both simple, as well as powerful enough to describe any
logical formula [34].

Next, we deﬁne the Herbrand model of a logic program.
A Herbrand Base (HB) is the set of all possible ground atoms,
i.e., atomic formulas without variables, obtained using pred-
icate names and constants in a logic program P. A Herbrand
Interpretation is a subset I of the Herbrand Base (I ⊆ HB). To
introduce the Least Herbrand Model we deﬁne the immediate
consequence operator T P : P (HB) → P (HB), which for
an Herbrand Interpretation I produces the interpretation that
immediately follows from I by the rules (Horn clauses) in
the program P :

T P (I)

= {A0 ∈ HB | A0 ← A1, ..., An
∈ ground(P ) ∧ {A1, ..., An} ⊆ I} ∪ I.

The least ﬁxed point lfp(TP) of the immediate conse-
quence operator with respect to subset-inclusion is the Least
Herbrand Model (LHM) of the program P . LHM identiﬁes the
semantics of the program P : it is the Herbrand Interpretation
that contains those and only those atoms that follow from
the program:

∀A ∈ HB : P |= A ⇔ A ∈ LHM.

As an example, consider the following program P :

p(a). q(c).
q(X) ← p(X).

Its Herbrand base is

HB = {p(a), p(c), q(a), q(c)},

ARXIV PREPRINT

5

Fig. 1. Relational TM processing steps

and its Least Herbrand Model is:

LHM = lfp(T P ) = {p(a), q(a), q(c)},

which is the set of atoms that follow from the program P .

3.2.2 Learning Problem
Let A = {a1, a2, . . . , aq} be a ﬁnite set of constants and
let R = {r1, r2, . . . , rp} be a ﬁnite set of relations of arity
wu ≥ 1, u ∈ {1, 2, . . . , p}, which forms the alphabet Σ. The
Herbrand base

HB

= {r1(a1, a2, . . . , aw1), r1(a2, a1, . . . , aw1 ),
. . . , rp(a1, a2, . . . , awp ), rp(a2, a1, . . . , awp ), . . .} (3)

is then also ﬁnite, consisting of all the ground atoms that
can be expressed using A and R.

We also have a logic program P , with program rules
expressed as Horn clauses without recursion. Each Horn
clause has the form:

B0 ← B1, B2, · · · , Bd.

(4)

Here, Bl, l ∈ {0, . . . , d}, is an atom ru(Z1, Z2, . . . , Zwu )
with
negation
¬ru(Z1, Z2, . . . , Zwu ). The arity of ru is denoted by
wu.

Z1, Z2, . . . , Zwu ,

variables

its

or

Now, let X be a subset of the LHM of P , X ⊆ lfp(T P ),
and let Y be the subset of the LHM that follows from X
due to the Horn clauses in P . Further assume that atoms
are randomly removed and added to X and Y to produce
a possibly noisy observation ( ˜X , ˜Y), i.e., ˜X and ˜Y are not
necessarily subsets of lfp(T P ). The learning problem is to
predict the atoms in Y from the atoms in ˜X by learning from
a sequence of noisy observations ( ˜X , ˜Y), thus uncovering the
underlying program P .

3.2.3 Relational Tsetlin Machine with Constants

We base our Relational TM on mapping the learning prob-
lem to a Propositional TM pattern recognition problem. We
consider Horn clauses without variables ﬁrst. In brief, we

map every atom in HB to a propositional input xk, obtain-
ing the propositional input vector X = (x1, . . . , xo) (cf. Sec-
tion 3.1). That is, consider the w-arity relation ru ∈ R, which
takes w symbols from A as input. This relation can thus
take qw unique input combinations. As an example, with
the constants A = {a1, a2} and the binary relations R =
{r1, r2}, we get 8 propositional inputs: x1,1
1 ≡ r1(a1, a1);
1 ≡ r1(a2, a1);x2,2
1 ≡ r1(a1, a2); x2,1
x1,2
1 ≡ r1(a2, a2);
2 ≡ r2(a1, a2); x2,1
2 ≡ r2(a1, a1); x1,2
x1,1
2 ≡ r2(a2, a1); and
x2,2
2 ≡ r2(a2, a2). Correspondingly, we perform the same
mapping to get the propositional output vector Y .

Finally, obtaining an input ( ˜X , ˜Y), we set the proposi-
tional input xk to true iff its corresponding atom is in ˜X ,
otherwise it is set to false. Similarly, we set the propositional
output variable ym to true iff its corresponding atom is in
˜Y, otherwise it is set to false.

Clearly, after this mapping, we get a Propositional TM
pattern recognition problem that can be solved as described
in Section 3.1 for a single propositional output ym. This is
illustrated as Step 1 in Fig. 1.

3.2.4 Detaching the Relational TM from Constants

The TM can potentially deal with thousands of proposi-
tional inputs. However, we now detach our Relational TM
from the constants, introducing Horn clauses with variables.
Our intent is to provide a more compact representation of
the program and to allow generalization beyond the data.
Additionally, the detachment enables faster learning even
with less data.

Let Z = {Z1, Z2, . . . , Zz} be z variables representing
the constants appearing in an observation ( ˜X , ˜Y). Here,
z is the largest number of unique constants involved in
any particular observation ( ˜X , ˜Y), each requiring its own
variable.

Seeking Horn clauses with variables instead of constants,
we now only need to consider atoms over variable conﬁgu-
rations (instead of over constant conﬁgurations). Again, we
map the atoms to propositional inputs to construct a propo-
sitional TM learning problem. That is, each propositional

Parent(Bob, Mary)Parent(Mary, Peter)1. Obtain input(possibly with errors)Grandparent(Bob, Peter)Grandparent(Z1, Z2)2. Replace constants inconsequent with variablesParent(Bob, Jane)Parent(Mary, Z2)Parent(Z1, Mary)Parent(Z1, Jane)3. Replace remaining constantswith variables. Generate allreplacement permutations.Cf. Convolutional TM patches.Grandparent(Z1, Z2)Parent(Z4, Z2)Parent(Z1, Z4)Parent(Z1, Z3)Grandparent(Z1, Z2)Parent(Z3, Z2)Parent(Z1, Z3)Parent(Z1, Z4)i)ii)4. Evaluate clause oneach permutation (assume closedworld). Cf. Convolutional TM inference.5. Output OR of evaluationsGrandParent(Z1,Z2) ←Parent(Z1, Z3), Parent(Z3, Z2)i)ii)Compare for reinforcementSubset of Interpretation (TrueGround Atoms)Immediate ConsequentTruth ValueofConsequentARXIV PREPRINT

6

input xk represents a particular atom with a speciﬁc variable
conﬁguration: xk ≡ ru(Zα1, Zα2 , . . . , Zαwu
), with wu being
the arity of ru. Accordingly, the number of constants in
A no longer affects the number of propositional inputs xk
needed to represent the problem. Instead, this is governed
by the number of variables in Z (and, again, the number of
relations in R). That is, the number of propositional inputs
is bounded by O(zw), with w being the largest arity of the
relations in R.

To detach the Relational TM from the constants, we
ﬁrst replace the constants in ˜Y with variables, from left to
right. Accordingly, the corresponding constants in ˜X is also
replaced with the same variables (Step 2 in Fig. 1). Finally,
the constants now remaining in ˜X is arbitrarily replaced
with additional variables (Step 3 in Fig. 1).

3.2.5 Relational Tsetlin Machine Convolution over Variable
Assignment Permutations

Since there may be multiple ways of assigning variables
to constants, the above approach may produce redundant
rules. One may end up with equivalent rules whose only
difference is syntactic, i.e., the same rules are expressed
using different variable symbols. This is illustrated in Step
3 of Fig. 1, where variables can be assigned to constants
in two ways. To avoid redundant rules, the Relational TM
produces all possible permutations of variable assignments.
To process the different permutations, we ﬁnally perform
a convolution over the permutations in Step 4, employing
a TM convolution operator [10]. The target value of the
convolution is the truth value of the consequent (Step 5).

3.2.6 Walk-through of Algorithm with Example Learning
Problem

Fig. 1 contains an example of the process of detaching a Re-
lational TM from constants. We use the parent-grandparent
relationship as an example, employing the following Horn
clause.

grandparent(Z1, Z2) ← parent(Z1, Z3), parent(Z3, Z2).

We replace the constants in each training example with
variables, before learning the clauses. Thus the Relational
TM never “sees” the constants, just the generic variables.
Assume the ﬁrst training example is

Input : parent(Bob, M ary) = 1;
T arget output : child(M ary, Bob) = 1.

Then Mary is replaced with Z1 and Bob with Z2 in the target
output:

Input : parent(Bob, M ary) = 1;
T arget output : child(Z1, Z2) = 1.

We perform the same exchange for the input, getting:

Input : parent(Z2, Z1) = 1;
T arget output : child(Z1, Z2) = 1.

Here, “parent(Z2, Z1)” is treated as an input feature by the
Relational TM. That is, “parent(Z2, Z1)” is seen as a single
propositional variable that is either 0 or 1, and the name
of the variable is simply the string “parent(Z2, Z1)”. The
constants may be changing from example to example, so
next time it may be Mary and Ann. However, they all end up
as Z1 or Z2 after being replaced by the variables. After some
time, the Relational TM would then learn the following
clause:

child(Z1, Z2) ← parent(Z2, Z1).

This is because the feature “parent(Z2, Z1)” predicts
“child(Z1, Z2)” perfectly. Other candidate features like
“parent(Z1, Z1)” or “parent(Z2, Z3)” are poor predictors of
“child(Z1, Z2)” and will be excluded by the TM. Here, Z3
is a free variable representing some other constant, different
from Z1 and Z2.
Then the next training example comes along:

Input : parent(Bob, M ary) = 1;
T arget output : child(Jane, Bob) = 0.

Again, we start with replacing the constants in the target
output with variables:

Input : parent(Bob, M ary) = 1;
T arget output : child(Z1, Z2) = 0
which is then completed for the input:
Input : parent(Z2, M ary) = 1;
T arget output : child(Z1, Z2) = 0.

The constant Mary was not in the target output, so we
introduce a free variable Z3 for representing Mary:

Input : parent(Z2, Z3) = 1;
T arget output : child(Z1, Z2) = 0.

The currently learnt clause was:

child(Z1, Z2) ← parent(Z2, Z1).

The feature “parent(Z2, Z1)” is not present in the input
in the second training example, only “parent(Z2, Z3). As-
suming a closed world, we thus have “parent(Z2, Z1)”=0.
Accordingly, the learnt clause correctly outputs 0.
For some inputs, there can be many different ways variables
can be assigned to constants (for the output, variables are
always assigned in a ﬁxed order, from Z1 to Zz). Returning
to our grandparent example in Fig. 1, if we have:

Input : parent(Bob, M ary); parent(M ary, P eter);

parent(Bob, Jane)

T arget output : grandparent(Bob, P eter).
replacing Bob with Z1 and Peter with Z2, we get:

Input : parent(Z1, M ary); parent(M ary, Z2);

parent(Z1, Jane)
T arget output : grandparent(Z1, Z2).

Above, both Mary and Jane are candidates for being Z3.
One way to handle this ambiguity is to try both, and
pursue those that make the clause evaluate correctly, which
is exactly how the TM convolution operator works [10].
Note that above, there is an implicit existential quan-
tiﬁer over Z3. That
is, ∀Z1, Z2(∃Z3(parent(Z1, Z3) ∧
parent(Z3, Z2) → grandparent(Z1, Z2)).

A practical view of how the TM learns in such a scenario
is shown in Fig. 2. Continuing in the same vein as the
previous examples, the Input Text in the ﬁgure is a set of
statements, each followed by a question. The text is reduced
to a set of relations, which act as the features for the TM to
learn from. The ﬁgure illustrates how the TM learns relevant
information (while disregarding the irrelevant), in order
to successfully answer a new question (Test Document).
The input text is converted into a features vector which
indicates the presence or absence of relations (R1, R2) in
the text, where R1 and R2 are respectively M oveT o (in the
statements) and W hereIs (in the question) relations. For
further simpliﬁcation and compactness of representation,
instead of using person and location names, those speciﬁc
details are replaced by (P1, P2) and (L1, L2), respectively. In
each sample, the person name that occurs ﬁrst is termed P1

ARXIV PREPRINT

7

throughout, the second unique name is termed P2, and so
on, and similarly for the locations. As seen in the ﬁgure, the
TM reduces the feature-set representation of the input into
a set of logical conditions or clauses, all of which together
describe scenarios in which the answer is L2 (or Location 2).
Remark 1. We now return to the implicit existential
and universal quantiﬁers of the Horn clauses, exempli-
ﬁed in: ∀Z1, Z2(∃Z3(parent(Z1, Z3) ∧ parent(Z3, Z2) →
grandparent(Z1, Z2)). A main goal of the procedure in
Fig. 1 is to correctly deal with the quantiﬁers “for all”
and “exists”. “For all” maps directly to the TM architecture
because the TM is operating with conjunctive clauses and
the goal is to make these evaluate to 1 (True) whenever the
learning target is 1. “For all” quantiﬁers are taken care of in
Step 3 of the relational learning procedure.

Remark 2. “Exists” is more difﬁcult because it means
that we are looking for a speciﬁc value for the variables
in the scope of the quantiﬁer that makes the expression
evaluate to 1. This is handled in the Steps 4-6 in Fig. 1,
by evaluating all alternative values (all permutations with
multiple variables involved). Some values make the expres-
sion evaluate to 0 (False) and some make the expression
become 1. If none makes the expression 1, the output of the
clause is 0. Otherwise, the output is 1. Remarkably, this is
exactly the behavior of the TM convolution operator deﬁned
in [10], so we have an existing learning procedure in place
to deal with the “Exists” quantiﬁer. (If there exists a patch
in the image that makes the clause evaluate to 1, the clause
evaluates to 1).

4 QA IN A RELATIONAL TM FRAMEWORK
In this section, we describe the general pipeline to reduce
natural language text into a machine-understandable rela-
tional representation to facilitate question answering. Fig. 3
shows the pipeline diagrammatically, with a small example.
Throughout this section, we make use of two toy examples
in order to illustrate the steps. One of them is derived from
a standard question answering dataset [35]. The other is a
simple handcrafted dataset, inspired by [36], that refers to
parent-child relationships among a group of people. Both
datasets consist of instances, where each instance is a set of
two or more statements, followed by a query. The expected
output for each instance is the answer to the query based on
the statements.

4.1 Relation Extraction

As a ﬁrst step, we need to extract the relation(s) present
in the text. A relation here is a connection between two (or
more) elements of a text. As discussed before, relations occur
in natural language, and reducing a text to its constituent
relations makes it more structured while ignoring superﬂu-
ous linguistic elements, leading to easier understanding. We
assume that our text consists of simple sentences, that is,
each sentence contains only one relation. The relation found
in the query is either equal to, or linguistically related to the
relations found in the statements preceding the query.

Table 1 shows examples of Relation Extraction on our
two datasets. In Example-Movement, each statement has
the relation “MoveTo”, while the query is related to “Lo-
cation”. The “Location” can be thought of as a result of the

“MoveTo” relations. Example-Parentage has “Parent” rela-
tions as the information and “Grandparent” as the query.

TABLE 1
Relation Extraction

Relation
Sentence
MoveTo
Mary went to the ofﬁce.
John moved to the hallway MoveTo
Location
Where is Mary?

Example-Movement

Sentence
Bob is a parent of Mary.
Bob is a parent of Jane.
Mary is a parent of Peter
Is Bob a grandparent of Peter? Grandparent
Example-Parentage

Relation
Parent
Parent
Parent

4.2 Entity Extraction

Once the relations have been identiﬁed, the next step is to
identify the elements of the text (or the entities) that are
participating in the respective relations. Doing so allows
us to further enrich the representation with the addition of
restrictions (often real-world ones), which allow the Rela-
tional TM to learn rules that best represent actions and their
consequences in a concise, logical form. Since the datasets
we are using here consist only of simple sentences, each
relation is limited to having a maximum of two entities (the
relations are unary or binary).

In this step, the more external world knowledge that
can be combined with the extracted entities, the richer the
resultant representation. In Table 2, Example-Movement, we
could add the knowledge that “MoveTo” relation always
involves a “Person” and a “Location”. Or in Example-
Parentage, “Parent” is always between a “Person” and a
“Person”. This could, for example, prevent questions like
“Jean-Joseph Pasteur was the father of Louis Pasteur. Louis
Pasteur is the father of microbiology. Who is the grandfather
of microbiology?”
Note that, as per Fig. 3, it is only possible to start answering
the query after both Relation Extraction and Entity Extrac-
tion have been performed, and not before. Knowledge of the
Relation also allows us to narrow down possible entities for
answering the query successfully.

TABLE 2
Entity Extraction

Sentence
Mary went to the ofﬁce.
John moved to the hallway MoveTo John, hallway
Where is Mary?

Relation
MoveTo Mary, ofﬁce

Location Mary, ?

Entities

Example-Movement
Relation
Parent
Parent
Parent

Sentence
Bob is a parent of Mary.
Bob is a parent of Jane.
Mary is a parent of Peter
Is Bob a grandparent of Peter? Grandparent Bob, Peter
Example-Parentage

Entities
Bob, Mary
Bob, Jane
Mary, Peter

4.3 Entity Generalization

One of the drawbacks of the relational representation is
that there is a huge increase in the number of possible

ARXIV PREPRINT

8

Fig. 2. The Relational TM in operation

work is utilized for question answering using TM.

4.4 Computational Complexity in Relation TM

One of the primary differences between the relational frame-
work proposed in this paper versus the existing TM frame-
work lies in Relation Extraction and Entity Generalization.
The reason for these steps is that they allow us more
ﬂexibility in terms of what the TM learns, while keeping
the general learning mechanism unchanged.

Extracting relations allows the TM to focus only on the
major operations expressed via language, without getting
caught up in multiple superﬂuous expressions of the same
thing. It also enables to bridge the gap between structured
and unstructured data. Using relations helps the resultant
clauses be closer to real-world phenomena, since they model
actions and consequences, rather than the interactions be-
tween words.

Entity Generalization allows the clauses to be succinct
and precise, adding another layer of abstraction away from
speciﬁc literals, much like Relation Extraction. It also gives
the added beneﬁt of making the learning of the TM more
generalized. In fact, due to this process, the learning reﬂects
‘concepts’ gleaned from the training examples, rather than
the examples themselves.

To evaluate computational complexity, we employ the
three costs α, β, and γ , where in terms of computational
cost, α is cost to perform the conjunction of two bits, β is cost
of computing the summation of two integers, and γ is cost
to update the state of a single automaton. In a Propositional
TM, the worst case scenario would be the one in which all
the clauses are updated. Therefore, a TM with m clauses and
an input vector of o features, needs to perform (2o + 1) × m
number of TA updates for a single training sample. For a
total of d training samples, the total cost of updating is d ×
γ × (2o + 1) × m.

Once weight updates have been successfully performed,
the next step is to calculate the clause outputs. Here the
worst case is represented by all the clauses including all the

Fig. 3. General Pipeline

relations as more and more examples are processed. One
way to reduce the spread is to reduce individual enti-
ties from their speciﬁc identities to a more generalised
identity. Let us consider two instances : “Mary went to
the ofﬁce. John moved to the hallway. Where is Mary?”
and “Sarah moved to the garage.
to the
kitchen. Where is Sarah?”. Without generalization, we end
up with six different relations : MoveTo(Mary, Ofﬁce),
MoveTo(John, Hallway), Location(Mary), MoveTo(Sarah,
Garage), MoveTo(James, Kitchen), Location(Sarah). How-
ever, to answer either of the two queries, we only need the
relations pertaining to the query itself. Taking advantage of
that, we can generalize both instances to just 3 relations:
MoveTo(Person1, Location1), MoveTo(Person2, Location2)
and Location(Person1).

James went

In order to prioritise, the entities present in the query
relation are the ﬁrst to be generalized. All occurrences of
those entities in the relations preceding the query are also
replaced by suitable placeholders.

The entities present in the other relations are then re-
placed by what can be considered as free variables (since
they do not play a role in answering the query).

In the next section we explain how this relational frame-

ARXIV PREPRINT

9

TABLE 3
Entity Generalization : Part 1

Sentence
Mary went to the ofﬁce.
John moved to the hallway MoveTo
Where is Mary?

Relation
MoveTo Mary, ofﬁce

Entities

Location Mary, ?

John, hallway

Reduced Relation

Source MoveTo(X, ofﬁce)
Source MoveTo(John, hallway)
Location(X, ?)
Target

Sentence
Bob is a parent of Mary.
Bob is a parent of Jane.
Mary is a parent of Peter
Is Bob a grandparent of Peter? Grandparent

Relation
Parent
Parent
Parent

Example-Movement
Entities
Bob, Mary
Bob, Jane
Mary, Peter
Bob, Peter

Example-Parentage

TABLE 4
Entity Generalization : Part 2

Sentence
Mary went to the ofﬁce.
John moved to the hallway MoveTo
Where is Mary?

Relation
MoveTo Mary, ofﬁce

Entities

Location Mary, ?

John, hallway

Sentence
Bob is a parent of Mary.
Bob is a parent of Jane.
Mary is a parent of Peter
Is Bob a grandparent of Peter? Grandparent

Relation
Parent
Parent
Parent

Example-Movement
Entities
Bob, Mary
Bob, Jane
Mary, Peter
Bob, Peter

Example-Parentage

Source
Source
Source
Target

Reduced Relation
Parent(X, Mary)
Parent(X, Jane)
Parent(Mary, Y)
Grandparent(X, Y)

Reduced Relation

Source MoveTo(X, A)
Source MoveTo(Y, B)
Location(X, ?)
Target

Source
Source
Source
Target

Reduced Relation
Parent(X, Z)
Parent(X, W)
Parent(Z, Y)
Grandparent(X, Y)

corresponding literals, giving us a cost of α × 2o × m (for a
single sample).

The last step involves calculating the difference in votes
from the clause outputs, thus incurring a per-sample cost of
β × (m − 1).

Taken together, the total cost function for a Propositional

TM can be expressed as:

f (d) = d×[(γ×(2o+1)×m)+(α×2o×m)+(β×(m−1))]
Expanding this calculation to the Relation TM scenario,
we need to account for the extra operations being per-
formed, as detailed earlier: Relation Extraction and Entity
Generalization. The number of features per sample is re-
stricted by the number of possible relations, both in the
entirety of the training data, as well as only in the context of
a single sample. For example, in the experiments involving
“MoveTo” relations, we have restricted our data to have 3
statements, followed by a question (elaborated further in the
next section). Each statement gives rise to a single “MoveTo”
relation, which has 2 entities (a location and a person).

When using the textual constants (i.e., without Entity
Generalization), the maximum number of possible features
thus becomes equal to the number of possible combination
between the unique entities in the relations. Thus if each
sample contains r Relations, and a Relation R involves
e different entities (E1, E2, ..., Ee), and cardinality of sets
E1, E2, ..., Ee be represented as |E1|, |E2|, ..., |Ee|, the num-
ber of features in the above equation can be re-written as
(cid:1) × ...(cid:0)|Ee|

o = {(cid:0)|E1|
1
As discussed earlier in Section 4.3 as well as shown in the
previous paragraph, this results in a large o, since it depends
on the number of unique textual elements in each of the en-
tity sets. Using Entity Generalization, the number of features
no longer depends on the cardinality of set En,1≤n≤e in the
context of the whole dataset. Instead, it only depends on the

(cid:1) × (cid:0)|E2|

(cid:1)} × r.

1

1

context of the single sample. Thus, if each sample contains
r Relations, and a Relation R involves e different entities
(E1, E2, ..., Ee), and maximum possible cardinality of sets
E1, E2, ..., Ee are |E1| = |E2| = ... = |En| = r, the number
of features become
(cid:1) × (cid:0)|r|

o = {(cid:0)|r|
In most scenarios, this number is much lower than the

(cid:1)} × r = r(e+1).

(cid:1) × ...(cid:0)|r|

1

1

1

one obtained without the use of Entity Generalization.

A little further modiﬁcation is required when using the
convolutional approach. In calculating f (d), the measure
of o remains the same as we just showed with/without
Entity Generalization. However the second term in the
equation, which refers to the calculation of clause outputs
(d × α × 2o × m), changes due to the difference in mech-
anism of calculating outputs for convolutional and non-
convolutional approaches. In the convolutional approach,
with Entity Generalization, we need to consider free and
bound variables in the feature representation. Bound vari-
ables are the ones which are linked by appearance in the
source and target relations, while the other variables, which
are independent of that restriction, can be referred to as
the free variables. Each possible permutation of the free
variables in different positions are used by the convolutional
approach to determine the best generic rule that describes
the scenario. In certain scenarios, it may be possible to have
certain permutations among the bound variables as well,
without violating the restrictions added by the relations.
One such scenario is detailed with an example in Section
5.2, where a bound “Person” entity can be permuted to
allow any other “Person” entity, as long as the order of
“MoveTo” relations are not violated. However, it is difﬁcult
to get a generic measure for the same, which would work ir-
respective of the nature of the relation (or their restrictions).
Therefore, for the purpose of this calculation, we only take

ARXIV PREPRINT

10

into account the permutations afforded to us by the free
variable. Using the same notation as before, if each sample
contains r Relations, and a Relation R involves e different
entities, the total number of variables is R × e. Of these, if
v is the number of free variables, then they can be arranged
in v! different ways. Assuming v is constant for all samples,
the worst case f (d) can thus be rewritten as

f (d) = d × [(γ × (2o + 1) × m) + (v! × α × 2o × m) +

(β × (m − 1))] .

5 EXPERIMENTAL STUDY

To further illustrate how the TM based logic modelling
works practically, we employ examples from a standard
question answering dataset [35]. For the scope of this work,
we limit ourselves to the ﬁrst subtask as deﬁned in the
dataset, viz. a question that can be answered by the pre-
ceding context, and the context contains a single supporting
fact.

To start with, there is a set of statements, followed
by a question, as discussed previously. For this particular
subtask, the answer to the question is obtained by a single
statement out of the set of statements provided (hence the
term, single supporting fact).

Input:William moved to the ofﬁce. Susan went to the garden.

William walked to the pantry. Where is William?

Output: pantry

We assume the following knowledge to help us construct
the task:

1) All statements only contain information pertaining to

relation MoveTo

2) All questions only relate to information pertaining to

relation CurrentlyAt

Possible Answers :

[Ofﬁce, Pantry, Garden, Foyer,

Kitchen]

Once training is complete, we can use the inherent inter-
pretability of the TM to get an idea about how the model
learns to discriminate the information given to it. The set
of all clauses arrived at by the TM at the end of training
represents a global view of the learning, i.e. what the model
has learnt in general. The global view can also be thought
of as a description of the task itself, as understood by the
machine. We also have access to a local snapshot, which
is particular to each input instance. The local snapshot
involves only those clauses that help in arriving at the
answer for that particular instance.

Table 5 shows the local snapshot obtained for the above
example. As mentioned earlier, the TM model depends on
two sets of clauses for each class, a positive set and a
negative set. The positive set represents information favour
of the class, while the negative set represents the opposite.
The sum of the votes given by these two sets thus represent
the ﬁnal class the model decides on. As seen in the example,
all the classes other than “Pantry” receive more negative
votes than positive, making it the winning class. The clauses
themselves allow us to peek into the learning mechanism.
For the class “Ofﬁce”, a clause captures the information that
(a) the question contains “William”, and (b) the relationship
MoveTo(William, Ofﬁce) is available. This clause votes in
support of the class, i.e. this is an evidence that the answer
to the question “Where is William?” may be “Ofﬁce”. How-
ever, another clause encapsulates the previous two pieces of
information, as well as something more : (c) the relationship
MoveTo(William, Pantry) is available. Not only does this
clause vote against the class “Ofﬁce”, it also ends up with a
larger share of votes than the clause voting positively.

3) Relation MoveTo involves 2 entities,

such that

The accuracy obtained over 100 epochs for this experi-

M oveT o(a, b) : a ∈ {P ersons}, b ∈ {Locations}

ment was 94.83%, with a F-score of 94.80.

4) Relation CurrentlyAt

involves 2 entities, such that

CurrentlyAt(a, b) : a ∈ {P ersons}, b ∈ {Locations}
5) MoveTo is a time-bound relation, it’s effect is super-
seded by a similar action performed at a later time.

5.1 Without Entity Generalization

The size of the set of statements from which the model has to
identify the correct answer inﬂuences the complexity of the
task. For the purpose of this experiment, the data is capped
to have a maximum of three statements per input, and over
all has ﬁve possible locations. This means that the task for
the TM model is reduced to classifying the input into one of
ﬁve possible classes.

To prepare the data for the TM, the ﬁrst step involves re-
ducing the input to relation-entity bindings. These bindings
form the basis of our feature set, which is used to train the
TM. Consider the following input example:

Input => MoveTo(William, Ofﬁce), MoveTo(Susan, Gar-

den), MoveTo(William, Pantry), Q(William).

Since the TM requires binary features, each input is
converted to a vector, where each element represents the
presence (or absence) of the relationship instances.

Secondly, the list of possible answers is obtained from
the data, which is the list of class labels. Continuing our
example, possible answers to the question could be:

5.1.1 Allowing Negative Literals in Clauses

Above results were obtained by only allowing positive liter-
als in the clauses. The descriptive power of the TM goes up
if negative literals are also added. However, the drawback
to that is, while the TM is empowered to make more precise
rules (and by extension, decisions), the overall complexity
of the clauses increase, making them less readable. Also,
previously, the order of the MoveTo action could be implied
by the order in which they appear in the clauses, since only
one positive literal can be present per sentence, but in case
of negative literals, we need to include information about
the sentence order. Using the above example again, if we do
allow negative literals the positive evidence for Class Ofﬁce
looks like:

Q(W illiam) AND N ot(Q(Susan)) AND

M oveT o(S1, W illiam, Off ice) AND
N OT (M oveT o(S3, W illiam, Garden)) AND
N OT (M oveT o(S3, W illiam, F oyer)) AND
N OT (M oveT o(S3, W illiam, Kitchen)) AND
N OT (M oveT o(S3, Susan, Garden)) AND
N OT (M oveT o(S3, Susan, Off ice)) AND
N OT (M oveT o(S3, Susan, P antry)) AND
N OT (M oveT o(S3, Susan, F oyer)) AND
N OT (M oveT o(S3, Susan, Kitchen)).

ARXIV PREPRINT

11

TABLE 5
Local Snapshot of Clauses for example “William moved to the ofﬁce. Susan went to the garden. William walked to the pantry. Where is William?”

Class

Clause

+/- Votes

Total Votes
for Class

Ofﬁce

Pantry

Garden

Foyer

Kitchen

Q(William) AND MoveTo(William, Ofﬁce)
Q(William) AND MoveTo(William, Ofﬁce)˜ AND MoveTo(William, Pantry)
Q(William) AND MoveTo(William, Ofﬁce)˜ AND MoveTo(William, Pantry)
Q(William) AND MoveTo(William, Ofﬁce)
MoveTo(Susan, Garden)
Q(William) AND MoveTo(William, Ofﬁce) AND MoveTo(William, Pantry)
-
Q(William) AND MoveTo(William, Ofﬁce) AND MoveTo(William, Pantry)
AND MoveTo(Susan, Garden)
-
Q(William) AND MoveTo(William, Ofﬁce) AND MoveTo(William, Pantry)
AND MoveTo(Susan, Garden)

+
-
+
-
+
-
+

-

+

-

12
47
64
15
12
48
0

106

0

113

-35

+49

-36

-106

-113

At this point, we can see that the use of constants lead
to a large number of repetitive information in terms of the
rules learnt by the TM. Generalizing the constants as per
their entity type can prevent this.

5.2 Entity Generalization

Given a set of sentences and a following question, the ﬁrst
step remains the same as in the previous subsection, i.e.
reducing the input to relation-entity bindings. In the second
step, we carry out a grouping by entity type, in order to
generalize the information. Once the constants have been
replaced by general placeholders, we continue as previously,
collecting a list of possible outputs (to be used as class
labels), and further, training a TM based model with binary
feature vectors.

As before, the data is capped to have a maximum of three
statements per input. Continuing with the same example as
above,

→ M oveT o(W illiam, off ice) + M oveT o(Susan, garden) +

M oveT o(W illiam, pantry)

→ M oveT o(P1, off ice) + M oveT o(P2, garden) +

M oveT o(P1, pantry)

→ M oveT o(P1, L1) + M oveT o(P2, L2) + M oveT o(P1, L3)
→ M oveT o(P1, L1) + ∗ + M oveT o(P1, Ln)
=⇒ Location(P1, Ln).
From the above two subsections, we can see that with
more and more generalization, the learning encapsulated
in the TM model can approach what could possibly be a
human-level understanding of the world.

5.3 Variable Permutation and Convolution

As described in Section 3.2.5, we can produce all possible
permutations of the available variables in each sample (after
Entity Generalization) as long as the relation constraints
are not violated. Doing this gives us more information per
sample:

Input:William moved to the ofﬁce. Susan went to the garden.

Input:William moved to the ofﬁce. Susan went to the garden.

William walked to the pantry. Where is William?

William walked to the pantry. Where is William?

Output: pantry
1. Reducing

Input
=> MoveTo(William, Ofﬁce), MoveTo(Susan, Garden),
MoveTo(William, Pantry), Q(William)

relation-entity bindings:

to

Output: pantry
1. Reducing

Input
=> MoveTo(William, Ofﬁce), MoveTo(Susan, Garden),
MoveTo(William, Pantry), Q(William)

relation-entity bindings:

to

2. Generalizing bindings: => MoveTo(Per1, Loc1),

2. Generalizing bindings: => MoveTo(Per1, Loc1),

MoveTo(Per2, Loc2), MoveTo(Per1, Loc3), Q(Per1)

MoveTo(Per2, Loc2), MoveTo(Per1, Loc3), Q(Per1)

3. Possible Answers : [Loc1, Loc2, Loc3]

The simplifying effect of generalization is seen right away:
even though there are 5 possible location in the whole
dataset, for any particular instance there are always max-
imum of three possibilities, since there are maximum three
statements per instance.

As seen from the local snapshot (Table 6), the clauses
formed are much more compact and easily understandable.
The generalization also releases the TM model from the
restriction of having had to seen deﬁnite constants before
in order to make a decision. The model can process “Rory
moved to the conservatory. Rory went to the cinema. Cecil
walked to the school. Where is Rory?”, without needing
to have encountered constants “Rory”, “Cecil”, “school”,
“cinema” and “conservatory”.

Accuracy for this experiment over 100 epochs was

99.48% , with a F-score of 92.53.

A logic based understanding of the relation “Move”

could typically be expressed as :

3. Permuted Variables: => MoveTo(Per2, Loc1),

MoveTo(Per1, Loc2), MoveTo(Per2, Loc3), Q(Per2)

4. Possible Answers : [Loc1, Loc2, Loc3]

This has two primary beneﬁts. Firstly, in a scenario where
the given data does not encompass all possible structural
differences in which a particular information maybe rep-
resented, using the permutations allows the TM to view a
closer-to-complete representation from which to build it’s
learning (and hence, explanations). Moreover, since the TM
can learn different structural permutations from a single
sample, it ultimately requires fewer clauses to learn effec-
tively. In our experiments, permutations using Relational
TM Convolution allowed for up to 1.5 times less clauses
than using a non-convolutional approach.

As detailed in Section 4.4, convolutional and non-
convolutional approaches have different computational
complexity. Hence, the convolutional approach makes sense
only when the reduction in complexity from fewer clauses
balance the increase due to processing the convolutional
window itself.

ARXIV PREPRINT

12

TABLE 6
Clause snapshot for “William moved to the ofﬁce. Susan went to the garden. William walked to the pantry. Where is William?” after generalization

Class

Clause

+/- Votes

Total Votes
for Class

Loc1

Loc2

Loc3

Q(Per1) AND MoveTo(Per1, Loc1)
Q(Per1) AND MoveTo(Per1, Loc1)AND MoveTo(Per1, Loc3)
MoveTo(Per1, Loc1)
Q(Per1) AND MoveTo(Per1, Loc3)
Q(Per1) AND MoveTo(Per1, Loc1)AND MoveTo(Per1, Loc3)
-

+
-
+
-
+
-

3
47
2
90
51
0

-44

-88

+51

TABLE 7
Average Accuracy on Test with Increase in Error in Training Data

Error Rate
Accuracy

0%
99.48

1%
98.79

2%
98.24

5%
97.02

10%
95.08

5.4 Noise Tolerance

To verify our claims of noise tolerance as shown by the TM
based architecture, the above experiments were repeated,
but with increasing amount of noise artiﬁcially introduced
into the training data. The results are shown in Table 7. We
observe that with 1%, 2%, 5% and 10% of noise, the testing
accuracy fell by approximately 1.1% each time when entity
generalization was used.

5.5 Horn Clause Representation

The example elaborated in the previous section can be
formulated as the following Horn clause representation:

1) P erson(Susan).
2) P erson(W illiam).
3) Location(Off ice).
4) Location(Garden).
5) Location(P antry).
6) CurrentlyAt(Susan, P antry).
7) CurrentlyAt(W illiam, P antry).
8) M oveT o(Susan, Garden) ← P erson(Susan),

Location(Garden),
not CurrentlyAt(Susan, Garden)

9) M oveT o(W illiam, Off ice) ← P erson(W illiam),

Location(Off ice),
not CurrentlyAt(W illiam, Off ice).

After generalization, we substitute ground rules 8 and 9
with the following rule:
10) M oveT o(P, L) ← P erson(P ), Location(L),

not CurrentlyAt(P, L).

The above set of Horn clauses deﬁne the immediate
consequences operator whose LFP represents the Herbrand
interpretation of our QA framework.

6 CONCLUSION

Making interpretable logical decisions in question answer-
ing system is an area of active research. In this work, we
propose a novel relational logic based TM framework to
approach QA tasks systematically. Our proposed method
takes advantage of noise tolerance showed by TMs to work
in uncertain or ambiguous contexts. We reduce the context-
question-answer tuples to a set of logical arguments, which
is used by the TM to determine rules that mimic real-world
actions and consequences.

The resulting TM is relational (as opposed to the pre-
viously propositional TM) and can take work on logical
structures that occur in natural language in order to encode
rules representing actions and effects in the form of Horn
clauses. We show initial results using the Relational TM on
artiﬁcial datasets of closed-domain question answering, and
those results are extremely promising. The use of ﬁrst-order
representations, as described in this paper, allows KBs to be
up to 10 times smaller, while at the same time showing an
answering accuracy increase of almost 5% to 99.48%.

Further work on this framework will involve a larger
number of relations, with greater inter-dependencies, and
analyzing how well the TM can learn the inherent logical
structure governing such dependencies. We also intend to
introduce recursive Horn clauses to make the computing
power of the Relational TM equivalent to a universal Tur-
ing machine. Moreover, we wish to experiment with this
framework on real-world natural language datasets, rather
than on toy ones. A prominent example is exploring large
corpus of documents related to human rights violation and
using them to assess risks of social instability. We expect that
the resultant logic structures will be large and complicated,
however, once obtained, can be used to effectively translate
to and fro between the machine world and the real world.

REFERENCES

[1] K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor, “Free-
base: a collaboratively created graph database for structuring
human knowledge,” in Proceedings of the 2008 ACM SIGMOD
international conference on Management of data, 2008, pp. 1247–1250.
J. M. Prager, “Open-domain question-answering.” Found. Trends
Inf. Retr., vol. 1, no. 2, pp. 91–231, 2006.

[2]

[3] O.-C. Granmo, “The Tsetlin Machine - A Game Theoretic Bandit
Driven Approach to Optimal Pattern Recognition with Proposi-
tional Logic,” arXiv preprint arXiv:1804.01508, 2018.

[4] M. L. Tsetlin, “On behaviour of ﬁnite automata in random
medium,” Avtom I Telemekhanika, vol. 22, no. 10, pp. 1345–1354,
1961.

[5] R. K. Yadav, L. Jiao, O.-C. Granmo, and M. Goodwin, “Human-
Level Interpretable Learning for Aspect-Based Sentiment Anal-
ysis,” in The Thirty-Fifth AAAI Conference on Artiﬁcial Intelligence
(AAAI-21). AAAI, 2021.

[6] R. K. Yadav, L. Jiao, O.-C. Granmo, and M. Goodwin, “Inter-
pretable classiﬁcation of word sense disambiguation using tsetlin
machine,” in 13th International Conference on Agents and Artiﬁcial
Intelligence (ICAART 2021).

INSTICC, 2021.

[7] B. Bhattarai, L. Jiao, and O.-C. Granmo, “Measuring the Novelty of
Natural Language Text Using the Conjunctive Clauses of a Tsetlin
Machine Text Classiﬁer,” in 13th International Conference on Agents
and Artiﬁcial Intelligence (ICAART 2021).

INSTICC, 2021.

[8] R. Saha, O.-C. Granmo, and M. Goodwin, “Mining Interpretable
Rules for Sentiment and Semantic Relation Analysis using Tsetlin
Machines,” in Lecture Notes in Computer Science: Proceedings of the
40th International Conference on Innovative Techniques and Applica-
tions of Artiﬁcial Intelligence (SGAI-2020). Springer, 2020.

ARXIV PREPRINT

13

[9] G. T. Berge, O.-C. Granmo, T. O. Tveit, M. Goodwin, L. Jiao, and
B. V. Matheussen, “Using the Tsetlin Machine to learn human-
interpretable rules for high-accuracy text categorization with med-
ical applications,” IEEE Access, vol. 7, pp. 115 134–115 146, 2019.

[10] O.-C. Granmo, S. Glimsdal, L. Jiao, M. Goodwin, C. W. Omlin, and
G. T. Berge, “The Convolutional Tsetlin Machine,” arXiv preprint
arXiv:1905.09688, 2019.

[11] K. D. Abeyrathna, O.-C. Granmo, and M. Goodwin, “Extending
the Tsetlin Machine With Integer-Weighted Clauses for Increased
Interpretability,” IEEE Access, vol. 9, 2021.

[12] K. D. Abeyrathna, O.-C. Granmo, X. Zhang, L. Jiao, and M. Good-
win, “The Regression Tsetlin Machine - A Novel Approach to
Interpretable Non-Linear Regression,” Philosophical Transactions of
the Royal Society A, vol. 378, 2019.

[13] J. Lei, T. Rahman, R. Shaﬁk, A. Wheeldon, A. Yakovlev, O.-C.
Granmo, F. Kawsar, and A. Mathur, “Low-Power Audio Keyword
Spotting using Tsetlin Machines,” arXiv preprint arXiv:2101.11336,
2021.

[14] C. D. Blakely and O.-C. Granmo, “Closed-Form Expressions for
Global and Local Interpretation of Tsetlin Machines with Ap-
plications to Explaining High-Dimensional Data,” arXiv preprint
arXiv:2007.13885, 2020.

[15] A. Wheeldon, R. Shaﬁk, A. Yakovlev, J. Edwards, I. Haddadi, and
O.-C. Granmo, “Tsetlin Machine: A New Paradigm for Pervasive
AI,” in SCONA Workshop at Design, Automation and Test in Europe
(DATE 2020), 2020.

[16] J. Lei, A. Wheeldon, R. Shaﬁk, A. Yakovlev, and O.-C. Granmo,
“From Arithmetic to Logic Based AI: A Comparative Analysis of
Neural Networks and Tsetlin Machine,” in 27th IEEE International
Conference on Electronics Circuits and Systems (ICECS2020).
IEEE,
2020.

[17] R. Shaﬁk, A. Wheeldon, and A. Yakovlev, “Explainability and De-
pendability Analysis of Learning Automata based AI Hardware,”
in IEEE 26th International Symposium on On-Line Testing and Robust
System Design (IOLTS).

IEEE, 2020.
[18] P. Rajpurkar, J. Zhang, K. Lopyrev, and P. Liang, “Squad: 100,000+
questions for machine comprehension of text,” arXiv preprint
arXiv:1606.05250, 2016.

[19] M. A. C. Soares and F. S. Parreiras, “A literature review on
question answering techniques, paradigms and systems,” Journal
of King Saud University-Computer and Information Sciences, vol. 32,
no. 6, pp. 635–646, 2020.

[20] A. M. Pundge, S. Khillare, and C. N. Mahender, “Question answer-
ing system, approaches and techniques: a review,” International
Journal of Computer Applications, vol. 141, no. 3, pp. 0975–8887, 2016.
[21] S. A. Ludwig, “Comparison of a deductive database with a seman-
tic web reasoning engine,” Knowledge-Based Systems, vol. 23, no. 6,
pp. 634–642, 2010.

[22] K. Cyras, R. Badrinath, S. K. Mohalik, A. Mujumdar, A. Nikou,
A. Previti, V. Sundararajan, and A. V. Feljan, “Machine reasoning
explainability,” arXiv preprint arXiv:2009.00418, 2020.

[23] C. Green, “Theorem proving by resolution as a basis for question-
answering systems,” Machine intelligence, vol. 4, pp. 183–205, 1969.
[24] H. Gallaire, J. Minker, and J.-M. Nicolas, “Logic and databases:
A deductive approach,” in Readings in Artiﬁcial Intelligence and
Databases. Elsevier, 1989, pp. 231–247.

[25] M. Jarke, R. Gallersd ¨orfer, M. A. Jeusfeld, M. Staudt, and S. Eherer,
“Conceptbase—a deductive object base for meta data manage-
ment,” Journal of Intelligent Information Systems, vol. 4, no. 2, pp.
167–192, 1995.

[26] J. S. Dong, J. Sun, and H. Wang, “Checking and reasoning about
semantic web through alloy,” in International Symposium of Formal
Methods Europe. Springer, 2003, pp. 796–813.

[27] A.-Y. Turhan, “Description logic reasoning for semantic web
ontologies,” in Proceedings of the International Conference on Web
Intelligence, Mining and Semantics, 2011, pp. 1–5.

[28] T. Mitchell, W. Cohen, E. Hruschka, P. Talukdar, B. Yang, J. Bet-
teridge, A. Carlson, B. Dalvi, M. Gardner, B. Kisiel et al., “Never-
ending learning,” Communications of the ACM, vol. 61, no. 5, pp.
103–115, 2018.

[29] A. Cropper, S. Dumanˇci´c, and S. H. Muggleton, “Turning 30:
New ideas in inductive logic programming,” arXiv preprint
arXiv:2002.11002, 2020.

[30] I. Bratko and S. Muggleton, “Applications of inductive logic
programming,” Communications of the ACM, vol. 38, no. 11, pp.
65–70, 1995.

[31] M. Nickles and A. Mileo, “Probabilistic inductive logic pro-
gramming based on answer set programming,” arXiv preprint
arXiv:1405.0720, 2014.

[32] L. De Raedt and K. Kersting, “Probabilistic inductive logic pro-
gramming,” in Probabilistic Inductive Logic Programming. Springer,
2008, pp. 1–27.

[33] J. Lloyd, Foundations of Logic Programming. New York: Springer-

Verlag, 1984.

[34] R. Kowalski, “Logic programming,” in Computational Logic, ser.
Handbook of the History of Logic, J. H. Siekmann, Ed. North-
Holland, 2014, vol. 9, pp. 523–569.

[35] J. Weston, A. Bordes, S. Chopra, A. M. Rush, B. van Merri¨enboer,
A.
Joulin, and T. Mikolov, “Towards ai-complete question
answering: A set of prerequisite toy tasks,” arXiv preprint
arXiv:1502.05698, 2015.

[36] R. Kowalski, “Algorithm= logic+ control,” Communications of the

ACM, vol. 22, no. 7, pp. 424–436, 1979.

Rupsa Saha received her M.Tech degree in in-
formation and communication technology with
specialization in machine intelligence from DAI-
ICT, India in 2014. She is currently pursuing
her Ph.D. on Tsetlin Machines with the Centre
for Artiﬁcial Intelligence Research, University of
Agder, Norway. Her research interests include
machine learning, NLP and chatbots.

Ole-Christoffer Granmo is a Professor and
Founding Director of Centre for Artiﬁcial Intel-
ligence Research (CAIR), University of Agder,
Norway. He obtained his master’s degree in 1999
and the PhD degree in 2004, both from the
University of Oslo, Norway. Dr. Granmo has au-
thored in excess of 140 refereed papers with
6 best paper awards, encompassing learning
automata, bandit algorithms, Tsetlin machines,
Bayesian reasoning, reinforcement learning, and
computational linguistics. He has further coordi-
nated 7+ Norwegian Research Council projects and graduated more
than 60 master- and PhD students. Dr. Granmo is also a co-founder of
the Norwegian Artiﬁcial Intelligence Consortium (NORA). Apart from his
academic endeavours, he co-founded the company Anzyz Technologies
AS.

Vladimir I. Zadorozhny is a Professor at the
University of Pittsburgh School of Computing
and Information. He is also a Core Faculty Mem-
ber at the University of Pittsburgh Biomedical
Informatics Training Program, an Adjunct Profes-
sor at Faculty of Engineering and Science and a
member of the Centre for Artiﬁcial Intelligence
Research, University of Agder, Norway. He re-
ceived his Ph.D. in 1993 from the Institute for
Problems of Informatics, Russian Academy of
Sciences in Moscow. Before coming to USA in
1998 he was a Principal Research Scientist in the Institute of System
Programming, Russian Academy of Sciences. His research interests
include information integration, data fusion, complex adaptive systems
and scalable architectures for wide-area environments. He speciﬁcally
interested in application of scalable data fusion methods to enable
efﬁcient data processing and sense-making in complex domains. His
research has been supported by NSF, EU and Norwegian Research
Council. Vladimir is a recipient of Fulbright Scholarship for 2014-2015.
He has received several best paper awards and has chaired and served
on program committees of multiple Database and Distributed Computing
Conferences and Workshops.

ARXIV PREPRINT

14

Morten Goodwin received the B.Sc. and M.Sc.
degrees from the University of Agder, Norway,
in 2003 and 2005, respectively, and the Ph.D.
degree from Aalborg University Department of
Computer Science, Denmark, in 2011, on ap-
plying machine learning algorithms on eGovern-
ment indicators which are difﬁcult to measure
automatically. He is a Professor with the De-
partment of ICT, the University of Agder, deputy
director for Centre for Artiﬁcial Intelligence Re-
search, a public speaker, and an active re-
searcher. His main research interests include machine learning, in-
cluding swarm intelligence, deep learning, and adaptive learning in
medicine, games, and chatbots. He has more than 100 peer reviews
of scientiﬁc publications. He has supervised more than 110 student
projects, including Master and Ph. D. theses within these topics, and
more than 90 popular science public speaking events, mostly in Artiﬁcial
Intelligence.

