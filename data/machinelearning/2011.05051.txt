Federated Learning via Intelligent Reﬂecting Surface

Zhibin Wang, Student Member, IEEE, Jiahang Qiu, Yong Zhou, Member, IEEE, Yuanming Shi, Member, IEEE,

Liqun Fu, Senior Member, IEEE, Wei Chen, Senior Member, IEEE, and Khaled B. Letaief, Fellow, IEEE

1

0
2
0
2

v
o
N
2
1

]
T
I
.
s
c
[

2
v
1
5
0
5
0
.
1
1
0
2
:
v
i
X
r
a

Abstract—Over-the-air computation (AirComp) based feder-
ated learning (FL) is capable of achieving fast model aggregation
by exploiting the waveform superposition property of multiple
access channels. However, the model aggregation performance is
severely limited by the unfavorable wireless propagation chan-
nels. In this paper, we propose to leverage intelligent reﬂecting
surface (IRS) to achieve fast yet reliable model aggregation
for AirComp-based FL. To optimize the learning performance,
we formulate an optimization problem that jointly optimizes
the device selection, the aggregation beamformer at the base
station (BS), and the phase shifts at the IRS to maximize the
number of devices participating in the model aggregation of
each communication round under certain mean-squared-error
(MSE) requirements. To tackle the formulated highly-intractable
problem, we propose a two-step optimization framework. Specif-
ically, we induce the sparsity of device selection in the ﬁrst step,
followed by solving a series of MSE minimization problems to
ﬁnd the maximum feasible device set in the second step. We
then propose an alternating optimization framework, supported
by the difference-of-convex-functions programming algorithm
for low-rank optimization, to efﬁciently design the aggregation
beamformers at the BS and phase shifts at the IRS. Simulation
results will demonstrate that our proposed algorithm and the
deployment of an IRS can achieve a lower training loss and
higher FL prediction accuracy than the baseline algorithms.

Index Terms—Federated learning, intelligent reﬂecting surface,

over-the-air computation, sparse optimization.

I. INTRODUCTION

Recent years have witnessed a bloom of artiﬁcial intel-
ligence (AI) applications, such as chess play [1], natural
language generation [2], and image classiﬁcation [3]. By
adopting advanced machine learning techniques, particularly
reinforcement learning and deep learning, computers are able
to mimic human behaviours by exploiting tremendous comput-
ing power and large amounts of data. With the further rise of
edge computing and Internet of Things (IoT), there emerges
a new AI paradigm, named edge AI [4]–[7], which pushes
the AI frontier from the cloud center to the network edge.
As the data collection and processing are mostly performed at
the network edge, the service latency and energy consumption
of edge devices can be signiﬁcantly reduced by edge AI. As
a promising framework for edge AI, federated learning (FL)

Z. Wang, Y. Zhou, and Y. Shi are with the School of Information Science
and Technology, ShanghaiTech University, Shanghai, 201210, China (E-mail:
{wangzhb, zhouyong, shiym}@shanghaitech.edu.cn).

J. Qiu and L. Fu are with the School of Informatics, and Key Laboratory
of Underwater Acoustic Communication and Marine Information Technology
Ministry of Education, Xiamen University, Xiamen 361005, China (E-mail:
jiahang@stu.xmu.edu.cn, liqun@xmu.edu.cn)

W. Chen is with the Department of Electronic Engineering, Tsinghua

University, Beijing 100084, China (E-mail: wchen@tsinghua.edu.cn).

K. B. Letaief is with the Department of Electronic and Computer Engineer-
ing, Hong Kong University of Science and Technology, Hong Kong (E-mail:
eekhaled@ust.hk). He is also with Peng Cheng Laboratory, Shenzhen, China.

[8], [9] has recently been proposed to coordinate multiple edge
devices to collaboratively train a global AI model. Speciﬁcally,
FL iteratively performs the following two processes [8]: 1)
model aggregation: the edge server receives the local model
updates from the edge devices over multiple-access channels,
and then updates the global model by averaging over the
received local model updates; and 2) model dissemination:
the edge server broadcasts its updated global model to the
edge devices, each of which updates the local model based
on its own local dataset. As only model parameters rather
than the real raw data are transmitted to the edge server in the
model aggregation process, FL is capable of achieving privacy
protection.

As the edge devices are usually connected to the edge
server over wireless channels, the model parameters received
by the edge server are inevitably distorted by channel fading
and additive noise. To tackle this issue, several digital FL
schemes have been proposed to achieve reliable and accurate
model aggregation [10]–[13]. Speciﬁcally, each edge device
is allocated an orthogonal resource block to upload its local
model parameters, while the edge server is assumed to cor-
rectly decode all the local models by adopting the adaptive
modulation and coding scheme [10]. The authors in [11]
minimized the training loss by jointly optimizing the resource
allocation and device selection, taking into account the delay
and energy consumption requirements. Besides, the device
scheduling policies for model uploading in each communi-
cation round were proposed in [12] and [13] to speed up the
convergence rate of FL. However, the aforementioned studies
adopted orthogonal multiple access (OMA) based resource
allocation schemes, such as time division multiple access
(TDMA) and orthogonal frequency division multiple access
(OFDMA), where the required radio resources are linearly
scaling with the number of edge devices that participate in
FL. When the number of edge devices is large, a substantial
communication latency is introduced in the model aggregation
process and in turn becomes the performance-limiting factor
of FL.

To address the above challenges, over-the-air computation
(AirComp) empowered analog FL emerged to enhance the
learning performance under the limited communication band-
width and stringent latency requirements. AirComp merges
the concurrent data transmission from multiple devices and
the function computation via exploiting the waveform su-
perposition property of multiple-access channels [14]–[16].
Meanwhile, as the edge server in FL is merely interested in
the aggregated model rather than the individual local mod-
els, AirComp, as a non-orthogonal multiple access (NOMA)
scheme, is recognized as a promising solution for achieving
spectral-efﬁcient and low-latency FL [17]–[21]. Speciﬁcally,

 
 
 
 
 
 
the authors in [17] proposed a fast model aggregation approach
by jointly optimizing device selection and receive beamform-
learning performance under
ing to improve the statistical
certain mean-squared-error (MSE) requirements for on-device
distributed FL. The authors in [18] developed a broadband
analog aggregation scheme for low-latency FL by considering
the communication-and-learning trade-off. The results in [19]
demonstrated that the analog approach via AirComp converges
faster than the digital approach due to its more efﬁcient use
of limited radio bandwidth. In [20], the authors developed a
gradient-based algorithm to directly deal with noise distorted
gradients for FL over wireless channels. In addition,
the
authors in [21] studied the optimal power control problem
for AirComp-based FL with gradient statistics. To achieve
an average behavior of local model updates during model
aggregation, magnitude alignment should be achieved at the
edge server to reduce the aggregation error of AirComp
[22]–[24]. However, unfavorable propagation environment in-
evitably leads to magnitude reduction and misalignment [24],
which in turn degrade the model aggregation accuracy of
AirComp-based FL.

To overcome the detrimental effect of channel fading in
wireless networks, intelligent reﬂecting surface (IRS) is a cost-
effective technology for improving the spectral and energy
efﬁciency via reconﬁguring the wireless propagation envi-
ronment [25]–[31]. In particular, a large number of low-cost
passive reﬂecting elements contained in an IRS are capable
of adjusting the phase shift of the incident signal, and thus
altering the propagation of the reﬂected signal. The signal
reﬂected by IRS can be constructively superposed with the
signal over the direct link to boost the received signal power
[25]. Due to the passive nature, the power consumption of
the IRS is negligible compared with that of the traditional
full-duplex amplify-and-forward relay. In [26], an IRS was
deployed to minimize the transmit power of the multi-antenna
access point (AP) by jointly optimizing active and passive
beamforming, while satisfying the signal-to-interference-plus-
noise ratio (SINR) constraints. A joint design of the downlink
transmit power and the phase shifts of IRS was developed in
[27] to maximize the energy efﬁciency. The authors in [28]
utilized the IRS to enhance the physical layer security by
jointly optimizing the beamformers at the base station (BS)
and the reﬂecting coefﬁcients at the IRS. The authors in [29]
leveraged the IRS to minimize the distortion of AirComp in
wireless networks. Moreover, the MSE of aggregated data can
be signiﬁcantly reduced by deploying an IRS in a wireless-
powered AirComp network [30]. The aforementioned studies
demonstrated the potential gains of deploying an IRS in harsh
wireless environment, which motivates us to leverage IRS
to compensate for magnitude reduction and misalignment of
AirComp in FL systems, thereby achieving a lower training
loss and higher test accuracy in fewer communication rounds.

A. Contributions

In this paper, we exploit the advantages of IRS to de-
sign a communication-efﬁcient model aggregation scheme for
AirComp-based FL systems. Developing such a scheme to

2

facilitate fast yet reliable model aggregation is challenging.
On one hand, selecting more devices to participate in FL at
each communication round is able to simultaneously collect
more local model updates, which has a positive impact on
the convergence rate of the training process. On the other
hand, selecting more devices in each communication round
enlarges the model aggregation error due to the inevitable
magnitude misalignment at the edge server, which is detri-
mental to the convergence rate of the training process. As a
result, the edge devices should be appropriately selected to
speed up the overall convergence rate of FL. The optimization
of device selection can be achieved by solving an ℓ0-norm
minimization problem, which, however, requires the design
of an efﬁcient algorithm to accurately induce sparsity. In
the learning performance from being
addition,
degraded by the large model aggregation error, it is critical
yet challenging to optimize the aggregation beamformer at the
BS and the phase shifts at the IRS to combat severe channel
fading and reduce the impact of additive noise. Therefore,
it is necessary to jointly optimize the device selection, the
aggregation beamformer at the BS, and the phase shifts at
the IRS to improve the learning efﬁciency and the prediction
accuracy of the IRS-assisted AirComp-based FL system. The
main contributions of this paper are summarized as follows.

to prevent

• We propose an IRS-assisted AirComp-based FL system
that is able to achieve fast yet reliable model aggrega-
tion. In particular, an IRS is deployed to mitigate the
magnitude misalignment at the edge server during model
aggregation, so as to schedule more edge devices to
participate in FL at each communication round under
a certain MSE requirement of each aggregated model,
thereby achieving a lower training loss and higher test
accuracy in fewer communication rounds.

• We propose to jointly optimize the device selection, the
aggregation beamformer at the BS, and the phase shifts
at the IRS, which, however, is highly intractable due to
the sparse objective function as well as the biquadratic
constraints due to the coupling between the aggregation
beamformer at the BS and the phase shifts at the IRS.
• We ﬁrst propose a two-step optimization framework to
tackle the sparse objective function. Speciﬁcally, we
induce the sparsity of the device selection by adopting
ℓ1-relaxation for the ℓ0-norm objective function in the
ﬁrst step, followed by solving a series of MSE minimiza-
tion problems in the second step to ﬁnd the maximum
feasible device selection set. Then, we propose an alter-
nating optimization method to decouple the aggregation
beamformer at the BS and the phase shifts at the IRS,
thereby removing the obstacles caused by the biquadratic
constraints in our problem.

• To address the nonconvex quadratic constraints in each
subproblem resulting from the alternating optimization
method, we convert
them into rank-one constrained
semideﬁnite programming (SDP) problems via matrix
lifting. Subsequently, we reformulate the SDP problems
as difference-of-convex (DC) programming problems by
introducing DC representations for rank-one constraints,

so as to effectively solve the low-rank optimization prob-
lem with the proposed DC algorithm.

Simulation results demonstrate that

the proposed IRS-
assisted AirComp-based FL system is able to schedule more
devices in each communication round under certain MSE
requirements. The proposed two-step alternating DC algo-
rithm achieves more accurate feasible set detection than the
SDR approach. Moreover, our proposed algorithm enables
FL to converge faster and achieve more accurate prediction
in the experiment of training a deep convolutional neural
network (CNN) on the MNIST dataset [32] than other baseline
schemes.

B. Organization and Notations

The rest of this paper is organized as follows. Section II
describes the system model and problem formulation in IRS-
assisted FL system. In Section III, we propose a two-step
framework to solve the problem. Section IV presents a two-
step alternating DC algorithm for solving the problem. The
simulation results are provided in Section V. Finally, Section
VI concludes this work.

Italic, boldface lower-case, and boldface upper-case letters
denote scalar, vector, and matrix, respectively. Rm×n and
Cm×n denote the real and complex domain with the space of
), and diag(
m
)
·
denote the transpose, Hermitian transpose, trace, and diagonal
matrix, respectively. E[
] denotes the statistical expectation.
denotes the cardinality of a set or the absolute
The operator
|·|
denotes the Euclidean norm.
value of a scalar number, and

n, respectively. The operators (
·

)H, tr(
·

)T, (
·

×

·

k·k

II. SYSTEM MODEL AND PROBLEM FORMULATION

In this section, we develop a computation and communi-
cation co-design for fast and reliable model aggregation in
AirComp-based FL systems, where an IRS is deployed to
compensate for the magnitude reduction and misalignment of
AirComp.

A. FL Model

|

}

{
k
|D

1, 2, . . . , K

labeled data samples

The IRS-assisted AirComp-based FL system under consid-
eration consists of one M -antenna BS serving as an edge
server, K single-antenna edge devices, and an IRS with N
passive reﬂecting elements, as shown in Fig. 1. Edge device
k
=
k
D
∈ K
Dk
k,
with Dk =
i=1 ∈ D
where (ui, vi) denotes the input-output data pair consisting of
training sample ui and its ground-truth label vi. For a given d-
Rd, the local loss function
dimensional model parameter z
for device k is deﬁned as
1
Dk

has its own local dataset

X(ui,vi)∈Dk
where f (z; ui, vi) denotes the sample-wise loss function.
Without loss of generality, we assume that all local datasets
, as in [18].
have a uniform size, i.e., Dk = D,

(ui, vi)
}

f (z; ui, vi),

Fk(z) =

(1)

∈

k

{

∀

∈ K

3

Fig. 1.

Illustration of an IRS-assisted AirComp-based FL system.

Then, the global loss function with model parameter z can
be represented as

F (z) =

1
K
k=1 Dk

k=1
X

K

DkFk(z) =

K

Fk(z).

(2)

1
K

k=1
X

The learning process aims to optimize the model parameter z
that minimizes the global loss function, i.e.,

P

z⋆ = arg min
z∈Rd

F (z).

(3)

To achieve this purpose, with the traditional method, the BS
gathers all the local data from the edge devices to train a global
model, which, however, not only increases the computation
burden on the centralized server but also causes the privacy
concern of edge devices.

Fortunately, as an on-device distributed machine learning
method, FL is able to collaboratively train a global model by
coordinating the distributed edge devices to update the local
model parameters according to the locally owned training data.
Without the need of uploading the local data to the BS, this
distributed learning method possesses the advantages of low
latency, low power consumption, and high data privacy. In
this paper, we leverage FedAvg [8], also referred to as model
averaging, to train a global model. Speciﬁcally, at the t-th
communication round, the BS and the edge devices perform
the following procedures

• The BS broadcasts the current global model z[t−1] to
the edge devices belonging to a selected set, denoted as

.

t
S

⊆ K

• Based on the received global model z[t−1], each edge
t performs a local model update algorithm
i to obtain an updated local

device i
by utilizing its local dataset
model z[t]
i

∈ S

D

.

• All the local model updates are aggregated at the BS by
taking an average to obtain the updated global model z[t],

4

3.5

3

2.5

2

1.5

1

0.5

0

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

4

6

8

10

12

14

16

18

20

4

6

8

10

12

14

16

18

20

Fig. 2. Training loss versus the number of selected devices under different
model aggregation errors.

Fig. 3. Test accuracy versus the number of selected devices under different
model aggregation errors.

which is given by

1

z[t] =

.

(4)

the BS. The target function for aggregating the local model
updates at the BS can be expressed as

z[t]
i

| X
i∈St

t
|S
In the following, we train a deep CNN on the MNIST
dataset by using the FedAvg algorithm to show the impact
of the number of selected devices on the training loss and the
test accuracy under different model aggregation errors. The
aggregated global model is given by

1

ˆz =

zi + e,

(5)

i∈S
|S| X

(0, σ2

∼ N

0I). As shown in Fig. 2 and Fig. 3,
where e
selecting more devices to participate in the training process
is able to obtain a model that provides lower training loss
and higher test accuracy. Besides, the training loss increases
and the test accuracy decreases as the model aggregation
error increases under the same number of selected devices.
Therefore, it is critical to schedule more devices and reduce the
aggregation error in each communication round for training a
high quality model. Note that the aggregation error is mainly
caused by channel fading and additive noise during model
aggregation and dissemination over wireless channels. Moti-
vated by these observations, we propose to jointly optimize the
device selection, the aggregation beamformer at the BS, and
the phase shifts at the IRS to maximize the number of edge
devices participating in model aggregation while ensuring the
aggregation error is within a certain bound. Such a design is
capable of enhancing the performance of FL in terms of the
training loss and test accuracy.

B. Communication Model for IRS-Assisted AirComp

Since the average sum in Eq. (4) for model aggregation falls
into the category of nomographic functions [16], AirComp
as a promising technique can be utilized to enhance the
efﬁciency of model aggregation from distributed edge devices.
Let φi(x) = x denote the pre-processing function at device
i and ψ(x) = 1
|S| x denote the post-processing function at

z = ψ

φi(zi)

!

,

(6)

i∈S
X

S

∈

is the device selection set. We denote si = zi

Rd
where
as the transmit symbol vector at device i. Without loss of
generality, the transmit symbols are assumed to be independent
and normalized to have zero mean and unit variance, i.e.,
E[sisH
i ] = Id [18]. Due to the limited capacity for data
storage and computing at the edge devices, the dimension
of model parameters is set to ensure that the entire model
parameters can be transmitted within one transmission interval
[33]. To simplify the notation, let ¯si denote a typical entry of
si within one communication interval. The target function to
be estimated at the BS is given by

g =

φi(¯si) =

¯si.

(7)

i∈S
X

i∈S
X

∈

i ∈

i ∈

Let hd

CN , and G

The transmitted signals may encounter detrimental channel
conditions during the model aggregation process through Air-
Comp in the uplink, which leads to magnitude reduction and
misalignment, thereby enlarging the aggregation error at the
BS. To tackle this issue, we propose to deploy an IRS to
alleviate the distortion of AirComp.
CM , hr

CM×N denote the
channel responses from device i to the BS, from device i
to the IRS, and from the IRS to the BS, respectively. The
channel gain of each link is assumed to be invariant within one
transmission interval. In addition, with various channel esti-
mation methods proposed for IRS-assisted wireless networks
[34]–[36], we assume that the perfect CSI is available in this
paper, as in [25]–[30]. The diagonal phase-shift matrix of the
IRS is denoted by Θ = diag(βejθ1 , . . . , βejθN )
CN ×N ,
where θn
[0, 2π) denotes the phase shift of element n and
[0, 1] is the amplitude reﬂection coefﬁcient on the incident
β
signals. Without loss of generality, we assume β = 1 in this
paper [26]. Compounded with reﬂected signals, the received

∈

∈

∈

 
signal at the BS is given by

y =

(GΘhr

i + hd

i )wi ¯si + n,

i∈S
X

CN

where wi

∈
0, σ2I

C is the transmit scalar of device i and n
∼
is the additive white Gaussian noise (AWGN).
By denoting the aggregation beamforming vector at the
CM , the estimated target function before post-

(cid:0)
BS as m
processing can be expressed as

(cid:1)
∈

To facilitate the algorithm design, the MSE constraint (14b)
can be rewritten as nonconvex constraints with quadratic and
biquadratic terms, as presented in Proposition 2.

(8)

5

Proposition 2. The constraint (14b) can be equivalently
rewritten as the following constraints:

m

k
m
k

2
k

mH

γ

|

(GΘhr

i + hd
i )
|

2

0, i

,

∈ S

≤

(15)

2

k

≥

−
1.

where

ˆg =

1
√η

mHy =

mH

1
√η

i∈S
X

(GΘhr

i + hd

i )wi¯si +

1
√η

mHn,

(9)

where η is a denoising factor. Thus, we can obtain the aggre-
gated global model at the BS by post-processing ˆz = ψ(ˆg).
The distortion of the estimated aggregated model, which
quantiﬁes the performance for global model aggregation via
AirComp, can be measured by the MSE between ˆg and the
target value g as follows

Proof. Please refer to Appendix B.

According to Proposition 2,

the objective function

|S|
represents the number of feasible MSE constraints (15), which
should be maximized under the regularity condition
≥
1. By adding an auxiliary variable x [37], we equivalently
transform the problem of maximizing the number of feasible
MSE constraints into the problem of minimizing the number
of nonzero xi’s. Hence, we turn to solve the following sparse
optimization problem

m

k

k

2

P : minimize
x∈RK

+ ,m,Θ k

subject to

k

σ2

2

k

.

m
k
η

(10)

x

k0
2
m

k

mH

γ

|

−

(GΘhr

i + hd
i )
|

2

≤

xi,

(16a)

,

i
∈ K
(16b)

∀

(16c)
(16d)

MSE (ˆg, g) = E

ˆg

2

g

|

−

|
h
(GΘhr

i
i + hd

i )wi

mH

1
√η

=

i∈S (cid:12)
X
(cid:12)
(cid:12)
(cid:12)

2

1

+

−

(cid:12)
(cid:12)
(cid:12)
(cid:12)

The following proposition presents the optimal transmit scalars
at the edge devices to minimize the MSE.

Proposition 1. Given the aggregation beamforming vector m
and the phase-shift matrix Θ, the minimum MSE is obtained
by using the following optimal transmit scalar

w⋆

i = √η

(mH(GΘhr
mH(GΘhr

i ))H
i + hd
i + hd
i )
|

2

|

Proof. Please refer to Appendix A.

,

i

∀

.

∈ S

(11)

The transmit power of device i is constrained by a given
P0. With the

maximum transmit power P0 > 0, i.e.,
optimal transmit scalar w⋆

wi

≤

2

|

|

i given in (11), we have
mH

(GΘhr

2.

i + hd
i )
|

η = P0 min
i∈S |

Therefore, the minimum MSE is given by

MSE (ˆg, g) =

σ2
P0

max
i∈S

|

C. Problem Formulation

2

m
k
mH(GΘhr
i + hd
i )

k

(12)

(13)

2 .

|

As observed in Section II-A, we aim to maximize the num-
ber of selected devices while satisfying the MSE requirement
of model aggregation to speed up the convergence of the
training process and to avoid the notable reduction of the
prediction accuracy. Speciﬁcally, given the MSE requirement
γ > 0 for model aggregation, the corresponding optimization
problem can be formulated as

maximize
S,m,Θ

|S|

subject to max
i∈S
|
Θn,n

|

|

k

2
m
k
mH(GΘhr
i + hd
i )
|
1, . . . , N
= 1,

2 ≤

n

∀

∈ {

(14a)

2

m
k
k
Θn,n
|

|

1,
≥
= 1,

n

∀

∈ {

1, . . . , N

.

}

Note that the selection of each edge device is indicated by
the sparsity structure of x, i.e., xi = 0 indicates that device i
can be selected while satisfying the MSE requirement. Due to
the sparse objective function and nonconvex constraints with
biquadratic (16b) and quadratic (16c) terms, problem P is
computationally difﬁcult. To tackle this issue, we shall propose
a two-step alternating low-rank optimization framework in the
following section.

III. ALTERNATING LOW-RANK OPTIMIZATION
FRAMEWORK FOR MODEL AGGREGATION

In this section, we propose a two-step framework to solve
problem P for IRS-assisted AirComp-based FL with device
selection, followed by proposing to use the alternating opti-
mization approach to solve the problem in each step.

A. Proposed Two-Step Framework for Solving Problem P

The main idea of our proposed two-step framework is to
induce the sparsity of x in the ﬁrst step, so as to determine
the priority for each device to be selected. With the obtained
priority vector, we then solve a series of MSE minimization
problems to ﬁnd the maximum feasible device set while
satisfying the MSE requirement in the second step.

1) Sparsity Inducing: For the nonconvex sparse objective
function being in the form of ℓ0-norm, we adopt the well-
recognized ℓ1-norm as a convex surrogate [38]. To solve
problem P, we shall solve the following problem in the ﬁrst
step:

γ,

(14b)

P1 : minimize
x∈RK

+ ,m,Θ k

x

k1

.

}

(14c)

subject to constraints (16b), (16c), (16d).

(17)

After solving problem P1, we proceed to the second step
to check the feasibility of the selected devices and ﬁnd the
maximum number of edge devices under the MSE constraint.
2) Feasibility Detection: The value of xi obtained from
the ﬁrst step characterizes the disparity between the MSE
requirement and the achievable MSE for device i. Therefore,
the higher priority device i
the smaller the value of xi,
K
being selected in the second step. We sort
i=1 in an
to determine the
ascending order xπ(1) ≤ · · · ≤
priority of edge devices, where xπ(i) denotes the i-th smallest
K
i=1. We adopt the bisection method to ﬁnd
element in
the maximum value of k that enables all devices in the set
to be feasibly selected. Specif-
π(1), π(2), . . . , π(k)
}
S
[k], we check the feasibility via
ically, for a given device set
S
comparing the MSE requirement with the minimum maximal
[k] obtained from the following
MSE of selected devices in
problem:

xπ(K)

[k] =

xi

xi

S

}

{

{

{

}

P2 : minimize

m,Θ

subject to

max
i∈S [k]
Θn,n

|

|
|

2

k

m
k
mH(GΘhr
i + hd
i )
|
1, . . . , N
= 1,

n

2

∀

∈ {

(18a)

(18b)

.

}

If the optimal objective value of problem (18) is less than the
required MSE, then set

[k] is considered as a feasible set.

S

B. Alternating Low-Rank Optimization

It can be observed that constraint (16b) and objective
function (18a) are both nonconvex due to the coupled opti-
mization variables. To address this issue, we propose to apply
alternating optimization [29].

1) Sparsity Inducing: In the ﬁrst step, variables (x, m) and
Θ of problem P1 can be optimized alternately. Speciﬁcally,
when the phase-shift matrix Θ is ﬁxed (i.e., the combined
channel vector hi = GΘhr
i + hd
i between device i and the
BS is ﬁxed), the problem can be expressed as

6

mHGdiag(hr
pressed as

i), and ci = mHhd

i , the problem can be ex-

ﬁnd v

(21a)

2

γ

m

subject to

(21b)
(21c)
∈ {
We denote ¯v = [v, t]T by introducing an auxiliary variable t.
Constraints (21b) can be rewritten as

≤
|
1, . . . , N

k
−
= 1,
|

k
vn
|

xi,
.

aHv + ci
n

∈ K

|
∀

∀

}

i

2

,

m

k

2

k

−

γ

¯vHRi ¯v +

2

ci

|

|

xi,

i

∀

≤

,

∈ K

(22)

where

(cid:0)

Ri =

aiaH
i
i aH
cH
i
Since ¯vHRi ¯v = tr(Ri ¯v ¯vH), we lift ¯v as a positive semidef-
inite (PSD) matrix V = ¯v ¯vH with rank(V ) = 1. Problem
(21) can be equivalently reformulated as the following low-
rank matrix optimization problem:

(23)

(cid:20)

(cid:21)

.

P1,2 : ﬁnd V
subject to

2

−

m
γ
k
k
Vn,n = 1,
V

tr(RiV ) +
n
0, rank(V ) = 1.

∈ {

(cid:0)
∀

ci
≤
|
1, . . . , N + 1

|

(cid:1)

}

i

∀

,

∈ K

xi,
,

(24)

2

(cid:23)

2) Feasibility Detection: In the second step, we ﬁrst refor-

mulate problem P2 as the following problem [29]:

(cid:1)
aici
0

minimize
m,Θ

subject to

2

m

k
k
mH
(GΘhr
Θn,n
= 1,

|

2

i + hd
i )
|
n

1,

i

≥

∀
1, . . . , N

∈ S
.

[k],

(25)

|

|

∈ {

∀
To decouple the optimization variables, we optimize the ag-
gregation beamforming vector m and the phase-shift matrix
Θ alternately. Speciﬁcally, given the phase-shift matrix Θ, we
have

}

minimize
x∈RK

+ ,m k

x

k1

minimize
m

subject to constraints (16b), (16c).

(19)

To address the nonconvexity of biquadratic and quadratic
constraints (16b) and (16c), we further transform problem (19)
into an SDP problem via the matrix lifting technique [39]. By
denoting M = mmH, problem (19) can be rewritten as a
low-rank optimization problem:

P1,1 : minimize

x

k1

x∈RK

+ ,M k
subject to tr(M )
tr(M )
M

(cid:23)

where Hi = hihH
i .

−

γ

·
1,

≥
0, rank(M ) = 1,

2

m
k
k
mHhi

2

subject to

1,

i

[k].

(26)

|
This problem can be further represented as a low-rank matrix
optimization problem:

∈ S

≥

∀

|

P2,1 : minimize

M

tr(M )

subject to tr(M Hi)

1,
∈ S
∀
0, rank(M ) = 1.

≥

i

[k],

(27)

tr(M Hi)

xi,

i

∀

≤

,

∈ K

M

(cid:23)

On the other hand, given the aggregation beamforming

(20)

vector m, we have

ﬁnd v

On the other hand, when the auxiliary vector x and the
aggregation beamforming vector m are ﬁxed, problem P1
is reduced to be a feasibility detection problem of phase-
shift matrix Θ. By denoting v = [ejθ1, . . . , ejθN ]T, aH
i =

subject to

|

|

aHv + ci
= 1,
vn

|

2

|

∀

≥
n

1,

i

∀
∈ S
1, . . . , N

[k],
,

}

∈ {

(28)

and its corresponding low-rank matrix optimization problem

is given by

P2,2 : ﬁnd V
subject to tr(RiV ) +

2

1,

ci
|
n
0, rank(V ) = 1.

∈ {

Vn,n = 1,
V

∀

|

i

[k],
≥
,
1, . . . , N + 1

∈ S

∀

}

(cid:23)

(29)

In summary, the entire proposed two-step alternating DC
algorithm for solving the sparse and low-rank optimization
problem P is presented in Algorithm 1. The resulting prob-
lems P1,1, P1,2, P2,1, and P2,2 in the alternating low-rank
optimization are still nonconvex because of the ﬁxed rank-
one constraints. This nonconvexity issue can be tackled by
simply dropping the nonconvex rank constraints via the SDR
technique [39]. In the procedure of solving the relaxed SDP
problems, if the obtained solution fails to be rank-one, the
Gaussian randomization method [39] can be adopted to obtain
a suboptimal solution. However, if the number of antennas and
the number of reﬂecting elements are large, the performance
of the SDR technique degenerates in the resulting high-
dimensional optimization problems due to the low probability
of returning rank-one solutions [15]. To address the limitations
of the SDR technique, we present a novel DC programming
approach for inducing rank-one solutions in the next section.

IV. ALTERNATING DC APPROACH FOR LOW-RANK
OPTIMIZATION

In this section, we present a DC formulation for the rank-
one constrained SDP problems in the alternating procedure,
followed by proposing a two-step alternating DC algorithm to
solve problem P in IRS-assisted AirComp-based FL systems.

A. DC Formulation for Rank-One Constrained Problems

The accurate detection of the rank-one constraint plays a
critical role in precisely detecting the feasibility of nonconvex
quadratic constraints, which is important
in our two-step
framework for device selection. Therefore, we provide a DC
representation for the rank-one constraints in the aforemen-
tioned problems in Section III-B.

The rank-one constraint of PSD matrix M

be equivalently rewritten as

CM×M can

∈

M

k{

σi(M )
}
where σi(M ) denotes the i-th largest singular value of matrix
M . Furthermore, since the trace norm and the spectral norm
are represented by

i=1k0 = 1,

(30)

M

tr(M ) =

σi(M ) and

respectively, we have [17]

i=1
X

M

k2 = σ1(M ),

k

(31)

7

Algorithm 1: Two-step alternating DC algorithm for
solving problem P in FL with device selection.
Step 1: Sparsity Inducing
Input: Initial point Θ0 and predeﬁned threshold ǫ > 0.
for t

1, 2, . . . do

←
Given Θt−1, obtain solution (xt, mt) by solving
problem P1,1.
Given (xt, mt), obtain solution Θt by solving
problem P1,2.
if Decrease of the objective value of problem P1
is below ǫ then

break.

end

end
Output: x⋆

xt.

←

Step 2: Feasibility Detection
[K] =
Input: Set

S

π(1), π(2), . . . , π(K)
}
{
by ordering x⋆ in an ascending order as
0, Nup ←
xπ(K), Nlow ←
xπ(1) ≤ · · · ≤
and predeﬁned threshold ǫ > 0.

obtained

K,

K.
k
←
while Nup −
Initialize Θ0 and
for t

Nlow > 1 do
[k]

S
1, 2, . . . do

π(1), π(2), . . . , π(k)

.
}
← {
←
Given Θt−1, obtain solution mt by solving
problem P2,1.
if Maximum MSE
Nlow ←
¯m
←
k
← ⌊
Break.

k.
mt.
Nlow+Nup
2

γ then

≤

⌋

.

else if Decrease of the objective value of
problem P2 is below ǫ then

k.

Nup ←
k
← ⌊
Break.

Nlow+Nup
2

.

⌋

end
Given mt, obtain solution Θt by solving
problem P2,2.

end

end
Output: m⋆
[k]

¯m and the set of selected devices

π(1), π(2), . . . , π(k⋆)
}

with

←
← {

Nlow.

S
k⋆

←

with tr(M ) > 0. Therefore, we can use a DC penalty to
induce rank-one solutions. The corresponding DC formulation
for problem P1,1 is given by

P ′

x

1,1 : minimize
x∈RK

+ ,M k
subject to tr(M )
tr(M )

k1 + ρ (tr(M )
γ
·
1, M

M

− k

k2)
xi,

≤

tr(M Hi)

−
≥

0,

(cid:23)

i

∀

∈ K

,
(33)

rank(M ) = 1

tr(M )

M

k2 = 0,

− k

⇔

(32)

where ρ > 0 denotes the penalty parameter. Hence, we
are able to obtain a rank-one matrix when the DC penalty

term is enforced to be zero. Then, the feasible aggregation
beamforming vector m of problem P1 can be recovered by
utilizing Cholesky decomposition for M ⋆ = mmH. Similarly,
we detect the feasibility of problem P1,2 by minimizing the
DC representation term that is given by

P ′

1,2 : minimize

V
subject to

tr(V )

− k
m
γ
k2 −
k
Vn,n = 1,
V

0.

(cid:23)

V

k2
tr(RiV ) +
n

2

ci
≤
|
1, . . . , N + 1
}

(cid:1)

|

∈ {

(cid:0)
∀

i

∀

,

∈ K

xi,
,

(34)

Once the objective value becomes zero, we can obtain an
exact rank-one feasible solution and extract ¯v = [v0, t0]T by
utilizing Cholesky decomposition for V ⋆ = ¯v ¯vH. Then, by
computing v = v0/t0, the phase-shift matrix can be recovered
according to Θ = diag(v).

Problems P2,1 and P2,2 in the second step can be reformu-
lated in the similar DC formulation to guarantee the feasibility
of the rank-one constraint, which are rewritten as

P ′

2,1 : minimize

M

tr(M ) + ρ (tr(M )

M

k2)

− k

subject to tr(M Hi)

M

0,

(cid:23)

1,

i

∀

≥

∈ S

[k],

(35)

and

P ′

2,2 : minimize

tr(V )

V

V

− k
subject to tr(RiV ) +

2

k2
ci
|
n

|

∀

∈ {

i

1,

[k],
≥
,
1, . . . , N + 1

∈ S

∀

}

(36)

Vn,n = 1,
V

0.

(cid:23)

B. DC Algorithm

Although the DC programs are still nonconvex, their prob-
lem structures of minimizing the difference of two convex
functions can be exploited to develop an efﬁcient DC algo-
rithm [40] by successively linearizing the concave part.

the objective functions of
h1

1,2 can be denoted as g1 −

problem P ′
and g2 −

Speciﬁcally, in the ﬁrst step,
1,1 and problem P ′
h2, respectively, where
k1 + ρ

g1 =
k
g2 = tr(V ),

tr(M ),
V

·
h2 =

x

h1 = ρ

M

k2,

· k

(37)

(38)

k2.
1,1, by linearizing the concave term

For problem P ′
h1 in
the objective function, the resulting subproblem at the t-th
iteration is given by

−

k

∂M [t−1] h1, M

minimize
x∈RK
+ ,M

g1 − h
subject to tr(M )
tr(M )

tr(M Hi)

xi,

i

,

≤

∀

∈ K

−

γ
·
1, M

(39)
[tr(X HY )] is the inner product of two
where
matrices, and ∂X[t−1] h denotes the subgradient of function h
with respect to X obtained at iteration t
1. Besides, problem

X, Y
h

=

(cid:23)

≥

ℜ

i

i

0,

−

P ′

1,2 can be solved by iteratively solving

minimize
V
subject to

∂V [t−1] h2, V

i

g2 − h
m
γ
k
k
Vn,n = 1,

−

2

2

tr(RiV ) +
n

ci
≤
|
1, . . . , N + 1

|

(cid:0)
∀

∈ {

(cid:1)

}

8

xi,
, V

i

∀

(cid:23)

,
(40)

∈ K
0.

2,1 and P ′

Likewise, in the second step, we can also transform the DC
programs P ′
2,2 into such a series of subproblems to
apply the DC algorithm. In particular, we denote the objective
functions of problem P ′
h3 and
g4 −

2,1 and problem P ′

h4, respectively, where

2,2 as g3 −

g3 = (1 + ρ)
g4 = tr(V ),

·

tr(M ),
h4 =

M

k2,

· k

h3 = ρ
k2.

(41)
(42)

V

k

The solution M [t] for P ′

2,1 is obtained by solving
g3 − h

∂M [t−1] h3, M

i

minimize
M

subject to tr(M Hi)

M

0.

(cid:23)

1,

i

∀

≥

∈ S

[k],

(43)

Besides, the solution V [t] for P ′

2,2 is obtained by solving

minimize
V

g4 − h

∂V [t−1] h4, V

subject to tr(RiV ) +

i
1,

2

|

ci
|
n

i

[k],
≥
,
1, . . . , N + 1

∈ S

∀

∀

∈ {

}

Vn,n = 1,
V

0.

(44)

·

k

V

(cid:23)
Therefore, we have ∂M h1 = ∂M h3 = ρ

M
k2 and
∂
k
X
k2 can be efﬁciently
k2, where ∂
∂V h2 = ∂V h4 = ∂
computed by u1uH
1 [17] and u1 is the eigenvector correspond-
ing to the largest eigenvalue of the matrix X. Consequently, it
can be veriﬁed that the above subproblems are convex and thus
can be efﬁciently solved by using CVX [41]. Furthermore, it
has been shown in [40] that the solving procedure with the
DC algorithm always converges to the critical points of the
DC programs from any feasible initial points.

k

C. Computation Complexity Analysis

O

O

In our proposed Algorithm 1, we need to solve a sequence of
SDP problems (39), (40) in the ﬁrst step, and (43), (44) in the
second step. To solve each SDP problem, the worst case com-
putational complexity by using the second-order interior point
((M 2+K)3.5) in problems (39) and (43), and
method [39] is
((N 2 +K)3.5) in problems (40) and (44). Supposing those
is
problems converging to critical points of the DC programs
with T > 1 iterations, the computational cost of solving a DC
program, i.e., one of problems P ′
1,2, P ′
2,2, is
(T (M 2 +K)3.5). Note that we merely
O
need to solve the SDP problem once for problems P1,1, P1,2,
P2,1, and P2,2 via SDR technique with simply dropping the
rank-one constraints, i.e., T = 1 in this case. The proposed
DC algorithm has a higher computational complexity than the
SDR method. Nevertheless, the sacriﬁce of the computational
complexity results in signiﬁcant improvement on the system
performance, which will be demonstrated in the following
section.

(T (M 2 +K)3.5) or

2,1, and P ′

1,1, P ′

O

V. SIMULATION RESULTS

In this section, we present the simulation results to demon-
strate the advantages of the proposed two-step alternating DC
algorithm for FL with device selection. The effectiveness of
deploying an IRS for the AirComp-based FL system will
also be illustrated. We consider a three-dimensional coordinate
system, where the antennas at
the BS and the reﬂecting
elements at the IRS are placed as a uniform linear array and
a uniform rectangular array, respectively. The locations of the
BS and the IRS are, respectively, set as (3, 0, 6) meters and
(0, 100, 6) meters, while the edge devices are distributed in
the region of ([0, 6], [100, 106], 0) meters surrounding the IRS.
The path loss model is given by

L(d) = C0(d/d0)−α,

(45)

where C0 denotes the path loss at the reference distance d0 =
1 meter, d is the link distance, and α is the path loss exponent.
All channels are assumed to suffer from Rician fading [26],
where the channel coefﬁcient can be expressed as

̺ =

r

ς
1 + ς

̺LoS +

1
1 + ς

r

̺NLoS,

(46)

p

p

i =

i =

L(dBI)̺BI, hr

where ς is the Rician factor, ̺LoS denotes the line-of-sight
(LoS) component, and ̺NLoS denotes the non-line-of-sight
(NLoS) component. In our simulations, the channel coefﬁ-
L(dID,i)̺ID,i,
cients are given by G =
and hd
L(dBD,i)̺BD,i, where dBI, dID,i and dBD,i
denote the distance between BS and IRS, the distance between
IRS and device i, and the distance between BS and device i,
respectively. As in [42], the Rician factors of ̺IB, ̺DI,i, and
̺DB,i are set to be 3 dB, 0, and 0, respectively, and the path
loss exponents for the BS-device channel, the BS-IRS channel,
and the IRS-device channel are set to be 3.6, 2.2, and 2.8,
respectively. Unless stated otherwise, other parameters are set
90 dBm,
as follows: C0 =
ǫ = 10−3, K = 20, M = 20, and N = 64.

30 dB, P0 = 20 dBm, σ2 =

p

−

−

To ensure the effectiveness of our proposed two-step alter-
nating DC algorithm for device selection, we ﬁrst show the
convergence behaviours of the sparse inducing step and the
feasibility detection step in Fig. 4 and Fig. 5, respectively. It
is observed that the objective values of problems P1 and P2
are both able to converge to the stationary points by accurately
ﬁnding rank-one solutions with DC programming.

Under the proposed two-step framework, we compare the
proposed alternating DC based device selection algorithm (i.e.,
Algorithm 1) with the following baseline schemes:

• Alternating SDR with IRS: In this scheme, the SDR
method is applied to solve problems P1,1, P1,2, P2,1,
and P2,2.

• Random phase shifts: In this scheme, the phase shift
of each reﬂecting element at the IRS is uniformly and
independently generated from [0, 2π). We merely solve
problem P1,1 in the ﬁrst step and problem P2,1 in the
second step with the proposed DC algorithm.

• Without IRS: In the circumstance without IRS, only
problem P1,1 in the ﬁrst step and problem P2,1 in the

9

3

2.5

2

1.5

1

0.5

5

10

15

0

0

10

20

30

15

14

13

12

11

10

9

8

7

6

0

Fig. 4. Convergence behaviour of sparse inducing step.

0.019

0.018

0.017

0.016

0.015

0.014

0.013

0.012

0.011

0.01

0

5

10

15

20

Fig. 5. Convergence behaviour of feasibility detection step.

second step need to be solved with the proposed DC
algorithm by setting Θ = 0.

A. Device Selection

Fig. 6 shows the average number of selected devices under
different schemes versus the MSE threshold γ for FL systems
with and without IRS. As the MSE threshold γ increases, the
average number of selected devices becomes larger. This is
because reducing the requirement for the aggregation error
is capable of inducing more edge devices to participate in the
training process of FL. In contrast to the scenario without IRS,
deploying an IRS in the FL system can support much more
devices for concurrent model aggregation under a certain MSE
requirement. Besides, the scheme with random phase shifts
performs worse than both the alternating DC and alternating
SDR methods, which demonstrates the importance of jointly
optimizing the device selection, the aggregation beamformer
at the BS, and the phase shifts at the IRS. Moreover, due to
the effectiveness of obtaining the rank-one solutions with the
DC algorithm, our proposed DC-based method signiﬁcantly
outperforms the SDR method.

10

20

18

16

14

12

10

8

6

4

2

0
-25

-24

-23

-22

-21

-20

-19

-18

-17

-16

-15

20

18

16

14

12

10

8

6

4

2

0
20

25

30

35

40

45

50

55

60

65

70

Fig. 6. Average number of selected devices versus the MSE threshold.

Fig. 8. Average number of selected devices versus the number of antennas
at BS.

20

18

16

14

12

10

8

6

4

2

0

30

40

50

60

70

80

90

100

Fig. 7. Average number of selected devices versus the number of reﬂecting
elements at IRS.

−

Fig. 7 illustrates the impact of the number of reﬂecting
elements at the IRS on the average number of selected devices
when γ =
20 dB. As the number of reﬂecting elements
increases, the IRS generates more accurate passive reﬂective
beamforming for the incident signals, thereby effectively re-
ducing the aggregation error at the BS. Therefore, the system
is capable of selecting more edge devices to participate in FL,
while satisfying the MSE requirement. In addition, since the
SDR method has a high probability of failing to return rank-
one solutions for high-dimensional optimization problems, it
is observed that the gap between the DC and SDR schemes
increases as the number of reﬂecting elements at the IRS
becomes larger.

Fig. 8 shows the impact of the number of antennas at the BS
on the average number of selected devices when γ =
22 dB.
As the number of antennas at the BS increases, the channel
gain between the BS and each edge device is enhanced by
gathering signals from more antennas. Therefore, the adverse
impact of additive noise at the BS can be alleviated and
in turn the aggregation error is reduced, thereby being able
to schedule more edge devices to participate in FL under
a certain MSE requirement. In addition, it is observed that

−

even when the number of antennas at the BS is doubled, it is
still difﬁcult for the system without IRS to achieve a similar
performance to the scenario with an IRS by jointly optimizing
the aggregation beamformer at the BS and the phase shifts at
the IRS. This observation implies that deploying an IRS not
only enhances the system performance but also reduces the
hardware complexity at the BS. Therefore, it is an efﬁcient
way to achieve fast and reliable model aggregation from the
edge devices under a certain MSE requirement by deploying
an IRS in AirComp-based FL system.

B. Performance Comparison for Federated Learning

To directly show the excellent performance of the proposed
two-step alternating DC algorithm for dealing with the FL
tasks, we train a deep CNN on the widely used MNIST
dataset. In the simulations, the MNIST dataset consists of
10 classes with 6000 handwritten digits per class. The case
that all devices are selected at each communication round
and without any aggregation error serves as the Benchmark.
We also consider that the dataset locally owned by each edge
device is non-independent and identically distributed (non-IID)
with uniform size. In addition, each edge device only has two
randomly selected classes.

−

When γ =

17 dB, the training loss and test accuracy aver-
aged over 10 realizations are illustrated in Fig. 9 and Fig. 10,
respectively. The results indicate that the proposed two-step
alternating DC algorithm achieves a desirable performance in
terms of a lower training loss and higher test accuracy than
other schemes due to more edge devices and richer datasets
being selected to participate in FL in each communication
round. In addition, the proposed algorithm achieves almost
the same performance as the Benchmark scheme, which is
an ideal case and serves as the performance upper bound.
Furthermore, Table I shows an example of handwritten digit
identiﬁcation under the FL system with and without IRS.
It can be observed that the IRS-assisted AirComp-based FL
system is capable of achieving more accurate prediction with
the given dataset, which indicates that under a speciﬁc MSE
requirement, admitting more edge devices to participate in FL

TABLE I
EXAMPLES OF HANDWRITTEN DIGIT IDENTIFICATION WITH DIFFERENT SCHEMES

Data

Label
FL w/ IRS
FL w/o IRS

Data

6
6
5 (

×

)

1
1
1

9
9
4 (

×

)

7
7
9 (

×

)

8
8
5 (

×

)

2
2
2

Label
FL w/ IRS
FL w/o IRS

5
5
5

3
2 (
2 (

×
×

)
)

7
7
7

2
2
4 (

×

)

6
6
5 (

×

)

9
7 (
4 (

×
×

)
)

11

4
4
4

0
0
0

5

4.5

4

3.5

3

2.5

2

1.5

1

0.5

0

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

2

4

6

8

10

12

14

16

18

20

2

4

6

8

10

12

14

16

18

20

Fig. 9. Training loss versus communication round.

Fig. 10. Test accuracy versus communication round.

and collaboratively train a global model can achieve a lower
training loss and higher test accuracy in fewer communication
rounds.

devices under certain MSE requirements compared with the
baseline scheme without IRS.

VI. CONCLUSIONS

In this paper, we proposed a novel IRS-assisted AirComp
approach for fast model aggregation in a FL system. To
accelerate the convergence and enhance the learning perfor-
mance of FL, we developed a two-step alternating low-rank
optimization framework to maximize the number of selected
devices under the MSE requirement for model aggregation. We
presented a DC formulation for rank-one constrained problems
in the alternating procedure, followed by proposing the DC
algorithm for solving the resulting DC programs. Simulation
results demonstrated that our proposed algorithm can achieve a
lower training loss and higher test accuracy by selecting more

APPENDIX A
PROOF OF PROPOSITION 1

The transmitter scalar

structure to enforce

wi

{

}

in Eq. (10) has the zero-forcing

1
√η

mH

(GΘhr

i + hd

i )wi

−

2

1

= 0.

(47)

i∈S (cid:12)
X
(cid:12)
(cid:12)
2 /η from Eq. (10).
Moreover, we have MSE(ˆg, g)
(cid:12)
k
We thus obtain the form of zero-forcing transmitter scalar
given in Proposition 1 which minimizes the MSE.

σ2

m

(cid:12)
(cid:12)
(cid:12)
(cid:12)

≥

k

12

[20] T. Sery and K. Cohen, “On analog gradient descent

learning over
multiple access fading channels,” IEEE Trans. Signal Process., vol. 68,
pp. 2897–2911, 2020.

[21] N. Zhang and M. Tao, “Gradient statistics aware power control for over-
the-air federated learning in fading channels,” in Proc. IEEE Int. Conf.
Comm. (ICC) Workshops, 2020.

[22] X. Cao, G. Zhu, J. Xu, and K. Huang, “Optimized power control
for over-the-air computation in fading channels,” IEEE Trans. Wireless
Commun., 2020.

[23] G. Zhu,

J. Xu,
6G-turning
air
http://arxiv.org/abs/2009.02181

and K. Huang,
computer,”

into

a

“Over-the-air

computing for
[Online]. Available:

2020.

[24] S. Tang, H. Yin, and S. Obana, “Reliable over-the-air computation
[Online]. Available:

by amplify-and-forward based relay,” 2020.
http://arxiv.org/abs/2010.12146

[25] Q. Wu and R. Zhang, “Towards smart and reconﬁgurable environment:
Intelligent reﬂecting surface aided wireless network,” IEEE Commun.
Mag., vol. 58, no. 1, pp. 106–112, 2020.

[26] ——, “Intelligent

reﬂecting surface enhanced wireless network via
joint active and passive beamforming,” IEEE Trans. Wireless Commun.,
vol. 18, no. 11, pp. 5394–5409, 2019.

[27] C. Huang, A. Zappone, G. C. Alexandropoulos, M. Debbah, and
C. Yuen, “Reconﬁgurable intelligent surfaces for energy efﬁciency in
wireless communication,” IEEE Trans. Wireless Commun., vol. 18, no. 8,
pp. 4157–4170, Aug. 2019.

[28] J. Chen, Y. Liang, Y. Pei, and H. Guo, “Intelligent reﬂecting surface: A
programmable wireless environment for physical layer security,” IEEE
Access, vol. 7, pp. 82 599–82 612, 2019.

[29] T. Jiang and Y. Shi, “Over-the-air computation via intelligent reﬂecting
surfaces,” in Proc. IEEE Global Commun. Conf. (Globecom), Dec. 2019.
[30] Z. Wang, Y. Shi, Y. Zhou, H. Zhou, and N. Zhang, “Wireless-powered
reﬂecting surface aided IoT

over-the-air computation in intelligent
networks,” IEEE Internet Things J., 2020.

[31] K. Yang, Y. Shi, Y. Zhou, Z. Yang, L. Fu, and W. Chen, “Federated ma-
chine learning for intelligent IoT via reconﬁgurable intelligent surface,”
IEEE Network, vol. 34, no. 5, pp. 16–22, 2020.

[32] Y. LeCun, “The MNIST database of handwritten digits,” 1998. [Online].

Available: http://yann.lecun.com/exdb/mnist

[33] D. Liu and O. Simeone, “Privacy for free: Wireless federated learning
via uncoded transmission with adaptive power control,” 2020. [Online].
Available: http://arxiv.org/abs/2006.05459

[34] D. Mishra and H. Johansson, “Channel estimation and low-complexity
beamforming design for passive intelligent surface assisted miso wireless
energy transfer,” in Proc. IEEE ICASSP, 2019, pp. 4659–4663.
[35] B. Zheng and R. Zhang, “Intelligent reﬂecting surface-enhanced ofdm:
Channel estimation and reﬂection optimization,” IEEE Wireless Com-
mun. Lett., vol. 9, no. 4, pp. 518–522, 2020.

[36] Z. Wang, L. Liu, and S. Cui, “Channel estimation for intelligent reﬂect-
ing surface assisted multiuser communications: Framework, algorithms,
and analysis,” IEEE Trans. Wireless Commun., vol. 19, no. 10, pp. 6607–
6620, 2020.

[37] Y. Shi, J. Cheng, J. Zhang, B. Bai, W. Chen, and K. B. Letaief,
“Smoothed lp-minimization for green Cloud-RAN with user admission
control,” IEEE J. Sel. Areas Commun., vol. 34, no. 4, pp. 1022–1036,
April. 2016.

[38] S. Boyd and L. Vandenberghe, Convex optimization. Cambridge Univ.

Press, 2004.

[39] Z. Luo, W. Ma, A. M. So, Y. Ye, and S. Zhang, “Semideﬁnite relaxation
of quadratic optimization problems,” IEEE Signal Process. Mag., vol. 27,
no. 3, pp. 20–34, May. 2010.

[40] P. D. Tao and L. T. H. An, “Convex analysis approach to DC pro-
gramming: Theory, algorithm and applications,” Acta Math. Vietnamica.,
vol. 22, no. 1, pp. 289–355, 1997.

[41] M. Grant and S. Boyd, “CVX: Matlab software for disciplined convex

programming, version 2.1,” http://cvxr.com/cvx, Mar. 2014.

[42] Q. Wu and R. Zhang, “Beamforming optimization for wireless network
aided by intelligent reﬂecting surface with discrete phase shifts,” IEEE
Trans. Commun., vol. 68, no. 3, pp. 1838–1851, 2020.

APPENDIX B
PROOF OF PROPOSITION 2

|

2

2

2

k

γ

≤

−

m

0, i

, where m

mH(GΘhr

The constraint (14b) can be reformulated as Fi(m) =
= 0. We
i + hd
m
i )
|
k
can further rewrite it as Fi(m/√τ ) = Fi(m)/τ
,
0, i
∈ S
τ and τ > 0. By introducing optimization
where
variable ˜m = m/√τ , the constraint (14b) can be equivalently
˜m
reformulated as
,
k
∈ S
k
where
1. Thus, we obtain the equivalent form of
constraint (14b) given in Eq. (15).

i + hd
i )
|

˜mH(GΘhr

˜m
k

∈ S

0, i

≤

≥

−

≤

≥

γ

k

k

k

2

2

2

|

REFERENCES

[1] D. Silver, T. Hubert, J. Schrittwieser, I. Antonoglou, M. Lai, A. Guez,
M. Lanctot, L. Sifre, D. Kumaran, T. Graepel et al., “A general
reinforcement
learning algorithm that masters chess, shogi, and Go
through self-play,” Science, vol. 362, no. 6419, pp. 1140–1144, 2018.

[2] A. Gatt and E. Krahmer, “Survey of the state of the art in natural
language generation: Core tasks, applications and evaluation,” J. Artif.
Intell. Res., vol. 61, pp. 65–170, 2018.

[3] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classiﬁcation
with deep convolutional neural networks,” in Proc. Neural Inf. Process.
Syst. (NeurIPS), 2012, pp. 1097–1105.

[4] Y. Mao, C. You, J. Zhang, K. Huang, and K. B. Letaief, “A survey
on mobile edge computing: The communication perspective,” IEEE
Commun. Surveys Tuts., vol. 19, no. 4, pp. 2322–2358, 2017.

[5] X. Wang, Y. Han, C. Wang, Q. Zhao, X. Chen, and M. Chen, “In-edge
AI: Intelligentizing mobile edge computing, caching and communication
by federated learning,” IEEE Netw., vol. 33, no. 5, pp. 156–165, Sep.
2019.

[6] K. B. Letaief, W. Chen, Y. Shi, J. Zhang, and Y. A. Zhang, “The roadmap
to 6G: AI empowered wireless networks,” IEEE Commun. Mag., vol. 57,
no. 8, pp. 84–90, 2019.

[7] Y. Shi, K. Yang, T. Jiang, J. Zhang, and K. B. Letaief, “Communication-
efﬁcient edge AI: Algorithms and systems,” IEEE Commun. Surveys
Tuts., 2020.

[8] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efﬁcient learning of deep networks from decentralized
data,” in Proc. Int. Conf. Artiﬁcial Intell. Stat. (AISTATS), vol. 54, 2017,
pp. 1273–1282.

[9] Q. Yang, Y. Liu, T. Chen, and Y. Tong, “Federated machine learning:
Concept and applications,” ACM Trans. Intell. Syst. Technol., vol. 10,
no. 2, p. 12, 2019.

[10] A. Elgabli, J. Park, C. B. Issaid, and M. Bennis, “Harnessing wireless
channels for scalable and privacy-preserving federated learning,” 2020.
[Online]. Available: http://arxiv.org/abs/2007.01790

[11] M. Chen, Z. Yang, W. Saad, C. Yin, H. V. Poor, and S. Cui, “A joint
learning and communications framework for federated learning over
wireless networks,” IEEE Trans. Wireless Commun., 2020.

[12] J. Ren, Y. He, D. Wen, G. Yu, K. Huang, and D. Guo, “Scheduling
for cellular federated edge learning with importance and channel aware-
ness,” IEEE Trans. Wireless Commun., 2020.

[13] H. H. Yang, Z. Liu, T. Q. S. Quek, and H. V. Poor, “Scheduling policies
for federated learning in wireless networks,” IEEE Trans. Commun.,
vol. 68, no. 1, pp. 317–333, 2020.

[14] B. Nazer and M. Gastpar, “Computation over multiple-access channels,”
IEEE Trans. Inf. Theory, vol. 53, no. 10, pp. 3498–3516, 2007.
[15] L. Chen, X. Qin, and G. Wei, “A uniform-forcing transceiver design
for over-the-air function computation,” IEEE Wireless Commun. Lett.,
vol. 7, no. 6, pp. 942–945, 2018.

[16] G. Zhu and K. Huang, “MIMO over-the-air computation for high-
mobility multimodal sensing,” IEEE Internet Things J., vol. 6, no. 4,
pp. 6089–6103, 2019.

[17] K. Yang, T. Jiang, Y. Shi, and Z. Ding, “Federated learning via over-
the-air computation,” IEEE Trans. Wireless Commun., vol. 19, no. 3, pp.
2022–2035, 2020.

[18] G. Zhu, Y. Wang, and K. Huang, “Broadband analog aggregation for
low-latency federated edge learning,” IEEE Trans. Wireless Commun.,
vol. 19, no. 1, pp. 491–506, 2020.

[19] M. Mohammadi Amiri and D. G¨und¨uz, “Machine learning at

the
wireless edge: Distributed stochastic gradient descent over-the-air,” IEEE
Trans. Signal Process., vol. 68, pp. 2155–2169, 2020.

6
