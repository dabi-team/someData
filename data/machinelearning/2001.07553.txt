EnsembleGeneticProgrammingNunoM.Rodrigues[0000−0001−5312−8276],Jo˜aoE.Batista[0000−0002−2997−8550],andSaraSilva[0000−0001−8223−4799]FaculdadedeCiˆenciasdaUniversidadedeLisboa,Lisboa,Portugal{nmrodrigues,jebatista,sara}@fc.ul.ptAbstract.Ensemblelearningisapowerfulparadigmthathasbeenusedinthetopstate-of-the-artmachinelearningmethodslikeRandomForestsandXGBoost.Inspiredbythesuccessofsuchmethods,wehavedevel-opedanewGeneticProgrammingmethodcalledEnsembleGP.Theevo-lutionarycycleofEnsembleGPfollowsthesamestepsasotherGeneticProgrammingsystems,butwithdiﬀerencesinthepopulationstructure,ﬁtnessevaluationandgeneticoperators.Wehavetestedthismethodoneightbinaryclassiﬁcationproblems,achievingresultssigniﬁcantlybetterthanstandardGP,withmuchsmallermodels.AlthoughothermethodslikeM3GPandXGBoostwerethebestoverall,EnsembleGPwasabletoachieveexceptionallygoodgeneralizationresultsonaparticularlyhardproblemwherenoneoftheothermethodswasabletosucceed.Keywords:GeneticProgramming·EnsembleLearning·BinaryClas-siﬁcation·MachineLearning.1IntroductionGeneticProgramming(GP)[25]isoneofthemostproﬁcientMachineLearning(ML)methods.Itiscapableofaddressingmultipletaskssuchasclassiﬁcationandregression,usingavarietyoftechniquesfromthemostclassical[17]tothemostrecent,likethegeometricsemanticapproaches[28]andthecluster-basedmulticlassclassiﬁcation[22].Ensemblelearning[9]isapowerfulMLparadigmwheremultiplemodelsareinducedandtheirpredictedoutputsarecombinedinordertoobtainpredictionsthataremoreaccuratethantheindividualones.SomeofthemostsuccessfulMLmethodsarebasedonensemblelearning,likeRandomForests(RF)[4]andXGBoost(XG)[7].Ontheotherhand,theirperformancemayvarysubstantiallydependingonthesettingofsomecrucialparameters,likethenumberoftreesandtheirmaximumdepth,whichinturndependonthepropertiesofeachdataset.Inspiredbythesuccessofsuchmethods,andmotivatedbytheneedtoau-tomaticallyﬁndtherightsettingsfortheseparameters,wehavedevelopedanewGPmethodcalledEnsembleGP(eGP).TheevolutionarycycleofeGPfol-lowsthesamestepsasotherGPsystems,butwithdiﬀerencesinthepopulationstructure,ﬁtnessevaluationandgeneticoperators.Inparticular,thepopulationiscomposedoftwosubpopulations,treesandforests,whereeachsubpopula-tionusesitsownﬁtnessfunctionandgeneticoperators.TheapproachcanbearXiv:2001.07553v1  [cs.NE]  21 Jan 20202Rodrigues,N.,Batista,J.,Silva,S.describedasco-evolutionary,cooperativeandcompositional,andinvolvessub-samplingofbothobservationsandfeatures.Therestofthepaperisorganizedasfollows.Section2describesrelatedwork,whileSection3providesthedetailsoftheeGPmethod.Section4speciﬁestheexperimentalsetup,andSections5and6reportanddiscusstheresultsobtained.Finally,Section7containstheconclusionsandfuturework.2RelatedWorkEvolutionarycomputationandotherbio-inspiredmethodshavebeenlinkedtoensemblelearningfromearlyon(see[11]andreferencestherein).Anobviouswaytobuildensemblesistocombinediﬀerentindividualsofapopulation,whethertheyareGPindividuals(e.g.[31])orothertypes,likeneuralnetworks(reviewin[15]).Manyothertypesofensembleshavebeenbuiltusingevolutionaryandotherbio-inspiredmethods,likeensemblesofclusteringalgorithms[8],DecisionTrees[5],SupportVectorMachines[1],oramixofdiﬀerenttypes[10].Di-versityisimportantamongensemblemembers,andmultiobjectiveevolutionaryapproacheshavebeenoftenusedtoaddressthisissue(e.g.[2,6,24]andreferencestherein).Amultitudeofpublicationsfocusonsinglespeciﬁcaspectsofensemblelearn-ing,likeselectingandcombiningthemembersoftheensemble(e.g.[10]andref-erencestherein),orevolvingthefunctionsthatcombinethediﬀerentmembers(e.g.[10,16,19]).Othersfocusonbuildingcompleteensemblesfromscratch,butevenifwelimitourselvestotheonesthatuseGPexclusively(e.g.[3,13,29]),weﬁndalargediversityofdesigns,goalsandscalesofapplication.Asystem-aticreviewofthisextremelyvastanddiverseliteratureismuchneededinbothevolutionaryandensemblelearningcommunities.3EnsembleGPNow,wedescribethemethodwecallensembleGP(eGP)withallthevariantsweimplementedandtested.TheevolutionarycycleofeGPfollowsthesamestepsasotherGPsystems,butwithdiﬀerencesinthepopulationstructure,ﬁtnessevaluationandgeneticoperators.Inparticular,thepopulationiscomposedoftwosubpopulations,whereeachsubpopulationusesitsownﬁtnessfunctionandgeneticoperators.Theapproachcanbedescribedasco-evolutionary,cooperativeandcompositional,andinvolvessubsamplingofbothobservationsandfeatures.Algorithm1describesthemainstepsofeGP.Beforedescribingthedetailsregardingthepopulation,ﬁtnessandgeneticoperatorsofeGP,webrieﬂydescribeaGPsystemcalledM3GP[22](Multidi-mensionalMulticlassGPwithMultidimensionalPopulations),notonlybecauseitisoneofthebaselinesinourexperiments,butalsobecausesomeelementsofeGParehighlyinspiredinM3GP.EnsembleGeneticProgramming3Algorithm1eGPprocedureeGP(Dataset(Ds),nt,nf)SplitDsintotraining,testingandsubsamplesΦTlist←GenerateTrees(Φ,nt)Flist←GenerateForests(nf)whilegeneration(g)<maxgenerationsdoTparents←Selection(Tlist)Fparents←Selection(Flist)Toffspring←Breeding(Tparents)Foffspring←Breeding(Fparents)Flist←Prune(Foffspring).Pruneonlythebestforestg++endwhileendprocedure3.1M3GPIntermsofrepresentationofthesolutions,themaindiﬀerencebetweenM3GPandstandardtree-basedGPisthenumberoftreesthatarepartofthesameindividual.WhileastandardGPindividualisasingletree,aM3GPindividualmaybecomposedofseveraltrees,calleddimensions.Originallydevelopedforperformingmulticlassclassiﬁcation[14,22],M3GPevolveseachindividualasasetofhyperfeatures,eachonerepresentedbyadiﬀerenttree/dimension.Afterremappingtheinputdataintothisnewmultidimensionalfeaturespace,itcal-culatestheaccuracybyformingclustersbasedonthedatalabelsandclassifyingeachobservationastheclassoftheclosestcentroidaccordingtotheMahalanobisdistance.M3GPhasalsobeenusedforevolvinghyperfeaturesforregression[23]andforclassiﬁcationinotherGPsystems[18].Startingwithonlyonetree/dimensionperindividual,M3GPusesstandardsubtreecrossoverandmutationbetweenindividuals,andthreeotheroperatorsdesignedforremovingatree/dimensionfromanindividual,addingarandomlycreatedtree/dimensiontoanindividual,andswappingtrees/dimensionsbetweenindividuals.Additionally,apruningoperatorisappliedtothebestindividualofeachgeneration,removingthetrees/dimensionsthatdonotimproveitsaccuracy.3.2eGPPopulationStructureThepopulationiscomposedoftwotypesofindividuals:treesandforests.Atreeisnottheoutputmodel,butonlyapartofit.Theoutputmodelisaforest,builtasanensembleoftrees.Eachtreemaybepartofmanydiﬀerentforests,andsometreesmaybepartofnone.TreeshavethesamestructureasthoseusedinstandardGP,butinsteadofhavingaccesstoalltheobservationsandfeaturesofthetrainingdataset,eachindividualonlyseesasubsetofobservations,andinmanycasesalsoasubsetoffeatures.DiﬀerentvariantsofeGPusediﬀerentsamplingoptions:1)60%ofallobservations,allfeaturesincluded;2)betweenoneandallobservations,4Rodrigues,N.,Batista,J.,Silva,S.onetoallfeaturesincluded,thesenumbersbeingrandomlychosenbeforeeachsampling.Inbothoptions,thesamplingisdoneuniformlywithoutreplacement,andrepeatedwheneveranewsubsetoftrainingdataisrequiredforallocatingtoanewtree.ForestshavethesamestructureastheM3GPindividuals,witheachdimen-sionbeingatreefromthesubpopulationoftrees.3.3eGPFitnessFunctionsThesubpopulationoftreesusesastandardﬁtnessfunctionbasedontheerrorbetweenexpectedandpredictedoutputs,liketheRootMeanSquaredError(RMSE).Inclassiﬁcationproblems,theclasslabelsareinterpretedasthenu-mericexpectedoutputs.Theﬁtnessofeachtreeiscalculatedusingonlythesubsetofobservationsallowedforthistree.Thesubpopulationofforestsusesaﬁtnessfunctionbasedontheaccuracyobtainedonalltheobservationsofthetrainingset.Eachforestgathers,foreachobservation,avote(onaclass)fromeachofthetreesthatcomposeitsensemble.Thisvoteisobtainedbyadoptingtheclasslabelthatisclosertothepredictedoutput.Thevotesfromthediﬀerenttreesoftheensemblecanbecombinedbynormalmajorityvotingorbyweightedvoting.Innormalvoting,foreachobservationtheclassthatreceivesmorevoteswins,andtiesaresolvedbyrandomlychoosingoneoftheclasses.Inweightedvoting(Algorithm2),foreachobservationacertaintyvalueiscalculatedforeachclasspredictionofeachtree,basedonthevectorofpredictedvaluesbyallthetreesoftheensemble(1).Thesumofcertaintyvaluesforeachclassisthencalculated,anddividedbythesumofcertaintyvaluesforbothclasses.Theclasswithhighestresultsischosenastheprediction.WechosetouseL2normalization(2)forconsistencywiththecosinesimilar-ityusedfortheeCrossover(describednext),whichalsousesL2.Othernormal-izationmethodswereconsidered.Min-Maxwasdiscardedduetoitsinabilityfordealingwithoutliers;Z-Scorewasdiscardedbecausetheresultingarraywasnotcontainedinthe]0,1[range.certainty=1−l2(X),X=x1x2...xn(1)l2normalization=vuutnXk=1|xk|2(2)3.4eGPGeneticOperatorsThetreesandforestsofeGPusediﬀerentgeneticoperators.Treesusewhatcanbedescribedasprotectedversionsofthestandardsubtreecrossoverandmuta-EnsembleGeneticProgramming5Algorithm2WeightedVotingprocedureweightedvoting(predictions,certainties)votes←[]forrowinpredictionsdozeros,ones←0forcolincertaintiesdoifpredictions[row][col]==1ones+=certainties[row][col]elsezeros+=certainties[row][col]endforvotes.append(0ifzeros/(zeros+ones)≥ones/(zeros+ones)else1)endforendproceduretion,designatedhereaseCrossoverandeMutation,respectively.Theprotectionisneededwhenparenttreesarenotallowedtoseeallthefeaturesduetofea-turesampling(seeSection3.2).Inthiscase,theoﬀspringmustinheritfeaturerestrictionsfromtheirparents,otherwiseafteranumberofgenerationsallthetreeswillbeusingallthefeatures.Withoutfeaturesampling,theseoperatorsbehavethesameasthestandardones.eMutationsimplyhastoensurethatthenewsubtreecreatedtoreplacearandombranchoftheparentisrestrictedtothesamesubsetoffeaturesastheparent.eCrossovermustguaranteethateachswappedbranchisalsorestrictedtothesubsetoffeaturesinheritedbythereceivingoﬀspring.Eachofthetwooﬀ-springinheritsfromoneofitstwoparents.Insteadofrelyingonacarefulchoiceofcompatiblecouplesandbranchestoswap,eCrossoverreliesonarepairpro-cedurethatreplacesfeaturesonthereceivedbrancheswheneverthesefeaturesarenotallowedbytheinheritedrestrictions(Algorithm3).Eachillegalfeatureiscomparedtoallthelegalonesonthecompletetrainingset,usingthecosinesimilaritymeasure(3).Thechosenreplacementisthemostsimilarfeaturetotheonethatwasremoved.Unliketheeuclideandistance,thecosinesimilaritycancompareandrecognizetwovectorsofsimilarmeaningeveniftheyhaveverydiﬀerentmagnitudes.S(X,Y)=Pnk=1|xk||yk|pPnk=1|xk|2pPnk=1|yk|2(3)Regardingthesubpopulationofforests,itusesthesamegeneticoperatorsasM3GP,namelytwomutationoperatorstoaddandremovetreesfromtheensemble,andonecrossoveroperatortoswaptreesbetweendiﬀerentensembles.4ExperimentalSetupThissectiondescribesourexperimentalsetupfortheeGPmethods,comparingthemagainsttwobaselines,standardGPandM3GP,andtwostate-of-the-art6Rodrigues,N.,Batista,J.,Silva,S.Algorithm3eCrossoverproceduresubtreecrossover(parent1,parent2)cp1,cp2←choosecrossoverpoints.crossoverpoint1and2refacttree(parent1,parent2,cp1,cp2,bag1,bag2,DataTraining)endprocedureprocedurerefacttree(parent1,parent2,cp1,cp2,bag1,bag2,DataTraining)parent1,parent2←swapbranches(cp1,cp2)fixterminals(p1,bag1,bag2,DataTraining)fixterminals(p2,bag2,bag1,DataTraining)endprocedureclassiﬁers,RandomForests(RF)andXGBoost(XG).SixdiﬀerentvariantsofeGPweretested,andtheresultswereanalysedintermsoftrainingandtestaccuracy,numberoftreesandnumberofnodesoftheﬁnalsolutions.Whencom-paringaccuracy,statisticalsigniﬁcanceisdeterminedusingthenon-parametricKruskal-Wallistestatp<0.01.Next,wedescribeallthe10methodstested,theirmainparametersettings,andtheeightdatasetsusedforobtainingthereportedresults.4.1MethodsTable1containstheacronymsanddescriptionsofallthemethodsused,andwillserveasamemoryaidfortheremainderofthispaper.ThesixeGPvariantsareeGP-NandeGP-W(normalandweightedvotingwithsamplingoffeaturesandobservations);eGP-N5andeGP-W5(sameaspreviousbutwithpopulationsof500treesand500forests,insteadof250each);eGPnandeGPw(sameaseGP-NandeGP-Wbutwithoutfeaturesampling).Table1.AcronymsanddescriptionsofthemethodsGPStandardGeneticProgrammingM3GPMultidimensionalMulticlassGPwithMultidimensionalPopulationseGP-NEnsembleGP,featuresampling,normalvotingeGP-WEnsembleGP,featuresampling,weightedvotingeGP-N5EnsembleGP,featuresampling,normalvoting,largerpopulationeGP-W5EnsembleGP,featuresampling,weightedvoting,largerpopulationeGPnEnsembleGP,nofeaturesampling,normalvotingeGPwEnsembleGP,nofeaturesampling,weightedvotingRFRandomForestsXGXGBoostEnsembleGeneticProgramming7Table2.MainparametersettingsRuns30Generations100PopulationSizeGP/M3GP=500,eGP={250+250,500+500}FunctionSet{+,−,×,/,log,p}(protected)FitnessGP=RMSE,M3GP/eGP=AccuracySelectionTournamentsize5(GP/M3GP=DoubleTournament)Crossover/MutationGP=0.95/0.05,M3GP/eGP=0.5/0.5NumberofEstimators{50,100,150,200}MaximumDepth{2,4,6,8}ImpurityMeasureRF={Gini,Entropy}4.2ParametersTable2summarizesthemainparametersusedintheGP-basedmethodsandintheRFandXGmethods.Eachexperimentisperformed30times,witheachrunusingadiﬀerentpartitionofthedatasetin70%trainingand%30test.TheGP-basedmethodsrunfor100generations.GPandM3GPusepopulationsof500individuals,whileeGPinitializeseachsubpopulationwith250(or500)individuals,foratotalof500(or1000)trees+forests.TreesareinitializedusingRampedHalf-and-Half,assuggestedbyKoza[17],whileforestsareinitializedinasimilarfashiontoM3GP,withonlyonetreeperforest[22].Thearithmeticoperatorsofthefunctionsetareprotectedinthefollowingway:whendividingavaluebyzero,wereturnthenumerator;whentryingtosquarerootorlogarithmanegativenumber,wereturnthenumberuntouched.Therefore,theprotectionistoignorethepresenceoftheoperatorwheneveritraisesanexception.Noconstantsareused.TheﬁtnessguidingtheevolutionistheRMSEinGP,andtheaccuracyinM3GPandeGP.InordertoobtaintheaccuracyfromGP,thepredictedoutputsaretransformedintotheclosestnumericclasslabels.SelectionforbreedingismadewithDoubleTournament[21]inGPandM3GP,andregulartournamentineGP,size5.Regardinggeneticoperators,thecrossover/mutationprobabilitiesare0.95/0.05forGP,and0.5/0.5forbothM3GPandeGP.Thismeanschoosingbetweencrossoverandmutationwithequalprobability,butforM3GPandeGPforeststhespeciﬁctypeofcrossoverormutationmustthenbechosen,alsowithequalprobability.Elitismguaranteesthatthebestparentiscopiedintothenewpopulation.RegardingRFandXG(lastthreerowsofthetable),bothwere10-foldcross-validatedfornumberofestimatorsandmaximumdepth,andRFwasalsocross-validatedfortheimpuritycriterion.4.3DatasetsTable3describesthemaincharacteristicsofthedatasetsusedinourexperi-ments.Wehaveselectedeightproblemsfromvariousdomains,allbeingbinaryclassiﬁcationtasks,withadiﬀerentnumberoffeaturesandobservations.8Rodrigues,N.,Batista,J.,Silva,S.Table3.Numberoffeatures,observationsandnegative/positiveratiooneachdataset.DatasetsBCWBRAZILGAMETESHEARTIONOPARKSPPISONARFeatures1181000133323361Observations6834872160027035119531320208Neg/PosRatio35/6542/5850/5045/5565/3575/2552/4846/54BCW,HEART,IONO,PARKS.BreastCancerWisconsin,HeartDis-ease,IonosphereandParkinsonsaredatasetsincludedintheUCIMLreposi-tory[20].BRAZIL.Brazilisadatasetfordetectingburnedareasinsatelliteimagery,containingtheradiancevaluesofasetofpixelsfromaLandsat8OLIimageoverBrazil,andcorrectedunburned/burnedlabels[26].GAMETES.GAMETESEpistasis2-Way1000atts0.4HEDM-1EDM-11isasimulatedGenome-WideAssociationStudies(GWAS)datasetgeneratedus-ingtheGAMETEStool[18],availableinOpenML[12].PPI.GRID/HPRD-unbal-HSisadatasetbuiltfromaProtein-ProteinInter-actionbenchmarkofthehumanspecies[30],containingtheResnikMaxsemanticsimilaritymeasurebetweeneachpairofproteinsonthreediﬀerentsemanticaspects[27].SONAR.sonar.all-dataisadatasetforbinaryclassiﬁcationofsonarreturns,availableinKaggle[32].5ResultsFigures1to8showboxplotsofthetrainingandtestaccuracyobtainedbyallthemethodsonalltheproblems.Foreachproblemtherearetwowhiskeredboxes,theleftonefortrainingandtherightonefortest.OntheBRAZILproblem,ﬁveoutlierswereremovedforvisualizationpurposes,twoontraining(90.97%and67.92%,bothforGP)andthreeontest(90.70%and68.95%forGP,77.29%foreGP-N5).Betweenthetwobaselines,asexpectedM3GPisbetterthanstandardGP,achievingsigniﬁcantlybettertrainingaccuracyonalleightproblems,andalsosigniﬁcantlybettertestaccuracyonﬁveofthem(BRAZIL,IONO,PARKS,PPIandSONAR).Infact,inallpairwisecomparisonswiththeothermethodsinalltheproblems,standardGPissigniﬁcantlyworsein96%ofthecasesontraining,and46%ontest.TheonlyexceptionwhereitperformssigniﬁcantlybetterisontheHEARTproblem,againstRFonthetestdata.RegardingthetwoproposedmethodseGP-NandeGP-W,acomparisonbe-tweenthemrevealsthattheweightedvoting(eGP-W)doesnotseemtoimproveperformanceoverthenormalvoting(eGP-N),astheweightedvotingresultedinonesigniﬁcantlyworsetrainingaccuracyinthePARKSproblem(andanotherborderlineworseinIONO),allotherresultsbeingequaltotheonesofnor-malvoting.AlsobetweeneGP-N5andeGP-W5theweightedvotingresultedinEnsembleGeneticProgramming9onesigniﬁcantlyworsetrainingaccuracyintheIONOproblem,allotherresultsshowingnosigniﬁcantdiﬀerences.Increasingthepopulationsizefrom250to500provedtobeonlymarginallybeneﬁcial,moretoweightedthantonormalvoting.eGP-N5achievedsigniﬁ-cantlybetterresultsthaneGP-Nonfourproblems(GAMETES,IONO,PARKSandSONAR)ontraining,andnoneontest,allotherresultsbeingstatisticallyequal.eGP-W5wassigniﬁcantlybetterthaneGP-Wonﬁveproblems(BCW,HEART,IONO,PARKSandSONAR)ontraining,andononeproblem(IONO)ontest,allotherresultsequal.RegardingtheeGPmethodswithoutfeaturesampling(eGPnandeGPw),inseveralcasestheyrevealedtobesigniﬁcantlybetterthantheirfeaturesamplingcounterparts(eGP-NandeGP-W),moreoftenontrainingbutalsoontwotestcases,onproblemsIONOandPARKS.Evenwhencomparedtothe500indi-vidualcounterparts,theywereoftenbetterontrainingandneverworseontest.Theweightedvotingdidnotimproveorworsentheobtainedaccuracy.WhencomparingtheeGPmethodswiththeM3GPbaseline,werealizethatontrainingaccuracyM3GPisbetterthanalleGPmethodsonfourproblems(GAMETES,HEART,PARKSandSONAR),worsethanalleGPmethodsontwoproblems(BCWandPPI),andontheremainingproblemsitisbetterorequaltomosteGPmethods,exceptonecasewhereitisworse(thaneGPw,onBRAZIL).OntestaccuracyM3GPisbetterthanalleGPmethodsonfourproblems(IONO,PARKS,PPIandSONAR),statisticallythesameasalleGPmethodsonthreeproblems(BCW,GAMETES,HEART),andontheremainingproblemM3GPisbetterthanalleGPfeaturesamplingmethodsandstatisticallythesameaseGPnandeGPw.WhencomparingtheeGPmethodswiththestate-of-the-artRFandXG,ontrainingbotharesigniﬁcantlybetterthanpracticallyalleGPmethodsonallproblems(exceptSONAR,whereRFissigniﬁcantlyworsethanallexcepteGP-NandeGP-W).Ontestaccuracy,ontwoproblems(BCWandGAMETES)therearefewsigniﬁcantdiﬀerences(XGisbetterthaneGP-NandeGP-W),ontwootherproblems(IONO,PARKS)bothRFandXGarebetterthanalleGPmethods,andontheremainingproblemsRFiseitherthesame(BRAZILandPPI),worse(HEART)orbetter(SONAR)inmostcases,whileXGisbetterinallexceptafewcases(eGPnandeGPwonBRAZIL,eGP-NonHEART,withnosigniﬁcantdiﬀerences).6DiscussionInordertobetterunderstandhoweachofthe10methodsscoredrelativelytoeachother,wehavecountedhowmanysigniﬁcantlybetterresultseachoneobtainedamongall72+72=144(training+test)pairwisecomparisonsonallproblems.Table4showsthecounting(totalsarethesumofallproblems)andranksthemethodsaccordingtothetesttotals(training+testincaseoftie).Thesenumbersconﬁrmwhathadalreadybeenobservedintheboxplots:1)theeGPmethods,althoughbetterthanstandardGP,werenotabletooutperform10Rodrigues,N.,Batista,J.,Silva,S.Fig.1.Boxplotforthetraining(left)andtest(right)accuracyofeachmethodintheBCWdataset.Fig.2.Boxplotforthetraining(left)andtest(right)accuracyofeachmethodintheBRAZILdataset.Outliersremovedforvisualizationpurposes:ontraining,90.97%and67.92%,bothforGP;ontest,90.70%and68.95%forGP,and77.29%foreGP-N5.Fig.3.Boxplotforthetraining(left)andtest(right)accuracyofeachmethodintheGAMETESdataset.EnsembleGeneticProgramming11Fig.4.Boxplotforthetraining(left)andtest(right)accuracyofeachmethodintheHEARTdataset.Fig.5.Boxplotforthetraining(left)andtest(right)accuracyofeachmethodintheIONOdataset.12Rodrigues,N.,Batista,J.,Silva,S.Fig.6.Boxplotforthetraining(left)andtest(right)accuracyofeachmethodinthePARKSdataset.Fig.7.Boxplotforthetraining(left)andtest(right)accuracyofeachmethodinthePPIdataset.Fig.8.Boxplotforthetraining(left)andtest(right)accuracyofeachmethodintheSONARdataset.EnsembleGeneticProgramming13Fig.9.Numberofnodesofﬁnalmodels.Foreachproblem,thefourboxesare:GP(black),M3GP(cyan),eGP-N+eGP-W+eGP-N5+eGP-W5alltogether(magenta),andeGPn+eGPwtogether(blue).Alloutliersremovedforvisualizationpurposes.Table4.Countingofhowmanysigniﬁcantlybetterresultseachmethodobtainedamongallpairwisecomparisons.Thetotalsarethesumforallproblems.Orderoftheproblems:BCW,BRAZIL,GAMETES,HEART,IONO,PARKS,PPI,SONAR.MethodTrainingTestXG3+9+9+7+9+9+8+9=632+6+0+8+8+7+8+8=47M3GP1+1+7+8+5+7+1+8=380+6+0+1+7+7+8+8=37RF9+6+8+9+8+8+9+1=580+1+0+0+8+8+2+4=23eGPw5+5+3+5+1+4+2+4=290+1+0+1+2+1+1+0=6eGPn2+1+5+5+5+4+3+4=290+1+0+1+2+0+1+0=5eGP-N52+1+2+2+5+3+3+4=220+1+0+1+2+0+1+0=5eGP-W54+1+1+3+2+1+2+4=180+1+0+1+2+0+1+0=5eGP-N2+1+1+1+2+1+2+1=110+1+0+1+1+0+1+0=4eGP-W2+1+1+1+1+0+2+1=90+1+0+0+0+0+1+0=2GP0+0+0+0+0+0+0+0=00+0+0+1+0+0+0+0=1M3GPorthestate-of-the-artRFandXG,2)theeGPvariantswithoutfeaturesampling(eGPnandeGPw)arebetterthantheothereGPmethods,and3)normalvotingisgenerallybetterthanweightedvoting.Notbeinganensemblemethod,itisnoteworthyhowwellM3GPscored,betterthanRFandallothermethodsexceptXG.Itisalsoimportanttoem-phasizethattheonlymethodswheretherunningparametersweretunedbycross-validationwereRFandXG(seeSection4.2).Therefore,wehavenodoubtregardingthesuperiorityofM3GPoverRF,andraisethequestionofwhetheritcouldsurpassXGhaditsparametersalsobeentuned.RegardingtherankingoftheeGPmethods,itispossiblethatfeaturesam-plingisnotnecessaryforaGPensemble,duetothefeatureselectionthatmostGPtreesnaturallydo.Wemustalsoconsiderthatthefeaturereplacementper-formedbyeCrossovermayhavehighlydestructiveeﬀectsontheﬁtnessoftheoﬀspring.Anotherthingtoconsideristhepossibleinadequacyofourcertaintymeasuretoweightthevotingoftheensembles.14Rodrigues,N.,Batista,J.,Silva,S.AlthoughtheresultsoftheeGPmethodsseemdisappointing,theyarenodoubtaviablealternativetostandardGP,notonlyintermsofﬁtnessbutalsointermsofthesizeoftheevolvedmodels.Figure9showsthetotalnumberofnodesofthebestmodelsfoundbytheGP-basedmethods,groupedinfoursets:1)GPonly(black);2)M3GPonly(cyan);3)eGPmethodswithfeaturesampling(eGP-N+eGP-W+eGP-N5+eGP-W5alltogether,magenta);4)eGPmethodswithoutfeaturesampling(eGPn+eGPwtogether,blue),resultsperproblem.ThevariantswithfeaturesamplingexhibitvalueswithmuchlessdispersionthantheonesproducedbyGP(exceptontheIONOproblem),andsigniﬁcantlyloweronthreeproblems(BCW,GAMETES,HEART).ThisresultbecomesevenmoreimportantwhenwerecallthatGPusedDoubleTournamentforbloatcontrol(seeSection4.2)andiscomposedofasingletree,whileeGPdidnotuseanybloatcontrolandiscomposedofanensembleoftrees.M3GPproducedthesmallestsolutionsofallGP-basedmethods,howeveritalsousedDoubleTournament.Regardingthenumberoftreesthatformtheevolvedensembles(notshown),theeGPmethodsrevealedaremarkableconsistencyamongthediﬀerentproblems,withdiﬀerentrunsalwaysusingbetween2(±1)and13(±2)treesonthebestforest.ThisisinsharpcontrasttothenumberofdimensionsusedbyM3GP,withsomeproblemsusingasfewas1-4(BCW)andothersusingasmanyas11-24(SONAR),13-30(HEART)and20-36(GAMETES).TheGAMETESproblemposedthelargestdiﬃcultiestoallthemethods,butspecialattentionmustbegiventotheresultsobtainedbysomeoftheeGPmethods,preciselytheonesthatscoredworseingeneral:eGP-N,eGP-W,eGP-N5,eGP-W5.LookingbackatFigure3,weobservealargeamountofoutliersofmuchhigheraccuracythannormal.Onthetestdata,thesearebyfarthebestresultsachieved,similartotheonesreportedin[18],andonlythefourmentionedeGPmethodswereabletoachievethem.Althoughoutofthescopeofthispaper,thesemethodswereindeedtheonlyonesabletoﬁnd,amongthe1000featuresofthisproblem,therightcombinationsthatallowedsuchabig“jump”inaccuracy.Therefore,theydeservemoreinvestigation,despitetheirapparentmodestperformance.7ConclusionsandFutureWorkWehavedevelopedanewGPmethodcalledEnsembleGP(eGP)andtesteditoneightbinaryclassiﬁcationproblemsfromvariousdomains,withadiﬀerentnumberoffeaturesandobservations.DiﬀerentvariantsofeGPwerecomparedtostandardGPandM3GPbaselines,andtotheRandomForestsandXGBooststate-of-the-artmethods.TheresultsshowthateGPconsistentlyevolvessmallerandmoreaccuratemodelsthanstandardGP.M3GPandXGBoostwerethebestmethodsoverall,butonaparticularlyhardproblemtheeGPvariantswereabletoreachexceptionallygoodgeneralizationresults,wayabovealltheothermethods.EnsembleGeneticProgramming15Asfuturework,wewillinvestigatewaystoimproveeGPindiﬀerentfronts,makingitmorecompetitivewithM3GPandXGBoostwhilemaintainingthecharacteristicsthatgranteditscurrentsuccess.Forexample,bloatcontrolandsomeparametertuningaretwoelementsthatothermethodsarebeneﬁtingfrom,andthatwewillincorporatealsoineGP.Diﬀerentvotingschemesmayalsoprovebeneﬁcial,aswellasalternativewaystosamplefeaturesandobservations.Additionally,wewillalsoworktowardsextendingeGPinordertogiveittheabilitytoaddressalsoregressionproblemsandmulticlassclassiﬁcationproblems.AcknowledgementThisworkwaspartiallysupportedbyFCTthroughfundingofLASIGEResearchUnitUIDB/00408/2020andprojectsPTDC/CCI-INF/29168/2017,PTDC/CCI-CIF/29877/2017,DSAIPA/DS/0022/2018,PTDC/ASP-PLA/28726/2017andPTDC/CTA-AMB/30056/2017.References1.deAra´ujoPadilha,C.A.,Barone,D.A.C.,Neto,A.D.D.:Amulti-levelap-proachusinggeneticalgorithmsinanensembleofleastsquaressup-portvectormachines.Knowledge-BasedSystems106,85–95(2016).https://doi.org/10.1016/j.knosys.2016.05.0332.Bhowan,U.,Johnston,M.,Zhang,M.,Yao,X.:Evolvingdiverseensem-blesusinggeneticprogrammingforclassiﬁcationwithunbalanceddata.IEEETransactionsonEvolutionaryComputation17(3),368–386(June2013).https://doi.org/10.1109/TEVC.2012.21991193.Brameier,M.,Banzhaf,W.:Evolvingteamsofpredictorswithlineargeneticpro-gramming.GeneticProgrammingandEvolvableMachines2(4),381–407(Dec2001).https://doi.org/10.1023/A:10129788053724.Breiman,L.:Randomforests.MachineLearning45,5–32(2001)5.Cantu-Paz,E.,Kamath,C.:Inducingobliquedecisiontreeswithevolutionaryal-gorithms.IEEETransactionsonEvolutionaryComputation7(1),54–68(2003)6.Chandra,A.,Yao,X.:Ensemblelearningusingmulti-objectiveevolutionaryalgo-rithms.JournalofMathematicalModellingandAlgorithms5(4),417–445(Dec2006).https://doi.org/10.1007/s10852-005-9020-37.Chen,T.,Guestrin,C.:Xgboost:Ascalabletreeboostingsystem.ArXivabs/1603.02754(2016)8.Coelho,A.L.V.,Fernandes,E.,Faceli,K.:Multi-objectivedesignofhierarchicalconsensusfunctionsforclusteringensemblesviageneticprogramming.Decis.Sup-portSyst.51(4),794–809(Nov2011).https://doi.org/10.1016/j.dss.2011.01.0149.Dietterich,T.G.:Ensemblemethodsinmachinelearning.In:MultipleClassiﬁerSystems.pp.1–15.SpringerBerlinHeidelberg,Berlin,Heidelberg(2000)10.Escalante,H.J.,Acosta-Mendoza,N.,Morales-Reyes,A.,Gago-Alonso,A.:Ge-neticprogrammingofheterogeneousensemblesforclassiﬁcation.In:ProgressinPatternRecognition,ImageAnalysis,ComputerVision,andApplications.pp.9–16.SpringerBerlinHeidelberg(2013)16Rodrigues,N.,Batista,J.,Silva,S.11.Gagn´e,C.,Sebag,M.,Schoenauer,M.,Tomassini,M.:Ensemblelearningforfreewithevolutionaryalgorithms?In:Proceedingsofthe9thAnnualConferenceonGeneticandEvolutionaryComputation.pp.1782–1789.GECCO’07,ACM,NewYork,NY,USA(2007).https://doi.org/10.1145/1276958.127731712.Gijsbers,P.:Gametesepistasis2-way1000atts0.4hedm-1edm-11(2017),https://www.openml.org/d/4064513.Iba,H.:Bagging,boosting,andbloatingingeneticprogramming.In:Proceedingsofthe1stAnnualConferenceonGeneticandEvolutionaryComputation-Volume2.pp.1053–1060.GECCO’99,MorganKaufmannPublishersInc.,SanFrancisco,CA,USA(1999),http://dl.acm.org/citation.cfm?id=2934046.293406314.Ingalalli,V.,Silva,S.,Castelli,M.,Vanneschi,L.:Amulti-dimensionalgeneticpro-grammingapproachformulti-classclassiﬁcationproblems.In:Nicolau,M.,Kraw-iec,K.,Heywood,M.I.,etal.(eds.)GeneticProgramming.pp.48–60.SpringerBerlinHeidelberg,Berlin,Heidelberg(2014)15.Islam,M.M.,Yao,X.:Evolvingartiﬁcialneuralnetworkensembles.IEEECompu-tationalIntelligenceMagazine3(2008)16.Johansson,U.,Lofstrom,T.,Konig,R.,Niklasson,L.:Buildingneuralnet-workensemblesusinggeneticprogramming.In:The2006IEEEInternationalJointConferenceonNeuralNetworkProceedings.pp.1260–1265(July2006).https://doi.org/10.1109/IJCNN.2006.24683617.Koza,J.R.:GeneticProgramming(1992)18.LaCava,W.,Silva,S.,Vanneschi,L.,Spector,L.,Moore,J.:Geneticprogram-mingrepresentationsformulti-dimensionalfeaturelearninginbiomedicalclassiﬁ-cation.In:Squillero,G.,Sim,K.(eds.)ApplicationsofEvolutionaryComputation.SpringerInternationalPublishing,Cham(2017)19.Langdon,W.B.,Buxton,B.F.:Geneticprogrammingforcombiningclassiﬁers.In:ProceedingsoftheGeneticandEvolutionaryComputationConference(GECCO-2001.pp.66–73.MorganKaufmann(2001)20.Lichman,M.:UCIMachineLearningRepository(2013),https://archive.ics.uci.edu/ml/index.php21.Luke,S.,Panait,L.:Fightingbloatwithnonparametricparsimonypressure.In:Guerv´os,J.J.M.,Adamidis,P.,Beyer,H.G.,Schwefel,H.P.,Fern´andez-Villaca˜nas,J.L.(eds.)ParallelProblemSolvingfromNature—PPSNVII.pp.411–421.SpringerBerlinHeidelberg(2002)22.Mu˜noz,L.,Silva,S.,Trujillo,L.:M3gp–multiclassclassiﬁcationwithgp.In:Machado,P.,Heywood,M.I.,McDermott,J.,Castelli,M.,Garc´ıa-S´anchez,P.,Burelli,P.,Risi,S.,Sim,K.(eds.)GeneticProgramming.pp.78–91.SpringerInternationalPublishing(2015)23.Mu˜noz,L.,Trujillo,L.,Silva,S.,Castelli,M.,Vanneschi,L.:Evolvingmultidimen-sionaltransformationsforsymbolicregressionwithm3gp.MemeticComputing11(2),111–126(Jun2019)24.deOliveira,D.F.,Canuto,A.M.P.,deSouto,M.C.P.:Useofmulti-objectivege-neticalgorithmstoinvestigatethediversity/accuracydilemmainheterogeneousensembles.2009InternationalJointConferenceonNeuralNetworkspp.2339–2346(2009)25.Poli,R.,Langdon,W.B.,McPhee,N.F.:AFieldGuidetoGeneticProgramming.LuluEnterprises,UKLtd(2008)26.Silva,S.,Vanneschi,L.,Cabral,A.I.,Vasconcelos,M.J.:Asemi-supervisedgeneticprogrammingmethodfordealingwithnoisylabelsandhiddenoverﬁtting.SwarmandEvolutionaryComputation39,323–338(2018).https://doi.org/10.1016/j.swevo.2017.11.003EnsembleGeneticProgramming1727.Sousa,R.T.,Silva,S.,Pesquita,C.:Evolvingknowledgegraphsimilarityforsu-pervisedlearningincomplexbiomedicaldomains.BMCBioinformatics(2019)28.Vanneschi,L.:Anintroductiontogeometricsemanticgeneticprogramming663,3–42(082017)29.Veeramachaneni,K.,Arnaldo,I.,Derby,O.,O’Reilly,U.M.:Flexgp.JournalofGridComputing13,391–407(2015)30.Yu,J.,Guo,M.,Needham,C.J.,Huang,Y.,Cai,L.,Westhead,D.R.:Simplesequence-basedkernelsdonotpredictprotein–proteininteractions.Bioinformatics26(20),2610–2614(082010).https://doi.org/10.1093/bioinformatics/btq48331.Zhang,B.,Joung,J.G.:Enhancingrobustnessofgeneticprogrammingatthespecieslevel.In:GeneticProgrammingConference(GP-97).pp.336–342.Mor-ganKaufmann(1997)32.Zhang,S.:sonar.all-data(2018),https://www.kaggle.com/ypzhangsam/sonaralldata1Table1.BCWp-valuesBCWGPM3GPeGP-NeGP-WeGP-N5eGP-W5eGPneGPwRFXGGP-0.0000.0000.0000.0000.0000.0000.0000.0000.000M3GP0.689-0.0000.0000.0000.0000.0000.0000.0000.000eGP-N0.4840.224-0.5530.1760.0130.8940.0010.0000.088eGP-W0.2240.0700.594-0.0120.0030.9530.0000.0000.029eGP-N50.5710.3350.6980.441-0.1100.0740.0150.0000.699eGP-W50.3240.8700.0760.0750.086-0.0060.2250.0000.766eGPn0.8590.5670.4410.1350.5050.976-0.0000.0000.002TRAINeGPw0.8290.8940.2540.1380.4830.4810.836-0.0000.057RF0.8120.6770.1220.0140.3570.8120.5630.688-0.000XG0.1040.1770.0080.0020.0140.4490.1920.1110.046-TESTTable2.BRAZILp-valuesBRAZILGPM3GPeGP-NeGP-WeGP-N5eGP-W5eGPneGPwRFXGGP-0.0000.0000.0000.0000.0000.0000.0000.0000.000M3GP0.000-0.9530.1870.8940.1770.7560.0030.0000.000eGP-N0.0000.000-0.2120.9470.2440.6780.0070.0000.000eGP-W0.0000.0010.688-0.1790.0290.0880.0000.0000.000eGP-N50.0010.0030.2240.317-0.2850.6990.0080.0010.000eGP-W50.0000.0010.6660.8640.427-0.4720.1260.0110.000eGPn0.0000.6650.0470.0560.0330.030-0.0270.0030.000TRAINeGPw0.0000.1200.3640.2680.1040.2030.439-0.2930.000RF0.0000.0000.3890.9060.2920.8820.0190.279-0.000XG0.0000.6330.0030.0030.0030.0010.2910.0450.000-TESTarXiv:2001.07553v1  [cs.NE]  21 Jan 20202Table3.GAMETESp-valuesGAMETESGPM3GPeGP-NeGP-WeGP-N5eGP-W5eGPneGPwRFXGGP-0.0000.0000.0000.0000.0000.0000.0000.0000.000M3GP0.468-0.0000.0000.0000.0000.0000.0000.0000.000eGP-N0.5440.679-0.5200.0030.0770.0000.0000.0000.000eGP-W0.8530.4500.739-0.0190.0710.0010.0060.0000.000eGP-N50.0770.5050.2310.153-0.0920.0060.4680.0000.000eGP-W50.5290.1560.1510.4870.025-0.0000.0270.0000.000eGPn0.3360.6250.9180.7060.1950.120-0.0380.0000.000TRAINeGPw0.4960.6050.8770.8530.1580.1730.762-0.0000.000RF0.3400.1640.1170.4870.0250.6310.1220.105-0.000XG0.9820.4240.5891.0000.1280.5200.4370.5200.348-TESTTable4.HEARTp-valuesHEARTGPM3GPeGP-NeGP-WeGP-N5eGP-W5eGPneGPwRFXGGP-0.0000.0000.0000.0000.0000.0000.0000.0000.000M3GP0.976-0.0000.0000.0000.0000.0000.0000.0000.000eGP-N0.0640.037-0.6450.0290.0020.0000.0000.0000.000eGP-W0.9590.9350.132-0.0050.0000.0000.0000.0000.000eGP-N50.9170.9170.0570.830-0.2600.0000.0000.0000.000eGP-W50.5940.8360.1640.6780.544-0.0000.0000.0000.000eGPn0.5220.5040.1800.5570.4890.929-0.8940.0000.000TRAINeGPw0.3430.3900.2600.4070.3740.3000.744-0.0000.000RF0.0020.0010.0000.0370.0030.0050.0000.000-0.000XG0.0010.0010.0610.0040.0010.0010.0020.0050.000-TESTTable5.IONOp-valuesIONOGPM3GPeGP-NeGP-WeGP-N5eGP-W5eGPneGPwRFXGGP-0.0000.0000.0000.0000.0000.0000.0000.0000.000M3GP0.000-0.0000.0000.2610.0000.0620.0000.0000.000eGP-N0.0000.000-0.0100.0000.9590.0010.9060.0000.000eGP-W0.0330.0000.018-0.0000.0080.0000.0120.0000.000eGP-N50.0000.0010.1510.001-0.0000.4030.0000.0000.000eGP-W50.0000.0000.1980.0000.865-0.0010.8880.0000.000eGPn0.0000.0000.3650.0020.7050.959-0.0020.0000.000TRAINeGPw0.0000.0000.4230.0030.7500.7500.784-0.0000.000RF0.0000.0000.0000.0000.0000.0000.0000.000-0.000XG0.0000.0000.0000.0000.0000.0000.0000.0000.553-TEST3Table6.PARKSp-valuesPARKSGPM3GPeGP-NeGP-WeGP-N5eGP-W5eGPneGPwRFXGGP-0.0000.4960.0120.0000.0700.0000.0000.0000.000M3GP0.000-0.0000.0000.0000.0000.0000.0000.0020.000eGP-N0.6300.000-0.0040.0010.2670.0000.0000.0000.000eGP-W0.3420.0000.640-0.0000.0010.0000.0000.0000.000eGP-N50.9290.0000.7500.436-0.0460.0450.0170.0000.000eGP-W50.2050.0000.1110.0260.177-0.0000.0000.0000.000eGPn0.1330.0000.0950.0200.1830.953-0.4570.0000.000TRAINeGPw0.0900.0000.0520.0070.1100.8470.952-0.0000.000RF0.0000.0010.0000.0000.0000.0000.0000.000-0.000XG0.0000.0990.0000.0000.0000.0000.0000.0000.021-TESTTable7.PPIp-valuesPPIGPM3GPeGP-NeGP-WeGP-N5eGP-W5eGPneGPwRFXGGP-0.0000.0000.0000.0000.0000.0000.0000.0000.000M3GP0.000-0.0000.0000.0000.0000.0000.0000.0000.000eGP-N0.0000.000-0.1300.1490.2400.0180.9530.0000.000eGP-W0.0000.0000.128-0.0050.0170.0000.1240.0000.000eGP-N50.0000.0000.9120.249-0.7900.3990.1220.0000.000eGP-W50.0000.0000.3010.3750.574-0.3370.2310.0000.000eGPn0.0000.0000.7450.0190.7730.231-0.0140.0000.000TRAINeGPw0.0000.0000.5690.0190.6630.1520.728-0.0000.000RF0.0000.0000.5300.0030.4690.0300.4160.690-0.000XG0.0000.8770.0000.0000.0000.0000.0000.0000.000-TESTTable8.SONARp-valuesSONARGPM3GPeGP-NeGP-WeGP-N5eGP-W5eGPneGPwRFXGGP-0.0000.0000.0000.0000.0000.0000.0000.0000.000M3GP0.000-0.0000.0000.0000.0000.0000.0000.0000.000eGP-N0.7030.000-0.2750.0000.0000.0000.0000.5940.000eGP-W0.7160.0000.509-0.0000.0000.0000.0000.5340.000eGP-N50.4090.0000.2951.000-0.7670.2170.1240.0000.000eGP-W50.4320.0000.7000.2860.193-0.3210.2250.0000.000eGPn0.0190.0000.0550.0180.0120.172-0.6030.0000.000TRAINeGPw0.0130.0000.0340.0120.0110.1100.760-0.0000.000RF0.0010.0000.0050.0040.0020.0140.5240.744-0.000XG0.0000.2070.0000.0000.0000.0000.0000.0000.000-TEST4Fig.1.BoxplotforthenumberofdimensionswitheachmethodintheBCWdataset.Fig.2.BoxplotforthenumberofnodeswitheachmethodintheBCWdataset.5Fig.3.BoxplotforthenumberofdimensionswitheachmethodintheBRAZILdataset.Fig.4.BoxplotforthenumberofnodeswitheachmethodintheBRAZILdataset.6Fig.5.BoxplotforthenumberofdimensionswitheachmethodintheGAMETESdataset.Fig.6.BoxplotforthenumberofnodeswitheachmethodintheGAMETESdataset.7Fig.7.BoxplotforthenumberofdimensionswitheachmethodintheHEARTdataset.Fig.8.BoxplotforthenumberofnodeswitheachmethodintheHEARTdataset.8Fig.9.BoxplotforthenumberofdimensionswitheachmethodintheIONOdataset.Fig.10.BoxplotforthenumberofnodeswitheachmethodintheIONOdataset.9Fig.11.BoxplotforthenumberofdimensionswitheachmethodinthePARKSdataset.Fig.12.BoxplotforthenumberofnodeswitheachmethodinthePARKSdataset.10Fig.13.BoxplotforthenumberofdimensionswitheachmethodinthePPIdataset.Fig.14.BoxplotforthenumberofnodeswitheachmethodinthePPIdataset.11Fig.15.BoxplotforthenumberofdimensionswitheachmethodintheSONARdataset.Fig.16.BoxplotforthenumberofnodeswitheachmethodintheSONARdataset.