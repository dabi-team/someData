0
2
0
2

b
e
F
9
2

]

O
R
.
s
c
[

1
v
5
2
2
0
0
.
3
0
0
2
:
v
i
X
r
a

Comparison of Distal Teacher Learning with Numerical and Analytical
Methods to Solve Inverse Kinematics for Rigid-Body Mechanisms

Tim von Oehsen1, Alexander Fabisch1,2, Shivesh Kumar2 and Frank Kirchner1,2

Abstract— Several publications are concerned with learning
inverse kinematics, however, their evaluation is often limited
and none of the proposed methods is of practical relevance
for rigid-body kinematics with a known forward model. We
argue that for rigid-body kinematics one of the ﬁrst proposed
machine learning (ML) solutions to inverse kinematics – distal
teaching (DT) – is actually good enough when combined with
differentiable programming libraries and we provide an ex-
tensive evaluation and comparison to analytical and numerical
solutions. In particular, we analyze solve rate, accuracy, sample
efﬁciency and scalability. Further, we study how DT handles
joint limits, singularities, unreachable poses, trajectories and
provide a comparison of execution times. The three approaches
are evaluated on three different rigid body mechanisms with
varying complexity. With enough training data and relaxed
precision requirements, DT has a better solve rate and is faster
than state-of-the-art numerical solvers for a 15-DoF mechanism.
DT is not affected by singularities while numerical solutions
are vulnerable to them. In all other cases numerical solutions
are usually better. Analytical solutions outperform the other
approaches by far if they are available.

I. INTRODUCTION

Human beings are extraordinary in performing move-
ments. They can describe and perform these movements in
their physical space without thinking about how to control
every individual muscle. Robots are systems built from var-
ious links and actuators capable of performing movements.
Roboticists often control
individual actuators directly to
interact with the world. To describe a movement in physical
space or in task space we need a relationship to convert the
task space conﬁguration into the joint space conﬁguration.
This is called the inverse kinematics problem (IKP) and is a
central problem in robot control. It is about calculating joint
angles θ ∈ Rn of a kinematic chain to reach a certain end
effector pose x ∈ Rm. n and m denote the degrees of free-
dom (DoF) of the joint space and work space respectively.
IKP is usually easy to formulate but difﬁcult to solve for
robots with serial architecture as it typically results in a set
of non-linear algebraic equations. Often there are multiple
solutions to this problem and their complexity is highly
dependent on the geometry of the robot. One of the early
efforts to solve the IKP was by Pieper [1]. He gave closed-
form solutions for 6-DoF manipulators with three revolute

*This work was supported by the German Federal Ministry for Economic
Affairs and Energy (BMWi, grant no. 50RA1701) and the German Federal
Ministry of Education and Research (BMBF, grant no. 01IW18003).

1Robotics Research Group, University of Bremen, Robert-Hooke-Str. 1,

D-28359 Bremen, Germany tim von@uni-bremen.de

2Robotics Innovation Center, German Research Center for Artiﬁcial In-
telligence (DFKI GmbH), Robert-Hooke-Str. 1, D-28359 Bremen, Germany
{shivesh.kumar,alexander.fabisch}@dfki.de

or prismatic joints whose axes intersect at a point. Similarly,
Paul [2] developed methods to compute analytical solutions
for robots with relatively simple geometry that have many
zero distances and parallel or perpendicular joint axes. For
the IKP of a 6R robot with arbitrary geometry, Raghavan and
Roth [3] derived a 16 degree univariate polynomial which
provides all possible solutions. When an explicit solution to
the IKP is not available or difﬁcult to obtain in real-time,
iterative numerical techniques based on Newton-Raphson or
inverse Jacobian-based methods can be utilized.

Despite the existence of analytical and numerical solutions
to solve this task, there is active research in the ﬁeld of
machine learning to solve the IKP. But why should we
learn inverse kinematics? Learning is beneﬁcial when the
kinematic model is completely or partially unknown. In this
case, traditional analytical or numerical solutions are less
accurate or not even available because they depend on a
model. Machine learning methods enable us to learn IK even
without a known kinematic model though. This is why most
work focuses on learning IK from scratch. However, to this
date, serial kinematic chains with rigid-body geometries are
still the most common type of robots employed in real-world
applications. For these speciﬁc robots the forward kinematics
are known very accurately. Despite rigid-body mechanisms
being a very common type,
there have not been made
extensive evaluations in this regard yet and it is not clear
whether machine learning also has potential to be a valid
alternative to analytical or numerical solutions. Hence, in this
work the main focus lies on the comparison of a machine
learning solution to an analytical and a numerical solution
under known forward kinematics (FK), that is, x = f (θ).

Additionally, the assumed perfect knowledge of the FK
makes it possible to evaluate a machine learning approach
to inverse kinematics in detail. Gained insights can also
(at least partially) be transferred to more difﬁcult variations
of the problem like unknown forward kinematics, ﬂexible
joints or links, torque-based gravity compensation or inverse
dynamics. These problems share some characteristics with
the IKP for known forward kinematics from the machine
learning perspective: (1) accurate model parameters are not
available, (2) training data has to cover the whole workspace,
(3) limits (e.g. joint limits) have to be respected, and (4)
computational efﬁciency is required for robot control.

II. RELATED WORK

In general, the IKP has multiple solutions, even if the robot
is properly actuated, i. e., m = n holds. The main problem
to overcome when learning IK is the nonconvexity of the

 
 
 
 
 
 
solution set which prevents the application of simple direct
regression techniques [4] because they lead to an averag-
ing over the nonconvex solution space. A lot of machine
learning approaches to solve inverse kinematics have been
published. Locally Weighted Projection Regression [5] works
with respect to the differentiated forward kinematics, that is
˙x = J (θ) ˙θ. The matrix J = df
dθ is the Jacobian of the ma-
nipulator. By doing so, the problem can be transformed into
a locally convex one. In [6], Invertible Neural Networks are
proposed. They can be utilized to solve inverse kinematics by
just learning the simpler forward kinematics which leads to
unique solutions. To resolve the redundancy of IK solutions,
latent variables containing the necessary information are
introduced. The method Goal Babbling [7], [8] aims to
learn an IK model by employing goal-directed movements
along paths to a pose. Removing redundant conﬁgurations
during sampling resolves the nonconvexity problem. B´ocsi
et al. [9] learned the joint probability density p(x, θ) via
Structured Output Learning. There have also been ideas to
apply deep reinforcement learning techniques [10]. While the
attempts have been quite diverse, none of these approaches
has been extensively examined and it is not clear whether
there is potential to use them for rigid-body mechanisms. In
particular, several of the aspects mentioned above have not
been explored on systems with varying complexity and no
comparisons to analytical and numerical methods were done.

III. INVESTIGATED SOLUTIONS TO THE IKP

A. Analytical Solution

It is important to note that analytical solutions are robot
dependent and need to be derived individually for every
mechanism. They can only be obtained if certain conditions
are met. For redundant robots (n > m) there are no general
analytical solutions. There are still conditions regarding the
geometrical structure of the mechanism such that a general
analytical solution exists if the dimensionalities of the task
and action space equal (n = m). An example for a 6-
DoF arm is the intersection of the axes of three consecutive
revolute joints in one point at the wrist. Many manipulators
in the industry use a spherical wrist which fulﬁlls this
requirement. For those mechanisms a geometrical closed-
form solution is possible. The spherical wrist permits to split
the IKP into a position and orientation equation that depend
on three joints each and are solvable analytically.

B. Numerical Solution: TRAC-IK

TRAC-IK [11] is a state-of-the-art numerical solver. Like
all numerical methods, it can be used for any serial kine-
matic chain with known geometrical parameters. The solver
consists of a combination of two algorithms. The ﬁrst one
is based on the pseudo-inverse of the Jacobian matrix i.e.
in case of redundant robots (n > m), the solution is given
by ˙θ = J +(θ) ˙x [12]. In case n = m, Jacobian inverse is
sufﬁcient. Via an iterative procedure an IK solution can be
approximated until the Cartesian error falls below a selected
threshold. TRAC-IK further adds random restarts whenever
the algorithm gets stuck in local minima. The second part of

the solver is based on Sequential Quadratic Programming
(SQP, [13]). It is required to formulate the IKP as a two
times differentiable optimization problem to apply SQP. In
TRAC-IK, the objective function φ = pT
errperr will be
minimized, where perr ∈ R6 contains Cartesian errors
in position and orientation. Thus,
the objective function
is the sum of squared errors. In addition, joint limits are
included as constraints. The reason behind combining these
two approaches is to beneﬁt from the different advantages
which are mainly the low execution time of the pseudo-
inverse solver and the high solve rate of the SQP solver.

C. Data-driven solution: Distal Teacher Learning

Distal

teacher learning [4] – we refer to it as distal
teaching (DT) in this paper – is a data-driven method to
solve inverse problems. It can be applied to the IKP as well
and does not depend on a known FK model. However, the
latter is usually known well for rigid-body mechanisms. It
can be used to simplify the training process. The main idea
of DT is to calculate the prediction error of the IK model
in the Cartesian space by propagating predicted joint angle
values through the FK model that acts as the distal teacher.
This procedure is one way to handle the nonconvexity of
the IKP. A direct calculation of prediction errors in the joint
space (direct inverse modeling) would lead to a very bad
performance of the learned IK model because an averaging
over the nonconvex solution space would occur. In DT, the
goal is the identity mapping

f (g(x∗)) = x∗

(1)

where f is the FK function, g the IK and x∗ the desired
pose. The difference of the predicted pose and the desired
pose is the error signal used to optimize the IK model. If
backpropagation is applied, this error signal needs to be
passed backwards through the FK model without updating
it and is then used to optimize the IK model parameters.
Under the assumption of a known FK function, we do not
need to learn a FK model ﬁrst and can directly optimize
an IK model. For this purpose, we propose to integrate the
FK function into the loss function of a feed-forward neural
network with fully connected layers. The latter serves as the
IK model. The implementation of this approach becomes
very easy with modern differentiable programming libraries.
In this case we use TensorFlow [14]. Due to its simplicity
in case of a known FK function, DT is very well suited for
learning the IK of rigid-body mechanisms. In order to train
the neural network, we need to deﬁne a suitable loss. In
general, in this work the weighted sum

ε = wεpos + (1 − w)εori

(2)

of the position error εpos and the orientation error εori of
the end effector is used. w ∈ [0, 1] is a freely choosable
hyperparameter, which we set to 0.75 for our analysis. The
position error is deﬁned as the Euclidean distance of the
desired pose and the predicted pose that results from propa-
gating the predicted joint angles through the FK model. For
the orientation error, we use the quaternion difference εori =

We sample training and test data from a uniform distribution
in joint space unless otherwise stated.

a) Sample efﬁciency: We investigate the effect of num-

ber of training samples on position and orientation errors.

b) Joint limits: We investigate handling of joint limits
and use the loss function given in Eq. 3 for DT. Note that
in all other experiments we use λ = 0, i. e., the loss given
in Eq. 2, and therefore neglect joint limits.

c) Singularities: We evaluate effects of singularities on
solutions to the IKP. We use a dataset which contains query
poses that correspond to at least one singular conﬁguration
and another dataset from which near-singular conﬁgurations
are removed entirely. Results are compared to a standard
dataset which is uniformly sampled in the joint space and
may contain both near-singular and nonsingular cases. It is
well-known that numerical solvers built on the basis of the
manipulator Jacobian tend to have problems near singular
conﬁgurations as det J ≈ 0 and an inversion of J leads to
very high joint velocities. For this reason it is interesting to
see whether DT suffers from the same problem.

d) Approximation of unreachable poses: We investigate
approximation of unreachable poses. Sometimes (e. g., in
reinforcement learning [19]) it is beneﬁcial if we can approx-
imate poses outside of the workspace as close as possible.
In the ﬁrst part of this experiment, the training data lies in
the workspace while the test data consists of end effector
positions that are not reachable. In the second part, the test
data stays the same, but some samples of the training data
are swapped with poses that lie outside of the workspace.

e) Consistency: We analyze for DT and TRAC-IK how
consistent the selection of the solution is. For this purpose
we look at one trajectory in the Cartesian space. The analysis
of discontinuities is performed in the joint space. With
regard to practical applications it would be advantageous
if discontinuities, i. e., changes of the chosen IK solution
for similar query poses, do not occur often. Note that in
this investigation the output of the preceding query pose is
always used as the initial conﬁguration for TRAC-IK.

f) Runtime: We examine prediction runtime of DT and

compare it with TRAC-IK and the analytical solution.

C. Evaluation Metrics

We use the position error εpos and the orientation error
εori of the prediction (described in Section III-C) as the
metric for DT. Whenever the accuracy is compared to TRAC-
IK, we calculate the solve rate for deﬁned error thresholds.
Regarding the investigation of how to handle joint limits in
DT, we introduce the metric η which describes the percentage
of infeasible conﬁgurations from all predictions. A predicted
conﬁguration is considered infeasible if at least one joint
angle violates the limits. In the experiment of approximation
of unreachable poses the position and orientation error alone
are not sufﬁcient to judge how accurate the predictions are.
As a comparative value, the mean euclidean distance from
the base to the desired end effector position over all query
poses, which is given by (cid:107)x∗
pos
consists of the desired Cartesian position coordinates of the

pos(cid:107), is used. The vector x∗

(a) 6-DoF arm
COMPI (source:
[18]).

(b) Model of the humanoid At-
las. A 15-DoF subchain (high-
lighted in red) from the left foot
to the left hand is investigated.

Fig. 1: Evaluated mechanisms in 3D space.
2 acos (cid:0)| ˆqT q∗|(cid:1) [15] since we represent the orientations as
quaternions (q). Furthermore, it is important to note that we
encode the predicted joint angles by using sin θ and cos θ
which is a common technique to encode periodic variables
[16, pp. 105–110] and increases performance. Hence, the
number of output nodes is doubled. Afterwards, joint angles
can be decoded as θ = atan2 (sin θ, cos θ). In its basic form
described above, DT does not take any measures regarding
the joint limits [7]. Hence, the learned IK outputs a lot
of infeasible predictions. In order to handle joint
limits
adequately we propose to add a linear penalty term to the
loss such that it becomes

ε = wεpos + (1 − w)εori + λdv.

(3)

λ is a hyperparameter that deﬁnes the strength of the penalty.
The variable dv is the violation distance, i. e., the sum of all
distances to the next joint limit in infeasible joint regions.

IV. METHODOLOGY

A main contribution of this paper is the rigorous evaluation
and comparison of three different approaches to the IKP.
We would like to encourage other researchers to use similar
benchmarks. Our concept will be presented in this section.
Our implementation can be found at https://github.
com/tvoeh/distal-teaching-ik.

A. Manipulators

We use three manipulators with different complexities.
All of them are serial kinematic chains with rigid links and
revolute joints only. The ﬁrst mechanism is a simple 3-DoF
arm with parallel joint axes which operates in a plane. Its
total length is 1.3 m. The other two mechanisms work in 3D
space and are shown in Fig. 1. One of them is the 6-DoF arm
COMPI [17] that possesses a spherical wrist and has a total
length of 1.12 m. The last mechanism is a 15-DoF subchain
of the humanoid Atlas of Boston Dynamics. We investigate
the serial chain from the left foot to the left hand where the
foot is treated as the base. We further added a tool to the left
hand which extends the total length of the chain to 2.31 m.

B. Experiment Design

We conduct various experiments to compare DT to the
analytical solution and the numerical solver TRAC-IK to get
insights on when it is useful in case of a known FK function.

TABLE I: Evaluation of DT’s sample efﬁciency. Tables list
the percentage of the solutions below given error thresholds.
The number of training samples is shown in brackets.
(a) Error thresholds: εpos < 0.01 m and εori < 0.03 rad.

Mechanism Analy-

tical
3-DoF
100%
Mechanism Analy-

6-DoF
15-DoF

tical
100%
-

DT
DT
Numerical
(100)
(800)
TRAC-IK
3.39% 62.88%
100%
DT
DT
Numerical
(4000)
(32000)
TRAC-IK
98.44%
1.86% 53.58%
93.23% 18.13% 82.96%

DT
(6400)
98.08%
DT
(256000)
94.53%
97.73%

(b) Error thresholds: εpos < 0.001 m and εori < 0.01 rad.

Mechanism Analy-

3-DoF
6-DoF
15-DoF

tical
100%
100%
-

Numerical
TRAC-IK

DT
DT
(4e+6)
(1e+6)
100% 76.49% 89.34%
98.44%
9.59%
3.58%
93.23% 21.97% 59.65%

TABLE II: Percentage of conﬁgurations with at least one
infeasible joint angle η and the mean and standard deviations
of the position error εpos and orientation error εori for
different penalty factors λ in DT. The number of training
samples is 800 (3-DoF) or 32000 (6-DoF and 15-DoF).

6-DoF

Mechanism λ
0
3-DoF
1
2
0
1
2
5
0
1
2
5

15-DoF

η

εpos [m]
12.81% 8.76e-3±8.25e-3
1.27% 1.38e-2±2.67e-2
0.97% 1.42e-2±2.60e-2
71.22% 8.39e-3±6.80e-3
3.30% 3.50e-2±4.57e-2
1.89% 3.72e-2±5.28e-2
1.16% 3.95e-2±5.47e-2
100% 6.93e-3±9.67e-3
6.12% 1.82e-2±3.80e-2
3.02% 1.65e-2±3.01e-2
1.59% 1.31e-2±2.67e-2

εori [rad]
1.20e-2±1.41e-2
1.61e-2±3.09e-2
1.57e-2±2.91e-2
3.15e-2±5.03e-2
1.27e-1±1.53e-1
1.19e-1±1.55e-1
1.45e-1±2.22e-1
1.80e-2±3.46e-2
5.56e-2±1.47e-1
4.95e-2±1.20e-1
4.13e-2±1.13e-1

the higher the chance to violate at least one joint limit. If
the penalty factor λ is increased, the percentage of infeasible
predictions η decreases to about 1% and for higher values of
λ potentially even further. The downside of this approach is
a signiﬁcant increase of the position and orientation errors.
The highest increase is noticed for the 6-DoF mechanism
where the errors increase approximately by a factor of four.
This means that the sample efﬁciency of DT is worse if we
consider joint limits as we need a much larger number of
training samples to reach the same solve rates as depicted
in Table Ia. Nevertheless, with a known FK function we can
generate a few million training samples quickly and using
that many samples is not a problem with modern hardware.

c) Singularities: Results are shown in Table III. The
analytical solution is exact. We expected that the numerical
solver TRAC-IK is sensitive to singularities due to the
pseudo-inverse of the Jacobian, which the resulting solve
rates conﬁrm. While there occur no failures for the simple
planar 3-DoF mechanism, solve rates are clearly lower for
singular conﬁgurations with the 6- and 15-DoF manipulators.
On the dataset from which near-singular conﬁgurations were
removed we also see an increase of the overall solve rate. DT
seems to be more robust against singularities. While there are
slight deviations in the solve rate, no clear trend can be seen
so that we assume that these differences are not caused by
singularities.

(a) Position errors.

(b) Orientation errors.

Fig. 2: Dependency of Cartesian errors of DT on number of
training samples for the 6-DoF and 15-DoF chains.

end effector while the base of the mechanism is located at
the origin of the coordinate system.

V. RESULTS AND DISCUSSION

We tuned the network architecture per robot, resulting in
dense hidden layers with 2x256 nodes (3-DoF arm), 6x512
nodes (COMPI), and 3x1024 nodes (Atlas).

a) Sample efﬁciency: Tables Ia and Ib show a com-
parison of the solve rates for different error thresholds and
dataset sizes. The analytical solution is exact, but only avail-
able for the 3-DoF and 6-DoF manipulator. TRAC-IK ﬁnds
less solutions the more complex the mechanism gets. If the
error threshold is relatively large (cf. Table Ia) and enough
training data is used, DT can come close or even surpass
(see 15-DoF) the numerical solve rate. However, in case of
a low error threshold (cf. Table Ib) DT performs far worse
than TRAC-IK, even with several million training samples.
Also note that DT – in contrast to TRAC-IK – ﬁnds more
solutions for the redundant 15-DoF manipulator compared to
the non-redundant 6-DoF mechanism. Fig. 2 conﬁrms this
as it displays a direct comparison of the Cartesian errors
between the 6-DoF and 15-DoF mechanism. It is further
observable that the errors roughly get reduced by 50% if
the number of training samples is multiplied by four.

b) Joint limits: Results are listed in Table II. We can see
that DT yields lots of infeasible predictions if we do not take
joint limits into account (λ = 0). The more joints are used,

48163264128256Number of training samples10−310−2Position error εpos [m]x 1036-DoF15-DoF48163264128256Number of training samples10−210−1Orientation error εori [rad]x 1036-DoF15-DoFTABLE III: Solve rates for error thresholds εpos < 0.01 m
and εori < 0.03 rad and different test sets. Numbers in brack-
ets below DT denote the number of training samples.

Mecha-
nism
3-DoF

Mecha-
nism
6-DoF

15-DoF

Test Set

Uniform
Singular
Nonsingular
Test Set

Uniform
Singular
Nonsingular
Uniform
Near-sing.
Nonsingular

Analy-
tical
100%
100%
100%
Analy-
tical
100%
100%
100%
-
-
-

Numerical
TRAC-IK

Numerical
TRAC-IK

DT
(800)
100% 62.88%
100% 61.81%
100% 59.17%
DT
(32000)
98.44% 53.58%
86.95% 52.27%
99.08% 51.58%
93.23% 82.96%
89.96% 78.21%
95.34% 82.96%

DT
(6400)
98.08%
99.08%
97.25%
DT
(256000)
94.53%
95.26%
95.98%
97.73%
96.60%
98.12%

(a) 6-DoF, distal teaching.

(b) 6-DoF, TRAC-IK.

TABLE IV: Means and standard deviations for the position
error εpos and orientation error εori for unreachable query
poses without and partly with unreachable poses (u.p.) in the
training data of DT. The number of training samples is 800
(3-DoF) or 32000 (6-DoF and 15-DoF).

3-DoF

Mechanism Training
Dataset
No u.p.
100 u.p.
No u.p.
1000 u.p.
No u.p.
1000 u.p.

15-DoF

6-DoF

(cid:107)x∗

pos(cid:107) [m]

εpos [m]

εori [rad]

3.25
3.25
1.95
1.95
5.28
5.28

2.54±0.47
2.25±0.43
1.62±0.35
1.17±0.25
4.51±0.73
3.27±0.62

0.95±0.76
0.10±0.09
1.95±0.70
0.66±0.46
2.27±0.62
0.44±0.43

d) Approximation of unreachable poses: Results are
listed in Table IV. If we do not use similar unreachable
poses in the training data, the predictions are of low quality.
The mean position error is a bit lower than the comparative
value (cid:107)x∗
pos(cid:107) which means that – on average – the arm is
stretching out into the right direction, but the difference of
(cid:107)x∗
pos(cid:107) and εpos is nowhere near the total arm length. Also
the orientation errors are very high. As we swap some of the
training samples with unreachable poses in a similar range
of the query poses, all of the errors are decreasing clearly.
Now the difference of (cid:107)x∗
pos(cid:107) and εpos gets close to the total
arm length for each mechanism (be aware that the difference
cannot reach the total arm length because the last link of
the manipulator needs to be used to approximate the desired
orientation). Furthermore, sharp declines of the orientation
errors are noticeable but these errors remain high compared
to the errors for query poses in the workspace (cf. Table II).
Consequently, an approximation of unreachable poses with
DT is possible but to reach very accurate predictions a large
proportion of the training data needs to lie outside of the
workspace. While not directly investigated, we can assume
that this impairs the predictions for query poses inside of the
workspace. Note that the applied numerical solution is not
directly suitable to solve for poses outside of the workspace
but it can be modiﬁed to do this accurately (e.g., [19]).

e) Consistency: Fig. 3 compares the predictions in joint
space for one end effector trajectory per mechanism. For the
3-DoF arm (not shown) both methods achieve an optimal
continuity. In the 6-DoF-case DT remains continuous but
TRAC-IK shows a few discontinuities, i.e., changes of the
chosen IK solution. Regarding the 15-DoF chain both results

(c) 15-DoF, distal teaching.

(d) 15-DoF, TRAC-IK.

Fig. 3: Solutions to the IKP in joint space for one trajectory.

are relatively good. No discontinuity occurs when DT is
used and only one if TRAC-IK is applied. While these cases
are only examples, it seems like DT does not switch the
IK solution as often as TRAC-IK. This is an advantageous
property of DT but note that TRAC-IK cannot be seen as a
representative of all numerical solvers because one of TRAC-
IK’s main objectives is to maximize the solve rate. Its SQP-
solver does not use information about the preceding joint
conﬁguration [11].

f) Runtime: In Table Va, runtime for sequential pro-
cessing of query poses with DT is compared with the other
approaches. It is very clear that the analytical solution is
is
by far the fastest and most constant method – if it
available. The numerical solver TRAC-IK needs much longer
in general. We can observe an increase of the runtime
with the complexity of the manipulator. The runtime also
ﬂuctuates a lot as there is a strong dependence on the speciﬁc
query pose (cf. the singular data set) while the runtimes
of the analytical solution and DT do not depend on the
input. The latter can be considered as quite slow for simple
mechanisms though. In DT the runtime strongly depends on
the neural network architectures which we tuned manually.
As the architecture was optimized for each manipulator
individually, the runtimes differ. In the 15-DoF case, DT
has the overall best runtime. Due to the fact that neural
networks can often be calculated more efﬁciently on GPUs
in parallel, we investigated some more cases for DT (Table
Vb). It turns out that the usage of a GPU results in faster
runtimes in case of the 6-DoF and 15-DoF mechanism for
which rather large neural networks are used. Furthermore,
processing query poses as batches of 32 nearly reduces the
runtime by a factor of the batch size. This can be beneﬁcial
if IK needs to be solved for full trajectories at once.

Another important aspect to be considered in a comparison

01020304050Query pose index k−3−2−10123Joint angle θi [rad]θ1θ2θ3θ4θ5θ601020304050Query pose index k−3−2−10123Joint angle θi [rad]θ1θ2θ3θ4θ5θ601020304050Query pose index k−3−2−10123Joint angle θi [rad]θ1θ2θ3θ4θ5θ6θ7θ8θ9θ10θ11θ12θ13θ14θ1501020304050Query pose index k−3−2−10123Joint angle θi [rad]θ1θ2θ3θ4θ5θ6θ7θ8θ9θ10θ11θ12θ13θ14θ15TABLE V: Means and standard deviations of the elapsed
real time to solve the IKP. CPU: Intel Core i7-6800K; GPU:
Nvidia Gefore GTX 1080 Ti.

(a) Computation times for sequential processing on a CPU.

Method
Analytical
Numerical
TRAC-IK

DT

Test Set
Uniform
Uniform
Singular
Nonsing.
Uniform

3-DoF [ms]
0.009±0.001
0.179±0.085
0.193±0.055
0.181±0.096
0.523±0.228

6-DoF [ms]
0.053±0.002
0.908±0.916
1.533±1.664
0.903±0.868
1.774±0.310

15-DoF [ms]
-
1.717±1.353
2.019±1.449
1.582±1.292
1.610±0.308

(b) Computation times for DT using different ways to process queries.

Processing
Sequential
Batch (32)
Sequential
Batch (32)

Device
CPU
CPU
GPU
GPU

3-DoF [ms]
0.523±0.228
0.014
0.983±0.239
0.017

6-DoF [ms]
1.774±0.310
0.054
1.520±0.099
0.046

15-DoF [ms]
1.610±0.308
0.061
1.180±0.113
0.039

to traditional solutions is the training time of DT. For the
15-DoF chain and four million training samples, the training
time on a modern GPU is roughly two weeks.

VI. CONCLUSIONS

We analyzed distal teaching (DT), a data-driven solution to
the IKP, in case of rigid-body mechanisms. For this purpose,
we propose the integration of the usually known forward
kinematics into the loss function of a feed-forward neural
network. Further, we compared the results to an analytical
solution as well as TRAC-IK, a numerical solver.

The results show that analytical solutions are superior due
to their exactness, low and constant runtime as well as the
provision of all solutions. However, they are unavailable for
general redundant manipulators. If high accuracy matters
or the degree of redundancy is fairly low, we reason that
numerical solutions are the best choice. For rather simple
mechanisms, they have shown to be faster and to achieve
better solve rates than DT, especially for high accuracy
requirements. DT only makes sense in case of rigid-body
mechanisms if those are highly redundant and accuracy
requirements are relaxed. With the example of the 15-DoF
serial chain of Atlas, we have shown that reaching higher
solve rates than TRAC-IK is possible while offering lower
and less ﬂuctuating runtimes. Such a performance is only
achievable with a large amount of training data (> 106)
though. While these are easy to generate under known
forward kinematics, this goes along with weeks of training.
Dealing with joint
limits and accurate approximation of
unreachable poses increases the need of data even further.
Positive properties of DT are the robustness against singu-
larities and the continuous choice of solutions. Numerical IK
solvers are better in terms of reconﬁgurability than analytical
solutions or learned IK solutions as they can deal with
generic robot geometry while analytical solutions may not
be valid if there is a signiﬁcant change in robot design and
machine learning based IK solutions would need retraining.
As a side note, there is an interesting similarity between
numerical solvers and machine learning (ML): while numer-
ical solvers ﬁnd one solution to an optimization problem
online, ML solves the same optimization problem ofﬂine and
stores a set of solutions, in our case, in a neural network.

In the future, we will need complex robotic systems that
are hard to model and control accurately (e. g., soft robots
[20], series-parallel hybrid robots with many DoF [21],
[22]) to act in highly dynamic environments, which poses a
problem to both purely classical and ML based approaches.
However, we believe that combining classical and ML-based
solutions in an optimal way to realize what should be called
hybrid artiﬁcial intelligence is the way forward.

ACKNOWLEDGMENT

We thank Matias Valdenegro-Toro for helpful feedback.

REFERENCES

[1] D. L. Pieper, “The kinematics of manipulators under computer con-

trol,” Stanford University, Tech. Rep., 1968.

[2] R. P. Paul, Robot Manipulators: Mathematics, Programming, and

Control, 1st ed. Cambridge, MA, USA: MIT Press, 1982.

[3] M. Raghavan and B. Roth, “Inverse kinematics of the general 6r
manipulator and related linkages,” J. Mech. Design, vol. 115, no. 3,
pp. 502–508, 1993.

[4] M. I. Jordan and D. E. Rumelhart, “Forward models: Supervised
learning with a distal teacher,” Cogn. Sci., vol. 16, no. 3, pp. 307–
354, 1992.

[5] A. D’Souza, S. Vijayakumar, and S. Schaal, “Learning inverse kine-

matics,” in IROS, 2001, pp. 298–303.

[6] L. Ardizzone, J. Kruse, C. Rother, and U. Kthe, “Analyzing inverse

problems with invertible neural networks,” in ICLR, 2019.

[7] M. Rolf, J. J. Steil, and M. Gienger, “Goal babbling permits direct
learning of inverse kinematics,” IEEE Trans. Auton. Ment. De., vol. 2,
no. 3, pp. 216–229, 2010.

[8] M. Rolf and J. J. Steil, “Efﬁcient exploratory learning of inverse
kinematics on a bionic elephant trunk,” IEEE Transactions on Neural
Networks and Learning Systems, vol. 25, no. 6, pp. 1147–1160, 2014.
[9] B. Bocsi, D. Nguyen-Tuong, L. Csato, B. Scholkopf, and J. Peters,
“Learning inverse kinematics with structured prediction,” in IROS,
2011, pp. 698–703.

[10] S. Phaniteja, P. Dewangan, P. Guhan, A. Sarkar, and K. M. Krishna, “A
deep reinforcement learning approach for dynamically stable inverse
kinematics of humanoid robots,” in ROBIO, 2017, pp. 1818–1823.

[11] P. Beeson and B. Ames, “Trac-ik: An open-source library for improved
solving of generic inverse kinematics,” in Humanoids, 2015, pp. 928–
935.

[12] S. Buss, “Introduction to inverse kinematics with jacobian transpose,
pseudoinverse and damped least squares methods,” IEEE Trans. Robot.
Automat., vol. 17, 05 2004.

[13] P. T. Boggs and J. W. Tolle, “Sequential quadratic programming,” Acta

numerica, vol. 4, pp. 1–51, 1995.

[14] M. Abadi et al., “TensorFlow: Large-scale machine learning
[Online]. Available: https:

systems,” 2015.

on heterogeneous
//www.tensorﬂow.org/

[15] Q. Du Huynh, “Metrics for 3d rotations: Comparison and analysis,”

J. Math. Imaging Vis., vol. 35, no. 2, pp. 155–164, 2009.

[16] C. M. Bishop, Pattern recognition and machine learning, 1st ed., ser.
Information science and statistics. New York: Springer, 2006.
[17] V. Bargsten and J. de Gea Fern´andez, “Compi: Development of a 6-dof
compliant robot arm for human-robot cooperation,” in International
Workshop on Human-Friendly Robotics, 2015.

[18] DFKI GmbH. (2019) COMPI. [Online]. Available: https://robotik.

dfki-bremen.de/en/research/robot-systems/compi.html

[19] A. Fabisch, “A comparison of policy search in joint space and cartesian
space for reﬁnement of skills,” in Advances in Service and Industrial
Robotics, K. Berns and D. G¨orges, Eds. Springer, 2020, pp. 301–309.
[20] B. Yu, J. d. G. Fern´andez, and T. Tan, “Probabilistic kinematic model
of a robotic catheter for 3d position control,” Soft Robotics, vol. 6,
no. 2, pp. 184–194, 2019.

[21] S. Bartsch et al., “Development and control of the multi-legged robot
mantis,” in International Symposium on Robotics, 2016, pp. 379–386.
[22] S. Kumar et al., “Modular design and decentralized control of the re-
cupera exoskeleton for stroke rehabilitation,” Applied Sciences, vol. 9,
no. 4, 2019.

