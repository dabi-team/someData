FuncNN: An R Package to Fit Deep Neural
Networks Using Generalized Input Spaces

Barinder Thind
Simon Fraser University

Sidi Wu
Simon Fraser University

Richard Groenewald
Columbia University

Jiguo Cao
Simon Fraser University

Abstract

Neural networks have excelled at regression and classiﬁcation problems when the input
space consists of scalar variables. As a result of this proﬁciency, several popular packages
have been developed that allow users to easily ﬁt these kinds of models. However, the
methodology has excluded the use of functional covariates and to date, there exists no
software that allows users to build deep learning models with this generalized input space.
To the best of our knowledge, the functional neural network (FuncNN) library is the ﬁrst
such package in any programming language; the library has been developed for R and
is built on top of the keras architecture. Throughout this paper, several functions are
introduced that provide users an avenue to easily build models, generate predictions, and
run cross-validations. A summary of the underlying methodology is also presented. The
ultimate contribution is a package that provides a set of general modelling and diagnostic
tools for data problems in which there exist both functional and scalar covariates.

Keywords: functional inputs, deep learning, R, keras.

1. Introduction

In recent years, deep learning methodologies have become the standard approach for predic-
tion problems. For example, He, Zhang, Ren, and Sun (2016) broke previous benchmarks by
developing deep neural networks with over a hundred hidden layers; this was made possible
by an innovation brought upon by a simple adjustment of the algorithm – adding the output
of a previous layer back into the layers following it. Another set of examples can be found
in any one of the annual ImageNet Large-Scale Visual Recognition Challenges (Krizhevsky,
Sutskever, and Hinton 2012; Russakovsky, Deng, Su, Krause, Satheesh, Ma, Huang, Karpa-
thy, Khosla, Bernstein et al. 2015) where neural networks are consistently on the podium.
These innovations naturally sparked the development of software that supplied users with an
arsenal of tools to apply these methods.

There is a wide array of software available in multiple programming languages that implements
a variety of methods in deep learning and neural networks. For example, R packages nnet
(Venables and Ripley 2002) and neuralnet (Fritsch, Guenther, and Wright 2019) are standard
sets of tools in the training of and prediction from neural networks using the Broyden-Fletcher-

0
2
0
2

p
e
S
2
2

]
L
M

.
t
a
t
s
[

2
v
1
1
1
9
0
.
9
0
0
2
:
v
i
X
r
a

 
 
 
 
 
 
2

The FuncNN Package

Goldfarb-Shanno (BFGS) algorithm and backpropagation, respectively. Both of these allow
for some ﬂexibility in terms of user selected activation functions and error measurements, but
vastly more broad selections of tools are available within the RSNNS (Bergmeir and Benítez
2012) and keras (Allaire and Chollet 2020) application programming interfaces (API), which
may be used in both R and Python. Both of these make detailed user customization possible
and are intended to facilitate the development of deep learning models and methodologies.

Central to this paper is functional data analysis (FDA), an area of modern applied statistics
that has witnessed swift development due to its ability to deal with a large and distinct class of
statistical problems. In particular, it is often the case that data is collected at high resolution
at many points in space or time, resembling and being treated as a smooth function - this is
known as functional data. FDA is used instead of the standard approach of analysing single
points when we are interested in framing an analysis of a set of points as if they are samples
from a speciﬁc curve.

Presently, the primary software for FDA in any programming language is the fda package
(Ramsay, Graves, and Hooker 2020) in R, designed to accompany the textbooks of Ramsay
and Silverman (2005) and Ramsay, Hooker, and Graves (2009). The main functionality
within the package revolves around functional regression, allowing users to ﬁt regression
models where one or several of the response and explanatory variables are functions instead
of scalar valued. Several packages in R build upon this base by extending standard statistical
methods to functional data. For example, funHDDC (Schmutz and Bouveyron 2019) and
funFEM (Bouveyron 2015) handle functional clustering, FDboost (Brockhaus and Ruegamer
2018) applies gradient boosting in functional regression and GPFDA (Shi and Cheng 2014)
incorporates functional regression as the mean response in Gaussian processes, among other
packages. Another library, fda.usc (Febrero-Bande and Oviedo de la Fuente 2012), streamlines
the ﬁtting process of many common functional modelling approaches such as non-parametric
functional regression (Ferraty and Vieu 2006) and functional partial least squares methods
(Aneiros-Pérez and Vieu 2006). Additionally, the BFDA package (Yang and Ren 2019) in
MATLAB provides a library for Bayesian FDA.

To the best of our knowledge, the applications of these packages do not extend to include
deep learning models. For this reason, this paper introduces the FuncNN package, which
allows users to include functions as input variables in neural networks and implements the
theoretical discussion in Thind, Multani, and Cao (2020) and Rossi and Conan-Guez (2005).
This methodology has been shown to outperform many other functional and multivariate
methods in a number of real world and simulated examples as seen in Thind et al. (2020).
The FuncNN package introduces several functions. The primary function fnn.fit(), grants
users the ability to eﬀortlessly generate models for their data; they also gain access to several
customization options in the form of hyperparameters. The output of this function can
be acted upon by several other functions within the package such as fnn.predict() and
fnn.fnc() which serve to be predictive and visualization functions. Moreover, we introduce
tuning and cross-validation functions aptly named fnn.tune() and fnn.cv(), respectively.
The package is readily available on CRAN can be installed as follows:

R> install.packages("FuncNN")

Or through GitHub using the devtools (Wickham, Hester, and Chang 2020) package:

R> devtools::install_github("b-thi/FuncNN")

Barinder Thind, Sidi Wu, Richard Groenewald, Jiguo Cao

3

The rest of the article is organized as follows: Section 2 explores some of the theoretical
In Section 3, the bulk of the functions are pre-
background associated with the package.
sented, including the model building and prediction functions; some visualization tools are
also showcased with accompanying examples. In Section 4, helper functions such as those for
cross-validation and tuning are detailed. Lastly, Section 5 includes concluding thoughts and
scheduled updates for the package.

2. Functional neural networks (FNN)

(cid:16)

W (1)x + b(1)(cid:17)

The conventional neural network is a contiguous combination of hidden layers, each of which
contains some number of neurons. Let nu denote the number of neurons in the u-th hid-
den layer. We can deﬁne the ﬁrst hidden layer (denoted by the superscript) as: v(1) =
, where x is a vector of J covariates, W (1) is an n1 × J weight matrix, b(1)
g
is the bias (or the intercept), and g : Rn1 → Rn1 is some activation function that transforms
the resulting linear combination (Tibshirani, Hastie, and Friedman 2009). The vector v(1) is
n1-dimensional and becomes the input to the next layer i.e., it takes the place of the x in the
proceeding layer.

Observe that the classic neural network framework only permits the vectors (of the N obser-
vations) {x1, x2, ..., xN } to contain elements that are ﬁnite scalar values. We now consider
the case when x‘ : ‘ ∈ {1, ..., N } can be a combination of functional and scalar inputs. In
this scenario, the input space takes the following form:

input‘ = {x1(t), x2(t), ..., xK(t), z1, z2, ..., zJ },

where K and J are the number of functional and scalar covariates, respectively. This set is
unique for each of the N observations. With this generalization, the i-th neuron of the ﬁrst
hidden layer corresponding to each of the ‘ observations takes the form (Thind et al. 2020):





v(1)
i = g

K
X

Z

k=1

Tk

βik(t)xk(t)dt +

ij zj + b(1)
w(1)

i


 ,

J
X

j=1

where β(t) is the weight on the functional covariate; this is of a functional form because each
of the k functional inputs must be weighted at every point along their domains, Tk. In order
to estimate β(t), it is rewritten as a linear combination of basis functions:





v(1)
i = g

K
X

Z

MkX

k=1

Tk

m=1

cikmφikm(t)xk(t)dt +





= g

K
X

MkX

k=1

m=1

cikm

Z

Tk

φikm(t)xk(t)dt +



ij zj + b(1)
w(1)

i



J
X

j=1

ij zj + b(1)
w(1)

i


 .

J
X

j=1

(1)

(2)

In Equation (1), βik(t) is approximated by PMk
m=1 cikmφikm(t) where φik(t) is the set of basis
functions and cik is the set of basis coeﬃcients to be estimated by the functional neural
network; in Equation (2), the integral and sum are swapped and the term R
φikm(t)xk(t)dt
can be approximated using any of the usual approximation methods such as Simpson’s rule
(SÃĳli and Mayers 2003). Note that xk(t) is deﬁned by its own set of basis functions.

Tk

4

The FuncNN Package

A by-product of this method is the set of functional weights, β(t), as represented by their basis
expansions. These weights diﬀer in comparison to the usual weights (found in conventional
neural networks) in that they can be easily visualized over the corresponding continuum.
This visualization illuminates the underlying relationship between the functional covariate
and the scalar response. Moreover, passing in information in this functional form preserves
the autocorrelation structure associated with the data. Due to the random initializations in
the conventional neural network, these properties of the data become diﬃcult to maintain if
passed in discretely. In the canonical cases where we have more than one neuron, the average
of the functional weights ˆβk(t) = Pn1
i=1
This formulation of the neural network was shown (Thind et al. 2020) to be a universal
approximator just as conventional neural networks are (Cybenko 1989). While the details are
omitted, the gist of the proof was to show that this form of the neuron, once simpliﬁed, held
the same properties as the usual neural network.

ˆβik(t)/n1, is used as the output.

3. Fitting, prediction, and visualization

3.1. Data description

Throughout this paper, we will focus on three main data sets: the tecator data set, the
gasoline data set and the gait data set. The classic tecator data from the fda.usc package
provides measurements of the near infrared absorbance spectrum and the moisture (water),
fat and protein contents of 215 meat samples. Samples composed of diﬀerent fat, water and
protein contents may behave inconsistently in incident radiation absorption, which can be
measured by absorbance spectroscopy. The data were recorded on a tecator infratec food and
feed analyzer with wavelength range from 850 nm to 1050 nm using the near infrared trans-
mission (NIT) principle. This data set consists of a list named absorp.fdata and a simple
data frame labelled with y. The list absorp.fdata includes the matrix data summarizing
a 100 channel spectrum of absorbance of each meat sample, where absorbance is − log10 of
the transmittance determined by the spectrometer, and the vector argvals which contains
the value of the 100 discretized channels from 850 nm to 1050 nm. The data frame y lays
out the contents of the fat, water and protein of the 215 meat samples that are determined
by analytic chemistry and measured in percent. This data has been applied with the goal of
classifying the fat content levels of the meat samples with the functional covariate of the near
infrared absorbance spectrum and the scalar covariate of the water content.
Secondly, we consider the gasoline data set sourced from the refund package (Goldsmith,
Scheipl, Huang, Wrobel, Di, Gellar, Harezlak, McLean, Swihart, Xiao, Crainiceanu, and Reiss
2019). This data set contains the near infrared reﬂectance (NIR) spectra and the speciﬁed
octane numbers of 60 gasoline samples. For each gasoline sample, 401 NIR spectra were
measured at diﬀerent wavelengths, from 900 nm to 1700 nm in 2-nm intervals, and recorded
using diﬀuse reﬂectance as log(1/reﬂectance). As a simple data frame, the gasoline data
consists of a vector containing the octane levels for each of the 60 collected samples, and a
60 × 401 matrix regarding the details of NIR measurements. This data set has been used in
examples with the aim of determining the octane number, a scalar value, of gasoline based
on the functional predictor of the NIR measurements. Studies in past years (Kelly, Barlow,
Jinguji, and Callis 1989; ÃŰzdemir 2005) have supported the concept that a relationship

Barinder Thind, Sidi Wu, Richard Groenewald, Jiguo Cao

5

exists between the chemical structure and the fuel-performance property of octane, while
NIR spectroscopy is a popular method for simultaneous chemical analysis. Therefore, it has
been implied that the properties of gasoline with diﬀerent octane levels can be reﬂected by
diﬀerent NIR spectral features.
Finally, the examples given in this paper also make use of the gait data set obtained from
the fda package. This data catalogs the hip and knee angles measured in degree through a
twenty-point gait cycle for 39 boys. It is in the form of an array of dimension 20 × 39 × 2,
indicating the 20 evenly-spaced standardized gait times (from 0.025 to 0.975), the 39 subjects
It is
of observation, and the two gait variables Hip Angle and Knee Angle, respectively.
unsurprisingly apparent that hip rotation has a regular association with knee movement in
a normal walk. Therefore, in our example, we consider using hip movement as a functional
covariate to make a prediction for the functional response knee angle.

3.2. Pre-processing

The FuncNN package allows two types of inputs of data; data can be passed in raw or
pre-processed. As with most functional data analysis coding, pre-processing is required to
approximate the raw data x(t), using basis expansions. However, this can be tedious and ul-
timately, a barrier for anyone who is not familiar with the required procedures. The FuncNN
package provides a remedy by letting novice users input their data without the heavy lift-
ing of converting it into its functional form while also granting the opportunity for further
customization for users who require a more speciﬁc or specialized pre-processing. In the case
where the data is passed in raw, the FuncNN package will do a simple pre-processing using a
Fourier basis expansion with 31 terms. While this is an average-case compromise that mini-
mizes initial eﬀort, the alternative approach of pre-processing allows for greater ﬂexibility in
the development of x(t).

Since the functional observations can be passed in two diﬀerent ways, they can be one of two
object types. In the raw case, the functional covariates are passed in as a K-dimensional list
where each element of the list is an N × p data.frame() containing p measurements over the
domain for each of the N subjects.

R>

func_cov_list = list(func_cov_1, func_cov_2, ..., func_cov_K)

The scalar covariates can be passed in similar to most predictive functions i.e., as an N × J
matrix containing information on the J scalar variables for each of the N observations.

If pre-processing is done beforehand, then the object being passed in must be a tensor. In
R, the tensor-type object exists as an array(). The dimensionality of the tensor will be
Mk ×N ×K where each row corresponds to the estimated coeﬃcient when the basis expansion
was made, each column is an individual observation, and each “slice” corresponds to one of the
K functional covariates. Note that scaling is handled internally by the fnn.fit() function.
The response can be passed in as a vector of length N .

While the focus here is on scalar responses, the FuncNN package can handle a version of
functional responses; this version entails a basis expansion of the response curves from which
the basis coeﬃcients are extracted and passed in as a matrix into the model function. The
model will then attempt to predict these coeﬃcients. More details are provided later in the
article.

6

The FuncNN Package

3.3. Classiﬁcation

In this example, we will focus on the tecator data set. The response will be the classiﬁcation
of the fat content of the meat samples as “high” or “low”, denoted by 1 and 0, respectively.
The threshold is 25 percent i.e., if the fat content of a sample is greater than 25, then we
designate the response associated with that sample as 1:

R> tecator_resp = as.factor(ifelse(tecator$y$Fat > 25, 1, 0))

We use the water content of the meat samples as a scalar covariate; as alluded to earlier, this
will be stored in a data.frame() object.

R> tecator_scalar = data.frame(water = tecator$y$Water)

Since this is a prediction problem, we split the data into a training and test set; a random
sample of 75% of the data will be used to build the model and evaluation is performed on
the rest. We will let the modelling function handle the pre-processing for this example and
therefore, the object type to be passed in must be a list which can be generated as follows:

R> func_covs_train = list(train_x)
R> func_covs_test = list(test_x)

where func_covs_train and func_covs_test are the functional covariate matrices for the
training and test sets, respectively (in this example, there is just one functional covariate).
Finally, we can ﬁt the model:

R> fit_class = fnn.fit(resp = train_y,
+
+
+
+

func_cov = func_covs_train,
scalar_cov = scalar_train,
domain_range = list(c(850, 1050)),
raw_data = T)

[1] "Evaluating Integrals:"

|++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=06s

Model
_______________________________________________________________________________________________________
Layer (type)
Output Shape
=======================================================================================================
dense (Dense)
(None, 64)
_______________________________________________________________________________________________________
dense_1 (Dense)
(None, 64)
_______________________________________________________________________________________________________
dense_2 (Dense)
=======================================================================================================
Total params: 4,866
Trainable params: 4,866
Non-trainable params: 0
_______________________________________________________________________________________________________

(None, 2)

Param #

4160

130

576

The ﬁrst item printed refers to the integral approximations that take place as shown in
Section 2; a progress bar is printed indicating the proportion of work completed in this phase.
The training error plot for this model is in Figure 1 – note that this output is a ggplot()

Barinder Thind, Sidi Wu, Richard Groenewald, Jiguo Cao

7

(Wickham 2016) object; this is the same type of object you would extract from the keras
package. As with any Keras model, you can observe the total number of parameters of the
model in the display (in this case, 4886); this printing of information can be muted by setting
print_info to FALSE. There are a number of hyperparameters that will be discussed later in
the article; in this simple example, we stick to the defaults. The only additional speciﬁcations
required in the model are to indicate that raw data is being passed in (the default is set to
FALSE) and the range of the domain. This simple syntax removes the steep learning curve that
comes with functional methods in some of the other packages discussed earlier. The output
contains a Keras model object as well the generated functional observations (if the raw data
was passed in), parameter information, and error rates over the training iterations. Additional
information about the output object can be found in the R documentation for the FuncNN
package. We now have a ﬁtted model to make predictions with. As with most predictive

Figure 1: The iterative error plot over the training process as measured by mean squared
error for the tecator data set.

functions, when one uses fnn.predict(), the ﬁtted model is passed in along with the “new
data” e.g., the func_covs_test object from before (along with the scalar counterpart).

R> predict_class = fnn.predict(fit_class,
+
+
+
+

func_cov = func_covs_test,
scalar_cov = scalar_test,
domain_range = list(c(850, 1050)),
raw_data = T)

The syntax is similar again. The function will automatically recognize that this is a clas-
siﬁcation problem and output class probabilities (the sum of each row will be 1). We can
round these probabilities to get classiﬁcations and plot the confusion matrix (using the caret
package (Kuhn 2020)); this is showcased in the following code chunk:

R> caret::confusionMatrix(as.factor(rounded_preds), as.factor(test_y))

Confusion Matrix and Statistics

Reference

mean_squared_error0204060801000.000.050.100.150.20Epoch Numberdatatrainingvalidation8

The FuncNN Package

Prediction 0 1
0 40 0
1 1 13

Accuracy : 0.9815

95% CI : (0.9011, 0.9995)

No Information Rate : 0.7593
P-Value [Acc > NIR] : 6.299e-06

Kappa : 0.9506

Mcnemar's Test P-Value : 1

Sensitivity : 0.9756
Specificity : 1.0000
Pos Pred Value : 1.0000
Neg Pred Value : 0.9286

We can also visualize the relationship between the functional covariates and the scalar re-
sponse by way of the functional weights using the fnn.fnc() function. The syntax is fairly
straight-forward:

R> fnc_tec = fnn.fnc(fit_class, domain_range = list(c(850, 1050)))

As a point of interest, the fnc part of the fnn.fnc() function stands for functional neural
coeﬃcient; this is legacy code naming convention but as a reference, anytime this is mentioned,
it refers to the functional weights of the model. For this function, we only need to pass in
the model along with the domain. The output will be the eﬀect of the functional weight on
the response over the continuum as estimated by the functional neural network; these can
be made sense of at times, however, contextual information is required. We do hazard that
because of the plethora of other parameters in the network, it can be diﬃcult to interpret these
parameters – these interpretations should be considered carefully on a case-by-case basis. In
this example, we observe that there seems to be two primary spikes over the continuum. The
resulting functional weight from this model is given in Figure 2.

3.4. Regression

We now consider an example of a regression problem; we will investigate the relationship
between the near-infrared reﬂectance spectra (functional covariate) and and octane values
(scalar response) of 60 gasoline observations in the gasoline data set. In this example, we
will process the raw data beforehand and then pass it into fnn.fit(); we will also use multiple
functional covariates by taking the derivatives of the functional data estimated using the raw
data. In order to generate the functional observations, we use 9 Fourier basis functions. The
Data2fd() function from the fda.usc package will allow us to create these functions with the
following code:

R> nbasis = 9
R> spline_basis = create.fourier.basis(c(900, 1700), nbasis)

Barinder Thind, Sidi Wu, Richard Groenewald, Jiguo Cao

9

Figure 2: The functional weight estimated through the functional neural network for the
tecator data set. We observe two spikes. We also note that the magnitude of the eﬀect
depends on the scale of both the functional data and the functional weight.

R> gasoline_fd = Data2fd(timepts, t(gasoline[,-1]), spline_basis)
R> gasoline_deriv1 = deriv.fd(gasoline_fd)
R> gasoline_deriv2 = deriv.fd(gasoline_deriv1)

where gasoline_fd is the functional data object converted from the functional predictor. As
alluded to earlier, when the data is pre-processed manually out of the function, we have to
pass it in as a tensor object i.e., arrays in R. We can develop the array with the following
code:

R> gasoline_data = array(dim = c(nbasis, 60, 3))
R> gasoline_data[,,1] = gasoline_fd$coefs
R> gasoline_data[,,2] = gasoline_deriv1$coefs
R> gasoline_data[,,3] = gasoline_deriv2$coefs

We now ﬁt the model using a functional weight deﬁned with ﬁve basis functions.
In this
initial release, we allow users to use Fourier and B-spline basis functions for the functional
weights. Note that we speciﬁed the learning rate and the number of epochs in this model as
well, along with the number of layers – these are just some of the numerous hyperparameters
that can be adjusted in this function.

R> gasoline_example <- fnn.fit(resp = train_y,
+
+
+
+
+
+
+
+
+
+
+

func_cov = gasoline_data_train,
scalar_cov = NULL,
basis_choice = c("bspline"),
num_basis = c(5),
hidden_layers = 2,
neurons_per_layer = c(64, 64),
activations_in_layers = c("relu", "linear"),
domain_range = list(c(900, 1700)),
epochs = 300,
learn_rate = 0.0001,
early_stopping = T)

−0.0020.0000.0020.00485090095010001050Continuumbeta(s)10

The FuncNN Package

[1] "Warning: You only specified basis information for one functional covariate --
it will be repeated for all functional covariates"
[1] "Evaluating Integrals:"

|++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=01s
|++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=01s
|++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=01s

Model
_______________________________________________________________________________________________________
Layer (type)
Output Shape
=======================================================================================================
dense (Dense)
(None, 64)
_______________________________________________________________________________________________________
(None, 64)
dense_1 (Dense)
_______________________________________________________________________________________________________
dense_2 (Dense)
=======================================================================================================
Total params: 5,249
Trainable params: 5,249
Non-trainable params: 0
_______________________________________________________________________________________________________

(None, 1)

Param #

4160

1024

65

Observe the warning present in the output – the FuncNN package has many stop checks
built to provide clear information to the user regarding errors and warnings. In this case,
we had 3 functional covariates but only speciﬁed information for one functional weight - i.e.,
we speciﬁed the functional weight to be a B-spline expansion of ﬁve terms. To make up for
the lack of information, fnn.fit() will just repeat this same setup for all of the inputted
functional covariates.

Again, we provide the Keras model information. We observe that there were 5249 parameters
being trained during the model building process. The error plot is given in Figure 3 – observe
that the early_stopping parameter was triggered in this case so the plot does not extend to
the speciﬁed 300 epochs. More information on this parameter is provided later in the article.
Predictions are handled using the same function, fnn.predict(); again, the only diﬀerence

Figure 3: The iterative error plot over the training process as measured by mean squared
error for the gasoline data set.

will be that the output will be a vector of values as opposed to a matrix containing class
probabilities.

mean_squared_error0501001502002503000.00.51.01.52.0Epoch NumberdatatrainingvalidationBarinder Thind, Sidi Wu, Richard Groenewald, Jiguo Cao

11

3.5. Functional responses

To demonstrate functional responses, we will predict knee movement using hip movement
with the information presented in the gait data set. While we present a straightforward
approach to functional response prediction, we will update the package with a more reﬁned
and sophisticated approach as we continue to develop such methodology. The approach used
in the following example boils down to predicting the coeﬃcients of the functional data object
corresponding to the response. To begin, we read in the data and generate our functional
observations:

R> hipbasis13 = create.fourier.basis(c(0,1), 13)
R> kneebasis11 = create.fourier.basis(c(0,1), 11)
R> timepts = as.numeric(rownames(gait))
R> hip_fd = Data2fd(timepts, gait[,,1], hipbasis13)
R> knee_fd = Data2fd(timepts, gait[,,2], kneebasis11)

In this example, we use 13 and 11 basis functions to generate the hip and knee observations,
respectively. The pre-processing is done in a manner similar to that of the regression case
above. A notable point is that the response will now be a N × Mresp matrix object where
N is the number of functional observations and Mresp is the number of basis functions used
to deﬁne these observations – the values in the matrix correspond to the estimated basis
coeﬃcients (in this example, we have 11 per observation).
We now ﬁt the model using four layers containing 64 neurons each with relu (Hahnloser,
Sarpeshkar, Mahowald, Douglas, and Seung 2000) activation function. The learning rate was
selected after a small grid search.

R> gait_fit <- fnn.fit(resp = resp_train,
+
+
+
+
+
+

func_cov = data_train,
hidden_layers = 3,
activations_in_layers = c("relu", "relu", "relu"),
neurons_per_layer = c(128, 128, 32),
epochs = 300,
learn_rate = 0.0007)

[1] "Evaluating Integrals:"

|++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=02s

Model
_______________________________________________________________________________________________________
Layer (type)
Output Shape
=======================================================================================================
dense (Dense)
(None, 128)
_______________________________________________________________________________________________________
dense_1 (Dense)
(None, 128)
_______________________________________________________________________________________________________
(None, 32)
dense_2 (Dense)
_______________________________________________________________________________________________________
dense_3 (Dense)
(None, 11)
=======================================================================================================
Total params: 22,027
Trainable params: 22,027
Non-trainable params: 0
_______________________________________________________________________________________________________

Param #

16512

1024

4128

363

The error plot corresponding to this model is given in Figure 4. This model was, thus far,
the most parameter heavy of the examples with a total of 22,027. Predictions are made in a

12

The FuncNN Package

Figure 4: The iterative error plot over the training process as measured by mean squared
error for the gait data set.

similar manner as before; the output object will be a matrix with a number of columns equal
to that of Mresp and a row dimensionality the same as the number of functional observations
in the test set.

R> predictions = fnn.predict(model = gait_fit,
+

func_cov = data_test)

To visualize the results, the fnn.plot() function can be used which will output the evalua-
tions of the functional response prediction over the domain. The syntax consists of specifying
the prediction object, the domain, a step size which determines how ﬁnely evaluations are
made, and the type of basis function to be used for the plot.

R> gait_func_pred = fnn.plot(predictions,
+
+
+

domain_range = c(0, 1),
step_size = 0.05,
Basis_Type = "fourier")

Using these predictions, we can compare our predicted curve to the true functional response;
Figure 5 shows one such comparison.

4. Model improvement tools

4.1. Hyperparameters

Thus far, we have generated models largely using the default settings of the FuncNN package;
however, there is ample opportunity to adjust these models so that they are best suited for
a particular context. These adjustments come by way of toying with the hyperparameter
options available to us in the modelling process.

mean_squared_error050100150200250300050100Epoch NumberdatatrainingvalidationBarinder Thind, Sidi Wu, Richard Groenewald, Jiguo Cao

13

Figure 5: A comparison of a knee angle prediction ˆy(t) over a 1 second interval (functional
response) with the observed movement, y(t).

Parameter

β(t)

w

b

Type

Estimated

Estimated

Estimated

Number of lyers

Hyperparameter

Details

Coeﬃcient function found by the FNN.

The scalar covariate weights.

The intercept in each neuron.

The depth of the FNN.

Neurons per layer

Hyperparameter

Number of neurons in each layer of the FNN.

Learn rate

Decay rate

Hyperparameter

The learning rate of the FNN.

Hyperparameter

A weight on the learning process across training iterations for the FNN.

Validation split

Hyperparameter

The split of training set during learning process.

Functional weight basis

Hyperparameter

The size of M for the estimation of β(t).

Training iterations

Hyperparameter

The number of learning iterations.

Batch size

Activations

Hyperparameter

Hyperparameter

Subset of data per pass of the FNN.

The choice of g(·) for each layer.

Early stopping

Hyperparameter

Stops the model building process if no improvement in error.

Dropout

Hyperparameter

Randomly drops some speciﬁed percentage of neurons from one layer to the next.

Table 1: A list of the parameters in the network.

Some parameters, such as the ones seen explicitly in Equation 1, are estimated through
gradient descent - i.e., the "learning" process of the model results in the ﬁnal values. Others,
such as the number of hidden layers and the neurons within each of these layers, are adjusted
for by the user. For example, as demonstrated earlier in the article, the early_stopping
option halts the learning process when signiﬁcant decreases in error have not been observed
for some number of training iterations – this number, known as the patience parameter, is
also a hyperparameter. Another example is that of the learning rate, γ, and the decay rate,
which both govern how quickly we move in the direction of the gradient. The complete list
of hyperparameters along with descriptions is provided in Table 1.

4.2. Cross-validation

A ﬁrst step in choosing parameter values in any modelling process is to ﬁnd a reliable mea-
suring stick to assess how a model performs. One approach to solving this problem is cross-
validation. The general deﬁnition for a k-fold cross-validation error is

0.00.20.40.60.81.0020406080100timetrue angle0.00.20.40.60.81.0020406080100timepredicted angle14

The FuncNN Package

MSPE =

K
X

X

(cid:16)

k=1

l∈Sk

ˆy(−k)
l

− yl

(cid:17)2

/ (|Sk|K)

l

k=1 is a partition of the data set, |Sk| denotes cardinality, and ˆy(−k)
where {Sk}K
, l ∈ Sk, is the
predicted value for yl obtained by training the functional neural network using data points
with indices not contained in Sk. Choosing to measure error in this way ensures that our
measurement is computed using data that was not used to train the model, reducing the bias
relative to other estimations of test error.
This paradigm is at the core of fnn.cv(), the package’s cross-validation function. Much
of the syntax overlaps with the fnn.fit() function. We demonstrate the cross-validation
function using the gasoline data set. Instead of splitting the data into test and training
sets, we can pass in the entire data set – the cross-validation function will take care of this
internally. The nfolds option determines the number of subsets in our partition of the full
data set – this is the only syntax diﬀerence between the fnn.fit() and fnn.cv() functions.

resp = octane,
func_cov = gasoline_data,
scalar_cov = NULL,
basis_choice = c("bspline", "bspline", "bspline"),
num_basis = c(5, 5, 5),
hidden_layers = 2,
neurons_per_layer = c(64, 64),
activations_in_layers = c("relu", "linear"),
domain_range = list(c(900, 1700),

R> gasoline_cv <- fnn.cv(nfolds = 10,
+
+
+
+
+
+
+
+
+
+
+
+
+
+

epochs = 300,
learn_rate = 0.0001,
early_stopping = T)

c(900, 1700),
c(900, 1700)),

While the function is running, the number of completed folds will be displayed and updated,
for example:

[1] "Folds Done: 1"
[1] "Folds Done: 2"
...

The output will contain the overall cross-validated error as well as the errors corresponding
to each fold. The indices for each fold split will also be available for users if they choose to
reproduce the function results manually. In this example, a 10-fold cross-validation was done
and the MSPE was 0.0735. We look to improve on this in the next section.

4.3. Tuning

Having honed in on a more robust measure of error, we can begin to outline the tuning
approach, which consists of a classic grid search to develop testable combinations of hyper-
parameters. Algorithm 1 below details the tuning process used in FuncNN.

Barinder Thind, Sidi Wu, Richard Groenewald, Jiguo Cao

15

Algorithm 1: Tuning (Hyperparameter optimization)

Input: A subset of all possible values for each of the hyperparameters of interest,

including: number of hidden layers, number of neurons, number of training
iterations, percentage of split, patience, learning rate, number of basis
functions, and activation function

Output: The optimal set of hyperparameters (η) over all combinations of the

elements in Input

1 Input the grid, along with the functional and scalar observations, and set the

non-tuning hyperparameters, e.g., type of basis functions, number of folds (k) for
cross-validation, rate of decay, etc.

2 Generate all possible combinations of hyperparameters, denoted η1, η2, ..., ηn, where n

is the total number of combinations
For each hyperparameter combination ηi, i = 1, ...., n
Construct the functional neural network with ηi
Train the designed functional neural network
Calculate the k-fold cross-validation error MSPE(ηi)

3

4

5

End

6 Return η = {ηk : MSPE(ηk) ≤ MSPE(ηi) for all i}

The FuncNN package makes this intuitive and easy. There is no automated pre-processing
for the tuning function, fnn.tune(); this decision was made due to eﬃciency concerns but
will be remedied for in the future. The syntax is as follows:

fnn.tune(tune_list,

resp,
func_cov,
scalar_cov = NULL,
basis_choice,
domain_range,
batch_size = 32,
decay_rate = 0,
nfolds = 5,
cores = 4,
raw_data = F)

Some of these have already been presented before. The ones to note are the tune_list and
cores parameters. The latter is an eﬃciency parameter that allows for parallelization. This
is handled internally by the dependency future (Bengtsson 2020). The former must be a list
object that contains the grid of combinations to be tested. An example of what this list might
look like is:

R> tune_list_gasoline = list(num_hidden_layers = c(2),
+

neurons = c(32, 64),

16

+
+
+
+
+
+
+

The FuncNN Package

epochs = c(250),
val_split = c(0.2),
patience = c(15),
learn_rate = c(seq(0.0001, 0.001,

length.out = 5)),

num_basis = c(5, 7, 9),
activation_choice = c("relu", "sigmoid"))

This object is not processed as obviously as it may seem. We assign each of the hidden layer
choices (in this case, just the one choice of 2 hidden layers) all combinations of neurons and
activation functions. This is exempliﬁed below:

L1_Act L2_Act FW_1 FW_2 FW_3 L1_N L2_N Epochs ValSplit Patience LearnRate
0.000100
32
0.000550
64
0.000550
64
0.001000
64
0.000100
64
0.000325
32
0.000325
32
0.001000
32
0.000775
32
0.000100
32
0.000550
32
0.000550
32
0.000550
32
0.001000
32
0.000325
32

relu
relu
relu
relu
relu
relu
relu
relu
relu
relu
relu
relu
relu
relu
relu

relu
relu
relu
relu
relu
relu
relu
relu
relu
relu
relu
relu
relu
relu
relu

0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2

250
250
250
250
250
250
250
250
250
250
250
250
250
250
250

32
32
32
32
32
32
32
64
32
64
32
32
32
32
64

15
15
15
15
15
15
15
15
15
15
15
15
15
15
15

5
5
5
5
5
5
5
5
5
5
5
5
5
5
5

5
5
5
5
5
5
5
5
5
5
5
5
5
5
5

5
7
5
5
5
7
5
5
5
5
9
7
5
5
5

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

Observe that we are cycling through all of the possible combinations of neuron numbers,
activation functions, and functional weight basis counts from the list. We did not need to
specify the number of neurons for each layer separately. While this is less obvious of an
approach than allowing the user to set the grid for each layer, it is much more eﬃcient when
one considers that they may want to be tuning over many layers. For example, tuning over
10 hidden layers in the traditional approach would require a list object that contains over 30
elements, whereas in this case, the length of the list remains the same no matter how many
layers you are attempting to tune for.

Having set up the tuning list, we can now consider the code required to run the tuning
function:

R> gasoline_tuned = fnn.tune(tune_list = tune_list_gasoline,
+
+
+
+
+
+

resp = octane,
func_cov = gasoline_data,
basis_choice = c("fourier", "fourier",

domain_range = list(c(900, 1700),
c(900, 1700),

"fourier"),

Barinder Thind, Sidi Wu, Richard Groenewald, Jiguo Cao

17

+
+

nfolds = 2)

c(900, 1700)),

With respect to nfolds, we see that the tuning comparisons will be done with a 2-fold cross-
validated error. Increasing this number, as expected, will increase the computational time of
this function. You may tune for a multiple number of layers at once. In that case, the grid
above is reproduced for each hidden layer. The output will be a list object containing the
ﬁnal grid (as seen above), the cross-validated MSPE values for every combination, the best
from each choice of layers, and the overall best across all layers (along with the corresponding
parameters).

While the functions runs, we took advantage of the pbapply package (Solymos and Zawadzki
2019) to provide users with a progress bar.

|++++++++++++++++++++++++++++++++++++++++++++++++

| 94% ~3m 49s

This progress bar displays the approximate amount of time remaining until the tuning is
ﬁnished; this information oﬀers some obvious beneﬁts to a user’s quality of experience.
Our goal for this tuning (applied to the gasoline data set) was to signiﬁcantly outperform
the cross-validated error from the default settings presented before. After running the tuning
function, the optimal parameters over the pre-deﬁned grid were:

R> gasoline_tuned$Parameters

$MSPE
[1] 0.002492664

$num_basis
[1] 7 9 9

$hidden_layers
[1] 2

$neurons_per_layer
[1] 32 32

$activations_in_layers
[1] "sigmoid" "relu"

$epochs
[1] 250

$val_split
[1] 0.2

$patience_param
[1] 15

18

The FuncNN Package

$learn_rate
[1] 0.001

Using these parameter choices, we can run the cross-validation function again (with ten folds
for the purposes of comparison under equivalent circumstances):

R> gasoline_tuned_cv <- fnn.cv(nfolds = 10,
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+

resp = octane,
func_cov = gasoline_data,
scalar_cov = NULL,
basis_choice = c("bspline", "bspline",

"bspline"),

num_basis = c(7, 9, 9),
hidden_layers = 2,
neurons_per_layer = c(32, 32),
activations_in_layers = c("sigmoid", "relu"),
domain_range = list(c(900, 1700),
c(900, 1700),
c(900, 1700)),

epochs = 250,
learn_rate = 0.001,
early_stopping = T)

And the resulting cross-validated MSPE was 0.0043. The results are summarized in Table 2:

Model

Default

Tuned

CV MSPE

0.0735

0.0043

Standard error

0.0534

0.00275

Table 2: Tuning vs. default model results.

We observe a much smaller standard error on our tuned model, indicating a greater level of
consistency with respect to the predictions. The high variance in the default model suggests
that there is some propensity for that particular model to overﬁt the data; it seems that
behaviour is largely contained in the tuned model.

5. Conclusion and future work

Functional data analysis is an emerging ﬁeld where new and exciting research is being con-
ducted through a diﬀerent data paradigm than the usual multivariate lens; this paper has
illustrated how the functions introduced in the FuncNN take advantage of this paradigm and
allow users to generate useful models which apply deep learning to functional data. Since
FuncNN package is built on top of the Keras architecture, many of the numerous parameters
available to users implementing Keras models are also available for the software introduced
here.

Barinder Thind, Sidi Wu, Richard Groenewald, Jiguo Cao

19

Throughout the article, we presented a number of functions. This includes core functions
such as those for model ﬁtting (fnn.fit()) and predicting (fnn.predict()) but also addi-
tional convenience functions for easier validation of analysis (e.g., fnn.cv(), fnn.tune()).
These functions were highlighted with the use of examples including those in the context of
regression, classiﬁcation, and functional responses.

A number of updates to the package have been scheduled including the introduction of more
core Keras options. We also are working on a better parallelization of the underlying processes
to help with eﬃciency. Lastly, while we presented one way of handling functional responses
in this article, there is a novel extension that is being worked on – this approach will also be
available in future versions of FuncNN.

Acknowledgments

We would like to thank Matthew Reyers, Meyappan Subbaiah, and Kevin Multani for their
useful discussions during the development of the package.

References

Allaire J, Chollet F (2020). keras: R Interface to ‘Keras’. R package version 2.3.0.0, URL

https://CRAN.R-project.org/package=keras.

Aneiros-Pérez G, Vieu P (2006). “Semi-functional Partial Linear Regression.” Statistics &

Probability Letters, 76(11), 1102–1110.

Bengtsson H (2020). future: Uniﬁed Parallel and Distributed Processing in R for Everyone.

R package version 1.18.0, URL https://CRAN.R-project.org/package=future.

Bergmeir C, Benítez JM (2012). “Neural Networks in R Using the Stuttgart Neural Network
Simulator: RSNNS.” Journal of Statistical Software, 46(7), 1–26. URL http://www.
jstatsoft.org/v46/i07/.

Bouveyron C (2015). funFEM: Clustering in the Discriminative Functional Subspace. R pack-

age version 1.1, URL https://CRAN.R-project.org/package=funFEM.

Brockhaus S, Ruegamer D (2018). FDboost: Boosting Functional Regression Models. URL

https://cran.r-project.org/web/packages/FDboost/index.html.

Cybenko G (1989). “Approximation by Superpositions of a Sigmoidal Function.” Mathematics

of Control, Signals and Systems, 2(4), 303–314.

Febrero-Bande M, Oviedo de la Fuente M (2012). “Statistical Computing in Functional Data
Analysis: The R Package fda.usc.” Journal of Statistical Software, 51(4), 1–28. URL
http://www.jstatsoft.org/v51/i04/.

Ferraty F, Vieu P (2006). Nonparametric Functional Data Analysis: Theory and Practice.

Springer-Verlag, New York.

20

The FuncNN Package

Fritsch S, Guenther F, Wright MN (2019). neuralnet: Training of Neural Networks. R package

version 1.44.2, URL https://CRAN.R-project.org/package=neuralnet.

Goldsmith J, Scheipl F, Huang L, Wrobel J, Di C, Gellar J, Harezlak J, McLean MW, Swihart
B, Xiao L, Crainiceanu C, Reiss PT (2019). refund: Regression with Functional Data.
R package version 0.1-21, URL https://CRAN.R-project.org/package=refund.

Hahnloser RH, Sarpeshkar R, Mahowald MA, Douglas RJ, Seung HS (2000). “Digital Se-
lection and Analogue Ampliﬁcation Coexist in a Cortex-inspired Silicon Circuit.” Nature,
405(6789), 947–951.

He K, Zhang X, Ren S, Sun J (2016). “Deep Residual Learning for Image Recognition.” In

Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.

Kelly JJ, Barlow CH, Jinguji TM, Callis JB (1989). “Prediction of Gasoline Octane Numbers
from Near-infrared Spectral Features in the Range 660-1215 nm.” Analytical Chemistry,
61(4), 313–320.

Krizhevsky A, Sutskever I, Hinton GE (2012). “Imagenet Classiﬁcation with Deep Convolu-

tional Neural Networks.” In Advances in Neural Information Processing Systems.

Kuhn M (2020). caret: Classiﬁcation and Regression Training. R package version 6.0-86,

URL https://CRAN.R-project.org/package=caret.

Ramsay JO, Graves S, Hooker G (2020).

fda: Functional Data Analysis. R package ver-

sion 5.1.4, URL https://CRAN.R-project.org/package=fda.

Ramsay JO, Hooker G, Graves S (2009). Functional Data Analysis with R and MATLAB.

Springer-Verlag, New York. ISBN 9780387981857.

Ramsay JO, Silverman BW (2005). Functional Data Analysis. 2nd edition. Springer-Verlag,

New York.

Rossi F, Conan-Guez B (2005). “Functional Multi-layer Perceptron: A Non-linear Tool for

Functional Data Analysis.” Neural Networks, 18(1), 45–60.

Russakovsky O, Deng J, Su H, Krause J, Satheesh S, Ma S, Huang Z, Karpathy A, Khosla
A, Bernstein M, et al. (2015). “Imagenet Large Scale Visual Recognition Challenge.” In-
ternational Journal of Computer Vision, 115(3), 211–252.

Schmutz A, Bouveyron JJC (2019).

funHDDC: Univariate and Multivariate Model-Based
Clustering in Group-Speciﬁc Functional Subspaces. R package version 2.3.0, URL https:
//CRAN.R-project.org/package=funHDDC.

Shi JQ, Cheng Y (2014). GPFDA: Apply Gaussian Process in Functional Data Analysis.

R package version 2.2, URL https://CRAN.R-project.org/package=GPFDA.

Solymos P, Zawadzki Z (2019). pbapply: Adding Progress Bar to ‘*apply’ Functions. R pack-

age version 1.4-2, URL https://CRAN.R-project.org/package=pbapply.

SÃĳli E, Mayers D (2003). An Introduction to Numerical Analysis. Cambridge University

Press, Cambridge.

Barinder Thind, Sidi Wu, Richard Groenewald, Jiguo Cao

21

Thind B, Multani K, Cao J (2020). “Deep Learning with Functional Inputs.” 2006.09590.

Tibshirani R, Hastie T, Friedman J (2009). The Elements of Statistical Learning: Data

Mining, Inference, and Prediction. Springer-Verlag, New York.

Venables WN, Ripley BD (2002). Modern Applied Statistics with S. 4th edition. Springer-
Verlag, New York. ISBN 0-387-95457-0, URL http://www.stats.ox.ac.uk/pub/MASS4.

Wickham H (2016). ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag, New York.

ISBN 978-3-319-24277-4. URL https://ggplot2.tidyverse.org.

Wickham H, Hester J, Chang W (2020). devtools: Tools to Make Developing R Packages
Easier. R package version 2.3.0, URL https://CRAN.R-project.org/package=devtools.

Yang J, Ren P (2019). “BFDA: A MATLAB Toolbox for Bayesian Functional Data Analysis.”
ISSN 1548-7660. doi:10.18637/

Journal of Statistical Software, Articles, 89(2), 1–21.
jss.v089.i02. URL https://www.jstatsoft.org/v089/i02.

ÃŰzdemir D (2005). “Determination of Octane Number of Gasoline Using Near Infrared
Spectroscopy and Genetic Multivariate Calibration Methods.” Petroleum Science and Tech-
nology, 23(9–10), 1139–1152.

22

The FuncNN Package

A. Computational times for all models

Section

3.3 - Classiﬁcation

3.3 - Classiﬁcation

3.3 - Classiﬁcation

3.4 - Regression

3.4 - Regression

3.4 - Regression

3.5 - Functional responses

3.5 - Functional responses

3.3 - Functional responses

3.5 - Functional responses

4.2 - Cross-validation

4.3 - Tuning

Method

fnn.fit()

fnn.predict()

fnn.fnc()

fnn.fit()

fnn.predict()

fnn.fnc()

fnn.fit()

fnn.predict()

fnn.plot()

fnn.fnc()

fnn.cv()

fnn.tune()

Run time

13.0s

2.22s

0.170s

4.22s

2.45s

0.410s

5.61s

0.410s

0.230s

0.270s

1m12s

8h24m

Table 3: Computational run times for every function used in this article from the FuncNN
package.

Barinder Thind, Sidi Wu, Richard Groenewald, Jiguo Cao

23

Aﬃliation:

Jiguo Cao
Department of Statistics
Faculty of Science
Simon Fraser University
8888 University Drive
E-mail: jiguo_cao@sfu.ca
URL: http://people.stat.sfu.ca/~cao/

