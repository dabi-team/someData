1
2
0
2

g
u
A
7
2

]
h
p
-
t
n
a
u
q
[

1
v
1
4
4
2
1
.
8
0
1
2
:
v
i
X
r
a

Optimal control of quantum thermal machines using machine learning

Ilia Khait,1 Juan Carrasquilla,2, 3 and Dvira Segal4, 1
1Department of Physics, University of Toronto, Toronto, Ontario, Canada M5S 1A7
2Vector Institute, MaRS Centre, Toronto, ON, Canada
3Department of Physics & Astronomy, University of Waterloo, Waterloo, ON, Canada
4Department of Chemistry and Centre for Quantum Information and Quantum Control,
University of Toronto, 80 Saint George St., Toronto, Ontario, M5S 3H6, Canada
(Dated: August 31, 2021)

Identifying optimal thermodynamical processes has been the essence of thermodynamics since its
inception. Here, we show that diﬀerentiable programming (DP), a machine learning (ML) tool,
can be employed to optimize ﬁnite-time thermodynamical processes in a quantum thermal machine.
We consider the paradigmatic quantum Otto engine with a time-dependent harmonic oscillator as
its working ﬂuid, and build upon shortcut-to-adiabaticity (STA) protocols. We formulate the STA
driving protocol as a constrained optimization task and apply DP to ﬁnd optimal driving proﬁles for
an appropriate ﬁgure of merit. Our ML scheme discovers proﬁles for the compression and expansion
strokes that are superior to previously-suggested protocols. Moreover, using our ML algorithm
we show that a previously-employed, intuitive energetic cost of the STA driving suﬀers from a
fundamental ﬂaw, which we resolve with an alternative construction for the cost function. Our
method and results demonstrate that ML is beneﬁcial both for solving hard-constrained quantum
control problems and for devising and assessing their theoretical groundwork.

Many problems in physics are formulated as optimiza-
tion tasks by identifying a cost function that has to be
minimized. Prime examples are Hamilton’s principle of
least action in Lagrangian mechanics [1], Fermat’s law
of least time in classical optics [2], and more recently,
variational algorithms in quantum computing [3]. Simi-
larly, since its inception, thermodynamics was concerned
with performance optimization by identifying constrains
and bounds on energy conversion processes. The ideal
Carnot engine is designed to reach the maximal eﬃ-
ciency. However, this upper bound is theoretically ob-
tained for arbitrarily slow, quasistatic processes, thus the
extracted power reduces to zero. Quasistatic processes
are described using the framework of equilibrium ther-
modynamics. In contrast, real thermal devices operate
on ﬁnite-time cycles, and they are naturally described
in terms of ﬁnite-time thermodynamics [4, 5]. This the-
ory is concerned with e.g. how the eﬃciency of thermal
machines erode when heat-to-work conversion processes
take place in ﬁnite-time cycles [6, 7].

Quantum thermal machines, in which e.g. quantum
coherences, correlations, and quantum statistics play a
decisive role cater fundamental understanding of ther-
modynamics at the nano and atomistic scale [8, 9]. Be-
yond fundamental interest, quantum thermal machines
promise compact, fast, and eﬃcient work extraction and
refrigeration schemes for quantum devices.
It remains
however a challenge to harness such eﬀects and achieve
a quantum advantage in thermal machines [10–14].

Optimizing the performance of nanoscale, quantum
thermal machines is a central problem in the rapidly-
emerging ﬁeld of quantum thermodynamics. Techniques
such as shortcut-to-adiabaticity (STA) allow the design
of ﬁnite-time protocols, which reproduce the same ﬁnal
state of an adiabatic time evolution, yet at a price of a

supplemental work on the system [15–19]. Much theo-
retical and experimental eﬀort [20–27] has been put to
realize and characterize these systems. Here, we focus on
a speciﬁc class of STA protocols - local counterdiabatic
driving (LCD), which are advantageous to the realization
of quantum engines since they only require the applica-
tion of local time-dependent potentials.

FIG. 1.
Scheme of the Otto refrigerator in the energy-
frequency domain. A cycle includes a compression stroke
(AB) of duration τ , an instant isochoric stroke (BC) with
the system coupled to a hot bath, an expansion stroke (CD)
of duration τ , and another instant isochoric stroke with a
cold bath (DA). Refrigeration corresponds to the withdrawal
of heat (cid:104)Q4(cid:105) from the cold bath. The energetic cost of the
cycle is the sum of the work contributions (cid:104)W1(cid:105) and (cid:104)W3(cid:105),
along with the energetic cost of the STA driving, (cid:104)CAB(cid:105) and
(cid:104)CCD(cid:105).

In this work, we harness state-of-the-art machine learn-
ing (ML) techniques to optimize the performance of
quantum thermal machines. Speciﬁcally, we optimize
an LCD protocol in the quantum Otto refrigerator, de-
picted in Fig. 1. ML allows us to employ a broad, unique
approach for the design, optimization and control of a

β1Frequencyω1ω2β2Mean energyABCDCABCCD 
 
 
 
 
 
large variety of classes of problems, including quantum
processes [28–32]. Advances in diverse research topics,
such as image recognition and natural language process-
ing have led physicists to exploit ML in quantum dynam-
ics and many-body physics [33].

∈

We adopt Diﬀerentiable Programming (DP) [34, 35] to
ﬁnd optimal refrigeration schemes for the quantum Otto
cycle under STA conditions. From a reinforcement learn-
ing (RL) perspective, in this scheme an agent plays a
“game”, where the time-dependent frequency ω(t) of the
harmonic oscillator acting as the working medium of the
refrigerator can be varied in the time interval t
[0, τ ].
For each attempted strategy, ω(t), the agent receives a
reward designed to minimize the energetic cost of the pro-
tocol while subjected to the physical constraints imposed
by the LCD condition (both aspects are elaborated later
in this text). The driving proﬁles that are discovered by
the ML scheme, exempliﬁed in Fig. 2, are superior to
previously-proposed protocols [36, 37]. Furthermore, the
ML approach helps uncovering a fundamental problem
with a previously-suggested energetic cost metric, which
under some conditions violate basic physical principles
(Carnot bound). We show a systematic optimization
path based on state-of-the-art ML tools, which permits
a search in a large multidimensional variational param-
eter space; the space consists of all functions fulﬁlling
STA conditions. The advantage of the DP-ML scheme
derives in it using the exact gradients of the quantity
of interest with respect to variational parameters, hence
reducing the number of required iterations to reach an
extremum [33, 38].

T2−T1

Quantum Otto refrigerators.– Prime examples of ther-
mal machines are heat engines and refrigerators [20, 39–
42]. While the ﬁrst performs work by utilizing heat cur-
rent from a hot reservoir, refrigerators extract heat from a
cold bath using external work. As a thermodynamic pro-
cess, refrigerators attain their maximal (Carnot) cooling
eﬃciency, (cid:15)C = T1
(with T1,2 as the temperatures of
the cold and hot reservoirs, respectively) for an inﬁnitely-
slow (adiabatic) process. Yet, for such processes the
power output, deﬁned as the extracted heat over cycle
time, Jc = (cid:104)Q4(cid:105)
2τ , is null due to the inﬁnitely long cycle
time, τ
. For a ﬁnite-time cycle, the eﬃciency de-
creases, and the power output increases. Therefore, the
core question of ﬁnite-time thermodynamics is: What is
the optimal cycle for a ﬁgure of merit given by the cooling
eﬃciency times output power?

→ ∞

The quantum Otto refrigerator is depicted in Fig. 1.
We choose a working medium consisting of a harmonic os-
cillator governed by the time-dependent Hamiltonian [43]

H0(t) =

1
2m

p2 +

mω(t)2
2

x2.

(1)

The cycle consists of an isothermal compression stroke
where the frequency ω(t) increases from ω1 at t = 0 to ω2
at t = τ . Then, the engine thermalizes with a hot bath in

2

an isochoric stroke, followed by an isothermal expansion
of duration τ back to the frequency ω1, and an isochoric
is extracted from a cold bath.
stroke in which heat
The thermalization strokes are assumed instantaneous.

Q4

(cid:105)

(cid:104)

STA and counterdiabatic driving.– The goal of the
STA driving is to speed up the compression and ex-
pansion strokes thus enhance the ﬁgure of merit. By
adding the nonadiabatic driving HSTA(t) to Eq. (1), the
system’s ﬁnal state after a time evolution from t = 0
to t = τ exactly matches the outcome of an adiabatic
approximation-based time-evolution of H0(t) [36, 44]. A
further canonical transformation of HSTA(t) leads to the
LCD Hamiltonian of a harmonic oscillator [45, 46] with
frequency Ω(t)2
2ω(t) [45]. This mod-
iﬁed driving should fulﬁl the following conditions [36],

3 ˙ω(t)2
4ω(t)2 + ¨ω(t)

ω(t)2

≡

−

ω(0) = ω1,
ω(τ ) = ω2,

˙ω(0) = 0,

¨ω(0) = 0,

˙ω(τ ) = 0,

¨ω(τ ) = 0,

(2)

which ensure that the ﬁnal state of the system is identical
(phase included) to the state resulting from an adiabatic
time evolution of H0(t).

During compression (AB) and expansion (CD) strokes
(Fig. 1), the system is thermally isolated and work is ap-
plied. Using the adiabatic solution of the time-dependent
Schr¨odinger equation [47, 48], the mean value of work is

W1
(cid:104)

(cid:105)

=

(cid:18)

1

(cid:126)ω2
2

ω1
ω2

−

(cid:19)

coth

(cid:18) β1(cid:126)ω1
2

(cid:19)

,

(3)

W3
(cid:104)

by replacing 1

and similarly for
the mean heat extracted during the DA stroke is [43]
(cid:18) β1(cid:126)ω1
2

(cid:18) β2(cid:126)ω2
2

(cid:126)ω1
2

coth

coth

(cid:19)(cid:21)

↔

Q4
(cid:104)

=

−

(cid:19)

(cid:20)

(cid:105)

(cid:105)

2. Furthermore,

. (4)

0

(cid:105)

dt

(cid:90) τ

= coth

(cid:12)
(cid:12)
(cid:12)
(cid:12)−

CAB
(cid:104)

1
ω(t)

(cid:18) β1(cid:126)ω1
2

3 ˙ω2
t
4ω(t)2 +

We estimate the energetic cost of the STA driving with
the time-averaged Schmidt norm of HSTA(t) [49, 50],
(cid:19) (cid:126)√3
4τ

¨ωt
2ω(t)
(5)
is obtained by switching the temperature and fre-
CCD
(cid:104)
quency β1, ω1 to β2, ω2, respectively, see Fig. 1. More
details are included in [45]. Below, we show that the
energetic cost, Eq. (5), preserves the physical (Carnot)
bound, which is missed by other suggested cost metrics.
Optimization procedure.– Our goal is to enhance the
ﬁgure of merit χ deﬁned as the product of the cooling
eﬃciency (cid:15) with the heat extracted per cycle, Jc,

(cid:105)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

.

Q4
(cid:104)
+

(cid:105)
CAB

χ

(cid:15)Jc =

≡

W1
(cid:104)

+

W3
(cid:104)

(cid:105)

(cid:104)
Motivated by Ref. [36], a possible way to boost the ﬁgure
of merit could be by using a polynomial ansatz, which by
construction satisﬁes the initial conditions of Eq. (2),

(cid:105)

(cid:105)

(cid:105)

+

CCD
(cid:104)

×

Q4
(cid:104)
2τ

. (6)

(cid:105)

ω(t) = ω1 + ∆ω

Nmax(cid:88)

n=3

αn

(cid:19)n

.

(cid:18) t
τ

(7)

ω1. A widely used ansatz which satisﬁes
Here, ∆ω = ω2
Eq. (2) consists of (α3, α4, α5) = (10,
15, 6) and all the
other α = 0, depicted as the dashed-dotted line in Fig. 2.
We use it throughout the paper as a benchmark.

−

−

The only quantity that depends on the transient val-
ues of ω(t) is the energetic cost function. Therefore, once
the physical parameters (βi, ωi) are set, the optimal cool-
[Eq. (5)].
ing protocol minimizes the energetic cost
Ci
(cid:105)
(cid:104)
Thus, we devise a cost function that includes
, along
Ci
(cid:105)
(cid:104)
with penalties for deviating from the STA constraints,
Eq. (2). Details are given in [45]. For generality, we
represent ω(t) as a neural network (NN) whose parame-
ters are optimized using automatic diﬀerentiation (AD),
which allows to compute exact gradients with respect to
the NN’s parameters. We use Adam [51], a ﬁrst-order
gradient-based optimization algorithm, to optimize our
objective function. This process is performed for a large
ensemble of 1000 initial conditions for the NN, out of
which the optimal strategies are selected.

FIG. 2. (a) Examples of frequency proﬁles ω(t) discovered by
the DP-ML scheme normalized by the compression or expan-
sion stroke duration τ . The gray dashed-dotted line displays
the polynomial ansatz, Eq. (7). The solid lines are the neu-
ral network results. The inset displays the ﬁrst and second
derivatives of ω(t) for one realization, showing compliance
with the STA conditions, Eq. (2). The fact that both deriva-
tives approximately follow each other allows for the minimiza-
tion of the energetic cost of the STA process (see Fig. 4). (b)
The function Ω(t) corresponding to the frequency of the eﬀec-
tive counterdiabatically-driven harmonic oscillator. Parame-
ters are ω1 = 0.1, ω2 = 0.5, β1 = 1 and β2 = 0.75.

Results.– Examples of optimal expansion proﬁles ω(t)
are depicted in Fig. 2; the compression stroke is a time-
t). We note that during our
reversed version of it, ω(τ
−
optimization process, which penalizes for deviations from
the initial and ﬁnal-time conditions, one ﬁnds local min-
ima in which the latter are not met. In order to satisfy
those, frequency proﬁles were stretched, in addition to
being smoothened in order to become physically realiz-
able [45]. In Fig. 2(a), we observe that optimal strategies
share a similar feature of a “late-bloomer”, hence they are

3

FIG. 3. Figure of merit of the Otto refrigerator χ, Eq. (6),
depicted as a function of the expansion or compression stroke
times τ for the frequency ramps ω(t) of Fig. 2. The gray
dashed-dotted line displays the polynomial ansatz, Eq. (7).
Solid lines represent NN results. For comparison, the nona-
diabatic sudden-frequency change, χNA, is plotted in light
orange. The NN optimization scheme almost doubles the ﬁg-
ure of merit—compared to the polynomial ansatz. The inset
shows the corresponding cooling eﬃciency and the ideal adi-
abatic limit, (cid:15)ad. The optimal NN strategies approach the
adiabatic eﬃciency faster than the polynomial benchmark.

very diﬀerent from the polynomial ansatz of Eq. (7) de-
picted as a dashed-dotted line in Fig. 2. The inset shows
the ﬁrst and second derivatives of one of these proﬁles.
The two derivatives rise together, which results in the
minimization of the energetic cost function as we discuss
in the next section. Fig. 2(b) displays the correspond-
ing frequency ramp, Ω(t), see text above Eq. (2). This
frequency would have to be followed in order to get the
exact same ﬁnal state as would be achieved by an adia-
batic driving, which follows ω(t).

In Fig. 3 we compare the ﬁgure of merit χ, Eq. (6),
from the diﬀerent strategies. Overall, we ﬁnd an almost
two-fold improvement of NN proﬁles over the benchmark.
The peak for the NN-based strategies occurs earlier than
for the polynomial, at around τ = 6. Further, we com-
pare these performances to the nonadiabatic, step func-
tion strategy [52]. As expected, the latter strategy could
be beneﬁcial for short stroke times, τ < 2, because the
energetic cost of maintaining STA is high. Yet, it is in-
ferior at longer cycles. We further plot the cooling eﬃ-
ciency, (cid:15), as a function of stroke duration (inset). The
black dashed line is the “ideal” adiabatic eﬃciency (cid:15)ad,
attain their
where the heat
adiabatic values and the associated driving energetic cost
is neglected (note that the relation to the Carnot cool-
ing eﬃciency is (cid:15)C
(cid:15)ad). NN-based strategies are able
to obtain a higher eﬃciency, and, in turn, similarly to
the polynomial benchmark, they approach the adiabatic
limit at large τ .

and work

W3
(cid:104)

Q4
(cid:104)

W1

,
(cid:105)

≥

(cid:105)

(cid:104)

(cid:105)

The cooling protocols minimize the cost metric.

In

0.00.51.0t/τ0.10.20.30.40.5ω(a)01t/τ0.000.02˙ω¨ω0.00.51.0t/τ0.10.20.30.40.5Ω(b)0510152025303540τ0.0000.0020.0040.0060.0080.010χχNAχPolynomialχNN040τ0.00.10.20.3(cid:15)ad(cid:15)NA(cid:15)Polynomial(cid:15)NNdeﬁnition recovers a positive value for the overall ener-
getic cost and an eﬃciency (cid:15)
(cid:15)C, in compliance with
thermodynamical laws.

≤

4

FIG. 5. Exemplifying the failure of the energetic cost deﬁni-
tion (cid:104)HSTA(cid:105). (a) Frequency ramp proﬁle, ω(t), optimized to
minimize (cid:104)HSTA(cid:105). The initial frequency ω1 is set at 0.34 such
that the sum of the average work needed for the expansion
and compression strokes, (cid:104)W1 + W3(cid:105), is relatively small. (b)
Instantaneous energetic cost as a function of time, ∂t(cid:104)CAB(cid:105)
of Eq. (5) (light line), and (cid:104)HSTA(cid:105), which is based on the
time-averaged mean STA driving (dark line). For the latter,
the overall input work plus energetic cost is negative, hence
unphysical.
In contrast, using (cid:104)C(t)(cid:105) as the energetic cost
yields the cooling eﬃciency (cid:15) = 0.47 < (cid:15)ad ≤ (cid:15)C = 3; τ = 4.8,
ω1 = 0.34, ω2 = 0.5, β1 = 1, β2 = 0.75.

Discussion.– We demonstrated the potential and ad-
vantage of NN combined with AD in the ﬁeld of quantum
control of ﬁnite-time thermodynamics. Our method al-
lowed to discover driving protocols of the strokes of an
Otto engine that perform twice as better compared to
previously-conceived solutions. This scheme was able to
ﬁnd a nontrivial family of functions in which the ﬁrst and
second derivatives follow each other; from our results we
conclude that it is a crucial property of the cost func-
tion. In [45] we discuss an attempt to optimize a simpler
ansatz, which can mimic the NN’s “late blooming” strat-
egy. Our conclusion is that NN-based results are diﬃcult
to generate with a simple analytical form. Furthermore,
employing the DP-ML optimization scheme enabled us to
uncover a ﬂaw in a previous deﬁnition for the cost of STA
driving.
In contrast, our modiﬁed deﬁnition,provided
physical results, which obeyed the Carnot bound on one
hand, and reached the adiabatic limit on the other hand.
We point out that among the plethora of energetic cost
metrics suggested in the literature [54, 57, 58] we do not
aim here to ﬁnd which one is the most appropriate. How-
ever, ML optimization naturally identiﬁed violations to
thermodynamical laws. Since our optimization method
is general, it can be easily turned to optimize other cost
functions and ﬁgures of merits with little eﬀort.

Our framework could be directly applied in other con-

FIG. 4. Mean instantaneous energetic cost of the STA drive
as a function of time, ∂t(cid:104)C(cid:105), deﬁned by the Schmidt norm of
HSTA(t), Eq. (5). The dashed line corresponds to the polyno-
mial ansatz, Eq. (7). Solid lines correspond to the optimized
NN of Figs. 2 and 3 with τ = 6.

(cid:104)

CAB

Fig. 4, we show the mean instantaneous energetic cost
of the STA drive as a function of time, ∂t
. The
(cid:105)
NN optimization is able to reduce the energetic cost by
a factor of two, compared to the polynomial ansatz. Re-
call that in Eq. (5) the ﬁrst and second derivative terms
appear with opposite signs. Hence, in order to reduce
the energetic cost one should envisage functions in which
both derivatives follow similar temporal features. This
is where the power of NN-based optimization techniques
come to play. The DP-ML method greatly reduces the
instantaneous cost by realizing functions with this prop-
erty (see inset in Fig. 2(a)).

Next, we discuss diﬀerent energetic cost metrics and
their adherence to thermodynamical principles. While
(5), previous studies suggested the
we employed Eq.
time-average of the mean STA driving,
=
1/τ (cid:82) τ
, as the energetic cost of STA [53–
55]. We show that this expression can lead to unphysi-
> 0, yet
cal results: The system is a refrigerator,
the total work plus associated STA cost are negative,
< 0, thus yielding a negative eﬃ-
W1 + W3
(cid:104)
ciency.

HSTA(t)
(cid:105)

HSTA
(cid:104)

HSTA
(cid:104)

0 dt
(cid:104)

Q4

+

(cid:105)

(cid:105)

(cid:104)

(cid:105)

(cid:105)

(cid:105)

and

Q4
(cid:104)

W1 + W3
(cid:104)

We compare cost metrics in Fig. 5. We use parameters
close to the edge of the cooling window (determined by
the condition β1ω1 < β2ω2, see Eq. (4)). This choice
leads to relatively small values of
,
(cid:105)
compared with parameters used in Fig. 2, and it allows
us to demonstrate the incentive for devising a diﬀerent
energetic cost function for STA protocols. NN optimiza-
tion with the cost metric
yields proﬁles that allow
HSTA
cooling, see Fig. 5 (a) for an example, yet give an overall
negative energetic cost; in Fig. 5(b) we show the instan-
, which is mostly negative.
taneous contribution ∂t
(cid:105)
In contrast, the metric
of Eq. (5) is positive through-
out. The cooling eﬃciency for these parameters becomes
energetic cost—which is unphys-
negative for the
ical: By ﬁne-tuning parameters, while maintaining the
cooling condition, one can achieve an eﬃciency that ex-
ceeds Carnot [56]. In contrast, the Schmidt norm-based

HSTA
(cid:104)
C
(cid:104)

HSTA

(cid:105)

(cid:104)

(cid:105)

(cid:105)

(cid:104)

01234567t0.000.010.020.030.04∂thCABi0.30.5ω(a)012345t−0.20.00.2Energeticcost∂thCABi∂thHSTAi(b)trol problems, such as entropy reduction in closed sys-
tems [59], dynamical decoherence control [60], steering
chemical reactions [61], and for the design of quantum
electronic and thermal machines [21]. We paved the way
for solving hard-constrained problems using state-of-the-
art ML tools, by orchestrating an objective as the mini-
mum of a cost function. More generally, our study shows
that ML has an advantage over standard theoretical tools
in designing quantum devices, thus making them favor-
able for an experimental realization.

Acknowledgments.– We acknowledge fruitful discus-
sions with Adolfo del Campo, Obinna Abah, Rodrigo
A. Vargas-Hern´andez, Junjie Liu and Aharon Brodutch.
The work of IK was supported by the Centre for Quan-
tum Information and Quantum Control (CQIQC) at the
University of Toronto. JC acknowledges support from
the Natural Sciences and Engineering Research Council
of Canada (NSERC), the Shared Hierarchical Academic
Research Computing Network (SHARCNET), Compute
Canada, Google Quantum Research Award, and the
Canadian Institute for Advanced Research (CIFAR) AI
chair program, and companies sponsoring the Vector In-
stitute. DS acknowledges support from an NSERC Dis-
covery Grant and the Canada Research Chair program.

[1] C. Lanczos, The Variational Principles of Mechanics

(University of Toronto Press, Toronto, 1970).

[2] A. Lipson, S. G. Lipson, and H. Lipson, Optical Physics

(Cambridge University Press, 2010), 4th ed.

[3] D. A. Fedorov, N. G. Bo Peng, and Y. Alexeev (2021),

2103.08505.

[4] J. Gemmer, M. Michel, and G. Mahler, Quantum thermo-
dynamics: Emergence of thermodynamic behavior within
composite quantum systems, vol. 784 (Springer, 2009).
[5] S. C. Kaushik, S. K. Tyagi, and P. Kumar, Finite
Time Thermodynamics of Power and Refrigeration Cy-
cles (Springer International Publishing, Cham, Switzer-
land, 2018).

[6] M. Esposito, R. Kawai, K. Lindenberg, and C. Van den
Broeck, Phys. Rev. Lett. 105, 150603 (2010), URL
https://link.aps.org/doi/10.1103/PhysRevLett.
105.150603.

[7] M. Esposito, R. Kawai, K. Lindenberg, and C. Van den
Broeck, EPL (Europhysics Letters) 89, 20003 (2010),
ISSN 1286-4854, URL http://dx.doi.org/10.1209/
0295-5075/89/20003.

[8] S. Deﬀner and S. Campbell, Quantum Thermodynamics,
2053-2571 (Morgan & Claypool Publishers, 2019), ISBN
978-1-64327-658-8.

[9] S. Bhattacharjee and A. Dutta (2020), 2008.07889.

[10] R. Kosloﬀ and A. Levy, Annual Review of Physical
Chemistry 65, 365 (2014), URL https://doi.org/10.
1146/annurev-physchem-040513-103724.

[11] S. Vinjanampathy and J. Anders, Contemporary Physics

57, 545 (2016).

[12] A. Das and V. Mukherjee, Phys. Rev. Research 2, 033083

(2020), ISSN 2643-1564.

5

[13] J. Klatzow, J. N. Becker, P. M. Ledingham, C. Weinzetl,
K. T. Kaczmarek, D. J. Saunders, J. Nunn,
I. A.
Walmsley, R. Uzdin, and E. Poem, Phys. Rev. Lett.
122, 110601 (2019), URL https://link.aps.org/doi/
10.1103/PhysRevLett.122.110601.

[14] R. B.

S, V. Mukherjee, U. Divakaran,

and
A. del Campo, Phys. Rev. Research 2,
043247
(2020), URL https://link.aps.org/doi/10.1103/
PhysRevResearch.2.043247.

[15] X. Chen, A. Ruschhaupt, S. Schmidt, A. del Campo,
D. Gu´ery-Odelin, and J. G. Muga, Phys. Rev. Lett.
104, 063002 (2010), URL https://link.aps.org/doi/
10.1103/PhysRevLett.104.063002.

[16] E. Torrontegui, S. Ib´a˜nez, S. Mart´ınez-Garaot, M. Mod-
ugno, A. del Campo, D. Gu´ery-Odelin, A. Ruschhaupt,
X. Chen, and J. G. Muga, Advances in Atomic,
Molecular, and Optical Physics p. 117–169 (2013),
ISSN 1049-250X, URL http://dx.doi.org/10.1016/
B978-0-12-408090-4.00002-5.

[17] X. Chen and J. G. Muga, Phys. Rev. A 82,
053403 (2010), URL https://link.aps.org/doi/10.
1103/PhysRevA.82.053403.

[18] J. G. Muga, X. Chen, S. Ib´a˜nez,

I. Lizuain, and
A. Ruschhaupt, Journal of Physics B: Atomic, Molec-
ular and Optical Physics 43, 085509 (2010), ISSN 1361-
6455, URL http://dx.doi.org/10.1088/0953-4075/
43/8/085509.

[19] Y.-Y. Cui, X. Chen, and J. G. Muga, The Journal of
Physical Chemistry A 120, 2962 (2016), URL https:
//doi.org/10.1021/acs.jpca.5b06090.

[20] O. Abah, J. Roßnagel, G. Jacob, S. Deﬀner, F. Schmidt-
Kaler, K. Singer, and E. Lutz, Phys. Rev. Lett. 109,
203006 (2012), URL https://link.aps.org/doi/10.
1103/PhysRevLett.109.203006.

[21] A. C. Santos and M. S. Sarandy, Scientiﬁc reports
5, 1 (2015), URL https://www.nature.com/articles/
srep15775.

[22] R. Kosloﬀ and Y. Rezek, Entropy 19, 136 (2017), URL

www.mdpi.com/journal/entropy.

[23] K. Funo, N. Lambert, B. Karimi, J. P. Pekola,
Y. Masuyama, and F. Nori, Phys. Rev. B 100,
035407 (2019), URL https://link.aps.org/doi/10.
1103/PhysRevB.100.035407.

[24] D. Gu´ery-Odelin, A. Ruschhaupt, A. Kiely, E. Tor-
rontegui, S. Mart´ınez-Garaot, and J. G. Muga, Rev.
Mod. Phys. 91, 045001 (2019), URL https://link.aps.
org/doi/10.1103/RevModPhys.91.045001.

[25] H. Zhou, Y. Ji, X. Nie, X. Yang, X. Chen,
J. Bian, and X. Peng, Phys. Rev. Applied 13,
044059 (2020), URL https://link.aps.org/doi/10.
1103/PhysRevApplied.13.044059.

[26] K. Ono, S. N. Shevchenko, T. Mori, S. Moriyama, and
F. Nori, Phys. Rev. Lett. 125, 166802 (2020), URL
https://link.aps.org/doi/10.1103/PhysRevLett.
125.166802.

[27] L. Dupays, D. C. Spierings, A. M. Steinberg, and A. del

Campo (2021), 2104.00999.

[28] A. A. Melnikov, H. Poulsen Nautrup, M. Krenn, V. Dun-
jko, M. Tiersch, A. Zeilinger, and H. J. Briegel, Pro-
ceedings of the National Academy of Sciences 115, 1221
(2018), ISSN 0027-8424, URL https://www.pnas.org/
content/115/6/1221.

[29] M. Bukov, A. G. R. Day, D. Sels, P. Weinberg,
A. Polkovnikov, and P. Mehta, Phys. Rev. X 8,

6

[49] Y. Zheng, S. Campbell, G. De Chiara, and D. Poletti,

Phys. Rev. A 94, 042132 (2016).

[50] S. Campbell and S. Deﬀner, Phys. Rev. Lett. 118, 100601

(2017).

[51] D. P. Kingma and J. Ba (2014), 1412.6980.
[52] We use the nonadiabatic parameter Q∗

NA = ω2

1 +ω2
2
2ω1ω2

, which

alters Eqs. (3) and (4) (see Refs. [20, 43] for details).
[53] O. Abah and E. Lutz, EPL 118, 40005 (2017),
https://iopscience.iop.

ISSN 12864854,
org/article/10.1209/0295-5075/118/40005https:
//iopscience.iop.org/article/10.1209/0295-5075/
118/40005/meta.

URL

[54] O. Abah and M. Paternostro, Phys. Rev. E 99, 1 (2019),

ISSN 24700053.

[55] O. Abah, M. Paternostro, and E. Lutz, Phys. Rev.
Research 2, 023120 (2020),
ISSN 2643-1564, URL
https://journals.aps.org/prresearch/abstract/10.
1103/PhysRevResearch.2.023120.

[56] Criticism to this approach, albeit from a diﬀerent aspect,

were raised in Ref. [10].

[57] A. Del Campo, J. Goold, and M. Paternostro, Scientiﬁc

Reports 4, 1 (2014), ISSN 20452322.

[58] K. Funo, J.-N. Zhang, C. Chatou, K. Kim, M. Ueda,
and A. del Campo, Phys. Rev. Lett. 118, 100602
(2017), URL https://link.aps.org/doi/10.1103/
PhysRevLett.118.100602.

[59] P. Sgroi, G. M. Palma, and M. Paternostro, Phys. Rev.
Lett. 126, 020601 (2021), URL https://link.aps.org/
doi/10.1103/PhysRevLett.126.020601.

[60] R. Porotti, D. Tamascelli, M. Restelli, and E. Prati,
Communications Physics 2 (2019), ISSN 2399-3650, URL
http://dx.doi.org/10.1038/s42005-019-0169-x.
[61] A. F. de Almeida, R. Moreira, and T. Rodrigues, Nature

Reviews Chemistry 3, 589 (2019).

031086 (2018), URL https://link.aps.org/doi/10.
1103/PhysRevX.8.031086.

[30] J. Walln¨ofer, A. A. Melnikov, W. D¨ur, and H. J. Briegel,
PRX Quantum 1, 010301 (2020), URL https://link.
aps.org/doi/10.1103/PRXQuantum.1.010301.

[31] C. Beeler, U. Yahorau, R. Coles, K. Mills, S. White-
lam, and I. Tamblyn, Optimizing thermodynamic tra-
jectories using evolutionary and gradient-based reinforce-
ment learning, 1903.08543.

[32] A. Jasinski, J. Montaner, R. C. Forrey, B. H. Yang,
P. C. Stancil, N. Balakrishnan, J. Dai, R. A. Vargas-
Hern´andez, and R. V. Krems, Phys. Rev. Research
2, 032051 (2020), URL https://link.aps.org/doi/10.
1103/PhysRevResearch.2.032051.

[33] J. Carrasquilla, Advances in Physics: X 5, 1797528
(2020), URL https://doi.org/10.1080/23746149.
2020.1797528.

[34] A. G. Baydin, B. A. Pearlmutter, A. A. Radul, and
J. M. Siskind, Journal of Machine Learning Research 18,
1 (2018), URL http://jmlr.org/papers/v18/17-468.
html.

[35] F. Sch¨afer, M. Kloc, C. Bruder, and N. L¨orch, Machine
Learning: Science and Technology 1, 035009 (2020),
ISSN 2632-2153.

[36] A. del Campo, Phys. Rev. Lett. 111, 100502 (2013), URL
https://link.aps.org/doi/10.1103/PhysRevLett.
111.100502.

[37] M. Beau, J. Jaramillo, and A. Del Campo, Entropy 18,

168 (2016).

[38] L. Coopmans, D. Luo, G. Kells, B. K. Clark, and J. Car-
rasquilla, PRX Quantum 2, 020332 (2021), URL https:
//link.aps.org/doi/10.1103/PRXQuantum.2.020332.

[39] J. Roßnagel, O. Abah, F. Schmidt-Kaler, K. Singer, and
E. Lutz, Phys. Rev. Lett. 112, 030602 (2014), URL
https://link.aps.org/doi/10.1103/PhysRevLett.
112.030602.

[40] J. Roßnagel, S. T. Dawkins, K. N. Tolazzi, O. Abah,
E. Lutz, F. Schmidt-Kaler, and K. Singer, Science 352,
325 (2016), ISSN 0036-8075, URL https://science.
sciencemag.org/content/352/6283/325.

[41] Y. Rezek and R. Kosloﬀ, New Journal of Physics 8, 83
(2006), URL https://doi.org/10.1088/1367-2630/8/
5/083.

[42] Y. Rezek, P. Salamon, K. H. Hoﬀmann, and R. Kosloﬀ,
EPL (Europhysics Letters) 85, 30008 (2009), URL
https://doi.org/10.1209/0295-5075/85/30008.
[43] O. Abah and E. Lutz, EPL 113, 60002 (2016), ISSN

12864854, URL www.epljournal.org.

[44] M. V. Berry, Journal of Physics A: Mathematical and
Theoretical 42, 365303 (2009), URL https://doi.org/
10.1088/1751-8113/42/36/365303.

[45] See Supplemental Material at [URL will be inserted by

publisher].

[46] O. Abah and E. Lutz, Phys. Rev. E 98, 032121 (2018),
URL https://link.aps.org/doi/10.1103/PhysRevE.
98.032121.

[47] K. Husimi, Progress of Theoretical Physics 9, 381 (1953),
ISSN 0033-068X, URL https://doi.org/10.1143/ptp/
9.4.381.

[48] M. A. Lohe, Journal of Physics A: Mathematical
ISSN 17518113,
and Theoretical 42, 35307 (2009),
URL https://iopscience.iop.org/article/10.1088/
1751-8113/42/3/035307https://iopscience.iop.org/
article/10.1088/1751-8113/42/3/035307/meta.

Supplemental Material: Optimal control of quantum thermal machines using machine learning

7

Derivation of the energetic cost proxy

For completeness we derive the modiﬁed Hamiltonian under local counterdiabatic (LCD) driving bellow. The

original driven Hamiltonian, H0(t), and the counterdiabatic term, HCD(t), are given explicitly by

H0(t) =

p2
2m

+

mx2ω(t)2
2

,

HCD(t) =

˙ω(t)
4ω(t)

−

(xp + px) .

The LCD Hamiltonian is

HLCD(t) = U †
x

(cid:16)

(cid:34)

= U †
x

H0(t) + HCD(t)

i(cid:126) ˙UxU †
x

(cid:17)

Ux

−

p2
2m

+

mx2ω(t)2
2

˙ω(t)
4ω(t)

−

(xp + px) +

(cid:18)

mx2
4ω(t)

¨ωt

−

˙ω2
t
ω(t)

(cid:19)(cid:21)

Ux,

(S1)

(S2)

where Ux = ei mx2 ˙ωt
counterdiabatic term HCD(t). Applying Ux leads to

4(cid:126)ω(t)

is a time-dependent, local operator which is in charge of eliminating the x, p coupling due to the

(cid:18)

=

HLCD(t) = H0(t) + HSTA(t)
p2
2m
p2
2m

mx2
2
mx2
2

+

+

=

Ω(t)2.

ω(t)2

3 ˙ω2
t
4ω(t)2 +

¨ωt
2ω(t)

−

(cid:19)

Here, Ω(t)2
with compression or expansion stroke time τ .

3 ˙ω2
4ω(t)2 + ¨ωt
t

ω(t)2

≡

−

2ω(t) . Naturally, a trap inversion condition follows our deﬁnition of Ω

Following Refs. [49, 50] we utilize Schmidt norm of the additional STA term, HSTA(t) = HLCD(t)

as a proxy to the energetic cost of the LCD drive,

(S3)

0 for t

[0, τ ],

∈

H0(t) to serve

≥

−

C
(cid:104)

.
(cid:105)

dt
(cid:107)

HSTA(t)
(cid:107)

C

(cid:104)

(cid:105) ≡

=

1
τ
m
2

(cid:90) τ

0
1
τ

(cid:90) τ

0

(cid:113)

dt

x4

LCD
t
(cid:105)

(cid:104)

(cid:12)
(cid:12)
(cid:12)
(cid:12)−

3 ˙ω2
t
4ω(t)2 +

¨ωt
2ω(t)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

.

(S4)

(cid:0)6n2 + 6n + 3(cid:1). Therefore, for a harmonic oscillator

, (cid:10)n(cid:12)
(cid:12)x4(cid:12)
For an eigenstate of a harmonic oscillator,
in a canonical thermal state given by ρth = (cid:80)∞
n=0 pn

n
(cid:105)

|

(cid:12)n(cid:11) = (cid:126)2
n
n
|

|

(cid:105)(cid:104)
3(cid:126)2
4m2ω2

4m2ω2
with pn = e−βEn
Z ,

(cid:20)

coth

(cid:18) β(cid:126)ω
2

(cid:19)(cid:21)2

.

Tr[ρthx4] =

Following Ref. [37] we can now evaluate this expectation value for the LCD state,

(cid:10)ΨLCD

x,t

(cid:12)
(cid:12)x4(cid:12)

(cid:12)ΨLCD
x,t

(cid:11) =

(cid:28)

ΨCD
x,t

2(cid:126)bad x4ei mx2 ˙bad

2(cid:126)bad

(cid:29)

ΨCD
x,t

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
e−i mx2 ˙bad
(cid:12)
(cid:12)
(cid:12)
(cid:12)x4(cid:12)
(cid:12)
(cid:11)

(cid:12)ΨCD
x,t
(cid:12)
(cid:12)

,t=0

Ψ x
bad

= (cid:10)ΨCD
x,t
(cid:68)
1
bad

=

(cid:12)x4(cid:12)

(cid:12)
(cid:12)Ψ x

bad

(cid:69)

,t=0

= b4
ad

(cid:126)2
4m2ω2
i

(cid:0)6n2 + 6n + 3(cid:1) .

(S5)

(S6)

8

FIG. S1. A schematic of a diﬀerent ansatz. We display the bare function, which contains discontinuities in its derivatives
(dashed-blue) and its smoothed interpolated counterpart (full-orange). This ansatz utilizes a mostly ﬂat region where both
derivatives of ω(t) vanish, separated by a linear ramp in the time domain t ∈ [t1, t2]. The smoothed ansatz contains two regions
of width σ around t = t1, t2. At the edges of these regions the smoothened function and its derivatives match the original
(dashed) function.

Averaging with respect to the thermal state we get

(cid:10)x4(cid:11)LCD

t

= b4
ad

3(cid:126)2
4m2ω2
i

(cid:20)

coth

(cid:18) βi(cid:126)ωi
2

(cid:19)(cid:21)2

,

(S7)

where we used Eq. (S5) in the last step, and with bad(t) = (cid:112)ωi/ω(t); ωi and βi are the initial-time frequency and
inverse temperatures (depending on the stroke). Plugging this expression back into Eq. (S4) yields the expression for
the energetic cost,

=

Ci
(cid:104)

(cid:105)

(cid:126)√3
4

= coth

dt

0

(cid:90) τ

1
τ
(cid:18) βi(cid:126)ωi
2

coth

b2
ad
ωi
(cid:19) (cid:126)√3

(cid:18) βi(cid:126)ωi
2

(cid:90) τ

dt

(cid:19) (cid:12)
(cid:12)
(cid:12)
(cid:12)−
(cid:12)
(cid:12)
(cid:12)
(cid:12)−

3 ˙ω2
t
4ω(t)2 +
3 ˙ω2
t
4ω(t)2 +

1
ω(t)

4τ ×

0

¨ωt
2ω(t)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

¨ωt
2ω(t)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

.

The total energetic cost of the STA is the sum of two terms corresponding to the two strokes:

(S8)

=

C
(cid:104)

(cid:105)

(cid:104)

CAB

+

(cid:105)

(cid:104)

CCD

.
(cid:105)

Additional ansatz

By examining the STA energetic cost function in Eq. (S4), one might suggest the following ansatz for minimizing the
cost, which is depicted in Fig. S1. This function is made of a mostly ﬂat region where both derivatives of ω(t) vanish.
[t1, t2]. This kind of function is shown in dashed-blue.
These domains are separated by a linear ramp at times t
In order to avoid discontinuities in the derivatives of ω(t) one can smooth this function at some times of range σ,
ﬁxing the values of the interpolated function and its two derivatives on both edges of the region to match those of the
original function. This interpolation is solved by a set of linear equations, and is shown in full line. Note that this
type of function allows for a “late bloomer” strategy that the Neural Network (NN) method discovered as optimal.

∈

Next, we turn to ﬁnd the optimal values of this suggested function in terms of the energetic cost function by
examining the three dimensional space (t1, t2, σ). We ﬁnd that the optimal solution for this ansatz is very similar
to the polynomial ansatz (main text). Although the present family of functions allows for diﬀerent proﬁles than the
polynomial ansatz, it is limited to a set of somewhat trivial functions, which cannot fully minimize the integrand of
the cost function. As a result, these functions do not allow for a behavior as well-captured by the NN, i.e. a function
in which both derivatives follow each other. In fact, using this ansatz and mimicking a “late blooming” strategy with
a large t1 is energetically disadvantageous.

0.00.20.40.60.81.0t/τ0.100.150.200.250.300.350.400.450.50ωt1t2σσNeural network optimization

9

Our NN is has a single input of time, t. It is passed through a “polynomial layer”, in which a polynomial in the
form of Eq. (7) (Main text) with Nmax = 10 is generated. This function is fed into three layers of 100 neurons with
a sigmoid activation function followed by one output neuron with a sigmoid activation function. The intermediate,
polynomial basis layer was found to assist in reaching a faster convergence, with practically no dependence on Nmax.
We apply our optimization scheme onto the following cost function

CF (θ) =

CAB (ω(t), ˙ω(t), ¨ω(t))

ω(0)

(cid:104)
+ Pω(0) |
+ P¨ω(0) |
+ P ˙ω(τ ) |
+ P∆ω ReLU(ω(0)

¨ω(0)
|
˙ω(τ )

ω1
−
|
+ Pω(τ ) |
+ P¨ω(τ )

|

(cid:105)
+ P ˙ω(0) |
ω(τ )
−

˙ω(0)
|
ω2

|

¨ω(τ )
|

ω(τ )),

−

|

(S9)

where θ are the NN parameters, and ReLU is a rectiﬁed linear unit. The ﬁrst term in the above is the STA energetic
cost, appearing in Eq. (S4) for the expansion cycle AB (See Fig. 1 Main text). The next six terms correspond to
the six STA requirements in Eq. (2) of the Main text. The last term in Eq. (S9) penalizes a situation in which
ω(τ )

ω(0) < 0 that we found to occur sometimes.

We start with random initial network parameters, θ, and run the ﬁrst (out of four) stochastic gradient descent
passes of 1000 steps with a large value of P∆ω and relatively low values for the other P s. We choose the parameters
that yield the lowest cost function value along the pass, and use those for the next step. For the next passes, we
gradually increase the values of all the P s but P∆ω, which is annualized for the ﬁnal pass.

−

