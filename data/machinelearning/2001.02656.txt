0
2
0
2

n
a
J

2
2

]
L
M

.
t
a
t
s
[

3
v
6
5
6
2
0
.
1
0
0
2
:
v
i
X
r
a

Stochastic Probabilistic Programs

DAVID TOLPIN, Ben-Gurion University of the Negev, Israel and PUB+
TOMER DOBKIN, Ben-Gurion University of the Negev, Israel

We introduce the notion of a stochastic probabilistic program and present a reference implementation of a
probabilistic programming facility supporting speciﬁcation of stochastic probabilistic programs and infer-
ence in them. Stochastic probabilistic programs allow straightforward speciﬁcation and eﬃcient inference in
models with nuisance parameters, noise, and nondeterminism. We give several examples of stochastic prob-
abilistic programs, and compare the programs with corresponding deterministic probabilistic programs in
terms of model speciﬁcation and inference. We conclude with discussion of open research topics and related
work.

1 INTRODUCTION
Perhaps somewhat counterintuitively, most probabilistic programs are deterministic. The prop-
erty that distinguishes a probabilistic program is that a probabilistic program computes the (un-
normalized) probability of its execution [13]. An execution is summarized as an instantiation of
the program trace, and the probability is a function of the trace. Some probabilistic programming
frameworks require that the trace shape is speciﬁed upfront [2, 10], others allow introduction of
trace components dynamically [4, 6–8, 11], in the course of a program execution.

A probabilistic programming framework passes the probabilistic program as an argument to an
inference algorithm. The algorithm may collect any program output for later summarization, but
otherwise ignores the output and uses only the trace probability for inference. In some probabilistic
programming languages the locations where the probability is computed are syntactically explicit,
and inference algorithms may exploit the program structure. For example, in Stan [2] operator ∼
and an increment of variable target update the trace probability; in Anglican [11], both sample
and observe update the trace probability, in addition, sample adds a component to the trace; but
neither ∼ nor sample introduce randomness in the computation of probability.

However, stochastic computation of trace probability naturally comes up in at least two diﬀer-
ent contexts. In one context, nuisance parameters must be marginalized: instead of inferring the
posterior distribution over both parameters of interest and nuisance parameters, and marginaliz-
ing over a representation of the posterior (for example, by summing up samples in Monte Carlo
approximations), the program can compute the execution probability stochastically by sampling
nuisance parameters, and perform marginalization during inference. For example, stochastic com-
putation can be used to represent ﬂipping a coin with an unobserved outcome. The other context
is the handling of nondeterminism, where the posterior distribution of the trace should be inferred
under any outcome of non-deterministic choices following a certain distribution, such as for pol-
icy learning in stochastic domains [12]. These two contexts admit diﬀerent inference schemes,
but both involve stochastic computation of trace probability and would beneﬁt from consistent
representation in probabilistic programs.

In this work, we formally deﬁne a stochastic probabilistic program (Section 2) and then intro-
duce inference schemes for both marginalization and nondeterminism (Section 3). We present a
reference implementation of probabilistic programming facility that support stochastic probabilis-
tic programs and show that such programs can be supported with little extra eﬀort compared to
traditional, deterministic probabilistic programs (Section 4). In case studies (Section 5), we imple-
ment benchmark problems from the literature as stochastic probabilistic programs and compare
both speciﬁcation of the programs and inference in them to deterministic implementations. We
also bring examples of models which are naturally represented as stochastic probabilistic programs

1

 
 
 
 
 
 
David Tolpin and Tomer Dobkin

but are diﬃcult to implement without introducing stochasticity. Probabilistic program examples in
Sections 2–3 are in a subset of the Go programming language [5], but should be legible for readers
who are not familiar with Go.

Contributions. This work brings the following contributions:

• deﬁnition of a stochastic probabilistic program;
• posterior inference on stochastic probabilistic programs for marginalization and nondeter-

minism;

• a reference implementation of probabilistic programming with support for stochastic prob-

abilistic programs.

Notation. We denote by p(xxx) the probability or probability density of random variable xxx, and by
p(xxx |yyy) the conditional probability or probability density of xxx given yyy, depending on the domain
of xxx. We write xxx ∼ p(·) when xxx is a random variable with probability p(·). We denote by ˜p(·) a
probability known up to a normalization constant (unnormalized probability).

2 A STOCHASTIC PROBABILISTIC PROGRAM

Diﬀerent deﬁnitions of (deterministic) probabilistic programs are given in the literature and reﬂect
diﬀerent views and accents. For the purpose of this work, let us give the following broad deﬁnition:

Deﬁnition 1. A deterministic probabilistic program Π that deﬁnes a distribution over traces p(xxx |yyy)
is a computer program that accepts a trace assignment xxx as one of its arguments, and returns the
unnormalized probability of xxx conditioned on other arguments yyy:

Π(xxx,yyy) ⇒ ˜p(xxx |yyy).

(1)

The trace assignment xxx may have the form of a vector, or of a list of address-value pairs, or
any other form suitable for a particular implementation. Accordingly, let us deﬁne a stochastic
probabilistic program:

Deﬁnition 2. A stochastic probabilistic program Ξ that deﬁnes a distribution over traces p(xxx |yyy) is
a computer program that accepts a trace assignment xxx as one of its arguments, and returns the un-
normalized probability of xxx conditioned on other arguments yyy and random variable zzz conditioned
on yyy:

zzz ∼ p(zzz|yyy)
Ξ(xxx,yyy) ⇒ ˜p(xxx |yyy,zzz).

(2)

A rationale for this deﬁnition is that zzz corresponds to nuisance parameters or nondeterministic

choices inside the program. Let us illustrate a stochastic probabilistic program on an example:

Example 1. A survey is conducted among company’s employees. The survey contains a single
question: "Are you satisﬁed with your compensation?" To preserve employees’ privacy, the em-
ployee ﬂips a coin before answering the question. If the coin shows head, the employee answers
honestly; otherwise, the employee ﬂips a coin again, and answers ’yes’ on head, ’no’ on tail. Based
on survey outcomes, we want to know how many of the employees are satisﬁed with their com-
pensations.

2

Stochastic Probabilistic Programs

prob := Beta(1, 1).pdf(theta)
for i := 0; i != len(y); i++ {

coin := Bernoulli(0.5).sample()
if coin {

1 func Survey(theta float, y []bool) float {
2
3
4
5
6
7
8
9
10
11
12 }

}
return prob

} else {

}

prob *= Bernoulli(0.5).cdf(y[i])

prob *= Bernoulli(theta).cdf(y[i])

Fig. 1. A probabilistic program for the compensation survey. Nuisance variable coin makes the program
stochastic.

prob := Beta(1, 1).pdf(theta)
for i := 0; i != len(y); i++ {

1 func Survey(theta float, y []bool) float {
2
3
4
5
6
7 }

}
return prob

prob *= 0.5*Bernoulli(theta).cdf(y[i]) + 0.5*Bernoulli(0.5).cdf(y[i])

Fig. 2. A deterministic probabilistic program for the compensation survey. The probability is marginalized
over the coin flip in the code of the program.

Stochastic probabilistic program. The stochastic probabilistic program modelling the survey (Fig-
ure 1) receives two parameters: probability theta that a randomly chosen employee is satisﬁed
with the compensation and vector y of boolean survey outcomes. The program trace consists of
a single variable theta. There are nuisance random variables coin representing point ﬂips which
are sampled inside the program from their prior distribution, but are not included in the trace —
this makes the probabilistic program stochastic. The unnormalized probability of the trace is accu-
mulated in variable prob. First, a Beta prior is imposed on theta (line 2). Then, prob is multiplied
by the probability of each answer given theta and coin (lines 5–9).

Manual marginalization. The program in Figure 1 can be rewritten as a deterministic probabilis-
tic program (Figure 2). Instead of ﬂipping a coin as in line 4 of the stochastic program in Figure 1,
the probability of observation y[i] is computed in lines 5–6 as the sum of probabilities given either
head or tail, weighted by the probabilities of head and tail (both are 0.5). Due to explicit marginal-
ization, the generative structure of the program becomes less obvious, but one can still argue that
a stochastic probabilistic program can be straightforwardly reduced to a deterministic one. It is
though easy to imagine a problem that is almost as simple as in the example but for which manual
marginalization is not possible. Imagine that the distribution of coin ﬂip outcomes is not known
but obtained from a black-box source. The survey still can be conducted, as long as the source is
stationary, if the probability of each outcome is unknown and even if consequent coin ﬂips are not
independent, by replacing line 4 in Figure 1 by

4

coin := Coins.sample()

3

David Tolpin and Tomer Dobkin

1 func Ball(alpha float, L float) float {
2
3
4
5
6
7 }

prob := Normal(Pi/4, Pi/8).pdf(alpha)
v := D.sample()
d := v*v/g*sin(2*alpha)
prob *= Normal(L, 1).pdf(d)
return prob

Fig. 3. Probabilistic program for inferring the throw angle.

where Coins is a black-box random source. However, after such modiﬁcation the program code
cannot be marginalized, and there is no obvious deterministic equivalent of the stochastic proba-
bilistic program. Worse yet, even if all instantiations of coin are included in the trace, making the
trace 1+len(y)-dimensional, inference cannot be performed on the resulting deterministic proba-
bilistic program because the probability of a coin ﬂip outcome with respect to the random source
Coins is unknown. Meanwhile, the stochastic probabilistic program constitutes a valid inference
model, as we show in the following sections.

3 INFERENCE IN STOCHASTIC PROBABILISTIC PROGRAMS

A stochastic probabilistic program of the same shape may appear in two diﬀerent contexts. In
one context, like in Example 1, stochasticity models nuisance parameters, such as latent noise,
and the posterior distribution of the trace is marginalized over the nuisance parameters. In the
other context, stochasticity models nondeterminism, and the posterior distribution of the trace is
inferred in expectation over all possible outcomes of nondeterministic choices. As an illustration
of the latter context, consider the following example:

Example 2. A player throws a ball into the basket at distance D. Knowing that the initial velocity
v of the ball varies with a known distribution D, at which angle α should the player throw the ball
to hit the basket?

For simplicity, let’s assume that the player’s hands and the basket are at the same level and that
air drag can be ignored. Then, for given α and v the ﬁnal distance d of the ball at the basket level
is:

sin 2α

d = v cos α

2v sin α
д
where д is the acceleration of gravity. The corresponding stochastic probabilistic program is shown
in Figure 3. In the program code, Pi denotes constant π = 3.1415926... and g is the acceleration of
gravity д = 9.80665. Note that the question we want to answer with this probabilistic program is
diﬀerent from just inferring the posterior distribution of α conditioned on observation d = L, with
v as a nuisance parameter (which would be the case if one observed the ball falling at distance L).
To model nondeterminism, one needs to ‘cut’ the dependency between the distribution of v and
the observation, and infer α for all v drawn from D.

= v 2
д

(3)

In the rest of the section, we describe posterior inference for both contexts. We limit analysis
to the case of xxx ∈ Rn and pF (xxx |yyy,zzz) diﬀerentiable by xxx. We represent the posterior inference as
the problem of drawing samples from posterior distribution p(xxx |yyy) given unnormalized probabil-
ity density ˜p(xxx |yyy,zzz) and a random source of zzz. In either context, the inference can be based on
stochastic gradient Hamiltonian Monte Carlo (sgHMC) [3], but diﬀers in the way the stochastic
gradient is computed. Similarly, maximum a posteriori estimation can be performed using a sto-
chastic gradient optimization algorithm [9].

4

Stochastic Probabilistic Programs

3.1 Marginalization
The unnormalized probability density ˜p(xxx |yyy) is a marginalization of ˜p(xxx |yyy,zzz) over zzz:

Posterior inference and maximum a posteriori estimation require a stochastic estimate of ∇xxx log ˜p(xxx |yyy):

˜p(xxx |yyy) =

∫z

p(zzz|yyy) ˜p(xxx |yyy,zzz)dzzz

(4)

∇xxx log ˜p(xxx |yyy) =

z p(zzz|yyy) ˜p(xxx |yyy,zzz)∇x log ˜p(xxx |yyy,zzz)dzzz
∫
˜p(xxx |yyy)

p(zzz|yyy)

˜p(xxx |yyy,zzz)
˜p(xxx |yyy)

∇x log ˜p(xxx |yyy,zzz)dzzz =

p(xxx |yyy,zzz)p(zzz|yyy)
p(xxx |yyy)

∫z

∇x log ˜p(xxx |yyy,zzz)dzzz

p(zzz|xxx,yyy)∇x log ˜p(xxx |yyy,zzz)dzzz

=

=

∫z

∫z

By Monte Carlo approximation,

zzzi ∼ p(zzz|xxx,yyy)

∇xxx log ˜p(xxx |yyy) ≈

N

∇x log ˜p(xxx |yyy,zzzi )

1
N

Õi =1
Draws of zzzi are conditioned on xxx and can be approximated by a Monte Carlo method, such as
Markov chain Monte Carlo; p(zzz|yyy) need not be known for the approximation. Note that there are
two Monte Carlo approximations involved:

(1) gradient ∇x log ˜p(xxx |yyy) is approximated by a ﬁnite sum of gradients ∇x log ˜p(xxx |yyy,zizizi );
(2) draws of zzzi from p(zzz|xxx,yyy) are approximated.
An intuition behind estimate (6) is that for marginalization, assignments to nuisance parameters

which make the trace assignment more likely contribute more to the gradient estimate.

3.2 Nondeterminism

When a stochastic probabilistic program is used to represent nondeterminism, the posterior infer-
ence is performed with respect to all possible instantiations of zzz in (2) (rather than any instan-
tiation, as in the case of marginalization). Thus, ˜p(xxx |yyy) is a geometric integral of p(xxx |yyy,zzz) over
zzz:

˜p(xxx |yyy) =

˜p(xxx |yyy,zzz)p(zzz |yyy)dz = exp

Özzz

p(zzz|yyy) log ˜p(xxx |yyy,zzz)dz

(cid:19)

(cid:18)∫zzz

(7)

Again, posterior inference and maximum a posteriori estimation require a stochastic estimate of
∇xxx log ˜p(xxx |yyy):

By Monte Carlo approximation,

∇x log ˜p(xxx |yyy) =

∫zzz

p(zzz|yyy)∇x log ˜p(xxx |yyy,zzz)dzzz

zzzi ∼ p(zzz|yyy)
N

1
N

∇xxx log ˜p(xxx |yyy) ≈

∇xxx log ˜p(xxx |yyy,zizizi )

Õi =1
Unlike in the marginalization context,zzzi are drawn from the prior distribution ofzzz. Here too, p(zzz|yyy)
need not be known.

The case of nondeterminism bears similarity to the setting for which sgHMC was introduced —
posterior inference on large or streaming data, equation (5) in [3]. A diﬀerence is that in [3], the

5

(5)

(6)

(8)

(9)

David Tolpin and Tomer Dobkin

gradient scales up with the data size, and the inﬂuence of the prior distribution of xxx vanishes as
the data size grows. In the nondeterminism setting, the expectation of the gradient estimate (9)
remains the same independently of the number of Monte Carlo samples.

4 IMPLEMENTATION

We implemented inference in stochastic probabilistic programs using Infergo [10]. Thanks to re-
liance of Infergo on pure Go code for probabilistic programs, no changes were necessary to the
way probabilistic programs are represented — it is suﬃcient just to draw samples from a random
number generator provided by one of Go libraries, for example, the standard library or Gonum [1].

Implementations of sgHMC variants for case studies in this paper are available at http://bitbucket.org/dtolpin/spp-studies

and will be included in a future version of Infergo.

5 CASE STUDIES
We evaluated inference in stochastic probabilistic programs on several models. In each evalua-
tion, we speciﬁed two models: a stochastic model and a corresponding deterministic model. Infer-
ence on stochastic models was performed using either sgHMC for nondeterminism, or MHMC,
a variant of sgHMC with the gradient computed as in (6), for marginalization; HMC was used
on deterministic models. In each of the case studies we checked that stochastic and determinis-
tic models yield consistent results. The probabilistic programs used in case studies are available at
http://bitbucket.org/dtolpin/spp-studies. In the appendix, we provide the source code of stochastic
and deterministic probabilistic programs for three studies:

• compensation survey (Example 1);
• ball throw (Example 2);
• Gaussian mixture model.

6 DISCUSSION
In this paper, we introduced the notion of a stochastic probabilistic program and inference schemes
for the contexts of marginalization and nondeterminism, in which stochastic probabilistic pro-
grams come up. Stochastic probabilistic programs facilitate natural speciﬁcation of probabilistic
models, and support inference in the models, for which deterministic probabilistic programs are
impossible or diﬃcult to write. We focused our analysis on the case of diﬀerentiable probabilistic
programs with a real-valued parameter vector, however this is not a limitation in general — sto-
chastic probabilistic programs can be speciﬁed for support of any type, albeit diﬀerent inference
algorithms may be required.

Our understanding of stochastic probabilistic programs, classes of models for which they are
best suited, and inference schemes is still at an early stage and evolving. In particular, we are work-
ing, towards future publications, on the analysis of stochastic gradient estimate for the marginal-
ization context. Another research direction worth exploring is programmatic transformation of
stochastic probabilistic programs into deterministic ones when the latter exist. Such transforma-
tion would allow specifying models as stochastic probabilistic programs where such representation
is natural but applying eﬃcient and well developed inference techniques for deterministic proba-
bilistic programs on transformed representations. Last but not least, we are looking into introduc-
ing stochastic probabilistic program support into existing probabilistic programming frameworks,
through transformation to deterministic probabilistic programs or by extending the frameworks.

7 ACKNOWLEDGEMENTS

Development of Infergo is supported by PUB+, http://pubplus.com/.

6

Stochastic Probabilistic Programs

REFERENCES
[1] Gonum authors. 2017. Gonum numerical packages. http://gonum.org/.
[2] Bob Carpenter, Andrew Gelman, Matthew Hoﬀman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus Brubaker,
Jiqiang Guo, Peter Li, and Allen Riddell. 2017. Stan: a probabilistic programming language. Journal of Statistical
Software, Articles 76, 1 (2017), 1–32.

[3] Tianqi Chen, Emily B. Fox, and Carlos Guestrin. 2014. Stochastic Gradient Hamiltonian Monte Carlo. In Proceedings
of the 31st International Conference on International Conference on Machine Learning (ICML’14). JMLR.org, II–1683–II–
1691.

[4] Hong Ge, Kai Xu, and Zoubin Ghahramani. 2018. Turing: composable inference for probabilistic programming. In
International Conference on Artiﬁcial Intelligence and Statistics, AISTATS 2018, 9-11 April 2018, Playa Blanca, Lanzarote,
Canary Islands, Spain. 1682–1690.

[5] The Go team. 2009. The Go programming language. http://golang.org/.
[6] Noah D. Goodman, Vikash K. Mansinghka, Daniel M. Roy, Keith Bonawitz, and Joshua B. Tenenbaum. 2008. Church:

a language for generative models. In Proc. of Uncertainty in Artiﬁcial Intelligence.

[7] N. D. Goodman and A. Stuhlmüller. 2014. The Design and Implementation of Probabilistic Programming Languages.

http://dippl.org/ electronic; retrieved 2019/3/29.

[8] Avi Pfeﬀer. 2009. Figaro: An Object-Oriented Probabilistic Programming Language. In Charles River Analytics Tech-

nical Report (2009).

[9] Sebastian Ruder. 2016. An overview of gradient descent optimization algorithms. arXiv:1609.04747
[10] David Tolpin. 2019. Deployable Probabilistic Programming. In Proceedings of the 2019 ACM SIGPLAN International
Symposium on New Ideas, New Paradigms, and Reﬂections on Programming and Software (Onward! 2019). ACM, New
York, NY, USA, 1–16.

[11] David Tolpin, Jan-Willem van de Meent, Hongseok Yang, and Frank Wood. 2016. Design and implementation of prob-
abilistic programming language Anglican. In Proceedings of the 28th Symposium on the Implementation and Application
of Functional Programming Languages (IFL 2016). ACM, New York, NY, USA, Article 6, 12 pages.

[12] Jan-Willem van de Meent, Brooks Paige, David Tolpin, and Frank Wood. 2016. Black-box policy search with proba-
bilistic programs. In Proceedings of the 19th International Conference on Artiﬁcial Intelligence and Statistics, AISTATS
2016, Cadiz, Spain, May 9-11, 2016. 1195–1204.

[13] Frank Wood, Jan-Willem van de Meent, and Vikash Mansinghka. 2014. A new approach to probabilistic programming

inference. In Artiﬁcial Intelligence and Statistics.

7

David Tolpin and Tomer Dobkin

A SOURCE CODE FOR CASE STUDIES
A.1 Compensation survey

1 package model
2
3 import (
4
5
6
7
8 )
9

. "bitbucket.org/dtolpin/infergo/dist"
"bitbucket.org/dtolpin/infergo/mathx"
"math"
"math/rand"

}

} else {

ll += Flip.Logp(0.5, m.Y[i])

ll += Flip.Logp(theta, m.Y[i])

coin := rand.Float64()
if coin > 0.5 {

theta := mathx.Sigm(x[0])
for i := 0; i != len(m.Y); i++ {

10 type Model struct {Y []bool}
11
12 type StochasticModel struct {Model}
13
14 func (m *StochasticModel) Observe(x []float64) float64 {
15
16
17
18
19
20
21
22
23
24
25 }
26
27 type DeterministicModel struct {Model}
28
29 func (m *DeterministicModel) Observe(x []float64) float64 {
30
31
32
33
34
35
36
37 }

Flip.Logp(theta, m.Y[i])+math.Log(0.5),
Flip.Logp(0.5, m.Y[i])+math.Log(0.5))

theta := mathx.Sigm(x[0])
for i := 0; i != len(m.Y); i++ {

ll += mathx.LogSumExp(

}
return ll

}
return ll

8

Stochastic Probabilistic Programs

A.2 Ball throw
To keep the deterministic model simple, the player throws the ball with one of two velocities: either
Vw (weak throw) or Vs (strong throw) with equal probability. The stochastic model can handle any
continuous or discrete random source of velocities.

1 package model
2
3 import (
4
5
6
7 )
8
9 const g = 9.80655

. "bitbucket.org/dtolpin/infergo/dist"
"bitbucket.org/dtolpin/infergo/mathx"
"math/rand"

v = m.Vs

} else {

float64 // distance to the basket

Vw, Vs float64 // velocities of weak and strong throw
L

sin2Alpha := mathx.Sigm(x[0])
// Choose a velocity randomly.
var v float64
if rand.Float64() > 0.5 {

10
11 type Model struct {
12
13
14 }
15
16 type StochasticModel struct {Model}
17
18 // The model parameter is Sigm^-1(sin(2*alpha))
19 func (m *StochasticModel) Observe(x []float64) float64 {
20
21
22
23
24
25
26
27
28
29
30 }
31
32 type DeterministicModel struct {Model}
33
34 // The model parameter is Sigm^-1(sin(2*alpha))
35 func (m *DeterministicModel) Observe(x []float64) float64 {
36
37
38
39
40
41
42 }

}
d := v * v / g * sin2Alpha
return Normal.Logp(m.L, 1, d)

sin2Alpha := mathx.Sigm(x[0])
// Compute weighted sum (or integral in continuous case) of
// log-probabilities.
dw := m.Vw * m.Vw / g * sin2Alpha
ds := m.Vs * m.Vs / g * sin2Alpha
return 0.5*Normal.Logp(m.L, 1, dw) + 0.5*Normal.Logp(m.L, 1, ds)

v = m.Vw

9

David Tolpin and Tomer Dobkin

A.3 Gaussian mixture model

1 package model
2
3 import (
4
5
6
7
8 )
9

. "bitbucket.org/dtolpin/infergo/dist"
"bitbucket.org/dtolpin/infergo/mathx"
"math"
"math/rand"

}

// number of components

Data []float64 // samples
NComp int

mu[j] = x[2*j]
sigma[j] = math.Exp(x[2*j+1])

// Fetch component parameters
for j := 0; j != m.NComp; j++ {

mu := make([]float64, m.NComp)
sigma := make([]float64, m.NComp)

10 // data are the observations
11 type Model struct {
12
13
14 }
15
16 type StochasticModel struct {Model}
17
18 func (m *StochasticModel) Observe(x []float64) float64 {
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37 }
38
39 type DeterministicModel struct {Model}
40
41 func (m *DeterministicModel) Observe(x []float64) float64 {
42
43
44
45
46
47
48
49
50

// Compute log likelihood under stochastic choices
// given the data
ll := 0.0
for i := 0; i != len(m.Data); i++ {

j := rand.Intn(m.NComp)
ll += Normal.Logp(mu[j], sigma[j], m.Data[i])

mu := make([]float64, m.NComp)
sigma := make([]float64, m.NComp)

// Fetch component parameters
for j := 0; j != m.NComp; j++ {

mu[j] = x[2*j]
sigma[j] = math.Exp(x[2*j+1])

return ll

}

}

10

Stochastic Probabilistic Programs

51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68 }

// Compute log likelihood of mixture
// given the data
ll := 0.0
for i := 0; i != len(m.Data); i++ {

var l float64
for j := 0; j != m.NComp; j++ {

lj := Normal.Logp(mu[j], sigma[j], m.Data[i])
if j == 0 {

l = lj

} else {

l = mathx.LogSumExp(l, lj)

}

}
ll += l

}

return ll

11

