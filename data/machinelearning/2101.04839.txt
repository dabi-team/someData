Vertex and Energy Reconstruction in JUNO with Machine
Learning Methods

Zhen Qiana, Vladislav Belavinb, Vasily Bokovc,d, Riccardo Brugnerae,
Alessandro Compagnuccie, Arsenii Gavrikovb,c, Alberto Garfagninie,
Maxim Goncharc, Leyla Khatbullinab, Ziyuan Li∗a, Wuming Luof,
Yury Malyshkin†c, Samuele Piccinellie, Ivan Provilkovg, Fedor Ratnikovb,
Dmitry Selivanovc, Konstantin Treskovc, Andrey Ustyuzhaninb, Francesco Vidaiche,
Zhengyun Youa, Yumei Zhanga, Jiang Zhua, and Francesco Manzalie

aSun Yat-sen University, Guangzhou, China
bNational Research University Higher School of Economics, Moscow, Russia
cJoint Institute for Nuclear Research, Dubna, Russia
dPhysics Department of Lomonosov Moscow State University, Moscow, Russia
ePhysics and Astronomy Department, Padova University and INFN Padova,
Padova, Italy
fInstitute for High Energy Physics, Beijing, China
gMoscow Institute of Physics and Technology, Dolgoprudny, Russia

2021-01-20

Abstract

The Jiangmen Underground Neutrino Observatory (JUNO) is an experiment de-
signed to study neutrino oscillations. Determination of neutrino mass ordering and pre-
cise measurement of neutrino oscillation parameters sin2 2θ12, ∆m2
32 are the
main goals of the experiment. A rich physical program beyond the oscillation analysis is
also foreseen. The ability to accurately reconstruct particle interaction events in JUNO
is of great importance for the success of the experiment.

21 and ∆m2

In this work we present a few machine learning approaches applied to the vertex
and the energy reconstruction. Multiple models and architectures were compared and
studied, including Boosted Decision Trees (BDT), Deep Neural Networks (DNN), a few
kinds of Convolution Neural Networks (CNN), based on ResNet and VGG, and a Graph
Neural Network based on DeepSphere.

Based on a study, carried out using the dataset, generated by the oﬃcial JUNO
software, we demonstrate that machine learning approaches achieve the necessary level
of accuracy for reaching the physical goals of JUNO: σE = 3% at Evis = 1 MeV for the
energy and σx,y,z = 10 cm at Evis = 1 MeV for the position.

∗

†

Corresponding author: liziyuan3@mail.sysu.edu.cn
Corresponding author: yum@jinr.ru

1

1
2
0
2

n
a
J

5
1

]
t
e
d
-
s
n
i
.
s
c
i
s
y
h
p
[

2
v
9
3
8
4
0
.
1
0
1
2
:
v
i
X
r
a

 
 
 
 
 
 
1

Introduction

JUNO is a 20 kt Liquid Scintillator (LS) detector designed with the primary goal of deter-
mining the neutrino mass ordering and the precise measurement of the neutrino oscillation
parameters sin2 θ12, ∆m2
31 [1]. JUNO is situated at an equal distance of about
52.5 km from two nuclear power plants and registers neutrinos produced in reactor cores
via the neutrino inverse beta-decay (IBD) channel: νe + p

21 and ∆m2

e+ + n.

The detailed description of the JUNO detector and the physics programme may be
found in [1, 2]. The detector design is typical for the experiments with reactor electron
antineutrinos. Liquid organic scintillator, rich with protons, is both the target for the IBD
reaction and the detection medium. When excited by the interaction with a charged particle,
the scintillator produces visible light with a yield roughly proportional to the particle energy.
It is also able to indirectly detect neutral particles. For instance, neutrons are captured by
hydrogen atoms, producing 2.2 MeV de-excitation gammas, which can ionize other atoms,
liberating electrons that are visible to the scintillator. Thus, the two-fold signal of the
positron and the neutron from IBD provides a clear signature for a neutrino interaction. In
this process the most of the neutrino energy is transferred to the positron.

−→

The detector design is presented in Figure 1. The target, consisting of 20 kt of LS, is
contained in a transparent acrylic sphere with an inner diameter of 35.4 m, which is located
in a cylindrical water pool. Photosensitive detectors facing inwards — almost 17 600 large
20(cid:48)(cid:48) photo-multiplier tubes (PMT) — are installed on a steel structure around the acrylic
sphere. The geometrical coverage of 75% is close to the maximum. The detector is also
equipped with 25 600 small 3(cid:48)(cid:48) photomultipliers (sPMT), placed between the large PMTs,
providing an extra coverage of 3%. The signal collected by PMTs is used for estimation of
the vertex and the energy of neutrino and background particle interactions.

Figure 1 – The central detector of JUNO. An acrylic sphere ﬁlled with 20 kt of liquid scintillator is located
in a water pool. Around 17 600 large PMTs looking inside are installed on a steel supporting structure.

The goal of the neutrino mass ordering determination at the level of 3 standard de-
viations poses stringent requirements on the detector performance: the energy resolution
width must be better or equal to σ = 3% at 1 MeV and the energy nonlinearity uncertainty
should be < 1%. The methods traditionally used for the energy reconstruction rely on the
reconstructed vertex and require a spatial resolution of at least 10 cm. Reconstruction of the
vertex is also needed for time-of-ﬂight correction for pulse shape discrimination of particle

2

types. The list of tasks requiring vertex reconstruction is not limited by the two aforemen-
tioned cases. Previous studies [1] indicate that the achievable spatial resolution is of the
order of 10 cm, with the ideal precision limit being of the order of a few centimetres.

On a technical level, a high energy resolution is achieved in JUNO by maximizing the
light collection via optimization of the LS composition, the usage of PMTs with high quan-
tum eﬃciency, and large geometrical coverage. The energy nonlinearity uncertainty will be
controlled by a calibration campaign [3]. On a software level the precision of the energy
reconstruction procedure should match the requirements as well.

In recent decades Machine Learning (ML) is becoming more and more popular in high
energy physics [4] both in collider experiments [5] and in neutrino experiments [6]. In ad-
dition to signal and background separation [7], we can also ﬁnd its broad application in
jet and event reconstruction [8]. ML has a long history of development. The concept of
the perceptron, the basic unit of current shallow networks, was proposed in 1958, and it is
now known as a Rosenblatt’s perceptron [9]. Backpropagation, an algorithm that is used to
train almost any neural network, was proposed in the 1980s [10]. However, after that, the
interest to deep learning revived only in 2005
2009 [11, 12] with the rapid development
of computational technologies, like GPUs, and collection of the signiﬁcant amounts of data
needed to train deep networks.

−

Given the tremendous success of ML in high energy physics, we investigate ML-based
approaches for energy and vertex information in the JUNO experiment. The time and
charge data collected from the PMTs can be provided as input for supervised training of
ML models. We observe that, after training on many samples, networks can predict the
event vertex and energy with high quality and fast speed.

In this paper, we study the applicability of diﬀerent ML approaches to the vertex and
the energy reconstruction for the energy range of 1–10 MeV covering the region of interest
for IBD events from reactor electron antineutrinos. The dataset used for the training of the
models is introduced in Section 2. In Section 3 we brieﬂy summarize the main concepts and
terminology of utilized ML approaches and describe the details of the models adopted for
our task. The performance of these models is presented in Section 4, where we also discuss
the impact of the electronics eﬀects on the reconstruction accuracy. The applicability of
ML to real data is discussed in Section 5. This section also covers a few future directions of
work. Finally, conclusions are given in Section 6.

2 Dataset

2.1 Data preparation

The training and testing of neural networks has been performed on Monte Carlo samples
generated with the oﬃcial JUNO software [13] and further processed to include the most
relevant eﬀects of the electronics response.

The detector simulation is based on the Geant4 framework [14] with the geometry [15,
16] implemented in details according to the latest design. The simulation starts from the
injection of positrons of diﬀerent energies in the range of 0-10 MeV characteristic for the
IBD reaction induced by reactor neutrinos.

After the generation of the primary particles, their ionisation energy losses are simulated.
In the liquid scintillator, this process is accompanied by the production of scintillation and
Cerenkov photons. The majority of photons in the region of PMT sensitivity are produced
by scintillation, which yields O(104) photons per MeV of deposited energy. The simulation

3

also includes interactions of primary particles with other particles of the medium, and allows
tracking the secondary particles as well. In particular, after depositing its kinetic energy
Ekin, the positron annihilates with an electron, producing a pair of gammas with energies of
511 keV each. These annihilation gammas then ionize the medium, causing the production
of the scintillation light. If gammas appear close to the detector edge, they may escape
from the detector, carrying away part of the energy, which leads to lower light yields and
complicates the reconstruction.

The photons are propagated through the detector with the most relevant optical pro-
cesses taken into account. The photons reaching the PMT photo-cathode may then produce
a photo-electron (p.e.) according to the photon detection eﬃciency measured in the labo-
ratory [17]. About 1350 p.e. are detected per 1 MeV of deposited energy at the detector
center. This number is aﬀected by statistical ﬂuctuations and systematic eﬀects like LS
non-linearity and detector response non-uniformity. The event of p.e. detection is called a
hit. The charge taken from PMT is, at the ﬁrst order, proportional to the number of hits.
In this work we ignore any statistical and systematic deviations from the linear relationship
between the number of hits and the charge, and refer to the number of hit on PMTs as a
charge information. It is hard to measure the time of each hit, instead we only assume that
the ﬁrst hit time on each PMT is measured. The time information is counted from the time
of event generated in simulation.

The second part of the data preparation, the application of electronics response eﬀects,
is done on top of the data produced by the detector simulation. Two eﬀects are included:
the dark noise (DN), i.e. spontaneous hits appearing in PMTs; and the transit time spread
(TTS), which happens due to stochasticity of the photo-electron path from the photo-
cathode to the anode. In this study, only 20(cid:48)(cid:48) PMTs from the central detector are used for
the reconstruction, including around 5000 Hamamatsu dynode PMTs (R12860) and around
12 600 Micro Channel Plates (MCP) PMTs from North Night Vision Technology (NNVT).
The information on the TTS distributions was taken from factory parameters of PMTs,
2.6 ns for Hamamatsu and 19 ns for NNVT, with additional smearing applied according to
the measurements performed at Daya Bay neutrino experiment (predecessor of JUNO). The
DN rates are sampled from distributions based on the test measurements performed for a
sample of PMTs expected to be installed in the central detector of JUNO. The distributions
span up to 50 kHz for Hamamatsu and up to 100 kHz for NNVT.

In this work, reconstruction is based exclusively on the data from the 20(cid:48)(cid:48) PMTs, since

the area coverage of the 3(cid:48)(cid:48) PMTs is signiﬁcantly smaller.

2.2 Data structure

We have prepared the training and the testing datasets with the following settings and
statistics:

1. Training dataset consists of 5 million events, uniformly distributed in kinetic energy
from 0 to 10 MeV and in the volume of the central detector (in liquid scintillator).
Typically, only the ﬁrst 90% of this dataset is reserved for iteratively optimizing the
models’ parameters. In-between each training pass over this data (epoch), the models’
performance is validated over the last 10% of the dataset.

2. Testing dataset consists of subsets with discrete kinetic energies of 0 MeV, 0.1 MeV,
0.3 MeV, 0.6 MeV, 1 MeV, 2 MeV, ..., 10 MeV. Each subset contains 10 thousand
events. This dataset is used to estimate performance after the end of training.

4

The targets of the reconstruction task are the following two variables: the total energy
deposited by each positron and by-product gammas inside the LS (Edep) and the average
position of the energy deposition calculated as:

rdep =

1
Ns

Ns

rs,iEdep,i,

(1)

i
(cid:88)
where rs,i is the position of the i-th simulation step and Edep,i is the energy deposited at
this step. The summation runs over all the steps. These two variables (Edep and rdep) are
also referred to as true information and are available for training from the Monte Carlo
simulation. They are predicted at the testing stage and the predictions are compared to the
true values.

As inputs, we use two types of information: aggregated features precalculated from PMT

signals and PMT-wise information.

The former is used for the simpler models, and are intuitively chosen to be the ones

which could contain the most information needed for reconstruction:

1. The total number of detected photo-electrons (hits), which is at ﬁrst order proportional
to the deposited energy. This number is less than the number of photons reaching the
photo-cathode of PMTs because of the limited

30% detection eﬃciency.

∼

2. The center of charge, deﬁned as

rcc =

NPMTs

rPMTinp.e.,

(2)

1
Nhits

i
(cid:88)
which is a rough estimation of the energy deposition location and allows accounting
for the non-uniformity of the detector response. The summation runs over all ﬁred
PMTs with positions rPMTi and numbers of detected photo-electrons np.e..

3. Mean and dispersion of the ﬁrst hit time distributions. These two features provide

extra information about the dynamics of the signal.

The PMT-wise measured information is used as input for the more complex models, and
includes the number of hits and the time of the ﬁrst hit at each PMT. Figure 2 illustrates
the time evolution of the signal in the PMT channels for a positron event of 5.5 MeV. The
event display software [18, 19] dedicated to JUNO can be used to dynamically display the
entire process. All the inputs are summarized in Table 1.

To study the impact of TTS and DN on the reconstruction, we have generated four
datasets for training and four corresponding testing datasets with diﬀerent TTS/DN op-
tions. The ﬁrst dataset does not include the inﬂuence of TTS and DN. The other two
datasets only include the inﬂuence of either TTS or DN. Then, the last dataset includes
both TTS and DN, which is the situation closest to the real case, and is used as the default
dataset in the following study if not speciﬁed otherwise.

3 Architectures of Machine Learning Models

The primary vertex and the energy are reconstructed by two classes of models. Simple
models, that use only several aggregated features, include Deep Neural Networks (DNN) and

5

Figure 2 – Example of an event seen by PMTs and evolving in time: 5th ns (top left), 55th ns (top right),
105th ns (bottom left) and 155th ns (bottom right). Only ﬁred PMTs are shown. The color represents the
accumulated charge in PMTs: yellow points show the channels with more hits, red points — the channels
with few hits. Only hits in 20(cid:48)(cid:48) PMTs are shown. The primary vertex is shown by the gray sphere.

Boosted Decision Trees (BDT). The complex models, that use the PMT-wise information
include Convolutional Neural Networks (CNN) and Graph Neural Networks (GNN).

DNN and BDT are minimalistic, which allows getting rough predictions at a very low
computational cost. The CNNs (VGG, ResNet) and GNN are more complex and provide
better precision by processing the full information, at the cost of an increased number of
intrinsic parameters and, as a consequence, a slower prediction rate.

In the current section we discuss the general terminology of supervised learning and the

architecture of each model.

3.1 Boosted Decision Trees

A decision tree [20] is a model that consists of a binary set of splitting rules based on values
of diﬀerent features of the object. As a result, the entire feature phase space is split into
separate cells. The predicted value for a given object is then completely deﬁned by the cell
which the combination of features of the object belongs to.

The decision tree thus may be used as a non-parametric model to be trained by the su-
pervised Machine Learning algorithm. This model is simple and interpretable. It is common,
instead of using a single decision tree as a complete model, to use an aggregated model like
an ensemble of decision trees. Two most common approaches for decision tree ensembles
are Boosted Decision Trees [21, 22] and Random Forests [23].

6

Parameter

True information

Event ID
int
Edep
Deposited energy
Average position of the energy deposition x edep, y edep, z edep

Name Type [

size]

×

ﬂoat

ﬂoat
3

×

Aggregated information

Total number of hits
Center of charge coordinates
Radial component of center of charge
Average of the ﬁrst hit time
Dispersion of the ﬁrst hit time

PMT-wise measured information

Number of hits (photoelectrons)
Hit time of the ﬁrst detected photon
Position
Type

nHits
x cc, y cc, z cc
R cc
ht mean
ht std

ﬂoat

int
3
×
ﬂoat
ﬂoat
ﬂoat

npe
hittime

int
ﬂoat
3
20(cid:48)(cid:48) Hamamatsu / 20(cid:48)(cid:48) NNVT

ﬂoat

×

Table 1 – Data structure of a single event. See details in the text.

Random Forests and Boosted Decision Trees diﬀer primarily in how an ensemble model
is built. In the former method, N decision trees are trained independently. The ﬁnal solution
for the entire ensemble is a mean prediction. In the latter method the models are trained
sequentially. Each subsequent decision tree is trained to correct errors of all previous decision
trees in the ensemble. Figure 3 shows an example of a decision tree from an ensemble of
Boosted Decision Trees. The value on the leaf is added to the prediction value of the previous
ensemble as a correction.

We explore the same aggregated features listed in Table 1. This allows for a direct
comparison of performances for both approaches. The XGBRegressor BDT implementation
from the XGBoost library [24] is used for this study.

Figure 3 – Example of a decision tree with a maximum depth equal to four.

7

nHits<17468.5NoYesht_std<169.372z_cc<11.493z_cc<11.240z_cc<4.848nHits<8825.5leaf=-0.00037894leaf=0.00068898leaf=-8.65783e-5leaf=0.00018958ht_mean<174.336leaf=0.00069301leaf=-0.00018959leaf=-0.00486328leaf=-0.00079091NoNoYesYesYesNoNoYesYesNoYesNo3.1.1 Tuning Boosted Decision Trees for JUNO

The selection of the optimal hyperparameters was carried out using a grid search. It deﬁnes
a grid of the parameter values and calculates the value of an objective function for each
node in the grid. We use the Root Mean Squared Error (RMSE) as an objective function.
The node with the lowest RMSE value is taken as the optimum.

The grid search was performed for the BDT method with a learning rate of 0.08 trained
on the dataset with 1M events, which includes the eﬀects of TTS and DN. We used cross-
validation with the dataset split in three parts with the KFold tool from the Scikit-learn
library [25]. The training of the model was stopped in case the RMSE on the validation set
did not decrease for ﬁve consecutive iterations. The resulting RMSE metric was calculated
on the additional test sample with 150K events.

Figure 4 – The dependence of number of trees in the ensemble and RMSE on the test sample on the
maximum depth.

The results, presented in Figure 4, demonstrate that the optimal depth of the trees is 10
or 11. Shallower trees necessitate more trees and yield worse precision. On the other hand,
deeper trees require fewer trees but provide worse precision because of overﬁtting.

Table 2 shows the permutation importance for the prediction of the z-coordinate of the
vertex and the energy of the event. Permutation importance indicates how the prediction
error increases when a feature is not available. These weights are computed with ELI5
library [26]. Not surprisingly, the most informative feature for a vertex coordinate is the
corresponding coordinate of the center of charge, and the total number of hits is the most
informative for the energy reconstruction. Table 2 also shows the other features sorted by
their importance. The order of the other features is similar for both reconstructed variables.

3.2 Deep Neural Networks

A Neural Network is a method to construct the function fW in a modular fashion, inspired
by the structures of a human brain. The simplest network consists of a single unit, called
a neuron, which computes a linear combination of its inputs and passes it to a non-linear

8

2468101214Maximal depth of a tree500100015002000Number of treesNumber of treesRMSE, keV86.0086.2586.5086.7587.0087.2587.5087.7588.00RMSE, keVFeature

z cc
ht mean
R cc
ht std
nHits

Weight

1.999

±
0.012)
0.002)
0.028)
0.004)

0.008
10−2
10−2
10−4
10−4

×
×
×
×

(2.436
(0.156
(5.720
(1.460

±
±
±
±
z edep

Feature

nHits
ht mean
R cc
z cc
ht std

Weight

2.041

±
0.002)
0.005)
0.006)
0.005)

0.005
10−2
10−2
10−3
10−3

×
×
×
×

(1.365
(1.049
(1.900
(1.623

±
±
±
±
edep

Table 2 – Permutation importance for the prediction of the z-coordinate (left) and the deposited energy
(right) on 1 million events.

activation function h:

fW(x) = h(Wx + b),

(3)

where the oﬀset b is called the bias of a neuron. There are diﬀerent methods to deﬁne
the activation function h. The most popular one is the Rectiﬁed Linear Unit (ReLU) [27],
deﬁned as h(y) = max(0, y).

Multiple neurons are combined in a layered structure, forming a Neural Network (see
Figure 5). Layers in which all neurons are connected to the previous units are said to be fully
connected, or dense. When the layers structure go deeper, the network becomes complex
and have better ability at ﬁtting, which forms a Deep Neural Network (DNN).

Figure 5 – Representation [28] of a simple Neural Network with 3 layers.

When working with high dimensional data, such as images, the connection count grows
drastically, and must be reduced to make training more eﬃcient. To do so, the neurons are
linked only to a subset of the previous units, which forms their receptive ﬁeld. Convolutional
Neural Networks (CNN) take this concept a step further, by making all receptive ﬁelds of a
layer the same size and shape, which is usually that of a square patch of input data. In this
way, the computed linear combination is a discrete convolution (see Figure 6). CNN has
a good advantage in information extraction for high-dimensional data. The methods using
CNNs will be introduced in the later sections (see Section 3.3–3.4).

However, in this section, we would like to discuss the method that implements the basic

DNN ﬁrst.

9

Σσ+1x1x2x3xnw0w1w2w3wnσ(cid:18)w0+nPi=1wixi(cid:19)...I1I2I3InputlayerHiddenlayerOutputlayerO1O2Figure 6 – 2D convolution of a 4 × 4 image. The receptive ﬁelds of two neurons (red and blue squares) are
shown. Note that they are of the same shape and size, which enables them to share the respective weights,
forming a ﬁlter W, which is also referred as a kernel. In this way 4 × 9 parameters are reduced to 4.

3.2.1 Tuning Deep Neural Networks for JUNO

In theory a DNN can approximate an arbitrary function given it has enough layers and
neurons. However, on practice, the eﬃciency of the DNNs heavily depends on a choice of
the architecture and the optimization procedure. Thus, an essential part of the application
of a DNN to a real-world problem is an accurate choice of hyperparameters.

In order to understand the achievable precision for such a minimalistic input (the aggre-
gated features listed in Table 1) and to identify the optimal architecture we have performed
an extensive optimization of the hyperparameters. The hyperparameters being optimized
as well as their respective ranges and optimal choices are all presented in Table 3.

Parameter

Range and optimum

Activation
Initialization
Scheduler type [29, 30]
Optimizer [31–33]
Layer norm [34]
Depth (number of hidden layers)
Width (number of neurons in a layer)
Batch size
log(lr) (learning rate)

ReLU, Tanh
normal, orthogonal, uniform
ReduceLROnPlateau, CosineLRAnnealing, None
Adam, RMSprop, SGD
True, False
[2, 10]: 7
[16, 128]: 32
[128, 1024]: 768
2]: 0.002
[
−

−

4,

Table 3 – Hyperparameters of Deep Neural Networks being tested, their ranges and options. The values
considered as the optimal are marked with emphasis.

We have trained the networks by sampling the hyperparameters randomly. To select
the best hyperparameters, we have performed an empirical posterior estimation of the pa-
rameters. Firstly, we selected 10% of the top-scoring experiments. Then for the continuous
variables we performed kernel density estimation [35] (KDE) — a non-parametric approach
for the reconstruction of the data distribution. According to the procedure of KDE we as-
signed a continuous kernel function (in our case, a Gaussian kernel) to each data point in
order to build a smooth approximation of the density. We selected kernel bandwidth accord-
ing to the Scott’s Rule [36]. For the discrete variables, we counted the probability of each
selection. This procedure gave us a rough estimate of the distribution of hyperparameters

10

13020214112341101201948965763InputOutputof well-performing models.

For the depth and the width, we found two local optima corresponding to a long-and-
narrow network and a short-and-wide network, which is not surprising because the network’s
complexity depends on both the depth and the width, which are in some sense interchange-
able. However, the interpretation of the depth and the width and their inﬂuence on the
network’s quality is still an active ﬁeld of the research. For example, in [37] authors argue
that depth is responsible for the level of abstraction that a network operates on, and width
is relevant for the ﬂow of the information through each layer. In our case, based on the
results of the posterior estimation procedure, we have chosen depth equal to 7 and width
equal to 32. A similar trade-oﬀ is observed for batch size and learning rate, with the rule
of the thumb is that the bigger the batch size implies the bigger learning rate [38]. We
have chosen a batch size equal to 768 and a learning rate equal to 0.002. As for the other
parameters, the choice of their values does not make much diﬀerence. Except for a few
combinations of hyperparameters, the vast majority of tested networks provide comparable
performance. The values we have chosen are listed in Table 3.

We have also performed an optimization of the loss function for the vertex reconstruction
and for the energy reconstruction by optimizing the coeﬃcients in the following parametric
representation of the combined loss function:

(gtrue, gpred) = α

L

1
N

N

i=1
(cid:88)

(cid:118)
(cid:117)
(cid:117)
(cid:116)

(gpred

−

gtrue)2 + β

gpred
|

−

gtrue

+
|

1
N

N

i=1
(cid:88)

γ

1
N

N

i=1
(cid:88)

(gpred

gtrue)2

−
Etrue

+ δ

1
N

N

|

i=1
(cid:88)

gpred

gtrue

−
Etrue

|

,

(4)

1
GeV2
(cid:104)
1
cm2

(cid:105)
, β

where the weights α + β + γ + δ = 1 sum to unity, g is a quantity of the interest (energy
or coordinates of the vertex). We note that terms in this loss function have diﬀerent units,
which might aﬀect the optimization of coeﬃcients and training stability if some loss terms
are too big or too small compared to the others. We found that when energy is represented in
GeV units and distance in cm, all loss terms have the same order of magnitude. So, when we
reconstruct energy the respective units of coeﬃcients are

, β

, γ

, δ

α

1

1
GeV

1
GeV

and when we reconstruct vertex the respective units are

(cid:110)
α

(cid:104)
1
cm

, γ

(cid:105)

(cid:104)
GeV
cm2

, δ

(cid:104)
(cid:105)
GeV
cm

(cid:105)(cid:111)
.

For both the vertex reconstruction and the energy reconstruction we have trained the
(cid:105)(cid:111)
(cid:104)
(cid:110)
, and we have found that the most

networks for diﬀerent random quadruplets of
optimal conﬁguration implies nearly equal contribution of these loss components.

α, β, γ, δ
{

}

(cid:105)

(cid:105)

(cid:104)

(cid:104)

(cid:104)

(cid:105)

In order to estimate the importance of each feature, we have computed SHAP (SHapley
Additive exPlanations) values [39]. It represents the prediction of the expected model when
conditioned on that feature, i.e., shows how important this single feature with respect to the
predicted entity. In plots, presented on Figure 7, all the features are normalized to the range
of [0, 1] and colours represent the normalized features. For example, we observe, that for the
energy prediction, the most important feature is nHits and an event with a larger number
of hits has higher energy predicted by the DNN, which is expected. The radial component
of the center of charge (R cc) is the second most important feature in the energy prediction.
It is negatively correlated with the predicted energy. For the prediction of x-coordinate of
the vertex the most important feature is x cc and the second most important is ht mean.

11

Figure 7 – SHAP values for the vertex (left) and for the energy (right) prediction.

3.3 Planar CNN Models

Convolutional Neural Networks (CNNs) is a deep learning network class commonly applied
to analyzing visual imagery [40]. CNN’s architecture makes it feasible to train them on
large datasets of images, showing an outstanding performance on object recognition and
classiﬁcation tasks. CNNs work only on d-dimensional Euclidean domains, in which each
input sample is represented as a regular grid of values, i.e. a d-dimensional cubic lattice.
In this way, all the neurons of a convolutional layer have receptive ﬁelds of the same area
and shape, capturing the same kind of features, and requiring the same number of weights
(which is a necessary condition for weight sharing). Geometrically, this means that the
shape of a receptive ﬁeld (i.e. of a ﬁlter) can be translated to cover diﬀerent “patches” of
the input data.

The case of using CNNs for reconstruction task in JUNO is to let the network learn
the pattern of the time and charge distribution obtained from the detector and predict the
energy and/or vertex. However, PMTs in JUNO are placed along a spherical surface, which
is a non-Euclidean domain. No regular grid can be constructed on the sphere, meaning
that there is no way to deﬁne a “spherical ﬁlter” that can be uniformly translated over its
surface. Therefore, we need to design a transformation of the spherical information obtained
from the detector into a planar image.

For CNNs, diﬀerent network architectures will also aﬀect the ﬁnal reconstruction perfor-
mance. We tried basic CNN architectures, including AlexNet [41], VGG [42], GoogLeNet [43],
and so on, and currently get the best performance with VGG and ResNet networks [44].

3.3.1 Projection Method

We have designed a method of projecting on a plane for spherical detectors like JUNO to
convert the detector response into a pair of images, one for charge (i.e. the number of PE
hits) and one for ﬁrst hit time. In order to transmit the information more eﬃciently, the
projection design follows the following guidelines:

1. A single PMT occupies a single pixel in the image to minimize the information loss.

2. The ﬁnal image has a similar arrangement as the original PMT in the detector.

3. The total amount of pixels should be minimized as soon as the requirement 1. is kept.

(This is required to reduce the amount of computations.)

There are about 17 600 PMTs in the central detector of JUNO. If we take a ring of PMTs
with same latitude, the higher latitude we take, the fewer PMTs it will contain. To avoid

12

15105051015SHAP value (impact on model output)y_ccz_ccht_stdnHitsR_ccht_meanx_cc0.00.250.50.751.0Feature value420246SHAP value (impact on model output)y_ccx_ccht_stdht_meanz_ccR_ccnHits0.00.250.50.751.0Feature valueoverlap of PMTs, we put the PMTs layer by layer from the top of the detector into the
image’s pixels so that PMTs with the same latitude will be arranged in the same row. The
ﬁnal image contains 124 rows, where one row corresponds to the latitude of the PMT. Since
the number of PMTs changes with the latitude, the eﬀective number of pixels in each row
also changes dynamically. The number of eﬀective pixels per row Neﬀ and the horizontal
position ix of the PMT in the image are given by:

Neﬀ =

Nmax

(cid:34)

z2

√R2
R

−

·

,

(cid:35)

ix =

Neﬀ

(cid:20)

arctan(x/y)
π

·

+

Nmax
2

,

(cid:21)

(5)

where x, y, z is the global position of the PMT, R is the radius of the detector and Nmax
is the total number of columns. Nmax controls the tightness of the PMT arrangement. The
optimal image size, that ensures that no PMTs are overlapped, is 230
124. The image
produced by this projection method is similar to that produced by sinusoidal projection,
but it is more convenient to manage the position of PMTs in the image. Furthermore, it
yields better results compared with the results of the Mercator projection in our study.

×

Using the mapping relationship from the PMT to the pixel position, the hit information
obtained by the detector can be converted into the image (see Figure 8). The images have
two channels: charge and ﬁrst hit time, which are the inputs of the CNNs.

(a) Map of PMTs.

(b) Charge channel.

(c) First hit time channel.

Figure 8 – The planar projection method ﬁrst generates a mapping of the ID of the PMTs and the position
of the pixel in the image (a). The charge (b) and ﬁrst hit time (c) information can be ﬁlled in the image
according to the mapping.

3.3.2 VGG-J

The VGG network is a classic convolutional neural network architecture that still has com-
3 kernel-sized ﬁlters applied in a chain, one
petitive performance today. It has multiple 3
after another. The advantage of using multiple 3
3 convolution kernels instead of large
convolution kernels is that it has fewer parameters and has better learning ability under
the same receptive ﬁeld. There are usually dense layers with thousands of nodes in the
last three layers of the original VGG network. The presence of the dense layer makes the
network better at ﬁtting, but also greatly increases the amount of parameters.

×

×

The VGG-J network we use has 17 layers (see Figure 9). According to the complexity
of the energy and vertex reconstruction tasks, we optimize the number of nodes in the ﬁnal
dense layer. The ﬁnal number of nodes in the last dense layers are: 1024 nodes, 512 nodes
and 100 nodes respectively; followed by 1 or 3 nodes, which are used to yield the prediction

13

0204060801001201401601802002200204060801001200200040006000800010000120001400016000PMTID020406080100120140160180200220020406080100120510152025303540Charge02040608010012014016018020022002040608010012020040060080010001200FirsthittimeFigure 9 – VGG-J network architecture for CNN reconstruction with 17 parameter layers. It is composed
of two main blocks: a sequence of 3 × 3 convolutional layers (with maxpooling used for coarsening) and a
few dense layers at the end. The last dense layer is used to output the prediction result, which is 1 node for
reconstructing energy and 3 nodes for reconstructing vertex coordinates.

of energy or vertex. Compared with the original VGG-16 network that has two layers with
4096 nodes, the amount of parameters in VGG-J network is 26 million, which has been
reduced by 65%, while the reconstruction accuracy has remained at the same level.

3.3.3 ResNet-J

In order to push the reconstruction performance to the limit, we would like to train a
network that has more layers, which may bring better learning ability. However, it will bring
undesirable eﬀects if more convolutional layers are added directly, including overﬁtting,
longer training process and slower prediction speed. In order to solve this problem, we
use ResNet network architecture [45]. The main feature of ResNet is the usage of residual
blocks, shown in Figure 10, where x denotes the input of the block. In a regular NN the
(x), while the ResNet lets the block ﬁt another feature
block yields the feature mapping
(x)
x which is called residual mapping. Therefore, the original mapping
(x) :=
mapping
(x) + x. It has been discussed that it is easier to optimize the residual
is converted into
mapping than to optimize the original one [44].

H
F

H

−

F

Compared with the original ResNet50 network, we optimized convolutional layers and
the dense layers for the reconstruction in JUNO. The ﬁnal network structure is shown in
the Figure 11 and contains a total of 53 layers with approximately 35 million trainable
parameters. In comparison with VGG-J it has more layers to enhance the learning ability,
see Table 4.

VGG-J ResNet-J

Layers
Parameters

17
26 310 035

53
38 352 403

Table 4 – Comparison of VGG-J and ResNet-J architectures.

14

23×31164x(230, 124, 2)64128256512Conv Layer}×2}×2}×3}×3230124MaxPooling Layer2×2Max22Flatten3 or 11024Convolutional BlockDense Block512100x= Batch Norm= ReLU= 2D Conv.= MaxPoolyx= StrideFigure 10 – Residual block structure in ResNet network.

Figure 11 – ResNet-J network architecture for CNN reconstruction with 53 parameters layers. It is composed
of a number of residual blocks (see a typical example below) and a couple of dense layers at the end. A
residual block is make up of a stack of convolutions. They are 1 × 1, 3 × 3, and 1 × 1 convolutions, where
the 1 × 1 layers are responsible for reducing and then increasing (restoring) dimensions and the 3 × 3 layers
are responsible for coarsening when it has a stride of 2 in conv block (red). Next to the main convolutions
(Full path), there is a 3 × 3 convolutional layer (Skip path), which has same dimensions and stride so that it
can be added to the outputs of stacked layers used for the residual function. Between the convolutions and
dense layers, an average pooling layer summarizes all feature got by convolutions, then the dense layers at
the end will output the prediction result.

We used same hyperparameters and training schedule for ResNet-J and VGG-J, see

Table 5. It takes about 4 days to train one model on a single V100 GPU.

3.4 Spherical Model (GNN-J)

As it was already mentioned in Section 3.3, the spherical arrangement of PMTs in JUNO
does not allow to directly use the signal as input for CNNs. One possible workaround is to
deﬁne an arbitrary projection to a Euclidean domain, and then use CNNs as usual, as it

15

weight layerweight layerReLUReLUIdentityxxℱ(x)ℱ(x)+x6426×3213×311643×32Flatten8×82512conv2_xconv3_xconv4_xconv5_xInputconv1AvgDense642561285122561024512204864642562561×111×113×3SInput3×3S"Skip" path"Full" path+Outputxxxxxxx= Batch Norm= ReLU= 2D Conv.= MaxPool= AvgPoolyx= StrideS=2S=1id/conv block}×3}×3×5×2}}100Out3 or 1Parameter

Value

Mean Squared Error
Loss
Optimizer
Adam (β1 = 0.9, β2 = 0.999)
Learning rate Linearly increasing from 0 to 10−3 during the ﬁrst epoch,
then exponential decay to 10−8.
64
15

Batch size
N. Epochs

Table 5 – Hyperparameters for VGG-J and ResNet-J.

was done in the previous Section 3.3.1.

However, this comes with a few problems:
• Deformation. Any projection inevitably stretches or shrinks certain areas. So, during
convolution, the same ﬁlter will capture features coming from spherical regions with
diﬀerent areas and shape, breaking translational invariance and making learning more
diﬃcult.

• Topology. Distances on the projection are not, in general, proportional to distances
on the spherical surface. So, features that are close on the sphere can be far in the 2D
projection, meaning that they may not be captured by a local ﬁlter.

These issues can be avoided by using Graph Neural Networks (GNNs), which generalize

CNNs to generic manifolds and remove the need for a projection.

The main idea is to encode the topology of the input domain in a graph structure,
and then properly deﬁne convolutions and pooling operations on it. In this work, we adapt
the DeepSphere model [46], previously used in cosmology, to the JUNO experiment. The
procedure is as follows:

1) First, we need to deﬁne the graph’s nodes which will hold the input samples. A
natural choice would be to directly use the PMTs as vertices in 3D space. However, we need
also a way to iteratively group neighboring nodes so that their data can be aggregated by
the pooling operation. The simplest possibility is to consider a hierarchical partition of the
spherical surface, and deﬁne nodes in the graph as the regions’ centers. In this work, we
use the Hierarchical Equal Area isoLatitude Pixelisation (HEALPix) algorithm [47], which
divides the surface into Npix = 12N 2
side spherical pixels, all with the same area and centered
2k controls the
along rings of equal latitude (see Figure 12, top). The parameter Nside
discretization resolution. For the input data, it is set at Nside = 16, dividing the detector’s
surface in Npix = 3072 regions, each containing on average 5.77 PMTs. Higher values of
Nside have been tried (up to Nside = 64, at which each pixel contains at most 1 PMT), but
they signiﬁcantly increase storage and computational requirements, while not improving
the reconstruction accuracy.

≡

A hierarchical discretization means that vertices can be labelled in a nested scheme (see

Figure 12, bottom), which makes pooling operations very eﬃcient.

2) We construct a simple, undirected graph

, W) encoding the discretization
R3 being
structure. In this notation,
∈
V
is the set of active
the center in 3D space of the i-th spherical pixel. Then,
RNpix×Npix is the positive symmetric weighted adjacency
links between vertices, and W
matrix, such that Wij is the weight of the connection from node i to j, representing their
“closeness”, with Wij > 0 if and only if (vi, vj)

,
E
i=1,...,Npix is the set of Npix vertices, with vi

E ⊂ V × V

vi
{

= (

=

∈

V

G

}

.

∈ E

16

Figure 12 – The HEALPix algorithm starts by dividing the spherical surface into 12 regions: 4 around each
pole, and 4 at the equator. Then, resolution can be increased by iteratively dividing each spherical pixel
into 4 sub-pixels of equal area, so that any edge of the original 12 regions is split into Nside parts. Pixels are
labelled in a nested scheme, so that subpixels belonging to the same region have consecutive indices. In this
way, a pooling operation on the discretized sphere is as eﬃcient as the usual 1D pooling. As an example,
consider the bottom picture. Pixels belonging to the same region have similar colors, with their brightness
representing diﬀerent values. The pooling operation consists of aggregating all pixels in the same region into
a single value, which in this example is given by the darkest color.

The choice of the connection weights is discretionary. For simplicity, we adopted the
same convention used by the DeepSphere model [46], for which only neighboring pixels i, j
have non-zero weights Wij deﬁned by a Gaussian function:

Wij = exp

vi
(cid:107)

2
2
(cid:107)

vj

−
2d2

,

(cid:33)

(cid:32)−

d2 =

1

vi

vj

2
2,
(cid:107)

−

(6)

(cid:107)
|E| (cid:88)(vi,vj )∈E

(cid:107)

x2
1 +

(cid:112)

· · ·

(cid:107)2 ≡
E

n denotes the Euclidean norm, and

+ x2
, i.e. the number of links in

x
is the number of elements
where
. The idea of (6) is that the connection weight
in the set
Wij between two nodes is higher if they are closer, and decays quickly with their (squared)
distance. Note that, since we are only connecting neighboring nodes, their distance on the
spherical surface can be locally approximated by the Euclidean norm. Then, the average d2
of the squared distances is used to normalize the argument of the exponential.

|E|

G

With this choice, the nodes are only locally connected, meaning that W is sparse, i.e.
contains mostly zeroes, and so computations may be optimized. To construct a GNN, the
only requirement for the Wij is to encode a connected graph, i.e. such that there is a set
of edges with non-zero Wij linking any two nodes i and j. However, we did not investigate
diﬀerent choices for (6).

3) An input sample x

a vector of F features.

∈

RNpix×F is a signal on

, i.e. a function mapping each node to

G

In this work F = 2, and we consider, for each PMT, its charge (i.e. the number of PE
hits) and its ﬁrst hit time, relative to the event’s origin. If a PMT receives no hits, we assign
a discretionary ﬁrst hit time of 1024 ns, denoting that it is hit “at inﬁnity”.

17

0123456713151719222335161814122021NSide = 1NSide = 20123458ZXYNorth PoleSpherical PixelCenterNSide = 1NSide = 2012345678...910111213012G

Since spherical pixels contain more than one PMT, we need to aggregate data from
RF of the i-th spherical pixel. So, for every
several PMTs to form the feature vector xi
∈
spherical pixel, we sum the charges of all the PMTs inside it, and take the minimum of
their ﬁrst hit times.

4) Before the training, we normalize each channel (charge and ﬁrst hit) in the training
dataset to 0 mean and unit standard deviation. In this way, all the features have the same
order of magnitude, which is necessary for the model to converge.

5) Convolutions on

can be deﬁned in many ways. In this work we use Chebyshev

Convolutional Layers [48], which use the spectral domain of the graph to deﬁne ﬁlters.

6) The model is implemented using the Spektral library [49] and Tensorﬂow 2.2 [50]

with tf.Keras.

The architecture, further referred to as GNN-J (see Figure 13), is inspired by that
of VGG-16, with some minor changes in the number of ﬁlters/layers which resulted in a
small (
5%) improvement in validation accuracy. All the model’s hyperparameters are
summarized in Table 6. They were found by a manual trial and error over a small set of
alternatives. In fact, since training takes
22 h on a single V100 GPU, it was not feasible
to perform a more comprehensive automated search.

∼

∼

Figure 13 – Architecture for the GNN-J model. It is composed of two main blocks: a sequence of Chebyshev
convolutional layers (with maxpooling used for coarsening) and a couple of dense layers at the end. Between
the two, a global average pooling layer computes averages for each ﬁlter, leading to a certain degree of rota-
tional invariance. Graph convolutions happen at the spectral domain, and involve ﬁlters that are localized,
i.e. with a ﬁnite (graph) radius K = 5. Their topology is parametrized by the coeﬃcients of a K-order
Chebyshev polynomial, which are part of the model’s learnable parameters.

As a ﬁnal detail, we note that using a relative loss, such as the Mean Absolute Percent-
age Error (MAPE), works best for the task of energy reconstruction, improving resolution
and bias at low energies. However, it also makes training more unstable: sometimes a bad
initialization results in an initial loss of 100%, which does not improve over time. In these
cases, weights need to be re-initialized, and the training restarted.

18

(3072, 2)1632NSide = 16326464128128256Dense*16 FiltersRadius K=5}Global Average Pooling25100First hitChargeFilteredsignalsChebConv LayerMaxPooling Layer + BatchNormNSide = 8NSide = 4NSide = 2NSide → Nside / 2MaxMeanParameter

Value

Loss
Optimizer
Learning rate Fixed at 0.001 for Nepoch < 3, then exponential decay at rate
Batch size
N. Epochs

Mean Absolute Percentage Error
Adam (β1 = 0.8, β2 = 0.9)
0.1.
64
10

−

Table 6 – Hyperparameters for GNN-J.

4 Results

In the following sections we will present the performance of the studied methods (BDT,
DNN, ResNet-J, VGG-J and GNN-J) for the reconstruction of primary vertex and energy.
Only one of the models, GNN-J is used exclusively for the energy reconstruction. The task
of the vertex reconstruction requires the time information of each PMT taken into account.
Since the current implementation of GNN-J aggregates data to a some degree even at the
input level, it is not suitable for the task. Ways to overcome this limitation will be discussed
in Section 5.

Before comparing the results, we also present an overview of performance parameters

and outline their expected behavior.

4.1 Deﬁnition of the performance parameters

In order to evaluate the performance of the trained models, both the neural networks and
the decision trees, we study two characteristics: resolution and bias. They are deﬁned by a
Gaussian ﬁt, as shown in Figure 14. The mean value of the best ﬁt Gaussian corresponds to
the reconstruction bias and represents the systematic shift introduced by the reconstruction,
which potentially may be compensated. The value of the σ of the Gaussian corresponds to
the reconstruction resolution. This approach is used for both the vertex and the energy
reconstruction. The uncertainties of the ﬁt values are shown on the plots with vertex and
energy resolution by error bars.

Figure 14 – An example of Gaussian ﬁt for a spatial variable in each direction for Evis = 4.022 MeV, used
to extract the bias and the resolution. The predictions are produced with VGG-J.

Bias and resolution are studied as a function of two variables. The ﬁrst one is visible
energy. It is a combination Evis = Ee + me = Ekin + 1.022 MeV of the total positron

19

2000200xpredxtrue, mm020040060080010001200Number of events per bin=-10.42 mm=50.75 mm2000200ypredytrue, mm020040060080010001200=-0.05 mm=51.44 mm2000200zpredztrue, mm020040060080010001200=4.08 mm=52.22 mmenergy and the electron mass, which appears due to positron-electron annihilation. The
light collection and the number of triggered PMTs grow with the energy, which makes the
reconstruction more precise.

The detector is symmetric versus rotation; therefore, the main diﬀerence in reconstruc-
tion arises from a distance between the detector center and the vertex — its radial position,
which is used as a second variable. Events in the center of the detector produce a more
symmetric response. The events on the edges of the detector are aﬀected by the light atten-
uation in the LS, eﬀects of the light scattering and re-emission and, near the edge, by the
total internal reﬂection in the acrylic sphere. The results are sampled versus r3, since cubic
sampling produces equal volume spherical layers and provides equal statistics samples.

The performance of the vertex reconstruction is studied as a function of both visible

energy and radial position. It is reported in absolute values in mm.

It is worth noting that while the angular resolution is high, the bias and resolution of
the radial component do not directly correspond to the Cartesian distance between the true
and reconstructed vertex.

The performance of the energy reconstruction is studied as a function of visible energy
and is reported as a ratio to the visible energy in percents. It could in principle be interesting
to study energy resolution as a function of number of photo-electrons, because to the ﬁrst
order the resolution is deﬁned as 1/√np.e.. However, for the large JUNO detector np.e.
depends on the event position in the detector. By this reason we do not present the results
as function of np.e..

It has to be noted here that the ML models learn that the event energy belongs to
the range of the training dataset (0–10 MeV) and never happens outside, therefore the
distribution of the reconstructed energy at the edges of the dataset becomes asymmetric,
as shown in Figure 15. In order to simplify the following considerations, we do not analyze
the points on the edges of the dataset. Instead, we only consider points from 0.1 MeV to
9.0 MeV, for which the prediction distributions are well ﬁt by Gaussian. Since the edge
values are outside the region of interest of physics, which has a range of 0.5–9.0 MeV, no
important information is lost by the truncation.

Figure 15 – An example of energy prediction distributions for Evis = 1.022 MeV (left) and Evis = 2.022 MeV
(right). The latter one is ﬁt with Gaussian function. The predictions are produced with BDT.

4.2 Vertex Reconstruction

The current VGG-J result shows that the absolute value of bias is less than 15 mm in the
whole detector when taking TTS and DN into account, see Figures 16 (left) and it is not

20

0.150.100.050.000.050.100.15EpredEtrue, MeV020040060080010001200Number of events per bin0.150.100.050.000.050.100.15EpredEtrue, MeV050100150200250300350Number of events per bin=0.002 MeV=0.042 MeVFigure 16 – Heatmap of rrec − rtrue versus r3
true for all the testing data samples (left). Mean bias versus
r3
true for diﬀerent energies (right). The results are obtained with VGG-J taking TTS and DN into account.
Error bars correspond to the standard error of the mean. The plot on the right panel is oﬀset along X-axis
within ±40 m3 for better readability.

energy-dependent, see Figure 16 (right).

From Figure 16 (left), it is clear that the resolution is much better in the border region
of the detector (R3 > 4000 m3), than the inner region of the detector (R3 < 4000 m3). The
reason is that TTS of the NVVT PMTs is relatively large, and so the charge information
could provide more strict constraint on the vertex position than the ﬁrst hit time information
when the vertex is close to the PMTs. Therefore, we separate the JUNO detector into two
parts to evaluate the resolution, as shown in Figure 17 (left). The vertex resolution is about
8.0 cm at 1 MeV and decreases to 3.1 cm at 9 MeV for the border region of the detector,
while it is about 11.5 cm at 1 MeV and decreases to 4.2 cm at 9 MeV for the inner region
of the detector.

Figure 17 – Resolution of the vertex z-coordinate obtained with VGG-J taking TTS and DN into account
for diﬀerent part of the detector (left) and the resolution of the whole detector for diﬀerent TTS/DN options
(right). The plots are oﬀset along X-axis within ±0.06 MeV for better readability.

The inﬂuence of TTS and DN on the vertex reconstruction is shown in Figure 17 (right).
The results show that TTS is the main inﬂuencing factor leading to the worsening of ver-
tex resolution, while the DN impact is negligible, which is reasonable because the time

21

010002000300040005000r3true,m3−400−300−200−1000100200300400rrec−rtrue,mm20406080100120140010002000300040005000r3true,m3−20−15−10−505101520Meanbiasofrrec−rtrue,mmEvis,MeV2.0224.0226.0228.02210.022020406080100120Resoltion, mmR3<4000 m3R3>4000 m3All123456789Visible energy,  MeV010Bias, mm020406080100120Resoltion, mmDN off / TTS offDN off / TTS onDN on / TTS offDN on / TTS on123456789Visible energy,  MeV010Bias, mminformation, that is aﬀected by TTS, is exploited by vertex reconstruction the most.

Figure 18 – Resolution of the vertex radial component of DNN, BDT, ResNet-J and VGG-J models (upper
panel), ratio between VGG-J and ResNet-J resolution (middle panel), and bias for all the four models (lower
panel). The plots are oﬀset along X-axis within ±0.06 MeV for better readability.

In a more realistic case that takes TTS and DN into account, the performance com-
parison of the four models is shown in Figure 18. The PMT-wise measured information,
containing both the hit time and the number of photo-electrons, is of great help to the
vertex reconstruction because of its details, which also oﬀers a decisive advantage for algo-
rithms that use it. So it is not a surprise that VGG-J and ResNet-J can provide suﬃcient
resolution, while BDT and DNN with aggregated information can not.

Figure 18 (middle panel) shows the ratio of resolution between VGG-J and ResNet-J.
Generally, ResNet-J performs slightly better. ResNet-J and VGG-J introduce small bias,
and for the other models, the bias is within 25 mm (except one very ﬁrst point), as shown
in Figure 18 (lower panel). The conclusion is similar for other TTS/DN options.

4.3 Energy Reconstruction

To estimate energy resolution and bias we analyze the distribution of (Epred
Etrue)/Etrue.
Prior to analysis, a small fraction of outliers is trimmed away by excluding the values
deviating by more than three standard deviations from the mean value. This procedure
allows getting rid of events where a part of the energy is carried out by gammas leaking the
detector. The fraction of such events lies in the range from 0.3% to 0.5%.

−

Figure 19 shows how the performance of DNN degrades when taking TTS and DN into
account. Generally TTS does not make much impact on the energy resolution, while one
can see that DN signiﬁcantly aﬀects it. Bias is kept within 0.5% and increases with inclusion
of the electronics eﬀects. The other models share a similar behavior.

The performance comparison of BDT, DNN, ResNet-J, VGG-J and GNN-J is shown in

22

0100200300400Resoltion, mmDNNBDTResNet-JVGG-J1.01.1VGG-J/ResNet-J123456789Visible energy,  MeV500Bias, mmFigure 19 – Energy reconstruction performance: resolution (upper panel) and bias (lower panel) obtained
with DNN. The plots are oﬀset along X-axis within ±0.06 MeV for better readability. Note that the ﬁrst
point corresponds to 1.122 MeV (see explanation in Section 4.1).

Figure 20 for the realistic case that takes TTS and DN into account. In general the complex
models (ResNet-J, VGG-J and GNN-J) perform better. Their resolution is systematically
ﬁner than the one achieved with DNN and BDT. ResNet-J and VGG-J also yield the lowest
bias which lies within 0.15%, while for the other models it is within 0.4%.

Interestingly BDT and DNN, using much less input, exhibit almost the same resolution
as the complex models. However, even such a small gain obtained with CNNs and GNN is
crucial for JUNO.

4.4 Computation performance

BDT are known for their ability to train fast in terms of number of events. We have inves-
tigated how the accuracy degrades with lowering of the dataset size from default 5 millions
to 1 million and 100 thousands, see Figure 21. Although there is a diﬀerence between all the
three options for the ideal case (neglecting DN and TTS, not shown), for the most realistic
case taking TTS and DN into account there is no noticeable gain from using more than 1M
events. Table 7 shows typical number of trees (estimators), training time, prediction time
and memory usage for each BDT model trained on diﬀerent amounts of events and used for
the energy reconstruction.

100k

1M 5M

Number of trees
Training time, min
Prediction time, sec
Memory usage, MB

150
1
1
4

150
5
1
17

600
90
5
60

Table 7 – Typical training and prediction time, number of trees, memory usage for the BDT model.

Table 8 shows prediction and training time and memory usage for all the models studied

23

1.01.52.02.53.0Resoltion, %DN off / TTS offDN off / TTS onDN on / TTS offDN on / TTS on123456789Visible energy,  MeV0.00.5Bias, %Figure 20 – Energy reconstruction performance: resolution (upper panel) and bias (lower panel) obtained
with DNN, BDT, ResNet-J, VGG-J and GNN-J model taking TTS and DN into account. The plots are
oﬀset along X-axis within ±0.06 MeV for better readability. Note the ﬁrst point correspond to 1.1 MeV.

in this work. All the models except BDT were trained and run to yield predictions on NVidia
V100 graphical card. BDT, due to its minimalistic nature, was run on a laptop with Intel i5-
7300HQ CPU (2.5 GHz). Since the batch size aﬀects the prediction time and is individually
optimized for each model it is also presented in the table. Training time is highly aﬀected
by the choice of the stopping rule. It was not common for our models, so the numbers in
the table are listed only to give a rough idea and can not be used for a direct comparison.
Nonetheless, general conclusions can be drawn. The simple models are much faster and
are advised to be used for the tasks not requiring the ﬁnest possible resolution. BDT is
especially fast. The complex models require much more computational resources, GNN-J
being somewhat less demanding than ResNet-J and VGG-J.

5 Discussion

5.1 Fine-tuning with calibration data

JUNO experiment will include a calibration campaign [3]: diﬀerent radio-active sources will
be introduced into the detector volume at various positions to study the detector response.
A large calibration is planed to be performed before starting physics data taking to perform
the initial evaluation of the detector. Shorter calibrations will be performed regularly to
monitor changes in the detector response. The obtained information will be used to improve
the computer simulation of the detector.

Although the JUNO simulation will be made as realistic as possible, there is a chance
that the predictions of ML models trained exclusively on MC will be biased. In order to
ﬁne-tune ML models the calibration data may be used directly:

24

1.01.52.02.53.0Resoltion, %DNNBDTResNet-JVGG-JGNN-J1.01.11.2Ratio123456789Visible energy,  MeV0.250.000.25Bias, %Figure 21 – BDT performance for 100 thousand, 1 million and 5 million events in the training dataset. The
plots are oﬀset along X-axis within ±0.06 MeV for better readability.

Planar CNN

Spherical

Architecture

BDT

DNN

ResNet-J

VGG-J

GNN-J

Prediction time, sec/100k events
Prediction batch size
Number of weights
Memory occupied by weights, MB
Training time, min/1M events
Training batch size

<1
100 000

17
5

<1
100 000
6625
0.073
1000
700

235
100
38 352 403
146
1543
64

155
100
26 310 035
100
840
64

110
10 000
353 979
4.2
265
64

Table 8 – Prediction time and memory usage for diﬀerent models. BDT was run on an ordinary laptop,
while the other models were run on graphical card NVidia V100. The preparation of data is computationally
expensive, but since we did not undertake any eﬀorts for its optimization in some cases, it is not shown in
the table.

1. Train ML models on a large amount of Monte-Carlo data.

2. Check how biased are the predictions on the calibration data.

If the prediction quality is not acceptable:

3. Continue training on a half (or other fraction) of calibration data.

4. Verify its accuracy with the rest of calibration data.

It was shown [51] that such an approach could yield a good performance even when
trained on a small sample of data compared to the original Monte Carlo. The problem is
that neither the energy range nor the detector volume is fully covered by the calibration.
In other words, the data comes from a diﬀerent domain, compared to the data that the ML
model were trained on. In case ﬁne-tuning fails, there is a possibility to implement domain
adaptation techniques [52, 53] to overcome the domain shift and dataset bias problems.

25

1.01.52.02.53.03.5Resoltion, %100K1M5M123456789Visible energy,  MeV0.00.5Bias, %5.2 Prospects

We see several ways that could be used in order to improve the precision and the prediction
speed of the models.

The further research includes: adding extra feature variables as new input to DNN and
BDT methods; reducing the number of layers and parameters of VGG-J and ResNet-J to
trade-oﬀ between better reconstruction precision and fewer computing resources.

Another interesting possibility is to generalize the GNN-J model so that no spherical
discretization is used, by using a graph coarsening algorithm such as Graclus [54]. This
would enable us to use the data from PMTs directly without any need of aggregation to an
initial resolution, as it is done in the current implementation.

Currently, only the time of the ﬁrst hit is used. In [55] it was pointed out that, taking into
account the time of all hits should improve the precision of vertex reconstruction. Thus, the
precision of the waveform reconstruction providing charge and time information is highly
important, especially when it comes to the reconstruction of the time of all the hits in the
event. The application of machine learning techniques for the waveform reconstruction looks
promising in terms of precision and numerical performance.

To improve the performance of the energy reconstruction, extra information provided
by 25 600 3(cid:48)(cid:48) PMTs in the CD can be used. Special methods, both classical and ML, may
be used to remove the DN counts from the signal which may further reduce the energy
reconstruction uncertainty.

6 Conclusions

In this work we present several novel strategies of the event vertex and energy reconstruc-
tion in JUNO detector using several machine learning methods trained on Monte Carlo
simulation data. We have studied the following approaches: boosted decision trees (BDT),
deep neural networks (DNN) and a few kinds of convolution neural networks (CNN) includ-
ing graph neural network (GNN). After proper tuning we could achieve vertex and energy
resolution satisfying the requirements posed by the physical goals of the experiment.

The study takes into account the electronics eﬀects: the dark noise and the transition
time spread. The former one is found to be the main eﬀect worsening the performance of the
energy reconstruction while the latter one has the main eﬀect on the vertex reconstruction.
For the vertex reconstruction it was found to be crucial to provide PMT-wise infor-
mation to the model: the planar CNN models (ResNet-J and VGG-J) have 4 times better
performance than minimalistic models (BDT and DNN) working with several aggregated
features. The best achieved resolution of the vertex coordinates is around σx,y,z = 10 cm at
Evis = 1 MeV and decreases at higher energies.

The minimalistic models (BDT and DNN), two implementations of CNNs (ResNet-J and
VGG-J) and the spherical model GNN-J provide the energy resolution of around σE = 3%
at Evis = 1 MeV. However, the latter three show slightly better performance thanks to
PMT-wise input information.

We plan to continue improving the models: searching for new informative aggregated fea-
tures for DNN and BDT, optimizing the structure of ResNet-J and VGG-J, and developing
the no-projection version of GNN-J.

Future work will include the investigation of the applicability of the models trained
on the simulation data to the real data collected by the JUNO detector. Methods for the
inclusion of the calibration data will be studied.

26

7 Acknowledgements

We would like to thank Weidong Li, Jiaheng Zou, Tao Lin, Ziyan Deng, Guofu Cao and
Miao Yu for their tremendous contribution to the development of JUNO oﬄine software
and to Xiaomei Zhang and Jo˜ao Pedro Athayde Marcondes de Andr´e for the production of
the MC samples.

We are grateful to N. Kutovskiy, N. Balashov for providing an extensive IT support
and computing resources of JINR cloud services [56] and to D. Podgainy, O. Streltsova,
D. Belyakov, M. Matveev for providing the dedicated GPU-enabled queue on HybriLIT
platform (LIT, JINR) [57] for this work. CloudVeneto is acknowledged for the use of com-
puting and storage facilities. This research was supported in part through computational
resources of HPC facilities at NRU HSE. We also deeply appreciate the help from the Com-
puting Center of the Institute of High Energy Physics, Chinese Academy of Science for
providing the GPU resources.

This work is supported by the National Natural Science Foundation of China (No.
11805294, 11975021), the China Postdoctoral Science Foundation (2018M631013), the Strate-
gic Priority Research Program of Chinese Academy of Sciences (XDA10010900), the Fun-
damental Research Funds for the Central Universities, Sun Yat-sen University (19lgpy268).
Maxim Gonchar and Yury Malyshkin are supported by the Ministry of science and higher
education of the Russian Federation under the contract №075-15-2020-77. Vladislav Belavin,
Andrey Ustyuzhanin, and Fedor Ratnikov are supported by the Russian Science Foundation
under grant agreement №17-72-20127 for their work on DNN methods and their optimiza-
tion. Konstantin Treskov is supported by the grant №21-202-10 of JINR Association of
Young Scientists and Specialists.

References

[1] F. P. An et al. “Neutrino Physics with JUNO”. J. Phys. G43.3 (2016), p. 030401.

[2] T. Adam et al. “JUNO Conceptual Design Report” (2015).

[3] A. Abusleme et al. “Calibration Strategy of the JUNO Experiment” (2020).

[4] P. Baldi et al. “Searching for Exotic Particles in High-Energy Physics with Deep

Learning”. Nature Commun. 5 (2014), p. 4308.

[5] D. Guest et al. “Deep Learning and its Application to LHC Physics”. Ann. Rev. Nucl.

Part. Sci. 68 (2018), pp. 161–181.

[6] A. M. Terwilliger et al. “Vertex reconstruction of neutrino interactions using deep
learning”. 2017 International Joint Conference on Neural Networks (IJCNN). 2017,
pp. 2275–2281.

[7] S. Shirobokov et al. “Accelerating dark matter search in emulsion SHiP detector by

deep learning”. J. Phys. Conf. Ser. 1525.1 (2020), p. 012087.

[8] D. Guest et al. “Jet Flavor Classiﬁcation in High-Energy Physics with Deep Neural

Networks”. Phys. Rev. D 94.11 (2016), p. 112002.

[9] F. Rosenblatt. “The perceptron: a probabilistic model for information storage and

organization in the brain.” Psychol Rev. 65.6 (1958), p. 386.

[10] D. E. Rumelhart et al. “Learning Representations by Back-Propagating Errors”. Neu-

rocomputing: Foundations of Research. 1988, 696–699.

27

[11] Y. Bengio et al. “Greedy Layer-Wise Training of Deep Networks”. Proceedings of the
19th International Conference on Neural Information Processing Systems. NIPS’06.
2006, 153–160.

[12] R. Raina et al. “Large-Scale Deep Unsupervised Learning Using Graphics Processors”.
Proceedings of the 26th Annual International Conference on Machine Learning. ICML
’09. 2009, 873–880.

[13] X. T. Huang et al. “Oﬄine Data Processing Software for the JUNO Experiment”.

PoS ICHEP2016 (2017), p. 1051.

[14] J. Allison et al. “Recent developments in Geant4”. Nucl. Instrum. Meth. A 835 (2016),

pp. 186–225.

[15] K. J. Li et al. “GDML based geometry management system for oﬄine software in

JUNO”. Nucl. Instrum. Meth. A 908 (2018), pp. 43–48.

[16] S. Zhang et al. A method of sharing dynamic geometry information to study liquid-

based detectors. 2020.

[17] H. Q. Zhang et al. “Tested Performance of JUNO 20” PMTs”. J. Phys. Conf. Ser.

1468.1 (2020), p. 012197.

[18] Z. Y. You et al. “A ROOT Based Event Display Software for JUNO”. J. Instrum.

13.02 (2018), T02002.

[19] J. Zhu et al. “A method of detector and event visualization with Unity in JUNO”. J.

Instrum. 14.01 (2019), T01007–T01007.

[20] R. Quinlan. “Simplifying Decision Trees”. Int. J. Man-Mach. Stud. 27 (1987), pp. 221–

234.

[21] J. Friedman. “Greedy Function Approximation: A Gradient Boosting Machine”. Ann.

Stat. 29 (2001), pp. 1189–1232.

[22] J. H. Friedman. “Stochastic gradient boosting”. Comput. Stat. Data Anal. 38 (2002),

pp. 367–378.

[23] L. Breiman. “Random Forests”. Machine Learning 45.1 (2001), pp. 5–32.

[24] T. Chen and C. Guestrin. “XGBoost: A Scalable Tree Boosting System” (2016).

[25] F. Pedregosa et al. “Scikit-learn: Machine Learning in Python”. J. Machine Learning

Res. 12 (2011), pp. 2825–2830.

[26] M. Korobovand et al. ELI5. Software available from eli5.readthedocs.io.

[27] A. F. Agarap. “Deep Learning using Rectiﬁed Linear Units (ReLU)” (2019).

[28] P. Veliˆckovi´c. Multilayer Perceptron (MLP). 2016.

[29] L. N. Smith. “A disciplined approach to neural network hyper-parameters: Part 1 –

learning rate, batch size, momentum, and weight decay” (2018).

[30]

I. Loshchilov and F. Hutter. “SGDR: Stochastic Gradient Descent with Warm Restarts”
(2017).

[31] D. P. Kingma and J. Ba. “Adam: A Method for Stochastic Optimization” (2017).

[32] F. Y. Zou et al. A Suﬃcient Condition for Convergences of Adam and RMSProp.

2019.

[33] S. Mandt et al. Stochastic Gradient Descent as Approximate Bayesian Inference. 2018.

28

[34] J. L. Ba et al. “Layer Normalization” (2016).

[35] B. Silverman. Density Estimation for Statistics and Data Analysis. Chapman & Hall/CRC

Monographs on Statistics & Applied Probability. Taylor & Francis, 1986.

[36] D. Scott. Multivariate Density Estimation: Theory, Practice, and Visualization. Wiley

Series in Probability and Statistics. Wiley, 2015.

[37] Z. Lu et al. The Expressive Power of Neural Networks: A View from the Width. 2017.

[38] F. X. He et al. “Control Batch Size and Learning Rate to Generalize Well: Theoretical
and Empirical Evidence”. Adv. Neural Inf. Proc. Syst. Vol. 32. 2019, pp. 1143–1152.

[39] S. Lundberg and S.-I. Lee. A Uniﬁed Approach to Interpreting Model Predictions.

2017.

[40] W. Rawat and Z. H. Wang. “Deep Convolutional Neural Networks for Image Classiﬁ-
cation: A Comprehensive Review”. Neural Computation 29.9 (2017), pp. 2352–2449.

[41] A. Krizhevsky et al. “ImageNet Classiﬁcation with Deep Convolutional Neural Net-

works”. Adv. Neural Inf. Proc. Syst. Vol. 25. 2012, pp. 1097–1105.

[42] K. Simonyan and A. Zisserman. Very Deep Convolutional Networks for Large-Scale

Image Recognition. 2015.

[43] C. Szegedy et al. Going Deeper with Convolutions. 2014.

[44] K. M. He et al. Deep Residual Learning for Image Recognition. 2015.

[45] K. M. He and J. Sun. Convolutional Neural Networks at Constrained Time Cost. 2014.

[46] N. Perraudin et al. “DeepSphere: Eﬃcient spherical Convolutional Neural Network
with HEALPix sampling for cosmological applications”. Astron. Comput. 27 (2019),
pp. 130–146.

[47] K. M. G´orski et al. The HEALPix Primer. 2018.

[48] M. Deﬀerrard et al. Convolutional Neural Networks on Graphs with Fast Localized

Spectral Filtering. 2017.

[49] D. Grattarola and C. Alippi. Graph Neural Networks in TensorFlow and Keras with

Spektral. 2020.

[50] M. Adabi et al. TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems.

Software available from tensorﬂow.org. 2015.

[51] N. Tajbakhsh et al. “Convolutional Neural Networks for Medical Image Analysis:
Full Training or Fine Tuning?” IEEE Transactions on Medical Imaging 35.5 (2016),
1299–1312.

[52] Y. Ganin and V. Lempitsky. “Unsupervised Domain Adaptation by Backpropaga-
tion”. Proceedings of the 32nd International Conference on Machine Learning. Vol. 37.
Proceedings of Machine Learning Research. 2015, pp. 1180–1189.

[53] E. Tzeng et al. Adversarial Discriminative Domain Adaptation. 2017.

[54]

I. Dhillon et al. “Weighted Graph Cuts without Eigenvectors A Multilevel Approach”.
IEEE Transactions on Pattern Analysis and Machine Intelligence 29 (2007).

[55] C. Galbiati and K. McCarty. “Time and space reconstruction in optical, non-imaging,
scintillator-based particle detectors”. Nucl. Instrum. Meth. A 568 (2006), pp. 700–709.

29

[56] A. Baranov et al. “JINR cloud infrastructure evolution”. Phys. Part. Nucl. Lett. 13.5

(2016), pp. 672–675.

[57] G. Adam et al. “IT-ecosystem of the HybriLIT heterogeneous platform for high-performance
computing and training of IT-specialists”. Proceedings of the 8th Distributed Com-
puting and Grid-technologies in Science and Education Conference (2018). CEUR
Workshop Proceedings 2267. 2018.

30

