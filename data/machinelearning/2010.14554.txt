Anomaly Detection for Physics Analysis
and Less than Supervised Learning

Benjamin Nachman

Physics Division, Lawrence Berkeley National Laboratory, Berkeley, CA 94720, USA

Berkeley Institute for Data Science, University of California, Berkeley, CA 94720, USA

E-mail: bpnachman@lbl.gov

Abstract: Modern machine learning tools oﬀer exciting possibilities to qualitatively
change the paradigm for new particle searches. In particular, new methods can broaden
the search program by gaining sensitivity to unforeseen scenarios by learning directly from
data. There has been a signiﬁcant growth in new ideas and they are just starting to
be applied to experimental data. This chapter introduces these new anomaly detection
methods, which range from fully supervised algorithms to unsupervised, and include weakly
supervised methods.

0
2
0
2

t
c
O
7
2

]
h
p
-
p
e
h
[

1
v
4
5
5
4
1
.
0
1
0
2
:
v
i
X
r
a

 
 
 
 
 
 
Contents

1 Introduction

2 Model Dependence in HEP Data Analysis

3 Signal Independent, Background Model Dependent

4 Supervised Approaches

5 Unsupervised Approaches

6 Weak Supervision and Topic Modeling

7 Hybrid Approaches

8 Results with Collider Data

9 Conclusions and Outlook

1

2

5

6

6

7

10

13

14

1 Introduction

Searching for new particles and forces of nature is one of the main goals of High Energy
Physics (HEP). Despite hints for new fundamental structure, there has been no convincing
evidence since the discovery of the Higgs Boson in 2012 [1, 2]. All of the major HEP
experiments are engaged in an extensive search program and the goal of this chapter is to
explore the dependence of these eﬀorts on particular models and to examine how machine
learning may be able to signiﬁcantly broaden existing eﬀorts.

In particular, the main topic of this chapter is machine learning-based anomaly detec-
tion. An anomaly is an unexpected feature of the data and as such all searches for new
particles are anomaly detection analyses. The main feature of the searches described in
this chapter that separates them from others is the level of model dependence in various
parts of the analysis. In particular, this chapter will focus on searches that rely as little as
possible on signal and background models for both achieving sensitivity to new physics as
well as calibrating the background. This is in contrast to most dedicated searches that are
optimized with a particular signal model. All of these concepts will be made more precise
below.

This chapter is organized as follows. Section 2 introduces traditional searches for
new particles in HEP and how model dependence plays a role in the analysis development
and statistical procedure. The remaining sections review various types of machine learning-
based anomaly detection approaches. These sections are organized by how labeled examples

– 1 –

are (or are not) provided to train machine learning classiﬁers (supervision). In particular,
the chapter covers supervised learning (Sec. 3 and Sec. 4), unsupervised learning (Sec. 5),
weakly supervised learning (Sec. 6), and lastly hybrid approaches (Sec. 7). Recent results
from ATLAS and CMS are highlighted in Sec. 8 and the chapter ends with conclusions and
outlook in Sec. 9.

2 Model Dependence in HEP Data Analysis

A typical search for new phenomena begins by selecting a target model or class of models,
S. Then, simulations of the signal and simulations of the Standard Model (SM) background
B are performed. These simulations are used to inform the construction of a test statistic
λ that is based on features x
S + B)
|
is signiﬁcantly larger than Pr(λ > c
B). A combination of simulations and data-driven
|
methods are used to estimate these tail probabilities given the observed data. A discovery
is declared when the data are much more consistent with the S + B hypothesis than the
B-only hypothesis. If instead the data are more consistent with the B-only hypothesis,
then one can set limits on the production cross section of a hypothetical signal.

RN . A threshold c is chosen so that Pr(λ > c

∈

In this paradigm, models are used in two important ways. First, models of both S
and B are used to choose λ. In the absence of nuisance parameters and for a single signal
model, the Neyman-Pearson lemma [3] states that for a ﬁxed probability of rejecting the null
hypothesis when it is true (level), the probability for rejecting the null hypothesis when the
alternative is true (power) is maximized with the likelihood ratio test statistic. Typically,
λ is chosen manually by scanning features that are known to enhance the likelihood ratio.
A growing number of searches use various machine learning methods to strive for optimal
performance. Machine learning methods can also be used to extend beyond a ‘cut-and-
count’ approach to achieve an unbinned optimal test statistic [4]. When a search involves
proﬁling nuisance parameters or composite alternative hypotheses (multiple signal models),
there is no uniformly most powerful test statistic. In these cases, the likelihood ratio is still
a reasonable target and there are also a variety of inference-aware methods for achieving
optimality [5, 6].

S + B) and Pr(λ > c
Second, models are used to determine the p-values Pr(λ > c
|
|

B).
In some cases, simulations are used to directly estimate these probabilities using Monte
Carlo (MC) methods. In many cases, data are used as part of the density estimation. The
extent to which data can be used depends on assumptions about the background and the
signal in the targeted region of phase space. Even if the p-values are ultimately computed
entirely from data using parametric or non-parameteric methods, simulations often play a
key role in validating the assumptions that justify the data-based procedure or in deriving
method non-closure uncertainties.

One can categorize a search strategy by its S- and B-dependence for both the sig-
nal sensitivity and background speciﬁcity, as shown in Fig. 1. As described above, most
searches can be placed in the lower left part of Fig. 1(a) (signal sensitivity). Searches
with a clear signal hypothesis that can be accurately simulated, but with a complex or
hard-to-simulate background are found in the upper left part of Fig. 1(a). The searches

– 2 –

Figure 1. A graphic depicting the classiﬁcation of searches by their dependence on models of
the signal and Standard Model (SM) background for both (a) gaining signal sensitivity (choosing
the test statistic λ) and (b) calibrating the background p-values. The Model Unspeciﬁc Search
for New Physics (MUSiC) [7–9] and General Search [10–12] are results from the CMS and AT-
LAS Collaborations, respectively. LDA stands for Latent Dirichlet Allocation [13, 14], ANODE
stands for ANOmaly detection with Density Estimation [15], SALAD stands for Simulation Assisted
Likelihood-free Anomaly Detection [16] and CWoLa stands for Classiﬁcation Without Labels [17–
19]. Direct density estimation is a form of side-banding where the multidimensional feature space
density is learned conditional on the resonant feature. Figure reproduced from Ref. [15].

|

depicted in the lower right corner of Fig. 1(a) will be discussed further in Sec. 3 and the
remaining search strategies illustrated in the top right corner of Fig. 1(a) will be described
in Sec. 5, 6, and 7. The notion of optimality is more complicated for these anomaly detec-
tion approaches because there is no single signal model hypothesis. However, one can still
consider optimality in the context of a diﬀerent hypothesis test: data versus background.
B) be the density describing the background and pdata(x) be the density
Let pbackground(x
observed in a signal region. One can view anomaly detection as positing pbackground(x
B)
|
as the null hypothesis with pdata(x) as the alternative hypothesis. By construction, the
data are consistent with the alternative hypothesis, but this does not mean that the null
hypothesis can be rejected. As a simple hypothesis test, the Neyman-Pearson lemma guar-
antees that pbackground/pdata is the optimal test statistic. An anomaly detection technique
is deﬁned to be asymptotically optimal if there is some limit in which it approaches this
optimal test statistic. While many of the techniques in Sec. 6 and 7 are asymptotically
optimal, most of the methods presented in Sec. 5 are not.

Achieving signal sensitivity is not suﬃcient to produce a physics result – one must
also calibrate the background. Said another way, selecting anomalous events is irrelevant
if there is no context to provide information on their strangeness. Precise background

– 3 –

signal model independencebackground (SM) model independencesignal model independencebackground (SM) model independenceMUSiC (CMS), General Search (ATLAS)Some searches(train signal versus data)autoencodersCWoLaABCDControl region methodPure MC predictionANODE(a) Signal sensitivity(b) Background speciﬁcityMost searches(train with simulations)LDADirect Density estimation, SidebandSALADcalibration is a key diﬀerence in anomaly detection between industry and HEP. In the
former, anomalies are often oﬀ-manifold (e.g. a ﬂying elephant) instead of local over-
densities (e.g. more elephants than expected at a watering hole) and so it is less important
that the background rate be known precisely. A variety of common methods are highlighted
in Fig. 1(b). Pure MC estimation is reserved for ﬁnal states that are relatively simple
and precisely known theoretically and experimentally such as pure electroweak processes
with only charged leptons [20]. Many searches use the control region method whereby
simulations are calibrated using event selections that are close to the ﬁnal phase space,
but suﬃciently far away that the expected signal purity is low. The requirement on signal
purity introduces a dependence on the signal model. Two ‘fully data driven’ approaches
are the ABCD and sideband methods. In both approaches, the data are used directly to
transport predictions from a control region to the signal sensitive region instead of relying
on simulation for this extrapolation. In the ABCD method, two classiﬁers f and g and
two working points a and b are constructed and then four regions called A, B, C and D are
deﬁned by f ≶ a and g ≶ b (for a machine learning version of ABCD, see [21–23]). If f and
g are independent, then one can relate the background prediction in the region f > a and
g > b to the other three regions. The ABCD method depends on the background model
by verifying independence and on the signal model by verifying low signal contamination
in the sidebands. The sideband method requires knowledge of one feature where the signal
should be localized and the background is not localized. Regions away from the signal are
then deﬁned as sidebands and a ﬁt can be used to interpolate the background prediction
into the signal region. Resonant new physics is expected to be localized at the mass of
the new particle, so this is a moderately weak assumption. Relatively simple parametric
models are often used for the ﬁt, although machine learning approaches have also been
proposed for this purpose [15, 16, 24, 25].

A core requirement of the sideband method is that the background is not localized
where the potential signal should be localized. While this is generally true inclusively
because background processes are often non-resonant, machine learning classiﬁers can arti-
ﬁcially introduce localized features in the background. This often happens if a classiﬁer is
trained to distinguish a resonant signal from the SM background and a feature sensitive to
the mass of the new particle is used in the training. One can simply remove mass-sensitive
features from the training, but powerful classiﬁers can learn the mass indirectly through
subtle correlations with other useful features. A variety of decorrelation techniques exist
to solve this problem [21, 26–39]. In the context of neural networks, one can add terms to
the loss function to achieve automatic decorrelation:

(f ) =

L

(cid:88)

i

Lclassiﬁer(f (xi), yi) + α (1

−

yi)

Ldecorrelation(f (xi), mi),

(2.1)

≥

0 is a hyperparameter,

Lclassiﬁer is the usual classiﬁer loss such as binary cross
where α
entropy or mean squared error, f is the classiﬁer, x are the features, y are the labels
(y = 0 is background), and m is the feature that needs to be independent from f . In one
Ldecorrelation is itself a neural network [30] that is designed to learn m from f .
approach,

– 4 –

This adversarial method is optimized as a minimax solution whereby the second neural
network is as bad as possible when decorrelation is achieved. Another possibility is for1
Ldecorrelation to be a measure of dependence between f (x) and m such as the distance
correlation [33]. The later introduces only one free parameter (α) compared with thousands
of parameters in adversarial method, but may be less ﬂexible and can require large batches
during training. It is also possible to relax the decorrelation assumption by allowing for a
controlled dependence on m [39].

In practice, analyses can mix and match strategies from Fig. 1(a) and Fig. 1(b). Some
methods are naturally paired, such as those described in Sec. 6 and 7, as they were de-
veloped in the context of the sideband method. Decorrelation techniques that were ﬁrst
introduced for background estimation can also be important for signal sensitivity. The
interplay between independence and signal sensitivity is discussed in Sections 6 and 7.
The remainder of this chapter focuses on machine learning methods for achieving signal
sensitivity.

3 Signal Independent, Background Model Dependent

In some sense, all searches for physics beyond the Standard Model are anomaly detec-
tion analyses because anything discovered would be anomalous by deﬁnition. Further-
more, many searches publish ‘model-independent limits’. Such limits are signal model-
independent only in the cross-section, but are strongly signal model-dependent in the
acceptance. The rest of this chapter will instead focus on searches that do not target
a particular signal model, although they often target a class of models such as resonance
decays into a particular ﬁnal state. Many searches are relatively inclusive and not opti-
mized for a particular signal (e.g. the inclusive dijet search at the LHC [40, 41]). While
such searches are broadly sensitive, this chapter will not focus on them because they are
not actively optimized for sensitivity to new physics aside from general considerations (e.g.
avoid large rapidity gaps in the case of dijets). Signal model-independent searches have a
long history in HEP and have been performed by D0 [42–45], H1 [46, 47], ALEPH [48],
CDF [49–51], CMS [7–9, 9], and ATLAS [10–12]. The general strategy in these analyses is
to directly compare data with simulation in a large number of exclusive ﬁnal states (bins).
Recent proposals extend this methodology to be unbinned by using nearest neigh-
bors [52], cluster similarity [53] and neural networks [54, 55]. Another innovation in Ref. [54]
is the introduction of a new loss function that leads the neural network to learn the log
likelihood ratio directly:

(f ) =

L

(cid:88)

(1

i

−

yi)(ef (xi)

1)

−

−

yi f (xi).

(3.1)

In the asymptotic limit (suﬃcient training data and network/training ﬂexibility), one could
then interpret the neural network output as log likelihood ratio which has analytic formu-
Interpreting the output directly as a test statistic
lae for computing p-values [56–58].

1Technically, for the distance correlation, this loss is applied at the level of a batch because it requires

computing expectation values over pairs of events.

– 5 –

/ likelihood ratio estimator has also been used for a variety of other studies related to
simulation-based inference and domain adaptation [16, 59–69].

The approaches mentioned above are nearly signal model independent. The only sig-
nal model dependence is in the selection of the targeted phase space and analysis features.
This is particularly beneﬁcial for non-resonant new physics2, where there are fewer methods
available. However, there is a strong dependence on the background model. Any signiﬁ-
cant sources of mis-modeling in the background will be ﬂagged as anomalies. Therefore,
potential signals need to be larger than these mis-modelings and the false positive rate
must be calibrated to account for the expected deviations between data and simulation.

4 Supervised Approaches

The remainder of this chapter focuses on searches that do not use diﬀerences between
background simulations and data to directly achieve signal sensitivity. Many of the follow-
ing methods still heavily rely on background simulations for the most natural background
calibration method, but that is not discussed further here. In general, techniques can be
classiﬁed based on their level of supervision. Fully supervised approaches use data with
labels of signal and background for the yi in their loss functions. Unsupervised approaches
have no per-instance labels and must resort to other methods of identifying structure in
data. A variety of methods called weakly supervised are based on incomplete label infor-
mation and will be introduced in Sec. 6.

One strategy for supervised anomaly detection is to train with a signal simulation that
includes a variety of individual signal processes. This idea was explored in one of the ﬁrst
modern machine learning based anomaly detection procedures called anti-QCD tagging [37]
(see also [70]). Instead of using a discrete set of signal models [71], a signal dataset was
generated using ﬂat matrix elements. This means that there is no special energy scale in
the problem and there is broad coverage for all of the kinematic conﬁgurations that can
occur with a certain number of ﬁnal state objects. In this way, no particular signal masses
were preferred, but the classiﬁer was able to learn generic features of a large class of signal
models such as the number of prongs within a jet. A generic feature of anomaly detection
that was well-characterized in Ref. [37] is that these approaches are less sensitive than
dedicated searches for targeted signal models. However, anomaly detection methods can
be more sensitive than dedicated searches for non-targeted signal models.

5 Unsupervised Approaches

Unsupervised methods do not use per-instance labels. The strategy of these approaches is
to identify events that are unlike typical background events. One way to do this would be to
learn the density pbackground(x) and then consider events with pbackground(x)
1. Learning
high-dimensional densities is diﬃcult and so this has not yet been studied3. Instead, the
approaches that have been studied so far use compression methods (see also representation

(cid:28)

2This may not apply to cases of strong signal-background interference.
3Density estimation has been studied in the context of likelihood ratio estimation [15].

– 6 –

≈

≈

learning [72]). Two networks f and g encode and decode data, respectively. These networks
x. The target of f is regularized so
are trained to be near inverses of each other: f (g(x))
x should be common
that the compression is lossy. The idea is that events with f (g(x))
and thus ignored while events with f (g(x)) far from x are anomaly candidates. This
strategy has been studied in the context of autoencoders (AE) / variational autoencoders
(VAE [73, 74]) [75–81] and generative adversarial networks (GANs [82]) [83]. Figure 2
illustrates the method for vanilla autoencoders. The lossy compression is achieved by
limiting the expressivity of f and the dimensionality of f (x). Both f and g are trained
2. A classiﬁer is created using
at the same time when minimizing the loss
f (g(x))
|
the loss (‘reconstruction error’). Ideally, typical events should have a lower reconstruction
loss than events that were not used or at least minimally present in the training of the
autoencoder. This is explicitly demonstrated in the bottom plot of Figure 2, where the
more typical generic QCD jet processes have a much lower reconstruction loss than top
quark pair production or gluino production. Other strategies for regulating the latent
space are possible, such as requiring it to be of a particular form. Variational autoencoders
(VAEs) use this strategy, where the latent space is typically required to be a multivariate
Gaussian distribution. The anomaly detection based on a GAN presented in Ref. [83] is
conceptually similar to the way AEs are used for anomaly detection, but the model is
trained using a bidrectional GAN [84] instead of a variational autoencoder setup. Another
unsupervised approach using a clustering method was proposed in Ref. [85].

x
|

−

A challenge with unsupervised approaches is that the signal may not occupy regions
of low pbackground.
If instead, the signal is an overdensity in a region of relatively high
background probability density, then it may be well-reconstructed by compression meth-
ods. Additionally, a feature of some compression methods is that high reconstruction loss
may not necessarily correspond to low pbackground. For example, consider a vanilla au-
toencoder trained to compress two dimensions into one dimension. Further suppose that
the background is a bivariate Gaussian. A limited capacity network may simply learn
f (x0, x1) = ρ σ1
µ0) + µ1, where µi, σi are the mean and standard deviation of the
σ0
ith direction and ρ is the correlation coeﬃcient. This function is the minimum variance
unbiased estimator of x1 given x0. If the signal is also a Gaussian with mean far from the
line deﬁned by f (x), then it will have a poor reconstruction error. However, the signal
could also be on the line, but from the (µ0, µ1). This would correspond to a very low
pbackground, but also a low reconstruction error. Despite these challenges, AEs are popular
in HEP and beyond (see Ref. [86] and papers that cite it) and are suﬃciently generic that
they may be complementary to the approaches described in the next sections.

(x0 −

6 Weak Supervision and Topic Modeling

One challenge with the unsupervised methods in the previous section is that they do not
explicitly use the (potential) presence of signal in the data. This section will introduce
methods that make use of the presence of the signal by using supervised learning without
explicit per instance labels. One setting where this is possible is the case of mixed samples.
M1, each of which is a mixture of S and
M0 and
Suppose that there are two sets of data

– 7 –

Figure 2. An illustration of a vanilla autoencoder-based anomaly detection strategy. The top
diagram illustrates how the image of a jet is compressed and then restored with two neural networks.
2, which is higher for processes that were
The bottom plot is the reconstruction error
f (g(x))
|
|
not used or at least minimally present in the training of the autoencoder. Figure reproduced from
Ref. [75].

−

x

B. If the per-instance labels are known, then one can train a fully supervised classiﬁer.
However, if these sets are from real events, then per-instance labels are unknown. A variety
of weakly supervised methods have been developed for this setting [17, 87–89]. The ﬁrst of
these posited that the fractions t of signal in each dataset are known. Then, one can train
a weakly supervised classiﬁer:

fweak = argminf (cid:48):Rn→[0,1]L

(cid:32) N
(cid:88)

f (cid:48)(xi)

N −

i=1

(cid:33)
t

,

(6.1)

– 8 –

Figure1:Theschematicdiagramofanautoencoder.Theinputismappedintoalow(er)dimensionalrepresentation,inthiscase6-dim,andthendecoded.threshold.Forconcreteness,wewillfocusinthisworkondistinguishing“fat”QCDjetsfromothertypesofheavier,boostedresonancesdecayingtojets.Buildingonpreviousworkontoptagging[12],wewillconcentrateonmachinelearningalgorithmsthattakejetimagesasinputs.Forsignal,wewillconsiderall-hadronictopjets,aswellas400GeVgluinosdecayingto3jetsviaRPV.Obviously,thisisnotmeanttobeanexhaustivestudyofallpossiblebackgroundsandsignalsandmethodsbutisjustmeanttobeaproofofconcept.Theideaofautoencodersforanomalydetectionisfullygeneralandnotlimitedtothesesignals.Wewillcommentonotherformsofinputsinsection5.Moreovertherearemanyotheranomalydetectiontechniquesthatarenotbasedonautoencoderand/oronreconstruction(loss)whichareworthexploringinfuturework.Atthesametimeautoencodershavebeenrecentlyusedinotherhighenergyphysicsapplications:inpartonshowersimulation[28],forfeatureselectionofasupervisedclassiﬁcation[30],andforautomateddetectionofdetectoraberrationsinCMS[31].Wewillexplorevariousarchitecturesfortheautoencoder,fromsimpledenseneuralnetworkstoconvolutionalneuralnetworks(CNNs),aswellasashallowlinearrepresen-tationintheformofPrincipalComponentAnalysis(PCA).Wewillseethatwhiletheyarealle↵ectiveatimprovingS/Bbyfactorsof⇠10ormore,theyhaveimportantdif-ferences.ThereconstructionerrorsofthedenseandPCAautoencoderscorrelatemorehighlywithjetmass,leadingtogreaterS/Bimprovementforthe400GeVgluinoscom-paredtotheCNNautoencoder.Whilethismayseembetteratﬁrstglance,wediscusshowonemightwanttouseanautoencoderthatisdecorrelatedwithjetmass,inordertoobtaindata-drivenside-bandestimatesoftheQCDbackgroundandperformabumphuntinjetmass.Indeed,weshowhowcuttingonthereconstructionerroroftheCNNautoencoderresultsinstablejetmassdistributions,andweshowhowthiscanbeusedtoimproveS/Bbyafactorof⇠6inajetmassbumphuntforthe400GeVgluino2Figure2:DistributionofreconstructionerrorcomputedwithaCNNautoencoderontestsamplesofQCDbackground(gray)andtwosignals:tops(blue)and400GeVgluinos(orange).Weseethattheautoencoderworksasadvertised:itlearnstoreconstructtheQCDbackgroundthatithasbeentrainedon(tobeprecise,wetrainon100kQCDjetsandthenweevaluatetheautoencoderonaseparatesampleofQCDjets),anditfailstoreconstructthesignalsthatithasneverseenbefore.ThisisfurtherillustratedinFig.3,whichshowstheaverageQCD,topandgluinojetimagebeforeandafterautoencoderreconstruction.WeseebyeyethattheQCDimagesarereconstructedwellonaverage,whiletheotherscontainmoreerrors.ByslidingthereconstructionlossthresholdL>LSaround,wecanturnthehis-togramsinFig.2intoROCcurves.TheROCcurvesforthedi↵erentautoencoderarchitecturesareshowninFig.4forthetopandgluinosignals.ForcomparisonwehavealsoincludedtheROCcurveobtainedbycuttingonjetmassasananomalythreshold.Whilethethreearchitectureshavecomparableperformancesitiscleartherearesomeimportantdi↵erences.Fortops,theCNNoutperformstheothers,whileforgluinosthesituationislargelyreversed.Surprisingly,forgluinos,theCNNisevenoutperformedbythehumblePCAautoencoderatallbutthelowestsignale ciencies!Wewillex-plorethisinmoredetailinsection4.2,butaclueastowhat’sgoingonisshowninthecomparisonofthePCAROCcurvewiththejetmassROCcurve.Forgluinos,theytrackeachotherextremelyclosely,suggestingthatthePCAreconstructionerrorishighlycorrelatedwithjetmass.Wewillconﬁrmthisinsection4.2.Evidently,thePCAautoencoder(andtoalesserextentthedenseautoencoder)haslearnedtoreconstruct7which should be contrasted with the fully supervised case:

fsupervised = argminf (cid:48):Rn→[0,1]

N
(cid:88)

L

i=1

(cid:0)f (cid:48)(xi)

(cid:1) ,

yi

−

(6.2)

L

M0 from

where in both cases,
is a loss function such as mean squared error. This modiﬁcation to
the loss is eﬀective, but (a) requires signiﬁcant modiﬁcation to the learning setup (learn on
average instead of per-instance) and (b) requires the fractions to be known4. An alternative
approach is the Classiﬁcation without labels (CWoLa) [17] framework. In this setup, one
assigns labels to each event and then performs supervised learning with the assigned labels.
M0 are labeled 0 and all the events in
M1 are labeled 1. This
In particular, all events from
is illustrated in the left part of Fig. 3. One can show that if the CWoLa classiﬁer is optimal
M1, then it will be also optimal at distinguishing5 S from B.
for distinguishing
The right plot of Fig. 3 shows that the CWoLa classiﬁer achieves the same performance
as a fully supervised classiﬁer on a particular quark-jet versus gluon-jet classiﬁcation task.
This is particularly powerful because the fully supervised classiﬁer has per instance labels
yi while the CWoLa classiﬁer has far less information. Before proceeding, it is important
to consider the assumptions of the CWoLa method. Most importantly, this approach only
works if the diﬀerences between p(S
|M1) (similarly for the background) are
small compared to the diﬀerence between p(S
In other words, the
M1 should be statistically identical (and the same for the
M0 and
signal events from
background). The only other requirement is that the signal fractions should not be the
y1) so the closer the
same. The eﬀective statistics available to learn scale like nsignal(y0 −
fractions y0 and y1 are to each other, the worse the classiﬁcation performance will be. In
1, CWoLa simply approaches fully supervised classiﬁcation.
the limit y0 →
Note that in order to make the performance curve in Fig. 3, one needs at least a small
set of labeled examples or the class fractions. If one does not need to know the actual
performance, this is not necessary.

|M0) and p(B

|M0) and p(S

0 and y1 →

|M0).

A variety of related concepts have been introduced for similar purposes. The sPlot [90,
91] method learns to decompose a dataset into its constituent processes without per-
B) for at least a subset of the
S) and p(x
instance labels, but it requires knowing p(x
|
|
features. The topic modeling introduced in Ref. [92] and further studied in Ref. [92–95]
relaxes this requirement by extracting information directly from data using extreme re-
gions of phase space that are nearly pure S or B. Another variation that seeks to solve the
challenge of diﬀerent classes sharing common features is the Latent Dirichlet Allocation
(LDA) [13] approach to mixed-membership models in Ref. [14, 96].

There are many ways to combine the weakly supervised methods described above with
anomaly detection. One approach combines CWoLa with a bump hunt in a feature mres
as illustrated in Fig. 4. In particular, two mixed samples are constructed by using a signal
region around a hypothetical resonance and a sideband region. The sideband region should

4The label fractions need not be known exactly for optimal performance [89].
5If 0 ↔ 1, then one may learn to anti-tag the signal. This simply then requires that one know which of

M0 or M1 is expected to have a higher signal proportion.

– 9 –

Figure 3. The left diagram illustrates the setup of the CWoLa method and the right plot demon-
strates that the weakly supervised CWoLa can achieve the same performance as a fully supervised
classiﬁer trained with the same features. In the right plot, a better classiﬁer would be up and to the
right (gluon jet rejection is one minus the gluon jet eﬃciency). Figure reproduced from Ref. [17].

be as close as possible to the signal region in order to ensure that the background is nearly
the same in the two mixed samples. The other features used for training the CWoLa
classiﬁer need to be nearly independent of mres. The bottom plots in Fig. 4 illustrates
the performance of this ‘CWoLa hunting’ method to a dijet search at the LHC using the
dijet mass as mres and other jet substructure features to train the CWoLa classiﬁer. In the
absence of an injected signal, the p-values are consistent with uniform while when there
is signal injected, the initially 1.5σ excess is automatically enhanced to a 7σ potential
discovery. In order to make the most use of the data and to avoid a large trials factor, this
search involves a complex k-fold cross-training procedure. The look elsewhere eﬀect would
be signiﬁcant if the same data were used for training and applying the CWoLa classiﬁer
as local ﬂuctuations would be ampliﬁed. One way around this is to divide the data in half
and train one one part and test on the other. The local ﬂuctuations in both halves are
uncorrelated and thus there is no additional trails factor aside from the one in the scan of
mres. This procedure is extended to k-fold in Ref. [18, 19] to avoid using only half of the
data.

7 Hybrid Approaches

One of the main limitations of the CWoLa hunting method is that the features used
for training the CWoLa classiﬁer must be nearly independent of mres. One hybrid so-
lution proposed to mitigate this problem is ANODE [15]. In this method, one ﬁrst learns
psideband(x
m) from the signal region.
|
m) serves as an asymptot-
The ratio of the interpolated psideband(x
|
ically optimal likelihood ratio estimator. There have been signiﬁcant advances in direct
density estimation and the demonstration of ANODE in Ref. [15] makes use of masked

mres) in the sideband regions and then psignal region(x
mres) to psignal region(x

|

|

– 10 –

BSSSSSSSSBSSBSBSSBSBSSSSS(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:4)(cid:11)SBSBBSBBSBBBBBBBSBBSBBBSB(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:4)(cid:12)01(cid:1)(cid:2)(cid:3)(cid:4)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)Figure1.AnillustrationoftheCWoLaframework.Ratherthanbeingtrainedtodirectlyclassifysignal(S)frombackground(B),theclassiﬁeristrainedbystandardtechniquestodistinguishdataascomingeitherfromtheﬁrstorsecondmixedsample,labeledas0and1respectively.Noinformationaboutthesignal/backgroundlabelsorclassproportionsinthemixedsamplesisusedduringtraining.Theorem1.GivenmixedsamplesM1andM2deﬁnedintermsofpuresamplesSandBusingEqs.(2.3)and(2.4)withsignalfractionsf1>f2,anoptimalclassiﬁertrainedtodistinguishM1fromM2isalsooptimalfordistinguishingSfromB.Proof.TheoptimalclassiﬁertodistinguishexamplesdrawnfrompM1andpM2isthelikelihoodratioLM1/M2(~x)=pM1(~x)/pM2(~x).Similarly,theoptimalclassiﬁertodistinguishexamplesdrawnfrompSandpBisthelikelihoodratioLS/B(~x)=pS(~x)/pB(~x).WherepBhassupport,wecanrelatethesetwolikelihoodratiosalgebraically:LM1/M2=pM1pM2=f1pS+(1 f1)pBf2pS+(1 f2)pB=f1LS/B+(1 f1)f2LS/B+(1 f2),(2.6)whichisamonotonicallyincreasingrescalingofthelikelihoodLS/Baslongasf1>f2,since@LS/BLM1/M2=(f1 f2)/(f2LS/B f2+1)2>0.Iff1<f2,thenoneobtainsthereversedclassiﬁer.Therefore,LS/BandLM1/M2deﬁnethesameclassiﬁer.AnimportantfeatureofCWoLaisthat,unliketheLLP-styleweaksupervisioninSec.2.2,thelabelproportionsf1andf2arenotrequiredfortraining.Ofcourse,thisproofonlyguaranteesthattheoptimalclassiﬁerfromCWoLaisthesameastheoptimalclassiﬁerfromfully-supervisedlearning.WeexplorethepracticalperformanceofCWoLainSecs.3and4.Theproblemoflearningfromunknownmixedsamplescanbeshowntobemathematicallyequivalenttotheproblemoflearningwithasymmetricrandomlabelnoise,wheretherehavebeenrecentadvances[32,40].Theequivalenceoftheseframeworksfollowsfromthefactthat–5–0.00.10.20.30.40.5QuarkFractionf1(=1 f2)0.50.60.70.80.91.0AUCCWoLa:Ntrain=25000pp!H!q¯q/ggPythia8.183ps=13TeVmH=500GeV(a)0.00.10.20.30.40.5QuarkFractionf1(=1 f2)0.50.60.70.80.91.0AUCCWoLa:Ntrain=150000pp!H!q¯q/ggPythia8.183ps=13TeVmH=500GeV(b)Figure4.TrainingperformanceoftheCWoLamethodontwomixedsampleswithf1=1 f2quarkfraction.ShownaretherangeofAUCvaluesobtainedfrom10repetitionsoftrainingtheneuralnetworkon(a)25keventsand(b)150keventsfor10epochs.0.00.20.40.60.81.0QuarkSignalEfﬁciency0.00.20.40.60.81.0GluonBackgroundRejectionf1,f2=0.8,0.2pp!H!q¯q/ggPythia8.183ps=13TeVmH=500GeVDenseNetw.CWoLaMultiplicityWidthMasspDTLHA(a)0.00.20.40.60.81.0QuarkSignalEfﬁciency0.00.20.40.60.81.01.21.41.6SigniﬁcanceImprovementf1,f2=0.8,0.2pp!H!q¯q/ggPythia8.183ps=13TeVmH=500GeVDenseNetw.CWoLaMultiplicityWidthMasspDTLHA(b)Figure5.Quark/gluondiscriminationperformanceintermsof(a)ROCcurvesand(b)SIcurves.Shownareresultsforthedensenettrainedon150kpuresamples,andthenwithCWoLaonf1=80%versusf2=20%mixedsamples,aswellastheinputobservablesindividually.Theclassiﬁertrainedonthemixedsamplesachievessimilarperformancetotheclassiﬁertrainedonthepuresamples,withimprovementinperformanceovertheinputobservables.–12–Figure 4. Top: a schematic diagram illustrating the CWoLa setup for the anomaly detection task.
Bottom: ﬁgures reproduced from Ref. [18, 19] that show the application of the CWoLa hunting
method to the dijet search at the LHC. The bottom left plot is the dijet invariant mass with
the diﬀerent lines corresponding to increasingly tighter thresholds on the CWoLa classiﬁer. The
injected signal is many order of magnitude below the background. The bottom right plot shows
the extracted p-value for a scan in the signal region location. Without any injected signal, the
p-values are consistent with uniform while when there is signal injected, the initially 1.5σ excess is
automatically enhanced to a 7σ potential discovery.

autoregressive ﬂows [97], a type of normalizing ﬂow [98]. Density learning is unsupervised
because there are no labels and one typically learns p via a maximum likelihood loss func-
tion. The main challenge in direct density estimation is that one needs a neural network
that integrates to unity. In the normalizing ﬂows setting, this is accomplished by starting
with a known density (often a Gaussian) and then applying a series of variable changes

– 11 –

mresdN/dmresbackgroundsignalBSSSSSSSSBSSBSBSSBSBSSSSS(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:4)(cid:11)SBSBBSBBSBBBBBBBSBBSBBBSB(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:4)(cid:12)01(cid:1)(cid:2)(cid:3)(cid:4)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)Figure1.AnillustrationoftheCWoLaframework.Ratherthanbeingtrainedtodirectlyclassifysignal(S)frombackground(B),theclassiﬁeristrainedbystandardtechniquestodistinguishdataascomingeitherfromtheﬁrstorsecondmixedsample,labeledas0and1respectively.Noinformationaboutthesignal/backgroundlabelsorclassproportionsinthemixedsamplesisusedduringtraining.Theorem1.GivenmixedsamplesM1andM2deﬁnedintermsofpuresamplesSandBusingEqs.(2.3)and(2.4)withsignalfractionsf1>f2,anoptimalclassiﬁertrainedtodistinguishM1fromM2isalsooptimalfordistinguishingSfromB.Proof.TheoptimalclassiﬁertodistinguishexamplesdrawnfrompM1andpM2isthelikelihoodratioLM1/M2(~x)=pM1(~x)/pM2(~x).Similarly,theoptimalclassiﬁertodistinguishexamplesdrawnfrompSandpBisthelikelihoodratioLS/B(~x)=pS(~x)/pB(~x).WherepBhassupport,wecanrelatethesetwolikelihoodratiosalgebraically:LM1/M2=pM1pM2=f1pS+(1 f1)pBf2pS+(1 f2)pB=f1LS/B+(1 f1)f2LS/B+(1 f2),(2.6)whichisamonotonicallyincreasingrescalingofthelikelihoodLS/Baslongasf1>f2,since@LS/BLM1/M2=(f1 f2)/(f2LS/B f2+1)2>0.Iff1<f2,thenoneobtainsthereversedclassiﬁer.Therefore,LS/BandLM1/M2deﬁnethesameclassiﬁer.AnimportantfeatureofCWoLaisthat,unliketheLLP-styleweaksupervisioninSec.2.2,thelabelproportionsf1andf2arenotrequiredfortraining.Ofcourse,thisproofonlyguaranteesthattheoptimalclassiﬁerfromCWoLaisthesameastheoptimalclassiﬁerfromfully-supervisedlearning.WeexplorethepracticalperformanceofCWoLainSecs.3and4.Theproblemoflearningfromunknownmixedsamplescanbeshowntobemathematicallyequivalenttotheproblemoflearningwithasymmetricrandomlabelnoise,wheretherehavebeenrecentadvances[32,40].Theequivalenceoftheseframeworksfollowsfromthefactthat–5–BSSSSSSSSBSSBSBSSBSBSSSSS(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:4)(cid:11)SBSBBSBBSBBBBBBBSBBSBBBSB(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:4)(cid:12)01(cid:1)(cid:2)(cid:3)(cid:4)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)Figure1.AnillustrationoftheCWoLaframework.Ratherthanbeingtrainedtodirectlyclassifysignal(S)frombackground(B),theclassiﬁeristrainedbystandardtechniquestodistinguishdataascomingeitherfromtheﬁrstorsecondmixedsample,labeledas0and1respectively.Noinformationaboutthesignal/backgroundlabelsorclassproportionsinthemixedsamplesisusedduringtraining.Theorem1.GivenmixedsamplesM1andM2deﬁnedintermsofpuresamplesSandBusingEqs.(2.3)and(2.4)withsignalfractionsf1>f2,anoptimalclassiﬁertrainedtodistinguishM1fromM2isalsooptimalfordistinguishingSfromB.Proof.TheoptimalclassiﬁertodistinguishexamplesdrawnfrompM1andpM2isthelikelihoodratioLM1/M2(~x)=pM1(~x)/pM2(~x).Similarly,theoptimalclassiﬁertodistinguishexamplesdrawnfrompSandpBisthelikelihoodratioLS/B(~x)=pS(~x)/pB(~x).WherepBhassupport,wecanrelatethesetwolikelihoodratiosalgebraically:LM1/M2=pM1pM2=f1pS+(1 f1)pBf2pS+(1 f2)pB=f1LS/B+(1 f1)f2LS/B+(1 f2),(2.6)whichisamonotonicallyincreasingrescalingofthelikelihoodLS/Baslongasf1>f2,since@LS/BLM1/M2=(f1 f2)/(f2LS/B f2+1)2>0.Iff1<f2,thenoneobtainsthereversedclassiﬁer.Therefore,LS/BandLM1/M2deﬁnethesameclassiﬁer.AnimportantfeatureofCWoLaisthat,unliketheLLP-styleweaksupervisioninSec.2.2,thelabelproportionsf1andf2arenotrequiredfortraining.Ofcourse,thisproofonlyguaranteesthattheoptimalclassiﬁerfromCWoLaisthesameastheoptimalclassiﬁerfromfully-supervisedlearning.WeexplorethepracticalperformanceofCWoLainSecs.3and4.Theproblemoflearningfromunknownmixedsamplescanbeshowntobemathematicallyequivalenttotheproblemoflearningwithasymmetricrandomlabelnoise,wheretherehavebeenrecentadvances[32,40].Theequivalenceoftheseframeworksfollowsfromthefactthat–5–Other features20002500300035004000mJJ/GeV10 1100101102103104105106Events/100GeVSignalregionSidebandSideband25003000350010 1210 1010 810 610 410 2100p03 4 5 6 7 3 4 5 6 7 mJJ/GeVNosignal25003000350010%1%0.2%WithsignalFigure8.Left:mJJdistributionofdijetevents(includinginjectedsignal,indicatedbytheﬁlledhistogram)beforeandafterapplyingjetsubstructurecutsusingtheNNclassiﬁeroutputforthemJJ'3TeVmasshypothesis.Thedashedredlinesindicatetheﬁttothedatapointsoutsideofthesignalregion,withthegraybandsrepresentingtheﬁtuncertainties.Thetopdatasetistherawdijetdistributionwithnocutapplied,whilethesubsequentdatasetshavecutsappliedatthresholdswithe ciencyof10 1,10 2,2⇥10 3,and2⇥10 4.Right:Localp0-valuesforarangeofsignalmasshypothesesinthecasethatnosignalhasbeeninjected(left),andinthecasethata3TeVresonancesignalhasbeeninjected(right).Thedashedlinescorrespondtothecasewherenosubstructurecutisapplied,andthevarioussolidlinescorrespondtocutsontheclassiﬁeroutputwithe cienciesof10 1,10 2,and2⇥10 3.forms:processandkinematic.ProcesscorrelationsoccurwhenYdependsontheproductionchannel(e.g.pp!qqorpp!gg)andmJJalsodependsontheproductionchannel;kinematiccorrelationsarethecasewhenmJJiscorrelatedwithYgiventheprocess.ResidualprocesscorrelationsdonotcausebumpsbecausethemJJdistributionofeachprocesstype(asidefromsignal)issmoothlyfalling.Thus,eveniftheclassiﬁercanexactlypickoutoneprocess,nobumpswillbeartiﬁciallysculpted.ResidualkinematiccorrelationscouldcauseartiﬁciallybumpsinthemJJdistribution.Physically,kinematiccorrelationsoccurbecauseYiiscorrelatedwithpT,i.Onewaytoshowindatathatresidualkinematiccorrelationsarenegligibleistouseamixedsampleinwhichpairsofjetsfromdi↵erenteventsarecombined.Aslongasthepotentialsignalfractionissmall,thismixedsamplewillhavenoresonancepeak.WhilethefeatureschoseninthissectionweredesignedtobeuncorrelatedwithmJJandnotsculptbumps,itmaybepossibletoutilizecorrelatedfeaturesinamodiﬁedCWoLahuntingprocedurethatincludessystematicuncertaintiesforstrongresidualcorrelations.Weleavestudiesofthispossibilitytofuturework.Wecaninvestigatewhattheclassiﬁerhaslearntbylookingatthepropertiesofeventswhichhavebeenclassiﬁedassignal-like.Intheﬁrst(second)plotofFig.9,eventsinthesignal(sideband)regionhavebeenplottedontheplaneofthejetmassesoftheheavierjet(mJ,A)andthelighterjet(mJ,B).Afterbeingtrainedtodiscriminatetheeventsofthe–17–with tractable Jacobians. In ANODE, one never compares signal region and sideband re-
gion directly and so it is more robust to correlations between x and mres; in fact, mres
can be one of the dimensions of x. This is illustrated in Fig. 5, which shows that when
correlations are artiﬁcially introduced to spoil the CWoLa hunting approach, ANODE is
still able to provide signal sensitivity. With advances in neural density estimation (see e.g.
Neural Autoregressive Flows [99] and Neural Spline Flows [100]), it is likely that methods
like ANODE will continue to improve. A key diﬀerence for HEP compared to industrial
applications is that one needs quantitatively precise density estimation - it is not good
enough to produce examples that qualitatively look realistic (as in the case of cat and
celebrity pictures).

Figure 5. Top: the performance of CWoLa and ANODE classiﬁers on a dataset with artiﬁcial
correlations. The CWoLa classiﬁer learns a non-trivial function for signal region versus sideband
region and as a result has only random performance on the signal. In contrast, by learning the
numerator and denominator of the likelihood ratio separately, ANODE is more robust to such
correlations (but still worse than the dedicated fully supervised tagger). Figure reproduced from
Ref. [15].

Another hybrid solution is Simulation Assisted Likelihood-free Anomaly Detection
(SALAD) [16] (see also SA-CWoLa [101]). The motivation of this method is that while
simulations are only an approximation to nature, they do encode signiﬁcant physics infor-
mation that it would be useful to incorporate into a classiﬁer. To this end, a parameterized
m) is learned in sidebands and then
reweighting function w(x
|

m)/psimulation(x
|

pdata(x

m)
|

≈

– 12 –

Figure11.ROC(left)andSIC(right)curvesinthesignalregionusingtheshifteddatasetspeciﬁedbyEq.5.1.Figure12.ThesameasFig.8,butfortheshifteddataset.Inparticular,theseplotscomparethebackgroundpredictionfromtwodirectdensityestimationtechniqueswiththetruebackgroundyieldafterathresholdrequirementR(x|m)>Rc.–19–interpolated to the signal region [59]. Any classiﬁer can then be used to distinguish the
reweighted simulation in the signal region from the data in that region. If the reweighting
is eﬀective, the result should not depend on the simulation. At the same time, the closer
the initial simulation is to the data, the less reliant the method is on an eﬀective learning
and interpolation for w(x

A third hybrid method is Tag N’ Train (TNT) [102], which combined autoencoders
with CWoLa. The motivation is that in the original CWoLa hunting method, the two mixed
samples are nearly 100% of a single class (background) so as a ﬁrst step, a weak classiﬁer
(using an autoencoder - see Sec. 5) slightly puriﬁes the samples before using CWoLa to
train a more powerful classiﬁer. As discussed in Sec. 6, the purer the samples, the larger
the eﬀective statistics for the CWoLa training and thus the more powerful it will be as a
classiﬁer.

m).
|

It is likely that no one method will be able to cover every scenario and so a diversity
of approaches will be needed to ensure broad coverage. Mixing diﬀerent approaches may
provide further advantages over single algorithms using either entirely supervised or entirely
un/weakly supervised methods.

8 Results with Collider Data

This chapter will close with a highlight of two recent results from the CMS and ATLAS
Collaborations. Figure 6 presents the ﬁrst application of CWoLa6 in a physics analysis.
The CWoLa classiﬁer is used to distinguish generic multijet events from t¯t production and
uses two regions with
(10%) signal purity. The ultimate goal of this analysis is to study
the t¯t + b¯b process that is an inherently interesting probe of the strong force and is also
an important process for Higgs physics in the t¯t + h ﬁnal state. Multijet backgrounds are
exceptionally diﬃcult to simulate accurately and the CWoLa classiﬁer provides a solution to
train directly from data. While not an anomaly detection search, this analysis demonstrates
the feasibility of learning directly from unlabeled data.

O

The ﬁrst machine learning anomaly detection result with data is presented in Fig. 7
from the ATLAS Collaboration. This search made use of the CWoLa hunting approach
described in Sec. 6 and targets a dijet ﬁnal state. This ﬁnal state is complex and challeng-
ing to model, so data-driven methods are critical. When the jets are due to hadronically
decaying particles that are much lighter than the target resonance mass, their decay prod-
ucts will be collimated and fully contained inside single jets. The substructure of these jets
can be exploited to enhance the signal sensitivity.

As the ﬁrst search of its kind, a limited feature space (two-dimensional) was used
to help with the technical and sociological integration of this new methodology into the
experimental program. With a two-dimensional feature space, the classiﬁer output can
be directly visualized as an image. Examples of these images are shown in the top plots
of Fig. 7, where the automatic identiﬁcation of an injected signal is demonstrated. The
bottom plot of Fig. 7 shows that for particular models, the CWoLa hunting analysis is able
to set the strongest limits for particular models. One of the most interesting challenges

6See Ref. [94] for the ﬁrst measurement to study the related idea of topic modeling.

– 13 –

Figure 6. A CWoLa classiﬁer (Boosted Decision Tree) used to purify the t¯t + b¯b ﬁnal state by the
CMS Collaboration. Figures reproduced from Ref. [103].

that is like no other analysis is that the event selection depends on the data. This means
that for every injected signal model, for every signal strength, the entire CWoLa hunting
procedure has to be rerun. Aside from making it challenging to recast this analysis, a large
number of neural networks (

(104)) must be trained to produce Fig. 7.

While there is no evidence for new particles using machine learning methods, this is
only the beginning of an expanding program that will produce exciting physics results for
many years to come.

O

9 Conclusions and Outlook

Given the current lack of convincing evidence for new fundamental structure from HEP
experiments, it is critical that the program of dedicated searches be complemented with
more model agnostic methods. The methods presented in this chapter represent a snapshot7
of the rapidly developing area of machine learning for anomaly detection in HEP.

To help catalyze new ideas in anomaly detection for HEP8, the LHC Olympics 2020

7See Ref. [105] for a more updated list of papers in this area.
8A parallel eﬀort under development is described in Ref. [106]. This dataset is planned to be a concoction
of SM processes and uses high-level objects instead of low-level hadrons as in the LHC Olympics. While
the current plan does not include multiple generators to emulate ‘data’ and ‘simulation’, the large number

– 14 –

 QGLR110210310410510610710810910 Events / bin DataMultijetjjttccttbtt2bttbbttSmall bkgsStat uncert (13 TeV)-135.9 fbCMS00.20.40.60.81QGLR0.51.01.5      Data / sim CWoLa BDT 110210310410510610710810910 Events / bin DataMultijetjjttccttbtt2bttbbttSmall bkgsStat uncert (13 TeV)-135.9 fbCMS0.4-0.2-00.20.40.6CWoLa BDT 0.51.01.5      Data / simFigure 7. Plots from the recent CWoLa hunting search performed by the ATLAS Collabora-
tion [104]. The top two plots show the CWoLa classiﬁer output in one particular signal region on
the left with no injected signal and with an injected signal with masses indicated by the cross in
the right plot. The CWoLa classiﬁer is able to automatically identify the signal-like region. While
there was no signiﬁcant evidence for new particles in this ﬁrst search, the ATLAS Collaboration
has set limits on the production cross section for particular models.

was developed [107]. This data challenge sets up a realistic environment where there is
‘simulation’ and ‘data’, where both are generated on a computer, but possibly from diﬀerent
physics programs. Furthermore, the ‘data’ comes without labels and may contain some
amount of signal. A variety of methods have been deployed to these datasets, exposing

of events and heterogeneous composition of physics processes oﬀers an interesting complement to the LHC
Olympics.

– 15 –

0100200300400500m1 [GeV]0100200300400500m2 [GeV]ATLAS = 13 TeV, 139 fb1No Injected Signal103102101100Efficiency0100200300400500m1 [GeV]0100200300400500m2 [GeV]ATLAS = 13 TeV, 139 fb1mA=3000 GeVmB=400 GeVmC=80 GeVInjected Signal103102101100Efficiency(400,400)(400,200)(400,80)(200,200)(200,80)(80,80)(mB,mC) [GeV]051015202530354095% CL Exclusion Limit(ppABC) [fb]ATLAS = 13 TeV, 139 fb1=0.1,mA=3000 GeVObservedExpected±1 ±2 Dijet (2mpT<0.4)Dijet (2mpT>0.4)Diboson Searchinteresting features of the various procedures and helping to prepare for analysis with real
data. With the ﬁrst results from collider data presented in Sec. 8, the ﬁeld enters a new
era where methods must be adapted and modiﬁed to meet the needs of real data and new
methods must be developed to ensure broad coverage.

Addressing the conceptual, computational, and other challenges associated with the
growing ﬁeld of machine learning-assisted anomaly detection in HEP will make for an
exciting research programs in the years ahead.

Acknowledgments

This work was supported by the U.S. Department of Energy, Oﬃce of Science under con-
tract DE-AC02-05CH11231. I thank Kees Benkendorfer, Jack Collins, Aviv Cukierman,
Gregor Kasieczka, Luc Le Pottier, Pablo Mart´ın, and David Shih for countless discussions
about anomaly detection that have contributed to the framing presented in this chapter.
Furthermore, I thank Gregor Kasieczka for detailed comments on the manuscript. I also
thank Anders Andreassen, Patrick Komiske, Eric Metodiev, Matt Schwartz, and Jesse
Thaler for many helpful discussions about learning from mixed samples.

References

[1] CMS Collaboration, S. Chatrchyan et al., Observation of a New Boson at a Mass of 125

GeV with the CMS Experiment at the LHC, Phys. Lett. B 716 (2012) 30–61,
[arXiv:1207.7235].

[2] ATLAS Collaboration, G. Aad et al., Observation of a new particle in the search for the

Standard Model Higgs boson with the ATLAS detector at the LHC, Phys. Lett. B716 (2012)
1–29, [arXiv:1207.7214].

[3] J. Neyman and E. S. Pearson, On the problem of the most eﬃcient tests of statistical

hypotheses, Phil. Trans. R. Soc. Lond. A 231 (1933) 289.

[4] B. Nachman, A guide for deploying Deep Learning in LHC searches: How to achieve

optimality and account for uncertainty, SciPost Phys. 8 (2020) 090, [arXiv:1909.03081].

[5] P. De Castro and T. Dorigo, INFERNO: Inference-Aware Neural Optimisation, Comput.

Phys. Commun. 244 (2019) 170–179, [arXiv:1806.04743].

[6] S. Wunsch, S. J¨orger, R. Wolf, and G. Quast, Optimal statistical inference in the presence
of systematic uncertainties using neural network optimization based on binned Poisson
likelihoods with nuisance parameters, arXiv:2003.07186.

[7] CMS Collaboration, MUSiC, a Model Unspeciﬁc Search for New Physics, in pp Collisions

at √s = 8 TeV, CMS-PAS-EXO-14-016 (2017).

[8] CMS Collaboration, Model Unspeciﬁc Search for New Physics in pp Collisions at √s = 7

TeV, CMS-PAS-EXO-10-021 (2011).

[9] CMS Collaboration, MUSiC: a model unspeciﬁc search for new physics in proton-proton

collisions at √s = 13 TeV, arXiv:2010.02984.

– 16 –

[10] ATLAS Collaboration, M. Aaboud et al., A strategy for a general search for new
phenomena using data-derived signal regions and its application within the ATLAS
experiment, Eur. Phys. J. C79 (2019) 120, [arXiv:1807.07447].

[11] ATLAS Collaboration, A general search for new phenomena with the ATLAS detector in

pp collisions at √s = 8 TeV, ATLAS-CONF-2014-006 (Mar, 2014).

[12] ATLAS Collaboration, A general search for new phenomena with the ATLAS detector in

pp collisions at √s = 7 TeV, ATLAS-CONF-2012-107 (2012).

[13] D. M. Blei, A. Y. Ng, and M. I. Jordan, Latent dirichlet allocation, J. Mach. Learn. Res. 3

(Mar., 2003) 993–1022.

[14] B. M. Dillon, D. A. Faroughy, and J. F. Kamenik, Uncovering latent jet substructure, Phys.

Rev. D100 (2019), no. 5 056002, [arXiv:1904.04200].

[15] B. Nachman and D. Shih, Anomaly Detection with Density Estimation, Phys. Rev. D 101

(2020) 075042, [arXiv:2001.04990].

[16] A. Andreassen, B. Nachman, and D. Shih, Simulation Assisted Likelihood-free Anomaly

Detection, Phys. Rev. D 101 (2020), no. 9 095004, [arXiv:2001.05001].

[17] E. M. Metodiev, B. Nachman, and J. Thaler, Classiﬁcation without labels: Learning from

mixed samples in high energy physics, JHEP 10 (2017) 174, [arXiv:1708.02949].

[18] J. H. Collins, K. Howe, and B. Nachman, Anomaly Detection for Resonant New Physics

with Machine Learning, Phys. Rev. Lett. 121 (2018), no. 24 241803, [arXiv:1805.02664].

[19] J. H. Collins, K. Howe, and B. Nachman, Extending the search for new resonances with

machine learning, Phys. Rev. D99 (2019), no. 1 014038, [arXiv:1902.02634].

[20] ATLAS Collaboration, M. Aaboud et al., Search for heavy ZZ resonances in the (cid:96)+(cid:96)−(cid:96)+(cid:96)−
and (cid:96)+(cid:96)−ν ¯ν ﬁnal states using proton-proton collisions at √s = 13 TeV with the ATLAS
detector, Eur. Phys. J. C78 (2018), no. 4 293, [arXiv:1712.06386].

[21] G. Kasieczka, B. Nachman, M. D. Schwartz, and D. Shih, ABCDisCo: Automating the

ABCD Method with Machine Learning, arXiv:2007.14400.

[22] S. Choi, J. Lim, and H. Oh, Data-driven Estimation of Background Distribution through

Neural Autoregressive Flows, arXiv:2008.03636.

[23] ATLAS Collaboration, Search for Higgs boson decays into a Z boson and a light

hadronically decaying resonance using 13 TeV pp collision data from the ATLAS detector,
arXiv:2004.01678.

[24] M. Frate, K. Cranmer, S. Kalia, A. Vandenberg-Rodes, and D. Whiteson, Modeling Smooth

Backgrounds and Generic Localized Signals with Gaussian Processes, arXiv:1709.05681.

[25] R. Di Sipio, M. Faucci Giannelli, S. Ketabchi Haghighat, and S. Palazzo, DijetGAN: A

Generative-Adversarial Network Approach for the Simulation of QCD Dijet Events at the
LHC, JHEP 19 (2020) 110, [arXiv:1903.02433].

[26] G. Louppe, M. Kagan, and K. Cranmer, Learning to Pivot with Adversarial Networks,

Advances in Neural Information Processing Systems 30 (2017) [arXiv:1611.01046].

[27] J. Dolen, P. Harris, S. Marzani, S. Rappoccio, and N. Tran, Thinking outside the ROCs:
Designing Decorrelated Taggers (DDT) for jet substructure, JHEP 05 (2016) 156,
[arXiv:1603.00027].

– 17 –

[28] I. Moult, B. Nachman, and D. Neill, Convolved Substructure: Analytically Decorrelating Jet

Substructure Observables, JHEP 05 (2018) 002, [arXiv:1710.06859].

[29] J. Stevens and M. Williams, uBoost: A boosting method for producing uniform selection

eﬃciencies from multivariate classiﬁers, JINST 8 (2013) P12013, [arXiv:1305.7248].

[30] C. Shimmin, P. Sadowski, P. Baldi, E. Weik, D. Whiteson, E. Goul, and A. Sogaard,

Decorrelated Jet Substructure Tagging using Adversarial Neural Networks, Phys. Rev. D96
(2017), no. 7 074034, [arXiv:1703.03507].

[31] L. Bradshaw, R. K. Mishra, A. Mitridate, and B. Ostdiek, Mass Agnostic Jet Taggers,

SciPost Phys. 8 (2020), no. 1 011, [arXiv:1908.08959].

[32] ATLAS Collaboration, Performance of mass-decorrelated jet substructure observables for

hadronic two-body decay tagging in ATLAS, ATL-PHYS-PUB-2018-014 (2018).

[33] G. Kasieczka and D. Shih, Robust Jet Classiﬁers through Distance Correlation, Phys. Rev.

Lett. 125 (2020), no. 12 122001, [arXiv:2001.05310].

[34] L.-G. Xia, QBDT, a new boosting decision tree method with systematical uncertainties into

training for High Energy Physics, Nucl. Instrum. Meth. A930 (2019) 15–26,
[arXiv:1810.08387].

[35] C. Englert, P. Galler, P. Harris, and M. Spannowsky, Machine Learning Uncertainties with
Adversarial Neural Networks, Eur. Phys. J. C79 (2019), no. 1 4, [arXiv:1807.08763].

[36] S. Wunsch, S. J¨orger, R. Wolf, and G. Quast, Reducing the dependence of the neural

network function to systematic uncertainties in the input space, Comput. Softw. Big Sci. 4
(2020), no. 1 5, [arXiv:1907.11674].

[37] J. A. Aguilar-Saavedra, J. H. Collins, and R. K. Mishra, A generic anti-QCD jet tagger,

JHEP 11 (2017) 163, [arXiv:1709.01087].

[38] CMS Collaboration, Identiﬁcation of heavy, energetic, hadronically decaying particles using

machine-learning techniques, JINST 15 (2020), no. 06 P06005, [arXiv:2004.08262].

[39] O. Kitouni, B. Nachman, C. Weisser, and M. Williams, Enhancing searches for resonances

with machine learning and moment decomposition, arXiv:2010.09745.

[40] ATLAS Collaboration, Search for new resonances in mass distributions of jet pairs using
1 of pp collisions at √s = 13 TeV with the ATLAS detector, JHEP 03 (2020) 145,

139 fb−
[arXiv:1910.08447].

[41] CMS Collaboration, Search for high mass dijet resonances with a new background

prediction method in proton-proton collisions at √s = 13 TeV, JHEP 05 (2020) 033,
[arXiv:1911.03947].

[42] B. Knuteson, “A Quasi-Model-Independent Search for New High pT Physics at D0.” Ph.D.

thesis, University of California at Berkeley (2000).

[43] D0 Collaboration, B. Abbott et al., Search for new physics in eµX data at DØ using
Sherlock: A quasi model independent search strategy for new physics, Phys. Rev. D62
(2000) 092004, [hep-ex/0006011].

[44] D0 Collaboration, V. M. Abazov et al., A Quasi model independent search for new physics

at large transverse momentum, Phys. Rev. D64 (2001) 012004, [hep-ex/0011067].

[45] D0 Collaboration, B. Abbott et al., A quasi-model-independent search for new high pT

physics at DØ, Phys. Rev. Lett. 86 (2001) 3712–3717, [hep-ex/0011071].

– 18 –

[46] H1 Collaboration, F. D. Aaron et al., A General Search for New Phenomena at HERA,

Phys. Lett. B674 (2009) 257–268, [arXiv:0901.0507].

[47] H1 Collaboration, A. Aktas et al., A General search for new phenomena in ep scattering at

HERA, Phys. Lett. B602 (2004) 14–30, [hep-ex/0408044].

[48] K. S. Cranmer, Searching for new physics: Contributions to LEP and the LHC. PhD thesis,

Wisconsin U., Madison, 2005.

[49] CDF Collaboration, T. Aaltonen et al., Model-Independent and Quasi-Model-Independent
Search for New Physics at CDF, Phys. Rev. D78 (2008) 012002, [arXiv:0712.1311].

[50] CDF Collaboration, T. Aaltonen et al., Model-Independent Global Search for New

High-p(T) Physics at CDF, arXiv:0712.2534.

[51] CDF Collaboration, T. Aaltonen et al., Global Search for New Physics with 2.0 fb−

1 at

CDF, Phys. Rev. D79 (2009) 011101, [arXiv:0809.3781].

[52] A. De Simone and T. Jacques, Guiding New Physics Searches with Unsupervised Learning,

Eur. Phys. J. C79 (2019), no. 4 289, [arXiv:1807.06038].

[53] G. M. Alessandro Casa, Nonparametric semisupervised classiﬁcation for signal detection in

high energy physics, arXiv:1809.02977.

[54] R. T. D’Agnolo and A. Wulzer, Learning New Physics from a Machine, Phys. Rev. D99

(2019), no. 1 015014, [arXiv:1806.02350].

[55] R. T. D’Agnolo, G. Grosso, M. Pierini, A. Wulzer, and M. Zanetti, Learning Multivariate

New Physics, arXiv:1912.12155.

[56] S. S. Wilks, The large-sample distribution of the likelihood ratio for testing composite

hypotheses, Ann. Math. Statist. 9 (03, 1938) 60–62.

[57] G. Cowan, K. Cranmer, E. Gross, and O. Vitells, Asymptotic formulae for likelihood-based
tests of new physics, Eur. Phys. J. C 71 (2011) 1554, [arXiv:1007.1727]. [Erratum:
Eur.Phys.J.C 73, 2501 (2013)].

[58] A. Wald, Tests of statistical hypotheses concerning several parameters when the number of
observations is large, Transactions of the American Mathematical Society 54 (1943), no. 3
426–482.

[59] A. Andreassen and B. Nachman, Neural Networks for Full Phase-space Reweighting and
Parameter Tuning, Phys. Rev. D 101 (2020), no. 9 091901, [arXiv:1907.08209].

[60] M. Stoye, J. Brehmer, G. Louppe, J. Pavez, and K. Cranmer, Likelihood-free inference with

an improved cross-entropy estimator, arXiv:1808.00973.

[61] J. Hollingsworth and D. Whiteson, Resonance Searches with Machine Learned Likelihood

Ratios, arXiv:2002.04699.

[62] J. Brehmer, K. Cranmer, G. Louppe, and J. Pavez, Constraining Eﬀective Field Theories
with Machine Learning, Phys. Rev. Lett. 121 (2018), no. 11 111801, [arXiv:1805.00013].

[63] J. Brehmer, K. Cranmer, G. Louppe, and J. Pavez, A Guide to Constraining Eﬀective Field

Theories with Machine Learning, Phys. Rev. D98 (2018), no. 5 052004,
[arXiv:1805.00020].

[64] J. Brehmer, F. Kling, I. Espejo, and K. Cranmer, MadMiner: Machine learning-based

inference for particle physics, Comput. Softw. Big Sci. 4 (2020), no. 1 3,
[arXiv:1907.10621].

– 19 –

[65] J. Brehmer, G. Louppe, J. Pavez, and K. Cranmer, Mining gold from implicit models to

improve likelihood-free inference, Proc. Nat. Acad. Sci. (2020) 201915980,
[arXiv:1805.12244].

[66] K. Cranmer, J. Pavez, and G. Louppe, Approximating Likelihood Ratios with Calibrated

Discriminative Classiﬁers, arXiv:1506.02169.

[67] C. Badiali, F. Di Bello, G. Frattari, E. Gross, V. Ippolito, M. Kado, and J. Shlomi,

Eﬃciency Parameterization with Neural Networks, arXiv:2004.02665.

[68] A. Andreassen, P. T. Komiske, E. M. Metodiev, B. Nachman, and J. Thaler, OmniFold: A
Method to Simultaneously Unfold All Observables, Phys. Rev. Lett. 124 (2020), no. 18
182001, [arXiv:1911.09107].

[69] A. Andreassen, S. Hsu, B. Nachman, N. Suaysom, A. Suresh.

[70] J. Aguilar-Saavedra, F. Joaquim, and J. Seabra, Mass Unspeciﬁc Supervised Tagging

(MUST) for boosted jets, arXiv:2008.12792.

[71] C. K. Khosa and V. Sanz, Anomaly Awareness, arXiv:2007.14462.

[72] Y. Bengio, A. Courville, and P. Vincent, Representation learning: A review and new

perspectives, IEEE Trans. Pattern Anal. Mach. Intell. 35 (Aug., 2013) 1798–1828.

[73] D. P. Kingma and M. Welling, Auto-encoding variational bayes., in ICLR (Y. Bengio and

Y. LeCun, eds.), 2014.

[74] D. P. Kingma and M. Welling, An introduction to variational autoencoders, Foundations

and Trends® in Machine Learning 12 (2019), no. 4 307–392.

[75] M. Farina, Y. Nakai, and D. Shih, Searching for New Physics with Deep Autoencoders,

Phys. Rev. D 101 (2020), no. 7 075021, [arXiv:1808.08992].

[76] T. Heimel, G. Kasieczka, T. Plehn, and J. M. Thompson, QCD or What?, SciPost Phys. 6

(2019), no. 3 030, [arXiv:1808.08979].

[77] T. S. Roy and A. H. Vijay, A robust anomaly ﬁnder based on autoencoder,

arXiv:1903.02032.

[78] A. Blance, M. Spannowsky, and P. Waite, Adversarially-trained autoencoders for robust

unsupervised new physics searches, JHEP 10 (2019) 047, [arXiv:1905.10384].

[79] J. Hajer, Y.-Y. Li, T. Liu, and H. Wang, Novelty Detection Meets Collider Physics, Phys.

Rev. D 101 (2020), no. 7 076015, [arXiv:1807.10261].

[80] O. Cerri, T. Q. Nguyen, M. Pierini, M. Spiropulu, and J.-R. Vlimant, Variational

Autoencoders for New Physics Mining at the Large Hadron Collider, JHEP 05 (2019) 036,
[arXiv:1811.10276].

[81] T. Cheng, J.-F. Arguin, J. Leissner-Martin, J. Pilette, and T. Golling, Variational

Autoencoders for Anomalous Jet Tagging, arXiv:2007.01850.

[82] I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair,

A. Courville, and Y. Bengio, Generative adversarial nets, in Proceedings of the 27th
International Conference on Neural Information Processing Systems - Volume 2, NIPS’14,
(Cambridge, MA, USA), pp. 2672–2680, MIT Press, 2014.

[83] O. Knapp, G. Dissertori, O. Cerri, T. Q. Nguyen, J.-R. Vlimant, and M. Pierini,

Adversarially Learned Anomaly Detection on CMS Open Data: re-discovering the top
quark, arXiv:2005.01598.

– 20 –

[84] J. Donahue, P. Kr¨ahenb¨uhl, and T. Darrell, Adversarial feature learning, 2016.

[85] V. Mikuni and F. Canelli, Unsupervised clustering for collider physics, arXiv:2010.07106.

[86] M. A. Pimentel, D. A. Clifton, L. Clifton, and L. Tarassenko, A review of novelty detection,

Signal Processing 99 (2014) 215 – 249.

[87] L. M. Dery, B. Nachman, F. Rubbo, and A. Schwartzman, Weakly Supervised Classiﬁcation

in High Energy Physics, JHEP 05 (2017) 145, [arXiv:1702.00414].

[88] P. T. Komiske, E. M. Metodiev, B. Nachman, and M. D. Schwartz, Learning to classify
from impure samples with high-dimensional data, Phys. Rev. D 98 (2018), no. 1 011502,
[arXiv:1801.10158].

[89] T. Cohen, M. Freytsis, and B. Ostdiek, (Machine) Learning to Do More with Less, JHEP

02 (2018) 034, [arXiv:1706.09451].

[90] M. Pivk and F. R. Le Diberder, SPlot: A Statistical tool to unfold data distributions, Nucl.

Instrum. Meth. A 555 (2005) 356–369, [physics/0402083].

[91] M. Borisyak and N. Kazeev, Machine Learning on data with sPlot background subtraction,

JINST 14 (2019), no. 08 P08020, [arXiv:1905.11719].

[92] E. M. Metodiev and J. Thaler, Jet Topics: Disentangling Quarks and Gluons at Colliders,

Phys. Rev. Lett. 120 (2018), no. 24 241602, [arXiv:1802.00008].

[93] P. T. Komiske, E. M. Metodiev, and J. Thaler, An operational deﬁnition of quark and gluon

jets, JHEP 11 (2018) 059, [arXiv:1809.01140].

[94] ATLAS Collaboration, Properties of jet fragmentation using charged particles measured

with the ATLAS detector in pp collisions at √s = 13 TeV, Phys. Rev. D 100 (2019), no. 5
052011, [arXiv:1906.09254].

[95] E. Alvarez, F. Lamagna, and M. Szewc, Topic Model for four-top at the LHC, JHEP 01

(2020) 049, [arXiv:1911.09699].

[96] B. M. Dillon, D. A. Faroughy, J. F. Kamenik, and M. Szewc, Learning the latent structure

of collider events, arXiv:2005.12319.

[97] G. Papamakarios, T. Pavlakou, and I. Murray, Masked autoregressive ﬂow for density

estimation, in Advances in Neural Information Processing Systems 30 (I. Guyon, U. V.
Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, eds.),
pp. 2338–2347. Curran Associates, Inc., 2017.

[98] D. Rezende and S. Mohamed, Variational inference with normalizing ﬂows, vol. 37 of

Proceedings of Machine Learning Research, (Lille, France), pp. 1530–1538, PMLR, 07–09
Jul, 2015.

[99] C. Huang, D. Krueger, A. Lacoste, and A. C. Courville, Neural autoregressive ﬂows, CoRR

abs/1804.00779 (2018) [arXiv:1804.00779].

[100] C. Durkan, A. Bekasov, I. Murray, and G. Papamakarios, Neural spline ﬂows,

arXiv:1906.04032.

[101] L. L. P. K. Benkendorfer and B. Nachman, Simulation-Assisted Decorrelation for Resonant

Anomaly Detection, arXiv:2009.02205.

[102] O. Amram and C. M. Suarez, Tag N’ Train: A Technique to Train Improved Classiﬁers on

Unlabeled Data, arXiv:2002.12376.

– 21 –

[103] CMS Collaboration, Measurement of the t¯tb¯b production cross section in the all-jet ﬁnal

state in pp collisions at √s = 13 TeV, Phys. Lett. B 803 (2020) 135285,
[arXiv:1909.05306].

[104] ATLAS Collaboration, Dijet resonance search with weak supervision using √s = 13 TeV

pp collisions in the ATLAS detector, Phys. Rev. Lett. 125 (2020), no. 13 131801,
[arXiv:2005.02983].

[105] M. Feickert and B. Nachman, for the IML Working Group, A living review of machine

learning for particle physics, 2020. https://iml-wg.github.io/HEPML-LivingReview/.

[106] G. Brooijmans et al., Les Houches 2019 Physics at TeV Colliders: New Physics Working
Group Report, in 11th Les Houches Workshop on Physics at TeV Colliders: PhysTeV Les
Houches, 2, 2020. arXiv:2002.12220.

[107] G. Kasieczka, B. Nachman, and D. Shih, LHC Olympics 2020, 2020.

https://lhco2020.github.io/homepage/.

– 22 –

