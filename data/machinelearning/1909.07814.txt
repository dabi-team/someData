CRYPTFLOW: Secure TensorFlow Inference

Nishant Kumar∗
Microsoft Research
t-niskum@microsoft.com

Divya Gupta
Microsoft Research
digup@microsoft.com

Mayank Rathee∗
Microsoft Research
t-may@microsoft.com

Aseem Rastogi
Microsoft Research
aseemr@microsoft.com

Nishanth Chandran
Microsoft Research
nichandr@microsoft.com

Rahul Sharma
Microsoft Research
rahsha@microsoft.com

0
2
0
2

r
a

M
9
1

]

R
C
.
s
c
[

2
v
4
1
8
7
0
.
9
0
9
1
:
v
i
X
r
a

Abstract— We present CRYPTFLOW, a ﬁrst of its kind system
that converts TensorFlow inference code into Secure Multi-party
Computation (MPC) protocols at the push of a button. To do
this, we build three components. Our ﬁrst component, Athos, is
an end-to-end compiler from TensorFlow to a variety of semi-
honest MPC protocols. The second component, Porthos, is an
improved semi-honest 3-party protocol that provides signiﬁcant
speedups for TensorFlow like applications. Finally, to provide
malicious secure MPC protocols, our third component, Aramis,
is a novel technique that uses hardware with integrity guarantees
to convert any semi-honest MPC protocol into an MPC protocol
that provides malicious security. The malicious security of the
protocols output by Aramis relies on integrity of the hardware
and semi-honest security of MPC. Moreover, our system matches
the inference accuracy of plaintext TensorFlow.

We experimentally demonstrate the power of our system by
showing the secure inference of real-world neural networks such
as RESNET50 and DENSENET121 over the ImageNet dataset
with running times of about 30 seconds for semi-honest security
and under two minutes for malicious security. Prior work in the
area of secure inference has been limited to semi-honest security
of small networks over tiny datasets such as MNIST or CIFAR.
Even on MNIST/CIFAR, CRYPTFLOW outperforms prior work.

I. INTRODUCTION

Secure multiparty computation (or MPC) allows a set of mu-
tually distrusting parties to compute a publicly known function
on their secret inputs without revealing their inputs to each
other. This is done through the execution of a cryptographic
protocol which guarantees that the protocol participants learn
only the function output on their secret inputs and nothing else.
MPC has made rapid strides - from being a theoretical concept
three decades ago [82], [35], to now being on the threshold
of having real world impact. One of the most compelling
use cases for MPC is that of machine learning (ML) - e.g.
being able to execute inference over ML algorithms securely
when the model and the query are required to be hidden
from the participants in the protocol. There has been a ﬂurry
of recent works aimed at running inference securely with
MPC such as SecureML [62], MinioNN [55], ABY3 [60],
CHET [27], SecureNN [79], Gazelle [49], Delphi [58], and
so on. Unfortunately, these techniques are not easy-to-use by
ML developers and have only been demonstrated on small
deep neural networks (DNNs) on tiny datasets such as MNIST

∗ Equal contribution

or CIFAR. However, in order for MPC to be truly ubiquitous
for secure inference tasks, it must be both effortless to use and
capable of handling large ImageNet [31] scale DNNs.

In this work, we present CRYPTFLOW, a ﬁrst of its kind
system,
that converts TensorFlow [6] inference code into
MPC protocols at the push of a button. By converting code
in standard TensorFlow, a ubiquitous ML framework that
is used in production by various technology companies, to
MPC protocols, we signiﬁcantly lower the entry barrier for
ML practitioners and programmers to use cryptographic MPC
protocols in real world applications. We make the following
four contributions:

First, we provide a compiler, called Athos, from Ten-
sorFlow to a variety of secure computation protocols
(both 2 and 3 party) while preserving accuracy. In the
absence of Athos, all prior works require manually re-
implementing ML models in an MPC friendly low-level
language/library, and hence, their evaluations have been
limited to small benchmarks where this task is feasible.
Second, we provide a semi-honest secure 3-party compu-
tation protocol, Porthos, that outperforms all prior proto-
cols for secure inference and enables us to execute, for
the ﬁrst time, the inference of ImageNet scale networks
in about 30 seconds.
Third, assuming a minimally secure hardware which
guarantees the integrity of computations, we show a
novel technique, Aramis, that compiles any semi-honest
secure MPC protocol to a malicious secure MPC protocol.
Aramis only relies on these integrity checks and assumes
no conﬁdentiality guarantees for data residing within the
hardware. Aramis enables the ﬁrst implementations of
DNN inference secure against malicious adversaries.
Fourth, we demonstrate the ease-of-use, efﬁciency and
scalability of CRYPTFLOW by evaluating on
(a) RESNET50 [40], which won the ImageNet Large
Scale Visual Recognition Challenge in 2015 [31];
(b) DENSENET121 [43], a convolutional neural network
that won the best paper at CVPR 2017.
These networks have heavily inﬂuenced the ML com-
munity with thousands of citations each. To demonstrate
that CRYPTFLOW is immediately useful in healthcare, we

 
 
 
 
 
 
also evaluate CRYPTFLOW on DNNs used for prediction
of lung diseases and diabetic retinopathy.

Our toolchain and all of our benchmarks are publicly

available1.We now describe our results in more detail.

A. Results

CRYPTFLOW outperforms prior work on ease-of-use, scal-
ability, and efﬁciency. It automatically compiles TensorFlow
code to MPC protocols with no loss in classiﬁcation accuracy.
This makes CRYPTFLOW the ﬁrst secure inference system
to produce a Top 1 accuracy of 76.45% and Top 5 accuracy
of 93.23% for predictions running securely on the ImageNet
dataset. Furthermore, in the 3-party (3PC) setting, this can
be done in about 30 seconds with semi-honest security and
about 2 minutes with malicious security. Prior work in the
area of secure inference has been limited to small networks
over tiny datasets such as MNIST or CIFAR. Moreover,
these implementations are limited to security against weaker
semi-honest adversaries, that are assumed not to modify the
code of the MPC protocol. In contrast, our largest network
RESNET-200 has 200 layers, 65 million parameters, over 1000
ImageNet classes, and the user can choose between semi-
honest and malicious security – the latter also protects against
adversaries who can deviate from the MPC protocol speciﬁ-
cation arbitrarily. We have evaluated CRYPTFLOW on secure
inference over DNNs that are at least an order of magnitude
larger than the state-of-the-art [58], [27], [72], [79], [62], [49],
[19], [55], [60], [15], [71], [12]. Even on MNIST/CIFAR,
CRYPTFLOW has lower communication complexity and is
more efﬁcient than prior and concurrent works [79], [60],
[72], [12]. Furthermore, CRYPTFLOW is the ﬁrst system to
implement2 malicious security for secure DNN inference. We
show that the overhead of Aramis over semi-honest protocols
is small and varies between 25% and 3X depending on the size
of the computation. Moreover, by very conservative estimates,
Aramis based secure DNN inference is faster than state-of-the-
art malicious secure MPC inference protocols [4] by at least
an order of magnitude (and also the maliciously secure MPC
protocols for general computation [80], [81], [50]). Hence, on
inference tasks, prior MPC protocols are either much slower
to provide security against malicious
than Aramis or fail
adversaries.

B. Components of CRYPTFLOW

We describe the three components of CRYPTFLOW next.

Athos (Section III). Athos is a compiler that compiles
TensorFlow inference code to secure computation protocols.
There are several challenges in doing so. For optimizations
(Section III-D),
the compiler needs the dimensions of all
the tensors occurring in the dynamic Python code. The

1https://github.com/mpc-msri/EzPC
2ABY3 [60] provided a theoretical protocol to convert their semi-honest
protocol
into a malicious secure protocol on much smaller benchmarks
than CRYPTFLOW, but did not provide an implementation or experimental
validation.

compiler is designed to be modular (Section III-C) and it
provides facilities for plugging in various MPC protocols.
To demonstrate this modularity, we have implemented the
following backends: ABY-based 2-party computation (2PC),
Porthos-based semi-honest secure 3-party computation (3PC),
and Aramis-based malicious secure 3-party computation.

The transformations implemented in Athos are sensitive
to the performance of MPC protocols. For performance
reasons all efﬁcient secure computation protocols perform
computation over ﬁxed-point arithmetic - i.e., arithmetic over
integers or arithmetic with ﬁxed precision. This is in contrast
to TensorFlow where computations are over ﬂoating-point
values. Athos automatically converts TensorFlow code over
ﬂoating-point values into code that computes the same
function over ﬁxed-point values. This compilation is done
while matching the inference accuracy of ﬂoating-point code.
Prior works ([62], [55], [49], [60], [79], [58]) in the area
of running ML securely have performed this task by hand
with signiﬁcant losses in accuracy over ﬂoating-point code.
Although these ﬁxed-point conversions are feasible to do
manually for one or two small benchmarks, this task quickly
becomes intractable for large benchmarks and needs to be
repeated for every new benchmark. Athos automates this
tedious and error prone task.

(Section IV). Porthos

Porthos
is an improved semi-
honest 3-party secure computation protocol (tolerating one
corruption) that builds upon SecureNN [79]. Porthos makes
two crucial modiﬁcations to SecureNN. First, SecureNN
reduces convolutions to matrix multiplications and invokes
the Beaver triples [13] based matrix multiplication protocol.
When performing a convolution with ﬁlter size f × f on
a matrix of size m × m,
the communication is roughly
in the ring Z264 , where
2q2f 2 + 2f 2 + q2 elements
q = m − f + 1. Porthos computes these Beaver triples by
appropriately reshaping m × m and f × f matrices. This
reduces the communication to roughly 2m2 + 2f 2 + q2 ring
elements. Typically the ﬁlter size, f , is between 1 and 11 and
the communication of Porthos can be up to two orders of
magnitudes lower than SecureNN. Additionally, in SecureNN,
the protocols for non-linear layers (such as Rectiﬁed Linear
Units (ReLU) and MaxPool) require the third party to send
secret shares to the ﬁrst two parties. In Porthos, we cut this
communication to half by eliminating the communication
of one of these shares. This reduces the communication in
the overall ReLU and MaxPool protocols by 25%. Thus,
by reducing the communication in both linear convolution
layers and non-linear layers, the communication in Porthos is
several GBs lower than SecureNN (Table VIII).

Aramis (Section V). Obtaining maliciously secure MPC
protocols through cryptography can often be challenging
and expensive – typically some sort of “proof of honest
computation” must be provided by the parties for every step
of the protocol. We present a novel technique, called Aramis,
that compiles MPC protocols secure against semi-honest

adversaries into MPC protocols that are secure against
malicious adversaries, by leveraging secure hardware. We
only require the hardware to provide code attestation and a
secure signing functionality (that we use to sign and verify
the protocol messages). Aramis has two attractive features:
(a) it works in a strong adversarial threat model; and (b) it
serves as a general technique that can work on a variety of
semi-honest secure MPC protocols. In more detail:

(a) The threat model of Aramis is signiﬁcantly stronger than
the prior work on MPC using secure hardware [74], [69],
[38], [11], [23], [29], [51], [32], [77], [83], [44]. Specif-
ically, in our threat model, not only is the host operating
system outside the Trusted Computing Base, but it is
also allowed to observe the entire state of the hardware
(including user data). In contrast, for security of the
protocol, the prior works require that the hardware hides
the state from the host and even if data is decrypted and
computed upon inside the hardware, it cannot be viewed
by the host. In Section V, we describe the Aramis threat
model in more detail, formalize the secure hardware as
an ideal functionality, provide a formal description of
the malicious secure MPC protocols, and formally prove
their security. The ideal functionality can potentially be
realized using various hardware platforms that provide
code attestation and signing, e.g., STM32H7, MediaTek
MT3620, CEC1702, ARMTrustZone, Intel’s SGX, etc.
We provide a proof-of-concept implementation of Aramis
by using SGX as the underlying secure hardware.

(b) Aramis is general and can be applied to any semi-
honest secure MPC protocol. To demonstrate this, we
derive malicious secure MPC protocols from both semi-
honest GMW (2 party protocol) [35] and Porthos (3
party protocol). Porthos compiled with Aramis gives the
ﬁrst experimentally vetted maliciously secure protocol for
neural network inference with at most 3X overhead over
semi-honest security. While these were the semi-honest
protocols we applied Aramis to, one could potentially
obtain performant maliciously secure variants of several
other recent semi-honest secure inference protocols (e.g.
[49], [58], [7]), and MPC protocols for other applica-
tions [52], [47].

C. Organization of the paper

We provide an end-to-end walkthrough of our system to
illustrate the overall toolchain in Section II. In Section III,
we describe our compiler Athos. Section IV describes our
improved 3-party semi-honest secure protocol for neural net-
works. We describe Aramis that compiles any semi-honest
secure protocol into a malicious secure protocol, in Section V.
We present all our experimental results in Section VI, related
works in Section VII and conclude in Section VIII.

II. MOTIVATING EXAMPLE

In this section, we describe the end-to-end working of
CRYPTFLOW through an example of logistic regression. The

Fig. 1: CRYPTFLOW: End-to-end toolchain

# x is an MNIST image of shape (1,784).
# W and b are the model parameters.

print(tf.argmax(tf.matmul(x, W) + b, 1))

Fig. 2: Logistic Regression: TensorFlow snippet

high-level toolchain is shown in Figure 1. We describe how
code compilation happens from TensorFlow to MPC protocols.
The CRYPTFLOW toolchain takes as input code written in
vanilla TensorFlow. For example, consider the code snippet
for logistic regression over MNIST dataset in TensorFlow as
shown in Figure 2. Our compiler ﬁrst generates the Ten-
sorFlow graph dump (as shown in Figure 3a) as well as
metadata to help compute the dimensions of all the tensors
(Figure 3b). III-A provides more details on the frontend. Next,
the TensorFlow graph dump is compiled into a high-level
intermediate language HLIL. The code snippet for logistic
regression in HLIL is shown in Figure 4a. Next, Athos’ ﬂoat-
to-ﬁxed converter translates the ﬂoating-point HLIL code to
ﬁxed-point code in a low-level intermediate language LLIL.
This step requires Athos to compute the right precision to
be used for maximum accuracy (Section III-B). Figure 4b
shows the LLIL code snippet for logistic regression. The
function calls in this sequence can be implemented with a
variety of secure computation backends - e.g. ABY [30] for
the case of 2-party secure computation, Porthos for the case
of semi-honest 3-party secure computation (Section IV) and
Aramis (Section V) for the malicious secure variant. Different
backends provide different security guarantees and hence vary
in their performance. For this example, the three backends take
227ms, 6.5ms, and 10.2ms respectively.

III. ATHOS

Athos compiles ML inference code written in TensorFlow

to MPC protocols. It has the following main components:

Frontend. Athos frontend compiles TensorFlow code to a
high-level intermediate language (HLIL). HLIL supports
ﬂoating-point
tensors and sequence of function calls
(corresponding to the TensorFlow nodes) that manipu-
late tensors. The main challenge in the frontend is to

TensorFlowCode (Fig. 2)ABY[30]Porthos(Sec. IV)Aramis(Sec. V)Private inputsOutputsAthosMetadatagenerationFloat-to-fixedHLIL(Fig. 4a)LLIL(Fig. 4b)MPC protocol(Fig. 3)(Sec. III(B))LLILcompilationRuntimeNode

x
W
MatMul
b
MatAdd
ArgMax

Outgoing
dimensions

1 × 784
784 × 10
1 × 10
1 × 10
1 × 10
1 × 1

(b)

(a)

Fig. 3: Logistic Regression: (a) TensorFlow graph deﬁnition
(b) Metadata consisting of graph nodes and their outgoing
dimensions

xW = MatMul(x, W);
xWb = MatAdd(xW, b);
output(ArgMax(xWb));

(a)

//Assume Athos chooses
//15 bit precision

xW = MatMul(x, W);
ScaleDown(xW, 15);
xWb = MatAdd(xW, b);
output(ArgMax(xWb));

(b)

Fig. 4: Logistic Regression in (a) ﬂoating-point: HLIL syntax
(b) ﬁxed-point: LLIL syntax

reconcile dynamic typing in TensorFlow to static typing
in HLIL. TensorFlow code, written in Python, does not
have tensor dimensions, whereas our HLIL has explicit
tensor dimensions as it enables the compiler to perform
analyses and optimizations.

Float-to-ﬁxed converter. While ML models use ﬂoating-
point arithmetic, MPC protocols operate on ﬁxed-point
arithmetic. Rather than requiring the programmers to
manually convert (or re-train) their models to integers,
Athos performs the conversion automatically, without
compromising on the inference accuracy.

Modular LLIL. Athos compiles ﬂoating-point HLIL code
to ﬁxed-point code in a low-level intermediate language
(LLIL). LLIL is a C-like imperative language that sup-
ports integer tensors, loops, conditionals, and functions.
LLIL also makes it easier for different cryptographic
backends to be plugged into Athos. It precisely speciﬁes
the interface that it requires the cryptographic protocols to
implement, while providing a library for other operations.
The LLIL is compiled down to the MPC protocol code.

Optimizations. Athos implements MPC speciﬁc optimiza-
tions as well as several standard dataﬂow analyses and
compiler optimizations. The design of HLIL and LLIL,
and the choice of them being statically typed, is partly
motivated by the requirements of these analyses.

Below we explain each of these components in detail.

A. Frontend and HLIL

Athos frontend compiles the input TensorFlow models to
HLIL (described next) with explicit tensor dimensions. To
obtain these dimensions, the frontend ﬁrst runs TensorFlow
code on one dummy input and generates TensorFlow metadata
that has all the required information. The metadata is then
translated to HLIL.

We discuss some details of the frontend. A plain dump
of the TensorFlow metadata contains some nodes that are
semantically irrelevant for actual inference, e.g. identity,
assign, etc. To avoid representing these nodes in HLIL,
we ﬁrst prune the TensorFlow graph to remove such nodes,
speciﬁcally we use the TensorFlow graph transform tool [1]
for this purpose. Next, Athos desugars the remaining (tens
of) TensorFlow nodes to HLIL, while keeping the number
of functions in HLIL as small as possible. TensorFlow also
supports “broadcasting” [76] that allows operations on tensors
of incompatible dimensions and sizes. For example, due to
broadcasting, addition of a four-dimensional tensor with a one-
dimensional tensor is a valid operation. Athos frontend passes
the broadcasting information to HLIL, which then accounts
for it by compiling it to the appropriate LLIL library function
call.

Constant
Float constant
Type
Matrix
Expression
Program

n ::= 0 | 1 | 2 | . . .
r
ˆτ
ˆM ::= r | ˆM

::= n.n
::= float | int | ˆτ [n]

ˆe
ˆp

::= n | x | ˆM | ˆe1 ⊕ ˆe2 | x[ˆe]
::= void main () {ˆτ x ; f (ˆe)}

Fig. 5: HLIL syntax

Figure 5 shows the HLIL (we use r to denote sequences of
ﬂoating-point constants, and similarly for other syntactic cate-
gories). It is a simple language of ﬂoating-point tensors ( ˆM ),
with dimensions (n) and sizes as explicit type annotations
(ˆτ [n]), and the main is a sequence of variable declarations
and function calls.

We next discuss how Athos performs ﬂoat-to-ﬁxed conver-

sion on HLIL programs.

B. Float-to-ﬁxed

As observed earlier, most ML models are expressed using
ﬂoating-point, while MPC protocols operate on integers. For
large models, we cannot expect the programmers to manually
translate or re-train ﬂoating-point ML models to integer code
(the common approach in literature on secure inference [62],
[55], [49], [60], [79], [58], [72]). Furthermore, it is well-
known that ﬂoating-point operations are much more inefﬁcient
than ﬁxed-point when evaluated securely ([62], [60]) – we
re-conﬁrm this by performing two-party secure multiplica-
tion [28] using both ﬁxed-point and ﬂoating-point arithmetic
to showcase the difference. This is illustrated in Table I
which shows the huge overheads associated with ﬂoating-point
arithmetic. In future, if efﬁcient protocols for ﬂoating-point

xWMatMulMatAddbArgMaxOutputbecome available then we can directly compile HLIL to them,
but until then Athos automatically performs the translation.

The translation is parametrized by a scale parameter s
that determines the precision. We discuss how this scale is
set later in the section. Given a scale s ∈ Z, we deﬁne
a map ρs : R → Z2b
that maps Reals to b-bit integers:
ρs(r) = (cid:98)r · 2s(cid:99). We abuse notation and also apply ρs
to matrices M of Reals where the result
is a point-wise
application of ρs to each matrix element. In the output ﬁxed-
point code, every Real number r is represented by a b-bit
integer. The Real representation of an integer n is given by n
2s .
The ﬂoat-to-ﬁxed conversion (for select cases) is described in
the following algorithm (ScaleDown is described in Table II):

F (MatAdd(A, B, C)) = MatAdd(A, B, C)
F (MatMul(A, B, C)) = MatMul(A, B, C);
ScaleDown(C, s)

As an example of the conversion process, consider the
program M1 ∗ M2 that multiplies the row vector M1 =
[400.1, 200.1] with the column vector M2 = [0.3, 0.1]T .
Then in inﬁnite precision Real arithmetic the result of the
computation 400.1 ∗ 0.3 + 200.1 ∗ 0.1 is 140.04. Single-
precision ﬂoating-point arithmetic with 32 bits only has a 23-
bit mantissa and computes the approximately correct result
140.040009. We use 0.1f to denote the ﬂoating-point number
closest to the Real number 0.1. Given s = 24, F (M1 ∗ M2)
results into the following program over integers

(ρ24(400.1f ) ∗ ρ24(0.3f ) + ρ24(200.1f ) ∗ ρ24(0.1f )) >> 24

# Sequential Multiplications
1
10
100
1000

Fixed (ms)
2.57
4.88
21.65
199.6

Float (ms)
72.35
278.8
2735
25281.42

Overhead
28.11x
57.1x
126.34x
126.6x

TABLE I: Floating-point vs Fixed-point multiplication.

Next, suppose s is set

is far from 140.04. Here, low scale values have lead to loss
of signiﬁcant bits. In particular, 0.1 has been rounded to zero
causing an imprecise result. Ideally we want to set the scale to
a large value so that the integers have many signiﬁcant digits.
to a very high value, e.g., 60.
Then, the computation ρ60(400.1f ) ∗ ρ60(0.3f ) overﬂows 64-
bit integers and the result is garbage (multiplication of these
two large positive numbers would become a negative number).
Thus, scale can neither be very low nor very high; we need
to ﬁnd a sweet spot. To determine an appropriate value of s, we
sweep over all its possible values {0, 1, . . . , b − 1} and choose
the value that leads to the best accuracy. For the example
400.1f ∗ 0.3f + 200.1f ∗ 0.1f , the most accurate result is
obtained at s = 24. In general, machine learning algorithms
have a validation dataset
is used for hyperparameter
that
tuning. We consider scale as a hyperparameter and select the
scale that leads to a ﬁxed-point classiﬁer implementation that
performs the best on the validation set. The scale chosen by
Athos is a leakage function that depends on the weights of the
model. Athos gives a methodical way of picking this scale that
prior works did manually. Hence, leakage by Athos is similar
to all prior works on secure inference.

which results in the following computation with 64-bit integers

C. Modular LLIL

(6712564224 ∗ 3357121024 + 5033165 ∗ 1677721) >> 24

The ﬁnal result is 2349481329 that represents the real number
2349481329
= 140.040000021457672119140625 which is good
224
approximation of the desired result 140.04. Although it is
feasible to constuct examples where ﬁxed-point computations
can be imprecise, ML usually operates on normalized values
and we have observed that Athos does not lose accuracy in
practice (Table VI).

Athos, assigns the same bit-width b and the same scale
s to all network parameters. While we could use different
b and s, our experimental results show that same values for
all parameters works quite well in practice. We keep the scale
public for efﬁciency: division with 2s when s is secret is much
more expensive than when s is public. Moreover, scaling down
operations (division by 2s) cause loss of precision, as they lose
signiﬁcant bits, and hence need to be minimized. Therefore,
Athos scales down only once per matrix multiplication and
does not scale down matrix additions.

While we use machine integer width (64) for b, ﬁnding a
good value of s is difﬁcult. We explain the various tradeoffs
that govern the choice of s and then discuss our solution.

Suppose, in our example, s is set too low: s = 2. Then
F ([400.1f, 200.1f ]∗[0.3f, 0.1f ]) is (1600∗1+800∗0) >> 2,
which represents the Real number 400/4 = 100. This result

Constant
Type

n ::= 0 | 1 | 2 | . . .
::= int | τ [n]
τ

Matrix M ::= n | M

Expression
Statement

Global
Program

e
s

g
p

::= n | x | M | e1 ⊕ e2 | x[e]
::= τ x | x = e | for(x = e1; x < e2; x + +){s}
x[e1] = e2 | if(e, s1, s2} | s1; s2 | return e
f (e) | d (e)

|
|

::= extern τ d (τ x) | τ f (τ x){s}
::= g; void main () {s}

Fig. 6: LLIL syntax

Athos compiles HLIL to LLIL, a crypto-aware, C-like in-
termediate language that has only integer-valued tensors. Fig-
ure 6 shows the syntax of LLIL. This language has sufﬁcient
expressiveness required to implement ML inference tasks. In
particular it supports arrays, basic arithmetic, loops, branching,
functions, and extern declarations. LLIL makes the Athos
interface to the MPC cryptographic protocols explicit. We
observe that the tensor operations in a typical TensorFlow
code fall into two categories: those that do not change the
values but just copy the data around (e.g. squeeze to remove
dimensions of size 1 from a tensor, pad to pad a tensor
with various kinds of paddings, transpose to take the
transpose of a tensor, and concat to concatenate two tensors
into a single tensor), and those that compute new values.

For functions that do not manipulate shares (denoted by f ),
LLIL provides a library with their implementations that is
automatically added as a prelude to LLIL programs. Changing
the underlying crypto protocol does not require changes to
these library functions and this library can be used by all
crypto developers. These functions are implemented in LLIL
and are compiled to C++ code.

Share-manipulating functions (extern d) are required to
be implemented in the cryptographic backend. All a crypto
developer needs to do is to implement these functions, and
then she would be able to directly evaluate the protocols on
ML models used in practice. We describe these functions with
their signatures and intended semantics in Table II. Concretely,
we provide three implementations of these functions: using the
2PC protocols of ABY [30], 3PC protocols of SecureNN [79],
and Porthos (Section IV).

Finally, Athos compiles LLIL programs to C++ and links

them with the cryptographic MPC protocol implementation.

D. Optimizations

Athos intermediate languages are designed to be amenable
to static analysis. In particular, we have implemented several
standard dataﬂow analyses and compiler optimizations [8]:
reaching deﬁnitions, liveness analysis, and so on. These anal-
yses help with optimizing memory utilization and we have
observed savings reaching up to 80%. To demonstrate the ease
of implementing analyses and optimizations, we provide an
example each: (a) a peephole optimization ReLU MaxPool
Switching on HLIL to improve efﬁciency of DNNs that use
ReLU and MaxPool, and (b) an analysis Counting Scale Down
operations on LLIL to determine the number of scale down
operations done in order to prevent loss in accuracy (a similar
analysis was done manually in [62], [79], [60]).

1) ReLU MaxPool Switching: Most TensorFlow developers
have adopted the convention of expressing DNN layers us-
ing the MaxPool(ReLU(·)) idiom. For protocols like Porthos
and SecureNN [79] that reduce ReLU and MaxPool to se-
cure comparison protocols, ReLU(MaxPool(·)) can be much
more efﬁcient than MaxPool(ReLU(·)) as this signiﬁcantly
reduces the number of comparisons. As opposed to SecureNN,
where this was done manually, we have built a peephole
optimization pass on HLIL that
replaces occurrences of
MaxPool(a, b, ReLU(A)); with ReLU(MaxPool(a, b, A));. For
example, if the input matrix A has dimensions 112 × 112 × 64
and we compute a MaxPool with 2 × 2 windows. Then, the
output matrix has dimensions 56 × 56 × 64. Hence, the latter
needs to compute only one fourth the number of ReLUs
compared to the former. In this case, the optimized code is
over 3× better in communication and over 2× faster in our
experimental setup (Section VI).

2) Counting Scale Down operations: We describe an anal-
ysis to count the number of scale down operations in an LLIL
code. The analysis uses an environment ρ that maps tensors
to the number of elements they contain. This environment
is populated using variable declarations in the code. The
analysis makes a single pass over main and for each call

ScaleDown(A, s) accumulates ρ(A) into a counter. The ﬁnal
value of the counter provides the number of scale down
operations in the code.

Note that this analysis is easy to describe as the LLIL code
contains dimensions of all the tensors explicitly. Hence, the
compiler can statically populate ρ. This analysis is impossible
to perform on the TensorFlow Python code as the sizes of
tensors are unknown at compile time.

IV. PORTHOS

We now describe Porthos, our improved secure 3PC proto-
col that provides semi-honest security against one corrupted
party and privacy against one malicious corruption. The notion
of privacy against malicious corruption (introduced by Araki
et al. [10]) informally guarantees that privacy of inputs hold
even against malicious party as long as none of the parties par-
ticipating in the protocol learn the output of the computation
(this is relevant, for example, when computation is ofﬂoaded to
servers). Porthos builds upon SecureNN [79] but makes crucial
modiﬁcations to reduce communication. We ﬁrst describe our
protocols that reduce communication and summarize concrete
improvements in Table III.

We reduce communication for both linear as well as non-
linear layers of DNNs. Linear layers include fully connected
layers as well as convolutional
layers. We improve the
communication for convolutional layers and our optimization
gains get better with larger ﬁlter sizes. With regards to
non-linear layers (ReLU and MaxPool), we modify how two
of the protocols in SecureNN are used – ComputeMSB and
ShareConvert. As we explain below, this directly translates
to better communication for both ReLU and MaxPool
computations. At a very high level, we trade communication
with compute by modifying the way certain shares are
generated in the protocol.

In

secure

SecureNN,

Convolution.
of
convolutional layers is done by reducing them to a (larger)
2-dimensional
matrix multiplication. As
convolution of a 3 × 3 input matrix X (with single input
channel and stride 1) with a ﬁlter Y of size 2 × 2 reduces to
a matrix multiplication as follows:

computation

example,

an





Conv2d





x1 x2 x3
x4 x5 x6
x7 x8 x9



 ,

(cid:20)y1
y3



(cid:21)
 =

y2
y4







x1 x2 x4 x5
x2 x3 x5 x6
x4 x5 x7 x8
x5 x6 x8 x9







×













y1
y2
y3
y4

In the above matrix multiplication, we call the left matrix
(derived from X) as the “reshaped input” (say, X (cid:48)) and the
right matrix (derived from Y ) as the “reshaped ﬁlter” (say, Y (cid:48)).
The matrix multiplication is computed securely using a matrix
Beaver triple [13], [62] based protocol. Later, the output can
be reshaped to get the output of convolution in correct shape.

MatMul(int[L][M] A, int[M][N] B, int[L][N] C) Multiply two tensors A and B and store results in C
MatAdd(int[L][M] A, int[L][M] B, int[L][M] C)
Conv(int[H][W][CI] A, int[FH][FW][CI][CO] F)
Avg/Max Pool(a, b, int[H][W][C] A)
ArgMax(int[M] A)
FusedBatchNorm(int[K][L][M][N] A, int[N] B, int[N] C)
ReLU(int[M][N] A)
ScaleDown(int[M][N] A, k)

Add two tensors A and B into C
Convolve a tensor A with ﬁlter F
Apply a stencil that computes the average/max value in windows of size a × b of tensor A.
Compute the index with maximum value in A
Returns ∀k, l, m, n.B[n] × A[k][l][m][n] + C[n]
Returns ∀i, j.Max(A[i][j], 0)
Arithmetic right shift each entry of A with k.

TABLE II: Share manipulating functions. These have been simpliﬁed for exposition by suppressing parameters such as padding
and strides. For comprehensive signatures, see https://www.tensorﬂow.org/api docs/python/tf/.

In this protocol, matrices being multiplied are masked by
random matrices of same size and communicated and hence,
the communication grows with the size of the matrices. We
observe that this is quite wasteful for convolution because the
reshaped input image (the ﬁrst matrix in multiplication) has
many duplicated entries (e.g., x2 in row 1 and row 2) that get
masked by independent random values. Let size of X be m×m
and size of Y be f × f . Then, the size of X (cid:48) is q2 × f 2, where
q = m − f + 1. In Porthos, we optimize the size of matrix-
based Beaver triples for convolution by exploiting the structure
of re-use of elements as the ﬁlter moves across the image. At
a high level, we pick random matrix of size matching X for
masking and communication only grows with size of X (i.e.,
m2) instead of X (cid:48) (i.e., q2f 2) in SecureNN.

0 and (cid:104)x(cid:105)t

0 = r and (cid:104)x(cid:105)t

Before, we describe our optimized protocol, we set up some
notation. Let (cid:104)x(cid:105)t
1 denote the two shares of a 2-out-
of-2 additive secret sharing of x over Zt – in more detail, pick
r $←− Zt, set (cid:104)x(cid:105)t
1 = x − r (mod t). (cid:104)x(cid:105)t denotes
a sharing of x over Zt. Reconstruction of a value x from its
shares x0 and x1 is simply x0 + x1 over Zt. This generalizes
to larger dimensions - e.g. for the m × n matrix X, (cid:104)X(cid:105)t
0 and
(cid:104)X(cid:105)t
1 denote the matrices that are created by secret sharing the
elements of X component-wise (other matrix notation such as
Reconstt(X0, X1) are similarly deﬁned).

j , (cid:104)Y (cid:105)L
0 into (cid:104)X (cid:48)(cid:105)L

Let Conv2dm,f denote a convolutional layer with input
m × m, 1 input channel, a ﬁlter of size f × f , and 1
output channel. Our protocol for Conv2dm,f is described
in Algorithm 1, where L = 2(cid:96), (cid:96) = 64. Algorithms
ReshapeInput, ReshapeFilter and ReshapeOutput are used to
reshape input, ﬁlter and output as described above and are
formally described in Appendix A. Parties P0 and P1 start
with shares of input matrix X and ﬁlter Y over ZL That is,
Pj holds ((cid:104)X(cid:105)L
j ) for j ∈ {0, 1}. In SecureNN, P0 ﬁrst
reshapes (cid:104)X(cid:105)L
0 by running ReshapeInput. Then, it
0 of same size as X (cid:48) and sends
picks a random matrix (cid:104)A(cid:48)(cid:105)L
(cid:104)E(cid:48)(cid:105)L
0 to P1 that requires communicating
q2f 2 elements. In Porthos, we optimize this as follows: P0
picks a random matrix (cid:104)A(cid:105)L
0 of same size as X (Step 1) and
sends (cid:104)E(cid:105)L
0 to P1 (Step 4) that requires
communicating m2 elements only. Later, parties can reshape
E locally to get E(cid:48). We reduce the communication by P1 in
a symmetric manner. Concretely, we reduce communication
from (2q2f 2 + 2f 2 + q2)(cid:96) in SecureNN to (2m2 + 2f 2 + q2)(cid:96).
This algorithm can be easily generalized to the setting where
there are i input ﬁlters, o output ﬁlters, and different stride

0 = (cid:104)X(cid:105)L

0 = (cid:104)X (cid:48)(cid:105)L

0 − (cid:104)A(cid:48)(cid:105)L

0 − (cid:104)A(cid:105)L

and padding parameters.

0 ) and P1 holds ((cid:104)X(cid:105)L

0 , (cid:104)Y (cid:105)L
, Y ∈ Zf ×f
L .

Algorithm 1 3PC protocol for Conv2dm,f
Input: P0 holds ((cid:104)X(cid:105)L
where X ∈ Zm×m
L
Output: P0
gets
(cid:104)Conv2dm,f (X, Y )(cid:105)L
1 .
Common Randomness: P0 & P1 hold shares of a zero matrix
U of dimension q×q, q = m−f +1 . P0 & P2 hold a common
PRF key k0, and P1 & P2 hold a common PRF key k1.

(cid:104)Conv2dm,f (X, Y )(cid:105)L
0

1 , (cid:104)Y (cid:105)L

and P1

gets

1 ),

(cid:104)A(cid:105)L

(cid:104)A(cid:105)L

, (cid:104)B(cid:105)L

1) P0 & P2 use PRF key k0 to generate random matrices
0 ∈ Zf ×f
L
2) P1 & P2 use PRF key k1 to generate random matrices

0 ∈ Zm×m
L

0 ∈ Zq×q
L .

and (cid:104)C(cid:105)L

and (cid:104)B(cid:105)L

1 ∈ Zm×m
L
3) P2 computes A = (cid:104)A(cid:105)L

1 ∈ Zf ×f
L .
0 + (cid:104)B(cid:105)L
1 and B = (cid:104)B(cid:105)L
0 + (cid:104)A(cid:105)L
1 .
Let A(cid:48) = ReshapeInput(A) and B(cid:48) = ReshapeFilter(B).
1 = A(cid:48) · B(cid:48) − (cid:104)C(cid:105)L
P2 computes (cid:104)C(cid:105)L
0 and sends it to P1.
j − (cid:104)A(cid:105)L
j and

4) For j ∈ {0, 1}, Pj computes (cid:104)E(cid:105)L
j − (cid:104)B(cid:105)L

j and sends to Pj⊕1.

j = (cid:104)X(cid:105)L

j = (cid:104)Y (cid:105)L

(cid:104)F (cid:105)L

j

∈

{0, 1}, Pj
j ), E(cid:48)

5) P0 & P1 reconstruct E and F using exchanged shares.
(cid:104)X (cid:48)(cid:105)L
=
6) For
j
ReshapeInput(E),
j ), F (cid:48) = ReshapeFilter(F ).
j = −jE(cid:48) ·F (cid:48) +(cid:104)X (cid:48)(cid:105)L
j ·

ReshapeInput((cid:104)X(cid:105)L
(cid:104)Y (cid:48)(cid:105)L

j = ReshapeFilter((cid:104)Y (cid:105)L
7) For j ∈ {0, 1}, Pj computes (cid:104)Z (cid:48)(cid:105)L
j + (cid:104)U (cid:105)L
j .
{0, 1}, Pj

F (cid:48) + E(cid:48) · (cid:104)Y (cid:48)(cid:105)L
j

computes
=

j + (cid:104)C(cid:105)L

(cid:104)Z(cid:105)L
j

=

outputs

8) For

∈

ReshapeOutput((cid:104)Z (cid:48)(cid:105)L

j ).

Activation Functions. In SecureNN protocols for computing
activations such as ReLU and MaxPool start with parties P0
and P1 having shares of values over L = 264. For both of
these, parties run a protocol called ComputeMSB to evaluate
most signiﬁcant bit (MSB) of secret values. This protocol
require shares over L − 1. So parties run a protocol called
ShareConvert to convert shares over L to shares over L − 1.
Both protocols ComputeMSB and ShareConvert require P2 to
send fresh shares of a value to P0 and P1. In SecureNN, both
of these shares were picked by P2 and explicitly communi-
cated to P0 and P1. As mentioned before, shares of a value x
are r and x − r, where r is a appropriately picked uniformly
random value. We observe that since one of the shares is truly
random, it can be computed as the output of a shared PRF
key between P2 and one of the parties, say P0. This cuts
the communication of this step to half. Moreover, since many

Protocol
Conv2dm,i,f,o
ShareConvert
ComputeMSB
ReLU
MaxPooln

Communication (SecureNN)
(2q2f 2i + 2f 2oi + q2o)(cid:96)
4(cid:96) log p + 6(cid:96)
4(cid:96) log p + 13(cid:96)
8(cid:96) log p + 24(cid:96)
(8(cid:96) log p + 29(cid:96))(n − 1)

Communication (Porthos)
(2m2i + 2f 2oi + q2o)(cid:96)
3(cid:96) log p + 5(cid:96)
3(cid:96) log p + 9(cid:96)
6(cid:96) log p + 19(cid:96)
(6(cid:96) log p + 24(cid:96))(n − 1)

TABLE III: Communication complexity of protocols; q = m−
f + 1 and log p = 8.

activations are computed in parallel, we can carefully “load-
balance” this optimization between P0 and P1 to reduce the
communication to half on the critical path. We implement
this load-balance optimization and observe that this reduces
the overall communication of ShareConvert, ComputeMSB,
ReLU and MaxPool by 25%.

The revised table with comparison of overall communi-
cation complexity of all protocols with improvements over
SecureNN are provided in Table III. Conv2dm,i,f,o denotes a
convolutional layer with input m×m, i input channels, a ﬁlter
of size f × f , and o output channels. MaxPooln computes the
maximum value out of a list of n elements. p denotes a prime
value strictly larger than 65 (set to 67 in SecureNN), with 8
bits being used to represent elements in Zp (hence log p = 8
in the table).

V. ARAMIS

In this section, we describe Aramis, a general technique to
convert any semi-honest secure MPC protocol into a secure
MPC protocol tolerating malicious corruptions by relying on
secure hardware. The threshold of corrupted parties tolerated
by the semi-honest protocol
is retained in the malicious
secure protocol by our technique.

Threat Model. We consider a strong threat model where not
only does the adversary control the operating system of the
corrupted parties (i.e., the host operating system is outside the
Trusted Computing Base) but also observes the entire state
of their secure hardware. Aramis makes a very minimal trust
assumption of integrity on hardware, namely that of code
attestation (the outputs generated by the hardware are indeed
from the code that it attested to). This implicitly requires the
hardware to possess a trusted component that can produce
signatures and this signature scheme cannot be forged by
the adversary. However, the adversary can see the state (i.e.,
all the code and the user data) of the hardware belonging to
the corrupted parties, i.e., we do not assume conﬁdentiality
of state. Prior works [74], [69], [38], [11], [23], [29], [51],
[32], [77], [83], [44] that combine MPC and hardware (SGX)
make stronger trust assumption on the hardware of both
conﬁdentiality and integrity, and hence, provide security only
in a weaker threat model where the hardware hides the data
residing in it from the adversary.

Overview. At a very high level, Aramis exploits the following
(well-known) observation: in order for a semi-honest protocol
to be made maliciously secure, one must ensure that all

messages sent by every party Pi are computed honestly
according to the speciﬁcation of the semi-honest protocol
consistent with Pi’s input and the transcript so far. The next
observation we make is that if party Pi possesses hardware
whose code can be attested by party Pj (and vice-versa),
then Pj can obtain guarantees on the correctness of protocol
messages sent by Pi as long as these messages are computed
and signed by Pi’s hardware. Using these observations, we
can convert a semi-honest secure protocol into one that is
maliciously secure by having every protocol message of Pi
be computed by the trusted hardware that Pi executes. We
shall now describe our techniques in more detail. We ﬁrst
describe the ideal functionality that is assumed out of the
hardware in Section V-A. We then describe our technique
in Section V-B. Finally, we provide an implementation of
Aramis using Intel SGX as the underlying secure hardware.
We explain how Intel SGX can realize the ideal functionality
in Section V-C and challenges in porting semi-honest MPC
protocols to SGX in Section V-D.

A. The attestation ideal functionality Fattest

Description. We formally deﬁne the ideal functionality for
attested executions in Figure 7. The functionality is parameter-
ized by a signing key pair (vk, sk). Let Signsk(m) denote the
signing algorithm on message m and Verifyvk(m, σ) denote
veriﬁcation of signature σ on message m. At a high level,
this functionality allows users to specify a function g to the
ideal functionality once using the Commit command. The
functionality returns a token Tg generated as Signsk(H(g)),
where H is a collision resistant hash function. Note that
this token is publicly veriﬁable given g and vk. Let statectr
be an internal state that the functionality maintains, indexed
by ctr – this state can be maintained by signing it along
with ctr and verifying the signature of the state on every
input message. When the functionality Fattest is initialized, the
initial state state0 is empty (or, (cid:15)). Subsequent invocations
of the functionality is done on input wctr using the Compute
command. The function g is a deterministic mapping from
(ctr, wctr, rctr, statectr−1) to (yctr, statectr), where rctr is the
required randomness. The functionality picks randomness rctr,
evaluates g and provide a signature on the function output
yctr using the signing key sk. Furthermore, (yctr, statectr) is
always given to party P such that statectr contains rctr in clear
and this ensures that there is no information hidden from P
and we only assume correct execution of g. That is, the ideal
functionality can evaluate functions and provide signed outputs
and these outputs could have anyway been computed by party
P given knowledge of g, wctr, rctr, ctr, statectr, which are all
known to P . Thereby, we only assume that the functionality
will sign the output of g on the appropriate input and not hide
any data from P . This signiﬁcantly weakens what is assumed
from the trusted hardware.

B. Semi-honest security to malicious security

Our technique takes any semi-honest secure MPC protocol
in

into a malicious secure MPC protocol

and converts it

Fattest interacts with a party P .

Functionality F (vk,sk)

attest

outputs ⊥. Note that statectr−1 already contains input xi,
the input of party Pi.

On input message (Commit, g) from P ,
1) Record (Commit, state0), where state0 = (cid:15);
2) Send (state0, Tg) to P , where Tg = Signsk(H(g)).
3) Ignore further (Commit, g) messages.
from P ,
On
rctr
retrieve
and
obtain
(yctr, statectr) such that statectr contains (yctr, rctr). Send
(yctr, ctr, Signsk(yctr||ctr), statectr) to P .

input message
statectr−1,

g(ctr, wctr, rctr, statectr−1)

(Compute, wctr)

randomness

compute

required

pick

to

Fig. 7: The Authentication functionality F (vk,sk)

attest

.

attest

to every other party Pj

the F (vk,sk)
attest −hybrid model. The idea is to have messages
sent by every party Pi
in the
semi-honest protocol be computed by the corresponding
F (vki,ski)
functionality interacting with Pi, where (vki, ski)
are keys used by the functionality. These messages can be
veriﬁed by functionality F (vkj ,skj )
interacting with Pj. We
assume that every F (vki,ski)
knows the veriﬁcation key vkj
used by functionalities of all other parties Pj in a reliable
manner. Later, we show how to achieve this through the use
of remote attestation in the context of Intel SGX. We now set
notation and describe the next message function of any semi-
honest secure MPC protocol and how we modify it for our use.

attest

attest

Next message function. Let π(·) be the next message
function of any semi-honest secure MPC protocol. π(·)
takes the following values as input - two party ids i and
input xi, a round number ctr, randomness ri,j,ctr and
j,
Transcripti, which includes the transcript of all messages
sent and received by the party Pi so far. Given these, π(·)
outputs yi,j
ctr , which is the message that Pi must send to
Pj in round ctr and also updates Transcripti appropriately.
Additionally, π(·) takes message yj,i
ctr sent by Pj to Pi at
round ctr and update Transcripti with this message. We now
describe how to modify π(·) to π∗(·) to incorporate checks
to detect malicious behavior.

Modiﬁed next message function. π∗(·),
function that builds upon π(·) and we describe it for Pi.

is the modiﬁed

1) For ctr = 1, Let xi be the input of Pi in π(·). Then,
(ctr, xi) is stored as state1 (also called as Transcript1
i )
and sent to Pi.

2) When π∗(·) receives a message M = (yj,i

ctr, ctr, σ) from
party Pj, it runs Verifyvkj ((yj,i
ctr, ctr), σ). If veriﬁcation
succeeds, it appends M to Transcripti. Else, Pi aborts.
3) π∗(·) on input (ctr, statectr−1, j) computes the next mes-
sage from Pi to Pj as follows: It checks that statectr−1
contains a valid transcript of all messages computed so
far. If it veriﬁes, it picks randomness ri,j,ctr and runs
π(ctr, statectr−1, j, ri,j,ctr) to compute next message yi,j
ctr
and updated state statectr (containing ri,j,ctr). Else it

attest

Malicious MPC in the Fattest−hybrid model. The malicious
MPC protocol works as follows: Each party Pi
invokes
F (vki,ski)
with the command Commit using function π∗(·)
described above and sends the received token T (i)
to other
π∗
parties Pj. It receives similar tokens T (j)
from party Pj and
π∗
veriﬁes it under vkj. Party Pi aborts if any of these veriﬁca-
tions fail. If all veriﬁcations succeed, it proceeds with running
π∗(·) inside F (vki,ski)

as described formally in Figure 8.

attest

attest

attest

attest

(Commit, π∗)

(H(π∗), T (j)
π∗ )

receive
to
to all parties Pj,

on
π∗ ) and sends T (i)
π∗

Protocol Protmalicious(P1, · · · , Pn)
Party Pi with input xi interacts with {Pj}j(cid:54)=i and F (vki,ski)
and does the following:
Invokes F (vki,ski)
(state(i)
0 , T (i)
j (cid:54)= i.
Receives T (j)
π∗ from Pj and runs Verifyvkj
for all j ∈ [n] \ i. Aborts if one of these checks fail.
Invokes F (vki,ski)
containing input xi.
When Pi receives a message M = (yj,i
party Pj, it invokes F (vki,ski)
and receives updated transcript or ⊥ (and aborts).
When Pi needs to send next message to Pj it invokes
F (vki,ski)
on (Compute, j) and receives (yi,j
ctr , ctr, σ)
along with updated transcript and randomness used.
Here, σ is a signature on (yi,j
ctr , ctr) under ski. It sends
(yi,j
When Pi has no more messages to send in π(·),
computes the output of the function from Transcripti.

on (Compute, xi) to get Transcript1
i

ctr , ctr, σ) from
ctr , ctr, σ))

on (Compute, (yj,i

ctr , ctr, σ) to Pj.

attest

attest

it

Fig. 8: Malicious secure MPC Protmalicious(P1, · · · , Pn).

Functionality F f

mpc(P1, · · · , Pn)

F f

mpc interacts with parties {P1, · · · , Pn} and the adversary S.
On input message xi from Pi record xi and ignore further
xi from Pi
Upon receiving xi from all Pi, i ∈ [n], compute y =
f (x1, · · · , xn) and send to S.
Upon receiving (i, Send) or (i, ⊥) from S, send y or ⊥
to Pi.

Fig. 9: The MPC functionality F f

mpc.

Malicious Security. Next, we prove that if π is secure against
semi-honest adversaries, then the protocol described in Fig-
ure 8 is an MPC protocol secure against malicious adversaries
with the same corruption threshold. We prove the following
result using the standard simulation paradigm in Appendix E.

securely

secure MPC
Theorem 1. Let π(·) be a semi-honest
protocol
protocol
Protmalicious(P1, · · · , Pn) described in Figure 8 securely
realizes F f
mpc in the F (vki,ski)
−hybrid model (with i ∈ [n])
against malicious adversaries.

realizing

Then,

F f

mpc.

attest

C. Realizing Fattest

We note that the ideal functionality assumed out of the
hardware can potentially be realized using various hardware
platforms that provide code attestation and secure signing, e.g.,
STM32H7, MediaTek MT3620, CEC1702, ARMTrustZone,
Intel SGX, etc. In this work, we provide an implementation
of Aramis based on Intel SGX.

SGX allows a host to create a protected region known as
an enclave. Intel gives integrity guarantees, that is, the code
and the data residing in the enclave, once attested, cannot be
modiﬁed by the host or the operating system. When SGX
receives a Commit command (Figure 7) for a function g, then
it creates an enclave with code g. Randomness rctr of Figure 7
can be sampled in SGX using sgx_read_rand command.
The attestation token Tg is generated by SGX communicating
with Intel’s Attestation Service (IAS) and this token is publicly
veriﬁable given g and public veriﬁcation key corresponding to
Intel’s Report Signing Key. The key-pair (vk, sk) for ECDSA
signature scheme is also generated inside the enclave and
the veriﬁcation key vk is sent as payload to IAS during the
generation of the attestation token. The token Tg contains the
veriﬁcation key vk in the clear and this vk can be used to
verify the signed outputs yctr. Now, on receiving the Compute
command, the enclave starts executing the code of g and
produces outputs signed under sk.

While running MPC in the Fattest-hybrid, we require the
enclave to reliably have veriﬁcation keys used by enclaves of
all other parties. This can be done by attaching the following
prelude to π∗ (the code running inside SGX): Read the tokens
of all parties, parse them to obtain the veriﬁcation keys, and
verify the signature on the tokens using veriﬁcation key of
Intel’s Report Signing key. Note that since all the parties are
running the same function π∗ (appended with this prelude),
they can compute the hash of π∗ locally and compare it with
the hash in the tokens (which has been signed by Intel’s IAS)
of all the other parties, proceeding only if they all match
perfectly.

D. Implementation challenges with Intel SGX

We outline some of the key challenges in implementing
MPC between multiple SGX enclaves that involve multiple
rounds of interaction and operate over large volumes of data.
1) Memory constraints in SGX: In SGX, all the enclave
content, including code, and related data is stored in a special
region of memory known as the Enclave Page Cache (EPC).
The size of EPC is ﬁxed in BIOS and can have a maximum
size of 128MB. Typically, paging facilitates the execution of
enclaves which cannot ﬁt in EPC and any page that is evicted
out is encrypted before storing it on unprotected memory [45].
This additional overhead has detrimental effects on the overall
performance of the enclave application. We reduce the working
set of secure inference tasks to limit these overheads.

• ReLU and MaxPool functions: We split the computation
of memory-intensive non-linear functions into chunks that
ﬁt in the EPC to avoid paging. However, lower chunk
sizes increase the number of rounds, and so, the chunk

sizes must be carefully selected. For RESNET50, we
set the chunk sizes for ReLU and MaxPool layers to
be 40 MB and 10 MB respectively. For our network
conﬁgurations, the increase in rounds is justiﬁed by the
elimination of paging costs and reduction in end-to-end
runtimes.

• Convolution and Matrix Multiplication functions: For the
linear functions, we block the matrices into smaller ones,
process the blocks, and aggregate them. We ensure that
individual blocks ﬁt in EPC.

• Liveness Analysis: Athos implements liveness analysis
(Section III-D) which reduces the memory footprint of
the compiled DNNs. For example, the memory footprint
of RESNET50 reduces from 1100 MB to 397 MB due to
liveness analysis. When chunking and liveness analysis
are done together, the memory footprint of RESNET50
comes down to 297MB.

2) Porting Interactive Protocols to SGX: To the best of our
knowledge, we are the ﬁrst work to implement highly interac-
tive protocols in SGX and this comes with unique challenges.
For example, whenever data is passed across the enclave’s
protected memory region, it has to be marshalled in/out of the
region. The performance of marshalling depends on the size of
the parameters crossing the bridge. Larger parameters imply
slower marshalling [45], while smaller parameters increase the
total numbers of cross-bridge calls (which have an overhead
of their own). Thus, we tune the payload size carefully.
the techniques in [78] for optimizing
We also implement
communication involving enclaves.

VI. EXPERIMENTS

Overview.
In this section, we present our experimental
results. First,
in Section VI-A, we use CRYPTFLOW
to securely compute inference on the ImageNet dataset
using the following TensorFlow programs: RESNET503 and
DENSENET1214. We also show that the performance of semi-
honest and malicious protocols generated by CRYPTFLOW
scale linearly with the depth of DNNs. Second, in Section
VI-B, we show that CRYPTFLOW outperforms prior works on
secure inference of DNNs. Next, we evaluate each component
of CRYPTFLOW in more detail. In Section VI-C, we show
that the ﬁxed-point code generated by Athos matches the
accuracy of ﬂoating-point RESNET50 and DENSENET121.
We show in Section VI-D how the optimizations in Porthos
help it outperform prior works in terms of communication
complexity and overall execution time. In Section VI-E,
we show the overhead of obtaining malicious secure MPC
(over semi-honest security) using Aramis for GMW [35] and
Porthos. We show Aramis-based malicious secure inference
outperforms pure crypto-based malicious secure protocols by
huge margins in Section VI-E1. Finally, in section VI-F, we
discuss two case-studies of running CRYPTFLOW on DNNs
for healthcare. We begin by providing details of the systems

3https://github.com/tensorﬂow/models/tree/master/ofﬁcial/r1/resnet
4https://github.com/pudae/tensorﬂow-densenet

Benchmark
RESNET50
DENSENET121

Semi-Honest (s) Malicious (s)

25.9
36.0

75.4
112.9

Comm. (GB)
6.9
10.5

TABLE IV: CRYPTFLOW: ImageNet scale benchmarks.

used to run our experiments.

System Details. All our
large benchmark experiments
are in a LAN setting on 3.7GHz machines, each with 4 cores
and with 16 GB of RAM running Linux Ubuntu 16.04. The
measured bandwidth between each of the machines was at
most 377 MBps and the latency was sub-millisecond. Since
we wanted to use the same machines to benchmark both our
semi-honest as well as our malicious secure protocols, we
were constrained to use machines that had Intel SGX enabled
on them - this led to machines that had considerably lower
bandwidth between them (377 MBps) than those normally
used by prior works in the area (e.g. [60], [12] used networks
with bandwidth of 1.5 GBps). For Aramis, we used Intel SGX
SDK version 2.4. The compilation time of CRYPTFLOW is
around 5 sec for RESNET50, 35 sec for DENSENET121 and
2 minutes for RESNET200.

A. Secure Inference on ImageNet

We brieﬂy describe our benchmarks and then present per-

formance results.

1) RESNET50 [40] is a network that follows the residual
neural network architecture. The residual nodes employ
“skip connections” or short cuts between layers. It con-
sists of 53 convolution layers with ﬁlters of size up to
7 × 7, and 1 fully connected layer of size 2048 × 1001.
layers is batch
The activation function between most
normalization (Appendix B) followed by ReLU. After
the ﬁrst convolutional layer, the activation function also
includes a MaxPool.

2) DENSENET121 [43] is a form of residual neural network
that employs several parallel skips. It consists of 121
convolutional layers with ﬁlters of size up to 7 × 7. The
activation function between these layers is usually batch
normalization, followed by ReLU. Some layers also use
MaxPool or AvgPool.

Performance. Table IV shows performance of CRYPTFLOW
on these benchmarks. We measure communication as total
communication between all 3 parties - each party roughly
communicates a third of this value. The communication in
semi-honest secure and malicious secure inference is almost
the same. Thus demonstrating that ImageNet scale inference
can be performed in about 30 seconds with semi-honest
security and in under two minutes with malicious security.
The malicious protocol of CRYPTFLOW is about 3x slower
than the semi-honest version.

Scalability. We show that the running time of CRYPTFLOW-
based protocols increases linearly with the depth of DNNs.

Fig. 10: Scalability of CRYPTFLOW on RESNET-n.

We compile RESNET-n (where n, the approximate number of
convolutional layers, varies from 18 to 200) with CRYPTFLOW
and evaluate with both semi-honest (Porthos) and malicious
secure protocols (Aramis) in Figure 10. Our largest benchmark
here is RESNET-200,
the deepest version of RESNET on
the ImageNet dataset [41], which has 65 million parameters.
Other RESNET-n benchmarks have between 11 to 60 million
parameters 5. We observe that the communication and runtime
increase linearly with depth. Even with increasing depth, the
overhead of malicious security (over semi-honest security)
remains constant at about 3X.

B. Comparison with prior work

In this section, we show that CRYPTFLOW outperforms
prior works on secure inference of DNNs on the benchmarks
they consider, i.e., tiny 2–4 layer DNNs over the MNIST and
CIFAR-10 datasets. We stress that these benchmarks are very
small compared to the ImageNet scale DNNs discussed above.
In order to provide a fair comparison, for these experiments,
we use a network with similar bandwidth as prior works (1.5
GBps) and machines with similar compute (2.7 GHz).

Table V shows that Porthos outperforms prior (ABY3
[60], Chameleon6 [72], and SecureNN [79]) and concurrent
(QuantizedNN [12]) semi-honest secure 3PC works on the
MNIST dataset. It is well-known that 3PC-based techniques
like Porthos are much faster than techniques based on 2PC and
FHE. We relegate comparison between Porthos and 2PC/FHE
works to Appendix D. We omit comparisons with [22], [20]
as their published MSB protocol was incorrect [21].

C. Athos experiments

Accuracy of Float-to-Fixed. We show that Athos generated
ﬁxed-point code matches the accuracy of ﬂoating-code on
RESNET50 and DENSENET121 in Table VI. The table also
shows the precision or the scale that is selected by Athos
(Section III-B). We observe that different benchmarks require

5Speciﬁcally, 11, 22, 25, 44 and 60 million parameters for RESNET-n for

n = 18, 34, 50, 101, and 152 respectively.

6Chameleon is a 2PC protocol in the online phase but requires a trusted

third party in the ofﬂine phase. We report overall time here.

0510152025050100150200250183450101152200Communication (GB)Time (seconds)nCommunication (GB)Porthos TimeAramis TimeBenchmark
Logistic Regression
SecureML (3 layer)
MiniONN (4 layer)
LeNet (4 layer)

[60]
4
8
-
-

[12]
−
20
80
120

[79]
−
17
47
79

[72]
-
-
2240
-

Porthos
2.7
8
34
58

TABLE V: Comparison with 3PC on MNIST dataset
with ABY3 [60], QuantizedNN [12], SecureNN [79], and
Chameleon [72]. All times in milliseconds.

Benchmark

RESNET50
DENSENET121

Float
Top 1
76.47
74.25

Fixed
Top 1
76.45
74.33

Float
Top 5
93.21
91.88

Fixed
Top 5
93.23
91.90

Scale

12
11

TABLE VI: Accuracy of ﬁxed-point vs ﬂoating-point.

different precision to maximize the classiﬁcation accuracy and
that the technique of “sweeping” through various precision
levels is effective. We show how accuracy varies with precision
in Appendix C. Evaluating accuracy also helps validate the
correctness of our compilation [63].

Modularity. Since CRYPTFLOW is modular, we can compile
it to various MPC backends. To demonstrate this ability, we
also add a 2PC semi-honest secure protocol ABY [30] to
CRYPTFLOW. The performance with this backend is in Table
VII. We ran logistic regression (LR) as well as a small LeNet
network [53] which comprises of 2 convolutional layers (with
maximum ﬁlter size of 5 × 5) and 2 fully connected layers,
with ReLU and MaxPool as the activation functions. This
evaluation shows that CRYPTFLOW can be easily used for
a variety of backends.

D. Porthos experiments

Since Porthos builds on SecureNN, we compare them in
mode detail. As described earlier, Porthos improves over
the communication complexity of SecureNN [79] both for
convolutional layers as well as for non-linear activation func-
tions. We have already compared SecureNN and Porthos on
benchmarks considered in SecureNN in Table V. Additionally,
we also compare Porthos and SecureNN on ImageNet scale
benchmarks in Table VIII. For this purpose, we add the
code of SecureNN available at [5] as another backend to
CRYPTFLOW. These results show that Porthos improves upon
the communication of SecureNN by a factor of roughly 1.2X–
1.5X and the runtime by a factor of roughly 1.4X–1.5X.

Benchmark
LogisticRegression
LeNet Small

CRYPTFLOW (s)
0.227
47.4

Communication (MB)
25.5
2939

TABLE VII: CRYPTFLOW compilation to 2PC on MNIST.

Benchmark

RESNET50
DENSENET121

SecureNN
(s)
38.36
53.99

Porthos
(s)
25.87
36.00

SecureNN
Comm. (GB)
8.54
13.53

Porthos
Comm. (GB)
6.87
10.54

TABLE VIII: Porthos vs SecureNN.

Benchmark
IP10,000
IP100,000
Add32
Mult32
Millionaire32

GMW (ms)
464
2145
279
354
292

Aramis (ms)
638
3318
351
461
374

Overhead
1.37x
1.54x
1.25x
1.30x
1.28x

TABLE IX: Semi-honest GMW vs Malicious Aramis.

E. Aramis experiments

We applied Aramis to both the 2-party GMW protocol [35]
(using the codebase [2], based on [24]) as well as Porthos.
The results for different functions using the GMW protocol are
presented in Table IX. IPn denotes the inner product of two
n-element vectors over F2, Add32 and Mult32 denote addition
and multiplication over 32 bits respectively, and Millionaire32
denotes the millionaires problem that compares two 32−bit
integers x and y and outputs a single bit denoting whether
x > y. The overheads of Aramis-based malicious security,
are within 54% of the semi-honest protocol. Table IV and
Figure 10 evaluate Aramis with Porthos.

1) Comparison with crypto-only malicious MPC: We
demonstrate that Aramis based malicious secure protocols
are better suited for large scale inference tasks compared to
pure cryptographic solutions. We compare the performance
of Porthos compiled with Aramis and the concurrent work
of QuantizedNN [12] that uses the MP-SPDZ [4] framework
to also provide a malicious secure variant of their protocol.
Both these approaches provide security for the same setting
of 3PC with 1 corruption. On the four MNIST inference
benchmarks A/B/C/D in the MP-SPDZ repository, Aramis is
10X/46X/44X/15X faster.

F. Real world impact

We discuss our experience with using CRYPTFLOW to
compile and run DNNs used in healthcare. These DNNs are
available as pre-trained Keras models. We converted them
into TensorFlow using [3] and compiled the automatically
generated TensorFlow code with CRYPTFLOW.

the

train

authors

a) Chest X-Ray:
[85],
a
In
DENSENET121 to predict
lung diseases from chest X-
ray images. They use the publicly available NIH dataset
of chest X-ray images and end up achieving an average
AUROC score of 0.845 across 14 possible disease labels.
During secure inference, we observed no loss in accuracy and
the runtime is similar to the runtime of DENSENET121 for
ImageNet.

b) Diabetic Retinopathy CNN: Diabetic Retinopathy
(DR), one of the major causes of blindness, is a medical
condition that leads to damage of retina due to diabetes [64].
In recent times, major tech companies have taken an interest
in using DNNs for diagnosing DR from retinal images [64],
[37]. Predicting whether a retina image has DR or not can be
done securely in about 30 seconds with CRYPTFLOW.

VII. RELATED WORK

High level
languages. CRYPTFLOW is the ﬁrst system
to compile pre-deﬁned TensorFlow code to secure MPC

protocols. There have been prior works that compile from
lower-level, domain-speciﬁc languages to MPC. Examples
include Fairplay [56], Wysteria [70], ObliVM [54], CBMC-
GC [42], SMCL [66], [59], Sharemind [16], EzPC [19],
and SPDZ [9]. Reimplementing large DNNs in the input
format of these tools is a formidable task. PySyft [73]
and TF-Encrypted [26] are ongoing efforts that also aim to
compile DNNs to MPC protocols. In contrast to CRYPTFLOW
that compiles standard TensorFlow code, these works require
reimplementing the DNNs in a dialect of PyTorch/TensorFlow.
To the best of our knowledge, these systems have not been
evaluated on ImageNet scale tasks.

Fixed-point
in MPC. Although the use of ﬁxed-point
for secure computations is well-known [68], prior works on
secure inference have addressed the ﬂoat-to-ﬁxed problem
by either generating a ﬁxed-point model by hand ([62], [55],
[49], [60], [79], [58], [72]), or by using non-standard training
algorithms that output ﬁxed-point models ([71], [7]). Both of
these approaches are unsatisfactory. In particular, some of the
challenges that one would face with the latter include: a) the
need to train again on the whole training data which is both
computationally expensive, and impossible if the training data
is unavailable; and b) training algorithms that generate integer
models is still an active research area and an overwhelming
majority of ML training algorithms still generate ﬂoating-
point models. Athos alleviates all these problems by working
with a trained model and being completely oblivious to the
training procedure. The ML users can train their networks in
the manner they see ﬁt and then use Athos to get ﬁxed-point
code. Finally, even with retraining, TensorFlow-generated
binary/integer networks suffer signiﬁcant accuracy loses [48]
whereas Athos matches the accuracy of ﬂoating-point models.

[65],

[36],

research literature

Float-to-ﬁxed. The
in ﬂoat-to-ﬁxed
for digital signal processors is rich and spans several decades.
However, it is only recently that these schemes have been
adapted to machine learning. Some recent ﬂoat-to-ﬁxed
schemes
show promise by quantizing
ﬂoating-point models to 8-bit or 16-bit integers. One could
potentially use one of these systems in place of our ﬂoat-to-
ﬁxed component – however, their compatibility with MPC
protocols [60], [79] is unclear. Additionally, since we use
higher bit-width of 64, not surprisingly,
the accuracy of
CRYPTFLOW is better.

[48]

Secure Machine Learning. There has been a ﬂurry of
recent results ([61], [75], [57], [25], [44]) in the area of
secure machine learning, both in the 2-party [17], [67], [34],
[55], [49], [58], [84], as well as in the 3-party setting [72],
[60], [79], [12]. The most relevant to our work are ABY3 [60]
and SecureNN [79] that both provide 3-party semi-honest
secure computation protocols for a variety of neural network
inference and training algorithms, with somewhat similar
performance guarantees. Porthos, our 3-party semi-honest
protocol, outperforms both these works. We also remark

that there have been other recent works [71], [75], [7], [33],
[27], [15], [14], [39], that modify the inference or training
algorithms in order to obtain performance beneﬁts. These
are applicable only to specialized benchmarks. For example,
the works that use fully homomorphic encryption (e.g., [27],
[15],
[14]) do not support secure evaluation of ReLUs,
XONN [71] requires DNNs to have binary weights, etc. On
the other hand, we focus on standard inference algorithms
and CRYPTFLOW has much wider applicability.

Hardware-based security. Our work is the ﬁrst to provide
experimentally validated malicious secure inference of ML
algorithms at the scale of RESNET50. As discussed earlier,
we achieve this by relying on minimally secure hardware
to provide integrity. Prior works that use hardware enclaves
for secure computation [74], [69], [38], [11], [23], [29],
[51], [32], [77], [83], [44] assume that the enclave hides all
data residing in it from the host. Thus, unlike Aramis, these
systems are not secure against an adversary that can observe
the SGX state. The only prior work that assumes a weaker
trust assumption from the hardware is that of [78]. Similar to
our work, they assume that the hardware provides integrity.
However,
their work is in the context of zero-knowledge
proofs and other fundamentally asymmetric primitives that
require only one enclave and not interactive protocols between
multiple enclaves.

VIII. CONCLUSION

CRYPTFLOW is the ﬁrst end-to-end system that translates
high-level TensorFlow inference code to MPC protocols. It
has 3 components - a) compiler from TensorFlow to MPC, b)
an improved semi-honest 3PC protocol for DNNs, and c) a
generic technique to convert semi-honest secure protocols to
malicious secure ones. Using CRYPTFLOW, we demonstrate
the ﬁrst instance of secure inference on large benchmarks such
as RESNET50 and DENSENET121 on the ImageNet dataset
with both semi-honest (in about thirty seconds) and malicious
security (in less than two minutes). CRYPTFLOW’s modular
design supports a variety of backends, and we hope that it can
serve as a testbed for benchmarking new MPC protocols in
the area.

Going forward, we would like to plugin protocols like
SPDZ [4] and Delphi [58] in CRYPTFLOW. Our more am-
bitious goal is to extend CRYPTFLOW to support TensorFlow
training. It is a challenging problem since in the absence of
the GPU support, the overheads of MPC protocols for secure
training can be prohibitive.

IX. ACKNOWLEDGEMENTS

We thank our shepherd Xiao Wang, and anonymous re-
viewers for their valuable feedback. We also thank Sridhar
Gopinath, Aayan Kumar, Wonyeol Lee, Sundararajan Ren-
ganathan, and Kapil Vaswani for helpful discussions.

REFERENCES

[1] “TensorFlow

Graph

Transform

Tool,”

https://github.com/

tensorﬂow/tensorﬂow/blob/master/tensorﬂow/tools/graph transforms/
README.md.

[2] “GMW

codebase,”

2012.

[Online].

Available:

http://

www.ee.columbia.edu/∼kwhwang/projects/gmw.html

[3] “Keras

to

TensorFlow,”

https://github.com/amir-abdi/keras to

tensorﬂow, 2019.

[4] “Multi-Protocol SPDZ: Versatile framework for multi-party computa-
tion,” 2019. [Online]. Available: https://github.com/data61/MP-SPDZ
[5] “SecureNN: 3-Party Secure Computation for Neural Network Training,”

https://github.com/snwagh/securenn-public, 2019.

[6] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro,
G. S. Corrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. J.
Goodfellow, A. Harp, G. Irving, M. Isard, Y. Jia, R. J´ozefowicz,
L. Kaiser, M. Kudlur, J. Levenberg, D. Man´e, R. Monga, S. Moore,
D. G. Murray, C. Olah, M. Schuster,
J. Shlens, B. Steiner,
I. Sutskever, K. Talwar, P. A. Tucker, V. Vanhoucke, V. Vasudevan,
F. B. Vi´egas, O. Vinyals, P. Warden, M. Wattenberg, M. Wicke,
Y. Yu, and X. Zheng, “TensorFlow: Large-Scale Machine Learning
on Heterogeneous Distributed Systems,” CoRR, vol. abs/1603.04467,
2016. [Online]. Available: https://arxiv.org/abs/1603.04467

[7] N. Agrawal, A. S. Shamsabadi, M. J. Kusner, and A. Gasc´on, “QUO-
TIENT: Two-Party Secure Neural Network Training and Prediction,” in
Proceedings of the 2019 ACM SIGSAC Conference on Computer and
Communications Security, CCS 2019, London, UK, November 11-15,
2019, 2019, pp. 1231–1247.

[8] A. V. Aho, M. S. Lam, R. Sethi, and J. D. Ullman, Compilers: Principles,
Boston, MA, USA: Addison-

Techniques, and Tools (2nd Edition).
Wesley Longman Publishing Co., Inc., 2006.

[9] T. Araki, A. Barak, J. Furukawa, M. Keller, Y. Lindell, K. Ohara, and
H. Tsuchida, “Generalizing the SPDZ Compiler For Other Protocols,”
in Proceedings of the 2018 ACM SIGSAC Conference on Computer and
Communications Security, CCS 2018, Toronto, ON, Canada, October
15-19, 2018, 2018, pp. 880–895.

[10] T. Araki, J. Furukawa, Y. Lindell, A. Nof, and K. Ohara, “High-
Throughput Semi-Honest Secure Three-Party Computation with an
Honest Majority,” in Proceedings of the 2016 ACM SIGSAC Conference
on Computer and Communications Security, CCS 2016, Vienna, Austria,
October 24-28, 2016, 2016, pp. 805–817.

[11] R. Bahmani, M. Barbosa, F. Brasser, B. Portela, A. Sadeghi, G. Scerri,
and B. Warinschi, “Secure Multiparty Computation from SGX,” in
Financial Cryptography and Data Security - 21st International Confer-
ence, FC 2017, Sliema, Malta, April 3-7, 2017, Revised Selected Papers,
2017, pp. 477–497.

[12] A. Barak, D. Escudero, A. Dalskov, and M. Keller, “Secure Evaluation
of Quantized Neural Networks,” Cryptology ePrint Archive, Report
2019/131, 2019, https://eprint.iacr.org/2019/131.

[13] D. Beaver, “Efﬁcient Multiparty Protocols Using Circuit Randomiza-
tion,” in Advances in Cryptology - CRYPTO ’91, 11th Annual Interna-
tional Cryptology Conference, Santa Barbara, California, USA, August
11-15, 1991, Proceedings, 1991, pp. 420–432.

[14] F. Boemer, A. Costache, R. Cammarota, and C. Wierzynski, “nGraph-
HE2: A High-Throughput Framework for Neural Network Inference on
Encrypted Data,” Cryptology ePrint Archive, Report 2019/947, 2019,
https://eprint.iacr.org/2019/947.

[15] F. Boemer, Y. Lao, R. Cammarota, and C. Wierzynski, “nGraph-HE:
A Graph Compiler for Deep Learning on Homomorphically Encrypted
Data,” in Proceedings of the 16th ACM International Conference on
Computing Frontiers, CF 2019, Alghero, Italy, April 30 - May 2, 2019,
2019, pp. 3–13.

[16] D. Bogdanov, S. Laur, and J. Willemson, “Sharemind: A Framework
for Fast Privacy-Preserving Computations,” in Computer Security -
ESORICS 2008, 13th European Symposium on Research in Computer
Security, M´alaga, Spain, October 6-8, 2008. Proceedings, 2008, pp.
192–206.

[17] R. Bost, R. A. Popa, S. Tu, and S. Goldwasser, “Machine Learning
Classiﬁcation over Encrypted Data,” in 22nd Annual Network and Dis-
tributed System Security Symposium, NDSS 2015, San Diego, California,
USA, February 8-11, 2015, 2015.

[18] R. Canetti, “Security and Composition of Multiparty Cryptographic

Protocols,” J. Cryptology, vol. 13, no. 1, pp. 143–202, 2000.

[19] N. Chandran, D. Gupta, A. Rastogi, R. Sharma, and S. Tripathi, “EzPC:
Programmable and Efﬁcient Secure Two-Party Computation for Machine
Learning,” in IEEE European Symposium on Security and Privacy,
EuroS&P 2019, Stockholm, Sweden, June 17-19, 2019, 2019, pp. 496–
511.

[20] H. Chaudhari, A. Choudhury, A. Patra, and A. Suresh, “ASTRA: High
Throughput 3PC over Rings with Application to Secure Prediction,” in
Proceedings of the 2019 ACM SIGSAC Conference on Cloud Computing
Security Workshop, CCSW@CCS 2019, London, UK, November 11,
2019, 2019, pp. 81–92.

[21] ——, “ASTRA: High Throughput 3PC over Rings with Application to
Secure Prediction,” Cryptology ePrint Archive, Report 2019/429, 2019,
https://eprint.iacr.org/2019/429.

[22] H. Chaudhari, R. Rachuri, and A. Suresh, “Trident: Efﬁcient 4PC
Framework for Privacy Preserving Machine Learning,” in 27th Annual
Network and Distributed System Security Symposium, NDSS 2020, San
Diego, California, USA, February 23-26, 2020, 2020.

[23] J. I. Choi, D. J. Tian, G. Hernandez, C. Patton, B. Mood, T. Shrimpton,
K. R. B. Butler, and P. Traynor, “A Hybrid Approach to Secure
Function Evaluation Using SGX,” in Proceedings of the 2019 ACM Asia
Conference on Computer and Communications Security, AsiaCCS 2019,
Auckland, New Zealand, July 09-12, 2019, 2019, pp. 100–113.

[24] S. G. Choi, K. Hwang, J. Katz, T. Malkin, and D. Rubenstein, “Secure
Multi-Party Computation of Boolean Circuits with Applications to
Privacy in On-Line Marketplaces,” in Topics in Cryptology - CT-RSA
2012 - The Cryptographers’ Track at the RSA Conference 2012, San
Francisco, CA, USA, February 27 - March 2, 2012. Proceedings, 2012,
pp. 416–432.

[25] H. Corrigan-Gibbs and D. Boneh, “Prio: Private, Robust, and Scalable
Computation of Aggregate Statistics,” in 14th USENIX Symposium on
Networked Systems Design and Implementation, NSDI 2017, Boston,
MA, USA, March 27-29, 2017, 2017, pp. 259–282.

[26] M. Dahl, J. Mancuso, Y. Dupis, B. Decoste, M. Giraud, I. Livingstone,
J. Patriquin, and G. Uhma, “Private Machine Learning in TensorFlow
using Secure Computation,” CoRR, vol. abs/1810.08130, 2018. [Online].
Available: http://arxiv.org/abs/1810.08130

[27] R. Dathathri, O. Saarikivi, H. Chen, K. Lauter, S. Maleki, M. Musu-
vathi, and T. Mytkowicz, “CHET: An Optimizing Compiler for Fully-
Homomorphic Neural-Network Inferencing,” in Proceedings of the 40th
ACM SIGPLAN Conference on Programming Language Design and
Implementation, PLDI 2019, Phoenix, AZ, USA, June 22-26, 2019, 2019,
pp. 142–156.

[28] D. Demmler, G. Dessouky, F. Koushanfar, A. Sadeghi, T. Schneider,
and S. Zeitouni, “Automated Synthesis of Optimized Circuits for Secure
Computation,” in Proceedings of the 22nd ACM SIGSAC Conference on
Computer and Communications Security, Denver, CO, USA, October
12-16, 2015, 2015, pp. 1504–1517.

[29] D. Demmler, T. Schneider, and M. Zohner, “Ad-Hoc Secure Two-
Party Computation on Mobile Devices using Hardware Tokens,” in
Proceedings of the 23rd USENIX Security Symposium, San Diego, CA,
USA, August 20-22, 2014, 2014, pp. 893–908.

[30] ——, “ABY - A Framework for Efﬁcient Mixed-Protocol Secure Two-
Party Computation,” in 22nd Annual Network and Distributed System
Security Symposium, NDSS 2015, San Diego, California, USA, February
8-11, 2015, 2015.

[31] J. Deng, W. Dong, R. Socher, L. Li, K. Li, and F. Li, “ImageNet:
A large-scale hierarchical image database,” in 2009 IEEE Computer
Society Conference on Computer Vision and Pattern Recognition (CVPR
2009), 20-25 June 2009, Miami, Florida, USA, 2009, pp. 248–255.
[32] S. Felsen, A. Kiss, T. Schneider, and C. Weinert, “Secure and Private
Function Evaluation with Intel SGX,” in Proceedings of
the 2019
ACM SIGSAC Conference on Cloud Computing Security Workshop,
CCSW@CCS 2019, London, UK, November 11, 2019, 2019, pp. 165–
181.

[33] S. Garg, Z. Ghodsi, C. Hazay, Y. Ishai, A. Marcedone, and M. Venkita-
subramaniam, “Outsourcing Private Machine Learning via Lightweight
Secure Arithmetic Computation,” CoRR, vol. abs/1812.01372, 2018.
[Online]. Available: http://arxiv.org/abs/1812.01372

[34] R. Gilad-Bachrach, N. Dowlin, K. Laine, K. E. Lauter, M. Naehrig,
and J. Wernsing, “CryptoNets: Applying Neural Networks to Encrypted
Data with High Throughput and Accuracy,” in Proceedings of the 33nd
International Conference on Machine Learning, ICML 2016, New York
City, NY, USA, June 19-24, 2016, 2016, pp. 201–210.

[35] O. Goldreich, S. Micali, and A. Wigderson, “How to Play any Mental
Game or A Completeness Theorem for Protocols with Honest Majority,”
in Proceedings of
the 19th Annual ACM Symposium on Theory of
Computing, 1987, New York, New York, USA, 1987, pp. 218–229.
[36] S. Gopinath, N. Ghanathe, V. Seshadri, and R. Sharma, “Compiling KB-
Sized Machine Learning Models to Tiny IoT Devices,” in Proceedings of
the 40th ACM SIGPLAN Conference on Programming Language Design
and Implementation, PLDI 2019, Phoenix, AZ, USA, June 22-26, 2019,
2019, pp. 79–95.

[37] V. Gulshan, L. Peng, M. Coram, M. C. Stumpe, D. Wu,
A. Narayanaswamy, S. Venugopalan, K. Widner, T. Madams, J. Cuadros,
R. Kim, R. Raman, P. C. Nelson, J. L. Mega, and D. R. Webster, “De-
velopment and Validation of a Deep Learning Algorithm for Detection
of Diabetic Retinopathy in Retinal Fundus Photographs,” JAMA, vol.
316, no. 22, pp. 2402–2410, 2016.

[38] D. Gupta, B. Mood, J. Feigenbaum, K. R. B. Butler, and P. Traynor,
“Using Intel Software Guard Extensions for Efﬁcient Two-Party Secure
Function Evaluation,” in Financial Cryptography and Data Security - FC
2016 International Workshops, BITCOIN, VOTING, and WAHC, Christ
Church, Barbados, February 26, 2016, Revised Selected Papers, 2016,
pp. 302–318.

[39] C. Hazay, Y.

Ishai, A. Marcedone, and M. Venkitasubramaniam,
“LevioSA: Lightweight Secure Arithmetic Computation,” in Proceed-
ings of the 2019 ACM Conference on Computer and Communications
Security, CCS 2019, London, UK, November 11-15, 2019, 2019, pp.
327–344.

[40] K. He, X. Zhang, S. Ren, and J. Sun, “Deep Residual Learning for Image
Recognition,” in 2016 IEEE Conference on Computer Vision and Pattern
Recognition, CVPR 2016, Las Vegas, NV, USA, June 27-30, 2016, 2016,
pp. 770–778.

[41] ——, “Identity Mappings in Deep Residual Networks,” in Computer
Vision - ECCV 2016 - 14th European Conference, Amsterdam, The
Netherlands, October 11-14, 2016, Proceedings, Part IV, 2016, pp. 630–
645.

[42] A. Holzer, M. Franz, S. Katzenbeisser, and H. Veith, “Secure two-party
computations in ANSI C,” in Proceedings of the 2012 ACM Conference
on Computer and Communications Security, CCS 2012, Raleigh, NC,
USA, October 16-18, 2012, 2012, pp. 772–783.

[43] G. Huang, Z. Liu, L. van der Maaten, and K. Q. Weinberger, “Densely
Connected Convolutional Networks,” in 2017 IEEE Conference on
Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI,
USA, July 21-26, 2017, 2017, pp. 2261–2269.

[44] T. Hunt, C. Song, R. Shokri, V. Shmatikov, and E. Witchel,
“Chiron: Privacy-preserving Machine Learning as a Service,” CoRR,
vol. abs/1803.05961, 2018. [Online]. Available: https://arxiv.org/abs/
1803.05961

[45] Intel,

“Performance Considerations

for
(Intel SGX) Applications,”

Intel Software Guard
[Online]. Avail-
2018.
Extensions
able: https://software.intel.com/sites/default/ﬁles/managed/09/37/Intel-
SGX-Performance-Considerations.pdf

[46] S. Ioffe and C. Szegedy, “Batch Normalization: Accelerating Deep
Network Training by Reducing Internal Covariate Shift,” in Proceedings
of the 32nd International Conference on Machine Learning, ICML 2015,
Lille, France, 6-11 July 2015, ser. JMLR Workshop and Conference
Proceedings, vol. 37, 2015, pp. 448–456.

[47] M. Ion, B. Kreuter, A. E. Nergiz, S. Patel, M. Raykova, S. Saxena,
K. Seth, D. Shanahan, and M. Yung, “On Deploying Secure Computing
Commercially: Private Intersection-Sum Protocols and their Business
Applications,” Cryptology ePrint Archive, Report 2019/723, 2019, https:
//eprint.iacr.org/2019/723.

[48] B. Jacob, S. Kligys, B. Chen, M. Zhu, M. Tang, A. G. Howard, H. Adam,
and D. Kalenichenko, “Quantization and Training of Neural Networks
for Efﬁcient Integer-Arithmetic-Only Inference,” in 2018 IEEE Confer-
ence on Computer Vision and Pattern Recognition, CVPR 2018, Salt
Lake City, UT, USA, June 18-22, 2018, 2018, pp. 2704–2713.

[49] C. Juvekar, V. Vaikuntanathan, and A. Chandrakasan, “GAZELLE: A
Low Latency Framework for Secure Neural Network Inference,” in 27th
USENIX Security Symposium, USENIX Security 2018, Baltimore, MD,
USA, August 15-17, 2018, 2018, pp. 1651–1669.

[50] J. Katz, S. Ranellucci, M. Rosulek, and X. Wang, “Optimizing Authenti-
cated Garbling for Faster Secure Two-Party Computation,” in Advances
in Cryptology - CRYPTO 2018 - 38th Annual International Cryptology
Conference, Santa Barbara, CA, USA, August 19-23, 2018, Proceedings,
Part III, 2018, pp. 365–391.

[51] P. Koeberl, V. Phegade, A. Rajan, T. Schneider, S. Schulz, and M. Zh-
danova, “Time to Rethink: Trust Brokerage Using Trusted Execution
Environments,” in Trust and Trustworthy Computing - 8th International
Conference, TRUST 2015, Heraklion, Greece, August 24-26, 2015,
Proceedings, 2015, pp. 181–190.

[52] V. Kolesnikov, M. Rosulek, N. Trieu, and X. Wang, “Scalable Private
Set Union from Symmetric-Key Techniques,” in Advances in Cryptology
- ASIACRYPT 2019 - 25th International Conference on the Theory
and Application of Cryptology and Information Security, Kobe, Japan,
December 8-12, 2019, Proceedings, Part II, 2019, pp. 636–666.
[53] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning
applied to document recognition,” in Proceedings of the IEEE, 1998, pp.
2278–2324.

[54] C. Liu, X. S. Wang, K. Nayak, Y. Huang, and E. Shi, “ObliVM:
A Programming Framework for Secure Computation,” in 2015 IEEE
Symposium on Security and Privacy, S&P 2015, San Jose, CA, USA,
May 17-21, 2015, 2015, pp. 359–376.

[55] J. Liu, M. Juuti, Y. Lu, and N. Asokan, “Oblivious Neural Network
Predictions via MiniONN Transformations,” in Proceedings of the 2017
ACM SIGSAC Conference on Computer and Communications Security,
CCS 2017, Dallas, TX, USA, October 30 - November 03, 2017, 2017,
pp. 619–631.

[56] D. Malkhi, N. Nisan, B. Pinkas, and Y. Sella, “Fairplay - Secure Two-
Party Computation System,” in Proceedings of the 13th USENIX Security
Symposium, August 9-13, 2004, San Diego, CA, USA, 2004, pp. 287–
302.

[57] L. Melis, C. Song, E. D. Cristofaro, and V. Shmatikov, “Exploiting
Unintended Feature Leakage in Collaborative Learning,” in 2019 IEEE
Symposium on Security and Privacy, S&P 2019, San Francisco, CA,
USA, May 19-23, 2019, 2019, pp. 691–706.

[58] P. Mishra, R. Lehmkuhl, A. Srinivasan, W. Zheng, and R. A. Popa,
“Delphi: A Cryptographic Inference Service for Neural Networks,” in
29th USENIX Security Symposium, USENIX Security 20, Boston, MA,
2020.

[59] J. C. Mitchell, R. Sharma, D. Stefan, and J. Zimmerman, “Information-
Flow Control for Programming on Encrypted Data,” in 25th IEEE
Computer Security Foundations Symposium, CSF 2012, Cambridge, MA,
USA, June 25-27, 2012, 2012, pp. 45–60.

[60] P. Mohassel and P. Rindal, “ABY3: A Mixed Protocol Framework
for Machine Learning,” in Proceedings of
the 2018 ACM SIGSAC
Conference on Computer and Communications Security, CCS 2018,
Toronto, ON, Canada, October 15-19, 2018, 2018, pp. 35–52.

[61] P. Mohassel, M. Rosulek, and N. Trieu, “Practical Privacy-Preserving K-
means Clustering,” Cryptology ePrint Archive, Report 2019/1158, 2019,
https://eprint.iacr.org/2019/1158.

[62] P. Mohassel and Y. Zhang, “SecureML: A System for Scalable Privacy-
Preserving Machine Learning,” in 2017 IEEE Symposium on Security
and Privacy, S&P 2017, San Jose, CA, USA, May 22-26, 2017, 2017,
pp. 19–38.

[63] B. Mood, D. Gupta, H. Carter, K. R. B. Butler, and P. Traynor, “Frigate:
A Validated, Extensible, and Efﬁcient Compiler and Interpreter for
Secure Computation,” in IEEE European Symposium on Security and
Privacy, EuroS&P 2016, Saarbr¨ucken, Germany, March 21-24, 2016,
2016, pp. 112–127.

[64] J. MSV, “Google’s Research In Artiﬁcial

In
Preventing Blindness Caused by Diabetes,” Forbes,
sep 2017.
[Online]. Available: https://www.forbes.com/sites/janakirammsv/2017/
09/05/googles-research-in-artiﬁcial-intelligence-helps-in-preventing-
blindness-caused-by-diabetes/#17b4f53256e1

Intelligence Helps

[65] M. Nagel, M. van Baalen, T. Blankevoort, and M. Welling,
“Data-Free Quantization through Weight Equalization and Bias
Correction,” CoRR, vol. abs/1906.04721, 2019. [Online]. Available:
http://arxiv.org/abs/1906.04721

[66] J. D. Nielsen and M. I. Schwartzbach, “A domain-speciﬁc programming
language for secure multiparty computation,” in Proceedings of the 2007
Workshop on Programming Languages and Analysis for Security, PLAS
2007, San Diego, California, USA, June 14, 2007, 2007, pp. 21–30.

[67] V. Nikolaenko, S. Ioannidis, U. Weinsberg, M. Joye, N. Taft, and
D. Boneh, “Privacy-preserving matrix factorization,” in 2013 ACM
SIGSAC Conference on Computer and Communications Security, CCS
2013, Berlin, Germany, November 4-8, 2013, 2013, pp. 801–812.
[68] V. Nikolaenko, U. Weinsberg, S. Ioannidis, M. Joye, D. Boneh, and
N. Taft, “Privacy-Preserving Ridge Regression on Hundreds of Millions

of Records,” in 2013 IEEE Symposium on Security and Privacy, S&P
2013, Berkeley, CA, USA, May 19-22, 2013, 2013, pp. 334–348.
[69] O. Ohrimenko, F. Schuster, C. Fournet, A. Mehta, S. Nowozin,
K. Vaswani, and M. Costa, “Oblivious Multi-Party Machine Learning
on Trusted Processors,” in 25th USENIX Security Symposium, USENIX
Security 16, Austin, TX, USA, August 10-12, 2016., 2016, pp. 619–636.
[70] A. Rastogi, M. A. Hammer, and M. Hicks, “Wysteria: A Programming
Language for Generic, Mixed-Mode Multiparty Computations,” in 2014
IEEE Symposium on Security and Privacy, S&P 2014, Berkeley, CA,
USA, May 18-21, 2014, 2014, pp. 655–670.

[71] M. S. Riazi, M. Samragh, H. Chen, K. Laine, K. E. Lauter, and
F. Koushanfar, “XONN: XNOR-based Oblivious Deep Neural Network
Inference,” in 28th USENIX Security Symposium, USENIX Security
2019, Santa Clara, CA, USA, August 14-16, 2019, 2019, pp. 1501–1518.
[72] M. S. Riazi, C. Weinert, O. Tkachenko, E. M. Songhori, T. Schneider,
and F. Koushanfar, “Chameleon: A Hybrid Secure Computation Frame-
work for Machine Learning Applications,” in Proceedings of the 2018 on
Asia Conference on Computer and Communications Security, AsiaCCS
2018, Incheon, Republic of Korea, June 04-08, 2018, 2018, pp. 707–721.
[73] T. Ryffel, A. Trask, M. Dahl, B. Wagner, J. Mancuso, D. Rueckert,
and J. Passerat-Palmbach, “A generic framework for privacy preserving
deep learning,” CoRR, vol. abs/1811.04017, 2018. [Online]. Available:
http://arxiv.org/abs/1811.04017

[74] F. Schuster, M. Costa, C. Fournet, C. Gkantsidis, M. Peinado, G. Mainar-
Ruiz, and M. Russinovich, “VC3: Trustworthy Data Analytics in the
Cloud Using SGX,” in 2015 IEEE Symposium on Security and Privacy,
S&P 2015, San Jose, CA, USA, May 17-21, 2015, 2015, pp. 38–54.

[75] J. So, B. Guler, A. S. Avestimehr, and P. Mohassel, “CodedPrivateML:
A Fast and Privacy-Preserving Framework for Distributed Machine
Learning,” Cryptology ePrint Archive, Report 2019/140, 2019, https:
//eprint.iacr.org/2019/140.

[76] TensorFlow, “Broadcasting semantics,” https://www.tensorﬂow.org/xla/

broadcasting, 2018.

[77] F. Tram`er and D. Boneh, “Slalom: Fast, Veriﬁable and Private Execution
of Neural Networks in Trusted Hardware,” in 7th International Confer-
ence on Learning Representations, ICLR 2019, New Orleans, LA, USA,
May 6-9, 2019, 2019.

[78] F. Tram`er, F. Zhang, H. Lin, J. Hubaux, A. Juels, and E. Shi, “Sealed-
Glass Proofs: Using Transparent Enclaves to Prove and Sell Knowledge,”
in 2017 IEEE European Symposium on Security and Privacy, EuroS&P
2017, Paris, France, April 26-28, 2017, 2017, pp. 19–34.

[79] S. Wagh, D. Gupta, and N. Chandran, “SecureNN: 3-Party Secure
Computation for Neural Network Training,” PoPETs, vol. 2019, no. 3,
pp. 26–49, 2019.

[80] X. Wang, S. Ranellucci, and J. Katz, “Authenticated Garbling and
Efﬁcient Maliciously Secure Two-Party Computation,” in Proceedings of
the 2017 ACM SIGSAC Conference on Computer and Communications
Security, CCS 2017, Dallas, TX, USA, October 30 - November 03, 2017,
2017, pp. 21–37.

[81] ——, “Global-Scale Secure Multiparty Computation,” in Proceedings of
the 2017 ACM SIGSAC Conference on Computer and Communications
Security, CCS 2017, Dallas, TX, USA, October 30 - November 03, 2017,
2017, pp. 39–56.

[82] A. C. Yao, “How to Generate and Exchange Secrets (Extended Ab-
stract),” in 27th Annual Symposium on Foundations of Computer Sci-
ence, Toronto, Canada, 27-29 October 1986.
IEEE Computer Society,
1986, pp. 162–167.

[83] W. Zheng, A. Dave, J. G. Beekman, R. A. Popa, J. E. Gonzalez, and
I. Stoica, “Opaque: An Oblivious and Encrypted Distributed Analytics
Platform,” in 14th USENIX Symposium on Networked Systems Design
and Implementation, NSDI 2017, Boston, MA, USA, March 27-29, 2017,
2017, pp. 283–298.

[84] W. Zheng, R. A. Popa, J. E. Gonzalez, and I. Stoica, “Helen: Mali-
ciously Secure Coopetitive Learning for Linear Models,” in 2019 IEEE
Symposium on Security and Privacy, S&P 2019, San Francisco, CA,
USA, May 19-23, 2019, 2019, pp. 724–738.
Iordanescu,

[85] X. Zhu, G.
2018.
machinelearning/2018/03/07/using-microsoft-ai-to-build-a-lung-
disease-prediction-model-using-chest-x-ray-images/

I. Karmanov, and M. Zawaideh, Mar
https://blogs.technet.microsoft.com/

Available:

[Online].

A. Algorithms used by Porthos

APPENDIX

The additional algorithms that reshape ﬁlters, input, and
output, used by Porthos are shown in Algorithms 2, 3, and
4.

.

L

Algorithm 2 ReshapeFilter
Input: X ∈ Zf ×f
L .
Output: Z ∈ Zf 2×1
1. for i = {0, ..., f − 1} do
2.
3.
4.
5. end for

end for

for j = {0, ..., f − 1} do

Z[i · f + j] = X[i][j]

where n = m − f + 1.

L

L

for j = {0, ..., m − f } do

Algorithm 3 ReshapeInput
Input: X ∈ Zm×m
.
Output: Z ∈ Zn2×f 2
Global Information: Filter dimension f .
1. for i = {0, ..., m − f } do
2.
3.
4.
5.
X[k + i][l + j]
6.
7.
8.
9. end for

end for

end for

end for

for k = {0, ..., f − 1} do

for l = {0, ..., f − 1} do

Z[i·(m−f +1)+j][k·f +j] =

.

L

L

Algorithm 4 ReshapeOutput
Input: X ∈ Zn2×1
.
Output: Z ∈ Zn×n
1. for i = {0, ..., n − 1} do
2.
3.
4.
5. end for

end for

for j = {0, ..., n − 1} do

Z[i][j] = X[i · n + j]

B. Batch Normalization

Batch Normalization [46] is used to normalize the inputs
to intermediate layers across a mini-batch of images. For
a batch B of inputs, let µB and σ2
B be the mean and the
variance respectively. For an input x, the output of the batch
normalization layer is deﬁned as

BN (x) = γ

(x − µB)
(cid:112)σ2
B + (cid:15)

+ β

where γ and β are the model parameters learned during
training phase. In the inference phase, µB and σ2
B represent
the mean and variance of the entire training dataset.

Fig. 11: RESNET50: Top 1 accuracy vs Scale

Fig. 14: DENSENET121: Top 5 accuracy vs Scale

Benchmark
SQUEEZENET∗ (CIFAR)
MiniONN (CIFAR)
MiniONN (MNIST)

CHET MiniONN
1342
-
-

-
544
9.4

Gazelle
-
12.9
0.81

Porthos
0.05
0.36
0.03

TABLE X: Comparison with 2PC – All times in seconds.
CHET replaces ReLUs in a small SQUEEZENET with square
activations.

Fig. 12: RESNET50: Top 5 accuracy vs Scale

C. Accuracy of Athos

In this section, we present the Top 1 and Top 5 accuracies

of Athos on the ImageNet dataset.

D. Comparison with 2PC/FHE

See Table X which validates the well-known fact that 3PC
protocols like Porthos are much faster than 2PC/FHE-based
approaches. We omit other 2PC/FHE works ([62], [19], [15],
[14], [58], etc.) as the performance comparisons are similar
and do not provide additional insights.

E. Proof of malicious security

For simplicity, consider the case of single malicious party
Pi. Informally, we argue that our technique constrains Pi
to follow the instructions of the semi-honest protocol π(·)
faithfully. Or, deviating from faithful execution would result
in some honest party to abort. The ﬁrst Compute invocation

attest

attest

attest

of F (vki,ski)
ﬁxes the input of Pi used in the protocol. Since
every other F (vkj ,skj )
reliably knows the veriﬁcation key vki
used by F (vki,ski)
, it checks the signatures on the function
description (i.e., T (i)
π∗ ) as well as the messages of the protocol.
The unforgeability of the signature scheme guarantees that
Pi cannot forge signatures on incorrectly generated protocol
messages. Note that we use this property to ensure that both of
the following signatures cannot be forged: (a) signatures under
vki on messages generated by F (vki,ski)
and sent to honest Pj
(b) signatures under vkj on messages sent by Pj being fed
into F (vki,ski)
provides correct randomness to
generate messages of Pi in the semi-honest secure protocol.
Hence, all messages from Pi
to any honest party Pj are
generated correctly as directed by π. This argument can be
easily extended to multiple colluding corrupt parties.

. Also, F (vki,ski)

attest

attest

attest

Formally, we give a security proof using the standard
simulation paradigm (we refer the reader to [35], [18] for
details on the paradigm). That is, the protocol in Figure 8
securely realizes the ideal MPC functionality described in
Figure 9 against malicious adversaries.

Theorem 2 (Restated). Let π(·) be a semi-honest se-
cure MPC protocol securely realizing F f
mpc. Then, protocol
Protmalicious(P1, · · · , Pn) described in Figure 8 securely real-
izes F f
−hybrid model (with i ∈ [n]) against
malicious adversaries.

mpc in the F (vki,ski)

attest

Fig. 13: DENSENET121: Top 1 accuracy vs Scale

Proof Sketch. Let A be the real world adversary. Ideal world
adversary S that simulates the view of A is as follows: Let
S (cid:48) be the ideal world adversary or the semi-honest simulator
for π (this exists because π is semi-honest secure). S picks
{(vkk, skk)}k∈[n] and gives {vkk}k∈[n] to A. We denote a
corrupt party by Pi and honest party by Pj. Next, when A
invokes an instance of F (vki,ski)
on command Commit for
a corrupted party Pi, S simulates the correct behavior of

attest

76.276.2576.376.3576.476.4576.59111315171921232527Top1 AccuracyScaling FactorTop1 Accuracy Vs Scaling FactorFixed Point AccuracyFloating Point Accuracy93.0893.193.1293.1493.1693.1893.293.2293.249111315171921232527Top5 AccuracyScaling FactorTop5 Accuracy Vs Scaling FactorFixed Point AccuracyFloating Point Accuracy73.373.573.773.974.174.374.581012141618202224262830Top1 AccuracyScaling FactorTop1 Accuracy Vs Scaling FactorFixed Point AccuracyFloating Point Accuracy91.391.491.591.691.791.891.981012141618202224262830Top5 AccuracyScaling FactorTop5 Accuracy Vs Scaling FactorFixed Point AccuracyFloating Point Accuracyattest

F (vki,ski)
. Also, S sends correctly generated tokens {T (j)
π∗ }
for all honest parties to A. When S receives token from A
corresponding to a corrupted party Pi, it checks it against
π∗ and vki. It aborts if veriﬁcation fails. When A invokes
F (vki,ski)
with xi, S stores it as input of Pi. When A commits
to inputs of all corrupt parties, S sends these to F f
mpc to learn
output y. It sends inputs of corrupt parties and outputs y to

attest

S (cid:48) that generates the view of the adversary in the semi-honest
protocol, that contains the randomness for all corrupt parties
as well as the transcript of the protocol. Using this, it is easy
for S to simulate the view of A in the rest of the protocol. The
indistinguishability of the adversary’s view in real and ideal
executions follows from the semi-honest security of π.

