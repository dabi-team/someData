2
2
0
2

l
u
J

1

]
L
M

.
t
a
t
s
[

2
v
6
0
8
0
1
.
2
0
2
2
:
v
i
X
r
a

Stochastic Causal Programming for Bounding Treatment Eﬀects

Kirtan Padh1, 3, Jakob Zeitler2, David Watson2, Matt Kusner2, Ricardo Silva2, Niki Kilbertus1,3

1Helmholtz AI, Munich
2University College London
3Technical University of Munich
Corresponding author: kirtan.padh@helmholtz-muenchen.de

Abstract

Causal eﬀect estimation is important for numerous tasks in the natural and social sciences. However, identifying
eﬀects is impossible from observational data without making strong, often untestable assumptions. We consider
algorithms for the partial identiﬁcation problem, bounding the eﬀects of multivariate, continuous treatments over
multiple possible causal models when unmeasured confounding makes identiﬁcation impossible. We propose a
framework where observable evidence is matched to the implications of constraints encoded in a causal model by
norm-based criteria. This generalizes classical approaches based on generative models. Casting causal eﬀects as
objective functions in a constrained optimization problem, we combine ﬂexible learning algorithms with Monte
Carlo methods to implement a family of solutions under the name of stochastic causal programming. In particular,
we present ways by which such constrained optimization problems can be parameterized without likelihood functions
for the causal or the observed data model, reducing the computational and statistical complexity of the task.

1

Introduction

Estimating causal eﬀects is a key goal of scientiﬁc inquiry, enabling better decision making in medicine (Bica
et al., 2021), economics (Chernozhukov et al., 2018), epidemiology (Vandenbroucke et al., 2016), and beyond (Pearl,
2009; Imbens and Rubin, 2015). The gold standard for estimating these eﬀects is the randomized controlled trial
(RCT): randomly assign individuals to treatment and control groups (e.g., vaccine or placebo) and observe outcomes
(e.g., antibody levels). These experiments work because randomization removes confounding, which occurs when
pre-treatment covariates drive both treatment propensities and potential outcomes. However, in many cases it is
physically, logistically, or ethically impossible to conduct RCTs. In such cases, causal eﬀects can only be identiﬁed
under structural assumptions (Pearl, 2009; Hernán and Robins, 2020).

When unobservable confounders are present, techniques such as instrumental variable (IV) models (Hernán and Robins,
2020, Ch. 16), the front-door criterion (Pearl, 2009, Ch. 3) and proxies (Tchetgen et al., 2022) may be applicable.
Even then, identiﬁcation requires further assumptions, not just about the graphical structure but about the functional
form of causal associations, e.g., monotonicity (Angrist and Imbens, 1995), additivity (Hartford et al., 2017; Singh
et al., 2019; Muandet et al., 2020; Bennett et al., 2019) or conditions such as completeness (Tchetgen et al., 2022),
which are not immediately intuitive as they refer to unspeciﬁed hidden variables. When such assumptions fail, eﬀects
may still be partially identiﬁable—i.e., bounded with respect to the set of models consistent with the data (Manski,
1990). This task has not received nearly as much attention as the point estimation problem, despite promising early
work in this area (Chickering and Pearl, 1996; Balke and Pearl, 1997). Lately the topic has sparked some interest
in reinforcement learning (Kallus and Zhou, 2020; Zhang and Bareinboim, 2020), algorithmic fairness (Wu et al.,
2019a,b), and other settings (Gunsilius, 2019; Zhang and Bareinboim, 2021; Hu et al., 2021). Xia et al. (2021) outline
a procedure for bounding causal eﬀects with neural networks but restrict their focus to discrete, low-dimensional
data. Duarte et al. (2021); Zhang et al. (2021) reduce the bounding problem to a polynomial program, but both
assume that variables are discrete and Zhang et al. (2021) further assumes that variables are ﬁnite. In a recent paper,
Kilbertus et al. (2020) propose a method for computing causal bounds in IV models with continuous treatments using
gradient descent and Monte Carlo integration. Their procedure is limited to univariate settings (see Appendix G for
further limitations).

We extend this work to higher dimensions and diﬀerent causal structures, replacing the copula formulation of Kilbertus
et al. (2020) with a more generic parameterization that decouples model ﬁtting from changes due to the unobserved
confounder U .

1

 
 
 
 
 
 
This parameterization is related to recent literature on (conditional) normalizing ﬂows (Papamakarios et al., 2021),
where base distributions are converted into targets through some diﬀeomorphic transformation(s). Whereas the goal
in ﬂow models is typically generative, the sampling step in our method is a means toward the end of causal eﬀect
bounding.

We make the following contributions: (1) We propose a generic, modular form of the eﬀect bounding problem
compatible with a wide range of graphical structures, function classes, optimization procedures, and distance measures,
as well as a systematic way of simplifying the computation. (2) We derive an eﬃcient solution to the problem via
constraint sampling and automatic diﬀerentiation, extending the work of Kilbertus et al. (2020) to data of arbitrary
dimension. (3) We illustrate our method on synthetic and semi-synthetic datasets, where simulations conﬁrm that
our approach computes valid bounds even in complex settings where common assumptions fail. We ﬁrst present
In Section 3, we introduce a
our ideas in a general framework in Sections 2, along with illustrative examples.
concrete instantiation of the framework, with explicit assumptions about the model space and optimization procedure.
Following a number of experiments in Section 4, Section 5 concludes.

2 Setup

S

∈

∈

Rp and outcome Y

We ﬁrst formulate the general setup and then provide two concrete running examples based on the IV model and
a “leaky mediation” setting. Assume we observe data from causal model S(cid:63), with density function pS(cid:63) , including
R among the observed variables. Using
a (possibly multivariate) continuous treatment X
Pearl’s do notation Pearl (2009), the estimand of interest is ox(cid:63) (S(cid:63)) := ES(cid:63) [Y
do(X = x(cid:63))], typically not identiﬁed.
Our goal will be to minimize/maximize ox(cid:63) (S(cid:63)) over all admissible causal models S among a (uncountable) model
class
. We characterize admissibility via two types of constraints. First, the missing edges of the assumed directed
acyclic graph (DAG) encode conditional independencies between variables. Further assumptions on the functional
form of structural equations are required for non-vacuous solutions (Kilbertus et al., 2020; Gunsilius, 2021). We refer
to the constraints implied by graphical and functional assumptions jointly as structural constraints. Second, we have
observational data from S(cid:63). Denoting an estimate of the data distribution pS(cid:63) by ˆp, the distribution pS entailed
by an admissible causal model S should replicate this distribution. We measure this data constraint via a distance
function dist(pS, ˆp) into R+ that measures the (estimated) discrepancy between model S
and the ground truth
model S(cid:63) via observations.
Hence, we arrive at the following general problem setting for computing the minimum/maximum causal eﬀect among
all models

that are (dist, (cid:15))-compatible with the observed data:

∈ S

|

S

min / max
S∈S
subject to

ox(cid:63) (S)

dist(pS, ˆp)
structural constraints

(cid:15) ,

≤

[obj]

[c-data]

[c-struct]

(1)

(2)

(3)

Note that, unlike most optimization objectives in machine learning, the objective in Equation (1) depends on the
data only via (functionals of) a ﬁtted distribution ˆp. This suggests an interpretation of our task as decoupling model
selection from model ﬁtting: the former is a search over an equivalence class of causal models that (approximately)
match the observable distribution. The latter is in the realm of standard machine learning, which produces (functionals
of) ˆp regardless of causal assumptions. We believe this to be a fruitful viewpoint for a large variety of problems in
causal inference that require us to simultaneously accommodate diﬀerent qualitative structural assumptions and
provide a good ﬁt to observed data. Instead of conﬂating regularization and causal speciﬁcation when no unique
causal model explains the data (implying likelihood functions full of high-dimensional plateaus), our formulation
considers all models in reasonable agreement with the estimated observable distribution given by any black-box
algorithm. Importantly, as we show later, we can pick distance functions such that no full density estimation problem
has to be solved.

(cid:54)⊥⊥
=

Rq, treatments X

Z, (A2) Z
xi, yi, zi

Consider the instrumental variable model in Figure 1a. Following the structural causal model (SCM) notation
of Pearl (Pearl, 2009), we observe instruments Z
R
with a potentially high-dimensional confounded pair of background variables UX and UY . Here we assume (A1)
. We denote the i.i.d. observations that make up ˆp by
UX , UY
X
}
. Instead of the common additive noise or linearity assumptions, we consider a larger class of
. We
Z and the ﬁrst two moments of

| {
D
potentially non-linear, non-additive functions f :
propose to avoid full density estimation for [c-data] and instead only estimate X
Y
In the SCM of the leaky mediation setting in Figure 1d., a second confounder between M and Y is added to the
standard non-parametrically identiﬁed mediation example for front-door adjustment (Pearl, 2009, Ch. 3), rendering

that we will later encode in

Rp, and outcomes Y

, and (A3) Z

X, UX , UY

∈ X ⊂

∈ Z ⊂

∈ Y ⊂

⊥⊥{
n
i=1

X × U

Z × U

→ X

X, Z

→ Y

, g :

⊥⊥

| {

S

Y

}

{

}

}

X

Y

|

.

2

⊥⊥

UM , and again allow for non-linear, non-additive functions f :

the causal eﬀect of X on Y unidentiﬁable. Here, we have the structural constraints (B1) X
UX
Requirements. The key diﬃculty in operationalizing the optimization in Equation (1) is the parameterization of
. Our design choices are guided by eﬃciency of (i) the (constrained) optimization of ox(cid:63) (S), (ii) the evaluation of
to causal models satisfying [c-struct]. Moreover, we explicitly aim for methods that

S
dist(pS, ˆp), (iii) restricting
scale to large sample sizes n as well as multivariate treatments (p > 1) and instruments/mediators (q > 1).

M, UY
| {
.
→ M

⊥⊥
X × U

and (B2)

M × U

→ Y

, g :

S

Y

M

}

Y

3 Method

We start this section by ﬁrst describing the suggested function space representation (Section 3.1) of SCMs, and how
to avoid unnecessary causal parameters by exploiting some structural signatures (Section 3.2). This is followed by a
detailed algorithmic description of the optimization procedure.

X → Y

, u) :
·

) := f (
·

3.1 Response function framework
Specifying a causal model S, such as the one depicted in Figure 1a., involves functions such as f and g, as well
as the distribution of the potentially inﬁnite dimensional confounders U =
. To tackle this complexity,
we make use of the so-called response function framework (Balke and Pearl, 1994; Kilbertus et al., 2020). We
the response function for the ﬁxed value U = u of the background variable U . Note
call fu(
that in this case, fu indeed encodes the direct causal eﬀect of X on Y . A distribution over values of U entails a
distribution over response functions fu. Hence, instead of explicitly modeling U and f separately as part of a causal
model S, we can directly encode them jointly via a distribution over response functions.
Without restrictions on the functional dependence of X and Y on U , one cannot obtain non-trivial bounds (Gunsilius,
2021, 2019). As in general we have little information about the dimensionality and distribution of U , we argue that
it is more practical to work with the equivalent assumptions on the function space and distribution of response
functions fu. Speciﬁcally, we choose a family of response functions
that captures plausible direct
causal eﬀects from X to Y under all possible values of the confounding variable(s). We then assume a parameterized
family of distributions over
. For concreteness, we propose parameterized response
functions as linear combinations of a set of non-linear basis functions

UX , UY
{

, denoted by

X → Y}

pF
η |

F ⊂ {

f :

Rd

N:

F

∈

{

}

}

η

ψk :

{

X → Y}

K
k=1

for some K

∈

(cid:110)

fθ :=

:=

F

K
(cid:88)

k=1

θkψk

(cid:12)
(cid:12)
(cid:12) θk

∈

(cid:111)

R

.

(4)

F

is ﬁxed, pF
η

is fully described as a distribution over θ

Hence, once
RK. For ease of notation, we often drop
and summarize ψ := (ψ1, . . . , ψK). We could ﬁt ψk adaptively with almost no modiﬁcation
the dependence on
to the algorithm presented in the sequel (as long as they are diﬀerentiable), but we will choose to keep the basis
functions ﬁxed to demonstrate in the experiments the trade-oﬀ between other sources of causal knowledge and the
informativeness of the bounds.

F

∈

A naïve interpretation of Equation (4), combined with a ﬁxed choice of basis functions that we adopt for the sake of
illustration, is that it may introduce unwanted constraints in the causal model and may lead to “invalid” bounds. We
address these possible misunderstandings in Appendix A.

3.2 Graphical reduction

We reduce a given graphical structure to simplify computation and remove unneeded assumptions. Figure 1 illustrates
the following reduction steps for IV and leaky mediator examples.

a. Imagine we are given a graph that explicitly includes the latent background variables U of a structural causal
model (Pearl, 2009), where each observed variable is a deterministic function of its direct causes. We express
unmeasured confounding with bidirected edges among the background variables. This forms a model of marginal
independence (Richardson, 2003) among U variables, which can be hard to parameterize.

b. To simplify computation, we convert as many bidirected edges to directed edges as possible while preserving the
same structural constraints (Drton and Richardson, 2008). This allows for a simpliﬁed parameterization. For
instance, for the leaky mediator we have p(ux, um, uy) = p(ux) p(um) p(uy
c. We can remove unnecessary assumptions about structural equations when p(v

do(pa(v)), the distribution of some
variable V under intervention on its parents pa(V ), is identiﬁable. Instead of treating UV as structural background
variables with an unknown distribution and dimensionality, we convert them into “non-causal” random variables NV

ux, um).

|

|

3

g
n
i
t
t
e
s
V
I

n
o
i
t
a
i
d
e
m
y
k
a
e
L

a.

Z

UX

UY

X

Y

b.

Z

UX

UY

X

Y

c.

Z

NX

UY

X

Y

d.

Z

NX

X

ηY

Y

UX

UM

UY

UX

UM

UY

NX

NM

UY

NX

NM

X
Rp

M
Rq
mediators

∈

X

M

Y

X

M

Y

X

M

Y

R

∈
outcome

∈

treatments

ηY

Y

Figure 1: We show the general graphical reduction procedure for modeling latent confounding described in the text
for the IV and leaky mediation setting.

of the same dimension as V , with a ﬁxed distribution so that V is a deterministic function of its parents, and
which is invertible on NV . For instance, we can model p(x
X | Z(NX ), where X is
one-dimensional and FX | Z(

) is the cdf of X given Z and NX is uniform on [0, 1].
·
d. Finally, any remaining background variable will require further causal assumptions. For that, we rely on recasting
the conditional model for each variable V with a parent UV as being generated by a mixture of deterministic
functions, as explained in the previous section.

z, ux) in the IV model as X = F −1

|

All of the above provides an alternative to blackbox models such as those of Hu et al. (2021), which ignore that many
of the assumptions about structural equations can be avoided, and that many factors of the data distribution can be
directly encoded without wasteful Monte Carlo simulations.

3.3 Parameterizing

and satisfying [c-struct]

S

Next, we describe how to leverage the response function framework for a useful parameterization of causal models
.
S
Again, we focus on the IV case for concreteness; see Appendix B for our analysis of the leaky mediator setting. Despite
recent advances in adding exact (conditional) independencies [c-struct] as explicit constraints in a smooth gradient-
based optimization (Zheng et al., 2018), this approach is still unwieldy in our case with unobserved confounding.
Therefore we encode [c-struct] directly in our choice of model class

and write for clarity

S

:=

pη

{

η

|

∈

S

Rd; (A1)-(A3) satisﬁed for (X, Y, Z)

pη

.

}

∼

S

. We think of N as a source of randomness1 that is shared in modeling X

Using the parameterization from Equation (4), we may now reformulate (A2) and (A3) as Z
X.
Consequently, we propose the DAG in Figure 1b. as a model for θ that explicitly encodes (A2) and (A3) via d-separation
on this graphical structure, we have absorbed [c-struct] into the
(Pearl, 2009). Hence, when basing all pη
N , thereby
and θ
deﬁnition of
still allowing for dependencies between X and θ. Observe that a model for X
can be ﬁt once upfront from
observed data and remains ﬁxed throughout the optimization. Later, we will need to deterministically recover N
from Z and X, leaving us with any invertible conditional model hZ(N ) for which h−1
∈ Z
. For example, conditional normalizing ﬂows composed of invertible and diﬀerentiable (i.e., diﬀeomorphic)
and x
transformations (Papamakarios et al., 2021) are ﬂexible candidates that we use in our experiments. Note that this
parameterization implies dN = p. We provide all details of the speciﬁc implementation in Appendix E.
Once hZ is ﬁxed, we model θ with a partially speciﬁed multivariate distribution as follows,

Z=z(x) exists uniquely for all z

θ and Z

Z, N

Z, N

∈ X

∈ S

(cid:54)⊥⊥

⊥⊥

| {

| {

}

}

θ

|

|

N

θ

|

∼

pη.θ

(cid:0)

·

; µη0 (N ), Ση1(N )(cid:1),

(5)

with mean and covariance functions µη0(N ) and Ση1(N ), both parameterized by our optimization parameters η =
(η0, η1). Other than that, we make no further assumptions about the shape of pη.θ, as they are unnecessary for
the inference problems we set up to solve. To ensure Ση1(N ) is a valid covariance matrix, we represent it in terms
of its Cholesky factor L and add a small constant Ω to the diagonal Ση1 = L(cid:62)L + Ω1. Again we can use ﬂexible
and resort to neural networks with parameters η0 and η1 in our experiments.
function approximators for µη0
, where Y is
The combined parameters η = (η0, η1) now encode our family of causal models
implicitly given by the random variable fθ(X) with X = hZ(N ), N
N

|
(0, 1), and the required moments of θ

and Ση1

Rd

pη

=

∈

S

}

{

η

∼ N

|

1For emphasis, we repeat that N is not to be interpreted as causal background variables for X: it is merely a device for parameterizing

p(x | z) and p(θ | x, z), and it is not meant to have a causal interpretation.

4

as in Equation (5). We remark that the choice of which functionals/moments of
θ to parameterize depends on
the information from the data that we want to use, which in the sequel will be the ﬁrst and second moments of
Y

X, Z

F

| {

.
}

We now rephrase our main optimization problem as:

min / max
η∈Rd
subject to

ox(cid:63) (η) = ψ(x(cid:63))(cid:62) EN [µη0(N )]

dist(pη, ˆp)

(cid:15) .

≤

[obj]

[c-data]

For the objective equation, we used the law of total expectation. Since N follows a standard Gaussian, we can
easily estimate the remaining expectation from a ﬁnite sample. So far, the data have only entered once when we
chose
. We still must enforce the remaining data matching constraints
[c-data].

Z) is matched by all pη

such that ˆp(X

∈ S

S

|

Algorithm 1 Computing upper or lower bounds on E[Y
Require: dataset D = {(zi, xi, yi)}n

i=1; constraint functions {φl : Y → R}L

|

do(X = x(cid:63))] in the IV setting.

l=1; basis functions {ψk : X → Y}K

k=1; norm (cid:107) · (cid:107) for

dist; batchsize for Monte Carlo B; number of support points M ; tolerance (cid:15) > 0
Setup: One-time computations shared for diﬀerent x(cid:63) values

1: Fit (invertible) conditional normalizing ﬂow X = hZ (N ) from data D for N ∼ N (0, 1p)
2: Fit MLPs ˆφ1 : xi, zi → yi and ˆφ2 : xi, zi → y2
3: subsample M indices from [n] (uniform, no replacement)

i by minimizing the squared loss from data D

(cid:46) “support points”, w.l.o.g. use [M ]

Optimization: performed separately for lower and upper bound for each x(cid:63)

4: minimize Objective(η) subject to Constraint(η) ≤ (cid:15) (see Appendix E.5)

5: function Objective(η)
6:

ox(cid:63) (η) ← ψ(x(cid:63))(cid:62) 1
B
return ±ox(cid:63) (η)

7:

(cid:80)B

j=1 µη0 (nj) with nj ∼ N (0, 1p)

8: function Constraint(η)
9:

zj (xj) for j ∈ [M ]

nj ← h−1
A1,j(η) ← ψ(xj)(cid:62)µη0 (nj) for j ∈ [M ]
A2,j(η) ← ψ(xj)(cid:62)(cid:16)
Ση1 (nj) + µη0 (nj)µη0 (nj)(cid:62)(cid:17)
νl,j ← ˆφl(xj, zj) − Al,j(η) for l ∈ {1, 2}, j ∈ [M ]
return (cid:107)ν(cid:107)

10:

11:

12:

13:

ψ(xj) for j ∈ [M ]

(cid:46) diﬀerentiable w.r.t. η
(cid:46) objective, ± for lower/upper bound

(cid:46) invert X | Z model to infer “noises”

(cid:46) moments implied by model

(cid:46) constraint matrix

3.4 Satisfying [c-data]: matching the data
is that we only
Z) p(Z). A key advantage of our construction of
We ﬁrst factorize p(Z, X, Y ) = p(Y
need to match the factor p(Y
X, Z) to satisfy [c-data] instead of having to perform density estimation to match
high-dimensional distributions via, e.g., f-divergences, integral probability metrics, Stein discrepancy, adversarial
X, Z) and
optimization, or variational inference. For us, any eﬃciently computable similarity measure dist on ˆp(Y
can be used to keep candidate models pη close to matching the entire observed data distribution. This
fθ(X)
matching can be conveniently formulated as matching expectations of the two distributions when transformed by a
ﬁxed set of dictionary functions

. That is, we want the absolute values of

X, Z) p(X

X, Z

| {

R

S

}

|

|

|

|

L
φl :
l=1
{
}
νl(x, z) = Ey∼ ˆp(y | x,z)[φl(y)]

Y →

Eθ∼pη(θ | x,z)[φl(fθ(x))]

−

(6)

∈ X × Z

to be small for all l and all (x, z)
. Since X, Z are continuous (and potentially high-dimensional), this would
amount to an uncountably inﬁnite set of constraints. In high dimensions, a naïve discretization of X, Z also fails
.
(Kilbertus et al., 2020). Instead, we aim to make
X × Z
|
Arguably, the most representative set is a uniformly random subsample of the observed data
of size M . For
notational simplicity, we assume w.l.o.g. that these “support points” are the ﬁrst M indices. In other words, deﬁning
RL×M via νl,j = νl(xj, zj) (using j = 1, . . . , M to index the selected
(by some overloading of notation) the matrix ν
on RL×M .2
support points), we obtain a natural family of overall distances dist(pη, ˆp) =

small at a representative, ﬁnite set of points in

for any (semi-)norm

νl(x, z)

D

∈

|

ν
(cid:107)

(cid:107)

(cid:107) · (cid:107)

2We remark that, formally, if we allow L, M → ∞ the functions φl can be chosen such that exact matching between ˆp and pη can be
approximated arbitrarily well, e.g., by approximating the characteristic function using l and matching it everywhere on X × Y using the
entry-wise sup-norm.

5

In our experiments, we speciﬁcally consider the entry-wise sup-norm
For
(cid:107) · (cid:107)
whereas for

2,2 we get away with a single overall constraint.

∞,∞ we require the absolute value of each entry to be small, i.e., practically have to enforce M

∞,∞ and the entry-wise 2-norm

(cid:107) · (cid:107)

2,2.
L constraints,

(cid:107) · (cid:107)

·

(cid:107) · (cid:107)

The ﬁrst expectation in Equation (6) is estimable from the observed data via ˆφl(x, z)
ˆφl :
X × Z →
on the training data
constraint formulation, in that we can explicitly write

→
. Because hZ was assumed to be invertible, our modeling choice for

x, z], where
≈
x, z] that were learned in a supervised fashion
plays nicely with our

R are regression functions mapping x, z

E[φl(Y )

E[φl(Y )

D

S

|

|

x, z

θ

|

θ
∼ F

(cid:16)

θ; µη0

(cid:0)h−1

z (x)(cid:1), Ση1

(cid:0)h−1

z (x)(cid:1)(cid:17)

.

(7)

For general dictionary functions φl, we can again estimate the second expectation in Equation (6) using ﬁnite
samples from a fully-speciﬁed version of Equation (7). To simplify optimization and modeling, in practice it often
suﬃces to constrain the ﬁrst few moments of Y
, e.g., to set φ1(Y ) = Y and φ2(Y ) = Y 2. This task is much
}
more data eﬃcient than modeling the complete joint distribution p(X, Y, Z), as required, for example, by generative
methods such as GANs (Hu et al., 2021). This further simpliﬁes the second expectation in Equation (6) to the
following:

X, Z

| {

A1,j(η) = ψ(xj)(cid:62)µη0 (nj) , A2,j(η) = ψ(xj)(cid:62)(cid:0)Ση1 (nj) + µη0(nj)µη0 (nj)(cid:62)(cid:1)ψ(xj) ,

(8)

where nj := h−1

zj (xj) for j

[M ].

∈

3.5 Solving the optimization
Taking all the steps from previous sections together, we have νl,j = ˆφl(xj, zj)
following non-convex optimization problem with non-convex constraints

−

min / max
η∈Rd
subject to

ox(cid:63) (η) = ψ(x(cid:63))(cid:62) EN [µη0(N )]

ν
(cid:107)

(cid:107) ≤

(cid:15)

Al,j(η) and ultimately arrive at the

[obj]

[c-data]

(9)

(cid:107) · (cid:107)

∞,∞ we aim at enforcing M

for which the augmented Lagrangian method with inequality constraints is a natural choice (Nocedal and Wright,
2006, Sect. 17.4). We provide a high-level description in Algorithm 1 and provide speciﬁcs in Appendix E.5. Note
L inequality constraints, one for each entry. While
that for the entry-wise sup-norm
we have already argued that L = 2 is a sensible choice, we get to choose a ﬁxed number of “support datapoints” M
regardless of the dimensionality of X to trade oﬀ capturing the observed distribution and stability of the augmented
Lagrangian optimization. For very high-dimensional data, one may take inspiration from Wang and Bertsekas (2016)
and further subsample a ﬁxed number of constraints uniformly at random at each step of the optimization. For convex
problems, this form of constraint subsampling can be shown to converge to the optimal solution (Wang and Bertsekas,
2016). Though global guarantees are elusive for non-convex problems, we follow a long tradition of machine learning
research that achieves impressive results on complex tasks with stochastic gradient descent. We record the largest
(maximization) and smallest (minimization) values over multiple runs with diﬀerent random initializations.

·

4 Experiments

Since ground truth causal eﬀects must be known to properly evaluate the validity of our bounds, we primarily make
use of simulated datasets. All experiments in the main paper are in a partially identiﬁable setting. As a sanity
check, we show experiments for identiﬁable settings as well as for other datasets and constraint formulations in
Appendix F.

4.1 Treatment choices
When visualizing results for multidimensional treatments X, we vary the interventional values x(cid:63) along a single
treatment dimension, keeping the remaining components at ﬁxed values. While this allows us to show continuous
treatment eﬀect curves, we note our method can compute bounds for any multidimensional intervention do(X = x(cid:63)).
Speciﬁcally, in the results shown here, we vary the ﬁrst component of X and ﬁx the values of the other components to
their empirical marginal means. For each ﬁgure, we include a kernel density estimate of the marginal distribution
of the empirically observed treatments to distinguish “data poor” from “data rich” regions. In “data poor” regions
(towards the tails of the empirical distribution), we may expect our bounds to become looser, as less information
about the data-matching constraints is available.

6

Figure 2: Top Left (IV-lin-2d-weak; comparing norms) Our framework easily allows for diﬀerent data-matching
criteria (dist). The choices shown here (
2,2) yield comparable and consistent bounds. Top Right
(LM-lin-2d-strong; leaky mediator setting) We get reliable bounds also in the leaky mediator setting compared to
the GAN framework. Bottom Left (IV-lin-2d-strong; comparing response functions) As expected, neural response
functions give wider bounds than a linear polynomial basis because of being less expressive. Bottom Right (IV-lin-
2d-strong; GAN comparison) Our method reliably yields valid bounds even under strong confounding, while the GAN
framework becomes unstable, potentially due to diﬃculties with the bilevel optimization problem.

∞,∞ and

(cid:107) · (cid:107)

(cid:107) · (cid:107)

4.2 Baselines

We compare our method to a naïve regression and the method of Hu et al. (2021). We are unaware of any other competi-
tor capable of estimating bounds in the presence of multivariate, continuous treatments/instruments/mediators.

• Regression with MLP. We naïvely ﬁt an MLP with quadratic loss to predict outcome Y from the multidimensional

treatment X, a modeling approach that assumes no confounding at all.

• GAN framework. Hu et al. (2021) parameterize the causal model (i.e., its exogenous random variables and
structural equations) with neural networks and apply the adversarial learning framework to search the parameter
space. We adjust the model in their code to our examples, but otherwise leave hyperparameter choices and
convergence criteria untouched. The error allowed on matching the observed distribution is η = 0.001 (not our η)
and bounds are calculated as the mean over the eﬀects of the 50 last models with error below η, plus/minus the
variance of those 50 values.

7

0.00.1Density−4−2024x?−4−202OutcomeE[Y|do(x?)]E[Y|x?]l2norml∞norm0.00.1Density−4−2024x?−4−3−2−1012OutcomeE[Y|do(x?)]E[Y|x?]OursGAN0.00.1Density−4−202x?−10−505OutcomeE[Y|do(x?)]E[Y|x?]PolybasisMLPbasis0.00.1Density−4−202x?−10−50510OutcomeE[Y|do(x?)]E[Y|x?]OursGAN4.3

Implementation choices

ψk
{

Choice of response functions. As described in Equation (4), we choose linear combinations of non-linear basis
}k∈[K]. For our experiments we mostly work with a set of K neural basis functions, obtained from the
functions
last hidden-layer activations of an MLP ﬁt to the observed data
}i∈[n], as well as (multivariate) polynomials
(xi, yi)
{
up to a ﬁxed degree (see Appendix E.4 for details). For two-dimensional treatments, we use K = 6 and K = 3
for polynomial and neural basis functions, respectively. For three-dimensional treatments we use K = 10 for both
polynomial and neural basis functions. This allows up to quadratic terms in the polynomial basis for both two- and
three-dimensional treatments.

R for one
For our method, we individually compute lower (
).
dimension of the treatment and show how it compares to the true causal eﬀect (
The lines shown for lower and upper (
) bounds are univariate cubic splines ﬁt to the bounds for individual x(cid:63)-grid
values. We use n = 10, 000 i.i.d. sampled datapoints for each experiment and subsample M = 100 datapoints uniformly
at random for the data constraints [c-data]. For the X
Z model in the IV setting we use a quadratic conditional
spline normalizing ﬂow. Details of the implementation, including hyperparameters, are described in Appendix E.

) bounds at multiple values x(cid:63)

) and naïve regression (

) and upper (

(cid:52)

(cid:53)

∈

|

Getting ﬁnal bound estimates. For each x(cid:63), we run 5 optimizations with diﬀerent seeds each for the lower and
upper bounds. For the ﬁnal upper bound estimate, we take the maximum of the 5 upper bound estimates we get, and
for the ﬁnal lower bound estimate we take the minimum of the 5 lower bound estimates we get. We follow the same
process for the GAN bounds.

4.4 Results
We focus on datasets where the true eﬀect is a linear or quadratic polynomial function of the treatment X. A full
glossary of datasets can be found in Appendix D, along with exact structural equations for each setting. While the
naming of the datasets is intuitive, Figure 4 provides a short description of the naming logic. We now describe the
results obtained for selected datasets with more results and details in Appendix F.

IV-lin-2d-strong. This dataset is simulated from an IV setting, where the true eﬀect Y
two-dimensional treatment X. The naïve regression E[Y
strong confounding (see, Figure 2 (bottom left)).

do(X) is linear in a
X] diﬀers substantially from the true eﬀect, indicating

|

|

We start by assessing the eﬀect of the ﬂexibility of response functions on our bounds in Figure 2 (bottom left).
Choosing less ﬂexible basis functions (polynomials) yields tighter bounds, highlighting the ﬂexibility of our approach in
obtaining more informative bounds when more restrictive assumptions are made. Our method can also accommodate
alternative constraint formulations and slack parameters. We show experiments demonstrating this ﬂexibility in
Appendix F. While sometimes loose, especially for ﬂexible basis functions (MLP) and in “data poor” regions towards
the tails of the empirical distribution of observed treatments, our bounds contain the true causal eﬀect for all x(cid:63).
This validity holds for all other experiments as well.

Next, Figure 2 (bottom right) compares our approach to the GAN framework baseline. First, we note that methods
that ﬁt a model and bounds at the same time, like Hu et al. (2021), essentially need to solve a bilevel optimization
problem, where the same parameters are shared in the deﬁnition of the constraints (which require optimizing a measure
of ﬁtness) and the causal quantity of interest (which requires optimizing a diﬀerent problem). Such a strategy can be
wasteful and potentially more prone to optimization and regularization challenges. Our goal in comparing3 to Hu
et al. (2021) is to show that our framework simpliﬁes constraints through structural encoding and avoids full density
estimation while giving comparable or better results than those from the GAN framework. Indeed, Figure 2 (bottom
right) shows that despite the ﬂexible neural basis functions, our approach can yield tighter bounds and avoid the
instabilities observed in the GAN approach when we move towards the tails of the observational distribution.

We show similar comparisons for linear and quadratic true eﬀect IV settings with strong and weak confounding as
well as two- and three-dimensional treatments in Appendix F.

IV-lin-2d-weak. This is an IV setting with weak confounding. In Figure 2 (top left) we show how our bounds
behave under diﬀerent choices of dist, namely under the entry-wise
L constraints
∞,∞ norm (which results in M
in the augmented Lagrangian) versus the entry-wise
2,2 norm (yielding only a single constraint). The obtained
bounds are compatible and comparable, indicating relatively mild eﬀects of the choice of the data-matching criterion
dist.
LM-lin-2d-strong. Figure 2 (top right) shows results for data from a leaky mediator setting, where the true
eﬀect is a linear function of the mediator M , and the treatment X is two-dimensional. Confounding between the

(cid:107) · (cid:107)

(cid:107) · (cid:107)

·

3For generality, we use the neural basis functions for all experiments where we compare to the GAN framework, as they are expected

to give wider bounds than polynomials.

8

mediator and the eﬀect is relatively strong. These results corroborate our ﬁndings regarding stability and reliability
of our bounds compared to the GAN framework from the IV setting, despite using the neural basis function. Again,
additional results for diﬀerent structural assumptions, treatment dimensions, and confounding strength are presented
in Appendix F.

5 Discussion

Causal modeling inevitably involves a trade-oﬀ between the strength of input assumptions and the speciﬁcity of
resulting inferences. If assumptions do not correspond to reality, the inference that follows is unwarranted. The role of
a method is to provide the sandbox in which assumptions can be transparently expressed and informative constraints,
where available, are not wasted. Ultimately, no automated method can choose the untestable assumptions on which
any particular application of causal inference relies. See Appendix A for further discussion.

After parameterization, the optimization problem in Equation (1) will generally result in a non-convex objective with
non-convex constraints. Therefore, our proposed gradient-based local optimization may not converge to a global
optimum, possibly rendering our bounds overly tight. Empirically, we do not observe evidence of consistently getting
stuck in bad local optima. Because we optimize both bounds individually for each value of x(cid:63), our method may be
computationally expensive when the intervention space is very large. However, it is well-suited for scenarios where
we want reliable bounds on a well-deﬁned set of plausible interventions. Finally, we have not accounted for the
uncertainty of our bounds. Conﬁdence or credible intervals for both extrema can help practitioners evaluate the
reliability of causal inferences, and are an interesting direction for future work.

From an ethical perspective, more reliable methods for bounding causal eﬀects could help quantify causal eﬀects
of high-stakes or consequential decisions when identiﬁability is impossible. They may also alleviate the temptation
to blindly accept whichever assumptions are necessary to ensure point identiﬁcation. However, by the same token,
bounds may still misrepresent treatment eﬀects when untestable assumptions are not satisﬁed. We provide more
details on ethical considerations in Appendix H.

We have introduced a stochastic causal program for bounding treatment eﬀects in partially identiﬁable settings. Our
approach does not rely on the typical assumptions of linearity, monotonocity, or additivity. We presented a novel
parameterization for decoupling observed from unobserved potential outcomes, and derived an eﬃcient procedure for
optimizing over a set of causal models consistent with the data. Experiments demonstrate that our method produces
valid and informative bounds in a wide range of settings, including with continuous and multidimensional instruments,
mediators, treatments, and outcomes.

References
Angrist, J. D. and Imbens, G. W. (1995). Two-stage least squares estimation of average causal eﬀects in models with

variable treatment intensity. J. Am. Stat. Assoc., 90(430):431–442.

Balke, A. and Pearl, J. (1994). Counterfactual probabilities: Computational methods, bounds and applications. In

Proceedings of the 10th Conference on Uncertainty in Artiﬁcial Intelligence, pages 46–54.

Balke, A. and Pearl, J. (1997). Bounds on treatment eﬀects from studies with imperfect compliance. J. Am. Stat.

Assoc., 92(439):1171–1176.

Bennett, A., Kallus, N., and Schnabel, T. (2019). Deep generalized method of moments for instrumental variable

analysis. In Advances in Neural Information Processing Systems.

Bica, I., Alaa, A. M., Lambert, C., and van der Schaar, M. (2021). From real-world patient data to individualized
treatment eﬀects using machine learning: Current and future methods to address underlying challenges. Clin.
Pharmacol. Ther., 109(1).

Bingham, E., Chen, J. P., Jankowiak, M., Obermeyer, F., Pradhan, N., Karaletsos, T., Singh, R., Szerlip, P. A.,
Horsfall, P., and Goodman, N. D. (2019). Pyro: Deep universal probabilistic programming. J. Mach. Learn. Res.,
20:28:1–28:6.

Chernozhukov, V., Chetverikov, D., and Kato, K. (2018). Inference on causal and structural parameters using many

moment inequalities. Rev. Econ. Stud., 86(5):1867–1900.

Chickering, D. M. and Pearl, J. (1996). A clinician’s tool for analyzing non-compliance. In Proceedings of the 13th

AAAI Conference on Artiﬁcial Intelligence, pages 1269–1276.

9

Daubechies, I., DeVore, R., Foucart, S., Hanin, B., and Petrova, G. (2021). Nonlinear approximation and (deep) relu

networks. Constr. Approx., pages 1–46.

Dawid, A. (2003). Causal inference using inﬂuence diagrams: the problem of partial compliance. In Green, P., Hjort,

N., and Richardson, S., editors, Highly Structured Stochastic Systems, pages 45–65. Oxford University Press.

Drton, M. and Richardson, T. (2008). Graphical methods for eﬃcient likelihood inference in Gaussian covariance

models. J. Mach. Learn. Res., 9:893–914.

Duarte, G., Finkelstein, N., Knox, D., Mummolo, J., and Shpitser, I. (2021). An automated approach to causal

inference in discrete settings. arXiv preprint, 2109.13471.

Gentzel, A. M., Pruthi, P., and Jensen, D. (2021). How and why to use experimental data to evaluate methods
for observational causal inference. Proceedings of the 38th International Conference on Machine Learning, pages
3660–3671.

Gunsilius, F. (2019). Bounds in continuous instrumental variable models. arXiv preprint, 1910.09502.

Gunsilius, F. F. (2021). Nontestability of instrument validity under continuous treatments. Biometrika, 108(4):989–995.

Gupta, M., Louidor, E., Mangylov, O., Morioka, N., Narayan, T., and Zhao, S. (2020). Multidimensional shape

constraints. Proceedings of the 37th International Conference on Machine Learning, pages 3918–3928.

Hartford, J., Lewis, G., Leyton-Brown, K., and Taddy, M. (2017). Deep IV: A ﬂexible approach for counterfactual

prediction. In Proceedings of the 34th International Conference on Machine Learning.

Hernán, M. A. and Robins, J. M. (2020). Causal Inference: What If. Chapman & Hall/CRC Studies, Boca Raton.

Hu, Y., Wu, Y., Zhang, L., and Wu, X. (2021). A generative adversarial framework for bounding confounded causal

eﬀects. In Proceedings of the 35th AAAI Conference on Artiﬁcial Intelligence.

Imbens, G. W. and Rubin, D. B. (2015). Causal Inference for Statistics, Social, and Biomedical Sciences: An

Introduction. Cambridge University Press, Cambridge.

Kallus, N. and Zhou, A. (2020). Confounding-robust policy evaluation in inﬁnite-horizon reinforcement learning. In

Advances in Neural Information Processing Systems.

Kilbertus, N., Ball, P. J., Kusner, M. J., Weller, A., and Silva, R. (2019). The sensitivity of counterfactual fairness to

unmeasured confounding. In Proceedings of the 35th Conference on Uncertainty in Artiﬁcial Intelligence.

Kilbertus, N., Kusner, M. J., and Silva, R. (2020). A class of algorithms for general instrumental variable models. In

Advances in Neural Information Processing Systems.

Kilbertus, N., Rojas Carulla, M., Parascandolo, G., Hardt, M., Janzing, D., and Schölkopf, B. (2017). Avoiding

discrimination through causal reasoning. Advances in neural information processing systems, 30.

Kusner, M. J., Loftus, J., Russell, C., and Silva, R. (2017). Counterfactual fairness. Advances in neural information

processing systems, 30.

Manski, C. F. (1990). Nonparametric bounds on treatment eﬀects. Am. Econ. Rev., 80(2):319–323.

Muandet, K., Mehrjou, A., Lee, S. K., and Raj, A. (2020). Dual instrumental variable regression. In Advances in

Neural Information Processing Systems, volume 33, pages 2710–2721.

Nocedal, J. and Wright, S. (2006). Numerical optimization. Springer Science & Business Media.

Papamakarios, G., Nalisnick, E., Rezende, D. J., Mohamed, S., and Lakshminarayanan, B. (2021). Normalizing ﬂows

for probabilistic modeling and inference. J. Mach. Learn. Res., 22(57):1–64.

Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L.,
Desmaison, A., Kopf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L., Bai,
J., and Chintala, S. (2019). Pytorch: An imperative style, high-performance deep learning library. In Advances in
Neural Information Processing Systems 32, pages 8024–8035.

Pearl, J. (2009). Causality. Cambridge University Press, New York.

Richardson, T. (2003). Markov properties for acyclic directed mixed graphs. Scand. J. Stat., 30(1):145–157.

10

Robins, J. M., VanderWeele, T. J., and Gill, R. D. (2015). A proof of Bell’s inequality in quantum mechanics using

causal interactions. Scandinavia Journal of Statistics, 42:329–335.

Schölkopf, B., Herbrich, R., and Smola, A. J. (2022). A generalized representer theorem. Lecture Notes in Computer

Science, 2111:416–426.

Shen, Z., Yang, H., and Zhang, S. (2021). Neural network approximation: Three hidden layers are enough. Neural

Netw., 141:160–173.

Singh, R., Sahani, M., and Gretton, A. (2019). Kernel instrumental variable regression. In Advances in Neural

Information Processing Systems, pages 4595–4607.

Sonja A. Swanson, M. A. H., Miller, M., Robins, J. M., and Richardson, T. S. (2018). Partial identiﬁcation of the
average treatment eﬀect using instrumental variables: Review of methods for binary instruments, treatments, and
outcomes. J. Am. Stat. Assoc., 113:933–947.

Spirtes, P., Glymour, C., and Scheines, R. (2000). Causation, Prediction and Search. MIT Press.

Tchetgen, E. J. T., Ying, A., Cui, Y., Shi, X., and Miao, W. (2022). An introduction to proximal causal learning.

arXiv:2009.10982.

Vandenbroucke, J. P., Broadbent, A., and Pearce, N. (2016). Causality and causal inference in epidemiology: the

need for a pluralistic approach. Int. J. Epidemiol., 45(6):1776–1786.

Wang, M. and Bertsekas, D. P. (2016). Stochastic ﬁrst-order methods with random constraint projection. SIAM J.

Optim., 26(1):681–717.

Wasserman, L. (2006). All of Nonparametric Statistics. Springer.

Wolfe, E., Spekkens, R. W., and Fritz, T. (2019). The inﬂation technique for causal inference with latent variables. J.

Causal Inference, 7(2).

Wu, Y., Zhang, L., and Wu, X. (2019a). Counterfactual fairness: Unidentiﬁcation, bound and algorithm. In Proceedings

of the 28th International Joint Conference on Artiﬁcial Intelligence, pages 1438–1444.

Wu, Y., Zhang, L., Wu, X., and Tong, H. (2019b). Pc-fairness: A uniﬁed framework for measuring causality-based

fairness. In Advances in Neural Information Processing Systems.

Xia, K., Lee, K.-Z., Bengio, Y., and Bareinboim, E. (2021). The neural-causal connection: expressiveness, learnability,

and inference. In Advances in Neural Information Processing Systems.

Zhang, J. and Bareinboim, E. (2020). Designing optimal dynamic treatment regimes: A causal reinforcement learning

approach. In Proceedings of the 37th International Conference on Machine Learning.

Zhang, J. and Bareinboim, E. (2021). Bounding causal eﬀects on continuous outcomes. In Proceedings of the 35th

AAAI Conference on Artiﬁcial Intelligence.

Zhang, J., Tian, J., and Bareinboim, E. (2021). Partial counterfactual identiﬁcation from observational and

experimental data. arXiv preprint, 2110.05690.

Zheng, X., Aragam, B., Ravikumar, P. K., and Xing, E. P. (2018). Dags with no tears: Continuous optimization for

structure learning. In Advances in Neural Information Processing Systems 31.

11

A On the Choice of Function Space

The function space in Eq. (4) is, at a high-level view, a standard ﬁnite basis expansion with or without adaptive
bases. We chose this particular function space template as it is (i) general, (ii) computationally advantageous and (iii)
scientiﬁcally advantageous.

It is general, as it can arbitrarily approximate any practical function of interest (keeping in mind that allowing
for an unbounded number of discontinuities will result in vacuous bounds (Gunsilius, 2021)), particularly when we
are dealing with a small number of causal parents. As a matter of fact, (Gunsilius, 2019) uses as basis functions a
truncated wavelet expansion. We could likewise use the dictionary of regression spline basis functions, with splits
decided by any rule of interest, including uniform grids or those based on the training points.

As a matter of fact, no computable estimator of nonparametric functions is inﬁnite dimensional at any given sample
size. In case of kernel machines, for instance, the celebrated Representer Theorem of (Schölkopf et al., 2022) shows
how any resulting estimate will be a function that is parameterized explicitly by the data (and such will be the case
for the broad class of linear smoothers (Wasserman, 2006, Ch. 5)). As our causal models are not ﬁt to the data
directly, but to estimated functionals of the observed distribution, which we use as constraints in a mathematical
program, we can directly parameterize it in terms of a ﬁnite basis expansion.

Moreover, there is nothing stopping us from making each element ψi of the basis functions parameterized by, say, a
linear transformation of the function inputs followed by some non-linearity (eﬀectively, a hidden unit in a feedforward
neural network). An entire neural network could also be used for each ψi, so that the function space becomes a deep
model, with the distribution over the function space conﬁned only to randomness on the θ parameters. Nothing in
the main algorithm changes, except for extra terms added to the overall gradient.

This leads to the fact that our function space is computationally advantageous, particularly when we can eliminate
bidirected edges using ideas from Drton and Richardson (2008), combined with the decision to use only the ﬁrst two
moments of target causal factors. In this case, all constraints can be computed in closed-form and we can perform a
relatively simple Monte Carlo approximation for the objective function. As a matter of fact, we did not have to make
any distributional assumptions about θ at all except for the existence of its ﬁrst and second moments. There is much
to appreciate in the generic blackbox of Hu et al. (2021), but solving full density estimation problems and requiring a
complex nesting of multiple optimization and simulation steps may not be the preferred way to go in some real-world
applications.

|

Moreover, response functions only need to be structural with respect to its manipulable inputs. If we want to model,
say, E[Y
do(x), w] for some pre-treatment covariates W , there is no need at all to model W structurally. The causal
model can be deﬁned in terms of the response function f(w,uy)(x), where W is just another source of background
variability (though observable, unlike UY ). This means that the distribution of θ will be parameterized as a black-box
function that includes w as inputs, while the basis function expansion can remain ﬂexible, and informative, in the
small dimensional space of X.
Finally, our setup is scientiﬁcally advantageous. A naïve view of causal inference postulates that since functional
constraints are untestable assumptions that will imply invalid bounds if misspeciﬁed, then we must, on purpose,
impoverish the language in which we allow causal models to be described by removing this choice. This line of
reasoning is incoherent on many accounts. First, practitioners do want to express functional constraints, as partial
identiﬁcation is notoriously uninformative in many cases. Shape constraints may be fruitful even in purely predictive
tasks (e.g Gupta et al., 2020), as further background knowledge to reduce degrees of freedom that cannot be fully
decided by data alone. Many domains have no clear reason to allow for dose-response curves that have many inﬂection
points, and in fact the community has been criticized by creating benchmarks with artiﬁcial outcome functions for
the sake of illustrating overly complex average treatment eﬀect estimators, which hardly deliver any advantages in
several empirical domains (e.g., Gentzel et al., 2021). The argument that restricting function spaces may lead to
invalid bounds is vacuous and misses the point of causal modeling. A model is what we remove from the space of
all possibilities, that is, the constraints we adopt.4 The missing edges in a causal graph are just that: constraints.
Invalid bounds are a consequence of an overconstrained feasible region, and the function space is part of the game as
much as any decisions about missing edges. The promotion of a type of constraint (independence constraints) as
having a protected place in causal modeling should not be taken seriously by methodologists or practitioners.

Second, like missing edges, function spaces can be partially tested. Testability is predictated on assumptions that
themselves may be untestable: in the case of purely missing edges, faithfulness (Spirtes et al., 2000) and its variants;
in the case of function spaces and the independence constraints that go along with them, we can test whether our
mathematical program has a feasible solution or not. Passing the mathematical program is not a guarantee of

4To use a quote usually apocryphally attributed to Michelangelo: “It is the sculptor’s power, so often alluded to, of ﬁnding the perfect
form and features of a goddess, in the shapeless block of marble; and his ability to chip oﬀ all extraneous matter, and let the divine
excellence stand forth for itself.” The Methodist Quarterly Review (1858), emphasis added.

12

correctness – which is not surprising, given that e.g. hypothesis testing and many frameworks of scientiﬁc falsiﬁability
are about deciding not to reject a postulated model, not about conﬁrming it. As another example, passing Fisher’s
sharp null hypothesis by itself does not prove that individual treatment eﬀects are exactly, or even close to, zero (or
whether counterfactuals have a physical meaning at all!), and so on. Nevertheless, there are important applications of
falsifying a causal model with partial identiﬁability (e.g Wolfe et al., 2019; Robins et al., 2015), which are useful so
long as it is understood that “testability” is always an asymmetric concept.

|

w, x] + r(w,uy)(x), the latter function r(w,uy)(x) taking particularly smooth shapes.

Among the practical uses of constrained function spaces, for instance, is the possibility of expressing knowledge as
smooth deviances from responses that do not control for unmeasured confounding: e.g., parameterizing Y = f(w,uy)(x)
as Y = E[Y
One line of criticism that deserves more serious consideration was raised by Dawid Dawid (2003) in the context
of classical categorical models for instrumental variables: postulating constraints on structural equations/response
functions is equivalent to making counterfactual claims which are never directly testable, even with perfect randomized
controlled trials (RCTs). This motivated Dawid to create an alternative to partial identiﬁcation in discrete IV settings
without postulating the existence of response functions. A discussion of interventional (response-function-free) and
counterfactual (adopting response functions) models is provided by Sonja A. Swanson et al. (2018). In our case,
expressing models in terms of latent variables and conditional distributions falls back to the issue we discussed in the
main text, by which it is unclear how to interpret an inﬁnite dimensional latent variable space and its relation to the
conditional distributions, and all the computational complications that follow. Our take is that the response functions
are idealizations that do not need to correspond to counterfactuals if all that is required is how well we can model
interventional distributions – themselves testable implications in the sense of comparisons against RCTS. Without
RCTs, the formulation has a degree of falsiﬁability in terms of the feasible region of the mathematical program, as
discussed above.

B Leaky mediator

In the “leaky mediator” setup, we have that the eﬀect of treatment X on outcome Y is completely mediated by some
vector M . On top of that, X and Y are confounded, and so are M and Y . Without the latter, this causal structure
would satisfy the front-door criterion, and be nonparametrically identiﬁable via the do-calculus (Pearl, 2009). A
causal diagram with our proposed parameterization is shown in Figure 1(d), right column.

For ﬁxed background variables UY encoded indirectly as function parameters θy, the structural equation for Y is
given by fθy (m). Assume we represent the density function of M given X, pm(
x), with an invertible conditional
· |
normalizing ﬂow M = hX (NM ), where NM
(0, 1). In what follows, we adopt no model for px(x)(= p(nx)), using
its empirical distribution ˆpx(
) as an estimate.
·
Representing the objective function. A main diﬀerence between this and the IV model is that we also need to
do(x(cid:63))] as following the same generative model
marginalize the mediator M . We can interpret the expectation E[Y
of the observational distribution, but where node X gets replaced by constant x(cid:63), with edge NX
X also removed.
This leads to the following integral and its Monte Carlo approximation:

∼ N

→

|

E[Y

|

do(x(cid:63))] =

≈

(cid:90)

1
n

fθy (m)p(m, nx, θy

|

do(x(cid:63))) dm dnx dθy

y ψ(m(i)),
θ(i)(cid:62)

(cid:88)

i

(10)

where

θ(i)
y

|

|

n(i)
do(x(cid:63))
ˆpx(
x
·
n(i)
m(i)
x(cid:63))
x , do(x(cid:63))
ˆpm(
|
· |
n(i)
m(i), do(x(cid:63)) = h−1
x(cid:63) (m(i))
m
|
x , n(i)
n(i)
m , m(i), n(i)
n(i)
m )
pη(

x , do(x(cid:63))

∼
∼

)

∼

· |

Here, n is the number of Monte Carlo samples; ˆpx(
) is the empirical distribution of X (and, hence, sampling from it
·
is just sampling with replacement from the training set for X). This can be interpreted conceptually, with the actual
algorithm being the sampling of NM from a standard Gaussian followed by the computation of M from x(cid:63) and NM .
As in the main text, pη(
Estimating the constraints. Our optimization is over multivariate Gaussian distributions of θy with the mean
and covariance modeled by MLPs with parameters η0 and η1, respectively. Let’s say the MLPs are µη0(nx, nm) and

) only needs to be speciﬁed up to its ﬁrst and second moments.
·

· | ·

,

13

Ση1(nx, nm). The constraints of the optimization are to match the generated data to the observed distribution, for
example by matching the ﬁrst and second moments of Y

X, M as in the IV case.

|

(cid:90)

E[Y

|

x, m] =

fθy (m)p(θy

x, m) dθy

|

= E[θ(cid:62)
x, m]ψ(m)
= µη0 (x, nm(x, m))(cid:62)ψ(m)

|

(11)

(12)

(13)

This is analogous to the IV setting because of the similar factorization of the background variables as a DAG after
re-encoding the bidirected edges as directed edges. After transforming the causal background variables UX , UM into
nm, nx). As
probabilistic “seeds” NX , NM for p(x) and p(m
NX is identically distributed as X and so can be estimated separately, and p(nm) is ﬁxed by design, the same general
pipeline follows.

x) , this results in the factorization p(nx) p(nm) p(θy

|

|

C Extensions

We introduced our problem formulation as a very generic deﬁnition of model proximity in terms of some dist(pη, ˆp),
and in particular the formulation

≡ ||
where f ˆp is a ﬁnite-dimensional vector of functionals of the (estimated) observable distribution, and f pη is a
ﬁnite-dimensional vector of functionals of the distribution as implied by an unidentiﬁable structural causal model.
Equation (6) is a particular implementation of this idea. Due to the challenge of evaluating this norm, we suggest
Monte Carlo approximation for the optimization procedure, based on Wang and Bertsekas (2016).

−

dist(pη, ˆp)

f pη

f ˆp
||

∞,

We have also presented results for alternative distance metrics, including special cases such as metrics that can be
associated with a single Lagrange multiplier such as
2. We note that also combinations of a limited number
f ˆp
||
of metrics are possible such as

f pη
||

−

1,

,
}

f
||

max

1, . . . ,

f ˆp
1 ||

f ˆp
2 ||

pη
K −

f ˆp
1
K||

pη
f
1 −
{||

pη
f
1 −
||
where each k = 1, 2, . . . , K describes a cluster of functionals that are easy to compare on the same scale.
We emphasize an approach where f ˆp is learned prior to solving an optimization problem. It may be of interest to
use the raw data directly and try to ﬁt pη while searching, among all equally best ﬁtting models, for the one with
the highest/lowest corresponding causal eﬀect. There are some appealing properties of using something like (Monte
Carlo approximations of) the log-likelihood function evaluated at the training points (i.e., the negative KL divergence
between model and data), maximum mean discrepancy measures, or generative adversarial network criteria, as they
are global measures of goodness-of-ﬁt. Future work on such approaches should also be considered. However, it is
not entirely obvious how nested optimization would complicate the solution to the problem, as optimizing (and
regularizing!) the ﬁt plays the role of a constraint for the “true” objective function that is optimized (the causal
eﬀect). Moreover, ﬁtting a generative model for the entire joint distribution is an obviously undesirable nuisance task
if we can get essentially the same bounds by estimating only one or two moments of interest.

Another extension is the provision of a calculus for a minimal parameterization of arbitrary structural causal models
for a given causal query of interest. Looking back at our instrumental variable scenario, we could have created a
single set of latent variables NXY that would be common causes of X and Y and model the structural equations for
both X and Y at the same time, instead of ﬁxing p(X
Z) a priori and deterministically extracting latent variables
N from X and Z. In general, we could add independent latent variables for each clique in the bidirected graph
component of the causal graph. This, however, is very wasteful. There is no need to create a causal model for the
(Z, X) marginal – which not only would assume that Z is an unconfounded cause of X, which is unnecessary, but
would also waste computation and stability trying to match the observable marginal of (Z, X) to the corresponding
causal-model-implied marginal, which is also completely unnecessary. Given that Z and X can be high-dimensional
while Y is a scalar, this is clearly a bad idea. Therefore, the structure-blind strategy of creating latent variables
for each bidirected clique is convenient but not ideal, and a smarter automated way of generating minimal causal
parameterizations for arbitrary graphs and causal queries is needed.

|

D Glossary of Synthetic Datasets

We describe here the synthetic datasets we use in our experiments.

14

Instrumental variable

Leaky mediation

C

U

C

Z
Rp

X
Rq
treatments

∈

Y

R

∈
outcome

∈

instruments

X
Rp

M
Rq
mediators

∈

Y

R

∈
outcome

∈

treatments

Figure 3: These are the structural equations we work with. In the description of the datasets, the dimensions of each
variable are denoted by a subscript. For instance if X is 2-dimensional, we write it as X = (x1, x2).

IV -

lin - 2d - strong - add (optional)

Figure 4: Naming logic for the datasets. The ﬁrst segment mentions whether it is the Instrumental Variable (IV) or
Leaky Mediator (LM) setting. The second segment says whether y is linear or quadratic in x. The third segment tells
the dimension of the treatment. The fourth segment denotes the strength of the confounding, strong or weak. The
ﬁfth and last segment is optional, and says whether the confounding is additive, which in the IV setting makes the
eﬀect identiﬁable.

We use various polynomial datasets where the causal eﬀect is a polynomial function of a single or multidimensional
treatment. We provide the construction of each of these here. Figure 3 shows the structural graphs. In both graphs,
every node except Y (outcome) could be multi-dimensional. If a node, say C, is multi-dimensional, we index the
dimension with a subscript. That is, we write C = (c1, c2). Figure 4 visually describes the naming logic behind the
datasets to make the exposition clearer.

D.1 Scalar treatment
We now describe settings where the treatment X is a scalar,which we present as a sanity check. The noises, confounder,
and instrument follow

(0, 1)
• IV-lin-1d-weak-add (fy linear in x, weak additive confounding)

ex, ey, c, z

∼ N

• IV-quad-1d-strong (fy quadratic in x, strong non-additive confounding)

fx(z, c, ex) = 3z + 0.5c + ex
fy(x, c, ey) = x

6c + ey

−

fx(z, c, ex) = 0.5z + 3c + ex
fy(x, c, ey) = 0.3x2

1.5xc + ey

−

• IV-quad-1d-weak (fy quadratic in x, weak non-additive confounding)

fx(z, c, ex) = 3z + 0.5c + ex
fy(x, c, ey) = 0.3x2

1.5xc + ey

−

D.2

IV model

We now describe datasets satisfying the IV assumptions.

2D treatment. The noises, confounder, and instruments follow

• IV-lin-2d-strong (fy linear in x, strong non-additive confounding)

c, z, ex
ey

2(0, 1)
(0, 1)

∼ N

∼ N

fx(z, c, ex) = 0.5z + 2c + ex
fy(x, c, ey) = x1 + x2

3(x1 + x2)(c1 + c2) + ey

−

15

• IV-lin-2d-weak (fy linear in x, weak non-additive confounding)

• IV-quad-2d-strong-add (fy quadratic in x, strong additive confounding)

fx(z, c, ex) = 2z + c + ex
fy(x, c, ey) = 5x1 + 6x2

−

x1(c1 + c2) + ey

• IV-quad-2d-weak (fy quadratic in x, weak non-additive confounding)

fx(z, c, ex) = z + 2c + ex
1 + 2x2
fy(x, c, ey) = 2x2

2 −

(c1 + c2) + ey

2fx(z, c, ex) = 2z + c + ex
1 + 6x2
fy(x, c, ey) = 5x2

2 −

(x1 + x2)(c1 + c2) + ey

3D treatment. The noises, confounders, and instruments follow
3(0, 1)
(0, 1)

c, z, ex
ey

∼ N

∼ N

• IV-quad-3d-weak (fy quadratic in x, weak non-additive confounding)

fx(z, c, ex) = 2z + c + ex
1 + 2x2
fy(x, c, ey) = 2x2
0.3(x2 + x3)(c1 + c2 + c3) + ey

2 + 2x3

−

D.3 Leaky Mediator

We now describe datasets following the leaky mediator model with noises, and confounder following

• LM-lin1-2d (fy linear in x, strong confounding)

ex, em, c, u
ey

2(0, 1)
(0, 1)

∼ N

∼ N

fx(u, ex) = u + ex
fm(x, c, em) = x + 3c
fy(m, c, u, ey) = 2m1 + m2

−

em

−
• LM-lin2-2d (fy linear in x, weak confounding)

(m1 + m2)(c1 + c2 + u1 + u2) + ey

fx(u, ex) = u + ex
fm(x, c, em) = 3x + c
fy(m, c, u, ey) = 2m1 + m2

−

em

−

0.3(m1 + m2)(c1 + c2 + u1 + u2) + ey

E Implementation Details

We use n = 10 000 data points for all our simulations. All implementation is in Python, using PyTorch (Paszke et al.,
2019). Code for the experiments is provided with the supplementary material.

{

R

φl :

L
l=1
Y →
}
}i∈[n] and

. In practice, we take L = 2 and match the ﬁrst and second moments of Y

E.1 Satisfying [c-data]
In Section 3.4 we explained how we match the observed data distribution by matching scalar statistics for L dictionary
,
functions
}
| {
which is to say that we set φ1(Y ) = Y and φ2(Y ) = Y 2. We learn φ1 and φ2 by regressing MLPs on the observed
data
i }i∈[n] as the
y2
xi, zi
{
target values. The outputs of these MLPs are then approximations of E[Y
X, Z], respectively. A
signiﬁcant advantage of this approach is that we can evaluate the constraints in closed form under our construction
(see Equation (8)). We use MLPs with 3 hidden layers of sizes (64, 32, 16) (ﬁrst to last) and train it with a batch size
of 512 for 200 epochs, with a learning rate of 0.01. We use ReLU activations. Identical settings were used for the
leaky mediator, with the only diﬀerence being that we match Y

}i∈[n] as the input and
|

i }i∈[n] respectively, with

}i∈[n] and
|

X, Z] and E[Y 2

instead of Y

xi, zi, y2

xi, zi, yi

M, X

yi
{

X, Z

X, Z

{

{

{

| {

}

| {

.
}

16

GAN comparison

(a) IV-lin-2d-weak.

(b) LM-lin-2d-weak.

Figure 5: Comparison with GAN

|

Z.

E.2 Satisfying [c-struct]
We describe in Section 3.3 how we write the mean and variance of X as a function of Z. We considered two distinct
ways of modeling X
Gaussian. . We write the mean and variance of X as a function of Z. That is to say, X = hZ(N ) := A(Z)N + b(Z).
We parameterize A(Z) as A = L(cid:62)L + Ω. A Cholesky factor L :
Rp×p ensures symmetry and a diagonal matrix
Ω adds small constants to the diagonal to ensure symmetry and positive deﬁniteness. We then learn L(cid:62)L + Ω from
observed data
Z). In practice, the parameters of A(Z) as described above,
|
and the parameters of b(Z) (which are just the entries of the vector b(Z)) are the output of an MLP which takes in
X. We learn the weights of this neural net once up front from observed data
by maximizing the log-likelihood of
Z). In practice, this MLP has 3 hidden layers of sizes (64, 32, 16) (ﬁrst to last) and is trained with a batch size
ˆp(X
of 512 for 200 epochs, with a learning rate of 0.01. We use ReLU activations.
Conditional normalizing ﬂow. . We use an invertible (conditional) normalizing ﬂow to model the distribution of
Z. Flows are a natural candidate for modeling distributions, and in this case follow both the properties we want
X
Z. (i) Given X, Z, we can invert the transformation to get N . (ii) We can sample from
from the modeling of X
X

Z = z. We use the Python library pyro Bingham et al. (2019).

by maximizing the log-likelihood of ˆp(X

Z →

D

D

|

|

|

All the experiments shown in this work use conditional normalizing ﬂows due to better performance and stable
optimization. However, the Gaussian modeling is described to point out one more way in which prior assumptions on
functional dependencies could be incorporated in our generic framework. Once again, the construction is identical for
the leaky mediator setting. The only diﬀerence is that there we model M

X instead of X

Z.

|

|

|

S

E.3 Parameterizing
We consider θ to be K-dimensional and use the neural basis function in all experiments unless speciﬁed otherwise.
Equation (5) describes how we parameterize our model. Here θ
N is parameterized by two MLPs with parameters
with weights denoted by η0 and η1. The weights of this MLP constitute our main optimization parameters η and we
has 2 hidden layers with size
denote the outputs by µη0
(32, 32). To evaluate the objective function, we perform Monte Carlo estimation EN [µη0(N )] with 500 samples for N
as in Equation (9).

|
has 2 hidden layers with size (16, 16) and Ση0

and Ση1

. µη0

The diﬀerence in the leaky mediator setting is that the parameterization of θ has 2 noise inputs instead of 1, as
described in Appendix B. The remaining implementation choices remain unchanged.

17

0.00.1Density−4−2024x?−4−202OutcomeE[Y|do(x?)]E[Y|x?]OursGAN0.00.1Density−4−2024x?−7.5−5.0−2.50.02.55.07.5OutcomeE[Y|do(x?)]E[Y|x?]OursGANScalar treatment

Identiﬁable settings

Multi-dimensional treatment

(a) IV-lin-1d-weak-add. An identiﬁable scalar treatment
with weak confounding. We get tight bounds despite using
the neural basis functions.

(b) IV-quad-2d-strong-add. Multi-dimension treatment
using the neural basis functions.

Figure 6: We see that our method is able to ﬁnd tight bounds in identiﬁable settings in the data-dense regions.

Strong instrument VS Weak instrument (Scalar treatment)

(a) iv-quad-1d-weak. This is a partially identiﬁable scalar
treatment setting. The bounds are particularly tight in the
data-dense regions due to the strong instrument.

(b) iv-quad-1d-strong. This is a partially identiﬁable scalar
treatment setting. The bounds are looser because the instru-
ment is weak.

Figure 7: As expected, the bounds are tighter in the case of strong instrument.

E.4 Response function choice
Our choice of response functions is characterized by the choice of K basis functions, as we saw in Equation (4). We
primarily use the neural basis functions described in Section 4.3. Note that a linear combination of basis functions
allows us to be arbitrarily expressive with out choice of family of response functions, and we can choose In particular,
we consider the following options:

18

0.000.25Density−4−2024x?−8−6−4−2024OutcomeE[Y|do(x?)]E[Y|x?]UpperboundLowerbound0.00.1Density−4−202x?−20246OutcomeE[Y|do(x?)]E[Y|x?]UpperboundLowerbound0.000.25Density−4−2024x?−5.0−2.50.02.55.07.510.0OutcomeE[Y|do(x?)]E[Y|x?]UpperboundLowerbound0.000.25Density−4−2024x?−40−30−20−100102030OutcomeE[Y|do(x?)]E[Y|x?]UpperboundLowerboundGAN comparison

(a) IV-quad-2d-weak.

(b) IV-quad-3d-weak.

Figure 8: We do note that in this instance, the bounds given by our method are not as smooth in the data poor
regions. However, our bounds are always valid, while the GAN framework gives some invalid bounds in both cases
above.

1. Neural basis functions: The basis function ψk is the activation of the kth neuron in the last hidden layer of an
xi, yi
{

MLP which has been trained on the observed data

}i∈[n] to learn y given x.

In practice, we train a 3-hidden layer MLP with 64 neurons in the ﬁrst two layers, rectiﬁed linear units (ReLU) as
activation functions and an MSE (mean squared error) loss for 100 epochs and a batch size of 512 using Adam
with a learning rate of 0.01. The size K of the last hidden layer is equal to the number of basis functions we wish
to have in our family of response functions.

An implicit assumption we have here is that the MLP can ﬁnd a good approximation of y given x. This assumption
is well supported by theoretical and empirical results showing the approximation power of neural networks (Shen
et al., 2021; Daubechies et al., 2021), making it the perfect candidate for multi-dimensional treatments.

2. Polynomials: For a multivariate input x = (x1, x2 . . . xd), a response function can be considered to be a multivariate
polynomial polynomial in x. However, in this case we would have 2d diﬀerent basis functions of degree up to d.
This leads to the question of what basis functions to use here so as to have enough expressive power, but not blow
up the number of basis functions and hence the dimension of the optimization parameter θ (see Equation (4)).
Due to this blowup in the choice of basis functions with the dimension of the treatment in the case of polynomials,
mainly use the neural basis functions.

In the cases when we do use the polynomial basis, we restrict ourselves to having upto quadratic terms in the basis
function. For a d-dimensional treatment, this amounts to having a d(d + 3)/2 + 1 dimensional θ.

3. Gaussian process basis functions (GP): We do not use this family of response functions, but mention them as a
possible option. There is some previous work which considers the GP basis to deﬁne a family of functions (Kilbertus
et al., 2020). In this approach a Gaussian process is ﬁt to K diﬀerent sub-samples
N . A
i∈N (cid:48) with N (cid:48)
}
single function is then sampled from each Gaussian process as the basis functions ψk for k
[K]. Here, ‘sampling a
function’ means to get the evaluation of the function at several points in the treatment space and then interpolate.
While this is a reasonable approach when the treatment is scalar, for a multidimensional treatment, this requires
the interpolating a multivariate function. The complexity and computational cost of such an interpolation increases
with the increase in dimensionality, while the reliability of the interpolated function decreases at the same time.
Also, higher dimension require exponentially higher number of point evaluations to get good interpolations. Due
to these reasons, the GP basis approach is not found suitable for higher dimensions. However, it can be a viable
options for scalar treatments.

(xi, yi)

≤

∈

{

19

0.00.1Density−4−2024x?−20246OutcomeE[Y|do(x?)]E[Y|x?]OursGAN0.000.05Density−4−2024x?−20246OutcomeE[Y|do(x?)]E[Y|x?]OursGANE.5 Solving the optimization

The various MLPs described in the previous sections eventually lead to the formulation of a constrained optimization
problem that we have seen in Equation (9).

We use the augmented Lagrangian method for inequality constraints to solve the constrained optimization problem in
Equation (9). The formulation is taken from Section 17.3 in (Nocedal and Wright, 2006).

L constraints. We can think of ˆφl(xi, yi) as target values,
We have seen in Section 3.5 that we have a total of N
estimated once up front from observed data. We denote ˆφl(xi, yi) = Bl,i. The right-hand side Al,i is a function of the
optimization parameter η as seen in Section 3.4. For ease of notation, we “ﬂatten” the indices n and l into a single
index l
Then our set of constraints is

L]. We set the constraint slack to be the same value for each constraint, so (cid:15)L = (cid:15).

[N

∈

·

·

With this, the Lagrangian we aim to minimize with respect to η can be formulated as:

cl(η) := (cid:15)

Bl

− |

−

Al(η)

| ≥

0

(η, λ, τ ) :=

L

ox(cid:63) (η) +

±

N ·L
(cid:88)

l=1

ξ(cl(η), λl, τ )

(14)

with

(cid:40)

ξ(cl(η), λl, τ ) :=

λlcl(η) + τ cl(η)2
λ2
l
2τ

2

−

−

if τ cl(η)
≤
otherwise,

λl,

where
temperature parameter.

−

/+ is used for the upper/lower bound. τ is increased throughout the optimization procedure and is seen as a

·

·

α

∈

−

←

←

[N

max

0, λl
{

τ for all l

l2 norm VS l∞ norm

Given an approximate minimum η of this subproblem, we then update λ and τ according to λl
τ cl(η)
}
L] and a ﬁxed α > 1. The overall strategy is to iterate between minimizing
and τ
Equation (14) and updating λl and τ . We ﬁnd empirical justiﬁcation in our experiments, where the approach
reliably converges on a range of diﬀerent datasets. We summarize our proposed procedure in Algorithm 1.
We have already seen how the basis function is chosen,
how we can write the A of the constraints in closed form,
how the B of the constraints is ﬁxed upfront using φ1 and
φ2, and how the objective is estimated. It now remains,
to solve this optimization problem, which we solve using
the augmented lagrangian method as described in S. In
practice we ﬁx the initial value of τ to be τinit = 10, and
the multiplier α to be 5, meaning that τ is updated by
multiplying it by 1.08 at each step. The max value of
τ is ﬁxed at τmax = 10, 000. We use 30 optimization
steps to ﬁnd the approximate optimal xk at the kth
round of the optimization, and perform 150 round of
optimization (number of times λ is updated) for each
value of x(cid:63) and each bound (upper and lower). The
optimization was performed using the Adam optimizer
with a learning rate of 0.001. All of this again is through
the use of auto-diﬀerentiation in PyTorch Paszke et al.
(2019), implemented in python.

Figure 9: IV-quad-weak. Partially identiﬁable multi-
dimension treatment. The l2 norm includes all the con-
straints without sampling.

E.6 Hyperparameter search

We did not perform an automated hyperparameter search
for τinit, τmax and τf actor = α since we observed that
the values τinit = 10, τmax = 100000 and τf actor = 5
worked reasonably well in all our settings. We arrived
at this value through trial and error. An automated
hyperparameter search can also be expected to improve
the bounds.

20

0.00.1Density−4−2024x?−20246OutcomeE[Y|do(x?)]E[Y|x?]l2norml∞normE.7 Computational resources

We used a computing cluster provided by the university, for ease of parallelization of experiments. We used 1 CPU,
8000MB of RAM for all the x(cid:63) bounds for a single random seed for the method. To clarify, the use of the cluster was
only for the purpose of running the optimization algorithm parallely for various diﬀerent random seeds. A single run
of the algorithm (for getting bounds on multiple values of x(cid:63)) runs comfortably on a local machine with 16GB of
RAM. No GPUs were used for the experiments.

F Further Experiments

Here we show the performance of our method in a variety of settings.

F.1

Identiﬁable settings

Appendix E.3 shows the performance in the case of identiﬁable settings. We see that our method is able to ﬁnd tight
bounds in identiﬁable settings in the data dense regions. However, it is natural that the more expressive the response
function, the wider the bounds. This can potentially be used as a test of identiﬁability as described in Section 5.
Such a test can be seen as a rather continuous measure of identiﬁability, giving an indication of being somewhere
between identiﬁable and partially identiﬁable based on the tightness of bounds, rather than being able to distinct
strictly between identiﬁable and non-identiﬁable settings.

F.2 Strong instrument VS Weak instrument

Figure 7 compares the bounds in the cases of having a strong or weak instrument, or equivalently having weak or strong
confounding relative to the instrument. As expected the bounds are looser when the confounding is stronger.

F.3 Comparing constraint norms

∞,∞ norm. Here we show experiments using the

In Section 3.4 we have formulated our constraints in terms of norms. All the experiments so far have been using
the
2,2 norm as a constraint. This optimization procedure
remains the same, but is potentially easier to solve since there is only 1 constraint now, but on the other hand this
constraint is looser than matching the moment of each data point (or a chosen subsample). The results can be seen in
Figure 9.

(cid:107) · (cid:107)

(cid:107) · (cid:107)

We point out that our formulation does not restrict us to norm based constraints. In fact given the generative model
we have deﬁne in Section 3, we could also use any measure of distance between distributions as a constraint. However
this would again lead to solving a bi-level optimization, making the optimization harder.

F.4 More comparisons to GAN bounds

We show some further comparisons of our method to the GAN bounds here. We see a similar trend where our bounds
are generally smoother. The plots can be found in Figure 8, Figure 5a and Figure 5b.

G Limitations of Kilbertus et al. (2020)

|

Z) instead of p(Y

Kilbertus et al. (2020) limit the number of constraints by estimating E[φl(Y )
zi] only for a small pre-determined set
of grid points zi around which they bin the observed datapoints for empirical estimates. Thereby, they only constrain
X, Z) and fundamentally limit themselves to low-dimensional settings, since otherwise the
p(Y
. In particular, their proposed interpolation of
number of grid points grows exponentially with the dimension of
empirical cumulative distribution functions to ﬁx p(x
z) in their copula model that parameterizes the distribution
over θ virtually only allows one-dimensional instruments and treatments. Note that the binning procedure for Z also
becomes problematic in the small data regime, where suﬃciently many points are needed in each bin to keep the
variance in the empirical mean and variance estimates low. As a consequence, the number of gridpoints in z must be
carefully tuned depending on the dataset size.

Z

|

|

|

Instead, our stochastic subsampling approach works with a ﬁxed number of constraints for each update step independent
of the size of the dataset and the dimensionality of Z and X. In addition, we encode the structural assumptions into
a graphical model for X, Z, θ that still allows for ﬂexible conditional density estimation techniques such as invertible
ﬂows for individual components. The copula model had to rely on interpolated empirical cumulative density function
estimated from potentially few datapoints within each bin. The Gaussian copula is also less ﬂexible than our proposal.
Finally, Kilbertus et al. (2020) used Monte Carlo estimates both for the objective as well as for each individual

21

constraint, often using diﬀerent sample sizes for these estimates. Instead, we exploit the form of response functions as
linear combinations of basis functions and compute the constraints in closed form, removing the additional variance
from the stochastic optimization procedure. This leads to fewer tunable parameters and more robust convergence of
the optimization.

H Ethical and social implications

The ethical implications of causal inference are numerous, especially when machine learning models are used to make
high-stakes decisions in areas like ﬁnance, criminal justice, and healthcare. Several authors in recent years have
developed causal notions of algorithmic fairness to acknowledge the structural links between protected attributes
and socially signiﬁcant outcomes Kusner et al. (2017); Kilbertus et al. (2017); Wu et al. (2019b); Kilbertus et al.
(2019). More reliable methods for bounding causal eﬀects could help quantify the counterfactual fairness of individual
decisions when identiﬁability is impossible. By the same token, these bounds may misrepresent treatment eﬀects
when untestable assumptions are not satisﬁed. In the worst case, an agent may design a DAG in an adversarial
manner to ensure some desired result. This can be mitigated by public disclosure of all structural assumptions, so
that regulators and data subjects may critically evaluate decision procedures.

22

