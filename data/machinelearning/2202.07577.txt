2
2
0
2

r
a

M
1
3

]
L
P
.
s
c
[

2
v
7
7
5
7
0
.
2
0
2
2
:
v
i
X
r
a

Weighted Programming∗
A Programming Paradigm for Specifying Mathematical Models

KEVIN BATZ, RWTH Aachen University, Germany
ADRIAN GALLUS, RWTH Aachen University, Germany
BENJAMIN LUCIEN KAMINSKI, Saarland University, Saarland Informatics Campus, Germany and Uni-
versity College London, United Kingdom
JOOST-PIETER KATOEN, RWTH Aachen University, Germany
TOBIAS WINKLER, RWTH Aachen University, Germany

We study weighted programming, a programming paradigm for specifying mathematical models. More specif-
ically, the weighted programs we investigate are like usual imperative programs with two additional features:
(1) nondeterministic branching and (2) weighting execution traces. Weights can be numbers but also other ob-
jects like words from an alphabet, polynomials, formal power series, or cardinal numbers. We argue that
weighted programming as a paradigm can be used to specify mathematical models beyond probability distri-
butions (as is done in probabilistic programming).

We develop weakest-precondition- and weakest-liberal-precondition-style calculi à la Dijkstra for reason-
ing about mathematical models speciﬁed by weighted programs. We present several case studies. For instance,
we use weighted programming to model the ski rental problem — an optimization problem. We model not only
the optimization problem itself, but also the best deterministic online algorithm for solving this problem as
weighted programs. By means of weakest-precondition-style reasoning, we can determine the competitive
ratio of the online algorithm on source code level.

CCS Concepts: • Theory of computation → Models of computation; Programming logic; Denota-
tional semantics; Invariants; Pre- and post-conditions; Program semantics.

Additional Key Words and Phrases: weighted programming, denotational semantics, weakest preconditions

1 INTRODUCTION AND OVERVIEW

Weighted programs are usual programs with two distinct features: (1) nondeterministic branching
and (2) the ability to weight the current execution trace. A prime and very well-studied example
of weighted programs are probabilistic programs which can branch their execution depending on
the outcome of a random coin ﬂip. For instance, the program { 𝐶1 }
{ 𝐶2 } weights the trace
that executes 𝐶1 with probability 1/3 and the trace executing 𝐶2 with 1 − 1/3 = 2/3. The weighted
outcomes of the two branches are then — simply put — summed together.

1
3

(cid:2)

(cid:3)

Besides applications as randomized algorithms for speed-up in solving computationally intractable

problems, probabilistic programming has over the past decade gained rapidly increasing attention
in machine learning. There, probabilistic programs serve as intuitive algorithmic descriptions of
complicated probability distributions. As Gordon et al. [2014] put it:

“The goal of probabilistic programming is to enable probabilistic modeling [. . . ] to be
accessible to the working programmer, who has suﬃcient domain expertise, but perhaps
not enough expertise in probability theory [. . . ].”

∗Accepted for publication (https://doi.org/10.1145/3527310).

Authors’ addresses: Kevin Batz, kevin.batz@cs.rwth-aachen.de, RWTH Aachen University, Aachen, Germany; Adrian
Gallus, adrian.gallus@rwth-aachen.de, RWTH Aachen University, Aachen, Germany; Benjamin Lucien Kaminski, b.
kaminski@ucl.ac.uk, Saarland University, Saarland Informatics Campus, Saarbrücken, Germany and University College
London, London, United Kingdom; Joost-Pieter Katoen, katoen@cs.rwth-aachen.de, RWTH Aachen University, Aachen,
Germany; Tobias Winkler, tobias.winkler@cs.rwth-aachen.de, RWTH Aachen University, Aachen, Germany.

 
 
 
 
 
 
2

Batz, Gallus, Kaminski, Katoen, and Winkler

In this paper, we consider more general weights than probabilities — in fact: more general than
numbers. We should stress that we are not the ﬁrst to consider weighted programs (see e.g. [Aguirre
and Katsumata 2020; Brunel et al. 2014; Gaboardi et al. 2021] and see Section 7 for detailed com-
parisons).

Our goal was, however, not to merely go from probabilistic to weighted programming, just for
the sake of generalization. Instead, we advocate weighted programming as a programming paradigm
for specifying mathematical models. In particular, our prime goal is to take a step towards making
mathematical modeling more accessible to people with a programming background. In a nutshell:

Render mathematical modeling accessible to the working programmer,
who has suﬃcient domain expertise, but perhaps not enough expertise
in the respective mathematical theory.

Towards that goal, let us have a look at how such modeling could work in practice.

Weighted Programming as a Paradigm for Specifying Mathematical Models
As a motivating example, we consider the classical Ski Rental Problem [Komm 2016], a classi-
cal optimization problem, studied also in the context of online algorithms and competitive anal-
ysis [Borodin and El-Yaniv 1998]. A precise textual description of the problem is as follows:

The Scenario: A person does not own a pair of skis but is going on a skiing trip
for 𝑛 days. At the beginning of each day, the person can chose between two options:
Either rent a pair of skis, costing 1e for that day; or buy a pair of skis, costing 𝑦e
(and then go skiing for all subsequent days free of charge).
The Question: What is the optimal (i.e. minimal) amount of money that the person
has to spend for a pair of skis for the entire length of the trip?

Using weighted programming, we can model the scenario of this op-
timization problem in a quite natural, simple, and intuitive way by
the weighted program opt on the right. Intuitively, this weighted
program tests each day whether the vacation is already over (Line
1). If not, it does the following (Lines 2–5): First, it decrements the
vacation length by 1 day (Line 2). It then models the two options
that the person has for each day by a nondeterministic branching
(Line 4). In the left branch, it realizes the ﬁrst option: Paying 1e
(Line 3). In the right branch, it realizes the second option: Paying
𝑦e and then setting the remaining vacation length to 0 (Line 5),
because with respect to having to pay for a pair of skis (not with
respect to the joy of skiing) the vacation has eﬀectively ended.

The Scenario:

1:

2:

3:

4:

5:

while ( 𝑛 > 0 ) {
𝑛 ≔ 𝑛 − 1
{

#

⊙ 1

} ⊕ {

⊙ 𝑦

𝑛 ≔ 0

}

#

}

If we now want to answer the question of the optimization prob-
lem, we ﬁrst chose a suitable semiring. In this setting of opti-
mizing (i.e. minimizing) incurred cost, the tropical semiring T =
(N+∞, min, +, ∞, 0) comes to mind. The carrier set of this semir-
ing are the extended natural numbers. The addition (⊕) in this semiring is taking the minimum
of two numbers. In the program, this is reﬂected by the fact that in Line 4 we would like to make
whatever choice is cheaper for us. The multiplication (⊙) is the standard addition of numbers. In
the program, this is reﬂected, for example, in Line 3, where we add a 1 to the current execution
trace.

The Question:

opt
K
J

( 1 ) = ?

wp

For actually answering the question of the optimization problem, we determine a weakest pre-
condition of sorts, but interpreted here in a more general “quantitative” setting, with respect to
post“condition” 1 — the multiplicative identity of the semiring; in this case, 1 is the natural number 0.

Weighted Programming

3

Intuitively, this will for each path multiply together the weights along the path (recall: semiring
multiplication is natural number addition). Then, we sum over the weights of all paths (recall:
semiring summation is natural number minimization), thus yielding the accumulated costs along
the least expensive path. As a result, our weakest-precondition-style calculus will yield

i.e. the minimum of the numbers 𝑛 and 𝑦. This is precisely the solution to our optimization problem:
If the trip length 𝑛 is larger than the cost of buying skis, we should buy skis which will cost us 𝑦e.
If 𝑛 is smaller than 𝑦, we should instead rent each day (at cost 1e/day) which will cost us 𝑛e.

wp

opt
K

J

( 1 ) = 𝑛 ⊕ 𝑦 ,

( 1 ) / wp

onl
K
J

onl that solves the ski rental problem and determine wp
opt
ratio wp
K

Toward competitive analysis, we can now model the cost of a deterministic online algorithm
( 1 ). Then, we can compute the
onl
( 1 ) to determine the competitive ratio of the online algorithm onl.
K
We stress that program opt from above is not strictly speaking executable. For that, one would
need some sort of scheduler who determinizes the nondeterministic choices. It is also not imme-
diately clear what weighting the individual execution traces on a physical computer would mean.
Instead, the above weighted program encodes a mathematical model, namely an optimization prob-
lem, by means of an algorithmic representation — much in the spirit of a probabilistic program that
is also not necessarily meant to be executed but instead models a probability distribution.

J

J

Lastly, we would like to note that determining weakest preconditions is related to inference in
probabilistic programming [Gordon et al. 2014], where one is concerned with, e.g., determining
the probability that the probabilistic program establishes some postcondition.

Contributions
Our main technical contribution is the — to the best of our knowledge — ﬁrst weakest precondition-
style reasoning framework for weighted programs, which conservatively extends both Dijkstra’s
classical weakest preconditions and weakest liberal weakest preconditions. Our weakest pre cal-
culi capture the semantics of unbounded and potentially nonterminating loops eﬀortlessly, while
other works explicitly avoid partiality (see Section 7). Our weakest liberal preweightings even
give a nuanced semantics to nonterminating runs in order to reason about such traces as well. We
demonstrate the applicability of our framework by several examples.

To achieve a high degree of generality and applicability, our framework is parameterized by
a monoid of weights for weighting computations of programs and so-called weightings that take
over the role of “quantitative assertions”. We prove well-deﬁnedness and healthiness conditions
of our calculi, provide formal connections to an operational semantics, and develop easy-to-apply
invariant-based reasoning techniques.

Outline
Section 2 provides preliminaries on monoids and semirings. Section 3 introduces the syntax and
operational semantics of weighted programs. We introduce our weakest (liberal) preweighting
calculi for reasoning about weighted programs in Section 4. Invariant-style reasoning for loops is
presented in Section 5. In Section 6, we demonstrate the eﬃcacy of our framework by means of
several examples. In Section 7, we give an overview of and a comparison to other works that study
weighted computations. We conclude in Section 8.

2 MONOIDS AND SEMIRINGS

The weights occurring in our programs are elements from a monoid. Intuitively, this is because we
would like to “multiply” the weights on a program’s computation trace together in order to obtain
the total weight of that trace. In particular, this multiplication should be associative and allow for

4

Batz, Gallus, Kaminski, Katoen, and Winkler

neutral, i.e. eﬀectless weighting. In Section 4.2 further below, we introduce monoid modules that
are another important ingredient for our theory.

Deﬁnition 2.1 (Monoids). A monoid W = (𝑊 , ⊙, 1) consists of a carrier set 𝑊 , an operation

⊙ : 𝑊 × 𝑊 → 𝑊 , and an identity 1 ∈ 𝑊 , such that for all 𝑎, 𝑏, 𝑐 ∈ 𝑊 ,

(1) the operation ⊙ is associative, i.e.
(2) 1 is an identity with respect to ⊙, i.e.

𝑎 ⊙ (𝑏 ⊙ 𝑐) = (𝑎 ⊙ 𝑏) ⊙ 𝑐,
𝑎 ⊙ 1 = 1 ⊙ 𝑎 = 𝑎.

and

The monoid W is called commutative if moreoever 𝑎 ⊙ 𝑏 = 𝑏 ⊙ 𝑎 holds.

△

· , 𝜖) over alphabet Γ ≠ ∅ and the
Important examples of monoids are the words monoid (Γ∗,
probability monoid ( [0, 1], · , 1) (the latter is commutative). Another algebraic structure that plays
a key role in this paper are semirings. Even though they are not strictly required for our theory, they
render the application of our framework easier and more intuitive. This is because every semiring
is a monoid module over itself, which we explain in more detail in Section 4.2. Our deﬁnition of
semirings is stated below; for an in-depth introduction, we refer to [Droste et al. 2009, Ch. 1, 2].
As usual, multiplication ⊙ binds stronger than addition ⊕ and we omit parentheses accordingly.

Deﬁnition 2.2 (Semirings). A semiring S = (𝑆, ⊕, ⊙, 0, 1) consists of a carrier set 𝑆, an addi-

tion ⊕ : 𝑆 × 𝑆 → 𝑆, a multiplication ⊙ : 𝑆 × 𝑆 → 𝑆, a zero 0 ∈ 𝑆, and a one 1 ∈ 𝑆, such that

(1) (𝑆, ⊕, 0) forms a commutative monoid;
(2) (𝑆, ⊙, 1) forms a (possibly non-commutative) monoid;
(3) multiplication distributes over addition, i.e. for all 𝑎, 𝑏, 𝑐 ∈ 𝑆,

𝑎 ⊙ (𝑏 ⊕ 𝑐) = 𝑎 ⊙ 𝑏 ⊕ 𝑎 ⊙ 𝑐

and

(𝑎 ⊕ 𝑏) ⊙ 𝑐 = 𝑎 ⊙ 𝑐 ⊕ 𝑏 ⊙ 𝑐 ;

and

(4) multiplication by zero annihilates 𝑆, i.e.

0 ⊙ 𝑎 = 𝑎 ⊙ 0 = 0 .

△

Our “cheat sheet” in Table 1 lists various example semirings along with possible applications in a
weighted programming context. Further well-known semirings not considered speciﬁcally in this
paper include (i) the Łukasiewicz semiring [Gerla 2003; Nola and Gerla 2005] motivated by multival-
ued logics and related to tropical geometry [Gavalec et al. 2015], (ii) the resolution semiring [Bagnol
2014] from proof theory, (iii) the categorial and lexicographic semirings [Sproat et al. 2014] used
in natural language processing, (iv) the thermodynamic semirings [Marcolli and Thorngren 2011,
2014] employed in information theory, and (v) the conﬁdence-probability semiring [Wirsching et al.
2010]. We leave the study of applications of weighted programs over these semirings for future
work. Finally, we mention that more complicated semirings can be created from existing ones
through algebraic constructions like matrices, tensors, polynomials, or formal power series.

3 WEIGHTED PROGRAMS
For a monoid W = (𝑊 , ⊙, 1) of weights, we study the W-weighted guarded command lan-
guage W-wGCL featuring — in addition to standard control-ﬂow instructions — branching and
weighting. If the monoid W is evident from the context, we omit the symbol and write just wGCL.

1Also known as max-min-semiring. The name Bottleneck semiring is taken from [Pouly 2010]. Quantitative veriﬁcation
using this semiring is further studied in [Zhang and Kaminski 2022a,b].

Weighted Programming

5

Table 1. Weighted programming cheat sheet.

Optimization via the Tropical semiring (N+∞, min, +, +∞, 0)
Weighting ⊙ 𝒂:
Accumulate cost 𝑎
Postweighting 𝒇 :

Branching ⊕:
Choose branch that will accumulate minimal cost
wp J𝑪 K ( 0 ):
Minimal accumulated cost amongst all termi-
nating executions of 𝐶

Cost that is accumulated after program ter-
mination; typically choose 𝑓 = 0

wlp J𝑪 K ( 𝒇 ):
Minimum of wp J𝐶K ( 𝑓 ) and the min-
imal accumulated cost amongst all non-
terminating executions of 𝐶

−∞, max, +, −∞, 0)

Optimization via the Arctic semiring (N+∞
Weighting ⊙ 𝒂:
Accumulate cost 𝑎
Postweighting 𝒇 :
Cost that is accumulated after program ter-
mination; typically choose 𝑓 = 0
Optimization via the Bottleneck semiring1 (R+∞
Weighting ⊙ 𝒂:
Restrict capacity of current branch to 𝑎

Branching ⊕:
Choose branch that will accumulate maximal cost
wp J𝑪 K ( 0 ):
Maximal accumulated cost amongst all termi-
nating executions of 𝐶

−∞, max, min, −∞, +∞)

Branching ⊕:
Choose branch with accumulate maximal capacity
wp J𝑪 K ( 𝒇 ):
Maximum bottleneck amongst all terminat-
ing executions of 𝐶

Postweighting 𝒇 :
Upper bound after program termination;
typically choose 𝑓 = +∞

Model Checking via the Formal languages semiring

2Γ∗

, ∪,

· , ∅, { 𝜀 }

Weighting ⊙ 𝒂:
Append symbol 𝑎 to current trace

Branching ⊕:
Account for/aggregate behavior of both branches
wp J𝑪 K ( {𝜺 } ):

(cid:0)

(cid:1)

Language of all terminating traces of 𝐶

Postweighting 𝒇 :
Language that is appended to each termi-
nated trace; typically choose 𝑓 = {𝜖 }
Combinatorics via the (extended) Natural Numbers semiring (N+∞, +,
Branching ⊕:
Weighting ⊙ 𝒂:
Make 𝑎 copies of current path/trace
Sum up number of paths/traces of both branches
wp J𝑪 K ( 1 ):
Number of all terminating paths/traces of 𝐶

Postweighting 𝒇 :
Number of copies that is made of each ter-
minated path/trace; typically choose 𝑓 = 1

wlp J𝑪 K ( 𝒇 ):
Same as wp J𝐶K ( 𝑓 ) if all executions of 𝐶
terminate, else +∞

wlp J𝑪 K ( 𝒇 ):
Maximum bottleneck amongst all executions
of 𝐶

wlp J𝑪 K ( {𝜺 } ):
Language of all terminating and nontermi-
nating traces of 𝐶

· , 0, 1)

wlp J𝑪 K ( 𝒇 ):
Same as wp J𝐶K ( 𝑓 ) if all executions of 𝐶
terminate, else +∞

Hidden Markov Models via the Viterbi semiring ( [0, 1], max,
Weighting ⊙ 𝒂:
Let what follows happen with probability 𝑎

Branching ⊕:
Choose branch of maximal probability

· , 0, 1)

Postweighting 𝒇 :
Probability additionally multiplied to each
terminated trace; typically choose 𝑓 = [𝜑 ],
i.e. the indicator function of some event 𝜑

wp J𝑪 K ( [𝝋] ):

Maximal probability of a terminating execu-
tion establishing 𝜑

wlp J𝑪 K ( [𝝋] ):
Maximal probability of a non-terminating ex-
ecution, or a terminating execution establish-
ing 𝜑

Veriﬁcation/Debugging via the Boolean semiring ({0, 1}, ∨, ∧, 0, 1)
Weighting ⊙ 𝒂:
Assert predicate 𝑎

Branching ⊕:
Angelic choice: choose “most true” branch
wp J𝑪 K ( 𝒇 ):

Postweighting 𝒇 :

Postcondition (a predicate) that should be
established after program termination

Weakest precondition of 𝑓 , the weakest pred-
icate 𝑔 so that starting in 𝑔, program 𝐶 can
terminate in state 𝜏 |= 𝑓

wlp J𝑪 K ( 𝒇 ):
Weakest liberal precondition of 𝑓 , the weak-
est predicate 𝑔 so that starting in 𝑔, program
𝐶 can either diverge or terminate in state
𝜏 |= 𝑓

Feature Selection via the Why semiring (propositional positive DNF, ∨, ∧, 0, 1) over a ﬁnite set
of variables 𝑋1, . . . , 𝑋𝑛 (cf. [Dannert et al. 2019])
Weighting ⊙ 𝒂:
Use resource 𝑎
Postweighting 𝒇 :

Branching ⊕:
Alternatives: use resources via 𝐶1 or via 𝐶2
wp J𝑪 K ( [𝝋] ):

Combinations of resources used after termi-
nation; typically choose 𝑓 = [𝜑 ]

Possible alternatives (disjunction) of
source sets (conjunction) to reach event 𝜑

re-

wlp J𝑪 K ( [𝝋] ):
Possible alternatives (disjunction) of
re-
source sets (conjunction) to either not termi-
nate or reach event 𝜑

6

Batz, Gallus, Kaminski, Katoen, and Winkler

3.1 Syntax
wGCL programs 𝐶 adhere to the grammar

𝐶

−→ { 𝐶1 } ⊕ { 𝐶2 }
𝑥 ≔ 𝐸
|
𝐶2
𝐶1
skip ≡ ⊙ 1

#

|

|

| ⊙ 𝑎
|

if ( 𝜑 ) { 𝐶1 } else { 𝐶2 }
while ( 𝜑 ) { 𝐶1 }
{ 𝐶1 } 𝑎 ⊕𝑏 { 𝐶2 } ≡ { ⊙ 𝑎

|

|

(branching | weighting)

(assignment | conditional choice)

(sequential composition | loop)

𝐶1 } ⊕ { ⊙ 𝑏

𝐶2 }

(syntactic sugar)

where 𝑥 is a program variable from a countable set Vars, 𝐸 is an arithmetic expression over Vars, 𝜑
is a Boolean expression (also called guard), and 𝑎 is a weight from the monoid’s carrier 𝑊 .

#

#

Our programs feature branching “{ 𝐶1 } ⊕ { 𝐶2 }” and weighting “⊙ 𝑎” of the current computation
path where 𝑎 ∈ 𝑊 represents some weight. For example, we can express a probabilistic choice “ex-
ecute 𝐶1 with probability 1/3 and 𝐶2 otherwise” as { 𝐶1 } 1/3⊕2/3 { 𝐶2 } over the monoid ( [0, 1], ·, 1).
We allow for syntactic sugar in weightings, e.g. ⊙ 𝑎𝑥 for some 𝑎 ∈ 𝑊 , 𝑥 ∈ Vars.2 The symbol ⊙
used in the weight-statement is reminiscent of the corresponding monoid operation in W. The
symbol ⊕ we use for the branching-statement will become evident in Section 4.

3.2 Program States
A program state 𝜎 maps each variable in Vars to its value in N. To ensure that the set of program
states is countable,3 we restrict to states in which at most ﬁnitely many variables have a non-zero
value. Intuitively, those that appear in a given program are possibly assigned a non-zero value.
Formally, the set Σ of program states is given by

Σ ≔ { 𝜎 : Vars → N | { 𝑥 ∈ Vars | 𝜎 (𝑥) ≠ 0 } is ﬁnite } .

We overload notation and denote by 𝜎 (𝜉) the evaluation of the (arithmetic, Boolean, or weight)
expression 𝜉 in 𝜎, i.e. the value obtained from evaluating 𝜉 after replacing every variable 𝑥 in 𝜉
by 𝜎 (𝑥). We denote by 𝜎 [𝑥 ↦→ 𝑣] the update of variable 𝑥 by value 𝑣 in state 𝜎. Formally:

𝜎 [𝑥 ↦→ 𝑣] ≔ 𝜆 𝑦.

𝑣
𝜎 (𝑦)

(

if 𝑦 = 𝑥,
otherwise.

3.3 Operational Semantics

To formalize our notion of weighted computation paths, we deﬁne small-step operational semantics
[Plotkin 2004] in terms of a weighted computation graph, or rather a weighted computation forest.4
Apart from our special weight operation ⊙ 𝑎, the operational semantics is standard but we include
the details for the sake of completeness. Intuitively, the computation forest of W-wGCL contains
one tree 𝑇𝐶,𝜎 per program 𝐶 and initial state 𝜎 representing the computation of 𝐶 on initial state
𝜎.

Deﬁnition 3.1 (Computation Forest of W-wGCL). For the monoid W = (𝑊 , ⊙, 1), the computa-

tion forest of W-wGCL is the (countably inﬁnite) directed weighted graph G = (𝑄, Δ), where
• 𝑄 = (wGCL ∪ { ↓ }) × Σ × N × { 𝐿, 𝑅 }∗ is the set of vertices (called conﬁgurations);
• Δ ⊆ 𝑄 × 𝑊 × 𝑄 is the set of directed weighted edges (called transitions) which is deﬁned as
△

the smallest set satisfying the SOS-rules in Fig. 1.

2The corresponding program 𝑖 ≔ 𝑥 # while ( 𝑖 > 0 ) { ⊙ 𝑎 # 𝑖 ≔ 𝑖 − 1 } requires introducing a fresh loop-variable 𝑖 ∈ Vars.
3We restrict Σ a priori to avoid technical issues; even wGCL programs over uncountable Σ reach just countably many
states.
4A path-based semantics in terms of trees is convenient for technical reasons; it allows to distinguish programs like skip
from { skip } ⊕ { skip }. The latter has two terminating computation paths with weight 1 and the former has only one.

Weighted Programming

𝜎′ = 𝜎 [𝑥 ↦→ J𝐸K(𝜎) ]
h𝑥 ≔ 𝐸, 𝜎, 𝑛, 𝛽 i ⊢1 h↓, 𝜎′, 𝑛+1, 𝛽 i

(assign)

h⊙ 𝑎, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h↓, 𝜎, 𝑛+1, 𝛽 i

(weight)

h𝐶1, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h↓, 𝜎′, 𝑛+1, 𝛽 i
h𝐶1 # 𝐶2, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶2, 𝜎′, 𝑛+1, 𝛽 i

(seq. 1)

𝜎 |= 𝜑
hif ( 𝜑 ) { 𝐶1 } else { 𝐶2 }, 𝜎, 𝑛, 𝛽 i ⊢1 h𝐶1, 𝜎, 𝑛+1, 𝛽 i

(if)

h𝐶1, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′

1, 𝜎′, 𝑛+1, 𝛽 i

h𝐶1 # 𝐶2, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′

and 𝐶′
1
1 # 𝐶2, 𝜎′, 𝑛+1, 𝛽 i
𝜎 |= ¬𝜑
hif ( 𝜑 ) { 𝐶1 } else { 𝐶2 }, 𝜎, 𝑛, 𝛽 i ⊢1 h𝐶2, 𝜎, 𝑛+1, 𝛽 i

(seq. 2)

≠ ↓

7

(else)

h{ 𝐶1 } ⊕ { 𝐶2 }, 𝜎, 𝑛, 𝛽 i ⊢1 h𝐶1, 𝜎, 𝑛+1, 𝛽𝐿i

(l. branch)

h{ 𝐶1 } ⊕ { 𝐶2 }, 𝜎, 𝑛, 𝛽 i ⊢1 h𝐶2, 𝜎, 𝑛+1, 𝛽𝑅i

(r. branch)

𝜎 |= 𝜑
hwhile ( 𝜑 ) { 𝐶 }, 𝜎, 𝑛, 𝛽 i ⊢1 h𝐶 # while ( 𝜑 ) { 𝐶 }, 𝜎, 𝑛+1, 𝛽 i

(while)

𝜎 |= ¬𝜑
hwhile ( 𝜑 ) { 𝐶 }, 𝜎, 𝑛, 𝛽 i ⊢1 h↓, 𝜎, 𝑛+1, 𝛽 i

(break)

Fig. 1. Structural operational semantics of wGCL-programs.

We use the notation 𝜅1 ⊢𝑎 𝜅2 instead of (𝜅1, 𝑎, 𝜅2) ∈ Δ. Intuitively, for a conﬁguration h𝐶, 𝜎, 𝑛, 𝛽i,
the component 𝐶 represents the program that still needs to be executed (thus playing the role
of a “program counter”) and 𝐶 = ↓ indicates termination; 𝜎 is the current program state (variable
valuation); 𝑛 is the number of computation steps that have been executed so far and 𝛽 is the history
of left and right branches that have been taken. Remembering the number of computation steps
and the history of left and right branches ensures that G is indeed a forest. Moreover, it is easy
to check that G has no multi-edges, i.e. there is at most one weighted edge between any two
conﬁgurations.

Note that G is ﬁnitely branching and that the only rules that alter the branching history 𝛽 are
(l. branch) and (r. branch). In particular, (if) and (else) do not change 𝛽 because they are not truly
branching: Indeed, all conﬁgurations of the form hif ( 𝜑 ) { 𝐶1 } else { 𝐶2 }, 𝜎, 𝑛+1, 𝛽i have a
unique successor conﬁguration which depends on whether or not 𝜎 satisﬁes 𝜑.

An initial conﬁguration is of the form 𝜅 = h𝐶, 𝜎, 0, 𝜖i for arbitrary 𝐶 and 𝜎. For initial conﬁgu-
rations we also write h𝐶, 𝜎i instead of h𝐶, 𝜎, 0, 𝜖i. By deﬁnition of Δ, initial conﬁgurations have
no incoming transitions; they are thus the roots of the trees in the computation forest. Similarly,
a conﬁguration h↓, 𝜎, 𝑛, 𝛽i is called ﬁnal. Final conﬁgurations are the leaves of the forest.

We can now deﬁne computation paths. For 𝜅 ∈ 𝑄, let succ(𝜅) ≔ { 𝜅 ′ ∈ 𝑄 | ∃𝑎 ∈ 𝑊 : 𝜅 ⊢𝑎 𝜅 ′ }
be the set of all possible successor conﬁgurations. A computation path of length 𝑛 ∈ N is a ﬁnite
path 𝜋 = 𝜅0𝜅1 . . . 𝜅𝑛 in G, i.e. 𝜅𝑖+1 ∈ succ(𝜅𝑖 ) for all 𝑖 = 0, . . . , 𝑛 − 1, such that 𝜅0 is initial. The
set of all such paths is denoted Paths𝑛
𝜅0 . Since G has no multi-edges, for two conﬁgurations 𝜅 and
𝜅 ′ ∈ succ(𝜅) we denote the unique weight 𝑎 ∈ 𝑊 such that 𝜅 ⊢𝑎 𝜅 ′ by wgt(𝜅 𝜅 ′). The weight of a
computation path 𝜅0𝜅1 . . . 𝜅𝑛 is then deﬁned as

wgt(𝜅0𝜅1 . . . 𝜅𝑛) ≔

𝑛−1

È𝑖=0

wgt(𝜅𝑖 𝜅𝑖+1) = wgt(𝜅0 𝜅1) ⊙ wgt(𝜅1 𝜅2) ⊙ · · · ⊙ wgt(𝜅𝑛−1 𝜅𝑛) .

Recall that our monoids are not commutative in general, and thus the order of the above product
matters. The last state of computation path 𝜋 = 𝜅0𝜅1 . . . 𝜅𝑛 is the program state at conﬁguration
𝜅𝑛 and is denoted last(𝜋) ∈ Σ. The computation path 𝜋 is called terminal if 𝜅𝑛 is ﬁnal. Given an
initial conﬁguration 𝜅0, we deﬁne the set of terminating computation paths starting in 𝜅0 as

TPaths𝜅0

=

Ø𝑛 ∈N

(cid:8)

𝜋 ∈ Paths𝑛
𝜅0

𝜋 is terminal

.

(cid:12)
(cid:12)

(cid:9)

Note that TPaths𝜅0 is a countable set for each 𝜅0. An inﬁnite computation path is an inﬁnite se-
quence 𝜅0𝜅1 . . . such that 𝜅0 . . . 𝜅𝑖 is a computation path for all 𝑖 ≥ 0.

8

Σ

Σ

wp J𝐶K ( 𝜓 )

(cid:3)

¬wp J𝐶K ( 𝜓 )

𝜓

¬𝜓

set

The

(a)
in
perspective:
wp J𝐶K ( 𝜓 ), 𝐶 can terminate in 𝜓 . Start-
ing in ¬wp J𝐶K ( 𝜓 ), 𝐶 either diverges or
terminates in ¬𝜓 , but it cannot terminate in 𝜓 .

Starting

Batz, Gallus, Kaminski, Katoen, and Winkler

( 𝜓 )

wp

𝐶
J

K

𝝈

(cid:3)

(cid:3)

𝐶

•
𝜓 (𝜏1)

Ô h

•
𝜓 (𝜏2)

•
𝜓 (𝜏3)

. . .

i

(b) The map perspective: Given initial state 𝜎,
wp J𝐶K ( 𝜓 ) determines all final states 𝜏𝑖 reach-
able from executing 𝐶 on 𝜎, evaluates 𝜓
in each 𝜏𝑖 , and returns the disjunction over
these truth values.

Fig. 2. Two perspectives on the angelic weakest precondition of program 𝐶 with respect to postcondition 𝜓 .

4 WEIGHTING TRANSFORMER SEMANTICS

Throughout this section, we develop a weakest-precondition-style calculus à la Dijkstra [1975]
for reasoning about weighted programs on source code level. We start with a recap on Dijkstra’s
weakest preconditions. We then gradually lift weakest preconditions to weakest preweightings.

4.1 Weakest Preconditions
Dijkstra’s weakest precondition calculus is based on predicate transformers

: B → B ,

where B = {0, 1}Σ

is the set of predicates over Σ,

which associate to each nondeterministic program 𝐶 a mapping from predicates to predicates.
Somewhat less common, we consider here an angelic setting, where the nondeterminism is re-
solved to our advantage. Speciﬁcally, the angelic weakest precondition transformer wp
maps
( 𝜓 ) over initial states, such that exe-
a postcondition 𝜓 over ﬁnal states to a precondition wp
( 𝜓 ) guarantees that 𝐶 can5 terminate
K
cuting the program 𝐶 on an initial state satisfying wp
𝐶
𝜎 denotes the set of all
in a ﬁnal state satisfying 𝜓 , see also Figure 2a. More symbolically, if
J
K
ﬁnal states reachable from executing 𝐶 on 𝜎, then
𝜏 |= 𝜓 .
𝜎 |= wp

𝐶
J
𝐶
J

implies

∃ 𝜏 ∈

𝐶
J

( 𝜓 )

K

K

𝐶
J

K

𝐶
J

𝜎 :
K

While the above is a set perspective on wp, a diﬀerent, but equivalent, perspective on wp is the map
perspective, see Figure 2b. From this perspective, the postcondition is a function 𝜓 : Σ → {0, 1}
( 𝜓 ) is then a function that takes
mapping program states to truth values. The predicate wp
as input an initial state 𝜎, determines for each reachable ﬁnal state 𝜏 ∈
𝜎 the (truth) value 𝜓 (𝜏),
K
and ﬁnally returns the disjunction over all these truth values. More symbolically,

𝐶
J

𝐶
J

K

wp

𝐶
J

K

wp

𝐶
J

K

( 𝜓 ) (𝜎)

=

𝜓 (𝜏) .

Ü𝜏 ∈J𝐶K𝜎

5Recall that 𝐶 is a nondeterministic program.

Weighted Programming

9

It is this map perspective which we will now gradually lift to a weighted setting. For that, we
ﬁrst need to leave the realm of Boolean values in which the predicates live. Instead of acting on
Boolean-valued predicates, our calculus will instead act on more general objects called weightings.

4.2 Weightings and Modules
For probabilistic programs, Kozen [1985] and later Morgan et al. [1996] have generalized predicates
to real-valued functions 𝑓 : Σ → R∞
≥0 (called expectations [McIver and Morgan 2005]) associating a
quantity to every program state. With weightings, we generalize further by associating a more gen-
eral “quantity” to every program state. Our wp-style calculus acts on these weightings instead of
Boolean-valued predicates. Weightings form — just like ﬁrst-order logic for weakest preconditions
— the assertion “language” of weakest preweighting reasoning.

Let us ﬁx a monoid W of weights. As with predicates and expectations, we need notions of
addition and multiplication operations for our weightings. The monoid W constituting our pro-
grams’ weights, however, only provides a multiplication ⊙. We hence require that our weightings
form a W-module M which does provide an addition. This is inspired by the probabilistic setting
where the program weights — the probabilities — are taken from the interval [0, 1]6. Expectations,
however, map program states to arbitrary extended reals in R∞
≥0 to reason about, e.g. expected
values of program variables. Another advantage of distinguishing between W and M in general
is explained in Example 4.4 further below.

We now deﬁne modules formally. (Monoid)-modules are similar to vector spaces over ﬁelds in

that they also have a well-behaved scalar multiplication.

Deﬁnition 4.1 (Monoid-Modules). Let W = (𝑊 , ⊙, 1) be a monoid. A (left) W-module M =
(𝑀, ⊕, 0, ⊗) is a commutative monoid (𝑀, ⊕, 0) equipped with a (left) action called scalar multipli-
cation ⊗ : 𝑊 × 𝑀 → 𝑀, such that for all monoid elements 𝑣, 𝑤 ∈ 𝑊 and module elements 𝑎, 𝑏 ∈ 𝑀,

(1) the scalar multiplication ⊗ is associative, i.e.
(2) the scalar multiplication ⊗ is distributive, i.e.
(3) 1 is neutral w.r.t. ⊗ and 0 annihilates, i.e.
We are now in a position to deﬁne weightings:

(𝑣 ⊙ 𝑤) ⊗ 𝑎 = 𝑣 ⊗ (𝑤 ⊗ 𝑎) ,
𝑣 ⊗ (𝑎 ⊕ 𝑏) = (𝑣 ⊗ 𝑎) ⊕ (𝑣 ⊗ 𝑏) ,

1 ⊗ 𝑎 = 𝑎

and 𝑣 ⊗ 0 = 0.

△

Deﬁnition 4.2 (Weightings). Given a W-module M, a function 𝑓 : Σ → 𝑀 associating a weight
from M to each program state is called weighting. We denote the set of all weightings by W.
Elements of W are denoted by 𝑓 , 𝑔, ℎ, . . . and variations thereof.
△
The structure (W, ⊕, 0, ⊗), where ⊕, 0, and ⊗ are lifted pointwise, also forms a W-module. We
refer to W as the module of weightings over M. We emphasize that all the results developed in
this paper apply to the important — and simpler — special case where the monoid and the mod-
ule together form a semiring: The multiplication ⊙ of a semiring S = (𝑆, ⊕, ⊙, 0, 1) is then the
left-action ⊗ of the multiplicative monoid of (𝑆, ⊙, 1) to the additive monoid (𝑆, ⊕, 0). For this
reason, we write ⊙ instead of ⊗ (as both are associative and it should be clear from the rightmost
multiplicant’s type) and adopt the following convention:

Convention. In all examples in this paper, unless stated otherwise, both the monoid W and the

W-module M are given in terms of a semiring S that will be clear from the context.

Towards our goal of deﬁning a weakest-precondition-style calculus for weighted programs, we
restrict to naturally ordered7 𝜔-bicontinuous modules:

6Note that probabilities form a monoid under multiplication.
7More generally, partially ordered modules (where the partial order is compatible with the algebraic structure, e. g. addition
and left-action are monotone) also work. However, the natural order is the least (w.r.t. ⊆) such partial order. We employ
the natural order for simplicity.

10

Batz, Gallus, Kaminski, Katoen, and Winkler

Deﬁnition 4.3 (Natural Order). Given a module M, the binary relation (cid:22) ⊆ 𝑀 × 𝑀 given by

𝑎 (cid:22) 𝑏

iﬀ

∃ 𝑐 ∈ 𝑀 :

𝑎 ⊕ 𝑐 = 𝑏

is called the natural order on M. If (cid:22) is a partial order, we call M naturally ordered.

△

The unique least element of a naturally ordered module is 0. We say that M is 𝜔-bicontinuous if (1)
both the natural order (cid:22) and the reversed natural order (cid:23) are (pointed8) 𝜔-cpos [Abramsky 1994,
Sec. 2.2.4], and (2) the operations ⊕ and ⊙ are 𝜔-continuous [Abramsky 1994, Sec. 2.2.4] functions
(w.r.t. both (cid:22) and (cid:23)). In particular, for M to be 𝜔-bicontinuous, we require the natural order (cid:22)
to possess a greatest element ⊤. The deﬁnition of naturally ordered 𝜔-bicontinuous semirings is
completely analogous. All these properties translate to the aforementioned module of weightings:
W is naturally ordered9 if the underlying module M is naturally ordered and joins/meets can be
deﬁned pointwise. For example, the Boolean semiring B and the tropical semiring T described in
Section 2 are 𝜔-continuous. Please confer Appendix A for details on the above terms.

Example 4.4 (Modules). Let Γ be a non-empty alphabet. The structure L∞

, ∪, ∅, ·) forms
a module over the word monoid Γ∗. Here, Γ∞ ≔ Γ∗ ∪ Γ𝜔 is the set of all ﬁnite and 𝜔-words
over Γ, and the subsets of Γ∞ are subsequently called 𝜔-potent languages over Γ. Our interest in
L∞
Γ stems from the fact that we want to study inﬁnite program runs as in Section 4.4. We stress
that this cannot be achieved by simply deﬁning a semiring on 2Γ∞
. In fact, even though such a
semiring can be deﬁned, its multiplication would not be 𝜔-cocontinuous (a counterexample is given
in Appendix B.3). On the other hand, L∞
Γ does form an 𝜔-bicontinuous module (cf. Appendix B.4).
△

Γ ≔ (2Γ∞

4.3 Weakest Preweightings
We now deﬁne a calculus for formal reasoning about weighted programs à la Dijkstra. In reference
to Dijkstra’s weakest precondition calculus and McIver & Morgan’s weakest preexpectation calculus,
we name our veriﬁcation system weakest preweighting calculus.

First, we notice that predicates just form a speciﬁc semiring, namely (B, ∨, ∧, 0, 1) and thus
they are in particular modules over their underlying “Boolean monoid” ({ 0, 1 } , ∧, 1). We refer to
this as the module of predicates. With that in mind, we can now generalize the map perspective of
weakest preconditions to weakest preweightings, see Figure 3a. Instead of a postcondition, we now
have a postweighting 𝑓 : Σ → 𝑀 mapping program states to elements from our W-module M.
( 𝑓 ) is then a function that takes as input an initial state 𝜎,
The weakest preweighting wp
determines the weight 𝑤 of each path starting in 𝜎 and terminating in some ﬁnal state 𝜏, scalar-
multiplies the path’s weight 𝑤 to the corresponding postweight 𝑓 (𝜏) from the module M, and
ﬁnally returns the module sum over all these so-determined weights, see Figure 3a.

𝐶
J

K

Figure 3b depicts how the general weighted setting is instantiated to a probabilistic setting: the
postweightings become real-valued functions (expectations), the path weights become the paths’
probabilities, and the summation remains a summation, thus obtaining an expected value.

One of the main advantages of Dijkstra’s calculus is that the weakest preconditions can be de-
ﬁned by induction on the program structure, thus allowing for compositional reasoning. Indeed, the
same applies to our weighted setting. In the following, we ﬁx an ambient monoid W of programs
weights and an 𝜔-bicontinuous W-module M that constitutes the habitat of our weightings W.
We now go over each construct of wGCL and see how a weakest preweighting semantics can be
developed and understood analogously to Dijkstra’s weakest preconditions.

8We additionally require existence of a least element ⊥.
9The natural order on W is the point-wise lifted natural order on M.

Weighted Programming

11

𝝈

⊕

𝑏

𝐶

𝑏

𝑎

𝑎

𝑏
⊕

𝑎

•
𝑓 (𝜏2)

𝑏

𝑏

•
𝑓 (𝜏3)

𝑏

•
𝑓 (𝜏1)

( 𝑓 )

wp

𝐶
J

K

É h

( 𝑓 )

wp

𝐶
J

K

𝝈

1
3

1
2

𝐶

. . .

i

Exp h

•
𝑓 (𝜏1)

•
𝑓 (𝜏2)

•
𝑓 (𝜏3)

. . .

i

(a) Weakest preweightings: Given initial
state 𝜎, wp J𝐶K ( 𝑓 ) (𝜎) determines the weight
𝑤 = 𝑎1𝑎2· · · of each path starting in 𝜎 and ter-
minating in some final state 𝜏𝑖 , scalar-multiplies
𝑤 to the corresponding postweight 𝑓 (𝜏), and
returns the module sum over all so-determined
weights.

(b) Weakest preexpectations: Given initial
state 𝜎, wp J𝐶K ( 𝑓 ) (𝜎) determines the ex-
pected value (with respect to the probability dis-
tribution generated by executing 𝐶 on 𝜎) of 𝑓
evaluated in the final states reached after execut-
ing 𝐶 on 𝜎.

Fig. 3. The meaning of weakest preweightings generally and weakest preexpectations specifically.

Assignment. The weakest precondition of an assignment is given by

wp

𝑥 ≔ 𝐸
J

K

( 𝜓 ) = 𝜓 [𝑥/𝐸] ,

where 𝜓 [𝑥/𝐸] is the replacement of every occurrence of variable 𝑥 in the postcondition 𝜓 by the
expression 𝐸. For weakest preweightings, we proceed analogously. That is, we “replace” every
“occurrence” of 𝑥 in 𝑓 by 𝐸. Since 𝑓 is actually not a syntactic object, we more formally deﬁne

wp

𝑥 ≔ 𝐸
J

K

( 𝑓 ) = 𝑓 [𝑥/𝐸] ≔ 𝜆 𝜎. 𝑓

𝜎 [𝑥 ↦→ 𝜎 (𝐸)]

.

So the weighting 𝑓 of the ﬁnal state reached after executing the assignment 𝑥 ≔ 𝐸 is precisely 𝑓
evaluated at the state 𝜎 [𝑥 ↦→ 𝜎 (𝐸)] — the state obtained from 𝜎 by updating variable 𝑥 to 𝜎 (𝐸).

(cid:16)

(cid:17)

Weighting. Consider the classical statement assert 𝜑. Operationally, when executing assert 𝜑
on some initial state 𝜎, we check whether 𝜎 satisﬁes the predicate 𝜑. If 𝜎 |= 𝜑, the execution
trace “passes through” the assertion and potentially proceeds with whatever program comes after
the assertion. If, however, 𝜎 6|= 𝜑, then the execution trace at hand is so-to-speak “annihilated”.
Intuitively, these two cases can be thought of as multiplying (or weighting) the execution trace
either by a multiplicative identity one or by an annihilating zero, respectively.

Denotationally, the weakest precondition of assert 𝜑 is given by

wp

assert 𝜑
J

( 𝜓 ) = 𝜑 ∧ 𝜓 .

K
Indeed, whenever an initial state 𝜎 satisﬁes the precondition 𝜑 ∧ 𝜓 , then (a) executing assert 𝜑
will pass through asserting 𝜑 and moreover — since the assertion itself does not alter the current
program state — (b) it terminates in state 𝜎 which also satisﬁes the postcondition 𝜓 . Dually, if 𝜎
does not satisfy 𝜑 ∧ 𝜓 , then either (a) executing assert 𝜑 does not pass through asserting 𝜑 or
(b) it does pass through the assertion but 𝜎 does not satisfy the postcondition 𝜓 .

When viewing the above through our monoid and module glasses, ∧ is just the scalar-multipli-
( 𝜓 ) weights (multiplies) 𝜓
cation in the module of predicates. So in other words, wp
with 𝜑. Therefore, we generalize from conjunction with a predicate to (scalar-)multiplication with a

assert 𝜑

K

J

12

Batz, Gallus, Kaminski, Katoen, and Winkler

monoid element 𝑎 from W and introduce the statement ⊙ 𝑎 into the programming language. Op-
erationally, our execution traces are weighted and the ⊙ 𝑎 statement scalar-multiplies the current
execution trace’s weight by an 𝑎. Denotationally, the weakest preweighting of ⊙ 𝑎 is given by

wp

⊙ 𝑎

( 𝑓 ) = 𝑎 ⊙ 𝑓 .

J

K

Remark 4.5 (On Non-commutativity and Notation). Recall that multiplication of weights is gen-
erally not commutative — think, for example, about the word monoid Γ∗. In the light of potential
non-commutativity, the ﬂipping of the sides, i.e. ⊙ 𝑎 in the program syntax versus 𝑎 ⊙
in the
denotational weighting transformer semantics, is on purpose: Programs are usually read (and ex-
ecuted) in a forward manner. Assuming that the weights along an execution trace are collected
from left to right, from initial to ﬁnal state, weighting by 𝑎 is a right-multiplication, appending at
the end of the current execution trace the weight 𝑎.

Weakest preweightings, on the other hand, are backward-moving: The 𝑓 is a postweighting
that potentially abstracts or summarizes the eﬀects of subsequent computations. Whenever we
encounter on our way from the back to the front of a program a weighting by 𝑎, we thus have to
prepend 𝑎 to the current postweighting 𝑓 , yielding a left-multiplication 𝑎 ⊙ 𝑓 in the denotations. △
Branching. We now consider the classical angelic nondeterministic choice { 𝐶1 } (cid:3) { 𝐶2 }. Op-
erationally, when “executing” this choice on some initial state 𝜎, either the program 𝐶1 or the
program 𝐶2 will be executed, chosen nondeterministically. Hence, the execution will reach either
a ﬁnal state in which executing 𝐶1 on 𝜎 terminates or a ﬁnal state in which executing 𝐶2 on 𝜎
terminates (or no ﬁnal state if both computations diverge).

Denotationally, the angelic weakest precondition of { 𝐶1 } (cid:3) { 𝐶2 } is given by
( 𝜓 ) .

( 𝜓 ) = wp

( 𝜓 ) ∨ wp

{ 𝐶1 } (cid:3) { 𝐶2 }

wp

𝐶1
J

K

𝐶2
J
𝐶1
J

K

K
( 𝜓 ) ∨ wp

Indeed, whenever an initial state 𝜎 satisﬁes the precondition wp
executing 𝐶1 or executing 𝐶2 will terminate in some ﬁnal state satisfying the postcondition 𝜓 .

𝐶2
J

K

( 𝜓 ) then

{ 𝐶1 } (cid:3) { 𝐶2 }

Again viewed through our module glasses, ∨ is just the addition of the module of predicates.
( 𝜓 ). We
So in other words, wp
thus generalize from disjunction of two predicates to addition of two module elements and introduce
the statement { 𝐶1 } ⊕ { 𝐶2 } into the programming language. Operationally, we have the same
interpretation as in the classical case: Either the program 𝐶1 can be executed or the program 𝐶2.
Denotationally, the weakest preweighting of { 𝐶1 } ⊕ { 𝐶2 } is given by

( 𝜓 ) unions (adds) wp

( 𝜓 ) and wp

𝐶1
J

𝐶2
J

K

J

K

K

wp

{ 𝐶1 } ⊕ { 𝐶2 }

( 𝑓 ) = wp

( 𝑓 ) ⊕ wp

( 𝑓 ) .

𝐶1
J

K

𝐶2
J

K

( 𝑓 ) tells us what element we obtain if 𝐶𝑖 is executed, and the module addition ⊕ tells us

wp
how to account for the fact that either 𝐶1 or 𝐶2 could have been executed.

𝐶𝑖
J

K

J

J

K

K

Conditional Choice. We now consider the classical conditional choice if ( 𝜑 ) { 𝐶1 } else { 𝐶2 }.
Operationally, when executing if ( 𝜑 ) { 𝐶1 } else { 𝐶2 } on some initial state 𝜎, we check whether
𝜎 satisﬁes the predicate 𝜑. If 𝜎 |= 𝜑, the program 𝐶1 is executed; otherwise the program 𝐶2.

Denotationally, the weakest precondition of if ( 𝜑 ) { 𝐶1 } else { 𝐶2 } (and in fact also the weak-

est precondition of { assert 𝜑

𝐶1 } (cid:3) { assert ¬𝜑

𝐶2 }) is given by

wp

if ( 𝜑 ) { 𝐶1 } else { 𝐶2 }
J

K

#

( 𝜓 ) = 𝜑 ∧ wp

#

𝐶1
J

K

( 𝜓 ) ∨ ¬𝜑 ∧ wp

( 𝜓 ) .

𝐶2
J

K

Indeed, whenever an initial state 𝜎 satisﬁes the above precondition then either 𝜎 |= 𝜑 and then
( 𝜓 ) — executing 𝐶1 will terminate in a ﬁnal state satisfy-
— since then 𝜎 must also satisfy wp
ing 𝜑, or 𝜎 6|= 𝜑 and — since then 𝜎 must also satisfy wp
( 𝜓 ) — executing 𝐶2 will terminate
in a ﬁnal state satisfying 𝜑.

𝐶2
J

𝐶1
J

K

K

Weighted Programming

13

In terms of monoids and modules, 𝜑 ∧

could be viewed as a scalar-multiplication by either 1
(leaving the right operand unaltered) or by 0 (annihilating the right operand). However, general
monoids do not posses an annihilating 0. In order to reenact the desired behavior, we introduce
the Iverson bracket [𝜑] of a predicate 𝜑, which for a weighting 𝑓 ∈ W deﬁnes the weighting

( [𝜙] 𝑓 ) (𝜎)

=

𝑓 (𝜎)
0

if 𝜎 |= 𝜑 ,
otherwise .

(
With this notation at hand, we deﬁne the weakest preweighting of if ( 𝜑 ) { 𝐶1 } else { 𝐶2 } by
( 𝑓 ) = [𝜑] wp

if ( 𝜑 ) { 𝐶1 } else { 𝐶2 }

( 𝑓 ) ⊕ [¬𝜑] wp

( 𝑓 ) .

wp

J

K

By convention, [𝜙] binds stronger than ⊕. Depending on the truth value of 𝜑, the above weakest
( 𝑓 ).
preweighting thus selects either the preweighting wp

( 𝑓 ) or the preweighting wp

𝐶2
J

K

𝐶1
J

K

𝐶1
J

K

Sequential Composition. Our composite statement 𝐶1
𝐶2 is standard. Operationally, 𝐶1 is ex-
ecuted ﬁrst and then — provided that 𝐶1 terminates — 𝐶2 is executed. A distinguishing feature of
the classical weakest precondition transformer is that it moves backwards through the program,
and the same applies to our weighting transformer, i.e.

#

wp

𝐶1
J

#

K

𝐶2

( 𝑓 ) = wp

( wp

( 𝑓 ) ) .

𝐶1
J

K

𝐶2
J

K

Indeed, to compute the weakest preweighting of the composition 𝐶1
ﬁrst compute an intermediate weighting wp

( 𝑓 ), which we then feed into wp

#

𝐶2 w.r.t. to some 𝑓 ∈ W, we

𝐶2
J

K

𝐶1
J

.
K

Looping. Operationally, a loop while ( 𝜑 ) { 𝐶 } is equivalent to the inﬁnite nested conditional

if ( 𝜑 ) { 𝐶

if ( 𝜑 ) { 𝐶

if ( 𝜑 ) { 𝐶

. . . } else { skip } } else { skip } } else { skip } ,

#

#

#

which is the same as saying that while ( 𝜑 ) { 𝐶 } ≡ if ( 𝜑 ) { 𝐶
while ( 𝜑 ) { 𝐶 } } else { skip }.
With the rules for conditional choice and composition as explained above, it is thus reasonable to
require that the preweighting wp

( 𝑓 ) should be a ﬁxed point of the function

#

𝐶2
J

K

while ( 𝜑 ) { 𝐶 }
J

𝑋 ↦→ [𝜑] wp

K
( 𝑋 ) ⊕ [¬𝜑] 𝑓

𝐶
J

K
which is indeed just the wp-characteristic function deﬁned above. For both the classical weakest
precondition transformer as well as for our weighted wp, we choose the semantics to be the least
ﬁxed point, which exists uniquely if the ambient module M is 𝜔-continuous (see Theorem 4.7
below). In the classical Boolean setting, this corresponds to choosing the strongest (least) possi-
ble predicate that satisﬁes the ﬁxed point equation. This ensures that the weakest precondition
contains only those initial states where the loop can actually terminate in a state satifying the
postcondition — but no such states for which the loop cannot terminate at all. Taking the least
ﬁxed point in the weighted setting generalizes this intuition as we will show in Theorem 4.15
below.

Properties of wp. Based on the above discussion, we now deﬁne wp formally, state healthiness
and soundness properties, and provide several examples.

Deﬁnition 4.6 (Weakest Preweighting Transformer). The transformer wp : wGCL → (W → W)
is deﬁned by induction on the structure of wGCL according to the rules in Table 2. The function

Φ𝑓 : W → W, 𝑋 ↦→ [¬𝜑] 𝑓 ⊕ [𝜑] wp

( 𝑋 )

𝐶 ′
J

K

whose least ﬁxed point deﬁnes the weakest preweighting of while ( 𝜑 ) { 𝐶 } is called the wp-
characteristic function of while ( 𝜑 ) { 𝐶 } with respect to postweighting 𝑓 .
△

14

Batz, Gallus, Kaminski, Katoen, and Winkler

Table 2. Rules defining the weakest preweighting wp J𝐶K ( 𝑓 ) of program 𝐶 w.r.t. postweighting 𝑓 .

#

𝐶
𝑥 ≔ 𝐸
𝐶1
𝐶2
if ( 𝜑 ) { 𝐶1 } else { 𝐶2 }
{ 𝐶1 } ⊕ { 𝐶2 }
⊙ 𝑎
while ( 𝜑 ) { 𝐶 ′ }

( 𝑓 )

wp
𝐶
J
K
𝑓 [𝑥/𝐸]
wp
𝐶1
J
[𝜑] wp
wp
𝐶1
J
𝑎 ⊙ 𝑓
lfp 𝑋 . [¬𝜑] 𝑓 ⊕ [𝜑] wp

( wp
K
𝐶1
J
( 𝑓 ) ⊕ wp
K

( 𝑓 ) )
( 𝑓 ) ⊕ [¬𝜑] wp
( 𝑓 )

𝐶2
J

𝐶2
J

K

K

( 𝑓 )

𝐶2
J

K

K

( 𝑋 )

𝐶 ′
J

K

Theorem 4.7 (Well-Definedness of wp). Let the monoid module M over W be 𝜔-continuous.
For all W-wGCL programs 𝐶, the weighting transformer wp
is a well-deﬁned 𝜔-continuous end-
ofunction on the module of weightings over M. In particular, if Φ𝑓 is the wp-characteristic function
of while ( 𝜑 ) { 𝐶 } with respect to postweighting 𝑓 , then

𝐶
J

K

wp

while ( 𝜑 ) { 𝐶 }

( 𝑓 )

=

J

K

Φ𝑖
𝑓 (0) .

Ä𝑖 ∈N

Our wp satisﬁes the following so-called healthiness criteria (see e.g. [Hino et al. 2016; Hoare 1978;
Keimel 2015; McIver and Morgan 2005]) or homomorphism properties [Back and von Wright 1998]:

Theorem 4.8 (Healthiness). Let the monoid module M over W be 𝜔-continuous. For all W-

wGCL programs 𝐶, the wp transformer is
(1) monotone, i.e. for all 𝑓 , 𝑔 ∈ W,
(2) strict, i.e.
(3) additive, i.e. for all 𝑓 , 𝑔 ∈ W,
(4) Moreover, if W is commutative, then wp is homogeneous, i.e. for all 𝑎 ∈ 𝑊 and 𝑓 ∈ W,
K

𝐶
J
( 𝑓 ⊕ 𝑔 ) = wp

𝐶
J
𝐶
J

implies wp

( 0 ) = 0,

( 𝑓 ) (cid:22) wp

K
( 𝑔 ).

( 𝑓 ) ⊕ wp

K
𝐶
J

𝑓 (cid:22) 𝑔

𝐶
J

𝐶
J

( 𝑔 ),

wp

wp

K

K

K

and together with (3), wp then becomes linear.

wp

𝐶
J

K

( 𝑎 ⊙ 𝑓 ) = 𝑎 ⊙ wp

( 𝑓 ) ,

𝐶
J

K

Homogeneity does not hold in general: Consider the formal languages semiring L { 𝑎,𝑏 } and the
program 𝐶 = ⊙ { 𝑎 } with the constant postweighting 𝑓 = 1 = { 𝜖 }. Then

( { 𝑏 } · 𝑓 ) = { 𝑎 } · { 𝑏 } = { 𝑎𝑏 } ≠ { 𝑏𝑎 } = { 𝑏 } · { 𝑎 } = { 𝑏 } · wp

( 𝑓 ) .

The next theorem states that wp indeed generalizes the map perspective on classical weakest pre-
conditions as anticipated at the beginning of Section 4.3. The operational semantics as well as
TPaths h𝐶, 𝜎 i, wgt, and last are deﬁned in Section 3.3.

Theorem 4.9 (Soundness of wp). Let the monoid module M over W be 𝜔-continuous. For all

𝐶 ∈ wGCL, 𝜎 ∈ Σ and 𝑓 ∈ W,

( 𝑓 ) (𝜎)

=

wp

𝐶
J

K

Ê𝜋 ∈TPathsh𝐶, 𝜎 i

wgt(𝜋) ⊙ 𝑓 (last(𝜋)) .

(1)

wp-Annotations. In the spirit of Hoare-style reasoning, we will annotate programs as is shown
abstractly in Fig. 4a and concretely in Fig. 4b. Read the annotations from bottom to top as follows:
𝑓 This ﬁrst annotation states that we start our reasoning from postweighting 𝑓 ∈ W.
(1)

((

wp

𝐶
J

K

𝐶
J

K

Weighted Programming

𝑔′
𝑔

⊲⊳

((
wp

((
𝐶

(meaning 𝑔 = wp

(meaning 𝑔 ⊲⊳ 𝑔′)
( 𝑓 ))
𝐶
J

K

𝑓

(postweighting is 𝑓 )
(a) Style for wp annotations. ⊲⊳ ∈ {(cid:22), =, (cid:23)}.

((

=

= 𝑔′

2
[𝑥 > 0] (1 + 1) ⊕ [𝑥 = 0] (2 min 3)

((
wp
((
if ( 𝑥 > 0 ) { ⊙ 1
= 𝑓

0

⊙ 1 } else { { ⊙ 2 } ⊕ { ⊙ 3 } }

#

15

= 𝑔

((

(b) Annotations for Example 4.10.

Fig. 4. Annotations for weakest preweightings. It is more intuitive to read these from the bottom to top.

(2) wp

((

(3) ⊲⊳

((

(

𝑔 The superscript wp before the annotation indicates that this annotation is obtained from
). The program passed into wp is the line immediately below this anno-
applying wp
tation — in this case 𝐶 — and the continuation passed into wp is the annotation immediately
below the program — in this case 𝑓 . Hence, this annotation states 𝑔 = wp
𝑔′ This last annotation states that 𝑔 ⊲⊳ 𝑔′, for ⊲⊳ ∈ {(cid:22), =, (cid:23)}. We thus allow rewriting, or
(like the classical rule of consequence in Hoare logic) to perform a monotonic relaxation.

𝐶
J

( 𝑓 ).

J

K

K

Let us illustrate wp by means of two examples. Recall our convention that the monoid W and the
module M stem from a semiring S unless stated otherwise.

Example 4.10. Let S = T = (N+∞, min, +, ∞, 0) be the tropical semiring and consider a wGCL-

program 𝐶. Theorem 4.9 implies that for all states 𝜎 ∈ Σ,

( 0 ) (𝜎)

=

“minimum weight of all terminating computation paths that start in 𝜎”

where the weight of a path is the usual sum of all weights along that path. Notice that the above
“0” is the map to the natural number 0 and not the semiring 0 = ∞. For instance, we can verify that

wp

if ( 𝑥 > 0 ) { ⊙ 1

⊙ 1 } else { { ⊙ 2 } ⊕ { ⊙ 3 } }

( 0 )

=

2 .

J

#

For that, consider the program annotations in Fig. 4b, which express that 2 = [𝑥 > 0] (1 + 1) ⊕
( 0 ) where 𝐶 = if (𝑥 > 0) {. . .}. This reﬂects that if 𝑥 > 0 initially,
[𝑥 = 0] (2 min 3) = wp
𝐶
then the only possible terminating path has weight 1 + 1 = 2. Otherwise, i.e. if 𝑥 = 0, then the
J
△
minimum weight of the two possible paths is also 2.

K

K

Example 4.11. Let S = LΓ = (2Γ∗

, ∪, ·, ∅, { 𝜖 }) be the semiring of formal languages over Γ.
Similarly to Example 4.4, we now choose the monoid W = Γ∗ of words and view LΓ as a Γ∗-
module, i.e. the weighting-statements are of the form ⊙ 𝑤 for some single word 𝑤 ∈ Γ∗. The
weightings W, however, associate an entire language to each state. For all initial states 𝜎 ∈ Σ, we
have

wp

𝐶
J

K

( { 𝜖 } ) (𝜎)

=

“language of all terminating computation paths starting in 𝜎” ,

where each terminating path contributes the single word obtained from concatenating all symbols
occurring in the weight-statements along this path (this may also yield the empty word 𝜖 = 1). △

wp

𝐶
J

K

4.4 Weakest Liberal Preweightings

The weakest preweighting calculus developed in the previous section assigns a weight to each
initial state 𝜎 based on the terminating computation paths starting in 𝜎 and the postweighting 𝑓 .
In particular, wp ignores (more precisely: assigns weight 0 to) nonterminating behavior, i.e. the
( 𝑓 ) is independend of the inﬁnite computation paths of 𝐶. For instance, in
preweighting wp
the formal languages semiring L { 𝑎,𝑏 } with monoid W = { 𝑎, 𝑏 }∗, we have for all 𝑓 ∈ W that
∅

while ( true ) { ⊙ 𝑏 }

= wp

( 𝑓 ) ,

𝐶
J

( 𝑓 )

wp

=

K

while ( true ) { ⊙ 𝑎 }
J

K

J

K

16

Batz, Gallus, Kaminski, Katoen, and Winkler

even though the computation trees of the two programs are clearly distinguishable.

In this section, we deﬁne weakest liberal preweightings (wlp) as a means to reason about such
inﬁnite, i.e. nonterminating, program behaviors, thus generalizing Dijkstra’s classical weakest lib-
eral preconditions. Unlike Dijkstra’s weakest liberal preconditions who just assign true (instead
of false) to any nonterminating behavior, our weakest liberal preweightings can inspect nontermi-
nating behavior more nuancedly. As a teaser: our weakest liberal preweightings can distinguish
between while ( true ) { ⊙ 𝑎 } and while ( true ) { ⊙ 𝑏 } as we will demonstrate below.

Reconsidering the map perspective on weakest preconditions explained in Section 4.3, the weak-
est liberal precondition of program 𝐶 with respect to postcondition 𝜓 maps an initial state 𝜎 to
true iﬀ (i) 𝐶 started on 𝜎 can terminate in a state 𝜏 satisfying 𝜓 , or (ii) it is possible that 𝐶 does not
terminate at all, or both. In more symbolic terms,

wlp

𝐶
J

K

( 𝜓 ) (𝜎)

=

𝜓 (𝜏) ∨

Ü𝜏 ∈J𝐶K𝜎

𝐶
J

⇑
𝜎 ,
K

where

wlp

𝐶
J

⇑
𝜎 holds iﬀ the nondeterministic program 𝐶 may not terminate on 𝜎.10 We have
K
( 𝜓 ) (𝜎) = wp
𝐶
J

( false ) (𝜎) =

( 𝜓 ) (𝜎) ∨

𝐶
J

𝐶
J

𝐶
J

𝐶
J

⇑
𝜎
K

and

wlp

K

K

⇑
𝜎 ,
K

( false ) captures precisely the nonterminating behavior of 𝐶, and hence

(2)

( false ) characterizes precisely the diﬀerence between wp

K

( 𝑓 ) and wlp

( 𝑓 ).

In the realm of monoids and modules, the predicate false is the zero 0 of the Boolean semiring.

K

K

K

𝐶
J

𝐶
J

𝐶
J

K
implying that wlp
wlp

𝐶
J

We now deﬁne a weakest liberal preweighting calculus generalizing (2) by satisfying

∀ 𝑓 ∈ W :

wlp

( 𝑓 )

= wp

( 𝑓 ) ⊕ wlp

( 0 ) .

𝐶
J

𝐶
J

Intuitively, wlp
ample programs from the beginning of this subsection considered over the Γ∗-module L∞
𝜔-potent formal languages, we get for example

K
( 0 ) captures the weights of the nonterminating paths in 𝐶: For the two ex-
{ 𝑎,𝑏 } of

𝐶
J

K

K

K

𝐶
J

wlp

while ( true ) { ⊙ 𝑎 }

( 0 ) = { 𝑎𝜔 }

and wlp

J

K

Deﬁnition 4.12 (Weakest Liberal Preweighting Transformer). The transformer wlp : wGCL →
(W → W) is inductively deﬁned according to Table 2 with lfp replaced by gfp and with every oc-
( 𝑓 ) is deﬁned as the greatest
currence of wp replaced by wlp. In particular, wlp
ﬁxed point of the characteristic function

while ( 𝜑 ) { 𝐶 ′ }

J

while ( true ) { ⊙ 𝑏 }
J

K

( 0 ) = { 𝑏𝜔 } .

Ψ𝑓 : W → W, 𝑋

↦→ [¬𝜑] 𝑓 ⊕ [𝜑] wlp

We obtain a well-deﬁnedness result analogous to Theorem 4.7:

( 𝑋 ) .

K

△

K
𝐶 ′
J

Theorem 4.13 (Well-Definedness of wlp). Let M be an 𝜔-cocontinuous W-module. For all
W-wGCL programs 𝐶, the transformer wlp
is a well-deﬁned 𝜔-cocontinuous endofunction on the
module of weightings over M. In particular, if Ψ𝑓 is the wlp-characteristic function of while ( 𝜑 ) { 𝐶 }
with respect to postweighting 𝑓 , then

𝐶
J

K

wlp

while ( 𝜑 ) { 𝐶 }
J

K

( 𝑓 )

= l
𝑖 ∈N

Ψ𝑖
𝑓 (⊤) .

As stated above, we furthermore get the following fundamental property:

Theorem 4.14 (Decomposition of wlp). Let M be an 𝜔-bicontinuous W-module. Then for all

programs 𝐶 and postweightings 𝑓 ,

10Recall that we consider angelic nondeterminism.

( 𝑓 )

= wp

wlp

𝐶
J

K

( 𝑓 ) ⊕ wlp

𝐶
J

K

( 0 ) .

𝐶
J

K

𝐶
J

K

Weighted Programming

Moreover, we get a statement relating (inﬁnite) computation paths and wlp

17

( 0 ):

Theorem 4.15 (Soundness of wlp). Let the monoid module M over W be 𝜔-bicontinuous11.

Then for all programs 𝐶 and initial states 𝜎,

( 0 ) (𝜎)

wlp

𝐶
J

K

= l
𝑛 ∈N

Ê𝜋 ∈Paths𝑛

h𝐶, 𝜎 i

wgt(𝜋) ⊙ ⊤ .

(3)

Note that Theorem 4.15 is phrased in terms of the ﬁnite computation paths Paths𝑛
h𝐶, 𝜎 i. This is
because it is somewhat diﬃcult to deﬁne a general inﬁnite product in W that is compliant with
the way our wlp assigns weights to inﬁnite computation paths. Nevertheless, the right-hand side
of (3) depends only on the inﬁnite paths which can be seen intuitively as follows: For arbitrary
𝑛 ∈ N consider the ﬁnite (not necessarily terminating) computation paths up to length 𝑛. Let 𝑣 (𝑛)
denote the sum their weights, where the weight of each path is additionally multiplied by ⊤, the
top element of M. Then (𝑣 (𝑛))𝑛 ∈N is a decreasing chain in the module M. In the limit (i.e. inﬁmum),
all terminating computation paths will be ruled out as each of them has some ﬁnite length. The
limit/inﬁmum of the 𝑣 (𝑛) exists by our theory and is independent of the program’s terminating
paths. In fact, for programs that do not exhibit inﬁnite paths, we can show that the limit is 0 using
Kőnig’s classic inﬁnity lemma. We discuss the implications of this in Section 5.2.

Note that Theorem 4.15 indeed implies that wlp is backward compatible to classical weakest
liberal preconditions: In the Boolean semiring, the right-hand side of (3) equals true iﬀ there exists
⇑
an inﬁnite computation path starting in 𝜎, and thus wlp
𝜎 holds as expected.
K
Example 4.16. Reconsider the tropical semiring T = (N+∞, min, +, ∞, 0) with ⊤ = 0. The in-
ﬁmum d in the natural order is the supremum in the standard order on N+∞, and multiplication
with the top element ⊤ = 0 is eﬀectless as 𝑎 ⊙ ⊤ = 𝑎 + 0 = 𝑎. It follows from Theorem 4.15 that

( 0 ) (𝜎) ≡

𝐶
J

𝐶
J

K

( 0 ) (𝜎)

=

“minimum weight of all inﬁnite computation paths starting in 𝜎” ,

or ∞ — the tropical 0 — if no inﬁnite path exists. Hence wlp
( 0 ) (𝜎) — where the natural
number 0 is the tropical 1 — is the minimum path weight among all ﬁnite and inﬁnite computation
paths starting in 𝜎. For example, for the program 𝐶 given by

𝐶
J

K

while ( 𝑥 = 2 ) {

{ 𝑥 ≔ 3

⊙ 5 } ⊕ { skip }

}

#
and initial state 𝜎 with 𝜎 (𝑥) = 2, we have wp
( 0 ) (𝜎) = 5 but wlp
there exists an inﬁnite path (only performing skip) with weight 0 < 5.

𝐶
J

K

𝐶
J

K

( 0 ) (𝜎) = 0 because
△

Example 4.17. Let M = L∞

Γ be the module of 𝜔-potent formal languages over the monoid of
words W = Γ∗ (cf. Example 4.11). Thus, weightings 𝑓 ∈ W associate states with languages that
contain both ﬁnite and 𝜔-words. Let 𝐶 be a Γ∗-wGCL program. It follows from Theorem 4.15 that

( 0 ) (𝜎)

wlp

𝐶
J

K

= “language of all (ﬁnite and 𝜔-)words that have some
inﬁnite computation path starting in 𝜎 as preﬁx”

,

where we have identiﬁed computation paths with the words they are labelled with. In particular, if
( 0 ) (𝜎) is precisely the language
all inﬁnite paths of 𝐶 are weighted with an 𝜔-word, then wlp
consisting of all these words. For example, let Γ = {𝑎, 𝑏} and consider the following program 𝐶:
{ 𝑥 ≔ 0

while ( 𝑥 = 1 ) {

⊙ 𝑎 } ⊕ { ⊙ 𝑏 }

𝐶
J

}

K

11In the statement, we assert 𝜔-bicontinuity: our proof makes heavy use of Theorem 4.14 and thus we need wp to be well-
deﬁned. However, it might be possible to prove a link between operational semantics and wlp assuming only 𝜔-cocontinuity.
But a proof seems much more convoluted than our current one.

#

wlp

𝐶
J

K

18

Batz, Gallus, Kaminski, Katoen, and Winkler

If initially 𝜎 (𝑥) = 1, then wp
{𝑏𝜔 } and hence

𝐶
J

K

( 1 ) (𝜎) = { 𝑎, 𝑏𝑎, 𝑏𝑏𝑎, . . . }, where 1 = { 𝜖 }, but wlp

( 0 ) (𝜎) =

𝐶
J

K

( 1 ) (𝜎) = wp

( { 𝜖 } ) (𝜎) ∪ wlp

( 0 ) (𝜎) = { 𝑏𝜔, 𝑎, 𝑏𝑎, 𝑏𝑏𝑎, . . . } .

△

wlp

𝐶
J

K

𝐶
J

K

𝐶
J

K

𝐶
J

Remark 4.18 (Probabilistic Weakest Liberal Preexpectations). McIver and Morgan [2005] and Kozen
( 0 ) (𝜎) yields the probability that 𝐶 di-
[1985] deﬁne a probabilistic wlp-semantics where wlp
verges on input 𝜎. Technically, probabilistic programs are wGCL-programs over the real semiring
(R∞
≥0, +, ·, 0, 1) where branching and weighting is restricted to statements of the form { . . . } 𝑝 ⊕𝑞
{ . . . }, where 𝑝 + 𝑞 = 1. However, by Theorem 4.15, our wlp over R∞
≥0 yields for all loops and all
( 0 ) (𝜎) ∈ {0 = 0, ⊤ = ∞} and is thus trivial. We cannot simply ﬁx this by choos-
states wlp
ing probabilities in [0, 1] as our module M since [0, 1] is not closed under addition. Nonetheless,
we can recover the wlp of Kozen [1985]; McIver and Morgan [2005] by considering the greatest
ﬁxed point below or equal to 1 instead of the true gfp in R∞
≥0, i.e. we would consider a modiﬁed
transformer wlp(cid:22)1. It is easy to show that this is well-deﬁned and still satisﬁes Theorem 4.14 and
△
Theorem 4.15 (with the multiplication ⊙⊤ on the right hand side of (3) omitted).

loop
J

K

K

5 VERIFICATION OF LOOPS

For loop-free programs, weakest (liberal) preweightings can be obtained essentially by means of
syntactic reasoning. For loops, however, this is not the case since we need to reason about ﬁxed
points. This section introduces easy-to-apply proof rules for bounding weakest (liberal) preweight-
ings of loops, generalizing rules from the probabilistic setting [McIver and Morgan 2005].

5.1 Invariant-Based Verification of Loops
Let us ﬁx throughout the rest of the section an ambient monoid W of program weights and an
ambient 𝜔-bicontinuous W-module M. Since the wp- and wlp-characteristic functions of loops
are 𝜔-(co)continuous (see Theorem 4.7 and 4.13), we obtain proof rules for loops by Park induction
Theorem A.4:

Theorem 5.1 (Induction Rules for Loops). Let Φ𝑓 and Ψ𝑓 be the wp- and wlp-characteristic

functionals of the loop while ( 𝜑 ) { 𝐶 } with respect to postweighting 𝑓 . Then for all 𝐼 ∈ W,

Φ𝑓 (𝐼 ) (cid:22) 𝐼
𝐼 (cid:22) Ψ𝑓 (𝐼 )

implies

wp

while ( 𝜑 ) { 𝐶 }

( 𝑓 ) (cid:22) 𝐼 ,

and

J
𝐼 (cid:22) wlp

K

implies

while ( 𝜑 ) { 𝐶 }
J
The weightings 𝐼 are called wp-superinvariants and wlp-subinvariants, respectively (or just invari-
ants if clear from context). In many cases — in particular for loop-free loop bodies — the above
proof rules are easy to apply as they only require to apply the respective characteristic functional
once. Example 5.5 demonstrates invariant-based reasoning and our annotation-style for loops.

( 𝑓 ) .

K

What about the converse directions, i.e. lower bounds for wp and upper bounds for wlp? For
that, the analogous formulations of the above proof rules do not hold in general [Kaminski 2019].
In the next subsection we show that in the case of terminating programs, these formulations do
hold.

5.2 Terminating Programs and Unique Fixed Points
The notion of universal certain termination is central to the results of this section:

Deﬁnition 5.2 (Universal Certain Termination). A wGCL-program 𝐶 terminates certainly on ini-
tial state 𝜎 ∈ Σ if there does not exist an inﬁnite computation path starting in h𝐶, 𝜎i. Moreover, 𝐶
is universally certainly terminating (UCT) if it terminates certainly on all 𝜎 ∈ Σ.
△

Weighted Programming

19

⊲⊳

((
Φ

𝐼

𝑔

((
while ( 𝜑 ) {

𝐼 ′′
𝐼 ′

⊲⊳

((
wp
((
𝐶

𝐼

88

}

𝑓

(meaning 𝑔 ⊲⊳ 𝐼 )
(𝑔 = [¬𝜑] 𝑓 ⊕ [𝜑] 𝐼 ′′)

=

((
Φ

[𝑥=0∨𝑦=0]0 ⊕ [𝑥=0∨𝑦=0] (2𝑥+𝑦) = 𝐼

[𝑥=0∨𝑦=0]0 ⊕ [𝑥 >0∧𝑦>0]𝐼 ′′ = 𝑔

(meaning 𝑔 = wp

(meaning 𝐼 ′ ⊲⊳ 𝐼 ′′)
( 𝑓 ))
𝐶
J

K

((
while ( 𝑥 > 0 ∧ 𝑦 > 0 ) {

=

[ (𝑥 >1)∨(𝑥 >0∧𝑦>1) ] (2𝑥+𝑦) ⊕ 1⊙ [𝑥 ≤1∨𝑦 ≤1]0 = 𝐼 ′′

(expression ommited) = 𝐼 ′

((
wp
((
{ 𝑥 ≔ 𝑥−1

𝑦 ≔ 𝑦+1 } ⊕ { 𝑦 ≔ 𝑦−1 }

⊙ 1

(we employ invariant 𝐼 )

[𝑥=0∨𝑦=0]0 ⊕ [𝑥=0∨𝑦=0] (2𝑥+𝑦) = 𝐼

#

#

(postweighting is 𝑓 )

}

88

0 = 𝑓

((

(a) Annotation style for loops using invariants.

((

(b) wp loop annotations for Example 5.5.

Fig. 5. Inside the loop, we push an invariant 𝐼 (provided externally, denoted by 88 𝐼 ) through the loop body,
thus obtaining 𝐼 ′′ which is (possibly an over- or underapproximation of) 𝐼 ′ = wp JC′K ( 𝐼 ). Above the loop
head, we then annotate 𝑔 = [¬𝜑] 𝑓 ⊕ [𝜑] 𝐼 ′′. In the first line, we establish 𝑔 ⊲⊳ 𝐼 , for ⊲⊳ ∈ {(cid:22), =, (cid:23)}.

𝐶
J

K

𝐶
J

K

Certain termination of a program 𝐶 ∈ wGCL is also known as demonic termination of the pro-
gram obtained from 𝐶 by ignoring all weight-statements and interpreting branching as demonic
non-determinism. Note that all loop-free programs are trivially UCT. A well-established method
for proving certain termination is by use of ranking functions [Dijkstra 1975]. An important con-
sequence of UCT is that wp and wlp coincide. This is intuitively clear because if 𝐶 is UCT then
wlp
. Formally:

has no additional nonterminating behavior to account for compared to wp

Theorem 5.3 (Uniqe Fixed Points by Universal Certain Termination). Let while ( 𝜑 ) { 𝐶 }
have a UCT loop body 𝐶 and let Φ𝑓 and Ψ𝑓 be its wp- and wlp-characteristic functionals with respect
to an arbitrary postweighting 𝑓 . Then Φ𝑓 = Ψ𝑓 .

Furthermore, let 𝐼, 𝐽 ∈ W be ﬁxed points of Φ𝑓 . Then
while ( 𝜑 ) { 𝐶 } terminates certainly on 𝜎

implies

𝐼 (𝜎) = 𝐽 (𝜎) .

Moreover, if while ( 𝜑 ) { 𝐶 } is UCT, then Φ𝑓 has a unique ﬁxed point and
while ( 𝜑 ) { 𝐶 }
J

while ( 𝜑 ) { 𝐶 }
J

( 𝑓 ) = wlp

wp

K

K

( 𝑓 ) .

𝐼 (cid:22) Φ𝑓 (𝐼 )
Ψ𝑓 (𝐼 ) (cid:22) 𝐼

Hence, the converse directions of the rules in Theorem 5.1 do hold for UCT loops with UCT loop-
body. In particular, we can reason about exact weakest (liberal) preweightings of such loops.
Corollary 5.4. If both while ( 𝜑 ) { 𝐶 } and 𝐶 are UCT, then for all 𝑓 ∈ W and all 𝐼 ∈ W,
𝐼 (cid:22) wp

while ( 𝜑 ) { 𝐶 }

( 𝑓 ) , and

implies

J

K

wlp

implies

( 𝑓 ) (cid:22) 𝐼 .

while ( 𝜑 ) { 𝐶 }
J
Let us now look at reasoning about loops in action. For this, we extend our annotation scheme to
loops as shown in Fig. 5a. Again, read the annotations from bottom to top as follows and consider
⊲⊳ as (cid:22) for simplicity:
(1)
(2)
(3) wp

𝑓 We start our reasoning from postweighting 𝑓 ∈ W.
((
𝐼 We choose (creatively) an invariant 𝐼 which we are going to push through the loop body.
𝐼 ′ This annotation is obtained (uncreatively) from applying wp
88
), just as in Fig. 4.
((
The program passed into wp is the loop body 𝐶 and the continuation is the invariant 𝐼 . Hence,
this annotation states 𝐼 ′ = wp
( 𝐼 ) and by that we have pushed 𝐼 through the loop body.

K

J

K

(

𝐶
J

K

20

Batz, Gallus, Kaminski, Katoen, and Winkler

(4) (cid:22)
(5) Φ
((
((

(6) (cid:22)

((

𝐼 ′′ This annotation states that 𝐼 ′ (cid:22) 𝐼 ′′, i.e. 𝐼 ′′ overapproximates 𝐼 ′, just as in Fig. 4.
𝑔 This annotation 𝑔 is obtained from 𝐼 ′′ — the result of pushing the invariant 𝐼 through the
loop body (and possibly overapproximating the result) — by constructing 𝑔 = [¬𝜑] 𝑓 ⊕ [𝜑] 𝐼 ′′.
This annotation states that 𝑔 (cid:23) Φ𝑓 (𝐼 ).
𝐼 This annotation states that 𝑔 (cid:22) 𝐼 , just as in Fig. 4. Since Φ𝑓 (𝐼 ) (cid:22) 𝑔 (cid:22) 𝐼 , this ﬁnal
( 𝑓 ) (cid:22) 𝐼 and we could continue reasoning
annotation states by Theorem 5.1 that wp
loop
with 𝐼 .

K

J

Example 5.5. Consider the arctic semiring A = (N+∞ ∪ { −∞ }, max, +, −∞, 0) and the pro-

gram

𝐶

=

while ( 𝑥 > 0 ∧ 𝑦 > 0 ) {

{ 𝑥 ≔ 𝑥 − 1

𝑦 ≔ 𝑦 + 1 } ⊕ { 𝑦 ≔ 𝑦 − 1 }

⊙ 1

} .

#

#

𝐶 is UCT, witnessed by the ranking function 𝑟 = 3𝑥 + 2𝑦: Both branches of the loop body strictly
decrease the value of 𝑟 . We verify that 𝐼 = [¬𝜑] 0 ⊕ [𝜑] (2(𝑥 − 1) + 𝑦), where 𝜑 = (𝑥 > 0 ∧ 𝑦 > 0),
is a ﬁxed point of Φ0 in Fig. 5b. Hence, by Corollary 5.4, we get wp
( 0 ) = 𝐼 . By Theorem 4.9,
( 0 ) is the maximum weight among all terminating computations paths. In 𝐶, the weight
wp
of a path is the number of times it passes through the loop body. We thus conclude that the number
of 𝐶’s loop iterations is bounded by 2(𝑥 − 1) + 𝑦 if initially 𝑥 > 0 ∧ 𝑦 > 0 holds. This bound is
sharp.

𝐶
J

𝐶
J

K

K

6 CASE STUDIES
6.1 Competitive Analysis of Online Algorithms by Weighted Programming

Field:
Problem:

Competitive Analysis
Ski Rental Problem

Model:
Semiring: Tropical Semiring

Optimization Problem

Techniques: wp

We now demonstrate how to model optimization problems by means of weighted programming and
how to reason about competitive ratios of online algorithms [Borodin and El-Yaniv 1998; Fiat and
Woeginger 1998] on source code level by means of our wp calculus with the aid of invariants. In
particular, we model both the optimal solution to the Ski Rental Problem itself as well as the opti-
mal deterministic online algorithm for the problem as weighted programs. We argue that weighted
programming provides a natural formalism for reasoning about the competitive ratio of online
algorithms since weighted programs enable the succinct integration of cost models.

6.1.1 Online Algorithms and Competitive Analysis. Online algorithms perform their computation
without knowing the entire input a priori. Rather, parts of the input are revealed to the online
algorithm during the course of the computation. We consider here the well-known Ski Rental
Problem [Komm 2016]: Suppose we go an a ski trip for an a priori unknown number of 𝑛 ≥ 1 days
and we do not own a pair of skis. At the beginning of each day, we must choose between either
renting skis for exactly one day (cost: 1 Euro) or to buy a pair of skis (cost: 𝑦 euros).

The optimization goal is to minimize the total cost for the whole trip. If we knew the duration 𝑛 of
the trip a priori, the optimal solution would be rather obvious: If 𝑛 ≥ 𝑦, we buy the skis. Otherwise,
we are cheaper oﬀ renting every day. This situation would correspond to an oﬄine setting, with
both 𝑛 and 𝑦 at hand, allowing for an optimal solution. Conversely, if the trip duration 𝑛 is unkown
and only the cost 𝑦 of the skis is known, we are in an online setting of the Ski Rental Problem.

Lacking knowledge about the entire input a priori often comes at the cost of non-optimality: An
online algorithm typically performs worse than the optimal oﬄine algorithm. Competitive analy-
sis [Borodin and El-Yaniv 1998] is a technique for measuring the degree of optimality of an online

Weighted Programming

21

while ( 𝑛 > 0 ) {
𝑛 ≔ 𝑛 − 1
{ (* rent *)
⊙ 1

#

} ⊕ { (* buy *)

⊙ 𝑦
#𝑛 ≔ 0 (* terminate *)

} }

𝑐 ≔ 𝑐 + 1

#

#

𝑐 ≔ 0
while ( 𝑛 > 0 ) {
𝑛 ≔ 𝑛 − 1
if ( 𝑐 < 𝑦 ) {
⊙ 1
} else {
⊙ 𝑦

#

} }

#

𝑛 ≔ 0

(a) The program 𝐶opt.

(b) The program 𝐶onl.

Fig. 6. The optimal solution to the Ski Rental Problem is modeled by 𝐶opt. The program 𝐶onl implements the
optimal deterministic online algorithm.

algorithm. The central notion is the competitive ratio of an online algorithm. Given a problem in-
stance 𝜌, denote by ONL(𝜌) and OPT(𝜌) the cost of an online algorithm ONL and the cost of its
optimal oﬄine counterpart OPT on 𝜌, respectively. The competitive ratio of ONL is deﬁned as

ONL(𝜌)
OPT(𝜌)

,

sup
𝜌

i.e. the smallest constant upper-bounding the ratio between the cost of ONL and OPT for all prob-
lem instances 𝜌. We determine such competitive ratios by wp-reasoning on weighted programs.

6.1.2 Modeling Infinite-State Online Algorithms as Weighted Programs. Together with wp-reasoning,
weighted programs over the tropical semiring T provide an appealing formalism for the compet-
itive analysis of inﬁnite-state online algorithms since (1) (nondeterministic) programs naturally
describe algorithmic problems- and solutions, and (2) reasoning on source code level enables rea-
soning about inﬁnite-state models. Modeling online algorithms as weighted programs is inspired
by [Aminof et al. 2009, 2010], who employ ﬁnite-state weighted automata for the automated com-
petitive analysis of ﬁnite-state online algorithms. We drop the restriction to ﬁnite-state algorithms
which comes, however, at the cost of full automation of their veriﬁcation.

Consider the nondeterministic weighted program 𝐶opt on the left-hand side of Figure 6 (let us
ignore the annotations for the moment). An initial program state 𝜎 ∈ Σ ﬁxes an instance of the Ski
Rental Problem given by the duration 𝜎 (𝑛) of the trip and the cost 𝜎 (𝑦) of the skis. Every execution
of 𝐶opt on 𝜎 corresponds to one possible solution: Each iteration of the loop corresponds to one day
of the ski trip. As long as the trip did not end (𝑛 > 0), we can either rent the skis (ﬁrst branch) or
buy the skis (second branch). If we buy the skis, there is no further choice to be taken, so the loop
terminates. The cost of each choice is modeled by weighing the respective branches appropriately.
Now recall that in the tropical semiring T we have ⊕ = min, ⊙ = +, 0 = ∞, and 1 = 0. Thus,
the weight of a terminating computation path 𝜋 is the sum of the weights along 𝜋, i.e. the cost of
the solution given by 𝜋. This enables determining the optimal cost for every initial program state
𝜎, i.e. every instance of the Ski Rental Problem, by wp-reasoning (cf. Example 4.11) since
wp q𝐶opty ( 1 ) (𝜎) = “minimum weight of all terminating computation paths starting in 𝜎” .
Program 𝐶onl on the right-hand side in Figure 6 implements the optimal solution for the online
version of the Ski Rental Problem. The decisions made by 𝐶onl must therefore not depend on 𝑛.

22

Batz, Gallus, Kaminski, Katoen, and Winkler

𝐶onl
J

K

Let us compare the programs 𝐶opt and 𝐶onl. Program 𝐶onl is obtained from 𝐶opt by introducing a
counter 𝑐 keeping track of the elapsed time and by replacing the nondeterministic choice in 𝐶opt
by a deterministic one. As long as the current duration of the trip is smaller than the cost of the
skis, we rent the skis. As soon as this duration is at least the cost of the skis, we buy the skis. Since
𝐶onl is deterministic, the cost of 𝐶onl on 𝜎 is given by wp

( 1 ) (𝜎).

6.1.3 Determining Competitive Ratios by wp-Reasoning. Due to the above reasoning,

.

sup
𝜎 ∈Σ

𝐶onl
J

( 1 ) (𝜎)
wp
K
wp q𝐶opty ( 1 ) (𝜎)
is the competitive ratio of 𝐶onl. Hence, we obtain the competitive ratio of 𝐶onl by determining
wp q𝐶opty ( 1 ) and wp

𝐶onl
J
Theorem 6.1. We have
wp q𝐶opty ( 1 ) = 𝑛 ⊕ 𝑦 , and wp
Proof. Since both 𝐶opt and 𝐶onl are UCT (witnessed by the ranking function 𝑛), it suﬃces to
show that the above weightings are ﬁxed points of the respective characteristic functional by
(cid:3)
Corollary 5.4. We proceed by annotating the programs. See Appendix E.1 for details.

( 1 ). This can be done in an invariant-based manner:

( 1 ) = [𝑛 = 0] 0 ⊕ [0 < 𝑦]

(2𝑦 − 1) ⊕ [𝑛 ≤ 𝑦 − 1] 𝑛

𝐶onl
J

K

K

(cid:0)

(cid:1)

.

𝐶onl
J

The fact that wp q𝐶opty ( 1 ) = 𝑛 ⊕ 𝑦 = 𝜆𝜎. 𝜎 (𝑛) min 𝜎 (𝑦) corresponds to our informal description
from the beginning of this section: Depending on whether the duration of the trip 𝑛 exceeds the
cost 𝑦 of the skis, it is optimal to either immediately buy the skis or to keep renting them every
( 1 ) of 𝐶onl is more involved. If 𝑛 = 0, the cost of 𝐶onl is 0. Otherwise, i.e.
day. The cost wp
if the trip lasts for at least one day, there are two cases. If 𝑛 is strictly smaller than 𝑦, then the cost
of 𝐶onl is the minimum of 2𝑦 − 1 and 𝑛. Otherwise, i.e. if 𝑛 is at least 𝑦, the cost of 𝐶onl is 2𝑦 − 1.

We can now determine the competitive ratio of 𝐶onl. Let, for simplicity, both 𝑛 > 0 and 𝑦 > 0
so that 𝑛 ⊕ 𝑦 > 0. This assumption is reasonable since the problem becomes trivial if the trip ends
= 𝜆𝜎. 𝑓 (𝜎)
immediately or the skis are gratis. Given two weightings 𝑓 , 𝑔 with 𝑔 > 0, we deﬁne 𝑓
𝑔 (𝜎) .
𝑔
We conclude that the competitive ratio of 𝐶onl is 2 since 2 is the smallest constant upper bounding

K

( 1 )
wp
𝐶onl
J
wp q𝐶opty ( 1 )

K

=

(2𝑦 − 1) ⊕ [𝑛 ≤ 𝑦 − 1] 𝑛
𝑛 ⊕ 𝑦

= [𝑛 ≥ 𝑦]

2 −

(cid:0)

1
𝑦

(cid:1)

⊕ [𝑛 < 𝑦] 1 .

6.2 Mutual Exclusion

Field:
Problem: Mutual Exclusion

Formal Veriﬁcation

Model:
Module: 𝜔-potent Formal Languages

Computation Traces

Techniques: wlp

In this case study, we instantiate weighted programming with the module of 𝜔-potent formal
languages to reason about inﬁnite behaviors of a semaphore-based mutual exclusion algorithm.
This is done in an invariant-based manner enabled by wlp-reasoning.

6.2.1 A Mutual Exclusion Protocol. Consider the program 𝐶mut shown in Fig. 7a and disregard
the weightings for the moment. Program 𝐶mut models 𝑁 processes participating in a semaphore-
based mutual exclusion protocol. On each iteration of the non-terminating while loop, a scheduler
selects one of the 𝑁 processes. The status ℓ [𝑖] of the selected process 𝑖 is either idle (𝑛), waiting
(𝑤), or critical (𝑐). If the process 𝑖 idles, it enters the waiting state. If the process 𝑖 is waiting,
it checks whether the binary semaphore (modeled by the shared variable 𝑦) allows to enter the
critical section (𝑦 > 0) and, if so, enters the critical section. Otherwise, i.e. if 𝑦 = 0, the process

Weighted Programming

23

must continue waiting. Finally, if the process 𝑖 is in the critical section, it releases the critical section
and updates the semaphore appropriately.

It can be shown by standard means that the protocol modeled by 𝐶mut indeed ensures mutual
exclusion. That is, whenever we start in a state where at most one process is in the critical section
and 𝑦 = 0, it will never be the case that more than one process is in the critical section. However,
the protocol exhibits unfair behavior. Suppose the semaphore forbids some waiting process 𝑘 to
enter the critical section, i.e. 𝑦 = 0 and ℓ [𝑘] = 𝑤. It is then possible that the scheduler behaves in
an adversarial manner such that process 𝑘 is going to starve, i.e. wait forever.

6.2.2 Reasoning about Infinite Behavior by wlp-Reasoning. We prove that the protocol exhibits un-
fair behavior by weighted programming and wlp-reasoning. To that end, we instantiate our frame-
work with the Γ∗-module12 L∞

Γ of 𝜔-potent formal languages over Γ (cf. Example 4.17), where

Γ =

{𝑅 𝑗 ,𝑊𝑗, 𝐶 𝑗 } .

Ø𝑗 ∈N\{0}

Recall that our module addition ⊕ is union ∪, the monoid and scalar-multiplications are concate-
nations and the zero element is 0 = ∅. Intuitively, (ﬁnite or inﬁnite) behaviors of 𝐶mut correspond
to (ﬁnite or inﬁnite) words over Γ. For instance, the 𝜔-word 𝐶1𝑊 𝜔
2 indicates that process 1 enters
the critical section and that subsequently process 2 waits forever. This is realized by weighing the
branches of the loop body in 𝐶mut appropriately: If the process 𝑖 enters the critical section, waits, or
releases the critical section, we weight the corresponding branch by 𝐶𝑖, 𝑊𝑖, or 𝑅𝑖, respectively. This
is similar to labeling the states of a transition system by atomic propositions to express properties
of the system in, e.g. LTL [Baier and Katoen 2008]. Notice, however, that the transition system
underlying 𝐶mut is inﬁnite so that standard ﬁnite-state model checking techniques do not apply.
Now recall from Example 4.17 that the language of 𝜔-words produced by the loop in 𝐶mut on initial
( 0 ) (𝜎). Since the natural ordering (cid:22) on L∞
Γ is ⊆, verifying that 𝐶mut indeed
state 𝜎 is wlp
exhibits the described unfair behavior boils down to proving that
𝑘 (cid:22) wlp

K
[1 ≤ 𝑘 ≤ 𝑁 ∧ ℓ [𝑘] = 𝑤 ∧ 𝑦 = 0] 𝑊 𝜔

𝐶mut
J

( 0 ) ,

i.e. we are obliged to prove a lower bound on the weakest liberal preweighting of 𝐶mut w.r.t. (ir-
relevant) postweighting 0, which is done in an invariant-based manner Appendix E.2. The above
property indeed states that 𝐶mut exhibits unfair behavior: Whenever some process 𝑘 is waiting
and the semaphore forbids entering the critical section (𝑦 = 0), the behavior 𝑊 𝜔
𝑘 is possible, i.e.
process 𝑘 might wait forever.

𝐶mut
J

K

6.3 Proving a Combinatorial Identity by Program Analysis

Field:
Problem: Counting bit patterns

Combinatorics

Model:
Semiring: Natural numbers

Combinatorial class

Techniques: wp

We instantiate our framework with the semiring (N+∞, +, ·, 0, 1) to count the number of com-
putation paths in our programs. If a program 𝐶 does not contain weight-statements, it follows
from Theorem 4.9 that the number of terminating computation paths starting in 𝜎 is given by
( 1 ) (𝜎). More generally, given a predicate 𝜑 over the program variables, the number of
wp
( [𝜑] 1 ) (𝜎). Thus,
paths terminating in a state satisfying 𝜑 on initial state 𝜎 is given by wp
counting computation paths reduces to weakest preweighting-reasoning as illustrated in the fol-
lowing example.

𝐶
J

𝐶
J

K

K

12This is the only example in this section where we do not pursue the default method of specifying both the monoid W
and the module M at once by means of a single semiring S.

24

while ( true ) {

𝑁

{ 𝑖 ≔ 𝑗 }

#

Ê𝑗=1
if ( ℓ [𝑖] = 𝑛 ) {
ℓ [𝑖] ≔ 𝑤

} else if ( ℓ [𝑖] = 𝑤 ) {
if ( 𝑦 > 0 ) { ⊙ 𝐶𝑖
else {⊙ 𝑊𝑖 }
} else if ( ℓ [𝑖] = 𝑐 ) {

#

𝑦 ≔ 𝑦 − 1

ℓ [𝑖] ≔ 𝑐 }

#

⊙ 𝑅𝑖

𝑦 ≔ 𝑦 + 1

ℓ [𝑖] ≔ 𝑛

#

#

}

}

(a) The program 𝐶mut.

Batz, Gallus, Kaminski, Katoen, and Winkler

𝑐 ≔ 0

𝑚 ≔ 0
#
#
while ( 𝑛 > 0 ) {
𝑛 ≔ 𝑛 − 1

// 𝑟𝑒𝑠 ≔ []

#

{

𝑐 ≔ 0 // append ( 𝑟𝑒𝑠, 0 )

#

} ⊕ {

#

𝑐 ≔ 𝑐 + 1
𝑚 ≔ max(𝑚, 𝑐)

#

// append ( 𝑟𝑒𝑠, 1 )

#

}

}

(b) The program 𝐶count.

Fig. 7. The program 𝐶mut is a mutual exclusion protocol adapted from [Baier and Katoen 2008]. The program
𝐶count generates 𝑛-bit strings and stores the maximum number of consecutive 1’s in 𝑚.

Suppose we were to count the number of bit strings of length 𝑛 that avoid the pattern “11”.
Program 𝐶count in Fig. 7b non-deterministically “constructs” bit strings of length equal to the (input)
variable 𝑛 and simultaneously keeps track of the maximum amount of consecutive 1’s that have
occurred in variable 𝑚. Since we are interested in counting strings not containing “11”, we have
( [𝑚 ≤ 1] 1 ). To handle the loop in 𝐶count, we employ the loop invariant
to determine wp

𝐶count
J
𝐼 ≔ [𝑚 ≤ 1] ( [𝑐 = 0] Fib(𝑛 + 2) ⊕ [𝑐 > 0] Fib(𝑛 + 1))

K

and verify that 𝐼 is indeed a ﬁxed point of the wp-characteristic functional of the loop Appendix E.3.
Here, Fib(𝑛) is the 𝑛-th Fibonacci number deﬁned recursively via Fib(0) ≔ 0, Fib(1) ≔ 1, and for
all 𝑛 ≥ 2, Fib(𝑛) ≔ Fib(𝑛 − 1) + Fib(𝑛 − 2). Since 𝐶count is obviously certainly terminating and 𝐼 is
a ﬁxed point of the wp-characteristic function of the loop w.r.t. postweighting [𝑚 ≤ 1] 1, we have

wp

𝐶count
J

K

( [𝑚 ≤ 1] 1 )

=

𝐼 [𝑐/0] [𝑚/0]

=

Fib(𝑛 + 2) ,

by Theorem 5.3, i.e. the number of “11”-avoiding bit strings of length 𝑛 is equal to Fib(𝑛 + 2).

7 RELATED WORK

We organize related works in three categories: (1) Other generalized predicate transformers, (2) semir-
ing programming paradigms, (3) other approaches to modelling optimization problems.

7.1 Generalized Predicate Transformers and Hoare Logics

A well-known concrete instance of generalized, quantitative predicates are potential functions
Φ : Σ → R≥0. Such functions are used in amortized complexity analysis [Tarjan 1985] can be re-
garded an instance of the weightings introduced in this paper. Carbonneaux [2018]; Carbonneaux
et al. [2015] present a resource bound veriﬁcation system for a subset of C programs based on po-
tential functions. A non-trivial subset of their veriﬁcation rules can be recovered by instantiating
our framework with the tropical semiring, and interpreting their resource consumption statement

Weighted Programming

25

tick(n) as our weight primitive ⊙ 𝑛. More speciﬁcally, Carbonneaux et al. [2015] deﬁne a quan-
titative Hoare triple { Φ } 𝑃 { Φ′ }, where Φ, Φ′ are potential functions, and 𝑃 is a (deterministic)
program. Such a triple is valid iﬀ for all initial states 𝜎 ∈ Σ such that 𝑃 terminates in a ﬁnal state 𝜎 ′
it holds that Φ(𝜎) ≥ 𝑛 + Φ′(𝜎 ′), where 𝑛 is the resource consumption of 𝑃 started on 𝜎. It follows
( Φ′ ) is the least poten-
that { wp
tial 𝑋 that validates the triple { 𝑋 } 𝑃 { Φ′ }. While the programming language from [Carbonneaux
et al. 2015] has advanced features such as procedures and recursion, it lacks a non-deterministic
choice as present in wGCL. A promising direction for future work is to investigate whether the
automatic inference algorithm of Carbonneaux et al. [2015] can be extended to non-deterministic
programs.

( Φ′ ) } 𝑃 { Φ′ } is always a valid triple; furthermore, wp

𝑃
J

𝑃
J

K

K

Very recent works have studied predicate transformers and Hoare-style logics from an abstract
categorical perspective. A generic approach to deﬁne predicate transformers, like our wp and wlp,
is given by Aguirre and Katsumata [2020], but only for loop-free programs. On the loop-free frag-
ment of wGCL, our weakest preweighting transformer wp is an instance of their framework. They
capture the computational side eﬀects, like our weightings, in a monad. More precisely, our trans-
former is obtained from the composed monad MSet (Writer w -) of a multiset monad MSet
- that distributes over a writer monad Writer w -. This speciﬁc instance, however, is not dis-
cussed explicitly by Aguirre and Katsumata [2020]. The writer monad corresponds to our weight-
ing monoid W, whereas the multiset monad captures the branching construct { 𝐶1 } ⊕ { 𝐶2 } that
we treat via W-modules. In contrast to their work, our wp is deﬁned for loops. Moreover, we
introduce two transformers, wp for ﬁnite computations and wlp that additionally accounts for in-
ﬁnite computations. Finally, the correspondence to an operational semantics is not established in
[Aguirre and Katsumata 2020]. An interesting direction for future work is to explicitly construct
a strongest postcondition transformer for weighted programming, which Aguirre and Katsumata
[2020] deﬁne non-constructively as an adjoint to wp. Problems with deﬁning strongest postexpec-
tations for probabilistic programs, see [Jones 1990], demonstrate that giving a concrete strongest
post semantics is far less easy, even if it can be deﬁned abstractly as an adjoint.

In a similar spirit, Gaboardi et al. [2021] introduce the notion of graded categories to unify
graded monadic and graded comonadic eﬀects. The gradings are over partially ordered monoids
(pomonoids) and can, for example, model probabilities or resources like our weightings. In the set-
ting of imperative languages, they consider it “natural to have just the multiplicative structure of
the semiring as a pomonoid” [Gaboardi et al. 2021, Sec. 6] because their programs only have one
input and output. The additive structure of semiring gradings has been used to join multiple inputs
for resource consumption in the 𝜆-calculus with comonadic contexts [Brunel et al. 2014; Ghica and
Smith 2014; Petricek et al. 2014]. In contrast, we use addition to join multiple outputs in monadic
computations, e. g. branching in our examples (Fig. 6 and Fig. 7). Hence, it might be interesting fu-
ture work to extend their categorical semantics with branching. They go on to construct a Graded
( [𝜓 ] 1 ) given
Hoare Logic (GHL) with judgments ⊢𝑤 {𝜙 } 𝐶 {𝜓 } corresponding to [𝜙] 𝑤 (cid:22) wp
(Boolean) pre- and postconditions 𝜙,𝜓 , program 𝐶, and a weight 𝑤 from a semiring. Although un-
bounded loops have been studied in concrete instances, they restrict to bounded loops in the general
setting: “This allows us to focus on the grading structures for total functions, leaving the study
of the interaction between grading and partiality to future work.” [Gaboardi et al. 2021, Sec. 2].
Our work does not impose such restrictions. Both of our veriﬁcation calculi wp and wlp deal with
possibly unbounded loops.

𝐶
J

K

Swierstra and Baanen [2019] handle eﬀects by monads, focussing on functional rather than
imperative programming. They show how to synthesize programs from speciﬁcations using general
results on predicate transformers. Combining these synthesis techniques with the above monad

26

Batz, Gallus, Kaminski, Katoen, and Winkler

instance of [Aguirre and Katsumata 2020] for the synthesis of weighted programs is an interesting
direction for future work.

7.2 Computing with Semirings
There exist a number of computation and programming paradigms in the literature that — similarly
to our approach — are parameterized by a semiring. O’Conner [2012] and Dolan [2013] show
that computational problems such as shortest paths, deriving the regular expression of a ﬁnite
automaton, dataﬂow analysis, and others can be reduced to linear algebra over a suitable semiring.
They also provide concise Haskell implementations solving the resulting matrix problems in a
uniﬁed way. The heart of these techniques is to compute the so-called star or closure 𝑥 ∗ = 1 +
𝑥 + 𝑥 2 + . . . where 𝑥 is a matrix over the semiring. The same 𝑥 ∗ is also the least solution of the
equation 𝑥 ∗ = 1+𝑥 ·𝑥 ∗. This ﬁxed point equation is closely related to the lfp occurring in our wp. In
fact, it can be interpreted as an automata-theoretic explicit-state analog to our wp. Our framework,
however, extends this to inﬁnite state spaces and allows reasoning in a symbolic fashion. The above
techniques, on the other hand, would require an inﬁnite transition matrix 𝑥, and are therefore
limited to ﬁnite-state problems, e. g. shortest paths in ﬁnite graphs.

Functional and declarative approaches for programming with semirings have also been explored.
Laird et al. [2013] and Brunel et al. [2014] consider functional languages parameterized by a semir-
ing and provide a categorical semantics. Their languages feature weighting computation steps
similar to our language. Additionally, Brunel et al. [2014] provide static analysis techniques to
obtain upper bounds on the weight of a computation. Indeed, with an appropriate semiring, the
semantics deﬁned in these works also allows reasoning about e. g. best/worst-case resource con-
sumption, reachability probabilities, or expected values. In contrast to [Brunel et al. 2014; Laird
et al. 2013], our programming language is imperative and our semantics generalizes weakest pre-
conditions. Moreoever, while Laird et al. [2013] exemplify how their framework can be used to
detect inﬁnite reduction sequences, it does not provide a general way to assign a weight to diverg-
ing computation paths as our wlp does. Brunel et al. [2014] do not deal with inﬁnite computations.
Belle and De Raedt [2020] pursue a declarative approach by computing the weighted model count
of logical formulae in some theory where the literals are weighted in a semiring. Applications in-
clude matrix factorization, computing polyhedral volumes, or probabilistic inference. Furthermore,
Balkir et al. [2020]; Cohen et al. [2008] study weighted logic programs with a focus on parsers. This
declarative paradigm is, however, rather diﬀerent from our weighted programs which allow spec-
ifying models in an algorithmic, imperative manner.

Kleene Algebras with Tests (KAT) [Kozen 1999, 2000] can model imperative programs in an
abstract fashion by identifying them with the objects from a Kleene algebra with an embedded
Boolean subalgebra. An important application of KAT is equational reasoning; and hence to e. g.
derive the rules of Hoare logic by applying algebraic manipulations. Note that a Kleene algebra is
itself an idempotent semiring whose purpose, however, is not to model weights of any kind but
the programs themselves. Nonetheless, to reason about weighted computations similar to us, KAT
was recently generalized to Graded KAT [Gomes et al. 2019] by replacing the Boolean subalgebra
with a more general object that can be viewed as a semiring with additional operations and axioms.
The elements of this semiring constitute the graded (or weighted) outcomes of the tests. However,
(Graded) KAT are no concrete programming languages; their main purpose is to prove general
results about imperative languages with loops and conditionals in an abstract fashion. Indeed,
investigating which of our wp (wlp) and invariant-based proof rules can be derived in Graded
KAT is an appealing direction for future work.

Weighted Programming

27

7.3 Optimization
There exists a large amount of work on modelling and solving optimization problems. A prominent
example is constrained optimization (e. g. linear programming [Horen 1985; Schrijver 1999]) for
which standardized- and domain-speciﬁc languages exist [Lofberg 2004; Nethercote et al. 2007].
Modelling and solving optimization problems with weighted programming diﬀers mainly in two
aspects from these techniques. (1) The way how optimization problems are modelled and (2) what
is modelled and for what purpose. Regarding aspect (1), techniques like integer linear program-
ming or languages like MiniZinc model optimization problems in a constraint-based manner. With
weighted programs, we describe these problems instead in an algorithmic fashion. As an intuition,
constrained optimization vs. weighted programming could be considered analogous to logic pro-
gramming vs. imperative programming.

Regarding aspect (2), constraint-based techniques often model one particular problem instance
for which an optimal solution is computed. Weighted programs, on the other hand, provide a means
to model and reason about every (out of possibly inﬁnitely many) problem instance at once. This
comes, however, at the cost of computability. The case study on the ski rental problem exempliﬁes
this: We verify the competitive ratio of the optimal online algorithm for every trip duration of the
ski rental problem. Automating this veriﬁcation process is an appealing direction for future work.
More closely related is the work by Bistarelli et al. [1997], who generalize Constraint Logic
Programming (CLP) by parameterizing CLP with a semiring 𝑆. Elements and operations of 𝑆 take
over the role Boolean constants and connectives. This allows to, e. g. solve optimization problems
by ﬁnding atom instantiations of minimal cost.

8 CONCLUSION
We have studied weighted programming as a programming paradigm for specifying mathematical
models. We developed a weakest (liberal) precondition-style veriﬁcation framework for reasoning
about both ﬁnite and inﬁnite computations of weighted programs and demonstrated the eﬃcacy of
our framework on several case studies. Future work includes automated reasoning about weighted
programs using, e.g., generalizations of 𝑘-induction [Batz et al. 2021; Sheeran et al. 2000] and
weighted program synthesis [Alur et al. 2015; Manna and Waldinger 1980]. Further directions are
weighted separation logics [Batz et al. 2019a; Ishtiaq and O’Hearn 2001; Reynolds 2002] as well
as to investigate “sampling” algorithms for weighted programs. For instance, what would be an
analogon to MCMC sampling in a weighted setting?

ACKNOWLEDGMENTS
This work was supported by the ERC AdG Frappant (787914) (https://cordis.europa.eu/project/id/787914)
and RTG 2236 UnRAVeL (https://gepris.dfg.de/gepris/projekt/282652900) funded by the German
Research Foundation. Part of this work was carried out at Schloss Dagstuhl – Leibniz Center for
Informatics. We thank Lena Verscht and Linpeng Zhang for the fruitful discussions at Schloss
Dagstuhl.

REFERENCES
Samson Abramsky. 1994. Handbook of Logic in Computer Science. Vol. 3. Clarendon Press, Chapter Domain Theory.

http://www.cs.bham.ac.uk/~axj/papers.html

Alejandro Aguirre and Shin-ya Katsumata. 2020. Weakest Preconditions in Fibrations. In MFPS (Electronic Notes in Theo-

retical Computer Science, Vol. 352). Elsevier, 5–27. https://doi.org/10.1016/j.entcs.2020.09.002

Rajeev Alur, Rastislav Bodík, Eric Dallal, Dana Fisman, Pranav Garg, Garvit Juniwal, Hadas Kress-Gazit, P. Madhusudan,
Milo M. K. Martin, Mukund Raghothaman, Shambwaditya Saha, Sanjit A. Seshia, Rishabh Singh, Armando Solar-Lezama,
In Dependable Software Systems Engineering.
Emina Torlak, and Abhishek Udupa. 2015. Syntax-Guided Synthesis.

28

Batz, Gallus, Kaminski, Katoen, and Winkler

NATO Science for Peace and Security Series, D: Information and Communication Security, Vol. 40. IOS Press, 1–25.
https://doi.org/10.3233/978-1-61499-495-4-1

Benjamin Aminof, Orna Kupferman, and Robby Lampert. 2009. Reasoning About Online Algorithms with Weighted Au-

tomata. In SODA. SIAM, 835–844. https://doi.org/10.1137/1.9781611973068.91

Benjamin Aminof, Orna Kupferman, and Robby Lampert. 2010. Reasoning about Online algorithms with Weighted Au-

tomata. ACM Trans. Algorithms 6, 2 (2010), 28:1–28:36. https://doi.org/10.1145/1721837.1721844

Ralph-Johan Back and Joakim von Wright. 1998.

Reﬁnement Calculus - A Systematic Introduction.

Springer.

https://doi.org/10.1007/978-1-4612-1674-2

Marc Bagnol. 2014. On the Resolution Semiring. (Sur le Semi-anneau de Résolution). Ph. D. Dissertation. Aix-Marseille

University, Aix-en-Provence, France.

Christel Baier and Joost-Pieter Katoen. 2008. Principles of Model Checking. MIT Press.
Esma Balkir, Daniel Gildea, and Shay B. Cohen. 2020. Tensors over Semirings for Latent-Variable Weighted Logic Programs.

In IWPT 2020. Association for Computational Linguistics, 73–90. https://doi.org/10.18653/v1/2020.iwpt-1.8

Kevin Batz, Mingshuai Chen, Benjamin Lucien Kaminski, Joost-Pieter Katoen, Christoph Matheja, and Philipp Schröer.
2021. Latticed k-Induction with an Application to Probabilistic Programs. In CAV (2) (Lecture Notes in Computer Science,
Vol. 12760). Springer, 524–549. https://doi.org/10.1007/978-3-030-81688-9_25

Kevin Batz, Benjamin Lucien Kaminski, Joost-Pieter Katoen, Christoph Matheja, and Thomas Noll. 2019a. Quantitative
separation logic: a logic for reasoning about probabilistic pointer programs. Proc. ACM Program. Lang. 3, POPL (2019),
34:1–34:29. https://doi.org/10.1145/3290347

Kevin Batz, Benjamin Lucien Kaminski, Joost-Pieter Katoen, Christoph Matheja, and Thomas Noll. 2019b. Quantitative
Separation Logic: A Logic for Reasoning about Probabilistic Pointer Programs. Proc. ACM Program. Lang. 3, POPL
(2019), 34:1–34:29. https://doi.org/10.1145/3290347

Vaishak Belle and Luc De Raedt. 2020. Semiring Programming: A Semantic Framework for Generalized Sum Product

problems. Int. J. Approx. Reason. 126 (2020), 181–201. https://doi.org/10.1016/j.ijar.2020.08.001

Stefano Bistarelli, Ugo Montanari, and Francesca Rossi. 1997. Semiring-based Constraint Logic Programming. In IJCAI (1).

Morgan Kaufmann, 352–357.

Allan Borodin and Ran El-Yaniv. 1998. Online Computation and Competitive Analysis. Cambridge University Press.
Aloïs Brunel, Marco Gaboardi, Damiano Mazza, and Steve Zdancewic. 2014. A Core Quantitative Coeﬀect Calculus. In
ESOP (Lecture Notes in Computer Science, Vol. 8410). Springer, 351–370. https://doi.org/10.1007/978-3-642-54833-8_19

Quentin Carbonneaux. 2018. Modular and certiﬁed resource-bound analyses. Ph. D. Dissertation. Yale University.
Quentin Carbonneaux, Jan Hoﬀmann, and Zhong Shao. 2015. Compositional certiﬁed resource bounds. In Proceedings of
the 36th ACM SIGPLAN Conference on Programming Language Design and Implementation, Portland, OR, USA, June 15-17,
2015, David Grove and Stephen M. Blackburn (Eds.). ACM, 467–478. https://doi.org/10.1145/2737924.2737955

Shay B. Cohen, Robert J. Simmons, and Noah A. Smith. 2008.

Dynamic Programming Algorithms as Prod-
ucts of Weighted Logic Programs. In ICLP (Lecture Notes in Computer Science, Vol. 5366). Springer, 114–129.
https://doi.org/10.1007/978-3-540-89982-2_18

Katrin M. Dannert, Erich Grädel, Matthias Naaf, and Val Tannen. 2019. Generalized Absorptive Polynomials and Prove-

nance Semantics for Fixed-Point Logic. CoRR abs/1910.07910 (2019). https://doi.org/10.48550/arXiv.1910.07910

Edsger Wybe Dijkstra. 1975. Guarded Commands, Nondeterminacy and Formal Derivation of Programs. CACM 18, 8

(1975), 453–457. https://doi.org/10.1145/360933.360975

Stephen Dolan. 2013. Fun with Semirings: A Functional Pearl on the Abuse of Linear Algebra. In ICFP. ACM, 101–110.

https://doi.org/10.1145/2500365.2500613

Manfred Droste, Werner Kuich, and Heiko Vogler. 2009. Handbook of Weighted Automata (1st ed.). Springer Publishing

Company, Incorporated. https://doi.org/10.1007/978-3-642-01492-5

Zoltán Ésik. 2008.

Iteration Semirings. In Developments in Language Theory, Masami Ito and Masafumi Toyama (Eds.).

Springer Berlin Heidelberg, Berlin, Heidelberg, 1–20. https://doi.org/10.1007/978-3-540-85780-8_1

Amos Fiat and Gerhard J. Woeginger (Eds.). 1998. Online Algorithms, The State of the Art. Lecture Notes in Computer
Science, Vol. 1442. Springer. https://doi.org/10.1007/BFb0029561 the book grow out of a Dagstuhl Seminar, June 1996.
Marco Gaboardi, Shin-ya Katsumata, Dominic Orchard, and Tetsuya Sato. 2021. Graded Hoare Logic and its Categorical
Semantics. In Programming Languages and Systems - 30th European Symposium on Programming, ESOP 2021, Held as Part
of the European Joint Conferences on Theory and Practice of Software, ETAPS 2021, Luxembourg City, Luxembourg, March
27 - April 1, 2021, Proceedings (Lecture Notes in Computer Science, Vol. 12648), Nobuko Yoshida (Ed.). Springer, 234–263.
https://doi.org/10.1007/978-3-030-72019-3_9

Martin Gavalec, Zuzana Nemcova, and Sergei Sergeev. 2015. Tropical linear algebra with the Łukasiewicz T-norm. Fuzzy

Sets Syst. 276 (2015), 131–148. https://doi.org/10.1016/j.fss.2014.11.008

Brunella Gerla. 2003. Many-valued logic and semirings. Neural Network World 13 (01 2003).

Weighted Programming

29

Dan R. Ghica and Alex I. Smith. 2014. Bounded Linear Types in a Resource Semiring. In Programming Languages and
Systems - 23rd European Symposium on Programming, ESOP 2014, Held as Part of the European Joint Conferences on
Theory and Practice of Software, ETAPS 2014, Grenoble, France, April 5-13, 2014, Proceedings (Lecture Notes in Computer
Science, Vol. 8410), Zhong Shao (Ed.). Springer, 331–350. https://doi.org/10.1007/978-3-642-54833-8_18

J. Golan.

2003.

Semirings

and Aﬃne

Equations

over

Them:

Theory

and Applications.

https://doi.org/10.1007/978-94-017-0383-3

Martin Goldstern. 2002. Completion of Semirings. (2002). https://doi.org/10.48550/arXiv.math/0208134
Leandro Gomes, Alexandre Madeira, and Luís Soares Barbosa. 2019. Generalising KAT to Verify Weighted Computations.

Sci. Ann. Comput. Sci. 29, 2 (2019), 141–184. https://doi.org/10.7561/sacs.2019.2.141

Andrew D. Gordon, Thomas A. Henzinger, Aditya V. Nori, and Sriram K. Rajamani. 2014. Probabilistic Programming. In

FOSE. ACM, 167–181. https://doi.org/10.1145/2593882.2593900

Wataru Hino, Hiroki Kobayashi, Ichiro Hasuo, and Bart Jacobs. 2016. Healthiness from Duality. In LICS. ACM, 682–691.

https://doi.org/10.1145/2933575.2935319

C. A. R. Hoare. 1978.

Some Properties of Predicate Transformers.

J. ACM 25, 3 (1978), 461–480.

https://doi.org/10.1007/978-1-4612-3228-5_6

Jeﬀ Horen. 1985. Linear Programming. Networks 15, 2 (1985), 273–274. https://doi.org/10.1002/net.3230150211
Samin S. Ishtiaq and Peter W. O’Hearn. 2001. BI as an Assertion Language for Mutable Data Structures. In POPL. ACM,

14–26. https://doi.org/10.1145/360204.375719

Claire Jones. 1990. Probabilistic Non-Determinism. Ph. D. Dissertation. University of Edinburgh, UK.
Benjamin Lucien Kaminski. 2019. Advanced Weakest Precondition Calculi for Probabilistic Programs. Ph. D. Dissertation.

RWTH Aachen University, Germany. https://doi.org/10.18154/RWTH-2019-01829

Georg Karner. 1992.

On Limits

in Complete Semirings.

Semigroup forum 45, 2 (1992), 148–165.

https://doi.org/10.1007/bf03025757

Georg Karner. 2004.

Continuous Monoids and Semirings.

Theor. Comput. Sci. 318, 3 (2004), 355–372.

https://doi.org/10.1016/j.tcs.2004.01.020

Klaus Keimel. 2015. Healthiness Conditions for Predicate Transformers. In MFPS (Electronic Notes in Theoretical Computer

Science, Vol. 319). Elsevier, 255–270. https://doi.org/10.1016/j.entcs.2015.12.016

Dennis Komm. 2016.

An Introduction to Online Computation - Determinism, Randomization, Advice.

Springer.

https://doi.org/10.1007/978-3-319-42749-2

Dexter Kozen.

1985.

A Probabilistic

PDL.

J. Comput.

Syst.

Sci.

30,

2

(1985),

162–178.

https://doi.org/10.1016/0022-0000(85)90012-1

Dexter Kozen. 1999. On Hoare Logic and Kleene Algebra with Tests. In LICS. IEEE Computer Society, 167–172.

https://doi.org/10.1109/lics.1999.782610

Dexter Kozen. 2000. On Hoare Logic and Kleene Algebra with Tests. ACM Trans. Comput. Log. 1, 1 (2000), 60–76.

https://doi.org/10.1145/343369.343378

Werner Kuich. 1991. Automata and Languages Generalized to 𝜔-Continuous Semirings. Theor. Comput. Sci. 79, 1 (1991),

137–150. https://doi.org/10.1016/0304-3975(91)90147-t

Jim Laird, Giulio Manzonetto, Guy McCusker, and Michele Pagani. 2013. Weighted Relational Models of Typed Lambda-

Calculi. In LICS. IEEE Computer Society, 301–310. https://doi.org/10.1109/lics.2013.36

Johan Lofberg. 2004. YALMIP: A Toolbox for Modeling and Optimization in MATLAB. 2004 IEEE International Conference
on Robotics and Automation (IEEE Cat. No.04CH37508) (2004), 284–289. https://doi.org/10.1109/cacsd.2004.1393890
Zohar Manna and Richard J. Waldinger. 1980. A Deductive Approach to Program Synthesis. ACM Trans. Program. Lang.

Syst. 2, 1 (1980), 90–121. https://doi.org/10.1145/357084.357090

Matilde Marcolli and Ryan Thorngren. 2011.

Thermodynamic Semirings.

CoRR abs/1108.2874 (2011).

https://doi.org/10.48550/arXiv.1108.2874

Matilde Marcolli and Ryan Thorngren. 2014. Thermodynamic semirings. Journal of Noncommutative Geometry 8, 2 (2014),

337–392. https://doi.org/10.4171/jncg/159

Annabelle McIver and Carroll Morgan. 2005. Abstraction, Reﬁnement and Proof for Probabilistic Systems.

Springer.

https://doi.org/10.1007/b138392

Carroll Morgan, Annabelle McIver, and Karen Seidel. 1996. Probabilistic Predicate Transformers. ACM Trans. Program.

Lang. Syst. 18, 3 (1996), 325–353. https://doi.org/10.1145/229542.229547

Nicholas Nethercote, Peter J. Stuckey, Ralph Becket, Sebastian Brand, Gregory J. Duck, and Guido Tack. 2007. MiniZinc:
Towards a Standard CP Modelling Language. In CP (Lecture Notes in Computer Science, Vol. 4741). Springer, 529–543.
https://doi.org/10.1007/978-3-540-74970-7_38

Antonio Nola and Brunella Gerla. 2005. Algebras of Lukasiewicz’s logic and their semiring reducts. Contemp. Math 377

(01 2005). https://doi.org/10.1090/conm/377/06988

30

Batz, Gallus, Kaminski, Katoen, and Winkler

Russel O’Conner. 2012.

A Very General Method of Computing Shortest Paths.

Personal blog entry.

http://r6.ca/blog/20110808T035622Z.html

Tomas Petricek, Dominic A. Orchard, and Alan Mycroft. 2014.

Coeﬀects: a calculus of context-dependent
computation.
the 19th ACM SIGPLAN international conference on Functional programming,
Gothenburg, Sweden, September 1-3, 2014, Johan Jeuring and Manuel M. T. Chakravarty (Eds.). ACM, 123–135.
https://doi.org/10.1145/2628136.2628160

In Proceedings of

Gordon D. Plotkin. 2004. A Structural Approach to Operational Semantics. The Journal of Logic and Algebraic Programming

60-61 (2004), 17–139. https://doi.org/10.1016/j.jlap.2004.05.001

Marc Pouly. 2010. Semirings for Breakfast. https://marcpouly.ch/pdf/internal_100712.pdf Visited on 2022-03-21..
John C. Reynolds. 2002. Separation Logic: A Logic for Shared Mutable Data Structures. In LICS. IEEE Computer Society,

55–74. https://doi.org/10.1109/lics.2002.1029817

Grzegorz Rozenberg and Arto Salomaa. 1997. Handbook of Formal Languages, Vol. 1: Word, Language, Grammar. Springer-

Verlag. https://doi.org/10.1007/978-3-642-59136-5

Alexander Schrijver. 1999. Theory of Linear and Integer Programming. Wiley.
Mary Sheeran, Satnam Singh, and Gunnar Stålmarck. 2000.

tion and a SAT-Solver.
https://doi.org/doi.org/10.1007/3-540-40922-x_8

In FMCAD (Lecture Notes

Checking Safety Properties Using Induc-
in Computer Science, Vol. 1954). Springer, 108–125.

Richard Sproat, Mahsa Yarmohammadi,

Izhak Shafran, and Brian Roark. 2014.

Semirings to Problems in Speech and Language Processing.
https://doi.org/10.1162/coli_a_00198

Applications of Lexicographic
Comput. Linguistics 40, 4 (2014), 733–761.

Wouter Swierstra and Tim Baanen. 2019. A Predicate Transformer Semantics for Eﬀects (functional pearl). Proc. ACM

Program. Lang. 3, ICFP (2019), 103:1–103:26. https://doi.org/10.1145/3341707

Robert Endre Tarjan. 1985. Amortized computational complexity. SIAM Journal on Algebraic Discrete Methods 6, 2 (1985),

306–318. https://doi.org/10.1137/0606031

Günther J. Wirsching, Markus Huber, and Christian Kölbl. 2010. The conﬁdence-probability semiring. Technical Report

2010-04. Fakultät für Angewandte Informatik.

Linpeng Zhang and Benjamin Lucien Kaminski. 2022a. Quantitative Strongest Post. CoRR abs/2202.06765 (2022).

https://doi.org/10.48550/arXiv.2202.06765

Linpeng Zhang and Benjamin Lucien Kaminski. 2022b. Quantitative Strongest Post. PACMPL (2022).

Issue OOPSLA.

https://doi.org/10.1145/3527331 To appear.

Weighted Programming

31

A BACKGROUND ON SEMIRINGS, SEMIMODULES, AND FIXED POINT THEORY
A.1 Fixed Points

We apply ﬁxed point iteration and ﬁxed point induction to our wp and wlp calculi. Hence, we
recall the required material from Domain Theory here. For a thorough introduction, we refer to
[Abramsky 1994, Ch. Domain Theory].

A reﬂexive, transitive, and antisymmetric binary relation (cid:22) on a set 𝐴 is a partial order and we
call (𝐴, (cid:22)) a partially ordered set (poset). Let 𝐵 ⊆ 𝐴. We say that 𝑏 ∈ 𝐵 is a least element in 𝐵 if
𝑏 (cid:22) 𝑏 ′ for all 𝑏 ′ ∈ 𝐵. Note that there exists at most one least element. The least element of 𝐵 = 𝐴 is
written ⊥ whenever it exists. Further, if the set { 𝑐 ∈ 𝐴 | ∀𝑏 ∈ 𝐵 : 𝑏 (cid:22) 𝑐 } has a least element, then
𝐵. An inﬁnite sequence
we call it the least upper bound or supremum of 𝐵 and denote it with
(𝑎𝑖 )𝑖 ∈N of elements from 𝐴 is called an ascending 𝜔-chain if

𝑎0 (cid:22) 𝑎1 (cid:22) 𝑎2 (cid:22) . . .

,

Ã

i.e. for all 𝑖 ∈ N we have 𝑎𝑖 (cid:22) 𝑎𝑖+1.

It is easy to verify that the structure (𝐴, (cid:23)) that results from reverting the order (cid:22) is also a poset.
Greatest elements, greatest lower bounds or inﬁma, and descending 𝜔-chains in (𝐴, (cid:22)) are deﬁned
as least elements, suprema and ascending 𝜔-chains in (𝐴, (cid:23)), respectively. The greatest element
in 𝐴 is denoted ⊤ if it exists and we adapt the notation d 𝐵 for inﬁma.

Deﬁnition A.1 (𝜔-cpo). The poset (𝐴, (cid:22)) is a (pointed) 𝜔-complete partial order (𝜔-cpo) if there
exists13 a least element ⊥ and every ascending 𝜔-chain (𝑎𝑖 )𝑖 ∈N has a supremum
𝑖 ∈N 𝑎𝑖 . Dually,
we call (𝐴, (cid:22)) a (pointed) 𝜔-cocomplete partial order (𝜔-cocpo) if (𝐴, (cid:23)) is an 𝜔-cpo, i.e. if there
exists a greatest element ⊤ and every descending 𝜔-chain (𝑎𝑖 )𝑖 ∈N has an inﬁmum d𝑖 ∈N 𝑎𝑖 . If (𝐴, (cid:22))
△
is both an 𝜔-cpo and an 𝜔-cocpo, then we call it an 𝜔-bicpo.

Ã

Consider a poset (𝐴, (cid:22)) with a function 𝑓 : 𝐴 → 𝐴. 𝑓 is called monotone if

∀𝑎1, 𝑎2 ∈ 𝐴 :

𝑎1 (cid:22) 𝑎2

implies

𝑓 (𝑎1) (cid:22) 𝑓 (𝑎2) .

Note that 𝜔-chains are preserved under monotone functions: If (𝑎𝑖 )𝑖 ∈N is ascending (descending,
respectively), then the same holds for (𝑓 (𝑎𝑖 ))𝑖 ∈N.

Deﬁnition A.2 (𝜔-continuous functions). Let (𝐴, (cid:22)) be a poset and 𝑓 : 𝐴 → 𝐴 a function. 𝑓 is

called 𝜔-continuous if it preserves suprema, i.e. for all ascending 𝜔-chains (𝑎𝑖 )𝑖 ∈N in 𝐴 we have

𝑓

𝑎𝑖

!

Ä𝑖 ∈N

=

𝑓 (𝑎𝑖 ) .

Ä𝑖 ∈N

Dually, 𝑓 is called 𝜔-cocontinuous if it preserves inﬁma of descending chains. If 𝑓 is both 𝜔-
△
continuous and -cocontinuous, then 𝑓 is called 𝜔-bicontinuous.

It is easy to see that 𝜔-(co)continuity implies monotonicity, but the converse is false in general.

Lemma A.3. If 𝑓 : (𝐴, (cid:22)) → (𝐴, (cid:22)) and 𝑔 : (𝐴, (cid:22)) → (𝐴, (cid:22)) are 𝜔-(co)continuous functions, then

their composition 𝑔 ◦ 𝑓 : (𝐴, (cid:22)) → (𝐴, (cid:22)) is also 𝜔-(co)continuous.

The 𝑛-fold composition of a function 𝑓 : 𝐴 → 𝐴 is recursively deﬁned as 𝑓 0 = id and 𝑓 𝑛 = 𝑓 ◦ 𝑓 𝑛−1
for all 𝑛 > 0.

Let (𝐴, (cid:22)) be a poset. A ﬁxed point of 𝑓 : 𝐴 → 𝐴 is an element 𝑎 ∈ 𝐴 such that 𝑓 (𝑎) = 𝑎. A least
(greatest) ﬁxed point of 𝑓 is a least (greatest, respectively) element in the set of ﬁxed points of 𝑓 .

13Some authors deﬁne 𝜔-cpo without requiring the existence of least elements, and speak of 𝜔-cpo with bottom or pointed
𝜔-cpo.

 
32

Batz, Gallus, Kaminski, Katoen, and Winkler

Theorem A.4 (Kleene Iteration & Park Induction). Let (𝐴, (cid:22)) be a poset and 𝑓 : 𝐴 → 𝐴.
(1) If (𝐴, (cid:22)) is an 𝜔-cpo and 𝑓 is 𝜔-continuous, then 𝑓 has a least ﬁxed point lfp 𝑓 satisfying

lfp 𝑓 =

𝑓 𝑛 (⊥)

and

∀𝑎 ∈ 𝐴 :

𝑓 (𝑎) (cid:22) 𝑎

implies

lfp 𝑓 (cid:22) 𝑎 .

(2) If (𝐴, (cid:22)) is an 𝜔-cocpo and 𝑓 is 𝜔-cocontinuous, then 𝑓 has a greatest ﬁxed point gfp 𝑓 satisfying

Ä𝑛 ∈N

gfp 𝑓 = l
𝑛 ∈N

𝑓 𝑛 (⊤)

A.2 Semirings

and

∀𝑎 ∈ 𝐴 :

𝑎 (cid:22) 𝑓 (𝑎)

implies 𝑎 (cid:22) gfp 𝑓 .

In the literature the term semiring is given diﬀerent meanings; to prevent any confusion we restate
the deﬁnition we use. As usual, multiplication ⊙ associates stronger than addition ⊕ and we drop
parentheses accordingly. For an in-depth introduction, we refer to [Droste et al. 2009, Chapter 1,
2].

Deﬁnition A.5 (Monoids). A monoid W = (𝑊 , ⊙, 1) consists of a carrier set 𝑊 , an operation

⊙ : 𝑊 × 𝑊 → 𝑊 , and an identity 1 ∈ 𝑊 , such that for all 𝑎, 𝑏, 𝑐 ∈ 𝑊 ,

(1) the operation ⊙ is associative, i.e. ,

(2) 1 is an identity with respect to ⊙, i.e. ,

𝑎 ⊙ (𝑏 ⊙ 𝑐) = (𝑎 ⊙ 𝑏) ⊙ 𝑐 ,

and

𝑎 ⊙ 1 = 1 ⊙ 𝑎 = 𝑎 .

The monoid W is commutative, if

(3) the operation ⊙ is commutative:

𝑎 ⊙ 𝑏 = 𝑏 ⊙ 𝑎 .

△

Deﬁnition A.6 (Semirings). A semiring S = (𝑆, ⊕, ⊙, 0, 1) consists of a carrier set 𝑆, an addi-

tion ⊕ : 𝑆 × 𝑆 → 𝑆, a multiplication ⊙ : 𝑆 × 𝑆 → 𝑆, a zero 0 ∈ 𝑆, and a one 1 ∈ 𝑆, such that

(1) (𝑆, ⊕, 0) forms a commutative monoid,
(2) (𝑆, ⊙, 1) forms a (possibly not-commutative) monoid,

and

and for all 𝑎, 𝑏, 𝑐 ∈ 𝑆,

(3) multiplication distributes over addition, i.e. ,
𝑎 ⊙ (𝑏 ⊕ 𝑐) = 𝑎 ⊙ 𝑏 ⊕ 𝑎 ⊙ 𝑐

and

(4) and multiplication by zero annihilates 𝑆, i.e. ,

(𝑎 ⊕ 𝑏) ⊙ 𝑐 = 𝑎 ⊙ 𝑐 ⊕ 𝑏 ⊙ 𝑐,

Given a semiring S, we can construct a semiring of functions via point-wise lifting of the oper-

0 ⊙ 𝑎 = 𝑎 ⊙ 0 = 0.

△

ations.

Lemma A.7 (Semirings of Semiring-valued Functions). Let S = (𝑆, ⊕S, ⊙S, 0S, 1 S) be a
semiring and 𝑋 be a non-empty set. Then S𝑋 ≔ (𝑆𝑋 , ⊕, ⊙, 0, 1), where 𝑆𝑋 is the set of functions of
type 𝑋 → 𝑆 and for all 𝑓 , 𝑔 ∈ 𝑆𝑋 ,

𝑓 ⊕ 𝑔 ≔ 𝜆 𝑥 .
𝑓 ⊙ 𝑔 ≔ 𝜆 𝑥 .
0 ≔ 𝜆 𝑥 .
1 ≔ 𝜆 𝑥 .

𝑓 (𝑥) ⊕S 𝑔(𝑥),
𝑓 (𝑥) ⊙S 𝑔(𝑥),
0S,
1 S ,

also forms a semiring which we call the lifting of S with respect to 𝑋 .

△

Weighted Programming

33

There is a canonical embedding 𝑆 → 𝑆𝑋 , 𝑎 ↦→ (𝜆 𝑥 . 𝑎) mapping semiring elements in 𝑆 to constant
functions in 𝑆𝑋 . For better readability, we overload notation and identify elements 𝑎 with their
corresponding constant functions 𝜆 𝑥 . 𝑎, e.g. writing 𝑎 ⊙ 𝑓 instead of (𝜆 𝑥 . 𝑎) ⊙ 𝑓 where 𝑓 ∈ 𝑆𝑋 .

For our purpose of developing a weakest-precondition-style calculus for weighted programs,
we need to impose additional structure on our semirings; most essentially: an order, in particular
one which is compatible with the algebraic structure of the semiring. Let us, for the remainder of
this section, ﬁx an ambient semiring S = (𝑆, ⊕, ⊙, 0, 1).

Deﬁnition A.8 (Natural Order). The relation (cid:22) is deﬁned for all 𝑎, 𝑏 ∈ 𝑆 by

𝑎 (cid:22) 𝑏

iﬀ

∃ 𝑐 ∈ 𝑆 :

𝑎 ⊕ 𝑐 = 𝑏.

If (cid:22) is a partial order, then we call S naturally ordered and (cid:22) the natural order on 𝑆.

△

Note that a presence of additive inverses (other than the self-inverse 0) prohibits the existence of
a natural order as antisymmetry is violated. Indeed, the relation (cid:22) degenerates to 𝑆 × 𝑆 for rings.

Lemma A.9 (Least Elements and Monotonicity of Algebraic Operations [Rozenberg and

Salomaa 1997, Ch. 9, Thm. 2.1]). Let S be naturally ordered. Then,

(1) 0 is the unique least element, and
(2) ⊕ and ⊙ are monotone, i.e. for all 𝑎, 𝑏, 𝑐 ∈ 𝑆,

𝑎 (cid:22) 𝑏

implies

𝑎 ⊕ 𝑐 (cid:22) 𝑏 ⊕ 𝑐

and 𝑎 ⊙ 𝑐 (cid:22) 𝑏 ⊙ 𝑐

and 𝑐 ⊙ 𝑎 (cid:22) 𝑐 ⊙ 𝑏 .

If the natural order (cid:22) moreover has a greatest element, then this is unique and denoted ⊤S, where
we drop the subscript S whenever it is clear from the context.

The partial order can be lifted pointwise to functions in the spirit of Lemma A.7, i.e. a partial

order (cid:22) ⊆ 𝑆𝑋 × 𝑆𝑋 on S𝑋 is given by

𝑓 (cid:22) 𝑔

iﬀ

∀𝑥 ∈ 𝑋 :

𝑓 (𝑥) (cid:22) 𝑔(𝑥) .

Moreover, if (cid:22) is the natural order on S, then (cid:22) as deﬁned above is the natural order on S𝑋 . In
case of 𝜔-(co)cpos, joins ⊔ (meets ⊓) are hence given by pointwise joins (meets).

Second, in order to apply ﬁxed point theory to semirings, we require some continuity con-

straints.

Deﬁnition A.10 (𝜔-continuous semirings [Ésik 2008, Def. 14]). A semiring S = (𝑆, ⊕, ⊙, 0, 1) is
𝜔-continuous, if (𝑆, (cid:22)) is an 𝜔-cpo and addition and multiplication by constants are 𝜔-continuous
functions, i.e. for all 𝑎 ∈ 𝑆 and all ascending chains (𝑏𝑖)𝑖 ∈N in 𝑆, we require

as well as

𝑎 ⊕

𝑏𝑖

=

(𝑎 ⊕ 𝑏𝑖)

Ä𝑖 ∈N

Ä𝑖 ∈N

𝑎 ⊙

𝑏𝑖

=

(𝑎 ⊙ 𝑏𝑖)

and

𝑏𝑖 ⊙ 𝑎

=

(𝑏𝑖 ⊙ 𝑎) .

Ä𝑖 ∈N

Ä𝑖 ∈N

Ä𝑖 ∈N

Ä𝑖 ∈N

Dually, S is 𝜔-cocontinuous if (𝑆, (cid:22)) is an 𝜔-cocpo and addition/multiplication with constants are
△
𝜔-cocontinuous functions. S is 𝜔-bicontinuous if it is both 𝜔-continuous and -cocontinuous.

Moreoever, it is clear that if S is 𝜔-(co)continuous, then the semiring S𝑋 of functions from a set
𝑋 to S (cf. Lemma A.7) is 𝜔-(co)continuous as well.

The 𝜔-continuity also allows to deﬁne countably inﬁnite sums. Semirings that admit an inﬁnite
sum operation are called complete. We only consider the case of 𝜔-ﬁnitary semirings [Karner 1992,

34

Batz, Gallus, Kaminski, Katoen, and Winkler

Sec. 5], with respect to the natural order (cid:22), where such inﬁnite sums are deﬁned as follows [Ésik
2008, Thm. 19]: Given a family (𝑎𝑖 )𝑖 ∈𝐼 in 𝑆 over a countable index set 𝐼 ,

𝑎𝑖 ≔

𝑎𝑖 .

Ê𝑖 ∈𝐼

Ä𝐹 ⊆𝐼,
𝐹 ﬁnite Ê𝑖 ∈𝐹

(4)

This deﬁnition enjoys two important properties: (i) If 𝐼 is ﬁnite, the value coincides with the
usual sum; (ii) the summation order is irrelevant by deﬁnition. In fact, if 𝐼 is inﬁnite it can be
shown [Rozenberg and Salomaa 1997, Ch. 9, Thm. 2.3], (Appendix B.2) that the right-hand side of
(4) is equal to the supremum of the partial sums associated with any arbitrary summation order,
i.e. for all N-indexed families (𝑏𝑖)𝑖 ∈N such that there exists a bijection 𝜏 : N → 𝐼 with 𝑏𝑖 = 𝑎𝜏 (𝑖) for
all 𝑖 ∈ N we have

𝑎𝑖

=

𝑏𝑖 .

(5)

Ê𝑖 ∈𝐼

Ä𝑛 ∈N

Ê𝑖 ≤𝑛

The latter formulation is used as deﬁnition of 𝜔-continuous semirings in [Kuich 1991]. It shows
𝑛 ∈N is clearly an 𝜔-
that being an 𝜔-cpo already suﬃces to deﬁne inﬁnite sums since
chain.14 Moreover, it follows by 𝜔-continuity that the extended distributive laws are satisﬁed: For
all 𝑐 ∈ 𝑆,

𝑖 ≤𝑛 𝑏𝑖

(cid:0)É

(cid:1)

𝑐 ⊙

=

𝑎𝑖

!

Ê𝑖 ∈𝐼

Ê𝑖 ∈𝐼

𝑐 ⊙ 𝑎𝑖

and

⊙ 𝑐 =

𝑎𝑖

!

Ê𝑖 ∈𝐼

Ê𝑖 ∈𝐼

𝑎𝑖 ⊙ 𝑐 .

For an in-depth discussion of complete, ﬁnitary, and continuous semirings we refer to [Ésik 2008;

Golan 2003; Goldstern 2002; Karner 1992, 2004; Kuich 1991; Rozenberg and Salomaa 1997].

A.3 Modules over Monoids

Like vector spaces over a ﬁeld, modules over rings, or semimodules over semirings we deﬁne mod-
ules over monoids. Semimodules over semirings in the setting of weighted automata are studied
in [Droste et al. 2009]. The modules represent what our programs act on – they are a required
generalization to study formal languages as Example B.2 shows. We present everything in parallel
to Appendix A.2.

Deﬁnition A.11 (Module over a Monoid). Let W = (𝑊 , ⊙, 1) be a monoid. A (left) W-module
M = (𝑀, ⊕, 0, ⊗) is a commutative monoid (𝑀, ⊕, 0) equipped with a (left) action called scalar
multiplication ⊗ : 𝑊 × 𝑀 → 𝑀, such that

(1) the scalar multiplication ⊗ is associative, i.e. for all 𝑎, 𝑏 ∈ 𝑊 and 𝑣 ∈ 𝑀,

(𝑎 ⊙ 𝑏) ⊗ 𝑣 = 𝑎 ⊗ (𝑏 ⊗ 𝑣) ,

(2) the scalar multiplication ⊗ is distributive, i.e. for all 𝑎 ∈ 𝑊 and 𝑣, 𝑤 ∈ 𝑀,

𝑎 ⊗ (𝑣 ⊕ 𝑤) = (𝑎 ⊗ 𝑣) ⊕ (𝑎 ⊗ 𝑤) ,
(3) the monoid’s one 1 is neutral and the module’s zero 0 annihilates, i.e. for all 𝑎 ∈ 𝑊 and 𝑣 ∈ 𝑀,

1 ⊗ 𝑣 = 𝑣

and

𝑎 ⊗ 0 = 0 .

△

To simplify language we speak of modules (and forget about the “over a monoid” part); this should
not be confused with a module over a ring. We emphasize that all the results developed in this paper
apply to the important special case where the monoid and the module together form a semiring:
The multiplication ⊙ of a semiring S = (𝑆, ⊕, ⊙, 0, 1) is then the left-action ⊗ : 𝑆 × 𝑆 → 𝑆 of the

14The converse also is true, e.g. 𝜔-ﬁnitary semirings with respect to the natural order (cid:22) are an 𝜔-cpo with respect to (cid:22)
[Kuich 1991, Thm. 2.3]. Their notion of 𝜔-continuous semiring is hence also equivalent to Deﬁnition A.10.

 
 
Weighted Programming

35

multiplicative monoid of (𝑆, ⊙, 1) to the additive monoid (𝑆, ⊕, 0). We also do not diﬀerentiate
multiplication ⊙ and left-action ⊗ and write ⊙ instead of ⊗ from now on – both are associative
and the operation should be clear from the rightmost multiplicant’s type.

Analogous to Lemma A.7, we also can construct a module of functions via point-wise lifting of

the operations.

Lemma A.12 (Module of Module-valued Functions). Let M = (𝑀, ⊕M, 0M, ⊙M) be an W-
module and 𝑋 be a non-empty set. Then M𝑋 ≔ (𝑀𝑋 , ⊕, 0, ⊙), where 𝑀𝑋 is the set of functions of
type 𝑋 → 𝑀 and for all 𝑎 ∈ 𝑊 , 𝑢, 𝑣 ∈ 𝑀𝑋 ,

𝑢 ⊕ 𝑣 ≔ 𝜆 𝑥 . 𝑢 (𝑥) ⊕M 𝑣 (𝑥) ,
𝑎 ⊙ 𝑣 ≔ 𝜆 𝑥 .
0 ≔ 𝜆 𝑥 .

𝑎 ⊙M 𝑣 (𝑥) ,
0M ,

also forms a W-module which we call the lifting of M with respect to 𝑋 .

△

Analogous to Deﬁnition A.8, we speak of naturally ordered modules M.

Deﬁnition A.13 (Natural Order). The relation (cid:22) is deﬁned for all 𝑎, 𝑏 ∈ 𝑀 by

𝑎 (cid:22) 𝑏

iﬀ

∃ 𝑐 ∈ 𝑀 :

𝑎 ⊕ 𝑐 = 𝑏.

If (cid:22) is a partial order, then we call M naturally ordered and (cid:22) the natural order on M.

△

Similar to Lemma A.9, we have for modules:

Lemma A.14 (Least Elements and Monotonicity of Algebraic Operations). Let M be nat-

urally ordered. Then,

(1) 0 is the unique least element, and
(2) ⊕ and ⊙ are monotone, i.e. for all 𝑎 ∈ 𝑆 and 𝑢, 𝑣, 𝑤 ∈ 𝑀,

𝑣 (cid:22) 𝑤

implies

𝑢 ⊕ 𝑣 (cid:22) 𝑢 ⊕ 𝑤 and 𝑎 ⊙ 𝑣 (cid:22) 𝑎 ⊙ 𝑤 .

Proof. The ﬁrst two statements directly follow from the natural order. For the last one, distribu-
(cid:3)

tivity is additionally required.

If the natural order (cid:22) moreover has a greatest element, then this is unique and denoted ⊤M, where
we drop the subscript M whenever it is clear from the context.

As for semirings, we also want to apply ﬁxed point theory to modules. Inspired by Deﬁni-

tion A.10, we deﬁne the following notion of 𝜔-continuous modules.

Deﬁnition A.15 (𝜔-continuous module). A W-module M is 𝜔-continuous, if (𝑀, (cid:22)) is an 𝜔-cpo
and addition and scalar multiplication with constants are 𝜔-continuous functions, i.e. for all 𝑎 ∈ 𝑊 ,
𝑢 ∈ 𝑀 and all ascending chains (𝑣𝑖 )𝑖 ∈N in 𝑀, we require

𝑢 ⊕

𝑣𝑖

=

( 𝑎 ⊕ 𝑣𝑖 )

and

𝑎 ⊙

𝑣𝑖

=

( 𝑎 ⊙ 𝑣𝑖 ) .

Ä𝑖 ∈N

Ä𝑖 ∈N

Ä𝑖 ∈N

Ä𝑖 ∈N

Dually, M is 𝜔-cocontinuous if (𝑀, (cid:22)) is an 𝜔-cocpo and addition/scalar multiplication with con-
stants are 𝜔-cocontinuous functions. M is 𝜔-bicontinuous if it is both 𝜔-continuous and -cocontinuous.
△

Moreover, if M is 𝜔-(co)continuous, then the module M𝑋 of functions from a set 𝑋 to M (cf.
Lemma A.12) is 𝜔-(co)continuous as well.

36

Batz, Gallus, Kaminski, Katoen, and Winkler

As for semirings, 𝜔-continuity allows to deﬁne countably inﬁnite sums. We call a module 𝜔-
ﬁnitary if the inﬁnite sum is deﬁned as follows: Given a family (𝑣𝑖)𝑖 ∈𝐼 in 𝑀 over a countable index
set 𝐼 ,

𝑣𝑖 ≔

𝑣𝑖 ≔

Ê𝑖 ∈𝐼

𝐹 ﬁnite Ê𝑖 ∈𝐹
Ä𝐹 ⊆𝐼,

𝑤𝑖 ,

Ä𝑛 ∈N

Ê𝑖 ≤𝑛

(6)

where (𝑏𝑖)𝑖 ∈N is any N-indexed family such that there exists a bijection 𝜏 : N → 𝐼 with 𝑏𝑖 = 𝑎𝜏 (𝑖)
for all 𝑖 ∈ N. Again, from 𝜔-continuity it follows that an extended distributive law is satisﬁed: For
all 𝑎 ∈ 𝑊 ,

𝑎 ⊙

=

𝑣𝑖

!

Ê𝑖 ∈𝐼

Ê𝑖 ∈𝐼

𝑎 ⊙ 𝑣𝑖

 
Weighted Programming

37

B PROOFS OF PRELIMINARIES A
B.1 Proof of Theorem A.4

We only show Item 1 which implies Item 2 by reversing the order. The ﬁrst part of Item 1 is
simply an instance of the classic Kleene Fixed Point Theorem. The second part—the Park Induction
principle—can be seen as follows. First we show by induction that 𝑓 𝑛 (⊥) (cid:22) 𝑎 for all 𝑛 ∈ N: For
𝑛 = 0 we have 𝑓 0(⊥) = ⊥ (cid:22) 𝑎. For 𝑛 ≥ 0, we have by the I.H. and monotonicity of 𝑓 that

𝑓 𝑛+1(⊥)

=

𝑓 (𝑓 𝑛 (⊥))

(cid:22)

𝑓 (𝑎)

(cid:22)

𝑎 .

By Kleene Fixpoint Theorem and the deﬁnition of suprema it follows that

lfp 𝑓

=

𝑓 𝑛 (⊥)

(cid:22)

𝑎 .

(cid:3)

Ä𝑛 ∈N

B.2 Proof that Eq. 4 and Eq. 5 (notions of 𝝎-finitary) coincide

Lemma B.1. Let S = (𝑆, ⊕, ⊙, 0, 1) be an 𝜔-continuous semiring, (𝑎𝑖 )𝑖 ∈𝐼 a family in 𝑆 over a
countably inﬁnite index set 𝐼 , and (𝑏 𝑗 ) 𝑗 ∈N a family in 𝑆 such that there exists a bijection 𝜏 : N → 𝐼
with 𝑏 𝑗 = 𝑎𝜏 ( 𝑗) for all 𝑗 ∈ N. Then,

𝑎𝑖

=

𝑎𝑖

=

𝑏 𝑗 .

Ê𝑖 ∈𝐼

𝐹 ﬁnite Ê𝑖 ∈𝐹
Ä𝐹 ⊆𝐼,

Ä𝑛 ∈N

Ê𝑗 ≤𝑛

In particular,

𝑖 ∈𝐼 𝑎𝑖 is well-deﬁned and Eq. (4) is compatible to Eq. (5).

Proof. First, as (

É

𝑗 ≤𝑛 𝑏 𝑗 )𝑛 ∈N is an 𝜔-chain under the natural order (cid:22). Thus the supremum is

well deﬁned in the 𝜔-continuous semiring.
É

Next, let 𝐹 ⊆ 𝐼 be a ﬁnite subset. We denote the image of 𝐹 under 𝜏 as 𝜏 (𝐹 ) ≔ { 𝜏 (𝑖) | 𝑖 ∈ 𝐹 }.
Next, deﬁne the maximal index 𝑛𝐹 ≔ max 𝜏 (𝐹 ) ∈ N corresponding to 𝐹 (with respect to 𝜏). Then,
we get the partition

{ 𝑗 ∈ N | 0 ≤ 𝑗 ≤ 𝑛𝐹 }

=

𝜏 (𝐹 ) ⊎ { 𝑗 ∈ N | 𝑗 ≤ 𝑛𝐹 , 𝑗 ∉ 𝜏 (𝐹 ) } .

By deﬁnition of the natural order (cid:22) it follows

𝑎𝑖 =

𝑏𝜏 (𝑖) =

𝑏 𝑗

(cid:22)

𝑏 𝑗 ⊕

𝑏 𝑗 =

𝑏 𝑗

(cid:22)

𝑏 𝑗 ,

Ê𝑖 ∈𝐹

Ê𝑖 ∈𝐹

Ê𝑗 ∈𝜏 (𝐹 )

Ê𝑗 ∈𝜏 (𝐹 )

Ê𝑗 ≤𝑛𝐹
𝑗∉𝜏 (𝐹 )

Ê𝑗 ≤𝑛𝐹

Ä𝑛 ∈N

Ê𝑗 ≤𝑛

and hence (if the left supremum exists)

𝑎𝑖

(cid:22)

𝑏 𝑗 .

𝐹 ﬁnite Ê𝑖 ∈𝐹
Ä𝐹 ⊆𝐼,

Ä𝑛 ∈N

Ê𝑗 ≤𝑛

On the other hand, we denote for 𝑛 ∈ N the preimage of ¯𝑛 ≔ { 𝑗 ∈ N | 0 ≤ 𝑗 ≤ 𝑛 } under 𝜏 as

𝐹𝑛 ≔ { 𝑖 ∈ 𝐹 | 𝜏 (𝑖) ≤ 𝑛 }. As this always is a ﬁnite subset of 𝐼 ,

𝑏 𝑗 =

𝑎𝜏 −1 ( 𝑗) =

𝑎𝑖

(cid:22)

𝑎𝑖 .

Ä𝑛 ∈N

Ê𝑗 ≤𝑛

Ä𝑛 ∈N

Ê𝑗 ≤𝑛

Ä𝑛 ∈N

Ê𝑖 ∈𝐹𝑛

𝐹 ﬁnite Ê𝑖 ∈𝐹
Ä𝐹 ⊆𝐼,

Combining both inequalities, we obtain exactly the equality claimed above.

(cid:3)

38

Batz, Gallus, Kaminski, Katoen, and Winkler

B.3 Problems with the Semiring of infinite words
In order to extend LΓ with 𝜔-words (i.e. words of countably inﬁnite length) to obtain a semiring
of mixed languages, i.e. subsets of Γ∞ = Γ∗ ∪ Γ𝜔 , one might be tempted to deﬁne the concatenation
of languages 𝐿1, 𝐿2 ⊆ Γ∗ ∪ Γ𝜔 as follows: Partition 𝐿1 = 𝐾1 ∪ 𝑀1 where 𝐾1 ⊆ Γ∗ are the ﬁnite and
𝑀1 ⊆ Γ𝜔 are the 𝜔-words of 𝐿1. We set

𝐿1 · 𝐿2 ≔

𝐾1 · 𝐿2 ∪ 𝑀1
∅

(

if 𝐿2 ≠ ∅ ,
if 𝐿2 = ∅ .

Intuitively, concatenating 𝜔-words from the left is absorptive. This way, (2Γ∗∪Γ𝜔
, ∪, ·, ∅, { 𝜖 })
indeed is a 𝜔-continuous semiring. However, the multiplication · is not 𝜔-cocontinuos as the fol-
lowing example shows.

Example B.2 (Counterexample). Consider the singular alphabet Γ = { 𝑎 }. Deﬁne the descending

𝜔-chain (𝐿𝑛)𝑛 ∈N where 𝐿𝑛 ≔

𝑎𝑖

𝑖 ≥ 𝑛

. Then,

(cid:8)
· { 𝑎𝜔 }

(cid:12)
(cid:12)
=

𝐿𝑛

l
𝑛 ∈N

!

(cid:9)

Ù𝑛 ∈N

𝐿𝑛

!

On the other hand,

· { 𝑎𝜔 }

=

∅ · { 𝑎𝜔 }

=

∅ .

l
𝑛 ∈N

(𝐿𝑛 · { 𝑎𝜔 })

=

(𝐿𝑛 · { 𝑎𝜔 })

=

{ 𝑎𝜔 }

=

{ 𝑎𝜔 } .

Ù𝑛 ∈N

Ù𝑛 ∈N

Hence, · is not 𝜔-cocontinuos.

Even as a semimodule multiplication with a semiring element would not be 𝜔-cocontinuos. An
approach to resolve this problem is the notion of star semiring - omega semimodule pairs or quemir-
ings [Droste et al. 2009, Ch. 3]. Using semirings has the beneﬁt that it allows to study matricial
theories [Droste et al. 2009, Ch. 1 & 2].

Alternatively, we have the following approach. Consider the alphabet Γ. We obtain the word
Γ ≔ () over

monoid Γ∗ = (Γ∗, ·, 𝜖) where · is the usual concatenation. Next, we deﬁne a module L∞
this monoid.

Γ is a 𝜔-bicontinuous module

B.4 Proof that L∞
Let Γ be a non-empty alphabet. The word monoid is Γ∗ = (Γ∗, ·, 𝜖), where · is the usual con-
catenation and 𝜖 is the empty word. As a shorthand denote Γ∞ ≔ Γ∗ ∪ Γ𝜔 . For a word 𝑣 ∈ Γ∗
(from the monoid) and a formal language 𝐿 ⊆ Γ∞ (from the module) we deﬁne their concatenation
𝑣 · 𝐿 ≔ { 𝑣𝑤 | 𝑤 ∈ 𝐿 } as usual. Clearly, the module of mixed languages L∞
, ∪, ∅, ·) is a
module over this monoid.

Γ ≔ (2Γ∞

Claim. This module is 𝜔-bicontinuous.

Proof. The natural order (cid:22) simply is set inclusion ⊆ of languages. The inﬁmum ⊓ of a descend-
ing 𝜔-chain simply is the intersection ∩, and the supremum ⊔ of an ascending 𝜔-chain simply
is the union ∪, i.e. subsets of Γ∞ by deﬁnition. Let (𝐴𝑖 )𝑖 ∈N be an ascending 𝜔-chain (𝐴𝑖 ⊆ 𝐴𝑖+1),
(𝐷𝑖 )𝑖 ∈N be an descending 𝜔-chain (𝐷𝑖 ⊇ 𝐷𝑖+1), 𝐿 ⊆ Γ∞, and 𝑣 ∈ Γ∗ then

• Clearly, addition ∪ is 𝜔-continuous:

𝐿 ∪

𝐴𝑖

=

(𝐿 ∪ 𝐴𝑖 ) .

Ø𝑖 ∈N

Ø𝑖 ∈N

 
 
Weighted Programming

39

• Also, addition ∪ is 𝜔-cocontinuous:

𝐿 ∪

𝐷𝑖

=

(𝐿 ∪ 𝐷𝑖 ) .

• More interestingly, scalar multiplication · also is 𝜔-continuous:

Ù𝑖 ∈N

Ù𝑖 ∈N

Ø𝑖 ∈N

𝑣 ·

𝐴𝑖

=

𝑣 · 𝐴𝑖 .

𝑖 ∈N 𝐴𝑖 , then there is an 𝑢 ∈
Let 𝑤 ∈ 𝑣 ·
with 𝑢 ∈ 𝐴𝑖 and hence 𝑤 = 𝑣𝑢 ∈ 𝑣 · 𝐴𝑖.
On the other hand, let 𝑤 ∈
𝑢 ∈ 𝐴𝑗 . But this implies 𝑢 ∈

Ð

Ø𝑖 ∈N

𝑖 ∈N 𝐴𝑖 such that 𝑤 = 𝑣𝑢. But then there is an 𝑖 ∈ N

Ð

𝑖 ∈N 𝑣 · 𝐴𝑖 , then there is an 𝑗 ∈ N such that 𝑤 = 𝑣𝑢 for some
𝑖 ∈N 𝐴𝑖 and hence 𝑤 = 𝑣𝑢 ∈ 𝑣 ·

𝑖 ∈N 𝐴𝑖.

• Finally, scalar multiplication · is 𝜔-cocontinuous:15

Ð
Ð
𝑣 ·

𝐷𝑖

=

𝑣 · 𝐷𝑖 .

Ð

Ù𝑖 ∈N

𝑖 ∈N 𝐷𝑖 , then there is an 𝑢 ∈

Let 𝑤 ∈ 𝑣 ·
hence 𝑤 = 𝑣𝑢 ∈ 𝑣 · 𝐷𝑖 for all 𝑖 ∈ N.
Ñ
On the other hand, let 𝑤 ∈
But as 𝑤 is ﬁxed, this implies 𝑢𝑖 = 𝑢 𝑗 for all 𝑖, 𝑗 ∈ N. Hence, there is an 𝑢 = 𝑢1 ∈
with 𝑤 = 𝑣𝑢, i.e. 𝑣 ·

𝑖 ∈N 𝑣 · 𝐷𝑖 . Then, there is an 𝑢𝑖 ∈ 𝐿𝑖 with 𝑤 = 𝑣𝑢𝑖 for all 𝑖 ∈ N.
𝑖 ∈N 𝐷𝑖

Ñ

Ñ

Ù𝑖 ∈N
𝑖 ∈N 𝐷𝑖 such that 𝑤 = 𝑣𝑢. But then 𝑢 ∈ 𝐷𝑖 and

𝑖 ∈N 𝐷𝑖 .

Ñ

(cid:3)

Ñ

15This is in general false if one were to allow languages (as opposed to single words) on the left hand side, i.e. 𝐿1 · 𝐿2 for
𝐿1 ⊂ Γ∗ and 𝐿2 ⊂ Γ∞

40

Batz, Gallus, Kaminski, Katoen, and Winkler

C PROOFS OF SECTION 4
First of all, note that [𝜑] distributes of ⊕: Let 𝑓 , 𝑔 ∈ W and 𝜎 ∈ Σ.

• Case 𝜎 |= 𝜑.

( [𝜑] (𝑓 ⊕ 𝑔)) (𝜎) = 𝑓 (𝜎) ⊕ 𝑔(𝜎) = ( [𝜑] 𝑓 ) (𝜎) ⊕ ( [𝜑] 𝑓 ) (𝜎) = ( [𝜑] 𝑓 ⊕ [𝜑] 𝑔)) (𝜎)

• Case 𝜎 6|= 𝜑.

( [𝜑] (𝑓 ⊕ 𝑔)) (𝜎) = 0 = 0(𝜎) ⊕ 0(𝜎) = ( [𝜑] 𝑓 ) (𝜎) ⊕ ( [𝜑] 𝑓 ) (𝜎) = ( [𝜑] 𝑓 ⊕ [𝜑] 𝑔) (𝜎)

C.1 Proof of Theorem 4.7
We will use the following:

Lemma C.1. Let (𝑎𝑖 )𝑖 ∈N and (𝑏𝑖)𝑖 ∈N be ascending 𝜔-chains in an 𝜔-continuous module M. Then

(𝑎𝑖 ⊕ 𝑏𝑖) =

𝑎𝑖 ⊕

𝑏𝑖 .

Ä𝑖 ∈N

Ä𝑖 ∈N

Ä𝑖 ∈N

△

Proof. Follows because addition with constants is 𝜔-continuous (see Deﬁnition A.15) and ap-
(cid:3)

plying e.g. [Abramsky 1994, Ch. Domain Theory, Lem. 3.2.6].

Theorem C.2 (Theorem 4.7). Let the monoid module M over W be 𝜔-continuous. For all W-
: W → W
wGCL programs 𝐶 and 𝜔-continuous W-modules M the weighting transformer wp
is a well-deﬁned 𝜔-continuous function. If 𝐶 is of the form while ( 𝜑 ) { 𝐶 ′ }, the least ﬁxed point is

𝐶
J

K

( 𝑓 )

=

wp

𝐶
J

K

Φ𝑖
𝑓 (0) .

Ä𝑖 ∈N

△

Proof. We employ induction on the structure of 𝐶. Let (𝑓𝑖 )𝑖 ∈N be an ascending 𝜔-chain in W.

Because M and W are 𝜔-continuous mondules, all the following joins exist.

The following forms the induction base.

Weighted Programming

41

• The program 𝐶 is of the form 𝑥 ≔ 𝐸.

wp

𝐶
J

𝑓𝑖

!

K  

Ä𝑖 ∈N

=

𝑓𝑖

[𝑥/𝐸]

(cid:16) Ä𝑖 ∈N

(cid:17)

= 𝜆 𝜎.

𝑓𝑖

𝜎 [𝑥 ↦→ 𝜎 (𝐸)]

(cid:1)

(cid:1)(cid:17)

(cid:1)(cid:17)

(cid:16) Ä𝑖 ∈N

(cid:17) (cid:0)

= 𝜆 𝜎.

𝑓𝑖

𝜎 [𝑥 ↦→ 𝜎 (𝐸)]

Ä𝑖 ∈N

(cid:16)

(cid:0)

=

=

=

𝜆 𝜎. 𝑓𝑖

𝜎 [𝑥 ↦→ 𝜎 (𝐸)]

Ä𝑖 ∈N

(cid:16)

(cid:0)

(𝑓𝑖 [𝑥/𝐸])

Ä𝑖 ∈N

Ä𝑖 ∈N

wp

𝐶
J

K

( 𝑓𝑖 )

(Def. of wp)

(Def. of [𝑥/𝐸])

(Def. of

(Def. of

)

)

Ã

Ã

(Def. of [𝑥/𝐸])

(Def. of wp)

• The program 𝐶 is of the form ⊙ 𝑎. This is an immediate consequence of Lemma A.3 and the

𝜔-continuity of ⊙.

wp

𝐶
J

𝑓𝑖

!

K  

Ä𝑖 ∈N

= 𝑎 ⊙

=

=

Ä𝑖 ∈N

Ä𝑖 ∈N

𝑓𝑖

(cid:16) Ä𝑖 ∈N

(cid:17)

(𝑎 ⊙ 𝑓𝑖 )

wp

𝐶
J

K

( 𝑓𝑖 )

(Def. of wp)

(⊙ is 𝜔-continuous in the second argument)

(Def. of wp)

The following forms the induction step. Hence, for each deconstruction of 𝐶, we assume both
to be 𝜔-continuous as our induction’s hypothesis. Notice that the subpro-

and wp

wp
grams 𝐶1, 𝐶2, 𝐶 ′ are always shorter than 𝐶.
K

𝐶2
J

𝐶1
J

K

42

Batz, Gallus, Kaminski, Katoen, and Winkler

• The program 𝐶 is of the form 𝐶1

𝐶2. This is an immediate consequence of Lemma A.3.

#

wp

𝐶
J

𝑓𝑖

!

K  

Ä𝑖 ∈N

= wp

wp

𝐶1
J

K  

𝐶2
J

𝑓𝑖

! !

K  

Ä𝑖 ∈N

= wp

𝐶1
J

K  

Ä𝑖 ∈N

wp

𝐶2
J

K

( 𝑓𝑖 )

!

=

=

Ä𝑖 ∈N

Ä𝑖 ∈N

wp

𝐶1
J

K

( wp

𝐶2
J

K

( 𝑓𝑖 ) )

wp

𝐶
J

K

( 𝑓𝑖 )

(Def. of wp)

(Induction Hypothesis)

(Induction Hypothesis)

(Def. of wp)

• The program 𝐶 is of the form if ( 𝜑 ) { 𝐶1 } else { 𝐶2 }. This is an immediate consequence

of Lemma A.3 and the module’s 𝜔-continuity.

wp

𝐶
J

𝑓𝑖

!

K  

Ä𝑖 ∈N

(Def. of wp)

= [𝜑] wp

𝐶1
J

K  

Ä𝑖 ∈N

𝑓𝑖

!

⊕ [¬𝜑] wp

𝐶2
J

K  

Ä𝑖 ∈N

𝑓𝑖

!

(Induction Hypothesis)

= [𝜑]

wp

𝐶1
J

K

(cid:16) Ä𝑖 ∈N

( 𝑓𝑖 )

⊕ [¬𝜑]

(cid:17)

wp

𝐶2
J

K

(cid:16) Ä𝑖 ∈N

( 𝑓𝑖 )

(cid:17)

(0, ⊤ are 𝜔-continuous)

=

=

=

[𝜑] wp

𝐶1
J

K

(cid:16) Ä𝑖 ∈N

( 𝑓𝑖 )

⊕

(cid:17)

(cid:16) Ä𝑖 ∈N

[¬𝜑] wp

( 𝑓𝑖 )

𝐶2
J
(⊕ is 𝜔-continuous, Lemma C.1)

K

(cid:17)

( 𝑓𝑖 ) ⊕ [¬𝜑] wp

( 𝑓𝑖 )

𝐶2
J

K

(cid:1)

(Def. of wp)

[𝜑] wp

𝐶1
J

K

Ä𝑖 ∈N

(cid:0)

wp

𝐶
J

K

( 𝑓𝑖 )

Ä𝑖 ∈N

Weighted Programming

43

• The program 𝐶 is of the form { 𝐶1 } ⊕ { 𝐶2 }. This is an immediate consequence of Lemma A.3

and the 𝜔-continuity of ⊕.

wp

𝐶
J

𝑓𝑖

!

K  

Ä𝑖 ∈N

= wp

𝐶1
J

K  

Ä𝑖 ∈N

𝑓𝑖

!

⊕ wp

𝐶2
J

K  

Ä𝑖 ∈N

𝑓𝑖

!

(Def. of wp)

(Induction Hypothesis)

=

=

=

wp

𝐶1
J

K

(cid:16) Ä𝑖 ∈N

( 𝑓𝑖 )

⊕

(cid:17)

(cid:16) Ä𝑖 ∈N

wp

𝐶2
J

( 𝑓𝑖 )

K
(⊕ is 𝜔-continuous, Lemma C.1)

(cid:17)

wp

𝐶1
J

K

Ä𝑖 ∈N

(cid:0)

( 𝑓𝑖 ) ⊕ wp

( 𝑓𝑖 )

𝐶2
J

K

(cid:1)

wp

𝐶
J

K

( 𝑓𝑖 )

Ä𝑖 ∈N

(Def. of wp)

• The program 𝐶 is of the form while ( 𝜑 ) { 𝐶 ′ }. First we show the loop-characteristic func-

tion

Φ𝑓 : W → W,

𝑔 ↦→ [¬𝜑] 𝑓 ⊕ [𝜑] wp

( 𝑔 )

𝐶 ′
J

K

to be 𝜔-continuous in both 𝑓 and its argument 𝑔.

Φ

𝑖∈N 𝑓𝑖

Ã

= 𝜆 𝑔. [¬𝜑]

𝑓𝑖

⊕ [𝜑] wp

(cid:16) Ä𝑖 ∈N

(cid:17)

= 𝜆 𝑔.

[¬𝜑] 𝑓𝑖

⊕ [𝜑] wp

(cid:16) Ä𝑖 ∈N

(cid:17)

( 𝑔 )

𝐶 ′
J

K

( 𝑔 )

𝐶 ′
J

K

( 𝑔 )

𝐶 ′
J

K

( 𝑔 )

𝐶 ′
J

K

(cid:17)

(cid:17)

= 𝜆 𝑔.

[¬𝜑] 𝑓𝑖 ⊕ [𝜑] wp

Ä𝑖 ∈N

(cid:16)

=

=

𝜆 𝑔. [¬𝜑] 𝑓𝑖 ⊕ [𝜑] wp

Ä𝑖 ∈N

(cid:16)

Φ𝑓𝑖

Ä𝑖 ∈N

(Def. of Φ𝑓 )

(0, ⊤ are 𝜔-continuous)

(⊕ is 𝜔-continuous)

(Def. of ⊔ on SW)

(Def. of Φ𝑓 )

44

Batz, Gallus, Kaminski, Katoen, and Winkler

Let (𝑔𝑖 )𝑖 ∈N be an (ascending) 𝜔-chain in W.

Φ𝑓

𝑔𝑖

(cid:16) Ä𝑖 ∈N

(cid:17)

= [¬𝜑] 𝑓 ⊕ [𝜑] wp

𝐶 ′
J

𝑔𝑖

!

K  

Ä𝑖 ∈N

= [¬𝜑] 𝑓 ⊕ [𝜑]

wp

𝐶 ′
J

K

( 𝑔𝑖 )

(cid:16) Ä𝑖 ∈N

= [¬𝜑] 𝑓 ⊕

[𝜑] wp

Ä𝑖 ∈N

(cid:0)

=

=

[¬𝜑] 𝑓 ⊕ [𝜑] wp

Ä𝑖 ∈N

(cid:0)

Φ𝑓 (𝑔𝑖 )

( 𝑔𝑖 )

𝐶 ′
J

K

( 𝑔𝑖 )

𝐶 ′
J

K

(cid:17)

(cid:1)

(cid:1)

(Def. of Φ𝑓 )

(Induction Hypothesis)

(0, ⊤ are 𝜔-continuous)

(⊕ is 𝜔-continuous)

(Def. of Φ𝑓 )

Ä𝑖 ∈N

while ( 𝜑 ) { 𝐶 ′ }
( 𝑓 ) is well deﬁned and equals the
By Theorem A.4 the ﬁxed point wp
claimed expression. It is 𝜔-continuous in 𝑓 by 𝜔-continuity of 𝑓 ↦→ Φ𝑓 and the ﬁxed-point
J
operator lfp, e.g. [Abramsky 1994, Ch. Domain Theory, Thm. 2.1.19].

K

C.2 Proof of Theorem 4.9 (Soundness of wp w.r.t. operational semantics)

The following proof is based on [Batz et al. 2019b, Appendix B].

Theorem C.3 (Theorem 4.9). Let the monoid module M over W be 𝜔-continuous. For any wGCL

program 𝐶, initial state 𝜎 ∈ Σ, and post-weighting 𝑓 ∈ W,

(cid:3)

( 𝑓 ) (𝜎)

=

wgt(𝜋) ⊙ 𝑓 (last(𝜋)) .

wp

𝐶
J

K

Ê𝜋 ∈TPathsh𝐶, 𝜎, 𝑛, 𝑣i
Proof. We use a few auxiliary deﬁnitions and lemmas that can be found below. By Lemma C.7
˜wp also is a wGCL-functional due to Lemma C.8, we get
˜wp (cid:22) ˜op by Lemma C.11. Both imply ˜wp = ˜op. Now, wp = op due to
(cid:3)

˜op is the least wGCL-functional. As
˜op (cid:22) ˜wp. On the other hand,
Deﬁnition C.4. This is the above claim by Deﬁnition C.6.

Deﬁnition C.4. A map Φ : wGCL → (W → W) is called weighting transformer. The correspond-

ing extended weighting transformer ˜Φ : (wGCL ∪ { ↓ }) → (W → W) is deﬁned via

( 𝑓 ) ≔

˜Φ

𝐶
J

𝑓
Φ

if 𝐶 = ↓
otherwise

𝐶
J
for all 𝐶 ∈ wGCL ∪ { ↓ } and 𝑓 ∈ W. Deﬁne the partial order (cid:22) for weighting transformers Φ, Ψ
via

(

K

K

( 𝑓 )

˜Φ (cid:22) ˜Ψ

iﬀ

( 𝑓 ) (cid:22) Ψ

Φ

𝐶
J

K

𝐶
J

K

( 𝑓 ) for all 𝐶 ∈ wGCL, 𝑓 ∈ W .

△

Weighted Programming

45

Deﬁnition C.5. An extended weighting transformer ˜Φ is called wGCL-functional if for all wGCL

programs 𝐶, postweightings 𝑓 ∈ W, states 𝜎 ∈ Σ, 𝑛 ∈ N, and 𝛽 ∈ { 𝐿, 𝑅 }∗,

˜Φ

𝐶
J

K

( 𝑓 ) (𝜎)

=

𝑎 ⊙ ˜Φ

( 𝑓 ) (𝜎 ′) .

△

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i
Deﬁnition C.6. The map op : wGCL → (W → W) is deﬁned for any wGCL program 𝐶, state

𝐶 ′
J

K

𝜎 ∈ Σ, and post-weighting 𝑓 ∈ W via

( 𝑓 ) (𝜎) ≔

wgt(𝜋) ⊙ 𝑓 (last(𝜋)) .

△

op

𝐶
J

K

Ê𝜋 ∈TPathsh𝐶, 𝜎, 0, 𝜖i
Lemma C.7. The map ˜op is the least wGCL-functional.

Proof. First, we show that

˜op is a wGCL-functional. Given a conﬁguration 𝜅0 = h𝐶, 𝜎, 𝑛, 𝛽i,

where 𝐶 is a wGCL program and 𝜎 ∈ Σ a state, we have

=

=

=

=

=

=

( 𝑓 ) (𝜎)

˜op

𝐶
J

K

wgt(𝜋) ⊙ 𝑓 (last(𝜋))

Ê𝜋 ∈TPaths𝜅0

(wgt(𝜅0 𝜅1) ⊙ wgt(𝜅1 . . . 𝜅𝑘 )) ⊙ 𝑓 (last(𝜅1 . . . 𝜅𝑘 ))

Ê𝜅0𝜅1...𝜅𝑘 ∈TPaths𝜅0

𝜅0 ⊢𝑎 𝜅1 Ê𝜋 ∈TPaths𝜅1
Ê

𝑎 ⊙ wgt(𝜋) ⊙ 𝑓 (last(𝜋))

𝑎 ⊙

wgt(𝜋) ⊙ 𝑓 (last(𝜋))

𝜅0 ⊢𝑎 𝜅1
Ê

Ê𝜋 ∈TPaths𝜅1

(Def. of op)

(Def. of wgt𝜋)

(split path)

(Distributivity)

(Induction on Fig. 1)

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i

Ê𝜋 ∈TPathsh𝐶′, 𝜎′, 0, 𝜖i

𝑎 ⊙

wgt(𝜋) ⊙ 𝑓 (last(𝜋))

(Def. of op)

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ ˜op

𝐶 ′
J

K

( 𝑓 ) (𝜎 ′) .

Now let ˜Φ be another wGCL-functional. We want to show that ˜op (cid:22) ˜Φ. Thus, we perform induc-
tion over the maximum length ℓ ∈ N of terminating paths from a conﬁguration 𝜅0 = h𝐶, 𝜎, 𝑛, 𝛽i.
To that end, denote

TPaths≤ℓ
𝜅0

≔

𝜅0 . . . 𝜅𝑘 ∈ TPaths𝜅0

𝑘 ≤ ℓ

and

(cid:8)

˜op≤ℓ

𝐶
J

K

( 𝑓 ) (𝜎) ≔

Ê𝜋 ∈TPaths≤ℓ
𝜅0

(cid:12)
(cid:12)

(cid:9)

wgt(𝜋) ⊙ 𝑓 (last(𝜋)) .

46

Batz, Gallus, Kaminski, Katoen, and Winkler

We prove ˜op≤ℓ
is 𝜔-ﬁnitary and hence

𝐶
J

K

( 𝑓 ) (cid:22) ˜Φ

( 𝑓 ) for all ℓ ∈ N, then the claim follows because the module M

𝐶
J

K

˜op

𝐶
J

K

( 𝑓 ) =

˜op≤ℓ

Äℓ ∈N

( 𝑓 ) (cid:22) ˜Φ

𝐶
J

K

( 𝑓 ) .

𝐶
J

K

Moreover, we may assume 𝐶 ≠ ↓ as otherwise ˜op

( 𝑓 ).
↓
The following forms the induction base. Let ℓ = 0. Then, TPaths≤0
= ∅ and
K
J
𝜅0

( 𝑓 ) = 𝑓 = ˜𝐶

𝐶
J

K

The following forms the induction step. Let ℓ ∈ N such that ˜op≤ℓ

˜op≤0

( 𝑓 ) = 0 (cid:22) ˜Φ

( 𝑓 ) .

𝐶
J

K

𝐶
J

K

˜op≤ℓ+1

𝐶
J

K

( 𝑓 ) (𝜎)

( 𝑓 ) (cid:22) ˜Φ

𝐶
J

K

( 𝑓 ).

𝐶
J

K

(wGCL-functional)

=

(cid:22)

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ ˜op≤ℓ

( 𝑓 ) (𝜎 ′)

𝐶 ′
J

K

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ ˜Φ

𝐶 ′
J

K

( 𝑓 ) (𝜎 ′)

= ˜Φ

𝐶
J

K

( 𝑓 ) (𝜎) .

(Induction Hypothesis)

(wGCL-functional)

(cid:3)

Lemma C.8. The map ˜wp is a wGCL-functional.

Proof. We employ structural induction on the rules from Fig. 1 grouped by the structure of 𝐶.
The following forms the induction base.
• The program 𝐶 is of the form 𝑥 ≔ 𝐸.

( 𝑓 ) (𝜎)

˜wp

𝐶
J

K

= 𝑓 [𝑥/𝐸] (𝜎)

= 𝑓 (𝜎 [𝑥 ↦→ 𝜎 (𝐸)])

( 𝑓 ) (𝜎 [𝑥 ↦→ 𝜎 (𝐸)])

= ˜wp

↓
K
J

=

𝑎 ⊙ ˜wp

𝐶 ′
J

K

( 𝑓 ) (𝜎 ′)

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i

• The program 𝐶 is of the form ⊙ 𝑎.

(Def. of wp)

(Def. of 𝑓 [𝑥/𝐸])

(Def. of

˜wp)

(Fig. 1 (assign))

Weighted Programming

47

( 𝑓 ) (𝜎)

˜wp

𝐶
J

K

= (𝑎 ⊙ 𝑓 ) (𝜎)

= 𝑎 ⊙ ˜wp

( 𝑓 ) (𝜎)

↓
K
J

=

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ ˜wp

𝐶 ′
J

K

( 𝑓 ) (𝜎 ′)

(Def. of wp)

(Def. of

˜wp)

(Fig. 1 (weight))

The following forms the induction step.

• The program 𝐶 is of the form 𝐶1

𝐶2.

#
There are the following two exclusive cases by the rules from Fig. 1:
(1) Case h𝐶1, 𝜎, 𝑛, 𝛽i ⊢𝑎 h↓, 𝜎 ′, 𝑛 + 1, 𝛽 ′i.

( 𝑓 ) (𝜎)

˜wp

𝐶
J

K

= ˜wp

𝐶1
J

K

(

˜wp

𝐶2
J

K

( 𝑓 ) ) (𝜎)

(Def. of wp)

(Induction Hypothesis)

=

=

=

Êh𝐶1, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h↓, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ ˜wp

↓
K
J

(

˜wp

𝐶2
J

K

( 𝑓 ) ) (𝜎 ′)

Êh𝐶1, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h↓, 𝜎′, 𝑛+1, 𝛽′ i

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ ˜wp

𝑎 ⊙ ˜wp

𝐶2
J

K

𝐶 ′
J

K

( 𝑓 ) (𝜎 ′)

( 𝑓 ) (𝜎 ′)

(Def. of

˜wp)

(Fig. 1 (seq. 1))

(2) Case h𝐶1, 𝜎, 𝑛, 𝛽i ⊢𝑎 h𝐶 ′

1, 𝜎 ′, 𝑛 + 1, 𝛽 ′i.

48

Batz, Gallus, Kaminski, Katoen, and Winkler

( 𝑓 ) (𝜎)

˜wp

𝐶
J

K

= ˜wp

𝐶1
J

K

(

˜wp

𝐶2
J

K

( 𝑓 ) ) (𝜎)

(Def. of wp)

(Induction Hypothesis)

h𝐶1, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′
Ê

1, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ ˜wp

𝐶 ′
1
J

K

(

˜wp

𝐶2
J

K

( 𝑓 ) ) (𝜎 ′)

h𝐶1, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′
Ê

1, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ ˜wp

𝐶 ′
1
J

#

𝐶2

( 𝑓 ) (𝜎 ′)

K

(Def. of wp)

(Fig. 1 (seq. 1))

=

=

=

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i
• The program 𝐶 is of the form if ( 𝜑 ) { 𝐶1 } else { 𝐶2 }.

𝑎 ⊙ ˜wp

( 𝑓 ) (𝜎 ′)

𝐶 ′
J

K

There are the following two exclusive cases:

(1) Case 𝜎 |= 𝜑.

( 𝑓 ) (𝜎)

˜wp

𝐶
J

K

= ( [𝜑]

˜wp

𝐶1
J

K

( 𝑓 ) ⊕ [¬𝜑]

˜wp

( 𝑓 )) (𝜎)

𝐶2
J

K

= ˜wp

𝐶1
J

K

( 𝑓 ) (𝜎)

=

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ ˜wp

𝐶 ′
J

K

( 𝑓 ) (𝜎 ′)

(2) Case 𝜎 6|= 𝜑.

( 𝑓 ) (𝜎)

˜wp

𝐶
J

K

= ( [𝜑]

˜wp

𝐶1
J

K

( 𝑓 ) ⊕ [¬𝜑]

˜wp

( 𝑓 )) (𝜎)

𝐶2
J

K

= ˜wp

𝐶2
J

K

( 𝑓 ) (𝜎)

=

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i
• The program 𝐶 is of the form { 𝐶1 } ⊕ { 𝐶2 }.

𝑎 ⊙ ˜wp

𝐶 ′
J

K

( 𝑓 ) (𝜎 ′)

(Def. of wp)

(Case 𝜎 |= 𝜑)

(Fig. 1 (if))

(Def. of wp)

(Case 𝜎 6|= 𝜑)

(Fig. 1 (else))

Weighted Programming

49

( 𝑓 ) (𝜎)

˜wp

𝐶
J

K

(Def. of wp)

= ˜wp

𝐶1
J

K

( 𝑓 ) (𝜎) ⊕ ˜wp

( 𝑓 ) (𝜎)

𝐶2
J

K

(Fig. 1 (l. branch), (r. branch))

=

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ ˜wp

𝐶 ′
J

K

( 𝑓 ) (𝜎 ′)

• The program 𝐶 is of the form while ( 𝜑 ) { 𝐶1 }.
There are the following two exclusive cases:

(1) Case 𝜎 |= 𝜑.

( 𝑓 ) (𝜎)

˜wp

𝐶
J

K

= ( [¬𝜑] 𝑓 ⊕ [𝜑] wp

𝐶1
J

K

( wp

𝐶
J

K

( 𝑓 ) )) (𝜎)

= wp

𝐶1
J

K

( wp

𝐶
J

K

( 𝑓 ) ) (𝜎)

= wp

𝐶1
J

𝐶

( 𝑓 ) (𝜎)

#

K

=

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ ˜wp

𝐶 ′
J

K

( 𝑓 ) (𝜎 ′)

(2) Case 𝜎 6|= 𝜑.

( 𝑓 ) (𝜎)

˜wp

𝐶
J

K

= ( [¬𝜑] 𝑓 ⊕ [𝜑] wp

𝐶1
J

K

( wp

𝐶
J

K

( 𝑓 ) )) (𝜎)

= 𝑓 (𝜎)

= ˜wp

↓
K
J

( 𝑓 ) (𝜎)

=

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ ˜wp

𝐶 ′
J

K

( 𝑓 ) (𝜎 ′)

Lemma C.9. Let 𝐶1, 𝐶2 be wGCL programs and 𝑓 ∈ W, then

(Def. of wp)

(Case 𝜎 |= 𝜑)

(Def. of wp)

(Fig. 1 (while))

(Def. of wp)

(Case 𝜎 6|= 𝜑)

(Def. of

˜wp)

(Fig. 1 (break))

(cid:3)

△

Proof. Consider any state 𝜎 ∈ Σ. We employ structural induction on the rules from Fig. 1.

𝐶2

( 𝑓 ) = op

op

𝐶1
J

#

K

𝐶1
J

K

( op

( 𝑓 ) ) .

𝐶2
J

K

50

Batz, Gallus, Kaminski, Katoen, and Winkler

The following forms the induction base. The case h𝐶1, 𝜎, 𝑛, 𝛽i ⊢𝑎 h↓, 𝜎 ′, 𝑛 + 1, 𝛽 ′i.

˜op

𝐶1
J

#

𝐶2

( 𝑓 ) (𝜎)

K

=

=

h𝐶1 # 𝐶2, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i
Ê

𝑎 ⊙ ˜op

𝐶 ′
J

K

( 𝑓 ) (𝜎 ′)

Êh𝐶1, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h↓, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ ˜op

𝐶2
J

K

( 𝑓 ) (𝜎 ′)

= ˜op

𝐶1
J

K

( ˜op

𝐶2
J

K

( 𝑓 ) ) (𝜎)

(wGCL-functional)

(Fig. 1 (seq. 1))

(wGCL-functional)

The following forms the induction step. The case h𝐶1, 𝜎, 𝑛, 𝛽i ⊢𝑎 h𝐶 ′

1, 𝜎 ′, 𝑛 + 1, 𝛽 ′i.

˜op

𝐶1
J

#

𝐶2

( 𝑓 ) (𝜎)

K

h𝐶1 # 𝐶2, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i
Ê

𝑎 ⊙ ˜op

𝐶 ′
J

K

( 𝑓 ) (𝜎 ′)

h𝐶1, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′
Ê

1, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ ˜op

𝐶 ′
1
J

#

𝐶2

( 𝑓 ) (𝜎 ′)

K

(wGCL-functional)

(Fig. 1 (seq. 1))

(Induction Hypothesis)

h𝐶1, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′
Ê

1, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ ˜op

𝐶 ′
1
J

K

( ˜op

𝐶2
J

K

( 𝑓 ) ) (𝜎 ′)

=

=

=

(wGCL-functional)

(cid:3)

= ˜op

𝐶1
J

K

( ˜op

𝐶2
J

K

( 𝑓 ) ) (𝜎)

Lemma C.10. Let 𝐶 ′ be a wGCL program and 𝑓 ∈ W, then

op

while ( 𝜑 ) { 𝐶 ′ }

𝐶 ′
J
Proof. Let 𝜎 ∈ Σ be a state. We distinguish two cases:

( 𝑓 ) = [𝜑] 𝑓 ⊕ [¬𝜑] op

K

J

( op

while ( 𝜑 ) { 𝐶 ′ }

( 𝑓 ) ) .

△

K

J

K

• 𝜎 |= 𝜑.

Weighted Programming

51

op

while ( 𝜑 ) { 𝐶 ′ }

( 𝑓 ) (𝜎)

J

K

=

Êh𝐶, 𝜎, 0, 𝜖 i ⊢𝑎 h𝐶′, 𝜎′, 1, 𝛽′ i

𝑎 ⊙ ˜op

𝐶 ′
J

K

( 𝑓 ) (𝜎 ′)

= op

= op

𝐶 ′
J

#

𝐶 ′
J

K

while ( 𝜑 ) { 𝐶 ′ }

( 𝑓 ) (𝜎)

K

( op

while ( 𝜑 ) { 𝐶 ′ }

( 𝑓 ) ) (𝜎)

J

K

(wGCL-functional)

(Fig. 1 (while))

(Lemma C.9)

(Case 𝜎 |= 𝜑)

= ( [¬𝜑] 𝑓 ⊕ [𝜑] op

𝐶 ′
J

K

( op

while ( 𝜑 ) { 𝐶 ′ }

( 𝑓 ) )) (𝜎) .

J

K

• 𝜎 6|= 𝜑.

op

while ( 𝜑 ) { 𝐶 ′ }

( 𝑓 ) (𝜎)

J

K

=

Êh𝐶, 𝜎, 0, 𝜖 i ⊢𝑎 h𝐶′, 𝜎′, 1, 𝛽′ i

𝑎 ⊙ ˜op

𝐶 ′
J

K

( 𝑓 ) (𝜎 ′)

( 𝑓 ) (𝜎)

= ˜op

↓
K
J

= 𝑓 (𝜎)

(wGCL-functional)

(Fig. 1 (break))

(Deﬁnition C.4)

(Case 𝜎 6|= 𝜑)

= ( [¬𝜑] 𝑓 ⊕ [𝜑] op

𝐶 ′
J

K

( op

while ( 𝜑 ) { 𝐶 ′ }

( 𝑓 ) )) (𝜎) .

J

K

(cid:3)

△

Lemma C.11. We have ˜wp (cid:22) ˜op.

Proof. We perform induction on the structure of wGCL programs.
The following forms the induction base.

• The program 𝐶 is of the form 𝑥 ≔ 𝐸.

We have

TPaths h𝐶, 𝜎, 0, 𝜖 i =

h𝐶, 𝜎, 0, 𝜖i ⊢1 h↓, 𝜎 [𝑥 ↦→ 𝜎 (𝐸)], 1, 𝜖i

.

(cid:8)

(cid:9)

52

Hence,

Batz, Gallus, Kaminski, Katoen, and Winkler

˜op

= ˜op

𝐶
J

K

↓
K
J

( 𝑓 ) (𝜎)

( 𝑓 ) (𝜎 [𝑥 ↦→ 𝜎 (𝐸)])

= 𝑓 (𝜎 [𝑥 ↦→ 𝜎 (𝐸)])

= 𝑓 [𝑥/𝐸] (𝜎)

= ˜wp

𝐶
J

K

( 𝑓 ) (𝜎) .

• The program 𝐶 is of the form ⊙ 𝑎.

We have

Hence,

TPaths h𝐶, 𝜎, 0, 𝜖 i = { h𝐶, 𝜎, 0, 𝜖i ⊢𝑎 h↓, 𝜎, 1, 𝜖i } .

( 𝑓 ) (𝜎)

˜op

𝐶
J

K

= 𝑎 ⊙ ˜op

( 𝑓 ) (𝜎)

↓
K
J

= 𝑎 ⊙ 𝑓 (𝜎)

= ˜wp

𝐶
J

K

( 𝑓 ) (𝜎) .

(wGCL-functional)

(Def. of ˜op)

(Def. of 𝑓 [𝑥/𝐸])

(Def. of wp)

(wGCL-functional)

(Def. of ˜op)

(Def. of wp)

The following forms the induction step.

• The program 𝐶 is of the form 𝐶1

𝐶2.

#

( 𝑓 ) (𝜎)

˜wp

𝐶
J

K

= ˜wp

(cid:22) ˜wp

𝐶1
J

K

𝐶1
J

K

(

˜wp

𝐶2
J

K

( ˜op

𝐶2
J

K

(Def. of wp)

( 𝑓 ) ) (𝜎)

(Monotonicity; Induction Hypothesis on 𝐶2)

( 𝑓 ) ) (𝜎)

(Induction Hypothesis on 𝐶1)

( 𝑓 ) ) (𝜎)

(cid:22) ˜op

= ˜op

𝐶1
J

K

𝐶
J

K

( ˜op

𝐶2
J

K

( 𝑓 ) (𝜎) .

(Lemma C.9)

• The program 𝐶 is of the form { 𝐶1 } ⊕ { 𝐶2 } or if ( 𝜑 ) { 𝐶1 } else { 𝐶2 }.

Weighted Programming

53

( 𝑓 ) (𝜎)

˜wp

𝐶
J

K

Êh𝐶, 𝜎, 0, 𝜖 i ⊢𝑎 h𝐶′, 𝜎′, 1, 𝛽′ i

(wGCL-functional)

𝑎 ⊙ ˜wp

𝐶 ′
J

K

( 𝑓 ) (𝜎 ′)

(Induction Hypothesis on 𝐶 ′ ∈ { 𝐶1, 𝐶2 })

Êh𝐶, 𝜎, 0, 𝜖 i ⊢𝑎 h𝐶′, 𝜎′, 1, 𝛽′ i

𝑎 ⊙ ˜op

𝐶 ′
J

K

( 𝑓 ) (𝜎 ′)

(wGCL-functional)

=

(cid:22)

= ˜op

𝐶
J

K

( 𝑓 ) (𝜎)

• The program 𝐶 is of the form while ( 𝜑 ) { 𝐶 ′ }.

Let Φ𝑓 be the corresponding characteristic function

Φ𝑓 (𝑋 ) ≔ [¬𝜑] 𝑓 ⊕ [𝜑] wp

i. e. wp

𝐶
J

K

( 𝑓 ) = lfp Φ𝑓 . The map ˜op

𝐶
J
K
( 𝑓 ))

Φ𝑓 ( ˜op

𝐶
J

K

( 𝑋 ) ,

𝐶 ′
J

K
( 𝑓 ) is a preﬁxed point of Φ𝑓 :

= [¬𝜑] 𝑓 ⊕ [𝜑] wp

(cid:22) [¬𝜑] 𝑓 ⊕ [𝜑] ˜op

𝐶 ′
J

K

𝐶 ′
J

K

( ˜op

( ˜op

𝐶
J

K

𝐶
J

K

= ˜op

𝐶
J

K

( 𝑓 ) .

(Def. of Φ𝑓 )

( 𝑓 ) )

(Induction Hypothesis on 𝐶 ′)

( 𝑓 ) )

(Lemma C.10)

With Theorem A.4 it follows ˜wp

𝐶
J

K

( 𝑓 ) (cid:22) ˜op

( 𝑓 ).

𝐶
J

K

(cid:3)

C.3 Proof of Theorem 4.8

Theorem C.12 (Theorem 4.8). Let the monoid module M over W be 𝜔-continuous. For all W-

wGCL programs 𝐶, the wp transformer is

• monotone, i.e. for all 𝑓 , 𝑔 ∈ W with 𝑓 (cid:22) 𝑔, wp
• strict, i.e. wp
𝐶
• additive, i.e. for all 𝑓 , 𝑔 ∈ W, wp
J
• and moreover, if the monoid W is commutative, then wp is linear, i.e. for all 𝑎 ∈ 𝑊 ,

𝐶
J
( 𝑓 ⊕ 𝑔 ) = wp

K
( 𝑓 ) ⊕ wp

( 0 ) = 0 ;

( 𝑓 ) (cid:22) wp

( 𝑔 ) ;

𝐶
J

𝐶
J

𝐶
J

𝐶
J

K

K

K

K

K

( 𝑔 ) ;

wp

𝐶
J

K

( 𝑎 ⊙ 𝑓 ) = 𝑎 ⊙ wp

( 𝑓 ) .

𝐶
J

K

△

Proof.

• Monotonicity. Follows directly from 𝜔-continuity of wp

𝐶
J

, Theorem 4.7.
K

54

Batz, Gallus, Kaminski, Katoen, and Winkler

• Strictness. Follows from Theorem 4.9 and annihilation of 0: Let 𝜎 ∈ Σ.

wp

𝐶
J

K

( 0 ) (𝜎)

wgt(𝜋) ⊙ 0(last(𝜋))

Ê𝜋 ∈TPathsh𝐶, 𝜎, 𝑛, 𝑣i

0

Ê𝜋 ∈TPathsh𝐶, 𝜎, 𝑛, 𝑣i
0

=

=

=

• Additivity. Follows from Theorem 4.9: Let 𝜎 ∈ Σ and 𝑓 , 𝑔 ∈ W.

=

=

=

=

wp

𝐶
J

K

( 𝑓 ⊕ 𝑔 ) (𝜎)

wgt(𝜋) ⊙ (𝑓 ⊕ 𝑔) (last(𝜋))

Ê𝜋 ∈TPathsh𝐶, 𝜎, 𝑛, 𝑣i

Ê𝜋 ∈TPathsh𝐶, 𝜎, 𝑛, 𝑣i

Ê𝜋 ∈TPathsh𝐶, 𝜎, 𝑛, 𝑣i

Ê𝜋 ∈TPathsh𝐶, 𝜎, 𝑛, 𝑣i

wgt(𝜋) ⊙ (𝑓 (last(𝜋) ⊕ 𝑔(last(𝜋))

wgt(𝜋) ⊙ 𝑓 (last(𝜋) ⊕ wgt(𝜋) ⊙ 𝑔(last(𝜋))

wgt(𝜋) ⊙ 𝑓 (last(𝜋)

⊕

wgt(𝜋) ⊙ 𝑔(last(𝜋))

= wp

( 𝑓 ) (𝜎) ⊕ wp

( 𝑔 ) (𝜎)

Ê𝜋 ∈TPathsh𝐶, 𝜎, 𝑛, 𝑣i

𝐶
J

𝐶
J

K
• Linearity. Let the monoid W be commutative; we apply Theorem 4.9: As additivity always

K

holds, we only have to show homogenity. Let 𝜎 ∈ Σ, 𝑎 ∈ 𝑊 and 𝑓 ∈ W.

=

=

=

=

=

=

=

wp

𝐶
J

K

( 𝑎 ⊙ 𝑓 ) (𝜎)

wgt(𝜋) ⊙ (𝑎 ⊙ 𝑓 ) (last(𝜋))

Ê𝜋 ∈TPathsh𝐶, 𝜎, 𝑛, 𝑣i

Ê𝜋 ∈TPathsh𝐶, 𝜎, 𝑛, 𝑣i

Ê𝜋 ∈TPathsh𝐶, 𝜎, 𝑛, 𝑣i

Ê𝜋 ∈TPathsh𝐶, 𝜎, 𝑛, 𝑣i

Ê𝜋 ∈TPathsh𝐶, 𝜎, 𝑛, 𝑣i
𝑎 ⊙

wgt(𝜋) ⊙ (𝑎 ⊙ 𝑓 (last(𝜋))

(wgt(𝜋) ⊙ 𝑎) ⊙ 𝑓 (last(𝜋)

(𝑎 ⊙ wgt(𝜋)) ⊙ 𝑓 (last(𝜋)

𝑎 ⊙ (𝑎 ⊙ wgt(𝜋) ⊙ 𝑓 (last(𝜋))

wgt(𝜋) ⊙ 𝑓 (last(𝜋)

𝑎 ⊙ wp

Ê𝜋 ∈TPathsh𝐶, 𝜎, 𝑛, 𝑣i
𝐶
J

K

( 𝑓 ) (𝜎)

(cid:3)

Weighted Programming

55

C.4 Proof of Theorem 4.13

Theorem C.13 (Theorem 4.13). Let M be an 𝜔-cocontinuous W-module. For all W-wGCL pro-
is a well-deﬁned 𝜔-cocontinuous endofunction on the

grams 𝐶, the weighting transformer wlp
module of weightings over M. In particular, if 𝐶 = while ( 𝜑 ) { 𝐶 ′ }, we have for all 𝑓 ∈ W that

𝐶
J

K

wlp

𝐶
J

K

( 𝑓 )

= l
𝑖 ∈N

Ψ𝑖
𝑓 (⊤) .

Proof. Fully analogous to Theorem 4.7.

△

(cid:3)

C.5 Proof of Theorem 4.14
Let M be an 𝜔-bicontinuous W-module. First we need an auxiliary lemma.

Lemma C.14. Let (𝑎𝑖 )𝑖 ∈N be an ascending 𝜔-chain and (𝑏𝑖)𝑖 ∈N be a descending 𝜔-chain in an 𝜔-
bicontinuous module. Furthermore, suppose that (𝑐𝑖 )𝑖 ∈N is a descending 𝜔-chain such that for all 𝑖 ∈ N
it holds that 𝑐𝑖 = 𝑎𝑖 ⊕ 𝑏𝑖. Then we have

Proof. Let 𝑎𝜔 ≔

=

𝑎𝑖 ⊕ l
𝑖 ∈N

𝑏𝑖 .

Ä𝑖 ∈N

𝑐𝑖

l
𝑖 ∈N
𝑖 ∈N 𝑎𝑖 . We have
= l
𝑖 ∈N

(cid:22) l
𝑖 ∈N
where the last equality holds by 𝜔-cocontinuity of ⊕.

(𝑎𝑖 ⊕ 𝑏𝑖)

l
𝑖 ∈N

Ã

𝑐𝑖

(𝑎𝜔 ⊕ 𝑏𝑖)

=

𝑎𝜔 ⊕ l
𝑖 ∈N

𝑏𝑖 ,

To prove the inequality in the other direction we will make use of the following auxiliary claim:

Claim. Suppose that (𝑥𝑖 )𝑖 ∈N is an ascending 𝜔-chain and (𝑦𝑖 )𝑖 ∈N is a descending 𝜔-chain such
𝑖 ∈N 𝑥𝑖 (cid:22) d𝑖 ∈N 𝑦𝑖 .

that for all 𝑖 ∈ N we have 𝑥𝑖 (cid:22) 𝑦𝑖 . Then

Proof of Claim. We ﬁrst show the following:

Ã

𝑥𝑖 (cid:22) 𝑦 𝑗 .
To this end let 𝑖, 𝑗 be arbitrary. There are two cases to consider:

∀𝑖 ∈ N ∀𝑗 ∈ N :

(1) 𝑖 ≤ 𝑗 . By assumption, 𝑥 𝑗 (cid:22) 𝑦 𝑗 . Further, since the 𝑥’s form an ascending chain, we have

𝑥𝑖 (cid:22) 𝑥 𝑗 .

(2) 𝑖 > 𝑗 . By assumption, 𝑥𝑖 (cid:22) 𝑦𝑖 . Further, since the 𝑦’s form a descending chain, we have

𝑦𝑖 (cid:22) 𝑦 𝑗 .

In both cases, 𝑥𝑖 (cid:22) 𝑦 𝑗 holds. Now ﬁx 𝑛 ∈ N. We just have shown that 𝑥𝑖 (cid:22) 𝑦𝑛 for all 𝑖 ∈ N. Thus
𝑖 ∈N 𝑥𝑖 (cid:22) 𝑦𝑛. Since 𝑛 was arbitrary, we ﬁnally obtain
by deﬁnition of
(cid:3)

we immediately have

𝑖 ∈N 𝑥𝑖 (cid:22) d𝑖 ∈N 𝑦𝑖 by deﬁnition of d.
To conclude the proof of Lemma C.14, let 𝑏𝜔 ≔

Ã

Ã

Ã

d𝑖 ∈N 𝑏𝑖 and note that for all 𝑖 ∈ N,

and that (𝑎𝑖 ⊕ 𝑏𝜔 )𝑖 ∈N is an ascending 𝜔-chain. Invoking the auxiliary claim above, we obtain

𝑎𝑖 ⊕ 𝑏𝜔

(cid:22)

𝑎𝑖 ⊕ 𝑏𝑖

(cid:22) 𝑐𝑖

Noticing that

𝑖 ∈N (𝑎𝑖 ⊕ 𝑏𝜔 ) = (

(𝑎𝑖 ⊕ 𝑏𝜔)

(cid:22) l
𝑖 ∈N

𝑐𝑖 .

Ä𝑖 ∈N
𝑖 ∈N 𝑎𝑖 ) ⊕ 𝑏𝜔 by 𝜔-continuity of ⊕ concludes the proof.

(cid:3)

Theorem C.15 (Theorem 4.14). Let M be an 𝜔-bicontinuous W-module. Let 𝐶 be a W-wGCL

Ã

Ã
program and M an 𝜔-bicontinuous W-module. Then for all 𝑓 ∈ W,
( 𝑓 )
𝐶
J

( 𝑓 ) ⊕ wlp

= wp

𝐶
J

𝐶
J

wlp

K

K

( 0 ) .

K

56

Batz, Gallus, Kaminski, Katoen, and Winkler

Proof. We employ induction on the structure of 𝐶. Let 𝑓 ∈ W be an arbitrary postweighting.

• The cases where 𝐶 is of the form 𝑥 ≔ 𝐸 or ⊙ 𝑎. Then wlp

( 0 ) = 0.

wp

𝐶
J

• 𝐶 is of the form 𝐶1

K

𝐶2.

= wp

𝐶
J

K

𝐶
J

K

and thus wlp

( 0 ) =

𝐶
J

K

#
In this case, we have

wlp

= wlp

= wlp

𝐶1
J

#

𝐶1
J

K

𝐶1
J

K

𝐶2

( 𝑓 )

K

( wlp

𝐶2
J

K

( 𝑓 ) )

( wp

𝐶2
J

K

( 𝑓 ) ⊕ wlp

𝐶2
J

K

𝐶2
J

K

( 0 ) )

( 0 ) ) ⊕ wlp

( 0 )

𝐶1
J

K

( 𝑓 ) ⊕ wlp

( 𝑓 ) ) ⊕ wp

( 𝑓 ) ) ⊕ wlp

𝐶1
J

K

𝐶1
J

K

( wlp

( wlp

𝐶2
J

K

𝐶2
J

K

( 0 ) ) ⊕ wlp

( 0 ) )

( wp

( wp

( wp

𝐶2
J

K

𝐶2
J

K

𝐶2
J

K

= wp

= wp

= wp

= wp

𝐶1
J

K

𝐶1
J

K

𝐶1
J

K

𝐶1
J

#

𝐶2

( 𝑓 ) ⊕ wlp

K

( 0 ) .

𝐶2

𝐶1
J

#

K

• 𝐶 is of the form if ( 𝜑 ) { 𝐶1 } else { 𝐶2 }.

wlp

if ( 𝜑 ) { 𝐶1 } else { 𝐶2 }

( 𝑓 )

J

[𝜑] wlp

[𝜑] (wp

𝐶1
J

K

𝐶1
J

K

K

( 𝑓 ) ⊕ [¬𝜑] wlp

( 𝑓 )

𝐶2
J

K

( 𝑓 ) ⊕ wlp

𝐶1
J

K

( 0 )) ⊕ [¬𝜑] (wp

𝐶2
J

K

[𝜑] wp

𝐶1
J
[¬𝜑] wp

K
𝐶2
J

K

( 𝑓 ) ⊕ [𝜑] wlp

𝐶1
J
( 𝑓 ) ⊕ [¬𝜑] wlp

( 0 )

K
𝐶2
J

( 0 )

K

[𝜑] wp

[𝜑] wlp

𝐶1
K
J
𝐶1
J

K

( 𝑓 ) ⊕ [¬𝜑] wp
𝐶2
K
J
( 0 ) ⊕ [¬𝜑] wlp
𝐶2
J

( 𝑓 )
( 0 )

K

=

=

=

⊕

=

⊕

(Def. of wlp)

(I.H. for 𝐶2)

(I.H. for 𝐶1)

(Additivity of wp)
( 0 )
(I.H. for 𝐶1)

𝐶1
J

K

(Def. of wp and wlp)

(Def. of wlp)

( 𝑓 ) ⊕ wlp

(I.H. on 𝐶1 and 𝐶2)
( 0 ))

𝐶2
J
(Distributivity)

K

(Commutativity of ⊕)

(Def. of wp and wlp)

= wp

if ( 𝜑 ) { 𝐶1 } else { 𝐶2 }

( 𝑓 ) ⊕ wlp

J

K

if ( 𝜑 ) { 𝐶1 } else { 𝐶2 }
J

K

( 0 ) .

Weighted Programming

57

• 𝐶 is of the form { 𝐶1 } ⊕ { 𝐶2 }.

wlp

{ 𝐶1 } ⊕ { 𝐶2 }

( 𝑓 )

= wlp

= wp

= wp

J

𝐶1
J

K

𝐶1
J

K

𝐶1
J

K

K

( 𝑓 ) ⊕ wlp

( 𝑓 )

𝐶2
J

K

( 𝑓 ) ⊕ wlp

( 𝑓 ) ⊕ wp

𝐶1
J

K

𝐶2
J

K

( 0 ) ⊕ wp

( 𝑓 ) ⊕ wlp

( 𝑓 ) ⊕ wlp

( 0 ) ⊕ wlp

𝐶2
J

K

𝐶1
J

K

= wp

{ 𝐶1 } ⊕ { 𝐶2 }

( 𝑓 ) ⊕ wlp

{ 𝐶1 } ⊕ { 𝐶2 }

( 0 )

J

K

J

K

(Def. of wlp)

(I.H. on 𝐶1 and 𝐶2)

( 0 )

𝐶2
J
(Commutativity of ⊕)

K

( 0 )

𝐶2
J
(Def. of wp and wlp)

K

• 𝐶 is of the form while ( 𝜑 ) { 𝐶 ′ }.

Let Ψ𝑓 and Φ𝑓 be the wlp- and wp-characteristic functions of the loop, respectively. We claim
that for all 𝑛 ∈ N it holds that

Ψ𝑛
𝑓 (⊤)

= Φ𝑛

𝑓 (0) ⊕ Ψ𝑛

0 (⊤) .

(7)

This claim is proved by induction on 𝑛 (the I.H. of this induction is referred to as “inner I.H.”):
– 𝑛 = 0. In this case, the claim holds trivially.

58

Batz, Gallus, Kaminski, Katoen, and Winkler

=

=

=

=

=

=

=

– 𝑛 > 0.

Ψ𝑛
𝑓 (⊤)

= Ψ𝑓 (Ψ𝑛−1

𝑓

(⊤))

= Ψ𝑓

Φ𝑛−1
𝑓

(0) ⊕ Ψ𝑛−1

0 (⊤)

(cid:16)

[¬𝜑] 𝑓 ⊕ [𝜑] wlp

(cid:17)

𝐶 ′
J

K (cid:16)

[¬𝜑] 𝑓 ⊕ [𝜑]

wp

(cid:16)

[¬𝜑] 𝑓 ⊕ [𝜑]

wp

(cid:16)

𝐶 ′
J

𝐶 ′
J

K (cid:16)

K (cid:16)

(n > 0)

(inner I.H.)

(Def. of Ψ𝑓 )

(I.H.)

(cid:17) (Linearity of wp)

Φ𝑛−1
𝑓

(0) ⊕ Ψ𝑛−1

0 (⊤)

Φ𝑛−1
𝑓

(0) ⊕ Ψ𝑛−1

0 (⊤)

(cid:17)

(cid:17)

⊕ wlp

( 0 )

𝐶 ′
J

K

Φ𝑛−1
𝑓

(0)

⊕ wp

𝐶 ′
J

K (cid:16)

Ψ𝑛−1
0 (⊤)

⊕ wlp

(cid:17)

𝐶 ′
( 0 )
J
(Distributivity)

K

(cid:17)

(cid:17)

(0)

[¬𝜑] 𝑓 ⊕ [𝜑] wp

⊕ [𝜑]

wp

(cid:16)

𝐶 ′
J

K (cid:16)

Φ𝑛−1
𝑓

𝐶 ′
J
K (cid:16)
Ψ𝑛−1
0 (⊤)

(cid:17)
⊕ wlp

(cid:17)

( 0 )

𝐶 ′
J

K

(cid:17)

Φ𝑛
𝑓 (0) ⊕ [𝜑]

wp

(cid:16)

𝐶 ′
J

K (cid:16)

Ψ𝑛−1
0 (⊤)

⊕ wlp

(cid:17)

( 0 )

𝐶 ′
J

K

(cid:17)

Φ𝑛
𝑓 (0) ⊕ [𝜑]

wlp

𝑓 (0) ⊕ Ψ𝑛
Φ𝑛

(cid:16)
0 (⊤) .

Ψ𝑛−1
0 (⊤)

𝐶 ′
J

K (cid:16)

(cid:17) (cid:17)

We are now in a position to conclude the proof:

wlp

while ( 𝜑 ) { 𝐶 ′ }
J

K

( 𝑓 )

= l
𝑛 ∈N

Ψ𝑛
𝑓 (⊤)

Φ𝑛
𝑓 (0) ⊕ Ψ𝑛

0 (⊤)

= l
𝑛 ∈N

(cid:16)

(cid:17)

=

Ä𝑛 ∈N

Φ𝑛
𝑓 (0) ⊕ l
𝑛 ∈N

Ψ𝑛
0 (⊤)

(Def. of Φ𝑓 )

(I.H.)

(Def. of Ψ0)

(Theorem 4.13)

(By (7))

(Lemma C.14)

(Theorem 4.7 & Theorem 4.13)

= wp

while ( 𝜑 ) { 𝐶 ′ }
J

K

( 𝑓 ) ⊕ wlp

while ( 𝜑 ) { 𝐶 ′ }

( 0 )

J

K

Weighted Programming

59

(cid:3)

C.6 Proof of Theorem 4.15 (Soundness of wlp w.r.t. operational semantics)

Theorem C.16 (Theorem 4.15). Let the monoid module M over W be 𝜔-bicontinuous. For any

wGCL program 𝐶 and initial state 𝜎 ∈ Σ,

( 0 ) (𝜎)

wlp

𝐶
J

K

= l
𝑛 ∈N

Ê𝜋 ∈Paths𝑛

h𝐶, 𝜎 i

wgt(𝜋) ⊙ ⊤ .

Proof. We use a few auxiliary deﬁnitions and lemmas that can be found below. First, the right
hand side is well-deﬁned by Lemma C.17. Now, the claim is exactly Lemma C.21 by Deﬁnition C.18.
(cid:3)

Lemma C.17. For any wGCL program 𝐶 and state 𝜎 ∈ Σ the sequence (𝑠𝑛)𝑛 ∈N, where

𝑠𝑛 ≔

wgt(𝜋) ⊙ ⊤ ,

Ê𝜋 ∈Paths𝑛

h𝐶, 𝜎 i

is a descending 𝜔-chain.

Proof. Let 𝑛 ∈ N. Given 𝜋 ∈ Paths𝑛

h𝐶, 𝜎 i,

wgt(last(𝜋) 𝜅) ⊙ ⊤ (cid:22) ⊤ .

Ê𝜅 ∈succ(last(𝜋))

As the module’s scalar multiplication ⊙ is 𝜔-continuous and thus monotone in the second argu-
ment, it follows

𝑠𝑛+1

=

=

(cid:22)

=

wgt(𝜋) ⊙ ⊤

Ê𝜋 ∈Paths𝑛+1

h𝐶, 𝜎 i

wgt(𝜋) ⊙

wgt(last(𝜋) 𝜅) ⊙ ⊤

Ê𝜋 ∈Paths𝑛

h𝐶, 𝜎 i

Ê𝜅 ∈succ(last(𝜋))

wgt(𝜋) ⊙ ⊤

Ê𝜋 ∈Paths𝑛
𝑠𝑛 .

h𝐶, 𝜎 i

(cid:3)

Deﬁnition C.18. The map olp : wGCL → W is deﬁned for any wGCL program 𝐶 and state 𝜎 ∈ Σ

via

olp

𝐶
J

K

(𝜎) ≔ l
𝑛 ∈N

Ê𝜋 ∈Paths𝑛

h𝐶, 𝜎 i

wgt(𝜋) ⊙ ⊤ .

It is well-deﬁned by Lemma C.17.

△

Lemma C.19. The map olp behaves like a wGCL-functional (see Deﬁnition C.5):16

=

olp

𝐶
J

K

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ olp

.

𝐶 ′
J

K

16But it is not an (extended) weighting transformer.

(Deﬁnition)

(Lemma C.17)

(split 𝜅0𝜅1 . . . 𝜅𝑛)

(Distributivity)

(M is 𝜔-cocontinuous)

(Deﬁnition)

(cid:3)

△

=

𝐶1
J

K

60

Proof.

olp

(𝜎)

𝐶
J

K

Batz, Gallus, Kaminski, Katoen, and Winkler

= l
𝑛 ∈N

= l
𝑛 ∈N
𝑛 ≥2

wgt(𝜋) ⊙ ⊤

Ê𝜋 ∈Paths𝑛

h𝐶, 𝜎 i

(wgt(𝜅0 𝜅1) ⊙ wgt(𝜅1 . . . 𝜅𝑛)) ⊙ ⊤

Ê𝜅0𝜅1...𝜅𝑛 ∈Paths𝑛

h𝐶, 𝜎 i

= l
𝑛 ∈N
𝑛 ≥2 Êh𝐶, 𝜎 i ⊢𝑎 𝜅1 Ê𝜅1...𝜅𝑛 ∈Paths𝑛−1
𝜅1

𝑎 ⊙ wgt(𝜋) ⊙ ⊤

= l
𝑛 ∈N

𝑎 ⊙

wgt(𝜋) ⊙ ⊤

Êh𝐶, 𝜎 i ⊢𝑎 𝜅1

Ê𝜅1...𝜅𝑛 ∈Paths𝑛

𝜅1

=

=

𝑎 ⊙ l
𝑛 ∈N

Êh𝐶, 𝜎 i ⊢𝑎 𝜅1

Ê𝜅1...𝜅𝑛 ∈Paths𝑛

𝜅1

wgt(𝜋) ⊙ ⊤

Êh𝐶, 𝜎 i ⊢𝑎 h𝐶′, 𝜎′, 1, 𝛽 i

𝑎 ⊙ olp

𝐶 ′
J

K

Lemma C.20. For any wGCL programs 𝐶1, 𝐶2,

olp

𝐶1
K
J
Proof. Consider any state 𝜎 ∈ Σ. We employ structural induction on the rules from Fig. 1.
The following forms the induction base. The case h𝐶1, 𝜎, 𝑛, 𝛽i ⊢𝑎 h↓, 𝜎 ′, 𝑛 + 1, 𝛽 ′i. First, olp

𝐶2
J

𝐶1
J

𝐶1
J

) ⊕ olp

( olp

𝐶2

op

K

K

K

#

.

=

0 as Paths𝑛

h𝐶1, 𝜎 i

= ∅ by Fig. 1 for any 𝑛 ≥ 2. Hence,

olp

𝐶1
J

#

𝐶2

(𝜎)

K

=

=

h𝐶1 # 𝐶2, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i
Ê

𝑎 ⊙ olp

(𝜎 ′)

𝐶 ′
J

K

Êh𝐶1, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h↓, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ olp

(𝜎 ′)

𝐶2
J

K

= op

= op

𝐶1
J

K

𝐶1
J

K

( olp

( olp

𝐶2
J

K

𝐶2
J

K

) (𝜎)

) (𝜎) ⊕ olp

(𝜎)

𝐶1
J

K

(Lemma C.19)

(Fig. 1 (seq. 1))

(wGCL-functional)

= 0)

(olp

𝐶1
J

K

Weighted Programming

61

The following forms the induction step. The case h𝐶1, 𝜎, 𝑛, 𝛽i ⊢𝑎 h𝐶 ′

1, 𝜎 ′, 𝑛 + 1, 𝛽 ′i.

olp

𝐶1
J

#

𝐶2

(𝜎)

K

h𝐶1 # 𝐶2, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i
Ê

𝑎 ⊙ olp

(𝜎 ′)

𝐶 ′
J

K

h𝐶1, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′
Ê

1, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ olp

𝐶 ′
1
J

#

𝐶2

(𝜎 ′)

K

h𝐶1, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′
Ê

1, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙

op

(cid:0)

𝐶 ′
1
J

K

( olp

𝐶2
J

K

) ⊕ olp

(Lemma C.19)

(Fig. 1 (seq. 1))

(Induction Hypothesis)
𝐶 ′
1
J

(𝜎 ′)

K

(cid:1)

(Distributivity)

h𝐶1, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′
Ê

1, 𝜎′, 𝑛+1, 𝛽′ i

h𝐶1, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′
Ê

1, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ op

𝑎 ⊙ olp

𝐶 ′
1
J

K
𝐶 ′
1
J

K

( olp

𝐶2
J

K

) (𝜎 ′)

(𝜎 ′)

(wGCL-functional; Lemma C.19)

=

=

=

=

⊕

= op

𝐶1
J

K

( olp

𝐶2
J

K

𝑓 ) (𝜎) ⊕ olp

(𝜎)

𝐶1
J

K

Lemma C.21. For any wGCL program 𝐶 and state 𝜎 ∈ Σ, it is wlp

Proof. We employ induction on the structure of 𝐶.
The following forms the induction base.
• The program 𝐶 is of the form 𝑥 ≔ 𝐸. Then, Paths𝑛

h𝐶, 𝜎 i

𝐶
J

K

( 0 ) = olp

𝐶
J

.
K

(cid:3)

△

= ∅ by Fig. 1 for any 𝑛 ≥ 2, hence

• The program 𝐶 is of the form ⊙ 𝑎. Then, Paths𝑛

h𝐶, 𝜎 i

( 0 ) = 0 = olp

wlp

𝐶
J

K

.

𝐶
J
= ∅ by Fig. 1 for any 𝑛 ≥ 2, hence

K

wlp

𝐶
J

K

( 0 ) = 𝑎 ⊙ 0 = 0 = olp

.

𝐶
J

K

The following forms the induction step.
• The program 𝐶 is of the form 𝐶1
𝐶2.

#
( 0 )

( wlp

( wlp

𝐶2
J

K

𝐶2
J

K

wlp

= wlp

𝐶
J

K

𝐶1
J

K

= wp

= op

𝐶1
J

K

𝐶1
J

K

= olp

𝐶2

𝐶1
J

#

K

( 0 ) )

( 0 ) ) ⊕ wlp

𝐶1
J

K

(Def. of wlp)

(Theorem 4.14)

( 0 )

(Theorem 4.9; Induction Hypothesis)

( olp

𝐶2
J

K

) ⊕ olp

𝐶1
J

K

(Lemma C.20)

62

Batz, Gallus, Kaminski, Katoen, and Winkler

• The program 𝐶 is of the form if ( 𝜑 ) { 𝐶1 } else { 𝐶2 }. Let 𝜎 ∈ Σ be a state. There are the

following two exclusive cases:

(1) Case 𝜎 |= 𝜑.

(2) Case 𝜎 6|= 𝜑.

( 0 ) (𝜎)

wlp

𝐶
J

K

= ( [𝜑] wlp

𝐶1
J

K

( 0 ) ⊕ [¬𝜑] wlp

( 0 )) (𝜎)

𝐶2
J

K

= wlp

𝐶1
J

K

( 0 ) (𝜎)

(Def. of wlp)

(Case 𝜎 |= 𝜑)

(Fig. 1 (if))

=

=

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ wlp

( 0 ) (𝜎 ′)

𝐶 ′
J

K

(Induction Hypothesis on 𝐶1)

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ olp

(𝜎 ′)

𝐶 ′
J

K

(Lemma C.19)

= olp

(𝜎)

𝐶
J

K

( 0 ) (𝜎)

wlp

𝐶
J

K

= ( [𝜑] wlp

𝐶1
J

K

( 0 ) ⊕ [¬𝜑] wlp

( 0 )) (𝜎)

𝐶2
J

K

= wlp

𝐶2
J

K

( 0 ) (𝜎)

(Def. of wlp)

(Case 𝜎 6|= ¬𝜑)

(Fig. 1 (else))

=

=

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ wlp

( 0 ) (𝜎 ′)

𝐶 ′
J

K

(Induction Hypothesis on 𝐶2)

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ olp

(𝜎 ′)

𝐶 ′
J

K

(Lemma C.19)

= olp

(𝜎)

𝐶
J

K

Weighted Programming

63

• The program 𝐶 is of the form { 𝐶1 } ⊕ { 𝐶2 }.

( 0 ) (𝜎)

wlp

𝐶
J

K

= wlp

𝐶1
J

K

( 0 ) (𝜎) ⊕ wlp

( 0 ) (𝜎)

𝐶2
J

K

(Def. of wlp)

(Induction Hypothesis)

= olp

𝐶1
J

K

(𝜎) ⊕ olp

(𝜎)

𝐶2
J

K

=

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ olp

𝐶 ′
J

K

(Fig. 1 (l. branch), (r. branch))
(𝜎 ′)

(Lemma C.19)

= olp

(𝜎)

𝐶
J

K

• The program 𝐶 is of the form while ( 𝜑 ) { 𝐶1 }. We show that olp

loop characteristic function Ψ0 for postweight 0, where

𝐶
J

K

is a ﬁxed point of the

Ψ0 (𝑋 )

=

=

=

[¬𝜑] 0 ⊕ [𝜑] wlp
( 𝑋 )
[𝜑] wlp
𝐶1
J

K

( 𝑋 )

𝐶1
J

K

[𝜑] (wp

𝐶1
J

K

( 𝑋 ) ⊕ wlp

( 0 )) .

𝐶1
J

K

(Theorem 4.14)

(8)

Let 𝜎 ∈ Σ be a state. There are the following two exclusive cases:
(1) Case 𝜎 |= 𝜑.

Ψ0 (olp

𝐶
J

) (𝜎)
K

=

[𝜑] (wp

(cid:0)
= (wp

𝐶1
J

K

𝐶1
J

K

( olp

= (op

= olp

𝐶1
J

K

𝐶1
J

#

=

) ⊕ wlp

𝐶
J

K

( olp

𝐶
J

K

) ⊕ olp

𝐶

(𝜎)

K

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i

= olp

(𝜎)

𝐶
J

K

( olp

𝐶
J

K

) ⊕ wlp

𝐶1
J

K

((8) above)

( 0 ))

(𝜎)

(cid:1)

(Case 𝜎 |= 𝜑)

( 0 )) (𝜎)

K

𝐶1
J
(Theorem 4.9, Induction Hypothesis on 𝐶1)
𝐶1
J

) (𝜎)
K

(Lemma C.20)

𝑎 ⊙ olp

(𝜎 ′)

𝐶 ′
J

K

(Fig. 1 (while))

(Lemma C.19)

64

Batz, Gallus, Kaminski, Katoen, and Winkler

(2) Case 𝜎 6|= 𝜑. Then, Paths𝑛
Ψ0 (olp

h𝐶, 𝜎 i
𝐶
J

) (𝜎)
K

= ∅ by Fig. 1 for any 𝑛 ≥ 2, hence olp

=

[𝜑] (wp

(cid:0)
= 0

𝐶1
J

K

( olp

𝐶
J

K

) ⊕ wlp

𝐶1
J

K

( 0 ))

(𝜎)

(cid:1)

(𝜎) = 0.

𝐶
J

K

((8) above)

(Case 𝜎 6|= 𝜑)

Overall, we have Ψ0 (olp
(cid:22) wlp
olp
𝐶
J
K
most olp
𝐶
J

𝐶
J

K

) = olp

𝐶
( 0 ). Next, we show that the greatest ﬁxed point of wlp
J
. To that end, we use induction on the path length ℓ ∈ N. Denote

( 0 ) is deﬁned as greatest ﬁxed point,
( 0 ) is at

. As wlp
K

𝐶
J

𝐶
J

𝐶
J

K

K

K

K

olp=ℓ

≔

𝐶
J

K

Ê𝜋 ∈Pathsℓ

h𝐶, 𝜎 i

wgt(𝜋) ⊙ ⊤ .

The following forms the induction base. Let ℓ = 0. Then, Pathsℓ

h𝐶, 𝜎 i

= ∅ and

( 0 ) (cid:22) ⊤ = olp=0

.

𝐶
J

The following forms the induction step. Fully analogous to Lemma C.8,
functional. Let ℓ ∈ N such that wlp
𝐶
K
J
( 0 ) (𝜎)

K
, and let 𝜎 ∈ Σ.
K

( 0 ) (cid:22) olp=ℓ

𝐶
J

wlp

K

wlp

𝐶
J

𝐶
J

K

(wGCL-functional)

˜wlp is a wGCL-

=

(cid:22)

Êh𝐶, 𝜎, 𝑛, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ wlp

( 0 ) (𝜎 ′)

𝐶 ′
J

K

Êh𝐶, 𝜎, ℓ, 𝛽 i ⊢𝑎 h𝐶′, 𝜎′, 𝑛+1, 𝛽′ i

𝑎 ⊙ olp=ℓ

𝐶 ′
J

K

(Induction Hypothesis)

(Lemma C.19)

= olp=ℓ+1

(𝜎) .
𝐶
J
K
( 0 ) (cid:22) olp

By Deﬁnition of ⊓, wlp

𝐶
J

K

. Both inequalities imply wlp

𝐶
J

K

( 0 ) = olp

𝐶
J

K

𝐶
J

.
K
(cid:3)

Weighted Programming

65

D PROOFS OF SECTION 5
D.1 Proof of Theorem 5.3

We will use the following lemma which is a useful alternative characterization of certain termina-
tion:

Lemma D.1. 𝐶 is certainly terminating for initial state 𝜎 ∈ Σ iﬀ there exists 𝑏 ∈ N such that

= ∅ for all 𝑛 ≥ 𝑏, i.e. the length of all computation paths starting in h𝐶, 𝜎i is bounded.

Paths𝑛

h𝐶, 𝜎 i

Proof. The direction from right to left is trivial. For the other direction we show that the sub-
tree G′ induced by succ∗(h𝐶, 𝜎i) ≔
𝑖 ≥0 succ𝑖 (h𝐶, 𝜎i) is ﬁnite which implies that all paths have
bounded length. Assume towards contradiction that G′ is inﬁnite. By deﬁnition, G′ is ﬁnitely
branching. Thus, by Kőnig’s classic inﬁnity lemma, there exists an inﬁnite path 𝜅1𝜅2 . . . in G′. But
then there also exists an inﬁnite path starting in h𝐶, 𝜎i since 𝜅1 is reachable from there. This is a
(cid:3)
contradiction to the assumption that 𝐶 is certainly terminating for 𝜎.

Ð

Proof of Theorem 5.3. First, since 𝐶 ′ is universally certainly terminating we have by Lemma D.1
= ∅ for all 𝑛 ≥ 𝑏 and 𝜎 ′ ∈ Σ and thus by Theorem 4.15

that there exists 𝑏 ∈ N such that Paths𝑛
h𝐶, 𝜎′ i
and Theorem 4.14, it holds for all 𝑔 ∈ W that

( 𝑔 ) = wp
This implies that the wp- and wlp-characteristic functions of the loop 𝐶 = while ( 𝜑 ) { 𝐶 ′ } are
equal, i.e.

( 𝑔 ) .

wlp

K

K

𝐶 ′
J

𝐶 ′
J

Φ𝑓

= 𝜆 𝑋 . [¬𝜑] 𝑓 ⊕ [𝜑] wp
= 𝜆 𝑋 . [¬𝜑] 𝑓 ⊕ [𝜑] wlp
= Ψ𝑓 .

𝐶 ′
J
K
𝐶 ′
J

K

( 𝑋 )

( 𝑋 )

Similarly, since 𝐶 is certainly terminating on 𝜎, we also have

and thus

wlp

𝐶 ′
J

K
(gfp Φ𝑓 ) (𝜎)

( 𝑓 ) (𝜎) = wp

( 𝑓 ) (𝜎)

𝐶 ′
J

K
(lfp Φ𝑓 ) (𝜎) .

=

Since 𝐼1 and 𝐼2 are ﬁxed points of Φ𝑓 ,

lfp Φ𝑓 (cid:22) 𝐼1, 𝐼2 (cid:22) gfp Φ𝑓

and thus 𝐼1(𝜎) = 𝐼2(𝜎).

(cid:3)

66

Batz, Gallus, Kaminski, Katoen, and Winkler

E ANNOTATED PROGRAMS
E.1 Ski Rental

wp

[𝑛=0]0 ⊕ [0<𝑦 ]

(2𝑦−1) ⊕ [𝑛 ≤𝑦−1]𝑛

=

((
Φ

𝑛 ⊕ 𝑦 = 𝐼
[𝑛 = 0] 1 ⊕ [𝑛 > 0] ⊙ (𝑛 ⊕ 𝑦)

((
while ( 𝑛 > 0 ) {

=

𝑛 ⊕ 𝑦
1 ⊙ (𝑛 − 1) ⊕ 𝑦

((
wp
((
𝑛 ≔ 𝑛 − 1
=

#

1 ⊙ 𝑛 ⊕ 𝑦
1 ⊙ 𝑛 ⊕ 1 ⊙ 𝑦 ⊕ 𝑦
1 ⊙ (𝑛 ⊕ 𝑦) ⊕ 𝑦
(* rent *)

((
=
((
wp

((
{

wp

1 ⊙ (𝑛 ⊕ 𝑦)

((
⊙ 1

𝑛 ⊕ 𝑦

((

} ⊕ {
=

((
wp

(* buy *)

𝑦
𝑦 ⊙ 1

((
⊙ 𝑦
=
1

#

((
=
0
((
wp
0 ⊕ 𝑦
((
𝑛 ≔ 0

𝑛 ⊕ 𝑦

((

𝑛 ⊕ 𝑦 = 𝐼

}

88

}

1

((

(* terminate *)

((
𝑐 ≔ 0
=

#

(cid:0)

(cid:1)

[𝑛=0] ⊕ [𝑐 ≥𝑦 ]𝑦 ⊕ [𝑐<𝑦 ]

((

Φ

((

(2𝑦−𝑐−1) ⊕ [𝑛 ≤𝑦−𝑐−1]𝑛

= 𝐼

[𝑛=0]0⊕ [𝑛>0]

(cid:0)

[𝑐+1≥𝑦 ]𝑦 ⊕ [𝑐+1<𝑦 ]
(cid:1)

(2𝑦−𝑐−1) ⊕ [𝑛 ≤𝑦−𝑐−1]𝑛

(cid:0)
while ( 𝑛 > 0 ) {

(cid:0)

[𝑐+1≥𝑦 ]𝑦 ⊕ [𝑐+1<𝑦 ]

(2𝑦−𝑐−1) ⊕ [𝑛 ≤𝑦−𝑐−1]𝑛

(cid:1)(cid:1)

(cid:1)

=

((

=

((

=

[𝑐+1≥𝑦 ]𝑦 ⊕

1⊙ [𝑛=1]0

(cid:0)
⊕ [𝑐+1<𝑦 ]
(cid:0)

[𝑐+1≥𝑦 ]𝑦 ⊕ [𝑐+1<𝑦 ]

(cid:0)
[𝑛=1]0 ⊕ [𝑐+1≥𝑦 ]𝑦

((

1⊙

(2𝑦−𝑐−1) ⊕ [𝑛 ≤𝑦−𝑐−1]𝑛

(cid:1)(cid:1)

⊕ [𝑐+1<𝑦 ]
(cid:0)

(2𝑦−𝑐−2) ⊕ [𝑛 ≤𝑦−𝑐−1] (𝑛−1)

[𝑐+1<𝑦 ] (1⊙𝐼 [𝑐/𝑐+1] [𝑛/𝑛−1]) ⊕ [𝑐+1≥𝑦 ]𝑦

wp

((
𝑛 ≔ 𝑛 − 1

(cid:0)

(cid:1)(cid:1)

wp

[𝑐+1<𝑦 ] (1⊙𝐼 [𝑐/𝑐+1]) ⊕ [𝑐+1≥𝑦 ]𝑦

#

((
𝑐 ≔ 𝑐 + 1

wp

[𝑐<𝑦 ] (1⊙𝐼 ) ⊕ [𝑐 ≥𝑦 ]𝑦

#

((
if ( 𝑐 < 𝑦 ) {

wp

1⊙𝐼

((

⊙ 1

𝐼
((
} else {
=

𝑦

((
wp

((

=

((
wp
((

𝑦 ⊙0

⊙ 𝑦

#

0

𝐼 [𝑛/0]

𝑛 ≔ 0

𝐼

((
}

[𝑛=0]0 ⊕ [𝑐 ≥𝑦 ]𝑦

88

⊕ [𝑐<𝑦 ]

(2𝑦−𝑐−1) ⊕ [𝑛 ≤𝑦−𝑐−1]𝑛

= 𝐼

(cid:0)

(cid:1)

}

1

((

Weighted Programming

E.2 Mutual Exclusion

(cid:23)

((
(cid:23)

[1≤𝑘 ≤𝑁 ∧ℓ [𝑘 ]=𝑤∧𝑦=0]𝑊 𝜔
𝑘

𝑊𝑘 ⊙ [1≤𝑘 ≤𝑁 ∧ℓ [𝑘 ]=𝑤∧𝑦=0]𝑊 𝜔
𝑘

67

𝑁
𝑗 =1 [ℓ [ 𝑗 ]=𝑤 ] (𝑊𝑗 ⊙ [1≤𝑘 ≤𝑁 ∧ℓ [𝑘 ]=𝑤∧𝑦=0]𝑊 𝜔
𝑘 )

((
Φ
(( É
while ( true ) {
wlp

𝑁
𝑗 =1 [ℓ [ 𝑗 ]=𝑤 ] (𝑊𝑗 ⊙ [1≤𝑘 ≤𝑁 ∧ℓ [𝑘 ]=𝑤∧𝑦=0]𝑊 𝜔
𝑘 )

(( É
𝑁

{ 𝑖 ≔ 𝑗 }

Ê𝑗=1

wlp

#

[ℓ [𝑖 ]=𝑤 ](𝑊𝑖 ⊙ [1≤𝑘 ≤𝑁 ∧ℓ [𝑘 ]=𝑤∧𝑦=0]𝑊 𝜔
𝑘 )

((
if ( ℓ [𝑖] = 𝑛 ) {

wlp

∅
((
ℓ [𝑖] ≔ 𝑤
(cid:23)

∅

((
((

[1≤𝑘 ≤𝑁 ∧ℓ [𝑘 ]=𝑤∧𝑦=0]𝑊 𝜔
𝑘

} else if ( ℓ [𝑖] = 𝑤 ) {

(cid:23)

𝑊𝑖 ⊙ [1≤𝑘 ≤𝑁 ∧ℓ [𝑘 ]=𝑤∧𝑦=0]𝑊 𝜔
𝑘

[𝑦=0] (𝑊𝑖 ⊙ [1≤𝑘 ≤𝑁 ∧ℓ [𝑘 ]=𝑤∧𝑦=0]𝑊 𝜔
𝑘 )

((
wlp
((
if ( 𝑦 > 0 ) {

wlp

∅
((
𝑦 ≔ 𝑦 − 1
ℓ [𝑖] ≔ 𝑐
⊙ 𝐶𝑖
(cid:23)

#

∅

#

((

[1≤𝑘 ≤𝑁 ∧ℓ [𝑘 ]=𝑤∧𝑦=0]𝑊 𝜔
𝑘

((
} else {
wlp

𝑊𝑖 ⊙ [1≤𝑘 ≤𝑁 ∧ℓ [𝑘 ]=𝑤∧𝑦=0]𝑊 𝜔
𝑘

((
⊙ 𝑊𝑖

[1≤𝑘 ≤𝑁 ∧ℓ [𝑘 ]=𝑤∧𝑦=0]𝑊 𝜔
𝑘

((

}

[1≤𝑘 ≤𝑁 ∧ℓ [𝑘 ]=𝑤∧𝑦=0]𝑊 𝜔
𝑘

} else if ( ℓ [𝑖] = 𝑐 ) {

((

wlp

∅
((
𝑦 ≔ 𝑦 + 1
ℓ [𝑖] ≔ 𝑛
⊙ 𝑅𝑖
(cid:23)

#

∅

#

[1≤𝑘 ≤𝑁 ∧ℓ [𝑘 ]=𝑤∧𝑦=0]𝑊 𝜔
𝑘

((

((

[1≤𝑘 ≤𝑁 ∧ℓ [𝑘 ]=𝑤∧𝑦=0]𝑊 𝜔
𝑘

}

88

}
wlp

((

0

68

Batz, Gallus, Kaminski, Katoen, and Winkler

E.3 Path Counting

=

((
Φ

𝐼

(because 𝐼 [𝑛/0] = [𝑚 ≤1])

[𝑛=0] [𝑚 ≤1] ⊕ [𝑛>0]𝐼

((
while ( 𝑛 > 0 ) {

=

((
=

[𝑚 ≤1] ( [𝑐=0] Fib(𝑛+2) ⊕ [𝑐>0] Fib(𝑛+1)) = 𝐼

[𝑚 ≤1] ( [𝑐=0] (Fib(𝑛+1) ⊕Fib(𝑛)) ⊕ [𝑐>0] Fib(𝑛+1))

[𝑚 ≤1] (Fib(𝑛+1) ⊕ [𝑐=0] Fib(𝑛))

[𝑚 ≤1] Fib(𝑛+1) ⊕ [𝑚 ≤1∧𝑐=0] Fib(𝑛)

((
=
((
wp
((
𝑛 ≔ 𝑛 − 1

wp

((
{

=

[𝑚 ≤1] Fib(𝑛+2) ⊕ [𝑚 ≤1∧𝑐=0] Fib(𝑛+1)

[𝑚 ≤1] Fib(𝑛+2)

[𝑚 ≤1] ( [0=0] Fib(𝑛+2) ⊕ [0>0] Fib(𝑛+1))

((
wp
((
𝑐 ≔ 0

[𝑚 ≤1] ( [𝑐=0] Fib(𝑛+2) ⊕ [𝑐>0] Fib(𝑛+1))

((
} ⊕ {
=

[𝑚 ≤1∧𝑐=0] Fib(𝑛+1)

[𝑚 ≤1∧𝑐+1≤1] ( [𝑐+1=0] Fib(𝑛+2) ⊕ [𝑐+1>0] Fib(𝑛+1))

((
wp
((
𝑐 ≔ 𝑐 + 1
=

#

[𝑚 ≤1∧𝑐 ≤1] ( [𝑐=0] Fib(𝑛+2) ⊕ [𝑐>0] Fib(𝑛+1))

[max(𝑚,𝑐) ≤1] ( [𝑐=0] Fib(𝑛+2) ⊕ [𝑐>0] Fib(𝑛+1))

((
((
𝑚 ≔ max(𝑚, 𝑐)

[𝑚 ≤1] ( [𝑐=0] Fib(𝑛+2) ⊕ [𝑐>0] Fib(𝑛+1))

((

}

[𝑚 ≤1] ( [𝑐=0] Fib(𝑛+2) ⊕ [𝑐>0] Fib(𝑛+1)) = 𝐼

88

}

[𝑚 ≤1]

((

(b) 𝐶count with annotations for verifying the loop invariant.

#
𝑐 ≔ 0

// 𝑟𝑒𝑠 ≔ []
𝑚 ≔ 0
#
#
while ( 𝑛 > 0 ) {
𝑛 ≔ 𝑛 − 1
{

// append ( 𝑟𝑒𝑠, 0 )
𝑐 ≔ 0

} ⊕ {

// append ( 𝑟𝑒𝑠, 1 )
𝑐 ≔ 𝑐 + 1
𝑚 ≔ max(𝑚, 𝑐)

#

#

#

}

}

program

non-
The
(a)
deterministically
bitstrings
of length 𝑛. The maximum number of
consecutive 1’s is stored in variable 𝑚.

“creates”

𝐶count

Weighted Programming

E.4 Knapsack

69

=

((
wp

1 ⊕ [𝑥 ≥8]1 ⊕ [𝑥 ≥13]1

[0≤1∧0≥8−𝑥 ]1 ⊕ [0=0]1 ⊕ [0≤4∧0≥8]1

⊕ [0≤3∧0≥13−𝑥 ]1 ⊕ [0≤2∧0≥5]1 ⊕ [0≤6∧0≥13]1

((
𝑡 ≔ 0
=

#

𝑟 ≔ 0

#

[𝑡 ≤1∧𝑟 ≥8−𝑥 ]1 ⊕ [𝑡=0]1 ⊕ [𝑡 ≤4∧𝑟 ≥8]1

((

wp

⊕ [𝑡 ≤3∧𝑟 ≥13−𝑥 ]1 ⊕ [𝑡 ≤2∧𝑟 ≥5]1 ⊕ [𝑡 ≤6∧𝑟 ≥13]1

[𝑡+2≤3∧𝑟 +5≥13−𝑥 ]1 ⊕ [𝑡+2≤2∧𝑟 +5≥5]1 ⊕ [𝑡+2≤6∧𝑟 +5≥13]1

[𝑡+3≤2∧𝑟 +𝑥 ≥5]1 ⊕ [𝑡+3≤6∧𝑟 +𝑥 ≥13]1 ⊕ [𝑡 ≤2∧𝑟 ≥5]1 ⊕ [𝑡 ≤6∧𝑟 ≥13]1

⊕ [𝑡 ≤3∧𝑟 ≥13−𝑥 ]1 ⊕ [𝑡 ≤2∧𝑟 ≥5]1 ⊕ [𝑡 ≤6∧𝑟 ≥13]1
𝑟 ≔ 𝑟 + 5 } ⊕ { skip }

[𝑡 ≤3∧𝑟 ≥13−𝑥 ]1 ⊕ [𝑡 ≤2∧𝑟 ≥5]1 ⊕ [𝑡 ≤6∧𝑟 ≥13]1

((
{ 𝑡 ≔ 𝑡 + 2
=

((
wp
((
{ 𝑡 ≔ 𝑡 + 3
=

((
wp
((
{ 𝑡 ≔ 𝑡 + 4

#

#

𝑟 ≔ 𝑟 + 𝑥 } ⊕ { skip }

[𝑡 ≤2∧𝑟 ≥5]1 ⊕ [𝑡 ≤6∧𝑟 ≥13]1

[𝑡+4≤6∧𝑟 +8≥13]1 ⊕ [𝑡 ≤6∧𝑟 ≥13]1

𝑟 ≔ 𝑟 + 8 } ⊕ { skip }

#

#

#
[𝑡 ≤6∧𝑟 ≥13]1

((

Fig. 9. Program modelling the Knapsack problem (see Appendix F.1). The three branchings correspond to
choosing the respective task or not. Variables 𝑡 and 𝑟 stand for time and reward, respectively.

70

Batz, Gallus, Kaminski, Katoen, and Winkler

F FURTHER APPLICATIONS OF WEIGHTED PROGRAMMING
F.1 Reasoning about 𝑛-th best solutions

Field:
Problem: Knapsack Problem

Discrete Optimization

Model:
Semiring: Natural numbers

Optimization problem

Techniques: wp

We apply path counting by weighted programming to quantify the ambiguity of the non-determinism
in a program. Assume we are given a nondeterministic weighted program 𝐶 modeling a discrete op-
timization problem. Each branching { ... } ⊕ { ... } in 𝐶 corresponds to a possible choice to be made
by an optimizer. Further, we assume that all program variables are either initialized explicitly by
the program or read-only. We will refer to such read-only variables as program parameters. Given
an initial parameters state 𝜎, the optimization goal is to reach a ﬁnal state 𝜎 ′ satisfying a given
predicate 𝜑 that maximizes 𝜎 ′(𝑟 ) for some ﬁxed special program variable 𝑟 — a “reward”, or payoﬀ.
Examples for the predicate 𝜑 include, e.g. thresholds on time- or energy consumption. A solution
to the optimization problem modeled by 𝐶 corresponds to a determinization 𝐶 ′ obtained from 𝐶 by
replacing every nondeterministic choice by a deterministic one. The reward 𝜎 ′(𝑟 ) achieved by 𝐶 ′
on initial state 𝜎 is called the score of 𝐶 ′ w.r.t. 𝜎. We can view the scores as a function 𝜌 : Σ → N
that only depends on the parameter variables. The solution 𝐶 ′ is called valid if for all parameters
𝜎, it reaches a ﬁnal state satisfying 𝜑. Note that valid solution are not necessarily optimal.

Given some problem parameters 𝜎, we are now interested in determining the rank of a given
solution 𝐶 ′ relative to the optimal solution implicitly encoded in 𝐶, e.g. “is 𝐶 ′ among the 3 best
solutions?”. Assume that 𝐶 ′ is valid. Then 𝐶 ′ is among the best 𝑛 solutions under parameters 𝜎 iﬀ

( [𝜑 ∧ 𝑟 ≥ 𝜌] 1 ) (𝜎) ≤ 𝑛 .

wp

𝐶
J

K

We illustrate determining ranks of solutions by wp-reasoning by means of the Knapsack prob-
lem: Suppose we operate a cloud computer earning money by completing computational tasks.
There are currently 3 tasks in the queue, which take 2, 3, and 4 hours to complete, respectively,
and generate a reward of 5, 𝑥, and 8 euros, where 𝑥 is a program variable (considered an input pa-
rameter). Our goal is to maximize the total reward earned within 6 hours, i.e. 𝜑 = (𝑡 ≤ 6). Hence,
we have to decide on a subset of the three tasks to stay within this time limit since completing all
three would take 7 hours. This optimization problem is modeled by the program 𝐶 in Fig. 10. We
initialize the variables 𝑡 (for time) and 𝑟 (for reward) by 0 and may subsequently choose a subset
of the available tasks. These choices are modeled by the three nondeterministic branchings.

Choosing the ﬁrst and the third task always yields a valid solution (𝑡 ≤ 6) generating an accu-
mulated reward of 13 euros. This solution is modeled by the determinization 𝐶 ′ of 𝐶 in Fig. 10. We
now compute

( [𝑡 ≤ 6 ∧ 𝑟 ≥ 13] 1 ) = 1 ⊕ [𝑥 ≥ 8] 1 ⊕ [𝑥 ≥ 13] 1 ,

where we can readily read oﬀ that 𝐶 ′ is (i) the unique optimal solution if 𝑥 < 8, (ii) among the two
best solutions if 8 ≤ 𝑥 < 13, and (iii) among the three best solutions else.

K

wp

𝐶
J

Weighted Programming

71

wp

1 ⊕ [𝑥 ≥ 8] 1 ⊕ [𝑥 ≥ 13] 1

𝑟 ≔ 0

((
𝑡 ≔ 0
#
{ 𝑡 ≔ 𝑡 + 2
{ 𝑡 ≔ 𝑡 + 3
{ 𝑡 ≔ 𝑡 + 4

#
𝑟 ≔ 𝑟 + 5 } ⊕ { skip }
𝑟 ≔ 𝑟 + 𝑥 } ⊕ { skip }
𝑟 ≔ 𝑟 + 8 } ⊕ { skip }

#
#

#
#

#
[𝑡 ≤ 6 ∧ 𝑟 ≥ 13] 1

((

𝑟 ≔ 0

#

𝑡 ≔ 0
𝑡 ≔ 𝑡 + 2
skip
#
𝑡 ≔ 𝑡 + 4

#
𝑟 ≔ 𝑟 + 5

#

𝑟 ≔ 𝑟 + 8

#

#

Fig. 10. Program 𝐶 modeling the Knapsack problem (left) and a valid solution 𝐶 ′ (right). The three branchings
model the possible choices (either choosing the respective task or not). The variables 𝑡 and 𝑟 stand for time
and reward, respectively. Variable 𝑥 is an input parameter.

