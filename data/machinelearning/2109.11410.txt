Learning to Robustly Aggregate Labeling Functions for Semi-supervised
Data Programming

Ayush Maheshwari 1∗, Krishnateja Killamsetty 2∗, Ganesh Ramakrishnan 1,
Rishabh Iyer2, Marina Danilevsky3 and Lucian Popa3
1Indian Institute of Technology Bombay, India
2 The University of Texas at Dallas
3 IBM Research – Almaden
{ayusham, ganesh}@cse.iitb.ac.in
{krishnateja.killamsetty, rishabh.iyer}@utdallas.edu
{mdanile, lpopa}@us.ibm.com

Abstract

A critical bottleneck in supervised machine
learning is the need for large amounts of
labeled data which is expensive and time-
consuming to obtain.
Although a small
amount of labeled data cannot be used to train
a model, it can be used effectively for the gen-
eration of human-interpretable labeling func-
tions (LFs). These LFs, in turn, have been
used to generate a large amount of additional
noisy labeled data in a paradigm that is now
commonly referred to as data programming.
Previous methods of generating LFs do not at-
tempt to use the given labeled data further to
train a model, thus missing opportunities for
improving performance. Additionally, since
the LFs are generated automatically, they are
likely to be noisy, and naively aggregating
these LFs can lead to suboptimal results.
In
this work, we propose an LF-based bi-level op-
timization framework WISDOM to solve these
two critical limitations. WISDOM learns a
joint model on the (same) labeled dataset used
for LF induction along with any unlabeled data
in a semi-supervised manner, and more criti-
cally, reweighs each LF according to its good-
ness, inﬂuencing its contribution to the semi-
supervised loss using a robust bi-level opti-
mization algorithm. We show that WISDOM
signiﬁcantly outperforms prior approaches on
several text classiﬁcation datasets. The source
code can be found at https://github.com/
ayushbits/robust-aggregate-lfs.

1

Introduction

Supervised machine learning approaches require
large amounts of labeled data to train robust ma-
chine learning models. Human-annotated gold la-
bels have become increasingly important to modern
machine learning systems for tasks such as spam
detection, (movie) genre classiﬁcation, sequence la-
beling, etc. The creation of labeled data is, however,
a time-consuming and costly process that requires

∗Equal contribution

large amounts of human labor. Together with the
heavy reliance on labeled data for training models,
this serves as a deterrent to achieving comparable
performance on new tasks. As a result, various
methods such as semi-supervision, distant super-
vision, and crowdsourcing have been proposed to
reduce reliance on human annotation.

In particular, several recent data programming
approaches (Bach et al., 2019; Maheshwari et al.,
2021; Chatterjee et al., 2020; Awasthi et al., 2020)
have proposed the use of human-crafted labeling
functions to weakly associate labels with the train-
ing data. Typically, users encode supervision as
rules/guides/heuristics in the form of labeling func-
tions (LFs) that assign noisy labels to the unlabeled
data, thus reducing dependence on human-labeled
data. The noisy labels were aggregated using La-
bel aggregators, which often employ generative
models, to assign a label to the data instance. Ex-
amples of label aggregators are SNORKEL (Ratner
et al., 2016) and CAGE (Chatterjee et al., 2020).
These models provide consensus on the noisy and
conﬂicting labels assigned by the discrete LFs
to help determine the correct labels probabilisti-
cally. We could use the obtained labels to train
any supervised model/classiﬁer and evaluate on
a test set. Apart from the cascaded approach de-
scribed above, recently proposed semi-supervised
paradigm (Awasthi et al., 2020; Maheshwari et al.,
2021) learns to aggregate labels using both features
and a very small labeled set in addition to label-
ing functions. Such approaches have been shown
to outperform the completely unsupervised data
programming approaches described above.

Data programming (unsupervised or semisuper-
vised) requires carefully curated LFs, generally
expressed in the form of regular expressions or
conditional statements. Even though creating LFs
can potentially take less time than creating large
amounts of supervised data, it requires domain ex-
perts to spend considerable time identifying and

2
2
0
2

r
a

M
0
1

]

G
L
.
s
c
[

2
v
0
1
4
1
1
.
9
0
1
2
:
v
i
X
r
a

 
 
 
 
 
 
Label
ENTITY

DESCRIPTION

NUMERIC

DESCRIPTION

HUMAN

DESCRIPTION

LOCATION

Generated LFs Weighting

what does
what is
how long
how
who
what kind
city

↑
↓
↑
↓
↑
↓
↑

Table 1: Illustration of induced LFs, including exam-
ples of the issue of conﬂicting LFs, on the TREC
dataset. Learning importance (weights) of LFs can be
used to reduce the conﬂicts among LFs.

determining the patterns that should be incorpo-
rated into LFs. In this paper, we circumvent the
requirement of human-curated LFs by instead au-
tomatically generating human-interpretable LFs as
compositions of simple propositions on the data
set by leveraging SNUBA (Varma and Ré, 2018)
which utilizes a small labeled-set to induce LFs
automatically. However, as we will show, SNUBA
suffers from two critical limitations, which keep it
from outperforming even a simple supervised base-
line that is trained on the same labeled-set. First,
SNUBA only uses the labeled-set to generate the
LFs but does not make effective use of it in the
ﬁnal model training. Secondly, as it naively aggre-
gates these LFs, it is not able to distinguish between
very noisy LFs and more useful ones. This work
addresses both of these limitations.

In Table 1, we present a sample set of induced
LFs and assigned labels for the TREC dataset (Li
and Roth, 2002). The induced LFs are likely to
be less precise compared with those created by hu-
mans, and they are likely to have more mutual con-
ﬂicts. Since the LFs are incomplete and noisy, ex-
isting label aggregators that merely consume their
outputs do not perform well when dealing with
such noisy LFs (c.f. Table 1). For instance, the
sentence How long does a dog sleep ?
will be assigned both DESCRIPTION and NUMERIC
labels due to the LFs how and how long.

As a solution, how should be given less im-
portance due to its noisy and conﬂicting nature,
whereas how long, associated with the NUMERIC
label, should be given higher importance. In this pa-
per, we present a bi-level optimization framework
for reweighting the induced LFs, which effectively
reduces the weights of noisy labels while simulta-
neously increasing the weights of the more useful
ones.

In Figure 1, we present an overview of our ap-
proach. We leverage semi-supervision in the fea-

Figure 1: Pictorial depiction of our WISDOM workﬂow.
A small labeled-set is used to automatically induce
LFs. This labeled set is split equally into supervised set
and validation set to be used by our re-weighted semi-
supervised data programming algorithm along with the
unlabeled set.

ture space for more effective data programming
using the induced (automatically generated) label-
ing functions. To enable this, we split the same
labeled-set (which was used to generate the LFs)
into a supervised set and validation set. The super-
vised set is used for semi-supervised data program-
ming, and validation set is used to tune (reweight)
the LFs. As a basic framework for semi-supervised
data programming, we leverage SPEAR (Mahesh-
wari et al., 2021), which has achieved state-of-the-
art performance. While the semi-supervised data
programming approach helps in using the labeled
data more effectively, it does not solve the prob-
lem of noise associated with the LFs. To address
this, we propose an LF reweighting framework,
WISDOM1, which learns to reweight the labeling
functions, thereby helping differentiate the noisy
LFs from the cleaner and more effective ones.

The reweighting is achieved by framing the prob-
lem in terms of bi-level optimization. We argue that
using a small labeled-set can help improve label
prediction over hitherto unseen test instances when
the labeled-set is bootstrapped for (i) inducing LFs,
(ii) semi-supervision, and (iii) bi-level optimiza-
tion to reweight the LFs. For most of this work,
the LFs are induced automatically by leveraging
part of the approach described in (Varma and Ré,
2018). The LFs are induced on the entire labeled-
set, whereas the semi-supervision and reweighting
are performed on the supervised set and validation
set respectively (which are disjoint partitions of
labeled-set).

Our Contributions are as follows: While lever-

1Expanded as reWeIghting based Semi-supervised Data

prOgraMming

Notation
li ∈ {0, 1}m
τij ∈ [0, K]
fφ

Pθ

labeled-set (L)

Description
Firings of all the LFs, λ1..λm on an instance xi
class kj associated by LF λj, when triggered (lij = 1) on xi
The feature-based model with parameters φ operating on feature
space X and on label space Y ∈ {1...K}
The label probabilities as per the LF-based aggregation model
with parameters θ
The entire labeled dataset: L = {(xi, yi)} where i ∈ {1 · · · N }.
This is used to induce the LFs

supervised set (S) Subset of L that is used for semi-supervision: S = {(xi, yi)}

validation set (V)

where i ∈ {1 · · · N/2}
Subset of L that is used for reweighting the LFs using a bi-level
optimization formulation: V = {(xi, yi)} where i ∈ {N/2 +
1 · · · N }

unlabeled-set (U) Unlabeled set: U = {xi} where i ∈ {N + 1 · · · M } . It is labeled

Lce
H
g
LLs

LLu
KL
R
Lss(θ, φ, w)

using the induced LFs
Cross Entropy Loss
Entropy function
Label Prediction from the LF-based graphical model
Supervised negative log likelihood over the parameters θ of the
LF aggregation model
Unsupervised negative log likelihood summed over labels
KL Divergence between two probability models
Quality Guide based loss
The semi-supervised bi-level optimization objective with addi-
tional weight parameters w over the LFs

Table 2: Summary of notations used in this paper.

erated labeling functions be denoted by λ1 to λm
where m is the number of labeling functions gener-
ated. Let the vector li = (li1, li2, . . . , lim) denote
the ﬁrings of all the LFs on an instance xi. Each lij
can be either 1 or 0; lij = 1 indicates that the LF
λj has ﬁred (i.e., triggered) on the instance xi and
0 indicates it has not. Furthermore, each labeling
function λj is associated with some class kj and
for an input xi, it outputs the label τij = kj when
triggered (i.e., lij = 1) and τij = 0 otherwise.

Let the labeled-set be denoted by L = {(xi, yi)}
where i ∈ {1 · · · N } and N is the number of
points in labeled-set. Similarly, we have an un-
labeled dataset denoted as U = {xi} where i ∈
{N + 1 · · · M } and M − N is the number of un-
labeled points. The labeled-set is further split
into two disjoint sets called supervised set and
validation set. Let the supervised set be denoted
by S = {(xi, yi)} where i ∈ {1 · · · N/2}. Let
V = {(xi, yi)} denote the validation set, where
i ∈ {N/2 + 1 · · · N }.

2.2 SNUBA: Automatic LF Generation

Varma and Ré (2018) present SNUBA, a three step
approach that (i) automatically generates candidate
LFs (referred to as heuristics) using a labeled-set,
(ii) ﬁlters heuristics based on diversity and accuracy
metrics to select only relevant heuristics, and (iii)
uses the ﬁnal set of ﬁltered LFs (heuristics) and
a label aggregator to compute class probabilities
for each point in the unlabeled set U. Steps (i) and
(ii) are repeated until the labeled set is exhausted
or a limit on the number of iterations is reached.
Each LF is a basic composition of propositions on
the labeled set. A proposition could be a word,

Figure 2: A summary plot contrasting the performance
gains obtained using WISDOM on previous state-of-the-
art approaches on YouTube and TREC (using Lemma
features). WISDOM outperforms other learning ap-
proaches with auto-generated LFs.

aging SNUBA (Varma and Ré, 2018) only for au-
tomatically generating LFs, we address the im-
portant limitations of SNUBA by (i) effectively us-
ing the labeled set in a semi-supervised manner
using SPEAR (Maheshwari et al., 2021), and (ii)
critically making the labeling function aggregation
more robust via a reweighting framework. We do
the reweighting by using our proposed bi-level opti-
mization algorithm that weighs each LF separately,
giving low importance to noisy LFs and high impor-
tance to relevant LFs. We present evaluations on
six text classiﬁcation datasets and show that WIS-
DOM demonstrates better performance than current
label aggregation approaches with automatically
(or even human) generated labeling functions.

A summary of the results are presented in Fig-
ure 2. As mentioned, SNUBA performs worse than
a simple supervised baseline that trained only on
the labeled data component. Furthermore, WIS-
DOM outperforms VAT (a state-of-the-art semi-
supervised learning algorithm) and HUM-SPEAR
sometimes (a state-of-the-art semi-supervised data
programming algorithm with human-generated
LFs), demonstrating the beneﬁt of having both
semi-supervision and robust LF reweighting with
the auto-generated LFs. Finally, WISDOM gets
to within 2 - 4% of HUM-SPEAR (using human
crafted-LFs), without having to incur the cost of
generating labeling functions manually, and which
can also require signiﬁcant domain knowledge.

2 Background

2.1 Notations

Let us denote the feature space by X and the label
space by Y ∈ {1...K} where K is the number of
classes. Let the automatically (or manually) gen-

YouTubeTREC608086.058.357.250.583.159.082.159.290.460.194.163.3SUPERVISEDSNUBAAUTO-SPEARVATWISDOMHUM-SPEARa phrase, or a lemma (c.f., the second column of
Table 1), or an abstraction such as a part of speech
tag. The composition is in the form of a classiﬁer
such as a decision stump (1-depth decision tree) or
logistic regression.

Our WISDOM framework utilizes SNUBA for
generating the LFs and thereafter reweigh the LFs
via our reweighting framework while jointly learn-
ing the model parameters and the LF aggregation
in a semi-supervised manner.

2.3 SPEAR: Joint SSL Data Programming

Maheshwari et al. (2021) propose a joint learning
framework called SPEAR that learns the parameters
of a feature-based classiﬁcation model and of the
label aggregation model (the LF model) in a semi-
supervised manner. SPEAR has a feature-based
classiﬁcation model fφ(x) that takes the features
as input and predicts the class label. SPEAR em-
ploys two kinds of models: a logistic regression
and a two-layer neural network model. For the LF
aggregation model, SPEAR uses an LF-based graph-
ical model inspired from CAGE (Chatterjee et al.,
2020). CAGE aggregates the LFs by regularizing
parameters such that learned joint distribution of
y and τj matches the user provided quality guides
over all y.

Pθ(i, y) =

1
Zθ

j=m
(cid:89)

j=1

ψθ(τij, y)

(1)

There are K parameters θj1, θj2...θjK for each
LF λj, where K is the number of classes. The
potential ψθ used in the CAGE model is deﬁned as:

ψθ(τij, y) =

(cid:40)

exp(θjy)
1

if τij (cid:54)= 0
otherwise

(2)

The loss function of SPEAR has six terms. These
include the cross entropy on the labeled set, an
entropy SSL term on the unlabeled dataset, a cross
entropy term to ensure consistency between the
feature model and the LF model, the LF graphical
model terms on the labeled and unlabeled datasets,
a KL divergence again for consistency between the
two models, and ﬁnally a regularizer. The objective
function is:

(cid:88)

i∈L
(cid:88)

Lce(fφ(xi), yi) +

(cid:88)

i∈U

H(fφ(xi))+

Lce(fφ(xi), g(li)) + LLs(θ|L) + LLu(θ|U )+

i∈U
(cid:88)

i∈U∪L

KL(Pθ(li), fφ(xi)) + R(θ|{qj})

(3)

where g is the label prediction from the LF-based
graphical model. The second component H()
models semi-supervision (Grandvalet and Bengio,
2005) in the form of minimization of the entropy
of the predictions on the unlabeled dataset U. It
provides some semi-supervision by trying to in-
crease the conﬁdence of the predictions made by
the model on the unlabeled dataset. (Refer Table
2 for notations used in the objective function). In
the objective function above, the LF model param-
eters are θ while the feature model parameters are
φ. The learning problem in SPEAR is simply to op-
timize the objective jointly over θ and φ. (We refer
readers to Maheshwari et al. (2021) for details.)
CAGE loss formulation: The learning problem
proposed in CAGE (Chatterjee et al., 2020) is a
special case of SPEAR where they just use the ﬁfth
loss term LLu(θ|U ) along with the quality guide
R(θ|{qj}). The speciﬁc loss formulation of CAGE
is as given below:

LLu(θ|U ) + R(θ|{qj})

(4)

3 The WISDOM Workﬂow

In this section, we present our robust aggregation
framework for automatically generated LFs. We
present the LF generation approach followed by
our reweighting algorithm, which solves a bi-level
optimization problem. In the bi-level optimization,
we learn the LF weights in the outer level, and in
the inner level, we learn the feature-based classi-
ﬁer’s and labeling function aggregator’s parameters
jointly. We describe the main components of the
WISDOM workﬂow below (see also Figure 1). A
detailed pseudocode of WISDOM is provided in Al-
gorithm 1. We describe the different components
of WISDOM below.
Automatic LF Generation using SNUBA: Our
WISDOM framework utilizes steps (i) and (ii) from
SNUBA (c.f., Section 2.2) for automatically induc-
ing LFs. That is, it initially iterates between i)
candidate LF generation on labeled-set L and ii) ﬁl-
tering them based on diversity and accuracy based
criteria, until a limit on the number of iterations is
reached (or until the labeled set is completely cov-
ered). We refer to these steps as SNUBALFGEN.
Re-Weighting CAGE: To deal with noisy labels
effectively, we associate each LF λj with an ad-
ditional weight parameter wj ∈ [0, 1] that acts as
its reliability measure. The w’s are optimized on
the validation set and have interactions amongst
themselves, unlike θ which is learned on the combi-
nation of unlabeled and training sets. The discrete

potential in CAGE (c.f., eq.(2)) can be modiﬁed to
include weight parameters as follows:

ψθ(τij, y) =

(cid:40)

exp(wjθjy)
1

if τij (cid:54)= 0
otherwise

Lss(θ, φ, w) =

(cid:88)

i∈S

Lce(fφ(xi), yi) +

(cid:88)

i∈U

H(fφ(xi))

(5)

+

(cid:88)

i∈U

Lce(fφ(xi), g(li, w)) + LLs(θ, w|S)

We observe that if the weight of the jth LF is
zero (i.e., wj = 0), the corresponding weighted
potential in eq. (5) becomes one, which in turn im-
plies that the jth LF is ignored while maximizing
the log-likelihood during label aggregation. Sim-
ilarly, if all the LFs are associated with a weight
value of one (i.e., wj = 1), the above weighted
potential will degenerate to the discrete potential
used in CAGE. The re-weighted CAGE is implicitly
invoked on lines 12, 13, 17 and 18 of Algorithm 1
where LSS(θ, φ, w) is invoked. We compare per-
formance of CAGE with a bi-level variation in Table
5.

Algorithm 1: WISDOM

Input: L, S, V, U, Learning rates: α, β
Output: θ, φ, w

1 **** Automatic LF generation using SNUBA ****
2 λ1, · · · , λm = SNUBALFGEN(L)
3 Get LFs trigger matrix ls, lu for sets S, U using

λ1, · · · , λm

4 Get LFs output label matrix τ s, τ u for sets S, U using

λ1, · · · , λm

5 **** The Reweighted Joint SSL ****
6 t = 0;
7 Randomly initialize model parameters θ0, φ0 and LF

weights w0;

8 repeat
9

Sample mini-batch s = (xs
u = (xu
i , lu
{S, τ s, ls}, {U, τ u, lu}

i , ys
i ),
i ) of batch size B from

i , τ u

i , τ s

i , ls

10

11

12

13

14

15

16

**** Bi-level Optimization ****
**** Inner level ****
θ∗
t = θt − α∇θLss(θt, φt, wt)
φ∗
t = φt − α∇φLss(θt, φt, wt)
**** Outer level ****
1
wt+1 = wt −β∇w
|V|

(cid:80)
i∈V

Lce(fφ∗
t

(xi), yi)

**** Update net parameters φ, θ ****

17

18

θt+1 = θt+1 − α∇θLss(θt, φt, wt+1)
φt+1 = φt+1 − α∇φLss(θt, φt, wt+1)
t = t + 1
19
20 until convergence
21 return θt+1, φt+1, wt+1

The Reweighted Joint SSL: Since the label ag-
gregator graphical model is now dependent on the
additional LF weight parameters w, the joint semi-
supervised learning objective function is modiﬁed
as follows:

+ LLu(θ, w|U) +

+ R(θ, w|{qj})

(cid:88)

i∈U ∪S

KL(Pθ,w(li), fφ(xi))

(6)

In Section 7, we present the somewhat intuitive

expansions of terms that are dependent on w.

Bi-Level Objective: WISDOM jointly learns the
LF weights and weighted labeling aggregator and
feature classiﬁer parameters for the objective func-
tion deﬁned in Equation (6). The LF weights are
learned by WISDOM by posing a bi-level optimiza-
tion problem for this objective function as deﬁned
in eq. (7) and employing alternating one-step gradi-
ent updates. As evident in eq. (7), WISDOM uses a
validation set (|V|) which is a subset of labeled-set
(|L|) to learn the LF weights. Furthermore, the in-
troduced weight parameters allow ﬁltering of LFs
based on the feature model and a bilevel objec-
tive in the form of a cross-entropy loss of feature
model predictions on the validation set. In essence,
WISDOM tries to learn LF weights that result in
minimum validation loss on the feature model that
is jointly trained with weighted labeling aggregator.

w∗ = argmin

w

1
|V|

(cid:88)

i∈V

Lce(fφ∗(xi), yi)

where φ∗, θ∗ = argmin

φ,θ

Lss(θ, φ, w)

(7)

However, determining the optimal solution to the
above Bi-level objective function is computation-
ally intractable. Hence, inspired by MAML (Finn
et al., 2017), WISDOM adopts an iterative alterna-
tive minimizing framework, wherein we optimize
the objective function at each level using a single
gradient descent step. As shown in Algorithm 1,
lines 12 and 13 are the inner level updates where
the parameters θ, φ are updated using the current
choice of weight parameters w for one gradient
step, and in line 15, the weight parameter w is up-
dated using the one-step updates from lines 12 and
13. Finally, the net parameters φ, θ are updated in
lines 17 and 18. This procedure is continued till
convergence (e.g., no improvement in the outer-
level loss) or for a ﬁxed number of epochs.

Dataset

|S|

|V|

|U |

#LFs

#Class

IMDB
YouTube
SMS
TREC
Twitter
SST-5

71
55
463
273
707
568

71
55
463
273
707
568

1278
977
8335
4918
12019
9651

18
11
21
13
25
25

2
2
2
6
3
5

Table 3: Summary statistics of the datasets and the au-
tomatically generated LFs using SNUBA. The test set
contains 500 instances for each dataset.

4 Experiments

We present evaluations across six datasets that we
describe in the following Section 4.1. In Table 3,
we present summary statistics of these datasets,
including the sizes of supervised set, validation set
(with labeled-set being the union of these disjoint
sets) and the number of (auto-generated) LFs used
in the experiments.

4.1 Datasets

We use the following datasets in our exper-
(1) TREC (Li and Roth, 2002): A
iments:
question classiﬁcation dataset with six cate-
Description, Entity, Human,
gories:
Abbreviation, Numeric, Location.
(2) YouTube Spam Classiﬁcation (Alberto
et al., 2015): A spam classiﬁcation task over
comments on YouTube videos. (3) IMDB Genre
Classiﬁcation2: A plot summary based movie
genre binary classiﬁcation dataset. (4) SMS Spam
Classiﬁcation (Almeida et al., 2011): A binary
spam classiﬁcation dataset to detect spam in SMS
messages. (5) Twitter Sentiment (Wan and Gao,
2015): This is a 3-class sentiment classiﬁcation
problem extracted from Twitter feed of popular
airline handles. Each tweet is either labeled as
negative, neutral, and positive labels. (6) Stanford
Sentiment Treebank (SST-5) (Socher et al.,
2013) is a single sentence movie review dataset,
with each sentence labeled as either negative,
somewhat negative, neutral, somewhat positive, or
positive.

4.2 Baselines

In Table 4, we compare our approach against the
following baselines:
Snuba (Varma and Ré, 2018): Recall from Sec-
tion 2.2 that SNUBA iteratively induces LFs from
the count-based raw features of the dataset in the
steps (i) and (ii). For the step (iii), as in (Varma

2www.imdb.com/datasets

and Ré, 2018), we employ a generative model to as-
sign probabilistic labels to the unlabeled set. These
probabilistic labels are obtained by training a 2-
layered NN model.
Supervised (SUP): This is the model obtained by
training the classiﬁer Pθ(y|x) only on labeled-set.
This baseline does not use the unlabeled set.
Learning to Reweight (L2R) (Ren et al., 2018):
This method trains the classiﬁer using a meta-
learning algorithm over the noisy labels in the un-
labeled set obtained using the automatically gen-
erated labeling functions and aggregated using
SNORKEL. It uses an online algorithm that assigns
importance to examples based on the gradient.
Posterior Regularization (PR) (Hu et al., 2016):
This is a method for joint learning of a rule and fea-
ture network in a teacher-student setup. Similarly
to L2R, it uses the noisy labels in the unlabeled set
obtained using the automatically generated label-
ing functions.
Imply Loss (IL) (Awasthi et al., 2020): This
method leverages both rules and labeled data by
associating each rule with exemplars of correct ﬁr-
ings (i.e., instantiations) of that rule. Their joint
training algorithms de-noise over-generalized rules
and train a classiﬁcation model. This is also run on
the automatically generated LFs.
SPEAR (Maheshwari et al., 2021): This method
employs a semi-supervised framework combined
with a graphical model for consensus amongst the
LFs to train the model. We compare against two
versions of SPEAR. The ﬁrst that (just like L2R,
PR, IL, and VAT) uses auto-generated LFs (which
we call AUTO-SPEAR), and the second, viz., HUM-
SPEAR, which uses the human LFs.
VAT: Virtual Adversarial Training (Miyato et al.,
2018) is a semi-supervised approach that uses the
virtual adversarial loss on the unlabeled points,
thereby ensuring robustness of the conditional label
distribution on the unlabeled points.

4.3 Experimental Setting

To train our model on the supervised set, we use a
neural network architecture with two hidden layers
(512 units) and ReLU activation function as our
feature-based model fφ. We choose our classiﬁca-
tion network to be the same as SPEAR (Maheshwari
et al., 2021). We consider two types of features: a)
raw words and b) lemmatizations, as an input to our
supervised model (lemmatization is a technique to
reduce a word, e.g., ‘walking,’ into its root form,
’walk’). Additionally, these features are used as
basic propositions over which composite LFs are
built.

Each experimental run involves training WIS-

DOM for 100 epochs with early stopping based on
validation set. Our model is optimized using mini-
batch gradient descent with the Adam optimizer.
We tuned the hyperparameters on the validation
set, and the optimal conﬁguration was found to
have a dropout probability of 0.80 and a batch size
of 32. Further, the optimal conﬁguration learning
rates for the classiﬁer and LF aggregation models
were 0.0003 and 0.01, respectively. Performance
numbers for each experiment are obtained by av-
eraging over ﬁve independent runs, each having a
different random initialization. For evaluation on
the test set, the model with the best performance
on the validation set was chosen. On all datasets,
macro-F1 is employed as the evaluation criterion.
We implement all our models in PyTorch3 (Paszke
et al., 2019). We run all our experiments on Nvidia
RTX 2080 Ti GPUs with 12 GB RAM set within
Intel Xeon Gold 5120 CPU having 56 cores and
256 GB RAM. Model training times range from 15
mins (YouTube) to 100 mins (TREC).

4.4 Results

In Table 4, we compare the performance of WIS-
DOM against different baselines (all using auto-
generated labeling functions except VAT), for both
raw and lemmatized count features (c.f. Sec-
tion 2.2) across multiple datasets. We observe
that SNUBA performs worse than the Supervised
baseline on all datasets, exhibiting high variance
over different runs (surprisingly, Varma and Ré
(2018) did not compare the performance of SNUBA
against the supervised baseline). Learning to
Reweight (L2R) performs worse than Supervised
on all datasets except YouTube. Posterior regu-
larization, imply loss and SPEAR show gains over
Supervised on a few datasets, but not consistently
across all datasets and settings. Finally, VAT ob-
tains competitive results in some settings (e.g.,
TREC dataset) but performs much worse on oth-
ers (e.g., IMDB and SST-5).
In contrast, WIS-
DOM achieves consistent gains over Supervised and
the other baselines in almost all datasets (except
TREC with raw features where VAT does slightly
better than WISDOM). Additionally, WISDOM
yields smaller variance over different runs com-
pared to other semi-supervised approaches. Recall
that the main difference between WISDOM and
Auto-SPEAR is that the former reweighs the LFs
in both the label aggregator as well as in the semi-
supervised loss, as against Auto-SPEAR which does
not reweigh the LFs at all. Consequently, the afore-
mentioned empirical gains illustrate the robustness

of the bi-level optimisation algorithm. Note that
these numbers are all reported using only 10% la-
beled data, and hence, results for some datasets
(starting with Supervised) might appear lower than
those reported in the literature. Note that, we com-
pare WISDOM (using automatically induced LFs)
against the HUM-SPEAR which uses the human
crafted LFs in conjunction with the state-of-the-art
SPEAR approach (Maheshwari et al., 2021). Al-
though WISDOM uses auto-generated LFs, it some-
times performs better than HUM-SPEAR, which
utilizes human-curated LFs. On careful analysis
(presented in Section 8 of the supplementary), we
observe that the human curated LFs tend to be more
generic abstractions of possible patterns without
assessing how precise they are for the end task.
Consequently, these abstract human-LFs tend to
have not only higher collective coverage but also
high mutual conﬂicts and lower average individ-
ual precision values than the automatically induced
LFs. Given the individual strengths of both human-
lfs and auto-lfs, it might be interesting to consider
using them in conjunction with each other in order
to improve performance as future work. An abla-
tion test in Figure 3 reveals that WISDOM performs
well even for small-sized labeled-set unlike other
baselines, demonstrating its robustness in scenarios
with only few labeled examples.

4.5

Importance of the Bi-Level formulation

A label aggregation approach, such as CAGE,
SNORKEL, may improve the consensus labeling
across LFs, but not necessarily their agreement
with the ground truth. Further, when LFs are noisy
(or induced automatically), the performance of the
CAGE model can suffer. However, the bi-level
framework of CAGE can alleviate these problems
since it implicitly reduces the noise in LFs. In order
to demonstrate effectiveness of the bi-level formu-
lation, we compare CAGE(Eq (4)) with two variants
4 that considers validation set feedback
(i) CAGEval
in the loss formulation for promoting LF agree-
ment with ground-truth label and (ii) CAGEBi-level
with the proposed bi-level formulation that tries to
do the same5. We present our results in Table 5.
The performance of our CAGEBi-level is clearly su-
perior to the original CAGE model, as well as to
the CAGEval model. Thus, the bi-level formula-
tion more effectively incorporates validation set
feedback than other formulations as demonstrated
by application of bi-level on both SPEAR as well

4CAGEval

- equivalent
LLu (θ, w|U) + R (θ, w|{qj}) in Eq (3)

to using only LLs(θ|L) +

3https://pytorch.org/

5In other words, CAGEBi-level is equivalent to using only

LLu (θ, w|U) + R (θ, w|{qj}) in Eq (6)

Dataset

IMDB

YouTube

SMS

TREC

Twitter

SST-5

Raw
Lemma
Raw
Lemma
Raw
Lemma
Raw
Lemma
Raw
Lemma
Raw
Lemma

Supervised
68.8 (0.2)
72.4 (1.3)
90.8 (0.3)
86 (0.3)
92.3 (0.5)
91.4 (0.5)
58.3 (3.1)
56.3 (0.3)
52.61 (0.12)
61.24 (0.52)
27.54 (0.12)
27.52 (0.52)

SNUBA
-5.9 (2)
-14.4 (5.7)
-33.2 (1.8)
-28.7 (2.9)
-16.7 (9.8)
-16.1 (5.3)
-6.8 (4.1)
-5.8 (5.1)
-7 (4.1)
-9.28 (5.1)
-9 (2.2)
-8.31 (3.1)

L2R
-6.6 (1.6)
-3.7 (14.7)
+0.5 (0.5)
-2.2 (0.7)
-5.6 (0.4)
-5.9 (0.5)
-11.8 (0.8)
-5.5 (0.6)
-5 (2.3)
-18.03 (1.5)
-7.98 (0.2)
-8.1 (8.1)

VAT
-12.3 (1)
-19.3 (0.1)
+0.5 (0)
-3.8 (0.2)
+1.1 (0.1)
+1.6 (0.5)
+3.7 (0.5)
+3.0 (0.5)
+0.41 (3.5)
-10.8 (5.3)
-6.12 (0.12)
-7.89 (1.6)

Methods
PR
+2.7 (15.6)
-11.7 (4.1)
-4.7 (0.4)
-7.5 (0.5)
+0.3 (0.1)
+0.6 (0.3)
-2.2 (0.6)
+0.4 (0.4)
-4.49 (3.6)
-8.12 (2.1)
-5.59 (0.2)
-7 (4.7)

IL
+2.4 (1.7)
-6.4 (8.2)
+0.2 (0.3)
-2.6 (0.3)
0 (0.3)
+1.5 (0.3)
-0.3 (0.8)
+0.8 (0.8)
-0.85 (0.6)
-3.79 (0.1)
-2.11 (0.1)
-3.4 (0.16)

AUTO-SPEAR WISDOM HUM-SPEAR
+3.4 (0.1)
+3.6 (1.4)
+1.4 (0.0)
+4.4 (0.2)
+1.5 (0.1)
+2 (0.5)
+3.4 (0.5)
+3.9 (0.5)
+1.04 (0.8)
+3.97 (0.7)
+0.97 (0.3)
+0.79 (0.3)

+2.4 (1.6)
-2.4 (1.6)
+0.8 (0.5)
-7.9 (3.7)
0.4 (0.8)
-1.5 (1.8)
-0.9 (0.5)
+2.7 (0.1)
-4.24 (0.4)
+1.9 (0.1)
-4.12 (0.1)
-3.13 (2.1)

NA
NA
+3.8 (0.2)
+6.9(0.7)
+0.1 (0.5)
0 (0.1)
+5 (0.5)
+4.7(0.3)
NA
NA
NA
NA

Table 4: Performance of different approaches on six datasets, viz., IMDB, YouTube, SMS, TREC, Twitter, and SST-
5. Results are shown for both ’Raw’ or ’Lemmatized’ features. The numbers reported are macro-F1 scores over
the test set averaged over 5 runs, and for all methods after the double-line are reported as gains over the baseline
(Supervised). L2R, PR, IL, AUTO-SPEAR, and WISDOM all use the automatically generated LFs; Supervised and
VAT do not use LFs; and HUM-SPEAR uses the human generated LFs. ’NA’ in HUM-SPEAR column is when
human LFs are not available. Numbers in brackets ‘()’ represents standard deviation of the original scores and not
of the gains.

by examples paradigm produces a program from
a given set of input-output pairs (Gulwani, 2012;
Singh and Gulwani, 2012). It synthesises those
programs that satisfy all input-output pairs. Ru-
leNN (Sen et al., 2020) learns interpretable ﬁrst-
order logic rules as composition of semantic role
attributes. Many of these approaches, however,
learn more involved rules (using e.g., a neural net-
work) which may not work in the realistic setting
of very small labeled data. In contrast, SNUBA and
WISDOM use more interpretable models (Rudin,
2019) like logistic regression and decision trees for
rule induction.

Semi-supervised Learning (SSL): The goal of
SSL is to effectively use unlabeled data while train-
ing. Early SSL algorithms used regularization-
based approaches like margin regularization, and
laplacian regularization (Chapelle et al., 2010).
Most recent SSL approaches like Mean Teacher
(Tarvainen and Valpola, 2018), VAT (Miyato et al.,
2018), UDA (Xie et al., 2020), MixMatch (Berth-
elot et al., 2019) and FixMatch (Sohn et al., 2020)
introduced various kinds of perturbations and aug-
mentations that can be used along with consistency
loss. Even though the current SSL approaches per-
form well even with minimal labels, they are com-
putationally intensive and cannot be easily imple-
mented in low-resource scenarios. Furthermore, it
is tough to explain the discriminative behavior of
the semi-supervised models.

Bi-level Optimization: The concept of bi-level
optimization has been discussed in (von Stackel-
berg et al., 1952; Bracken and McGill, 1973; Bard,
2006). Since then, the framework of bi-level opti-

Figure 3: Ablation study with different labeled-set
sizes on the YouTube dataset.

CAGE
CAGEval
CAGEBi-level

Youtube
62.45
84.62
87.11

SMS
18.1
39.61
43.22

TREC
14.1
37.99
39.34

Table 5: Comparison of CAGE model with two vari-
ants. CAGEval includes validation set feedback in the
original CAGE loss function and CAGEBi-level is bi-level
formulation of CAGE objective using Eq 5.

as on CAGE. In Table 1, we had presented some
illustrative examples (from the TREC dataset) of
automatically induced LFs whose weights are rel-
atively higher based on the bi-level formulation
along with those that are down-weighted owing
to their conﬂicting signals. We present additional
examples as well as further qualitative analysis in
Section 9 of the supplementary.

5 Related Work

In this section, we describe some additional related
work that was not covered in Section 2.
Automatic Rule Generation: The programming

YouTube(5%)YouTube(10%)YouTube(15%)608066.467.6272.991.191.392.289.891.688.890.891.293.591.792.292.2SNUBAVATSPEARSUPWISDOMmization has been used in various machine learning
applications like hyperparameter tuning (Mackay
et al., 2019; Franceschi et al., 2018; Sinha et al.,
2020), robust learning (Ren et al., 2018; Guo et al.,
2020), meta-learning (Finn et al., 2017), efﬁcient
learning (Killamsetty et al., 2021) and continual
learning (Borsos et al., 2020). Previous applica-
tions of the bi-level optimization framework for
robust learning have been limited to supervised and
semi-supervised learning settings. To the best of
our knowledge, WISDOM is the ﬁrst framework
that uses a bi-level optimization approach for ro-
bust aggregation of labeling functions.

6 Conclusion

While induction of labeling functions (LFs) for
data-programming has been attempted in the past
by Varma and Ré (2018), we observe in our exper-
iments that the resulting model in itself does not
perform well on text classiﬁcation tasks, and turns
out to be even worse than the supervised baseline.
A more recent semi-supervised data programming
approach called SPEAR (Maheshwari et al., 2021),
when used in conjunction with the induced LFs,
performs better, though it fails to consistently out-
perform the supervised baseline. In this paper, we
introduce WISDOM, a bi-level optimization for-
mulation for reweighting the LFs, which injects
robustness into the semi-supervised data program-
ming approach, thus allowing it to perform well
in the presence of noisy LFs. On a reasonably
wide variety of text classiﬁcation datasets, we show
that WISDOM consistently outperforms all other
approaches, while also coming close to the skyline
of SPEAR using human-generated LFs.

Acknowledgements and Disclosure of
Funding

We thank anonymous reviewers for providing con-
structive feedback. Ayush Maheshwari is sup-
ported by a Fellowship from Ekal Foundation
(www.ekal.org). We are also grateful to IBM Re-
search, India (speciﬁcally the IBM AI Horizon Net-
works - IIT Bombay initiative) for their support
and sponsorship. Rishabh Iyer and Krishnateja
Killamsetty were funded by the National Science
Foundation(NSF) under Grant Number 2106937,
a startup grant from UT Dallas, and a Google and
Adobe research award. Any opinions, ﬁndings, and
conclusions or recommendations expressed in this
material are those of the author(s) and do not nec-
essarily reﬂect the views of the National Science
Foundation, Google or Adobe.

References

Túlio C Alberto, Johannes V Lochter, and Tiago A
Almeida. 2015. Tubespam: Comment spam ﬁlter-
In 2015 IEEE 14th international
ing on youtube.
conference on machine learning and applications
(ICMLA), pages 138–143. IEEE.

Tiago A Almeida, José María G Hidalgo, and Akebo
Yamakami. 2011. Contributions to the study of sms
In Pro-
spam ﬁltering: new collection and results.
ceedings of the 11th ACM symposium on Document
engineering, pages 259–262.

Abhijeet Awasthi, Sabyasachi Ghosh, Rasna Goyal,
and Sunita Sarawagi. 2020. Learning from rules
generalizing labeled exemplars. In 8th International
Conference on Learning Representations,
ICLR
2020, Addis Ababa, Ethiopia, April 26-30, 2020.
OpenReview.net.

Stephen H Bach, Daniel Rodriguez, Yintao Liu, Chong
Luo, Haidong Shao, Cassandra Xia, Souvik Sen,
Alex Ratner, Braden Hancock, Houman Alborzi,
et al. 2019. Snorkel drybell: A case study in deploy-
ing weak supervision at industrial scale. In Proceed-
ings of the 2019 International Conference on Man-
agement of Data, pages 362–375.

Jonathan F. Bard. 2006. Practical Bilevel Optimization:
Algorithms and Applications (Nonconvex Optimiza-
tion and Its Applications). Springer-Verlag, Berlin,
Heidelberg.

David Berthelot, Nicholas Carlini, Ian Goodfellow,
Nicolas Papernot, Avital Oliver, and Colin Raffel.
2019. Mixmatch: A holistic approach to semi-
supervised learning.

Zalán Borsos, Mojmír Mutný, and Andreas Krause.
2020. Coresets via bilevel optimization for contin-
ual learning and streaming.

Jerome Bracken and James T. McGill. 1973. Mathe-
matical programs with optimization problems in the
constraints. Operations Research, 21(1):37–44.

Olivier Chapelle, Bernhard Schlkopf, and Alexander
Zien. 2010. Semi-Supervised Learning, 1st edition.
The MIT Press.

Oishik Chatterjee, Ganesh Ramakrishnan, and Sunita
Sarawagi. 2020. Robust data programming with
precision-guided labeling functions. In AAAI.

Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017.
Model-agnostic meta-learning for fast adaptation of
deep networks.

Luca Franceschi, Paolo Frasconi, Saverio Salzo,
Riccardo Grazzi, and Massimilano Pontil. 2018.
Bilevel programming for hyperparameter optimiza-
tion and meta-learning.

Yves Grandvalet and Yoshua Bengio. 2005. Semi-
supervised learning by entropy minimization.
In
Advances in neural information processing systems,
pages 529–536.

Sumit Gulwani. 2012. Synthesis from examples: Inter-
action models and algorithms. In 2012 14th Interna-
tional Symposium on Symbolic and Numeric Algo-
rithms for Scientiﬁc Computing, pages 8–14. IEEE.

Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel
Urtasun. 2018. Learning to reweight examples for
In International Conference
robust deep learning.
on Machine Learning, pages 4334–4343. PMLR.

Lan-Zhe Guo, Zhen-Yu Zhang, Yuan Jiang, Yu-Feng
Li, and Zhi-Hua Zhou. 2020.
Safe deep semi-
supervised learning for unseen-class unlabeled data.
In Proceedings of the 37th International Conference
on Machine Learning, volume 119 of Proceedings
of Machine Learning Research, pages 3897–3906.
PMLR.

Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard H.
Harnessing
CoRR,

Hovy, and Eric P. Xing. 2016.
deep neural networks with logic rules.
abs/1603.06318.

Cynthia Rudin. 2019. Stop explaining black box ma-
chine learning models for high stakes decisions and
use interpretable models instead. Nature Machine
Intelligence, 1:206–215.

Prithviraj Sen, Marina Danilevsky, Yunyao Li, Sid-
dhartha Brahma, Matthias Boehm, Laura Chiticariu,
and Rajasekar Krishnamurthy. 2020. Learning ex-
plainable linguistic expressions with neural induc-
tive logic programming for sentence classiﬁcation.
In Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing (EMNLP),
pages 4211–4221.

Krishnateja Killamsetty, Durga Sivasubramanian,
Ganesh Ramakrishnan, and Rishabh Iyer. 2021.
Glister: Generalization based data subset selection
for efﬁcient and robust learning. In AAAI 2021.

Rishabh Singh and Sumit Gulwani. 2012. Synthesiz-
ing number transformations from input-output ex-
amples. In International Conference on Computer
Aided Veriﬁcation, pages 634–651. Springer.

Xin Li and Dan Roth. 2002. Learning question clas-
In COLING 2002: The 19th International

siﬁers.
Conference on Computational Linguistics.

Matthew Mackay, Paul Vicol,

Jonathan Lorraine,
David Duvenaud, and Roger Grosse. 2019. Self-
tuning networks: Bilevel optimization of hyperpa-
rameters using structured best-response functions.
In International Conference on Learning Represen-
tations.

Ayush Maheshwari, Oishik Chatterjee, KrishnaTeja
Killamsetty, Rishabh K. Iyer, and Ganesh Ramakr-
Data programming using semi-
ishnan. 2021.
supervision and subset selection. In Proceedings of
the 59th Annual Meeting of the Association for Com-
putational Linguistics.

Takeru Miyato, Shin-ichi Maeda, Masanori Koyama,
and Shin Ishii. 2018. Virtual adversarial training:
a regularization method for supervised and semi-
IEEE transactions on pat-
supervised learning.
tern analysis and machine intelligence, 41(8):1979–
1993.

Adam Paszke, Sam Gross, Francisco Massa, Adam
Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca
Antiga, Alban Desmaison, Andreas Köpf, Edward
Yang, Zach DeVito, Martin Raison, Alykhan Tejani,
Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Jun-
jie Bai, and Soumith Chintala. 2019. Pytorch: An
imperative style, high-performance deep learning li-
brary.

Ankur Sinha, Tanmay Khandait, and Raja Mohanty.
2020. A gradient-based bilevel optimization ap-
proach for tuning hyperparameters in machine learn-
ing.

Richard Socher, Alex Perelygin, Jean Wu, Jason
Chuang, Christopher D Manning, Andrew Y Ng,
and Christopher Potts. 2013. Recursive deep mod-
els for semantic compositionality over a sentiment
treebank. In Proceedings of the 2013 conference on
empirical methods in natural language processing,
pages 1631–1642.

Kihyuk Sohn, David Berthelot, Chun-Liang Li, Zizhao
Zhang, Nicholas Carlini, Ekin D. Cubuk, Alex Ku-
rakin, Han Zhang, and Colin Raffel. 2020. Fix-
match: Simplifying semi-supervised learning with
consistency and conﬁdence.

Antti Tarvainen and Harri Valpola. 2018. Mean teach-
ers are better role models: Weight-averaged consis-
tency targets improve semi-supervised deep learning
results.

Paroma Varma and Christopher Ré. 2018. Snuba: Au-
tomating weak supervision to label training data.
Proc. VLDB Endow., 12(3):223–236.

Paroma Varma and Christopher Ré. 2018. Snuba: au-
tomating weak supervision to label training data. In
Proceedings of the VLDB Endowment. International
Conference on Very Large Data Bases, volume 12,
page 223. NIH Public Access.

H. von Stackelberg, S.H. Von, and A.T. Peacock. 1952.
The Theory of the Market Economy. Oxford Univer-
sity Press.

Alexander J Ratner, Christopher M De Sa, Sen Wu,
Daniel Selsam, and Christopher Ré. 2016. Data pro-
gramming: Creating large training sets, quickly. In
Advances in neural information processing systems,
pages 3567–3575.

Yun Wan and Qigang Gao. 2015. An ensemble senti-
ment classiﬁcation system of twitter data for airline
services analysis. In 2015 IEEE international con-
ference on data mining workshop (ICDMW), pages
1318–1325. IEEE.

Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Lu-
ong, and Quoc V. Le. 2020. Unsupervised data aug-
mentation for consistency training.

7 Explanation of loss terms

Appendix

(cid:16)

(L1):
(cid:17)

the loss LCE

φ (y = yi|xi)

The ﬁrst component

First Component
P f

(L1) of
is the standard cross-entropy loss on the labelled dataset L for the model P f
φ .

− log
Second Component (L2): The second component L2 is the semi-supervised loss on the unlabelled data
U. In our framework, we can use any unsupervised loss function.
Third Component (L3): The third component LCE
is the cross entropy of the
classiﬁcation model using the hypothesised labels from CAGE (Chatterjee et al., 2020) on U. Given that
li is the output vector of all labelling functions for any xi ∈ U, we specify the predicted label for xi using
the LF-based graphical model Pθ(li, y) as: g(li) = argmax

φ (y|xi), g(li), w

φ (y|xi), yi

Pθ,w(li, y)

P f

=

(cid:16)

(cid:17)

(cid:16)

P f

(cid:17)

y

loss on the labelled dataset L: LLs(θ, w|L) = −

Fourth Component (L4): The fourth component LLs(θ|L) is the (supervised) negative log likelihood
N
(cid:80)
i=1
Fifth Component (L5): The ﬁfth component LLu(θ, w|U) is the negative log likelihood loss for the
unlabelled dataset U. Since the true label information is not available, the probabilities need to be summed

log Pθ,w(li, yi)

over y: LLu(θ, w|U) = −

M
(cid:80)
i=N +1

log (cid:80)
y∈Y

Pθ,w(li, y)

Sixth Component (L6): The sixth component KL(P f
φ,w(y|xi), Pθ(y|li)) is the Kullback-Leibler (KL)
divergence between the predictions of both the models, viz., feature-based model fφ and the LF-based
graphical model Pθ summed over every example xi ∈ U ∪ L. Through this term, we try and make the
models agree in their predictions over the union of the labelled and unlabelled datasets.

Quality Guides (QG): As a last component in our objective, we use quality guides R(θ, w|{qj}) on
LFs which have been shown (Chatterjee et al., 2020) to stabilise the unsupervised likelihood training
while using labelling functions. Let qj be the fraction of cases where λj correctly triggered. And let qt
j be
the user’s belief on the fraction of examples xi where yi and lij agree. If user’s beliefs weren’t available,
we consider precision of LFs on validation set as the user’s beliefs. Except SMS dataset, we take precision
of LFs on validations set as quality guides. If Pθ,w(yi = kj|lij = 1) is the model-based precision over the

LFs, the quality guide based loss can be expressed as R(θ, w|{qt

(cid:18)

j}) = −

(cid:80)

j qt

j log Pθ,w(yi = kj|lij =

1) + (1 − qt

j) log(1 − Pθ,w(yi = kj|lij = 1))

(cid:19)
.

8 LF Analysis

We compare statistics of automatically induced LFs and human-curated LFs in Table 6. While developing
LFs, humans generally tend to design LFs based on generalizibility of the pattern without worrying
much about the conﬂicts among the patterns. Whereas the LF induction in WISDOM focuses on inducing
individually precise LFs without necessarily focusing on the overall coverage. Except in the case of the
SMS dataset, collective coverage of human designed LFs is much higher than that of the automatically
induced LFs. We also observe in Table 6 that higher coverage leads to higher conﬂicts. Whereas, on an
average, the precision is higher for each of the automatically induced LFs in the case of every dataset.

9 Qualitative Analysis of Automatically Induced LFs

For the six datasets used for experimentation, we automatically induce LFs using Snuba (Varma and Ré,
2018). We show the automatically induced LFs and their respective weights assigned by WISDOM for
three datasets TREC, IMDB, and SMS below.

In Table 7, we present LFs produced by the Snuba for the TREC dataset sorted in descending order of
weights for each class along with the weights assigned by WISDOM to each of the LFs. From analysis,
we observe that WISDOM does a good job of reweighting LFs. For instance, how many was given
higher weightage than how and many for class Numeric; this sounds logical as well since sentences
containing the keyword how many are more likely to belong to class Numeric than sentences containing

Auto LFs
#LFs Precision Conﬂict Cover (%)

Human LFs
#LFs Precision Conﬂict Cover(%)

YouTube
SMS
TREC

11
25
13

94.3
94.9
70.1

8.1
3.2
2.3

63.4
47.9
62.3

10
73
68

79.8
92.3
59.9

28.7
1.0
22.3

88.0
33.3
95.1

Table 6: Comparison of automatically generated LFs with human-curated LFs. Coverage is fraction of instances
in U covered by at least one rule. Precision refers to micro precision of rules. Conﬂict denotes the fraction of
instances covered by conﬂicting rules among all the covered instances.

LF

Class
NUM how many
NUM how
NUM many
DESC what kind
DESC what was
LOC
LOC
LOC
ENTY what does
ENTY def
ENTY why
ENTY what is
HUM who

city
country
where

Weights
1
1
0.62
1
0.54
1
0.84
0.05
1
1
0.8
0.65
0.00012

Table 7: Automatically induced LFs by Snuba (Varma and Ré, 2018) for the TREC dataset sorted in descending
order of weights per class assigned by WISDOM. Column 1 refers to the class associated with the induced LF. No
LFs were induced for class Abbreviation.

the keyword how or many. Another example is among LFs associated with Location class, LFs city and
country were given higher weightage than where. However, WISDOM does a poor job by assigning a
very small weight value to the single LF who associated with the Human class.

In Table 8, we present LFs produced by the Snuba for the IMDB dataset sorted in descending order of
weights for each class along with the weights assigned by WISDOM to each of the LFs. For the IMDB
dataset as well, we can see that WISDOM does a good job of reweighting LFs. For instance,among
the LFs associated with the class ROMANCE, wife and love were given higher weightage than
other LFS like friendship, wealthy, town; this sounds logical as well since ROMANCE is often
associated with the sentences containing the keywords wife, love than sentences containing the
keyword friendship, town, wealthy. One more key observation is that apart from LFs wife
and love, all other LFs associated with the class ROMANCE are given weights of 0(equivalent to
ignoring them). However, assigning 0 weights is controversial for LFs like boyfriend since there is a
possibility of ROMANCE associated with the sentence containing keyword boyfriend. Similarly for
LFs associated with Action class, LFs government, agent, and plan were given higher weightage
than race, and team.

In Table 9, we present LFs produced by the Snuba for the SMS dataset sorted in descending order of
weights for each class along with the weights assigned by WISDOM to each of the LFs. For the SMS
dataset, we can see that WISDOM did not do as good a job of reweighting as done on other datasets.
For instance,among the LFs associated with the class SPAM, ur, video and cam were given higher
weightage while completely ignoring(i.e., assigned a weight of zero) to other important LFS like free,
claim, won. Whereas for LFs associated with the class NOT SPAM, WISDOM did a good job. One
possible reason for the poor job of WISDOM for reweighting LFs associated with the class SPAM is that
class imbalance present in the unlabeled set, where the sample count of samples of the class SPAM is

Class

LF

ROMANCE wife
ROMANCE love
ROMANCE boyfriend
ROMANCE friendship
ROMANCE wealthy
ROMANCE story
ROMANCE town
ROMANCE friend
ACTION
ACTION
ACTION
ACTION
ACTION

government
plan
agent
team
race

Weights
0.412
0.042
0
0
0
0
0
0
1
0.985
0.913
0.753
0.685

Table 8: Automatically induced LFs by Snuba (Varma and Ré, 2018) for the IMDB dataset sorted in descending
order of weights per class assigned by WISDOM. Column 1 refers to the class associated with the induced LF.

Class

LF

Weights

ur
SPAM
video
SPAM
com
SPAM
contact
SPAM
holiday
SPAM
free
SPAM
claim
SPAM
stop
SPAM
won
SPAM
win
SPAM
uk
SPAM
text
SPAM
SPAM
urgent
NOTSPAM come
NOTSPAM ok
NOTSPAM got
NOTSPAM like
NOTSPAM sorry

1
1
1
0.2213
0.1593
0
0
0
0
0
0
0
0
1
1
1
1
0.03731254

Table 9: Automatically induced LFs by Snuba (Varma and Ré, 2018) for the SMS dataset sorted in descending
order of weights per class assigned by WISDOM. Column 1 refers to the class associated with the induced LF.

eight times smaller than the sample count of the class SPAM. From our LF analysis results across the
three datasets, we observe that WISDOM tries to up weigh LFs that are more speciﬁc and precise and
downweigh LFs that are abstract and less precise.

