Simulation-Assisted Decorrelation for
Resonant Anomaly Detection

Kees Benkendorfer,1,3 Luc Le Pottier,2,3 and Benjamin Nachman3

1Physics Department, Reed College, Portland, OR 97202, USA
2Physics Department, University of Michigan, Ann Arbor, MI 48109, USA
3Physics Division, Lawrence Berkeley National Laboratory, Berkeley, CA 94720, USA

E-mail: kebenkend@reed.edu, luclepot@umich.edu, bpnachman@lbl.gov

Abstract: A growing number of weak- and unsupervised machine learning ap-
proaches to anomaly detection are being proposed to signiﬁcantly extend the search
program at the Large Hadron Collider and elsewhere. One of the prototypical exam-
ples for these methods is the search for resonant new physics, where a bump hunt can
be performed in an invariant mass spectrum. A signiﬁcant challenge to methods that
rely entirely on data is that they are susceptible to sculpting artiﬁcial bumps from the
dependence of the machine learning classiﬁer on the invariant mass. We explore two
solutions to this challenge by minimally incorporating simulation into the learning. In
particular, we study the robustness of Simulation Assisted Likelihood-free Anomaly De-
tection (SALAD) to correlations between the classiﬁer and the invariant mass. Next,
we propose a new approach that only uses the simulation for decorrelation but the
Classiﬁcation without Labels (CWoLa) approach for achieving signal sensitivity. Both
methods are compared using a full background ﬁt analysis on simulated data from the
LHC Olympics and are robust to correlations in the data.

0
2
0
2

p
e
S
4

]
h
p
-
p
e
h
[

1
v
5
0
2
2
0
.
9
0
0
2
:
v
i
X
r
a

 
 
 
 
 
 
Contents

1 Introduction

2 Methods

2.1 Simulation Assisted Likelihood-free Anomaly Detection (SALAD)
2.2 Simulation Augmented Classiﬁcation without Labels (CWoLa)
2.3 Bump Hunt Analysis

3 Simulation

4 Results

5 Conclusions

1

Introduction

1

2
3
3
4

5

7

11

Despite compelling experimental (e.g. dark matter) and theoretical (e.g. the hierarchy
problem) evidence for new phenomena at the electroweak scale, experiments at the
Large Hadron Collider (LHC) have not yet discovered any physics beyond the Standard
Model (BSM). There are major search eﬀorts across LHC experiments [1–7], where most
analyses target a particular class of BSM models. While this work is well-motivated
and continuing to improve in sensitivity (in part due to machine learning [8–11]), there
is also a growing need for new search strategies capable of discovery in unexpected
scenarios.

A variety of automated anomaly detection techniques using innovative machine
learning methods are being proposed to cover the unexpected [12–38]. An important
subset of these proposals targets resonant new physics, where sideband methods can be
used to estimate the SM background directly from data. A key challenge facing such
methods is that the machine learning classiﬁers must be relatively independent from
the resonant feature, for otherwise artiﬁcial bumps can be formed. Many automated
decorrelation methods have been proposed to ensure that classiﬁers are decorrelated
from particular features by construction [39–50], but they may not apply in all cases.
In particular, weakly supervised approaches that learn directly on the signal region
cannot be simply combined with a decorrelation scheme because such an approach could

– 1 –

degrade the performance in the presence of a signal. A localized signal would manifest
as a dependence between the resonant feature and other features for classiﬁcation, so
forcing independence could eliminate signal sensitivity.

In this paper, two weakly supervised approaches are studied: Classiﬁcation with-
out Labels (CWoLa) [13–15, 51] and Simulation Assisted Likelihood-free Anomaly
Detection (Salad) [27]. CWoLa is a method that does not depend on simulation and
achieves signal sensitivity by comparing a signal region with nearby sideband regions
in the resonance feature. As a result, CWoLa is particularly sensitive to dependencies
between the classiﬁcation features and the resonant feature. Salad uses a reweighted
simulation to achieve signal sensitivity. Since it never directly uses the sideband region,
Salad is expected to be more robust than CWoLa to dependencies. In order to re-
cover the performance of CWoLa in the presence of signiﬁcant dependence between the
classiﬁcation features and the resonant feature, a new method called simulation aug-
mented CWoLa (SA-CWoLa) is introduced. The SA-CWoLa approach augments
the CWoLa loss function to penalize the classiﬁer for learning diﬀerences between the
signal region and the sideband region in simulation, which is signal-free by construc-
tion. All of these methods will be investigated using the correlation test proposed in
Ref. [28].

This paper is organized as follows. Section 2 reviews the Salad and CWoLa
methods and introduces the simulation augmented CWoLa search strategy. Further-
more, the sideband analysis is setup in Sec. 2. The simulations used for illustrating
the various approaches are described in Sec. 3. Results for the diﬀerent strategies are
presented in Sec. 4. The paper ends with conclusions and outlook in Sec. 5.

2 Methods

For a set of features (m, x) ∈ Rn+1, let f : Rn → [0, 1] be parameterized by a neural
network. The observable m is special, for it is the resonance feature that should be
relatively independent from f (x). The signal region (SR) is deﬁned by an interval in
m and the sidebands (SB) are neighboring intervals.

All neural networks were implemented in Keras [52] with the Tensorflow back-
end [53] and optimized with Adam [54]. Each network is composed of three hidden
layers with 64 nodes each and use the rectiﬁed linear unit (ReLU) activation function.
The sigmoid function is used after the last layer. Training proceeds for 10 epochs with
a batch size of 200. None of these parameters were optimized; it is likely that improved
performance could be achieved with an in-situ optimization based on a validation set.

– 2 –

2.1 Simulation Assisted Likelihood-free Anomaly Detection (SALAD)
The Salad network [27] is optimized using the following loss:

LSALAD[f ] = −

(cid:88)

log(f (xi)) −

(cid:88)

w(xi, m) log(1 − f (xi))

(2.1)

i∈SR,data

i∈SR,sim.

where w(xi, m) = g(xi, m)/(1 − g(xi, m)) are a set of weights using the Classiﬁcation
for Tuning and Reweighting (Dctr) [55] method. The function g is a parameterized
classiﬁer [56, 57] trained to distinguish data and simulation in the sideband:

L[g] = −

(cid:88)

log(g(xi, m)) −

(cid:88)

log(1 − g(xi, m)) .

(2.2)

i∈SB,data

i∈SB,sim.

The above neural networks are optimized with binary cross entropy, but one could use
other functions as well, such as the mean-squared error. Intuitively, the idea of Salad is
to train a classiﬁer to distinguish data and simulation in the SR. However, there may be
signiﬁcant diﬀerences between the background in data and the background simulation,
so a reweighting function is learned in the sidebands that makes the simulation look
more like the background in data.

2.2 Simulation Augmented Classiﬁcation without Labels (CWoLa)
The idea of CWoLa [51] is to construct two mixed samples of data that are each
composed of two classes. Using CWoLa for resonant anomaly detection [13, 14], one
can construct the mixed samples using the SR and SB. In the absence of signal, the
SR and SB should be statistically identical and therefore the CWoLa classiﬁer does
not learn anything useful. However, if there is a signal, then it can detect the presence
of a diﬀerence between the SR and SB. In practice, there are small diﬀerences between
the SR and SB because there are dependencies between m and x and so CWoLa will
only be able to ﬁnd signals that introduce a bigger diﬀerence than already present
in the background. The CWoLa anomaly detection strategy was recently used in a
low-dimensional application by the ATLAS experiment [15].

We propose a modiﬁcation of the usual CWoLa loss function in order to construct

a simulation-augmented (SA) CWoLa classiﬁer:

LSA-CWola[f ] = −

(cid:88)

log(f (xi)) −

(cid:88)

log(1 − f (xi))

i∈SR,data

i∈SB,data

(cid:32)

(cid:88)

+ λ

log(f (xi)) +

(cid:88)

i∈SR,sim.

i∈SB,sim.

(cid:33)

log(1 − f (xi))

,

(2.3)

– 3 –

where λ > 0 is a hyper-parameter. The limit λ → 0 is the usual CWoLa approach
and for λ > 0, the classiﬁer is penalized if it can distinguish the SR from the SB in the
(background-only) simulation1. In order to help the learning process, the upper and
lower sidebands are given the same total weight as each other and together, the same
weight as the SR.

2.3 Bump Hunt Analysis

In addition to quantifying performance with Receiver Operating Characteristic (ROC)
curves, it is also useful to emulate a proper background estimation based on a bump
hunt. A histogram of the mjj spectrum, possibly after applying a threshold on one of
the classiﬁers described above, is ﬁt to the following parametric function:

dσ
dmjj

=

p0 (1 − x)p1
xpx+p3 log(x) ,

(2.4)

√

s and pi are ﬁt parameters. This function has a long history and
where x = mjj/
has also been recently used by the ATLAS and CMS collaborations (see e.g. [58, 59]).
Alternative non-parametric functions are also possible (such as Gaussian processes [60]),
but these are not needed for the demonstration considered here. The SR is masked
during the ﬁt and then a p-value of the observed data is computed in the usual way.
In particular, a test statistic is formed from the proﬁle likelihood ratio:

λ0 =

maxθ p(n|µ = 0, θ)
maxµ,θ p(n|µ, θ)

,

(2.5)

where n is the number of observed events in the SR and θ is a nuisance parameter from
the sideband ﬁt:

p(n|µ, θ) = Poisson(n|b + θ + µ)e−θ2/2σ2,

(2.6)

where b and σ are the number of events and uncertainty from the sideband ﬁt, respec-
tively. The test statistic itself is q0 = −2 log(λ0) when the extracted signal strength
(µ, θ) = argmaxµ(cid:48),θ(cid:48)p(n|µ(cid:48), θ(cid:48)) is µ > 0 and 0 otherwise. Asymptotic formulae from
Wald and Wilks then give the signiﬁcance Z =

q0 [61–63].

√

1One could also use the SALAD-reweighted background simulation. In practice, we found little
diﬀerence between using and not using the weights as the data/sim diﬀerences were a subleading
correction to the mass-dependence. However, this may be more useful in other applications. We
thank Jesse Thaler for this interesting idea.

– 4 –

In practice, one would scan the signal region across the mjj spectrum.

In this
analysis, we will focus on a single region with or without signal injected. The signal
region is deﬁned by mjj ∈ [3.3, 3.7] TeV and the sideband for CWoLa training is
deﬁned as mjj ∈ [3.1, 3.3] ∪ [3.7, 3.9] TeV. Long sidebands extended by 300 GeV in
either direction are used to train the Salad reweighting function. The background ﬁt
is performed between 2.6 and 5 TeV using 30 equally-spaced bins.

3 Simulation

The simulations used for this study were produced for the LHC Olympics 2020 com-
munity challenge [64]. In particular, the background process is composed of generic
dijet events with a requirement for at least one such jet with pT > 1.3 TeV. Signal
events are W (cid:48) → XY for mW (cid:48) = 3.5 TeV and hypothetical particles X and Y of mass
500 and 100 GeV, each decaying into pairs of quarks. Due to the mass hierarchy be-
tween the W (cid:48) boson and its decay products, the ﬁnal state is characterized by two
large-radius jets with two-prong substructure. The background and signal are simu-
lated using Pythia 8 [65, 66] and an alternative background sample is simulated using
Herwig++ [67]. A detector simulation is performed with Delphes 3.4.1 [68–70] using
the default CMS detector card. Particle ﬂow objects are the input to jet clustering,
implemented using Fastjet [71, 72] and the anti-kt algorithm [73] using R = 1.0 for
In what follows, Pythia will play the role of ‘data’ and the
the radius parameter.
Herwig sample will be used as the ‘simulation’. There are one million events for both
background samples, corresponding to an integrated luminosity of about 100 fb−1. In
order to simplify the analysis, the dataset is divided in half for training and testing.
More complicated procedures based on k-folding to use the entire dataset for both
training and testing are also possible, but are not considered here [13, 14].

Both the CWoLa and Salad methods have been demonstrated on the unmodiﬁed
LHC Olympics dataset. Following Ref. [28], the dependence between the jet masses and
mjj is artiﬁcially strengthened by redeﬁning mj (cid:55)→ mj + α mjj for α = 0.1. As shown
in Ref. [28], this shift is suﬃcient to reduce the eﬃcacy of the unmodiﬁed CWoLa
method.

In addition to the dijet invariant mass, four features are used for the anomaly
detection: the invariant mass of the lighter jet, the mass diﬀerence of the leading two
jets, and the τ21 [74, 75] of the leading two jets. The N -subjettiness τ21 quantiﬁes
the extent to which a jet is characterized by two subjets or one subjet. Histograms
of the four input features for the background are shown in Fig. 1. The signal jet
masses are localized at the X and Y masses (shifted by α mW (cid:48)) and the τ21 are shifted
In addition to presenting the data and
to lower values, indicating two-pronginess.

– 5 –

simulation histograms, Fig. 1 also shows the reweighted background simulation using
parameterized weights learned from a long sideband.

Figure 1. Left: the jet mass and τ21 of the jet with a smaller mass. Right: the diﬀerence
between the heavier and lighter jet masses and τ21 of the heavier jet. In addition to showing
the data, simulation, and signal, the histogram labeled ‘Sim.+DCTR’ is the simulation with
weights derived from a parameterized reweighting function trained on long sidebands.

– 6 –

0.00.20.40.60.81.0mJ1 [TeV]024681012Normalized to UnityBackground in SRDataSim.Sim. + DCTRSignal0.00.20.40.60.81.0mJ2mJ1 [TeV]01234567Normalized to UnityBackground in SRDataSim.Sim. + DCTRSignal0.00.20.40.60.81.0J1210.00.51.01.52.02.53.03.54.0Normalized to UnityBackground in SRDataSim.Sim. + DCTRSignal0.00.20.40.60.81.0J2210.00.51.01.52.02.53.03.54.0Normalized to UnityBackground in SRDataSim.Sim. + DCTRSignal4 Results

As a benchmark, 1500 signal events corresponding to a ﬁtted signiﬁcance of about 2σ is
injected into the data for training. For evaluation, the entire signal sample (except for
the small number of injected events) is used. Figure 2 shows the performance of various
conﬁgurations. The fully supervised classiﬁer uses high statistics signal and background
samples in the SR with full label information. Since the data are not labeled, this is
not achievable in practice. A solid red line labeled ‘Optimal CWoLa’ corresponds
to a classiﬁer trained using two mixed samples, one composed of pure background in
the single region and the other composed of mostly background (independent from
the ﬁrst sample) in the SR with the 1500 signal events. This is optimal in the sense
that it removes the eﬀect from phase space diﬀerences between the SR and SB for
the background. The Optimal CWoLa line is far below the fully supervised classiﬁer
because the neural network needs to identify a small diﬀerence between the mixed
samples over the natural statistical ﬂuctuations in both sets. The actual CWoLa
method is shown with a dotted red line. By construction, there is a signiﬁcant diﬀerence
between the phase space of the SR and SB and so the classiﬁer is unable to identify the
signal. At low eﬃciency, the CWoLa classiﬁer actually anti-tags because the SR-SB
diﬀerences are such that the signal is more SB-like then SR-like. Despite this drop
in performance, the simulation augmenting modiﬁcation (solid orange) with λ = 0.5
nearly recovers the full performance of CWoLa.

For comparison, a classiﬁer trained using simulation directly is also presented in
Figure 2. The line labeled ‘Data vs. Sim.’ directly trains a classiﬁer to distinguish the
data and simulation in the SR without reweighting. Due to the diﬀerences between the
background in data and the simulated background, this classiﬁer is not eﬀective. In
fact, the signal is more like the background simulation than the data background and
so the classiﬁer is worse than random (preferentially removes signal). The performance
is signiﬁcantly improved by adding in the parameterized reweighting, as advocated
by Ref. [27]. With this reweighting, the Salad classiﬁer is signiﬁcantly better than
random and is comparable to SA-CWoLa. The Optimal CWoLa line also serves as
the upper bound in performance for Salad because it corresponds to the case where
the background simulation is statistical identical to the background in data.

The SA-CWoLa method has one free parameter that must be tuned. Figure 3
quantiﬁes the performance of the SA-CWoLa classiﬁer as a function of λ. The perfor-
mance of SA-CWoLa is strong and relatively stable for 0.3 < λ < 0.6. For λ (cid:38) 0.2,
the classiﬁer is eﬀectively blinded to diﬀerences between the SR and SB as illustrated
in the orange lines in Fig. 3 approaching 0.5 in the left plot.

– 7 –

Figure 2. A Receiver Operating Characteristic (ROC) curve (left) and signiﬁcance im-
provement curve (right) for various anomaly detection methods described in the text. The
signiﬁcance improvement is deﬁned as the ratio of the signal eﬃciency to the square root of
the background eﬃciency. A signiﬁcance improvement of 2 means that the initial signiﬁcance
would be ampliﬁed by about a factor of two after employing the anomaly detection strategy.
The supervised line is unachievable unless there is no mismodeling and one designed a search
for the speciﬁc W (cid:48) signal used in this paper. The curve labeled ‘Random’ corresponds to
equal eﬃciency for signal and background.

Figure 3. The Area Under the ROC Curve (AUC) (left) and signiﬁcance improvement at
50% signal eﬃciency (right) using the SA-CWoLa method for a scan in the hyperparameter λ
introduced in Eq. 2.3. When λ = 0, SA-CWoLa is the same as the original CWoLa method.
For comparison, the performance of the classiﬁer for distinguishing signal and background
is shown in blue and the performance for distinguishing the SR and SB is shown in orange.
Ideally, the latter would have an AUC of 0.5.

– 8 –

0.00.20.40.60.81.0Signal Efficiency (True Positive Rate)100101102103104105106Rejection (1/False Positive Rate)SupervisedData vs. Sim.SALADOptimal CWoLaCWoLaSA-CWoLaRandom0.00.20.40.60.81.0Signal Efficiency (True Positive Rate)012345Significance Improvement0.00.20.40.60.81.00.00.20.40.60.81.0AUCSignal versus BackgroundBackground in SR versus SB0.00.20.40.60.81.012345S / B @ S=50%Signal versus BackgroundBackground in SR versus SBWhile ROC and signiﬁcance improvement curves are eﬀective for quantifying per-
formance, they do not communicate the complete story because they ignore the impact
of background estimation. Figures 6 and 7 show the results of the sideband ﬁt and
statistical test (See Sec. 2.3). The ﬁt quality is excellent when considering all bins (see
Fig. 4), but there happens to be a small local deﬁcit in the SR. The right plot of Fig. 6
removes this eﬀect by subtracting the ﬁtted residuals in the background-only case for
each value of the NN background eﬃciency. The spectra after applying the nominal
CWoLa classiﬁer cannot be ﬁt to the same shape and are thus not included - see Fig. 5.

Figure 4. A ﬁt to the mjj distribution in the background-only case with no selection on any
neural networks. The 1500 signal events used for training is super-imposed for illustration.
Vertical dashed lines indicate the SR and SB regions used for training. A Kolmogorov-Smirnov
(KS) test using only bins outside of the SR yields a p-value of 0.69.

Figure 5. Histograms of mjj for CWoLa (top) and SA-CWoLa (bottom) for various
thresholds on the classiﬁers in the background-only case.

– 9 –

250030003500400045005000mjj [GeV]101102103104105Events per binSRSBSBFit (KS p= 0.69)BackgroundSignal300040005000mjj [GeV]104Number of events80%CWoLa300040005000mjj [GeV]10440%300040005000mjj [GeV]10010110210310420%300040005000mjj [GeV]10010110210310410%300040005000mjj [GeV]1001011021031%300040005000mjj [GeV]104Number of events80%SA-CWoLa300040005000mjj [GeV]10310440%300040005000mjj [GeV]10310420%300040005000mjj [GeV]10310%300040005000mjj [GeV]1021%Figure 6. Fit excess with signal injected using the statistical procedure described in Sec. 2.3.
There is a small local deﬁcit in the simulation. The left plot shows the ﬁtted excess without
modifying the background while the right plot corrects for the initial deﬁcit by subtracting
the residuals of the background-only ﬁt before performing the signal+background ﬁt. In the
latter case, the signiﬁcances are still not S/
B due to the uncertainty from the sideband ﬁt.

√

Figure 7. Fit excess without signal injected using the statistical procedure described in
Sec. 2.3. Without any signal injected, there is a small (∼ 1.5σ) deﬁcit in the simulation. The
right plot shifts the curves so that the 100% eﬃciency point corresponds to 0σ.

– 10 –

106105104103102101100NN background efficiency01234567SR excess [units of ]Optimal CWoLaSA-CWoLaSALAD106105104103102101100NN background efficiency246810SR excess [units of ]Optimal CWoLaSA-CWoLaSALAD106105104103102101100NN background efficiency32101SR excess [units of ]Optimal CWoLaSA-CWoLaSALAD106105104103102101100NN background efficiency10123Shifted SR excess [units of ]Optimal CWoLaSA-CWoLaSALAD5 Conclusions

This paper has investigated the impact of dependencies between mjj and classiﬁca-
tion features for the resonant anomaly detection methods Salad and CWoLa. A
new simulation-augmented approach has been proposed to remedy challenges with the
CWoLa method. This modiﬁcation is shown to completely recover the performance
of CWoLa from the ideal case where dependences are ignored in the training. In both
the Salad and SA-CWoLa methods, background-only simulations provide a critical
tool for mitigating the sensitivity of the classiﬁers on dependences between the resonant
feature and the classiﬁer features.

These weakly supervised methods are particularly promising, but they are not
the only recently-proposed machine-learning based anomaly detection methods.
In
particular, unsupervised methods also have great potential. The Anomaly Detection
with Density Estimation (Anode) [28] does not use simulation at all and has been
shown to be relatively robust to dependencies between the resonant feature and the
classiﬁer features. Additionally, autoencoder methods have been combined with explicit
decorrelation to build in robustness to such dependencies [18].

Each of these unsupervised and semisupervised methods have advantages and weak-
nesses and it is likely that multiple approaches will be required to achieve broad sensi-
tivity to BSM physics. Therefore, it is critical to study the sensitivity of each technique
to dependencies and propose modiﬁcations where possible to build robustness. This
paper is an important step in the decorrelation program for automated anomaly detec-
tion with machine learning. Tools like the ones proposed here may empower higher-
dimensional versions of the existing ATLAS search [15] as well as other related searches
by other experiments in the near future.

Code and Data

The code for this paper can be found at https://github.com/bnachman/DCTRHunting
and the simulated data are available from the LHC Olympics [64].

Acknowledgments

BN would like to thank Jack Collins for useful discussions and Jesse Thaler for helpful
feedback on the manuscript. This work was supported by the Department of Energy,
Oﬃce of Science under contract number DE-AC02-05CH11231. KB was supported in
part by NSF PHY REU Grant 1949923. LLP was supported in part by the U.S. De-
partment of Energy, Oﬃce of Science, Oﬃce of Workforce Development for Teachers

– 11 –

and Scientists (WDTS) under the Science Undergraduate Laboratory Internships Pro-
gram (SULI). BN would like to thank NVIDIA for providing Volta GPUs for neural
network training.

References

[1] ATLAS Collaboration, “Exotic physics searches,” 2018.

https://twiki.cern.ch/twiki/bin/view/AtlasPublic/ExoticsPublicResults.

[2] ATLAS Collaboration, “Supersymmetry searches,” 2018. https:

//twiki.cern.ch/twiki/bin/view/AtlasPublic/SupersymmetryPublicResults.

[3] ATLAS Collaboration, “Higgs and Diboson Searches,” 2019.

https://twiki.cern.ch/twiki/bin/view/AtlasPublic/HDBSPublicResults.

[4] CMS Collaboration, “Cms exotica public physics results,” 2018.

https://twiki.cern.ch/twiki/bin/view/CMSPublic/PhysicsResultsEXO.

[5] CMS Collaboration, “Cms supersymmetry physics results,” 2018.

https://twiki.cern.ch/twiki/bin/view/CMSPublic/PhysicsResultsSUS.

[6] CMS Collaboration, “Cms beyond-two-generations (b2g) public physics results,” 2018.

https://twiki.cern.ch/twiki/bin/view/CMSPublic/PhysicsResultsB2G.

[7] LHCb Collaboration, “Publications of the QCD, Electroweak and Exotica Working
Group,” 2019. http://lhcbproject.web.cern.ch/lhcbproject/Publications/
LHCbProjectPublic/Summary_QEE.html.

[8] A. J. Larkoski, I. Moult, and B. Nachman, “Jet Substructure at the Large Hadron

Collider: A Review of Recent Advances in Theory and Machine Learning,” Phys. Rept.
841 (2020) 1–63, arXiv:1709.04464 [hep-ph].

[9] D. Guest, K. Cranmer, and D. Whiteson, “Deep Learning and its Application to LHC

Physics,” arXiv:1806.11484 [hep-ex].

[10] M. Abdughani, J. Ren, L. Wu, J. M. Yang, and J. Zhao, “Supervised deep learning in

high energy phenomenology: a mini review,” Commun. Theor. Phys. 71 (2019) 955,
arXiv:1905.06047 [hep-ph].

[11] A. Radovic, M. Williams, D. Rousseau, M. Kagan, D. Bonacorsi, A. Himmel,

A. Aurisano, K. Terao, and T. Wongjirad, “Machine learning at the energy and
intensity frontiers of particle physics,” Nature 560 no. 7716, (2018) 41–48.

[12] R. T. D’Agnolo and A. Wulzer, “Learning New Physics from a Machine,” Phys. Rev.

D99 no. 1, (2019) 015014, arXiv:1806.02350 [hep-ph].

– 12 –

[13] J. H. Collins, K. Howe, and B. Nachman, “Anomaly Detection for Resonant New
Physics with Machine Learning,” Phys. Rev. Lett. 121 no. 24, (2018) 241803,
arXiv:1805.02664 [hep-ph].

[14] J. H. Collins, K. Howe, and B. Nachman, “Extending the search for new resonances

with machine learning,” Phys. Rev. D99 no. 1, (2019) 014038, arXiv:1902.02634
[hep-ph].

[15] ATLAS Collaboration, “Dijet resonance search with weak supervision using 13 TeV pp

collisions in the ATLAS detector,” arXiv:2005.02983 [hep-ex].

[16] R. T. D’Agnolo, G. Grosso, M. Pierini, A. Wulzer, and M. Zanetti, “Learning

Multivariate New Physics,” arXiv:1912.12155 [hep-ph].

[17] M. Farina, Y. Nakai, and D. Shih, “Searching for New Physics with Deep

Autoencoders,” Phys. Rev. D 101 no. 7, (2020) 075021, arXiv:1808.08992 [hep-ph].

[18] T. Heimel, G. Kasieczka, T. Plehn, and J. M. Thompson, “QCD or What?,” SciPost

Phys. 6 no. 3, (2019) 030, arXiv:1808.08979 [hep-ph].

[19] T. S. Roy and A. H. Vijay, “A robust anomaly ﬁnder based on autoencoder,”

arXiv:1903.02032 [hep-ph].

[20] O. Cerri, T. Q. Nguyen, M. Pierini, M. Spiropulu, and J.-R. Vlimant, “Variational

Autoencoders for New Physics Mining at the Large Hadron Collider,” JHEP 05 (2019)
036, arXiv:1811.10276 [hep-ex].

[21] A. Blance, M. Spannowsky, and P. Waite, “Adversarially-trained autoencoders for

robust unsupervised new physics searches,” JHEP 10 (2019) 047, arXiv:1905.10384
[hep-ph].

[22] J. Hajer, Y.-Y. Li, T. Liu, and H. Wang, “Novelty Detection Meets Collider Physics,”

Phys. Rev. D 101 no. 7, (2020) 076015, arXiv:1807.10261 [hep-ph].

[23] A. De Simone and T. Jacques, “Guiding New Physics Searches with Unsupervised
Learning,” Eur. Phys. J. C79 no. 4, (2019) 289, arXiv:1807.06038 [hep-ph].

[24] A. Mullin, H. Pacey, M. Parker, M. White, and S. Williams, “Does SUSY have friends?

A new approach for LHC event analysis,” arXiv:1912.10625 [hep-ph].

[25] G. M. Alessandro Casa, “Nonparametric semisupervised classiﬁcation for signal

detection in high energy physics,” arXiv:1809.02977 [hep-ex].

[26] B. M. Dillon, D. A. Faroughy, and J. F. Kamenik, “Uncovering latent jet

substructure,” Phys. Rev. D100 no. 5, (2019) 056002, arXiv:1904.04200 [hep-ph].

[27] A. Andreassen, B. Nachman, and D. Shih, “Simulation Assisted Likelihood-free

Anomaly Detection,” Phys. Rev. D 101 no. 9, (2020) 095004, arXiv:2001.05001
[hep-ph].

– 13 –

[28] B. Nachman and D. Shih, “Anomaly Detection with Density Estimation,” Phys. Rev.

D 101 (2020) 075042, arXiv:2001.04990 [hep-ph].

[29] J. A. Aguilar-Saavedra, J. H. Collins, and R. K. Mishra, “A generic anti-QCD jet

tagger,” JHEP 11 (2017) 163, arXiv:1709.01087 [hep-ph].

[30] M. Romo Crispim, N. Castro, R. Pedro, and T. Vale, “Transferability of Deep Learning
Models in Searches for New Physics at Colliders,” Phys. Rev. D 101 no. 3, (2020)
035042, arXiv:1912.04220 [hep-ph].

[31] M. C. Romao, N. Castro, J. Milhano, R. Pedro, and T. Vale, “Use of a Generalized

Energy Mover’s Distance in the Search for Rare Phenomena at Colliders,”
arXiv:2004.09360 [hep-ph].

[32] O. Knapp, G. Dissertori, O. Cerri, T. Q. Nguyen, J.-R. Vlimant, and M. Pierini,

“Adversarially Learned Anomaly Detection on CMS Open Data: re-discovering the top
quark,” arXiv:2005.01598 [hep-ex].

[33] B. M. Dillon, D. A. Faroughy, J. F. Kamenik, and M. Szewc, “Learning the latent

structure of collider events,” arXiv:2005.12319 [hep-ph].

[34] M. C. Romao, N. Castro, and R. Pedro, “Finding New Physics without learning about

it: Anomaly Detection as a tool for Searches at Colliders,” arXiv:2006.05432
[hep-ph].

[35] O. Amram and C. M. Suarez, “Tag N’ Train: A Technique to Train Improved

Classiﬁers on Unlabeled Data,” arXiv:2002.12376 [hep-ph].

[36] T. Cheng, J.-F. Arguin, J. Leissner-Martin, J. Pilette, and T. Golling, “Variational

Autoencoders for Anomalous Jet Tagging,” arXiv:2007.01850 [hep-ph].

[37] C. K. Khosa and V. Sanz, “Anomaly Awareness,” arXiv:2007.14462 [cs.LG].

[38] P. Thaprasop, K. Zhou, J. Steinheimer, and C. Herold, “Unsupervised Outlier

Detection in Heavy-Ion Collisions,” arXiv:2007.15830 [hep-ex].

[39] G. Louppe, M. Kagan, and K. Cranmer, “Learning to Pivot with Adversarial

Networks,” Advances in Neural Information Processing Systems 30 (2017) 981,
arXiv:1611.01046 [stat.ME].

[40] J. Dolen, P. Harris, S. Marzani, S. Rappoccio, and N. Tran, “Thinking outside the

ROCs: Designing Decorrelated Taggers (DDT) for jet substructure,” JHEP 05 (2016)
156, arXiv:1603.00027 [hep-ph].

[41] I. Moult, B. Nachman, and D. Neill, “Convolved Substructure: Analytically

Decorrelating Jet Substructure Observables,” JHEP 05 (2018) 002, arXiv:1710.06859
[hep-ph].

– 14 –

[42] J. Stevens and M. Williams, “uBoost: A boosting method for producing uniform
selection eﬃciencies from multivariate classiﬁers,” JINST 8 (2013) P12013,
arXiv:1305.7248 [nucl-ex].

[43] C. Shimmin, P. Sadowski, P. Baldi, E. Weik, D. Whiteson, E. Goul, and A. Sgaard,
“Decorrelated Jet Substructure Tagging using Adversarial Neural Networks,” Phys.
Rev. D 96 no. 7, (2017) 074034, arXiv:1703.03507 [hep-ex].

[44] L. Bradshaw, R. K. Mishra, A. Mitridate, and B. Ostdiek, “Mass Agnostic Jet
Taggers,” SciPost Phys. 8 no. 1, (2020) 011, arXiv:1908.08959 [hep-ph].

[45] ATLAS Collaboration, “Performance of mass-decorrelated jet substructure observables
for hadronic two-body decay tagging in ATLAS,” ATL-PHYS-PUB-2018-014 (2018) .
http://cds.cern.ch/record/2630973.

[46] L.-G. Xia, “QBDT, a new boosting decision tree method with systematical

uncertainties into training for High Energy Physics,” Nucl. Instrum. Meth. A930
(2019) 15–26, arXiv:1810.08387 [physics.data-an].

[47] C. Englert, P. Galler, P. Harris, and M. Spannowsky, “Machine Learning Uncertainties

with Adversarial Neural Networks,” Eur. Phys. J. C79 no. 1, (2019) 4,
arXiv:1807.08763 [hep-ph].

[48] S. Wunsch, S. J¨orger, R. Wolf, and G. Quast, “Reducing the dependence of the neural
network function to systematic uncertainties in the input space,” Comput. Softw. Big
Sci. 4 no. 1, (2020) 5, arXiv:1907.11674 [physics.data-an].

[49] G. Kasieczka and D. Shih, “DisCo Fever: Robust Networks Through Distance

Correlation,” arXiv:2001.05310 [hep-ph].

[50] M. S. D. S. G. Kasieczka, B. Nachman, “ABCDisCo: Automating the ABCD Method

with Machine Learning,” arXiv:2007.14400 [hep-ph].

[51] E. M. Metodiev, B. Nachman, and J. Thaler, “Classiﬁcation without labels: Learning
from mixed samples in high energy physics,” JHEP 10 (2017) 174, arXiv:1708.02949
[hep-ph].

[52] F. Chollet, “Keras.” https://github.com/fchollet/keras, 2017.

[53] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin, S. Ghemawat,

G. Irving, M. Isard, et al., “Tensorﬂow: A system for large-scale machine learning.,” in
OSDI, vol. 16, pp. 265–283. 2016.

[54] D. Kingma and J. Ba, “Adam: A method for stochastic optimization,”

arXiv:1412.6980 [cs].

[55] A. Andreassen and B. Nachman, “Neural Networks for Full Phase-space Reweighting
and Parameter Tuning,” Phys. Rev. D 101 no. 9, (2020) 091901, arXiv:1907.08209
[hep-ph].

– 15 –

[56] K. Cranmer, J. Pavez, and G. Louppe, “Approximating Likelihood Ratios with

Calibrated Discriminative Classiﬁers,” arXiv:1506.02169 [stat.AP].

[57] P. Baldi, K. Cranmer, T. Faucett, P. Sadowski, and D. Whiteson, “Parameterized

neural networks for high-energy physics,” Eur. Phys. J. C 76 no. 5, (2016) 235,
arXiv:1601.07913 [hep-ex].

[58] CMS Collaboration, A. M. Sirunyan et al., “Search for narrow and broad dijet

√

resonances in proton-proton collisions at
mediators and other new particles,” JHEP 08 (2018) 130, arXiv:1806.00843
[hep-ex].

s = 13 TeV and constraints on dark matter

[59] ATLAS Collaboration, G. Aad et al., “Search for new resonances in mass

distributions of jet pairs using 139 fb−1 of pp collisions at
ATLAS detector,” JHEP 03 (2020) 145, arXiv:1910.08447 [hep-ex].

s = 13 TeV with the

√

[60] M. Frate, K. Cranmer, S. Kalia, A. Vandenberg-Rodes, and D. Whiteson, “Modeling
Smooth Backgrounds and Generic Localized Signals with Gaussian Processes,”
arXiv:1709.05681 [physics.data-an].

[61] S. S. Wilks, “The large-sample distribution of the likelihood ratio for testing composite

hypotheses,” Ann. Math. Statist. 9 no. 1, (03, 1938) 60–62.
https://doi.org/10.1214/aoms/1177732360.

[62] A. Wald, “Tests of statistical hypotheses concerning several parameters when the

number of observations is large,” Transactions of the American Mathematical Society
54 no. 3, (1943) 426–482. http://www.jstor.org/stable/1990256.

[63] G. Cowan, K. Cranmer, E. Gross, and O. Vitells, “Asymptotic formulae for
likelihood-based tests of new physics,” Eur. Phys. J. C 71 (2011) 1554,
arXiv:1007.1727 [physics.data-an]. [Erratum: Eur.Phys.J.C 73, 2501 (2013)].

[64] G. Kasieczka, B. Nachman, and D. Shih, “R&D Dataset for LHC Olympics 2020

Anomaly Detection Challenge,” Apr., 2019. https://doi.org/10.5281/zenodo.2629073.

[65] T. Sj¨ostrand, S. Mrenna, and P. Z. Skands, “PYTHIA 6.4 Physics and Manual,” JHEP

05 (2006) 026, arXiv:hep-ph/0603175 [hep-ph].

[66] T. Sjostrand, S. Mrenna, and P. Z. Skands, “A Brief Introduction to PYTHIA 8.1,”

Comput. Phys. Commun. 178 (2008) 852–867, arXiv:0710.3820 [hep-ph].

[67] M. Bahr et al., “Herwig++ Physics and Manual,” Eur. Phys. J. C58 (2008) 639–707,

arXiv:0803.0883 [hep-ph].

[68] J. de Favereau, C. Delaere, P. Demin, A. Giammanco, V. Lematre, A. Mertens, and
M. Selvaggi, “DELPHES 3, A modular framework for fast simulation of a generic
collider experiment,” JHEP 02 (2014) 057, arXiv:1307.6346 [hep-ex].

[69] A. Mertens, “New features in Delphes 3,” J. Phys. Conf. Ser. 608 (2015) 012045.

– 16 –

[70] M. Selvaggi, “DELPHES 3: A modular framework for fast-simulation of generic

collider experiments,” J. Phys. Conf. Ser. 523 (2014) 012033.

[71] M. Cacciari, G. P. Salam, and G. Soyez, “FastJet User Manual,” Eur. Phys. J. C72

(2012) 1896, arXiv:1111.6097 [hep-ph].

[72] M. Cacciari and G. P. Salam, “Dispelling the N 3 myth for the kt jet-ﬁnder,” Phys.

Lett. B641 (2006) 57–61, arXiv:hep-ph/0512210 [hep-ph].

[73] M. Cacciari, G. P. Salam, and G. Soyez, “The Anti-k(t) jet clustering algorithm,”

JHEP 04 (2008) 063, arXiv:0802.1189 [hep-ph].

[74] J. Thaler and K. Van Tilburg, “Maximizing Boosted Top Identiﬁcation by Minimizing

N-subjettiness,” JHEP 02 (2012) 093, arXiv:1108.2701 [hep-ph].

[75] J. Thaler and K. Van Tilburg, “Identifying Boosted Objects with N-subjettiness,”

JHEP 03 (2011) 015, arXiv:1011.2268 [hep-ph].

– 17 –

