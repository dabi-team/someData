JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2019

1

Learning End-User Behavior for Optimized Bidding
in HetNets: Impact on User/Network Association

Mohammad Yousefvand, Member, IEEE, Narayan Mandayam, Fellow, IEEE,

9
1
0
2

p
e
S
1
1

]

Y
S
.
s
s
e
e
[

1
v
9
7
6
5
0
.
9
0
9
1
:
v
i
X
r
a

Abstract—We study the impact of end-user behavior on service
provider (SP) bidding and user/network association in a HetNet
with multiple SPs while considering the uncertainty in the service
guarantees offered by the SPs. Using Prospect Theory (PT) to
model end-user decision making that deviates from expected
utility theory (EUT), we formulate user association with SPs as
a multiple leader Stackelberg game where each SP offers a bid
to each user that includes a data rate with a certain probabilistic
service guarantee and at a given price, while the user chooses
the best offer among multiple such bids. We show that when
users underweight the advertised service guarantees of the SPs
(a behavior observed under uncertainty), the rejection rate of
the bids increases dramatically which in turn decreases the SPs
utilities and service rates. To overcome this, we propose a two-
stage learning-based optimized bidding framework for SPs. In
the ﬁrst stage, we use a support vector machine (SVM) learning
algorithm to predict users’ binary decisions (accept/reject bids),
and then in the second stage we cast the utility-optimized bidding
problem as a Markov Decision Problem (MDP) and propose a
reinforcement learning-based dynamic programming algorithm
to efﬁciently solve it. Simulation results and computational
complexity analysis validate the efﬁciency of our proposed model.

Index Terms—HetNets, Bidding, Pricing, Stackelberg Game,

EUT, Prospect Theory, Reinforcement Learning, SVM.

I. INTRODUCTION

U LTRA-DENSE heterogeneous networks (HetNets) with

overlaid macro and small cells is a design solution that
has emerged in 5G networks to cope with the increasing
demand from mobile users for more capacity and higher data
rates. In such HetNets users could have the option of choosing
from multiple service providers (SPs), the one that offers
them the best data service to meet their current demands
and application requirements. In such a scenario, SPs will
have to dynamically compete with each other to get
the
users to connect to their network by offering attractive service
guarantees and prices. Therefore, user/network association and
smart data pricing are extremely important from both user
and SP perspectives [1]–[3]. Earlier work in the literature on
both user/network association as well as pricing (discussed in
section II) has primarily relied on models based on Expected
Utility Theory (EUT). When a SP controls access to end-users
via differentiated and hierarchical monetary pricing, then the
performance of the network is directly subject to end-user

M. Yousefvand and N. Mandayam are with the Wireless Information
Network Lab (WINLAB), Department of Electrical and Computer Engi-
neering, Rutgers University, New Brunswick NJ, 08902, e-mails: {my342,
narayan}@winlab.rutgers.edu.

This work is supported in part by the U.S. National Science Foundation

under Grant No. 1421961 and Grant No. ACI-1541069

decision-making that has shown to deviate from EUT in many
cases and is better captured by models based on the Nobel
Prize-winning Prospect Theory (PT) [4].

Due to uncertainties in channel and trafﬁc conditions, when
the advertised data rates offered by SPs can only be met
with probabilistic guarantees, then these probabilities are not
necessarily the same from user and SPs perspectives owing to
the subjective biases of human decision making. This disparity
in the rejection of SP offers as shown in our
can result
previous work [5]. In fact, it was shown in [5] that when
users underweight the advertised service guarantees of the SPs
(a behavior observed under uncertainty), the rejection rate of
the bids increases dramatically which in turn decreases the
SPs utilities and service rates. In this paper, to overcome
this, we propose a two-stage learning-based optimized bidding
framework for SPs. In the ﬁrst stage, we use a support vector
machine learning algorithm to predict users’ binary decisions
(accept/reject bids), and then in the second stage we cast
the utility-optimized bidding problem as a Markov Decision
Problem (MDP) and propose a reinforcement learning-based
dynamic programming algorithm to efﬁciently solve it. Simu-
lation results and computational complexity analysis validate
the efﬁciency of our proposed model.

The rest of this paper is organized as follows. In section
II, we review the related works. In section III, we present the
HetNet model used along with optimization problems from
the user and SP perspectives. In section IV, we introduce the
proposed two-stage learning-based optimized bidding method
for SPs to learn the end users behavior and optimize their
bids based on that. We validate the efﬁciency of the proposed
model in section V, and conclude in section VI.

II. RELATED WORK

Numerous studies have been done in recent years to ad-
dress user association in HetNets [1]. Due to the inherent
interdependencies between user/cell association and resource
allocation problems in HetNets and their direct impacts on
each other, these two problems are usually jointly addressed
and optimized with respect to a given performance parameter
[6], [7]. The diverse range of performance criteria considered
in the user/network association schemes proposed for HetNets
to energy efﬁciency
spans from load balancing [8]–[10],
[11]–[14], interference management [15], coverage maximiza-
tion [16], and latency minimization [17]. Also,
in terms
of the methodology, the range of approaches proposed for
user/network association in HetNets spans from optimization
methods [12], to game theoretic solutions [14], [17]–[21],

 
 
 
 
 
 
JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2019

2

evolutionary algorithms [22], estimation methods [23] and
learning algorithms [24].

Moreover, several works investigated the role of network
economics on user/network association and allocation of net-
work resources, via supply and demand-based smart pricing
models [25]–[29]. For example, in [25] an iterative double-
auction mechanism is proposed to ofﬂoad trafﬁc from macro
BSs to third party small cell access points. A cost-aware
adaptive bandwidth management mechanism for empowering
users to make trafﬁc ofﬂoading decisions is proposed in [26].
The effects of users social learning on service providerâ ˘A ´Zs
dynamic pricing policies is investigated in [27]. In [28] the
duopoly competition between mobile network operators for
mobile data plans with time ﬂexibility is characterized using a
three stage game model. In [29] a framework for realization of
time depending pricing for multimedia data trafﬁc is proposed
to modify users’ behavior and prevent congestion. The role of
PT in wireless data pricing has been explored in [30], [31]
where users use their subjective biases in evaluating objective
probabilistic parameters, and has been observed via human
subject studies in [32].

In contrast to the earlier works, in this paper, using PT
we address both user/network association and data pricing
with emphasis on end-user behavior and decision making
under uncertainty. We model the HetNet with probabilistic
service guarantees and PT based decision making using the
approach in [5] where it was observed that the underweighting
of the service guarantees by the users results in an increased
rejection of the SP bids. To overcome this, a heuristic solution
based on expanding the bandwidth available to the SPs bids
was proposed in [5]. However, it required the SPs to have
knowledge of how the users perceive the uncertainty in the
service guarantees, while in reality, SPs donâ ˘A ´Zt have access
to such information. The focus of the current paper is to
overcome the bid rejection problem via a completely different
approach, namely a two-stage learning-based optimized bid-
ding framework for SPs. In the ﬁrst stage, we use a support
vector machine learning algorithm to predict usersâ ˘A ´Z binary
decisions, and then in the second stage we cast the utility-
optimized bidding problem as a Markov Decision Problem and
propose a reinforcement learning-based dynamic programming
algorithm to efﬁciently solve it.

III. SYSTEM MODEL AND PROBLEM FORMULATION

A. Network Model

To study user association in HetNets, we developed a two-
tier HetNet scenario which includes N wireless users that
are randomly distributed within the coverage area of K base
stations. As shown in Fig. 1, in our HetNet model there is one
macrocell LTE BS located in the center of the area and K − 1
overlaid small cell WiFi access points who are competing with
each other to serve the users in the HetNet. We assume each
user in the HetNet receives several bids from service providers
(SPs) in both cellular and WiFi tiers, where each bid includes
a data rate with a certain probabilistic service guarantee and
at a given price. Upon receiving such bids, the user makes a
binary decision to accept or reject each of the received bids.

Fig. 1. Heterogeneous Network (HetNet) Model.

B. Stackelberg Game for User Association in HetNets

In our HetNet model, each user receives K different bids
from all K base stations, i.e., one bid from the cellular BS
and K − 1 bids from the WiFi BSs. To enable multihoming,
we assume each user can be simultaneously connected to both
cellular and WiFi SPs to receive the data service. Speciﬁcally,
we assume that each user can only be associated to the cellular
SP and the best serving WiFi SP for that speciﬁc user, which
is the SP who offers a bid with highest utility among all WiFi
SPs. Hence, we model user association problem in this work
as a Stackelberg game with two leaders and one follower,
where SPs act as the leaders who make service offers to
the user, and the user serves as a follower who accepts or
rejects the received bids. Since we have N users in our HetNet
model, to solve the user/network association problem in a
distributed manner, we need to solve N stackelberg games
each with three players including WiFi SP and cellular SP
as the leaders and one user as the follower. Assuming the
BS’s maximum bandwidth budget per user is ﬁxed and the
same for all users as shown in Eq. 16, these N Stackelberg
games are independent, and hence we consider and solve only
one of these Stackelberg games without loss of generality.
Note that ﬁnding the optimal bandwidth/power allocation for
SPs is a NP-hard problem [33] and not the focus of this
paper. In the remainder of this paper, we focus on one of
these games. Using the index w for user’s preferred WiFi SP
and the index c for cellular SP, we denote the bids of WiFi
and cellular SPs with triples (bw, rEUT (bw), BWw,EUT ), and
(bc, rEUT (bc), BWc,EUT ), respectively, in which the ﬁrst term
shows the advertised data rate, the second term is the proposed
price for the offered data rate, and the third term is the amount
of BW that will be allocated to the user by each SP. User
decisions are binary, which means the user either accepts a
bid or rejects it, and there is no probabilistic decision by user.
We denote user decisions on cellular and WiFi SPs bids with
pc and pw respectively, which are binary variables. So, the

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2019

3

incurred service cost. The SPs’ payoff from the user is
equal to the offered price in their bids if the user accepts
their bids, otherwise their payoff from the user is equal to
zero. In this work, we assume both SPs use convex pricing
functions, as rEUT (bw) = α1(bw)β1, and rEUT (bc) = α2(bc)β2,
(β1, β2 > 1), where α1 and β1 are payoff parameters for
the WiFi SP, and α2 and β2 are payoff parameters for the
cellular SP. We also assume the SPs use linear cost func-
tions, as Cw(bw, BWw,EUT ) = c1(bw) + c2(BWw,EUT ), and
Cc(bc, BWc,EUT ) = c3(bc) + c4(BWc,EUT ), where c1 and c2
are cost coefﬁcients for the WiFi SP, and c3 and c4 are cost
coefﬁcients for the cellular SP. To satisfy the user’s minimum
data rate constraint, the SPs must ensure that their offered
data rate is higher than the minimum data rate required by the
user, bmin. Thus, the data rate constraints for the WiFi and the
cellular SPs will be deﬁned as below, respectively:

bw ¯FBw (bw, BWw,EUT ) ≥ bmin,
bc ¯FBc (bc, BWc,EUT ) ≥ bmin.

(6)

(7)

C. User Optimization Problem

Upon receiving the bids from the SPs, the user will run an
optimization problem to ﬁnd its best strategy with regard to
the received bids. We assume the user’s payoff function from
the received data is a concave function, as deﬁned in Eq.
1, in which the user’s utility is not linearly increased with
increasing the data rate. It means that as long as the minimum
data rate constraint is satisﬁed, the user is not willing to pay
extra price with linear relation to the extra data rate offered
by SPs. To ﬁnd its best response strategy,(p∗
w), user will
run the following optimization problem (denoted as Max1):

c, p∗

Max1 Problem: User’s Utility Maximization.
—————————————————————————

[ δ(Bjoint )1/θ − pwα1(bw)β1 − pcα2(bc)β2 ]

max
pc, pw
subject to
Bjoint ≥ bmin
δ(Bjoint )1/θ ≥ pwα1(bw)β1 + pcα2(bc)β2,
pc, pw ∈ {0, 1}

(8)

(9)

(10)

(11)

As shown above, the user has two major constraints for bid
selection. The ﬁrst constraint, shown in Eq. 9, is the user’s
data rate constraint which ensures the expected data rate for
the user is higher than its minimum required data rate, bmin.
The second constraint deﬁned in Eq. 10 is the user’s utility
constraint which guarantees a positive utility for the user from
its strategy.

D. SPs Optimization Problems

When the SPs receive user’s decision with regard to
their bids, they choose their best response strategy. The the
best response strategy (b∗
w, BW ∗
w,EUT ) for the WiFi BSs is
obtained by solving the optimization problem below (denoted
as Max2):

Fig. 2. Stackelberg Game Model.

tuple (pc, pw) represents userâ ˘A ´Zs strategy with regard to the
received bids, hence, the user has four possible strategies (0, 0),
(0, 1), (1, 0) and (1, 1). Fig. 2 illustrates the Stackelberg game
model between cellular and WiFi SPs and mobile user.

All three players have a cost function and a beneﬁt function,
and their utility functions are simply the difference of the cost
and beneﬁt functions. We represent userâ ˘A ´Zs utility function
as

(cid:1) − cuser (pw, pc) ,

Uuser,EUT {pc, pw } = H (cid:0)Bjoint

(1)
where H(Bjoint ) = δ(Bjoint )1/θ is the users beneﬁt function
which is a logarithmic concave function of the user’s expected
aggregate data rate, Bjoint , and cuser (pw, pc) = pwrEUT (bw)+
pcrEUT (bc) is the userâ ˘A ´Zs cost function which shows the
aggregate price that must be paid by user to the SPs for each
(pc, pw) strategy. The user’s expected aggregate data rate is
deﬁned by
Bjoint = bc ¯FBc (bc, BWc,EUT )pc + bw ¯FBw (bw, BWw,EUT )pw,
(2)
where ¯FBc (bc, BWc,EUT ) is the service guarantee of the bid
received from the cellular SP, and denotes the probability of
having the actual data rate of user from cellular SP, Bc which
is a random variable, equal or higher than the advertised data
rate by cellular SP, bc, and is given by

¯FBc (bc, BWc,EUT ) = Pr(Bc ≥ bc |BWc,EUT ),

(3)

where for a ﬁxed data rate bc, a larger BWc,EUT yields
a higher service guarantee. Similar deﬁnition holds for
¯FBw (bw, BWw,EUT ) which is the service guarantee of the bid
received from WiFi SP.

Once the user chooses its best response strategy, (p∗

w),
the SPs will respond with their best response strategies to max-
imize their own utilities based on the received user decision.
The utility of the WiFi SP, US P,w is deﬁned as

c, p∗

US P,w = pwrEUT (bw) − Cw(bw, BWw,EUT ),

and the utility of cellular SP, US P,c is deﬁned as

US P,c = pcrEUT (bc) − Cc(bc, BWc,EUT ),

(4)

(5)

where, the ﬁrst term in both of these equations is the SPs’
expected payoff from the user, and the second term is their

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2019

4

Max2 Problem: WiFi SP’s Utility Maximization.
—————————————————————————

[pwα1(bw)β1 − (c1bw + c2BWw,EUT ) ]

max
bw, BWw, EUT
subject to
0 ≤ BWw,EUT ≤ BWw,max,
0 ≤ bw ≤ bw,max,
bw ¯FBw (bw, BWw,EUT ) ≥ bmin,

(12)

(13)

(14)

(15)

in which, BWw,max is the maximum amount of bandwidth
that can be allocated to the user by the WiFi SP, and bw,max
is the maximum achievable data rate by the user from the
WiFi SP considering BWw,max and the gain of the channel
between the WiFi SP and the user. We assume the SPs
use a proportionally fair bandwidth allocation algorithm to
determine the maximum amount of bandwidth that can be
allocated to each of their users. Assuming BW as the total
amount of bandwidth available at SP i, i ∈ {w, c}, and N as
the total number of users in our HetNet, the maximum amount
of bandwidth that can be allocated to each user by the SP i,
BWi,max is given as

BWi,max = (GB A ∗ BW)/

N
(cid:213)

(aj ∗ cj),

(16)

j=1

in which GB A is the gain of bandwidth allocation which is
less than one due to the guard bands between channels for
preventing interference, aj is a binary variable showing the
activity of the users which aj = 1 if the user j is active and
has data demand, otherwise aj = 0, and cj is also a binary
variable representing the coverage of the user j by the the
BS i, where cj = 1 if the SINR of the link between the user
j and the BS i is higher than a certain threshold to have a
reliable transmission, otherwise cj = 0. Considering BWi,max,
the maximum achievable data rate by user, bi,max is given by:

bi,max = BWi,max log(1 +

Phj aj cj
σ2

),

(17)

where, P is the transmit power of the BS, hj is the channel
gain between the user j and the SP i, and σ2 is the noise
variance over the transmission channel. Similarly, the cellular
SP runs Max3 optimization problem, which is deﬁned exactly
similar to Max2, except the index w is replaced with the
index c and the parameters α1, β1, c1, c2 are replaced with the
parameters α2, β2, c3, c4, respectively. In Theorem 1, we prove
that for both WiFi and cellular SPs, the best response strategies
derived from Max2 and Max3 optimization problems, satisfy
the minimum data rate constraint with equality.

Theorem 1. The SPs best response strategies, derived from
Max2 and Max3 problems, will always satisfy the minimum
data rate constraint in the boundary of its feasibility region,
w,EUT ) = bmin, and
¯FBw (b∗
i.e. we always have b∗
w, BW ∗
w
c,EUT ) = bmin for the WiFi and the Cellular
b∗
c, BW ∗
c
SPs, respectively.

¯FBc (b∗

Proof. We prove this by contradiction for the WiFi SP.
Assume (b∗
w,EUT ) is the optimal solution for Max2
i.e.
problem,

w, BW ∗
and BW ∗

a marginal BW,

is not

w,EUT

w, BW (cid:48)

w, BW ∗

w,EUT < BW ∗

w,EUT ) and BW ∗

w,EUT ) (cid:44) bmin. Considering Eq. 15, we can
¯FBw (b∗
b∗
w, BW ∗
w
¯FBw (b∗
w, BW ∗
infer that b∗
w,EUT ) > bmin (1). In this case
w
w,EUT ) = bmin (2).
∃ BW (cid:48)
¯FBw (b∗
w,EUT such that b∗
w
From (1) and (2), and considering the direct relation be-
tween FBw (b∗
w,EUT , we can infer that
BW (cid:48)
w,EUT . Now, considering the WiFi SP’s utility
function deﬁned in Eq. (11) and due to its reverse relation
with the advertised bandwidth, BWw,EUT , we can infer that
US P,w(b∗
w, BW ∗
w,EUT ) which is in
conﬂict with the initial assumption that (b∗
w, BW ∗
w,EUT ) is the
optimal solution for Max2 problem. So, the proof is complete.
(cid:3)
The same proof is valid for the cellular SP.

w,EUT ) > US P,w(b∗

w, BW (cid:48)

A characterization of the Nash Equilibria under the EUT
and the PT models follows directly from the above Theorem,
and can be found in [5]. To model the effects of PT on user
decision making, we assume that users use their subjective
biases in evaluating the bids made by the SPs. Speciﬁcally,
we use the probability weighting effect (PWE) of PT to model
how the user evaluates the probabilistic service guarantee that
is part of the SPs bids. We use the Prelec function [34] to
model the PWE under PT, which is given by

w(p) = exp(−(−ln(p)α),

(0 < α < 1),

(18)

where w(p) is the weighted version of the probability p,
which is used by end-users while making decisions based
on probabilistic parameters, and α is the Prelec function
parameter that describes the deviation of w(p) from p. This
function is a regressive and s-shaped function which is concave
in 0 < p < 1/e region and convex in 1/e < p < 1 region,
and w(p) > p in the former domain while w(p) < p in
the later. Under this PWE model, we can infer that the user
overestimates the service guarantees of the received offers if
the advertised service guarantees are less than 1/e = 0.37%,
and user underestimates them if advertised service guarantees
are higher than 0.37%. Assuming that SP networks are well
designed to offer service guarantees higher than 1/e, we focus
on the underestimating of service guarantees by the user under
PT. It is also justiﬁed by the fact that end-users in real world
wireless networks typically perceive the quality of their service
as lower than that advertised by the SPs [35], [36].

The results in [5] reveal that when users underweight the
SPs advertised service guarantees, the rejection rate of the SP
bids, and consequently the resulting utility and revenue for SPs
decreases dramatically. To overcome this, we discuss next a
learning-based optimized bidding mechanism for SPs.

IV. LEARNING-BASED OPTIMIZED BIDDING METHOD FOR
SPS

To ﬁnd the utility-optimized bids, we propose a two-stage
learning method for SPs where in the ﬁrst stage, SPs learn
a binary user decision classiﬁer function via a support vector
machine learning algorithm. Then in the second stage, SPs ﬁnd
the utility-optimized bids using a reinforcement learning-based
bidding algorithm in which the classiﬁer function obtained in
the ﬁrst stage is used to evaluate the value of each potential
bid by predicting the user decision with regard to that bid. A
heuristic solution based on expanding the offered bandwidth in

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2019

5

the SPs bids was proposed in [5]. However, it requires the SPs
to have knowledge of how the users perceive the uncertainty
in the service guarantees, while in reality, SPs donâ ˘A ´Zt have
access to such information.

A. SVM-based Classiﬁer for Predicting User Decisions

Using a record of previous user decisions in response to
different offered services, and noting the binary nature of user
decisions in our work, we can efﬁciently train a SVM classiﬁer
to predict user decisions with regard to any future bid. The set
of training data, here denoted as D, is given by

D = {(x1, y1), (x2, y2), (xN, yN )}

(19)

which includes N entries of labeled data samples (xi, yi),
where the feature vector xi = (bi, r(bi), BWi) represents the
bid i features including its advertised data rate, the offered
price, and offered bandwidth, respectively, and yi represents
the previous binary decision of user in response to bid i. Using
the gathered training data, the SVM classiﬁer parameters, w
and b, can be derived by solving the optimization problem
given in (20)-(22) using the SVM learning algorithm.

SVM Learning Optimization.
—————————————————————————

1/2 wT w + c

min
w,b,(cid:15)

N
(cid:213)

i=1

(cid:15)i,

subject to:
yi (wT φ(xi) + b) ≥ 1 − (cid:15)i,
(cid:15)i ≥ 0.

(20)

(21)

(22)

In the SVM optimization objective function given in Eq. (20),
2/wT w is the width of the separating margin between two
groups of accepted and rejected bids which is supposed to be
maximized by minimizing its inverse, and (cid:15)i is the amount of
error in classifying each data point i, which is supposed to be
minimized, and c is a regularization parameter that deﬁnes
the trade-off between these two objectives. The inequality
constraint in Eq. (21) enforces wT φ(xi) + b ≥ 1 − (cid:15)i for all
accepted bids and wT φ(xi) + b ≤ −(1 − (cid:15)i) for all rejected
bids, as it combines these two constraints. The constraint in
Eq. (22) ensures that the amount of classiﬁcation error for each
data point i, (cid:15)i, is either zero for correctly classiﬁed points,
or a positive value for misclassiﬁed points. After ﬁnding the
SVM classiﬁer parameters w and b from solving the SVM
optimization, we can deﬁne the SVM classiﬁer function f (xi)
as

f (xi) = wT xi + b =

(cid:40)

≥ 0,
≤ 0,

i.e. d(xi) = 1, accepted,
i.e. d(xi) = 0, re jected,

(23)

to predict the user’s binary decision with regard to any given
bid xi, denoted as d(xi).

B. Reinforcement Learning-based Optimized Bidding

To ﬁnd the utility-optimized bids for SPs that are highly
likely to be accepted by the user while maximizing their utility,
we formulate the SPs optimized bidding problem as a Markov
Decision Problem (MDP) with the tuple (S, AS, PS A, γ, R) in
which S denotes the set of states, AS deﬁnes the set of
actions in each state, PS A is the set of state-action transition
probabilities, γ is the discount factor, and R is the reward
function. In this work, the set of states is deﬁned as

S = {s1, s2, , sM∗N |si = (bsi, BWsi )}

(24)

in which, each state si is associated with a tuple (bsi, BWsi )
which is a potential bid and shows how much data rate, and
bandwidth will be advertised to the user, respectively, if SPs
bid si. Note that to cast the SPs bidding problem as a MDP,
we need to have discrete set of states, and to do so we quantize
the possible values for both originally continuous bid variables
bandwidth, BW, and data rate, b, by considering M possible
values for data rate, and N possible values for bandwidth.
Since there is one state deﬁned for each possible combination
of the values of b and BW, we have overall M ∗ N states in
our MDP model, considering all such possible combinations.
AS = { Asi }M N
is the set of is the set of actions available
i=1
in each state si ∈ S, i = 1, 2, , M ∗ N . Taking each action aj
in a given state si results in a transition from state si to the
new state sj , with new data rate and bandwidth coordinates
of (bsj, BWsj ). Hence, each action can be deﬁned in terms of
how that action changes the current data rate, and bandwidth
coordinates of the system, and hence the action set for any
given state si, Asi , is given by

= {a1, a2, , aM∗N |aj = (∆bj, ∆BWj)

Asi
= (bsj − bsi, BWsj − BWsi )}

(25)

in which, there is one unique action deﬁned for each possible
transition from any state si to any other state sj. For example,
taking action aj in state si changes the state of the MDP from
the state si to the state sj by adding the (∆bj, ∆BWj) to the
coordinates of the state si. Equation (26) explains how this
a j→ sj, happens between these two
transition, denoted as si
states in the MDP.

a j→: (bsi, BWsi ) + (∆bj, ∆BWj))
si
= (bsi, BWsi ) + (bsj − bsi, BWsj − BWsi ) = (bsi, BWsi ) = sj
(26)

PS A deﬁnes the transition probabilities for all state-action
pairs, which in our model are deterministic and given as

PS A = {Pr(s(cid:48)|si, aj), ∀si, s(cid:48) ∈ S, ∀aj ∈ Asi )}

(27)

where

Pr(s(cid:48)|si, aj) =

(cid:40)

1,
0,

if s(cid:48) = sj,
if s(cid:48) (cid:44) sj .

(28)

R(si, aj) is the state-action reward function which deﬁnes an
immediate reward that can be achieved from taking the action
aj in state si. In our model, R(si, aj) is deﬁned as
R(si, aj) = d(sj) ∗ {r(bsi )) − c(bsj, BW sj)},

(29)

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2019

6

where d(sj) is the users predicted decision with regard to bid
sj which is deﬁned in Eq. (23), r(bsi ) and c(bsj, BW sj) are the
advertised price and the expected cost associated with bid sj,
respectively, which are deﬁned in section III-B. In our model,
the reward of taking any action aj in a given state si to go to
the new state sj is equal to the expected utility of bidding the
bid (bsj, BW sj) which is associated to the destination state sj.
The goal for SPs is to ﬁnd a bid which maximizes their utility,
which in our MDP model is equivalent to ﬁnding the best state
with an associated bid with the highest amount of reward or
expected utility. Such a state is accessible from any initial state
in the MDP, by taking a set of actions based on the optimal
policy. A policy is any function π : S → A mapping from the
states to the actions, and we say that we are executing some
policy π if whenever we are in any state s, we take action
a = π(s). The value function Vπ(si) for evaluating the value
of each policy π in each state si is deﬁned as

Vπ(si) = R(si, π(si)) + γ

(cid:213)

pr(s(cid:48)|si, π(si)) Vπ(s(cid:48))

(30)

s(cid:48) ∈S
assuming π(si) = aj, and since transition probabilities are
binary and given in our MDP model, the value function can
be simpliﬁed to

(31)

Vπ(si) = R(si, aj) + γVπ(sj)
as in our model we have Pr(s(cid:48)|si, aj) = 0 ∀s(cid:48) (cid:44) sj, and
Pr(s(cid:48)|si, aj) = 1 i f s(cid:48) = sj. Also, since the optimal state
is accessible from any initial state in the MDP, we set the
discount factor γ = 0 to focus on the current action only and
ﬁnd the optimal action that takes us from the current state to
the optimal state. Such an action is given by executing the
optimal policy, π∗, in any given state si, as

π∗(si) = argmax
a j ∈ Asi

[R(si, aj)].

(32)

To ﬁnd the optimal policy which deﬁnes the best action for
each state, we should theoretically exhaust all possible actions
in each state, which is computationally intractable for MDPs
with large number of states and actions. To solve this issue,
we propose an efﬁcient dynamic programming based algorithm
which ﬁnds the optimal action for each state in the formulated
MDP, with a logarithmic convergence rate.

C. Dynamic Programming-based Optimized Bidding (DPOB)
Algorithm

In the formulated MDP for optimized bidding, if user rejects
any bid si, it will also reject any other bid sj that results in a
lower expected utility for that user, considering the rationality
of users and their objective to maximize their expected utility.
In fact, if user rejects the bid si = (bsi, BWsi ) it will reject
any other bid sj = (bsj, BWsj ) if (bsi ≤ bsj ) ∧ (BWsi ≥ BWsj )
since si Pareto dominates sj
from the user’s perspective,
under such conditions. Likewise, when user accepts any
bid si,
the offering SP is not willing to offer any new
if sj results in a lower utility for that SP. In fact,
bid sj
if user accepts any bid si = (bsi, BWsi ), the offering SP

will not offer any new bid sj = (bsj, BWsj ) to the user if
(bsi ≥ bsj )∧(BWsi ≤ BWsj ) since si Pareto dominates sj from
the SP’s perspective, under such conditions. Note that based
on the utility functions of user and SPs deﬁned in section
III-B, when other parameters remain the same,
increasing
the advertised data rate will increase the utility of SPs and
decrease the utility of users, while increasing the allocated
bandwidth increases the utility of users and decreases the
utility of SPs. The Pareto optimal relation between different
states in the MDP and their associated bids helps SPs to
update the set of feasible actions in each state after taking
any random action, by removing the infeasible actions from
the list of actions in the newly visited state while executing
the reinforcement learning algorithm. The proposed dynamic
learning algorithm for
programming-based reinforcement
optimized bidding is given in Algorithm 1. Note that
in
Algorithm 1, instead of initializing the MDP with a random
state/bid, we initialize it with the SP’s previous bid derived
from MAX2 optimization under EUT model, here denoted
as ¯s = (b∗
to increase the efﬁciency of the
algorithm. The iterative pruning of infeasible actions from the
list of actions in the proposed dynamic programming-based
optimized bidding algorithm,
to converge to the
optimal solution, and ﬁnd the utility-optimized bids with a
logarithmic convergence rate according to Theorem 2.

EUT, BW ∗

leads it

EUT ),

Algorithm1: Dynamic
Bidding (DPOB) Algorithm
——————————————————————–

Programming-based Optimized

Input: {Set of states: S, Initial state of the system:

¯s = (b∗

EUT, BW ∗
Initialize SP_Utility=0, s∗ = (0, 0)
while A ¯s (cid:44) ∅ do

EUT ), Initial set of actions:A ¯s}

choose a random action aj from the set A ¯s
calculate R( ¯s, aj) using Eq. (29)
if R( ¯s, aj) ≥ SP_Utility then
Set SP_Utility = R( ¯s, aj)
Set s∗ = (bsj, BWsj )

end
Update set of actions:
Calculate d(sj) using SVM classiﬁer in Eq. (23)
if d(sj) = 1 then

Update S: remove all actions ak from A ¯s if
(bsk ≤ bsj ) ∧ (BWsk ≥ BWsj )

end
if d(sj) = 0 then

Update S: remove all actions ak from A ¯s if
(bsk ≥ bsj ) ∧ (BWsk ≤ BWsj )

end

end
Output: s∗, SP_Utility.

Theorem 2. The proposed DPOB algorithm converges to
the optimal solution with a logarithmic convergence rate of
O(log1.33 |S|).

Proof. We ﬁrst show that DPOB algorithm converges to the

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2019

7

optimal solution. We prove this by contradiction. Assume
sj∗ ∈ S is the optimal state in the MDP such that
its
associated bid (bsj∗, BWsj∗ ) maximizes the SPs utility, i.e.
aj∗ = argmax
[R( ¯s, aj)], assuming ¯s to be the initial state of
a j ∈ A ¯s

the MDP. Since the DPOB algorithm exhausts all possible
transition actions from initial state to all other states, the
optimal state sj∗ will be visited by the algorithm unless the
action aj∗ gets removed from the set of actions, A ¯s, during
iterative updates of this set in the algorithm. In that case,
there must exists a state sk ∈ S which Pareto dominates sj∗
and results in higher utility for the SP as compared to sj∗,
which is in contrast with initial assumption that sj∗
is the
optimal state in the MDP. Now we have to show that DPOB
algorithm converges to the optimal solution with a logarithmic
convergence rate of O(log1.33 |S|). Assume sl ∈ S and sh ∈ S
to be the states with lowest and highest expected utility for the
SP, respectively. If SP bids sl and user accepts that, still all
the other actions are feasible, i.e. no action will be removed
from A ¯s after its update, while if SP bids sh and user accepts
that, all other actions become infeasible as sh Pareto dominates
all other states, which means the list of actions A ¯s becomes
empty immediately. However, in general after visiting any new
state like sj, on average for half of the remaining feasible
states like sk we either have (bsk ≤ bsj ) ∧ (BWsk ≥ BWsj ), or
(bsk ≥ bsj ) ∧ (BWsk ≤ BWsj ), which means either the state
sj Pareto dominates them, or they will Pareto dominate the
state sj, and depending on the users response, one group of
such states become infeasible, and their associated transition
actions will be removed from the set of actions, A ¯s. Hence,
on average the initial set of actions A ¯s shrinks by one fourth
after each iteration of the algorithm, and become empty after
O(log(4/3) |S|) iterations which proves the converges to the
optimal solution with O(log1.33 |S|), where |S| denotes the total
(cid:3)
number of states in the MDP.

According to Theorem 2, the complexity of the proposed
DPOB algorithm is O(log1.33 |S|) while model-free reinforce-
ment learning algorithms like Q-learning have a complexity
of O(ne) where n denotes the number of states, and e the
number of actions [37]. For the bidding problem considered
here, we have e = n = |S|, and it follows that the complexity
of a Q-learning algorithm used to solve it would be O(|s|2).
Thus, the computational gain of DPOB as compared to model
free reinforcement learning algorithms is noteworthy since it
reduces the network access delay for users which is attractive
for SPs to enable and support delay critical applications in 5G
HetNets.

V. SIMULATION RESULTS

In this section, we provide simulation results to validate the
efﬁciency of the proposed learning based bidding algorithm.
As shown in Fig. 3, we consider a HetNet scenario in which
there are U randomly distributed mobile users, that are covered
by 9 BSs including one cellular BS (CBS) with the coverage
radius of 1000 f t located in the center of a macro-cell and 8
overlaid small-cell long-range WiFi BSs (WBSs) with maxi-
mum coverage radius of of 300 f t. Each WBS competes with

TABLE I
SIMULATION PARAMETERS.

the CBS to offer data service to each mobile user located in a
coverage area common to them. We use the Hata propagation
model for urban environments [38] to capture the effects
of path loss on each of the radio links. Table I details the
parameters used in the simulation of the HetNet environment
modeled here.

Fig. 3. Simulated HetNet Scenario.

Fig. 4 compares the sum utility of the SPs under three
scenarios: (i) EUT- where there is no difference between
the users objective and subjective perceptions of the SPs
service guarantee, (ii) Deviation from EUT- where the users
subjectively weight the SPs service guarantees with the Prelec
probability weighting function parameterized by α, and (iii)
DPOB- where the learning algorithm is used to predict the
users responses to bids. In the ﬁgure, in each of the cases,
the total number of users (load) in the HetNet changes from
U = 50 to U = 500. As we can see, when the number of users
is lower than 200, since the advertised data rates are high and
low service guarantees in the range of [0, 1/e] are advertised
by SPs to satisfy users data rate constraints, users overestimate
the value of the SPs bids due to PWE of PT described in Eq.
(18). When the total number of users is more than 200, since
the advertised data rates are low, the SPs bids include high
service guarantees in the range of [1/e, 1] which results in the

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2019

8

underestimation of such bids by the users and their subsequent
rejection. Thus the deviation from EUT affects the network
adversely in the region corresponding to underweighting of
the service guarantees. It can also be seen that the proposed
DPOB algorithm uniformly improves performance in both low
and high load situations, by taking (a) advantage of learning
the end users decision making, and (b) optimizing the SPs
bids based on the learned information to maximize the users
acceptance rate of the offered bids. In fact, as seen in Fig. 4,
the sum utility of SPs under DPOB increases on average by
a factor of 3.27 as compared to EUT model.

Further, the gap between DPOB and EUT is bigger in low
load situations. The reason is that when the total number of
users is low, the SPs allocate more bandwidth to each user
and hence their advertised data rates are much higher, which
in turn results in a very high price for their bids considering the
convex pricing function used by them. This situation results
in a rejection of bids by the users since their payoff function
is a concave function of the data rate, making the SPs offers
unattractive. In the case of DPOB, the ability to learn user
actions (accept/reject) by evaluating all feasible bids, allows
the SPs to make only those bids that are still affordable to the
users.

Fig. 5 compares the sum utility of users under the mentioned
three scenarios. As we can see again, the proposed DPOB
algorithm uniformly outperforms EUT model in terms of users
sum utility, due to offering more affordable bids to users which
increases user’s acceptance rates and utilities, accordingly.
Moreover, we observe that users sum utility under all three
models increases with increasing the number of users, before
reaching the max network capacity under our setting when
U = 400. The reason is that when the load is low, users
receive bids with advertised data rates much higher than their
required minimum data rate, and due to SPs convex pricing
and users concave payoff functions, such bids result in low
utility for users, while by increasing the load, the gap between
advertised data rates of SPs and required data rates of users
shrinks, which increases the users utility accordingly. As seen
in Fig. 5, the sum utility of users under DPOB increases on
average by a factor of 1.65 as compared to the EUT model.

We can also see in both Fig. 4 and Fig. 5 that when the
number of users is more than 400, which is the max network
capacity under our setting, most of the SPs are not capable
of satisfying the users data rate constraints since their BW
budget per user decreases with increasing load. Therefore, the
number of users who accept bids, and are connected to BSs
decreases, which in turn reduces both the SPs and users sum
utilities.

Fig. 6 and Fig. 7 compare the sum utility of SPs and sum
utility of users for the three scenarios, respectively, when the
Prelec parameter α = 0.5. This corresponds to a situation
where the PWE of PT is more intense, i.e. the deviation
of end-user behavior from EUT is greater. The performance
results in the ﬁgures show that the deviation from EUT is
more pronounced and the performance improvements in sum
utilities using DPOB are also more signiﬁcant.

Fig. 4. Sum Utility of SPs under EUT, Deviation from EUT and DPOB.

Fig. 5. Sum Utility of Users under EUT, Deviation from EUT and DPOB.

Fig. 6. Sum Utility of SPs under EUT, Deviation from EUT and DPOB.

Fig. 7. Sum Utility of Users under EUT, Deviation from EUT and DPOB.

VI. CONCLUSION

In this paper, we studied the impact of end-user behavior
on SP bidding and user/network association in a HetNet with
multiple SPs while considering the uncertainty in the service
guarantees offered by the SPs. We formulated user association
with SPs as a multiple leader Stackelberg game where each SP
offers a bid to each user that includes a data rate with a certain

50100150200250300350400450500Number of Users00.511.522.533.544.55Sum Utility of SPs×106 EUT Deviation from EUT DPOB     <<<  Users overweight guarantee >>>                                                       <<<    Users underweight guarantee  >>>50100150200250300350400450500Number of Users0123456789Sum Utility of Users×106 EUT Deviation from EUT DPOB <<< Users overweight guarantee >>>                                 <<<    Users underweight guarantee  >>>50100150200250300350400450500Number of Users0123456Sum Utility of SPs×106 EUT Deviation from EUT DPOB50100150200250300350400450500Number of Users012345678910Sum Utility of Users×106 EUT Deviation from EUT DPOBJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2019

9

[18] Y. Sun, G. Feng, S. Qin and S. Sun, “Cell Association With User
Behavior Awareness in Heterogeneous Cellular Networks,” IEEE Trans.
Veh. Technol., vol. 67, no. 5, pp. 4589-4601, May 2018.

[19] S. Brihi, A. Walid, J. Ben-Othman and M. El Koutbi, “A New Proﬁle-
QoS Aware User Association Scheme for 5G Ultra-Dense mmW-µW
IEEE Global Commun. Conf. (GLOBECOM), Abu Dhabi,
HetNets,”
United Arab Emirates, 2018.

[20] Y. M. Waheidi, M. Jubran and M. Hussein, “User Driven Multiclass Cell
Association in 5G HetNets for Mobile & IoT Devices,” IEEE Access,
vol. 7, pp. 82991-83000, 2019.

[21] A. Keshavarz-Haddad, E. Aryafar, M. Wang and M. Chiang, “Het-
Nets Selection by Clients: Convergence, Efﬁciency, and Practicality,”
IEEE/ACM Trans. Netw., vol. 25, no. 1, pp. 406-419, Feb. 2017.

[22] M. Amine, A. Walid, A. Kobbane and J. Ben-Othman, “New User
Association Scheme Based on Multi-Objective Optimization for 5G Ultra-
Dense Multi-RAT HetNets,” IEEE Int. Conf. Commun. (ICC), Kansas
City, MO, 2018.

[23] G. Hattab and D. Cabric, “Long-Term Rate-Based User-Centric Associ-
ation for Downlink Multi-Antenna HetNets,” IEEE Int. Conf. Commun.
(ICC), Kansas City, MO, 2018.

[24] F. Pervez, M. Jaber, J. Qadir, S. Younis and M. A. Imran, “Memory-
Based User-Centric Backhaul-Aware User Cell Association Scheme,”
IEEE Access, vol. 6, pp. 39595-39605, 2018.

[25] G. Iosiﬁdis, L. Gao, J. Huang and L. Tassiulas, “A Double-Auction
IEEE/ACM Trans.

Mechanism for Mobile Data-Ofﬂoading Markets,”
Netw., vol. 23, no. 5, pp. 1634-1647, Oct. 2015.

[26] Y. Im, C. Joe-Wong, S. Ha, S. Sen, T. â ˘AIJTaekyoungâ ˘A˙I Kwon and
M. Chiang, “AMUSE: Empowering Users for Cost-Aware Ofﬂoading with
Throughput-Delay Tradeoffs,” IEEE Trans. Mobile Comput., vol. 15, no.
5, pp. 1062-1076, May 2016.

[27] Q. Ma, B. Shou, J. Huang, T. BaÅ§ar, “Dynamic Pricing in the Presence
of Participation-Dependent Social Learning,” Proc. ACM Mobihoc, Los
Angeles, CA, USA, 2018

[28] Z. Wang, L. Gao and J. Huang, “Duopoly Competition for Mobile Data
Plans with Time Flexibility,” IEEE Trans. Mobile Comput., Apr. 2019
[29] S. Sen, C. Joe-Wong, S. Ha and M. Chiang, “Time-Dependent Pricing
for Multimedia Data Trafﬁc: Analysis, Systems, and Trials,” IEEE JSAC,
vol. 37, no. 7, pp. 1504-1517, July 2019.

[30] T. Li and N. Mandayam, “When users interfere with protocols: Prospect
theory in wireless networks using random access and data pricing as an
example,” IEEE Trans. Wireless Commun., vol. 13, no. 4, April 2014, pp.
1888â ˘A ¸S1907.

[31] Y. Yang and N. B. Mandayam, “Impact of end-user decisions on pricing
in wireless networks,” IEEE Conf. Inf. Sci. Sys. (CISS), 2014, pp. 1â ˘A ¸S6.
[32] Y. Yang, L. T. Park, N. B. Mandayam, I. Seskar, A. L. Glass and
N. Sinha, “Prospect Pricing in Cognitive Radio Networks,” IEEE Trans.
Cogn. Commun. Netw., vol. 1, no. 1, March 2015, pp. 56-70.

[33] M. Yousefvand, T. Han, N. Ansari, A. Khreishah, “Distributed Energy-
Spectrum Trading in Green Cognitive Radio Cellular Networks,” IEEE
Trans. Green Commun. Netw., vol. 1, no. 3, Sept. 2017, pp. 253-263.
[34] Prelec Drazen, “The probability weighting function.” Econometrica,

1998, pp. 497-527.

[35] Measuring Mobile Broadband America Mobile. FCC Website [online].
Available: http://www.fcc.gov/measuring-broadband-america/mobile
[36] Measuring Broadband America. FCC Website [online]. Available:

http://www.fcc.gov/measuring-broadband-america/

[37] S. Koenig, R. G. Simmons, “ Complexity analysis of real-time reinforce-
ment learning applied to ﬁnding shortest paths in deterministic domains,”
School of Computer Science, Carnegie Mellon University, Dec. 1992.
[38] T. S. Rappaport, “Wireless Communications: Principles and Practice,”

2d ed., Prentice Hall., 2002, pp. 153-154.

probabilistic service guarantee and at a given price, while the
user chooses the best offer among multiple such bids. Using
PT to model end-user decision making that deviates from
EUT, we showed that when users underweight the advertised
service guarantees of the SPs, the rejection rate of the bids
increases dramatically which in turn decreases the SPs utilities
and service rates. To overcome this, we proposed a two-
stage learning-based optimized bidding framework for SPs.
In the ﬁrst stage, we used a support vector machine learning
algorithm to predict users’ binary decisions, and then in the
second stage we cast the utility-optimized bidding problem as
a MDP and proposed the DPOB algorithm to efﬁciently solve
it. Simulation results and computational complexity analysis
validated the efﬁciency of the proposed learning based bidding
algorithm.

REFERENCES

[1] D. Liu et al., “User Association in 5G Networks: A Survey and an
Outlook,” IEEE Commun. Surveys Tuts., vol. 18, no. 2, pp. 1018-1044,
2016.

[2] S. Sen, C. Joe-Wong, S. Ha, M. Chiang, “A survey of smart data pricing:
Past proposals, current plans, and future trends,” ACM Comput. Surv.,
vol. 46, no. 2, pp. 15-37, Nov. 2013.

[3] S. Sen, C. Joe-Wong, S. Ha, M. Chiang, “Smart data pricing: using
economics to manage network congestion,”Commun. ACM, vol. 58, no.
12, pp. 86-93, Dec. 2015.

[4] D. Kahneman and A. Tversky, “Prospect theory: An analysis of deci-
sion under risk,” Econometrica: J. Econom. Soc., Vol. 47, No. 2, pp.
263â ˘A ¸S291, 1979.

[5] M. Yousefvand, M. Hajimirsadeghi and N. B. Mandayam, “Impact of
End-User Behavior on User/Network Association in HetNets,” IEEE Int.
Conf. Commun. (ICC), Kansas City, MO, 2018.

[6] D. Fooladivanda and C. Rosenberg, “Joint Resource Allocation and User
Association for Heterogeneous Wireless Cellular Networks,” IEEE Trans.
Wireless Commun., vol. 12, no. 1, pp. 248-257, January 2013.

[7] Q. Kuang, W. Utschick and A. Dotzler, “Optimal Joint User Association
and Multi-Pattern Resource Allocation in Heterogeneous Networks,”
IEEE Trans. Signal Process., vol. 64, no. 13, pp. 3388-3401, 1 July1,
2016

[8] A. T. Hirata, E. C. Xavier and J. F. Borin, “Optimal and Heuristic Decision
Strategies for Load Balancing and User Association on HetNets,” IEEE
Symp. Comput. and Commun. (ISCC), Natal, 2018.

[9] X. Huang, W. Xu, G. Xie, S. Jin and X. You, “Learning Oriented Cross-
Entropy Approach to User Association in Load-Balanced HetNet,” IEEE
Wireless Commun. Lett., vol. 7, no. 6, pp. 1014-1017, Dec. 2018.
[10] Y. L. Lee, T. C. Chuah, A. A. El-Saleh and J. Loo, “User Association
for Backhaul Load Balancing With Quality of Service Provisioning for
IEEE Commun. Lett., vol. 22, no. 11, pp.
Heterogeneous Networks,”
2338-2341, Nov. 2018.

[11] H. Ding, H. Zhang, J. Tian, S. Xu and D. Yuan, “Energy Efﬁcient User
Association and Power Control for Dense Heterogeneous Networks,” Int.
Conf. Comput., Netw. Commun. (ICNC), Maui, HI, 2018, pp. 741-746.

[12] Q. Li, Q. Yang, M. Qin and K. Kwak, “Energy efﬁcient user association
and resource allocation in active array aided HetNets,” IET Commun.,
vol. 12, no. 6, pp. 672-679, Apr. 2018.

[13] U. Bin Farooq, U. Sajid Hashmi, J. Qadir, A. Imran and A. N.
Mian, “User Transmit Power Minimization through Uplink Resource
Allocation and User Association in HetNets,” IEEE Global Commun.
Conf. (GLOBECOM), Abu Dhabi, United Arab Emirates, 2018.

[14] F. Yin, A. Wang, D. Liu and Z. Zhang, “Energy-Aware Joint User
Association and Resource Allocation for Coded Cache-Enabled HetNets,”
IEEE Access, vol. 7, pp. 94128-94142, 2019.

[15] M. Feng and S. Mao, “Interference Management and User Association
IEEE Trans. Veh.

for Nested Array-Based Massive MIMO HetNets,”
Technol., vol. 67, no. 1, pp. 454-466, Jan. 2018.

[16] G. Hattab and D. Cabric, “Coverage and Rate Maximization via User
Association in Multi-Antenna HetNets,” IEEE Trans. Wireless Commun.,
vol. 17, no. 11, pp. 7441-7455, Nov. 2018.

[17] M. Elkourdi, A. Mazin and R. D. Gitlin, “Towards Low Latency in 5G
HetNets: A Bayesian Cell Selection / User Association Approach,” IEEE
5G World Forum (5GWF), Silicon Valley, CA, 2018.

