Theory and Algorithms for Shapelet-based
Multiple-Instance Learning ∗

Daiki Suehiro
SUEHIRO@AIT.KYUSHU-U.AC.JP
Kyushu University
and AIP, RIKEN

Kohei Hatano
HATANO@INF.KYUSHU-U.AC.JP
Kyushu University
and AIP, RIKEN

Eiji Takimoto
EIJI@INF.KYUSHU-U.AC.JP
Kyushu University

Shuji Yamamoto
YAMASHU@MATH.KEIO.AC.JP
Keio University
and AIP, RIKEN

Kenichi Bannai
BANNAI@MATH.KEIO.AC.JP
Keio University
and AIP, RIKEN

Akiko Takeda
TAKEDA@MIST.I.U-TOKYO.AC.JP
The University of Tokyo
and AIP, RIKEN

0
2
0
2

t
c
O
3
1

]

G
L
.
s
c
[

3
v
0
3
1
1
0
.
6
0
0
2
:
v
i
X
r
a

Abstract
We propose a new formulation of Multiple-Instance Learning (MIL), in which a unit of
data consists of a set of instances called a bag. The goal is to ﬁnd a good classiﬁer of bags

*. This is the preprint version of a paper published in Neural Computation.

1

 
 
 
 
 
 
based on the similarity with a “shapelet” (or pattern), where the similarity of a bag with
a shapelet is the maximum similarity of instances in the bag. In previous work, some of
the training instances are chosen as shapelets with no theoretical justiﬁcation. In our for-
mulation, we use all possible, and thus inﬁnitely many shapelets, resulting in a richer class
of classiﬁers. We show that the formulation is tractable, that is, it can be reduced through
Linear Programming Boosting (LPBoost) to Difference of Convex (DC) programs of ﬁnite
(actually polynomial) size. Our theoretical result also gives justiﬁcation to the heuristics
of some of the previous work. The time complexity of the proposed algorithm highly de-
pends on the size of the set of all instances in the training sample. To apply to the data
containing a large number of instances, we also propose a heuristic option of the algorithm
without the loss of the theoretical guarantee. Our empirical study demonstrates that our
algorithm uniformly works for Shapelet Learning tasks on time-series classiﬁcation and
various MIL tasks with comparable accuracy to the existing methods. Moreover, we show
that the proposed heuristics allow us to achieve the result with reasonable computational
time.

1. Introduction

Multiple-Instance Learning (MIL) is a fundamental framework of supervised learning with
a wide range of applications such as prediction of molecular activity, and image classiﬁca-
tion. MIL has been extensively studied both in theoretical and practical aspects [14, 2, 26,
39, 13, 6], since the notion of MIL was ﬁrst proposed by Dietterich et al. [11].

A standard MIL setting is described as follows: A learner receives sets B1, B2, . . . , Bm
called bags; each contains multiple instances. In the training phase, each bag is labeled but
instances are not labeled individually. The goal of the learner is to obtain a hypothesis that
predicts the labels of unseen bags correctly1. One of the most common hypotheses used in
practice has the following form:

hu(B) = max
x∈B

(cid:104)u, Φ(x)(cid:105) ,

(1)

where Φ is a feature map and u is a feature vector which we call a shapelet. In many appli-
cations, u is interpreted as a particular “pattern” in the feature space and the inner product
as the similarity of Φ(x) from u. Note that we use the term “shapelets” by following the
terminology of Shapelet Learning (SL), which is a framework for time-series classiﬁcation,
although it is often called “concepts” in the literature of MIL. Intuitively, this hypothesis
evaluates a given bag by the maximum similarity between the instances in the bag and the
shapelet u. Multiple-Instance Support Vector Machine (MI-SVM) proposed by Andrews
et al. [2] is a widely used algorithm that employs this hypothesis class and learns u. It is
well-known that MIL algorithms using this hypothesis class perform empirically better in
various multiple-instance datasets. Moreover, a generalization error bound of the hypothe-
sis class is given by Sabato and Tishby [26].

1. Although there are settings where instance label prediction is also considered, we focus only on bag-label

prediction in this paper.

2

However, in some domains such as image recognition and document classiﬁcation, it
is said that the hypothesis class (1) is not effective [see, e.g., 7]. To employ MIL on such
domains more effectively, Chen et al. [7] extend a hypothesis to a convex combination of
hu :

g(B) =

(cid:88)

u∈U

wu max
x∈B

(cid:104)u, Φ(x)(cid:105) ,

(2)

i=1 Bi}, which is constructed from all instances in the training sample.

for some set U of shapelets. In particular, Chen et al. consider Utrain = {Φ(z) | z ∈
(cid:83)m
The authors
demonstrate that this hypothesis with the Gaussian kernel performs well in image recog-
nition. The generalization bound provided by Sabato and Tishby [26] is applicable to a
hypothesis class of the form (2) for the set U of inﬁnitely many shapelets u with bounded
norm. Therefore, the generalization bound also holds for Utrain. However, it has never
been theoretically discussed why such a ﬁxed set Utrain using training instances effectively
works in MIL tasks.

1.1 Our Contributions

In this paper, we propose an MIL formulation with the hypothesis class (2) for sets U of
inﬁnitely many shapelets.

The proposed learning framework is theoretically motivated and practically effective.
We show the generalization error bound based on the Rademacher complexity [5] and large
margin theory. The result indicates that we can achieve a small generalization error by
keeping a large margin for large training sample.

The learning framework can be applied to various kinds of data and tasks because of
our uniﬁed formulation. The existing shapelet-based methods are formulated for their tar-
get domains. More precisely, the existing shapelet-based methods are formulated using a
ﬁxed similarity measure (or distance), and the generalization ability is shown empirically
in their target domains. For example, Chen et al. [7] and Sangnier et al. [27] calculated
the feature vectors based on the similarity between every instance using the Gaussian ker-
In time-series domain, shapelet-based methods [35, 20, 17] usually use Euclidean
nel.
distance as a similarity measure (or distance). By contrast, our framework employs a ker-
nel function as a similarity measure. Therefore, our learning framework can be uniformly
applied if we can set a kernel function as a similarity measure according to a target learning
task. For example, the Gaussian kernel (behaves like the Euclidean distance) and Dynamic
Time Warping (DTW) kernel [30]. Our framework can be also applied to non-real-valued
sequence data (e.g., text, and a discrete signal) using a string kernel. Moreover, our general-
ization performance is guaranteed theoretically. The experimental results demonstrate that
the provided approach uniformly works for SL and MIL tasks without introducing domain-
speciﬁc parameters and heuristics, and compares with the state-of-the-art shapelet-based
methods.

We show that the formulation is tractable. The algorithm is based on Linear Program-
ming Boosting [LPBoost, 10] that solves the soft margin optimization problem via a col-

3

umn generation approach. Although the weak learning problem in the boosting becomes
an optimization problem over an inﬁnite-dimensional space, we can show that an analog of
the representer theorem holds on it and allows us to reduce it to a non-convex optimization
problem (difference of convex program) over a ﬁnite-dimensional space. While it is difﬁ-
cult to solve the sub-problems exactly because of non-convexity, it is possible to ﬁnd good
approximate solutions with reasonable time in many practical cases [see, e.g., 21].

Remarkably, our theoretical result gives justiﬁcation to the heuristics of choosing the
shapelets in the training instances. Our representer theorem indicates that at t-th iteration
of boosting, the optimal solution ut (i.e., shapelet) of the weak learning problem can be
written as a linear combination of the feature maps of training instances, that is, ut =
(cid:80)
αt,zΦ(z). Thus, we obtain a ﬁnal classiﬁer of the following form

z∈(cid:83)m

i=1 Bi

g(B) =

T
(cid:88)

t=1

wt max
x∈B

(cid:104)ut, Φ(x)(cid:105) =

T
(cid:88)

t=1

wt max
x∈B

(cid:88)

z∈(cid:83)m

i=1 Bi

αt,z(cid:104)Φ(z), Φ(x)(cid:105).

Note that the hypothesis class used in the standard approach [7, 27] corresponds to the
special case where ut ∈ Utrain = {Φ(z) | z ∈ (cid:83)m
i=1 Bi}. This observation would suggest
that the standard approach of using Utrain is reasonable.

1.2 Comparison to Related Work for MIL

There are many MIL algorithms with hypothesis classes which are different from (1) or
(2). [e.g., 3, 14, 1, 38, 7]. For example, these algorithms adopted diverse approaches for
the bag-labeling hypothesis from shapelet-based hypothesis classes (e.g., Zhang et al. [38]
used a Noisy-OR based hypothesis and G¨artner et al. [14] proposed a new kernel called a set
kernel). Shapelet-based hypothesis classes have a practical advantage of being applicable
to SL in the time-series domain (see next subsection).

Sabato and Tishby [26] proved generalization bounds of hypotheses classes for MIL
including those of (1) and (2) with inﬁnitely large sets U . The generalization bound we
provided in this paper is incomparable to the bound provided by Sabato and Tishby. When
some data-dependent parameter is regarded as a constant, our bound is slightly better in
terms of the sample size m by the factor of O(log m).
They also proved the PAC-
learnability of the class (1) using the boosting approach under some technical assumptions.
Their boosting approach is different from our work in that they assume that labels are con-
sistent with some hypothesis of the form (1), while we consider arbitrary distributions over
bags and labels.

1.3 Connection between MIL and Shapelet Learning for Time Series Classiﬁcation

Here we mention brieﬂy that MIL with type (2) hypotheses is closely related to SL, a
framework for time-series classiﬁcation that has been extensively studied [35, 20, 17, 15]
in parallel to MIL. SL is a notion of learning with a feature extraction method, deﬁned by a
ﬁnite set M ⊆ R(cid:96) of real-valued “short” sequences called shapelets. A similarity measure

4

is given by (not necessarily a Mercer kernel) K : R(cid:96) × R(cid:96) → R in the following way. A
time series τ = (τ [1], . . . , τ [L]) ∈ RL can be identiﬁed with a bag Bτ = {(τ [j], . . . , τ [j +
(cid:96) − 1]) | 1 ≤ j ≤ L − (cid:96) + 1} consisting of all subsequences of τ of length (cid:96). The feature of
τ is a vector (maxx∈Bτ K(z, x))z∈M of a ﬁxed dimension |M | regardless of the length L
of the time series τ . When we employ a linear classiﬁer on top of the features, we obtain a
hypothesis in the form:

g(τ ) =

(cid:88)

z∈M

wz max
x∈Bτ

K(z, x),

(3)

which is essentially the same form as (2), except that ﬁnding good shapelets M is a part
of the learning task, as well as to ﬁnd a good weight vector w. This task is one of the
most successful approaches for SL [17, 15, 16, 25, 18], where a typical choice of K is
K(z, x) = −(cid:107)z−x(cid:107)2. However, almost all existing methods heuristically choose shapelets
M and with no theoretical guarantee on how good the choice of M is.

Note also that in the SL framework, each z ∈ M is called a shapelet, while in this paper,
we assume that K is a kernel K(z, x) = (cid:104)Φ(z), Φ(x)(cid:105) and any u (not necessarily Φ(z) for
some z) in the Hilbert space is called a shapelet.

Sangnier et al. [27] proposed an MIL-based anomaly detection algorithm for time series
data. They showed an algorithm based on LPBoost and the generalization error bound
based on the Rademacher complexity [5]. Their hypothesis class is same as [7]. However,
they did not analyze the theoretical justiﬁcation to use ﬁnite set U made from training
instances (the authors mentioned as future work). By contrast, we consider a hypothesis
class based on inﬁnitely many shapelets, and our representer theorem guarantees that our
learning problem over the inﬁnitely large set is still tractable. As a result, our study justiﬁes
the previous heuristics of their approach.

There is another work which treats shapelets not appearing in the training set. Learn-
ing Time-Series Shapelets (LTS) algorithm [15] tries to solve a non-convex optimization
problem of learning effective shapelets in an inﬁnitely large domain. However, there is
no theoretical guarantee of its generalization error. In fact, our generalization error bound
applies to their hypothesis class.

For SL tasks, many researchers focus on improving efﬁciency [20, 25, 16, 34, 18, 19].
However, these methods are specialized in the time-series domain, and the generalization
performance has never been theoretically discussed.

Curiously, despite MIL and SL share similar motivations and hypotheses, the relation-
ship between MIL and SL has not yet been pointed out. From the shapelet-perspective in
MIL, the hypothesis (1) is regarded as a “single shapelet”-based hypothesis, and the hy-
pothesis (2) is regarded as a “multiple-shapelets”-based hypothesis. In this study, we refer
to a linear combination of maximum similarities based on shapelets such as (2) and (3) as
shapelet-based classiﬁers.

5

2. Preliminaries

Let X be an instance space. A bag B is a ﬁnite set of instances chosen from X . The learner
receives a sequence of labeled bags S = ((B1, y1), . . . , (Bm, ym)) ∈ (2X × {−1, 1})m
called a sample, where each labeled bag is independently drawn according to some un-
known distribution D over 2X × {−1, 1}. Let PS denote the set of all instances that appear
in the sample S. That is, PS = (cid:83)m
i=1 Bi. Let K be a kernel over X , which is used to mea-
sure the similarity between instances, and let Φ : X → H denote a feature map associated
with the kernel K for a Hilbert space H, that is, K(z, z(cid:48)) = (cid:104)Φ(z), Φ(z(cid:48))(cid:105) for instances
z, z(cid:48) ∈ X , where (cid:104)·, ·(cid:105) denotes the inner product over H. The norm induced by the inner
product is denoted by (cid:107) · (cid:107)H deﬁned as (cid:107)u(cid:107)H = (cid:112)(cid:104)u, u(cid:105) for u ∈ H.

For each u ∈ H which we call a shapelet, we deﬁne a shapelet-based classiﬁer denoted
by hu, as the function that maps a given bag B to the maximum of the similarity scores
between shapelet u and Φ(x) over all instances x in B. More speciﬁcally,

For a set U ⊆ H, we deﬁne the class of shapelet-based classiﬁers as

hu(B) = max
x∈B

(cid:104)u, Φ(x)(cid:105) .

HU = {hu | u ∈ U }

and let conv(HU ) denote the set of convex combinations of shapelet-based classiﬁers in
HU . More precisely,

(cid:26)(cid:90)

conv(HU ) =

wuhudu | wu is a density over U

(cid:27)

(cid:40)

=

u∈U

(cid:88)

wuhu | ∀u ∈ U (cid:48), wu ≥ 0,

u∈U (cid:48)

wu = 1, U (cid:48) ⊆ U is a ﬁnite support

.

(4)

(cid:41)

(cid:88)

u∈U (cid:48)

The goal of the learner is to ﬁnd a hypothesis g ∈ conv(HU ), so that its generalization error
ED(g) = Pr(B,y)∼D[sign(g(B)) (cid:54)= y] is small. Note that since the ﬁnal hypothesis sign ◦ g
is invariant to any scaling of g, we assume without loss of generality that

U = {u ∈ H | (cid:107)u(cid:107)H ≤ 1}.

Let Eρ(g) denote the empirical margin loss of g over S, that is, Eρ(g) = |{i | yig(Bi) <
ρ}|/m.

3. Optimization Problem Formulation

In this paper, we formulate the problem as soft margin maximization with 1-norm regu-
larization, which ensures a generalization bound for the ﬁnal hypothesis [see, e.g., 10].

6

Speciﬁcally, the problem is formulated as a linear programming problem (over inﬁnitely
many variables) as follows:

max
ρ,w,ξ

ρ −

(cid:90)

sub.to

1
νm

m
(cid:88)

i=1

ξi

yiwuhu(Bi)du ≥ ρ − ξi ∧ ξi ≥ 0, i ∈ [m],

u∈U

(cid:90)

u∈U

wudu = 1, wu ≥ 0, ρ ∈ R,

(5)

where ν ∈ [0, 1] is a parameter. To avoid the integral over the Hilbert space, it is convenient
to consider the dual form:

(6)

min
γ,d

γ

m
(cid:88)

sub.to

yidihu(Bi) ≤ γ, u ∈ U,

i=1
0 ≤ di ≤ 1/(νm), i ∈ [m],

m
(cid:88)

i=1

di = 1, γ ∈ R.

The dual problem is categorized as a semi-inﬁnite program because it contains inﬁnitely
many constraints. Note that the duality gap is zero because the problem (6) is linear and the
optimum is ﬁnite [see Theorem 2.2 of 29]. We employ column generation to solve the dual
problem: solve (6) for a ﬁnite subset U (cid:48) ⊆ U , ﬁnd u to which the corresponding constraint
is maximally violated by the current solution (column generation part), and repeat the
procedure with U (cid:48) = U (cid:48) ∪ {u} until a certain stopping criterion is met.
In particular,
we use LPBoost [10], a well-known and practically fast algorithm of column generation.
Since the solution w is expected to be sparse due to the 1-norm regularization, the number
of iterations is expected to be small.

Following the boosting terminology, we refer to the column generation part as weak

learning. In our case, weak learning is formulated following the optimization problem:

max
u∈H

m
(cid:88)

i=1

yidi max
x∈Bi

(cid:104)u, Φ (x)(cid:105) sub.to (cid:107)u(cid:107)2

H ≤ 1.

(7)

Thus, we need to design a weak learner for solving (7) for a given sample weighted by d.
However, it seems to be impossible to solve it directly because we only have access to U
through the associated kernel. Fortunately, we prove a version of representer theorem given
below, which makes (7) tractable.
Theorem 1 (Representer Theorem) The solution u∗ of (7) can be written as u∗ = (cid:80)
for some real numbers αz.

z∈PS

αzΦ(z)

7

Our theorem can be derived from a non-trivial application of the standard representer the-
orem [see, e.g., 23]. Intuitively, we prove the theorem by decomposing the optimization
problem (7) into a number of sub-problems, so that the standard representer theorem can
be applied to each of the sub-problems. The detail of the proof is given in Appendix A.

This result gives justiﬁcation to the simple heuristics in the standard approach: choosing
the shapelets based on the training instances. More precisely, the hypothesis class used in
the standard approach [7, 27] corresponds to the special case where u ∈ Utrain = {Φ(z) |
z ∈ PS}. Thus, our representer theorem would suggest that the standard approach of using
Utrain is reasonable.

Theorem 1 says that the weak learning problem can be rewritten in the following

tractable form:

OP 1 Weak Learning Problem

min
α

−

m
(cid:88)

i=1

diyi max
x∈Bi

(cid:88)

z∈PS

αzK (z, x)

sub.to

(cid:88)

(cid:88)

z∈PS

v∈PS

αzαvK (z, v) ≤ 1.

Unlike the primal solution w, the dual solution α is not expected to be sparse. To obtain
a more interpretable hypothesis, we propose another formulation of weak learning where
1-norm regularization is imposed on α, so that a sparse solution of α will be obtained. In
αzΦ(z) : (cid:107)α(cid:107)1 ≤ 1(cid:9),
other words, instead of U , we consider the feasible set ˆU = (cid:8)(cid:80)
where (cid:107)α(cid:107)1 is the 1-norm of α.

z∈PS

OP 2 Sparse Weak Learning Problem

min
α

−

m
(cid:88)

i=1

diyi max
x∈Bi

(cid:88)

z∈PS

αzK (z, x)

sub.to (cid:107)α(cid:107)1 ≤ 1

Note that when running LPBoost with a weak learner for OP 2, we obtain a ﬁnal hypothesis
that has the same form of generalization bound as the one stated in Theorem 2, which is of
a ﬁnal hypothesis obtained when used with a weak learner for OP 1. To see this, consider
a feasible space ˆUΛ = (cid:8)(cid:80)
αzΦ(z) : (cid:107)α(cid:107)1 ≤ Λ(cid:9) for a sufﬁciently small Λ > 0, so that
ˆUΛ ⊆ U . Then since H ˆUΛ
. On
the other hand, since the ﬁnal hypothesis sign ◦ g for g ∈ conv(H ˆUΛ
) is invariant to the
scaling factor Λ, the generalization ability is independent of Λ.

z∈PS
⊆ HU , a generalization bound for HU also applies to H ˆUΛ

4. Algorithms

In this section, we present the pseudo-code of LPBoost in Algorithm 1 for completeness.
Moreover, we describe our algorithms for the weak learners. For simplicity, we denote by

8

kx ∈ RPS a vector given by kx,z = K(z, x) for every z ∈ PS. The objective function of
OP 1 (and OP 2) is rewritten as

(cid:88)

i:yi=−1

di max
x∈Bi

kT

x α −

(cid:88)

i:yi=1

di max
x∈Bi

kT

x α,

which can be seen as a difference F − G of two convex functions F and G of α. Therefore,
the weak learning problems are DC programs and thus we can use DC algorithm [31, 36]
to ﬁnd an (cid:15)-approximation of a local optimum. We employ a standard DC algorithm. That
is, for each iteration t, we linearize the concave term G with ∇αG(αt)T α at the current
solution αt, which is (cid:80)
x α in our case, and then
update the solution to αt+1 by solving the resultant convex optimization problem OP(cid:48)
t.

i = arg maxx∈Bi kT

In addition, the problems OP(cid:48)

t for OP 1 and OP 2 are reformulated as a second-order
cone programming (SOCP) problem and an LP problem, respectively, and thus both prob-
lems can be efﬁciently solved. To this end, we introduce new variables λi for all negative
bags Bi with yi = −1 which represent the factors maxx∈Bi kT
x α. Then we obtain the
equivalent problem to OP(cid:48)

i:yi=1 dikT
x∗
i

α with x∗

t for OP 1 as follows:
(cid:88)

(cid:88)

diλi −

min
α,λ

sub.to kT

i:yi=1

i:yi=−1
x α ≤ λi (∀i : yi = −1, ∀x ∈ Bi),
(cid:88)
αzαvK (z, v) ≤ 1.

(cid:88)

di max
x∈Bi

kT

x α

(8)

v∈PS
It is well known that this is an SOCP problem. Moreover, it is clear that OP(cid:48)
be formulated as an LP problem. We describe the algorithm for OP 1 in Algorithm 2.

z∈PS

t for OP 2 can

One may concern that a kernel matrix may become large when a sample consists a large
amount of bags and instances. However, note that the kernel matrix of K(z, x) which is
used in Algorithm 2 needs to be computed only once at the beginning of Algorithm 1, not
at every iteration.

As a result, our learning algorithm outputs a classiﬁer

g(B) = sign

(cid:32) T

(cid:88)

t=1

wt max
x∈B

(cid:88)

z∈PS

(cid:33)

αt,zK(z, x)

where wt and αt are obtained in training phase. Therefore, the computational cost for
predicting the label of B is O(T |PS||B|) in the worst case when all elements of αt,z are
non-zero. However, when we employ our sparse formulation OP 2 which allows us to ﬁnd
a sparse α, the computational cost is expected to be much smaller than the worst case.

5. Generalization Bound of the Hypothesis Class

In this section, we provide a generalization bound of hypothesis classes conv(HU ) for
various U and K.

9

Algorithm 1 LPBoost using WeakLearn

Inputs:

S, kernel K, ν ∈ (0, 1], (cid:15) > 0

Initialize:

d0 ← ( 1
for t = 1, . . . do

m , . . . , 1

m ), γ = 0

ht ← Run WeakLearn(S, K, dt−1, (cid:15))
if (cid:80)m

i=1 yidiht(Bi) ≤ γ then
t = t − 1, break

end if

(γ, dt) ← arg min
γ,d

γ

sub.to

m
(cid:88)

i=1

yidihj(Bi) ≤ γ (j = 1, . . . , t),

0 ≤ di ≤ 1/νm (i ∈ [m]),

m
(cid:88)

di = 1, γ ∈ R.

i=1

end for
w ← Lagrangian multipliers of the last solution
g ← (cid:80)t
j=1 wjhj
return sign(g)

Let Φ(PS) = {Φ(z) | z ∈ PS}. Let Φdiﬀ(PS) = {Φ(z) − Φ(z(cid:48)) | z, z(cid:48) ∈ PS, z (cid:54)= z(cid:48)}.
By viewing each instance v ∈ Φdiﬀ(PS) as a hyperplane {u | (cid:104)v, u(cid:105) = 0}, we can naturally
deﬁne a partition of the Hilbert space H by the set of all hyperplanes v ∈ Φdiﬀ(PS). Let
I be the set of all cells of the partition, that is, I = {I | I = ∩v∈V {u | (cid:104)v, u(cid:105) > 0}, I (cid:54)=
∅, V ⊆ Φdiﬀ(PS), v ∈ V ⇔ −v /∈ V for all v ∈ Φdiﬀ(PS)}. Each cell I ∈ I is a
polyhedron which is deﬁned by a minimal set VI ⊆ Φdiﬀ(PS) that satisﬁes I = (cid:84)
{u |
(cid:104)u, v(cid:105) > 0}. Let

v∈VI

min
v∈VI
Φ,S be the VC dimension of the set of linear classiﬁers over the ﬁnite set Φdiﬀ(PS),

max
u∈I∩U

|(cid:104)u, v(cid:105)|.

µ∗ = min
I∈I

Let d∗
given by FU = {f : v (cid:55)→ sign((cid:104)u, v(cid:105)) | u ∈ U }.

Then we have the following generalization bound on the hypothesis class of (2).

Theorem 2 Let Φ : X → H. Suppose that for any z ∈ X , (cid:107)Φ(z)(cid:107)H ≤ R. Then, for any
ρ > 0, with high probability the following holds for any g ∈ conv(HU ) with U ⊆ {u ∈ H |
(cid:107)u(cid:107)H ≤ 1}:

ED(g) ≤Eρ(g) + O

R





(cid:113)

d∗
Φ,S log |PS|
√
m
ρ



 ,

(10)

10

Algorithm 2 WeakLearn using the DC Algorithm

Inputs:

S, K, d, (cid:15) (convergence parameter)

Initialize:

α0 ∈ R|PS |, f0 ← ∞

for t = 1, . . . do

for ∀k : yk = +1 do

x∗
k ← arg max
x∈Bk

end for

(cid:88)

z∈PS

dkαt,zK (z, x)

f ← min
α,λ

−

(cid:88)

(cid:88)

dk

k:yk=+1

z∈PS

αzK (z, x∗

k) +

(cid:88)

drλr

r:yr=−1
(9)

(cid:88)

sub.to

αzK (z, x) ≤ λr (∀r : yr = −1, ∀x ∈ Br),

z∈PS
(cid:88)

(cid:88)

αzαvK (z, v) ≤ 1.

z∈PS

v∈PS

αt ← α, ft ← f
if ft−1 − ft ≤ (cid:15) then

break

end if

end for
return h(B) = maxx∈B

(cid:80)

z∈PS

αt,zK(z, x)

Φ,S = O((R/µ∗)2), (ii) if X ⊆ R(cid:96) and Φ is the identity mapping
where (i) for any Φ, d∗
(i.e., the associated kernel is the linear kernel), or (iii) if X ⊆ R(cid:96) and Φ satisﬁes the
condition that (cid:104)Φ(z), Φ(x)(cid:105) is monotone decreasing with respect to (cid:107)z − x(cid:107)2 (e.g., the
mapping deﬁned by the Gaussian kernel) and U = {Φ(z) | z ∈ R(cid:96), (cid:107)Φ(z)(cid:107)H ≤ 1}, then
Φ,S = O(min((R/µ∗)2, (cid:96))).
d∗

We show the proof in Appendix B.

Comparison with the existing bounds A similar generalization bound can be derived
from a known bound of the Rademacher complexity of HU [Theorem 20 of 26] and a
generalization bound of conv(H) for any hypothesis class H [see Corollary 6.1 of 23]:

ED(g) ≤ Eρ(g) + O

(cid:18) log ((cid:80)m

i=1 |Bi|) log(m)

√

ρ

m

(cid:19)

.

Note that Sabato and Tishby [26] ﬁxed R = 1. For simplicity, we omit some constants
of [Theorem 20 of 26]. Note that |PS| ≤ (cid:80)m
i=1 |Bi| by deﬁnition. The bound above is

11

incomparable to Theorem 2 in general, as ours uses the parameter d∗
Φ,S and the other has
the extra (cid:112)log ((cid:80)m
i=1 |Bi|) log(m) term. However, our bound is better in terms of the
sample size m by the factor of O(log m) when other parameters are regarded as constants.

6. SL by MIL

6.1 Time-Series Classiﬁcation with Shapelets

In the following, we introduce a framework of time-series classiﬁcation problem based
on shapelets (i.e., SL problem). As mentioned in the previous section, a time series τ =
(τ [1], . . . , τ [L]) ∈ RL can be identiﬁed with a bag Bτ = {(τ [j], . . . , τ [j +(cid:96)−1]) | 1 ≤ j ≤
L − (cid:96) + 1} that consists of all subsequences of τ of length (cid:96). The learner receives a labeled
sample S = ((Bτ 1, y1), . . . , (Bτ m, ym)) ∈ (2R(cid:96) × {−1, 1})m, where each labeled bag (i.e.
labeled time series) is independently drawn according to some unknown distribution D
over a ﬁnite support of 2R(cid:96) × {−1, +1}. The goal of the learner is to predict the labels
of an unseen time series correctly. In this way, the SL problem can be viewed as an MIL
problem, and thus we can apply our algorithms and theory.

Note that, for time-series classiﬁcation, various similarity measures can be represented
by a kernel. For example, the Gaussian kernel (behaves like the Euclidean distance) and
Dynamic Time Warping (DTW) kernel. Moreover, our framework can generally apply to
non-real-valued sequence data (e.g., text, and a discrete signal) using a string kernel.

6.2 Our Theory and Algorithms for SL

By Theorem 2, we can immediately obtain the generalization bound of our hypothesis class
in SL as follows:

Corollary 3 Consider time-series sample S of size m and length L. For any ﬁxed (cid:96) < L,
the following generalization error bound holds for all g ∈ conv(HU ) in which the length
of shapelet is (cid:96):

ED(g) ≤ Eρ(g) + O

R





(cid:113)

d∗
Φ,S log(m(L − (cid:96) + 1))
m

√

ρ



 .

To the best of our knowledge, this is the ﬁrst result on the generalization performance of
SL.

Theorem 1 gives justiﬁcation to the heuristics which choose the shapelets extracted
from the instances appearing in the training sample (i.e., the subsequences for SL tasks).
Moreover, several methods using a linear combination of shapelet-based classiﬁers [e.g.,
17, 15], are supported by Corollary 3.

For time-series classiﬁcation problem, shapelet-based classiﬁcation has a greater advan-
tage of the interpretability or visibility than other time-series classiﬁcation methods [see,
e.g., 35]. Although we use a nonlinear kernel function, we can observe important subse-
quences that contribute to effective shapelets by solving OP 2 because of the sparsity (see

12

also the experimental results). Moreover, for unseen time-series data, we can observe the
type of subsequences that contribute to the predicted class by observing maximizer x ∈ B.

6.3 Learning Shapelets of Different Lengths

For time-series classiﬁcation, many existing methods take advantage of using shapelets of
various lengths. Below, we show that our formulation can be easily applied to the case.

A time series τ = (τ [1], . . . , τ [L]) ∈ RL can be identiﬁed with a bag Bτ = {(τ [j], . . . , τ [j+

(cid:96) − 1]) | 1 ≤ j ≤ L − (cid:96) + 1, ∀(cid:96) ∈ Q} that consists of all length (cid:96) ∈ Q ⊆ {1, . . . , L} of
subsequences of τ . That is, this is also a special case of MIL that a bag contains different
dimensional instances.

There is a simple way to apply our learning algorithm to this case. We just employ
some kernels K(z, x) which supports different dimensional instance pairs z and x. For-
tunately, such kernels have been studied well in the time-series domain. For example,
DTW kernel and Global Alignment kernel [9] are well-known kernels which support time
series of different lengths. However, the size of the kernel matrix of K(z, x) becomes
m((cid:80)
(cid:96)∈Q(L − (cid:96) + 1))2. In practice, it requires high memory cost for large time-series data.
Moreover, in general, the above kernel requires a higher computational cost than standard
kernels.

We introduce a practical way to learn shapelets of different lengths based on heuristics.
In each weak learning problem, we decomposed the original weak learning problem over
different dimensional data space into the weak learning problems over each dimensional
data space. For example, we consider solving the following problem instead of the weak
learning problem OP 1:

min
(cid:96)

min
α

−

m
(cid:88)

i=1

diyi max
x∈B(cid:96)
i

(cid:88)

z∈PS

(cid:96)

αzK (z, x) ,

(cid:88)

(cid:88)

sub.to

αzαvK (z, v) ≤ 1.

z∈PS

(cid:96)

v∈PS

(cid:96)

i=1 B(cid:96)

i . The total size of kernel matrices becomes m (cid:80)

(cid:96)
where B(cid:96)
i denotes the (cid:96) dimensional instances (i.e., length (cid:96) of subsequences) in Bi, and PS
denotes (cid:83)m
(cid:96)∈Q((L−(cid:96)+1))2, and thus
this method does not require so large kernel matrix. Moreover, in this way, we do not need
to use a kernel which supports different dimensional instances. Note that, even using this
heuristic, the obtained ﬁnal hypothesis has theoretical generalization performance. This is
because the hypothesis class still represented as the form of (4). In our experiment, we use
the latter method by giving weight to memory efﬁciency.

6.4 Heuristics for computational efﬁciency

For the practical applications, we introduce some heuristics for improving efﬁciency in our
algorithm.

13

Reduction of PS Especially for time-series data, the size |PS| often becomes large be-
cause |PS| = O(mL). Therefore, constructing a kernel matrix of |PS| × |PS| has high
computational costs for time-series data. For example, when we consider subsequences as
instances for time series classiﬁcation, we have a large computational cost because of the
number of subsequences of training data (e.g., approximately 106 when sample size is 1000
and length of each time series is 1000, which results in a similarity matrix of size 1012).
However, in most cases, many subsequences in time series data are similar to each other.
Therefore, we only use representative instances ˆPS instead of the set of all instances PS. In
this paper, we use k-means clustering to reduce the size of |PS|. Note that our heuristic ap-
proach is still supported by our theoretical generalization error bound. This is because the
hypothesis set HU (cid:48) with the reduced shapelets U (cid:48) is the subset of HU , and the Rademacher
complexity of HU (cid:48) is exactly smaller than the Rademacher complexity of HU . Thus, The-
orem 2 holds for the hypothesis class considering the set HU of all possible shapelets U ,
and thus Theorem 2 also holds for the hypothesis class using the set HU (cid:48) of some reduced
shapelets U (cid:48). Although this approach may decrease the training classiﬁcation accuracy in
practice, it drastically decreases the computational cost for a large dataset.

Initialization in weak learning problem DC program may slowly converge to local op-
timum depending on the initial solution. In Algorithm 2, we ﬁx an initial α0 as following:
More precisely, we initially solve

α0 = arg max

α

m
(cid:88)

i=1

diyi max
x∈Bi

(cid:88)

z∈PS

αzK (z, x) ,

(11)

sub.to α is a one-hot vector.

That is, we choose the most discriminative shapelet from PS as the initial point of u for
given d. We expect that it will speed up the convergence of the loop of line 3, and the
obtained classiﬁer is better than the methods that choose effective shapelets from subse-
quences.

7. Experiments

In this section, we show some experimental results implying that our algorithm performs
comparably with the existing shapelet-based classiﬁers for both SL and MIL tasks 2.

7.1 Results for Time-Series Data

We use binary labeled datasets3 available in UCR datasets [8], which are often used as
benchmark datasets for time-series classiﬁcation methods. We used a weak learning prob-
lem OP 2 because the interpretability of the obtained classiﬁer is required in shapelet-based
time-series classiﬁcation.

2. The code of our method is available in https://github.com/suehiro93/MILIMS_NECO
3. Note that our method is applicable to multi-class classiﬁcation tasks by easy expansion (e.g., [24]).

14

We compare the following three shapelet-based approaches.

• Shapelet Transform (ST) provided by Bagnall et al. [4]

• Learning Time-Series Shapelets (LTS) provided by Grabocka et al. [15]

• Our algorithm using shapelets of different lengths (Ours)

We used the implementation of ST provided by L¨oning et al. [22], and used the imple-
mentation of LTS provided by Tavenard et al. [32]. The classiﬁcation rule of Shapelets
Transform has the form:

(cid:18)

(cid:19)

g(B) = f

max
x∈B

−(cid:107)z1 − x(cid:107), . . . , max
x∈B

−(cid:107)zk − x(cid:107)

,

where f is a user-deﬁned classiﬁcation function (the implementation employs decision for-
est), z1, . . . , zk ∈ PS (in the time-series domain, this zj is called a shapelet). The shapelets
are chosen from training subsequences in some complicated way before learning f . The
classiﬁcation rule of Learning Time-series Shapelets has the form:

g(B) =

k
(cid:88)

j=1

wj max
x∈B

−(cid:107)zj − x(cid:107),

where wj ∈ R and zj ∈ R(cid:96) are learned parameters, the number of desired shapelets k is a
hyper-parameter.

Below we show the detail condition of the experiment. For ST, we set the shapelet
lengths {2, . . . , L/2}, where L is the length of each time series in the dataset. ST also
requires a parameter of time limit for searching shapelets, and we set it as 5 hours for
each dataset. For LTS, we used the hyper-parameter sets (regularization parameter, num-
that the authors recommended in their website4, and we found
ber of shapelets, etc.)
an optimal hyper-parameter by 3-fold cross-validation for each dataset. For our algo-
rithms, we implemented a weak learning algorithm which supports shapelets of different
lengths (see Section 6.3). In this experiment, we consider the case that each bag contains
lengths {0.05, 0.1, 0.15, . . . , 0.5} × L of the subsequences. We used the Gaussian kernel
K(x, x(cid:48)) = exp(− (cid:107)x−x(cid:48)(cid:107)2
), chose 1/σ2 from {0.01, 0.05, 0.1, . . . , 50}. We chose ν from
{0.1, 0.2, 0.3, 0.4}. We use 100-means clustering with respect to each class to reduce PS.
The parameters we should tune are only ν and σ. We tuned these parameters via a proce-
dure we give in Appendix B.1. As an LP solver for WeakLearn and LPBoost we used the
CPLEX software. In addition to Ours, LTS employs k-means clustering to set the initial
shapelets in the optimization algorithm. Therefore, we show the average accuracies for
LTS and Ours considering the randomness of k-means clustering.

(cid:96)σ2

The classiﬁcation accuracy results are shown in Table 1. We can see that our algorithms
achieve comparable performance with ST and LTS. We conducted the Wilcoxon signed-
rank test between Ours and the others. The p-value of Wilcoxon signed-rank test for Ours

4. http://fs.ismll.de/publicspace/LearningShapelets/

15

and ST is 0.1247. The p-value of Wilcoxon signed-rank test for Ours and LTS is 0.6219.
The p-values are higher than 0.05, and thus we cannot rejcect that there is no signiﬁcant
difference between the medians of the accuracies. We can say that our MIL algorithm
works well for time-series classiﬁcation tasks without using domain-speciﬁc knowledge.

We would like to compare the computation time of these methods. We selected the
datasets that these three methods have achieved similar performance. The experiments
are performed on Intel Xeon Gold 6154, 36 core CPU, 192GB memory. Table 2 shows the
comparison of the running time of the training. Note that again, for ST, we set the limitation
of the running time as 5 hours for ﬁnding good shapelets. This running time limitation is
a hyper-parameter of the code and it is difﬁcult to be estimated before experiments. LTS
efﬁciently worked compared with ST and Ours. However, it seems that LTS achieved lower
performance than ST and Ours on accuracy. Table 3 shows the testing time of the methods.
LTS also efﬁciently worked, simply because LTS ﬁnds effective shapelets of a ﬁxed number
(hyper-parameter). ST and Ours may ﬁnd a large number of shapelets and this increases the
computation time of prediction. For Wafer dataset, ST and Ours required large computation
time compared with LTS.

We can not fairly compare the efﬁciency of these methods because the implementation
environments (e.g., programming languages) are different. However, we can say that the
proposed method totally achieved high classiﬁcation accuracy with reasonable running time
for training and prediction.

Interpretability of our method We would like to show the interpretability of our method.
We use CBF dataset which contains three classes (cylinder, bell, and funnel) of time series.
The reason is that, it is known that the discriminative patterns are clear, and thus we can
easily ascertain if the obtained hypothesis can capture the effective shapelets. For simplic-
ity, we obtain a binary classiﬁcation model for each class preparing one-vs-others training
set. We used Ours with ﬁxed shapelet length (cid:96) = 25. As following, we introduce two types
of visualization approach to interpret a learned model.

One is the visualization of the characteristic subsequences of an input time series. When
we predict the label of the time series B, we calculate a maximizer x∗ in B for each hu,
that is, x∗ = arg maxx∈B(cid:104)u, Φ(x)(cid:105). For image recognition tasks, the maximizers are com-
monly used to observe the sub-images that characterize the class of the input image [e.g.,
7]. In time-series classiﬁcation tasks, the maximizers also can be used to observe some
characteristic subsequences. Fig. 1 is an example of a visualization of maximizers. Each
value in the legend indicates wu maxx∈B(cid:104)u, Φ(x)(cid:105). That is, subsequences with positive
values contribute to the positive class and subsequences with negative values contribute to
the negative class. Such visualization provides the subsequences that characterize the class
of the input time series. For cylinder class, although both positive and negative patterns
match almost the same subsequence, the positive pattern is stronger than negative, and thus
the hypothesis can correctly discriminate the time series. For bell and funnel class, we can
observe that the highlighted subsequences clearly indicate the discriminative patterns.

16

Table 1: Classiﬁcation accuracies for time-series datasets.

ST
0.8
0.9
0.964
0.704 0.619
0.757 0.714
0.741 0.748
0.85
0.835
0.999 0.961
0.856 0.914
0.9
0.74
0.987 0.971
0.762 0.782
0.919 0.892
0.594 0.652
0.947 0.951
0.639 0.695
0.794 0.579
0.927 0.849
0.773 0.633
0.869 0.742
0.994 0.989
0.932 0.903
0.922 0.895
0.941 0.844
0.956 0.947
0.792 0.886
0.995 0.981
0.993
0.741 0.487
0.831 0.752
0.847
0.69

LTS Ours
0.835
0.765
0.935
0.93
1
0.964
0.623
0.802
0.728
0.872
1
0.89
0.786
0.987
0.698
0.87
0.588
0.943
0.779
0.632
0.845
0.792
0.844
1
0.841
0.887
0.947
0.906
0.823
0.949
0.991
0.72
0.608
0.804

1

Dataset
BeetleFly
BirdChicken
Coffee
Computers
DistalPhalanxOutlineCorrect
Earthquakes
ECG200
ECGFiveDays
FordA
FordB
GunPoint
Ham
HandOutlines
Herring
ItalyPowerDemand
Lightning2
MiddlePhalanxOutlineCorrect
MoteStrain
PhalangesOutlinesCorrect
ProximalPhalanxOutlineCorrect
ShapeletSim
SonyAIBORobotSurface1
SonyAIBORobotSurface2
Strawberry
ToeSegmentation1
ToeSegmentation2
TwoLeadECG
Wafer
Wine
WormsTwoClass
Yoga

17

Table 2: Training time (sec.) for several time series datasets.

dataset
Earthquakes
GunPont
ItalyPowerDemand
ShapeletSim
Wafer

#train length
322
50
67
20
1000

512
150
24
180
152

ST
18889.8
18016.2
18000.8
18011.6
18900.8

LTS
250.5
22.3
11.5
30.4
91.5

Ours
1339.2
36.9
8.6
32.8
431.7

Table 3: Testing time (sec.) for several time series datasets.

dataset
Earthquakes
GunPont

#test
139
150
ItalyPowerDemand 1029
180
6164

ShapeletSim
Wafer

length
512
150
24
180
152

ST
389.7
48.0
3.3
104.0
5688.2

LTS Ours
11.55
2.75
3.9
1.1
10.7
0.5
1.1
1.8
173.1
4.3

(cid:80)

zj ∈ ˆPS

The other is the visualization of a ﬁnal hypothesis g(B) = (cid:80)t

j=1 wjhj(B), where
αj,zj K(zj, x) ( ˆPS is the set of representative subsequences ob-
hj(B) = maxx∈B
tained by k-means clustering). Fig. 2 is an example of the visualization of a ﬁnal hypothesis
obtained by our algorithm. The colored lines are all the zjs in g where both wj and αj,zj
were non-zero. Each legend value shows the multiplication of wj and αj,zj corresponding
to zj. That is, positive values of the colored lines indicate the contribution rate for the pos-
itive class, and negative values indicate the contribution rate for the negative class. Note
that, because it is difﬁcult to visualize the shapelets over the Hilbert space associated with
the Gaussian kernel, we plotted each of them to match the original time series based on
the Euclidean distance. Unlike the previous visualization analyses [see, e.g., 35], our vi-
sualization does not exactly interpret the ﬁnal hypothesis because of the non-linear feature
map. However, we can deduce that the colored lines represent “important patterns”, which
make signiﬁcant contributions to classiﬁcation.

7.2 Results for Multiple-Instance Data

We selected the baselines of MIL algorithms as mi-SVM and MI-SVM [2], and MILES [7].
mi-SVM and MI-SVM are classical method in MIL, but still perform favorably compared
with state-of-the-art methods for standard multiple-instance data [see, e.g., 12]. The details
of the datasets are shown in Table 4.

mi- and MI-SVM ﬁnd a single but an optimized shapelet u which is not limited to the
instance in the training sample. The classiﬁers obtained by these algorithms are formulated

18

(cylinder)

(bell)

(funnel)

Figure 1: Examples of the visualization of maximizers for a CBF time-series data. Black
lines are original time series. We highlight each subsequence that maximizes the similarity
with some shapelet in a classiﬁer. Subsequences with positive values (red) contribute to
the positive class and subsequences with negative values (blue) contribute to the negative
class.

as:

g(B) = max
x∈B

(cid:104)u, Φ(x)(cid:105) = max
x∈B

(cid:88)

z∈PS

αzK(z, x).

(12)

MILES ﬁnds the multiple-shapelets, but they are limited to the instances in the training
sample. The classiﬁer of MILES is formulated as follows:

g(B) =

(cid:88)

z∈PS

wz max
x∈B

K(z, x).

(13)

We used the implementation provided by Doran5 for mi-SVM and MI-SVM. We com-
bined the Gaussian kernel with mi-SVM and MI-SVM. Parameter C was chosen from
{1, 10, 100, 1000, 10000}. For our method and MILES6, we chose ν from {0.5, 0.3, 0.2, 0.15, 0.1},

5. https://github.com/garydoranjr/misvm
6. MILES uses 1-norm SVM to obtain a ﬁnal classiﬁer. We implemented 1-norm SVM by using the formu-

lation of [33]

19

020406080100120−4−2024timevalue020406080100120−4−2024timevalue020406080100120−4−2024timevalue0.333−0.229020406080100120−4−2024timevalue020406080100120−4−2024timevalue020406080100120−4−2024timevalue020406080100120−4−2024timevalue020406080100120−4−2024timevalue020406080100120−4−2024timevalue0.3120.0276−0.0726−0.102−0.123020406080100120−4−2024timevalue020406080100120−4−2024timevalue020406080100120−4−2024timevalue020406080100120−4−2024timevalue020406080100120−4−2024timevalue0.313−0.055−0.0585−0.12(cylinder)

(bell)

(funnel)

Figure 2: Examples of the visualization of shapelets for a CBF time-series data. The col-
ored lines show important patterns of the obtained classiﬁer. Positive values on the colored
lines (red to yellow) indicate the contribution rate for the positive class, and negative values
(blue to purple) indicate the contribution rate for the negative class.

and we only used the Gaussian kernel. Furthermore, we chose σ from {0.005, 0.01, 0.05, 0.1, 0.5, 1.0}.
We use 100-means clustering with respect to each class to reduce PS. To avoid the random-
ness of k-means, we ran 30 times of training and selected the model which achieved the
best training accuracy. For efﬁciency, we demonstrated the weak learning problem OP
2. For all these algorithms, we estimated optimal parameter set via 5-fold cross-validation.
We used well-known multiple-instance data as shown on the left-hand side of Table 5. The
accuracies resulted from 10 times of 5-fold cross-validation.

Table 4: Details of MIL datasets.

dataset
MUSK1
MUSK2
elephant
fox
tiger

sample size # instances dimension
476
6598
1391
1320
1220

92
102
200
200
200

166
166
230
230
230

20

020406080100120−4−2024020406080100120−4−2024020406080100120−4−2024020406080100120−4−2024020406080100120−4−20240.6920.023−0.047−0.238020406080100120−3−2−10123020406080100120−3−2−10123020406080100120−3−2−10123020406080100120−3−2−10123020406080100120−3−2−10123020406080100120−3−2−101230.4640.1290.090.045−0.172020406080100120−4−2024020406080100120−4−2024020406080100120−4−2024020406080100120−4−2024020406080100120−4−2024020406080100120−4−20240.4480.0790.058−0.06−0.132Table 5: Classiﬁcation accuracies for MIL datasets.

dataset
MUSK1
MUSK2
elephant
fox
tiger

mi-SVM
0.834 ± 0.084
0.749 ± 0.082
0.785 ± 0.070
0.618 ± 0.069
0.752 ± 0.078

MI-SVM

MILES

0.820 ± 0.081 0.865 ± 0.068
0.871 ± 0.072
0.840 ± 0.074
0.823 ± 0.056
0.796 ± 0.068
0.578 ± 0.075 0.675 ± 0.071
0.815 ± 0.055 0.827 ± 0.057

Ours
0.844 ± 0.076
0.879 ± 0.067
0.828 ± 0.061
0.646 ± 0.063
0.817 ± 0.058

Table 6: Training accuracies for MIL datasets.

dataset MILES Ours
0.985
MUSK1
0.993
MUSK2
0.993
elephant
0.995
fox
0.993
tiger

0.987
0.980
0.963
0.987
0.973

Table 7: Training time (sec.) for MIL datasets.

dataset mi-SVM MI-SVM MILES Ours
5.57
MUSK1
80.5
MUSK2
8.30
elephant
26.4
fox
9.8
tiger

29.6
3760.1
240.6
201.9
158.5

28.1
3530.0
130.3
139.2
118.0

0.584
103.1
5.84
5.4
4.6

Table 8: Testing time (sec.) for MIL datasets.

dataset mi-SVM MI-SVM MILES Ours
0.045
MUSK1
0.083
MUSK2
0.115
elephant
0.145
fox
0.118
tiger

0.011
0.129
0.067
0.118
0.065

0.004
0.063
0.015
0.025
0.012

0.010
0.577
0.053
0.078
0.059

The results are shown in Table 5. MILES and Ours achieve signiﬁcantly better perfor-
mance than mi- and MI-SVM. Ours achieves comparable performance to MILES. Table 6
shows the training accuracies of MILES and Ours. It can be seen that Ours achieves higher
training accuracy. This result is theoretically reasonable because our hypothesis class is
richer than MILES. However, in other words, this means that Ours has a higher overﬁtting
risk than MILES.

21

Table 7 shows that the training time of the ﬁve methods. It is clear that MILES and
Ours are more efﬁcient than mi- and MI-SVM. The main reason is that mi- and MI-SVM
solve Quadratic Programming (QP) problem while MILES and Ours solve LP problems.
MILES worked averagely more efﬁcient than Ours. However, for MUSK2 which has a
large number of instances, Ours worked more efﬁciently than MILES.

The testing time of each algorithm is shown in Table 8. We can see that Ours is com-

parable to the other algorithms.

8. Conclusion and Future Work

We proposed a new MIL formulation that provides a richer class of the ﬁnal classiﬁers
based on inﬁnitely many shapelets. We derived the tractable formulation over inﬁnitely
many shapelets with theoretical support, and provided an algorithm based on LPBoost
and DC (Difference of Convex) algorithm. Our result gives theoretical justiﬁcation for
some existing shapelet-based classiﬁers [e.g., 7, 17]. The experimental results demonstrate
that the provided approach uniformly works for SL and MIL tasks without introducing
domain-speciﬁc parameters and heuristics, and compares with the baselines of shapelet-
based classiﬁers.

Especially for time-series classiﬁcation, the number of instances usually becomes large.
Although we took a heuristic approach in the experiment, we think it is not an essential
solution to improve the efﬁciency. We preliminarily implemented OP 1 with Orthogonal
Random Features [37] that can approximate the Gaussian kernel accurately. It allows us
to solve the primal problem of OP 1 directly, and allows us to avoid constructing a large
kernel matrix. The implementation improved the efﬁciency drastically; however, it did
not achieve high accuracy as compared with solutions of OP 2 with the heuristics. For
SL tasks, there are many successful efﬁcient methods using some heuristics specialized
in time-series domain [20, 25, 16, 34, 18, 19]. We will explore many ways to improve
efﬁciency for SL tasks.

Moreover, we would like to improve the generalization error bound. Our bound is still
incomparable with the existing bound. Since we think it requires to study more complex
analysis, we reserve this for future work. Our heuristics might reduce the model complexity
(i.e., the risk of overﬁtting); however, we do not know how the complexity can be reduced
by our heuristics theoretically. To apply our method to various domains, we would like to
explore the general techniques for reducing overﬁtting risk of our method.

Acknowledgement

We would like to thank Prof. Eamonn Keogh and all the people who have contributed
to the UCR time series classiﬁcation archive. This work is supported by JST CREST
(Grant Number JPMJCR15K5) and JSPS KAKENHI (Grant Number JP18K18001). In the
experiments, we used the computer resource offered under the category of General Projects
by Research Institute for Information Technology, Kyushu University.

22

References

[1] Andrews, S. and Hofmann, T. (2004). Multiple instance learning via disjunctive pro-
gramming boosting. In Advances in Neural Information Processing Systems, pages 65–
72.

[2] Andrews, S., Tsochantaridis, I., and Hofmann, T. (2003). Support vector machines
for multiple-instance learning. In Advances in Neural Information Processing Systems,
pages 577–584.

[3] Auer, P. and Ortner, R. (2004). A boosting approach to multiple instance learning. In

European Conference on Machine Learning, pages 63–74.

[4] Bagnall, A., Lines, J., Bostrom, A., Large, J., and Keogh, E. (2017). The great time
series classiﬁcation bake off: a review and experimental evaluation of recent algorithmic
advances. Data Mining and Knowledge Discovery, 31(3):606–660.

[5] Bartlett, P. L. and Mendelson, S. (2003). Rademacher and gaussian complexities: Risk

bounds and structural results. Journal of Machine Learning Research, 3:463–482.

[6] Carbonneau, M.-A., Cheplygina, V., Granger, E., and Gagnon, G. (2018). Multiple
instance learning: A survey of problem characteristics and applications. Pattern Recog-
nition, 77:329 – 353.

[7] Chen, Y., Bi, J., and Wang, J. Z. (2006). Miles: Multiple-instance learning via em-
bedded instance selection. IEEE Transactions on Pattern Analysis and Machine Intelli-
gence, 28(12):1931–1947.

[8] Chen, Y., Keogh, E., Hu, B., Begum, N., Bagnall, A., Mueen, A., and Batista, G.
(2015). The ucr time series classiﬁcation archive. www.cs.ucr.edu/˜eamonn/
time_series_data/.

[9] Cuturi, M. (2011). Fast global alignment kernels.

In International conference on

machine learning, pages 929–936.

[10] Demiriz, A., Bennett, K. P., and Shawe-Taylor, J. (2002). Linear Programming Boost-

ing via Column Generation. Machine Learning, 46(1-3):225–254.

[11] Dietterich, T. G., Lathrop, R. H., and Lozano-P´erez, T. (1997). Solving the multiple
instance problem with axis-parallel rectangles. Artiﬁcial Intelligence, 89(1-2):31–71.

[12] Doran, G. (2015). Multiple Instance Learning from Distributions. PhD thesis, Case

WesternReserve University.

[13] Doran, G. and Ray, S. (2014). A theoretical and empirical analysis of support vector
machine methods for multiple-instance classiﬁcation. Machine Learning, 97(1-2):79–
102.

23

[14] G¨artner, T., Flach, P. A., Kowalczyk, A., and Smola, A. J. (2002). Multi-instance

kernels. In International Conference on Machine Learning, pages 179–186.

[15] Grabocka, J., Schilling, N., Wistuba, M., and Schmidt-Thieme, L. (2014). Learn-
In ACM SIGKDD International Conference on Knowledge

ing time-series shapelets.
Discovery and Data Mining, pages 392–401.

[16] Grabocka, J., Wistuba, M., and Schmidt-Thieme, L. (2015). Scalable discovery of

time-series shapelets. CoRR, abs/1503.03238.

[17] Hills, J., Lines, J., Baranauskas, E., Mapp, J., and Bagnall, A. (2014). Classiﬁca-
tion of time series by shapelet transformation. Data Mining and Knowledge Discovery,
28(4):851–881.

[18] Hou, L., Kwok, J. T., and Zurada, J. M. (2016). Efﬁcient learning of timeseries

shapelets. In AAAI Conference on Artiﬁcial Intelligence,, pages 1209–1215.

[19] Karlsson, I., Papapetrou, P., and Bostr¨om, H. (2016). Generalized random shapelet

forests. Data Mining and Knowledge Discovery, 30(5):1053–1085.

[20] Keogh, E. J. and Rakthanmanon, T. (2013). Fast shapelets: A scalable algorithm for
discovering time series shapelets. In International Conference on Data Mining, pages
668–676.

[21] Le Thi, H. A. and Pham Dinh, T. (2018). DC programming and DCA: thirty years of

developments. Mathematical Programming, 169(1):5–68.

[22] L¨oning, M., Bagnall, A., Ganesh, S., Kazakov, V., Lines, J., and Kir´aly, F. J. (2019).

sktime: A uniﬁed interface for machine learning with time series.

[23] Mohri, M., Rostamizadeh, A., and Talwalkar, A. (2012). Foundations of Machine

Learning. The MIT Press.

[24] Platt, J. C., Cristianini, N., and Shawe-Taylor, J. (2000). Large margin DAGs for
multiclass classiﬁcation. In Advances in Neural Information Processing Systems, pages
547–553.

[25] Renard, X., Rifqi, M., Erray, W., and Detyniecki, M. (2015). Random-shapelet: an
algorithm for fast shapelet discovery. In IEEE International Conference on Data Science
and Advanced Analytics, pages 1–10.

[26] Sabato, S. and Tishby, N. (2012). Multi-instance learning with any hypothesis class.

Journal of Machine Learning Research, 13(1):2999–3039.

[27] Sangnier, M., Gauthier, J., and Rakotomamonjy, A. (2016). Early and reliable event
detection using proximity space representation. In International Conference on Machine
Learning, pages 2310–2319.

24

[28] Sch¨olkopf, B. and Smola, A. (2002). Learning with Kernels: Support Vector Ma-
chines, Regularization, Optimization, and Beyond. Adaptive Computation and Machine
Learning. MIT Press.

[29] Shapiro, A. (2009). Semi-inﬁnite programming, duality, discretization and optimality

conditions. Optimization, 58(2):133–161.

[30] Shimodaira, H., Noma, K.-i., Nakai, M., and Sagayama, S. (2001). Dynamic time-
In International Conference on Neural

alignment kernel in support vector machine.
Information Processing Systems, pages 921–928.

[31] Tao, P. D. and Souad, E. B. (1988). Duality in D.C. (Difference of Convex functions)

Optimization. Subgradient Methods, pages 277–293.

[32] Tavenard, R., Faouzi, J., and Vandewiele, G. (2017).

tslearn: A machine learn-
ing toolkit dedicated to time-series data. https://github.com/rtavenar/
tslearn.

[33] Warmuth, M., Glocer, K., and R¨atsch, G. (2008). Boosting algorithms for maximizing
the soft margin. In Advances in Neural Information Processing Systems, pages 1585–
1592.

[34] Wistuba, M., Grabocka, J., and Schmidt-Thieme, L. (2015). Ultra-fast shapelets for

time series classiﬁcation. CoRR, abs/1503.05018.

[35] Ye, L. and Keogh, E. (2009). Time series shapelets: A new primitive for data mining.
In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,
pages 947–956.

[36] Yu, C.-N. J. and Joachims, T. (2009). Learning structural svms with latent variables.

In International Conference on Machine Learning, pages 1169–1176.

[37] Yu, F. X. X., Suresh, A. T., Choromanski, K. M., Holtmann-Rice, D. N., and Kumar,
S. (2016). Orthogonal random features. In Advances in Neural Information Processing
Systems, pages 1975–1983.

[38] Zhang, C., Platt, J. C., and Viola, P. A. (2006). Multiple instance boosting for object
detection. In Advances in Neural Information Processing Systems, pages 1417–1424.

[39] Zhang, D., He, J., Si, L., and Lawrence, R. (2013). MILEAGE: Multiple instance
In International Conference on Machine Learning,

learning with global embedding.
pages 82–90.

25

Appendix A. Proof of Theorem 1

First, we give a deﬁnition for convenience.

Deﬁnition 1 [The set Θ of mappings from a bag to an instance]
Given a sample S = (B1, . . . , Bm). For any u ∈ U , let θu,Φ : {B1, . . . , Bm} → X be a
mapping deﬁned by

θu,Φ(Bi) := arg max
x∈Bi

(cid:104)u, Φ (x)(cid:105) ,

and we deﬁne the set of all θu,Φ for S as ΘS,Φ = {θu,Φ | u ∈ U }. For the sake of brevity,
θu,Φ and ΘS,Φ will be abbreviated as θu and Θ, respectively.

Below we give a proof of Theorem 1.
Proof We can rewrite the optimization problem (7) by using θ ∈ Θ as follows:

max
θ∈Θ

max
u∈H:θu=θ

sub.to

m
(cid:88)

yidi (cid:104)u, Φ (θ(Bi))(cid:105)

i=1
(cid:107)u(cid:107)2

H ≤ 1.

(14)

Thus, if we ﬁx θ ∈ Θ, we have a sub-problem. Since the constraint θ = θu can be written as
the number |PS| of linear constraints (i.e., sub.to (cid:104)u, Φ(x)(cid:105) ≤ (cid:104)u, Φ(θ(Bi))(cid:105) (i ∈ [m], x ∈
Bi)), each sub-problem is equivalent to a convex optimization. Indeed, each sub-problem
can be written as the equivalent unconstrained minimization (by neglecting constants in the
objective)

min
u∈H

β(cid:107)u(cid:107)2

H −

m
(cid:88)

(cid:88)

i=1

x∈Bi

ηi,x ((cid:104)u, Φ (θ(Bi))(cid:105) − (cid:104)u, Φ(x)(cid:105)) −

m
(cid:88)

i=1

yidi (cid:104)u, Φ (θ(Bi))(cid:105)

where β and ηi,x (i ∈ [m], x ∈ Bi) are the corresponding positive constants. Now for each
sub-problem, we can apply the standard Representer Theorem argument [see, e.g., 23]).
Let H1 be the subspace {u ∈ H | u = (cid:80)
αzΦ(z), αz ∈ R}. We denote u1 as the
z∈PS
orthogonal projection of u onto H1 and any u ∈ H has the decomposition u = u1 + u⊥.
Since u⊥ is orthogonal w.r.t. H1, (cid:107)u(cid:107)2
H = (cid:107)u1(cid:107)2
H. On the other hand,
(cid:104)u, Φ (z)(cid:105) = (cid:104)u1, Φ (z)(cid:105). Therefore, the optimal solution of each sub-problem has to be
contained in H1. This implies that the optimal solution, which is the maximum over all
solutions of sub-problems, is contained in H1 as well.

H ≥ (cid:107)u1(cid:107)2

H + (cid:107)u⊥(cid:107)2

Appendix B. Proof of Theorem 2

We use θ and Θ of Deﬁnition 1.

Deﬁnition 2 [The Rademacher and the Gaussian complexity [5]]
Given a sample S = (x1, . . . , xm) ∈ X m, the empirical Rademacher complexity R(H) of

26

a class H ⊂ {h : X → R} w.r.t. S is deﬁned as RS(H) = 1
i=1 σih(xi)],
where σ ∈ {−1, 1}m and each σi is an independent uniform random variable in {−1, 1}.
The empirical Gaussian complexity GS(H) of H w.r.t. S is deﬁned similarly but each σi is
drawn independently from the standard normal distribution.

[suph∈H

m E
σ

(cid:80)m

The following bounds are well-known.

Lemma 1 [Lemma 4 of [5]] RS(H) = O(GS(H)).

Lemma 2 [Corollary 6.1 of [23]] For ﬁxed ρ, δ > 0, the following bound holds with
probability at least 1 − δ: for all f ∈ conv(H),

ED(f ) ≤ Eρ(f ) +

2
ρ

RS(H) + 3

(cid:115)

log 1
δ
2m

.

To derive generalization bound based on the Rademacher or the Gaussian complexity
is quite standard in the statistical learning theory literature and applicable to our classes of
interest as well. However, a standard analysis provides us sub-optimal bounds.

Lemma 3 Suppose that for any z ∈ X , (cid:107)Φ(z)(cid:107)H ≤ R. Then, the empirical Gaussian
complexity of HU with respect to S for U ⊆ {u | (cid:107)u(cid:107)H ≤ 1} is bounded as follows:

(cid:113)
√
(

R

GS(H) ≤

2 − 1) + 2(ln |Θ|)

√

m

.

27

Proof Since U can be partitioned into (cid:83)

θ∈Θ{u ∈ U | θu = θ},

(cid:34)

(cid:34)

sup
θ∈Θ

sup
u∈U :θu=θ

m
(cid:88)

i=1
(cid:42)

(cid:35)

σi (cid:104)u, Φ (θ(Bi))(cid:105)

(cid:32) m
(cid:88)

(cid:33)(cid:43)(cid:35)

σiΦ (θ(Bi))

u,

i=1

(cid:33)(cid:43)(cid:35)

σiΦ (θ(Bi))

u,

(cid:32) m
(cid:88)

i=1

σiΦ (θ(Bi))

(cid:35)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)H

E
σ

E
σ

E
σ

E
σ

GS(HU ) =

=

≤

≤

=

1
m

1
m

1
m

1
m

1
m

sup
θ∈Θ

(cid:34)

(cid:34)

sup
θ∈Θ

sup
θ∈Θ



sup
u∈U :θu=θ
(cid:42)

m
(cid:88)

sup
u∈U
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:118)
(cid:117)
(cid:117)
(cid:116)

i=1
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

m
(cid:88)

i=1

E
σ

sup
θ∈Θ

σiΦ (θ(Bi))

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

H

σiΦ (θ(Bi))

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

H









σiΦ (θ(Bi))

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

H



.

(15)

=

1
m

E
σ





(cid:118)
(cid:117)
(cid:117)
(cid:116)sup
θ∈Θ

(cid:118)
(cid:117)
(cid:117)
(cid:117)
(cid:116)E
σ

1
m



sup
θ∈Θ

≤

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

m
(cid:88)

i=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

m
(cid:88)

i=1

The ﬁrst inequality is derived from the relaxation of u, the second inequality is due to
Cauchy-Schwarz inequality and the fact (cid:107)u(cid:107)H ≤ 1, and the last inequality is due to Jensen’s
inequality. We denote by K(θ) the kernel matrix such that K(θ)
ij = (cid:104)Φ((θ(Bi)), Φ(θ(Bj))(cid:105).
Then, we have



E
σ

sup
θ∈Θ

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

m
(cid:88)

i=1

σiΦ (θ(Bi))

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

H



(cid:34)

 = E
σ

sup
θ∈Θ

m
(cid:88)

i,j=1

(cid:35)

σiσjK(θ)
ij

.

(16)

We now derive an upper bound of the r.h.s. as follows.

28

For any c > 0,

(cid:32)

(cid:34)

(cid:35)(cid:33)

σiσjK(θ)
ij

m
(cid:88)

i,j=1

exp

c E
σ

sup
θ∈Θ
(cid:32)

≤ E
σ

(cid:34)

(cid:34)

exp

(cid:33)(cid:35)

σiσjK(θ)
ij

m
(cid:88)

i,j=1

c sup
θ∈Θ

(cid:32)

exp

c

m
(cid:88)

σiσjK(θ)
ij

(cid:33)(cid:35)

(cid:34)

exp

i,j=1
(cid:32)
c

m
(cid:88)

i,j=1

(cid:33)(cid:35)

σiσjK(θ)
ij

≤

(cid:88)

θ∈Θ

E
σ

= E
σ

sup
θ∈Θ

The ﬁrst inequality is due to Jensen’s inequality, and the second inequality is due to the fact
that the supremum is bounded by the sum. By using the symmetry property of K(θ), we
have (cid:80)m

ij = σ(cid:62)K(θ)σ, which is rewritten as

i,j=1 σiσjK(θ)

(cid:62)σK(θ)σ = (cid:62)((cid:62)Vσ)






λ(θ)
1

0



0

. . .

λ(θ)
m


 (cid:62)Vσ,

1 ≥ · · · ≥ λ(θ)

where λ(θ)
m ≥ 0 are the eigenvalues of K(θ) and V = (v1, . . . , vm) is the
orthonormal matrix such that vi is the eigenvector that corresponds to the eigenvalue λi.
By the reproductive property of Gaussian distribution, (cid:62)Vσ obeys the same Gaussian
distribution as well. So,

(cid:88)

θ∈Θ
(cid:88)

θ∈Θ

(cid:88)

θ∈Θ
(cid:88)

θ∈Θ
(cid:88)

θ∈Θ

(cid:88)

θ∈Θ

=

=

=

=

=

(cid:34)

(cid:32)
c

m
(cid:88)

exp

i,j=1

(cid:33)(cid:35)

σiσjK(θ)
ij

(cid:104)

exp

(cid:16)

c(cid:62)σK(θ)σ

(cid:17)(cid:105)

(cid:34)

(cid:32)
c

m
(cid:88)

exp

λ(θ)
k ((cid:62)vkσ)2

(cid:33)(cid:35)

E
σ

E
σ

E
σ

k=1
(cid:16)

(cid:104)

Πm

exp

k=1 E
σk
(cid:18)(cid:90) ∞

Πm

k=1

−∞

(cid:32)(cid:90) ∞

−∞

Πm

k=1

cλ(θ)

k σ2

k

(cid:17)(cid:105)

(replace σ = (cid:62)vkσ)

(cid:16)

exp

cλ(θ)

(cid:19)

k σ2(cid:17) exp(−σ2)
√
(cid:33)

2π

dσ

exp(−(1 − cλ(θ)
√

k )σ2)

dσ

.

2π

29

Now we replace σ by σ(cid:48) =

(cid:113)

1 − cλ(θ)

k σ. Since dσ(cid:48) =

(cid:113)

1 − cλ(θ)

k dσ, we have:

(cid:90) ∞

−∞

exp(−(1 − cλ(θ)
√

k )σ2)

2π

dσ =

1
√
2π

(cid:90) ∞

−∞

exp(−σ(cid:48)2)
(cid:113)

1 − cλ(θ)
k

dσ(cid:48)

=

1

(cid:113)

1 − cλ(θ)
k

.

Now, applying the inequality that
becomes

1√
1−x ≤ 1 + 2(

√

2 − 1)x for 0 ≤ x ≤ 1

2, the bound

(cid:32)

(cid:34)

exp

c E
σ

sup
θ∈Θ

(cid:35)(cid:33)

m
(cid:88)

σiσjK(θ)
ij

(cid:88)

≤

Πm

k=1

(cid:16)

θ∈Θ

i,j=1
√

1 + 2(

2 − 1)cλ(θ)

k + 2λ1

(cid:17)

.

(17)

1
Further, taking logarithm, dividing the both sides by c, letting c =
2 maxk λ(θ)
k
ﬁx θ = θ∗ such that θ∗ maximizes (17), and applying ln(1 + x) ≤ x, we get:

= 1/(2λ(θ)

1 ),

(cid:34)

E
σ

sup
θ∈Θ

m
(cid:88)

i,j=1

(cid:35)

σiσjK(θ∗)

ij

√

2 − 1)

≤ (

m
(cid:88)

k=1

k + 2λ(θ∗)
λ(θ∗)

1

ln |Θ|

√

√

= (

≤ (

2 − 1)(cid:62)(K(θ∗)) + 2λ(θ∗)
2 − 1)mR2 + 2mR2 ln |Θ|,

1

ln |Θ|

(18)

where the last inequality holds since λ(θ∗)
tion (15) and (18), we have:

1 = (cid:107)K(θ∗)(cid:107)2 ≤ m(cid:107)K(θ)(cid:107)max ≤ R2. By Equa-

GS(H) ≤

(cid:34)

(cid:118)
(cid:117)
(cid:117)
(cid:116)E
σ

1
m

m
(cid:88)

i,j=1

sup
θ∈Θ

(cid:35)

σiσjK(θ)
ij

√

(cid:113)
(

R

≤

2 − 1) + 2 ln |Θ|

.

√

m

Thus, it sufﬁces to bound the size |Θ|. The basic idea to get our bound is the following
geometric analysis. Fix any i ∈ [m] and consider points {Φ(x) | x ∈ Bi}. Then, we

30

deﬁne equivalence classes of u such that θu(i) is in the same class, which deﬁne a Voronoi
diagram for the points {Φ(x) | x ∈ Bi}. Note here that the similarity is measured by
the inner product, not a distance. More precisely, let {Vi(x) | x ∈ Bi} be the Voronoi
diagram, each of the region is deﬁned as Vi(x) = {u ∈ H | θu(Bi) = x} Let us consider
the set of intersections (cid:84)
i∈[m] Vi(xi) for all combinations of (x1, . . . , xm) ∈ B1 × · · · × Bm.
The key observation is that each non-empty intersection corresponds to a mapping θu ∈ Θ.
Thus, we obtain |Θ| = (the number of intersections (cid:84)
i∈[m] Vi(xi)). In other words, the size
of Θ is exactly the number of rooms deﬁned by the intersections of m Voronoi diagrams
V1, . . . , Vm. From now on, we will derive upper bound based on this observation.

Lemma 4

|Θ| = O(|PS|2d∗

Φ,S ).

Proof We will reduce the problem of counting intersections of the Voronoi diagrams to
that of counting possible labelings by hyperplanes for some set. Note that for each neigh-
boring Voronoi regions, the border is a part of hyperplane since the closeness is deﬁned in
terms of the inner product. Therefore, by simply extending each border to a hyperplane,
we obtain intersections of halfspaces deﬁned by the extended hyperplanes. Note that, the
size of these intersections gives an upper bound of intersections of the Voronoi diagrams.
More precisely, we draw hyperplanes for each pair of points in Φ(PS) so that each point
on the hyperplane has the same inner product between two points. Note that for each pair
Φ(z), Φ(z(cid:48)) ∈ PS, the normal vector of the hyperplane is given as Φ(z) − Φ(z(cid:48)) (by ﬁx-
ing the sign arbitrary). Thus, the set of hyperplanes obtained by this procedure is exactly
(cid:1), which is at most |PS|2. Now, we consider a “dual”
Φdiﬀ(PS). The size of Φdiﬀ(PS) is (cid:0)|PS |
space by viewing each hyperplane as a point and each point in U as a hyperplane. Note that
points u (hyperplanes in the dual) in an intersection give the same labeling on the points in
the dual domain. Therefore, the number of intersections in the original domain is the same
as the number of the possible labelings on Φdiﬀ(PS) by hyperplanes in U . By the classical
Sauer’s Lemma and the VC dimension of hyperplanes [see, e.g., Theorem 5.5 in 28]), the
size is at most O((|PS|2)d∗

Φ,S ).

2

Theorem 4

(i) For any Φ, |Θ| = O(|PS|8(R/µ∗)2).

(ii) if X ⊆ R(cid:96) and Φ is the identity mapping over PS, then |Θ| = O(|PS|min{8(R/µ∗)2,2(cid:96)}}).

(iii) if X ⊆ R(cid:96) and Φ satisﬁes that (cid:104)Φ(z), Φ(x)(cid:105) is monotone decreasing with respect to
(cid:107)z − x(cid:107)2 (e.g., the mapping deﬁned by the Gaussian kernel) and U = {Φ(z) | z ∈
X ⊆ R(cid:96), (cid:107)Φ(z)(cid:107)H ≤ 1}, then |Θ| = O(|PS|min{8(R/µ∗)2,2(cid:96)}}).

(i) We follow the argument in Lemma 4. For the set of classiﬁers F = {f :
Proof
Φdiﬀ(PS) → {−1, 1} | f = sign((cid:104)u, v(cid:105)), (cid:107)u(cid:107)H ≤ 1, minv∈Φdiﬀ (PS ) |(cid:104)u, v(cid:105)| = µ}, its VC

31

dimension is known to be at most R2/µ2 for Φdiﬀ(PS) ⊆ {v | (cid:107)v(cid:107)H ≤ 2R} [see, e.g., 28]).
By the deﬁnition of µ∗, for each intersection given by hyperplanes, there always exists a
point u whose inner product between each hyperplane is at least µ∗. Therefore, the size
of the intersections is bounded by the number of possible labelings in the dual space by
U (cid:48)(cid:48) = {u ∈ H | (cid:107)u(cid:107)H ≤ 1, minv∈Φdiﬀ (PS ) |(cid:104)u, v(cid:105)| = µ∗}. Thus, we obtain that d∗
Φ,S is at
most 8(R/µ∗)2 and by Lemma 4, we complete the proof of case (i).

(ii) In this case, the Hilbert space H is contained in R(cid:96). Then, by the fact that VC

dimension d∗

Φ,S is at most (cid:96) and Lemma 4, the statement holds.

(iii) If (cid:104)Φ(z), Φ(x)(cid:105) is monotone decreasing for (cid:107)z − x(cid:107), then the following holds:

arg max
x∈X

(cid:104)Φ(z), Φ(x)(cid:105) = arg min
x∈X

(cid:107)z − x(cid:107)2.

Therefore, maxu:(cid:107)u(cid:107)H=1(cid:104)u, Φ(x)(cid:105) = (cid:107)Φ(x)(cid:107)H, where u = Φ(x)
(cid:107)Φ(x)(cid:107)H . It indicates that the
number of Voronoi cells made by V (x) = {z ∈ R(cid:96) | z = arg maxx∈B(z · x)} corresponds
to the ˆV (x) = {Φ(z) ∈ H | z = arg maxx∈B(cid:104)Φ(z), Φ(x)(cid:105)}. Then, by following the same
argument for the linear kernel case, we get the same statement.

Now we are ready to prove Theorem 2.
Proof [Proof of Theorem 2] By using Lemma 1, and 2, we obtain the generalization bound
in terms of the Gaussian complexity of H. Then, by applying Lemma 3 and Theorem 4,
we complete the proof.

B.1 Hyper-parameter tuning for time-series classiﬁcation

. In the experiment for time series classiﬁcation, we roughly tuned ν and σ2 of the Gaussian
kernel. As we mentioned before, we need high computation time when learning very large
time series. The main computational cost is to iteratively solve weak learning problems
by using an LP (or QP) solver. The number of constraints of the optimization problem
(9) depends on the total number of instances in negative bags. Therefore, in the hyper-
parameter tuning phase, we ﬁnish solving each weak learning problem by obtaining the
solution of the optimization problem (11). Using the rough weak learning problem, we
tuned ν and σ through a grid search via three runs of 3-fold cross validation.

32

