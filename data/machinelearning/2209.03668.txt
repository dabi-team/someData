PREDICT+OPTIMIZE FOR PACKING AND COVERING LPS WITH
UNKNOWN PARAMETERS IN CONSTRAINTS

Xinyi Hu
Department of Computer Science and Engineering
The Chinese University of Hong Kong
Hong Kong
xyhu@cse.cuhk.edu.hk

Jasper C.H. Lee
Department of Computer Sciences
Institute for Foundations of Data Science
University of Wisconsin–Madison
WI, USA
jasper.lee@wisc.edu

Jimmy H.M. Lee
Department of Computer Science and Engineering
The Chinese University of Hong Kong
Hong Kong
jlee@cse.cuhk.edu.hk

ABSTRACT

Predict+Optimize is a recently proposed framework which combines machine learning and con-
strained optimization, tackling optimization problems that contain parameters that are unknown at
solving time. The goal is to predict the unknown parameters and use the estimates to solve for an
estimated optimal solution to the optimization problem. However, all prior works have focused on
the case where unknown parameters appear only in the optimization objective and not the constraints,
for the simple reason that if the constraints were not known exactly, the estimated optimal solution
might not even be feasible under the true parameters. The contributions of this paper are two-fold.
First, we propose a novel and practically relevant framework for the Predict+Optimize setting, but
with unknown parameters in both the objective and the constraints. We introduce the notion of a
correction function, and an additional penalty term in the loss function, modelling practical scenarios
where an estimated optimal solution can be modiﬁed into a feasible solution after the true parameters
are revealed, but at an additional cost. Second, we propose a corresponding algorithmic approach for
our framework, which handles all packing and covering linear programs. Our approach is inspired by
the prior work of Mandi and Guns, though with crucial modiﬁcations and re-derivations for our very
different setting. Experimentation demonstrates the superior empirical performance of our method
over classical approaches.

2
2
0
2

p
e
S
8

]
I

A
.
s
c
[

1
v
8
6
6
3
0
.
9
0
2
2
:
v
i
X
r
a

1

Introduction

Constrained optimization problems are ubiquitous in daily life, yet, they often contain parameters that are unknown at
solving time. As an example, retail merchants wish to optimize their stocking of products in terms of revenue and cost,
and yet the precise demands for each product are not known ahead of time. The goal, then, is to 1) predict the unknown
parameters and 2) solve the optimization problem using these predicted parameters, in the hopes that the estimated
solution is good even under the true parameters revealed later on. The classical approaches would learn a predictor
for these unknown parameters using losses like the mean squared error, which are independent of the optimization at
hand. However, a small error for the predicted parameters in the parameter space does not necessarily guarantee a high
solution quality evaluated under the true parameters. The recent framework of Predict+Optimize by Elmachtoub and
Grigas [1, 2] proposes to instead use the more effective regret function as the loss function, capturing the difference in
objective between the estimated and true optimal solutions, both evaluated using the true parameters.

 
 
 
 
 
 
Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints

A number of prior works [3, 4, 5] have developed algorithmic implementations of this framework on a variety of
classes of optimization problems. Yet, all the prior works have focused on the case where only the optimization
objective contains unknown parameters, and never the constraints. This is for a simple technical reason: if we had used
some predicted parameters to solve for an estimated solution, the solution might not even be feasible under the true
parameters! On the other hand, some application scenarios allow for post-hoc correction of an estimated solution into
a feasible solution after the true parameters are revealed, potentially at additional cost or penalty. Using the product
stocking example again, a hard constraint is the available warehouse space, which needs to be predicted, depending on
how well the already-bought products sell. If a merchant buys in excess of the available space, they always have the
option to throw away some of the newly-bought products, which would involve 1) paying a disposal company as well
as 2) losing out on the proﬁt of the thrown-away products as a “penalty".

The contributions of this paper are two-fold. First, we capture the above intuition and signiﬁcantly generalize the
Predict+Optimize framework (Section 3), allowing us to address optimization problems with unknown parameters
in both the objective and the constraints. Speciﬁcally, we introduce the notion of a correction function, and modify
the deﬁnition of regret to take into account the post-doc correction of a solution, and the associated cost and penalty.
Second, we propose an algorithmic implementation for this novel framework as applied to packing and covering linear
programs (LPs), a well-studied and signiﬁcant class of practically relevant optimization problems. We give a general
correction function for packing and covering LPs, and demonstrate how to learn a predictor in this setting using an
approach inspired by the work of Mandi and Guns [6]. We also apply our approach on 3 benchmarks to demonstrate the
superior empirical performance of our method over classic learning algorithms1.

2 Background

In this section, we describe the formulation of Predict+Optimize as it appears in prior works, on problems with unknown
parameters appearing only in the objective. The theory is stated in terms of minimization but applies of course also to
maximization, upon appropriate negation.

An optimization problem P is deﬁned as ﬁnding

x∗ = arg minx obj(x) s.t. C(x)
where x ∈ Rd is a vector of decision variables, obj : Rd → R is a function mapping x to a real objective value which is
to be minimized, and C(x) is a set of constraints over x. We say x∗ is an optimal solution and obj(x∗) is the optimal
value.

In prior works, a parameterized optimization problem (Para-OP) P (θ) extends an optimization problem P as:

x∗(θ) = arg minx obj(x, θ) s.t. C(x)
where θ ∈ Rt is a vector of parameters. The objective depends on θ, and note that the constraints do not (in prior
works). When the parameters are known, a Para-OP is just an optimization problem.
In Predict+Optimize [1, 2], the true parameters θ ∈ Rt for a Para-OP are unknown at solving time, and estimated
parameters ˆθ are used instead. Suppose that for each parameter, there are m relevant features. A learner is given n
observations forming a training data set {(A1, θ1), . . . , (An, θn)}, where Ai ∈ Rt×m is a feature matrix for θi, and the
task is to learn a prediction function f : Rt×m → Rt predicting parameters ˆθ = f (A) from any feature matrix A.
The key aspect of Predict+Optimize is to measure quality of the estimated parameters ˆθ using the regret function as the
loss function. The regret is the objective difference between the true optimal solution x∗(θ) and the estimated solution
x∗(ˆθ) under the true parameters θ. Formally, the regret function Regret(ˆθ, θ) : Rt × Rt → R≥0 is:

Regret(ˆθ, θ) = obj(x∗(ˆθ), θ) − obj(x∗(θ), θ)
where obj(x∗(ˆθ), θ) is the estimated optimal value and obj(x∗(θ), θ) is the true optimal value. Following the empirical
risk minimization principle, prior learning methods [4] aim to return the prediction function to be the function f from
the set of models F attaining the smallest average regret over the training data:

f ∗ = arg minf ∈F

1
n

(cid:80)n

i=1 Regret(f (Ai), θi)

(1)

Mandi and Guns [6] proposed to use a (feedforward) neural network to predict the unknown parameters from features.
The standard approach to training neural networks is via gradient descent using the backpropagation algorithm, in order

1We allow estimated solutions to be corrected also for these classic learning algorithms, but the training itself just uses the

original loss function, which is oblivious to any potential correction.

2

Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints

to learn the weight on each edge of the network. Concretely, ﬁxing a training feature matrix A and a corresponding true
parameter vector θ, for each edge e on the network with weight we, we need to compute the derivative dRegret
. Using
the multivariate chain rule, the derivative can be decomposed as follows:

dwe

dRegret(ˆθ, θ)
dwe

=

∂Regret(ˆθ, θ)
∂x∗(ˆθ)

∂x∗(ˆθ)
∂ ˆθ

∂ ˆθ
∂we

(2)

where ∂Regret(ˆθ,θ)
is
a vector with the same length as the number of unknown parameters. The right hand side of the Equation 2 is to be
interpreted as a matrix product.

is a vector with the same length as the decision variable vector x∗, ∂x∗(ˆθ)
∂ ˆθ

is a matrix, and ∂ ˆθ
∂we

∂x∗(ˆθ)

On the right hand side, the ﬁrst term is the gradient of the regret with respect to the estimated optimal solution. In
the context of linear programs, this is trivial to compute since the objective function is linear in x∗. The third term,
on the other hand, is the gradient of the estimated parameters with respect to the neural network edge weight, which
can be computed efﬁciently using the standard backpropagation algorithm [7]. What remains is the second term ∂x∗
:
∂ ˆθ
the derivative of each decision variable with respect to each predicted parameter. In general, these derivatives do
not exist for linear programs. Mandi and Guns [6] thus proposed to use an interior-point LP solver: it generates a
sequence of modiﬁed programs, with logarithmic barrier terms of decreasing weights introduced into the objective.
Upon termination of the solver at an approximate optimum of the LP, the interior-point solver returns the approximate
optimum as well as auxiliary information such as the weight of the barrier term at termination, all of which are used by
Mandi and Guns to extract some gradient information related to the original problem. Due to page limits, we do not
present their approach in any detail here, but instead refer the reader directly to our new method (Section 4), which is a
substantial modiﬁcation.

3 Predict+Optimize for Unknown Constraint Parameters

We now generalize the framework in the previous section to include unknown parameters also in constraints.

The notion of a Para-OP can be easily extended to allow unknown parameters in both the objective and constraints:
x∗(θ) = arg minx obj(x, θ) s.t. C(x, θ)

Note that in this extension, both the objective and constraints depend on the unknown parameters θ.

When constraints contain unknown parameters, the feasible region is only approximated at solving time, and the
estimated solution may be infeasible under the true parameters. Fortunately, in some applications, once the true
parameters are revealed, there might be possible ways for us to correct an infeasible solution into a feasible one.
This can be formalized as a correction function, which takes an estimated solution x∗(ˆθ) and true parameters θ and
corr(ˆθ, θ) that is feasible under θ. The choice of correction function will be problem and
returns a corrected solution x∗
application-speciﬁc; indeed, the space of correction functions depends on the situation. The goal then is to choose a
correction function that generally loses the least amount in the objective from the correction.
Example 1. Consider a simpliﬁed version of the product stocking problem. There are 4 divisible products (e.g. oil and
rice). Each product i has a per-unit revenue ri and a per-unit weight wi, and there is a maximum of Mi units available
for sourcing. The goal is to make an order of xi units of item i, so as to maximize (cid:80)4
i=1 ri · xi subject to the constraint
(cid:80)4
i=1 wi · xi ≤ C, where r = [13, 14, 10, 11] and w = [5, 3, 4, 9] are two arrays representing the per-unit revenues
and weights of the products, as well as the constraint that xi ≤ Mi for all i. However, the available capacity C when
the products arrive is unknown at solving time, depending on the volume of sales between the orders being made and
the arrival of the products.

In Example 1, the products are selected based on an estimated warehouse capacity, but the prediction might be an
overestimate. One trivial correction function is to throw out the entire order, which is not useful. A more useful
correction function is to throw out some of each product to ﬁt them into the actually available capacity.

While application scenarios may allow for post-hoc correction of an estimated solution, such correction may incur a
penalty. A penalty function P en(x∗(ˆθ) → x∗
corr(ˆθ, θ)) takes an estimated solution x∗(ˆθ) and the corrected solution
corr(ˆθ, θ) and returns a non-negative penalty. In Example 1, the correction incurs both 1) logistical costs for removing
x∗
items and 2) costs of having paid for these products.
We are now ready to deﬁne the notion of post-hoc regret P Reg(ˆθ, θ) with respect to correction function x∗
and penalty function P en:

corr(ˆθ, θ)

P Reg(ˆθ, θ) = obj(x∗

corr(ˆθ, θ), θ) − obj(x∗(θ), θ) + P en(x∗(ˆθ) → x∗

corr(ˆθ, θ))

(3)

3

Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints

Given a correction function and a penalty, we will follow Mandi and Guns [6] and train a neural network to minimize
the empirical post-hoc regret. In the rest of the paper, we will study the application of this framework to packing and
covering linear programs. We will propose a generic correction function that should be applicable generally, and show
how we can learn a neural network that performs well under the post-hoc regret.

4 Predict+Optimize on Packing LPs

In this section, we derive how we can train a neural network to predict unknown parameters in both the objective and
constraints of a packing LP, under the new Predict+Optimize framework proposed in Section 3.

Consider a packing LP in the standard form:

x∗ = arg max

c(cid:62)x s.t. Gx ≤ h, x ≥ 0

x

(4)

with decision variables x ∈ Rd and problem parameters c ∈ Rd, G ∈ Rp×d
general setting where all the problem parameters c, G, and h can be unknown.

≥0 , h ∈ Rp

≥0. Here, we consider the most

We stated in Section 3 that the choice of a correction function generally depends on the speciﬁc problem and application.
On the other hand, packing LPs have a lot of structure we can exploit. For example, the all 0s solution is always
feasible. We propose the following generic correction function, which is generally applicable for packing LPs: given
an uncorrected solution x∗, ﬁnd the largest λ ∈ [0, 1] such that λx∗ satisﬁes the constraints under the true parameters.
This can be formalized as follows:

corr(ˆθ, θ = (c, G, h)) = λx∗(ˆθ)
x∗
where λ = max{λ ∈ [0, 1] | G(λx∗(ˆθ)) ≤ h}

(5)

We also need to decide on a penalty function, which again is generally problem and application-speciﬁc. For simplicity
and for wide applicability, in the rest of the paper we will assume that the penalty function is linear, in the sense
that the penalty for the correction is the dot product between 1) the difference between the corrected and uncorrected
solution vectors and 2) a vector of penalty factors. Due to scaling reasons, we express this vector of penalty factors in
units of the objective c, that is, the penalty vector is σ ◦ c where ◦ is the Hadamard/entrywise product, and σ ≥ 0 is
corr(ˆθ, θ)) =
a non-negative tunable vector. Then, the penalty function P en is formally deﬁned as P en(x∗(ˆθ) → x∗
(σ ◦ c)(cid:62)(x∗ − x∗

corr).

With the above choices of correction and penalty, we can now write down the simpliﬁed form of post-hoc regret for
packing LPs. Note that, since packing LPs are maximization problems instead of minimization, the following has some
sign differences from Equation 3.

P Reg(ˆθ, θ) = c(cid:62)(x∗(θ) − x∗

corr(ˆθ, θ)) + (σ ◦ c)(cid:62)(x∗(ˆθ) − x∗

corr(ˆθ, θ))

(6)

where σ ∈ Rd

≥0.

Following the approach of Mandi and Guns [6], brieﬂy described in Section 2, we use a neural network (of various
architectures depending on the precise problem) to predict the parameters, before feeding the parameters into the
interior-point LP solver of Mandi and Guns. This interior point solver iteratively generates a sequence of relaxations to
the LP, into problems of the form

arg maxx c(cid:62)x + µ[(cid:80)d

i=1 ln(xi) + (cid:80)p

i=1 ln(hi − G(cid:62)

i x)]

for a sequence of decreasing non-negative µ. Upon termination, we retrieve a solution x which is approximately the
optimum of the original LP, as well as the value of µ last used.

We derive how, using the solution x and the barrier weight µ, we can compute the relevant (approximations of)
derivatives in order to train the neural network via gradient descent. Using the law of total derivative, we get

dP Reg(ˆθ, θ)
dwe

=

∂P Reg(ˆθ, θ)
∂x∗

∂x∗(ˆθ)
∂ ˆθ

corr

corr

∂x∗

∂x∗

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)x∗
(cid:12)
(cid:12)
(cid:12)x∗
∂x∗
∂x∗
= σ ◦ c. The term ∂ ˆθ
∂we

corr

(cid:12)
(cid:12)
(cid:12)x∗

On the right hand side, the terms ∂P Reg(ˆθ,θ)
−(1 + σ) ◦ c and ∂P Reg(ˆθ,θ)
by the standard backpropagation algorithm [7]. Therefore, in the remainder of this section, we show how to compute
(approximations of) ∂x∗
∂x∗

are straightforward from (6): ∂P Reg(ˆθ,θ)

relates only to the neural network and is handled directly

and ∂P Reg(ˆθ,θ)

(cid:12)
(cid:12)
(cid:12)x∗

and ∂x∗(ˆθ)
∂ ˆθ

∂x∗

∂x∗

=

corr

corr

corr

corr

.

(cid:12)
(cid:12)
(cid:12)x∗

∂ ˆθ
∂we

+

∂P Reg(ˆθ, θ)
∂x∗

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)x∗

corr

∂x∗(ˆθ)
∂ ˆθ

∂ ˆθ
∂we

4

Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints

Computing ∂x∗
the LP solver. We use the law of total derivative again to decompose the term:

∂x∗ . The term ∂x∗

∂x∗

corr

corr

is determined solely by the correction function (5), and has nothing to do with

c (ˆθ, θ)
∂x∗
∂x∗(ˆθ)

=

∂x∗

c (ˆθ, θ)
∂λ

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)x∗

∂λ
∂x∗(ˆθ)

+

c (ˆθ, θ)
∂x∗
∂x∗(ˆθ)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)λ

c (ˆθ,θ)
∂λ

= x∗(ˆθ) and ∂x∗

(cid:12)
Observe that ∂x∗
(cid:12)
(cid:12)x∗
in the following lemma.
corr(ˆθ, θ) = λx∗(ˆθ) be
Lemma 1. Let x∗(ˆθ) denote the estimated optimal solution of the packing LP shown in (4), x∗
the correction function shown in (5). Suppose that at the optimal λ of (5), the ith inequality constraint Gi is tight,
namely G(cid:62)

= λI (I is an identity matrix). It remains to derive

i (λx∗(ˆθ)) = hi. Then, we have

c (ˆθ,θ)
∂x∗(ˆθ)

, captured

∂λ
∂x∗(ˆθ)

(cid:12)
(cid:12)
(cid:12)λ

As a corollary, we have

∂λ
∂x∗(ˆθ)

= −

λ
i x∗(ˆθ)

G(cid:62)

G(cid:62)
i .

∂x∗

corr(ˆθ, θ)
∂x∗(ˆθ)

=

−λ
i x∗(ˆθ)

G(cid:62)

x∗(ˆθ)G(cid:62)

i + λI.

Proof. Since the ith inequality constraint Gi is tight, we have:

λ

n
(cid:88)

j=1

Gijx∗(ˆθ)j = hi

(7)

The implicit differentiation of Equation 11 with respect to x∗(ˆθ) is:

∂
∂x∗(ˆθ)

(λ

n
(cid:88)

j=1

Gijx∗(ˆθ)j) =

∂hi
∂x∗(ˆθ)

Since x∗(ˆθ) is a vector, differentiation on the lth variable is:

where

∂
∂x∗(ˆθ)l

(λ

n
(cid:88)

j=1

Gijx∗(ˆθ)j) =

∂hi
∂x∗(ˆθ)l

∂
∂x∗(ˆθ)l

(λ

n
(cid:88)

j=1

Gijx∗(ˆθ)j) =

∂λ
∂x∗(ˆθ)l

G(cid:62)

i x∗(ˆθ) + λGil

Since

∂hi
∂x∗(ˆθ)l

= 0, we can obtain:

corr(ˆθ,θ)
∂λ

Since ∂x∗
predicted optimal solution is:

= x∗(ˆθ), ∂x∗

corr(ˆθ,θ)
∂x∗(ˆθ)

∂λ
∂x∗(ˆθ)

= −

λ
i x∗(ˆθ)

G(cid:62)

G(cid:62)
i .

(cid:12)
(cid:12)
(cid:12)λ

= λI, the gradient of the corrected optimal solution with respect to the

∂x∗

corr(ˆθ, θ)
∂x∗(ˆθ)

=

=

∂x∗

corr(ˆθ, θ)
∂λ

∂λ
∂x∗(ˆθ)

+

∂x∗

corr(ˆθ, θ)
∂x∗(ˆθ)

(cid:12)
(cid:12)
(cid:12)λ

−λ
i x∗(ˆθ)

G(cid:62)

x∗(ˆθ)G(cid:62)

i + λI.

5

Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints

Approximating ∂x∗(ˆθ)
∂ ˆθ
the following form:

. Recall that the interior point solver of Mandi and Guns solves a sequence of relaxations of

x∗ = arg max

c(cid:62)x + µ

x

(cid:34) d

(cid:88)

i=1

ln(xi) +

(cid:35)

ln(hi − G(cid:62)

i x)

p
(cid:88)

i=1

(8)

i=1 ln(xi) + (cid:80)p

The term µ[(cid:80)d
i x)] is also known as a logarithmic barrier term, which is commonly used
in interior-point based solving methods [8]. At termination, we get the values of x∗ and µ. We will use these values, as
well as Equation (13), to approximate the gradient information ∂x∗(ˆθ)
∂ ˆθ

i=1 ln(hi − G(cid:62)

.

In the context of the packing LP, the unknown parameter ˆθ may either be c, G or h. The case of c has already been
derived by Mandi and Guns [6] (see Appendix A.1 and A.2 in their paper). The following two lemmas captures the
other two cases.
i=1 ln(xi)) + µ((cid:80)p
Deﬁne the notation f (x, c, G, h) = c(cid:62)x + µ((cid:80)d
i=1 ln(hi − Gix)). Then, Problem (13) can be
expressed as ﬁnding x∗ = arg maxx f (x, c, G, h). Using this notation, we write down the following two lemmas on
computing ∂x∗
Lemma 2. Consider the LP relaxation (13), deﬁning x∗ as a function of c, G and h. Then, under this deﬁnition of x∗,

∂G approximately.

∂h and ∂x∗

where fxx denotes the matrix of second derivatives of f with respect to different coordinates of x, and similarly for
other subscripts, and explicitly:

∂x∗
∂h

= −fxx(x∗)−1fhx(x∗)

fxkxj (x) =

and

(cid:26)−µx−2
−µ (cid:80)p

j − µ (cid:80)p
i=1 G2
i=1 GijGik/(hi − G(cid:62)

ij/(hi − G(cid:62)
i x)2

i x)2

j = k
j (cid:54)= k

fh(cid:96)xj (x) = µG(cid:96)j/(h(cid:96) − G(cid:62)

(cid:96) x)2

Proof. Since x∗ = arg maxx f (x, c, G, h) is an optimum, fx(x∗) = ∂f (x)

∂x

(cid:12)
(cid:12)
(cid:12)x=x∗

= 0. Thus,

By the chain rule,

∂
∂h

fx(x∗) = 0

fx(x∗) = fhx(x∗) + fxx(x∗)

∂
∂h

∂x∗
∂h

Rearranging the aboved equation, we can obtain:
∂x∗
∂h

= −fxx(x∗)−1fhx(x∗)

where

and

fxkxj (x) =

(cid:26) −µx−2

j − µ (cid:80)p

−µ (cid:80)p

i=1 G2
i=1 GijGik/(hi − G(cid:62)

ij/(hi − G(cid:62)

i x)2,

i x)2,

j = k

j (cid:54)= k

fh(cid:96)xj (x) = µG(cid:96)j/(h(cid:96) − G(cid:62)

(cid:96) x)2

Lemma 3. Consider the LP relaxation (13), deﬁning x∗ as a function of c, G and h. Then, under this deﬁnition of x∗,

where fxx denotes the matrix of second derivatives of f with respect to different coordinates of x, and similarly for
other subscripts, and explicitly:

∂x∗
∂G

= −fxx(x∗)−1fGx(x∗)

fxkxj (x) =

(cid:26)−µx−2
−µ (cid:80)p

j − µ (cid:80)p
i=1 G2
i=1 GijGik/(hi − G(cid:62)

ij/(hi − G(cid:62)
i x)2

i x)2

j = k
j (cid:54)= k

and

fG(cid:96)qxj (x) =

(cid:26)−µG(cid:96)jxq/(h(cid:96) − G(cid:62)
−µG(cid:96)jxq/(h(cid:96) − G(cid:62)

(cid:96) x)2 − µ/(h(cid:96) − G(cid:62)
(cid:96) x)2

(cid:96) x)

q = j
q (cid:54)= j.

6

Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints

Proof. Since x∗ = arg maxx f (x, c, G, h) is an optimum, fx(x∗) = ∂f (x)

∂x

(cid:12)
(cid:12)
(cid:12)x=x∗

= 0. Thus,

By the chain rule,

∂
∂G

fx(x∗) = 0

∂
∂G

fx(x∗) = fGx(x∗) + fxx(x∗)

∂x∗
∂G

Rearranging the aboved equation, we can obtain:

∂x∗
∂G

= −fxx(x∗)−1fGx(x∗)

where

and

fxkxj (x) =

(cid:26) −µx−2

j − µ (cid:80)p

−µ (cid:80)p

i=1 G2
i=1 GijGik/(hi − G(cid:62)

ij/(hi − G(cid:62)

i x)2,

i x)2,

j = k

j (cid:54)= k

fG(cid:96)qxj (x) =

(cid:26) −µG(cid:96)jxq/(h(cid:96) − G(cid:62)

−µG(cid:96)jxq/(h(cid:96) − G(cid:62)

(cid:96) x)2 − µ/(h(cid:96) − G(cid:62)
(cid:96) x)2,

(cid:96) x),
q (cid:54)= j.

q = j

We end this section with a remark that the LP solver of Mandi and Guns [6] in fact returns more information than just x
and µ. In their work, they start not with (13) but with the homogeneous self-dual (HSD) formulation of the original
LP, involving the extra information returned by the solver, and perform derivative calculations similar in spirit to our
lemmas in this section. However, in our context of unknown G and h, if we also tried using the HSD formulation for
gradient calculations, we would end up with derivatives that are degenerate. For this reason, we have opted to use the
simpler Equation (13) which, as we demonstrate in the experiments in Section 6, appears to work well in practice.

5 Predict+Optimize on Covering LPs

Covering LPs are closely related to packing LPs—in fact, they are the duals of each other. Consider a covering LP in
standard form:

x∗ = arg min

c(cid:62)x s.t. Gx ≥ h, x ≥ 0

(9)

x

with decision variables x ∈ Rd and problem parameters c ∈ Rd, G ∈ Rp×d, h ∈ Rp. We are again in the general
setting where all the problem parameters c, G, and h can be unknown.

Performing Predict+Optimize on covering LPs is essentially the same as in the previous section, up to some sign
changes to account for changed inequality directions and minimization vs maximization. The only non-trivial difference
is the need to change the correction function. Instead of scaling down an uncorrected solution for feasibility, we will
scale up in covering LPs, deﬁned formally as follows:

corr(ˆθ, θ = (c, G, h)) = λx∗(ˆθ)
x∗
where λ = min{λ ≥ 1 | G(λx∗(ˆθ)) ≥ h}

(10)

We use the same penalty function as in the packing LP case. The differentiation calculations from the last section apply
essentially verbatim to covering LPs apart from minor sign differences.
Lemma 4. Let x∗(ˆθ) denote the estimated optimal solution of the covering LP shown in (9), x∗
corr(ˆθ, θ) = λx∗(ˆθ) be
the correction function shown in (10). Suppose that at the optimal λ of (10), the ith inequality constraint Gi is tight,
namely G(cid:62)

i (λx∗(ˆθ)) = hi. Then, we have

As a corollary, we have

∂λ
∂x∗(ˆθ)

= −

λ
i x∗(ˆθ)

G(cid:62)

G(cid:62)
i .

∂x∗

corr(ˆθ, θ)
∂x∗(ˆθ)

=

−λ
i x∗(ˆθ)

G(cid:62)

x∗(ˆθ)G(cid:62)

i + λI.

7

Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints

Proof. Since the ith inequality constraint Gi is tight, we have:

λ

n
(cid:88)

j=1

Gijx∗(ˆθ)j = hi

(11)

The implicit differentiation of Equation 11 with respect to x∗(ˆθ) is:

∂
∂x∗(ˆθ)

(λ

n
(cid:88)

j=1

Gijx∗(ˆθ)j) =

∂hi
∂x∗(ˆθ)

Since x∗(ˆθ) is a vector, differentiation on the lth variable is:

where

∂
∂x∗(ˆθ)l

(λ

n
(cid:88)

j=1

Gijx∗(ˆθ)j) =

∂hi
∂x∗(ˆθ)l

∂
∂x∗(ˆθ)l

(λ

n
(cid:88)

j=1

Gijx∗(ˆθ)j) =

∂λ
∂x∗(ˆθ)l

G(cid:62)

i x∗(ˆθ) + λGil

Since

∂hi
∂x∗(ˆθ)l

= 0, we can obtain:

corr(ˆθ,θ)
∂λ

Since ∂x∗
predicted optimal solution is:

= x∗(ˆθ), ∂x∗

corr(ˆθ,θ)
∂x∗(ˆθ)

∂λ
∂x∗(ˆθ)

= −

λ
i x∗(ˆθ)

G(cid:62)

G(cid:62)
i .

(cid:12)
(cid:12)
(cid:12)λ

= λI, the gradient of the corrected optimal solution with respect to the

∂x∗

corr(ˆθ, θ)
∂x∗(ˆθ)

=

∂x∗

corr(ˆθ, θ)
∂λ

∂λ
∂x∗(ˆθ)

+

∂x∗

corr(ˆθ, θ)
∂x∗(ˆθ)

(cid:12)
(cid:12)
(cid:12)λ

= −

λ
i x∗(ˆθ)

G(cid:62)

x∗(ˆθ)G(cid:62)

i + λI.

Lemma 5. In the context of covering LP, consider the LP relaxation in the following form:

x∗ = arg min

c(cid:62)x − µ

x

(cid:34) d

(cid:88)

i=1

ln(xi) −

(cid:35)
i x − hi)

ln(G(cid:62)

p
(cid:88)

i=1

(12)

Deﬁning x∗ as a function of c, G and h. Then, under this deﬁnition of x∗,

∂x∗
∂h

= −fxx(x∗)−1fhx(x∗)

where fxx denotes the matrix of second derivatives of f with respect to different coordinates of x, and similarly for
other subscripts, and explicitly:

fxkxj (x) =

and

(cid:26) µx−2

j + µ (cid:80)p
µ (cid:80)p

i=1 G2
i=1 GijGik/(hi − G(cid:62)

ij/(hi − G(cid:62)

i x)2,

i x)2,

j = k

j (cid:54)= k

fh(cid:96)xj (x) = −µG(cid:96)j/(h(cid:96) − G(cid:62)

(cid:96) x)2

Proof. Since x∗ = arg minx f (x, c, G, h) is an optimum, fx(x∗) = ∂f (x)

∂x

(cid:12)
(cid:12)
(cid:12)x=x∗

= 0. Thus,

∂
∂h

fx(x∗) = 0

8

Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints

By the chain rule,

Rearranging the aboved equation, we can obtain:

∂
∂h

fx(x∗) = fhx(x∗) + fxx(x∗)

∂x∗
∂h

∂x∗
∂h

= −fxx(x∗)−1fhx(x∗)

where

and

fxkxj (x) =

(cid:26) µx−2

j + µ (cid:80)p
µ (cid:80)p

i=1 G2
i=1 GijGik/(hi − G(cid:62)

ij/(hi − G(cid:62)

i x)2,

i x)2,

j = k

j (cid:54)= k

fh(cid:96)xj (x) = −µG(cid:96)j/(h(cid:96) − G(cid:62)

(cid:96) x)2

Lemma 6. In the context of covering LP, consider the LP relaxation in the following form:

x∗ = arg min

c(cid:62)x − µ

x

(cid:34) d

(cid:88)

i=1

ln(xi) −

(cid:35)
i x − hi)

ln(G(cid:62)

p
(cid:88)

i=1

(13)

Deﬁning x∗ as a function of c, G and h. Then, under this deﬁnition of x∗,

∂x∗
∂G

= −fxx(x∗)−1fGx(x∗)

where fxx denotes the matrix of second derivatives of f with respect to different coordinates of x, and similarly for
other subscripts, and explicitly:

fxkxj (x) =

(cid:26) µx−2

j + µ (cid:80)p
µ (cid:80)p

i=1 G2
i=1 GijGik/(hi − G(cid:62)

ij/(hi − G(cid:62)

i x)2,

i x)2,

j = k

j (cid:54)= k

and

fG(cid:96)qxj (x) =

(cid:26) µG(cid:96)jxq/(h(cid:96) − G(cid:62)

µG(cid:96)jxq/(h(cid:96) − G(cid:62)

(cid:96) x)2 + µ/(h(cid:96) − G(cid:62)
(cid:96) x)2,

(cid:96) x),
q (cid:54)= j.

q = j

Proof. Since x∗ = arg maxx f (x, c, G, h) is an optimum, fx(x∗) = ∂f (x)

∂x

(cid:12)
(cid:12)
(cid:12)x=x∗

= 0. Thus,

By the chain rule,

∂
∂G

fx(x∗) = 0

∂
∂G

fx(x∗) = fGx(x∗) + fxx(x∗)

∂x∗
∂G

Rearranging the aboved equation, we can obtain:

∂x∗
∂G

= −fxx(x∗)−1fGx(x∗)

where

and

fxkxj (x) =

(cid:26) µx−2

j + µ (cid:80)p
µ (cid:80)p

i=1 G2
i=1 GijGik/(hi − G(cid:62)

ij/(hi − G(cid:62)

i x)2,

i x)2,

j = k

j (cid:54)= k

fG(cid:96)qxj (x) =

(cid:26) µG(cid:96)jxq/(h(cid:96) − G(cid:62)

µG(cid:96)jxq/(h(cid:96) − G(cid:62)

(cid:96) x)2 + µ/(h(cid:96) − G(cid:62)
(cid:96) x)2,

(cid:96) x),
q (cid:54)= j.

q = j

9

Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints

Model

Proposed

k-NN
RF

NN

Max ﬂow transportation
optimizer: optim.Adam;
learning rate: 5−6;
µ = 10−3; epochs=8

optimizer: optim.Adam;
learning rate: 10−3;
epochs=8

Hyperaprameters
Alloy production
optimizer: optim.Adam;
learning rate: 5−6;
µ = 10−3; epochs=8
k=5
n_estimator=100
optimizer: optim.Adam;
learning rate: 10−3;
epochs=8

Fractional knapsack
optimizer: optim.Adam;
learning rate: 5−6;
µ = 10−3; epochs=8

optimizer: optim.Adam;
learning rate: 10−3;
epochs=8

Table 1: Hyperparameters of the maximum ﬂow transportation, alloy production, and fractional knapsack problems.

PReg
POLSKA
USANet
GÉANT

Proposed
10.00±0.67
16.64±1.34
10.84±1.10

Ridge
11.20±0.73
19.52±1.16
12.47±1.14

k-NN
14.39±0.83
22.89±1.58
15.13±1.08

CART
16.65±1.06
24.15±1.51
17.01±1.59

RF
12.30±0.90
22.27±1.34
12.52±1.19

NN
12.18±1.08
18.62±1.23
12.05±1.13

TOV
88.66±1.10
96.22±1.38
98.71±1.98

Table 2: Mean post-hoc regrets and standard deviations for the maximum ﬂow transportation problem.

6 Experimental Evaluation

We evaluate the proposed method on 3 benchmarks: a maximum ﬂow transportation problem with unknown edge
capacities, an alloy production problem with unknown chemical composition in the raw materials, and a fractional
knapsack problem with unknown rewards and weights. We compare our method with 5 classical regression methods [9]
including ridge regression (Ridge), k-nearest neighbors (k-NN), classiﬁcation and regression tree (CART), random
forest (RF), and neural network (NN). All of these methods train the prediction models with their classic loss function.
We also apply the chosen correction function of each problem to the estimated solutions for these classical regression
methods, in order to ensure feasibility, to compute the post-hoc regret. However, the correction function has nothing
to do with the training of these classic methods. The methods of k-NN, RF and NN as well as our method have
hyperparameters, which we tune via cross-validation: for k-NN, we tried k ∈ {1, 3, 5}; for RF, we try different numbers
of trees in the forest {10, 50, 100}; for both NN and our method, we treat the learning rate, epochs and weight decay as
hyperparameters. The ﬁnal hyperparameter choices are shown in Table 1.

Ridge, k-NN, CART and RF are implemented using scikit-learn [10]. The neural network is implemented using
PyTorch [11]. All models are trained with Intel(R) Xeon(R) CPU @ 2.20GHz. To compute the optimal solution of an
LP under the true parameters, we use the LP solver from OR-Tools [12] instead of the solver of Mandi and Guns.

A maximum ﬂow transportation problem with unknown capacities.
In our ﬁrst experiment, we formulate a
transportation problem as a single-source-single-sink maximum ﬂow problem (MFP). To formulate it as a packing
LP, we use the formulation where the decision variables each correspond to a simple path from the source to the sink.
In this experiment, the unknown parameters are the edge capacities, which is the h vector in the packing LP. We
experiment in a setting where the goal is to use Predict+Optimize to learn which paths we will be using for transport,
and proportionally how much ﬂow we will be sending along each path—for example, the prediction is used to apply for
permits from a city council for sending a lot of trafﬁc along particular routes. Given that we are less concerned about
predicting the actual ﬂow magnitudes, in this experiment we set the penalty factor σ to the all-0s vector.

We conduct experiments on 3 real-life graphs: POLSKA [13] with 12 vertices and 18 edges, USANet [14] with 24
vertices and 43 edges, and GÉANT [15] with 40 vertices and 61 edges. Given that we are unable to ﬁnd datasets
speciﬁcally for this max-ﬂow problem, we follow the experimental approach of Demirovic et al. [16, 17, 18] and use
real data from a different problem (the ICON scheduling competition) as numerical values required for our experiment
instances. In this dataset, each unknown edge capacity has 8 features. For experiments on POLSKA and USANet, out of
the available 789 instances, 610 are used for training and 179 for testing the model performance, while for experiments
on GÉANT, out of the available 620 instances, 490 are used for training and 130 for testing the model performance.

For both NN and our method, we use a 3-layer fully-connected network with 16 neurons per hidden layer.

Tables 2 and 3 report the mean post-hoc regrets and standard deviations across 10 runs, and the mean square errors
(MSE) and standard deviations across 10 runs for each approach on the maximum ﬂow transportation problem with
unknown capacities respectively.

10

Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints

MSE
POLSKA
USANet
GÉANT

Proposed
1.45E+04±2.63E+04
1.76E+04±2.20E+04
1.62E+04±2.58E+04

Ridge
290.75±127.31
755.54±90.39
700.35±72.66

k-NN
363.13±120.51
913.79±91.48
842.45±75.78

CART
474.00±145.07
1626.40±195.31
1484.84±203.11

RF
309.94±123.44
779.04±83.86
704.96±76.64

NN
324.38±132.49
903.86±105.96
828.18±95.18

Table 3: Mean square errors and standard deviations for the maximum ﬂow transportation problem.

Figure 1: True parameters vs Predicted parameters.

Table 2 shows that the proposed method achieves the best performance in all cases. Compared with other methods,
the proposed method obtains at least 10.71% smaller post-hoc regret on POLSKA, 10.67% smaller on USANet, and
10.02% smaller on GÉANT. We also report the average True Optimal Values (TOV) in the last column of Table 2 for
reference. The proposed method achieves 11.49% relative error on POLSKA, 16.23% relative error on USANet, and
10.28% relative error on GÉANT.

For comparison, we also show a table of the mean squared error (MSE), i.e. squared (cid:96)2 error, of the predicted
parameters, across different methods and graphs, in Table 3. Even though the goal is to minimize post-hoc regret and it
is unreasonable to evaluate our method on the MSE, we present these results anyway for all our experiments, as they
help illustrate the behavior of our method. In this experiment, the MSE of the proposed method is drastically worse
than all the other methods, while ridge regression achieves the best performance in all of the cases unsurprisingly since
it is explicitly designed to learn in (cid:96)2 error, and RF always achieves the second best performance. We argue that this is
by design: our method optimizes for learning in terms of post-hoc regret, while all the other classical methods learn
to minimize in MSE. There does remain the question of why our method has that bad of an MSE. Here, we give a
scatterplot (Figure 1) of the norm of the predicted parameters versus the true parameters, across all the methods. As we
can see in Figure 1, the predicted parameters values of the proposed method are several orders of magnitude higher
than the true parameters values, i.e., our method predicting the unknown parameters at several orders of magnitude
larger than the true parameters. The reason for this phenomenon lies in the problem formulation, where we are trying
to predict which paths to send ﬂows through, and are less concerned with predicting the precise amount of ﬂow. As
a modelling choice, therefore, we picked the penalty factor σ = 0. Note that, since the unknown parameters are the
“h" vector in the packing LP, if we scale up the h vector, then the corresponding solutions x are scaled up by the same
factor. Thus, the phenomenon is equivalent to the estimated solution being much larger than the true optimal solution.
This is ﬁne from the Predict+Optimize perspective: the correction function scales down an over-capacity estimated
solution, and so the predictor only needs to predict the direction of the solution vector; even if it gives a far-too-large
norm, the correction function will ﬁx the magnitude at no cost. Our learning algorithm appears to have learnt to exploit
this correction function, and nonetheless, the estimated solution still gives the desired information—which paths to
send ﬂow along in the graph.

If we did care about predicting the actual ﬂow values, then we would set the penalty factor to a non-zero value. In the
next couple of experiments, we explore how the penalty factor affects the performance of our method, in terms of both
the post-hoc regret and the MSE of the predicted parameters. We note again that the penalty factor is a property of the
application, and not an algorithmic choice we make.

An alloy production problem with unknown chemical compositions in raw materials.
In our second experiment,
we consider an alloy production problem that is expressible as a covering LP. An alloy production plant needs to
produce a certain amount of a particular alloy, requiring a mixture of M kinds of metals. To that end, it must acquire at
least reqm tons of each of the m ∈ [M ] metals. The raw materials are to be obtained from K suppliers, each supplying

11

Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints

PReg

Alloy

Brass

Titanium-alloy

Penalty factor
0
0.25±0.015
0.5±0.015
1±0.015
2±0.015
0
0.25±0.015
0.5±0.015
1±0.015
2±0.015

Proposed

Ridge

k-NN

CART

RF

NN

TOV

37.66±4.52
68.16±6.26
82.91±5.45
107.64±6.85
150.47±12.99
4.07±0.75
6.45±0.81
7.90±0.561
10.73±0.81
14.17±1.31

61.93±3.17
75.16±4.48
88.36±6.24
114.80±10.30
167.64±18.69
6.15±0.67
7.54±0.81
8.92±0.96
11.69±1.28
17.23±1.92

65.68±5.76
80.11±7.85
94.52±10.19
123.37±15.08
181.05±25.29
6.51±0.50
8.03±0.59
9.56±0.69
12.59±0.92
18.69±1.41

87.57±8.83
109.94±10.04
132.24±11.59
176.91±15.55
266.19±24.29
7.95±0.64
10.05±0.67
12.15±0.73
16.34±0.87
24.72±1.24

61.40±2.96
74.11±4.14
86.77±5.81
112.16±9.69
162.91±17.65
5.93±0.63
7.22±0.75
8.53±0.88
11.12±1.16
16.32±1.75

61.46±6.69
73.93±6.07
86.36±6.16
111.25±8.31
161.03±15.46
5.87±0.66
7.14±0.79
8.52±0.90
11.08±1.19
16.25±1.72

312.02±6.94

30.27±0.54

Table 4: Mean post-hoc regrets and standard deviations for the alloy production problem.

MSE

Alloy

Brass

Titanium-alloy

Penalty factor
0
0.25±0.015
0.5±0.015
1±0.015
2±0.015
0
0.25±0.015
0.5±0.015
1±0.015
2±0.015

Proposed

Ridge

k-NN

CART

RF

NN

395.81±331.56
168.27±38.07
37.33±0.58
36.97±0.56
38.22±2.37
301.41±213.73
48.23±7.95
44.69±5.74
39.00±2.63
45.28±4.28

39.33±0.64

43.68±0.92

73.98±1.74

37.43±0.40

37.80±0.47

38.93±0.32

43.92±0.53

73.82±0.47

37.51±0.33

36.60±0.26

Table 5: Mean square errors and standard deviations for the alloy production problem.

a different type of ore. The ore supplied by site k ∈ [K] contains a conkm ∈ [0, 1] fraction of material m at a price of
costk per ton. The objective is to meet the minimum material requirements for each metal, at the minimum cost. The
decision variables xk are the number of tons of ores to order from each site k. Affected by the uncertainty in the mining
process, the metal concentration (% of the m ∈ M material per ton) of each ore is unknown, i.e. conkm is unknown,
which is the G matrix in the covering LP.

Following the correction function and penalty described in Sections 5 and 4 respectively, if the estimated solution does
not meet the minimum tonnage requirements of any metal, the alloy production plant will scale up its order by a factor
of λ ≥ 1 (from Equation 10) across all the suppliers. On the other hand, for this after-the-fact order, each supplier k
will charge a new cost of (1 + σk)costk per ton of its ore, instead of the previous cost of costk. We experimented on
various values of penalty factors σk and we will report and discuss how the value of σk affects the performance of the
prediction pipeline. We stress again that the value of σk is from the application, and not an algorithmic choice.

We conduct experiments on two real alloys: brass and an alloy blend for strengthening Titanium. For brass, 2 kinds of
metal materials, Cu and Zn, are required [19], that is M = 2. The requirements of the two materials are, proportionally,
req = [627.54, 369.72]. For the titanium-strengthening alloy, 4 kinds of metal materials, C, Al, V, and Fe, are
required [20], i.e., M = 4. The requirements of the four materials are req = [0.8, 60, 40, 2.5]. Since we could not
ﬁnd any real data on the concentration of metals in ores, we again use real data from a different problem (a knapsack
problem [21]) as numerical values in our experiment instances. In this dataset, each unknown metal concentration is
related to 4096 features. For experiments on both of the two alloys productions, 350 instances are used for training and
150 instances for testing the model performance.

For NN and our method, we use a 5-layer fully connected network with 512 neurons per hidden layer.

We conduct experiments on 5 types of penalty factor (σ) settings: the all-0s vector, and then 4 vectors where each
entry is i.i.d. uniformly sampled from [0.25 ± 0.015], [0.5 ± 0.015], [1.0 ± 0.015], and [2.0 ± 0.015] respectively. This
random sampling of σ ensures that the penalty factor for each supplier is different, but remain roughly in the same scale.

Tables 4 and 5 report the mean post-hoc regrets and standard deviations across 10 runs, and the mean square errors
(MSE) and standard deviations across 10 runs for each approach on the alloy production problem with unknown metal
concentrations, across the different scales of penalty factor σ.

When the penalty factor is 0, our method improves the solution quality substantially, obtaining at least 38.67% smaller
post-hoc regret than the other methods in brass production, and at least 30.73% smaller post-hoc regret in titanium-alloy
production. When the penalty factor is non-zero as given in the last paragraph, our method obtains at least 7.80%,
3.99%, 3.24%, and 6.56% smaller post-hoc regret respectively in brass production, and at least 9.65%, 7.30%, 3.14%,
and 12.82% smaller post-hoc regret respectively in titanium-alloy production. The results suggest that the advantages of
the proposed method on solution quality ﬁrst decreases and then increases as the penalty factor σ grows. The average

12

Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints

Capacity

50

100

150

200

PReg

Penalty factor
0
0.25±0.015
0.5±0.015
1.0±0.015
2.0±0.015
0
0.25±0.015
0.5±0.015
1.0±0.015
2.0±0.015
0
0.25±0.015
0.5±0.015
1.0±0.015
2.0±0.015
0
0.25±0.015
0.5±0.015
1.0±0.015
2.0±0.015

Proposed

Ridge

k-NN

CART

RF

NN

TOV

35.36±0.51
38.17±0.76
39.57±0.85
41.90±0.85
44.92±0.91
45.66±0.66
49.97±0.86
52.27±0.66
55.71±1.12
58.88±0.79
42.01±0.37
46.59±0.23
50.25±0.59
54.07±0.66
58.40±0.63
25.70±0.36
31.50±0.50
35.08±0.69
39.54±0.45
44.59±0.55

38.00±0.89
39.17±0.86
40.33±0.83
42.65±0.82
47.30±0.90
49.52±1.29
51.12±1.22
52.73±1.17
55.93±1.15
62.35±1.36
47.56±1.08
49.37±1.02
51.20±0.98
54.83±1.01
62.11±1.38
33.07±0.98
34.91±0.92
36.76±0.90
40.45±0.98
47.83±1.44

36.95±1.04
38.46±0.96
39.97±0.90
42.99±0.84
49.03±1.00
48.20±1.31
50.38±1.14
52.36±1.08
56.23±0.98
64.25±0.97
46.16±1.13
48.37±1.04
50.58±0.97
54.99±0.95
63.81±1.31
32.73±0.92
34.91±0.89
37.10±0.91
41.47±1.06
50.22±1.66

35.53±0.71
38.85±0.75
42.16±0.82
48.80±1.04
62.08±1.63
48.08±0.75
51.88±0.71
55.66±0.75
63.25±1.01
78.42±1.82
46.91±0.67
50.49±0.66
54.07±0.74
61.23±1.07
75.55±1.96
33.18±0.88
36.36±0.83
39.55±0.89
45.92±1.22
58.65±2.22

37.90±0.65
38.87±0.58
39.85±0.53
41.99±0.47
45.71±0.63
49.85±1.31
51.19±1.23
52.53±1.15
55.74±0.63
60.57±0.93
48.09±0.97
49.68±0.87
51.27±0.79
54.44±0.69
60.78±0.84
33.63±0.84
35.33±0.80
37.03±0.81
40.42±0.92
47.20±1.39

39.75±1.18
40.51±1.03
41.26±0.90
42.77±0.71
45.79±0.86
52.19±1.84
53.25±1.56
54.31±1.32
56.44±1.05
60.69±1.66
49.78±2.02
51.08±1.58
52.38±1.19
54.97±0.86
60.54±2.15
34.67±2.13
36.19±1.55
37.71±1.09
40.76±1.20
46.85±3.58

90.79±0.46

156.46±0.79

207.92±0.99

246.86±1.20

Table 6: Mean post-hoc regrets and standard deviations for the fractional knapsack problem.

True Optimal Values (TOV) are reported in the last column of Table 4. The relative errors of all the methods grow
larger when the penalty factor grows larger. For example, the relative errors of the proposed method are 11.77%,
20.77%, 26.57%, 34.34%, and 47.03% on brass production when the penalty factors are all zero, or are sampled from
[0.25 ± 0.015], [0.5 ± 0.015], [1.0 ± 0.015], [2.0 ± 0.015] respectively.

We show also the MSE of the predicted parameters in Table 5, across different methods. As discussed in the previous
max-ﬂow experiment, when the penalty is 0, the MSE for our method can be very large as the lack of penalty gets
exploited by the method. Interestingly, as we observe in Table 5, the MSE for our method ﬁrst decreases and then
increases as σ grows (the growth at the end is slightly difﬁcult to read on this plot). Here we explain why the MSE
values of the proposed method may increase when the penalty term grows too large. When the penalty is non-zero but
somewhat small, it acts as a regularizer to prevent our method from exploiting the correction function as in the previous
experiment. On the other hand, as the penalty increases, the post-hoc regret becomes dominated by the penalty term. As
such, our method is strongly disincentivized to use any correction whatsoever. Therefore, when σ is large, our method
tends to be conservative and always predicts parameters that make the estimated solution a bit too large. This explains
why the MSE of the predicted parameters gets bigger again (albeit not by much) as σ increases.

Fractional knapsack problem with unknown prices and weights. The last experiment is on the fractional knapsack
problem with unknown rewards and weights. The unknown parameters appear in both objective “c" and constraints
“G" of the packing LP. In our setting, word descriptions of a collection of M inﬁnitely-divisible items is presented to
the algorithm, from which the weight wi and reward ci of each item i need to be predicted. The player’s goal is to
maximize the total reward of (fractionally) selected items without exceeding a known ﬁxed capacity of the knapsack.
We use the dataset of Paulus et al. [21], in which each fractional knapsack instance consists of 10 items and each item
has 4096 features related to its reward and weight.

For both NN and our method, we use a 5-layer fully-connected network with 512 neurons per hidden layer.

In line with the choice of correction function and penalty in Section 4, if the estimated solution violates the capacity
constraint, items will need to be removed at a penalty and in a proportional manner (i.e. the over-capacity knapsack is
scaled down). If the change in the amount of item i is ∆i, then the penalty for this removal is σici∆i.

We conduct experiments on 4 different capacities: 50, 100, 150, and 200. We use 700 instances for training and 300
instances for testing the model performance. Identically to the second experiment, we use 5 scales of penalty factors:
all-0s penalty, and penalty factor σ with i.i.d. entries drawn uniformly from [0.25 ± 0.015], [0.5 ± 0.015], [1.0 ± 0.015],
and [2.0 ± 0.015].

Table 6 shows the post-hoc regrets of the different methods across the different scales of penalty factors. The performance
of the proposed method is at least as good as other classical approaches when the capacity is 50, 100, or 150, and is
consistent better than others when the capacity is 200. Observing a similar trend as in the alloy production experiment,
the improvements of our method over other classical methods, in terms of the post-hoc regret, ﬁrst decreases and then
increases as the penalty factor σ grows. The relative errors of all the methods grow smaller when the capacity grows

13

Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints

Capacity

50

100

150

200

MSE

Penalty factor
0
0.25±0.015
0.5±0.015
1.0±0.015
2.0±0.015
0
0.25±0.015
0.5±0.015
1.0±0.015
2.0±0.015
0
0.25±0.015
0.5±0.015
1.0±0.015
2.0±0.015
0
0.25±0.015
0.5±0.015
1.0±0.015
2.0±0.015

Proposed

Ridge

k-NN

CART

RF

NN

190.05±3.89
79.75±2.33
79.52±2.69
75.30±1.20
72.88±1.31
162.95±22.35
83.28±3.32
77.57±1.62
72.28±1.08
71.57±0.58
161.92±22.60
80.33±2.05
80.96±1.98
75.39±1.15
71.35±0.66
151.91±35.18
79.12±3.26
75.40±1.50
70.62±1.03
71.58±0.66

75.40±0.65

83.47±0.77

140.51±1.75

72.04±0.73

71.66±0.58

Table 7: Mean square errors and standard deviations for the fractional knapsack problem.

larger, for example, the relative errors of the proposed method are around 38-49%, 29-37%, 20-28%, 10-18% when the
capacity is 50, 100, 150, and 200 respectively.

As in the previous experiments, we also compare the MSE of the parameters predicted by our method against the other
methods, as shown in Table 7. Similar to the other experiments, when the penalty term is zero, the predicted parameters
of the proposed method are shifted by several orders of magnitude from the true parameters (the post-hoc regret is
small but the MSE value is large). Then, as σ grows, the MSE of our method decreases to roughly the same as the
other methods, before growing slightly again as σ becomes large and the predictor learnt from our method becomes
conservative.

Runtime Analysis Table 8 shows the average runtime across 10 simulations for different optimization problems. In
the alloy production problem and the fractional knapsack problem, the runtimes of the proposed method are comparable
to NN, and are much better than RF. In the maximum ﬂow transportation problem, the runtimes of the proposed method
are comparable to NN in POLSKA and GÉANT, but the runtime of the proposed method is large in USANet. The
reason is that we use the formulation where the decision variables each correspond to a simple path from the source to
the sink. Thus, when the number of paths is large (the number of paths in USANet is 242), the number of the decision
variables of the LP is large and the LP requires more time to be solved.

Runtime(s)

Proposed
Ridge
k-NN
CART
RF
NN

Maximum ﬂow transportation
POLSKA USANet GÉANT
132.22
<1
<1
<1
11.00
12.82

18.65
<1
<1
<1
4.11
10.33

15.48
<1
<1
<1
11.89
13.89

Brass
228.00
20.22
25.14
30.33
959.50
212.22

331.38
56.89
70.22
94.89
2552.25
321.11

22.33
26.00
34.83
1034.07
135.80

Alloy production

Fractional knapsack

Titanium-alloy Capacity=50 Capacity=100 Capacity=150 Capacity=200
132.89

132.37

131.49

139.44

Table 8: Average runtime (in seconds) for the maximum ﬂow transportation, alloy production, and fractional knapsack
problems.

7 Summary

We proposed the ﬁrst Predict+Optimize framework addressing the scenario where the constraints may contain unknown
parameters. Speciﬁcally, we introduced the novel notions of correction function and post-hoc regret into the framework.
Algorithmically, we focused on packing and covering linear programs—a large and widely-studied class of problems—
and presented a method to train parameter predictors in our novel framework. Empirical results in 3 benchmarks
demonstrate better prediction performance of our method over 5 classical methods which do not take the correction
function into account during training.

14

Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints

References

[1] Adam N Elmachtoub and Paul Grigas.
https://arxiv.org/pdf/1710.08005.pdf., 2017.

Smart “predict,

then optimize”.

Technical

report.

[2] Adam N Elmachtoub and Paul Grigas. Smart “predict, then optimize”. Management Science, 68(1):9–26, 2022.

[3] Bryan Wilder, Bistra Dilkina, and Milind Tambe. Melding the data-decisions pipeline: Decision-focused learning
for combinatorial optimization. In Proceedings of the Thirty-Third AAAI Conference on Artiﬁcial Intelligence,
pages 1658–1665, 2019.

[4] Adam N. Elmachtoub, Jason Cheuk Nam Liang, and Ryan McNellis. Decision trees for decision-making under
the predict-then-optimize framework. In Proceedings of the 37th International Conference on Machine Learning,
pages 2858–2867, 2020.

[5] Ali Ugur Guler, Emir Demirovi´c, Jeffrey Chan, James Bailey, Christopher Leckie, and Peter J Stuckey. A divide
and conquer algorithm for Predict+Optimize with non-convex problems. In Proceedings of the Thirty-Sixth AAAI
Conference on Artiﬁcial Intelligence, 2022.

[6] Jayanta Mandi and Tias Guns. Interior point solving for LP-based prediction+optimisation. Advances in Neural

Information Processing Systems, 33:7272–7282, 2020.

[7] David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning representations by back-propagating

errors. nature, 323(6088):533–536, 1986.

[8] Stephen Boyd and Lieven Vandenberghe. Convex optimization. Cambridge University Press, 2004.
[9] Jerome Friedman, Trevor Hastie, and Robert Tibshirani. The elements of statistical learning. Springer series in

statistics New York, 2001. Volume 1, Number 10.

[10] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss,
V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn:
Machine learning in Python. Journal of Machine Learning Research, 12:2825–2830, 2011.

[11] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen,
Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito,
Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala.
In Advances in Neural Information
Pytorch: An imperative style, high-performance deep learning library.
Processing Systems 32, pages 8024–8035. Curran Associates, Inc., 2019.

[12] Laurent Perron and Vincent Furnon. OR-Tools, 2019.

[13] S. Orlowski, M. Pióro, A. Tomaszewski, and R. Wessäly. SNDlib 1.0–Survivable Network Design Library. In
Proceedings of the 3rd International Network Optimization Conference, April 2007. http://sndlib.zib.de, extended
version accepted in Networks, 2009.

[14] Diego Lucerna, Nicola Gatti, Guido Maier, and Achille Pattavina. On the efﬁciency of a game theoretic approach
to sparse regenerator placement in WDM networks. In GLOBECOM 2009-2009 IEEE Global Telecommunications
Conference, pages 1–6. IEEE, 2009.

[15] MultiMedia LLC. Geant topology map dec2018 copy. https://www.geant.org/Resources/Documents/

GEANT_Topology_Map_December_2018.pdf, 2018. Accessed: 2020-09-10.

[16] Emir Demirovi´c, Peter J Stuckey, James Bailey, Jeffrey Chan, Chris Leckie, Kotagiri Ramamohanarao, and Tias
Guns. An investigation into prediction+optimisation for the knapsack problem. In International Conference
on Integration of Constraint Programming, Artiﬁcial Intelligence, and Operations Research, pages 241–257.
Springer, 2019.

[17] Emir Demirovi´c, Peter J Stuckey, James Bailey, Jeffrey Chan, Christopher Leckie, Kotagiri Ramamohanarao, and
Tias Guns. Predict+Optimise with ranking objectives: Exhaustively learning linear functions. Proceedings of the
Twenty-Eighth International Joint Conference on Artiﬁcial Intelligence, pages 1078–1085, 2019.

[18] Emir Demirovi´c, Peter J Stuckey, Tias Guns, James Bailey, Christopher Leckie, Kotagiri Ramamohanarao, and
Jeffrey Chan. Dynamic programming for Predict+Optimise. In Proceedings of the Thirty-Fourth AAAI Conference
on Artiﬁcial Intelligence, pages 1444–1451, 2020.

[19] Kazi Bayzid Kabir and Iqbal Mahmud. Study of erosion-corrosion of stainless steel, brass and aluminum by open

circuit potential measurements. Journal of Chemical Engineering, pages 13–17, 2010.

[20] Nizamettin Kahraman, Behçet Gülenç, and Fehim Findik. Joining of titanium/stainless steel by explosive welding

and effect on interface. Journal of Materials Processing Technology, 169(2):127–133, 2005.

15

Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints

[21] Anselm Paulus, Michal Rolínek, Vít Musil, Brandon Amos, and Georg Martius. Comboptnet: Fit the right np-hard
problem by learning integer programming constraints. In International Conference on Machine Learning, pages
8443–8453. PMLR, 2021.

16

