How to Train Your Program:
a Probabilistic Programming Pattern for Bayesian Learning From Data

David Tolpin
Ben-Gurion University of the Negev, Israel PUB+
david.tolpin@gmail.com

2
2
0
2

n
a
J

5
1

]

G
L
.
s
c
[

2
v
0
5
6
3
0
.
5
0
1
2
:
v
i
X
r
a

Abstract
We present a Bayesian approach to machine learn-
ing with probabilistic programs. In our approach,
training on available data is implemented as infer-
ence on a hierarchical model. The posterior distri-
bution of model parameters is then used to stochas-
tically condition a complementary model, such that
inference on new data yields the same posterior dis-
tribution of latent parameters corresponding to the
new data as inference on a hierarchical model on
the combination of both previously available and
new data, at a lower computation cost. We frame
the approach as a design pattern of probabilistic
programming referred to herein as ‘stump and fun-
gus’, and evaluate realization of the pattern on syn-
thetic and real-world case studies.

1 Introduction
The ultimate Bayesian approach to learning from data is em-
bodied by hierarchical models (Gelman et al., 2013; Good-
man et al., 2016; McElreath, 2020). In a hierarchical genera-
tive model, the distribution of each observation yij from the
ith group of observations depends on group parameter θi, and
the distribution of each θi depends on hyperparameter τ :

(1)

τ ∼ H
θi|τ ∼ D(τ )
yij|θi ∼ F (θi)
A hierarchical model can be thought of as a way of inferring,
or ‘learning’, the prior of θi from all observations in the data
set. Consider the following example problem: multiple boxes
are randomly ﬁlled by K marbles from a bag containing a
mixture of blue and white marbles. We are presented with
a few draws with replacement from each of the boxes, yij
being the jth draw from the ith box; our goal is to infer the
number of blue marbles θi in each box. Intuitively, since the
boxes are ﬁlled from the same bag, the posterior distribution
of θi should account both for draws from the ith box and,
indirectly, for draws from all other boxes. This is formalized
by the following hierarchical model:

τ ∼ Beta(1, 1)

θi|τ ∼ Beta(Kτ, K(1 − τ ))

(2)

yij|θi ∼ Bernoulli(θi)

Model (2) learns from the data in the sense that inference
for each box is inﬂuenced by draws from all boxes. However,
learning from training data to improve inference on future
data with a hierarchical model is computationally inefﬁcient
— if a new box is presented, one has to add observations of
the new box to the previously available data and re-run in-
ference on the extended data set. Inference performance can
be improved by employing data subsampling (Korattikara et
al., 2014; Bardenet et al., 2014, 2017; Maclaurin and Adams,
2014; Quiroz et al., 2018), but the whole training data set
still needs to be kept and made accessible to the inference
algorithm. A hierarchical model cannot ‘compress’, or sum-
marize, training data for efﬁcient inference on future obser-
vations.

An alternative approach, known as empirical Bayes (Rob-
bins, 1951; Casella, 1985; Robbins, 1992), consists in adjust-
ing the hyperprior based on the training data; e.g. by ﬁxing
τ at a likely value, or by replacing H in (1) with a suitable
approximation of the posterior distribution of τ . However,
empirical Bayes is not Bayesian. While practical efﬁciency
of empirical Bayes was demonstrated in a number of set-
tings (Robbins, 1992), in other settings empirical Bayes may
result in a critically misspeciﬁed model and overconﬁdent or
biased inference outcomes.

In this work, we propose an approach to learning from data
in probabilistic programs which is both Bayesian in nature
and computationally efﬁcient. First, we state the problem of
learning from data in the context of Bayesian generative mod-
els (Section 2). Then, we introduce the approach and discuss
its implementation (Section 3). For evaluation, we apply the
approach to inference in synthetic and real-world problems
(Section 5). Finally, we conclude with a overview of related
work and discussion (Sections 6 and 7).

2 Problem: Learning from Data
The challenge we tackle here is re-using inference outcomes
on the training data set for inference on new data. Formally,
population Y is a set of sets yyyi ∈ Y of observations yij ∈ yyyi.
Members of each yyyi are assumed to be drawn from a known
distribution F with unobserved parameter θi, yij ∼ F (θi).
θi are assumed to be drawn from a common distribution H.
Our goal is to devise a scheme that, given a subset Y ⊂ Y,
the training set, infers the posterior distribution of θk|Y, yyyk
for any yyyk ∈ Y in a shorter amortized time than running in-

 
 
 
 
 
 
ference on a hierarchical model Y ∪ {yyyk}. By amortized time
we mean here average time per yyyk, k ∈ 1 : K as K → ∞.

In other words, we look for a scheme that works in two
stages. At the ﬁrst stage, inference is performed on the train-
ing set Y only. At the second stage, the inference outcome
of the ﬁrst stage is used, together with yyyk, to infer θk|Y, yyyk.
We anticipate a scheme that ‘compresses’ the training set at
the ﬁrst stage, resulting in a shorter running time of the sec-
ond stage. Such scheme bears similarity to the conventional
machine learning paradigm: an expensive computation on the
training data results in shorter running times on new data.

3 Main Idea: Stump and Fungus
In quest of devising such a scheme, we make two observa-
tions which eventually help us arrive at a satisfactory solu-
tion:

1. In Bayesian modelling, information about data is usually
conveyed through conditioning of the model on various
aspects of the data.

2. In a hierarchical model, inﬂuence of the ith group of ob-
servations on the hyperparameters τ and, consequently,
on other groups, passes exclusively through the group
parameters θi.

If,

instead of conditioning on
training data yi, we could condition
on parameters θi corresponding to
the training data, then we could per-
form inference on new data item yk
at a lower time and space complex-
ity. Continuing the well known anal-
ogy between a hierarchical model
and a tree, with the hyperparameter
τ at the root and observations yij in the leaves, we can liken a
model which receives all θi of the training data and new data
item yk to a stump — the hierarchical model with the trunk
cut off just after the hyperparameters — and a fungus grow-
ing on the stump — the new data item. The problem is, of
course, that we infer distributions, rather than ﬁxed values,
of θi, and the model must be, somewhat unconventionally,
conditioned on the distributions of θi.

However, a recently introduced notion of stochastic con-
ditioning (Tolpin et al., 2021) makes conditioning on distri-
butions of θi possible, both theoretically and in the practical
case when the posteriors of θi are approximated using Monte
Carlo samples. Stochastic conditioning (Tolpin et al., 2021)
extends deterministic conditioning p(x|y = y0), i.e. con-
ditioning on some random variable y taking on a particu-
lar value y0, to conditioning p(x|y ∼ D0) on y having the
marginal distribution D0. A probabilistic model with stochas-
tic conditioning is a tuple (p(x, y), D) where p(x, y) is the
joint probability density of random variable x and observa-
tion y and D is the distribution of observation y, with density
q(y). To infer p(x|y ∼ D), one must be able to compute
p(x, y ∼ D) = p(x)p(y ∼ D|x). p(y ∼ D|x) has the fol-
lowing unnormalized density:
(cid:18)(cid:90)

(cid:19)

p(y ∼ D|x) = exp

(log p(y|x)) q(y)dy

(3)

Y

Conditioning the model both stochastically on the poste-
rior distributions of θi on training data and deterministically
on new data yk would yield the same posterior distribution
of θk as inference on the full hierarchical model. However,
that would also mean that the inference algorithm can sample
from the posterior distribution of θi to infer yk. To achieve
the objective of ‘compression’ of the training set for faster in-
ference on new data, the parameter posterior can be approxi-
mated by a weighted ﬁnite set of samples. This is related to
Bayesian coresets (Huggins et al., 2016; Zhang et al., 2021),
although with essential differences, discussed in Section 6.
Based on this, we propose the ‘stump-and-fungus’ pattern for
learning from data in probabilistic programs:

1. Training is accomplished through inference on a hierar-

chical model, in the usual way.

2. The parameter posterior is approximated by a set of M

weighted samples (˜θθθ, www).

• ˜θi are drawn from the mixture of parameter poste-
riors of all groups. The set size M is chosen as a
compromise between approximation accuracy and
inference performance.

• The weights are selected to minimize approxima-
tion error of the hyperparameter posterior, as de-
tailed in Section 4.

3. For inference on new data yyy, a stump-and-fungus model

is employed:

τ ∼ H

(˜θθθ, www)|τ ∼ D(τ ) — stochastic conditioning

θ|τ ∼ D(τ )
yyy|θ ∼ F (θ)

(4)

The unnormalized conditional log probability of (˜θθθ, www)
given τ is computed as (5), following Tolpin et al.
(2021):

log p((˜θθθ, www)|τ ) =

M
(cid:88)

j=1

wj log p(˜θj|τ )

(5)

A gain in time and space complexity follows from replac-
ing the dataset Y with a weighted sample set (˜θθθ, www) of size
M . Many inference algorithms scale at least linearly with the
size of the data, hence the corresponding complexity term de-
creases from O(|Y |) to O(M ). In addition, the likelihood of
a weighted sample skips the lowest level of the hierarchy and
is thus cheaper to compute than of an observation, though the
exact gain depends on the particular model.

Although two models — hierarchical and stump-and-
fungus — are involved in the pattern, the models are in fact
two roles fulﬁlled by the same generative model, combin-
ing stochastic conditioning on training data and deterministic
conditioning on new data (consisting potentially of multiple
data items). This preserves a common practice in machine
learning in which the same model is used for both training
and inference.

(a) weighted sample set

(b) posterior

Figure 1: Inferring parameters of a normal distribution

4 Weighted Sample Set Approximation of

pliﬁes to (8):

Parameter Posterior

In Section 3, we suggested to stochastically condition the
model on the posterior distributions of θi of the training data.
We further suggested that, to ‘compress’ the training set, the
distribution be approximated by a ﬁnite weighted sample set
(˜θθθ, www) of size M . Let us assume that the sample set (˜θθθ) is
drawn and ﬁxed, and show how the weights www are computed.
Our objective is to approximate the posterior of the hyper-
parameter τ given the training set Y , by conditioning τ on
(˜θθθ, www). We can achieve this by selecting weights www such that
the KL divergence between p(τ |Y ) and p(τ |(˜θθθ, www)) is min-
imized. Since p(τ |Y ) does not depend on www, minimizing
KL(p(τ |Y )||p(τ |(˜θθθ, www)) is equivalent to the following max-
imization problem:

www = arg max
(cid:90)

S(www)

www
p(τ |Y ) log p(τ |(˜θθθ, www))dτ

S(www) =

where, from (5)

τ ∈T

p(τ |(˜θθθ, www)) =
(cid:82)

p(τ ) exp

(cid:16)(cid:80)M

(cid:17)
j=1 wj log p(˜θj|τ )
(cid:17)
j=1 wj log p(˜θj|τ (cid:48))

(cid:16)(cid:80)M

τ (cid:48)∈T p(τ (cid:48)) exp

dτ (cid:48)
(6)
In the context of Bayesian inference in hierarchical generative
models, the posterior is commonly approximated by a set of
Monte Carlo samples. Assuming that τ |Y is approximated
by a (large) set of N samples τ1...τN , S(www) can be estimated
as

p(τi) exp

(cid:16)(cid:80)M

(cid:17)
j=1 wj log p(˜θj|τi)

log



ˆS(www) =

=

N
(cid:88)

i=1

N
(cid:88)

i=1

(cid:80)

k p(τk) exp

log p(τi) +

M
(cid:88)

j=1

(cid:16)(cid:80)M

(cid:17)
j=1 wj log p(˜θj|τk)


wj log p(˜θj|τi)



− N log

N
(cid:88)

i=1



exp

log p(τi) +

wj log p(˜θj|τi)





M
(cid:88)

j=1

(7)
When it is feasible to impose a uniform improper prior
p(τ ) = C on the hyperparameter, such as in the case of a
sufﬁciently large number of groups in the hierarchy, (7) sim-

ˆS(www) =

N
(cid:88)

M
(cid:88)

i=1

j=1

wj log p(˜θj|τi)

− N log

N
(cid:88)

i=1

exp





M
(cid:88)

j=1



(8)

wj log p(˜θj|τi)



∇www ˆS(www) is readily obtainable, either analytically or algorith-
mically, and (6) can be solved using gradient ascent. Al-
though S(www) is not concave in general, there is an obvious
initial guess www = 111 in proximity of the global maximum; the
larger M , the closer is the guess to the maximum.

Let us illustrate the computation on a toy example. We use

model (9)

p(µ, log σ) ∝ 1

yj|µ, σ ∼ Normal(µ, σ)

(9)

to infer the parameters of a single-dimensional normal distri-
bution given observations yyy = {−1.33, −0.61, −0.20, 0.34,
0.71, 1.23, 1.45, 1.47, 1.83, 2.05}. The posterior is shown in
blue in Figure 1b. Then, we draw 10 samples from the pre-
dictive posterior, and condition (9) on the samples. The new
posterior is likely to be different, with the standard deviation
of the mean ≈ 0.33. For ˜yyy = {−2.77, −1.80, −0.71, −0.62,
0.31, 0.38, 0.43, 0.70, 1.66, 2.6}, the posterior is shown
in green in Figure 1b. We then compute, according to (6)
and (8), the weights (Figure 1a), and condition model (9) on
the weighted sample, resulting in the posterior (orange in Fig-
ure 1b) almost coinciding with the original posterior. In a hi-
erarchical model, hyperparameters τ would correspond to µ
and σ, and group parameters θθθ to yyy.

5 Case Studies
We evaluate the stump-and-fungus pattern on three case stud-
ies. We begin with a basic synthetic case study “Boxes With
Marbles” (Section 5.1), which, while does not pose compu-
tational challenges, allows us to show most aspects of appli-
cation of the pattern to a hierarchical model. We then con-
tinue to a didactic study “Tumor Incidence in Rats” (Sec-
tion 5.2) which involves a large number of groups in the hi-
erarchy. Finally, we apply the pattern to “Educational At-
tainment in Secondary Schools” (Section 5.3), an elaborated
cross-classiﬁed model based on data used in a real-world so-
ciological research. We implemented in the studies in In-
fergo (Tolpin, 2019) and ﬁt models using HMC (Neal, 2011)
or NUTS (Hoffman and Gelman, 2011). We used gradient
ascent with momentum for computation of sample weights.

321012y0.51.01.52.02.5weight2.01.51.00.50.00.51.01.52.00.000.250.500.751.000.51.01.52.02.53.00.00.51.01.5posteriorweightedunweighted6420246y0.00.10.20.3(a) stump & fungus vs. hierarchical

(b) empirical Bayes vs. hierarchical

(c) discrepancy

Figure 2: Marbles in boxes. Stump-and-fungus with 10 samples faithfully approximates the hierarchical posterior, while
empirical Bayes results in a greater discrepancy.

The data and source code for the case studies are provided in
the supplementary material.

5.1 Boxes With Marbles
This case study is inspired by an introductory example
in McElreath (2020). Boxes are ﬁlled with marbles from
a bag with a mix of blue and white marbles. There are 6
boxes, with 4 marbles in each box. Marbles are drawn from
the boxes, with replacement, and observed. The number of
blue marbles in each box are to be inferred. The problem is
formalized by model (10):

p0 ∼ Uniform(0, 1)

pi|p0 ∼ Beta (4p0, 4 (1 − p0))
yj|pbj ∼ Bernoulli (cid:0)pbj

(cid:1)

(10)

where p0 is the proportion of blue marbles in the bag, pi —
in the ith box, yj is 1 if the jth drawn marble was blue, 0
otherwise, and bj is the box from which the jth marble was
drawn.

We ﬁt

• the hierarchical model;
• the empirical Bayes model in which p0 is ﬁxed to the

posterior mean of p0 in the hierarchical model;

• 6 stump-and-fungus models, with each box as the fun-
gus, in turn, using 10 samples from the parameter poste-
rior for the stump.

Figure 2 compares the posteriors. Figure 2a shows the pos-
terior distributions of pi from the hierarchical model (white)
and each of the stump-fungus models (light blue), overlaid.
Similarly, Figure 2b compares the posteriors of the hierar-
chical and the empirical Bayes models. One can observe
that stump-and-fungus results in a better approximation of
the posterior than empirical Bayes. Figure 2c visualizes
discrepancy between the posteriors with the distribution of
Kolmogorov-Smirnov statistics of pi over boxes, conﬁrming
the advantage of stump-and-fungus.

5.2 Tumor Incidence in Rats
In this case study, based on Tarone (1982) and discussed in
Gelman et al. (2013, Chapter 5), data on tumor incidence in
rats in N = 70 laboratory experiments is used to infer tumor
incidence based on outcomes of yet another experiment. A
different number of rats ni was involved in each experiment,

and the number of tumor cases yi was reported. An applica-
tion of the stump-and-fungus pattern in this case would be to
replace the original data set of size N × 2 with a ‘stump’ of
a smaller size M × 2 for assessment of outcomes of future
experiments. The problem is formalized by model 11:

α, β ∼ Prior

pi|α, β ∼ Beta(α, β)

yi|pi ∼ Binomial(ni, pi)

(11)

where the non-informative prior distribution is set such that
p(α, β) ∝ (α + β)−5/2 (Gelman et al., 2013, Section 5.3). In
addition, each group can be ﬁt an ‘unpooled’ Beta-Binomial
model (12):

pi ∼ Beta(1, 1)

yi|pi ∼ Binomial(ni, pi)

(12)

We ﬁt

• a separate ‘unpooled’ model for each experiment;

• the hierarchical model;

• 71 stump-and-fungus models, with each experiment as
the fungus, in turn, using 10 samples from the parameter
posterior for the stump.

Since Gelman et al. (2013, Section 5.3) give a detailed ac-
count of empirical Bayes vs. hierarchical model, we omit
this comparison here.

Inference on model (11) can be performed efﬁciently
thanks to summarization of n observations from Bernoulli(p)
as a single observation from Binomial(n, p). In general how-
ever, the use of a hierarchical model would require carrying
all observations of all previous experiments for learned infer-
ence on ﬁndings of a new experiment.

Figure 3 shows the posterior distributions for p inferred on
71 unpooled models (Figure 3a), on the hierarchical model
(Figure 3b) and through 71 applications of stump-and-fungus
(Figure 3c). One can observe that the posteriors obtained on
both hierarchical and stump-and-fungus models appear to be
the same, except for small discrepancies apparently caused by
ﬁnite sample size approximation. Compared to the unpooled
posteriors, signiﬁcant shrinkage takes place. Table 1 shows
the inference times for each of the models. Inference on a
single group with the stump-and-fungus model takes less than
10% of time on the hierarchical model.

123456123456box0.20.40.60.81.0pBlue123456123456box0.20.40.60.81.0pBlueEBS&F, 10 samples0.0150.0200.0250.0300.0350.040KS statistics(a) Unpooled models

(b) Hierarchical model

(c) Stump-and-fungus models

Figure 3: Tumor incidence in rats. The posteriors are the same in hierarchical and stump-and-fungus model, except for small
discrepancies apparently caused by ﬁnite sample size approximation. Colorful lines are posterior distributions of p for each of
71 experiments. Black lines are posterior distributions of p for a future experiment.

Table 1: Tumor incidence in rats: inference times for 1000
burn-in and 5000 posterior samples, 10 stump samples.

Model Hierarchical Separate Stump & Fungus Weights
15±1.1

2.1

7.2

Time, sec

93

5.3 Educational Attainment in Secondary Schools
This study is based on Paterson (1991) and explores educa-
tional attainment of children in Scotland. There are two real-
valued predictors: social class scale CC and verbal reasoning
score VRQ on entry to the secondary school, three hierarchies:
by secondary school(SID), by gender (SEX), and by primary
school (PID), and a real valued target — attainment score
ATTAIN at the age of 16. There are 3,435 children, 148 pri-
mary schools, and 19 secondary schools in the data set. An
application of stump-and-fungus problem would be to pro-
vide a new secondary school with a small ‘stump’, instead of
the full data set, for attainment assessment. The problem can
be formalized as model (13), a cross-classiﬁed hierarchical
linear regression model:

µβ, log σβ, µσ, log σσ ∼ Uniform(−∞, ∞)
β|µβ, σβ ∼ Normal(µβ, σβ)
log σ|µσ, σσ ∼ Normal(µσ, σσ)

(13)

p(yi|β, σ) =

(cid:89)

h

Normal(yi | βhgih · xi, σhgih )

Here, h is the hierarchy index, xi and yi are the predictors
and the target of the ith pupil, gih is the group index of the
ith pupil in the hth hierarchy. µβ, log σβ, µσ, log σσ are the
hyperparameters of the model, and β, σ are the group param-
eters; in total, the model has 700 real-valued parameters, of
which 18 are hyperparameters.

We ﬁt
• the hierarchical model;
• the empirical Bayes model in which the hyperparame-
ters are ﬁxed to their posterior means in the hierarchical
model;

• 19 stump-and-fungus models, with each secondary
school as the fungus, in turn, using 10 and 20 sam-
ples from the parameter posterior for the stump. Since
parameters in each hierarchy are mutually independent
given hyperparameters, a separate weight is assigned to

each component of a sample, rather than to the sample
as a whole.

Figure 4 compares the posteriors. Figures 4a and 4b show
the posterior distributions of pi from the hierarchical model
(white) and each of the stump-fungus models (light blue) for
10 and 20 samples, correspondingly. Similarly, Figure 4c
compares the posteriors of the hierarchical and the empirical
Bayes models. One can observe that stump-and-fungus re-
sults in a better approximation of the posterior than empirical
Bayes. Figure 4d visualizes discrepancy between the poste-
riors with the distribution of Kolmogorov-Smirnov statistics
of the group parameters over the secondary schools, conﬁrm-
ing the advantage of stump-and-fungus. Table 2 shows the
inference times for each of the models. Inference on a single
group with the stump-and-fungus model takes less than 25%
of time on the hierarchical model.

Table 2: Educational attainment:
inference times for 1000
burn-in and 5000 posterior samples, 10 and 20 stump sam-
ples.

Model Hierar- Empirical Stump & Fungus

Weights

Time, sec

chical
908

Bayes
860

10

20

10

20

180±12 224±15 236±30 490±55

6 Related Work
The importance of learning from data is well appreciated in
probabilistic programming. Along with empirical Bayes, ap-
plicable to probabilistic programming as well as to Bayesian
generative models in general, probabilistic-programming spe-
ciﬁc approaches were proposed. One possibility is to induce
a probabilistic program suited for a particular data set (Liang
et al., 2010; Perov and Wood, 2014; Perov, 2018; Hwang et
al., 2011). A related but different research direction is infer-
ence compilation (Le et al., 2017; Baydin et al., 2019), where
the cost of inference is amortized through learning proposal
distributions from data. Another line of research is concerned
by speeding up inference algorithms by tuning them based on
training data (Eslami et al., 2014; Mansinghka et al., 2018).
Our approach to learning from data in probabilistic programs
is different in that it does not require any particular imple-
mentation of probabilistic programming to be used, nor intro-
spection into the structure of probabilistic programs or infer-

(a) stump & fungus, 10 samples vs. hierarchical

(b) stump & fungus, 20 samples vs. hierarchical

(c) empirical Bayes vs. hierarchical

(d) discrepancy

Figure 4: Educational attainment. Stump-and-fungus with both 10 and 20 samples approximate the hierarchical posterior better
than empirical Bayes.

ence algorithms. Instead, the approach uses inference in ubiq-
uitously adopted hierarchical models for training, and con-
ditioning on observations for incorporation of training out-
comes in inference.

Approximation of a large sample set by a small weighted
subset bears similarity to Bayesian coresets (Huggins et al.,
2016; Campbell and Beronov, 2019; Manousakas et al., 2020;
Zhang et al., 2021) — a family of approaches aiming at
speeding up inference with large datasets. A Bayesian coreset
is a small weighted subset of the original large dataset, with
the promise that inference on the coreset yields the same or
approximately the same posterior. However, there are signif-
icant differences between Bayesian coresets and the setting
in this work. First, in Bayesian coresets, the posterior is un-
known when the coreset is constructed.
In the stump-and-
fungus pattern, the posterior distribution of the hyperparam-
eter is known (as a Monte Carlo approximation) before the
samples are selected and the weights are computed. In partic-
ular, Campbell and Beronov (2019) minimize the KL diver-
gence between the approximate and the exact posterior, while
(6) in this work minimizes the complementary KL divergence
between the exact posterior and its stump-and-fungus approx-
imation. This facilitates a simpler formulation of divergence
minimization. Second, careful selection of samples to be in-

cluded in the coreset is necessitated by high dimensionality
of data in the dataset (Manousakas et al., 2020). However,
even in elaborated hierarchical Bayesian models the group
parameters are low-dimensional, and interdependencies be-
tween multiple hierarchies in cross-classiﬁed models are as-
sumed to be negligible. Because of that, a random draw from
the parameter posterior sufﬁces for stump-and-fungus even if
it might not work in a higher-dimensional setting.

7 Discussion

We presented a probabilistic programming pattern for
Bayesian learning from data. The stump-and-fungus pattern
is easy to understand and simple to implement. When ap-
plied to hierarchical generative models, the pattern allows to
realize learning from data within the Bayesian paradigm, and
results in signiﬁcant improvement in inference performance
on new groups. Even if certain aspects of the pattern can be
improved, the pattern is applicable in its current form to real-
world statistical studies.

References
R´emi Bardenet, Arnaud Doucet, and Chris Holmes. Towards
scaling up Markov chain Monte Carlo: an adaptive sub-

1234567891011121314151617181912345678910111213141516171819group index0.200.150.100.050.000.050.100.15SIDINT1234567891011121314151617181912345678910111213141516171819group index0.600.650.700.750.80VRQ1234567891011121314151617181912345678910111213141516171819group index0.000.050.100.150.200.250.30SC1234567891011121314151617181912345678910111213141516171819group index0.200.150.100.050.000.050.100.15SIDINT1234567891011121314151617181912345678910111213141516171819group index0.6000.6250.6500.6750.7000.7250.7500.775VRQ1234567891011121314151617181912345678910111213141516171819group index0.000.050.100.150.200.25SC1234567891011121314151617181912345678910111213141516171819group index0.200.150.100.050.000.050.100.15SIDINT1234567891011121314151617181912345678910111213141516171819group index0.5750.6000.6250.6500.6750.7000.7250.7500.775VRQ1234567891011121314151617181912345678910111213141516171819group index0.000.050.100.150.200.250.30SCEBS&F, 10 samplesS&F, 20 samples0.000.050.10KS statisticsIn Proceedings of the 31st Interna-
sampling approach.
tional Conference on Machine Learning, pages 405–413,
2014.

R´emi Bardenet, Arnaud Doucet, and Chris Holmes. On
Markov chain Monte Carlo methods for tall data. Journal
of Machine Learning Research, 18(47):1–43, 2017.

Atilim Gunes Baydin, Lei Shao, W. Bhimji, L. Hein-
rich, Lawrence Meadows, Jialin Liu, Andreas Munk,
Saeid Naderiparizi, Bradley Gram-Hansen, Gilles Louppe,
Mingfei Ma, X. Zhao, P. Torr, V. Lee, K. Cranmer, Prabhat,
and Frank D. Wood. Etalumis: bringing probabilistic pro-
gramming to scientiﬁc simulators at scale. Proceedings of
the International Conference for High Performance Com-
puting, Networking, Storage and Analysis, 2019.

Trevor Campbell and Boyan Beronov. Sparse variational in-
In H. Wallach,
ference: Bayesian coresets from scratch.
H. Larochelle, A. Beygelzimer, F. d’Alch´e Buc, E. Fox,
and R. Garnett, editors, Advances in Neural Information
Processing Systems, volume 32. Curran Associates, Inc.,
2019.

George Casella. An introduction to empirical bayes data anal-

ysis. The American Statistician, 39(2):83–87, 1985.

Ali Eslami, Daniel Tarlow, Pushmeet Kohli, and John Winn.
In
Just-in-time learning for fast and ﬂexible inference.
NIPS’14 Proceedings of the 27th International Conference
on Neural Information Processing Systems, pages 154–
162. MIT Press Cambridge, December 2014.

A. Gelman, J.B. Carlin, H.S. Stern, D.B. Dunson, A. Vehtari,
and D.B. Rubin. Bayesian Data Analysis. Chapman &
Hall/CRC Texts in Statistical Science. CRC Press, 2013.
Noah D Goodman, Joshua B. Tenenbaum, and the Prob-
Mods contributors. Probabilistic Models of Cognition.
World Wide Web, second edition, 2016. electronic; re-
trieved: 2019-4-29.

Matthew D. Hoffman and Andrew Gelman. The No-U-Turn
sampler: adaptively setting path lengths in Hamiltonian
Monte Carlo. arXiv:1111.4246, 2011.

Jonathan Huggins, Trevor Campbell, and Tamara Broder-
ick. Coresets for scalable bayesian logistic regression. In
D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Gar-
nett, editors, Advances in Neural Information Processing
Systems, volume 29. Curran Associates, Inc., 2016.

I. Hwang, Andreas Stuhlm¨uller, and Noah D. Goodman. In-
ducing probabilistic programs by Bayesian program merg-
ing. ArXiv, abs/1110.5667, 2011.

Anoop Korattikara, Yutian Chen, and Max Welling. Auster-
ity in MCMC land: Cutting the Metropolis-Hastings bud-
get. In Proceedings of the 31st International Conference
on Machine Learning, pages 181–189, 2014.

Tuan Anh Le, Atilim Gunes Baydin, and Frank Wood.

In-
ference compilation and universal probabilistic program-
ming. In Proceedings of the 34th International Conference
on Machine Learning, pages 1338–1348, 2017.

Percy Liang, Michael I. Jordan, and Dan Klein. Learning Pro-
grams: A Hierarchical Bayesian Approach. In Proceedings

of the 27th International Conference on Machine Learning,
pages 639–646. Omnipress, 2010.

Dougal Maclaurin and Ryan P. Adams. Fireﬂy Monte Carlo:
Exact MCMC with subsets of data. In Proceedings of the
30th Conference on Uncertainty in Artiﬁcial Intelligence,
pages 543–552, 2014.

Dionysis Manousakas, Zuheng Xu, Cecilia Mascolo, and
Trevor Campbell.
In
H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and
H. Lin, editors, Advances in Neural Information Process-
ing Systems, volume 33, pages 14950–14960. Curran As-
sociates, Inc., 2020.

Bayesian pseudocoresets.

Vikash K. Mansinghka, Ulrich Schaechtle, Shivam Handa,
Alexey Radul, Yutian Chen, and Martin Rinard. Probabilis-
tic programming with programmable inference. SIGPLAN
Not., 53(4):603–616, June 2018.

Richard McElreath. Statistical Rethinking. CRC Press, 2nd

edition, 2020.

Radford M. Neal. Mcmc using hamiltonian dynamics. Chap-
ter 5 of the Handbook of Markov Chain Monte Carlo, 2011.
Lindsay Paterson. Socio-economic status and educational
attainment: A multi-dimensional and multi-level study.
Evaluation & Research in Education, 5(3):97–121, 1991.
Yura N. Perov and Frank D. Wood. Learning probabilistic

programs, 2014.

Yura Perov. Inference over programs that make predictions,

2018.

Matias Quiroz, Mattias Villani, Robert Kohn, Minh-Ngoc
Tran, and Khue-Dung Dang. Subsampling mcmc — an in-
troduction for the survey statistician. Sankhya A, 80(1):33–
69, Dec 2018.

Herbert Robbins. Asymptotically subminimax solutions of
compound statistical decision problems. In Proceedings of
the Second Berkeley Symposium on Mathematical Statis-
tics and Probability, pages 131–149, Berkeley, Calif.,
1951. University of California Press.

Herbert Robbins. An Empirical Bayes Approach to Statistics,
pages 388–394. Springer New York, New York, NY, 1992.
Robert Tarone. The use of historical control information in
testing for a trend in proportions. Biometrics, 38(1):215–
220, 1982.

David Tolpin, Yuan Zhou, Tom Rainforth, and Hongseok
Yang. Probabilistic programs with stochastic conditioning,
2021.

David Tolpin. Deployable probabilistic programming.

In
Proceedings of the 2019 ACM SIGPLAN International
Symposium on New Ideas, New Paradigms, and Reﬂections
on Programming and Software, pages 1–16, 2019.

Jacky Zhang, Rajiv Khanna, Anastasios Kyrillidis, and Sanmi
Koyejo. Bayesian coresets: Revisiting the nonconvex op-
timization perspective.
In Arindam Banerjee and Kenji
Fukumizu, editors, Proceedings of The 24th International
Conference on Artiﬁcial Intelligence and Statistics, volume
130 of Proceedings of Machine Learning Research, pages
2782–2790. PMLR, 13–15 Apr 2021.

