0
2
0
2

t
c
O
8
2

]

G
L
.
s
c
[

1
v
6
5
0
5
1
.
0
1
0
2
:
v
i
X
r
a

Self-Awareness In Intelligent Vehicles:
Experience based Abnormality Detection

Divya Kanapram 1,3, Pablo Marin-Plaza 2, Lucio Marcenaro 1, David Martin 2
Arturo de la Escalera 2, Carlo Regazzoni1

1University of Genova, Italy. divya.kanapram@ginevra.dibe.unige.it,
{carlo.regazzoni,lucio.marcenaro}@unige.it
2Universidad Carlos III, Leganes Spain. {pamarinp, dmgomez, escalera}@ing.uc3m.es
3Queen Mary University of London, UK.

Abstract. The evolution of Intelligent Transportation System in re-
cent times necessitates the development of self-driving agents: the self-
awareness consciousness. This paper aims to introduce a novel method
to detect abnormalities based on internal cross-correlation parameters
of the vehicle. Before the implementation of Machine Learning, the de-
tection of abnormalities were manually programmed by checking every
variable and creating huge nested conditions that are very diï¬ƒcult to
track. Nowadays, it is possible to train a Dynamic Bayesian Network
(DBN) model to automatically evaluate and detect when the vehicle is
potentially misbehaving. In this paper, diï¬€erent scenarios have been set
in order to train and test a switching DBN for Perimeter Monitoring
Task using a semantic segmentation for the DBN model and Hellinger
Distance metric for abnormality measurements.

Keywords: Autonomous vehicles, Intelligent Transportation System(ITS),
Dynamic Bayesian Network(DBN), Hellinger distance, Abnormality de-
tection.

1

Introduction

The self-awareness ï¬eld is vast in terms of detecting abnormalities in the ï¬eld
of Intelligent Vehicles [22]. It is possible to classify critical, medium, or minor
abnormalities by deï¬ning the line between normal and abnormal behaviour with
the help of top design architectures. The problem of self-awareness systems is
to measure every sensor, data acquired, and behavior of the system at every
moment, comparing each measurement with the nominal range. Due to the huge
amount of data, these tasks are not easy and becomes typically dead-end in big
projects where the re-usability is not possible. Furthermore, it is possible to be
unaware of situations where the vehicle is not working in the normal ranges for
a very short period of time. Self-awareness management could be divided into
three main categories which are hardware, software, and behavior. The ï¬rst cat-
egory is based on the detection of malfunctions on electronic devices, actuators,
sensors, CPUs, communication, etc. The second category focuses on software

 
 
 
 
 
 
2

Divya et al.

requirements where the most important measurements for message delivery are
time, load, bottlenecks, delays, heartbeat, among others. Finally, the last self-
awareness ï¬eld analyzes the behavior of the vehicle which is related to the per-
formance of the task assigned at each moment such as keep in lane, lane change,
intersection management, roundabout management, overtaking, stop, etc. Ac-
cordingly, the management of self-awareness is a cross-layer problem where every
manager should be built subsequently to the other layers to create a coherent
self-awareness system [20].

To reduce the amount of process eï¬€ort in intelligent self-awareness system,
the emergent techniques in Machine Learning allow the creation of models using
Dynamic Bayesian Networks (DBN) to automatize this process [14]. The novelty
of this paper is the use of DBN models to generate a cross-correlation between
a pair of internal features of the vehicle using a Hellinger distance metric for ab-
normality detection. Finally, compared the performance of diï¬€erent DBN models
in order to select the best model for abnormality detection.

The remainder of this paper is organized as follows. Section 2 presents a
survey of the related work. In section 3, described the proposed method, deï¬ning
principles exploited in the training phase and the steps involved in the test phase
for detecting the abnormality. Section 4 summarizes the experimental setup in
addition to the description of the research platform used. Section 5 gathered the
results (i.e., abnormality measurements) from pair based DBNs for each vehicle
and compared the results, and ï¬nally, section 6 concludes the paper.

2 State of the art
This section describes some of the related work regarding the development of
self-awareness in agents. In [4], the authors propose an approach to develop a
multilevel self-awareness model learned from multisensory data of an agent. Such
a learned model allows the agent to detect abnormal situations present in the
surrounding environment. In another work [19], the learning of the self-awareness
model for autonomous vehicles based on the data collected from human driving.
On the other hand, in [13], the authors propose a new architecture for mobile
robots with a model for risk assessment and decision making when detecting dif-
ï¬culties in the autonomous robot design. In [21], the authors proposed a model
of driving behavior awareness (DBA) that can infer driving behaviours such as
lane change. In all the above works either used the data from one entity or the
objective was limited; for example in [21] the objective was to detect lane change
either on left or right side of the considered vehicles. In this work, we have con-
sidered the data from the real vehicles and developed pair based switching DBN
models for each vehicle and ï¬nally made the performance comparison among
diï¬€erent DBNs learned.

3 Proposed method
This section discusses how to develop â€œintelligenceâ€ and â€œawarenessâ€ into ve-
hicles to generate â€œSelf-aware intelligent vehicles.â€ The ï¬rst step is to perform
synchronization operation over the acquired multisensory data to make them
synchronized in time in a way to match their time stamps. The data sets col-
lected for training and testing are heterogeneous, and two vehicles are involved

Self-Awareness in IV: Experience Based Abnormality Detection

3

in the considered scenarios. The observed multisensory data from the vehicles
are partitioned into diï¬€erent groups to learn a pair-based switching DBN model
for each pair-based vehicle feature. Then compare the performances to qualify
the best pair-based feature for automatic detection of abnormality. Switching
DBNs are probabilistic models to integrate observations received from multiple
sensors in order to understand the environment where they operate and take
appropriate actions in diï¬€erent situations. The proposed method is divided into
two phases: oï¬„ine training and online testing. In the oï¬„ine training phase, learn
DBNs from the experiences of the vehicle in their normal behaviour. In the next
phase, online testing, we have used a dynamic data series that are collected from
the vehicles while they pass through diï¬€erent experiences than in the training
phase. Accordingly, a ï¬lter called Markov Jump Particle Filter (MJPF) applied
to the learned DBN models to estimate the future states of the vehicles and
ï¬nally detects the abnormality situations present in the environment.

3.1 Oï¬„ine training phase

In this phase, learn switching DBNs from the datasets collected from the expe-
riences of the vehicle in their normal behaviour. The various steps involved in
learning a DBN model are described below.
Generalized states The intelligent vehicles used in this work are equipped with
one lidar of 16 layers and 360 degrees of Field of view(FOV), a stereo camera,
and encoder devices to monitor diï¬€erent tasks being performed. In this work, it
is assumed that each vehicle is aware of the other vehicle by its communication
scheme and cooperation skills. By considering the vehicles endowed with a cer-
tain amount of sensors that monitors its activity, it is possible to deï¬ne Z c
k as
any combination (indexed by c) of the available measurements in a time instant
k. Let X c
k + Ï‰k;
where Ï‰k represents the sensor noise. The generalized states of a sensory data
combination c can be deï¬ned as:
k = [X c
k

k be the states related to measurements Z c

k, such that: Z c

k Â· Â· Â· X c,(L)

k = X c

Ë™X c
k

X c

Â¨X c

](cid:124),

(1)

k

where (L) indicates the L-th time derivative of the state.

Vocabulary generation and state transition matrix calculation In order
to learn the desecrate level of the DBN (i.e., the orange outlined box in Fig.
1), it is required to map the generalized states into a set of nodes. We have
used a clustering algorithm called Growing Neural Gas (GNG) to group these
generalized states and to obtain nodes. In GNG, the learning is continuous, and
the addition or removal of nodes is automated [8]. These are the main reasons
to choose GNG algorithm over other clustering algorithms such as K-means [9]
or self-organizing map (SOM) [11]. The output of each GNG consists of a set
of nodes that encode constant behaviours for speciï¬c sensory data combinations
time derivative order. In other words, at a time instant, each GNG takes the
data related to a single time derivative X c,(i)
k and cluster it with the same
time derivative data acquired in previous time instances. The nodes associated
with each GNG can be called as a set of letters containing the main behaviours

âˆˆ X c

k

4

Divya et al.

of generalized states. The collection of nodes encoding i-th order derivatives in
an observed data combination c is deï¬ned as follows:
, Â· Â· Â· Â¯X (i),c
Ac

(2)

}

i = { Â¯X (i),c

, Â¯X (i),c
2

1

P c
i

where P c
i is the number of nodes in the GNG associated to the i-th order deriva-
tive of data in data combination c. Each node in a GNG represents the centroids
of associated data point clusters. By taken into consideration all the possible
combinations of centroids obtained from GNGs, we can get a set of words, that
deï¬ne generalized states in an entirely semantic way. The obtained words can
form a dictionary and can be deï¬ned as:

Dc = {Î², Ë™Î², Â· Â· Â· Î²(L)}

(3)

c âˆˆ Ac

where Î²(i)
i . Dc contains all possible combinations of discrete generalized
states. Dc is a high-level hierarchy variable that explains the system states from
a semantic viewpoint. In this work, we have only considered states, and itâ€™s ï¬rst-
order derivatives.
Furthermore, estimated the state transition matrices based on the timely evolu-
tion of such letters and words. The state transition matrix is a matrix that con-
tains the transition probability between the discrete level nodes of the switching
DBN shown in Fig. 1. When the ï¬rst data emission occurs, the state transition
matrix provides the probability of the next discrete level, i.e., the probability of
activation of a node from the GNG associated with the ï¬rst-order derivatives of
the states. The vocabulary (i.e.,letters, words and dictionary and the transition
matrices constitute the discrete level of the DBN model.

DBN model Learning All the previous steps are the step by step learning
process of the switching DBNs by each entity taken into consideration. The
number of DBNs learned by each entity in the network can be written as:

DBN m = {DBN1, Â· Â· Â· , DBNn}.

(4)

where m represents the mth vehicle in the network and n is the total number
DBN learned by the mth vehicle. The same DBN architecture is considered for
making inferences with diï¬€erent sensory data combinations belong to diï¬€erent
vehicles. The learned DBN can be represented as shown in the Fig.1. The DBN
has mainly three levels such as measurements, continuous and discrete levels.

3.2 Online test phase
In this phase, we have proposed to apply a dynamic switching model called
Markov Jump Particle Filter (MJPF) [3] to make inferences on the learned DBN
models. MJPF is a mixed approach with particles inside each Kalman ï¬lter. The
MJPF is able to predict and estimate continuous and discrete future states and
to detect deviations from the normal model. In MJPF, we use Kalman Filter
(KF) in state-space and Particle Filter (PF) in super state space in Fig. 1.
Abnormality detection and complementarity check In probability the-
ory, a statistical distance quantiï¬es the distance between two statistical objects,
which can be two random variables, or two probability distributions, etc. Some
important statistical distances include: Bhattacharya distance [6], Hellinger Dis-
tance [17], Jensenâ€“Shannon divergence [7], Kullbackâ€“Leibler (KL) divergence

Self-Awareness in IV: Experience Based Abnormality Detection

5

Fig. 1: Proposed DBN

[10] etc. and they are the distances generally used between two distributions.
Although, the HD is deï¬ned between vectors having only positive or zero ele-
ments [1]. The datasets in this work are normalized, so the values vary between
zero and one; there arenâ€™t any negative values. Moreover, HD is symmetric com-
pared to KL divergence. By these reasons, HD is more appropriate than using
other distance metrics as abnormality measure. Moreover, the works in [15] and
[2] used HD as an abnormality measurement.
Abnormality measurement can be deï¬ned as the distance between predicted state
values and the observed evidence. Accordingly, let p(X c
kâˆ’1) be the predicted
generalized states and p(Zk|X m
k ) be the observation evidence. The HD can be
written as:

k|X c

k = (cid:112)1 âˆ’ Î»c
Î¸c
k,

where Î»c

k is deï¬ned as the Bhattacharyya coeï¬ƒcient [5], such that:

(cid:90) (cid:113)

Î»c
k =

p(X c

k|X c

kâˆ’1)p(Z c

k|X c

k) dX c
k.

(5)

(6)

When a given experience in evaluation an abnormality measurement obtains at
each time instant, and can be seen in the equation (5). The variable Î¸c
k âˆˆ [0, 1],
where values close to 0 indicate that measurements match with predictions;
whereas values close to 1 reveal the presence of an abnormality. After calculating
the abnormality measures by HD, it is possible to check the complementarity
among diï¬€erent DBN models learned.

4 Experimental Setup

In order to validate the proposed method, it has been used two intelligent re-
search platform called iCab (Intelligent Campus AutomoBile)[16] (see Fig.2a)

ğ‘(ğ·ğ‘˜+1/ğ·ğ‘˜)Particle filterKalman filter Vocabularyğ´0,ğ‘˜ğ´ğ¿,ğ‘˜ğ´0,ğ‘˜+1ğ´ğ¿,ğ‘˜+1ğ‘ğ‘˜+1ğ‘ğ‘˜ğ‘¿ğ‘˜ğ‘¿ğ‘˜+1ğ·ğ‘˜ğ·ğ‘˜+1ğ‘(ğ´ğ¿,ğ‘˜+1/ğ´ğ¿,ğ‘˜)ğ‘(ğ‘¿ğ‘˜+1/ğ‘¿ğ‘˜)6

Divya et al.

with autonomous capabilities. To process and navigate through the environment,
the vehicles count with two powerful computers along with the screen for debug-
ging and Human-Machine Interaction (HMI) purposes. The software prototyping
tool used is ROS [18].

(a) The autonomous vehicles (iCab)

(b) The environment

Fig. 2: The agents and the environment used for the experiments.

The data sets collected with the two iCab vehicles are synchronized in order
to observe the vehicles as diï¬€erent entities in a heterogeneous way to match their
time stamps. The intercommunication scheme is proposed in [12] where both
vehicles share all its information over the network by a Virtual Private Net-
work(VPN). For this experiment, as long as the synchronization level reaches
the nanoseconds, the recorded dataset in both vehicles has been merged and
ordered using the timestamp generated by the clock on each vehicle which has
been previously conï¬gured with a Network Time Protocol (NTP) tool called
Chrony. Both vehicles perform a PMT task which consists of the autonomous
movement of platooning around a square building (see Fig.2b). The data gen-
erated from the lidar odometry such as the ego-motion of the vehicle and the
diï¬€erent combinations of the control variables such as steering angle, rotor ve-
locity and power of the rotor are considered the main metrics to learn and test
the models. Moreover, it aims to detect the unseen dynamics of the vehicles with
the proposed method.

4.1 Perimeter Monitoring Task (PMT)
In order to generate the required data for learning and detect abnormalities,
both vehicles perform a rectangular trajectory in a platooning mode. The leader
just follows the rectangular path and the follower receives the path and keep the
desired distance with the leader. This task has been divided into two diï¬€erent
scenarios.

â€“ Scenario I: Both vehicles perform the platooning operation by following
a rectangular trajectory in a closed environment, as shown in Fig. 2b, four
laps in total by recording the ego-motion, stereo camera images, lidar Point
Cloud Data, encoders, and self-state. Notice that the GPS has troubles to
acquire good signal because of the urban canyon. Fig.3a and Fig.4a show
the plots of odometry data for the perimeter monitoring task for iCab1 and
iCab2 respectively. Moreover, Fig.5 shows the steering angle w.r.t the iCab1â€™s

Self-Awareness in IV: Experience Based Abnormality Detection

7

(a) Perimeter monitoring

(b) Emergency stop

Fig. 3: Odometry data for iCab1

(a) Perimeter monitoring

(b) Emergency stop

Fig. 4: Odometry data for iCab2

position(Fig.5a) and rotor velocity w.r.t the iCab1â€™s position(Fig.5b). The
rotor power data plotted w.r.t iCab1â€™s position is shown in Fig.6.

â€“ Scenario II: Both vehicles perform the same experiment, but now a pedes-
trian crosses in front of the leader vehicle(i.e., iCab1). When the leader
vehicle detects the pedestrian, automatically executes a stop and wait until
the pedestrian fully crosses and move out from the danger zone. Meanwhile,
the follower (i.e., iCab2) detects the stop of the leader and stops at a cer-
tain distance. When the leader continues the PMT, the follower mimics the
action of the leader. Fig.3b and Fig.4b show the plots of odometry data for
the emergency stop criteria for iCab1 and iCab2 respectively.

5 Results
As explained in the previous section, there are two diï¬€erent scenarios taken into
consideration with two vehicles. Moreover, the data combinations from odometry
and control of vehicles have been treated independently and ï¬nally compared the

-20-10010200510152025303540Odometry trajectory for iCab1-20-10010200510152025303540Emergency stop trajectory for iCab1Emergency stop-20-10010200510152025303540Odometry trajectory for iCab2-20-10010200510152025303540Emergency stop trajectory for iCab2Emergency stop8

Divya et al.

(a) Steering angle(s) w.r.t position

(b) Velocity(v ) w.r.t position

Fig. 5: Control data for iCab1 for perimeter monitoring task

Fig. 6: Rotor power(p) w.r.t position for iCab1 for perimeter monitoring task

abnormality measures to understand the correlation between them. We set the
abnormality threshold to 0.4, considering the average Hellinger distance value
of 0.2 when vehicles operate in normal conditions. The DBN models are trained
over the scenario I based on PMT where no pedestrians are crossing in front
of the vehicles. As said at the beginning of this paper, one of the objectives is
the automatic extraction of abnormalities by learning from experiences. Hence,
for PMT, the DBN models have been trained to extract the HD by pairing
two diï¬€erent variables: Steering Angle-Power (SP), Velocity-Power (VP) and
Steering Angle-Velocity (SV).
Testing phase The switching DBN model in this work is designed for the
control part of the vehicles. However, we have considered odometry data and
tested the performance of the learned DBN. Fig. 7 shows the plots of abnormality
measures by considering odometry data for the vehicle leader (iCab1) and the
vehicle follower (iCab2), respectively. During the interval (cyan shaded area)

Self-Awareness in IV: Experience Based Abnormality Detection

9

while pedestrian passes and vehicle stops, there isn'â€™t any signiï¬cant diï¬€erence
in HD value for iCab1 (leader) as well as iCab2 (follower). This behaviour is
due to the fact that, during that interval the vehicles always inside the normal
trajectory range. However, there are speciï¬c intervals when the vehicle deviates
from the normal trajectory range, and the HD measures provided a high value of
about 0.2 during those intervals. So the learned DBN model was able to predict
if any trajectory deviation occurred.

â€“ Steering Angle-Velocity (SV): It is necessary to check that the HD is
working in both directions when the metrics involved reï¬‚ect abnormal be-
haviour such as power and velocity and in cases when the metric used does
not notice when there is an abnormal behavior such as steering angle. For
this reason, the pair (S-V) shown in ï¬g. 8 displays that this pair is not de-
tecting abnormalities when a pedestrian crosses in front of the vehicle (cyan
shaded), which is expected.

â€“ Steering Angle-Power (SP): Fig. 9 shows that the HD is high when
a pedestrian is crossing in front of the leader vehicle (iCab1). This high
value is considered as an abnormality in the behaviour of the leader, and
as it is expected, the follower (iCab2) also gives an abnormal behaviour
for the platooning task. However, the HD measures for the follower is not
as signiï¬cant as the leader, because the follower was not doing emergence
break rather reducing its speed until reaching the minimum distance with
the leader.

â€“ Velocity-Power (VP): The last pair tested is velocity and the power con-
sumption which are highly related. In Fig. 10, it is shown the moment when
a pedestrian cross in front of the leader in cyan colour, which match with the
highest value of the HD. For the follower vehicle, the abnormality measure-
ment is very signiï¬cant due to the new performance of the vehicle against
the emergency brake of the leader. The consecutive peaks in the HD are
caused by the high acceleration when the leader vehicle starts moving, but
the current distance between them is still lower than the desired. Next peak
in HD is caused by the acceleration of the leader and the emergency stop
in the follower due to the pedestrian. To summarize, the switching DBN
learned from SP and VP data were able to predict the unusual situations
present; however, odometry and SV combination of control was not showing
good combination to detect abnormal behavior.

6 Conclusion and future work
It has been proved that the HD for automatically detecting abnormalities in a
DBN model learned from experiences, is a possible and plausible solution. The
main idea of the proposed method has been demonstrated with the training and
testing phase, and the results support that the methodology applied is more
useful instead of checking and delimiting each metric of the vehicle depending
on the event and deï¬ning each upper and lower limits in which an abnormal
behaviour is considered.
The future work of this new approach could be extended by establishing com-
munication between the objects involved in the tasks and develop collective

10

Divya et al.

Fig. 7: Abnormality measurements for odometry: (a) iCab1, (b) iCab2

Fig. 8: Abnormality measurements for control (SV): (a) iCab1, (b) iCab2

Fig. 9: Abnormality measurements for control (SP): (a) iCab1, (b) iCab2

(a)

(b)

(a)

(b)

(a)

(b)

(a)

(b)

Fig. 10: Abnormality measurements for control (VP): (a) iCab1, (b) iCab2

010020030040050060070080000.20.40.60.81Odometry iCab1010020030040050060070080000.20.40.60.81Odometry iCab2010020030040050060070080000.20.40.60.81Control SV iCab1010020030040050060070080000.20.40.60.81Control SV iCab2010020030040050060070080000.20.40.60.81Control SP iCab1010020030040050060070080000.20.40.60.81Control SP iCab2010020030040050060070080000.20.40.60.81Control VP iCab1010020030040050060070080000.20.40.60.81Control VP iCab2awareness models. Such models can make the mutual prediction of the future
states of the objects involved in the task and enrich the contextual awareness
where they operate. Another direction could be the development of an optimized
model from the diï¬€erent feature combinations that can be used for the future
state predictions of the considered entities. Additionally, the classiï¬cation of de-
tected abnormality by considering diï¬€erent test scenarios and comparing the
performance of abnormality detection by using diï¬€erent metric as abnormality
measure could be considered.

Acknowledgement
Supported by SEGVAUTO 4.0 P2018/EMT-4362) and CICYT projects (TRA2015-
63708-R and TRA2016-78886-C3-1-R).

Bibliography

[1] Abdi, H., Salkind, N.J.: Encyclopedia of measurement and statistics. Thou-
sand Oaks, CA: Sage. Agresti, A.(1990) Categorical data analysis., New
York: Wiley. Agresti, A.(1992) A survey of exact inference for contingency
tables. Statist Sci 7, 131â€“153 (2007)

[2] Baydoun, M., Campo, D., Kanapram, D., Marcenaro, L., Regazzoni, C.S.:
Prediction of multi-target dynamics using discrete descriptors: an interac-
tive approach. In: ICASSP 2019-2019 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP). pp. 3342â€“3346. IEEE
(2019)

[3] Baydoun, M., Campo, D., Sanguineti, V., Marcenaro, L., Cavallaro, A.,
Regazzoni, C.: Learning switching models for abnormality detection for au-
tonomous driving. In: 2018 21st International Conference on Information
Fusion (FUSION). pp. 2606â€“2613. IEEE (2018)

[4] Baydoun, M., Ravanbakhsh, M., Campo, D., Marin, P., Martin, D.,
Marcenaro, L., Cavallaro, A., Regazzoni, C.S.: A multi-perspective ap-
proach to anomaly detection for self-aware embodied agents. arXiv preprint
arXiv:1803.06579 (2018)

[5] Bhattacharyya, A.: On a measure of divergence between two statistical pop-
ulations deï¬ned by their probability distributions. Bulletin of the Calcutta
Mathematical Society 35, 99â€“109 (1943)

[6] Bhattacharyya, A.: On a measure of divergence between two statistical pop-
ulations deï¬ned by their probability distributions. Bull. Calcutta Math. Soc.
35, 99â€“109 (1943)

[7] Endres, D.M., Schindelin, J.E.: A new metric for probability distributions.

IEEE Transactions on Information theory (2003)

[8] Fritzke, B.: A growing neural gas network learns topologies. In: Advances

in neural information processing systems. pp. 625â€“632 (1995)

[9] Hartigan, J.A., Wong, M.A.: Algorithm as 136: A k-means clustering algo-
rithm. Journal of the Royal Statistical Society. Series C (Applied Statistics)
28(1), 100â€“108 (1979)

12

Divya et al.

[10] Hershey, J.R., Olsen, P.A.: Approximating the kullback leibler divergence
between gaussian mixture models. In: 2007 IEEE International Conference
on Acoustics, Speech and Signal Processing-ICASSPâ€™07. vol. 4, pp. IVâ€“317.
IEEE (2007)

[11] Kohonen, T.: The self-organizing map. Proceedings of the IEEE 78(9),

1464â€“1480 (1990)

[12] Kokuti, A., Hussein, A., MarÂ´Ä±n-Plaza, P., de la Escalera, A., GarcÂ´Ä±a, F.: V2x
communications architecture for oï¬€-road autonomous vehicles. In: Vehicular
Electronics and Safety (ICVES), 2017 IEEE International Conference on.
pp. 69â€“74. IEEE (2017)

[13] Leite, A., Pinto, A., Matos, A.: A safety monitoring model for a faulty

mobile robot. Robotics 7(3), 32 (2018)

[14] Lewis, P.R., Platzner, M., Rinner, B., TÃ¸rresen, J., Yao, X.: Self-Aware

Computing Systems. Springer (2016)

decision making: An

[15] Lourenzutti, R., Krohling, R.A.: The hellinger distance

in mul-
ticriteria
and
todim methods. Expert Syst. Appl. 41(9), 4414â€“4421 (Jul 2014).
http://dx.doi.org/10.1016/j.
https://doi.org/10.1016/j.eswa.2014.01.015,
eswa.2014.01.015

illustration

topsis

the

to

[16] Marin-Plaza, P., Hussein, A., Martin, D., Escalera, A.d.l.: Global and lo-
cal path planning study in a ros-based research platform for autonomous
vehicles. Journal of Advanced Transportation 2018 (2018)

[17] Pardo, L.: Statistical inference based on divergence measures. Chapman and

Hall/CRC (2005)

[18] Quigley, M., Conley, K., Gerkey, B., Faust, J., Foote, T., Leibs, J., Wheeler,
R., Ng, A.Y.: Ros: an open-source robot operating system. In: ICRA work-
shop on open source software. vol. 3, p. 5. Kobe, Japan (2009)

[19] Ravanbakhsh, M., Baydoun, M., Campo, D., Marin, P., Martin, D., Marce-
naro, L., Regazzoni, C.S.: Learning multi-modal self-awareness models for
autonomous vehicles from human driving. arXiv preprint arXiv:1806.02609
(2018)

[20] Schlatow, J., MÂ¨ostl, M., Ernst, R., Nolte, M., Jatzkowski, I., Maurer, M.,
Herber, C., Herkersdorf, A.: Self-awareness in autonomous automotive sys-
tems. In: Proceedings of the Conference on Design, Automation & Test
in Europe. pp. 1050â€“1055. European Design and Automation Association
(2017)

[21] Xie, G., Gao, H., Huang, B., Qian, L., Wang, J.: A driving behavior aware-
ness model based on a dynamic bayesian network and distributed genetic
algorithm. International Journal of Computational Intelligence Systems
11(1), 469â€“482 (2018)

[22] Xiong, G., Zhou, P., Zhou, S., Zhao, X., Zhang, H., Gong, J., Chen, H.:
Autonomous driving of intelligent vehicle bit in 2009 future challenge of
china. In: Intelligent Vehicles Symposium (IV), 2010. pp. 1049â€“1053. IEEE
(2010)

