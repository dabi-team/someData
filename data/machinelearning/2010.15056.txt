0
2
0
2

t
c
O
8
2

]

G
L
.
s
c
[

1
v
6
5
0
5
1
.
0
1
0
2
:
v
i
X
r
a

Self-Awareness In Intelligent Vehicles:
Experience based Abnormality Detection

Divya Kanapram 1,3, Pablo Marin-Plaza 2, Lucio Marcenaro 1, David Martin 2
Arturo de la Escalera 2, Carlo Regazzoni1

1University of Genova, Italy. divya.kanapram@ginevra.dibe.unige.it,
{carlo.regazzoni,lucio.marcenaro}@unige.it
2Universidad Carlos III, Leganes Spain. {pamarinp, dmgomez, escalera}@ing.uc3m.es
3Queen Mary University of London, UK.

Abstract. The evolution of Intelligent Transportation System in re-
cent times necessitates the development of self-driving agents: the self-
awareness consciousness. This paper aims to introduce a novel method
to detect abnormalities based on internal cross-correlation parameters
of the vehicle. Before the implementation of Machine Learning, the de-
tection of abnormalities were manually programmed by checking every
variable and creating huge nested conditions that are very diﬃcult to
track. Nowadays, it is possible to train a Dynamic Bayesian Network
(DBN) model to automatically evaluate and detect when the vehicle is
potentially misbehaving. In this paper, diﬀerent scenarios have been set
in order to train and test a switching DBN for Perimeter Monitoring
Task using a semantic segmentation for the DBN model and Hellinger
Distance metric for abnormality measurements.

Keywords: Autonomous vehicles, Intelligent Transportation System(ITS),
Dynamic Bayesian Network(DBN), Hellinger distance, Abnormality de-
tection.

1

Introduction

The self-awareness ﬁeld is vast in terms of detecting abnormalities in the ﬁeld
of Intelligent Vehicles [22]. It is possible to classify critical, medium, or minor
abnormalities by deﬁning the line between normal and abnormal behaviour with
the help of top design architectures. The problem of self-awareness systems is
to measure every sensor, data acquired, and behavior of the system at every
moment, comparing each measurement with the nominal range. Due to the huge
amount of data, these tasks are not easy and becomes typically dead-end in big
projects where the re-usability is not possible. Furthermore, it is possible to be
unaware of situations where the vehicle is not working in the normal ranges for
a very short period of time. Self-awareness management could be divided into
three main categories which are hardware, software, and behavior. The ﬁrst cat-
egory is based on the detection of malfunctions on electronic devices, actuators,
sensors, CPUs, communication, etc. The second category focuses on software

 
 
 
 
 
 
2

Divya et al.

requirements where the most important measurements for message delivery are
time, load, bottlenecks, delays, heartbeat, among others. Finally, the last self-
awareness ﬁeld analyzes the behavior of the vehicle which is related to the per-
formance of the task assigned at each moment such as keep in lane, lane change,
intersection management, roundabout management, overtaking, stop, etc. Ac-
cordingly, the management of self-awareness is a cross-layer problem where every
manager should be built subsequently to the other layers to create a coherent
self-awareness system [20].

To reduce the amount of process eﬀort in intelligent self-awareness system,
the emergent techniques in Machine Learning allow the creation of models using
Dynamic Bayesian Networks (DBN) to automatize this process [14]. The novelty
of this paper is the use of DBN models to generate a cross-correlation between
a pair of internal features of the vehicle using a Hellinger distance metric for ab-
normality detection. Finally, compared the performance of diﬀerent DBN models
in order to select the best model for abnormality detection.

The remainder of this paper is organized as follows. Section 2 presents a
survey of the related work. In section 3, described the proposed method, deﬁning
principles exploited in the training phase and the steps involved in the test phase
for detecting the abnormality. Section 4 summarizes the experimental setup in
addition to the description of the research platform used. Section 5 gathered the
results (i.e., abnormality measurements) from pair based DBNs for each vehicle
and compared the results, and ﬁnally, section 6 concludes the paper.

2 State of the art
This section describes some of the related work regarding the development of
self-awareness in agents. In [4], the authors propose an approach to develop a
multilevel self-awareness model learned from multisensory data of an agent. Such
a learned model allows the agent to detect abnormal situations present in the
surrounding environment. In another work [19], the learning of the self-awareness
model for autonomous vehicles based on the data collected from human driving.
On the other hand, in [13], the authors propose a new architecture for mobile
robots with a model for risk assessment and decision making when detecting dif-
ﬁculties in the autonomous robot design. In [21], the authors proposed a model
of driving behavior awareness (DBA) that can infer driving behaviours such as
lane change. In all the above works either used the data from one entity or the
objective was limited; for example in [21] the objective was to detect lane change
either on left or right side of the considered vehicles. In this work, we have con-
sidered the data from the real vehicles and developed pair based switching DBN
models for each vehicle and ﬁnally made the performance comparison among
diﬀerent DBNs learned.

3 Proposed method
This section discusses how to develop “intelligence” and “awareness” into ve-
hicles to generate “Self-aware intelligent vehicles.” The ﬁrst step is to perform
synchronization operation over the acquired multisensory data to make them
synchronized in time in a way to match their time stamps. The data sets col-
lected for training and testing are heterogeneous, and two vehicles are involved

Self-Awareness in IV: Experience Based Abnormality Detection

3

in the considered scenarios. The observed multisensory data from the vehicles
are partitioned into diﬀerent groups to learn a pair-based switching DBN model
for each pair-based vehicle feature. Then compare the performances to qualify
the best pair-based feature for automatic detection of abnormality. Switching
DBNs are probabilistic models to integrate observations received from multiple
sensors in order to understand the environment where they operate and take
appropriate actions in diﬀerent situations. The proposed method is divided into
two phases: oﬄine training and online testing. In the oﬄine training phase, learn
DBNs from the experiences of the vehicle in their normal behaviour. In the next
phase, online testing, we have used a dynamic data series that are collected from
the vehicles while they pass through diﬀerent experiences than in the training
phase. Accordingly, a ﬁlter called Markov Jump Particle Filter (MJPF) applied
to the learned DBN models to estimate the future states of the vehicles and
ﬁnally detects the abnormality situations present in the environment.

3.1 Oﬄine training phase

In this phase, learn switching DBNs from the datasets collected from the expe-
riences of the vehicle in their normal behaviour. The various steps involved in
learning a DBN model are described below.
Generalized states The intelligent vehicles used in this work are equipped with
one lidar of 16 layers and 360 degrees of Field of view(FOV), a stereo camera,
and encoder devices to monitor diﬀerent tasks being performed. In this work, it
is assumed that each vehicle is aware of the other vehicle by its communication
scheme and cooperation skills. By considering the vehicles endowed with a cer-
tain amount of sensors that monitors its activity, it is possible to deﬁne Z c
k as
any combination (indexed by c) of the available measurements in a time instant
k. Let X c
k + ωk;
where ωk represents the sensor noise. The generalized states of a sensory data
combination c can be deﬁned as:
k = [X c
k

k be the states related to measurements Z c

k, such that: Z c

k · · · X c,(L)

k = X c

˙X c
k

X c

¨X c

](cid:124),

(1)

k

where (L) indicates the L-th time derivative of the state.

Vocabulary generation and state transition matrix calculation In order
to learn the desecrate level of the DBN (i.e., the orange outlined box in Fig.
1), it is required to map the generalized states into a set of nodes. We have
used a clustering algorithm called Growing Neural Gas (GNG) to group these
generalized states and to obtain nodes. In GNG, the learning is continuous, and
the addition or removal of nodes is automated [8]. These are the main reasons
to choose GNG algorithm over other clustering algorithms such as K-means [9]
or self-organizing map (SOM) [11]. The output of each GNG consists of a set
of nodes that encode constant behaviours for speciﬁc sensory data combinations
time derivative order. In other words, at a time instant, each GNG takes the
data related to a single time derivative X c,(i)
k and cluster it with the same
time derivative data acquired in previous time instances. The nodes associated
with each GNG can be called as a set of letters containing the main behaviours

∈ X c

k

4

Divya et al.

of generalized states. The collection of nodes encoding i-th order derivatives in
an observed data combination c is deﬁned as follows:
, · · · ¯X (i),c
Ac

(2)

}

i = { ¯X (i),c

, ¯X (i),c
2

1

P c
i

where P c
i is the number of nodes in the GNG associated to the i-th order deriva-
tive of data in data combination c. Each node in a GNG represents the centroids
of associated data point clusters. By taken into consideration all the possible
combinations of centroids obtained from GNGs, we can get a set of words, that
deﬁne generalized states in an entirely semantic way. The obtained words can
form a dictionary and can be deﬁned as:

Dc = {β, ˙β, · · · β(L)}

(3)

c ∈ Ac

where β(i)
i . Dc contains all possible combinations of discrete generalized
states. Dc is a high-level hierarchy variable that explains the system states from
a semantic viewpoint. In this work, we have only considered states, and it’s ﬁrst-
order derivatives.
Furthermore, estimated the state transition matrices based on the timely evolu-
tion of such letters and words. The state transition matrix is a matrix that con-
tains the transition probability between the discrete level nodes of the switching
DBN shown in Fig. 1. When the ﬁrst data emission occurs, the state transition
matrix provides the probability of the next discrete level, i.e., the probability of
activation of a node from the GNG associated with the ﬁrst-order derivatives of
the states. The vocabulary (i.e.,letters, words and dictionary and the transition
matrices constitute the discrete level of the DBN model.

DBN model Learning All the previous steps are the step by step learning
process of the switching DBNs by each entity taken into consideration. The
number of DBNs learned by each entity in the network can be written as:

DBN m = {DBN1, · · · , DBNn}.

(4)

where m represents the mth vehicle in the network and n is the total number
DBN learned by the mth vehicle. The same DBN architecture is considered for
making inferences with diﬀerent sensory data combinations belong to diﬀerent
vehicles. The learned DBN can be represented as shown in the Fig.1. The DBN
has mainly three levels such as measurements, continuous and discrete levels.

3.2 Online test phase
In this phase, we have proposed to apply a dynamic switching model called
Markov Jump Particle Filter (MJPF) [3] to make inferences on the learned DBN
models. MJPF is a mixed approach with particles inside each Kalman ﬁlter. The
MJPF is able to predict and estimate continuous and discrete future states and
to detect deviations from the normal model. In MJPF, we use Kalman Filter
(KF) in state-space and Particle Filter (PF) in super state space in Fig. 1.
Abnormality detection and complementarity check In probability the-
ory, a statistical distance quantiﬁes the distance between two statistical objects,
which can be two random variables, or two probability distributions, etc. Some
important statistical distances include: Bhattacharya distance [6], Hellinger Dis-
tance [17], Jensen–Shannon divergence [7], Kullback–Leibler (KL) divergence

Self-Awareness in IV: Experience Based Abnormality Detection

5

Fig. 1: Proposed DBN

[10] etc. and they are the distances generally used between two distributions.
Although, the HD is deﬁned between vectors having only positive or zero ele-
ments [1]. The datasets in this work are normalized, so the values vary between
zero and one; there aren’t any negative values. Moreover, HD is symmetric com-
pared to KL divergence. By these reasons, HD is more appropriate than using
other distance metrics as abnormality measure. Moreover, the works in [15] and
[2] used HD as an abnormality measurement.
Abnormality measurement can be deﬁned as the distance between predicted state
values and the observed evidence. Accordingly, let p(X c
k−1) be the predicted
generalized states and p(Zk|X m
k ) be the observation evidence. The HD can be
written as:

k|X c

k = (cid:112)1 − λc
θc
k,

where λc

k is deﬁned as the Bhattacharyya coeﬃcient [5], such that:

(cid:90) (cid:113)

λc
k =

p(X c

k|X c

k−1)p(Z c

k|X c

k) dX c
k.

(5)

(6)

When a given experience in evaluation an abnormality measurement obtains at
each time instant, and can be seen in the equation (5). The variable θc
k ∈ [0, 1],
where values close to 0 indicate that measurements match with predictions;
whereas values close to 1 reveal the presence of an abnormality. After calculating
the abnormality measures by HD, it is possible to check the complementarity
among diﬀerent DBN models learned.

4 Experimental Setup

In order to validate the proposed method, it has been used two intelligent re-
search platform called iCab (Intelligent Campus AutomoBile)[16] (see Fig.2a)

𝑝(𝐷𝑘+1/𝐷𝑘)Particle filterKalman filter Vocabulary𝐴0,𝑘𝐴𝐿,𝑘𝐴0,𝑘+1𝐴𝐿,𝑘+1𝑍𝑘+1𝑍𝑘𝑿𝑘𝑿𝑘+1𝐷𝑘𝐷𝑘+1𝑝(𝐴𝐿,𝑘+1/𝐴𝐿,𝑘)𝑝(𝑿𝑘+1/𝑿𝑘)6

Divya et al.

with autonomous capabilities. To process and navigate through the environment,
the vehicles count with two powerful computers along with the screen for debug-
ging and Human-Machine Interaction (HMI) purposes. The software prototyping
tool used is ROS [18].

(a) The autonomous vehicles (iCab)

(b) The environment

Fig. 2: The agents and the environment used for the experiments.

The data sets collected with the two iCab vehicles are synchronized in order
to observe the vehicles as diﬀerent entities in a heterogeneous way to match their
time stamps. The intercommunication scheme is proposed in [12] where both
vehicles share all its information over the network by a Virtual Private Net-
work(VPN). For this experiment, as long as the synchronization level reaches
the nanoseconds, the recorded dataset in both vehicles has been merged and
ordered using the timestamp generated by the clock on each vehicle which has
been previously conﬁgured with a Network Time Protocol (NTP) tool called
Chrony. Both vehicles perform a PMT task which consists of the autonomous
movement of platooning around a square building (see Fig.2b). The data gen-
erated from the lidar odometry such as the ego-motion of the vehicle and the
diﬀerent combinations of the control variables such as steering angle, rotor ve-
locity and power of the rotor are considered the main metrics to learn and test
the models. Moreover, it aims to detect the unseen dynamics of the vehicles with
the proposed method.

4.1 Perimeter Monitoring Task (PMT)
In order to generate the required data for learning and detect abnormalities,
both vehicles perform a rectangular trajectory in a platooning mode. The leader
just follows the rectangular path and the follower receives the path and keep the
desired distance with the leader. This task has been divided into two diﬀerent
scenarios.

– Scenario I: Both vehicles perform the platooning operation by following
a rectangular trajectory in a closed environment, as shown in Fig. 2b, four
laps in total by recording the ego-motion, stereo camera images, lidar Point
Cloud Data, encoders, and self-state. Notice that the GPS has troubles to
acquire good signal because of the urban canyon. Fig.3a and Fig.4a show
the plots of odometry data for the perimeter monitoring task for iCab1 and
iCab2 respectively. Moreover, Fig.5 shows the steering angle w.r.t the iCab1’s

Self-Awareness in IV: Experience Based Abnormality Detection

7

(a) Perimeter monitoring

(b) Emergency stop

Fig. 3: Odometry data for iCab1

(a) Perimeter monitoring

(b) Emergency stop

Fig. 4: Odometry data for iCab2

position(Fig.5a) and rotor velocity w.r.t the iCab1’s position(Fig.5b). The
rotor power data plotted w.r.t iCab1’s position is shown in Fig.6.

– Scenario II: Both vehicles perform the same experiment, but now a pedes-
trian crosses in front of the leader vehicle(i.e., iCab1). When the leader
vehicle detects the pedestrian, automatically executes a stop and wait until
the pedestrian fully crosses and move out from the danger zone. Meanwhile,
the follower (i.e., iCab2) detects the stop of the leader and stops at a cer-
tain distance. When the leader continues the PMT, the follower mimics the
action of the leader. Fig.3b and Fig.4b show the plots of odometry data for
the emergency stop criteria for iCab1 and iCab2 respectively.

5 Results
As explained in the previous section, there are two diﬀerent scenarios taken into
consideration with two vehicles. Moreover, the data combinations from odometry
and control of vehicles have been treated independently and ﬁnally compared the

-20-10010200510152025303540Odometry trajectory for iCab1-20-10010200510152025303540Emergency stop trajectory for iCab1Emergency stop-20-10010200510152025303540Odometry trajectory for iCab2-20-10010200510152025303540Emergency stop trajectory for iCab2Emergency stop8

Divya et al.

(a) Steering angle(s) w.r.t position

(b) Velocity(v ) w.r.t position

Fig. 5: Control data for iCab1 for perimeter monitoring task

Fig. 6: Rotor power(p) w.r.t position for iCab1 for perimeter monitoring task

abnormality measures to understand the correlation between them. We set the
abnormality threshold to 0.4, considering the average Hellinger distance value
of 0.2 when vehicles operate in normal conditions. The DBN models are trained
over the scenario I based on PMT where no pedestrians are crossing in front
of the vehicles. As said at the beginning of this paper, one of the objectives is
the automatic extraction of abnormalities by learning from experiences. Hence,
for PMT, the DBN models have been trained to extract the HD by pairing
two diﬀerent variables: Steering Angle-Power (SP), Velocity-Power (VP) and
Steering Angle-Velocity (SV).
Testing phase The switching DBN model in this work is designed for the
control part of the vehicles. However, we have considered odometry data and
tested the performance of the learned DBN. Fig. 7 shows the plots of abnormality
measures by considering odometry data for the vehicle leader (iCab1) and the
vehicle follower (iCab2), respectively. During the interval (cyan shaded area)

Self-Awareness in IV: Experience Based Abnormality Detection

9

while pedestrian passes and vehicle stops, there isn'’t any signiﬁcant diﬀerence
in HD value for iCab1 (leader) as well as iCab2 (follower). This behaviour is
due to the fact that, during that interval the vehicles always inside the normal
trajectory range. However, there are speciﬁc intervals when the vehicle deviates
from the normal trajectory range, and the HD measures provided a high value of
about 0.2 during those intervals. So the learned DBN model was able to predict
if any trajectory deviation occurred.

– Steering Angle-Velocity (SV): It is necessary to check that the HD is
working in both directions when the metrics involved reﬂect abnormal be-
haviour such as power and velocity and in cases when the metric used does
not notice when there is an abnormal behavior such as steering angle. For
this reason, the pair (S-V) shown in ﬁg. 8 displays that this pair is not de-
tecting abnormalities when a pedestrian crosses in front of the vehicle (cyan
shaded), which is expected.

– Steering Angle-Power (SP): Fig. 9 shows that the HD is high when
a pedestrian is crossing in front of the leader vehicle (iCab1). This high
value is considered as an abnormality in the behaviour of the leader, and
as it is expected, the follower (iCab2) also gives an abnormal behaviour
for the platooning task. However, the HD measures for the follower is not
as signiﬁcant as the leader, because the follower was not doing emergence
break rather reducing its speed until reaching the minimum distance with
the leader.

– Velocity-Power (VP): The last pair tested is velocity and the power con-
sumption which are highly related. In Fig. 10, it is shown the moment when
a pedestrian cross in front of the leader in cyan colour, which match with the
highest value of the HD. For the follower vehicle, the abnormality measure-
ment is very signiﬁcant due to the new performance of the vehicle against
the emergency brake of the leader. The consecutive peaks in the HD are
caused by the high acceleration when the leader vehicle starts moving, but
the current distance between them is still lower than the desired. Next peak
in HD is caused by the acceleration of the leader and the emergency stop
in the follower due to the pedestrian. To summarize, the switching DBN
learned from SP and VP data were able to predict the unusual situations
present; however, odometry and SV combination of control was not showing
good combination to detect abnormal behavior.

6 Conclusion and future work
It has been proved that the HD for automatically detecting abnormalities in a
DBN model learned from experiences, is a possible and plausible solution. The
main idea of the proposed method has been demonstrated with the training and
testing phase, and the results support that the methodology applied is more
useful instead of checking and delimiting each metric of the vehicle depending
on the event and deﬁning each upper and lower limits in which an abnormal
behaviour is considered.
The future work of this new approach could be extended by establishing com-
munication between the objects involved in the tasks and develop collective

10

Divya et al.

Fig. 7: Abnormality measurements for odometry: (a) iCab1, (b) iCab2

Fig. 8: Abnormality measurements for control (SV): (a) iCab1, (b) iCab2

Fig. 9: Abnormality measurements for control (SP): (a) iCab1, (b) iCab2

(a)

(b)

(a)

(b)

(a)

(b)

(a)

(b)

Fig. 10: Abnormality measurements for control (VP): (a) iCab1, (b) iCab2

010020030040050060070080000.20.40.60.81Odometry iCab1010020030040050060070080000.20.40.60.81Odometry iCab2010020030040050060070080000.20.40.60.81Control SV iCab1010020030040050060070080000.20.40.60.81Control SV iCab2010020030040050060070080000.20.40.60.81Control SP iCab1010020030040050060070080000.20.40.60.81Control SP iCab2010020030040050060070080000.20.40.60.81Control VP iCab1010020030040050060070080000.20.40.60.81Control VP iCab2awareness models. Such models can make the mutual prediction of the future
states of the objects involved in the task and enrich the contextual awareness
where they operate. Another direction could be the development of an optimized
model from the diﬀerent feature combinations that can be used for the future
state predictions of the considered entities. Additionally, the classiﬁcation of de-
tected abnormality by considering diﬀerent test scenarios and comparing the
performance of abnormality detection by using diﬀerent metric as abnormality
measure could be considered.

Acknowledgement
Supported by SEGVAUTO 4.0 P2018/EMT-4362) and CICYT projects (TRA2015-
63708-R and TRA2016-78886-C3-1-R).

Bibliography

[1] Abdi, H., Salkind, N.J.: Encyclopedia of measurement and statistics. Thou-
sand Oaks, CA: Sage. Agresti, A.(1990) Categorical data analysis., New
York: Wiley. Agresti, A.(1992) A survey of exact inference for contingency
tables. Statist Sci 7, 131–153 (2007)

[2] Baydoun, M., Campo, D., Kanapram, D., Marcenaro, L., Regazzoni, C.S.:
Prediction of multi-target dynamics using discrete descriptors: an interac-
tive approach. In: ICASSP 2019-2019 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP). pp. 3342–3346. IEEE
(2019)

[3] Baydoun, M., Campo, D., Sanguineti, V., Marcenaro, L., Cavallaro, A.,
Regazzoni, C.: Learning switching models for abnormality detection for au-
tonomous driving. In: 2018 21st International Conference on Information
Fusion (FUSION). pp. 2606–2613. IEEE (2018)

[4] Baydoun, M., Ravanbakhsh, M., Campo, D., Marin, P., Martin, D.,
Marcenaro, L., Cavallaro, A., Regazzoni, C.S.: A multi-perspective ap-
proach to anomaly detection for self-aware embodied agents. arXiv preprint
arXiv:1803.06579 (2018)

[5] Bhattacharyya, A.: On a measure of divergence between two statistical pop-
ulations deﬁned by their probability distributions. Bulletin of the Calcutta
Mathematical Society 35, 99–109 (1943)

[6] Bhattacharyya, A.: On a measure of divergence between two statistical pop-
ulations deﬁned by their probability distributions. Bull. Calcutta Math. Soc.
35, 99–109 (1943)

[7] Endres, D.M., Schindelin, J.E.: A new metric for probability distributions.

IEEE Transactions on Information theory (2003)

[8] Fritzke, B.: A growing neural gas network learns topologies. In: Advances

in neural information processing systems. pp. 625–632 (1995)

[9] Hartigan, J.A., Wong, M.A.: Algorithm as 136: A k-means clustering algo-
rithm. Journal of the Royal Statistical Society. Series C (Applied Statistics)
28(1), 100–108 (1979)

12

Divya et al.

[10] Hershey, J.R., Olsen, P.A.: Approximating the kullback leibler divergence
between gaussian mixture models. In: 2007 IEEE International Conference
on Acoustics, Speech and Signal Processing-ICASSP’07. vol. 4, pp. IV–317.
IEEE (2007)

[11] Kohonen, T.: The self-organizing map. Proceedings of the IEEE 78(9),

1464–1480 (1990)

[12] Kokuti, A., Hussein, A., Mar´ın-Plaza, P., de la Escalera, A., Garc´ıa, F.: V2x
communications architecture for oﬀ-road autonomous vehicles. In: Vehicular
Electronics and Safety (ICVES), 2017 IEEE International Conference on.
pp. 69–74. IEEE (2017)

[13] Leite, A., Pinto, A., Matos, A.: A safety monitoring model for a faulty

mobile robot. Robotics 7(3), 32 (2018)

[14] Lewis, P.R., Platzner, M., Rinner, B., Tørresen, J., Yao, X.: Self-Aware

Computing Systems. Springer (2016)

decision making: An

[15] Lourenzutti, R., Krohling, R.A.: The hellinger distance

in mul-
ticriteria
and
todim methods. Expert Syst. Appl. 41(9), 4414–4421 (Jul 2014).
http://dx.doi.org/10.1016/j.
https://doi.org/10.1016/j.eswa.2014.01.015,
eswa.2014.01.015

illustration

topsis

the

to

[16] Marin-Plaza, P., Hussein, A., Martin, D., Escalera, A.d.l.: Global and lo-
cal path planning study in a ros-based research platform for autonomous
vehicles. Journal of Advanced Transportation 2018 (2018)

[17] Pardo, L.: Statistical inference based on divergence measures. Chapman and

Hall/CRC (2005)

[18] Quigley, M., Conley, K., Gerkey, B., Faust, J., Foote, T., Leibs, J., Wheeler,
R., Ng, A.Y.: Ros: an open-source robot operating system. In: ICRA work-
shop on open source software. vol. 3, p. 5. Kobe, Japan (2009)

[19] Ravanbakhsh, M., Baydoun, M., Campo, D., Marin, P., Martin, D., Marce-
naro, L., Regazzoni, C.S.: Learning multi-modal self-awareness models for
autonomous vehicles from human driving. arXiv preprint arXiv:1806.02609
(2018)

[20] Schlatow, J., M¨ostl, M., Ernst, R., Nolte, M., Jatzkowski, I., Maurer, M.,
Herber, C., Herkersdorf, A.: Self-awareness in autonomous automotive sys-
tems. In: Proceedings of the Conference on Design, Automation & Test
in Europe. pp. 1050–1055. European Design and Automation Association
(2017)

[21] Xie, G., Gao, H., Huang, B., Qian, L., Wang, J.: A driving behavior aware-
ness model based on a dynamic bayesian network and distributed genetic
algorithm. International Journal of Computational Intelligence Systems
11(1), 469–482 (2018)

[22] Xiong, G., Zhou, P., Zhou, S., Zhao, X., Zhang, H., Gong, J., Chen, H.:
Autonomous driving of intelligent vehicle bit in 2009 future challenge of
china. In: Intelligent Vehicles Symposium (IV), 2010. pp. 1049–1053. IEEE
(2010)

