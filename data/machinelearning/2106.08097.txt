Reservoir optimization and Machine Learning methods

Xavier Warin ∗

June 28, 2022

Abstract

2
2
0
2

n
u
J

7
2

]

C
O
.
h
t
a
m

[

2
v
7
9
0
8
0
.
6
0
1
2
:
v
i
X
r
a

After showing the eﬃciency of feedforward networks to estimate control in high dimension in the
global optimization of some storages problems, we develop a modiﬁcation of an algorithm based on
some dynamic programming principle. We show that classical feedforward networks are not eﬀective
to estimate Bellman values for reservoir problems and we propose some neural networks giving far
better results. At last, we develop a new algorithm mixing LP resolution and conditional cuts
calculated by neural networks to solve some stochastic linear problems.

1 Introduction

In the industry, storages are reservoirs used to manage a stock of fuel to satisfy a given objective function.
Hydraulic reservoirs use water to produce electricity and the goal of the manager is to supply energy to
satisfy a demand at the lowest cost. Gas storage is a special case of storages with a valuation achieved
by buying and selling gas on the market. Another example of storages are batteries where electricity is
directly injected or withdrawn leading to systems that can be valuated directly facing the market or that
can be used to secure a global electrical system.
When the number of reservoirs in low, traditional Dynamic Programming methods are generally used.
A typical example is the gas storage which is optimized and hedged using this kind of approach [War12]:
the storage level is discretized on a grid, and continuation values are calculated by regression either using
the Bellman values at the following time step [TVR01] or using the cash generated at the following dates
according to the classical Longstaﬀ Schwartz approach [LS01]. Theses regressions are coupled with linear
interpolation in the Bellman values or the cash generated at the diﬀerent points of the grid. The method
can be used for non linear problems only in low dimension for two reasons. The most obvious one is
the computing time that explodes with the dimension and computer clusters are necessary to face this
computing cost even with a number of reservoir limited to 3 or 4. The second reason which is in fact the
ﬁrst limiting one is the need to store in memory the Bellman values needed by the software. This has led
to the development of algorithms splitting the Bellman values on the memory of the diﬀerent nodes of
the computer cluster (see [MVW07] and the StOpt library [Gev+18] for a recent implementation). But
even with this kind of approach it is impossible to optimize problems with more than 4 or 5 reservoirs.
Another pitfall that managers encounter even in dimension one, as it is the case for gas storage optimiza-
tion facing the gas market, is the loss of concavity observed due to the regressions and interpolations
while calculating conditional expectations even when the solution is known to be concave with respect to
the storage level.
In most countries having many dams, dynamic programming methods are not directly used and generally
the SDDP (Stochastic Dual Dynamic Programming) method [PP91] is used to manage the dams using
a cut approximation of the Bellman values that are concave for a linear objective function with respect
to the stocks level in reservoirs. Transition problems are solved using LP solvers with Bellman cuts as
a upper estimation of the terminal value. When uncertainties have to be included in the state breaking
concavity of the Bellman values, trees are generally introduced and cuts have to be generated at each
node of the tree as explained in [PP91]. Another approach consists in generating conditional cuts using
regressions [AW20]. In all the cases, forward resolutions (exploration of the possible uncertainties and
storage levels visited) and backward resolutions (adding cuts at the levels visited in the forward reso-
lution) give an iterative method that converges [Sha11]. One advantage of this method is that, as cuts

∗EDF R&D, FiME xavier.warin at edf.fr

1

 
 
 
 
 
 
are used to generate an approximation of the Bellman values, concavity is preserved with respect to the
storage level and the marginal cost of the system (i.e. the derivative of the Bellman value with respect to
the storage level) is decreasing with the storage level. However the method may be very slow to converge
if the number of transition step is high and it only can be used for linear or special quadratic problems.

In this article, we will investigate the use of neural networks to valuate reservoirs possibly in high
dimension. This approach is old as it has been ﬁrst used for gas storage in [BE+06] at a time where
no automatic diﬀerentiation software were available and maximization of the proﬁt generated by the
storage had to be achieved using a gradient method calculating explicitly the gradients. In this work,
feedforward networks are used to approximate the control (gas injection- withdrawal ) at each time step
and the solution obtained is compared to some trees method used to describe uncertainties. This part
of the previous article has been at that time largely ignored by the scientiﬁc community. Recently, this
kind of representation of the control has been used to solve some BSDE problems [HJW18] leading to
many works on this approach.
Using some Dynamic Programming methods, [Bac+21] proposed some algorithm using neural networks
and give some numerical results for the valuation of a storage:

• The ﬁrst one ”Control Learning by Performance Iteration” has Longstaﬀ Schwartz ﬂavor: the
control at the current date is approximated by a neural network and the controls calculated at the
previous time steps (so at the next time steps as the resolution is backward) are reused to estimate
the expectation of the objective function starting with a randomized initial state at the current
date. In practice, this method can only be used for a very low number of time steps as the cost of
recalculating the objective function using the previously calculated controls is very high.

• The second method ”Hybrid now” ﬁrst consists in calculating the control at the current time step
by a ﬁrst optimization by neural networks and then estimate the Bellman values at a current time
step by regression by a second optimization problem using a second feedforward network.

At last in a very recently article, [Cur+21] studies the valuation and hedging of a gas storage using a
single optimization approximating the control at each time step by some neural networks as in [BE+06].
They also propose to ”merge” the network between diﬀerent time steps (so introducing a dependence on
time in a network shared between diﬀerent time steps). This kind of approach merging all time steps
(so using a single neural network shared between all time steps) is the one proposed in [FMW19] for risk
valuation or [CWNMW19] for BSDE resolution: they show that it gives better stabilized results on these
problems.
The present article studies ﬁrst the ”Global Valuation” method (GV) of one or many storage using the
global approach used in [BE+06] and [Cur+21] testing diﬀerent formulations and network to represent
the control.
This type of resolution is impossible to use on real problem involving optimization for example on the
global year on an hourly basis for one storage, or the global year even on a daily basis when many storages
are linked together: this is for example the case for the valuation of a high number of batteries with a
management having an inﬂuence on the price of electricity as it would the case for some windmill ﬁelds
with batteries.
In this case, we have to split the problem and use a modiﬁcation the ”Hybrid now” scheme solving the
problem backward but estimating the control not a single time step but for a whole period. This scheme
will be called the ”Global Split Dynamic Programming” method (GSDP) and ”Hybrid now” scheme is a
special case were the transition problem is solved on a single time step. This scheme is studied on some
diﬃcult test cases and the use of nearly optimal network to represent the Bellman values is studied.
The main ﬁndings of this article are the following ones:

• When the underlying process of the problem is Markovian, it is possible to optimize reservoirs very
accurately with simple feedforward networks with a small number of layers and neurons for the
control even in high dimension using the GV method but it is necessary to use a network for each
time step and the ”merged” network has to be avoided as it leads to very poor result when the case
is really stochastic. When the underlying process is not Markovian, we propose a combination of a
LSTM network with some feedforward networks to solve the problem and we show the eﬀectiveness
of the methodology.

2

• The use of the GSDP method results in a loss of optimality due to the calculation of the Bellman
values by regression with classical feed forward networks. We show that with a single storage, it is
possible to get reasonable results using a feedforward network by increasing the number of layers
and neurons. Using 5 or 10 storages optimized together, we show that feedforward are not eﬀective
In order to use the GSDP method in high dimension, we develop
to estimate bellman values.
a network inspired by [AXK17] and show that it gives reasonable results in all dimension tested
even with a small number of layers and neurons. When the problem is concave with respect to
the storage level, we show that the network proposed in [AXK17] can be used to get good results
while preserving concavity and we show that this network is surpassed by an extension of the new
GroupMax network proposed in [War22].

• As the GroupMax network generate cuts, we develop a new a algorithm GMCSDP to solve stochastic
linear problem using a dynamic programming approach based on LP resolutions as the SDDP
method does but with only a single backward resolution. This approach permit to avoid the
problem of storing the Bellman values one a grid and LP can solved in parallel using threads. We
show the eﬀectiveness of the method on a linear case.

In the whole article we will focus on a maximization of the gain of management in expectation. This
choice is driven but the fact that, in practice, it is the main concern associated to this kind of man-
agement. Introducing some hedging strategies as proposed in [Cur+21] leads to the need to use a risk
function to discriminate an optimal strategy. Another important point associated with this choice is
the fact that we can implement multi storage optimization problems that can easily be reduced to a
one storage optimization permitting to get a reference by the classical dynamic programming approach
using regressions. Therefore we can check that neural network really permit to solve some rather high
dimension problems.

2 The global approach for storage optimization

On ﬁrst recall for convenience that a feedforward network with K hidden layers and m neurons is a non
linear operator φ Rd0 −→ Rd1 deﬁned by the following recurrence:

z0 =x ∈ Rd0,

zi+1 =ρ(σizi + bi), 0 ≤ i < K,
φ(x) =ˆρ(σKzK + bK),

(1)

(2)

(3)

where :

• σ1 ∈ Rm×d0, σi ∈ Rm×m for i = 1, . . . , K − 1, σK ∈ Rd1×m,

• bi ∈ Rm, for i = 0, . . . , K − 1, bK ∈ Rd1,

• ρ, ˆρ are activation functions (Elu, Relu, tanh etc..) applied component wise.

The set of all matrix and vector coeﬃcients of σi, bi, i = 0, . . . , K deﬁne the set θ of the parameters of
the network.
In a ﬁrst part, we test diﬀerent approximation and formulation for a linear storage problem. We then
extend our results in dimension above taking a non linear problem linking the management of the diﬀerent
storages.

2.1 On a linear problem in dimension one

We suppose we want to manage a storage (gas storage, battery) on a commodity market (gas, electricity)
where the commodity follows the HJM model

dF (t, T )
F (t, T )

= e−a(T −t)σdWt

(4)

where Wt is a one dimensional Brownian motion deﬁned on a probability space (Ω, F, P). The spot price
is then St = F (t, t).

3

The characteristics of the storage are the withdrawal CW and injection CI capacities (both taken positive)
during one time step ∆t, its capacity QM ax and the initial stock position QInit.
We deﬁne the objective function for N optimization dates ti = i∆t, for i = 0, . . . , N − 1 :

J(U ) = −E[

N −1
(cid:88)

Stiui]

i=0

for U = (ui)i=0,N −1 in the set U of the non anticipative admissible strategies such that

0 ≤ Qj := Qinit +

j−1
(cid:88)

ui ≤ QM ax,

for j = 0, . . . , N,

i=0
−CW ≤ ui ≤ CI ,

for j = 0, . . . , N − 1.

We want to maximize the expected gain associated the storage management

J ∗ = sup
U ∈U

J(U )

(5)

(6)

(7)

As the problem is Markovian in (S, Q) where Q is the storage level, we can introduce as in [BE+06] a feed
forward networks φθi
i with parameters θi per time step i as an operator from R2 to R approximating a
transformation of the control ui. There are many ways to deal with the constraints imposed on the level
of the storage (Q has to stay positive and below Qmax): among them clipping the control, penalization
of the objective function are possible but the best approach (we won’t report results on less eﬀective
approaches) consists in using the [Cur+21] approach. First we introduce for a given i in 0, . . . , N − 1:

ˆC i

I = ((Qi + CI ) ∧ Qmax) − Qi,

ˆC i

W = Qi − ((Qi − CW ) ∨ 0).

(8)

Then φθi
i
with values in [0, 1] for ˆρ. At last the control is approximated as:

is a function of (S, Q) using an tanh activation function for ρ and a sigmoid activation function

− ˆC i

W + ( ˆC i

W + ˆC i

I )φθi
i

Noting θ = (θi)i=0,N −1, we approximate the optimal storage management by solving

θ∗ = argmin

E[

θ

N −1
(cid:88)

i=0

Sti(− ˆC i

W + ( ˆC i

W + ˆC i

I )φθi

i (Sti, Qi))]

(9)

where Qi follows (6), ˆC i

W and ˆC i

I are given by (8) and the dynamic of F follows (4).

A second version consists classically in introducing a single neural network φ (”merged” network)

with parameters θ as a function of (t, F, Q) and the optimization (9) is modiﬁed as:

θ∗ = argmin

E[

θ

N −1
(cid:88)

i=0

Sti

(cid:0) − ˆC i

W + ( ˆC i

W + ˆC i

I )φθ(ti, Sti, Qi)(cid:1)]

(10)

We use a classical stochastic gradient descent ADAM method in Tensorﬂow [Aba+15] and use some
normalized data for F and Q as input of the neural network.
For the test case, we suppose that we optimize on N = 365 days a storage with one decision per day
(∆t = 1). The price parameters (expressed in days) σ = 0.08, a = 0.01. The initial forward curve presents
seasonal and weekly oscillations as in the energy market and is given by F (0, T ) = 30 + 5 cos( 2πT
N ) +
cos( 2πT
7 ). As for the storage, we take CW = 10, CI = 5, QM ax = 100, QInit = 50. A reference is
calculated using the StOpt library [Gev+18] by dynamic programming using adaptive linear regression
[BW12] and cash ﬂow interpolations as exposed in [War12]. In optimization, 100 basis functions and 1e6
trajectories are used to optimize the control with regressions. The parameters are taken such that the
solution is very stochastic and the problem hard to solve by dynamic programming explaining while we
took such parameters for the resolution. As the solution is bang bang [BE+06], we use 20 grid points to

4

discretize the storage and only bang bang controls are tested leading to a very rapid estimation. Then
a simulation using the Bellman values calculated in optimization is achieved. The value in optimization
obtained is equal to 4938, while the value in simulation taken as a reference is equal to 4932.

Prices

Optimal storage trajectories

Figure 1: 10 spot and optimal management trajectories.

Using 2 hidden layers with 11 neurons, we train the problem (9) and (10) using mini batch with size
200, 100000 iterations for the gradient descent, and an initial learning rate equal to 2E − 3. Results
obtained after training using 200000 trajectories are given in table 1 using 10 runs. Minimal/Maximal is
the minimal/maximal value obtained on the 10 runs, while Average is the average value obtained.

One network per day (9)
A singe network (10)

4925
3944

4914
1795

4922
3702

7
988

Maximal Minimal Average Min diﬀ with DP

Table 1: Neural network valuation with 10 runs.

Results are excellent with a network by day but very bad with a single network. Results with a single
network don’t change while increasing the number of layers and neurons. Using a network per time step,
we can check that results remains in all case very good while decreasing the volatility σ.

2.2 Linear problem increasing the dimension

To get a linear problem with a higher dimension, we suppose that we have M similar storages to manage
each one with a strategy (uj
0, . . . , uj
i is the
level in storage j at date ti, U = ((uj

N −1) for j = 1, . . . , M . We note Qi = (Qj
i )i=0,N −1)j=1,M and the function to maximize is:

i )j=1,...,M where Qj

and

J M (U ) = −E[

M
(cid:88)

N −1
(cid:88)

Stiuj
i ]

j=1

i=0

J M,∗ = sup
U ∈U

J M (U )

(11)

(12)

where all strategies satisfy a ﬂow equation similar to (3). Similarly to the previous section, we introduce
a neural network per time step depending on the current prices and the diﬀerent storage levels. Then a
transformation of the network leads to the control. Therefore the network with parameters θi per time

5

step i as an operator from R1+M to RM approximating a transformation of the controls (u1
Using the same activation function as in the previous section, we have to optimize:

i , . . . , uM

i ).

θ∗ = argmin

θ

N −1
(cid:88)

E[

i=0

Sti(− ˆC i

W + ( ˆC i

W + ˆC i

I )φθi

i (Sti, Qi)).1M ],

(13)

where now the ˆC i
(8).
In this part, we test two networks:

W and ˆC i

I are now vectors in RM with each component satisfying an equation similar to

• First, the classical feedforward network φ previously introduced,

• Secondly, as the solution is symmetrical, we test the DeepSet network [Zah+17] (with the same
parameters for the number of layers and neutrons as originally proposed by the authors) permitting
to impose that the control satisfy the symmetry:

ul(S, Q1, . . . , Ql, . . . , Qm, . . . , QM ) = um(S, Q1, . . . , Qm, . . . , Ql, . . . , QM )

for all (Q1, . . . , QM ) state positions in the storages. This network has proved to be more eﬀective
than feedforward networks but for very high dimension PDE arising from particular approximation
of some mean ﬁeld problems [Ger+21].

For each storage, we take the same storage characteristics as before and we have J M,∗ = M J 1,∗. Training
and simulation parameters are the same as in previous section except the number of neurons taken equal
to 10 + M . On ﬁgure 2 we plot the results obtained by the two networks. Results obtained by the
classical feedforward networks are already optimal and DeepSet networks are not interesting in so small
dimensions.

Network
feedforward
feedforward
DeepSet
DeepSet

M Maximal Minimal Average Min diﬀ with DP
3
10
3
10

4926
4931
4896
4904

4915
4918
4882
4891

4921
4925
4889
4896

6
1
35
28

Table 2: Neural network valuation divided by the dimension in the linear case. 10 runs.

2.3 Results on a non linear case

In order to get reference results for a non linear case, we now suppose that the price is not exogenous
anymore and that the impact is proportional to P

M leading to modify the function to maximize:

J M (U ) = −E[

M
(cid:88)

N −1
(cid:88)

(Sti +

j=1

i=0

P
M

M
(cid:88)

l=1

i)uj
ul
i ]

(14)

This kind of modeling of a price impact is necessary for example while managing some batteries when
the amount of energy managed represents a rather important part of the energy available on the market.
Using the same methodology as before, taking P = 0.2 and the same parameters as in the previous
sections, we can ﬁrst for M = 1 get a reference with a very thin discretization of the command and
the grid storage using dynamic programming with the StOpt library. The value obtained by classical
regressions is equal to 3802 in optimization and a value in simulation taken as reference is equal to 3796.
The solution of (12) satisﬁes again J M,∗ = M J 1,∗ and we give J M,∗
M obtained by the previously deﬁned
feed forward network for this non linear case in table 3.

M Maximal Minimal Average Min diﬀ with DP
1
5
10

3794
3799
3797

3788
3794
3791

3780
3789
3784

7
2
5

Table 3: Neural network valuations with ten run divided by the dimension in the non linear case.

6

Once again results are very good in dimension 1 to 10 on this very stochastic case as shown on table

3.

2.4 Extension in the non Markovian case

When the price, or in a more general framework the uncertainties are not Markovian, it is possible to
extend the previous feedforward network to deal with this feature.
As the optimal control is, at a date t, a function of the whole history of price (Su)u≤t and the current
position in the storage, the idea is to use a recurrent network such a LSTM network [HS97] to deal with
the price dependency. At each time step, the output of the LSTM network (with the price as input) and
the position in the storages are used as the input of a feedforward network giving the control. The ﬁgure
2 represents an unrolled version of the LSTM linked with the feedforward at each time step.

Figure 2: Unrolled LSTM with feedforward to approximate control.

In order to test this network we now suppose that the future price (4) is replaced by (15).

dF (t, T )
F (t, T )

=

3
(cid:88)

i=1

e−ai(T −t)σidW i
t ,

(15)

t , W 2

t , W 3

where now Wt = (W 1
t ) is a three dimensional Brownian motion.
We still consider the linear problem (5) with the same characteristics as before but with (σ1, σ2, σ3) =
(0.04, 0.028, 0.023) and (a1, a2, a3) = (0.01, 0.005, 0.0033). In table 4, we compare the results obtained
using the feedforward taking as input the three risk factors of the price model (σi
s)i=1,3
and the storage level with the results obtained with the LSTM-Feedforward network where the LSTM
network takes the price as input and has 50 units as output. Using dynamic programming with the
StOpt library we could get a value of 4300 achieving an optimization regressing with [BW12] method
in dimension 3 with 1e7 trajectories and 103 meshes. We could not reﬁne the results due to memory
problems.

(cid:82) t
0 e−ai(t−s)dW i

Network
feedforward
feedforward
feedforward
LSTM-feedforward
LSTM-feedforward
LSTM-feedforward

M Maximal Minimal Average
1
5
10
1
5
10

4328
4327
4329
4280
4279
4279

4322
4320
4318
4277
4273
4268

4332
4333
4334
4285
4284
4285

Table 4: Neural network valuation divided by the dimension in the linear case for the non Markovian
case (10 runs).

Results are very good with a very small loss of accuracy compared the feedforward network. We
notice that the results obtained with the feedforward networks are slightly above the results obtained by
our not converged classical regression method.

7

3 Global Split Dynamic Programming method

The Global method proposed in the previous section appears to be very eﬀective but may be impossible
to implement if the number of dates is too important: memory issues appears and another approach has
to be used. This leads to the development of a combination of the Hybrid-Now method of [Bac+21] and
the global method of [BE+06]. Suppose that the objective is

N −1
(cid:88)

J(U ) = E[

i=0

f (ti, Sti, Ui)]

(16)

where the control Ui is a vector of size M , with some ﬂow constraints as in (6) but applied component
by component on the control. Suppose that we want to solve (12) and that we split the N dates in
N = (cid:80)L
ˆNl with ˆNl ∈ N∗ for l = 1, . . . , L. Algorithm 1 permits to solve the problem (12).

l=1

Algorithm 1: GSDP method

, for ˜l = 1, L − 1, and all optimal

ˆNl

l=1

Output: Estimates the Bellman values at dates t0, t(cid:80)˜l
controls.
˜i = N
V BL = 0
for l = L, . . . , 1 do
˜i = ˜i − ˆNl
Introduce ˆNl feedforward networks φθk
for the output

k on RM +1 with values in RM with sigmoid activation

θ∗ := (θ∗

0, . . . , θ∗

ˆNl−1

) = argmin

θ

ˆNl−1
(cid:88)

E[

i=0

f (t˜i+i, St˜i+i

, U θ

i ) + V Bl(S˜i+ ˆNl

, Q ˆNl

)]

(17)

such that Q0 ∼ U [0, Qmax]M and for 0 ≤ i < ˆNl:

ˆC i
i = − ˆC i
U θ

I = ((Qi + CI ) ∧ Qmax) − Qi,
W + ( ˆC i
I )φθi

W + ˆC i

ˆC i
, Qi), Qi+1 = Qi + U θ
i

i (St˜i+i

W = Qi − ((Qi − CW ) ∨ 0)

(18)

Introduce a neural network ψκ with identity output activation function with parameters κ

κ∗ = argmin

E[(cid:0)

κ

ˆNl−1
(cid:88)

i=0

f (t˜i+i, St˜i+i

, U θ∗

i ) + V Bl(S˜i+ ˆNl

, Q ˆNl

) − ψκ(St˜i

, Q0)(cid:1)2

],

(19)

where (18) is satisﬁed and Q0 ∼ U [0, Qmax]M
V Bl−1 = ψκ∗

In this algorithm the use of a feedforward may seem natural to solve (19) as it was proposed for the
hydrid-now method in [Bac+21]. We take our linear test case in dimension 1 and test the use of this
network for ψκ to solve (19) for diﬀerent number of L values (only ˆN0 may diﬀer from the ˆNl for l > 0
that are all equal : ˆNl = ˆNm for l > 0 and m > 0). As for the neural networks used for the control in (17)
we keep the same characteristics as in the previous sections.
Using diﬀerent number of neurons and layers to approximate the Bellman values, in table 5 we give the
results obtained with the best of 3 runs taking 100000 gradient iterations with an initial learning rate
equal to 5E − 3 still with the ADAM method. The activation function ρ in (3) is a Relu function as it
gives better results than tanh activation function and it gives similar results to Elu activation function.

8

L m ˜L solution Min diﬀ with DP
4
13
53
4
13
53

4900
4816
4389
4899
4834
4633

32
116
543
33
98
299

11
11
11
30
30
30

2
2
2
3
3
3

Table 5: GSDP method for the one dimensional linear case using a feed forward with a number of neuron
m, and a number of layers ˜L to solve (19). We take the best of 10 runs.

There is a loss of optimality increasing as L increases. For L = 53 we have to take at least 3 layers and
30 neurons to avoid too much loss of accuracy. Using more layers or neurons can very slightly improve the
results and now we take 5 layers with 20 neurons for this feedforward network and now test the previous
linear case and the non linear one from section 2.2 and 2.3 keeping L = 53 and letting the dimension
increase. We report results on table 6.

Test case M max min
4543
1
4252
5
1831
10
3646
1
2122
5
1379
10

Linear
Linear
Linear
Non linear
Nonlinear
Nonlinear

4651
4352
2547
3687
3074
2039

average min error

4606
4179
2151
3664
2529
1165

280
579
1248
108
721
1756

Table 6: Feed forward results J M,∗
M with the GSDP method for linear and non linear cases with 5 layers,
20 neurons for (19), L = 53 and letting the dimension M vary. We use 10 runs and report the best (max),
the worst (min) results, and at last the error for the best result obtained.

The degradation of the result obtained with the dimension is obvious and even in dimension 5 the
error obtained is far too important. The treatment of the storage levels has to be made diﬀerent from
the uncertainty regression and it leads to the development of more adapted networks. Then the input of
the network is split into two parts:

• All uncertainties that are regressed are be treated using a feedforward network,

• A special treatment of the dimension associated to the storage where only interpolation is needed

is proposed.

We propose to use three diﬀerent networks.

3.1 A ﬁrst network ψA preserving concavity

As on this case, the solution is concave with respect to storage we can use a modiﬁcation of the [AXK17]
network avoiding penalization given by the recursion (20). Supposing that the input of the neural network
˜x = (x, y) ∈ Rd0 where we have concavity in y ∈ Rk,

ui+1 =˜ρ( ˜Wiui + ˜bi)
zi+1 =ρ([W (z)

i ⊗ (W (zu)
(y ◦ (W (yu)

i

i
u0 = x,

ui + b(z)
i
ui + b(y)
i
z0 = 0

)]+zi+
)) + W (u)

W (y)
i
ψA =zK+1,

i ui + bi),

for i ≤ K

(20)

where ρ is a concave non increasing activation function that we will take equal to minus Relu, ◦ denote the
Hadamard product, ⊗ is applied between a matrix A ∈ Rm×n and vector B ∈ Rn such that A⊗B ∈ Rm×n
and (A ⊗ B)i,j = Ai,jBj. As stated in [AXK17], concavity of the solution is given by the characteristics
of ρ and the fact that the weight before zi is positive in (20). Using mx neurons for the non concave part

9

of function and my neural networks for the convex part of the network, ˜W0 ∈ Rmx×d0−k, ˜Wi ∈ Rmx×mx
for i > 0, W (zu)
K ∈ R1×my as the output is a scalar
function. We don’t detail the size of the diﬀerent matrix W (y), W (yu), W (u) and the diﬀerent bias that
are obvious.

i ∈ Rmy×my for j < K, W (z)

∈ Rmy×mx for i > 0, W (z)

i

In all experiments, ˜ρ is the ReLU activation function.

3.2 A second network ψAD removing the concavity constraints

We naturally modify the previous one removing the constraints on concavity by

ui+1 =˜ρ( ˜Wiui + ˜bi)
zi+1 =ρ(W (z)

i
W (y)
i
ψAD =zK+1,

i
(y ◦ (W (yu)

i
u0 = x,

ui + b(y)
i
z0 = 0

(zi ◦ (W (zu)

ui + b(z)

))+
i
)) + W (u)

i ui + bi),

for i ≤ K

(21)

Removing the concavity constraints, we get a network that can be used even for non concave/convex
problems. In all experiments ˜ρ and ρ are ReLU activation functions.

3.3 The GroupMax network ψGM using cuts when the solution is concave

The GroupMax is a network developed very recently [War22] combining ideas in [ALG19], [TB21] and
the ones in [AXK17] but permitting to have cuts to represent a concave solution. When the function is
only concave with respect to y, the following network is proposed in [War22] generating cuts conditional
to x:

u0 =x,

z0 = 0

ui+1 =˜ρ( ˜Wiui + ˜bi)
zi+1 =ρ([W (z)

ψGM (x, y) =ˆρ([W (z)

W (y)
i

i

i ⊗ (W (zu)
(y ◦ (W (yu)
K ⊗ (W (zu)
K (y ◦ (W (yu)

ui + b(z)
i
ui + b(y)
K uK + b(z)
K uK + b(y)

)]+zi+
)) + W (u)
K )]+zK+
K )) + W (u)

i

i

W (y)

i ui + bi),

K uK + bK)

for i ≤ K − 1

(22)

where all matrices involved have the same size as the matrices in (21) except that the matrix W (z)
Rmy×my .
In (22), the ˜ρ is a classical activation function such as ReLU and in order to get conditional cuts to
approximate the solution, we take ˆρ as an activation function working on the whole vector:

K is in

ˆρ(x) = min

i=1,...,d

xi

for x ∈ Rd .

The ρ is deﬁned grouping the elements of the vector as in the GroupSort network [ALG19]. Supposing
that x ∈ Rmy , G ≤ my ∈ N∗ the group size such that ˜m = my
G ∈ N∗ representing the number of groups,
ρ maps Rmy to R ˜m such that:

ρ(x)i = min

j=1,...,G

x(i−1)G+j,

for i = 1, . . . , ˜m.

In [War22], it is shown that this network generates conditional cuts with respect to x. In all experiments,
˜ρ is a ReLU activation function.

3.4 Numerical results

We test the three networks on the linear and the non linear case. It is obvious that in the linear case, the
Bellman value is concave with respect to the storage level. In the non linear case, concavity is still present

10

[GLP15]. All the Bellman values obtained by the three networks are not very sensitive to the number of
layers and neurons. For the three networks used to approximate Bellman values, we take mx = 10 and 3
hidden layers, taking my = 20 for the two ﬁrst networks and my = 40 for the GroupMax network. We
keep the same parameters as in the previous sections to estimate the controls.

M Network max min
4618
1
4738
1
4777
1
3949
5
4318
5
4519
5
3724
10
3890
10
4316
10

φA
φAD
φGM
φA
φAD
φGM
φA
φAD
φGM

4679
4798
4810
4352
4482
4641
4027
4151
4425

average min error

4645
4771
4795
4179
4399
4601
4027
4031
4351

252
133
122
579
449
290
904
780
506

Table 7: Result J M,∗
10 runs.

M of the Linear case with the GSDP method with L=53 for the diﬀerent networks.

M Network max min
3540
1
3646
1
3663
1
3206
5
3278
5
3589
5
3044
10
3308
10
3482
10

φA
φAD
φGM
φA
φAD
φGM
φA
φAD
φGM

3585
3687
3688
3444
3538
3633
3456
3389
3556

average min error

3558
3664
3676
3412
3434
3614
3288
3205
3556

210
108
107
351
257
162
339
406
239

Table 8: Result J M,∗
10 runs.

M on the Non Linear case with the GSDP method with L=53 for the diﬀerent networks.

As the dimension M increases, the variance of the results obtained increases. The GroupMax is
clearly superior to other networks. Results are better, the loss of accuracy decreases less quickly with the
dimension and the variance of the results obtained is much lower than with the other networks.
We conclude that is optimal to use a number L as low as possible. When the problem is not concave
with respect to the storage levels, the φAD network is the best one and when the problem is concave, the
cut methodology given by the GroupMax network φGM is the best choice.

4 GroupMax Cut Split Dynamic Programming (GMCSDP) method

The management of reservoirs in high dimension is often achieved with a linear stochastic model. Using
a hazard decision framework, the resolution uses a stochastic model where uncertainties are revealed for
a period ∆t and some decisions are taken on sub intervals of ∆t. Using the fact that the Bellman values
are concave with respect to the storage levels, at each time step ti = i∆t, decisions are taken starting at a
level in the reservoirs Q = (Q1, . . . , QM ) in the storage problem by solving some LP problem with termi-
nal conditions given by some cuts of the Bellman values at date ti+1. The Bellman values being generally
not concave with respect to the uncertainties, cuts are conditional to the uncertainty level. Theses cuts
are often given at the node of a scenario tree [PP91] and can also be calculated by regressions as in [AW20].

• When the dimension is low, starting point in the reservoirs for the LP problems are derived by
exploring a grid, and a single backward resolution is achieved. This is a dynamic programming

11

method.

• When the dimension becomes higher, a procedure iterating backward resolution and some forward
exploration simulations is used. The forward step permits to reveal the reservoir levels of interest
to explore during the following backward step that adds new cuts. This iteration procedure is the
SDDP of [PP91].

The two methods are developed in some libraries such StOpt [Gev+18] using regressions and trees. These
methods are very popular as they permit to treat diﬃcult constraints dealt by the LP solver used to solve
the transition problems.

Remark 4.1. The non linear transition problem with a cost function quadratic concave with respect to
the control and the reservoir level can also solved by a quadratic solver using the same methodology but
at a higher cost.

As stated in the introduction, the convergence can be very slow and the stopping criterion be can be
tricky to implement especially when the Bellman values are not concave with respect to the uncertainties.
The use of dynamic programming methods estimating the cuts on a grid suﬀers both from the computing
time and the memory needed. We propose to use the GroupMax network to estimate the Bellman values
by cuts.
We suppose that we want to solve equation the following equation

J ∗ =

sup
U =(U0,UN −1)∈U

N −1
(cid:88)

i=0

E[f (ti, Ui, Sti)]

U ≤Ui ≤ ¯U , with Ui ∈ Rp,
X0 = ˜X ∈ Rq

i = 0, N − 1

Xi+1 =Xi + Ai(Si)Ui + Bi(Si) ∈ Rq,

i = 0, N − 1

X ≤Xi ≤ ¯X,

i = 0, N

(23)

where f is linear or quadratic concave with respect to U , St is a discrete time Markov process in Rd, Ai
a function from Rd to Rq×p, Bi function from Rd in Rq for i = 0, N − 1.
Based on the dynamic programming principal and using the GroupMax network, we propose to use the

12

algorithm 2 to optimize (23) where the Bellman values are estimated by cuts.

Algorithm 2: GMCSDP method

Output:
V BN −1 = 0
for i = N − 1, 1 do

Introduced a GroupMax neural network ψGM,θ(S, X) with parameter θ

θ∗ = argmin

θ

E[(ψGM,θ(Sti−1, X) − Q(Sti, X))2]

where

Q(Sti, X) = max
U ∈Rp

f (ti, Sti, U ) + ξ

ξ ≤V Bi(Sti, ˜X)
˜X =X + Ai(Sti)U + Bi(Sti)
X ≤ ˜X ≤ ¯X,
U ≤U ≤ ¯U ,

with X ∼ U ([X, ¯X]), Sti−1 sampled from S0 and Sti sampled from Sti−1
V Bi−1(s, x) = ψGM,θ∗
Optimize ﬁrst time step:

(s, x)

max
U ∈Rp

f (0, S0, U ) + ξ

ξ ≤V B0(S0, ˜X)
˜X =X0 + A0(S0)U + B0(S0)
X ≤ ˜X ≤ ¯X,
U ≤U ≤ ¯U ,

To test the algorithm, we suppose that the problem is linear, given by (12), (11) with the ﬂow
equation (6). The characteristics of the storages are unchanged. The initial forward curve is given by
F (0, T ) = 30+4 cos( 2πT
7 ). The price model is still given by (4) but with the parameters σ = 0.3, a = 0.16.
We take N = 42 and the optimization by the dynamic programming method using the property that
the optimal control are bang bang gives a value of 3426 while the value obtained in forward using the
optimal control is 3424. Using algorithm 2, we use a GroupMax network with 2 layers (one hidden layer)
and a group size equal to 2. The resolution with the ADAM stochastic gradient descent uses a batch size
of 200, a number of gradient iterations equal to 15000 with an initial learning rate equal to 5E − 3 and
decreasing to 1e − 4. Local optimizations are achieved with the Coin LP solver. Results for J ∗
M are given
in table 9.

M my max min
3317
1
3321
1
3334
1
3113
3
3173
3
3166
3
2758
5
2729
5
2799
5

3362
3370
3355
3207
3225
3233
3063
3012
3052

8
10
12
8
10
12
8
10
12

average min error

3335
3349
3345
3163
3202
3194
2913
2885
2980

61
53
69
218
200
192
360
411
371

Table 9: GMCSDP results on 10 runs for J ∗

M . Reference is SDP with regressions.

13

The accuracy decreases with the dimension while the variance of the result obtained increases. We
don’t see any clear diﬀerences using diﬀerent my values except perhaps in dimension 3, where an increase
of my seems to give slightly better results.

Remark 4.2. As the time induced by the LP resolution is highly related to the number of cuts used, we
my
2 cuts using my neurons). We keep
limit the number of layers to 2 (K = 1 which permit to have my2
mx equal to 8. As shown in [War22], it is necessary to increase the number of layers to get high accuracy
but this leads to very time consuming problems to solve.

In real industrial problems, constraints between storage reduces the volatility of the system and
convergence should be easier to achieve. This approach permits to avoid the memory cost due to the
storage of the Bellman functions and only the computing time remains a constraint: parallelization by
threads and MPI should permit to reduce eﬃciently this computing cost.

References

[Aba+15]

[ALG19]

[AW20]

[AXK17]

[Bac+21]

[BE+06]

[BW12]

Martin Abadi et al. TensorFlow: Large-Scale Machine Learning on Heterogeneous Sys-
tems. Software available from tensorﬂow.org. 2015. url: https : / / www . tensorflow .
org/.

Cem Anil, James Lucas, and Roger Grosse. “Sorting out Lipschitz function approxima-
tion”. In: International Conference on Machine Learning. PMLR. 2019, pp. 291–301.

Wim van Ackooij and Xavier Warin. “On conditional cuts for stochastic dual dynamic
programming”. In: EURO Journal on Computational Optimization 8.2 (2020), pp. 173–
199.

Brandon Amos, Lei Xu, and J Zico Kolter. “Input convex neural networks”. In: Interna-
tional Conference on Machine Learning. PMLR. 2017, pp. 146–155.

Achref Bachouch, Cˆome Hur´e, Nicolas Langren´e, and Huyen Pham. “Deep neural net-
works algorithms for stochastic control problems on ﬁnite horizon: numerical applica-
tions”. In: Methodology and Computing in Applied Probability (2021), pp. 1–36.

Christophe Barrera-Esteve et al. “Numerical methods for the pricing of swing options:
a stochastic control approach”. In: Methodology and computing in applied probability 8.4
(2006), pp. 517–540.

Bruno Bouchard and Xavier Warin. “Monte-Carlo valuation of American options: facts
and new algorithms to improve existing methods”. In: Numerical methods in ﬁnance.
Springer, 2012, pp. 215–255.

[Cur+21]

Nicolas Curin et al. “A deep learning model for gas storage optimization”. In: arXiv
preprint arXiv:2102.01980 (2021).

[CWNMW19] Quentin Chan-Wai-Nam, Joseph Mikael, and Xavier Warin. “Machine learning for semi

linear PDEs”. In: Journal of Scientiﬁc Computing 79.3 (2019), pp. 1667–1712.

[FMW19]

[Ger+21]

[Gev+18]

[GLP15]

[HJW18]

Simon F´ecamp, Joseph Mikael, and Xavier Warin. “Risk management with machine-
learning-based algorithms”. In: arXiv preprint arXiv:1902.05287 (2019).

Maximilien Germain, Mathieu Lauri`ere, Huyˆen Pham, and Xavier Warin. DeepSets and
their derivative networks for solving symmetric PDEs. 2021. arXiv: 2103.00838 [math.OC].

Hugo Gevret et al. “STochastic OPTimization library in C++”. PhD thesis. EDF Lab,
2018.

Pierre Girardeau, Vincent Leclere, and Andrew B Philpott. “On the convergence of de-
composition methods for multistage stochastic convex programs”. In: Mathematics of
Operations Research 40.1 (2015), pp. 130–145.

Jiequn Han, Arnulf Jentzen, and E Weinan. “Solving high-dimensional partial diﬀerential
equations using deep learning”. In: Proceedings of the National Academy of Sciences
115.34 (2018), pp. 8505–8510.

14

[HS97]

[LS01]

[MVW07]

[PP91]

[Sha11]

[TB21]

[TVR01]

[War12]

[War22]

[Zah+17]

Sepp Hochreiter and J¨urgen Schmidhuber. “Long short-term memory”. In: Neural com-
putation 9.8 (1997), pp. 1735–1780.

Francis A Longstaﬀ and Eduardo S Schwartz. “Valuing American options by simulation:
a simple least-squares approach”. In: The review of ﬁnancial studies 14.1 (2001), pp. 113–
147.

Constantinos Makassikis, St´ephane Vialle, and Xavier Warin. “Distribution of a stochas-
tic control algorithm applied to gas storage valuation”. In: 2007 IEEE International
Symposium on Signal Processing and Information Technology. IEEE. 2007, pp. 485–490.

Mario VF Pereira and Leontina MVG Pinto. “Multi-stage stochastic optimization applied
to energy planning”. In: Mathematical programming 52.1 (1991), pp. 359–375.

Alexander Shapiro. “Analysis of stochastic dual dynamic programming method”. In:
European Journal of Operational Research 209.1 (2011), pp. 63–72.

Ugo Tanielian and Gerard Biau. “Approximating Lipschitz continuous functions with
GroupSort neural networks”. In: International Conference on Artiﬁcial Intelligence and
Statistics. PMLR. 2021, pp. 442–450.

John N Tsitsiklis and Benjamin Van Roy. “Regression methods for pricing complex
American-style options”. In: IEEE Transactions on Neural Networks 12.4 (2001), pp. 694–
703.

Xavier Warin. “Gas storage hedging”. In: Numerical methods in ﬁnance. Springer, 2012,
pp. 421–445.

Xavier Warin. “The GroupMax neural network approximation of convex functions”. In:
arXiv preprint arXiv:2206.06622 (2022).

M. Zaheer et al. “Deep Sets”. In: Advances in Neural Information Processing Systems
30. Ed. by I. Guyon et al. Curran Associates, Inc., 2017, pp. 3391–3401.

15

