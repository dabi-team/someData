CPM-sensitive AUC for CTR prediction

Zhaocheng Liu
zhaocheng.liu@mobvista.com
Mobvista. Inc
Chaoyang, Beijing, China

Guangxue Yin
guangxue.yin@mobvista.com
Mobvista. Inc
Chaoyang, Beijing, China

9
1
0
2

r
p
A
3
2

]

G
L
.
s
c
[

1
v
2
7
2
0
1
.
4
0
9
1
:
v
i
X
r
a

ABSTRACT
The prediction of click-through rate (CTR) is crucial for industrial
applications, such as online advertising. AUC is a commonly used
evaluation indicator for CTR models. For advertising platforms,
online performance is generally evaluated by CPM. However, in
practice, AUC often improves in oﬄine evaluation, but online CPM
does not. As a result, a huge waste of precious online traﬃc and hu-
man costs has been caused. This is because there is a gap between
oﬄine AUC and online CPM. AUC can only reﬂect the order on
CTR, but it does not reﬂect the order of CTR*Bid. Moreover, the
bids of diﬀerent advertisements are diﬀerent, so the loss of income
caused by diﬀerent reverse-order pair is also diﬀerent. For this rea-
son, we propose the CPM-sensitive AUC (csAUC) to solve all these
problems. We also give the csAUC calculation method based on dy-
namic programming. It can fully support the calculation of csAUC
on large-scale data in real-world applications.

KEYWORDS
CTR prediction, CPM-sensitive, AUC, evaluation indicator

ACM Reference format:
Zhaocheng Liu and Guangxue Yin. 2016. CPM-sensitive AUC for CTR
prediction. In Proceedings of ACM Conference, Washington, DC, USA, July
2017 (Conference’17), 3 pages.
DOI: 10.1145/nnnnnnn.nnnnnnn

1 INTRODUCTION
The prediction of click-through rate (CTR) is crucial for online ad-
vertising. For each request, we need to choose the ads that maxi-
mize our beneﬁts from a bunch of candidate ads to return. The bid
and CTR of each ad varies on diﬀerent traﬃc. Therefore, in order
to maximize the expected revenue, the common practice is to use
CTR*bid as the basis for rank. We need to constantly optimize the
CTR model to make the online rank more accurate.

To determine whether the new iterated model is better than the
baseline, the usual approach is to evaluate the model oﬄine ﬁrst.
Compare the AUC of the old and new models on the validation data
set. If the auc is improved, the online A/B test experiment can be
carried out to verify the online cost per mille (CPM) improvement.
However, it often happens that oﬄine auc has improvement,
while online CPM has not. This is due to the gap between oﬄine

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
Conference’17, Washington, DC, USA
© 2016 ACM. 978-x-xxxx-xxxx-x/YY/MM. . . $15.00
DOI: 10.1145/nnnnnnn.nnnnnnn

auc evaluation and online CPM performance. Traditional AUC is
the probability of correct ranking of a random ﬁpositiveﬁ-ﬁnegativeﬁ
pair. That is to say, only the order of CTR is considered, while the
order of CTR*bid is not. Moreover, diﬀerent reverse-order pairs
will cause diﬀerent income losses. AUC also cannot reﬂect this.

A lot of work has been done in the ﬁeld of CTR estimation, but
most of them focus on the model structure (FM[5], Wide&Deep[1],
PNN[4], DeepFM[2], DIN[8], DIEN[7] etc). There are also some ef-
forts to solve real-world common problems (ESSM[3], DeepMatch[10],
Rocket Training[6] etc). However, none of the above work attempts
to solve the fundamental problemﬁ!?ﬁ!?gap between evaluation in-
dicator and online performance. The GAUC[9] only guarantees the
consistency of oﬀ-line and on-line in sample distribution to a cer-
tain extent. But GAUC can’t eliminate the gap mentioned above.
In order to solve the above problem, we propose CPM-sensitive
AUC (csAUC). In the next section you will see its deﬁnition and
analysis. In order to use csAUC in real-world applications, we give
a detailed calculation of csAUC in the third section.

2 OUR APPROACH
2.1 Deﬁnition of csAUC
In dataset D, a positive sample xpos and a negative sample xneд are
randomly selected. The estimated values of the two samples in the
model are pCT Rpos and pCT Rneд. The value of AUC indicates the
probability that pCT Rpos is greater than pCT Rneд. The Deﬁnition
of AUC is as follows:

Deﬁnition 2.1. Using pCT R as rank basis, AUC is the probability

of correct ranking of a random (xpos , xneд ) pair.

In our csAUC:

• Samples are multilevel. The level of negative sample is
the lowest, and the level of positive sample is determined
according to its corresponding bid. The higher the bid is,
the higher the level of positive sample is.

• The revenue of every negative sample is 0. The rev-

enue of a positive sample equals its bid.

Now a high-level sample xh and a low-level sample xl are ran-
domly selected from dataset D. Deﬁne our revenue (Rev) of (xh, xl )
is as follows:

Rev(xh, xl ) =

T (xi ) =

bidh
T (xl )
(

0
bidi
(

pCT Rh ∗ bidh >= pCT Rl ∗ bidl
otherwise

i f xi is a neдative sample
otherwise

Using Rev function deﬁne csAUC as [DEF 2.2]

Deﬁnition 2.2. CsAuc of dataset D is

(xh , xl )∈D Rev(xh, xl )
(xh , xl )∈D bidh

.

Í

Í

 
 
 
 
 
 
Conference’17, July 2017, Washington, DC, USA

Zhaocheng Liu and Guangxue Yin

Table 1: Data demo

SampleID Bid

Label

A
B
C
D
E

100
4
3
2
999

1
1
1
1
0

Table 2: Sequences demo

Seq1

Seq2

Seq3

Seq4

Seq5

Seq6

D
C
B
A
E

A
B
C
D
E

A
C
B
D
E

A
B
D
C
E

B
C
D
E
A

A
B
E
C
D

2.3 gcsAUC
In order to ensure that the sample distribution is more consistent
between oﬄine and online evaluation, we can do group like GAUC[9]
ﬁrst, and then calculate csAUC in group. We call it gcsAUC. gc-
sAUC is the maximum simulation of online CPM in oﬄine evalua-
tion.

2.4 Overall Oﬀline Evaluation Metrics
We generally use AUC, COPC (click-over-predicted-click), gcsAUC,
ROPR (revenue-over-predicted-revenue) for oﬄine evaluation.

• AUC is used to evaluate the order of CTR.
• COPC is used to assess whether the overall estimate is

high or low.

• gcsAUC reﬂects the performance of oﬄine simulated CPM.
• ROPR reﬂects whether the expected income estimate is

high or low.

The formula for calculating COPC and ROPR of dataset D is as
follows:

COPC(D) =

i yi
i pCT Ri
Í
i yi ∗ bidi
Í
i pCT Ri ∗ bidi
Í

Table 3: AUC and csAUC for Seqs in Table 1

ROPR(D) =

Seq1

Seq2

Seq3

Seq4

Seq5

Seq6

AUC
csAUC 0.2976

1

1
1

1
0.9976

1
0.9976

0.9
0.069

0.8
0.988

2.2 Anlysis of csAUC
When the pCTR of any positive sample is greater than the pCTR
of every negative sample, the AUC is equal to 1. At this time, the
csAUC is not necessarily equal to 1.

Corollary 2.3. csAUC is equal to 1 if and only if the pCTR of
any positive sample is greater than the pCTR of all negative samples,
and positive samples are internally reversed by bid.

Traditional AUC can only measure the discrimination of posi-
tive and negative samples, it is far from enough. For example, our
validation set is shown in [TAB 1]. Suppose we have six diﬀerent
CTR models that need to be validated on this validation dataset.
Using pCT R ∗ bid as rank basis, the results of simulated rank are
Seq[1-6] which are shown in [TAB 2]. The AUC and csAUC for
these squences are shown in [TAB 3].

Seq[1-4] successfully separate positive and negative samples,
but the bias of ordering inside positive samples causes the values
of csAUC to be diﬀerent. Speciﬁcally, seq2 is the most proﬁtable,
seq1 loses a lot of revenue, and the beneﬁts of seq3 and seq4 are
equal. This reﬂects that the value of csAUC is closely aligned with
oﬄine cpm performance, while AUC is not. Moreover, Seq[5,6]
shows that AUC is sometimes negatively correlated with oﬄine
cpm performance. Since in the oﬄine data, the label of a sample is
equal to 1 or 0, thus csAUC deﬁned in [DEF 2.2] represents oﬄine
CPM performance. Therefore, csAUC is a better oﬄine evaluation
indicator than AUC.

3 IMPLEMENTATION OF CSAUC
Since the samples are multilevel, the computational complexity of
csAUC is much larger than that of AUC. We take a two-level bucket
to record the required statistics. Speciﬁcally:

Í

• The ﬁrst-level bucket represents a combination of label
and bid. All negative samples are placed under barrel No.
0 of the ﬁrst level. For positive samples, bid is divided into
buckets. The bigger the bid is, the bigger the bucket id.
• The second bucket represents the bucket of pCPM, calcu-
lates the pCPM of all samples in the validation set, and
normalizes it by Min-Max norm. Multiply the value of
norm by 1E5 to get the second-level bucket number.

The Min-Max norm is as follows:

pCPM ′
i

=

pCPMi − min{pCPM1, .., pCPMn }
max {pCPM1, .., pCPMn } − min{pCPM1, .., pCPMn }

After calculating the bucket number of each sample, the COUNT
operation is performed inside the bucket. So far we have triple data
like (level 1, level 2, cnt num).

Suppose there are l1 buckets in the ﬁrst-level and l2 buckets in
the second-level. The time complexity of the most direct method
for calculating csAUC from triple data is O(C2
∗ l2). Based on dy-
l1
namic programming, we reduce the time complexity to O(l1 ∗ l2).
See [ALG 1].

4 CONCLUSION
We propose the deﬁnition, analysis and fast calculation method
of csAUC. Compared with AUC, csAUC relies on CTR*Bid as the
sorting criterion, and is more sensitive to the loss of income caused
by diﬀerent reverse-order pairs. At the same time csAUC can be
combined with gauc, we call it gcsAUC. gcsAUC is basically the
maximum simulation of online CPM in oﬄine evaluation.

CPM-sensitive AUC for CTR prediction

Conference’17, July 2017, Washington, DC, USA

[3] Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, and
Kun Gai. 2018. Entire Space Multi-Task Model: An Eﬀective Approach for Esti-
mating Post-Click Conversion Rate. (2018).

[4] Yanru Qu, Han Cai, Kan Ren, Weinan Zhang, Yong Yu, Ying Wen, and Jun Wang.
2016. Product-based neural networks for user response prediction. In 2016 IEEE
16th International Conference on Data Mining (ICDM). IEEE, 1149–1154.

[5] Steﬀen Rendle. 2010. Factorization machines. In 2010 IEEE International Confer-

ence on Data Mining. IEEE, 995–1000.

[6] Guorui Zhou, Ying Fan, Runpeng Cui, Weijie Bian, Xiaoqiang Zhu, and Gai
Kun. 2018. Rocket Launching: A uniﬁed and eﬀecient framework for training
well-behaved light net. In Proceedings of the 32nd AAAI Conference on Artiﬁcial
Intelligence. AAAI.

[7] Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang
Zhu, and Kun Gai. 2018. Deep Interest Evolution Network for Click-Through
Rate Prediction. (2018).

[8] Guorui Zhou, Chengru Song, Xiaoqiang Zhu, Ying Fan, Han Zhu, Xiao Ma,
Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2017. Deep Interest Network for
Click-Through Rate Prediction. (2017).

[9] Han Zhu, Junqi Jin, Chang Tan, Fei Pan, Yifan Zeng, Han Li, and Kun Gai. 2017.
Optimized cost per click in taobao display advertising. In Proceedings of the 23rd
ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.
ACM, 2191–2200.

[10] Han Zhu, Xiang Li, Pengye Zhang, Guozheng Li, Jie He, Han Li, and Kun Gai.
2018. Learning Tree-based Deep Model for Recommender Systems. In Proceed-
ings of the 24th ACM SIGKDD International Conference on Knowledge Discovery
& Data Mining. ACM, 1079–1088.

Algorithm 1 Calculation of csAUC.
Require:

The set of predict sample (value,ecpm, cnt), Pn ;
The max level of value mlv and max level of ecpm mlc

Ensure:

cpm-sensitive AUC, csAU C;

1: Init дrid, le f t, middle,riдht as zero mlv ×mlc matrix, ls as zero

mlv × 1 matrix
2: feed Pn into дird as
3: for (value,ecpm,cnt) ∈ Pn do
4:

дridvalue,ecpm
+ = cnt
lsvalue
5:
6: end for
7: construct auxiliary variables
8: for v ∈ ranдe(mlv) do
9:

+ = cnt

tmp = 0
for c ∈ ranдe(mlc) do
tmp+ = дridv,c
le f tv,c = (v == 0?0 : le f tv−1,c ) + tmp
middlev,c = (v == 0?0 : middlev−1,c) + дridv,c

end for

14:
15: end for
16: for v ∈ ranдe(mlv) do
17:

tmp = 0
for c ∈ reverse(ranдe(mlc)) do

riдhtv,c = (v == 0?0 : riдhtv−1,c) + tmp

end for

20:
21: end for
22: calculate reward
23: tmp = 0, rewardmax = 0.0
24: for v ∈ ranдe(mlv) do
25:

rewardmax + = lsv ∗ tmp ∗ v
tmp+ = lsv

26:
27: end for
28: rewardr ank
29: for v ∈ ranдe(1,mlv ) do
for c ∈ ranдe(mlc) do
30:

= 0.0

+ = (c == 0?0 : le f tv−1,c−1) ∗ дridv,c ∗ v
+ = ((riдhtv−1, j − (c == mlc − 1?0 :

rewardr ank
rewardr ank
riдhti −1, j+1)) + middlei −1, j) ∗ дridv,c ∗ v ∗ 0.5
rewardr ank

+ = (c == mlc − 1?0 : riдhtv−1,c+1) ∗ дridv,c

end for

34:
35: end for
36: return rewardr ank /rewardmax ;

In addition, we also present the whole set of oﬄine indicators
that we are using. Each indicator provides its own insights for
understanding the eﬀects of our models.

REFERENCES
[1] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra,
Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al.
2016. Wide & deep learning for recommender systems. In Proceedings of the 1st
Workshop on Deep Learning for Recommender Systems. ACM, 7–10.

[2] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017.
DeepFM: a factorization-machine based neural network for CTR prediction.
arXiv preprint arXiv:1703.04247 (2017).

10:

11:

12:

13:

18:

19:

31:

32:

33:

