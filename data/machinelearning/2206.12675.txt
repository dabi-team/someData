2
2
0
2

n
u
J

5
2

]

V
C
.
s
c
[

1
v
5
7
6
2
1
.
6
0
2
2
:
v
i
X
r
a

Learning to Infer 3D Shape Programs
with Differentiable Renderer

Yichao Liang∗
Department of Computer Science
University of Oxford
ycliang6@gmail.com

Abstract

Given everyday artifacts, such as tables and chairs, humans recognize high-level
regularities within them, such as the symmetries of a table, the repetition of its legs,
while possessing low-level priors of their geometries, e.g., surfaces are smooth
and edges are sharp. This kind of knowledge constitutes an important part of
human perceptual understanding and reasoning. Representations of and how to
reason in such knowledge, and the acquisition thereof, are still open questions
in artiﬁcial intelligence (AI) and cognitive science. Building on the previous
proposal of the 3D shape programs representation alone with the accompanying
neural generator and executor from Tian et al. [12], we propose an analytical yet
differentiable executor that is more faithful and controllable in interpreting shape
programs (particularly in extrapolation) and more sample efﬁcient (requires no
training). These facilitate the generator’s learning when ground truth programs are
not available, and should be especially useful when new shape-program components
are enrolled either by human designers or—in the context of library learning—
algorithms themselves. Preliminary experiments on using it for adaptation illustrate
the aforesaid advantages of the proposed module, encouraging similar methods
being explored in building machines that learn to reason with the kind of knowledge
described above, and even learn this knowledge itself.

1

Introduction

We study the inverse problem of inferring holistic representations from 3D shapes. When given a 3D
shape object (e.g., a chair), we are interested in inducing a graphics program deﬁned in a Domain-
Speciﬁc Language (DSL) that captures, in particular, the high-level regularities of the 3D object, as
well as the low-level shape priors. Using a program-like latent representation brings forth notably the
following three advantages. 1. Given images of real-life objects, such as tables, ofﬁce chairs, humans
immediately recognize the high-level concept embodied in the objects such as reﬂective symmetries
of tables, radial symmetries of the legs of ofﬁce chairs, etc. This kind of knowledge has been shown
to constitute an important aspect of human visual recognition and reasoning [4, 2], and is naturally
expressed by programming language constructs such as the For loop statement. 2. By using shape
primitives as the terminals in a DSL grammar, we are able to capture the shape priors such as sharp
edges and smooth surfaces that the other shape representations such as voxels, point clouds, meshes
ﬁnd hard to capture. 3. Finally, such high-level, holistic object representations can facilitate low-level
manipulation tasks such as inpainting and extrapolation.

In recent years, there is a particular surge of interest in modelling perceptual data using graphics
programs. These include focuses on 2D images [8, 6], 3D shapes [13, 12], or even scenes and short
videos [5, 7]. Most inspiring to us, Tian et al. [12] propose 3D shape programs—as deﬁned by a
DSL (Fig. 1)—as a useful representation for modeling 3D shapes. The DSL is accompanied by

∗Work done in 2020 during an internship with Bob Fisher, The University of Edinburgh.

 
 
 
 
 
 
a pair of neural generator-executor (a.k.a. encoder-decoder) for inferring and interpreting shape
programs respectively. In particular, the neural program executor is motivated by the need for
ﬁnetuning the generator in the absence of ground truth programs and by the understanding that certain
high-level program command, e.g., the For loop statement would make any analytical renderer
non-differentiable [12]. In our work, we argue that the For loop statement and the shape programs
in general can indeed be executed by a non-neural yet still differentiable renderer that we contribute.

The analytical renderer is not only more precise and requires fewer parameters, which could be
important in ﬁnetuning; but also make enrollment of new shape primitives much more straightforward,
which could be particularly useful in the context of library learning as neural alternatives would likely
require additional data and training for the new shape program components.

In summary, our contributions are mainly two-fold:

1. we contribute a differentiable rendering method for shape programs, which can lead to more

effective adaptation to new classes of objects.

2. we suggest several methods of training the program generator when such a renderer is

available, and show preliminary results when one of these objectives is employed.

Figure 1: The DSL for 3D shape programs, copied from [12].

2 Related work

Many recent works attempt to capture program-like perceptual abstraction of visual data. For 2D
images, Mao et al. [8] demonstrate the ability to capture the regularities (lattice, circular pattern)
of repeated objects’ position in the scene captured from a fronto-parallel plane with respect to
the object plane, with a search-based algorithm. Li et al. [6] exploit the regularities among the
objects, generalizing the previous work to allow arbitrary viewpoints, by explicitly estimating the
camera pose as a part of the program synthesize process in a hybrid of search and gradient-based
algorithm. Liu et al. [7] model regularly placed primitive objects in images with not only centroids
but the shape primitives themselves, such as cubes, spheres, and cylinders, alone their position and
rotation in the scene. On the front of 3D objects, Tulsiani et al. [13] model 3D voxel representation
of more complex objects, e.g., chairs, tables, with cuboids but without using high-level program
statements, e.g., the For loops, which results in difﬁculties in capturing regularities in objects and
the semantics of primitives. Sharma et al. [11] use programs in a language of Constructive Solid
Geometry (CSG) (which allows arithmetic operations on shapes) to enable modeling of more complex
shapes. Tian et al. [12] performs program synthesis on similarly complex objects in canonical view
frames, directly from 3D voxel, using purely a neural approach. Their system leverages the common
bilateral and/or radial symmetry of artifacts to achieve higher accuracy than Tulsiani et al. [13]. To
allow self-supervised learning without program-level annotation, they propose another neural module,
the program executor, for rendering programs in their DSL.

Their system is trained through a biphasic procedure: 1. train each of the two modules on hand
designed, synthetic data, in a supervised learning setting; 2. train the program generator with gradient
signals backpropogated through the program executor computed on reconstruction loss with respect
to real data, e.g., from ShapeNet. The latter is named as Guided Adaptation in the sense that the
neural program executor guides the generator to adapt to out-of-distribution object classes.

2

PublishedasaconferencepaperatICLR2019Program→Statement;ProgramStatement→Draw(Semantics,Shape,PositionParams,GeometryParams)Statement→For(ForParams);Program;EndForSemantics→semantics1|semantics2|semantics3|...Shape→Cuboid|Cylinder|Rectangle|Circle|Line|...PositionParams→(x,y,z)GeometryParams→(g1,g2,g3,g4,...)ForParams→TranslationParams|RotationParamsTranslationParams→(timesi,orientationu)RotationParams→(timesi,angleθ,axisa)Table1:Thedomainspeciﬁclanguage(DSL)for3Dshapes.Semanticsdependsonthetypesofobjectsthataremodeled,i.e.,semanticsforvehicleandfurnitureshouldbedifferent.FordetailsofDSLinourexperimentalsetting,pleaserefertosupplementary.Programsynthesis.IntheAIliterature,Ellisetal.(2018)leveragedsymbolicprogramsynthesistechniquestoinfer2Dgraphicsprogramsfromimages,extendingtheirearlierworkbyusingneuralnetsforfasterinferenceoflow-levelcuessuchasstrokes(Ellisetal.,2015).Here,weshowhowapurelyend–to–endnetworkcanrecover3Dgraphicsprogramsfromvoxels,conceptuallyrelevanttoRobustFill(Devlinetal.,2017),whichpresentsapurelyend-to-endneuralprogramsynthesizerfortextediting.TheveryrecentSPIRALsystem(Ganinetal.,2018)alsotakesasitsgoaltolearnstructuredprogram–likemodelsfrom(2D)images.AnimportantdistinctionfromourworkhereisthatSPIRALexplainsanimageintermsofpaint-like“brushstrokes”,whereasweexplain3Dvoxelsintermsofhigh-levelobjectsandsemanticallymeaningfulpartsofobjects,likelegsortops.OthertangentialrelatedworkonprogramsynthesisincludesBalogetal.(2017);Devlinetal.(2017);Parisottoetal.(2017);Gauntetal.(2016);Sunetal.(2018a);Liuetal.(2019).Learningtoexecuteprograms.NeuralProgramInterpreters(NPI)havebeenextensivelystudiedforprogramsthatabstractandexecutetaskssuchassorting,shapemanipulation,andgrade-schoolarithmetic(Reed&DeFreitas,2016;Caietal.,2017;Boˇsnjaketal.,2017).InNPI(Reed&DeFreitas,2016),thekeyinsightisthataprogramexecutiontracecanbedecomposedintopre-deﬁnedoperationsthataremoreprimitive;andateachstep,anNPIlearnstopredictwhatoperationtotakenextdependingonthegeneralenvironment,domainspeciﬁcstate,andpreviousactions.Caietal.(2017)improvedthegeneralizationofNPIsbyaddingrecursion.Johnsonetal.(2017)learnedtoexecuteprogramsforvisualquestionandanswering.Inthispaper,wealsolearna3Dshapeprogramexecutorthatrenders3Dshapesfromprogramsasacomponentofourmodel.33DSHAPEPROGRAMSInthissection,wedeﬁnethedomain-speciﬁclanguagefor3Dshapes,aswellastheproblemofshapeprogramsynthesis.Table1showsourDSLfor3Dshapeprograms.Eachshapeprogramconsistsofavariablenumberofprogramstatements.AprogramstatementcanbeeitherDraw,whichdescribesashapeprimitiveaswellasitsgeometricandsemanticattributes,orFor,whichcontainsasub-programandparametersspecifyinghowthesubprogramshouldberepeatedlyexecuted.Thenumberofargumentsforeachprogramstatementvaries.Wetokenizeprogramsforthepurposeofneuralnetworkprediction.Eachshapeprimitivemodelsasemantically-meaningfulpartofanobject.Itsgeometricattributes(Table1:GeometryParams,PositionParams)specifythepositionandorientationofthepart.Itssemanticattributes(Table1:Semantics)specifyitsrelativerolewithinthewholeshape(e.g.,top,back,leg).Theydonotaffectthegeometryoftheprimitive;instead,theyassociategeometricpartswiththeirsemanticmeaningsconveyinghowpartscanbesharedacrossobjectcategoriessemanticallyandfunctionally(e.g.,achairandatablemayhavesimilarlegs).OurForstatementcaptureshigh-levelregularityacrossparts.Forexample,thelegsofatablecanbesymmetricwithrespecttoparticularrotationangles.Thehorizontalbarsofachairmaylayoutregularlywithaﬁxedverticalgap.EachForstatementcancontainsub-programs,allowingrecursivegenerationofshapeprograms.3We note that the Guided-Adaptation towards new subclasses of objects outside the synthetic ones,
i.e., subclass are not seen during the training with synthetic data e.g., beds, benches, did not lead to
ideal results, as demonstrated in Fig. 2. Many reconstructions are neither faithful nor consistent. We
hypothesize that a part of this side effect is due to the approximation nature of the program executor.
With this and its relatively poor sample efﬁciency, we regard our method as the ﬁrst step towards more
efﬁcient and effective adaptation to new object classes and possible shape-program library learning.

(a)

(e)

(b)

(f)

(c)

(g)

(d)

(h)

Figure 2: Representative reconstruction samples after “guided adaptation" from Tian et al. [12] from
a random class of objects—beds. The ﬁrst row shows the input shapes in from ShapeNet a voxel
representation; the second row depicts the shape rendered from the predicted shape programs.

3 Problem Statement

We review the problem of Shape Primitive Decomposition and Shape Program Decomposition. Let
denote the mesh, voxel, and point

denote a 3D object, e.g., the 3D model of a chair, and

,

,
M

V

P

O
cloud representation of

, respectively.

O

O

1, . . . , n

and a set of N shape primitives

Shape Primitive Decomposition. Use [n] to represent the set of integers
. Inspired by
{
}
Tulsiani et al. [13] and Zou et al. [14], we formulate the problem of shape primitive decomposition
Pn}
[N ], ﬁnd a collection of
as: given a shape object
{
M primitives such that their afﬁne transformed version [ ¯Pm] has a small discrepancy when placed
((cid:83)
) is small. Note that this objective can
together with respect to the target shape, i.e.,
in principle computed between any combination of primitive, target representations (such as voxel,
mesh, etc).
In more detail, each transformed primitive ¯Pm is speciﬁed by a 4-tuple (P i
identiﬁes its type, e.g., a cuboid, or an ellipsoid, etc; P z
width, depth; P t
m = (tx
its rotation in Euler angle and axis form.

m), where P i
m, P z
m
m its size, e.g., in case Pm is a cuboid, its height,
m)

m) its center coordinate in the target frame, and P q

m = (qx

m, P q

m, P t

m, qy

with n

m, qz

m, ty

m, tz

¯Pm,

O

L

∈

m

Shape Program Decomposition. Shape programs can be viewed as an extension to shape primi-
tives that are able to more holistically captures the structures of shapes by leveraging control ﬂow
statements from imperative programming languages.

, infer a shape program
In this context, the problem can be framed as, when given a shape object
ρ such that the shape rendered from it has small discrepancy with respect to the target object
) to denote the interpreter for the language. This is similar in ﬂavor to the
·

L
objective in shape primitive decomposition.

)—using R(

(R(ρ),

O

O

3

Figure 3: Schematics borrowed from Tian et al. [12] to illustrate the design of the shape program
generator. Exactly the same design is used in our experiment to evaluate the renderer that we are
proposing. The architecture is composed of three modules: a 3D convolution network, a Block, and a
Step LSTM.

4 Approach

Building on the neural program generator (a.k.a., encoder) from Tian et al. [12] (summarized in § 4.1),
we describe in detail the analytical, differentiable renderer that we are contributing (§ 4.2) as well as
two concrete ways of ﬁnetuning the program generator in a self-supervised fashion. When used in
tandem with our renderer, we refer to them as Direct Adaptation (DA). The renderer we present here
is more accurate, especially in extrapolation, and does not require any training compared to neural
alternatives. Consequently, this should lead to a more preferable ﬁnetuning result and would be
particularly convenient when additional shape-program components are enrolled by either designers
or during library learning, as a neural renderer would require additional training.

4.1 Program Generator

) predicts
At a high level, given the voxel representation
·
the corresponding shape program consisting of K program blocks, each with J steps, that attempts to
capture the geometry of
. The inferred programs are deﬁned by a DSL (Fig. 1). We use exactly the
same design as in Tian et al. [12] for the later experiments to compare the beneﬁt of using different
renderers.

, the program generator h(

of a shape

O

V

V

In more detail, as illustrated in Fig. 3, the generator processes an input voxel in the following three
steps: 1. a 3D convolution net takes the stack of the target voxel and the voxel-reconstruction-so-far,
to generate a feature encoding, hk
shape to
compute a block-level feature hk
block to
produce a ﬁxed, J-steps of program statements. At each step, the output consists of G logits for
the categorical distribution of the program statement (including one for the empty statement) and L
values for parameterizing the sampled statement, independent of the ﬁnal statement chosen.

shape; 2. a LSTM (denoted as the block LSTM) uses hk
block; 3. ﬁnally, another LSTM (the step LSTM) takes hk

4.2 Direct Adaptation with Differentiable Executor

In the absence of program-level supervision, as it is usually the case, after learning on synthetic data,
the generator can primarily only be trained with variations of the reconstruction tasks; compute a
reconstruction loss of the rendering output with respect to any representation of the target object
and backpropagate the gradient to the generator for updates.

O

To this end, one can either leverage a neural program executor—as in [12]—or an analytical, differen-
tiable renderer, which is introduced in this section. To be speciﬁc, a differentiable renderer transforms
a shape program predicted by the renderer, ρ = [ρkj], to a graphical representation of the program
such as a point cloud or voxel, which can be used in computing differentiable loss objectives, for
ﬁnetuning the generator’s parameters.

4

PublishedasaconferencepaperatICLR2019draw('Top','Rect',…)for (…):for (…):draw('Leg','Cub',…)draw('Layer','Rect',…)Vacant TokenProgram ParamsStep LSTMBlock 1Block 2Block 3Step LSTMStep LSTMBlock 4EmptyCanvas++++Block featuresProgram ID 1Program ID 1InitProgram ParamsProgram ID 2Program ID 2Block LSTMStep 2Step 1++Step LSTMStep LSTMStep LSTM3D Conv3D Conv3D Conv3D Conv3D ConvFigure2:Thecoreofour3DshapeprogramgeneratoraretwoLSTMs.TheBlockLSTMemitsfeaturesforeachprogramblock.TheStepLSTMtakesthesefeaturesasinputandoutputsprogramsinsideeachblock,whichincludeseitherasingledrawingstatementorcompoundstatements.Theproblemofinferringa3Dshapeprogramisdeﬁnedasfollows:predictinga3Dshapeprogramthatreconstructstheinputshapewhentheprogramisexecuted.Inthispaper,weusevoxelizedshapesasinputwitharesolutionof32×32×32.4INFERRINGANDEXECUTING3DSHAPEPROGRAMSOurmodel,calledShapePrograms,consistsofaprogramgeneratorandaneuralprogramexecutor.Theprogramgeneratortakesa3Dshapeasinputandoutputsasequenceofprimitiveprogramsthatdescribethis3Dshape.Theneuralprogramexecutortakestheseprogramsasinputandgeneratesthecorresponding3Dshapes.Thisallowsourmodeltolearninaself-supervisedwaybygeneratingprogramsfrominputshapes,executingtheseprograms,andback-propagatingthedifferencebetweenthegeneratedshapesandtherawinput.4.1PROGRAMGENERATORWemodelprogramgenerationasasequentialpredictionproblem.Wepartitionfullprogramsintotwotypesofsubprograms,whichwecallblocks:(1)asingledrawingstatementdescribingasemanticpart,e.g.circletop;and(2)compoundstatements,whicharealoopstructurethatinterpretsasetoftranslatedorrotatedparts,e.g.foursymmetriclegs.Thispart-based,symmetry-awaredecompositionisinspiredbyhumanperception(Fleuretetal.,2011).OurprogramgeneratorisshowninFigure2.ThecoreoftheprogramgeneratorconsistsoftwoorthogonalLSTMs.Theﬁrstone,theBlockLSTM,connectssequentialblocks.Thesecondone,theStepLSTM,generatesprogramsforeachblock.Ateachblock,weﬁrstrendertheshapedescribedbypreviousprogramblockswithagraphicsengine.Then,therenderedshapeandtherawshapearecombinedalongthechanneldimensionandfedintoa3DConvNet.TheBlockLSTMtakesthefeaturesoutputbythe3DConvNetandoutputsfeaturesofthecurrentblock,whicharefurtherfedintothestepLSTMtopredicttheblockprograms.ThereasonwhyweneedthestepLSTMisthateachblockmighthaveadifferentlength(e.g.,loopbodiesofdifferentsizes).Givenblockfeaturehblk,theStepLSTMpredictsasequenceofprogramtokens,eachconsistingofaprogramidandanargumentmatrix.Thei-throwoftheargumentmatrixservesforthei-thprimitiveprogram.FromtheLSTMhiddenstateht,twodecodersgeneratetheoutput.Thesoftmaxclassiﬁcationprobabilityoverprogramsetsisobtainedbyfprog:RM→RN.Theargumentmatrixiscomputedbyfparam:RM→RN×K,whereNisthetotalnumberofprogramprimitivesandKisthemaximumpossiblenumberofarguments.Thefeed-forwardstepsoftheStepLSTMaresummarizedasht=flstm(xt,ht−1),(1)pt=fprog(ht),at=fparam(ht),(2)wheretheptandatcorrespondstotheprogramprobabilitydistributionandargumentmatrixattimet.AftergettingtheprogramID,weobtainitsargumentsbyretrievingthecorrespondingrowinthe4The key insight that enables analytical yet differentiable rendering in the presence of high-level
statements such as the For loop statement is that each block of the generated program ρm can be
unrolled and transformed, via a differentiable operation, into a semantically equivalent, collection
n, P q
n)
, as in the problem of shape primitive decomposition. For
of shape primitives,
}
example, the For loops with shape primitive statement inside them, can be expended into a set of
basic drawing statements with the renderings before and after the expansion correspond to the same
ﬁnal shape.

n, P z

n , P t

(P i

{

The procedure of removing higher-order statements is performed on a case-by-case basis as they
are parameterized in distinct spaces. As a concrete example, a Translation For statement ρ is
parameterized by (ρ1, ρ2, ρ3) representing the incremental shift on the (x, y, z) axes of the objects
inside the loop, while a Rotation For statement has only one meaningful parameter, (ρ1), indicating
the number of times the inner drawing statement should be repeated with respect to the x-axis to
complete a full rotation, e.g., ρ1 = 3 denotes the inner statements are drawn 3 times with 120-degree
rotation apart, and ρ1 = 5 means 5 repetitions, 72-degree apart.

Different primitive statements ρ also have distinct parameter spaces, which would need to be taken
into consideration both when they are inside higher-order statements and when converting them from
their own program parameter spaces [ρl] to the shape primitive space, (P i, P z, P t, P q). To illustrate,
a line drawing statement draws a cylindrical shape that has (ρ1, ρ2, ρ3), (ρ4, ρ5, ρ6) to indicate its
start, end coordinates respectively, and (ρ7) to specify its radius; While a chair_back statement has
(ρ1, ρ2, ρ3) representing the front-bottom-left position of a cuboid, (ρ4, ρ5, ρ6) specifying its height,
width and depth, and (ρ7) representing its elevation angle. In total, 22 semantically distinct programs
statements exist in the original DSL.

n, P z

ρkj}
{

(P i
{

is unrolled and replaced with the collection of semantically
With this in mind, a shape program
equivalent basic program statements, then the basic statements are transformed to the shape primitive
space with
. In the end, these standardized shapes are either cuboids or cylinders
}
for the current DSL. Up to this point, we have in our hand a rather abstract representation of
the reconstructed shape; we haven’t provided any method for “displaying" them onto the screen.
Nevertheless, we can already derive a differentiable objective for learning, as we will describe in
§ 4.3.2.

n, P q
n)

n , P t

[

−

∼ U

We carry on to present a way of rendering the shapes primitives to a point cloud representation,
exercising the reparameterization trick in a similar spirit to [13, 3]. We exploit the fact that sampling
a point p on a transformed primitive ¯P , is semantically equivalent to sampling a point p(cid:48) from
1, 1]3, then transforming it according to the shape’s
a standard uniform distribution, p(cid:48)
parameters (P z, P t, P q). Compared to sampling directly from the range deﬁned by ¯Pm, this method
has the crucial beneﬁt of decoupling the outputting parameters from the stochastic sampling process,
which enables backpropagation of the loss gradient to the shape’s geometric parameters. As an
example, to sample a point from the lateral surface of a cylinder ¯Pc with parameters (P z
c , P q
c , P t
c )
2 , 1
1
where P z
2 ].
[
−
∼ U
Then the corresponding point on ¯Pc can be obtained by applying the rotation P t
q and translation P t
c
to the point p(cid:48)(cid:48) = (sh ∗
To ensure uniform sampling coverage w.r.t. all primitive surfaces corresponding to an object, the
number of points sampled on each shape primitive’s surface is determined to be proportional to its
surface area.

c = (sr, sh), we can ﬁrst sample an angle value θ

π, π] and a height h

h, sin(θ), cos(θ))

∼ U

−

[

Note that besides the abstract primitive representation and the point cloud representation we presented
here, other differentiable representations could also be devised and employed (e.g., voxel, mesh,
hidden activations from another neural net). Further, while the geometry parameters of a shape
program (including position, rotation, etc) may receive gradients when trained with these renderers,
the program indices itself (i.e., whether to use the table_top program or chair_leg program or a
For loop statement) does not. But this is independent of whether higher-level statements exist in the
DSL, and gradient estimators for discrete variables such as REINFORCE and NVIL [9, 10] can be
utilized.

4.3 Learning Objectives

With the reconstructed representations, self-supervised learning objectives can be deﬁned on top of
nearly all (target representation, reconstructed representations) combinations. We elaborate on two

5

such objectives, building on the two representations we discussed in § 4.2 respectively. Namely, we
introduce a loss for when target point clouds are paired with abstract shape primitives reconstructions
(§ 4.3.2), and with point clouds reconstructions (§ 4.3.1). Point cloud representations for target
shapes are commonly available; they could be easily obtained from a mesh representation which is
the default representation in many 3D shape datasets, e.g., ShapeNet [1] or derived from the voxel
representation that the program generator uses.

4.3.1 Point Cloud with Point Cloud

We start with a straightforward objective deﬁned with respect to a target point cloud and a recon-
structed point cloud. With a pair of point clouds, Chamfer distance (CD) can be readily computed
and leveraged for learning: it is computed by taking the sum of the square distances for each point in
one point cloud to its nearest point in the other point cloud. Note that by the deﬁnition as above, CD
is not symmetrical in its arguments and hence not a mathematical distance function. Thus one may
wish to utilize a combination of the forward and backward score in optimization.

4.3.2 Point Cloud with Shape Primitives

With the set of shape primitives
the target point cloud
generator to target shapes without program supervision, as inspired by Tulsiani et al. [13].

representing the generator prediction, the coverage loss of
and the union of the shape primitives is another criterion for adapting the

P

¯Pm}
{

The objective suggests that the generator should be penalized if the union of the generated shapes
(cid:83)
. A sufﬁcient condition to ensure this is that all sample

¯Pm does not cover the target point cloud

P
points from the target point cloud evaluate zero in the distance ﬁeld of the generated shapes:

m

(cid:34)

(
L

¯Pm}
,
{

P

) = Ep

∼P

(cid:107)C

(cid:35)

(p;

(cid:91)

m

¯Pm)

(cid:107)2

(1)

Where we make use of the notion of distance ﬁeld
P , denoting the closest distance from a point p to the surface of the shape primitives P .

→

C

(p; P ) :: R3

R+ deﬁned on shape primitive

When calculating the distance ﬁeld of a set of shape primitives, it can be shown that the distance ﬁeld
w.r.t. the union of a set of primitives equals to the element-wise minimum among the distance ﬁelds
of the individual primitives.

C(p;

(cid:91)

m

¯Pm) = minmC

(p; ¯Pm)

(2)

As we only have cuboid and cylinder primitives in the current DSL, if sufﬁce to deﬁne the distance
Ccub(p; P z) of an origin-centered cuboid with P z =
ﬁeld for them. For cuboid, the distance ﬁeld
(sx, sy, sz) can be deﬁned as in as2:
Ccub(p; P z)2 = (
px| −
|

sz)2
py| −
(3)
+
|
Ccyl(p; P z) of an origin-centered cylinder with
as in [13]. By a similar token, the distance ﬁeld
P z = (sx, sy) corresponding to the height, radius of the cylinder can be computed by a simple
algorithm (for details, see Appendix A).

pz| −

+ + (

+ + (

sx)2

sy)2

|

With the method of computing the distance ﬁeld of primitives in their canonical frame, the distance
ﬁeld at a point p of a transformed primitive ¯P with transformation parameters (P t, P q) can be
calculated by evaluating the result of applying the inverse transformation of P t, P q to the point p in

; P ). We thereby obtain a way to compute the distance ﬁeld of any primitive in any pose:

(
·

C

(

; Pm) =
·

C

(cid:26)

; P z
Ccub(
·
; P z
Ccyl(
·

m),
m),

m = cuboid

if P i
otherwise

(4)

5 Experiments

We experiment with the accuracy (§ 5.1) and utility (§ 5.2) of our differentiable renderer. We show
preliminary results of direct adaptation that uses the point cloud representation and the chamfer

2let max(0, x) ≡ x+.

6

(a)

(b)

(c)

(d)

(e)

(g)

(h)

(i)

(f)

(j)

Figure 4: The ﬁrst row shows the shape program corresponding to the ﬁrst 2 chairs below; the second
row shows the rendered shapes from the non-differentiable render; and the third row shows the
outputs of our differentiable renderer in the form of sampled surface points, which can be used to
train the program generator model.

distance objective. We run experiment on a subset of ShapeNetCore v2. Each object
mesh representation
32x32x32 as the input for the neural program generator.

and binvox3 is used to convert

to a voxel representation

M

M

V

has a
O
of dimension

5.1 Differentiable Rendering

Figure 4 shows sampled non-differentiable vs differentiable renderings, and their corresponding
program outputs. The output of our renderer is illustrated by 5,000 sample points on the surface of
the shape primitives. Qualitatively, the differentiable renderer is able to accurately interpret different
types of complex program statements, which is critical to the generator’s successful adaptation to
new classes of shapes. And we hope to perform more quantitative evaluations in future works.

5.2 Results of Direct Adaptation

By sampling 5,000 points on the reconstructed shape primitives’ surfaces and the mesh surface
respective, we ﬁnetune the generator on the Chamfer distance loss as deﬁned in § 4.3.1. Table 1
shows that our model outperforms the Guided Adaptation model by more than. 50% as measured by
Chamfer distance on the held out set. We leave further qualitative and quantitative evaluations for
future work.

6 Conclusion

In this work, we present an analytical differentiable renderer for more accurate rendering and more
efﬁcient adaptation of the neural program generator that requires no training. We show that, with
preliminary results, it has prospects of becoming a useful member of the shape program toolkit. While

3https://www.patrickmin.com/binvox/

7

Table 1: The performance of the Shape Program Generator after being ﬁne-tuned with different
adaptation methods. The ﬁrst row shows the model without any adaptation.

Models

CD bench CD cabinet

Shape Programs
Shape Programs w. GA
Shape Programs w. DA (ours)

0.0135
0.0078
0.0035

0.0104
0.0092
0.0043

our executor is presented as an alternative to the neural executor, one may also wish to experiment
with the utility of using a hybrid of them which we leave for future work. We hope this is also a
step towards learning shape program libraries, as, in contrast to neural program interpreters, our
renderer can be ﬂexibly modiﬁed to precisely interpret new program statements without any training.
In future works, we hope to realized library learning of shape programs, and experiment with other
differentiable reconstruction representations and learning objectives.

7 Acknowledgment

We thank our advisor Bob Fisher for his constant support, insightful discussion throughout this
project, and helpful comments on early manual scripts.

References

[1] A. X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva,
S. Song, H. Su, et al. Shapenet: An information-rich 3d model repository. arXiv preprint
arXiv:1512.03012, 2015.

[2] D. D. Dilks, J. B. Julian, J. Kubilius, E. S. Spelke, and N. Kanwisher. Mirror-image sensitivity
and invariance in object and scene processing pathways. Journal of Neuroscience, 31(31):
11305–11312, 2011.

[3] D. P. Kingma and M. Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114,

2013.

[4] K. Koffka. Principles of Gestalt psychology, volume 44. Routledge, 2013.

[5] Y. Li, J. Mao, X. Zhang, B. Freeman, J. Tenenbaum, N. Snavely, and J. Wu. Multi-plane
program induction with 3d box priors. Advances in Neural Information Processing Systems, 33:
7425–7436, 2020.

[6] Y. Li, J. Mao, X. Zhang, W. T. Freeman, J. B. Tenenbaum, and J. Wu. Perspective plane program
induction from a single image. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, pages 4434–4443, 2020.

[7] Y. Liu, J. Wu, Z. Wu, D. Ritchie, W. T. Freeman, and J. B. Tenenbaum. Learning to describe
scenes with programs. In International Conference on Learning Representations, 2019. URL
https://openreview.net/forum?id=SyNPk2R9K7.

[8] J. Mao, X. Zhang, Y. Li, W. T. Freeman, J. B. Tenenbaum, and J. Wu. Program-guided image
manipulators. In The IEEE International Conference on Computer Vision (ICCV), October
2019.

[9] A. Mnih and K. Gregor. Neural variational inference and learning in belief networks. In

International Conference on Machine Learning, pages 1791–1799. PMLR, 2014.

[10] J. Schulman, N. Heess, T. Weber, and P. Abbeel. Gradient estimation using stochastic computa-

tion graphs. arXiv preprint arXiv:1506.05254, 2015.

[11] G. Sharma, R. Goyal, D. Liu, E. Kalogerakis, and S. Maji. Neural shape parsers for constructive

solid geometry. arXiv preprint arXiv:1912.11393, 2019.

8

[12] Y. Tian, A. Luo, X. Sun, K. Ellis, W. T. Freeman, J. B. Tenenbaum, and J. Wu. Learning to infer

and execute 3d shape programs. arXiv preprint arXiv:1901.02875, 2019.

[13] S. Tulsiani, H. Su, L. J. Guibas, A. A. Efros, and J. Malik. Learning shape abstractions by
assembling volumetric primitives. In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, pages 2635–2643, 2017.

[14] C. Zou, E. Yumer, J. Yang, D. Ceylan, and D. Hoiem. 3d-prnn: Generating shape primitives with
recurrent neural networks. In Proceedings of the IEEE International Conference on Computer
Vision, pages 900–909, 2017.

9

Algorithm 1 Distance Field of a Cylinder
Input: point p, cylinder_shape sx, sy
Return: squared_distance d
Initialize c = [0, 0, 0], a = [sx, 0, 0], b = [
a,b the center of the top/bottom disc of the cylinder}
Initialize u = (b
x = (c
−
n2 = (c
−
y2 = n2
−
x
if
|
{if p is on the side of the cylinder}
if y2 =< r2 then

p)
·
p)2 {squared distance from c to p}
x2 {squared distance from p to u-axis}

b
||
u {projection onto u}

=< sx/2 then

a)/

−

−

−

||

a

|

sx, 0, 0] {c denotes the origin/center of the cylinder,

{unit vector in the direction of b-a}

{if p is inside of the cylinder}
return d = 0

else

{p is outside of the cylinder}
(cid:112)
return d =
(y

r)2

−

end if

> sx/2 then

end if
x
if
|
{otherwise}
if y2 < s2

|

x then

{if p is in the Disc region}
(cid:112)
sx)2
(
return d =

x
|

| −

else

{else its in the Circle region}
(cid:112)
x
(y
return d =

r)2 + (

−

sx/2)2

| −

|

end if

end if

Figure 5: Depicting when a point p is on the side (outside) of a cylinder.

A Distance Field of Cylinders

Algorithm 1 describes the algorithm for evaluating the distance ﬁeld of cylinders. Fig. 5 demonstrates
one of the four possible cases; when a point p is on the side and within the height of the cylinder).

10

pabcxyDiscCircleSideoutsideinside