1
2
0
2

n
a
J

0
3

]

G
L
.
s
c
[

1
v
0
3
2
0
0
.
2
0
1
2
:
v
i
X
r
a

ICodeNet - A Hierarchical Neural Network
Approach for Source Code Author
Identiﬁcation(cid:63)

Pranali Bora1, Tulika Awalgaonkar1, Himanshu Palve1, Raviraj Joshi2, and
Purvi Goel2

1 Pune Institute of Computer Technology
2 Indian Institute of Technology Madras
{pranalibora98, tulika.awalgaonkar, himanshupalve1999}@gmail.com
{ravirajoshi,goyalpoorvi}@gmail.com

Abstract. With the open-source revolution, source codes are now more
easily accessible than ever. This has, however, made it easier for mali-
cious users and institutions to copy the code without giving regards to
the license, or credit to the original author. Therefore, source code au-
thor identiﬁcation is a critical task with paramount importance. In this
paper, we propose ICodeNet - a hierarchical neural network that can be
used for source code ﬁle-level tasks. The ICodeNet processes source code
in image format and is employed for the task of per ﬁle author identi-
ﬁcation. The ICodeNet consists of an ImageNet trained VGG encoder
followed by a shallow neural network. The shallow network is based ei-
ther on CNN or LSTM. Diﬀerent variations of models are evaluated on
a source code author classiﬁcation dataset. We have also compared our
image-based hierarchical neural network model with simple image-based
CNN architecture and text-based CNN and LSTM models to highlight
its novelty and eﬃciency.

Keywords: Author Identiﬁcation · Convolutional Neural Network · Long
Short Term Memory · Transfer Learning.

1

Introduction

As the amount of publicly available source code increases, even the volume and
diversity of software programs available to the software community increases. A
large number of sources available online are unknown and often lack authorship.
Therefore it is important to develop mining techniques for understanding code
and related authors. It is one of the main attributes for measuring the contri-
bution and importance of researchers and has important academic, social, and
ﬁnancial implications.

Recently, the code authorship identiﬁcation task has gained increased aware-
ness in the software industry due to its application. The main application in-

(cid:63) Supported by L3Cube Pune.

 
 
 
 
 
 
2

P. Bora et al.

cludes code plagiarism detection[6], automated code generation, cyber-attack in-
vestigation, code integrity investigations[11], and malicious code detection [17].
Code Authorship Identiﬁcation is the task of identifying the programmer of a
particular piece of code. Every programmer has a unique and distinct style of
writing the code known as code stylometry. Style is based on various factors
such as the way of deﬁning variables, indentation and commenting styles, and
the number of lines per function.

The Author identiﬁcation task is commonly done using Natural Language
Processing (NLP) techniques that would successfully derive semantic and syn-
tactic features for classiﬁcation. This process would generally proceed by to-
kenization and vocabulary creation. Optionally it may involve removing stop
words, casings, and reducing words to their stem versions. The NLP techniques
are mostly augmented with manual features as it is not possible to capture im-
portant information using textual analysis. The features like average variable
length, type of variable casing, indentation style, the ratio of comment lines to
code lines, white spaces per line, and formatting of operators are unique to the
authors and hence very helpful in the author identiﬁcation task [27,9,19]. Most
of these features have to be explicitly captured and cannot be automatically cap-
tured using text-based approaches. This work is in the direction of getting rid of
manual feature engineering completely. Our approach aims to capture the struc-
tural features of code that are unique to a particular author while eliminating
preprocessing overheads of tokenization.

In this work, we aim at solving the task of author identiﬁcation using its
visual features. Our work makes use of the SnapCode[22] approach which in-
troduces the idea of extracting structural and syntactic features automatically
from the source code using image-based processing techniques. The SnapCode
approach completely eliminates the tasks of manual feature engineering and to-
kenization while preserving the unique features within the source code. It does
so by creating an image of the code snippet which can be visualized as taking
a snapshot of the snippet. The snapshot contains the entire code snippet along
with its layout thus eliminating loss of any information or feature. This snapshot
is directly processed by the neural network allowing it to automatically learn the
discriminative features. We use a similar approach for representing the source
code snippets as code snapshots.

The entire source code ﬁle can be seen as a sequence of code snippets. So the
problem of processing a source code ﬁle can be formulated as a sequence pro-
cessing task. Each element of this sequence is a code snippet. Since we process
images instead of text, each element is a code snapshot. This formulation allows
us to use a deep neural network to ﬁrst extract representations of these indi-
vidual snapshots. The sequence of representations can be fed to another neural
network for ﬁnal classiﬁcation. We thus propose ICodeNet which employs hier-
archical neural networks for the task of author identiﬁcation. This hierarchical
setup helps in increasing the accuracy of author identiﬁcation to a great ex-
tent. This work is concerned with the ﬁle-level classiﬁcation of source codes as
opposed to the fragment-level classiﬁcation. File-level or document level classi-

ICodeNet - A Hierarchical Approach for Source Code Author Identiﬁcation

3

ﬁcation is desirable when the entire ﬁle is written by a single author. Moreover,
it may sometimes become hard to identify the author from the individual small
code snippets which mostly look alike across diﬀerent authors, therefore looking
at the entire ﬁle may be desirable. With this motivation, we explore ﬁle-level
classiﬁcation utilizing the SnapCode approach. This is the ﬁrst work to employ
an image-based technique to document level author attribution. Although ICo-
deNet is applied to the task of author identiﬁcation for source code ﬁles, it is
generic enough to model any ﬁle-level task for text data. It can also be used to
model classiﬁcation tasks related to very long text sequences.

The main contributions of this paper are as follows:

– We introduce hierarchical neural networks to encode source code ﬁle infor-
mation and show that it captures representations helpful for the task of
author identiﬁcation.

– We show that transfer learning from ImageNet can also work in the context
of source code. We propose a simple ﬁne-tuning approach to adapt a pre-
trained VGG network to source code snippet images.

– We propose data augmentation techniques speciﬁc to our use case which
allows us to train the model even with very few source ﬁles for an author.

2 Background

2.1 Related Work

The classic literature authorship identiﬁcation problem has largely motivated
and inspired research in the ﬁeld of source code authorship identiﬁcation. Even
though natural languages have more ﬂexible grammatical rules than program-
ming languages, there is a large degree of variation in the code writing styles of
various programmers. For example, the coding styles exhibited by experienced
programmers are diﬀerent than those of the novice ones. Diﬀerent approaches
have been applied for automatic author identiﬁcation to date. Early work in this
domain used plain text features of source code archives to identify the authors.
Frantzeskou et.al. in their work[12] used a technique to extract the frequency of
sequences of n-characters from the source code ﬁles to form an author proﬁle
which was compared with the test author ﬁles. Analysis of code depends on the
sequences of text occurring in the source code. One of the widely used methods
to preprocess text data includes tokenization, separation of alphanumeric char-
acters and symbols, removal of unknowns, replacement of tokens by indexes in
the dictionary, and padding. After the completion of preprocessing and feature
extraction various machine learning algorithms like Naive Bayes, Support Vec-
tor Machines, k-nearest neighbor, Random Forest classiﬁer, etc. are applied to
classify the source code depending on their authors [21].

One of the most successfully used ways for representing source code is Ab-
stract Syntax Trees(AST). AST’s have also been used in code clone detection
because of their ability to capture structural features of the code. Lazar et.al.
in their work[18], extract an AST for each program by parsing the source code.

4

P. Bora et al.

Hash codes are then created for each subtree and provided as input to the clone
detection algorithms. However, AST’s drop the formatting features and rely on
hand-constructed features which may be obfuscated.

Previous studies used various types of features to improve the accuracy of
the classiﬁcation and implemented a feature selection technique to remove the
least signiﬁcant features[26,10]. An unsupervised approach for source code attri-
bution was proposed by Bandara et.al.[4]. Features like the number of characters
and words per line, frequency of access speciﬁers and comments, length of each
identiﬁer, number of underscores, etc were manually extracted and a sparse auto-
encoder was used to learn a non-linear representation of these features. These
features were used as inputs for the logistic regression model which was built for
every author.

Further progress into the domain saw many deep learning architectures be-
ing used depending on the various applications. These architectures eliminated
the task of manual feature engineering and extracted the features automatically
from the source code[29]. Convolutional neural network(CNN) is one such deep
learning architecture that is very popular these days. CNNs have shown that
they can achieve excellent results in many natural language processing tasks
such as search query retrieval[23], text summarization[2], semantic parsing[28],
sentence modeling[14] etc. In this work, we propose an architecture that uses the
capabilities of CNNs to extract discriminative features automatically from the
source code archives and attributes them to the diﬀerent authors. In a recent
work[1], the source code samples were represented using two techniques, namely
term frequency-inverse document frequency(TFIDF) and word embeddings be-
fore feeding them as inputs to the CNN model. The TFIDF approach reﬂected
the importance of a word to a document in the collection, and the word embed-
dings approach allowed similar representations for words with similar meanings.
However, our approach is based on images and helps us better represent struc-
tural aspects of the code which otherwise can only be captured manually. In this
work, we use both the CNN and LSTM architectures for the classiﬁcation of
authors.

2.2 Convolutional Neural Networks

A convolutional neural network is a type of deep neural network that is mostly
used to analyze the visual data [16]. A deep ConvNet consists of multiple hidden
layers which include the convolutional, pooling, non-linearity, batch normaliza-
tion, and fully connected layers. It is mainly used in the ﬁeld of image recognition,
anomaly detection, drug discovery, video analysis, etc. A ConvNet has the abil-
ity to learn the features of the input which were otherwise hand-engineered in
the primitive methods. Each layer in the ConvNet learns diﬀerent features dur-
ing training, with increasing complexity as the network gets deeper. As CNNs
can successfully capture spatial and temporal dependencies in an image, they
can be employed to solve challenging problems like plagiarism detection, author
identiﬁcation, malware detection, and code analysis in a more eﬃcient manner.

ICodeNet - A Hierarchical Approach for Source Code Author Identiﬁcation

5

2.3 Long Short Term Memory

A long short term memory is an improvement over the RNNs as they are capable
of storing information for a longer period of time [13]. They are widely used
in the ﬁeld of text recognition, language translation, image captioning because
their predictions are conditioned by the past experience of the network’s inputs.
LSTMs have the ability to successfully learn on data with long-range temporal
dependencies. So they are mainly used for sequence processing applications. The
LSTM architecture consists of memory blocks/cells and mechanisms called gates
to perform manipulation operations on the cells. These gates learn the relevance
of information and decide the information to be kept or forgotten during training.
LSTMs have been long used in many NLP tasks to give remarkable results. In
this work, the sequence of vectoral representation of code snapshots is modeled
using LSTMs.

2.4 Transfer Learning

Transfer learning is the improvement in learning a new task through the transfer
of knowledge from a related task that has already been learned. It is a popular
approach in deep learning where parameters of the model trained on a large
dataset can be reused to solve a related problem. The extracted weights and
features of the state-of-the-art pre-trained models are used for the new task to
improve its performance. Transfer learning strategies can be applied to a wide
multitude of domains like text classiﬁcation, spam ﬁltering, online recommenda-
tions, and medical applications[20].

In this work, we have used transfer learning from the ImageNet dataset by
utilizing the pre-trained VGG16 model. The VGG16 model pre-trained on the
ImageNet dataset[25] is used as a feature extractor and is also ﬁnetuned on the
target dataset. VGG16 is a deep CNN architecture with 16 weight layers. It is
one of the most popular pre-trained models used today.

3 Approach

Tokenization is elementary in all text processing applications. It aims at splitting
the sentence into a stream of tokens followed by using processing methods like
stemming and lemmatization. This type of preprocessing eliminates features like
indentation information, number of characters per line, length of identiﬁers, and
the way of deﬁning a function that is essential to the task at hand. With the
current approaches, the only way to extract these features is by hand-engineering.
Therefore, the ICodeNet carries out automatic extraction of features for the
task of author identiﬁcation using image processing techniques in a hierarchical
setup.

3.1 Dataset

The dataset used was raw source code Java ﬁles taken from the GitHub reposito-
ries of various authors. The original dataset consisted of source code archives for

6

P. Bora et al.

40 diﬀerent authors [27]. The dataset was highly imbalanced with some authors
having very few source code ﬁles. So, the authors having less than 50 ﬁles were
removed from the dataset. Thus, the ﬁnal dataset consisted of the raw source
code Java ﬁles for 20 diﬀerent authors. The data is shared publicly to enable
further research in this area 3.

This dataset is a good representative of real-world code examples, as opposed
to the competitive coding examples, used by most of the other works [24,3,7,1].
The problems with large competitive coding datasets that give near-perfect ac-
curacy are thoroughly discussed in [5]. The author name at the top of the source
code ﬁles was explicitly removed.

3.2 Preprocessing

1. Splitting the Data. The dataset was split into two subsets - train and
test. The test set consisted of 30 ﬁles per author and the remaining ﬁles
were added to the train set. The average number of train ﬁles was 57 with
an average of 100 lines of code per ﬁle. The data regarding the total number
of java ﬁles and the average number of lines of code per ﬁle is as shown in
Fig. 1.

Fig. 1. Dataset Details.

2. Creating the Chunks. As the number of lines of code per ﬁle for the au-
thors is varying, the source code ﬁles were divided into partially overlapping
snippets of 20 lines each with a shift of 5 lines for the successive chunk. The
chunks were created using the grouper function provided by python. Over-
sampling was done on this overlapped data to balance the data of diﬀerent
authors. It was ensured that the train and test set do not contain snippets
from the same ﬁle. Therefore, we propose a simple data augmentation tech-
nique by varying the number of lines in a chunk and the shift size. This
allows us to repeat the same ﬁle having diﬀerent chunk and shift sizes for
each repetition. Oversampling and overlapping techniques were only used for

3 Author Identiﬁcation Dataset

ICodeNet - A Hierarchical Approach for Source Code Author Identiﬁcation

7

training the encoder network. Encoded representations of non-overlapping
chunks were fed to the shallow network.

3. Cleaning the Chunks. The chunks so formed, were cleaned to get useful
data for classiﬁcation. All the chunks with less than 20 lines of code and
fewer(less than 5) characters per line were discarded to get a cleaner version
of the data. The chunks per author in the train set were equalized to 1000 to
ensure no imbalance in the data. The chunks were equalized for ﬁne-tuning
the VGG network explained in the next section.

4. Image Formation. The cleaned, overlapped, and oversampled chunks of
data were converted into images with a resolution of 256x256 pixels using
the Pillow API. These images were fed to the VGG encoder for classiﬁcation.

Fig. 2. Flowchart (left) describes the process of ﬁne-tuning the VGG network on in-
dividual snapshot or fragment classiﬁcation task (auxiliary task) and the ﬂowchart
(right) describes the entire process of classiﬁcation of source code ﬁles into their re-
spective authors (original task).

8

P. Bora et al.

3.3 Classiﬁcation

After pre-processing each source code ﬁle is represented as a sequence of images.
The process of classiﬁcation is carried out in two steps. In the initial step, indi-
vidual images are encoded into a ﬁxed dimensional vector. This can also be seen
as converting raw images into feature vectors. The sequence of feature vectors is
then used for classiﬁcation.

A VGG16 model was used for extracting features from the image snapshots.
For a sequence of snapshots, each individual snapshot was passed through the
VGG16 model, and the resulting feature vectors were passed through another
neural network for classiﬁcation. The VGG network was used because it is one
of the popular models for feature extraction in vision tasks [8]. The pre-trained
VGG network was also separately ﬁnetuned on an auxiliary source code image
classiﬁcation task as it was originally pre-trained on conventional images. The
initial layers of VGG were frozen and the last four layers were ﬁne-tuned. An
auxiliary dataset of code snapshot images and their authors was created by
splitting the parent ﬁle and converting it to images. The VGG network was
then trained on the task of classifying individual snapshots by adding a task-
speciﬁc dense layer. This task can be seen as a simple image classiﬁcation task
where individual snapshots of the source ﬁle are training samples and labels
are the corresponding author names. As opposed to the parent task of author
identiﬁcation for a complete ﬁle this ﬁnetuning subtask identiﬁes the author for
code fragments. This helped the VGG network to better adapt to the target
dataset. The convolutional layers of this VGG network were used as a feature
extractor. Note that instead of training and ﬁnetuning in an end to end network,
the VGG was separately ﬁnetuned on a similar classiﬁcation task. The original
pre-trained VGG is referred to as non-ﬁnetuned VGG and the VGG re-trained
on source code snapshots is referred to as ﬁne-tuned VGG in this work. The
complete ﬂow is described in Fig. 2.

A total of 20000 training samples and 13263 testing samples, created using
the overlapping and oversampling techniques. The model was trained using the
RMSProp optimizer and categorical cross-entropy loss function. After training,
feature vectors were extracted from the 1024 neuron dense layer. The extracted
feature vectors represented the individual chunks. As multiple chunks were cre-
ated per ﬁle, the feature vectors of the chunks belonging to the same ﬁle were
concatenated in order, to give feature vectors for the entire ﬁle. The feature vec-
tors obtained per ﬁle had variable length, as the number of chunks per ﬁle was
variable. A diﬀerent number of chunks per ﬁle were created due to the variable
number of lines of code per ﬁle.

The extracted feature vectors were used in two settings. In the ﬁrst approach,
the VGG was followed by a 1D-CNN based network, we represent it as VGG
+ CNN. The second approach used LSTM instead of a CNN to process the
time series of feature vectors and is represented as VGG + LSTM. One of the
reasons for having this hierarchical structure is the large size of the input ﬁles.
It was diﬃcult to train a VGG only network with a single big image ﬁle for the
entire source code ﬁle. So the snippet based approach is used where the features

ICodeNet - A Hierarchical Approach for Source Code Author Identiﬁcation

9

obtained from individual snippets are then merged using CNN and LSTM based
networks.

1D-CNN[15] is very eﬀective for the detection of features that span over
multiple segments of the dataset. The 1D-CNN model consists of three 1D-
Convolutional layers with 256 ﬁlters of size 3 followed by two dense layers. The
network architecture is shown in Fig. 3. In the second approach, LSTM was used

Fig. 3. VGG+CNN Architecture.

for the classiﬁcation task. As shown in Fig. 4, three LSTM layers with 256 units
are stacked together to form the network. Feature vectors extracted from the
ﬁne-tuned VGG model were fed as inputs to both models. In both approaches, a
softmax layer was used for classiﬁcation. Therefore, the entire ﬁle classiﬁcation is
done using these two novel architectures utilizing the hierarchical setup naturally
presented by the data. This separately ﬁne-tuned VGG encoder followed by a
shallow time-series network is termed the ICodeNet Architecture.

4 Results

Along with VGG + CNN and VGG + LSTM, the results for VGG + Voting
are also evaluated for comparison. VGG + Voting refers to the classiﬁcation of
individual chunks using VGG followed by a voting layer to determine the label
for the entire ﬁle. Another model used for comparison is a simple CNN(s-CNN)
based image encoder instead of the VGG encoder. The s-CNN model consists
of ﬁve alternating convolutional and max-pooling layers with two dense layers

10

P. Bora et al.

Fig. 4. VGG+LSTM Architecture.

stacked on top for feature extraction. Similar to the VGG encoder, this model was
also separately trained on snapshot data and then used as a feature extractor.

Table 1. Classiﬁcation accuracies over diﬀerent architectures

Neural Network architecture Fine-tuned

Image Encoder + Voting

Image Encoder + CNN

VGG

73.90%

82.88%

Image Encoder + LSTM

85.42%

Fine-tuned
VGG

S-CNN

72.00%

79.02%

82.04%

66.98%

69.32%

72.00%

Both the steps i.e. feature extraction and classiﬁcation using hierarchical
networks were carried out on the two models. The ﬁne-tuned VGG based CNN
model gave an accuracy of 73.90% after voting as compared to 72% by the
non-ﬁne tuned model and 66.98% by s-CNN. The drop in accuracy of s-CNN
shows that it was not able to properly identify the discriminative features from
code snippets like the VGG based model. The feature vectors were extracted
from both these models to perform the further tasks. An accuracy of 82.88%
was reported with the ﬁne-tuned VGG+CNN model, whereas the non-ﬁne tuned
VGG+CNN model reported a slightly less accuracy of 79.02%. With, s-CNN+CNN
the accuracy further dropped to 69.32%. Similarly, the same set of tasks was
performed for the hierarchical LSTM model, and results were observed. The
ﬁne-tuned VGG+LSTM architecture gave the best accuracy of 85.42%. The con-

ICodeNet - A Hierarchical Approach for Source Code Author Identiﬁcation

11

fusion matrix for this best conﬁguration is shown in Fig. 5. It indicates that the
accuracy is not biased towards some speciﬁc authors. While the non-ﬁne tuned
VGG+LSTM model resulted in 82.04% accuracy and s-CNN+LSTM gave an
accuracy of 72% with the same dataset.

Fig. 5. Confusion matrix of the best accuracy model.

The results have been combined in Table 1. The results show that ﬁne-tuning
helps in adjusting the parameters of the model very precisely thus, improving
its performance to give the most optimized outcomes. They also indicate that a
simple CNN model cannot be used to represent the discriminative features and
style of writing the code with the same eﬀectiveness as our models.

We have also compared our approach with standard text-based CNN and
LSTM models to further highlight its eﬃciency. The LSTM model architecture
consisting of two layers of bidirectional LSTM with 256 and 128 neurons respec-
tively followed by a global max-pooling layer and dense layer with 128 neurons
gave an accuracy of 74.83%. The text-based CNN model with two 1D-CNN lay-
ers of 256 and 128 ﬁlters respectively with a ﬁlter size of 4 followed by a global
max-pooling layer and dense layer with 128 neurons gave an accuracy of 81.33%.
The ICodeNet approach performs better than text-based approaches. It was
able to preserve the features and code styling as required for author classiﬁca-
tion. These features would rather have been very diﬃcult to extract with the
traditional methods.

Conclusion

In this work, we proposed a methodology to extract style-related features from
source code automatically, which otherwise have been highly diﬃcult to deﬁne
and extract. We have used two hierarchical neural networks for the classiﬁcation

12

P. Bora et al.

of the extracted feature representations according to their authors. The pre-
trained CNN model based on the VGGNet was used to extract discriminative
features from the source code snapshots which were later fed to two diﬀerent
neural networks i.e CNN and LSTM for classiﬁcation. We assume that each ﬁle
is speciﬁc to an author. Handling of multi-author source codes is left to future
scope.

Acknowledgements

This work was done under the L3Cube Pune mentorship program. We would like
to express our gratitude towards our mentors at L3Cube for their continuous
support and encouragement.

References

1. Abuhamad, M., Rhim, J.s., AbuHmed, T., Ullah, S., Kang, S., Nyang, D.: Code
authorship identiﬁcation using convolutional neural networks. Future Generation
Computer Systems 95, 104–115 (2019)

2. Alquliti, W., Binti, N.: Convolutional neural network based for automatic text sum-
marization. International Journal of Advanced Computer Science and Applications
10 (01 2019). https://doi.org/10.14569/IJACSA.2019.0100424

3. Alsulami, B., Dauber, E., Harang, R., Mancoridis, S., Greenstadt, R.: Source code
authorship attribution using long short-term memory based networks. In: Euro-
pean Symposium on Research in Computer Security. pp. 65–82. Springer (2017)
4. Bandara, U., Wijayarathna, G.: Source code author identiﬁcation with unsuper-

vised feature learning. Pattern Recognition Letters 34(3), 330–334 (2013)

5. Bogomolov, E., Kovalenko, V., Bacchelli, A., Bryksin, T.: Authorship attribution
of source code: A language-agnostic approach and applicability in software engi-
neering. arXiv preprint arXiv:2001.11593 (2020)

6. Burrows, S., Tahaghoghi, S.M.M., Zobel, J.: Eﬃcient plagiarism detection for large

code repositories. Softw. Pract. Exp. 37, 151–175 (2007)

7. Caliskan-Islam, A., Harang, R., Liu, A., Narayanan, A., Voss, C., Yamaguchi,
F., Greenstadt, R.: De-anonymizing programmers via code stylometry. In: 24th
{USENIX} Security Symposium ({USENIX} Security 15). pp. 255–270 (2015)
8. Canziani, A., Paszke, A., Culurciello, E.: An analysis of deep neural network models

for practical applications. arXiv preprint arXiv:1605.07678 (2016)

9. Ding, H.: Extraction of Java Program Fingerprints for Software Authorship Iden-

tiﬁcation. Ph.D. thesis, Oklahoma State University (2002)

10. Elenbogen, B.S., Seliya, N.: Detecting outsourced student programming assign-

ments. Journal of Computing Sciences in Colleges 23(3), 50–57 (2008)

11. Forensics, C.H.M.M.: Investigating and analyzing malicious code. Cameron H. Ma-
lin, Eoghan Casey, James M. Aquilina.–1 edition.–Waltham: Syngress (2008)
12. Frantzeskou, G., Stamatatos, E., Gritzalis, S., Chaski, C.E., Howald, B.S.: Iden-
tifying authorship by byte-level n-grams: The source code author proﬁle (scap)
method. International Journal of Digital Evidence 6(1), 1–18 (2007)

13. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural computation

9(8), 1735–1780 (1997)

ICodeNet - A Hierarchical Approach for Source Code Author Identiﬁcation

13

14. Kalchbrenner, N., Grefenstette, E., Blunsom, P.: A convolutional neural network

for modelling sentences. arXiv preprint arXiv:1404.2188 (2014)

15. Kiranyaz, S., Avci, O., Abdeljaber, O., Ince, T., Gabbouj, M., Inman, D.J.:
1d convolutional neural networks and applications: A survey. arXiv preprint
arXiv:1905.03554 (2019)

16. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classiﬁcation with deep con-
volutional neural networks. Advances in neural information processing systems 25,
1097–1105 (2012)

17. Krsul, I., Spaﬀord, E.H.: Authorship analysis: Identifying the author of a program.

Computers & Security 16(3), 233–257 (1997)

18. Lazar, F., Banias, O.: Clone detection algorithm based on the abstract syntax tree
approach. In: 2014 IEEE 9th IEEE International Symposium on Applied Compu-
tational Intelligence and Informatics (SACI). pp. 73–78 (2014)

19. Lim, H.i., Park, H., Choi, S., Han, T.: A method for detecting the theft of java pro-
grams through analysis of the control ﬂow information. Information and Software
Technology 51(9), 1338–1350 (2009)

20. Raghu, M., Zhang, C., Kleinberg, J., Bengio, S.: Transfusion: Understanding trans-
fer learning for medical imaging. In: Advances in neural information processing
systems. pp. 3347–3357 (2019)

21. Reyes, J., Ram´ırez, D., Paciello, J.: Automatic classiﬁcation of source code archives
by programming language: A deep learning approach. In: 2016 International Con-
ference on Computational Science and Computational Intelligence (CSCI). pp.
514–519 (2016)

22. Sarnot, S.A.P., Rinke, S., Raimalwalla, R., Joshi, R., Khengare, R., Goel, P.: Snap-
code - a snapshot based approach to code stylometry. In: 2019 International Con-
ference on Information Technology (ICIT). pp. 337–341 (2019)

23. Shen, Y., He, X., Gao, J., Deng, L., Mesnil, G.: Learning semantic representations
using convolutional neural networks for web search. In: Proceedings of the 23rd
international conference on world wide web. pp. 373–374 (2014)

24. Simko, L., Zettlemoyer, L., Kohno, T.: Recognizing and imitating programmer
style: Adversaries in program authorship attribution. Proceedings on Privacy En-
hancing Technologies 2018(1), 127–144 (2018)

25. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale

image recognition. arXiv preprint arXiv:1409.1556 (2014)

26. Tennyson, M.F.: A replicated comparative study of source code authorship attri-
bution. In: 2013 3rd International Workshop on Replication in Empirical Software
Engineering Research. pp. 76–83 (2013)

27. Yang, X., Xu, G., Li, Q., Guo, Y., Zhang, M.: Authorship attribution of source code
by using back propagation neural network based on particle swarm optimization.
PloS one 12(11), e0187204 (2017)

28. Yih, W.t., He, X., Meek, C.: Semantic parsing for single-relation question answer-
ing. In: Proceedings of the 52nd Annual Meeting of the Association for Computa-
tional Linguistics (Volume 2: Short Papers). pp. 643–648 (2014)

29. Zekany, S., Rings, D., Harada, N., Laurenzano, M.A., Tang, L., Mars, J.: Crystal-
ball: Statically analyzing runtime behavior via deep sequence learning. In: 2016
49th Annual IEEE/ACM International Symposium on Microarchitecture (MI-
CRO). pp. 1–12. IEEE (2016)

