Performance Evaluation of Python Parallel
Programming Models: Charm4Py and mpi4py

Zane Fink∗, Simeng Liu∗, Jaemin Choi∗, Matthias Diener∗, Laxmikant V. Kale∗†
∗Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, Illinois, USA
†Charmworks, Inc., Urbana, Illinois, USA

Email:

@illinois.edu
zanef2, simengl2, jchoi157, mdiener, kale
}
{

1
2
0
2

v
o
N
1
1

]

C
D
.
s
c
[

2
v
2
7
8
4
0
.
1
1
1
2
:
v
i
X
r
a

Abstract—Python is rapidly becoming the lingua franca of
machine learning and scientiﬁc computing. With the broad use
of frameworks such as Numpy, SciPy, and TensorFlow, scientiﬁc
computing and machine learning are seeing a productivity boost
on systems without a requisite loss in performance. While high-
performance libraries often provide adequate performance within
a node, distributed computing is required to scale Python across
nodes and make it genuinely competitive in large-scale high-
performance computing. Many frameworks, such as Charm4Py,
DaCe, Dask, Legate Numpy, mpi4py, and Ray, scale Python
across nodes. However, little is known about these frameworks’
relative strengths and weaknesses,
leaving practitioners and
scientists without enough information about which frameworks
are suitable for their requirements. In this paper, we seek to
narrow this knowledge gap by studying the relative performance
of two such frameworks: Charm4Py and mpi4py.

We perform a comparative performance analysis of Charm4Py
and mpi4py using CPU and GPU-based microbenchmarks other
representative mini-apps for scientiﬁc computing.

Index Terms—performance, analysis, benchmark, HPC, GPU,

Python, parallel programming, MPI, Charm++

I. INTRODUCTION

Driven by the end of Moore’s law, current and future
large-scale systems are largely heterogeneous, with different
combinations of CPUs, GPUs, and other accelerators such
as FPGAs. This increasing heterogeneity is associated with
a concordant increase in programming complexity. Recently,
the community has focused on performance portability, with
frameworks such as Kokkos [1] and RAJA [2] providing
promises of “write once, run anywhere”.

While these systems provide performance portability, we
believe they leave much to be desired concerning produc-
tivity. Python, the king of productive programming, has for
many years been out of the realm of performance-oriented
programming: the interpreted language is much too slow to run
serious scientiﬁc computing workloads on its own. However,
a proliferation of performance-oriented Python libraries has
recently brought lots of attention in the HPC community. Most
notably, the Numpy [3] project brings array programming
to Python near the speed of raw C/C++ code for some
applications.

Numpy demonstrated that Python and high-performance are
not orthogonal. Following its success, many other projects ac-
celerate Python, either through bindings to existing C libraries
such as CuPy [4], PyOpenCL [5], and PyKokkos [6] or by
compiling a subset of Python to native code. Examples of the

these

frameworks

are well-suited

latter approach are Numba [7], Pythran [8], or Data-Centric
Python [9].
While

high-
performance within a node, distributed-memory computing
is necessary to scale Python beyond one node, making it
suitable for high-performance computing. Over the years,
different frameworks such as Charm4Py [10], Dask [11],
Legate NumPy [12], MPI for Python (mpi4py) [13], and
Ray [14] intend in one way or another to ﬁll this performance
gap.

for

Despite

applications
little

high-
for
different
the many
is known about
performance distributed Python,
these frameworks’ relative strengths and weaknesses, leaving
scientists and practitioners to guess which is best suited for
their purposes. In this paper, we seek to narrow this gap by
performing a study comparing the performance of two such
frameworks: Charm4Py and mpi4py. We choose Charm4Py
and mpi4py because each provides Python bindings to
widely-used parallel programming models, enabling us to
evaluate the performance overhead of Python.

In this paper, we perform a comprehensive performance
analysis between Charm4Py and mpi4py. We compare them
along different dimensions, comparing microbenchmark per-
formance and performance in representative proxy applica-
tions including Stencil2D and a Particle-in-Cell (PIC) code
with load imbalance. We perform both CPU and GPU-based
benchmarks, discovering the strengths and weaknesses of each
framework.

The rest of this paper is organized as follows:
1) Section II introduces Charm4Py and mpi4py.
2) Section III describes in detail our chosen benchmarks.
3) Section IV contains our performance evaluation and

benchmarking results.

4) Section V performs a survey of related work.
5) Section VI concludes our paper.

II. BACKGROUND

A. Charm4Py

Charm4Py [15] is a parallel programming model built on top
of Charm++. Charm4Py features the message-driven schedul-
ing of Charm++ [16], and has support for many Charm++
features such as dynamic load balancing, GPU-direct commu-
nication [17], overdecomposition, and sections. Following the

 
 
 
 
 
 
programming model of Charm++, Charm4Py programs consist
of one or more chares on each PE in the computation. These
chares communicate through entry methods in a message-
driven fashion: chares execute when they have received a
message via an entry method invocation.

B. mpi4py

MPI for Python (mpi4py) [13] is a popular package provid-
ing python bindings for MPI that has been in development
since 2005. MPI for Python uses Cython [18] as a high-
performance middleware between Python and C/C++.

C. Messaging in Python

Both Charm4Py and MPI for Python can send arbitrary
Python objects over the network using Python’s Pickle frame-
work. Additionally, both have optimizations for objects that
implement the buffer protocol, such as Numpy [3] arrays. This
optimization avoids pickling and allows the underlying buffer
to be sent directly over the network.
In addition to optimizations

for host-resident data,
Charm4Py and mpi4py are capable of inter-process commu-
nication consisting of GPU-resident data without ﬁrst staging
data on the host. Charm4Py uses the underlying UCX capa-
balities of Charm++ [17], and mpi4py utilizes CUDA-aware
MPI implementations.

In the following section, we describe the microbenchmarks

and proxy applications presented in this paper.

III. BENCHMARK SUITE

A. Communication Microbenchmarks

the

We

assess

communication performance of both
Charm4Py and mpi4py through point-to-point bandwidth and
latency CPU and GPU benchmarks using the OSU mi-
crobenchmark suite [19]. These benchmarks have a twofold
purpose: to determine the relative communication performance
of Charm4Py and mpi4py, and to evaluate the Python overhead
of each. High overhead may result in degraded application
performance, potentially rendering a framework unsuitable
for large-scale execution. Furthermore, we compare the mi-
crobenchmark performance of each framework to their C/C++
counterparts.

On the CPU and GPU, we measure inter-socket and inter-
node latency and bandwidth. We refer the reader to [19] for a
complete description of the benchmarks.

B. Proxy Application: Jacobi2D

Because stencil communication patterns are common in
scientiﬁc computing workloads, we demonstrate the perfor-
mance of Charm4Py and mpi4py using the Jacobi iteration
in two dimensions. The problem domain is decomposed into
rectangular blocks of equal size such that
the surface-to-
volume ratio is minimized. We assign portions of the domain
to PEs as follows.

For P PEs and an n

m problem domain, we arrange
the PEs into a p1
p2 = P .
Each PE is assigned equal portions of the domain of size

p2 rectangular grid, where p1

×

×

·

×

(n/p1)
(m/p2). Without loss of generality, we assume that
n mod p1 = 0 and m mod p2 = 0. Every iteration, each PE
performs the stencil computation and exchanges halo regions
with its neighbors. We consider non-periodic boundaries, but
do not expect that periodic boundaries conditions will affect
our conclusions.

We use Numpy arrays to represent the problem domain, and

Numba is used to JIT-compile computational kernels.

C. Proxy Application: Particle-In-Cell

To assess the performance of each framework in appli-
the particle-
cations with load imbalance, we implement
in-cell (PIC) parallel research kernel
introduced by Geor-
gana et. al. [20]. A brief description of the kernel follows.
We refer the reader to [20] for a complete description.

×

The simulation domain is modeled as an L

L mesh
composed of h
h cells with periodic boundaries in both
x and y dimensions. At each timestep, a particle’s position
and velocity are calculated. Following [20], we initialize the
grid with positive charges at columns with mesh points at odd
indices and negative charges at columns with mesh points at
even indices. In this paper, we consider the geometric particle
distribution introduced by [20].

×

Similar to Section III-B, we use Numpy arrays to represent
particles, and computational kernels are JIT-compiled using
Numba. In contrast to the Stencil2D kernel, the PIC kernel has
application-induced load imbalance. Consequently, we employ
overdecomposition in the Charm4Py implementation, though
this choice does not affect the implementation: the degree of
overdecomposition is a tunable runtime parameter subject to
a user’s preferences.

IV. PERFORMANCE EVALUATION

A. Experimental Setup

1) Hardware Platforms: We perform our evaluation using
two different platforms: STAMPEDE2 and SUMMIT. A descrip-
tion of each system can be found in Appendix A.

2) Software Conﬁguration: In the interest of space, we refer
the reader to Appendix A for a description of the software
conﬁguration used in the experiments that follow.

3) Evaluation Methodology: Unless otherwise stated, we
perform each experiment for ten trials. The independent vari-
able groups experiments, i.e., all ten trials for an experiment
with 768 PEs are in one group. Within a group of 10 trials,
the same nodes are used. Between groups, we do not control
whether jobs are submitted to the same sets of nodes. Because
different calls to mpirun may not be independent, we follow
the recommendation of [21] and randomize the order of calls
to mpirun1 within a group of trials.

Timing begins and ends with a global barrier. Unless
otherwise stated, within each trial, ten warmup iterations are
performed before timing begins. We report the mean of times
recorded from the ten trials and calculate conﬁdence intervals
using bootstrapping. We calculate p-values using the non-
parametric Mann-Whitney U Test [22].

1Or whichever launcher is appropriate for a given platform

(a)

(c)

(b)

(d)

(a)

(c)

(b)

(d)

Fig. 1: Intra-node (inter-socket) and inter-node bandwidth
(a), (c) and latency (b), (d) for Charm++, Charm4Py, MPI,
and mpi4py. Message sizes range from 16 bytes to 4 MiB.
In (c), the horizontal line marks the reported bandwidth of
STAMPEDE2’s interconnection network, 12.5 GB/s.

B. Communication Microbenchmarks

In the microbenchmark experiments that follow, within a
trial, 1000 iterations are performed for messages less than
8192 bytes; for messages 8192 bytes or larger, we perform
100 trials. In the latency experiments, we performed 60
warmup iterations; we observed that ten warmup iterations
were sufﬁcient for the bandwidth experiments. On SUMMIT,
we found that setting the rendezvous threshold UCX uses
to 131072 bytes yields the best performance for intra-node
messages; for inter-node messages, we ﬁnd that setting the
threshold to 8192 bytes provides the best performance.

In Figure 1, the results for CPU-only inter-socket and inter-
node bandwidth (a), (c), and latency (b), (d) respectively, are
shown. Because the purpose of this benchmark is to evaluate
the overhead Charm4Py and mpi4py induce on the reference
frameworks, we disable the use of RDMA in Charm++. This is
because Charm4Py does not currently support RDMA for host-
resident messages. Instead, message marshaling is used, where
RDMA would generally be recommended in this benchmark.
From the intra-node data, we make the following obser-
vations. First,
the Python layer of mpi4py is lightweight,
resulting in little overhead on top of MPI. MPI for Python
has 5% lower2 to 86% higher latency than MPI (Figure 1(b)).
On the other hand, the Python layer of Charm4Py is heavy:
we observe that Charm4Py has 37
311% higher latency than
Charm++. This is because Charm4Py performs tasks such as
chare management in Python, requiring multiple Python func-
tion calls and data accesses for each message, whereas mpi4py

−

2We found that when mpi4py outperformed MPI the result was insigniﬁcant

(p > 0.01).

Fig. 2: Intra-node bandwidth (GB/s) and latency (µs) (a),
(b) and inter-node bandwidth (MB/s) and latency (µs) (c),
(d) for GPU-resident data on SUMMIT. In (a),
the black
horizontal line is at 50 GB/s: the reported bandwidth of the
NVLink connection between GPUs within a node. In (c) the
horizontal black line is at 12.5GB/s, the stated bandwidth of
the interconnection network of SUMMIT.

has a lightweight Python layer. We note that this comparison
overestimates mpi4py overhead relative to Charm4Py: it is
harder to impose less overhead over a faster baseline. Second,
the MPI-based frameworks exhibit much greater bandwidth
than the Charm-based frameworks (Figure 1(a)). Recall from
Appendix A that Charm++ is built upon MPI on STAMPEDE2.
Nevertheless, Charm++ achieves 25% of the bandwidth peak
of MPI. This is because of the host-staging that the Charm
frameworks perform, requiring additional copies.

Inter-node bandwidth and latency are shown in Figure 1(c),
(d), where we see a similar pattern to that observed within
a node: the additional copies performed preclude Charm4Py
from achieving peak bandwidth; both MPI and mpi4py saturate
the node injection bandwidth.

In Figure 2, the intra-node bandwidth and latency are shown
in (a) and (b), and the inter-node bandwidth and latency
are shown in (c), (d). Recall from Section II-C that all
frameworks use GPU-direct for messages containing GPU-
resident data. Contrasting CPU messages, mpi4py imposes
substantial overhead over the raw MPI calls. We observe that
mpi4py latency is between 24% and 851% higher than MPI;
for Charm4Py we see latency between 38% and 570% higher
than Charm++. This is because both Charm4Py and mpi4py
must extract metadata for the underlying device buffer from
the host abstraction for CUDA data. This metadata lookup
involves accessing a Python dictionary and several attribute
lookups.

In the bandwidth ﬁgures, we see that MPI has substantially
higher bandwidth than all other frameworks. However, we ﬁnd

46810121416182022Messagesize(bytes×2x)05101520Bandwidth(GB/s)Charm4PyCharm++mpi4pyMPI46810121416182022Messagesize(bytes×2x)024166425610244096Latency(µs)Charm4PyCharm++mpi4pyMPI46810121416182022Messagesize(bytes×2x)05101520Bandwidth(GB/s)Charm4PyCharm++mpi4pyMPI46810121416182022Messagesize(bytes×2x)024166425610244096Latency(µs)Charm4PyCharm++mpi4pyMPI46810121416182022Messagesize(bytes×2x)0.00010.0010.010.11.010.0100.0Bandwidth(GB/s)Charm4PyCharm++mpi4pyMPI46810121416182022Messagesize(bytes×2x)248163264128256512Latency(µs)Charm4PyCharm++mpi4pyMPI46810121416182022Messagesize(bytes×2x)0.00010.0010.010.11.010.0100.0Bandwidth(GB/s)Charm4PyCharm++mpi4pyMPI46810121416182022Messagesize(bytes×2x)248163264128256512Latency(µs)Charm4PyCharm++mpi4pyMPI(a)

(b)

Fig. 3: Time per timestep (in ms) vs. the number of PEs used
for Stencil2D onSTAMPEDE2. Results are for strong-scaling.
In (a), we show results for PE counts between 6 and 192 (1-4
nodes); in (b), results are shown for PE counts between 384
and 6144 (8-128 nodes). Error bars designate the 99% CI of
the mean for computation time and communication time in
blue and red, respectively.

that for both intra-node messages Figure 2(a) and inter-node
messages Figure 2(b), all frameworks eventually saturate the
bandwidth of the link being used.

1) Stencil2D: In Figure 3, we see the strong-scaling results
for the CPU implementation of the Stencil2D proxy applica-
tion. The problem domain is 24576
24576. Recall that each
node of STAMPEDE2 has 48 total cores, 24 per socket. We
ﬁnd that below 768 PEs, the differences between Charm4Py
and mpi4py are insigniﬁcant (p > 0.01). However, beyond
768 PEs, the Charm4Py implementation suffers. Speciﬁcally,
we can see that the communication performance observed in
Section IV-B results in degraded communication performance
for Charm4Py, limiting scalability.

×

In Figure 4, weak scaling results for the Stencil2D appli-
cation are shown. To weak scale the problem, we begin with
a domain of 6144
6144. We ﬁrst double the domain in the
x-dimension and then the y-dimension. We observe that both
implementations weak scale well from 48-3072 cores. We are
investigating the increase in time between 24 and 48 PEs,
though we suspect resource contention as the simulation grows
from utilizing one to two sockets.

×

Figure 5 shows the strong-scaling performance of the GPU
implementation of Stencil2D. In this experiment, the domain
is 73728
73728, approximately the largest domain size that
ﬁts in the available 96GiB of device memory on one node.
Consistent with the microbenchmark results in Section IV, we
ﬁnd that Charm4Py and mpi4py perform similarly. Indeed, no
signiﬁcant difference in their performance is observed.

×

In Figure 6, we observe the weak scaling performance of
Charm4Py and mpi4py. The beginning problem domain is
73728
73728. We scale ﬁrst in the x-dimension and then in
the y-dimension. This ﬁgure shows that both implementations
weak-scale well (parallel efﬁciency E
1) and exhibit similar
communication performance characteristics.

×

≈

2) Particle-In-Cell: To evaluate

the performance of
Charm4Py and mpi4py in the PIC kernel, we use a grid of
2998 with 600, 000 particles. The simulation is
size 2998

×

Fig. 4: Time per timestep (ms) vs. the number of PEs used in
the Stencil2D proxy application weak-scaled on STAMPEDE2.

(a)

(b)

Fig. 5: Time per timestep (in ms) vs. the number of nodes used
in the Stencil2D proxy application on strong-scaled SUMMIT.
In (a), we show results for small node counts (6-48 GPUs);
(b) contains results at larger node counts (72-768 GPUs). Each
node is equipped with 6 GPUs. The 99% CI of the mean for
computation and communication are outlined in the error bows
in blue and red, respectively.

run for 1000 iterations. Following Georganas et.al. [20], we
use an exponential distribution of particles with r = 0.999,
and k = 0. We ﬁnd that Charm4Py performs best with an
overdecomposition factor (ODF) of 8 chares per PE, and that
performance is best when load balancing is performed every
80 iterations.

The results of the simulation are shown in Figure 7. We ﬁnd
that without overdecomposition or load balancing, Charm4Py
is out-performed by mpi4py up to 96 PEs. The simulation
features a high communication volume with few processors,
as many particles migrate from one PE to another. However,
we see that overdecomposition makes a substantial impact on
Charm4Py performance. This is because overdecomposition
results in a different assignment of chares to processors,
yielding a more balanced computation. Explicit load balancing
improves Charm4Py performance even further: a speedup up
to 2.6
is observed over mpi4py. At large PE counts, the
cost of migrating chares to balance load is high, as chares
have to be serialized and deserialized using expensive pickling
operations. We are investigating methods to reduce the cost of
chare migration in Charm4Py.

×

612244896192NumberofPEs050100150200250300350TimeperTimestep(ms)Charm4Py-Comm.mpi4py-Comm.Charm4Py-Comp.mpi4py-Comp.384768153630726144NumberofPEs024681012TimeperTimestep(ms)Charm4Py-Comm.mpi4py-Comm.Charm4Py-Comp.mpi4py-Comp.61224489619238476815363072NumberofPEs00.250.50.751.01.251.5TimeperTimestep(ms)Charm4Py-Comm.mpi4py-Comm.Charm4Py-Comp.mpi4py-Comp.1248NumberofNodes0255075100125TimeperTimestep(ms)Charm4Py-Comm.mpi4py-Comm.Charm4Py-Comp.mpi4py-Comp.163264128NumberofNodes05101520TimeperTimestep(ms)Charm4Py-Comm.mpi4py-Comm.Charm4Py-Comp.mpi4py-Comp.based applications with uniform load balance between PEs
that both Charm4Py and mpi4py perform comparably when
the granularity of tasks is large; at smaller task granularities,
the poor communication performance of Charm4Py dominates,
and strong-scaling performance is limited. Work to add the
RDMA support of Charm++ to Charm4Py is required to
bring the communication performance of Charm4Py to the
level observed in mpi4py. Following this implementation,
we anticipate comparable CPU-based communication perfor-
mance between Charm4Py and mpi4py, as we observed in our
GPU performance results. In applications with load imbalance
between processing elements, we ﬁnd that Charm4Py makes
effective use of the load-balancing capabilities of Charm++,
yielding speedup up to 2.6

over mpi4py.

Future work includes considering a broader set of frame-
works and benchmarks to model workloads found in big data
analytics and machine learning.

×

ACKNOWLEDGEMENT

This material is based in part upon work supported by the
Department of Energy, National Nuclear Security Administra-
tion, under Award Number DE-NA0003963.

This work used the Extreme Science and Engineering Dis-
covery Environment (XSEDE), which is supported by National
Science Foundation grant number ACI-1548562.

The authors acknowledge the Texas Advanced Computing
Center (TACC) at The University of Texas at Austin for
providing HPC resources that have contributed to the research
results reported within this paper.

This research used resources of the Oak Ridge Leadership
Computing Facility, which is a DOE Ofﬁce of Science User
Facility supported under Contract DE-AC05-00OR22725.

REFERENCES

[1] H. C. Edwards and C. R. Trott, “Kokkos: Enabling
performance portability across manycore architectures,”
in 2013 Extreme Scaling Workshop (xsw 2013), 2013,
pp. 18–24. DOI: 10.1109/XSW.2013.7.

[2] D. A. Beckingsale, J. Burmark, R. Hornung, H. Jones,
W. Killian, A. J. Kunen, O. Pearce, P. Robinson, B. S.
Ryujin, and T. R. Scogland, “Raja: Portable perfor-
mance for large-scale scientiﬁc applications,” in 2019
IEEE/ACM International Workshop on Performance,
Portability and Productivity in HPC (P3HPC), 2019,
pp. 71–81.

[3] C. R. Harris, K. J. Millman, S. J. van der Walt, R.
Gommers, P. Virtanen, D. Cournapeau, E. Wieser, J.
Taylor, S. Berg, N. J. Smith, R. Kern, M. Picus, S.
Hoyer, M. H. van Kerkwijk, M. Brett, A. Haldane, J. F.
del R´ıo, M. Wiebe, P. Peterson, P. G´erard-Marchant,
K. Sheppard, T. Reddy, W. Weckesser, H. Abbasi, C.
Gohlke, and T. E. Oliphant, “Array programming with
NumPy,” Nature, vol. 585, no. 7825, pp. 357–362, 7825
Sep. 2020.

Fig. 6: Time per timestep (in ms) vs. the number of nodes
used in the simulation for weak scaling performance data for
Stencil2D on SUMMIT.

Fig. 7: Time per timestep (in milliseconds) vs. the number of
PEs used for Charm4Py and mpi4py for the particle-in-cell
research kernel executed onSTAMPEDE2. Charm4Py is shown
with overdecomposition only (O) and overdecomposition and
load balancing (O, LB). Shaded areas outline the 99% CI of
the mean.

V. RELATED WORK

A substantial body of work comparing parallel program-
ming models exists. In [23] the LULESH mini-app is used to
investigate the performance and productivity aspects of parallel
programming models. They consider only the LULESH mini-
app, and Python is not considered. Slaughter et al.
[24]
present Task Bench, a parameterized benchmarking platform
for programming models. In their evaluation, they only have
coverage of Dask in the Python programming model space.
The parallel research kernels [25] are a project that covers
many different kernels in many different programming models.
However, these kernels lack Python coverage. NPBench [26]
is a benchmarking suite for Numpy implementations, but they
do not consider distributed computing.

VI. CONCLUSION

With increasing heterogeneity in current and future large-
scale systems, Python’s productivity and performance porta-
bility make it attractive to scientists and practitioners. In
this paper, we have conducted a comprehensive performance
analysis of Charm4Py and mpi4py using a set of microbench-
marks and representative mini-apps. We found that in CPU-

1248163264128NumberofNodes0255075100125TimeperTimestep(ms)Charm4Py-Comm.mpi4py-Comm.Charm4Py-Comp.mpi4py-Comp.244896192384786NumberofPEs050100150200250300350TimeperTimestep(ms)mpi4pyCharm4PyCharm4Py(O)Charm4Py(O,LB)[4] R. Okuta, Y. Unno, D. Nishino, S. Hido, and C. Loomis,
“Cupy: A numpy-compatible library for nvidia gpu
calculations,” in Proceedings of Workshop on Machine
Learning Systems (LearningSys), 2017. [Online]. Avail-
able: http : / / learningsys . org / nips17 / assets / papers /
paper 16.pdf.

[5] A. Kl¨ockner, N. Pinto, Y. Lee, B. Catanzaro, P. Ivanov,
and A. Fasih, “Pycuda and pyopencl: A scripting-based
approach to gpu run-time code generation,” Parallel
Comput., vol. 38, no. 3, pp. 157–174, Mar. 2012.
[6] N. A. Awar, S. Zhu, G. Biros, and M. Gligoric, “A
Performance Portability Framework for Python,” p. 12,
2021.

[7] S. K. Lam, A. Pitrou, and S. Seibert, “Numba: A
llvm-based python jit compiler,” in Proceedings of the
Second Workshop on the LLVM Compiler Infrastructure
in HPC, ser. LLVM ’15, Austin, Texas, 2015. DOI: 10.
1145/2833157.2833162.

[8] S. Guelton, P. Brunet, M. Amini, A. Merlini, X. Cor-
billon, and A. Raynaud, “Pythran: Enabling static opti-
mization of scientiﬁc python programs,” Computational
Science & Discovery, vol. 8, no. 1, p. 014 001, Mar.
2015.

[9] A. N. Ziogas, T. Schneider, T. Ben-Nun, A. Calotoiu,
T. De Matteis, J. d. F. Licht, L. Lavarini, and T. Hoeﬂer.
(Jul. 1, 2021). “Productivity, Portability, Performance:
Data-Centric Python.”
J. J. Galvez, K. Senthil, and L. Kale, “CharmPy: A
Python Parallel Programming Model,” in 2018 IEEE
International Conference on Cluster Computing (CLUS-
TER), Sep. 2018.

[10]

[11] M. Rocklin, “Dask: Parallel Computation with Blocked
algorithms and Task Scheduling,” presented at
the
Python in Science Conference, Austin, Texas, 2015,
pp. 126–132.

[12] M. Bauer and M. Garland, “Legate NumPy: Accelerated
and distributed array computing,” in Proceedings of
the International Conference for High Performance
Computing, Networking, Storage and Analysis, Denver
Colorado: ACM, Nov. 17, 2019, pp. 1–23.

[13] L. Dalcin and Y.-L. L. Fang, “Mpi4py: Status update
after 12 years of development,” Computing in Science
Engineering, vol. 23, no. 4, pp. 47–54, 2021. DOI: 10.
1109/MCSE.2021.3083216.

[14] P. Moritz, R. Nishihara, S. Wang, A. Tumanov, R. Liaw,
E. Liang, M. Elibol, Z. Yang, W. Paul, M. I. Jordan,
and I. Stoica. (Sep. 29, 2018). “Ray: A Distributed
Framework for Emerging AI Applications.”
J. J. Galvez, K. Senthil, and L. Kale, “Charmpy: A
python parallel programming model,” in 2018 IEEE
International Conference on Cluster Computing (CLUS-
TER), 2018, pp. 423–433. DOI: 10 . 1109 / CLUSTER .
2018.00059.

[15]

[16] B. Acun, A. Gupta, N. Jain, A. Langer, H. Menon,
E. Mikida, X. Ni, M. Robson, Y. Sun, E. Totoni,
L. Wesolowski, and L. Kale, “Parallel programming

[17]

with migratable objects: Charm++ in practice,” in SC
’14: Proceedings of the International Conference for
High Performance Computing, Networking, Storage and
Analysis, 2014, pp. 647–658.
J. Choi, Z. Fink, S. White, N. Bhat, D. F. Richards,
and L. V. Kale, “Gpu-aware communication with ucx
in parallel programming models: Charm++, mpi, and
python,” in 2021 IEEE International Parallel and Dis-
tributed Processing Symposium Workshops (IPDPSW),
Los Alamitos, CA, USA, Jun. 2021, pp. 479–488.
[18] S. Behnel, R. Bradshaw, C. Citro, L. Dalcin, D. S.
Seljebotn, and K. Smith, “Cython: The best of both
worlds,” Computing in Science Engineering, vol. 13,
no. 2, pp. 31–39, 2011.

[19] D. Bureddy, H. Wang, A. Venkatesh, S. Potluri, and
D. K. Panda, “OMB-GPU: A Micro-Benchmark Suite
for Evaluating MPI Libraries on GPU Clusters,” in
Recent Advances in the Message Passing Interface,
ser. Lecture Notes in Computer Science, vol. 7490,
2012, pp. 110–120.

[20] E. Georganas, R. F. Van Der Wijngaart, and T. G.
Mattson, “Design and Implementation of a Parallel Re-
search Kernel for Assessing Dynamic Load-Balancing
Capabilities,” in 2016 IEEE International Parallel and
Distributed Processing Symposium (IPDPS), May 2016,
pp. 73–82.

[21] S. Hunold and A. Carpen-Amarie, “Reproducible mpi
benchmarking is still not as easy as you think,”
IEEE Transactions on Parallel and Distributed Systems,
vol. 27, no. 12, pp. 3617–3630, 2016.

[23]

[22] H. B. Mann and D. R. Whitney, “On a Test of Whether
one of Two Random Variables is Stochastically Larger
than the Other,” The Annals of Mathematical Statistics,
vol. 18, no. 1, pp. 50–60, 1947.
I. Karlin, A. Bhatele, J. Keasler, B. L. Chamberlain,
J. Cohen, Z. Devito, R. Haque, D. Laney, E. Luke,
F. Wang, D. Richards, M. Schulz, and C. H. Still, “Ex-
ploring traditional and emerging parallel programming
models using a proxy application,” in IPDPS 2013,
2013, pp. 919–932.

[24] E. Slaughter, W. Wu, Y. Fu, L. Brandenburg, N. Garcia,
W. Kautz, E. Marx, K. S. Morris, Q. Cao, G. Bosilca,
S. Mirchandaney, W. Lee, S. Treichler, P. McCormick,
and A. Aiken, “Task bench: A parameterized benchmark
for evaluating parallel runtime performance,” in SC20.
IEEE Press, 2020.

[25] R. F. Van der Wijngaart and T. G. Mattson, “The parallel
research kernels,” in 2014 IEEE High Performance
Extreme Computing Conference (HPEC), 2014, pp. 1–6.
[26] A. N. Ziogas, T. Ben-Nun, T. Schneider, and T. Hoeﬂer,
“NPBench: A benchmarking suite for high-performance
NumPy,” in Proceedings of
the ACM International
Conference on Supercomputing, ACM, Jun. 3, 2021,
pp. 63–74.

APPENDIX A
ARTIFACT DESCRIPTION APPENDIX: PERFORMANCE
EVALUATION OF PYTHON PARALLELPROGRAMMING
MODELS: CHARM4PY AND MPI4PY

A. Abstract

This section describes the hardware and software environ-
ment in which the results reported in this paper were obtained.
Links to software used and build instructions are also given.

B. Description

1) Check-list (artifact meta information): Fill in whatever
is applicable with some informal keywords and remove the rest

• Algorithm: Jacobi iteration, Particle-in-cell
• Program: Python, Charm4Py, mpi4py, Charm++, MPI
• Compilation: GCC v8.3.0; Numba v0.53.1;
• Output: Output is either a CSV ﬁle containing relevant output
data (e.g., runtime, iteration number, process number), or data
are printed to STDOUT and captured via pipes. Scripts to parse
these data are found in the GitHub repository.

• Experiment workﬂow: Clone and build software on the
relevant platforms, run the appropriate scripts to submit jobs
to the platform’s management system.

• Experiment customization: Number of processes, message
size, domain size, location of data, number of particles, number
of warmup iterations, number of iterations, particle distribution
strategy.

• Publicly available?: Yes.

2) How software can be obtained (if available): All soft-
ware can be obtained from GitHub. All scripts and bench-
mark programs used to produce this paper can be found
in the repository located at: https://github.com/UIUC-PPL/
charm4py-mpi4py-compare in the branch espm2_2021. Ad-
ditional software packages can also be found on Github:

1) Charm4Py https://github.com/uiuc-ppl/charm4py
2) Charm++ https://github.com/uiuc-ppl/charm
3) mpi4py https://github.com/mpi4py/mpi4py
4) OpenMPI https://github.com/open-mpi/ompi

3) Hardware dependencies: We describe the hardware plat-

forms used in this paper.

STAMPEDE2 is a CPU-based machine at Texas Advanced
Computing Center. In our evaluation, we use the Skylake
nodes. Each node is equipped with 2
Intel Xeon Platinum
8160 (Skylake) @ 2.1GHz, each with 24 cores and has a
memory capacity of 192GB of DDR4 RAM. Connecting the
nodes is a 100Gb/s Intel Omni-Path network organized in a
fat-tree topology.

×

SUMMIT, located at Oak Ridge Leadership Computing Fa-
cility, is an IBM Power9 System. Each node is equipped with
2
IBM POWER9 Processors, each with 44 cores. Nodes have
×
512GB of DDR4 memory. Additionally, each node has 6
×
NVIDIA Tesla V100 GPUs connected with NVLink capable
of 50GB/s bandwidth between GPUs. Nodes are connected
with a 12.5GB/s dual-rail EDR Inﬁniband network in a non-
blocking Fat Tree topology.

4) Software dependencies: In what follows, we describe the
software used on both platforms, STAMPEDE2 and SUMMIT.
STAMPEDE2 We compile all software with -O3 using
gcc 8.3.0. We build Charm++ on commit ID 77209f5aa
with the MPI backend using the default MPI installation
on STAMPEDE2, as we ﬁnd it offers the best performance.
Charm4Py commit ID 35ee630 is built against Charm++.
mpi4py is built on commit ID 761ac19 against the default
installation of MPI; in all experiments for MPI on STAMPEDE2
we use the default installation (Intel MPI v18.0.2).

SUMMIT All software is compiled with -O3 using gcc
v8.3.1. To enable GPU-aware communication in Charm++
and Charm4Py we build Charm++ with the UCX back-
end using UCX v1.11.1. UCX is itself built with gdrcopy
v2.0 and libevent v2.1.12. Charm++ is built on commit ID
fa767dd9b; Charm4Py on commit ID ba3e95c

We build OpenMPI v4.1.1 with the same UCX libraries as
Charm++. mpi4py commit ID 23d3635 is built against this
installation of OpenMPI. Both Charm++ and MPI use PMIx
v3.1.1 and CUDA v10.2.89.

On both platforms, we use Python v3.8 with Numba
v0.53.1. We provide the Anaconda environment ﬁle used on
each platform in the GitHub repository for this paper.

5) Datasets: The data presented in this paper have been
made available at DOI: 10.5281/zenodo.5629346. To
perform the analysis that produced the ﬁgures in this paper, the
data should be extracted into a directory named data within
the charm4py-mpi4py-compare repository. The analyses
within the analysis directory can then be performed.

C. Installation

Due to space constraints, we refer the reader to the ﬁle
README.md within the GitHub repository for the paper
(Section A-B2), where we provide complete instructions for
software compilation and conﬁguration on STAMPEDE2 and
SUMMIT.

D. Experiment workﬂow

For each benchmark ran (microbenchmarks for CPU and
GPU-based messages, weak and strong scaling for CPU and
GPU-based implementations of the Jacobi iteration, and the
particle in cell code), scripts that submit the experiments to
the scheduler are found within the scripts subdirectory.

E. Evaluation and expected result

Experiments may be run following software installation on
the desired platforms. Scripts used to perform experiments
typically require the user to change paths within the scripts
to their local installation.

F. Notes

We welcome any questions and are happy to help the
interested reader perform the experiments presented in this
paper, or any follow-up experiments. We ask that interested
parties contact Zane Fink at zanef2@illinois.edu.

