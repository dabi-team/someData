Practical phase-modulation stabilization in quantum key
distribution via machine learning

Jing-Yang Liu,1, 2, 3 Hua-Jian Ding,1, 2, 3 Chun-Mei
Zhang,1, 2, 3 Shi-Peng Xie,1, 2, 3, ∗ and Qin Wang1, 2, 3, †
1Institute of quantum information and technology,
Nanjing University of Posts and Telecommunications, Nanjing 210003, China
2Broadband Wireless Communication and Sensor
Network TechnologyKey Lab of Ministry of Education,
Ministry of Education, Nanjing 210003, China
3Telecommunication and NetworksNational Engineering
Research Center, NUPT, Nanjing 210003, China
Abstract
In practical implementation of quantum key distributions (QKD), it requires eﬃcient, real-
time feedback control to maintain system stability when facing disturbance from either external
environment or imperfect internal components. Usually, a ”scanning-and-transmitting” program
is adopted to compensate physical parameter variations of devices, which can provide accurate
compensation but may cost plenty of time in stopping and calibrating processes, resulting in
reduced eﬃciency in key transmission. Here we for the ﬁrst propose to employ a well known
machine learning model, i.e., the Long Short-Term Memory Network (LSTM), to predict those
physical parameter variations in advance and actively perform real-time control on corresponding
QKD devices. Experimentally, we take the phase-coding scheme as an example and run the LSTM
model based QKD system for more than 10 days. Experimental results show that we can keep
the same level of quantum-bit error rate as the traditional ”scanning-and-transmitting” program
by employing our new machine learning method, but dramatically reducing the scanning time and
resulting in signiﬁcantly enhanced key transmission eﬃciency. Furthermore, our present machine
learning model should also be applicable to any other QKD systems using any coding scheme or
QKD protocols, and thus seems a very promising candidate in large-scale application of quantum
communication network in the near future.

9
1
0
2

n
u
J

6
1

]
h
p
-
t
n
a
u
q
[

1
v
1
8
6
6
0
.
6
0
9
1
:
v
i
X
r
a

∗ xie@njupt.edu.cn
† qinw@njupt.edu.cn

1

 
 
 
 
 
 
I.

INTRODUCTION

Quantum key distributions (QKD) [1–4] can provide information-theoretic secure keys
between two communicated parties, usually called Alice and Bob, and has attracted extensive
attention from the scientiﬁc world since the ﬁrst BB84 protocol was proposed [2].To date,
signiﬁcant progresses have been achieved in this ﬁeld both theoretically and experimentally,
making it moving from laboratory research to practical implementation and from point-to-
point communication to multiuser complex networks [5, 6].

In practical implementation of QKD, in order to maintain the stability and reliability of
the system, especially for fast-speed QKD networks, real-time control are highly demanded
due to very complex realistic environment and imperfect internal devices. In the history, the
Faraday-Michelson Interferometer (FMI) was designed for phase encoding QKD systems to
solve the problem of interference instability existing in Mach-Zehnder Interferometers (MZI)
[7] caused by polarization changes in transmission ﬁbers. Both theory and experiment have
proven the polarization stability of FMI based QKD systems [8]. Nevertheless, neither MZI
nor FMI can maintain phase stability for a long time due to ineluctable internal phase shift.
Therefore, it is quite common to use a ”scanning-and-transmitting” program to calibrate
those physical parameters in present QKD systems [9–12]. Although present calibration pro-
grams can keep the stability of QKD systems, it is at the cost of transmission eﬃciency, since
it takes time to run the calibration program and no signal data can be transmitted during
the calibrating process. Traditionally, the operation mode of a ”scanning-and-transmitting”
program can be described by the concept of ”duty ratio” [13] which refers to the ratio of
the transmission time to the total time. Obviously, the transmission eﬃciency of a QKD
system is closely related to its ”duty ratio” and it is crucial to increase the ”duty ratio” of
complex QKD networks towards practicality.

The Long Short-Term Memory network (LSTM) [14, 15] is a special kind of recurrent
neural network, whose chain-like nature reveals that it is the natural architecture of neural
network to use for time series [16]. By virtue of these innate advantages, here we for the ﬁrst
time propose to employ LSTM networks to improve the ”duty ratio” of present QKD systems
and solve those existing problems. Furthermore, we carry out corresponding experimental
demonstrations, where we take a FMI based BB84 QKD system as an example and do
comparisons between adopting our present method and applying conventional ”scanning-
and-transmitting” model.

This paper is arranged as follows: In Sec. II, we describe in detail how we construct a
LSTM model to predict the variations of phase voltage and run it on a FMI based BB84
QKD system. In Sec. III, we analyze the experimental data and do comparisons between
our present work and conventional work. Finally, summaries and outlooks are given out in
Sec. IV.

II. METHODS

In this section, we will give descriptions on the methods including how to construct
the LSTM model, how to predict the variations of phase voltages and how to carry out
corresponding experimental demonstrations. Below let us introduce it step by step.

2

A. Establish data structure

Considering the memory characteristics of the LSTM, we divide the training data into
into many sequences according to time, and at each time the data point consists of ”features”
and ”labels”. Now the purpose of applying machine learning is to construct certain mapping
from the characteristics of ”features” to ”labels” by learning from known data.

As we know, phase shift inevitably exists in phase-coding QKD systems due to variations
of many factors in ambient environments, including the temperature, the humidity and the
voltages. Moreover, the intensity ﬂuctuation of a laser also has a great impact on the applied
voltage of a phase modulator. Based on the above, we extract useful ”features” from existing
data, i.e., the operating temperature, the humidity, the intensity of a laser, and the voltages,
and designate the voltage of the next moment as ”labels”. It is worth mentioning that, here
we add ﬁve time-series displacement voltages into ”features” to enhance temporal relevance
of diﬀerent points in time, facilitating learning. Corresponding data structure diagram is
shown in Fig. 1.

FIG. 1. The data structure diagram. T, temperature; H, humidity; P,
U, voltage.
[Tt, Ht, Pt, Ut−4, Ut−3, Ut−2, Ut−1, Ut]T , the label of this moment is Ut+1.

if the current time is t,

For example,

intensity of laser;
then the feature of t moment is

Here we are doing supervised learning with the LSTM model to predict the voltage output
of the traditional ”scanning-and-transmitting” program. We depict the curve of zero-phase
voltage versus time in Fig. 2 to indicate the variation of the zero-phase voltages over a
relative long time period.

3

FIG. 2. Zero-phase voltage versus time curve.

B. Predict phase voltage by LSTM

Before addressing our machine learning work, let us brieﬂy review the working principles
of traditional ”scanning-and-transmitting” programs. Usually, Alice ﬁxes her phase voltage,
and Bob scans his phase modulation voltage across the full scale range of the Data Acqui-
sition Chassis with a large number of steps. At each step, Bob records the photon counts
through single-photon detectors (SPD), and he is able to ascertain the zero-phase voltage
of the minimum count by ﬁtting or other means, which corresponds to the phase where
the destructive interference exactly takes place. According to the ﬁtted zero-phase voltage,
Alice and Bob process feedback control and key transmission.

In contrast to the above traditional program, in our present work the zero-phase voltages
can be actively predicted through implementing the LSTM model instead of scanning and
ﬁtting the interference fringes. Of course, before predicting, a large number of data points
should be collected for training the LSTM network, which can be performed before real key
transmission. We prepared the training data by running the FMI based BB84 QKD system
with traditional ”scanning-and-transmitting” program, including the scanned zero-voltages,
the operating temperatures, the humidities, and the intensities of the laser. During the
above ”scanning-and-transmitting” process, the duty ratio of the QKD system is 0.5. The
whole training data consists of 10 sets, and each set contains a time series of 3600 data
points, temporally corresponding to 20 hours.

In order to enable the network executing deep learning, here we design an improved
two-layer LSTM network structure and utilize a mean squared error cost function. The
number of hidden neurons in the ﬁrst layer is 20 and the number of hidden neurons in the
second layer is 10. Moreover, an method of Z-score normalization has been adopted for all
data before input into the network. The developed LSTM network structure is shown in
Fig. 3. Furthermore, to ensure the long-term reliability of network forecasting, we adopt a
structure combining forecasting with updating. Speciﬁcally, we use the scanning program
as a tool to update the LSTM network, eliminating the cumulative error in the prediction
process and keeping the quantum-bit error rate (QBER) of the QKD system within an
acceptable level. For example, after each prediction of 25 points (250 seconds), we run the
scanning program for 5 times (50 seconds), recording the zero-voltages applied on the phase

4

FIG. 3. Diagram of a two-layer LSTM network, the length of this network is the time span of a
training set. ht denotes the output of last moment, ct represents current cell state, xt refers current
input.

FIG. 4. Data ﬂow of predicting with a two-layer LSTM network. The round boxes represent
programs and squared boxes represent data. The network ﬁrst executes training with 10×3600 sets
of training data. After training, it can predict the zero-voltage at the next moment by reading-
in current values of ”features”, i.e., the temperature and humidity, the optical power, and the
displacement voltages predicted at the previous ﬁve moments as well. Finally, the predicted voltage
is applied on the phase modulator on Bob’s side for the next moment.

modulator. Meantime, corresponding values of the ambient temperature, the humidity, the
laser intensity are also returned to the network. Then the weights and the biases of the
network can be updated accordingly.

Although the LSTM network requires that the training data and subsequent testing data

5

must be a continuous time series, considering the practicability, it is not possible to retrieve
training data with the original QKD system every time before using the network. Therefore,
we discover a way by updating the LSTM network continuously for 10 minutes every time
before transmission. When the training process is good enough, it does not matter even if
the training data and testing data are not continuous, because the rule of data changes has
been embedded in all the weights and biases of the network, we only need to ﬁne-tune the
network parameters to adapt to the current time series through a period of updating.

We use Adam as the optimization algorithm for 270 epochs, which takes approximately
15 minutes on our PC (CPU:Intel Core i7 9700@ 3.6GHz; GPU: NVIDIA GeForce RTX
2080; RAM: DDR4 8GBytes). The initial learning rate is 0.02, and drop 80% every 100
epochs. Batch size is 3600 data points.

C. Experiment

FIG. 5. Schematic of the experimental setup. FMI, Faraday-Michelson Interferometer; BS, beam
splitter; OPM, optical power meter; CB, control board; FM, Faraday mirror; THD, temperature
and humidity detector; PM, phase modulator; SPD, single-photon detector.

The schematic of our experimental setup is displayed in Fig. 5. At Alice’s side, a diode
laser with a repetition rate of 1 MHz possessing a central wavelength of 1550 nm is sent
into a 1:99 beam-splitter (BS) which split the light into two paths, each sent into the optical
power meter (OPM) and the FMI respectively. For each light pulse sent into the FMI, it is
randomly prepared into one of the BB84 state, encoding information, and sent out to Bob
through a commercial standard single-mode optical ﬁber. At Bob’s side, he randomly chooses
one of the basis (X or Z) to carry out projection measurements through FMI, and decoding
out useful information. For each side, a control board (CB) and a personal computer (PC)
are utilized to run the LSTM network and apply proper voltages to the phase modulator
(PM). Besides, each of the OPM, the temperature and humidity detector (THD), and the
SPD are used to real-time record the laser power, the temperature and humidity, and the
counting rate individually. Here the SPD used is a InGaAs single-photon detector working
at a gated mode.

In our experiment, at each of the transmission distance (50 km and 150 km), we in-
dependently run the BB84 QKD system by applying either traditional ”scanning-and-

6

FIG. 6. Comparisons between applying traditional ”scanning-and-transmitting” program and using
present LSTM model based QKD systems. (a) and (b) each refers to the variations of the QBER
with time and its average value at the transmission distance of 50 km and 150 km respectively. The
QBER of traditional method is linked to left Y-axis and of LSTM model is linked to right Y-axis.
(c) The key generation rate versus transmission distance. In each ﬁgure, the square points refer
to the results of applying traditional ”scanning-and-transmitting” program, and the circle points
correspond to using our new method.

7

transmitting” program or our present LSTM model for two days, corresponding QBER and
counting rates at each time are recorded. During the transmission process, we implement
the three-intensity decoy state method,
i.e., modulating light pulse into three diﬀerent
intensities (µ=0.5, ν=0.1, 0), and calculate the QBER for the above two programs. Cor-
responding experimental results are shown in Fig. 6. Here the misalignment error rate
of the optical system is 0.0123, the detection eﬃciency and the dark count rate of the
single-photon detector is 10% and 8 × 10−7 respectively. The ”duty ratio” of traditional
”scanning-and-transmitting” program and our present LSTM model based system is 50%
and 83%, individually.

Moreover, in order to demonstrate that our LSTM model has the ability of long-time
continuous prediction. We run the LSTM model based QKD system for 10 days at the
transmission distance of 50 km. Corresponding result is shown in Fig. 7.

FIG. 7. The variations of the QBER with time and its average value within 10 days by running
the LSTM model based QKD systems at the transmission distance of 50 km.

III. ANALYSIS AND DISCUSSION

In Fig. 6(a) and (b), the variations of the QBER with time and its moving average at the
transmission distance of 50 km and 150 km are plotted out individually. In Fig. 6(a), the
average QBER of traditional method is 0.0176 and of the LSTM model is 0.0185. In Fig.
6(b), the average QBER of traditional method is 0.0518 and of the LSTM model is 0.532.
For simplicity, here we only display the QBER of the signal states µ, for both methods the
QBER value of the decoy state ν keeps almost the same level as the signal state at the
same transmission distance. In Fig. 6(c), we do comparisons between the theory and the
experiment for the quantum key generation rates at diﬀerent transmission distance, where
the line refers to the theoretical predictions, and the points correspond to the experimental
data using either traditional ”scanning-and-transmitting” program (square points) or our
present LSTM model based QKD system (circle points).

We can see from Fig. 6(a) and (b) that, our LSTM model based QKD system can keep the
same level of QBER as traditional ”scanning-and-transmitting” program with continuous
two days monitoring, and our present work can obtain similar QBER for each signal pulse as

8

the traditional program. As a result, we can obtain almost the same quantum key generation
rate for each transmitted signal pulse as the latter. However, if we take the ”duty ratio”
into account, our present method has increased the transmission eﬃciency with at least 33
percent compared with the latter, and this value in principle can be further improved by
optimizing the network structure.

In Fig. 7, the QBER of our LSTM model based QKD system for continuous 10 days
measurements has been displayed out, and it shows no trend of deterioration from beginning
to end, demonstrating the long-time reliability and stability of our present method.

In both Fig. 6(a) and 7, the QBER appears some rising points. These rising points
mainly rooted in some additional disturbances in our laboratory. Then, in the 150 km ﬁber
experiment, we eliminate these additional disturbances, and the QBER results appear no
such rising point.

IV. CONCLUSIONS AND OUTLOOKS

In conclusion, we have developed a new operating mode for present QKD system called
”predicting-and-updating” pattern which can enable the QKD system working reliably and
steadily for a long time only with a few scans to update the network. Furthermore, we
carry out corresponding experimental demonstration by running a phase-coding BB84 QKD
system with either our present method and applying traditional ”scanning-and-transmitting”
program. Experimental results show that we can keep almost the same level of QBER as the
traditional ”scanning-and-transmitting” program by applying our present operating mode,
but dramatically reduce the scanning and stopping time than the latter, and thus achieve
signiﬁcantly improved transmission eﬃciency.

Finally, we should declare that our present work is not limited to phase-coding schemes
or BB84 protocols. Here we only take a phase-coding BB84 QKD system as an example to
run our model and get excellent experimental results. In principle, this model should also
be applicable to any other coding scheme and QKD protocols [17–20], since the machine
learning model only needs enough training data to construct out corresponding mapping
relationship between ”features” and ”labels”, and has no requirements for speciﬁc systems
or protocols. Therefore, we believe that our present machine learning based operating mode
could replace traditional ”scanning-and-transmitting” program and play an important role
in practical applications of large-scale quantum communication networks in the near future.

V. ACKNOWLEDGEMENT

This work has been supported by the National Key Research and Development Pro-
gram of China (2018YFA0306400, 2017YFA0304100, 2016YFA0302600); National Natural
Science Foundation of China (NSFC) (61705110, 11847215, 11774180, 61675235, 61475197,
61590932); China Postdoctoral Science Foundation (2018M642281); Natural Science Foun-
dation of Jiangsu Province (BK20170902); Jiangsu Planned Projects for Postdoctoral Re-
search Funds (2018K185C); University Natural Science Research Project of Jiangsu Province
(17KJB510038); The Postgraduate Research & Practice Innovation Program of Jiangsu
Province through Grant No. KYCX19 0951.

9

APPENDIX A: WORKING PRINCIPLE OF LSTM NETWORK

Considering reasoning about previous events of sequencing events to inform later ones,
its unclear how a traditional neural network could do. Recurrent neural networks (RNN)
[16] address this issue. They are networks with loops, allowing information to persist and
also the natural architecture of neural network to use for time series. However, the standard
RNN is unable to solve the long-term Dependencies problem [21, 22] which means RNNs
become unable to learn to connect the previous information as its time gap grows.

FIG. 8. Schematic diagram of the internal structure of a LSTM block.

The LSTM is explicitly designed to tackle this problem [23, 24]. All recurrent neural
networks have the form of a chain of repeating modules of neural network. In a standard
RNN, this repeating module has a simple structure, usually a single hidden layer. An LSTM
also has the chain like structure, but the repeating module has a diﬀerent structure. Instead
of having a single hidden layer, there are four layers, interacting in a very special way.

The key to LSTMs is the cell state Ct which is kind of like a conveyor belt. Information
that has been learned ﬂows along it and runs through the entire chain. The LSTM has the
ability to remove or add information to the cell state, regulated by structures called gates.
An LSTM block has three of these gates to control the cell state [25].

Firstly, a sigmoid layer called the ”forget gate layer” decides what past information we
are going to throw away from the cell state. The input of current moment xt and the output
of last moment ht−1 go through the synapses with certain weights Wf and biases bf and
then are processed by a sigmoid active function σ as following:

ft = σ(Wf · [ht−1, xt] + bf ).

(A1)

The next step is to decide what new information were going to store in the cell state.
This step consists of two parts. First, also a sigmoid layer called the input gate layer decides
which values need to be updated. This process is shown in Eq.(A2). Then a tanh layer
creates a vector of new candidate values ˜Ct which could be added to the cell. This process
is shown in Eq.(A3).

it = σ(Wi · [ht−1, xt] + bi),

(A2)

10

˜Ct = tanh(Wc · [ht−1, xt] + bc).
The cell state is updated by multiplying with the two gates mentioned above as shown

(A3)

in Eq.(A4).

Ct = ft × Ct−1 + it × ˜Ct.
Finally, the ”output gate layer” output the values we need after the ﬁltration of the cell
state. We put the cell state through the tanh active function (to push the values to be
between -1 and 1) and multiply it by the output of the output gate, so that we only output
the parts we decided to. These steps are shown in Eq.(A5) and Eq.(A6).

(A4)

Ot = σ(Wo · [ht−1, xt] + bo),

ht = Ot × tanh(Ct).

(A5)

(A6)

APPENDIX B: COMPARISONS OF DIFFERENT MODELS

Before our experiment, we have done some comparisons between the predictions by using
diﬀerent machine learning models, including lower order polynomials, neural network, RNN,
and LSTM. Here we use a representative time series of 3300 data points which its voltage
ﬂuctuates violently. The ﬁrst 70 percent of this dataset is used for training and the second
30 percent for prediction. The inputs of models are temperature T, humidity H, intensity
of laser P, and current zero-phase voltage U which is predicted at previous moment. The
comparisons of the predicted results from lower order polynomials, a neural network, a RNN,
and the LSTM are in Fig. 9. We take the root mean square error (RMSE) of the prediction
part as the key index for comparison. Other training details are the same as above.

Compared with RNN and LSTM, the prediction results of neural network and low order
polynomial are poor. It can also be seen from FIG. 9(a) and 9(b) that the prediction curve
does not ﬁt well with the actual target curve. However, when we compare RNN with LSTM,
we can ﬁnd that LSTM is more accurate than RNN, the RMSE of LSTM is much smaller
than that of RNN. Therefore, we ﬁnd that among the above machine learning models, LSTM
model is the best candidate for predicting zero-phase voltages.

11

FIG. 9. Comparisons of prediction results from lower order polynomial, neural network, RNN, and
LSTM.

[1] W. Diﬃe, and M. E. Helman, New Directions in Cryptography, IEEE Trans. Inf. Theory 22,

644 (1976).

[2] C. H. Bennett, and G. Brassard, Quantum cryptography: public key distribution and coin
tossing, in Proceedings of the IEEE International Conference on Computers, Systems and
Signal Processing (IEEE, New York, 1984), pp. 175-179.

[3] A. K. Ekert, Quantum cryptography based on Bell’s theorem, Phys. Rev. Lett. 67, 661 (1991).
[4] D. J. Bernstein, and T. Lange, Post-quantum cryptography, Nature 549, 188-194 (2017).
[5] X. B. Wang, Beating the Photon-Number-Splitting Attack in Practical Quantum Cryptogra-

phy, Phys. Rev. Lett. 94, 230503 (2005).

[6] H. K. Lo, X. Ma, K. Chen, Decoy State Quantum Key Distribution, Phys. Rev. Lett. 94,

230504 (2005).

[7] X. F. Mo, B. Zhu, Z. F. Han, Y. Z. Gui, and G. C. Guo, Faraday Michelson system for

quantum cryptography, Opt. Lett. 30, 2632-2634 (2005).

[8] Z. F. Han, X. F. Mo, Y. Z. Gui, and G. C. Guo, Stability of phase-modulated quantum key

distribution systems, Appl. Phys. Lett. 86, 221103 (2005).

[9] Q. Wang, W. Chen, G. Xavier, M. Swillo, T. Zhang, S. Sauge, M. Tengner, Z-F Han, G-C.
Guo and A. Karlsson, Experimental Decoy-State Quantum Key Distribution with a Sub-
Poissionian Heralded Single-Photon Source, Phys. Rev. Lett. 100, 090501 (2008).

[10] C. H. Zhang, X. Y. Zhou, H. J. Ding, C. M. Zhang, G. C. Guo, and Q. Wang, Proof-of-
Principle Demonstration of Passive Decoy-State Quantum Digital Signatures Over 200 km,
Phys.Rev.Appl. 10, 034033 (2018).

12

[11] S. Wang, W. Chen, Z. Q. Yin, et al, Practical gigahertz quantum key distribution robust

against channel disturbance, Opt. Lett. 43 2030-2033 (2018).

[12] X. B. An, H. Zhang, C. M. Zhang, et al, Practical quantum digital signature with a gigahertz

BB84 quantum key distribution system, Opt. Lett. 44 139-142 (2019).

[13] C. Wang, Z. F. Han, X. F. Mo, et al, Active phase compensation of quantum key distribution

system, Chinese Sci. Bull. 53 1310-1314 (2008).

[14] S. Hochreiter, and J. Schmidhuber, Long short-term memory, Neural Comput. 9, 1735-1780

(1997).

[15] S. Jurgen, Deep learning in neural networks: An overview, Neural Netw. 61, 85-117.
[16] J. T. Connor, R. D. Martin, and L. E. Atlas, Recurrent neural networks and robust time series

prediction, IEEE Trans. Neural Netw. 5, 240-254 (1994).

[17] H. K. Lo, M. Curty, and B. Qi, Measurement-Device-Independent Quantum Key Distribution,

Phys. Rev. Lett. 108, 130503 (2012).

[18] Y. H. Zhou, Z. W. Yu, and X. B. Wang, Making the decoy-state measurement-device-
independent quantum key distribution practically useful, Phys. Rev. A 93, 042324 (2016).
[19] G. L. Roberts, M. Lucamarini, Z. L. Yuan, J. F. Dynes, L. C. Comandar, et al, Experimental
measurement-device-independent quantum digital signatures, Nat. Commun. 8 1098 (2017).
[20] M. Lucamarini, Z. L. Yuan, J. F. Dynes, and A. J. Shields, Overcoming the rate–distance
limit of quantum key distribution without quantum repeaters, Nature 557, 400 (2018).
[21] M. Hagan, H. Demuth, and M. Beale, Neural Network Design (PWS Publishing Company,

Boston, MA, 1996), p. 734.

[22] Y. Bengio, P. Simard, P. Frasconi, Learning long-term dependencies with gradient descent is

diﬃcult, IEEE Trans. Neural Netw. 5, 157-166 (1994).

[23] S. Haykin, Neural NetworksA Comprehensive Foundation, 2nd ed. (Prentice-Hall, Englewood

Cliﬀs, NJ, 1999).

[24] C. M. Bishop, Pattern Recognition and Machine Learning, 1st ed. (Springer-Verlag, New York,

2006).

[25] http://colah.github.io/posts/2015-08-Understanding-LSTMs/.

13

