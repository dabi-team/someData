Noname manuscript No.
(will be inserted by the editor)

An Adaptive Stochastic Sequential Quadratic
Programming with Diﬀerentiable Exact Augmented
Lagrangians

Sen Na · Mihai Anitescu · Mladen Kolar

2
2
0
2

n
u
J

6

]

C
O
.
h
t
a
m

[

2
v
0
2
3
5
0
.
2
0
1
2
:
v
i
X
r
a

Received: date / Accepted: date

Abstract We consider solving nonlinear optimization problems with stochastic
objective and deterministic equality constraints. We assume for the objective
that its evaluation, gradient, and Hessian are inaccessible, while one can com-
pute their stochastic estimates by, for example, subsampling. We propose a
stochastic algorithm based on sequential quadratic programming (SQP) that
uses a diﬀerentiable exact augmented Lagrangian as the merit function. To mo-
tivate our algorithm design, we ﬁrst revisit and simplify an old SQP method [25]
developed for solving deterministic problems, which serves as the skeleton of our
stochastic algorithm. Based on the simpliﬁed deterministic algorithm, we then
propose a non-adaptive SQP for dealing with stochastic objective, where the
gradient and Hessian are replaced by stochastic estimates but the stepsizes are
deterministic and prespeciﬁed. Finally, we incorporate a recent stochastic line
search procedure [31] into the non-adaptive stochastic SQP to adaptively select
the random stepsizes, which leads to an adaptive stochastic SQP. The global
“almost sure” convergence for both non-adaptive and adaptive SQP methods is
established. Numerical experiments on nonlinear problems in CUTEst test set
demonstrate the superiority of the adaptive algorithm.

Keywords Stochastic optimization · Sequential quadratic programming ·
Augmented Lagrangian · Exact penalty

Sen Na
Department of Statistics, University of California, Berkeley
International Computer Science Institute
E-mail: senna@berkeley.edu

Mihai Anitescu
Mathematics and Computer Science Division, Argonne National Laboratory
E-mail: anitescu@mcs.anl.gov

Mladen Kolar
Booth School of Business, University of Chicago
E-mail: mladen.kolar@chicagobooth.edu

 
 
 
 
 
 
2

1 Introduction

Na et al.

We consider the nonlinear equality-constrained stochastic optimization problem

f (x) = E[f (x; ξ)],

min
x∈Rd

s.t. c(x) = 0,

(1)

where f : Rd → R is the objective, c : Rd → Rm are the constraints, and ξ ∼ P
is a random variable following the distribution P. In stochastic optimization, the
function f (x), gradient ∇f (x), and Hessian ∇2f (x) either cannot be evaluated
due to the expectation over ξ, or are too expensive to compute, for example, in
big data applications in machine learning. Instead, one can generate either
a single sample ξ ∼ P and let ¯f (x) = f (x; ξ), ¯∇f (x) = ∇f (x; ξ), ¯∇2f (x) =
∇2f (x; ξ); or a mini-batch ξi1, . . . ξiB
j=1 f (x; ξij ),
¯∇f (x) = 1
j=1 ∇2f (x; ξij ) be the corre-
B
sponding stochastic estimates at x.

j=1 ∇f (x; ξij ), ¯∇2f (x) = 1

i.i.d∼ P and let ¯f (x) = 1
B

(cid:80)B

(cid:80)B

(cid:80)B

B

Problem (1) prominently appears in machine learning where the objective

takes the form

(cid:90)

f (x) =

f (x; y, z) dP(y, z)

with (y, z) representing random input-output pairs with the joint distribution
P(y, z). The loss function f is parameterized by x, and our goal is to obtain
the optimal parameter x(cid:63) by minimizing the loss function under nonlinear
constraints. In practice, the distribution P(y, z) is unknown and only n data
points {ξi = (yi, zi)}n
i=1 from P(y, z) are available. In that case, P(y, z) is
approximated by the empirical distribution and the objective can be written as

f (x) =

1
n

n
(cid:88)

i=1

f (x; ξi) = E [f (x; ξ)] ,

(2)

where ξ ∼ Uniform ({ξi}n
i=1) follows uniform distribution over n discrete data
points. The ﬁnite-sum loss function above is called the empirical risk. For ex-
ample, recent studies on constrained deep neural networks [28, 36] are in the
form of (2).

Problem (1) also appears widely in statistics as a way to estimate model
parameters that best ﬁt the data. The constraint set encodes prior information
or physical constraints on the parameters. In applications of maximum likeli-
hood estimation (MLE) under constraints, f (x, ξ) is a negative log-likelihood
function evaluated at one data point. For example, [27] studied least square
problems under nonlinear equality constraints; [16] studied constrained MLE;
and [39] studied constrained M -estimation. These references established con-
sistency and asymptotic normality for the optimizer x(cid:63) of (1). See [35, 45] for
more statistical background on the problem.

While there is a rich history on statistical properties of constrained esti-
mators, numerical procedures for solving (1) are less well developed. When

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

3

constraints are characterized by an abstract set, projected stochastic ﬁrst- and
second-order methods have been developed [29, 5]. However, these projection-
based methods are not applicable for (1), since the projection to the null space
of nonlinear equations may not be easily computed. To our knowledge, only
recently [3] proposed the very ﬁrst practical algorithm for solving (1), which is a
stochastic sequential quadratic programming (StoSQP) with (cid:96)1 penalized merit
function. The method of [3] possesses the following three main components:

(a) [3] designed a novel stepsize selection scheme, where the stepsize ¯αk is set by
projecting a quantity to an interval. The quantity and the interval bound-
aries depend on the magnitude of the search direction, the Lipschitz constant
of the merit function, and a prespeciﬁed deterministic sequence {βk}k. Such
a stepsize selection scheme is designed to introduce certain adaptivity into
the algorithm without involving a line search. The sequence {βk}k, which
is either constant or decaying with a proper rate, determines the iteration
convergence behavior, however, still heavily aﬀects the selection of ¯αk. As
shown numerically in [3], the line search procedure is still preferable for
most of problems.

(b) The penalty parameter of the merit function in each iteration is adaptively
selected in [3], which can be viewed as a random walk. To establish conver-
gence, it is important to show two properties for the underlying random walk.
(i) It stabilizes after a number of iterations, so that one can accumulate
the descent of the merit function in each iteration. (ii) The stabilized penalty
value is less (or greater depending on the deﬁnition) than a deterministic
threshold, so that SQP iterates indeed converge to a KKT point instead of
a stationary point of the merit function. [3] showed (i) under a boundedness
condition (cf. Proposition 3.18), which is a standard condition even in
deterministic setting (cf. [4, Chapter 4]). However, (ii) is more subtle for
StoSQP, where the stabilized value itself is random and diﬀerent in each
run. To this end, [3] showed (ii) under additional assumptions on the noise
distribution (e.g Gaussian). See Proposition 3.16 and Example 3.17 therein.
(c) [3] employed an (cid:96)1 penalized merit function. As noticed for deterministic
problems, diﬀerentiable merit functions are alternative choices that may en-
joy some local beneﬁts, such as overcoming the Maratos eﬀect [26]. Although
local analysis of StoSQP is not a goal of the paper, and it is unclear whether
the Maratos eﬀect is a serious issue on stochastic problems (given the
randomness of objective estimation), it still stimulates interest in designing
a StoSQP with an alternative, diﬀerentiable merit function.

This paper provides diﬀerent resolutions on the above three components to de-
rive an adaptive StoSQP. For (a), we study a diﬀerent setup compared to [3].
Under the setup, we are allowed to generate mini batches to have a more pre-
cise objective approximation, which further allows us to adaptively select the
stepsize via stochastic line search. To this end, we generalize the stochastic line
search procedure in [31] to equality-constrained problems under constraint
qualiﬁcations. The generalization is non-trivial since, due to the constraints, we
have to use the merit function with varying stochastic penalty parameters in the

4

Na et al.

Armijo condition, while [31] used the ﬁxed objective function. With the help of
the line search, we do not have to prespecify a sequence to control the stepsize.
For (c), we employ a diﬀerentiable exact augmented Lagrangian merit func-
tion. Comparing with a standard design of using the (cid:96)1 merit function in
the line search, our experiments provide some evidence for supporting the
usage of the augmented Lagrangian. Although our experiments only investigate
the global convergence so that the improvement of the augmented Lagrangian
is not so signiﬁcant, and we do not attempt to claim beneﬁts of the augmented
Lagrangian over the (cid:96)1 merit function under the present global analysis, our pa-
per indeed serves as the ﬁrst step towards understanding the local convergence
of diﬀerentiable merit functions for solving constrained stochastic problems.
Finally, for (b)(i), we consider a similar setup to [3], and show that the penalty
parameter is stabilized when the estimation errors are bounded in each iteration
(cf. Assumption 4). However, for (b)(ii), we adopt a diﬀerent approach. We
modify the SQP scheme when specifying the penalty parameter. In particular,
we accept the penalty parameter only if a more stringent condition is satisﬁed,
where the feasibility error is bounded by the gradient magnitude of the aug-
mented Lagrangian. By such modiﬁcation, we ensure the convergence to a KKT
point without relying on the noise distribution. With all above diﬀerences,
we establish the global convergence of the proposed StoSQP by showing that
lim inf k→∞ (cid:107)∇L(xk, λk)(cid:107) = 0 almost surely, where L(x, λ) = f (x) + λT c(x)
is the Lagrange function with λ ∈ Rm being the dual variables associated with
the constraints; and (xk, λk) is the k-th primal-dual iterate. This type of result
is also diﬀerent from [3], which shows lim inf k→∞ E[(cid:107)∇L(xk, λk)(cid:107)] = 0.

1.1 Literature review

Problem (1) is closely related to two classes of problems: constrained determin-
istic optimization and unconstrained stochastic optimization, both of which
have been extensively investigated. We review some related literature.

There exist numerous methods for solving constrained deterministic prob-
lems, including exact penalty methods, augmented Lagrangian methods, and se-
quential quadratic programming (SQP) methods [30]. This paper utilizes SQP
schemes to solve stochastic problems. SQP schemes apply Newton’s method on
KKT equations of (1). Within a SQP scheme, an exact penalty function is used
in the line search to monitor the iteration progress towards a KKT point. One
of the advantages of SQP is that Newton’s system preserves the structure of
the objective, which contrasts with exact penalty method and augmented La-
grangian method. The search direction of the latter two methods is derived by
minimizing a penalized objective, and the penalty term may aﬀect the problem
structure. See [21, 20] and references therein for a brief review of SQP.

The present paper contributes to the existing literature on SQP by studying
its global convergence for solving stochastic optimization problems. [3] designed
a StoSQP using the exact penalty function f (x) + µ(cid:107)c(x)(cid:107)1. We instead
use L(x, λ) + µ/2 · (cid:107)∇λL(x, λ)(cid:107)2
2 with µ, ν > 0

2 + ν/2 · (cid:107)∇T c(x)∇xL(x, λ)(cid:107)2

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

5

being the penalty parameters. This function is deﬁned on the primal-dual pair
(x, λ) and called exact augmented Lagrangian [32]. The exactness of such an
augmented Lagrangian has been studied in [33, 34]. [25] employed it in a SQP
framework for deterministic problems, which we will revisit and modify in
Section 2. The modiﬁed algorithm serves as the skeleton of our StoSQP designed
in Sections 3 and 4.

Without constraints, numerous ﬁrst- and second-order methods have also
been reported for solving stochastic problems. We refer to [9, 2] for a recent
review. One practical concern for stochastic methods is the adaptivity of the
stepsize. A growing body of literature has generalized the natural line search
for gradient descent to stochastic line search by dynamically controlling the
sample size for computing the gradient estimates [18, 10, 24, 15, 7]. However,
most of works study convex problems, do not provide convergence guarantees
for the line search, and use sample size selection strategies that depend on
unknown quantities such as the true gradient. Practical stochastic stepsize se-
lection methods with convergence guarantees have been developed only recently.
[1, 12, 23, 14, 6, 13] studied stochastic trust-region methods, where stepsizes
are absorbed in local quadratic models. [11] established the expected iteration
complexity of stochastic line search for nonconvex objectives, while required
function evaluations to be computed exactly. [38] allowed for stochastic evalua-
tions, but only proved convergence for strongly convex objectives. Finally, [31]
generalized the analysis in [11] and [38] by applying the martingale framework
in [6], and obtained convergence guarantees for stochastic line search with both
convex and nonconvex objectives.

Our paper generalizes [31] to equality-constrained problems under constraint
qualiﬁcations. As discussed earlier, the generalization is not immediate since
the merit function has varying stochastic penalty parameters. In addition, in
unconstrained problems, if one observes a suﬃcient decrease of the objective in
each iteration, then one can claim that the iterates converge to a stationary point
(or a minimizer if the objective is convex). Diﬀerently, in constrained problems,
if one observes a suﬃcient decrease of the merit function in each iteration, then
one can only claim that the iterates converge to a stationary point of the merit
function. Only if the penalty parameter of the exact penalty merit function is
less than a critical threshold can one claim the iterates indeed converge to a KKT
point. In stochastic optimization, the problem is even more challenging: one has
to show that the stabilized penalty parameter, a random quantity, is less than
the deterministic threshold to ensure convergence. [3, Section 3.2.2] discussed
this subtlety and resolved it for some noise distributions (e.g. Gaussian), while,
instead, we achieve convergence to a KKT point by modifying a SQP scheme
and imposing a more stringent condition when selecting the penalty parameter.
Our analysis does not rely on the symmetry of the noise distributions (cf. [3,
Example 3.17]).

Structure of the paper: We revisit and simplify an old deterministic SQP
scheme [25] in Section 2. Based on the simpliﬁed SQP scheme, a non-adaptive
StoSQP is designed in Section 3, and an adaptive StoSQP that utilizes a stochas-

6

Na et al.

tic line search is designed in Section 4. Numerical experiments and conclusions
are presented in Sections 5 and 6. Due to space limit, some technical proofs
are deferred to the appendix.

Notation: We use (cid:107) · (cid:107) to denote the (cid:96)2 norm for vectors and the spectral
norm for matrices. I denotes the identity matrix and 0 denotes the zero matrix
or vector, whose dimensions are clear from the context. For scalars a and b,
a ∨ b = max(a, b) and a ∧ b = min(a, b). For random variables ξ1, ξ2, we denote
Eξ1[g(ξ1, ξ2)] = E[g(ξ1, ξ2) | ξ2] to be the conditional expectation, that is, the
expectation taken over randomness in ξ1 only.

2 SQP with Diﬀerentiable Exact Augmented Lagrangian

In this section, we assume f is deterministic. We revisit and simplify the SQP
scheme proposed by [25] to facilitate the later design of StoSQP. Let L(x, λ) =
f (x) + λT c(x) be the Lagrangian function of (1). We aim at ﬁnding a KKT
point (x(cid:63), λ(cid:63)) that satisﬁes

(cid:18)∇xL(x(cid:63), λ(cid:63))
∇λL(x(cid:63), λ(cid:63))

(cid:19)

(cid:18)∇f (x(cid:63)) + GT (x(cid:63))λ(cid:63)
c(x(cid:63))

(cid:19)

(cid:19)

(cid:18)0
0

,

=

=

where G(x) = ∇T c(x) = (∇c1(x), . . . , ∇cm(x))T ∈ Rm×d is the Jacobian ma-
trix. The diﬀerentiable exact augmented Lagrangian considered in this paper
takes the form

Lµ,ν(x, λ) = L(x, λ) +

µ
2

(cid:107)c(x)(cid:107)2 +

ν
2

(cid:107)G(x)∇xL(x, λ)(cid:107)2.

(3)

The ﬁrst penalty characterizes the feasibility error, which is a quadratic penalty
on ∇λL(x, λ). The second penalty characterizes the optimality error, where
∇xL(x, λ) is transformed by the Jacobian G(x). We notice that, even without
transformation G(x), the function (3) is still an exact augmented Lagrangian,
provided µ is suﬃciently large and ν is suﬃciently small [4, Proposition 4.15].
On the other hand, G(x) can be replaced by other suitable weight matrices that
satisfy certain conditions. See [33] for other choices and their comparisons in
experiments. Our analysis can be easily extended to other forms of augmented
Lagrangian. We use G(x) for transformation as it is simpler than other choices,
especially when computing the gradient ∇Lµ,ν; and, unlike without transfor-
mation, ν > 0 in our analysis can be any positive parameter and need not be
adapted. The gradient of Lµ,ν(x, λ) is

(cid:18)∇xLµ,ν(x, λ)
∇λLµ,ν(x, λ)

(cid:19)

=

where

(cid:18)I + νM (x, λ)G(x) µGT (x)

νG(x)GT (x)G(x)

I

(cid:19) (cid:18)∇xL(x, λ)
∇λL(x, λ)

(cid:19)

(4)

M (x, λ) =∇x(G(x)∇xL(x, λ)) = ∇2
T (x, λ) = (cid:0)∇2c1(x)∇xL(x, λ), . . . , ∇2cm(x)∇xL(x, λ)(cid:1) .

xL(x, λ)GT (x) + T (x, λ) ∈ Rd×m,

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

7

We now present a SQP scheme. Given a pair (xk, λk) at the k-th iteration,
we denote fk = f (xk), ∇fk = ∇f (xk) (similar for Gk, Mk, ∇xLk etc.) to be the
quantities evaluated at the k-th iterate. We then compute the search direction
(∆xk, ∆λk) by solving

(cid:18)Bk GT
k
Gk 0

(cid:19)

(cid:19)

(cid:19) (cid:18)∆xk
ˆ∆λk
k ∆λk = −(Gk∇xLk + M T

(cid:18)∇xLk
ck

= −

GkGT

,

k ∆xk),

(5)

where Bk is an approximation of the Lagrangian Hessian ∇2
iterate is then

xLk. The next

(cid:19)

(cid:18)xk+1
λk+1

=

(cid:19)

(cid:18)xk
λk

+ αk

(cid:18)∆xk
∆λk

(cid:19)

,

where the stepsize αk is chosen to make the Armijo condition hold

Lk+1

µ,ν ≤ Lk

µ,ν + αkβ

(cid:18)∇xLk
∇λLk

µ,ν

µ,ν

(cid:19)

(cid:19)T (cid:18)∆xk
∆λk

(6)

(7)

for a prespeciﬁed β ∈ (0, 1).

Remark 1 We should mention that the dual search direction in this scheme is
∆λk, not ˆ∆λk like in most of SQP schemes. This diﬀerence is driven by the
penalty term (cid:107)G(x)∇xL(x, λ)(cid:107)2 in (3). In fact, if Bk ≈ ∇2
xLk and (xk, λk) is
close to a KKT point, ∆λk ≈ ˆ∆λk by noting that Mk ≈ ∇2
k . However,
for an iterate that is far from a KKT point or Bk (cid:54)≈ ∇2
xLk (which is the case in
this paper), ∆λk and ˆ∆λk are signiﬁcantly diﬀerent and such a modiﬁcation is
essential. For a SQP scheme that uses the merit function Lµ,ν, we desire a dual
direction that, together with ∆xk, is a descent direction of Lk
µ,ν for any ν > 0, as
long as µ > 0 is suﬃciently large. A suﬃcient (may not be necessary) condition
for such a dual direction, proposed by [25, (8)], is

xLkGT

lim
α→0

GkGT

k ∆λk(α) = −(Gk∇xLk + M T

k ∆xk),

where ∆λk(α) can depend on the stepsize α selected by the line search. This pa-
per removes the dependence on α and directly solves ∆λk from the above equa-
tion. We note, however, that ˆ∆λk does not satisfy this condition. For a general
penalty term (cid:107)W (x)∇xL(x, λ)(cid:107)2 with a diﬀerentiable weight matrix W (x) ∈
Rm×d, we let S(x, λ) = ∇x (W (x)∇xL(x, λ)) ∈ Rd×m, and the above condi-
tion can be adapted as

lim
α→0

WkGT

k ∆λk(α) = −(Wk∇xLk + ST

k ∆xk).

By the exact penalty analysis (cf. [33, Proposition 3]), W (x)GT (x) is assumed
to be invertible.

8

Na et al.

Algorithm 1 SQP with Diﬀerentiable Exact Augmented Lagrangian
1: Input: initial iterate (x0, λ0), scalars ν, µ0, δ0 > 0, ρ > 1, β ∈ (0, 1);
2: for k = 0, 1, 2 . . . do
3:

Compute (∆xk, ∆λk) by (5);
(cid:19)

(cid:18)∇xLk
∇λLk

µk,ν
µk,ν
Let µk = ρµk, δk = δk/ρ;

(cid:19)T (cid:18)∆xk
∆λk

while

> −δk

(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:18) ∆xk

Gk∇xLk

2

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

do

end while
Select αk to satisfy the Armijo condition in (7) with parameters µk, ν, and β;
Update the iterate by (6);
Let µk+1 = µk, δk+1 = δk;

4:

5:
6:
7:
8:
9:
10: end for

The downside of the above scheme is that the penalty parameter µ is ﬁxed.
To prove convergence, µ needs to be large enough so that the square matrix in
(4) is invertible. Then (cid:107)∇Lk
µ,ν(cid:107) → 0 implies (cid:107)∇Lk(cid:107) → 0. The threshold depends
on multiple unknown quantities of the problem and is hard to tune manually.
Thus, we propose an adaptive SQP method in Algorithm 1 to resolve this issue.
The adaptivity is achieved by the While loop in Line 4. In the While loop, we
iteratively check if the inner product of the search direction (∆xk, ∆λk) and
(cid:0)(cid:107)∆xk(cid:107)2 + (cid:107)Gk∇xLk(cid:107)2(cid:1). If not,
the gradient ∇Lk
we increase µk and decrease δk until the condition is satisﬁed. This parameter
selection scheme is also used in our later design of StoSQP, although there we
require an additional condition to be satisﬁed for µk.

µk,ν is upper bounded by −δk

The global convergence of Algorithm 1 can be established in a similar way to
[25]. We do not go over the analysis in this paper, but mainly focus on analyzing
a stochastic version of it. However, we should mention that Algorithm 1 adopts
two simpliﬁcations from [25] as listed below.

(a) [25] applied ﬁnite diﬀerences to approximate Mk = ∇x (Gk∇xLk) in (5),
while we assume that second-order matrices are computable to simplify the
presentation. This allows us to compute the Lagrangian Hessian ∇2
xL, the
constraint Hessian ∇2ci, ∀i, and hence Mk.

(b) [25] used a more complex While loop to select µk. That update of µk depends
on the iterate (cf. [25, (13)]). In the end, the complex While loop condition
implies that the inner product of the search direction and the gradient
∇Lk
µk,ν is bounded by −δ((cid:107)∆xk(cid:107)2 + (cid:107)Gk∇xLk(cid:107)2) for some δ > 0 (cf. [25,
Proposition 4.2]), which is what the authors ﬁnally used in the analysis. We
simplify their While loop by directly enforcing the ﬁnal condition, and
increasing µk by a ﬁxed factor ρ > 1 each time (Line 5 in Algorithm 1).

Algorithm 1 is a framework that shows how to design an adaptive SQP
using diﬀerentiable exact augmented Lagrangian as the merit function. Using
the constructed SQP as a skeleton, we design a non-adaptive and adaptive
StoSQP scheme in Sections 3 and 4, respectively.

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

9

Algorithm 2 A Non-Adaptive StoSQP
1: Input: initial iterate (x0, λ0), stepsizes {αk}k;
2: for k = 0, 1, 2 . . . do
3:
4:
5:
6: end for

Generate independent realizations ξk
Compute ( ¯∆xk, ¯∆λk) by (9);
Update the iterate by (10);

g and ξk

H , and compute ¯∇xLk and ¯Mk as in (8);

3 Warm-up: A Non-Adaptive Stochastic SQP

Before designing an adaptive StoSQP in Section 4, we design a non-adaptive
StoSQP in this section. It is a straightforward counterpart of Algorithm 1, except
that the deterministic gradient and Hessian of f are replaced by their stochastic
estimates, and the line search is replaced by a prespeciﬁed sequence of stepsizes
{αk}k. Since no line search is used, the merit function (3) is not involved in
the algorithm presentation, and is only used to analyze the convergence.

Suppose f is stochastic, and its function value, gradient, and Hessian are not
accessible. Instead, we have access to their estimates ¯f , ¯g, and ¯H. In what
follows, we use ¯(·) to denote random quantities, except for the iterate (xk, λk).
Let ξk
H be two independent realizations of the random variable ξ, and denote

g , ξk

¯gk = ∇f (xk; ξk

g ),

¯∇xLk = ¯∇xL(xk, λk; ξk

g ) = ¯gk + GT
k λk,
m
(cid:88)

H ) = ¯Hk +

¯Hk = ∇2f (xk; ξk

H ), ¯∇2

xLk = ¯∇2

xL(xk, λk; ξk

(λk)j∇2cj(xk),

¯Tk = (cid:0)∇2c1(xk) ¯∇xL(xk, λk; ξk
k + ¯Tk.
¯Mk = ¯∇2

xLkGT

H ), · · · , ∇2cm(xk) ¯∇xL(xk, λk; ξk

H )(cid:1) ,

(8)

j=1

g is used for estimating the gradient ¯∇xLk, while ξk

In particular, ξk
H is used for
estimating the second-order derivatives, including ¯∇2
g and
H are independent, ¯Mk and ¯∇xLk are also independent. The subscript k for
ξk
both stochastic and deterministic quantities corresponds to the evaluation at
the k-th iterate (xk, λk).

xLk and ¯Mk. Since ξk

g , ξk
Given the iterate (xk, λk), the non-adaptive StoSQP generates ξk = (ξk
H )
and computes ¯∇xLk and ¯Mk as in (8). Then, the stochastic search direction
( ¯∆xk, ¯∆λk) is given similarly to (5) by
(cid:18)Bk GT
k
Gk 0

(cid:18) ¯∇xLk
ck

(cid:19) (cid:18) ¯∆xk
˜∆λk

= −

(cid:19)

(cid:19)

,

(9)

GkGT
k

¯∆λk = −(Gk ¯∇xLk + ¯M T
k

¯∆xk).

Same as [3], we suppose Bk is deterministic given (xk, λk). In practice, Bk = I
is suﬃcient for global convergence. Then, for a prespeciﬁed stepsize αk, we let

(cid:19)

(cid:18)xk+1
λk+1

=

(cid:19)

(cid:18)xk
λk

+ αk

(cid:18) ¯∆xk
¯∆λk

(cid:19)

.

(10)

10

Na et al.

The procedure is summarized in Algorithm 2.
Relationship to StoSQP in [3]: The non-adaptive StoSQP is applicable un-
der the fully stochastic setup as in [3], where the derivatives of f are estimated
with constant variance. This setup contrasts with the line search setup in
Section 4, where we will require a more precise model approximation. [3] has a
smaller computational cost1: in each iteration, it generates one sample, and eval-
uates one gradient for the objective, and one function value and one Jacobian
for the constraints. In contrast, Algorithm 2 generates two independent samples,
and evaluates two gradients and one Hessian for the objective, one function
value, one Jacobian, and one Hessian for the constraints. Thus, Algorithm 2
is at least twice as expensive as [3]. The additional cost arises from the usage
of the augmented Lagrangian merit function; we note that Newton’s system
(9) contains second-order information that is not involved in [3]. Requiring the
Hessian information is a drawback of using the augmented Lagrangian if only
global convergence is of interest. The independence between estimating the
gradient and Hessian is not ideal, but common in the literature [8].

The basic design of Algorithm 2 is not as practical as [3], since the stepsize
sequence {αk}k is prespeciﬁed without any adjustment based on the iterate.
[3] designed a novel scheme for selecting the stepsize, which introduces certain
adaptivity into the StoSQP algorithm without relying on the line search. How-
ever, that scheme still requires another prespeciﬁed sequence {βk}k to control
the stepsize. As revealed in experiments in Section 5, Algorithm 2 with a simple
setup of αk may outperform [3] in some cases, especially when αk, βk are decay-
ing. This observation suggests that the prespeciﬁed sequence in both algorithms
highly aﬀects the performance.

This paper addresses the adaptivity under a diﬀerent, more restrictive setup.
We suppose that the estimation variance can be diminished by generating more
samples; and this setup allows us to adopt (natural) stochastic line search to
select the stepsize. Before designing an adaptive StoSQP, we establish the global
“almost sure” convergence of Algorithm 2. The “almost sure” type of convergence
guarantee is consistent with our later analysis of adaptive StoSQP, and diﬀers
from [3], which established the convergence in expectation.

3.1 Convergence Analysis

We show the convergence of Algorithm 2 for two diﬀerent stepsize sequences: a
constant sequence and a decaying sequence. We need the following assumptions.

Assumption 1 The iterates (xk, λk) and trial points (xk + αk ¯∆xk, λk +
αk ¯∆λk) are contained in a convex compact set X ×Λ. The functions f and c are
thrice continuously diﬀerentiable over X ; and the Jacobian G(x) = ∇T c(x) has
full row rank over X . The sequence {Bk}k satisﬁes xT Bkx ≥ γRH (cid:107)x(cid:107)2 for any
x ∈ {x : Gkx = 0, x (cid:54)= 0}, and (cid:107)Bk(cid:107) ≤ κB for constants 0 < γRH ≤ 1 ≤ κB.

1The implicit cost for deriving Lipschitz constants sequence in [3] is not counted here,

which, however, requires non-negligible evaluations for the objective and constraints.

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

11

Assumption 2 We assume ∇f (xk; ξ) and ∇2f (xk; ξ) are unbiased estimators
of ∇fk and ∇2fk with bounded variance. That is, for a constant ψ > 0,

Eξ[(cid:107)∇f (xk; ξ) − ∇fk(cid:107)2] ≤ ψ,
Eξ[∇f (xk; ξ)] =∇fk,
Eξ[∇2f (xk; ξ)] =∇2fk, Eξ[(cid:107)∇2f (xk; ξ) − ∇2fk(cid:107)2] ≤ ψ.

(11)

Assumption 1 is standard in SQP literature [4, 30]. In particular, the convex
compactness condition, as assumed, for example, in [30, Theorem 18.3] and [4,
Proposition 4.15], ensures that all continuous functions such as Lµ,ν, f , c are
bounded over X ×Λ (or over X ); and a linear combination of two iterates still lies
in the set. We note that [3] assumed a convex open set, while the boundedness
of f , c was assumed additionally. We prefer to assume a compact set, which is
more common for studying exact augmented Lagrangian [34], [4, Chapter 4.3].
We also assume f, c are thrice continuously diﬀerentiable. This is standard
in the literature on augmented Lagrangian (cf. [4, Proposition 4.16] and [34,
Section 3]), since the third derivatives are needed for the existence of the Hessian
∇2Lµ,ν. This condition ensures that the second-order Taylor expansion of Lµ,ν
is valid and ∇2Lµ,ν is continuous and hence bounded in X × Λ. It can be
replaced by assuming Lipschitz continuity on ∇Lµ,ν, equivalently, on ∇2f and
∇2c, which is stronger than [3] where Lipschitz continuity on ∇f and ∇c was
assumed. Fortunately, the third derivatives are required only for the analysis,
and never computed in the implementation.

We also assume that the Jacobian G(x) has full row rank, and Bk is positive
deﬁnite in the null space of Gk. These conditions are same as [3] and other SQP
literature [25], and ensure that matrices in (9) are invertible (cf. [30, Lemma
16.1]). Thus, Algorithm 2 is well-posed. The range of positive constants γRH ,
κB (and also the range of other positive constants deﬁned later) is not crucial
to the analysis; all results hold by replacing γRH by γRH ∧ 1 and κB by κB ∨ 1
if we enforce γRH , κB > 0 only.

Assumption 2 assumes that the gradient and Hessian estimators have bounded
variance, which is similar to the fully stochastic setup in [3], although, [3] only re-
quired a gradient estimator. We need a Hessian estimator since (9) contains
the second-order information.

An immediate implication of Assumption 1 is that there exist multiple posi-
xc ∧ κν ∧ κLµ,ν ∧ κM such that

tive constants 0 < κ1,G ≤ 1 ≤ κ2,G ∧ κ∇xL ∧ κ∇2

κ1,GI (cid:22) GkGT

k (cid:22) κ2,GI,

(cid:107)∇xLk(cid:107) ≤ κ∇xL,

m
(cid:88)
(

(cid:107)∇2ci(xk)(cid:107)2)

1

2 ≤ κ∇2

xc,

sup
X ×Λ

(cid:13)
(cid:13)∇2Lµ,ν

(cid:13)
(cid:13) ≤ κLµ,ν := µ · sup
X

(cid:13)∇ (cid:0)GT c(cid:1)(cid:13)
(cid:13)

i=1
(cid:13) + κν,

(cid:107)Mk(cid:107) ≤ κM .

(12)

Here, κLµ,ν is a uniform bound of the Hessian ∇2Lµ,ν over X × Λ.

The following lemma characterizes the bias and variance of the stochastic

search direction ( ¯∆xk, ¯∆λk).

12

Na et al.

Lemma 1 Under Assumptions 1 and 2, there exists a constant Υ0 > 0 such that
(cid:18)∆xk
∆λk

g ,ξk
ξk
H

(cid:19)(cid:21)

=

(cid:19)

E

,

(cid:20)(cid:18) ¯∆xk
¯∆λk
(cid:34)(cid:13)
(cid:18) ¯∆xk
(cid:13)
(cid:13)
¯∆λk
(cid:13)

E

g ,ξk
ξk
H

2(cid:35)

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

≤ Υ0

(cid:32)(cid:13)
(cid:18)∆xk
(cid:13)
(cid:13)
∆λk
(cid:13)

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

(cid:33)

+ ψ

.

Proof See Appendix A.1.

(cid:117)(cid:116)

Using Lemma 1, we are able to show the global convergence of Algorithm 2.
We streamline the analysis procedure. For any penalty parameters µ, ν > 0, we
apply Taylor’s expansion and have
(cid:18) ∇xLk
∇λLk

(cid:19)T (cid:16) ¯∆xk
¯∆λk

(cid:13)
(cid:16) ¯∆xk
(cid:13)
(cid:13)
¯∆λk

µ,ν ≤ Lk

µ,ν + αk

(cid:17)(cid:13)
2
(cid:13)
(cid:13)

Lk+1

κLµ,ν α2
k
2

+

(cid:17)

µ,ν

µ,ν

.

Taking conditional expectation over randomness in ξk

g , ξk

H and applying Lemma 1,

E

g ,ξk
ξk
H

[Lk+1

µ,ν ] ≤ Lk

µ,ν + αk

(cid:18) ∇xLk
∇λLk

µ,ν

µ,ν

(cid:19)T

(cid:0) ∆xk
∆λk

(cid:1) +

Υ0κLµ,ν α2
k
2

(cid:8) (cid:13)
(cid:13)

(cid:0) ∆xk
∆λk

(cid:1)(cid:13)
2
(cid:13)

+ ψ(cid:9).

(13)
In principle, the middle term on the right hand side provides a suﬃcient descent,
while the last term leads to a higher-order error if the stepsize is small enough
(since it depends on the stepsize quadratically). In particular, by direct calcu-
lation (as rigorously proved in Appendix A.2),
(cid:18) ∇xLk
∇λLk

(cid:1) = (∆xk)T ∇xLk − µ(cid:107)ck(cid:107)2 + cT

k ∆λk − ν(cid:107)Gk∇xLk(cid:107)2. (14)

(cid:0) ∆xk
∆λk

(cid:19)T

µ,ν

µ,ν

Then, by [25, Proposition 4.2], there exist a threshold ˜µ > 0 and a constant
˜δ > 0, such that if µ ≥ ˜µ,
(cid:18) ∇xLk
∇λLk

(cid:1) ≤ −˜δ (cid:13)
(cid:13)

(cid:0) ∆xk
∆λk

(cid:0) ∆xk

Gk∇xLk

(cid:1)(cid:13)
2
(cid:13)

(cid:19)T

µ,ν

.

µ,ν

Further, by the system (5), we can show (as rigorously proved in Appendix A.2)

(cid:13)
(cid:13)

(cid:0) ∆xk
∆λk

(cid:1)(cid:13)
2
(cid:13)

≤

3κ2
M
κ2

1,G

(cid:13)
(cid:13)

(cid:0) ∆xk

Gk∇xLk

(cid:1)(cid:13)
2
(cid:13)

.

Plugging the above two displays into (13), we further obtain

E

g ,ξk
ξk
H

[Lk+1

µ,ν ] ≤ Lk

µ,ν − αk

(cid:8)˜δ −

3Υ0κLµ,ν κ2
M
2κ2

1,G

αk

(cid:9) (cid:13)
(cid:13)

(cid:0) ∆xk

Gk∇xLk

(cid:1)(cid:13)
2
(cid:13)

+

Υ0κLµ,ν ψ
2

α2
k

≤ Lk

µ,ν −

˜δ

αk
2

(cid:13)
(cid:13)

(cid:0) ∆xk

Gk∇xLk

(cid:1)(cid:13)
2
(cid:13)

+

Υ0κLµ,ν ψ
2

α2
k.

(if αk ≤

˜δκ2
3Υ0κLµ,ν κ2
M

1,G

)

(15)

With this recursion, we apply a supermartingale argument [17, Theorem 4.2.12]
and have the following result. A similar supermartingale technique has been
used in [44, 13] for analyzing diﬀerent stochastic algorithms.

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

13

Theorem 1 (Global convergence of Algorithm 2) Consider Algorithm 2
under Assumptions 1 and 2. There exist positive constants ˜µ, ˜δ > 0, such that
, ∀k ≥ 0, where Υ0 > 0 is from Lemma 1, then
if µ ≥ ˜µ and αk ≤
we have the following two cases.
(a) If αk = α is a constant sequence, then

˜δκ2
3Υ0κLµ,ν κ2
M

1,G

1
K + 1

K
(cid:88)

k=0

E[(cid:107)∇Lk(cid:107)2] ≤

(cid:32)

2(κ2

B + κ2,G)
˜δκ1,G

L0

µ,ν − minX ×Λ Lµ,ν
(K + 1)α

+

Υ0κLµ,ν ψ
2

α

(cid:33)

(b) If αk is a decaying sequence with (cid:80)∞

k=0 αk = ∞, and (cid:80)∞

k=0 α2

k < ∞, then

lim
K→∞

1
(cid:80)K
k=0 αk

K
(cid:88)

k=0

αk(cid:107)∇Lk(cid:107)2 = 0

almost surely.

Furthermore, lim inf k→∞ (cid:107)∇Lk(cid:107) = 0 almost surely.

Proof See Appendix A.2.

(cid:117)(cid:116)

Theorem 1(b) diﬀers from [3, Corollary 3.14(b)], where the authors showed
the “liminf” convergence of the expected KKT residual E[(cid:107)∇Lk(cid:107)]. Our “almost
sure” convergence result suggests that, in each run of the algorithm, the KKT
residual sequence {(cid:107)∇Lk(cid:107)}k contains a convergent subsequence. Diﬀerently, the
convergence in expectation suggests that, the average of the KKT residual
sequence {(cid:107)∇Lk(cid:107)}k across multiple runs contains a convergent subsequence.
Our “almost sure” convergence is achieved by using a supermartingale argument
[17, Theorem 4.2.12], which states that a positive supermartingale converges
almost surely. The convergence in expectation can also be established for
Algorithm 2, by analogy to the analysis in [3].

As commented earlier, the design of Algorithm 2 is impractical due to the
lack of adaptivity of the stepsize: a whole stepsize sequence has to be speci-
ﬁed without any adjustment based on the iterate, with an unknown stepsize
upper bound being tuned manually. [3] introduced a novel stepsize selection
scheme to resolve this limitation and introduce certain adaptivity into the
method. However, that scheme requires another prespeciﬁed sequence {βk}k
to control the stepsize, which still highly aﬀects the performance as revealed
in our experiments. This paper resolves the limitation from a diﬀerent angle
in Section 4. In particular, we incorporate a (stochastic) line search step into
SQP, to make the resulting algorithm more adaptive than Algorithm 2 and [3];
although such enhancement requires a more precise model approximation.

4 An Adaptive Stochastic SQP

We now develop an adaptive StoSQP scheme. We embed a stochastic line search
procedure into our SQP framework. Unlike the scheme in Section 3, the stepsize
in this section is stochastic.

14

Na et al.

The stochastic line search procedure replaces inaccessible quantities in (7),
Lµ,ν and ∇Lµ,ν, by their stochastic estimates, ¯Lµ,ν and ¯∇Lµ,ν. This results in
three main challenges. First, the stochastic merit function ¯Lµ,ν is a random func-
tion. Its decrease in each iteration may not accumulate, as ¯Lµ,ν depends on the
particular realization of ξ that varies with k. Second, a bad estimate of Lµ,ν or
∇Lµ,ν may cause αk to become arbitrarily small. As a result, αk does not have a
uniform lower bound, which, however, is critical for global analysis in determin-
istic setting. Finally, even if the Armijo condition (7) is satisﬁed for a stochastic
function, the objective in expectation may be arbitrarily large and the value of
Lµ,ν may actually increase. [31] resolved these technical challenges for uncon-
strained problems by combining approaches of [6] and [11]. In principle, one
requires a suﬃciently accurate model in the line search step to ensure the valid-
ity of the selected random stepsize. In other words, the line search adaptivity is
achieved by drawing more samples in each iteration. While this might not seem
ideal, it is standard in the design of other adaptive algorithms [18, 10, 24, 15, 7].
We generalize the line search scheme of [31] to equality-constrained problems
under constraint qualiﬁcations. There are two additional challenges. First, we
have to adaptively select the penalty parameter in the algorithm. Without con-
straints, the Armijo condition uses the objective function, and there are no extra
parameters. With constraints, the search direction is a descent direction of Lµ,ν
only if µ is large enough. In stochastic case, the selected µ is a random quantity
that induces a random walk. We need to ensure that the random walk enjoys a
similar property to that in deterministic case, that is, µ stabilizes after a number
of iterations. Second, for unconstrained problems, if the Armijo condition is
satisﬁed for f in each iteration, then the iterates converge to a stationary point
of f , that is (cid:107)∇fk(cid:107) → 0. However, we utilize a merit function in the line search
for constrained problems. The stationary point of Lµ,ν is not necessarily a
KKT point of the original problem (1), unless µ is greater than an unknown
deterministic threshold such that the square matrix in (4) is invertible. In
stochastic case, the stabilized value of µ is random and varies in each run. Thus,
it is diﬃcult to enforce the stabilized µ to be always above the deterministic
threshold.

To resolve the ﬁrst challenge, we adopt a similar While loop to Algorithm 1,
and iteratively increase µ until the projection of the search direction on the
gradient of the merit function yields a suﬃcient descent on the merit function.
To resolve the second challenge, we further adjust the While loop condition to
impose a diﬀerent, but more stringent condition on µ. Our adjustment is inspired
by the following critical observation.

Proposition 1 For any point (x, λ) and penalty parameters (µ, ν) with ν (cid:54)= 0,
if G(x)GT (x) is non-singular, then (cid:107)c(x)(cid:107) = (cid:107)∇Lµ,ν(x, λ)(cid:107) = 0 implies
(cid:107)∇L(x, λ)(cid:107) = 0.

Proof We suppress the evaluation point for simplicity. It suﬃces to show that
(cid:107)∇xL(cid:107) = 0. By the deﬁnition of ∇λLµ,ν in (4), since ∇λLµ,ν = 0 and c(x) = 0,
we know that

νGGT G∇xL = 0,

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

15

which implies G∇xL = 0. Combining this result with ∇xLµ,ν = 0, we obtain
(cid:117)(cid:116)
∇xL = 0, and complete the proof.

µ,ν(cid:107), so that the convergence of (cid:107)∇Lk

By Proposition 1, we notice that any stationary point of the merit function
that is feasible is a KKT point of (1). The signiﬁcance of Proposition 1 is that
there is no requirement on the penalty parameter µ. Thus, instead of investigat-
ing if µ is above the threshold or not like [3, Proposition 3.16, Example 3.17],
we can be more selective to which stationary point we converge. In particular,
we can converge to a stationary point that is also feasible. We can achieve this
goal by enforcing (cid:107)ck(cid:107) ≤ (cid:107)∇Lk
µ,ν(cid:107) implies
the convergence of (cid:107)ck(cid:107). In stochastic case, we instead enforce (cid:107)ck(cid:107) ≤ (cid:107) ¯∇Lk
µ,ν(cid:107),
where ¯∇Lk
µ,ν. As shown in Lemma 4, this condition is
achievable for suﬃciently large µ. We note that the condition (cid:107)ck(cid:107) ≤ (cid:107)∇Lk
µ,ν(cid:107)
has never been enforced in deterministic SQP, which converges globally even
without enforcing it (cf. [25, Theorem 4.1]). For StoSQP, [3] also did not impose
additional conditions on the feasibility error (cid:107)ck(cid:107). However, we realize that
having this additional and more stringent condition in the penalty parameter
selection in StoSQP is helpful (at least for our study), in the sense that the
condition imposed on the noise distribution in [3, Proposition 3.16], in order
to converge to a KKT point based on the merit function, is not required in our
analysis.

µ,ν is an estimate of ∇Lk

4.1 The StoSQP scheme

g to let it denote a set of independent realizations
g | is its size. We recall that ν > 0 is any ﬁxed penalty parameter.

We generalize the notation of ξk
of ξ, and |ξk
Given the k-th iterate (xk, λk, ¯αk, ¯(cid:15)k), the algorithm proceeds in four steps.
Step 1: Estimate the derivatives. We generate samples ξk

g and let

¯gk =

1
|ξk
g |

(cid:88)

ζ∈ξk
g

∇f (xk; ζ),

¯Hk =

1
|ξk
g |

(cid:88)

ζ∈ξk
g

∇2f (xk; ζ).

(16)

We compute ¯∇xLk, ¯∇2
xLk, ¯Mk and ¯Tk as in (8). Diﬀerent from the estimation in
Section 3, we do not require ¯gk and ¯Hk to be independent. For some constants
κgrad > 0, pgrad ∈ (0, 1) to be chosen later, we deﬁne the event

Ak =

(cid:26) (cid:13)
(cid:18)¯gk − ∇fk + ν (cid:0) ¯MkGk ¯∇xLk − MkGk∇xLk
(cid:13)
(cid:13)
(cid:13)

(cid:1)

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

νGkGT
k Gk (¯gk − ∇fk)
(cid:13)
(cid:18) ¯∇xLk + ν ¯MkGk ¯∇xLk + GT
(cid:13)
(cid:13)
(cid:13)

k Gk ¯∇xLk

νGkGT

≤ κgrad · ¯αk

k ck

(cid:27)

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

, (17)

for a monotonically increasing sequence |ξk

g | chosen so that

P (Ac

k | xk, λk) ≤ pgrad.

(18)

16

Na et al.

µ,ν such that (cid:107) ¯∇Lk

The event Ak contains all good estimates of ∇Lk
µ,ν(cid:107)
is small. We note that the diﬀerence ¯∇Lk
µ,ν is independent of µ, so
that we can generate samples to estimate the gradient before selecting µ. We
will show in Lemma 2 that (18) can be satisﬁed for suﬃciently large |ξk
Step 2: Select the penalty parameter. Given stochastic estimates ¯∇xLk
and ¯Mk, we generate Bk and compute ( ¯∆xk, ¯∆λk) by (9). Then, we select ¯µk
such that

µ,ν − ∇Lk

µ,ν − ∇Lk

g |.

(cid:18) ¯∇xLk
¯∇λLk

¯µk ,ν

¯µk ,ν

(cid:19)T (cid:16) ¯∆xk
¯∆λk

(cid:17)

≤ −

γRH ∧ ν
2

(cid:16)

(cid:13)
(cid:13)
(cid:13)

¯∆xk
Gk ¯∇xLk

(cid:17)(cid:13)
2
(cid:13)
(cid:13)

and (cid:107)ck(cid:107) ≤ (cid:107) ¯∇Lk

¯µk,ν(cid:107),

(19)
where γRH ∈ (0, 1] is the lower bound of Bk in the null space of Gk (cf. Assump-
tion 1), which is an input of our algorithm, and ¯∇Lk

¯µk,ν can be expressed as

(cid:18) ¯∇xLk
¯∇λLk

¯µk,ν

¯µk,ν

(cid:19)

=

(cid:18)(cid:0)I + ν ¯MkGk

(cid:1) ¯∇xLk + ¯µkGT
k Gk ¯∇xLk

k ck

ck + νGkGT

(cid:19)

.

(20)

The ﬁrst condition in (19) is similar to Line 4 in Algorithm 1, except that
we do not update δk but ﬁx it to be (γRH ∧ ν)/2 for simplicity. The second
condition is our adjustment introduced at the beginning of this section, which
is not required in Algorithm 1 but is critical in our StoSQP. This condition
bounds the feasibility error by the magnitude of the gradient of the augmented
Lagrangian, so that we could converge to a feasible stationary point as the
gradient vanishes, which is a KKT point as implied by Proposition 1. We will
show in Lemma 4 that both conditions in (19) can be satisﬁed for suﬃciently
large ¯µk. Note that the other penalty parameter ν > 0 is an input of our
algorithm and need not to be updated with iteration.
Step 3: Estimate the merit function. Given the selected ¯µk from Step 2,
we estimate the merit function that is used in the line search step. Recall that
¯αk is from the (k − 1)-th step. We let xsk = xk + ¯αk ¯∆xk (similar for λsk ) be
the test point, and let csk = c(xsk ), Gsk = G(xsk ). We then generate a set of
independent realizations ξk

f and let

¯fk =

¯∇fk =

1
|ξk
f |

1
|ξk
f |

(cid:88)

ζ∈ξk
f
(cid:88)

ζ∈ξk
f

f (xk; ζ),

¯fsk =

∇f (xk; ζ),

¯∇fsk =

1
|ξk
f |

1
|ξk
f |

(cid:88)

ζ∈ξk
f
(cid:88)

ζ∈ξk
f

f (xsk ; ζ),

∇f (xsk ; ζ).

Note that we distinguish ¯∇fk from ¯gk in (16), although they are both estimates
of ∇fk. This simpliﬁes our analysis as the randomness in each step is indepen-
dent from other steps. Then, we let

¯µk,ν = ¯fk + cT
¯Lk

k λk +

¯µk,ν = ¯fsk + cT
¯Lsk
sk

λsk +

¯µk
2

ν
2
(cid:107)csk (cid:107)2 +

(cid:107)ck(cid:107)2 +
¯µk
2

(cid:107)Gk( ¯∇fk + GT

k λk)(cid:107)2,

ν
2

(cid:107)Gsk ( ¯∇fsk + GT
sk

λsk )(cid:107)2

(21)

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

17

be the estimates of Lk
be chosen later, we deﬁne the event

¯µk,ν and Lsk

¯µk,ν. For some constants κf > 0, pf ∈ (0, 1) to

(cid:26)

Bk =

(cid:12)
(cid:12) ¯Lk

¯µk,ν − Lk

¯µk,ν

(cid:12) ∨ (cid:12)
(cid:12)

(cid:12) ¯Lsk

¯µk,ν − Lsk

¯µk,ν

(cid:12)
(cid:12) ≤ −κf ¯α2
k

(cid:18) ¯∇xLk
¯∇λLk

¯µk,ν

¯µk,ν

(cid:19)T (cid:18) ¯∆xk
¯∆λk

(cid:19) (cid:27)
,

(22)

(23)

(24)

for |ξk

f | large enough so that

P (Bc

k | xk, λk, ¯∆xk, ¯∆λk) ≤ pf

and

E

ξk
f

[| ¯Lk

¯µk,ν − Lk

¯µk,ν|2] ∨ E

ξk
f

[| ¯Lsk

¯µk,ν − Lsk

¯µk,ν|2] ≤ ¯(cid:15)2
k.

Here ¯(cid:15)k is updated with the iteration. Again, we will show in Lemma 3 that
(23) and (24) can be satisﬁed for suﬃciently large |ξk
g , we
do not require |ξk
Step 4: Perform the line search step. Using the estimates deﬁned above,
we update the iterate based on whether the Armijo condition is satisﬁed.
(a) If the Armijo condition holds:

f | to be an increasing sequence.

f |. Diﬀerent from ξk

¯Lsk
¯µk,ν ≤ ¯Lk

¯µk,ν + ¯αkβ

(cid:18) ¯∇xLk
¯∇λLk

¯µk,ν

¯µk,ν

(cid:19)T (cid:18) ¯∆xk
¯∆λk

(cid:19)

,

(25)

then we let xk+1 = xsk , λk+1 = λsk and increase the stepsize by ¯αk+1 =
ρ¯αk ∧ αmax, with ρ > 1. Moreover, if we observe a suﬃcient decrease, that is,

−¯αkβ

(cid:18) ¯∇xLk
¯∇λLk

¯µk,ν

¯µk,ν

(cid:19)

(cid:19)T (cid:18) ¯∆xk
¯∆λk

≥ ¯(cid:15)k,

(26)

we then increase ¯(cid:15)k as ¯(cid:15)k+1 = ρ¯(cid:15)k, otherwise ¯(cid:15)k+1 = ¯(cid:15)k/ρ.
(b) If the Armijo condition (25) does not hold, we do not update the current
iterate and let xk+1 = xk, λk+1 = λk, and decrease the stepsize ¯αk by
¯αk+1 = ¯αk/ρ and ¯(cid:15)k by ¯(cid:15)k+1 = ¯(cid:15)k/ρ.

The four steps are summarized in Algorithm 3. Before delving into the

algorithm, we provide few remarks.

Remark 2 Our condition (24) simpliﬁes the condition of [31, (2.3)], which re-
quires the variance of the merit function estimates to be bounded by max{¯(cid:15)2
k, Tk}
for a term Tk that depends on the gradient ∇fk. As explained in [31, Remark 1],
Tk is unknown in stochastic optimization. Adding the term Tk is just to make
algorithm more ﬂexible, in case one has external knowledge of ∇fk. Our paper
does not assume the access to ∇fk; hence we remove Tk to make the condition
(24) checkable in practice.

Remark 3 Compared to [3] which generates a single sample in each iteration,
and Algorithm 2 which generates two samples, the line search StoSQP in Algo-
rithm 3 requires much more samples. Seeing from conditions (18), (23), and (24),
we require a more precise model estimation to make the selected stochastic

18

Na et al.

Algorithm 3 An Adaptive StoSQP with Exact Augmented Lagrangian
1: Input: initial iterate (x0, λ0), parameters γRH ∈ (0, 1], ¯α0 = αmax > 0, ν, ¯µ0, ¯(cid:15)0,

κgrad > 0, ρ > 1, pgrad, pf , β ∈ (0, 1), κf ∈ (0, β/4αmax];

2: for k = 0, 1, 2 . . . do
Generate ξk
3:

g and compute ¯∇xLk, ¯Mk, such that |ξk

g | ≥ |ξk−1

g

| + 1 (|ξ−1

g | = 0) and

P (Ac

k | xk, λk) ≤ pgrad;

4:

5:

6:
7:
8:

9:

10:

11:

12:

13:
14:
15:
16:
17:

18:

Generate Bk such that xT Bkx ≥ γRH (cid:107)x(cid:107)2, for any x ∈ {x : Gkx = 0, x (cid:54)= 0}, and

compute ( ¯∆xk, ¯∆λk) by solving (9);

(cid:19)T (cid:18) ¯∆xk
¯∆λk

(cid:19)

> − γRH ∧ν

2

(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:18) ¯∆xk
Gk

¯∇xLk

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

2

OR (cid:107)ck(cid:107) > (cid:107) ¯∇Lk

¯µk,ν (cid:107) do

while

(cid:18) ¯∇xLk
¯µk,ν
¯∇λLk
¯µk,ν
Let ¯µk = ρ¯µk;

end while
Generate ξk

f and compute ¯Lk

¯µk,ν and ¯Lsk

¯µk,ν , such that

E

ξk
f

[| ¯Lk

¯µk,ν − Lk

P (Bc
¯µk,ν |2] ∨ E

k | xk, λk, ¯∆xk, ¯∆λk) ≤pf ,
¯µk,ν − Lsk
¯µk,ν |2] ≤¯(cid:15)2
k;

[| ¯Lsk

ξk
f

if ¯Lsk

¯µk,ν ≤ ¯Lk
(cid:18)xk+1
λk+1

¯µk,ν + ¯αkβ
(cid:18)xk
λk

=

(cid:19)

Let

(cid:19)

(cid:18) ¯∇xLk
¯∇λLk

+ ¯αk

(cid:19)T (cid:18) ¯∆xk
¯∆λk

¯µk,ν
¯µk,ν
(cid:18) ¯∆xk
¯∆λk

(cid:19)
;

(cid:19)

then

(cid:46) Successful step

Set ¯αk+1 = αmax ∧ ρ ¯αk;
(cid:18) ¯∇xLk
¯∇λLk

¯µk,ν
¯µk,ν
Let ¯(cid:15)k+1 = ρ¯(cid:15)k;

if − ¯αkβ

(cid:19)T (cid:18) ¯∆xk
¯∆λk

(cid:19)

≥ ¯(cid:15)k then

else

Let ¯(cid:15)k+1 = ¯(cid:15)k/ρ;

end if

else

Let

(cid:19)

(cid:18)xk+1
λk+1

=

(cid:19)

(cid:18)xk
λk

, ¯αk+1 = ¯αk/ρ, ¯(cid:15)k+1 = ¯(cid:15)k/ρ;

(cid:46) Reliable step

(cid:46) Unreliable step

(cid:46) Unsuccessful step

19:
20:
21: end for

end if
¯µk+1 = ¯µk;

stepsize informative. The beneﬁt of generating more samples is that the line
search scheme is more adaptive than [3] and Algorithm 2, in the sense that no
prespeciﬁed sequence, which highly aﬀects the performance and determines the
convergence behavior, is required. As introduced earlier, achieving adaptivity
at the cost of sample complexity is common in the literature [18, 10, 24, 15, 7].
As part of the line search, Algorithm 3 has to evaluate the merit function for
checking the Armijo condition, which is not required for Algorithm 2, and also
for [3] if the Lipschitz constants of objective and constraints are given.

We also comment on the randomness of the iteration. Let F0 ⊆ F1 ⊆ F2 . . .
be a ﬁltration of σ-algebras where Fk is generated by {ξj
j=0. Let Fk−0.5 be
the σ-algebra generated by {ξj
g . We have Fk−1 ⊆ Fk−0.5 ⊆ Fk.
Finally, we let F−1 = σ(x0, λ0). By ¯µk we denote the quantity obtained after

j=0 ∪ ξk

g}k−1

f , ξj

f , ξj

g}k

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

19

the While loop in Line 5 of Algorithm 3. By the construction, it is easy to see

σ(xk, λk) ∪ σ(¯αk) ∪ σ(¯(cid:15)k) ⊆ Fk−1,

σ( ¯∆xk, ¯∆λk) ∪ σ(¯µk) ⊆ Fk−0.5,

∀k ≥ 0.

In particular, the ﬁltration Fk−1 contains all the randomness before the k-th
iteration in Line 3. In the k-th iteration, we ﬁrst generate ξk
g and obtain Fk−0.5.
Then, we compute the search direction ( ¯∆xk, ¯∆λk) and ¯µk. Finally, we generate
ξk
f and obtain Fk, allowing us to obtain (xk+1, λk+1).

In the line search step, which starts from Line 9 in Algorithm 3, ¯(cid:15)k charac-
terizes the reliability of the decrease we observe on the stochastic merit function.
In particular, each iteration is divided into a successful step (Armijo condition
is satisﬁed) or an unsuccessful step (Armijo condition is not satisﬁed). If the
step is successful, we further divide it into a reliable step or an unreliable step.
When the amount of decrease on the stochastic merit function is greater than
¯(cid:15)k, we classify it as a reliable step, because it reduces the deterministic merit
function with high probability as well. We then increase ¯(cid:15)k and require a less
accurate model in the next iteration (see (24)). When the observed decrease
is less than ¯(cid:15)k, we decrease ¯(cid:15)k, as we are not conﬁdent that the deterministic
merit function is decreased. Thus, we require a more accurate model in the
next iteration.

4.2 Well-posedness of Algorithm 3

We study the well-posedness of Algorithm 3 and show that each of its step can
be performed in ﬁnite time. We ﬁrst lay out the assumption.

Assumption 3 We assume that Assumption 1 holds for the iterates generated
by Algorithm 3. In particular, the iterates (xk, λk) and trial points (xsk , λsk )
are contained in a convex compact set X × Λ. The functions f and c are thrice
continuously diﬀerentiable over X ; and the Jacobian G(x) = ∇T c(x) has full
row rank over x ∈ X . The sequence {Bk}k satisﬁes xT Bkx ≥ γRH (cid:107)x(cid:107)2 for
any x ∈ {x : Gkx = 0, x (cid:54)= 0}, and (cid:107)Bk(cid:107) ≤ κB for constants 0 < γRH ≤ 1 ≤
κB. Furthermore, we assume (cid:107)∇Lk(cid:107) ∧ (cid:107)( ¯∆xk, ¯∆λk)(cid:107) > 0.

Note that (cid:107)∇Lk(cid:107)∧(cid:107)( ¯∆xk, ¯∆λk)(cid:107) > 0 is imposed only for analytical reasons.
It allows us to generate an inﬁnite sequence of iterates {(xk, λk)}k. A similar
condition can be found in (2.2) in [7]. We point out that a practical algorithm
should stop whenever (cid:107) ¯∇Lk(cid:107) ∧ (cid:107)( ¯∆xk, ¯∆λk)(cid:107) ≤ τ for a tolerance τ . By As-
sumption 3, bounds in (12) hold immediately. We also strengthen the bounded
variance condition in Assumption 2 to the following boundedness condition.

Assumption 4 We assume that, for any ξ ∼ P and x ∈ X , |f (x; ξ)−f (x)| ≤
Ω0, (cid:107)∇f (x; ξ) − ∇f (x)(cid:107) ≤ Ω1, and (cid:107)∇2f (x; ξ) − ∇2f (x)(cid:107) ≤ Ω2 for constants
Ω0, Ω1, Ω2 > 0.

We require Assumption 4 when applying (matrix) Bernstein concentration
inequality [43, Theorem 6.1.1], which is used for characterizing the batch sizes re-
quired to ensure conditions, (18), (23), and (24), on the model precision to hold.

20

Na et al.

Algorithm 4 Sample size selection
1: Input: initial |ξk
2: while True do
Generate |ξk
3:
if
4:

g | samples to compute ¯∇xLk and ¯Mk as in (8);

g |, known variables ¯αk, ck, Gk, κgrad, pgrad, d, ν, scalars ρ > 1, Cgrad > 0;

(cid:16) 4d

(cid:17)

pgrad

Cgrad log
(cid:18) ¯∇xLk + ν ¯MkGk
k Gk

νGkGT

¯∇xLk + GT
¯∇xLk

k ck

(27)

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

∧ 1

|ξk

g | <

grad · ¯α2
κ2
k

(cid:13)
(cid:13)
(cid:13)
(cid:13)

then

g | = ρ|ξk
g |;

|ξk

else

5:
6:
7:
8:
end if
9: end while

Break;

The same concentration result holds if random errors have sub-exponential tail.
See [42, Theorems 6.1 and 6.2] for deﬁnitions and details. Either condition on
the error is stronger than the bounded variance condition, which does not imply
an exponential tail in general. On the other hand, Assumption 4 is widely used
in subsampling analysis [41, 37]; and reasonably holds if iterates are bounded
(as assumed in Assumption 3) and we target a ﬁnite-sum problem. Assuming
that the gradient error is bounded is also required for ensuring the penalty
parameter to stabilize in [3, Proposition 3.18], and we obtain similar guarantee
in Lemma 4.

We are now ready for analyzing Algorithm 3. To show that Algorithm 3 is
well-posed, it suﬃces to show that the condition (18) in Line 3, the condition
(19) in Line 5, and the conditions (23) and (24) in Line 8 can be satisﬁed. We
study them in the next three lemmas.

Lemma 2 Under Assumptions 3 and 4, the condition (18) can be satisﬁed us-
ing Algorithm 4 with a large enough constant Cgrad. Moreover, Algorithm 4
terminates in ﬁnite time.

Proof Let Pξk
in ξk
g . We have

g

(·) = P (· | xk, λk) be the conditional probability over randomness

(cid:13)
(cid:18)¯gk − ∇fk + ν (cid:0) ¯MkGk ¯∇xLk − MkGk∇xLk
(cid:13)
(cid:13)
(cid:13)

(cid:1)

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

≤

(cid:18)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

νGkGT

νGkGT
¯gk − ∇fk
k Gk (¯gk − ∇fk)

k Gk (¯gk − ∇fk)
+ ν (cid:13)

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:13) ¯MkGk ¯∇xLk − MkGk∇xLk

(cid:13)
(cid:13)

(12)
≤ (1 + νκ3/2

2,G) (cid:107)¯gk − ∇fk(cid:107) + νκ1/2

2,G

(cid:0)(cid:107) ¯Mk − Mk(cid:107)(cid:107)¯gk − ∇fk(cid:107) + κ∇xL(cid:107) ¯Mk − Mk(cid:107)

+ κM (cid:107)¯gk − ∇fk(cid:107)(cid:1)
2,G + νκ1/2

= (1 + νκ3/2

2,GκM )(cid:107)¯gk − ∇fk(cid:107) + νκ1/2

2,G ((cid:107)¯gk − ∇fk(cid:107) + κ∇xL) (cid:107) ¯Mk − Mk(cid:107).

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

21

Moreover, we have

(cid:107) ¯Mk − Mk(cid:107)

√

√

(8)
≤

(8)
≤

κ2,G(cid:107) ¯Hk − ∇2fk(cid:107) + (cid:107) ¯Tk − Tk(cid:107)

κ2,G(cid:107) ¯Hk − ∇2fk(cid:107) + {(cid:107)¯gk − ∇fk(cid:107)2

m
(cid:88)

i=1

(cid:107)∇2ci(xk)(cid:107)2}1/2

√

(12)
≤

κ2,G(cid:107) ¯Hk − ∇2fk(cid:107) + κ∇2

xc · (cid:107)¯gk − ∇fk(cid:107).

(28)

Combining the above two displays, we obtain

(cid:18)¯gk − ∇fk + ν (cid:0) ¯MkGk ¯∇xLk − MkGk∇xLk

(cid:13)
(cid:13)
(cid:13)
(cid:13)
≤ (cid:8)1 + νκ3/2

νGkGT
2,G + νκ1/2

k Gk (¯gk − ∇fk)
2,GκM + νκ1/2

(cid:1)

(cid:19) (cid:13)
(cid:13)
(cid:13)
(cid:13)

2,Gκ∇2

xc ((cid:107)¯gk − ∇fk(cid:107) + κ∇xL) (cid:9)(cid:107)¯gk − ∇fk(cid:107)
(29)

+ νκ2,G ((cid:107)¯gk − ∇fk(cid:107) + κ∇xL) (cid:107) ¯Hk − ∇2fk(cid:107).

Let us denote

tk = κgrad · ¯αk

(cid:13)
(cid:18) ¯∇xLk + ν ¯MkGk ¯∇xLk + GT
(cid:13)
(cid:13)
(cid:13)

k Gk ¯∇xLk

νGkGT

k ck

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

,

then the above display implies that Ak happens by requiring

(cid:107)¯gk − ∇fk(cid:107) ≤

(cid:107) ¯Hk − ∇2fk(cid:107) ≤

tk ∧ 1

2,GκM + 2νκ1/2

2,Gκ∇xLκ∇2

xc)

2(1 + νκ3/2
tk
4νκ2,Gκ∇xL

2,G + νκ1/2
=: tk
2.

=: tk
1,

By Assumption 4, we apply Bernstein inequality [43, Theorem 6.1.1] and have

Pξk

g

(cid:0)(cid:107)¯gk − ∇fk(cid:107) ≤ tk

1

(cid:1) ≥ 1 −

Pξk

g

(cid:0)(cid:107) ¯Hk − ∇2fk(cid:107) ≤ tk

2

(cid:1) ≥ 1 −

pgrad
2
pgrad
2

,

,

if

if

|ξk

g | ≥

|ξk

g | ≥

4Ω2
1
(tk
1)2
4Ω2
2
(tk
2)2

log

log

(cid:18) 4d
pgrad
(cid:18) 4d
pgrad

(cid:19)

(cid:19)

,

.

Plugging the deﬁnitions of tk
(cf. (12)), we know Pξk

(Ac

g

k) ≤ pgrad provided

1 and tk

2 and using the fact that κ2,G ∧ κ∇2

xc ≥ 1

|ξk

g | ≥

Cgrad log

(cid:17)

(cid:16) 4d
pgrad

t2
k ∧ 1

(30)

with Cgrad = 16 max{Ω1, Ω2}2{1+νκ3/2
above condition (30) is consistent with (27) in Algorithm 4.

2,G +νκ1/2

2,GκM +2νκ2,Gκ∇xLκ∇2

xc}2. The

To complete the proof, we have to show that (30) can be satisﬁed by Al-
gorithm 4 and Algorithm 4 terminates in ﬁnite time. This is not immediate,
as the right hand side depends on ξk
g | increases, the

g as well. Intuitively, as |ξk

22

Na et al.

right hand side term will approach a ﬁxed quantity with nonzero denominator,
so that (30) can be satisﬁed ﬁnally. Let us deﬁne

t(cid:63)
k = κgrad · ¯αk

(cid:13)
(cid:18)∇xLk + νMkGk∇xLk + GT
(cid:13)
(cid:13)
(cid:13)

k Gk∇xLk

νGkGT

k ck

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

.

By Assumption 3, we have t(cid:63)
k Gk∇xLk(cid:107) = 0 and thus
(cid:107)Gk∇xLk(cid:107) = 0. Then 0 = Gk(∇xLk + νMkGk∇xLk + GT
k ck) = GkGT
k ck and
thus ck = 0. Finally, ∇xLk = 0 and ∇Lk = 0, which contradicts (cid:107)∇Lk(cid:107) > 0
in Assumption 3. Moreover, we have

k > 0. Otherwise, (cid:107)νGkGT

|tk − t(cid:63)

k| ≤ κgrad · ¯αk

(cid:13)
(cid:18)¯gk − ∇fk + ν (cid:0) ¯MkGk ¯∇xLk − MkGk∇xLk
(cid:13)
(cid:13)
(cid:13)

k Gk (¯gk − ∇fk)

νGkGT

(cid:1)

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

. (31)

Similar to the sample complexity shown in (30), we let the right hand side of
(31) be bounded by t(cid:63)

k/2, that is
(cid:13)
(cid:18)¯gk − ∇fk + ν (cid:0) ¯MkGk ¯∇xLk − MkGk∇xLk(cid:1)
(cid:13)
(cid:13)
(cid:13)

k Gk (¯gk − ∇fk)

νGkGT

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

≤

1
2

(cid:13)
(cid:18)∇xLk + νMkGk∇xLk + GT
(cid:13)
(cid:13)
(cid:13)

k Gk∇xLk.

νGkGT

k ck

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

=

t(cid:63)
k
2κgrad ¯αk

.

Replacing tk in the denominator of (30) by the right hand side term of the
above display, we know that

Pξk

g

provided

(|tk − t(cid:63)

k| ≤ t(cid:63)

k/2) ≥ 0.99

|ξk

g | ≥

4κ2

grad ¯α2
(t(cid:63)

kCgrad log (cid:0) 4d

0.01

k)2 ∧ 4κ2

grad ¯α2
k

(cid:1)

.

(32)

(33)

Under the event (32), we have tk ≥ t(cid:63)
implied by

k/2 > 0, and hence the condition (30) is

|ξk

g | ≥

(cid:17)

(cid:16) 4d
pgrad

.

4Cgrad log
(t(cid:63)

k)2 ∧ 4

Finally, combining the above display with (33), we know that (30) holds with
a nonzero denominator with probability at least 0.99 as long as

|ξk

g | ≥

grad ¯α2
4Cgrad(κ2
k)2 ∧ 4κ2
(t(cid:63)

k ∨ 1) log
grad ¯α2

k ∧ 4

(cid:16)

4d
pgrad∧0.01

(cid:17)

.

(34)

Note that the right hand side term is a deterministic quantity conditional on
(xk, λk). Since Algorithm 4 increases |ξk
g | by a factor of ρ in each iteration, the
above requirement will ﬁnally be satisﬁed. After |ξk
g | exceeds the right hand
side threshold, (30) (i.e. (27) in Algorithm 4) is satisﬁed with probability at
least 0.99 in each While loop iteration. Thus, the While loop will stop in ﬁnite
(cid:117)(cid:116)
time with probability one. This completes the proof.

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

23

As shown in (27), the sample complexity |ξk

g | depends on a tuning parameter
Cgrad. This dependence seems unavoidable and appears in diﬀerent forms in [7,
31]. The expression of Cgrad is provided after (30). Fortunately, noting that the
denominator in (27) is bounded by (cid:107) ¯∇Lk(cid:107)2 which, as the estimate of (cid:107)∇Lk(cid:107)2,
should be close to zero when k is large, the eﬀect of the tuning parameter
Cgrad is negligible. The sample complexity is proportional to the reciprocal of
the square of the gradient, which is also standard in the literature [31].

In addition, we note that the right-hand side term of (27) is computed by the
generated samples ξk
g . As we showed in (34), there is a deterministic (conditional
on Fk−1) threshold on |ξk
g | is above the threshold, then the
inequality (27) on |ξk
g | does not hold with high probability. Thus, the While loop
in Algorithm 4 always terminates in ﬁnite time (with probability one). In the
implementation, if we encounter a rare situation where the denominator in (27)
is zero, we can just keep increasing |ξk
g | by Line 5. As we proved (cf. statement
before (31)), the denominator is ﬁnally nonzero since

g | such that, if |ξk

(cid:16) ¯∇xLk+ν ¯MkGk ¯∇xLk+GT

k ck

νGkGT

k Gk ¯∇xLk

(cid:17) |ξk

g |→∞
−→

(cid:16) ∇xLk+νMkGk∇xLk+GT

k ck

νGkGT

k Gk∇xLk

(cid:17)

(cid:54)= 0.

The following result shows that the conditions (23) and (24) can be satisﬁed.
The analysis follows the same structure as the one in Lemma 2, and applies
Bernstein inequality [43, Theorem 6.1.1]. We defer the proof to the appendix.

Lemma 3 Under Assumptions 3 and 4, the conditions (23) and (24) are
satisﬁed if

|ξk

f | ≥

(cid:40)

κf ¯α2
k

Cf log

(cid:17)

(cid:16) 8d
pf
(cid:19)T (cid:18) ¯∆xk
¯∆λk

(cid:18) ¯∇xLk
¯∇λLk

¯µk,ν

¯µk,ν

for a large enough constant Cf .

Proof See Appendix B.1.

(cid:19)(cid:41)2

∧ ¯(cid:15)2

k ∧ 1

(35)

(cid:117)(cid:116)

Unlike Lemma 2, the denominator in (35) is computable given Fk−0.5. As
a result, there is no need to apply a While loop to ﬁnd ξk
f iteratively, as we did
in Algorithm 4 for ξk
g . The tuning parameter Cf is similar to Cgrad in Lemma
2 and has an ignorable eﬀect on performance due to the small magnitude of the
denominator. The expression of Cf is provided after (B.4). Again, we should
emphasize that the denominator in (35) is nonzero. Otherwise, by (19) we
know ¯∆xk = 0 and Gk ¯∇xLk = 0. Then, by (9) we know ¯∆λk = 0, which
contradicts (cid:107)( ¯∆xk, ¯∆λk)(cid:107) > 0 in Assumption 3.

The last result of this subsection shows that the condition (19) on ¯µk can be
satisﬁed, so that the While loop in Line 5 of Algorithm 3 will stop in ﬁnite time.
Furthermore, like in deterministic SQP in Algorithm 1, ¯µk will stabilize after a
number of iterations.

24

Na et al.

Lemma 4 Under Assumptions 3 and 4, the condition (19) can be satisﬁed by
the While loop in Line 5 of Algorithm 3. Furthermore, there exists a determin-
istic constant ˜µ > 0 such that ¯µk = ¯µ ¯K ≤ ˜µ, ∀k ≥ ¯K for some ¯K < ∞.

Proof It suﬃces to show that (19) is satisﬁed if ¯µk is suﬃciently large, and
the threshold has a deterministic upper bound that is independent of k. By
analogy to (14), we have from Newton’s system (9) that

(cid:18) ¯∇xLk
¯∇λLk

¯µk,ν

¯µk,ν

(cid:19)

(cid:19)T (cid:18) ¯∆xk
¯∆λk

(14)
= ( ¯∆xk)T ¯∇xLk + cT
k
(9)
= −( ¯∆xk)T Bk ¯∆xk + cT

¯∆λk − ¯µk(cid:107)ck(cid:107)2 − ν(cid:107)Gk ¯∇xLk(cid:107)2

k ( ¯∆λk + ˜∆λk) − ¯µk(cid:107)ck(cid:107)2 − ν(cid:107)Gk ¯∇xLk(cid:107)2.

Let ¯∆xk = ¯∆uk + ¯∆vk with ¯∆uk ∈ Image(GT

k ) and Gk ¯∆vk = 0, then

(cid:19)

¯µk,ν

(cid:19)T (cid:18) ¯∆xk
¯∆λk

(cid:18) ¯∇xLk
¯∇λLk
= −( ¯∆vk)T Bk ¯∆vk − 2( ¯∆vk)T Bk ¯∆uk − ( ¯∆uk)T Bk ¯∆uk + cT

¯µk,ν

k ( ¯∆λk + ˜∆λk)

− ¯µk(cid:107)ck(cid:107)2 − ν(cid:107)Gk ¯∇xLk(cid:107)2
(cid:13)
2
(cid:13)
− ¯µk(cid:107)ck(cid:107)2 − ν(cid:107)Gk ¯∇xLk(cid:107)2.

(cid:13)
(cid:13) ¯∆vk

≤ −γRH

+ 2(cid:107) ¯∆vk(cid:107)(cid:107)Bk ¯∆uk(cid:107) − ( ¯∆uk)T Bk ¯∆uk + cT

k ( ¯∆λk + ˜∆λk)

Using the fact that 2 (cid:13)
(cid:13) ¯∆vk
and (cid:107) ¯∆xk(cid:107)2 = (cid:107) ¯∆vk(cid:107)2 + (cid:107) ¯∆uk(cid:107)2, we further have

(cid:13)
(cid:13)Bk ¯∆uk

(cid:13)
(cid:13)

(cid:13)
(cid:13) ≤ γRH (cid:107) ¯∆vk(cid:107)2/4 + 4(cid:107)Bk ¯∆uk(cid:107)2/γRH ,

(cid:18) ¯∇xLk
¯∇λLk

¯µk,ν

¯µk,ν
3γRH
4

(cid:19)

(cid:19)T (cid:18) ¯∆xk
¯∆λk

(cid:107) ¯∆vk(cid:107)2 + ( ¯∆uk)T

(cid:18) 4B2
k
γRH

(cid:19)

− Bk

¯∆uk + cT

k ( ¯∆λk + ˜∆λk)

≤ −

− ¯µk(cid:107)ck(cid:107)2 − ν(cid:107)Gk ¯∇xLk(cid:107)2

= −

3γRH
4

(cid:107) ¯∆xk(cid:107)2 + ( ¯∆uk)T

(cid:18) 4B2
k
γRH

+

3γRH
4

(cid:19)

I − Bk

¯∆uk + cT

k ( ¯∆λk + ˜∆λk)

− ¯µk(cid:107)ck(cid:107)2 − ν(cid:107)Gk ¯∇xLk(cid:107)2
(cid:19)(cid:13)
(cid:13)
(cid:18) ¯∆xk
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
Gk ¯∇xLk
(cid:13)
(cid:13)

γRH ∧ ν
2

≤ −

+ Dk,

where

Dk = ( ¯∆uk)T

(cid:18) 4B2
k
γRH

+

3γRH
4

I − Bk

−

γRH
4

(cid:19)

¯∆uk + cT

k ( ¯∆λk + ˜∆λk)
ν
2

(cid:107) ¯∆xk(cid:107)2 −

(cid:107)Gk ¯∇xLk(cid:107)2 − ¯µk(cid:107)ck(cid:107)2.

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

25

We now bound (cid:107) ¯∆uk(cid:107), (cid:107) ¯∆λk(cid:107), and (cid:107) ˜∆λk(cid:107). By (28) and Assumption 4, we have

(cid:107) ¯Mk(cid:107) ≤ (cid:107)Mk(cid:107)+(cid:107) ¯Mk −Mk(cid:107)

(28)
≤ (cid:107)Mk(cid:107)+

√

κ2,G(cid:107) ¯Hk −∇2fk(cid:107)+κ∇2

xc(cid:107)¯gk −∇fk(cid:107)

(12)
≤ κM + Ω2

√

κ2,G + Ω1κ∇2

xc =: κ ¯M .

(36)

Since ¯∆uk ∈ Image(GT
−GT

k (GkGT

k )−1ck. Thus, (cid:107) ¯∆uk(cid:107) ≤ (cid:107)ck(cid:107)/

√

k ) and Gk ¯∆vk = 0, using Gk ¯∆xk = −ck leads to ¯∆uk =

κ1,G. Furthermore,

(cid:107) ¯∆λk(cid:107)

(cid:107) ˜∆λk(cid:107)

(9)
= (cid:107)(GkGT

k )−1(Gk ¯∇xLk + ¯M T

k

¯∆xk)(cid:107) ≤

1
κ1,G

((cid:107)Gk ¯∇xLk(cid:107) + κ ¯M (cid:107) ¯∆xk(cid:107)),

(9)
= (cid:107)(GkGT

k )−1(Gk ¯∇xLk + GkBk ¯∆xk)(cid:107)
1
κ1,G

≤

((cid:107)Gk ¯∇xLk(cid:107) +

√

κ2,GκB(cid:107) ¯∆xk(cid:107)).

Using the above results and Assumption 3, we can bound Dk as

Dk ≤

(cid:26) 1
κ1,G
κ ¯M +

(cid:18) 4κ2
B
γRH
√

κ2,GκB

+

3γRH
4

(cid:19)

(cid:27)

+ κB

− ¯µk

(cid:107)ck(cid:107)2 +

(cid:107)ck(cid:107)(cid:107)Gk ¯∇xLk(cid:107)

(cid:107)ck(cid:107)(cid:107) ¯∆xk(cid:107) −

γRH
4

(cid:107) ¯∆xk(cid:107)2 −

(cid:107)Gk ¯∇xLk(cid:107)2

+

3γRH
4

(cid:19)

+ κB

+

2
νκ2

1,G

+

(κ ¯M +

κ2,GκB)2

γRH κ2

1,G

(cid:41)

− ¯µk

(cid:107)ck(cid:107)2

2
κ1,G
ν
2
√

κ1,G
(cid:18) 4κ2
B
γRH

1
κ1,G

6κ2
B
γRH κ1,G

+

+

(cid:40)

(cid:32)

(cid:32)

≤

≤

≤

√

2 + (κ ¯M +
κ2
1,G(γRH ∧ ν)

κ2,GκB)2

(cid:33)

− ¯µk

(cid:107)ck(cid:107)2

√

κ2,GκB)2

7(κ ¯M +
κ2
1,G(γRH ∧ ν)

(cid:33)

− ¯µk

(cid:107)ck(cid:107)2,

where the third inequality uses κB ≥ γRH , and the last inequality uses κM ∧
κ2,G ∧ κB ≥ 1. Thus, as long as

¯µk ≥

√

κ2,GκB)2

7(κ ¯M +
κ2
1,G(γRH ∧ ν)

=: ˜µ1/ρ,

(37)

we know Dk ≤ 0 and hence the ﬁrst condition in (19) holds.

We now check the second condition. We have

(cid:18) 1
ν

I + Gk ¯Mk

(cid:19)

(GkGT

¯µk,ν

I + Gk ¯Mk

k )−1 ¯∇λLk
(cid:18) 1
ν
(cid:18) 1
ν

I + Gk ¯Mk

(20)
=

(20)
=

(cid:19)

(cid:19)

(GkGT

k )−1ck + (cid:0)I + νGk ¯Mk

(cid:1) Gk ¯∇xLk

(GkGT

k )−1ck + Gk ¯∇xLk

¯µk,ν − ¯µkGkGT

k ck,

26

which implies

(cid:18)

¯µkGkGT

k −

(cid:19)

I + Gk ¯Mk

(cid:18) 1
ν

(GkGT

(cid:19)

k )−1
(cid:18) 1
ν

= Gk ¯∇xLk

¯µk,ν −

ck

(cid:19)

I + Gk ¯Mk

(GkGT

k )−1 ¯∇λLk

¯µk,ν

Na et al.

and, by (12) and (36),

(cid:18)

¯µkκ1,G −

1 + νκ ¯M

√

κ2,G

(cid:19)

κ1,Gν

(cid:107)ck(cid:107) ≤

√

1 + ν

κ2,G(κM + κ1,G)

κ1,Gν

Therefore, as long as

(cid:13)
(cid:18) ¯∇xLk
(cid:13)
(cid:13)
¯∇λLk
(cid:13)

¯µk,ν
¯µk,ν.

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

.

¯µk ≥

√

2 + 2ν

κ2,G(κM + κ1,G)

κ2
1,Gν

=: ˜µ2/ρ,

(38)

the second condition in (19) holds. Combining (37) and (38) together, we see
that if ¯µk ≥ (˜µ1 ∨ ˜µ2)/ρ, then (19) holds. Moreover, we see that the threshold
is independent of k. As Algorithm 3 increases ¯µk by a factor of ρ in each
while loop, there must exist ¯K < ∞ such that ¯µk = ¯µ ¯K for all k ≥ ¯K, and
¯µ ¯K ≤ ˜µ := ˜µ1 ∨ ˜µ2. This completes the proof.
(cid:117)(cid:116)

Lemma 4 suggests that, for each run of Algorithm 3, the merit function is
invariant after certain number of iterations. This property is critical for estab-
lishing global convergence. Since we always let k → ∞, we do not have to study
the iteration before ¯K. We note that the threshold ¯K is random, which might
be diﬀerent for each run. However, it must exist and be ﬁnite. A similar result
is shown in [3]. Finally, we note that ¯µ ¯K has a deterministic upper bound ˜µ.

4.3 Convergence analysis

Our convergence analysis is based on the potential function

¯µ ¯K ,ν,ω = ωLk
Φk

¯µ ¯K ,ν +

(1 − ω)
2

¯(cid:15)k +

(1 − ω)
2

¯αk(cid:107)∇Lk

¯µ ¯K ,ν(cid:107)2,

where ω ∈ (0, 1) is a deterministic parameter speciﬁed later. This function is a
¯µ ¯K ,ν(cid:107)2. Throughout the analysis,
linear combination of Lk
we condition on F ¯K and only study the iterates after ¯K iterations, where ¯K is
the iteration index determined in Lemma 4, after which µk stabilizes.

¯µ ¯K ,ν, ¯(cid:15)k, and ¯αk(cid:107)∇Lk

We begin by presenting a proposition that relates diﬀerent critical quan-
tities. We rely on these relations in later analysis. The results are shown by
straightforward calculations and the proofs are deferred to Appendix B.2.

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

27

Proposition 2 Under Assumptions 3 and 4, there exist constants {Υi}4
that are independent of parameters (αmax, β, κgrad, pgrad, κf , pf ) such that

i=1

(cid:13)
(cid:18) ¯∇xLk + ν ¯MkGk ¯∇xLk + GT
(cid:13)
(cid:13)
(cid:13)

k ck

νGkGT
(cid:13)
(cid:18) ¯∆xk
(cid:13)
(cid:13)
Gk ¯∇xLk
(cid:13)

Υ2

≤

k Gk ¯∇xLk
(cid:13)
(cid:19)(cid:13)
(cid:18) ¯∆xk
(cid:13)
(cid:13)
(cid:13)
(cid:13)
¯∆λk
(cid:13)
(cid:13)
(cid:13)
(cid:18) ¯∇xLk
(cid:13)
(cid:13)
¯∇λLk
(cid:13)

¯µ ¯K ,ν

¯µ ¯K ,ν

Proof See Appendix B.2.

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

≤ Υ1

≤ Υ3

≤ Υ4

(cid:13)
(cid:18) ¯∆xk
(cid:13)
(cid:13)
Gk ¯∇xLk
(cid:13)
(cid:13)
(cid:18) ¯∆xk
(cid:13)
(cid:13)
Gk ¯∇xLk
(cid:13)
(cid:13)
(cid:18) ¯∆xk
(cid:13)
(cid:13)
Gk ¯∇xLk
(cid:13)

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

,

,

.

(39)

(cid:117)(cid:116)

We emphasize that constants {Υi}4

i=1 (whose expressions are provided in the
appendix) are independent of probability parameters (pgrad, pf ). In Theorem
2, we impose a condition on pf , pgrad. Due to independence, the condition is
not an implicit function of pf , pgrad.

We have the following two lemmas, which connect the stochastic line search

with deterministic line search.

Lemma 5 For k ≥ ¯K, we suppose the event Ak ∩ Bk happens, where Ak is
deﬁned in (17) and Bk is deﬁned in (22). If

¯αk ≤

(1 − β)(γRH ∧ ν)
3 + κgradΥ1Υ3 + κf γRH )

2(κL ˜µ,ν Υ 2

,

where Υ1, Υ3 are given by Proposition 2 and κL ˜µ,ν is deﬁned in (12) with ˜µ
given by Lemma 4, then the k-th step is a successful step (i.e. the Armijo
condition is satisﬁed).

Proof Our proof resembles [31, Lemma 4.2], but targets a diﬀerent merit func-
tion, and relies on the properties in Proposition 2. On the events of Ak and Bk,
the merit function and its gradient are precisely estimated. Since ¯µ ¯K ≤ ˜µ by
Lemma 4, κL ¯µ ¯K ,ν ≤ κL ˜µ,ν by (12). We apply the Taylor expansion and get

(cid:19)

+

(cid:19)T (cid:18) ¯∆xk
¯∆λk
(cid:19)T (cid:18) ¯∆xk
¯∆λk

¯µ ¯K ,ν

¯µ ¯K ,ν

κL ˜µ,ν ¯α2
k
2

(cid:19)

+ ¯αk

(cid:13)
(cid:18) ¯∆xk
(cid:13)
(cid:13)
¯∆λk
(cid:13)
(cid:18) ¯∇xLk
¯∇λLk

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

(cid:19)

(cid:19)T (cid:18) ¯∆xk
¯∆λk

¯µ ¯K ,ν

¯µ ¯K ,ν

Lsk
¯µ ¯K ,ν ≤ Lk

¯µ ¯K ,ν + ¯αk

= Lk

¯µ ¯K ,ν + ¯αk

+

κL ˜µ,ν ¯α2
k
2

¯µ ¯K ,ν

(cid:18)∇xLk
∇λLk
¯µ ¯K ,ν
(cid:18)∇xLk
¯µ ¯K ,ν − ¯∇xLk
¯µ ¯K ,ν − ¯∇λLk
∇λLk
(cid:19)(cid:13)
(cid:13)
(cid:18) ¯∆xk
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
¯∆λk
(cid:13)
(cid:13)
(cid:18) ¯∇xLk
¯∇λLk

¯µ ¯K ,ν

(17)
≤ Lk

(cid:19)

(cid:19)T (cid:18) ¯∆xk
¯∆λk

¯µ ¯K ,ν + ¯αk
(cid:13)
(cid:18) ¯∇xLk + ν ¯MkGk ¯∇xLk + GT
(cid:13)
(cid:13)
(cid:13)

k Gk ¯∇xLk

νGkGT

kκgrad

¯µ ¯K ,ν

+

κL ˜µ,ν ¯α2
k
2
k ck

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:18) ¯∆xk
(cid:13)
(cid:13)
¯∆λk
(cid:13)
(cid:13)
(cid:18) ¯∆xk
(cid:13)
(cid:13)
¯∆λk
(cid:13)

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

+ ¯α2

28

(39)
≤ Lk

¯µ ¯K ,ν + ¯αk

(cid:18) ¯∇xLk
¯∇λLk

¯µ ¯K ,ν

(cid:19)

(cid:19)T (cid:18) ¯∆xk
¯∆λk

¯µ ¯K ,ν
2(κL ˜µ,ν Υ 2

(19)
≤ Lk

¯µ ¯K ,ν + ¯αk

(cid:26)

1 −

3 + κgradΥ1Υ3)¯αk
γRH ∧ ν

(cid:27) (cid:18) ¯∇xLk
¯∇λLk

¯µ ¯K ,ν

¯µ ¯K ,ν

Na et al.

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:18) ¯∆xk
(cid:13)
(cid:13)
Gk ¯∇xLk
(cid:13)
(cid:19)T (cid:18) ¯∆xk
(cid:19)
¯∆λk

.(40)

+ (κL ˜µ,ν Υ 2

3 + κgradΥ1Υ3)¯α2
k

Moreover, by event Bk we have

¯Lsk

¯µ ¯K ,ν

(22)
≤ Lsk

¯µ ¯K ,ν − κf ¯α2

(40)
≤ Lk

¯µ ¯K ,ν + ¯αk

(22)
≤ ¯Lk

¯µ ¯K ,ν + ¯αk

(cid:26)

(cid:26)

1 −

1 −

Thus, if

k

(cid:18) ¯∇xLk
¯∇λLk
2(κL ˜µ,ν Υ 2

¯µ ¯K ,ν

(cid:19)

(cid:19)T (cid:18) ¯∆xk
¯∆λk

¯µ ¯K ,ν
3 + κgradΥ1Υ3) + κf γRH

γRH ∧ ν

2(κL ˜µ,ν Υ 2

3 + κgradΥ1Υ3 + κf γRH )

γRH ∧ ν

¯αk

¯αk

(cid:27) (cid:18) ¯∇xLk
¯∇λLk
(cid:27) (cid:18) ¯∇xLk
¯∇λLk

¯µ ¯K ,ν

¯µ ¯K ,ν

¯µ ¯K ,ν

¯µ ¯K ,ν

(cid:19)T (cid:18) ¯∆xk
¯∆λk
(cid:19)T (cid:18) ¯∆xk
¯∆λk

(cid:19)

(cid:19)

.

1−

2(κL ˜µ,ν Υ 2

3 + κgradΥ1Υ3 + κf γRH )

γRH ∧ ν

¯αk ≥ β ⇐⇒ ¯αk ≤

(1 − β)(γRH ∧ ν)
3 + κgradΥ1Υ3 + κf γRH )

2(κL ˜µ,ν Υ 2

,

we have

¯Lsk
¯µ ¯K ,ν ≤ ¯Lk

¯µ ¯K ,ν + ¯αkβ

(cid:18) ¯∇xLk
¯∇λLk

¯µ ¯K ,ν

¯µ ¯K ,ν

(cid:19)T (cid:18) ¯∆xk
¯∆λk

(cid:19)

,

which completes the proof.

(cid:117)(cid:116)

Lemma 6 For k ≥ K, we suppose Bk happens. If the k-th step is a successful
step, then

Lsk
¯µ ¯K ,ν ≤ Lk

¯µ ¯K ,ν +

¯αkβ
2

(cid:18) ¯∇xLk
¯∇λLk

¯µ ¯K ,ν

¯µ ¯K ,ν

(cid:19)T (cid:18) ¯∆xk
¯∆λk

(cid:19)

.

Proof Since Bk happens and the k-th step is successful, we have

Lsk

¯µ ¯K ,ν

(22)
≤ ¯Lsk

¯µ ¯K ,ν − κf ¯α2

(cid:19)

¯µ ¯K ,ν

¯µ ¯K ,ν

k

(cid:18) ¯∇xLk
¯∇λLk
(cid:18) ¯∇xLk
¯∇λLk
(cid:18) ¯∇xLk
¯∇λLk
(cid:18) ¯∇xLk
¯∇λLk

¯µ ¯K ,ν

¯µ ¯K ,ν

¯µ ¯K ,ν

¯µ ¯K ,ν

¯µ ¯K ,ν

¯µ ¯K ,ν

(cid:19)T (cid:18) ¯∆xk
¯∆λk
(cid:19)T (cid:18) ¯∆xk
(cid:19)
¯∆λk
(cid:19)T (cid:18) ¯∆xk
¯∆λk
(cid:19)T (cid:18) ¯∆xk
¯∆λk

(cid:19) (cid:18)

(cid:19) (cid:18)

(25)
≤ ¯Lk

¯µK ,ν + ¯αkβ

(22)
≤ Lk

¯µ ¯K ,ν + ¯αkβ

≤ Lk

¯µ ¯K ,ν + ¯αkβ

− κf ¯α2
k

(cid:18) ¯∇xLk
¯∇λLk
(cid:19)

¯µK ,ν

¯µK ,ν

(cid:19)

(cid:19)T (cid:18) ¯∆xk
¯∆λk

1 −

2κf ¯αk
β

1 −

2κf αmax
β

(cid:19)

,

where the last inequality is due to ¯αk ≤ αmax from Algorithm 3. Using the
(cid:117)(cid:116)
input condition on κf in Line 1 of Algorithm 3 completes the proof.

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

29

Using the above two lemmas, we establish the one-step error recursion for
Φk
¯µ ¯K ,ν,ω. Our analytical structure follows [31, Theorem 4.6] but generalizes it
to a diﬀerent merit function for studying equality-constrained problems. We
consider three cases of approximation of Algorithm 3: Ak ∩ Bk, Ac
k ∩ Bk, and
Bc
k. We study them in the next three lemmas.
Lemma 7 For k ≥ ¯K, we suppose the event Ak ∩ Bk happens. Let

≤

1 − ω
ω

β(γRH ∧ ν)
32ρ (cid:8)κL ˜µ,ν αmaxΥ3 ∨ (κgradαmaxΥ1 + Υ4)(cid:9)2 ∧
where Υ1, Υ3, Υ4 are given by Proposition 2 and κL ˜µ,ν is deﬁned in (12) with ˜µ
given by Lemma 4. Then

1
4(ρ − 1)

(41)

¯µ ¯K ,ν,ω − Φk
Φk+1

¯µ ¯K ,ν,ω = −

(cid:18)

(1 − ω)

1 −

1
2

1
ρ

(cid:19) (cid:32)

¯(cid:15)k + ¯αk

(cid:13)
(cid:18)∇xLk
(cid:13)
(cid:13)
∇λLk
(cid:13)

¯µ ¯K ,ν

¯µ ¯K ,ν

2(cid:33)

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

.

Proof For each iteration, we have the following three types of steps.
Case 1: reliable step. We have
(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:18) ¯∇xLk
(cid:18) ¯∇xLk
¯µ ¯K ,ν − ∇xLk
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
¯∇λLk
¯∇λLk
¯µ ¯K ,ν − ∇λLk
(cid:13)
(cid:13)
(cid:13)
¯µ ¯K ,ν
(cid:13)
(cid:13)
(cid:19)(cid:13)
(cid:18) ¯∇xLk + ν ¯MkGk ¯∇xLk + GT
(cid:18) ¯∇xLk
k ck
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
¯∇λLk
(cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:18)∇xLk
(cid:13)
(cid:13)
∇λLk
(cid:13)
(17)
≤ κgrad ¯αk

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

¯µ ¯K ,ν

¯µ ¯K ,ν

¯µ ¯K ,ν

¯µ ¯K ,ν

¯µ ¯K ,ν

+

≤

+

(39)
≤ (κgradαmaxΥ1 + Υ4)

νGkGT
(cid:13)
(cid:18) ¯∆xk
(cid:13)
(cid:13)
Gk ¯∇xLk
(cid:13)

k Gk ¯∇xLk
(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

.

¯µ ¯K ,ν

¯µ ¯K ,ν

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

(42)

By Lemma 6 and the reliability of the step, we further have

¯µ ¯K ,ν − Lk
Lk+1

¯µ ¯K ,ν ≤

¯αkβ
2

(19)
≤ −

¯αkβ(γRH ∧ ν)
8

¯µ ¯K ,ν

¯µ ¯K ,ν

(cid:19)T (cid:18) ¯∆xk
¯∆λk

(cid:18) ¯∇xLk
¯∇λLk
(cid:13)
(cid:19)(cid:13)
(cid:18) ¯∆xk
2
¯(cid:15)k
(cid:13)
(cid:13)
(cid:13)
(cid:13)
Gk ¯∇xLk
4
(cid:13)
(cid:13)
(cid:13)
(cid:18)∇xLk
(cid:13)
(cid:13)
∇λLk
(cid:13)

−

¯µ ¯K ,ν

¯µ ¯K ,ν

(cid:19) (26)
≤

¯αkβ
4

(cid:18) ¯∇xLk
¯∇λLk

(42)
≤ −

¯αkβ(γRH ∧ ν)
16

¯µ ¯K ,ν

(cid:19)T (cid:18) ¯∆xk
¯∆λk
¯µ ¯K ,ν
(cid:13)
(cid:18) ¯∆xk
(cid:13)
(cid:13)
Gk ¯∇xLk
(cid:13)

(cid:19)

−

¯(cid:15)k
4

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

−

¯(cid:15)k
4

.

(43)

−

¯αkβ(γRH ∧ ν)
16 (κgradαmaxΥ1 + Υ4)2

Moreover, by Line 13 of Algorithm 3, ¯(cid:15)k+1 − ¯(cid:15)k = (ρ − 1)¯(cid:15)k and, by Taylor
expansion,

¯αk+1

(cid:13)
(cid:18)∇xLk
(cid:13)
(cid:13)
∇λLk
(cid:13)
(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

¯µ ¯K ,ν

¯µ ¯K ,ν

+ κ2

L ˜µ,ν

¯α2
k

− ¯αk

2
(cid:19)(cid:13)
(cid:13)
(cid:18)∇xLk+1
(cid:13)
(cid:13)
¯µ ¯K ,ν
(cid:13)
(cid:13)
∇λLk+1
(cid:13)
(cid:13)
¯µ ¯K ,ν
(cid:32)(cid:13)
(cid:18)∇xLk
(cid:13)
(cid:13)
∇λLk
(cid:13)
(cid:32)(cid:13)
(cid:18)∇xLk
(cid:13)
(cid:13)
∇λLk
(cid:13)

≤ 2¯αk+1

≤ 2ρ¯αk

¯µ ¯K ,ν

¯µ ¯K ,ν

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

+ κ2

L ˜µ,ν

maxΥ 2
α2
3

¯µ ¯K ,ν

¯µ ¯K ,ν

(cid:13)
(cid:18) ¯∆xk
(cid:13)
(cid:13)
¯∆λk
(cid:13)

2(cid:33)

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:18) ¯∆xk
(cid:13)
(cid:13)
Gk ¯∇xLk
(cid:13)

2(cid:33)

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

. (44)

30

Na et al.

The last inequality uses ¯αk+1 ≤ ρ¯αk, ¯αk ≤ αmax, and (39). Combining the above
three displays,

Φk+1
¯µ ¯K ,ν,ω − Φk

¯µ ¯K ,ν,ω ≤ −

β(γRH ∧ ν)ω
32

¯αk

(cid:13)
(cid:19)(cid:13)
(cid:18) ¯∆xk
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
Gk ¯∇xLk
(cid:13)
(cid:13)
(cid:13)
(cid:18)∇xLk
(cid:13)
(cid:13)
∇λLk
(cid:13)

−

β(γRH ∧ ν)ω
32 (κgradαmaxΥ1 + Υ4)2 ¯αk

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

−

ω¯(cid:15)k
8

,

¯µ ¯K ,ν

¯µ ¯K ,ν

since

−

ωβ(γRH ∧ ν)
16

+ (1 − ω)ρκ2

L ˜µ,ν

maxΥ 2
α2

3 ≤ −

−

ωβ(γRH ∧ ν)

16 (κgradαmaxΥ1 + Υ4)2 + (1 − ω)ρ ≤ −
1
(1 − ω)(ρ − 1) ≤ −
+
2

ω
4

−

,

ωβ(γRH ∧ ν)
32
ωβ(γRH ∧ ν)
32 (κgradαmaxΥ1 + Υ4)2 ,
ω
,
8

as implied by the condition (41).
Case 2: unreliable step. For unreliable step, we apply Lemma 6 and (43) is
changed to

Lk+1
¯µ ¯K ,ν − Lk

¯µ ¯K ,ν ≤

(42)
≤ −

¯αkβ(γRH ∧ ν)
8

¯αkβ
2

¯µ ¯K ,ν

(cid:18) ¯∇xLk
¯∇λLk
(cid:13)
(cid:18) ¯∆xk
(cid:13)
(cid:13)
Gk ¯∇xLk
(cid:13)

¯µ ¯K ,ν

(cid:19)T (cid:18) ¯∆xk
¯∆λk

(cid:19) (19)

≤ −

¯αkβ(γRH ∧ ν)
4

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

−

¯αkβ(γRH ∧ ν)
8 (κgradαmaxΥ1 + Υ4)2

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:18) ¯∆xk
(cid:13)
(cid:13)
Gk ¯∇xLk
(cid:13)
(cid:19)(cid:13)
(cid:13)
2
(cid:18)∇xLk
(cid:13)
(cid:13)
(cid:13)
(cid:13)
∇λLk
(cid:13)
(cid:13)

¯µ ¯K ,ν

¯µ ¯K ,ν

.

By Line 15 of Algorithm 3, ¯(cid:15)k+1 − ¯(cid:15)k = −(1 − 1/ρ)¯(cid:15)k, while (44) is still the
same. Thus, under the condition (41), we obtain

¯µ ¯K ,ν,ω − Φk
Φk+1

¯µ ¯K ,ν,ω ≤ −

β(γRH ∧ ν)ω
32

−

β(γRH ∧ ν)ω
32 (κgradαmaxΥ1 + Υ4)2 ¯αk

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

¯αk

(cid:13)
(cid:18) ¯∆xk
(cid:13)
(cid:13)
Gk ¯∇xLk
(cid:13)
(cid:19)(cid:13)
(cid:13)
2
(cid:18)∇xLk
(cid:13)
(cid:13)
(cid:13)
(cid:13)
∇λLk
(cid:13)
(cid:13)

¯µ ¯K ,ν

¯µ ¯K ,ν

−

(cid:18)

(1 − ω)

1 −

1
2

(cid:19)

1
ρ

¯(cid:15)k.

Case 3: unsuccessful step. Noting that (xk+1, λk+1) = (xk, λk),

¯µ ¯K ,ν,ω − Φk
Φk+1
1
2

= −

¯µ ¯K ,ν,ω
(cid:18)

(1 − ω)

1 −

(cid:19)

1
ρ

¯(cid:15)k −

1
2

(cid:18)

(1 − ω)

1 −

(cid:19)

1
ρ

¯αk

(cid:13)
(cid:18)∇xLk
(cid:13)
(cid:13)
∇λLk
(cid:13)

¯µ ¯K ,ν

¯µ ¯K ,ν

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

.

(45)

Noting that under the condition (41), we have

β(γRH ∧ ν)ω

−

32 (κgradαmaxΥ1 + Υ4)2 ≤ −
(cid:18)

−

≤ −

(1 − ω)

1 −

ω
8

1
2

(cid:19)

.

1
ρ

(cid:18)

(1 − ω)

1 −

1
2

(cid:19)

,

1
ρ

Therefore, (45) holds for all three cases, which completes the proof.

(cid:117)(cid:116)

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

31

The proofs of Lemmas 8 and 9 are similar to Lemma 7, hence deferred to

the appendix.

Lemma 8 For k ≥ ¯K, we suppose the event Ac
satisﬁes (41). Then

k ∩ Bk happens. Suppose ω

¯µ ¯K ,ν,ω − Φk
Φk+1

¯µ ¯K ,ν,ω ≤ ρ(1 − ω)¯αk

(cid:13)
(cid:18)∇xLk
(cid:13)
(cid:13)
∇λLk
(cid:13)

¯µ ¯K ,ν

¯µ ¯K ,ν

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

.

Proof See Appendix B.3.

(cid:117)(cid:116)

Lemma 9 For k ≥ ¯K, we suppose the event Bc
(41). Then

k happens. Suppose ω satisﬁes

¯µ ¯K ,ν,ω − Φk
Φk+1

¯µ ¯K ,ν,ω ≤ ρ(1 − ω)¯αk

(cid:13)
(cid:18)∇xLk
(cid:13)
(cid:13)
∇λLk
(cid:13)
+ ω(| ¯Lsk

¯µ ¯K ,ν

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

¯µ ¯K ,ν
¯µ ¯K ,ν − Lsk

¯µ ¯K ,ν| + | ¯Lk

¯µ ¯K ,ν − Lk

¯µ ¯K ,ν|).

Proof See Appendix B.4.

(cid:117)(cid:116)

The above three lemmas show how Φk

¯µ ¯K ,ν,ω changes in each iteration. We
observe from Lemmas 8 and 9 that if either the function or the gradient are
imprecisely estimated, then there is no guarantee that Φk
¯µ ¯K ,ν,ω will decrease.
The following theorem shows that the increase of Φk
¯µ ¯K ,ν,ω can be controlled,
when the probabilities pf , pgrad of bad events are small enough. In particular,
in expectation, Φk
¯µ ¯K ,ν,ω always decreases. Our analysis is conditional on F ¯K, so
that (x ¯K+1, λ ¯K+1) and ¯µ ¯K are ﬁxed. Our proof resembles [31, Theorem 4.6],
but the conditions on pgrad, pf are diﬀerent. To simplify notation, we let Φk
¯µ ¯K
denote Φk
¯µ ¯K ,ν,ω. Recall that ω is not a parameter of the algorithm.

Theorem 2 (One-step error recursion) For k > ¯K, suppose ω satisﬁes
(41) and pf , pgrad satisfy

pgrad +

√

pf

(1 − pgrad)(1 − pf )

≤

ρ − 1
8ρ

(cid:18) 1
ρ

∧

1 − ω
ω

(cid:19)

.

(46)

Then,

E[Φk+1
¯µ ¯K

− Φk

¯µ ¯K

| Fk−1]

(1 − pgrad)(1 − pf )(1 − ω)

1 −

(cid:18)

≤ −

1
4

(cid:19) (cid:32)

¯(cid:15)k + ¯αk

1
ρ

Proof By (18) and (23), we have

(cid:13)
(cid:18)∇xLk
(cid:13)
(cid:13)
∇λLk
(cid:13)

¯µ ¯K ,ν

¯µ ¯K ,ν

2(cid:33)

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

.

P (Ak | Fk−1) ≥ 1 − pgrad

and

P (Bk | Fk−0.5) ≥ 1 − pf .

(47)

32

We further have

E[Φk+1
¯µ ¯K

− Φk
¯µ ¯K
+E[1AC
k ∩Bk (Φk+1
¯µ ¯K

| Fk−1] = E[1Ak∩Bk (Φk+1
− Φk
¯µ ¯K
¯µ ¯K
) | Fk−1] + E[1BC

− Φk

¯µ ¯K

k

) | Fk−1]
(Φk+1
¯µ ¯K

− Φk

¯µ ¯K

Na et al.

) | Fk−1].(48)

Using Lemma 7,

E[1Ak∩Bk (Φk+1
¯µ ¯K

− Φk

¯µ ¯K

) | Fk−1]
(cid:18)

E [1Ak∩Bk | Fk−1]

1 −

≤ −

= −

1 − ω
2

1 − ω
2

E [1Ak

E [1Bk | Fk−0.5] | Fk−1]

(47)
≤ −

1
2

(1 − pgrad)(1 − pf )(1 − ω)

1 −

(cid:18)

1
ρ

(cid:19) (cid:32)

¯(cid:15)k + ¯αk

1
ρ

2(cid:33)

(cid:13)
(cid:18)∇xLk
(cid:13)
(cid:13)
∇λLk
(cid:13)
(cid:19) (cid:32)

¯µ ¯K ,ν

¯µ ¯K ,ν

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:18)∇xLk
(cid:13)
(cid:13)
∇λLk
(cid:13)
(cid:13)
(cid:18)∇xLk
(cid:13)
(cid:13)
∇λLk
(cid:13)

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

¯(cid:15)k + ¯αk

¯µ ¯K ,ν

¯µ ¯K ,ν

(cid:18)

1 −

1
ρ

(cid:19) (cid:32)

¯(cid:15)k + ¯αk

2(cid:33)

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

¯µ ¯K ,ν

¯µ ¯K ,ν
2(cid:33)

.

(49)

Using Lemma 8,

E[1AC

k ∩Bk (Φk+1
¯µ ¯K

− Φk

¯µ ¯K

) | Fk−1] ≤ (1 − ω)E[1AC

k ∩Bk | Fk−1]ρ¯αk

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

¯µ ¯K ,ν

¯µ ¯K ,ν
(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:18)∇xLk
(cid:13)
(cid:13)
∇λLk
(cid:13)
(cid:13)
(cid:18)∇xLk
(cid:13)
(cid:13)
∇λLk
(cid:13)
(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

¯µ ¯K ,ν

¯µ ¯K ,ν

.

(50)

≤ (1 − ω)E[1AC

k

| Fk−1]ρ¯αk

(47)
≤ pgrad(1 − ω)ρ¯αk

(cid:13)
(cid:18)∇xLk
(cid:13)
(cid:13)
∇λLk
(cid:13)

¯µ ¯K ,ν

¯µ ¯K ,ν

Using Lemma 9,

E[1BC

k

(Φk+1
¯µ ¯K

− Φk

¯µ ¯K

) | Fk−1]
(cid:13)
(cid:18)∇xLk
(cid:13)
(cid:13)
∇λLk
(cid:13)
¯µ ¯K ,ν − Lsk
(cid:13)
(cid:18)∇xLk
(cid:13)
(cid:13)
∇λLk
(cid:13)

≤ pf (1 − ω)ρ¯αk

+ E[1BC

k

| ¯Lsk

(24)
≤ pf (1 − ω)ρ¯αk

¯µ ¯K ,ν| | Fk−1](cid:1)
(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

¯µ ¯K ,ν

¯µ ¯K ,ν

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

+ ω(cid:0)E[1BC

k

| ¯Lk

¯µ ¯K ,ν − Lk

¯µ ¯K ,ν| | Fk−1]

¯µ ¯K ,ν

¯µ ¯K ,ν

+ 2ω

√

pf ¯(cid:15)k.

(51)

The last inequality also uses H¨older’s inequality. Combining (48), (49), (50),
(51), we obtain

E[Φk+1
¯µ ¯K

− Φk

¯µ ¯K

| Fk−1]

(1 − pgrad)(1 − pf )(1 − ω)

1 −

(cid:18)

≤ −

1
2

(cid:19) (cid:32)

¯(cid:15)k + ¯αk

1
ρ

(cid:13)
(cid:18)∇xLk
(cid:13)
(cid:13)
∇λLk
(cid:13)

¯µ ¯K ,ν

¯µ ¯K ,ν

2(cid:33)

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

+ (pgrad + pf )(1 − ω)ρ¯αk

(cid:13)
(cid:18)∇xLk
(cid:13)
(cid:13)
∇λLk
(cid:13)

¯µ ¯K ,ν

¯µ ¯K ,ν

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

√

+ 2ω

pf ¯(cid:15)k.

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

33

Under the condition (46), we have

(pgrad + pf )(1 − ω)ρ ∨ 2ω

√

pf ≤

1
4

(1 − pgrad)(1 − pf )(1 − ω)

1 −

(cid:18)

(cid:19)

.

1
ρ

Combining the above two displays completes the proof.

(cid:117)(cid:116)

Based on the one-step error recursion, the following theorem shows the

convergence of ¯αk(cid:107)∇Lk(cid:107)2.

Theorem 3 Suppose the conditions of Theorem 2 are satisﬁed. Then, almost
surely, we have lim
k→∞

¯αk(cid:107)∇Lk(cid:107)2 = 0.

Proof By Lemma 4, for any realization of the iteration sequence {(xk, λk)}k,
with probability 1 there exists ¯K < ∞ such that ¯µk is stabilized after ¯K. Note
that Algorithm 3 ensures that for k > ¯K,

(cid:107)ck(cid:107) = E [(cid:107)ck(cid:107) | Fk−1] ≤ E[(cid:107) ¯∇Lk

¯µ ¯K ,ν(cid:107) | Fk−1]
¯µ ¯K ,ν(cid:107) + E[(cid:107) ¯∇Lk

≤ (cid:107)∇Lk

(29)
≤ (cid:107)∇Lk

¯µ ¯K ,ν(cid:107) + Υ5(Eξk

g

¯µ ¯K ,ν − ∇Lk
¯µ ¯K ,ν(cid:107) | Fk−1]
(cid:2)(cid:107)¯gk − ∇fk(cid:107) + (cid:107) ¯Hk − ∇2fk(cid:107)(cid:3)),

where we let Υ5 := 1 + νκ3/2
| + 1, we know |ξk
|ξk−1
g

2,G + νκ1/2
g | ≥ k. Therefore,

2,G + νκ2,Gκ∇2

xc(Ω1 + κ∇xL). Since |ξk

g | ≥

Eξk

g

[(cid:107)¯gk − ∇fk(cid:107)] ≤ (Eξk

g

(cid:2)(cid:107)¯gk − ∇fk(cid:107)2(cid:3))1/2 ≤

Ω1√
k

,

and the above result holds similarly for Eξk
above two displays, we obtain

g

[(cid:107) ¯Hk − ∇2fk(cid:107)]. Combining the

(cid:107)ck(cid:107) ≤ (cid:107)∇Lk

¯µ ¯K ,ν(cid:107) +

Υ5 max{Ω1, Ω2}
√
k

.

Moreover, by the deﬁnition of ∇Lk
Lemma 4, we have

¯µ ¯K ,ν in (4) and the bound on ¯µ ¯K ≤ ˜µ in

(cid:107)∇xLk(cid:107) ≤ (cid:107)∇xLk

¯µ ¯K ,ν(cid:107) + νκM (cid:107)Gk∇xLk(cid:107) + ˜µ

κ2,G(cid:107)ck(cid:107)

√

and

(cid:107)Gk∇xLk(cid:107) ≤

1
νκ1,G

(cid:107)νGkGT

k Gk∇xLk(cid:107)

(4)
≤

1
νκ1,G

((cid:107)∇λLk

¯µ ¯K ,ν(cid:107) + (cid:107)ck(cid:107)).

Combining the above three displays,

(cid:107)∇Lk(cid:107) ≤ Υ6(cid:107)∇Lk

¯µ ¯K ,ν(cid:107) +

(cid:18)

1 +

κM
κ1,G

√

+ ˜µ

κ2,G

(cid:19) Υ5 max{Ω1, Ω2}
√

k

34

Na et al.

where Υ6 = 2 + 2κM /κ1,G + ˜µ

√

κ1,G. Since ¯αk ≤ αmax, we have

lim
k→∞

¯αk(cid:107)∇Lk(cid:107)2 ≤ Υ 2

6 lim
k→∞

¯αk(cid:107)∇Lk

¯µ ¯K ,ν(cid:107)2.

¯µ ¯K ,ν(cid:107)2 = 0.
It hence suﬃces to show that for any iteration sequence lim
k→∞
By Theorem 2, we sum the error recursion for k ≥ ¯K + 1, compute the
conditional expectation given the ﬁrst ¯K + 1 iterates, and obtain

¯αk(cid:107)∇Lk

∞
(cid:88)

k= ¯K+1

E[¯αk(cid:107)∇Lk

¯µ ¯K ,ν(cid:107)2 | F ¯K] ≤ Υ7

∞
(cid:88)

E[Φk

¯µ ¯K

| F ¯K] − E[Φk+1
¯µ ¯K

| F ¯K]

k= ¯K+1
≤ Υ7(Φ ¯K+1
¯µ ¯K

− ω min
X ×Λ

L¯µ ¯K ,ν(x, λ)) < ∞,

where Υ7 = 4ρ/ {(1 − pgrad)(1 − pf )(1 − ω)(ρ − 1)}. Thus, we have

lim
k→∞

E[¯αk(cid:107)∇Lk

¯µ ¯K ,ν(cid:107)2 | F ¯K] = 0.

Since ¯αk ≤ αmax and {(xk, λk)}k are in a compact set X × Λ, we have
¯αk(cid:107)∇Lk
¯µ ¯K ,ν(cid:107)2 ≤ Υ8 for some constant Υ8 uniformly. By dominated convergence
theorem [17, Theorem 1.5.8], we exchange the order of expectation and limit
and get E[ lim
¯µ ¯K ,ν(cid:107)2 is non-negative,
¯µ ¯K ,ν(cid:107)2 | F ¯K] = 0. Since ¯αk(cid:107)∇Lk
k→∞
¯µ ¯K ,ν(cid:107)2 = 0 almost surely, which completes the proof. (cid:117)(cid:116)

¯αk(cid:107)∇Lk

¯αk(cid:107)∇Lk

we have lim
k→∞

Our ﬁnal result establishes the “liminf” convergence of ∇Lk. A key step is
to apply the lower bound on the stochastic stepsize in Lemma 5. Based on this
lemma, when both the gradient and function are precisely estimated, a stepsize
that is smaller than a ﬁxed threshold will always induce a successful step. If
we regard {¯αk}k as a random walk, the supremum of ¯αk will not vanish due to
a positive upward drift probability.

Theorem 4 (Global convergence of Algorithm 3) Consider Algorithm 3
under Assumption 3. Suppose ω satisﬁes (41) and pf , pgrad satisfy (46). Then,
almost surely, we have that

Proof We deﬁne two random sequences

lim inf
k→∞

(cid:107)∇Lk(cid:107) = 0.

φk = log (¯αk) ,
ϕk = min (cid:8)log (τ ) , 1Ak−1∩Bk−1 (log(ρ) + ϕk−1) + (1 − 1Ak−1∩Bk−1)(ϕk−1 − log(ρ))(cid:9) ,

where ϕ0 = log (¯α0). Let τ be a deterministic constant such that

τ ≤

2 (cid:0)κL ˜µ,ν Υ 2

(1 − β)(γRH ∧ ν)
3 + κgradΥ1Υ3 + κf γRH

(cid:1) ∧ αmax,

and τ = ρiαmax for some integer i ≤ 0. Therefore, by the stepsize updating
rule in Algorithm 3, we have that for any k, ¯αk = ρjk τ for some integer jk. We

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

35

lower bound φk by ϕk using induction. First, we observe that φk and ϕk are
both Fk−1-measurable. Note that φ0 = ϕ0. Suppose φk ≥ ϕk and we consider
the following three cases:
(a). If φk > log(τ ), then φk ≥ log(τ ) + log(ρ). Thus, φk+1 ≥ φk − log(ρ) ≥
log(τ ) ≥ ϕk+1.
(b). If φk ≤ log(τ ) and 1Ak∩Bk = 1, then, by Lemma 5,

φk+1 = min {log(αmax), φk + log(ρ)} ≥ min{log(τ ), ϕk + log(ρ)} = ϕk+1.

Here the inequality is due to the deﬁnition of τ and the induction hypothesis.
(c). If φk ≤ log(τ ) and 1Ak∩Bk = 0, then

φk+1 ≥ φk − log(ρ) ≥ ϕk − log(ρ) ≥ ϕk+1.

Thus, φk ≥ ϕk, ∀k. Note that ϕk is a random walk with a maximum and a
drift upward. Thus, by analogy to Example 6.1.2 in [19] and noting from (46)
that pgrad + pf < 1/2, we know from Sections 6.2 and 6.3 (pp 290) in [19] that
log(τ ) is a positive recurrent state of the process ϕk. That is, ϕk visits log(τ )
inﬁnite times. Thus, “limsup” of ¯αk is lower bounded by noting that
φk ≥ log(τ )(cid:1) ≥ P (cid:0) lim sup

ϕk ≥ log(τ )(cid:1) = 1.

P (cid:0) lim sup

k→∞

k→∞

Using Theorem 3, we complete the proof.

(cid:117)(cid:116)

k=0 α2

We complete the global analysis of Algorithm 3. The result in Theorem 4
is consistent with Theorem 1(b). However, the stepsize behavior of the two al-
gorithms is largely diﬀerent. Algorithm 2 employs a deterministic stepsize se-
quence. The condition (cid:80)∞
k < ∞ implies that αk decays to zero with a
certain rate. Diﬀerently, as proved in Theorem 4, the stepsize ¯αk derived from
stochastic line search has a subsequence that is lower bounded away from zero.
Therefore, stochastic line search often suggests a stepsize that is larger than the
one suggested by Theorem 1(b), especially for large k, which leads to a better
performance. On the other hand, we note that employing stochastic line search
requires a more stringent setup than the fully stochastic setup of Algorithm 2.
The former generates batch samples to diminish the model estimation error,
while the latter only generates two samples in each iteration ([3] only gener-
ates one sample). In addition, the analysis of Algorithm 2 requires only the
estimation errors to have bounded variance, while the analysis of Algorithm 3
requires the errors to be bounded. Such a boundedness condition ensures that
the penalty parameter is ﬁnally stabilized.

Theorem 4.1]), where one has lim
k→∞

Both results in Theorems 1 and 4 are weaker than deterministic SQP (cf. [25,
(cid:107)∇Lk(cid:107) = 0. The intrinsic diﬀerence between
Algorithm 3 and deterministic SQP still lies in the stepsize behavior. For deter-
ministic SQP, a standard result is that αk is lower bounded away from zero for
all suﬃciently large k, which leads to convergence of the KKT residual sequence
(cid:107)∇Lk(cid:107). In contrast, due to the existence of imprecise model estimation, ¯αk
only provably has a subsequence that is lower bounded away from zero. Thus,
we can only conclude that there exists a convergent subsequence for (cid:107)∇Lk(cid:107).

36

Na et al.

We note that [31] established the expected iteration complexity for a stochas-
tic line search. Performing a similar complexity analysis for constrained prob-
lems is signiﬁcantly more diﬃcult. The main issue stems from the adaptivity
in selecting the penalty parameter. In general, there is no guarantee on how
long it takes for a randomly selected penalty parameter sequence to stabilize.
Although we believe that a similar analysis to [31] is applicable after the
penalty parameter stabilizes, a more advanced technique and a ﬁner analysis
are required to study the early period of the random walk induced by the
penalty parameter, where the parameter varies in each iteration. In other words,
a deeper understanding on the random iteration threshold ¯K (cf. Lemma 4) is
desired. We leave the investigation of this problem to future work.

5 Experiments

We implement four StoSQP algorithms for solving constrained nonlinear opti-
mization problems collected in CUTEst test set [22]. We use Julia implementa-
tion of CUTEst [40]. The four algorithms that we implement are: (cid:96)1 penalized
SQP in [3], NonAdapSQP in Algorithm 2, AdapSQP in Algorithm 3, and (cid:96)1
penalized AdapSQP. The (cid:96)1 penalized AdapSQP has a similar iteration scheme
to AdapSQP, except that it employs the (cid:96)1 penalized merit function

Lµ(x) = f (x) + µ(cid:107)c(x)(cid:107)1.

In particular, the condition (17) in the ﬁrst step is replaced by

Ak = (cid:8)(cid:107)¯gk − ∇fk(cid:107) ≤ κgrad · ¯αk(cid:107) ¯∇Lk(cid:107)(cid:9) ,

where the right hand side uses the KKT residual as the counterpart of (cid:107)¯gk(cid:107) used
in unconstrained problems. For the second step, the search direction is solved by
the ﬁrst system in (9). For a prespeciﬁed ρ ∈ (1, 2), the penalty parameter ¯µk is
¯∆xk/{(ρ − 1)(cid:107)ck(cid:107)1}, suggested by [30, (18.33)], to ensure
updated by ¯µk = ¯gT
k
the directional derivative of ¯Lk
along the direction ¯∆xk yields a suﬃcient
¯µk
decrease. Furthermore, the condition (22) in the third step is replaced by

Bk = (cid:8)| ¯Lk
¯µk

− Lk
¯µk

| ∨ | ¯Lsk

¯µk − Lsk

¯µk | ≤ −κf α2
k

(cid:0)¯gT

k

¯∆xk − ¯µk(cid:107)ck(cid:107)1

(cid:1)(cid:9)

where the right hand side is the directional derivative of ¯Lk
along ¯∆xk. The
¯µk
fourth step for line search is the same as AdapSQP. We should mention that
there may exist advanced modiﬁcations for SQP using the (cid:96)1 merit function.
Here, we only consider the stochastic counterpart of the most basic deterministic
SQP scheme. An advanced design of the (cid:96)1 penalized AdapSQP and a rigorous
analysis are left for future work.

Of more than 1000 problems in CUTEst collection, we select problems that
have a non-constant objective with only equality constraints, satisfy d < 1000,
and do not report singularity on GkGT
k during the iteration process. This
results in a total of 47 problems. The implementation details of each algorithm
are as follows. Our code is available at https://github.com/senna1128/
Constrained-Stochastic-Optimization.

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

37

(a) (cid:96)1 SQP in [3]. We implement [3, Algorithm 3.1] following the setup in that
paper. In particular, using their notation, we let ¯τ−1 = 1, (cid:15) = 10−6, σ = 0.5,
¯ξ−1 = 1, and θ = 10. The Lipschitz constant is estimated around the
initialization. We try multiple choices for the stepsize related sequence {βk}k.
For constant case, we let βk = {0.01, 0.1, 0.5, 1} and, for decaying case, we
let βk = {1/k0.6, 1/k0.9}. Note that [3] only tried βk = 1.

(b) NonAdapSQP in Algorithm 2. Following the same setup as above, we try

αk = {0.01, 0.1, 0.5, 1} and αk = {1/k0.6, 1/k0.9}.

g | and |ξk

(c) AdapSQP in Algorithm 3. We let ν = 0.001, ¯α0 = αmax = 1.5, ¯µ0 = ¯(cid:15)0 =
κgrad = 1, ρ = 1.2, β = 0.3, pgrad = pf = 0.1, κf = β/(4αmax) = 0.05, and
Cgrad = Cf = {1, 5, 10, 50}. Recall that Cgrad and Cf are used for selecting
|ξk
f | using (27) and (35), respectively. We try a wide range of Cgrad
and Cf to investigate how do these two tuning parameters aﬀect the scheme
performance. In the above setting, we let ν be small to make Lµ,ν similar
to standard augmented Lagrangian. Another motivation of using small ν is
that, without G(x) in the second penalty of (3), Lµ,ν is an exact augmented
Lagrangian only if ν is suﬃciently small. We let αmax = 1.5 > 1 since, as also
shown later, that the selected stepsize may be greater than 1 in a stochastic
scheme. ¯µ0, ¯(cid:15)0 are initialized at 1 and adaptively updated with iterations.
κgrad, κf , pgrad, pf all aﬀect the generated sample sizes |ξk
f | via
(27) and (35). They play a similar role to parameters Cgrad, Cf . Thus, for
simplicity, we ﬁx them and only try multiple Cgrad, Cf in experiments. As
suggested by Theorem 2, pgrad, pf should be small, so we set them to be
0.1; κf = β/(4αmax) is the largest theoretical value that is allowed. We let
ρ = 1.2 > 1 be a moderate increasing factor. A large ρ may terminate the
While loop in Line 5 of Algorithm 3 (as well as Algorithm 4) faster, while
also resulting in a rough estimate of penalty parameter. We let β = 0.3 be
a (nearly) middle value of interval (0, 0.5), which is the range to have a fast
local rate in deterministic case [25] (although local behavior is not a focus
of the paper and cannot be investigated by our experiments).

g | and |ξk

(d) (cid:96)1 AdapSQP. We adopt the same setup as above, except that the parameter

ν is not required.

For all algorithms, the initialization of primal-dual variables is given by
CUTEst package. Moreover, the package provides deterministic evaluations of
the function, gradient, and Hessian at each iterate. Based on them, we generate
our estimators. In particular, the estimator of fk is drawn from N (fk, σ2); the
estimator of ∇fk is drawn from N (∇fk, σ2(I + 11T )), where 1 denotes the
d-dimensional all one vector; and the (i, j) and (j, i) entries of the estimator
of ∇2fk correspond to the same draw of N ((∇2fk)i,j, σ2). We vary σ2 from
{10−8, 10−4, 10−2, 10−1, 1}. Throughout the simulation, we let Bk = I and set
the maximum iteration budget to be 105. For each algorithm, under each setup
(a combination of a noise level and stepsize/constants Cgrad, Cf ), we perform
5 independent runs. The stopping criterion is set as

(cid:107)¯αk · ( ¯∆xk; ¯∆λk)(cid:107) ≤ 10−6 OR (cid:107)∇Lk(cid:107) ≤ 10−4 OR k ≥ 105.

(52)

38

Na et al.

If the former two cases occur, we say that the algorithm converges, while if
the last case occurs, we say that the algorithm does not converge within the
prespeciﬁed iteration budget. For (cid:96)1 SQP, ¯αk is determined by βk (see [3]) and
we also drop ¯∆λk in the ﬁrst term. We comment that the ﬁrst criterion in
(52) measures the distance between two successive iterates, which depends on
the stochastic search direction and stepsize, and thus is computable without
knowing true quantities in contrast to the second criterion. We add it to stop
algorithms whenever we (tend to) have limited progress for later iterations. It
is triggered if (cid:107)( ¯∆xk; ¯∆λk)(cid:107) is small or/and ¯αk is small. For the ﬁrst case, by
Newton’s system we know (cid:107) ¯∇Lk(cid:107) is small and we should naturally stop. For
the second case, we note that the stepsize in NonAdapSQP is either constant
or a decaying sequence; thus, it is also natural to stop as the stepsize, if it is
small, can only get smaller and smaller. For (cid:96)1 SQP in [3], although ¯αk is not
monotonically decreasing, it is upper and lower controlled by the sequence βk,
which is either constant or decaying (cf. Lemma 3.6). Thus, ¯αk roughly has a
similar trend as βk, and cannot increase signiﬁcantly if it is already very small.
So we stop as well. For AdapSQP and (cid:96)1 AdapSQP, by Lemma 5 we know
that ¯αk cannot be small if the merit function and its gradients are precisely
estimated, which has a high probability in each iteration. Further, whenever
¯αk decreases, a more precise model will be generated for next round (Line 18 of
Algorithm 3). Thus, it is not very likely that ¯αk decreases to a very small value
due to a series of bad estimates, although there is indeed a positive probability
for such a bad scenario. Thus, we make the ﬁrst criterion more restrictive than
the second in (52) to prevent extreme scenarios.

Convergence behavior. We now evaluate convergence behavior of each algo-
rithm. For each run of each setup of each algorithm on each problem, we derive
the KKT residual of the last iterate if the algorithm converges, and then average
residuals over all convergent runs (across 5 runs) as the evaluation result. We
ﬁnd in the implementation that, for two line search algorithms AdapSQP and (cid:96)1
AdapSQP, if they converge for a particular run, they always converge for all
5 runs. However, for NonAdapSQP and (cid:96)1 SQP, occasionally it occurs that
some runs (across 5 runs) do not converge while some runs do. This is likely
because the performance of these two algorithms on some problems tends to
be more random, due to limited samples that are generated. In this scenario,
instead of viewing the problem as a divergent problem, we prefer to average
over convergent runs to improve the performance of NonAdapSQP and (cid:96)1 SQP.

For NonAdapSQP and (cid:96)1 SQP, we have six cases for both: four constant
stepsizes and two decay stepsizes. For AdapSQP and (cid:96)1 AdapSQP, we have four
cases for both, corresponding to Cgrad = Cf = {1, 5, 10, 50}. For each case, we
have ﬁve diﬀerent noise levels of σ2. We draw residual boxplots for all cases in
Figures 1 and 2. Each box reﬂects the residual range of convergent problems.
Each plot in Figure 1 corresponds to a stepsize setup of NonAdapSQP and (cid:96)1
SQP. The results of AdapSQP and (cid:96)1 AdapSQP in Figure 1 do not change
(as their stepsize is selected by stochastic line search), and correspond to the
case where Cgrad = Cf = 1. If the box of NonAdapSQP is missing in the plot,

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

39

which often happens for constant stepsize with large variance, it suggests that
NonAdapSQP does not converge for all problems (within the iteration budget).
Each plot in Figure 2 corresponds to a setup of constants Cgrad, Cf of AdapSQP
and (cid:96)1 AdapSQP.

From Figure 1, we see that line search schemes AdapSQP and (cid:96)1 AdapSQP
perform as well as NonAdapSQP and (cid:96)1 SQP when the noise level is low (e.g.
σ2 = 10−8), while perform signiﬁcantly better when the noise level is high. This
phenomenon can be explained by intrinsic diﬀerences of the two types of stochas-
tic algorithms. AdapSQP and (cid:96)1 AdapSQP adaptively increase the batch sizes
as the iteration proceeds. The large batch size suppresses the eﬀect of the noise
variance. In particular, given |ξk
g | samples, the estimated gradient has variance
σ2/|ξk
g |. Thus, diﬀerent levels of noise
can be interpreted as diﬀerent setups for constants Cgrad, Cf . As we discussed
in Section 4 and will empirically show later (Figures 2, 3, 4), these constants
have a marginal eﬀect on the performance of line search schemes. Consistently,
although their residuals get slightly larger as σ2 increases, both AdapSQP and
(cid:96)1 AdapSQP have a robust performance for diﬀerent noise levels.

g |, which is notably small for large |ξk

In contrast, we see from Figure 1 that both NonAdapSQP and (cid:96)1 SQP are
heavily aﬀected by noise levels and prespeciﬁed sequences. (cid:96)1 SQP performs
better than NonAdapSQP for constant sequences, while worse for decaying
sequences. Both algorithms have higher residuals as σ2 increases. Their sensi-
tivity on σ2 is reasonable because these two algorithms only generate one or
two samples in each iteration, which cannot reduce the estimation variance like
line search schemes do. These two algorithms are also sensitive to prespeciﬁed
sequences. (cid:96)1 SQP involves a novel stepsize selection scheme to enhance adap-
tivity; and we indeed observe that it is more robust than NonAdapSQP for
constant sequences. The latter may converge to a smaller residual compared to
AdapSQP for some problems under a particular setup (e.g. αk = 0.5, σ2 = 0.01),
but it also frequently does not converge within the budget for most, if not all,
of problems if the stepsize is large and the noise level is high. The divergence
can be explained by the violation of upper boundedness condition on the
stepsize; and the upper bound is inversely proportional to σ2 (cf. Theorem
1 and (A.7)). Thus, a larger σ2 implies a more stringent condition on the
stepsize. A more well-designed NonAdapSQP, for example, similar to (cid:96)1 SQP,
may resolve the divergence issue, but we do not investigate this here. However,
even for this basic design without any adaptivity, we see from Figures 1(e), 1(f)
that NonAdapSQP performs better than (cid:96)1 SQP for decaying sequences. This
phenomenon can be explained by [3, Lemma 3.6]. In particular, the selected
stepsize of (cid:96)1 SQP is in an interval whose length is proportional to β2
k. Thus,
for decaying βk, the adaptivity gained by the scheme in [3] is less eﬀective,
especially when βk has a fast decay rate. Overall, NonAdapSQP and (cid:96)1 SQP
are both sensitive to the sequences αk, βk. Compared to NonAdapSQP, (cid:96)1 SQP
is indeed more robust to constant sequences, while does not behave well for
decaying sequences.

From Figure 2, we observe that AdapSQP consistently performs better than
(cid:96)1 AdapSQP in all noise levels for all constants setups, although the improve-

40

Na et al.

(a) αk, βk = 0.01

(b) αk, βk = 0.1

(c) αk, βk = 0.5

(d) αk, βk = 1

(e) αk, βk = k−0.6

(f) αk, βk = k−0.9

Fig. 1 KKT residual boxplot. Each panel corresponds to a stepsize setup, αk for Non-
AdapSQP and βk for (cid:96)1 SQP. Each panel has 5 groups, corresponding to 5 diﬀerent σ2.
The results of AdapSQP and (cid:96)1 AdapSQP on all panels are the same, which correspond to
Cgrad = Cf = 1.

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

41

(a) Cgrad = Cf = 1

(b) Cgrad = Cf = 5

(c) Cgrad = Cf = 10

(d) Cgrad = Cf = 50

Fig. 2 KKT residual boxplot. Each panel corresponds to a setup of constants Cgrad, Cf .

ment is not signiﬁcant and we only consider a basic design for (cid:96)1 AdapSQP, so
that the two methods are not fully comparable. Furthermore, AdapSQP utilizes
more information than (cid:96)1 AdapSQP, such as the Hessians of constraints that are
typically utilized for accelerating the local convergence of SQP schemes. That
said, we believe there is evidence supporting the usage of diﬀerentiable merit
functions. We leave both the theoretical and empirical investigations of local
beneﬁts of the augmented Lagrangian to future work. We also see from Figure
2 that the two methods are robust to tuning parameters Cgrad, Cf —the KKT
residuals do not change much when we vary Cgrad, Cf from 1 to 50. This is
because the sample complexity to ensure conditions (18), (23), (24), studied
in Section 4.2, is proportional to the reciprocal of certain quantities, which
converge to zero as k → ∞ and dominate the order of the sample complexity.
In summary, we observe that the performance of AdapSQP is better than
(cid:96)1 AdapSQP; and these two line search schemes indeed reﬂect the beneﬁts of
generating a large batch set and perform better than NonAdapSQP and (cid:96)1 SQP.
The line search schemes are robust to tuning parameters and noise levels, while
(cid:96)1 SQP and NonAdapSQP are sensitive to prespeciﬁed sequences and noise
levels. Figure 1 also suggests that line search schemes are not preferable over (cid:96)1
SQP and NonAdapSQP for σ2 = 10−8. This is because the latter two methods

42

Na et al.

can have a precise gradient estimate even with one sample. Thus, the beneﬁts
gained from a large batch set is marginal.

Sample complexity. We compare the number of evaluations of the objective
and its gradient, which is equivalent to comparing the corresponding generated
sample sizes. Similar to the KKT residuals, we average generated sample sizes
over all convergent runs. The results are shown in Figures 3 and 4. Each plot
in Figures 3 and 4 corresponds to a setup of constants Cgrad, Cf . The boxes of
NonAdapSQP and (cid:96)1 SQP do not appear in Figure 4 since both methods do
not require objective evaluations (if we prespecify the Lipschitz constants). The
results of these two methods in Figure 3 correspond to the setup αk, βk = 0.01.
In general, with small stepsizes, more iterations are performed so that more
samples are generated. However, even with small stepsizes, we note from Figure
3 that (cid:96)1 SQP and NonAdapSQP require much fewer gradient evaluations than
the two line search schemes when σ2 = 10−8, under which all methods converge
to similar KKT residuals (cf. Figure 1(a)). Thus, clearly, line search schemes
are more expensive to perform when the noise level is small.

Between the two line search schemes, we see from Figures 3 and 4 that Adap-
SQP requires slightly fewer gradient and objective evaluations. The diﬀerence
is more evident for large noise variance. By the observation from Figure 2 that
AdapSQP converges to smaller KKT residuals, Figures 3 and 4 further justify
the choice of the augmented Lagrangian merit function. We point out that
the evaluations of (cid:96)1 AdapSQP may be decreased by a diﬀerent update of the
penalty parameter or a diﬀerent deﬁnition for Ak, Bk; while how to reﬁne the
design of (cid:96)1 AdapSQP is not considered here. In addition, we see that both
AdapSQP and (cid:96)1 AdapSQP have stable performance in terms of the generated
sample sizes for diﬀerent constants setups. This observation again suggests
that both line search schemes are robust to tuning parameters.

We should mention that adopting the augmented Lagrangian merit function
also requires to estimate the Hessian of the objective. We do not show the
Hessian result since all methods using the (cid:96)1 merit function do not require such
information for global convergence, and the number of Hessian evaluations is
dominated by the number of gradient evaluations. The cost of second-order
information may be alleviated to some extent if we take local convergence into
account (as all methods would have to estimate the Hessian then).

Finally, an interesting comparison metric is to ﬁx the total number of sam-
ples (for which diﬀerent methods have diﬀerent usages) and then compare the
attained KKT residuals. To investigate this metric, we again take αk, βk = 0.01
for NonAdapSQP and (cid:96)1 SQP, and vary Cgrad, Cf for AdapSQP and (cid:96)1 Adap-
SQP. For all methods, we adjust the stopping criteria (52) by only checking if
the generated sample size exceeds 106 or not. We see from Figures 3 and 4 that
AdapSQP and (cid:96)1 AdapSQP require more than 106 samples; thus, their perfor-
mance is worsened under the above setup. However, by (52), the performance
of (cid:96)1 SQP and NonAdapSQP is enhanced due to more iterations are performed.
Figure 5 shows the KKT residual boxplot. From Figure 5, we see that two
fully stochastic methods—(cid:96)1 SQP and NonAdapSQP—achieve smaller KKT

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

43

(a) Cgrad = Cf = 1

(b) Cgrad = Cf = 5

(c) Cgrad = Cf = 10

(d) Cgrad = Cf = 50

Fig. 3 Gradient evaluation boxplot. Each panel corresponds to a constants setup. The results
of NonAdapSQP and (cid:96)1 SQP on all panels are the same, which correspond to αk, βk = 0.01.

(a) Cgrad = Cf = 1

(b) Cgrad = Cf = 5

(c) Cgrad = Cf = 10

(d) Cgrad = Cf = 50

Fig. 4 Objective evaluation boxplot. Each panel corresponds to a setup of constants.

44

Na et al.

(a) Cgrad = Cf = 1

(b) Cgrad = Cf = 5

(c) Cgrad = Cf = 10

(d) Cgrad = Cf = 50

Fig. 5 KKT residual boxplot. Each panel corresponds to a setup of constants. The results
of NonAdapSQP and (cid:96)1 SQP on all panels are the same, which correspond to αk, βk = 0.01.

(a) AdapSQP

(b) (cid:96)1 AdapSQP

Fig. 6 Stepsize process. Each ﬁgure has ﬁve rows, from top to bottom, corresponding to σ2 =
10−8, 10−4, 10−2, 10−1, 1. Each plot has 10 lines corresponding to the stepsizes sequences of
10 convergent problems. The dash line corresponds to the unit stepsize.

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

45

residuals than two line search methods—AdapSQP and (cid:96)1 AdapSQP—when
σ2 is small. This suggests that fully stochastic methods are preferable if each
sample can accurately estimate the stochastic quantity. However, from the ﬁg-
ure, we also see that two line search methods are comparable to fully stochastic
methods when σ2 is large. Due to the adaptivity and much fewer iterations
that are conducted, line search methods are preferable in this scenario.

Stochastic stepsize. We now investigate the random process of stepsizes se-
lected by stochastic line search. We consider the setup of Cgrad = Cf = 1, and
use the ﬁrst 10 convergent problems to visualize the process. In particular, for
each problem, we randomly pick one out of ﬁve runs, and show a sequence of
stepsizes that are associated to successful steps (i.e. the Armijo condition is
satisﬁed; cf. Line 9 of Algorithm 3).

From Figure 6, we see that the stochastic stepsize can frequently exceed 1
even if it has been diminished to a small value. Allowing stepsizes to exceed 1 is
a special property in stochastic optimization, which is also shared by [3] but not
common in deterministic optimization. Diﬀerent from NonAdapSQP and [3],
line search can signiﬁcantly increase the stepsize back as desired even if the
current stepsize is small. This property reveals the exclusive beneﬁt of utilizing
line search, and is crucial to enable a fast convergence in practice. In other words,
line search can suggest a stepsize that is larger than the prespeciﬁed, controlled
sequence, especially for large k. We note that the stepsize selection scheme in
(cid:96)1 SQP enjoys certain adaptivity. However, if αk is small, then all the following
stepsizes cannot be large because of the relation between αk and prespeciﬁed
βk in [3, Lemma 3.6].

Although the stepsizes for some problems are ﬁnally small in Figure 6, it
is not a negative evidence of the local beneﬁts of the augmented Lagrangian.
This is simply because studying local behavior requires a diminishing Hessian
modiﬁcation, i.e. Bk ≈ ∇2
xLk, while we ﬁx Bk to be Bk = I in our simulation.
It is unclear how to quantify local beneﬁts based on a stochastic stepsize
process. We leave both theoretical and empirical investigations to future work.

6 Conclusions

We proposed an adaptive StoSQP for solving constrained stochastic optimiza-
tion problems. Our StoSQP scheme adopts a diﬀerentiable exact augmented
Lagrangian as the merit function and incorporates a line search procedure to
select the stepsize. To this end, we ﬁrst revisited a classical SQP method in [25]
for deterministic objectives. We simpliﬁed that algorithm and then designed a
non-adaptive StoSQP, where the stepsize is given by a deterministic prespec-
iﬁed sequence. Finally, using a stochastic line search method, we developed
an adaptive StoSQP that chooses the stepsize adaptively in each iteration. By
adjusting the condition on selecting the penalty parameter, the algorithm au-
tomatically avoids converging to stationary points of the merit function where
KKT residuals do not vanish. For both non-adaptive StoSQP and adaptive

46

Na et al.

StoSQP, we established an “almost sure” convergence result, which diﬀers from
the result of convergence in expectation in [3].

One future work is to design StoSQP algorithms for solving inequality-
constrained stochastic optimization problems. Moreover, establishing a local
convergence result is very promising, which helps to understand whether diﬀer-
entiable merit functions enjoy local beneﬁts or not in stochastic optimization.
In addition, the iteration complexity analysis of our StoSQP remains an open
question, that requires a deeper understanding on the random walk of the se-
lected penalty parameter. Finally, applying some acceleration techniques such
as momentum and heavy ball to StoSQP is also an interesting future research
direction.

Acknowledgments

We would like to thank Associated Editor and two anonymous reviewers for
helpful and instructive comments. Sen Na would like to thank Nick Gould
for helping with the implementation of CUTEst in Julia. This material was
completed in part with resources provided by the University of Chicago Research
Computing Center. This material was based upon work supported by the
U.S. Department of Energy, Oﬃce of Science, Oﬃce of Advanced Scientiﬁc
Computing Research (ASCR) under Contract DE-AC02-06CH11347 and by
NSF through award CNS-1545046.

A Proofs of Section 3

A.1 Proof of Lemma 1

The expectation is taken over randomness of ξk
H , which means that the k-th iterate
(xk, λk) is supposed to be ﬁxed. By the unbiasedness condition in Assumption 2, we have

g and ξk

E

ξk
g

[ ¯∆xk] = E[ ¯∆xk | xk, λk]

(cid:20)

(9)
= −E

= − (cid:0)I 0(cid:1) (cid:16) Bk GT
k
Gk 0

(cid:17)−1

E

(cid:20)(cid:16) ¯∇xLk
ck

and

(cid:17)−1 (cid:16) ¯∇xLk

(cid:17) (cid:12)
(cid:0)I 0(cid:1) (cid:16) Bk GT
(cid:12)
xk, λk
k
(cid:12)
Gk 0
(cid:12)
(cid:21) (11)
= − (cid:0)I 0(cid:1) (cid:16) Bk GT
k
Gk 0

(cid:17) (cid:12)
(cid:12)
xk, λk
(cid:12)
(cid:12)

ck

(cid:21)

(cid:17)−1 (cid:16) ∇xLk

ck

(cid:17) (5)

= ∆xk,

E

g ,ξk
ξk
H

[ ¯∆λk] = E[ ¯∆λk | xk, λk]

(9)
= −E

(cid:104)

(GkGT

k )−1Gk

k )−1GkE[ ¯∇xLk | xk, λk] − (GkGT
k )−1E[ ¯M T
k )−1Gk∇xLk − (GkGT

k )−1Gk∇xLk − (GkGT

k )−1M T

k ∆xk

= −(GkGT
= −(GkGT
(11)
= −(GkGT
(5)
= ∆λk,

¯∆xk | xk, λk

(cid:105)

¯∇xLk + (GkGT

k )−1 ¯M T
k
¯∆xk | xk, λk]
k | xk, λk]E[ ¯∆xk | xk, λk]

k )−1E[ ¯M T
k

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

47

where the fourth equality is due to the independence between ξk

g and ξk

H . Moreover, we have

E

ξk
g

(cid:2)(cid:107) ¯∆xk(cid:107)2(cid:3) = (cid:107)∆xk(cid:107)2 + E

(9)
= (cid:107)∆xk(cid:107)2 + E

ξk
g
(cid:20)(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:2)(cid:107) ¯∆xk − ∆xk(cid:107)2(cid:3)

(cid:0)I 0(cid:1) (cid:16) Bk GT
k
Gk 0
(cid:123)(cid:122)
(cid:124)
=:K

(cid:17)−1

(cid:16) ¯gk−∇fk
0

(cid:125)

(cid:17) (cid:13)
(cid:13)
(cid:13)
(cid:13)

2(cid:12)
(cid:12)
xk, λk
(cid:12)
(cid:12)

(cid:21)

(11)
≤ (cid:107)∆xk(cid:107)2 + (cid:107)K(cid:107)2ψ.

(A.1)

We now bound (cid:107)K(cid:107). Suppose GT
Image(GT
Ker(Gk). By Assumption 1, we know Ek is nonsingular and ZT
verifying

k = YkEk where Yk has orthonormal columns spanning
k ) and Ek is a square matrix, and suppose Zk has orthonormal columns spanning
k BkZk (cid:23) γRH I. By directly

K = I, one can show

(cid:17)

(cid:16) Bk GT
k
Gk 0

(cid:18)

K =

Zk(ZT

k BkZk)−1ZT
k
k BkZk)−1ZT

k (I−BkZk(ZT

E−1

k Y T

k ) E−1

k Y T

(I−Zk(ZT
k (BkZk(ZT

k BkZk)−1ZT

k Bk)YkE−1

k

k BkZk)−1ZT

k Bk−Bk)YkE−1

k

(cid:19)

.

Noting that (cid:107)E−1
k )T (cid:107) = (cid:107)(GkGT
1/γRH , we can bound (cid:107)K(cid:107) by summing the spectrum norm of each block, and get

k (cid:107)2 = (cid:107)E−1

k (E−1

k )−1(cid:107)

k BkZk)−1(cid:107) ≤

(12)
≤ 1/κ1,G, and (cid:107)(ZT

(cid:107)K(cid:107) ≤

1
γRH

+

√

2
κ1,G

(cid:18)

1 +

(cid:19)

+

κB
γRH

1
κ1,G

(cid:32)

κ2
B
γRH

(cid:33)

+ κB

.

Since κB ≥ 1 ≥ γRH ∨ κ1,G, we can simplify the bound by

(cid:107)K(cid:107) ≤

√

5κB
κ1,GγRH

+

2κ2
B
κ1,GγRH

≤

7κ2
B
κ1,GγRH

.

Plugging the above inequality into (A.1), we have

E

ξk
g

(cid:2)(cid:107) ¯∆xk(cid:107)2(cid:3) ≤ (cid:107)∆xk(cid:107)2 +

49κ4
B
1,Gγ2
κ2

RH

ψ.

(A.2)

Similarly, we can bound E

g ,ξk
ξk
H

[(cid:107) ¯∆λk(cid:107)2] as follows.

E

g ,ξk
ξk
H

(cid:2)(cid:107) ¯∆λk(cid:107)2(cid:3) = (cid:107)∆λk(cid:107)2 + E

(cid:2)(cid:107) ¯∆λk − ∆λk(cid:107)2(cid:3)

g ,ξk
ξk
H
k )−1 (cid:16)

(cid:20)(cid:13)
(cid:13)(GkGT
(cid:13)

Gk

¯∇xLk + ¯M T
k

¯∆xk − Gk∇xLk − Mk∆xk

(9)
= (cid:107)∆λk(cid:107)2 + E

g ,ξk
ξk
H

(12)
≤ (cid:107)∆λk(cid:107)2 +

(12)
≤ (cid:107)∆λk(cid:107)2 +

(11)
≤ (cid:107)∆λk(cid:107)2 +

2
κ2

1,G

2
κ2

1,G

2
κ2

1,G

2(cid:21)

(cid:17)(cid:13)
(cid:13)
(cid:13)
k ∆xk(cid:107)2(cid:105)(cid:111)

(cid:110)

E

ξk
g

(cid:104)(cid:13)
(cid:13)Gk

¯∇xLk − Gk∇xLk

2(cid:105)

(cid:13)
(cid:13)

+ E

g ,ξk
ξk
H

(cid:104)

(cid:107) ¯M T
k

¯∆xk − M T

(cid:110)

(cid:110)

κ2,GE

ξk
g

(cid:2)(cid:107)¯gk − ∇fk(cid:107)2(cid:3) + E

g ,ξk
ξk
H

(cid:104)

(cid:107) ¯M T
k

¯∆xk − M T

k ∆xk(cid:107)2(cid:105)(cid:111)

κ2,Gψ + E

g ,ξk
ξk
H

(cid:104)

(cid:107) ¯M T
k

¯∆xk − M T

k ∆xk(cid:107)2(cid:105)(cid:111)

.

(A.3)

48

Na et al.

For the last term, we have

(cid:104)

E

g ,ξk
ξk
H

(cid:107) ¯M T
k

(cid:104)

(cid:104)

= E

g ,ξk
ξk
H

= E

g ,ξk
ξk
H

(12)
≤ E

ξk
H
+ E

ξk
H

¯∆xk − M T

k ∆xk(cid:107)2(cid:105)
(cid:107)( ¯Mk − Mk)T ( ¯∆xk − ∆xk) + M T

k ( ¯∆xk − ∆xk) + ( ¯Mk − Mk)T ∆xk(cid:107)2(cid:105)

(cid:107)( ¯Mk − Mk)T ( ¯∆xk − ∆xk)(cid:107)2 + (cid:107)M T

k ( ¯∆xk − ∆xk)(cid:107)2 + (cid:107)( ¯Mk − Mk)T ∆xk(cid:107)2(cid:105)

(cid:2)(cid:107) ¯Mk − Mk(cid:107)2(cid:3) E

ξk
g

(cid:2)(cid:107)( ¯∆xk − ∆xk)(cid:107)2(cid:3) + κ2

M

E

ξk
g

(cid:2)(cid:107)( ¯∆xk − ∆xk)(cid:107)2(cid:3)

(cid:2)(cid:107) ¯Mk − Mk(cid:107)2(cid:3) (cid:107)∆xk(cid:107)2,

(A.4)

where the second equality is due to the independence between ξk

g and ξk

H . We note that

(cid:107) ¯Mk − Mk(cid:107)2

(8)
≤ 2(cid:107)Gk(cid:107)2(cid:107) ¯Hk − ∇2fk(cid:107)2 + 2(cid:107) ¯Tk − Tk(cid:107)2
(8)
≤ 2(cid:107)Gk(cid:107)2(cid:107) ¯Hk − ∇2fk(cid:107)2 + 2(cid:107)∇f (xk; ξk

H ) − ∇fk(cid:107)2

m
(cid:88)

i=1

(cid:107)∇2ci(xk)(cid:107)2

(12)
≤ 2κ2,G(cid:107) ¯Hk − ∇2fk(cid:107)2 + 2κ2

xc(cid:107)∇f (xk; ξk

∇2

H ) − ∇fk(cid:107)2.

Taking expectation over ξk

H on both sides and using (11), we have

E

ξk
H

[(cid:107) ¯Mk − Mk(cid:107)2] ≤ 2(κ2,G + κ2

xc)ψ.
∇2

(A.5)

Combining (A.5) with (A.4) and (A.1), we obtain

E

g ,ξk
ξk
H

(cid:104)

(cid:107) ¯M T
k

¯∆xk − M T

k ∆xk(cid:107)2(cid:105)

(cid:110)

≤

2(κ2,G + κ2

xc)ψ + κ2

M

∇2

(cid:111) 49κ4
B
1,Gγ2
κ2

RH

ψ + 2(κ2,G + κ2

xc)ψ(cid:107)∆xk(cid:107)2.

∇2

Plugging the above inequality into (A.3),

E

g ,ξk
ξk
H

(cid:2)(cid:107) ¯∆λk(cid:107)2(cid:3) ≤ (cid:107)∆λk(cid:107)2 +

4(κ2,G + κ2

∇2

xc

κ2

1,G

)ψ

(cid:107)∆xk(cid:107)2

(cid:40)

+

2κ2,G
κ2

1,G

+

(cid:16)

98κ4
B
1,Gγ2
κ4

RH

Combining (A.6) with (A.2), we can deﬁne

2(κ2,G + κ2

xc)ψ + κ2

M

∇2

(cid:41)

(cid:17)

ψ.

(A.6)

4(κ2,G + κ2

∇2

xc

κ2

1,G

)ψ

∨

2κ2,G
κ2

1,G

+

49κ4
B
1,Gγ2
κ2

RH






·

1 +

Υ0 := 1 +

and have

4(κ2,G + κ2
∇2
κ2

xc

1,G

)ψ + 2κ2
M






(A.7)

E

g ,ξk
ξk
H

2(cid:35)

(cid:34)(cid:13)
(cid:18) ¯∆xk
(cid:13)
(cid:13)
¯∆λk
(cid:13)

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

≤ Υ0

(cid:32)(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:18)∆xk
∆λk

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

(cid:33)

+ ψ

.

This completes the proof.

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

49

A.2 Proof of Theorem 1

We require the following lemmas.

Lemma 10 Let (∆xk, ∆λk) be solved by (5). Then for any µ, ν,

(cid:18)∇xLk
∇λLk

µ,ν

µ,ν

(cid:19)

(cid:19)T (cid:18)∆xk
∆λk

= (∆xk)T ∇xLk − µ(cid:107)ck(cid:107)2 + cT

k ∆λk − ν(cid:107)Gk∇xLk(cid:107)2.

Proof We have

(cid:18)∇xLk
∇λLk

µ,ν

µ,ν

(cid:19)T (cid:18)∆xk
∆λk

(cid:19) (4)

= (∆xk)T (I + νMkGk) ∇xLk + µ(∆xk)T GT

k ck + (∆λk)T ck

+ ν(∆λk)T GkGT

k Gk∇xLk

(5)
= (∆xk)T ∇xLk − µ(cid:107)ck(cid:107)2 + cT

k ∆λk − ν(cid:107)Gk∇xLk(cid:107)2.

This completes the proof.

Lemma 11 Under Assumption 1, we have

(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:18)∆xk
∆λk

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

≤

3κ2
M
κ2

1,G

(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:18) ∆xk

Gk∇xLk

2

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

.

Proof By (5), we know

(cid:107)∆λk(cid:107)2 =(cid:107)(GkGT

k )−1(Gk∇xLk + M T

k ∆xk)(cid:107)2

(12)
≤

2
κ2

1,G

((cid:107)Gk∇xLk(cid:107)2 + κ2

M (cid:107)∆xk(cid:107)2)

≤

2κ2
M
κ2

1,G

((cid:107)Gk∇xLk(cid:107)2 + (cid:107)∆xk(cid:107)2).

(since κM ≥ 1 ≥ κ1,G)

This completes the proof.

Now, we are ready for proving Theorem 1. We note that

(cid:117)(cid:116)

(cid:117)(cid:116)

(cid:107)∇xLk(cid:107)2 = (cid:107)(I − GT
(5)
= (cid:107)(I − GT

k (GkGT

k )−1Gk)∇xLk(cid:107)2 + (cid:107)GT

k (GkGT

k )−1Gk∇xLk(cid:107)2

(12)
≤ κ2

B(cid:107)∆xk(cid:107)2 +

k )−1Gk)Bk∆xk(cid:107)2 + (cid:107)GT
k (GkGT
1
κ1,G

(cid:107)Gk∇xLk(cid:107)2,

k (GkGT

k )−1Gk∇xLk(cid:107)2

(cid:107)ck(cid:107)2 (5)

= (cid:107)Gk∆xk(cid:107)2

(12)
≤ κ2,G(cid:107)∆xk(cid:107)2.

Since κ2,G ∧ κB ≥ 1 ≥ κ1,G,

(cid:107)∇Lk(cid:107)2 ≤

κ2
B + κ2,G
κ1,G

(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:18) ∆xk

Gk∇xLk

2

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

.

Plugging the above inequality into (15), we have

E

g ,ξk
ξk
H

[Lk+1

µ,ν ] ≤ Lk

µ,ν −

˜δκ1,G
αk
2(κ2
B + κ2,G)

(cid:107)∇Lk(cid:107)2 +

Υ0κLµ,ν ψ
2

α2
k.

(A.8)

Case 1: constant stepsize. If αk = α, we take full expectation of (A.8), sum over k =
0, . . . , K, and have

min
X ×Λ

Lµ,ν − L0

µ,ν ≤ −

˜δκ1,G
B + κ2,G)

2(κ2

· α

K
(cid:88)

k=0

E[(cid:107)∇Lk(cid:107)2] +

Υ0κLµ,ν ψ(K + 1)
2

α2.

50

Na et al.

Rearranging the above inequality leads to

1
K + 1

K
(cid:88)

k=0

E[(cid:107)∇Lk(cid:107)2] ≤

2(κ2

B + κ2,G)
˜δκ1,G

·

L0

µ,ν − minX ×Λ Lµ,ν
(K + 1)α

+

Υ0(κ2

B + κ2,G)κLµ,ν ψ

˜δκ1,G

α.

Case 2: decaying stepsize. Let us deﬁne two sequences

sk = Lk

µ,ν +

Υ0κLµ,ν ψ
2

∞
(cid:88)

i=k

α2
i ,

ek =

˜δκ1,G
αk
2(κ2
B + κ2,G)

(cid:107)∇Lk(cid:107)2.

From (A.8), we know

E

g ,ξk
ξk
H

[sk+1] = E

g ,ξk
ξk
H

[Lk+1

µ,ν ] +

Υ0κLµ,ν ψ
2

∞
(cid:88)

α2
i

i=k+1

≤ Lk

µ,ν −

˜δκ1,G
αk
2(κ2
B + κ2,G)

(cid:107)∇Lk(cid:107)2 +

Υ0κLµ,ν ψ
2

∞
(cid:88)

i=k

α2

i = sk − ek.

Since ek ≥ 0, {sk − minX ×Λ Lµ,ν }k is a positive supermartingale. By [17, Theorem 4.2.12],
we have sk → s almost surely for some random variable s and E[s] ≤ s0 < ∞. Therefore,

∞
(cid:88)

E[

k=0

ek] =

∞
(cid:88)

k=0

E [ek] ≤

∞
(cid:88)

k=0

E[sk] − E[sk+1] < ∞,

where the ﬁrst equality is due to Fubini-Tonelli theorem [17, Theorem 1.7.2]. The above
display implies that (cid:80)∞
k=0 ek < ∞ almost surely. Moreover, since (cid:80)∞
k=0 αk = ∞, we obtain
(cid:80)∞
k=0 αk = 0 and lim inf k→0 (cid:107)∇Lk(cid:107) = 0 almost surely. This completes the proof.

k=0 ek/ (cid:80)∞

B Proofs of Section 4

B.1 Proof of Lemma 3

(·) = P (· | xk, λk, ¯∆xk, ¯∆λk) be the conditional probability over randomness in ξk
f .

Let Pξk
f
We have that

(cid:12)
(cid:12) ¯Lk

¯µk,ν −Lk

¯µk,ν

(cid:12)
(cid:12)

(21)
≤ (cid:12)

(cid:12) ¯fk − fk

(cid:12)
(cid:12) +

≤ (cid:12)

(cid:12) ¯fk − fk

(cid:12)
(cid:12) +

ν
2
ν
2

(cid:12)
(cid:12)(cid:107)Gk( ¯∇fk + GT
(cid:12)
(cid:107)Gk(cid:107)2 (cid:13)

(cid:13) ¯∇fk − ∇fk

k λk)(cid:107)2 − (cid:107)Gk(∇fk + GT

(cid:13)
(cid:13)

2 + ν(cid:107)Gk(∇fk + GT

k λk)(cid:107)2(cid:12)
(cid:12)
(cid:12)
k λk)(cid:107)(cid:107)Gk(cid:107)(cid:107) ¯∇fk − ∇fk(cid:107)

(12)
≤ (cid:12)

(cid:12) ¯fk − fk

(cid:12)
(cid:12) + νκ2,G

(cid:0)(cid:13)
(cid:13) ¯∇fk − ∇fk

(cid:13)
(cid:13) + κ∇xL

(cid:1) (cid:107) ¯∇fk − ∇fk(cid:107).

(B.1)

Let us denote

then the above display implies that | ¯Lk

mk = −κf ¯α2
k

(cid:19)

(cid:18) ¯∇xLk
¯∇λLk
¯µk,ν − Lk

(cid:19)T (cid:18) ¯∆xk
¯∆λk

¯µk,ν
¯µk,ν
¯µk,ν | ≤ mk by requiring

,

(cid:12)
(cid:12) ¯fk − fk

(cid:12)
(cid:12) ≤

mk
2

and

(cid:13)
(cid:13) ¯∇fk − ∇fk

(cid:13)
(cid:13) ≤

mk
4νκ2,Gκ∇xL

∧ 1.

The above condition is further implied by requiring

(cid:12)
(cid:12) ¯fk − fk

(cid:12) ∨ (cid:13)
(cid:12)

(cid:13) ¯∇fk − ∇fk

(cid:13)
(cid:13) ≤

mk ∧ 1
4νκ2,Gκ∇xL ∨ 2

.

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

51

Thus, we apply Bernstein inequality [43, Theorem 6.1.1] and have that if

|ξk

f | ≥

16 max{Ω0, Ω1}2(4ν2κ2

2,Gκ2

∇xL ∨ 1)

m2

k ∧ 1

log

(cid:19)

,

(cid:18) 8d
pf

(B.2)

then

Pξk

f

¯µk,ν | > mk) ≤ pf /2.

(| ¯Lk

¯µk,ν − Lk
¯µk,ν − Lsk

(| ¯Lsk

Under (B.2), we also have Pξk
(23) holds. As for the condition (24), we apply (B.1) to obtain

f

¯µk,ν | > mk) ≤ pf /2, which implies the condition

E

ξk
f

(cid:2)(cid:12)
(cid:12) ¯Lk

¯µk,ν − Lk

¯µk,ν

(cid:12)
2(cid:3) ≤ 2E
(cid:12)

[| ¯fk − fk|2] + 2ν2κ2

2,G (Ω1 + κ∇xL)2 E

[(cid:107) ¯∇fk − ∇fk(cid:107)2]

ξk
f

ξk
f
2Ω2

≤

0 + 2ν2κ2

1 (Ω1 + κ∇xL)2
2,GΩ2
|ξk
f |

,

where the last inequality applies the variance bound for the sample average, that is E[| ¯fk −
f | (and similar for E[(cid:107) ¯∇fk − ∇fk(cid:107)2]). Following the
fk|2] = E[|f (xk; ξ) − fk|2]/|ξk
same calculation, we can show the same bound for | ¯Lsk
¯µk,ν |2. Thus, the condition (24)
holds if

f | ≤ Ω2

0 /|ξk

2Ω2

0 + 2ν2κ2

|ξk

f | ≥

¯µk,ν − Lsk
1 (Ω1 + κ∇xL)2
2,GΩ2
¯(cid:15)2
k

.

(B.3)

Combining (B.2) and (B.3) and taking maximum on the right hand side, the conditions (23)
and (24) are satisﬁed simultaneously when

|ξk

f | ≥

Cf log

m2

k ∧ ¯(cid:15)2

(cid:17)

(cid:16) 8d
pf
k ∧ 1

,

(B.4)

with Cf = 16 max{Ω0, Ω1}2{1 ∨ 4ν2κ2
Otherwise, by (19) we know ¯∆xk = 0 and Gk
which contradicts (cid:107)( ¯∆xk, ¯∆λk)(cid:107) > 0 in Assumption 3. This completes the proof.

2,G(Ω1 ∨ κ∇xL)2}. Finally, we note that mk (cid:54)= 0.
¯∇xLk = 0. Then, by (9) we have ¯∆λk = 0,

B.2 Proof of Proposition 2

Note that

¯∇xLk+ν ¯MkGk
=(I − GT

¯∇xLk + GT
k (GkGT

k ck

(9)
= − (I − GT

k (GkGT

k )−1Gk) ¯∇xLk + GT
¯∆xk +

k )−1Gk)Bk

k (GkGT
(cid:16)

k )−1Gk

¯∇xLk + ν ¯MkGk

¯∇xLk + GT

k ck

GT

k (GkGT

k )−1 + ν ¯Mk

(cid:17)

Gk

¯∇xLk − GT

k Gk

¯∆xk.

Thus, we know

(cid:18) ¯∇xLk + ν ¯MkGk
k Gk
k (GkGT

νGkGT
(cid:18)−(I − GT

¯∇xLk + GT
¯∇xLk
k )−1Gk)Bk − GT

k ck

(cid:19)

=

0

k Gk GT

k (GkGT

k )−1 + ν ¯Mk

νGkGT
k

(cid:19) (cid:18) ¯∆xk
Gk

¯∇xLk

(cid:19)

.

(B.5)

Using (12) and (36), we upper bound the spectrum norm of each block of the right hand
side matrix, and deﬁne

Υ1 = κB + κ2,G +

√

1
κ1,G

+ ν(κ ¯M + κ2,G)

52

Na et al.

with κ ¯M given in (36), then the ﬁrst inequality in (39) is satisﬁed. Furthermore, we know

(cid:18) ¯∆xk
Gk

¯∇xLk

(cid:19) (9)
=

(cid:18)

− ¯M T
k

¯∆xk
¯∆xk − GkGT
k

¯∆λk

(cid:19)

=

(cid:18) I

0
k −GkGT
k

− ¯M T

(cid:19) (cid:18) ¯∆xk
¯∆λk

(cid:19)

.

Thus, we let

1
1 + κ ¯M + κ2,G
and the second inequality in (39) is satisﬁed. Moreover,

Υ2 =

−(GkGT

k )−1 ¯M T

k

(cid:18) ¯∆xk
¯∆λk

(cid:18)

(cid:19) (9)
=

Thus, we let

¯∆xk

¯∆xk − (GkGT
(cid:18)

¯∇xLk

k )−1Gk
I
k )−1 ¯M T
−(GkGT

=

(cid:19)

0

k −(GkGT

k )−1

(cid:19) (cid:18) ¯∆xk
Gk

¯∇xLk

(cid:19)

.

Υ3 = 1 +

κ ¯M + 1
κ1,G

and the third inequality in (39) is satisﬁed. Finally,

(cid:33)

(cid:32) ¯∇xLk
¯∇λLk

¯µ ¯K ,ν
¯µ ¯K ,ν

(20)
=

(cid:18)(cid:0)I + ν ¯MkGk

(cid:1) ¯∇xLk + ¯µ ¯K GT

k ck

(cid:19)

ck + νGkGT

k Gk

¯∇xLk

(cid:18)−(I − GT

k (GkGT

k )−1Gk)Bk − ¯µ ¯K GT

k Gk GT

k (GkGT

k )−1 + ν ¯Mk

(B.5)
=

νGkGT
k

(cid:19) (cid:18) ¯∆xk
Gk

¯∇xLk

(cid:19)

.

−Gk

By Lemma 4, we know ¯µ ¯K ≤ ˜µ with deterministic ˜µ. Thus, we let

Υ4 = κB + (˜µ + 1)κ2,G +

√

1
κ1,G

+ ν(κ ¯M + κ2,G)

and the fourth inequality in (39) is satisﬁed. This completes the proof.

B.3 Proof of Lemma 8

We consider the following three cases.
Case 1: reliable step. For the reliable step, we apply Lemma 6 and (43) is changed to

Lk+1
¯µ ¯K ,ν − Lk

¯µ ¯K ,ν ≤

¯αkβ
2

(cid:32) ¯∇xLk
¯∇λLk

¯µ ¯K ,ν
¯µ ¯K ,ν

(19)
≤ −

¯αkβ(γRH ∧ ν)
8

(cid:19) (26)
≤

(cid:33)T (cid:18) ¯∆xk
¯∆λk
(cid:18) ¯∆xk
Gk

(cid:13)
(cid:13)
(cid:13)
(cid:13)

¯∇xLk

¯αkβ
4

(cid:32) ¯∇xLk
¯∇λLk

¯µ ¯K ,ν
¯µ ¯K ,ν

(cid:33)T (cid:18) ¯∆xk
¯∆λk

(cid:19)

−

¯(cid:15)k
4

2

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

−

¯(cid:15)k
4

.

(B.6)

By Line 13 of Algorithm 3, ¯(cid:15)k+1 − ¯(cid:15)k = (ρ − 1)¯(cid:15)k, while (44) is the same. Thus, by the
condition on ω in (41) we obtain

Φk+1
¯µ ¯K ,ν,ω−Φk

¯µ ¯K ,ν,ω ≤ −

β(γRH ∧ ν)ω
32

¯αk

(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:18) ¯∆xk
Gk

¯∇xLk

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

2

−

ω¯(cid:15)k
8

+ρ(1−ω) ¯αk

Case 2: unreliable step. For the unreliable step, (B.6) is changed to

(cid:32)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

∇xLk
∇λLk

¯µ ¯K ,ν
¯µ ¯K ,ν

2

(cid:33)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(B.7)

.

Lk+1
¯µ ¯K ,ν − Lk

¯µ ¯K ,ν ≤

¯αkβ
2

(cid:32) ¯∇xLk
¯∇λLk

¯µ ¯K ,ν
¯µ ¯K ,ν

(cid:33)T (cid:18) ¯∆xk
¯∆λk

(cid:19) (19)

≤ −

β(γRH ∧ ν)
4

¯αk

(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:18) ¯∆xk
Gk

¯∇xLk

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

2

.

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

53

By Line 15 of Algorithm 3, ¯(cid:15)k+1 − ¯(cid:15)k = −(1 − 1/ρ)¯(cid:15)k and (44) is the same. Thus, under the
condition on ω in (41),

Φk+1
¯µ ¯K ,ν,ω − Φk

¯µ ¯K ,ν,ω ≤ −

β(γRH ∧ ν)ω
32

¯αk

(cid:13)
(cid:18) ¯∆xk
(cid:13)
(cid:13)
Gk
(cid:13)

¯∇xLk

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

−

1
2

(1 − ω)

(cid:18)

1 −

(cid:19)

1
ρ

¯(cid:15)k + ρ(1 − ω) ¯αk

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

Case 3: unsuccessful step. The result in (45) holds.

Combining (B.7), (B.8), (45), we have

(cid:32)

∇xLk
∇λLk

¯µ ¯K ,ν
¯µ ¯K ,ν

2

(cid:33)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

.

(B.8)

(cid:32)

∇xLk
∇λLk

¯µ ¯K ,ν
¯µ ¯K ,ν

2

(cid:33)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

,

Φk+1
¯µ ¯K ,ν,ω − Φk

¯µ ¯K ,ν,ω ≤ ρ(1 − ω) ¯αk

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

which completes the proof.

B.4 Proof of Lemma 9

We consider the following three cases.
Case 1: reliable step. We have

Lk+1
¯µ ¯K ,ν − Lk

¯µ ¯K ,ν ≤ |Lk+1

¯µ ¯K ,ν
¯µ ¯K ,ν

(25)
≤ ¯αkβ

(26)
≤

¯αkβ
2

(cid:32) ¯∇xLk
¯∇λLk
(cid:32) ¯∇xLk
¯∇λLk

¯µ ¯K ,ν
¯µ ¯K ,ν

(19)
≤ −

β ¯αk(γRH ∧ ν)
4

(cid:33)T (cid:18) ¯∆xk
¯∆λk
(cid:33)T (cid:18) ¯∆xk
¯∆λk
(cid:18) ¯∆xk
Gk

(cid:13)
(cid:13)
(cid:13)
(cid:13)

¯µ ¯K ,ν | + ¯Lsk
¯µ ¯K ,ν − ¯Lsk
(cid:19)

¯µ ¯K ,ν − ¯Lk

¯µ ¯K ,ν + | ¯Lk

¯µ ¯K ,ν − Lk

¯µ ¯K ,ν |

+ | ¯Lsk

¯µ ¯K ,ν − Lsk

¯µ ¯K ,ν | + | ¯Lk

¯µ ¯K ,ν − Lk

¯µ ¯K ,ν |

(cid:19)

−

¯(cid:15)k
2

+ | ¯Lsk

¯µ ¯K ,ν − Lsk

¯µ ¯K ,ν | + | ¯Lk

¯µ ¯K ,ν − Lk

¯µ ¯K ,ν |

2

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

−

¯(cid:15)k
2

+ | ¯Lsk

¯µ ¯K ,ν − Lsk

¯µ ¯K ,ν | + | ¯Lk

¯µ ¯K ,ν − Lk

¯µ ¯K ,ν |.(B.9)

¯∇xLk

By Line 13 of Algorithm 3, ¯(cid:15)k+1 − ¯(cid:15)k = (ρ − 1)¯(cid:15)k, and (44) holds as well. By (41), we have

Φk+1
¯µ ¯K ,ν,ω − Φk

¯µ ¯K ,ν,ω ≤ −

β(γRH ∧ ν)ω
32
¯µ ¯K ,ν − Lsk
+ ω(| ¯Lsk

(cid:18) ¯∆xk
Gk
¯µ ¯K ,ν | + | ¯Lk

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)
¯µ ¯K ,ν − Lk

¯∇xLk

(cid:13)
(cid:13)
(cid:13)
(cid:13)

¯αk

2

−

¯µ ¯K ,ν |).

ω¯(cid:15)k
8

+ ρ(1 − ω) ¯αk

(cid:32)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

∇xLk
∇λLk

¯µ ¯K ,ν
¯µ ¯K ,ν

2

(cid:33)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(B.10)

Case 2: unreliable step. The inequality in (B.9) is changed to

Lk+1
¯µ ¯K ,ν − Lk

¯µ ¯K ,ν ≤ |Lk+1

¯µ ¯K ,ν | + ¯Lsk

¯µ ¯K ,ν + | ¯Lk

¯µ ¯K ,ν − Lk

¯µ ¯K ,ν |

¯µ ¯K ,ν − ¯Lsk
(cid:32) ¯∇xLk
¯∇λLk

¯µ ¯K ,ν
¯µ ¯K ,ν

(25)
≤ ¯αkβ

(19)
≤ −

β ¯αk(γRH ∧ ν)
2

¯µ ¯K ,ν − ¯Lk
(cid:19)

(cid:33)T (cid:18) ¯∆xk
¯∆λk
(cid:13)
(cid:18) ¯∆xk
(cid:13)
(cid:13)
Gk
(cid:13)

¯∇xLk

+ | ¯Lsk

¯µ ¯K ,ν − Lsk

¯µ ¯K ,ν | + | ¯Lk

¯µ ¯K ,ν − Lk

¯µ ¯K ,ν |

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

+ | ¯Lsk

¯µ ¯K ,ν − Lsk

¯µ ¯K ,ν | + | ¯Lk

¯µ ¯K ,ν − Lk

¯µ ¯K ,ν |.

We further have ¯(cid:15)k+1 − ¯(cid:15)k = −(1 − 1/ρ)¯(cid:15)k and (44) holds as well. Using (41), we get

Φk+1
¯µ ¯K ,ν,ω − Φk

¯µ ¯K ,ν,ω ≤ −
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:32)

+ ρ(1 − ω) ¯αk

β(γRH ∧ ν)ω
32

¯αk

(cid:13)
(cid:18) ¯∆xk
(cid:13)
(cid:13)
Gk
(cid:13)

¯∇xLk

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

−

1
2

(1 − ω)

(cid:18)

1 −

(cid:19)

1
ρ

¯(cid:15)k

∇xLk
∇λLk

¯µ ¯K ,ν
¯µ ¯K ,ν

2

(cid:33)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

+ ω(| ¯Lsk

¯µ ¯K ,ν − Lsk

¯µ ¯K ,ν | + | ¯Lk

¯µ ¯K ,ν − Lk

¯µ ¯K ,ν |).

(B.11)

54

Na et al.

Case 3: unsuccessful step. The result in (45) holds.

Combining (B.10), (B.11), (45), we obtain

Φk+1
¯µ ¯K ,ν,ω − Φk

¯µ ¯K ,ν,ω ≤ ρ(1 − ω) ¯αk

which completes the proof.

(cid:32)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

∇xLk
∇λLk

¯µ ¯K ,ν
¯µ ¯K ,ν

2

(cid:33)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

+ ω(| ¯Lsk

¯µ ¯K ,ν − Lsk

¯µ ¯K ,ν | + | ¯Lk

¯µ ¯K ,ν − Lk

¯µ ¯K ,ν |),

C Additional Simulation Results

We list the detailed results for each selected CUTEst problem. For each problem and each
method, we have ﬁve levels of noise. For all four methods, we report the smallest result among
diﬀerent setups. In particular, for NonAdapSQP and (cid:96)1 SQP, we take the minimum over all
six setups of stepsize sequences (four constant sequences and two decaying sequences). For
AdapSQP and (cid:96)1 AdapSQP, we take the minimum over four setups of constants Cgrad, Cf =
{1, 5, 10, 50}. The result here is the KKT residual of the last iterate. We average over
convergent runs across ﬁve independent runs. The convergence results are summarized in
Tables 1, 2, and 3.

In tables, the column of logR shows log((cid:107)∇Lk(cid:107)) and the column of logStd shows the log
of standard deviation. For each problem, the ﬁrst line is the result of AdapSQP; the second
line is the result of (cid:96)1 AdapSQP; the third line is the result of (cid:96)1 SQP; and the fourth line
is the result of NonAdapSQP. The entry ‘(cid:30)’ means that the algorithm does not converge
(within the given budget).

References

1. Bandeira AS, Scheinberg K, Vicente LN (2014) Convergence of trust-region methods
based on probabilistic models. SIAM Journal on Optimization 24(3):1238–1264, DOI
10.1137/130915984, URL https://doi.org/10.1137/130915984

2. Berahas AS, Bollapragada R, Nocedal J (2020) An investigation of newton-sketch and
subsampled newton methods. Optimization Methods and Software 35(4):661–680, DOI 10.
1080/10556788.2020.1725751, URL https://doi.org/10.1080/10556788.2020.1725751
3. Berahas AS, Curtis FE, Robinson D, Zhou B (2021) Sequential quadratic optimization
for nonlinear equality constrained stochastic optimization. SIAM Journal on Opti-
mization 31(2):1352–1379, DOI 10.1137/20m1354556, URL https://doi.org/10.1137/
20M1354556

4. Bertsekas D (1982) Constrained Optimization and Lagrange Multiplier Methods. Else-
vier, Belmont, Mass, DOI 10.1016/c2013-0-10366-2, URL https://doi.org/10.1016/
C2013-0-10366-2

5. Bertsekas DP (1982) Projected newton methods for optimization problems with simple
constraints. SIAM Journal on Control and Optimization 20(2):221–246, DOI 10.1137/
0320018, URL https://doi.org/10.1137/0320018

6. Blanchet J, Cartis C, Menickelly M, Scheinberg K (2019) Convergence rate analysis of a
stochastic trust-region method via supermartingales. INFORMS Journal on Optimization
1(2):92–119, DOI 10.1287/ijoo.2019.0016, URL https://doi.org/10.1287/ijoo.2019.
0016

7. Bollapragada R, Byrd R, Nocedal J (2018) Adaptive sampling strategies for stochastic
optimization. SIAM Journal on Optimization 28(4):3312–3343, DOI 10.1137/17m1154679,
URL https://doi.org/10.1137/17M1154679

8. Bollapragada R, Byrd RH, Nocedal J (2018) Exact and inexact subsampled newton
methods for optimization. IMA Journal of Numerical Analysis 39(2):545–578, DOI
10.1093/imanum/dry009, URL https://doi.org/10.1093/imanum/dry009

9. Bottou L, Curtis FE, Nocedal J (2018) Optimization methods for large-scale machine
learning. SIAM Review 60(2):223–311, DOI 10.1137/16m1080173, URL https://doi.
org/10.1137/16M1080173

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

55

Table 1 KKT results summary.

Problem

BT9

BYRDSPHR

BT10

HS39

MSS1

MARATOS

ORTHREGB

HS6

BT8

MSS2

BT1

GENHS28

BT5

HS61

BT4

BT2

σ2 = 10−8

σ2 = 10−4

σ2 = 10−2

logR
-9.94
-9.40
-9.37
-9.47
-10.12
-9.36
-9.23
-9.77
-10.02
-9.30
-9.49
-9.55
-9.92
-9.82
-9.58
-9.47
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.51
-9.78
-9.77
-9.60
-9.71
-9.69
-9.38
-9.33
-9.77
-9.30
-8.60
-9.51
-10.25
-9.76
-9.65
-9.46
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.18
-10.23
-9.52
-10.11
-9.76
-9.31
-9.37
-9.34
-10.22
-9.97
-9.43
-9.51
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.62
(cid:30)
-9.51
-9.41
-9.65
-9.75
-9.41
-9.34

logStd
-10.37
-11.08
-11.21
-11.21
-11.73
-15.49
-14.53
-10.40
-10.38
-14.55
-10.98
-10.48
-10.22
-16.00
-10.97
-11.19
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.95
-14.27
-10.68
-10.31
-10.49
-10.64
-11.57
-13.29
-12.02
-11.85
-9.65
-10.98
-10.42
-10.51
-10.52
-10.52
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.62
-15.53
-10.49
-10.89
-10.33
-11.53
-11.26
-11.61
-11.08
-15.38
-11.17
-10.76
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.29
(cid:30)
-10.55
-11.23
-10.23
-10.88
-11.98
-11.62

logR
-9.47
-9.10
-9.35
-9.36
-9.64
-8.80
-4.07
-9.50
-9.91
-9.18
-9.44
-10.06
-9.50
-8.67
-9.43
-9.32
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.80
-8.88
-9.68
-10.11
-9.04
-9.17
-4.04
-7.95
-9.81
-8.85
-9.70
-9.85
-9.57
-8.46
-9.66
-9.57
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.82
-8.87
-9.83
-10.07
-9.40
-8.76
(cid:30)
-7.68
-9.84
-8.53
-9.56
-9.45
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.39
(cid:30)
-9.47
-9.48
-8.39
-9.07
-9.57
-9.57

logStd
-10.66
-10.91
-12.37
-11.17
-10.90
-10.77
-4.92
-11.06
-10.69
-11.11
-Inf
-10.62
-11.56
-10.30
-11.96
-11.53
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.47
-10.74
-10.77
-11.17
-9.98
-11.75
-Inf
-9.65
-10.45
-10.78
-10.35
-10.92
-11.39
-9.88
-Inf
-10.57
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.52
-10.36
-10.63
-10.51
-10.78
-10.41
(cid:30)
-9.15
-10.72
-9.95
-10.60
-10.70
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.05
(cid:30)
-10.82
-10.63
-8.77
-11.60
-10.78
-Inf

logR
-9.74
-8.39
-0.31
-5.96
-9.65
-8.62
-1.63
-6.96
-9.86
-7.97
-0.95
-10.62
-9.58
-9.03
-0.30
-6.23
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.70
-8.50
-9.56
-7.32
-7.19
-8.34
1.06
(cid:30)
-9.84
-8.17
-9.42
-5.16
-9.42
-9.00
(cid:30)
-6.81
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.13
-8.44
-9.78
-6.88
-9.20
-8.42
(cid:30)
(cid:30)
-9.63
-8.97
(cid:30)
-9.39
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.51
(cid:30)
(cid:30)
(cid:30)
-9.50
-8.49
-1.75
(cid:30)

logStd
-10.47
-9.84
-3.09
-7.28
-10.36
-10.14
-2.52
-6.50
-10.31
-9.29
-4.48
-Inf
-10.41
-11.71
-2.79
-6.64
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.27
-10.21
-10.62
-6.66
-6.76
-9.95
-0.97
(cid:30)
-10.89
-9.26
-Inf
-5.90
-10.80
-11.43
(cid:30)
-7.02
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-11.03
-10.11
-10.47
-6.15
-11.83
-9.82
(cid:30)
(cid:30)
-11.17
-11.38
(cid:30)
-11.00
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.61
(cid:30)
(cid:30)
(cid:30)
-10.34
-10.20
-3.46
(cid:30)

σ2 = 10−1
logR logStd
-10.26
-9.55
-9.17
-7.91
-2.24
0.21
(cid:30)
(cid:30)
2.06
1.26
-9.13
-7.92
-1.50
-0.61
(cid:30)
(cid:30)
-10.83
-9.81
-7.57
-6.26
-1.97
-0.19
-10.41
-9.65
-10.82
-9.49
-9.83
-8.37
-2.43
0.04
-Inf
-4.67
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.26
-9.64
-9.81
-8.27
-0.79
-0.21
-5.60
-5.64
-8.59
-7.72
-8.21
-6.92
1.73
2.83
(cid:30)
(cid:30)
-10.36
-9.72
-8.73
-7.39
-3.41
-3.07
-5.36
-4.54
-11.55
-9.30
-9.94
-8.38
-3.07
0.15
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
0
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.61
-9.51
-9.97
-8.45
-Inf
-9.26
-7.96
-4.98
-9.97
-8.44
-9.29
-7.66
-1.04
0.87
(cid:30)
(cid:30)
-10.40
-9.10
-8.99
-7.76
(cid:30)
(cid:30)
-5.06
-4.95
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.79
-9.46
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.23
-9.12
-9.12
-7.80
3.36
8.61
(cid:30)
(cid:30)

σ2 = 1

logR
-8.36
-6.85
0.83
(cid:30)
2.64
-7.50
0.56
(cid:30)
-9.52
-5.06
-0.12
-10.03
-8.23
-7.07
0.80
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.73
-7.17
-0.01
-3.60
-3.86
-6.14
4.67
(cid:30)
-8.97
-6.75
-2.38
-4.13
-8.88
-7.09
0.64
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.95
-7.60
(cid:30)
-3.75
-7.32
-6.20
1.61
(cid:30)
-8.07
-7.27
1.69
-4.38
0
(cid:30)
(cid:30)
(cid:30)
-8.32
(cid:30)
(cid:30)
(cid:30)
-8.49
-6.73
8.58
(cid:30)

logStd
-9.85
-7.97
-1.18
(cid:30)
2.06
-8.51
-2.07
(cid:30)
-11.73
-6.00
-0.94
-10.86
-8.69
-8.46
-1.80
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.18
-8.12
-4.10
-3.63
-3.13
-7.92
1.31
(cid:30)
-10.06
-8.00
-Inf
-4.94
-9.51
-8.20
-2.10
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.56
-8.63
(cid:30)
-4.02
-9.95
-7.83
-0.06
(cid:30)
-9.44
-8.76
0.03
-5.11
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.01
(cid:30)
(cid:30)
(cid:30)
-9.29
-8.65
5.04
(cid:30)

logR = log((cid:107)∇Lk (cid:107)), logStd is the standard deviation. The first line: AdapSQP; the second line: (cid:96)1 AdapSQP;
the third line: (cid:96)1 SQP; the fourth line: NonAdapSQP.

56

Na et al.

Table 2 KKT results summary.

Problem

S316-322

FLT

HS51

BT12

HS52

HS48

S308NE

HS42

HS27

DIXCHLNG

COATINGNE

HS28

DEVGLA2NE

BT3

HS79

HS7

σ2 = 10−8

σ2 = 10−4

logR
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.59
-9.32
-6.37
-9.37
-10.02
-9.38
-9.34
-9.35
-9.42
-10.03
-9.67
-8.54
-9.74
-9.41
-9.34
-9.43
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.78
-10.32
-9.46
-9.33
-10.39
-9.46
-9.53
-9.35
9.95
(cid:30)
-9.36
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.41
-9.30
(cid:30)
-9.34
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.86
-10.14
-9.54
-9.51
-9.66
-9.40
-9.49
-9.55
-9.58
-9.44
-9.46
-9.68

logStd
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.96
-10.94
-Inf
-12.03
-10.82
-11.10
-11.50
-11.53
-11.31
-12.54
-10.57
-9.00
-10.45
-10.59
-Inf
-11.08
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.63
-11.32
-11.31
-12.35
-10.27
-10.27
-10.49
-10.78
-9.54
(cid:30)
-11.56
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.72
-11.32
(cid:30)
-11.66
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.40
-11.04
-11.05
-11.02
-10.32
-10.92
-11.02
-10.85
-11.02
-10.30
-10.49
-10.53

logR
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.83
-8.20
-4.49
-9.40
-9.62
-8.96
(cid:30)
-7.68
-8.71
-8.95
(cid:30)
-9.32
-9.50
-9.09
-1.25
-9.37
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.47
-8.05
-10.08
-9.58
-9.94
-8.34
-9.38
-9.53
9.95
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.65
-8.94
(cid:30)
-9.51
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.48
-8.67
(cid:30)
-9.33
-9.62
-8.99
-2.88
(cid:30)
-9.66
-9.10
-9.65
-9.89

logStd
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.58
-9.46
-Inf
-11.19
-10.57
-10.98
(cid:30)
-7.85
-9.06
-11.26
(cid:30)
-12.21
-10.67
-11.83
-8.06
-10.68
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-11.14
-9.30
-11.18
-11.19
-10.60
-9.69
-11.02
-10.60
-5.63
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.25
-10.42
(cid:30)
-10.82
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.77
-10.25
(cid:30)
-12.09
-10.95
-11.15
-5.61
(cid:30)
-10.79
-10.97
-11.31
-10.52

σ2 = 10−2
logR logStd

σ2 = 10−1
logR logStd

σ2 = 1
logR logStd

(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.46
-8.74
(cid:30)
-6.22
-9.37
-8.83
(cid:30)
-6.29
-9.22
-8.26
(cid:30)
(cid:30)
-9.39
-8.72
-0.74
-6.80
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.50
-8.58
(cid:30)
-5.98
-9.73
-8.41
-9.38
(cid:30)
9.95
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.69
-8.31
(cid:30)
-9.36
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.44
-9.06
(cid:30)
-6.39
-9.38
-9.14
-1.59
(cid:30)
-9.87
-7.70
-9.70
-5.61

(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-11.15
-10.44
(cid:30)
-6.93
-11.37
-10.54
(cid:30)
-7.78
-10.94
-9.57
(cid:30)
(cid:30)
-11.29
-10.52
-Inf
-7.59
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-11.16
-10.34
(cid:30)
-6.17
-10.30
-10.09
-Inf
(cid:30)
-2.27
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.51
-9.86
(cid:30)
-11.61
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.84
-12.04
(cid:30)
-7.87
-10.39
-12.37
-2.76
(cid:30)
-10.86
-8.94
-10.31
-5.03

(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-8.98
-7.34
-0.32
(cid:30)
-8.97
-7.73
0.13
-5.27
-8.64
-7.48
(cid:30)
(cid:30)
-8.86
-7.71
-0.63
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.25
-8.07
(cid:30)
-5.21
-9.25
-7.34
-1.88
(cid:30)
9.95
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.07
-8.11
(cid:30)
-5.35
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-8.67
-8.02
(cid:30)
-6.80
-9.14
-7.57
-0.80
(cid:30)
-9.75
-8.34
-9.39
-5.23

(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.57
-8.44
-Inf
(cid:30)
-10.49
-8.78
-Inf
-5.86
-9.20
-8.94
(cid:30)
(cid:30)
-10.26
-8.83
-Inf
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.02
-9.85
(cid:30)
-Inf
-9.80
-8.49
-2.86
(cid:30)
-1.72
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.63
-9.47
(cid:30)
-7.07
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.40
-9.18
(cid:30)
-Inf
-10.41
-8.49
-2.51
(cid:30)
-10.51
-9.70
-Inf
-5.59

(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-7.66
-6.39
(cid:30)
(cid:30)
-7.80
-6.77
(cid:30)
(cid:30)
-7.89
-7.01
(cid:30)
(cid:30)
-7.86
-6.65
-0.75
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-7.78
-7.21
1.29
(cid:30)
-8.75
-6.53
-1.16
(cid:30)
9.95
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-8.82
-7.39
(cid:30)
-4.69
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-8.01
-6.66
(cid:30)
(cid:30)
-7.90
-6.62
0.52
(cid:30)
-9.16
-6.94
0.01
-3.90

(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-8.08
-7.79
(cid:30)
(cid:30)
-9.72
-8.21
(cid:30)
(cid:30)
-8.75
-8.18
(cid:30)
(cid:30)
-8.93
-8.05
-1.53
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-8.32
-8.89
-0.43
(cid:30)
-9.33
-7.42
-3.44
(cid:30)
-0.69
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.91
-8.72
(cid:30)
-Inf
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-8.91
-7.91
(cid:30)
(cid:30)
-9.13
-7.94
-1.16
(cid:30)
-9.97
-7.75
-3.56
-4.63

logR = log((cid:107)∇Lk (cid:107)), logStd is the standard deviation. The first line: AdapSQP; the second line: (cid:96)1 AdapSQP;
the third line: (cid:96)1 SQP; the fourth line: NonAdapSQP.

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

57

Table 3 KKT results summary.

Problem

BT11

BT6

HS40

HS50

HS26

HS9

HS100LNP

HS77

MWRIGHT

HS46

HS49

HS78

HS56

HS111LNP

HS47

σ2 = 10−8

logR
-9.45
-9.55
-9.57
-9.50
-10.28
-9.32
-9.25
-9.30
-10.04
-10.08
-9.80
-9.57
-9.66
-9.23
-6.19
-8.27
-9.14
-8.64
0.90
-9.15
-9.24
-9.22
(cid:30)
-9.32
-8.23
-9.40
-9.44
-6.30
-9.59
-9.97
-9.23
-9.31
-7.71
-9.89
-9.47
-8.14
-9.22
-9.21
-9.23
-9.22
-8.55
-8.09
(cid:30)
-9.23
-9.85
-9.58
-9.46
-9.58
-9.30
-9.47
-9.41
-8.48
-8.58
-8.42
(cid:30)
-9.24
-9.22
-9.21
-7.87
-7.97

logStd
-10.81
-11.17
-11.63
-10.66
-10.67
-10.67
-12.89
-12.03
-10.84
-11.07
-11.23
-10.79
-10.19
-12.03
-Inf
-10.53
-10.97
-10.23
1.71
-11.13
-12.83
-14.15
(cid:30)
-12.08
-8.51
-10.54
-11.07
-6.42
-10.55
-11.32
-13.27
-12.54
-8.11
-11.04
-10.77
-8.92
-13.26
-16.47
-13.49
-14.39
-10.23
-9.81
(cid:30)
-13.84
-10.34
-14.76
-10.96
-10.72
-11.46
-10.63
-11.00
-9.53
-9.93
-10.09
(cid:30)
-12.42
-13.80
-11.86
-10.99
-9.43

σ2 = 10−4
logR logStd
-12.18
-9.34
-10.34
-8.69
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.52
-9.67
-10.33
-8.53
-4.61
-2.52
-Inf
-9.37
-11.28
-9.86
-10.25
-8.76
(cid:30)
(cid:30)
-11.06
-9.45
-10.50
-9.47
-10.30
-8.66
-8.89
-5.07
(cid:30)
(cid:30)
-9.45
-8.92
-8.51
-7.39
1.91
1.60
-11.01
-9.46
-13.21
-9.25
-13.61
-9.19
(cid:30)
(cid:30)
-10.61
-9.60
-7.89
-7.83
-10.00
-8.38
-7.11
2.68
(cid:30)
(cid:30)
-11.12
-9.67
-10.12
-8.57
-4.53
-2.57
(cid:30)
(cid:30)
-5.98
-6.24
-10.77
-8.82
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-12.64
-9.21
-12.35
-9.11
-6.25
-2.51
-Inf
-9.38
-7.99
-7.53
-7.48
-6.56
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-11.26
-9.49
-9.63
-8.32
-4.62
-3.00
-7.90
-7.09
-10.47
-9.08
-11.15
-8.94
-6.81
-0.37
(cid:30)
(cid:30)
-8.30
-7.22
-7.66
-6.53
(cid:30)
(cid:30)
-6.98
-2.82
-10.13
-9.08
-8.95
-7.82
-Inf
-5.62
-Inf
-9.23

σ2 = 10−2
logR logStd
-10.61
-9.26
-10.93
-8.90
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.53
-9.43
-10.62
-8.84
-3.07
-0.87
(cid:30)
(cid:30)
-10.90
-9.56
-10.37
-8.66
-2.58
-0.32
-6.89
-6.38
-10.81
-9.35
-11.03
-8.87
-3.45
-2.70
(cid:30)
(cid:30)
-9.14
-8.57
-7.71
-6.69
1.91
2.00
(cid:30)
(cid:30)
-9.23
-8.97
-8.47
-7.39
(cid:30)
(cid:30)
-10.39
-9.70
-8.08
-7.45
-9.42
-7.99
-4.91
2.68
(cid:30)
(cid:30)
-10.98
-9.37
-11.97
-9.10
-1.78
-0.63
(cid:30)
(cid:30)
-5.80
-6.09
-6.90
-5.97
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-11.95
-9.23
-9.39
-8.00
-Inf
-2.34
(cid:30)
(cid:30)
-7.67
-7.30
-7.64
-6.46
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-11.36
-9.35
-10.90
-8.88
-1.88
-0.63
-6.88
-5.91
-8.12
-8.23
(cid:30)
(cid:30)
-2.69
0.14
(cid:30)
(cid:30)
-7.75
-7.03
-6.78
-5.79
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-11.33
-9.29
-9.71
-8.35
-Inf
-3.00
(cid:30)
(cid:30)

σ2 = 10−1
logR logStd
-10.11
-8.97
-8.43
-7.38
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.37
-8.78
-9.51
-7.58
-2.36
-0.43
(cid:30)
(cid:30)
-9.92
-9.03
-9.65
-8.36
-3.31
-0.31
-6.42
-5.70
-9.40
-8.90
-8.73
-7.71
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-7.87
-7.67
-8.56
-7.45
1.67
1.04
(cid:30)
(cid:30)
-9.50
-9.28
-8.47
-7.43
(cid:30)
(cid:30)
-10.47
-9.58
-7.63
-6.98
-7.03
-5.98
-3.63
2.69
(cid:30)
(cid:30)
-10.64
-8.77
-8.41
-7.20
-1.33
-0.02
(cid:30)
(cid:30)
-6.54
-6.80
-7.26
-6.20
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.74
-8.86
-8.63
-7.48
-2.98
-1.64
(cid:30)
(cid:30)
-6.96
-6.79
-8.32
-6.96
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-10.53
-9.23
-9.02
-7.76
-0.72
0.62
-Inf
-6.14
-7.44
-7.10
(cid:30)
(cid:30)
-1.83
0.77
(cid:30)
(cid:30)
-7.81
-6.80
-6.79
-5.63
(cid:30)
(cid:30)
(cid:30)
(cid:30)
-9.19
-8.36
-8.75
-7.13
-3.94
-1.01
(cid:30)
(cid:30)

σ2 = 1

logR
-7.43
-6.56
1.63
(cid:30)
-7.90
-6.29
3.83
(cid:30)
-8.35
-7.15
-0.17
(cid:30)
-7.77
-6.63
(cid:30)
(cid:30)
-8.04
-7.00
1.96
(cid:30)
-8.97
-6.25
(cid:30)
-10.10
-5.10
-6.29
2.71
(cid:30)
-7.65
-6.34
3.78
(cid:30)
-6.41
-5.74
2.76
(cid:30)
-7.68
-6.91
0.98
(cid:30)
-7.15
-6.33
(cid:30)
(cid:30)
-7.69
-6.54
1.40
(cid:30)
-6.71
(cid:30)
1.11
(cid:30)
-6.19
-5.91
(cid:30)
(cid:30)
-7.88
-6.24
1.56
(cid:30)

logStd
-8.21
-7.73
-1.80
(cid:30)
-9.08
-7.45
-1.24
(cid:30)
-8.89
-8.66
-1.59
(cid:30)
-8.99
-7.97
(cid:30)
(cid:30)
-7.68
-8.81
1.08
(cid:30)
-9.31
-7.24
(cid:30)
-10.50
-4.96
-8.07
-2.29
(cid:30)
-8.60
-7.60
-0.86
(cid:30)
-6.76
-7.01
-Inf
(cid:30)
-8.15
-8.28
-1.30
(cid:30)
-7.70
-8.06
(cid:30)
(cid:30)
-8.26
-8.28
-1.34
(cid:30)
-7.11
(cid:30)
-0.86
(cid:30)
-6.38
-7.33
(cid:30)
(cid:30)
-9.21
-7.55
-1.48
(cid:30)

logR = log((cid:107)∇Lk (cid:107)), logStd is the standard deviation. The first line: AdapSQP; the second line: (cid:96)1 AdapSQP;
the third line: (cid:96)1 SQP; the fourth line: NonAdapSQP.

58

Na et al.

10. Byrd RH, Chin GM, Nocedal J, Wu Y (2012) Sample size selection in optimization
methods for machine learning. Mathematical Programming 134(1):127–155, DOI 10.
1007/s10107-012-0572-5, URL https://doi.org/10.1007/s10107-012-0572-5

11. Cartis C, Scheinberg K (2017) Global convergence rate analysis of unconstrained optimiza-
tion methods based on probabilistic models. Mathematical Programming 169(2):337–375,
DOI 10.1007/s10107-017-1137-4, URL https://doi.org/10.1007/s10107-017-1137-4
12. Chen R, Menickelly M, Scheinberg K (2017) Stochastic optimization using a trust-

region method and random models. Mathematical Programming 169(2):447–487, DOI
10.1007/s10107-017-1141-8, URL https://doi.org/10.1007/s10107-017-1141-8
13. Curtis FE, Shi R (2020) A fully stochastic second-order trust region method. Optimization
Methods and Software pp 1–34, DOI 10.1080/10556788.2020.1852403, URL https:
//doi.org/10.1080/10556788.2020.1852403

14. Curtis FE, Scheinberg K, Shi R (2019) A stochastic trust region algorithm based on
careful step normalization. INFORMS Journal on Optimization 1(3):200–220, DOI
10.1287/ijoo.2018.0010, URL https://doi.org/10.1287/ijoo.2018.0010

15. De S, Yadav A, Jacobs D, Goldstein T (2017) Automated Inference with Adaptive
Batches. PMLR, Fort Lauderdale, FL, USA, Proceedings of Machine Learning Research,
vol 54, pp 1504–1513, URL http://proceedings.mlr.press/v54/de17a.html

16. Dupacova J, Wets R (1988) Asymptotic behavior of statistical estimators and of optimal
solutions of stochastic optimization problems. The Annals of Statistics 16(4):1517–1549,
DOI 10.1214/aos/1176351052, URL https://doi.org/10.1214/aos/1176351052

17. Durrett R (2019) Probability, vol 49. Cambridge University Press, DOI 10.1017/

9781108591034, URL https://doi.org/10.1017/9781108591034

18. Friedlander MP, Schmidt M (2012) Hybrid deterministic-stochastic methods for data
ﬁtting. SIAM Journal on Scientiﬁc Computing 34(3):A1380–A1405, DOI 10.1137/
110830629, URL https://doi.org/10.1137/110830629

19. Gallager RG (2013) Stochastic Processes. Cambridge University Press, DOI 10.1017/

cbo9781139626514, URL https://doi.org/10.1017/cbo9781139626514

20. Gill PE, Wong E (2011) Sequential quadratic programming methods. In: Mixed
Integer Nonlinear Programming, IMA Vol. Math. Appl., vol 154, Springer New
York, pp 147–224, DOI 10.1007/978-1-4614-1927-3 6, URL https://doi.org/10.1007/
978-1-4614-1927-3_6

21. Gill PE, Murray W, Saunders MA (2005) SNOPT: An SQP algorithm for large-scale
constrained optimization. SIAM Review 47(1):99–131, DOI 10.1137/s0036144504446096,
URL https://doi.org/10.1137/S0036144504446096

22. Gould NIM, Orban D, Toint PL (2014) CUTEst: a constrained and unconstrained
testing environment with safe threads for mathematical optimization. Computational
Optimization and Applications 60(3):545–557, DOI 10.1007/s10589-014-9687-3, URL
https://doi.org/10.1007/s10589-014-9687-3

23. Gratton S, Royer CW, Vicente LN, Zhang Z (2017) Complexity and global rates
of trust-region methods based on probabilistic models. IMA Journal of Numerical
Analysis 38(3):1579–1597, DOI 10.1093/imanum/drx043, URL https://doi.org/10.
1093/imanum/drx043

24. Kreji´c N, Krklec N (2013) Line search methods with variable sample size for unconstrained
optimization. Journal of Computational and Applied Mathematics 245:213–231, DOI
10.1016/j.cam.2012.12.020, URL https://doi.org/10.1016/j.cam.2012.12.020

25. Lucidi S (1990) Recursive quadratic programming algorithm that uses an exact aug-
mented lagrangian function. Journal of Optimization Theory and Applications 67(2):227–
245, DOI 10.1007/bf00940474, URL https://doi.org/10.1007/BF00940474

26. Maratos N (1978) Exact penalty function algorithms for ﬁnite dimensional and control
optimization problems. Doctoral dissertation URL http://hdl.handle.net/10044/1/
7283

27. Nagaraj NK, Fuller WA (1991) Estimation of the parameters of linear time series
models subject to nonlinear restrictions. The Annals of Statistics 19(3):1143–1154,
DOI 10.1214/aos/1176348242, URL https://doi.org/10.1214/aos/1176348242

28. Nandwani Y, Pathak A, Mausam, Singla P (2019) A primal dual formulation for
deep learning with constraints. In: Advances in Neural Information Processing Sys-
tems 32, Curran Associates, Inc., pp 12157–12168, URL http://papers.nips.cc/paper/

An Adaptive Stochastic SQP with Diﬀerentiable Exact Augmented Lagrangians

59

9385-a-primal-dual-formulation-for-deep-learning-with-constraints.pdf

29. Nemirovski A, Juditsky A, Lan G, Shapiro A (2009) Robust stochastic approximation
approach to stochastic programming. SIAM Journal on Optimization 19(4):1574–1609,
DOI 10.1137/070704277, URL https://doi.org/10.1137/070704277

30. Nocedal J, Wright SJ (2006) Numerical Optimization, 2nd edn. Springer Series in
Operations Research and Financial Engineering, Springer New York, DOI 10.1007/
978-0-387-40065-5, URL https://doi.org/10.1007/978-0-387-40065-5

31. Paquette C, Scheinberg K (2020) A stochastic line search method with expected complex-
ity analysis. SIAM Journal on Optimization 30(1):349–376, DOI 10.1137/18m1216250,
URL https://doi.org/10.1137/18M1216250

32. Pillo G (1994) Exact penalty methods. In: Algorithms for Continuous Optimiza-
tion, NATO Adv. Sci. Inst. Ser. C Math. Phys. Sci., vol 434, Springer Nether-
lands, pp 209–253, DOI 10.1007/978-94-009-0369-2 8, URL https://doi.org/10.1007/
978-94-009-0369-2_8

33. Pillo GD, Grippo L (1979) A new class of augmented lagrangians in nonlinear program-
ming. SIAM Journal on Control and Optimization 17(5):618–628, DOI 10.1137/0317044,
URL https://doi.org/10.1137/0317044

34. Pillo GD, Grippo L, Lampariello F (1980) A method for solving equality constrained
optimization problems by unconstrained minimization. In: Optimization Techniques,
Springer-Verlag, Lecture Notes in Control and Information Sci., vol 23, pp 96–105,
DOI 10.1007/bfb0006592, URL https://doi.org/10.1007/BFb0006592

35. Pr´ekopa A (1973) Contributions to the theory of stochastic programming. Mathematical
Programming 4(1):202–221, DOI 10.1007/bf01584661, URL https://doi.org/10.1007/
BF01584661

36. Ravi SN, Dinh T, Lokhande VS, Singh V (2019) Explicitly imposing constraints in deep
networks via conditional gradients gives improved generalization and faster convergence.
In: Proceedings of the AAAI Conference on Artiﬁcial Intelligence, Association for the
Advancement of Artiﬁcial Intelligence (AAAI), vol 33, pp 4772–4779, DOI 10.1609/aaai.
v33i01.33014772, URL https://doi.org/10.1609/aaai.v33i01.33014772

37. Roosta-Khorasani F, Mahoney MW (2018) Sub-sampled newton methods. Mathematical
Programming 174(1-2):293–326, DOI 10.1007/s10107-018-1346-5, URL https://doi.
org/10.1007/s10107-018-1346-5

38. di Seraﬁno D, Kreji´c N, Jerinki´c NK, Viola M (2020) Lsos: Line-search second-order
stochastic optimization methods. arXiv preprint arXiv:200715966 URL https://arxiv.
org/abs/2007.15966

39. Shapiro A (2000) On the asymptotics of constrained local $m$-estimators. The Annals
of Statistics 28(3):948–960, DOI 10.1214/aos/1015952006, URL https://doi.org/10.
1214/aos/1015952006

40. Siqueira AS, Orban D (2020) Cutest.jl. https://github.com/JuliaSmoothOptimizers/

CUTEst.jl, DOI 10.5281/ZENODO.1188851

41. Tripuraneni N, Stern M, Jin C, Regier J, Jordan MI (2018) Stochastic cubic regularization
for fast nonconvex optimization. In: Advances in neural information processing systems,
pp 2899–2908, URL https://dl.acm.org/doi/10.5555/3327144.3327213

42. Tropp JA (2011) User-friendly tail bounds for sums of random matrices. Foundations
of computational mathematics 12(4):389–434, DOI 10.1007/s10208-011-9099-z, URL
https://doi.org/10.1007/s10208-011-9099-z

43. Tropp JA (2015) An introduction to matrix concentration inequalities. Foundations
and Trends® in Machine Learning 8(1-2):1–230, DOI 10.1561/2200000048, URL http:
//dx.doi.org/10.1561/2200000048

44. Wang X, Ma S, Goldfarb D, Liu W (2017) Stochastic quasi-newton methods for nonconvex
stochastic optimization. SIAM Journal on Optimization 27(2):927–956, DOI 10.1137/
15m1053141, URL https://doi.org/10.1137/15M1053141

45. Wets R (1983) Stochastic programming: Solution techniques and approximation
schemes. In: Mathematical Programming The State of the Art, Springer Berlin Heidel-
berg, pp 566–603, DOI 10.1007/978-3-642-68874-4 22, URL https://doi.org/10.1007/
978-3-642-68874-4_22

60

Na et al.

Government License: The submitted manuscript has been created by UChicago Argonne,
LLC, Operator of Argonne National Laboratory (“Argonne”). Argonne, a U.S. Department
of Energy Oﬃce of Science laboratory, is operated under Contract No. DE-AC02-06CH11357.
The U.S. Government retains for itself, and others acting on its behalf, a paid-up nonex-
clusive, irrevocable worldwide license in said article to reproduce, prepare derivative works,
distribute copies to the public, and perform publicly and display publicly, by or on be-
half of the Government. The Department of Energy will provide public access to these
results of federally sponsored research in accordance with the DOE Public Access Plan.
http://energy.gov/downloads/doe-public-access-plan.

