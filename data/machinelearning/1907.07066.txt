1
2
0
2

r
p
A
2

]

G
L
.
s
c
[

4
v
6
6
0
7
0
.
7
0
9
1
:
v
i
X
r
a

Selection Heuristics on Semantic Genetic Programming for
Classiﬁcation Problems

Claudia N. S´anchez1,2

Mario Graﬀ1,3

1INFOTEC Centro de Investigaci´on e Innovaci´on en Tecnolog´ıas de la Informaci´on
y Comunicaci´on, Circuito Tecnopolo Sur No 112, Fracc. Tecnopolo Pocitos II,
Aguascalientes 20313, M´exico
2Facultad de Ingenier´ıa. Universidad Panamericana, Aguascalientes, M´exico
3CONACyT Consejo Nacional de Ciencia y Tecnolog´ıa, Direcci´on de C´atedras,
Insurgentes Sur 1582, Cr´edito Constructor, Ciudad de M´exico 03940 M´exico

This work has been submitted to the Evolutionary Computation journal for
possible publication.

Abstract

Individual’s semantics have been used for guiding the learning process of Genetic Pro-
gramming solving supervised learning problems. The semantics has been used to proposed
novel genetic operators as well as diﬀerent ways of performing parent selection. The lat-
ter is the focus of this contribution by proposing three heuristics for parent selection that
replace the ﬁtness function on the selection mechanism entirely. These heuristics comple-
ment previous work by being inspired in the characteristics of the addition, Naive Bayes,
and Nearest Centroid functions and applying them only when the function is used to cre-
ate an oﬀspring. These heuristics use diﬀerent similarity measures among the parents to
decide which of them is more appropriate given a function. The similarity functions con-
sidered are the cosine similarity, Pearson’s correlation, and agreement. We analyze these
heuristics’ performance against random selection, state-of-the-art selection schemes, and 18
classiﬁers, including auto-machine-learning techniques, on 30 classiﬁcation problems with a
variable number of samples, variables, and classes. The result indicated that the combination
of parent selection based on agreement and random selection to replace an individual in the
population produces statistically better results than the classical selection and state-of-the-art
schemes, and it is competitive with state-of-the-art classiﬁers. Finally, the code is released as
open-source software.

1 Introduction

Classiﬁcation is a supervised learning problem that consists of ﬁnding a function that learns
It could be
the relation between inputs and outputs, where the outputs are a set of labels.
applied for solving problems like object recognition, medical diagnosis, identiﬁcation of symbols,
among others. The starting point would be the training set composed of input-output pairs,
i.e., X = {( (cid:126)x1, y1), . . . , ( (cid:126)xn, yn)}, where ∀(cid:126)x∈X (cid:126)x ∈ Rm, and ∀y∈X y ∈ R. The training set X
is used to ﬁnd a function, f , that minimize a loss function, L, that is, f is the function that
minimize (cid:80)
L(f ((cid:126)x), y), where the ideal scenario would be ∀((cid:126)x,y)∈X f ((cid:126)x) = y, and, also
to accurately predict the labels of unseen inputs. Genetic programming (GP) is a ﬂexible and
powerful evolutionary technique with some features that can be very valuable and suitable for
the evolution of classiﬁers (Espejo et al., 2010). The ﬁrst document related to GP was presented
by Friedberg (1958), but the term was coined by Koza (1992). The classiﬁers constructed with

((cid:126)x,y)∈X

1

 
 
 
 
 
 
GP started appearing around the 2000s (Loveard and Ciesielski, 2001; Brameier and Banzhaf,
2001), and nowadays, they can be comparable with state-of-the-art machine learning techniques
for solving hard classiﬁcation problems. For example, GP has been used for medical proposes
(Brameier and Banzhaf, 2001; Olson et al., 2016), image classiﬁcation (Iqbal et al., 2017), fault
classiﬁcation (Guo et al., 2005), only to mention some of them. Also, the GP performance has
been successfully compared with others machine learning techniques as Neural Networks (Brameier
and Banzhaf, 2001), Support Vector Machines (Lichodzijewski and Heywood, 2008; McIntyre and
Heywood, 2011). Speciﬁcaly, GP can be applied in the preprocessing task (Guo et al., 2005; Badran
and Rockett, 2012; Ingalalli et al., 2014; La Cava et al., 2019), in model extraction (Loveard and
Ciesielski, 2001; Brameier and Banzhaf, 2001; Muni et al., 2004; Zhang and Smart, 2006; Folino
et al., 2008; McIntyre and Heywood, 2011; Graﬀ et al., 2016; Iqbal et al., 2017), or for building
machine learning pipelines (Olson et al., 2016).

Traditionally, GP uses individuals’ ﬁtness to select the parents that build the next generation
of individuals (Poli et al., 2008). Recently, new approaches for parent selection that use angles
among individuals’ semantics have been developed. For example, Angle-Driven Selection (ADS),
proposed by Chen et al. (2019), chooses parents maximizing the angle between their relative
semantics aiming to have parents with diﬀerent behaviors. Vanneschi et al. (2019) introduced a
selection scheme based on the angle between the error vectors. Besides, there have been approaches
that analyze evolutive algorithms’ behavior where the ﬁtness function is replaced with a heuristic.
Nguyen et al. (2012) proposed Fitness Sharing, a technique that promotes dispersion and diversity
of individuals. Lehman and Stanley (2011) proposed Novelty Search, where the individual’s ﬁtness
is related totally to its novelty without care about its target behavior. The individual’s novelty
is computed as the average distance between its behavior and its k-nearest neighbors’ behavior.
Naredo et al. (2016) used Novelty Search in GP for solving classiﬁcation problems. However, one
of the main characteristics of GP is that the function set deﬁnes its search space, and to the best
of our knowledge, there are not documents that propose the use of functions’ properties for parent
selection.

The intersection between our proposal and the previous research works is on the selection stage
of the evolutionary process. Most of the proposed methods produce a selection mechanism that
considers the semantics of individuals as well as the individual’s ﬁtness to choose the parents. The
exception is the proposals using Novelty Search, where the selection process is entirely performed
using the semantics. It enhances population diversity. Our approach follows this path by aban-
doning the ﬁtness function in the selection process. The diﬀerence with Novelty Search is that our
proposal searches for individuals whose semantics might help the function used to create the oﬀ-
spring. Besides, once the individual was created, local optimization is performed using the training
outputs, or, traditionally named, the target semantics. Functions’ properties inspire our selection
heuristics; in particular, these were inspired by the addition and the classiﬁers Naive Bayes and
Nearest Centroid. The proposed heuristics measure the similarity among parents. They are based
on cosine similarity, Pearson’s correlation coeﬃcient, and agreement1. Speciﬁcally, our heuristic
based on Pearson’s correlation coeﬃcient is quite similar to ADS, but the diﬀerence is that our
proposal is applied only to speciﬁc functions. In this document, we present the comparison of the
use of ADS and our proposal.

The selection heuristics are tested on a steady-state GP called EvoDAG. It was inspired by the
Geometric Semantic genetic operators proposed by Moraglio et al. (2012) with the implementation
of Vanneschi et al. (Vanneschi et al., 2013; Castelli et al., 2015a). It has been successfully applied
to a variety of text classiﬁcation problems (Graﬀ et al., 2020).
In steady-state evolution, the
selection mechanism is used twice to perform parent selection and decide the individual being
replaced by an oﬀspring; we refer to the later negative selection. The proposed selection is used
to select the parent; however, on the negative selection, we also tested the system’s performance
using random selection or the traditional selection guided by ﬁtness.

We analyze the performance of diﬀerent GP systems obtained by combining the schemes for
parent selection (our heuristics, random selection, and traditional selection) and negative selec-

1We thank the anonymous reviewer for suggesting this name which considerably improves the description clarity.

2

tion (random and traditional selection). Besides, we compare our selection heuristics against
two state-of-the-art techniques, Angle-Driven-Selection (Chen et al., 2019), and Novelty Search
(Naredo et al., 2016). To provide a complete picture of the performance of our selection heuris-
tics, we decided to compare them against state-of-the-art classiﬁers and two auto-machine learning
algorithms. The results show that our selection heuristic guided by agreement and random neg-
ative selection outperforms traditional selection, presenting a statistically signiﬁcant diﬀerence.
On the other hand, our selection heuristics outperforms the state-of-the-art techniques Angle-
Driven-Selection and Novelty Search. Furthermore, compared with state-of-the-art classiﬁers, our
GP system obtained the second-lowest rank being the ﬁrst one TPOT, an auto-machine learning
technique, although the diﬀerence in performance between these systems, in terms of macro-F1,
is not statistically signiﬁcant.

The rest of the manuscript is organized as follows. Section 2 presents the related work. The
GP system used to test the proposed heuristics is described in Section 3. The proposed selection
heuristics are presented in Section 4. Section 5 presents the experiments and results. The discus-
sion and limitations of the approach are treated in Section 6. Finally, Section 7 concludes this
research.

2 Related work

We can deﬁne supervised learning as follows Vanneschi (2017): given the training set composed
of input-output pairs, X = {( (cid:126)x1, y1), . . . , ( (cid:126)xn, yn)}, where ∀(cid:126)x∈X (cid:126)x ∈ Rm, and ∀y∈X y ∈ R; the
learning process can be deﬁned as the problem of ﬁnding a function f that minimizes a loss
function, L, that is, f is the function that minimize (cid:80)
L(f ((cid:126)x), y), where the ideal scenario
would be ∀((cid:126)x,y)∈X f ((cid:126)x) = y. Traditionally, the vector composed by all the outputs, (cid:126)t = {y1, . . . , yn},
is called target vector. In this way, a GP individual P can be seen as a function h that, for each
input vector (cid:126)xi returns the scalar value h( (cid:126)xi), and the objective is to ﬁnd the GP individual that
minimizes (cid:80)

L(h((cid:126)x), y).

((cid:126)x,y)∈X

((cid:126)x,y)∈X

On Semantic Genetic Programming (SGP), for example in (Vanneschi, 2017), each individual
P can be represented by its semantics vector (cid:126)Sp that corresponds to all the inputs’ evaluations
in the function h, this is, (cid:126)Sp = {h( (cid:126)x1), . . . , h( (cid:126)xn)}. We can imagine the existence of two spaces:
the genotype space, where individuals are represented by their structures, and the phenotype or
semantic space, where individuals are represented by points, which are their semantics. Remark
that the target vector (cid:126)t is a point in the semantic space. The dimensionality of the semantic space
is the number of input vectors. Using this notation, the objective of SGP is to ﬁnd the individual
P whose semantics Sp is as close as possible to the target vector (cid:126)t in the semantic space. The
distance between the individual’s semantics (cid:126)Sp and the target vector (cid:126)t is used as the individual’s
ﬁtness.

In order to provide a complete picture of the research documents related to this contribution,
the section starts by describing semantic genetic operators; this is followed by presenting research
proposals proposing selection mechanisms; and, lastly, some proposals where GP has been used
to develop classiﬁers.

2.1 Semantic Genetic Operators

Semantic Genetic Programming uses the target behavior, (cid:126)t, to guide the search. Krawiec (2016)
aﬃrmed that semantically aware methods make search algorithms better informed. Speciﬁcally,
several crossover and mutation operators have been developed with the use of semantics. Beadle
and Johnson (2008) proposed a crossover operator that measures the semantic equivalence between
parents and oﬀsprings and rejects the oﬀspring that is semantically equivalent to its parents. Uy
et al. (2011) developed a semantic crossover and a mutation operator. The crossover operator
searches for a crossover point in each parent so that subtrees are semantically similar, and the
mutation operator allows the replacement of an individual’s subtree only if the new subtree is

3

semantically similar. Hara et al. (2012) proposed the Semantic Control Crossover that uses se-
mantics to combine individuals. A global search is performed in the ﬁrst generations and a local
search in the last ones. Graﬀ et al. used subtrees semantics and partial derivatives to propose a
crossover (Graﬀ et al., 2014b; Su´arez et al., 2015) and a mutation (Graﬀ et al., 2014a) operator.
Moraglio et al. proposed the Geometric Semantic Genetic Programming (GSGP) (Moraglio
and Poli, 2004; Moraglio et al., 2012). Their work called the GP scientiﬁc community’s attention
because the crossover operator produces an oﬀspring that stands in the segment joining the par-
ents’ semantics. Therefore, oﬀspring ﬁtness cannot be worse than the worst ﬁtness of the parents.
Given two parents’ semantics (cid:126)p1 and (cid:126)p2, the crossover operator generates an oﬀspring whose se-
mantics is r · (cid:126)p1 + (1 − r) · (cid:126)p2, where r is a real value between 0 and 1. This property transforms
the ﬁtness landscape into a cone. Unfortunately, the oﬀspring is always bigger than the sum of its
parents’ size; this makes the operator unusable in practice. Later, some operators were developed
to improve Moraglio’s GSGP. For example, Approximately Geometric Semantic Crossover (SX)
(Krawiec and Lichocki, 2009), Deterministic Geometric Semantic Crossover (Hara et al., 2012),
Locally Geometric Crossover (LGX) (Krawiec and Pawlak, 2012, 2013), Approximated Geomet-
ric Crossover (AGX) (Pawlak et al., 2015), and Subtree Semantic Geometric Crossover (SSGX)
(Nguyen et al., 2016).

Graﬀ et al. (2015b) proposed a new crossover operator based on projections in the phenotype
It creates a plane in the semantic space using the parents’ semantics. The oﬀspring is
space.
calculated as the projection of the target in that plane. Given the parents’ semantics (cid:126)p1 and
(cid:126)p2, and the target semantics (cid:126)t, the oﬀspring is calculated as α (cid:126)p1 + β (cid:126)p2, where α and β are real
values that are calculated solving the equation A[α, β](cid:48) = (cid:126)t, where A = ( (cid:126)p1, (cid:126)p1). It implies the
oﬀspring will be at least as good as the best parent. Memetic Genetic Programming based on
Orthogonal Projections in the Phenotype Space was also proposed by Graﬀ et al. (2015a). In that
work, they used a linear combination of k parents as (cid:80)
k αk (cid:126)pk, where (cid:126)pk represents the semantics
of the k parent. The main idea is optimizing the coeﬃcients {αi} with ordinary least squares
(OLS) to guarantee that the oﬀspring is the best of its family. As a result, the generated tree’s
ﬁtness is always better or equal to any internal tree. It was not the ﬁrst time that parameters
were added to GP nodes; Smart and Zhang (2004) deﬁned the Inclusion Factors as numeric values
between 0 and 1 assigned to each node in the tree structure, except the root node. This value
represents the inclusion proportion of the node in the tree. Castelli et al. (2015b) presented a
mutation operator, in their work called Geometric Semantic Genetic Programming with Local
Search, based on Moraglio’s mutation operator, that also uses parameters. In this operator, an
individual’s semantics (cid:126)p is modiﬁed with the following equation, α0 + α1(cid:126)p + α2( (cid:126)r1 − (cid:126)r2), where
(cid:126)r1 and (cid:126)r2 are the semantics of random trees, and, αi (cid:15) R. {αi} are calculated using the target
semantics and OLS for getting the better linear combination of the individual’s semantics and the
random trees. They extended their work in (Castelli et al., 2019) applying Local Search to all
the individuals during a separate step after mutation and crossover. For each individual, p, they
calculated another one as p(cid:48) = αp + β, where α and β are optimized with OLS minimizing the
error between the individual’s semantics and target semantics. Moreover, they generalized the
idea and transformed it into a regression problem p(cid:48) = (cid:80)

j αjfj(p), where fj : R → R.

All those operators use semantics to guide the learning process; however, one of the main
characteristics of GP is that the function set deﬁnes its search space, and to the best of our
knowledge, there are not documents that propose the use of functions’ properties for designing
operators.

2.2 Fitness and Selection in Genetic Programming

According to Vanneschi et al. (2014), one way to promote diversity in GP is by using diﬀerent
selection schemes. Nguyen et al. (2012) proposed Fitness Sharing, a technique that promotes
dispersion and diversity of individuals. Their proposal consisted of calculating an individual’s
shared ﬁtness as f (cid:48)
i = fi(mi + 1), where fi is the individual’s ﬁtness, and mi is approximately
equal to the number of individuals that behave similarly to individual i. Galvan-Lopez et al.
(2013) applied crossover only to those individuals whose diﬀerence in behavior is greater than a

4

deﬁned threshold for every element on the semantic vectors. Hara et al. proposed Deterministic
Geometric Semantic Crossover (Hara et al., 2012), and later, they proposed to select the parents
in such a way that the line connecting them is as close as possible to the target in the semantic
space (Hara et al., 2016).

Ruberto et al. (2014) deﬁned the Error Vector and Error Space. The individual error vector (cid:126)ep
is deﬁned as (cid:126)ep = (cid:126)p −(cid:126)t, where (cid:126)p is the individual’s semantics and (cid:126)t represents the target semantics.
The error space contains all the individuals represented by their error vectors, where (cid:126)t is the origin.
The proposal is to search, in the error space, for two or three individuals aligned, instead of using
the ﬁtness function; the rationality comes from the fact that given the aligned individuals, then
there is a straightforward procedure to compute the optimal solution. Chu et al. (2016, 2018) used
the error vectors and the Wilcoxon signed-rank test to decide whether to select the ﬁttest or the
smaller individual as a parent. Their results show that the proposed techniques aim to enhance
semantic diversity and reduce the code bloat in GP. Vanneschi et al. (2019) introduced a selection
scheme based on the angle between the error vectors.

Chen et al. (2019) proposed Angle-Driven Geometric Semantic Genetic Programming (ADGSGP).

Their work attempts to further explore the geometry of geometric operators in the search space to
improve GP for symbolic regression. Their proposal included Angle-Driven Selection (ADS) that
selects a pair of parents that have good ﬁtness values and are far away from each other regarding
the angle-distance of their relative semantics. The ﬁrst parent is selected using ﬁtness, and the
second one is chosen maximizing the relative angle-distance between its semantics and the seman-
tics of the ﬁrst parent. The angle-distance is deﬁned as γr = arccos( ((cid:126)t− (cid:126)p1)((cid:126)t− (cid:126)p2)
), where (cid:126)t, (cid:126)p1,
||(cid:126)t− (cid:126)p1||||(cid:126)t− (cid:126)p2||
and (cid:126)p2, represent the target semantics, and semantics of the ﬁrst and the second parent, respec-
tively. Also, they proposed Perpendicular Crossover (PC) and Random Segment Mutation (RSM)
that likewise used angles to guide their process. Their experiments show that the angle-driven
geometric operators drive the evolutionary process to ﬁt the target semantics more eﬃciently and
improve the generalization performance.

Our proposal, as well as these documents, aims to promote individuals’ diversity but uses

functions’ properties for guiding the parent selection.

2.3 Genetic Programming for classiﬁcation

Genetic programming (GP) is a ﬂexible and powerful evolutionary technique with some features
that can be very valuable and suitable for the evolution of classiﬁers (Espejo et al., 2010). For
example, GP has been used for medical proposes (Brameier and Banzhaf, 2001; Olson et al.,
2016), image classiﬁcation (Iqbal et al., 2017), and fault classiﬁcation (Guo et al., 2005). Also, GP
classiﬁers have been successfully compared with state-of-the-art classiﬁers. Brameier and Banzhaf
(2001) compared GP against neural networks on medical classiﬁcation problems from a benchmark
database. Their results show that GP performs comparably in classiﬁcation and generalization.
McIntyre and Heywood (2011) compared their GP framework against SVM classiﬁers over 12
UCI datasets with between 150 and 200,000 training instances. Solutions from the GP framework
appear to provide a good balance between classiﬁcation performance and model complexity, espe-
cially as the dataset instance count increases. La Cava et al. (2019) compared their GP framework
to several state-of-the-art classiﬁcation techniques (Random Forest, Neural Networks, and Sup-
port Vector Machines) across a broad set of problems, and showed that their technique achieves
competitive test accuracies while also producing concise models.

Data can be transformed at the preprocessing stage to increase the quality of the knowledge
obtained, and GP can be used to perform this transformation (Espejo et al., 2010). Badran and
Rockett (2012) proposed multi-objective GP to evolve a feature extraction stage for multiple-class
classiﬁers. They found mappings that transform the input space into a new multi-dimensional
decision space to increase the discrimination between all classes; the number of dimensions of this
decision space is optimized as part of the evolutionary process. Ingalalli et al. (2014) introduced
a GP framework called Multi-dimensional Multi-class Genetic Programming (M2GP). The main
idea is to transform the original space into another one using functions evolved with GP, then, a

5

centroid is calculated for each class, and the vectors are assigned to the class that corresponds to
the nearest centroid using the Mahalanobis distance. M2GP takes as an argument the dimension
of the transformed space. This parameter is evolved in M3GP (Munoz et al., 2015) by including
specialized search operators that can increase or decrease the number of feature dimensions pro-
duced by each tree. They extended M3GP and proposed M4GP (La Cava et al., 2019) that uses
a stack-based representation in addition to new selection methods, namely lexicase selection and
age-ﬁtness Pareto survival.

Naredo et al. (2016) used Novelty Search (NS) for evolving GP classiﬁers based on M3GP,
where the diﬀerence is the procedure to compute the ﬁtness. Each GP individual is represented
as a binary vector whose length is the training set size, and each vector element is set to 1 if the
classiﬁer assigns the class label correctly and 0 otherwise. Then, those binary vectors are used
to measure the sparseness among individuals, and the more the sparseness, the higher the ﬁtness
value. Their results show that all their NS variants achieve competitive results relative to the
traditional objective-based.

It
Auto machine learning consists of obtaining a classiﬁer (or a regressor) automatically.
includes the steps of preprocessing, feature selection, classiﬁer selection, and hyperparameters
tuning. Feurer et al. (2015) developed a robust automated machine learning (AutoML) technique
using Bayesian optimization methods. It is based on scikit-learn (Pedregosa et al., 2011), using 15
classiﬁers, 14 feature preprocessing methods, and 4 data preprocessing methods; giving rise to a
structured hypothesis space with 110 hyperparameters. Olson et al. (2016) proposed the use of GP
to develop an algorithm that automatically constructs and optimizes machine learning pipelines
through a Tree-based Pipeline Optimization Tool (TPOT). On classiﬁcation, the objective consists
of maximizing the accuracy score performing a searching of the combinations of 14 preprocessors,
ﬁve feature selectors, and 11 classiﬁers; all these techniques are implemented on scikit-learn. It is
interesting to note that TPOT uses a tree-based GP programming approach where the diﬀerent
learning process components are nodes in a tree, and traditional subtree crossover is used as a
genetic operator.

The use of the proposed selection heuristics improves EvoDAG, a GP system described in
Section 3, making it competitive with the auto-machine learning techniques explained above and
other state-of-the-art classiﬁers.

3 Genetic Programming System

We decided to implement the proposed selection heuristics and the selection heuristics of the
state-of-the-art in our previously developed GP system called EvoDAG2 (Graﬀ et al., 2016, 2017).
EvoDAG is inspired by the implementation of GSGP performed by Castelli et al. (2015a), where
the main idea is to keep track of all the individuals and their behavior, leading to an eﬃcient
evaluation of the oﬀspring whose complexity depends only on the number of ﬁtness cases. Let us
recall that the oﬀspring, in the geometric semantic crossover, is (cid:126)o = r (cid:126)p1 + (1 − r) (cid:126)p2, where r is a
random function or a constant, and, (cid:126)p1 and (cid:126)p2 are the parents’ semantics. As it was explained in
the previous section, in (Graﬀ et al., 2015b), we decided to extend this operation by allowing the
oﬀspring to be a linear combination of the parents, that is, (cid:126)o = θ1 (cid:126)p1 + θ2 (cid:126)p2, where θ1 and θ2 are
obtained using ordinary least squares (OLS) minimizing the diﬀerence between the oﬀspring and
the target semantics. Continuing with this line of research, in (Graﬀ et al., 2016), we investigated
the case when the oﬀspring is a linear combination of more than two parents, and, also, to include
the possibility that the parents could be combined using a function randomly selected from the
function set.

EvoDAG, as customary, uses a function set F = {(cid:80)

·, | · |, sin, tan,
atan, tanh, hypot2, NB5, MN5, NC2}, and a terminal set T = {x1, . . . , xm}, to create the indi-
viduals. It is also included in F classiﬁers such as Naive Bayes with Gaussian distribution (NB5),
with Multinomial distribution (MN5), and Nearest Centroid (NC2). The function-set elements
are traditional operations where the subscript indicates the number of arguments. EvoDAG’s

20, max5, min5,

60, (cid:81)

√

2https://github.com/mgraﬀg/EvoDAG

6

default parameters, including the number of arguments, were deﬁned performing a random search
(Bergstra and Bengio, 2012), on the parameter space, using as a benchmark of classiﬁcation prob-
lems that included diﬀerent sentiment analysis problems as well as problems taken from UCI
repository (not included in the problems used to measure the performance of the selection heuris-
tics). The ﬁnal values were the consensus of the parameters obtaining the best performance in
the problems tested.

The initial population starts with P = {θ1x1, . . . , θmxm, NB(x1, . . . , xm), MN(x1, . . . , xm),
NC(x1, . . . , xm)}, where xi is the i-th input, and θi is obtained using OLS. In the case that the num-
ber of individuals is lower than the population size, the process starts including an individual cre-
ated by randomly selecting a function from F and the arguments are drawn from the current pop-
ulation P. For example, let hypot be the selected function, and the ﬁrst and second arguments are
θ2x2, and NB(x1, . . . , xm). Then, the individual inserted to P is θ hypot(θ2x2, NB(x1, . . . , xm)),
where θ is obtained using OLS. This process continues until the population size is reached; EvoDAG
sets population size of 4000.

EvoDAG uses a steady-state evolution; consequently, P is updated by replacing a current
individual, selected using a negative selection, with an oﬀspring that can be selected as a parent
just after being inserted in P. The evolution process is similar to the one used to create the initial
population, and the diﬀerence is in the procedure used to select the arguments. That is, a function
f is selected from F, its arguments are selected from P using tournament selection or any of the
proposed selection heuristics, and ﬁnally, the parameters θ associated to f are optimized using
OLS. The addition is deﬁned as (cid:80)
i θixi, where xi is an individual in P. The rest of the arithmetic
functions, trigonometric functions, min, and max are deﬁned as θf (. . . , xi, . . .), where f is the
function at hand, and xi is an individual in P. For preventing overﬁtting, EvoDAG stops the
evolutionary process using early stopping; that is, the training set is split into a smaller training
set (50% reduction) and a validation set containing the remaining elements. The training set is
used to calculate the ﬁtness and the parameters θ. The evolution stops when the best individual
on the validation set has not been updated in a deﬁned number of evaluations; EvoDAG sets this
as 4000. The ﬁnal model corresponds to the best individual in the validation set found during the
whole evolutionary process.

At this point, it is worth mentioning that EvoDAG uses a one-vs-rest scheme on classiﬁcation
problems. That is, a problem with k diﬀerent classes is converted into k problems; each one
assigns 1 to the current class and −1 to the other labels. Instead of evolving one tree per class,
as done, for example, in Muni et al. (2004), we decided to use only one tree and optimize k
diﬀerent θ parameters, one for each label. The result is that each node outputs k values, and
the class is the one with the highest value. In the nodes representing classiﬁers, like Naive Bayes
In order to provide an idea of the type
or Nearest Centroid, the output is the log-likelihood.
of models produced by EvoDAG, Figure 1 presents a model of the Iris dataset. The inputs
(x0, . . . , x3, NB, MN, NC) are at the bottom of the ﬁgure. The computation ﬂow goes from bottom
to top; the output node is at the top of the ﬁgure, i.e., Naive Bayes using Gaussian distribution.
The ﬁgure helps to understand the role of optimizing the k set of parameters, one for each class,
where each node outputs k values; consequently, each node is a classiﬁer. EvoDAG uses macro-
F1 score to calculate the individuals’ ﬁtness. The macro-F1 score was chosen because it helps to
handle imbalanced datasets. The class imbalance problem typically occurs when, in a classiﬁcation
In such cases, standard
problem, there are many more instances of some classes than others.
classiﬁers tend to be overwhelmed by the class with more examples ignoring the less represented
classes (Chawla et al., 2004).

It is well known that in evolutionary algorithms, there are runs that do not produce an ac-
ceptable result, to improve stability, we decided to use Bagging (Breiman, 1996) in our approach.
We create 30 diﬀerent models by randomly selecting 50% samples for training and the remain-
ing for validation. A bagging estimator can be expected to perform similarly by either drawing
n elements from the training set with-replacement or selecting n
2 elements without-replacement
(Friedman and Hall, 2007). In addition, we reduce the learning complexity that, in EvoDAG’s
case, is measured in terms of training samples. EvoDAG’s ﬁnal prediction is the average of the
models’ predictions.

7

Figure 1: A model evolved by EvoDAG on the Iris dataset. The inputs are in the bottom of the
ﬁgure and the output is on the top.

4 Selection Heuristics

This document proposes selection heuristics for GP tailored to classiﬁcation problems based on
the idea that functions’ properties and individuals’ semantics can guide parent selection. The
heuristics replace the ﬁtness function used in the selection procedure - tested in particular in
tournament selection - to select the parent. Let us recall that in a steady-state evolution, there
are two stages where selection takes place. On the one hand, the selection is used to choose the
parents, and on the other hand, the selection is applied to decide which individual, in the current
population, is replaced by the oﬀspring. This last one is called negative selection. The most
popular selection method in GP is tournament selection (Fang and Li, 2010), and also, negative
selection is commonly performed using the same selection scheme; nonetheless, in the latter case,
the winner of the tournament is the one with the worst ﬁtness.
In the rest of the section, we
describe the process of creating an oﬀspring in EvoDAG, and the traditional tournament selection
(based on ﬁtness), random selection, and our three proposed selection heuristics.

In EvoDAG, the process of creating an oﬀspring starts by selecting a function from the function
set F, and then parent selection needs to be performed to choose each one of the k arguments (or
parents). Figure 2 shows an example of the traditional tournament selection (with tournament size
two) where the function (cid:80) was selected, and 3 individuals need to be selected as arguments from
the population P for creating the new oﬀspring. It can be seen that for selecting each argument,
a binary tournament needs to be performed. For selecting an argument, two individuals from the
population are randomly chosen, and the one with the highest ﬁtness is selected as the argument;
each tournament is depicted using a diﬀerent color. The procedure represented in Figure 2 also
helps to describe random selection where each argument of the function (cid:80) is selected randomly
from the population, and a tournament is not needed. As can be seen, random selection is the most
straightforward and less expensive strategy given that there is no need to perform the tournament.
Let us start by describing the selection heuristics that were inspired by functions’ properties.
The functions are the addition and the classiﬁers Naive Bayes and Nearest Centroid. The addition

8

Figure 2: Diagram of tournament selection using the ﬁtness function to decide the winner of the
tournament.

is deﬁned in our GP system as (cid:80)
k θkpk, where OLS and target semantics are used to estimate
θk. As can be seen, to accurately identify the k coeﬃcients, the exogenous variables pk must
be linearly independent.
In general, knowing whether a set of vectors is linearly independent
requires a non-zero determinant; however, the trivial case is when these vectors are orthogonal.
Based on Brereton (2016), uncorrelated vectors are also linearly independent. In Naive Bayes’s
case, its model assumes that given a class, the features are independent. As expected, the process
to calculate independence is expensive, so instead, we use the correlation among features in our
heuristic. The correlation of two statistically independent variables is zero, although the inverse
is not necessarily true. Finally, Nearest Centroid (NC) is a classiﬁer representing each class
with its centroid calculated with the elements associated with that class. The label of a given
instance corresponds to the class of the closest centroid. Therefore, we think it might improve the
performance of NC if the diversity of the inputs is increased.

To sum up, the three functions (addition, Naive Bayes, and Nearest Centroid) perform better
when their input vectors are orthogonal, uncorrelated, or independent. The main idea is quite
similar to the proposal in Novelty Search (Lehman and Stanley, 2011), where instead of promoting
ﬁtness, they promote diversity.
In our case, we want ﬁt individuals for the ﬁnal solution, but
we select parents promoting diversity among them. The proposed selection heuristics use the
individuals’ semantics for choosing diverse parents.

The ﬁrst selection heuristic ideally would select orthogonal vectors; evidently, this event is
unlikely, so a function that measures the closeness to orthogonality is needed. The cosine similarity
is such a measure, it is deﬁned in Equation 1, where (cid:126)v1 and (cid:126)v2 are vectors, · represents the dot
Its range is between −1 and 1, where 1 indicates that the
product, and (cid:107)(cid:126)v(cid:107) the norm of (cid:126)v.
vectors are in the same direction, −1 exactly the opposite direction, and 0 indicates that vectors

9

Figure 3: Diagram of parent selection based on heuristics.

are orthogonal. It is worth mentioning that the absolute of the cosine similarity is used instead
because a cosine-similarity value of 1 or −1 is similar regarding the linear independence.

CS( (cid:126)v1, (cid:126)v2) = cos(θ) =

(cid:126)v1 · (cid:126)v2
(cid:107) (cid:126)v1(cid:107) (cid:107) (cid:126)v2(cid:107)

(1)

The process of selecting a parent using the absolute cosine similarity is depicted in Figure
3. Let us recall that tournament selection (with a tournament size of two) is being used, and the
selection heuristic replaces the ﬁtness function used traditionally in the tournament to select the
parents. Under this conﬁguration, the ﬁgure depicts the selection of three arguments for being used
with the addition function. The ﬁrst of the arguments is selected randomly from the population;
this is depicted on the red box. Selecting the second argument (box in green) requires choosing
two individuals from the population randomly and then comparing them using the absolute cosine
similarity between each of the selected individuals and the ﬁrst argument. The second argument
is the one with the lowest value: the closest to a 90-degree angle. The absolute cosine similarity
is obtained using the individuals’ semantics, and these are vectors or a list of vectors (in case
of multi-class problems); in the latter case, the average of the absolute cosine similarity is used
instead. Finally, selecting the last argument (blue box) is equivalent to the previous one. That
is, the individuals selected from the population are compared using the absolute cosine similarity
with respect to the ﬁrst argument selected. Although this process does not guarantee that all
the arguments are unique, the implementation ensures that all individuals are diﬀerent; this is
depicted in the ﬁgure by representing each possible argument with a diﬀerent tree.

The second heuristic uses the Person’s Correlation Coeﬃcient to select uncorrelated in-
puts. The correlation coeﬃcient is deﬁned in Equation 2, where (cid:126)v1 and (cid:126)v2 are vectors with the
values of the variables, · represents the dot product, ¯(cid:126)v is the average value of vector (cid:126)v, and (cid:107)(cid:126)v(cid:107)
the norm of (cid:126)v. Pearson’s range is between −1 and 1, where 1 indicates positively correlated,
0 represents no linear correlation, and −1 represents a total negative linear correlation. It can

10

be observed that Equations 1 and 2 are similar. The diﬀerence is that correlation (Equation 2)
subtracts the average value to the vectors. It means that the heuristics based on cosine similarity
and correlation will be the same when the data is zero-centering.

ρ (cid:126)v1, (cid:126)v2 =

( (cid:126)v1 − ¯(cid:126)v1) · ( (cid:126)v2 − ¯(cid:126)v2)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13) (cid:126)v2 − ¯(cid:126)v2
(cid:13) (cid:126)v1 − ¯(cid:126)v1
(cid:13)
(cid:13)

(2)

Figure 3 depicts the process of selecting three arguments for the addition function. The process
is similar to the one used for the cosine similarity, being the only diﬀerence between them the use
of the absolute value of the Pearson’s coeﬃcient instead of the cosine similarity. That is, the ﬁrst
argument is selected randomly from the population, whereas the second and third arguments are
the individuals whose semantics obtained the lowest absolute Pearson’s correlation coeﬃcient for
each tournament.

The previous selection heuristics increase the variety of the inputs using cosine similarity
and Pearson’s Correlation coeﬃcient. However, these similarities do not consider the prediction
labels. In classiﬁcation problems, the individual’s outputs are transformed to obtain the labels
taking, for example, the maximum value index in a multiple output representation. The idea of
the last heuristic is to complement the previous selection heuristics by measuring diversity using
the predicted labels; the measure used with this purpose is named agreement – deﬁned in the
Equation 33, where (cid:126)p1 and (cid:126)p2 represent the labels vectors of two individuals, n is the number of
samples, and δ(.) returns 1 if its input is true and 0 otherwise.

agr( (cid:126)p1, (cid:126)p2) =

1
n

(cid:88)

i

δ(p1i == p2i)

(3)

Figure 3 depicts the procedure to select three arguments for the addition function using the
agreement as the selection heuristic. The process is similar to the ones used for the previous
selection heuristics. That is, the ﬁrst argument is an individual randomly selected from the
population. The second and third argument is selected performing a tournament where the ﬁtness
function is replaced by agreement. For example, the second argument (green box) is selected
by ﬁrst transforming the ﬁrst argument’s outputs into labels and transforming the outputs of
the two individuals selected in the tournament. The labels obtained are used to compute two
agreement values, one for each individual in the tournament using in common the labels of the ﬁrst
argument, i.e., the individual selected randomly. The second argument selected is the individual
with the lowest agreement, i.e., the one that optimizes the variety. The third argument is selected
performing another tournament following an equivalent method used on the second argument.

To sum up, three selection heuristics are proposed, in this contribution, corresponding to the
use of the absolute cosine similarity, Pearsons’ Correlation coeﬃcient, and agreement. These
heuristics replace the ﬁtness function in the tournament selection procedure, and, consequently,
the selected individuals are the ones with the lowest values on the particular heuristic used.

5 Experiments and results

The selection heuristics performance is analyzed in this section and compared against our GP
system with the default parameters, with state-of-the-art selection heuristics, and with traditional
classiﬁers and classiﬁers using full-model selection.

5.1 Datasets

The classiﬁcation problems used as benchmarks are 30 datasets taken from the UCI repository
(Dua and Graﬀ, 2017). Table 1 shows the dataset information. It can be seen that the datasets
are heterogeneous in terms of the number of samples, variables, and classes. Additionally, some of
the classiﬁcation problems are balanced, and others are imbalanced. We use Shannon’s entropy to

3Note that in the case (cid:126)p2 is the target behavior, then the agreement is computing the accuracy of (cid:126)p1.

11

indicate the degree of the class-imbalance in the problem. It is deﬁned as H(X) = − (cid:80)
i pi log(pi),
where pi represents the probability of the category i. We calculate those probabilities by counting
the frequencies of each category. Besides, for normalizing, we use the logarithm base on the
number of categories. For example, if the classiﬁcation problem has four categories, we calculate
the Shannon’s entropy as H(X) = − (cid:80)
i pi log4(pi). In this sense, if the value is equal to 1.0, it
indicates a perfect balance problem. In opposite, the smaller the value, the bigger the imbalance.

Table 1: Datasets used to compare the performance of the algorithms. These problems are taken
from the UCI repository. The table includes Shannon’s entropy to indicate the degree of the class-
imbalance, where the value 1.0 indicates that the samples are perfectly balanced. In opposite, the
smaller the value, the bigger the imbalance.

Dataset

ad
adult
agaricus-lepiota
aps-failure
banknote
bank
biodeg
car
census-income
cmc
dota2
drug-consumption
fertility
IndianLiverPatient
iris
krkopt
letter-recognition
magic04
ml-prove
musk1
musk2
optdigits
page-blocks
parkinsons
pendigits
segmentation
sensorless
tae
wine
yeast

Train
samples
2295
32561
5686
60000
960
31647
738
1209
199523
1031
92650
1319
69
407
105
19639
14000
13314
4588
333
4618
3823
3831
135
7494
210
40956
105
123
1038

Test
samples
984
16281
2438
16000
412
13564
317
519
99762
442
10294
566
30
175
45
8417
6000
5706
1530
143
1980
1797
1642
59
3498
2100
17553
45
53
446

Variables Classes Classes
entropy
0.58
0.8
0.81
0.12
0.99
0.52
0.91
0.6
0.34
0.98
1.0
0.44
0.43
0.85
1.0
0.84
1.0
0.93
0.98
0.99
0.61
1.0
0.27
0.79
1.0
1.0
1.0
0.99
0.99
0.76

1557
14
22
170
4
16
41
6
41
9
116
30
9
10
4
6
16
10
56
166
166
64
10
22
16
19
48
5
13
9

2
2
7
2
2
2
2
4
2
3
2
7
2
2
3
18
26
2
2
2
2
10
5
2
10
7
11
3
3
10

The performance of the classiﬁers is measured in a test set. Some of the problems are already
split between a training set and a test set in the repository. For those problems that this partition
is not present, we performed cross-validation; that is, we randomly split the dataset using 70% of
the samples for the training set and 30% for the test set.

12

5.2 Computer Equipment

The computer characteristics where the experiments were executed are shown in Table 2. For a
fair comparison, the experiments were executed using only one core.

Table 2: Characteristics of the computer where the experiments were executed

Operating system
Processor (CPU)
Processor (CPU) speed
Computer memory size
Hard disk size
Cores number

Ubuntu 16.04.2 LTS
Intel (R) Xeon(R) CPU E5-2680 v4
2.5GHz
256 GB
1 TB
14

5.3 Performance Metrics

The classiﬁers’ performance is analyzed in terms of precision and time spent on training using two
metrics: macro-F1 and time (in seconds) per sample.

Its
Accuracy is maybe the most used metric for measuring the performance of classiﬁers.
value ranges from 0 to 1, being one the best performance and zero the worst. It can be seen as
the percentage of samples that are correctly predicted. However, if the classes are imbalanced,
as the problems in this benchmark, accuracy is not reliable. On the other hand, the F1 score
measures a binary classiﬁer’s performance taking into account the positive class. It is robust to
imbalanced problems. For a multi-class problem, the F1 score can be extended as the macro-F1
score that corresponds to the average of the F1 score per class. Besides, most of the comparisons
are performed based on the rank of macro-F1. It means, for each dataset, the classiﬁers are ranked
according to their performance. The number 1 is assigned to the classiﬁer with the highest value
in macro-F1, number 2 corresponds to the one with the second-highest value in macro-F1, and
so on. If several classiﬁers have the same value in macro-F1, they got the same rank, and the
following rank number will be increased the number of repeated values.

In addition to a classiﬁer’s performance for predicting the samples correctly, time is an es-
sential factor in an algorithm. When the number of samples in the training set is small, all the
algorithms learn the model quickly. However, if the number of samples grows, some algorithms
spend considerably more and more time, and in some cases, it could be impossible to wait until
the algorithm converges. As we mention in the previous section, the datasets vary on the number
of samples, and, logically, algorithms spend more time learning big datasets. In that sense, to
normalize the time, and with the idea of making comparisons based on this measure, we divided
the time (in seconds) that algorithms spend in the training phase by the number of samples in
the datasets.

5.4 Comparison of the Proposed Selection Heuristics against Classic

Tournament Selection

We performed a comparison of diﬀerent selection schemes for parent and negative selection. Specif-
ically for parent selection, we compare the use of the following techniques: (1) traditional tourna-
ment selection, which uses the individual’s ﬁtness (ﬁt), (2) random selection (rnd), (3) tournament
selection with the absolute of cosine similarity (sim), (4) tournament selection with the absolute
of Pearson’s correlation coeﬃcient (prs), and, (5) tournament selection with the agreement (agr).
The latest three selection methods correspond to the proposed selection heuristics; in this case, the
selection heuristics are applied only for the functions that inspired them, i.e., addition ((cid:80)), Naive
Bayes (NB and MN), and Nearest Centroid (NC), in the rest of the functions random selection is
used instead. In addition, for negative selection, we analyze the use of the traditional negative

13

selection, which uses the individual’s ﬁtness to select the worst individual in the tournament (ﬁt),
and random selection (rnd).

The selection schemes were tested on our GP system (EvoDAG). To improve the reading,
we use the following notation. The selection scheme used for parent selection is followed by the
symbol “-”, and then comes the abbreviation of the negative selection scheme. For example, sim-ﬁt
means tournament selection with the absolute cosine similarity for parent selection and traditional
negative selection are used. In total, we analyze the performance of eight combinations: ﬁt-ﬁt, rnd-
rnd, sim-ﬁt, sim-rnd, prs-ﬁt, prs-rnd, agr-ﬁt, and agr-rnd. Furthermore, to complete the picture
of the proposed selection heuristics and the relation with the functions that served as inspiration,
we decided to include in the comparison the performance GP systems when the heuristics are used
in all the functions with two or more arguments. These systems are identiﬁed with the symbol *.
For example, agr-rnd indicates that agreement is used with the functions (cid:80), NB, MN, and NC;
whereas, agr-rnd* means that the heuristic is used with the functions: (cid:80), (cid:81), max, min, hypot,
NB, MN, and NC.

Figure 4 shows the performance for the diﬀerent techniques used for parent and negative se-
lection on classiﬁcation tasks. The detailed results can be observed on Table 4. Figure 4a shows
the performance results based on macro-F1 ranks over the test sets. It can be seen that the best
performance is obtained by selecting the parents with the agreement heuristic and random nega-
tive selection (agr-rnd), followed by the use of the same scheme for parent selection and negative
tournament selection (agr-ﬁt). The combinations agr-rnd, agr-ﬁt, sim-ﬁt, prs-ﬁt*, prs-rnd, prs-ﬁt,
prs-rnd*, sim-ﬁt*, sim-rnd, and sim-rnd* are better than ﬁt-ﬁt (i.e., selection using the ﬁtness
function) in terms of macro-F1 average rank. It means that our proposed heuristics improve the
performance of the classical selection schemes (ﬁt-ﬁt). Random selection for parent and negative
selection, rnd-rnd, also improves the performance of EvoDAG using the classical selection schemes
based on ﬁtness (ﬁt-ﬁt). It indicates the importance of population diversity, as mentioned in Nov-
elty Search Lehman and Stanley (2011). Besides, as we mention in Section 3, once the individual is
created, the function parameters are optimized using OLS and the target semantics. Our heuristic
based on agreement works well because it is quite similar to the Novelty Search implemented in
(Naredo et al., 2016), but instead of improving diversity among all individuals in the population,
it enhances the diversity among parents.

From the ﬁgure, it can also be observed that there exists a tendency when the heuristics
(identiﬁed with the symbol *) are applied to all functions with more than one argument ((cid:80),
(cid:81), max, min, hypot, NB, MN, and NC); the results are worse than those systems that use the
proposed heuristics on the functions that inspired them (i.e., addition, Naive Bayes and Nearest
Centroid). It aﬃrms the importance of generating heuristics that are speciﬁcally designed based
on the functions’ properties. Comparing by the time that the classiﬁers spend in the training
phase (see Figure 4.b), it can be seen that rnd-rnd is the fastest; this is because it is the most
straightforward.

For the statistical analysis, we use the Friedman and Nemenyi tests (Demˇsar, 2006). Macro-
F1 ranks values were used for the Friedman test where there was rejected the null hypothesis,
with a p-value of 4.39e − 22. Based on Nemenyi test, the groups of techniques that are not
signiﬁcantly diﬀerent (at p=0.10) are: Group 1 (agr-rnd, agr-ﬁt, rnd-rnd, sim-ﬁt, prs-ﬁt*, prs-rnd,
prs-rnd*, prs-ﬁt, sim-ﬁt*, sim-rnd, and sim-rnd*), Group 2 (agr-ﬁt, rnd-rnd, sim-ﬁt, prs-ﬁt*, prs-
rnd, prs-rnd*, prs-ﬁt, sim-ﬁt*, sim-rnd, sim-rnd*, and ﬁt-ﬁt), and Group 3 (agr-rnd*, agr-ﬁt*).
It indicates that our proposed heuristic combination based on the agreement for parent selection
and random negative selection (agr-rnd) performs statistically better than the classical tournament
selection using ﬁtness (ﬁt-ﬁt) because they belong to diﬀerent groups, i.e., Group 1 and Group 2,
respectively. The test also indicates that there is not enough evidence to diﬀerentiate the systems
of Group 2 (except ﬁt-ﬁt) with system agr-rnd.

14

(a)

(b)

Figure 4: Selection schemes comparison. a) Macro-F1 ranks that are measured over the test
datasets. b) Time, in seconds, required by the diﬀerent selection technique combinations in the
In both
training phase. The time is divided by the number of train samples in the datasets.
ﬁgures, green boxplots represent where the selection heuristics (sim, prs, or agr) are applied to all
functions. The average rank, or time per sample, sorts the classiﬁers, and it appears on the left.

15

5.5 Comparison of the Proposed Selection Heuristics against State-of-

the-Art Selection Schemes

As we mention in Section 2, there are selection heuristics related to this research. Consequently,
we decided to compare our selection heuristics with the two most similar methods; these are
Angle-Driven-Selection (Chen et al., 2019) and Novelty Search (Lehman and Stanley, 2011). In
Angle-Driven Selection (ads), the ﬁrst individual is selected using traditional tournament selection
and then replaces the ﬁtness function, in the tournament selection, with their relative angle in
the error space. As can be seen, in Angle-Drive-Selection, the ﬁrst individual is chosen using the
ﬁtness, whereas, in our proposal, it is selected randomly. Therefore, we decided to add another
parameter to indicate whether the ﬁrst individual is selected using the ﬁtness (ﬁt) or random
(rnd). The combinations of selection techniques’ notation is as follows. The symbol “-” follows
the parent selection technique, then comes the abbreviation of the negative selection scheme, and,
for our heuristics and ads, at the ending, after the symbols “–”, comes the abbreviation of the
scheme to select the ﬁrst individual. For example, agr-rnd–ﬁt means that agreement is used for
parent selection, the negative selection is performed randomly, and the ﬁrst individual is selected
using the ﬁtness.

Figure 5: Proposed heuristics against state-of-the-art selection schemes based on macro-F1. Box-
plots present the ranks, and those are measured using macro-F1 over the test datasets. Gray
boxplots represent the selection techniques from the state-of-the-art, Novelty Search (nvs) and
Angle-Driven Selection (ads). The average rank sorts the classiﬁers, and it appears on the left.

Figure 5 presents the results of the comparison, based on macro-F1, of our proposed heuristics,
agreement, Pearson’s Correlation coeﬃcient, and cosine similarity (agr, prs, and sim) against state-
of-the-art selection techniques: Angle-Driven Selection (ads) and Novelty Search (nvs). Tables
5 and 6 show the detailed results. It can be observed that the performance of our heuristics is
generally better than Angle-Driven Selection (ads) and Novelty Search (nvs). Using Friedman and

16

Nemenyi tests (Demˇsar, 2006), it was found that agr-rnd–rnd, agr-ﬁt–ﬁt, agr-ﬁt–rnd, rnd-rnd, sim-
ﬁt–rnd, agr-rnd–ﬁt, prs-ﬁt–rnd, prs-rnd–rnd, ads-rnd–rnd, and sim-rnd–rnd are not signiﬁcantly
diﬀerent (at p = 0.10), but agr-rnd–rnd is signiﬁcantly better than novelty search (nvs-rnd),
angle-driven with the original proposal of selecting the ﬁrst individual at random (ads-ﬁt–ﬁt),
ﬁt-ﬁt, ads-rnd–rnd*, and ads-ﬁt–ﬁt*.

In the original proposal of Angle-Driven selection (Chen et al., 2019), it is implemented in a
Geometric Semantic GP system. However, in this case, it is applied in EvoDAG. Angle-Driven
selection is quite similar to the proposed heuristics based on Pearson’s Correlation coeﬃcient
and cosine similarity (albeit following a diﬀerent path). These techniques use the geometry of
individuals’ semantics for parent selection. ADS measures the angle between relative semantics
(see Section 2), while our heuristics measure the angle between the semantics and the centered
semantics (see Section 4). On Figure 5, it can be observed that Angle-Driven selection (ads-rnd–
rnd) performs similar to Pearson’s Correlation coeﬃcient (prs-rnd–rnd) and cosine similarity (sim-
rnd–rnd); in fact, its rank is in the middle of these two systems. Besides, Angle-Drive Selection is
better when it uses the combination of selection schemes ads-rnd–rnd than the original proposal
ads-ﬁt–ﬁt. As our heuristics behavior, we can see that Angle-Drive Selection works better when
applied only to the functions addition, Naive Bayes, and Nearest Centroid than when applied to
all functions with more than one argument.

On the other hand, Novelty Search was used in a traditional GP system to optimize the inputs
of a Nearest Centroid classiﬁer (Naredo et al., 2016). An individual’s novelty is calculated from
the whole population, not only of the individuals participating in the tournament as done in our
proposed selection heuristics. Novelty Search’s performance is just below our GP system with
the default parameters (ﬁt-ﬁt), and it is the third system with the worst rank. The performance
obtained by Novelty Search might indicate that it is better to use only the information of the
individuals participating in the tournament to compute the similarity. The agreement selection
heuristic could be seen as a way to transform the novelty search measure using only the individuals
participating in the tournament.

5.6 Comparison of Proposed Selection Heuristics against State-of-the-

Art Classiﬁers

After analyzing the diﬀerent selection schemes’ performance, it is the moment to compare our
selection heuristics against state-of-the-art classiﬁers. We chose the combination of the selection
schemes: agr-rnd, rnd-rnd, ﬁt-ﬁt, ads-rnd, nvs-rnd. The reason is that agr-rnd is the combination
that gives the best results, rnd-rnd represents the simplest schemes being also highly competi-
tive, ﬁt-ﬁt represents the traditional tournament selection, and ﬁnally, ads-rnd and nvs-rnd are
the state-of-the-art selection schemes. We decided to perform the comparison against sixteen
classiﬁers of the scikit-learn python library (Pedregosa et al., 2011), all of them using their de-
fault parameters. Speciﬁcally, these classiﬁers are Perceptron, MLPClassiﬁer, BernoulliNB, Gaus-
sianNB, KNeighborsClassiﬁer, NearestCentroid, LogisticRegression, LinearSVC, SVC, SGDClassi-
ﬁer, PassiveAggressiveClassiﬁer, DecisionTreeClassiﬁer, ExtraTreesClassiﬁer, RandomForestClas-
siﬁer, AdaBoostClassiﬁer and GradientBoostingClassiﬁer. It is also included in the comparison
two auto-machine learning libraries: autosklearn (Feurer et al., 2015) and TPOT (Olson et al.,
2016).

Figure 6: Comparison of selection heuristics against state-of-the-art classiﬁers based on macro-F1
rank. The average rank sorts the classiﬁers, and those values appear on the left. The blue boxplots
represent the selection heuristics.

Table 3: Performance using macro-F1 (with ranks) of: tpot, autosklearn, Selection Heuristics (agr-rnd, rnd-rnd, ﬁt-ﬁt, nvs-rnd, and ads-rnd), Percep-
tron (PER), MLPClassiﬁer (MLP), BernoulliNB (NBB), GaussianNB (NB), KNeighborsClassiﬁer (KN), NearestCentroid (NC), LogisticRegression
(LR), LinearSVC (LSVC), SVC, SGDClassiﬁer (SDG), PassiveAggressiveClassiﬁer (PA), DecisionTreeClassiﬁer (DT), ExtraTreesClassiﬁer (ET),
RandomForestClassiﬁer (RF), AdaBoostClassiﬁer (AB) and GradientBoostingClassiﬁer (GB). The symbol - represents that the classiﬁer can not
solve the classiﬁcation problem. The rest of the systems are in Table 7.

tpot

acc-rnd

autosklearn

rnd-rnd

GB

ads-rnd

ﬁt-ﬁt

nvs-rnd

ET

RF

MLP

DT

ad

adult

agaricus-lepiota

aps-failure

banknote

bank

biodeg

car

census-income

cmc

dota2

0.96(4)

0.81(1)

0.67(7)

0.9(1)

1.0(1)

0.74(6)

0.81(8)

1.0(1)

0.78(1)

0.54(2)

0.59(7)

drug-consumption

0.18(12)

fertility

0.44(16)

IndianLiverPatient

0.55(16)

0.94(8)

0.79(4)

0.68(2)

0.83(8)

1.0(1)

0.76(3)

0.84(2)

0.87(6)

0.77(3)

0.54(4)

0.59(2)

0.23(2)

0.45(4)

0.66(3)

0.98(2)

0.96(3)

0.93(14)

0.96(2)

0.96(5)

0.93(12)

0.94(7)

0.94(6)

0.96(1)

0.93(11)

0.94(10)

0.81(2)

0.68(5)

0.87(2)

1.0(10)

0.71(8)

0.82(6)

0.96(3)

0.75(6)

0.55(1)

0.59(8)

0.79(5)

0.8(3)

0.68(3)

0.56(16)

0.86(3)

0.85(4)

1.0(1)

0.99(17)

0.76(1)

0.72(7)

0.85(1)

0.79(12)

0.86(7)

0.77(2)

0.53(8)

0.97(2)

0.75(5)

0.52(9)

0.59(3)

0.56(13)

0.13(20)

0.2(7)

0.19(11)

0.79(9)

0.68(4)

0.84(6)

1.0(1)

0.76(5)

0.82(7)

0.8(11)

0.75(7)

0.53(5)

0.59(4)

0.21(4)

0.79(6)

0.68(6)

0.85(5)

1.0(1)

0.76(4)

0.83(5)

0.79(8)

0.76(11)

0.77(10)

0.58(18)

0.74(12)

0.68(1)

0.43(21)

0.45(20)

0.61(11)

0.42(22)

0.83(9)

0.76(18)

0.8(12)

0.82(10)

0.83(7)

1.0(1)

1.0(12)

0.99(14)

1.0(1)

0.98(19)

0.76(2)

0.68(12)

0.7(11)

0.67(13)

0.7(9)

0.84(3)

0.81(10)

0.81(8)

0.8(11)

0.79(13)

0.84(9)

0.81(10)

0.87(5)

0.85(8)

0.59(15)

0.94(4)

0.75(4)

0.38(23)

0.72(9)

0.49(19)

0.71(10)

0.48(21)

0.53(7)

0.59(1)

0.2(8)

0.53(6)

0.47(16)

0.48(14)

0.52(10)

0.45(18)

0.59(5)

0.55(15)

0.54(16)

0.59(10)

0.52(18)

0.2(5)

0.16(16)

0.17(13)

0.45(4)

0.45(4)

0.25(1)

0.45(4)

0.2(6)

0.59(2)

0.61(6)

0.57(11)

0.59(8)

0.54(17)

0.45(4)

0.45(4)

0.44(16)

0.45(4)

0.44(16)

0.56(14)

0.69(1)

0.55(15)

0.66(2)

0.64(5)

0.45(4)

0.65(4)

0.98(8)

0.98(2)

0.98(2)

0.94(14)

0.96(10)

0.98(2)

0.96(10)

0.92(17)

0.94(14)

0.98(2)

0.96(10)

letter-recognition

0.97(2)

0.65(11)

0.91(1)

0.19(11)

-(23)

-(23)

0.2(9)

0.61(6)

0.2(10)

0.15(15)

0.18(12)

0.66(10)

0.91(7)

0.65(13)

0.65(13)

0.65(12)

0.87(2)

0.85(5)

0.87(1)

0.85(6)

0.85(3)

0.84(9)

0.83(10)

0.84(8)

1.0(1)

-(23)

0.98(1)

0.98(1)

0.85(2)

0.81(5)

0.98(1)

0.95(1)

1.0(1)

1.0(1)

0.88(5)

0.94(6)

0.95(7)

0.83(4)

0.75(9)

0.94(8)

0.91(7)

0.96(8)

1.0(1)

1.0(1)

1.0(1)

1.0(1)

1.0(13)

0.87(10)

0.87(11)

0.91(1)

0.89(4)

0.86(13)

1.0(1)

0.9(3)

0.98(2)

0.98(2)

0.94(7)

0.93(10)

0.94(9)

0.95(3)

0.92(13)

0.96(6)

0.96(4)

0.92(15)

0.94(11)

0.89(1)

0.76(12)

0.82(5)

0.76(11)

0.77(10)

0.95(8)

0.78(9)

0.82(3)

0.73(11)

0.85(1)

0.75(8)

0.67(15)

0.67(12)

0.98(3)

0.94(2)

0.94(9)

0.91(8)

1.0(3)

0.95(10)

0.94(4)

0.99(5)

0.91(6)

0.95(9)

0.96(6)

0.93(11)

0.94(10)

0.92(13)

0.51(5)

0.36(14)

0.45(6)

0.32(16)

0.52(4)

0.37(12)

1.0(1)

0.53(5)

0.98(4)

0.47(6)

1.0(1)

0.55(2)

0.98(4)

0.45(9)

0.98(4)

0.59(1)

0.98(4)

0.46(7)

0.9(11)

0.89(12)

0.96(7)

0.92(12)

0.44(7)

0.98(4)

0.3(18)

0.98(4)

0.7(4)

0.94(4)

0.84(7)

0.76(3)

0.93(5)

0.54(8)

0.92(6)

0.83(2)

0.87(8)

0.85(4)

0.77(13)

0.79(12)

1.0(17)

0.97(20)

1.0(13)

1.0(1)

0.91(2)

0.95(4)

0.87(9)

0.81(14)

0.79(16)

0.94(8)

0.95(5)

0.92(12)

0.95(9)

0.94(12)

0.96(5)

0.86(19)

0.82(6)

0.84(2)

0.96(5)

0.93(5)

1.0(2)

0.54(3)

0.98(4)

0.79(7)

0.65(15)

0.85(3)

0.81(5)

0.43(18)

0.74(10)

0.96(7)

0.97(4)

0.92(12)

0.94(3)

0.68(16)

0.95(11)

0.4(8)

1.0(4)

0.6(2)

1.0(1)

0.91(9)

0.98(6)

0.63(1)

0.14(23)

0.94(14)

iris

krkopt

magic04

ml-prove

musk1

musk2

optdigits

page-blocks

parkinsons

pendigits

segmentation

sensorless

tae

wine

yeast

Average rank

4.8

5.3

5.9

6.4

6.9

7.1

8.0

8.2

8.5

9.2

10.5

10.8

0.46(8)

0.45(10)

0.54(3)

0.44(12)

0.05(21)

0.45(11)

Figure 7: Performance of Selection Heuristics and state-of-the-art classiﬁers by dataset based on macro-F1. The classiﬁers keep their position
in all the images. Closer classiﬁers perform similarly. The macro-F1 value is represented by color, where dark red represents 1.0 and dark blue
represents 0.0. The color scale is represented on the right. The systems are: tpot, autosklearn, Selection Heuristics (agr-rnd, rnd-rnd, ﬁt-ﬁt, nvs-
rnd, and ads-rnd), Perceptron (PER), MLPClassiﬁer (MLP), BernoulliNB (NBB), GaussianNB (NB), KNeighborsClassiﬁer (KN), NearestCentroid
(NC), LogisticRegression (LR), LinearSVC (LSVC), SVC, SGDClassiﬁer (SDG), PassiveAggressiveClassiﬁer (PA), DecisionTreeClassiﬁer (DT),
ExtraTreesClassiﬁer (ET), RandomForestClassiﬁer (RF), AdaBoostClassiﬁer (AB) and GradientBoostingClassiﬁer (GB)

Table 3 and Figure 6 show the comparison of classiﬁers based on macro-F1 ranks. The best
classiﬁer, based on the results of these experiments, is TPOT, followed by our GP system using
agreement and random negative selection (agr-rnd), autosklearn, and GP with random selection
(rnd-rnd) in both tournaments (positive and negative). It can be seen that the use of our proposed
selection heuristic based on accuracy and negative random selection improves the performance of
traditional selection (ﬁt-ﬁt) and positioned it into second place. The agreement selection heuristic
with random negative selection produces a system that outperforms the scikit-learn classiﬁers, and
it is competitive with auto-machine learning libraries, i.e., TPOT and autosklearn. Additionally,
Table 3 shows that autosklearn and TPOT cannot solve some classiﬁcation problems.

Friedman’s test rejects the null hypothesis that all classiﬁers perform similarly, with a p-value
of 2.3e − 54. Nemenyi test (following the steps described in Demˇsar (2006)) results can be ob-
served in Figure 8. There were no statistical diﬀerences between TPOT, our proposed heuristics
(agr-rnd, rnd-rnd, ads-rnd, nvs-rnd), autosklearn, GradientBoosting, ExtraTrees, RandomForest,
and DecisionTree.
It can also be observed that TPOT and agr-rnd belong to diﬀerent groups
(i.e., these are statistically diﬀerent) than LogisticRegression, KNeighbors, AdaBoost, SVC, Lin-
earSVC, Naive Bayes (Gaussian and Bernoulli), NearestCentroid, PassiveAggressive, Perceptron,
and StochasticGradientDescent.

Figure 8: Comparison of all classiﬁers against each other using the macro-F1 average ranks with
the Nemenyi test. Groups of classiﬁers that are not signiﬁcantly diﬀerent (at p = 0.10) are
connected.

In order to analyze the systems’ performance, the diﬀerence in behavior, and the hardness of
the problems, we decided to depict this information using our visualization technique proposed
in S´anchez et al. (2019). The idea is to represent each classiﬁer with a point in a plane. Each
system can be seen as a vector where each dimension represents a problem, and the value is the
system’s performance (macro-F1) in that problem; using this representation, the idea is to depict
this vector in a plane where the distance is preserved. Figure 7 shows the classiﬁers’ visualization;
the color represents the macro-F1, and all the systems conserved the same position in all boxes.
Small boxes represent a problem, and the one in the center is the average of all problems. The
ﬁgure helps to identify those problems where all the systems behave similarly. For example, it

21

can be observed that all the systems ﬁnd easy the banknote and ml-prove problems. On the other
hand, all the systems ﬁnd complex the drug-consumption problem.

From the ﬁgure, we can observe that the selection heuristics are close, the classiﬁers based on
decision trees are close to the heuristics, and in opposite extremes are TPOT and autosklearn. Let
us draw a line from the left upper corner to the right upper corner; we can see that the systems
on the right of the line (including autosklearn) are in the top group shown in Figure 8 the only
system missing is MLP which is on the left.

The classiﬁers’ comparison based on the time spend in learning the model is presented in Figure
9. Tables 8, 9, and 10 show the detailed results. It can be seen that scikit-learn classiﬁers have
the best ranks; these spend from 0.007 to 0.01 seconds per sample. With the diﬀerent selection
schemes, our GP system spends more time than scikit-learn classiﬁers in the learning phase. It
spends, on average, from 0.5 to 5 seconds per sample. However, it is considerably faster than
the auto-machine learning libraries, autosklearn and TPOT, which consume on average 11.5 and
57.68 seconds, respectively. Friedman’s test rejects the null hypothesis that all classiﬁers spend
the same time, with a p-value of 7.186e − 94. Nemenyi test (following Demˇsar (2006)) results can
be observed in Figure 10. The ﬁgure shows a group formed by TPOT, the selection heuristics
(except rnd-rnd), and autosklearn. The only selection heuristic that is statistically diﬀerent from
TPOT is rnd-rnd.

Figure 9: Comparison of selection heuristics against state-of-the-art classiﬁers based on the time
required by the classiﬁers’ training phase. The time is presented in seconds, and it is the av-
erage time per sample. The average time sorts the classiﬁers, and those values are on the left.
The blue boxplots represent the selection heuristics. The time, represented on the x-axis, grows
exponentially.

6 Discussion

In this contribution, we have analyzed diﬀerent selection schemes for GP. The system used to
perform the analysis is EvoDAG. So, it is essential to mention that the signiﬁcant diﬀerence
between EvoDAG and other GP systems is that each node contains constant(s) optimized using
OLS to minimize the error. This characteristic is also present in TPOT and the Novelty Search
Classiﬁer (Naredo et al., 2016), albeit a diﬀerent optimizer is used on those research works. The
results obtained are in line with the results presented on Novelty Search (Lehman and Stanley,
2011; Naredo et al., 2016) where the idea is to abandon the ﬁtness function, although the work
presented by Naredo et al. (2016) and ours optimize constants in the evolutionary process. For

22

Figure 10: Comparison of all classiﬁers against each other using the time per sample average ranks
with the Nemenyi test. Groups of classiﬁers that are not signiﬁcantly diﬀerent (at p = 0.10) are
connected.

those systems that do not optimize constants in the evolution, we believe the random selection
schemes would not be competitive as these are in the current scenario.

It is pertinent to mention the characteristics of the problems used as benchmarks, particularly
the number of variables. It can be observed in Table 1 that the maximum number of variables is
1557, which corresponds to the ”ad” dataset; also, this dataset is easy for the majority of classiﬁers
(see Figure 7), and the second problem with more features is ”aps-failure” with 170. Consequently,
the analysis performed can guide selecting a classiﬁer when the number of features is around 100,
and it might not be of help regarding high-dimensional problems. As a side note, in preliminary
experiments, while doing research described in Graﬀ et al. (2020), we did compare EvoDAG on
text classiﬁcation problems with a representation that contains more than 10 thousand features,
and the result is that EvoDAG is not competitive against LinearSVC, neither in time nor in
performance.

Figure 7 allows us to identify a limitation of our approach, let us look at the problems ”krkopt”
and letter-recognition; these problems are easily solved by TPOT and hard for GP using our
selection heuristics. Although there is not enough evidence to draw some conclusions, it is observed
that these problems are easily solved by classiﬁers based on Decision Trees (TPOT considers
Decision Trees as its base learners) and contained the maximum number of classes, 18 and 26. As
can be seen, Decision Trees are utterly diﬀerent from the trees evolved by GP. Perhaps, the most
distinctive characteristic is that the computation ﬂow is the complement of GP trees; that is, the
starting point is the root, and the output is a leaf.

One GP characteristic that has captured researchers’ attention is the ability to create white-
box models; in this contribution, we have not adequately analyzed whether the models evolved
by our GP system, using any selection heuristic, are easy or diﬃcult to understand. Nonetheless,
we have observed some of the models evolved in a few of the problems used as benchmarks. Our
general impression is that the models evolved are complex containing at least ten inner nodes. For
example, Figure 1 presents a model for the Iris problem; clearly, this problem could have been

23

solved with a more straightforward tree obtaining similar performance. However, the system used
did not promote the development of simple models, and we will address this issue in future work.

7 Conclusion

In this research, we proposed three selection heuristics for parent selection in GP that used in-
dividuals’ semantics and were inspired by functions’ properties. These are described as follows.
First, tournament selection based on cosine similarity (sim) aims to promote the selection of par-
ents whose semantics’ vectors ideally are orthogonal. Tournament selection based on Pearson’s
Correlation coeﬃcient (prs) aims to promote the selection of parents whose semantics’ vectors are
uncorrelated. Finally, tournament selection based on the agreement (agr) tries to select parents
whose predictions are diﬀerent based on their prediction labels. These heuristics were inspired by
the properties of the addition function, and the classiﬁers Naive Bayes and Nearest Centroid. To
the best of our knowledge, this is the ﬁrst time in Genetic Programming that functions’ properties
are taken into account to design methodologies for parent selection.

We compared our proposed heuristics against the classical parent selection technique, tradi-
tional tournament selection, and random parent selection. We also tested two state-of-the-art
selection schemes, Novelty Search (nvs) and Angle-Driven Selection (ads). For negative selec-
tion, we tested the use of standard negative tournaments and random selection. Furthermore, our
selection heuristics were compared against 18 state-of-the-art classiﬁers, 16 of them from the scikit-
learn python library, and two auto-machine learning algorithms. The performance was analyzed on
thirty classiﬁcation problems taken from the UCI repository. The datasets were heterogeneous in
terms of the number of samples, variables, and some of them are balanced, and others imbalanced.
The results indicate that the selection heuristic using agreement combined with random neg-
ative selection (agr-rnd) is statistically better than the traditional selection that uses ﬁtness (i.e.,
the system identiﬁed as ﬁt-ﬁt). On the other hand, on the comparison of the selection heuristics
against diﬀerent classiﬁers, it is observed that agr-rnd is a competitive classiﬁer obtaining the
second-best rank; additionally, the diﬀerence in performance with TPOT, which obtained the best
rank, is not statistically signiﬁcant. Furthermore, it is observed that the selection heuristic iden-
tiﬁed as agr-rnd is grouped with the classiﬁers based on ensembles and the auto-machine learning
algorithms; the group also includes Multilayer Perceptron and Decision Trees.

Finally, we have only tested our GP systems in classiﬁcation problems and left aside regression
problems. As can be observed, two of the selection heuristics develop, namely cosine similarity
and Pearson’s correlation, can be used without any modiﬁcation on selection problems. On the
other hand, the agreement heuristic is only deﬁned for classiﬁcation problems. We have performed
some preliminary runs on regressions problems. The results indicated that the selection heuristics
are competitive; however, we do not have enough evidence on whether these heuristics are diﬀer-
ent from traditional selection schemes or random selection on regression. We will deal with the
comparison in regression problems as future work.

References

Badran, K. and Rockett, P. (2012). Multi-class pattern classiﬁcation using single, multi-dimensional
feature-space feature extraction evolved by multi-objective genetic programming and its application to
network intrusion detection. Genetic Programming and Evolvable Machines, 13(1):33–63.

Beadle, L. and Johnson, C. G. (2008). Semantically driven crossover in genetic programming. In 2008
IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence),
pages 111–116. IEEE.

Bergstra, J. and Bengio, Y. (2012). Random Search for Hyper-Parameter Optimization. Journal of

Machine Learning Research, 13(Feb):281–305.

Brameier, M. and Banzhaf, W. (2001). A comparison of linear genetic programming and neural networks

in medical data mining. IEEE Transactions on Evolutionary Computation, 5(1):17–26.

24

Breiman, L. (1996). Bagging predictors. Machine Learning, 24(2):123–140.

Brereton, R. G. (2016). Orthogonality, uncorrelatedness, and linear independence of vectors. Journal of

Chemometrics, 30(10):564–566.

Castelli, M., Manzoni, L., Mariot, L., and Saletta, M. (2019). Extending local search in geometric semantic

genetic programming. In EPIA Conference on Artiﬁcial Intelligence, pages 775–787. Springer.

Castelli, M., Silva, S., and Vanneschi, L. (2015a). A C++ framework for geometric semantic genetic

programming. Genetic Programming and Evolvable Machines, 16(1):73–81.

Castelli, M., Trujillo, L., Vanneschi, L., Silva, S., Z-Flores, E., and Legrand, P. (2015b). Geometric Seman-
tic Genetic Programming with Local Search. In Proceedings of the 2015 on Genetic and Evolutionary
Computation Conference - GECCO ’15, pages 999–1006, New York, New York, USA. ACM Press.

Chawla, N. V., Japkowicz, N., and Kotcz, A. (2004). Editorial: Special Issue on Learning from Imbalanced

Data Sets. ACM SIGKDD Explorations Newsletter, 6(1):1.

Chen, Q., Xue, B., and Zhang, M. (2019). Improving Generalization of Genetic Programming for Symbolic
IEEE Transactions on Evolutionary

Regression With Angle-Driven Geometric Semantic Operators.
Computation, 23(3):488–502.

Chu, T. H., Nguyen, Q. U., and O’Neill, M. (2016). Tournament selection based on statistical test in
In International Conference on Parallel Problem Solving from Nature, pages

genetic programming.
303–312. Springer.

Chu, T. H., Nguyen, Q. U., and O’Neill, M. (2018). Semantic tournament selection for genetic program-

ming based on statistical analysis of error vectors. Information Sciences, 436-437:352–366.

Demˇsar, J. (2006). Statistical Comparisons of Classiﬁers over Multiple Data Sets. Technical report.

Dua, D. and Graﬀ, C. (2017). UCI Machine Learning Repository.

Espejo, P. G., Ventura, S., and Herrera, F. (2010). A Survey on the Application of Genetic Programming
to Classiﬁcation. IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and
Reviews), 40(2):121–144.

Fang, Y. and Li, J. (2010). A Review of Tournament Selection in Genetic Programming. In International
Symposium on Intelligence Computation and Applications ISICA 2010, pages 181–192. Springer, Berlin,
Heidelberg.

Feurer, M., Klein, A., Eggensperger, K., Springenberg, J., Blum, M., and Hutter, F. (2015). Eﬃcient and

Robust Automated Machine Learning.

Folino, G., Pizzuti, C., and Spezzano, G. (2008). Training distributed gp ensemble with a selective
algorithm based on clustering and pruning for pattern classiﬁcation. IEEE Transactions on Evolutionary
Computation, 12(4):458–468.

Friedberg, R. M. (1958). A learning machine: Part i. IBM Journal of Research and Development, 2(1):2–

13.

Friedman, J. H. and Hall, P. (2007). On bagging and nonlinear estimation. Journal of Statistical Planning

and Inference, 137(3):669–683.

Galvan-Lopez, E., Cody-Kenny, B., Trujillo, L., and Kattan, A. (2013). Using semantics in the selection
mechanism in Genetic Programming: A simple method for promoting semantic diversity. In 2013 IEEE
Congress on Evolutionary Computation, pages 2972–2979. IEEE.

Graﬀ, M., Flores, J. J., and Ortiz, J. (2014a). Genetic Programming: Semantic point mutation operator
based on the partial derivative error. In 2014 IEEE International Autumn Meeting on Power, Electronics
and Computing (ROPEC), pages 1–6. IEEE.

Graﬀ, M., Graﬀ-Guerrero, A., and Cerda-Jacobo, J. (2014b). Semantic crossover based on the partial

derivative error. In European Conference on Genetic Programming, pages 37–47. Springer.

25

Graﬀ, M., Miranda-Jim´enez, S., Tellez, E. S., and Moctezuma, D. (2020). Evomsa: A multilingual

evolutionary approach for sentiment analysis. Computational Intelligence Magazine, 15:76 – 88.

Graﬀ, M., Tellez, E. S., Escalante, H. J., and Miranda-Jim´enez, S. (2017). Semantic genetic programming

for sentiment analysis. In NEO 2015, pages 43–65. Springer.

Graﬀ, M., Tellez, E. S., Escalante, H. J., and Ortiz-Bejar, J. (2015a). Memetic Genetic Programming
based on orthogonal projections in the phenotype space. In 2015 IEEE International Autumn Meeting
on Power, Electronics and Computing (ROPEC), pages 1–6. IEEE.

Graﬀ, M., Tellez, E. S., Miranda-Jimenez, S., and Escalante, H. J. (2016). EvoDAG: A semantic Genetic
Programming Python library. In 2016 IEEE International Autumn Meeting on Power, Electronics and
Computing (ROPEC), pages 1–6. IEEE.

Graﬀ, M., Tellez, E. S., Villase˜nor, E., and Miranda-Jim´enez, S. (2015b). Semantic Genetic Programming
In Research in Computing Science, pages

Operators Based on Projections in the Phenotype Space.
73–85.

Guo, H., Jack, L. B., and Nandi, A. K. (2005). Feature generation using genetic programming with
IEEE Transactions on Systems, Man, and Cybernetics, Part B

application to fault classiﬁcation.
(Cybernetics), 35(1):89–99.

Hara, A., Kushida, J.-i., and Takahama, T. (2016). Deterministic Geometric Semantic Genetic Program-
In 2016 IEEE International Conference on Systems, Man, and

ming with Optimal Mate Selection.
Cybernetics (SMC), pages 003387–003392. IEEE.

Hara, A., Ueno, Y., and Takahama, T. (2012). New crossover operator based on semantic distance
between subtrees in Genetic Programming. In 2012 IEEE International Conference on Systems, Man,
and Cybernetics (SMC), pages 721–726. IEEE.

Ingalalli, V., Silva, S., Castelli, M., and Vanneschi, L. (2014). A multi-dimensional genetic programming
In European Conference on Genetic Programming,

approach for multi-class classiﬁcation problems.
pages 48–60. Springer.

Iqbal, M., Xue, B., Al-Sahaf, H., and Zhang, M. (2017). Cross-domain reuse of extracted knowledge
IEEE Transactions on Evolutionary Computation,

in genetic programming for image classiﬁcation.
21(4):569–587.

Koza, J. R. (1992). Genetic programming: on the programming of computers by means of natural selection.

MIT Press.

Krawiec, K. (2016). Semantic Genetic Programming.

In Behavioral Program Synthesis with Genetic

Programming, pages 55–66. Springer, Cham.

Krawiec, K. and Lichocki, P. (2009). Approximating geometric crossover in semantic space. In Proceedings
of the 11th Annual conference on Genetic and evolutionary computation - GECCO ’09, page 987, New
York, New York, USA. ACM Press.

Krawiec, K. and Pawlak, T. (2012). Locally geometric semantic crossover. In Proceedings of the fourteenth
international conference on Genetic and evolutionary computation conference companion - GECCO
Companion ’12, page 1487, New York, New York, USA. ACM Press.

Krawiec, K. and Pawlak, T. (2013). Locally geometric semantic crossover: a study on the roles of semantics
and homology in recombination operators. Genetic Programming and Evolvable Machines, 14(1):31–63.

La Cava, W., Silva, S., Danai, K., Spector, L., Vanneschi, L., and Moore, J. H. (2019). Multidimensional
genetic programming for multiclass classiﬁcation. Swarm and Evolutionary Computation, 44:260–272.

Lehman, J. and Stanley, K. O. (2011). Abandoning Objectives: Evolution Through the Search for Novelty

Alone. Evolutionary Computation, 19(2):189–223.

Lichodzijewski, P. and Heywood, M. I. (2008). Managing team-based problem solving with symbiotic bid-
based genetic programming. In Proceedings of the 10th annual conference on Genetic and evolutionary
computation, pages 363–370.

26

Loveard, T. and Ciesielski, V. (2001). Representing classiﬁcation problems in genetic programming. In
Proceedings of the 2001 Congress on Evolutionary Computation (IEEE Cat. No.01TH8546), volume 2,
pages 1070–1077. IEEE.

McIntyre, A. R. and Heywood, M. I. (2011). Classiﬁcation as clustering: A pareto cooperative-competitive

gp approach. Evolutionary Computation, 19(1):137–166.

Moraglio, A., Krawiec, K., and Johnson, C. G. (2012). Geometric semantic genetic programming.

In

International Conference on Parallel Problem Solving from Nature, pages 21–31. Springer.

Moraglio, A. and Poli, R. (2004). Topological interpretation of crossover. In Genetic and Evolutionary

Computation Conference, pages 1377–1388. Springer.

Muni, D. P., Pal, N. R., and Das, J. (2004). A Novel Approach to Design Classiﬁers Using Genetic

Programming. IEEE Transactions on Evolutionary Computation, 8(2):183–196.

Munoz, L., Silva, S., and Trujillo, L. (2015). M3gp–multiclass classiﬁcation with gp. In European Confer-

ence on Genetic Programming, pages 78–91. Springer.

Naredo, E., Trujillo, L., Legrand, P., Silva, S., and Mu˜noz, L. (2016). Evolving genetic programming

classiﬁers with novelty search. Information Sciences, 369:347–367.

Nguyen, Q. U., Nguyen, X. H., O’Neill, M., and Agapitos, A. (2012). An investigation of ﬁtness sharing
with semantic and syntactic distance metrics. In European Conference on Genetic Programming, pages
109–120. Springer.

Nguyen, Q. U., Pham, T. A., Nguyen, X. H., and McDermott, J. (2016). Subtree semantic geometric

crossover for genetic programming. Genetic Programming and Evolvable Machines, 17(1):25–53.

Olson, R. S., Urbanowicz, R. J., Andrews, P. C., Lavender, N. A., Moore, J. H., et al. (2016). Automating
In European Conference on the

biomedical data science through tree-based pipeline optimization.
Applications of Evolutionary Computation, pages 123–137. Springer.

Pawlak, T. P., Wieloch, B., and Krawiec, K. (2015). Semantic Backpropagation for Designing Search
Operators in Genetic Programming. IEEE Transactions on Evolutionary Computation, 19(3):326–340.

Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer,
P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., and
Duchesnay, (2011). Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research,
12(Oct):2825–2830.

Poli, R., Langdon, W. B., and McPhee, N. F. N. (2008). A ﬁeld guide to genetic programming. Published

via lulu.com and freely available at www.gp-ﬁeld-guide.org.uk.

Ruberto, S., Vanneschi, L., Castelli, M., and Silva, S. (2014). Esagp - a semantic gp framework based
In European Conference on Genetic Programming, pages 150–161.

on alignment in the error space.
Springer.

S´anchez, C. N., Dom´ınguez-Soberanes, J., Escalona-Buend´ıa, H. B., Graﬀ, M., Guti´errez, S., and S´anchez,
G. (2019). Liking product landscape: going deeper into understanding consumers’ hedonic evaluations.
Foods, 8(10):461.

Smart, W. and Zhang, M. (2004). Continuously evolving programs in genetic programming using gradient

descent. In Proceedings of THE 7th Asia-Paciﬁc Conference on Complex Systems.

Su´arez, R. R., Graﬀ, M., and Flores, J. J. (2015). Semantic crossover operator for gp based on the second

partial derivative of the error function. Research in Computing Science, 94:87–96.

Uy, N. Q., Hoai, N. X., O’Neill, M., McKay, R. I., and Galv´an-L´opez, E. (2011). Semantically-based
crossover in genetic programming: application to real-valued symbolic regression. Genetic Programming
and Evolvable Machines, 12(2):91–119.

Vanneschi, L. (2017). An Introduction to Geometric Semantic Genetic Programming. In Oliver Sch¨utze,
Leonardo Trujillo, Pierrick Legrand, and Yazmin Maldonado, editors, Neo 2015, pages 3–42. Springer,
Cham.

27

Vanneschi, L., Castelli, M., Manzoni, L., and Silva, S. (2013). A new implementation of geometric
semantic gp and its application to problems in pharmacokinetics. In European Conference on Genetic
Programming, pages 205–216. Springer.

Vanneschi, L., Castelli, M., Scott, K., and Trujillo, L. (2019). Alignment-based genetic programming for

real life applications. Swarm and evolutionary computation, 44:840–851.

Vanneschi, L., Castelli, M., and Silva, S. (2014). A survey of semantic methods in genetic programming.

Genetic Programming and Evolvable Machines, 15(2):195–214.

Zhang, M. and Smart, W. (2006). Using gaussian distribution to construct ﬁtness functions in genetic

programming for multiclass object classiﬁcation. Pattern Recognition Letters, 27(11):1266–1274.

8 Appendix A

This appendix contains all the detailed results.

Table 4: Selection schemes comparison based on macro-F1, the ranks are in parenthesis. Macro-f1 values were measured over test datasets.

acc-rnd

agr-ﬁt

rnd-rnd

sim-ﬁt

prs-ﬁt*

prs-rnd

prs-rnd*

prs-ﬁt

sim-ﬁt*

sim-rnd

sim-rnd*

ﬁt-ﬁt

agr-rnd*

agr-ﬁt*

ad

adult

agaricus-lepiota

0.94(1)

0.79(2)

0.68(5)

0.93(3)

0.79(5)

0.79(3)

0.79(11)

0.79(12)

0.68(3)

0.68(11)

0.68(6)

0.79(6)

0.68(8)

0.93(8)

0.93(6)

0.93(10)

0.93(6)

0.92(12)

aps-failure

banknote

bank

biodeg

car

0.83(11)

0.84(4)

0.86(1)

1.0(1)

0.76(5)

0.84(5)

0.87(5)

1.0(1)

0.76(8)

0.84(7)

0.91(1)

census-income

0.77(7)

0.51(12)

0.77(1)

0.55(3)

0.53(12)

0.84(7)

0.83(10)

1.0(1)

1.0(1)

0.76(2)

0.76(10)

0.76(4)

0.84(3)

0.83(10)

0.82(12)

0.87(3)

0.77(2)

0.54(7)

0.85(8)

0.77(4)

0.55(2)

0.79(4)

0.68(9)

0.85(2)

1.0(1)

0.76(9)

0.83(8)

0.86(7)

0.93(9)

0.79(1)

0.68(1)

0.84(9)

1.0(1)

0.85(2)

0.87(4)

0.93(3)

0.79(7)

0.93(2)

0.79(8)

0.92(11)

0.93(3)

0.55(13)

0.55(14)

0.79(9)

0.79(10)

0.69(13)

0.69(13)

0.68(2)

0.68(10)

0.68(7)

0.68(12)

0.04(13)

0.04(13)

0.84(5)

0.83(12)

0.84(8)

0.85(3)

0.74(13)

0.74(13)

0.76(3)

0.76(11)

1.0(1)

0.84(3)

1.0(1)

0.76(7)

0.84(6)

1.0(1)

1.0(1)

0.82(13)

0.82(13)

0.76(6)

0.76(12)

0.71(13)

0.71(13)

0.83(8)

0.83(11)

0.63(13)

0.63(13)

0.77(9)

0.51(11)

0.77(5)

0.77(8)

0.77(6)

0.75(10)

0.42(13)

0.42(13)

0.55(1)

0.55(4)

0.55(5)

0.53(10)

0.54(6)

0.53(11)

0.47(13)

0.47(13)

0.86(6)

0.83(12)

0.89(2)

0.83(11)

0.84(10)

0.84(9)

0.29(13)

0.29(13)

0.54(9)

0.59(3)

0.23(2)

0.45(1)

0.66(4)

0.98(1)

0.19(2)

0.65(2)

0.85(4)

1.0(1)

0.95(3)

0.83(1)

0.75(2)

0.94(3)

0.91(4)

0.96(6)

cmc

dota2

drug-consumption

fertility

IndianLiverPatient

iris

krkopt

letter-recognition

magic04

ml-prove

musk1

musk2

optdigits

page-blocks

parkinsons

pendigits

segmentation

sensorless

tae

wine

yeast

0.6(1)

0.59(9)

0.59(12)

0.59(10)

0.59(11)

0.23(1)

0.45(1)

0.21(8)

0.45(1)

0.21(5)

0.21(9)

0.45(1)

0.44(11)

0.59(8)

0.21(6)

0.45(1)

0.59(4)

0.22(4)

0.45(1)

0.59(5)

0.21(7)

0.59(2)

0.2(14)

0.45(1)

0.44(11)

0.47(14)

0.48(13)

0.2(11)

0.4(13)

0.2(11)

0.4(13)

0.65(6)

0.64(12)

0.67(3)

0.65(6)

0.66(5)

0.64(10)

0.65(9)

0.64(11)

0.63(13)

0.63(13)

0.2(1)

0.14(11)

0.14(9)

0.14(12)

0.98(1)

0.96(10)

0.96(10)

0.98(1)

0.96(10)

0.88(4)

0.88(7)

0.86(11)

0.95(3)

0.94(10)

0.94(5)

0.16(5)

0.65(5)

0.84(8)

1.0(1)

0.18(3)

0.65(3)

1.0(1)

0.85(2)

0.84(11)

0.65(5)

1.0(1)

0.87(8)

0.94(9)

0.95(5)

0.81(2)

0.96(1)

0.94(12)

0.79(5)

0.76(11)

0.73(3)

0.65(14)

0.7(10)

0.65(5)

0.85(6)

1.0(1)

0.89(2)

0.95(2)

0.95(9)

0.77(7)

0.72(7)

0.14(9)

0.65(5)

0.98(1)

0.15(8)

0.65(5)

0.96(10)

0.96(10)

0.12(13)

0.12(13)

0.65(5)

0.65(5)

0.84(10)

0.83(12)

0.65(13)

0.65(13)

1.0(1)

0.9(1)

1.0(12)

0.7(13)

0.7(13)

0.86(10)

0.37(13)

0.37(13)

0.94(11)

0.95(1)

0.46(13)

0.46(13)

0.94(11)

0.94(10)

0.73(13)

0.73(13)

0.77(10)

0.77(8)

0.76(13)

0.76(13)

0.72(7)

0.67(13)

0.67(11)

0.67(11)

0.94(5)

0.92(12)

0.93(10)

0.92(11)

0.94(8)

0.8(13)

0.8(13)

0.91(3)

0.89(12)

0.9(9)

0.89(11)

0.9(7)

0.82(13)

0.82(13)

0.98(1)

0.16(7)

0.65(5)

0.84(9)

1.0(1)

0.89(3)

0.94(7)

0.95(4)

0.8(4)

0.73(3)

0.94(6)

0.92(1)

0.96(4)

0.3(14)

0.98(1)

0.16(6)

0.65(5)

0.85(3)

1.0(1)

0.95(7)

0.8(3)

0.72(7)

0.95(1)

0.9(8)

0.96(5)

0.32(7)

0.94(7)

0.91(2)

0.96(8)

0.32(8)

0.36(6)

0.32(12)

0.98(2)

0.47(1)

0.98(2)

0.45(9)

0.32(8)

0.98(2)

0.45(8)

0.98(2)

0.96(13)

0.98(11)

0.96(13)

0.98(11)

0.46(6)

0.46(3)

0.45(10)

0.45(11)

0.43(14)

0.46(2)

0.44(13)

0.44(12)

0.96(3)

0.42(4)

0.96(7)

0.95(12)

0.95(11)

0.38(5)

0.98(2)

0.3(13)

0.98(2)

0.47(1)

1.0(1)

0.96(2)

0.44(2)

0.98(2)

0.46(7)

0.8(13)

0.32(8)

0.98(2)

0.46(4)

0.8(13)

0.32(8)

0.98(2)

0.46(4)

0.88(5)

0.86(12)

0.94(4)

0.91(12)

0.95(6)

0.79(6)

0.76(12)

0.75(1)

0.95(2)

0.9(6)

0.73(6)

0.94(4)

0.91(5)

0.97(1)

0.95(10)

1.0(1)

0.76(1)

0.85(1)

0.59(6)

0.2(13)

0.45(1)

0.69(2)

0.98(1)

0.66(1)

0.85(7)

1.0(1)

0.87(9)

0.94(8)

0.96(2)

0.59(7)

0.2(10)

0.45(1)

0.71(1)

0.98(1)

0.18(4)

0.65(4)

0.85(1)

1.0(1)

0.68(4)

0.84(6)

1.0(1)

0.77(3)

0.54(8)

0.22(3)

0.45(1)

0.65(8)

0.98(1)

0.65(5)

0.85(5)

1.0(1)

0.88(6)

0.94(6)

0.95(8)

0.77(9)

0.73(3)

0.93(9)

0.9(10)

0.95(9)

0.42(3)

Average rank

3.6

4.9

5.1

5.4

5.7

5.9

5.9

5.9

6.3

6.8

7.2

7.6

11.7

11.7

Table 5: Proposed heuristics against state-of-the-art selection schemes based on macro-F1, the ranks are in parenthesis. The table continues in Table
6.

agr-rnd–rnd

agr-ﬁt–ﬁt

agr-ﬁt–rnd

rnd-rnd

sim-ﬁt–rnd

agr-rnd–ﬁt

prs-ﬁt–rnd

prs-rnd–rnd

ads-rnd–rnd

sim-rnd–rnd

ads-ﬁt–ﬁt

0.93(9)

0.93(13)

0.93(11)

0.93(15)

0.93(14)

0.93(11)

ad

adult

agaricus-lepiota

aps-failure

banknote

bank

biodeg

car

census-income

cmc

dota2

drug-consumption

fertility

IndianLiverPatient

iris

krkopt

letter-recognition

magic04

ml-prove

musk1

musk2

optdigits

page-blocks

parkinsons

pendigits

segmentation

sensorless

tae

wine

yeast

Average rank

0.94(5)

0.79(2)

0.68(7)

0.83(10)

1.0(1)

0.76(8)

0.84(5)

0.87(4)

0.77(4)

0.54(7)

0.59(3)

0.23(1)

0.45(1)

0.66(7)

0.98(1)

0.19(5)

0.65(4)

0.85(6)

1.0(1)

0.88(8)

0.94(4)

0.95(3)

0.83(1)

0.75(6)

0.94(5)

0.91(3)

0.96(7)

0.36(8)

0.98(1)

0.47(1)

4.3

0.94(6)

0.79(11)

0.69(2)

0.84(7)

1.0(1)

0.76(4)

0.85(2)

0.86(5)

0.76(6)

0.53(11)

0.59(10)

0.22(5)

0.45(1)

0.67(4)

0.98(1)

0.19(3)

0.66(2)

0.85(1)

1.0(1)

0.88(5)

0.94(8)

0.95(5)

0.79(6)

0.73(8)

0.95(3)

0.91(5)

0.97(2)

0.36(7)

0.98(1)

0.45(8)

4.7

0.79(4)

0.79(3)

0.68(4)

0.68(11)

0.84(3)

0.86(1)

1.0(1)

0.76(10)

0.84(10)

0.91(1)

0.51(12)

1.0(1)

0.76(1)

0.85(1)

0.86(7)

0.77(1)

0.55(2)

0.53(15)

0.59(6)

0.2(12)

0.45(1)

0.71(1)

0.98(1)

0.18(8)

0.65(6)

0.85(2)

1.0(1)

0.59(5)

0.2(14)

0.45(1)

0.69(2)

0.98(1)

0.2(1)

0.66(1)

0.85(9)

1.0(1)

0.86(15)

0.87(12)

0.91(15)

0.95(7)

0.94(7)

0.96(2)

0.79(5)

0.76(13)

0.75(4)

0.95(2)

0.9(8)

0.73(8)

0.94(6)

0.91(4)

0.97(1)

0.95(12)

0.32(13)

0.32(12)

0.98(1)

0.45(6)

0.98(1)

0.45(5)

0.79(8)

0.68(6)

0.84(4)

1.0(1)

0.76(5)

0.84(4)

0.83(12)

0.77(2)

0.54(6)

0.6(1)

0.22(2)

0.45(1)

0.65(9)

0.98(1)

0.14(13)

0.65(11)

0.85(7)

1.0(1)

0.88(9)

0.94(6)

0.95(9)

0.77(10)

0.73(7)

0.93(10)

0.9(13)

0.95(10)

0.42(3)

0.98(1)

0.46(3)

0.79(9)

0.69(1)

0.83(8)

1.0(1)

0.76(3)

0.84(9)

0.87(2)

0.51(13)

0.53(12)

0.59(13)

0.21(6)

0.45(1)

0.67(5)

0.98(1)

0.18(9)

0.66(3)

0.85(4)

1.0(1)

0.88(10)

0.93(10)

0.95(4)

0.81(2)

0.73(8)

0.94(4)

0.91(6)

0.96(8)

0.34(9)

0.98(1)

0.44(12)

0.79(1)

0.68(3)

0.84(6)

1.0(1)

0.76(6)

0.85(2)

0.87(3)

0.51(11)

0.55(3)

0.59(7)

0.21(9)

0.44(12)

0.65(8)

0.96(13)

0.18(6)

0.65(5)

0.85(3)

1.0(1)

0.86(14)

0.94(5)

0.96(1)

0.79(4)

0.79(5)

0.68(9)

0.83(9)

1.0(1)

0.76(7)

0.82(14)

0.85(8)

0.77(3)

0.55(1)

0.59(11)

0.21(8)

0.45(1)

0.64(13)

0.98(1)

0.16(10)

0.65(11)

0.85(5)

1.0(1)

0.88(7)

0.95(3)

0.95(8)

0.8(3)

0.65(15)

0.72(11)

0.94(7)

0.91(2)

0.96(4)

0.42(4)

0.98(12)

0.43(15)

0.95(1)

0.9(10)

0.96(6)

0.32(10)

0.98(12)

0.45(7)

6.9

5.7

5.7

6.2

6.3

6.6

0.96(1)

0.79(13)

0.68(13)

0.84(5)

1.0(1)

0.76(12)

0.82(15)

0.8(15)

0.75(8)

0.53(9)

0.59(9)

0.21(10)

0.45(1)

0.66(6)

0.96(13)

0.2(2)

0.65(11)

0.84(12)

1.0(1)

0.89(3)

0.94(9)

0.92(12)

0.76(11)

0.75(4)

0.93(13)

0.91(1)

0.95(11)

0.37(5)

0.98(1)

0.46(2)

7.6

0.93(7)

0.79(6)

0.68(10)

0.83(13)

1.0(1)

0.76(9)

0.84(8)

0.83(11)

0.77(5)

0.53(10)

0.59(4)

0.22(3)

0.45(1)

0.64(11)

0.98(1)

0.14(14)

0.65(11)

0.93(8)

0.79(15)

0.68(15)

0.82(14)

1.0(1)

0.75(14)

0.83(13)

0.86(6)

0.5(14)

0.54(8)

0.59(14)

0.2(13)

0.45(1)

0.68(3)

0.98(1)

0.19(4)

0.65(9)

0.85(8)

0.84(11)

1.0(1)

0.89(2)

0.95(2)

0.95(10)

0.77(8)

0.72(11)

0.93(11)

0.9(12)

0.95(14)

0.3(15)

0.98(1)

1.0(1)

0.87(11)

0.93(11)

0.92(13)

0.76(12)

0.76(2)

0.94(8)

0.91(7)

0.96(5)

0.44(1)

0.98(1)

0.44(11)

0.45(10)

7.7

8.2

Table 6: Proposed heuristics against state-of-the-art selection schemes based on macro-F1, the ranks are in parenthesis.

ﬁt-ﬁt

nvs-rnd

ads-rnd–rnd*

ads-ﬁt–ﬁt*

ad

adult

0.93(9)

0.94(4)

0.79(7)

0.79(10)

agaricus-lepiota

0.68(14)

0.68(5)

aps-failure

banknote

bank

biodeg

car

0.85(2)

0.83(11)

1.0(1)

0.76(11)

0.83(11)

1.0(1)

0.76(2)

0.84(7)

0.84(9)

0.81(14)

census-income

0.75(7)

0.38(15)

cmc

dota2

0.53(14)

0.53(13)

0.59(2)

0.59(12)

drug-consumption

0.2(15)

fertility

0.44(12)

IndianLiverPatient

0.64(12)

0.2(11)

0.45(1)

0.65(9)

iris

krkopt

letter-recognition

magic04

ml-prove

musk1

musk2

optdigits

page-blocks

parkinsons

pendigits

segmentation

sensorless

tae

wine

yeast

Average rank

0.98(1)

0.96(13)

0.15(11)

0.65(11)

0.18(7)

0.65(7)

0.83(15)

0.84(10)

1.0(14)

0.86(13)

1.0(1)

0.9(1)

0.95(1)

0.92(13)

0.94(11)

0.77(9)

0.95(6)

0.78(7)

0.67(14)

0.67(13)

0.94(9)

0.92(15)

0.9(9)

0.89(15)

0.96(3)

0.92(15)

0.44(2)

0.98(1)

0.46(4)

8.5

0.3(14)

0.98(1)

0.45(9)

8.7

0.95(2)

0.79(14)

0.68(8)

0.83(12)

1.0(1)

0.75(15)

0.83(12)

0.83(10)

0.74(9)

0.54(4)

0.59(8)

0.21(7)

0.44(12)

0.62(15)

0.98(1)

0.15(12)

0.65(8)

0.84(13)

1.0(1)

0.88(5)

0.91(14)

0.92(14)

0.76(15)

0.76(2)

0.93(14)

0.89(14)

0.95(13)

0.37(6)

0.96(14)

0.44(13)

9.6

0.94(3)

0.79(12)

0.68(12)

0.81(15)

1.0(1)

0.75(13)

0.84(6)

0.81(13)

0.74(10)

0.54(5)

0.59(15)

0.22(4)

0.44(12)

0.63(14)

0.98(1)

0.13(15)

0.65(10)

0.84(14)

1.0(14)

0.89(4)

0.93(12)

0.92(15)

0.76(14)

0.78(1)

0.93(12)

0.9(11)

0.96(9)

0.32(11)

0.96(14)

0.43(14)

10.2

Table 7: Performance using macro-F1 (with ranks) of: LogisticRegression (LR), LinearSVC (LSVC), SVC, SGDClassiﬁer (SDG), PassiveAggressive-
Classiﬁer (PA), DecisionTreeClassiﬁer (DT), ExtraTreesClassiﬁer (ET), RandomForestClassiﬁer (RF), AdaBoostClassiﬁer (AB) and GradientBoost-
ingClassiﬁer (GB). The begining of the table appears on Table 3.

LR

KN

AB

SVC

LSVC

NB

NC

PA

PER

NBB

SGD

ad

adult

0.94(9)

0.9(16)

0.93(13)

0.79(18)

0.88(17)

0.7(20)

0.77(19)

0.5(21)

0.46(22)

0.92(15)

0.46(22)

0.64(15)

0.63(16)

0.79(7)

0.44(23)

0.58(19)

0.64(14)

0.46(22)

0.61(17)

0.52(21)

0.68(13)

0.55(20)

agaricus-lepiota

0.62(10)

0.53(18)

0.2(23)

0.56(15)

0.64(9)

0.57(13)

0.46(19)

0.56(14)

0.66(8)

0.58(12)

0.55(17)

aps-failure

banknote

bank

biodeg

car

0.79(14)

0.78(16)

0.8(11)

0.53(21)

0.79(13)

0.63(20)

0.77(17)

0.78(15)

0.49(23)

0.65(19)

0.49(22)

0.99(14)

1.0(10)

1.0(1)

1.0(1)

0.99(16)

0.82(21)

0.69(23)

0.99(13)

0.98(18)

0.82(22)

0.97(20)

0.63(16)

0.65(15)

0.7(10)

0.47(23)

0.51(22)

0.67(14)

0.54(20)

0.53(21)

0.59(17)

0.59(18)

0.55(19)

0.84(3)

0.77(17)

0.78(15)

0.78(16)

0.79(14)

0.72(19)

0.62(21)

0.57(22)

0.72(20)

0.74(18)

0.55(23)

0.26(23)

0.74(12)

0.71(13)

0.69(14)

0.26(22)

0.32(20)

0.37(17)

0.41(16)

0.32(19)

0.34(18)

0.3(21)

census-income

0.68(11)

0.68(12)

0.73(8)

0.48(20)

0.56(18)

0.59(17)

0.63(14)

0.45(22)

0.66(13)

0.61(15)

0.61(16)

cmc

dota2

0.48(13)

0.49(12)

0.5(11)

0.54(3)

0.48(15)

0.46(17)

0.35(20)

0.17(23)

0.28(21)

0.44(19)

0.26(22)

0.59(6)

0.52(17)

0.58(11)

0.59(9)

0.35(21)

0.56(14)

0.5(19)

0.35(22)

0.41(20)

0.56(12)

0.34(23)

drug-consumption

0.16(15)

0.16(14)

0.13(23)

0.13(21)

0.14(17)

0.14(18)

0.19(10)

0.14(19)

0.2(9)

0.23(3)

0.13(22)

fertility

0.45(4)

0.45(4)

0.52(3)

0.45(4)

0.45(4)

0.41(21)

0.6(1)

0.38(23)

0.41(21)

0.44(16)

0.43(20)

IndianLiverPatient

0.5(18)

0.57(12)

0.59(7)

0.43(20)

0.41(21)

0.57(10)

0.56(13)

0.41(22)

0.47(19)

0.41(22)

0.58(9)

iris

krkopt

0.88(19)

0.18(13)

0.98(8)

0.94(14)

1.0(1)

0.9(18)

0.96(10)

0.98(2)

0.64(20)

0.53(22)

0.13(23)

0.56(21)

0.66(5)

0.1(18)

0.58(7)

0.16(14)

0.13(16)

0.12(17)

0.05(21)

0.08(19)

0.04(22)

0.08(20)

letter-recognition

0.71(9)

0.94(3)

0.19(21)

0.97(1)

0.6(16)

0.64(15)

0.59(17)

0.45(19)

0.36(20)

0.08(22)

0.45(18)

magic04

ml-prove

musk1

musk2

optdigits

page-blocks

parkinsons

pendigits

0.75(15)

0.76(14)

0.82(11)

0.41(22)

0.66(17)

0.65(18)

0.63(20)

0.48(21)

0.63(19)

0.39(23)

0.67(16)

1.0(1)

0.94(21)

1.0(1)

0.99(18)

1.0(1)

1.0(16)

0.73(23)

1.0(1)

0.99(19)

0.85(22)

1.0(15)

0.88(6)

0.88(6)

0.88(8)

0.37(22)

0.86(12)

0.77(18)

0.68(20)

0.81(14)

0.57(21)

0.72(19)

0.78(17)

0.91(14)

0.92(11)

0.9(15)

0.73(21)

0.9(16)

0.75(20)

0.61(23)

0.85(17)

0.83(18)

0.66(22)

0.76(19)

0.95(10)

0.98(3)

0.53(23)

0.64(22)

0.93(13)

0.79(21)

0.89(18)

0.93(14)

0.91(17)

0.84(20)

0.92(16)

0.79(8)

0.71(13)

0.46(19)

0.35(21)

0.61(16)

0.65(14)

0.22(22)

0.5(18)

0.36(20)

0.19(23)

0.5(17)

0.76(7)

0.67(14)

0.82(4)

0.49(17)

0.3(22)

0.67(12)

0.6(16)

0.21(23)

0.41(21)

0.43(18)

0.43(18)

0.89(14)

0.98(2)

0.55(22)

0.08(23)

0.81(18)

0.82(17)

0.77(19)

0.86(15)

0.84(16)

0.6(21)

0.77(20)

segmentation

0.9(10)

0.8(13)

0.33(23)

0.36(22)

0.42(20)

0.79(14)

0.69(15)

0.56(18)

0.57(17)

0.4(21)

0.45(19)

sensorless

0.5(15)

0.11(22)

0.33(17)

0.26(18)

0.61(14)

0.76(13)

0.07(23)

0.19(20)

0.2(19)

0.48(16)

0.18(21)

tae

wine

yeast

0.34(15)

0.38(10)

0.37(13)

0.38(9)

0.3(19)

0.17(22)

0.31(17)

0.24(20)

0.38(11)

0.13(23)

0.2(21)

0.98(12)

0.73(15)

0.98(4)

0.21(21)

0.71(17)

0.96(13)

0.72(16)

0.28(20)

0.44(19)

0.18(22)

0.46(18)

0.31(13)

0.28(15)

0.3(14)

0.26(16)

0.05(18)

0.54(4)

0.05(20)

0.05(19)

0.03(22)

0.12(17)

0.02(23)

Average rank

11.7

12.2

12.8

15.6

16.0

16.0

17.4

18.3

18.4

18.5

19.2

Table 8: Performance using time (with ranks) of: LogisticRegression (LR), LinearSVC (LSVC), SVC, SGDClassiﬁer (SDG), PassiveAggressiveClas-
siﬁer (PA), DecisionTreeClassiﬁer (DT), ExtraTreesClassiﬁer (ET), RandomForestClassiﬁer (RF), AdaBoostClassiﬁer (AB) and GradientBoosting-
Classiﬁer (GB). Part 1.

NBB

DT

LR

AB

PA

KN

ET

LSVC

ad

adult

6.16e-03(6)

7.58e-03(10)

7.17e-03(8)

7.49e-03(9)

5.34e-03(3)

5.82e-03(5)

5.06e-03(2)

8.79e-03(14)

1.24e-04(3)

1.33e-04(6)

1.33e-04(7)

1.58e-04(11)

1.25e-04(4)

1.41e-04(9)

1.58e-04(10)

2.46e-04(15)

agaricus-lepiota

5.03e-04(11)

2.75e-04(4)

5.45e-04(12)

4.77e-04(6)

4.92e-04(8)

2.84e-04(5)

2.72e-04(3)

6.6e-04(14)

aps-failure

banknote

bank

biodeg

car

2.19e-01(5)

2.19e-01(4)

2.24e-01(9)

2.22e-01(7)

2.34e-01(11)

2.33e-01(10)

2.39e-01(12)

2.21e-01(6)

5.53e-04(9)

4.86e-04(7)

2.39e-04(4)

4.16e-04(5)

7.93e-04(14)

1.79e-04(1)

4.63e-04(6)

6.67e-04(10)

1.19e-04(6)

1.43e-04(9)

1.30e-04(8)

1.47e-04(10)

1.06e-04(2)

1.60e-04(13)

1.52e-04(12)

2.45e-04(15)

2.66e-04(5)

1.24e-04(1)

7.29e-04(15)

7.27e-04(13)

2.49e-04(4)

6.82e-04(11)

2.70e-04(6)

3.34e-04(7)

7.45e-05(5)

6.55e-05(2)

7.88e-05(6)

1.75e-04(13)

6.96e-05(3)

7.08e-05(4)

8.94e-05(8)

2.82e-04(14)

census-income

3.72e-04(2)

3.74e-04(3)

5.14e-04(12)

5.11e-04(11)

4.14e-04(7)

1.39e-03(15)

3.69e-04(1)

7.54e-04(14)

cmc

dota2

1.86e-04(6)

1.27e-04(3)

8.77e-04(12)

7.63e-04(10)

1.36e-04(4)

1.05e-03(15)

1.57e-04(5)

3.50e-04(8)

4.43e-04(5)

5.23e-04(11)

4.28e-04(3)

4.95e-04(8)

4.21e-04(1)

1.13e-03(15)

4.99e-04(9)

7.27e-04(14)

drug-consumption

2.47e-04(4)

2.7e-04(6)

3.68e-04(12)

3.86e-04(13)

2.89e-04(7)

3.05e-04(9)

3.07e-04(10)

7.5e-04(14)

fertility

2.57e-04(6)

1.47e-04(1)

1.82e-04(2)

1.59e-03(15)

1.89e-04(4)

5.13e-04(8)

6.62e-04(12)

1.86e-04(3)

IndianLiverPatient

1.94e-04(8)

2.48e-04(12)

1.05e-04(5)

4.38e-04(15)

5.56e-05(1)

1.46e-04(7)

2.10e-04(9)

4.21e-04(14)

iris

krkopt

3.76e-04(7)

8.10e-05(1)

3.48e-04(6)

1.87e-03(13)

1.52e-04(4)

5.32e-04(8)

1.58e-04(5)

1.95e-03(16)

6.54e-05(4)

5.31e-05(2)

1.21e-04(11)

1.48e-04(12)

7.25e-05(10)

6.8e-05(7)

6.64e-05(6)

1.21e-03(13)

letter-recognition

5.26e-05(1)

5.95e-05(3)

4.87e-04(12)

2.31e-04(11)

9.84e-05(9)

1.93e-04(10)

8.62e-05(6)

2.01e-03(14)

magic04

ml-prove

musk1

musk2

optdigits

page-blocks

parkinsons

pendigits

segmentation

sensorless

tae

wine

yeast

7.55e-05(7)

8.07e-05(10)

7.87e-05(9)

1.65e-04(14)

7.82e-05(8)

7.39e-05(6)

7.14e-05(5)

1.64e-04(13)

2.63e-04(5)

2.75e-04(8)

2.15e-04(2)

5.17e-04(14)

2.41e-04(4)

3.87e-04(11)

2.67e-04(6)

4.67e-04(13)

1.20e-03(8)

1.08e-03(7)

1.31e-03(12)

2.24e-03(14)

1.28e-03(11)

1.03e-03(4)

8.95e-04(2)

1.43e-03(13)

6.9e-04(2)

7.28e-04(3)

1.22e-03(12)

1.45e-03(13)

8.74e-04(5)

1.21e-03(11)

6.25e-04(1)

8.15e-04(4)

3.51e-04(4)

3.64e-04(6)

7.34e-04(14)

4.47e-04(10)

1.92e-04(1)

5.26e-04(12)

3.87e-04(9)

5.22e-04(11)

7.74e-05(9)

6.02e-05(5)

1.66e-04(12)

1.4e-04(11)

7.09e-05(8)

4.50e-05(2)

6.11e-05(6)

3.38e-04(13)

2.35e-04(3)

1.65e-04(1)

2.11e-04(2)

1.03e-03(16)

3.41e-04(6)

7.01e-04(13)

4.48e-04(11)

2.96e-04(4)

9.51e-05(4)

9.49e-05(3)

3.25e-04(13)

1.9e-04(11)

9.90e-05(6)

1.34e-04(10)

9.83e-05(5)

3.53e-04(14)

1.22e-03(12)

8.18e-04(4)

1.05e-03(9)

1.25e-03(14)

1.13e-03(10)

9.49e-04(6)

9.67e-04(8)

1.23e-03(13)

2.60e-04(6)

3.32e-04(9)

2.46e-03(13)

5.18e-04(11)

2.74e-04(7)

4.88e-04(10)

1.51e-04(2)

6.67e-03(15)

3.98e-04(10)

2.64e-04(4)

4.72e-04(11)

1.38e-03(14)

6.79e-04(12)

2.76e-04(6)

3.68e-04(9)

3.5e-04(8)

1.18e-04(1)

3.02e-04(7)

3.37e-04(8)

1.02e-03(15)

6.90e-04(14)

1.31e-04(4)

6.17e-04(13)

4.03e-04(10)

2.62e-04(11)

2.02e-04(4)

2.69e-04(12)

2.16e-04(7)

2.06e-04(6)

2.05e-04(5)

2.44e-04(9)

8.52e-04(15)

Average time per sample

Average rank

0.0078

5.8

0.0078

5.2

0.0082

9.1

0.0083

11.5

0.0083

6.5

0.0084

8.4

0.0084

6.9

0.0085

11.7

Table 9: Performance using time (with ranks) of: LogisticRegression (LR), LinearSVC (LSVC), SVC, SGDClassiﬁer (SDG), PassiveAggressiveClas-
siﬁer (PA), DecisionTreeClassiﬁer (DT), ExtraTreesClassiﬁer (ET), RandomForestClassiﬁer (RF), AdaBoostClassiﬁer (AB) and GradientBoosting-
Classiﬁer (GB). Part 2.

RF

SGD

GB

PER

NB

NC

MLP

SVC

ad

adult

7.62e-03(11)

5.78e-03(4)

7.76e-03(12)

4.97e-03(1)

6.58e-03(7)

8.48e-03(13)

1.10e-02(16)

1.03e-02(15)

1.58e-04(12)

1.23e-04(2)

2.17e-04(13)

1.31e-04(5)

1.40e-04(8)

1.17e-04(1)

2.29e-04(14)

1.38e-02(16)

agaricus-lepiota

2.71e-04(1)

4.87e-04(7)

1.07e-03(16)

4.97e-04(9)

2.71e-04(2)

4.97e-04(10)

9.10e-04(15)

6.49e-04(13)

aps-failure

banknote

bank

biodeg

car

2.43e-01(13)

2.52e-01(14)

2.22e-01(8)

2.78e-01(16)

2.8e-01(18)

2.78e-01(17)

2.62e-01(15)

2.96e-01(19)

7.02e-04(11)

7.97e-04(15)

5.26e-04(8)

7.45e-04(12)

1.81e-04(3)

1.80e-04(2)

3.11e-03(16)

7.53e-04(13)

1.2e-04(7)

1.17e-04(5)

1.95e-04(14)

1.15e-04(4)

1.01e-04(1)

1.10e-04(3)

1.48e-04(11)

1.30e-02(16)

6.77e-04(9)

2.36e-04(3)

5.86e-04(8)

2.36e-04(2)

6.83e-04(12)

7.28e-04(14)

1.53e-03(16)

6.82e-04(10)

8.90e-05(7)

1.00e-04(10)

5.86e-04(15)

1.03e-04(11)

3.65e-05(1)

9.79e-05(9)

5.24e-03(16)

1.39e-04(12)

census-income

4.52e-04(9)

4.07e-04(4)

5.30e-04(13)

4.09e-04(6)

4.07e-04(5)

4.47e-04(8)

4.98e-04(10)

1.08e-01(17)

cmc

dota2

8.76e-04(11)

1.89e-04(7)

5.84e-04(9)

5.81e-05(1)

9.60e-04(14)

6.01e-05(2)

2.33e-03(16)

9.2e-04(13)

5.14e-04(10)

4.45e-04(6)

7.14e-04(13)

4.26e-04(2)

4.56e-04(7)

4.37e-04(4)

5.82e-04(12)

3.82e-02(16)

drug-consumption

1.77e-04(1)

2.34e-04(2)

1.83e-03(15)

2.42e-04(3)

2.61e-04(5)

2.95e-04(8)

2.86e-03(16)

3.36e-04(11)

fertility

8.51e-04(13)

1.93e-04(5)

1.00e-03(14)

5.13e-04(7)

5.28e-04(10)

5.15e-04(9)

2.94e-03(16)

6.23e-04(11)

IndianLiverPatient

2.26e-04(10)

5.91e-05(2)

3.7e-04(13)

8.41e-05(3)

1.24e-04(6)

8.68e-05(4)

1.24e-03(16)

2.4e-04(11)

iris

krkopt

8.33e-04(11)

1.45e-04(2)

1.86e-03(12)

1.51e-04(3)

8.22e-04(10)

1.92e-03(15)

1.89e-03(14)

5.40e-04(9)

6.59e-05(5)

6.95e-05(9)

2.48e-03(16)

6.83e-05(8)

5.09e-05(1)

6.19e-05(3)

2.34e-03(15)

1.63e-03(14)

letter-recognition

5.61e-05(2)

7.25e-05(5)

4.15e-03(16)

7.20e-05(4)

8.98e-05(7)

9.04e-05(8)

2.48e-03(15)

1.06e-03(13)

magic04

ml-prove

musk1

musk2

optdigits

page-blocks

parkinsons

pendigits

segmentation

sensorless

tae

wine

yeast

8.97e-05(11)

6.80e-05(4)

2.21e-04(15)

6.76e-05(3)

4.79e-05(1)

5.07e-05(2)

1.47e-04(12)

4.46e-03(16)

3.34e-04(10)

2.00e-04(1)

5.86e-04(16)

2.38e-04(3)

2.71e-04(7)

3.03e-04(9)

4.43e-04(12)

5.45e-04(15)

1.21e-03(10)

1.07e-03(6)

2.56e-03(15)

9.35e-04(3)

8.49e-04(1)

1.05e-03(5)

2.78e-03(16)

1.21e-03(9)

8.82e-04(6)

9.37e-04(10)

1.83e-03(14)

8.97e-04(7)

9.07e-04(9)

9.05e-04(8)

4.20e-03(16)

2.92e-03(15)

2.37e-04(2)

3.58e-04(5)

4.13e-03(16)

3.78e-04(8)

2.48e-04(3)

3.68e-04(7)

6.09e-04(13)

1.33e-03(15)

9.29e-05(10)

5.12e-05(3)

7.04e-04(15)

5.32e-05(4)

4.16e-05(1)

7.07e-05(7)

6.82e-04(14)

1.92e-03(16)

3.97e-04(8)

4.14e-04(10)

9.03e-04(15)

4.11e-04(9)

3.13e-04(5)

5.81e-04(12)

8.42e-04(14)

3.94e-04(7)

8.28e-05(1)

1.14e-04(9)

1.17e-03(15)

1.11e-04(8)

1.01e-04(7)

9.39e-05(2)

2.92e-04(12)

1.22e-03(16)

7.14e-04(2)

1.25e-03(15)

4.14e-03(16)

7.36e-04(3)

8.34e-04(5)

6.83e-04(1)

9.66e-04(7)

1.2e-03(11)

2.91e-04(8)

2.22e-04(5)

4.21e-03(14)

1.83e-04(3)

2.15e-04(4)

1.35e-04(1)

1.09e-03(12)

1.22e-02(16)

8.21e-04(13)

1.51e-04(3)

2.38e-03(16)

1.48e-04(2)

2.75e-04(5)

1.44e-04(1)

1.74e-03(15)

2.81e-04(7)

2.88e-04(6)

1.25e-04(3)

2.30e-03(16)

1.22e-04(2)

3.88e-04(9)

5.04e-04(11)

5.90e-04(12)

2.83e-04(5)

2.31e-04(8)

1.2e-04(2)

1.31e-03(16)

2.44e-04(10)

1.54e-04(3)

1.15e-04(1)

5.97e-04(14)

4.02e-04(13)

Average time per sample

Average rank

0.0087

7.9

0.0089

5.9

0.0091

13.8

0.0097

5.4

0.0099

5.9

0.0099

6.6

0.0105

13.9

0.0172

13.0

Table 10: Performance using time (with ranks) of: LogisticRegression (LR), LinearSVC (LSVC), SVC, SGDClassiﬁer (SDG), PassiveAggressiveClas-
siﬁer (PA), DecisionTreeClassiﬁer (DT), ExtraTreesClassiﬁer (ET), RandomForestClassiﬁer (RF), AdaBoostClassiﬁer (AB) and GradientBoosting-
Classiﬁer (GB). Part 3.

EvoDAG rnd-rnd

EvoDAG ﬁt-ﬁt

EvoDAG agr-rnd

EvoDAG nvs-rnd

EvoDAG ads-rnd

autosklearn

tpot

ad

adult

agaricus-lepiota

aps-failure

banknote

bank

biodeg

car

census-income

cmc

dota2

3.25e-01(17)

5.17e-01(18)

2.16e-01(19)

3.47e-01(20)

4.56e-01(17)

5.27e-01(18)

1.39e-01(2)

1.23e-01(1)

2.82e-02(17)

1.34e-01(19)

1.4e-01(18)

1.95e-01(20)

4.36e-01(18)

3.86e-01(17)

3.18e-01(17)

5.5e-01(18)

1.66e-01(19)

1.45e-01(18)

3.28e-01(17)

5.04e-01(18)

3.29e-01(19)

2.59e-01(18)

drug-consumption

2.38e-01(17)

2.65e-01(18)

fertility

1.24e+00(18)

1.65e+00(19)

IndianLiverPatient

3.07e-01(17)

5.61e-01(18)

iris

krkopt

4.76e-01(17)

7.5e-01(18)

1.28e+00(18)

1.05e+00(17)

letter-recognition

1.46e+00(18)

1.19e+00(17)

magic04

ml-prove

musk1

musk2

optdigits

page-blocks

parkinsons

pendigits

segmentation

sensorless

tae

wine

yeast

Average time per sample

Average rank

3.95e-01(18)

4.19e-01(19)

5.73e-02(17)

1.83e-01(19)

6.55e-01(18)

6.22e-01(17)

2.77e-01(17)

3.08e-01(18)

7.58e-01(17)

1.54e+00(20)

1.46e-01(17)

1.77e-01(18)

5.73e-01(17)

6.22e-01(18)

6.80e-01(18)

1.84e+00(20)

8.57e-01(17)

1.23e+00(19)

9.22e-01(18)

1.48e+00(19)

1.03e+00(17)

1.64e+00(18)

6.02e-01(17)

7.02e-01(18)

4.68e-01(17)

5.61e-01(18)

0.5102

17.0

0.683

17.8

8.48e-01(19)

8.44e-01(21)

8.36e-01(20)

5.71e-01(21)

8.38e-02(18)

5.21e-01(21)

8.12e-01(19)

8.44e-01(19)

5.09e-01(21)

6.93e-01(19)

6.62e-01(21)

4.31e-01(19)

1.20e+00(17)

1.06e+00(19)

9.98e-01(19)

1.39e+00(19)

1.75e+00(19)

1.30e+00(20)

1.38e-01(18)

9.56e-01(19)

7.44e-01(19)

9.40e-01(18)

3.3e-01(19)

8.49e-01(19)

1.24e+00(19)

1.09e+00(18)

2.16e+00(20)

1.64e+00(19)

1.04e+00(19)

8.27e-01(19)

0.9104

19.2

4.91e+00(22)

2.4e+00(21)

1.57e+00(20)

2.82e+02(23)

2.05e-01(18)

2.40e+00(22)

1.10e-01(17)

9.85e+00(23)

3.53e+00(21)

6.17e+00(22)

6.32e-01(19)

1.14e+01(23)

3.70e-01(20)

4.25e-01(20)

1.80e-01(19)

2.42e+00(20)

2.85e+00(20)

1.99e+00(22)

1.58e-01(3)

3.38e+01(23)

1.81e+00(21)

3.75e+00(22)

4.43e+00(23)

1.91e+00(22)

1.14e-01(17)

1.40e+01(23)

3.02e+00(21)

4.87e+00(22)

2.42e+01(23)

4.83e+00(22)

2.97e+00(21)

3.07e+01(23)

4.78e-01(20)

1.79e+00(22)

1.85e-02(16)

1.15e+01(23)

2.75e+00(20)

3.29e+00(21)

3.49e+00(22)

2.37e+01(23)

5.35e-01(20)

1.98e+00(22)

3.95e-02(17)

1.14e+01(23)

2.25e+00(20)

3.01e+00(20)

3.17e+00(20)

1.69e+00(20)

3.39e+00(20)

3.07e+00(20)

4.38e+00(22)

4.78e-01(20)

3.10e+00(20)

3.75e+00(22)

3.27e+00(21)

1.86e+00(21)

2.55e+00(20)

2.95e+00(21)

2.95e+00(20)

2.26e+00(21)

3.65e+00(20)

1.82e+00(20)

3.02e+00(20)

2.3754

20.3

4.76e+00(22)

2.73e+00(21)

5.53e+01(23)

3.94e+00(21)

5.21e+01(22)

7.42e+01(23)

3.41e+00(21)

8.83e+00(22)

1.87e+01(23)

4.77e+00(21)

3.43e+01(22)

5.08e+01(23)

1.08e+01(21)

5.21e+01(22)

7.76e+01(23)

1.18e+01(21)

5.21e+01(23)

3.92e+01(22)

2.91e+00(21)

2.70e-01(17)

5.18e+01(23)

8.52e-01(22)

7.84e-01(21)

1.69e+01(23)

3.48e+00(21)

1.08e+01(22)

2.82e+02(23)

2.57e+00(21)

7.8e-01(20)

5.68e+01(23)

6.66e+00(22)

9.41e-01(19)

6.32e+01(23)

3.01e+00(22)

9.39e-01(20)

3.98e+01(23)

4.75e+00(21)

2.66e+01(22)

3.37e+01(23)

1.22e+01(22)

4.8e-01(17)

5.68e+01(23)

6.92e+00(21)

1.71e+01(22)

1.03e+02(23)

1.55e+01(22)

8.83e-02(17)

2.23e+01(23)

9.55e+00(21)

3.43e+01(22)

8.20e+01(23)

3.87e+00(21)

2.93e+01(22)

8.69e+01(23)

8.11e+00(22)

3.46e+00(21)

6.25e+01(23)

5.0449

21.5

11.5265

19.7

57.6855

23.0

References

Badran, K. and Rockett, P. (2012). Multi-class pattern classiﬁcation using single, multi-dimensional
feature-space feature extraction evolved by multi-objective genetic programming and its application to
network intrusion detection. Genetic Programming and Evolvable Machines, 13(1):33–63.

Beadle, L. and Johnson, C. G. (2008). Semantically driven crossover in genetic programming. In 2008
IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence),
pages 111–116. IEEE.

Bergstra, J. and Bengio, Y. (2012). Random Search for Hyper-Parameter Optimization. Journal of

Machine Learning Research, 13(Feb):281–305.

Brameier, M. and Banzhaf, W. (2001). A comparison of linear genetic programming and neural networks

in medical data mining. IEEE Transactions on Evolutionary Computation, 5(1):17–26.

Breiman, L. (1996). Bagging predictors. Machine Learning, 24(2):123–140.

Brereton, R. G. (2016). Orthogonality, uncorrelatedness, and linear independence of vectors. Journal of

Chemometrics, 30(10):564–566.

Castelli, M., Manzoni, L., Mariot, L., and Saletta, M. (2019). Extending local search in geometric semantic

genetic programming. In EPIA Conference on Artiﬁcial Intelligence, pages 775–787. Springer.

Castelli, M., Silva, S., and Vanneschi, L. (2015a). A C++ framework for geometric semantic genetic

programming. Genetic Programming and Evolvable Machines, 16(1):73–81.

Castelli, M., Trujillo, L., Vanneschi, L., Silva, S., Z-Flores, E., and Legrand, P. (2015b). Geometric Seman-
tic Genetic Programming with Local Search. In Proceedings of the 2015 on Genetic and Evolutionary
Computation Conference - GECCO ’15, pages 999–1006, New York, New York, USA. ACM Press.

Chawla, N. V., Japkowicz, N., and Kotcz, A. (2004). Editorial: Special Issue on Learning from Imbalanced

Data Sets. ACM SIGKDD Explorations Newsletter, 6(1):1.

Chen, Q., Xue, B., and Zhang, M. (2019). Improving Generalization of Genetic Programming for Symbolic
IEEE Transactions on Evolutionary

Regression With Angle-Driven Geometric Semantic Operators.
Computation, 23(3):488–502.

Chu, T. H., Nguyen, Q. U., and O’Neill, M. (2016). Tournament selection based on statistical test in
In International Conference on Parallel Problem Solving from Nature, pages

genetic programming.
303–312. Springer.

Chu, T. H., Nguyen, Q. U., and O’Neill, M. (2018). Semantic tournament selection for genetic program-

ming based on statistical analysis of error vectors. Information Sciences, 436-437:352–366.

Demˇsar, J. (2006). Statistical Comparisons of Classiﬁers over Multiple Data Sets. Technical report.

Dua, D. and Graﬀ, C. (2017). UCI Machine Learning Repository.

Espejo, P. G., Ventura, S., and Herrera, F. (2010). A Survey on the Application of Genetic Programming
to Classiﬁcation. IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and
Reviews), 40(2):121–144.

Fang, Y. and Li, J. (2010). A Review of Tournament Selection in Genetic Programming. In International
Symposium on Intelligence Computation and Applications ISICA 2010, pages 181–192. Springer, Berlin,
Heidelberg.

Feurer, M., Klein, A., Eggensperger, K., Springenberg, J., Blum, M., and Hutter, F. (2015). Eﬃcient and

Robust Automated Machine Learning.

Folino, G., Pizzuti, C., and Spezzano, G. (2008). Training distributed gp ensemble with a selective
algorithm based on clustering and pruning for pattern classiﬁcation. IEEE Transactions on Evolutionary
Computation, 12(4):458–468.

Friedberg, R. M. (1958). A learning machine: Part i. IBM Journal of Research and Development, 2(1):2–

13.

Friedman, J. H. and Hall, P. (2007). On bagging and nonlinear estimation. Journal of Statistical Planning

and Inference, 137(3):669–683.

Galvan-Lopez, E., Cody-Kenny, B., Trujillo, L., and Kattan, A. (2013). Using semantics in the selection
mechanism in Genetic Programming: A simple method for promoting semantic diversity. In 2013 IEEE
Congress on Evolutionary Computation, pages 2972–2979. IEEE.

Graﬀ, M., Flores, J. J., and Ortiz, J. (2014a). Genetic Programming: Semantic point mutation operator
based on the partial derivative error. In 2014 IEEE International Autumn Meeting on Power, Electronics
and Computing (ROPEC), pages 1–6. IEEE.

Graﬀ, M., Graﬀ-Guerrero, A., and Cerda-Jacobo, J. (2014b). Semantic crossover based on the partial

derivative error. In European Conference on Genetic Programming, pages 37–47. Springer.

Graﬀ, M., Miranda-Jim´enez, S., Tellez, E. S., and Moctezuma, D. (2020). Evomsa: A multilingual

evolutionary approach for sentiment analysis. Computational Intelligence Magazine, 15:76 – 88.

Graﬀ, M., Tellez, E. S., Escalante, H. J., and Miranda-Jim´enez, S. (2017). Semantic genetic programming

for sentiment analysis. In NEO 2015, pages 43–65. Springer.

Graﬀ, M., Tellez, E. S., Escalante, H. J., and Ortiz-Bejar, J. (2015a). Memetic Genetic Programming
based on orthogonal projections in the phenotype space. In 2015 IEEE International Autumn Meeting
on Power, Electronics and Computing (ROPEC), pages 1–6. IEEE.

Graﬀ, M., Tellez, E. S., Miranda-Jimenez, S., and Escalante, H. J. (2016). EvoDAG: A semantic Genetic
Programming Python library. In 2016 IEEE International Autumn Meeting on Power, Electronics and
Computing (ROPEC), pages 1–6. IEEE.

Graﬀ, M., Tellez, E. S., Villase˜nor, E., and Miranda-Jim´enez, S. (2015b). Semantic Genetic Programming
In Research in Computing Science, pages

Operators Based on Projections in the Phenotype Space.
73–85.

Guo, H., Jack, L. B., and Nandi, A. K. (2005). Feature generation using genetic programming with
IEEE Transactions on Systems, Man, and Cybernetics, Part B

application to fault classiﬁcation.
(Cybernetics), 35(1):89–99.

Hara, A., Kushida, J.-i., and Takahama, T. (2016). Deterministic Geometric Semantic Genetic Program-
In 2016 IEEE International Conference on Systems, Man, and

ming with Optimal Mate Selection.
Cybernetics (SMC), pages 003387–003392. IEEE.

Hara, A., Ueno, Y., and Takahama, T. (2012). New crossover operator based on semantic distance
between subtrees in Genetic Programming. In 2012 IEEE International Conference on Systems, Man,
and Cybernetics (SMC), pages 721–726. IEEE.

Ingalalli, V., Silva, S., Castelli, M., and Vanneschi, L. (2014). A multi-dimensional genetic programming
In European Conference on Genetic Programming,

approach for multi-class classiﬁcation problems.
pages 48–60. Springer.

Iqbal, M., Xue, B., Al-Sahaf, H., and Zhang, M. (2017). Cross-domain reuse of extracted knowledge
IEEE Transactions on Evolutionary Computation,

in genetic programming for image classiﬁcation.
21(4):569–587.

Koza, J. R. (1992). Genetic programming: on the programming of computers by means of natural selection.

MIT Press.

Krawiec, K. (2016). Semantic Genetic Programming.

In Behavioral Program Synthesis with Genetic

Programming, pages 55–66. Springer, Cham.

Krawiec, K. and Lichocki, P. (2009). Approximating geometric crossover in semantic space. In Proceedings
of the 11th Annual conference on Genetic and evolutionary computation - GECCO ’09, page 987, New
York, New York, USA. ACM Press.

Krawiec, K. and Pawlak, T. (2012). Locally geometric semantic crossover. In Proceedings of the fourteenth
international conference on Genetic and evolutionary computation conference companion - GECCO
Companion ’12, page 1487, New York, New York, USA. ACM Press.

Krawiec, K. and Pawlak, T. (2013). Locally geometric semantic crossover: a study on the roles of semantics
and homology in recombination operators. Genetic Programming and Evolvable Machines, 14(1):31–63.

La Cava, W., Silva, S., Danai, K., Spector, L., Vanneschi, L., and Moore, J. H. (2019). Multidimensional
genetic programming for multiclass classiﬁcation. Swarm and Evolutionary Computation, 44:260–272.

Lehman, J. and Stanley, K. O. (2011). Abandoning Objectives: Evolution Through the Search for Novelty

Alone. Evolutionary Computation, 19(2):189–223.

Lichodzijewski, P. and Heywood, M. I. (2008). Managing team-based problem solving with symbiotic bid-
based genetic programming. In Proceedings of the 10th annual conference on Genetic and evolutionary
computation, pages 363–370.

Loveard, T. and Ciesielski, V. (2001). Representing classiﬁcation problems in genetic programming. In
Proceedings of the 2001 Congress on Evolutionary Computation (IEEE Cat. No.01TH8546), volume 2,
pages 1070–1077. IEEE.

McIntyre, A. R. and Heywood, M. I. (2011). Classiﬁcation as clustering: A pareto cooperative-competitive

gp approach. Evolutionary Computation, 19(1):137–166.

Moraglio, A., Krawiec, K., and Johnson, C. G. (2012). Geometric semantic genetic programming.

In

International Conference on Parallel Problem Solving from Nature, pages 21–31. Springer.

Moraglio, A. and Poli, R. (2004). Topological interpretation of crossover. In Genetic and Evolutionary

Computation Conference, pages 1377–1388. Springer.

Muni, D. P., Pal, N. R., and Das, J. (2004). A Novel Approach to Design Classiﬁers Using Genetic

Programming. IEEE Transactions on Evolutionary Computation, 8(2):183–196.

Munoz, L., Silva, S., and Trujillo, L. (2015). M3gp–multiclass classiﬁcation with gp. In European Confer-

ence on Genetic Programming, pages 78–91. Springer.

Naredo, E., Trujillo, L., Legrand, P., Silva, S., and Mu˜noz, L. (2016). Evolving genetic programming

classiﬁers with novelty search. Information Sciences, 369:347–367.

Nguyen, Q. U., Nguyen, X. H., O’Neill, M., and Agapitos, A. (2012). An investigation of ﬁtness sharing
with semantic and syntactic distance metrics. In European Conference on Genetic Programming, pages
109–120. Springer.

Nguyen, Q. U., Pham, T. A., Nguyen, X. H., and McDermott, J. (2016). Subtree semantic geometric

crossover for genetic programming. Genetic Programming and Evolvable Machines, 17(1):25–53.

Olson, R. S., Urbanowicz, R. J., Andrews, P. C., Lavender, N. A., Moore, J. H., et al. (2016). Automating
In European Conference on the

biomedical data science through tree-based pipeline optimization.
Applications of Evolutionary Computation, pages 123–137. Springer.

Pawlak, T. P., Wieloch, B., and Krawiec, K. (2015). Semantic Backpropagation for Designing Search
Operators in Genetic Programming. IEEE Transactions on Evolutionary Computation, 19(3):326–340.

Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer,
P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., and
Duchesnay, (2011). Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research,
12(Oct):2825–2830.

Poli, R., Langdon, W. B., and McPhee, N. F. N. (2008). A ﬁeld guide to genetic programming. Published

via lulu.com and freely available at www.gp-ﬁeld-guide.org.uk.

Ruberto, S., Vanneschi, L., Castelli, M., and Silva, S. (2014). Esagp - a semantic gp framework based
In European Conference on Genetic Programming, pages 150–161.

on alignment in the error space.
Springer.

S´anchez, C. N., Dom´ınguez-Soberanes, J., Escalona-Buend´ıa, H. B., Graﬀ, M., Guti´errez, S., and S´anchez,
G. (2019). Liking product landscape: going deeper into understanding consumers’ hedonic evaluations.
Foods, 8(10):461.

Smart, W. and Zhang, M. (2004). Continuously evolving programs in genetic programming using gradient

descent. In Proceedings of THE 7th Asia-Paciﬁc Conference on Complex Systems.

Su´arez, R. R., Graﬀ, M., and Flores, J. J. (2015). Semantic crossover operator for gp based on the second

partial derivative of the error function. Research in Computing Science, 94:87–96.

Uy, N. Q., Hoai, N. X., O’Neill, M., McKay, R. I., and Galv´an-L´opez, E. (2011). Semantically-based
crossover in genetic programming: application to real-valued symbolic regression. Genetic Programming
and Evolvable Machines, 12(2):91–119.

Vanneschi, L. (2017). An Introduction to Geometric Semantic Genetic Programming. In Oliver Sch¨utze,
Leonardo Trujillo, Pierrick Legrand, and Yazmin Maldonado, editors, Neo 2015, pages 3–42. Springer,
Cham.

Vanneschi, L., Castelli, M., Manzoni, L., and Silva, S. (2013). A new implementation of geometric
semantic gp and its application to problems in pharmacokinetics. In European Conference on Genetic
Programming, pages 205–216. Springer.

Vanneschi, L., Castelli, M., Scott, K., and Trujillo, L. (2019). Alignment-based genetic programming for

real life applications. Swarm and evolutionary computation, 44:840–851.

Vanneschi, L., Castelli, M., and Silva, S. (2014). A survey of semantic methods in genetic programming.

Genetic Programming and Evolvable Machines, 15(2):195–214.

Zhang, M. and Smart, W. (2006). Using gaussian distribution to construct ﬁtness functions in genetic

programming for multiclass object classiﬁcation. Pattern Recognition Letters, 27(11):1266–1274.

