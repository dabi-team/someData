Projection-freeGraph-basedClassiﬁerLearningusingGershgorinDiscPerfectAlignmentChengYang,1GeneCheung,2GuangtaoZhai31ShanghaiUniversityofElectricPower,Shanghai,China2YorkUniversity,Toronto,Canada3ShanghaiJiaoTongUniversity,Shanghai,Chinacheng.yang@shiep.edu.cn,genec@yorku.ca,zhaiguangtao@sjtu.edu.cnAbstractInsemi-supervisedgraph-basedbinaryclassiﬁerlearning,asubsetofknownlabelsˆxiareusedtoinferunknownlabels,assumingthatthelabelsignalxissmoothwithrespecttoasimilaritygraphspeciﬁedbyaLaplacianmatrix.Whenre-strictinglabelsxitobinaryvalues,theproblemisNP-hard.Whileaconventionalsemi-deﬁniteprogrammingrelaxation(SDR)canbesolvedinpolynomialtimeusing,forexample,thealternatingdirectionmethodofmultipliers(ADMM),thecomplexityofprojectingacandidatematrixMontotheposi-tivesemi-deﬁnite(PSD)cone(M(cid:23)0)periterationremainshigh.Inthispaper,leveragingarecentlinearalgebraictheorycalledGershgorindiscperfectalignment(GDPA),weproposeafastprojection-freemethodbysolvingasequenceoflinearprograms(LP)instead.Speciﬁcally,weﬁrstrecasttheSDRtoitsdual,whereafeasiblesolutionH(cid:23)0isinterpretedasaLaplacianmatrixcorrespondingtoabalancedsignedgraphminusthelastnode.Toachievegraphbalance,wesplitthelastnodeintotwo,eachretainstheoriginalpositive/negativeedges,resultinginanewLaplacian¯H.WereposetheSDRdualforsolution¯H,thenreplacethePSDconeconstraint¯H(cid:23)0withlinearconstraintsderivedfromGDPA—sufﬁcientconditionstoensure¯HisPSD—sothattheoptimizationbe-comesanLPperiteration.Finally,weextractpredictedlabelsfromconvergedsolution¯H.Experimentsshowthatouralgo-rithmenjoyeda28×speedupoverthenextfastestschemewhileachievingcomparablelabelpredictionperformance.IntroductionBinaryclassiﬁcation—assignmentoflabelsx∈{−1,1}NtoanN-samplesettoseparatetwodistinctclasses—isabasicmachinelearningproblem(Bishop2006).Onecommonsettingissemi-supervisedgraphclassiﬁerlearning:useMknownlabels,ˆxi,1≤i≤M,toinferN−Munknownlabelsxi,M+1≤i≤N,assumingthatxissmoothwithrespectto(w.r.t.)asimilaritygraphGspeciﬁedbyagraphLaplacianmatrixL(Zhouetal.2003;Belkin,Matveeva,andNiyogi2004;GuilloryandBilmes2009).ThisbinarygraphclassiﬁerproblemisNP-hard(Luoetal.2010).Semi-deﬁniteprogramming(SDP)relaxation(SDR)(Li,Liu,andTang2008)isknowntoprovidegooderror-boundedapproximationstoquadraticallyconstrainedquadraticpro-grams(QCQP),ofwhichbinarygraphclassiﬁcationisaPreprint.Underreview.specialcase(SeeTableIandIIin(Luoetal.2010)).Inanutshell,SDRreplacesthebinarylabelconstraintwithamorerelaxedpositivesemi-deﬁnite(PSD)coneconstraint(i.e.,matrixvariableMrelatedtoxx>satisfyingM(cid:23)0).Therelaxedproblemcanbesolvedinpolynomialtimeusing,forexample,thealternatingdirectionmethodofmultipliers(ADMM)(O’Donoghueetal.2016).However,ADMMstillrequiresprojectiontothePSDconeS={M|M(cid:23)0}perit-eration,whichisexpensive(O(N3))duetofull-matrixeigen-decomposition.Analternativeapproachremovesthebinaryconstraintandminimizesdirectlyaquadraticgraphsmooth-nesstermcalledgraphLaplacianregularization(GLR)x>Lx(PangandCheung2017)forx∈RN,thenroundsxi’stonearestbinaryvalues{−1,1}.However,spectralmethodssuchasGLRdonothavetightperformanceboundscommoninSDR(GoemansandWilliamson1995).ToensurematrixvariableMisPSDwithouteigen-decomposition,onenaïveapproachistoenforcelinearcon-straintsderiveddirectlyfromtheGershgorincircletheorem(GCT)(Varga2004).ByGCT,everyrealeigenvalueλofarealsymmetricmatrixMresidesinsideatleastoneGersh-gorindiscΨi—correspondingtorowiofM—withcenterci(M),Mi,iandradiusri(M),Pj6=i|Mi,j|,i.e.,ci(M)−ri(M)≤λ≤ci(M)+ri(M),∃i.(1)Thecorollaryisthatthesmallesteigenvalue,λmin(M),ofMislower-boundedbythesmallestGershgorindiscleft-end,denotedbyλ−min(M),i.e.,λ−min(M),minici(M)−ri(M)≤λmin(M).(2)Thus,toensureM(cid:23)0,onecanimposethesufﬁcientcondi-tionλ−min(M)≥0.WhilereplacingthePSDconeconstraintwithasetofNlinearconstraints,ci(M)−ri(M)≥0,∀i,isattractivecomputationally,GCTlowerboundλ−min(M)tendstobeloose.Asanexample,considerthepositivedeﬁnite(PD)matrixMinFig.1(a)withλmin(M)=0.1078.TheﬁrstGershgorindiscleft-endisc1(M)−r1(M)=2−3=−1,andλ−min(M)<0.Thus,imposingλ−min(M)≥0directlywouldaggressivelyrestrictthesearchspace,resultinginasub-optimalsolutiontotheposedproblem.ArecentlinearalgebraictheorycalledGershgorindiscperfectalignment(GDPA)(Yang,Cheung,andHu2021)providesatheoreticalfoundationtotightentheGCTlowerarXiv:2106.01642v3  [cs.LG]  19 Aug 2022M=2−2−1−25−2−1−24SMS−1=2−1.30−0.59−3.075−1.82−1.69−2.204λmin(M)Σj|j≠i|Mi,j|Mi,iΨ1Ψ2Ψ3GDPA-135λmin(MM)Σj|j≠i|MMi,j|Mi,iΨ1Ψ2Ψ3179-135179Figure1:ExampleofaPDmatrixManditssimilaritytransform˜M=SMS−1,andtheirrespectiveGershgorindiscsΨi.NotethatGershgorindiscleft-endsof˜Marealignedatλmin(M)=0.1078.bound.Speciﬁcally,GDPAstatesthatgivenagraphLapla-cianmatrixLcorrespondingtoabalancedsignedgraphG(CartwrightandHarary1956),onecanperformasimilaritytransform1,˜L=SLS−1,whereS=diag(v−11,...,v−1N)andvistheﬁrsteigenvectorofL,suchthatallGershgorindiscleft-endsof˜Lareexactlyalignedatλmin(L)=λmin(˜L).Thus,transformed˜Lsatisﬁesλ−min(˜L)=λmin(˜L);i.e.,theGCTlowerboundisthetightestpossibleafteranappropri-atesimilaritytransform.Continuingourexample,similaritytransform˜M=SMS−1hasallitsdiscleft-endsexactlyalignedatλmin(M)=λmin(˜M)=0.1078.LeveragingGDPA,wedevelopafastprojection-freealgo-rithmforsemi-supervisedgraphclassiﬁerlearning.WeﬁrstderiveanSDRformulationformatrixsolutionMfromtheoriginalgraphclassiﬁerproblem.However,solutionMisnotaLaplaciantoabalancedgraph,asrequiredbyGDPA.Thus,weconverttheproblemtoitsSDRdual(GartnerandMa-tousek2012)andinterpretthedualvariableHasaLaplaciantoabalancedgraphminusthelastgraphnode.Toachievegraphbalance,wesplitthelastnodeintotwoanddividetheoriginalpositiveandnegativeedgesbetweenthem,resultinginarevisedLaplacian¯H.WereposetheSDRdualproblemforsolution¯H,thenreplacethePSDconeconstraint¯H(cid:23)0withlinearconstraintsderivedfromGDPA.Thischangestheoptimizationtoalinearprogram(LP)periteration,whichissolvedefﬁcientlyusingafastLPsolver(Vanderbei2021).Finally,weextractpredictionlabelsfromconvergedsolu-tion¯H.Experimentsshowthatouralgorithmenjoyed28×speeduponaverageoverthenextfastestscheme,whilere-tainingcomparablelabelpredictionperformance.RelatedWorkGraph-basedclassiﬁcationwasﬁrststudiedtwodecadesago(Zhouetal.2003;Belkin,Matveeva,andNiyogi2004;Guil-loryandBilmes2009).Withtheadventofgraphsignalprocessing(GSP)(Ortegaetal.2018;Cheungetal.2018a)—analysisofdiscretesignalsresidingonﬁnitegraphs—interestintheproblemwasrevived(Gavish,Nadler,andCoifman2010;Shuman,Faraji,andVandergheynst2011;Cheungetal.1AsimilaritytransformB=SAS−1andtheoriginalmatrixAsharethesamesetofeigenvalues(Varga2004).2018b).Theproblemoflearningasimilaritygraphfromdatahasbeenextensivelystudied(Dongetal.2019).WefocusontheorthogonalproblemofpredictingbinarylabelsgivenagraphandasubsetofMlabels.SDR—usefulinapproximatingNP-hardproblems(Gart-nerandMatousek2012)suchasQCQP—providesaneffec-tiverelaxationtothebinarygraphclassiﬁerproblem(Li,Liu,andTang2008).Aninteriorpointmethodtailoredfortheslightlymoregeneralbinaryquadraticproblem2(BQP)hascomplexityO(N3.5log(1/(cid:15))),where(cid:15)isthetolerableerror(Helmbergetal.1996).ThecomplexitywasimprovedtoO(N3)bySDCut(Wang,Shen,andvandenHengel2013;Wangetal.2017)viaspectrahedron-basedrelaxation.Re-placingthePSDconeconstraintM(cid:23)0withafactoriza-tionM=XX>wasproposedin(Shahetal.2016),butresultedinanon-convexoptimizationforXthatwasmin-imizedlocally,whereineachiterationamatrixinverseofworst-casecomplexityO(N3)wasrequired.Morerecentﬁrst-ordermethodsforSDPsuchas(O’Donoghueetal.2016)usedADMM(Boydetal.2011;Zheng,Fantuzzi,andPapachristodoulou2019;Zhengetal.2020),buttheiterativeprojectionontoPSDconerequiresfull-matrixeigen-decompositionandthusexpensive.Incontrast,leveragingGDPAtheory(Yang,Cheung,andHu2021),ouralgorithmisentirelyprojection-free.Itisknowningraphspectraltheory(Chung1996)thatbal-ancedsignedgraphshaveuniquespectralproperties(DittrichandMatz2020);forexample,thesignedgraphLaplacianmatrix(Kunegisetal.2010)haseigenvalue0ifftheunderly-inggraphisbalanced.Incontrast,GDPA(Yang,Cheung,andHu2021)statesthatallGershgorindiscleft-endsofasimilar-itytransformSMS−1ofgraphLaplacianMtoabalancedgraphcanbeperfectlyalignedatλmin(M).GDPAtheorywasdevelopedforfastmetriclearning(Moutaﬁs,Leng,andKakadiaris2017)tooptimizeaPDmatrixMgivenaconvexanddifferentiableobjectiveQ(M).WhilealsoleveragingGDPA,thisworkaddressesthebi-narygraphclassiﬁcationprobleminadifferentandnon-trivialmanner.Speciﬁcally,observingthatsolutionHtotheSDRdualisaLaplaciantoabalancedgraphGminusthelastnode,weaugmentthelastnodetoobtainanoverallbalancedgraph¯GvianewLemma1,andsolveamodiﬁedSDRdualforLaplacian¯Hto¯GviaGDPAlinearization.PreliminariesGraphDeﬁnitionsAgraphG(V,E,W)hasnodesetV={1...,N}andedgesetE={(i,j)},where(i,j)meansnodesiandjareconnectedwithedgeweightwi,j∈R.Apositivegraphmeanswi,j≥0,∀(i,j)∈E,whileasignedgraphmeanswi,jcanbenegativeaswell.Anodeimayhaveself-loopofweightui∈R.DenotebyWtheadjacencymatrix,whereWi,j=wi,jif(i,j)∈Eand=0otherwise,andWi,i=ui.Weassumeundirectededges,andthusWissymmetric.DeﬁnethediagonaldegreematrixD,where2BQPobjectivetakesaquadraticformx>Qx,butQisnotrequiredtobeaLaplaciantoasimilaritygraph.Di,i=di,PjWi,jisthedegreeofnodei.Thecom-binatorialgraphLaplacianmatrix(Ortegaetal.2018)isdeﬁnedasL,D−W.Toaccountforself-loops,thegener-alizedgraphLaplacianmatrixisL,D−W+diag(W).NotethatanyrealsymmetricmatrixcanbeinterpretedasageneralizedgraphLaplacianmatrix.ThegraphLaplacianregularizer(GLR)(PangandCheung2017)thatquantiﬁessmoothnessofsignalx∈RNw.r.t.graphspeciﬁedbyLisx>Lx=X(i,j)∈Ewi,j(xi−xj)2+Xi∈Vuix2i.(3)GLRisalsotheobjectiveofourgraphclassiﬁcationproblem.IterativeGDPALinearizationDenotebyLageneralizedgraphLaplacianmatrixtoabal-ancedandconnectedsignedgraphG(withorwithoutself-loops).Abalancedgraphhasnocycleofoddnumberofnegativeedges.BytheCartwright-HararyTheorem(CHT)(CartwrightandHarary1956),agraphisbalancediffnodescanbecoloredintoblueandred,suchthatpositive(negative)edgesconnectnodesofthesame(different)colors.GDPA(Yang,Cheung,andHu2021)statesthatasimi-laritytransform˜L=SLS−1,whereS=diag(s1,...,sN),si=v−1i,∀i,andvistheprovablystrictlynon-zeroﬁrsteigenvectorofL,hasallitsGershgorindiscleft-endsalignedexactlyatsmallesteigenvalueλmin(L),i.e.,˜Li,i−Xj6=i|˜Li,j|=Li,i−Xj6=i|siLi,j/sj|=λmin(L),∀i∈{1,...,N}.(4)TosolveanoptimizationoftheformminL(cid:23)0Q(L),onecanleverageGDPAandoptimizeiterativelyasfollows.Atitera-tiontwithpreviouslycomputedsolutionLt,computeﬁrsteigenvectorvttoLtcorrespondingtoλmin(Lt);extremeeigenvectorvtcanbecomputedinlinear-timecomplexityO(N)usingLocallyOptimalBlockPreconditionedConju-gateGradient(LOBPCG)(Knyazev2001)assumingasparsematrix3Deﬁnescalarssti=1/vti,∀i,thensolveminLQ(L),s.t.Li,i−Xj6=i|stiLi,j/stj|≥0,∀i∈{1,...,N}.(5)Linearconstraintsin(5)ensurethatthesimilaritytransform˜L=SLS−1isPSDbyGCT,andhencesolutionLisPSD.Sincescalars{sti}arecomputedfromﬁrsteigenvectorvtofLt(cid:23)0,byGDPA,similaritytransformSLtS−1hasallitsdiscleft-endsalignedexactlyatλmin(Lt)≥0,andhenceLtremainsfeasibleatiterationt.Thus,objectiveQ(Lt)ismono-tonicallynon-increasingwitht,andthealgorithmconvergestoalocalminimum4.WeinvokethisiterativeproceduretosolveourposedSDRdualinthesequel.3Forcomputationreasons,LaplacianListypicallysparsetospecifyasparsegraphGintheGSPliterature(Ortegaetal.2018).4Seethesupplementforanexpositionoflocalconvergence.123w1,2w2,3123w1,2w2,3123w1,2w2,3445-z1-z2-z2-z1(a)(b)(c)y1+z1y2+z2y3u4y1+z1y2+z2y3u4Figure2:(a)3-nodelinegraphexample.(b)SolutionHtoSDRdual(12)asgraphLaplacianmatrix.(c)Solution¯HtomodiﬁedSDRdual(21)asgraphLaplacianmatrix.Positive/negativeedgesarecoloredinblue/red.Self-loopweightu4in(b)fornode4isu4=y4+z1+z2.BinaryGraphClassiﬁcationWeﬁrstformulatethebinarygraphclassiﬁcationproblemandrelaxittoanSDRproblem.WethenpresentitsSDRdualwithdualvariablematrixH.Finally,weinterpretHasagraphLaplacian,andaugmentitscorrespondinggraphGtoabalancedgraph¯GforGDPAlinearization.SDRPrimalGivenaPSDgraphLaplacianmatrixL∈RN×Nofapos-itivesimilaritygraphGo,onecanformulateabinarygraphclassiﬁcationproblemasminxx>Lx,s.t.(cid:26)x2i=1,∀i∈{1,...,N}xi=ˆxi,∀i∈{1,...,M}(6)where{ˆxi}Mi=1aretheMknownlabels.Theobjectivein(6)dictatesthatsignalxissmoothw.r.t.graphGospeciﬁedbyL.BecauseLisPSD(Cheungetal.2018a),theobjectiveislower-boundedby0,i.e.,x>Lx≥0,∀x∈RN.Theﬁrstbinaryconstraintensuresxi∈{−1,1}.Thesecondconstraintensuresthatentriesxiinsignalxagreewithknownlabels{ˆxi}Mi=1.Asanexample,considera3-nodelinegraphshowninFig.2(a),whereedges(1,2)and(2,3)haveweightsw1,2andw2,3,respectively.ThecorrespondingadjacencymatrixWandgraphLaplacianmatrixLareW="0w1,20w1,20w2,30w2,30#,L="w1,2−w1,20−w1,2w1,2+w2,3−w2,30−w2,3w2,3#.(7)Supposeknownlabelsareˆx1=1andˆx2=−1.(6)isNP-hard(Luoetal.2010).Onecanderiveacor-respondingSDR(Luoetal.2010)asfollows.DeﬁneﬁrstX=xx>andM=[Xx;x>1].MisPSDbecause:i)sub-block1istriviallyPSD,andii)theSchurcomplementofsub-block1ofMisX−xx>=0,whichisalsoPSD.Thus,X=xx>(orequivalentlyrank(X)=1)impliesM(cid:23)0,butnotviceversa.X=xx>andXii=1,∀iimplyx2i=1,∀i.Toconvexifytheproblem,werelaxX=xx>toM(cid:23)0andwritetheSDRforoptimizationvariableMasminx,XTr(LX)s.t.M,(cid:20)Xxx>1(cid:21)(cid:23)0Xii=1,i∈{M+1,...,N}xi=ˆxi,i∈{1,...,M}(8)whereTr(x>Lx)=Tr(Lxx>)=Tr(LX).Because(8)haslinearobjectiveandconstraintswithanadditionalPSDconeconstraint,M(cid:23)0,itisanSDPproblem(GartnerandMatousek2012).Wecall(8)theSDRprimal.Continuingourexample,considerground-truthlabelsx=[1−11]>forthe3-nodegraphinFig.2(a).ThecorrespondingsolutionmatrixM=[xx>x;x>1]isM=1−111−11−1−11−1111−111.(9)ObservethatMisnotagraphLaplacianmatrixcorrespond-ingtoabalancedsignedgraph,asrequiredbyGDPA.ThismotivatesustoinvestigatethecorrespondingSDPdual.SDRDualWewritethecorrespondingdualproblembasedonSDPdualitytheory(GartnerandMatousek2012).WeﬁrstdeﬁneAi=diag(eN+1(i)),Bi=(cid:20)0N×NeN(i)e>N(i)0(cid:21)(10)whereeN(i)∈{0,1}Nisalength-Nbinarycanonicalvec-torwithasinglenon-zeroentryequalsto1atthei-thentry,0N×NisaN-by-Nmatrixofzeros,anddiag(v)isadiago-nalmatrixwithdiagonalentriesequaltov.NotethatbothAiandBiaresymmetric.Next,wecollectMknownlabels{ˆxi}Mi=1intoavectorb∈RMoflengthM,i.e.,bi=2ˆxi,∀i∈{1,...,M}.(11)WenowdeﬁnetheSDRdualof(8)asminy,z1>N+1y+b>z,(12)s.t.H,N+1Xi=1yiAi+MXi=1ziBi+(cid:20)L0N0>N0(cid:21)(cid:23)0where1Nisalength-Nvectorofones,anddualvariablesarey∈RN+1andz∈RM.Giventhat(12)isaminimization,whenbi<0(i.e.,ˆxi<0),thecorrespondingziisnon-negative5,i.e.,zi≥0.Similarly,forbi>0,zi≤0.Thus,thesignsofzi’sareknownapriori.Withoutlossofgenerality,weassumezi≤0,∀i∈{1,...,M1}andzi≥0,∀i∈{M1+1,...,M},where1≤M1<M,inthesequel.5zi<0whenbi<0wouldmeanaworseobjectiveandlargerGershgorindiscradiiforrowsiandN+1ofmatrixH,makingHmoredifﬁculttoresideinthePSDconeH(cid:23)0.ReformulatingtheSDRDualWeinterpretH∈R(N+1)×(N+1)in(12)asagraphLapla-ciancorrespondingtoasignedgraphG.However,Gisnotbalanced,becauseofthelastrow/columninH.Toseethis,wewriteH=(cid:20)Lygg>yN+1(cid:21)(13)whereg=[z1...zM0>N−M]>.MatrixLy∈RN×N,de-ﬁnedasLy,diag(y1,...,yN)+L,isageneralizedLapla-ciantoaN-nodepositivegraphG+.However,nodeN+1hasbothpositiveandnegativeedgestoG+stemmingfromnegativezi’sandpositivezi’s,respectively.Asaresult,HisnotaLaplaciantoabalancedsignedgraph.Continuingour3-nodelinegraphexamplewithLaplacianL,thecorrespondingLyandHareLy=y1+w1,2−w1,20−w1,2y2+w1,2+w2,3−w2,30−w2,3y3+w2,3,H=y1+w1,2−w1,20z1−w1,2y2+w1,2+w2,3−w2,3z20−w2,3y3+w2,30z1z20y4.(14)InterpretingHasagraphLaplacian,node1hasdegreed1=y1+w1,2=u1+w1,2−z1,andthusu1=y1+z1.Similarly,node4hasdegreed4=y4=u4−z1−z2,andthusu4=y4+z1+z2.SeeFig.2(b)foranillustrationofthisunbalancedsignedgraphG.Moregenerally,self-loopweightsareui=yi+zifori∈{1,...,M},ui=yifori∈{M+1,...,N},anduN+1=yN+1+PMj=1zj.NodeN+1haspositiveandnegativeedges,withre-spectiveweights{−zi}M1i=1and{−zi}Mi=M1+1toG+,andaself-loopwithweightuN+1.Weconstructanaugmentedgraph¯GwithN+2nodesfromGbysplittingnodeN+1inGintotwoin¯G,assigningpositiveandnegativeedgestothetworespectively.Thegraphconstructionprocedureis1.ConstructeachiofﬁrstNnodeswiththesameinter-nodeedgesasG+plusself-loopwithweightui.2.ConstructnodeN+1withpositiveedges{−zi}M1i=1,andnodeN+2withnegativeedges{−zi}Mi=M1+1,totheﬁrstNnodesinsub-graphG+.3.Addself-loopfornodesN+2withweightuN+1.Step3impliesthatnodesN+1andN+2havedegreesκN+1,−PM1i=1ziandκN+2,uN+1−PMi=M1+1zi,re-spectively.Denoteby¯H∈R(N+2)×(N+2)thegraphLapla-cianmatrixcorrespondingto¯G.Continuingour3-nodegraphexample,Fig.2(c)showstheaugmentedgraph¯G,andthecorrespondingLaplacian¯His¯H=d1−w1,20z10−w1,2d2−w2,30z20−w2,3d300z100−z100z200u4−z2(15)wheredi=yi+Pj6=iwi,jisthedegreeofnodeifori∈{1,...,N}.Crucially,¯HandHarerelatedinspectraltermsbythefollowingimportantlemma.Lemma1.Smallesteigenvalueλmin(¯H)ofgraphLapla-cian¯Htoaugmentedgraph¯Gisalowerboundforsmallesteigenvalueλmin(H)ofLaplacianHtoG,i.e.,λmin(¯H)≤λmin(H).(16)Proof.DenotebyGthegraphrepresentedbygeneralizedgraphLaplacianH,withinter-nodeedgeweights{wi,j}andself-loopweights{ui}.Denotebyv∈RN+1theﬁrsteigenvectorofHcorrespondingtothesmallesteigenvalueλmin(H).From(3),GLRofHcomputedusingvisv>Hv=X(i,j)∈E|1≤i,j≤Nwi,j(vi−vj)2−MXi=1zi(vN+1−vi)2+NXi=1uiv2i+uN+1v2N+1.(17)Nowconstructlength-(N+2)vectorα∈RN+2,whereα=[v1...vNvN+1vN+1]>.GLRof¯Husingαisα>¯Hα=X(i,j)∈E|1≤i,j≤Nwi,j(vi−vj)2−M1Xi=1zi(vN+1−vi)2−MXi=M1+1zi(vN+1−vi)2+NXi=1uiv2i+uN+1v2N+1.(18)Thus,v>Hv=α>¯Hα.SinceﬁrsteigenvectorvofHminimizesitsRayleighquotient,λmin(H)=v>Hvv>v(a)≥α>¯Hαα>α(b)≥λmin(¯H).(19)(a)holdssincev>v≤α>αbyconstruction,and(b)holdssinceλmin(¯H)=minxx>¯Hxx>x.Inourexperiments,weverifynumericallythattheboundλmin(¯H)≤λmin(H)wastightinrealisticdatasets.GivenLemma1,wereformulatetheSDRdual(12)bykeepingthesameobjectivebutimposingthePSDconecon-strainton¯HinsteadofH.First,deﬁneA0i,B0iandB00isimi-larlyto(10)butforalarger(N+2)-by-(N+2)matrix;i.e.,A0i,diag(eN+2(i)),B0i,(cid:20)Bi0N+10>N+10(cid:21),B00i,(cid:20)0(N+1)×(N+1)eN+1(i)e>N+1(i)0(cid:21).(20)ThereformulatedSDRdualisminy,z1>N+1y+b>z,(21)s.t.¯H,NXi=1yiA0i+κN+1A0N+1+κN+2A0N+2+M1Xi=1ziB0i+MXi=M1+1ziB00i+(cid:20)L0N×202×N02×2(cid:21)(cid:23)0whereκN+1andκN+2arethedegreesofnodesN+1andN+2,respectively,deﬁnedearlier.Wecanboundthedifferenceinobjectivevaluesbetweentheoptimalsolutionsto(12)and(21)asfollows.Weﬁrstconstructyetanothermodiﬁedgraph˜GfromG,whereweight−ziofeachedgefromnodeN+1tonodei∈{1,...,M}isincrementedbyφ.ThisresultsinanotherrelatedgraphLaplacianmatrix˜Hformodiﬁed˜G.Continuingourexample,themodiﬁedgraphLaplacian˜HfromHin(14)is˜H=H+φ00−φ0φ0−φ0000−φ−φ02φ.(22)SimilartoLemma1,weclaiminthefollowinglemmathat˜HandHarerelatedinspectralterms.Lemma2.Thesmallesteigenvalueλmin(H)ofgraphLapla-cianHtographGisalowerboundforλmin(˜H)ofLapla-cian˜Hto˜G,i.e.,λmin(H)≤λmin(˜H).(23)Seetheproofinthesupplementaryﬁle.Thecorollaryisthat˜H(cid:23)0ifH(cid:23)0,ormoresimply,˜H(cid:23)H.Thismeansthatminimizingthesameobjectivein(12)butusingthemorerelaxedconstraint˜H(cid:23)0insteadwillyieldanobjectivevalueF(˜H)thatisnoworsethanF(H).Given˜H(cid:23)H(cid:23)¯H,weknowF(˜H)≤F(H)≤F(¯H).Thus,wecanboundtheapproximationerror|F(¯H)−F(H)|betweenthemodiﬁedSDRdual(21)andtheoriginalSDRdual(12)as|F(¯H)−F(H)|≤|F(¯H)−F(˜H)|.(24)Finally,wenotethatminimizingobjectivein(12)withconstraint˜H≥0ismucheasierifφissufﬁcientlylargesuchthatalledgesfromnodeN+1becomespositive.Insuchcase,˜Gisapositivegraph,andGDPAlinearizationcanbeapplied.Thus,theerrorbound(24)canbenumericallycomputedefﬁcientlyforeachinstantofSDRdual(12).Given¯HisaLaplaciantoabalancedgraph,wediscussusingGDPAlinearizationtosolve(21)next.AlgorithmImplementationGDPALinearizationWereplacethePSDconeconstrainton¯Hin(21)withN+2linearconstraintsviaGDPA.Speciﬁcally,atiter-ationt,wecomputeﬁrsteigenvectorvtofsolution¯HtusingLOBPCG(Knyazev2001).Wedeﬁnescalarssi=1/vti,∀i∈{1,...,N+2}.Finally,wewriteN+2con-straintscorrespondingtoλ−min(S¯HS−1)≥0,whereS=diag(s1,...,sN+2),i.e.,¯Hi,i−Xj6=i|si¯Hi,j/sj|≥0,∀i∈{1,...,N+2}.(25)Notethattheabsolutevalueoperationcanbeappropriatelyremovedforeachtermsi¯Hi,j/sj,sincethesignsforsiand¯Hi,jareknown.Togetherwithlinearobjectivein(21),thisconstitutesanLPforvariablesyandz,solvableusinganavailablefastLPsolver(Vanderbei2021)6.ComparedtoSDRprimal(8)withalargematrixvariableM∈R(N+1)×(N+1),dimensionsofourLPvariables,y∈RN+1andz∈RM,aremuchsmaller.AsequenceofLPsaresolved,eachtimewithscalarssi’supdatedfromcomputedsolution¯Ht,untilconvergence.ThebulkofthecomplexityresidesinthecomputationoftheﬁrsteigenvectorvtforeachLPsolution¯Ht.LOBPCG(Knyazev2001)isaniterativealgorithmrunninginlineartimeforex-tremeeigenvectorsofsparsematrices,whichfurtherbeneﬁtsfromwarmstart:withagoodinitialguessforvt,thealgo-rithmconvergesfaster.Since¯Htchangesgraduallyduringtheiterations,weusepreviouslycomputedeigenvectorvt−1of¯Ht−1asinitialguessforvtof¯Ht.Experimentsshowthatwarmstartimprovesconvergencespeedsigniﬁcantly.Initialization&PredictionLabelExtractionOurposedLPrequiresaninitial¯H0tocomputeﬁrsteigen-vectorv0,sothatscalars{si}N+2i=1canbedeﬁnedforN+2linearconstraintsin(25).Toinitialize¯H0,wesety0=[1>M0>N−MM]>andz0=[−ˆx1...−ˆxM].¯H0canthenbecomputedusingdeﬁnitionof¯Hin(21).Assimilarlydonein(Luoetal.2010),weextractlabelsx∗=[x1...xN]>fromconvergedLPsolutiony∗andz∗asfollows.WeﬁrstconstructH∗usingy∗andz∗usingdeﬁnitionofHin(12).Wethencomputex∗=sign(ˆx1v1v),wherev1istheﬁrstentryoftheﬁrsteigenvectorvofH∗.See(Luoetal.2010)fordetailsofrecoveringSDPprimalvariablesfromdualvariablesinBQP.Finally,weextractthepredictionlabelsas˜x=[x∗M+1,...,x∗N]>.ExperimentsExperimentalSetupWeimplementedourGDPAclassiﬁerinMatlab7,andevalu-ateditintermsofaverageclassiﬁcationerrorrateandrunningtime.AllcomputationswerecarriedoutonaWindows1064bitPCwithAMDRyzenThreadripper3960X24-corepro-cessor3.80GHzand128GBofRAM.WecomparedouralgorithmagainstthefollowingschemesthatsolvetheSDRprimalproblem(8)directly:i)twoprimal-dualinterior-pointsolversforSDP,SeDuMiandMOSEK(CVX2020),ii)an6ThelowestcomplexityofageneralLPsolver(Jiangetal.2020)todateisO(N2.055).NotethattheLPﬁeldisstillfast-evolving,andourproposalisnottiedtoaspeciﬁcLPsolver.7availableathttps://anonymous.4open.science/r/gc_-80C0ADMMﬁrst-orderoperator-splittingsolverCDCS(Zheng,Fantuzzi,andPapachristodoulou2019;CDCS2016),iii)aspectrahedron-basedrelaxationsolverSDCut(Wang,Shen,andvandenHengel2013;SDcut2013)thatinvolvesL-BFGS-B(Zhuetal.1997),andiv)abiconvexrelaxationsolverBCR(Shahetal.2016;BCR2020),allofwhichareimplementedinMatlab.Further,weemployedCDCSagaintosolveourmodiﬁedSDRdualproblem(21).WefocusourcomparisonwithSDRschemesbecause,again,SDRisknowntoprovidegooderror-boundedapproximationsingeneralforNP-hardQCQPproblems(Luoetal.2010).Inaddition,wecomparedagainstthefollowingnon-SDRmethodsapproximatingoriginalclassiﬁerformulation(6)directly.Arecentmethodcalledstochasticneighborhoodsearch(SNS)(LamandLiew2020;SNS2021)solves(6)byalternatelyapplyingKarush–Kuhn–Tuckeroptimalitycondi-tionguideddeterministicsearchandbootstrappingsamplingbasedstochasticsearch.Wesolvedarelaxedversionof(6)usingSeDuMi,whereconstraintx2i=1wasrelaxedtoaboxconstraintxi∈[−1,1]—wedenotethismethodbyGLR-box.Finally,binaryconstraintx2i=1canbeignoredentirely,andobjectivex>Lxin(6)canbeoptimizedsimplybycomput-ingextremeeigenvectorsplusrounding.WedenotethisclassofspectralmethodsbySPEC,whicharefastbutareknowntohavepoorworst-caseerrors(GuatteryandMiller1998).ExperimentalResultsWeﬁrstshowinTable1thatSPEChasbyfartheworstperfor-manceinbinarysignalrestorationcomparedtoSDR-basedschemesandSNS,demonstratingthelimitationsofspectralmethodsingeneral.Speciﬁcally,followinganillustrativeex-amplein(LamandLiew2020),weﬁrstcorruptedalength-N1-Dsignal[1>N/2,−1>N/2]withiidnoise,thensolvedtheop-timizationmaxxi∈{−1,1}x>Px,whereP=[1c>;cW].Here,cdenotesthenoisy1-Dsignal,andWdenotestheadjacencymatrixcorrespondingtoanunweightedlinegraph.WeoptimizedtheaboveobjectiveusingSPEC,SDRprimalformulationlike(8),ourproposedGDPA,andSNS.Resultswereaveragedover100runs.Table1showsthatSPECper-formedbyfartheworstatallproblemsizes(N=100or200),typesoflinegraphs(1-hopor2-hopneighbor)andnoisestandarddeviationσ.Incontrast,GDPAperformedsimilarlytoSDRprimalandnon-SDRschemeSNS.WethusremoveSPECfromexperimentalcomparisonsinthesequel.Wenextevaluatecompetingschemesonclassiﬁcationer-rorandruntimeonrealdatasets.Foreachdataset,weﬁrstperformedmin-max(RussellandNorvig2009)andstan-dardization(Dongetal.2020),twodifferentdatare-scalingschemes,tothefeaturesofdatasetsamples,usedtocomputegraphedgeweightsviaanexponentialkernel(Ortegaetal.2018).Forexperimentalefﬁciency,weperformedaK-fold(K≤5)splitforeachdatasetwithrandomseed0,andthencreated10instancesof50%training-50%testsplitforeachfold,withrandomseeds1-10(RussellandNorvig2009).Weused50%training-50%testsplitforeachexperiment.Seethesupplementaryﬁlefordetailedexperimentalsettings.Table2andFig.3(left)showaverageclassiﬁcationerrorratesandruntime(inlogscale)of17binarydatasets(UCI2021;Lib-Table1:Binarysignalrestorationerror(%).Originalsignal[1>N/2,−1>N/2]isﬁrstlycorruptedusingwhitenoisewithstdσandthenrestoredusingspectralmethodSPEC,SDPsolverSeDuMionSDRprimalin(8),proposedGDPAandnon-SDRmethodSNS.Resultsareaveragedover100runs.Ngraph1-hopneighbor2-hopneighborσ11.5211.52100SPEC13.0423.2429.5910.0220.9428.06SDRprimal2.4511.9620.820.904.8212.92GDPA2.7811.0119.570.863.579.13SNS1.9711.0119.880.632.508.32200SPEC13.5423.3829.3611.1921.6928.20SDRprimal1.7610.7819.160.283.0110.87GDPA2.4610.8118.670.392.838.52SNS1.7210.9219.090.201.487.36Table2:Meanclassiﬁcationerror(%)of17binarydatasets.datare-scalingmin-maxstandardizationSeDuMi(8)30.1932.60MOSEK(8)30.3132.61CDCS(8)30.7631.76CDCS(21)30.0829.40BCR27.6026.24SDcut27.4926.81GLR-box28.6328.38SNS33.7530.50GDPA28.2126.94SVM2021)withproblemsizesfrom29to400,respectively.Thex-axisofeachplotdenotesthedatasetsinascendingorderofproblemsizes.Fig.3(right)showsruntimeusingthesamedatasetcod-rnawithproblemsizesfrom4to24428.WedidnotexecuteSeDuMi(8),MOSEK(8),CDCS(8),CDCS(21),BCR,SDcutorGLR-boxwhenproblemsizeexceeded976.Intermsofclassiﬁcationerrorrate,CDCSsolvingthemod-iﬁeddual(21)hadsimilarperformanceastheoriginalSDRprimal(SeDuMi(8),MOSEK(8)andCDCS(8)),show-ingthevalidityofourproposedmodiﬁedSDRdual(21).Further,ourproposedGDPAcloselyapproximatedthemodi-ﬁedSDRdual(CDCS(21))inperformance,demonstratingtheeffectivenessofourprojection-freeGDPAlinearizationscheme.ByfactorizingaPSDmatrixM=XX>,BCRavoidedtuningofanyforwardprogressstepsizeaftereachPSDconeprojection,whichmayexplainitsslightlybetteraverageperformance.However,BCRsolvedanon-convexoptimizationproblemconvergingtoalocalminimum,andthusoccasionallytheperformancewasrelativelypoor(e.g.,seecolon-cancerintheerrorrateplotsinthesupple-mentaryﬁle).Overall,allsolversperformedsimilarlygivenconstructedsimilaritygraphsinthetwocases.Intermsofruntime,BCRwascompetitivewithGDPAwhentheproblemsizewassmall,butGDPAsigniﬁcantlyoutperformedallcompetingsolverswhentheproblemsizewaslarge.Speciﬁcally,thespeedgainincreasedasproblemsizeincreased;formadelonwithsize400,thespeedupofGDPAoverthenextfastestschemeSNSwas34×.liver-disordersplanningsonarhabermancolon-cancervotingmonk1WDBCILPDheartbreast-canceraustraliandiabetespimafourclassgermanmadelonavg.100102104runtime (ms)102104problem size101102103104105runtime (ms)SeDuMi (8)MOSEK (8)CDCS (8)CDCS (21)BCRSDcutGLR-boxSNSGDPAFigure3:Runtime(ms)on17datasets(left)withproblemsizes29to400andcod-rna(right)withproblemsizes4to24428.Fig.3(right)showsthatthecomputationtimeforGDPAincreasedgracefullyastheproblemsizeincreasedtoverylargesizes.OnereasonforourdramaticspeedgainisthefastcomputationofﬁrsteigenvectorsusingLOBPCG,whichben-eﬁtedfromwarmstart.Ingeneral,GDPAperformedfewerthan10LP’suntilconvergence.Incontrast,bothCDCSandSDCutrequiredfullmatrixeigen-decompositionofamatrixofsizeN×Nperiteration;thespeedupofreplacingthefulleigen-decompositionwithoneLPplusﬁrsteigenvectorcomputationperiterationwassigniﬁcant.ForBCR,eachiterationrequiredeitherN-dimensionalmatrixinversionforaleast-squaresproblemoriterativegradientdescent,whichwascomputationallyexpensiveastheproblemsizeincreased.SNSrequiredmanymatrix-vectormultiplications—whichwastime-consumingastheproblemsizeincreased—thoughmanuallyadjustingthenumberofneighborhoodvectorscanpotentiallyimprovespeed.Onaverage,GDPAenjoyeda28×speedupoverthenextfastestsolverSNS.Onaverage,thedifferencebetweenλmin(H)andλmin(¯H)inLemma1is1.1608×10−7,whichisverysmall.Thisdemonstratesthetightnessofboundλmin(¯H)≤λmin(H)inpractice,andthustheeffectivenessofLemma1.ConclusionWeproposeafastprojection-freealgorithmforthebinarygraphclassiﬁcationproblem.Thekeyideaistoreplacethedifﬁcultpositivesemi-deﬁnite(PSD)coneconstraintwithlinearconstraintsderivedfromtherecentGershgorindiscperfectalignment(GDPA)theory,sothateachiterationre-quiresonlyonelinearprogram(LP)andoneﬁrsteigenvectorcomputation.Experimentsshowthatouralgorithmenjoyedonaverage28×speedupoverthenextfastestcompetitorwhileretainingcomparablelabelpredictionperformance.Asanoptimizationproblem,binarygraphclassiﬁcationisrathernarrowlydeﬁned(thoughmulti-classclassiﬁcationcanbeimplementedasatreeofbinaryclassiﬁers).Further,performancedependsheavilyontheconstructionofagoodsimilaritygraph,whichisoutsidethispaper’sscope.How-ever,weconjecturethatthegeneralmethodologyofGDPAlinearizationcanbesimilarlytailoredtootherQCQPprob-lemswithPSDconeconstraints.WeanticipatethatspeedupsinotherQCQPproblemswillalsobesigniﬁcant.ReferencesBCR.2020.BCRimplementation.https://github.com/Axeldnahcram/biconvex_relaxation.Accessed:2022-8-15.Belkin,M.;Matveeva,I.;andNiyogi,P.2004.Regular-izationandsemisupervisedlearningonlargegraphs.InShawe-TaylorJ.,SingerY.(eds)LearningTheory,COLT2004,LectureNotesinComputerScience,volume3120,624–638.Bishop,C.M.2006.PatternRecognitionandMachineLearn-ing(InformationScienceandStatistics).Berlin,Heidelberg:Springer-Verlag.ISBN0387310738.Boyd,S.;Parikh,N.;Chu,E.;Peleato,B.;andEckstein,J.2011.DistributedOptimizationandStatisticalLearningviatheAlternatingDirectionmethodofMultipliers.InFounda-tionsandTrendsinOptimization,volume3,no.1,1–122.Cartwright,D.;andHarary,F.1956.Structuralbalance:ageneralizationofHeider’stheory.InPsychologicalReview,volume63,no.5,277–293.CDCS.2016.CDCSimplementation.https://github.com/oxfordcontrol/CDCS.Accessed:2022-8-15.Cheung,G.;Magli,E.;Tanaka,Y.;andNg,M.2018a.GraphSpectralImageProcessing.InProceedingsoftheIEEE,volume106,no.5,907–930.Cheung,G.;Su,W.-T.;Mao,Y.;andLin,C.-W.2018b.Ro-bustSemisupervisedGraphClassiﬁerLearningwithNegativeEdgeWeights.InIEEETransactionsonSignalandInforma-tionProcessingoverNetworks,volume4,no.4,712–726.Chung,F.1996.SpectralGraphTheory.AmericanMathe-maticalSociety.CVX.2020.CVXResearch.http://cvxr.com/cvx/.Accessed:2022-8-15.Dittrich,T.;andMatz,G.2020.SignalProcessingonSignedGraphs:Fundamentalsandpotentials.InIEEESignalPro-cessingMagazine,volume37,no.6,86–98.Dong,M.;Wang,Y.;Yang,X.;andXue,J.2020.Learn-ingLocalMetricsandInﬂuentialRegionsforClassiﬁcation.IEEETPAMI,42(6):1522–1529.Dong,X.;Thanou,D.;Rabbat,M.;andFrossard,P.2019.LearningGraphsFromData:ASignalRepresentationPer-spective.IEEESignalProcessingMagazine,36(3):44–63.Gartner,B.;andMatousek,J.2012.ApproximationAlgo-rithmsandSemideﬁniteProgramming.Springer.Gavish,M.;Nadler,B.;andCoifman,R.2010.Multiscalewaveletsontrees,graphsandhighdimensionaldata:The-oryandapplicationstosemi-supervisedlearning.In27thInternationalConferenceonMachineLearning.Haifa,Israel.Goemans,M.;andWilliamson,D.1995.ImprovedAp-proximationAlgorithmsforMaximumCutandSatisﬁabilityProblemsUsingSemideﬁniteProgramming.J.ACM,42(6):1115–1145.Guattery,S.;andMiller,G.L.1998.OntheQualityofSpectralSeparators.SIAMJournalonMatrixAnalysisandApplications,19(3):701–719.Guillory,A.;andBilmes,J.2009.LabelSelectiononGraphs.InTwenty-ThirdAnnualConferenceonNeuralInformationProcessingSystems.Vancouver,Canada.Helmberg,C.;Rendl,F.;Vanderbei,R.;andWolkowicz,H.1996.Aninterior-pointmethodforsemideﬁniteprogram-ming.InSAIMJ.Optim.,volume6,no.2,342–361.Jiang,S.;Song,Z.;Weinstein,O.;andZhang,H.2020.FasterDynamicMatrixInverseforFasterLPs.arXiv:2004.07470.Knyazev,A.V.2001.TowardtheOptimalPreconditionedEigensolver:LocallyOptimalBlockPreconditionedConju-gateGradientMethod.SIAMJournalonScientiﬁcComput-ing,23(2):517–541.Kunegis,J.;Schmidt,S.;Lommatzsch,A.;Lerner,J.;Luca,E.D.;andAlbayrak,S.2010.Spectralanalysisofsignedgraphsforclustering,predictionandvisualization.InSIAMInternationalConferenceonDataMining.Columbus,OH.Lam,B.S.;andLiew,A.W.C.2020.AFastBinaryQuadraticProgrammingSolverbasedonStochasticNeigh-borhoodSearch.IEEETransactionsonPatternAnalysisandMachineIntelligence,1–1.Li,Z.;Liu,J.;andTang,X.2008.Pairwiseconstraintprop-agationbysemideﬁniteprogrammingforsemi-supervisedclassiﬁcation.InACMInternationalConfereneonMachineLearning.Helsinki,Finland.LibSVM.2021.LibSVMData:Classiﬁcation(BinaryClass).https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html.Accessed:2022-8-15.Luo,Z.;Ma,W.;So,A.M.;Ye,Y.;andZhang,S.2010.SemideﬁniteRelaxationofQuadraticOptimizationProblems.IEEESignalProcessingMagazine,27(3):20–34.Moutaﬁs,P.;Leng,M.;andKakadiaris,I.A.2017.AnOverviewandEmpiricalComparisonofDistanceMetricLearningMethods.IEEETransactionsonCybernetics,47(3):612–625.O’Donoghue,B.;Chu,E.;Parikh,N.;andBoyd,S.2016.ConicOptimizationviaOperatorSplittingandHomogeneousSelf-DualEmbedding.InJournalofOptimizationTheoryandApplications,volume169,no.3,1042–1068.Ortega,A.;Frossard,P.;Kovacevic,J.;Moura,J.M.F.;andVandergheynst,P.2018.GraphSignalProcessing:Overview,Challenges,andApplications.InProceedingsoftheIEEE,volume106,no.5,808–828.Pang,J.;andCheung,G.2017.GraphLaplacianRegulariza-tionforInverseImaging:AnalysisintheContinuousDomain.InIEEETransactionsonImageProcessing,volume26,no.4,1770–1785.Russell,S.;andNorvig,P.2009.ArtiﬁcialIntelligence:AModernApproach.USA:PrenticeHallPress,3rdedition.ISBN0136042597.SDcut.2013.SDcutimplementation.https://github.com/chhshen/SDCut.Accessed:2022-8-15.Shah,S.;Kumar,A.;Castillo,C.;Jacobs,D.;Studer,C.;andGoldstein,T.2016.BiconvexRelaxationforSemideﬁniteProgramminginComputerVision.InEuropeanConferenceonComputerVision.Amsterdam,theNetherlands.Shuman,D.;Faraji,M.;andVandergheynst,P.2011.Semi-supervisedlearningwithspectralgraphwavelets.InInter-nationalConferenceonSamplingTheoryandApplications(SampTA).Singapore.SNS.2021.SNSimplementation.https://github.com/bensonsylam/BQP.Accessed:2021-10-10.UCI.2021.UCImachinelearningrepository.https://archive.ics.uci.edu/ml/datasets.php.Accessed:2022-8-15.Vanderbei,R.2021.LinearProgramming:FoundationsandExtensions(5thEdition).SpringerNature.Varga,R.S.2004.Gershgorinandhiscircles.Springer.Wang,P.;Shen,C.;Hengel,A.;andTorr,P.2017.Large-ScaleBinaryQuadraticOptimizationUsingSemideﬁniteRelaxationandApplications.IEEETransactionsonPatternAnalysisandMachineIntelligence,39(3):470–485.Wang,P.;Shen,C.;andvandenHengel,A.2013.AFastSemideﬁniteApproachtoSolvingBinaryQuadraticProb-lems.InIEEEInternationalConferenceonComputerVisionandPatternRecognition.Portland,OR.Yang,C.;Cheung,G.;andHu,W.2021.SignedGraphMetricLearningviaGershgorinDiscPerfectAlignment.IEEETransactionsonPatternAnalysisandMachineIntelligence,1–1.Zheng,Y.;Fantuzzi,G.;andPapachristodoulou,A.2019.FastADMMforSum-of-SquaresProgramsUsingPartialOrthogonality.IEEETransactionsonAutomaticControl,64(9):3869–3876.Zheng,Y.;Fantuzzi,G.;Papachristodoulou,A.;Goulart,P.;andWynn,A.2020.Chordaldecompositioninoperator-splittingmethodsforsparsesemideﬁniteprograms.Mathe-maticalProgramming,180:489—-532.Zhou,D.;Bousquet,O.;Lal,T.N.;Weston,J.;andScholkopf,B.2003.Learningwithlocalandglobalconsistency.In16thInternationalConferenceonNeuralInformationProcessing(NIPS).Whistler,Canada.Zhu,C.;Byrd,R.;Lu,P.;andNocedal,J.1997.Algorithm778:L-BFGS-B:FortranSubroutinesforLarge-ScaleBound-ConstrainedOptimization.ACMTrans.Math.Softw.,23(4):550–560.TechnicalAppendixofpaper“Projection-freeGraph-basedClassiﬁerLearningusingGershgorinDiscPerfectAlignment”LocalConvergenceofGDPALinearizationWediscussconvergencetoalocalminimumviaGDPAlin-earizationwhensolvinganoptimizationminL(cid:23)0Q(L)whereQ(L)islinear.Inatopologicalspace[Hausdorff(1957)],asetisaneighborhoodV(a)ofapointaiffitcontainsthepointainitsinterior—itisanopensetthatcontainsthepoint.GivenaPSDgraphLaplacianL(cid:23)0toabal-ancedsignedgraphG,weﬁrstdeﬁneaneighborhoodVr(L)aroundLasanopenballofradiusrcenteredatL,i.e.,Vr(L),{L∈S+|kL−Lk2F<r},whereS+isthesetofPSDgraphLaplacianmatricestobalancedgraphsofthesameedgesigns.OnecanshowthatS+isaconvexcone,andthusgivenobjectiveQ(L)isalsoconvex,iterativelycomput-inganoptimalsolutionLt+1inlocalneighborhoodVr(Lt)atiterationtwouldconvergetoagloballyoptimalsolutionast→∞.SincetheoriginalfeasiblespaceissimplyPSDcone{L|L(cid:23)0}whichcontainsS+,convergencewithinS+isalocalconvergence.ToensureGDPAlinearizationcomputesanoptimalsolutionLt+1inawell-deﬁnedneighborhoodUρ(Lt)thatapproxi-matesVr(Lt),wecanperformthefollowingprocedure1.First,deﬁneUρ(Lt)asthesetofmatricessatisfyingslightlyrelaxedconstraints:Li,i−Xj6=i|siLi,j/sj|≥−ρ,∀i(1)whereρ>0isasmallparameter.Scalars{si}in(1)arecomputedfromtheﬁrsteigenvectorvofLtassi=v−1i,∀i.Forsmallenoughr,matricesL∈Vr(L)havesimilarﬁrsteigenvectorsasv,andthusconstraints(1)wouldbesatisﬁed.Thus,computinganLPwiththerelaxedconstraints(1)wouldapproximateanoptimalsolutioninVr(Lt).TherearethreepossibilitiesfortheobtainedsolutionLt+1:1.Ifλmin(Lt+1)≥0andLt+16=Lt,thenonecancom-putenewscalars{si}usingtheﬁrsteigenvectorvofnewsolutionLt+1,andthealgorithmproceedstothenextiterationt+1.2.Iftheobtainedsolutionλmin(Lt+1)≥0andLt+1=Lt,thenweincreaseρ,andtheiterationtisrepeated.1TheprocedureisappliedaftertheiterationsofGDPAlineariza-tionreturnnonewsolutionsLt+1whensettingρ=0.3.Ifλmin(Lt+1)<0,thenLt+1isnotafeasiblesolution,andwedecreaseρ,andtheiterationtisrepeated.Possibility1meansthatUρ(Lt)isaproperlydeﬁnedneigh-borhood,sinceLtisnotatthesetboundaryandanewsolutionLt+16=Ltisfound.Possibility2meansthatUρ(Lt)isnotaproperlydeﬁnedneighborhood,sinceLtisatthesetboundary.WethusincreaseρtodeﬁnealargersetUρ(Lt).Possibility3meansthatsetUρ(Lt)istoolargeandincludesindeﬁnitematrixLt+1,andthusρisdecreased.Notethatforpossibility3,λmin(Lt+1)>−ρ,sinceLt+1isaLaplaciantoabalancedgraphsatisfying(1)usingscalars{si}computedusingﬁrsteigenvectorvofLt6=Lt+1,andthuswhenitsdiscleft-endsareperfectlyaligned,thealignedlocationmustbe>−ρ.NotethattisincrementediffUρ(Lt)isawell-deﬁnedneighborhood.Thismeansthattheonlywaythealgorithmter-minatesisifaftermultiplepossibility1,thealgorithmrepeatspossibility2and3alternately.Asthesequenceofadjustedρbecomesincreasinglyindistinguishable,thiswouldimplywehaveconvergedtoalocalminimum.ProofofLemma2Proof.Denotebyv∈RNtheﬁrsteigenvectorof˜H.Wewritev>Hv=X(i,j)∈E|1≤i,j≤Nwi,j(vi−vj)2+N+1Xi=1uiv2i−MXi=1zi(vN+1−vi)2v>˜Hv=X(i,j)∈E|1≤i,j≤Nwi,j(vi−vj)2+N+1Xi=1uiv2i+MXi=1(φ−zi)(vN+1−vi)2Givenφ−zi>−zi,∀i,v>˜Hv≥v>Hv.SincevminimizestheRayleighquotientof˜H,λmin(˜H)=v>˜Hvv>v≥v>Hvv>v(a)≥λmin(H).(2)(a)holdssinceλmin(H)=minxx>Hxx>x.arXiv:2106.01642v3  [cs.LG]  19 Aug 2022ExperimentalDetailsforResultReproductionWesettheconvergencethresholdoftheﬁrsteigenvectorsolverLOBPCGto10−4asconsistentintheLOBPCGliterature[Duerschetal.(2018)Duersch,Shao,Yang,andGu],withmax-imumnumberofiterations200.Wesettheconvergencethresh-oldofourLPsolvertobe10−4also,withmaximumnumberofiterations100,sinceﬁrst-ordermethods,i.e.,CDCSandSD-Cut,aimatcomputingasolutionofmoderateaccuracy[Zheng,Fantuzzi,andPapachristodoulou(2019)].Accordingly,wesettheconvergencethresholdofSeDuMiandMOSEKtobe‘low’,whichisapproximatelyequalto10−4andthelowestprecisionsettinginCVX.WesettheconvergencethresholdsofCDCSandSDCuttobe10−3,themaximumnumberofADMMitera-tionsinCDCStobe1000,themaximumnumberofiterationsforL-BFGS-BinSDCutandthemainloopinBCRtobe100,andtheFrobeniusnormweightinSDCuttobe100.WechosethesesettingssincesmallerconvergencethresholdsandlargernumberofiterationswouldcauseCDCS,SDCutandBCRtobesigniﬁcantlyslowertoconverge.Weuseddefaultsettingsforallremainingsolvers.AllcomputationswerecarriedoutonaWindows1064bitPCwithAMDRyzenThreadripper3960X24-coreprocessor3.80GHzand128GBofRAM.Weadopted17binarydatasetsthatarefreelyavailableinUCI[UCI(2021)]andLibSVM[LibSVM(2021)].Forexperi-mentalefﬁciency,weﬁrstperformedaK-fold(K≤5)splitforeachdatasetwithrandomseed0,andthencreated10instancesof50%training-50%testsplitforeachfold,withrandomseeds1-10[RussellandNorvig(2009)].Theabovesetupresultedinproblemsizesfrom29to400.Weappliedthefollowingtwodatanormalizationschemesforthetraining/testdata:i)astandardizationschemein[Dongetal.(2020)Dong,Wang,Yang,andXue]thatﬁrstsubtractsthemeananddividesbythefeature-wisestandarddeviation,andthennormalizestounitlengthsample-wise,andii)amin-maxscheme[RussellandNorvig(2009)]thatrescaleseachfeaturetowithin0and1.Weadded10−12noisetothedatasettoavoidNaN’sduetodatanormalizationonsmallsamples.FurtherExperimentalResultsWeshowinTable1thatSPEChasbyfartheworstperfor-manceinbinarysignalrestorationcomparedtoSDR-basedschemesandSNS,demonstratingthelimitationsofspectralmethodsingeneral.Speciﬁcally,followinganexamplein[LamandLiew(2020)],weﬁrstcorruptedalength-N1-Dsig-nal[1>N/2,−1>N/2]withiidnoise,thensolvedtheoptimizationmaxxi∈{−1,1}x>Px,whereP=[1c>;cW].Here,cde-notesthenoisy1-Dsignal,andWdenotestheadjacencyma-trixcorrespondingtoanunweightedlinegraph.WeoptimizedtheaboveobjectiveusingSPEC,SDRprimalformulationlike(8),SDRdualformulationlike(12),modiﬁedSDRdualfor-mulationlike(20),ourproposedGDPA,andSNS.Resultswereaveragedover100runs.Table1showsthatthespectralmethodSPECperformedbyfartheworstatallproblemsizes(N=50,100,150and200),typesoflinegraphs(1-hopneighborand2-hopneighbor)andnoiselevels,asobservedinpreviousliterature[GuatteryandMiller(1998)].Ontheotherhand,ourproposedGDPAperformedsimilarlytotheSDRschemesvia(8),(12)and(20)andSNS.liver-disordersplanningsonarhearthabermancolon-cancervotingmonk1WDBCILPDbreast-canceraustraliandiabetespimafourclassgermanmadelonavg.5101520253035404550error rate (%)SeDuMi (8)MOSEK (8)CDCS (8)CDCS (21)BCRSDcutGLR-boxSNSGDPAFigure1:Classiﬁcationerrorrateswithmin-maxdatare-scalingandproblemsizesfrom29to400.liver-disordersplanningsonarhabermancolon-cancervotingmonk1WDBCILPDheartbreast-canceraustraliandiabetespimafourclassgermanmadelonavg.1020304050error rate (%)SeDuMi (8)MOSEK (8)CDCS (8)CDCS (21)BCRSDcutGLR-boxSNSGDPAFigure2:Classiﬁcationerrorrateswithstandardizationdatare-scalingandproblemsizesfrom29to400.Fig.1andFig.2showtheclassiﬁcationerrorratewithmin-maxandstandardizationdatare-scaling,respectively.Again,ourproposedGDPAlinearization(24)closelyapproximatedthemodiﬁedSDRdual(20)inperformance.ByfactorizingaPSDmatrixM=XX>,BCRavoidedtuningofanyforwardprogressstepsizeafteraPSDconeprojection,whichmayexplainitsslightlybetterperformancehere.However,BCRsolvedanon-convexoptimizationproblemconvergingtoalocalminimum,andthusoccasionallytheperformancewasrelativelypoor(e.g.,seecolon-cancerintheerrorrateplotsinFig.2).Overall,allsolversperformedsimilarlygivenconstructedsimilaritygraphsinthetwocases.Fig.3andFig.4showthedifferencebetweenλmin(H)andλmin(¯H)describedinLemma1.Onaverage,thedifferencebetweenλmin(H)andλmin(¯H)inLemma1is1.1608×10−7,whichisverysmall.Thisdemonstratesthetightnessofboundλmin(¯H)≤λmin(H)inpractice,andthustheeffectivenessofLemma1.Table1:Binarysignalrestorationerror(%).Originalsignal[1>N/2,−1>N/2]isﬁrstlycorruptedusingwhitenoisewithstdσandthenrestoredusingspectralmethodSPEC,SDPsolverSeDuMionSDRprimalin(8),SDRdualin(12),modiﬁedSDRdualin(21),proposedGDPAandnon-SDRmethodSNS.Resultsareaveragedover100runs.Ngraph1-hopneighbor2-hopneighborσ11.5211.5250SPEC11.9823.0229.748.4219.8827.56SDRprimal(8)3.3612.4422.142.087.5815.68SDRdual(12)3.3612.722.181.886.4614.3modiﬁedSDRdual(21)3.2611.7620.781.585.1411.06GDPA3.5612.1621.441.926.3412.72SNS2.911.9420.961.564.9610.46100SPEC13.0423.2429.5910.0220.9428.06SDRprimal(8)2.4511.9620.820.904.8212.92SDRdual(12)2.2813.6824.280.774.4417.80modiﬁedSDRdual(21)2.7510.9019.280.803.318.85GDPA2.7811.0119.570.863.579.13SNS1.9711.0119.880.632.508.32150SPEC13.3223.6229.7110.6023.3828.32SDRprimal(8)1.8510.7620.230.4310.7811.55SDRdual(12)2.5211.5120.220.5613.6711.74modiﬁedSDRdual(21)2.4310.6018.850.5010.688.33GDPA2.4510.8319.110.5110.818.11SNS1.7310.8919.760.3110.927.19200SPEC13.5423.3829.3611.1921.6928.20SDRprimal(8)1.7610.7819.160.283.0110.87SDRdual(12)2.5613.6724.050.363.7914.78modiﬁedSDRdual(21)2.4810.6818.610.362.808.34GDPA2.4610.8118.670.392.838.52SNS1.7210.9219.090.201.487.36liver-disordersplanningsonarhearthabermancolon-cancervotingmonk1WDBCILPDbreast-canceraustraliandiabetespimafourclassgermanmadelonavg.123456difference10-7Figure3:Differencebetweenλmin(H)andλmin(¯H)usingGDPAwithmin-maxdatare-scaling.liver-disordersplanningsonarhabermancolon-cancervotingmonk1WDBCILPDheartbreast-canceraustraliandiabetespimafourclassgermanmadelonavg.123456difference10-7Figure4:Differencebetweenλmin(H)andλmin(¯H)usingGDPAwithstandardizationdatare-scaling.References[Dongetal.(2020)Dong,Wang,Yang,andXue]Dong,M.;Wang,Y.;Yang,X.;andXue,J.2020.LearningLocalMetricsandInﬂuentialRegionsforClassiﬁcation.IEEETPAMI,42(6):1522–1529.[Duerschetal.(2018)Duersch,Shao,Yang,andGu]Duersch,J.A.;Shao,M.;Yang,C.;andGu,M.2018.ARobustandEfﬁcientImplementationofLOBPCG.SIAMJournalonScientiﬁcComputing,40(5):C655–C676.[GuatteryandMiller(1998)]Guattery,S.;andMiller,G.L.1998.OntheQualityofSpectralSeparators.SIAMJour-nalonMatrixAnalysisandApplications,19(3):701–719.[Hausdorff(1957)]Hausdorff,F.1957.SetTheory.ChelseaPublishingCompany.[LamandLiew(2020)]Lam,B.S.;andLiew,A.W.C.2020.AFastBinaryQuadraticProgrammingSolverbasedonStochasticNeighborhoodSearch.IEEETransactionsonPatternAnalysisandMachineIntelligence,1–1.[LibSVM(2021)]LibSVM.2021.LibSVMData:Classiﬁca-tion(BinaryClass).https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html.Accessed:2022-8-15.[RussellandNorvig(2009)]Russell,S.;andNorvig,P.2009.ArtiﬁcialIntelligence:AModernApproach.USA:Pren-ticeHallPress,3rdedition.ISBN0136042597.[UCI(2021)]UCI.2021.UCImachinelearningreposi-tory.https://archive.ics.uci.edu/ml/datasets.php.Accessed:2022-8-15.[Zheng,Fantuzzi,andPapachristodoulou(2019)]Zheng,Y.;Fantuzzi,G.;andPapachristodoulou,A.2019.FastADMMforSum-of-SquaresProgramsUsingPartialOr-thogonality.IEEETransactionsonAutomaticControl,64(9):3869–3876.