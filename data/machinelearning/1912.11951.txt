0
2
0
2

n
u
J

6
2

]

R
C
.
s
c
[

2
v
1
5
9
1
1
.
2
1
9
1
:
v
i
X
r
a

EVA: An Encrypted Vector Arithmetic Language and Compiler for
Efﬁcient Homomorphic Computation

Roshan Dathathri*, Blagovesta Kostova†, Olli Saarikivi‡, Wei Dai‡, Kim Laine‡, and Madanlal Musuvathi‡

*University of Texas at Austin, USA
roshan@cs.utexas.edu
†EPFL, Switzerland
blagovesta.pirelli@epﬂ.ch
‡Microsoft Research, USA
{olsaarik,wei.dai,kilai,madanm}@microsoft.com

Abstract

Fully-Homomorphic Encryption (FHE) offers powerful ca-
pabilities by enabling secure ofﬂoading of both storage and
computation, and recent innovations in schemes and imple-
mentations have made it all the more attractive. At the same
time, FHE is notoriously hard to use with a very constrained
programming model, a very unusual performance proﬁle,
and many cryptographic constraints. Existing compilers for
FHE either target simpler but less efﬁcient FHE schemes or
only support speciﬁc domains where they can rely on expert-
provided high-level runtimes to hide complications.

This paper presents a new FHE language called Encrypted
Vector Arithmetic (EVA), which includes an optimizing com-
piler that generates correct and secure FHE programs, while
hiding all the complexities of the target FHE scheme. Bol-
stered by our optimizing compiler, programmers can develop
efﬁcient general-purpose FHE applications directly in EVA.
For example, we have developed image processing applica-
tions using EVA, with a very few lines of code.

EVA is designed to also work as an intermediate represen-
tation that can be a target for compiling higher-level domain-
speciﬁc languages. To demonstrate this, we have re-targeted
CHET, an existing domain-speciﬁc compiler for neural net-
work inference, onto EVA. Due to the novel optimizations
in EVA, its programs are on average 5.3× faster than those
generated by CHET. We believe that EVA would enable a
wider adoption of FHE by making it easier to develop FHE
applications and domain-speciﬁc FHE compilers.

1. Introduction

Fully-Homomorphic Encryption (FHE) allows arbitrary com-
putations on encrypted data without requiring the decryption
key. Thus, FHE enables interesting privacy-preserving ca-
pabilities, such as ofﬂoading secure storage and secure com-
putation to untrusted cloud providers. Recent advances in
FHE theory [12, 11] along with improved implementations
have pushed FHE into the realm of practicality. For instance,

with appropriate optimization, we can perform encrypted
ﬁxed-point multiplications within a few microseconds, which
matches the speed of 8086 processors that jumpstarted the
computing revolution. Future cryptographic innovations will
further reduce the performance gap between encrypted and
unencrypted computations.

Despite the availability of multiple open-source implementa-
tions [40, 27, 37, 24], programming FHE applications remains
hard and requires cryptographic expertise, making it inaccessi-
ble to most programmers today. Furthermore, different FHE
schemes provide subtly different functionalities and require
manually setting encryption parameters that control correct-
ness, performance, and security. We expect the programming
complexity to only increase as future FHE schemes become
more capable and performant. For instance, the recently in-
vented CKKS scheme [12] supports ﬁxed-point arithmetic op-
erations by representing real numbers as integers with a ﬁxed
scaling factor, but requires the programmer to perform rescal-
ing operations so that scaling factors and the cryptographic
noise do not grow exponentially due to multiplications. More-
over, the so-called RNS-variant of the CKKS scheme [11]
provides efﬁcient implementations that can use machine-sized
integer operations as opposed to multi-precision libraries, but
imposes further restrictions on the circuits that can be evalu-
ated on encrypted data.

To improve the developer friendliness of FHE, this paper
proposes a new general-purpose language for FHE computa-
tion called Encrypted Vector Arithmetic (EVA). EVA is also
designed to be an intermediate representation that is a backend
for other domain-speciﬁc compilers. At its core, EVA supports
arithmetic on ﬁxed-width vectors and scalars. The vector in-
structions naturally match the encrypted SIMD – or batching
– capabilities of FHE schemes today. EVA includes an opti-
mizing compiler that hides all the complexities of the target
FHE scheme, such as encryption parameters and noise. It en-
sures that the generated FHE program is correct, performant,
and secure. In particular, it eliminates all common runtime
exceptions that arise when using FHE libraries.

 
 
 
 
 
 
EVA implements FHE-speciﬁc optimizations, such as opti-
mally inserting operations like rescaling and modulus switch-
ing. We have built a compiler incorporating all these opti-
mizations to generate efﬁcient programs that run using the
Microsoft SEAL [40] FHE library which implements the
RNS-variant of the CKKS scheme. We have built an EVA
executor that transparently parallelizes the generated program
efﬁciently, allowing programs to scale well. The executor also
automatically reuses the memory used for encrypted messages,
thereby reducing the memory consumed.

To demonstrate EVA’s usability, we have built a Python
frontend for it. Using this frontend, we have implemented
several applications in EVA with a very few lines of code and
much less complexity than in SEAL directly. One application
computes the length of a path in 3-dimensional space, which
can be used in secure ﬁtness mobile applications. We have
implemented some statistical machine learning applications.
We have also implemented two image processing applications,
Sobel ﬁlter detection and Harris corner detection. We believe
Harris corner detection is one of the most complex programs
that have been evaluated using CKKS.

In addition, we have built a domain-speciﬁc compiler on top
of EVA for deep neural network (DNN) inference. This com-
piler takes programs written in a higher-level language as input
and generates EVA programs using a library of operations on
higher-level constructs like tensors and images. In particular,
our DNN compiler subsumes the recently proposed domain-
speciﬁc compiler called CHET [17]. Our DNN compiler uses
the same tensor kernels as CHET, except that it generates EVA
programs instead of generating SEAL programs. Nevertheless,
the optimizing compiler in EVA is able to outperform CHET
in DNN inference by 5.3× on average.

In summary, EVA is a general-purpose language and an
intermediate representation that improves the programmability
of FHE applications by guaranteeing correctness and security,
while outperforming current methods.

The rest of this paper is organized as follows. Section 2
gives background on FHE. Section 3 presents the EVA lan-
guage. Section 4 gives an overview of the EVA compiler. We
then describe transformations and analysis in the compiler
in Sections 5 and 6 respectively. Section 7 brieﬂy describes
the domain-speciﬁc compilers we built on top of EVA. Our
evaluation is presented in Section 8. Finally, related work and
conclusions are presented in Sections 9 and 10 respectively.

2. Background and Motivation

In this section, we describe FHE (Section 2.1) and the chal-
lenges in using it (Section 2.2). We also describe an imple-
mentation of FHE (Section 2.3). Finally, we present the threat
model assumed in this paper (Section 2.4).

2.1. Fully-Homomorphic Encryption (FHE)

schemes, for example, BGV [6], BFV [18], and CKKS [12],
are constructed on the Ring Learning with Errors (RLWE)
problem [33]. At the time of key generation, a polynomial
ring of degree N with integer coefﬁcients modulo Q must be
chosen to represent ciphertexts and public keys according to
the security standard [1]. We call Q the ciphertext modulus.
A message is encoded to a polynomial, and subsequently en-
crypted with a public key or a secret key to form a ciphertext
consisting of two polynomials of degree up to N − 1. Encryp-
tion also adds to a ciphertext a small random error that is later
removable in decryption.

FHE schemes are malleable by design. From the perspective
of the user, they offer a way to encrypt integers (or ﬁxed-
point numbers in CKKS — see the next section) such that
certain arithmetic operations can be evaluated on the resulting
ciphertexts. Evaluation primarily includes four operations:
addition of ciphertexts, addition of a ciphertext and a plaintext,
multiplication of ciphertexts, and multiplication of a ciphertext
and a plaintext. Decrypting (with a secret key) and decoding
reveals the message, as if the computation was performed on
unencrypted data.

Many modern FHE schemes also include a SIMD-like fea-
ture known as batching which allows a vector of values to be
encrypted as a single ciphertext (N/2 values in CKKS). With
batching, arithmetic operations happen in an element-wise
fashion. Batching-compatible schemes can evaluate rotations
which allow data movement inside a ciphertext. But evaluating
each rotation step count needs a distinct public key.

2.2. Challenges in Using FHE

Programmers using FHE face signiﬁcant challenges that must
be overcome for correct, efﬁcient, and secure computation.
We discuss those challenges here to motivate our work.

Depth of Computation: Computations on ciphertexts in-
crease the initially small error in them linearly on the number
of homomorphic additions and exponentially on the multiplica-
tive depth of the evaluation circuit. When the errors get too
large, ciphertexts become corrupted and cannot be decrypted,
even with the correct secret key. This bound is in turn deter-
mined by the size of the encryption parameter Q. Thus, to
support efﬁcient homomorphic evaluation of a circuit, one
must optimize the circuit for low depth.

Relinearization: Each ciphertext consists of 2 or more poly-
nomials (freshly encrypted ciphertexts consist of only 2 poly-
nomials). Multiplication of two ciphertexts with k and l poly-
nomials yields a ciphertext with k + l + 1 polynomials. To
prevent the number of polynomials from growing indeﬁnitely,
an operation called relinearization is performed to reduce it
back to 2. Relinearization from each distinct number of poly-
nomials to 2 requires a distinct public key. Relinearization is
costly and their optimal placement is an NP-hard problem [10].

An FHE scheme includes four stages: key generation, encryp-
tion, evaluation, and decryption. Most of the efﬁcient FHE

CKKS and Approximate Fixed-Point: The CKKS [12]
scheme introduced an additional challenge by only providing

2

approximate results (but much higher performance in return).
There are two main sources of error in CKKS: (i) error from
the encoding of values to polynomials being lossy, and (ii)
the noise added in every homomorphic operation being mixed
with the message. To counter this, CKKS adopts a ﬁxed-point
representation by associating each ciphertext with an unen-
crypted scaling factor. Using high enough scaling factors
allows the errors to be hidden.

CKKS further features an operation called rescaling that
scales down the ﬁxed-point representation of a ciphertext.
Consider a ciphertext x that contains the encoding of 0.25
multiplied by the scale 210 (a relatively low scale). x2 encodes
0.0625 multiplied by the scale 220. Further powers would
rapidly overﬂow modest values of the modulus Q, requir-
ing impractically large encryption parameters to be selected.
Rescaling the second power by 210 will truncate the ﬁxed-point
representation to encode the value at a scale of 210.

Rescaling has a secondary effect of also dividing the cipher-
text’s modulus Q by the same divisor as the ciphertext itself.
This means that there is a limited “budget” for rescaling built
into the initial value of Q. The combined effect for CKKS is
that log Q can grow linearly with the multiplicative depth of
the circuit. It is common to talk about the level of a ciphertext
as how much Q is left for rescaling.

A further complication arises from the ciphertext after
rescaling being encrypted under fundamentally different en-
cryption parameters. To apply any binary homomorphic op-
erations, two ciphertexts must be at the same level, i.e., have
the same Q. Furthermore, addition and subtraction require
ciphertexts to be encoded at the same scale due to the proper-
ties of ﬁxed-point arithmetic. CKKS also supports a modulus
switching operation to bring down the level of a ciphertext
without scaling the message. In our experience, inserting the
appropriate rescaling and modulus switching operations to
match levels and scales is a signiﬁcantly difﬁcult process even
for experts in homomorphic encryption.

In the most efﬁcient implementations of CKKS (so called
RNS-variants [11]), the truncation is actually performed by
dividing the encrypted values by prime factors of Q. Fur-
thermore, there is a ﬁxed order to these prime factors, which
means that from a given level (i.e., how many prime factors are
left in Q) there is only one valid divisor available for rescaling.
This complicates selecting points to rescale, as doing so too
early might make the ﬁxed-point representation so small that
the approximation errors destroy the message.

Encryption Parameters:
In CKKS, all of the concerns
about scaling factors, rescaling, and managing levels are intri-
cately linked with selecting encryption parameters. Thus, a
typical workﬂow when developing FHE applications involves
a lot of trial-and-error, and repeatedly tweaking the parame-
ters to achieve both correctness (accuracy) and performance.
While some FHE libraries warn the user if the selected en-
cryption parameters are secure, but not all of them do, so a
developer may need to keep in mind security-related limita-

Table 1: Types of values.

Type

Description

Cipher An encrypted vector of ﬁxed-point values.
Vector
Scalar
Integer A 32-bit signed integer.

A vector of 64-bit ﬂoating point values.
A 64-bit ﬂoating point value.

tions, which typically means upper-bounding Q for a given N.

2.3. Microsoft SEAL

Microsoft SEAL [40] is a software library that implements
the RNS variant of the CKKS scheme. In SEAL, the modulus
Q is a product of several prime factors of bit sizes up to 60
bits, and rescaling of ciphertexts is always done by dividing
away these prime factors. The developer must choose these
prime factors and order them correctly to achieve the desired
rescaling behavior. SEAL automatically validates encryption
parameters for correctness and security.

2.4. Threat Model

We assume a semi-honest threat model, as is typical for homo-
morphic encryption. This means that the party performing the
computation (i.e., the server) is curious about the encrypted
data but is guaranteed to run the desired operations faithfully.
This model matches for example the scenario where the server
is trusted, but a malicious party has read access to the server’s
internal state and/or communication between the server and
the client.

3. EVA Language

The EVA framework uses a single language as its input for-
mat, intermediate representation, and executable format. The
EVA language abstracts batching-compatible FHE schemes
like BFV [18], BGV [6], and CKKS [12, 11], and can be
compiled to target libraries implementing those schemes. In-
put programs use a subset of the language that omits details
speciﬁc to FHE, such as when to rescale. In this section, we
describe the input language and its semantics, while Section 4
presents an overview of the compilation to an executable EVA
program.

Types and Values: Table 1 lists the types that values in EVA
programs may have. The vector types Cipher and Vector
have a ﬁxed power-of-two size for each input program. The
power-of-two requirement comes from the target encryption
schemes.

We introduce some notation for talking about types and
values in EVA. For Vector, a literal value with elements ai is
written [a1, a2, . . . , ai] or as a comprehension [ai for i = 1 . . . i].
For the ith element of Vector a, we write ai. For the product
type (i.e., tuple) of two EVA types A and B, we write A × B,
and write tuple literals as (a, b) where a ∈ A and b ∈ B.

3

Table 2: Instruction opcodes and their semantics (see Section 2 for details on semantics of the restricted instructions).

Opcode

Signature

Description

Restrictions

NEGATE
ADD
SUB
MULTIPLY

Cipher → Cipher
Cipher × (Vector|Cipher) → Cipher Add arguments element-wise.
Cipher × (Vector|Cipher) → Cipher
Subtract right argument from left one element-wise.
Cipher × (Vector|Cipher) → Cipher Multiply arguments element-wise (and multiply

Negate each element of the argument.

ROTATELEFT

Cipher × Integer → Cipher

ROTATERIGHT Cipher × Integer → Cipher

RELINEARIZE
MODSWITCH
RESCALE

Cipher → Cipher
Cipher → Cipher
Cipher × Scalar → Cipher

scales).
Rotate elements to the left by given number of in-
dices.
Rotate elements to the right by given number of
indices.

Apply relinearization.
Switch to the next modulus in the modulus chain.
Rescale the ciphertext (and divide scale) with the
scalar.

Not in input
Not in input
Not in input

Instructions: Programs in EVA are Directed Acyclic
Graphs (DAGs), where each node represents a value available
during execution. Example programs are shown in Figures 2(a)
and 3(a). Nodes with one or more incoming edges are called
instructions, which compute a new value as a function of its
parameter nodes, i.e., the parent nodes connected to it. For
the ith parameter of an instruction n, we write n.parmi and the
whole list of parameter nodes is n.parms. Each instruction n
has an opcode n.op, which speciﬁes the operation to be per-
formed at the node. Note that the incoming edges are ordered,
as it corresponds to the list of arguments. Table 2 lists all the
opcodes available in EVA. The ﬁrst group are opcodes that
frontends may generate, while the second group lists FHE-
speciﬁc opcodes that are inserted by the compiler. The key to
the expressiveness of the input language are the ROTATELEFT
and ROTATERIGHT instructions, which abstract rotation (cir-
cular shift) in batching-compatible FHE schemes.

Inputs: A node with no incoming edges is called a constant
if its value is available at compile time and an input if its
value is only available at run time. For a constant n, we write
n.value to denote the value. Inputs may be of any type, while
constants can be any type except Cipher. This difference
is due to the fact that the Cipher type is not fully deﬁned
before key generation time, and thus cannot have any values
at compile time. The type is accessible as n.type.

Program: A program P is a tuple (M, Insts, Consts, Inputs,
Outputs), where M is the length of all vector types in P; Insts,
Consts and Inputs are list of all instruction, constant, and input
nodes, respectively; and Outputs identiﬁes a list of instruction
nodes as outputs of the program.

Execution Semantics: Next, we deﬁne execution semantics
for EVA. Consider a dummy encryption scheme id that instead
of encrypting Cipher values just stores them as Vector values.
In other words, the encryption and decryption are the identity
function. This scheme makes homomorphic computation very

easy, as every plaintext operation is its own homomorphic
counterpart. Given a map I : Inputs → Vector, let Eid(n) be
the function that computes the value for node n recursively by
using n.value or I(n) if n is a constant or input respectively
and using n.op and Eid() on n.parms otherwise. Now for
a program P, we further deﬁne its reference semantic as a
function Pid, which given a value for each input node maps
each output node in P to its resulting value:

Pid : ×ni∈Inputsni.type → ×no∈OutputsVector

Pid(I(n1

i ), . . . , I(n|Inputs|

)) = (Eid(n1

o), . . . , Eid(n|Outputs|

o

))

i

These execution semantics hold for any encryption scheme,
except that output is also encrypted (i.e., Cipher type).

Discussion on Rotation and Vector Sizes: The EVA lan-
guage restricts the size for any Cipher or Vector input to
be a power-of-2 so as to support execution semantics of
ROTATELEFT and ROTATERIGHT instructions.

The target encryption schemes use the same vector size
se (= N/2) for all Cipher values during execution. How-
ever, the vector size si for an input could be different from
se. Nevertheless, the target encryption scheme and the EVA
language enforce the vector sizes se and si, respectively, to
be powers-of-2. EVA chooses encryption parameters for the
target encryption scheme such that for all inputs i, si ≤ se (be-
cause N can be increased trivially without hurting correctness
or security — note that increasing N will hurt performance).
For a Cipher or Vector input i such that si < se, EVA con-
structs a vector (before encryption for Cipher) i(cid:48) with se/si
copies of the vector i contiguously such that s(cid:48)
i = se, and re-
places i with i(cid:48) in the program. For example, if an input
a = [a1, a2] and se = 4, then EVA constructs a(cid:48) = [a1, a2, a1, a2]
and replaces a with a(cid:48). ROTATERIGHT or ROTATERIGHT in-
struction on the original vector i and the constructed larger
vector i(cid:48) have the same result on their ﬁrst si elements. This is

4

1 syntax = ‘‘proto3’’;

2
3 package EVA;

4
5 enum OpCode {

UNDEFINED_OP = 0;
NEGATE = 1;
ADD = 2;
SUB = 3;
MULTIPLY = 4;
SUM = 5;
COPY = 6;
ROTATE_LEFT = 7;
ROTATE_RIGHT = 8;
RELINEARIZE = 9;
MOD_SWITCH = 10;
RESCALE = 11;
NORMALIZE_SCALE = 12;

6

7

8

9

10

11

12

13

14

15

16

17

18
19 }

20
21 enum ObjectType {

UNDEFINED_TYPE = 0;
SCALAR_CONST = 1;
SCALAR_PLAIN = 2;
SCALAR_CIPHER = 3;
VECTOR_CONST = 4;
VECTOR_PLAIN = 5;
VECTOR_CIPHER = 6;

22

23

24

25

26

27

28
29 }

30
31 message Object {
uint64 id = 1;

32
33 }

34
35 message Instruction {

Object output = 1;
OpCode op_code = 2;
repeated Object args = 3;

36

37

38
39 }

40
41 message Vector {

repeated double elements = 1;

42
43 }

44
45 message Input {

Object obj = 1;
ObjectType type = 2;
double scale = 3;

46

47

48
49 }

50
51 message Constant {

Object obj = 1;
ObjectType type = 2;
double scale = 3;
Vector vec = 4;

52

53

54

55
56 }

57
58 message Output {

Object obj = 1;
double scale = 2;

59

60
61 }

62
63 message Program {

uint64 vec_size = 1;
repeated Constant constants = 2;
repeated Input inputs = 3;
repeated Output outputs = 4;
repeated Instruction insts = 5;

64

65

66

67

68
69 }

Figure 1: The EVA language deﬁnition using Protocol Buffers.

feasible because si divides se. EVA thus ensures that the exe-
cution semantics of the EVA program holds for any encryption
scheme.

Implementation: As shown in Figure 1, the EVA language
has a serialized format deﬁned using Protocol Buffers [22], a
language and platform neutral data serialization format. Addi-
tionally, the EVA language has an in-memory graph represen-
tation that is designed for efﬁcient analysis and transformation,
which is discussed in Section 4.

4. Overview of EVA Compiler

In this section, we describe how to use the EVA compiler
(Section 4.1). We then describe the constraints on the code
generated by EVA (Section 4.2). Finally, we give an overview
of the execution ﬂow of the EVA compiler (Section 4.3).

4.1. Using the Compiler

In this paper, we present the EVA compiler for the RNS
variant of the CKKS scheme [11] and its implementation

in the SEAL library [40]. Targeting EVA for other FHE li-
braries [27, 24, 37] implementing CKKS [12, 11] would be
straightforward. The EVA compiler can also be adapted to sup-
port other batching-compatible FHE schemes like BFV [18]
and BGV [6].

The EVA compiler takes a program in the EVA language as
input. Along with the program, it needs the ﬁxed-point scales
or precisions for each input in the program and the desired
ﬁxed-point scales or precisions for each output in the program.
The compiler then generates a program in the EVA language
as output. In addition, it generates a vector of bit sizes that
must be used to generate the encryption parameters as well as
a set of rotation steps that must be used to generate the rotation
keys. The encryption parameters and the rotations keys thus
generated are required to execute the generated EVA program.

While the input and the output programs are in the EVA
language, the set of instructions allowed in the input and the
output are distinct, as listed in Table 2. The RELINEARIZE,
RESCALE, and MODSWITCH instructions require understand-
ing the intricate details of the FHE scheme. Hence, they are

5

Figure 2: x2y3 example in EVA: (a) input; (b) after ALWAYS-RESCALE; (c) after ALWAYS-RESCALE & MODSWITCH; (d) after
WATERLINE-RESCALE; (e) after WATERLINE-RESCALE & RELINEARIZE (S: RESCALE, M: MODSWITCH, L: RELINEARIZE).

omitted from the input program. Note that we can make these
instructions optional in the input and the compiler can handle
it if they are present, but for the sake of exposition, we assume
that the input does not have these instructions.

The input scales and the desired output scales affect the
encryption parameters, and consequently, the performance
and accuracy of the generated program. Choosing the right
values for these is a trade-off between performance and ac-
curacy (while providing the same security). Larger values
lead to larger encryption parameters and more accurate but
slower generated program, whereas smaller values lead to
smaller encryption parameters and less accurate but faster gen-
erated program. Proﬁling techniques like those used in prior
work [17] can be used to select the appropriate values.

4.2. Motivation and Constraints

There is a one-to-one mapping between instructions in the
EVA language (Table 2) and instructions in the RNS-CKKS
scheme. However, the input program cannot be directly exe-
cuted. Firstly, encryption parameters are required to ensure
that the program would be accurate. EVA can simply deter-
mine the bit sizes that is required to generate the parameters.
However, this is insufﬁcient to execute the program correctly
because some instructions in the RNS-CKKS scheme have
restrictions on their inputs. If these restrictions are not met,
the instructions would just throw an exception at runtime.

Each ciphertext in the RNS-CKKS scheme has a coefﬁcient
modulus q (Q = ∏r
i=1 qi)1 and a ﬁxed-point scale associated
with it. All freshly encrypted ciphertexts have the same q but
they may have different scale. The following constraints apply

1In SEAL, if the coefﬁcient modulus q is {q1, q2, ..., qr}, then qi is a prime
close to a power-of-2. EVA compiler (and the rest of this paper) assumes qi is
the corresponding power-of-2 instead. To resolve this discrepancy, when a
RESCALE instruction divides the scale by the prime, the scale is adjusted (by
the EVA executor) as if it was divided by the power-of-2 instead.

for the binary instructions involving two ciphertexts:

n.parm1.modulus = n.parm2.modulus
if n.op ∈ {ADD, SUB, MULTIPLY}

n.parm1.scale = n.parm2.scale
if n.op ∈ {ADD, SUB}

(1)

(2)

In the rest of this paper, whenever we mention ADD regarding
constraints, it includes both ADD and SUB.

Consider the example to compute x2y3 for ciphertexts x and
y in Figure 2 (viewed as a dataﬂow graph). Constraint 2 is triv-
ially satisﬁed because they are no ADD instructions. Only
RESCALE and MODSWITCH instructions modify q. Con-
straint 1 is also trivially satisﬁed due to the absence of these
instructions. Nonetheless, without the use of RESCALE in-
structions, the scales and the noise of the ciphertexts would
grow exponentially with the multiplicative depth of the pro-
gram (i.e., maximum number of MULTIPLY nodes in any path)
and consequently, the log2 of the coefﬁcient modulus product
Q required for the input would grow exponentially. Instead,
using RESCALE instructions ensures that log2 Q would only
grow linearly with the multiplicative depth of the program.

In Figure 2, the output has a scale of 260 ∗260 ∗230 ∗230 ∗230
(with x.scale = 260 and y.scale = 230). This would require
Q to be at least 2210 ∗ so, where so is the user-provided de-
sired output scale. To try to reduce this, one can insert
RESCALE after every MULTIPLY, as shown in Figure 2(b).
However, this yields an invalid program because it violates
Constraint 1 for the last (bottom) MULTIPLY (and there is
no way to choose the same q for both x and y). To satisfy
this constraint, MODSWITCH instructions can be inserted, as
shown in Figure 2(c). Both RESCALE and MODSWITCH drop
the ﬁrst element in their input q (or consume the modulus),
whereas RESCALE also divides the scale by the given scalar
(which is required to match the ﬁrst element in q). The output

6

Algorithm 1: Execution of EVA compiler.

:Program Pi in EVA language
:Scales Si for inputs in Pi
:Desired scales Sd for outputs in Pi

Input
Input
Input
Output :Program Po in EVA language
Output :Vector Bv of bit sizes
Output :Set Rs of rotation steps

1 Po = Transform(Pi, Si)
2 if Validate(Po) == Failed then
Throw an exception
3
4 Bv = DetermineParameters(Po, Si, Sd )
5 Rs = DetermineRotationSteps(Pi, Si)

In the SEAL library, s f = 260 (which enables a performant
implementation by limiting scales to machine-sized integers).
To summarize, FHE schemes (or libraries) are tedious for
a programmer to reason about, due to all their cryptographic
constraints. Programmers ﬁnd it even more tricky to satisfy
the constraints in a way that optimizes performance. The EVA
compiler hides such cryptographic details from the program-
mer while optimizing the program.

4.3. Execution Flow of the Compiler

As mentioned in Section 3, the in-memory internal represen-
tation of the EVA compiler is an Abstract Semantic Graph,
also known as a Term Graph, of the input program. In the
rest of this paper, we will use the term graph to denote an
Abstract Semantic Graph. In this in-memory representation,
each node can access both its parents and its children, and
for each output, a distinct leaf node is added as a child. It
is straightforward to construct the graph from the EVA pro-
gram and vice-versa, so we omit the details. We use the terms
program and graph interchangeably in the rest of the paper.

Algorithm 1 presents the execution ﬂow of the compiler.
There are four main steps, namely transformation, validation,
parameters selection, and rotations selection. The transfor-
mation step takes the input program and modiﬁes it to satisfy
the constraints of all instructions, while optimizing it. In the
next step, the transformed program is validated to ensure that
no constraints are violated. If any constraints are violated,
then the compiler throws an exception. By doing this, EVA
ensures that executing the output program will never lead
to a runtime exception thrown by the FHE library. Finally,
for the validated output program, the compiler selects the bit
sizes and the rotation steps that must be used to determine
the encryption parameters and the public keys required for
rotations respectively, before executing the output program.
The transformation step involves rewriting the graph, which is
described in detail in Section 5. The other steps only involve
traversal of the graph (without changing it), which is described
in Section 6.

5. Transformations in EVA Compiler

Figure 3: x2 + x example in EVA: (a) input; (b) after ALWAYS-
RESCALE & MODSWITCH; (c) after MATCH-SCALE.

now has a scale of 260 ∗ 230. This would require choosing
q = {230, 230, 260, 260, 230, so}. Thus, although Figure 2(c) ex-
ecutes more instructions than Figure 2(a), it requires the same
Q. A better way to insert RESCALE instructions is shown in
Figure 2(d). This satisﬁes Constraint 1 without MODSWITCH
instructions. The output now has a scale of 260 ∗ 230. We can
choose q = {260, 260, 230, so}, so Q = 2150 ∗ so. Hence, this
program is more efﬁcient than the input program.

If the computation was modiﬁed to x2 + y3 in Figure 2(d),
then the last (bottom) MULTIPLY would be replaced by ADD
and the program would violate Constraint 2 as ADD would
have operands with scales 260 and 230. Consider a simi-
lar but simpler example of x2 + x in Figure 3(a). One way
to satisfy Constraints 1 and 2 is by adding RESCALE and
MODSWITCH, as shown in Figure 3(b), which would require
q = {230, 230, so}. Another way is to introduce MULTIPLY
of x and a constant 1 with 230 scale to match the scale of
ADD operands, as shown in Figure 3(c), which would require
q = {260, so}. Although the product Q = 260 ∗ so is same in
both cases, the modulus length r is different. Hence, the pro-
gram in Figure 3(c) is more efﬁcient due to a smaller r.

MULTIPLY has another constraint. Each ciphertext consists
of 2 or more polynomials. MULTIPLY of two ciphertexts
with k and l polynomials yields a ciphertext with k + l + 1
polynomials. Nevertheless, fewer the polynomials faster the
MULTIPLY, so we enforce it to be the minimum:

∀i n.parmi.num_polynomials = 2
if n.op ∈ {MULTIPLY}

(3)

RELINEARIZE reduces the number of polynomials in a cipher-
text to 2. This constraint guarantees that any relinearization
in the program would reduce the number of polynomials in
a ciphertext from 3 to 2, thereby ensuring that only one pub-
lic key is sufﬁcient for all relinearizations in the program.
RELINEARIZE can be inserted in the program in Figure 2(d)
to satisfy this constraint, as shown in Figure 2(e).

Finally, we use s f to denote the maximum allowed rescale
value in the rest of this paper (log2 s f is also the maximum bit
size that can be used for encryption parameters), i.e.,

n.parm2.value ≤ s f
if n.op ∈ {RESCALE}

(4)

In this section, we describe the key graph transformations in
the EVA compiler. We ﬁrst describe a general graph rewrit-

7

ALWAYS − RESCALE

n ∈ Insts

n.op = MULTIPLY

Nck = {(nc, k) | nc.parmk = n}

Insts ← Insts ∪ {ns}

ns.op ← RESCALE

ns.parm1 ← n

ns.parm2 ← min(∀ j, n.parmj.scale)

∀(nc, k) ∈ Nck, nc.parmk ← ns

WATERLINE − RESCALE

n ∈ Insts

n.op = MULTIPLY

Nck = {(nc, k) | nc.parmk = n}

(n.parm1.scale ∗ n.parm2.scale)/s f ≥ max(∀n j ∈ {Consts, Inputs}, n j.scale)

Insts ← Insts ∪ {ns}

ns.op ← RESCALE
∀(nc, k) ∈ Nck, nc.parmk ← ns

ns.parm1 ← n

ns.parm2 ← s f

LAZY − MODSWITCH

n ∈ Insts
Insts ← Insts ∪ {nm}

n.op ∈ {ADD, SUB, MULTIPLY}
nm.op ← MODSWITCH

n.parmi.level > n.parmj.level

nm.parm1 ← n.parmj

n.parmj ← nm

EAGER − MODSWITCH

c.parmi.rlevel > n2
n1
Insts ← Insts ∪ {nm}

n ∈ {Insts, Consts, Inputs}

n1
c.parmi = n

n2
c.parmj = n

c.parmj.rlevel

Nck = {(nc, k) | nc.parmk = n ∧ nc.parmk.rlevel = n2

nm.op ← MODSWITCH

nm.parm1 ← n

c.parmj.rlevel}
∀(nc, k) ∈ Nck, nc.parmk ← nm

MATCH − SCALE

n ∈ Insts

Insts ← Insts ∪ {nt }

n.op ∈ {ADD, SUB}
Consts ← Consts ∪ {nc}

n.parmi.scale > n.parmj.scale

nc.value ← n.parmi.scale/n.parmj.scale

nt .op ← MULTIPLY

nt .parm1 ← n.parmj

nt .parm2 ← nc

n.parmj ← nt

RELINEARIZE

n ∈ Insts

n.op = MULTIPLY

n.parm1.type = n.parm2.type = Cipher

Nck = {(nc, k) | nc.parmk = n}

Insts ← Insts ∪ {nl}

nl.op ← RELINEARIZE

nl.parm1 ← n

∀(nc, k) ∈ Nck, nc.parmk ← nl

Figure 4: Graph rewriting rules (each rule is a transformation pass) in EVA (s f : maximum allowed rescale value).

ing framework (Section 5.1). Then, we describe the graph
transformation passes (Sections 5.2 and 5.3).

5.1. Graph Rewriting Framework

A graph transformation can be captured succinctly using graph
rewrite rules (or term rewrite rules). These rules specify the
conditional transformation of a subgraph (or an expression)
and the graph transformation consists of transforming all ap-
plicable subgraphs (or expressions) in the graph (or program).
The graph nodes have read-only properties like the opcode and
number of parents. In a graph transformation, some state or
data may be stored on each node in the graph and the rewrite
rules may read and update the state.

The rewrite rules specify local operations on a graph and
the graph transformation itself is composed of applying these
operations wherever needed. The schedule in which these
local operations are applied may impact the correctness or
efﬁciency of the transformation. Consider two schedules:
1. Forward pass from roots to leaves of the graph: a node
is scheduled for rewriting only after all its parents have
already been rewritten.

2. Backward pass from leaves to roots of the graph: a node
is scheduled for rewriting only after all its children have
already been rewritten.

Note that the rewriting operation may not do any modiﬁcations
if its condition does not hold. In forward pass, state (or data)
ﬂows from parents to children. Similarly, in backward pass,
state (or data) ﬂows from children to parents.
In general,
multiple forward or backward passes may be needed to apply
the rewrite rules until quiescence (no change).

EVA includes a graph rewriting framework for arbitrary
rewrite rules for a subgraph that consists of a node along
with its parents or children. The rewrite rules for each graph
transformation pass in EVA are deﬁned in Figure 4. A sin-
gle backward pass is sufﬁcient for EAGER-MODSWITCH,
while a single forward pass is sufﬁcient for the rest. The
rewrite rules assume the passes are applied in a speciﬁc
order: WATERLINE-RESCALE, EAGER-MODSWITCH,
MATCH-SCALE, and RELINEARIZE (ALWAYS-RESCALE
and LAZY-MODSWITCH are not used but deﬁned only for
clarity). For the sake of exposition, we will ﬁrst describe
RELINEARIZE pass before describing the other passes.

5.2. Relinearize Insertion Pass

Each ciphertext is represented as 2 or more polynomials. Mul-
tiplying two ciphertexts each with 2 polynomials yields a
ciphertext with 3 polynomials. The RELINEARIZE instruction
reduces a ciphertext to 2 polynomials. To satisfy Constraint 3,
EVA must insert RELINEARIZE after MULTIPLY of two nodes
with Cipher type and before another such MULTIPLY.

The RELINEARIZE rewrite rule (Figure 4) is applied for
a node n only if it is a MULTIPLY operation and if both its
parents (or parameters) have Cipher type. The transformation
in the rule inserts a RELINEARIZE node nl between the node
n and its children. In other words, the new children of n will
be only nl and the children of nl will be the old children of n.
For the example graph in Figure 2(d), applying this rewrite
rule transforms the graph into the one in Figure 2(e).

Optimal placement of relinearization is an NP-hard prob-
lem [10]. Our relinearization insertion pass is a simple way to

8

enforce Constraint 3. More advanced relinearization insertion,
with or without Constraint 3, is left for future work.

5.3. Rescale and ModSwitch Insertion Passes

Goal: The RESCALE and MODSWITCH nodes (or instruc-
tions) must be inserted such that they satisfy Constraint 1, so
the goal of the RESCALE and MODSWITCH insertion passes
is to insert them such that the coefﬁcient moduli of the parents
of any ADD and MULTIPLY node are equal.

While satisfying Constraint 1 is sufﬁcient for correctness,
performance depends on where RESCALE and MODSWITCH
are inserted (as illustrated in Section 4.2). Different choices
lead to different coefﬁcient modulus q = {q1, q2, ..., qr}, and
consequently, different polynomial modulus N for the roots
(or inputs) to the graph (or program). Larger values of N
and r increase the cost of every FHE operation and the mem-
ory of every ciphertext. N is a non-decreasing function of
Q = ∏r
i=1 qi (i.e., if Q grows, N either remains the same or
grows as well). Minimizing both Q and r is a hard problem to
solve. However, reducing Q is only impactful if it reduces N,
which is unlikely as the threshold of Q, for which N increases,
grows exponentially. Therefore, the goal of EVA is to yield the
optimal r, which may or may not yield the optimal N.

Constrained-Optimization Problem: The only nodes that
modify a ciphertext’s coefﬁcient modulus are RESCALE and
MODSWITCH nodes; that is, they are the only ones whose
output ciphertext has a different coefﬁcient modulus than that
of their input ciphertext(s). Therefore, the coefﬁcient modulus
of the output of a node depends only on the RESCALE and
MODSWITCH nodes in the path from the root to that node. To
illustrate their relation, we deﬁne the term rescale chain.

Deﬁnition 1 Given a directed acyclic graph G = (V, E):
For n1, n2 ∈ V , n1 is a parent of n2 if ∃(n1, n2) ∈ E.
A node r ∈ V is a root if r.type = Cipher and (cid:64)n ∈ V s.t. n

is a parent of r.

Deﬁnition 2 Given a directed acyclic graph G = (V, E):

A path p from a node n0 ∈ V to a node n ∈ V is a sequence
of nodes p0, ..., pl s.t. p0 = n0, pl = n, and ∀0 ≤ i < l, pi ∈ V
and pi is a parent of pi+1. A path p is said to be simple if
∀0 < i < l, pi.op (cid:54)= RESCALE and pi.op (cid:54)= MODSWITCH.

Deﬁnition 3 Given a directed acyclic graph G = (V, E):

A rescale path p to a node n ∈ V is a sequence of nodes
p0, ..., pl s.t. (∀0 ≤ i ≤ l, pi.op ∈ {RESCALE, MODSWITCH}),
∃ a simple path from a root to p0, ∃ a simple path from pl to
n, (∀0 ≤ i < l, ∃ a simple path from pi to pi+1), and (n.op =
RESCALE or n.op = MODSWITCH) =⇒ (pl = n) .

A rescale chain of a node n ∈ V is a vector c s.t. ∃ a rescale
path p to n and (∀0 ≤ i < |p|, (pi.op = MODSWITCH =⇒
ci = ∞) and (pi.op = RESCALE =⇒ ci = pi.parm2.value)).
Note that ∞ is used here to distinguish MODSWITCH from
RESCALE in the rescale chain.

9

if (|c| = |c(cid:48)| and (∀0 ≤ i < |c|, ci = c(cid:48)

A rescale chain c of a node n and c(cid:48) of a node n(cid:48) are equal
i = ∞)).
A rescale chain c of a node n ∈ V is conforming if ∀ rescale

i or ci = ∞ or c(cid:48)

chain c(cid:48) of n, c is equal to c(cid:48).

Note that all the roots in the graph have the same coefﬁcient
modulus. Therefore, for nodes n1 and n2, the coefﬁcient mod-
ulus of the output of n1 is equal to that of n2 if and only if
there exists conforming rescale chains for n1 and n2, and the
conforming rescale chain of n1 is equal to that of n2. Thus, we
need to solve two problems simultaneously:
• Constraints: Ensure the conforming rescale chains of the

parents of any MULTIPLY or ADD node are equal.

• Optimization: Minimize the length of the rescale chain of

every node.

In general, the constraints problem can be solved

Outline:
in two steps:
• Insert RESCALE in a pass (to reduce exponential growth of

scale and noise).

• Insert MODSWITCH in another pass so that the constraints

are satisﬁed.

The challenge is in solving this problem in this way, while
yielding the desired optimization.

Always Rescale Insertion: A naive approach of inserting
RESCALE is to insert it after every MULTIPLY of Cipher
nodes. We call this approach as always rescale and deﬁne
it in the ALWAY-RESCALE rewrite rule in Figure 4. Consider
the example in Figure 2(a). Applying this rewrite rule on this
example yields the graph in Figure 2(b). For some MULTIPLY
nodes (e.g., the bottom one), the conforming rescale chains
of their parents do not exist or do not match. To satisfy these
constraints, MODSWITCH nodes can be inserted appropriately,
as shown in Figure 2(c) (we omit deﬁning this rule because
it would require multiple forward passes). The conforming
rescale chain length for the output is now more more than the
multiplicative depth of the graph. Thus, always rescale and
its corresponding modswitch insertion may lead to a larger
coefﬁcient modulus (both in the number of elements and their
product) than not inserting any of them.

Insight: Consider that all the roots in the graph have the
same scale s. For example in Figure 2(a), let x.scale = 230
instead of 260. Then, after always rescale (replace 260 with
230 in Figure 2(b)), the only difference between the rescale
chains of a node n would be their length and not the values in
it. This is the case even when roots may have different scales
as long as all RESCALE nodes rescale by the same value s.
Then, a conforming rescale chain cn for n can be obtained by
adding MODSWITCH nodes in the smaller chain(s). Thus, |cn|
would not be greater than the multiplicative depth of n. The
ﬁrst key insight of EVA is that using the same rescale value
for all RESCALE nodes ensures that |co| cannot be greater
than the multiplicative depth of o (a tight upper bound). The
multiplicative depth of a node n is not a tight lower bound

or more efﬁcient code than lazy insertion.

Matching Scales: As illustrated in Section 4.2, it is easy
to match scales of parents of ADD by multiplying one of
the parents and 1 with the appropriate scale. The MATCH-
SCALE rewrite rule (Figure 4) takes this simple approach
to satisfy Constraint 2 while avoiding introduction of any
additional RESCALE or MODSWITCH. For the example graph
in Figure 3(a), applying this rewrite rule transforms the graph
into the one in Figure 3(c).

s f

Optimality: EVA selects encryption parameters (see Sec-
tion 6.2) s.t. r = max(∀o ∈ {Out puts}, 1 + |co| + (cid:100) o.scale∗so
(cid:101)),
where so is the desired scale for the output o. WATERLINE-
RESCALE is the only pass that determines |co| and o.scale
for any output o (neither LAZY-MODSWITCH nor MATCH-
SCALE modify that). If |co| is decreased by 1 (an element
s f from co is removed), then o.scale would increase by at
least s f , so it would not decrease r. Due to waterline rescale,
o.scale < sw ∗ s f , so RESCALE cannot be inserted to reduce
o.scale by at least s f (because the minimum required scale is
sw). Thus, EVA yields the minimal or optimal r.

6. Analysis in EVA Compiler

In this section, we brieﬂy describe our graph traversal frame-
work (Section 6.1) and a few analysis passes (Section 6.2).

6.1. Graph Traversal Framework and Executor

EVA’s graph traversal framework allows either a forward
traversal or a backward traversal of the graph.
In the for-
ward traversal pass, a node is visited only after all its parents
are visited. Similarly, in the backward traversal pass, a node
is visited only after all its children are visited. Graph traver-
sals do not modify the structure of the graph (unlike graph
rewriting) but a state on each node can be maintained during
the traversal. A single pass is sufﬁcient to perform forward or
backward data-ﬂow analysis of the graph because the graph is
acyclic. Execution of the graph is a forward traversal of the
graph, so uses the same framework.

Parallel Implementation: We implement an executor for
the generated EVA program using the traversal framework.
A node is said to be ready or active if all its parents (or chil-
dren) in forward (or backward) pass have already been visited.
These active nodes can be scheduled to execute in parallel as
each active node only updates its own state (i.e., there are no
conﬂicts). For example in Figure 2(e), the parents of the bot-
tom MULTIPLY can execute in parallel. Each FHE instruction
(node) can take a signiﬁcant amount of time to execute, so it
is useful to exploit parallelism among FHE instructions. The
EVA executor automatically parallelizes the generated EVA
program by implementing a parallel graph traversal using the
Galois [36, 19] parallel library.

A node is said to retire if all its children (or parents) in
forward (or backward) pass have already been visited. The

Figure 5: x2 + x + x in EVA: (a) after WATERLINE-RESCALE
(b) after WATERLINE-RESCALE & LAZY-MODSWITCH; (c) after
WATERLINE-RESCALE & EAGER-MODSWITCH.

for |cn|, as shown in Figure 2(d). The second key insight of
EVA is that using the maximum rescale value s f (satisfying
Constraint 4) for all RESCALE nodes minimizes |co| because
it minimizes the number of RESCALE nodes in any path.

Waterline Rescale Insertion: Based on our insights, the
value to rescale is ﬁxed to s f (= 260 in SEAL). That does not
address the question of when to insert RESCALE nodes. If the
scale after RESCALE becomes too small, then the computed
message may lose accuracy irrevocably. We call the minimum
required scale as waterline and use sw to denote it. We choose
sw to be maximum of the scales of all roots. Consider a
MULTIPLY node n whose scale after multiplication is sn. Then,
a RESCALE in inserted between n and its children only if the
scale after RESCALE is above the waterline, i.e., (sn/s f ) ≥ sw.
We call this approach as waterline rescale and deﬁne the
WATERLINE-RESCALE rewrite rule in Figure 4. This rule
(assuming sw = 230 instead of 260) transforms the graph in
Figure 2(a) to the one in Figure 2(d).

ModSwitch Insertion: For a node n, let n.level denote its
conforming rescale chain length. Let n.rlevel denote the con-
forming rescale chain length of n in the transpose graph.
A naive way to insert MODSWITCH is to ﬁnd a ADD or
MULTIPLY node for which level of the parents do not match
and insert the appropriate number of MODSWITCH nodes be-
tween one of the parents and the node. We call this lazy
insertion and deﬁne the LAZY-MODSWITCH rewrite rule
in Figure 4. We call inserting it at the earliest feasible edge
in the graph as eager insertion. The EAGER-MODSWITCH
rewrite rule (Figure 4) ﬁnds a node for which rlevel of the
children do not match and inserts the appropriate number of
MODSWITCH nodes between some of the children and itself.
If the rlevel of the roots do not match, then there is another
rule (omitted in Figure 4 for brevity) that inserts the appropri-
ate MODSWITCH nodes between some of the roots and their
children.

Consider the x2 +x+x example in Figure 5(a). Applying the
LAZY-MODSWITCH and EAGER-MODSWITCH rewrite
rules yields the graphs in Figures 5(b) and (c) respectively. The
operands of ADD after eager insertion use a smaller coefﬁcient
modulus than after lazy insertion, so ADD would be faster if
eager insertion is used. Thus, eager insertion leads to similar

10

state for the retired nodes will no longer be accessed, so it can
be reused for other nodes. In Figure 2(e), the ciphertext for x2
can be reused after the RELINEARIZE is executed. The EVA
executor automatically reuses the memory used for encrypted
messages, thereby reducing the memory consumed.

6.2. Analysis Passes

Validation Passes: We implement a validation pass for each
of the constraints in Section 4.2. All are forward passes. The
ﬁrst pass computes the rescale chains for each node and asserts
that it is conforming. It also asserts that the conforming rescale
chains of parents of ADD and MULTIPLY match, satisfying
Constraint 1. The second and third passes compute a scale and
num_polynomials for each node respectively and assert that
Constraint 2 and 3 is satisﬁed respectively. If any assertion
fails, an exception in thrown at compile-time. Thus, these
passes elide runtime exceptions thrown by SEAL.

Encryption Parameter Selection Pass: Akin to encryption
selection in CHET [17], the encryption parameter selection
pass in EVA computes the conforming rescale chain and the
scale for each node. For each leaf or output o after the pass,
let co be the conforming rescale chains of o without ∞ in it
and let s(cid:48)
o = so ∗ o.scale, where so is the desired output scale.
s(cid:48)
o is factorized into s0 ∗ s1 ∗ ... ∗ sk such that sk is a power-of-
two, sk ≤ s f (= 260 in SEAL), and ∀0 ≤ i < k, si = s f . Let
o| denote the number of factors of s(cid:48)
|s(cid:48)
o. Then EVA ﬁnds the
output m with the maximum |cm| + |s(cid:48)
m|. The factors of sm are
appended to cm and s f (the special prime that is consumed
during encryption) is inserted at the beginning of cm. For each
element s in cm, log2 s is applied to obtain a vector of bit sizes,
which is then returned.

Rotation Keys Selection Pass: Similar to rotation keys se-
lection in CHET [17], EVA’s rotation keys selection pass com-
putes and returns the set of unique step counts used among all
ROTATELEFT and ROTATERIGHT nodes in the graph.

7. Frontends of EVA

The various transformations described so far for compiling an
input EVA program into an executable EVA program make up
the backend in the EVA compiler framework. In this section,
we describe two frontends for EVA, that make it easy to write
programs for EVA.

7.1. PyEVA

We have built a general-purpose frontend for EVA as a DSL
embedded into Python, called PyEVA. Consider the PyEVA
program in Figure 6 for Sobel ﬁltering, which is a form of
edge detection in image processing. The class Program is a
wrapper for the Protocol Buffer [22] format for EVA programs
shown in Figure 1. It includes a context manager, such that
inside a with program: block all operations are recorded in
program. For example, the inputEncrypted function inserts
an input node of type Cipher into the program currently in

1 from EVA import *
2 def sqrt(x):

3

return x*constant(scale, 2.214) +

4

(x**2)*constant(scale, -1.098) +
(x**3)*constant(scale, 0.173)
5
6 program = Program(vec_size=64*64)
7 scale = 30
8 with program:

9

10

11

12

13

14

15

16

17

18

19

20

21

22

image = inputEncrypted(scale)
F = [[-1, 0, 1],

[-2, 0, 2],
[-1, 0, 1]]

for i in range(3):

for j in range(3):

rot = image << (i*64+j)
h = rot * constant(scale, F[i][j])
v = rot * constant(scale, F[j][i])
first = i == 0 and j == 0
Ix = h if first else Ix + h
Iy = v if first else Iy + v

d = sqrt(Ix**2 + Iy**2)
output(d, scale)

Figure 6: PyEVA program for Sobel ﬁltering 64 × 64 images.
The sqrt function evaluates a 3rd degree polynomial approxi-
mation of square root.

context and additionally returns an instance of class Expr,
which stores a reference to the input node. The expression
additionally overrides Python operators to provide the simple
syntax seen here.

7.2. EVA for Neural Network Inference

CHET [17] is a compiler for evaluating neural networks on
encrypted inputs. The CHET compiler receives a neural net-
work as a graph of high-level tensor operations, and through
its kernel implementations, analyzes and executes these neural
networks against FHE libraries. CHET lacks a proper backend
and operates more as an interpreter coupled with automatically
chosen high-level execution strategies.

We have obtained the CHET source code and modiﬁed it to
use the EVA compiler as a backend. CHET uses an interface
called Homomorphic Instruction Set Architecture (HISA) as
a common abstraction for different FHE libraries. In order
to make CHET generate EVA programs, we introduce a new
HISA implementation that instead of calling homomorphic
operations inserts instructions into an EVA program. This
decouples the generation of the program from its execution.
We make use of CHET’s data layout selection optimization,
but not its encryption parameter selection functionality, as this
is already provided in EVA. Thus, EVA subsumes CHET.

8. Experimental Evaluation

In this section, we ﬁrst describe our experimental setup (Sec-
tion 8.1). We then describe our evaluation of homomorphic
neural network inference (Section 8.2) and homomorphic arith-

11

Table 3: Deep Neural Networks used in our evaluation.

Table 5: Average latency (s) of CHET and EVA on 56 threads.

No. of layers

# FP

Accu-

Model

CHET EVA Speedup from EVA

Network

LeNet-5-small
LeNet-5-medium
LeNet-5-large
Industrial
SqueezeNet-
CIFAR

Conv

FC Act

operations

racy(%)

2
2
2
5
10

2
2
2
2
0

4
4
4
6
9

159960
5791168
21385674
-
37759754

98.45
99.11
99.30
-
79.38

Table 4: Programmer-speciﬁed input and output scaling fac-
tors used for both CHET and EVA, and the accuracy of homo-
morphic inference in CHET and EVA (all test inputs).

Model

Input Scale (log P) Output Accuracy(%)

Cipher Vector Scalar Scale CHET EVA

LeNet-5-small
LeNet-5-medium
LeNet-5-large
Industrial
SqueezeNet-CIFAR

25
25
25
30
25

15
15
20
15
15

10
10
10
10
10

30
30
25
30
30

98.42 98.45
99.07 99.09
99.34 99.32

-

-

79.31 79.34

metic, statistical machine learning, and image processing ap-
plications (Section 8.3).

8.1. Experimental Setup

All experiments were conducted on a 4 socket machine with
Intel Xeon Gold 5120 2.2GHz CPU with 56 cores (14 cores per
socket) and 190GB memory. Our evaluation of all applications
uses GCC 8.1 and SEAL v3.3.1 [40], which implements the
RNS variant of the CKKS scheme [11]. All experiments use
the default 128-bit security level.

We evaluate a simple arithmetic application to compute the
path length in 3-dimensional space. We also evaluate appli-
cations in statistical machine learning, image processing, and
deep neural network (DNN) inferencing using the frontends
that we built on top of EVA (Section 7). For DNN inferencing,
we compare EVA with the state-of-the-art compiler for homo-
morphic DNN inferencing, CHET [17], which has been shown
to outperform hand-tuned codes. For the other applications, no
suitable compiler exists for comparison. Hand-written codes
also do no exist as it is very tedious to write them manually.
We evaluate these applications using EVA to show that EVA
yields good performance with little programming effort. For
DNN inferencing, the accuracy reported is for all test inputs,
whereas all the other results reported are an average over the
ﬁrst 20 test inputs. For the other applications, all results re-
ported are an average over 20 different randomly generated
inputs.

8.2. Deep Neural Network (DNN) Inference

Networks: We evaluate ﬁve deep neural network (DNN) ar-
chitectures for image classiﬁcation tasks that are summarized

12

LeNet-5-small
LeNet-5-medium
LeNet-5-large
Median
SqueezeNet-CIFAR

3.7
5.8
23.3
70.4
344.7

0.6
1.2
5.6
9.6
72.7

6.2
4.8
4.2
7.3
4.7

in Table 3:
• The three LeNet-5 networks are all for the MNIST [31]
dataset, which vary in the number of neurons. The largest
one matches the one used in the TensorFlow’s tutorials [41].
• Industrial is a network from an industry partner for privacy-

sensitive binary classiﬁcation of images.

• SqueezeNet-CIFAR is a network for the CIFAR-10
dataset [30] that uses 4 Fire-modules [14] and follows the
SqueezeNet [26] architecture.
We obtain these networks (and the models) from the authors
of CHET, so they match the networks evaluated in their pa-
per [17]. Industrial is a FHE-compatible neural network that
is proprietary, so the authors gave us only the network struc-
ture without the trained model (weights) or the test datasets.
We evaluate this network using randomly generated numbers
(between -1 and 1) for the model and the images. All the other
networks were made FHE-compatible by CHET authors using
average-pooling and polynomial activations instead of max-
pooling and ReLU activations. Table 3 lists the accuracies we
observed for these networks using unencrypted inference on
the test datasets. We evaluate encrypted image inference with
a batch size of 1 (latency).

Scaling Factors: The scaling factors, or scales in short,
must be chosen by the user. For each network (and model),
we use CHET’s proﬁling-guided optimization on the ﬁrst 20
test images to choose the input scales as well as the desired
output scale. There is only one output but there are many
inputs. For the inputs, we choose one scale each for Cipher,
Vector, and Scalar inputs. Both CHET and EVA use the same
scales, as shown in Table 4. The scales impact both perfor-
mance and accuracy. We evaluate CHET and EVA on all test
images using these scales and report the accuracy achieved by
fully-homomorphic inference in Table 4. There is negligible
difference between their accuracy and the accuracy of unen-
crypted inference (Table 3). Higher values of scaling factors
may improve the accuracy, but will also increase the latency
of homomorphic inference.

Comparison with CHET Compiler: Table 5 shows that
EVA is at least 4× faster than CHET on 56 threads for all
networks. Note that the average latency of CHET is slower
than that reported in their paper [17]. This could be due to
differences in the experimental setup. The input and output
scales they use are different, so is the SEAL version (3.1 vs.
3.3.1). We suspect the machine differences to be the primary
reason for the slowdown because they use smaller number of

Table 6: Encryption parameters selected by CHET and EVA
(where Q = ∏r

i=1 Qi).

Model

LeNet-5-small
LeNet-5-medium
LeNet-5-large
Industrial
SqueezeNet-CIFAR

CHET

EVA

log2 N log2 Q
480
480
740
1222
1740

15
15
15
16
16

r

8
8
13
21
29

log2 N log2 Q
360
360
480
810
1225

14
14
15
15
16

r

6
6
8
14
21

large. Reducing N and r reduces the cost (and the memory)
of each homomorphic operation (and ciphertext) signiﬁcantly.
In CHET, RESCALE and MODSWITCH used by the experts
for a given tensor kernel may be sub-optimal for the program.
On the other hand, EVA performs global (inter-procedural)
analysis to minimize the length of the coefﬁcient modulus,
yielding much smaller encryption parameters.

To understand the differences in parallelization, we evalu-
ated CHET and EVA on 1, 7, 14, 28, and 56 threads. Figure 7
shows the strong scaling. We omit LeNet-5-small because it
takes too little time, even on 1 thread. It is apparent that EVA
scales much better than CHET. The parallelization in CHET
is within a tensor operation or kernel using OpenMP. Such
static, bulk-synchronous schedule limits the available paral-
lelism. In contrast, EVA dynamically schedules the directed
acyclic graph of EVA (or SEAL) operations asynchronously.
Thus, it exploits the parallelism available across tensor ker-
nels, resulting in much better scaling. The average speedup of
EVA on 56 threads over EVA on 1 thread is 18.6× (excluding
LeNet-5-small).

Comparison with Hand-Written LoLa: LoLa [7] imple-
ments hand-tuned homomorphic inference for neural networks,
but the networks they implement are different than the ones
we evaluated (and the ones in CHET). Nonetheless, they im-
plement networks for the MNIST and CIFAR-10 datasets.

For the MNIST dataset, LoLa implements the highly-tuned
CryptoNets [20] network (which is similar in size to LeNet-
5-small). This implementation has an average latency of 2.2
seconds and has an accuracy of 98.95%. EVA takes only 1.2
seconds on a much larger network, LeNet-5-medium, with a
better accuracy of 99.09%. For the CIFAR-10 dataset, LoLa
implements a custom network which takes 730 seconds and
has an accuracy of 74.1%. EVA takes only 72.7 seconds on a
much larger network with a better accuracy of 79.34%.

LoLa uses SEAL 2.3 (which implements BFV [18]) which
is less efﬁcient than SEAL 3.3.1 (which implements RNS-
CKKS [11]) but much more easier to use. EVA is faster
because it exploits a more efﬁcient FHE scheme which is
much more difﬁcult to manually write code for. Thus, EVA
outperforms even highly tuned expert-written implementations
like LoLa with very little programming effort.

Figure 7: Strong scaling of CHET and EVA (log-log scale).

heavier cores (16 3.2GHz cores vs. 56 2.2GHz cores). In any
case, our comparison of CHET and EVA is fair because both
use the same input and output scales, SEAL version, Channel-
Height-Width (CHW) data layout, and hardware. Both CHET
and EVA perform similar encryption parameters and rotation
keys selection. The differences between CHET and EVA are
solely due to the beneﬁts that accrue from EVA’s low-level
optimizations.

CHET relies on an expert-optimized library of homomor-
phic tensor kernels, where each kernel (1) includes FHE-
speciﬁc instructions and (2) is explicitly parallelized. However,
even experts cannot optimize or parallelize across different
kernels as that information is not available to them. In contrast,
EVA uses a library of vectorized tensor kernels and automati-
cally (1) inserts FHE-speciﬁc instructions using global analy-
sis and (2) parallelizes the execution of different instructions
across kernels. Due to these optimizations, EVA is on average
5.3× faster than CHET. On a single thread (Figure 7), EVA
is on average 2.3× faster than CHET and this is solely due to
better placement of FHE-speciﬁc instructions. The rest of the
improvement on 56 threads (2.3× on average) is due to better
parallelization in EVA.

Both CHET and EVA have similar RELINEARIZE place-
ment. However, they differ in the placement of the other FHE-
speciﬁc instructions — RESCALE and MODSWITCH. These
instructions directly impact the encryption parameters (both
CHET and EVA use a similar encryption parameter selection
pass). We report the encryption parameters selected by CHET
and EVA in Table 6. EVA selects much smaller coefﬁcient
modulus, both in terms of the number of elements r in it
and their product Q. Consequently, the polynomial modulus
N is one power-of-2 lower in all networks, except LeNet-5-

13

IndustrialSqueezeNet-CIFARLeNet-5-mediumLeNet-5-large2832283216642561285122048283232128ThreadsAverage Latency (s)CHETEVATable 7: Compilation, encryption context (context), encryption,
and decryption time for EVA.

Model

LeNet-5-small
LeNet-5-medium
LeNet-5-large
Industrial
SqueezeNet-CIFAR

Time (s)

Compilation Context Encrypt Decrypt

1.21
0.14
1.26
0.50
7.24
1.13
15.70
0.59
4.06 160.82

0.03
0.03
0.08
0.12
0.42

0.01
0.01
0.02
0.03
0.26

Table 8: Evaluation of EVA for fully-homomorphic arithmetic,
statistical machine learning, and image processing applica-
tions on 1 thread (LoC: lines of code).

Application

Vector Size LoC Time (s)

3-dimensional Path Length
Linear Regression
Polynomial Regression
Multivariate Regression
Sobel Filter Detection
Harris Corner Detection

4096
2048
4096
2048
4096
4096

45
10
15
15
35
40

0.394
0.027
0.104
0.094
0.511
1.004

Compilation Time: We present the compilation time, en-
cryption context time, encryption time, and decryption time
for all networks in Table 7. The encryption context time in-
cludes the time to generate the public key, the secret key, the
rotation keys, and the relinearization keys. This can take a
lot of time, especially for large N, like in SqueezeNet-CIFAR.
Compilation time, encryption time, and decryption time are
negligible for all networks.

8.3. Arithmetic, Statistical Machine Learning, and Image

Processing

We implemented several applications using PyEVA. To il-
lustrate a simple arithmetic application, we implemented an
application that computes the length of a given encrypted 3-
dimensional path. This computation can be used as a kernel in
several applications like in secure ﬁtness tracking on mobiles.
For statistical machine learning, we implemented linear re-
gression, polynomial regression, and multi-variate regression
on encrypted vectors. For image processing, we implemented
Sobel ﬁlter detection and Harris corner detection on encrypted
images. All these implementations took very few lines of code
(< 50), as shown in Table 8.

Table 8 shows the execution time of these applications on
encrypted data using 1 thread. Sobel ﬁlter detection takes half
a second and Harris corner detection takes only a second. The
rest take negligible time. We believe Harris corner detection
is one of the most complex programs that have been evaluated
using CKKS. EVA enables writing advanced applications in
various domains with little programming effort, while provid-
ing excellent performance.

9. Related Work

Libraries for FHE SEAL [40] implements RNS variants of
two FHE schemes: BFV [18] and CKKS [12, 11]. HElib [24]
implements two FHE schemes: BGV [6] and CKKS. PAL-
ISADE [37] is a framework that provides a general API for
multiple FHE schemes including BFV, BGV, and CKKS. For
BFV and CKKS, PALISADE is similar to SEAL as it only
implements lower-level FHE primitives. On the other hand,
EVA language abstracts batching-compatible FHE schemes
like BFV, BGV, and CKKS while hiding cryptographic details
from the programmer. Although EVA compiler currently gen-
erates code targeting only CKKS implementation in SEAL,
it can be adapted to target other batching-compatible FHE
scheme implementations or FHE libraries.

General-Purpose Compilers for FHE To reduce the bur-
den of writing FHE programs, general-purpose compilers have
been proposed that target different FHE libraries. These
compilers share many of the same goals as ours. Some
of these compilers support general-purpose languages like
Julia (cf. [2]), C++ (cf. [13]), and R (cf. [3]), whereas
ALCHEMY [15] is the only one that provides its own general-
purpose language. Unlike EVA, none of these languages are
amenable to be a target for domain-speciﬁc compilers like
CHET [17] because these languages do not support rotations
on ﬁxed power-of-two sized vectors. Nonetheless, techniques
in these compilers (such as ALCHEMY’s static type safety
and error rate analysis) are orthogonal to our contributions in
this paper and can be incorporated in EVA.

All prior general-purpose compilers target (libraries imple-
menting) either the BFV scheme [18] or the BGV scheme [6].
In contrast, EVA targets (libraries implementing) the recent
CKKS scheme [12, 11], which is much more difﬁcult to write
or generate code for (compared to BFV or BGV). For exam-
ple, ALCHEMY supports the BGV scheme and would require
signiﬁcant changes to capture the semantics (e.g., RESCALE)
of CKKS. ALCHEMY always inserts MODSWITCH after ev-
ery ciphertext-ciphertext multiplication (using local analysis),
which is not optimal for BGV (or BFV) and would not be
correct for CKKS. EVA is the ﬁrst general-purpose compiler
for CKKS and it uses a graph rewriting framework to in-
sert RESCALE and MODSWITCH operations correctly (using
global analysis) so that the modulus chain length is optimal.
These compiler passes in EVA can be incorporated in other
general-purpose compilers (to target CKKS).

Domain-Speciﬁc Compilers for FHE Some prior compil-
ers for DNN inferencing [17, 5, 4] target CKKS. CHET [17]
is a compiler for tensor programs that automates the selec-
tion of data layouts for mapping tensors to vectors of vectors.
The nGraph-HE [5] project introduced an extension to the
Intel nGraph [16] deep learning compiler that allowed data
scientists to make use of FHE with minimal code changes.
The nGraph-HE compiler uses run-time optimization (e.g.,
detection of special plaintext values) and compile-time opti-

14

mizations (e.g., use of ISA-level parallelism, graph-level op-
timizations). nGraph-HE2 [4] is an extension of nGraph-HE
that uses a hybrid computational model – the server inter-
acts with the client to perform non-HE compatible operations,
which increases the communication overhead. Moreover, un-
like CHET and EVA, neither nGraph-HE nor nGraph-HE2
automatically select encryption parameters.

To hide the complexities of FHE operations, all existing
domain-speciﬁc compilers rely on a runtime of high-level ker-
nels which can be optimized by experts. However, experts
are limited to information within a single kernel (like convo-
lution) to optimize insertion of FHE-speciﬁc operations and
to parallelize execution. In contrast, EVA optimizes insertion
of FHE-speciﬁc operations by using global analysis and paral-
lelizes FHE operations across kernels transparently. Therefore,
CHET, nGraph-HE, and nGraph-HE2 can target EVA instead
of the FHE scheme directly to beneﬁt from such optimizations
and we demonstrated this for CHET.

Compilers for MPC Multi-party computation (MPC) [21,
43] is another technique for privacy-preserving computation.
The existing MPC compilers [23] are mostly general-purpose
and even though it is possible to use them for deep learning
applications, it is hard to program against a general-purpose
interface. The EzPC compiler [9] is a machine learning com-
piler that combines arithmetic sharing and garbled circuits and
operates in a two-party setting. EzPC uses ABY [34] as a
cryptographic backend.

Privacy-Preserving Deep Learning CryptoNets [20], one
of the ﬁrst systems for neural network inference using FHE and
the consequent work on LoLa [7], a low-latency CryptoNets,
show the ever more practical use of FHE for deep learning.
CryptoNets and LoLa however use kernels for neural networks
that directly translate the operations to the cryptographic prim-
itives of the FHE schemes. There are also other algorithms
and cryptosystems speciﬁcally for deep learning that rely on
FHE (CryptoDL [25], Chabanne et al. [8], Jiang et al. [28]),
MPC (Chameleon [38], DeepSecure [39], SecureML [35]),
oblivious protocols (MiniONN [32]), or on hybrid approaches
(Gazelle [29], SecureNN [42]). None of these provide the
ﬂexibility and the optimizations of a compiler approach.

10. Conclusions

This paper introduces a new language and intermediate rep-
resentation called Encrypted Vector Arithmetic (EVA) for
general-purpose Fully-Homomorphic Encryption (FHE) com-
putation. EVA includes a Python frontend that can be used
to write advanced programs with little programming effort,
and it hides all the cryptographic details from the programmer.
EVA includes an optimizing compiler that generates correct,
secure, and efﬁcient code, targeting the state-of-the-art SEAL
library. EVA is also designed for easy targeting of domain spe-
ciﬁc languages. The state-of-the-art neural network inference
compiler CHET, when re-targeted onto EVA, outperforms its

unmodiﬁed version by 5.3× on average. EVA provides a solid
foundation for a richer variety of FHE applications as well as
domain-speciﬁc compilers and auto-vectorizing compilers for
computing on encrypted data.

Acknowledgments

This research was supported by the NSF grants 1406355,
1618425, 1705092, 1725322, and by the DARPA contracts
FA8750-16-2-0004 and FA8650-15-C-7563. We thank Keshav
Pingali for his support. We thank the anonymous reviewers
and in particular our shepherd, Petar Tsankov, for their many
suggestions in improving this paper.

References

[1] Martin Albrecht, Melissa Chase, Hao Chen, Jintai Ding, Shaﬁ Gold-
wasser, Sergey Gorbunov, Shai Halevi, Jeffrey Hoffstein, Kim Laine,
Kristin Lauter, Satya Lokam, Daniele Micciancio, Dustin Moody,
Travis Morrison, Amit Sahai, and Vinod Vaikuntanathan. Homomor-
phic encryption security standard. Technical report, HomomorphicEn-
cryption.org, Toronto, Canada, November 2018.

[2] David W. Archer, José Manuel Calderón Trilla, Jason Dagit, Alex Mal-
ozemoff, Yuriy Polyakov, Kurt Rohloff, and Gerard Ryan. Ramparts:
A programmer-friendly system for building homomorphic encryption
applications. In Proceedings of the 7th ACM Workshop on Encrypted
Computing &#38; Applied Homomorphic Cryptography, WAHC’19,
pages 57–68, New York, NY, USA, 2019. ACM.

[3] Louis JM Aslett, Pedro M Esperança, and Chris C Holmes. A review
of homomorphic encryption and software tools for encrypted statistical
machine learning. arXiv preprint arXiv:1508.06574, 2015.

[4] Fabian Boemer, Anamaria Costache, Rosario Cammarota, and Casimir
Wierzynski. nGraph-HE2: A high-throughput framework for neu-
ral network inference on encrypted data. In Proceedings of the 7th
ACM Workshop on Encrypted Computing & Applied Homomorphic
Cryptography, 2019.

[5] Fabian Boemer, Yixing Lao, Rosario Cammarota, and Casimir
Wierzynski. nGraph-HE: A graph compiler for deep learning on
homomorphically encrypted data. In Proceedings of the 16th ACM
International Conference on Computing Frontiers, 2019.

[6] Zvika Brakerski, Craig Gentry, and Vinod Vaikuntanathan. (Leveled)
fully homomorphic encryption without bootstrapping. In Shaﬁ Gold-
wasser, editor, ITCS 2012: 3rd Innovations in Theoretical Computer
Science, pages 309–325, Cambridge, MA, USA, January 8–10, 2012.
Association for Computing Machinery.

[7] Alon Brutzkus, Ran Gilad-Bachrach, and Oren Elisha. Low latency
privacy preserving inference.
In Kamalika Chaudhuri and Ruslan
Salakhutdinov, editors, Proceedings of the 36th International Confer-
ence on Machine Learning, ICML, 2019.

[8] Hervé Chabanne, Amaury de Wargny, Jonathan Milgram, Constance
Morel, and Emmanuel Prouff. Privacy-preserving classiﬁcation on
deep neural network. IACR Cryptology ePrint Archive, page 35, 2017.
[9] Nishanth Chandran, Divya Gupta, Aseem Rastogi, Rahul Sharma, and
Shardul Tripathi. Ezpc: Programmable and efﬁcient secure two-party
computation for machine learning. In IEEE European Symposium on
Security and Privacy, EuroS&P, 2019.

[10] Hao Chen. Optimizing relinearization in circuits for homomorphic
encryption. CoRR, abs/1711.06319, 2017. https://arxiv.org/
abs/1711.06319.

[11] Jung Hee Cheon, Kyoohyung Han, Andrey Kim, Miran Kim, and Yong-
soo Song. A full RNS variant of approximate homomorphic encryption.
In Carlos Cid and Michael J. Jacobson Jr:, editors, SAC 2018: 25th
Annual International Workshop on Selected Areas in Cryptography,
volume 11349 of Lecture Notes in Computer Science, pages 347–368,
Calgary, AB, Canada, August 15–17, 2019. Springer, Heidelberg, Ger-
many.

[12] Jung Hee Cheon, Andrey Kim, Miran Kim, and Yong Soo Song. Ho-
momorphic encryption for arithmetic of approximate numbers.
In
Tsuyoshi Takagi and Thomas Peyrin, editors, Advances in Cryptology –
ASIACRYPT 2017, Part I, volume 10624 of Lecture Notes in Computer
Science, pages 409–437, Hong Kong, China, December 3–7, 2017.
Springer, Heidelberg, Germany.

[13] Cingulata. https://github.com/CEA-LIST/Cingulata, 2018.

15

[29] Chiraag Juvekar, Vinod Vaikuntanathan, and Anantha Chandrakasan.
GAZELLE: A low latency framework for secure neural network in-
ference. In William Enck and Adrienne Porter Felt, editors, USENIX
Security 2018: 27th USENIX Security Symposium, pages 1651–1669,
Baltimore, MD, USA, August 15–17, 2018. USENIX Association.

[30] Alex Krizhevsky.

The CIFAR-10 dataset.

https://www.cs.

toronto.edu/~kriz/cifar.html, 2009.

[31] Yann LeCun, Corinna Cortes, and Christopher J.C. Burges. The
MNIST database of handwritten digits. http://yann.lecun.com/
exdb/mnist/.

[32] Jian Liu, Mika Juuti, Yao Lu, and N. Asokan. Oblivious neural network
predictions via MiniONN transformations. In Bhavani M. Thuraising-
ham, David Evans, Tal Malkin, and Dongyan Xu, editors, ACM CCS
2017: 24th Conference on Computer and Communications Security,
pages 619–631, Dallas, TX, USA, October 31 – November 2, 2017.
ACM Press.

[33] Vadim Lyubashevsky, Chris Peikert, and Oded Regev. On ideal lattices
and learning with errors over rings. In Henri Gilbert, editor, Advances
in Cryptology – EUROCRYPT 2010, volume 6110 of Lecture Notes
in Computer Science, pages 1–23, French Riviera, May 30 – June 3,
2010. Springer, Heidelberg, Germany.

[34] Payman Mohassel and Peter Rindal. ABY3: A mixed protocol frame-
work for machine learning.
In David Lie, Mohammad Mannan,
Michael Backes, and XiaoFeng Wang, editors, ACM CCS 2018: 25th
Conference on Computer and Communications Security, pages 35–52,
Toronto, ON, Canada, October 15–19, 2018. ACM Press.

[35] Payman Mohassel and Yupeng Zhang. SecureML: A system for scal-
able privacy-preserving machine learning. In 2017 IEEE Symposium
on Security and Privacy, pages 19–38, San Jose, CA, USA, May 22–26,
2017. IEEE Computer Society Press.

[36] Donald Nguyen, Andrew Lenharth, and Keshav Pingali. A Lightweight
In Proceedings of the Twenty-
Infrastructure for Graph Analytics.
Fourth ACM Symposium on Operating Systems Principles, SOSP ’13,
pages 456–471, New York, NY, USA, 2013. ACM.
[37] Palisade homomorphic encryption software library.

https://

palisade-crypto.org/, 2020.

[38] M. Sadegh Riazi, Christian Weinert, Oleksandr Tkachenko, Ebrahim M.
Songhori, Thomas Schneider, and Farinaz Koushanfar. Chameleon:
A hybrid secure computation framework for machine learning appli-
cations. In Jong Kim, Gail-Joon Ahn, Seungjoo Kim, Yongdae Kim,
Javier López, and Taesoo Kim, editors, ASIACCS 18: 13th ACM Sympo-
sium on Information, Computer and Communications Security, pages
707–721, Incheon, Republic of Korea, April 2–6, 2018. ACM Press.

[39] Bita Darvish Rouhani, M. Sadegh Riazi, and Farinaz Koushanfar.
In Proceed-
Deepsecure: Scalable provably-secure deep learning.
ings of the 55th Annual Design Automation Conference, DAC ’18,
pages 2:1–2:6, New York, NY, USA, 2018. ACM.

[40] Microsoft SEAL (release 3.3). https://github.com/Microsoft/

SEAL, June 2019. Microsoft Research, Redmond, WA.
model

convolutional

MNIST

[41] LeNet-5-like

example.

https://github.com/tensorflow/models/blob/v1.9.0/
tutorials/image/mnist/convolutional.py, 2016.

[42] Sameer Wagh, Divya Gupta, and Nishanth Chandran. SecureNN: 3-
party secure computation for neural network training. Proceedings on
Privacy Enhancing Technologies, 2019(3):26–49, July 2019.

[43] Andrew Chi-Chih Yao. How to generate and exchange secrets (ex-
tended abstract). In 27th Annual Symposium on Foundations of Com-
puter Science, pages 162–167, Toronto, Ontario, Canada, October 27–
29, 1986. IEEE Computer Society Press.

[14] David Corvoysier.

Squeezenet
//github.com/kaizouman/tensorsandbox/tree/master/
cifar10/models/squeeze, 2017.

for CIFAR-10.

https:

[15] Eric Crockett, Chris Peikert, and Chad Sharp. Alchemy: A language
and compiler for homomorphic encryption made easy. In Proceedings
of the 2018 ACM SIGSAC Conference on Computer and Communica-
tions Security, CCS ’18, page 1020–1037, New York, NY, USA, 2018.
Association for Computing Machinery.

[16] Scott Cyphers, Arjun K. Bansal, Anahita Bhiwandiwalla, Jayaram
Bobba, Matthew Brookhart, Avijit Chakraborty, William Constable,
Christian Convey, Leona Cook, Omar Kanawi, Robert Kimball, Jason
Knight, Nikolay Korovaiko, Varun Kumar Vijay, Yixing Lao, Christo-
pher R. Lishka, Jaikrishnan Menon, Jennifer Myers, Sandeep Aswath
Narayana, Adam Procter, and Tristan J. Webb. Intel ngraph: An in-
termediate representation, compiler, and executor for deep learning.
CoRR, abs/1801.08058, 2018.

[17] Roshan Dathathri, Olli Saarikivi, Hao Chen, Kim Laine, Kristin Lauter,
Saeed Maleki, Madanlal Musuvathi, and Todd Mytkowicz. Chet:
An optimizing compiler for fully-homomorphic neural-network infer-
encing. In Proceedings of the 40th ACM SIGPLAN Conference on
Programming Language Design and Implementation, 2019.

[18] Junfeng Fan and Frederik Vercauteren. Somewhat practical fully ho-
momorphic encryption. Cryptology ePrint Archive, Report 2012/144,
2012. https://eprint.iacr.org/2012/144.

[19] Galois system, 2019.
[20] Ran Gilad-Bachrach, Nathan Dowlin, Kim Laine, Kristin E. Lauter,
Michael Naehrig, and John Wernsing. Cryptonets: Applying neural
networks to encrypted data with high throughput and accuracy. In
Proceedings of the 33nd International Conference on Machine Learn-
ing, ICML 2016, New York City, NY, USA, June 19-24, 2016, pages
201–210, 2016.

[21] Oded Goldreich, Silvio Micali, and Avi Wigderson. How to play any
mental game or A completeness theorem for protocols with honest
majority. In Alfred Aho, editor, 19th Annual ACM Symposium on
Theory of Computing, pages 218–229, New York City, NY, USA,
May 25–27, 1987. ACM Press.
buffer.

https://developers.google.com/

[22] Protocol

protocol-buffers. Google Inc.

[23] Marcella Hastings, Brett Hemenway, Daniel Noble, and Steve
Zdancewic. SoK: General purpose compilers for secure multi-party
In 2019 IEEE Symposium on Security and Privacy,
computation.
pages 1220–1237, San Francisco, CA, USA, May 19–23, 2019. IEEE
Computer Society Press.

[24] Helib. https://github.com/homenc/HElib, 2020.
[25] Ehsan Hesamifard, Hassan Takabi, and Mehdi Ghasemi. Cryptodl:
Deep neural networks over encrypted data. CoRR, abs/1711.05189,
2017.

[26] Forrest N. Iandola, Matthew W. Moskewicz, Khalid Ashraf, Song
Han, William J. Dally, and Kurt Keutzer. Squeezenet: Alexnet-level
accuracy with 50x fewer parameters and <1mb model size. CoRR,
abs/1602.07360, 2016. https://arxiv.org/abs/1602.07360.
[27] Cryptography Lab in Seoul National University. Homomorphic en-
cryption for arithmetic of approximate numbers (heaan). https:
//github.com/snucrypto/HEAAN.

[28] Xiaoqian Jiang, Miran Kim, Kristin E. Lauter, and Yongsoo Song. Se-
cure outsourced matrix computation and application to neural networks.
In David Lie, Mohammad Mannan, Michael Backes, and XiaoFeng
Wang, editors, ACM CCS 2018: 25th Conference on Computer and
Communications Security, pages 1209–1222, Toronto, ON, Canada,
October 15–19, 2018. ACM Press.

16

