2
2
0
2

n
u
J

2

]

C
O
.
h
t
a
m

[

1
v
5
7
0
1
0
.
6
0
2
2
:
v
i
X
r
a

A Preference Elicitation Approach for the
Ordered Weighted Averaging Criterion using
Solution Choice Observations

Werner Baak∗ and Marc Goerigk

Network and Data Science Management, University of Siegen,
Unteres Schloß 3, 57072 Siegen, Germany

Abstract

Decisions under uncertainty or with multiple objectives usually require the decision
maker to formulate a preference regarding risks or trade-oﬀs. If this preference is known,
the ordered weighted averaging (OWA) criterion can be applied to aggregate scenarios or
objectives into a single function. Formulating this preference, however, can be challenging,
as we need to make explicit what is usually only implicit knowledge. In this paper, we
explore methods of preference elicitation to identify the decision maker’s weights that
deﬁne OWA. We assume that we have a set of examples available, where the decision
maker has chosen a preferred solution by hand. We then use these examples to determine
the underlying preference. We propose and compare two approaches for this purpose.
The ﬁrst is an optimization-based model, where weights are determined by solving an
alternating sequence of linear programs and standard OWA problems. The second is a
machine learning model to predict weights using a regression approach. Our numerical
experiments indicate that the performance of optimization-based models is improving
with an increasing size of given examples, which means that these models make eﬀective
use of the given information; whereas the regression models can perform better when only
few examples are provided.

Keywords: decision making under uncertainty; preference elicitation; ordered weighted av-
eraging
Acknowledgements: Supported by the Deutsche Forschungsgemeinschaft (DFG) through
grant GO 2069/2-1.

1 Introduction

Decision making is an ubiquitous challenge, where often multiple conﬂicting objectives or
the consequences over multiple scenarios need to be taken into account [Ehr05].
In such
settings, a popular approach is to use an aggregation function to combine several values
into a single one. The Ordered Weighted Average (OWA) operator, introduced by Yager

∗Corresponding author. Email: werner.baak@uni-siegen.de

1

 
 
 
 
 
 
in 1988 [Yag88], is one such method. Since its inception, it has been widely studied and
applied in settings as diverse as fuzzy modeling [O’H88, Yag98], location planning [Mal06],
ﬁnancial decision-making problems [MGL09, MC11], geographic information system based
site planning [ZAKL+19] or risk assignment [CC11], see also the survey [EM14].

The idea of the OWA function is to take a vector of values as input, sort this vector from
largest to smallest value, and to calculate the scalar product of this sorted vector with a
weight vector. Hence, the weights are assigned to ordered values and can be used to stress
importance on high, low or mid-ranged inputs. These weights should represent the decision
maker’s preferences.

Solving problems with the OWA operator is usually more challenging than solving their
nominal counterparts, where a single objective function is given. Diﬀerent solution methods
have been developed, including linear programming (LP) or mixed-integer linear programming
(MILP) models, see, e.g., [O´S03, OO12]. In [CG15], a compact reformulation of the problem
based linear programming duality was established. The complexity of discrete decision making
problems with the OWA criterion has been studied as well, see [KZ15] and [CGKZ20], where
approximation algorithms have been developed, or [GS12], where exact algorithms for the
spanning tree problem are considered.

For the purpose of such theoretical analysis, it is usually assumed that the preference
weights are given by the decision maker.
In practice however, these weights are not sim-
ply given, but must ﬁrst be determined. Moreover, inaccuracies, instabilities or conﬂicts of
preferences are mapped during this preference elicitation process. For this purpose, several
methods have already been developed, see the surveys [Xu05, Liu11].

The idea of sample learning methods is to use empirical data to ﬁt OWA weights. Given
a set of observations consisting of solutions and objective values, an optimization model is
used to ﬁt preference vectors that satisfy these observations as far as possible (see, e.g.,
[Yag96, GLLP11]). Using a similar idea, [Ahn08] assumes that pairwise comparisons between
solutions are given to indicate preferences. We then solve an optimization model to ﬁnd
preference vectors that adhere to these comparisons.

Many more methods exist to elicit preference weights for OWA criteria. We brieﬂy sum-
[BGPV15] uses a search tree model for regret-based optimization,
marize some of these.
[AD21] guarantees a
including OWA, where a maximization of max regret is performed.
robust approach identifying preferences and also an error detection method for wrong prefer-
ences in which OWA models are utilized to test against the true model. [LMD15] uses binary
alternatives (ordinal information) as extension to the so-called MACBETH method to elicit
an OWA operator and where the weights given are trapezoidal but can be weakened to a
convex fuzzy set and thus taking account inconsistencies. [KA18] elicits the decision maker’s
preferences by comparing answers given with extreme or arbitrary options and based on the
results adding constraints to the OWA weights.
[WLH07] makes use of the orness degree
to determine the weights by analyzing the decision maker’s optimism level. Further prefer-
ence elicitation methods include maximal entropy methods [FM01], data-driven approaches
[FY94], introduction of a weight generating function [FY98, YA16] or using kernel density
estimations [LXLC20].

Extensions to the OWA operator have been studied as well. These include OWAWA (Or-
dered Weighted Average Weighted Average), WOWA (Weighted Ordered Weighted Average)
and IOWA (Induced Ordered Weighted Average). The latter variant enables the possibility
to reorder variables in a more complex way. Building on that, [Mer10] proposes the in-
duced generalized ordered weighted averaging (IGOWA) operator. The aggregation operator

2

combines the characteristics of the generalized OWA and the induced OWA operator. The
IEOWAD (Induced Euclidean Ordered Weighted Averaging Distance) approach by [MC11],
parameterizes distances measures using an IOWA operator, resulting in a modality which
allows considering more complex attitudinal characters of the decision maker and resulting
in diﬀerent conclusions.

In this paper we propose a model which enables us to determine the decision maker’s
preference (weight vector) based on observations. These observations only include information
that is actually available to the decision maker, that is, for a given decision making problem,
we only require the preferred solution. Contrary to previous approaches, we do not require
additional information, such as the OWA value of the preferred solution. We propose and
compare two approaches to determine OWA weights. The ﬁrst is an optimization-based
model, where weights are determined by solving a sequence of MILPs. The second is a
machine learning model to predict weights using a regression approach. By measuring the
average distance between the true OWA weights and the estimated weights, we can measure
and compare the performance of the approaches.

The paper is organized in the following order: In Section 2 we deﬁne the OWA problem
and the notation. We present our optimization approach for preference elicitation and discuss
modeling alternatives in Section 3, while a machine learning approach is presented in Section 4.
In Section 5 we discuss the computational experiments, considering setup, results and insights.
Finally, in Section 6 we reﬂect and conclude the paper taking into account possible further
research approaches.

2 OWA Problem Deﬁnition

In this section we give a formal description of the OWA criterion and related optimization
problems. Throughout this paper, we use the notation [K] to denote a set {1, . . . , K}, write
vectors in bold, and drop the transpose symbol for vector multiplication if the context is clear.
We consider an optimization problem over some set of feasible solutions X ⊆ Rn with a
linear objective function cccxxx that we would like to minimize. We explore the case that there
is more than one cost coeﬃcient vector that is relevant for the decision making process. This
can be because there are multiple relevant objectives, or due to uncertainty. We denote by
{ccc1, . . . , cccK} the set of K cost coeﬃcient vectors that we would like to consider simultaneously.
This means that for a given decision vector xxx ∈ X , there are K objective values ccc1xxx, . . . , cccKxxx.
The purpose of the OWA criterion is to aggregate these values into a single value.

To this end, we require a preference vector www ∈ [0, 1]K with (cid:80)

k∈[K] wk = 1. We write
W = {www ∈ [0, 1]K : (cid:80)
k∈[K] wk = 1}. The purpose of wk is to assign an importance to the
kth-largest objective value for k ∈ [K]. Let π be a permutation that sorts the K objective
values from largest to smallest, i.e., π is such that cccπ(1)xxx ≥ cccπ(2)xxx ≥ . . . ≥ cccπ(K)xxx. Then, the
OWA operator is deﬁned as

OWAwww(xxx, C) =

wk(cccπ(k)xxx)

(cid:88)

k∈[K]

Note that the permutation π depends on the solution xxx. The OWA operator contains several
well-known decision making criteria as special cases. By setting www = (1, 0, . . . , 0), all weight
is assigned to the largest objective value, which means that OWA becomes the worst-case

3

criterion. On the other hand, setting www = (0, . . . , 0, 1) gives the best-case criterion. Addition-
ally, w = (α, 0, . . . , 0, 1 − α) for some α ∈ [0, 1] corresponds to the Hurwicz criterion, while
w = (1/K, . . . , 1/K) gives the average value.

A special case of OWA operators uses risk-averse preference vectors. Risk-averse preference
vectors play an important role in practice, reﬂecting typical preferences of decision makers
who assign a proportionally larger importance to bad outcomes than to good outcomes.
Such preference vectors also have advantages from a modeling perspective. Let us deﬁne
W (cid:48) = {www ∈ W : w1 ≥ w2 ≥ . . . ≥ wK}. Using a preference from W (cid:48), the permutation π that
deﬁnes OWA is also a permutation that maximizes the objective function, that is, we have

OWAwww(xxx, C) = max
π∈ΠK

wk(cccπ(k)xxx)

(cid:88)

k∈[K]

where ΠK denotes the set of permutations of vectors of size K. As discussed in [CG15], using
the dual of the maximization problem allows us to reformulate the problem of minimizing
OWA as follows:

min
xxx∈X

OWAwww(xxx, C) = min

(cid:88)

k∈[K]

αk + βk

s.t. αj + βk ≥

wjck

i xi

(cid:88)

i∈[n]

∀j, k ∈ [K]

xxx ∈ X
ααα, βββ ∈ RK

(1)

(2)

(3)

(4)

In particular, if X deﬁnes an (integer) linear set of feasible solutions, minimizing OWA be-
comes an (integer) linear optimization problem as well.

3 An Optimization Model for Preference Elicitation

3.1 Basic Model and Solution Method

We assume that the preference vector www is not known. Instead, we would like to identify a
suitable vector www ∈ W (cid:48) based on observations how a decision maker chooses an alternative.
That is, we assume that we are given pairs (C1, xxx1), . . . , (CS, xxxS) of S historic decisions. The
task of preference elicitation is to identify a suitable vector www that can explain the choice of
solutions for each observation. Note that we only assume knowledge of past problems and
corresponding solution choices. Contrary to previous approaches, we do not assume knowledge
of previous OWA objective values (which may not have been calculated in the decision making
process) or pairwise comparisons between solutions, which may only be available through an
interview process.

The underlying idea is to deﬁne for each observation s ∈ [S] the set of preference vectors
that can explain this observation, and to ﬁnd a vector www that is as close to each such set as
possible. That is, we deﬁne the sets

Opts =

(cid:26)

www ∈ W (cid:48) : xxxs ∈ arg min

xxx∈X

OWAwww(xxx, Cs)

(cid:27)

4

which contain those weight vectors for which xxxs is optimal for the corresponding OWA prob-
lem, and propose to solve

min




(cid:88)



s∈[S]

D(www, Opts) : www ∈ W (cid:48)






(Pref)

where D : [0, 1]K × 2[0,1]K → R+ is a suitable distance measure between vector and set, given
as the distance to its closest element, i.e. D(x, Y ) = miny∈Y d(x, y) for a distance metric d.
To clarify this approach, we ﬁrst present an example. Consider a decision making problem
with X = {xxx ∈ {0, 1}4 : x1 + x2 + x3 + x4 = 3}, i.e., we need to select three out of n = 4
given items. As there is only one such observation given, S = 1 and we drop the index
s for simplicity. For this example problem, there are only four solutions: xxx1 = (1, 1, 1, 0),
xxx2 = (1, 1, 0, 1), xxx3 = (1, 0, 1, 1) and xxx4 = (0, 1, 1, 1). We assume that there are K = 3
scenarios. For a cost matrix





C =

1 6 8 4
6 7 8 3
9 3 2 8


 ∈ RK×n

we are told that the decision maker prefers the solution xxx1 = (1, 1, 1, 0). What does this
imply for the underlying preference vector? There are four possible solutions. Calculating the
sorted vectors of objective values for each solution gives (21, 15, 14), (20, 16, 11), (19, 17, 13)
and (18, 18, 13), respectively. From the choice of xxx as the preferred solution, we can deduce
that its OWA-value is not larger than the OWA value of any other solution. This gives three
constraints on the www vector of the form OWAwww(xxx1, C) ≤ OWAwww(xxxi, C) for i = 2, 3, 4. These
are equivalent to the following system of linear equations.

(21 − 20)w1 + (15 − 16)w2 + (14 − 11)w3 = w1 − w2 + 3w3 ≤ 0
(21 − 19)w1 + (15 − 17)w2 + (14 − 13)w3 = 2w1 − 2w2 + w3 ≤ 0
(21 − 16)w1 + (15 − 18)w2 + (14 − 13)w3 = 3w1 − 3w2 + w3 ≤ 0

(5)

(6)

(7)

Substituting w3 = 1 − w1 − w2 allows us to plot these equations in two dimensions, see
Figure 1, where the three black lines indicate points where each of the equations in (5-7) is
fulﬁlled with equality.

The light gray area contains those vectors (w1, w2) ∈ [0, 1]2 that fulﬁll (5-7). As we only
consider non-increasing weights to reﬂect a risk-averse decision maker, we furthermore require
that w1 ≥ w2 ≥ w3. The dark gray area hence indicates the set W (cid:48).
In this example,
there is only one element in W (cid:48) that also fulﬁlls the system of equations (5-7), which is
Opt = {(1/2, 1/2, 0)}. In other words, Opt contains the only feasible preference vector that
leads to the observed choice of xxx.

In general, note that Opts is a bounded polyhedron if the number of feasible solutions |X |
is ﬁnite. For multiple observations S > 1, it is possible that the intersection ∩s∈[S] Opts is
empty. This may happen if there is no underlying ”true” value for www that the decision maker
uses; decisions may be made intuitively, rather than systematically. For this reason, we would
like to ﬁnd a value of www that is as close as possible to those values Opts that can explain each
observation. It may also happen that for some s ∈ [S], Opts = ∅, i.e., there is no possible
preference vector that can explain a speciﬁc choice. In this case, Problem (Pref) needs to

5

Figure 1: Areas for preference vectors in the example problem.

be slightly modiﬁed, which is explained later in this section. Also note that while (Pref) is
deﬁned using the same set X for each observation s, this assumption might also be relaxed to
allow diﬀerent sets of feasible solutions for each decision making observation. We only require
that there is the same number of scenarios K for each problem, so that vectors www are of the
same dimension.

We now discuss how to solve Problem (Pref). For each xxx ∈ X , let us denote by as

1(xxx), . . . , as
the objective values Csxxx, sorted from largest to smallest value. Using this notation, we have

K(xxx)

Opts =




www ∈ W (cid:48) :



(cid:88)

k∈[K]

wkas

k(xxxs) ≤

(cid:88)

k∈[K]

wkas

k(xxx) ∀xxx ∈ X






This allows us to rewrite Problem (Pref) as follows:

(cid:88)

s∈[S]
(cid:88)

min

s.t.

d(www, wwws)

wkas

k(xxxs) ≤

k∈[K]
(cid:88)

k∈[K]
(cid:88)

ws

k = 1

wk = 1

(cid:88)

k∈[K]

wkas

k(xxx)

k∈[K]
2 ≥ . . . ws
1 ≥ ws
ws
K ≥ 0
w1 ≥ w2 ≥ . . . wK ≥ 0

∀s ∈ [S], xxx ∈ X

∀s ∈ [S]

∀s ∈ [S]

(8)

(9)

(10)

(11)

(12)

(13)

Note that the constraints (9-13) are linear, as values as
k(xxx) can be precomputed. However,
depending on the number of elements in X , there my be inﬁnitely or exponentially many
constraints of type (9).

6

(5)(6)(7)k ≤ wk − ws

Considering the distance d, several choices result in tractable optimization problems. Using
the 1-norm, objective function (8) can be linearized by introducing new variables ds
k ≥ 0 with
(cid:80)
constraints −ds
k∈[K] ds
k,
we hence minimize the sum of absolute diﬀerences in each component. It is also possible to
use weights on positions k ∈ [K], e.g., one unit of diﬀerence in w1 may be more important
than one unit of diﬀerence in wK. Alternatively, also the ∞-norm can be linearized, while
using the 2-norm results in a convex quadratic optimization problem.

k for all s ∈ [S] and k ∈ [K]. By minimizing (cid:80)

k ≤ ds

s∈[S]

We now discuss how to treat the large number of constraints of type (9). We propose to

use an iterative solution procedure that is summarized in Figure 2.

Figure 2: Iterative solution algorithm for (Pref).

We begin with a ﬁnite subset of alternatives X (cid:48) ⊆ X , for example, we may set X (cid:48) =
{xxx1, . . . , xxxS}. We solve the optimization problem (Pref), where we restrict constraints (9)
to X (cid:48). We refer to this problem as Pref(X (cid:48)). This is a linear program, given that d can
be linearized. The result is a candidate preference vector www ∈ W (cid:48), along with preference
vectors wwws for each s ∈ [S]. We then consider each s ∈ [S] separately to check if indeed
it holds that wwws ∈ Opts. To this end, we need to compare the value OWAwwws(xxxs, Cs) with
minxxx∈X OWAwwws(xxx, Cs). If it turns out that there exists a solution that results in a better
objective value than xxxs under wwws, we add this solution to X (cid:48) and repeat the process.

Note that this solution method ends after a ﬁnite number of iterations, if X is ﬁnite. This
holds, e.g., if X ⊆ {0, 1}n is the set of feasible solutions for a combinatorial optimization
problem. In this case, we have found an optimal solution to (Pref). Alternatively, we may
stop the method after a ﬁxed number of iterations is reached or if the diﬀerence between
consecutive solutions for www becomes suﬃciently small.

To conclude the description of our approach, we consider the case that Opts = ∅ for
some s ∈ [S], i.e., the decision maker chooses a solution that is optimal with respect to no
preference vector in W (cid:48). This means that some model Pref(X (cid:48)) that we try to solve in the
iterative procedure becomes infeasible. In that case, we can follow a lexicographic approach
to consider those preferences wwws that remain as close to optimality as possible. To this end,
we solve the optimization problem

Inf s := max
www∈W (cid:48)

min
xxx∈X

(cid:16)

OWAwww(xxx, Cs) − OWAwww(xxxs, Cs)

(cid:17)

(14)

to calculate the smallest possible violation of the corresponding constraint (9). We then

7

replace the constraint with
(cid:88)

k∈[K]

wkas

k(xxxs) ≤

(cid:88)

k∈[K]

wkas

k(xxx) + Inf s

∀xxx ∈ X

to ensure feasibility of Problem (Pref). To solve the problem in (14), we can use an iterative
procedure analogously to the method described in Figure 2. Alternatively, Inf s is used as
an additional non-negative variable in Problem (Pref), where we modify the objective to
additionally minimize (cid:80)
s∈[S] Inf s with a large weight to give it priority over minimizing the
sum of distances in the preference vectors.

3.2 Alternative Model Formulation

In the preference elicitation model (Pref), we minimize the distance in preference vectors www.
Alternatively, it is possible to consider how diﬀerent optimal solutions are. For example, it
may be possible that with a slight modiﬁcation of www, the optimal solution changes dramati-
cally; on the other hand, it is also possible that very diﬀerent vectors www result in only slightly
diﬀerent optimal solutions.

In this sense, we may redeﬁne our model as follows. The set of optimal solutions for a given

preference vector www is denoted as

Opt(cid:48)

s(www) =

(cid:110)
yyy ∈ X : OWAwww(yyy, Cs) ≤ OWAwww(xxx, Cs) ∀xxx ∈ X

(cid:111)
,

that is, while Opts is a subset of RK, we now consider a subset of the set of feasible solutions
X . The modiﬁed preference elicitation model now asks for a vector www ∈ W (cid:48) such that the
s(www) are close to the given solutions xxxs in a distance metric d(cid:48) : X × X → R+. We
sets Opt(cid:48)
thus deﬁne the following problem:

min




(cid:88)



s∈[S]

d(cid:48)(yyys, xxxs) : www ∈ W (cid:48), yyys ∈ Opt(cid:48)

s(www) ∀s ∈ [S]






(Pref’)

To solve this problem, we need a tractable formulation of constraints

yyys ∈ Opt(cid:48)

s(www) ∀s ∈ [S],

which are equivalent to

(cid:88)

k∈[K]

wkas

k(yyys) ≤

(cid:88)

k∈[K]

wkas

k(xxx) ∀xxx ∈ X , s ∈ [S].

(15)

1(yyys) ≥ . . . ≥ as

K(yyys) give a worst-case sorting of the objective values of yyys in
The values as
observation s. Hence, we must ensure that the left-hand side value of equation (15) is not
underestimated. Using the assumption that www ∈ W (cid:48), we have the equivalent formulation
(cid:88)

(cid:88)

wkcccs,kyyys ≤

wkas

k(xxx) ∀xxx ∈ X , s ∈ [S].

max
π∈ΠK

k∈[K]

k∈[K]

Applying the same dualization technique as in the OWA reformulation in (1-4), we introduce
new variables αααs and βββs to reformulate Problem (Pref’) as follows.

min

(cid:88)

s∈[S]

d(cid:48)(yyys, xxxs)

(16)

8

(cid:88)

s.t.

k + βs
αs

k ≤

(cid:88)

wkas

k(xxx)

k∈[K]
j + βs
αs

k ≥

k∈[K]
wjcs,k

i ys
i

(cid:88)

i∈[n]

yyys ∈ X
(cid:88)

wk = 1

k∈[K]

w1 ≥ w2 ≥ . . . ≥ wK ≥ 0

∀xxx ∈ X , s ∈ [S]

∀s ∈ [S], j, k ∈ [K]

∀s ∈ [S]

(17)

(18)

(19)

(20)

(21)

As before, values as
k(xxx) can be precomputed for a given xxx. To treat the potentially exponential
or inﬁnite number of constraints in (17), an iterative solution method analogous to the one
presented in Section 3.1 can be applied. If X is the set of feasible solutions of a combinatorial
decision making problem, then we can linearize products wjys
i by introducing additional
variables τ s
i − 1. In this case, a natural choice for a distance measure
d(cid:48) may be the Hamming distance, where we simply count the number of diﬀering entries. In
our notation, this means we minimize

ji ≥ 0 with τ s

ji ≥ wj + ys

d(cid:48)(yyys, xxxs) =

(cid:88)

(1 − ys

i ) +

(cid:88)

ys
i

i∈[n]:xs

i =1

i∈[n]:xs

i =0

which implies that Problem (Pref’) can be solved through a sequence of mixed-integer pro-
gramming formulations.

3.3 Heuristic Model

We now reconsider model (Pref) and develop a heuristic formulation for the case that X is
given by a polyhedron, i.e., we assume that X = {xxx ≥ 0 : Axxx ≥ bbb} for A ∈ Rm×n and
bbb ∈ Rm. Recall that some combinatorial optimization problems, such as the shortest path or
the minimum spanning tree problems, also allow for such linear programming formulations
where binary variables are not required.

Constraints (9) ensure for each s ∈ [S] that solutions xxxs are indeed optimal, that is, they

are equivalent to

OWAwww(xxxs) ≤ min
xxx∈X

OWAwww(xxx)

Previously, we treated the right-hand side by constructing one constraint per solution xxx ∈ X .
As X is a polyhedron, we can use strong duality to reformulate the right-hand side as a
maximization problem with the same optimal objective value. Furthermore, by weak duality,
the objective value of any feasible solution to the dual problem gives a lower bound to the
optimal primal objective value. The dual of OWA problem with costs Cs, see (1-4), is given
as:

max bbbtσσσ

s.t.

(cid:88)

k∈[K]
(cid:88)

j∈[K]

πjk = 1

πjk = 1

9

∀j ∈ [K]

∀k ∈ [K]

Atσσσ ≤

(cid:88)

(cid:88)

ws

jcccs,kπjk

j∈[K]

k∈[K]

σσσ ≥ 000
πππ ≥ 000

We can thus ﬁnd the following compact reformulation of model (Pref).

(cid:88)

s∈[S]
(cid:88)

min

s.t.

d(www, wwws)

ws

kas

k(xxxs) ≤ bbbtσσσs

k∈[K]
(cid:88)

k∈[K]
(cid:88)

πs
jk = 1

πs
jk = 1

j∈[K]
Atσσσs ≤

(cid:88)

(cid:88)

ws

jcccs,kπjk

j∈[K]

k∈[K]

www ∈ W (cid:48)
wwws ∈ W (cid:48)
σσσs ≥ 000
πππs ≥ 000

∀s ∈ [S]

∀j ∈ [K], s ∈ [S]

∀k ∈ [K], s ∈ [S]

∀s ∈ [S]

∀s ∈ [S]

∀s ∈ [S]

∀s ∈ [S]

Note that there remains a non-linearity in the product ws
tinuous. Using McCormick envelopes, we may substitute τ s
jk ≤ ws
τ s
heuristic but has the advantage of avoiding the iterative solution method.

j πjk, where both variables are con-
j πjk with the constraints
jk ≤ πjk. As this is not an equivalent reformulation, the resulting model is

k and τ s

jk = ws

4 Machine Learning for Preference Elicitation

We now consider the use of machine algorithms to predict a preference vector www. As in
Section 3, we assume that S pairs of observations (C1, xxx1), . . . , (CS, xxxS) are given. We would
like to construct a function that maps these observations to a vector in W (cid:48).

Note that the observations are the input to our prediction function, but not the training
set in the sense of machine learning. To generate training data, we can generate an arbitrary
size of data points by randomly sampling optimization problems (given by matrix C) and
preference vectors www ∈ W (cid:48), and solving the resulting OWA-problems to ﬁnd optimal solutions
xxx.

As the number of observations S may vary, we would like to construct predictors that do
not require a ﬁxed input size. One way to do so is to use neural networks with long short-
term memory (LSTM). Alternatively, we may simply predict each pair (Cs, xxxs) separately
and average results, i.e., we train a function f : RK×n × Rn → W (cid:48), (C, xxx) (cid:55)→ www and use this
function to predict a weight www = (cid:80)
s∈[S] f (Cs, xxxs)/S. Note that W (cid:48) is a convex set; hence,
the average of preference vectors is also in W (cid:48). Using C and xxx directly as input to f has
drawbacks, as rows in C may be given in arbitrary order and so do columns in C if entries

10

in xxx are permuted accordingly. As an alternative, we only give the ordered objective values
a1(xxx) ≥ . . . ≥ aK(xxx) as a K-dimensional input to the predictor, as it contains the key piece
of information (balancing of objective values) and has a unique sorting.

To model a mapping to an element in W (cid:48), we consider two approaches. As a ﬁrst approach,
we predict each of the K components of www with a multi-regressor function and then normalize
Instead of
these values so that they sum to one and are sorted from largest to smallest.
predicting each component value directly, we predict its logarithm to prevent negative values.
As a second approach, we use a subset of W (cid:48) that can be parameterized by a one-dimensional
value. While this has the disadvantage that not all possible vectors in W (cid:48) can be output of
our predictor (i.e., f is not surjective), the advantage is that we only need to predict this one
value instead of K values, also eliminating the need to normalize and sort. To this end, we
use the generator functions proposed in [KZ16]. For α ∈ (0, 1), we deﬁne

gα(z) =

1
1 − α

(1 − αz),

which is a concave function with gα(0) = 0 and gα(1) = 1. Weights www(α) are then given by
wk(α) = gα(j/K) − gα((j − 1)/K) for j ∈ [K]. Note that each preference vector generated
this way is indeed in W (cid:48) due to the concavity of gα. The value α reﬂects the risk attitude of
the decision maker; the closer α to zero is, the more weight is on the ﬁrst entries of www. As
before, we predict the logarithm of α instead of α directly.

In total, this gives the following combinations of methods: To generate training data, we
can sample preference vectors www from W (cid:48) or sample generator parameters α from (0, 1). To
sample α, we may use a continuous distribution over the interval, or a discrete distribution.
To model predictor functions, we can either predict each component of wk and subsequently
normalize, or predict a generating value α. This prediction of α can by regression to ﬁnd a
value in the interval (0, 1), or by a classiﬁcation approach to determine one value of a discrete
choice of representative values. There remains leeway on the decision which method from
machine learning is used to this purpose. Through preliminary testing, we decided to use
deep neural networks, but other methods such as decision trees are conceivable as well.

5 Computational Experiments

5.1 Setup

The purpose of these experiments is to evaluate the degree to which decision maker prefer-
ences can be identiﬁed based on observations using the optimization and machine learning
approaches proposed in this paper.

We consider simple selection problems, where p out of n items must be chosen, i.e., X =
{xxx ∈ {0, 1}n : (cid:80)
i∈[n] xi = p}. Problems of this type are frequently considered, see, e.g.,
[CGKZ18], and have the advantage that the decision maker is mostly unconstrained in her
choice of items, which means that the underlying preference becomes more important in the
decision making process. In our experiments, we chose n = 40, p = 20 with K = 5 objectives.
Preference vectors www are generated in three diﬀerent ways. For vectors of ”uniform” type,
we sample each wk value uniformly from [0, 1], then normalize and sort the vector. For
preference vectors of ”uniform α” type, we choose a random value a uniformly in [−4, −1]
and use the gα generator functions described in Section 4 with α = 10a. Finally, for ”discrete
α” preference vectors, the value a is chosen uniformly over {−4, −3, −2, −1}.

11

To test our methods, we create 1,000 preference vectors of each type. For each preference
vector, we sample 32 cost matrices C and solve the resulting OWA problems to ﬁnd the
corresponding solutions xxx. These will be used as observations for values S from 1 up to
32. To sample cost matrices, each entry in C is generated uniformly as a random integer in
[1, 100]. Additionally, we incorporate the setting that the decision maker may slightly deviate
from her underlying preference vector for each decision. To model this behavior, we include a
noise parameter (cid:15). When solving an OWA problem, we modify each value of www by multiplying
with a uniformly random value in [1 − (cid:15), 1 + (cid:15)]. Afterwards, www is normalized and sorted. We
create 1,000 times 32 observations using (cid:15) in {0.0, 0.1, 0.3}.

The machine learning model also requires training data (recall that this is not the case for
the optimization model). To generate training data, we create 32,000 random instances for
each of the three types of www value. We train two types of neural networks. In the ”regression”
approach, we predict the exponent log10 α as a continuous value. In the ”multi-regression”
approach, we predict a K-dimensional vector, take the logarithm in each component, normal-
ize and sort to predict www without generator functions gα. Each type of network is trained on
each training dataset. To train the regression approach on uniform-type preference vectors,
we approximate them using the closest possible vector generated by function gα. Neural net-
works have ﬁve hidden layers with 50 nodes each. For this machine learning approach, we
use the MLPRegressor function from the python sklearn package with default parameters.
As training neural networks is a randomized algorithm, we repeat the process 10 times and
average prediction performance.

For the optimization approach, we implemented the iterative method presented in Sec-
tion 3.1 to solve model (Pref) with the 1-norm as distance measure. The method was imple-
mented in C++ using CPLEX version 12.8 to solve optimization models.

To evaluate the quality of our methods, we compare the diﬀerence between the predicted

preference vector and the actual preference vector in the 2-norm.

5.2 Results

We ﬁrst present the comparison between the optimization model and the regression machine
learning approach, where we predict one-dimensional α-values, in Figure 3. On the logarithmic
horizontal axis we show the value S, i.e., how many of the 32 observations we generated where
available. On the vertical axis we show the average distance of the predicted preference vector
to the actual preference vector. The black line shows the performance of the optimization
model, while the red, blue, and orange line show the performance of the regression machine
learning approach trained with discrete α (DA), uniform α (UA) and uniform (UW) data,
respectively. Dashed lines indicate the 30% and 70% quantiles over the 10 repetitions for the
training of neural networks. Additionally, the green line indicates the distance we achieve if
we always just predict the average preference vector of the training dataset that corresponds
to the test dataset.

We ﬁrst consider Figure 3(a). This plot shows the performance when the actual preference
vector is of discrete α type. All observations are made with the original preference vector,
i.e., no noise is added ((cid:15) = 0). We see that regression models trained on DA and UA
outperform the regression model trained on UW. Also, they consistently outperform the
average prediction over the discrete α dataset. Further note that the lines corresponding to
machine learning models run mostly horizontally, which means that additional observations
only very slightly improve the prediction performance. Contrast this with the performance

12

(a) Discrete α, (cid:15) = 0.0

(b) Discrete α, (cid:15) = 0.1

(c) Discrete α, (cid:15) = 0.3

(d) Uniform α, (cid:15) = 0.0

(e) Uniform α, (cid:15) = 0.1

(f) Uniform α, (cid:15) = 0.3

(g) Uniform, (cid:15) = 0.0

(h) Uniform, (cid:15) = 0.1

(i) Uniform, (cid:15) = 0.3

Figure 3: Regression results

of the optimization model. If there are only few observations available, the set of preference
vectors that lead to the same decisions can be large. The optimization model will choose an
arbitrary such vector, which explains the relatively bad performance for small values of S.
Once the number of observations is suﬃciently large (in this case, around 16), the optimization
model outperforms the machine learning approaches. Note that these approaches have an
advantage, as they always predict a preference vector of the same type as the test data.

Considering the further results in Figure 3, we see that the performance for discrete and
uniform α test data is similar. For uniform-type preference vectors, the machine learning
model that has been trained on such data performs better, as can be expected. For high error
rates in the given observations (right column of plots with (cid:15) = 0.3), we can observe the eﬀect
that the performance of models does not necessarily improve with more observations.

In Figure 4, we present the results for multi-regression machine learning models. The black
line indicating the performance of the optimization model and the green line for the average
prediction remain the same as in Figure 3.

Recall that the multi-regression approach can predict any vector in W (cid:48) instead of only those
that are generated by gα functions. Hence it can be expected that on discrete and uniform

13

 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 1 2 4 8 16 32preference vector distanceSoptimizationregression (DA)regression (UA)regression (UW)average 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 1 2 4 8 16 32preference vector distanceSoptimizationregression (DA)regression (UA)regression (UW)average 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 1 2 4 8 16 32preference vector distanceSoptimizationregression (DA)regression (UA)regression (UW)average 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 1 2 4 8 16 32preference vector distanceSoptimizationregression (DA)regression (UA)regression (UW)average 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 1 2 4 8 16 32preference vector distanceSoptimizationregression (DA)regression (UA)regression (UW)average 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 1 2 4 8 16 32preference vector distanceSoptimizationregression (DA)regression (UA)regression (UW)average 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 1 2 4 8 16 32preference vector distanceSoptimizationregression (DA)regression (UA)regression (UW)average 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 1 2 4 8 16 32preference vector distanceSoptimizationregression (DA)regression (UA)regression (UW)average 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 1 2 4 8 16 32preference vector distanceSoptimizationregression (DA)regression (UA)regression (UW)average(a) Discrete alpha, (cid:15) = 0.0

(b) Discrete alpha, (cid:15) = 0.1

(c) Discrete alpha, (cid:15) = 0.3

(d) Uniform alpha, (cid:15) = 0.0

(e) Uniform alpha, (cid:15) = 0.1

(f) Uniform alpha, (cid:15) = 0.3

(g) Uniform, (cid:15) = 0.0

(h) Uniform, (cid:15) = 0.1

(i) Uniform, (cid:15) = 0.3

Figure 4: Multi-regression results

α datasets, the multi-regression approach will perform worse. In fact, this can be conﬁrmed
in the results (e.g., compare Figure 4(a) with Figure 3(a). Even for uniform data, we ﬁnd
that only the best predictors (see lower dashed quantile line) can have an advantage over the
regression approach.

5.3 Insights

Our experiments show that already with few observations, it is possible to identify the un-
derlying preference vector with reasonable preciseness using model (Pref). For example, with
only two observations the average Euclidean distance between the predicted and the actual
preference vector on the uniform dataset is about 0.2. This is the same distance as between the
vectors (0.4, 0.3, 0.2, 0.1, 0.0) and (0.5, 0.2, 0.1, 0.1, 0.1). More observations lead to a further
increase in accuracy.

To better understand this behavior, we consider the following small experiment. We gen-
erate 1000 random problems of the same size as before, each with uniform type preference
vectors. For each instance, we sample 1000 additional random preference vectors and check

14

 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 1 2 4 8 16 32preference vector distanceSoptimizationregression (DA)regression (UA)regression (UW)average 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 1 2 4 8 16 32preference vector distanceSoptimizationregression (DA)regression (UA)regression (UW)average 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 1 2 4 8 16 32preference vector distanceSoptimizationregression (DA)regression (UA)regression (UW)average 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 1 2 4 8 16 32preference vector distanceSoptimizationregression (DA)regression (UA)regression (UW)average 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 1 2 4 8 16 32preference vector distanceSoptimizationregression (DA)regression (UA)regression (UW)average 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 1 2 4 8 16 32preference vector distanceSoptimizationregression (DA)regression (UA)regression (UW)average 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 1 2 4 8 16 32preference vector distanceSoptimizationregression (DA)regression (UA)regression (UW)average 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 1 2 4 8 16 32preference vector distanceSoptimizationregression (DA)regression (UA)regression (UW)average 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 1 2 4 8 16 32preference vector distanceSoptimizationregression (DA)regression (UA)regression (UW)averageif this preference vector can explain the given observations, in other words, we check if this
random vector is a solution to (Pref) with objective value zero. Figure 5 shows the aver-
age percentage of random vectors where this is the case, depending on the given number of
observations S. Note the logarithmic horizontal axis.

Figure 5: Fraction of random www vectors that are optimal for (Pref).

We see that for small values S, a relatively large proportion of random preference vectors
are able to explain all given observations. The optimization model has no further structural
guidance to diﬀerentiate between these candidate solutions. As S increases, this proportion
rapidly declines (for S = 9, less than one percent of random vectors remain optimal).

While the optimization model does not make structural assumptions on www (apart from being
non-increasing), the machine learning models can reach better predictions for small numbers
of observations if they are trained on data where preference vectors have the same structure as
in the test set. This means that if additional structural information about the true preference
vector is known, it can be incorporated to further improve predictions. Comparing the two
machine learning methods tested in the experiments, there are more advantages to predicting
a one-dimensional value that parameterizes a subset of preference vectors, than to predicting
the 5-dimensional preference vector directly.

6 Conclusions and Further Research

The ordered weighted averaging (OWA) criterion is a popular method to aggregate the per-
formance of a solution over multiple objectives or scenarios. This aggregation is controlled
by a vector www which is used to express the decision maker’s preference. Some well-known
and often-used preference vectors can be used to model the worst-case, best-case, average,
median, or conditional value at risk criteria. But going beyond these standard vectors, a
strength of the OWA criterion is that it also allows for a more nuanced reﬂection of decision
maker preferences. A crucial question then becomes: how can we express this preference
through the vector www?

One way to approach this question is to prepare a catalog of questions to elicit preferences.
A drawback of such a method is that it requires interaction with the decision maker. Further-
more, the decision situations such a catalog models are often artiﬁcial and do not necessarily

15

 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 1 2 4 8 16 32ratio of optimal preference vectorsSreﬂect the way a decision is being made for the problem at hand. Other approaches assume
observations of historic OWA values, but it is unclear how these should be computed without
having a preference vector already available.

In this paper we propose a new and indirect approach to elicit preferences.

Instead of
asking questions to the decision maker, we observe her preferred choice on a set of example
problems which may have come from previous rounds of decision making. Using this set of
observations, we then ﬁnd a preference vector that is able to explain these choices.

To construct this vector, we propose the use of an optimization model. As the model has a
large number of constraints, it can be approached through an iterative solution method, where
we alternate between solving a linear program to determine www and solving OWA problems to
check its feasibility. Furthermore, we show how machine learning methods may be used as an
alternative method to determine www based on given observations.

In computational experiments, we compared the performance of these methods to elicit
preferences for a selection problem. Our results indicate that if the number of observations is
suﬃciently large (up to a maximum of 32 observations in our experiments), the optimization
model is able to identify preference vectors that are very close to the ”true” vectors under-
lying the decisions. While machine learning models beneﬁt less from increasing numbers of
observations, they can give a high-quality guess already with few observations.

In further research, a study to test our preference elicitation approach with real-world
decision makers will be a valuable addition, see, e.g. the recent study [RSV17]. Note that
such an experiment is not trivial, as the ”true” preference of a decision maker cannot be
determined. Furthermore, our philosophy may be applied to other decision making criteria.
In particular the weighted ordered weighted averaging (WOWA) criterion seems a natural
choice as a generalization of the OWA criterion considered in this paper, see [O´S09].

References

[AD21]

Lo¨ıc Adam and S´ebastien Destercke. Possibilistic preference elicitation by mini-
max regret.
In Uncertainty in Artiﬁcial Intelligence, pages 718–727. PMLR,
2021.

[Ahn08]

Byeong Seok Ahn. Preference relation approach for obtaining OWA operators
weights. International Journal of Approximate Reasoning, 47(2):166–178, 2008.

[BGPV15] Nawal Benabbou, Christophe Gonzales, Patrice Perny, and Paolo Viappiani.
Minimax regret approaches for preference elicitation with rank-dependent ag-
gregators. EURO Journal on Decision Processes, 3(1):29–64, 2015.

[CC11]

[CG15]

Kuei-Hu Chang and Ching-Hsue Cheng. Evaluating the risk of failure using
the fuzzy OWA and DEMATEL method. Journal of Intelligent Manufacturing,
22(2):113–129, 2011.

Andr´e Chassein and Marc Goerigk. Alternative formulations for the ordered
weighted averaging objective. Information Processing Letters, 115(6-8):604–608,
2015.

[CGKZ18] Andr´e Chassein, Marc Goerigk, Adam Kasperski, and Pawe(cid:32)l Zieli´nski. On re-
coverable and two-stage robust selection problems with budgeted uncertainty.
European Journal of Operational Research, 265(2):423–436, 2018.

16

[CGKZ20] Andr´e Chassein, Marc Goerigk, Adam Kasperski, and Pawe(cid:32)l Zieli´nski. Approxi-
mating combinatorial optimization problems with the ordered weighted averaging
criterion. European Journal of Operational Research, 286(3):828–838, 2020.

[Ehr05]

Matthias Ehrgott. Multicriteria optimization, volume 2. Springer, 2005.

[EM14]

[FM01]

[FY94]

Ali Emrouznejad and Marianna Marra. Ordered weighted averaging operators
1988–2014: A citation-based literature survey. International Journal of Intelli-
gent Systems, 29(11):994–1014, 2014.

Robert Full´er and P´eter Majlender. An analytic approach for obtaining maximal
entropy OWA operator weights. Fuzzy Sets and Systems, 124(1):53–57, 2001.

Dimitar Filev and Ronald R Yager. Learning OWA operator weights from data.
In Proceedings of 1994 IEEE 3rd International Fuzzy Systems Conference, pages
468–473. IEEE, 1994.

[FY98]

Dimitar Filev and Ronald R Yager. On the issue of obtaining OWA operator
weights. Fuzzy Sets and Systems, 94(2):157–169, 1998.

[GLLP11]

Jos´e Luis Garc´ıa-Lapresta, Bonifacio Llamazares, and Teresa Pena. Generat-
ing OWA weights from individual assessments. In Recent Developments in the
Ordered Weighted Averaging Operators: Theory and Practice, pages 135–147.
Springer, 2011.

[GS12]

[KA18]

[KZ15]

[KZ16]

[Liu11]

Lucie Galand and Olivier Spanjaard. Exact algorithms for OWA-optimization
in multiobjective spanning tree problems. Computers & Operations Research,
39(7):1540 – 1554, 2012.

Eun Young Kim and Byeong Seok Ahn. Implicit elicitation of attitudinal charac-
ter in the OWA operator. International Journal of Intelligent Systems, 33(2):281–
287, 2018.

Adam Kasperski and Pawe(cid:32)l Zieli´nski. Combinatorial optimization problems with
uncertain costs and the OWA criterion. Theoretical Computer Science, 565:102–
112, 2015.

Adam Kasperski and Pawe(cid:32)l Zieli´nski. Using the WOWA operator in robust
discrete optimization problems. International Journal of Approximate Reasoning,
68:54–67, 2016.

Xinwang Liu. A review of the OWA determination methods: Classiﬁcation and
In Recent Developments in the Ordered Weighted Averaging
some extensions.
Operators: Theory and Practice, pages 49–90. Springer, 2011.

[LMD15]

Christophe Labreuche, Brice Mayag, and Bertrand Duqueroie. Extension of the
MACBETH approach to elicit an ordered weighted average operator. EURO
Journal on Decision Processes, 3(1):65–105, 2015.

[LXLC20] Mingwei Lin, Wenshu Xu, Zhanpeng Lin, and Riqing Chen. Determine OWA
operator weights using kernel density estimation. Economic Research-Ekonomska
Istraˇzivanja, 33(1):1441–1464, 2020.

17

[Mal06]

[MC11]

Jacek Malczewski. Ordered weighted averaging with fuzzy quantiﬁers: GIS-based
multicriteria evaluation for land-use suitability analysis. International Journal
of Applied Earth Observation and Geoinformation, 8(4):270–277, 2006.

Jos´e M Merig´o and Montserrat Casanovas.
Induced aggregation operators in
the euclidean distance and its application in ﬁnancial decision making. Expert
Systems with Applications, 38(6):7603–7608, 2011.

[Mer10]

Jos´e M Merig´o. Fuzzy decision making with immediate probabilities. Computers
& Industrial Engineering, 58(4):651–657, 2010.

[MGL09]

Jos´e M Merig´o and Anna M Gil-Lafuente. The induced generalized OWA oper-
ator. Information Sciences, 179(6):729–741, 2009.

[O’H88]

[OO12]

[O´S03]

[O´S09]

[RSV17]

[WLH07]

[Xu05]

[YA16]

[Yag88]

Michael O’Hagan. Aggregating template or rule antecedents in real-time expert
systems with fuzzy set logic. In Twenty-second asilomar conference on signals,
systems and computers, volume 2, pages 681–689. IEEE, 1988.

W(cid:32)lodzimierz Ogryczak and Pawe(cid:32)l Olender. On MILP models for the OWA op-
timization. Journal of Telecommunications and Information Technology, pages
5–12, 2012.

W(cid:32)lodzimierz Ogryczak and Tomasz ´Sliwi´nski. On solving linear programs with
the ordered weighted averaging objective. European Journal of Operational Re-
search, 148(1):80–91, 2003.

W(cid:32)lodzimierz Ogryczak and Tomasz ´Sliwi´nski. On eﬃcient WOWA optimization
for decision support under risk. International Journal of Approximate Reasoning,
50(6):915 – 928, 2009. Ninth European Conference on Symbolic and Quantitative
Approaches to Reasoning with Uncertainty (ECSQARU 2007).

Olivier Reimann, Christian Schumacher, and Rudolf Vetschera. How well does
the OWA operator represent real preferences? European Journal of Operational
Research, 258(3):993–1003, 2017.

Ying-Ming Wang, Ying Luo, and Zhongsheng Hua. Aggregating preference rank-
ings using OWA operator weights.
Information Sciences, 177(16):3356–3363,
2007.

Zeshui Xu. An overview of methods for determining OWA weights. International
Journal of Intelligent Systems, 20(8):843–865, 2005.

Ronald R Yager and Naif Alajlan. Some issues on the OWA aggregation with
importance weighted arguments. Knowledge-Based Systems, 100:89–96, 2016.

Ronald R. Yager. On ordered weighted averaging aggregation operators in multi-
criteria decisionmaking. Systems, Man and Cybernetics, IEEE Transactions on,
18(1):183–190, 1988.

[Yag96]

Ronald R Yager. Quantiﬁer guided aggregation using OWA operators. Interna-
tional Journal of Intelligent Systems, 11(1):49–73, 1996.

18

[Yag98]

Ronald R Yager. Including importances in OWA aggregations using fuzzy systems
modeling. IEEE Transactions on Fuzzy Systems, 6(2):286–294, 1998.

[ZAKL+19] Hasan Zabihi, Mohsen Alizadeh, Philip Kibet Langat, Mohammadreza Karami,
Himan Shahabi, Anuar Ahmad, Mohamad Nor Said, and Saro Lee. GIS multi-
criteria analysis by ordered weighted averaging (OWA): toward an integrated
citrus management strategy. Sustainability, 11(4):1009, 2019.

19

