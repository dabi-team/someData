Noname manuscript No.
(will be inserted by the editor)

Adversarial Genetic Programming for Cyber
Security: A Rising Application Domain Where GP
Matters

Una-May O’Reilly · Jamal Toutouh ·
Marcos Pertierra · Daniel Prado
Sanchez · Dennis Garcia · Anthony Erb
Luogo · Jonathan Kelly · Erik Hemberg

Received: date / Accepted: date

Abstract Cyber security adversaries and engagements are ubiquitous and
ceaseless. We delineate Adversarial Genetic Programming for Cyber Security,
a research topic that, by means of genetic programming (GP), replicates and
studies the behavior of cyber adversaries and the dynamics of their engage-
ments. Adversarial Genetic Programming for Cyber Security encompasses ex-
tant and immediate research eﬀorts in a vital problem domain, arguably oc-
cupying a position at the frontier where GP matters. Additionally, it prompts
research questions around evolving complex behavior by expressing diﬀerent
abstractions with GP and opportunities to reconnect to the Machine Learn-
ing, Artiﬁcial Life, Agent-Based Modeling and Cyber Security communities.
We present a framework called RIVALS which supports the study of network
security arms races. Its goal is to elucidate the dynamics of cyber networks
under attack by computationally modeling and simulating them.

Keywords Genetic programming · Coevolutionary algorithms · Cyber
Security

Una-May O’Reilly
MIT CSAIL
Tel.: +617-253-6437
Fax: +123-45-678910
E-mail: unamay@csail.mit.edu

Erik Hemberg
MIT CSAIL
Tel.: +123-45-678910
Fax: +123-45-678910
E-mail: hembergerik@gmail.com

0
2
0
2

r
p
A
7

]

R
C
.
s
c
[

1
v
7
4
6
4
0
.
4
0
0
2
:
v
i
X
r
a

 
 
 
 
 
 
2

1 Introduction

Una-May O’Reilly et al.

The natural world yields many examples of adversarial advantages arising
through evolution. These are testaments to biological arms races that have
played out with complex dynamics, typically over macroscopic time scales.
There is a wide range of advantages evolved by predators and prey includ-
ing examples of animal coloration – camouﬂage that is static such as the
yellow crab spider (Misumena vatia) and dynamic such as the cuttleﬁsh (see
Fig. 1a,1b), bioluminescence (e.g. mid-water crustaceans and ﬁreﬂies, Fig 1e,1f),
and mimicry (e.g. the Monarch and Viceroy butterﬂies, Fig 1c,1d).

Contemporary human-made ecosystems also yield arms races that arise
from adversarial competitions. In the U.S. automotive industry, ﬁrms engage
in an arms race to develop innovative new products ahead of the competi-
tion. The relationship between innovations and ﬁrm performance has been

(a) A spider(Misumena vatia) [138]

(b) Cuttleﬁsh [137]

(c) A Monarch butterﬂy [140]

(d) A Viceroy Butterﬂy [139]

(e) Fireﬂies [43]

(f) Fireﬂy squid [141], Appendix A.1.

Fig. 1: Adversarial defense and attack adaptions. Coloration adaptation – cam-
ouﬂage (a), (b) and biomimicry (c), (d). Bioluminescence defensive (e), (f).

Adversarial Genetic Programming for Cyber Security

3

analyzed from a coevolutionary perspective [133] (See Appendix A.2). The
circular economy and its related cradle-to-cradle idea describe manufacturer-
customer relationships that cooperatively evolve while business ecosystems
within the economy also evolve, though competitively [105]. In an example
from taxation, tax shelters prey upon unintended lapses of the tax code until
defensive mediations address them. On occasion, however, these mediations ei-
ther introduce new ambiguity or signal evaders to target a diﬀerent weakness
or ineﬃciency and the arms race continues [125,147].

One of the contemporary crucibles of adversarial activity and arms races
is cyberspace. It is a complex, human-made ecosystem that spans networks
(including the Internet), edge devices, servers, clouds, supercomputers. Each
sub-ecosystem has sets of resources that collectively are a source of contention.
Each includes human actors in circumstances where their software is proxy for
their part in cyber adversarial engagements. Actors can have conﬂicting ob-
jectives. From a security perspective one population of actors have benign
intentions and the other has malicious intentions. Benign “cyber actors” are
conforming within social and legal norms. They may control data which they
need to keep conﬁdential or private. They may operate networks, or websites
in order to conduct their enterprise’s business – digital commerce. Diﬀerent
devices e.g. cellphones and laptops support everyday social and economic func-
tions. Underpinning all these activities are computational hardware and soft-
ware. Through attacks on these resources, malicious actors seek to disrupt,
inﬁltrate and exﬁltrate to steal, poison, extort so they can proﬁt ﬁnancially
and advance their causes.

Focusing on network security, one pernicious kind of network attack is
named Denial of Service (DOS). The goal of a DOS attack is to consume
resources of a target so the target has none left to serve legitimate clients. At
the extreme end of the range of volume are Distributed DOS (DDOS) attacks.
These are extremely aggressive but more rare, likely due to the cost of setting
them up. At a technical level, DDOS attacks are composed from a software
toolkit. One set of software comprises multiple tactics that allow a network
of compromised servers, i.e. a botnet, to be stealthily established. Another
has tactics that enable, from a command and control location, a (human)
controller to direct the bots to launch DOS attacks. These tactics can even
react to defensive measures being deployed during an attack. The controller
strategically selects the tactics and aims them at a target.

It is arguable that DDOS attacks are analogous to population members of
a species, with tactical variation akin to biological variation. This population
arguably undergoes evolutionary adaptation because ineﬀective attacks are not
reused and eﬀective ones undergo adaptation in order to circumvent defensive
measures (i.e. reproductive selection and variation are present). With each new
generation of attacks, the defensive measures themselves adapt or evolve then
they face the next round of adaptation based on the toolkit. The attackers
general goal is to minimize its use of resources while maximizing its denial of
service and the defenders general goal is to minimize the impact of the attack.

4

Una-May O’Reilly et al.

Fig. 2: Time series of size of bots (number of unique IPs of the compromised
servers) in the MIRAI net. The size escalates prior to an attack. It plummets as
the attack is repelled but adaptations allow it to sustain its size then regrow [6],
modiﬁed for legibility [4].

In terms of dynamics, an escalating, adversarial arms race around engagements
based on the conﬂicting objectives consequently emerges.

There is reliable and thorough documented evidence of DDOS attacks and
counter measures that support an evolutionary interpretation, at a high level
of abstraction [10]. MIRAI [130] is a notorious DDOS, receiving publicity for
two high proﬁle attacks: Krebs [24] and DYN [118]. From its inception to the
present, MIRAI has adapted its tactics and targets to thwart defensive counter-
measures, see Fig. 2. Fig. 3 shows a Red Queen like DDOS dynamics – while
evolution is churning beneath the surface, the number of attacks and their
diversity of volume barely changes. Defensive gains are relative and transient.
DOS attacks sit amongst an alarming array of other cyber attack types,
such as Advanced Persistent Threats (APT) and Ransomware (see Ap-
pendix A.3) that exhibit intelligent and agile attacks as well as attack versus
defense arms race dynamics. Across the entire cyber ecosystem there is cease-
less evolution of kinds, arguably species, of attacks and co-evolving responses.
Beyond their inconvenience, attacks risk lives, have ﬁnancial costs, threaten
businesses, impinge upon privacy and disrupt legitimate activity.

One way to improve defenses requires understanding better how an attacker
behaves and how competing attacks and defenses react to one another. Feeding
back information on what could happen is extremely valuable. It elucidates
potential or past behaviors. For defensive design, knowing what could happen
can help by identifying unforeseen or particularly critical attacks. Knowledge
of arms race dynamics can inform the adversarially hardening of defensive
designs ahead of time.

Understanding what could happen requires examining, actually playing
out, or simulating, the dynamics of ongoing engagements between multiple
parties with varying behaviors. Genetic programming (GP) can meet these

Adversarial Genetic Programming for Cyber Security

5

Fig. 3: Evolution is churning underneath the surface where we see DDOS
attack densities over time, modiﬁed for legibility [5].

requirements. It is ideally suited to represent the behavior of an adversary
when it engages an opponent. Within a competitive evolutionary algorithm,
GP representations can serve as the units of its selection and variation and
GP operators can serve as the means of generating new solutions from existing
ones.

Cyber security needs a way of exploring and executing attack versus defense
engagements. GP is a paradigm that handles the performance selection and
variation of units that behave! It can explore by directly manipulating exe-
cutable functions without syntactic destruction or explicit program knowledge.
It can express behavioral solutions drawn from a search space of hierarchical,
varying length, executable structures and it has genetic operators that are
able to blindly, at the representation level, generate novel syntactically cor-
rect solutions. Cyber security needs an expressively powerful way to describe
abstracted attacks and defenses in a way that they are also able to actually
compete against each other. GP can fulﬁll this because it can accommodate
any abstraction that can be described as a set of functions and terminals or
a computational language expressed by a grammar.

Combinations of adversarial evolutionary algorithms and GP matched with
the rich problem domain of cyber security thus meld into an increasingly crit-
ical intersection with an agenda of compelling and still untapped scope, see
Fig. 4. We name this topic Adversarial Genetic Programming for Cyber Secu-
rity. It is not a new topic; it is the delineation of extant and current research
approaches. We call attention to them because cyber security is urgent and es-
calating in challenge, and despite contributions to date, many novel approaches
are required. At the 20 year mark of GP, when it is no longer necessary to
show that GP works, it is timely to direct mature and nascent GP methods
plus GP researchers in the direction of this critical domain with real world
problems. Can search-based software engineering techniques gain traction on

6

Una-May O’Reilly et al.

Fig. 4: Domain intersections of Adversarial Genetic Programming for Cyber
Security.

security exploits by considering adaptation at actual code level? Can GP en-
able the exploration of cyber space actors’ goals and resulting plans, thereby
addressing their intentions and cognitive reasoning? These questions and ones
in between represent an opportunity for GP research that matters.

Paper Roadmap Having motivated Adversarial Genetic Programming for
Cyber Security, in Section 2, we ﬁrst succinctly cover GP and evolutionary
algorithms (EAs). To consider adversarial evolution, we then describe com-
petitive coevolutionary algorithms to remind readers of their complexity. We
end the section by showing how GP and a coevolutionary algorithm can be
combined. In Section 3 we survey prior evolutionary computation research into
Artiﬁcial Intelligence (AI) and games (relevant because games are also com-
petitive contexts), and software engineering (related because tests have been
evolved to compete with program solutions to spur correctness). We then sur-
vey research around and within our central topic with Table 1 summarizing.
Sections 2 and 3 inform the design motivations underlying a framework we
present in Section 4. Named RIVALS , it combines competitive coevolutionary
algorithms and GP for network security design. We describe three systems
drawing on the framework and a component that extracts useful solutions to
support the design decisions of a network defense designer. We draw to a close
with a summary and a broad discussion of possible paths forward within this
exciting, important paradigm.

2 Basis Algorithms for Adversarial Evolution

Variable length genotypes, such as the hierarchical tree structures introduced
by Koza [69], deﬁne large search spaces and improve the ﬂexibility and power
of Evolutionary Algorithms conducted by executable structure search [67,100].
GP is arguably deﬁned by its distinctive structures that are variable length
and executable plus its operators that preserve syntactic correctness while
changing genotype size and structure. An Evolutionary Algorithm (EA) can
evolve individual solutions in the form of executable structures, ﬁxed length

Adversarial Genetic Programming for Cyber Security

7

genotypes such as the bit strings used by Genetic Algorithms (GAs) [51] are
inﬂexible.

Biological coevolution refers to the inﬂuences two or more species exert
on each other’s evolution [112]. A seminal paper on reciprocal relationships
between insects and plants coined the word “coevolution” [40]. Coevolution
can occur in the context of cooperation, where the species experience mutual
beneﬁt and adaptation, or in the context of competition, where the species neg-
atively interact due to constrained resources that are under shared contention
or a predator-prey relationship.

EAs usually abstract the evolutionary process while ignoring coevolution.
To evaluate the quality of an individual, they apply an a-priori deﬁned ﬁtness
function and this function does not reﬂect the possible interactions between
another individual or a dynamic environment. Optimality can be formulated
by an absolute rather than relative objective. Coevolutionary algorithms ex-
tend EAs by basing the ﬁtness of an individual on its interactions with other
individuals or the environment. They mimic the coupled species-to-species in-
teraction mechanisms of natural coevolution in order to solve a niche of search,
optimization, design, and modeling problems [11, 108,112, 120].

Similar to the biology, coevolutionary algorithms are categorized as cooper-
ative or competitive. Cooperative coevolutionary algorithms abstractly model
the beneﬁcial interaction between populations or in environments with time
dependent factors [70]. They are frequently set up with multiple populations
each solving a distinct sub-problem of a larger problem. We continue this sec-
tion by describing competitive coevolutionary algorithms in more detail as it
is central to adversarial behavior.

2.1 Competitive Coevolutionary Algorithms

A basic competitive coevolutionary algorithm evolves two coupled popula-
tions, each with conventional selection and representation-aligned variation
(crossover and mutation) operators which suit the representation of the pop-
ulation’s genotype. One population comprises what is commonly called tests
and the other solutions. We refer to individuals in a competitive coevolutionary
algorithm generally as adversaries. In each generation, diﬀerent competitions
are formed by pairing up a test and a solution drawn from their respective pop-
ulations. This couples the two population as they share a ﬁtness evaluation
component. We shall shortly describe diﬀerent ways in which these competi-
tions can be set up.

A test competes to demonstrate the solution as incorrect; this is its objec-
tive. The solution competes to solve the test correctly; this is its objective. In
a security setting, it may be more apt to translate from test and solution to
attack and defense as well as to refer to engagements rather than competitions.
Fitness is calculated over all of an adversary’s engagements. The dynamic of
the algorithm, driven by conﬂicting objectives and guided by performance-
based selection and random variation can gradually produce better and more

8

Una-May O’Reilly et al.

robust solutions (i.e defenses) [112,120]. Generally, competitive coevolutionary
algorithms suit domains in which there is no exogenous objective measure of
performance but wherein performance is relative to others. These have been
called interactive domains in [108] and include games and software engineering.
In most domains a competition is often computationally expensive because it
involves simulation or a complex testbed. We next describe how competition
structuring addresses this challenge.

Competition Structures For eﬃciency, the algorithm designer tries to minimize
the number of competitions per generation while maximizing the accuracy of
its ﬁtness estimate of each adversary. The designer is able to control how
competitions are structured and how many competitions are used to estimate
the ﬁtness of an adversary. Assuming one or both populations are of size N ,
two extreme structures are: one-vs-one, each adversary competes only once
against a member of the opposing population, see Fig. 5a and 5d, and all-vs-
all, each adversary competes against all members of the opposing population,
see Fig. 5b and 5e. One-vs-one has minimal ﬁtness evaluations1 (O(N )) and
strong competition bias. In contrast, all-vs-all has a quadratic number of ﬁt-
ness evaluations, yielding a high computational cost, O(N 2) but weaker com-
petition bias [120]. Other structures provide intermediate trade-oﬀs between
computation costs and competition bias, e.g. a tournament structure ranks
individuals based on diﬀerent rounds of peer competitions, see Fig. 5c.

In [89], adversaries termed hosts and parasites are placed on a M ×M grid
with a ﬁxed neighborhood (size c) and one host and parasite per cell. The
structure of the competitions is competition among all competitors in the
neighborhood. Fitness evaluations are reduced to O(M c2) by this. An adver-
sary has an outcome for each competition. We next discuss how these outcomes
can be united to assign it a ﬁtness score.

(a) One-vs-one,
for 1 population.

(b) All-vs-all, for
1 population.

(c) Tournament,
for 1 population.

(d) One-vs-one,
for 2 populations.

(e) All-vs-all, for
2 popualtions.

Fig. 5: Competition structures between adversaries/competitors.

Fitness Assignment At each generation an adversary needs to be assigned
a ﬁtness score derived from some function of its performance outcomes in its

1 computational cost is shown for two populations.

Adversarial Genetic Programming for Cyber Security

9

competitions. For example, the function can average the performance outcomes
or use the maximum, minimum, or median outcome [15]. Other approaches
have been deﬁned depending on the speciﬁc problem domain, e.g. [44,9,27,
76,81,135]. A more formal approach, using the solution and test perspective,
describes ﬁtness assignments as solution concepts [108]. Solution concepts in-
clude: best worst case, maximization of expected utility, Nash equilibrium, and
Pareto optimality.

Coevolutionary algorithms are more complex and challenging to direct to-
ward some expected outcome than a single population EA. We next explain
the pathologies they exhibit and describe accepted remedies for them.

Pathologies and Remedies The interactive aspect of ﬁtness implies that a com-
petitive coevolutionary algorithm lacks an exact ﬁtness measurement. While
EAs use a ﬁtness function that allows an individual to be compared and glob-
ally ranked, in coevolutionary algorithms two members of the same population,
during selection, may be imprecisely compared when they did not compete
against the same opponents. Adding more imprecision, regardless of the func-
tion that computes a ﬁtness score, an adversary’s score may change if it later
competes against diﬀerent opponents. These properties imply that any rank-
ing of individuals is a noisy estimate. This estimation can lead to competitive
coevolutionary algorithms pathologies that limit the eﬀectiveness of their arms
race modeling [108]. Furthermore, pathologies can arise from competitive im-
balance, particularly when the behavior space of one population is not the
same as that of the other. This asymmetry is considered and addressed in
[98]. Pathologies include: disengagement – occurring when opponents are not
challenging enough, eliminating an incentive to adapt, or when opponents are
too challenging and progress becomes impossible [28], cyclic dynamics – gener-
ally appearing in transitive domains (A beats B, B beats C and C beats A) as
oscillation of the evaluation metric [58], focusing or overspecialization – arising
when an adversary evolves to beat only some of its opponents, while neglect-
ing the others [26], and coevolutionary forgetting – occurs when an adversary’s
ability to beat an opponent evolves away [23].

In order to remediate these pathologies, assorted methods have been pro-
posed [22,23,26,28,42,58,70,144]. These center on archives or memory mech-
anisms, maintaining suboptimal individuals in the population, using a neigh-
borhood spatial structure, and/or monitoring the progress of the algorithm.

With the basics of GP and competitive coevolutionary algorithms intro-
duced, we are now able to present a combined competitive coevolutionary and
GP algorithm.

2.2 GP and Adversarial Evolution

Combining GP and competitive coevolutionary algorithms enables cyber secu-
rity arms races to be replicated by evolving executable adversaries. An exam-
ple of an alternating GP competitive coevolutionary algorithm [14] is shown

10

Una-May O’Reilly et al.

ξ: Crossover probability, N : Population size

(cid:46) Initialize minimizer(attacker) population
(cid:46) Initialize maximizer(defender) population
(cid:46) Initialize iteration counter

t ← t + 1
At ← select(At−1))
At ← mutate(At, µ))
At ← crossover(At, ξ))
a(cid:48)
∗, d(cid:48)
if L(a(cid:48)

Algorithm 1 Example of alternating GP Competitive coevolutionary algo-
rithm
Input:
T : number of generations L: Fitness function, F: Functions, T : Terminals
µ: Mutation probability,
1: A0 ← [a1,0, . . . , aN,0] ∼ U ({F , T })
2: D0 ← [d1,0, . . . , dN,0] ∼ U ({F , T })
3: t ← 0
4: repeat
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23: until t ≥ T
24: a∗, d∗ ← arg mina∈AT arg maxd∈DT L(a, d)
25: return a∗, d∗

(cid:46) Copy population
(cid:46) Increase counter before alternating to maximizer
(cid:46) Selection
(cid:46) Mutation
(cid:46) Crossover
(cid:46) Best maximizer
(cid:46) Replace worst maximizer
(cid:46) Update population

end if
At ← At−1
t ← t + 1
Dt ← select(Dt−1))
Dt ← mutate(Dt, µ))
Dt ← crossover(Dt, ξ))
a(cid:48)
∗, d(cid:48)
if L(a(cid:48)

(cid:46) Increase counter
(cid:46) Selection
(cid:46) Mutation
(cid:46) Crossover
(cid:46) Best minimizer
(cid:46) Replace worst minimizer
(cid:46) Update population

∗ ← arg mina∈At arg maxd∈Dt L(a, d)
∗, d(cid:48)
∗) > L(aN,t, dN,t−1) then
dN,t−1 ← d(cid:48)
∗

∗ ← arg mina∈At arg maxd∈Dt−1 L(a, d)
∗) < L(aN,t−1, dN,t−1) then

∗, d(cid:48)
aN,t−1 ← a(cid:48)
∗

end if
Dt ← Dt−1

(cid:46) Copy population

(cid:46) Best minimizer

in Algorithm 1. The adversaries (attacker/defender) are coupled and evolve
in an alternating manner. First, the adversaries are initialized. Then, at each
generation, a new attacker population, At, is selected, mutated, recombined
and evaluated against the current defense population, Dt−1. Based on the
evaluation the attackers are replaced. Then, control reverts to the defender
population so it can evolve to conclude the generation. This algorithm allows
more attack evolution than defensive evolution, reﬂecting what can happen
in real cyber systems. A note of caution about this approach in the context
of algorithms, rather than reality, is oﬀered by [87] where it is observed that
moderate environmental variation across generations is suﬃcient to promote
the evolution of robust solutions.

There are some open challenges when applying Adversarial Genetic Pro-
gramming for Cyber Security. Some of them are inherent in the use of EAs and
adversarial evolution, such as the subjective solution evaluation, i.e., indi-
viduals interact with diﬀerent opponents and the ﬁtness is based on these, so
it only provides a relative ordering [109,110, 107]. Other ampliﬁed challenges
are the evaluation cost, since the individual’s ﬁtness is calculated based
on its interaction with other individuals which might require high computa-
tional costs [17,66,78,89,79]; Finally, combining GP and adversarial evolution
generates complex models that complicate the algorithm operator and pa-
rameter selection.

Adversarial Genetic Programming for Cyber Security

11

This section has described algorithms that form the foundation of computa-
tional adversarial evolution. In the next section we describe prior Evolutionary
Computation work that use GP, competitive coevolutionary algorithms or a
combination of them in the domains of AI and Games, security, and Software
Engineering.

3 Related Work

We now turn our attention to prior work relating to the theme of adversarial
contexts. We organize by application domain, starting with domains which are
competitive in nature but not cyber security: AI and games (3.1) and Software
Engineering (3.2). Most examples take technical approaches that use compet-
itive coevolutionary algorithms or GP. They provide essential illustrations of
how the algorithms can be used as building blocks. Table 1 catalogs the related
work by domain, algorithm, representation, competition structure, and ﬁtness
scoring. Fig. 6 illustrates how they intersect thematically.

Fig. 6: Venn diagram showing the intersections of domains in Adversarial Ge-
netic Programming for Cyber Security related work.

3.1 AI and Games

We ﬁnd related work in AI and games because many games are competitive
and game playing is a fertile research ground for investigating adversarial
learning. We embrace a broad deﬁnition of game – encompassing board games,
e.g. [106], video game playing, e.g. [63,121] and social science games e.g. [15].
One of the ﬁrst competitive coevolutionary algorithms was used to ﬁnd
eﬃcient strategies for the Iterated Prisoners Dilemma [15,16]. This seminal
project used a single population and it structured its strategy competition
by running a tournament among the population members. A single popula-
tion is typical for symmetric games, i.e. games where each player has the

A
r
c
u
r
i

&
Y
a
o

[
1
3
]

C
o
m
p
C
o
e
v
G
P

T
w
o
:

p
r
o
g
r
a
m

s

a
n
d

t
e
s
t
s

T
r
e
e
s

12

O

l
i
v
e
i
r
a

e
t

a
l
.

[
9
7
]

C
o
m
p
C
o
e
v
G
A

T
w
o
:

p
r
o
g
r
a
m

s

a
n
d

t
e
s
t
s

A
d
a
m
o
p
o
u
l
o
s

e
t

a
l
.

[
3
]

C
o
m
p
C
o
e
v
G
A

T
w
o
:

p
r
o
g
r
a
m

s

a
n
d

t
e
s
t
s

a
n
d

t
e
s
t
s

a
n
d

t
e
s
t
s

S
e
q
u
e
n
c
e
s

o
f

m
u
t
a
n
t

p
r
o
g
r
a
m

s

S
e
q
u
e
n
c
e
s

o
f

m
u
t
a
n
t

p
r
o
g
r
a
m

s

O
n
e

v
s

a
l
l

P
a
r
e
t
o

o
p
t
i

m
a
l
i
t
y

O
n
e

v
s

a
l
l

O
n
e

v
s

a
l
l

N
a
s
h

e
q
u
i
l
i
b
r
i
u
m

M
a
x
i
m
u
m
e
x
p
e
c
t
e
d

u
t
i
l
i
t
y

W

i
l
k
e
r
s
o
n
&
T
a
u
r
i
t
z

[
1
4
2
]

C
o
m
p
C
o
e
v
G
P

T
w
o
:

p
r
o
g
r
a
m

s

a
n
d

t
e
s
t
s

T
r
e
e
s

a
n
d

l
i
s
t
s

O
n
e

v
s

a

s
u
b
s
e
t

M
a
x
i
m
u
m
e
x
p
e
c
t
e
d

u
t
i
l
i
t
y

W
i
n
t
e
r
r
o
s
e
&
C
a
r
t
e
r

[
1
4
5
]

S
u
a
r
e
z
-
T
a
n
g
i
l

e
t

a
l
.

[
1
2
9
]

G
A

G
P

S
e
r
v
i
c
e
&
T
a
u
r
i
t
z

[
1
1
9
]

C
o
m
p
C
o
e
v
G
A

R
u
s
h

e
t

a
l
.

[
1
1
3
]

C
o
m
p
C
o
e
v

E
A

O
s
t
a
s
z
e
w
s
k
i

e
t

a
l
.

[
1
0
2
]

C
o
m
p
C
o
e
v
A
I
S

O
n
e

s
y
s
t
e
m

f
a
u
l
t
s

O
n
e
:

s
t
r
a
t
e
g
i
e
s

T
w
o
:

s
y
s
t
e
m
h
a
r
d
e
n
i
n
g
s

a
n
d

B
i
t

s
t
r
i
n
g
s
:

u
n
i
ﬁ
e
d

p
o
w
e
r

ﬂ
o
w

c
o
n
t
r
o
l
l
e
r

i
n
s
t
a
l
l
a
t
i
o
n

O
n
e

v
s

a

s
u
b
s
e
t

N
a
s
h

e
q
u
i
l
i
b
r
i
u
m

a
t
t
a
c
k
e
r
s

T
w
o
:

d
e
f
e
n
d
e
r
s

a
n
d

a
n
o
m
a
l
i
e
s

T
w
o
:

d
e
t
e
c
t
o
r
s

a
n
d

N
o
t

s
p
e
c
i
ﬁ
e
d

O
n
e

v
s

s
u
b
s
e
t

M
a
x
i
m
u
m
e
x
p
e
c
t
e
d

u
t
i
l
i
t
y

V
e
c
t
o
r

o
f

p
a
r
a
m
e
t
e
r
s

O
n
e

v
s

s
u
b
s
e
t

M
a
x
i
m
u
m
e
x
p
e
c
t
e
d

u
t
i
l
i
t
y

S
o
f
t
w
a
r
e

e
n
g
i
n
e
e
r
i
n
g

m
a
c
h
i
n
e

B
i
t

s
t
r
i
n
g
s
:

ﬁ
n
i
t
e

s
t
a
t
e
s

F
i
x
e
d

s
c
e
n
a
r
i
o
s

S
u
c
c
e
s
s

a
g
a
i
n
s
t

t
h
e

d
e
f
e
n
d
e
r

T
r
e
e
s
:

i
n
t
r
u
s
i
o
n

d
e
t
e
c
t
i
o
n

r
u
l
e
s

R
i
s
k

a
s
s
e
s
s

m
e
n
t

M
a
x
i
m
u
m
e
x
p
e
c
t
e
d

u
t
i
l
i
t
y

Una-May O’Reilly et al.

G
a
r
c
i
a

e
t

a
l
.

[
4
8
]

H
e
m
b
e
r
g

e
t

a
l
.

[
5
6
]

C
o
m
p
C
o
e
v
G
P

C
o
m
p
C
o
e
v
G
P

T
w
o
:

D
e
f
e
n
d
e
r
&
A
t
t
a
c
k
e
r

I
n
t
e
g
e
r
s
&
B
N
F
G
r
a
m
m
a
r

N
A

T
w
o
:

D
e
f
e
n
d
e
r
&
A
t
t
a
c
k
e
r

I
n
t
e
g
e
r
s
&
B
N
F
G
r
a
m
m
a
r

A

l
l

v
s
A

l
l

P
a
r
e
t
o

o
p
t
i

m
a
l
i
t
y

M
u
l
t
i
p
l
e

c
o
m
p
a
r
i
s
o
n

M
c
D
o
n
a
l
d
&
U
p
t
o
n

[
8
6
]

C
o
m
p
C
o
e
v
G
A

T
w
o
:

r
e
d

a
n
d

b
l
u
e

t
e
a
m

s

V
e
c
t
o
r

o
f

p
a
r
a
m
e
t
e
r
s

O
n
e

v
s

a
l
l

F
o
r
c
e

E
x
c
h
a
n
g
e
R
a
t
i
o

K
e
w
l
e
y
&
E
m
b
r
e
c
h
t
s

[
6
4
]

C
o
m
p
C
o
e
v
G
A

H
i
n
g
s
t
o
n
&
P
r
e
u
s
s

[
5
7
]

C
o
m
p
C
o
e
v
G
A

e
n
e
m
y

f
o
r
c
e
s

t
w
o

o
f

t
e
s
t
s

F
o
u
r
:

t
w
o

o
f

l
e
a
r
n
e
r
s

a
n
d

E
i
g
h
t
:

f
o
u
r

f
r
i
e
n
d
l
y

a
n
d

f
o
u
r

P
a
i
r
s

o
f

r
e
a
l

n
u
m
b
e
r
s

O
n
e

v
s

a
l
l

B
e
s
t
-
w
o
r
s
t

c
a
s
e

V
e
c
t
o
r

o
f

f
o
u
r

p
a
r
a
m
e
t
e
r
s

O
n
e

v
s

a

s
u
b
s
e
t

M
a
x
i
m
u
m
e
x
p
e
c
t
e
d

u
t
i
l
i
t
y

M

i
l
e
s

e
t

a
l
.

[
8
8
]

L
u
k
e

e
t

a
l
.

[
8
1
]

i

L
m
e
t

a
l
.

[
7
6
]

H
a
r
p
e
r

[
5
5
]

K
e
a
v
e
n
e
y
&
O
R
i
o
r
d
a
n

[
6
3
]

C
o
m
p
C
o
e
v
G
A

C
o
m
p
C
o
e
v
G
P

G
P

C
o
m
p
C
o
e
v
G
P

C
o
m
p
C
o
e
v
G
P

O
n
e

O
n
e

O
n
e

O
n
e

O
n
e

A
x
e
l
r
o
d
,

e
t

a
l
.

[
1
5
,
1
6
]

C
o
m
p
C
o
e
v
G
A

O
n
e

C
r
a
w
f
o
r
d
-
M
a
r
k
s

e
t

a
l
.

[
3
5
]

C
o
m
p
C
o
e
v
G
P

s

m
a
r
t
-
b
a
l
l
s

T
w
o
:

p
l
a
y
e
r
s

a
n
d

S
e
c
u
r
i
t
y

T
r
e
e
s

T
r
e
e
s

T
r
e
e
s

B
i
t

s
t
r
i
n
g
s

G
a
m
e
s

T
r
e
e
s

B
i
t

s
t
r
i
n
g
s

V
a
r
i
a
b
l
e

i
n
t
e
g
e
r

v
e
c
t
o
r

P
l
a
y
i
n
g

g
a
m
e
s

P
a
r
e
t
o

o
p
t
i

m
a
l
i
t
y

O
n
e

O
n
e

v
s

v
s

o
n
e

o
n
e

M
a
x
i
m
u
m
e
x
p
e
c
t
e
d

u
t
i
l
i
t
y

M
a
x
i
m
u
m
e
x
p
e
c
t
e
d

u
t
i
l
i
t
y

O
n
e

O
n
e

v
s

v
s

s
u
b
s
e
t

M
a
x
i
m
u
m
e
x
p
e
c
t
e
d

u
t
i
l
i
t
y

a

s
u
b
s
e
t

M
a
x
i
m
u
m
e
x
p
e
c
t
e
d

u
t
i
l
i
t
y

O
n
e

v
s

s
u
b
s
e
t

M
a
x
i
m
u
m
e
x
p
e
c
t
e
d

u
t
i
l
i
t
y

T
o
u
r
n
a
m
e
n
t

M
a
x
i
m
u
m
e
x
p
e
c
t
e
d

u
t
i
l
i
t
y

R
e
f
e
r
e
n
c
e

A
l
g
o
r
i
t
h
m

#
o
f

P
o
p
u
l
a
t
i
o
n
s

R
e
p
r
e
s
e
n
t
a
t
i
o
n

S
t
r
u
c
t
u
r
e

C
o
m
p
e
t
i
t
i
o
n

F
i
t
n
e
s
s

S
c
o
r
i
n
g

o
f

t
h
e

i
n
d
i
v
i
d
u
a
l
s
,

c
o
m
p
e
t
i
t
i
o
n

s
t
r
u
c
t
u
r
e

a
n
d

h
o
w
ﬁ
t
n
e
s
s

i
s

a
s
s
i
g
n
e
d

t
o

a
n

i

n
d

i
v
i
d
u
a
l
.

C
o
e
v

a
n
d
G
P

.

T
h
e

c
o
l
u
m
n
s

r
e
l
a
t
e

t
o

p
r
o
p
e
r
t
i
e
s

d
e
s
c
r
i
b
e
d

i

n

S
e
c
t
i
o
n

2
.
1
,

a
l
g
o
r
i
t
h
m
c
l
a
s
s
,

n
u
m
b
e
r

o
f

p
o
p
u
l
a
t
i
o
n
s
,

r
e
p
r
e
s
e
n
t
a
t
i
o
n

a
n
d

t
h
r
e
e

a
l
g
o
r
i
t
h
m
i
c

s
o
l
u
t
i
o
n
s
:

G
P
(
g
e
n
e
t
i
c

p
r
o
g
r
a
m
m
n
g
)
,

i

C
o
m
p
C
o
e
v

(
C
o
m
p
e
t
i
t
i
v
e

c
o
e
v
o
l
u
t
i
o
n
)
,

a
n
d

c
o
m
b

i

n
a
t
i
o
n

o
f

C
o
m
p

T
a
b
l
e

1
:

S
o
m
e

r
e
p
r
e
s
e
n
t
a
t
i
v
e

r
e
l
a
t
e
d
w
o
r
k

t
o

c
y
b
e
r

s
e
c
u
r
i
t
y
.

I
t

i

n
c
l

u
d
e
s

t
h
r
e
e

i

d
ﬀ
e
r
e
n
t

d
o
m
a
i

n
s
:

g
a
m
e
s
,

s
e
c
u
r
i
t
y
,

a
n
d

s
o
f
t
w
a
r
e
,

Adversarial Genetic Programming for Cyber Security

13

same set of moves (behavioral repertoire) and objectives. We ﬁnd symmet-
ric board game projects that use single population competitive coevolution-
ary algorithms to evolve Tic-Tac-Toe, Othello and Backgammon players. The
Tic-Tac-Toe project represented players with GP [9] while both Othello and
Backgammon projects used temporal diﬀerence learning, which is a gradient-
based local search method [71,106,131,132,123]. A subsequent work used sym-
metric competitive coevolution in games and demonstrated impressive results
through self-play [30]. A noteworthy system at the intersection of competitive
coevolutionary algorithms and GP used a single population of agents coop-
erating as a team to compete for the “RoboCup97” soccer competition [81].
Soccer, being symmetric, would allow the system to potentially train against
itself. In [122] the authors designed an evolutionary strategizing machine for
game playing and other contexts. In [124], the authors coevolved strategies
to solve Rubik’s Cube where the test population evolved the Rubik’s Cube
conﬁgurations while the learner population evolved GP individuals to solve
the Cube conﬁgurations. An ablation study demonstrated the contribution of
competitive coevolution over random replacement of Cube conﬁgurations.

Cyber security adversaries are arguably asymmetric. In asymmetric games
where opponents have diﬀerent objectives and move sets, we ﬁnd multi-
population competitive coevolutionary algorithms. These include a compet-
itive coevolutionary algorithm with evolutionary strategies that evolves Pac-
Man versus Ghost Team players [27] and a PushGP system coevolving player
versus smart-ball for the game “Quidditch”. The latter is noteworthy for its
intersection of a competitive coevolutionary algorithm and GP.

In some asymmetric games one adversary is external to the learning sys-
tem and quite complex. This drives single or multi-population coevolutionary
algorithm systems. A competitive coevolutionary algorithm and GP study
compared using a single population to nine populations when evolving con-
trollers for a car racing game [135]. The multi-population approach generally
produced better controllers. Similarly, real time strategy games (which provide
challenging AI problems [72,95]) have applied a single-population competitive
coevolutionary algorithm and GP to develop automated players that use a
progressive reﬁnement planning technique [63]. Other work [88] coevolved real
time strategy players by representing the AI agents with Inﬂuence Maps [38].
A real-time Neuroevolution of Augmenting Topologies (rtNEAT) approach
evolved neural networks in real time while a game was played [128]. Behav-
ior Trees (BT) were introduced to encode formal system speciﬁcations [7],
but have also represented game AI behavior in commercial games [94]. GP
evolved BT controllers for “Mario” [103] and “DEFCON” [76] games. Another
study used Grammatical Evolution to generate Java programs to compete in
“Robocode”. The players were represented by programs [55] and a spatial and
temporal competitive coevolutionary algorithm and GP were used.

14

Una-May O’Reilly et al.

3.2 Software Engineering and Software Testing

Software testing called fuzzing arguably started with [54] which used gram-
mars to generate program inputs for tests. This transitioned to direct auto-
mated random testing. One relevant security example is
[50] that searched
for bugs in a security protocol. Later, constraint based automatic test data
generation was used to generate tests to verify if software variants were safe
from malicious manipulation [39].

For similar purposes, the search based software engineering community uses
evolutionary computation. Coevolution is used in SBSE with GA representa-
tions, see e.g.
[3,8,97]. The community has used competitive coevolutionary
algorithms and GP to coevolve programs and unit tests from their speciﬁ-
cation, e.g. [13,142,14]. Another study, [18], used coevolution to distinguish
correct behavior from incorrect.

3.3 Cyber Security

We now turn to the domain of cyber security. There are a number of exam-
ples where, without any computational modeling or simulation, cyber security
dynamics are described as evolutionary or as arms races. According to [143],
cyber security is the task of minimizing an attack surface over time. The at-
tack surface is the portion of a system which has vulnerabilities. Attackers
attempt to inﬂuence the system’s nominal state and operation by varying
their interactions with the attack surface by stealth and non-compliance (see
Appendix A.4). Cyber security perimeter protection (e.g. a ﬁrewall) is a battle
fought and lost. Attackers are able to now gain access and defenders must
resort to strategies that assume the attacker is present but hidden. One tactic
to detect their presence is deception. For this a “honeypot” that entraps an at-
tacker by imitating its target is commonly deployed. This arms race escalates
ad inﬁnitum as attackers then anticipate what the defenders have anticipated
(e.g. the honeypots) and so on.

Retrospective security event reports also document coevolution. For exam-
ple,
[53] is an empirical study of malware evolution. Arguments for employing
nature-inspired technologies for cyber security that mention how biological
and ecological systems use information to adapt in an unpredictable world
include [34,45,60,85,114].

A selected set of cyber security research that takes technical approaches is
described in the Security subsection of Table 1. This set include works that
we would not consider Adversarial Genetic Programming for Cyber Security:
one work uses a genetic algorithm and neither coevolution or GP[145] and
six others use are adversarial in nature, i.e. they use coevolution, but not
GP[57, 64, 86,102,113,119]. The remaining three projects ﬁt within the topic
of Adversarial GP[129,48,56]. The research within this set, along with other
related work, can also be distinguished by what speciﬁc application it addresses
in the domain of cyber security:

Adversarial Genetic Programming for Cyber Security

15

Moving target defense (MTD) techniques seek to randomize compo-
nents to reduce the likelihood of a successful attack, reduce the attack lifetime,
and diversify systems to limit the damage [41,96]. A MTD study investigates
an adaptable adversarial strategy based on Prisoners Dilemma in [145]. Strate-
gies are encoded as binary chromosomes representing ﬁnite state machines that
evolve according to GA. The study has one adaptive defender population in
GA and few ﬁxed scenarios.

Network Defense Investigation is studied with the coevolutionary
agent-based network defense lightweight event system (CANDLES) [113] a
framework designed to coevolve attacker and defender agent strategies with
a custom, abstract computer network defense simulation. The RIVALS net-
work security framework, elaborated in Section 4 supports three studies into
respectively DDOS, deceptive and isolation defense.

for

example

Self-Adapting Cyber Defenses are

the Helix self-
regenerative architecture [74]. Helix shifts the attack surface by automati-
cally repairing programs that fail test cases using Software Dynamic Transla-
tion, e.g. Strata [117]. Another example of automated fault analysis and ﬁlter
generation within a system is named “FUZZBUSTER” [91,92]. Like Helix,
FUZZBUSTER is designed to automatically identify software vulnerabilities
and create adaptations that protect those vulnerabilities before attackers can
exploit them. Both FUZZBUSTER and Helix use a GP system called Gen-
Prog [136] for automatically ﬁxing code.

Physical Infrastructure defense is studied in terms of how network

components can be made resilient in [119].

Anomaly detection attempts to discern network or other activity be-
havior that is out of the ordinary or that diﬀers from normal. In the auto-
immune system computational paradigm, normal has been characterized as
“self” [46]. Anomaly detection has been studied as a one class learning prob-
lem by [102] who use the artiﬁcial immune systems paradigm and coevolution
for search. Attempts to build GP anomaly detectors have mostly assumed la-
beled data sets and they evolve a classiﬁer that labels outputs as normal or
not. They frequently encounter a class imbalance issue. This is explicitly ad-
dressed in [126]. Later work adopted an explicitly Pareto archive formulation
of competitive coevolution[75].

Vulnerabilty Testing Vulnerability testing involves testing a system
with modiﬁcations to known exploits or attack vectors. Examples of develop-
ing mimicry attacks to test for vulnerability are found in [61,62]. The approach
used the alarm signal for coevolution of a GP exploit generator. Moreover, GP
was limited to instructions that were in legitimate applications, forcing GP to
search for exploits described in terms of instructions used by legitimate appli-
cations. Others have also used GP to coevolve port scans against the ’Snort’
intrusion detector with the objective of evolving port scans that demonstrate
holes in the IDS. See for example [73]. Vulnerability testing for malware in
mobile applications using coevolution appears in [25].

16

Una-May O’Reilly et al.

Malware detection has seen GP used to evolve novel PDF malware to
automatically evade classiﬁers [148] and to study malware in the form of
return-oriented program evolution [47].

Intrusion detection Most examples of intrusion detection are addressed
as a multi-class classiﬁcation problem where activity such as network traf-
ﬁc must be labeled as normal, denial of service, botnet or something else.
Multi-class classiﬁcation has been studied using GP without coevolution. For
example, [129] optimizes intrusion detection rules. Others study botnet detec-
tion with GP under streaming data label budgets and class imbalance [65].
With both intrusion detection and anomaly detection, one challenge is obtain-
ing a dataset that truly reﬂects the network or any other cyber environment.
For example, a widely used dataset known at KDD’99 has been criticized for
its artiﬁcially generated normal data, which did not encompass the diversity
in real normal behavior, see [77,84] for more details. It is also challenging to
label and maintain datasets, see [49] as an example. The persistent nature of
these challenges provides additional motivation for RIVALS .

Battle management has historically noteworthy work by [12] which fo-
cuses on security in battle management. It was novel in considering semi-
autonomous control of several intelligent agents; plan adjustment based on
developments during plan execution; and the inﬂuence of the presence of an ad-
versary in devising plans. Similar but contemporary work on a computational
military tactical planning system uses fuzzy sets and competitive coevolution-
ary algorithm with a battleﬁeld tactics simulator for decision support [64].

Red teaming is a technique utilized by the military operational analysis
community to check defensive operational plans by pitting actors posing as
attackers (a red team) against the defense (a blue team). This activity has
evolved from human teams to teams of programmers overseeing automated
attacks tactics and defensive measures. See [37] and studies [1,93] trying to
automate the exercise to use less manpower, or use it more eﬃciently with
agent-based models [19,86,146,149,150,57].

The Next Section Prior work in AI and games, cyber security and software
engineering domains is helpful in showing how competitive coevolutionary al-
gorithms and GP can be used in adversarial contexts. It also provides a mod-
est number of examples of GP combined with a competitive coevolutionary
algorithm. We now proceed to present a detailed example of research within
Adversarial Genetic Programming for Cyber Security. Named RIVALS , it is
a software framework for studying network security. RIVALS addresses an
aspect of central importance to the 2016 DARPA grand challenge in cyber se-
curity named “The World’s First All-Machine Hacking Tournament”[37]. This
aspect that adaptation of both sides of a cyber security battle ground must
be anticipated and that eventually posture reconﬁguration needs to be fully
automated.

Adversarial Genetic Programming for Cyber Security

17

Fig. 7: High level view of RIVALS framework. The left hand side compo-
nent is a competitive coevolutionary algorithm that evolves two competing
populations: attacks and defenses. The right hand side component from a
computational perspective is a modeling or simulation environment. The en-
vironment is initialized with a mission and can be reset each time it is passed
an attack-defense pairing to run an engagement. It ﬁrst installs the defense,
then it starts the mission and the attack. It evaluates the performance of the
adversaries relative to their objectives and returns appropriate measurements.

4 RIVALS

Consistent with the Adversarial Genetic Programming for Cyber Security
paradigm, our goal is to study the dynamics of cyber networks under at-
tack by computationally modeling and simulating them. Ultimately we aim to
provide defenders with information that allows them to anticipate attacks and
design for resilience and resistance before their attack surfaces are attacked.
We exploit competitive coevolutionary algorithms and GP for these purposes
within a framework named RIVALS [101,104,111].

Conceptually, the framework consists of three elements: adversaries, en-
gagements and their environments, and competitive coevolution. These ﬁt to-
gether as two connected modules – one executing the coevolutionary algorithm
and executing the engagements, and the other executing the engagements with
the competitive coevolutionary algorithm directing attack and defense engage-
ment pairings, see Fig. 7,.

We now proceed to describe each of these elements and RIVALS ’ use cases.

4.1 Elements of RIVALS

Adversaries: The system consists of two adversarial populations – attacks
and defenses. The primary objective of an attack is to impair a mission by
maximizing disruption of some resource. The primary objective of a defense is
to complete a mission by minimizing disruptions. Both attack and defense can
have secondary objectives based on the cost of their behavior. We design attack
and defense behavior by deﬁning grammars that can express the diﬀerent
variations of attacks and defenses. An attack or defense is a “sentence” in the
grammar’s language. We implement a rewriting process (“generator”) to form
sentences from the grammar [99], see Fig. 8. The sentences (i.e. attacks and

Coevolutionary AlgorithmEngagement EnvironmentAttack and DefenseEngagement Measures18

Una-May O’Reilly et al.

Fig. 8: Grammatical evolution string rewriting. A context free grammar
rewrites an integer sequence (genotype) to an output sentence (phenotype).

defenses) are functions that are executable in the layers of the engagement
environment.

The grammar has Backus Naur Form (BNF) and is parsed to a context
free grammar structure. The (rewrite) rules of the generator express how a
sentence, i.e. attack or defense, can be composed by rewriting a start sym-
bol. The adversaries are represented with variable length integer vectors. The
generator decodes these vectors to control its rewriting. As a result, diﬀerent
vectors generate diﬀerent attacks or defenses. For diﬀerent use cases, it is only
necessary to change the BNF grammar, engagement environment and ﬁtness
function of the adversaries. This modularity, and reusability of the parser and
rewriter are eﬃcient software engineering and problem solving advantages.
The grammar additionally helps communicate to the designer how the system
works and its assumptions, i.e. threat model. This enables conversations and
validation at the domain level with experts and increases the conﬁdence in
solutions from the system.

Engagements and the Engagement Environment An engagement is an attack
on a defense. Engagements take place in an engagement environment which
is initialized with a mission to complete and a set of resources such as net-
work services that support the mission. The defense is ﬁrst installed in the
environment and then, while the mission runs, the attack is launched. The
scenario (mission and resources) and attacks are then executed. Engagements
have outcomes that match up to objectives; they are phrased in terms of mis-
sion completion (primary objective) and resource usage (second objective).
Implementation-wise, the engagement environment component can support a
problem-speciﬁc network testbed, simulator or model. Mod-sim is appropriate
when testbeds incur long experimental cycle times or do not abstract away
irrelevant detail.

Coevolutionary Algorithms RIVALS maintains two populations of competing
attackers and defenders. It calculates the ﬁtness of each population member
(in both attack and defense populations) by assessing its ability to success-
fully engage one or more members from the adversarial population, given its
objective(s). It also directs selection and variation. RIVALS [111,104] utilizes
diﬀerent coevolutionary algorithms to generate diverse behavior. The algo-
rithms, for further diversity, use diﬀerent “solution concepts”, i.e. measures of

Adversarial Genetic Programming for Cyber Security

19

Fig. 9: Overview of the ESTABLO framework used by RIVALS for decision sup-
port through selection and visualization by using a compendium of solutions
from coevolutionary algorithms.

adversarial success. However, engagements are often computationally expen-
sive and have to be pairwise sampled from two populations at each generation,
a number of enhancements enables eﬃcient use of a ﬁxed budget of computa-
tion or time.

RIVALS’ Compendium Solely emulating or simulating cyber arms races is not
suﬃcient to practically inform the design of better, anticipatory defenses. In
fact, competitive coevolution poses general challenges when used for design
optimization. The following ones in RIVALS make it diﬃcult to present a
designer with clear information derived solely from multiple simulation runs
[115,111]:

1. Attacks (and defenses) of diﬀerent generations are not comparable because
ﬁtness is based solely on the composition of the defense (attack) popula-
tion at each generation. So no clear champion emerges from running the
algorithm.

2. From multiple runs, with one or more algorithms, it is unclear how to

automatically select a “best” attack or design.

To this end, RIVALS provides an additional decision support component,
named ESTABLO [111,115], see Fig. 9. At the implementation level, the engage-
ments and results of every run of any of the system’s coevolutionary algorithms
are cached. Later, oﬄine, ESTABLO ﬁlters these results and moves a subset to
its compendium. To prepare for the decision support analysis, it then com-
petes all the attacks in the compendium against all defenses and ranks them
according to multiple criteria, e.g. maximum-expected utility, best-worst case.
For the defensive designer, it also provides visualizations and comparisons of
adversarial behaviors to inform the design process.

Use Cases The RIVALS framework supports use cases – investigations into
arms races of a particular cyber network context. They each interface with the
framework through a set of domain speciﬁc information. For each use case,
grammars deﬁne the behavioral space of the adversaries, objectives deﬁne the
goals of the adversaries for scoring ﬁtness and the threat environment describes
its engagement environment. For each use case, diﬀerent parameters to control
the coevolutionary algorithm are also available. Fig. 10 depicts the high level
decomposition of the framework and shows how a use case interfaces with it.

COEVOLUTIONARY SEARCH-SolutionConceptsCOMPENDIUM CREATION-AlgorithmcombinationCOMPENDIUM EVALUATION-AllvsAllSOLUTION SELECTION-Rank-Unseen DataVISUALIZATION-Selected solutions-Diversity20

Una-May O’Reilly et al.

Table 2 presents the domain speciﬁc information for three use cases. By name,
these are:

– DIFFRACTED: Defending a peer-to-peer network against Distributed De-

nial of Service (DDOS) attacks [48] (Section 4.2)

– AVAIL: Defenses against device compromise contagion in a segmented en-

terprise network [56] (Section 4.3), and

– DARK-HORSE : Deceptive defense against the internal reconnaissance of

an adversary within a software deﬁned network [104] (Section 4.4)

Fig. 10: RIVALS framework component decomposition showing interface with
use cases.

The following sections elaborate on these use cases.

4.2 DIFFRACTED– DOS Attacks on Peer-to-Peer Networks

A peer-to-peer (P2P) network is a robust and resilient means of securing mis-
sion reliability in the face of extreme distributed denial of service (DDOS)
attacks. DIFFRACTED [48], assists in developing P2P network defense strate-
gies against DDOS attacks. Attack completion and resource cost minimization
serve as attacker objectives. Mission completion and resource cost minimiza-
tion are the reciprocal defender objectives. DDOS attack strategies are mod-
eled with a variety of behavioral languages.

A simple language e.g. allows a strategy to select one or more network
servers to disable for some duration. Defenders choose one of three diﬀer-
ent network routing protocols: shortest path, ﬂooding and a peer-to-peer ring
overlay to try to maintain their performance. A more complex language allows
a varying number of steps over which the attack is modulated in duration,
strength and targets. It can even support an attack learning a parameterized

Adversarial Genetic Programming for Cyber Security

21

Fig. 11: The x axis shows a sorted subsample of attackers (note, the top 10
are shown and then every tenth) and the y axis shows the ranking score. The
ranking is done on the scores from the compendium. The values for the same
run and unseen test sets are shown on separate lines. The algorithm used to
evolve the attacker is shown by the marker and the color. The attacker in the
box with the solid line is the top ranked solution from the Combined Score
ranking schemes. The solution in the dashed box is the top ranked solution
from the Minimum Fitness ranking scheme.

condition that controls how it adapts during an attack, i.e. “online”, based on
feedback it collects from the network on its impact. Defenders have simple lan-
guages related to parameterizations of P2P networks that inﬂuence the degree
to which resilience is traded oﬀ with service costs. A more complex language
allows the P2P network to adapt during an attack based on local or global
observations of network conditions.

An example of attackers from ESTABLO on a mobile resource allocation
defense used in DIFFRACTED [115] is shown in Fig. 11. The mobile asset
placement defense challenge is to optimize the strategic placement of assets in
the network. While under the threat of node-level DDOS attack, the defense
must enable a set of tasks. It does this by ﬁelding feasible paths between the
nodes that host the assets which support the tasks. A mobile asset is, for
example, mobile personnel or a software application that can be served by any
number of nodes. A task is, for example, the connection that allows personnel
to use a software application.

4.3 AVAIL- Availability Attacks on Segmented Networks

Attackers often introduce malware into networks. Once an attacker has com-
promised a device on a network, they spread to connected devices, akin to
contagion. AVAIL considers network segmentation, a widely recommended de-
fensive strategy, deployed against the threat of serial network security attacks
that delay the mission of the network’s operator [56] in the context of malware
spread.

22

Una-May O’Reilly et al.

Fig. 12: Flow of the competitive coevolutionary algorithm used to evaluate de-
fensive network enclave conﬁgurations(blue boxes) and contagion attacks(red
boxes) in AVAIL [56]. A Monte Carlo simulation of device compromise conta-
gion in a segemented network is used to assign the ﬁtness of the adversaries.
AVAIL uses Maximum Expected Utility as a ﬁtness score based on the mission
delay

Network segmentation divides the network topologically into enclaves that
serve as isolation units to deter inter-enclave contagion. How much network
segmentation is helpful is a tradeoﬀ. On the one hand, a more segmented net-
work provides lower mission eﬃciency because of increased overhead in inter-
enclave communication. On the other hand, smaller enclaves contain com-
promise by limiting the spread rate, and their cleansing incurs fewer mission
delays. Adding complexity, given some segmentation, a network operator can
monitor threats and utilize cleansing policies to detect and dislodge attackers,
with the caveat of cost versus eﬃcacy.

AVAIL assumes an enterprise network in carrying out a mission, and that
an adversary employs availability attacks against the network to disrupt it.
Speciﬁcally, the attacker starts by using an exploit to compromise a vulnera-
ble device on the network. This inﬂicts a mission delay when a mission critical
device is infected. The attacker moves laterally to compromise additional de-
vices to further delay the mission. Fig 12 shows AVAIL.

AVAIL employs a Monte Carlo simulation model as its engagement en-
vironment. Malware contagion of a speciﬁc spread rate is assumed. The de-
fender decides placement of mission devices and tap sensitivities in the pre-
determined enclave segmentation. The attacker decides the strength, duration
and number of attacks in an attack plan targeting all enclaves. For a network
with a set of four enclave topologies, the framework is able to generate strong
availability attack patterns that were not identiﬁed a priori. It also identiﬁes
eﬀective conﬁgurations that minimize mission delay when facing these attacks.

Adversarial Genetic Programming for Cyber Security

23

Fig. 13: DARK-HORSE ﬁtness evaluation(left side) has a defensive SDN sys-
tem based on the POX SDN Controller that creates diﬀerent network views
and manipulates traﬃc, and an attacker that performs NMAP scans in a
mininet simulation. The scan results are passed into a ﬁtness function that
assigns ﬁtness values for the adversaries’ conﬁgurations. The search in the
competitive coevolutionary algorithm uses Maximum Expected Utility of the
detection time to assign a ﬁtness value.

4.4 DARK-HORSE – Internal Reconnaissance in Software Deﬁned Networks

Once an adversary has compromised a network endpoint, they can perform
network reconnaissance [127]. After reconnaissance provides a view of the net-
work and an understanding of where vulnerable nodes are located, attackers
are able to execute a plan of attack. One way to protect against reconnais-
sance is by obfuscating the network to delay the attacker. This approach is
well suited to software deﬁned networks (SDN) such as those deployed in cloud
server settings because it requires programmability that they support [68]. The
SDN controller knows which machines are actually on the network and can
superﬁcially alter (without function loss) the network view of each node, as
well as place decoys (honeypots) on the network to mislead, trap and slow
down reconnaissance. DARK-HORSE is shown in Fig. 13.

One such multi-component deceptive defense system [2] foils scanning by
generating “camouﬂaged” versions of the actual network and providing them
to hosts when they renew their DHCP leases. We use this deception system
and mininet [134] within the framework as an engagement environment. This
allows us to explore the dynamics between attacker and defender on a network
where the deception and reconnaissance strategies can be adapted in response
to each other [104].

A deception strategy is executed through a modiﬁed POX SDN controller.
A reconnaissance strategy is executed by an NMAP scan[82]. The attacker
strategy includes choices of: which IP addresses to scan, how many IP addresses
to scan, which subnets to scan, the percent of the subnets to scan, the scanning
speed, and the type of scan. The defender strategy includes choices of: the
number of subnets to set up, the number of honeypots, the distribution of the
real hosts throughout the subnets, and the number of real hosts that exist on
the network. Fitness is comprised of four components: how fast the defender
detects that there is a scan taking place, the total time it takes to run the scan,
the number of times that the defender detects the scanner, and the number of

24

Una-May O’Reilly et al.

Table 2: How RIVALS components are conﬁgured to express speciﬁc use cases.

Use Case

Component

NAME

Robustness
vs Denial
DIFFRACTED DARK-HORSE

Deception vs Re-
connaissance

Isolation vs Con-
tagion
AVAIL

Threat Environment
Evaluation
Objective

Behavior: Attacker

Behavior: Defender

Adaptivity
Text description

P2P vs DDOS
ALFA sim
Mission disrup-
tion
Node/Edge im-
pairment
Network
tings
Yes
Section 4.2

set-

Pox SDN vs Nmap
Mininet
Detection speed

Enclave vs Malware
High level Sim
Mission delay

Scanning parameters

Strength & Duration

Honeypots

No
Section 4.4

Network taps & de-
vice placement
No
Section 4.3

real hosts that the scanner discovers. Through experimentation and analysis,
the framework is able to discover conﬁgurations that the defender can use to
signiﬁcantly increase its ability to detect scans. Similarly, there are speciﬁc
reconnaissance conﬁgurations that have a better chance of being undetected.

4.5 RIVALS Summary

We summarize RIVALS use cases with Table 2 and its architecture with
Fig. 10. The RIVALS framework is one example of Adversarial Genetic Pro-
gramming for Cyber Security, where the domain of network security is one of
many possibilities in cyber security. Possible future steps are elaborated in the
next section.

5 Taking Stock and Moving Forward

Summary Considering the paper from bottom to top, we described three use
cases: DIFFRACTED, AVAIL, and DARK-HORSE . For 3 speciﬁc network
security contexts, they investigate unique threat environments, objectives and
behaviors for their adversary species, and varying capacities to adapt during
an attack on a mission. They draw upon the RIVALS framework in which
adversarial arms races are the activity of interest. RIVALS is an example of
Adversarial Genetic Programming for Cyber Security and is motivated by a
call to arms to work on automated defensive reaction to waves of attacks. RI-
VALS pushes towards this goal by considering how both attack and defense
adapt to each other. While we identiﬁed a breadth of applications to cyber
security in the set of EAs we surveyed, we found just a modest number of
extant adversarial GP that represented approaches for behavior investigation
and two population dynamics, the latter combining competitive coevolution

Adversarial Genetic Programming for Cyber Security

25

with GP. The body of prior work relevant to cyber security from AI and games
and software engineering more generally informs the reader as to how com-
petitive coevolutionary algorithms and EAs can be used as building blocks
in diﬀerent adversarial contexts. Finally, at the top, we argue that Adversar-
ial Genetic Programming for Cyber Security is compellingly worthy of future
community attention because of its potential to solve a critical and growing
set of challenges in cyber security and because of how well GP and adversarial
evolution match the technical nature of the challenges.

Future directions To end, we consider what future research questions and di-
rections of study, stemming from the domain of cyber security, are prompted
by Adversarial GP.

We forecast explorations driven by the wide array of cyber security sce-
narios will arise. There is a plethora of attack surfaces. We have mentioned
some in Section 3.3, however, there are others such as networked cyber phys-
ical systems, ransomware, gadgets and malware. For example, how can GP
help examine the adversarial cyber security of a power grid or self-driving
cars? How could ransomware’s next mutation be predictable? Can GP lever-
age code repositories and gadgets to discover new malware? Social engineering
is currently an Achilles heel for security measures because it preys on human
nature and once privileged access has been obtained, it is much harder to
discern an attacker. Insider threats similarly disguise attacks. How can GP
inform insider threats and social engineering?

One challenge for the GP community is to become adequately conversant
in cyber security topics (though no member needs to be conversant in all of
them). Collaborations with cyber security researchers seem advisable, oﬀering
additive and synergistic beneﬁts. It will be important to identify the most
appropriate level of abstractions from which to design GP languages or func-
tion and terminal sets. It will be imperative to develop metrics of success and
paths to technology transfer and solution deployment. At a practical level,
undoubtedly new modeling and simulation modeling platforms will be needed.
They will need to be general purpose (somewhat like RIVALS ) and speciﬁc.
Undoubtedly some will need to be scaled due to the computational cost of
executing a mission.

We forecast the opportunity for extensions and innovations in GP and
coevolutionary algorithms for cyber security. Diﬀerent patterns and rates of
evolution will be observed across diﬀerent security scenarios. The opening to
develop new algorithmic models of these phenomena is exciting. GP evolves
behavior but many diﬀerent expressions of behavior remain unexplored. De-
veloping the new behavioral evolutionary capabilities that will be needed is
both challenging and motivating.

We also forecast that research into Adversarial Genetic Programming for
Cyber Security will push bridge building to other research areas. One impetus
will be the quest to describe at a ﬁner granularity what is happening during
cyber evolution. For this, it may be advisable to consider evolution through the
lens of individuals, such as how Artiﬁcial Life (ALife) [83] models individuals.

26

Una-May O’Reilly et al.

What cyber security scenario should be studied with ALife? How can agents in
a cyber security ALife system be represented by evolvable GP behaviors? What
if a GP defender “died” after an attack and attackers starve as they fail to
penetrate defenses? How would dynamics at this scale oﬀer diﬀerent insights?
What would a simulation of the DDOS attack ecosystem reveal about the
progression of botnet sizes if intra-species competition was examined? What
can ALife studies into ecosystem dynamics around intra-species competition
and cooperation reveal?

Arguably, adversarial GP is a form of agent-based modeling (ABM, [90])
where agents are GP executable structures. Some ABM systems model more
complex domains while the agents have simpler strategy spaces. Are there
ABM investigations such as those of ﬁnancial markets, crowd control, infec-
tious diseases or traﬃc simulation that suggest innovative transfer to Adversar-
ial GP and cyber security? Both ALife and ABM have examples that consider
the spatial dimension of a domain. Competitive coevolutionary algorithms
have spatial models. Interesting new models lie at these intersections.

Another area with potentially valuable interaction is Machine Learning
(ML). Statistical machine learning relies on retrospective training data to
learn a model capable of generalizing to new unseen data drawn from the
same distribution as the retrospective data. In contrast, Adversarial Genetic
Programming for Cyber Security is not data driven and this conveys it a niche.
However, what can be transferred from the studies that have started to bridge
supervised learning and test-based co-optimization[107]? Adversarial classiﬁ-
cation [36] as a game between classiﬁer and adversary also appears in ML. As
well, Generative Adversarial Networks (GANs) [52] derive generative models
from samples of a distribution using adversarial neural network training. Co-
evolution has been applied to improve the robustness and scalability of these
systems [116]. Competitive coevolution has also been combined with multi-
layer perceptron classiﬁers with ﬂoating point representation [29].

Studies of adversarial coevolution in cyber security based on data that clas-
sify attacks using machine learning methods exist, e.g. see a pro-active defense
for evolving cyber threats and a predictive defense against evolving adversaries
in [31,32,33]. In adversarial Machine Learning the attacker manipulates data
in order to defeat the Machine Learning model [80, 59,20]. Can coevolution be
used to anticipate continual adversarial evasion and guide model hardening?
Game theory considers equilibria and paths to equilibria. What is an equi-
librium in cyber security? It could be the complete wipeout of one side of the
adversarial equation. Or, it could be the point where an attacker chooses not
to target a defense because it is less expensive to go elsewhere. It could be
a Nash equilibrium where neither attacker or defender has a better tactical
position to go to unless the other simultaneously changes also. One direction
should investigate how these game theoretic notions can inform the highly
empirical, algorithmic systems of Adversarial GP.

We believe the future directions are not enumerable because the likelihood
of new adaptations by adversaries will never be zero. To date, defenses expose
far more attack surface than they can protect and attackers only need to ﬁnd

Adversarial Genetic Programming for Cyber Security

27

one crack to penetrate. To this end, the emerging importance of Adversarial
Genetic Programming for Cyber Security is not likely to fade. We trust this
justiﬁes our call to arms.

Acknowledgements

This was supported by the CSAIL CyberSecurity Initiative. This material is
based upon work supported by DARPA. The views and conclusions contained
herein are those of the authors and should not be interpreted as necessarily
representing the oﬃcial policies or endorsements. Either expressed or implied
of Applied Communication Services, or the US Government. This project has
received funding from the European Unions Horizon 2020 research and in-
novation programme under the Marie Skodowska-Curie grant agreement No
799078.

References

1. Abbass, H.A.: The art of red teaming.

In: Computational Red Teaming, pp. 1–45.

Springer (2015)

2. Achleitner, S., Laporta, T., McDaniel, P.: Cyber deception: Virtual networks to de-
fend insider reconnaissance. In Proceedings of the 2016 International Workshop on
Managing Insider Security Threats pp. 57–68 (2016)

3. Adamopoulos, K., Harman, M., Hierons, R.M.: How to overcome the equivalent mutant
problem and achieve tailored selective mutation using co-evolution. In: Genetic and
Evolutionary Computation–GECCO 2004, pp. 1338–1349. Springer (2004)

4. Akamai: Akamais State

the
rep., Akamai Technologies,

Internet

of

Tech.

report.
//www.akamai.com/us/en/multimedia/documents/state-of-the-internet/
q1-2017-state-of-the-internet-security-report.pdf

(2017).

Inc.

/ Security Report

- Q1
2017
URL https:

5. Akamai: Akamais State

the
rep., Akamai Technologies,

Internet

of

Tech.

report.
//www.akamai.com/us/en/multimedia/documents/state-of-the-internet/
q3-2017-state-of-the-internet-security-report.pdf

(2017).

Inc.

/ Security Report

- Q3
2017
URL https:

Technologies:
reports

6. Akamai
curity
us/en/about/our-thinking/state-of-the-internet-report/
global-state-of-the-internet-security-ddos-attack-reports.jsp

the
URL

internet

(2017).

State

of

se-
quarterly
https://www.akamai.com/

7. Alex, J.C.: Behavior trees for next-gen game ai.

In: Game Developers Conference,

Lyon, France, pp. 3–4 (2007)

8. Anand, S., Burke, E.K., Chen, T.Y., Clark, J., Cohen, M.B., Grieskamp, W., Harman,
M., Harrold, M.J., McMinn, P., et al.: An orchestrated survey of methodologies for
automated software test case generation. Journal of Systems and Software 86(8),
1978–2001 (2013)

9. Angeline, P.J., Pollack, J.B.: Competitive environments evolve better solutions for
complex tasks. In: Proceedings of the Fifth International Conference (GA93), Genetic
Algorithms, pp. 264–270 (1993)

10. Antonakakis, M., April, T., Bailey, M., Bernhard, M., Bursztein, E., Cochran, J., Du-
rumeric, Z., Halderman, J.A., Invernizzi, L., Kallitsis, M., et al.: Understanding the
mirai botnet. In: 26th {USENIX} Security Symposium ({USENIX} Security 17), pp.
1093–1110 (2017)

28

Una-May O’Reilly et al.

11. Antonio, L.M., Coello, C.A.C.: Coevolutionary multi-objective evolutionary algo-
IEEE Transactions on Evolutionary Com-

rithms: A survey of the state-of-the-art.
putation pp. 1–16 (2018). DOI 10.1109/TEVC.2017.2767023

12. Applegate, C., Elsaesser, C., Sanborn, J.: An architecture for adversarial planning.

Systems, Man and Cybernetics, IEEE Transactions on 20(1), 186–194 (1990)

13. Arcuri, A., Yao, X.: Coevolving programs and unit tests from their speciﬁcation. In:
Proceedings of the twenty-second IEEE/ACM international conference on Automated
software engineering, pp. 397–400. ACM (2007)

14. Arcuri, A., Yao, X.: Co-evolutionary automatic programming for software development.

Information Sciences 259, 412–432 (2014)

15. Axelrod, R.: The Evolution of Cooperation. 10. Basic, NY, New York (1984)
16. Axelrod, R., et al.: The evolution of strategies in the iterated prisoners dilemma. The

dynamics of norms pp. 1–16 (1987)

17. Bari, A.G., Gaspar, A., Wiegand, R.P., Bucci, A.: Selection methods to relax strict ac-
ceptance condition in test-based coevolution. In: 2018 IEEE Congress on Evolutionary
Computation (CEC), pp. 1–8. IEEE (2018)

18. Barr, E., Harman, M., McMinn, P., Shahbaz, M., Yoo, S.I.: The oracle problem in

software testing: A survey (2015)

19. Beard, D.: Enhancing Automated Red Teaming with Monte Carlo Tree Search (2011)
20. Biggio, B., Roli, F.: Wild patterns: Ten years after the rise of adversarial machine

learning. arXiv preprint arXiv:1712.03141 (2017)

21. Bodeau, D., Graubart, R.: Characterizing eﬀects on the cyber adversary: A vocabulary

for analysis and assessment. The MITRE Corporation, Bedford, MA (2013)

22. Bongard, J.C., Lipson, H.: Nonlinear system identiﬁcation using coevolution of models
and tests. IEEE Transactions on Evolutionary Computation 9(4), 361–384 (2005)
23. Boyd, R.: Mistakes allow evolutionary stability in the repeated prisoner’s dilemma

game. Journal of theoretical Biology 136(1), 47–56 (1989)

24. Brian Krebs: Akamai

https:
//krebsonsecurity.com/2016/11/akamai-on-the-record-krebsonsecurity-attack/
(2016). (Accessed October 10,2018)

on the Record KrebsOnSecurity Attack.

25. Bronfman-Nadas, R., Zincir-Heywood, N., Jacobs, J.T.: An artiﬁcial arms race: Could
it improve mobile malware detectors? In: 2018 Network Traﬃc Measurement and
Analysis Conference (TMA), pp. 1–8. IEEE (2018)

26. Bucci, A.: Emergent geometric organization and informative dimensions in coevolu-

tionary algorithms. Ph.D. thesis, Brandeis University (2007)

27. Cardona, A.B., Togelius, J., Nelson, M.J.: Competitive coevolution in ms. pac-man.

In: 2013 IEEE Congress on Evolutionary Computation, pp. 1403–1410 (2013)

28. Cartlidge, J., Bullock, S.: Combating coevolutionary disengagement by reducing par-

asite virulence. Evolutionary Computation 12(2), 193–222 (2004)

29. Castellani, M.: Competitive co-evolution of multi-layer perceptron classiﬁers. Soft

Computing 22(10), 3417–3432 (2018)

30. Chellapilla, K., Fogel, D.B.: Evolution, neural networks, games, and intelligence. Pro-

ceedings of the IEEE 87(9), 1471–1496 (1999)

31. Colbaugh, R., Glass, K.: Proactive defense for evolving cyber threats. In: Intelligence
and Security Informatics (ISI), 2011 IEEE International Conference on, pp. 125–130.
IEEE (2011)

32. Colbaugh, R., Glass, K.: Predictive defense against evolving adversaries.

In: Intel-
ligence and Security Informatics (ISI), 2012 IEEE International Conference on, pp.
18–23. IEEE (2012)

33. Colbaugh, R., Glass, K.: Moving target defense for adaptive adversaries. In: Intelligence
and Security Informatics (ISI), 2013 IEEE International Conference on, pp. 50–55.
IEEE (2013)

34. Crandall, J.R., Ensaﬁ, R., Forrest, S., Ladau, J., Shebaro, B.: The ecology of malware.
In: Proceedings of the 2008 workshop on New security paradigms, pp. 99–106. ACM
(2009)

35. Crawford-Marks, R., Spector, L., Klein, J.: Virtual witches and warlocks: A quid-
ditch simulator and quidditch-playing teams coevolved via genetic programming. In:
Late-Breaking Papers of GECCO-2004, the Genetic and Evolutionary Computation
Conference. Published by the International Society for Genetic and Evolutionary Com-
putation (2004)

Adversarial Genetic Programming for Cyber Security

29

36. Dalvi, N., Domingos, P., Sanghai, S., Verma, D., et al.: Adversarial classiﬁcation. In:
Proceedings of the tenth ACM SIGKDD international conference on Knowledge dis-
covery and data mining, pp. 99–108. ACM (2004)

37. DARPA: The World’s First All-Machine Hacking Tournament.

http://archive.

darpa.mil/cybergrandchallenge/ (2016). (Accessed October 10,2018)
38. DeLoura, M.A.: Game programming gems 2. Cengage learning (2001)
39. DeMilli, R., et al.: Constraint-based automatic test data generation. Software Engi-

neering, IEEE Transactions on 17(9), 900–910 (1991)

40. Ehrlich, P.R., Raven, P.H.: Butterﬂies and plants: a study in coevolution. Evolution

18(4), 586–608 (1964)

41. Evans, D., Nguyen-Tuong, A., Knight, J.: Eﬀectiveness of moving target defenses. In:

Moving Target Defense, pp. 29–48. Springer (2011)

42. Ficici, S.G.: Solution concepts in coevolutionary algorithms. Ph.D. thesis, Brandeis

University (2004)

43. Flickr: Fireﬂies brighter (2014). URL https://www.flickr.com/photos/antoniseb/
14325795079/in/gallery-flickr-72157645552049011flickr. Picture taken by Jay
Cross - License: CC-BY-SA-2.0

44. Fogel, D.: Blondie24: Playing at the edge of artiﬁcial intelligence (2001)
45. Ford, R., Bush, M., Bulatov, A.: Predation and the cost of replication: New approaches

to malware prevention? computers & security 25(4), 257–264 (2006)

46. Forrest, S., Hofmeyr, S.A., Somayaji, A., Longstaﬀ, T.A.: A sense of self for unix
processes. In: Proceedings 1996 IEEE Symposium on Security and Privacy, pp. 120–
128. IEEE (1996)

47. Fraser, O.L., Zincir-Heywood, N., Heywood, M., Jacobs, J.T.: Return-oriented pro-
gramme evolution with roper: a proof of concept. In: Proceedings of the Genetic and
Evolutionary Computation Conference Companion, pp. 1447–1454. ACM (2017)
48. Garcia, D., Lugo, A.E., Hemberg, E., O’Reilly, U.M.: Investigating coevolutionary
archive based genetic algorithms on cyber defense networks. In: Proceedings of the Ge-
netic and Evolutionary Computation Conference Companion, GECCO ’17, pp. 1455–
1462. ACM, New York, NY, USA (2017)

49. Garcia, S., Grill, M., Stiborek, J., Zunino, A.: An empirical comparison of botnet

detection methods. computers & security 45, 100–123 (2014)

50. Godefroid, P., Klarlund, N., Sen, K.: Dart: directed automated random testing. In:

ACM Sigplan Notices, vol. 40, pp. 213–223. ACM (2005)

51. Goldberg, D.E.: Genetic Algorithms in Search, Optimization and Machine Learning,
1st edn. Addison-Wesley Longman Publishing Co., Inc., Boston, MA, USA (1989)
52. Goodfellow, I.J., Shlens, J., Szegedy, C.: Explaining and harnessing adversarial exam-

ples. arXiv preprint arXiv:1412.6572 (2014)

53. Gupta, A., Kuppili, P., Akella, A., Barford, P.: An empirical study of malware evolu-
tion. In: Communication Systems and Networks and Workshops, 2009. COMSNETS
2009. First International, pp. 1–10. IEEE (2009)

54. Hanford, K.V.: Automatic generation of test cases. IBM Systems Journal 9(4), 242–257

(1970)

55. Harper, R.: Evolving robocode tanks for evo robocode. Genetic Programming and

Evolvable Machines 15(4), 403–431 (2014)

56. Hemberg, E., Zipkin, J.R., Skowyra, R.W., Wagner, N., O’Reilly, U.M.: Adversarial
co-evolution of attack and defense in a segmented computer network environment. In:
Proceedings of the Genetic and Evolutionary Computation Conference Companion,
pp. 1648–1655. ACM (2018)

57. Hingston, P., Preuss, M.: Red teaming with coevolution. In: Evolutionary Computa-
tion (CEC), 2011 IEEE Congress on, pp. 1155–1163 (2011). DOI 10.1109/CEC.2011.
5949747

58. Hornby, G.S., Mirtich, B.: Diﬀuse versus true coevolution in a physics-based world. In:
Proceedings of the 1st Annual Conference on Genetic and Evolutionary Computation-
Volume 2, pp. 1305–1312. Morgan Kaufmann Publishers Inc. (1999)

59. Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J.: Adversarial machine
learning. In: Proceedings of the 4th ACM workshop on Security and artiﬁcial intelli-
gence, pp. 43–58. ACM (2011)

30

Una-May O’Reilly et al.

60. Iliopoulos, D., Adami, C., Szor, P.: Darwin inside the machines: malware evolution and

the consequences for computer security. arXiv preprint arXiv:1111.2503 (2011)

61. Kayacık, H.G.: Can the best defense be a good oﬀense? Evolving (MIMICRY) attacks
for detector vulnerability testing under a black-boxassumption. Ph.D. thesis, Dalhousie
University Halifax (2009)

62. Kayacık, H.G., Zincir-Heywood, A.N., Heywood, M.I.: Can a good oﬀense be a good
defense? Vulnerability testing of anomaly detectors through an artiﬁcial arms race.
Applied Soft Computing 11(7), 4366–4383 (2011)

63. Keaveney, D., O’Riordan, C.: Evolving coordination for real-time strategy games. IEEE
Transactions on Computational Intelligence and AI in Games 3(2), 155–167 (2011)
64. Kewley, R., Embrechts, M.: Computational military tactical planning system. Systems,
Man, and Cybernetics, Part C: Applications and Reviews, IEEE Transactions on 32(2),
161–171 (2002). DOI 10.1109/TSMCC.2002.801352

65. Khanchi, S., Vahdat, A., Heywood, M.I., Zincir-Heywood, A.N.: On botnet detection
with genetic programming under streaming data label budgets and class imbalance.
Swarm and evolutionary computation 39, 123–140 (2018)

66. Kim, H.S., Cho, S.B.: An eﬃcient genetic algorithm with less ﬁtness evaluation by
clustering. Proceedings of the 2001 Congress on Evolutionary Computation pp. 887–
894 (2001)

67. Kinnear, K.E., Langdon, W.B., Spector, L., Angeline, P.J., O’Reilly, U.M.: Advances

in genetic programming, vol. 3. MIT press (1999)

68. Kirkpatrick, K.: Software-deﬁned networking. Communications of the ACM 56(9)

(2013)

69. Koza, J.R.: Genetic programming II, automatic discovery of reusable subprograms.

MIT Press, Cambridge, MA (1992)

70. Krawiec, K., Heywood, M.: Solving complex problems with coevolutionary algorithms.
In: Proceedings of the 2016 on Genetic and Evolutionary Computation Conference
Companion, pp. 687–713. ACM (2016)

71. Krawiec, K., Szubert, M.G.: Learning n-tuple networks for othello by coevolutionary
gradient search. In: Proceedings of the 13th Annual Conference on Genetic and Evo-
lutionary Computation, GECCO ’11, pp. 355–362. ACM (2011)

72. Lara-Cabrera, R., Cotta, C., Fernndez-Leiva, A.J.: A review of computational intel-
In: 2013 IEEE Symposium on Foundations of Computational

ligence in rts games.
Intelligence (FOCI), pp. 114–121 (2013)

73. LaRoche, P., Zincir-Heywood, N., Heywood, M.I.: Evolving tcp/ip packets: a case study
of port scans. In: 2009 IEEE Symposium on Computational Intelligence for Security
and Defense Applications, pp. 1–8. IEEE (2009)

74. Le Goues, C., Nguyen-Tuong, A., Chen, H., Davidson, J.W., Forrest, S., Hiser, J.D.,
Knight, J.C., Van Gundy, M.: Moving target defenses in the helix self-regenerative
architecture. In: Moving Target Defense II, pp. 117–149. Springer (2013)

75. Lemczyk, M., Heywood, M.I.: Training binary gp classiﬁers eﬃciently: a pareto-
In: European Conference on Genetic Programming, pp.

coevolutionary approach.
229–240. Springer (2007)

76. Lim, C.U., Baumgarten, R., Colton, S.: Evolving behaviour trees for the commercial
game DEFCON. In: European Conference on the Applications of Evolutionary Com-
putation, pp. 100–110. Springer (2010)

77. Lippmann, R., Haines, J.W., Fried, D.J., Korba, J., Das, K.: The 1999 darpa oﬀ-line

intrusion detection evaluation. Computer networks 34(4), 579–595 (2000)

78. Liskowski, P., Krawiec, K.: Non-negative matrix factorization for unsupervised deriva-
In: Proceedings of the 2016 on

tion of search objectives in genetic programming.
Genetic and Evolutionary Computation Conference, pp. 749–756. ACM (2016)

79. Liskowski, P., Krawiec, K.: Online discovery of search objectives for test-based prob-

lems. Evolutionary computation 25(3), 375–406 (2017)

80. Lowd, D., Meek, C.: Adversarial learning.

In: Proceedings of the eleventh ACM
SIGKDD international conference on Knowledge discovery in data mining, pp. 641–
647. ACM (2005)

81. Luke, S., et al.: Genetic programming produced competitive soccer softbot teams for

robocup97. Genetic Programming 1998, 214–222 (1998)

Adversarial Genetic Programming for Cyber Security

31

82. Lyon, G.: Nmap network scanner. https://nmap.org/ (2018).

[Online; accessed 6-

July-2018]

83. Macal, C.M., North, M.J.: Tutorial on agent-based modelling and simulation. Journal

of simulation 4(3), 151–162 (2010)

84. Mahoney, M.V., Chan, P.K.: An analysis of the 1999 darpa/lincoln laboratory eval-
uation data for network anomaly detection.
In: G. Vigna, C. Kruegel, E. Jonsson
(eds.) Recent Advances in Intrusion Detection, pp. 220–237. Springer Berlin Heidel-
berg, Berlin, Heidelberg (2003)

85. Mazurczyk, W., Drobniak, S., Moore, S.: Towards a systematic view on cybersecurity

ecology. arXiv preprint arXiv:1505.04207 (2015)

86. McDonald, M.L., Upton, S.C.: Investigating the dynamics of competition: coevolving
red and blue simulation parameters. In: Proceedings of the 37th conference on Winter
simulation, pp. 1008–1012. Winter Simulation Conference (2005)

87. Milano, N., Carvalho, J.T., Nolﬁ, S.: Moderate environmental variation across gener-
ations promotes the evolution of robust solutions. Artiﬁcial life 24(4), 277–295 (2019)
88. Miles, C., Quiroz, J., Leigh, R., Louis, S.J.: Co-evolving inﬂuence map tree based
strategy game players. In: Computational Intelligence and Games, 2007. CIG 2007.
IEEE Symposium on, pp. 88–95. IEEE (2007)

89. Mitchell, M.: Coevolutionary learning with spatially distributed populations. Compu-

tational intelligence: principles and practice (2006)

90. Moran, N., Pollack, J.: Eﬀects of cooperative and competitive coevolution on complex-
ity in a linguistic prediction game. In: Artiﬁcial Life Conference Proceedings 14, pp.
298–205. MIT Press (2017)

91. Musliner, D.J., Friedman, S.E., Rye, J.M., Marble, T.: Meta-control for adaptive cy-
bersecurity in fuzzbuster. In: Self-Adaptive and Self-Organizing Systems (SASO), 2013
IEEE 7th International Conference on, pp. 219–226. IEEE (2013)

92. Musliner D. J. Friedman Scott E., R.J.M.: Automated fault analysis and ﬁlter genera-
tion for adaptive cybersecurity. In: Proc. 6th Int’l Conf. on Adaptive and Self-Adaptive
Systems and Applications (2014)

93. Nettles, A.B.: The president has no clothes: the case for broader application of red

teaming within homeland security. Tech. rep., DTIC Document (2010)

94. Nicolau, M., Perez-Liebana, D., ONeill, M., Brabazon, A.: Evolutionary behavior tree
approaches for navigating platform games. IEEE Transactions on Computational In-
telligence and AI in Games 9(3), 227–238 (2017)

95. Nogueira-Collazo, M., Porras, C.C., Fernndez-Leiva, A.J.: Competitive algorithms for
coevolving both game content and ai. a case study:planet wars. IEEE Transactions on
Computational Intelligence and AI in Games 8(4), 325–337 (2016)

96. Okhravi, H., Hobson, T., Bigelow, D., Streilein, W.: Finding focus in the blur of

moving-target techniques.
10.1109/MSP.2013.137

Security Privacy, IEEE 12(2), 16–26 (2014). DOI

97. de Oliveira, A.A.L., Camilo-Junior, C.G., Vincenzi, A.M.R.: A coevolutionary algo-
rithm to automatic test case selection and mutant in mutation testing. In: 2013 IEEE
Congress on Evolutionary Computation, pp. 829–836 (2013)

98. Olsson, B.: Co-evolutionary search in asymmetric spaces. Information Sciences 133(3-

4), 103–125 (2001)

99. O’Neill, M., Ryan, C.: Grammatical evolution: evolutionary automatic programming

in an arbitrary language, vol. 4. Springer (2003)

100. O’Reilly, U.M., Angeline, P.J.: Introduction to the special issue: Trends in evolutionary

methods for program induction. Evolutionary Computation 5(2), v–ix (1997)

101. O’Reilly, U.M., Erik, H.: An artiﬁcial coevolutionary framework for adversarial ai. In:
Adversary-aware Learning techniques and trends in Cybersecurity, AAAI Fall Sympo-
sium (2018)

102. Ostaszewski, M., Seredynski, F., Bouvry, P.: Coevolutionary-based mechanisms for
network anomaly detection. Journal of Mathematical Modelling and Algorithms 6(3),
411–431 (2007)

103. Perez, D., Nicolau, M., ONeill, M., Brabazon, A.: Evolving behaviour trees for the
Mario AI competition using grammatical evolution. In: European Conference on the
Applications of Evolutionary Computation, pp. 123–132. Springer (2011)

32

Una-May O’Reilly et al.

104. Pertierra, M.: Investigating coevolutionary algorithms for expensive ﬁtness evaluations
in cybersecurity. Master’s thesis, Massachusetts Institute of Technology (2018)
105. Petrlic, A.: Circular economy: a coevolutionary perspective on diversity.

uwf

UmweltWirtschaftsForum 24(2), 253–260 (2016)

106. Pollack, J.B., Blair, A.D.: Co-evolution in the successful learning of backgammon strat-

egy. Machine Learning 32(3), 225–240 (1998)

107. Popovici, E.: Bridging supervised learning and test-based co-optimization. Journal of

Machine Learning Research 18(38), 1–39 (2017)

108. Popovici, E., Bucci, A., Wiegand, R.P., De Jong, E.D.: Coevolutionary Principles, pp.

987–1033. Springer Berlin Heidelberg, Berlin, Heidelberg (2012)

109. Popovici, E., Bucci, A., Wiegand, R.P., De Jong, E.D.: Coevolutionary principles. In:

Handbook of Natural Computing, pp. 987–1033. Springer (2012)

110. Popovici, E., Winston, E.: A framework for co-optimization algorithm performance
and its application to worst-case optimization. Theoretical Computer Science 567,
46–73 (2015)

111. Prado Sanchez, D.: Visualizing adversaries - transparent pooling approaches for deci-
sion support in cybersecurity. Master’s thesis, Massachusetts Institute of Technology
(2018)

112. Rosin, C.D., Belew, R.K.: New methods for competitive coevolution. Evolutionary

Computation 5(1), 1–29 (1997)

113. Rush, G., Tauritz, D.R., Kent, A.D.: Coevolutionary agent-based network defense
lightweight event system (CANDLES).
In: Proceedings of the Companion Publica-
tion of the 2015 on Genetic and Evolutionary Computation Conference, pp. 859–866.
ACM (2015)

114. Sagarin, R.D., Taylor, T.: Natural security: how biological systems use information to

adapt in an unpredictable world. Security Informatics 1(1), 14 (2012)

115. Sanchez, D.P., Pertierra, M.A., Hemberg, E., O’Reilly, U.M.: Competitive coevolu-
tionary algorithm decision support. In: Proceedings of the Genetic and Evolutionary
Computation Conference Companion, pp. 300–301. ACM (2018)

116. Schmiedlechner, T., Al-Dujaili, A., Hemberg, E., O’Reilly, U.M.: Towards distributed

coevolutionary gans. arXiv preprint arXiv:1807.08194 (2018)

117. Scott, K., Davidson, J.: Strata: A software dynamic translation infrastructure. In: In

IEEE Workshop on Binary Translation (2001)

118. Scott Hilton: Dyn Analysis Summary Of Friday October 21 Attack. https://dyn.
com/blog/dyn-analysis-summary-of-friday-october-21-attack/ (2016). (Accessed
October 10,2018)

119. Service, T., Tauritz, D.: Increasing infrastructure resilience through competitive co-
evolution. New Mathematics and Natural Computation 5(02), 441–457 (2009)
120. Sims, K.: Evolving 3d morphology and behavior by competition. Artiﬁcial life 1(4),

353–372 (1994)

121. Sipper, M.: Evolved to Win. Lulu. com (2011)
122. Sipper, M., Azaria, Y., Hauptman, A., Shichel, Y.: Designing an evolutionary strate-
gizing machine for game playing and beyond. IEEE Transactions on Systems, Man,
and Cybernetics, Part C (Applications and Reviews) 37(4), 583–593 (2007)

123. Smith, R.E.: Co-adaptive genetic algorithms: An example in othello strategy. In: Proc.

Florida Artiﬁcial Intelligence Research Symposium, 1994 (1994)

124. Smith, R.J., Heywood, M.I.: Coevolving deep hierarchies of programs to solve complex
tasks. In: Proceedings of the Genetic and Evolutionary Computation Conference, pp.
1009–1016. ACM (2017)

125. Son of Boss: Son of boss — Wikipedia, the free encyclopedia. https://en.wikipedia.

org/wiki/Son_of_Boss (2018). (Accessed October 10,2018)

126. Song, D., Heywood, M.I., Zincir-Heywood, A.N.: Training genetic programming on
half a million patterns: an example from anomaly detection. IEEE Transactions on
Evolutionary Computation 9(3), 225–239 (2005)

127. Sood, A., Enbody, R.: Targeted cyberattacks: a superset of advanced persistent threats.

IEEE security & privacy 11(1), 54–61 (2013)

128. Stanley, K.O., Bryant, B.D., Miikkulainen, R.: Real-time neuroevolution in the nero

video game. IEEE Transactions on Evolutionary Computation 9(6), 653–668 (2005)

Adversarial Genetic Programming for Cyber Security

33

129. Suarez-Tangil, G., Palomar, E., de Fuentes, J.M., Blasco, J., Ribagorda, A.: Automatic
rule generation based on genetic programming for event correlation. In: Computational
Intelligence in Security for Information Systems, pp. 127–134. Springer (2009)
130. Symantec Security Response: Mirai: what you need to know about the botnet
https://www.symantec.com/connect/blogs/

behind recent major DDoS attacks.
mirai-what-you-need-know-about-botnet-behind-recent-major-ddos-attacks
(2016). (Accessed October 10,2018)

131. Szubert, M., Jaskowski, W., Krawiec, K.: Coevolutionary temporal diﬀerence learning
for othello. In: 2009 IEEE Symposium on Computational Intelligence and Games, pp.
104–111 (2009)

132. Szubert, M., Jakowski, W., Krawiec, K.: On scalability, generalization, and hybridiza-
tion of coevolutionary learning: A case study for othello. IEEE Transactions on Com-
putational Intelligence and AI in Games 5(3), 214–226 (2013)

133. Talay, M.B., Calantone, R.J., Voorhees, C.M.: Coevolutionary dynamics of automotive
competition: Product innovation, change, and marketplace survival. Journal of Product
Innovation Management 31(1), 61–78

134. Team, M.: Mininet - realistic virtual sdn network emulator. http://mininet.org/

(2018). [Online; accessed 6-July-2018]

135. Togelius, J., Burrow, P., Lucas, S.M.: Multi-population competitive co-evolution of
In: 2007 IEEE Congress on Evolutionary Computation, pp.

car racing controllers.
4043–4050 (2007)

136. Weimer, W., Forrest, S., Le Goues, C., Nguyen, T.: Automatic program repair with
evolutionary computation. Communications of the ACM 53(5), 109–116 (2010)
137. Wikimedia Commons: Cuttleﬁsh changing color. URL https://upload.wikimedia.
org/wikipedia/commons/thumb/1/1c/Cuttlefish_color.jpg/636px-Cuttlefish_
color.jpg. Picture taken by Nick Hobgood - License: CC BY-SA 3.0

138. Wikimedia Commons: Misumena vatia with wasp (1998).

URL https://en.
wikipedia.org/wiki/File:Misumena.vatia.beute.wespe.1771.jpg#filelinks. Pic-
ture taken by Olaf Leillinger - License: CC-BY-SA-2.0/DE and GNU FDL

139. Wikimedia Commons: Viceroy butterﬂy (2005). URL https://commons.wikimedia.
org/wiki/File:Viceroy_Butterfly.jpg. License: CC BY-SA 3.0. Subject to dis-
claimers.

140. Wikimedia Commons: Monarch in may (2007). URL https://en.wikipedia.org/
wiki/Monarch_butterfly#/media/File:Monarch_In_May.jpg. Created: 29 May 2007
By Kenneth Dwain Harrelson - License: CC BY-SA 3.0

141. Wikimedia Commons: Bioluminnescence

in ocean organisms

(2014).

URL

https://en.wikipedia.org/wiki/Bioluminescence#/media/File:Squid_
Counterillumination.png. Picture taken by Chiswick Chap - License: CC BY-
SA 4.0

142. Wilkerson, J.L., Tauritz, D.: Coevolutionary automated software correction. In: Pro-
ceedings of the 12th Annual Conference on Genetic and Evolutionary Computation,
GECCO ’10, pp. 1391–1392. ACM, New York, NY, USA (2010)

143. Willard, G.: Understanding the co-evolution of cyber defenses and attacks to achieve

enhanced cybersecurity. Warfare 14, 17–31 (2015)

144. Williams, N., Mitchell, M.: Investigating the success of spatial coevolution. In: Pro-
ceedings of the 7th annual conference on Genetic and evolutionary computation, pp.
523–530. ACM (2005)

145. Winterrose, M.L., Carter, K.M.: Strategic evolution of adversaries against temporal
platform diversity active cyber defenses. In: Proceedings of the 2014 Symposium on
Agent Directed Simulation, p. 9. Society for Computer Simulation International (2014)
146. Wood, B.J., Duggan, R., et al.: Red teaming of advanced information assurance con-
cepts. In: DARPA Information Survivability Conference and Exposition, 2000. DIS-
CEX’00. Proceedings, vol. 2, pp. 112–118. IEEE (2000)

147. Wright Jr, D.: Financial alchemy: How tax shelter promoters use ﬁnancial products to

bedevil the irs (and how the irs helps them). Ariz. St. LJ 45, 611 (2013)

148. Xu, W., Qi, Y., Evans, D.: Automatically evading classiﬁers. In: Proceedings of the

2016 Network and Distributed Systems Symposium (2016)

149. Yuen, J.: Automated cyber red teaming. Tech. rep., DTIC Document (2015)

34

Una-May O’Reilly et al.

150. Zeng, F., Decraene, J., Low, M., Zhou, S., Cai, W.: Evolving optimal and diversiﬁed
military operational plans for computational red teaming. Systems Journal, IEEE
6(3), 499–509 (2012). DOI 10.1109/JSYST.2012.2190693

Appendix A

A.1 Fireﬂy squid bioluminescence defense

When ﬁreﬂy squid are seen from below by a predator, the bioluminescence
helps to match the squid’s brightness and color to the sea surface above.

A.2 A coevolutionary perspective of the U.S. automotive industry

Talay, Calantone, and Voorhees presented an study that explicitly terms com-
petitive interactions between ﬁrms “Red Queen competition”, in which gains
from innovations are relative and impermanent [133].

A.3 Advanced Persistent Threats and Ransomware

Some DOS attacks includes Advanced Persistent Threats (APT) and Ran-
somware. The ﬁrst ones have multiple stages starting at external reconnais-
sance then moving to intrusion (e.g. social engineering or use of zero day
exploits), laterally moving malware, command and control direction to data
exﬁltration and, ﬁnally, self-erasure. Ransomware, which largely preys upon
unpatched systems and which exploits anonymous payment channels enabled
by Bitcoin, has also recently become more frequent.

A.4 Cyber security attack categorization

Examples of attacks, classiﬁcations and taxonomies can be found at https:
//cwe.mitre.org/index.html. One categorization is: A) Advanced Persis-
tent Threats, “lurking” threats from resourceful persevering adversaries B) De-
nial of Service Attack, defense resource limitation and exposure, means of pen-
etrating systems C) Identity theft, e.g. impersonating users. Attacks are also
characterized by their stages on a timeline. Another characterization is based
on the attacker identity, from individuals to organized criminals and nation
states, and what resources they access, see [21] for details.

