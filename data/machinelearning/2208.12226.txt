Lifelong Learning for Neural powered Mixed Integer Programming

Sahil Manchanda, Sayan Ranu

Department of Computer Science and Engineering
Indian Institute of Technology, Delhi
{sahil.manchanda,sayanranu}@cse.iitd.ac.in

2
2
0
2

g
u
A
6
2

]

C
O
.
h
t
a
m

[

2
v
6
2
2
2
1
.
8
0
2
2
:
v
i
X
r
a

Abstract

Mixed Integer programs (MIPs) are typically solved by the
Branch-and-Bound algorithm. Recently, Learning to imitate
fast approximations of the expert strong branching heuristic
has gained attention due to its success in reducing the running
time for solving MIPs. However, existing learning-to-branch
methods assume that the entire training data is available in a
single session of training. This assumption is often not true,
and if the training data is supplied in continual fashion over
time, existing techniques suffer from catastrophic forgetting.
In this work, we study the hitherto unexplored paradigm of
Lifelong Learning to Branch on Mixed Integer Programs. To
mitigate catastrophic forgetting, we propose LIMIP, which is
powered by the idea of modeling an MIP instance in the form
of a bipartite graph, which we map to an embedding space
using a bipartite Graph Attention Network. This rich embed-
ding space avoids catastrophic forgetting through the appli-
cation of knowledge distillation and elastic weight consolida-
tion, wherein we learn the parameters key towards retaining
efﬁcacy and are therefore protected from signiﬁcant drift. We
evaluate LIMIP on a series of NP-hard problems and estab-
lish that in comparison to existing baselines, LIMIP is up to
50% better when confronted with lifelong learning.

1

Introduction and Related Work

Combinatorial optimization (CO) is a subclass of optimiza-
tion problems that deals with optimizing a certain objec-
tive function by selecting a subset of elements from a ﬁ-
nite set. Although CO problems are generally NP-hard (Taha
2014) from a complexity theory viewpoint, still they are
solved routinely in diverse ﬁelds such as capacity planning,
resource allocation, scheduling, and manufacturing (Taha
2014). It is common to formulate most of these CO prob-
lems as Mixed integer programs (MIPs) (Achterberg 2007).
However, these MIPs are difﬁcult to solve due to the non-
convexity of their feasible region. Instead of solving it
directly, their LP-relaxed versions are solved (Achterberg
2007). Modern solvers such as SCIP (Gamrath et al. 2020)
employ the Branch-and-Bound (B&B) (Achterberg 2007)
algorithm to solve these MIPs. B&B recursively partitions
the solution space into a search tree and then prunes sub-
trees that provably cannot generate an optimal solution. This
is an iterative process, which consists of making sequential

PrePrint

Figure 1: Illustration of catastrophic forgetting on SoA
method (Gasse et al. 2019) on Set Cover dataset. The plot
shows the rapid increase in the geometric mean of solving
time on instances of past problems when the model is fur-
ther trained sequentially on instances of a new problems.

decisions such as node selection, branching variable selec-
tion, etc., to direct the search procedure. The efﬁciency of
the B&B algorithm mainly depends upon the branching vari-
able selection and node selection (Achterberg 2007). In this
work, we focus on the former. In modern MIP solvers (Gam-
rath et al. 2020), the branching variable decisions are gener-
ally based upon hard-coded heuristics designed by experts
to direct the search process to solve an MIP (Achterberg
2007). Among various heuristics, strong branching is one
such heuristic that is highly effective in reducing the size
of Branch-and-Bound tree (Achterberg 2007; Gasse et al.
2019). However, its main disadvantage is the extremely high
computational cost associated with choosing the best vari-
able to branch. Hence, it is rarely used in practice (Achter-
berg 2007; Huang et al. 2021).

In order to utilize the advantage of the powerful strong
branching heuristic, however at a lower computational cost,
recently, multiple algorithms have been developed (Gasse
et al. 2019; Khalil et al. 2016; Nair et al. 2020; Gupta et al.
2020). At their core, they use imitation learning to learn fast
approximations of the strong branching heuristic on a fam-
ily of MIP instances. These algorithms estimate scores of
branching candidate variables quickly on unseen but sim-
ilar MIP instances. This paradigm is popularly known as
learning to branch. These methods have obtained signiﬁ-

 
 
 
 
 
 
cant gains in terms of problem solving time over modern
MIP solvers such as SCIP.

Despite signiﬁcant success, existing techniques on learn-
ing to branch are limited by the assumption that the entire
training data is available in single session of training.

This assumption is not realistic in the context of MIPs as
the semantics of CO problems may keep changing with time.
Consequently, the data to train the learning-to-branch model
is dynamic with updates arriving sequentially over time. The
above scenario is commonly observed in industries such as
shipping and food delivery where entities, such as service lo-
cations and warehouses, get added/removed over time. Fur-
ther, the semantics of the problem such as the demand, sup-
ply, customer distribution, facility constraints etc. also ﬂuc-
tuate. Hence, to tackle such scenarios, the model should be
capable of learning in an incremental fashion as more data
appears over time as retraining the entire model again can be
computationally expensive.

The ability to continually learn over time is referred to as
lifelong/continual learning (Parisi et al. 2019). This aligns
with the ability of humans to continually acquire skills
throughout their lifespan. Lifelong learning aspires to gain
more knowledge sequentially and improve existing model as
more data arrives. However, the quintessential failure model
of lifelong learning on neural models is catastrophic forget-
ting i.e when new concepts are learned sequentially, the neu-
ral model forgets the concepts it learned previously (Kirk-
patrick et al. 2017; Parisi et al. 2019)1.

In this context, we analyze the performance of the
state-of-the-art learning-to-branch technique GCNN (Gasse
et al. 2019) in the lifelong learning scenario, i.e., training
the model sequentially on different problems. In Fig. 1 we
observe that the solving time on instances of the SetCover
(SC) problem with edge-probability 0.05,
i.e., SC0.05
increases signiﬁcantly when the parameters of the model
are updated sequentially using training data of SC0.075,
2. Similar phenomenon is observed on
SC0.125 and SC0.2
other problems in the sequence such as SC0.075, etc. It can
be clearly concluded from Fig. 1 that GCNN (Gasse et al.
2019) suffers from catastrophic forgetting in the lifelong
learning scenario.

In the context of MIPs, a lifelong learning paradigm, due
to its nature, promotes efﬁcient learning since retraining
from scratch is costly (Parisi et al. 2019), especially on in-
dustrial level MIPs where the number of variables and con-
straints are in orders of millions (Nair et al. 2020). Further,
such a paradigm of continually gaining competencies on dif-
ferent problems, offers opportunity to transfer the gained
knowledge to unseen as well as previously seen problems.
Owing to knowledge sharing across problems, these models
cope better with low availability of training data. Learning
from low-volume training data is important in the context
of MIPs since generating training data (state-action pairs)
itself is a computationally expensive process (Nair et al.
2020). Finally, using a single model that is updated regularly
with various competencies, instead of maintaining multiple

1Detailed related work present in Appendix A.1
2Details of the dataset in Experimental Section

problem-speciﬁc models is desired as it is memory efﬁcient
with lower maintenance overhead.

Motivated by the above listed beneﬁts of lifelong learning,
in this work we focus on the novel paradigm of Lifelong
Learning to Branch in Mixed Integer Programs. Our core
contributions are as follows.
• Problem Formulation: We present the paradigm of Life-
long Learning to Branch in Mixed Integer Programs. To
the best of our knowledge, we are the ﬁrst to investigate
this paradigm.

• Investigation of catastrophic forgetting: We conduct an
empirical investigation of the SoA method (Gasse et al.
2019) and demonstrate that it suffers from catastrophic
forgetting when it learns to branch on different problems
in succession.

• Novel Algorithm: We propose LIMIP, a Lifelong Learn-
ing method to solve Mixed Integer Programs. LIMIP
encodes the state-space of a problem through an edge-
weighted, bipartite Graph Attention Network. To mitigate
catastrophic forgetting, LIMIP utilizes a novel combina-
tion of Knowledge Distillation and Elastic Weight Consol-
idation to shield the key parameters of previously learned
problems from signiﬁcant drift.

• Experimental Evaluation: We conduct empirical evalu-
ation on a series of NP-hard problems with drifting data
distribution and evolving constraints. We establish that
LIMIP is effective in learning to solve MIPs in a lifelong
fashion and overcomes the problem of catastrophic forget-
ting. Further, it is also capable of transferring the gained
knowledge effectively to NP-hard problems with very lim-
ited amount of training data.

2 Preliminaries
Deﬁnition 1 (Mixed Integer Program). A mixed-integer lin-
ear program is an optimization problem of the form:

minimize c(cid:62)x
subject to Ax ≤ b
l ≤ x ≤ u
x ∈ Zp × Rn−p,
where n is the total number of variables, p is the number
of integral variables. x ∈ Zp × Rn−p, A ∈ Rm×n is the
constraint coefﬁcient matrix, b ∈ Rm, right hand side con-
straint coefﬁcient vector, c ∈ Rn is the objective coefﬁcient
vector. Further, the variables l, u ∈ Rn represent the lower
and upper variable bound vectors.

MIPs are solved widely using Branch-and-Bound (B&B)
technique, which relaxes the integrality constraints and ob-
tains a continuous linear program (LP). The LP is solved
efﬁciently using the simplex algorithm (Achterberg 2007).
In case the relaxed solution is also integral and respects all
the constraints, then it is also a solution to the problem (not
necessarily optimal). Otherwise B&B decomposes the LP
relaxation into two sub-problems, by splitting the feasible
region based upon a variable that does not respect integral-
ity constraints in the current LP solution x∗. Speciﬁcally,

xi ≤ (cid:98)x(cid:63)

i (cid:99) ∨ xi ≥ (cid:100)x(cid:63)

i (cid:101) ,

∃i ≤ p | x(cid:63)

i /∈ Z,

The B&B solving process repeatedly performs decompo-
sition generating a search tree. The process stops if both
the upper and lower bounds are equal or when the feasible
regions do not decompose anymore, which is a certiﬁcate
of infeasibility or optimality. This B&B procedure involves
an extremely important step of selecting the fractional deci-
sion variable to branch upon from the set of candidate vari-
ables C. The chosen variable is used to partition the search
space and has a signiﬁcant impact on the size of the resulting
search tree (Achterberg 2007).

Among several heuristics available to choose the branch-
ing variable, strong branching is widely known to produce
the smallest B&B trees. It calculates the expected bound
improvement for each candidate variable before performing
branching. Although it produces the smallest B& B trees,
strong branching requires computing the solution of two LPs
for each candidate variable. The cost of ﬁnding the best vari-
able is prohibitively high and hence strong branching is not
used in practice.

In the B&B setup, the MILP solver is considered to be the
environment, and the brancher the agent (Khalil et al. 2016;
Gasse et al. 2019). At the tth decision step, the solver is in
state st, which comprises the B&B tree with all past branch-
ing decisions (Gasse et al. 2019), the best integer solution
found so far, the LP solution of each node, the currently fo-
cused leaf node, as well as any other solver statistics (for ex-
ample, the number of times every primal heuristic has been
called). In the context of strong branching, at a given state st,
let at be the variable chosen by strong branching among the
set of all candidate variables C. Based upon the above dis-
cussion, we now deﬁne the problem of Learning to Branch.
Problem 1 (Learning to Branch). For a B&B tree, at the tth
decision step of the solver, let the solver be in state st and a
decision to choose a variable to branch is to be made from a
set of candidate variables. Given a collection of state-action
(st, at) pairs obtained from running strong branching, the
goal is to learn a scoring function f parameterized by θ that
imitates branching decisions made by the strong branching
expert.
Since in our setup we aim to learn on multiple problems,
therefore in this context, we refer to each problem as a task.
Problem 2 (Lifelong Learning to Branch). Given a se-
quence of tasks T = [T1, · · · , TT ] of length T , we aim to
update the parameters of the model sequentially over time
such that at the ith task, when parameter θi−1 is updated to
θi by training using the instances of the task Ti, the model
avoids catastrophic forgetting on tasks Tj for j<i. Specif-
ically, the increase in running time on problems Tj ∀j<i
using the updated model θi should be reasonably low. Addi-
tionally, the performance on newly learned tasks should also
not be hindered signiﬁcantly.

3 LIMIP: Our proposed metholodogy
In this section we describe our proposed method LIMIP.
Fig. 2 presents the overview of LIMIP. We ﬁrst convert a
given MIP instance to a bipartite graph. Next, we describe
a method to encode the variables and constraints of MIP
using an edge-weighted, bipartite graph attention network

(GAT). Finally, we describe the procedure of learning the
parameters of the model in a lifelong fashion by avoiding
catastrophic forgetting. With the outline being set, we next
discuss each of these components in detail.

3.1 MIP Representation: State Encoding
Inspired from Gasse et al. (2019), to encode the state st of
the B&B tree at timestep t, we use a bipartite graph repre-
sentation G = (V, E, C) . One side of the graph containing
n nodes represent the n variables and the other side consist-
ing of m nodes represent the m constraints. There exists an
edge between jth variable node and ith constraint node if
jth variable appears in the ith constraint. The weight of an
edge ei,j corresponds to the value of the coefﬁcient of the
variable vj in the constraint ci. We use V ∈ Rn×d1 to repre-
sent variable features, E ∈ Rn×m×1 for edge features, and
C ∈ Rm×d2 to represent the constraint features. For each
of the node in the graph we use the raw solver speciﬁc input
features of Gasse et al. (2019), which can be found in the
appendix A.4. Fig. 2 shows an example of encoding an MIP
to a bipartite graph.

3.2 Policy Parameterization: Edge Weighted

Bipartite GAT

Observing the weighted and bipartite nature of the graph,
it is natural to parameterize the branching variable policy
fθ(a|st) using an edge-weighted bipartite GAT. Speciﬁcally,
for each node in the graph, the attention layer learns to weigh
each of the node’s neighbors differently based upon its im-
portance (Vaswani et al. 2017). Since, our graph is bipartite,
we perform two levels of message passing through the GAT.
Speciﬁcally, ﬁrst we pass message from the variable side to
the constraint side to obtain rich representation of the con-
straint nodes as follows:

ci = αi,iθCci +

αi,jθCvj

(1)

(cid:88)

j∈N (i)

Here, ci and vj refer to the embeddings of ith constraint
and jth variable respectively. N (i) refers to the neighbors
of ith node. θC refers to MLP associated to constrained side
aggregation. α represents the attention coefﬁcient(deﬁned
later). Next, we perform message passing from constraint
side to variable side. This allows us to generate richer repre-
sentations for each of the variables nodes.
vj = αj,jθV vj +

αj,iθV ci

(cid:88)

(2)

θV refers to weights associated to the variable side aggre-

gation. The attention coefﬁcient α is computed as below:

i∈N (j)

αi,j =

(cid:16)

(cid:16)

ρ

exp

(cid:80)

k∈N(i)

exp

(aC)
(cid:16)
(cid:16)

ρ

T (cid:2)θCci(cid:107)θCvj(cid:107)θC
e ei,j
(aC)T [θCci(cid:107)θCvk(cid:107)θC

(cid:17)(cid:17)

e ei,k]

(cid:3)(cid:17)(cid:17)

The above attention mechanism is parameterized by the
weight vector aC. θC
e on the constraint side aggregation
refers to an MLP associated with the edge features. ρ refers
to the activation function3. αj,i is deﬁned analogously to αi,j

3We use LeakyReLU with negative slope = 0.2

Figure 2: Bipartite graph representation of an MIP with n = 3 variables and m = 2 constraints. The bipartite graph is encoded
via 2 half-aggregations of Bipartite GAT .

where C is swapped with V and the ith and jth nodes are
interchanged.

After the two half-aggregations of eq. 1 and 2, we obtain
the ﬁnal representation of the candidate variable nodes. The
ﬁnal representation of each candidate variable node is passed
through a softmax layer to obtain a probability distribution
over the variables represented by fθ (a | st). Further, to sta-
bilize the training procedure of the bipartite-GAT, we use
attention mechanism with multiple heads, details of which
are present in Appendix Sec. A.5. The detailed architecture
is present in Fig. 2.

Imitation Loss

3.3
Since strong branching is a powerful heuristic in reducing
the size of the tree, we train the parameters θ by imitation
learning of the strong branching rule.

k)}N

We ﬁrst collect a set of strong branching state-action pairs
D = {(sk, a(cid:63)
k=1, where N is the number of branching
samples collected. Then through imitation learning, we op-
timize the parameters θ using the following imitation loss
function:

L(θ) = −

1
N

(cid:88)

log fθ (a∗ | s)

(3)

(s,a∗)∈D

The optimization of the above objective encourages the
neural model to predict the variable for branching which
strong-branching would have chosen.

3.4 Life-Long Learning to Branch
Until now we discussed how to learn the parameters θ of the
model for a given task. In this section we discuss how to
learn to branch on MIPs in a lifelong fashion. As discussed
earlier in Def. 2, we have a set of T problems appearing in
sequence T = [T1, · · · , TT ], and our goal is to learn the pa-
rameters sequentially over time where the training data Di
for each task Ti also appears sequentially. A na¨ıve solution
is to update the parameters of the model sequentially as new
tasks arrive. However, as we already observed in Fig. 1, if
the neural model is updated in this fashion, it suffers from
catastrophic forgetting on the earlier learned tasks. Hence,
our goal is to update the parameters of the model on new

tasks while preserving the knowledge gained on previous
tasks to avoid catastrophic forgetting.

One way to consolidate past knowledge is to replay the
training data of the past tasks. However, as the number of
tasks increase, it becomes computationally expensive. Fur-
ther, another option of storing only a small set of labeled
samples and replaying them is prone to over-ﬁtting (Wang
et al. 2020). Hence, inspired by recent works on continual
learning (Buzzega et al. 2020; Wang et al. 2020), to tackle
the problem of catastrophic forgetting in lifelong learning to
branch we take the following two perspectives. First idea is
to approximate the knowledge gained by the model in the
past via distillation of model’s past behavior when learning
new tasks. Second, we optimize the parameters of the model
in a constrained way in order to prevent signiﬁcant drift on
the parameters important for previously learned tasks. Fig. 3.
visually describes the process. Now, we discuss both the per-
spectives below in detail.

Mimicking model’s past behavior through Knowledge
Distillation:
In order to maintain past learned patterns
during lifelong learning, our goal is to search for model pa-
rameters that ﬁt well on the current task and also approxi-
mate the optimal behavior of the model on the older tasks.
Towards this we aim to encourage the model to mimic its
original(past) output logits for a small number of samples
of the past tasks. To accomplish this we apply Knowledge
distillation(KD) (Buzzega et al. 2020) approach to enforce
the neural network to generate similar logits that the model
produced for these samples in the past during optimizing of
the task to which the related sample belonged to. Mathemat-
ically,

(4)

LKL = E(s,z)∼M [DKL (z(cid:107)fθ(s))]
Here z = fθj ∗(s) refers to the logits z of sample s and
θ∗
j refers to the set of optimal parameters of task Tj. These
(s, z) pairs are stored in a ﬁxed-size buffer M . Speciﬁcally,
for s ∈ M , fθ∗
(s) is preserved where s is a training sample
from task Tj. When the lifelong learning model is at step i
of the sequence T , M consists of samples of past experi-
ences(logits) for tasks seen till step i − 1. Further, since we

j

Figure 3: Architecture diagram representing the update mechanism of LIMIP at the ith step of sequence T .

do not have any prior information of how many tasks we
will observe, we use reservoir sampling to preserve samples
for Knowledge-Distillation. Reservoir sampling ensures that
samples from all tasks are stored with equal probability in
the buffer without knowing the number of tasks/samples in
the stream in advance(Buzzega et al. 2020).

Preservation of model’s important parameters: As we
store only a small set of logits in our memory buffer instead
of the entire training data of past tasks, it is prone to over-
ﬁtting. Although, over-ﬁtting can be tackled to an extent by
L2 regularizers, the restriction imposed by L2 regularizers
by constraining the entire network through a ﬁxed coefﬁ-
cient is too severe and might prevent learning of the new
tasks itself. Inspired from recent works (Kirkpatrick et al.
2017; Wang et al. 2020), to counter this problem, we aim
to learn to adjust the magnitude of the parameter updates
on certain model weights based on how important they are
to the previously learned tasks. To accomplish this we ap-
ply Elastic Weight Consolidation (EWC) (Wang et al. 2020;
Kirkpatrick et al. 2017). Speciﬁcally, after the training on
a task Tj is complete, we compute the importance of each
parameter w on the task Tj as follows:

Ωw

j = E(s,a∗)∼Dj

(cid:20)(cid:16) δL(s,a∗)
δθw
j

(cid:17)2(cid:21)

δθw
j

L(s, a∗) refers to the loss on sample s with ground-truth
a∗. The term δL(s,a∗)
calculates the gradient of the loss with
respect to the parameter w learned on task Tj. Ωw
j captures
the importance of weight w to task Tj. We note that Dj is
no more required during future tasks once the computation
of Ω for task Tj is complete.

Now, when a new task Ti arrives, we apply the above
regularization (penalize) to prevent large amount of drift
on parameters important for earlier learned tasks. Here, the
weights of the regularization are obtained from Ω. We ac-

complish the regularization by the below loss function.

Limportance =

i−1
(cid:88)

(cid:88)

j=1

w

Ωw
j

(cid:0)θw

i − θw
j∗

(cid:1)2

(5)

The above term is a quadratic penalty term on the differ-
ence between the parameters for the new and the old tasks.
Ω consists of diagonal weighing proportional to the diago-
nal of the Fisher information metric over the old parameters
on the old tasks (Liu, Yang, and Wang 2021). θj∗ refers to
optimal parameters of task Tj When updating parameters of
the model to learn to branch on a new task Ti, the above pe-
nalization will encourage the important model parameters to
be close to the parameters obtained for earlier learned tasks
T1, T2 · · · Ti−1. Fig. 2 b) summarizes this concept visually
through overlapping optimal parameter spaces.

Lifelong learning optimization objective: Finally, com-
bining the loss functions of eqs. 3, 4 and 5, we obtain the
optimization objective at the ith step as follows

Llif elong =

(cid:88)

log fθ (a∗ | s)

(s,a∗)∈Di
+ αE(s,z)∼M[DKL (z(cid:107)fθ(s)]

+ β

i−1
(cid:88)

(cid:88)

j=1

w

Ωw
j

(cid:0)θw

i − θw
j∗

(cid:1)2

The above equation while learning new tasks, consoli-
dates past information in order to maintain stability of pa-
rameters important for previously learned tasks. α controls
the weight corresponding to mimicking past logits and β
controls scale of the weight consolidation regularizer.

4 Experiments
In this section we measure the effectiveness of our proposed
approach LIMIP and establish:

• Minimal forgetting: LIMIP is capable of lifelong learn-
ing on NP-hard problems with drifting data distributions
and avoids catastrophic forgetting on previously learned
problems.

• No hindrance in learning future tasks: Despite adding
constraints to prevent signiﬁcant updates to the model,
LIMIP does not hinder learning on new tasks.

• Transfer to Low data regime: We compare the perfor-
mance of LIMIP to transfer on a low-training data regime
task which is similar to a task LIMIP learned in the past.
LIMIP effectively transfers its previously gained and un-
forgotten knowledge to the unseen task.

• Efﬁcient learning through Bipartite GAT: Attributed to
rich representations learned through the attention mech-
anism, LIMIP reduces solving time on instances when
compared to GCNN (Gasse et al. 2019).

4.1 Datasets
We use the following datasets to evaluate the performance
of our method against different baselines.

Set Cover: We consider the Set Cover problem of Balas
and Ho (1980). Let p be the probability of an item belonging
to a set in the Set Cover(SC) problem. SCp refers to Set
Cover problem with set-item probability p. To simulate
lifelong learning setup, we generate multiple Set Cover
problems datasets each with a different probability, i.e.,
T = [SC0.05, SC0.075, SC0.1, SC0.125, SC0.15, SC0.2]. In
all instances we set number of rows to 700 and number of
columns to 800.

Independent Set : We consider the Maximum Indepen-
dent Set (MIS) problem on the Barab´asi-Alberta graph (Al-
bert and Barab´asi 2002) generated with different sizes
and afﬁnities. ISA,S denotes as instance where A is the
afﬁnity and S is the size of the graph. To simulate life-
long learning setup, we generate independent set prob-
lem datasets with different sizes and afﬁnities as T =
[IS4,750, IS4,500, IS4,450, IS5,450, IS5,400, IS5,350].

Facility Location with constraints: We consider the Fa-
cility Location problem (Gasse et al. 2019) and to sim-
ulate lifelong learning scenario, we use facility capaci-
ties and customer demands sampled from drifting distri-
butions over time. This is a realistic scenario where cus-
tomer demands and facility capacities keep changing over
time. We deﬁne a certain task of facility location prob-
lem as F C(Clow,Chigh),(Dlow,Dhigh). Clow, Chigh refers
to the lower and upper limit of the facility capacity. Dlow,
Dhigh refers to the lower and upper limit of customer
demand. Generating a facility location problem requires,
for each facility, sampling a capacity uniformly at random
from [Clow, Chigh] and for each customer a demand sam-
pled from [Dlow, Dhigh]. In addition to evolving customer
demand and facility supply distribution, we also simulate
the setting of adding new constraints. We add the con-
straint of the maximum number of customers that can be
served by a facility and denote it by M S. We consider
the following sequence of facility location problem datasets
T = [F C(40,50),(5,10), F C(50,55),(30,35), F C(80,90),(60,65),
F C(100,110),(80,90), F C(100,110),(80,90),M S=95]. In all cases,
we set the number of customers and facilities to 100. The

detailed procedure to generate these instances is described
in Appendix A.6.

These datasets are challenging for state-of-the-art solvers,
and also representative of the types of integer programming
problems encountered in practice.

4.2 Experimental Setup and Parameters
We use SCIP (Gamrath et al. 2020) as the backend solver,
with a time limit of 45 minutes. We use a system running
on Intel Xeon 6248 processor with 96 cores and 1 NVIDIA
A100 GPU with 40GB memory for our experiments. Simi-
lar to existing works (Gasse et al. 2019), we enable cutting
planes at the root node and deactivate solver restarts. We
keep all other SCIP parameters to default. We use attention
mechanism with 2 heads. We set the default buffer size to
500. We set α and β in eq. 6 to 1.5 and 100 respectively.
For details of all parameters and system settings, we refer to
App. A.7.
Training data generation: For each task, we generate
150,000 branching samples extracted using 10,000 gener-
ated instances for training and 30000 validation/test samples
generated using 2000 instances.

Metrics: We perform evaluation on 20 different test in-
stances using 5 different SCIP seeds. We report the standard
benchmark metric for MILP benchmarking, i.e., the geomet-
ric mean of the running time of the solver. Additionally,
we report the hardware independent node count (in Ap-
pendix A.9). We compute the average per-instance standard
deviation so a value X ± s% means it took X secs to solve
an instance and while solving one of those instances the time
varied by s on an average.

Baselines: We compare our work LIMIP with the state-
of-the-art method for learning to branch GCNN (Gasse
et al. 2019). We skip comparison with Zarpellon et al.
(2020) since it approximates the weaker reliability pseu-
docost branching heuristic, which has been shown to have
an inferior performance in terms of running time (See Ap-
pendix A.11). Further, we skip comparison with Gupta et al.
(2020) since its focus is on developing CPU based version
of learning to branch, which is out of scope of our work. For
the sake of completion, we compare with the default SCIP
Solver and strong branching in App. A.10.

In the context of lifelong learning, we compare with
(1) Fine-tuning (FT) i.e directly updating the model on
new tasks as they arrive, (2) Experience Replay (ER) and
(3) Elastic Weight Consolidation (EWC) (Kirkpatrick et al.
2017). Details of baseline are present in App. A.8.

4.3 Evaluation in Lifelong Learning Scenario
Evaluating forgetting: In Fig. 4 and Fig. 5, in each sub-
plot we study the performance of different methods on test
instances of each dataset in the lifelong sequence T . Speciﬁ-
cally, each subplot in these ﬁgures refer to a test task and the
x-axis shows the sequence of training tasks in the lifelong
setup. We observe that as training progresses on different
problems in the lifelong setup, the performance of GCNN
(FT) (Gasse et al. 2019) on old problem deteriorates signiﬁ-
cantly. The older the task, the worse is the deterioration. For

Model

GCNN SC0.047
Bipartite GAT SC0.047
Bipartite GAT(FT) + SC0.047
LIMIP
LIMIP + (SC0.047)

Time

16.01
17.06
16.07
15.05
14.05

# Nodes

607
702
702
602
441

Table 1: Transferability performance: Test perfor-
mance comparison of ﬁne-tuned model against model
trained from scratch on the SC0.047 dataset. LIMIP
and Bipartite GAT (FT) were trained sequentially on
[SC0.05, SC0.075, SC0.1, SC0.125, SC0.15, SC0.2] and then
ﬁne-tuned on SC0.047

havior and the weight consolidation penalty term which pre-
vents signiﬁcant drift on important parameters.

Low hindrance on future tasks: While avoiding catas-
trophic forgetting is one of the aims of lifelong learning, it
should not be at the cost of learning new tasks. From Fig. 4
and Fig. 5, we observe that, while LIMIP does not forget the
knowledge it gained in the past, still it does it without im-
pacting future tasks. We can clearly see that on future tasks
too LIMIP obtains superior performance compared to exist-
ing baselines.
For the sake of completeness, in App. A.12 we also com-
pare with GAT (FT), GAT (EWC) and GAT (ER). Due to
space limitation, the results on Independent Set Problem are
present in App. A.10. Comparison with respect to the hard-
ware independent node count is present in A.10.

4.4 Transferability on low data regimes
As a model learns on more tasks and gains several com-
petencies, it can be utilized as a weight initializer to learn
on an unseen task with low availability of training data, es-
pecially in the case of strong branching where obtaining
training data is costly. To test the performance of LIMIP
on transfer learning, we create a new dataset SC0.047 with
only 300 branching samples for training. This number is ex-
tremely low compared to other datasets where number of
samples = 150000. We perform lifelong learning on T =
[SC0.05, SC0.075, SC0.1, SC0.125, SC0.15, SC0.2] and then
ﬁne-tune on SC0.047. We compare it with training a model
from scratch on the 300 branching samples of SC0.047. In
Table 1, we study the performance gain obtained using a
ﬁne-tuned lifelong learned model vs. a model learned from
scratch (GCNN SC0.047). We observe that on an aver-
age the running time of the LIMIP method ﬁne-tuned on
SC0.047 model is signiﬁcantly better than the model trained
from scratch.

4.5 Ablation studies
GCN vs Bipartite GAT:
In this section we study the im-
pact of using our Bipartite GAT compared to mean pool
based GCNN. In Table 2 we observe that Bipartite GAT
improves over GCNN by a small margin in terms of both
running time and number of tree nodes.

Impact of regularizer on lifelong learning:
In Appendix
A.12, we study the impact of weight regularization on the

Figure 4: Testing on Set Cover in lifelong scenario: Evo-
lution of solving time for each task when different methods
are updated on each task sequentially. Different evaluation
tasks are shown in different subplots. The x-axis denotes the
sequence of training tasks and the y-axis denotes the geo-
metric mean of solving time for test instances of each task
in the sequence. The shaded area refers to standard devia-
tion.

example, since SC0.05 (top, left in Fig. 4) is trained ﬁrst, it
witnesses maximum increase in time across algorithms ex-
cept the proposed LIMIP. This clearly shows that GCNN
suffers from catastrophic forgetting when its parameters are
updated on new tasks. In sharp contrast, LIMIP is able to
maintain the learned patterns of past tasks when learning
new tasks. This is attributed to the knowledge distillation
loss, which helps in promoting the model to mimic past be-

Figure 5: Testing on Facility location in lifelong scenario:
Evolution of solving time for each task when different meth-
ods are updated on each task sequentially.

Dataset

Method

Time

Nodes

SC0.2

IS4, 750

Bipartite GAT
GCNN

7.9 ± 2.56
8.21 ± 2.45

87.2 ± 15.31
91.2 ± 13.61

Bipartite GAT 22.25 ± 1.24
25.73 ± 1.32
GCNN

555.6 ± 6.02
672.2 ± 6.2

F C(40,50),(5,10)

Bipartite GAT 33.94 ± 1.11
35.14 ± 1.30
GCNN

246.10 ± 4.02
248.20 ± 4.70

Table 2: Performance comparison between Bipartite GAT
and GCNN encoding.

overall performance of the model.

Performance against buffer size:
In Appendix A.12 we
study the performance of LIMIP and ER against the size of
the buffer.

5 Conclusion
Learning-to-Branch techniques have shown signiﬁcant suc-
cess in reducing the solving time of Mixed Integer Programs.
Although, signiﬁcant progress has been made, the paradigm
of learning to branch in a lifelong fashion was unexplored.
In this work we ﬁrst examined the behavior of existing tech-
niques in the lifelong learning scenario and discovered that
they suffer from catastrophic forgetting. To tackle this prob-
lem, in this work we study the hitherto unexplored paradigm
of Lifelong Learning to Branch on Mixed Integer Programs.
We propose a method LIMIP powered by a Bipartite GAT to
encode MIP instances. Further, to mitigate catastrophic for-
getting, we apply knowledge distillation and elastic weight
consolidation to shield key parameters from drifting and
thereby retaining efﬁcacy. Through extensive experiments
on multiple NP-hard problems, we established that LIMIP
is able to mitigate forgetting signiﬁcantly better compared
to existing baselines when confronted with lifelong learn-
ing. Additionally, the proposed method does not hinder the
performance on future learning tasks too.

References

Achterberg, T. 2007. Constraint integer programming.
Albert, R.; and Barab´asi, A.-L. 2002. Statistical mechanics
of complex networks. Reviews of modern physics, 74(1): 47.
Aljundi, R.; Babiloni, F.; Elhoseiny, M.; Rohrbach, M.; and
Tuytelaars, T. 2018. Memory aware synapses: Learning
what (not) to forget. In Proceedings of the European Con-
ference on Computer Vision (ECCV), 139–154.
Alvarez, A. M.; Louveaux, Q.; and Wehenkel, L. 2014. A
supervised machine learning approach to variable branching
in branch-and-bound. In In ecml. Citeseer.
Alvarez, A. M.; Louveaux, Q.; and Wehenkel, L. 2017. A
machine learning-based approximation of strong branching.
INFORMS Journal on Computing, 29(1): 185–195.
Balas, E.; and Ho, A. 1980. Set covering algorithms using
cutting planes, heuristics, and subgradient optimization: a
In Combinatorial Optimization, 37–
computational study.
60. Springer.

Banitalebi-Dehkordi, A.; and Zhang, Y. 2021. ML4CO: Is
GCNN All You Need? Graph Convolutional Neural Net-
works Produce Strong Baselines For Combinatorial Opti-
mization Problems, If Tuned and Trained Properly, on Ap-
propriate Data. arXiv preprint arXiv:2112.12251.

Buzzega, P.; Boschini, M.; Porrello, A.; Abati, D.; and
Calderara, S. 2020. Dark experience for general continual
learning: a strong, simple baseline. Advances in neural in-
formation processing systems, 33: 15920–15930.

Chaudhry, A.; Ranzato, M.; Rohrbach, M.; and Elhoseiny,
M. 2018. Efﬁcient lifelong learning with a-gem. arXiv
preprint arXiv:1812.00420.

Draelos, T. J.; Miner, N. E.; Lamb, C. C.; Cox, J. A.; Vine-
yard, C. M.; Carlson, K. D.; Severa, W. M.; James, C. D.;
and Aimone, J. B. 2017. Neurogenesis deep learning: Ex-
tending deep networks to accommodate new classes.
In
2017 International Joint Conference on Neural Networks
(IJCNN), 526–533. IEEE.

Febrinanto, F. G.; Xia, F.; Moore, K.; Thapa, C.; and Aggar-
wal, C. 2022. Graph Lifelong Learning: A Survey. arXiv
preprint arXiv:2202.10688.

Gamrath, G.; Anderson, D.; Bestuzheva, K.; Chen, W.-K.;
Eiﬂer, L.; Gasse, M.; Gemander, P.; Gleixner, A.; Gottwald,
L.; Halbig, K.; et al. 2020. The SCIP optimization suite 7.0.

Gasse, M.; Ch´etelat, D.; Ferroni, N.; Charlin, L.; and Lodi,
A. 2019. Exact combinatorial optimization with graph con-
volutional neural networks. Advances in Neural Information
Processing Systems, 32.

Gupta, P.; Gasse, M.; Khalil, E.; Mudigonda, P.; Lodi, A.;
and Bengio, Y. 2020. Hybrid models for learning to branch.
Advances in neural information processing systems, 33:
18087–18097.

Huang, L.; Chen, X.; Huo, W.; Wang, J.; Zhang, F.; Bai, B.;
and Shi, L. 2021. Branch and bound in mixed integer linear
programming problems: A survey of techniques and trends.
arXiv preprint arXiv:2111.06257.

Khalil, E.; Le Bodic, P.; Song, L.; Nemhauser, G.; and Dilk-
ina, B. 2016. Learning to branch in mixed integer program-
ming. In AAAI, volume 30.

Kirkpatrick, J.; Pascanu, R.; Rabinowitz, N.; Veness, J.; Des-
jardins, G.; Rusu, A. A.; Milan, K.; Quan, J.; Ramalho, T.;
Grabska-Barwinska, A.; et al. 2017. Overcoming catas-
trophic forgetting in neural networks. Proceedings of the
national academy of sciences, 114(13): 3521–3526.

Liu, H.; Yang, Y.; and Wang, X. 2021. Overcoming catas-
In Proceed-
trophic forgetting in graph neural networks.
ings of the AAAI Conference on Artiﬁcial Intelligence, vol-
ume 35, 8653–8661.

Lopez-Paz, D.; and Ranzato, M. 2017. Gradient episodic
memory for continual learning. Advances in neural infor-
mation processing systems, 30.

Marcos Alvarez, A.; Wehenkel, L.; and Louveaux, Q. 2016.
Online learning for strong branching approximation in
branch-and-bound.

Integer programming: theory, applica-

Nair, V.; Bartunov, S.; Gimeno, F.; von Glehn, I.; Li-
chocki, P.; Lobov, I.; O’Donoghue, B.; Sonnerat, N.; Tjan-
Solving mixed
draatmadja, C.; Wang, P.; et al. 2020.
arXiv preprint
integer programs using neural networks.
arXiv:2012.13349.
Parisi, G. I.; Kemker, R.; Part, J. L.; Kanan, C.; and Wermter,
S. 2019. Continual lifelong learning with neural networks:
A review. Neural Networks, 113: 54–71.
Rebufﬁ, S.-A.; Kolesnikov, A.; Sperl, G.; and Lampert, C. H.
2017. icarl: Incremental classiﬁer and representation learn-
In Proceedings of the IEEE conference on Computer
ing.
Vision and Pattern Recognition, 2001–2010.
Riemer, M.; Cases, I.; Ajemian, R.; Liu, M.; Rish, I.; Tu, Y.;
and Tesauro, G. 2018. Learning to learn without forgetting
by maximizing transfer and minimizing interference. arXiv
preprint arXiv:1810.11910.
Taha, H. A. 2014.
tions, and computations.
Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones,
L.; Gomez, A. N.; Kaiser, Ł.; and Polosukhin, I. 2017. At-
tention is all you need. Advances in neural information pro-
cessing systems, 30.
Wang, J.; Song, G.; Wu, Y.; and Wang, L. 2020. Streaming
graph neural networks via continual learning. In Proceed-
ings of the 29th ACM International Conference on Informa-
tion & Knowledge Management, 1515–1524.
Yoon, J.; Yang, E.; Lee, J.; and Hwang, S. J. 2017. Life-
long learning with dynamically expandable networks. arXiv
preprint arXiv:1708.01547.
Zarpellon, G.; Jo, J.; Lodi, A.; and Bengio, Y. 2020. Param-
eterizing branch-and-bound search trees to learn branching
policies. arXiv preprint arXiv:2002.05120.
Zenke, F.; Poole, B.; and Ganguli, S. 2017. Continual learn-
ing through synaptic intelligence. In International Confer-
ence on Machine Learning, 3987–3995. PMLR.
Zhou, F.; and Cao, C. 2021. Overcoming catastrophic forget-
ting in graph neural networks with experience replay. In Pro-
ceedings of the AAAI Conference on Artiﬁcial Intelligence,
volume 35, 4714–4722.

A Appendix

A.1 Related Work

A.2 Learning to solve MIPs

Strong Branching is widely accepted as the most efﬁcient
branching expert in terms of number of nodes. However, its
main advantage is the high computational cost of ﬁnding the
variable to branch. To tackle this problem, Learning-based
techniques(Alvarez, Louveaux, and Wehenkel 2014, 2017;
Marcos Alvarez, Wehenkel, and Louveaux 2016; Khalil
et al. 2016; Gasse et al. 2019; Nair et al. 2020; Gupta
et al. 2020) have focused on learning fast approximations
of Strong Branching rule by learning from a set of training
instances for a class of MIPs. Most of these techniques either
learn to rank candidate branching variables or learn to imi-
tate expert strong branching rule. Among various learning
based methods, GCNN(Gasse et al. 2019) has shown sig-
niﬁcant scalability gains and is considered the state-of-the
art method for learning to branching(Banitalebi-Dehkordi
and Zhang 2021). It has shown to to improve upon previ-
ously proposed approaches for branching on several MILP
problem benchmarks, and further, also obtains faster run-
ning time compared to the default SCIP solver. Recently,
(Zarpellon et al. 2020) proposed TreeGate model to learn ap-
proximation of reliability pseudo-cost branching. However,
in our study we observed, the technique does not scale well
in comparison to GCNN(Gasse et al. 2019) and default SCIP
solver in terms of the running time metric. Recently, there
have been attempts to use reinforcement learning to obtain
better heuristics4, however, in terms of running time they are
still inferior to imitation learning of strong branching.

A.3 Continual Learning

Although deep neural networks have obtained signiﬁcant
success on sever learning tasks, however most of them suffer
from catastrophic forgetting in the continual learning sce-
nario. The goal of continual learning is to learn to adapt
to new data in a streaming scenario while consolidating
the knowledge learned from previous data to prevent catas-
trophic forgetting. Many recent endeavours have been made
towards alleviating catastrophic forgetting. The ﬁrst one’s
being replay-based(Rebufﬁ et al. 2017; Riemer et al. 2018;
Lopez-Paz and Ranzato 2017; Chaudhry et al. 2018) where
a subset of old data samples are replayed from a memory
buffer while learning a new task. Second category is the
regularization based techniques(Zenke, Poole, and Ganguli
2017; Kirkpatrick et al. 2017; Aljundi et al. 2018) which
learn importance of weights of the neural model for each
task and prevent signiﬁcant changes on them. The third cat-
egory is dynamic network expansion. In this context, some
progress has been made to intelligently expand the neural
network(Yoon et al. 2017; Draelos et al. 2017) when the
current capacity of the model is not sufﬁcient to learn new
tasks without causing forgetting of earlier one’s. These ap-
proaches introduced here change architectural properties in

4Scavuzzo, L. Learning to branch with Tree MDPs. arXiv

preprint arXiv:2205.11107.

response to new information by dynamically accommodat-
ing novel neural resources with due course of time such as
increased number of neurons or network layers. Recently,
some amount of progress has been made on continual learn-
ing on GNNs(Wang et al. 2020; Liu, Yang, and Wang 2021;
Zhou and Cao 2021). We refer the reader to the follow sur-
veys on continual learning on neural networks(Parisi et al.
2019) and continual learning for GNNs(Febrinanto et al.
2022).

A.4 Solver Features

In Table 3 we present the input features used. These features
are based upon Gasse et al. (2019).

A.5 Multi-head attention

The multi-head attention equation is based upon Vaswani
et al. (2017). Speciﬁcally, for K heads





(cid:126)h(cid:48)
i = (cid:107)K

k=1ρ



(cid:88)

ijWk(cid:126)hj
αk



j∈N (i)

where hi can be replaced by ci or vi and W be replaced

with θC or θV respectively.

A.6 Data

Facility location: For facility location, as discussed the
main paper, a certain task of facility location problem is de-
ﬁned as F C(Clow,Chigh),(Dlow,Dhigh). Clow, Chigh refers
to the lower and upper limit( respectively) of the facil-
ity capacity. Dlow, Dhigh refers to the lower and upper
limit(respectively) of the customer demand . To generate
an instance of the facility location problem, we require,
for each facility, sampling a capacity uniformly at random
from [Clow, Chigh] and for each customer a demand sam-
pled uniformly at random from [Dlow, Dhigh]. Using these
values, an instance is constructed. In addition to evolving
customer demand and facility supply distribution, we also
simulate the setting of adding new constraints. We add the
constraint of the maximum number of customers that can
be served by a facility and denote it by M S. For example
M S = 95 in F C(100,110),(80,90),M S=95 denotes that maxi-
mum number of customers that can be served by a facility is
95. In all cases, we set the number of customers and facilities
for an instance to be 100.

A.7 Parameters

We set number of heads to 2 for multi-head attention with
MLP hidden size 32. We train until convergence of valida-
tion loss. We set learning rate to 0.001. We use Adam opti-
mizer for training.

A.8 Baselines

For EWC baseline(only using EWC), we set weight of the
elastic weight component to 1000. For GCNN we use em-
bedding size 64.

Tensor

Feature

Description

C

E

V

obj cos sim
bias
dualsol val
is tight
age

Coef
type
coef
has lb
has ub
sol is at lb
sol is at ub
sol frac
basis status
reduced cost
age
sol val
inc val
avg inc val

Cosine similarity with objective.
Bias value, normalized with constraint coefﬁcients.
Dual solution value, normalized.
Tightness indicator in LP solution
LP age, normalized with total number of LPs

Constraint coefﬁcient, normalized per constraint
Type (binary, integer, impl. integer, continuous) as a one-hot encoding
Objective coefﬁcient, normalized
Lower bound indicator.
Upper bound indicator.
Solution value equals lower bound.
Solution value equals upper bound
Solution value fractionality
Simplex basis status (lower, basic, upper, zero) as a one-hot encoding
Reduced cost, normalized
LP age, normalized
Solution value.
Value in incumbent
Average value in incumbents

Table 3: Description of the constraint, edge and variable features in our bipartite state representation st

A.9 Number of nodes

In addition to plots based upon solving time shown in the
main paper, in ﬁg. 6 and 7, we present the number of nodes
solved for different methods.

Figure 6: Number of Nodes: Testing on SetCover in life-
long scenario: Evolution of number of nodes for each task
when different methods are updated on each task sequen-
tially.

A.10 Additional Results

Results on Independent Set We present the results on In-
dependent set problem in ﬁg 8. We observe that in indepen-
dent set also, LIMIP achieves signiﬁcant lower forgetting in

Figure 7: Number of Nodes: Testing on Facility location
in lifelong scenario: Evolution of number of nodes for each
task when different methods are updated on each task se-
quentially.

comparison to other methods. Standard deviation on Inde-
pendent set is signiﬁcantly high, a phenomenon observed in
earlier works too (Gasse et al. 2019).

Results on default SCIP solver heuristics
: For the sake
of completeness we present results of SCIP solver in table
4. We skip results of fsb for F C(40,50),(5,10) due to its poor
running time performance.

A.11 Poor scalability of TreeGate (Zarpellon

et al. 2020)

We test the performance of TreeGate (Zarpellon et al. 2020)
in our setup where we have a set of training instances avail-

A.12 Ablation
LIMIP without Elastic weight consolidation In ﬁg. 9
we study the performance of LIMIP without the EWC loss.
We observe that there does exist improvement when EWC
loss is part of our loss function Llif elong.

Figure 8: Independent Set: Testing on Independent Set in
lifelong scenario: Evolution of solving time for each task
when different methods are updated on each task sequen-
tially.

Dataset

SC0.05

IS4,750

Method

relpscost
fsb

Time

Nodes

9.93 ± 1.1
63.50 ± 2.1

497.2 ± 16.1
91.5 ± 4.5

relpscost
fsb

66.2 ± 0.1

21010 ± 1.2
1531.50 ± 0.15 1195.5 ± 0.1

F C(40,50),(5,10)

relpscost

268.2 ± 0.88

7528 ± 0.62

Table 4: Results of SCIP Full Strong (fsb) and SCIP Relia-
bility pseudocost(relpscost) branching

able for a class of MIP. We generate relpscost branching
pairs from the SC0.05 dataset similar to procedure described
in (Zarpellon et al. 2020) i.e using different random seeds
and also performing random branching. We used same set of
training instances as used in LIMIP and GCNN to generate
branching pairs.

We compare the running time and number of nodes. In
Table 5 we observe that TreeGate is twice slower compared
to imitation learning of strong branching.

Model

TreeGate
LIMIP (Bipartite GAT)

Time

24.1
11.01

# Nodes

764
320

Table 5: Comparison against TreeGate(Zarpellon et al.
2020): Comparison of Imitation learning of Strong Branch-
ing against TreeGate which learns weaker heuristic of relia-
bility pseudo cost branching. Both models were trained and
tested on SC0.05.

Figure 9: LIMIP without EWC: Testing on SetCover in
lifelong scenario: Evolution of Solving time for each task
when different methods are updated on each task sequen-
tially.

Using small sized memory buffer: We use a buffer of
size 200 instead of 500 used earlier. We observe similar con-
clusion on a lower buffer size as can be seen in ﬁg. 10. For
simplicity, we show result on the ﬁrst and the last problem
in the facility location problem sequence.

Figure 10: Comparison of LIMIP and ER model on
buffer size 200: Testing on ﬁrst and last problem in the Fa-
cility location problem sequence.

Using Bipartite GAT encoding for baselines instead of
GCNN In ﬁg. 11 and 12 we study the performance of
different baselines when the base model used for them is
bipartite GAT. This shows that LIMIP outperforms exist-
ing baselines irrespective of the GNN encoding used. We

observe similar conclusion as observed on GCNN in main
paper.

Figure 11: Comparison using Bipartite GAT as encoding
model for baselines: Testing on Facility location in life-
long scenario: Evolution of solving time for each task when
different methods are updated on each task sequentially.

Figure 12: Comparison using encoding model as Bipar-
tite GAT for baselines : Testing on SetCover in lifelong
scenario: Evolution of solving time for each task when dif-
ferent methods are updated on each task sequentially.

