Abductive Knowledge Induction From Raw Data

Wang-Zhou Dai , Stephen H. Muggleton
Department of Computing, Imperial College London, London, UK

@imperial.ac.uk
w.dai, s.muggleton
}

{

1
2
0
2

y
a
M
0
2

]
I

A
.
s
c
[

2
v
4
1
5
3
0
.
0
1
0
2
:
v
i
X
r
a

Abstract

For many reasoning-heavy tasks involving raw in-
puts, it is challenging to design an appropriate end-
to-end learning pipeline. Neuro-Symbolic Learn-
ing, divide the process into sub-symbolic percep-
tion and symbolic reasoning, trying to utilise data-
driven machine learning and knowledge-driven rea-
soning simultaneously. However, they suffer from
the exponential computational complexity within
the interface between these two components, where
the sub-symbolic learning model lacks direct super-
vision, and the symbolic model lacks accurate input
facts. Hence, most of them assume the existence of
a strong symbolic knowledge base and only learn
the perception model while avoiding a crucial prob-
lem: where does the knowledge come from? In
this paper, we present Abductive Meta-Interpretive
Learning (M etaAbd) that unites abduction and in-
duction to learn neural networks and induce logic
theories jointly from raw data. Experimental results
demonstrate that M etaAbd not only outperforms
the compared systems in predictive accuracy and
data efﬁciency but also induces logic programs that
can be re-used as background knowledge in subse-
quent learning tasks. To the best of our knowledge,
M etaAbd is the ﬁrst system that can jointly learn
neural networks from scratch and induce recursive
ﬁrst-order logic theories with predicate invention.

1 Introduction

Despite the success of data-driven end-to-end deep learn-
ing in many traditional machine learning tasks, it has been
shown that incorporating domain knowledge is still necessary
for some complex learning problems [Dhingra et al., 2020;
Grover et al., 2019; Trask et al., 2018]. In order to leverage
complex domain knowledge that is discrete and relational,
end-to-end learning systems need to represent it with a dif-
ferentiable module that can be embedded in the deep learn-
ing context. For example, graph neural networks (GNN)
use relational graphs as an external knowledge base [Zhou
et al., 2018]; some works even considers more speciﬁc do-
main knowledge such as differentiable primitive predicates

and programs [Dong et al., 2019; Gaunt et al., 2017]. How-
ever, it is hard to design a uniﬁed differentiable module to ac-
curately represent general relational knowledge, which may
contain complex inference structures such as recursion [Glas-
machers, 2017; Garcez et al., 2019].

Therefore, many researchers propose to break the end-to-
end learning pipeline apart, and build a hybrid model that
consists of smaller modules where each of them only ac-
counts for one speciﬁc function [Glasmachers, 2017]. A rep-
resentative branch in this line of research is Neuro-Symbolic
(NeSy) AI [De Raedt et al., 2020; Garcez et al., 2019] aim-
ing to bridge System 1 and System 2 AI [Kahneman, 2011;
Bengio, 2017], i.e., neural-network-based machine learning
and symbolic-based relational inference.

However, the lack of supervision in the non-differentiable
interface between neural and symbolic systems, based on the
facts extracted from raw data and their truth values, leads to
high computational complexity in learning [Li et al., 2020;
Dai et al., 2019]. Consequently, almost all neural-symbolic
models assume the existence of a very strong predeﬁned do-
main knowledge base and could not perform program induc-
tion. This limits the expressive power of the hybrid-structured
model and sacriﬁces many beneﬁts of symbolic learning (e.g.,
predicate invention, learning recursive theories, and re-using
learned models as background knowledge).

In this paper, we integrate neural networks with Inductive
Logic Programming (ILP) [Muggleton and de Raedt, 1994] to
enable ﬁrst-order logic theory induction from raw data. More
speciﬁcally, we present Abductive Meta-Interpretive Learn-
ing (M etaAbd) which extends the Abductive Learning (ABL)
framework [Dai et al., 2019; Zhou, 2019] by combining log-
ical induction and abduction [Flach et al., 2000] with neural
networks in Meta-Interpretive Learning (MIL) [Muggleton
et al., 2015]. M etaAbd employs neural networks to extract
probabilistic logic facts from raw data, and induces an ab-
ductive logic program [Kakas et al., 1992] that can efﬁciently
infer the truth values of the facts to train the neural model.

To the best of our knowledge, M etaAbd is the ﬁrst system
that can simultaneously (1) train neural models from scratch,
(2) learn recursive logic theories and (3) perform predicate
invention from domains with sub-symbolic representation.
In the experiments we compare M etaAbd to the compared
state-of-the-art end-to-end deep learning models and neuro-
symbolic methods on two complex learning tasks. The results

 
 
 
 
 
 
show that, given the same amount of background knowledge,
M etaAbd outperforms the compared models signiﬁcantly in
terms of predictive accuracy and data efﬁciency, and learns
human interpretable models that could be re-used in subse-
quent learning tasks.

2 Related Work
Solving “System 2” problems requires the ability of relational
and logical reasoning [Kahneman, 2011; Bengio, 2017]. Due
to its complexity, many researchers have tried to embed in-
tricate background knowledge in end-to-end deep learning
models. For example, [Trask et al., 2018] propose the dif-
ferentiable Neural Arithmetic Logic Units (NALU) to model
basic arithmetic functions (e.g., addition, multiplication, etc.)
in neural cells; [Grover et al., 2019] encode permutation op-
erators with a stochastic matrix and present a differentiable
approximation to the sort operation; [Wang et al., 2019] in-
troduce a differentiable SAT solver to enable gradient-based
constraint solving. However, most of these specially designed
differentiable modules are ad hoc approximations to the orig-
inal symbolic inference mechanisms.

To exploit the complex background knowledge expressed
by formal languages directly, Statistical Relational (StarAI)
and Neural Symbolic (NeSy) AI [De Raedt et al., 2020;
Garcez et al., 2019] try to use probabilistic inference or other
differentiable functions to approximate logical inference [Co-
hen et al., 2020; Dong et al., 2019; Manhaeve et al., 2018;
Donadello et al., 2017]. However, they require a pre-deﬁned
symbolic knowledge base and only train the attached neu-
ral/probabilistic models due to the highly complex interface
between the neural and symbolic modules.

One way to learn symbolic theories is to use Inductive
Logic Programming [Muggleton and de Raedt, 1994]. Some
early work on combining logical abduction and induction can
learn logic theories even when input data is incomplete [Flach
et al., 2000]. Recently, ∂ILP was proposed for learning ﬁrst-
order logic theories from noisy data [Evans and Grefenstette,
2018]. However, ILP-based works are designed for learning
in symbolic domains. Otherwise, they need to use a fully
trained neural models to make sense of the raw inputs by ex-
tracting logical facts from the data before program induction.
Machine apperception [Evans et al., 2021] uniﬁes Answer
Set Programming with perception by modeling it with binary
neural networks. It can learn recursive logic theories and per-
form concept (monadic predicate) invention. However, both
logic hypotheses and the parameters of neural networks are
represented by logical groundings, making the system very
hard to optimise. For problems involving noisy inputs like
MNIST images, it still requires a fully pre-trained neural net
for pre-processing due to its high complexity in learning.

Previous work on Abductive Learning (ABL) [Dai et al.,
2019; Dai and Zhou, 2017] also unites subsymbolic percep-
tion and symbolic reasoning through logical abduction, but
they need a pre-deﬁned knowledge base to enable abduction
and cannot perform program induction. Our presented Ab-
ductive Meta-Interpretive Learning takes a step further, which
not only learns a perception model that can make sense of raw
data, but also learns logic programs and performs predicate
invention to understand the underlying relations in the task.

3 Abductive Meta-Interpretive Learning
3.1 Problem Formulation
A typical model bridging sub-symbolic and symbolic learn-
ing contains two major parts: a perception model and a
reasoning model [Dai et al., 2019]. The perception model
maps sub-symbolic inputs x
to some primitive symbols
∈ X
, such as digits, objects, ground logical expressions,
z
etc. The reasoning model takes the interpreted z as input and
infers the ﬁnal output y
according to a symbolic knowl-
edge base B. Because the primitive symbols z are uncertain
and not observable from both training data and the knowledge
base, we have named them as pseudo-labels of x.

∈ Z

∈ Y

|

∪

H

x) = P (z

The perception model is parameterised with θ and outputs
x, θ); the reason-
the conditional probability Pθ(z
|
is a set of ﬁrst-order logical clauses such
ing model H
=” means “logically entails”. Our
that B
z
|
target is to learn θ and H simultaneously from training data
n
i=1. For example, if we have one example
D =
with x = [
] and y = 6, given background knowl-
,
edge about adding two numbers, the hybrid model should
learn a perception model that recognises z = [1, 2, 3] and
induce a program to add each number in z recursively.

∈ H
= y, where “
∪
|
xi, yi(cid:105)}
,

{(cid:104)

Assuming that D is an i.i.d. sample from the underlying

distribution of (x, y), our objective can be represented as
(cid:89)

(cid:88)

(H ∗, θ∗) = arg max

P (y, z

B, x, H, θ),
|

(1)

H,θ

(cid:104)x,y(cid:105)∈D

z∈Z

where pseudo-label z is a hidden variable. Theoretically, this
problem can be solved by Expectation Maximisation (EM) al-
gorithm. However, the symbolic hypothesis H—a ﬁrst-order
logic theory—is difﬁcult to be optimised together with the
parameter θ, which has a continuous hypothesis space.

We propose to solve this problem by treating H like z as

an extra hidden variable, which gives us:

θ∗ = arg max

(cid:89)

(cid:88)

(cid:88)

θ

(cid:104)x,y(cid:105)∈D

H∈H

z∈Z

P (y, H, z

|

B, x, θ).

(2)

|

∼

P (H, z

Now, the learning problem can be split into two EM steps:
(1) Expectation: obtaining the expected value of H and z
by sampling them in their discrete hypothesis space from
B, x, y, θ); (2) Maximisation: estimating
(H, z)
θ by maximising the likelihood of training data with numeri-
cal optimisation approaches such as gradient descent.
Challenges The main challenge is to estimate the expecta-
tion of the hidden variables H
z, i.e., we need to search for
∪
the most probable H and z given the θ learned in the previous
iteration. This is not trivial. Even when B is sound and com-
plete, estimating the truth-values of hidden variable z results
in a search space growing exponentially with the number of
training examples, which is veriﬁed in our experiments with
DeepProblog [Manhaeve et al., 2018] in section 4.1.

Furthermore, the size and structure of hypothesis space
H
of ﬁrst-order logic programs makes the search problem even
] and
more complicated. For example, given x = [
y = 6, when the perception model is accurate enough to out-
put the most probable z = [1, 2, 3], we have at least two
choices for H: cumulative sum or cumulative product. When

,

,

Figure 1: Example of M etaAbd’s abduction-induction learning. Given training examples, background knowledge of abducible primitives
and probabilistic facts generated by a perceptual neural net, M etaAbd learns an abductive logic program H and abduces relational facts as
constraints (implemented with the CLP(Z) predicate “#=”1) over the input images; it then uses them to efﬁciently prune the search space of
the most probable pseudo-labels z (in grey blocks) for training the neural network.

the perception model is under-trained and outputs the most
probable z = [2, 2, 3], then H could be a program that only
multiplies the last two digits. Hence, H and z are entangled
and cannot be treated independently.

3.2 Probabilistic Abduction-Induction Reasoning
Inspired by early works in abductive logic program-
ming [Flach et al., 2000], we propose to solve the challenges
above by combining logical induction and abduction. The in-
duction learns an abductive logic theory H based on Pθ(z
x);
|
the abduction made by H reduces the search space of z.

Abductive reasoning, or abduction refers to the process of
selectively inferring speciﬁc grounded facts and hypotheses
that give the best explanation to observations based on back-
ground knowledge of a deductive theory.

Deﬁnition 3.1 (Abducible primitive) An abducible primi-
tive is a predicate that deﬁnes the explanatory grounding facts
in abductive reasoning.

Deﬁnition 3.2 (Abductive hypothesis) An abductive hy-
pothesis is a set of ﬁrst-order logic clauses whose body
contains literals of abductive primitives.

Following is an example of using abductive hypothesis and

abducible primitive in problem-solving:

,

,

Example 1 Observing raw inputs x = [
] and a
symbolic output y = 6, we could formulate an abductive hy-
pothesis H that is a recursive cumulative sum function, whose
abductive primitives are “+” and “=”. Hence, H will abduce
.
a set of explanatory ground facts
+ = Z, Z + = 6
}
Based on these facts, we could infer that none of the digits
in x is greater than 6. Furthermore, if the current percep-
= 2 and
tion model assigns very high probabilities to
= 1 even when the
perception model has relatively low conﬁdence about it, as
this is the only solution that satisﬁes the constraint stated by
the explanatory groundings.

= 3, we could easily infer that

{

An illustrative example of combining abduction and induc-
tion with probabilities is shown in Fig. 1. Brieﬂy speaking,
instead of directly sampling pseudo-labels z and H together
from the huge hypothesis space, our M etaAbd induces ab-
ductive hypothesis H consists of abducible primitives, and
then use the abduced facts to prune the search space of z.
Meanwhile, the perception model outputs the likelihood of
x) deﬁning a distribution over all
pseudo-labels with pθ(z
|
z.
possible values of z and helps to ﬁnd the most probable H
in Eq. 2:
Formally, we re-write the likelihood of each

∪

x, y
(cid:104)

(cid:105)

P (y, H, z

B, x, θ) = P (y, H
|

= P (y
=P (y

|

x)
B, z)Pθ(z
|
B, z)Pθ(z
B, H, z)P (H
|
|
B)Pθ(z
B, H, z)Pσ∗ (H
|
|

x)
|
x), (3)
|

where Pσ∗ (H
B) is the Bayesian prior distribution on ﬁrst-
|
order logic hypotheses, which is deﬁned by the transitive
closure of stochastic reﬁnements σ∗ given the background
knowledge B [Muggleton et al., 2013], where a reﬁnement
σ is a unit modiﬁcation (e.g., adding/removing a clause or
literal) to a logic theory. The equations hold because: (1)
pseudo-label z is conditioned on x and θ since it is the output
of the perception model; (2) H follows the prior distribution
so it only depends on B; (3) y
H is independent from x
given z because the relations among B, H, y and z are deter-
mined by pure logical inference, where:

∪

P (y

B, H, z) =
|

(cid:26)1,

if B
∪
0, otherwise.

H

∪

z

= y,
|

(4)

Following Bayes’ rule we have P (H, z

P (y, H, z
H

∝
B, x, θ). Now we can search for the most probable
z in the expectation step according to Eq. 3 as follows:

|

B, x, y, θ)
|

∪
1. Induce an abductive theory H

Pσ∗ (H

B);

|

∼

1CLP(Z) is a constraint logic programming package accessible
at https://github.com/triska/clpz. More implementation details are
in Appendix.

Example(hx,yi):f([,,],15).AbduciblePrimitives(B):add([A,B|T],[C|T]):-C#=A+B.mult([A,B|T],[C|T]):-C#=A*B.eq([A|],B):-A#=B.head([H|],H).tail([|T],T).NeuralProbabilisticfacts(pθ(z|x)):nn(=0,0.02).nn(=1,0.39)....nn(=0,0.09).nn(=1,0.02)....nn(=0,0.07).nn(=1,0.00)....Pseudo-labels(z):[0,0,0]...[3,5,0]...[0,3,5]...[0,5,3]...[1,3,5]...[7,8,0][7,8,1]...[7,3,5]...Abducedfacts:+#=15.*#=15.*#=15....+#=X.X+#=15.+#=X.X*#=15....*#=X.X*#=15....Abductivehypotheses(H):f(A,B):-add(A,B).f(A,B):-mult(A,B).f(A,B):-add(A,C),eq(C,B)....f(A,B):-add(A,C),f(C,B).f(A,B):-eq(A,B)....f(A,B):-tail(A,C),f1(C,B).f1(A,B):-mult(A,C),eq(C,B)....f(A,B):-mult(A,C),f1(C,B).f1(A,B):-mult(A,C),eq(C,B)....Abductive Meta-Interpreter

prove([], Prog, Prog, [], Prob, Prob).
prove([Atom|As], Prog1, Prog1, Abds, Prob1, Prob2) :-

deduce(Atom),
prove(As, Prog1, Prog2, Abds, Prob1, Prob2).
prove([Atom|As], Prog1, Prog1, Abds, Prob1, Prob2) :-

call abducible(Atom, Abd, Prob),
Prob3 is Prob1 * Prob,
get max prob(Max), Prob3 > Max,
set max prob(Prob3),
prove(As, Prog1, Prog1, [Abd|Abds], Prob3, Prob2).

prove([Atom|As], Prog1, Prog2, Abds, Prob1, Prob2) :-

meta-rule(Name, MetaSub,(Atom :- Body), Order),
Order,
substitue(metasub(Name, MetaSub), Prog1, Prog3),
prove(Body, Prog3, Prog4),
prove(As, Prog4, Prog2, Abds, Prob1, Prob2)

2. Use H

Figure 2: Prolog code for M etaAbd.
B and y to abduce2 possible pseudo-labels z,
y and

which are guaranteed to satisfy H
z
B
∪
B, H, z) = 0;
exclude the values of z such that P (y
|

∪

∪

(cid:96)

3. According to Eq. 3 and 4, score each sampled H

z:

score(H, z) = Pσ∗ (H

B)Pθ(z

x)
|

|

∪

(5)

4. Return the H

z with the highest score.

∪
3.3 The M etaAbd Implementation
We implement the above abduction-induction algorithm with
Abductive Meta-Interpretive Learning (M etaAbd).

Meta-Interpretive Learning [Muggleton et al., 2015] is a
form of ILP [Muggleton and de Raedt, 1994]. It learns ﬁrst-
order logic programs with a second-order meta-interpreter,
which consists of a deﬁnite ﬁrst-order background knowledge
B and meta-rules M . B contains the primitive predicates
for constructing ﬁrst-order hypotheses H; M is second-order
clauses with existentially quantiﬁed predicate variables and
universally quantiﬁed ﬁrst-order variables. In short, MIL at-
tempts to prove the training examples and saves the resulting
programs for successful proofs.

M etaAbd extends the general meta-interpreter of MIL by
including an abduction procedure (bold fonts in Fig. 2) that
can abduce groundings (e.g., speciﬁc constraints on pseudo-
labels z). As shown in Fig. 2, it recursively proves a series
of atomic goals by deduction (deduce/1), abducing explana-
tory facts (call abducible/3) or generating a new clause
from meta-rule/4.

|

The last argument of call abducible/3, Prob =
x), describes the distribution of possible worlds col-
Pθ(z
lected from the raw inputs. It helps pruning the search space
of the abductive hypothesis H. During the iterative reﬁne-
ment of H, M etaAbd greedily aborts its current prove/6
procedure once it has a lower probability than the best ab-
duction so far (the 8th line in Fig. 2).

After an abductive hypothesis H has been constructed, the
search for z will be done by logical abduction. Finally, the
score of H
x)
is the output of the perception model, which in this work is
implemented with a neural network ϕθ that outputs:

z will be calculated by Eq. 5, where Pθ(z

∪

|

Pθ(z

x) = sof tmax(ϕθ(x, z)).
|

2It can be parallelled, please see Appendix.

Meanwhile, we deﬁne the prior distribution on H by follow-
ing [Hocquette and Muggleton, 2018]:
6
c(H))2 ,

Pσ∗ (H

B) =

(π

|

·

where C(H) is the complexity of H, e.g., its size.

4 Experiments
This section describes the experiments of learning recursive
arithmetic and sorting algorithms from images of handwritten
digits3, aiming to address the following questions:

1. Can M etaAbd learn ﬁrst-order logic programs and train

perceptual neural networks jointly?

2. Given the same or less amount of domain knowledge
shown in Tab. 1, is hybrid modelling, which directly
leverages the background knowledge in symbolic form,
better than end-to-end learning?

4.1 Cumulative sum and product from images
Materials We follow the settings in [Trask et al., 2018].
The inputs of the two tasks are sequences of randomly chosen
MNIST digits; the numerical outputs are the sum and product
of the digits, respectively. The lengths of training sequences
are 2–5. To verify if the learned models can extrapolate to
longer inputs, the length of test examples ranges from 5 to
100. For cumulative product, when the randomly generated
sequence is long enough, it will be very likely to contain a
0 and makes the ﬁnal outputs equal to 0. So the extrapola-
tion examples has maximum length 15 and only contain dig-
its from 1 to 9. The dataset contains 3000 and 1000 examples
for training and validation, respectively; the test data of each
length has 10,000 examples.
Methods We compare M etaAbd with following state-of-
the-art baselines: End-to-end models include RNN, LSTM
and LSTMs attached to Neural Accumulators(NAC) and
Neural Arithmetic Logic Units (NALU) [Trask et al., 2018];
NeSy system DeepProblog [Manhaeve et al., 2018]4.

A convnet processes the input images to the recurrent
networks and Problog programs, as [Trask et al., 2018]
and [Manhaeve et al., 2018] described;
it also serves as
the perception model of M etaAbd to output the probabilis-
tic facts. As shown in Tab. 1, NAC, NALU and M etaAbd
are aware of the same amount of background knowledge for
learning both perceptual convnet and recursive arithmetic al-
gorithms jointly, while DeepProblog is provided with the
ground-truth program and only trains the perceptual convnet.
Like NAC and NALU, M etaAbd uses the same background
knowledge for both sum and product tasks.

Each experiment is carried out ﬁve times, and the average
of the results are reported. The performance is measured by
classiﬁcation accuracy (Acc.) on length-one inputs, mean av-
erage error (MAE) in sum tasks, and mean average error on
logarithm (log MAE) of the outputs in product tasks whose
error grows exponentially with sequence length.

3Code & data: https://github.com/AbductiveLearning/Meta Abd
4We use NAC/NALU at https://github.com/kevinzakka/NALU-
pytorch; DeepProblog at https://bitbucket.org/problog/deepproblog

Domain Knowledge End-to-end Models

Recurrence

Arithmetic functions

Sequence & Odering

Sorting

LSTM & RNN
NAC& NALU [Trask et al., 2018]
Permutation matrix Psort [Grover et al., 2019]
sort operator [Grover et al., 2019]

Neuro-Symbolic Models

Problog’s list operations

Full program of accumulative sum/product
Predicates “>”, “=” and “<” [Dong et al., 2019]
swap(i,j) operator [Dong et al., 2019]

MetaAbd

Prolog’s list operations

Predicates add, mult and eq

Prolog’s permutation

Predicate s (learned from sub-task)

Table 1: Domain knowledge used by the compared models.

Sequence Length

LSTM
RNN-Relu

DeepProblog

MNIST cumulative sum

MNIST cumulative product

Acc.

1

5

MAE

10

100

Acc.

1

log MAE

5

10

15

9.80% 15.3008
10.32% 12.3664

44.3082
41.4368

449.8304
446.9737

9.80% 11.1037
9.80% 10.7635

19.5594
19.8029

21.6346
21.8928

Training timeout (72 hours)

93.64%

Test timeout (72 hours)

LSTM-NAC
LSTM-NAC10k
LSTM-NALU
LSTM-NALU10k
M etaAbd
LSTM-NAC1-shot CNN
LSTM-NALU1-shot CNN
M etaAbd+1-shot CNN

6.0531
7.02%
1.9013
8.85%
6.2233
0.00%
0.00%
6.1041
95.27% 0.5100

49.83% 0.8737
0.00%
6.0070
98.11% 0.2610

29.8749
21.4870
32.7772
31.2402
1.2994

21.1724
30.2110
0.6813

435.4106
424.2194
438.3457
436.8040
6.5867

426.0690
435.7494
4.7090

0.00%
9.6164
10.50% 9.3785
9.6154
0.00%
0.00%
8.9741
97.73% 0.3340

6.0190
0.00%
0.00%
9.6176
97.94% 0.3492

20.9943
20.8712
20.9961
20.9966
0.4951

13.4729
20.9298
0.4920

17.9787
17.2158
17.9487
18.0257
2.3735

17.9787
18.1792
2.4521

Table 2: Accuracy on the MNIST cumulative sum/product tasks.

Results Our experimental results are shown in Tab. 2; the
learned ﬁrst-order logic theories are shown in Fig. 3a. The
end-to-end models that do not exploit any background knowl-
edge (LSTM and RNN) perform worst. NALU and NAC is
slightly better because they include neural cells with arith-
metic modules, but the end-to-end learning pipeline based on
embeddings results in low sample-efﬁciency. DeepProblog
does not ﬁnish the training on the cumulative sum task and
the test on cumulative product task within 72 hours because
the recursive programs result in a huge groundings space for
its maximum a posteriori (MAP) estimation.

The EM-based learning
of M etaAbd may be trapped
optima, which
in
local
frequently
happens more
in
sum than
cumulative
produce since its distribu-
tion P (H, z
is
B, x, y, θ)
|
much denser. Therefore, we
also carry out experiments
with
pre-trained
convnets, which are trained
by randomly sampling one
example in each class from
MNIST data. Although the
pre-trained convnet is weak
at start (Acc. 20%
35%), it
provides a good initialisation
and signiﬁcantly improves
the learning performance.

one-shot

∼

Fig.

3b

compares

the

(a) Learned programs

(b) Time costs of sampling z or H

Figure 3: Learned programs and
the time efﬁciency of M etaAbd.

time efﬁciency between ILP’s induction and M etaAbd’s
abduction-induction in one EM iteration of learning cumula-
H” means ﬁrst sampling z and then inducing
tive sum. “z
z” means ﬁrst sampling an abductive
H with ILP; “H

→

→

hypothesis H and then using H to abduce z. The x-axis de-
notes the average number of Prolog inferences, the number at
the end of each bar is the average inference time in seconds.
Evidently, the abduction leads to a substantial improvement
in the number of Prolog inferences and signiﬁcantly the
complexity of searching pseudo-labels.
4.2 Bogosort from images
Materials We follow the settings in [Grover et al., 2019].
The input of this task is a sequence of randomly chosen
MNIST images of distinct numbers; the output is the cor-
rect ranking (from large to small) of the digits. For exam-
] then the output should
ple, when x = [
be y = [3, 1, 4, 5, 2] because the ground-truth labels z∗ =
[5, 9, 4, 3, 8]. The training dataset contains 3000 training/test
and 1000 validation examples. The training examples are se-
quences of length 5, and we test the learned models on image
sequences with lengths 3, 5 and 7.

,

,

,

,

Methods We compare M etaAbd to an end-to-end model
NeuralSort [Grover et al., 2019] and a state-of-the-art NeSy
approach Neural Logical Machines (NLM) [Dong et al.,
2019]5. All experiments are repeated ﬁve times.

NeuralSort can be regarded as a differentiable approxima-
tion to bogosort (permutation sort). Given an input list of
scalars, it generates a stochastic permutation matrix by apply-
ing the pre-deﬁned deterministic or stochastic sort operator
on the inputs. NLM can learn sorting through reinforcement
learning in a domain whose states are described by vectors
of relational features (groundings of dyadic predicates“>”,
“==”, “<”) and action “swap”. However, the original NLM
only takes symbolic inputs6, which provides a noisy-free re-

5We use NeuralSort at https://github.com/ermongroup/neuralsort;

NLM at https://github.com/google/neural-logic-machines.

6Please see https://github.com/google/neural-logic-machines

/blob/master/scripts/graph/learn policy.py

CumulativeSum:f(A,B):-add(A,C),f(C,B).f(A,B):-eq(A,B).CumulativeProduct:f(A,B):-mult(A,C),f(C,B).f(A,B):-eq(A,B).Bogosort:f(A,B):-permute(A,B,C),s(C).s(A):-s1(A,B),s(B).s(A):-tail(A,B),empty(B).s1(A,B):-nnpred(A),tail(A,B).Sequence Length

3

5

7

Neural Logical Machine (NLM)

17.97% (34.38%)

1.03% (20.27%)

0.01% (14.90%)

Deterministic NeuralSort

95.49% (96.82%)

88.26% (94.32%)

80.51% (92.38%)

Stochastic NeuralSort

95.37% (96.74%)

87.46% (94.03%)

78.50% (91.85%)

M etaAbd

96.33% (97.22%)

91.75% (95.24%)

87.42% (93.58%)

Table 3: Accuracy of MNIST sort. First value is the rate of correct permutations; second value is the rate of correct individual element ranks.

For M etaAbd,

lational features vector. In our experiments, we attach NLM
with the same convnet as other methods to process images.
We also compared to DeepProblog with the ground-truth pro-
gram of sorting in this task, but it does not terminate when the
neural predicate “swap net”7 is implemented to take noisy
image inputs by the aforementioned convnet. Therefore, we
do not display its performance in this task.
it

is easy to include stronger back-
ground knowledge for learning more efﬁcient sorting algo-
rithms [Cropper and Muggleton, 2019]. But in order to make
a fair comparison to NeuralSort, we adapt the same back-
ground knowledge to logic program and let M etaAbd learn
bogosort. The knowledge of permutation in M etaAbd is
implemented with Prolog’s built-in predicate permutation.
Meanwhile, instead of providing the information about sort-
ing as prior knowledge like the NeuralSort, we try to learn
the concept of “sorted” (represented by a monadic predicate
s) from data as a sub-task, whose training set is the subset of
the sorted examples within the training dataset (< 20 exam-
ples). The two tasks are trained sequentially as a curriculum.
M etaAbd learns the sub-task in the ﬁrst ﬁve epochs and then
re-uses the learned models to learn bogosort.

M etaAbd uses an MLP attached to the same untrained con-
vnet as other models to produce dyadic probabilistic facts
nn pred([ , | ]), which learns if the ﬁrst two items in
the image sequence satisfy a dyadic relation. Unlike NLM,
the background knowledge of M etaAbd is agnostic to order-
ing, i.e., the dyadic nn pred is not provided with supervision
on whether it should learn “greater than” or “less than”, so
nn pred only learns an unknown dyadic partial order among
MNIST images. As we can see, the background knowledge
used by M etaAbd is much weaker than the others.

Results Tab. 3 shows the average accuracy of the compared
methods in the sorting tasks; Fig. 3a shows the learned pro-
grams by M etaAbd. The performance is measured by the av-
erage proportion of correct permutations and individual per-
mutations following [Grover et al., 2019]. Although using
weaker background knowledge, M etaAbd has a signiﬁcantly
better performance than NeuralSort. Due to the high sample-
complexity of reinforcement learning, NLM failed to learn
any valid perceptual model and sorting algorithm (success
trajectory rate 0.0% during training).

The learned program of s and the dyadic neural net
nn pred are both successfully re-used in the sorting task,
where the learned program of s is consulted as interpreted
background knowledge [Cropper et al., 2020], and the neural
network that generates probabilistic facts of nn pred is di-
rectly re-used and continuously trained during the learning of

7Please see https://bitbucket.org/problog/deepproblog/src/master

/examples/NIPS/Forth/Sort/quicksort.pl

sorting. This experiment also demonstrates M etaAbd’s abil-
ity of learning recursive logic programs and predicate inven-
tion (the invented predicate s 1 in Fig. 3a).
5 Conclusion
In this paper, we present the Abductive Meta-Interpretive
Learning (M etaAbd) approach that can simultaneously train
neural networks and learn recursive ﬁrst-order logic theo-
ries with predicate invention. By combining ILP with neural
networks, M etaAbd can learn human-interpretable logic pro-
grams directly from raw-data, and the learned neural models
and logic theories can be directly re-used in subsequent learn-
ing tasks. M etaAbd adopts a general framework for combin-
ing perception with logical induction and abduction. The per-
ception model extracts probabilistic facts from sub-symbolic
data; the logical induction searches for ﬁrst-order abductive
theories in a relatively small hypothesis space; the logical
abduction uses the abductive theory to prune the vast search
space of the truth values of the probabilistic facts. The three
parts are optimised together in a probabilistic model.

In future work, we would like to apply M etaAbd in
real tasks such as computational science discovery, which
involve both sym-
is a typical abductive process that
bolic domain knowledge and continuous/noisy raw data.
Since M etaAbd uses pure logical inference for reasoning,
it is possible to leverage more advanced symbolic infer-
ence/optimisation techniques like Satisﬁability Modulo The-
ories (SMT) [Barrett and Tinelli, 2018] and Answer Set Pro-
gramming (ASP) [Lifschitz, 2019] to reason more efﬁciently.
Acknowledgements
The ﬁrst author acknowledges support from the UK’s EPSRC
Robot Synthetic Biologist, grant EP/R034915/1, for ﬁnan-
cial support. The second author acknowledges support from
the UK’s EPSRC Human-Like Computing Network, grant
EP/R022291/1, for which he acts as director. The authors
thank C´eline Hocquette, Stassa Patsantzis and Ai Lun for
their careful proofreading and helpful comments.

References
[Barrett and Tinelli, 2018] Clark W. Barrett and Cesare Tinelli. Sat-
In Handbook of Model Checking,

isﬁability modulo theories.
pages 305–343. Springer, 2018.

[Bengio, 2017] Yoshua Bengio. The consciousness prior. CoRR,

abs/1709.08568, 2017.

[Cohen et al., 2020] William W. Cohen, Fan Yang, and Kathryn
Mazaitis. Tensorlog: A probabilistic database implemented us-
ing deep-learning infrastructure. Journal of Artiﬁcial Intelligence
Research, 67:285–325, 2020.

[Cropper and Muggleton, 2019] Andrew Cropper and Stephen H.
Muggleton. Learning efﬁcient logic programs. Maching Learn-
ing, 108(7):1063–1083, 2019.

[Cropper et al., 2020] Andrew Cropper, Rolf Morel, and Stephen
Muggleton. Learning higher-order logic programs. Maching
Learning, 109(7):1289–1322, 2020.

[Dai and Zhou, 2017] W.-Z. Dai and Z.-H. Zhou. Combining logi-
cal abduction and statistical induction: Discovering written prim-
itives with human knowledge. In Proceedings of the 31st AAAI
Conference on Artiﬁcial Intelligence, pages 4392–4398, San
Francisco, CA, 2017.

[Dai et al., 2019] Wang-Zhou Dai, Qiu-Ling Xu, Yang Yu, and Zhi-
Hua Zhou. Bridging machine learning and logical reasoning by
abductive learning. In Advances in Neural Information Process-
ing Systems 32, pages 2811–2822. Curran Associates, Inc., 2019.
[De Raedt et al., 2020] Luc De Raedt, Sebastijan Dumanˇci´c, Robin
Manhaeve, and Giuseppe Marra. From statistical relational to
neuro-symbolic artiﬁcial intelligence. In Christian Bessiere, ed-
itor, Proceedings of the 29th International Joint Conference on
Artiﬁcial Intelligence, pages 4943–4950. IJCAI, 7 2020.

[Dhingra et al., 2020] Bhuwan Dhingra, Manzil Zaheer, Vidhisha
Balachandran, Graham Neubig, Ruslan Salakhutdinov, and
William W. Cohen. Differentiable reasoning over a virtual knowl-
edge base. In International Conference on Learning Representa-
tions, Addis Ababa, Ethiopia, 2020. OpenReview.

[Donadello et al., 2017] Ivan Donadello, Luciano Seraﬁni, and Ar-
tur S. d’Avila Garcez. Logic tensor networks for semantic im-
age interpretation. In Proceedings of the 26th International Joint
Conference on Artiﬁcial Intelligence, pages 1596–1602, Mel-
bourne, Australia, 2017. IJCAI.

[Dong et al., 2019] Honghua Dong, Jiayuan Mao, Tian Lin, Chong
Wang, Lihong Li, and Denny Zhou. Neural logic machines. In
International Conference on Learning Representations, New Or-
leans, LA, 2019. OpenReview.

[Evans and Grefenstette, 2018] Richard Evans and Edward Grefen-
stette. Learning explanatory rules from noisy data. Journal of
Artiﬁcial Intelligence Research, 61:1–64, 2018.

[Evans et al., 2021] Richard Evans, Matko Boˇsnjak, Lars Buesing,
Kevin Ellis, David Pfau, Pushmeet Kohli, and Marek J. Sergot.
Making sense of raw input. Artiﬁcial Intelligence, 299:103521,
2021.

[Flach et al., 2000] Peter A. Flach, Antonis C. Kakas, and Anto-
nis M. Hadjiantonis, editors. Abduction and Induction: Essays on
Their Relation and Integration. Applied Logic Series. Springer
Netherlands, 2000.

[Garcez et al., 2019] Artur S. d’Avila Garcez, Marco Gori, Lu´ıs C.
Lamb, Luciano Seraﬁni, Michael Spranger, and Son N. Tran.
Neural-symbolic computing: An effective methodology for prin-
cipled integration of machine learning and reasoning. IfCoLog
Journal of Logics and their Applications, 6(4):611–632, 2019.
[Gaunt et al., 2017] Alexander L. Gaunt, Marc Brockschmidt, Nate
Kushman, and Daniel Tarlow. Differentiable programs with neu-
In Proceedings of the 34th International Confer-
ral libraries.
ence on Machine Learning, volume 70, pages 1213–1222, Syd-
ney, Australia, 2017. PMLR.

[Glasmachers, 2017] Tobias Glasmachers. Limits of end-to-end
In Proceedings of The 9th Asian Conference on Ma-
learning.
chine Learning, volume 77, pages 17–32, Seoul, Korea, 2017.
PMLR.

[Grover et al., 2019] Aditya Grover, Eric Wang, Aaron Zweig, and
Stefano Ermon. Stochastic optimization of sorting networks via
continuous relaxations. In International Conference on Learning
Representations, New Orleans, LA, 2019. Openreview.

[Hocquette and Muggleton, 2018] C´eline

and
Stephen H. Muggleton. How much can experimental cost
In Proceed-
be reduced in active learning of agent strategies?
ings of the 28th International Conference on Inductive Logic
Programming, volume 11105, pages 38–53, Ferrara, Italy, 2018.
Springer.

Hocquette

[Kahneman, 2011] Daniel Kahneman. Thinking, fast and slow. Far-

rar, Straus and Giroux, New York, 2011.

[Kakas et al., 1992] Antonis C. Kakas, Robert A. Kowalski, and
Francesca Toni. Abductive logic programming. Journal of Logic
Computation, 2(6):719–770, 1992.

[Li et al., 2020] Qing Li, Siyuan Huang, Yining Hong, Yixin Chen,
Ying Nian Wu, and Song-Chun Zhu. Closed loop neural-
symbolic learning via integrating neural perception, grammar
parsing, and symbolic reasoning. In Proceedings of the 37th In-
ternational Conference on Machine Learning, volume 119, pages
5884–5894, Online, 2020. PMLR.

[Lifschitz, 2019] Vladimir Lifschitz. Answer Set Programming.

Springer, 2019.

[Manhaeve et al., 2018] Robin Manhaeve, Sebastijan Dumancic,
Angelika Kimmig, Thomas Demeester, and Luc De Raedt. Deep-
problog: Neural probabilistic logic programming. In Advances
in Neural Information Processing Systems 31, pages 3753–3763,
Montr´eal, Canada, 2018. Curran Associates, Inc.

[Muggleton and de Raedt, 1994] Stephen H. Muggleton and Luc
Inductive logic programming: Theory and methods.

de Raedt.
The Journal of Logic Programming, 19-20:629 – 679, 1994.
[Muggleton et al., 2013] Stephen H. Muggleton, Dianhuan Lin,
Jianzhong Chen, and Alireza Tamaddoni-Nezhad. MetaBayes:
higher-order
Bayesian meta-interpretative
stochastic reﬁnement. In Proceedings of the 23rd International
Conference on Inductive Logic Programming, volume 8812,
pages 1–17, Rio de Janeiro, Brazil, 2013. Springer.

learning

using

[Muggleton et al., 2015] Stephen H. Muggleton, Dianhuan Lin,
and Alireza Tamaddoni-Nezhad. Meta-interpretive learning of
higher-order dyadic datalog: predicate invention revisited. Ma-
chine Learning, 100(1):49–73, 2015.

[Trask et al., 2018] Andrew Trask, Felix Hill, Scott E Reed, Jack
Rae, Chris Dyer, and Phil Blunsom. Neural arithmetic logic units.
In Advances in Neural Information Processing Systems 31, pages
8035–8044. Curran Associates, Inc., 2018.

[Wang et al., 2019] Po-Wei Wang, Priya L. Donti, Bryan Wilder,
and J. Zico Kolter. SATNet: Bridging deep learning and logical
reasoning using a differentiable satisﬁability solver. In Proceed-
ings of the 36th International Conference on Machine Learning,
pages 6545–6554, Long Beach, CA, 2019. PMLR.

[Zhou et al., 2018] Jie Zhou, Ganqu Cui, Zhengyan Zhang, Cheng
Yang, Zhiyuan Liu, and Maosong Sun. Graph neural networks:
A review of methods and applications. CoRR, abs/1812.08434,
2018.

[Zhou, 2019] Zhi-Hua Zhou. Abductive learning: towards bridging
machine learning and logical reasoning. Science China Informa-
tion Sciences, 62(7), 2019.

A Appendix
We introduce more implementation details and experimental results in the following sub-sections.

{(cid:104)

∝
P (y

P (H, y, z

A.1 Parallel Abduction
As described in section 3.2, M etaAbd tries to estimate the most probable z by abduction following Eq. 3. Given
z the
training data D =
posterior P (H, z

n
i=1, let x = (x1, . . . , xn), y = (y1, . . . , yn) and z = (z1, . . . , zn), for H
xi, yi
(cid:105)}
B, x, y, θ)
|

B, x, θ), which can be further re-written as:
|
B, H, z)Pσ∗(H
|
= Pσ∗(H

B)Pθ(z
|
B) (cid:81)n
|
where the last equation holds because the examples are drawn i.i.d. from the underlying distribution.
Therefore, the logical abduction in the expectation step of M etaAbd can be parallelised naturally:
1. Sample an abductive hypothesis H from the prior distribution H
2. Parallelly abduce zi from H and
3. Aggregate the results by Eq. 6;
4. Get the best H

, and then calculate their scores by Eq. 5;
(cid:105)

z and continue the maximisation step to optimise θ.

B, H, zi)Pθ(zi
|

x)
|
i=1 P (yi

xi, yi
(cid:104)

xi),
|

B);
|

Pσ∗(H

(6)

∼

∪

We applied this strategy in our implementation of M etaAbd and have achieved better efﬁciency on multi-threaded
CPUs.

∪

A.2 MNIST Cumulative Sum/Product
The background knowledge used in the MNIST cumulative sum/product experiments is shown in Fig. 4. We demon-
strate how it works by the following example.

% Non-abducible primitives of list operations.
head([H| ],H).
tail([ |T],T).
empty([]).

% Abducible primitives for generating CLP constraints.
abduce add([X,Y|T],[N|T],Abduced,1.0):-

(not(ground(N)) ->

metagol:new var(N); number(N)),

atomics to string([X,’+’,Y,’#=’,N], Abduced).

abduce mult([X,Y|T],[N|T],Abduced,1.0):-

(not(ground(N)) ->

metagol:new var(N); number(N)),

atomics to string([X,’*’,Y,’#=’,N], Abduced).

abduce eq([X|T],[N|T],Abduced,1.0):-

(not(ground(N)) ->

metagol:new var(N); number(N)),
atomics to string([X,’#=’,N], Abduced).

Figure 4: Background knowledge used in the MNIST cumulative sum/product tasks.

Example (Constraint abduction) Given a training example f([ , , , ],15), M etaAbd will try to learn a
program of the dyadic predicate f to satisfy (i.e., logically prove) the example. The program to be learned is the
abductive hypothesis H. The learning process is similar to generic Meta-Interpretive Learning [Muggleton et al.,
2015] except that it abduces some ground expressions (the Abduced atom in Fig. 4) according to the deﬁnition of
the abducible primitives. In the MNIST sum/product tasks, the Abduced atoms are strings like “X+ #=3”, which is
a CLP(Z)8 constraint. According to the deﬁnition in Fig. 4, when the Prolog variable is not grounded (i.e., constant),
the abducible variable will create a new variable to represent N; if the Prolog variable is grounded to a number, which
means it is the ﬁnal output in our example, then there is no need to generate a new variable to represent it. Assume
that the currently sampled H is the cumulative sum program in Fig. 3a, then for the example f([ , , , ],15)
M etaAbd can abduce four CLP(Z) constraints: “ + #=N1”, “N1+ #=N2”, “N2+ #=N3” and “N3#=15”. Note that

8https://github.com/triska/clpz

(a) MNIST sum

(b) MNIST product

(c) MNIST sum with 1-shot CNN pre-train

(d) MNIST product with 1-shot CNN pre-train

Figure 5: Pseudo-label accurracy during M etaAbd and M etaAbd+1-shot CNN learning.

nn( ,0,P00).
nn( ,0,P10).
nn( ,0,P20).
nn( ,0,P30).

nn( ,1,P01).
nn( ,1,P11).
nn( ,1,P21).
nn( ,1,P31).

nn( ,2,P02).
nn( ,2,P12).
nn( ,2,P22).
nn( ,2,P32).

...
...
...
...

Figure 6: Monadic probabilistic facts generated by neural network in the sum/product tasks.

the scores of the abducibles in Fig. 4 are all 1.0, which means that these constraints are hard constraints that have to
be satisﬁed.

After abducing the constraints, M etaAbd will call the CLP(Z) to solve them, giving a small set of pseudo-labels z
z according to Eq. 5.
that satisfy those constraints. Then, M etaAbd will try to calculate the scores of the abduced H
x) is given by the probabilistic
B) is directly given by H’s complexity, i.e., the size of the program; Pθ(z
Pσ∗(H
|
facts by the perception neural network, which are shown in Fig. 6. The predicate “nn(Img,Label,Prob)” means
the probability of Img being an instance of Label is Prob. To get the probability of all pseudo-labels of an image
sequence, M etaAbd simply multiplies the probabilities of each image:

∪

|

x) =

pθ(z

|

(cid:89)

j

pθ(zj

xj),

|

where xj is the j-th image in x (ﬁrst argument of predicate nn), zj is the abduced pseudo-label of xj (second
argument of nn), and the probability is the third argument of nn.

We also report the pseudo-label accuracy of abduction and perception during training, which are shown in Fig. 5.
The blue lines are the accuracy of the abduced labels (i.e., the accuracy of the expectation of z) in each EM iteration;
the orange lines are the accuracy of the perceptual neural net’s classiﬁcation accuracy on the MNIST test set. As we

11020304050Epochs0.20.40.60.81.0Pseudo-label AccuracyAbduction AccuracyTest Accuracy11020304050Epochs0.20.40.60.81.0Pseudo-label AccuracyAbduction AccuracyTest Accuracy11020304050Epochs0.20.40.60.81.0Pseudo-label AccuracyAbduction AccuracyTest Accuracy11020304050Epochs0.30.40.50.60.70.80.91.0Pseudo-label Accurac Abduction Accurac Test Accurac % List operations.
head([H| ],H).
tail([ |T],T).
empty([]).

% Background knowledge about permutation
permute(L1,O,L2):-

length(L1,N),
findall(S,between(1,N,S),O1),
% generate permutation with Prolog’s built-in predicate
catch(permutation(O1,O), ,fail),
permute1(L1,O,L2).

% permute the image list with order O
permute1([],[], ).
permute1([S|List],[O|Os],List2):-

nth1(O,List2,S),
permute1(List,Os,List2).

% Abducible primitives.
abduce nn pred([X,Y| ],nn pred(X,Y),Score):-

nn pred(X,Y,Score).

Figure 7: Background knowledge used in the MNIST sorting task.

nn pred(X,Y,P) :- nn(X,Y,P), !.
nn pred(X,Y,P) :- nn(Y,X,P1), P is 1-P1, !.

nn( , ,P01). nn( , ,P02).
nn( , ,P12). nn( , ,P13).

nn( , ,P02).
nn( , ,P13).

...
...

Figure 8: Dyadic probabilistic facts generated by neural network in the sorting task.

can observe, the convergence speed of cumulative sum is slower, because its the posterior distribution on pseudo-
labels (P (H, z
B, x, y, θ)) is much denser than that of cumulative product. After applying the one-shot CNN pre-
train, whose test accuracy is shown at 0 epoch in the ﬁgures, the convergence speed of MNIST cumulative sum is
signiﬁcantly improved because the EM algorithm is less-likely to be trapped in local optimums.

|

A.3 MNIST Sorting
Different to the MNIST cumulative sum/product tasks which learn a perceptual neural network predicting the digit
in each single image, in the MNIST sorting task, M etaAbd uses a perceptual neural network to learn an unknown
binary relation between two images. Examples are shown in Fig. 8. The neural network uses the same convnet as
before to take the input from a pair of images (the ﬁrst two arguments of predicate nn), and then a Multi-Layered
Perception (MLP) is used to predict the probability PIJ. The ﬁrst two clauses translate the neural network’s output
nn to the probabilistic facts for M etaAbd’s abduction.
Example (Dyadic facts abduction) Background knowledge of the MNIST sorting task is shown in Fig. 7. Dif-
ferent to the previous example which abduces the label of each input image, in the sorting task, the facts be-
ing extracted from raw data are dyadic relationship between two images. Given an training example with input
x = [ , , , ], the perceptual neural network will process all the pairwise combinations among them and
output a score as shown in Fig. 8. Because the pairwise combinations are just a half of pairwise permutations, we
also provided a symmetric rule to complete them (the ﬁrst two clauses in Fig. 8). During M etaAbd’s induction, the
abduced facts are the pairwise probabilistic facts themselves instead of CLP(Z) constraints like before, so the Score
is the probability of each probabilistic fact. In other words, in the sorting task, the abduction of z (the truth values
of the probabilistic facts) is performed simultaneously with logical induction. Recall the Prolog code of M etaAbd
in Fig. 2, there is a greedy process that keeps the current most probable abduction with getmaxprob(Max) and
setmaxprob(Max). The greedy strategy is used to prune the search space of z, it excludes the facts with low prob-
ability and quickly ﬁnd a locally optimal z (truth value assignment), which will be used as pseudo-labels to train the
perceptual neural network in the maximisation step.

Figure 9: MNIST pairwise ordering (nn pred) accuracy during learning.

metarule([P,Q],[P,A],[[Q,A]]).
metarule([P,Q],[P,A],[[Q,A,B],[P,B]]).
metarule([P,Q,R],[P,A],[[Q,A,B],[R,B]]).
metarule([P,Q,R],[P,A,B],[[Q,A],[R,A,B]]).
metarule([P,Q],[P,A,B],[[Q,A,B]]).
metarule([P,Q,R],[P,A,B],[[Q,A,B],[R,A,B]]).
metarule([P,Q,R],[P,A,B],[[Q,A,B,C],[R,C]]).
metarule([P,Q,R],[P,A,B],[[Q,A,B],[R,B]]).
metarule([P,Q,R],[P,A,B],[[Q,A,C],[R,C,B]]).

Figure 10: Meta-rules used in all the experiments.

Fig. 9 shows the perception accuracy during training. The test pairs contains 10,000 randomly sampled images
from the MNIST test set. The vertical line at epoch 5 shows the time point when M etaAbd switching from the
sub-task (learning concept of “sorted” with target predicate s) to the main tasks (learning permutation sort). The
results in this ﬁgure veriﬁes that the perception model is successfully re-used in this experiment.

A.4 Reproducibility
We introduce more experimental details in this subsection. All experiments are completed on a PC with AMD Ryzen
3900X CPU and Nvidia 2080Ti GPU. The data and source codes of M etaAbd will be available after the publication
of this work.

meta-rules
The meta-interpreter of M etaAbd uses a set of meta-rules to guide the induction of the logic theory H. We use
9 [Cropper et al., 2020], which are shown in
the meta-rules from the higher-order meta-interpreter M etagolho
Fig. 10.It has been shown that these meta-rules have universal Turing expressivity and can represent higher-order
programs [Cropper et al., 2020].

We further compared the inference speed of M etaAbd with different sizes of meta-rules. Speciﬁcally, following
are the time difference measured by the average number of Prolog inferences in each batch of ’s abduction-induction
inference in the accumulative sum task. The settings are as follows:

• M etaAbd contains at least one metarule, which is P(A,B):-Q(A,B), i.e., calling a primitive function. However,
it is not complete for representing the hypothesis space since none of the primitive predicates is able to deﬁne
the target concept (otherwise they won’t be called as “primitives”). Hence, we start from at least 2 meta-rules;
• The perceptual CNN is randomly initialised and un-trained, i.e., the distribution of probabilistic facts is random,

which is the worst-case for abduction, so the result here is slower than the average result in Fig. 3b;

• Choosing metarules is a subset selection problem. Following the traditions in combinatorial optimisation, we

report the worst result among all varied combinations;

9https://github.com/andrewcropper/mlj19-metaho

151020304050Epochs0.50.60.70.80.91.0Pairwise Image Ordering Acc racyTest Acc racyNumber of meta-rules Number of Prolog inferences Time (seconds)

9
8
7
6
5
4
3
2

26324856
26324638
26324626
26324287
26324009
26321479
26314047
10991735

1.571
1.567
1.567
1.527
1.528
1.521
1.521
0.635

Table 4: Time costs (worst-case) of using different numbers of meta-rules. Note that the setting of using only 2 meta-rules is equivalent to
RNNs which are forced to learn a minimum recursive program.

• The number of Prolog inferences includes the CLP(Z) optimisation.

As we can see from Fig. 4, there is not much difference between using 9–3 metarules for M etaAbd (when the
program hypothesis space is complete). Hence, if the users have a strong bias on the target theory and only use the
relevant metarules, the search speed can be very fast.

Neural Network & Hyperparameters
The convnet in our experiments is from PyTorch’s MNIST tutorial10 as [Trask et al., 2018] suggested. The LSTM
and RNN models in the MNIST cumulative sum/product experiments have 2 hidden layers with dimension 64; the
NAC and NALU modules have 2 hidden layers with dimension 32. In the MNIST sorting experiments, we set the
hyperparameter τ = 1.0 for NeuralSort, which is the default value in the original codes11. Moreover, the output of
NeuralSort is a vector with ﬂoating numbers, in order to reproduce the result from the original paper, we rank the
output scores to generate the ﬁnal prediction of orderings.

DeepProblog [Manhaeve et al., 2018] and Neural Logical Machines (NLM) [Dong et al., 2019] are treated as
blackbox models attached with the same convnet as M etaAbd. The Problog programs of DeepProblog are the
ground-truth programs in Fig. 3a; the parameters of NLM is tuned following the instructions in its repository.

10https://github.com/pytorch/examples/tree/master/mnist
11https://github.com/ermongroup/neuralsort

