FF-NSL: Feed-Forward Neural-Symbolic Learner

Daniel Cunnington1,2, Mark Law2, Alessandra Russo2 and Jorge Lobo2,3

1IBM Research Europe, Winchester, UK
2Imperial College London, London, UK
3Universitat Pompeu Fabra, Barcelona, Spain

Abstract
Inductive Logic Programming (ILP) aims to learn generalised, interpretable hypotheses in a data-efficient
manner. However, current ILP systems require training examples to be specified in a structured logical
form. To address this problem, this paper proposes a neural-symbolic learning framework, called Feed-
Forward Neural-Symbolic Learner (FF-NSL), that integrates state-of-the-art ILP systems, based on the
Answer Set semantics, with Neural Networks (NNs), in order to learn interpretable hypotheses from
labelled unstructured data. To demonstrate the generality and robustness of FF-NSL, we use two datasets
subject to distributional shifts, for which pre-trained NNs may give incorrect predictions with high
confidence. Experimental results show that FF-NSL outperforms tree-based and neural-based approaches
by learning more accurate and interpretable hypotheses with fewer examples.

Keywords
inductive logic programming, neural-symbolic learning, distributional shift

1. Introduction

Inductive Logic Programming (ILP) systems learn a set of logical rules, called a ℎ𝑦𝑝𝑜𝑡ℎ𝑒𝑠𝑖𝑠, that
together with some (optional) background knowledge, explains a set of labelled examples [1].
ILP systems are capable of learning general and interpretable hypotheses in a data efficient
manner. However, training examples are specified in a structured logical form, which limits their
applicability to many real-world tasks. Differentiable learning systems, such as (deep) Neural
Networks (NNs), are able to learn directly from unstructured data. These approaches, however,
are vulnerable to distributional shifts, where data observed at run-time belongs to a different
distribution than that observed during training, which often leads to incorrect predictions with
high confidence [2, 3, 4]. Also, they require large amounts of training data, and their learned
models are difficult to interpret [5]. This paper introduces a neural-symbolic learning framework,
called Feed-Forward Neural-Symbolic Learner (FF-NSL), that aims to address the drawbacks of
these two paradigms by integrating pre-trained NNs, to extract symbolic facts from unstructured
data, with state-of-the-art ILP systems [6, 7], to learn generalised and interpretable hypotheses
that can solve a downstream classification task. The novel component is the Example Generator
that bridges the neural and symbolic learning components. This enables pre-trained NNs to
be used more reliably by exploiting the ability of the ILP system to learn complex and general

" dancunnington@uk.ibm.com (D. Cunnington); mark.law09@imperial.ac.uk (M. Law); a.russo@imperial.ac.uk
(A. Russo); jorge.lobo@upf.edu (J. Lobo)

© 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
CEUR Workshop Proceedings (CEUR-WS.org)

1
2
0
2

l
u
J

2

]

G
L
.
s
c
[

2
v
3
0
1
3
1
.
6
0
1
2
:
v
i
X
r
a

CEURWorkshopProceedingshttp://ceur-ws.orgISSN 1613-0073 
 
 
 
 
 
knowledge from noisy examples, so that incorrect NN predictions, made potentially with high
confidence, can be tolerated. We evaluated our approach on two classification tasks: Follow
Suit winner, where the objective is to predict the winner of a four-player trick-based card
game1, and Sudoku grid validity, where the objective is to learn the classification of invalid
Sudoku grids represented as sequences of MNIST digits. Our results show that FF-NSL learned
accurate and interpretable hypotheses from unstructured input data subject to distributional
shifts, outperforming random forest and NN baseline approaches.

2. Background

⟨

Learning from Answer Sets (LAS) [8] is a general ILP approach [6] supported by state-of-the-
art systems (ILASP [6] and FastLAS [7]) that are robust to noisy data [9] and, in the case of
FastLAS, scalable to large hypothesis spaces [7]. The LAS approach learns logic programs
expressed using Answer Set Programming (ASP) [10]. Typically, a problem can be encoded as
an ASP program whose answer sets correspond to solutions of the original problem. In the LAS
framework, such ASP programs are learned from examples, defined as partial interpretations [9].
A partial interpretation 𝑒𝑝𝑖 is a pair of sets of ground atoms
, called inclusion and
𝑝𝑖 ∩ 𝐴 = ∅. A LAS
exclusion sets respectively. An answer set 𝐴 extends 𝑒𝑝𝑖 iff 𝑒𝑖𝑛𝑐
task uses the special notion of Weighted Context-Dependant Partial Interpretation (WCDPI)
examples. A WCDPI is a tuple 𝑒 = ⟨𝑒𝑖𝑑, 𝑒𝑝𝑒𝑛, 𝑒𝑝𝑖, 𝑒𝑐𝑡𝑥⟩. 𝑒𝑖𝑑 is a unique identifier for 𝑒; 𝑒𝑝𝑒𝑛,
called penalty or weight, is either ∞, meaning the example must be covered, or it is a positive
integer representing the penalty for not covering the example; 𝑒𝑝𝑖 is a partial interpretation used
to encode positive and negative labels as part of its inclusion and exclusion sets respectively;
and 𝑒𝑐𝑡𝑥 is an ASP program (e.g., a conjunction of facts), called the context in which the example
is interpreted. An ASP program 𝑃 accepts a WCDPI example 𝑒 if and only if there is an answer
set of 𝑃 ∪ 𝑒𝑐𝑡𝑥 that extends 𝑒𝑝𝑖. In practice, the penalty 𝑒𝑝𝑒𝑛 is used to bias the ILP system
towards hypotheses that accept (or reject) certain examples, as it constitutes the penalty paid
by a hypothesis for 𝑛𝑜𝑡 accepting that example. The cost of a hypothesis 𝐻 is the length of the
hypothesis plus the sum over the penalties of all examples that are not accepted by 𝐻.

𝑝𝑖 , 𝑒𝑒𝑥𝑐
𝑒𝑖𝑛𝑐
𝑝𝑖
𝑝𝑖 ⊆ 𝐴 and 𝑒𝑒𝑥𝑐

⟩

𝐿𝐴𝑆

Formally, a context-dependent LAS task (denoted as 𝐼𝐿𝑃 𝑐𝑜𝑛𝑡𝑒𝑥𝑡

) is defined as a tuple ⟨𝐵,𝑆𝑀 ,
𝐸 ⟩, where 𝐵 is background knowledge expressed as an ASP program, 𝑆𝑀 is the hypothesis
space, defined by a language bias2 𝑀 , and 𝐸 is a set of WCDPI examples3. The hypothesis space
task
is the set of rules that can be used to construct a solution to the task. In an 𝐼𝐿𝑃 𝑐𝑜𝑛𝑡𝑒𝑥𝑡
without noise, all examples have ∞ penalty and a solution is an ASP program 𝐻 ⊆ 𝑆𝑀 such
that 𝐻 ∪ 𝐵 accepts each example 𝑒 ∈ 𝐸. In a noisy 𝐼𝐿𝑃 𝑐𝑜𝑛𝑡𝑒𝑥𝑡
task, examples have positive
integer penalties and solutions do not need to accept every example, but they incur a penalty
for each example not accepted. Therefore, an optimal solution of a noisy 𝐼𝐿𝑃 𝑐𝑜𝑛𝑡𝑒𝑥𝑡
task is
an ASP program 𝐻 ⊆ 𝑆𝑀 that has the lowest cost, i.e., a short hypothesis that also minimises
the total penalty of examples not accepted by 𝐻. In this paper, 𝐼𝐿𝑃 𝑐𝑜𝑛𝑡𝑒𝑥𝑡
tasks will be noisy
tasks, and we will refer to WCDPI examples as simply ILP examples.

𝐿𝐴𝑆

𝐿𝐴𝑆

𝐿𝐴𝑆

𝐿𝐴𝑆

1https://en.wikipedia.org/wiki/Trick-taking_game
2For a detailed definition of a language bias see [6].
3We assume 𝐸 contains only positive examples, whereas the LAS framework also supports negative examples.

Figure 1.: FF-NSL architecture with an example Follow Suit winner task.

3. FF-NSL Framework

𝐿𝐴𝑆

FF-NSL integrates a pre-trained NN with an ILP system for solving LAS tasks from unstructured
input data. The neural component extracts symbolic facts from unstructured input data and
together with the labels of the input data, these facts are used to automatically generate ILP
examples. Alongside prior background knowledge (if any) and a hypothesis space, the ILP
task. The trained FF-NSL architecture can
component solves the corresponding 𝐼𝐿𝑃 𝑐𝑜𝑛𝑡𝑒𝑥𝑡
then be used to predict a label from unseen unstructured input data. An overview of the FF-NSL
architecture is presented in Figure 1. The novel component is the Example Generator that
bridges the neural and symbolic learning components. Informally, the symbolic facts predicted
by a NN form the context 𝑒𝑐𝑡𝑥 of an example 𝑒, the label determines the partial interpretation
𝑒𝑝𝑖 of 𝑒, and the NN confidence scores over the predicted symbolic facts determine the penalty
𝑒𝑝𝑒𝑛 of 𝑒. Formally, let us consider a classification task where the objective is to predict a target
label 𝑦 ∈ Z from a set 𝑋 = {𝑥𝑖 ∈ R𝑑 |1 ≤ 𝑖 ≤ |𝑋|} of input unstructured data points. |𝑋|
denotes the length of 𝑋. The neural component of FF-NSL is a pre-trained NN that extracts a
discrete feature of type 𝑡, with 𝑘 possible values, from a data point 𝑥𝑖, 𝑓𝑡 : R𝑑 −→ [0, 1]𝑘. For
an input data point 𝑥𝑖, the NN outputs a confidence score vector 𝑓𝑡(𝑥𝑖) ∈ [0, 1]𝑘 over the 𝑘
possible feature values. The Example Generator considers from each input data point 𝑥𝑖 ∈ 𝑋
the value 𝑠𝑖 that corresponds to the NN prediction with maximum confidence score, i.e., 𝑠𝑖 =
𝑎𝑟𝑔𝑚𝑎𝑥𝑗∈{1,𝑘} (𝑓𝑡(𝑥𝑖)[𝑗]) and constructs the example 𝑒⟨𝑋,𝑦⟩ = ⟨𝑒𝑖𝑑, 𝑒𝑝𝑒𝑛(𝑋), 𝑒𝑝𝑖(𝑦), 𝑒𝑐𝑡𝑥(𝑋)⟩,
as follows. Note the arguments 𝑋 and 𝑦 in the tuple elements indicate the dependency on the
input 𝑋 and label 𝑦.

For a given classification task, the Example Gener-
Generating the context of an example.
ator has a lookup table 𝑙, associated to the feature 𝑡, that maps each of the 𝑠𝑖 NN predictions into
(a set of) ground logical facts 𝑙𝑡(𝑠𝑖) = {𝑓 𝑎𝑐𝑡𝑖}. For example, for the Follow Suit winner task, the
feature 𝑡 is the type of playing card from a deck of 52 cards and each prediction 𝑠𝑖 corresponds
to a specific card (e.g., King of spades). Each unstructured data point 𝑥𝑖 ∈ 𝑋 is an image of
the card played by player 𝑖 ∈ [1..4]. Let’s assume that for input data point 𝑥1 the NN predicts
𝑠1 to be a King of spades. The lookup table will generate the entry 𝑙𝑡(𝑠1) = {𝑐𝑎𝑟𝑑(1, 𝑘, 𝑠).}.
Hence, given unstructured input data 𝑋, the generated example 𝑒⟨𝑋,𝑦⟩ will have as context
𝑒𝑐𝑡𝑥(𝑋) = ⋀︀
1≤𝑖≤|𝑋| 𝑙𝑡(𝑠𝑖). Note that the structure of the lookup table is task specific. Differ-
ent symbolic representations of the NN predictions could be used, but the FF-NSL framework
assumes it to be given as part of the classification task.

Calculating the penalty of an example. The Example Generator defines the penalty of
an example 𝑒 to be the level of “certainty” of the context 𝑒𝑐𝑡𝑥(𝑋), which is informed by the
confidence score of the NN predictions. Given an unstructured input data 𝑋, the confidence
value of the associated NN prediction 𝑠𝑖 is given by 𝑐𝑖 = 𝑚𝑎𝑥(𝑓𝑡(𝑥𝑖)), for 1 ≤ 𝑖 ≤ |𝑋|. The
Example Generator aggregates these individual confidence values to form the penalty 𝑒𝑝𝑒𝑛(𝑋)
for the example 𝑒 generated from the input data 𝑋. We use as an aggregated confidence score
the minimum of the NN confidence values of 𝑥𝑖 ∈ 𝑋. This is a generalisation of the binary
Gödel t-norm used in fuzzy logic to encode fuzzy conjunctions [11]. Experimental evaluation
has also shown that for the penalties to have effect they have to be sparse. Hence, the Example
Generator defines the penalty of an ILP example as follows, where 𝜆 > 1 is a fixed constant4:

𝑒𝑝𝑒𝑛(𝑋) = ⌊𝜆 × 𝑚𝑖𝑛 ({𝑐𝑖 | 1 ≤ 𝑖 ≤ |𝑋|})⌋

(1)

FF-NSL learning task. Let 𝑋 be a set of unstructured input data with label 𝑦, from a set of
target labels 𝑌 . The Example Generator generates an example 𝑒⟨𝑋,𝑦⟩ = ⟨𝑒𝑖𝑑, 𝑒𝑝𝑒𝑛(𝑋), 𝑒𝑝𝑖(𝑦),
𝑒𝑐𝑡𝑥(𝑋)⟩ where 𝑒𝑖𝑑 is a unique example identifier, 𝑒𝑝𝑒𝑛(𝑋) is the example penalty generated
from 𝑋 as defined in equation 1, 𝑒𝑝𝑖(𝑦) is the partial interpretation ⟨{𝑦}, 𝑌 ∖{𝑦}⟩ and the context
𝑒𝑐𝑡𝑥(𝑋) = ⋀︀
1≤𝑖≤|𝑋| 𝑙𝑡(𝑠𝑖) is generated from the NN predictions 𝑠𝑖 from each input data point
𝑥𝑖 ∈ 𝑋. Given a set 𝐷 of labelled unstructured input data, consisting of ⟨𝑋, 𝑦⟩ pairs, FF-NSL
solves the learning task 𝑇 = ⟨𝐵, 𝑆𝑀 , 𝐷⟩, where 𝐵 is optional background knowledge and
𝑆𝑀 is a mode bias, given as input. An optimal solution for this task 𝑇 is an ASP program
task 𝑇𝐿𝐴𝑆 = ⟨𝐵, 𝑆𝑀 , 𝐸⟩
𝐻 ⊆ 𝑆𝑀 that is an optimal solution for the generated 𝐼𝐿𝑃 𝑐𝑜𝑛𝑡𝑒𝑥𝑡
where 𝐸 = {𝑒⟨𝑋,𝑦⟩ | ⟨𝑋, 𝑦⟩ ∈ 𝐷}.

𝐿𝐴𝑆

4. Evaluation

Our evaluation targets the robustness of FF-NSL to distributional shifts observed in unstructured
input data, as FF-NSL requires a pre-trained NN which may predict incorrectly for data outside
the training distribution. For baselines, we combined the same pre-trained NN used in FF-NSL
with two classifiers respectively: (1) Random Forest (RF), which is commonly used to learn rules,
trains quickly and is somewhat interpretable; (2) Deep Fully Connected Network (FCN) (with a
surrogate decision tree applied for rule extraction [12]), to evaluate a deeper architecture. For
more details on the baselines, see Appendix F. Firstly, using a structured test set, we evaluated the
accuracy and interpretability of the hypotheses learned by FF-NSL (and the models learned by
the baselines) when an increasing percentage of training examples were subject to distributional
shift. We show that FF-NSL outperformed both baselines. Secondly, we evaluated FF-NSL “at
run-time", where unstructured test data was subject to the same proportion of distributional
shift as observed during training. FF-NSL outperformed both baselines trained with the same
number of examples, until 80% of the unseen test data were subject to distributional shift. The
results and discussion of this second evaluation are presented in Appendix B. To analyse the
impact of incorrect NN predictions on the accuracy of learned hypotheses, we considered the
case where a pre-trained uncertainty-aware NN [13] was used instead of a conventional Softmax

4We set 𝜆 = 100 to encourage strong example coverage and sufficient differentiation in ILP example penalties.

based NN. Results show improved FF-NSL accuracy, which demonstrates the importance of
using confidence scores that better reflect the uncertainty of NN predictions, and the role that
the corresponding example penalty has on learning more accurate hypotheses. Further analysis
is discussed in Section 5. To evaluate interpretability, for the RF we extracted learned rules from
the first tree in the forest. For the FCN, we extracted rules from the surrogate decision tree.
Hypotheses with a lower number of atoms were considered to be more interpretable [14]. See
Appendix G for details.

,

Tasks. We evaluated our FF-NSL framework on two classification tasks: Follow Suit winner
and Sudoku grid validity. Due to space limitations, the task and results for Sudoku grid validity
are presented in Appendix C. The Follow Suit winner task consisted of predicting the winning
player (𝑦 ∈ [1..4]) of a trick composed of four playing cards, e.g., 𝑋 = { ,
, }, where each
card was played by a single player. The player that played the highest ranked card with the same
suit as the card played by player 1 is the winner. For each 𝑥𝑖 ∈ 𝑋, the pre-trained NN predicted
a value 𝑠𝑖 ∈ [1..52] (of the feature card), which corresponds to the rank (𝑟𝑘𝑖) and suit (𝑠𝑡𝑖) of a
playing card from a standard deck. The lookup table is defined as 𝑙𝑐𝑎𝑟𝑑(𝑠𝑖) = {𝑐𝑎𝑟𝑑(𝑖, 𝑟𝑘𝑖, 𝑠𝑡𝑖)}.
To apply distributional shifts to our training set, we substituted card images from a standard deck
with card images from an alternative deck. We have considered five alternative decks: Captain
America, Batman Joker, Adversarial standard, Adversarial Batman Joker and Adversarial Captain
America. In this section, we present results where the Captain America deck was used. Results
for the other decks are presented in Appendix D. We pre-trained a Softmax-based Convolutional
Neural Network (CNN) on card images from the standard deck. The CNN takes as input a
card image and outputs a 52 dimensional Softmax vector. For details on the accuracy of this
pre-trained CNN, see Appendix A. We used the ILASP [6] ILP system and encode, as part of
the background knowledge 𝐵, suit and rank values, the four players, and the definition of a
rank_higher predicate which compares the rank value of different player’s cards. A full task
listing is given in Appendix I. We generated 10 training datasets, 5 containing 104 examples
and 5 containing 10,400 examples. To evaluate the accuracy of the learned hypothesis we used
a separate test set of 1001 examples. Further dataset details are given in Appendix E.

Figure 2 shows six lines per graph:
Results, Follow Suit Winner Captain America Deck.
two instances of FF-NSL, one called Softmax that uses a Softmax-based pre-trained NN and
a second one called EDL-GEN that uses an uncertainty aware pre-trained NN; two instances
of the RF baseline, one trained with the same dataset size as FF-NSL and another with 100X
more data; similarly for the FCN baseline. Figure 2a shows that FF-NSL learns a more accurate
hypothesis, even when the baselines were trained with 100X more data. The hypotheses learned
by FF-NSL were significantly more interpretable (see Figure 2b). For large distributional shifts
(≥ 90%), the FCN was more interpretable only because the surrogate model gave a very small
tree that largely predicted the same class. Figure 2c shows that FF-NSL’s learning time increased
with the % of distributional shift. This is because the generated ILP examples were increasingly
incorrect. Within the two FF-NSL instances, EDL-GEN was faster than Softmax, because the
EDL-GEN NN provided better confidence scores and the ILP example weight penalties were
more accurate (see Section 5). Therefore, ILASP required fewer iterations to learn an optimal

(a) Accuracy

(b) Interpretability

(c) Learning time

Figure 2.: Learned hypothesis accuracy, interpretability and learning time when card images in an
increasing percentage of training examples are subject to distributional shift, using Captain America
card images. 𝑌 axes shows average over 5 repeats for each 𝑋% of distributional shift. Error bars indicate
standard error.

hypothesis (see Appendix I).

5. Analysis

We hypothesised that the superior performance of FF-NSL EDL-GEN is related to the proportion
of correct ILP examples generated from the pre-trained NN. A correct ILP example is an ILP
example whose generated example context (based on the NN predictions) and associated label
satisfy the ground truth hypothesis. ILP examples also have a penalty related to the confidence
scores of the NN predictions. To compare the two FF-NSL approaches, we calculated the
proportion of the total penalty over the generated ILP examples that was allocated to correct ILP
𝑒𝑝𝑒𝑛
examples. We refer to this as the correct ILP example penalty ratio, defined as
,
where 𝐸𝑐𝑜𝑟𝑟𝑒𝑐𝑡 is the set of correctly generated ILP examples and 𝐸 is the complete set of
generated ILP examples. This quantified how much bias was given to the ILP system, as a
result of the NN confidence scores. For a baseline, we also calculated the ratio assuming a
constant penalty 𝑒𝑝𝑒𝑛 = 10 for every 𝑒 ∈ 𝐸. In this case, the ratio decreased linearly as the %
of examples subject to distributional shift increased. Figures 3a and 3b show that the decrease
of the correct ILP example penalty ratio was much slower when the pre-trained NN EDL-GEN
was used. This means that with FF-NSL EDL-GEN, a significantly larger proportion of the
total example penalty was allocated to correct ILP examples, giving ILASP an improved bias.
Interestingly, penalties calculated from the Softmax NN confidence scores do not provide any
benefit over constant penalties. This is because the Softmax NN predicts with high confidence
for out-of-distribution data (see Appendix A), which results in similar behaviour to using
constant penalties.

𝑒∈𝐸𝑐𝑜𝑟𝑟𝑒𝑐𝑡
∑︀

𝑒∈𝐸 𝑒𝑝𝑒𝑛

∑︀

Figure 2a shows how the accuracy of FF-NSL EDL-GEN drops with respect to FF-NSL Softmax
when the distributional shifts were over 92%. We investigated this and generated 50 dataset
repeats for each 95-100% cases of distributional shift, instead of the 5 repeats used for all the

0102030405060708090100Training examples subject to distributional shift (%)0.40.50.60.70.80.91.0Hypothesis accuracyFF-NSL Softmax 104 examplesFF-NSL EDL-GEN 104 examplesBaseline RF 104 examplesBaseline RF 10,400 examplesBaseline FCN 104 examplesBaseline FCN 10,400 examples0102030405060708090100Training examples subject to distributional shift (%)0.30.40.50.60.70.80.91.0Learned hypothesis accuracy0102030405060708090100Training examples subject to distributional shift (%)101102103104Total number of atoms0102030405060708090100Training examples subject to distributional shift (%)101100101102103Learning time (s)other % of distributional shift, to better evaluate the statistical significance of this apparent
drop. Indeed, by doing so, we are able to show that FF-NSL EDL-GEN learned a more accurate
hypothesis up to (and excluding) 100% of distributional shift (see Figure 3c).

(a) Correct ILP example
penalty ratio, 0-100% shifts,
5 repeats

(b) Correct ILP example
penalty ratio, 95-100%
shifts, 50 repeats

(c) Accuracy, 95-100% shifts, 50

repeats

Figure 3.: The effect of NN confidence scores on the bias to the ILP system and FF-NSL accuracy. 𝑌
axes shows average over 5 repeats for each 𝑋% of distributional shift. Error bars indicate standard error.

We have also analysed the relationship between the predictive performance of each of the
pre-trained NNs, with the percentage of incorrect ILP examples generated, and finally, the
accuracy of the learned hypothesis, considering a constant ILP example penalty. This allowed us
to investigate the impact of incorrect NN predictions on the accuracy of the learned hypotheses.
We have considered in particular the case of 95% distributional shift. The results are shown
in Table 1 as means over 50 dataset repeats with best results highlighted in bold. For the
Batman Joker, Captain America and Adversarial Standard decks, the EDL-GEN NN predicted
more playing cards correctly than Softmax (2nd column), which led to a lower percentage
of incorrect ILP examples (5th column) and higher FF-NSL accuracy (6th column). For the
Adversarial Batman Joker deck, despite the Softmax NN predicting more cards correctly, the
predictions from EDL-GEN led to a lower percentage of incorrect ILP examples and therefore
improved FF-NSL EDL-GEN accuracy. This is evident by the distribution of the predicted rank
value between the Softmax NN and the EDL-GEN NN shown in Figure 4a. The Softmax NN
predicted the same rank more often, with 72.70% of cards predicted as a King, whereas the
EDL-GEN NN had a more varied distribution of rank predictions. This explains the higher
percentage of incorrect ILP examples generated when using the Softmax NN: if most of the
rank predictions are a King, it’s unlikely that the ILP example will satisfy the ground truth
hypothesis as there won’t be a distinct player (out of the 4) with a higher ranked card than
the other players. Analysing the hypotheses learned by FF-NSL, only 50% of the hypotheses
learned by FF-NSL Softmax contained the correct rank_higher predicate, compared to 98% of
the hypotheses learned by FF-NSL EDL-GEN. This closely matches the mean accuracy of the
learned hypotheses in the 6th column of Table 1.

Similar observations can be made for the Adversarial Captain America deck. In Figure 4b,

0102030405060708090100Training examples subject to distributional shift (%)30405060708090100Correct ILP example penalty ratioFF-NSL Softmax (with NN penalties)FF-NSL EDL-GEN (with NN penalties)FF-NSL Softmax (with constant penalties)FF-NSL EDL-GEN (with constant penalties)0102030405060708090100Training examples subject to distributional shift (%)30405060708090100Correct ILP example penalty ratio9596979899100Training examples subject to distributional shift (%)35404550556065Correct ILP example penalty ratio616262636465Incorrect generated ILP examples, FF-NSL Softmax (%)596060616263Incorrect generated ILP examples, FF-NSL EDL-GEN (%)9596979899100Training examples subject to distributional shift (%)0.8250.8500.8750.9000.9250.9500.9751.000Learned hypothesis accuracyDeck

Batman Joker

Captain America

Adversarial
Standard
Adversarial
Batman Joker
Adversarial
Captain America

Mean neural
network accuracy
(card rank and suit)
Softmax: 0.2288
EDL-GEN: 0.2865
Softmax: 0.1206
EDL-GEN: 0.172
Softmax: 0.0907
EDL-GEN: 0.0932
Softmax: 0.0992
EDL-GEN: 0.0829
Softmax: 0.0764
EDL-GEN: 0.0788

Mean neural network
accuracy (card rank)

Mean neural network
accuracy (card suit)

Mean % of incorrect ILP
examples generated

Softmax: 0.3581
EDL-GEN: 0.4021
Softmax: 0.2062
EDL-GEN: 0.2663
Softmax: 0.1445
EDL-GEN: 0.1788
Softmax: 0.1567
EDL-GEN: 0.1412
Softmax: 0.1164
EDL-GEN: 0.1341

Softmax: 0.4173
EDL-GEN: 0.5903
Softmax: 0.448
EDL-GEN: 0.5156
Softmax: 0.2974
EDL-GEN: 0.300
Softmax: 0.3461
EDL-GEN: 0.3016
Softmax: 0.3827
EDL-GEN: 0.329

Softmax: 59
EDL-GEN: 53
Softmax: 61
EDL-GEN: 59
Softmax: 86
EDL-GEN: 79
Softmax: 82
EDL-GEN: 73
Softmax: 73
EDL-GEN: 75

Mean learned hypothesis
accuracy with constant
ILP example penalties
FF-NSL Softmax: 0.9328
FF-NSL EDL-GEN: 0.9899
FF-NSL Softmax: 0.9354
FF-NSL EDL-GEN: 0.9510
FF-NSL Softmax: 0.7152
FF-NSL EDL-GEN: 0.9754
FF-NSL Softmax: 0.5502
FF-NSL EDL-GEN: 0.9323
FF-NSL Softmax: 0.3154
FF-NSL EDL-GEN: 0.6949

Table 1.
The effect of NN predictions on the ILP examples generated by FF-NSL, and the resulting FF-NSL learned
hypothesis accuracy, when using constant ILP example weight penalties.

although the Softmax NN predicted the rank King for 58.39% of the cards, the distribution
of the rank prediction from the EDL-GEN NN is more uniform. Analysing the hypotheses
learned by FF-NSL, only 24% of the hypotheses learned by FF-NSL Softmax contained the
correct rank_higher predicate, compared to 70% learned by FF-NSL EDL-GEN. This explains
the performance gap between the two FF-NSL methods, shown in the 6th column of Table 1.

(a) Adversarial
Batman Joker

(b) Adversarial
Captain America

Figure 4.: Distribution of predicted playing card rank values, Follow Suit winner, Adversarial Batman
Joker and Adversarial Captain America decks.

6. Related Work and Conclusion

There are many approaches that train a NN given a fixed logic program [15, 16, 17, 18]. FF-NSL
is the opposite, we are given a pre-trained NN and subsequently learn the logic program.
In FF-NSL, the use of t-norms to perform aggregation over NN predictions is similar to Real
Logic [15, 16], although FF-NSL differs in that we calculate an example penalty to bias the
optimisation of the ILP system as opposed to computing the aggregated probability of a set of
probabilistic facts. Within probabilistic ILP and StarAI [19, 20], systems such as [21, 22, 23, 24],
are related as a hypothesis is induced based on a set of probabilistic facts. Fundamentally, these
systems adopt a different notion of uncertainty than FF-NSL and also require different types
of learning tasks. In our approach, an example is either accepted or not. In probabilistic ILP,
examples are accepted with a probability. Probabilistic ILP systems don’t have the concept of

2345678910jqkaPlaying card rank0.00.10.20.30.40.50.60.70.8DistributionSoftmaxEDL-GEN2345678910jqkaPlaying card rank0.00.10.20.30.40.50.60.70.8DistributionSoftmaxEDL-GENpositive and negative examples and it’s impossible to ensure negative examples, represented as
facts with probability 0, would not be accepted by the learned hypothesis.

In summary, this paper introduced a neural-symbolic learning framework called FF-NSL
that is robust to distributional shift over unstructured input data, outperforming random
forest and deep NN baselines. FF-NSL learns more accurate and interpretable hypotheses from
unstructured data, requiring fewer training examples. Also, the robustness of FF-NSL can be
improved using an uncertainty-aware NN, due to a higher percentage of correct ILP examples,
more informative ILP example penalties and an improved bias for the ILP system.

References

[1] S. Muggleton, Inductive logic programming, New Generation Computing 8 (1991) 295–318.

doi:10.1007/BF03037089.

[2] Y. Ovadia, E. Fertig, J. Ren, Z. Nado, D. Sculley, S. Nowozin, J. V. Dillon, B. Lakshmi-
narayanan, J. Snoek, Can you trust your model’s uncertainty? evaluating predictive
uncertainty under dataset shift, in: 33rd Conference on Neural Information Processing
Systems (NeurIPS), 2019, pp. 13969–13980.

[3] M. Sensoy, L. Kaplan, M. Kandemir, Evidential deep learning to quantify classification
uncertainty, in: Advances in Neural Information Processing Systems, 2018, pp. 3179–3189.
[4] D. Amodei, C. Olah, J. Steinhardt, P. F. Christiano, J. Schulman, D. Mané, Concrete problems

in ai safety, ArXiv abs/1606.06565 (2016).

[5] L. H. Gilpin, D. Bau, B. Z. Yuan, A. Bajwa, M. Specter, L. Kagal, Explaining explanations:
in: 2018 IEEE 5th International

An overview of interpretability of machine learning,
Conference on Data Science and Advanced Analytics (DSAA), 2018, pp. 80–89.

[6] M. Law, Inductive learning of answer set programs, Ph.D. thesis, Imperial College London,

2018.

[7] M. Law, A. Russo, E. Bertino, K. Broda, J. Lobo, Fastlas: scalable inductive logic program-
ming incorporating domain-specific optimisation criteria, in: Proceedings of the AAAI
Conference on Artificial Intelligence, volume 34, 2020, pp. 2877–2885.

[8] M. Law, A. Russo, K. Broda, Logic-based learning of answer set programs, in: Reasoning
Web. Explainable Artificial Intelligence - 15th International Summer School 2019, Bolzano,
Italy, September 20-24, 2019, Tutorial Lectures, 2019, pp. 196–231.

[9] M. Law, A. Russo, K. Broda, Inductive learning of answer set programs from noisy examples,

Advances in Cognitive Systems (2018).

[10] M. Gelfond, Y. Kahl, Knowledge Representation, Reasoning, and the Design of Intelligent
Agents: The Answer-Set Programming Approach, Cambridge University Press, 2014.
doi:10.1017/CBO9781139342124.

[11] G. Metcalfe, N. Olivetti, D. M. Gabbay, Proof theory for fuzzy logics, volume 36, Springer

Science & Business Media, 2008.

[12] C. Molnar, Interpretable Machine Learning, Lulu.com, 2020.
[13] M. Sensoy, L. Kaplan, F. Cerutti, M. Saleki, Uncertainty-aware deep classifiers using
generative models, in: Proceedings of the AAAI Conference on Artificial Intelligence,
volume 34, 2020, pp. 5620–5627.

[14] H. Lakkaraju, S. H. Bach, J. Leskovec,

Interpretable decision sets: A joint framework
for description and prediction, in: Proceedings of the 22nd ACM SIGKDD international
conference on knowledge discovery and data mining, 2016, pp. 1675–1684.

[15] L. Serafini, A. d. Garcez, Logic tensor networks: Deep learning and logical reasoning from

data and knowledge, arXiv preprint arXiv:1606.04422 (2016).

[16] I. Donadello, L. Serafini, A. D. Garcez, Logic tensor networks for semantic image interpre-

tation, arXiv preprint arXiv:1705.08968 (2017).

[17] R. Manhaeve, S. Dumancic, A. Kimmig, T. Demeester, L. De Raedt, Deepproblog: Neural
probabilistic logic programming, in: Advances in Neural Information Processing Systems,
2018, pp. 3749–3759.

[18] Z. Yang, A. Ishay, J. Lee, Neurasp: Embracing neural networks into answer set program-
ming, in: C. Bessiere (Ed.), Proceedings of the Twenty-Ninth International Joint Conference
on Artificial Intelligence, IJCAI-20, International Joint Conferences on Artificial Intelli-
gence Organization, 2020, pp. 1755–1762. URL: https://doi.org/10.24963/ijcai.2020/243.
doi:10.24963/ijcai.2020/243.

[19] L. De Raedt, K. Kersting, Probabilistic inductive logic programming,

in: Probabilistic

Inductive Logic Programming, Springer, 2008, pp. 1–27.

[20] L. D. Raedt, K. Kersting, S. Natarajan, D. Poole, Statistical relational artificial intelligence:
Logic, probability, and computation, Synthesis Lectures on Artificial Intelligence and
Machine Learning 10 (2016) 1–189.

[21] L. De Raedt, A. Dries, I. Thon, G. Van den Broeck, M. Verbeke, Inducing probabilistic
relational rules from probabilistic examples, in: Proceedings of 24th International Joint
Conference on Artificial Intelligence (IJCAI), volume 2015-January, Yang, Q, IJCAI-INT
JOINT CONF ARTIF INTELL, 2015, pp. 1835–1842.

[22] E. Bellodi, F. Riguzzi, Structure learning of probabilistic logic programs by searching
the clause space, Theory and Practice of Logic Programming 15 (2013). doi:10.1017/
S1471068413000689.

[23] D. Tuckey, K. Broda, A. Russo, Towards structure learning under the credal semantics,

The 7th Workshop on Probabilistic Logic Programming, ICLP (2020).

[24] M. Richardson, P. Domingos, Markov logic networks, Machine learning 62 (2006) 107–136.
[25] L. De Raedt, A. Kimmig, H. Toivonen, Problog: A probabilistic prolog and its application
in link discovery, in: International Joint Conferences on Artificial Intelligence (IJCAI),
2007, pp. 2462–2467.

[26] Y. LeCun, L. Bottou, Y. Bengio, P. Haffner, Gradient-based learning applied to document

recognition, Proceedings of the IEEE 86 (1998) 2278–2324.

[27] I. Stahl, Predicate invention in ilp—an overview, in: European Conference on Machine

Learning, Springer, 1993, pp. 311–322.

Acknowledgments

This research was sponsored by the U.S. Army Research Laboratory and the U.K. Ministry of
Defence under Agreement Number W911NF-16-3-0001. The views and conclusions contained in
this document are those of the authors and should not be interpreted as representing the official

policies, either expressed or implied, of the U.S. Army Research Laboratory, the U.S. Government,
the U.K. Ministry of Defence or the U.K. Government. The U.S. and U.K. Governments are
authorized to reproduce and distribute reprints for Government purposes notwithstanding any
copyright notation hereon.

A. Follow Suit winner NN Details

Firstly, we trained a Softmax-based CNN with 4 2D convolutional layers and 2 fully connected
layers for 20 epochs in PyTorch. The network accepts 3-channel RGB input with images of
size 274x174 pixels and outputs a 52 dimensional softmax vector to predict each playing card.
When this NN was used within FF-NSL we use the term FF-NSL Softmax. Secondly, we trained
an uncertainty-aware NN based on evidential deep learning [13], modifying 𝑘, the number of
outputs to 52 and the layer dimensions to accept 274x174 RGB card images. We also trained
this NN for 20 epochs, and when used within FF-NSL we use the term FF-NSL EDL-GEN.

Figure 5.: Neural network performance under distributional shifts, Follow Suit Winner.

We trained both NNs on standard playing card images. Figure 5 presents the test set accuracy
and confidence score distribution of the trained NNs on six playing card test datasets; Standard,
Batman Joker, Captain America, Adversarial Standard, Adversarial Batman Joker and Adversarial
Captain America representing distributional shifts. The Softmax NN predicted with high confi-
dence for data subject to a distributional shift, despite low test accuracy. For example, when
trained with standard playing card images, 94% of predictions were made with confidence in the
interval [0.96, 1] for playing card images in the Captain America test set, despite an accuracy
of 0.0657. With an EDL-GEN NN, only 9% of predictions were made with confidence in the
interval [0.96, 1], showing the confidence scores of predictions made by the EDL-GEN NN were
better calibrated with its predictive accuracy of 0.1193. For further dataset details, please refer
to Appendix E.

B. Run-time results, Follow Suit Winner, Captain America Deck

We evaluated FF-NSL at run-time where unseen unstructured data was observed that was subject
to a similar proportion of distributional shift that was observed during training. In this case,

Softmax | Standard | 0.9996Softmax | Batman Joker | 0.1835Softmax | Captain America | 0.0657Softmax | Adversarial Standard | 0.0344Softmax | Adversarial Batman Joker | 0.0437Softmax | Adversarial Captain America | 0.021EDL-GEN | Standard | 0.9969EDL-GEN | Batman Joker | 0.2478EDL-GEN | Captain America | 0.1193EDL-GEN | Adversarial Standard | 0.0379EDL-GEN | Adversarial Batman Joker | 0.0287EDL-GEN | Adversarial Captain America | 0.0231Confidence Score Distribution (%)Network | Dataset | Test AccuracyConfidence Score Value89797272415714116787912111115456688111116234764111110122439950949595953749432140 - 0.250.26 - 0.50.51 - 0.750.76 - 0.90.91 - 0.950.96 - 1the NNs were required to make a prediction for each player’s card image and the predictions
together with the learned rules were used to make a final classification. ProbLog [25], in sampling
mode, was used to integrate the learned hypothesis with NN predictions to make the final
prediction, where NN predictions were represented as annotated disjunctions, with probabilities
set according to the confidence of NN predictions. The final prediction was probabilistic, with
the probabilities for each player winning summing to 1. We assumed the final prediction as
the class with the maximum probability assigned. Our evaluation considered accuracy on the
unstructured test data and also the Brier score, a scoring function designed to measure the
accuracy of probabilistic predictions.

(a) Accuracy

(b) Brier Score

Figure 6.: Run-time performance, Follow Suit winner, Captain America deck

The results are presented in Figure 6. FF-NSL outperformed baselines trained with the same
number of examples and performed similarly to baselines trained with 100X the number of
examples, in terms of accuracy (Figure 6a), until 90% of the test examples were subject to
distributional shift. Note that FF-NSL achieved this run-time performance whilst learning more
accurate hypotheses than baseline approaches (Figure 2a). Finally, FF-NSL achieved a lower
Brier score than baseline approaches trained with the same number of examples until 70%
of test examples were subject to distributional shift and the Brier score of FF-NSL EDL-GEN
improved as the percentage of test examples subject to distributional shift increased. This is
because the EDL-GEN NN was able to better express predictive uncertainty when data subject to
distributional shift was observed, and therefore the final class probability predicted by ProbLog
improved.

0102030405060708090100Training examples subject to distributional shift (%)0.40.50.60.70.80.91.0Hypothesis accuracyFF-NSL Softmax 104 examplesFF-NSL EDL-GEN 104 examplesBaseline RF 104 examplesBaseline RF 10,400 examplesBaseline FCN 104 examplesBaseline FCN 10,400 examples0102030405060708090100Training and test examples subject to distributional shift (%)0.30.40.50.60.70.80.91.0Unstructured test set accuracy0102030405060708090100Training and test examples subject to distributional shift (%)0.00.20.40.60.81.0Unstructured test data Brier scoreC. Sudoku Grid Validity Task and Results

This section presents results for 4x4 and 9x9 Sudoku grids. Let us first introduce the task. The ob-
jective is to predict if a Sudoku grid 𝑋, represented by a sequence 𝑋 = { ,
, ...}
of images of digits at different cells in the grid,5 is valid or invalid (𝑌 = {𝑣𝑎𝑙𝑖𝑑, 𝑖𝑛𝑣𝑎𝑙𝑖𝑑}). A
NN pre-trained on MNIST digits is used to extract from each 𝑥𝑖 ∈ 𝑋, the feature digit with
predicted value 𝑠𝑖 ∈ [1..4] for 4x4 grids and 𝑠𝑖 ∈ [1..9] for 9x9 grids. For this task, each input
data point 𝑥𝑖 is a digit at row 𝑟𝑜𝑤𝑖 and column 𝑐𝑜𝑙𝑖 of the grid. The lookup table is defined as
𝑙𝑑𝑖𝑔𝑖𝑡(𝑠𝑖) = {𝑑𝑖𝑔𝑖𝑡(𝑟𝑜𝑤𝑖, 𝑐𝑜𝑙𝑖, 𝑠𝑖)}.

,

,

,

,

C.1. Neural Networks

We trained two types of NNs. Firstly, we adopted the CNN architecture available in the MNIST
PyTorch tutorial6 and replaced the LogSoftmax layer with a Softmax layer and the Negative Log
Likelihood loss function with Cross-Entropy Loss. This is to satisfy the NN definition in Section 3
such that a confidence score 𝑐 ∈ [0, 1]𝑘 is returned for 𝑘 possible feature values. For the two
grid sizes, 4x4 and 9x9, we train two separate networks. For 4x4 grids, we set 𝑘 = 4 and train
on digits 1-4 inclusive, whilst for 9x9 grids we set 𝑘 = 9 and train on digits 1-9 inclusive. We
adopted all existing hyper-parameter values and trained for 20 epochs. When these NNs were
used within FF-NSL we use the term FF-NSL Softmax.

Secondly, we trained two state-of-the-art uncertainty-aware NNs based on evidential deep
learning [13] which improved the calibration of NN confidence predictions under distributional
shift. We used the available implementation in TensorFlow,7 and set 𝑘, the number of outputs, to
4 and 9, for 4x4 and 9x9 grids respectively. We used existing hyper-parameter values and trained
for 20 epochs. When these NNs were used within FF-NSL we use the term FF-NSL EDL-GEN.
We trained all NNs on standard images from the MNIST training set. Figure 7 presents the test
set accuracy and confidence score distribution of the trained NNs on two test datasets; standard
MNIST test digits and MNIST test digits rotated 90∘ clockwise, representing a distributional
shift. The Softmax NN predicted with high confidence for data subject to a distributional shift,
despite low test set accuracy. For example, in Figure 7b, when trained with standard images of
MNIST digits 1-9, 55% of predictions were made with confidence in the interval [0.96, 1] for
the rotated MNIST test set, despite an accuracy of 0.109. With an EDL-GEN NN, only 3% of
predictions were made with confidence in the interval [0.96, 1], showing the confidence scores
of predictions made by the EDL-GEN NN were better calibrated with its predictive accuracy.

C.2. ILP Configuration: Background Knowledge and Mode Declarations

For the Sudoku task, we used the FastLAS [7] ILP system as FastLAS scales to large hypothesis
spaces. For both 4x4 and 9x9 Sudoku grids, knowledge of the grid was encoded within the
learning task presented to the ILP system. Sudoku grid cells, denoted by row and column
coordinates were mapped to column, row and block identifiers. In ASP this was specified

5We assume that a Sudoku grid has been pre-processed to return images of digits in different cells.
6https://github.com/pytorch/examples/tree/master/mnist
7https://muratsensoy.github.io/gen.html

(a) 4x4 Sudoku grid validity NNs
trained with MNIST Digits 1-4 inclusive.

(b) 9x9 Sudoku grid validity NNs
trained with MNIST Digits 1-9 inclusive.

Figure 7.: NN performance under distributional shifts, Sudoku grid validity

as col(“r, c′′, id), row(“r, c′′, id) and block(“r, c′′, id) where r and c represent row and
column coordinates, and id represents the identifier of the column, row, or block. Finally, a
predicate called neq was defined to encode “not equal to" for cell identifiers.

For mode declarations, which specify the hypothesis space for the ILP system, digit, col,
row, block, and neq predicates were added to the set of possible body predicates alongside
negation as failure for the column, row and block predicates, i.e., not col, not row, and not
block. The fact invalid was added to the set of possible head atoms. The subset of the
hypothesis space computed by FastLAS contained 2350 possible rules. An example listing of a
Sudoku grid validity ILP task is presented in Appendix H.

For 4x4 Sudoku grids, we created an additional, more challenging learning task with a reduced
set of background knowledge, where the col, row and block predicates were replaced with a
division predicate that enables column, row and block identifiers to be learned, based on the
cell coordinates given in the example contexts. For 9x9 grids, we also create an additional learn-
ing task for the best performing baseline approach, where NN predictions are post-processed to
create 3 Boolean input features, denoting if digits are in the same row, column or block. This
effectively encodes the grid background knowledge into the learning task and goes beyond the
background knowledge given to FF-NSL. We demonstrate that FF-NSL performs similarly to
the best performing baseline in this case.

C.3. Baselines

For all baseline approaches, we used the same pre-trained Softmax NN as used in FF-NSL
Softmax, and evaluated two alternative rule learning approaches: (1) Random Forest (RF) which
is commonly used to perform classification tasks, trains quickly and is somewhat interpretable.
(2) CNN-LSTM to evaluate a deep architecture designed for sequence classification problems
where the CNN component can learn spatial dependencies in the Sudoku grid. For both the RF

Softmax | Standard | 0.999Softmax | Rotated | 0.140EDL-GEN | Standard | 0.997EDL-GEN | Rotated | 0.170Confidence Score Distribution (%)Network | Dataset | Test AccuracyConfidence Score Value2681971558997697300 - 0.250.26 - 0.50.51 - 0.750.76 - 0.90.91 - 0.950.96 - 1Softmax | Standard | 0.991Softmax | Rotated | 0.109EDL-GEN | Standard | 0.990EDL-GEN | Rotated | 0.146Confidence Score Distribution (%)Network | Dataset | Test AccuracyConfidence Score Value143323018213144684298558530 - 0.250.26 - 0.50.51 - 0.750.76 - 0.90.91 - 0.950.96 - 1and CNN-LSTM, the training data consists of sequences of 16 digits (4x4 grids) and 81 digits
(9x9 grids), where 0 was used to represent an empty cell and the digit values in the Sudoku grid
were predicted by the FF-NSL Softmax NNs. Each sequence was labelled with the validity of the
Sudoku grid. Finally, all architecture and hyper-parameter details for the baseline approaches
are presented in Appendix F.

C.4. Sudoku Grid Datasets

For each task, 10 training datasets were generated; 5 small and 5 large, each containing 320
examples and 32,000 examples respectively. Each dataset contained an equal distribution of valid
and invalid examples, and the invalid examples contained an equal distribution of examples
containing two of the same digit in a row, column or block. FF-NSL was trained using small
datasets and the baselines were trained with both small and large datasets. Also, two test sets
were created with an additional 1000 examples, called the structured test set and the unstructured
test set. The examples in the test sets were identical, except the structured test set contained
structured data (e.g., digit values in the Sudoku grid) and the unstructured test set contained
unstructured data (e.g., images of digits in the Sudoku grid). The structured test set was used to
evaluate the accuracy of the hypothesis learned by FF-NSL, or the accuracy of the model learned
using the baseline approaches. It assumes perfect predictions by the NNs and therefore the
evaluation on this dataset targets the ability of the rule learning system to handle distributional
shift present during training. The unstructured test set was used for run-time evaluation, where
the NNs were required to make a prediction for digit images, which were subject to a similar
proportion of distributional shift as observed during training. Let us now present the results for
4x4 Sudoku grids.

C.5. 4x4 Sudoku Grid Results

(a) Learned hypothesis

accuracy

(b) Interpretability

(c) Learning time

Figure 8.: Robustness to distributional shifts during learning, and the effect of background knowledge,
4x4 Sudoku grid validity.

Figure 8a shows the mean learned hypothesis accuracy on the structured test set over 5
repeats, where training examples were subject to an increasing percentage of distributional

0102030405060708090100Training examples subject to distributional shift (%)0.50.60.70.80.91.0Learned hypothesis accuracyFF-NSL Softmax 320 examplesFF-NSL EDL-GEN 320 examplesFF-NSL Reduced Background Knowledge 320 examplesRF 320 examplesRF 32,000 examplesCNN-LSTM 320 examplesCNN-LSTM 32,000 examples0102030405060708090100Training examples subject to distributional shift (%)0.50.60.70.80.91.0Learned hypothesis accuracy0102030405060708090100Training examples subject to distributional shift (%)101102103104105Total number of atoms0102030405060708090100Training examples subject to distributional shift (%)100101102Learning time (s)shift. Results for both FF-NSL Softmax and FF-NSL EDL-GEN are shown, as well as FF-NSL
with reduced background knowledge, where the explicit knowledge of the Sudoku grid was
removed. In this case, the EDL-GEN NN was used. FF-NSL outperformed the baselines until 90%
of training examples were subject to distributional shift, even when the baselines were trained
with 100X the number of examples and the background knowledge was reduced. FF-NSL with
reduced background knowledge outperforms FF-NSL with knowledge of the Sudoku grid at
90% and 100% shifts because the ILP system has more flexibility in the hypothesis space. With
the grid knowledge, the hypothesis space contains rules that will perform either very well or
very poorly, as the task is constrained by the grid.

To evaluate interpretability, we assumed a hypothesis was more interpretable if it contained
a lower number of atoms [14]. For the baseline RF, we obtained the learned hypothesis by
inspecting the first tree in the forest and following the tree from the root down to each leaf. For
the CNN-LSTM, we assumed the learned model was a black-box and applied a surrogate decision
tree model to approximate model predictions [12]. We then obtained the learned hypothesis by
following the decision tree from the root down to each leaf. Figure 8b shows hypotheses learned
by FF-NSL were significantly more interpretable. Finally, the learning time of FF-NSL with grid
background knowledge was within the same order of magnitude as training the CNN-LSTM
with 100X the number of examples (Figure 8c). Note also that the learning time for FF-NSL in
this task is relatively constant (compared to Follow Suit), demonstrating FastLAS’ scalability to
large hypothesis spaces. Error bars in all Figures indicate standard error across the 5 dataset
repeats.

Given FF-NSL’s superior performance, we investigated why the framework is robust to
distributional shift and specifically, the effect of using an uncertainty-aware NN and calculating
the ILP example penalty from NN confidence scores. This follows the same methodology as
presented in Section 3 for the Follow Suit winner task. In this analysis, we also focused on
high percentages of distributional shift, {80, 90, 95, 96}%, and generated 50 datasets to ensure
statistically significant results. Figure 9 presents the results for 4x4 Sudoku grids. Figures 9a
and 9b demonstrate that calculating the ILP example weight penalty based on NN predictions
resulted in an improved bias for the ILP system, as a larger proportion of the total example
weight penalty was allocated to correct ILP examples. Furthermore, the EDL-GEN NN leads to
an improvement over Softmax, as EDL-GEN was able to better estimate its predictive confidence.
The Softmax NN outperforms EDL-GEN with constant penalties because there was a greater
proportion of incorrect ILP examples generated with EDL-GEN. This is shown with the 2nd
and 3rd x-axes in Figure 9b. Finally, despite EDL-GEN predicting digits with slightly lower
accuracy than Softmax, the calculated weight penalties when using the NN confidence predicted
by EDL-GEN created an improved bias for the ILP system and therefore outperforms Softmax,
and constant penalties, in terms of learned hypothesis accuracy for FF-NSL (Figure 9c). Error
bars indicate standard error across dataset repeats.

Finally, we evaluated FF-NSL at run-time where unseen unstructured data was observed that
was subject to a similar proportion of distributional shift that was observed during training.
In this case, NNs were required to make a prediction for each digit image in a Sudoku grid
and the predictions together with the learned rules were used to make a final classification.
As in the Follow Suit experiments, ProbLog [25], in sampling mode, was used to integrate the
learned hypothesis with NN predictions to make the final prediction, where NN predictions

(a) Correct ILP example penalty
ratio, 0-100% shifts, 5 repeats

(b) Correct ILP example penalty
ratio, 80-96% shifts, 50 repeats

(c) Learned hypothesis accuracy,

80-96% shifts, 50 repeats

Figure 9.: The effect of using an uncertainty-aware NN based on evidential deep learning, 4x4 Sudoku
grid validity

were represented as annotated disjunctions, with probabilities set according to the confidence
of NN predictions. The final prediction was probabilistic, with the probabilities for a valid
and invalid Sudoku grid summing to 1. We assumed the final prediction as the class with the
maximum probability assigned. Our evaluation considered accuracy on the unstructured test
data and also the Brier score. The results are shown in Figure 10. FF-NSL outperformed baselines
trained with the same number of examples and performed similarly to baselines trained with
100X the number of examples, in terms of accuracy (Figure 10a), until 80% of the test examples
were subject to distributional shift. Note that FF-NSL achieved this run-time performance
whilst learning more accurate hypotheses than baseline approaches (Figure 8a). Finally, FF-NSL
achieved a lower Brier score than baseline approaches trained with the same number of examples
until 60% of test examples were subject to distributional shift and the Brier score of FF-NSL
EDL-GEN improved as the percentage of test examples subject to distributional shift increased.
This is because the EDL-GEN NN was able to better express predictive uncertainty when data
subject to distributional shift was observed, and therefore the final class probability predicted
by ProbLog improved.

C.6. 9x9 Sudoku Grid Results

Let us now present the results for 9x9 Sudoku grids. We follow the same format and methodology
as presented for the 4x4 Sudoku grids.

Figure 11 demonstrates FF-NSL’s robustness to distributional shift during learning. FF-NSL
outperformed the baseline approaches, even when the baselines were trained with 100X the
number of examples (Figure 11a). The RF trained with extra background knowledge performed
similarly to FF-NSL. This learning task post-processed NN predictions to create 3 Boolean input
features, denoting if digits were in the same row, column or block. This effectively encoded
knowledge of the Sudoku grid into the learning task and goes beyond the background knowledge

0102030405060708090100Training examples subject to distributional shift (%)60708090100Correct ILP example penalty ratioFF-NSL Softmax (with NN penalties)FF-NSL EDL-GEN (with NN penalties)FF-NSL Softmax (with constant penalties)FF-NSL EDL-GEN (with constant penalties)0102030405060708090100Training examples subject to distributional shift (%)60708090100Correct ILP example penalty ratio8085909596Training examples subject to distributional shift (%)5860626466687072Correct ILP example penalty ratio3234363839Incorrect generated ILP examples, FF-NSL Softmax (%)3436384141Incorrect generated ILP examples, FF-NSL EDL-GEN (%)8085909596Training examples subject to distributional shift (%)0.50.60.70.80.91.0Learned hypothesis accuracyFigure 10.: Run-time performance, 4x4 Sudoku grid validity

(a) Accuracy

(b) Brier Score

given to FF-NSL, it was a significantly easier task. Hypotheses learned by FF-NSL were more
interpretable, as the rules within the hypothesis contained a significantly lower number of
atoms (Figure 11b). Finally, for 9x9 grids, the learning time of FF-NSL was larger than the
baselines (Figure 11c). Error bars in all Figures indicate standard error across the 5 dataset
repeats.

(a) Learned hypothesis

accuracy

(b) Interpretability

(c) Learning time

Figure 11.: Robustness to distributional shifts during learning, and the effect of background knowledge,
9x9 Sudoku grid validity.

Figures 12a and 12b demonstrate that calculating the ILP example weight penalty based
on NN predictions resulted in an improved bias for the ILP system, as a larger proportion of the
total example weight penalty was allocated to correct ILP examples. Figure 12c demonstrates
the effect of this bias in terms of learned hypothesis accuracy (Figure 9c), where improved
performance was achieved. Error bars indicate standard error across dataset repeats.

Evaluating the FF-NSL framework at run-time on an unseen test set containing unstructured
data, FF-NSL outperformed baselines except the RF with extra knowledge, in terms of accuracy.
This is shown in Figure 13a. Note that FF-NSL achieved this run-time performance whilst
learning more accurate hypotheses than baseline approaches (Figure 11a). Finally, FF-NSL

0102030405060708090100Training examples subject to distributional shift (%)0.50.60.70.80.91.0Learned hypothesis accuracyFF-NSL Softmax 320 examplesFF-NSL EDL-GEN 320 examplesFF-NSL Reduced Background Knowledge 320 examplesRF 320 examplesRF 32,000 examplesCNN-LSTM 320 examplesCNN-LSTM 32,000 examples0102030405060708090100Training and test examples subject to distributional shift (%)0.50.60.70.80.91.0Unstructured test set accuracy0102030405060708090100Training and test examples subject to distributional shift (%)0.00.20.40.60.81.0Unstructured test set Brier score0102030405060708090100Training examples subject to distributional shift (%)0.50.60.70.80.91.0Learned hypothesis accuracyNSL Softmax 320 examplesNSL EDL-GEN 320 examplesBaseline RF 320 examplesBaseline RF 32,000 examplesBaseline RF (with knowledge) 320 examplesBaseline CNN-LSTM 320 examplesBaseline CNN-LSTM 32,000 examples0102030405060708090100Training examples subject to distributional shift (%)0.50.60.70.80.91.0Learned hypothesis accuracy0102030405060708090100Training examples subject to distributional shift (%)100101102103104105Total number of atoms0102030405060708090100Training examples subject to distributional shift (%)100101102Learning time (s)(a) Correct ILP example penalty
ratio, 0-100% shifts, 5 repeats

(b) Correct ILP example penalty
ratio, 80-96% shifts, 50 repeats

(c) Learned hypothesis accuracy,

80-96% shifts, 50 repeats

Figure 12.: The effect of using an uncertainty-aware NN based on evidential deep learning, 9x9 Sudoku
grid validity.

achieved a lower Brier score than baseline approaches trained with the same number of examples
until 40% of test examples were subject to distributional shift (with the exception of the RF with
extra knowledge) and the Brier score of FF-NSL EDL-GEN improved as the percentage of test
examples subject to distributional shift increased. This is because the EDL-GEN NN was able to
better express predictive uncertainty when data subject to distributional shift was observed,
and therefore the final class probability predicted by ProbLog improved.

Figure 13.: Run-time performance, 9x9 Sudoku grid validity

(a) Accuracy

(b) Brier Score

0102030405060708090100Training examples subject to distributional shift (%)5060708090Correct ILP example penalty ratioFF-NSL Softmax (with NN penalties)FF-NSL EDL-GEN (with NN penalties)FF-NSL Softmax (with constant penalties)FF-NSL EDL-GEN (with constant penalties)0102030405060708090100Training examples subject to distributional shift (%)5060708090Correct ILP example penalty ratio9596979899100Training examples subject to distributional shift (%)50515253545556Correct ILP example penalty ratio474748484950Incorrect generated ILP examples, FF-NSL Softmax (%)474748494950Incorrect generated ILP examples, FF-NSL EDL-GEN (%)9596979899Training examples subject to distributional shift (%)0.700.750.800.850.900.95Learned hypothesis accuracy0102030405060708090100Training examples subject to distributional shift (%)0.50.60.70.80.91.0Learned hypothesis accuracyNSL Softmax 320 examplesNSL EDL-GEN 320 examplesBaseline RF 320 examplesBaseline RF 32,000 examplesBaseline RF (with knowledge) 320 examplesBaseline CNN-LSTM 320 examplesBaseline CNN-LSTM 32,000 examples0102030405060708090100Training and test examples subject to distributional shift (%)0.50.60.70.80.9Unstructured test set accuracy0102030405060708090100Training and test examples subject to distributional shift (%)0.20.40.60.81.0Unstructured test set Brier scoreD. Follow Suit Winner Additional Results

D.1. Batman Joker

(a) Learned hypothesis

accuracy

(b) Interpretability

(c) Learning time

Figure 14.: Robustness to distributional shifts during learning, Batman Joker deck.

(a) Correct ILP
example penalty
ratio, 0-100% shifts,
5 repeats

(b) Correct ILP
example penalty
ratio, 95-100%
shifts, 50 repeats

(c) Learned hypothesis
accuracy, 95-100%
shifts, 50 repeats

Figure 15.: The effect of using an uncertainty-aware neural network, Batman Joker deck.

Figure 16.: Run-time performance, Batman Joker deck.

(a) Accuracy

(b) Brier Score

0102030405060708090100Training examples subject to distributional shift (%)0.40.50.60.70.80.91.0Hypothesis accuracyFF-NSL Softmax 104 examplesFF-NSL EDL-GEN 104 examplesBaseline RF 104 examplesBaseline RF 10,400 examplesBaseline FCN 104 examplesBaseline FCN 10,400 examples0102030405060708090100Training examples subject to distributional shift (%)0.40.50.60.70.80.91.0Learned hypothesis accuracy0102030405060708090100Training examples subject to distributional shift (%)101102103104105Total number of atoms0102030405060708090100Training examples subject to distributional shift (%)101100101102103Learning time (s)0102030405060708090100Training examples subject to distributional shift (%)30405060708090100Correct ILP example penalty ratioFF-NSL Softmax (with NN penalties)FF-NSL EDL-GEN (with NN penalties)FF-NSL Softmax (with constant penalties)FF-NSL EDL-GEN (with constant penalties)0102030405060708090100Training examples subject to distributional shift (%)30405060708090100Correct ILP example penalty ratio9596979899100Training examples subject to distributional shift (%)40506070Correct ILP example penalty ratio596060616263Incorrect generated ILP examples, FF-NSL Softmax (%)535354555657Incorrect generated ILP examples, FF-NSL EDL-GEN (%)9596979899100Training examples subject to distributional shift (%)0.8250.8500.8750.9000.9250.9500.9751.000Learned hypothesis accuracy0102030405060708090100Training examples subject to distributional shift (%)0.40.50.60.70.80.91.0Hypothesis accuracyFF-NSL Softmax 104 examplesFF-NSL EDL-GEN 104 examplesBaseline RF 104 examplesBaseline RF 10,400 examplesBaseline FCN 104 examplesBaseline FCN 10,400 examples0102030405060708090100Training and test examples subject to distributional shift (%)0.40.50.60.70.80.91.0Unstructured test set accuracy0102030405060708090100Training and test examples subject to distributional shift (%)0.00.20.40.60.81.0Unstructured test data Brier scoreD.2. Adversarial Standard

(a) Learned hypothesis

accuracy

(b) Interpretability

(c) Learning time

Figure 17.: Robustness to distributional shifts during learning, Adversarial Standard deck.

(a) Correct ILP
example penalty
ratio, 0-100% shifts,
5 repeats

(b) Correct ILP
example penalty
ratio, 95-100%
shifts, 50 repeats

(c) Learned hypothesis
accuracy, 95-100%
shifts, 50 repeats

Figure 18.: The effect of using an uncertainty-aware neural network, Adversarial Standard deck.

Figure 19.: Run-time performance, Adversarial Standard deck.

(a) Accuracy

(b) Brier Score

0102030405060708090100Training examples subject to distributional shift (%)0.40.50.60.70.80.91.0Hypothesis accuracyFF-NSL Softmax 104 examplesFF-NSL EDL-GEN 104 examplesBaseline RF 104 examplesBaseline RF 10,400 examplesBaseline FCN 104 examplesBaseline FCN 10,400 examples0102030405060708090100Training examples subject to distributional shift (%)0.00.20.40.60.81.0Learned hypothesis accuracy0102030405060708090100Training examples subject to distributional shift (%)101102103104Total number of atoms0102030405060708090100Training examples subject to distributional shift (%)101100101102Learning time (s)0102030405060708090100Training examples subject to distributional shift (%)30405060708090100Correct ILP example penalty ratioFF-NSL Softmax (with NN penalties)FF-NSL EDL-GEN (with NN penalties)FF-NSL Softmax (with constant penalties)FF-NSL EDL-GEN (with constant penalties)0102030405060708090100Training examples subject to distributional shift (%)20406080100Correct ILP example penalty ratio9596979899100Training examples subject to distributional shift (%)102030405060Correct ILP example penalty ratio868788899091Incorrect generated ILP examples, FF-NSL Softmax (%)798080818284Incorrect generated ILP examples, FF-NSL EDL-GEN (%)9596979899100Training examples subject to distributional shift (%)0.00.20.40.60.81.0Learned hypothesis accuracy0102030405060708090100Training examples subject to distributional shift (%)0.40.50.60.70.80.91.0Hypothesis accuracyFF-NSL Softmax 104 examplesFF-NSL EDL-GEN 104 examplesBaseline RF 104 examplesBaseline RF 10,400 examplesBaseline FCN 104 examplesBaseline FCN 10,400 examples0102030405060708090100Training and test examples subject to distributional shift (%)0.20.40.60.81.0Unstructured test set accuracy0102030405060708090100Training and test examples subject to distributional shift (%)0.00.20.40.60.81.0Unstructured test data Brier scoreD.3. Adversarial Batman Joker

(a) Learned hypothesis

accuracy

(b) Interpretability

(c) Learning time

Figure 20.: Robustness to distributional shifts during learning, Adversarial Batman Joker deck.

(a) Correct ILP
example penalty
ratio, 0-100% shifts,
5 repeats

(b) Correct ILP
example penalty
ratio, 95-100%
shifts, 50 repeats

(c) Learned hypothesis
accuracy, 95-100%
shifts, 50 repeats

Figure 21.: The effect of using an uncertainty-aware neural network, Adversarial Batman Joker deck.

Figure 22.: Run-time performance, Adversarial Batman Joker deck.

(a) Accuracy

(b) Brier Score

0102030405060708090100Training examples subject to distributional shift (%)0.40.50.60.70.80.91.0Hypothesis accuracyFF-NSL Softmax 104 examplesFF-NSL EDL-GEN 104 examplesBaseline RF 104 examplesBaseline RF 10,400 examplesBaseline FCN 104 examplesBaseline FCN 10,400 examples0102030405060708090100Training examples subject to distributional shift (%)0.20.40.60.81.0Learned hypothesis accuracy0102030405060708090100Training examples subject to distributional shift (%)101102103104Total number of atoms0102030405060708090100Training examples subject to distributional shift (%)101100101102Learning time (s)0102030405060708090100Training examples subject to distributional shift (%)30405060708090100Correct ILP example penalty ratioFF-NSL Softmax (with NN penalties)FF-NSL EDL-GEN (with NN penalties)FF-NSL Softmax (with constant penalties)FF-NSL EDL-GEN (with constant penalties)0102030405060708090100Training examples subject to distributional shift (%)20406080100Correct ILP example penalty ratio9596979899100Training examples subject to distributional shift (%)15202530Correct ILP example penalty ratio828384848587Incorrect generated ILP examples, FF-NSL Softmax (%)737374757678Incorrect generated ILP examples, FF-NSL EDL-GEN (%)9596979899100Training examples subject to distributional shift (%)0.20.40.60.81.0Learned hypothesis accuracy0102030405060708090100Training examples subject to distributional shift (%)0.40.50.60.70.80.91.0Hypothesis accuracyFF-NSL Softmax 104 examplesFF-NSL EDL-GEN 104 examplesBaseline RF 104 examplesBaseline RF 10,400 examplesBaseline FCN 104 examplesBaseline FCN 10,400 examples0102030405060708090100Training and test examples subject to distributional shift (%)0.20.40.60.81.0Unstructured test set accuracy0102030405060708090100Training and test examples subject to distributional shift (%)0.00.20.40.60.81.01.2Unstructured test data Brier scoreD.4. Adversarial Captain America

(a) Learned hypothesis

accuracy

(b) Interpretability

(c) Learning time

Figure 23.: Robustness to distributional shifts during learning, Adversarial Captain America deck.

(a) Correct ILP
example penalty
ratio, 0-100% shifts,
5 repeats

(b) Correct ILP
example penalty
ratio, 95-100%
shifts, 50 repeats

(c) Learned hypothesis
accuracy, 95-100%
shifts, 50 repeats

Figure 24.: The effect of using an uncertainty-aware neural network, Adversarial Captain America
deck.

0102030405060708090100Training examples subject to distributional shift (%)0.40.50.60.70.80.91.0Hypothesis accuracyFF-NSL Softmax 104 examplesFF-NSL EDL-GEN 104 examplesBaseline RF 104 examplesBaseline RF 10,400 examplesBaseline FCN 104 examplesBaseline FCN 10,400 examples0102030405060708090100Training examples subject to distributional shift (%)0.20.40.60.81.0Learned hypothesis accuracy0102030405060708090100Training examples subject to distributional shift (%)101102103104Total number of atoms0102030405060708090100Training examples subject to distributional shift (%)101100101102103Learning time (s)0102030405060708090100Training examples subject to distributional shift (%)30405060708090100Correct ILP example penalty ratioFF-NSL Softmax (with NN penalties)FF-NSL EDL-GEN (with NN penalties)FF-NSL Softmax (with constant penalties)FF-NSL EDL-GEN (with constant penalties)0102030405060708090100Training examples subject to distributional shift (%)20406080100Correct ILP example penalty ratio9596979899100Training examples subject to distributional shift (%)15202530354045Correct ILP example penalty ratio737475757678Incorrect generated ILP examples, FF-NSL Softmax (%)757576777880Incorrect generated ILP examples, FF-NSL EDL-GEN (%)9596979899100Training examples subject to distributional shift (%)0.20.40.60.81.0Learned hypothesis accuracyFigure 25.: Run-time performance, Adversarial Captain America deck.

(a) Accuracy

(b) Brier Score

0102030405060708090100Training examples subject to distributional shift (%)0.40.50.60.70.80.91.0Hypothesis accuracyFF-NSL Softmax 104 examplesFF-NSL EDL-GEN 104 examplesBaseline RF 104 examplesBaseline RF 10,400 examplesBaseline FCN 104 examplesBaseline FCN 10,400 examples0102030405060708090100Training and test examples subject to distributional shift (%)0.30.40.50.60.70.80.91.0Unstructured test set accuracy0102030405060708090100Training and test examples subject to distributional shift (%)0.00.20.40.60.81.01.2Unstructured test data Brier scoreE. Dataset Details

E.1. Sudoku Grid Validity

The Sudoku grid validity datasets were generated using valid 4x4 and 9x9 Sudoku starting
configurations obtained from Hanssen’s Sudoku puzzle generator.8 Invalid starting configura-
tions were obtained by taking a valid example (that didn’t exist in the set of valid examples)
and changing one digit at random in a row, column or block to match another digit in the
same row, column or block. All sets of invalid examples contained an equal distribution of
examples containing two of the same digit in a row, column or block. The small training datasets
contained 320 examples, each consisting of 160 valid starting configurations and 160 invalid
starting configurations. The large training datasets contained 32,000 examples, with 16,000 valid
and 16,000 invalid examples. Finally, separate test sets were created for 4x4 and 9x9 boards,
which contained 1000 examples: 500 valid and 500 invalid.

For the NN used in the 4x4 grids, we used digit classes 1-4 from the standard MNIST
dataset [26] and created a training set of 24,674 examples and a test set of 4,160 examples.
The MNIST test set was further split (∼70%/30%), maintaining an equal representation of digits,
into two datasets as follows. The first, denoted MNIST_TEST_A contained 2910 images and was
used to create FF-NSL training sets for learning a hypothesis. Digits in the Sudoku training
sets were replaced with a random image of the corresponding digit from MNIST_TEST_A. The
second split, denoted MNIST_TEST_B contained 1249 images and was used to create a hold out
test set such that FF-NSL could be evaluated on unseen data once a hypothesis was learned.
Digits in the Sudoku test set were replaced with a random image of the corresponding image
from MNIST_TEST_B.

For the NN used in the 9x9 grids, we used digit classes 1-9 from the standard MNIST
dataset [26] and created a training set of 54,078 examples and a test set of 9,021 examples.
The MNIST test set was further split (∼70%/30%), maintaining an equal representation of digits,
into two datasets as follows. The first, denoted MNIST_TEST_A contained 6310 images and was
used to create FF-NSL training sets for learning a hypothesis. Digits in the Sudoku training
sets were replaced with a random image of the corresponding digit from MNIST_TEST_A. The
second split, denoted MNIST_TEST_B contained 2710 images and was used to create a hold out
test set such that FF-NSL could be evaluated on unseen data once a hypothesis was learned.
Digits in the Sudoku test set were replaced with a random image of the corresponding image
from MNIST_TEST_B.

Note that data observed by FF-NSL at learning time was completely unseen by the NN and
was therefore vulnerable to distributional shift. Also, data observed by FF-NSL at evaluation
time was completely unseen by the NN and also FF-NSL itself during learning.

Distributional shift was achieved by rotating MNIST digit images 90∘ clockwise in an increas-
ing percentage of examples in the Sudoku training sets. When we evaluated with unstructured
test data, the same procedure applied to the Sudoku test set, i.e., when we evaluated a hypothesis
learned from a training set with 20% of the examples containing rotated images, 20% of the test
set examples also contained rotated images.

8https://www.menneske.no/sudoku/2

E.2. Follow Suit Winner

The Follow Suit winner dataset was generated by simulating multiple games, where each game
began with a randomly shuffled deck of playing cards split between the four players. Each game
consisted of 13 tricks and the card played by each player along with the winner of each trick
was stored. The small training datasets contained 104 example tricks from 8 games and the
large training datasets contained 10,400 example tricks from 800 games. A test set was created
containing 1001 example tricks from 77 games. For the NN, an image was taken of every playing
card in a standard deck. The ImageDataGenerator class from the Keras image pre-processing
library9 was used to apply transformations to each playing card image, generating 750 variations
of each image. We set the rotation range to 55, brightness range to 0.5-1.5, shear range to 15,
channel shift range to 2.5, zoom range to 0.1 and enable horizontal flip. From a total of 39,000
images, we created a training set of 27,300 images and a test set of 11,700 images (70%/30%
split), maintaining an equal representation of each playing card. Similarly to the Sudoku grid
validity task, the test set was further split into two datasets (∼70%/30%), maintaining an equal
representation of each playing card, as follows. The first, denoted CARDS_TEST_A contains
8164 images and was used to create FF-NSL training sets for learning a hypothesis. Playing cards
in the Follow Suit winner training sets were replaced with a random image of the corresponding
playing card from CARDS_TEST_A. The second split, denoted CARDS_TEST_B contained 3536
images and was used to create a hold out test set such that FF-NSL can be evaluated on unseen
data once a hypothesis has been learned.

(a)

(b)

(c)

(d)

(e)

(f)

Figure 26.: Example playing card images

Distributional shift was achieved by replacing playing card images from the standard deck
with playing card images from alternative decks in an increasing percentage of examples in the
Follow Suit winner training sets. We used playing card images from Batman Joker and Captain
America decks and also created adversarial examples from each deck, placing the candidate
playing card image on a background containing playing card images from the standard deck.
We applied the same image transformations to the alternative decks such that standard playing
card images can be directly swapped with a corresponding card image from an alternative deck.
Figure 26 shows an example queen of hearts playing card image from each deck: Standard (26a),
Batman Joker (26b), Captain America (26c), Adversarial Standard (26d), Adversarial Batman Joker
(26e) and Adversarial Captain America (26f).

9https://keras.io/api/preprocessing/image/

F. Baseline Details

F.1. Sudoku Grid Validity

The baseline random forest model was implemented with scikit-learn 0.23.2 and tuned on the
first small dataset with no examples subject to distributional shift. The number of estimators
was tuned across: {10, 20, 50, 100, 200}. The best performing parameter value of 100 estimators
was chosen and used for all Sudoku grid validity experiments. The random seed was set to 0 to
enable reproducability.

The baseline CNN-LSTM consisted of an embedding layer, followed by a 1D convolutional
layer with a kernel size of 3 and the ReLU activation function. Then, a 1D max pooling layer
with pool size 2 was used, followed by a dropout layer, an LSTM layer and a second dropout
layer. Finally, a dense fully connected layer with the sigmoid activation function was used to
produce a binary classification of the input digit sequence. The input sequence length to the
embedding layer was 16 for 4x4 grids and 81 for 9x9 grids, representing each cell on the Sudoku
grid. We implemented the architecture in PyTorch v1.7.0.

To tune the CNN-LSTM, we sampled the learning rate 𝑙𝑟 ∈ {0.1, 0.001, 0.0001}, the embed-
ding dimension of the embedding layer 𝑒𝑑 ∈ {32, 96, 256}, the number of output channels
of the 1D convolution layer 𝑜𝑐 ∈ {64, 96}, the number of hidden features in the LSTM layer
𝑙ℎ ∈ {32, 96, 128} and the dropout probability 𝑑𝑟 ∈ {0.01, 0.05, 0.1} in both dropout layers.
We performed 10 samples and evaluated the model on the first large dataset with 0 examples
subject to distributional shift, trained for 2 epochs. The best performing parameter values of
𝑙𝑟 = 0.0001, 𝑒𝑑 = 96, 𝑜𝑐 = 64, 𝑙ℎ = 96 and 𝑑𝑟 = 0.01 were chosen. These parameters were
then fixed for all models trained and following tuning, each model was trained for 5 epochs.
Finally, the random seed was set to 0 to enable reproducability.

F.2. Follow Suit Winner

The baseline random forest model was implemented with scikit-learn 0.23.2 and tuned on the
first small dataset with 0 examples subject to distributional shift. The number of estimators was
tuned across: {10, 20, 50, 100, 200}. The best performing parameter value of 100 estimators
was chosen and used for all Follow Suit winner experiments. The random seed was set to 0 to
enable reproducability.

The baseline FCN consists of 3 fully connected layers with the ReLU activation function
applied to each layer. Dropout was also applied after the first and second layers. Finally, a
Softmax layer squashed the final logits into 4 classes, representing each possible winner. The
input consisted of one-hot encoded suit values and the rank value of the playing card for each
player. Therefore, the input size to the first fully connected layer was 20. We implemented the
architecture in PyTorch v1.7.0.

To tune the FCN, we sampled the number of output units in the first and second layers, i.e.,
𝑙1 ∈ {20, 32, 46, 52} and 𝑙2 ∈ {52, 64, 74, 80} respectively, along with the dropout probability
in both dropout layers 𝑑𝑟 ∈ {0.1, 0.2, 0.5}. We sampled all possible parameter combinations
and tuned on the first small dataset, with no examples subject to distributional shift, trained for
50 epochs. The best performing parameter values of 𝑙1 = 20, 𝑙2 = 74 and 𝑑𝑟 = 0.1 were chosen.

These parameters were then fixed for all models trained and following tuning, each model was
trained for 50 epochs. Finally, the random seed was set to 0 to enable reproducability.

G. System Details

All experiments in this paper (with the exception of the deep NN baselines) were run on the
same machine with the following specifications:
Hardware: QEMU KVM virtual machine standard PC (i440FX + PIIX 1996) with 10 nodes of
8-core AMD EPYC Zen 2 CPUs (80 cores total), 16GB RAM.
Operating System: Ubuntu 18.04.4 LTS.
Software: FastLAS 1.1 (FastLAS 3 for 4x4 Sudoku grid validity with reduced background
knowledge), ILASP 4, Python 3.7.3, PyTorch 1.7.0, TensorFlow 1.14.0, Keras 2.4.0, scikit-learn
0.23.2, numpy 1.19.1, problog 2.1.0.42. The NN baselines were run on a machine with the
following specifications:
Hardware: x86 compute node with 24 cores (CPU) and an NVIDIA Tesla K80 GPU, 512GB
RAM.
Operating System: Red Hat Enterprise Linux 7.6.
Software: Same as above.

H. Sudoku Grid Validity ILP

There are two variations of ILP tasks presented in this paper, where knowledge of the Sudoku
grid was specified, and where grid knowledge was removed and replaced with a division
predicate, which enabled FastLAS to learn column, row and block identifiers, based on the cell
coordinates given in the example contexts. Both of these variations are presented below, with
an example for 9x9 boards with the grid knowledge, and 4x4 boards without the grid knowledge.
For each variation, we present the background knowledge specified, the mode declarations
used and the learned hypotheses under different amounts of distributional shift. For the sudoku
task with grid knowledge, we present a walk-through the FF-NSL framework, from images to
learned hypothesis.

H.1. Encoding the Sudoku grid

H.1.1. Background knowledge

col(“1, 1", 1).
col(“1, 2", 2).
col(“1, 3", 3).
col(“1, 4", 4).
col(“1, 5", 5).
col(“1, 6", 6).
col(“1, 7", 7).
col(“1, 8", 8).
col(“1, 9", 9).
...

row(“1, 1", 1).
row(“1, 2", 1).
row(“1, 3", 1).
row(“1, 4", 1).
row(“1, 5", 1).
row(“1, 6", 1).
row(“1, 7", 1).
row(“1, 8", 1).
row(“1, 9", 1).
...

block(“1, 1", 1).
block(“1, 2", 1).
block(“1, 3", 1).
block(“2, 1", 1).
block(“2, 2", 1).
block(“2, 3", 1).
block(“3, 1", 1).
block(“3, 2", 1).
block(“3, 3", 1).
...

H.1.2. Mode Declarations

#modeh(invalid).
#modeb(digit(var(cell), var(num))).
#modeb(row(var(cell), var(row))).
#modeb(col(var(cell), var(col))).
#modeb(block(var(cell), var(block))).
#modeb(neq(var(cell), var(cell))).
#maxv(4).
num(1..9).
row(1..9).
col(1..9).
block(1..9).
cell(C) :- digit(C, _).
neq(X, Y) :- cell(X), cell(Y), X != Y.

H.1.3. Example FF-NSL walk-through: 4x4 Sudoku grid validity

In this section, we present an example walk-through of the FF-NSL framework, from unstruc-
tured data to learned hypotheses, where no distributional shift was applied and where 80% of
training examples were subject to distributional shift.

Let us assume a valid 4x4 Sudoku grid, shown in Figure 27, i.e., 𝑋 = {

}
and 𝑦 = 0 (valid). Let us also assume an EDL-GEN NN, 𝑓𝑑𝑖𝑔𝑖𝑡. With no distributional
shift applied, 𝑓𝑑𝑖𝑔𝑖𝑡 returned a confidence score vector for each digit image, i.e. 𝑓𝑑𝑖𝑔𝑖𝑡(𝑥1)

,

,

,

Figure 27.: Example 4x4 Sudoku grid

= [0.1, 0.05, 0.05, 0.8], 𝑓𝑑𝑖𝑔𝑖𝑡(𝑥2) = [0.01, 0.9, 0.04, 0.05], 𝑓𝑑𝑖𝑔𝑖𝑡(𝑥3) = [0.02, 0.9, 0.05, 0.03],
𝑓𝑑𝑖𝑔𝑖𝑡(𝑥4) = [0.87,0.03,0.06,0.04].

FF-NSL EDL-GEN then generated the ILP example 𝑒 = ⟨1, 80, ⟨{𝑣𝑎𝑙𝑖𝑑} , {𝑖𝑛𝑣𝑎𝑙𝑖𝑑}⟩, {
digit(“1, 2′′, 4). digit(“2, 2′′, 2). digit(“3, 3′′, 2). digit(“4, 3′′, 1). }⟩ using additional
given information encoding the row and column of each digit. Given 319 additional ILP exam-
ples, the following hypothesis was learned, which states a Sudoku grid is invalid if two digits
are in the same row, column or block:

invalid :- neq(V2,V1), digit(V1,V3), block(V2,V0), block(V1,V0), digit(V2,V3).
invalid :- neq(V1,V0), digit(V0,V2), digit(V1,V2), row(V0,V3), row(V1,V3).
invalid :- neq(V1,V0), digit(V0,V3), digit(V1,V3), col(V0,V2), col(V1,V2).

When 90% of the training examples were subject to distributional shift, 𝑓𝑑𝑖𝑔𝑖𝑡(𝑥1) =

[0.2, 0.35, 0.3, 0.15], 𝑓𝑑𝑖𝑔𝑖𝑡(𝑥2) = [0.1, 0.4, 0.3, 0.2], 𝑓𝑑𝑖𝑔𝑖𝑡(𝑥3) = [0.02, 0.25, 0.15, 0.58], 𝑓𝑑𝑖𝑔𝑖𝑡(𝑥4) =
[0.3, 0.1, 0.06, 0.54]. FF-NSL EDL-GEN generated the ILP example 𝑒 = ⟨1, 35, ⟨{𝑣𝑎𝑙𝑖𝑑} ,
{𝑖𝑛𝑣𝑎𝑙𝑖𝑑} ⟩, { digit(“1, 2′′, 2). digit(“2, 2′′, 2). digit(“3, 3′′, 4). digit(“4, 3′′, 4). }⟩. Given
319 additional ILP examples, FF-NSL EDL-GEN learned the following incorrect rules:

invalid :- not block(V2,V0), block(V1,V0), col(V1,V3), col(V2,V3).
invalid :- not block(V2,V0), block(V1,V0), row(V1,V3), row(V2,V3).
invalid :- neq(V2,V1), neq(V2,V3), neq(V3,V1), block(V1,V0), block(V2,V0), block(

V3,V0).

H.2. Without encoding the Sudoku grid

H.2.1. Background knowledge

div_same1(X, Y, C) :- (X - 1) / C = (Y - 1) / C, idx1(X), idx1(Y), X < Y, quotient

(C).

div_same2(X, Y, C) :- (X - 1) / C = (Y - 1) / C, idx2(X), idx2(Y), X < Y, quotient

(C).

quotient(1..3).
idx1(1..4).
idx2(1..4).

H.2.2. Mode Declarations

#modeh(invalid).
#modeb(digit(var(idx1), var(idx2), var(num))).
#modeb(div_same1(var(idx1), var(idx1), const(quotient))).
#modeb(div_same2(var(idx2), var(idx2), const(quotient))).

#maxv(5).
num(1..4).

#bias(“penalty(1, head).").
#bias(“penalty(1, body(X)) :- in_body(X).").
#ground_without_replacement.

H.2.3. Example FastLAS learned hypotheses

With no distributional shift applied, the following rules were learned:

invalid :- div_same1(V0,V1,2), digit(V0,V2,V4), digit(V0,V2,V4) != digit(V1,V3,V4)
, div_same2(V2,V3,2), digit(V1,V3,V4), idx1(V0), idx1(V1), idx2(V2), idx2(V3),

num(V4).

invalid :- div_same1(V0,V1,2), digit(V0,V3,V4), digit(V0,V3,V4) != digit(V1,V2,V4)
, div_same2(V2,V3,2), digit(V1,V2,V4), idx1(V0), idx1(V1), idx2(V2), idx2(V3),

num(V4).

invalid :- digit(V0,V2,V3), digit(V0,V2,V3) != digit(V1,V2,V3), digit(V1,V2,V3),

idx1(V0), idx1(V1), idx2(V2), num(V3).

invalid :- digit(V0,V1,V4), digit(V0,V1,V4) != digit(V0,V3,V4), digit(V0,V3,V4),

idx1(V0), idx2(V1), idx2(V3), num(V4).

When 80% of training examples were subject to distributional shift, the following rules were

learned:

invalid :- div_same2(V2,V3,2), digit(V0,V2,V4), digit(V0,V2,V4) != digit(V0,V1,V4)

, digit(V0,V1,V4), idx1(V0), idx2(V1), idx2(V2), idx2(V3), num(V4).

invalid :- div_same1(V0,V1,2), digit(V0,V3,V4), digit(V0,V3,V4) != digit(V1,V2,V4)
, digit(V1,V2,V4), div_same2(V2,V3,2), idx1(V0), idx1(V1), idx2(V2), idx2(V3),

num(V4).

invalid :- div_same1(V0,V1,3), digit(V0,V3,V4), digit(V0,V3,V4) != digit(V1,V3,V4)
, digit(V1,V3,V4), div_same2(V2,V3,2), idx1(V0), idx1(V1), idx2(V2), idx2(V3),

num(V4).

invalid :- div_same1(V0,V1,2), digit(V1,V3,V4), digit(V1,V3,V4) != digit(V0,V2,V4)
, div_same2(V2,V3,2), div_same2(V2,V3,3), digit(V0,V2,V4), idx1(V0), idx1(V1),

idx2(V2), idx2(V3), num(V4).

invalid :- div_same1(V0,V1,2), div_same1(V0,V1,3), digit(V1,V3,V4), digit(V1,V3,V4
) != digit(V0,V2,V4), div_same2(V2,V3,2), digit(V0,V2,V4), idx1(V0), idx1(V1),

idx2(V2), idx2(V3), num(V4).

invalid :- digit(V0,V3,V4), digit(V0,V3,V4) != digit(V0,V2,V4), div_same2(V2,V1,3)

, div_same2(V2,V1,3) != digit(V0,V2,V4), digit(V0,V2,V4), idx1(V0), idx2(V1),
idx2(V2), idx2(V3), num(V4).

invalid :- div_same1(V1,V0,3), digit(V2,V3,V4), digit(V2,V3,V4) != digit(V1,V3,V4)

, digit(V1,V3,V4), idx1(V0), idx1(V1), idx1(V2), idx2(V3), num(V4).

I. Follow Suit Winner ILP

For the Follow Suit winner task, we used the ILASP [6] ILP system as ILASP supports predicate
invention [27]. Predicate invention was required for this task as the target ground truth hypoth-
esis included a rank_higher predicate, to compare the rank value of different player’s cards,
and this predicate did not exist in the context of each ILP example. For FF-NSL Softmax, we had
to implement early stopping criteria that ensured ILASP returned the best scoring hypothesis
after either 15 minutes had elapsed, an ILASP iteration ran for longer than 5 minutes or when
ILASP achieved a candidate hypothesis score ≤ 500. With FF-NSL EDL-GEN, no early stopping
criteria was used and ILASP was allowed to find the optimal solution w.r.t. the scoring function.
We encoded as background knowledge possible suit and rank values, the four players, as well
as the definition of the rank_higher predicate. The set of body mode declarations included a
suit predicate, which linked a player’s card to a suit, alongside the rank_higher predicate.
The set of head mode declarations included a player variable, specified to support predicate
invention. The hypothesis space for this task contained 96 possible rules and an example listing
is presented in this section.

I.1. Background Knowledge

% Suits
suit(h).
suit(s).
suit(d).
suit(c).

% Ranks
rank(a).
rank(2).
rank(3).
rank(4).
rank(5).
rank(6).
rank(7).
rank(8).
rank(9).
rank(10).
rank(j).
rank(q).
rank(k).

% Rank Value
rank_value(2, 2).
rank_value(3, 3).
rank_value(4, 4).
rank_value(5, 5).
rank_value(6, 6).
rank_value(7, 7).

rank_value(8, 8).
rank_value(9, 9).
rank_value(10, 10).
rank_value(j, 11).
rank_value(q, 12).
rank_value(k, 13).
rank_value(a, 14).

% 4 Players
player(1..4).

% Definition of higher rank
rank_higher(P1, P2) :- card(P1, R1, _), card(P2, R2, _), rank_value(R1, V1),

rank_value(R2, V2), V1 > V2.

% Link player’s card to suit
suit(P1, S) :- card(P1, _, S).

I.2. Mode Declarations

P(X) :- Q(X), identity(P, Q).
P(X) :- player(X), not Q(X), inverse(P, Q).
#modem(2, inverse(target/1, invented/1)).
#modem(2, identity(target/1, invented/1)).
#predicate(target, winner/1).
#predicate(invented, p1/1).

#constant(player, 1).
#constant(player, 2).
#constant(player, 3).
#constant(player, 4).
#modeh(p1(var(player))).
#modeb(1, var(suit) != var(suit)).
#modeb(1, suit(var(player), var(suit)), (positive)).
#modeb(1, suit(const(player), var(suit)), (positive)).
#modeb(1, rank_higher(var(player), var(player)), (positive)).

I.3. Example FF-NSL walk-through: Follow Suit winner

(a)

(b)

(c)

(d)

Figure 28.: Example playing card images

In this section, we present an example walk-through of the FF-NSL framework, from unstruc-
tured data to learned hypotheses, where no distributional shift was applied and where 100% of
training examples were subject to distributional shift.

Let us assume a Follow Suit winner trick, shown in Figure 28, i.e., 𝑋 = { ,

, } and 𝑦 = 4.
Let us also assume an EDL-GEN NN, 𝑓𝑑𝑖𝑔𝑖𝑡. With no distributional shift applied, 𝑓𝑑𝑖𝑔𝑖𝑡 returned a
confidence score vector for each digit image of length 52, representing a class prediction for each
playing card. The EDL-GEN NN predicted the correct class for each card with confidence scores
[0.9, 0.85, 0.93, 0.99] for each image respectively. FF-NSL EDL-GEN generated the ILP example
𝑒 = ⟨1, 85, ⟨{𝑝𝑙𝑎𝑦𝑒𝑟(4)} , {𝑝𝑙𝑎𝑦𝑒𝑟(3), 𝑝𝑙𝑎𝑦𝑒𝑟(2), 𝑝𝑙𝑎𝑦𝑒𝑟(1)}⟩ , { card(1, k, c). card(2, j, c).
card(3, 9, c). card(4, a, c). }⟩. Given 103 additional examples, FF-NSL EDL-GEN learned the
following rules, which state that a player is a winner if they play the highest ranked card with
the same suit as player 1:

,

inverse(winner,p1).
p1(V1) :- V2 != V3; suit(1,V2); suit(V1,V3); player(V1); suit(V2); suit(V3).
p1(V1) :- rank_higher(V2,V1); suit(1,V3); suit(V2,V3); player(V1); player(V2);

suit(V3).

When 100% of training examples were subject to distributional shift, using the Captain Amer-
ica deck, FF-NSL EDL-GEN generated the ILP example 𝑒 = ⟨1, 25, ⟨{𝑝𝑙𝑎𝑦𝑒𝑟(4)} , { 𝑝𝑙𝑎𝑦𝑒𝑟(3),
𝑝𝑙𝑎𝑦𝑒𝑟(2), 𝑝𝑙𝑎𝑦𝑒𝑟(1) }⟩, { card(1, 9, c). card(2, 10, s). card(3, a, c). card(4, a, s). }⟩. Given
103 additional examples, FF-NSL EDL-GEN learned the following rules, which swap the players
in the rank_higher predicate:

inverse(winner,p1).
p1(V1) :- rank_higher(V1,V2); suit(1,V3); suit(V2,V3); player(V1); player(V2);

suit(V3).

p1(V1) :- V2 != V3; suit(1,V2); suit(V1,V3); player(V1); suit(V2); suit(V3).

