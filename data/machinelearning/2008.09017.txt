Swerhun et al.

RESEARCH

A summary of the prevalence of Genetic
Algorithms in Bioinformatics from 2015 onwards
Mekaal Swerhun*†, Jasmine Foley†, Brandon Mossop† and Vijay Mago

*Correspondence:
mdswerhu@lakeheadu.ca
Department of Computer Science,
Lakehead University, 955 Oliver
Rd, P7B 5E1 Thunder Bay,
Canada
Full list of author information is
available at the end of the article
†Equal contributor

0
2
0
2

g
u
A
0
2

]
E
N
.
s
c
[

1
v
7
1
0
9
0
.
8
0
0
2
:
v
i
X
r
a

Abstract

Background: In recent years, machine learning has seen an increasing presence
in a large variety of ﬁelds, especially in health care and bioinformatics. More
speciﬁcally, the ﬁeld where machine learning algorithms have found most
application is Genetic Algorithms.

Objective: The objective of this paper is to conduct a survey of articles
published from 2015 onwards that deal with Genetic Algorithms and how they are
used in bioinformatics.

Methods: To achieve the objective, a scoping review was conducted that utilized
Google Scholar alongside Publish or Perish and the Scimago Journal& Country
Rank to search for respectable sources.

Results: Upon analyzing 31 articles from the ﬁeld of bioinformatics, it became
apparent that genetic algorithms rarely form a full application, instead they rely
on other vital algorithms such as support vector machines. Indeed, support vector
machines were the most prevalent algorithms used alongside genetic algorithms
(GA); however, while the usage of such algorithms contributes to the heavy focus
on accuracy by GA programs, it often sidelines computation times in the process.
In fact, most applications employing GAs for classiﬁcation and feature selection
are nearing or at 100% success rate, and the focus of future GA development
should be directed elsewhere.

Conclusion: Population-based searches, like GA, are often combined with other
machine learning algorithms. In this scoping review, genetic algorithms combined
with Support Vector Machines were found to perform best. The performance
metric that was evaluated most often was the accuracy. Measuring the accuracy
avoids measuring the main weakness of GAs, which is computational time. The
future of genetic algorithms could be “open-ended” evolutionary algorithms,
which attempt to increase complexity and ﬁnd diverse solutions, rather than
optimize a ﬁtness function and converge to a single “best” solution from the
initial population of solutions.

Keywords: Genetic Algorithm; Bioinformatics; Machine Learning; Feature
Selection; Datasets

1 Introduction
Genetic Algorithms
Genetic Algorithms (GA) belong to a larger class of evolutionary algorithms. A
parallel search heuristic algorithm inspired by Charles Darwin’s theory of natural
selection is modeled by the guiding principle of Survival of the Fittest [1]. The
algorithm selects the ﬁttest individuals of the population with the aim of producing
oﬀspring for the next generation that inherit the optimal characteristics of the

 
 
 
 
 
 
Swerhun et al.

Page 2 of 20

parents. This process continues to iterate developing sequential populations, until
it converges on a generation with the ﬁttest individuals [2]. Similarly, GA solves
problems by optimizing a single criterion, known as a ﬁtness function. The ﬁtness
function estimates the importance by assigning a value to each chromosome that
relates to its ability to solving the problem [2, 3]. A chromosome could be an array
of numbers, a binary string, or a list of instances in a database, all relating to and
depending on the problem. Each individual that forms the population, represents
diﬀerent possible solutions. Chromosomes deemed ﬁtter have an increased likelihood
of being used in the following generation. The individuals proceed through a process
of evolution, which are is of the principles of mutation, selection, and crossover all
impacting the ﬁtness value [2, 4]. The most noteworthy beneﬁt about GA is its
ability to search sophisticated and massive spaces proﬁciently and identify near
optimal solutions rapidly [3]. Often in order to achieve better performance, GA-
based selected features are applied as input to classiﬁers [2].

Popularity of Genetic Algorithms in Biomedical Applications
While the properties accredited to GAs make them desirable to a variety of ﬁelds,
their use in biomedical applications is far-ranging and well-established as shall be
made evident in this article. In the medical ﬁeld GA-based solutions have been posed
for a variety of problems including symptom and ailment classiﬁcation [3, 4, 5], vi-
sualization [6] as well as identiﬁcation and diagnoses of diseases [2, 7]. GA-based
solutions have also increasingly been used at the molecular level in tasks such as
handling and predicting transposon-derived piRNAs [8]. Yet the importance of GA-
based solutions in the medical ﬁeld is not limited to solving problems on the micro-
scopic scope as applications have been developed to handle larger scale infrastruc-
ture and logistics that can be vital for entire health care systems [9, 10]. Among
the most frequent uses of GAs however, is their role in feature selection where they
help to narrow down the possible features so that a complementary algorithm can
achieve far greater performance [7, 11, 12, 13, 14]. At times, a GA-based solution
may involve the GA ﬁll multiple of the above mentioned roles such as ﬁnding usage
in both feature selection and classiﬁcation. Of course, other GA applications beyond
what has already been mentioned exist; however, the applications mentioned here
show just how important GA has become in the biomedical ﬁeld and these are the
most common uses found in the papers surveyed in this article.

Key Findings of the Survey
While conducting research, a few key points have been discerned which frequently
appeared in the selected papers for this survey article. These have been summarized
below.

• Applications often use GA alongside other machine learning algorithms, most

commonly classiﬁcation algorithms.

• Among classiﬁcation engines used in conjunction with GA, Support Vector

Machines (SVM) is the top performing.

• Accuracy is one of the prime evaluation metrics focused on; while computa-
tion time is often ignored or under-performing for usage in live biomedical
situations.

Swerhun et al.

Page 3 of 20

• In general, applications employing GAs for classiﬁcation, and feature selection

are reaching close to perfect and at times even perfect results.

Structure of the Paper
The following sections of this survey article are organized as follows: Section 2
focuses on the thirty-one papers surveyed for this article. This section ﬁrst discusses
the methodology explaining how the papers were selected before discussing the
biomedical issues the papers investigate. Section 2 concludes with a discussion of
the common data sets and tools used within the papers. In section 3, the focus is
on how the researchers evaluate their studies, with the various performance metrics
used being examined and explained to discern the advantages and disadvantages of
prioritizing one metric over another. Next in section 4, this article brieﬂy discusses
the future of GA. The ﬁnal section concisely concludes the ﬁndings of this survey
article.

2 Methodology
Paper Selection
The proposed searching procedure in this survey aims to outline a simple yet eﬀec-
tive sequence of operations in order to identify and select high quality manuscripts
published in journals. While utilizing Google Scholar and/or Publish or Perish [15],
the ﬁrst step was to establish the date range of the journals published starting
with 2015 and proceeding onward. This survey focuses on the applications of GA,
which yields a wide range of possibilities. Therefore, in order to narrow the scope,
additional key search terms were needed. In step two, additional key terms, such as
biomedical/medicine, and machine learning, were used alongside the main search
term. Once a paper was identiﬁed it was added to a list of prospective sources. The
quality of the paper was examined and identiﬁed in step three by utilizing Scimago
Journal & Country Rank (SJR)[16] to access the quality of the journal where the
paper has been published. Papers published in journals with a journal ranking of
Q2, Q3, and Q4 were immediately removed from the list, and papers published
in journals with a journal ranking of Q1 at time of publication were kept. Once
the paper met the quality criteria for its journal ranking, step four ensured if the
GA has a dominant role or is used as a key element in the paper. If the paper
does not have either, it was removed from the list. Papers that had GA serving a
dominant role or where GA was used as a key element were kept, further analyzed,
and contributed to this survey. Therefore, each paper had to meet all of the above
requirements set in place to be selected. The whole process is illustrated and can
be found as a ﬂowchart in Figure 1. As a result of this searching methodology, a
total of 31 papers were selected for this survey and can be found in Table 1.

Applications of GA in Bioinformatics
Using the described searching procedure above, Table 1 provides a summary con-
taining key information on the papers selected for this survey. In addition to Table 1,
Table 3 shows the extent to which results could be replicated to obtain similar ﬁnd-
ings to those papers studied in this survey. Yet Table 3 also serves to highlight
a concerning issue as it shows how few papers provide the necessary information

Swerhun et al.

Page 4 of 20

needed in order for others to reproduce their results. All chosen papers discuss the
possible and proposed application in biomedical applications, and are limited to
SJR Q1 rankings, from 2015 and later. Key ﬁndings included in Table 1 in addition
to the biomedical application were examined, the use of GA was noted, and the
beneﬁts of the proposed application were identiﬁed. 19 of the 31 papers surveyed
mention the GA playing a key role in feature selection. Feature selection is a data
pre-processing technique that reduces the overall number of features by eliminating
redundant samples [1]. The task of feature selection is to extract those features
that are deemed the most informative and important in predicting the outcome
for an individual [2]. This technique is an essential step in reducing the dimen-
sionality of the search space and the computational complexity. Alongside feature
selection, GAs are commonly used in classiﬁcation programs. Just about half of the
papers surveyed, 16 out of the 31, use a form of classiﬁcation. Classiﬁcation aims
to predict outcomes associated with a particular individual given a feature vector
describing that individual. GA provides an eﬃcient and robust feature selection
algorithm that speeds up the learning process of classiﬁers and stabilizes the clas-
siﬁcation accuracy. Within bioinformatics, feature selection and classiﬁcation both
serve vital roles and can often be found within the same program, with the GA
selecting features that are then used by a separate algorithm to assign a label that
may be a diagnosis of a general disease or even the identiﬁcation of symptoms. In
recent years, GA-based applications have developed to not only identify ailments,
but recommend what treatments should be used to combat an ailment that has
appeared in diﬀerent patients [5]. GA also has been utilized in non-standard im-
plementations such as running multiple GA in parallel [11], or nested inside one
another as in [7], which has allowed for the diagnosis and identiﬁcation of diﬀerent
cancers biomarkers. Indeed, non-standard implementations have even allowed for a
hybrid GA-based application to be created that can determine the person to receive
the highest quality of life improvement from a lung transplant, helping to ensure
that any unforeseen bias does not eﬀect the transplant [12]. Additionally, GAs have
been used for imaging and visualizing applications both due to their importance in
feature selection and their ability to combine representations of learned information
such as known shapes, and relative position into a single framework that can be
used in three-dimensional segmentation [17]. Finally GAs have been employed to
handle logistics both in handling complex hospital supply chains [9] and in opti-
mizing ambulance dispatches to non-emergency situations [10]. Therefore, it can be
easily seen that bioinformatics research entails many problems that can be solved
using machine learning tasks, and that GA is well-suited for such tasks. Yet, it is
important that research conducted in this area be highly accurate, eﬃcient, and
reliable in order for the results to be meaningful. They need to be prompt and able
to withstand the volatile situations that can be found in this ﬁeld, especially since
such solutions are becoming prevalent in nearly every aspect of bioinformatics.

Datasets
In order to learn more about how the papers selected for this survey came to their
conclusions, a closer look was given to the data used and the sources of the data.
Out of the 31 surveyed papers, not a single one used the exact same raw data. Three
general patterns emerge from the diversity of datasets.

Swerhun et al.

Page 5 of 20

The most common method for data acquisition in the 31 papers was conducted
by accessing digital repositories to ﬁnd datasets relevant for the topic of the paper.
These repositories act as a tool, compiling datasets that are available to the public
and therefore allowing researchers to focus on their project immediately rather than
having to conduct a multitude of tests just to acquire data to use for testing. Some
examples of repositories seen in the surveyed papers are as follows.

• UCSC Genome Browser used by both Li et al. (2016) and Tangherloni et al.
(2019) provides access to assembled genomes including the human genome
[8, 18].

• Gene Expression Omnibus used by Sayed et al. (2019) provides more special-
ized data related to genomics and is itself part of the National Center for
Biotechnology Information data resources [7].

• Protein Data Bank used by Moraes et al. (2017) provides data relating to

wide selection of proteins and related components [19].

Besides acquiring data from public repositories, another method of data acquisition
employed by some of the surveyed papers was requesting access to data that is
generally kept private. Among the sources for this type of data, private databases
curated by institutions were the most common. It is important to note that not
all required a paper’s authors to be a member of the institution as is the case in
Oztekin et al. (2018), who accessed their data from the United Network for Organ
Sharing [12]. In addition, some data sources originate from entities whose primary
concern was not data curation, but who could grant access to records of their
regular functions. One instance of such data collection can be seen in the work of
Fogue et al. (2016) who received their data from an Ambulance Company based in
Husca, Spain [10]. The ﬁnal method of data acquisition employed was only used by
a minority of the papers surveyed -creation of the data by the project members [20].
This ﬁnal method although being necessary in cases where the data needed is not
available does not ensure an unbiased result and would consume signiﬁcant time
for properly compiling the information. Indeed, it would appear to be that due to
these downsides, this method of data acquisition is far from favoured.

Despite the prevalence of acquiring data from pre-existing sources, the raw data
acquired often has to go through preprocessing before it is used. What this entails
can be widely diﬀerent depending on the source of the data and its intended purpose;
however, most commonly the goal is to narrow down the raw data into a set deemed
usable for the project. Such a process may be necessary because in some cases a)
the raw dataset does not have enough records, or b) not all records are complete,
or c) records are not usable (too much noise) [13]. A summary of the datasets used
by the 31 surveyed papers and their sources can be found in Table 2.

Tools
In addition to looking at what datasets the surveyed papers use, this paper takes
a look at the tools and additional machine learning algorithms employed alongside
the GA, although a few papers rely solely on GA. Indeed, when looking at the
surveyed papers it would appear that GA-focused solutions beneﬁt the most when
they are supported by complimentary tools and algorithms. The use of components
is much like the datasets mentioned, where a wide variety was used in each study

Swerhun et al.

Page 6 of 20

to achieve the goal of that particular paper. However, unlike the datasets a few
tools and additional machine learning algorithms were employed across multiple
papers fairly regularly. The full selection of tools and machine learning algorithms
employed has been compiled in Table 4.

Amongst the 31 surveyed articles, two tools proved to be the most prevalent. The
ﬁrst of these is MATLAB, which is used in [6, 9, 11, 21, 17, 22, 23, 13]. The second
tool is Weka, which sees usage in [24, 2, 25, 21]. MATLAB is a fairly well-known and
important tool in studies such as signal processing, data analytics, image processing,
and machine learning, partially due to its versatility. In fact, even though all the
surveyed papers have a focus on GAs, the way that MATLAB is utilized varies
from paper to paper. For instance Soufan et al. (2015) only makes limited use of
MATLAB to ensure fairness when evaluating programs [11]. P(cid:32)lawiak (2018) uses
MATLAB alongside the library, LIBSVM, to implement their study [13].

Weka is a more specialized tool that provides an environment for classiﬁcation,
regression, clustering, and feature selection. It accomplishes this by aiding its users
in the extraction of information and helping them ﬁnd suitable algorithms for cre-
ating accurate predictive model with that information [26]. Although Weka has a
far smaller toolbox, it can be ideal for researchers working in bioinformatics due
to its focus. Indeed, both of these tools have proven beneﬁcial for a number of the
surveyed articles as shown by Hashem et al. (2017) who use both tools to perform
algorithms such as Particle Swarm Optimization [21].

Throughout the surveyed articles, additional machine learning algorithms are of-
ten used alongside the GA, where they prevalently serve as classiﬁcation algorithms.
The goal of such algorithms is to be able to predict successfully the correct outcome
that is associated with a particular occurrence after having received a selection of
features that describe the occurrence [26]. A vast number of these algorithms are
used in the articles surveyed including diﬀerent types of Neural Networks (NN), as
seen in Table 4; however, the most common is Support Vector Machines (SVM).
SVM are frequently used in biomedical applications, and this survey shows that the
addition of GA does not change this fact. One of the biggest appeal of SVM is their
near perfect success rate and their perceived simplicity of simply assigning labels
to objects based on what side of a hyperplane they end up on [27]. Computation
requirements for the SVM scale quadratically, resulting in longer run times as data
inputs increase [27]. This in itself is not necessarily a current negative; however, as
applications become more complex, the SVM quadratic run time growth should not
be ignored in future works employing it alongside GA.

3 Performance Metrics
A key step in the process of building a machine learning model is to estimate
its performance on data that was not part of building the model. The data to
evaluate the performance of the model is called the testing set, while the data that
is used to build the model is called the training set. A primary concern for any
machine learning prediction model is avoiding a model with either high bias or
high variance. Bias is the error resulting from a wrong assumption. A model with
high bias oversimpliﬁes. This is also known as underﬁtting. It results in a large
error between the test set outcome value and the model prediction. Variance is

Swerhun et al.

Page 7 of 20

the error from the model being overly sensitive to ﬂuctuations in the training set.
High variance can cause an algorithm to model the noise in the data, which results
in model overﬁtting. High variance decreases the amount of ﬂexibiliy, and reduces
the ability of the model to generalize to unseen instances. A visualization of the
trade-oﬀs made between bias and variance can be seen in Figure 2.

The confusion matrix is a key concept related to the performance metrics of a
classiﬁer model. The confusion matrix is simply a square matrix that records the
counts of the true positive (TP), true negative (TN), false positive (FP), and false
negative (FN) predictions of a classiﬁer. The true positive rate (TPR) is calculated
as the number of true positives divided by the sum of the false positives and the
true negatives,

T P R =

T P
F N + T P

(1)

The false positive rate (FPR) is calculated as the number of false positives divided
by the sum of the false positives and the true positives,

F P R =

F P
F P + T N

(2)

A dimension of the confusion matrix represents the instances in a predicted class
while the other dimension represents the instances in the actual class (ground truth).
If the predicted class is the same as the ground truth, then the confusion matrix
will label this sample as true, otherwise false [28].

The precision is deﬁned as the ratio of the true positives to the sum of the true

positives and the false positives,

P recision =

T P
T P + F P

(3)

The recall is deﬁned as the ratio of the true positives to the sum of the true positives
and the false negatives,

Recall =

T P
T P + F N

(4)

The F1 score is deﬁned as the two divided by the inverse of the precision, plus the
inverse of the recall,

F 1 =

2
recall-1 + precision-1

(5)

Receiver Operating Characteristic (ROC) graphs are useful tools to select mod-
els for classiﬁcation based on performance with respect to the false positive rate
(FPR) and true positive rate (TPR), which are computed by shifting the decision
threshold of the classiﬁer. The diagonal of an ROC graph presents random guessing
(50 percent probability of being correct), and classiﬁcation models that fall below
this value are considered worse than random guessing. A perfect classiﬁer would

Swerhun et al.

Page 8 of 20

fall into the top left corner of the graph with a TPR of 1 and an FPR of 0. Based
on the ROC curve, the area under the curve can be computed to characterize the
performance of the classiﬁcation model [28].

The prediction error and accuracy provide general information regarding the per-
formance of the prediction model. The error can be understood as the sum of the
false predictions divided by the total number of predictions,

Error =

F P + F N
F P + F N + T P + T N

(6)

The accuracy is calculated as the sum of the correct predictions divided by the total
number of predictions. More precisely, accuracy is the ratio of the number of correct
predictions (the sum of the true positives and true negatives) to the total number
of predictions from the model (the sum of the true positives, true negatives, false
positives, false negatives),

Accuracy =

T P + T N
F P + F N + T P + T N

(7)

There are many methods to evaluate the performance of a model. Each perfor-
mance metric has certain advantages and disadvantages based on the data, such as
the number of classes in the prediction variable, the number of instances of each
class, or how imbalanced the outcome class happens to be, and the cost of misclas-
sifying a prediction. In medicine, misclassiﬁcation can be deadly. The discussion
relating to advantages and disadvantages will focus on the accuracy, as it was the
most common performance metric. Some attention will be also be paid to the true
positive rate and false positive rate, as it oﬀers a more nuanced metric, especially in
relation to biomedical applications. What metrics are used by each surveyed paper
can be found in Table 5.

Advantages
Accuracy is a simple performance metric to compute, and the most intuitive eval-
uation method. It is the most common metric, so it is often used to compare with
other models in the literature.

The true positive rate and false positive rate are especially usefully for imbalanced
class problems. For example, in tumour diagnosis, the detection of malignant tu-
mours is the primary concern since missing the potential presence of a tumour could
have serious implications, like death. However, it is also important to decrease the
number of benign tumours that are incorrectly classiﬁed as malignant (false posi-
tive) to not unnecessarily concern a patient. The true positive rate provides useful
information about the fraction of positive (or relevant) samples that were correctly
identiﬁed out of the total number of positives. In medicine, the samples tend to
be imbalanced, so the true positive rate and false positive rate will be the most
appropriate performance metric.

An ROC graph is a useful tool to visualize the true positive rate and false pos-
itive rate. Finding the area under the curve is a simple method to determine the
performance of the model.

Swerhun et al.

Page 9 of 20

Disadvantages
Accuracy was the primary performance metric used in this scoping review. However,
it has some limitations that are important to consider, especially in the medical
domain. It is only a reliable performance metric when the number of samples are
equal for each class (no imbalance). For example, consider a case where 99 percent
of samples belong to class A and only 1 percent to class B. Then it is trivial for the
model to obtain 99 percent accuracy by simply predicting every training instance
to belong to class A. If the identical model is evaluated on a diﬀerent test set then
the accuracy would be signiﬁcantly reduced. For example, if the test set has 60
percent of its samples from class A and 40 percent of its samples from class B, then
the accuracy would plummet to 60 percent. This examples illuminates the potential
for the accuracy metric to be misleading, which can lead to assuming the model
is better than reality. In the medical ﬁeld, the price of misclassifying a sample has
the potential to be extremely costly. If the model is attempting to predict a rare
but fatal disease, the cost of failing to diagnose the disease of a sick person is much
greater than the cost of sending a healthy person to do more tests.

The papers mostly failed to evaluate a major drawback of GA, which is the amount
of computation it requires. In traditional machine learning, such as neural networks,
the model improves as the amount of training data increases. However, the perfor-
mance of a GA might degrade before it improves. GAs also keep a population of
solutions, instead of a single solution. These requirements of GA are computation-
ally costly, and should be evaluated as a performance metric whenever considering
a genetic algorithm as a learning algorithm[14].

4 Discussion and Future Research Directions
Some of the founders of computer science, such as Alan Turing, John von Neu-
mann, Norbert Wiener, were motivated by the idea of providing computer pro-
grams with operations like self-replication and adaption[14]. These motivations have
been explored in various areas of research such as evolution strategies, evolutionary
programming, and genetic algorithms. These eﬀorts grew into the ﬁeld known as
evolutionary computation, of which GAs are the most prominent example.

The GAs are a powerful tool for solving problems and for simulating natural sys-
tems in a wide range of scientiﬁc ﬁelds. GAs are promising approaches for solving
challenging technological problems. GAs are an important area of research in ma-
chine learning, especially working together with other approaches such as neural net-
works. GAs are part of a movement in computer science that explores biologically-
inspired approaches to computation. These systems are adaptable, parallel, able to
handle complexity, able to learn, and even be creative [14]. Furthermore, the com-
puting resources that are currently widely available and allow for unprecedented
parallel processing are well-suited to implementing GA.

The GA attempt to model natural evolution, which is done with operators such as
adaption, selection, crossover, and mutation. This approach retains a population of
solutions that converges on the objective, which is a form of black-box optimization.
However, natural evolution is a process that ceaselessly creates greater complexity
and novelty, rather than a process that converges on a single solution. In fact,
evolution on Earth can be thought of as a single run of a single algorithm that

Swerhun et al.

Page 10 of 20

invented all of nature [29]. Another term for the notion of a single process inventing
massive complexity for near-eternity is “open-ended.” Open-endedness has proven
impossible to program. Presently, no such algorithm exists that has the endless,
proliﬁc creative potential of natural evolution.

Currently, most evolutionary algorithms (EAs) converge to a solution, based on
the ﬁtness function that is chosen. The ﬁtness function, which tends to select the
“best” performing individuals in the population of solutions, acts as an objective
that is optimized. The optimization consists of selecting more of the ﬁtter solutions
on average, while only selecting a minority of other “less” ﬁt solutions to main-
tain some diversity. However, the divergence of natural evolution and the “open-
endedness” is not implemented with this approach. Natural evolution is not struc-
tured like an optimization algorithm as there is no explicit objective, and organisms
are often rewarded for being diﬀerent rather than just better. For example, organ-
isms that are suﬃciently diﬀerent from their predecessors can establish a new niche
in which they can beneﬁt from reduced competition and are therefore more likely to
survive [30][31]. In opposition to optimization algorithms that converge to a single
“best” solution, natural evolution has a tendency toward divergence. This alterna-
tive perspective in evolutionary computation in that evolution is an algorithm for
diversiﬁcation rather than optimization [32].

An EA inspired by this approach is called novelty search (NS), which searches
for behavioural diversity without any explicit objective. In some domains, NS ﬁnds
the global optimum even when objective-based solutions consistently fail [32]. An
algorithm that avoids an objective function is able to ﬁnd solutions that are not
possible if attempting to solve them directly with objectives. This insight has im-
plications beyond GA, such as in the pursuit of “human-level” AI, since it captures
what many consider our most human-like quality–creativity.

A potentially fruitful application for open-ended evolutionary algorithms is in
any sort of creative design. This includes the design of cars, art, medicines, robots,
video games, and so on. Open-ended evolutionary algorithms oﬀer the potential to
generate endless alternatives in almost any conceivable design domain, in the same
way that natural evolution generated endless solutions to the problems of survival
and reproduction in nature [29].

There are many potential biomedical applications for open-ended, evolutionary
algorithms. One would be the development of vaccines. The open-ended algorithm
could search the space of possibilities while simultaneously ﬁnding solutions that
work in each environment. Provided some initial set of rules that describe what
is possible biologically, the algorithm could continuously explore this space of pos-
sibilities, and report any number of potentially useful ﬁndings to researchers to
investigate further.

5 Conclusion
Population-based search like GAs are often combined with other machine learning
algorithms. In classiﬁcation problems, GA serves as a population of solutions, rather
than a single solution. In this scoping review, GAs combined with Support Vector
Machines were found to perform best. The performance metric that was evaluated
most often was the accuracy. This avoids measuring the main weakness of GA, which

Swerhun et al.

Page 11 of 20

is computational time. In an attempt to better utilize the power of GAs, the future
of GAs could be “open-ended” evolutionary algorithms, which attempt to increase
complexity and ﬁnd diverse solutions, rather than optimize a ﬁtness function to ﬁnd
a single “best” solution. This approach attempts to model the most powerful feature
of natural evolution—its endless ability to create novel and creative solutions to ﬁt
an environment that is constantly changing.

Competing interests
The authors declare that they have no competing interests.

Author’s contributions
The ﬁrst three authors contributed equally for the development of this research article. The last author provided
supervision and guidance.

Acknowledgements
The authors would like to thank the infrastructure support provided by the CASES Building at Lakehead University.

References

1. Lu, H., Chen, J., Yan, K., Jin, Q., Xue, Y., Gao, Z.: A hybrid feature selection algorithm for gene expression

data classiﬁcation. Neurocomputing 256, 56–62 (2017)

2. Aliˇckovi´c, E., Subasi, A.: Breast cancer diagnosis using ga feature selection and rotation forest. Neural

Computing and Applications 28(4), 753–763 (2017)

3. Salem, H., Attiya, G., El-Fishawy, N.: Classiﬁcation of human cancer diseases by gene expression proﬁles.

Applied Soft Computing 50, 124–134 (2017)

4. Subasi, A., Kevric, J., Canbaz, M.A.: Epileptic seizure detection using hybrid machine learning methods. Neural

Computing and Applications 31(1), 317–325 (2019)

5. Zhang, P., West, N.P., Chen, P.-Y., Thang, M.W., Price, G., Cripps, A.W., Cox, A.J.: Selection of microbial
biomarkers with genetic algorithm and principal component analysis. BMC bioinformatics 20(6), 413 (2019)
6. Mohammed, M.A., Ghani, M.K.A., Arunkumar, N.a., Hamed, R.I., Abdullah, M.K., Burhanuddin, M.: A real

time computer aided object detection of nasopharyngeal carcinoma using genetic algorithm and artiﬁcial neural
network based on haar feature fear. Future Generation Computer Systems 89, 539–547 (2018)

7. Sayed, S., Nassef, M., Badr, A., Farag, I.: A nested genetic algorithm for feature selection in high-dimensional

cancer microarray datasets. Expert Systems with Applications 121, 233–243 (2019)

8. Li, D., Luo, L., Zhang, W., Liu, F., Luo, F.: A genetic algorithm-based weighted ensemble method for

predicting transposon-derived pirnas. BMC bioinformatics 17(1), 329 (2016)

9. Khanduzi, R., Sangaiah, A.K.: A fast genetic algorithm for a critical protection problem in biomedical supply

chain networks. Applied Soft Computing 75, 162–179 (2019)

10. Fogue, M., Sanguesa, J.A., Naranjo, F., Gallardo, J., Garrido, P., Martinez, F.J.: Non-emergency patient

transport services planning through genetic algorithms. Expert Systems with Applications 61, 262–271 (2016)

11. Soufan, O., Kleftogiannis, D., Kalnis, P., Bajic, V.B.: Dwfs: a wrapper feature selection tool based on a parallel

genetic algorithm. PloS one 10(2) (2015)

12. Oztekin, A., Al-Ebbini, L., Sevkli, Z., Delen, D.: A decision analytic approach to predicting quality of life for
lung transplant recipients: A hybrid genetic algorithms-based methodology. European Journal of Operational
Research 266(2), 639–651 (2018)

13. P(cid:32)lawiak, P.: Novel methodology of cardiac health recognition based on ecg signals and evolutionary-neural

system. Expert Systems with Applications 92, 334–349 (2018)

14. Mitchell, M.: An Introduction to Genetic Algorithms. MIT press, ??? (1998)
15. Publish or Perish. https://harzing.com/resources/publish-or-perish
16. Scimago Journal & Country Rank. https://www.scimagojr.com/journalrank.php
17. Ghosh, P., Mitchell, M., Tanyi, J.A., Hung, A.Y.: Incorporating priors for medical image segmentation using a

genetic algorithm. Neurocomputing 195, 181–194 (2016)

18. Tangherloni, A., Spolaor, S., Rundo, L., Nobile, M.S., Cazzaniga, P., Mauri, G., Li`o, P., Merelli, I., Besozzi, D.:

Genhap: a novel computational method based on genetic algorithms for haplotype assembly. BMC
bioinformatics 20(4), 172 (2019)

19. Moraes, J.P., Pappa, G.L., Pires, D.E., Izidoro, S.C.: Gass-web: a web server for identifying enzyme active sites

based on genetic algorithms. Nucleic acids research 45(W1), 315–319 (2017)

20. Liu, P., El Basha, M.D., Li, Y., Xiao, Y., Sanelli, P.C., Fang, R.: Deep evolutionary networks with expedited

genetic algorithms for medical image denoising. Medical image analysis 54, 306–315 (2019)

21. Hashem, S., Esmat, G., Elakel, W., Habashy, S., Raouf, S.A., Elhefnawi, M., Eladawy, M.I., ElHefnawi, M.:
Comparison of machine learning approaches for prediction of advanced liver ﬁbrosis in chronic hepatitis c
patients. IEEE/ACM transactions on computational biology and bioinformatics 15(3), 861–868 (2017)
22. Hemanth, D.J., Anitha, J.: Modiﬁed genetic algorithm approaches for classiﬁcation of abnormal magnetic

resonance brain tumour images. Applied Soft Computing 75, 21–28 (2019)

23. Tan, M.S., Tan, J.W., Chang, S.-W., Yap, H.J., Kareem, S.A., Zain, R.B.: A genetic programming approach to

oral cancer prognosis. PeerJ 4, 2482 (2016)

24. Al-Rajab, M., Lu, J., Xu, Q.: Examining applying high performance genetic data feature selection and

classiﬁcation algorithms for colon cancer diagnosis. Computer methods and programs in biomedicine 146,
11–24 (2017)

Swerhun et al.

Page 12 of 20

25. Gangavarapu, T., Patil, N.: A novel ﬁlter–wrapper hybrid greedy ensemble approach optimized using the
genetic algorithm to reduce the dimensionality of high-dimensional biomedical datasets. Applied Soft
Computing 81, 105538 (2019)

26. Frank, E., Hall, M., Trigg, L., Holmes, G., Witten, I.H.: Data mining in bioinformatics using weka.

Bioinformatics 20(15), 2479–2481 (2004)

27. Noble, W.S.: What is a support vector machine? Nature biotechnology 24(12), 1565–1567 (2006)
28. Chawla, N.V.: Data mining for imbalanced datasets: An overview. In: Data Mining and Knowledge Discovery

Handbook, pp. 875–886. Springer, ??? (2009)

29. Lehman, J., Stanley, K.O.: Abandoning objectives: Evolution through the search for novelty alone. Evolutionary

computation 19(2), 189–223 (2011)

30. Kirschner, M., Gerhart, J.: Evolvability. Proceedings of the National Academy of Sciences 95(15), 8420–8427

(1998)

31. Lehman, J., Stanley, K.O.: Evolvability is inevitable: Increasing evolvability without the pressure to adapt. PloS

one 8(4) (2013)

32. Pugh, J.K., Soros, L.B., Stanley, K.O.: Quality diversity: A new frontier for evolutionary computation. Frontiers

in Robotics and AI 3, 40 (2016)

33. Ramadan, E., Naef, A., Ahmed, M.: Protein complexes predictions within protein interaction networks using

genetic algorithms. BMC bioinformatics 17(7), 269 (2016)

34. Lee, N.K., Li, X., Wang, D.: A comprehensive survey on genetic algorithms for dna motif prediction.

Information Sciences 466, 25–43 (2018)

35. Corus, D., Oliveto, P.S.: Standard steady state genetic algorithms can hillclimb faster than mutation-only

evolutionary algorithms. IEEE Transactions on Evolutionary Computation 22(5), 720–732 (2017)

36. Ans´otegui, C., Malitsky, Y., Samulowitz, H., Sellmann, M., Tierney, K.: Model-based genetic algorithms for

algorithm conﬁguration. In: Twenty-Fourth International Joint Conference on Artiﬁcial Intelligence (2015)
37. Bhardwaj, A., Tiwari, A., Krishna, R., Varma, V.: A novel genetic programming approach for epileptic seizure

detection. Computer methods and programs in biomedicine 124, 2–18 (2016)

38. Tan, C.H., Tan, M.S., Chang, S.W., Yap, K.S., Yap, H.J., Wong, S.Y.: Genetic algorithm fuzzy logic for medical
knowledge-based pattern classiﬁcation. Journal of Engineering Science and Technology 13, 242–258 (2018)
39. Dashtban, M., Balafar, M.: Gene selection for microarray cancer classiﬁcation using a new evolutionary method

employing artiﬁcial intelligence concepts. Genomics 109(2), 91–107 (2017)

40. La Cava, W., Silva, S., Danai, K., Spector, L., Vanneschi, L., Moore, J.H.: Multidimensional genetic
programming for multiclass classiﬁcation. Swarm and evolutionary computation 44, 260–272 (2019)
41. Devarriya, D., Gulati, C., Mansharamani, V., Sakalle, A., Bhardwaj, A.: Unbalanced breast cancer data

classiﬁcation using novel ﬁtness functions in genetic programming. Expert Systems with Applications 140,
112866 (2020)

Figure 1 Finding Quality Papers. Search criteria used to identify papers for the article.

Swerhun et al.

Page 13 of 20

Figure 2 Bias Variance Trade-Oﬀs Visualization of underﬁtting and overﬁtting.

Table 1: Information about the Quality of the Papers

How the GA is Used

Beneﬁts

Article

SJR
Rank

[3]

Q1

Cities
Per
Year
23

Year of
publica-
tion
2017

[24]

Q1

6.67

2017

[1]

Q1

28.33

2017

[2]

Q1

27.67

2017

Genetic Programming used
for cancer disease classiﬁca-
tion.

Using GA for feature selec-
tion. Combing GA and PSO
for feature selection. Classi-
ﬁcation using GP.

Adaptive Genetic Algorithm
(AGA)
conven-
improves
tional GA by adjusting val-
ues of crossover and muta-
tion probability. The adapt-
ability increases robustness,
increasing the chance of
ﬁnding optimal solutions.
GA feature selection - ex-
traction of information and
signiﬁcant features.

[25]

Q1

2.00

2019

GA optimizes the subspace
ensembling process.

[6]

Q1

18.50

2018

[9]

Q1

2.00

2019

[4]

Q1

37.00

2019

[11]

Q1

13

2015

[8]

Q1

9.25

2016

learning

Machine
ap-
proaches based on the GA
for feature selection.

GA results in high-quality
solutions (accuracy and ex-
ecution time)

GA used to determine opti-
mum parameters of SVM.

Feature selection tool devel-
oped based on GA

Uses a GA-based weighted
ensemble method to predict
transposon-derived piRNAs

IG/GA method improves classiﬁ-
cation accuracy by reducing the
number of features and prevent-
ing the GA from being trapped
by local optimum.
Selecting fewer genes, classiﬁca-
tion algorithm takes less com-
putational
time. GA/DT and
GA/GP yields highest classiﬁca-
tion accuracy.
Combing MIM (Mutual informa-
tion maximization) with AGA,
eliminates
samples
redundant
and reduces the dimension of the
gene expression data.

Reduces computation complex-
ity and speeds up the data min-
ing process.
GA for feature selection, com-
bined with Rotation Forest re-
sulted in highest classiﬁcation
accuracy.
Optimizing with GA, outper-
forms selected base feature se-
lection techniques in terms of
prediction accuracy.
Reduces overlapping between
classes, and reduces the number
of features to enhance the time
cost.
GA-FBC (Fast Branch Cut
Method) provides eﬃcient so-
lutions,
regarding performance
metrics.
Combing GA with SVM oﬀers
quick global optimizing ability.

Able to signiﬁcantly reduce the
number of
features without
sacriﬁcing classiﬁcation perfor-
mance.
Has higher performance and ro-
bustness compared to similar
methods.

Biomedical
tions

Applica-

Cancer Classiﬁcation

Colon Cancer.

General applications to
biomedical datasets.

Breast Cancer Diagno-
sis.

General applications to
biomedical datasets.

border
resection
Nasopharyngeal

Visualizing
points
for
of
Carcinoma.
Biomedical
chain networks.

supply

Classiﬁcation of EEG
data
Epileptic
for
seizure detection.
Feature selection for
biomedical data.

Prediction of piRNAs.

Swerhun et al.

Page 14 of 20

GA used in feature selection
while predicting the Quality
of Life

Study included all UNOS fea-
tures (after preprocessing) al-
lowing for their eﬀect to be as-
sessed.

[18]

Q1

8.00

2019

GAs with tournament selec-
tion and elitism

[19]

Q1

1.33

2017

GA performs the search of
the generated database

GA used to ﬁnd subset of
the principal components,
from a Principal component
analysis.
GA used to identify com-
plexes in protein interaction
networks

Uses 2 GAs. The outer GA
serves as the main algo-
rithm and outputs the sub-
set of genes evaluated by
SVM. The inner GA takes
data from DNA methylation
and outputs subset of CpG
sites.
Compares the performance
of multiple GAs

N/A

[5]

Q1

1.00

2019

[33]

Q1

3.50

2016

[7]

Q1

11.00

2019

[34]

Q1

4.00

2018

[12]

Q1

17

2018

[35]

Q1

10.67

2018

the

beneﬁts

Prove
of
crossover in Genetic Algo-
rithms

[21]

[36]

Q1

Q1

2.67

2018

10.20

2015

Finding the best features,
predict advanced ﬁbrosis.
Automatic algorithm con-
ﬁguration

[17]

Q1

10.00

2016

[22]

Q1

5.00

2018

[37]

Q1

8.25

2016

GA for combining represen-
tations of learned informa-
tion such as known shapes,
regional properties and rel-
ative position of objects
into a single framework to
perform automated three-
dimensional segmentation.
Three diﬀerent modiﬁed
Genetic
Algorithm ap-
proaches are proposed for
feature selection
Classiﬁcation

[23]

Q1

1.50

2016

Feature Selection

Speeds up the required compu-
tations, and can take into ac-
count datasets produced by 3rd
generation sequencing technolo-
gies
A freely
available method,
through a webapp that ranks
among the top (4th)

component
Use of Principal
analysis before the GA improves
the results of GA selection

Method allows for
identifying
clustering with varying densities.
It is more scalable and robust
and it can be tuned.
Far higher accuracy compared
to other methods, and has been
shown to be able to diﬀerentiate
between lung cancer subtypes

Helps solve the haplo-
typing problem.

Identiﬁcation of
en-
zyme active sites al-
lowing for non-exact
matches.
identify what
Help
treatments
should
be done for diﬀerent
patients.
Used to detect dense
and sparse protein clus-
ters.

Identiﬁcation of dis-
ease (cancer) biomark-
ers.

Guidelines for the de-
velopment of GA based
solutions for DNA mo-
tif prediction.
Minimize
elimi-
or
nate personal bias in
by
transplants
lung
automation. Helping
to increase the rate
of
lung
transplants.
N/A

successful

Predict advanced ﬁbro-
sis.
N/A

GA tested for prostate
segmentation on pelvic
computed
tomogra-
phy
and magnetic
resonance images.

Established
that GA with
crossover is 25 percent faster
than mutation
alone, with
certain parameters.
GA is able to work in parallel.

show that
results
Numerical
model-based genetic algorithms
signiﬁcantly improve our abil-
ity to eﬀectively conﬁgure algo-
rithms automatically.
GA-based method are very use-
ful for medical imaging applica-
tions.

The number of features are re-
duced, decreasing the dimen-
sionality of the features

Magnetic
Resonance
brain image classiﬁca-
tion

Proposes a constructive genetic
programming approach that in-
creasing the number of useful
“building blocks”
Compared the performance to
support vector machines, logistic
regression and performed better.

Classifying EEG signals

of

Recognition
can-
cerous cells and also
gene expression proﬁl-
ing data

Swerhun et al.

Page 15 of 20

[38]

Q1

1.00

2018

[39]

Q1

17.00

2017

[20]

Q1

3.00

2018

[10]

Q1

4.5

2016

[13]

Q1

38

2018

[40]

Q1

15

2018

Proposes a hybrid of a
generic algorithm and fuzzy
logic for pattern recognition

Introduces a novel evolu-
tionary algorithm,
Intelli-
gent Dynamic Genetic Al-
gorithm (IDGA), based on
the GAs and Artiﬁcial Intel-
ligence.
Optimized GA-based strat-
egy to explore CNN struc-
tures.

local

GAs assign services/tasks
to ambulances with the aid
of
search and the
constraint-dominance con-
cept
GA used for feature selec-
tion and classiﬁer parameter
optimization
Multiclass
classiﬁcation
method that learns multi-
feature trans-
dimensional
formation
using Genetic
Programming

[41]

Q1

2

2019

Classiﬁcation

Exempliﬁes the advantage of the
best heuristic search (genetic al-
gorithm) with the ease of under-
standing and interpretability of
fuzzy logic
Reduces dimensionality of the
feature space to provide statis-
tically important features.

GA based network evolution ap-
proach to search for the ﬁttest
genes to optimize network struc-
ture automatically. Outperforms
state-of-the-art methods consis-
tently at various noise levels.
Program is shown to reduce
waiting time by 10% and in-
crease vehicle usage by 30%

Focuses on eﬃciency while re-
taining accuracy

Optimizes models by ﬁrst per-
forming a transformation of the
feature space into a new space of
potentially diﬀerent dimension-
ality, and then performing clas-
siﬁcation using a distance func-
tion in the transformed space
The GA is better able to handle
the unbalanced dataset by alter-
ing the ﬁtness function

Breast Cancer, Dia-
betes, Parkinson’s Dis-
ease

Selection

Gene
Cancer Classiﬁcation

for

Medical
Noising

Image De-

Route planning for am-
bulances responding to
non-emergency assign-
ments

Uses ECG signal to ef-
ﬁciently classify cardiac
disorders
Identifying
interactions
ulated
associated studies

nonlinear
sim-
in
genome-wide

Breast Cancer classiﬁ-
cation

Article
[3]

[24]
[1]

[2]

[25]

[6]

[9]
[4]

[11]

Table 2: Datasets Used

Dataset Used
7 Skewed Gene Expression Datasets:
Leukemia, Colon tumor, Central nervous system, Lung
cancer-Ontario, Lung cancer-Michigan, Diﬀuse Large B-
Cell Lymphoma (DLBCL) and Prostate Cancer
Gene expression dataset - Colon Cancer
6 Gene Expression Datasets:
Leukemia, Colon, Prostate, Lung, Breast, SBRCT
(Small Blue Round Cell Tumor)
2 diﬀerent Wisconsin Breast Cancer datasets:
Wisconsin Breast Cancer (Diagnostic) (WBC (DIAG-
NOSTIC), Wisconsin Breast Cancer Original Dataset
3 Biomedical Datasets:
1. Translation Initiation Sites (TIS)
2. Skin Cancer
3. Epileptic Seizure Recognition

Dataset included 381 NPC endoscopic images with 159
tumors (abnormal cases) and 222 of normal tissues

N/A
Five EEG Datasets

9 datasets in experimental setup:
TIS, TFTF, Medelon, Wdbc, Pre-miRNAs, Lung cancer
(microarrays), Leukemia (microarrays), Prostate cancer
(microarrays), Promoters

Source
Kent Ridge Biomedical Dataset website

Extracted from public cancer datasets
Does not specify.

Obtained from UCI Machine Learning Repository
https://archive.ics.uci.edu/ml/index.php

1. Extracted from genome sequences from the Gen-
Bank
https://www.ncbi.nlm.nih.gov/genbank/
2. Extracted from pixel information of 28 x 28RGB
images of skin cancer MNIST: HAM10000
3. EEG Segments
NPC endoscopic images obtained from ENT De-
partment Tun Fatimah Specialist Hospital, Muar,
Johor
N/A
http://www.meb.unibonn.de/epileptologie/
ence/physik/eegdata.html
http://www.cbrc.kaust.edu.sa/dwfs/data desc.php

sci-

Swerhun et al.

Page 16 of 20

[8]

6 constructed datasets half balanced, half imbalanced
for: Human, Mouse and Fruit Fly data.

[18]

[19]

[5]

[33]

[7]

[34]

[12]

[35]
[21]

[36]
[17]

[22]

[37]
[23]

[38]

[39]

[20]
[10]

2 generated using the: reference sequence of the human
chromosome 22

Constructed database consisting of data from the Pro-
tein Data Bank

Constructed dataset using collected samples, Green-
genes 16S taxonomy database V13.5
Collins protein interaction network from the the BioGrid
dataset, MIPSyeast genome database, CYC2008
TCGA gene expression data: DNA Methylation, GEO
gene expression data, Copy Number Variation (CNV)

Used to compare GAs: CRP(18), CREB(17), SRF(20),
ERE(25), MEF2(17), MYOD(17), TBP(39), E2F(25).
Numerous others mentioned for each individual GA
Dataset constructed from UNOS standard Transplant
Analysis and Research ﬁles for: lung
N/A
A group of 39,567 chronic hepatitis C patients from the
National Treatment Program of HCV patients in Egypt
N/A
Pelvic images were obtained from CT and MRI scans
of patients being treated for Prostate Cancer at Oregon
Health and Science University, CT and MRI images of
10 patients manually segmented by Dr. A. H. and Dr.
J. T, (Dept. of Radiation Medicine, OHSU)
Real time abnormal brain tumour images are used in
this work. These images are collected from M/s. Devaki
Scan centre, Madurai, India
EEG Dataset
A total of 31 oral cancer cases of 3-year prognosis

2 Datasets: Wisconsin Breast Cancer (458 Benign, 241
Breast Cancer), Pima Indian Diabetes (500 without di-
abetes, 268 with diabetes)
1. Small Round Blue Cell Tumor
2. Breast Cancer
3. Large B-cell lymphoma - Standford University
4. Acute Lymphoblastic Leukemia / Acute Myeliod
Leukemia
5.Prostate Cancer
Collection of 10,775 cerebral perfusion CT images
3 scenarios using provided data from actual events

at:

at:

at:

V3

Gene

from:

Dataset

Browser

Browser

Genome

Genome

Datasets

Omnibus

-Constructed
https://github.com/zw9977129/piRNAPredictor
-NONCODE
https://www.ncbi.nlm.nih.gov/pmc/articles/
PMC3245065/
-UCSC
at:
https://www.ncbi.nlm.nih.gov/pubmed/24270787
-NCBI
at:
Expression
https://www.ncbi.nlm.nih.gov/pubmed/15608262
https://www.ncbi.nlm.nih.gov/pubmed/
and
17952056/
-UCSC
GRCh37/hg19Feb.2009assembly
-Real
https://www.pacb.com/blog/data-release-54x-
long-read-coverage-for/
-Tested
models
https://github.com/andrea-
tango/GenHap/blob/master/Models.zip
Protein Data Bank: https://www.rcsb.org/
-Templates from: Catalytic Site Atlas found at:
https://www.ncbi.nlm.nih.gov/pubmed/24319146
NCBI-VAST
-Enzymes
non-redundant
at:
database
https://www.ncbi.nlm.nih.gov/pubmed/24319143
Can be requested from Menzies Health Institute
Queensland.
http://faculty.kfupm.edu.sa/ics/eramadan/
GACluster.zip
-The Cancer Genome Atlas found at: https://tcga-
data.nci.nih.gov/tcga,
-GEO
https://www.ncbi.nlm.nih.gov/gds
-CNV
http://ﬁrebrowse.org/?cohort=COAD
N/A

FireBrowse

found

found

found

found

NCBI

from

from

from

the

at:

at:

at:

Must be requested from the: United Network for
Organ Sharing
N/A
Egyptian National Committee for Control of Viral
Hepatitis database
N/A
Oregon Health and Science University (OHSU)

N/A

N/A
The Malaysia Oral Cancer Database and Tissue
Bank System (MOCDTBS) coordinated by the
OCRCC, Faculty of Dentistry, University of Malaya
https://archive.ics.uci.edu/ml/datasets/
Breast+Cancer+Wisconsin+(Diagnostic)

1,2 and 5. does not specify.
3. Standford University
4. Broad Institute Website
https://www.broadinstitute.org/

Created own data sets.
Ambulance Company located in Huesca, Spain

Swerhun et al.

Page 17 of 20

[13]

[40]
[41]

Constructed database using ECG signals from 45
patients using data from the MIH-BIH Arrhythmia
database

16 GAMETES datasets
Wisconsin Breast Cancer dataset

MIH-BIH Arrhythmia database accessed through
the PhysioNet service. Constructed database pro-
vided at: https://www.sciencedirect.com/science/
article/abs/pii/S0957417417306292?via%3Dihub
https://www.ncbi.nlm.nih.gov/pubmed/23025260
https://archive.ics.uci.edu/ml/datasets/Breast+
Cancer+Wisconsin+(Diagnostic)

Table 3: Analysis for Reproducibility

Article
[3]
[24]
[1]
[2]
[25]
[6]
[9]
[4]
[11]
[8]
[18]
[19]
[5]
[33]
[7]
[34]
[12]
[35]
[21]
[36]
[17]
[22]
[37]
[23]
[38]
[39]
[20]
[10]
[13]
[40]
[41]

Pseudocode
(cid:88)

×
×
×
(cid:88)

×
(cid:88)

×
×
×
×
×
×
(cid:88)
(cid:88)

×
×
(cid:88)

×
×
×
×
(cid:88)

×
(cid:88)

×
(cid:88)

×
(cid:88)

×
(cid:88)

Public Code Repository
×
×
×
×
×
×
×
×
×
(cid:88)
(cid:88)

×
×
(cid:88)

×
×
×
×
×
×
×
×
×
×
×
×
×
×
×
×
×

Table 4: Tools Used

Article
[3]

Tools
Does not specify.

[24]

Weka Machine Learning package

Additional ML Algorithms Utilized/Validation
10-fold cross validation
Classiﬁcation Algorithm:
- Genetic Programming (GP)
Leave one out cross validation (LOOCV), k-fold cross
validation
Classiﬁcation Algorithms:
- Decision Tree,
- Naive Bayes,
- Support Vector Machine,
- Genetic Programming

Swerhun et al.

Page 18 of 20

[1]

Does not specify.

[2]

Weka employed to implement algorithms.

[25]

[6]

[9]

[4]

[11]

[8]

[18]

[19]

[5]

[33]
[7]

[34]

All experiments coded in Python 2.7 and
Weka 3.8.3 (to implement all the prede-
termined feature selection methods).
Python Scikit-learn package implemented
all the classiﬁers.
MATLAB 2014a utilized for the evalua-
tion of the present approach.

All approaches in this study are coded us-
ing MATLAB software.
Does not specify.

PGAPack software libraries, K-Nearest
Neighbour from AlgLib Library, Matlab
R2012b

Random forest classiﬁcation engine from
scikit-learn python package

Message Passing Interface speciﬁcations
in C++, Roche/454 genome sequencer,
PacBio RS II sequencer, General Error-
Model based SIMulator toolbox
Flask framework for Python, frontend de-
veloped using Bootstrap framework. Runs
on top of an Apache server with commu-
nication being made using a Web Server
Gateway Interface
Use of sequence analysis pipelines such as:
- DADA2
- PEAR Software V0.9.6
- BWA Software Package V0.7.12
- Stats package in R
GO term ﬁnder
- biomaRt
- GenomicRanges
- Mminﬁ
-
tion27kabbi:ilmn12:hg19 R packages
- SVM method from e1071 package
- Gene Ontology, Kyoto Encyclopedia of
Genes and Genomes
Local Search Techniques
Gibbs Sampling
Expectation maximization
Additional non-GA methods/tools men-
tioned but not shown to be tested: list
can be found in supplementary materials
pdf.

IlluminaHumanMethyla-

Multiple cross validations.
Classiﬁcation Algorithm:
- Back Propagation Neural Network (BP),
- Support Vector Machine (SVM),
- Extreme Leaning Machine (ELM),
- Regularized Extreme Leaning Machine (RELM)
10-fold cross validation.
Classiﬁcation Algorithm:
- Rotation Forest Model,
- Logistic Regression,
- Bayesian Network,
- Multilayer Perceptron (MLP),
- Radial Basis Function Networks (RBFN),
- Support Vector Machine (SVM),
- C4.5 Decision Tree,
- Random Forest,
- Rotation Forest
10-fold cross validation
Classiﬁcation Algorithms:
- Random Forests,
- Bootstrap Aggregating with C4.5 Decision Trees,
- K-Nearest Neighbour
Cross validation.
Classiﬁcation Algorithms:
- Artiﬁcial Neural Networks
N/A

10-fold cross validation s Classiﬁcation Algorithm:
- Support Vector Machine
Classiﬁcation algorithms :
- K-Nearest Neighbour
- Naive-Bayes
- Combination of above 2 algorithms.
10-fold cross validation, Their weighted ensemble
method is constructed using training data.
Classiﬁcation Algorithms: - Random forest
- Support Vector Machine
N/A

N/A

5-fold Cross Validation
- Classiﬁcation Algorithms:
- Logistic Regression

Spectral clustering
5-fold Cross Validation
Deep-learning Neural Network
Classiﬁcation algorithm:
- Support vector machine

GA Motif discovery: PCEA, GAPWM, kmerGA, GAMI,
FGMA, Paul and Iba, Gadem, GA-DPAF, GASMEN,
MDGA, GALF (GALF-P), GALF-G, GAME, GEMFA,
GAPK, iGAPK

Swerhun et al.

Page 19 of 20

[12]

Does not specify.

[35]
[21]

[36]

[17]

[22]
[37]
[23]

[38]
[39]

[20]

[10]
[13]

[40]
[41]

The ONEMAX benchmark function
MedCalc, MATLAB, Weka

Optimizers

Continuous

Comparing
(COCO) software
In preprocessing, the images were im-
proved with the “imadjust” function in
MATLAB
Implemented in MATLAB
N/A
GPLAB, which is a genetic program- ming
toolbox, which runs in the MATLAB en-
vironment
N/A
Does not specify

GA progress is processed on Tensorﬂow
platform with GEFORCE GTX TITAN
GPUs
Google Maps API
MATLAB R2014b,
MATLAB

libsvm library for

PyTorch
Python packages

5-fold Cross Validation
Random undersampling
Classiﬁcation algorithm used:
- k-Nearest neighbour
- Support Vector Machine (SVM)
- Artiﬁcial Neural Network (ANN)
N/A.
Implemented several types of Machine learning tech-
niques:
- particle swarm optimization
- multi-linear regression
- decision tree learning algorithms to compare.
Classiﬁcation Algorithm:
- Random Trees
N/A

Neural Network
N/A
Classiﬁcation Algorithms:
- Support Vector Machine
- Logistic Regression
Fuzzy Logic
LOOCV and 10 Fold CV
Classiﬁers:
- KNN
- Support Vector Machine
- Naive Bayes
Filter Methods:
- Laplacian-score
- Fisher-score
Convolutional Neural Networks

N/A
4-fold cross validation
10-fold cross validation
Classiﬁcation Algorithms:
-Support Vector Machine
-K-Nearest Neighbour
-Probabilistic Neural Network
-Radial Basis Function Neural Network
Neural Network, Decision Tree
None

Table 5: Performance Evaluation

Article

Acc.

ROC
Curve

AUC

TP

TN

FP

FN

Speciﬁcity

Sensitivity
/ Recall

Prec./
PPV

F-
Mea-
sure

Avg.
Run-
time

[3]
[24]
[1]
[2]
[25]

[6]
[9]
[4]

(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

(cid:88)
(cid:88)
(cid:88)

×
×
×
(cid:88)

×

(cid:88)

×
×

×
×
×
(cid:88)

×

×
×
×

(cid:88)

×
×
(cid:88)

×

(cid:88)

×
(cid:88)

(cid:88)

×
×
×
×

×
×
(cid:88)

(cid:88)

×
×
(cid:88)

×

(cid:88)

×
(cid:88)

(cid:88)

×
×
×
×

×
×
(cid:88)

(cid:88)

×
×
×
×

(cid:88)

×
(cid:88)

(cid:88)

×
×
×
×

(cid:88)
(cid:88)
(cid:88)

×
×
×
×
×

×
×
×

×
×
×
(cid:88)

×

×
×
×

×
(cid:88)

×
×
×

×
(cid:88)

×

Other

Comp.
Com-
plex-
ity
(cid:88)
(cid:88)

×
(cid:88)
(cid:88)

×
×
×

im-

-Feature
portance
-chi-square
test

Fitness classi-
ﬁcation accu-
racy

Swerhun et al.

Page 20 of 20

[11]

[8]
[18]

[19]
[5]
[33]
[7]
[34]
[12]
[35]
[21]
[36]
[17]

[22]
[37]
[23]
[38]
[39]

[20]
[10]

[13]

[40]
[41]

×

(cid:88)
(cid:88)

(cid:88)

×
×
(cid:88)

×
(cid:88)

×
(cid:88)
(cid:88)

×

(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

(cid:88)

×

(cid:88)

(cid:88)
(cid:88)

×

(cid:88)

×

×
(cid:88)

×
×
×
×
×
(cid:88)

×
×

(cid:88)
(cid:88)
(cid:88)
(cid:88)

×

×
×

×

(cid:88)

×

×
(cid:88)

×
×
×
×
×
(cid:88)

×
×

(cid:88)
(cid:88)
(cid:88)
(cid:88)

×

×
×

(cid:88)

(cid:88)

×

×
×
(cid:88)
(cid:88)
(cid:88)
(cid:88)

×
(cid:88)

×
×

(cid:88)
(cid:88)

×
×
×

×
×

(cid:88)

(cid:88)

×

×
×
(cid:88)
(cid:88)

×
(cid:88)

×
(cid:88)

×
×

×
×
×
×
×

×
×

(cid:88)

(cid:88)

×

×
×
(cid:88)
(cid:88)
(cid:88)
(cid:88)

×
(cid:88)

×
×

×
×
×
×
×

×
×

(cid:88)

(cid:88)

×

×
×
×
(cid:88)
(cid:88)
(cid:88)

×
(cid:88)

×
×

×
×
×
×
×

×
×

(cid:88)

(cid:88)

×

×
×
×
×
×
(cid:88)

×
(cid:88)

×
×

(cid:88)
(cid:88)

×
×
×

×
×

×

×

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)
(cid:88)

(cid:88)
(cid:88)

(cid:88)
(cid:88)

(cid:88)
(cid:88)

(cid:88)
(cid:88)

(cid:88)
(cid:88)

(cid:88)
(cid:88)

(cid:88)

(cid:88)

×

×
×
(cid:88)

×
(cid:88)
(cid:88)

×
(cid:88)

×
×

(cid:88)
(cid:88)

×
×
×

×
×

(cid:88)

(cid:88)
(cid:88)

(cid:88)

×
×

×
×
(cid:88)

×
(cid:88)
(cid:88)

×
×
×
×

×
×
×
×
×

×
×

(cid:88)

×
×

×
×
(cid:88)

×
(cid:88)
(cid:88)

×
×
×
×

×
×
×
×
×

×
×

(cid:88)

×
(cid:88)

(cid:88)

×
×
×
×
×
(cid:88)

×
×
×

×
×
×
×
(cid:88)

×
×

×

×
×

×
×
×
×
×
×
×
×
×
×

×
×
×
×
(cid:88)

×
×

×

×

(cid:88)

(cid:88)

(cid:88)
(cid:88)

(cid:88)
(cid:88)

×
×

×
×

-Stability
-G-Mean

Convergence
rate for Av-
erage
Best
Fitness

Discard Ratio

G-Mean

Dice Similar-
ity

Laplacian-
score, Fisher-
score

-Ambulance
Usage
-Patient
Waiting time
-Sum of Er-
rors
-k-coeﬃcient
-Acceptance
feature coef-
ﬁcient

