0
2
0
2

r
p
A
2
2

]

C
O
.
h
t
a
m

[

2
v
8
9
3
0
1
.
1
0
0
2
:
v
i
X
r
a

Proceedings of Machine Learning Research vol 120:1–9, 2020

2nd Annual Conference on Learning for Dynamics and Control

A Kernel Mean Embedding Approach to Reducing Conservativeness
in Stochastic Programming and Control

Jia-Jie Zhu
Empirical Inference Department
Max Planck Institute for Intelligent Systems, T¨ubingen, Germany

JZHU@TUEBINGEN.MPG.DE

Moritz Diehl
Department of Microsystems Engineering
University of Freiburg, Freiburg, Germany

MORITZ.DIEHL@IMTEK.UNI-FREIBURG.DE

Bernhard Sch¨olkopf
Empirical Inference Department
Max Planck Institute for Intelligent Systems, T¨ubingen, Germany

BS@TUEBINGEN.MPG.DE

Editors: A. Bayen, A. Jadbabaie, G. J. Pappas, P. Parrilo, B. Recht, C. Tomlin, M. Zellinger

Abstract
In this paper, we apply kernel mean embedding methods to sample-based stochastic optimization
and control. Speciﬁcally, we use the reduced-set expansion method as a way to discard sampled
scenarios. The effect of such constraint removal is improved optimality and decreased conservative-
ness. This is achieved by solving a distributional-distance-regularized optimization problem. We
demonstrated this optimization formulation is well-motivated in theory, computationally tractable,
and effective in numerical algorithms.
Keywords: Stochastic Control, Stochastic Programming, Kernel Methods, Robust Optimization,
Data-Driven Optimization

1. Introduction

Robustiﬁcation against uncertain events is at the core of modern optimization and control. From
the classic S-lemma to recent advances in distributionally robust optimization, we have witnessed
computational tools giving rise to new robustiﬁcation designs. The classic “worst-case” approach
sets out to robustify constraints against all realizations of disturbances in a mathematical model,
resulting in the often over-conservativeness. Consider the illustrative example of a sample-based
approach to solving constrained stochastic control problem in Figure 1. In this case, we sample
different numbers of realizations of the uncertainty in (left) and (right), and then solve the control
problem under those realized scenarios. Intuitively, one may expect the controller associated with
more scenarios in (left) to be more robust against constraint violation than (right). However, this
results in conservative designs which may be reﬂected in high cost.

The central idea of modern data-driven robust optimization, in non-technical terms, is to use
data samples to form empirical understanding of the true distribution. Then, one only seeks to ro-
bustify against this empirical understanding instead of the whole distribution support. One concrete
relevance to our discussion, for example in Figure 1, is that fewer scenarios translate to fewer con-
straints, which in turn lead to reduced cost. Therefore, this is a trade-off between optimality and
feasibility.

c(cid:13) 2020 J.-J. Zhu, M. Diehl & B. Sch¨olkopf.

 
 
 
 
 
 
RKHS EMBEDDING FOR STOCHASTIC PROGRAMMING AND CONTROL

1
x

time step

Figure 1: Steering the state trajectories (blue) without crossing constraints (red). Two ﬁgures depict

optimization over different number of scenarios (N = 100 vs. N = 17).

In this paper, we show that constraint removal can be formulated as an optimization problem
aiming to form a new distribution close to the empirical data distribution. Our contributions are (1)
We formulate the constraint removal in stochastic programming and control as a tractable convex
optimization problem with reproducing kernel Hilbert space (RKHS)-distance regularization or con-
straint. This formulation is well motivated in theory and effective in numerical studies. (2) To our
knowledge, this is the ﬁrst use of RKHS-embedding reduced-set method in stochastic optimization
and scenario approaches to control.

Notation.

In this work, symbol H denotes a reproducing kernel Hilbert space (RKHS). We
write ξ ∼ P to denote that the random variable or vector (RV) ξ follows the distribution law P . By
empirical distribution of the data, we mean the convex combination of Dirac-measures of the seen
data Pdata := 1
N

i δ(ξi) where {ξi}N

i=1 is the data set.

(cid:80)N

2. Background & related work

2.1. Stochastic programming and scenario optimization for control

In this paper, the problem of interest is the (chance-constrained) stochastic programming (SP; also
known as stochastic optimization) in the following canonical formulation.

minimize
x

E[F (x, ξ)]

subject to Pr{C(x, ξ) ≤ 0} ≥ 1 − α.

(1)

As ξ is assumed to be an RV, program (1) may be intuitively understood as making decision x
under uncertainty originated from ξ . We consider the following sample-based SP (a.k.a. scenario
approach).

Suppose we have a set of i.i.d. realizations {ξi}N

i=1 of ξ, we solve the sample-based program

minimize
x

E[F (x, ξ)]

subject to C(x, ξi) ≤ 0 for i = 1, . . . , N.

(2)

If F and C are convex in x, measurable in ξ, it can be shown that this formulation is a convex
approximation to the original SP (1). As N → ∞, the solution recovers that of the SP with level

2

0.00.51.0Time [s]0.51.01.52.0x10.00.51.0Time [s]0.51.01.52.0x1RKHS EMBEDDING FOR STOCHASTIC PROGRAMMING AND CONTROL

α = 0. However, with a large N , the solution to (2) is overly conservative— it aims to satisfy
the constraints almost everywhere in the distribution of ξ. Therefore, the size N trades off the
conservativeness with constraint-satisfaction. Extensive research (e.g.,Calaﬁore and Campi (2006);
Dentcheva et al. (2000); Luedtke et al. (2010) ) has focused on approaches to remove a subset of
sampled constraints to reduce conservativeness of the solution.

Relevant to this paper, Campi and Garatti (2011) established guaranteed bounds for the con-
straint satisfaction probability and the number of removed constraints κ. Our method is built upon
their sampling-and-discarding framework. Campi and Car´e (2013) used l1 regularization to encour-
age sparsity in decision variables, which is different from our sparsity in RKHS expansion terms.
For readers who are interested in sample-based stochastic programming, good text references are
given by Ch.5 of Shapiro et al. (2009) and Ch.9 of Birge and Louveaux (2011).

2.2. Reproducing kernel Hilbert space (RKHS) embeddings
A positive deﬁnite kernel is a real-valued bivariate, symmetric function k(·, ·) : X × X → R such
that (cid:80)n
i,j=1 αiαjk(xi, xj) ≥ 0 for any n ∈ N, (α1, . . . , αn) ∈ Rn, and (x1, . . . , xn) ∈ X n. One
may intuitively think k(x, x(cid:48)) as a generalized similarity measure (inner product) between x and x(cid:48)
after mapping them into the feature space H, k(x, x(cid:48)) = (cid:104)φ(x), φ(x(cid:48))(cid:105)H. We refer to φ as feature
map associated with the kernel k, and H the associated RKHS. A canonical kernel is the Gaussian
kernel k(x, x(cid:48)) = exp (cid:0)− 1

(cid:1) where σ > 0 is a bandwidth parameter.

2σ2 (cid:107)x − x(cid:48)(cid:107)2

2

RKHS embedding, or kernel mean embedding (KME) [Smola et al. (2007)] maps probability
distributions to (deterministic) elements of a Hilbert space. Mathematically, the KME of a random
variable X is given by the function µX (·) = (cid:82) (cid:104)φ(x), φ(·)(cid:105) dP (x), which is a member of the RKHS.
For example, the RKHS associated with the second-order polynomial kernel consists of quadratic
functions whose coefﬁcients preserve statistical mean and variance. Gaussian kernel embeddings,
on the other hand, preserve richer information up to inﬁnite order.

Reduced-set expansion method using RKHS embeddings. Given a data set xi

N
i=1, the sample-
based KME is given by ˆµx = (cid:80)N
i=1 αiφ(xi), where one can simply choose αi = 1
N . It has been
shown that one may use fewer than the total N data sample to represent the distribution. This is
the idea of reduced-set approximation. (cf. Sch¨olkopf et al. (2002)) Mathematically, this method
i=1 αiφ(xi) ≈ ˆµx, NR < N,where
seeks to ﬁnd an embedding with fewer expansion terms ˆµR
the approximation is in the sense of RKHS distance measure. The reduced-set method forms the
backbone of our approach. We also note that there are other related approximation methods such
as those of Chen et al. (2012); Bach et al. (2012). Recently, Zhu et al. (2019) considered recursive
applications of reduced-set method to uncertainty in stochastic systems.

x = (cid:80)NR

3. Method

3.1. Stochastic programming with reduced-set expansion of RKHS embeddings

We consider the sample-based formulation of the stochastic programming problem (2). Our main
idea is to perform constraint removal systematically using the aforementioned RKHS embedding
reduced-set methods. Typically, constraint removal discards low-probability scenarios to reduce
conservativeness of the resulting solution. Given a set of realized scenarios ξ := {ξ1, . . . ξn} and

3

RKHS EMBEDDING FOR STOCHASTIC PROGRAMMING AND CONTROL

Algorithm 1 RKHS approximation to stochastic programming

1: Solve the sample-based stochastic programming problem (2).
2: Find the reduced-set RKHS embeddings

ˆµR

x =

(cid:88)

i∈R

αiφ(ξi).

by solving the convex optimization problem (3). R is the reduced index set deﬁned in (5).
3: Solve the stochastic programming problem according to the reduced set RKHS approximation

(i.e., constraint removal by sparse optimization).

minimize
x

L(x),

subject to C(x, ξj) ≤ 0, j ∈ R.

(6)

4: Output: Solution of the above reduced stochastic program.

positive deﬁnite kernel k, we formulate optimization problem as

minimize
α

(cid:107)w(cid:62)α(cid:107)1

subject to (cid:107)

N
(cid:88)

i=1

αiφ(ξi) − ˆµξ(cid:107)H ≤ (cid:15),

(3)

where w ∈ RN denotes scaling vector for the l1-penalty. This can often be set to reﬂect spe-
ciﬁc concerns, such as the distance of states to the constraint. The KME expansion weights α :=
(α1, . . . , αN ) ∈ RN need not sum to one. ˆµξ denotes the empirical KME estimator of the distribu-
tion ˆµξ := 1
i=1 φ(ξi). We further write down the equivalent Lagrangian form.
N

(cid:80)N

minimize
α

(cid:107)

N
(cid:88)

i=1

αiφ(ξi) − ˆµξ(cid:107)2

H + λ(cid:107)w(cid:62)α(cid:107)1.

(4)

The resulting solution α∗ is sparse due to the sparsity-inducing l1 term. We then discard the
points ξi, i ∈ I with the index set I = {i | αi = 0, i = 1, . . . , n}. Finally, the we re-solve the
stochastic programming problem with the reduced-set scenarios

R := {1, . . . , n} \ I.

(5)

The intuition of the optimization formulation (3) and (4) is to produce a subset of data whose
distribution is close to the empirical data in the sense of RKHS-embedding distance (cid:107)ˆµR
x − ˆµx(cid:107)H.
Meanwhile, the weighted l1-penalty incentivizes the solution to become sparse. Therefore, the so-
lution to (4) discards the “corner” cases while maintaining the statistical information. We outline
the algorithmic procedure in Algorithm 1. The following lemma shows formulation (4) is computa-
tionally tractable.

If H in problem (4) is the RKHS associated with a positive deﬁnite kernel, the objective of
optimization problem is convex. To see this, we use the sample based estimator for the RKHS
distance to rewrite the objective as

minimize
α

α(cid:62)Kα + α(cid:62)Kβ + λ · (cid:107)w(cid:62)α(cid:107)1.

(7)

N , . . . , 1

β = ( 1
N ) is a constant vector. K := {k(xi, xj)}i,j is the gram matrix associated with the
positive deﬁnite kernel, which implies K ≥ 0. As (cid:107) · (cid:107)1 is convex, so is the optimization problem.

4

RKHS EMBEDDING FOR STOCHASTIC PROGRAMMING AND CONTROL

Remark 1 We can equivalently write the constraint of program (3) in the form of maximum mean
discrepancy, (cid:107)P R − ˆPdata(cid:107)MMD ≤ (cid:15). Optimization problems with constraints on the probability
distributions are often referred to as moment problems.

3.2. Application to stochastic optimal control

Let us consider the following sample-based (scenario) formulation of stochastic optimal control
problem (OCP).

minimize
u

subject to

N
(cid:88)

(cid:90) T

L(xi(t), u(t)) dt

1
N

i=1

0
˙xi = f (xi, u, ξi),
h(xi, u, ξi) ≤ 0,
xi(0) = ξi

0, i = 1, 2, . . . , N.

(8)

where ξ, ξ0 are uncertain variables and ξi, ξi
0 their realizations. The uncertainty in the initial state
ξ0 is particularly relevant to MPC designs. After proper transcription and discretization, this OCP
subsequently becomes the same form as the sample-based SP (2), solvable by Algorithm 1.

4. Numerical Experiments

4.1. Min-max robust regression

We ﬁrst consider a synthetic stochastic programming problem given in the form of the following
min-max robust regression.

minimize
x

S,

subject to |Aix − bi| (cid:54) S, ∀i.

(9)

For simplicity, we consider scalars Ai and bi generated randomly according to the distributions.
n1, n2 ∼ N(0, 1), Ai = 3 + 3n1, bi = Aix∗ + 5n2. where x∗ is the (unknown) true parameter
drawn from Uniform([2, 3]).

i

i=1 αR

Given the computed solution to the full program (9) ˆx, let us consider the quantity of interest
ˆξi := Ai ˆx − bi, which is an RV due to the uncertainty in Ai and bi. We now apply Algorithm 1 to
, ˆµ ˆξ = (cid:80)NR
ﬁnd the reduced-set embedding of { ˆξi}NR
i φ(ξi). In step 3, in solving program (4),
we used the scaling factor wi ∝ exp (T ˆξi) to incentivize the removal of “corner” points (T may
be thought of as the “softness” parameter of this softmax scaling factor). We then remove the
constraints with identiﬁed index set I, |Aix − bi| ≤ S, ∀i ∈ I, from the stochastic program and
re-compute a solution. Following our discussion in the previous sections, this embedding captures
the distribution information while discarding the rare scenarios. This is done by solving the sparse
optimization problem (3). The results are illustrated in Figure 2. As we can see, scenarios associated
with “corner” data points are not selected, causing the reduction in conservativeness. Figure 3
illustrates the effect of constraint removal on the optimal objective value and constraint violation.
See the caption for detailed description.

5

RKHS EMBEDDING FOR STOCHASTIC PROGRAMMING AND CONTROL

Figure 2: Solutions of the min-max robust regression problem. Three ﬁgures correspond to three
different regularization coefﬁcients λ and number of discarded scenarios κ: (left) λ =
0, κ = 0. (center) λ = 0.01, κ = 57. (right) λ = 0.05, κ = 144. The shaded strip
denotes the robust margin. Red points are the selected points by Step 2 in Algorithm 1.
Dark points correspond to discarded scenarios and constraints. We used Gaussian kernel
of bandwidth 1√
2

to calculate the RKHS embedding in Algorithm 1.

Figure 3: Estimates produced by a large-sample (N = 1000) Monte Carlo simulation. (left). Con-
straint violation probability of the solution produced by Algorithm 1. This is estimated by
I(|Aix − bi| > S) where I is the indicator function
the Monte Carlo estimation 1
N
of random events. (right).The new expected cost associated with the solution produced by
Algorithm 1. This is estimated by the Monte Carlo estimation 1
i=1 F (x∗, ξi) where
N
x∗ is the solution by the proposed method.

(cid:80)NR
i=1

(cid:80)NR

4.2. Stochastic control

We now consider the Van der Pol oscilator model

d
dt

(cid:20) x1
x2

(cid:21)

(cid:20)

=

x2
(cid:1) x2 − x1 + u
−0.1 (cid:0)1 − x2
1

(cid:21)

.

(10)

6

246Ai5051015202530bi24650510152025302465051015202530RKHS EMBEDDING FOR STOCHASTIC PROGRAMMING AND CONTROL

The goal of the control design is to steer the system state x1 to a certain level. This is formulated as
the following OCP.

minimize
x(·),u(·)
subject to

2 dt

(cid:82) T
0 (cid:107)x1(t) − 3(cid:107)2
˙x(t) = f (x(t), u(t)) ∀t ∈ [0, T ]
−40 ≤ u(t) ≤ 40 ∀t ∈ [0, T ]
−0.25 ≤ x1(t) ≤ 2 + 0.1 cos(10t) ∀t ∈ [0, T ]
x(0) = s

(11)

We sample the i.i.d. uncertainty realizations {s1, . . . sn} ∼ N (m, Σ), where m = [0.5 0]T , Σ =

. Because of the nonlinear dynamics, we cannot propagate the uncertainty in a

(cid:20) 0.012
0

(cid:21)

0
0.12

tractable manner as in LQG without resorting to approximations. We use the sampled scenarios
to form the OCP (8). The continuous-time dynamics is transcribed using multiple-shooting with
CVodes (interfaced with CasADi) integrator. We then solve the discretized OCP with IPOPT to
obtain the optimal control. An example of states associated with the solution is given in Figure 1
(left). The total time horizon is 1.0s and we consider 10 control steps in this experiment.

Let us consider the quantity of interest ξi(t) := 2 + 0.1 cos(10t) − xi

1(t), the distance from state
position to the upper bound constraint. This quantity reﬂects how close we are to be infeasible. It
is random due to the states being a function of RV s. In Step 2 of Algorithm 1, the scaling factor is
taken to be wi ∝ exp (

) to encourage the removal of close-to-constraint trajectories.

C
(cid:15)+mint( ˆξi(t))

We are now ready to apply Algorithm 1 to ﬁnd the reduced-set embedding of { ˆξi(t)}NR

, t =
1, . . . T , ˆµξ = (cid:80)NR
i=1 αiφ(ξi), where ξi is a vector comprising ξi(t) at all time steps. Finally, we
re-solve the subsequent reduced-set SP—OCP. Figure 1 (right) illustrates the reduced number of
scenarios.

i

After we applied Algorithm 1, we obtain the “optimistic” controller u∗. To evaluate the perfor-
mance of this controller, we use a large-sample Monte Carlo simulation to estimate the constraint
violation probability, i.e., Pr{C(x, ξ) ≤ 0} in the chance-constrained SP (1), as well as the expected
(cid:82) T
cost over the large-sample simulation 1
0 L(xi(t), u∗(t))dt. We plot the state trajectories
N
with different number of removed constraints in Figure 4. The trade off between those is illustrated
in Figure 5. The result makes intuitive sense that the more constraints we remove, the less the
conservativeness, but with higher violation probability.

(cid:80)N

i=1

5. Discussion

This paper proposed a distributional-distance-regularized optimization formulation for stochastic
programming under the framework of sampling-and-discarding. We demonstrated effective conser-
vativeness reduction in data-driven optimization and control tasks. Although we did not study the
guaranteed bounds, all analysis in Campi and Garatti (2011) applies to our case. Our on-going work
is to apply our approach to distributionally robust optimization and control design.

Acknowledgments

We thank Joris Gillis for his help in the numerical experiment, Wittawat Jitkrittum for his helpful
feedback. This project has received funding from the European Unions Horizon 2020 research

7

RKHS EMBEDDING FOR STOCHASTIC PROGRAMMING AND CONTROL

and innovation programme under the Marie Skodowska-Curie grant agreement No 798321, the
German Federal Ministry for Economic Affairs and Energy (BMWi) via eco4wind (0324125B) and
DyConPV (0324166B), and by DFG via Research Unit FOR 2401.

1
x

time step

Figure 4: (left) The optimistic controller evaluated in independent Monte Carlo simulations with
N = 100 trajectories. The controller is produced with Algorithm 1 with κ = 14 re-
moved scenarios (l1 regularization coefﬁcient 10−5). The estimated constraint-violation
probability is 2%. (right) Controller produced with κ = 83 removed scenarios (l1 regu-
larization 5 × 10−3). The constraint violation probability is 5%.

Figure 5: Performance estimates produced by independent (N = 100) Monte Carlo simulations.
(left). Constraint violation probability of the solution produced by Algorithm 1. This is
I(C(x, u) > 0) where I is the indicator
estimated by the Monte Carlo estimation 1
N
function. C(x, u) ≤ 0 denotes all the constraints in OCP (11). (right).The new expected
cost of OCP associated with the solution produced by Algorithm 1. This is estimated
(cid:82) T
by the Monte Carlo estimation 1
0 L(xi(t), u∗(t)) dt where u∗ is the optimistic
N
controller.

(cid:80)NR
i=1

(cid:80)N

i=1

8

0.00.51.0Time [s]0.51.01.52.0x10.00.51.0Time [s]0.51.01.52.0x1RKHS EMBEDDING FOR STOCHASTIC PROGRAMMING AND CONTROL

References

Francis Bach, Simon Lacoste-Julien, and Guillaume Obozinski. On the equivalence between herd-

ing and conditional gradient algorithms. arXiv preprint arXiv:1203.4523, 2012.

John R Birge and Francois Louveaux. Introduction to stochastic programming. Springer Science &

Business Media, 2011.

Giuseppe C Calaﬁore and Marco C Campi. The scenario approach to robust control design. IEEE

Transactions on Automatic Control, 51(5):742–753, 2006.

Marco C Campi and Algo Car´e. Random convex programs with l 1-regularization: sparsity and

generalization. SIAM Journal on Control and Optimization, 51(5):3532–3557, 2013.

Marco C Campi and Simone Garatti. A sampling-and-discarding approach to chance-constrained
optimization: feasibility and optimality. Journal of Optimization Theory and Applications, 148
(2):257–280, 2011.

Yutian Chen, Max Welling, and Alex Smola. Super-samples from kernel herding. arXiv preprint

arXiv:1203.3472, 2012.

Darinka Dentcheva, Andr´as Pr´ekopa, and Andrzej Ruszczynski. Concavity and efﬁcient points of
discrete distributions in probabilistic programming. Mathematical Programming, 89(1):55–77,
2000.

James Luedtke, Shabbir Ahmed, and George L Nemhauser. An integer programming approach
for linear programs with probabilistic constraints. Mathematical programming, 122(2):247–272,
2010.

Bernhard Sch¨olkopf, Alexander J Smola, Francis Bach, et al. Learning with kernels: support vector

machines, regularization, optimization, and beyond. MIT press, 2002.

Alexander Shapiro, Darinka Dentcheva, and Andrzej Ruszczy´nski. Lectures on stochastic program-

ming: modeling and theory. SIAM, 2009.

Alexander J. Smola, Arthur Gretton, Le Song, and Bernhard Sch¨olkopf. A Hilbert space embedding
for distributions. In Proceedings of the 18th International Conference on Algorithmic Learning
Theory (ALT), pages 13–31. Springer-Verlag, 2007.

Jia-Jie Zhu, Krikamol Muandet, Moritz Diehl, and Bernhard Sch¨olkopf. A new distribution-free
concept for representing, comparing, and propagating uncertainty in dynamical systems with
kernel probabilistic programming. arXiv preprint arXiv:1911.11082, 2019.

9

