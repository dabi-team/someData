GPU backed Data Mining on Android Devices

Robert Fritze
Faculty of Computer Science
University of Vienna
Vienna, Austria
ORCID 0000-0001-7061-9587

Claudia Plant
Faculty of Computer Science
University of Vienna
Vienna, Austria
ORCID 0000-0001-5274-8123

1
2
0
2
c
e
D
9

]

C
D
.
s
c
[

1
v
0
0
8
4
0
.
2
1
1
2
:
v
i
X
r
a

Abstract—Choosing an appropriate programming paradigm
for high-performance computing on low-power devices can be
useful to speed up calculations. Many Android devices have
an integrated GPU and - although not ofﬁcially supported -
the OpenCL framework can be used on Android devices for
addressing these GPUs. OpenCL supports thread and data
parallelism. Applications that use the GPU must account for
the fact that they can be suspended by the user or the Android
operating system at any moment.

We have created a wrapper library that allows to use OpenCL
on Android devices. Already written OpenCL programs can
be executed with almost no modiﬁcation. We have used this
library to compare the performance of the DBSCAN and Kmeans
algorithms on an integrated GPU of an Arm-v7 tablet with other
single and multithreaded implementations on the same device. We
have investigated which programming paradigm and language
allows the best tradeoff between execution speed and energy
consumption.

Using the GPU for HPC on Android devices can help to carry
out computationally intensive machine learning or data mining
tasks in remote areas, under harsh environmental conditions and
in areas where energy supply is an issue.

Index Terms—Android, OpenCL, GPU, DBSCAN, Kmeans,

multithreading, HPC, machine learning, data mining

I. INTRODUCTION
Low-power CPUs (Central Processing Units) have become
increasingly popular in recent years, especially for mobile or
edge computing and if energy efﬁciency is an issue. These
CPUs often have a lower clock rate and, therefore, efﬁcient
parallelization techniques may be important to optimize run-
time for more complex workloads.

Android (Open Handset Alliance, Mountain View, USA)
is a widely used Linux-based open-source operating system
for mobile devices. Android Studio (Google, Mountain View,
USA) provides a free and easy to use IDE (integrated devel-
opment environment) for the creation and analysis of appli-
cations. Programs written in Java (Sun Microsystems, Santa
Clara, USA) or Kotlin (JetBrains, Prague, Czech Republic)
are compiled on a host machine and afterwards the executable
binary is transferred to the device. Many Android devices are
equipped with an integrated GPU (Graphics Processing Unit)
that supports task and data based parallelism.

The ﬁrst GPUs have been developed in the 1970s. The pur-
pose of GPUs is to lighten the load of the CPU especially for
graphic intense applications (e.g., video games). Today GPUs
can be located directly on the motherboard (integrated GPU) or
can be provided through a separate video card (discrete GPU).

Integrated GPUs use the main memory whereas discrete GPUs
have an own memory. For these GPUs parts of the memory
have to be copied to the device before the GPU can transform
the data. Android devices usually have integrated GPUs.

The OpenCL (Khronos Group, Beaverton, USA, [1]) project
provides a framework for the compilation and execution of
C-style programs on a great variety of platforms like CPUs,
GPUs, FPGAs (Field Programmable Gate Array) and many
more. An advantage of OpenCL is its portability across devices
[2]. Many Android devices are shipped with the necessary
OpenCL shared libraries for the integrated GPU on the device
[3].

The Android OS (operating system) imposes some restric-
tions on the program execution that do not apply to usual
computing environments. The Android OS is designed to
maximize user comfort. Therefore, if the device is not used, the
OS activates the standby or doze mode after some minutes to
save the battery. Having reached these modes, most activities
are suspended. Moreover, on Android devices the user may
decide to move to another activity. The activity from which
the users moves away is immediately suspended and resources
are relinquished. Please see [4] for an explanation of the life
cycle of an Android activity. These two restrictions make it
impossible to execute long running jobs reliably inside an
activity bound to the UI (user interface).

A. Contributions

• A framework for using OpenCL compliant GPUs on
Android devices. This framework includes locking mech-
anism to safely abort calculations performed on the GPU
when the user has paused/stopped an activity. This frame-
work can be applied not only to data mining tasks but also
to vast area of appropriately parallelizable problems (e.g.,
machine learning) and it complies with the restrictions
on the use of external libraries imposed by the Android
operating system from Android 7 onwards.

• Measurement of the wall clock time needed for the
calculation of the DBSCAN and the Kmeans algorithms
started with several different parameters. Different im-
plementations (single threaded, multithreaded, GPU) with
two different languages (Java and C (Dennis Ritchie &
Bell Labs, Murray Hill, USA)) have been compared.
• Analysis of the energy efﬁciency of the implemented

algorithms.

 
 
 
 
 
 
B. Previous literature

1) Literature related to the use of GPUs on mobile devices:
All publications related to the use of the GPU on Android
devices have used the OpenCL framework.

2014 First published attempts to use the GPU on mobile
devices were made in 2014. That year Ross et al. [5] published
a paper where they compare the calculation of an N-body
simulation on different types of graphic cards. One of them
was a GPU on a mobile device. The same year Wang et al.
[6] implemented an image processing application on Android
mobile devices with GPUs. This application allowed the
removal of objects from images.

2016 Acosta et al. [7] have developed a framework based
on ParallDroid [8] to access the GPU of mobile devices. The
same year Wang et al. [9] used the Mandelbrot set to evaluate
the performance of an Adreno-GPU (Qualcomm, San Diego,
USA) on an Android tablet.

2018 Acosta et al. [3] gave a overview of the availability
of OpenCL capable GPUs on mobile devices. Valery et al.
[10] have implemented PCA (principal component analysis)
on Android mobile devices using the GPU.

2019 A year later the same group has published a framework
“TransferCL” [11] based on OpenCL that allows to use deep
learning on mobile devices using the GPU. Afonso et al. [12]
have implemented a tiling optimization on GPUs of Android
devices for tuning the execution of different algorithms. The
same year Fasogbon et al. [13] have implemented a Depth-
Map algorithm on a mobile device using the GPU.

2020 In 2020 Wang et al. [14] have implemented an
neural network training algorithm that optimized for the device
capabilities. The training of the neural network was made on
the GPU or the CPU.

A few other papers have been published (e.g., [15]) in which
the GPU of a mobile device is used only for inference of
pretrained models.

2) Literature related to data mining on mobile devices:
Many papers have been published on how to analyze data
generated by mobile phone (e.g., usage patterns) with data
mining method, but only a few publications deal with the
implementation of data mining algorithms on mobile devices.
We do not focus on publications where mobile devices are
only used for collecting data and where the process of data
mining or model generation is executed on an external server,
even if the generated model is sent back to the mobile device
on which inference is carried out, because this is not the scope
of this paper.

In 2014 Srinivasan et al. [16] have published a paper where
they present an app called “MobileMiner” that allows to
perform a data mining tasks on mobile devices. The app was
designed for the Tizen operating system.

A paper published 2019 by Yates et al. [17] evaluates the
performance of various data mining algorithms on mobile
devices. The authors have imported a Weka [18] jar archive
into an Android project. The authors have used publicly
available datasets. The DBSCAN and the Kmeans algorithms
were not part of their survey. Short after the same authors have

published an article [19] on a data mining app (“DataLearner”)
developed by them and designed for the use on Android mo-
bile devices. They followed the same approach they described
in the former paper. The authors mention that so far very few
attempts had been made to introduce data mining on Android
mobile devices.

Earlier (2011) there have already been made efforts to port
Weka to Android [20], but this project does not seem to be
maintained any more. Recently Android has added machine
learning capabilities to the API (Application programmer
interface) [21]. Users can chose to use either pretrained models
(e.g., image recognition) or have a custom model trained on
an external server. In both cases inference is performed on the
device.

As of August 2021 we found many books and tutorials on
data mining on Google Play but beside the app “DataLearner”
created by Yates there was just one other app (“Data Min-
ing Calculator”, published in 2020), that offers data mining
algorithms on Android devices.

A. Program design

II. METHODS

We use the ”WorkManager” job scheduling framework
provided by Android for the execution of data mining tasks.
The tasks are executed in a deferred manner as background
tasks but formally are labelled as foreground service. This job
scheduling service allows to continue tasks even after a reboot
of the device.

At the very beginning of the execution of the data mining
algorithms, the method acquires a ”partial wake lock” which
allowes the screen to switch off but kept the CPU at full output.
The lock is released when all jobs have been executed.

We use an app with only one activity. When the activity is
started, it tries to connect to the WorkManager and searches
for a previously submitted data mining job. If there is none, the
activity allowes the user to start a new job. If instead there is a
background job, the current progress is read out and displayed.
Furthermore, the activity tries to ﬁnd an OpenCL device. If it
is not able to detected automatically a GPU, the user can enter
the path to the OpenCL shared library on the device manually.
The execution of the data mining tasks continues even if
the user leaves the app, but the submitted background jobs
compete for the system resources with other apps (e.g. CPU
cores, GPU). The parts written in C are accessed from Java
using JNI (Java native interface) [22]. The GPU can not be
used directly from Java but has to be addressed using the C
programming language.

We use a shared wrapper library that serves as glue between
the program and the native shared OpenCL library on the
device. A loading method of the wrapper library has to be
called before every other call to an OpenCL function. This
method loads dynamically the native shared OpenCL library
on the device. If the library can not be found, an error is
returned. The library can be unloaded and reloaded at runtime.
The OS decides if and when the memory occupied by the
native library is freed or not. The wrapper library implements

(Java Virtual Machine) is not aware that the GPU still holds
a reference, might be subject to premature automatic garbage
collection.

We use a self implemented reentrant writer preferred RW
(reader writer) lock. All Kmeans and DBSCAN implementa-
tions have to test from time to time a ﬂag and check if they
should abort immediately. For the implementations that use the
GPU, the ﬂag is tested between OpenCL kernel executions.
The ﬂag is accessed using the reader lock of the RW lock.
To terminate the calculations prematurely, a special method
acquires the writer lock. As the lock prefers the writers, from
the moment a writer is waiting, all new readers have to queue
up. After the readers, that already have acquired the lock when
the writer arrived, have released the lock again, the writer can
change the value of the ﬂag. This mechanism assures that ﬂag
is updated by the writer as soon as possible. After the writer
has released the writer lock, all waiting readers see the new
value.

The source code of the app and the framework is avail-
able on Github (Microsoft, San Francisco, USA) [https://
github.com/robertfritze/AGPUDM.git]. Import the project to
AndroidStudio - it should compile and run without any
modiﬁcation. All current Android platforms (Arm-v7, Arm-
v8, x86, x86 64) from API 24 (Android 7) onwards are
supported. Please respect the project’s MIT licence and the
Apache Licence 2.0 of the parts provided by the Khronos
group (OpenCL header ﬁles).

B. Execution environment

Please see Table I for a description of the execution environ-
ment we have used. During the execution of the calculations
the device was always attached to the power line. Wiﬁ and
Bluetooth were switched off. No other activity was used.

The hardware acceleration has been switched off (developer
options of the device and in the app’s manifest ﬁle). This
should preserve the maximum GPU output for the execution
of the OpenCL jobs.

We did NOT use a rooted device for this project. Please
note, that the device used is an Arm-v8 device, but was used
in Arm-v7 mode. This is imposed by the device/the vendor
and can not be changed by the user. Arm allows to switch
between legacy Arm-v7 and thumb Arm-v7 mode (not used),
but does not allow to switch between Arm-v7 and Arm-v8
execution modes (not even on rooted devices). The app has
been tested on tablets and mobile phones. It has not been
tested for Android TV and Android Wear.

We have used AndroidStudio 3.6.3. All C programs were
compiled with the Clang 8.0.7 (The LLVM Team) compiler
with the -std=c99 and -O3 switches. The JVM version 1.8
was used.

C. Algorithms

DBSCAN is a very popular density based data mining
algorithm that has been developed by Ester et al. [23]. We use a
non-recursive implementation [24] of the DBSCAN algorithm,
because it is not possible to use recursion with OpenCL. On

Fig. 1: Activity diagram of each call to an OpenCL method
of the wrapper library.

all methods of the OpenCL standard. If an OpenCL method of
the wrapper library is called before the shared library has been
loaded or after it has been unloaded, an error is returned (an
error code that is returned by the native method is used). If the
library has been loaded correctly beforehand, the method calls
are forwarded from the wrapper library to the native library.
The symbols of the native library have to be resolved by hand.
This is done only if they are needed and immediately prior to
the ﬁrst invocation of the method. During the build process,
the app is linked against the wrapper library. The wrapper
library is packed into the Android apk ﬁle.

The programmer can use any piece of existing OpenCL code
almost without modiﬁcation. Only the loading mechanism has
to be invoked. Besides the loading mechanism, the wrapper
library behaves completely transparent with respect to the
native OpenCL library. The library is fully thread-safe as
long as the underlying native OpenCL library is thread-safe.
A reentrant RW (reader/writer) lock is used to get exclusive
access to variables that control the loading status of the shared
library. Fig. 1 depicts the activity diagram of each OpenCL
method of the wrapper library.

The data mining jobs in the background can be stopped by
the user (pressing a button in the app). In this case calculations
should terminated timely. The app should not wait more
than a few seconds to kill the running jobs. Otherwise the
display might freeze and a message stating that the app is
not responding any more would be displayed. On the other
hand, some calculations (especially DBSCAN with many data
points) need more than a minute to complete. If the GPU
is used, the resources on the GPU have to be freed in an
ordered manner. Especially allocated buffers of which the JVM

TABLE I: Execution environment

Manufacturer
Model
Android Version
Android API
SoCb name
CPU/GPU manufacturer

Type
CPU-speed (MHz)
Cores
Architecture
RAM (MB) available

Samsunga
SM-T510
11
30
Exynos 7885
Armc

CPU

Cortex
449-1768
2xCortex A73 + 6xCortex A53
Arm-v7d
2879

GPU

Type
Max. GPU speed (MHz)
Compute units
a Samsung, Seoul, South Korea, bSoC=System on Chip,
cArm Ltd, Cambridge, UK, dArm-v8 in compatibility mode

Mali-G71 MP 2
850
2

the GPU we use two DBSCAN kernels that have almost the
same purpose: They examine if a data points is (directly)
reachable from a given core point. One kernel is called from
the main loop, the other during cluster expansion.

We use the Lloyd-Algorithm [38] for the implementation
of the Kmeans [25], [26] algorithm. For OpenCL we use one
kernel that calculates in parallel the distance of a point to each
cluster center and saves the cluster number with the lowest
distance.

The buffers necessary for the execution of the kernels are
created with the CL_MEM_USE_HOST_PTR ﬂag set. The
memory is pinned beforehand to indicate the JVM that this
part of the memory must not be relocated. The data buffer has
also the CL_MEM_READ_ONLY ﬂag set.

For the multithreaded version, seven parallel threads are
used (eight cores are available on the device used, one is
left for the OS). Each thread is assigned a ﬁxed number
of data items. The total number of data items is distributed
equally among the the threads. For Java, the Thread class is
derived, whereas for C the pthread library is used. Semaphores,
locks (JAVA) and AtomicBoolean variables (JAVA) are used to
synchronize access to variables and for the program execution.
For both algorithms the memory needed for the execution
grows linearly with the total number of data items. For each
data item an additional 16 bit variable is used. For Kmeans this
variable holds the cluster number the data point is currently
assigned to. For DBSCAN the ﬁrst three bits indicate if the
data item has been visited and the density reachability. The
other bits are used to store the cluster number (0 equals to
noise). The ﬁrst three bits are deleted before the algorithm
ﬁnishes.

We use a ﬁxed set of features (1,2 or 4), a ﬁxed set of
generated clusters (2,4,6 or 8) and a ﬁxed set of cluster
sizes (128, 256, 512, 1,024 and 2,048). In total 60 different
combinations (tuples) of theses three variables are tested. We
here present the results for the values selected. However, our
approach supports data of arbitrary dimensionality, cluster
number and cluster size. The program we use also allows to

generate clusters with unequal cluster sizes.
For each pass a new random dataset

is generated. All
implementations of both algorithms use the same data. The
implementations leave the data unmodiﬁed. We generate nor-
mally distributed random data with randomly selected cluster
centers and randomly selected variances. Different variances
are allowed for each feature (if more than one feature is used).
All data items are shufﬂed randomly before the execution of
the data mining algorithms. Before a pass starts, the sequence
the methods are executes is also shufﬂed randomly.

The Kmeans algorithm has to search as many clusters
as have been generated and to terminate if the sum of the
absolute displacements of the cluster centers is less than 1e-6
or 100,000 iterations have been completed. The later restriction
should avoid endless loops due to cycling which occurs from
time to time with single precision. Fig. 2 shows an example
of six clusters to be detected by the Kmeans algorithm.

For the DBSCAN algorithm the number of neighbours is
set to ten times the number of features and the distance ((cid:15)) is
set to the square root of the number of features. Fig. 3 shows
the result of the DBSCAN algorithm. The same dataset as in
Fig. 2 was used.

Both algorithms were implemented in Java (single thread
and multithreaded), in C (single thread and multithreaded) and
in C with GPU support via OpenCL. All calculations were
carried out in single precision.

D. Statistical methods

We have used R [27] and Python3 [28] for the statistical
evaluation of the results. We did not perform an outlier
detection. We used the Shapiro-Wilk test [29] to see if data was
normally distributed. We have used the Brown-Forsythe-test
(R) [30] or the Levene-test (Python3) [31] for the analysis of
heteroscedasticity for not normally distributed data. In the case
of homoscedasticity we have used the Kruskal-Wallis [32] test

Fig. 2: Example Kmeans cluster identiﬁcation. Same dataset
as in Fig. 3 (six clusters generated; 2 features)

or the Wilcoxon [33] test to compare distributions. The Bon-
ferroni [34] correction was applied for the post-hoc analysis of
pairwise Wilcoxon-tests. In the case of heteroscedasticity we
have used the Median test [35]. We have used a signiﬁcance
level of α = 0.05.

The plots were produced with R, Python3 and Visual-
Paradigm (Visual Paradigm, Hong Kong, China). For the
analysis of the power consumption, data was imported into
a SQLite3 [36] database and processed by Python3.

III. RESULTS

In total 4272 tests have been executed on the device. For
each of the 60 possible tuples described above, between 65 and
76 tests have been made. For each test the wall clock time for
each of the ﬁve implementations and both algorithms has been
recorded. Additionally we have recorded the time that was
used for setting up the threads (in Java and C) and the GPU
(buffer allocation, program compilation). In total 16 intervals
per test have been stored. Furthermore we have tested if all
implementations of the DBSCAN algorithm returned the same
result. For the Kmeans algorithm the initial cluster centers
were selected randomly by each implementation and therefore
the results were not comparable.

A. Comparison of programming paradigms

Fig. 4 resumes the major ﬁndings of the wall clock times
(wct) recorded. The upper two rows show the wct for Kmeans,
the lower two those for DBSCAN. The x-axis labels are the
same for each column, therefore the x-axis labels are only
displayed in the lowermost ﬁgures. For both algorithms the
upper row shows the results for the smallest number of data
items, the lower row for the largest number of data items. The
ﬁrst column displays the results with respect to the cluster
number, the second with respect to the cluster size and the third

with respect to the features. Independently of the algorithm we
have noticed the following results:

• Pure C was always the fastest implementation.
• With longer executions times, Java tends to take longer

than all other implementations.

• For very short computation times, the GPU takes very
long with respect to all other implementations. The longer
the execution times becomes, the better perfoms the GPU
and becomes faster then Java (single and multithreaded).
• For very short computation times, multithreaded versions
they become better the
are also not competitive, but
longer the execution takes. Multithreaded C is always
faster than multithreaded Java, but multithreaded C is not
faster than single threaded C.

• The GPU implementation scales better with the number

of clusters and the input data size.
• Kmeans is much faster then DBSCAN.
Please not that in Fig. 4 the plots are log-plots (left and right
column) or log-log-plots (middle column). Both algorithms
depend linearly on the number of clusters. Nevertheless, we
choose to use a log scale on the y-axsis due to the very
large range of values to be displayed. For the log-log plots
different logarithms have been used on the abscissa (binary
logarithm) and the ordinate (common logarithm). On log-log
plots monomials (y = k·xα) appear as straight lines with slope
α. If on the abscissa the binary logarithm is used, the slope
transforms to 0.301029995664 · α. Kmeans depends linearly
and DBSCAN quadratically on the number of data items.

B. OpenCL overhead

The use of the GPU implies the overhead of setting up
the GPU (buffer allocation, program compilation, etc.). Fig. 5
shows the time needed for setting up the GPU and destroying
the buffers afterwards. The time for the execution of the
algorithms has been subtracted from the time taken in JAVA
before and after the JNI (Java native interface) calls. Therefore,
this time includes also the time needed for the JNI.

The difference of the medians is signiﬁcant (p < 0.05). The
median of the time needed for OpenCL was 141.514ms for
DBSCAN and 115.387ms for Kmeans. Sometimes the setup
of the GPU takes very long.

C. Thread overhead

Setting up threads is not for free either, but the time needed
is much shorter. Fig. 6 depicts the time needed for the setup the
threads. Again this time includes the time needed for the JNI.
The intervals are distributed unsymmetrically. The differences
of the medians between Java and C are signiﬁcant (p < 0.05)
for both groups. Table II shows the medians of the thread
setup times for multithreaded Java and C implementations of
DBSCAN and Kmeans. DBSCAN needs approximately twice
as much time for the setup as Kmeans.

Fig. 3: Example DBSCAN cluster identiﬁcation. Same dataset
as in Fig. 2. (six clusters generated with two features; three
clusters found; crosses are noise points)

D. Proﬁling

We have used Android’s Perfetto proﬁler that allows to
comfortably proﬁle Android devices. The sampeling frequency

Fig. 4: Wall clock time for DBSCAN and Kmeans. Further explanations see III-A

was set to the lowest possible value (100 or 250ms) depending
on the component tested. The execution time of the Kmeans
algorithm was too short to reliably proﬁle the algorithms given
the sampling frequency. Therefore, the proﬁling was made
only for DBSCAN. For the proﬁling tests six clusters, two
features and 1,024 data items per cluster were used.

1) GPU load: Fig. 7 depicts the GPU frequency (“GPU 0
Frequency”) and the GPU memory access (“GPU Memory”).
As GPU acceleration has been disabled, the GPU has almost

Fig. 5: Overhead for GPU setup

Fig. 6: Overhead for the setup and the destruction of threads

TABLE II: Medians for the thread setup times

DBSCAN Kmeans
5.467ms
10.579ms
1.778ms
3.198ms

Java
C

zero background activity and works only if the OpenCL
kernels are executed. The GPU kernels require very frequent
access to the memory.

2) Energy efﬁciency: Fig. 7 shows that there is not much
difference in the current while the program is executed. We
have investigates this ﬁnding more in detail.

We have proﬁled the counter for the electrical current
provided by the proﬁler. During the proﬁling the device was
attached to the computer (via USB) and therefore the device
was charging. The current counter indicates the net current of
the device (current out of the battery to the components minus
the charging current). The counter can become negative if the
charging current is larger than the current consumed by the
device.

We have run the test 25 times with the monitor turned on
all the time. We have integrated the battery current counter
values over the runtime of each algorithm and pass. These
integrals gave the electrical charge. Fig. 9 shows the boxplots
of the charge during the calculation for each method. The
distributions differ signiﬁcantly (p < 0.05) and the difference
of the medians is also signiﬁcant (p < 0.05). The median
of the charge was highest for Java and lowest for C. We have
analyzed the distributions of the single- and multithreaded Java
implementations separately and found no signiﬁcant difference
(p < 0.05)

We have divided each integral by the runtime of each pass.
This gave the mean current during the calculation for each
pass. This method respects the individual
intervals of the
calculations. There was no statistical signiﬁcant difference of
the distributions and medians (p = 0.85) regarding the battery
current during the calculations.

3) CPU frequency and idle states: Fig. 8 shows the CPU
frequency and idle states. The older UI version had to be
used to display the chart. The eight CPUs are shown from
the top to the bottom. In the lower part the Gantt chart for
the data mining algorithms are shown. The distance between
two vertical lines is 20 seconds (a total of 150 seconds have
been recorded). A C-state of zero indicates that the core is not
idle. Higher values indicate increasing C-states. When a core
enters a C-state, its frequency can become unreliable. Several
interesting facts can be observed.

• Despite a wake lock is held, the CPUs are allowed to

enter C-states.

• After the calculations have ﬁnished all cores enter almost
immediately a C-state and clock frequency is reduced.

• One core (#6) is almost all the time idle.
• Two cores (#6 + #7) exhibit a different pattern than the
others. The frequency changes seem to be less frequent
and happen on a coarser scale. Furthermore these two

Fig. 7: Chart of GPU frequency and power consuption (same trace as in Fig. 8)

Fig. 8: Chart of CPU frequency and C-states (same trace as in Fig. 7)

cores show always the same frequency, even if one of
them is idle.

• During multithreaded jobs, seven cores are running but

the maximum frequency is rarely attained.

• While data mining is performed on the GPU, at least

three cores are active.

• Single threaded versions of the DBSCAN algorithm are
always executed on core #7 while the others are idle.

IV. DISCUSSION

We have presented a framework including a wrapper library
that allows to execute arbitray OpenCL code on the GPU
of Android devices almost without modiﬁcation. We have
tested the Kmeans and the DBSCAN algorithms with this
framework. We have analyzed the wall clock time of these
two algorithms implemented with different programming lan-
guages and programming paradigms. As far as we know this
is the ﬁrst publication of a OpenCL framework for Android

Fig. 9: Charge during calculations. J mt = multithreaded Java,
C mt = multithreaded C

devices that links to the native OpenCL library on the device
only at runtime and not at compile-time.

We wanted to show, that it is possible to reliably perform
data mining tasks of moderate size on mobile devices. In
contrast to deep learning where complex and large models
have to be trained, data mining algorithms implemented in
standard programming languages often have a shorter runtime,
require less memory and have a smaller energy footprint.
We have selected these two algorithms because we wanted
to compare a fast and a slower algorithm and see if it
was possible to achieve relevant speedups with alternative
programming paradigms.

Due to the huge effort of setting up the GPU, OpenCL is
not well suited for fast algorithms. At least our results suggest
that the runtime of the GPU implementation scales better with
the workload. Both algorithms need very frequent access to
the memory because many distances have to be calculated.
DBSCAN needs more time to set up the GPU than Kmeans
because two kernels have to be compiled.

In earlier published papers the device’s OpenCL library
was linked directly to the Android binary during the build
process (e.g., [5], [9]). This build process reduces portability
signiﬁcantly, because the APK ﬁle has to be compiled for each
GPU. The authors of [5] admit that “This recipe is complicated
and clearly not designed to allow the easy execution of user
binaries.”. On POSIX (Portable Operating System Interface,
Austin Group [37]) compliant systems, shared libraries can be
loaded dynamically and do not have to be present at compile-
time. The symbols in the library must be resolved manually at
runtime. Android is not fully POSIX compliant but the POSIX
standards needed for this project are supported. Since Android
7, it is not any more possible to load arbitrary shared libraries
on the device at runtime. Vendor provided libraries are an
exception to this rule as long as their name appears in speciﬁc
ﬁle on the device. If they do not, or the list does not exist
at all, the shared OpenCL library on the device can not be
accessed by the program.

We have used single precision, because integrated GPUs
often do not support double precision. On the other hand,
GPUs (even the GPU used for this project) often allow to use
half precision. Half precision storage is supported by many
CPUs but half precision arithmetics is available only on some
Arm-v8 CPUs.

We used CL_MEM_USE_HOST_PTR ﬂag for the OpenCL
data buffers because we wanted to avoid unnecessary memory
copy operations. The GPU is an integrated GPU, therefore it
will most likely operate directly on the original buffer. We
did not declare the OpenCL data buffer as constant memory
because on integrated GPUs there is no difference between
global, local and constant memory and OpenCL devices are
required to provide constant memory buffers of only 64KB.
This limit is too low for data mining purposes.

For future project

the following methods could help to

exploit the GPU on Android devices better:

• Optimize for half precision

• Using the same allocated OpenCL memory buffers in
multiple different C methods (switching back and forth
from C to Java) is perhapes not advisable but one could
try to reuse the compiled kernels (either the version com-
piled for the device or some intermediate representation
[SPIR-V]).

• Programs that execute parts of their code on the GPU can
use the CPU for other tasks while they are waiting for
the results of the GPU.

Java multithreaded version performed better than Java ex-
cept for the case that very few data items had to be processed,
whereas multithreaded C implementations were never faster
than single threaded ones. This can be explained with the
asymmetric CPUs. The single threaded implementations were
all executed on the faster and much more advanced (out of
order execution) Cortex A73 cores, whereas the multithreaded
versions had to use the slower and less powerfull Cortex A53
CPUs. Moreover, these CPUs rarely attained the maximum
frequency. The time needed for the setup of the multithreaded
environment takes longer with DBSCAN because this algo-
rithm has to start twice as many threads (one set for the main
loop and one set for the cluster expansion) as Kmeans.

implemented
a

have
performed
the

a
clock_gettime
CLOCK_PROCESS_CPUTIME_ID

We have tried to measure the process and thread
separate C function
time. We
system call
that
and
with
CLOCK_THREAD_CPUTIME_ID ﬂags
the
is approach adds the JNI overhead to the time
fact
measured (Fast- and Critical-JNI calls are available on
Android devices only for the operating system) we have got
only unreliable values. We ware not able to use performance
counters in the source code.

set. Besides

that

We have used the ”WorkManager” framework, because
jobs can be scheduled in a comfortable way for a deferred
execution. The jobs have to marked as ”foreground service”
because as long as a foreground service is active, the device
will not enter the standby or doze mode (although the screen
might switch off). Furthermore, running as foreground service,
tasks are exempted from battery saving policies and are
allowed to use more than ten minutes for their completion.
The OS imposes that the user has to allow explicitly this
behaviour beforehand. The device was always charging during
the calculations because we wanted to preserve the battery life
and avoid charging cycles.

We have detected no signiﬁcant difference in the current
consumed during the calculations but we have found a signif-
icant difference of the charge. We were not able to measure
the electric potential of the battery or the power consumed and
can therefore not provide direct measurements of the power.
If the voltage of the battery is regarded as constant during the
measurement, the electric charge will allow to estimate the
power consumed.

The sampling frequency for the battery counters was 250ms
(lowest possible value). The current we have measured in-
cludes the current necessary for all components of the device
(e.g., monitor). We have tried to use the PowerRail con-

ﬁguration to measure the power consumed by the SoC but
unfortunately this feature was not present on the device. The
device used allows not only to proﬁle it externally (via an
USB-cable) but also after detaching it and using the developer
options. Unfortunately the device sets the sampling frequency
for the battery counters to 1000ms. This frequency is far to
coarse and can not be modiﬁed when sampling directly on
the device. The power consumption should be investigated in
future surveys with devices that have the PowerRail feature
enabled.

The background activity was very low for the GPU (see Fig.
7). Hardware acceleration had been switched of beforehand.
The background activity of the CPU seemed to be very low
as well. Once the calculations have, ﬁnished all CPUs enter
C-states and the frequencies drop to low values.

Possible future research could focus on the use of SIMD
(single data multiple data) instructions. SIMD instructions are
able to process several single or double values in parallel
(e.g., calculate a distance). These days compilers try to extract
automatically vector parallelism but sometimes hand coded
SIMD assembler is even faster. SIMD instructions can be used
with intrinsics (Arm NEON or Intel SSE) or using assembler
language together with C. Unfortunately this methods binds
the app to the platform the assembler language was written for.
OpenCL provides vector instructions as well. The compiler
decides how these vector instructions are translated (true
vector instructions or (unrolled) loops). We have used an Arm
Mali Bifrost GPU (Mali G71). These GPUs use quad-style
vectorization [39] and no explicit vectorization is required.
Scalar instructions are executed automatically in parallel.

GPUs are not ofﬁcially supported by Android. Moreover,
not all devices have an OpenCL compliant GPU. If in the
future GPUs should become ofﬁcially supported, for the
devices (including the emulators) a workaround must be found.
A shared OpenCL library compiled for the CPU (similar to
the POCL [40] project) could be used.

Executing data mining algorithms on remote devices can
help to preserve privacy for sensitive data and supersedes
an internet connection. Regarding the DBSCAN and Kmeans
algorithms, the results we have obtained depended on the
device used. Currently there are Android devices with more
powerful GPUs on the market.

V. CONCLUSIONS

it

We have shown that

is possible to use OpenCL on
Android devices in a portable and reliable manner. Existing
OpenCL programs can be integrated into apps almost without
modiﬁcations and without rebuilding the app. We have tested
two popular data mining algorithms (DBSCAN and Kmeans).
The implementations on the GPU as well as multithreaded
implementations suffer from a long setup time with respect to
the total execution time. On multicore systems with different
CPU properties, the runtime of single threaded programs can
be better than the runtime of a multithreaded version. We did
not ﬁnd any difference in the mean current consumed during
the calculations but the electric charge differed signiﬁcantly.

Algorithms that use the GPU (via OpenCL) cloud help to
improve execution time except for algorithms with a very short
runtime.

REFERENCES

[1] https://www.khronos.org/opencl/, accessed on August 27th, 2021
[2] P. Du, R. Weber, P. Luszczek, S. Tomov, G. Peterson, and J. Dongarra,
“From CUDA to OpenCL: Towards a performance-portable solution for
multi-platform GPU programming”, Parallel Computing, vol. 38, pp 391
- 407, 2012

[3] A. Acosta, C. Merino, and J. Totz, “Analysis of OpenCL Support
for Mobile GPUs on Android”, Association for Computing Machinery,
IWOCL’18, pp 1-6, 2018

[4] https://developer.android.com/guide/components/activities/

activity-lifecycle, accessed on August 27th, 2021

[5] J. Ross, D. Richie, S. Park, D. Shires and L. Pollock, “A case study of
OpenCL on an Android mobile GPU”, 2014 IEEE High Performance
Extreme Computing Conference (HPEC), 2014, p1-6

[6] G. Wang, Y. Xiong, J. Yun and J.R. Cavallaro, “Accelerating computer
vision algorithms using opencl framework on the mobile gpu - a case
study”, ICASSP ’13, 2014, pp2629-2633

[7] A. Acosta, S. Afonso, and F. Almeida, “Extending Paralldroid for the
Automatic Generation of OpenCL Code”, IWOCL ’16, Association for
Computing Machinery, 2016, article 17

[8] A. Acosta and F. Almeida, “Paralldroid: Performance Analysis of GPU

Executions”, Euro-Par ’14, 2014, pp387–399

[9] K. Wang, J. Nurmi and T. Ahonen, “Accelerating Computation
on an Android Phone with OpenCL Parallelism and Optimizing
Workload Distribution between a Phone and a Cloud Service”,
UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld 2016, pp636-642
[10] O. Valery, P. Liu and J.J. Wu, “A collaborative CPU–GPU approach
for principal component analysis on mobile heterogeneous platforms”,
Journal of Parallel and Distributed Computing, (120)2018, pp44-61
[11] O. Valery, P. Liu and J.J. Wu, “A collaborative CPU-GPU approach for
deep learning on mobile devices”, Concurrency Computat Pract Exper.
(31)2019, e5225

[12] S. Afonso, A. Acosta and F. Almeida, Francisco, “High-performance
code optimizations for mobile devices”, The Journal of Supercomputing,
(75)2019, pp1382-1395

[13] P. Fasogbon, E. Aksu and L. Heikkil¨a, “Demo: Accelerating Depth-Map
on Mobile Device Using CPU-GPU Co-processing”, Computer Analysis
of Images and Patterns. CAIP 2019. Lecture Notes in Computer Science,
vol 11678, 2019, pp75-86

[14] J. Wang, K. Rao and H. Ye, “An Application-Speciﬁc Approach to
Energy Optimization on Android Mobile Devices”, IEEE Transactions
on Mobile Computing, (19)2020, pp1492-1505

[15] L.N. Huynh, Y. Lee, Youngki and R.K. Balan, “DeepMon: Mobile GPU-
Based Deep Learning Framework for Continuous Vision Applications,
MobiSys ’17: Proceedings of the 15th Annual International Conference
on Mobile Systems, Applications, and Services, 2017, pp82–95
[16] V. Srinivasan, S. Moghaddam, A. Mukherji, K.K. Rachuri, C. Xu and
E.M. Tapia, “MobileMiner: mining your frequent patterns on your
phone”, UbiComp ’14: Proceedings of the 2014 ACM International Joint
Conference on Pervasive and Ubiquitous ComputingSeptember 2014,
pp389–400

[17] D. Yates, Z. Islam and J. Gao, “Implementation and performance
analysis of data mining classiﬁcation algorithms on smartphones”, 16th
Australasian Data Mining Conference (AusDM 2018), 996, pp331–343,
2019

[18] https://www.cs.waikato.ac.nz/ml/weka/, accessed on September 2nd,

2021

[19] D. Yates, Z. Islam and J. Gao, “DataLearner: A Data Mining and Knowl-
edge Discovery Tool for Android Smartphones and Tablets”, Advanced
Data Mining and Applications - 15th International Conference, ADMA
2019, Dalian, China, (11888)2019, pp828-838

[20] Weka-for-Android. https://github.com/rjmarsan/Weka-for-Android, ac-

cessed on September 1st, 2021

[21] https://developer.android.com/ml, accessed on August 28th, 2021
[22] https://docs.oracle.com/javase/8/docs/technotes/guides/jni/, accessed on

September 2nd, 2021

[23] M. Ester, H.P. Kriegel, J. Sander and X. Xu, “A density-based algorithm
for discovering clusters in large spatial databases with noise”, Proceed-
ings of the Second International Conference on Knowledge Discovery
and Data Mining (KDD-96). AAAI Press. pp226–231.

[24] https://de.wikipedia.org/wiki/DBSCAN, accessed on August 28th, 2021
[25] J. B. MacQueen, “Some Methods for classiﬁcation and Analysis of
Multivariate Observations” In: Proceedings of 5th Berkeley Symposium
on Mathematical Statistics and Probability. University of California
Press, 1967, pp281–297

[26] H. Steinhaus, “Sur la division des corps mat´eriels en parties”, Bull.

Acad. Polon. Sci. (4)1957, pp801–804

[27] R Core Team, “R: A Language and Environment for Statistical Com-
puting”, R Foundation for Statistical Computing, Vienna, Austria, 2018,
https://www.R-project.org/

[28] Python Software Foundation. Python Language Reference, version

3.6.12. Available at http://www.python.org

[29] S.S. Shapiro and M.B. Wilk, “An analysis of variance test for normality

(complete samples)”, Biometrika, (52)1965, pp591-611

[30] M.B. Brown and A.B. Forsythe, “Robust

tests for the equality of
variances”, Journal of the American Statistical Association, (69)1974,
pp364–367

[31] H. Levene, “Robust tests for equality of variances”, In: Ingram Olkin,

Harold Hotelling et al. (ed): Contributions to Probability and Statistics:
Essays in Honor of Harold Hotelling. Stanford University Press, 1960,
pp278–292.

[32] W.H. Kruskal and W.A. Wallis, “Use of ranks in one-criterion variance
analysis”, Journal of the American Statistical Association, (47)1952,
pp583–621

[33] F. Wilcoxon, “Individual Comparisons by Ranking Methods”, Biomet-

rics Bulletin, (1)1945, pp80–83

[34] C.E. Bonferroni, “Teoria statistica delle classi e calcolo delle proba-
bilit`a”, Pubblicazioni del Istituto Superiore di Scienze Economiche e
Commerciali di Firenze 1936

[35] A. McFarlane Mood, “Introduction to the Theory of Statistics” McGraw-

Hill Book Co., New York 1950, pp394–398

[36] https://www.sqlite.org/index.html, accessed on September 2nd, 2021
[37] IEEE, “IEEE Standard for Information Technology–Portable Operating
System Interface (POSIX(TM)) Base Speciﬁcations”, IEEE Std 1003.1-
2017 (Revision of IEEE Std 1003.1-2008), Issue 7, 2018, pp=1-3951

[38] https://de.wikipedia.org/wiki/K-Means-Algorithmus, accessed on Au-

gust 28th, 2021

[39] ARM Mali GPU OpenCL, Version 3.3, Developer Guide, 2012
[40] http://portablecl.org/, accessed on July 12th, 2020

