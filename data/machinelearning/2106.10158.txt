2
2
0
2

n
a
J

3
2

]

G
L
.
s
c
[

2
v
8
5
1
0
1
.
6
0
1
2
:
v
i
X
r
a

Published as a conference paper at ICLR 2022

LEARNING TO COMPLETE CODE WITH SKETCHES

Daya Guo
Microsoft Research
Beijing, China
t-dayaguo@microsoft.com

Jian Yin
School of Data and Computer Science
Sun Yat-sen University, China
issjyin@mail.sysu.edu.cn

Marc Brockschmidt, Miltiadis Allamanis
Microsoft Research
Cambridge, UK
{mabrocks,miallama}@microsoft.com

Alexey Svyatkovskiy
Microsoft
Redmond, WA, USA
alsvyatk@microsoft.com

Nan Duan
Microsoft Research
Beijing, China
nanduan@microsoft.com

ABSTRACT

Code completion is usually cast as a language modelling problem, i.e., contin-
uing an input in a left-to-right fashion. However, in practice, some parts of the
completion (e.g., string literals) may be very hard to predict, whereas subsequent
parts directly follow from the context. To handle this, we instead consider the
scenario of generating code completions with “holes” inserted in places where a
model is uncertain. We develop GRAMMFORMER, a Transformer-based model
that guides code generation by the programming language grammar, and compare
it to a variety of more standard sequence models.
We train the models on code completion for C# and Python given partial code
context. To evaluate models, we consider both ROUGE as well as a new metric
REGEXACC that measures success of generating completions matching long out-
puts with as few holes as possible. In our experiments, GRAMMFORMER gener-
ates 10-50% more accurate completions compared to traditional generative mod-
els and 37-50% longer sketches compared to sketch-generating baselines trained
with similar techniques.

1

INTRODUCTION

Recent high-capacity language models (LM) have shown that machine learning models are able to
generate coherent, realistic text, but it is often hard to guide them towards a speciﬁc goal, especially
when describing the intent is complex or more costly than manually generating the target output.

One such scenario are LMs of source code (LMC). Since Hindle et al. (2012) increasingly sophis-
ticated LMCs have been built, including transformer-based ones, such as those of Svyatkovskiy
et al. (2020); Feng et al. (2020); Chen et al. (2021) and various similar unpublished models such
as TabNine and SourceAI. These models generate full sequences of code tokens left-to-right with
any preﬁx acting as the (partial) user intent. While LMs generate realistic-looking outputs, they are
known to occasionally “hallucinate” (Puduppully et al., 2019; Malmi et al., 2019; Maynez et al.,
2020; Liu et al., 2021), i.e. generate plausible but incorrect content. This is particularly problematic
in generating source code, where small mistakes can lead to erroneous code that is very hard to
debug or introduces vulnerabilities (Pearce et al., 2021).

In this work, we investigate models that can decline to make predictions in places where there is
high uncertainty (e.g., where the user should choose a name), but continue generating around these
“holes”. For example, in Fig. 1(left) a developer has typed some code and is about to type the next
line. A likely completion is to consume more command line arguments, but their name is unclear

1

 
 
 
 
 
 
Published as a conference paper at ICLR 2022

Code Context:

1 import sys
2 target = sys.argv[1]
3 I

Ground-Truth:
ID = sys.argv[2]

Suggested Code Completions:

L → R
L → R + ⦸
L → R + (cid:4)
Copilot
GRAMMFORMER (cid:4) = sys.argv[2]

target = target.replace("\\", "/")
target =
print(target)
(No suggestion)

Figure 1: A sample snippet (left; abbreviated from Fig. 12 in Appx. A). A developer has just typed
the code and their cursor (in blue) is at line 3. Code completions provided by a number of models
are shown on the right, where L → R is a standard LMC and GRAMMFORMER is our new model.

from the context. A traditional generative model (e.g. Fig. 1; top right) may choose to provide a
completion that exists in the training data, but is not clearly called for here. On the other hand, a
model able to explicitly mark where it is uncertain (Fig. 1; bottom right) makes it clear to a user
where further input is required.

However, creating such models is not trivial. A simple ﬁrst attempt may be to use a standard LMC,
but output a “hole token” (cid:4) whenever the model is uncertain about the next output token. However,
continuing after the “(cid:4)” then becomes infeasible, as the LMC was not trained on such data. Hence,
a suitable training dataset and objective need to devised. As no large datasets with holes exist, we
instead choose to use a reinforcement learning approach in which our reward function encourages
the model to make “long” predictions with as few “(cid:4)” tokens as possible, but to avoid making
incorrect predictions. We found that standard left-to-right sequence models perform poorly on this
task. Hence, we developed GRAMMFORMER, a model that construct suggestions by generating a
(partial) syntax tree, but which has the option of leaving non-terminals in its output.

Contributions (1) We present GRAMMFORMER, a transformer-based model that generates code
based on the programming language grammar and can predict hole tokens rather than output it is
uncertain about. (2) We develop REGEXACC, a metric that can evaluate the ﬁt of predictions with
holes. (3) We evaluate GRAMMFORMER on large corpora of Python and C# code and show that
GRAMMFORMER can make longer and more precise statement-level sketch completions compared
to a number of baselines.

2 METHOD

Our aim is to predict code completions as sketches, a mix of actual tokens and “holes” (cid:4), which
are meant to signify that the model is unable to make a useful prediction within the given context
and further user input is required. Formally, we consider models that take a context sequence x of
tokens as input and have to produce an output sequence y; intuitively, x is what the user typed so far,
and y is the suggestion presented to the user. In our setting, y is a sketch, a mix of tokens from the
programming language and the special token (cid:4) signifying a “hole” that could be ﬁlled by an arbitrary
sequence of tokens. For example, t = foo((cid:4)) is a sketch corresponding to assigning the return
value of function foo to variable t, but leaves the arguments of the function call undetermined.

Metric A good sketch is one that (a) can be completed into the correct output and (b) is as precise
as possible. To measure how successful a method is in doing so, we deﬁne a new metric REGEXACC.
For (a), we use toRegex(ˆy) to turn a predicted code sketch ˆy into a regular expression by replacing
all holes with the wildcard matching any non-empty sequence (“.+” in Perl Compatible Regular
Expression syntax). If the regex matches the ground truth, matches(⋅, ⋅) returns a score of 1
otherwise it returns 0. To implement (b), we scale this result by the proportion of terminal tokens
predicted, by deﬁning nTokens(ˆy) as the function that returns the number of non-hole symbols in
ˆy. More formally, assume an output sketch ˆy and a ground-truth sequence y
does not
contain any (cid:4) tokens. REGEXACC is then deﬁned as

, where y

∗

∗

REGEXACC(ˆy, y

∗

) ≜ matches(toRegex(ˆy), y

∗

) ⋅

nTokens(ˆy)
nTokens(y∗
)

.

Beyond REGEXACC, we also consider ROUGE (Lin, 2004), since a sketch can be thought as a form
of a “summary” of the target text. For this, we use a helper function ERASEHOLES(ˆy) that simply

2

Published as a conference paper at ICLR 2022

⟨Expr⟩

⟨ParenthesizedExpr⟩
⟨Expr⟩

⟨Expr⟩

x(0):
x(1):
x(2):
x(3):
x(4):
x(5):
x(6):
x(7):
x(8):
x(9):

r =
r =
r =
r =
r =
r =
r =
r =
r =
r = x

⟨Expr⟩
⟨Expr⟩
⟨Expr⟩
⟨Expr⟩
⟨Expr⟩
⟨Expr⟩
⟨Expr⟩
⟨Identiﬁer⟩

*
* (
* (
* (
* (
* (
* (
* (
* (

⟨Expr⟩
⟨Expr⟩
⟨Expr⟩
⟨Expr⟩
⟨Expr⟩
⟨Expr⟩
⟨Expr⟩

-
-
-
-
-
-
-

⟨Identiﬁer⟩ (
foo
foo
foo
foo
foo

)
⟨ArgList⟩
( ⟨ArgList⟩
)
( ⟨Identifer⟩ )
)
(
)
(
(
)
the sketch r = x * ((cid:4)-
Figure 2:
foo(args)) by GRAMMFORMER. Each line represents consecutive x(t) in Alg. 1. Terminal
tokens are shown in monospace blue font. The underlined non-terminal at position i(t) is se-
lected by Ps and its expansion is generated by Pe, i.e. the output underneath the selected (under-
lined) non-terminal. Fig. 5 and Fig. 6 in Appx. A show real example generation sequences from our
datasets.

Progress of grammar-based code generation of

args
args
args

i(0) = 3
i(1) = 5
)
i(2) = 6
)
i(3) = 8
)
i(4) = 8
)
i(5) = 10
)
i(6) = 10
) i(7) = 6
) i(8) = 6
) i(9) = ⦸

drops all (cid:4) tokens, and then consider ROUGEF1(ERASEHOLES(ˆy), y
errors than REGEXACC and gives partial credit to non-matching but plausible sketches.

). ROUGE is more lenient to

∗

2.1 LINEAR CODE SKETCH GENERATION

First, we consider the idea of generating code sketches using a standard generative model for lan-
guage. To this end, we simply extend the vocabulary with the special “(cid:4)” token. An obvious
problem is that while we have plenty of training data for a standard generative model, we do not
have training data for outputs y that contain the (cid:4) token. Consequently, we cannot train the model
in a fully supervised fashion, and instead turn to reinforcement learning. Concretely, we devise a
reward function r(⋅) that averages REGEXACC and ROUGE, i.e. for a predicted output sketch ˆy and
a ground truth output (without (cid:4) tokens) y
, we deﬁne

∗

r(ˆy, y

∗

) =

1
2 (REGEXACC(ˆy, y

∗

) + ROUGEF1(ERASEHOLES(ˆy, y

∗

)) .

(1)

Using the combination of ROUGE (which does not consider holes) and REGEXACC is crucial here,
as ROUGE is much “smoother” compared to REGEXACC, which is 0 for all but very few predictions,
allowing us to measure partial improvement. We use our reward function from Eq. 1 to evaluate the
quality of the output of the full model and compute a loss. Inspired by Paulus et al. (2017) we use
self-critical policy gradient training (Rennie et al., 2017) and for a prediction ˆy we minimise

∗

∗

(2)
Here, ˜r(x) is the reward achieved by the prediction from the snapshots of the model that achieved
the best score so far and Lgen is the loss of the generative model. Intuitively, this objective rewards
models that improve upon the previous best policy with respect to r.

) − ˜r(x)) ⋅ Lgen (x, ˆy)

) = (r(ˆy, y

L(x, y

To model this in practice, we use a standard encoder/decoder Transformer model Vaswani et al.
(2017); Radford et al. (2019), “translating” the context x into the output y using separate encoder
and decoder models. We additionally also consider the language modelling case, i.e., a model that
conditioned on x predicts token y0, conditioned on x, y0 predicts token y1, etc..

Pretraining In practice, we found that directly training a sequence model to maximise Eq. 1, is
very slow and does not converge to a useful model. Instead, we heuristically generate a dataset
suitable for supervised pretraining. We replace random AST non-terminals of the target output by
(cid:4) and generate target sequences. These contain terminals and zero or more (cid:4). We then pretrain the
model on this dataset to convergence, and then ﬁne-tune it using the reward of Eq. 1.

2.2 GRAMMAR-BASED CODE SKETCH GENERATION

In our experiments, we found the simple extended sequence model from above to not per-
form well, in particular, (cid:4) tokens would not replace semantically meaningful subsequences (e.g.

3

Published as a conference paper at ICLR 2022

Algorithm 1 GRAMMFORMER generative process, given an input sequence x(0).

for t = 0, 1, 2, ... do

i(t) ∼ Ps (i ∣ x(t), N (x(t)))
if i(t) = ⦸ then
break

▷ sample non-terminal position from N (x(t)) to expand
▷ if x(t) does not contain non-terminals or none was selected by Ps
▷ stop generation
▷ sample expansion of non-terminal at position i(t)
▷ create x(t+1) by replacing non-terminal at i(t) by u(t)
⊚i(t)
return NONTERMINALSTOHOLES(x(t))▷ convert remaining non-terminals to holes and return

u(t)
⊚i(t) ∼ Pe (u ∣ x(t), i(t))
x(t+1) ← x(t)
<i(t)

∶∶ u(t)
⊚i(t)

∶∶ x(t)
>i(t)

“szconv.(cid:4))” does not contain a left parenthesis and requires the user to ﬁll it in.). To resolve
this, we developed GRAMMFORMER, a grammar-guided model. It generates code by following the
structure of the context-free grammar (CFG) deﬁning the programming language syntax, iteratively
expanding non-terminal symbols. Crucially, it can choose to not expand some non-terminal symbols,
which can then be presented as (cid:4) to the user. In traditional grammar-based generation of text (Cohen
et al., 2012) or code (Maddison & Tarlow, 2014; Yin & Neubig, 2017; Allamanis & Sutton, 2014;
Bielik et al., 2016), the CFG is followed by sequentially expanding the left-most, bottom-most non-
terminal symbol, using one of the production rules of the grammar. GRAMMFORMER changes this
and instead selects which (if any) non-terminal symbol to expand. An example generation is dis-
played in Fig. 2.

Probabilistic Model A CFG is deﬁned as a tuple (Σ, N , S, R) where Σ is a set of terminal sym-
bols, N is a set of non-terminal symbols, S ∈ N is the root symbol and R is a set of production rules.
We denote non-terminals as ⟨NonTerminalName⟩. GRAMMFORMER can be viewed as a sequence-
to-sequence model transforming x = x0, x1, ..., xn into a new sequence in which one non-terminal
symbol xi has been replaced by a new sequence of new symbols, according to a production rule of
the grammar. Examples of such sequences and rewrites are shown in Fig. 2.

GRAMMFORMER does this rewriting in two steps. First, a non-terminal selector model Ps selects
a non-terminal in x to expand and then the non-terminal expansion model Pe determines how to
expand it. To deﬁne Ps, let N (x) = {i ∣ xi ∈ N }∪{⦸} denote the set of non-terminal positions in x
and a special “stop expansion” ⦸ symbol. Conditioned on x, Ps produces a probability distribution
over N (x). In turn, Pe is conditioned on x and a position i ∈ N (x) and models a probability
distribution over expansion sequences u ∈ (Σ ∪ N )
. Note that factorising GRAMMFORMER
into two models Ps and Pe is an important modelling decision: how to best expand a non-terminal
is entirely separated from predicting whether a hole should be introduced. These two concepts
are intermixed in standard (sequence) decoders. In practice, we deﬁne both models using neural
architectures with partially shared parameters, as discussed below.

∗

Alg. 1 shows a high-level description of GRAMMFORMER, in which Ps and Pe are used repeatedly
to select and expand non-terminals (not necessarily the left-most one), until none are left or the Ps
indicates that expansion should stop. Here, NONTERMINALSTOHOLES(⋅) replaces all remaining
non-terminal symbols with a hole (cid:4). Note that GRAMMFORMER is not context-free, taking into
account the whole input sequence when expanding a non-terminal. Second, in contrast to many
grammar-based methods (Yin & Neubig, 2017; Bielik et al., 2016), any non-terminal can be ex-
panded at each step. Finally, Pe is not directly constrained to follow the production rule set R, but
can generate any sequence. In practice, it learns to follow to the rules of R from the data, but this
ﬂexibility is important for handling string literals and argument tuples of variable length.

Neural Model To implement Ps and Pe, we use a shared encoder module that computes a rep-
resentation of the input sequence x = x0, . . . , xn as vectors e0, . . . , en, ei ∈ RD, where D is a
hyperparameter. Our encoder module is a Transformer (Vaswani et al., 2017), given the impres-
sive results of transformer-based models in NLP and code (Feng et al., 2020). Other architectures
(RNNs, 1D-CNNs, Transformer variants) would be suitable as well, but we leave their study for
future work.

4

Published as a conference paper at ICLR 2022

Ps is implemented similar to a pointer network on top of this encoder module, i.e.

Ps(i ∣ x) = softmax
i∈N (x)

(f (ei)) ,

where f is a learnable feed-forward neural network. For our purposes, we deﬁne e⦸ as the repre-
sentation of the special start symbol [CLS] used in our Transformer encoder.

The expansion model Pe follows a standard autoregressive decoder formulation, i.e.

Pe(u ∣ x, i) =

m
∏
j=1

Pdec(uj ∣ e0, . . . , en, i, u<j).

We implement Pdec as a (causal) relational Transformer decoder, similar to Wang et al. (2019).
Relational transformers augment the attention mechanism by incorporating predeﬁned relationships
among elements; attention scores are then biased by learnable weights for each relation. In GRAMM-
FORMER, we only use a single relation, connecting each token to the expanded non-terminal token
xi, to help the model focus on the token it needs to generate an expansion for.

Objective Due to the lack of supervised data, we employ reinforcement learning to train GRAMM-
FORMER. We use our reward function from Eq. 1 to evaluate the quality of the output of the full
model. We use self-critical policy gradient training as in Eq. 2 and minimise

L(x, y

∗

) = (r(ˆy, y

∗

) − ˜r(x)) ⋅

T
∑
t=0

(− log Ps (i(t) ∣ x(t)) − I (i(t) ≠ ⦸) ⋅ log Pe ((u(t)

∗
⊚i(t))

∣ x(t), i(t))) .

(3)

Here, ˜r(x) is the reward achieved by the snapshots of Ps and Pe that achieved the best score so far.
The rest of the objective follows the iterations of the loop in Alg. 1, where t is the iteration index,
is the ground-truth sequence of terminals, and I(⋅) is the indicator
ˆy is the predicted sketch, y
function.

∗

Pretraining As in the sequence model, directly training with the RL objective Eq. 3 is computa-
tionally intensive due to the sampling requirement. We again use a pretraining strategy. First, we
train Pe to expand every non-terminal, independently of the expansion order learned by Ps. To do
this, we use the input training examples and follow Alg. 1, but instead of sampling from Ps(⋅), we
sample i(t) from a uniform distribution over the non-terminals in x(t), ̃N (x(t)) = {i ∣ xi ∈ N }.
This yields sequences of intermediate sketches x(t) for each example. Furthermore, for each x(t),
∗
we compute the ground-truth expansion (u(t)
for all non-terminals i ∈ ̃N (x(t)). We can then
⊚i )
pretrain Pe using the supervised objective

Lpre, e (x(t), (u(t)
⊚i )

∗

i∈ ̃N (x(t))) =

1
∣ ̃N (x(t))∣

⋅ ∑

i∈ ̃N (x(t))

− log Pe ((u(t)

⊚i(t))

∗

∣ x(t), i) ,

i.e. the negative log-likelihood of the correct expansion for all non-terminals in x(t). This computa-
tion is more computationally efﬁcient compared to the one in Eq. 3 since the cost of encoding x(t)
is amortised across all potential expansions and no sampling is required. Once Pe is pretrained, we
pretrain Ps. For this, we ﬁx the weights of the shared encoder module, and optimise only the re-
maining parameters of Ps through Eq. 3. Once we have a pretrained both models, we then ﬁne-tune
all model weights end-to-end, using Eq. 3.

Optimisation: Grammar Flattening Following the formal grammar of a programming language
commonly introduces tedious expansions. For example, the Python non-terminal ⟨Call⟩ is always
expanded to ⟨Expr⟩(⟨ArgumentList⟩), and the C# non-terminal ⟨NotEqualOp⟩ is always ex-
panded to the terminal !=. We “ﬂatten” the grammar by replacing non-terminals such as ⟨Call⟩
and ⟨NotEqualOp⟩ with all their possible expansions. In Appx. C we provide the list of the ﬂat-
tened non-terminals. Note that if we repeated this process for all non-terminals except from the
starting symbol S, GRAMMFORMER would degenerate into a standard encoder-decoder model.

5

Published as a conference paper at ICLR 2022

Beam Search At test time, we employ a two-step beam search, and replace sampling from Ps
and Pe with their top-ν outputs, keeping a beam of size k. First, for each x(t) in the beam, we
compute Ps and select the top-m non-terminal positions to expand. For each of those m positions,
we sample the top-n expansions from Pe using a standard beam search. We compute the likelihood
of all k ⋅ n ⋅ m results, and then keep only the top-k. This process (detailed in Appx. E) is similar to
a standard beam search but takes into account that two submodels are used.

Computational Cost GRAMMFORMER’s ability to predict sketches comes with additional com-
putational cost compared to standard transformer encoder-decoder models: since at each iteration of
the loop in Alg. 1 x(t) changes, Ps and Pe must be recomputed. This means that the encoder-decoder
needs to run once on each partial sequence, in contrast to left-to-right causal generation, in which
intermediate results can be re-used. Future work may consider selecting more than one element to
expand from N (x(t)) to expand at each step, reducing the total number of expansion steps, similar
to Welleck et al. (2019); Stern et al. (2019).

3 EVALUATION

To empirically evaluate the ability of our models to learn to predict useful code completions, we use
the metrics REGEXACC and ROUGE as discussed above. Note that we measure these only on the
newly generated output sequence, i.e. we ignore the “prompt” of context tokens.

Datasets To collect a dataset, we clone all non-fork repositories with more than 20 stars on GitHub
that have C# or Python as their top language. Then, we deduplicate the corpus using the method
of Allamanis (2019); Lopes et al. (2017). Finally, we parse all ﬁles into a syntax tree using Tree-
sitter, ignoring any ﬁles that cannot be parsed using the v0.19.0 grammar deﬁnitions. Finally, we
split the ﬁles into 70-10-20 train-validation-test. To create (pre-)training examples, i.e. inputs to
Alg. 1, we search the syntax tree of each ﬁle and for each ⟨SimpleStatement⟩ non-terminal create
an example. The syntax tree rooted at the ⟨SimpleStatement⟩ non-terminal is then used to get the
ground-truth expansions during pre-training and the ground-truth expansion y
. For our test set,
we randomly sample a ⟨SimpleStatement⟩ non-terminal for each ﬁle to evaluate and obtain 318K
(resp. 362K) examples for C# (resp. Python). For each example, x is the 200 terminal tokens before
the ⟨SimpleStatement⟩ non-terminal. More details about the dataset can be found in Appx. B.

∗

Baselines Since we are not aware of any prior model that targets code completion with sketches,
we consider two Transformer-based baselines. We consider both the sequence-to-sequence setting
using separate encoder and decoder models (Vaswani et al., 2017) as well as the language modelling
setting (where there is no distinction between encoder and decoder). We refer to these as “L → R”
and “LM ”. We use “L → R” to denote a standard Transformer encoder-decoder model (Vaswani
et al., 2017) used in sequence-to-sequence tasks. Additionally, we consider “L → R + ⦸” and
“LM + ⦸”, which are trained to stop generation by inserting a ﬁnal (cid:4) token that captures any sufﬁx.
Note that this models can only generate sketches that are preﬁxes of the target completion, i.e. it
corresponds to a standard token-level generative model with a learnable stopping ability. To train
this model, we use self-critical policy gradient training (as in Eq. 2).

Model Training We provide the training details for all experiments. Most of our models use a
6-layer Transformer as encoder and 6-layer Transformer as decoder, each with a hidden dimension
of 768 and 12 attention heads, with the exception of the LM model (and its variations), which uses
a single 12-layer Transformer, to match the number of parameters of the other models. We set the
intermediate dimension of each Transformer layer as 3072 and use 3 fully-connected layers with
3072, 768 and 1 hidden sizes as the feed-forward neural network f in the selector model Ps. The
vocabulary is constructed using byte-pair encoding (Sennrich et al., 2015) and the vocabulary size is
25 000. We set max length of input and output sequences as 512 and 64, respectively. We train the
model with Adam optimiser using a learning rate of 2e-5 and batch size 4 096. We used automatic
mix precision. Training was performed on 64 NVIDIA Tesla P100 with 16GB memory for 10 days.
During beam search we use k = 5, n = 1 and m = ∞, i.e. we consider all non-terminal positions
in each x(t). We selected these numbers during early experiments as a reasonable trade-off between
speed and predictive performance.

6

Published as a conference paper at ICLR 2022

Table 1: Performance of GRAMMFORMER compared to baselines for Python and C#.

C#

Python

REGEXACC

ROUGE Avg

REGEXACC

ROUGE Avg

Top 1

Top 5

Len

Top 1

Top 5

LM
L → R
LM + ⦸
L → R + ⦸
LM + (cid:4)
L → R + (cid:4)
GRAMMFORMER (pre-trained only)
GRAMMFORMER

0.42
0.42
0.42
0.45
0.44
0.45
0.45
0.47

0.52
0.47
0.49
0.54
0.54
0.55
0.57
0.59

75.7
77.0
70.9
69.1
73.3
73.5
77.0
77.4

8.0
7.1
6.8
5.3
6.3
5.8
7.2
7.5

0.18
0.17
0.19
0.20
0.20
0.18
0.20
0.21

0.24
0.20
0.25
0.29
0.27
0.22
0.29
0.30

Len

8.6
5.8
7.3
3.0
6.6
4.7
5.7
6.1

51.0
53.2
49.5
39.3
53.9
48.9
50.2
51.6

(a) C#

(b) Python

Figure 3: Sketch length vs. ground-truth length

Results Tbl. 1 shows the results for all considered models. For both Python and C#, GRAMM-
FORMER outperforms the baseline methods in terms of REGEXACC, showing that the grammar-
based generation can create better sketches compared to simpler methods. Note that although L → R
has a comparable or better ROUGE score, it does substantially worse than GRAMMFORMER with re-
spect to REGEXACC, meaning that the predictions are “similar” but the sketches contain errors (i.e.
do not match the ground-truth). This means that if a code completion system suggested the full
output of L → R, the user would have to pause and correct the suggestion more frequently. On the
other hand, L → R + ⦸ improves over L → R in terms of REGEXACC but has a worse ROUGE and
generates signiﬁcantly shorter suggestions (5.3 vs. 7.5 tokens-long for C#). This is expected since
L → R + ⦸ is trained to be more “conservative” (i.e. avoid incorrect suggestions) but is also unable
to introduce holes beyond the last generated token. Finally, we can see that while GRAMMFORMER
already performs well after our pre-training procedure, we can further improve its performance with
our ﬁne-tuning technique. We believe that this is because when Ps and Pe are trained jointly, they
co-adapt: some of the capacity of the shared encoder module that is used to make predictions for
hard-to-expand non-terminals is “freed” since Ps learns to not expand them.

Fig. 3 shows how the length of the generated code sketch relates to the length of the ground truth
expression. While the differences between models are small for short target sequences, GRAMM-
FORMER generates substantially longer suggestions than other models when more complex sugges-
tions are required. In particular, the L → R + ⦸ model generates very short suggestions, as it is
trained to stop generation whenever it reaches a point at which it is uncertain about the next token.

Fig. 4 in turn shows how often the suggested sketch was correct dependent on the length of the
ground truth token sequence. Here, L → R + ⦸ does best because it generates the shortest (i.e., least
determined) predictions, which is exactly the trade-off captured by our REGEXACC metric. Of the
models that generate longer suggestions, GRAMMFORMER clearly does best, with the improvement
becoming more pronounced with the length of the target sequence. Note that the performance of the
models on C# is generally better compared to the performance in Python. We believe that this has
to do with the grammar of each language and the patterns it induces within the developer’s code.

7

234567891011121314151617181920Ground-truth length0.02.55.07.510.012.515.017.520.0Sketch lengthL->RL->R with Stop PolicyL->R with HolesGrammFormer234567891011121314151617181920Ground-truth length0.02.55.07.510.012.515.017.520.0Sketch lengthL->RL->R with Stop PolicyL->R with HolesGrammFormerPublished as a conference paper at ICLR 2022

(a) C#

(b) Python

Figure 4: Percent Correct (i.e., matching) sketches (top-1 generated sketch) vs. ground-truth length

Table 2: Performance for GRAMMFORMER ablations (C#), for different Ps and reward functions.

REGEXACC

ROUGE Avg Length

GRAMMFORMER
Random expansion, no ⦸
Random expansion, ⦸ at ﬁxed threshold
GRAMMFORMER, r(⋅) = ROUGEF 1
GRAMMFORMER, r(⋅) = REGEXACC
L → R
GRAMMFORMER, no ⦸

Top 1 Top 5

0.47

0.42
0.45

0.42
0.51

0.42
0.42

0.59

0.54
0.57

0.54
0.62

0.47
0.55

77.4

78.3
71.6

78.2
70.8

77.0
78.1

7.5

8.1
5.8

8.1
5.8

7.1
8.2

Casalnuovo et al. (2019); Karampatsis et al. (2020) have observed a similar phenomenon on the
perplexity across (standard left-to-right) language models for different programming languages.

Ablations Next, we look into ablations of GRAMMFORMER and reason about how its components
perform. To this end, Tbl. 2 shows the performance of different model variants on the C# dataset.

First, we analyse the effect of the selector model Ps. To this end, we consider two ablations. The ﬁrst
is the “random expansion” model, in which the non-terminal token to expand is sampled uniformly at
random from the full set of non-terminal symbols, and which hence does not stop expansion as long
as any holes are remaining. This is effectively GRAMMFORMER after our pre-training procedure
for Pe. This model achieves the best ROUGE score, but a relatively bad REGEXACC, as it is forced
to generate a prediction even when it is very uncertain. The second ablation, a “ﬁxed threshold”
model is similar to our ﬁrst ablation, but stops expansion when the probability of the generated
x(t) falls below a threshold. We choose this threshold on the validation set. This model makes
shorter, but more accurate sketch predictions compared to the “random expansion”, but is worse
than GRAMMFORMER. These two ablations demonstrate that our learned Ps is required for best
performance.
Second, we consider the effect of using different reward functions r(⋅) in the training of GRAMM-
FORMER. Concretely, whereas we use the mean of REGEXACC and ROUGE in GRAMMFORMER,
we now consider using only a single of these two metrics. As expected, the results on the correspond-
ing metric improve, with a substantial cost in the other metric. Concretely, using only REGEXACC
leads to signiﬁcantly shorter predictions with a low ROUGE score. We believe that this is because
REGEXACC is a strict metric, returning 0 if the sketch does not match, which leads to sparse rewards
and makes the resulting model more conservative at expanding non-terminals.

Finally, to evaluate the beneﬁt of the grammar-guided decoder, we consider a variant of GRAMM-
FORMER that does not allow the introduction of (cid:4) and instead has continue expansion until no
non-terminals exist anymore. This variant can be compared to L → R, which also cannot stop or

8

234567891011121314151617181920Ground-truth length0.00.20.40.60.81.0AccuracyL->RL->R with Stop PolicyL->R with HolesGrammFormer234567891011121314151617181920Ground-truth length0.00.20.40.60.81.0AccuracyL->RL->R with Stop PolicyL->R with HolesGrammFormerPublished as a conference paper at ICLR 2022

introduce (cid:4) tokens. Our ablation shows that there is substantial beneﬁt in using grammar-guided
decoding, leading both to longer predictions as well as more correct ones.

3.1 QUALITATIVE EVALUATION

Having observed the quantitative results, we now turn our attention to a qualitative look at the
results and show some cherry-picked examples that illustrate desired and undesired behaviours of
GRAMMFORMER and the baselines, where we also include the suggestions of the GitHub Copilot
system GitHub (2021). Fig. 1 shows an example and eleven more are shown in Appx. A. Fig. 1
illustrates the importance of generating sketches instead of concrete sequences of terminal tokens:
oftentimes, the code context does not provide sufﬁcient information about the user’s intent. Sketch-
generating models can offer more informative suggestions given the partial intent.
Of course, GRAMMFORMER also makes mistakes. For example, GRAMMFORMER and L → R + ⦸
are sometimes “too” conservative (e.g. Fig. 15 in Appx. A) generating holes where L → R generates
fully concrete completions. This suggests future research opportunities for better calibration of Ps.

Finally, a pure language modelling approach to code completion will always be insufﬁcient. For
example, user-deﬁned types and rare APIs cannot be predicted by a language model, since the
names of the APIs cannot be known during training (Fig. 7 and Fig. 17 in Appx. A). Researching
methods to scalably introduce information from static analyses and additional context may alleviate
this problem.

4 RELATED WORK

One of the most successful applications of LMCs is code completion (Svyatkovskiy et al., 2019;
Karampatsis et al., 2020). Transformer LMs have been recently shown exceptional performance at
the task being able to predict relatively long sequences of code (Svyatkovskiy et al., 2020; Chen
et al., 2021). Grammar-based code completion and generation has been researched with neural
(Maddison & Tarlow, 2014; Yin & Neubig, 2017; Kim et al., 2021) and non-neural models (Bielik
et al., 2016), always expanding the left-most, bottom-most non-terminal. In contrast to GRAMM-
FORMERs, all these models target the generation of complete code without the ability to create
sketches. R3NN (Parisotto et al., 2017) generates only complete programs of a simple string trans-
formation DSL but expands the non-terminal with the highest conﬁdence, instead of the left-most,
bottom-most one, similar to GRAMMFORMER. In contrast to the aforementioned models, GRAMM-
FORMER does not maintain an explicit tree representation but instead uses the sequences of leaves
in the generation tree.

Sketch-like ideas appear in NLP such as the coarse-to-ﬁne semantic parsing of Dong & Lapata
(2018) and chat-bots of Shum et al. (2019). However, sketches are extracted deterministically to
create a supervised dataset. Similarly, SketchAdapt (Nye et al., 2019) uses a sequence model to
generate sketches for small functional programs of a simple DSL towards speeding-up enumerative
program synthesis from input-output examples. SketchAdapt is also trained as a supervised sketch
generator. A supervised corpus is created by enumerating all possible sketches and selecting the one
with the highest-probability and within a heuristically computed time budget. In GRAMMFORMER
domain, enumerating all sketches is computationally intractable due to the complexity of general-
purpose programming languages while no similar heuristic exists for code completion.

Recently, sequence generation approaches that go beyond the left-to-right paradigm have been pro-
posed (Welleck et al., 2019; Stern et al., 2019; Gu et al., 2019; Ford et al., 2018; Lee et al., 2018; Shah
et al., 2018), usually by considering generation as an iterative reﬁnement procedure that changes or
extends a sequence in every iteration. These models often aim in speeding-up inference or allowing
models to ﬁgure a better order for generating a full sentence (of terminal tokens). However, since
these models focus on natural language and since its grammar is not deﬁned a priori, these methods
do not follow a language grammar which effectively limits the space for sketch generation. Addi-
tionally, these work generate full utterances of text, rather than sketches. Future work may consider
combining ideas in GRAMMFORMER with those models.

A related concept is learning to abstain (Ziyin et al., 2019) where a model learns to predict a “don’t
know” when it is uncertain about the outcome of a classiﬁcation task. This resembles the stop

9

Published as a conference paper at ICLR 2022

symbol “⦸” with the difference that GRAMMFORMER employs reinforcement learning to learn Ps
for a sequential problem rather than learning to abstain for a single-step classiﬁcation problem.

5 DISCUSSION & CONCLUSIONS

In this work, we presented GRAMMFORMER, a generative model of code that goes beyond standard
left-to-right generation and is able to generate sketches, i.e. snippets of code with holes. Design-
ing generative machine learning models with such abilities is important towards facilitating better
collaboration between machine learning models and their human users.

While we have shown that GRAMMFORMER performs better than other alternatives in the sketch
generation task, there are still many opportunities for improvement in the future. First, larger trans-
former models will most probably yield better results, as shown in the relevant literature. Second,
although we used REGEXACC as a plausible evaluation metric, human studies for evaluating the
trade-off between sketch correctness and concreteness are needed. Such studies, similar to those
conducted for machine translation and summarization metrics, can yield more informed reward
functions r(⋅) and improved user experiences.
Second, although we focused on programming languages, modelling natural language also seems
possible. However, training such a model would require large corpora of parsed text. Finally, we
have treated programming languages as a sequence of terminal and non-terminal symbols, ignoring
the structure imposed by code’s strict semantics, such as data and control ﬂow. Explicitly provid-
ing information about the code’s (deterministic) structure, e.g. with relational transformer encoders
similar to Hellendoorn et al. (2019) may further improve GRAMMFORMER’s performance.

ACKNOWLEDGMENTS

The authors would like to thank Alex Polozov for useful discussions. We also thank Patrick Fer-
nandes, Szymon Malik, and Guilherme Ilunga for working on earlier modeling ideas on sketch
generation. Although those were unsuccessful, they provided the inspiration for this work.

REFERENCES

Miltiadis Allamanis. The adverse effects of code duplication in machine learning models of code. In
Proceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms,
and Reﬂections on Programming and Software, pp. 143–153, 2019.

Miltiadis Allamanis and Charles Sutton. Mining idioms from source code. In Proceedings of the

International Symposium on Foundations of Software Engineering (FSE), 2014.

Pavol Bielik, Veselin Raychev, and Martin Vechev. PHOG: Probabilistic model for code. In Pro-

ceedings of the International Conference on Machine Learning (ICML), 2016.

Casey Casalnuovo, Kenji Sagae, and Prem Devanbu. Studying the difference between natural and

programming language corpora. Empirical Software Engineering, 24(4):1823–1868, 2019.

Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared
Kaplan, Harrison Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri,
Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan,
Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian,
Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fo-
tios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex
Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders,
Christopher Hesse, Andrew N. Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa,
Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob
McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating
large language models trained on code. arXiv preprint arXiv:2107.03374, 2021.

Shay B Cohen, Karl Stratos, Michael Collins, Dean Foster, and Lyle Ungar. Spectral learning
In Proceedings of the 50th Annual Meeting of the Association for

of latent-variable PCFGs.
Computational Linguistics (Volume 1: Long Papers), pp. 223–231, 2012.

10

Published as a conference paper at ICLR 2022

Li Dong and Mirella Lapata. Coarse-to-ﬁne decoding for neural semantic parsing. arXiv preprint

arXiv:1805.04793, 2018.

Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou,
Bing Qin, Ting Liu, Daxin Jiang, et al. CodeBERT: A pre-trained model for programming and
natural languages. arXiv preprint arXiv:2002.08155, 2020.

Nicolas Ford, Daniel Duckworth, Mohammad Norouzi, and George E Dahl. The importance of

generation order in language modeling. arXiv preprint arXiv:1808.07910, 2018.

GitHub. Copilot - your ai pair programmer. https://copilot.github.com/, 2021.

Jiatao Gu, Changhan Wang, and Jake Zhao.

Levenshtein transformer.

arXiv preprint

arXiv:1905.11006, 2019.

Vincent J Hellendoorn, Charles Sutton, Rishabh Singh, Petros Maniatis, and David Bieber. Global
relational models of source code. In International conference on learning representations, 2019.

Abram Hindle, Earl T Barr, Zhendong Su, Mark Gabel, and Premkumar Devanbu. On the natu-
In Proceedings of the International Conference on Software Engineering

ralness of software.
(ICSE), 2012.

Rafael-Michael Karampatsis, Hlib Babii, Romain Robbes, Charles Sutton, and Andrea Janes. Big
code!= big vocabulary: Open-vocabulary models for source code. In Proceedings of the Interna-
tional Conference on Software Engineering (ICSE), 2020.

Seohyun Kim, Jinman Zhao, Yuchi Tian, and Satish Chandra. Code prediction by feeding trees to
transformers. In Proceedings of the International Conference on Software Engineering (ICSE),
pp. 150–162. IEEE, 2021.

Jason Lee, Elman Mansimov, and Kyunghyun Cho. Deterministic non-autoregressive neural se-

quence modeling by iterative reﬁnement. arXiv preprint arXiv:1802.06901, 2018.

Chin-Yew Lin. ROUGE: A package for automatic evaluation of summaries. In Text summarization

branches out, pp. 74–81, 2004.

Tianyu Liu, Yizhe Zhang, Chris Brockett, Yi Mao, Zhifang Sui, Weizhu Chen, and Bill Dolan. A
token-level reference-free hallucination detection benchmark for free-form text generation. arXiv
preprint arXiv:2104.08704, 2021.

Cristina V Lopes, Petr Maj, Pedro Martins, Vaibhav Saini, Di Yang, Jakub Zitny, Hitesh Sajnani, and
Jan Vitek. Déjàvu: a map of code duplicates on github. Proceedings of the ACM on Programming
Languages, 1(OOPSLA):84, 2017.

Chris Maddison and Daniel Tarlow. Structured generative models of natural source code. In Pro-

ceedings of the International Conference on Machine Learning (ICML), 2014.

Eric Malmi, Sebastian Krause, Sascha Rothe, Daniil Mirylenka, and Aliaksei Severyn. Encode, tag,

realize: High-precision text editing. arXiv preprint arXiv:1909.01187, 2019.

Joshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald. On faithfulness and factuality

in abstractive summarization. arXiv preprint arXiv:2005.00661, 2020.

Maxwell Nye, Luke Hewitt, Joshua Tenenbaum, and Armando Solar-Lezama. Learning to infer
program sketches. In International Conference on Machine Learning, pp. 4861–4870. PMLR,
2019.

Emilio Parisotto, Abdel-rahman Mohamed, Rishabh Singh, Lihong Li, Dengyong Zhou, and Push-
meet Kohli. Neuro-symbolic program synthesis. In Proceedings of the International Conference
on Learning Representations (ICLR), 2017.

Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive

summarization. arXiv preprint arXiv:1705.04304, 2017.

11

Published as a conference paper at ICLR 2022

Hammond Pearce, Baleegh Ahmad, Benjamin Tan, Brendan Dolan-Gavitt, and Ramesh Karri.
An empirical cybersecurity evaluation of github copilot’s code contributions. arXiv preprint
arXiv:2108.09293, 2021.

Ratish Puduppully, Li Dong, and Mirella Lapata. Data-to-text generation with content selection
and planning. In Proceedings of the AAAI conference on artiﬁcial intelligence, volume 33, pp.
6908–6915, 2019.

Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language

models are unsupervised multitask learners. 2019.

Steven J Rennie, Etienne Marcheret, Youssef Mroueh, Jerret Ross, and Vaibhava Goel. Self-critical
sequence training for image captioning. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, pp. 7008–7024, 2017.

Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words with

subword units. arXiv preprint arXiv:1508.07909, 2015.

Harshil Shah, Bowen Zheng, and David Barber. Generating sentences using a dynamic canvas. In

Proceedings of the AAAI Conference on Artiﬁcial Intelligence, volume 32, 2018.

Michael Shum, Stephan Zheng, Wojciech Kry´sci´nski, Caiming Xiong, and Richard Socher. Sketch-
Fill-AR: A persona-grounded chit-chat generation framework. arXiv preprint arXiv:1910.13008,
2019.

Mitchell Stern, William Chan, Jamie Kiros, and Jakob Uszkoreit. Insertion transformer: Flexible

sequence generation via insertion operations. arXiv preprint arXiv:1902.03249, 2019.

Alexey Svyatkovskiy, Ying Zhao, Shengyu Fu, and Neel Sundaresan. Pythia: AI-assisted code com-
pletion system. In Proceedings of the 25th ACM SIGKDD International Conference on Knowl-
edge Discovery & Data Mining, pp. 2727–2735, 2019.

Alexey Svyatkovskiy, Shao Kun Deng, Shengyu Fu, and Neel Sundaresan. IntelliCode Compose:
Code generation using transformer. In Proceedings of the 28th ACM Joint Meeting on European
Software Engineering Conference and Symposium on the Foundations of Software Engineering,
pp. 1433–1443, 2020.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
In Advances in Neural Infor-

Łukasz Kaiser, and Illia Polosukhin. Attention is all you need.
mation Processing Systems, pp. 5998–6008, 2017.

Bailin Wang, Richard Shin, Xiaodong Liu, Oleksandr Polozov, and Matthew Richardson. RAT-
SQL: Relation-aware schema encoding and linking for text-to-SQL parsers. arXiv preprint
arXiv:1911.04942, 2019.

Sean Welleck, Kianté Brantley, Hal Daumé III, and Kyunghyun Cho. Non-monotonic sequential

text generation. arXiv preprint arXiv:1902.02192, 2019.

Pengcheng Yin and Graham Neubig. A syntactic neural model for general-purpose code generation.

2017.

Liu Ziyin, Zhikang Wang, Paul Pu Liang, Ruslan Salakhutdinov, Louis-Philippe Morency, and
Masahito Ueda. Deep gamblers: Learning to abstain with portfolio theory. arXiv preprint
arXiv:1907.00208, 2019.

12

Published as a conference paper at ICLR 2022

A GENERATED SAMPLES

Fig. 5 and Fig. 6 show two examples from our dataset along with the ground-truth and the sequence
of expansions performed by GRAMMFORMER. Fig. 7-13 show example generations by GRAMM-
FORMER and the baseline models L → R and L → R + ⦸. The parentheses in red indicate the
REGEXACC score for each suggestion. For the L → R + ⦸ baseline the special non-terminal
<suffix> is added to indicate that a hole is introduced at the end of the left-to-right generation.
Finally Fig. 15-17 show example generations where GRAMMFORMER make mistakes. A discussion
for each of those sample is found at the caption of each ﬁgure.

Figure 5: An example GRAMMFORMER generation for C#. Each line in the generation process
shows subsequent states of xt in Alg. 1. Here, GRAMMFORMER predicts a sketch that matches the
ground-truth expansion, but places a hole at the key of the dictionary lookup, instead of predicting a
low-likelihood string literal.

B DATASET STATISTICS

Some statistics about the datasets used throughout this work are shown in Tbl. 3

C FLATTENED NON-TERMINALS

The non-terminals in Tbl. 4 are always expanded and are not considered as non-terminals. Most
of these non-terminals have always the same children (terminals or non-terminals), representing
a single CFG rule. By ﬂattening those non-terminals the depth of tree is reduced (and hence the
number of loops needed in Alg. 1).

13

Context:usingSystem.Collections;usingSystem.Collections.Generic;usingUnityEngine;publicclassBottleFlipAcademy:Academy{publicfloatMaxDistance;publicfloatMinScale;publicboolIsRandomDirection;publicoverridevoidAcademyReset(){MaxDistance=resetParameters["max_distance"];<expression_statement>Ground Truth:MinScale=resetParameters["min_scale"];Prediction:MinScale=resetParameters[<string_literal>];Generation Process:<expression_statement><left><assignment_operator><right>;<left>=<right>;<identifier>=<right>;<identifier>=<expression>[<argument>];<identifier>=<identifier>[<argument>];<identifier>=resetParameters[<argument>];<identifier>=resetParameters[<string_literal>];MinScale=resetParameters[<string_literal>];Published as a conference paper at ICLR 2022

Figure 6: An example GRAMMFORMER generation for Python. Each line in the generation process
shows subsequent states of xt in Alg. 1. GRAMMFORMER here predicts that the user’s intent is to
read-in a second argument and store it in a variable. However, within the current context, the name
of the variable storing the second argument would be impossible to predict. GRAMMFORMER—
reasonably — places a hole at the given location and generates a matching sketch. In this example,
any traditional left-to-right model would need to ﬁrst predict an accurate target variable name (which
seems unlikely in the given context) before predicting the right-hand side of the assignment.

Num Training Files/Trees
Num Validation Files/Trees
Num Test Files/Trees
Avg num tokens of xt
Median num tokens of xt
99 percentile num tokens of xt
Avg num tokens of y
Median num tokens of y
99 percentile num tokens of y

Python

1973400
218398
460874
194.5
205
250
1.9
1
9

C#

1948516
216299
480166
201.4
206
260
1.9
1
7

Table 3: Statistics of the datasets used.

D UNDERSTANDING REGEXACC

Since REGEXACC is a new metric, we include two deterministic ways of introducing sketches in
Tbl. 5. First, if all literals (strings, numeric) are replaced with a hole, we see that a high REGEXACC

14

Context:importsysimportosimportplatformifplatform.system()=="Linux":os.system('clear')elifplatform.system()=="Windows":os.system('cls')target=sys.argv[1]<expression_statement>Ground Truth:ID=sys.argv[2]Prediction:<identifier>=sys.argv[2]Generation Process:<left>=<right><left>=<subscript><left>=<value>[<subscript>]<identifier>=<value>[<subscript>]<identifier>=<attribute>[<subscript>]<identifier>=<object>.<attribute>[<subscript>]<identifier>=<object>.<identifier>[<subscript>]<identifier>=<object>.argv[<subscript>]<identifier>=<object>.argv[<integer>]<identifier>=<object>.argv[2]<identifier>=<identifier>.argv[2]<identifier>=sys.argv[2]Published as a conference paper at ICLR 2022

Figure 7: A C# example and completion outputs from different models. REGEXACC score re-
ported in red. Here, GRAMMFORMER correctly identiﬁes that a method should be invoked on
exchangeActivity, but does not predict the concrete method. If GRAMMFORMER was ex-
tended with information from a static analysis about the ExchangeActivity (potentially a user-
deﬁned type) then an accurate suggestion could have potential been made.

is achieved. In contrast, replacing both identiﬁers and literals (leaving “just” parentheses, brackets,
dots, etc.) we get an easy “lower-bound”. Note how C# — which is syntactically more verbose —
achieves a better score, compared to Python. In Tbl. 6, we show some example sketches and their
associated REGEXACC score.

E BEAM SEARCH

Alg. 2 presents the beam search used in GRAMMFORMER.

15

Context:...ExchangeActivity=(ExchangeActivity)Singleton<ActivitySys>.GetInstance().GetActivity(COM_WEAL_TYPE.COM_WEAL_EXCHANGE,msg.stPkgData.stWealExchangeRes.dwWealID);if(exchangeActivity!=null){exchangeActivity.IncreaseExchangeCount((int)msg.stPkgData.stWealExchangeRes.bWealIdx,msg.stPkgData.stWealExchangeRes.dwDrawCnt);<expression_statement>Ground Truth:exchangeActivity.UpdateView();Prediction:𝑳→𝑹: Singleton<CUIManager>.GetInstance().CloseSendMsgAlert(); (0.000)𝑳→𝑹+⦸:Singleton<<suffix>(0.000)𝑳→𝑹∪∎:exchangeActivity.<hole>(); (0.833)𝑪𝒐𝑷𝒊𝒍𝒐𝒕:} (0.000)𝑮𝒓𝒂𝒎𝒎𝑭𝒐𝒓𝒎𝒆𝒓: exchangeActivity.<identifier>(); (0.833)Published as a conference paper at ICLR 2022

Figure 8: A C# example and completion outputs from different models. REGEXACC score reported
in red. Here, GRAMMFORMER correctly predicts that an AreEqual assert statement should be
made, checking the value of buffer[50]. However, within this context, the correct concrete
expected value (0) would be hard to predict, even for a human. GRAMMFORMER places a hole
there and generates a correct line-level sketch. In contrast, L → R introduces a wrong completion
and L → R + ⦸ creates a correct, but much shorter sketch.

Algorithm 2 GRAMMFORMER beam search, given an input sequence x0.

b ← {(x0, 0, false)}
while ∃(x, p, isDone) ∈ b with isDone = false do
generations
′ ← {}
b
for (x, p, isDone) ∈ b do

if isDone then
′ ← b
b
continue

′ ∪ {(x, p, isDone)}

for i ∈ TOPM(Ps(i∣x, N (x))) do
ps ← log Ps(i∣x, N (x))
if i = ⦸ then
′ ← b
b
else

′ ∪ {(x, p + ps, true)}

for y ∈ TOPN(Pe(y∣x, i)) do

▷ Initialize Beam (state, logprob, isDone)
▷ While beam contains incomplete

▷ For each sample in beam
▷ If suggestion is complete
▷ No operation, beam is complete

▷ Get top-m non-terminal positions

▷ Stop Expansion

▷ Beam search on y yields n candidates

▷ Expand xi
▷ Prune Candidates and keep top k

pe ← Pe(y∣x, i)
′ ← b
b

′ ∪ {(x<i ∶∶ y ∶∶ x>i), p + ps + pe, false)}

b ← TOPK(b

return b

′

)

16

Context:...[Test]publicvoidCanPassTwoProviders(){//arrangevarexpectedLength=100;varinput1=newTestSampleProvider(44100,2,50);varinput2=newTestSampleProvider(44100,2,50);varconcatenator=newConcatenatingSampleProvider(new[]{input1,input2});varbuffer=newfloat[2000];varread=concatenator.Read(buffer,0,buffer.Length);Assert.AreEqual(expectedLength,read,"read==expectedLength");Assert.AreEqual(49,buffer[49]);<expression_statement>Ground Truth:Assert.AreEqual(0,buffer[50]);Prediction:𝑳→𝑹: Assert.AreEqual(50,buffer[50]); (0.000)𝑳→𝑹+⦸:Assert.AreEqual(<suffix> (0.333)𝑳→𝑹∪∎:Assert.AreEqual(expectedLength, read);(0.00)𝑪𝒐𝑷𝒊𝒍𝒐𝒕:Assert.AreEqual(50,buffer[50]); (0.000)𝑮𝒓𝒂𝒎𝒎𝑭𝒐𝒓𝒎𝒆𝒓: Assert.AreEqual(<argument>,buffer[50]); (0.917)Published as a conference paper at ICLR 2022

Figure 9: A C# example and completion outputs from different models. REGEXACC score reported
in red. While all models predict that an assignment needs to be made to each data[i], the exact
form of the constructor is hard to predict. GRAMMFORMER seems to be looking at the constructor
deﬁnition and predicts that some ⟨StringLiteral⟩ needs to be used as the second argument, although
it is uncertain about its concrete form, hence introducing a hole.

17

Context:...namespaceBug604053.Prueba{publicclassData{publicintM1{get;set;}publicstringM2{get;set;}publicData(intm1,stringm2){M1=m1;M2=m2;}}[DataObject(true)]publicclassDataSource{publicData[]Retrieve(){Data[]data=newData[10];for(inti=0;i<10;i++){<expression_statement>Ground Truth:data[i]=newData(i,i.ToString());Prediction:𝑳→𝑹: data[i]=newData(); (0.000)𝑳→𝑹+⦸:data[i]=newData(); (0.000)𝑳→𝑹∪∎:data[i]=newData(); (0.000)𝑪𝒐𝑷𝒊𝒍𝒐𝒕:data[i]=newData(i, "Data" + i); (0.000)𝑮𝒓𝒂𝒎𝒎𝑭𝒐𝒓𝒎𝒆𝒓: data[i]=newData(i,<string_literal>); (0.706)Published as a conference paper at ICLR 2022

Figure 10: A Python example and completion outputs from different models. REGEXACC score
reported in red. Here both L → R and GRAMMFORMER predict the full line correctly, but L →
R + ⦸ seems to return a more conservative (but correct) sketch.

18

Context:#Providesacharacter-basedwidthestimatewhensimpletags#suchas<b>and<i>arepresentinamulti-line,#\"break\"-delimited,string.Veryapproximate,butauseful#default.defhtmlWidth(sIn):iBr=indexOfBr(sIn)if(-1==iBr):s=sInelse:s=sIn[:iBr]<return_statement>Ground Truth:returnlen(s)Prediction:𝑳→𝑹: returnlen(s) (1.000)𝑳→𝑹+⦸:return<suffix> (0.200)𝑳→𝑹∪∎:returns(0.000)𝑪𝒐𝑷𝒊𝒍𝒐𝒕:s= s.replace("&nbsp;", " ") (0.000)𝑮𝒓𝒂𝒎𝒎𝑭𝒐𝒓𝒎𝒆𝒓: returnlen(s) (1.000)Published as a conference paper at ICLR 2022

Figure 11: A Python example and completion outputs from different models. REGEXACC score
reported in red. See main text in the introduction for a description.

Python

C#

false,

ellipsis,

not_operator,

unary_operator,

assignment_expression,

dictionary_comprehension,

member_access_expression,

for_in_clause,
none,

block, tuple, and, or, +, -, *, /, &, ||, //, %, @, +=, -=,
*=, /=, //=, @=, &=, |=, call, keyword_argument, name,
binary_operator,
**,
boolean_operator,
true,
augumented_assignment, await, >>, pair, |, parameters,
<<,
arguments,
assignment, ^, ~
block, tuple, and, or, +, -, *, /, &, ||, //, %, @,
+=, -=, *=, /=, //=, %=, @=, &=, |=, **, >>, |, <<, ^,
invocation_expression,
~,
arguments,
try_statement,
catch_clause, conditional_expression, ==, array_type,
rank, base_expression, conditional_access_expression,
member_binding_expression, initializer, null_literal,
>,
??,
implicit_array_creation_expression,
this_expression,
variable_declaration,
cast_expression,
as_expression,
&&,
implicit_type,
local_declaration_statement,
as,
throw_expression,
if_statement,
is_pattern_expression,
pattern,
default_expression,
name,
bracketed_argument_list,
binary_expression,
object_creation_expression, await_expression, ,

element_access_expression,

subscript,

>=,

<=,

!=,

<,

Table 4: Non-terminals that are always expanded in the Tree-Sitter grammar for the two languages
considered.

19

Context:#!/usr/bin/envpython2from__future__importprint_functionimportargparseimportosimportsubprocessimportsysap=argparse.ArgumentParser()ap.add_argument("--release",action="store_true")ap.add_argument("--prerelease",action="store_true")<expression_statement>Ground Truth:ap.add_argument("--experimental",action="store_true")Prediction:𝑳→𝑹: args=ap.parse_args() (0.000)𝑳→𝑹+⦸:args=ap.parse_args() (0.000)𝑳→𝑹∪∎:args=ap.add_argument(<hole>(0.000)𝑪𝒐𝑷𝒊𝒍𝒐𝒕:ap.add_argument("--beta",action="store_true") (0.000)𝑮𝒓𝒂𝒎𝒎𝑭𝒐𝒓𝒎𝒆𝒓: ap.add_argument(<string>,action="store_true") (0.833)Published as a conference paper at ICLR 2022

Figure 12: A Python example and completion outputs from different models. REGEXACC score
reported in red. Generation steps of GRAMMFORMER shown in Fig. 6. L → R and L → R + ⦸
cannot generate correct sketches since the ﬁrst token would be impossible to guess within this code
context.

Replace all literals with holes
Replace all literals and identiﬁers with holes

0.865
0.126

0.608
0.060

C#

Python

Table 5: REGEXACC when deterministically introducing holes at speciﬁc location.

Table 6: Example REGEXACC scores for a variety of sketches.

Ground-truth
ap.add_argument("--experimental", action="store_true")

ap.add_argument((cid:4) , action="store_true")
ap.add_argument((cid:4) , action=(cid:4) )
ap.add_argument((cid:4) , (cid:4) )
ap.add_argument((cid:4) , action="store_false")
ap.add_argument((cid:4) , required=(cid:4))

REGEXACC

0.9
0.8
0.6
0.0
0.0

20

Context:importsysimportosimportplatformifplatform.system()=="Linux":os.system('clear')elifplatform.system()=="Windows":os.system('cls')target=sys.argv[1]<expression_statement>Ground Truth:ID=sys.argv[2]Prediction:𝑳→𝑹: target=target.replace("\\\\","/") (0.000)𝑳→𝑹+⦸:target=<suffix> (0.000)𝑳→𝑹∪∎:print(target) (0.000)𝑪𝒐𝑷𝒊𝒍𝒐𝒕:No Suggestion (0.000)𝑮𝒓𝒂𝒎𝒎𝑭𝒐𝒓𝒎𝒆𝒓: <identifier>=sys.argv[2] (0.875)Published as a conference paper at ICLR 2022

Figure 13: A Python example and completion outputs from different models. REGEXACC score
reported in red. GRAMMFORMER completes the line creating a correct sketch with two holes at
locations avoiding to make the mistakes that L → R and L → R + ⦸ makes.

Figure 14: A C# example and incorrect completion outputs from different models. REGEXACC
score reported in red. The prediction from GRAMMFORMER is almost right but should have created
a hole at the ﬁrst argument for the user to ﬁll-in. This shows that improved methods for training the
policy network may improve results in the future.

21

Context:...console.setLevel(logging.DEBUG)log.addHandler(console)#movingassembledcontigs(scaffolds)tomiscdirifos.path.isfile(args.corrected):shutil.move(args.corrected,args.assembled)tmp_dir_for_corrector=os.path.join(args.output_dir,"mismatch_corrector",args.assembly_type)#correctingresult_corrected_filename=os.path.join(tmp_dir_for_corrector,"corrected_contigs.fasta")<expression_statement>Ground Truth:dst_configs=os.path.join(tmp_dir_for_corrector,"configs")Prediction:𝑳→𝑹: result_corrected_fasta=os.path.join(args.output_dir,"corrected_fasta") (0.000)𝑳→𝑹+⦸:result_corrected_fasta=<suffix> (0.000)𝑳→𝑹∪∎:result_corrected_filename=<hole> (0.000)𝑪𝒐𝑷𝒊𝒍𝒐𝒕:ifos.path.isfile(tmp_dir_for_corrector):(0.000)𝑮𝒓𝒂𝒎𝒎𝑭𝒐𝒓𝒎𝒆𝒓: <identifier>=os.path.join(tmp_dir_for_corrector,<string>) (0.769)Context:...left=right=newRect(0,0,config.borderSize,height);right.x=width-config.borderSize;top=bottom=newRect(config.borderSize,0,width-config.borderSize*2,config.borderSize);bottom.y=height-config.borderSize;}Color32previousColor;publicoverridevoidOnGUI(){if(!props.wrongActionShowFrame)return;previousColor=GUI.color;GUI.color=config.borderColor;GUI.DrawTexture(left,config.texture);GUI.DrawTexture(right,config.texture);<expression_statement>Ground Truth:GUI.DrawTexture(top,config.texture);Prediction:𝑳→𝑹: GUI.color=previousColor; (0.000)𝑳→𝑹+⦸:GUI.color=previousColor; (0.000)𝑳→𝑹∪∎:GUI.color=Color.white; (0.000)𝑪𝒐𝑷𝒊𝒍𝒐𝒕:GUI.DrawTexture(top,config.texture); (1.000)𝑮𝒓𝒂𝒎𝒎𝑭𝒐𝒓𝒎𝒆𝒓: GUI.DrawTexture(bottom,config.texture); (0.000)Published as a conference paper at ICLR 2022

Figure 15: A C# example and completion outputs from different models. REGEXACC score reported
in red. GRAMMFORMER suggests a correct sketch but the right-hand side of the assignment has
to stop expansion since ⟨IntegerLiteral⟩ cannot generate int.Parse(args[2]). This suggests
some of the limitations that the grammar-based generation of GRAMMFORMER may have, especially
for shorter sequences.

Figure 16: A Python example and completion outputs from different models. REGEXACC score
reported in red. Although the sketch of the prediction from GRAMMFORMER is typically correct, it
is not useful. Researching better evaluation metrics may improve GRAMMFORMER.

22

Context:···namespaceAspNetMvcCorePerformance{publicclassProgram{publicstaticintMain(string[]args){try{stringurlBase="http://localhost:54562/";varthreadCount=1;variterationsPerThread=50;if(args?.Length>0){urlBase=args[0];threadCount=int.Parse(args[1]);<expression_statement>Ground Truth:iterationsPerThread=int.Parse(args[2]);Prediction:𝑳→𝑹: iterationsPerThread=int.Parse(args[2]); (1.000)𝑳→𝑹+⦸:iterationsPerThread=int.Parse(args[2]); (1.000)𝑳→𝑹∪∎:iterationsPerThread=int.Parse(args[2]); (1.000)𝑪𝒐𝑷𝒊𝒍𝒐𝒕:iterationsPerThread=int.Parse(args[2]); (1.000)𝑮𝒓𝒂𝒎𝒎𝑭𝒐𝒓𝒎𝒆𝒓: iterationsPerThread=<integer_literal>; (0.250)Context:importmultiprocessingfromosimportgetenvbind='127.0.0.1:8001'<expression_statement>Ground Truth:workers=multiprocessing.cpu_count()*3Prediction:𝑳→𝑹: workers=2(0.000)𝑳→𝑹+⦸:workers=<suffix> (0.222)𝑳→𝑹∪∎:workers=4(0.000)𝑪𝒐𝑷𝒊𝒍𝒐𝒕:workers=multiprocessing.cpu_count()*2+1(0.000)𝑮𝒓𝒂𝒎𝒎𝑭𝒐𝒓𝒎𝒆𝒓: <identifier>=<string> (0.111)Published as a conference paper at ICLR 2022

Figure 17: A Python example and completion outputs from different models. REGEXACC score
reported in red. All model fail to invoke the correct API of the library. A potential future direction
to mitigate the problem is to incorporate deﬁnitions of the external or system classes.

23

Context:#importpythonmodulesimportrandomimporttimeimportOSC#ConnecttoSuperCollider'sinternalport<expression_statement>Ground Truth:c=OSC.OSCClient()Prediction:𝑳→𝑹: OSC.ConnectCollider() (0.000)𝑳→𝑹+⦸:OSC.<suffix> (0.000)𝑳→𝑹∪∎:OSC.connect() (0.000)𝑪𝒐𝒑𝒊𝒍𝒐𝒕: client=OSC.OSCClient()(0.000)𝑮𝒓𝒂𝒎𝒎𝑭𝒐𝒓𝒎𝒆𝒓: conn=OSC.connect() (0.000)