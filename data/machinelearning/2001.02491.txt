0
2
0
2

n
a
J

8

]
S
M

.
s
c
[

1
v
1
9
4
2
0
.
1
0
0
2
:
v
i
X
r
a

Comparing Python, Go, and C++ on the N -Queens Problem

Pascal Fua, Krzysztof Lis
Computer Vision Laboratory, EPFL

January 14, 2020

Abstract

Python currently is the dominant language in the ﬁeld of Machine Learning but is often criticized
for being slow to perform certain tasks. In this report, we use the well-known N -queens puzzle [1] as a
benchmark to show that once compiled using the Numba compiler it becomes competitive with C++ and
Go in terms of execution speed while still allowing for very fast prototyping. This is true of both sequential
and parallel programs. In most cases that arise in an academic environment, it therefore makes sense to
develop in ordinary Python, identify computational bottlenecks, and use Numba to remove them.

Figure 1: Three solutions of the puzzle on an 8 × 8 board and one on a 10 × 10 board.

1 Introduction

Python currently is the dominant language in the ﬁeld of Machine Learning and gives easy access to powerful
Deep Learning packages such as TensorFlow and PyTorch. However, it is known to be slow to perform some
operations such as loops, which are not always easy to vectorize away. In such situations, one might consider
switching to another language, such as C++ or the more recent Go language whose similarity to Python makes
them potentially attractive replacements. In this note, we will argue that this may be necessary only rarely
because the Numba python compiler [8] delivers performance close to those of C++ while preserving the
compactness and ease of development that make Python such a powerful prototyping tool. Furthermore, it
is easy to use. Once a set of Python functions has been identiﬁed as computationally intensive, one simply
adds Numba decorators before their deﬁnitions to instruct Python to compile them while leaving the rest of
the code largely unchanged.

To demonstrate this, we use the well known N -queens puzzle [1] as a benchmark. It involves placing N
chess queens on an N × N chessboard so that no two queens threaten each other. Fig. 1 depicts three solutions
on a standard 8 × 8 board and one on a larger 10 × 10 one. We will focus on ﬁnding the number of solutions
as a function of N . This is easy for small values of N but quickly becomes computationally intractable for
larger ones because the complexity of our algorithm is exponential with respect to N . There is no known
formula for the exact number of solutions and, to date, 27 is the larger value of N for which the answer has
been computed [12].

All our benchmarking code available is available online.1 We welcome comments and suggestions for

potential improvements.

1https://github.com/cvlab-epfl/n-queens-benchmark

1

 
 
 
 
 
 
2 Sequential Processing

We started from the recursive algorithm described in [15] to compute one single solution of the 8-queens
problem and translated it to Python. Our implementation relies on the fact that for two queens at board
locations (i1, j1) and (i2, j2) not to be in conﬂict with each other, they must not be on the same row, on the
same same column, or on the same diagonal. The ﬁrst two mean that i1 (cid:54)= i2 and j1 (cid:54)= j2. The third holds if
i1 + i2 (cid:54)= j1 + j2 and i1 − i2 (cid:54)= j1 − j2. In other words, the two diagonals going through any (i, j) location
are completely characterized by i + j and i − j.

To exploit this, the function allQueensRec of Tab. 1 allocates boolean arrays col, dg1, and dg2 to keep
track on which columns and diagonals are still available to place a new queen on an n×n board. It then invokes
the recursive function allQueensRecursive. At recursion level i, for each j, it adds a queen at location (i, j)
if it is available, marks the column j and the diagonals i + j and i − j as unavailable for additional queens,
and calls itself for row i + 1. The recursion ends in one of two ways. Either i reaches n, meaning that all
rows have been successfully ﬁlled, or no more queen can be added. If the ﬁrst case, a counter is incremented.
In the second case, nothing happens. In both cases, the program backtracks, undoes it earlier marking, and
continues until all solutions have been found. This process could be sped up by exploiting the symmetries of
the N -queens problems. However, this is not required for benchmarking purposes an we chose not to do it to
keep the code simple. We also chose to use the C++ and Go naming convention for functions and variables,
that is, we use allQueensRec instead of the more typical all_queens_rec, so that we can use the same names
in all versions of the code we present.

In Fig. 2(a), the red curves depicts the computation time on a 2.9 GHz Quad-Core Intel Core i7 Mac
running the Catalina operating system. In the top part of the ﬁgure, we plot the wall-clock time as as function
of the board size n using a standard scale. In the bottom part of the ﬁgure, we plot the same computation times
using a log-scale instead, which results in an almost straight curve. This serves as a sanity check because the
computational complexity grows exponentially with n. As allQueensRecursive performs loops, our vanilla
Python implementation is inefﬁcient. To remedy this, we used the Numba python compiler [8] as shown in
Tab. 2. The code is almost unchanged except for adding a couple of Numba decorators and Yet, as depicted by
the green curve in Fig. 2(a), these minor modiﬁcations deliver a 33-fold increase in average computing speed
of allQueensNmb over allQueensRec.

The Numba decorator njit() that appears in Tab. 2 is short for jit(nopython=True). It ensures that if
the code compile without errors it will not invoke python while running and will therefore be fast. Addition-
ally, we could have used jit(nopython=True,nogil=True) to instruct Numba to release the Python Global
Interpreter Lock [3] while executing the function, thus allowing several versions to run simultaneously on
threads of a single process, something that standard Python code cannot do because of the aforementioned
lock. This does not have any signiﬁcant impact on performance in a sequential execution scenario.

To further assess how effective the Python/Numba combination is, we rewrote the code in Go and C++,
as shown in Tabs. 3 and 4. The short variable declarations make the Go code very similar to the Python code
while being statically typed. The C++ code is slightly more verbose and one must remember to deallocate
what has been allocated because there is no garbage collector. As shown in Fig. 5, this can be remedied by
using more sophisticated containers such as the standard vectors of C++ that are automatically deallocated
at the end of the scope of their deﬁnition. Note that we used vector<uint8_t> as the type for our boolean
arrays instead of the apparently more natural vector<bool>. We did this because the latter packs the bits
densely and has to perform binary arithmetic to extract the requested bit for each access because memory can
only be addressed down to whole bytes. In other words, it reduces memory usage at the expense of increased
computation. As we are interested in speed, it is therefore more effective to explicitly use bytes (uint8_t) for
our purpose. Nevertheless, we have veriﬁed that even when using byte vectors, the implementation of Fig. 5
incurs a small, but noticeable, performance decrease with respect to that of Tab. 4 and we therefore chose to
stick with it, even though it is less elegant. In short, unlike Go, C++ gives the programmer great freedom to
carry out tasks in many different ways but it takes a lot expertise to exploit it effectively and to avoid the many
lurking pitfalls.

For example, unlike Python and Go, C++ does not automatically check that one does not write beyond the
bounds of arrays. As a result, the buggy code of Tab. 6 runs but returns nonsensical values. We unintentionally
made this mistake while translating the code from Python and, even though this is a short program, it took
us a while to spot it. Of course, we could have used a tool such as valgrind, which would have detected the
error, but this is far less convenient than being given a runtime warning. By default Numba does not perform

2

1 def allQueensRec(n):

2

3

4

5

6

7

# Arrays used to flag available columns and diagonals
col = np.ones(n,dtype=bool)
dg1 = np.ones(2*n,dtype=bool)
dg2 = np.ones(2*n,dtype=bool)

return allQueensRecursive(n,0,col,dg1,dg2)

8
9 def allQueensRecursive(n,i,col,dg1,dg2):

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

# All rows are filled, stop the recursion and report a new solution
if n == i :

return 1

# Try putting a queen in each cell of row i
nsol = 0
for j in range(n):

if (col[j] and dg1[i+j] and dg2[i-j+n]):

= False
col[j]
dg1[i+j]
= False
dg2[i-j+n] = False

# Mark column j as occupied
# Mark diagonal i+j as occupied
# Mark diagonal i-j as occupied

nsol+=allQueensRecursive(n,i+1,col,dg1,dg2)

= True
col[j]
dg1[i+j]
= True
dg2[i-j+n] = True

# Unmark column j
# Unmark diagonal i+j
# Unmark diagonal i-j

return nsol

Table 1: Vanilla python code.

bounds checks but they can be enabled using the decorator njit(boundscheck=True), which can be useful
while debugging.

The cyan and purple curves of Fig. 2(a) depict the corresponding runtimes. The Numba, Go, and C++
curves are almost superposed. Closer examination of the raw numbers give in Tab. 15 in appendix show that
C++ wins. Go in slower by about 6% and Numba by 12%. Numba is slower mostly for low values of n, which
suggests that the algorithm itself runs just as fast but that calling the Numba function from Python involves an
overhead. While the observed differences are statistically signiﬁcant based on the variances of the different
runs, in our daily research practice, they are rarely large enough to justify giving up the development speed
that Python provides and to contend with potential bugs such as the one discussed above.

However, there are optimizations that require the low-level control that C++ or Go can provide. For
example, in all versions of the code presented here, the memory for the col, dg1, and dg2 arrays is allocated
dynamically on the heap. The array sizes are decided at runtime and this code could in theory handle the N -
queens problem for any value of n. However the computational cost is exponential and any value of n > 32
is wildly impractical. If we accept to limit ourselves to n <= 32, we can use ﬁxed-sized arrays allocated on
the stack by declaring them as var col[32]bool in Go or std::array<bool, 32> in C++. Unlike in the
case discussed above, using bool instead uint8_t has no adverse effect. We have checked that the C++ code
modiﬁed in this manner delivers a 20% gain over Numba, instead of the earlier 12%. Potential explanations
are that putting the arrays on the stack works better for the CPU cache or that the optimizer has an easier
time reasoning about ﬁxed-size stack arrays. In any event, this shows that C++, and Go, being closer to the
hardware may be useful to ﬁne-tune code under some circumstances.

Go can therefore be considered a promising alternative to both Python and C++ because its run-time
checks make bugs such as the one of Fig. 6 easy to detect and correct. Furthermore, it is almost as concise
as a Python and a little faster than Numba. However, some of its design features make it unwieldy in the
prototyping role. For example, insisting that all variables and packages declared in a ﬁle be used makes sense
for production code but is unhelpful when groping for a solution to a research problem: Commenting out a
particular line of code, can mean many modiﬁcations in the ﬁle, which are unnecessary until a ﬁnal solution
has been found. Similarly not providing a full-ﬂedged class-system can be understood as a way to discourage
the writing of hard-to-maintain spaghetti code, which is commendable in production mode but unnecessarily
rigid in prototyping mode.

3

Figure 2: Run times as a function of the board size. Linear scale at the top and log scale at the bottom. (a)
Sequential. (b) Parallel.

(a)

(b)

3 Parallel Processing

Nearly every modern computer, including the one we used, has a multicore CPU and we can speed things up
by running independent parts of the computation simultaneously on separate cores. In Go and C++, this can
be done using multiple threads. Standard Python cannot do this due to the Global Interpreter Lock (GIL) [3]
that we have already encountered in the previous section. Fortunately, there are several workarounds and we
explored two of them:

1. Using Numba’s automatic parallelization [10]. Numba implements the ability to run loops in parallel as
in Open Multi-Processing (OpenMP). The loop’s body is scheduled in separate threads and the system
automatically takes care of data privatization and reduction.

2. Using a pool of processes. The pool distributes the computation into separate processes and tasks are
sent to the available processors using a FIFO scheduling. Each process has its own interpreter and GIL,
so they do not interfere. The price to pay is that objects need to be serialized and sent to the processes.

To test these two approaches, we parallelized the allQueensRec in a simple way. As shown in Tab. 7, we
deﬁned a new function allQueensCol that puts a queen in column j of the ﬁrst row and then invokes the func-
tion allQueensNumba deﬁned in Tab. 2 starting at the second row instead of the ﬁrst, as in allQueensRec.
Summing the results for all possible values of j yields the same results by performing n independent com-
putations. In Tab. 8, we integrate this code into two functions that spread the tasks across separate cores:
allQueensPara uses the ﬁrst method described above while allQueensPool uses the second. We will refer
to them as para and pool respectively. Numba can take parallelization even further and produce functions that
exploit the GPU. However, we did not explore this aspect in this study because our problem is not conducive
to GPU processing.

In Fig. 2(b), we compare runtimes of the sequential Numba-compiled code of the previous section with
our two parallelized versions. As before, the sequential code is depicted by the green curve while the two
parallel versions are depicted by the red and blue curves, labeled para and pool respectively. para clearly

4

891011121314Number of queens0.00.51.01.52.02.53.0time [s]PythonNumbaGoC++LispJulia12131415161718Number of queens02004006008001000time [s]NumbaParaPoolGoC++891011121314Number of queens104103102101100101102time [s]PythonNumbaGoC++LispJulia12131415161718Number of queens102101100101102103time [s]NumbaParaPoolGoC++1 @njit() #Numba decorator
2 def allQueensNmb(n,i=0,col=None,dg1=None,dg2=None):

3

4

5

6

7

8

# np.bool_ not np.bool because of https://github.com/numba/numba/issues/1311
col = np.ones(n,dtype=np.bool_)
dg1 = np.ones(2*n,dtype=np.bool_)
dg2 = np.ones(2*n,dtype=np.bool_)

return allQueensNumba(n,0,col,dg1,dg2)

9
10 @njit() #Numba decorator
11 def allQueensNumba(n,i,col,dg1,dg2):

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

# All rows are filled, stop the recursion and report a new solution
if n == i :

return 1

# Try putting a queen in each cell of row i
nsol=0
for j in range(n):

if (col[j] and dg1[i+j] and dg2[i-j+n]):

= False
col[j]
dg1[i+j]
= False
dg2[i-j+n] = False

# Mark column j as occupied
# Mark diagonal i+j as occupied
# Mark diagonal i-j as occupied

nsol+=allQueensNumba(n,i+1,col,dg1,dg2)

= True
col[j]
dg1[i+j]
= True
dg2[i-j+n] = True

# Unmark column j
# Unmark diagonal i+j
# Unmark diagonal i-j

return nsol

Table 2: The python code of Tab. 1 slightly modiﬁed to force numba compilation. .

delivers a signiﬁcant improvement. However, for smaller values of n, we noted that para does not always
fully use the 8 cores of our machines, which impacts its performance. For values of n up to 13, the overhead
involved in spawning new processes dominates the computational cost of pool and makes it uncompetitive.
However, for n > 13, this overhead becomes negligible with respect to the rest of the computation and pool
starts dominating, albeit only by a small margin for large values of n, as can be seen in Tab. 15.

To again compare against Go and C++, we rewrote the code in these two languages using their built-in
multi-threading capabilities, as shown in Tabs 9 and 10. Note that we used the template function std::async
function to make the C++ version compact. The corresponding performance measurements are depicted by
the cyan and purple curves of Fig. 2(b). As before for small values of n, para and pool are uncompetitive
because the initial overhead is too large. However, for larger values of n they catch up and eventually do
better than Go and almost as well as C++. In short, there are corner cases in which it might pay to switch from
Python to C++ or go but it is not clear how pervasive they are in our research practice.

4 Numba Limitations

In the two previous sections, we have argued that Numba is a powerful tool to painlessly compile potentially
slow Python code so that it runs almost as fast as Go and C++. However, it also has limitations: Only a subset
of Python [11] and NumPy [9] features are available inside compiled functions. Numba has a compilation
mode that generates code able to handle all values as Python objects and uses the Python C API to perform all
operations on such objects. Unfortunately, relying on this mode results in almost no performance gain over
non-compiled code. This is why we used the njit() decorator in all our examples. It yields much faster code
but requires that the native types of all values in the function can be inferred, which is not necessarily true in
standard Python. Otherwise, the compilation fails.

In practice, this imposes an additional workload on the programmer who has to ﬁgure out what parts of
the code are computationally expensive, encapsulate them in separate functions, and make sure that these
functions can be compiled using the no-python mode that njit() enforces. This is probably why there are
ongoing efforts to optimize whole Python programs such as PyPy [13]. Unfortunately, the results are not

5

1 func allQueensRec(n int) int {

// Allocate arrays
col := make([]bool, n, n)
dg1 := make([]bool, 2*n, 2*n)
dg2 := make([]bool, 2*n, 2*n)
// All columns and diagonals are initially available
for i := 0; i < n; i++ {

col[i] = true

}
for i := 0; i < 2*n; i++ {

dg1[i] = true
dg2[i] = true

}
// Perform the recursive computation and return the results
return allQueensRecursive(n, 0, col, dg1, dg2)

2

3

4

5

6

7

8

9

10

11

12

13

14

15
16 }

17
18 func allQueensRecursive(n int, i int, col [32]bool, dg1 [64]bool, dg2 [64]bool) int {

if n == i {

return 1

}
nsol := 0
for j := 0; j < n; j++ {

if col[j] && dg1[i+j] && dg2[i-j+n] {
= false
col[j]
= false
dg1[i+j]
dg2[i-j+n] = false

nsol += allQueensRecursive(n, i+1, col, dg1, dg2)

= true
col[j]
dg1[i+j]
= true
dg2[i-j+n] = true

}

}
return nsol

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36
37 }

Table 3: Go version of the python code of Tab. 1.

always compatible with libraries utilizing the C API, such as those routinely used in the ﬁeld of scientiﬁc
computing. As discussed in appendix, Julia is a potential alternative to Python/Numba that supports both
high performance scientiﬁc computing and fast prototyping, is compiled, and could eventually address this
problem.

5 Conclusion

As Computer Vision and Machine Learning researchers, we primarily need a language that allows us to test
and reﬁne ideas quickly while giving us access to as many mathematical, image processing, and machine
learning libraries as possible. The latter spares us the need to reinvent the wheel every time we want to try
something new. Maintainability and ability to work in large teams are secondary considerations as our code
often stops evolving once the PhD student or post-doctoral researcher who wrote it leaves our lab. Before that
happens, we typically make it publicly available to demonstrate that the ideas we published in conference and
journals truly work and, in the end, that is often its main function.

Python ﬁts that bill perfectly at the cost of being slow when performing operations such as loops. Fortu-
nately, as we showed in this report, this shortcoming can be largely overcome by using the Numba compiler
that delivers performance comparable to that of C++, which itself tends to be faster than Go. This suggests
that a perfectly valid workﬂow is to ﬁrst write and debug a program in ordinary Python; identify the compu-
tational bottlenecks; and use Numba to eliminate them. This will work most of the time. In the rare cases
where it does not, we can rewrite the relevant section of the code in C++ and call it from Python, which can
be achieved using Cython [2] or pybind11 [4]. Interestingly, this approach harkens to the standard way one
used to work in the much older Common Lisp language, as discussed in the appendix.

6

1 int allQueensRecursive(int n,int i,bool *col,bool *dg1,bool *dg2)
2 {

if (n == i) {
return 1;

}
int nsol = 0;
for (int j = 0; j < n; j++) {

if (col[j] && dg1[i+j] && dg2[i-j+n]) {
= false;
col[j]
dg1[i+j]
= false;
dg2[i-j+n] = false;

nsol += allQueensRecursive(n, i+1, col, dg1, dg2);

= true;
col[j]
dg1[i+j]
= true;
dg2[i-j+n] = true;

}

}
return nsol;

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20
21 }

22
23 int allQueensRec(int n)
24 {

// Allocate dynamic memory on the heap
bool *col = new bool[n];
bool *dg1 = new bool[2*n];
bool *dg2 = new bool[2*n];
// All columns and diagonals are initially available
memset((void *)col,1,n*sizeof(bool));
memset((void *)dg1,1,2*n*sizeof(bool));
memset((void *)dg2,1,2*n*sizeof(bool));
// Perform the recursive computation
int nsol = allQueensRecursive(n,0, col, dg1, dg2);
// No garbage collector, must deallocate to prevent memory leaks
delete[] col;
delete[] dg1;
delete[] dg2;

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

return nsol;

40
41 }

Table 4: C++ version of the python code of Tab. 1. To initialize the arrays, we could have used loops as in the
Go code of Tab. 3. Instead we used the lower level instruction memset, which performs the same tasks without
loops and can therefore be expected to be faster.

1 typedef vector<uint8_t> BoolArray;

// Use uint8_t instead of bool to boost efficiency

2
3 int allQueensRecursive(int n,int i,BoolArray& col,BoolArray& dg1,BoolArray& dg2){

4
5 }

........

6
7 int allQueensRec(int n)
8 {

BoolArray col(n,
true);
BoolArray dg1(2*n, true);
BoolArray dg2(2*n, true);

int nsol = allQueensRecursive(n,0,col,dg1,dg2);

return nsol;

9

10

11

12

13

14

15
16 }

Table 5: Using C++ vectors makes it unnecessary to explicitly free them. The call to allQueensRecursive
has been slightly modiﬁed slightly so that they are passed by value instead of by reference and therefore not
copied.

7

1 int allQueensRec(int n)
2 {

// dg1 and dg2 are of size n instead of 2n
bool *col = new bool[n];
bool *dg1 = new bool[n];
bool *dg2 = new bool[n];
memset((void *)col,1,n*sizeof(bool));
memset((void *)dg1,1,n*sizeof(bool));
memset((void *)dg2,1,n*sizeof(bool));

........

3

4

5

6

7

8

9

10

11
12 }

Table 6: Buggy version of the C++ code of Tab. 4. It runs but returns nonsensical results.

1 @njit()
2 def allQueensCol(n,j):

3

4

5

6

7

8

9

10

11

12

col = np.ones(n,dtype=np.bool_)
dg1 = np.ones(2*n,dtype=np.bool_)
dg2 = np.ones(2*n,dtype=np.bool_)
# Put a queen in cell j of the first row
= False
col[j]
dg1[j]
= False
dg2[n-j] = False
# Fills the rest of the board starting with the second row
return allQueensNumba(n,1,col,dg1,dg2)

13
14 if __name__ == "__main__":

15

16

17

nsol = 0
for j in range(8):

nsol += allQueensCol(8,j)

Table 7: The python code of Tab. 2 rewritten to perform n independent computations.

1 @njit(parallel=True)
2 def allQueensPara(n):

3

4

5

6

nsol = 0
for j in prange(n):

nsol+=allQueensCol(n,j)

return nsol

7
8 def allQueensPool(n,np=None):

# prange is only applicable inside jit(parallel=True)

9

10

11

with Pool_proc() as pool:

# Create a pool of processes

nsols= pool.map(partial(poolWorker,n),range(n))
return (sum(nsols))

12
13 def poolWorker(n,j):

14

return allQueensCol(n,j)

Table 8: Two different ways to Invoke the function allQueensCol of Tab. 7 so that the computation is split into
n tasks potentially running on different cores. Note how compact this code is.

8

1 func allQueensPara(nd int) int {

// Create the structure that will be used to synchronize
var wg sync.WaitGroup
wg.Add(nd)
// Explicitly allow go to run on 8 cores
runtime.GOMAXPROCS(8)

sols := make([]int, nd)

f := func(wg *sync.WaitGroup, n int, j int) {

sols[j] = allQueensCol(n, j) // Result for a queen in cell k of first row
wg.Done()

// Flag the thread as complete

}
for j := 0; j < nd; j++ {
go f(&wg, nd, j)

}
wg.Wait()

nsol := sols[0]
for j := 1; j < nd; j++ {

nsol += sols[j]

}
return nsol

// Launch a new thread for each computation

// Wait for all threads to be completed

// Sum the individual results

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23
24 }

25
26 func allQueensCol(n int, j int) int {

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43
44 }

col := make([]bool, n, n)
dg1 := make([]bool, 2*n, 2*n)
dg2 := make([]bool, 2*n, 2*n)

for i := 0; i < n; i++ {

col[i] = true

}
for i := 0; i < 2*n; i++ {

dg1[i] = true
dg2[i] = true

}
= false
col[j]
dg1[j]
= false
dg2[n-j] = false

return allQueensRecursive(n, 1, col, dg1, dg2, 0)

Table 9: Go version of the parallel python code of Tabs. 7 and 8.

9

1 int allQueensCol(int n,int j) {

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19
20 }

bool *col = new bool[n];
bool *dg1 = new bool[2*n];
bool *dg2 = new bool[2*n];
memset((void *)col,1,n*sizeof(bool));
memset((void *)dg1,1,2*n*sizeof(bool));
memset((void *)dg2,1,2*n*sizeof(bool));

= false;
col[j]
dg1[j]
= false;
dg2[n-j] = false;

int ncol = allQueensRecursive(n,1,col, dg1, dg2);

free(col);
free(dg1);
free(dg2);
return ncol;

21
22 int allQueensPara(int nd){

23

24

25

26

27

28

29

30

31

32

33

34

35

36
37 }

vector<future<int>> running_tasks;
// Start one process per column
for(int col = 0; col < nd; col++){

running_tasks.push_back(

async(std::launch::async, [=]() {return allQueensCol(nd,col);})

);

}
// Wait for results
int nsol_sum = 0;
for(auto& f : running_tasks) {

nsol_sum += f.get();

}
return nsol_sum;

Table 10: C++ version of the parallel python code of Tabs. 7 and 8. The async template function makes the
code very compact.

10

Appendix

A Other Languages

In his book [15], N. Wirth proposed the N -queens algorithm implemented in Pascal and shown in Tab. 11.
It is speciﬁc to the case n = 8 and is designed to stop when the ﬁrst solution is found.
It then returns
the corresponding conﬁguration. As shown in Tab. 12, this can be done even more concisely in Prolog,
a logic programming language of the same era as Pascal. What makes Prolog particularly interesting is
that, of all the languages discussed in this report, it is the only one that forces a truly different approach to
programming. It is well suited to performing the kind of systematic exploration and backtracking that solving
the N -queens problem requires and is still used to solve speciﬁc tasks that involve rule-based logical queries
such as searching databases.

As not all implementations of the Pascal standard support dynamic arrays, extending the program of
Tab. 11 that is speciﬁc to the n = 8 case to the general case would require manually allocating memory
using pointers, much as in C. This would not be necessary in the even older Common Lisp language, as
shown in Tab. 13. Although among the most ancient languages still in regular use, Lisp offers many of the
same amenities as Python, that is, dynamically allocated arrays, sophisticated loop structures, and garbage
collection among others. It can be used either in interpreted or compiled form, much like Python without
and with Numba. When invoking the compiler, the optional type declarations help it generate faster code. A
standard approach to developing in Lisp is therefore to prototype quickly without the declarations and then
add them as needed to speed up the code. Interestingly Python is now moving in that direction with its support
for type hints but does not yet enforce that variable and argument values match their declared types at runtime.
They are only intended to be used by third party tools such as type checkers, IDEs, and linters [14].

As can be seen in Fig. 2(a), because it is compiled, Lisp does not perform so badly compared to the
more recent languages we discussed in this report. The even newer Julia [6] language can be understood as
being related to it in that it supports rapid prototyping by allowing interactive execution while being compiled.
Type declarations are available but optional and the code is very Python-like, as can be seen in Tab. 14. Like
Numba, Julia uses LLVM [7] to perform low level optimizations and produce efﬁcient native binary binary
code. Unlike in C++ or Go, there is no explicit compilation step and yet it delivers performance that are almost
on par with those of the other compiled languages we discussed, as can be seen in Fig. 2(a) and Tab. 15.

This make Julia a potentially attractive alternative to Python/Numba. Unfortunately, there are some sig-
niﬁcant obstacles to its adoption. First, it still is a new language. Some important features remain experi-
mental and the number of third-party libraries is limited, whereas Python gives access to a wealth of powerful
libraries, such as the deep learning ones that have become absolutely central to our research activities. Fur-
thermore, it features some design choices that differentiate it from currently popular languages [5], such as
1-indexed arrays and multiple-dispatch instead of classes. Whether or not these choices are wise, they make
it harder to switch from an established language like Python to Julia.

B Raw Data

The performance numbers we used to produce the plots of Fig. 2 are given in Tab. 15. For both the sequential
versions of the code and for each value of n, the time for the fastest implementation appears in red and the
one for the second best in blue. These numbers were obtained on a 2.9 GHz Quad-Core Intel Core i7 Mac
running the Catalina operating system. For all versions of the code we ran 20 trials for 8 ≤ n ≤ 15, 10
for 16 ≤ n ≤ 17, and 3 for n = 18 and computed the mean and variance in each case. We have rerun
all these benchmarks on an Intel Xeon X5690 CPU running Ubuntu 18.04 and the overall ranking of the
implementations was unchanged.

References

[1] J. Bell and B. Stevens. A survey of known results and research areas for n-queens. Discrete Mathematics,

309(1):1–31, 2009. 1

[2] Cython: C-extensions for python. https://cython.org/. 6

11

[3] Global interpreter lock.

https://en.wikipedia.org/wiki/Global_interpreter_lock. 2, 4

[4] Wenzel Jakob, Jason Rhinelander, and Dean Moldovan. pybind11 – seamless operability between c++11

and python, 2017.
https://github.com/pybind/pybind11. 6

[5] Julia: Noteworthy Differences from other Languages.

https://docs.julialang.org/en/v1/manual/noteworthy-differences/. 11

[6] The Julia Programming Language.

https://julialang.org/. 11

[7] The LLVM Compiler Infrastructure Project.

https://llvm.org/. 11

[8] Numba: A High Performance Python Compiler.
https://numba.pydata.org/. 1, 2

[9] Numba: Supported NumPy Features.

https://numba.pydata.org/numba-doc/dev/reference/numpysupported.html.
5

[10] Numba: Automatic parallelization with @jit.

https://numba.pydata.org/numba-doc/dev/user/parallel.html. 4

[11] Numba: Supported Python Features.

https://numba.pydata.org/numba-doc/dev/reference/pysupported.html. 5

[12] T. Preußer, B. Nägel, and R. Spallek. Putting queens in carry chains. 2009. 1

[13] PyPy: a fast, compliant alternative implementation of the Python language.

https://pypy.org/. 5

[14] Support for Type Hints in Python.

https://docs.python.org/3/library/typing.html. 11

[15] Niklaus Wirth et al. Algorithms+ Data Structures. Prentice-Hall, 1976. 2, 11

12

1 program eightqueen1(output);

2
3 var i : integer; q : boolean;

4

5

6

7

a : array[ 1 .. 8] of boolean;
b : array[ 2 .. 16] of boolean;
c : array[ -7 .. 7] of boolean;
x : array[ 1 .. 8] of integer;

8
9 procedure try( i : integer; var q : boolean);

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

var j : integer;
begin
j := 0;
repeat

j := j + 1;
q := false;
if a[ j] and b[ i + j] and c[ i - j] then

begin
] := j;
x[ i
a[ j
] := false;
b[ i + j] := false;
c[ i - j] := false;
if i < 8 then
begin
try( i + 1, q);
if not q then
begin
a[ j]
:= true;
b[ i + j] := true;
c[ i - j] := true;
end

end

else

q := true

end
until q or (j = 8);
end;

37
38 begin
39 for i :=
40 for i :=
41 for i := -7 to
42 try( 1, q);
43 if q then

8 do a[ i] := true;
1 to
2 to 16 do b[ i] := true;
7 do c[ i] := true;

for i := 1 to 8 do write( x[ i]:4);

44
45 writeln
46 end.

Table 11: Pascal program by Niklaus Wirth in 1976. It ﬁnds one solution to the eight queens problem.

13

1 /* Use clpfd package to loop through all configurations until a feasible one is found */
2 n_queens(N, Qs) :-

3

4

5

length(Qs, N),
Qs ins 1..N,
safe_queens(Qs).

6
7 /* Predicate is true if the configuration is feasible */
8 safe_queens([]).
9 safe_queens([Q|Qs]) :- safe_queens(Qs, Q, 1), safe_queens(Qs).
10 safe_queens([], _, _).
11 safe_queens([Q|Qs], Q0, D0) :-

12

13

14

15

Q0 #\= Q,
abs(Q0 - Q) #\= D0,
D1 #= D0 + 1,
safe_queens(Qs, Q0, D1).

16
17 /* Example */
18 ?- n_queens(8, Qs), labeling([ff], Qs).
Qs = [1, 5, 8, 6, 3, 7, 2, 4] ;
Qs = [1, 6, 8, 3, 7, 4, 2, 5] .

20

19

Table 12: Prolog version of the Pascal code of Tab. 11 from https://www.metalevel.at/queens/.

1 (defun allQueensRec(n)

2

3

4

5

6

7

8

9

(declare (type fixnum n))

(let ((col (make-array n

:initial-element t :element-type ’boolean))
(dg1 (make-array (* 2 n) :initial-element t :element-type ’boolean))
(dg2 (make-array (* 2 n) :initial-element t :element-type ’boolean)))

(declare (type (array boolean 1) col dg1 dg2 ))

(allQueensRecursive n 0 col dg1 dg2 0)))

10
11 (defun allQueensRecursive(n i col dg1 dg2)

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

;; Optional declarations. Some compilers exploit them to speed up the code
(declare (type (array boolean 1) col dg1 dg2 ))
(declare (type fixnum n i))

(if (= i n)

1

(let ((nsol 0))

(declare (type fixnum nsol))

(loop for j from 0 below n

when (and (aref col j) (aref dg1 (+ i j)) (aref dg2 (- (+ i n) j)))
do

(setf

(aref col j) nil
(aref dg1 (+ i j)) nil
(aref dg2 (- (+ i n) j)) nil)

(incf nsol (allQueensRecursive n (+ i 1) col dg1 dg2))

(setf

(aref col j) t
(aref dg1 (+ i j)) t
(aref dg2 (- (+ i n) j)) t))

nsol)))

Table 13: Common Lisp version of the python code of Tab. 1.

14

1 function allQueensRecursive(n, i, col, dg1, dg2)

# All rows are filled, stop the recursion and report a new solution
if n == i

return 1

end

# Try putting a queen in each cell of row i
nsol = 0

for j = 0:n-1

if (col[j+1] && dg1[i+j+1] && dg2[i-j+n+1])

= false
col[j+1]
dg1[i+j+1]
= false
dg2[i-j+n+1] = false

# Mark column j as occupied
# Mark diagonal i+j as occupied
# Mark diagonal i-j as occupied

nsol += allQueensRecursive(n,i+1,col,dg1,dg2)

= true
col[j+1]
dg1[i+j+1]
= true
dg2[i-j+n+1] = true

# Unmark column j
# Unmark diagonal i+j
# Unmark diagonal i-j

end

end
return nsol

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24
25 end

26
27 function allQueensRec(n)

col = ones(Bool, n)
dg1 = ones(Bool, 2*n)
dg2 = ones(Bool, 2*n)

return allQueensRecursive(n,0,col,dg1,dg2)

28

29

30

31

32
33 end

Table 14: Julia version of the code of Tab. 1

Sequential
Python
Lisp
Julia
Numba
Go
C++
Parallel
Numba Para
Numba Pool
Go
C++

8
0.00391
0.00036
0.00010
0.00011
0.00009
0.00009
8
0.00008
0.13120
0.00012
0.00012

9
0.01625
0.00148
0.00047
0.00053
0.00044
0.00041
9
0.000248
0.130002
0.000221
0.000202

10
0.07024
0.00577
0.00213
0.00219
0.00198
0.00189
10
0.00087
0.13113
0.00055
0.00063

11
0.33707
0.02711
0.01057
0.01054
0.01007
0.00935
11
0.00473
0.13105
0.00236
0.00272

12
1.77808
0.13346
0.05555
0.05455
0.05404
0.04991
12
0.02509
0.13349
0.01222
0.01293

13
9.58502
0.72808
0.30745
0.28898
0.30519
0.29386
13
0.15463
0.13280
0.08580
0.06945

14
57.5610
4.43882
1.90335
1.74438
1.80617
1.67399
14
0.98384
0.44365
0.51022
0.39773

15
-
29.1243
13.1295
11.0766
10.9284
9.99408
15
6.6811
2.52153
3.44080
2.75142

16
-
-
89.8649
75.5948
73.6867
66.7773
16
17.2807
16.9606
22.9841
18.7342

17
-
-
634.371
546.312
527.514
491.910
17
135.166
135.078
140.860
122.827

18
-
-
-
4085.54
4014.05
3677.10
18
1184.33
994.799
1068.71
877.398

Table 15: Benchmarking results in seconds per trial for n from 8 to 18.

15

