On Learning Combinatorial Patterns to Assist Large-Scale Airline Crew Pairing
Optimization

Divyam Aggarwal1 , Yash Kumar Singh1 and Dhish Kumar Saxena1,∗
1Department of Mechanical & Industrial Engineering, Indian Institute of Technology Roorkee, Roorkee,
Uttarakhand-247667, India
{daggarwal, ysingh, dhish.saxena}@me.iitr.ac.in

0
2
0
2

y
a
M
2

]

G
L
.
s
c
[

3
v
4
1
7
3
1
.
4
0
0
2
:
v
i
X
r
a

Abstract

Airline Crew Pairing Optimization (CPO) aims at
generating a set of legal ﬂight sequences (crew
pairings),
to cover an airline’s ﬂight schedule,
at minimum cost.
It is usually performed us-
ing Column Generation (CG), a mathematical pro-
gramming technique for guided search-space ex-
ploration. CG exploits the interdependencies be-
tween the current and the preceding CG-iteration
for generating new variables (pairings) during
the optimization-search. However, with the un-
precedented scale and complexity of the emergent
ﬂight networks, it has become imperative to learn
higher-order interdependencies among the ﬂight-
connection graphs, and utilize those to enhance
the efﬁcacy of the CPO. In ﬁrst of its kind and
what marks a signiﬁcant departure from the state-
of-the-art, this paper proposes a novel adaptation
of the Variational Graph Auto-Encoder for learning
plausible combinatorial patterns among the ﬂight-
connection data obtained through the search-space
exploration by an Airline Crew Pairing Optimizer,
AirCROP (developed by the authors and validated
by the research consortium’s industrial sponsor, GE
Aviation). The resulting ﬂight-connection predic-
tions are combined on-the-ﬂy using a novel heuris-
tic to generate new pairings for the optimizer. The
utility of the proposed approach is demonstrated on
large-scale (over 4200 ﬂights), real-world, complex
ﬂight-networks of US-based airlines, characterized
by multiple hub-and-spoke subnetworks and sev-
eral crew bases.

1 Introduction
Crew operating cost constitutes the second-largest compo-
nent of an airline’s total operating cost (next to the fuel cost).
Hence, even marginal improvements in it may translate to
savings of millions of dollars, annually. Given this, crew
scheduling optimization assumes critical importance for any
airline. Airline Crew Pairing Optimization (CPO), being the
primary step of crew scheduling, is aimed at constructing a

∗Contact Author

set of legal crew pairings to cover an airline’s ﬂight schedule
at minimum-cost. A legal crew pairing is a ﬂight sequence
to be ﬂown by an airline crew, starting and ending at the
same crew base, while satisfying several complex constraints.
The resulting optimization problem, referred to as CPOP, is a
highly-constrained NP-Hard optimization problem [Bernhard
and Vygen, 2012]. Major airlines handle large (3000+ ﬂights)
and complex ﬂight networks on a weekly basis, resulting in
billion-plus possible legal pairings. This renders their ofﬂine
enumeration intractable, and exhaustive search for their op-
timal full ﬂight-coverage, impractical. A detailed review of
CPOP could be found in [Barnhart et al., 2003].

CPOP is a large integer programming (IP) problem, im-
practical to be solved using standard IP techniques (branch-
and-bound algorithm [Land and Doig, 1960]). The CPOP’s
literature suggests that Column Generation (CG) is the most
widely adopted optimization technique, since it allows for
guided exploration of search-space based on the correspond-
ing gain in the objective function(s). Interested readers are
referred to [L¨ubbecke, 2010] for an extensive review on
CG. While several researchers have used CG before the IP-
phase to solve CPOP’s relaxed-form, a linear programm-
ming (LP) problem [Gabriel Crainic and Rousseau, 1987;
Anbil et al., 1992; Vance et al., 1997; Anbil et al., 1998]; oth-
ers have used CG inside the IP-phase by adopting a branch-
and-price framework (proposed by [Barnhart et al., 1998])
[Desaulniers and Soumis, 2010; Zeren and ¨Ozkol, 2016].
This research adopts the former approach, and the workﬂow
of the optimizer is as follows. A full ﬂight coverage set
of legal pairings is used to initialize CG-phase of the opti-
mizer. In that, several CG-iterations are performed to ﬁnd a
near-optimal LP-solution, which is fed in to the subsequent
IP-phase. Each CG-iteration is decomposed into two prob-
lems, a restricted master problem (RMP) and a pricing sub-
problem. The RMP is modeled as a set-covering problem
[Bernhard and Vygen, 2012], and solved using the Simplex
algorithm [Murty, 1983]. The dual-information embedded in
the resulting solution, is then utilized to generate new pair-
ings promising further cost-improvement (pricing subprob-
lem). This approach suffers from two major limitations.
Firstly, it may be noted that the solution to the pricing sub-
problem at CG-iteration t − 1 feeds into the RMP and pric-
ing subproblems at iteration t. Hence, effectively, CG cap-
tures the interdependencies between two subsequent itera-

 
 
 
 
 
 
tions (local information), rendering the LP-solution vulner-
able to local optimality. Secondly, there is over-reliance on
the use of the dual-information. In that, any hidden/indirect
ﬂight-connection patterns which may not be obvious, yet be
drivers for better pairings, have been overlooked. This paper
seeks to overcome both these limitations by learning ﬂight-
connection patterns which are recurrent from the initial till
the current CG-iteration t, and by utilizing this knowledge
to guide the the CG-search towards otherwise unexplored
(ﬂight-connections) regions of the search space.

The advancements in machine learning (ML) techniques
have enabled the researchers to solve operations research
(OR) problems using ML-based approaches. Aytug et al.
[1994] highlights the need to incorporate Artiﬁcial Intelli-
gence (AI)-based methods in scheduling problems. The work
on Innovization by Deb and Srinivasan [2006] highlights the
beneﬁts of identifying salient design rules that make a so-
lution optimal, providing essential process knowledge to the
user that may not be otherwise directly attainable. Priore et al.
[2014] provides a recent survey on the use of ML techniques
in dynamic scheduling for manufacturing systems. Wang et
[2016] predicted the anticipated bus trafﬁc by using a
al.
standard NN, however, did not use it in combination with
an OR-based optimizer. A recent survey of the use of ML
techniques for combinatorial optimization problems is pre-
sented in Bengio et al. [2018]. Khalil et al. [2017] proposed
a unique combination of graph embedding and reinforcement
learning techniques to learn the structure of combinatorial op-
timization problems which are required to be solved again
and again but with different data. A similar approach has
[2019] in which regular/-
been proposed by Soumis et al.
common ﬂight clusters, that are part of hundreds of previous
optimal solutions, are learnt. The learnt clusters are used to
construct a better initial feasible solution for an airline crew
pairing optimizer, drastically reducing the time to generate an
acceptable sub-optimal solution. These two approaches fo-
cused only on learning regularity-based structures from mul-
tiple solutions of previous optimizer-runs which is not the
aim of this research work. Convolutional Neural Networks
(CNN) have proved useful in learning generalized patterns
in complex structures such as image data. This concept of
convolutions has been extended to graph problems, leading
to the development of Graph Convolutional Networks (GCN)
[Kipf and Welling, 2016a]. In a recent approach [Li et al.,
2018], authors used the GCN to estimate the likelihood of
vertices of being in the optimal solution and a guided tree
search to generate a diverse set of solutions using the pre-
dicted vertices. Its utility was demonstrated for generalized
and less complex combinatorial optimization problems, and
that too using a GCN for semi-supervised learning which may
not be useful in the context the CPOP. However, a motivation
is drawn for the use of GCNs and its types for learning use-
ful patterns in the graph-structured data.It was identiﬁed as a
semi-supervised learning problem which is not useful in the
context of CPOPs. As adaptive learning framework is pro-
posed by Gaur and Deb [2016] to assist Multi-objective Evo-
lutionary Algorithms. However, the same is not applicable
in CPO due to its combinatorial as well as single-objective
nature.

This research paper attempts to address the challenge of
developing a learning framework for assisting large-scale
airline CPO by using a novel-adaptation of the Variational
Graph Auto-encoder (VGAE; given by Kipf and Welling
[2016b]). The adapted VGAE is used to learn hidden and
indirect patterns among the ﬂight-connection graphs, con-
structed during CPO. A novel heuristic is proposed to com-
bine the resulting ﬂight-connection predictions for generating
new pairings in the same CG-iteration as that of the learning.
In the learning framework:

1. CPOP is modeled as a graph-problem by transforming
the optimization-data into a graph-structured data, en-
abling the adaptation of VGAE as the learning algo-
rithm.

2. Relevant features are formulated in a way to capture the
evolution of solution-quality as the optimization-search
proceeds.

3. Predictions from VGAE are transformed on-the-ﬂy into
new pairings, resulting in higher cost-improvements.

The efﬁcacy of the proposed learning framework is demon-
strated on large-scale (∼4200 ﬂights) and complex ﬂight net-
works of US-based airlines, provided by the industrial spon-
sor, GE Aviation.

The outline of the paper is as follows: Section 2 includes
a brief discussion on the airline crew pairing problem and
the developed optimizer, Section 3 describes the proposed
learning framework, Section 4 presents the results of com-
putational experiments on real-world airline ﬂight datasets,
and Section 5 perspectively concludes the paper.

2 Airline Crew Pairing Optimization Problem

2.1 Terminology
A sequence of ﬂight legs ﬂown by a crew member, starting
and ending at their home base (airport), is called a crew pair-
ing. Each crew is assigned a home base, called the crew
base. Each ﬂight sub-sequence within a crew pairing that
a crew ﬂies in its working day is called a crew duty or a
duty. Within each duty, two consecutive ﬂights are separated
by a small rest-time to allow for operations such as aircraft
changes, cleaning, bagging, etc. and this is called a sit-time or
a connection-time. A longer rest-time, provided between two
consecutive duties, is called an overnight-rest. Two shorter
time-periods, brieﬁng and debrieﬁng times, are provided in
the beginning and ending of a duty respectively. The total
time elapsed in a crew pairing is known as the Time Away
From Base (TAFB). An example of a legal crew pairing is
shown in Figure. 1. In some cases, where two ﬂights cannot
be covered in a pairing because they do not share legal ﬂight
connection, a third ﬂight is used to connect them in which the
crew travels as passenger instead of ﬂying it. Such a ﬂight is
called a deadhead ﬂight for the crew going as passenger. The
deadhead ing not only leads to revenue loss on the passenger
seats being occupied by the deadheading crew, but also leads
to paying crew wages for the deadheading hours. Hence, it is
desirable for airlines to reduce deadhead ﬂights in their crew
schedules to the minimum possible, ideally zero.

corresponding to a ﬂight f . For a tth CG-iteration, these
dual-variables are calculated by solving a dual-model of the
CPOP. This dual-model is constructed using LP (t) and the
given ﬂight set, F. The dual-variables are collectively rep-
resented by a dual-vector, y(t), which is a column-matrix,
given as [[y(t)
f ≥ 0]]T. In this manner, the in-
terdependencies between the active (tth) and its immediately
preceding iteration ((t − 1)th) are captured.

f ∀f ∈ F | y(t)

it

In CPOP, being a combinatorial optimization problem,
a pairing (optimization-variable) is neither explicitly good
nor explicitly bad until evaluated in a feasible set of pair-
ings. At a tth CG-iteration,
is highly likely that a
pairing rejected from any of the previous LP-solutions
(LP (t−1), LP (t−2), ..., orLP (1)), due to its lower contribu-
tion in them, might become a critical-part of the LP (t). Sim-
ilarly, there might exist other implicit relationships which
are not interpretable using the existing domain-knowledge.
This builds the rationale for the development of the proposed
learning framework that attempts to learn implicit combi-
In the
natorial pattern(s), hidden in the optimization-data.
proposed framework, the learning is performed at the end
of multiple CG-iterations, each called a learning-iteration.
The learnt pattern(s) are simultaneously used (in the same
iteration) to assist the convergence of the succeeding itera-
tions. The solution’s quality is extremely poor in initial CG-
iterations and improves as the optimization-search converges.
Hence, to avoid pre-mature learning, the learning-iterations
are kept at larger-gaps initially. The frequency of learning is
increased as the optimization-search converges. What hap-
pens in each of these learning-iterations is discussed in detail
in the following subsections.

Input Dataset

3.1
At a tth CG-iteration, the optimization-data from all t CG-
iterations is available. This consists of:
• LP-solutions (LP (t), LP (t−1), ...LP (1)),
• cost of LP-solutions (C (t), C (t−1), ...C (1)), and
• dual-vectors (y(t), y(t−1), ...y(1))

An LP (t) consists of a set of pairings P (t) and its primal-
vector x(t) which is a column-matrix, given as [[x(t)
p ∀p ∈
P (t) | 0 ≤ x(t)
p ≤ 1]]T. A x(t) is simply a weight-vector
of P (t), representing relative-contribution of its pairings to-
wards covering the ﬂights in F. During experiments, it is
observed that the optimization-search of a large and complex
CPOP (4212 ﬂights and 15 crew bases) involves generation
and evaluation of billion-plus pairings. This makes it im-
practical to explicitly use these billion-plus pairings as input
data points for the learning algorithm. Alternatively, LP (t)
is modeled as a weighted directed multigraph G(t), given by
an ordered pair (F, E (t)), where ﬂights in F become vertices,
and E (t) is the set of directed edges (legal ﬂight-connection),
given as {(fi, fj) | (fi, fj) ∈ pk ∀ pk ∈ P (t) ∧ i < j}.
Please note that G is referred to as ﬂight-connection graph
interchangeably throughout this paper. In the test-instances

Figure 1: A legal crew pairing starting and ending at Dallas, DAL,
crew base

2.2 Pairing Legality Constraints & Costing Rules
A number of airline regulatory bodies, such as FAA1, EASA2,
etc., govern the safety of the passengers and protects the in-
terest of the crew members. For this, several non-linear con-
straints have to be satisﬁed by a crew pairing to be classi-
ﬁed as legal. Moreover, several other constraints linked to an
airline’s in-house regulations, region-speciﬁc labor laws, etc.
have to be satisﬁed by a legal crew pairing. Furthermore, a
set of non-linear costing rules is used by airlines to calculate
the cost of legal crew pairings. Interested readers are referred
to [Aggarwal et al., 2018] for a detailed discussion on these
non-linear legality constraints and costing rules.

2.3 Developed Airline Crew Pairing Optimizer
The developed CG-based airline crew pairing optimizer,
named as AirCROP, is capable of generating high-quality so-
lutions for large-scale CPOPs [Aggarwal et al., 2020a]. It has
been validated on large and complex ﬂight networks (char-
acterized by multiple hub-and-spoke subnetworks, multiple
crew bases & billion-plus legal crew pairings) in collabora-
tion with the industrial sponsor. A number of modules make
up this proprietary optimizer, namely Legal Crew Pairing
Generation [Aggarwal et al., 2018], Initial Feasible Solution
Generation [Aggarwal et al., 2020b], and Optimization En-
gine. The aim of the proposed research work is to assist the
Optimization Engine module, especially in the CG-phase of
the optimizer. Being a propriety optimizer, AirCROP is used
as a black-box for demonstration of the utility of this research
work.

3 Proposed Learning Framework
As discussed in Section 1,
the notion of incorporating
domain-knowledge in CG heuristics has gained traction in
solving large-scale CPOPs [Zeren and ¨Ozkol, 2016]. In each
CG-iteration, domain-knowledge inspired special heuristics
utilize the existing ﬂight-connection information to identify
a set of critical ﬂights. Subsequently, the identiﬁed set is
used to construct the pricing subproblem from which new
pairings are generated and only the pairings with negative re-
duced costs (c(cid:48)) are added to the existing LP-solution, say
LP. For a pairing p, c(cid:48)
f ∈p yf , where
cp is the pre-calculated cost of p, and yf is a dual-variable

p is calculated as cp − (cid:80)

1FAA stands for Federal Aviation Administration.
2EASA stands for European Aviation Safety Agency.

used in this research work, the ﬂight indexes are sorted with-
respect-to their timestamps3. And a ﬂight cannot have a le-
gal ﬂight connection with itself. Hence, the ordered pairs
in {(fi, fj) | (fi, fj) ∈ F 2 ∧ i >= j} are invalid and ex-
cluded from the deﬁnition of G(t). Figure 2 presents a ﬂight-
connection graph of a very small pairing set for a CPOP with
3202 ﬂights. The largest test-case provided by the industrial

Figure 2: Flight-connection graph of a small LP for a CPOP, cover-
ing 3202 ﬂight nodes using 21,564 edges in 7991 pairings

sponsor contains 4212 ﬂights and its number of all legal ﬂight
connections will be ≤ 4212 × 4212. Hence, the adjacency
matrix A(t) (size |F| × |F|) of a ﬂight-connection graph G(t)
is a viable representation of an input data point than a huge
set of pairings (matrix of size |P| × |F| where |P| can vary
upto a million). Therefore, a global adjacency matrix ˜A(t)
is constructed to be used as input dataset for the learning al-
gorithm. In addition to this, an input feature matrix F(t) is
constructed by formulating critical features from the avail-
able optimization-data. These two matrices are discussed in
detail in the following text.

Global Adjacency Matrix
For a ﬂight-connection graph G(t) with vertex set F, the adja-
cency matrix A(t) is a square matrix of size |F| × |F| whose
elements represent the legal ﬂight-connections, i.e., edges in
E (t). An element a(t)
ij of A(t), corresponding to its ith row
and jth column, is a binary variable, and is either = 1 if the
ordered pair (fi, fj) exists in G(t), or is = 0 otherwise. In ac-
cordance with the deﬁnition of G(t), matrix A(t) is a strictly
upper-triangular matrix.

For learning at a tth CG-iteration, a global adjacency ma-
trix ˜A(t) is constructed by superimposing individual adja-
cency matrices A(k) ∀k ∈ [1, t]. Let ˜a(t)
ij be the element
of matrix ˜A(t), corresponding to its ith row and jth column.
Therefore,

˜a(t)
ij =

(cid:26)1,

if aij = 1 ∈ A(1) ∪ A(2) ∪ ... ∪ A(t)

0, otherwise

(1)

3A timestamp gives the information about the date and time of

the event.

Feature Matrix
For higher prediction accuracy of any learning algorithm, it
is desirable to train it not only on a large number of fea-
tures but also on the most critical ones. From the avail-
able optimization-data, several critical features are formu-
lated using the domain-knowledge. As mentioned before, the
solution quality (LP-cost, C (t)) improves iteratively during
the optimization-search and it is imperative to ensure that
the characteristics of a tth CG-iteration are weighed more
than those of the (t − 1)th iteration. This is done by mul-
tiplying them with a cost-ratio, CR(t), given as CR(t) =
C (t−1)/C (t). This enables the learning algorithm to capture
the solution’s evolution by giving higher weights to the better
and more recent solution. The features formulated using the
primal- and dual-information, available in the optimization-
data at a tth iteration, are as follows:
F1- Enhanced Primal Matrix, X(t): As explained above,
in a tth CG-iteration,
the fractional contribution of
a pairing p ∈ P (t) for covering a ﬂight-connection
(fi, fj) ∈ G(t) is given by its primal-variable x(t)
p .
Hence, the weight w(t)
ij of an edge (fi, fj) is given as
ij = (cid:80)
w(t)
p∈P (t)(x(t)
| (fi, fj) ∈ p). Using these
weights and matrix A(t) , a weighted-adjacency matrix
ˆA(t) is deﬁned whose elements ˆa(t)
ij =
a(t)
ij ∗ w(t)
ij . The ˆA(t) for all t iterations are enhanced
using the corresponding CR(t) and are added to con-
struct an enhanced primal matrix X(t) of size |F| × |F|.
Therefore, X(t) = CR(1). ˆA(1) + CR(2). ˆA(2) + ... +
CR(t). ˆA(t). It is to be noted that CR(1) is assumed to
be = 1 on the basis that C (0) does not exists.

ij are given as ˆa(t)

p

F2- Enhanced Dual Matrix, Y(t): In a tth CG-iteration,
a dual-vector y(t) consists of dual-variables which are
shadow-prices of the corresponding ﬂights and reﬂect
their contribution in the C (t). The distribution of these
fractional contributions (y(t)
f /C (t)) over all t iterations
for all ﬂights does not follow the same trend and are not
explicitly interpretable. Hence, these ﬂights’ fractional
contributions for each iteration are concatenated to con-
struct an enhanced dual matrix Y(t) of size |F|×t, given
as
Y(t) = [[ CR(1)

CR(t)
C(t) .y(t)]].
The features formulated using the graphical properties of the
ﬂight nodes are as follows:
F3- Enhanced In-degree Matrix, ˜I(t):

CR(2)
C(2) .y(2)

C(1) .y(1)

In a ﬂight-
connection graph, the sum of weights of incoming edges
for a ﬂight f is referred to as its in-degree, denoted by
deg−(f ). For a G(t), an in-degree matrix ˆI(t) is con-
structed whose elements are = sum(ˆa∗,j), where ˆa∗,j
is the jth column of matrix ˆA(t). Using these ˆI(t) and
the corresponding CR(t), an enhanced in-degree ma-
trix ˜I(t) of size |F| × 1 is constructed which is given
as ˜I(t) = CR(1).ˆI(1) + CR(2).ˆI(2) + ... + CR(t).ˆI(t).

...

F4- Enhanced Out-degree Matrix, ˜O(t):

In a ﬂight-
connection graph, the sum of weights of outgoing edges

from a ﬂight f is referred to as its out-degree, denoted by
deg+(f ). For a G(t), an out-degree matrix ˆO(t) is con-
structed whose elements are = sum(ˆai,∗), where ˆai,∗
is the ith row of matrix ˆA(t). Using these ˆO(t) and
the corresponding CR(t), an enhanced out-degree ma-
trix ˜O(t) of size |F| × 1 is constructed which is given as
˜O(t) = CR(1). ˆO(1) + CR(2). ˆO(2) + ... + CR(t). ˆO(t).
These two features help gauge the importance of ﬂights
by measuring how densely each ﬂight is connected to other
ﬂights. The ﬂight(s) with higher in-degree and out-degree
might be intuitively considered to be important than the other
ﬂights.

Each of the above-deﬁned features is normalized within it-
self using a min-max normalization technique [Hastie et al.,
2009] so that the values are scaled to [0, 1]. This ensures that
none of the features get unduly high weightage and all fea-
tures are on a similar scale. After feature re-scaling, these fea-
ture matrices are concatenated to construct the input feature
matrix F(t), given as F(t) = [[X(t)
|F |×1]],
and its size is |F| × N where N = |F| + t + 2.

|F |×|F | Y(t)

˜O(t)

˜I(t)

|F |×1

|F |×t

3.2 Learning Algorithm
In the proposed framework, a Variational Graph Autoencoder
(VGAE) [Kipf and Welling, 2016b] is adapted as the learn-
ing algorithm. VGAE is a type of variational auto-encoders,
developed for unsupervised learning on graph-structured data
by using the interpretable latent representations of the graphs.
[Kipf and Welling, 2016b] demonstrated the supremacy of
VGAE over traditional methods of link prediction and un-
supervised learning on graph-structured data. A working
representation of VGAE in the context of airline CPOP is
demonstrated in Figure 3. The ﬁgure represents the input
dataset of the learning algorithm, i.e., matrix ˜A(t) at a tth
CG-iteration of an optimizer-run for a 3202 ﬂight dataset.
Let ˜E (t)+ & ˜E (t)− be the disjoint sets of ﬂight-pairs corre-
sponding to all 1’s & all 0’s in ˜A(t) respectively. Hence,
˜E (t)+ = {(fi, fj)|(fi, fj) ∈ ˜A(t) ∧ ˜a(t)
ij = 1}, and ˜E (t)− =
{(fi, fj)|(fi, fj) ∈ ˜A(t) ∧ ˜a(t)
l be the learn-
ing model. The output of M(t)
includes the prediction val-

ij = 0}. Let M(t)

l

Figure 3: Working of VGAE

l ), F, y(t), Pairing_Gen()

s ← sort_descend( ˜E (t)−) using P ( ˜E (t)−)

sort do
if | ˜F (t)| ≤ (cid:98)P aram1 ∗ Acc(M(t)
˜F (t) ← Add ﬂights fi & fj

Algorithm 1 Combination heuristic
Input: ˜E (t)−, P ( ˜E (t)−), Acc(M(t)
Parameter: P aram1
Output: ˜P (t)
1: ˜F (t) ← φ
2: ˜E (t)−
3: for (fi, fj) ∈ ˜E (t)−
4:
5:
6:
7:
end if
8:
9: end for
10: γ ← P aram1 − | ˜F (t)|
11: ˜F (t) ← Randomly select γ ﬂights from F
12: ˜P (t) ← Pairing_Gen( ˜F (t), y(t))
13: return ˜P (t)

break

else

l )(cid:99) then

ues, P ( ˜E (t)+) & P ( ˜E (t)−), and its ROC score, roc(M(t)
l ) in
decimal. The aim of the proposed learning algorithm is not
only to ﬁnd the most convoluted ﬂight-pairs but also to ﬁnd a
set of ﬂight-pairs different from ˜E (t)+. This helps in expand-
ing the search-space of the optimizer by generating pairings
different from the ones encountered during the optimization-
search. Hence, the only relevant information from the output
of M(t)

includes roc(M(t)

l ) and P ( ˜E (t)−).

l

3.3

Integration with AirCROP

The proposed learning framework is aimed to assist in the
CG-iterations of AirCROP by providing a set of most criti-
cal ﬂight-pairs, after learning from previous solutions. These
learnt ﬂight-pairs are combined using a special heuristic to
generate new legal pairings. The pseudo code of this com-
bination heuristic is summarized in Algorithm 1. Let ˜F (t)
& ˜P (t) be the set of ﬂights to be extracted from the learnt
ﬂight-pairs and the set of pairings to be generated from these
ﬂights. Let P aram1 be a user-deﬁned parameter which de-
cides the number of ﬂights to be added to ˜F (t). It is restricted
to be < |F|/2 to maintain tractability in the subsequent pair-
ing generation phase. In line 2, ˜E (t)− is sort in descending-
order w.r.t. P ( ˜E (t)−). In lines 3-9, individual ﬂights from
the top ﬂight-pairs of ˜E (t)−
are added to ˜F (t) until its length
exceeds a user-deﬁned limit (cid:98)P aram1 ∗ roc(M(t)
l )(cid:99). The
roc(M(t)
l ) is used here to account for unreliability factor
(1 − roc(M(t)
. The rest of the ﬂights
(P aram1 − (cid:98)P aram1 ∗ roc(M(t)
l )(cid:99)) are selected randomly
from F. Finally, in line 12, the pairing generation module is
called using ˜F (t) & y(t) as inputs, to generate new legal pair-
ings with negative reduced costs. As discussed in Section 3,
the learning framework performs learning several times dur-
ing the CG-iterations of AirCROP. The decision on how much
gap to maintain between two successive learning-iterations
and whether the gap should be constant or adaptive, is left in

l )) in the results of M(t)

s

l

n

100

500

1000

α = 0.001

α = 0.01

α = 0.1

roc

0.75

0.85

0.91

t (s)

219.97

1050.75

2124.94

roc

0.90

0.94

0.94

t (s)

214.68

1053.98

2108.37

roc

0.72

0.71

0.50

t (s)

213.07

1054.05

2093.39

Table 1: First step of hyperparameter tuning

the hands of the airline users to cater to their varying require-
ments.

4 Computational Experiments
All computational experiments have been conducted on a
HP-Z640 workstation, powered by Intel R(cid:13) Xeon R(cid:13) Processor
E5-2630v3, with 64GB of RAM and 32 cores at 2.4 GHz
clock speed. The proposed methodology is implemented us-
ing python v3.6 programming language. The VGAE has been
adapted from its original code, given by [Kipf and Welling,
2016b]. The internal settings of AirCROP are kept constant
for all runs so that the results are not skewed and are compa-
rable. The run-time of AirCROP (without the learning frame-
work) is around 6 & 14 hours for CPOPs with around 3200 &
4200 ﬂights respectively. To keep the run-time of AirCROP
with learning framework as low as possible, the learning
model is allowed to terminate as soon as roc(M(t)

l ) ≥ 0.9.

For this research work, the industrial sponsor has provided
three real-world large-scale airline test-cases, (1) TC1 with
3202 ﬂights, (2) TC2 with 3228 ﬂights, and (3) TC3 with
4212 ﬂights, from the networks of their client airlines. These
test-cases, extracted from networks of US-based airlines, con-
tain multiple hub-and-spoke subnetworks and 15 crew bases.
As a result, the number of possible legal pairings is extremely
large (in the order of millions/billions). A set of pairing’s le-
gality constraints and costing rules are also provided in these
test-cases. An interesting observation is that it is these le-
gality constraints which are responsible for the shape of the
ﬂight-connections in Figure 3.

4.1 Hyperparameter Tuning
Being in an assistive role, the learning model is tuned in a way
to keep the run-time of learning-iterations as low as possible
while ensuring a good roc score (≥ 0.9). This in turn helps in
keeping the optimizer’s runtime under control. Two possible
hyperparameters (epochs n & learning rate α) are selected for
hyperparameter tuning which is performed in two steps. In
the ﬁrst step, n is varied as 100, 500 and 1000 with α varying
as powers of 10 and its results are shown in Table 1. Clearly,
a reasonable choice is n = 100 with α = 0.01 (highlighted

Mesure(s)

α

0.02

0.03

0.04

0.05

roc
t (s)

0.901
215.79

0.919
213.32

0.877
215.32

0.861
214.64

Table 2: Second step of hyperparameter tuning (n = 100)

in Table 1). By selecting n = 100 from here, a favorable
baseline run-time is established for the second step in which
α is then varied as multiples of the chosen power of 10. From
its results, shown in Table 2, the optimum value of α comes
out as 0.03.

4.2 AirCROP-Runs with Learning Framework
For all three test-cases, the optimizer-runs are performed with
& without the learning framework and the respective results
are compared to establish the signiﬁcance of the proposed
contributions. These results are presented in Table 3. In large-
scale CPOPs, it is observed that the cost of integer solution at
the end of the main optimization loop is extremely poor un-
less new pairings are also generated in the IP-phase. To over-
come this limitation, the integer solution from the main op-
timization loop is re-optimized using the same methodology
(CG followed by IP). This re-optimization loop is repeated
multiple times till IP-cost becomes equal to its root LP-cost,
or till a user deﬁned cut-off. In the referred table, the val-
ues of cost and number of CG-iterations4 z for all optimiza-
tion loops are presented for all test cases. It is observed that
in optimizer-runs with the learning framework, substantially
lower costs are achieved, especially for TC1 & TC3. These
reductions are seen across datasets as well as successive op-
timization loops albeit there are some exceptions. Another
critical observation is the achievement of lower-cost solution
in fewer re-optimization loops while using the optimizer with
the learning framework for TC3.

Figures 4a-4c represent the comparison plots of cost vs
number of iterations (from beginning of the runs) for all
optimizer-runs and all datasets. The initial solutions are ex-
cluded from these ﬁgures as their respective costs are ex-
tremely poor in comparison to their respective optimal-costs,
leading to distortion of scales. In Figures 4a & 4c, the IP-
sol. lines for runs with and without the learning framework
intersect at a point A. This implies that after point A, the run
with the learning framework provides better IP-solutions and
that too in a shorter runtime. Moreover, each IP-solution is a
sufﬁcient solution in itself and the decision lies with the user
to stop after any IP as per individual time constraints. The
proposed learning framework is only used to assist the CG-
phase. Hence, the changes in IP-cost (mostly positive im-
provements) are attributed to the changes in the LP-solutions
of their respective CG-phases. Even though a drop in costs is
observed across the board, an increase (approximately dou-
bled) in optimizer’s runtime is observed when the learning
framework is used. This is attributed to the fact that training
an auto-encoder is a time- and resource-intensive process.

5 Conclusion
To the authors’ knowledge, this research has proposed a ﬁrst
of its kind learning framework within the paradigm of Air-
line Crew Pairing Optimization. This framework based on
the Variational Graph Auto-Encoder, is shown to be capable
of learning implicit combinatorial ﬂight-connection patterns,
on-the-ﬂy, eventually leading up to signiﬁcant cost savings

4modules other than CG are assumed in equivalence to 1 CG-

iteration

AirCROP’s

Modules

Cost
(USD)

Initial Solution

4,696,619

Main-Opt CG 3,475,707
3,685,633
IP
Loop

Re-Opt
Loop 1

Re-Opt
Loop 2

Re-Opt
Loop 3

Re-Opt
Loop 4

Re-Opt
Loop 5

CG 3,483,479
IP
3,581,795

CG 3,487,314
3,541,958
IP

CG 3,487,476
3,511,944
IP

CG 3,487,662
IP
3,502,514

CG
IP

TC1

TC2

TC3

w/o Learning

w/ Learning

w/o Learning

w/ Learning

w/o Learning

w/ Learning

z

01

65
01

28
01

22
01

22
01

20
01

Cost
(USD)

4,696,619

3,468,115
3,710,720

3,472,723
3,565,269

3,476,249
3,509,156

3,480,835
3,501,972

3,482,579
3,491,307

z

01

79
01

31
01

24
01

21
01

14
01

Change
in cost
(USD)

Cost
(USD)

0

5,002,751

-7,592
+25,087

-10,756
-16,526

-11,065
-32,802

-6,641
-9,972

-5,083
-11,207

3,499,950
3,748,000

3,505,069
3,559,727

3,513,929
3,528,128

3,513,784
3,513,784

3,513,437
3,513,437

z

01

63
01

38
01

17
01

17
01

12
01

Cost
(USD)

5,002,751

3,499,832
3,692,650

3,504,403
3,545,146

3,509,138
3,526,182

3,509,916
3,512,760

3,509,986
3,513,232

z

01

75
01

34
01

25
01

19
01

18
01

Change
in cost
(USD)

Cost
(USD)

z

Cost
(USD)

0

5,415,114

01

5,415,114

-118
-55,350

-666
-14,581

-4,791
-1,946

-3,868
-1,024

-3,451
-205

4,599,803
4,896,974

4,613,596
4,710,090

4,632,585
4,652,460

4,631,449
4,648,552

4,631,700
4,639,736

4,634,794
4,634,794

134
01

50
01

36
01

35
01

26
01

17
01

4,592,395
4,935,672

4,6105,94
4,739,417

4,634,389
4,642,060

4,632,915
4,637,990

4,632,343
4,632,343

Change
in cost
(USD)

0

-7,408
+38,698

-3,002
+29,327

+1,804
+10,400

+1,466
-10,562

+643
-7,393

z

01

131
01

67
01

47
01

26
01

27
01

Final Results

3,502,514

163

3,491,307

175

11,207

3,513,437

153

3,513,232

177

205

4,634,794

287

4,632,343

304

2,451

Time (hrs)

6.53

13.14

5.82

13.43

13.58

29.69

Table 3: Results of AirCROP’s runs with & without the learning framework

(a) TC1

(b) TC2

(c) TC3

Figure 4: Plots of cost vs number of iterations for optimizer-runs with & without the learning framework

within fewer CG-iterations. The efﬁcacy and robustness of
the proposed framework is endorsed through empirical results
on three real-world, large and complex ﬂight datasets of US-
based airlines. On the ﬂip side, the above advantages come at
the expense of larger (almost double) run time for the overall
optimizer. However, this runtime could be drastically reduced
with the usage of GPU(s). Though the cost of computational
resources may be signiﬁcant, the corresponding cost-savings
for an airline may well offset those in the long-run.

Acknowledgment

This research work is an outcome of an Indo-Dutch joint re-
search project. It is supported by the Ministry of Electron-
ics and Information Technology (MEITY) from India [grant
13(4)/2015-CC&BT], Netherlands Organization for Scien-
tiﬁc Research (NWO) from the Netherlands, and General
Electric (GE) Aviation. The authors would like to acknowl-
edge the invaluable support of GE Aviation team members:
Saaju Paulose (Senior Manager), Arioli Arumugam (Senior
Director- Data & Analytics), and Alla Rajesh (Senior Staff
Data & Analytics Scientist) for providing problem deﬁnition,

real-world test cases, and for sharing domain-knowledge dur-
ing numerous insightful discussions that helped the authors
in successfully completing this work.

References

[Aggarwal et al., 2018] Divyam Aggarwal, Dhish Kumar
Saxena, Michael Emmerich, and Saaju Paulose. On large-
In 2018 IEEE
scale airline crew pairing generation.
Symposium Series on Computational Intelligence (SSCI),
pages 593–600. IEEE, 2018.

[Aggarwal et al., 2020a] Divyam Aggarwal, Dhish Kumar
Saxena, Thomas B¨ack, and Michael Emmerich. Aircrop:
Airline crew pairing optimizer for complex ﬂight networks
involving multiple crew bases & billion-plus variables.
arXiv:2003.03994 [cs.MS], 2020.

[Aggarwal et al., 2020b] Divyam Aggarwal, Dhish Kumar
Saxena, Thomas B¨ack, and Michael Emmerich. On ini-
tializing airline crew pairing optimization for large-scale
complex ﬂight networks. arXiv:2003.03994 [cs.AI], 2020.

[Kipf and Welling, 2016a] Thomas N. Kipf

timization algorithms over graphs. In Advances in Neural
Information Processing Systems, pages 6348–6358, 2017.
and Max
Semi-supervised classiﬁcation with graph

Welling.
convolutional networks. CoRR, abs/1609.02907, 2016.

[Kipf and Welling, 2016b] Thomas N. Kipf

Welling.
abs/1611.07308, 2016.

Variational graph auto-encoders.

and Max
ArXiv,

[Land and Doig, 1960] AH Land and AG Doig. An auto-
matic method of solving discrete programming problems.
Econometrica, 28(3):497–520, 1960.

[Li et al., 2018] Zhuwen Li, Qifeng Chen, and Vladlen
Koltun. Combinatorial optimization with graph convolu-
In Advances in
tional networks and guided tree search.
Neural Information Processing Systems, pages 539–548,
2018.

[L¨ubbecke, 2010] Marco E L¨ubbecke. Column generation.
Wiley Encyclopedia of Operations Research and Manage-
ment Science, John Wiley and Sons, Chichester, UK, 2010.
[Murty, 1983] Katta G. Murty. Linear programming. John
Wiley & Sons, Inc., New York, 1983. With a foreword by
George B. Dantzig.

[Priore et al., 2014] Paolo Priore, Alberto G´omez, Ra´ul
Pino, and Rafael Rosillo. Dynamic scheduling of man-
ufacturing systems using machine learning: An updated
review. AI EDAM, 28(1):83–97, 2014.

[Soumis et al., 2019] Franc¸ois Soumis, Yassine Yaakoubi,
and Simon Lacoste-Julien. Flight-connection prediction
for airline crew scheduling to construct initial clusters for
or optimizer. 2019.

[Vance et al., 1997] Pamela H Vance, Cynthia Barnhart, Eric
Gelman, Ellis L Johnson, Alamuru Krishna, Deepa Mahid-
hara, George L Nemhauser, and Ranjit Rebello. A heuris-
tic branch-and-price approach for the airline crew pairing
problem. Technical report lec-97-06, Georgia Institute of
Technology, Atlanta, 1997.

[Wang et al., 2016] Peng Wang, Gang Zhao, and Xingren
Yao. Applying back-propagation neural network to pre-
dict bus trafﬁc. In 2016 12th International Conference on
Natural Computation, Fuzzy Systems and Knowledge Dis-
covery (ICNC-FSKD), pages 752–756. IEEE, 2016.

[Zeren and ¨Ozkol, 2016] Bahadır Zeren and Ibrahim ¨Ozkol.
A novel column generation strategy for large scale airline
crew pairing problems. Expert Systems with Applications,
55:133–144, 2016.

[Anbil et al., 1992] Ranga Anbil, Rajan Tanga, and Ellis L.
Johnson. A global approach to crew-pairing optimization.
IBM Systems Journal, 31(1):71–78, 1992.

[Anbil et al., 1998] Ranga Anbil,

and
William R Pulleyblank. Column generation and the airline
crew pairing problem. Documenta Mathematica, 3(1):677,
1998.

John J Forrest,

[Aytug et al., 1994] Haldun Aytug,

Siddhartha Bhat-
tacharyya, Gary Koehler, and Jane Snowdon. A review
of machine learning in scheduling. Engineering Man-
IEEE Transactions on, 41:165 – 171, 06
agement,
1994.

[Barnhart et al., 1998] Cynthia Barnhart, Ellis L Johnson,
George L Nemhauser, Martin WP Savelsbergh, and
Pamela H Vance. Branch-and-price: Column generation
for solving huge integer programs. Operations research,
46(3):316–329, 1998.

[Barnhart et al., 2003] Cynthia Barnhart, Amy M Cohn, El-
lis L Johnson, Diego Klabjan, George L Nemhauser, and
Pamela H Vance. Airline crew scheduling. In Handbook
of transportation science, pages 517–560. Springer, 2003.
[Bengio et al., 2018] Yoshua Bengio, Andrea Lodi, and An-
toine Prouvost. Machine learning for combinatorial op-
a methodological tour d’horizon. CoRR,
timization:
abs/1811.06128, 2018.

[Bernhard and Vygen, 2012] Korte Bernhard and Jens Vy-
gen. Combinatorial Optimization: Theory and Algorithms
(5 ed.). Springer, 2012.

Innovization:

[Deb and Srinivasan, 2006] Kalyanmoy Deb and Aravind
Innovating design principles
Srinivasan.
In Proceedings of the 8th an-
through optimization.
nual conference on Genetic and evolutionary computation,
pages 1629–1636. ACM, 2006.
[Desaulniers and Soumis, 2010] G

and
F Soumis. Airline crew scheduling by column gen-
eration. CIRRELT Spring School, Montr´eal Canada,
2010.

Desaulniers

[Gabriel Crainic and Rousseau, 1987] Teodor

Gabriel Crainic and Jean-Marc Rousseau.
The col-
umn generation principle and the airline crew scheduling
problem. INFOR: Information Systems and Operational
Research, 25(2):136–151, 1987.

[Gaur and Deb, 2016] Abhinav Gaur and Kalyanmoy Deb.
Adaptive use of innovization principles for a faster con-
vergence of evolutionary multi-objective optimization al-
gorithms. In Proceedings of the 2016 on Genetic and Evo-
lutionary Computation Conference Companion, pages 75–
76. ACM, 2016.

[Hastie et al., 2009] Trevor Hastie, Robert Tibshirani, and
Jerome Friedman. The elements of statistical learning:
data mining, inference, and prediction. Springer Science
& Business Media, 2009.

[Khalil et al., 2017] Elias Khalil, Hanjun Dai, Yuyu Zhang,
Bistra Dilkina, and Le Song. Learning combinatorial op-

