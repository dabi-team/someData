1
2
0
2

r
a

M
1
3

]
I

A
.
s
c
[

1
v
8
5
1
0
0
.
4
0
1
2
:
v
i
X
r
a

Under consideration for publication in Theory and Practice of Logic Programming

1

Online Learning Probabilistic Event Calculus Theories
in Answer Set Programming

NIKOS KATZOURIS1, ALEXANDER ARTIKIS2,1 and GEORGIOS PALIOURAS1,
1Institute of Informatics & Telecommunications,
National Center for Scientiﬁc Research (NCSR) “Demokritos”, Athens, Greece
2Department of Maritime Studies, University of Piraeus, Piraeus, Greece
@iit.demokritos.gr)
(e-mail:
}

nkatz,a.artikis,paliourg

{

submitted 1 January 2003; revised 1 January 2003; accepted 1 January 2003

Abstract

Complex Event Recognition (CER) systems detect event occurrences in streaming time-stamped input us-
ing predeﬁned event patterns. Logic-based approaches are of special interest in CER, since, via Statistical
Relational AI, they combine uncertainty-resilient reasoning with time and change, with machine learning,
thus alleviating the cost of manual event pattern authoring. We present a system based on Answer Set Pro-
gramming (ASP), capable of probabilistic reasoning with complex event patterns in the form of weighted
rules in the Event Calculus, whose structure and weights are learnt online. We compare our ASP-based
implementation with a Markov Logic-based one and with a number of state-of-the-art batch learning algo-
rithms on CER datasets for activity recognition, maritime surveillance and ﬂeet management. Our results
demonstrate the superiority of our novel approach, both in terms of efﬁciency and predictive performance.
This paper is under consideration for publication in Theory and Practice of Logic Programming (TPLP).

1 Introduction

Complex Event Recognition (CER) systems (Cugola and Margara 2012) detect occurrences of
complex events (CEs) in streaming input, deﬁned as spatio-temporal combinations of simple
events (e.g. sensor data), using a set of CE patterns. Since such patterns are not always known be-
forehand, machine learning algorithms for discovering them from data are highly useful. Thanks
to their efﬁciency, online learning algorithms are of special interest. Such algorithms should be
resilient to noise & uncertainty, which are ubiquitous in temporal data streams (Alevizos et al.
2017), while taking into account commonsense phenomena (Mueller 2014), which often charac-
terize dynamic application domains, such as CER.

Logic-based CER systems (Artikis et al. 2012) stand up to these challenges. They com-
bine reasoning under uncertainty with machine learning, via Statistical Relational AI techniques
(De Raedt et al. 2016), while supporting reasoning with time and change, via action formalisms
such as the Event Calculus (Artikis et al. 2015).

We advance the state of the art in online learning for CER by proposing WOLED (Online
Learning of Weighted Event Deﬁnitions), an algorithm that learns CE patterns in the form of
weighted rules in the Event Calculus. The proposed algorithm is based entirely on Answer Set
Programming (ASP) (Lifschitz 2019), which allows to take advantage of the grounding, solv-
ing, optimization and uncertainty modeling abilities of modern answer set solvers, while em-
ploying structure learning techniques from non-monotonic Inductive Logic Programming (ILP)
(De Raedt 2008), which are easily implemented in ASP.

 
 
 
 
 
 
2

N. Katzouris, A. Artikis and G. Paliouras

We compare WOLED’s ASP-based implementation to an MLN-based one, and to a number of
state of the art online & batch structure & weight learning algorithms, on three CER datasets
for activity recognition, maritime surveillance and vehicle ﬂeet management. Our results demon-
strate the superiority of WOLED, both in terms of efﬁciency and predictive performance.

This paper is an extended version of (Katzouris and Artikis 2020), which has been nominated

as a candidate for TPLP’s rapid publication track by KR2020’s program committee.

2 Related Work

Event Calculus-based CER (Artikis et al. 2015) was combined with MLNs in (Skarlatidis et al.
2015), in order to deal with the noise and uncertainty of CER applications. An inherent lim-
itation of this approach is the fact that the non-monotonic semantics of the Event Calculus is
incompatible with the open-world semantics of MLNs. Therefore, performing inference with
Event Calculus-based MLN theories calls for extra, costly operations, such as computing the
completion of a theory (Mueller 2014), in order to endow MLNs’ ﬁrst-order logic representa-
tions with a non-monotonic semantics. We bridge this gap via translating probabilistic inference
with MLNs into an optimization task in ASP, which naturally supports non-monotonic and com-
monsense reasoning. This also allows to delegate probabilistic temporal reasoning and machine
learning tasks to sophisticated, off-the-shelf answer set solvers.

Translating MLN inference in ASP has been put forth in (Lee and Wang 2016; Lee et al. 2017).
This line of work is mostly concerned with theoretical aspects of the translation, limiting appli-
cations to simple, proof-of-concept examples. Although we do rely on the theoretical foundation
of this work, we take a more application-oriented stand-point and investigate the usefulness of
these ideas in challenging domains, such as CER. We also propose a methodology for online
structure and the weight learning using ASP tools.

Regarding machine learning, a number of algorithms in non-monotonic Inductive Logic Pro-
gramming (ILP), such as XHAIL (Ray 2009), TAL (Athakravi et al. 2013) and ILASP (Law et al.
2018) are capable of learning Event Calculus theories, see (Katzouris 2017) for a comprehensive
review of such approaches. These algorithms are batch learners, they are thus poor matches to the
online nature of CER applications. Moreover, they learn crisp logical theories, thus their ability
to cope with noise and uncertainty is limited. Existing online learning algorithms are either crisp
learners (Katzouris et al. 2019), or they rely on MLNs (Katzouris et al. 2018; Michelioudakis
et al. 2016), so they suffer from the same limitations discussed earlier in this section. A recent
online learner based on probabilistic theory revision (Guimar˜aes et al. 2019) is limited to Horn
logic and cannot handle Event Calculus reasoning.

3 Background

Answer Set Programming. In what follows a rule r is an expression of the form α
δ1, . . . , δn,
where α is an atom, called the head of r, δ (cid:48)i s are literals (possibly negated atoms), which collec-
tively form the body of r and commas in the bodies of rules denote conjunction. A rule is ground
if it contains no variables and a grounding of a rule r is called an instance of r. A (Herbrand)
interpretation is a collection of true ground facts. An interpretation I satisﬁes an atom α iff α
I.
I satisﬁes a ground rule iff satisfying each literal in the body implies that the head atom is also
satisﬁed and it satisﬁes a non-ground rule r if it satisﬁes all ground instances of r. An interpreta-
tion I is a model of a logic program Π (collection of rules) if it satisﬁes every rule in Π and it is

←

∈

Theory and Practice of Logic Programming

3

(a)
Predicate:
happensAt(E, T )
initiatedAt(F, T )
terminatedAt(F, T )
holdsAt(F, T )

Meaning:
Event E occurs at time T .
At time T , a period of time for which ﬂuent F holds is initiated.
At time T , a period of time for which ﬂuent F holds is terminated.
Fluent F holds at time T .

(b) Axioms of the Event Calculus

holdsAt(F, T + 1)
holdsAt(F, T + 1)

←
←

initiatedAt(F, T ).
holdsAt(F, T ), not terminatedAt(F, T ).

(1)
(2)

(c)
Observations I1 at time 1:
happensAt(walk(id1), 1), happensAt(walk(id2), 1)
coords(id1, 201, 454, 1), coords(id2, 230, 440, 1),
direction(id1, 270, 1), direction(id2, 270, 1)
}

{

Target CE instances at time 1:
holdsAt(move(id1, id2), 2), holdsAt(move(id2, id1), 2)
}

{

(d) Weighted CE patterns:
1.283 initiatedAt(move(X,Y ), T )
←
0.923 terminatedAt(move(X,Y ), T )

happensAt(walk(X), T ), happensAt(walk(Y ), T ), close(X,Y, 25, T ), orientation(X,Y, 45, T ).

happensAt(inactive(X), T ), not close(X,Y, 30, T ).

←

Table 1: (a), (b) The basic predicates and the Event Calculus axioms. (c) Example CAVIAR data. At time
point 1 person with id1 is walking, her (X,Y ) coordinates are (201, 454) and her direction is 270◦. The
target CE atoms (true state – supervision) for time point 1 state that persons id1 and id2 are moving together
at the next time point. (d) An example of two domain-speciﬁc axioms in the EC. E.g. the ﬁrst rule dictates
that moving together between two persons X and Y is initiated at time T if both X and Y are walking at time
T , their euclidean distance is less than 25 pixel positions and their difference in direction is less than 45◦.
The second rule dictates that moving together between X and Y is terminated at time T if one of them is
standing still at time T and their euclidean distance at T is greater that 30.

a minimal model if no strict subset of I has this property. An interpretation I is an answer set of
Π iff it is a minimal model of the reduct of Π, i.e. the program that results by removing all rules
with a negated body literal not satisﬁed by I and removing all negated literals from the bodies of
the remaining rules.

A choice rule is an expression of the form

δ1, . . . , δn with the intuitive meaning that
α
{
whenever the body δ1, . . . , δn is satisﬁed by an answer set I of a program that includes the choice
rule, instances of the head α are arbitrarily included in I (satisﬁed) as well. A weak constraint
is an expression of the form : ~ δ1, . . . , δn.[w], where δi’s are literals and w is an integer. The
intuitive meaning of a weak constraint c is that the satisfaction of the conjunction δ1, . . . , δn by
an answer set I of a program that includes c incurs a cost of w for I. Inclusion of weak constraints
in a program triggers an optimization process that yields answer sets of minimum cost.

} ←

The Event Calculus is a temporal logic for reasoning about events and their effects. Its on-
tology comprises time points (integers), ﬂuents, i.e. properties which have certain values in time,
and events, i.e. occurrences in time that may affect ﬂuents and alter their value. Its axioms incor-
porate the commonsense law of inertia, according to which ﬂuents persist over time, unless they
are affected by an event. Its basic predicates and axioms are presented in Table 1(a), (b). Axiom
(1) states that a ﬂuent F holds at time T if it has been initiated at the previous time point, while
Axiom (2) states that F continues to hold unless it is terminated. Deﬁnitions of initiatedAt/2 and
terminatedAt/2 predicates are provided in a application-speciﬁc manner.

Using the Event Calculus in a CER context allows to reason with CEs that have duration in
time and are subject to commonsense phenomena, via associating CEs to ﬂuents. In this case, a
set of CE patterns is a set of initiatedAt/2 and terminatedAt/2 rules.

4

N. Katzouris, A. Artikis and G. Paliouras

As an example we use the task of activity recognition, as deﬁned in the CAVIAR project1.
The CAVIAR dataset consists of videos of a public space, where actors perform some activities.
These videos have been manually annotated by the CAVIAR team to provide the ground truth
for two types of activity. The ﬁrst type, corresponding to simple events, consists of knowledge
about a person’s activities at a certain video frame/time point (e.g. walking, standing still and so
on). The second type, corresponding to CEs/ﬂuents, consists of activities that involve more than
one person, for instance two people moving together, meeting each other and so on. The aim is
to detect CEs as of combinations of simple events and additional domain knowledge, such as a
person’s position and direction.

Table 1(c) presents an example of CAVIAR data, consisting of observations for a particular
time point, in the form of an interpretation I1. A stream of interpretations is matched against a
set of CE patterns (initiation/termination rules – see Table 1(d)), to infer the truth values of CE
instances in time, using the Event Calculus axioms as a reasoning engine. We henceforth call the
atoms corresponding to CE instances whose truth values are to be inferred/predicted, target CE
instances. Table 1(c) presents the target CE instances corresponding to the observations in I1.

In what follows the CE patterns included in a logic program Π are associated with real-valued
weights, deﬁning a probability distribution over answer sets of Π. Similarly to Markov Logic,
where a possible world may satisfy a subset of the formulae in an MLN, and the weights of the
formulae in a unique, maximal such subset determine the probability of the possible world, an
answer set of a program with weighted rules may satisfy subsets of these rules, and these rules’
weights determine the answer set’s probability. Based on this observation, (Lee and Wang 2016)
propose to assign probabilities to answer sets of a program Π with weighted rules as follows: For
each interpretation I, ﬁrst ﬁnd the maximal subset RI of the weighted rules in Π that are satisﬁed
by I. Then, assign to I a weight WΠ(I) proportional to the sum of weights of the rules in RI, if
I is an answer set of RI, else assign zero weight. Finally, deﬁne a probability distribution over
answer sets of Π by normalizing these weights.

Formally, let wr be the weight of rule r and ans(Π) the set of all interpretations I which are
answer sets of RI and which, moreover, satisfy all hard-constrained rules in Π (rules without
weights). Then:

WΠ(I) =






exp

0

(cid:18)

(cid:19)

wr

∑
RI

∈

r

if I

ans(Π)

∈
otherwise

(1)

PΠ(I) =

J

WΠ(I)
∑
ans(Π)

WΠ(J)

∈

(2)

4 Structure & Weight Learning in ASP

The task that WOLED, our proposed algorithm, addresses is to online learn the structure and
weights of CE patterns, while using their current version at each point in time to perform CER
in the streaming input. We adopt a standard online learning approach consisting of the following
steps: at time t the learner maintains a theory Ht (weighted CE pattern set, as in Table 1(c)),
has access to some static background knowledge (e.g. the axioms of the Event Calculus – Table
1(a)) and receives an interpretation It , consisting of a data mini-batch (as in Table 1(b)). Then
Ht on It (B is the background knowledge) and
(i) the learner performs inference (CER) with B

∪

1 http://homepages.inf.ed.ac.uk/rbf/CAVIARDATA1/

Theory and Practice of Logic Programming

5

generates a “predicted state”, consisting of inferred holdsAt/2 instances of the target predicate.
Via closed-world assumption, all such instances not present in the predicted state are assumed
false; (ii) if available, the true state, consisting of the actual truth values of the predicted atoms
is revealed; (iii) the learner identiﬁes erroneous predictions via comparing the predicted state to
the true one, and uses these mistakes to update the structure and the weights of the CE patterns
in Ht , yielding a new theory Ht+1. We next discuss each of these steps.

4.1 Generating the Inferred State

To make predictions with the weighted CE patterns in the incoming data interpretations, WOLED
uses MAP (Maximum A Posteriori) probabilistic inference2, which amounts to computing a most
probable answer set A of Π = B

It . From Equations (1), (2) it follows that

Ht

∪

∪

∈

A = arg max
I
ans(Π)

WΠ(I) = arg max
I
ans(Π)

PΠ(I) = arg max
I
ans(Π)
that is, a most probable answer set is one that maximizes the sum of weights of satisﬁed rules,
similarly to the MLN case, for possible worlds. This is a weighted MaxSat problem that may be
delegated to an answer set solver using built-in optimization tools. Since answer set solvers only
optimize integer-valued objective functions, a ﬁrst step is to convert the real-valued CE pattern
weights to integers. We do so by scaling the weights, via multiplying them by a positive factor,
while preserving their relative differences, and rounding the result to the closest integer.

∑
RI
r
∈

(3)

wr

∈

∈

Note that as it may be seen from Eq. (3), weight scaling by a positive factor does not alter the
set of most probable answer sets. Therefore, the inference result remains unaffected, provided
that rounding the weights to integer values preserves their relative differences. To ensure the
latter, we set the scaling factor to K/dmin, where dmin = mini
is the smallest distance
between any pair of weights and K is a large positive constant, which reduces precision loss when
rounding the scaled weights to integer values.

wi
|

wj

−

=j

|

The MAP inference/weighted MaxSat computation is realized via a standard generate-and-
test ASP approach, presented in Algorithm 1, whose input is the background knowledge B, the
current CE pattern set Ht and the current interpretation It . First, Ht is transformed into a new
bodyi is “decom-
program, T (Ht ), as follows: each CE pattern ri in Ht of the form ri = headi
posed”, so as to associate headi with a fresh predicate, satisﬁed/2, wrapping headi’s variables
and its unique id, i (line 5, Algorithm 1). The choice rule in line 6, the “generate” part of the
process, generates instances of satisﬁed/2 that correspond to groundings of bodyi. The weak
constraint in line 7, the “test” part of the process, decides which of the generated satisﬁed/2
instances will be included in an answer set, indicating groundings of the initial CE pattern ri, that
will be true in the inferred state.

←

∪

T (Ht )

It , i.e. the satisfaction of a ground instance of ri by A , incurs a cost of

As it may be seen from line 7, the violation of a weak constraint by an answer set A of
Π = B
wi on
A , where wi is ri’s integer-valued weight. The optimization process triggered by the inclusion
of these weak constraints in a program generates answer sets of minimum cost. During the cost
wi are actually rewards for rules with a positive wi, whose
minimization process, costs of

−

∪

−

2 Marginal inference, i.e. computing the probability of each target CE instance is also possible, but it is computationally
expensive since it requires a full enumeration of a program’s answer sets, or utilizing techniques for sampling from
such answer sets. We are not concerned with marginal inference in this work.

(cid:54)
6

N. Katzouris, A. Artikis and G. Paliouras

satisfaction by an answer set, via the violation of the corresponding weak constraint, reduces
the answer set’s total cost. The situation is reversed for rules with a negative weight, whose
corresponding weak constraint is associated with a positive cost.

Obtaining the inferred state amounts to “reading-off” target CE instances from an optimal
T (Ht )

(minimum-cost) answer set of the program B

It .

∪

∪

Algorithm 1 MAPInference(B, Ht, It)
Input: background knowledge B; the current CE pattern set Ht ;
the input interpretation It .
Output: Target CE instances included in the most probable
answer set of B

T (Ht )

It .

∪

∪

1: T (Ht ) := /0
2: for each CE pattern ri = α

δ1, . . . , δn in Ht with integer

weight wi do

←
3:
let vars(α) be a term wrapping the variables of α.
4:
Add to T (Ht ) the following rules:
5:
satisﬁed(vars(α), i).
α
←
6:
satisﬁed(vars(α), i)
{
} ←
: ~ satisﬁed(vars(α), i). [
7:
8: Find an optimal answer set Aopt of B
∪
9: return the target CE instances in Aopt.

wi, vars(α), i]
T (Ht )

δ1, . . . , δn.

It .

−

∪

Fig. 1: ASP-based MAP inference example.

Example 1
We illustrate the inference process via the example in Figure 1, where we assume that the target
CE to be recognized is a. (a) presents a CE pattern set Ht , i.e. a set of initiation & termination
condition for the target CE, a. We assume that the actual real-valued weights of the patterns
have been converted into integers; (b) presents the current data interpretation It ; (c) presents the
inferred state obtained with crisp logical inference, i.e. the target CE instances included in the
unique answer set of the program BK
It , where the CE patterns’ weights have been ignored.
∪
Ht , so a holds
Note that the occurrence of happensAt(b, 2)
at the next time point, 3, and it also holds at time points 4 & 5 via inertia. Then, the occurrence
of happensAt(c, 5)
Ht , so a does not holds at times 6,7,8, while the
occurrence of happensAt(d, 8)

It initiates the target CE a via rule1

Ht , so a holds at times 9 & 10.

It terminates a, via rule2

It re-initiates a, via rule3

Ht

∪

∈

∈

∈

∈

T (Ht )

(d) in Figure 1 presents the program T (Ht ) obtained from Ht , via the transformation in Al-
gorithm 1, to allow for MAP inference; Finally, (e) presents the MAP-inferred state, i.e. the
target predicate instances included in an optimal (minimum-cost) answer set of the program
It (for illustrative purposes the satisﬁed/2 instances in the optimal answer set
BK
are also presented). Note that the set of target CE inferences is reduced, as compared to the
crisp case, since the negative-weight, rule3
Ht is not satisﬁed by the optimal answer set. The
satisﬁed/2 instances in the MAP-inferred state correspond to the ground atoms terminatedAt(a, 5)
and initiatedAt(a, 2), which, along with inertia, are responsible for the target CE inferences.

∈

∪

∪

∈

∈

(a)CurrentCEpatternsetHt:11initiatedAt(a,T)←happensAt(b,T).(rule1)13terminatedAt(a,T)←happensAt(c,T).(rule2)−2initiatedAt(a,T)←happensAt(d,T).(rule3)(b)CurrentdatainterpretationIt:{happensAt(c,1),happensAt(b,2),happensAt(c,5),happensAt(d,8)}(c)Inferredstatewithcrisplogicalinference:{holdsAt(a,3),holdsAt(a,4),holdsAt(a,5),holdsAt(a,9),holdsAt(a,10)}(d)ProgramT(Ht)forMAPinference:initiatedAt(a,T)←satisﬁed(vars(T),rule1).{satisﬁed(vars(T),rule1)}←happensAt(b,T).:~satisﬁed(vars(T),rule1).[−11,vars(T),rule1]terminatedAt(a,T)←satisﬁed(vars(T),rule2).{satisﬁed(vars(T),rule2)}←happensAt(c,T).:~satisﬁed(vars(T),rule2).[−13,vars(T),rule2]initiatedAt(a,T)←satisﬁed(vars(T),rule3).{satisﬁed(vars(T),rule3)}←happensAt(d,T).:~satisﬁed(vars(T),rule3).[2,vars(T),rule3](e)InferredstatewithMAPinference:{holdsAt(a,3),holdsAt(a,4),holdsAt(a,5),satisﬁed(vars(5),rule2),satisﬁed(vars(2),rule1)}Theory and Practice of Logic Programming

7

Algorithm 2 LearnNewRules(B, M, Ht, It, IMAP
)
Input: background knowledge B; mode declarations M, the
current CE pattern set Ht ; the current data interpretation It ; the
MAP-inferred state IMAP
t
t
Output: A set Hnew of new CE patterns.

; the true state Itrue

, Itrue
t

t

:= /0, T(H
.

⊥

) := /0

\

1: Π := /0, Hnew := /0, H
⊥
2: Mistakes := Itrue
IMAP
t
t
3: for each m
Mistakes do
4:
H
5: H
6: for each bottom rule ri = αi
7:

⊥ ←

⊥ ←

∈
generateBottomRule(m, It , M)

compressBottomRules(H
)
⊥
i , . . . , δ n
δ 1
i

in H

do

←
i )), . . . , try(i, n, v(δ n
use(i, 0), try(i, 1, v(δ 1

) the following rules:

⊥

i )).

i ))
i ))

←
←

use(i, 1), δ 1
i .
not use(i, 1).

8: Π

i ))
i ))
T (Ht )
inference-related transformation
of Algorithm 1 applied to the current CE pattern set Ht .

use(i, n), δ n
i .
not use(i, n).
T (H

), where T (Ht ) is the MAP

←
←
∪

←

∪

∪

B

⊥

9: Add to Π the following rules:

←

Add to T (H
⊥
αi
try(i, 1, v(δ 1
try(i, 1, v(δ 1
. . .
try(i, n, v(δ n
try(i, n, v(δ n
It

use(I, J)
{
: ~ use(I, J). [1, I, J]

} ←

ruleId(I), literalId(J).

10: Add to Π one weak constraint of the form

: ~ not α. [1] (resp. : ~ α. [1]) for each target CE
instance α included (resp. not included – closed world
assumption) in Itrue

.

t
11: Find an optimal answer set Aopt of Π.
12: Remove from H
⊥

every body literal δ j
for which
i
Aopt and each rule ri for which use(i, 0) /
∈

use(i, j) /
∈
Aopt .
13: Hnew
.
⊥
14: return Hnew.

←

H

Fig. 2: Example of new rule induction in response to
prediction mistakes.

4.2 Learning New Rules

Right after making a prediction via MAP inference on the current interpretation the true state
is revealed to the learner, compared against the MAP-inferred state and the erroneous predic-
tions are identiﬁed. The existing CE pattern set Ht is expanded with the addition of new rules,
generated in response to these mistakes, via the addition of new initiatedAt/2 (resp. terminatedAt/2)
patterns, generated from false negative (FN) (resp. false positive (FP)) mistakes, which have the
potential to prevent similar mistakes in the future. For instance, an FN mistake at time t, i.e. a
target CE instance predicted as false, while actually being true at t, could have been prevented
via a pattern that initiates the target CE at some time prior to t.

Generating new CE patterns from the entirety of mistakes may result in a very large number of
rules, many of which are redundant, or generated from noisy data points. To avoid that, WOLED
instantiates an optimization process that seeks a good trade-off between theory complexity and
accuracy. This is done by combining structure induction techniques from non-monotonic ILP
with probabilistic reasoning with the existing CE pattern set Ht , in order to learn a new set
of CE patterns R, which is as compressive as possible, while at the same time, the result of
reasoning with B
R on the current interpetation approximates the corresponding true state
as close possible. Viewing the current input interpretation as a small training set, such a process
corresponds to the standard machine learning practice of jointly minimizing training error and
model complexity.

Ht

∪

∪

To realize this process, WOLED employs the strategy for new rule generation, presented in
Algorithm 2: First, a set of bottom rules (BRs) is created (line 4), using the constants in the

Inputinterpretation:It={happensAt(c,1),happensAt(b,2),happensAt(c,5),happensAt(d,8)}MAP-inferredstateusingtheweightedtheoryfromTable2:IMAPt={holdsAt(a,3),holdsAt(a,4),holdsAt(a,5)}Truestate:Itruet={holdsAt(a,3),holdsAt(a,4),holdsAt(a,5),holdsAt(a(cid:48),6),holdsAt(a(cid:48),7),holdsAt(a(cid:48),8),holdsAt(a(cid:48),9),holdsAt(a(cid:48),10)}ModeDeclarations:head(initiatedAt(a(cid:48),time))head(terminatedAt(a(cid:48),time))head(initiatedAt(a,time))head(terminatedAt(a,time))body(happensAt(c,time))body(happensAt(b,time))body(nothappensAt(e,time))body(holdsAt(a,time))Bottomrule⊥generatedfromtimepoint5:Ground:initiatedAt(a(cid:48),5)←happensAt(c,5),nothappensAt(e,5),holdsAt(a,5).Lifted:initiatedAt(a(cid:48),T)←happensAt(c,T),nothappensAt(e,T),holdsAt(a,T).SyntacticallytransformedprogramH⊥fornewruleinduction:initiatedAt(a(cid:48),T)←use(1,0),try(1,1,T),try(1,2,T),try(1,3,T).try(1,1,T)←use(1,1),happensAt(c,T).try(1,1,T)←notuse(1,1),time(T).try(1,2,T)←use(1,2),nothappensAt(e,T).try(1,2,T)←notuse(1,2),time(T).try(1,3,T)←use(1,3),holdsAt(a,T).try(1,3,T)←notuse(1,3),time(T).8

N. Katzouris, A. Artikis and G. Paliouras

erroneously predicted atoms to generate ground initiatedAt/2 and terminatedAt/2 atoms, which are
placed in the head of a set of initially empty-bodied rules. The bodies of these rules are then
populated with literals, grounded with constants that appear in the head, that are true in the
current data interpretation It . The signatures of allowed body literals are speciﬁed via mode
declarations (De Raedt 2008).

⊥

Next, constants in the BRs are replaced by variables and the BR set is “compressed” (line 5)
to a bottom theory H
, which consists of unique, w.r.t. θ -subsumption, variabilized BRs. The
new CE patterns are chosen among those that θ -subsume H
. To this end, the generalization
technique of (Ray 2009), which allows to search into the space of theories that θ -subsume H
,
⊥
is combined with inference with the existing weighted CE pattern set Ht , yielding a concise
It best-
set of CE patterns Hnew with the property that an optimal answer set of B
approximates the true state associated with It .

Hnew

Ht

∪

∪

∪

⊥

⊥

∈

H

To this end, each BR ri

is “decomposed” in the way shown in line 7 of Algorithm 2,
where the head of ri corresponds to an atom use(i, 0) and each of its body literals, δ j
i , to a try/3
atom, which, via the try/3 deﬁnitions provided, may be satisﬁed either by satisfying δ j
i and an
additional use(i, j) atom, or by “assuming” not use(i, j). Choosing between these two options
is done via ASP optimization in line 9 of Algorithm 2, where the choice rule generates use/2
atoms that correspond to head atoms/body literals for H
, and the subsequent weak constraint
minimizes the generated instances to those necessary to approximate the true state, as encoded
via the additional weak constraints in line 10. New rules are “assembled” from the bottom rules
in H
, by following the prescriptions encoded in the use/2 atoms of an optimal answer set of the
resulting program, as in line 12.

⊥

⊥

This is essentially the XHAIL algorithm (Ray 2009) in an ASP context. The difference of our
approach from usages of this structure induction technique in previous works (Ray 2009; Kat-
zouris et al. 2015), is that here the search into the space of H(cid:48)
s subsumers is combined with MAP
⊥
inference with the existing set of weighted CE patterns (line 8, Algorithm 2). Therefore, new pat-
terns are generated only insofar they indeed help to better approximate the true state, given the
already existing weighted rules. This technique allows to generalize from the data in the current
interpretation, while taking into account previously discovered patterns and their relative quality,
as reﬂected by their weights.

Example 2
We illustrate the rule induction technique in Algorithm 2 via an example. Recall Example 1
and assume that after making a prediction and generating the MAP-inferred state we receive
the true state presented in Figure 2. Assume also that we have an additional target CE here,
a(cid:48). The true state in Figure 2 differs from the MAP-inferred one as it contains holdsAt/2 atoms
concerning a(cid:48). These atoms are missing from the MAP-inferred state, therefore, they are false
negative (FN) predictions, i.e. true instances of a target complex event, which are not recognized
by the weighted theory of Figure 1. In order to revise the current theory towards eliminating
the FN’s we employ the strategy of Algorithm 2. First, a set of ground atoms that eliminate the
erroneous predictions if added to the current theory are generated via abductive reasoning. These
atoms will serve as heads for new rules and their signatures are predeﬁned via mode declarations
(see Figure 2). In our example one such atom, initiatedAt(a(cid:48), 5), sufﬁces (note that a(cid:48) in the true
state holds from time 6 onwards, therefore, it must have been initiated in the previous time
having this atom in the head is generated from the data in the current
point). A bottom rule
are speciﬁed
interpretation, as shown in Figure 2. The signatures of literals in the body of

⊥

⊥

Theory and Practice of Logic Programming

9

⊥

via the mode declarations and the actual atoms are groundings of such literals, generated using
constants in the head, that are true in the data. The “lifted” version of
shown in Figure 2 is
then transformed into program H

in Figure 2, forming a search space for learning a new rule.

⊥

Approximating the true state is then realized via ﬁnding an optimal answer set of a program Π
consisting of the following parts: (i) the axioms of the Event Calculus (background knowledge);
(ii) program T (Ht ) from Figure 1, used for probabilistic inference with the weighted theory Ht ;
(iii) program H
from Figure 2, used for new rule induction; (iv) a choice rule for use/2 atoms
and weak constraints that minimize the use/2 atoms included in the optimal answer set, thus
encoding a preference for simpler rules in the rule induction process (line 9, Algorithm 2); (v)
weak constraints that minimize the “disagreement” between the optimal answer set and the true
state w.r.t. the target CE instances included in the optimal answer set (line 10, Algorithm 2).

⊥

∪

←

r correctly accounts for the true state.

An optimal answer set of program Π contains the atoms use(1, 0), use(1, 1) and use(1, 3),
happensAt(c, T), holdsAt(a, T). This is the sim-

which correspond to the rule r(cid:63) : initiatedAt(a(cid:48), T)
plest rule r with the property that Ht
Remark. Note that reasoning with the weighted theory Ht is necessary in order to learn the new
rule r(cid:63) in this example. Indeed, rule1 in Figure 1 initiates a at time 2, thus causing it to hold at time
5 and allowing the holdsAt(a, T) atom to be added to the body of r(cid:63). Observe that without this
atom, the more general rule, initiatedAt(a(cid:48), T)
happensAt(c, T) would yield a number of false
←
positive predictions, since it would initiate a(cid:48) at time 1, due to the happensAt(c, 1) atom in the
input data, thus causing a(cid:48) to (erroneously) hold in the interval [2, 5]. It can be seen by comparing
costs in the optimization process that “settling” for the initial false negative predictions for a(cid:48) in
the interval [6, 10] (by not learning a new rule at all) is more cost-efﬁcient than learning the rule
happensAt(c, T), which does retrieve the false negatives, but causes the false
initiatedAt(a(cid:48), T)
positives for a(cid:48) in the interval [2, 5]. Therefore, had we not used Ht as background knowledge,
we would not have learned a new rule from the data in this example. It is worth mentioning that
the same would have happened if we used Ht as a crisp theory, i.e. without the rules’ weights. In
that case rule3 from Figure 1 would be responsible for a number of false positives in the inferred
state. This example, therefore, demonstrates the merit of combining probabilistic inference with
existing rules with the new rule induction process.

←

4.3 Weight Learning

The CE patterns’ weights (which are initialized to a close-to-zero value) are updated by compar-
ing their true groundings in the inferred and the true state respectively. For a target CE α and
an initiatedAt/2 (resp. terminatedAt/2) CE pattern ri, a true grounding, either in the inferred, or in
the true state, is a grounding of ri at time t, such that holdsAt(α,t + 1) is true (resp. false). CE
patterns that contribute towards correct predictions are promoted, while those that contribute to
erroneous predictions are down-weighted.

As in (Katzouris et al. 2018), we use the AdaGrad algorithm (Duchi et al. 2011) for weight
updates, a version of Gradient Descent that dynamically adapts the learning rate, i.e. the magni-
tude of weight promotion/demotion, for each CE pattern individually, by taking into account the
pattern’s performance on the past data. AdaGrad updates a weight vector, whose coordinates cor-
respond to a set of features (the CE patterns in our case), based on the subgradient of a convex
loss function of these features. Our loss function, called the prediction-based loss, is a simple
variant of the max-margin loss for structured prediction for MLNs (Huynh and Mooney 2011),
whose subgradient is the vector with ∆gi in its i-th coordinate, where ∆gi = gMAP
denotes

gtrue
ri

ri −

10

N. Katzouris, A. Artikis and G. Paliouras

the difference in the true groundings of the i-th pattern, ri, in the MAP-inferred and the true state
respectively. Essentially, ∆gi counts prediction mistakes which are relevant to ri, either false
positive mistakes (∆gi > 0), for which ri is responsible, or false negative predictions (∆gi < 0),
committed by the entire theory, which ri could have helped prevent. The weight update rule for
the i-th CE pattern ri is then:

i = sign(wt
wt+1

i −

η
Ct
i

∆gt

i) max

0,
{

wt
|

i −

η
Ci
t

∆gt

i| −

λ

η
Ci
t }

(4)

j=1(∆g j
∑t
where η is a learning rate parameter, λ is a regularization parameter and Ct
i )2
i = δ +
is a term proportional to the sum of ri’s past subgradients (the ∆gi’s) (plus a δ
0 to avoid
division by zero in η/Ct
i ). Note that according to Eq. (4), a ∆gi > 0, i.e. a case where ri is
responsible for false positive predictions, leads to a weight demotion for ri, while a ∆gi < 0 leads
to a promotion of its weight, that can help the theory retrieve the false negative misses.

≥

(cid:113)

The Ct

i term is the adaptive factor that assigns a different learning rate to each CE pattern, since
η
∆gt
the magnitude of a weight update via the term
is affected by the CE pattern’s previ-
i|
Ci
t
ous history, in addition to its current utility, expressed by ∆gt
i. Smaller values for Ct
i correspond to
“rare”, but potentially highly informative features, and therefore lead to weight updates of larger
magnitude. The “informativeness” of these features is reﬂected in the magnitude of the current
subgradient ∆gi, since, regardless of the value of Ct
i , zero, or very small values of the current
subgradient (corresponding to non-informative features) have very small effect to the weight.

wt
|

i −

The regularization term in Eq. (4), λ η
Ci
t

, is the amount by which the i-th CE pattern’s weight
is discounted when ∆gt
i = 0. As usual, the role of regularization is to introduce a bias towards
simpler models, in this case by eventually (over time) pushing to zero the weights of irrelevant
rules, that play no signiﬁcant role in helping the theory make correct predictions.

4.4 Revising Existing CE patterns’ Structure

Although the rules induced with the process described in Section 4.2 are useful locally, that is,
w.r.t. the current input interpretation It , they may be proven inadequate w.r.t. a more “global”
view of the data. A case where this typically occurs is inducing the simplest rule that helps ap-
proximate the true state in It , which turns out to be over-general once larger regions of the data
are taken into account. Weight learning may help suppress the effects of such rules in the predic-
tive performance of the model, but this is not enough: Since the data are processed incrementally
in small batches, it may be the case that a “data view” large-enough for learning a high-quality
target rule may never occur, causing the learning process to fail.

A remedy is to revise the rules’ structure over time, as larger portions of the data are revealed.
Similarly to OLED (Katzouris et al. 2016), WOLED does so via a classical in ILP, hill-climbing
search process, searching for a high-quality CE pattern into a subsumption lattice deﬁned by a
bottom rule. Such bottom rules are generated during the rule induction process of Section 4.2.
Each induced rule r is associated with a bottom rule
r), which
serves as a pool to draw literals from, in order to specialize r over time. This process is online,
using the data in the incoming interpretations to evaluate a CE pattern and its current specializa-
tions. A Hoeffding test (Domingos and Hulten 2000) allows to identify, with high probability,
the best specialization from a small subset of the input interpretations. Once the test succeeds,

r (such that r θ -subsumes

⊥

⊥

Theory and Practice of Logic Programming

11

Fig. 3: A subsumtion lattice.

the parent rule is replaced by its best specialization and the process continues for as long as new
specializations improve the current rule’s performance.

In particular, at each point in time a parent rule and its specializations are evaluated on incom-
ing data, via an information gain scoring function, assessing the cumulative merit of a special-
ization over the parent rule, across the portion of the stream seen so far:

G(r, r(cid:48)) = Pr

(log

·

Pr

Pr + Nr −

log

Pr(cid:48)
+ Nr(cid:48)

)

Pr(cid:48)

where r(cid:48) is r’s parent rule and for each rule r, Pr (resp. Nr) denotes the sum of true (resp. false)
groundings of r in the MAP-inferred states generated so far. The information gain function is
normalized in [0, 1] by taking 0 as the minimum (as we are interested in positive gain only)
and dividing a G-value by its maximum, Gmax(r, r(cid:48)) = Pr(cid:48) ·
). When the range of
G is [0, 1], a Hoeffding test succeeds, allowing to select r1 as the best of a parent rule r’s spe-
(cid:113) log1/δ
cializations, when G(r1, r)
2N , where r1, r2 are respectively r’s best and
second-best specializations, δ is a conﬁdence parameter and N is the number of observations
seen so far, we refer to (Katzouris et al. 2016) for further details.

G(r2, r) > ε =

log Pr(cid:48)
Pr(cid:48)

(
−

+Nr(cid:48)

−

A successful Hoeffding test results in replacing the parent rule r with its best specialization
r1 and moving one level down in the subsumption lattice, via generating r1’s specializations and
subsequently evaluating them on new data. Figure 3 illustrates the process for an initiation CE
pattern. The rules at each level of the lattice represent the specializations of a corresponding rule
at the preceding level. The greyed-out part of the search space in Figure 3 represents the portion
that has already been searched, while the non greyed-out rule at the third level represents the
best-so-far rule that has resulted from a sequence of Hoeffding tests.

The specializations’ weights are learnt simultaneously to those of their parent rules, by com-
paring the specializations’ true groundings over time in the MAP-inferred states (generated from
“top theories”, consisting of parent rules only) and the true states respectively.

initiatedAt(meet(X,Y),T)←initiatedAt(meet(X,Y),T)←happensAt(inactive(X),T)initiatedAt(meet(X,Y),T)←happensAt(active(X),T)initiatedAt(meet(X,Y),T)←happensAt(active(X),T),orientation(X,Y,45),T)initiatedAt(meet(X,Y),T)←happensAt(active(X),T),close(X,Y,25),T)initiatedAt(meet(X,Y),T)←happensAt(active(X),T),close(X,Y,25),T),orientation(X,Y,45),T)initiatedAt(meet(X,Y),T)←happensAt(active(X),T),close(X,Y,25),T),happensAt(inactive(X),T).........BottomRule.........12

N. Katzouris, A. Artikis and G. Paliouras

5 Discussion on Implementations

We highlight the differences between the ASP-based version of WOLED, which we henceforth
denote by WOLED-ASP, with the version of (Katzouris et al. 2018), which relies on MLN libraries,
and which we henceforth denote by WOLED-MLN.

Contrary to WOLED-ASP, which is based entirely on the Clingo3 answer set solver, WOLED-MLN
is based on a number of different software tools. It uses the LoMRF library for Markov Logic
Networks (Skarlatidis and Michelioudakis 2014), for grounding MLN theories and performing
circumscription via predicate completion (Skarlatidis et al. 2015), in order to convert them into a
form that supports the non-monotonic semantics of the Event Calculus for reasoning, something
that WOLED-ASP has out of the box. MAP inference in WOLED-MLN is performed via a state-of-
the-art in MLNs, Integer Linear Programming-based approach, which is introduced in (Huynh
and Mooney 2009) and is implemented using the lpsolve4 solver.

Another important difference between WOLED-ASP and WOLED-MLN from an algorithmic per-
spective, lies in the new CE pattern generation process. As discussed in Section 4.2, WOLED-ASP
is able to perform the search for new structure, while taking into account the contribution of
the weights of existing patterns in approximating the true state. In contrast, WOLED-MLN lacks
this ability. It generates a bottom theory H
from the erroneously predicted atoms, and then at-
tempts to gradually learn a high-quality CE pattern from the rules therein, regardless of their
quality. In comparison, WOLED-ASP’s strategy may lead, in principle, to simpler theories of more
meaningful rules.

⊥

6 Experimental Evaluation

We present an experimental evaluation of our approach on three CER data sets from the domains
of activity recognition, maritime monitoring and vehicle ﬂeet management.
Datasets. CAVIAR5 is a benchmark dataset for activity recognition, described in Section 3, con-
sisting of 28 videos with 26,419 video frames in total. We experimented with learning CE pat-
terns for two CEs from CAVIAR, related to two people meeting each other and moving together,
which we henceforth denote by meeting and moving respectively. There are 6,272 video frames
in CAVIAR where moving occurs and 3,722 frames where meeting occurs. A fragment of a CE
deﬁnition for moving is presented in Table 1(d).

Our second dataset is a publicly available dataset from the ﬁeld of maritime monitoring6. It
consists of Automatic Identiﬁcation System (AIS) position signals collected from vessels sailing
around the area of Brest, France, for a period of six months, between October and March 2015.
The data have been pre-processed using trajectory compression techniques (Patroumpas et al.
2017) that identify “critical points” in a trajectory, i.e. mobility features, such as vessel stops,
turns, slow motion movements etc. The critical points maritime dataset has been further pre-
processed, in order to extract spatial relations between vessels (e.g. vessels being close to each
other) and areas of interest, such as protected areas, areas near coast, open-sea areas etc. There
are 16,152,631 critical points in the maritime dataset, involving 4,961 vessels and 6,894 areas,
for a total size of approximately 1,3GB.

3 https://potassco.org/
4 https://sourceforge.net/projects/lpsolve
5 http://homepages.inf.ed.ac.uk/rbf/CAVIARDATA1/
6 https://zenodo.org/record/1167595#.WzOOGJ99LJ9

Theory and Practice of Logic Programming

13

The maritime dataset is not labeled in terms of occurring CE instances, we therefore used
hand-crafted CE patterns to perform CER on the critical points, thus generating the annotation.
The purpose of learning was to reconstruct the hand-crafted CE patterns. We experimented with
learning CE patterns for a CE related to vessels involved in potentially suspicious rendezvous
(henceforth denoted by rendezVous), which holds when two vessels are stopped, or move with
very low speed in proximity to each other in the open sea. Since such behavior is often related to
illegal activities, tracking it is of special interest for maritime surveillance.

Our third dataset is provided by Vodafone Innovus7, a commercial vehicle ﬂeet management
provider and our partner in the Track & Know8 EU-funded funded project. The data consist of
time-stamped vehicle positions (GPS), in addition to mobility-related events, such as abrupt ac-
celeration, abrupt deceleration, harsh cornering, provided by an accelerometer device installed
in each commercial vehicle. Moreover, map-matched weather attributes were used to enrich the
dataset with contextual information, such as icy road. We refer to (Tsilionis et al. 2019) for a
detailed account of this dataset.

Similarly to the maritime dataset, due to the lack of CE-related ground truth we used hand-
crafted patterns, developed in collaboration with domain experts in Track & Know to generate
the ground truth CE instances. The learning target was a CE related to dangerous driving, which
holds in a number of occasions, such as abruptly accelerating/decelerating on an icy road. The
ﬂeet management dataset consists of 4M records for a total size of 527 MB.

All experiments were carried-out on a machine with a 3.6GHz processor (4 cores, 8 threads)
and 16GB of RAM. Clingo (v. 5.4.0) was used with the –opt-strategy=usc option, which signiﬁ-
cantly speeds-up the optimization process. The hyper-parameters for the different algorithms the
are compared in these experiments were set as follows: For AdaGrad, η = 1.0, λ = 0.01, δ = 1.0.
2. The code for all algorithms
The signiﬁcance parameter for Hoeffding tests was set to δ = 10−
used in these experiments in available online9.

6.1 Scalability of Inference

The purpose of our ﬁrst experiment was to compare the scalability of the ASP-based MAP in-
ference process, which lies at WOLED-ASP’s core, to that of WOLED-MLN’s. To that end we used
the task of online weight learning with hand-crafted CE patterns, where the learner is required
to ﬁrst perform MAP inference on the incoming interpretations with a ﬁxed-structure CE pattern
set, and then update the CE patterns’ weights, based on their contribution to erroneous inferences
in the MAP-inferred state. Given that the weight update cost is negligible and the CE pattern set
is ﬁxed, the MAP inference cost is the dominant one in this task and it depends on the cost
of grounding the current CE pattern set, plus the cost of solving the corresponding weighted
MaxSat problem for each incoming interpretation. Note that since the CE pattern sets for each
CE are ﬁxed in this experiment, predicate completion in WOLED-MLN is performed only once at
the beginning of a run, therefore its cost is negligible.

The data were consumed by the learners in mini-batches, where each mini-batch is an interpre-
tation consisting of data in a particular time interval. We performed weight learning with different
mini-batch sizes of 50, 100, 500 & 1000 time points. We measured the average MAP inference

7 https://www.vodafoneinnovus.com
8 https://trackandknowproject.eu/
9 https://github.com/nkatzz/ORL

14

N. Katzouris, A. Artikis and G. Paliouras

(a) Meeting

(a) Moving

(c) Rendezvous

(d) Dangerous driving

Fig. 4: Scalability of MAP inference.

time (grounding plus solving time) for WOLED-ASP and WOLED-MLN respectively, throughout a
single-pass over the data, for different mini-batch sizes. Note that as the mini-batch size grows,
so does the size of the corresponding ground program from which the MAP-inferred state is
extracted.

Figure 4 presents the results, which indicate that the growth in the size of the ground program,
as the mini-batch size increases, entails an exponential growth to the MAP inference cost for
WOLED-MLN. In contrast, thanks to Clingo’s highly optimized grounding and solving abilities,
MAP inference with WOLED-ASP takes near-constant time.

6.2 Online Structure & Weight Learning Performance

In our next experiment we assess WOLED-ASP’s predictive performance and efﬁciency in the task
of online structure & weight learning and we compare it to (i) WOLED-MLN; (ii) OLED (Katzouris
et al. 2016), the crisp version of the algorithm that learns unweighted CE patterns; (iii) Hand-
Crafted, a set of predeﬁned rules for each CE and (iv) HandCrafted-WL, the rules in HandCrafted
with weights learnt by WOLED-ASP.

To assess the predictive performance of the systems compared we used two methods: Pre-
quential evaluation (Bifet et al. 2018), where each incoming data interpretation is ﬁrst used to
evaluate the current CE pattern set and then to update its structure and weights, and standard
cross-validation. In prequential evaluation we typically measure the average prediction loss over
time, which is an indication of a learner’s ability to incorporate new information that arrives over
time into the current model. With cross-validation we assess a learner’s generalization abilities,
by evaluating the predictive performance of a learnt model on a test set.

The results from prequential evaluation for meeting & moving are presented in Figure 5, while
Table 2 reports several statistics for the systems being compared: (i) F1-scores on a test set.
For CAVIAR we used tenfold cross-validation and the reported F1-scores are micro-averages
obtained from ten different test sets. For the maritime and the ﬂeet management datasets, whose
size makes tenfold cross-validation impractical, we used half the dataset for training and half for
testing, so the reported F1-scores are obtained from the latter half; (ii) CE pattern set sizes (total
number of literals) at the end of a single-pass over a dataset; (iii) total inference time at the end
of a single-pass over a dataset (MAP inference for WOLED-ASP, WOLED-MLN & HandCrafted-WL,
crisp logical inference for OLED); (iv) for WOLED-MLN, total time spent on predicate completion;
(v) total training time at the end of a single-pass over a dataset, which includes time spent on CE
pattern generation, computing θ -subsumption etc, i.e. the dominant costs involved in learning
CE patterns structure. Note that we report on (iii), (iv), (v) only for approaches that require

1.1K2.2K9K15K0246810Avg.#atomsingroundprogramGrounding+solving(sec)WOLED-ASPWOLED-MLN1.3K2.6K10K19.2K024681012Avg.#atomsingroundprogramGrounding+solving(sec)WOLED-ASPWOLED-MLN2.6K3.8K18K29K05101520Avg.#atomsingroundprogramGrounding+solving(sec)WOLED-ASPWOLED-MLN1.8K2.9K12K16K0246810Avg.#atomsingroundprogramGrounding+solving(sec)WOLED-ASPWOLED-MLNTheory and Practice of Logic Programming

15

Method

F1-score (test set)

Theory size

Inference
Time (sec)

Pred. Compl. Time
(sec)

Total Time
(sec)

Moving

Meeting

Rendezvous

Dang.Drive

WOLED-ASP

WOLED-MLN

OLED

HandCrafted

HandCrafted-WL

WOLED-ASP

WOLED-MLN

OLED

HandCrafted

HandCrafted-WL

WOLED-ASP

WOLED-MLN

OLED

WOLED-ASP

WOLED-MLN

OLED

0.821
0.801
0.730
0.637
0.702

0.887
0.841
0.782
0.735
0.753

0.98
0.98
0.98

0.99
0.99
0.99

26
47
24
28
28

34
56
42
23
23

18
18
18

21
28
21

15
187
13
–
16

12
134
10
–
13

647
2,923
623

341
926
312

–
28
–
–
–

–
12
–
–
–

–
434
–

–
287
–

112
478
74
–
52

82
145
36
–
31

4,856
6,218
4,688

2,465
3,882
2,435

Table 2: Online structure & weight learning results.

Fig. 5: Prequential Evaluation on CAVIAR.

training (i.e., not for HandCrafted). Also, we did not experiment with hand-crafted CE patterns in
the maritime and the ﬂeet management datasets, since in these datasets hand-crafted CE patterns
were used to generate the ground truth in the ﬁrst place. We also omit prequential learning curves
for rendezVous & dangerous driving in Figure 5, since, due to the synthetic ground truth in the
maritime & the ﬂeet management datasets, the learning curves for these complex events are very
similar for all algorithms being compared and are not informative.

The results in Figure 5 and in Table 2 seem to validate the claim of Section 5 on the differences
in predictive performance between WOLED-ASP and WOLED-MLN. Indeed, WOLED-ASP clearly
outperforms WOLED-MLN, both in prequential error and in cross-validation F1-scores, indicating
better generalization abilities. Moreover, WOLED-ASP learns simpler CE patterns sets, as shown
by the theory size statistic. HandCrafted-WL outperforms WOLED-ASP in the prequential task for
the most part of the training process. This was expected, since HandCrafted-WL has the advantage
of operating on a good set of rules provided beforehand and, therefore, is less prone to erroneous

05010015020025000.51Mini−batches(size100)AverageLossMovingWOLED-ASPWOLED-MLNHandCrafted-WLearnOLED05010015020025000.20.40.60.811.2Mini−batches(size100)AverageLossMeetingWOLED-ASPWOLED-MLNHandCrafted-WLearnOLED16

N. Katzouris, A. Artikis and G. Paliouras

predictions. On the other hand, its inability to learn new rules explains its inferior test-set F1-
scores for meeting & moving.

OLED aims at quickly discovering a good set of rules. It is not concerned with optimizing their
joint predictive performance and does not learn weights. It is the most efﬁcient of all learners,
but it is also outperformed by all in terms of prequential error and test set F1-scores.

Regarding efﬁciency, it may be seen by comparing inference times to total training times, that
the dominant cost is related to structure learning tasks (recall that total training times factor-in
such costs). Yet, in comparison to WOLED-MLN, WOLED-ASP achieves signiﬁcantly lower costs
for MAP inference, which approximate the cost of OLED’s crisp logical inference. In addition to
its more sophisticated CE pattern creation strategy, which tends to generate fewer CE patterns of
high quality, this results in WOLED-ASP being signiﬁcantly more efﬁcient than WOLED-MLN. Note
also, that an additional, not negligible cost for WOLED-MLN stems from predicate completion.

6.3 Comparison to Batch Learners

In our last experiment we compare WOLED-ASP to a number of batch learning algorithms for
learning structure and weights. To that end we used smaller datasets whose size makes batch
learning practical. In particular, we used a fragment of the CAVIAR dataset that has been used in
batch learning experiments in previous work (Skarlatidis et al. 2015) and a small excerpt of the
maritime dataset. The fragment CAVIAR dataset consists of the regions of the original dataset
where the two target complex events (meeting and moving) occur and contains a total of 25,738
training interpretations. The maritime fragment dataset contains 11,930 training interpretations
corresponding to six data sequences, extracted from the original maritime dataset, where ren-
dezvous between pairs of vessels occurs.

We compare WOLED-ASP to the following batch learning algorithms: (i) XHAIL (Ray 2009),
a non-monotonic ILP learner whose rule induction strategy WOLED-ASP combines with proba-
bilistic reasoning; (ii) ILED (Katzouris et al. 2015), an algorithm that combines XHAIL’s learning
machinery with theory revision, in order to learn incrementally, and has been shown to achieve
performance comparable to that of XHAIL’s, while being much more efﬁcient; (iii) ILASP (Law
et al. 2015), a state of the art ILP system that learns answer set programs from examples and has
been used for inducing complex event patterns (Law et al. 2018); (iv) MaxMargin, a batch weight
learning algorithm for MLN, introduced in (Huynh and Mooney 2009), which has been used
with the CAVIAR fragment dataset in the past and as been shown to achieve very good results.
XHAIL, ILED and ILASP are crisp learners (i.e. there is no weight learning involved). MaxMargin was
used with hand-crafted rule sets and the task was to learn weights for these rules.

WOLED-ASP, XHAIL, ILED and ILASP are based on ASP and rely on Clingo. The implementation
of XHAIL and ILED is available online10 and so is the most recent version of ILASP (ILASP4)11.
MaxMargin is available from the LoMRF platform.

The original ILED algorithm is designed for soundness and cannot tolerate noise. To account
for that in this experiment we used a noise-tolerant version (denoted by ILED-HC) that learns theo-
ries in an iterative hill-climbing process: It ﬁrst constructs a bottom theory (collection of bottom
rules) from the mode declarations and then passes once over the data, which are presented in
mini-batches, to generate a number of different theories, by generalizing the bottom theory w.r.t.

10 https://github.com/nkatzz/ORL
11 http://www.ilasp.com/download

Theory and Practice of Logic Programming

17

Fig. 6: Comparison with batch learners.

each mini-batch. The theory with the best performance on the training set is retained and is sub-
sequently further revised from each mini-batch in an additional pass over the data. The process
continues, keeping the best revision at each iteration, until no improvement in performance is ob-
served, or a max-iterations threshold is reached. In these experiments we used batch size of 100
time points with ILED-HC, from which the algorithm converged in approximately 5-7 iterations
over the data for meeting and moving and 3 iterations for rendezvous.

We used tenfold cross-validation process for meeting and moving and sixfold cross-validation
for rendezVous. The results are presented in Figure 6 in the form of (micro-averaged) F1-scores
from the testing sets and average training times for each algorithm. We omit results for MaxMargin
on rendezVous, since the hand-crafted rules that MaxMargin would learn weights for are those that
were used to generate the ground truth.

WOLED-ASP achieves the best F1-score for meeting, with a signiﬁcant distance from the other
algorithms. It also achieves the second-best F1-score for moving. In rendezVous, XHAIL is a clear
winner w.r.t. predictive performance, while all other algorithms achieve comparable F1-scores.
WOLED-ASP is signiﬁcantly faster than ILASP, XHAIL and MaxMargin, while its efﬁciency is com-
parable to that of ILED-HC’s, which, however, is outperformed by WOLED-ASP.

To appreciate the differences in performance between the algorithms being compared, it is
helpful to take a look into their inner-workings. XHAIL generalizes a bottom theory from the
entirety of the training data in one go, which explains its increased training times. On the other
hand, it is thanks to this strategy that XHAIL is capable to learn better theories for rendezVous than
algorithms that process the training examples individually, thus failing to discover fragments of
the rendezVous deﬁnition, whose utility is revealed only when “looking” at the training data as
a whole. In contrast to the rendezVous case where the ground truth is synthetic, XHAIL’s learning
strategy seems less useful in CAVIAR, where XHAIL marginally outperforms ILASP at the cost
of much higher training times, it achieves identical performance to ILED and is outperformed by
WOLED-ASP on both meeting and moving and by MaxMargin on moving. This latter observation is
an indication for the merit of weight learning.

In contrast to XHAIL, ILED-HC and WOLED-ASP, which generate rules on demand in a data-
driven fashion, ILASP4 explicitly enumerates its search space. This yields large search spaces,
which explains ILASP’s increased training times. ILASP4’s inferior predictive performance is at-
tributed to the learning setting, which for ILASP4 follows closely the one reported in (Law et al.
2018) and aims at keeping learning tractable: ﬁrst, to limit the number of irrelevant answer sets
generated during learning, additional constraints on ILASP4’s search space dictate that the learnt

MaxMarginXHAILILASP4ILED-HCWOLED-ASP0.9270.8620.8550.8620.8630.8620.8410.8130.8410.890.9120.9240.9220.971F1-ScoreonTestSetMeetingMovingRendezVousMaxMarginXHAILILASP4ILED-HCWOLED-ASP0.31.14.7120190.51.513.5130280.20.86.547TrainingTime(minutes)MeetingMovingRendezVous18

N. Katzouris, A. Artikis and G. Paliouras

event patterns should only account for the “turning points” in a ﬂuent’s truth value. That is, initi-
ation rules for a ﬂuent f are learnt from data points t, such that f does not hold at t and holds at
t + 1. Similarly, for termination rules, f should hold at t and not hold at t + 1. Second, since such
turning points in ﬂuents’ truth values are too few in the datasets, as compared to points where
ﬂuents hold/do not hold continuously, the turning point examples are weighted12, reﬂecting their
increased importance and simulating the effect of “over-sampling” such examples. This allows
for efﬁcient learning with ILASP4 in this domain. The downside is that learning becomes very
susceptible to the even the slightest noise in the turning point examples, which explains ILASP4’s
inferior performance, as compared to the other algorithms.

We conclude this section by pointing-out that XHAIL and ILASP4 are more general-purpose
learners than the event-based algorithms they were compared to. Therefore, they may be outper-
formed by the latter on the particular task of learning event deﬁnitions, but on the other hand,
they may be used for learning tasks that the event-based algorithms cannot.

7 Conclusions & Future Work

We presented an online algorithm for learning weighted Event Calculus rules. Our system is
entirely implemented in ASP and it is capable of combining temporal reasoning under uncer-
tainty via probabilistic logical inference, with online structure and weight learning techniques.
Our empirical evaluation on three datasets indicates that it compares favorably to state of the
art online & batch learners. Future work involves combination with semi-supervised learning,
towards handling the scarcity of labeled data in streaming settings.

Acknowledgements

This work is supported by the project entitled “INFORE: Interactive Extreme-Scale Analytics
and Forecasting”, funded by the EU’s Horizon 2020 research and innovation programme under
grant agreement No 825070 and by the project SYNTELESIS “Innovative Technologies and
Applications based on the Internet of Things and Cloud Computing” (MIS 5002521), which
is funded by the Operational Programme “Competitiveness, Entrepreneurship and Innovation”
(NSRF 2014-2020) and co-ﬁnanced by Greece and the EU. We would like to thank Mark Law
for his assistance in running ILASP.

References

ALEVIZOS, E., SKARLATIDIS, A., ARTIKIS, A., AND PALIOURAS, G. 2017. Probabilistic complex event

recognition: A survey. ACM Comput. Surv. 50, 5, 71:1–71:31.

ARTIKIS, A., SERGOT, M., AND PALIOURAS, G. 2015. An event calculus for event recognition. Knowl-

edge and Data Engineering, IEEE Transactions on 27, 4, 895–908.

ARTIKIS, A., SKARLATIDIS, A., PORTET, F., AND PALIOURAS, G. 2012. Logic-based event recognition.

The Knowledge Engineering Review 27, 04, 469–506.

ATHAKRAVI, D., CORAPI, D., BRODA, K., AND RUSSO, A. 2013. Learning through hypothesis reﬁne-

ment using answer set programming. In Inductive Logic Programming. Springer, 31–46.

BIFET, A., GAVALD `A, R., HOLMES, G., AND PFAHRINGER, B. 2018. Machine learning for data streams:

with practical examples in MOA. MIT Press.

12 The weight is translated to a cost for hypotheses that do not correctly account for these turning point examples.

Theory and Practice of Logic Programming

19

CUGOLA, G. AND MARGARA, A. 2012. Processing ﬂows of information: From data stream to complex

event processing. ACM Computing Surveys (CSUR) 44, 3, 15.

DE RAEDT, L. 2008. Logical and relational learning. Springer Science & Business Media.
DE RAEDT, L., KERSTING, K., NATARAJAN, S., AND POOLE, D. 2016. Statistical relational artiﬁcial in-
telligence: Logic, probability, and computation. Synthesis Lectures on Artiﬁcial Intelligence and Machine
Learning 10, 2, 1–189.

DOMINGOS, P. M. AND HULTEN, G. 2000. Mining high-speed data streams. In ACM SIGKDD. 71–80.
DUCHI, J., HAZAN, E., AND SINGER, Y. 2011. Adaptive subgradient methods for online learning and

stochastic optimization. Journal of Machine Learning Research 12, Jul, 2121–2159.

GUIMAR ˜AES, V., PAES, A., AND ZAVERUCHA, G. 2019. Online probabilistic theory revision from exam-

ples with proppr. Mach. Learn. 108, 7, 1165–1189.

HUYNH, T. N. AND MOONEY, R. J. 2009. Max-margin weight learning for markov logic networks. In

ECML-2009. Springer, 564–579.

HUYNH, T. N. AND MOONEY, R. J. 2011. Online max-margin weight learning for markov logic networks.

In SDM. SIAM, 642–651.

KATZOURIS, N. 2017. Scalable relational learning for event recognition. PhD Thesis, University of

Athens http://users.iit.demokritos.gr/ nkatz/papers/nkatz-phd.pdf.

KATZOURIS, N. AND ARTIKIS, A. 2020. WOLED: A tool for online learning weighted answer set rules

for temporal reasoning under uncertainty. In KR 2020.

KATZOURIS, N., ARTIKIS, A., AND PALIOURAS, G. 2015. Incremental learning of event deﬁnitions with

inductive logic programming. Machine Learning 100, 2-3, 555–585.

KATZOURIS, N., ARTIKIS, A., AND PALIOURAS, G. 2016. Online learning of event deﬁnitions.

TPLP 16, 5-6, 817–833.

KATZOURIS, N., ARTIKIS, A., AND PALIOURAS, G. 2019. Parallel online event calculus learning for

complex event recognition. Future Gener. Comput. Syst. 94, 468–478.

KATZOURIS, N., MICHELIOUDAKIS, E., ARTIKIS, A., AND PALIOURAS, G. 2018. Online learning of

weighted relational rules for complex event recognition. In ECML-PKDD 2018. 396–413.

LAW, M., RUSSO, A., AND BRODA, K. 2015. The ILASP system for learning answer set programs.

www.ilasp.com.

LAW, M., RUSSO, A., AND BRODA, K. 2018.
examples. Advances in Cognitive Systems.

Inductive learning of answer set programs from noisy

LEE, J., TALSANIA, S., AND WANG, Y. 2017. Computing LPMLN using ASP and MLN solvers. Theory

Pract. Log. Program. 17, 5-6, 942–960.

LEE, J. AND WANG, Y. 2016. Weighted rules under the stable model semantics. In KR, 2016.
LIFSCHITZ, V. 2019. Answer set programming. Springer.
MICHELIOUDAKIS, E., SKARLATIDIS, A., PALIOURAS, G., AND ARTIKIS, A. 2016. Osla: Online struc-

ture learning using background knowledge axiomatization. In ECML. Springer, 232–247.

MUELLER, E. T. 2014. Commonsense reasoning: an event calculus based approach. Morgan Kaufmann.
PATROUMPAS, K., ALEVIZOS, E., ARTIKIS, A., VODAS, M., PELEKIS, N., AND THEODORIDIS, Y. 2017.

Online event recognition from moving vessel trajectories. GeoInformatica 21, 2, 389–427.

RAY, O. 2009. Nonmonotonic abductive inductive learning. Journal of Applied Logic 7, 3, 329–340.
SKARLATIDIS, A. AND MICHELIOUDAKIS, E. 2014. Logical Markov Random Fields (LoMRF): an open-

source implementation of Markov Logic Networks.

SKARLATIDIS, A., PALIOURAS, G., ARTIKIS, A., AND VOUROS, G. A. 2015. Probabilistic event calculus

for event recognition. ACM Transactions on Computational Logic (TOCL) 16, 2, 11.

TSILIONIS, E., KOUTROUMANIS, N., NIKITOPOULOS, P., DOULKERIDIS, C., AND ARTIKIS, A. 2019.
Online event recognition from moving vehicles: Application paper. Theory Pract. Log. Program. 19, 5-6,
841–856.

