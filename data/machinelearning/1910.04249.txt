Probabilistic Veriﬁcation and Reachability Analysis of
Neural Networks via Semideﬁnite Programming

Mahyar Fazlyab, Manfred Morari, George J. Pappas

9
1
0
2

t
c
O
9

]

Y
S
.
s
s
e
e
[

1
v
9
4
2
4
0
.
0
1
9
1
:
v
i
X
r
a

Abstract— Quantifying the robustness of neural networks or
verifying their safety properties against input uncertainties
or adversarial attacks have become an important research
area in learning-enabled systems. Most results concentrate
around the worst-case scenario where the input of the neural
network is perturbed within a norm-bounded uncertainty set.
In this paper, we consider a probabilistic setting in which
the uncertainty is random with known ﬁrst two moments. In
this context, we discuss two relevant problems: (i) probabilistic
safety veriﬁcation, in which the goal is to ﬁnd an upper bound
on the probability of violating a safety speciﬁcation; and (ii)
conﬁdence ellipsoid estimation,
in which given a conﬁdence
ellipsoid for the input of the neural network, our goal is to
compute a conﬁdence ellipsoid for the output. Due to the
presence of nonlinear activation functions, these two problems
are very difﬁcult to solve exactly. To simplify the analysis, our
main idea is to abstract the nonlinear activation functions by a
combination of afﬁne and quadratic constraints they impose
on their input-output pairs. We then show that the safety
of the abstracted network, which is sufﬁcient for the safety
of the original network, can be analyzed using semideﬁnite
programming. We illustrate the performance of our approach
with numerical experiments.

I. INTRODUCTION

Neural Networks (NN) have been very successful in vari-
ous applications such as end-to-end learning for self-driving
cars [1], learning-based controllers in robotics [2], speech
recognition, and image classiﬁers. Their vulnerability to in-
put uncertainties and adversarial attacks, however, refutes the
deployment of neural networks in safety critical applications.
In the context of image classiﬁcation, for example, it has
been shown in several works [3]–[5] that even adding an
imperceptible noise to the input of neural network-based
classiﬁers can completely change their decision. In this con-
text, veriﬁcation refers to the process of checking whether the
output of a trained NN satisﬁes certain desirable properties
when its input is perturbed within an uncertainty model.
More precisely, we would like to verify whether the neural
network’s prediction remains the same in a neighborhood of a
test point x(cid:63). This neighborhood can represent, for example,
the set of input examples that can be crafted by an adversary.
In worst-case safety veriﬁcation, we assume that the input
uncertainty is bounded and we verify a safety property for
all possible perturbations within the uncertainty set. This
approach has been pursued extensively in several works using
various tools, such as mixed-integer linear programming
[6]–[8], robust optimization and duality theory [9], [10],

†Corresponding author: mahyarfa@seas.upenn.edu. This work was sup-
ported by DARPA Assured Autonomy and NSF CPS 1837210. The authors
are with the Department of Electrical and Systems Engineering, University
of Pennsylvania. Email: {mahyarfa, morari, pappasg}@seas.upenn.edu.

Satisﬁability Modulo Theory (SMT) [11], dynamical systems
[12], [13], Robust Control [14], Abstract Interpretation [15]
and many others [16], [17].

In probabilistic veriﬁcation, on the other hand, we as-
sume that the input uncertainty is random but potentially
unbounded. Random uncertainties can emerge as a result of,
for example, data quantization, input preprocessing, and en-
vironmental background noises [18]. In contrast to the worst-
case approach, there are only few works that have studied
veriﬁcation of neural networks in probabilistic settings [18]–
[20]. In situations where we have random uncertainty mod-
els, we ask a related question: “Can we provide statistical
guarantees on the output of neural networks when their input
is perturbed with a random noise?” In this paper, we provide
an afﬁrmative answer by addressing two related problems:

• Probabilistic Veriﬁcation: Given a safe region in the output
space of the neural network, our goal
is estimate the
probability that the output of the neural network will be
in the safe region when its input is perturbed by a random
variable with a known mean and covariance.

• Conﬁdence propagation: Given a conﬁdence ellipsoid on
the input of the neural network, we want to estimate the
output conﬁdence ellipsoid.

The rest of the paper is organized as follows. In Sec-
tion II, we discuss safety veriﬁcation of neural networks
in both deterministic and probabilistic settings. In Section
III, we provide an abstraction of neural networks using
the formalism of quadratic constraints. In Section IV we
develop a convex relaxation to the problem of conﬁdence
ellipsoid estimation. In Section V, we present the numerical
experiments. Finally, we draw our conclusions in Section VI.

A. Notation and Preliminaries

We denote the set of real numbers by R, the set of real
n-dimensional vectors by Rn, the set of m
n-dimensional
matrices by Rm×n, and the n-dimensional identity matrix
by In. We denote by Sn, Sn
++ the sets of n-
by-n symmetric, positive semideﬁnite, and positive deﬁnite
matrices, respectively. We denote ellipsoids in Rn by

+, and Sn

×

|

{

x

xc)(cid:62)P −1(x

−

(x

xc)

(xc, P ) =

1
}
Rn is the center of the ellipsoid and P

E
where xc ∈
++
determines its orientation and volume. We denote the mean
Rn
and covariance of a random variable X
and Cov[X]

∈
Rn by E[X]

Sn
+, respectively.

Sn

−

≤

∈

∈

,

∈

 
 
 
 
 
 
II. SAFETY VERIFICATION OF NEURAL NETWORKS

A. Deterministic Safety Veriﬁcation

Consider a multi-layer feed-forward fully-connected neu-

ral network described by the following equations,

x0 = x

(1)

xk+1 = φ(W kxk + bk) k = 0,
f (x) = W (cid:96)x(cid:96) + b(cid:96),

, (cid:96)

1

−

· · ·

to the network, W k

where x0 = x is the input
∈
Rnk+1×nk , bk
Rnk+1 are the weight matrix and bias
vector of the k-th layer. The nonlinear activation function
) (Rectiﬁed Linear Unit (ReLU), sigmoid, tanh, leaky
φ(
·
ReLU, etc.) is applied coordinate-wise to the pre-activation
vectors, i.e., it is of the form

∈

φ(x) = [ϕ(x1)

ϕ(xd)](cid:62),

· · ·

(2)

where ϕ is the activation function of each individual neuron.
Although our framework is applicable to all activation func-
tions, we focus our attention to ReLU activation functions,
ϕ(x) = max(x, 0).

X ⊂

In deterministic safety veriﬁcation, we are given a bounded
Rnx of possible inputs (the uncertainty set), which
set
is mapped by the neural network to the output reachable set
). The desirable properties that we would like to verify
f (
Rny in the output space
can often be described by a set
of the neural network, which we call the safe region. In this
context, the network is safe if f (

S ⊂

X

)

.

X
B. Probabilistic Safety Veriﬁcation

⊆ S

In a deterministic setting, reachability analysis and safety
veriﬁcation is a yes/no problem whose answer does not
quantify the proportion of inputs for which the safety is
violated. Furthermore, if the uncertainty is random and po-
tentially unbounded, the output f (x) would satisfy the safety
constraint only with a certain probability. More precisely,
given a safe region
in the output space of the neural
network, we are interested in ﬁnding the probability that the
neural network maps the random input X to the safe region,

S

Pr(f (X)

).

∈ S

Since f (x) is a nonlinear function, computing the distribution
of f (X) given the distribution of X is prohibitive, except
for special cases. As a result, we settle for providing a lower
bound p

(0, 1) on the desired probability,

∈

Pr(f (X)

p.

)

≥

∈ S

To compute the lower bound, we adopt a geometrical ap-
proach, in which we verify whether the reachable set of a
conﬁdence region of the input lies entirely in the safe set
.
We ﬁrst recall the deﬁnition of a conﬁdence region.

S

Deﬁnition 1 (Conﬁdence region) The p-level (p
∈
conﬁdence region of a vector random variable X
∈
deﬁned as any set
∈ Ep)
≥

Rn for which Pr(X

Ep ⊆

[0, 1])
Rn is
p.

Although conﬁdence regions can have different represen-
tations, our particular focus in this paper is on ellipsoidal
conﬁdence regions. Due to their appealing geometric prop-
erties (e.g., invariance to afﬁne subspace transformations),
ellipsoids are widely used in robust control
to compute
reachable sets [21]–[23].

The next two lemmas characterize conﬁdence ellipsoids
for Gaussian random variables and random variables with
known ﬁrst two moments.

(µ, Σ) be an n-dimensional Gaussian
Lemma 1 Let X
random variable. Then the p-level conﬁdence region of X is
given by the ellipsoid

∼ N

x

(x

µ)(cid:62)Σ−1(x

Ep =
≤
n(p) is the quantile function of

where χ2
distribution with n degrees of freedom.

µ)

−

−

{

|

χ2

n(p)
}

,

(3)

the chi-squared

For non-Gaussian random variables, we can use Cheby-
shev’s inequality to characterize the conﬁdence ellipsoids, if
we know the ﬁrst two moments.

Lemma 2 Let X be an n-dimensional random variable with
E[X] = µ and Cov[X] = Σ. Then the ellipsoid
n

Ep =

x
{

|
is a p-level conﬁdence region of X.

−

−

(x

µ)(cid:62)Σ−1(x

µ)

,
p }

≤

1

−

(4)

Lemma 3 Let
able X. If f (
for the random variable f (X), i.e., Pr(f (X)

Ep be a conﬁdence region of a random vari-
is a p-level conﬁdence region
Ep)
⊆ S

, then

p.

S

)

∈ S
implies Pr(f (X)

≥

)

Proof: The inclusion f (
Pr(f (X)

∈
Ep)). Since f is not necessarily a one-
f (
∈
∈
p. Combining the last two inequalities yields the

S
∈
≥
to-one mapping, we have Pr(f (X)
Ep)
≥
desired result.

Ep))

Pr(X

Ep)

⊆ S

f (

≥

According to Lemma 3, if we can certify that the output
reachable set f (
for some
Ep) lies entirely in the safe set
(0, 1), then the network is safe with probability at least
p
p. In particular, ﬁnding the best lower bound corresponds to
the non-convex optimization problem,

∈

S

maximize p subject to f (

Ep)
[0, 1). By Lemma 3, the optimal

⊆ S

(5)

,

with decision variable p
solution p(cid:63) then satisﬁes

∈

Pr(f (X)

)

≥

∈ S

p(cid:63).

(6)

C. Conﬁdence Propagation

A closely related problem to probabilistic safety veriﬁ-
cation is conﬁdence propagation. Explicitly, given a p-level
Ep of the input of a neural network, our
conﬁdence region
goal is to ﬁnd a p-level conﬁdence region for the output. To
see the connection to the probabilistic veriﬁcation problem,
be any outer approximation of the output reachable
let
S
is a p-level conﬁdence
set, i.e., f (

. By lemma 3,

Ep)

⊆ S

S

for the ReLU function, we recall some deﬁnitions, which can
be found in many references; for example [24], [25].

Deﬁnition 3 (Sector-bounded nonlinearity) A nonlinear
function ϕ : R
R is sector-bounded on the sector [α, β]
(0
α

β) if the following condition holds for all x,

→

≤

≤

(ϕ(x)

−

αx)(ϕ(x)

βx)

0.

≤

−

(9)

Deﬁnition 4 (Slope-restricted nonlinearity) A nonlinear
function ϕ(x) : R
R is slope-restricted on [α, β]
(0

β) if for any (x, ϕ(x)) and (x(cid:63), ϕ(x(cid:63))),

→

α

≤
(ϕ(x)

≤
ϕ(x(cid:63))

−

α(x

−

−

x(cid:63)))(ϕ(x)

ϕ(x(cid:63))

β(x

−

−

x(cid:63)))

−

0.
≤
(10)

Repeated nonlinearities. Assuming that the same activa-
tion function is used in all neurons, we can exploit this
structure to reﬁne the QC abstraction of the nonlinearity.
Explicitly, suppose ϕ : R
R is slope-restricted on [α, β]
→
ϕ(xd)](cid:62) be a vector-valued
and let φ(x) = [ϕ(x1)
· · ·
function constructed by component-wise repetition of ϕ. It is
not hard to verify that φ is also slope-restricted in the same
sector. However, this representation simply ignores the fact
that all the nonlinearities that compose φ are the same. By
taking advantage of this structure, we can reﬁne the quadratic
constraint that describes φ. To be speciﬁc, for an input-output
Rd, we can write the slope-restriction
pair (x, φ(x)), x
condition

∈

(ϕ(xi)

ϕ(xj)

α(xi −

−

−

xj))(ϕ(xi)

ϕ(xj)

β(xi −

−

xj))

−

0,
≤
(11)

for all distinct i, j. This particular QC can tighten the
relaxation incurred by the QC abstraction of the nonlinearity.
There are several results in the literature about repeated
nonlinearities. For instance, in [25], [26], the authors derive
QCs for repeated and odd nonlinearities (e.g. tanh function).

B. QC for ReLU function

In this subsection, we derive quadratic constraints for
Rd. Note
the ReLU function, φ(x) = max(0, x), x
that this function lies on the boundary of the sector [0, 1].
More precisely, we can describe the ReLU function by three
quadratic and/or afﬁne constraints:

∈

yi = max(0, xi)

yi ≥
On the other hand, for any two distinct indices i
can write the constraint (11) with α = 0, and β = 1,

xi, yi ≥

i = xiyi.

⇔

0, y2

(12)

= j, we

yi)2

(yj −

(yj −
By adding a weighted combination of all these constraints
(positive weights for inequalities), we ﬁnd that the ReLU
function y = max(0, x) satisﬁes

yi)(xj −

xi).

(13)

≤

d
(cid:88)

i=1

λi(y2

i −
(cid:88)

xiyi) + νi(yi −
(cid:0)(yj −
yi)2

−

xi) + ηiyi−

(14)

(yj −

yi)(xj −

xi)(cid:1)

0,

≥

λij

i(cid:54)=j

Fig. 1: p-level input conﬁdence ellipsoid Ep, its image f (Ep), and
the estimated output conﬁdence ellipsoid.

region for the output. Of course, there is an inﬁnite number
of such possible conﬁdence regions. Our goal is ﬁnd the
“best” conﬁdence region with respect to some metric. Using
the volume of the ellipsoid as an optimization criterion, the
best conﬁdence region amounts to solving the problem

minimize Volume(

S

)

subject to f (

Ep)

.

⊆ S

(7)

The solution to the above problem provides the p-level conﬁ-
dence region with the minimum volume. Figure 1 illustrates
the procedure of conﬁdence estimation. In the next section,
we provide a convex relaxation of the optimization problem
(7). The other problem in (5) is a straightforward extension
of conﬁdence estimation, and hence, we will not discuss the
details.

III. PROBLEM RELAXATION VIA QUADRATIC
CONSTRAINTS

⊆ S

Due to the presence of nonlinear activation functions,
checking the condition f (
in (5) or (7) is a non-
Ep)
convex feasibility problem and is NP-hard, in general. Our
main idea is to abstract the original network f by another
network ˜f in the sense that ˜f over-approximates the output
of the original network for any input ellipsoid, i.e., f (
⊆
˜f (
[0, 1). Then it will be sufﬁcient to verify
the safety properties of the relaxed network, i.e., verify the
inclusion ˜f (
. In the following, we use the framework
of quadratic constraints to develop such an abstraction.

Ep) for any p
Ep)

Ep)

⊆ S

∈

A. Relaxation of Nonlinearities by Quadratic Constraints

In this subsection, we show how we can abstract activa-
tion functions, and in particular the ReLU function, using
quadratic constraints. We ﬁrst provide a formal deﬁnition,
introduced in [14].

Deﬁnition 2 Let φ : Rd
S2d+1
is the set of all symmetric and indeﬁnite matrices Q such
that the inequality

Rd be and suppose

Q ⊂

→



(cid:62)





Q







x
φ(x)
1





x
φ(x)
1

0,

≥

(8)

holds for all x
constraint deﬁned by

∈

.
Q

Rd. Then we say φ satisﬁes the quadratic

Note that
the matrix Q in Deﬁnition 2 is indeﬁnite, or
otherwise, the constraint trivially holds. Before deriving QCs

Ep<latexit sha1_base64="TCgjEPzO85Lb5oCVkSm+VVj37fc=">AAAB+HicbVBNS8NAFHypX7V+NOrRy2IreCpJPejBQ0EEjxVsLbQhbLabdulmE3Y3Qg39JV48KOLVn+LNf+OmzUFbBxaGmfd4sxMknCntON9WaW19Y3OrvF3Z2d3br9oHh10Vp5LQDol5LHsBVpQzQTuaaU57iaQ4Cjh9CCbXuf/wSKVisbjX04R6ER4JFjKCtZF8u1ofRFiPCebZzcxP6r5dcxrOHGiVuAWpQYG2b38NhjFJIyo04Vipvusk2suw1IxwOqsMUkUTTCZ4RPuGChxR5WXz4DN0apQhCmNpntBorv7eyHCk1DQKzGSeUi17ufif1091eOllTCSppoIsDoUpRzpGeQtoyCQlmk8NwUQykxWRMZaYaNNVxZTgLn95lXSbDfe84d41a62roo4yHMMJnIELF9CCW2hDBwik8Ayv8GY9WS/Wu/WxGC1Zxc4R/IH1+QM4GZLG</latexit>f(Ep)<latexit sha1_base64="5zR85ZlT+yz2Hwf3iAT1/kAGLak=">AAAB+3icbVDLSsNAFL2pr1pfsS7dDLZC3ZSkLnThoiCCywq2FtoQJtNJO3TyYGYilpBfceNCEbf+iDv/xkmbhbYeGDiccy/3zPFizqSyrG+jtLa+sblV3q7s7O7tH5iH1Z6MEkFol0Q8En0PS8pZSLuKKU77saA48Dh98KbXuf/wSIVkUXivZjF1AjwOmc8IVlpyzWrdbwwDrCYE8/Qmc+OzumvWrKY1B1oldkFqUKDjml/DUUSSgIaKcCzlwLZi5aRYKEY4zSrDRNIYkyke04GmIQ6odNJ59gydamWE/EjoFyo0V39vpDiQchZ4ejKPKZe9XPzPGyTKv3RSFsaJoiFZHPITjlSE8iLQiAlKFJ9pgolgOisiEywwUbquii7BXv7yKum1mvZ5075r1dpXRR1lOIYTaIANF9CGW+hAFwg8wTO8wpuRGS/Gu/GxGC0Zxc4R/IHx+QPLdpOb</latexit>f<latexit sha1_base64="r+xhBdATjNqTJpT+6+/dcYDxDh8=">AAAB6nicbVA9TwJBEJ3DL8Qv1NJmI5hYkTsstLAgsbHEKEgCF7K37MGGvb3L7pwJufATbCw0xtZfZOe/cYErFHzJJC/vzWRmXpBIYdB1v53C2vrG5lZxu7Szu7d/UD48aps41Yy3WCxj3Qmo4VIo3kKBkncSzWkUSP4YjG9m/uMT10bE6gEnCfcjOlQiFIyile6rYbVfrrg1dw6ySrycVCBHs1/+6g1ilkZcIZPUmK7nJuhnVKNgkk9LvdTwhLIxHfKupYpG3PjZ/NQpObPKgISxtqWQzNXfExmNjJlEge2MKI7MsjcT//O6KYZXfiZUkiJXbLEoTCXBmMz+JgOhOUM5sYQyLeythI2opgxtOiUbgrf88ipp12veRc27q1ca13kcRTiBUzgHDy6hAbfQhBYwGMIzvMKbI50X5935WLQWnHzmGP7A+fwBgSaNQQ==</latexit>(cid:54)
for any multipliers (λi, νi, ηi, λij)
1,
{
form (8), as stated in the following lemma.

∈
. This inequality can be written in the compact
, d
}

+ for i, j

· · ·

×

∈

R

R3

Lemma 4 (QC for ReLU function) The ReLU function,
φ(x) = max(0, x) : Rd
where

Rd, satisﬁes the QC deﬁned by

→

Q






=

Q

Q =

Q

|














ν
−
ν +η
0

0
T
−
ν(cid:62) ν(cid:62) +η(cid:62)

T
2T

−
Sd
+ is given by

0 and T

∈

Here η, ν

T =

≥
d
(cid:88)

i=1

λieie(cid:62)

i +

d−1
(cid:88)

d
(cid:88)

i=1

j>i

λij(ei −

ej)(ei −

ej)(cid:62),

where ei is the i-th basis vector in Rd and λij ≥

0.

Proof: See [14].

Lemma 4 characterizes a family of valid QCs for the ReLU
function. It is not hard to verify that the set
of valid QCs is
a convex cone. As we will see in the next section, the matrix
Q in (15) appears as a decision variable in the optimization
problem.

Q

C. Tightening the Relaxation

In the previous subsection, we derived QCs that are valid
for the whole space Rd. When restricted to a region
Rd,
R ⊆
we can tighten the QC relaxation. Consider the relationship
− be the
φ(x) = max(0, x), x
set of neurons that are always active or always inactive, i.e.,

Rd and let

+, and

∈ R ⊆

I

I

+ =
− =

I

I

|

0 for all x
xi ≥
xi < 0 for all x

i
{
i
{
xi holds with equality for active neurons.

∈ R}
.
∈ R}

(16)

|

The constraint yi ≥
Therefore, we can write

R if i

νi ∈
Similarly, the constraint yi ≥
inactive neurons. Therefore, we can write

+, νi ≥

∈ I

0 otherwise.

0 holds with equality for

∈ I

R if i

ηi ∈

0 otherwise.

−, ηi ≥
Finally, it can be veriﬁed that the cross-coupling constraint in
(13) holds with equality for pairs of always active or always
inactive neurons. Therefore, for any 1
d, we can
write

i < j

≤

≤

+

R if (i, j)
0 otherwise.

∈ I

× I

λij ∈
λij ≥

+ or (i, j)

−

−

∈ I

× I

These additional degrees of freedom on the multipliers can
tighten the relaxation incurred in (14). Note that the set of
active or inactive neurons are not known a priori. However,
we can partially ﬁnd them using, for example,
interval
arithmetic.

IV. ANALYSIS OF THE RELAXED NETWORK VIA
SEMIDEFINITE PROGRAMMING

In this section, we use the QC abstraction developed in
the previous section to analyze the safety of the relaxed
network. In the next theorem, we state our main result for
one-layer neural networks and will discuss the multi-layer
case in Section IV-A.

.

(15)

Theorem 1 (Output covering ellipsoid) Consider a one-
layer neural network f : Rnx
Rny described by the
equation

→

y = W 1φ(W 0x + b0) + b1,

(17)

Rn1 satisﬁes the quadratic constraint

where φ : Rn1
deﬁned by

→

, i.e., for any Q

Q




z
φ(z)
1



(cid:62)





Q



z
φ(z)
1

,
∈ Q




0

for all z.

(18)

≥

Suppose x
inequality

∈ E

(µx, Σx). Consider the following matrix

M1 + M2 + M3

0,

(cid:22)

(19)

where

M1 =





M2 =

M3 =

with


0
Inx
0
0
 P (τ )
0
1

W 0(cid:62)

0

b0(cid:62)

0
W 1(cid:62)


b1(cid:62)

0
In1
0






Inx
0
0



0

0
 Q
1

(cid:62)


0
0

1





W 0
0
0

0
In1
0





b0
0
1

(cid:20)0 W 1
0
0

(cid:21)

b1
1

0

0
 S(A, b)
1

P (τ ) = τ

S(A, b) =

(cid:21)

x µx
x µx + 1

Σ−1
x Σ−1
µ(cid:62)
(cid:21)

(cid:20)
Σ−1
x
−
x Σ−1
µ(cid:62)
x
(cid:20) A2
b(cid:62)A b(cid:62)b

−
Ab

1

−

.

If (19) is feasible for some (τ, A, Q, b)

Rny , then y

(µy, Σy) with µy =

−

∈ E

R+

Sny

∈

× Q ×
×
A−1b and Σy = A−2.

Proof: We ﬁrst introduce the auxiliary variable z, and

rewrite the equation of the neural network as

z = φ(W 0x + b0)

y = W 1z + b1.

Since φ satisﬁes the QC deﬁned by
following QC from the identity z = φ(W 0x + b0):

Q

, we can write the





W 0x + b0
z
1



(cid:62)



Q





W 0x + b0
z
1





≥

0, for all Q

.
∈ Q

(21)

By substituting the identity






W 0x + b0
z
1



 =



W 0
0
0

0
In1
0





b0
0
1





x
z
1



 ,

back into (21) and denoting x = [x(cid:62) z(cid:62)](cid:62), we can write
the inequality

Lemma 5 The matrix inequality in (19) is equivalent to the
linear matrix inequality (LMI)







M =

M1 + M2

ee(cid:62)

−

0ny×nx AW 1 Ab1 +b

0nx×ny
W 1(cid:62)
A
b1(cid:62)
A+b(cid:62)
Iny

−





 (cid:22)

0,

(24)

(cid:21)(cid:62)

(cid:20)x
1

M2

(cid:21)

(cid:20)x
1

0,

≥

(22)

in (τ, A, Q, b), where e = (0,

, 0, 1)

∈

· · ·

Rnx+n1+1.

Proof:
as M3 = F F (cid:62)

It is not hard to verify that M3 can be written
ee(cid:62), where F , afﬁne in (A, b), is given by

−

for any Q

(µx, Σx), we have (x

∈ Q

E
is equivalent to

−

and all x. By deﬁnition, for all x
x (x

µx)(cid:62)Σ−1

∈
1, which

µx)

−

≤



0nx×ny
W 1(cid:62)
A
A + b(cid:62)



b1(cid:62)




 .

(cid:21)(cid:62) (cid:20)

(cid:20)x
1

τ

Σ−1
x
−
x Σ−1
µ(cid:62)
x

Σ−1
x Σ−1
µ(cid:62)

x µx
x µx + 1

−

(cid:21)

(cid:21) (cid:20)x
1

0.

≥

F (A, b) =

By using the identity

(cid:21)

(cid:20)x
1

(cid:20)Inx
0

=

(cid:21)

0 0
0 1



 ,





x
z
1

we conclude that for all x

(cid:21)(cid:62)

(cid:20)x
1

∈ E

M1

(µx, Σx), z = φ(W 0x + b),
(cid:20)x
1

0.

(cid:21)

(23)

≥

Rny .
Suppose (19) holds for some (A, Q, b)
By left- and right- multiplying both sides of (18) by [x(cid:62) 1]
and [x(cid:62) 1](cid:62), respectively, we obtain

× Q ×

Sny

∈

(cid:21)(cid:62)

(cid:20)x
1

M1

(cid:21)(cid:62)

(cid:21)
(cid:20)x
1

+

(cid:20)x
1

M2

(cid:21)(cid:62)

(cid:21)

(cid:20)x
1

(cid:20)x
1

+

M3

(cid:21)

(cid:20)x
1

0.

≤

∈ E

For any x
(µx, Σx) the ﬁrst two quadratic terms are
nonnegative by (23) and (22), respectively. Therefore, the
last term on the left-hand side must be nonpositive for all
x

(µx, Σx),

∈ E

(cid:21)(cid:62)

(cid:20)x
1

M3

(cid:21)

(cid:20)x
1

0.

≤

ee(cid:62))+F F (cid:62)

Using this deﬁnition, the matrix inequality in (19) reads
0, which implies that the term in
(M1 +M2
(cid:22)
the parentheses must be non-negative, i.e., M1 +M2
(cid:22)
0. Using Schur Complements, the last two inequalities are
equivalent to (24).

ee(cid:62)

−

−

Having established Lemma 5, we can now ﬁnd the
minimum-volume covering ellipsoid by solving the following
semideﬁnite program (SDP),

minimize

log det(A) subject to (24).

(25)

−
where the decision variables are (τ, A, Q, b)

Rny . Since

×
is a convex cone, (25) is a convex program

×

∈

Q×
and can be solved via interior-point method solvers.

Q

R+

Sny

A. Multi-layer Case

For multi-layer neural networks, we can apply the result
of Theorem 1 in a layer-by-layer fashion provided that the
input conﬁdence ellipsoid of each layer is non-degenerate.
1 we
This assumption holds when for all 0
≤
nk (reduction in the width of layers), and the
have nk+1
Rnk+1×nk are full rank. To see this,
weight matrices W k
we note that ellipsoids are invariant under afﬁne subspace
transformations such that

≤

−

≤

∈

k

(cid:96)

But the preceding inequality, using the relation y = W 1z +
b1, is equivalent to

W k

E

(µk, Σk) + bk =

(W kµk + bk, W kΣkW k(cid:62)

).

E

(cid:20)y
1

(cid:21)(cid:62) (cid:20) A2

Ab

b(cid:62)A b(cid:62)b

−

(cid:21)

(cid:21) (cid:20)y
1
1

0,

≤

which is equivalent to (y+A−1b)(cid:62)A2(y+A−1b)
our notation for ellipsoids, this means for all x
we must have y

A−1b, A−2).

≤
∈ E

1. Using
(µx, Σx),

(
−

∈ E

This implies that Σk+1 := W kΣkW k(cid:62)
is positive deﬁnite
whenever Σk is positive deﬁnite, implying that the ellipsoid
(µk+1, Σk+1) is non-degenerate. If the assumption nk+1
E
≤
nk is violated, we can use the compact representation of
multi-layer neural networks elaborated in [14] to arrive at
the multi-layer couterpart of the matrix inequality in (19).

In Theorem 1, we proposed a matrix inequality,
in
variables (Q, A, b), as a sufﬁcient condition for enclos-
ing the output of the neural network with the ellipsoid
A−1b, A−2). We can now use this result to ﬁnd the
E
minimum-volume ellipsoid with this property. Note that the
matrix inequality (19) is not linear in (A, b). Nevertheless,
we can convexify it by using Schur Complements.

−

(

V. NUMERICAL EXPERIMENTS

In this section, we consider a numerical experiment, in
which we estimate the conﬁdence ellipsoid of a one-layer
neural network with nx = 2 inputs, n1
10, 30, 50
}
hidden neurons and ny = 2 outputs. We assume the input
is Gaussian with µx = (1, 1) and Σx = diag(1, 2). The
weights and biases of the network are chosen randomly.
We use MATLAB, CVX [27], and Mosek [28] to solve the

∈ {

[6] O. Bastani, Y. Ioannou, L. Lampropoulos, D. Vytiniotis, A. Nori, and
A. Criminisi, “Measuring neural net robustness with constraints,” in
Advances in neural information processing systems, pp. 2613–2621,
2016.

[7] A. Lomuscio and L. Maganti, “An approach to reachability analysis for
feed-forward relu neural networks,” arXiv preprint arXiv:1706.07351,
2017.

[8] V. Tjeng, K. Xiao, and R. Tedrake, “Evaluating robustness of
neural networks with mixed integer programming,” arXiv preprint
arXiv:1711.07356, 2017.

[9] J. Z. Kolter and E. Wong, “Provable defenses against adversarial
examples via the convex outer adversarial polytope,” arXiv preprint
arXiv:1711.00851, vol. 1, no. 2, p. 3, 2017.

[10] K. Dvijotham, R. Stanforth, S. Gowal, T. Mann, and P. Kohli, “A dual
approach to scalable veriﬁcation of deep networks,” arXiv preprint
arXiv:1803.06567, 2018.

[11] L. Pulina and A. Tacchella, “Challenging smt solvers to verify neural

networks,” AI Communications, vol. 25, no. 2, pp. 117–135, 2012.

[12] R. Ivanov, J. Weimer, R. Alur, G. J. Pappas, and I. Lee, “Verisig:
verifying safety properties of hybrid systems with neural network
controllers,” arXiv preprint arXiv:1811.01828, 2018.

[13] W. Xiang, H.-D. Tran, and T. T. Johnson, “Output reachable set
estimation and veriﬁcation for multilayer neural networks,” IEEE
transactions on neural networks and learning systems, no. 99, pp. 1–7,
2018.

[14] M. Fazlyab, M. Morari, and G. J. Pappas, “Safety veriﬁcation and
robustness analysis of neural networks via quadratic constraints and
semideﬁnite programming,” arXiv preprint arXiv:1903.01287, 2019.
[15] M. Mirman, T. Gehr, and M. Vechev, “Differentiable abstract in-
terpretation for provably robust neural networks,” in International
Conference on Machine Learning, pp. 3575–3583, 2018.

[16] M. Hein and M. Andriushchenko, “Formal guarantees on the robust-
ness of a classiﬁer against adversarial manipulation,” in Advances in
Neural Information Processing Systems, pp. 2266–2276, 2017.
[17] S. Wang, K. Pei, J. Whitehouse, J. Yang, and S. Jana, “Efﬁcient formal
safety analysis of neural networks,” in Advances in Neural Information
Processing Systems, pp. 6369–6379, 2018.

[18] T.-W. Weng, P.-Y. Chen, L. M. Nguyen, M. S. Squillante, I. Oseledets,
and L. Daniel, “Proven: Certifying robustness of neural networks with
a probabilistic approach,” arXiv preprint arXiv:1812.08329, 2018.
[19] K. Dvijotham, M. Garnelo, A. Fawzi, and P. Kohli, “Veriﬁcation of

deep probabilistic models,” arXiv preprint arXiv:1812.02795, 2018.

[20] A. Bibi, M. Alfadly, and B. Ghanem, “Analytic expressions for
probabilistic moments of pl-dnn with gaussian input,” in Proceedings
of the IEEE Conference on Computer Vision and Pattern Recognition,
pp. 9099–9107, 2018.

[21] K. P. Wabersich and M. N. Zeilinger, “Linear model predictive safety
certiﬁcation for learning-based control,” in 2018 IEEE Conference on
Decision and Control (CDC), pp. 7130–7135, IEEE, 2018.

[22] D. Van Hessem and O. Bosgra, “A conic reformulation of model
predictive control including bounded and stochastic disturbances under
state and input constraints,” in Proceedings of the 41st IEEE Confer-
ence on Decision and Control, 2002., vol. 4, pp. 4643–4648, IEEE,
2002.

[23] M. Cannon, B. Kouvaritakis, S. V. Rakovic, and Q. Cheng, “Stochastic
tubes in model predictive control with probabilistic constraints,” IEEE
Transactions on Automatic Control, vol. 56, no. 1, pp. 194–200, 2011.
[24] A. Megretski and A. Rantzer, “System analysis via integral quadratic
constraints,” IEEE Transactions on Automatic Control, vol. 42, no. 6,
pp. 819–830, 1997.

[25] F. D’amato, M. A. Rotea, A. Megretski, and U. J¨onsson, “New results
for analysis of systems with repeated nonlinearities,” Automatica,
vol. 37, no. 5, pp. 739–747, 2001.

[26] V. V. Kulkarni and M. G. Safonov, “All multipliers for repeated
monotone nonlinearities,” IEEE Transactions on Automatic Control,
vol. 47, no. 7, pp. 1209–1212, 2002.

[27] M. Grant, S. Boyd, and Y. Ye, “Cvx: Matlab software for disciplined

convex programming,” 2008.

[28] M. ApS, The MOSEK optimization toolbox for MATLAB manual.

Version 8.1., 2017.

Fig. 2: Top: the estimated 95% conﬁdence ellipsoid along with 104
samples of the output. Bottom: The image of the 95% input conﬁ-
dence ellipsoid (f (Ep) with p = 0.95) and its outer approximation
(the output conﬁdence ellipsoid).

corresponding SDP. In Figure 2, we plot the estimated 0.95-
level output conﬁdence ellipsoid along with 104 sample out-
puts. We also plot the image of 0.95-level input conﬁdence
ellipsoid under f along with the estimated 0.95-level output
conﬁdence ellipsoid.

VI. CONCLUSIONS

We studied probabilistic safety veriﬁcation of neural net-
works when their inputs are subject to random noise with
known ﬁrst two moments. Instead of analyzing the network
directly, we proposed to study the safety of an abstracted
network instead, in which the nonlinear activation functions
are relaxed by the quadratic constraints their input-output
pairs satisfy. We then showed that we can analyze the safety
properties of the abstracted network using semideﬁnite pro-
gramming. It would be interesting to consider other related
problems such as closed-loop statistical safety veriﬁcation
and reachability analysis.

REFERENCES

[1] M. Bojarski, D. Del Testa, D. Dworakowski, B. Firner, B. Flepp,
P. Goyal, L. D. Jackel, M. Monfort, U. Muller, J. Zhang, et al., “End to
end learning for self-driving cars,” arXiv preprint arXiv:1604.07316,
2016.

[2] G. Shi, X. Shi, M. O’Connell, R. Yu, K. Azizzadenesheli, A. Anand-
kumar, Y. Yue, and S.-J. Chung, “Neural lander: Stable drone landing
control using learned dynamics,” arXiv preprint arXiv:1811.08027,
2018.

[3] S. Zheng, Y. Song, T. Leung, and I. Goodfellow, “Improving the ro-
bustness of deep neural networks via stability training,” in Proceedings
of the ieee conference on computer vision and pattern recognition,
pp. 4480–4488, 2016.

[4] S.-M. Moosavi-Dezfooli, A. Fawzi, O. Fawzi, and P. Frossard, “Uni-

versal adversarial perturbations,” arXiv preprint, 2017.

[5] J. Su, D. V. Vargas, and K. Sakurai, “One pixel attack for fooling deep
neural networks,” IEEE Transactions on Evolutionary Computation,
2019.

-10-50-10-50510n1=10-10-50-50510n1=10-10010-25-20-15-10-505n1=30-10010-25-20-15-10-505n1=300510-15-10-50n1=500510-15-10-5n1=50