Functional Tensors for Probabilistic Programming

Fritz Obermeyer 1 * Eli Bingham 1 * Martin Jankowiak 1 * Du Phan 1 Jonathan P. Chen 2 †

0
2
0
2

r
a

M
0
1

]
L
M

.
t
a
t
s
[

2
v
5
7
7
0
1
.
0
1
9
1
:
v
i
X
r
a

Abstract

It is a signiﬁcant challenge to design probabilis-
tic programming systems that can accommodate
a wide variety of inference strategies within a
uniﬁed framework. Noting that the versatility
of modern automatic differentiation frameworks
is based in large part on the unifying concept
of tensors, we describe a software abstraction
for integration—functional tensors—that captures
many of the beneﬁts of tensors, while also being
able to describe continuous probability distribu-
tions. Moreover, functional tensors are a natural
candidate for generalized variable elimination and
parallel-scan ﬁltering algorithms that enable par-
allel exact inference for a large family of tractable
modeling motifs. We demonstrate the versatility
of functional tensors by integrating them into the
modeling frontend and inference backend of the
Pyro programming language. In experiments we
show that the resulting framework enables a large
variety of inference strategies, including those
that mix exact and approximate inference.

1. Introduction

Probabilistic programming systems allow speciﬁcation of
probabilistic models in high-level programming languages
and provide automation of probabilistic inference (van de
Meent et al., 2018). It remains a signiﬁcant challenge to
design uniﬁed frameworks that can accommodate a wide
variety of exact and approximate inference strategies, in-
cluding message-passing, MCMC, and variational inference.
This work is motivated by the general goal of enabling
mixed inferences strategies for probabilistic programs. As a
concrete example consider an inference algorithm that com-
bines modern black-box variational inference with classic
algorithms that leverage conjugacy (e.g. Kalman ﬁlters). En-
abling the former requires support for Monte Carlo sampling
and automatic differentiation (AD), while the latter calls for

*Equal contribution . †Work done at Uber AI. 1Uber AI, San
Francisco, CA, USA 2Facebook, Menlo Park, CA, USA. Corre-
spondence to: Fritz Obermeyer <fritzo@uber.com>.

Preliminary work. Submitted to ICML 2020.

symbolic computation of sums (for discrete factors) and
integrals (for Gaussian factors). Recent work (Obermeyer
et al., 2019) exploits the algebraic properties of tensors
to support such mixed inference in discrete latent variable
models. We extend these ideas with functional tensors, a
software abstraction and embedded domain-speciﬁc lan-
guage for seminumerical automatic integration that serves
as an intermediate representation for a wide variety of mixed
inference strategies in probabilistic programming systems.

2. Functional tensors

Tensors, or more properly “multidimensional arrays,” are a
popular and versatile software abstraction for performing
parallelizable operations on homogeneous blocks of mem-
ory. Each tensor is backed by a single block of memory
addressable by a tuple of bounded integers, where each inte-
ger indexes into a dimension of the tensor. Tensor libraries
provide operations that act on tensors, including pointwise
operations like addition and multiplication, reduction oper-
ations such as product and sum, and combined operations
such as matrix multiplication and convolution. A impor-
tant property of tensor libraries is support for broadcasting,
whereby an operation deﬁned on smaller tensors or scalars
can be uniquely extended to an operation on tensors with ex-
tra dimensions on the left, so long as shapes are compatible
(Oliphant, 2006).

This property is extensively exploited by the Pyro proba-
bilistic programming language (Bingham et al., 2018) and
its implementation of tensor variable elimination for ex-
act inference in discrete latent variable models (Obermeyer
et al., 2019), in which each random variable in a model is
associated with a distinct tensor dimension and broadcasting
is used to compile a probabilistic program into a discrete
factor graph (Obermeyer et al., 2018).

Functional tensors (hereafter “funsors”) both formalize and
extend this seemingly idiosyncratic but highly successful
approach to probabilistic program compilation by general-
izing tensors and broadcasting to allow free variables of
non-integer types that appear in probabilistic models, such
as real number, real-valued vector, or real-valued matrix.
Building on this, we describe a simple language of lazy
funsor expressions that can serve as a uniﬁed intermediate
representation for a wide variety of probabilistic programs

 
 
 
 
 
 
Functional Tensors for Probabilistic Programming

and inference algorithms. While in general there is no ﬁnite
representation of functions of real variables, we provide a
funsor interface for restricted classes of functions,1 includ-
ing lazy algebraic expressions, non-normalized Gaussian
functions, and Dirac delta distributions. This restricted class
of funsors retains the important property of tensors that
an atomic funsor with n free variables is backed by O(1)
many blocks of memory, and operations on funsors can be
implemented by O(1) many parallel operations (e.g. GPU
kernels) on that memory.

In the remainder of this section, we overview funsor syntax
(Sec. 2.1), type judgements (Sec. 2.2), and operational se-
mantics (Sec. 2.3), including the atomic distribution funsors
Tensor, Gaussian, and Delta; we also include a complete
example (Fig. 1) and describe how inference algorithms may
be implemented as nonstandard interpretations (Sec. 2.4).

2.1. Funsor syntax

Funsors are terms in a ﬁrst order language of arrays and
array indices; we exclude higher order functions.

Deﬁnition 1. A type is deﬁned by the grammar

τ ∈ Type ::= Zn

“bounded integer”

(cid:12)
(cid:12) Zn1× · · · ×Znk → R “real-valued array”

for any n, n1, . . . , nk, k ∈ N. A type context is a set Γ =
(v1 :τ1, . . . , vk :τk) of name:type pairs for names v ∈ S
in a countable set of symbols S (e.g. strings). We write
real-valued array types as Rn1×···×nk and scalars R1 as R.

Note a type generalizes the size of a tensor dimension, and
a type context generalizes the shape of a tensor. A funsor
generalizes both tensors and lazy tensor expressions.

Deﬁnition 2. A funsor is deﬁned by the grammar

e ∈ Funsor ::= Tensor(Γ, w)
(cid:12)
(cid:12) Gaussian(Γ, i, Λ)
(cid:12)
(cid:12) Delta(v, e)
(cid:12)
(cid:12) Variable(v, τ )
(cid:12)
(cid:12) (cid:98)f (e1, . . . , en)
(cid:12)
(cid:12) e1[v (cid:55)→ e2]
(cid:12)
e
(cid:12)
(cid:12)
(cid:12) (cid:81)

(cid:80)
v

e

v

“discrete factor”

“Gaussian factor”

“point mass”

“delayed value”

“apply function”

“substitute”

“marginalize”

“plated product”

“component means”
“component index”

z ← Variable(z:R2×3)
c ← Variable(c:Z2)
j ← Variable(j :Z50)
pc ← Tensor((c:Z2), [0.5, 0.5])
pz ← Gaussian((z :R3), iz, Λz)
px|c,z ← Gaussian((c:Z2, z :R3, x:R3), ix, Λx)
px ← (cid:80)

pz[z (cid:55)→ z[[[ c ]]]]

“data index”

(cid:17)

(cid:80)
c

pc × px|c,z[z (cid:55)→ z[[[ c ]]], x (cid:55)→ (cid:98)x[[[ j ]]]]

z

(cid:16)(cid:81)
c
× (cid:81)
j

Figure 1: Example: computing marginal likelihood of Gaussian
mixture model over an N = 50 by D = 3 dataset x ∈ R50×3
written as a funsor term px: where tensors (iz ∈ R3, Λz ∈ R3×3)
deﬁne the shared prior over z; batched tensors (ix ∈ R2×6, Λx ∈
R2×6×6) deﬁne a conditional distribution of x|c, z; and z[[[ c ]]] =
(cid:100)take(z, c) and (cid:98)x[[[ i ]]] = (cid:100)take((cid:98)x, i) are shorthand for the lifted
indexing function take(-,-) ∈ Rn×k × Zn → Rk. See 2.1-2.3.

a type, and f is any function deﬁned on numerical objects,
e.g. binary multiplication × and constants 0 and 1.

2.2. Typing rules

Funsor expressions are typed according to the types of their
subexpressions and free variables.2 Deﬁnition 3 ﬁrst intro-
duces some notation used here and elsewhere in the paper.
Deﬁnition 3. The set of free variables of a funsor e is de-
noted fv(e). A funsor is open if it has free variables and
closed otherwise. Each basic numerical object x ∈ τ de-
ﬁnes a ground funsor (cid:98)x = Tensor((), x). To declare that Γ
is a type context for the free variables of a funsor f of type
τ , we write Γ (cid:96) f :τ . As sets, type contexts are unordered.3

Some terms may introduce or eliminate free vari-
ables.
the marginalization and plated
product funsor operations eliminate an input variable.4

For example,

Γ, v :τ (cid:96) e:Rs
Γ (cid:96) (cid:80)
e : Rs
v

Γ, v :τ (cid:96) e:Rs
Γ (cid:96) (cid:81)
e : Rs
v

Most other funsor operations, such as binary product ×,
simply aggregate the free variables of all of their arguments:

f ∈ τ1 × · · · × τn → τ0
· · ·

Γn (cid:96) en :τn

Γ1 (cid:96) e1 :τ1

where Γ is a type context, w, i, Λ are multidimensional
arrays of numerical data, v ∈ S is a variable name, τ ∈ T is

1Note that funsor expressions technically represent distribu-
tions in the functional analysis sense, since expressions containing
Delta terms are not proper functions of their free variables and are
only formally deﬁned via integration against test functions.

∪nΓn (cid:96) (cid:98)f (e1, . . . , en) : τ0

2See Appendix B.1 for complete list of typing rules.
3In our implementation, to ensure determinism and repro-
ducibility we ﬁx a canonical order based on orders of subexpres-
sions, but this does not affect our semantics.

4We sometimes overload this notation to multiple variables

Functional Tensors for Probabilistic Programming

2.3. Operational semantics

Funsor computations are executed by seminumerical term
rewriting. We specify an interpretation in the form of a
complete set of patterns and rewrite rules5 for every term in
the language 2 and rely on a dispatch mechanism to match
and execute rules until termination (Carette et al., 2009),
using types to ensure rewrites are valid. Rewrites include
both symbolic term rewriting (including reﬂection, in which
an expression is rewritten to a lazy version of itself) and
low-level numerical computation, similar to AD systems.

The low-level numerical computations are performed in
rewrite rules that manipulate distribution funsors, which
are the basic latent factors in sum-product expressions con-
structed during probabilistic inference. We focus attention
on three special distributions that are jointly closed under
products and marginalization,6 and thus especially attractive
as representations of latent variable models. These three
funsors are: i) Tensor funsors to represent discrete joint
probability mass functions; ii) Gaussian funsors to repre-
sent joint multivariate normal distributions among sets of
real-tensor valued variables, possibly dependent on other
discrete variables; and iii) Delta funsors to represent degen-
erate distributions and Monte Carlo samples.

2.3.1. TENSOR

Tensor funsors represent a non-normalized mass function as
a single tensor (multidimensional array) of weights. Mem-
ory cost and computation cost are both exponential in the
number of free variables. The crucial rewrite rule for Tensor
funsors allows operations (cid:98)f (e1, . . . , en) on Tensor funsors
e1, . . . , en to be eagerly evaluated even in the presence of
free variables; this is especially useful when e.g. f is a neu-
ral network whose inputs depend on lazily sampled discrete
random variables:

(cid:98)f (Tensor(Γ1, w1), . . . , Tensor(Γn, wn)) ⇒

Tensor(∪kΓk, f (w1, . . . , wn))

This rule admits an efﬁcient and general implementation
when using a modern tensor library like PyTorch as a back-
end, since all of their ops natively support broadcasting.

2.3.2. GAUSSIAN

Gaussian funsors represent a Gaussian density function
among multiple real-array-valued free variables. using
the information form of the Kalman ﬁlter (Anderson and
Moore, 1979; Bar-Shalom and Li, 1995), i.e. as pair (i, Λ),
where i = Λµ is the information vector, µ is the mean,

5See Appendix B.2 for a partial list of rewrite rules.
6The EXACT interpretation disallows marginalizing over Gaus-
sian mixture components; the approximate MOMENTMATCHING
interpretation allows arbitrary marginalization.

and Λ = Σ−1 is the precision matrix, the inverse of the
covariance matrix Σ. The information form is useful in in-
formation fusion problems because it allows representation
of rank-deﬁcient joint distributions, such as a conditional
distribution treated as a single Gaussian factor. We imple-
ment marginalization via Cholesky decomposition in the
usual way, thus restricting marginalization to variables with
full-rank precision matrices. Binary and plated products of
Gaussian funsors correspond to Bayesian fusion in which
the information vectors and precision matrices are added:

Gaussian(Γ1, i1, Λ1) × Gaussian(Γ2, i2, Λ2) ⇒

Gaussian(Γ1 ∪ Γ2, i1 + i2, Λ1 + Λ2)

where the underlying numerical arrays ik, Λk have been
aligned correctly based on the information in the type con-
texts and operations on them like + broadcast.7 Gaussians
are canonicalized to map the zero vector to zero log den-
sity. Normalized Gaussian densities are represented as lazy
products of a Tensor funsor (for the normalization constant)
and a Gaussian funsor (for geometry), so while Gaussian
funsors are not closed under marginalization, products of
Tensor and Gaussian funsors are. Memory cost is quadratic
and computation cost is cubic in the total number of ele-
ments in all free real-tensor-valued variables; both costs are
exponential in the number of bounded integer free variables.

2.3.3. DELTA

Gaussian and Tensor funsors are jointly closed under
marginalization and products, but they can only represent
a limited set of probability distributions over real variables.
Rather than adding other non-Gaussian real-valued density
terms to our language, none of which have such favorable
algebraic properties, we introduce a representation of em-
pirical distributions, so that even analytically intractable
joint distributions can be represented approximately. Delta
funsors represent a point distribution as a pair of numerical
arrays (v, x), where v is a symbol and x is a Tensor fun-
sor, possibly with free discrete variables corresponding to
batch dimensions. The crucial rewrite rule for Delta funsors
triggers substitution in binary products: if v ∈ fv(e2),

Delta(v, e1) × e2 ⇒ Delta(v, e1) × e2[v (cid:55)→ e1]

Delta funsors are normalized to integrate to 1: if v /∈ fv(e3)
(for example, as is the case after applying the previous rule),

(cid:80)
v

Delta(v, e1) × e3 ⇒ e3

We can combine these two rules with the Tensor
broadcasting rule to represent Monte Carlo expectations
(cid:80)
v Delta(v, e) × (cid:98)f (Variable(v :R)) for arbitrary f , signif-

icantly expanding the expressiveness of the language.

7See Appendix B for details on atomic term data handling

Functional Tensors for Probabilistic Programming

Memory and computational costs for a product of Deltas
are linear in the number of terms in the product.

2.4. Approximation with nonstandard interpretation

Tensors, Gaussians, and Deltas are algebraically closed in
combination, i.e. any sum-product of Tensor, Gaussian, and
Delta factors can be rewritten6 to a product of zero or more
Deltas, an optional Tensor, and an optional Gaussian. Our
rewrite system captures this fact as a normal form funsor8
representing a lazy ﬁnitary product, together with rules for
commutativity, associativity, distributivity, and substitution.

This closure property makes it possible to specify and com-
pose program transformations as nonstandard interpretations
(Carette et al., 2009). Each interpretation is a set of rewrite
rules that conform to the typing rules in this section and
the appendix, and users can choose and interleave interpre-
tations at runtime. For example an EXACT interpretation
eagerly evaluates tractable funsors but leaves non-analytic
integrals lazy, a fully LAZY interpretation records an ex-
pression for optimization and static analysis, and an OP-
TIMIZE interpretation (discussed in Sec. 4.1) implements
variable elimination by using distributivity to rewrite lazy
sum-product funsor expressions. Most interpretations build
on EXACT and LAZY, sharing all of their rewrite rules ex-
cept for a small number of new or modiﬁed rules.

Program transformations are especially important in our
language because, unlike typical tensor operations in AD
libraries, some funsor expressions may be non-analytic or
computationally intractable, in which case they can only be
evaluated approximately. We can express and compose even
these non-semantics-preserving transformations as interpre-
tations, provided they preserve this closure property; for
example, MONTECARLO and MOMENTMATCHING inter-
pretations (discussed in Secs. 4.5 and 4.4 respectively) add
extra rules for approximate integration through nonstandard
interpretations of atomic funsors and marginalization opera-
tions. As we will see, the hierarchy of computational com-
plexity in the three distribution funsors makes this language
a natural substrate for approximations where intractable
exact terms are rewritten to tractable approximate terms.

3. An intermediate language for probabilistic

programming

Probabilistic programming languages like Pyro extend
general-purpose languages with two new primitives for rep-
resenting probabilistic models as programs, a sample state-
ment for sampling random variables and an observe state-
ment for conditioning program executions on data. Funsors
ﬁll two roles in probabilistic programming: as representa-

8See Appendix B.2 for details.

tions of lazy tensor expressions in user-facing model code
generated by nonstandard interpretation of sample state-
ments to return Variable funsors, and as representations
of joint distributions as products of factors in automatic
inference strategies. We demonstrate these roles in two
probabilistic inference tasks, shown in Figs. 2 and 3.9

Note that Figs. 2-3 use Gaussian factors for concreteness
but if we change the factors to Tensors we can reuse the
same modeling code, and the inference backend compiles to
the same funsor code except for the atomic terms, demon-
strating the strength of the language for building reusable
inference components. For example, the sample state-
ments return lazy values by default, but by interleaving the
EXACT and LAZY interpretations we can easily implement a
sophisticated inference strategy like delayed sampling (Mur-
ray et al., 2017) in which fragments of a program are lazily
evaluated, marginalized with variable elimination and used
as low-variance proposal distributions in a particle ﬁlter.

We also remark that the simplicity of this design comes with
other tradeoffs; our language as described only supports
a limited subset of probabilistic programs, ﬁlling a niche
analogous to that of the intermediate expression languages
in popular trace-based automatic differentiation systems
like PyTorch (Paszke et al., 2017), in which the class of
differentiable programs in the host language is restricted.

4. Algorithms employing funsors

We now describe several algorithms for performing exact
and approximate inference, implemented as syntax exten-
sions or nonstandard interpretations for our term language.
None of these algorithms is novel in isolation, but they
demonstrate the utility of our language’s closure properties
and its suitability for building extensible, general-purpose
inference tools. All interpretations are detailed in App. B.

4.1. Funsor variable elimination

Variable elimination is a dynamic programming algorithm
for performing exact inference efﬁciently by exploiting con-
ditional independence to distribute sums inside of products.
To perform variable elimination with funsors, we record
a lazy funsor sum-product expression with the LAZY in-
terpretation, rewrite the expression with an OPTIMIZE in-
terpretation using a standard library for tensor contraction
(Smith and Gray, 2018), and evaluate the optimized expres-
sion with the EXACT interpretation. We further implement
plated variable elimination following the algorithm of (Ober-
meyer et al., 2019) nearly verbatim, but generalizing from
discrete to arbitrary free variable types because the OPTI-
MIZE interpretation is agnostic to the atomic term types.

9See Appendix C for detailed walkthrough of these examples

Functional Tensors for Probabilistic Programming

1
2
3
4
5

fun GenerativeModel(x)

z ← sample(Gaussian((v :R), iz, Λz))
y ← exp(z)
observe(Gaussian((v :R, θ :R), ix, Λx)[θ (cid:55)→ y], x)

end

p ← 1
p ← p × Gaussian((v :R), iz, Λz)[v (cid:55)→ Variable(z :R)]

p ← p × Gaussian((v :R, θ :R), ix, Λx)[θ (cid:55)→ y, v (cid:55)→ x]
Maximize over ix, Λx, iz, Λz: (cid:80)

p

z

Figure 2: User-facing probabilistic program (left) and automatic inference (right) for maximum marginal likelihood inference. sample
and observe statements multiply the joint probability by their input funsor; sample statements also return Variables for lazy evaluation.

1
2
3
4
5
6
7

fun GenerativeModel(x)

z ← sample(Gaussian((v :R), iz, Λz))
observe(Gaussian((v :R, θ :R), ix, Λx)[θ (cid:55)→ z], x)

p ← 1
p ← p × Gaussian((v :R), iz, Λz)[v (cid:55)→ Variable(z :R)]
p ← p × Gaussian((v :R, θ :R), ix, Λx)[v (cid:55)→ x, θ (cid:55)→ z]

end
fun InferenceModel(x)

z ← sample(Gaussian((v :R, θ :R), iq, Λq)[θ (cid:55)→ x])

end

q ← 1
q ← q × Gaussian((v :R, θ :R), iq, Λq)[v (cid:55)→ z, θ (cid:55)→ x]
Maximize over iq, Λq: (cid:80)

q log p
q

z

Figure 3: User-facing probabilistic program (left) and automatic inference (right) for variational inference with delayed sampling;
sample and observe statements behave as in Fig. 2. The argument x is a Tensor funsor of observations. The quantity maximized is
the ELBO, demonstrating that other computations in approximate inference are easy to express using our marginalization term.

4.2. Parallel-scan Bayesian ﬁltering

Parallel-scan Bayesian ﬁltering (Särkkä and García-
Fernández, 2019) offers an exponential speedup of sequen-
tially structured variable elimination problems on parallel
hardware such as GPUs. We provide a general implemen-
tation of this class of algorithms that integrates seamlessly
with the variable elimination machinery of the previous
section, ﬁrst adding new syntax for a generalized “Markov
product” operation, and then implementing a parallel-scan
rewrite rule in the EXACT interpretation for this operation.
This Markov product operation and rule cover familiar cases
including Hidden Markov Models (as Markov products of
Tensors) and Kalman ﬁltering (as inference in Markov prod-
ucts of Gaussians); however the general syntax supports
ﬁltering in arbitrarily complex sequential models. More-
over, the implementation consists of a series of batched
products, marginalizations and substitutions, making it auto-
matically compatible with other interpretations that modify
those rewrite rules. See Appendix A for details.

4.3. Alternate semirings

The previous two sections describe how funsors enable high-
performance, concise, model-agnostic implementations of
parallel variable elimination algorithms that immediately
generalize to new atomic term types. In fact, while variable
elimination in its most well-known form computes marginal
likelihoods, the same generic algorithm can be applied to
many other problems by replacing the (sum, product) oper-

ations with different semirings (Kohlas and Wilson, 2008;
Belle and De Raedt, 2016; Khamis et al., 2016), such as
(max,product) for computing MAP (maximum a posteriori)
estimates. We exploit this fact to make our implementations
immediately reusable for these other computational tasks,
relying on nonstandard interpretation of the marginalization
and binary and plated product operations.

4.4. Moment matching approximation

Variable elimination provides a tractable exact inference
algorithm in structured probabilistic models with either all
discrete or all Gaussian factors. However exact inference
becomes exponentially expensive in models combining both
discrete and Gaussian factors, e.g. the switching linear dy-
namical system in Sec. 6.3.

To enable tractable inference in structured probabilistic mod-
els combining discrete and Gaussian factors, we implement
an approximate moment matching interpretation generaliz-
ing Interacting Multiple Model (IMM) ﬁlters (Mazor et al.,
1998) and similar to expectation propagation (Minka, 2001).
This interpretation adds a new rewrite rule whereby a Gaus-
sian mixture is approximated by a single joint Gaussian of
matching normalizer, mean, and covariance:

(cid:80)
v

Tensor(Γ1, w) × Gaussian(Γ2, i, Λ) ⇒

Gaussian(Γ2 − (v :τ ), i(cid:48), Λ(cid:48)) × (cid:80)

Tensor(Γ1, w(cid:48))

v

Functional Tensors for Probabilistic Programming

where i(cid:48), Λ(cid:48), and w(cid:48) are computed to match moments of
the original expression. For example, in the simplest case
of a discrete mixture of Gaussian factors indexed by k and
with weights wk this rewrite rule results in a Gaussian with
mean and covariance given by

µ(cid:48) =

Σ(cid:48) =

(cid:88)

k
(cid:88)

k

wkµk = Λ(cid:48)−1i(cid:48)

wkΣk +

(cid:88)

k

wk(µ(cid:48) − µk)(µ(cid:48) − µk)T = Λ(cid:48)−1

4.5. Differentiable Monte Carlo approximation

Above we have described a variety of funsor algorithms that
can be used to exactly compute or approximate marginal
likelihoods, variational objectives, and other key quanti-
ties in Bayesian inference. We can combine these with
a MONTECARLO interpretation that approximates some
Tensor or Gaussian funsors in a computationally or analyt-
ically intractable part of a larger sum-product expression
with Monte Carlo samples in Delta funsors, while preserv-
ing the tractable parts of the expression for exact compu-
tation. Importantly, by carefully designing rewrite rules
using reparametrized samplers (Kingma and Welling, 2013)
and DiCE factors (Foerster et al., 2018) where appropriate,
we ensure that the MONTECARLO interpretation preserves
differentiability to all orders; see Appendix B.3 for details.

5. Related work

Murray et al. (2017) introduce delayed sampling, a pro-
grammatic approach to structured Rao-Blackwellization that
combines eager and lazy sampling. Obermeyer et al. (2019)
generalize discrete variable elimination to factor graphs with
plates, enabling fast inference on parallel hardware. Our
work combines these approaches, extending vectorized and
mixed eager/lazy inference to continuous models and for-
malizing the resulting expressions as open terms, i.e. terms
with free variables (Barendregt et al., 2013).

PSI Solver (Gehr et al., 2016) and Hakaru (Narayanan et al.,
2016; Carette and Shan, 2016) use symbolic algebra sys-
tems to perform exact inference on all or part of a proba-
bilistic model. Our work can be seen as a mixed symbolic-
numerical approach that provides limited symbolic pattern
manipulation and relies on a high-level tensor library (Py-
Torch (Paszke et al., 2017)) for automatic differentiation
and parallelization. Indeed we see functional tensors as a
compromise between fully symbolic and fully numerical
integration in the same way that automatic differentiation
is a compromise between symbolic differentiation and nu-
merical differentiation (Baydin et al., 2018). Bradbury et al.
(2018) describe a system of a ﬁrst-order intermediate lan-
guage on which machine learning program transformations
are expressed as ﬁnal-style interpreters (Carette et al., 2009),

with a focus on advanced automatic differentiation and hard-
ware acceleration.

Dillon et al. (2017) describe a low-level software abstrac-
tion for implementing probability distributions, in particular
taking care to implement batching and broadcasting. Our
work can be seen as generalization of such distributions
in three directions: from broadcastable dimensions to free
variables, from normalized to unnormalized, and from sin-
gle distributions to joint distributions (still with O(1) many
underlying tensors). Hoffman (2018) design a system for
automatic conjugacy detection in computation graphs; our
system matches coarser patterns, e.g. Gaussians rather than
polynomials.

Särkkä and García-Fernández (2019) adapts parallel-scan
algorithms to Bayesian ﬁltering settings, demonstrating ex-
ponential parallel speedup for inference in discrete HMMs
and Kalman ﬁlters. Baudart et al. (2019) develop a model-
ing language for sequential probabilistic models together
with linear-time bounded memory inference algorithms. We
generalize parallel-scan inference to a modeling language
wider than (Särkkä and García-Fernández, 2019) but more
restrictive than (Baudart et al., 2019).

6. Experiments

To evaluate the versatility of funsors in probabilistic pro-
gramming, we perform inference on a variety of probabilis-
tic models using the algorithms from Sec. 4. We include
models in which inference can be done exactly (Sec. 6.1-
6.2) as well as models for which inference is intractable but
where approximate inference algorithms can beneﬁt from
funsor computations of tractable subproblems (Sec. 6.3-6.4),
excercising compositions of the individual pieces of Sec. 4.

6.1. Discrete factor graphs

Hidden Markov models (HMMs) are widely used to analyze
animal behavioral data due to their interpretable nature and
the availability of efﬁcient exact inference algorithms (Zuc-
chini et al., 2016; McClintock and Michelot, 2018). Here
we reproduce one such application, the model selection anal-
ysis in (McClintock et al., 2013) of GPS movement data
from a colony of harbor seals in the United Kingdom.

Using our parallel scan algorithms for marginal likelihood
computation, we ﬁt four variants of a hierarchical HMM
with no random effects (No RE), sex-level discrete ran-
dom effects (Group RE), individual-level discrete random
effects (Individual RE), and both types of random ef-
fects (Individual+Group RE). We describe the mod-
els, dataset, and training procedure in Appendix D.1.

We report AIC scores for the four model variants in Table
1. As in the original analysis (McClintock et al., 2013),

Functional Tensors for Probabilistic Programming

Model
No RE
Individual RE
Group RE
Individual+Group RE

AIC
299.3 × 103
288.2 × 103
288.8 × 103
288.0 × 103

TVE time (s)
3.21
3.54
3.70
4.01

FVE time (s)
0.033
0.033
0.042
0.052

· · ·

zt−1

· · ·

xt−1

zt

xt

β

· · ·

· · ·

S

Table 1: AIC scores and wall clock time to compute marginal like-
lihood and gradients of all parameters using parallel-scan funsor
variable elimination (FVE) and sequential tensor variable elimina-
tion (TVE) as in Obermeyer et al. (2019). See Sec. 6.1.

Figure 5: Graphical structure of the continuous state space model
in Sec. 6.2. z are latent states, x are observations, and β is the
persistent sensor bias.

Figure 4: Time to compute marginal likelihood and gradients
of all parameters with funsor variable elimination in a simpliﬁed
version of model Individual RE on fake seal data extended
in time. See Appendix D.2 for details.

our results support the inference that there is behavioral
variation across individuals that is unexplained either by sex
or the available covariates. The times in Table 1 show that
our parallel-scan implementation (Sec. 4.2) is more than two
orders of magnitude faster than tensor variable elimination
(Obermeyer et al., 2019) for this class of models. Figure
4 shows that it achieves the expected logarithmic scaling
for series > 10× longer than the harbor seal tracks. See
Appendix D.2 for details and more scaling experiments.

6.2. Kalman ﬁlters with global latents

Consider a 2-D tracking problem where an object is ob-
served for T time steps by S = 5 synchronized sensors
that introduce both iid noise and unknown persistent bias.
Suppose the object follows nearly-constant-velocity (linear-
Gaussian) dynamics and observations, but that the scales of
the process/observation noise and bias are unknown.

Neglecting bias, we could naively perform inference via
differentiable Kalman ﬁltering and optimize noise scales to
maximize marginal likelihood. To account for bias we add a
persistent Gaussian random variable, as shown in Fig. 5. We
exactly marginalize out the bias latent states, then optimize
noise scales using gradient descent, leading to more accurate
position estimates as in Figure 6. See Sec. D.3 for details.

Figure 6: Position error of the ﬁnal state estimate for the autotun-
ing Gaussian state space ﬁlter of Sec. 6.2 neglecting bias (dashed
black) and modeling bias (solid red).

is both a discrete switching label st ∈ [1, ..., K] and a con-
tinuous latent state xt; both follow Markovian dynamics,
see Fig. 8. We consider three model variants: I) the tran-
sition probabilities p(xt|xt−1, st) depend on the switching
state; II) the emission probabilities p(yt|xt, st) depend on
the switching state; and III) both the transition and emission
probabilities depend on the switching state. See Sec. D.4 in
the supplementary materials for details.

Exact inference for this class of models is O(K T ). To
make inference tractable, we use a moment-matching ap-
proximation with window length L, reducing the complex-
ity to O(K L+1). Representing this approximate inference
algorithm follows immediately by employing a MOMENT-
MATCHING interpretation for funsor reductions.10 For pa-
rameter learning we use gradient ascent on the (approx-
imate) log marginal likelihood log p(y1:T ). See Table 2
for the results we obtain for all three model variants with
K = 2 switching states and window lengths L ∈ {1, 3, 5}.
We obtain the best results with the richest model (SLDS-III),
with the most expensive moment-matching approximation
(L = 5) yielding the lowest mean squared error. In Fig. 7
we depict smoothing estimates for the training data and one-
step-ahead predictions for the held-out data using the best
performing model, validating the efﬁcacy of the moment-
matching approximation.

6.4. Neural variational Kalman ﬁlter

6.3. Switching linear dynamical system

We use a switching linear dynamical system (SLDS) (Ack-
erson and Fu, 1970) to model an EEG time series dataset
{yt}T
t=1 from the UCI database (Dua and Graff, 2017). The
generative model is as follows. At each time step t there

We model a high-dimensional count-valued time series by
combining exact computations with variational inference.
The data we consider are hourly ridership counts for every
pair of 47 stations in a metropolitan transit system, totalling

10See Ex. 21 in the appendix for example funsor code.

010000200003000040000500006000070000Max time series length in fake extended dataset0.000.050.100.15Wall clock time (s)Model: Individual REMax series length in actual seal dataset51015202530Track Length2.22.42.6Position RMSEFunctional Tensors for Probabilistic Programming

L = 1

L = 3

L = 5

z0

z1

· · ·

zT

Model
SLDS-I
SLDS-II
SLDS-III

MSE
0.574
0.527
0.512

LL
-10.13
-9.55
-9.33

MSE
0.574
0.497
0.511

LL
-10.13
-9.64
-9.41

MSE
0.574
0.498
0.482

LL
-10.13
-9.64
-9.46

p1

g1

λ1

c1

· · ·

pT

gT

· · ·

λT

cT

pt

λt

ct

T

Table 2: One-step-ahead test log likelihoods and mean squared
errors for SLDS variants with various moment-matching window
lengths L. See Sec. 6.3 for details.

Figure 9: Graphical structure of the generative model (left) and
collapsed variational inference model (right) for ridership fore-
casting. Grey nodes are observed, solid white nodes are sampled
via stochastic variational inference, and dashed white nodes are
exactly marginalized out.

Inference
Latent dim
MAE
CRPS

Mean Field
4
2.35
1.76

2
2.39
1.78

8
2.33
1.74

Collapsed-MC
4
2
8
2.76
2.59
2.65
2.06
1.93
1.95

Figure 7: Smoothing estimates (red) and one-step-ahead predic-
tions (blue; with 90% conﬁdence intervals) for three randomly
selected output dimensions (y1, y5, y11) for the SLDS experiment
in 6.3. The bottom ﬁgure depicts the observed eye state (black) as
well as the smoothing estimate of the inferred switching label st
(red). Note that the eye state was unobserved during training.

· · ·

st−1

st

st+1

· · ·

· · ·

xt−1

xt

xt+1

· · ·

Table 3: Mean Absolute Error and mean Continouous Ranked
Probability Score (Gneiting and Raftery, 2007) of 1-week forecasts
based on two inference strategies for a state space model with
varying latent state dimension.

counts c, independently predicts fully independent normal
distributions over p and λ, and exactly marginalizes z using
the parallel-scan Markov product Alg. 1. In both strategies
we jointly train the generative model and inference model
using stochastic variational inference on 2-week long mini-
batches of data. We then condition on the ﬁnal 2 weeks and
predict forward 1 week. Table 3 shows forecast accuracy.
See Appendix D.5 for details.

· · ·

yt−1

yt

yt+1

· · ·

7. Conclusion

Figure 8: Graphical structure for the SLDS-III model in Sec. 6.3.
The {st} form a chain of discrete switching states and the {xt} are
continuous. Here the transition probabilities p(xt|xt−1, st) and
emission probabilities p(yt|xt, st) both depend on the switching
label st.

over 78M nonzero observations (BART, 2019). Our genera-
tive model consists of a low-dimensional (dim ∈ {2, 4, 8})
linear state space model with high-dimensional (one di-
mension per origin-destination pair) zero-inﬂated Poisson
observations that depend non-linearly (via a neural network)
on the low-dimensional latent state, the hour of week, and
a boolean vector encoding whether each station is open or
closed (see Fig. 9).

We consider two inference strategies combining amortized
variational inference with exact marginalization. The ﬁrst
“mean ﬁeld” strategy inputs a block of observed counts c1:T
and predicts fully independent normal distributions over
latent gate probability p1:T , Poisson rate λ1:T , and state
z1:T ; the gate variable g1:T is marginalized out. The second
“collapsed” strategy inputs a single timestep of observed

We introduced funsors, a software abstraction that general-
izes tensors to provide ﬁnite representations for a restricted
class of discrete and continuous distributions, including lazy
algebraic expressions, non-normalized Gaussian distribu-
tions, and Dirac delta distributions. We demonstrated how
funsors can be integrated into a probabilistic programming
system, enabling a wide variety of inference strategies. Fi-
nally, we have implemented funsors and funsor algorithms
as a Python library built on PyTorch, with source code avail-
able at https://github.com/pyro-ppl/funsor.

In future work, we could follow AD systems in increasing
our term language’s expressivity by adding simple control
ﬂow constructs like loops, branching or ﬁxpoints, and with
basic union/pair types to represent custom data structures.
We could also expand the class of inference algorithms
represented in our formalism by adding interpreters that
approximate other operations. For example, just as our
MOMENTMATCHING interpreter approximates the “sum”
operation, we could naturally represent other algorithms
like mini-bucket elimination (Dechter, 1997) or one step of
loopy belief propagation by also approximating the binary
“product” operation that constructs full joint distributions.

505y1010y5010y11020406080100120Time (s)0.00.51.0Eye stateFunctional Tensors for Probabilistic Programming

References

G Ackerson and K Fu. On state estimation in switching
environments. IEEE transactions on automatic control,
15(1):10–17, 1970.

Brian Anderson and John B Moore. Optimal ﬁltering.

Prentice-Hall, 1979.

Yaakov Bar-Shalom and Xiao-Rong Li. Multitarget-
multisensor tracking: principles and techniques, vol-
ume 19. YBs Storrs, CT, 1995.

Henk Barendregt, Wil Dekkers, and Richard Statman.
Lambda calculus with types. Cambridge University Press,
2013.

BART.

Bay Area Rapid Transit: Ridership reports.

https://www.bart.gov/about/reports/
ridership, 2019.

Guillaume Baudart, Louis Mandel, Eric Atkinson, Ben-
jamin Sherman, Marc Pouzet, and Michael Carbin.
arXiv preprint
Reactive probabilistic programming.
arXiv:1989.07563, 2019.

Atilim Gunes Baydin, Barak A Pearlmutter, Alexey An-
dreyevich Radul, and Jeffrey Mark Siskind. Automatic
differentiation in machine learning: a survey. Journal of
machine learning research, 18(153), 2018.

Vaishak Belle and Luc De Raedt. Semiring programming:
A framework for search, inference and learning. arXiv
preprint arXiv:1609.06954, 2016.

Eli Bingham, Jonathan P. Chen, Martin Jankowiak, Fritz
Obermeyer, Neeraj Pradhan, Theofanis Karaletsos, Rohit
Singh, Paul Szerlip, Paul Horsfall, and Noah D. Goodman.
Pyro: Deep Universal Probabilistic Programming. arXiv
preprint arXiv:1810.09538, 2018.

Roy

James Bradbury,

Frostig,

Peter Hawkins,
Matthew James Johnson, Chris Leary, Dougal Maclaurin,
and Skye Wanderman-Milne. JAX: composable trans-
formations of Python+NumPy programs, 2018. URL
http://github.com/google/jax.

Jacques Carette and Chung-chieh Shan. Simplifying prob-
abilistic programs using computer algebra. In Interna-
tional Symposium on Practical Aspects of Declarative
Languages, pages 135–152. Springer, 2016.

Jacques Carette, Oleg Kiselyov, and Chung-chieh Shan.
Finally tagless, partially evaluated: Tagless staged inter-
preters for simpler typed languages. Journal of Func-
tional Programming, 19(5):509–543, 2009.

Rina Dechter. Mini-buckets: A general scheme for gener-
ating approximations in automated reasoning. In IJCAI,
volume 97, pages 1297–1303. Citeseer, 1997.

Joshua V Dillon, Ian Langmore, Dustin Tran, Eugene
Brevdo, Srinivas Vasudevan, Dave Moore, Brian Patton,
Alex Alemi, Matt Hoffman, and Rif A Saurous. Ten-
sorﬂow distributions. arXiv preprint arXiv:1711.10604,
2017.

Dheeru Dua and Casey Graff. UCI machine learning
repository, 2017. URL http://archive.ics.uci.
edu/ml.

Jakob Foerster, Gregory Farquhar, Maruan Al-Shedivat, Tim
Rocktäschel, Eric P Xing, and Shimon Whiteson. Dice:
The inﬁnitely differentiable monte-carlo estimator. arXiv
preprint arXiv:1802.05098, 2018.

Timon Gehr, Sasa Misailovic, and Martin Vechev. Psi:
Exact symbolic inference for probabilistic programs. In
International Conference on Computer Aided Veriﬁcation,
pages 62–83. Springer, 2016.

Tilmann Gneiting and Adrian E Raftery. Strictly proper scor-
ing rules, prediction, and estimation. Journal of the Amer-
ican Statistical Association, 102(477):359–378, 2007.

Matthew D Hoffman. Autoconj: recognizing and exploiting
conjugacy without a domain-speciﬁc language. In Ad-
vances in Neural Information Processing Systems, pages
10716–10726, 2018.

Mahmoud Abo Khamis, Hung Q Ngo, and Atri Rudra. Faq:
questions asked frequently. In Proceedings of the 35th
ACM SIGMOD-SIGACT-SIGAI Symposium on Principles
of Database Systems, pages 13–28. ACM, 2016.

Diederik P Kingma and Jimmy Ba. Adam: A method for
stochastic optimization. arXiv preprint arXiv:1412.6980,
2014.

Diederik P Kingma and Max Welling. Auto-encoding varia-
tional bayes. arXiv preprint arXiv:1312.6114, 2013.

Juerg Kohlas and Nic Wilson. Semiring induced valua-
tion algebras: Exact and approximate local computation
algorithms. Artiﬁcial Intelligence, 172(11):1360–1399,
2008.

Eﬁm Mazor, Amir Averbuch, Yakov Bar-Shalom, and
Joshua Dayan. Interacting multiple model methods in tar-
get tracking: a survey. IEEE Transactions on aerospace
and electronic systems, 34(1):103–123, 1998.

Brett T. McClintock and ThÃl’o Michelot. momentuhmm:
R package for generalized hidden markov models of ani-
mal movement. Methods in Ecology and Evolution, 9(6):
1518–1530, 2018. doi: 10.1111/2041-210X.12995.

Brett T McClintock, Deborah JF Russell, Jason Matthiopou-
los, and Ruth King. Combining individual animal

Functional Tensors for Probabilistic Programming

John Schulman, Nicolas Heess, Theophane Weber, and
Pieter Abbeel. Gradient estimation using stochastic com-
putation graphs. In Advances in Neural Information Pro-
cessing Systems, pages 3528–3536, 2015.

Daniel G. A. Smith and Johnnie Gray. opt_einsum -
a python package for optimizing contraction order for
einsum-like expressions. Journal of Open Source Soft-
ware, 3(26):753, 2018. URL https://doi.org/10.
21105/joss.00753.

Jan-Willem van de Meent, Brooks Paige, Hongseok Yang,
and Frank Wood. An introduction to probabilistic pro-
gramming. arXiv preprint arXiv:1809.10756, 2018.

Walter Zucchini, Iain L MacDonald, and Roland Langrock.
Hidden Markov models for time series: an introduction
using R. Chapman and Hall/CRC, 2016.

movement and ancillary biotelemetry data to investigate
population-level activity budgets. Ecology, 94(4):838–
849, 2013.

Thomas P Minka. Expectation propagation for approximate
bayesian inference. In Proceedings of the Seventeenth
conference on Uncertainty in artiﬁcial intelligence, pages
362–369. Morgan Kaufmann Publishers Inc., 2001.

Lawrence M Murray, Daniel Lundén, Jan Kudlicka, David
Broman, and Thomas B Schön. Delayed sampling and
automatic rao-blackwellization of probabilistic programs.
arXiv preprint arXiv:1708.07787, 2017.

Praveen Narayanan, Jacques Carette, Wren Romano, Chung-
chieh Shan, and Robert Zinkov. Probabilistic infer-
ence by program transformation in hakaru (system de-
scription). In International Symposium on Functional
and Logic Programming - 13th International Sympo-
sium, FLOPS 2016, Kochi, Japan, March 4-6, 2016, Pro-
ceedings, pages 62–79. Springer, 2016. doi: 10.1007/
978-3-319-29604-3_5. URL http://dx.doi.org/
10.1007/978-3-319-29604-3_5.

Fritz Obermeyer, Eli Bingham, Martin Jankowiak, Neeraj
Pradhan, and Noah Goodman. Automated enumeration of
discrete latent variables. In The International Conference
on Probabilistic Programming (PROBPROG), 2018.

Fritz Obermeyer, Eli Bingham, Martin Jankowiak, Neeraj
Pradhan, Justin Chiu, Alexander Rush, and Noah Good-
man. Tensor variable elimination for plated factor graphs.
In International Conference on Machine Learning, pages
4871–4880, 2019.

Travis E Oliphant. A guide to NumPy, volume 1. Trelgol

Publishing USA, 2006.

Adam Paszke, Sam Gross, Soumith Chintala, Gregory
Chanan, Edward Yang, Zachary DeVito, Zeming Lin,
Alban Desmaison, Luca Antiga, and Adam Lerer. Auto-
matic differentiation in pytorch. In NIPS-W, 2017.

Rajesh Ranganath, Sean Gerrish, and David Blei. Black
box variational inference. In Artiﬁcial Intelligence and
Statistics, pages 814–822, 2014.

Danilo Jimenez Rezende, Shakir Mohamed, and Daan
Wierstra. Stochastic backpropagation and approximate
inference in deep generative models. arXiv preprint
arXiv:1401.4082, 2014.

Simo Särkkä and Ángel F García-Fernández. Temporal
parallelization of bayesian ﬁlters and smoothers. arXiv
preprint arXiv:1905.13002, 2019.

Functional Tensors for Probabilistic Programming

A. A Markov product operation

Plates and Markov chains are ubiquitous motifs in struc-
tured probabilistic modeling. We deﬁne a basic operation
that uniﬁes pointwise products over plates, chained matrix
multiplication, and Bayesian ﬁltering. The Markov product
generalize the usual plated product, with syntax given by

e ∈ Funsor ::= . . . (cid:12)
(cid:12)

(cid:81)

e

v/s

“Markov product”

and semantics given by the following deﬁnition:

Deﬁnition 4. Let f be a funsor with output type τ =
R, let t : ZT be a free variable over T ≥ 1 “time
steps”, and let s ⊆ fv(f ) × fv(f ) be a partial “time
step” matching among the free variables of f such
(i) t does not appear in s; (ii) s is one-to-one,
that:
i.e. |{u | (u, v) ∈ s} ∪ {v | (u, v) ∈ s}| = 2|s|; and (ii) for
every pair (u, v) ∈ s, u and v are identically typed in con-
text Γ. We deﬁne the Markov product (cid:81)
t/s f of f along
variable t modulo s by induction on T :

Algorithm 1 MARKOVPRODUCT
input a funsor f , a time variable t ∈ fv(f ),
a step mapping s ⊆ fv(f ) × fv(f ).
output the Markov product funsor (cid:81)
Create substitutions with fresh names (barred):
se ← {(y, ¯x) | (x, y) ∈ s} to rename even factors, and
so ← {(x, ¯x) | (x, y) ∈ s} to rename odd factors.
Let v ← {¯x | (x, y) ∈ s} be variables to marginalize.
Let T ← |Γf [t]| be the length of the time axis.
while T > 1 do

t/s f .

Split f into even and odd parts of equal length:
fe ← f [se, t (cid:55)→ (0, 2, 4, 6, ..., 2(cid:98)T /2(cid:99) − 2)]
fo ← f [so, t (cid:55)→ (1, 3, 5, 7, ..., 2(cid:98)T /2(cid:99) − 1)]
Perform parallel sum-product contraction:
f (cid:48) ← (cid:80)
v fe × fo
if T is even then f ← f (cid:48)
else f ← concatt (f (cid:48), f [t (cid:55)→ T − 1]) ;
T ← (cid:100)T /2(cid:101)

end
return f [t (cid:55)→ 0]

f =

(cid:81)

t/s






f [t (cid:55)→ 0]
(cid:80)
w

f [t (cid:55)→ T, u (cid:55)→ w] × (cid:81)
t/s

if T = 1; otherwise

f [t : ZT −1, v (cid:55)→ w]

where w is a tuple of |s|-many fresh variables, u = dom s =
(u | (u, v) ∈ s) is the domain tuple of s, v = cod s =
(v | (u, v) ∈ s) is the codomain tuple of s, f [t : ZT −1] is
the preﬁx of f to the ﬁrst T − 1 time steps, and (cid:80)
w denotes
either summing out a discrete variable or integrating out a
real-tensor variable.

Note the time step mapping s corresponds to the pre op-
erator in (Baudart et al., 2019), and formalizes the idiom
of marking variable names with time lags like x_prev,
x_curr.

Example A.1. In the simplest case of empty matching s,
the Markov product reduces to the usual product

(cid:81)

v/∅

f = (cid:81)
v

f = f [t (cid:55)→ 0] × · · · × f [t (cid:55)→ T − 1].

f

a

be

Example A.2. Let
funsor with shape
t:ZT , i:ZN , j :ZN (cid:96) f : R, equivalent
to a batch of
N × N matrices. Let s = {(i, j)} map a single previous
discrete state i to a current state j. Then the Markov product
is equivalent to a chain of matrix multiplies

Example A.3. Let
funsor with shape
be
t:ZT , xprev :R3, xcurr :R3 (cid:96) f : R deﬁned by a density
with two conditional multivariate normal factors

a

f

f = MVN (xcurr; F xprev, P ) × MVN (y; Hxcurr, Q)

corresponding to a dynamical system with linear dynamics
F ∈ R3×3, process noise covariance P , linear observation
matrix H ∈ R2×3, observation noise covariance Q, and
observations y that depend on time, t:ZT (cid:96) y :R2. This
Markov product is equivalent to a Kalman ﬁlter, producing
a joint distribution over the initial and ﬁnal states. The ﬁnal
state distribution is given by further marginalizing out the
initial state:

xprev :R3, xcurr :R3 (cid:96)

xcurr :R3 (cid:96) (cid:80)
xprev

(cid:81)

t/(xprev,xcurr)
(cid:81)

t/(xprev,xcurr)

f : R

f : R

The Markov product operation generalizes the Bayesian
ﬁltering operations of (Särkkä and García-Fernández, 2019)
to multiple latent random variables; Sec. 4.2 extends their
temporal parallelization algorithms to Markov products of
funsors.

(cid:81)

t/(i,j)

f = f [t (cid:55)→ 0] • f [t (cid:55)→ 1] • · · · • f [t (cid:55)→ T − 1],

A.1. Parallel-scan Bayesian ﬁltering

where each binary operation can be deﬁned as a sum-product
expression, which is the core computation in variable elimi-
nation in discrete Markov models,

We implement parallel-scan Bayesian ﬁltering (Särkkä and
García-Fernández, 2019) as a parallel-scan rewrite rule Al-
gorithm 1 for the Markov product operation.

f • g = (cid:80)
k

f [j (cid:55)→ k] × g[i (cid:55)→ k].

Theorem 1. MARKOVPRODUCT Algorithm 1 has parallel
complexity logarithmic in time length T .

Functional Tensors for Probabilistic Programming

Proof. Each funsor operation parallelizes over time, and
the while loop executes O(log(T )) many times, hence total
parallel complexity is O(log(T )).

B. Syntax and operational semantics

B.1. Type inference

Type inference rules for funsors are presented in Fig. 10.
Most type inference rules for funsors generalize shape in-
ference rules for tensors. We annotate such rules with their
tensor analogs in NumPy, e.g. the Delta funsor generalizes
one-hot encoded arrays; the Variable funsor generalizes
reshaped identity matrices; substitution e1[v (cid:55)→ e2] corre-
sponds to indexing via brackets or np.take; and function
lifting (cid:98)f (· · · ) corresponds to broadcasting.

Because funsor types include shape information, we can
perform shape checking even under a lazy interpretation.
While this is less powerful than static shape checking (which
would require static analysis of Python code), it does allow
us to catch errors before expression optimization, evaluation,
or approximation. Most usefully, funsor types prevent a
large class of broadcasting bugs, which have proved to be
a common class of bugs, especially when using discrete
variable elimination algorithms for inference.

B.2. Term rewriting

Rewrite rules are speciﬁed by registering a pattern together
with a handler to execute when the pattern is matched.
Figs. 12-15 present a subset of the rewriting rules deﬁning
operational semantics in different interpretations. Fig. 11
provides two example rules. Some properties of rules are
too complex for the simple pattern matching mechanism,
e.g. the conditions on the right of Fig. 12. We support this
ﬁner grained matching by allowing extra matching logic in
the handler for each pattern, whereby the handler can reject
a pattern match.

Code in user-facing models often contains a mixture of
raw tensors and funsors. We use operator overloading and
multiple dispatch to handle mixtures of raw tensors and
funsors. Further, we abstract operators into classes such
as Unary, Binary, and Associative (a subclass of Binary),
allowing us to write individual rules that can each handle
large classes of operations.

Inference code often requires patterns too deep for the min-
imal syntax described in Section 2.1. Thus our implemen-
tation adds syntax for a number of compound funsors. For
example the slicing operations in Algorithm 4.2

fe ← f [se, t (cid:55)→ (0, 2, 4, 6, ..., 2(cid:98)T /2(cid:99) − 2)]

are represented as symbolic Slice funsors that are equivalent
to Tensor funsors but with an extra rule allowing zero-copy

Γ = (v1 :Zd1, . . . , vn :Zdn )
w ∈ Zd1× · · · ×Zdn → τ
Γ (cid:96) Tensor(Γ, τ, w) : τ

“np.array”

s = s1× · · · ×sn
i ∈ Zd1 × · · · ×Zd1 → Rs
Λ ∈ Zd1 × · · · ×Zd1 → Rs × Rs p.s.d.
Γ = (u1 :Zd1 , . . . , um :Zdm , v1 :Rs1, . . . , vn :Rsn )
Γ (cid:96) Gaussian(Γ, i, Λ) : R

Γ (cid:96) x:τ
Γ, v :τ (cid:96) Delta(v, x) : R

“one_hot”

v :τ (cid:96) Variable(v, τ ) : τ

“np.eye”

Γ, v :τ2 (cid:96) e1 :τ1

Γ (cid:96) e2 :τ2

Γ (cid:96) e1[v (cid:55)→ e2] : τ1

“np.take”

Γ, v :τ (cid:96) e:Rs
Γ (cid:96) (cid:80)
e : Rs
v

Γ, v :Zn (cid:96) e:Rs
Γ (cid:96) (cid:81)
e : Rs
v

“np.sum”

“np.prod”

Γ, v :Zn (cid:96) e:Rs

σ ⊆ fv(e) × fv(e) valid

Γ (cid:96) (cid:81)
v/σ

e : Rs

f ∈ τ1 × · · · × τn → τ0
· · ·

Γ (cid:96) en :τn

Γ (cid:96) e1 :τ1

Γ (cid:96) (cid:98)f (e1, . . . , en) : τ0

“broadcast”

Figure 10: Typing rules for funsors. We use set notation ∈ to
denote numerical objects like functions f ∈ τ1 → τ2 and multi-
dimensional arrays x ∈ Z3 × Z3 → R. We reserve type notation
e : τ for funsors e. The precision matrix Λ in a Gaussian must be
symmetric positive semideﬁnite for all values of batch variables
(u1, . . . , um). The step substitution σ in the Markov product must
be a valid matching as deﬁned Deﬁnition 4.

substitution. Similarly concatenation in that algorithm is
represented by a Cat funsor.

B.2.1. AFFINE PATTERN MATCHING

Both Tensor funsors and Gaussian funsors are closed under
a large class of substitutions. Tensor funsors are closed
under substitution of Tensors, thereby permitting batched
computation in the presence of delayed discrete random
variables. Gaussians are closed under substitution of afﬁne

Functional Tensors for Probabilistic Programming

@eager.register(Binary, Op, Tensor, Tensor)
def eager_binary_tensor(op, lhs, rhs) :
assert lhs .dtype == rhs.dtype
inputs , (x, y) = align_tensors(lhs , rhs)
data = op(x, y)
return Tensor(data, inputs ,

lhs .dtype)

@eager.register(Binary, AddOp, Delta, Funsor)
def eager_add_delta(op, lhs, rhs):
if lhs .name in rhs.inputs:

rhs = rhs(∗∗{lhs .name: lhs.point })
return op(lhs, rhs)

return None # defer to default

implementation

Figure 11: Example rewriting rules for Binary addition, a special
case of lifted function (cid:98)f (-, -). The eager_binary_tensor rule
performs a tensor operation. The eager_add_delta rule performs
extra matching logic.

funsors of real-tensor valued variables.

We recognize afﬁne funsors using a two-step process: ﬁrst
we specify a sound but incomplete algorithm to decide
whether a pattern is afﬁne; and then we determine afﬁne
coefﬁcients by substituting 1 + n different grounding sub-
stitutions (or “probes”) into the matched funsor: one probe
to determine the constant offset, and one batched probe
for each of the n real-tensor valued free variables in the
matched funsor. The resulting afﬁne funsor is represented
in a canonical form using einsum, similar to the approach
of (Hoffman, 2018).

B.3. Monte Carlo gradient estimation

Stochastic gradient estimation is a fundamental computa-
tion in black-box variational inference (Kingma and Welling,
2013; Rezende et al., 2014; Ranganath et al., 2014), aim-
ing to produce unbiased estimates of the gradient of a loss
function w.r.t. parameters, in the presence of integrals and
sums approximated by Monte Carlo sampling. Two broad
approaches include: i) constructing a surrogate loss func-
tion (a secondary compute graph) whose expected gradient
matches the gradient of the expected loss (Schulman et al.,
2015); and ii) multiplying each stochastic choice by a differ-
entiable “DiCE” factor to ensure the original compute graph
is differentiable (Foerster et al., 2018).

In our approach to stochastic gradient estimation, an approx-
imate MONTECARLO interpretation stochastically rewrites
one funsor (a deterministic but possibly non-analytic com-
pute graph) to a more tractable funsor. The key rewrite
rules of the MONTECARLO interpretation are shown in
Fig. 15. This allows rewriting to evaluate analytic inte-
grals and drop zero-expectation terms before sampling. The
MONTECARLO interpretation rewrites Tensor and Gaus-
sian funsors to Tensor-weighted Delta funsors that match in

expectation at all derivatives. Continuous samples are repa-
rameterized (and hence differentiable) and weighted by a
normalizer Tensor. Discrete samples are non-differentiable,
and are weighted by a normalizer and a differentiable DiCE
factor.

B.4. Atomic term data handling

Tensor, Gaussian and Delta terms have underlying numerical
data attached to them in the form of one or more PyTorch
tensors. Our semantics and implementation rely heavily on
efﬁcient broadcasting as implemented in PyTorch and other
tensor libraries, but because free variables have names and
type contexts are unordered, atomic terms and operations
that interact with their data are responsible for maintaining
an alignment between the data tensor shape and the type
contexts.

In our implementation, this is accomplished by having
atomic terms maintain an ordering in their type contexts
(which are typically referred to as “inputs” in our code).
This ordering is an implementation detail and does not af-
fect our semantics; we use it to associate individual free
variables with individual dimensions of the data tensor(s).
To make this more concrete, we include the actual code for
the eager binary product of two Tensor funsors from our
implementation in eager_binary_tensor in Fig. 11.
The align_tensors function uses the ordered type con-
texts to permute and reshape the underlying data tensors
x = lhs.data and y = rhs.data so that the result-
ing data tensor computed by op(x, y) using PyTorch’s
broadcasting behavior can be wrapped with a Tensor funsor
with the correct type context.

C. Details of example programs

C.1. Gaussian mixture model

Fig. 1 of the main text provides a complete example of a
probabilistic computation in our language as described in
the paper. To illustrate the close correspondence between
our paper and our actual implementation, we include in
Fig. 16 of the appendix a Python version of this example.

C.2. Maximum marginal likelihood

Fig. 2 in Sec. 3 of the main text illustrates a funsor com-
putation for maximum marginal likelihood inference in a
simple generative model. Inference steps on the right are
triggered by execution of each line of model code on the left.
On line 1 the joint distribution is initialized to the trivial
normalized distribution. On line 2 a delayed sample state-
ment triggers creation of a Variable funsor z in the model
code and accumulation of an unevaluated factor distribution
pz = Gaussian((v :R), iz, Λz)[v (cid:55)→ z] in inference code.

Functional Tensors for Probabilistic Programming

(We assume by convention distributions like pz, px|z, qz|x
name their variate v and parameter, if any, θ.) On line 3 a
nonlinear function is lazily applied to z creating a lazy fun-
sor expression y = (cid:100)exp(z). On line 4 a distribution is condi-
tioned on ground data x, triggering accumulation of a factor
px|z = Gaussian((v :R, θ :R), ix, Λx)[θ (cid:55)→ y, v (cid:55)→ x] with
free variable z (because x is ground and y has free variable
z). Model termination on line 5 triggers marginalization of
the z variable, which can be performed either exactly by pat-
tern matching or approximately by Monte Carlo sampling.
The resulting objective is differentiable with respect to any
parameters. Optimization is achieved by repeatedly execut-
ing model code, accumulating factors, and marginalizing
over z, using PyTorch autograd to compute gradients of the
objective with respect to the model parameters, and updat-
ing the parameter values with a stochastic gradient-based
optimizer.

C.3. Variational inference

the main text

illustrates a
Fig. 3 in Sec. 3 of
typical
inference,
funsor computation for variational
where a data-dependent variational distribution qz|x =
Gaussian((v :R, θ :R), iq, Λq)[v (cid:55)→ Variable(z :R), θ (cid:55)→
x] is ﬁt to data. Lines 1–6 execute delayed sample state-
ments in the model code, and accumulate distributions p
and q with a single free variable z in inference code. Line 7
combines p and q to compute the ELBO, which can be per-
formed either exactly by pattern matching or approximately
by Monte Carlo sampling z from q. As in the previous
example, optimization is achieved by repeatedly executing
model code, accumulating factors, integrating over z, using
PyTorch autograd to compute gradients of the objective with
respect to the model parameters, and updating the parameter
values with a stochastic gradient-based optimizer.

This example is not terribly interesting as written, due to
space constraints in the main text. Readers looking for a
more complete variational inference example may wish to
examine the details of the neural variational Kalman ﬁlter
described in Sec. 6.4 of the main text and Sec.D.5 of the
appendix.

D. Experimental details

D.1. Discrete Factor Graphs

In this section we describe in more detail the experiments
of Sec. 6.1 of the main text. Code for these experiments
may be found in the examples/mixed_hmm/ directory
of our source code.

D.1.1. DATASET DETAILS

R package for analyzing animal movement data with gen-
eralized hidden Markov models. The raw datapoints are in
the form of irregularly sampled time series (datapoints sepa-
rated by 5-15 minutes on average) of GPS coordinates and
diving activity for each individual in the colony (10 males
and 7 females) over the course of a single day recorded
by lightweight tracking devices physically attached to each
animal by researchers. We used the momentuHMM harbour
seal example11 preprocessing code (whose functionality is
described in detail in section 3.7 of (McClintock and Mich-
elot, 2018)) to independently convert the raw data for each
individual into smoothed, temporally regular time series of
step sizes, turn angles, and diving activity, saving the results
and using them for our population-level analysis.

D.1.2. MODEL DETAILS

Our models are discrete hidden Markov models whose state
transition distribution is speciﬁed by a hierarchical gener-
alized linear mixed model. At each timestep t, for each
individual trajectory b ∈ I in each group a ∈ G, we have

logit(p(x(t)

ab = state i | x(t−1)

ab = state j)) =
(cid:0)(cid:15)
(cid:124)
I,abθ1 + (cid:15)

(cid:124)
G,aθ2

(cid:1)

ij

where a, b correspond to plate indices, (cid:15)s are independent
discrete random variables, and θs are parameter vectors. See
Fig. 17 for the corresponding plate diagram.

The values of the independent random variable (cid:15)I and (cid:15)G
are each sampled from a set of three possible values shared
across the individual and group plates, respectively. That is,
for each individual trajectory b ∈ I in each group a ∈ G, we
sample single random effect values for an entire trajectory:

(cid:15)G,a ∼ Categorical(πG)
(cid:15)I,ab ∼ Categorical(πI,a)

Observations y(t) are represented as sequences of real-
valued step lengths, modelled by a zero-inﬂated Gamma
distribution, turn angles, modelled by a von Mises distri-
bution, and intensity of diving activity between successive
locations, modelled with a zero-inﬂated Beta distribution fol-
lowing (McClintock and Michelot, 2018; Obermeyer et al.,
2019). Each likelihood component has a global learnable
parameter for each possible value of x. We grouped animals
by sex and implemented versions of this model with no ran-
dom effects, and with random effects present at the group,
individual, or both group and individual levels.

As in (Obermeyer et al., 2019), we downloaded the data
from momentuHMM (McClintock and Michelot, 2018), an

11https://github.com/bmcclintock/

momentuHMM/blob/master/vignettes/
harbourSealExample.R

Functional Tensors for Probabilistic Programming

D.1.3. TRAINING AND IMPLEMENTATION DETAILS

continuous observations with additive Gaussian noise.

We performed batch gradient descent with the Adam opti-
mizer with initial learning rate 0.1 and default momentum
hyperparameters (Kingma and Ba, 2014). We annealed the
learning rate once by a factor of 0.1 when the training loss
stopped decreasing, ultimately training the models for 2000
epochs with 10 restarts from random initializations. The
number of random effect parameter values was taken from
(McClintock and Michelot, 2018).

Our models are implemented in Python on top of PyTorch,
which we use for automatic differentiation. To compute
the wall clock times in Table 1, we evaluated the marginal
likelihood of our models on the full preprocessed harbour
seal dataset and used PyTorch’s reverse-mode automatic
differentiation to compute gradients with respect to all train-
able parameters. All experiments were performed on an
Ubuntu 18.04 workstation with a 24-core Intel Xeon proces-
sor, 64GB of RAM, and two NVIDIA RTX 2080 GPUs. In
all cases, the majority of the time is spent in the PyTorch
backward pass, which is independent of any pure Python
overhead in our impementation of the forward pass.

zt = Ft−1zt−1 + q
xt = Ht−1zt + r + β

where F ∈ Rnz×nz is the state transition matrix, H ∈
Rnz×nx is the state-to-observation matrix, q, r are indepen-
dent Gaussians with covariances Q, R respectively, and β
is the joint bias distribution, a zero mean Gaussian with
learnable covariance B. We can now write the conditional
probabilities as follows:

p(zt|zt−1) = N (Ftzt−1, Q)
p(xt|zt) = N (Htzt, R + B)

To compute the marginal probability, we perform a sequen-
tial version of the sum product algorithm, collapsing out
previous states after each measurement update. We learn
the joint bias scale, process noise, and observation noise
using gradient descent with the Adam optimizer (Kingma
and Ba, 2014) for 50 steps with a learning rate of 0.1, and
beta parameters (0.5, 0.8).

D.2. Additional performance experiments

D.4. Switching Linear Dynamical System

We systematically evaluate the parallel scaling of our algo-
rithms using a simpliﬁed version (Figure 18) of the mixed-
effect hidden Markov models used in Section 6.1. These
models have no group-level random effects and a single
categorical likelihood per timestep.

For many combinations of plate size I and chain length T ,
we generate appropriately sized fake datasets and measure
the time taken by tensor variable elimination (Obermeyer
et al., 2019) and funsor variable elimination described in
4.1 to compute gradients of transition parameters θ, π. As
in the previous section, all experiments were performed on
an Ubuntu 18.04 workstation with a 24-core Intel Xeon
processor, 64GB of RAM, and two NVIDIA RTX 2080
GPUs.

Figure 19 shows the average times across 20 trials for each
(I, T ) combination. Our parallel algorithms scale nearly
perfectly with chain length on a single GPU, and typically
achieve a wall-clock time speedup of 2 or more orders of
magnitude over the sequential versions.

D.3. Kalman ﬁlter with global latents

In this section we describe in more detail the experiment of
Sec. 6.2 of the main text. Code for this experiment may be
found in examples/sensor.py in our source code.

The underlying dynamics model used to generate the data is
a 2-D linear Nearly Constant Velocity (NCV) model. The
state space model has both continuous transition states and

In this section we describe in more detail the experiment of
Sec. 6.3 of the main text. Code for this experiment may be
found in examples/eeg_slds.py in our source code.

The joint probability p(y1:T , s1:T , x1:T ) of model variant
SLDS-I is given by

T
(cid:89)

t=1

p(st|st−1)N (xt|Astxt−1, σst

trans)N (yt|Bxt, σobs)

where Ast is a state-dependent transition matrix, σst
trans is
a state-dependent diagonal transition noise matrix, B is a
state-independent observation matrix, and σobs is a state-
independent diagonal observation noise matrix. Similarly,
the joint probability of variant SLDS-II is given by:

T
(cid:89)

t=1

p(st|st−1)N (xt|Axt−1, σtrans)N (yt|Bstxt, σst

obs)

where now A and σtrans are state-independent and Bst and
σst
obs are state-dependent. Finally, the joint probability of
variant SLDS-III is given by

T
(cid:89)

t=1

p(st|st−1)N (xt|Astxt−1, σst

trans)N (yt|Bstxt, σst

obs)

where now both the transition and emission probabilities
are state-dependent. In all our experiments we use K = 2
switching states and set the dimension of the continous state
to dim(xt) = 5.

Functional Tensors for Probabilistic Programming

predicts latent state z from a multilayer perceptron; this
neural net introduces weak time dependency in the form of
a fully time-pooled layer.

We train on random two-week minibatches of data. This
introduces two forms of bias which we argue are negligible.
First, subsampling a time series introduces dependency bias,
however empirically data is week-to-week Markov, so that
a single week of data captures all long-term effects. Second,
subsampling windows introduces a trapezoidal data weight-
ing whereby the ﬁrst two weeks and last two weeks are not
uniformly sampled; however we ﬁnd this negligible since
we train on at least six years of data at a time. An advantage
of minibatches spanning exactly two weeks is that the cyclic
hour-of-week features are evenly covered in each minibatch.

We train using an Adam optimizer (Kingma and Ba, 2014)
with gradient clipping, learning rate that exponentially de-
cays from 0.05 to 0.005 over 1000 gradient descent steps,
and momentum parameters β = (0.8, 0.99). Our loss func-
tion is the negative ELBO, as computed in Figure 25.

To compute the log marginal likelihood used in training
we use a moment-matching approximation with a window
length of L, see Ex. 21. During prediction and smoothing
we use L = 1.

The raw dataset has T = 14980 timesteps, which we sub-
sample by a factor of 20, yielding a dataset with T = 749.
We use the ﬁrst 400 timesteps for training. Of the remaining
349 timesteps, we use random subsets of size 149 and 200
for validation and testing, respectively. In particular we
use the validation set to choose learning hyperparameters
and determine early stopping for gradient ascent. The 14-
dimensional outputs {yt} are normalized to have zero mean
and unit variance.

We use the Adam optimizer for training (Kingma and Ba,
2014). We train for up to 250 gradient steps and decay the
learning rate exponentially. We use the validation set to do a
hyperparameter search over the exponential decay factor γ
and the momentum parameter β1. For each hyperparameter
setting we do 7 independent runs with different random
number seeds for parameter initialization. We then report
results on the test set.

D.5. Neural variational Kalman ﬁlter

In this section we describe in more detail the experiment
of Sec. 6.4 of the main text. Since this experiment is more
complex, in addition to full source code in a separate ﬁle
we also include isolated Funsor code in Figs. 23-25 of the
appendix.

We examine data publicly available at https://www.
bart.gov/about/reports/ridership, contain-
ing hourly ridership counts between every pair of Bay Area
Rapid Transit train stations for the years 2011-2018. Our
objective is to jointly forecast all station-station pairs such
that users can aggregate these forecasts as desired, e.g.
rides between a given pair of stations, or all arrivals-to and
departures-from a given station, as in Figures 22.

Our generative model and collapsed variational inference
model are shown in Figure 23 and Figure 24, respectively.
Our model neural network is a multilayer perceptron of
the form linear-sigmoid-linear, whose output we split into
(i) a gate logit which is mapped to a probability p via a
sigmoid funnction, and (ii) a Poisson rate which is mapped
to a bounded positive number λ via a bounded exponential
function (combining an afﬁne transform and a sigmoid). Our
guide neural network is a multilayer perceptron of the form
linear-sigmoid-linear and with middle layer tuned to the
same low-dimension as the model state space (we examine
sizes {2, 4, 8}). Both neural networks operate independently
over each time step, i.e. we rely on the Gaussian state space
model rather than a convolution or RNN for coupling states
over time. Our mean ﬁeld inference model additionally

Functional Tensors for Probabilistic Programming

LAZY

Delta(v1, e1)[v2 (cid:55)→ e2] ⇒ Delta(v1, e1[v2 (cid:55)→ e2])

if v1 (cid:54)= v2 and v1 /∈ fv(e2)

Variable((v :τ ))[v (cid:55)→ e] ⇒ e
Variable((v :τ ))[v(cid:48) (cid:55)→ e] ⇒ Variable((v :τ ))

e1[v (cid:55)→ e2] ⇒ e1

(cid:98)f (e1, . . . , en) [v (cid:55)→ e0] ⇒ (cid:98)f (e1[v (cid:55)→ e0], . . . , en[v (cid:55)→ e0])

if v (cid:54)= v(cid:48)

v /∈ fv(e1)

(cid:0)(cid:80)
v1
(cid:0) (cid:81)
v1/s

e1

e1

(cid:1)[v2 (cid:55)→ e2] ⇒ (cid:80)
v1
(cid:1)[v2 (cid:55)→ e2] ⇒ (cid:81)
v1/s

e1[v2 (cid:55)→ e2]

v1 /∈ fv(e2) and v1, v2 distinct

e1[v2 (cid:55)→ e2]

v1 /∈ fv(e2) and v1, s, v2 all distinct

Figure 12: Selected rewrite rules for the LAZY interpretation. This interpretation only handles substitution into non-atomic terms, and
unlike EXACT none of its rules trigger numerical computation. Terms that do not match any of the rules are reﬂected, i.e. evaluated to lazy
versions of themslves. Additional rules include normalization rules with respect to associativity, commutativity, and distributivity. Bound
variables are α-renamed to avoid conﬂict during substitution.

Functional Tensors for Probabilistic Programming

EXACT

Delta(v, e1) × e2 ⇒ Delta(v, e1) × e2[v (cid:55)→ e1]

if v ∈ fv(e2)

Delta(v, e) ⇒ 1

(cid:80)
v

Delta(v, e1) × e2 ⇒ e2

(cid:80)
v

if v /∈ fv(e2)

Variable((v :Zn)) ⇒ Tensor((v :Zn), arange(n))

Tensor(Γ1, w1)[v (cid:55)→ Tensor(Γ2, w2)] ⇒ Tensor((Γ1 − (v :τ )) ∪ Γ2, index(w1, v, w2))

if (v :τ ) ∈ Γ1

(cid:98)f (Tensor(Γ1, w1), . . . , Tensor(Γn, wn)) ⇒ Tensor(∪kΓk, f (w1, . . . , wn))

Tensor(Γ, w) ⇒ Tensor(Γ-(v:τ ), sum(w, v))

Tensor(Γ, w) ⇒ Tensor(Γ-(v:τ ), prod(w, v))

(cid:80)
v
(cid:81)
v

if (v :τ ) ∈ Γ

if (v :τ ) ∈ Γ

Gaussian(Γ1, i, Λ)[v (cid:55)→ Tensor(Γ2, w)] ⇒ Gaussian((Γ1 − (v :τ )) ∪ Γ2, i(cid:48), Λ(cid:48))
Gaussian(Γ1, i, Λ)[v (cid:55)→ Tensor(Γ2, w)] ⇒ Tensor((Γ1 − (v :τ )) ∪ Γ2, w(cid:48))
Gaussian(Γ1, i1, Λ1) × Gaussian(Γ2, i2, Λ2) ⇒ Gaussian(Γ1 ∪ Γ2, i1 + i2, Λ1 + Λ2)

if a v2 (cid:54)= v ∈ Γ1 is real-valued
if only v ∈ Γ1 is real-valued

(cid:81)
v
(cid:80)
v

Gaussian(Γ, i, Λ) ⇒ Gaussian(Γ − (v :Zn), sum(i, v), sum(Λ, v))

if v is a bounded integer variable

Gaussian(Γ, i, Λ) ⇒ Tensor(Γd, w) × Gaussian(Γ − (v :τ ), i(cid:48), Λ(cid:48))

if v ∈ Γ is a real array variable

(cid:80)
v

Tensor(Γ1, w) × Gaussian(Γ2, i, Λ) ⇒ Tensor(Γ1, w) × (cid:80)

Gaussian(Γ2, i, Λ)

if v ∈ Γ2 is a real array variable

v

Figure 13: Selected rewrite rules for the EXACT interpretation. Terms that do not match any of these rules are evaluated with LAZY.
Some rules trigger a numerical computation, as described in the main text and indicated with monospace font. The Gaussian rules
for substitution and marginalization perform standard multivariate Gaussian computations that can be found in most graduate statistics
or machine learning textbook, and as such we do not specify them in detail in this paper. Additional rules assist with pattern matching,
including normalization rules with respect to associativity, commutativity, and distributivity. Bound variables are α-renamed to avoid
conﬂict during substitution.

Functional Tensors for Probabilistic Programming

EXACT

OPTIMIZE

e ⇒ MARKOVPRODUCT(e, v, c)

if v is a bounded integer variable

(cid:81)

v/c

and c ⊆ (fv(e) − v) × (fv(e) − v)

e ⇒ e

(cid:80)
V

if V ⊆ fv(e) is empty

(cid:80)
V

e1 × · · · × en ⇒ (cid:80)
V (cid:48)

( (cid:80)
V1∩V

e1) × · · · × ( (cid:80)
Vn∩V

en)

where Vk = fv(ek) − ∪
j(cid:54)=k

fv(ej)

and where V (cid:48) = V − ∪
k

Vk

if V ⊆ fv(e1 × · · · × en)
and if any v ∈ V appear in only one ek

(cid:80)
V

e1 × · · · × en ⇒ (cid:80)
V −V (cid:48)

( (cid:80)
V (cid:48)∩V

eσ1 × eσ2 ) × eσ3 × · · · × eσn where σ1, . . . , σn is a min-cost path

where V (cid:48) = fv(eσ1 × eσ2 ) − ∪
k>2

fv(eσk )

if V ⊆ fv(e1 × · · · × en)
and if all v ∈ V appear in ≥ 2 ek

Figure 14: Selected rewrite rules for the variable elimination algorithms of Sec. 4. MARKOVPRODUCT means invoking Algorithm 1,
described in Sec. 4.2 of the main text and Sec. A of the appendix, all of whose steps are also evaluated with the EXACT interpretation.
Terms that do not match rules in the OPTIMIZE interpretation are evaluated with the LAZY interpretation. The permutation σ1, . . . , σn
in the ﬁnal rule of OPTIMIZE has the following form: σ1, σ2 are selected via argmink,k(cid:48) cost(fv(ek × ek(cid:48) ) − ∪
fv(ej), ek, ek(cid:48) )
where cost(V (cid:48), ek, ek(cid:48) ) is a heuristic cost function, such as memory usage, representing the computational cost of a binary sum-product
operation, and the remaining σ3, . . . , σn follow the original term ordering. This overall approach to variable elimination or tensor
contraction is not novel. Indeed, our implementation directly uses the tensor contraction library opt_einsum (Smith and Gray, 2018) to
compute the σks; for this reason we defer to their paper and documentation for detailed formal explanations.

j(cid:54)=k,k(cid:48)

Functional Tensors for Probabilistic Programming

MOMENTMATCHING

Tensor(Γ1, w) × Gaussian(Γ2, i, Λ) ⇒ Gaussian(Γ2 − (v :τ ), i(cid:48), Λ(cid:48)) × (cid:80)

Tensor(Γ1, w(cid:48))

if v is a bounded integer variable

v

MONTECARLO

(cid:80)
v

Tensor(Γ, w) × e ⇒ Tensor(Γ − (v :τ ), wN × wD) × (cid:80)

Delta(v, es) ×e

if v is a bounded integer variable

v

Gaussian(Γd ∪ (v :τ ), i, Λ) × e ⇒ Tensor(Γd, wN ) × (cid:80)

Delta(v, es) ×e

if v is a real array variable

v

(cid:80)
v

(cid:80)
v

Figure 15: Selected rewrite rules for the approximate MONTECARLO and MOMENTMATCHING interpretations of Sec. 4. Terms that
do not match any rules in the MONTECARLO and MOMENTMATCHING interpretations are evaluated with the EXACT interpretation.
In the moment matching rules, the new values i(cid:48), Λ(cid:48), w(cid:48) are computed to match the moments of the original expression as discussed in
Sec. 4.4 of the main text. In the MONTECARLO rules, es refers to the sample Tensor and wN and wD refer to normalizer and Dice factors
discussed in Sec. B.3 of the appendix.

from collections import OrderedDict

import torch

import funsor
from funsor.domains import bint, reals
from funsor.gaussian import Gaussian
from funsor.ops import add, logaddexp
from funsor.torch import Tensor
from funsor.terms import Variable

def gmm(x, i_z, prec_z, i_x , prec_x):

x = Tensor(x, OrderedDict(), ’ real ’ )
z = Variable( "z" , reals (2, 3))
c = Variable( "c" , bint (2) )
j = Variable( " j " , bint (50))
logp_c = Tensor(torch.tensor ([0.5, 0.5]) .log () , OrderedDict(c=bint(2)))
logp_z = Gaussian(i_z, prec_z, OrderedDict(z=reals(3)))
logp_xc = Gaussian(i_x, prec_x, OrderedDict(c=bint(2), z=reals(3), x=reals(3)) )

logp_x = logp_c + logp_xc(z=z[c], x=x[j ])
logp_x = logp_x.reduce(logaddexp, "c").reduce(add, "j")
logp_x = logp_x + logp_z(z=z[c]).reduce(add, "c")
logp_x = logp_x.reduce(logaddexp, "z")
return logp_x

Figure 16: Funsor code for computation of the Gaussian mixture model likelihood in Fig. 1. The code is very similar to Fig. 1, except
that we work with log-probabilities rather than probabilities for numerical stability and represent the plated product and marginalization
terms with a single reduce function parametrized by an operation.

Functional Tensors for Probabilistic Programming

θG

πG

(cid:15)G

θI

πI

(cid:15)I

· · ·

|G|

|I|

xt

yt

xt+1

· · ·

yt+1

Figure 17: A single state transition in the hierarchical mixed-
effect hidden Markov model used in our experiments in Section
6.1. θs and πs are learnable parameters.

θI

πI

(cid:15)I

· · ·

|I|

xt

yt

xt+1

· · ·

yt+1

Figure 18: A single state transition in the simpliﬁed hidden
Markov model used to demonstrate the scalability of funsor vari-
able elimination using the MARKOVPRODUCT operation described
in Section 4.1.

Functional Tensors for Probabilistic Programming

Figure 19: Visualizing average wall clock times required to compute marginal likelihoods using funsor variable elimination and gradients
of the marginal likelihood for all transition parameters using PyTorch’s reverse-mode automatic differentiation. Top left: average
computation time with sequential tensor variable elimination as a function of time series length T , for different ﬁxed values of plate size I.
The triangle-marked line at the bottom is the average time required for parallel computation, shown for scale here and in detail below.
Bottom left: average computation time with parallel funsor variable elimination as a function of time series length T , for different ﬁxed
values of plate size I. Top right: average computation time with sequential tensor variable elimination as a function of plate size I, for
different ﬁxed values of time series length T . The triangle-marked line at the bottom is the average time required for parallel computation,
shown for scale here and in detail below. Bottom right: average computation time with parallel funsor variable elimination as a function
of plate size I, for different ﬁxed values of time series length T .

2505007501000125015001750chain length0.02.55.07.510.012.515.017.5sequential gradient time (s)plate size: 100plate size: 200plate size: 300plate size: 400plate size: 500plate size: 600plate size: 7000100200300400500600700800plate size0.02.55.07.510.012.515.017.5sequential gradient time (s)chain length: 200chain length: 600chain length: 1000chain length: 1400chain length: 18002505007501000125015001750chain length0.0000.0250.0500.0750.1000.1250.1500.1750.200parallel gradient time (s)plate size: 40plate size: 100plate size: 200plate size: 300plate size: 400plate size: 500plate size: 600plate size: 7000200400600800plate size0.0000.0250.0500.0750.1000.1250.1500.1750.200parallel gradient time (s)chain length: 200chain length: 600chain length: 1000chain length: 1400chain length: 1500chain length: 1800Functional Tensors for Probabilistic Programming

curr = " state_init "
log_p = init_dist (state=curr)
log_p += bias_dist
for time, obs in enumerate(track):
# update previous and current
prev, curr = curr ,
# add the transition dynamics
log_p += trans_dist(prev=prev, curr=curr)
# add observation noise
log_p += observation_dist(state=curr, obs=obs)
# collapse out the previous state
log_p = log_p.reduce(ops.logaddexp, prev)

f "state_{time}"

states

# marginalize out remaining latent variables
log_p = log_p.reduce(ops.logaddexp)

Figure 20: Python code using the funsor library implementing the
sum product algorithm to perform inference on the biased state
space model model described in section 6.2. Note that strings are
automatically coerced to Variable funsors on substitution, as in
init_dist (state=" state_init ") .

Functional Tensors for Probabilistic Programming

to funsor that all reduce operations should be done using a moment−matching approximation.

the observed data . we use an interpretation decorator to

# returns the marginal log probability of
# signal
#
# inputs :
# observations ( torch . Tensor of shape (T, obs_dim))
# trans_probs ,
@funsor.interpreter. interpretation (funsor.terms.moment_matching)
def marginal_log_prob(observations, trans_probs, x_init_dist , x_trans_dist, y_dist ,

x_init_dist , x_trans_dist , y_dist ( funsors )

L=2, num_components=2, hidden_dim=5):

log_prob = funsor.Number(0.)
s_vars = {−1: funsor.Tensor(torch.tensor(0) , dtype=num_components)}
x_vars = {}

for t , y in enumerate(observations):

s_vars[t ] = funsor.Variable( f "s_{t } " , funsor. bint (num_components))
x_vars[t ] = funsor.Variable( f "x_{t } " , funsor.reals(hidden_dim))

# incorporate discrete switching probability p( s_t
log_prob += dist .Categorical(trans_probs(s=s_vars[t − 1]), value=s_vars[t])

| s_{ t−1})

# incorporate continuous
if

t == 0:
log_prob += x_init_dist (value=x_vars[t])

transition

probability p(x_t

| x_{t−1}, s_t )

else:

log_prob += x_trans_dist(s=s_vars[t ], x=x_vars[t − 1], y=x_vars[t ])

# do a moment−matching reduction of latent variables from L time steps in the past
# [ i . e . we retain a running (L+1)−length window of latent variables throughout
if

t > L − 1:
log_prob = log_prob.reduce(ops.logaddexp, {s_vars[t − L].name, x_vars[t − L].name})

the for loop]

# incorporate observation probability p(y_t
log_prob += y_dist(s=s_vars[t ], x=x_vars[t ], y=y)

| x_t , s_t )

T = data.shape[0]
for t in range(L):

log_prob = log_prob.reduce(ops.logaddexp, {s_vars[T − L + t].name, x_vars[T − L + t].name})

return log_prob

Figure 21: funsor code for the computation of the log marginal probability log p(y1:T ) for the SLDS model in Sec. 6.3.

Functional Tensors for Probabilistic Programming

Figure 22: One week of forecasted (pink region) and true (black line) trafﬁc for the San Francisco international airport station and
Embarcadero station. Forecast regions are 10% and 90% percentiles, and should bound the truth roughly 80% of the time. Note total
arrivals-to and departures-from any one station are much larger than trafﬁc between a single pair of stations. See Sec. D.5 for details.

Functional Tensors for Probabilistic Programming

def model(features, trip_counts) :
total_hours = len(features)
observed_hours, n, n = trip_counts.shape
gate_rate = funsor.Variable( "gate_rate_t", reals(observed_hours, 2 ∗ n ∗ n))[ "time"]

@funsor.torch.function(reals(2 ∗ n ∗ n), ( reals(n, n, 2), reals(n, n)) )
def unpack_gate_rate(gate_rate):

batch_shape = gate_rate.shape[:−1]
gate, rate = gate_rate.reshape(batch_shape + (2, n, n)).unbind(−3)
gate = gate.sigmoid().clamp(min=0.01, max=0.99)
rate = bounded_exp(rate, bound=1e4)
gate = torch.stack((1 − gate, gate), dim=−1)
return gate, rate

# Create a Gaussian latent dynamical system .
init_dist , trans_matrix,

trans_dist , obs_matrix, obs_dist = \

nn_dynamics(features[:observed_hours])
init = dist_to_funsor( init_dist ) (value="state")
trans = matrix_and_mvn_to_funsor(trans_matrix, trans_dist,

obs = matrix_and_mvn_to_funsor(obs_matrix, obs_dist,

( "time" ,) , "state" , "state(time=1)")

( "time" ,) , "state (time=1)", "gate_rate")

# Compute dynamic prior over gate_rate .
prior = trans + obs(gate_rate=gate_rate)
prior = MarkovProduct(ops.logaddexp, ops.add,

prior , "time", { "state" : "state (time=1)"})

prior += init
prior = prior .reduce(ops.logaddexp, {"state", "state(time=1)"})

# Compute zero−inﬂated Poisson likelihood .
gate, rate = unpack_gate_rate(gate_rate)
likelihood = fdist .Categorical(gate[" origin " , "destin" ], value="gated")
trip_counts = tensor_to_funsor(trip_counts, ( "time", " origin " , "destin" ) )
likelihood += funsor.Stack("gated", (

fdist .Poisson(rate[" origin " , "destin" ], value=trip_counts),
fdist .Delta(0, value=trip_counts)))

likelihood = likelihood .reduce(ops.logaddexp, "gated")
likelihood = likelihood .reduce(ops.add, {"time", " origin " , "destin" })

return prior + likelihood

Figure 23: Funsor computation of the generative model in ridership forecasting Sec. D.5. Here nn_dynamics(−) is the model’s neural
network. Note that @funsor.torch.function combines the lifting operator (cid:98)f with variable substitution, and is used to lift a Python/PyTorch
function to a funsor with one free variable for each function argument. Note also the use of the take(-,-) operator described in Example 1,
used to change the shape of funsors like rate [" origin ", "destin "] , where the symbols “origin” and “destin” are coerced to Variable
funsors. We use helpers like matrix_and_mvn_to_funsor to convert between PyTorch distribution objects and funsors.

Functional Tensors for Probabilistic Programming

def guide(features, trip_counts) :

observed_hours = len(trip_counts)
log_counts = trip_counts.reshape(observed_hours, −1).log1p()
loc_scale = (( nn_diag_part ∗ log_counts.unsqueeze(−2)).reshape(observed_hours, −1) +

nn_lowrank(torch.cat([features [: observed_hours], log_counts], dim=−1)))

loc , scale = loc_scale.reshape(observed_hours, 2, −1).unbind(1)
scale = bounded_exp(scale, bound=10.)

# Create a diagonal normal distribution .
diag_normal = dist.Normal(loc, scale).to_event(2)
return dist_to_funsor(diag_normal)(value="gate_rate_t")

Figure 24: Funsor computation of the collapsed variational inference model in ridership forecasting Sec. D.5. Here nn_diag_part is a
learnable parameter and nn_lowrank(−) is the guide’s neural network. We use helpers like dist_to_funsor to convert between PyTorch
distribution objects and funsors.

Functional Tensors for Probabilistic Programming

def elbo_loss(features, counts):

# Interpret
q = guide(features, counts)

the inference model exactly .

# Interpret
with interpretation (lazy) :

the generative model lazily .

p = model(features, counts)
pq = p − q

# Monte Carlo approximate the ELBO.
with interpretation (monte_carlo):

elbo = funsor. Integrate (q, pq, "gate_rate_t")

loss = −elbo
assert isinstance(loss, funsor.Tensor)
return loss.data

Figure 25: Funsor computation of the ELBO for variational in-
ference in ridership forecasting Sec. D.5. Note that here the user
interleaves three different interpretations: EXACT, LAZY, and
MONTECARLO.

