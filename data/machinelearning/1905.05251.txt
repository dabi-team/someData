9
1
0
2

y
a
M
6
2

]
L
P
.
s
c
[

3
v
1
5
2
5
0
.
5
0
9
1
:
v
i
X
r
a

Learning Scalable and Precise Representation
of Program Semantics

Ke Wang
Visa Research
Palo Alto, CA 94306
kewang@visa.com

Abstract

Neural program embedding has shown potential in aiding the analysis of large-scale,
complicated software. Newly proposed deep neural architectures pride themselves
on learning program semantics rather than superﬁcial syntactic features. However,
by considering the source code only, the vast majority of neural networks do not
capture a deep, precise representation of program semantics. In this paper, we
present DYPRO, a novel deep neural network that learns from program execution
traces. Compared to the prior dynamic models, not only is DYPRO capable of
generalizing across multiple executions for learning a program’s dynamic semantics
in its entirety, but DYPRO is also more efﬁcient when dealing with programs
yielding long execution traces. For evaluation, we task DYPRO with semantics
classiﬁcation (i.e. categorizing programs based on their semantics) and compared it
against two prominent static models: Gated Graph Neural Network and TreeLSTM.
We ﬁnd that DYPRO achieves the highest prediction accuracy among all models.
To further reveal the capacity of all aforementioned deep neural architectures, we
examine if the models can learn to detect deeper semantic properties of a program.
In particular given a task of recognizing loop invariants, we ﬁnd that DYPRO
outperforms all static models by a wide margin.

1

Introduction

“Big Code” emerged as a major line of research in the past decade. The idea is reusing the knowledge
distilled from existing code repositories in an attempt to simplify the future development of software.
Early methods applied NLP techniques to discover textual patterns existed in the source code [1; 2; 3];
following approaches opted to learn the syntactic program embedding from the Abstract Syntax Trees
(ASTs) [4; 5; 6]. Although these pioneering efforts manage to transform programs in an amenable
form to deep learning models, they only capture shallow, syntactic features and therefore are limited
in what they can do. For example, a model that recognizes the reoccurring syntactic patterns may be
sufﬁcient for a code completion task; but to conquer more sophisticated and challenging problems in
program synthesis or repair, thorough understanding and precise representations of program semantics
can not be circumvented. Of late, a number of new deep learning architectures have been developed to
speciﬁcally address this issue [7; 8; 9; 10]. Those works can be divided into two categories: dynamic
and static. The former learns from program executions [7; 8]. The latter dissects program semantics
from source code. As an example, Allamanis et al. [9] constructed a graph out of a program’s AST.
Subsequently they fed the graph to a Gated Graph Neural Network (GGNN) [11] for predicting
variable misuse bugs in a method.

In this paper, we present a novel deep neural architecture, DYPRO, that is capable of learning program
semantics from execution traces. DYPRO targets two major issues of the existing dynamic models.
First, how to learn the dynamic semantics of a program as a whole rather than individual executions;
second how to handle long execution traces that tend to hurt the generalization of underlying models.

Preprint. Under review.

 
 
 
 
 
 
For the ﬁrst challenge, we apply random testing, a powerful technique in software testing, to run
a program with a large number of inputs, each of which will trigger a separate execution trace.
DYPRO then learns an embedding for each execution before compressing them into one vector that
represents the semantics of the whole program. Regarding the second challenge, DYPRO employs a
bi-directional RNN to scan through an entire execution trace for ﬁltering out the steps that are less
essential to the trace. Our hope is DYPRO could still learn a precise representation of the program
semantics since the reduced traces would be likely to preserve the essence of the executions. More
importantly, such reduction helps DYPRO to handle longer traces more efﬁciently.

We create a dataset to thoroughly evaluate how precise DYPRO can capture the deep and rigid program
semantics. The dataset consists of almost eighty-ﬁve thousand programs each of which solves one of
ten coding problems. We pick the set of problems to cover a wide spectrum of difﬁculty levels ranging
from entry-level programming exercises to challenging algorithmic questions frequently appearing on
the coding interviews of major tech companies. The task is to classify programs in the dataset based
on their semantics. For example, given a sorting routine, our goal is to test if models can differentiate
among the algorithms that implement a sorting function (e.g. Bubble Sort and Insertion Sort shown
in Figure 1), an instance that in fact tricks all static models in our experiment. All programs in
the dataset have been manually inspected and labeled before hand. Results show DYPRO achieves
signiﬁcantly higher prediction accuracy than several prominent static models including GGNN, and
TreeLSTM. We also found out that as the size of execution traces grows, DYPRO suffers a smaller
drop in prediction accuracy than Dynamic State Trace Neural Network (DSTNN) [7].

We conduct a second study to further examine if models can learn to detect deeper semantic properties
of a program. Speciﬁcally, we choose loop invariants to evaluate all the above-mentioned deep neural
architectures. Our intuition is recognition of loop invariants poses signiﬁcant challenges to the model
capacity. An effective model, at a bare minimum, needs to capture a precise representation of the
program semantics; in addition it may also estimate the program properties derived from its semantics.
Note our goal is not to invent models for generating loop invariants [12] but predicting loop invariants
from a set of given properties. We use the classiﬁcation accuracy as a means to gauge how precise
and deep models have learnt the program semantics. Results show DYPRO is far more accurate in
predicting loop invariants than all static models. Our ﬁndings indicate DYPRO is the most precise
deep neural network in learning representations of program semantics.

static int Difference ( int [] a )
{

static int Difference ( int [] a )
{

// step 1: bubble sort the input array
int left = 0;
int right = a . Length - 1 ;

// step 1: insertion sort the input array
int left = 0;
int right = a . Length ;

for ( int i = right ; i > left ; i --) {
for ( int j = left ; j < i ; j ++ ) {

for ( int i = left ; i < right ; i ++ ) {

for ( int j = i -1 ; j >= left ; j --) {

if ( a [ j ] > a [ j + 1]) {
int tmp = a [ j ];
a [ j ] = a [ j + 1];
a [ j + 1] = tmp ;

if ( a [ j ] > a [ j + 1]) {
int tmp = a [ j ];
a [ j ] = a [ j + 1];
a [ j + 1] = tmp ;

}}}
// step 2: comput the largest difference
return a [ a . Length -1] - a [0];

}}}
// step 2: same as the left
return a [ a . Length -1] - a [0];

}

}

Figure 1: Two functions both compute the largest difference between two elements in a given array.
According to our evaluation, none of the static models recognize the semantic differences between
the two functions even though they apply distinct sorting routines: Bubble Sort and Insertion Sort.
Code highlighted in shadow box are the only syntactic differences between the two functions.

We make the following contributions:

• We design DYPRO, a novel deep neural architecture capable of learning dynamic program

semantics from execution traces.

• We evaluate DYPRO using a task of semantics classiﬁcation. Results show DYPRO achieves

the highest prediction accuracy among all competing models.

• We examine if models can learn to detect loop invariants. We ﬁnd DYPRO is signiﬁcantly

more accurate than all static models.

2

Figure 2: Architecture of DYPRO.

2 Background and Related Work

ML/DL for Source Code Hindle et al. [1] pioneered the ﬁeld of learning language models from
source code. A signiﬁcant ﬁnding of theirs is programs, similar to natural language, are highly
repetitive and predictable. With the rapid development of deep learning techniques and the increasing
accessibility of large scale open source code repository, many works begin to apply deep neural
networks to learn syntactic program representations [2; 3; 4; 5; 6]. More recently, a new line of
research emerges aiming to tackle the problem of learning semantic representation [7; 8; 9; 10].

Execution-Based Program Representation Neural program interpreter [13] is the ﬁrst deep neu-
ral network that deal with programs in the form of execution trace. The idea is to learn to synthesize
a sequence of low-level primitive operations for solving a high-level task such as addition and sorting.
Later Cai et al. propose an improvement [14] by addressing the NPI’s generalization issues. In
particular they replace loops with recursions that used to synthesize the low-level operations. Unlike
the prior attempts which still rely on the syntactical representation of execution traces, Wang et al.
[7] encode each step of the execution trace as a snapshot of the memory. Their intuition is such
processing, widely regarded as dynamic analysis in the ﬁeld of program analysis, leads to a direct and
concrete expression of program semantics. As a result, models can work with the program semantics
while totally detaching themselves from the program syntax. Furthermore, Wang et al. [7] deals with
real world programs, albeit mostly entry-level programming exercises, whereas the others work with
artiﬁcial programs written in low-level language.

In this paper, we choose state trace encoding scheme over variable trace encoding scheme for
better precision. State trace encoding scheme also enables a far more efﬁcient implementation in
DSTNN that is almost as accurate as Dependency Enforcement Network according to Wang et
al.’s evaluation [7]. We address two major weaknesses of DSTNN. First DSTNN learns semantic
representations for individual executions rather than a entire program; second DSTNN has difﬁculty
in handling programs yielding long execution traces.

Random Testing Random testing is a software testing technique where programs are tested by
generating random, independent inputs. Results of the output are compared against software spec-
iﬁcations to verify the test output is pass or fail. Alternatively, random testing can also be used to
catch the exceptions of the language (i.e. crashes) which means if an exception arises during testing
execution then it means there is a fault in the program.

Random testing is practical, effective that is shown to be able to achieve good coverage in a variety
of testing domains [15; 16]. As a result, it’s one of the most powerful and widely adopted testing
technique in software testing.

3 The Model Architecture of DYPRO

In a general description, DYPRO consists of two recurrent neural networks (RNN) and another
bi-directional RNN. Given the execution traces triggered by random testing, we encode each trace

3

into a sequence of program states. Speciﬁcally, a program state is a tuple of values based on the
variable valuations (i.e. the state of the memory). Each program state is created due to a memory
update issued by a statement/instruction. By collecting the history of memory updates occurred
during an execution, one can convert the trace into a sequence of program states. Formally, given a
program P , and its variable set V (v1, v2,..,vn ∈ V ), we encode St_e, the t-th program state in e-th
execution of P , to be (xt_e_v1 ,xt_e_v2 ,..,xt_e_vn ), where xt_e_vn is the value of variable vn in St_e.
Using this notation, we explain DYPRO’s working pipeline.

Embedding Program States Each program state will be embedded by RNN1 into a vector. Take
St_e for example, we feed the variable values (i.e. xt_e_v1 to xt_e_vn ) as a sequence to RNN1 and
extract its ﬁnal hidden state ht_e (Equation (1)) as the state embedding vector of St_e. ht_e_v1 ,..,ht_e
∈ Rk1 where k1 denotes the size of the hidden layer of RNN1. Note that we do not assume the
order in which variables values are encoded by RNN1 for each program state but rather maintain a
consistent order throughout all states for a given trace.

ht_e_v1 = RNN1(ht_e_v0 , xt_e_v1 ) ht_e_v2 = RNN1(ht_e_v1 , xt_e_v2 )...ht_e = RNN1(ht_e_vn−1 , xt_e_vn ) (1)

Improving DYPRO’s Scalability State reduction layer is dedicated to enhancing DYPRO’s re-
silience against programs yielding long execution trace. We describe its inner workings as follow.
After obtaining all the state embeddings, we feed them into a bi-directional RNN which aims to ﬁlter
out those that are less essential to the execution. Formally, let h1_e to hm_e denote the whole sequence
−−−→
Hm_e of
of state embedding vectors for e-th execution of P , we register the hidden vectors
←−−
H1_e
the forward one in the bi-directional RNN as deﬁned in Equation (2). Similarly we also extract
←−−−
Hm_e out of the backward RNN deﬁned in Equation (3). Next for each program state, we deﬁne
to
←−−
H1_e to
two context vectors to represent its prior and subsequent execution using
←−−−
Hm_e. For example, given embedding vector ht_e, we deﬁne the two context vectors Cf (ht_e) and
Cb(ht_e) in Equation (4). Finally we concatenate the context vectors with the state embedding vector
to determine if a program state should be retained or discarded. Speciﬁcally, we train a Multi-Layer
Perceptron1 (MLP) to produce a mask (Equation (5) where ⊕ denotes vector concatenation). Equation
(6) applies the mask on the program states; (cid:12) denotes element-wise matrix multiplication assuming
the broadcasting behavior. Our intention is to equip DYPRO with the capability of selecting program
states that are most essential to the execution while discarding others that somewhat recoverable.
←−−
H1_e,..,
denotes the size of the hidden
layer of the bi-directional RNN. M (ht_e) ∈ (0,1).

−−−→
Hm_e; Cf (ht_e); and Cb(ht_e) ∈ Rk

−−−→
Hm_e and

−−→
H1_e to

−−→
H1_e to

−−→
H1_e,..,

←−−−
Hm_e;

where k

(cid:48)

(cid:48)

−−→
H1_e = FR(
←−−
H1_e = BR(

−−→
H0_e, h1_e)
←−−
H0_e, hm_e)
−−→
H1_e,

−−→
H2_e = FR(
←−−
H2_e = BR(
−−→
H2_e, ..,

−−−−→
Ht−1_e)

−−→
H1_e, h2_e)
←−−
H1_e, hm−1_e)

...

...

−−−→
Hm_e = FR(
←−−−
Hm_e = BR(
←−−
H1_e,

Cb(ht_e) = pooling(

Cf (ht_e) = pooling(

−−−−−→
Hm−1_e, hm_e)
←−−−−−
Hm−1_e, h1_e)

←−−
H2_e, ..,

←−−−−−
Hm−t_e)

M (ht_e) = MLP(Cf (ht_e) ⊕ Cb(ht_e) ⊕ ht_e)

[h

(cid:48)

1_e;h

(cid:48)

2_e;..;h

(cid:48)

m_e] = [h1_e;h2_e;..;hm_e] (cid:12) [M (h1_e);M (h2_e);..;M (hm_e)]

(2)

(3)

(4)

(5)

(6)

Embedding Executions Given h
layer. Equation (7) computes h
(cid:48)(cid:48)
2_e,..,h
h
h

1_e = RNN2(h

0_e, h

1_e)

h

(cid:48)(cid:48)

(cid:48)(cid:48)

(cid:48)(cid:48)

(cid:48)(cid:48)

(cid:48)(cid:48)

(cid:48)

e ∈ Rk2 where k2 denotes the size of the hidden layer of RNN2.
2_e = RNN2(h

1_e, h

2_e)

...

h

(cid:48)(cid:48)

(cid:48)(cid:48)

(cid:48)

(cid:48)

(cid:48)

(cid:48)

1_e, h

2_e,...,h

e , the embedding vector that represents the whole execution. h

m_e, the state embeddings preserved by the previous
1_e,

(cid:48)(cid:48)

(cid:48)(cid:48)

m−1_e, h
e = RNN2(h
m
(cid:88)

q
(cid:88)

(cid:48)

m_e)

M (ht_e)

L = H +

(7)

(9)

hP = max_pooling(h

(cid:48)(cid:48)

1 , h

(cid:48)(cid:48)

2 , .., h

q )

(cid:48)(cid:48)

(8)

Embedding Programs Pooling layer is solely responsible for distilling the program representation
from all execution embeddings. Let h
q denote the embedding vectors for all executions of
P . Equation (8) computes the embedding vector of program P . hP ∈ Rk2 .

2 ,..,h

1 , h

(cid:48)(cid:48)

(cid:48)(cid:48)

(cid:48)(cid:48)

e=1

t=1

1with one single sigmoid output neuron.

4

Designing Loss Function The network is trained to minimize the cross-entropy loss on a softmax
over the semantic labels (denoted by H in Equation (9)) along with the sum of M (ht_e) w.r.t. all
program states among all executions of P . At a high-level, we force DYPRO to cut as many states
from each trace as possible provided that it can still maintain a high prediction accuracy.

4 Evaluation

We present the evaluation of DYPRO which begins with semantics classiﬁcation followed by the
detection of loop invariants.

4.1 Semantics Classiﬁcation

Dataset The dataset consists of 84,165 programs in total. They are obtained from a popular online
coding platform. Programs were written in several different languages: Java, C# and Python. All
programs solve a particular coding problem. We hand picked the problems to ensure the diversity
of the programs in the dataset. Speciﬁcally, it contains introductory programming exercises for
beginners, coding puzzles that exhibit considerable algorithmic complexity and challenging problems
frequently appearing on coding interviews. The dataset was manually analyzed and labeled. The
work was done by fourteen PhD students and exchange scholars at University of California, Davis. To
reduce the labeling error, we distributed programs solving the same coding problem mostly to a single
person and had them cross check the results for validation. The whole process took more than three
months to complete. Participants came from different research backgrounds such as programming
language, database, security, graphics, machine learning, etc. All of them were interviewed and tested
for their knowledge on program semantics. The labeling is on the basis of operational semantics (e.g.
bubble sort, insertion sort, merge sort, etc., for a sorting routine). We allow certain kind of variations
to keep the total number of labels manageable. For example, we ignore local variables allocated for
temporary storage, the iterative style of looping or recursion, the sort order: descending or ascending.
Readers are invited to consult the supplemental material for the descriptions of all coding problems
and the list of all labels.

To seek random inputs for producing the execution traces, we separate 100 programs for each coding
problem to apply random testing. In particular we ﬁrst generate N different inputs to execute each
program and then select top N (out of 100 ∗ N ) inputs that achieve the highest line coverage to be
the test cases for all programs. We remove programs that fail to pass all the test cases (i.e. crashes or
incorrect outputs) from the dataset. In the end we are left with 72,376 programs which we split into
a training set containing 52,376 programs, a validation set of 10,000 programs and a test set of the
remaining 10,000 programs (Table 1). Figure 3a depicts the cumulative percent distribution of all
traces by length. We calculate the average length of an execution trace to be 218 (median=192).

Benchmarks
Print Chessboard
Find Array Max Difference
Check Matching Parenthesis
Reverse a String
Sum of Two Numbers
Find Extra Character
Maximal Square
Maximal Product Subarray
Longest Palindrome
Trapping Rain Water
Total

Training Validation Testing
1,000
1,000
1,000
1,000
1,000
1,000
1,000
1,000
1,000
1,000
1,000
1,000
1,000
1,000
1,000
1,000
1,000
1,000
1,000
1,000
10,000
10,000

7,415
5,821
3,269
5,946
6,635
5,020
4,836
5,174
5,273
2,987
52,376

Table 1: Dataset used in semantics classiﬁcation.

Prediction Task Similar to the image classiﬁcation setting, models are required to predict the
category a program falls into based on its semantics. In other words, not only do models need to
classify which coding problem a program attempts to solve but also how the program solves it. We
adopt prediction accuracy and F1 score as the evaluation metrics.

5

(a) Traces distribution.

(b) Prediction (Accuracy).

(c) Prediction (F1 Score).

(d) Scalability (Accuracy).

(e) Coverage (Accuracy).

(f) Reduction (Accuracy).

(g) Scalability (F1 Score).

(h) Coverage (F1 Score).

(i) Reduction (F1 Score).

Figure 3: Evaluation Results.

Evaluation Subjects Apart from DYPRO, We select GGNN, arguably the state-of-the-art deep
neural network for learning source code. We also include TreeLSTM [17], one of the mostly applied
deep neural networks for learning data structure of trees, in our case the ASTs of programs.

Implementation We use Roslyn, IronPython and Eclipse JDT for parsing programs written in C#,
Python and Java. All models are implemented in Tensorﬂow. Before training, we have uniﬁed as
many hyperparameters as possible across all models such as the number of recurrent layers: 1; the
number of hidden unit in the recurrent layer: 100; the embedding dimensions for each input token:
100; the optimizer: the Adam algorithm; the maximum value for normalizing the gradient when
clipping: 0.9, etc. We use two Red Hat Linux servers each of which host two Tesla V100 GPUs (of
32GB GPU memory). Training DYPRO took the longest: approximately 48 hours in total while all
other models ﬁnished within three hours.

Results Figure 3b shows the prediction accuracy of all models. DYPRO leads the pack by almost
15%. TreeLSTM is barely above 60%. In terms of the F1 score, DYPRO also achieves better results
than all others (Figure 3c). Regarding scalability, Figure 3d (resp. 3g) depicts how DYPRO’s prediction
accuracy (resp. F1 score) vary with the size of execution traces. As a baseline for comparison, we
re-implemented DYPRO without the state reduction layer. Results show as the number of program
states reaches two hundred, DYPRO starts to outperform the baseline conﬁguration, especially the
gap grows to be approximately 10% in accuracy (resp. 0.1 in F1 score) for traces of ﬁve hundred
program states. To measure DYPRO’s capability of compressing execution traces, we ﬁnd on average
DYPRO discarded 27% (median=26%) of the program states for each execution trace among all
testing programs. Finally we investigate the inﬂuence of code coverage on DYPRO’s prediction.
According to Figure 3e and 3h, when N is initialized to 10, we begin with on average 64% line
coverage (among all programs in the test set), where DYPRO already outperforms all static models
in both prediction accuracies and F1 score, albeit by a small margin. As N continues to grow,
line coverage monotonically increases. So does DYPRO’s prediction accuracy and F1 score. After

6

N=60, additional test inputs produce no further improvement beyond 96% line coverage. Overall we
demonstrate random testing lays a good foundation for DYPRO.

Analysis To investigate the cause of inaccuracies, we look into the misclassiﬁcations static models
produced. In general, we see two common classes of errors. First as brieﬂy mentioned in Section 1,
when given syntactically similar programs in Figure 1, static models struggle to differentiate their
semantic differences. This type of mistakes indicates the insufﬁciency of the underlying program
representation w.r.t. the provided model capacity. Similarly, when programs are written in vastly
different syntax, static models have difﬁculty in recognizing the same semantics programs denote.2
Our ﬁndings indicate that static models still largely generalize at the level of program syntax. Although
certain semantic features can be learnt, their generalization will result in imprecise modeling of
program semantics. In contrast, DYPRO correctly classiﬁed all example programs, especially the
syntactic variations that hindered static models are automatically canonicalized by the executions.
This observation gives rise to a hypothesis—that is, due to the uniﬁcation of syntactic discrepancies
by the runtime execution, we expect DYPRO to present a similar capacity with the static models
despite learning from a smaller set of training data. To conﬁrm this hypothesis, we conduct another
experiment in which we randomly remove programs from the original training set. As depicted in
Figure 3f and Figure 3i, using approximately 70% of the training data, DYPRO is almost as accurate
as the static models.

However, DYPRO can also be inaccurate at times for the following reasons. Although reducing
program states beneﬁts DYPRO overall, it also causes DYPRO to misclassify which it otherwise
wouldn’t. By simply removing the state reduction layer, DYPRO remedies more than 10% of the
misclassiﬁcations. On the other hand, 31% of the misclassiﬁcations are due to programs yielding long
execution traces (i.e. more than eight hundred program states) indicating DYPRO still has difﬁculties
in generalizing longer traces. This phenomenon necessitates the split of the problem into smaller
ones which can be solved with separate tactics. In particular, when given shorter traces, DYPRO may
chose to skip the state reduction layer and take the trace in its entirety to prioritize the precision of the
learning. On the contrary, for much longer traces, DYPRO can be more aggressive in trace reduction
since trading precision for scalability is generally worthwhile as shown in this experiment.

4.2 Detection of Loop Invariants

As a more challenging task, we evaluate if models can recognize loop invariants — properties of
loops that are true before (and after) each iteration — from a set of program expressions. Worth
noting in this paper we do not formally infer loop invariants which requires extra functionality such
as search or logic deduction. Instead, our rationale is given deeper program properties like loop
invariants, a capable model not only would understand the program semantics, but may also “infer”
the properties determined by the semantics. In other words, a model with high prediction accuracy is
a testament to its capability of learning deep and precise representation of program semantics.

Data Preparation In order to reuse the dataset introduced in Section 4.1, we need to ﬁnd loop
invariants as our training labels. Here is our methodology. For each program in the dataset, ﬁrst we
use Daikon [18] to propose the likely loop invariants in each loop. Since Daikon’s output forms a
speciﬁcation from the view of a client for each procedure, it does not produce invariants for local
variables, neither does it within a procedure. To address the issue, we convert all local variables within
a loop to be members of the class; in addition we insert a dummy procedure both at the beginning and
end of the loop that takes in all the variables. The dummy procedure’s pre- and post-conditions will
be identical and will represent the potential loop invariants. To formally verify Daikon’s proposal,
we inject Contracts.Assert statements for each candidate invariant at the beginning and end of
the loop. We then invoke the static checker provided by the Microsoft Code Contract Utility [19]
to perform the formal veriﬁcation (we made our best efforts to translate programs written in Java
and Python to C#). Any loop invariant that can not be proved, albeit may still be legitimate, will be
removed from the dataset. After obtaining loop invariants for positive examples, we also generate
negative examples to balance the dataset. In particular, we exhaustively mutate loop invariants at
the token level and pick a mutant that is conﬁrmed to be a non-invariant (via random testing) as a
negative example. Take the program in Figure 4 for example, after max >= diff is veriﬁed to be an
loop invariant for the inner loop, we mutate the binary operator >= to generate a negative example
max > diff. Due to the limited power of the static checker, we collected 14,412 formally veriﬁed

2We have provided several examples in the supplemental material.

7

static int Difference ( int [] a ) {

int max = 0;

for ( int i = 0; i < a . Length -1; i ++) {

for ( int j = i + 1; j < a . Length ; j ++) {
int diff = Math . Abs ( a [ i ] - a [ j ]);
max = Math . Max ( max , diff );

}}

return max ;

Models
GGNN
TreeLSTM

Accuracy
47.5%
51.8%

F1 Score
0.47
0.50

DYPRO

73.9%

0.71

}
Figure 4: Example program for detecting loop
invariants.

Table 2: Classiﬁcation results for all models in
detecting loop invariants.

loop invariants out of 9,663 loops. Along with the same number of non loop invariants, we split them
into a training set of 20,824, a validation set of 4,000 and a test set of the remaining 4,000.

Model Design We adapt the existing models to detect loop invariants. To establish a fair comparison,
we adopt a uniﬁed architecture across all deep neural networks. Speciﬁcally, given a program along
with the candidate invariants, we concatenate the program embedding with the invariants embeddings
before feeding the concatenations to the prediction layer. At a lower-level, we extract embeddings
of root nodes in ASTs to be the program embeddings for GGNN and TreeLSTM. Regarding loop
invariants, we feed the token sequences (in the vector format according to the embedding matrix of
the vocabulary) into another RNN from which we extract the ﬁnal hidden states to be the invariant
embeddings. Tailoring DYPRO towards the uniﬁed architecture is slightly more involved. First, to
embed loop invariants as explained above, we incorporate their syntactic tokens that are ignored
by the state encoding scheme into DYPRO’s vocabulary. Next, for variables appearing in loop
invariants, we inform DYPRO of their values along each step of the execution. In particular, we inject
the embeddings of the variable Ids to that of their values in each program state. We keep the rest
of DYPRO’s architecture intact and extract the program embeddings from the pooling layer. We
experiment two loss functions: cross-entropy loss and hinge loss, and ﬁnd the latter gives better
results for all models. As depicted in Table 2, DYPRO outperforms all static models by a wide margin.
This strongly indicates DYPRO is capable of learning deeper semantic properties from executions. On
the contrary, by considering the source code only, static models fail to learn any plausible mapping
from the syntactic features to the semantic properties which further conﬁrms static models only
capture simple, and shallow semantic features.

4.3 Remarks

Through two experiments, we have thoroughly demonstrated how DYPRO stacks up against the
static models. To summarize, despite the considerable progress, static models are still limited in
learning semantic representation of a program. It is evident their generalization mostly happens
at the level of program syntax, manifested in their struggle of digging deeper semantic properties.
In comparison to the static models, DYPRO learns from executions, a more direct and concrete
expression of program semantics. To elevate the learning from the level of executions to programs,
DYPRO learns a representation for each individual execution obtained via random testing before
compressing them into a compact program representation. To deal with long execution traces, we
equip DYPRO with the state reduction mechanism so it only generalizes from the key program states
while discarding the peripherals. Also worth noting, even if we did not demonstrate the utility of
DYPRO in speciﬁc problem settings, given its strong capability of learning scalable and precise
representation of program semantics, DYPRO should be readily applicable to many downstream
programming tasks such as bug prediction or patch generation.

5 Conclusion

In this paper, we propose DYPRO, a novel deep neural architecture that learns program semantics
from execution trace. We thoroughly evaluate DYPRO in a couple of semantically related tasks
including head-to-head comparisons against several prominent static models. Results show DYPRO
is the most accurate in both tasks and more importantly can capture deep semantic properties that
static models struggle with. For future work, we will deploy DYPRO to speciﬁc problem settings.
Due to its high efﬁciency and precision in representing the program semantics, we expect DYPRO to
be useful in those settings too.

8

References

[1] Abram Hindle, Earl T Barr, Zhendong Su, Mark Gabel, and Premkumar Devanbu. On the
naturalness of software. In Software Engineering (ICSE), 2012 34th International Conference
on, pages 837–847. IEEE, 2012.

[2] Rahul Gupta, Soham Pal, Aditya Kanade, and Shirish Shevade. Deepﬁx: Fixing common c

language errors by deep learning. 2017.

[3] Yewen Pu, Karthik Narasimhan, Armando Solar-Lezama, and Regina Barzilay.

sk_p: a
neural program corrector for moocs. In Companion Proceedings of the 2016 ACM SIGPLAN
International Conference on Systems, Programming, Languages and Applications: Software for
Humanity, pages 39–40. ACM, 2016.

[4] Chris Maddison and Daniel Tarlow. Structured generative models of natural source code. In

International Conference on Machine Learning, pages 649–657, 2014.

[5] Pavol Bielik, Veselin Raychev, and Martin Vechev. Phog: probabilistic model for code. In

International Conference on Machine Learning, pages 2933–2942, 2016.

[6] Lili Mou, Ge Li, Lu Zhang, Tao Wang, and Zhi Jin. Convolutional neural networks over tree

structures for programming language processing. 2016.

[7] Ke Wang, Rishabh Singh, and Zhendong Su. Dynamic neural program embedding for program

repair. arXiv preprint arXiv:1711.07163, 2017.

[8] Jordan Henkel, Shuvendu Lahiri, Ben Liblit, and Thomas Reps. Code vectors: Understanding
programs through embedded abstracted symbolic traces. arXiv preprint arXiv:1803.06686,
2018.

[9] Miltiadis Allamanis, Marc Brockschmidt, and Mahmoud Khademi. Learning to represent

programs with graphs. arXiv preprint arXiv:1711.00740, 2017.

[10] Daniel DeFreez, Aditya V. Thakur, and Cindy Rubio-González. Path-based function embeddings.
In Proceedings of the 40th International Conference on Software Engineering: Companion
Proceeedings, ICSE ’18, pages 430–431, New York, NY, USA, 2018. ACM. ISBN 978-1-4503-
5663-3. doi: 10.1145/3183440.3195042. URL http://doi.acm.org/10.1145/3183440.
3195042.

[11] Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. Gated graph sequence neural

networks. arXiv preprint arXiv:1511.05493, 2015.

[12] Xujie Si, Hanjun Dai, Mukund Raghothaman, Mayur Naik, and Le Song. Learning loop
invariants for program veriﬁcation. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman,
N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems
31, pages 7751–7762. Curran Associates, Inc., 2018. URL http://papers.nips.cc/paper/
8001-learning-loop-invariants-for-program-verification.pdf.

[13] Scott Reed and Nando De Freitas. Neural programmer-interpreters.

arXiv preprint

arXiv:1511.06279, 2015.

[14] Jonathon Cai, Richard Shin, and Dawn Song. Making neural programming architectures

generalize via recursion. arXiv preprint arXiv:1704.06611, 2017.

[15] J. W. Duran and S. C. Ntafos. An evaluation of random testing. IEEE Transactions on Software

Engineering, 1984.

[16] Priyam Patel, Gokul Srinivasan, Sydur Rahaman, and Iulian Neamtiu. On the effectiveness
of random testing for android: Or how i learned to stop worrying and love the monkey. In
Proceedings of the 13th International Workshop on Automation of Software Test, AST ’18,
pages 34–37. ACM, 2018. ISBN 978-1-4503-5743-2. doi: 10.1145/3194733.3194742. URL
http://doi.acm.org/10.1145/3194733.3194742.

[17] Kai Sheng Tai, Richard Socher, and Christopher D. Manning. Improved semantic representations
from tree-structured long short-term memory networks. CoRR, abs/1503.00075, 2015. URL
http://arxiv.org/abs/1503.00075.

9

[18] Michael D Ernst, Jeff H Perkins, Philip J Guo, Stephen McCamant, Carlos Pacheco, Matthew S
Tschantz, and Chen Xiao. The daikon system for dynamic detection of likely invariants. Science
of computer programming, 69(1-3):35–45, 2007.

[19] Manuel Fähndrich and Francesco Logozzo. Static contract checking with abstract interpretation.
In International Conference on Formal Veriﬁcation of Object-oriented Software, pages 10–30.
Springer, 2010.

10

