1
2
0
2

p
e
S
2
2

]
I
S
.
s
c
[

1
v
7
3
9
0
1
.
9
0
1
2
:
v
i
X
r
a

Proceedings of Machine Learning Research vol 132:1–31, 2022

Temporal Scale Estimation for Oversampled Network Cascades:
Theory, Algorithms, and Experiments

Abram Magner
University at Albany, SUNY

Carolyn Kaminski
University at Albany, SUNY

Petko Bogdanov
University at Albany, SUNY

AMAGNER@ALBANY.EDU

CKAMINSKI@ALBANY.EDU

PBOGDANOV@ALBANY.EDU

Abstract
Spreading processes on graphs arise in a host of application domains, from the study of online
social networks to viral marketing to epidemiology. Various discrete-time probabilistic models for
spreading processes have been proposed. These are used for downstream statistical estimation and
prediction problems, often involving messages or other information that is transmitted along with
infections caused by the process. It is thus important to design models of cascade observation that
take into account phenomena that lead to uncertainty about the process state at any given time.
We highlight one such phenomenon – temporal distortion – caused by a misalignment between the
rate at which observations of a cascade process are made and the rate at which the process itself
operates, and argue that failure to correct for it results in degradation of performance on downstream
statistical tasks. To address these issues, we formulate the clock estimation problem in terms of a
natural distortion measure. We give a clock estimation algorithm, which we call FastClock, that
runs in linear time in the size of its input and is provably statistically accurate for a broad range of
model parameters when cascades are generated from the independent cascade process with known
parameters and when the underlying graph is Erd˝os-R´enyi. We further give empirical results on
the performance of our algorithm in comparison to the state of the art estimator, a likelihood proxy
maximization-based estimator implemented via dynamic programming. We ﬁnd that, in a broad
parameter regime, our algorithm substantially outperforms the dynamic programming algorithm in
terms of both running time and accuracy.
Keywords: independent cascade, spreading processes, estimation, contagion, diffusion, temporal
resolution

1. Introduction

There are a variety of well-established and simple probabilistic generative models for graphs and
and infectious processes that run over these graphs. In this work we speciﬁcally focus on models for
spreading processes on networks such as the diffusion of innovation Montanari and Saberi (2010),
information Bakshy et al. (2012) and misinformation Shin et al. (2018) in social networks. Accurate
estimation of model parameters of such processes based on observational data is essential for a
variety of important applications: from product marketing and social network recommendations
to studying ﬁnancial markets and detecting insurgent networks and limiting misinformation. At
the same time, accurate modeling critically depends on our ability to account for major sources of
uncertainty induced by the manner in which observational data about such evolving processes is
acquired.

© 2022 A. Magner, C. Kaminski & P. Bogdanov.

 
 
 
 
 
 
NETWORK CASCADE TEMPORAL SCALE ESTIMATION

Discrete-time diffusion process models. Several well-studied information diffusion models as-
sume a discrete timeline in which at every time step nodes participate in the diffusion process (i.e.,
get “infected”) based on inﬂuence from network neighbors who got infected in past time steps. For
example, according to the independent cascade model Kempe et al. (2003) infected nodes have one
chance to infect their neighbors, while in the linear threshold model nodes get infected when a
critical fraction of their neighbors have been infected in any prior time steps.

It is important for our subsequent discussion to note what “discrete-time” means in the context
of a process running in the real world, about which we would like to draw statistical inferences
based on observations at potentially arbitrary physical time points. We think of a diffusion process
as running in continuous time, so that, in principle, a vertex infection may occur at any t ∈ R.
A discrete-time process model posits the existence of a sequence of (possibly random) time steps
0 ≤ τ0 < τ1 < ..., τj ∈ [0, ∞), and speciﬁes the probability distribution of the process state at each
time τj+1 conditioned on the state of the process at time τj. Each such conditional distribution is
invariant to the actual values of the τj. In this sense, we can think of a discrete-time process model
as a partial speciﬁcation of a continuous-time process model whose state evolves according to a
discrete-valued variable.

The need to account for temporal distortion. One major source of uncertainty that is over-
whelmingly overlooked in current literature is a misalignment of time points at which we observe
a discrete-time process trajectory with the time points at which the state variables governing the
process evolve. Here, an observation of a process at a particular time consists of the current state
(infected or not) of every node. The aforementioned misalignment may be, for example, due to
drawing observations at a higher rate than that at which the cascade process itself operates. This
leads to what we call temporal distortion in process observations. Correcting for this distortion is
the main focus of this paper. We illustrate this phenomenon with a concrete example, Example 1,
that shows the deleterious effect of uncorrected temporal distortion on a downstream statistical es-
timation task.

Example 1 (Temporal distortion affects downstream statistical inference)

Consider a cascade generated by the independent cascade model Kempe et al. (2003) on a
graph G with n vertices, with edge transmission parameter pn = 1 and probability of infection
from an external source pe = 0. Assume that G is a complete binary tree and that the infection
starts at the root node. We recall that this model runs in discrete time, with physical timesteps
t0 = 0 < t1 < ... < tN , with tj ∈ R for all j, producing infected vertex sets Sj ⊆ [n] = {1, ..., n},
for each j ∈ {0, ..., N }. That is, Sj is the set of vertices infected in the physical time interval
(tj−1, tj]. In each time interval (tj−1, tj], the set of active vertices (those vertices that can transmit
infections across edges) is Sj−1. Let us suppose that the infection times of vertices infected in a
given time interval are uniformly distributed in that interval. For this example, we choose physical
observation times t(cid:48)
for each j. Thus, our
view of the cascade consists of a sequence of infected sets ˆSj, j ∈ {0, 1, ..., 2N + 1}.

2j+1 = tj +tj+1

2j = tj and t(cid:48)

2N +1 with t(cid:48)

0 = 0, t(cid:48)

1, ..., t(cid:48)

2

Consider the problem of doubling time prediction: given cascade observations up to/including
a time t ∈ R in which m vertices are infected, the task is to predict an interval [a, b] such that, with
probability at least 1 − δ, for some ﬁxed parameter δ > 0, the physical time of the 2m-th infection
event lies in [a, b].

If temporal distortion is not accounted for, so that we incorrectly assume that the process
j, we have an inaccurate knowledge of the set of active vertices at

timesteps occur at times t(cid:48)

2

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

k=0 2k + 22j+1 = 22j+1 + 22j+1−20

any given time. This has the following effect on doubling time prediction at times t = t(cid:48)
2j+1:
at these times, approximately (cid:80)2j
2j+1 + 22j+1 =
22j+1 · (1 + O(1/j)) vertices are infected, and we believe that approximately 22j+1 vertices are
active (when, in fact, only O(22j/j) = o(22j+1) vertices are active). We would thus predict that
the doubling time is exactly t(cid:48)
2(j+1), despite the fact that the number of vertices infected at this time
is exactly (cid:80)2(j+1)
j+1 (cid:28) 22j+2. Thus, failure to account for
temporal distortion in this setting leads to substantial and, in this setting, avoidable inaccuracy.

2j+1−0 = 22j+1−1

2j+2 = 22j+2−1

2k = 22(j+1)+1−20

= 22j+3−1

2j+2

k=0

More realistic empirical experiments in DiTursi et al. (2017, 2019) conﬁrm that accounting for
temporal distortion can, in practical settings, improve performance on doubling time prediction and
several other downstream statistical tasks.

More generally, temporal distortion degrades statistical performance on problems where model
parameters are dependent on knowledge of the infectious sets of vertices (the so-called active ver-
tices mentioned in the example) at given times. Correction for temporal distortion, which is the
main focus of the present paper, is thus an important problem.

Prior work. The general topic of analysis of cascades has received a large amount of attention,
both from theoretical and empirical perspectives. There are many cascade models, with features
depending on application domains. E.g., the independent cascade (IC) and linear threshold (LT)
models were popularized in Kempe et al. (2003) for the application of inﬂuence maximization. This
problem continues to be studied Lee et al. (2016); Abbe et al. (2017). Variations on the inﬂuence
maximization problem that have time-critical components and, thus, may be sensitive to temporal
perturbation in the sense that we study here, have also been studied Chen et al. (2012); Ali et al.
(2019). These models are also used outside the context of inﬂuence maximization, e.g., in the
modeling of the spread of memes on social networks Adamic et al. (2016).

Statistical prediction tasks involving cascades have also been asked. For instance, the cascade
doubling time prediction task was considered in Cheng et al. (2014). Other works propose models
in which a piece of information, such as a message, an opinion, or a viral genome, is transmitted
along with the infection of a node Eletreby et al. (2020); De et al. (2016); Park et al. (2020). For
such statistical problems, statistical inferences about the transmitted information can be disrupted
by inaccurate estimation of the set of infectious vertices at a given time, further motivating the
consideration of methods for correcting for temporal distortion.

In DiTursi et al. (2017) (see also followup work in DiTursi et al. (2019)), the authors formulated
a version of the problem of clock recovery (equivalent to temporal distortion correction studied here)
from adversarially temporally perturbed cascade data as a problem of maximization of a function of
the clock that serves as a proxy (in particular, an upper bound) for the log likehood of the observed
cascades. They proposed a solution to this problem via a dynamic programming algorithm. While
the dynamic programming algorithm is an exact solution to their formulation of the problem, it has
a running time of Θ(n4), where n is the total number of vertices in the graph on which the observed
cascade runs, which is prohibitively expensive for graphs of moderate to large size. Furthermore,
their formulation of the problem makes no comparison with the ground truth clock, and thus there
are no theoretical guarantees or empirical evaluations of the accuracy of their estimator (which
we call the maximum likelihood proxy (MLP) estimator) as an approximation to the ground truth
clock. In contrast, the present work gives a rigorous formulation of the problem as one of statistical

3

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

estimation of the ground truth clock from observed cascades. We compare our proposed algorithm
and estimator with the MLP estimator in this framework in terms of both accuracy and running time.

Our contributions
In the present work, we propose an approximation formulation of the clock
recovery problem, allowing us to quantify the proximity of estimated clocks to the ground truth
in a principled manner. Our formulation is general, covering arbitrary varying observation rates.
However, our algorithms, theorems, and experiments are speciﬁc to the oversampling case, wherein
observations are made at a higher rate than that at which the spreading process operates. We leave
estimators for the more complicated general case to future work.

We propose a novel estimation algorithm, which we call FastClock, that runs in time linear in
the size of the cascade. We rigorously prove that, under natural conditions on the input graph and
cascade parameters, the FastClock estimator produces a clock whose distance to the ground truth is
vanishingly small as the size of the graph tends to inﬁnity. Our guarantees on FastClock hold for a
broad range of the parameter of the Erd˝os-R´enyi graph model.

We bolster our theoretical results via experiments on synthetic graphs and cascades. We ﬁnd
that the FastClock estimator empirically outperforms the dynamic programming-based estimator
from DiTursi et al. (2017) in these experimental conditions in terms of accuracy and running time.

Organization of the paper
In Section 2, we give a precise formulation of the problem and in-
troduce notation. In Section 3, we state the FastClock algorithm and the main theoretical results.
We give proof sketches (and, where noted, full proofs) in Section 4. Section 5 gives empirical re-
sults comparing FastClock and the DP algorithm implementing the MLP estimator. We conclude in
Section 6. Full proofs of all results are given in the appendix.

2. Problem formulation and notation

Our goal in this section is to formulate the problems of clock estimation and spreading process
history reconstruction from a temporally perturbed cascade observation. As mentioned in the in-
troduction, our formulation is quite general and covers temporal distortion arising from arbitrarily
varying observation rates. Since this general case is algorithmically and statistically more compli-
cated (in particular, while our proposed algorithm succeeds at clock estimation, the more relevant
problem of history reconstruction is more difﬁcult), we then focus on the oversampling case. In this
case, our general problem formulation can be replaced by a simpler one, and the two problems of
clock estimation and spreading process history reconstruction become equivalent.

2.1. General formulation

We ﬁx a graph G on the vertex set [n] = {1, ..., n}, and we deﬁne the timeline of length N , for
any number N ∈ N, to be the set [[N ]] = {0, 1, ..., N }. The ﬁrst ingredient of our framework is a
cascade model.

Deﬁnition 1 (Cascade model) A (discrete-time) cascade model C(N ) is a probability distribution
on sequences (S0, S1, ..., SN ) of disjoint subsets of vertices of G. We think of St, t ∈ {0, ..., N } as
the set of vertices infected in timestep t. We call any such sequence an infection sequence, and we
write |S| = N + 1.

As mentioned in the introduction, we think of a discrete-time cascade as running in continuous,
physical time, so that the jth timestep begins at some physical time tj−1 and ends at physical time

4

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

tj, and every vertex v ∈ Sj is infected at some physical time in the interval (tj−1, tj]. Note, however,
that physical times are not formally part of the logical framework, and our models have no explicit
dependence on them. We introduce them only to aid intuition.

Next, we deﬁne our observation model, which formalizes our notion of temporal perturbations.
To do this, we need the notion of a clock. Intuitively, a clock encodes the number of observations
of the cascade made during each cascade timestep. For us, an observation of a cascade at some
physical time t consists of the set of nodes that have been infected at or before time t. We will talk
about the kth observation to occur, k ≥ 0, as having index k.

Deﬁnition 2 (Clock) A clock C on a timeline [[N ]] is a map C : [[N ]] → Z≥0. Equivalently, it is
a tuple of N + 1 non-negative integers (C(0), ..., C(N )), where C(j) intuitively gives the number
of observations made in the physical time interval (tj−1, tj]. The size |C| of C is given by

|C| =

N
(cid:88)

j=0

C(j).

(1)

It will be convenient to introduce more notation regarding clocks:

• For a clock C, let the jth partial sum of C be given by (cid:80)j

k=0 C(k), and denote it by C(0 : j).

This is the number of observations made prior to the jth cascade timestep.

• Let MC : [[N ]] → 2[[N (cid:48)]] be given as follows: MC(j) = {C(0 : j − 1) + 1, ..., C(0 : j)}.
In other words, MC(j) is the set of observation indices that occur during the time interval
(j − 1, j], according to C.

The following deﬁnition captures the notion of an infection sequence S(cid:48) that could arise from

observing a ground truth infection sequence S according to a schedule dictated by a clock C.

Deﬁnition 3 (Clock-consistent observation of an infection sequence) Fix two infection sequences
S = (S0, ..., SN ) and S(cid:48) = (S(cid:48)
N (cid:48)) and a clock C on [[N ]] with size |C| = N (cid:48). We say that
S(cid:48) is an observation of S that is consistent with C if, for each ground truth timestep t ∈ [[N ]],

0, ..., S(cid:48)

St =

(cid:91)

S(cid:48)
t(cid:48).

t(cid:48)∈MC (t)

(2)

In other words, S(cid:48)
by S, according to the schedule dictated by C.

j can be interpreted as encoding jth observation of the infection sequence given

As an easy consequence of this deﬁnition, if S(cid:48) is an observation of S consistent with any clock C,
then C is the unique clock for which this is true.

Example 2 (Infection sequences, clocks, clock-consistent observations) Consider a graph G on
the vertex set [n] = [10]. One possible infection sequence on G is

S = (S0, S1, S2) = ({2, 8, 10}, {1, 3, 4, 7, 9}, {6}).

(3)

5

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

This encodes a sequence of infections occurring in three timesteps – i.e., on the timeline [[2]]. In
particular, we may think of S1 as encoding that vertices 1, 3, 4, 7, 9 are all infected during timestep
1, but the order in which they are infected is not encoded.

One possible example clock on the timeline [[2]] is C = (C0, C1, C2) = (0, 4, 1). This encodes

that 0 observations are made in timestep 0, 4 are made in timestep 1, and 1 is made in timestep 2.
An example infection sequence ˆS that is an observation of S consistent with C is as follows:

ˆS = ( ˆS0, ˆS1, ˆS2, ˆS3, ˆS4) = ({2, 7, 8, 10}, {1, 9}, {3, 4}, {}, {6})

(4)

Note that ˆS is necessarily an infection sequence on the timeline [[0 + 4 + 1 − 1]] = [[4]].

We ﬁnally come to the deﬁnition of a temporal distortion model.

Deﬁnition 4 (Temporal distortion model) A temporal distortion model is a conditional probabil-
ity distribution P (· | S) on infection sequences, parameterized by infection sequences S (which we
think of as being the ground truth infection sequences), such that P (S(cid:48) | S) > 0 only if S(cid:48) is an
observation of S consistent with some clock.

In other words, a temporal distortion model is a probabilistic generative model for observations of
an infection sequence.

2.2. Specialization to the oversampling regime

In this work, we will focus without much further comment on oversampling temporal distor-
tion models, which are models resulting in observations according to clocks with C(j) > 0 for all
j. Intuitively, this covers the case where observations are made at a higher rate than that at which
the process itself operates. In the oversampling regime, we can simplify the deﬁnition of a clock:

Deﬁnition 5 (Clock (oversampling case)) A(n oversampling) clock C on the timeline [[N ]] with
size N (cid:48) + 1 is a partition of [[N (cid:48)]] into N + 1 subintervals. We call the jth such subinterval, for
j = 0 to N , the jth observation interval.

In the above deﬁnition, we think of [[N ]] as the ground truth timeline and [[N (cid:48)]] as the observa-
tion timeline. An oversampling clock partitions the observation timeline into subintervals, each
corresponding to a single ground truth timestep.

Example 3 (Oversampling clock) Consider the timeline [[5]] (here, N (cid:48) = 5). An example of an
oversampling clock is

This is equivalent to the following clock on [[2]], with N = 2, in the sense of Deﬁnition 2:

C = {[0, 2], [3, 3], [4, 5]}.

C = (3, 1, 2).

(5)

(6)

An infection sequence S naturally induces a partial order on the set of vertices: namely, for two
vertices a, b, a < b if and only if a ∈ Si, b ∈ Sj for some i < j. Similarly, a clock on an infection
sequence, in the sense of Deﬁnition 5, induces a partial order.

6

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

We will consider two clocks C0, C1 to be equivalent with respect to a given observed infec-
tion sequence S if they induce the same partial order. The reason for this is that two equivalent
clocks separate vertices in the same way into a sequence of time steps. We will sometimes abuse
terminology and use “clock” to mean “clock equivalence class”.

We next deﬁne a distortion function on clock equivalence classes. This will allow us to measure
how far a given estimated clock is from the ground truth. Note that given an observed infection
sequence S, a clock cannot reverse the order of any pair of events, so that the standard Kendall τ
distance between partial orders is not appropriate here.

Deﬁnition 6 (Distortion function on clock pairs) Consider two clocks C0, C1 with respect to an
observed infection sequence S. We deﬁne DisC0,C1(i, j) to be the indicator that the clocks C0 and
C1 order vertices i and j differently (i.e., that the partial order on vertices induced by Cb orders i
and j and the partial order induced by C1−b does not, for b equal to either 0 or 1). If the clocks in
question are clear from context, we may drop the subscript.

We deﬁne the following distortion measure on clock pairs:

dS(C0, C1) =

1
(cid:1)
(cid:0)n
2

(cid:88)

i<j

DisC0,C1(i, j).

(7)

We ﬁnally come to the general problem that we would like to solve:

Deﬁnition 7 (Clock estimation/Spreading process history reconstruction) Fix a graph G, a cas-
cade model C(G, T ), and an oversampling temporal distortion model T . An infection sequence
S ∼ C(G, T ) is generated on G. Finally, an observed infection sequence ˆS with | ˆS| = N + 1 is
generated according to T , with implicit clock C. Our goal is to produce an estimator ˆC = ˆC( ˆS) of
C so as to minimize E[d ˆS(C, ˆC)]. This is called the clock estimation problem.

We call the problem of estimating S the spreading process history reconstruction problem. An
estimated oversampling clock ˆC induces an estimate ˜S of S, so that clock estimation and spreading
process history reconstruction are equivalent in the oversampling case.

We note that the above deﬁnition implicitly assumes knowledge of the parameters of the cascade
model. Estimation of these parameters has been studied in the literature. Furthermore, we note
that knowledge of the initial conditions of the cascade is necessary in order to achieve an expected
estimation error that tends to 0 in general. We thus assume that the number of initially infected
vertices is given to us. Under mild additional assumptions on the model (e.g., that S0 consists of
Θ(1) vertices chosen uniformly at random, and that the graph is sparse, so that S0 is an independent
set with high probability), the initial set S0 can be inferred with high probability.

Speciﬁc cascade models. Having laid out the general framework for temporal distortion models,
we specify a few example cascade models for our problem. Our approach generalizes beyond these
two, as we will explain after the statement of our algorithm.

We ﬁrst deﬁne the independent cascade (IC) process. We ﬁx a graph G, an initial infection set
S0 of vertices in G (given by elements of [n] = {1, ..., n}), and probability parameters pn and pe.
Here, pn denotes the probability of transmission of an infection across an edge, and pe denotes the
probability of infection from an external source.

Step j + 1 of the IC process proceeds as follows: for each node v in Sj and each uninfected
neighbor w, v attempts to infect w, succeeding with probability pn, independent of anything else.

7

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

Next, each uninfected node is independently infected with probability pe. The set of nodes infected
in step j + 1 is denoted by Sj+1. The process terminates either after a speciﬁed number of steps,
after all nodes are infected, or when Sj+1 = ∅ and pe = 0.

The linear threshold (LT) process works as follows: for every node v in G, a threshold θv is
drawn independently from some known distribution on [0, 1]. Some initial subset S0 of vertices is
infected, and, in each subsequent timestep, vertex v is infected if either it has already been infected
or the fraction of its neighbors that are infected exceeds θv.

3. Main results: Algorithm, approximation and running time guarantees

In this section, we present our proposed algorithm (Algorithm 1) for clock estimation, which we
call FastClock. It takes as input a graph G, an observed infection sequence ˆS = ( ˆS0, ..., ˆSN ), and
the parameters θ of the cascade model, including the initial infection set S0 (see our discussion
of this assumption in the previous section). The output of the algorithm is an estimated clock ˆC,
which takes the form of a sequence of interval endpoints ˆt0, ˆt1, ..., ˆt ˆN ∈ [[N ]], for some ˆN and is
an estimate of the ground truth clock C speciﬁed by t0, ..., tN .

Our algorithm proceeds by iteratively computing the estimate ˆtj. In the (j + 1)-st iteration, to
compute ˆtj+1, it chooses the size of the next interval of the clock so as to match as closely as possible
the expected number of newly infected nodes in the next timestep. We will prove that the resulting
clock estimate is very close, in terms of d ˆS(·, ·), to the ground truth clock, using concentration
inequalities.

In particular, the correctness of FastClock is based on the following intuition: if we manage
to correctly estimate t0, ..., tj, then we can estimate the conditional expected number of vertices
infected in the (j + 1)-st timestep of the process (i.e., |Sj+1|). We can show a conditional concen-
tration result for |Sj+1| around its expectation. Thus, we output as our next clock interval endpoint
ˆtj+1 the smallest integer t ≥ ˆtj for which the number of vertices in (cid:83)t
ˆSt does not exceed
its conditional expectation, corrected by a small quantity. This quantity is determined by the con-
centration properties of the random variable |Sj+1| conditioned on the state of the process given by
ˆS0, ..., ˆSj. We choose the threshold to be such that, under this conditioning, the number of vertices
infected in the next process timestep is slightly less than it with probability tending exponentially
to 1. Our approximation analysis illustrate that the approximation quality depends on the graph
structure and the model parameters.

k=tj +1

The signiﬁcance of the approximation and running time results (Theorems 8 and 9 below) is
that oversampling temporal distortion under natural conditions can be quickly corrected for with
provably high accuracy using relatively simple expected value calculations. While our approxi-
mation theorem is formally stated for the IC model, the conclusions hold as long as the number
of infected nodes in the next cascade timestep, conditioned on the current state of the process, is
well-concentrated and as long as the expected number of such nodes is immune to small errors in
the estimation of the process state. These are both functions of the cascade model and of the struc-
ture of the graph G on which the cascade runs: our results hold when the graph is an expander
with appropriate parameters (which is implied by our Erd˝os-R´enyi stipulation in the approximation
theorem).

As long as the expected number of nodes infected in the next timestep can be calculated efﬁ-

ciently, the FastClock algorithm can be adapted to a wide variety of cascade models.

8

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

3.1. The FastClock algorithm

Before we deﬁne our algorithm we introduce some necessary notation. For an infection sequence
˜S and a timestep index t ∈ | ˜S|, deﬁne σt( ˜S) to be the σ-ﬁeld generated by the event that the ﬁrst
t infection sets of the cascade process are given by ˜S0, ˜S1, ..., ˜St. That is, the event in question is
that S0 = ˜S0, ..., St = ˜St. We also deﬁne µt( ˜S) to be µt( ˜S) = E[|St+1| | σt( ˜S)]. The algorithm is
given in Algorithm 1.

Algorithm 1: FastClock

Data: Graph G, cascade model parameters θ, observed infection sequence ˆS = ( ˆS0, ..., ˆSN )
Result: An estimated clock ˆC.
// An initially empty list for the estimated clock.

1 Set ˆC = ();

// t: index of the next estimated clock interval, i.e., t is an

index in S, the un-distorted infection sequence.

// tobs: the index in ˆS of the beginning of the next estimated

clock interval

2 Set t = 1, tobs = min{j ≤ N : | ∪j

ˆSk| = S0};

k=0

// ˜S: the estimated infection sequence approximating the

ground truth sequence S.

3 Set ˜S0 = ∪tobs
ˆSk;
k=0
4 Append tobs to ˆC;
5 while tobs (cid:54)= N do

// Compute the expected number µt of infected nodes in a
single step of the cascade process, starting from the
state of the process estimated so far.

6

7

Set µt = E[|St+1| | σt( ˜S0, ˜S1, ..., ˜St)];
Set

t(cid:48)
obs = tobs + max




∆ |



tobs+∆
(cid:88)

i=tobs+1

| ˆSi| ≤ µt · (1 + µ−1/3

t



)


(8)

8

9

10

obs to ˆC;
Append t(cid:48)
t(cid:48)
Set ˜St = ∪
obs
i=tobs+1
Set t = t + 1;
Set tobs = t(cid:48)
obs;

ˆSi;

11
12 end
13 return ˆC;

After an initialization, the main loop in FastClock (Steps 5-11) iteratively determines the ﬁrst
infection event in the next step of the process, by estimating the expected number of nodes µt to be
infected next (Step 6). The key step in this process is the computation of µt which we discuss next.

9

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

Computing µt( ˜S) in the IC model. Let us be more precise in specifying how to compute µt( ˜S) =
E[|St+1| | σt( ˜S)] in the independent cascade model. A node can be infected in one of two ways:
through external factors (governed by pe) or via transmission from a vertex in ˜St through an edge.
In the latter case, the node must lie in the frontier set Ft( ˜S), deﬁned as follows: Ft( ˜S) is the set
Ft( ˜S) = N ( ˜St) \ (cid:83)t
˜St; i.e., it is the set of neighbors of ˜St that we believe to be uninfected at
the beginning of cascade timestep t.

j=0

For a set of vertices W ⊆ [n] and a vertex v ∈ [n], let degW (v) denote the number of edges

incident on v that are also incident on vertices in W . We have, by linearity of expectation,

µt( ˜S) =

=

=

(cid:88)

v∈[n]
(cid:88)

v /∈Ft

Pr[v gets infected at time t | σt( ˜S)]

Pr[v gets infected at time t | σt( ˜S)] +

Pr[v gets infected at time t | σt( ˜S)]

(cid:88)

v∈Ft

(9)

(10)

(cid:88)

v /∈Ft∪(cid:83)t

j=0

˜Sj

Pr[v gets infected at time t | σt( ˜S)] +

Pr[v gets infected at time t | σt( ˜S)]

(cid:88)

v∈Ft


n − |Ft| −

= pe ·



| ˜Sj|

 +

t
(cid:88)

j=0

(cid:88)

v∈Ft

(pe + (1 − pe)(1 − (1 − pn)deg ˜St

(v))).

(11)

(12)

A similar expression can be derived for the more general case where transmission probabilities
across edges may differ from each other.
The calculation of the summation (cid:80)t

j=0 | ˜Sj| can be performed efﬁciently by keeping track of
its value in the t-th iteration of the loop of the algorithm. In the t-th iteration, the value of the
summation is updated by adding | ˜St| to the running total. Note also that this estimation will be
the only difference in our algorithm when applied to alternative cascade models such as the linear
threshold model.

3.2. Approximation guarantee for FastClock

Our ﬁrst theorem gives an approximation guarantee for FastClock in the case of the IC model. It
is subject to a few assumptions about the temporal distortion model, the parameters of the cascade
model and those of the graph model from which G is sampled, which we state next. It is, however,
important to note that FastClock itself does not assume anything about the graph.

Assumption 1 (Assumption on the temporal distortion model) No observed infection set ˆSi has
too few vertices compared to the ground truth infection set Sj from which it came. In particular, this
means that, for all i, the width of each observation interval Ci is bounded above by a constant, and
there is some absolute constant (cid:15) > 0 such that, for each j ∈ Ci,

| ˆSj| ≥ (cid:15)

| ˆSk|.

(cid:88)

k∈Ci

(13)

Note that we do not assume anything else about the distribution of vertices in these observation
intervals. Furthermore, this assumption can be somewhat relaxed to hold with high enough proba-
bility.

10

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

Assumption 2 (Assumptions on random graph model parameters) We assume that G ∼ G(n, p)
(i.e., that G is sampled from the Erd˝os-R´enyi model), where p satisﬁes the following relation with
the ground truth number of cascade timesteps T : p = o(n− T
T +1 ) and p ≥ C log n/n, for some
C > 1. The former condition may be viewed as a constraint on T , for a given choice of p. It is
natural in light of the fact that, together with our assumptions on pn and pe below, it implies that the
cascade does not ﬂood the graph, in the sense of infecting a Θ(1)-fraction of nodes. Many cascades
in practice do not ﬂood the graph in this sense.

The latter condition implies that the graph is connected with high probability.
Regarding parameters of the IC process, we assume that pn is some ﬁxed positive constant and
that pe = o(p). Our results also hold if pn is different for every edge e (so that pn = pn(e)), provided
that there are two positive constants 0 < c0, c1 < 1 such that for every edge e, pn(e) ∈ [c0, c1].

The assumption that pn is constant with respect to n is natural in the sense that, for many
infectious processes, the probability of transmission from one node to another should not depend on
the number of nodes.

The assumption on pe, the probability of infection from an external source, is reasonable when

the cascade is overwhelmingly driven by network effects, rather than external sources.

Theorem 8 (Main FastClock approximation theorem) Suppose that Assumptions 1 and 2 hold.
We have, with probability at least 1 − e−Ω(np),

d ˆS(C, ˆC) = O((np)−1/3),

(14)

where we recall that S is an infection sequence generated by the cascade model, C is the ground
truth clock, ˆS is the observed infection sequence generated by the temporal distortion model, and
ˆC is the output of FastClock.

3.3. Running time analysis

We have a strong guarantee on the running time of FastClock in the independent cascade case.

Theorem 9 (Running time of FastClock) The FastClock algorithm for the independent cascade
model runs in time O(N + n + m), where m is the number of edges in the input graph.

Thus, the running time of FastClock is asymptotically much smaller than that of the dynamic

programming estimator from DiTursi et al. (2017).

4. Proof sketches

In this section, we primarily give proof sketches (except where subsection headers indicate full
proofs). Full proofs of all results are given in the appendix.

4.1. Sketch of proof of Theorem 8

The proof of Theorem 8 employs an auxiliary result (Theorem 11 in the appendix, which we call
the FastClock utility theorem) stating that with high probability, for every i, the intersection of the
ground truth infection sequence element Si with the estimated infection sequence element ˜Si is

11

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

asymptotically equivalent in cardinality to Si itself. We prove this theorem by induction on the
infection sequence element index i, which requires a careful design of the inductive hypothesis.

Given the utility theorem, the required upper bound on the distortion d ˆS(C, ˆC) follows by sum-
ming over all possible pairs Si, Sj of infection sequence elements in S, the ground truth infection
sequence, then summing over all vertex pairs u ∈ Si, v ∈ Sj. This inner sum can be approximated
using the utility theorem.

4.2. Full proof of Theorem 9

We analyze the worst-case running time of FastClock as follows: initialization takes O(1) time. The
dominant contribution to the running time is the while loop. Since tobs is initially 0 and increases
by at least 1 in each iteration, the total number of iterations is at most N . The remaining analysis
involves showing that each vertex and edge is only processed, a constant number of times, in O(1)
of these loop iterations, so that the running time is at most O(N + n + m), as claimed.

In particular, the calculation of µt in every step involves a summation over all edges from cur-
rently active vertices to their uninfected neighbors, along with a calculation involving the current
number of uninfected vertices (which we can keep track of using O(1) calculations per iteration of
the loop). A vertex is only active in a single iteration of the loop. Thus, each of these edges is only
obs entails calculating a sum over elements of ˆS that
processed once in this step. The calculation of t(cid:48)
are only processed once in all of the iterations of the loop. The calculation of all of the | ˆSi| can be
done as a preprocessing step via an iteration over all n vertices of G. Finally, the calculation of Ft+1
entails a union over the same set of elements of ˆS as in the calculation of the maximum, followed
by a traversal of all edges incident on elements of ˜St+1 whose other ends connect to uninfected
vertices. These operations involve processing the vertices in ˜St+1 (which happens only in a single
iteration of the loop, and, thus, with the preprocessing step of calculating the | ˆS|i|, only a constant
number of times in the entire algorithm). The edges leading to elements of Ft+1 from elements
of ˜St+1 are traversed at most twice in the loop: once in the building of Ft+1 and once in the next
iteration in the calculation of µt.

This implies that each vertex and edge is only processed O(1) times in the entire algorithm.

This leads to the claimed running time of O(N + n + m), which completes the proof.

5. Empirical results on synthetic graphs

In this section, we present empirical results on synthetic graphs and cascades. Our goal is to conﬁrm
the theoretical guarantees of FastClock and compare it to the dynamic programming (DP) algorithm
optimizing a proxy of the maximum likelihood for observed cascades proposed by DiTursi et al.
(2017). Our comparative analysis focuses on (i) distance of the estimated clock from the ground
truth clock (see Deﬁnition 6) and (ii) empirical running time of both techniques.

We generate synthetic graphs using both the Erd˝os–R´enyi and the Stochastic Block Model.
We then generate synthetic cascades on each graph using the independent cascade (IC) model.
We employ the obtained cascade sequence S as the ground truth infection sequence, and create
corresponding distorted (disaggregated) sequences ˆS by “stretching” each ground truth time step of
S. Speciﬁcally, to obtain a sample of a distorted observation sequence ˆS, we distribute the activated
nodes in the ground truth time steps to l corresponding time steps, where each node is placed in one
of these l timesteps uniformly at random. Here, l is an integer stretch factor greater than 1. This
implicitly speciﬁes a clock C on the stretched timeline, which we would like to infer (we note that

12

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

(a) Distance with n

(b) Run time with n

(c) Distance with pn

(d) Run time with pn

(e) Distance with density

(f ) Run time with density

(g) Distance with stretch

(h) Run time with stretch

Figure 1: Comparison of the distance and runtime of the estimated clocks by FastClock and the baseline DP from
DiTursi et al. (2017) on Erd˝os–R´enyi graphs (default parameters for all experiments: pn = 0.1, pe = 10−7,
n = 3000, p = n−1/3, stretch l = 2 unless varying in the speciﬁc experiment). (a),(b): Varying graph size.
(c),(d): Varying infection probability pn. (e),(f): Varying graph density p = n−1/α. (g),(h): Varying stretch.

while all of our experiments involve a uniformly stretched timeline, our theoretical contributions are
more general). We then employ both FastClock and DP to estimate the ground truth clock from
ˆS. We draw 50 samples for each setting and report average and standard deviation for both running
time and quality of estimations for each setting.

Experiments on Erd˝os–R´enyi graphs. We ﬁrst experiment with Erd˝os–R´enyi to conﬁrm the
theoretical behavior of our estimator and compare its running time and quality to the DP base-
line. We report the results in Figure 1. With increasing graph size FastClock’s distance from
the ground truth clock diminishes (as expected based on Theorem 8), while that of DP increases
(Fig. 1(a)). Note that DP optimizes a proxy to the cascade likelihood and in our experiments tend to
over-aggregate the timeline which for large graph sizes results in incorrect recovery of the ground
truth clocks. Similarly, FastClock’s estimate quality is better than that of DP for varying on pn
(Fig. 1(c)), graph density (Fig. 1(e)) and stretch factor for the cascades (Fig. 1(g)), with distance
from ground truth close to 0 for regimes aligned with the key assumptions we make for our main
results (Assumptions 1,2). In addition to superior quality, FastClock’s running time scales linearly
with the graph size and is orders of magnitude smaller than that of DP for sufﬁciently large instances
(Figs. 1(b), 1(d), 1(f ), 1(h)).

Experiments on Stochastic Block Model (SBM) graphs. We would also like to understand the
behavior of our estimator on graphs with communities where the cascade may cross community
boundaries. To this end, we experiment with SBM graphs varying the inter-block connectivity and
virality (pn) of the cascades and report results in Fig. 2. As the cross-block connectivity increases
and approaches that within blocks (i.e. the graph structure approaches ER-graph) FastClock’s qual-
ity improves and is signiﬁcantly better than that of DP (Fig. 2(a)). When, however, the transmission

13

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

(a) Dist. with connectivity

(b) Time with connectivity

(c) Distance with pn

(d) Run time with pn

Figure 2: Comparison of the distance and runtime of the estimated clocks by FastClock

and the baseline DP
from DiTursi et al. (2017) on Stochastic Block Model graphs (default parameters: n = 5000, two
n, pe = 10−7, stretch l = 2). (a),(b): Varying inter-
blocks/communities of sizes n/
block connectivity (pn = 0.1) where a setting of 0.2 makes the graph equivalent to an Erd˝os–R´enyi graph
with p = 0.2. (c),(d): Varying infection probability pn (inter-block connectivity is set to 0.01).

n and n − n/

√

√

probability pn is high, coupled with sparse inter-block connectivity, FastClock’s estimation quality
deteriorates beyond that of DP (Fig. 2(c)). This behavior is due to the relatively large variance of µt
when the cascade crosses a sparse cut in the graph with high probability. This challenging scenario
opens an important research direction we plan to explore in future work.

6. Conclusions and future work

We have formulated a statistical estimation framework for the problem of recovery of all states of a
discrete-time cascade from temporally distorted observation sequences. In the case of oversampling
clocks, we showed that temporal distortion can be corrected with high accuracy and low compu-
tational cost, subject to certain natural constraints on the structure of the underlying graph and on
the cascade model: in essence, these must be such that the graph is an expander with appropriate
parameters; that, conditioned on an estimated current state of the process at any time, the expected
number of vertices infected in the next timestep is immune to small errors in the estimated state; and
that the number of vertices infected in the next timestep is well-concentrated around its conditional
expected value. We empirically showed that the FastClock algorithm is superior in accuracy and
running time to the current state of the art dynamic programming algorithm. Furthermore, unlike
this baseline, FastClock comes with theoretical accuracy guarantees. Our results are formally stated
for the independent cascade model, but they very likely hold for a broad class of other models,
including the linear threshold model.

We intend to pursue further work on this problem: most pressingly, our empirical results and
intuition derived from our theorems indicate that FastClock may not perform accurately when the
graph contains very sparse cuts (so that it is not an expander graph). Further work is needed to deter-
mine whether accuracy and computational efﬁciency can be achieved for such graphs. Furthermore,
our method relies on knowledge of the parameters of the cascade process. We intend to investigate
the extent to which this assumption can be relaxed.

References

Emmanuel Abbe, Sanjeev Kulkarni, and Eun Jee Lee. Nonbacktracking bounds on the inﬂuence
in independent cascade models. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus,

14

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems,
volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/
paper/2017/file/8b5040a8a5baf3e0e67386c2e3a9b903-Paper.pdf.

Lada A. Adamic, Thomas M. Lento, Eytan Adar, and Pauline C. Ng. Information evolution in social
networks. In Proceedings of the Ninth ACM International Conference on Web Search and Data
Mining, WSDM ’16, page 473–482, New York, NY, USA, 2016. Association for Computing
ISBN 9781450337168. doi: 10.1145/2835776.2835827. URL https://doi.
Machinery.
org/10.1145/2835776.2835827.

Junaid Ali, Mahmoudreza Babaei, Abhijnan Chakraborty, Baharan Mirzasoleiman, Krishna P. Gum-
madi, and Adish Singla. On the fairness of time-critical inﬂuence maximization in social net-
works, 2019.

Eytan Bakshy, Itamar Rosenn, Cameron Marlow, and Lada Adamic. The role of social networks in
information diffusion. In Proceedings of the 21st international conference on World Wide Web,
pages 519–528, 2012.

Wei Chen, Wei Lu, and Ning Zhang. Time-critical inﬂuence maximization in social networks with
time-delayed diffusion process. In Proceedings of the Twenty-Sixth AAAI Conference on Artiﬁcial
Intelligence, AAAI’12, page 592–598. AAAI Press, 2012.

Justin Cheng, Lada Adamic, P. Alex Dow, Jon Michael Kleinberg, and Jure Leskovec. Can cas-
cades be predicted? In Proceedings of the 23rd International Conference on World Wide Web,
WWW ’14, page 925–936, New York, NY, USA, 2014. Association for Computing Machin-
ery. ISBN 9781450327442. doi: 10.1145/2566486.2567997. URL https://doi.org/10.
1145/2566486.2567997.

Abir De, Isabel Valera, Niloy Ganguly, Sourangshu Bhattacharya, and Manuel Gomez-Rodriguez.
Learning and forecasting opinion dynamics in social networks. In Proceedings of the 30th Inter-
national Conference on Neural Information Processing Systems, NIPS’16, page 397–405, Red
Hook, NY, USA, 2016. Curran Associates Inc. ISBN 9781510838819.

Daniel J DiTursi, Gregorios A Katsios, and Petko Bogdanov. Network clocks: Detecting the tem-
poral scale of information diffusion. In 2017 IEEE International Conference on Data Mining
(ICDM), pages 841–846. IEEE, 2017.

Daniel J DiTursi, Carolyn S Kaminski, and Petko Bogdanov. Optimal timelines for network pro-
In 2019 IEEE International Conference on Data Mining (ICDM), pages 1024–1029.

cesses.
IEEE, 2019.

Rashad Eletreby, Yong Zhuang, Kathleen Carley, Osman Yagan, and H. Vincent Poor. The effects
of evolutionary adaptations on spreading processes in complex networks. Proceedings of the
National Academy of Sciences, 117:201918529, 03 2020. doi: 10.1073/pnas.1918529117.

David Kempe, Jon Kleinberg, and ´Eva Tardos. Maximizing the spread of inﬂuence through a social
network. In Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, KDD ’03, page 137–146, New York, NY, USA, 2003. Association

15

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

for Computing Machinery. ISBN 1581137370. doi: 10.1145/956750.956769. URL https:
//doi.org/10.1145/956750.956769.

Eun Jee Lee, Sudeep Kamath, Emmanuel Abbe, and Sanjeev R. Kulkarni. Spectral bounds for
In 2016 Annual Conference on Information

independent cascade model with sensitive edges.
Science and Systems (CISS), pages 649–653, 2016. doi: 10.1109/CISS.2016.7460579.

Andrea Montanari and Amin Saberi. The spread of innovations in social networks. Proceedings of

the National Academy of Sciences, 107(47):20196–20201, 2010.

Sang Park, Benjamin Bolker, David Champredon, David Earn, Michael Li, Joshua Weitz, Bryan
Grenfell, and Jonathan Dushoff. Reconciling early-outbreak estimates of the basic reproductive
number and its uncertainty: framework and applications to the novel coronavirus (sars-cov-2)
outbreak. Journal of The Royal Society Interface, 17:20200144, 07 2020. doi: 10.1098/rsif.2020.
0144.

Jieun Shin, Lian Jian, Kevin Driscoll, and Franc¸ois Bar. The diffusion of misinformation on social
media: Temporal pattern, message, and source. Computers in Human Behavior, 83:278–287,
2018.

Appendix A. Glossary of notation

Here we collect the notation that is used in the main body of the paper and in the proofs in the
appendix.

1. N (S): Neighborhood of the set S of vertices in a given graph.

2. S = (S0, S1, ..., ST ) – An infection sequence generated by a cascade model with T + 1
timesteps. Each Sj is a subset of vertices, and Si ∩ Sj = ∅ for i (cid:54)= j. We denote by |S| the
number of timesteps of S: T + 1. We think of S as the ground truth infection sequence.

3. ˆS = ( ˆS0, ˆS1, ..., ˆSN ) – An observation of an infection sequence that has been temporally

distorted by a clock.

4. C – The ground-truth clock in our estimation problem.

5. ˆC – The clock estimated by our algorithm.

6. ˜S – The estimate of the original infection sequence S induced by our estimate ˆC of the clock

C applied to the observed infection sequence ˆS.

7. σt(S), for an infection sequence S and a timestep index t ∈ |S| – The σ-ﬁeld generated by

the event that the ﬁrst t infection sets of the IC process are given by S0, ..., St.

8. µt(S), for an infection sequence S and a timestep index t ∈ |S| – E[|St+1| | σt(S)]. This is
the expected number of vertices infected in the t + 1st timestep, given the infection sequence
up to and including timestep t.

9. N – The index of the last observed infection set. That is, | ˆS| = N + 1.

16

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

10. T – The index of the last ground truth infection set. That is, |S| = T + 1.

11. n – The size of the graph.

12. pn – The probability in the IC model of transmission across an edge in a single timestep.

13. pe – The probability of infection of a vertex in a single timestep by a non-network source.

14. R(S, i) – For an infection sequence S and an index i, deﬁne the ith running sum to be

R(S, i) =

Sj.

(cid:91)

j≤i

(15)

15. F(S, i) – For an infection sequence S and an index i ∈ {0, 1, ..., |S|}, deﬁne the ith frontier

set to be

F(S, i) = N (Si) \ R(S, i).

(16)

The ith frontier with respect to S is the set of neighbors of vertices infected in timestep i that
have not infected by the end of timestep i.

16. CF(S, i) – The candidate frontier set at the end of timestep i in infection sequence S. That

is, this is

CF(S, i) = [n] \ R(S, i).

Note that F(S, i) ⊆ CF(S, i).

17. CCF(S, ˜S, i, j) – The common candidate frontier:

CCF(S, ˜S, i, j) = CF(S, i) ∩ CF( ˜S, j).

(17)

(18)

Appendix B. Proofs

In this section, we give full proofs of all results.

B.1. Proof of Theorem 8

To prove the main FastClock approximation theorem, we start by characterizing the growth of µi(S)
and |Si| as a function of n and i. Note that this is a result about the independent cascade process,
not the FastClock algorithm.

Lemma 10 (Growth of µi(S) and |Si|) We have that, with probability at least 1 − e−np, for all
i ≤ T ,

µi(S) = Θ((np)i+1),

where the Θ(·) is uniform in i. Furthermore, with probability at least 1 − e−np, we have

|Si| = Θ((np)i)

for every i.

Proof We prove this by induction on i and use the formula (12) throughout.

(19)

(20)

17

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

Base case (i = 0):
In the base case, we are to verify that µ0(S) = Θ(np). The ﬁrst term of (12)
is non-negative and at most pe · n. By our assumption, we have that pe = o(pn), implying that the
ﬁrst term is o(np). Thus, it remains for us to show that the second sum is Θ(np). The dominant
contribution comes from the second term of each term of the sum:

(cid:88)

(pe + (1 − pe)(1 − (1 − pn))degS0

(v)) = Θ(

(cid:88)

1 − (1 − pn)degS0

(v))

(21)

v∈F0(S)

v∈F0(S)
= Θ(|F0(S)| +

(cid:88)

v∈F0(S)

(1 − pn)degS0

(v)).

(22)

In the ﬁnal expression above, the remaining sum is lower bounded by 0 and upper bounded by
|F0(S)|, since each term is between 0 and 1. Thus, we have shown that, with probability exactly 1,

µ0(S) = Θ(|F0(S)|) + o(np).

(23)

Since |F0(S)| is the set of uninfected neighbors of all vertices in S0, and, by assumption, |S0| =
Θ(1), we have that with probability at least 1 − e−np,

Thus, we have

|F0(S)| = Θ(np).

µ0(S) = Θ(np)

(24)

(25)

with probability ≥ 1 − e−np. Conditioning on this event (which is only an event dealing with the
graph structure), we have that |S1| ∼ Binomial(Θ(np), pn), and a Chernoff bound gives us that
with probability 1 − e−Ω(np), |S1| = Θ(np), as desired. This completes the proof of the base case.

Induction (i > 0, and we verify the inductive hypothesis for i): We assume that µj(S) =
Θ((np)j+1) and |Sj+1| = Θ((np)j+1) for j = 0, 1, ..., i − 1. We must verify that it holds for j = i,
with probability at least 1 − e−np. As in the base case, the ﬁrst term of (12) is O(npe) (cid:28) np (cid:28)
(np)i+1. It is, therefore, negligible with probability 1. The second term again provides the dominant
contribution and is easily seen to be Θ(|Fi(S)|), just as in the base case. Thus, it remains to show
that |Fi(S)| = Θ((np)i+1) with probability at least 1 − e−Ω(np), which implies the desired result
for µi(S). The inductive hypothesis implies that |Si| = Θ((np)i), and the number of uninfected
vertices is n − (cid:80)i
j=0 |Sj| = n − Θ((np)i+1). Since i ≤ T − 1, this is asymptotically equivalent to
n.

Now, conditioned on the ﬁrst i elements of S, the ith frontier |Fi(S)| ∼ Binomial(n · (1 −

o(1)), 1 − (1 − p)|Si|). Thus, with probability at least 1 − e−Ω((np)i), we have

Now,

Since p = o(1), we have

|Fi(S)| = Θ(n · (1 − (1 − p)|Si|)).

1 − (1 − p)|Si| = 1 − (1 − p)(np)i

.

1 − (1 − p)(np)i

∼ 1 − e−pi+1ni

18

(26)

(27)

(28)

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

From (68) below, we have that

This implies that

pi+1ni = o(1).

1 − e−pi+1ni

= 1 − (1 − pi+1ni)(1 + O(pi+1ni)) = pi+1ni(1 + o(1)).

Thus, with probability at least 1 − e−Ω((np)i),

which implies that

|Fi(S)| = Θ((np)i+1),

µi(S) = Θ((np)i+1).

By concentration of |Si|, we then have that with probability at least 1 − e−Ω(µi(S)),

|Si| = Θ((np)i+1),

as desired.

(29)

(30)

(31)

(32)

(33)

Completing the proof Let Gi be the event that the inductive hypothesis holds for index i =
0, 1, ..., T − 1. Then we have

Pr[∩i≥0Gi] = Pr[G0] ·

Pr[Gi | ∩i−1

j=0 Gj] ≥

(cid:89)

i≥1

T −1
(cid:89)

(1 − e−Ω((np)i))1 − e−Ω((np)).

(34)

i=0

This completes the proof.

Next, we state and prove a utility theorem (Theorem 11 below). To state it, we need some
notation: our estimated clock ˆC induces an estimate ˜S of the ground truth infection sequence S. In
particular, ˜S is the unique infection sequence such that distorting ˜S according to ˆC yields ˆS as an
observed infection sequence.

Theorem 11 (Main FastClock analysis utility theorem) We have that with probability 1−e−Ω(np),
for every i ≤ T − 1,

|Si ∩ ˜Si| = |Si| · (1 − O((np)−1/3)).

(35)

We will prove this theorem by induction on i. The inductive hypothesis needed is subtle, as a
na ive hypothesis is too weak. To formulate it and to prove our result, we need some notation: for
an infection sequence W , we deﬁne the ith running sum to be

R(W, i) =

i
(cid:91)

j=0

Wj.

19

(36)

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

We deﬁne the frontier and running sum discrepancy sets as follows:

∆F(S, ˆS, i, j) = Fi(S) (cid:52) Fj( ˆS)
∆R(S, ˆS, i, j) = R(S, i) (cid:52) R( ˆS, j),

where (cid:52) denotes the symmetric difference between two sets.

We deﬁne the candidate frontier at timestep i in infection sequence S to be

CF(S, i) = [n] \ R(S, i).

This is the set of vertices that are not yet infected after timestep i.

We deﬁne the common candidate frontier to be

CCF(S, ˆS, i, j) = CF(S, i) ∩ CF( ˆS, j).

With this notation in hand, we deﬁne the following inductive hypotheses:

1. There is a small discrepancy between the running sums of the true and estimated clocks:

||R(S, i)| − |R( ˜S, i|| ≤ f1(n, i),

where we set, with foresight, f1(n, i) = µi−1(S).66 = o(µi−1(S)2/3).

2. There is a small discrepancy between Si and ˜Si:

1 −

|Si ∩ ˜Si|
|Si|

≤ f2(n, i),

(37)

(38)

(39)

(40)

(41)

(42)

where we set, with foresight, f2(n, i) = D · µi−1(S)−1/3, for some large enough absolute
constant D.

We will use these to prove Theorem 11. The base case and inductive steps are proven in Proposi-
tions 13 and 14 below. First, we start by proving an upper bound (Theorem 12) on the following
difference:

|µi(S) − µi( ˜S)|.

(43)

In essence, the upper bound says that at any given clock time step, the expected number of nodes
infected in the next timestep is almost the same according to both the true and estimated clock. This
will later be used verify the two inductive hypotheses stated above.

Theorem 12 (Upper bound on (43)) Granted the inductive hypotheses explained above, we have
that

|µi(S) − µi( ˜S)| ≤ pµi−1(S)2/3µi(S),

(44)

with probability ≥ 1 − e−Ω(µi(S)).

20

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

Proof To upper bound (43), we apply the triangle inequality to (12) to get

|µi(S) − µi( ˜S)| ≤ pe ·
(cid:12)
(cid:12)
i
(cid:88)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

+ pe

(cid:12)
(cid:12)
(cid:12)|Fi(S)| − |Fi( ˜S)|
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
|Sj|
(cid:12)
(cid:12)
(cid:12)

| ˜Sj| −

i
(cid:88)

j=0

j=0

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

+

(cid:88)

v∈Fi(S)

Q(i, S, v) −

(cid:88)

v∈Fi( ˜S)

(cid:12)
(cid:12)
(cid:12)
Q(i, ˜S, v)
(cid:12)
(cid:12)
(cid:12)

,

where Q(i, S, v) = pe + (1 − pe)(1 − (1 − pn)degSi

(v)).

We will upper bound each of the three terms (45), (46), and (47) separately.

Upper bounding (45) by O(pe|Fi(S)|): We ﬁrst note that

(cid:12)
(cid:12)|Fi(S)| − |Fi( ˜S)|
(cid:12)

(cid:12)
(cid:12) ≤ |∆F(S, ˜S, i, i)|.
(cid:12)

(45)

(46)

(47)

(48)

So it is enough to upper bound the frontier discrepancy set cardinality.
decompose it as follows:

In order to do this, we

|∆F(S, ˜S, i, i)| = |∆F(S, ˜S, i, i) ∩ ∆R(S, ˜S, i, i)| + |∆F(S, ˜S, i, i) ∩ CCF(S, ˜S, i, i)|.

(49)

This decomposition holds for the following reason: let v be a vertex in the frontier discrepancy set
∆F(S, ˜S, i, i). Suppose, further, that v is not in the common candidate frontier for Si, ˜Si (so it does
not contribute to the second term on the right-hand side of (49)). We will show that it must be a
member of ∆R(S, ˜S, i, i), which will complete the proof of the claimed decomposition. Then v
must be a member of at least one of R(S, i), R( ˜S, i) (i.e., it must already be infected in at least
one of these). If it were a member of both, then it would not be a member of either frontier, so it
could not be a member of the frontier discrepancy set. Thus, it v is only a member of one of R(S, i)
or R( ˜S, i). This implies that v ∈ ∆R(S, ˜S, i, i). This directly implies the claimed decomposition
(49).

We now compute the expected value of each term of the right-hand side of (49), where the
expectation is taken with respect to the graph G. After upper bounding the expectations, standard
concentration inequalities will complete our claimed bound on the size of the frontier discrepancy
set.

In the ﬁrst term, the size of the intersection of the frontier discrepancy with the running sum
discrepancy is simply the number of vertices in the running sum discrepancy set that have at least one
edge to some vertex in Si (here we assume, without loss of generality, that |R(S, i)| ≤ |R( ˜S, i)|).
Using linearity of expectation, the expected number of such vertices is

E[|∆F(S, ˜S, i, i) ∩ ∆R(S, ˜S, i, i)|] = |∆R(S, ˜S, i, i)| · (1 − (1 − p)|Si|).

(50)

Here (1 − (1 − p)|Si|) is the probability that, for a ﬁxed vertex w ∈ ∆R(S, ˜S, i, i), there is at least
one edge between w and some vertex in Si.

We compute the expected value of the second term of (49) as follows.

21

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

We claim that

∆F(S, ˜S, i, i) ∩ CCF(S, ˜S, i, i) ⊆ CCF(S, ˜S, i, i) ∩ (N (∆R(S, ˜S, i, i)) \ N (Si)).

(51)

To show this, let v ∈ ∆F(S, ˜S, i, i) ∩ CCF(S, ˜S, i, i). The fact that v is in the frontier discrepancy
set means that it has an edge to exactly one of Si, ˜Si. This implies that it has an edge to the running
sum discrepancy set. Recalling that we assumed wlog that |R(S, i)| ≤ |R( ˜S, i)|, we must have
that ∆R(S, ˜S, i, i) ∩ Si = ∅, and so we must also have that there are no edges from v to Si. This
completes the proof of the claimed set inclusion. This implies that

E[|∆F(S, ˜S, i, i) ∩ CCF(S, ˜S, i, i)|] ≤ E[|CCF(S, ˜S, i, i) ∩ (N (∆R(S, ˜S, i, i)) \ N (Si))|]. (52)

As above, the expectation is taken with respect to the random graph G.

For a single vertex in the common candidate frontier, the probability that it lies in the frontier

discrepancy set is thus at most

(1 − (1 − p)|∆R(S, ˜S,i,i)|) · (1 − p)|Si|.

(53)

Thus, using linearity of expectation, the expected size of the second term in (49) is upper bounded
by

E[|∆F(S, ˜S, i, i) ∩ CCF(S, ˜S, i, i)| | σi(S)] ≤ |CCF(S, ˜S, i, i)| · (1 − (1 − p)|∆R(S, ˜S,i,i)|) · (1 − p)|Si|.

(54)

Combining (50) and (54) and deﬁning q = 1 − p, we have the following expression for the expected
size of the frontier discrepancy set:

E[|∆F(S, ˜S, i, i)|]
= |∆R(S, ˜S, i, i)| · (1 − q|Si|)
+ |CCF(S, ˜S, i, i)| · (1 − q|∆R(S, ˜S,i,i)|) · q|Si|.

(55)

(56)

(57)

We would like this to be O(E[|Fi(S)| | σi(S)]). Note that E[|Fi(S)| | σi(S)] can be expressed

as follows:

E[|Fi(S)| | σi(S)] = (|∆R(S, ˜S, i, i)|

+ |CCF(S, ˜S, i, i)|) · (1 − q|Si|).

(58)

(59)

The intuition behind (55) being O(E[|Fi(S)| | σi(S)]) is as follows: the ∆R term is exactly the
same as in (58). However, this term is negligible compared to the common candidate frontier term
in both expected values. The second term, (57), can be asymptotically simpliﬁed as follows: we
have

1 − q|∆R(S, ˆS,i,i)| = 1 − (1 − p)|∆R(S, ˜S,i,i)|

∼ 1 − (1 − p) · |∆R(S, ˜S, i, i)|)
= p · |∆R(S, ˜S, i, i)|

(60)

(61)

(62)

22

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

= p|Si| ·

∼ (1 − q|Si|) ·

|∆R(S, ˜S, i, i)|
|Si|
|∆R(S, ˜S, i, i)|
|Si|

.

(63)

(64)

Here, we have used the following facts:

• For the ﬁrst asymptotic equivalence, we used the fact that p|∆R(S, ˜S, i, i)| = o(1). More

precisely, we have from the inductive hypothesis that

|∆R(S, ˜S, i, i)| = o(µi−1(S)0.66) = o((np)i·0.66),

(65)

so we have

p|∆R(S, ˜S, i, i)| = o(p0.66i+1n0.66i) = o(n−T /(T +1)+0.66i/(T +1)),

(66)

which is polynomially decaying in n.

• For the second asymptotic equivalence, we used the fact that p|Si| = o(1). More precisely,

this comes from the fact that

p|Si| = O(p(np)i) = O(pi+1ni).

Now, we use the fact that p = o(n− T

T +1 ):

pi+1ni = o(n− T

T +1 (i+1)+i),

(67)

(68)

from our assumption on the growth of p. Now, we need to show that the exponent is sufﬁ-
ciently negative and bounded away from 0.

−

T
T + 1

(i + 1) + i =

−T · (i + 1) + i · (T + 1)
T + 1

=

−T + i
T + 1

≤

−1
T + 1

.

(69)

We have used the fact that i ≤ T − 1. Now, the constraints that we imposed on p imply that
T = o(log n), so

−1
T +1 = e

− log n
T +1 = o(1),

n

as desired, since the exponent tends to −∞ as n → ∞.

Let us be more precise about what we proved so far. We have

E[|∆F(S, ˜S, i, i)| | σi(S)] ∼ (1 − q|Si|) · |CCF(S, ˜S, i, i)| ·

(cid:18) |∆R|
|CCF|

+

|∆R|
|Si|

(cid:19)

.

q|Si|

Meanwhile,

E[|Fi(S)| | σi(S)] = (1 − q|Si|) · |CCF| ·

(cid:18)

1 +

(cid:19)

.

|∆R|
|CCF|

23

(70)

(71)

(72)

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

We have that

E[|∆Fi| | σi(S)]
E[|Fi| | σi(S)]

∼

· q|Si|

|∆R|

|CCF| + |∆R|
|Si|
1 + |∆R|
|CCF|

.

(73)

This can be simpliﬁed as follows:

E[|∆Fi| | σi(S)]
E[|Fi| | σi(S)]

∼

· q|Si|

|∆R|

|CCF| + |∆R|
|Si|
1 + |∆R|
|CCF|

|∆R| ·

(cid:16)

1 + |CCF|

|Si| q|Si|(cid:17)

|CCF| + |∆R|

=

.

(74)

This can be upper bounded as follows, by distributing in the numerator and upper bounding |∆R|
by |∆R| + |CCF| in the numerator of the resulting ﬁrst term:

|∆R| ·

(cid:16)

1 + |CCF|

|Si| q|Si|(cid:17)

|CCF| + |∆R|

≤ 1 +

|∆R| · |CCF|q|Si|
|Si|(|CCF| + |∆R|)

.

We can further upper bound by noticing that |CCF| + |∆R| ≥ |CCF|, so

E[|∆Fi| | σi(S)]
E[|Fi| | σi(S)]

≤ 1 +

|∆R|
|Si|

.

(75)

(76)

Now, by our inductive hypothesis, we know that |∆R|i = o(µi−1(S)0.66), and by concentration, we
know that |Si| = Θ(µi−1(S)). Thus, we have

E[|∆Fi| | σi]
E[|Fi| | σi]

≤ 1 +

|∆R|
|Si|

= 1 + o(µi−1(S)−(1−0.66)) = O(1).

Thus,

E[|∆F(S, ˜S, i, i)| | σi(S)] = O(E[|Fi(S)| | σi(S)]).

(77)

(78)

Now, remember that our goal is to show that |∆F(C, ˆC, i, i)| = O(|Fi(C)|) with high probabil-
ity, conditioned on σi(S). This follows from the expectation bound above and the fact that the size
of the frontier in both clocks is binomially distributed, so that standard concentration bounds apply.
This results in the following:

pe|∆Fi| = O(pe|Fi|)

with conditional probability at least 1 − e−Ω((np)i).

Upper bounding (46) by o(pe|R(S, i)|):

To upper bound (46), we note that

i
(cid:88)

j=0

|Sj| = |R(S, i)|,

and an analogous identity holds with ˜S in place of S. Moreover,

(cid:12)
(cid:12)
(cid:12) = |∆R(S, ˜S, i, i)|.
(cid:12)R(S, i) − R( ˜S, i)
(cid:12)
(cid:12)

24

(79)

(80)

(81)

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

Thus, we have

(46) = pe|∆R(S, ˜S, i, i)| ≤ pef1(n, i),

(82)

where the inequality is by the inductive hypothesis. We want this to be o(pe · |R(S, i)|), which
means that we want |∆R(S, ˜S, i, i)| = o(|R(S, i)|). This is follows from the inductive hypothesis.
In particular, we know that |R(S, i)| ≥ |Si|, since Si ⊂ R(S, i). Furthermore, we have by the
inductive hypothesis that |∆R(S, ˜S, i, i)| = o(µi−1(S)0.66) = o(|Si|0.66). Thus, we have

pe|∆R(S, ˜S, i, i)| = o(pe|R(S, i)|),

(83)

with (conditional) probability 1, as desired.

Upper bounding (47) by (cid:80)
i−1(S): To upper bound (47), we apply the tri-
angle inequality and extend both sums to v in Fi(S) ∪ Fi( ˜S). This results in the following upper
bound:

v∈Fi(S) Q(i, S, v)pµ2/3

(47) ≤

(cid:88)

|Q(i, S, v) − Q(i, ˜S, v)|.

(84)

v∈Fi(S)∪Fi( ˜S)

To proceed, we will upper bound the number of nonzero terms in (84). Each nonzero term can
be upper bounded by 1, since Q(i, S, v), Q(i, ˜S, v) are both probabilities. We will show that the
number of nonzero terms is at most O(|Fi(S)|p · µ2/3

i−1(S)) with high probability.

We write

Q(i, S, v) − Q(i, ˜S, v)
= pe + (1 − pe)(1 − (1 − pn)degSi
= (1 − pe)((1 − pn)deg ˜Si

(v) − (1 − pn)degSi

(v)).

(v)) − pe − (1 − pe)(1 − (1 − pn)deg ˜Si

(v))

(85)

(86)

(87)

Thus, a term in the sum (84) is nonzero if and only if degSi(v) (cid:54)= deg ˜Si

(v). This happens if and
only if v has at least one edge to some vertex in ˜Si − Si. Thus, our task reduces to ﬁguring out how
many vertices v there are that connect to some element of ˆCi − Ci. The expected number of such
vertices is

|Fi(S) ∪ Fi( ˜S)| · (1 − q| ˜Si−Si|).

This is an upper bound on the contribution of (47). We thus have

(47) ≤ |Fi(S) ∪ Fi( ˜S)| · (1 − q| ˜Si−Si|).

(88)

(89)

Next, we show that |Fi(S) ∪ Fi( ˜S)| = O(|Fi(S)|). To do this, we apply the results from upper

bounding (45). In particular,

|Fi(S) ∪ Fi( ˜S)| = |Fi(S) ∩ Fi( ˜S)| + |∆F(S, ˜S, i, i)| ≤ |Fi(S)| + |∆F(S, ˜S, i, i)| = O(|Fi(S)|).
(90)

25

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

Next, we show that 1 − q| ˜Si−Si| = pµ2/3

i−1(S). We can write

q| ˜Si−Si| = (1 − p)| ˜Si−Si| ∼ e−p| ˜Si−Si|,

(91)

provided that p · | ˜Si − Si| = o(1). Now from the inductive hypothesis, | ˜Si − Si| = O(|Si|2/3), and
from Lemma 10, we know that |Si| = O((np)i). Then we have that

1 − q| ˜Si−Si| ≤ 1 − e−O(p(np)2/3i).

In order for this second term to be 1 − o(1), it is sufﬁcient to have that

pi+1ni = o(1).

This happens if and only if

pi+1 = o(n−i) ⇐⇒ p = o(n− i

i+1 ).

This is guaranteed by our assumption that p = o(n− T

T +1 ). Thus,

1 − q| ˜Si−Si| ≤ 1 − e−O(p(np)2/3i) ∼ pµ2/3

i−1(S).

We have shown that

Next, we show that (cid:80)

v∈Fi(S) Q(i, S, v) = Ω(|Fi(S)|). We have

(47) = O(|Fi(S)| ˙pµ2/3

i−1(S)).

Q(i, s, v) ≥ 1 − (1 − pn)degSi

(v).

Since the sum is over v ∈ Fi(S), this implies that degSi(v) ≥ 1. So

Q(i, C, v) ≥ 1 − (1 − pn) = pn = Ω(1).

Thus,

(cid:88)

v∈Fi(S)

Q(i, C, v) ≥ |Fi(S)| · pn = Ω(|Fi(S)|).

(92)

(93)

(94)

(95)

(96)

(97)

(98)

(99)

Thus, we have shown that

(47) ≤ const ·

(cid:88)

v∈Fi(C)

Q(i, C, v) · (1 − q| ˆCi−Ci|) = const

(cid:88)

v∈Fi(C)

Q(i, C, v)pµ2/3

i−1(C),

(100)

with conditional probability at least 1 − e−Ω((np)i).

26

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

Completing the proof We combine (100), (79), and (83) to complete the proof.

So we have that the difference between µi(C) and µi( ˆC) is negligible in relation to µi(C).
Now, the next two propositions give the base case and inductive step of the proof of Theorem 11.

Proposition 13 (Base case of the proof of Theorem 11) We have that, with probability 1,

and

|∆R0| = |∆R(S, ˜S, 0, 0)| = 0,

| ˜S0(cid:52)S0| = 0.

(101)

(102)

Proof This follows directly from the assumed initial conditions.

Proposition 14 (Inductive step of the proof of Theorem 11) Assume that the inductive hypothe-
ses (41) and (42) hold for i. Then we have the following:

| ˜Si+1(cid:52)Si+1| ≤ |∆Ri| = |∆R(S, ˜S, i, i)| = o(µi−1(S)2/3) = o(µi(S)2/3).

(103)

Equivalently,

Furthermore,

1 −

| ˜Si+1 ∩ Si+1|
|Si|

= o(µi(S)2/3).

|∆Ri+1| ≤ |∆Ri| ≤ o(µi−1(S)2/3) = o(µi(S)2/3).

(104)

(105)

In other words, both inductive hypotheses are satisﬁed for i + 1. This holds with probability at least
1 − e−Ω(µi(C)).

Proof To prove this, we ﬁrst need a few essential inequalities.

• By deﬁnition of the algorithm,

| ˜Si+1| ≤ µi( ˜S)(1 + µi( ˜S)−1/3),

(106)

with probability 1.

• We will also need to prove an upper bound on | ˜Si+1| − |Si+1|. In particular, we will show

that with probability at least 1 − e−Ω(µi(S)),

| ˜Si+1| ≤ |Si+1| · (1 + O(µi(S)−1/3)).

(107)

We show this as follows. From Theorem 12,

µi( ˜S) ≤ µi(S)(1 + pµi−1(S)2/3),

27

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

with probability ≥ 1 − e−Ω(µi(S)). This implies, via (106), that

| ˜Si+1| ≤ µi(S) · (1 + pµi−1(S)2/3) · (1 + O(µi(S)−1/3)).

By concentration of |Si+1|, with probability at least 1 − e−Ω(µi(S)), this is upper bounded as
follows:

| ˜Si+1| ≤ |Si+1|(1 + O(|Si+1|−1/2+const))(1 + pµi−1(S)2/3)(1 + O(µi(S)−1/3)).

Now, we can see from (68) that this is equal to the desired upper bound. We have thus shown
(107).

Now, with the preliminary inequalities proven, we proceed to prove the proposition. We split

into two cases:

• Si+1 begins before ˜Si+1 (in other words, |R(S, i)| < |R( ˜S, i)|).

In this case, we will show (i) that Si+1 must end before ˜Si+1 (i.e., that |R(S, i + 1)| ≤
|R( ˜S, i + 1)|) with high probability, (ii) that

and (iii) that

∆Ri+1 = 0,

| ˜Si+1(cid:52)Si+1| ≤ |∆Ri|.

(108)

(109)

To show that (i) is true, we note that because Si+1 begins before ˜Si+1, Si+1 consists of an ini-
tial segment ˆSj1, ˆSj1+1, ..., ˆSj2 with total cardinality |∆Ri|, ending in an observation endpoint
(speciﬁcally, the one corresponding to R( ˜S, i)), followed by a segment ˆSj2+1, ..., ˆSj3 of total
c ardinality |Si+1|−|∆Ri|, again ending in an observation endpoint. This is true by deﬁnition
of ∆Ri. The second segment begins at the same point as ˜Si+1 (that is, R( ˜S, i) = (cid:83)j2+1
ˆSj),
j=0
and we know that it has cardinality

|Si+1| − |∆Ri| ≤ |Si+1| ≤ µi(S)(1 + µi(S)−1/2+const) ≤ µi( ˜S)(1 + µi( ˜S)−1/3),

(110)

by concentration of |Si+1|. The last inequality follows from the fact that µi(S) = Θ(µi( ˜S)).
Thus, the second segment of Si+1 must be contained in ˜Si+1, by (106), by deﬁnition of the
FastClock algorithm, as desired.

This has the following implication: we can express |∆Ri+1| as

|∆Ri+1| = | ˜Si+1| − (|Si+1| − |∆Ri|) ≤ µi(S)−1/3 + |∆Ri|.

(111)

We have used (107). Since, by the inductive hypothesis, we have |∆Ri| = o(µi−1(C)0.66),
and since this is o(|Ci+1|), we have that

|∆Ri+1| = 0,

(112)

by Assumption 1 that no observation interval has too few vertices. This follows because, if
∆Ri+1 were nonempty, then it would contain an observation interval (i.e., ˆSj for some j)

28

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

with cardinality at most o(|Si+1|) that is a subset of Si+1. This contradicts Assumption 1.
Thus, we have established (ii).

We next show (iii). We have

| ˜Si+1(cid:52)Si+1| ≤ |∆Ri|,

(113)

by the fact that | ˜Si+1(cid:52)Si+1| = |∆Ri| + |∆Ri+1|.

• Or Si+1 begins after or at the same time as ˜Si+1 (in other words, |R(S, i)| ≥ |R( ˜S, i)|).

In this case, we will show (i) that

and (ii) that

|∆Ri+1| = 0,

| ˜Si+1(cid:52)Si+1| ≤ |∆Ri|.

This is because of the following identity:

where

| ˜Si+1| = |∆Ri| + |Si+1| + |∆Ri+1|Ii+1,

Ii+1 =

(cid:40)
1
−1 otherwise

Si+1 stops before ˜Si+1

(114)

(115)

(116)

(117)

This is a consequence of the following derivation, which relies on the deﬁnitions of all in-
volved terms.

|∆Ri| + |Si+1| + |∆Ri+1|Ii+1 =

=

i
(cid:88)

k=0
i+1
(cid:88)

|Sk| −

|Sk| −

k=0
= | ˜Si+1|.

i
(cid:88)

k=0
i
(cid:88)

k=0

| ˜Sk| + |Si+1| +

(cid:12)
i+1
(cid:12)
(cid:88)
(cid:12)
(cid:12)
(cid:12)

k=0

|Sk| −

| ˜Sk| −

(cid:32) i+1
(cid:88)

k=0

|Sk| −

i+1
(cid:88)

k=0

| ˜Sk|

(cid:12)
(cid:12)
| ˜Sk|
(cid:12)
(cid:12)
(cid:12)

i+1
(cid:88)

k=0
(cid:33)

Ii+1

Rearranging (116) to solve for |∆Ri+1|, we have that

|∆Ri+1| = || ˜Si+1| − |∆Ri| − |Si+1||
≤ || ˜Si+1| − |Si+1|| + |∆Ri|
= || ˜Si+1| − |Si+1|| + o(µi−1(S)2/3)
≤ O(µi(S)−1/3) + o(µi−1(S)2/3)
= o(µi(S)).

Here, we have used the triangle inequality and the inductive hypothesis on |∆Ri|, followed
by the inequality (107).

29

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

Since |∆Ri+1| = o(µi(C)), it must be 0 because of Assumption 1, which veriﬁes the induc-
tive hypothesis on |∆Ri+1|.

Furthermore, this implies that

| ˜Si+1(cid:52)Si+1| ≤ |∆Ri|,

(118)

which veriﬁes the inductive hypothesis on | ˜Si+1(cid:52)Si+1|.

The inductive hypotheses follow directly from the above.

We can now prove the utility theorem, Theorem 11.

Proof [Proof of Theorem 11] Let Bi denote the bad event that either inductive hypothesis fails to
hold at step i. We will lower bound

T −1
(cid:92)

Pr[

i=0

¬Bi].

By the chain rule, we have

T −1
(cid:92)

Pr[

i=0

¬Bi] = Pr[¬B0]

T −1
(cid:89)

i=1

Pr[¬Bi |

i−1
(cid:92)

j=0

¬Bj].

From Proposition 14, Proposition 13, and Lemma 10, this is lower bounded by

T −1
(cid:89)

(1 − e−D·(np)i+1

) = exp

i=1

(cid:16)

1 − e−D(np)i+1(cid:17)

log

(cid:33)

(cid:32)T −1
(cid:88)

i=1

(cid:32)

= exp

−

T −1
(cid:88)

e−D(np)i+1

(cid:33)

· (1 + o(1))

i=1
= 1 − e−Ω(np).

(119)

(120)

(121)

(122)

(123)

Now, the event that none of the bad events hold implies the claim, which completes the proof.

With Theorem 11 in hand, we can prove the main result, Theorem 8.
Proof [Proof of Theorem 8] Let us recall the deﬁnition of d ˆS(C, ˆC). We have

d ˆS(C, ˆC) =

1
(cid:0)n
(cid:1)
2

(cid:88)

i<j

DisC, ˆC(i, j).

(124)

What we need is an upper bound on this quantity in terms of the error term f (n) = (np)−1/3 in
Theorem 11. To this end, we partition the sum according to vertex membership in clock intervals as
follows:

(cid:19)

(cid:18)n
2

d ˆS(C, ˆC) =

|S|
(cid:88)

(cid:88)

k1=1

i<j∈Sk1

DisC, ˆC(i, j) +

|S|
(cid:88)

|S|
(cid:88)

(cid:88)

k1=1

k2=k1+1

i∈Sk1 ,j∈Sk2

DisC, ˆC(i, j).

(125)

30

NETWORK CASCADE TEMPORAL SCALE ESTIMATION

In the ﬁrst sum, i and j are not ordered by C, because they lie in the same set in S. We consider
the corresponding set in ˜S. From the theorem, at least (cid:0)|Ck1 |·(1−f (n))
(cid:1) vertex pairs from Sk1 are
correctly placed together in ˜S. Furthermore, at least

2

|Sk1| · (1 − f (n)) ·

|S|
(cid:88)

(1 − f (n))|Sk2|

k2=k1+1

(126)

pairs of vertices with one vertex in Sk1 are correctly placed in different intervals. So the number of
correctly ordered/unordered vertex pairs is at least





|S|
(cid:88)

k1=1

|Sk1|2 · (1 − f (n))2
2

+

|S|
(cid:88)

k2=k1+1



|Sk1||Sk2|(1 − f (n))2

 ∼

(cid:19)

(cid:18)n
2

· (1 − f (n))2.

(127)

Since f (n) = o(1), this is asymptotically equal to (cid:0)n
2

(cid:1) · (1 − 2f (n)).

This completes the proof.

B.2. Proof of Theorem 9

We analyze the worst-case running time of FastClock as follows: initialization takes O(1) time. The
dominant contribution to the running time is the while loop. Since tobs is initially 0 and increases
by at least 1 in each iteration, the total number of iterations is at most N . The remaining analysis
involves showing that each vertex and edge is only processed, a constant number of times, in O(1)
of these loop iterations, so that the running time is at most O(N + n + m), as claimed.

In particular, the calculation of µt in every step involves a summation over all edges from cur-
rently active vertices to their uninfected neighbors, along with a calculation involving the current
number of uninfected vertices (which we can keep track of using O(1) calculations per iteration of
the loop). A vertex is only active in a single iteration of the loop. Thus, each of these edges is only
obs entails calculating a sum over elements of ˆS that
processed once in this step. The calculation of t(cid:48)
are only processed once in all of the iterations of the loop. The calculation of all of the | ˆSi| can be
done as a preprocessing step via an iteration over all n vertices of G. Finally, the calculation of Ft+1
entails a union over the same set of elements of ˆS as in the calculation of the maximum, followed
by a traversal of all edges incident on elements of ˜St+1 whose other ends connect to uninfected
vertices. These operations involve processing the vertices in ˜St+1 (which happens only in a single
iteration of the loop, and, thus, with the preprocessing step of calculating the | ˆS|i|, only a constant
number of times in the entire algorithm). The edges leading to elements of Ft+1 from elements
of ˜St+1 are traversed at most twice in the loop: once in the building of Ft+1 and once in the next
iteration in the calculation of µt.

This implies that each vertex and edge is only processed O(1) times in the entire algorithm.

This leads to the claimed running time of O(N + n + m), which completes the proof.

31

