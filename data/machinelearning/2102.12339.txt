1
2
0
2

b
e
F
4
2

]
E
N
.
s
c
[

1
v
9
3
3
2
1
.
2
0
1
2
:
v
i
X
r
a

Functional neural network for decision processing, a racing network of
programmable neurons with fuzzy logic where the target operating model relies on
the network itself

Frederic Jumelle,1 Kelvin So,1 Didan Deng2
1 Bright Nation Limited, Smart-Space 3F, Cyberport, Hong Kong
2 Neuromorphic Interactive System Laboratory, Department of Electronic and Computer Engineering, The Hong Kong
University of Science and Technology, Hong Kong
f.jumelle@brightnationlimited.com, ccso@brightnationlimited.com, ddeng@ust.hk

Abstract

In this paper, we are introducing a novel model of artiﬁ-
cial intelligence, the functional neural network for model-
ing of human decision-making processes. This neural net-
work is composed of multiple artiﬁcial neurons racing in the
network. Each of these neurons has a similar structure pro-
grammed independently by the users and composed of an in-
tention wheel, a motor core and a sensory core representing
the user itself and racing at a speciﬁc velocity. The mathe-
matics of the neuron’s formulation and the racing mechanism
of multiple nodes in the network will be discussed, and the
group decision process with fuzzy logic and the transforma-
tion of these conceptual methods into practical methods of
simulation and in operations will be developed. Eventually,
we will describe some possible future research directions in
the ﬁelds of ﬁnance, education and medicine including the
opportunity to design an intelligent learning agent with appli-
cation in business operations supervision. We believe that this
functional neural network has a promising potential to trans-
form the way we can compute decision-making and lead to a
new generation of neuromorphic chips for seamless human-
machine interactions.

Introduction
Modeling the internal dynamics of human central nervous
system has been a prominent and signiﬁcant research prob-
lem in artiﬁcial intelligence (AI) for decades. Not only is
such knowledge appealing for intellectual purpose, but is
also important for the advance of brain-inspired AI tech-
nology and strong AI, i.e. machines that can experience
consciousness and aim to achieve human cognitive abili-
ties (Long and Cotner 2019; Alpcan, Erfani, and Leckie
2017; ˇSekrst 2020). However, the major streams of AI
technology focus on weak AI, i.e. the use of machines
for analysing and accomplishing well-deﬁned and speciﬁc
problem solving and reasoning tasks with certain given
rules (Gams et al. 1997; Rajan and Safﬁotti 2017). Exam-
ples of weak AI include the most common applications of
AI, namely, facial recognition, which analyse human facial
image in a pixel scale and is mostly based on the framework
of convolutional neural network (CNN) to extract features
of human faces with trained ﬁlters (Sun, Wu, and Hoi 2018;
Mahmood et al. 2017). Competency of these models of weak

Preprint

AI is further improved by enhancement of computational ef-
ﬁciency than by comprehensive and rigorous understanding
of how intelligence is generated or processed in human cen-
tral nervous system (Strong 2016).

As a recent breakthrough in deep learning, generative ad-
versarial network (GAN) suggests a new direction on strong
AI research. GAN comprises of two alternating neural net-
works, the generator and the discriminator, and attempts to
mimic the computing power of the human brain in term of
learning to distinguish real data from fake data (Goodfellow
2016; Goodfellow et al. 2014). However, instead of being
inspired from the neuro-biological architectures and trans-
mission mechanisms of the central nervous system, the in-
trinsic architecture of GAN is based on the CNN framework,
making it less appealing for modelling the decision-making
process of humans and brings scarce insight into understand-
ing the mechanism of human central nervous system. On the
other side, Spiking Neural Networks (SNN) are networks
that more closely mimic natural brain networks (Ghosh-
Dastidar and Adeli 2009; Wang, Lin, and Dang 2020). In
addition to neuronal and synaptic state, SNNs incorporate
the concept of time into the operating model. The idea is
that neurons in the SNN do not ﬁre at each propagation cy-
cle but ﬁre only when the neuron’s electrical charge reaches
a speciﬁc value.

Decision-making is a complex process with multiple in-
puts, a fuzzy logic and an output unique to a person,
which requires a computing model capable of operating a
timed competition of neurons programmed upon personal
attributes such as neuropsychological performance and cen-
tral nervous system processing latency. This neuromorphic
approach has been put in place wherein the neurons are pro-
grammed by the users to create a racing network for decision
processing where the operating model is the network itself.
This model refers to the function(s) of learning by accumu-
lating try and succeed or try and fail processes such as those
driven by the urge to execute and those by the urge to en-
gage, along with the long short term memory of them. One
of the assumptions is that decision making involves at least
4 components, namely the intention, the reaction time, the
emotional response and the velocity of the process, that can
be modelled in a way that computing them becomes pos-
sible. The second assumption is that decision-making is a
learning process for which reinforcement is a key compo-

 
 
 
 
 
 
nent based on success or failure when the record of these
outputs can be kept in memory. The third assumption is that
human logic is fuzzy in which the truth values of variables
may be any real number between totally true and totally
false, between 0 and 1 both inclusive. However, in human
society a decision is expected to be made in terms of a sim-
plistic yes or no. This extreme bipolarity is quite challenging
and can throw light onto what researchers have called the
mirror neuron system in the learning process especially in
action observation and action execution (Shillcock, Thomas,
and Bailes 2019; Zhang et al. 2018), which could be playing
a signiﬁcant role in human decision making process such as
in the case of moral dilemma (Christov-Moore, Conway, and
Iacoboni 2017). This observation makes the invention of a
novel neural network architecture with the insight of the hu-
man mirror neuron system (Kilroy and Aziz-Zadeh 2017), a
keen step towards understanding the central nervous system
and computing artiﬁcial intelligence.

In this paper, we are proposing a novel artiﬁcial gen-
eral intelligence model, the Functional Neural Network
(FNN), which refers to the capacity of a neuron to be-
come part of a neural network through temporal synchro-
nization. FNN is made of programmable neurons based on
a 3-dimensional proﬁle (using attributes such as biological-
metrics, neuropsychological-metrics and chrono-metrics) of
each user generated from a neuropsychological performance
test taking inputs from the user’s mobile camera for facial
attributes recognition and emotional state capture. The Arti-
ﬁcial Mirror Neuron (AMN) is a single hybrid neuron cre-
ated upon the user’s proﬁle scores which comprises a mir-
ror structure articulated between a motor core and a sensory
core, and determines the velocity of a user’s neuron in a
network of multiple users represented by other neurons in
a race. This competition is used for modelling the decision-
making process of each user as seen in a group of other users
of similar, competitive, or challenging nature which depends
on the type of their individual request for decision process-
ing. Decision types can be simple binary choice or reactional
to sentiment analysis or a probabilistic response to a speciﬁc
market signal whether social, industrial, or ﬁnancial. Given
sufﬁcient training by a variety of users under a wide set of
requests that are kept in memory, the FNN is able to gen-
erate a prescription to a user’s question or dilemma, upon
group consensus and/or expert consensus for the user’s ref-
erence and trigger an executive decision. Group consensus
and expert consensus are a breakthrough from existing arti-
ﬁcial intelligence techniques and offer a new perspective in
understanding the importance of synchronicity in human de-
cision processing with potential application in industry sec-
tors where rational decision-making matters greatly.

Methodology
Artiﬁcial Mirror Neuron (AMN) of the Functional
Neural Network
Artiﬁcial Mirror Neuron (AMN) is a hybrid structure serv-
ing as the fundamental building block of the Functional
Neural Network (FNN). A single functional network com-
prises a large network of mirror neurons. Each of them is

a programmable single unit which has multiple inputs. The
inputs of each neuron are obtained at the time of launch-
ing a new request by using a simple cognitive test that
can quantify the subject’s reaction time, combined with the
MIMAMO-net (Deng et al. 2019) that can qualify the sub-
ject’s emotional response by facial emotion recognition. In
other words, FNN is an AI model based on a network of
specialized neurons, i.e. AMN, to simulate some user brain
functions, obtain a reaction and generate a prescription use-
ful to the user.

Each neuron is made of 3 basic elements: the intention
wheel (large circle above the axis x with the green hypocy-
cloid with 3 cusps), the motor core inside (small circle inside
the intention wheel and above the axis x) and its counterpart
the sensory core (small circle and below the axis x with the
red epicycloid with one cusp). The neuron moves dynami-
cally from left to right in a calculated velocity depending on
the age of the user.

A schematic structural view of an AMN is presented in

Figure 1.

The 4 featured components of AMN includes:

• Size of intention wheel R1: the intention wheel is a ﬁc-
titious component of an intention-based decision since it
is hardly measurable, it only refers to the initial driver of
a decision for which the size is apprehended by a coef-
ﬁcient, usually 3 in reference to the triangle made of the
occipital lobe, the frontal cortex and the thalamus, applied
to the motor core;

• Radius of the motor core r2: the motor core refers to the
reaction time of the user in the programming test, which
depends on the relative cognitive velocity of the subject in
a range of 1 to 5. This score sets the radius of the motor
core;

• Radius of the sensory core r3: the sensory core refers to
the emotional response of the user in the same test mir-
roring the reaction time, which depends on the valence-
arousal status of the user in a range of 1 to 5. This score
sets the radius of the sensory core:

• Velocity of the feed forward system v1: the velocity of the
feed forward system is the motor’s velocity and inversely
proportional to the age of the user, i.e. the decision maker.
To initialize a mirror neuron, the inputs are:

• the size of the intention wheel R1
• the motor core’s radius r1
• the sensory core’s radius r2
• the velocity of the motor core v1

The internal dynamic of each Artiﬁcial Mirror Neuron is
tri-cycloid whereas the intention wheel takes the form of a
hypocycloid, the motor core describes a cycloid and the sen-
sory core an epicycloid. When these 3 elements are com-
bined and put in motion, they can compute the behavior’s
complexity of a single unit of the natural architecture in-
volved in functional decision processing. They can also be
used to construct a model of acquisition of social skills such
as inter-personal communication of information whether by
imitation or reprocessing.

Figure 1: Tri-cycloid structure of the artiﬁcial mirror neuron.

Mathematical Formulations of AMN
Now we present the mathematical formulations of AMN and
outline the formulas governing the dynamics of the intention
wheel, motor core and sensory core.

Motor core The trajectory of the motor is a cycloid, which
is the curve traced by a point of the rim of a circular wheel
as the wheel rolls along a straight line without slipping.

The cycloid (motor core) runs through the origin, with a
horizontal base given by the x-axis, generated by a circle of
radius r rolling over the positive side of the base (y ≥ 0). Its
trajectory consists of the points (x, y), with

Sensory core Sensory core is an epicycloid, which is a
plane curve produced by tracing the path of a chosen point
on the circumference of a circle – called an epicycle – which
rolls without slipping around a ﬁxed circle.

If the small cycle has radius r, and the larger circle has
radius R=kr, then the parametric equations for the trajectory
of the epicycloid (sensory core) is given by either:
(cid:19)

x = (R + r) cos θ − r cos

y = (R + r) sin θ − r sin

(cid:18) R + r
r
(cid:18) R + r
r

θ

(cid:19)

θ

x = r (θ − sin θ)
y = r (1 − cos θ)

or

(1)
(2)

x = r (k + 1) cos θ − r cos ((k + 1) θ)
y = r (k + 1) sin θ − r sin ((k + 1) θ)

(5)

(6)

(7)
(8)

where θ is a real parameter, corresponding to the angle
through which the rolling circle has rotated. (See ﬁgure 3).
For given θ, the circle’s center lies at (x, y) = (rθ, r).

Solving for θ and replacing, the Cartesian equation of the

motor core is found to be:
x = r cos−1 (cid:16)

1 −

(cid:17)

y
r

− (cid:112)y(2r − y)

(3)

On the other hand, when y is viewed as a function of x,
the cycloid is differentiable everywhere except at the cusps,
where it hits the x-axis, with the derivative tending toward
inf or − inf as one approaches a cusp. The map from θ to
(x, y) is a differentiable curve, and the singularity where the
derivative is 0 is an ordinary cusp.

A cycloid segment from one cusp to the next is called an
arch of the cycloid. The ﬁrst arch of the cycloid consists of
points such that 0 ≤ θ ≤ 2π. All in all, the equation of the
cycloid (motor core) satisﬁes the differential equation:

where θ can be referred to in ﬁgure 3.

We can observe that if k is an integer, then the curve is
closed, and has k cusps. If k is a rational number, say k =
p/q expressed in simplest terms, then the curve has p cusps.
If k is an irrational number, then the curve never closes, and
forms a dense subset of the space between the larger circle
and a circle of the radius R + 2r.

Intention wheel An intention wheel is a hypocycloid,
which is a special plane curve generated by the trace of a
ﬁxed point on a small circle that rolls within a larger circle.
In AMN, the hypocycloid of the intention wheel depends
completely on the cycloid of the motor core.

If the small cycle has radius r, and the larger circle has
radius R=kr, then the parametric equations for the trajectory
of the hypocycloid (intention wheel) is given by either:

x = (R − r) cos θ + r cos

(cid:19)

θ

(cid:19)

(cid:18) R − r
r
(cid:18) R − r
r

θ

(9)

(10)

(cid:19)2

(cid:18) dy
dx

=

2r
y

− 1

(4)

y = (R − r) sin θ − r sin

Figure 3: Value of the angle θ at the deadline determines the
state of the neuron and the output value.

memory (memorial) and a new neuron (request neuron), that
move forward until they reach a preset deadline where the
state of each individual neuron is determined by the value
of the angle θ (see ﬁgure 3) and will qualify the network
for a sum state and deliver a prescription to make a decision
regarding the request. Figure 2 shows a structural view of
the racing mechanics.

The FNN model is an intention-based decision processing
system that delivers an output in the form of a sum of states.
The competing neurons are reaching the deadline in different
states and the network is deemed to deliver a prescription ac-
cording to the sum of states at the deadline. Then the output
result can trigger a near-natural decision such as buy or sell,
yes or no on behalf of the user. In other words, this personal
neural network has a human fuzzy logic effect and the idea
of extending each personal neural network to other personal
networks of similar structure is only logical and the sum of
all these networks can help to understand synchronicity in
human societies, organized markets and crowd psychology
regarding decision making especially these involved in crisis
whether social, ﬁnancial, medical or environmental.

Modelling human fuzzy logic for decision processing
means that each neuron has many-valued output. The cy-
cloid movement of the motor core along the timeline en-
sures that there are 360 values of truth between the 1 or
false and the 0 or true, both inclusive. Accordingly, the con-
ﬁdence score of the result will be 1 minus the value of truth
e.g. 0% at 1 (false) and 100% at 0 (true). This output model
delivers a binary response with conﬁdence score. Figure 3
illustrates the correspondence between angle degree in the
cycloid movement and output value.

In terms of formulas, we can express the binary response

and conﬁdence score for motor core of a node as

Binary response =

(vmt)%(2πr1)
2πr1

Conﬁdence score (in %) = (1 −

(vmt)%(2πr1)
2πr1

) · 100

where vm will be the velocity of the motor core.

Figure 2: Structural view of the racing mechanics of a Func-
tional Network of 8 competing neurons which can stop at a
preset deadline whether set in time or distance.

or

x = r (k − 1) cos θ + r cos ((k − 1) θ)
y = r (k − 1) sin θ − r sin ((k − 1) θ)

(11)
(12)
We can observe that if k is an integer, then the curve is
closed, and has k cusps. If k is a rational number, say k =
p/q expressed in simplest terms, then the curve has p cusps.
If k is an irrational number, then the curve never closes, and
ﬁlls the space between the larger circle and a circle of radius
R − 2r.

Lastly, the area enclosed by the hypocycloid and the arc

length of the hypocycloid are given by:

A =

(k − 1)(k − 2)
k2

and

πR2 = (k − 1)(k − 2)πr2

(13)

s =

8(k − 1)
k

πR = 8(k − 1)r

(14)

respectively.

Functional Neural Network (FNN) and Fuzzy
Logic
The mechanics of the Functional Mirror Network is based
on a pool of competing mirror neurons made of neurons in

Similarly, we can express the binary response and conﬁ-

dence score for sensory core of a node as

Binary response =

(vst)%(2πr2)
2πr2

Conﬁdence score (in %) = (1 −

(vst)%(2πr2)
2πr2

) · 100

where vs will be the velocity of the sensory core.

For the FNN, we can deﬁne also the concept of group
binary response and conﬁdence score of the motor cores and
the sensory cores in the network respectively. In terms of
formulas, we can express them as follows. For motor cores
of N nodes we have,

1
N

N
(cid:88)

(cid:20) (vmit)%(2πr1i)
2πr1i

(cid:21)

Group binary response =

i=1
Group conﬁdence score (in %) =
(cid:20) (vmit)%(2πr1i)
2πr1i

N
(cid:88)

1
N

1 −

(cid:32)

i=1

(cid:21)(cid:33)

· 100

where vmi are be the velocity of the i-th motor core. On the
other hand, for sensory cores of N nodes we have,

1
N

N
(cid:88)

(cid:20) (vsit)%(2πr2i)
2πr2i

(cid:21)

Group binary response =

i=1
Group conﬁdence score (in %) =
(cid:20) (vsit)%(2πr2i)
2πr2i

N
(cid:88)

1
N

1 −

(cid:32)

i=1

(cid:21)(cid:33)

· 100

where vsi are be the velocity of the i-th sensory core.

From the group binary response and conﬁdence score of
the motor cores and sensory cores, we can deduce and ana-
lyze the expert consensus and group consensus and derive
the various additional functions based on these computa-
tions, for example, after ﬁnding the best performers in terms
of the binary response, we can compute the ideal velocities
for those low performers to boost in order to achieve the per-
formance of the best performers. We are going to layout the
whole framework in the following sections.

In our FNN model, the loss function is based on the binary
response of the nodes. The loss function captures the differ-
ence between the predicted binary response and the correct
decision.

Loss function = (cid:107)ypredicted − y(cid:107)

where ypredicted is the predicted binary response, which can
be in terms of individual or group, and y is the correct deci-
sion.

Important algorithms and methods of FNN
The functional mirror network for decision processing is a
cognitive computing design that aims to describe the follow-
ing mechanisms of the brain in reference to two distinctive

groups of algorithms and new methods regarding the execu-
tive decision and/or the intuitive decision including calculat-
ing the time response of a single neuron, ﬁnding the expert
consensus in the network, boosting the velocity of certain
neurons based on the preset deadline, anticipating the best
performer, the best result, the best performance and plan-
ning for boosting reward.

Modeling executive decision, new methods and algo-
rithms for the motor core:

• MOTOR TIME RESPONSE: to compute the average an-
gle θ (see ﬁgure 3) and the group binary response and con-
ﬁdence score of the motor cores in the network according
to the rule of the fuzzy logic with preset time deadline;

• MOTOR DISTANCE RESPONSE: to compute the aver-
age angle θ (see ﬁgure 3) and the group binary response
and conﬁdence score of the motor cores in the network ac-
cording to the rule of the fuzzy logic with preset distance
deadline;

• MOTOR NET COMPETE: to select the best performers
based on their motor cores performance in the network
according to the rule of the fuzzy logic with a preset time
deadline. This method can contribute to building an “ex-
pert mirror network”;

• MOTOR BOOST REQUEST: to boost the velocity of low
performers motor core according to the ratio of the best
performers. In other words, to compute how much the ve-
locity (in %) of low performance motor cores should be
increased to meet the performance of the best performers.

• MOTOR BOOST REWARD: to call both the MOTOR
NET COMPETE and MOTOR BOOST REQUEST in or-
der to anticipate reward. Based on the new average binary
response and conﬁdence score computed in the network
for a speciﬁc request, this method combines the expert
mirror network (best performers per request type) with
boost request (increased velocities) to anticipate perfor-
mance and reward.

• IDEAL TIME: to predict best results according to a time
deadline comparatively to the function of best performers.

• IDEAL DISTANCE: to predict best results according to
a distance deadline comparatively to the function of best
performance.

Modeling intuitive decision, new methods and algo-
rithms for the sensory core:

• The SENSORY TIME RESPONSE: to compute the an-
gle θ (see ﬁgure 3) angle and the group binary response
and conﬁdence score of the sensory cores in the network
according to the rule of the fuzzy logic with preset time
deadline;

• SENSORY DISTANCE RESPONSE: to compute the an-
gle θ (see ﬁgure 3) angle and the group binary response
and conﬁdence score of the sensory cores in the network
according to the rule of the fuzzy logic with preset dis-
tance deadline;

are both deﬁned on the same x-axis and share some math-
ematic properties, they may not be identical as shown in
ﬁgure 4. Motor core and sensory core are not necessarily
synchronized depending on their respective sizes and veloc-
ities. That leads us to introduce the concepts of relative syn-
chronicity and true asynchrony between the executive and
intuitive parts of a same decision process or between dif-
ferent processes regarding the motor and sensory cores’ be-
haviors. This research direction opens the way to simulation
of the learning process(es) whether by accelerating, slow-
ing down, or controlling it with applications in education
such as computer-assisted training, enhanced learning, spe-
cial needs education for autists, or cognitive behavioral ther-
apy (CBT) such as desensitization to control phobias and
anxiety, and reconditioning. It could also allow psychiatrists
and neuropsychologists to better understand the relationship
between disorderly learning and personality disorders, ad-
dictions, and criminal misconducts.

Learning agent with application in Artiﬁcial
General Intelligence
Apart from the direct applications in the ﬁelds of ﬁnance
and medicine, we can also foresee the potential of the FNN
in the design of learning agent for Artiﬁcial General Intel-
ligence (AGI). AGI is a strong AI that has the capacity to
understand or learn to execute an intellectual task like a hu-
man being. Because FNN has the capacity to process a de-
cision, prescribe a decision trend while forcing the feedback
into a performance memorial, it could act as a cognitive ad-
visor rendering cognitive computing services that can me-
diate human-machine interactions and enhance signiﬁcantly
the performance of complex business environments such as
regulated ﬁnancial markets. In this sense, AGI can become
an intelligent regulator for business supervision as shown
in Figure 5. In this design, the receptors are a selection of
pre-synaptic neurons running in FNN(s) and the effectors
are post-synaptic neurons that are connected to the FNN by
synaptic gates for performance optimization. The gating and
ﬁring will take advantage of the feedback from the deci-
sions made by the user in relation to the FNN prescriptions,
whether correct or not, and from the ﬁnal effect of the deci-
sion on real business operations. The feedback will create a
retrograde signaling to affect the gates’ subsequent ﬁrings.
The learning patterns will accumulate in the LSTM perfor-
mance memorial to serve as a database of the conduct edge.
A conduct edge is a subplot using a database of observed
conducts or performance memorial (LSTM) to react to an
incoming signal captured by the receptors in the business
environment. On the other side of the Learning Element, the
Policy Administrator is another subplot that can cause the
Governance, Risk management and Compliance (GRC) li-
brary to trial the conduct notice issued upon reception of
a bad label, and make the Cognitive Expert Advisor learn,
concur and effect a decision.

Conclusion
In this paper we have proposed a novel model of Artiﬁcial
General Intelligence (AGI), the Functional Neural Network

Figure 4: The velocity and radius of motor core and sensory
core can be different.

• SENSORY NET COMPETE: to select the best perform-
ers based on the sensory cores in the network according
to the rule of the fuzzy logic with a preset time deadline;
• SENSORY BOOST REQUEST: to boost the velocity of
low performers of sensory core according to the ratio
of the best performers. In other words, to compute how
much the velocity (in %) of low performance motor cores
should be increased to meet the performance of the best
performers.

• SENSORY BOOST REWARD: to call both the SEN-
SORY NET COMPETE and MOTOR BOOST RE-
QUEST to anticipate reward. Based on the new average
binary response and conﬁdence score computed in the
network for a speciﬁc request, this method combines the
expert mirror network (best performers per request type)
with boost request (increased velocities) to anticipate per-
formance and reward.

Future research directions and applications

Simulations in Finance
One of the key parameters of the FNN is the velocity of the
cores of different nodes competing against a preset deadline.
In the current conﬁguration, we are assuming that all veloc-
ities are set when the nodes are initialized. Based on this
initial setup, we have developed some core functions such
as NET COMPETE, BOOST REQUEST and BOOST RE-
WARD. But we are keen to extend the concept of velocity to
allow acceleration and deceleration of the nodes to simulate
scenarios closer to real life such as fast-cycling markets risk
management and high frequency trading. This research di-
rection can not only lead to testing new models of decision
making for the actors of ﬁnancial markets, but also enable
more accurate simulations in ﬁnance and trading that can
also be applied to the supply chain in anticipation of the de-
mand.

Simulation in Medicine
In the methodology, we have separated the algorithms and
methods of the FNN into two groups, one of them relates to
the motor core and the other to the sensory core. It is im-
portant to note that although motor core and sensory core

Figure 5: Intelligent Learning Regulator for business operations supervision.

(FNN) for modeling of human decision-making processes.
The FNN is made of multiple Artiﬁcial Mirror Neurons
(AMN) racing in the network. Each neuron has the same
structure comprising motor core, sensory core and intention
wheel and a speciﬁc velocity. We have discussed the struc-
ture of a simple AMN and its mathematical formulation. We
have illustrated the racing mechanism of multiple nodes in
the FNN, the group decision process using fuzzy logic and
how to transform these conceptual methods into practical
methods of simulation and in operations. Finally, we have
presented possible future research directions in the ﬁelds of
ﬁnance, education and medicine including the opportunity to
design an intelligent learning agent with application in AGI.
We believe that FNN promises to transform the way we can
compute decision-making and lead to a new generation of
AI chips for seamless human-machine interactions.

Acknowledgment. The theory presented in this paper is
based on three of our patents, namely, ”Method for In-
formed Decision Making” and ”System for Informed De-
cision Making”, Frederic Andre Jumelle, Yu Zhao and Yat
Wan Lui, Hong Kong short-term patents grant certiﬁcate
No. HK30012597A and No. HK30024011A, and ”Method
and System for Informed Decision Making”, Frederic An-
dre Jumelle, Yu Zhao and Yat Wan Lui, international patent
application No. PCT/CN2019/124550.

References
Alpcan, T.; Erfani, S. M.; and Leckie, C. 2017. Toward the
starting line: A systems engineering approach to strong AI.
arXiv preprint arXiv:1707.09095 .

Christov-Moore, L.; Conway, P.; and Iacoboni, M. 2017.
Deontological dilemma response tendencies and sensorimo-
tor representations of harm to others. Frontiers in integrative
neuroscience 11: 34.

Deng, D.; Chen, Z.; Zhou, Y.; and Shi, B. 2019. MIMAMO
Net: Integrating Micro-and Macro-motion for Video Emo-
tion Recognition. arXiv preprint arXiv:1911.09784 .
Gams, M.; et al. 1997. Is weak AI stronger than strong AI?
Mind Versus Computer: Were Dreyfus and Winograd Right .
Ghosh-Dastidar, S.; and Adeli, H. 2009. Spiking neural net-
works. International journal of neural systems 19(04): 295–
308.
Goodfellow, I. 2016. NIPS 2016 tutorial: Generative adver-
sarial networks. arXiv preprint arXiv:1701.00160 .
Goodfellow, I.; Pouget-Abadie, J.; Mirza, M.; Xu, B.;
Warde-Farley, D.; Ozair, S.; Courville, A.; and Bengio, Y.
In Advances in neural
2014. Generative adversarial nets.
information processing systems, 2672–2680.
Kilroy, E.; and Aziz-Zadeh, L. 2017. Neuroimaging re-
search on empathy and shared neural networks. Empathy-an
evidence-based interdisciplinary perspective 619–634.
Long, L. N.; and Cotner, C. F. 2019. A Review and Proposed
Framework for Artiﬁcial General Intelligence. In 2019 IEEE
Aerospace Conference, 1–10. IEEE.
Mahmood, Z.; Muhammad, N.; Bibi, N.; and Ali, T. 2017.
A review on state-of-the-art face recognition approaches.
Fractals 25(02): 1750025.
Rajan, K.; and Safﬁotti, A. 2017. Towards a science of inte-
grated AI and Robotics.
ˇSekrst, K. 2020. AI-Completeness: Using Deep Learning
to Eliminate the Human Factor. In Guide to Deep Learning
Basics, 117–130. Springer.
Shillcock, R.; Thomas, J.; and Bailes, R. 2019. Mirror neu-
rons, prediction and hemispheric coordination: the prioritiz-
ing of intersubjectivity over ‘intrasubjectivity’. Axiomathes
29(2): 139–153.

Strong, A. 2016. Applications of artiﬁcial intelligence &
associated technologies. Science [ETEBMS-2016] 5(6).
Sun, X.; Wu, P.; and Hoi, S. C. 2018. Face detection using
deep learning: An improved faster RCNN approach. Neuro-
computing 299: 42–50.
Wang, X.; Lin, X.; and Dang, X. 2020. Supervised learn-
ing in spiking neural networks: A review of algorithms and
evaluations. Neural Networks .
Zhang, J. J.; Fong, K. N.; Welage, N.; and Liu, K. P. 2018.
The activation of the mirror neuron system during action ob-
servation and action execution with mirror visual feedback
in stroke: a systematic review. Neural plasticity 2018.

