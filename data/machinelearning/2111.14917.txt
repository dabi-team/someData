57

1
2
0
2

v
o
N
9
2

]
L
P
.
s
c
[

1
v
7
1
9
4
1
.
1
1
1
2
:
v
i
X
r
a

A Separation Logic for Negative Dependence

JIALU BAO, Cornell University, USA
MARCO GABOARDI, Boston University, USA
JUSTIN HSU, Cornell University, USA
JOSEPH TASSAROTTI, Boston College, USA

Formal reasoning about hashing-based probabilistic data structures often requires reasoning about random
variables where when one variable gets larger (such as the number of elements hashed into one bucket), the
others tend to be smaller (like the number of elements hashed into the other buckets). This is an example
of negative dependence, a generalization of probabilistic independence that has recently found interesting
applications in algorithm design and machine learning. Despite the usefulness of negative dependence for
the analyses of probabilistic data structures, existing veriï¬cation methods cannot establish this property for
randomized programs.

To ï¬ll this gap, we design LINA, a probabilistic separation logic for reasoning about negative dependence.
Following recent works on probabilistic separation logic using separating conjunction to reason about the
probabilistic independence of random variables, we use separating conjunction to reason about negative
dependence. Our assertion logic features two separating conjunctions, one for independence and one for
negative dependence. We generalize the logic of bunched implications (BI) to support multiple separating
conjunctions, and provide a sound and complete proof system. Notably, the semantics for separating con-
junction relies on a non-deterministic, rather than partial, operation for combining resources. By drawing on
closure properties for negative dependence, our program logic supports a Frame-like rule for negative depen-
dence and monotone operations. We demonstrate how LINA can verify probabilistic properties of hash-based
data structures and balls-into-bins processes.

Additional Key Words and Phrases: Probabilistic programs, separation logic, negative dependence

1 INTRODUCTION
Hashing plays a fundamental role in many probabilistic data structures, from basic hash tables to
more sophisticated schemes such as Bloom ï¬lters. In these applications, a hash function â„ maps
a universe of possible values, typically large, to a set of buckets, typically small. Hash-based data
structures satisfy a variety of probabilistic guarantees. For instance, we may be interested in the
false positive rate: the probability that a data structure mistakenly identiï¬es an element as being
stored in a collection, when it was not inserted. We may also be interested in load measures, such
as the probability that a bucket in the data structure overï¬‚ows. A typical way to analyze these
quantities is to treat random hash functions as balls-into-bins processes. For example, hashing ğ‘
unique elements into ğµ bins can be modeled as throwing ğ‘ balls into ğµ bins, where each bin is
drawn uniformly at random.

While this modeling is convenient, one complication is that the counts of the elements in the
diï¬€erent buckets are not probabilistically independent: one bin containing many elements makes
it more likely that other bins contain few elements. The lack of independence makes it diï¬ƒcult

Authorsâ€™ addresses: Jialu Bao, Cornell University, USA; Marco Gaboardi, Boston University, USA; Justin Hsu, Cornell Uni-
versity, USA; Joseph Tassarotti, Boston College, USA.

Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee
provided that copies are not made or distributed for proï¬t or commercial advantage and that copies bear this notice and
the full citation on the ï¬rst page. Copyrights for third-party components of this work must be honored. For all other uses,
contact the owner/author(s).
Â© 2022 Copyright held by the owner/author(s).
2475-1421/2022/1-ART57
https://doi.org/10.1145/3498719

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

 
 
 
 
 
 
57:2

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

to reason about multiple bins, for instance bounding the number of empty bins. Moreover, many
common tools for analyzing probabilistic processes, like concentration bounds, usually require in-
dependence. This subtlety has also been a source of problems in pen-and-paper analyses of proba-
bilistic data structures. For instance, the standard analysis of the Bloom ï¬lter bounds the number
of occupied bins in order to bound the false positive rate. The original version of this analysis
presented by Bloom [1970], and also repeated in many papers, assumes that the bin counts are
independent. However, Bose et al. [2008] pointed out that this assumption is incorrect, and in fact
the claimed upper-bound on the false-positive rate is actually a lower bound. Proving a correct
bound on the false-positive rate required a substantially more complicated argument; recently,
Gopinathan and Sergey [2020] mechanized a correct, but complex proof in Coq.

We aim to develop a simpler method to formally reason about hash-based data structures and

balls-into-bins processes, drawing on a key concept in probability theory: negative dependence.

Towards a simpler analysis: negative dependence. To study balls-into-bins processes and other

phenomena, researchers in probability theory have developed a theory of negative dependence [Pemantle
2000]. Intuitively, variables are negatively dependent if when one is larger, then the others tend to
be smaller. The counts of the bins in the balls-into-bins process is a motivating example of negative
dependence.

While there are multiple incomparable deï¬nitions of negative dependence, Joag-Dev and Proschan

[1983] proposed a notion called negative association (NA) that has many good probabilistic proper-
ties. For instance, the binsâ€™ counts in the balls-into-bins process satisï¬es NA, and NAâ€™s closure prop-
erties enable simple, calculation-free proofs of NA. More intriguingly, as Dubhashi and Ranjan
[1998] identiï¬ed, sums of NA variables satisfy some concentration bounds that usually assume
probabilistic independence, including the widely-used Chernoï¬€ bounds.

Our goal: formal reasoning about negative dependence. From a veriï¬cation perspective, the clo-
sure properties suggest a compositional method for proving NA in probabilistic programs. In this
work, we develop a separation logic for negative dependence, building on a separation logic for
probabilistic programs called PSL [Barthe et al. 2020]. Like all separation logics, PSL is a program
logic where assertions are drawn from the logic of bunched implications (BI) [Oâ€™Hearn and Pym
1999], a substructural logic. In PSL, the separating conjunction âˆ— states that two sets of variables
are probabilistically independent, a common and useful property when analyzing probabilistic
programs.

We aim to extend the assertions of PSL so that they can describe both independence and negative

dependence. There are three main diï¬ƒculties:

â€¢ To support reasoning about negative dependence, the assertion logic needs to be extended
with a second separating conjunction that is weaker than the separating conjunction of PSL.
It is easy to extend the syntax of formulas, but the extended logic should also enjoy good
metatheoretical properties like BI does, including a sound and complete proof system.

â€¢ The standard resource semantics of BI [Pym 2002], based on partial commutative monoids
(PCMs), is not expressive enough to model negative association because two variables with
given marginal distributions can be negatively associated in more than one way.

â€¢ Deï¬ning the semantics of separating conjunction to capture NA is surprisingly challenging.
Straightforward deï¬nitions fail to satisfy expected properties, like associativity of separating
conjunction.

Beyond the assertions, it is also unclear how to integrate negative association with the proof rules
of PSL. In particular, to view negative association as a kind of separation, our program logic should
have an analogue of the Frame rule for NA.

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:3

Contributions and outline. In this paper, we oï¬€er the following contributions.

â€¢ A novel logic ğ‘€-BI that extends BI with multiple separating conjunctions, related by a pre-
order. Following Docherty [2019], models of ğ‘€-BI allow two states to be combined into a
single state in more than one way (Section 3). We develop a proof system for ğ‘€-BI, and use
Dochertyâ€™s duality-theoretic approach to prove soundness and completeness.

â€¢ A probabilistic model of ğ‘€-BI that can capture both the independence and negative associ-

ation (Section 4). There are two interesting aspects of our model:
â€“ We crucially use the â€œnon-deterministicâ€ combination of resources allowed by Dochertyâ€™s
semantics of BI. While this semantics was originally used to simplify the metatheory of
BI, our model shows that the added ï¬‚exibility can enable new applications of the logic.

â€“ Our model relies on a novel notion called PNA that is more expressive than Joag-Dev and Proschan

[1983]â€™s NA. The generalization is needed to satisfy the conditions for an ğ‘€-BI model.
Moreover, the closure properties and useful consequences of NA continue to hold for our
generalization.

â€¢ A program logic, LINA (Logic of Independence and Negative Association), extending PSL
with ğ‘€-BI-assertions and a new negative-association Frame rule (Section 5). Being a conser-
vative extension of PSL, the proof rules of PSL remain valid in LINA. We demonstrate our
program logic by proving negative association and related properties on several case studies
(Section 6). For example, using NA, it is possible to give a signiï¬cantly simpler veriï¬cation of
the false positive rate of the Bloom ï¬lter. Another exampleâ€”an analysis of a repeated balls-
into-bins process motivated by distributed computingâ€”involves a loop with a probabilistic
guard, and requires reasoning about conditional distributions.

We discuss related work in Section 7, and conclude in Section 8.

2 OVERVIEW AND KEY IDEA

In this section, we introduce negative association as a tool for analyzing hashing-based algorithms.
We use Bloom ï¬lters, a hash-based data structure, as a motivating example. After sketching a
standard proof applying negative association to Bloom ï¬lters, we will show how the same analysis
can be formalized in LINA.

2.1 Background on negative association
Negative association is a property of a set of random variables, which intuitively says that when
some variables are larger, we expect the others to be smaller. It is formalized as follows:

Deï¬nition 2.1 (Negative Association (NA)). Let ğ‘‹1, . . . ğ‘‹ğ‘› be random variables. The set {ğ‘‹ğ‘– }ğ‘– is
negatively associated (NA) if for every pair of subsets ğ¼, ğ½ âŠ† {1, . . . , ğ‘›} such that ğ¼ âˆ© ğ½ = âˆ…, and
every pair of both monotone or both antitone functions1 ğ‘“ : R|ğ¼ | â†’ R and ğ‘” : R|ğ½ | â†’ R, where
ğ‘“ , ğ‘” is either lower bounded or upper bounded, we have:

E[ğ‘“ (ğ‘‹ğ‘–, ğ‘– âˆˆ ğ¼ ) Â· ğ‘”(ğ‘‹ ğ‘—, ğ‘— âˆˆ ğ½ )] â‰¤ E[ğ‘“ (ğ‘‹ğ‘–, ğ‘– âˆˆ ğ¼ )] Â· E[ğ‘”(ğ‘‹ ğ‘—, ğ‘— âˆˆ ğ½ )]

We can view NA as generalizing independence: a set of independent random variables is NA
because equality holds. NA also strengthens negative covariance, a simpler notion of negative de-
ğ‘– âˆˆ[ğ‘› ] E[ğ‘‹ğ‘–].
pendence that requires E[

ğ‘– âˆˆ[ğ‘› ] ğ‘‹ğ‘– ] â‰¤

The survey paper by Dubhashi and Ranjan [1998] explains several properties of NA random
variables useful for algorithm analysis. First, some standard theorems about sums of independent

Ã

Ã

1In the following, we will consistently use monotone to mean monotonically non-decreasing and antitone to mean mono-
tonically non-increasing.

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:4

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

random variables apply more generally to sums of NA random variables. In particular, the widely-
used Chernoï¬€ bound, which intuitively says that the sum of independent random variables is close
to the expected value of the sum with high probability, holds also for NA variables. In addition,
NA is preserved by some common operations on random variables. Thus, we can easily prove that
a set of random variables satisï¬es NA if they are generated by applying NA-preserving operations
to a few basic, building-block random variables:

Theorem 2.2. The random variables {ğ‘‹ğ‘– }ğ‘– in the following cases are negatively associated:
(1) Let {ğ‘‹1, . . . , ğ‘‹ğ‘›} be Bernoulli random variables such that
(2) Let ğ‘‹ğ‘– be the ğ‘–-th entry in the vector ğ‘‹ , where ğ‘‹ is a uniformly random permutation of a ï¬nite,

ğ‘‹ğ‘– = 1.

nonempty set ğ´.

(3) Let {ğ‘‹1, . . . , ğ‘‹ğ‘›} be independent random variables.

Ã

In particular, the ï¬rst case of this theorem implies that if we draw a length-ğ‘› one-hot vector, i.e.,
a vector that has one entry being one and all remaining entries being zero, uniformly at random,
then the entries of the vector satisfy negative association.

The following theorem states two key closure properties of NA random variables.

Theorem 2.3. The set ğ‘† of random variables in the following cases are negatively associated:
(1) Let ğ‘‡ be negatively associated, and let ğ‘† be a non-empty subset of ğ‘‡ .
(2) Let ğ‘‡ and ğ‘ˆ be two sets of negatively associated random variables such that every ğ‘‹ âˆˆ ğ‘‡ and

ğ‘Œ âˆˆ ğ‘ˆ is independent of each other. Let ğ‘† = ğ‘‡ âˆª ğ‘ˆ .

(3) Let {ğ‘‹1, . . . ğ‘‹ğ‘›} be negatively-associated, and ğ¼1, . . . , ğ¼ğ‘š be a partition of the set {1, . . . , ğ‘›}. For
each 1 â‰¤ ğ‘— â‰¤ ğ‘š, let ğ‘“ğ‘— : R|ğ¼ ğ‘— | â†’ R be monotone. Let ğ‘† = {ğ‘“1 (ğ‘‹ğ‘˜, ğ‘˜ âˆˆ ğ¼1), . . . , ğ‘“ğ‘š (ğ‘‹ğ‘˜, ğ‘˜ âˆˆ ğ¼ğ‘š)}.

The ï¬rst case shows that negative association is preserved if we discard random variables, while
the second case allows us to join two independent sets of negatively associated random variables to
form a larger negatively associated set. Finally, the third case guarantees that negative association
is preserved under applying monotone maps on disjoint subsets of variables.

2.2 Example: Bloom filters

We demonstrate how NA and its closure properties can be used to analyze Bloom ï¬lters. A Bloom
ï¬lter is a space-eï¬ƒcient probabilistic data structure for storing a set of items from a universe ğ‘ˆ .
An ğ‘ -bit Bloom ï¬lter consists of a length-ğ‘ array ğ‘ğ‘™ğ‘œğ‘œğ‘š holding zero-one entries. We assume
there is a family A of hash functions mapping ğ‘ˆ to {0, . . . , ğ‘ âˆ’ 1} such that for any ğ‘¥ âˆˆ ğ‘ˆ and
any bucket ğ‘˜, Pğ‘“ âˆˆA (ğ‘“ (ğ‘¥) = ğ‘˜) = 1/ğ‘ . Let ğ‘™1, . . . , ğ‘™ğ» be a collection of hash functions drawn from
A. We assume the hash functions are independent, meaning the collection of variables {ğ‘™ğ‘– (ğ‘¥) |
ğ‘¥ âˆˆ ğ‘ˆ , ğ‘– âˆˆ {1, . . . , ğ» }} are mutually independent. To add an item ğ‘¥ âˆˆ ğ‘ˆ to the ï¬lter, we compute
ğ‘™1(ğ‘¥), . . . , ğ‘™ğ» (ğ‘¥) to get ğ» positions in the bit array and then set the bits at each of these positions
to 1. To check if an item ğ‘¦ is in the ï¬lter, we check whether the bits at positions ğ‘™1 (ğ‘¦), . . . , ğ‘™ğ» (ğ‘¦) in
ğ‘ğ‘™ğ‘œğ‘œğ‘š are all 1. If they are, the item is said to be in the ï¬lter, but if any is 0, then the item is not
in the ï¬lter. This membership test may suï¬€er from false positives, i.e., it may show that an item
ğ‘¦ is in the ï¬lter even when ğ‘¦ was never added to the ï¬lter. This can happen because with hash
collisions, other items added to the Bloom ï¬lter could set all the bits at locations ğ‘™1 (ğ‘¦), . . . , ğ‘™ğ» (ğ‘¦)
to 1. A basic quantity of interest is the false positive rate: the probability that a Bloom ï¬lter reports
a false positive.

Our goal is to bound an ğ‘ -bit Bloom ï¬lterâ€™s false positive rate after ğ‘€ distinct items are added,
assuming that it uses ğ» independent hash functions. Here, we brieï¬‚y sketch a standard proof
where negative association plays a key role. Let ğ‘¥ be some data item not in the set, and let FP be

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:5

the event the Bloom ï¬lter returns a false positive on ğ‘¥. We split the analysis of the probability of
FP into two steps.

For the ï¬rst step, we condition on ğœŒ, the fraction of bits in ğ‘ğ‘™ğ‘œğ‘œğ‘š that are set to 1 after all
items have been added. With ğœŒ ï¬xed to some value, for each hash function ğ‘™ğ›¼ the probability that
ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ‘™ğ›¼ (ğ‘¥)] = 1 is ğœŒ. For ğ‘¥ to be a false positive, we must have ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ‘™ğ›¼ (ğ‘¥)] = 1 for all ğ›¼. Since
ğ‘™1, . . . , ğ‘™ğ» are independent hash functions, this occurs with probability ğœŒğ» .

The next step is to show that with high probability, ğœŒ lies within a narrow range around its
expected value. Before showing how to prove this, let us ï¬rst see why such a bound is useful. Let ğœ‡
be the expected value of ğœŒ. Suppose we have that for some small ğœ– and ğ›¿ that Pr[ğœŒ â‰¤ ğœ‡ +ğœ–] â‰¥ 1 âˆ’ğ›¿.
Then, by the law of total probability we have:

Pr[FP] â‰¤ Pr[FP | ğœŒ â‰¤ ğœ‡ + ğœ–] + Pr[ğœŒ > ğœ‡ + ğœ–]

â‰¤ (ğœ‡ + ğœ–)ğ» + ğ›¿

where the second line follows from the calculation of the probability of FP when conditioned on
ğœŒ.

Now, we turn to the question of how to obtain a bound of the form Pr[ğœŒ â‰¤ ğœ‡ + ğœ–] < 1 âˆ’ ğ›¿. As
mentioned in Section 1, a common (incorrect) analysis of ğœŒ assumes that the entries of ğ‘ğ‘™ğ‘œğ‘œğ‘š are
independent, and then applies a Chernoï¬€ bound. However, the entries in ğ‘ğ‘™ğ‘œğ‘œğ‘š, {ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]}ğ›½, are
not independentâ€”what we can actually prove is that are negatively associated, which fortunately
still allows us to apply the Chernoï¬€ bound, as stated later in Theorem 6.1.

â„ â† 0
while â„ < ğ» do

ğ‘ğ‘™ğ‘œğ‘œğ‘š â† ğ‘§ğ‘’ğ‘Ÿğ‘œ (ğ‘ );
ğ‘š â† 0;
while ğ‘š < ğ‘€ do

To see that the {ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]}ğ›½ are NA, consider the program in
Figure 1, which models the process of adding ğ‘€ distinct items to
the Bloom ï¬lter. Because the ğ‘€ items are distinct, we model the
hash functions as independently, randomly sampling hash values
for each item as they are added, a standard model used in the anal-
ysis of hashing data structures [Mitzenmacher and Upfal 2005].
That is, we encode the hashing step as sampling a one-hot vec-
tor with the command ğ‘œâ„ and storing it in the variable ğ‘ğ‘–ğ‘›, where
the hot bit of the vector ğ‘ğ‘–ğ‘› represents the selected position. To set
the corresponding position in the ï¬lter to 1, we update ğ‘ğ‘™ğ‘œğ‘œğ‘š to
be ğ‘ğ‘™ğ‘œğ‘œğ‘š || ğ‘ğ‘–ğ‘›, the bitwise-or of the current array and the sampled
one-hot array. To show that {ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]}ğ›½ are NA, we can reason
using the closure properties. Initially, ğ‘ğ‘™ğ‘œğ‘œğ‘š is set to ğ‘§ğ‘’ğ‘Ÿğ‘œ (ğ‘ ). Any
set of constant random variables is independent, and hence negatively associated by Theorem 2.3.
Next, when an item is added, the ğ‘ğ‘–ğ‘› array is NA by Theorem 2.2. Because ğ‘ğ‘–ğ‘› is sampled indepen-
dently of ğ‘ğ‘™ğ‘œğ‘œğ‘š, the set {ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]}ğ›½ âˆª {ğ‘ğ‘–ğ‘›[ğ›½]}ğ›½ is NA. The bitwise-or operation || is monotone,
so again by Theorem 2.3, the array ğ‘¢ğ‘ğ‘‘ is negatively associated, thereby showing that ğ‘ğ‘™ğ‘œğ‘œğ‘š is
NA at the end of each loop iteration.

ğ‘ğ‘–ğ‘› $â† ğ‘œâ„( [ğ‘ ]);
ğ‘¢ğ‘ğ‘‘ â† ğ‘ğ‘™ğ‘œğ‘œğ‘š || ğ‘ğ‘–ğ‘›;
ğ‘ğ‘™ğ‘œğ‘œğ‘š â† ğ‘¢ğ‘ğ‘‘;
â„ â† â„ + 1;

Fig. 1. Example: Bloom filter

ğ‘š â† ğ‘š + 1

2.3 Representing negative association with separating conjunction

Now that we have seen some properties of negative association and how they can be used to
analyze the Bloom ï¬lter, we give a high-level explanation of how these ideas are formalized in
LINA, a novel program logic that is a core contribution of our work. As mentioned in Section 1,
an earlier separation logic PSL has a separating conjunction âˆ— which is interpreted as probabilistic
independence. That is, a program state satisï¬es ğ‘ƒ âˆ— ğ‘„ if its randomized program variables can
be split so that one subset satisï¬es ğ‘ƒ, another satisï¬es ğ‘„, and the distributions of these two sets
are independent. LINA augments PSL with a weaker separating conjunction âŠ› modeling negative

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:6

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

association. The precise deï¬nition of negative association needs to be modiï¬ed to form a proper
model of bunched implications, but for now, one can informally think of ğ‘ƒ âŠ› ğ‘„ as meaning the
random variables can be split into two sets negatively associated with each other that satisfy ğ‘ƒ
and ğ‘„ respectively.

The proof rules of LINA can be used to prove NA by applying closure properties to building-
block NA-distributions, much like in our proof sketch above for the Bloom ï¬lter. For example, we
can derive a rule that captures NA of entries in a one-hot distribution:

âŠ¢{âŠ¤} ğ‘¥ $â† ğ‘œâ„(ğ‘›) { ğ‘›âŠ›

ğ›½=0

hğ‘¥ [ğ›½]i} ,

where the assertion hğ‘¦i means that the program variable ğ‘¦ is distributed according to some un-

speciï¬ed probability distribution, and âŠ› is an iterated version of the âŠ› separating conjunction.

Thus, the post-condition here says that all of the entries of the ğ‘¥ vector are negatively associated.
Meanwhile, since NA is closed under monotone maps, we obtain a form of separation logicâ€™s

frame rule for âŠ›:

âŠ¢ {ğœ™ } ğ‘ {ğ‘¦ âˆ¼ ğ‘“ (ğ‘‹ )}

ğ‘“ monotone

(side conditions omitted)

âŠ¢ {ğœ™ âŠ› ğœ‚} ğ‘ {hğ‘¦i âŠ› ğœ‚}

,

where ğ‘‹ is a set of variables contained in any program states satisfying ğœ™, ğ‘“ is a monotone func-
tion mapping ğ‘‹ to a variable ğ‘¦, and ğœ‚ is an assertion on some other random variables that are
negatively associated with those satisfying ğœ™. (We describe a complete version of this rule with
all side conditions later, in Section 5.4.) Using this rule, we can show monotone vector operations
like || in the Bloom ï¬lter example preserve negative associativity. For example, we can derive:

âŠ¢{ ğ‘›âŠ›

ğ›½=0

hğ‘¥ [ğ›½]i âŠ›

ğ‘›âŠ›

ğ›¾=0

hğ‘¦ [ğ›¾]i} ğ‘§ â† ğ‘¥ || ğ‘¦ { ğ‘›âŠ›

ğ›½=0

hğ‘§ [ğ›½]i} ,

which says that if the union of entries in ğ‘¥ and entries in ğ‘¦ satisfy NA, then entries in ğ‘§ = ğ‘¥ || ğ‘¦
also satisfy NA.

We now sketch how to formalize the proof that {ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]}ğ›½ in the Bloom ï¬lter are NA; we defer
the rest of the proof of this example to Section 6. The basic idea is to establish âŠ›ğ‘

ğ›½=0 hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]i
as a loop invariant. When an item is added in the loop, we combine the frame rule with the
one-hot sampling vector rule to get that the ğ‘ğ‘–ğ‘› vector is negatively associated, thus showing:

ğ›¾=0 hğ‘ğ‘–ğ‘›[ğ›¾]i. Applying the rule for || above, we obtain that ğ‘¢ğ‘ğ‘‘ is neg-

ğ›½=0 hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]i âŠ› âŠ›ğ‘
âŠ›ğ‘
atively associated, âŠ›ğ‘

ğ›½=0hğ‘¢ğ‘ğ‘‘ [ğ›½]i. At that point ğ‘¢ğ‘ğ‘‘ is assigned to ğ‘ğ‘™ğ‘œğ‘œğ‘š, restoring the loop

invariant.

3 THE LOGIC ğ‘€-BI

Having seen the role of negative association in analyzing randomized algorithms and how its prop-
erties correspond to rules in LINA, we now show how negative association can be interpreted
by separating conjunction. As a ï¬rst step, we extend the logic of bunched implications (BI), the
assertion logic underlying separation logic, to support multiple forms of separating conjunction
simultaneously, related by a pre-order. Our motivation to design this logic is to reason about in-
dependence and negative association in one logic and capture that independence implies negative
association, but the logic is more general and accommodates other potentially interesting models.

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:7

3.1 The syntax and proof rules
Let AP be a set of atomic propositions, and (ğ‘€, â‰¤) be a ï¬nite pre-order. The formula in the logic
of ğ‘€-bunched implications (ğ‘€-BI) has the following grammar:

ğ‘ƒ, ğ‘„ ::= ğ‘ âˆˆ AP | âŠ¤ | ğ¼ğ‘š âˆˆğ‘€ | âŠ¥ | ğ‘ƒ âˆ§ ğ‘„ | ğ‘ƒ âˆ¨ ğ‘„ | ğ‘ƒ â†’ ğ‘„ | ğ‘ƒ âˆ—ğ‘š âˆˆğ‘€ ğ‘„ | ğ‘ƒ âˆ’âˆ—ğ‘š âˆˆğ‘€ ğ‘„.
ğ‘€-BI associates each element of ğ‘€ with a separating conjunction âˆ—ğ‘š, a corresponding multiplica-
tive identity ğ¼ğ‘š and a separating implication âˆ’âˆ—ğ‘š. The proof system for M-BI is based on the proof
system for BI, with indexed copy of rules for each separation, and in addition has âˆ—-Weakening
rules. We present the full Hilbert-style proof system in Appendix B; most of the rules are the same
as in the proof system for BI. Here, we only comment on the new rules.

The âˆ—-Weakening rule says that if ğ‘š1 â‰¤ ğ‘š2, then the assertion ğ‘ƒ âˆ—ğ‘š1 ğ‘„ implies ğ‘ƒ âˆ—ğ‘š2 ğ‘„.

ğ‘š1 â‰¤ ğ‘š2
ğ‘ƒ âˆ—ğ‘š1 ğ‘„ âŠ¢ ğ‘ƒ âˆ—ğ‘š2 ğ‘„

âˆ—-Weakening

We can derive analogous weakening rules for separating implications and multiplicative identities,
in the reverse direction.

Lemma 3.1. The following rules are derivable in ğ‘€-BI:

ğ‘š1 â‰¤ ğ‘š2
ğ‘ƒ âˆ’âˆ—ğ‘š2 ğ‘„ âŠ¢ ğ‘ƒ âˆ’âˆ—ğ‘š1 ğ‘„

âˆ’âˆ—-Weakening

ğ‘š1 â‰¤ ğ‘š2
ğ¼ğ‘š2 âŠ¢ ğ¼ğ‘š1

UnitWeakening

3.2 Semantics
As is standard with bunched logics [Pym et al. 2004], we give a Kripke style semantics to ğ‘€-BI. We
will deï¬ne a structure called ğ‘€-BI frame, and then deï¬ne ğ‘€-BI models and the satisfaction rules
on ğ‘€-BI models.

An ğ‘€-BI frame is a collection of BI frames satisfying some frame conditions. While BI frames
are often presented as partial, pre-ordered commutative monoids over states, we need the more
general presentation due to Docherty [2019], where the binary operation returns a set of states,
instead of at most one state. Such binary operations can be deterministic (returning a set of at
most one element) or non-deterministic. The admission of non-deterministic models was originally
motivated by the metatheory; somewhat surprisingly, it is also a crucial ingredient in deï¬ning the
negative association model we will see in Section 4.

Deï¬nition 3.2 (BI Frame). A (Down-Closed) BI frame is a structure X = (ğ‘‹, âŠ‘, âŠ•, ğ¸) such that âŠ‘
is a pre-order on the set of states ğ‘‹ , âŠ• : ğ‘‹ 2 â†’ P (ğ‘‹ ) is a binary operation, and ğ¸ âŠ† ğ‘‹ , satisfying
following frame conditions (with outermost universal quantiï¬cation omitted for readability):

(Down-Closed)
(Commutativity)
(Associativity)
(Unit Existence)
(Unit Coherence)
(Unit Closure)

ğ‘§ âˆˆ ğ‘¥ âŠ• ğ‘¦ âˆ§ ğ‘¥ â€² âŠ‘ ğ‘¥ âˆ§ ğ‘¦â€² âŠ‘ ğ‘¦ â†’ âˆƒğ‘§â€²(ğ‘§â€² âŠ‘ ğ‘§ âˆ§ ğ‘§â€² âˆˆ ğ‘¥ â€² âŠ• ğ‘¦â€²);
ğ‘§ âˆˆ ğ‘¥ âŠ• ğ‘¦ â†’ ğ‘§ âˆˆ ğ‘¦ âŠ• ğ‘¥;
ğ‘¤ âˆˆ ğ‘¡ âŠ• ğ‘§ âˆ§ ğ‘¡ âˆˆ ğ‘¥ âŠ• ğ‘¦ â†’ âˆƒğ‘  (ğ‘  âˆˆ ğ‘¦ âŠ• ğ‘§ âˆ§ ğ‘¤ âˆˆ ğ‘¥ âŠ• ğ‘ );
âˆƒğ‘’ âˆˆ ğ¸ (ğ‘¥ âˆˆ ğ‘’ âŠ• ğ‘¥);
ğ‘’ âˆˆ ğ¸ âˆ§ ğ‘¥ âˆˆ ğ‘¦ âŠ• ğ‘’ â†’ ğ‘¦ âŠ‘ ğ‘¥;
ğ‘’ âˆˆ ğ¸ âˆ§ ğ‘’ âŠ‘ ğ‘’ â€² â†’ ğ‘’ â€² âˆˆ ğ¸.

Since all frames we consider in this paper will be Down-Closed, we often abbreviate Down-
Closed BI frame as just BI frame. The (Commutativity), (Associativity) and (Unit Existence) condi-
tions capture the properties of commutative monoids, and the (Down-Closed) condition ensures
that the binary operation is coherent with the pre-order. Properties (Associativity) and (Commuta-
tivity) are generalizations of the usual algebraic properties to accommodate the non-determinism.

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:8

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

The three Unit frame conditions ensure that the set ğ¸ behaves like a set of units, and satisï¬es
various closure properties under the binary operation and the pre-order.

We can now deï¬ne ğ‘€-BI frame to be a collection of BI frames sharing the same set of states and

pre-order, with ordered binary operations:

Deï¬nition 3.3 (ğ‘€-BI Frame). An ğ‘€-BI frame is a structure X = (ğ‘‹, âŠ‘, âŠ•ğ‘š âˆˆğ‘€ , ğ¸ğ‘š) such that for

each ğ‘š, (ğ‘‹, âŠ‘, âŠ•ğ‘š, ğ¸ğ‘š) is a BI frame, and there is a preorder â‰¤ on ğ‘€ satisfying:

(Operation Inclusion) ğ‘š1 â‰¤ ğ‘š2 â†’ ğ‘¥ âŠ•ğ‘š1 ğ‘¦ âŠ† ğ‘¥ âŠ•ğ‘š2 ğ‘¦.

The (Operation Inclusion) condition together with the frame conditions of BI also imply an

inclusion on unit sets:

Lemma 3.4. Let X be an ğ‘€-BI frame. If ğ‘š1 â‰¤ ğ‘š2 then ğ¸ğ‘š2 âŠ† ğ¸ğ‘š1.

Proof. Let ğ‘’2 âˆˆ ğ¸ğ‘š2. By (Unit Existence), there exists ğ‘’1 âˆˆ ğ¸ğ‘š1 such that ğ‘’2 âˆˆ ğ‘’1 âŠ•ğ‘š1 ğ‘’2. By
(Operation Inclusion), ğ‘’2 âˆˆ ğ‘’1 âŠ•ğ‘š2 ğ‘’2, so (Unit Coherence) implies that ğ‘’1 âŠ‘ ğ‘’2, and then (Unit
(cid:3)
Closure) implies ğ‘’2 âˆˆ ğ¸ğ‘š1 . So ğ¸ğ‘š2 âŠ† ğ¸ğ‘š1.

To obtain a BI model over a given BI frame, we must provide a valuation, which deï¬nes which
atomic propositions hold at each states in the frame. For the soundness of the proof system, it is
important that the valuation is persistent: any formula true at a state remains true at any larger
state. Formally, we deï¬ne ğ‘€-BI models as follows.

Deï¬nition 3.5 (Valuation and model). A persistent valuation is a map V : AP â†’ P (ğ‘‹ ) such
that, for all ğ‘ƒ âˆˆ AP, if ğ‘¥ âˆˆ V (ğ‘ƒ) and ğ‘¥ âŠ‘ ğ‘¦ then ğ‘¦ âˆˆ V (ğ‘ƒ). An ğ‘€-BI model (X, V) is an ğ‘€-BI
frame X = (ğ‘‹, âŠ‘, âŠ•ğ‘š, ğ¸ğ‘š) associated with a persistent valuation V on it.

Next, we deï¬ne which ğ‘€-BI formula are true at a state in a ğ‘€-BI model.

Deï¬nition 3.6. On model (X, V), we deï¬ne the satisfaction relation |=V between states in X

and ğ‘€-BI formula: for ğ‘¥ âˆˆ X

ğ‘¥ |=V ğ‘
ğ‘¥ |=V âŠ¤
ğ‘¥ |=V ğ¼ğ‘š
ğ‘¥ |=V âŠ¥
ğ‘¥ |=V ğ‘ƒ âˆ§ ğ‘„
ğ‘¥ |=V ğ‘ƒ âˆ¨ ğ‘„
ğ‘¥ |=V ğ‘ƒ â†’ ğ‘„
ğ‘¥ |=V ğ‘ƒ âˆ—ğ‘š ğ‘„
ğ‘¥ |=V ğ‘ƒ âˆ’âˆ—ğ‘š ğ‘„ iï¬€ for all ğ‘¦ and ğ‘§ such that ğ‘§ âˆˆ ğ‘¥ âŠ•ğ‘š ğ‘¦, if ğ‘¦ |=V ğ‘ƒ then ğ‘§ |=V ğ‘„

iï¬€ ğ‘¥ âˆˆ V (ğ‘)
iï¬€ True
iï¬€ ğ‘¥ âˆˆ ğ¸ğ‘š
iï¬€ False
iï¬€ ğ‘¥ |=V ğ‘ƒ and ğ‘¥ |=V ğ‘„
iï¬€ ğ‘¥ |=V ğ‘ƒ or ğ‘¥ |=V ğ‘„
iï¬€ for all ğ‘¦ such that ğ‘¥ âŠ‘ ğ‘¦, if ğ‘¦ |=V ğ‘ƒ then ğ‘¦ |=V ğ‘„
iï¬€ there exist ğ‘¥ â€², ğ‘¦, and ğ‘§ with ğ‘¥ â€² âŠ‘ ğ‘¥ and ğ‘¥ â€² âˆˆ ğ‘¦ âŠ•ğ‘š ğ‘§ such that ğ‘¦ |=V ğ‘ƒ and ğ‘§ |=V ğ‘„

We say that a formula ğ‘ƒ is valid in the model (X, V), written as X |=V ğ‘ƒ, iï¬€ ğ‘¥ |=V ğ‘ƒ for all
ğ‘¥ âˆˆ X. We also say that ğ‘ƒ is valid if and only if ğ‘ƒ is valid in all models and write that as |= ğ‘ƒ.
Finally, we write ğ‘ƒ |= ğ‘„ if and only if for any model (X, V), X |=V ğ‘ƒ implies X |=V ğ‘„.

We prove the following theorem in Appendix E.

Theorem 3.7. Let ğ‘ƒ and ğ‘„ be any two ğ‘€-BI formulas. Then ğ‘ƒ |= ğ‘„ iï¬€ ğ‘ƒ âŠ¢ ğ‘„.

The reverse direction of (soundness) is straightforward by induction on the proof derivation,
but the forward direction (completeness) is less obvious; we use the duality-theoretic framework
proposed by Docherty [2019] to establish this theorem.

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:9

3.3 Potential models
Our design of ğ‘€-BI is mainly motivated by our intended model of negative association and prob-
abilistic independence, which we will see in the next section, but the logic ğ‘€-BI is quite ï¬‚exible
and we can see other natural models. Here we outline three models, inspired by the heap model
of separation logic [Reynolds 2001].

Hierarchical heaps. In the heap model of separation logic, heaps are partial maps â„ : N â‡€ Val
from integer addresses to values, and heap combination â—¦â„ğ‘’ğ‘ğ‘ is a partial binary operation that
takes the union if the two heaps have disjoint domains, and is not deï¬ned otherwise. In many
systems, memory addresses are partitioned into larger units, for instance pages. We can deï¬ne
another partial binary operation â—¦ğ‘ğ‘ğ‘”ğ‘’ that takes the union if the two heaps have disjoint domains
and are deï¬ned on disjoint pages. Then, â„1 â—¦ğ‘ğ‘ğ‘”ğ‘’ â„2 âŠ† â„1 â—¦â„ğ‘’ğ‘ğ‘ â„2, so we can build a model of
ğ‘€-BI on the two-point pre-order. The two separating conjunctions âˆ—â„ğ‘’ğ‘ğ‘ and âˆ—ğ‘ğ‘ğ‘”ğ‘’ then describe
heap and page separation respectively, which could be useful for reasoning about which memory
accesses may require a page-table lookup.

Strong separation logic. Heaps in separation logic can store values, but also addresses of other
locations. In the standard heap model, two separate heaps must have disjoint domains but may
store common addresses, i.e., they may hold dangling pointers to the same locations. Searching for
a separation logic with better decidability properties, Pagel and Zuleger [2021] proposed a notion
of strong separation logic, where two strongly-separated heaps can only hold common addresses
that are already stored in stack variables. The resulting form of separation can be modeled by
a separating conjunction âˆ—ğ‘ ğ‘¡ , and the standard (weak) form of separation can be modeled by a
separating conjunction âˆ—ğ‘¤ğ‘˜ . Since strong separation implies weak separation, we can again build
a model of ğ‘€-BI supporting both conjunctions on the two-point pre-order.

âˆ—(â„,ğ‘)

Tagged memory. In some security-focused architec-
tures, pointers contain an address as well as a tag, in-
dicating capabilities that may be performed with that
piece of memory. To reason about these machines, we
can consider a resource frame where states are pairs
of (â„, ğ‘), where â„ is a heap and ğ‘ is a permission (say
shared access, or exclusive access). We can then consider
four kinds of separation taking all combinations of heaps
aliasing/non-aliasing, and permissions compatible/incompatible. The result is a ğ‘€-BI frame, with
the lattice of separating conjunctions depicted in Figure 2. Assertions in models on this frame can
reason about all four kinds of separation, where âˆ—âˆ’ degenerates to the standard conjunction âˆ§.

Fig. 2. The pre-order for âˆ—ğ‘š

âˆ—âˆ’

âˆ—â„

âˆ—ğ‘

4 A MODEL OF NEGATIVE ASSOCIATION AND INDEPENDENCE

In this section, we will present a ğ‘€-BI model for reasoning about both probabilistic independence
and negative association. Barthe et al. [2020] proposed a BI model that captures probabilistic in-
dependence, developed a program logic (PSL) to reason about independence in probabilistic pro-
grams. We will construct a BI model for negative association and combine it with the PSL model to
obtain a 2-BI model for both probabilistic independence and negative association, where 2 = {1, 2}
is the two-point set with pre-order 1 â‰¤ 2.

One may wonder if it is a simple exercise to replace the independence semantics of the separat-
ing conjunction in PSL by a semantics that capture negative association, but there are technical
challenges. As we will show in Section 4.2, two intuitive BI model deï¬nitions fail to satisfy all
frame conditions. To overcome the diï¬ƒculties, in Section 4.3 we deï¬ne a new notion of negative

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:10

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

association that can express negative dependence of various strengths, and then deï¬ne a model
based on our new notion.

4.1 Preliminaries and the PSL model

We need to introduce some notation to deï¬ne the models.

First, we represent program states as memories. Let the set of all program variables be Var, and
the set of all possible values be Val. For any ï¬nite set of variables ğ‘† âŠ† Var, a memory on ğ‘† is a map
ğ‘† â†’ Val, and Mem[ğ‘†] denotes the set of memories on ğ‘†. For disjoint sets of variables ğ‘†,ğ‘‡ âŠ† Var,
and ğ‘š1 âˆˆ Mem[ğ‘†], ğ‘š2 âˆˆ Mem[ğ‘‡ ], we deï¬ne ğ‘š1 âŠ²âŠ³ ğ‘š2 to be the union of ğ‘š1, ğ‘š2.

Now we will introduce probabilistic memories. For a real-valued function ğ‘“ , we say that ğ‘¥ is in
the support of ğ‘“ if ğ‘“ (ğ‘¥) â‰  0. A countable distribution on a set ğ‘‹ is a countable support function
ğ‘¥ âˆˆğ‘‹ ğœ‡(ğ‘¥) = 1. Let D (ğ‘‹ ) denote the set of countable distributions on
ğœ‡ : ğ‘‹ â†’ [0, 1] such that
ğ‘‹ . A probabilistic memory on variables ğ‘† is a distribution over Mem[ğ‘†], so the set of probabilistic
memories on ğ‘† is D (Mem[ğ‘†]).

Ã

Next, we will need some constructions on distributions. A family of special distributions in
D (Mem[ğ‘†]) is Dirac distributions: for any ğ‘¥ âˆˆ Mem[ğ‘†], the Dirac distribution ğ›¿ (ğ‘¥) puts all the
weight on ğ‘¥, that is, for any ğ‘¦ âˆˆ Mem[ğ‘†], ğ›¿ (ğ‘¥) (ğ‘¦) = 1 if ğ‘¥ = ğ‘¦, and ğ›¿ (ğ‘¥) (ğ‘¦) = 0 otherwise. For any
sets of variables ğ‘† âŠ† ğ‘† â€², we deï¬ne the projection map ğœ‹ğ‘†â€²,ğ‘† to map a distribution ğœ‡ on Mem[ğ‘† â€²] to
a distribution on Mem[ğ‘†]: for any ğ‘¥ âˆˆ Mem[ğ‘†],

ğœ‹ğ‘†â€²,ğ‘† ğœ‡(ğ‘¥) :=

ğœ‡(ğ‘¥ â€²),

ğ‘¥ â€² âˆˆMem[ğ‘†â€² ] and pğ‘† (ğ‘¥ â€²)=ğ‘¥
Ã•

where pğ‘† (ğ‘¥ â€²) is ğ‘¥ â€² restricted on ğ‘†. Often ğ‘† â€² is clear, so we just write ğœ‹ğ‘† for ğœ‹ğ‘†â€²,ğ‘† . Then, we can
formally deï¬ne independence of variables in a distribution:

Deï¬nition 4.1 (Independence). For any ğœ‡ âˆˆ D (Mem[ğ‘†]), and disjoint ğ‘‡1,ğ‘‡2 âŠ† ğ‘†, we say ğ‘‡1,ğ‘‡2 are

independent in ğœ‡ if for any ğ‘¥ âˆˆ Mem[ğ‘‡1 âˆª ğ‘‡2],

ğœ‹ğ‘‡1âˆªğ‘‡2 ğœ‡(ğ‘¥) = ğœ‹ğ‘‡1 ğœ‡(pğ‘‡1 (ğ‘¥)) Â· ğœ‹ğ‘‡2 ğœ‡(pğ‘‡2 (ğ‘¥)).

We then deï¬ne the independent product âŠ— as: for any ğœ‡1 âˆˆ D (Mem[ğ‘†]), ğœ‡2 âˆˆ D (Mem[ğ‘‡ ]),

ğœ‡1 âŠ— ğœ‡2 =

(

âˆ…
{ğœ‡ | for any ğ‘¥ âˆˆ Mem[ğ‘† âˆª ğ‘‡ ], ğœ‡(ğ‘¥) = ğœ‡1 (pğ‘† (ğ‘¥)) Â· ğœ‡2 (pğ‘‡ (ğ‘¥))}

if ğ‘†,ğ‘‡ not disjoint
if ğ‘†,ğ‘‡ disjoint

For any distribution ğœ‡ âˆˆ D (Mem[ğ‘†]), we call ğ‘† the domain of ğœ‡, denoted dom(ğœ‡). By construction,
if ğœ‡ âˆˆ ğœ‡1 âŠ— ğœ‡2, then dom(ğœ‡1) and dom(ğœ‡2) are independent in ğœ‡, and ğœ‡ is the unique element in
ğœ‡1 âŠ— ğœ‡2. Simple calculations also show that if ğœ‡ âˆˆ ğœ‡1 âŠ— ğœ‡2, then ğœ‹ğ‘† ğœ‡ = ğœ‡1, ğœ‹ğ‘‡ ğœ‡ = ğœ‡2.

We can then present the Independence frame from Barthe et al. [2020] as the following BI frame.

For simplicity, we restrict its states to probabilistic memories for now.2

Deï¬nition 4.2. Let ğ‘‹ = âˆªğ‘† âŠ†VarD (Mem[ğ‘†]). Say ğœ‡ âŠ‘ ğœ‡â€² iï¬€ dom(ğœ‡) âŠ† dom(ğœ‡â€²) and ğœ‹dom(ğœ‡) ğœ‡â€² = ğœ‡.

Let ğ¸indep = ğ‘‹ . We call Xindep = (ğ‘‹, âŠ‘, âŠ—, ğ¸indep) the Independence structure.

This Independence structure Xindep is a BI frame.

2Technically we take a slightly diï¬€erent notion of BI frames that is more suitable for our purposes. Barthe et al. [2020]
presents BI frames with partial, pre-ordered commutative monoids, which require a unique unit for all states. But we can
encode their frame as our BI frame by taking its partial operation as an operation that returns sets of size at most one and
deï¬ning the unit set ğ¸ to include their unique unit and be closed under âŠ‘.

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:11

4.2 Initial attempts at a NA model
Our goal is to design a BI model XPNA that can capture negative association and can be combined
with Xindep. To be compatible with Xindep, we let XPNA have the same set of states and the same
pre-order as Xindep. The important remaining piece of the puzzle is the binary operation âŠ•, which
must satisfy the frame conditions.

One ï¬rst attempt is to let ğœ‡1 âŠ• ğœ‡2 return the set of distributions that agree with ğœ‡1, ğœ‡2, and satisfy

strong NAâ€”we say ğœ‡ satisï¬es strong NA if dom(ğœ‡) satisï¬es NA.

Deï¬nition 4.3. (Attempt 1: Strong NA model) Let ğ‘‹ = âˆªğ‘† âŠ†VarD (Mem[ğ‘†]). For ğœ‡, ğœ‡â€² âˆˆ ğ‘‹ , say

ğœ‡ âŠ‘ ğœ‡â€² iï¬€ dom(ğœ‡) âŠ† dom(ğœ‡â€²) and ğœ‹dom(ğœ‡) ğœ‡â€² = ğœ‡. Let ğ¸ğ‘  = ğ‘‹ . Deï¬ne âŠ•ğ‘  : ğ‘‹ Ã— ğ‘‹ â†’ P (ğ‘‹ ):

ğœ‡1 âŠ•ğ‘  ğœ‡2 = {ğœ‡ âˆˆ D (Mem[ğ‘† âˆª ğ‘‡ ]) | ğœ‡ satisï¬es strong NA, ğœ‹ğ‘† ğœ‡ = ğœ‡1, ğœ‹ğ‘‡ ğœ‡ = ğœ‡2, ğ‘† âˆ© ğ‘‡ = âˆ…}.

We call Xğ‘  = (ğ‘‹, âŠ‘, âŠ•ğ‘ , ğ¸ğ‘ ) the strong NA structure.

Unfortunately, the strong NA structure fails to have the (Unit Existence) property: if ğœ‡ does not
satisfy strong NA, then there exists no ğœ‡â€² that marginalizes to ğœ‡ and satisï¬es strong NA, and thus
no ğ‘’ such that ğœ‡ âˆˆ ğ‘’ âŠ•ğ‘  ğœ‡. The failure of this property implies that whether or not two states can
be combined depends on properties of the single states in isolation (e.g., whether a distribution
satisï¬es strong NA), and not just on how the two states relate to each other; this is hard to justify
if we are to read âŠ• as describing which pairs of states can be safely combined.

Looking for a diï¬€erent way of capturing NA, we can take inspiration from the Xindep. There,
ğœ‡1 âŠ— ğœ‡2 returns a distribution that agrees with ğœ‡1, ğœ‡2 and on which dom(ğœ‡1) are independent from
dom(ğœ‡2). Thus, we can try letting ğœ‡1 âŠ• ğœ‡2 return distributions that agree with ğœ‡1, ğœ‡2 where any
variable ğ‘¥ in dom(ğœ‡1) must be negatively associated with any variable ğ‘¦ in dom(ğœ‡2), but variables
within dom(ğœ‡1) and variables within dom(ğœ‡2) need not be negatively associated. We call this
notion weak NA.

Deï¬nition 4.4 (Weak NA). Let ğ‘† âŠ† Var be a set of variables, and let ğ´, ğµ be two disjoint subsets
of ğ‘†. A distribution ğœ‡ âˆˆ D (Mem[ğ‘†]) satisï¬es (ğ´, ğµ)-NA if for every pair of both monotone or both
antitone functions ğ‘“ : Mem[ğ´] â†’ R, ğ‘” : Mem[ğµ] â†’ R, where we take the point-wise orders on
Mem[ğ´] and Mem[ğµ], such that ğ‘“ , ğ‘” is either lower bounded or upper bounded, we have

Eğ‘šâˆ¼ğœ‡ [ğ‘“ (pğ´ğ‘š) Â· ğ‘”(pğµğ‘š)] â‰¤ Eğ‘šâˆ¼ğœ‡ [ğ‘“ (pğ´ğ‘š)] Â· Eğ‘šâˆ¼ğœ‡ [ğ‘”(pğµğ‘š)].

By deï¬nition, being (ğ´, ğµ)-NA for all disjoint ğ´, ğµ âŠ† ğ‘† is equivalent to strong NA on ğ‘†. Now, we

can try deï¬ning another model based on weak NA.

Deï¬nition 4.5. (Attempt 2: Weak NA model) Let ğ‘‹ = âˆªğ‘† âŠ†VarD (Mem[ğ‘†]). For ğœ‡, ğœ‡â€² âˆˆ ğ‘‹ , ğœ‡ âŠ‘ ğœ‡â€²

iï¬€ dom(ğœ‡) âŠ† dom(ğœ‡â€²) and ğœ‹dom (ğœ‡) ğœ‡â€² = ğœ‡. Let ğ¸ğ‘¤ = ğ‘‹ . Deï¬ne âŠ•ğ‘¤ : ğ‘‹ Ã— ğ‘‹ â†’ P (ğ‘‹ ):

ğœ‡1 âŠ•ğ‘¤ ğœ‡2 = {ğœ‡ âˆˆ D (Mem[ğ‘† âˆª ğ‘‡ ]) | ğœ‡ satisï¬es (ğ‘†,ğ‘‡ )-NA, ğœ‹ğ‘† ğœ‡ = ğœ‡1, ğœ‹ğ‘‡ ğœ‡ = ğœ‡2, ğ‘† âˆ© ğ‘‡ = âˆ…}.

We call Xğ‘¤ = (ğ‘‹, âŠ‘, âŠ•ğ‘¤, ğ¸ğ‘¤) the weak NA structure.

This weak NA structure satisï¬es most BI frame conditions, except that (Associativity) is unclear.
In short, the deï¬nition of âŠ•ğ‘¤ and (Associativity) requires that: if ğ‘¤ satisï¬es (ğ‘… âˆª ğ‘†,ğ‘‡ )-NA and
(ğ‘…, ğ‘†)-NA, then ğ‘¤ also satisï¬es (ğ‘†,ğ‘‡ )-NA and (ğ‘…, ğ‘† âˆªğ‘‡ )-NA. Now ğ‘¤ satisï¬es (ğ‘†,ğ‘‡ )-NA by projec-
tion closure, but it is unclear whether ğ‘¤ must satisfy (ğ‘…, ğ‘† âˆª ğ‘‡ )-NA; we leave this question as an
interesting open problem. Failing to satisfy (Associativity) would lead to a logic where separating
conjunction is not associative, and signiï¬cantly more diï¬ƒcult to use. Since it is unknown whether
Xğ‘¤ is a BI frame, we will deï¬ne another structure to capture negative association.

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:12

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

4.3 Our NA model
Facing the problems with the strong NA structure and the weak NA structures, we will deï¬ne a
BI model for negative association based on a new notion of negative association called partition
negative association (PNA). This notion interpolates weak NA and strong NA, in the following sense:
{ğ´, ğµ}-PNA is equivalent to (ğ´, ğµ)-NA for disjoint ğ´, ğµ âŠ† ğ‘†, and {{ğ‘ } | ğ‘  âˆˆ ğ‘† }-PNA is equivalent
to strong NA for distributions in D (Mem[ğ‘†]).

Deï¬nition 4.6 (Partition Negative Association). We say a partition Sâ€² coarsens a partition S if

âˆªS = âˆªSâ€² and for any ğ‘  â€² âˆˆ Sâ€², ğ‘  â€² = âˆªR for some R âŠ† S.

A distribution ğœ‡ is S-PNA if and only if for any T that coarsens S, for any family of non-negative
monotone functions (or family of non-negative antitone functions), {ğ‘“ğ´ : Mem[ğ´] â†’ R+}ğ´ âˆˆT ,3
where we take the point-wise order on Mem[ğ´] for each ğ´ âˆˆ T , we have

Eğ‘šâˆ¼ğœ‡

"
We can use PNA to prove NA:

ğ‘“ğ´ (pğ´ğ‘š)

â‰¤

#

Ã–ğ´ âˆˆT

Ã–ğ´ âˆˆT

Eğ‘šâˆ¼ğœ‡ [ğ‘“ğ´ (pğ´ğ‘š)].

Theorem 4.7. Given a set of variables ğ‘†, ğ‘† satisï¬es NA in ğœ‡ iï¬€ ğœ‡ satisï¬es S-PNA for any S parti-

tioning ğ‘† iï¬€ ğœ‡ satisï¬es {{ğ‘ } | ğ‘  âˆˆ ğ‘† }-PNA.4

We require PNA to be closed under coarsening, which helps us to prove the next structure we

deï¬ne is a BI frame.

Deï¬nition 4.8. Let XPNA = (ğ‘‹, âŠ‘, âŠ•, ğ¸PNA), where ğ‘‹ = ğ¸PNA = âˆªğ‘† âŠ†VarD (Mem[ğ‘†]). For ğœ‡, ğœ‡â€² âˆˆ ğ‘‹ ,

say ğœ‡ âŠ‘ ğœ‡â€² iï¬€ dom(ğœ‡) âŠ† dom(ğœ‡â€²) and ğœ‹dom (ğœ‡) ğœ‡â€² = ğœ‡. Deï¬ne the operation âŠ• : ğ‘‹ Ã— ğ‘‹ â†’ P (ğ‘‹ ):

ğœ‡1 âŠ• ğœ‡2 = {ğœ‡ âˆˆ D (Mem[ğ‘† âˆª ğ‘‡ ]) | ğœ‹ğ‘† ğœ‡ = ğœ‡1, ğœ‹ğ‘‡ ğœ‡ = ğœ‡2,

ğœ‡ is (S âˆª T )-PNA for any partition S, T such that
ğœ‡1 is S-PNA, and ğœ‡2 is T -PNA, and (âˆªS) âˆ© (âˆªT ) = âˆ….}

This deï¬nition of âŠ• interpolates âŠ•ğ‘¤ and âŠ•ğ‘  , in the following sense.
Theorem 4.9. For any two states ğœ‡1, ğœ‡2 âˆˆ ğ‘‹ , ğœ‡1 âŠ•ğ‘  ğœ‡2 âŠ† ğœ‡1 âŠ• ğœ‡2 âŠ† ğœ‡1 âŠ•ğ‘¤ ğœ‡2.
The ï¬rst inclusion is because ğœ‡ satisfying strong NA implies ğœ‡ is R-PNA for any partition
R on dom(ğœ‡). The second inclusion is because ğœ‡1 âˆˆ D (Mem[ğ‘†]) satisï¬es {ğ‘† }-PNA and ğœ‡2 âˆˆ
D (Mem[ğ‘‡ ]) satisï¬es {ğ‘‡ }-PNA trivially, which implies any ğœ‡ âˆˆ ğœ‡1 âŠ• ğœ‡2 would satisfy (ğ‘†,ğ‘‡ )-NA.

Note that âŠ• is non-deterministic, and not just partial.

Theorem 4.10. There are distributions ğœ‡1, ğœ‡2 such that |ğœ‡1 âŠ• ğœ‡2 | â‰¥ 2.
Proof. Let ğœ‡1 âˆˆ D (Mem[{ğ‘¥ }]) and ğœ‡2 âˆˆ D (Mem[{ğ‘¦}]) be uniform distribution over memories
over 0/1 variables ğ‘¥, ğ‘¦. Then the independent product ğœ‡ âŠ— âˆˆ ğœ‡1 âŠ— ğœ‡2 is in ğœ‡1 âŠ• ğœ‡2, because the
projections to ğ‘¥ and to ğ‘¦ are ğœ‡1 and ğœ‡2 respectively, and ğœ‡ âŠ— satisï¬es PNA since independence
implies PNA (we will see this shortly in Theorem 4.12). But the one-hot uniform distribution ğœ‡ğ‘œâ„
over variables ğ‘¥ and ğ‘¦, i.e., ğœ‡ğ‘œâ„ ( [ğ‘¥ â†¦â†’ 1, ğ‘¦ â†¦â†’ 0]) = ğœ‡ğ‘œâ„ ( [ğ‘¥ â†¦â†’ 0, ğ‘¦ â†¦â†’ 1]) = 1/2, is also in ğœ‡1 âŠ• ğœ‡2,
since again the projections match ğœ‡1 and ğœ‡2 and the one-hot distribution satisï¬es NA, and hence
(cid:3)
PNA. Since ğœ‡ğ‘œâ„ â‰  ğœ‡ âŠ• , we are done.
3We restrict the family of functions to be non-negative: prior work like Joag-Dev and Proschan [1983] has assumed non-
negativity when working with notions of NA on partitions; furthermore, without that requirement, for partitions with odd
number of components, PNA would be equivalent to independence, a strange property.
4Technically, we slightly modify Dubhashi and Ranjan [1998]â€™s NA when deï¬ning it in Deï¬nition 2.1 by in addition assum-
ing that ğ‘“ , ğ‘” are bounded from one side. We add that condition to have a cleaner version of this theorem and Theorem 5.3.
All our other results and properties we state about NA in Section 1 hold with or without this condition.

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:13

Thus, we can build a BI frame on probabilistic memories, crucially using a non-deterministic

combination operation on states [Docherty 2019].

Theorem 4.11. The structure XPNA = (ğ‘‹, âŠ‘, âŠ•, ğ¸PNA) is a Down-Closed BI frame.

See the full proof in Appendix C.1. For the frame conditions where the previous attempts failed,
(Unit Existence) holds by letting the unit ğ‘’ to always be the trivial distribution on the empty set, and
(Associativity) can be proved using the facts that PNA is closed under coarsening and coarsening
commute with projections. We call XPNA the PNA model.

Now that we know the PNA frame is a BI frame and captures NA, we want to combine it with the
PSL frame to construct a ğ‘€-BI frame. To combine them, we need to show that for any ğœ‡1, ğœ‡2 âˆˆ ğ‘‹ ,

The inclusion is implied by the following theorem:

ğœ‡1 âŠ— ğœ‡2 âŠ† ğœ‡1 âŠ• ğœ‡2.

Theorem 4.12 (Independence implies PNA). Let ğ‘†,ğ‘‡ âŠ† Var be two disjoint sets of variables.
Suppose ğœ‡1 âˆˆ D (Mem[ğ‘†]), ğœ‡2 âˆˆ D (Mem[ğ‘‡ ]). If ğœ‡1 satisï¬es S-PNA and ğœ‡2 satisï¬es T -PNA, then
any ğœ‡ âˆˆ ğœ‡ğ‘† âŠ— ğœ‡ğ‘‡ satisï¬es S âˆª T -PNA.

This theorem generalizes the independence closure for NA from Theorem 2.3. Its proof, however,
is more involved because PNA is more expressive and is closed under coarsening. (See the proof
in Appendix C.2.)

Thus, we can combine Xindep and XPNA into a 2-BI model.

Theorem 4.13. Let 2 = {1, 2} with pre-order 1 â‰¤ 2. Let âŠ•1 = âŠ—, ğ¸1 = ğ¸indep, âŠ•2 = âŠ•, ğ¸2 = ğ¸PNA.

The structure XD (Mem) = (ğ‘‹, âŠ‘, âŠ•1, ğ¸1, âŠ•2, ğ¸2) is a 2-BI model.

Thus XD (Mem) is a 2-BI frame on probabilistic memories.

4.4 Combining with deterministic memory

While we can model the program states of probabilistic programs as probabilistic memories, some
variables might only get deterministic assignments. It is useful to know whether a variable is deter-
ministic; for instance, a deterministic variable is automatically independent of other variables. To
keep track of deterministic variables, we want a 2-BI frame whose states distinguish deterministic
memories and probabilistic memories. We will construct it using a general approach for composing
ğ‘€-BI models. In particular, we will compose XD (Mem) with a 2-BI frame on deterministic memo-
ries.

We can deï¬ne the product of two ğ‘€-BI frames if they share the same pre-order for indexing, ğ‘€.

Deï¬nition 4.14. Let ğ‘€ be a pre-order. Given two ğ‘€-BI frames, X1 = (ğ‘‹1, âŠ‘1, âŠ•(1,ğ‘š âˆˆğ‘€) , ğ¸ (1,ğ‘š âˆˆğ‘€) )
and X2 = (ğ‘‹2, âŠ‘2, âŠ•(2,ğ‘š âˆˆğ‘€) , ğ¸ (2,ğ‘š âˆˆğ‘€) ). The product frame, X = X1 Ã— X2 = (ğ‘‹, âŠ‘, âŠ•ğ‘š âˆˆğ‘€ , ğ¸ğ‘š âˆˆğ‘€ ) is
deï¬ned as

â€¢ ğ‘‹ = ğ‘‹1 Ã— ğ‘‹2;
â€¢ (ğ‘¥1, ğ‘¥2) âŠ‘ (ğ‘¥ â€²
â€¢ For ğ‘š âˆˆ ğ‘€, (ğ‘¥1, ğ‘¥2) âŠ•ğ‘š (ğ‘¥ â€²
â€¢ ğ¸ğ‘š = ğ¸1,ğ‘š Ã— ğ¸2,ğ‘š.

1, ğ‘¥ â€²

2) if and only if ğ‘¥1 âŠ‘1 ğ‘¥ â€²
1, ğ‘¥ â€²

1 and ğ‘¥2 âŠ‘2 ğ‘¥ â€²
2;

2) = {(ğ‘¦1, ğ‘¦2) | ğ‘¦1 âˆˆ ğ‘¥1 âŠ•1,ğ‘š ğ‘¥ â€²

1 âˆ§ ğ‘¦2 âˆˆ ğ‘¥2 âŠ•2,ğ‘š ğ‘¥ â€²

2};

Theorem 4.15. If X1 and X2 are two Mâˆ’ğµğ¼ frames, then X = X1 Ã— X2 is also an ğ‘€-BI frame.

The proof is straightforward.

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:14

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

We now deï¬ne a 2-BI frame modeling the independence and NA separation on the determin-
istic memories. Because deterministic variables are automatically independent of other variables,
it is meaningless to check whether a set of deterministic variables can be separated into two dis-
joint subsets independent of each other. Thus, we do not require the separation of domain when
modeling the independence and NA of deterministic variables:

Deï¬nition 4.16. Let ğ‘‹ â€² = âˆªğ‘† âˆˆVarMem[ğ‘†], and âŠ‘ be =, and the unit set ğ¸d = ğ‘‹ â€². Deï¬ne âŠ•ğ‘‘ by:

ğ‘š1 âŠ•ğ‘‘ ğ‘š2 =

{ğ‘š1}
âˆ…

(

if ğ‘š1 = ğ‘š2
if ğ‘š1 â‰  ğ‘š2

Theorem 4.17. The structure XMem = (ğ‘‹ â€², âŠ‘ğ‘‘, âŠ•1, ğ¸1, âŠ•2, ğ¸2), where âŠ•1 = âŠ•2 = âŠ•ğ‘‘ and ğ¸1 = ğ¸2 =

ğ¸d, is a 2-BI frame.

Both XMem and XD (Mem) are 2-BI frames, so we can take their product.
Corollary 4.18. Xcomb = XMem Ã— XD (Mem) is a 2-BI frame.

As desired, the states of Xcomb describe both deterministic memories and probabilistic memo-
ries. Furthermore, restricting to the BI model in Xcomb with operators indexed by 1 recovers the
probabilistic BI model in Barthe et al. [2020].

5 PROGRAM LOGIC

Given the model for NA developed in the previous section, we now have a suitable logic of as-
sertions. In this section, we complete the picture by designing a program logic, named LINA, for
reasoning about negative association and independence on probabilistic programs. We defer proofs
and details to Appendix D.

5.1 Probabilistic programs
We consider probabilistic programs in a basic probabilistic imperative language pWhile. Let DV, RV
be disjoint countable subsets of Var that respectively contain all deterministic variables and all
probabilistic variables. We consider program states to be a pair of a deterministic memory ğœ, and
a distribution ğœ‡ over the probabilistic memory, i.e., (ğœ, ğœ‡) âˆˆ Mem[DV] Ã— D (Mem[RV]).

Because we will want to decompose a program state as a product of two disjoint memories,
each satisfying a sub-formula, we also want to interpret program expressions on memories whose
probabilistic part is only on part of RV. These memories have type Mem[DV] Ã— D (Mem[ğ‘‡ ])
for some ğ‘‡ âŠ† RV, and we call them conï¬gurations, denoted Config.

We assume all expressions in pWhile are well-typed:

E âˆ‹ ğ‘’ ::= DV | RV | [E, . . . , E] | E + E | E âˆ§ E | . . .

Given an expression ğ‘’, we can interpret it as Mem[DV] Ã— Mem[ğ‘‡ ] â†’ Val for any ğ‘‡ âŠ† RV that
includes all the free variables in ğ‘’. We can also lift it to an interpretation from conï¬gurations to
distributions of values, i.e., Jğ‘’K : Mem[DV] Ã— D (Mem[ğ‘‡ ]) â†’ D (Val) (see Deï¬nition D.1).

We then deï¬ne commands in pWhile and again assume that they are well-typed:

C âˆ‹ ğ‘ ::= skip | DV â† Exp | RV â† Exp | RV $â† Uğ‘‡ | C ; C

| if E then C else C | while E do C.

The randomization is introduced by the sampling command: RV $â† Uğ‘‡ , where Uğ‘‡ stands for the
uniform distribution on a multi-set ğ‘‡ . We assume that the while loops terminate in ï¬nite steps on
all inputs. We also assume that an expression assigned to a deterministic variable only mentions

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:15

deterministic variables, and a command branching on a randomized expression does not assign to
deterministic variables in its body/branches. This assumption ensures that deterministic variables
will not receive randomized values during the execution. It is not diï¬ƒcult to enforce this condition
by a syntactic restriction, which we omit for a cleaner presentation.

Following the standard semantics for probabilistic programs due to Kozen [1981], we interpret

pWhile programs as transformers from program states to program states, i.e.,

Jğ‘K : Mem[DV] Ã— D (Mem[RV]) â†’ Mem[DV] Ã— D (Mem[RV]).

The semantics of pWhile is standard (see Deï¬nition D.3).

In our examples, permutation distributions, uniform distributions over permutation(ğ´):

Deï¬nition 5.1. Given a ï¬nite multi-set of ğ´, a permutation of ğ´ is a bijective function ğ›¼ : ğ´ â†’ ğ´.
We let permutation(ğ´) be the multi-set of ğ´â€™s permutations. When ğ´ has duplicates, we distinguish
them using additional labels; so there are always |ğ´|! elements in permutation(ğ´).

Let one-hot([n]) denote the set of length-ğ‘› one hot vectors. We then deï¬ne the shorthands:
RV $â† ğ‘ğ‘’ğ‘Ÿğ‘š(ğ´) , RV $â† Upermutation(ğ´)
RV $â† ğ‘œâ„(ğ‘›) , RV $â† Uone-hot ( [ğ‘› ])
if ğ‘ then ğ‘ , if ğ‘ then ğ‘ else skip.

5.2 Assertion Logic: atomic propositions and axioms
Like other program logics, LINA has two layers: the program logic layer describing the relation
between pre-conditions, programs and post-conditions, and the assertion logic layer describing
program states. In Section 4, we have constructed a probabilistic model of 2-BI, Xcomb, whose
states encompass all of Config, so our starting point for the assertion logic is this model. In this
section, we introduce atomic propositions AP for describing states in Xcomb and some axioms
that will hold on Xcomb.

We extend the core atomic formula from Barthe et al. [2020]. To talk about probabilities on
program states distributions, we ï¬rst deï¬ne an event to be a function that maps a deterministic
program conï¬guration to 0 or 1, and let EV be a set of expressions that can be interpreted as event
on deterministic conï¬gurations i.e., for any ğ‘’ğ‘£ âˆˆ EV, Jğ‘’ğ‘£K : Mem[DV] Ã— Mem[ğ‘‡ ] â†’ {0, 1} for
some ğ‘‡ âŠ† RV. Since boolean expressions in the programming language can also be interpreted
as this type, we will let EV include all boolean expression. Let

AP âˆ‹ ğ‘ ::= Uğ‘‡ hEi | Bernğ‘ hEi | DetmhEi | E âˆ¼ E | E â‰¤ E | EV = ğ‘ | Pr[EV] âŠ²âŠ³ ğ›¿
(1)
where âŠ²âŠ³ âˆˆ {=, â‰¤, â‰¥}, ğ‘ âˆˆ {0, 1}, and ğ›¿ âˆˆ R is a constant. In particular, for boolean expression ğ‘’
and for ğ‘ âˆˆ {0, 1}, since we can also view ğ‘’ as an event, ğ‘’ âˆ¼ ğ‘ and ğ‘’ = ğ‘ are both valid atomic
propositions. We distinguish their notations ( âˆ¼ v.s. = ) because, in general, the left hand side of
EV = ğ‘ may not be an expression and the left hand side of E âˆ¼ E may not be an event.

We deï¬ne the satisfaction of atomic proposition on program conï¬gurations as follows. Let FV(ğ‘’)

be the set of free variables in expression ğ‘’.

Deï¬nition 5.2 (Atomic Propositions). For (ğœ, ğœ‡) âˆˆ Xcomb, deï¬ne
â€¢ (ğœ, ğœ‡) |= Uğ‘‡ hğ‘’i iï¬€ FV(ğ‘’) âŠ† dom(ğœ) âˆª dom(ğœ‡) and Jğ‘’K(ğœ, ğœ‡) is a distribution that assigns

probability 1

|ğ‘‡ | to each element of ğ‘‡ ;

â€¢ (ğœ, ğœ‡) |= Bernğ‘ hğ‘’i iï¬€ FV(ğ‘’) âŠ† dom(ğœ) âˆª dom(ğœ‡) and Jğ‘’K(ğœ, ğœ‡) is a distribution that assign

probability ğ‘ to 1 and probability 1 âˆ’ ğ‘ to 0, i.e., the Bernoulli distribution;

â€¢ (ğœ, ğœ‡) |= Detmhğ‘’i iï¬€ FV(ğ‘’) âŠ† dom(ğœ) âˆª dom(ğœ‡) and Jğ‘’K(ğœ, ğœ‡) is a Dirac distribution;

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:16

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

â€¢ (ğœ, ğœ‡) |= ğ‘’ âˆ¼ ğ‘’ â€² iï¬€ FV(ğ‘’) âˆª FV(ğ‘’ â€²) âŠ† dom(ğœ) âˆª dom(ğœ‡) and Jğ‘’K(ğœ, ğ‘š) = Jğ‘’ â€²K(ğœ, ğ‘š) for any ğ‘š

in the support of ğœ‡;

â€¢ (ğœ, ğœ‡) |= ğ‘’ â‰¤ ğ‘’ â€² iï¬€ FV(ğ‘’) âˆª FV(ğ‘’ â€²) âŠ† dom(ğœ) âˆª dom(ğœ‡) and Jğ‘’K(ğœ, ğ‘š) â‰¤ Jğ‘’ â€²K(ğœ, ğ‘š) for any

ğ‘š in the support of ğœ‡;

â€¢ (ğœ, ğœ‡) |= ğ‘’ğ‘£ = ğ‘ if for any ğ‘š in the support of ğœ‡, Jğ‘’ğ‘£K(ğœ, ğ‘š) = ğ‘.
â€¢ (ğœ, ğœ‡) |= Pr[ğ‘’ğ‘£] âŠ²âŠ³ ğ›¿ iï¬€ the probability of event Jğ‘’ğ‘£K in (ğœ, ğœ‡), deï¬ned to be Pr(ğœ,ğœ‡) [ğ‘’ğ‘£] =

ğ‘š âˆˆMem [dom(ğœ‡) ] ğœ‡(ğ‘š) Â· Jğ‘’ğ‘£K(ğœ, ğ‘š), satisï¬es Pr(ğœ,ğœ‡) [ğ‘’] âŠ²âŠ³ ğ›¿.

Ã

We use the abbreviations:
â€¢ hğ‘’i , ğ‘’ âˆ¼ ğ‘’. That is, (ğœ, ğœ‡) |= hğ‘’i holds if all of the variables in ğ‘’ are deï¬ned in ğœ and ğœ‡.
â€¢ OHğ‘ hğ‘’i , Uone-hot([N])hğ‘’i.
â€¢ For multi-set ğ´, Permğ´ hğ‘’i , Upermutation(A)hğ‘’i.

For any operation âŠ™ âˆˆ {âˆ§, âˆ¨, âŠ›, âˆ—}, we pick the corresponding big-operation

âˆˆ

to be their iterated version (see Deï¬nition D.4).

o
With the atomic propositions and abbreviations, we can formally state that Xcomb captures NA.

Ã‡

Ã”

, âŠ›,âˆ—

,
nÃ“

Theorem 5.3. Let ğ‘† be any subset of RV. A set of randomized program variables ğ‘Œ = {ğ‘¦ğ‘–
| 0 â‰¤
ğ‘– < ğ¾ } satisï¬es NA in distribution ğœ‡ âˆˆ D (Mem[ğ‘†]) if and only if for any deterministic memory
ğœ âˆˆ Mem[DV], we have (ğœ, ğœ‡) |= âŠ›ğ¾
In the Xcomb model, all axioms from Barthe et al. [2020, Lemma 3, 4] still hold, and we have new

ğ‘–=0hğ‘¦ğ‘– i.

axioms for the negative association conjunction and the permutation distribution.

Lemma 5.4. Let ğ‘¥ğ›¾ be variables. The following axioms are valid in Xcomb.

|= OHğ‘ h[ğ‘¥0, . . . , ğ‘¥ğ‘ âˆ’1]i â†’

ğ‘âŠ›

ğ›¾=0

hğ‘¥ğ›¾ i

|= Permğ´ h[ğ‘¥0, . . . , ğ‘¥ğ‘ âˆ’1]i â†’

ğ‘âŠ›

ğ›¾=0

hğ‘¥ğ›¾ i

(OH-PNA)

(Perm-PNA)

The two axioms follow from Theorem 2.2, which shows that random variables in one-hot dis-
tributions and permutation distributions are NA, and Theorem 5.3, which shows that âŠ› captures
the NA of random variables. We can also encode the monotone map closure in Theorem 2.3 as an
axiom in the logic.

Lemma 5.5 (Monotone map). Let ğ‘¥, ğ‘¥ğ›¾,ğ›¼ and ğ‘¦ğ›¾ be variables. The following is valid in Xcomb.

ğ‘âŠ›

ğ›¾=0

|=

ğ¾ğ›¾ +1

ğ‘

hğ‘¥ğ›¾,ğ›¼ i

âˆ§

ğ‘¦ğ›¾ = ğ‘“ğ›¾

ğ‘¥ğ›¾,0, . . . , ğ‘¥ğ›¾,ğ¾ğ›¾
(cid:16)

(cid:17)

â†’

ğ‘âŠ›

ğ›¾=0

hğ‘¦ğ›¾ i

Ã›ğ›¾=0

Ã›ğ›¼ =0

Â©

Â«

Âª
Â®
Â¬

when ğ‘“1, . . . , ğ‘“ğ‘ all monotone or all antitone

(Mono-Map)

When we establish NA from permutation distributions, it is preserved under not only mono-
tone/antitone maps but also any element-wise homogeneous maps. The reason is that ï¬xing a
multi-set and a permutation, permuting ï¬rst and then applying the same map on each element
is the equivalent to applying the map on each element and then permuting. So applying homoge-
neous maps on a permutation distribution gives another permutation distribution. We can capture
this property in an axiom.

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

 
A Separation Logic for Negative Dependence

57:17

Lemma 5.6 (Permutation Map). Let ğ‘¥ğ›¾ be variables, and ğ‘“ (ğ´) be {ğ‘“ (ğ‘) | ğ‘ âˆˆ ğ´}. The following

axiom is valid in Xcomb.

|= Permğ´ h[ğ‘¥1, . . . , ğ‘¥ğ‘ ]i âˆ§ ğ‘¦ âˆ¼ [ğ‘“ (ğ‘¥1), . . . , ğ‘“ (ğ‘¥ğ‘ )] â†’ Permğ‘“ (ğ´) hğ‘¦i

(Perm-Map)

5.3 Restricting the assertion language

When designing a separation logic for reasoning about negative association and independence,
we sometimes want to separate out a smaller conï¬guration (ğœ â€², ğœ‡â€²) inside a given program state
(ğœ, ğœ‡) |= ğœ™, such that (ğœ â€², ğœ‡â€²) satisï¬es some sub-formula of ğœ™. In the program logic we will present
in Section 5.4, the soundness of RCase, Const, Frame and NegFrame rules all rely on the ability
to do that. To ensure there exists such a smaller conï¬guration, we require the assertion logic to
satisfy a key condition called restriction, which says that to check whether a conï¬guration satisï¬es
ğœ™, it suï¬ƒces to check whether the conï¬gurationâ€™s projection on FV(ğœ™) satisï¬es ğœ™. We identify a
subset of ğ‘€-BI formulas that satisfy the restriction property when interpreted on states in Xcomb:

Deï¬nition 5.7. We deï¬ne ğ‘€-BIrestricted as

ğ‘€-BIrestricted âˆ‹ ğ‘ƒ, ğ‘„ ::= ğ‘ âˆˆ AP | âŠ¤ | âŠ¥ | ğ‘ƒ âˆ§ ğ‘„ | ğ‘ƒ âˆ¨ ğ‘„ | ğ‘ƒ â†’ ğ‘„ | ğ‘ƒ âˆ— ğ‘„ | ğ‘ƒ âˆ’âˆ— ğ‘„ | ğ‘ƒ âŠ› ğ‘„

where AP is deï¬ned as in Equation (1).

ğ‘€-BIrestricted omits multiplicative identities ğ¼ğ‘š because on Xcomb they are all equivalent to âŠ¤. The

only limitation is that ğ‘€-BIrestricted excludes the use of âˆ’âŠ›.

Theorem 5.8 (Restriction). Let (ğœ, ğœ‡) be any conï¬guration, and let ğœ™ be an ğ‘€-BIrestricted formula

interpreted on Xcomb, Then, for any ğ‘š âˆˆ Mem[DV \ FV(ğœ™)],

(ğœ, ğœ‡) |= ğœ™ â‡â‡’ (pFV(ğœ™ )ğœ âŠ²âŠ³ ğ‘š, ğœ‹FV(ğœ™ ) ğœ‡) |= ğœ™ .

Indeed, we can exhibit a counterexample showing that âˆ’âŠ› does not satisfy restriction.

Theorem 5.9. There exists (ğœ, ğœ‡) âˆˆ Config and formula ğœ™ such that (ğœ, ğœ‡) |= ğœ™ but (ğœ, ğœ‹FV(ğœ™ )) 6|= ğœ™.

In the following, we will consider ğ‘€-BIrestricted formula on the Xcomb model as the assertion

logic.

5.4 The program logic
We now introduce the program logic layer of LINA. Judgements in LINA have the form {ğ‘ƒ} ğ‘ {ğ‘„},
where ğ‘ âˆˆ C is a probabilistic program, and ğ‘ƒ, ğ‘„ âˆˆ ğ‘€-BIrestricted are restricted assertions.

Deï¬nition 5.10 (Validity). A LINA judgment is valid, written |= {ğ‘ƒ} ğ‘ {ğ‘„}, if for all (ğœ, ğœ‡) âˆˆ

Mem[DV] Ã— D (Mem[RV]) such that (ğœ, ğœ‡) |= ğ‘ƒ, we have Jğ‘K(ğœ, ğœ‡) |= ğ‘„.

Next, we present the proof system of LINA. Since our assertions are a conservative extension
of assertions from PSL, most of the rules carry over unchanged; we list existing rules in Figure 3.
Here, we comment on the new and generalized rules, which we list in Figure 4.

NA frame rule. Our most important addition is the frame rule for the negative association con-
junction âŠ›. Informally, the NegFrame rule says that if a set of variables ğ‘‹ is negatively associated
with another set of variables ğ‘Œ that satisfy ğœ‚ in a program state, and the program ğ‘ performs a
monotone operation ğ‘“ on ğ‘‹ and stores the result in a variable ğ‘¦, then in the resulting program
state, ğ‘¦ and the untouched variables ğ‘Œ will also be negatively associated, and ğ‘Œ will still satisfy ğœ‚.
Like the Frame rule for independence âˆ—, the NegFrame rule uses syntactic restrictions to control
which variables the program may read and write. The three sets of variables RV(ğ‘), WV(ğ‘), MV(ğ‘)

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:18

DAssn

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

âŠ¢ {ğœ“ [ğ‘’ğ‘‘ /ğ‘¥ğ‘‘ ]} ğ‘¥ğ‘‘ â† ğ‘’ğ‘‘ {ğœ“ }

Skip

âŠ¢ {ğœ™ } skip {ğœ™ }

Seqn

âŠ¢ {ğœ™ } ğ‘ {ğœ“ }

âŠ¢ {ğœ“ } ğ‘ â€² {ğœ‚}

âŠ¢ {ğœ™ } ğ‘ ; ğ‘ â€² {ğœ‚}

Cond

âŠ¢ {ğœ™ âˆ§ ğ‘ âˆ¼ tt} ğ‘ {ğœ“ }

âŠ¢ {ğœ™ âˆ§ ğ‘ âˆ¼ ï¬€ } ğ‘ â€² {ğœ“ }

|= ğœ™ â†’ Detmhğ‘i

âŠ¢ {ğœ™ } if ğ‘ then ğ‘ else ğ‘ â€² {ğœ“ }

Loop

âŠ¢ {ğœ™ âˆ§ ğ‘ âˆ¼ tt} ğ‘ {ğœ™ }

|= ğœ™ â†’ Detmhğ‘i

âŠ¢ {ğœ™ } while ğ‘ do ğ‘ {ğœ™ âˆ§ ğ‘ âˆ¼ ï¬€ }

RAssn

ğ‘¥ğ‘Ÿ âˆ‰ FV(ğ‘’ğ‘Ÿ )
âŠ¢ {âŠ¤} ğ‘¥ğ‘Ÿ â† ğ‘’ğ‘Ÿ {ğ‘¥ğ‘Ÿ âˆ¼ ğ‘’ğ‘Ÿ }

RSamp

âŠ¢ {âŠ¤} ğ‘¥ğ‘Ÿ

$â† Uğ‘† {Uğ‘† hğ‘¥ğ‘Ÿ i}

RSamp*

âŠ¢ {ğœ™ } ğ‘¥ğ‘Ÿ

ğ‘¥ğ‘Ÿ âˆ‰ FV(ğœ™)
$â† Uğ‘† {ğœ™ âˆ— Uğ‘† hğ‘¥ğ‘Ÿ i}

Weak

âŠ¢ {ğœ™ } ğ‘ {ğœ“ }

|= ğœ™ â€² â†’ ğœ™ âˆ§ ğœ“ â†’ ğœ“ â€²

âŠ¢ {ğœ™ â€²} ğ‘ {ğœ“ â€²}

True

âŠ¢ {âŠ¤} ğ‘ {âŠ¤}

Conj

âŠ¢ {ğœ™1} ğ‘ {ğœ“1}

âŠ¢ {ğœ™2} ğ‘ {ğœ“2}

âŠ¢ {ğœ™1 âˆ§ ğœ™2} ğ‘ {ğœ“1 âˆ§ ğœ“2}

Case

âŠ¢ {ğœ™1} ğ‘ {ğœ“1}

âŠ¢ {ğœ™2} ğ‘ {ğœ“2}

âŠ¢ {ğœ™1 âˆ¨ ğœ™2} ğ‘ {ğœ“1 âˆ¨ ğœ“2}

Const

âŠ¢ {ğœ™ } ğ‘ {ğœ“ }

FV(ğœ‚) âˆ© MV(ğ‘) = âˆ…

âŠ¢ {ğœ™ âˆ§ ğœ‚} ğ‘ {ğœ“ âˆ§ ğœ‚}

Frame

âŠ¢ {ğœ™ } ğ‘ {ğœ“ }

FV(ğœ‚) âˆ© MV(ğ‘) = âˆ…

FV(ğœ“ ) âŠ† ğ‘‡ âˆª RV(ğ‘) âˆª WV(ğ‘)

|= ğœ™ â†’ hğ‘‡ âˆª RV(ğ‘)i

âŠ¢ {ğœ™ âˆ— ğœ‚} ğ‘ {ğœ“ âˆ— ğœ‚}

Fig. 3. LINA rules: from PSL.

ğœ‚ âˆˆ CC

|=Mem ğœ‚ â†’

ğœ‚ğ›¼

ğœ“ âˆˆ CM

âˆ€ğ›¼ âˆˆ ğ‘†. âŠ¢ {ğœ™ âˆ— ğœ‚ğ›¼ } ğ‘ {ğœ“ }

RCase

|= ğœ™ â†’ hRV(ğ‘)i

NegFrame

Ãœğ›¼ âˆˆğ‘†

âŠ¢ {ğœ™ âˆ— ğœ‚} ğ‘ {ğœ“ }

FV(ğœ‚) âˆ© MV(ğ‘) = âˆ…

âŠ¢ {ğœ™ } ğ‘ {ğ‘¦ âˆ¼ ğ‘“ (ğ‘‹ )}

ğ‘‹ âŠ† RV(ğ‘) \ MV(ğ‘)
ğ‘“ is a monotone function

ğ‘¦ âˆ‰ FV(ğœ‚)

âŠ¢ {ğœ™ âŠ› ğœ‚} ğ‘ {hğ‘¦i âŠ› ğœ‚}

ProbBound

âŠ¢ {ğ‘’ğ‘£1 = 1} ğ‘ {Pr[ğ‘’ğ‘£2] â‰¤ ğ›¿ }
âŠ¢ {Pr[ğ‘’ğ‘£1] â‰¥ 1 âˆ’ ğœ–} ğ‘ {Pr[ğ‘’ğ‘£2] â‰¤ ğ›¿ + ğœ–}

Fig. 4. LINA rules: new and extended.

represent the variables that ğ‘ may read from, must write to, and may modify, respectively; these
sets can be deï¬ned by induction on the syntax of the program. Roughly, the side conditions guaran-
tee the program ğ‘ does not read from or modify ğ‘Œ , the set of variables satisfying ğœ‚; they in addition

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:19

guarantee that ğ‘‹ , the domain of the monotone map will not be modiï¬ed by ğ‘, and ğ‘¦, the codomain
of the monotone map does not belong to ğ‘Œ .

Generalized random case analysis. As a more minor extension, we also generalize the random-
ized case analysis rule from PSL in RCase. At a high level, this rule allows reasoning by case
analysis on a property ğœ‚ of the program memory (e.g., whether a variable is true or false). Since
the input is a distribution, which may have some probability of ğœ‚ holding, and some probability of
ğœ‚ not holding, soundness of the rule is a delicate matter requiring several technical side conditions.
The original rule in PSL only allowed case analysis on a Boolean expression; we generalize this
rule to allow a case analysis on any ï¬nite number of cases (e.g., performing case analysis on the
value of a bounded variable).

To explain this rule, we ï¬rst introduce the side conditions in order. We say that a formula ğœ‚ is
closed under conditioning (CC) if for any (ğœ, ğœ‡) |= ğœ‚, for any ğ‘š in the support of ğœ‡, (ğœ, ğ›¿ (ğ‘š)) |= ğœ‚.
In the second condition, |=Mem ğœ™ denotes that for any ğœ âˆˆ Mem[DV], ğ‘š âˆˆ Mem[ğ‘‡ ] where
ğ‘‡ âŠ† RV, (ğœ, ğ›¿ (ğ‘š)) |= ğœ™, which says ğœ™ is valid on all eï¬€ectively deterministic conï¬gurations.
Finally, we say that a formula ğœ™ is closed under mixtures (CM) if (ğœ, ğœ‡1) |= ğœ™, (ğœ, ğœ‡2) |= ğœ™ and ğœ‡ is a
convex combination of ğœ‡1, ğœ‡2 together imply (ğœ, ğœ‡â€²) |= ğœ™.

Then, the rule RCase says if an assertion ğœ‚ is independent from the rest of the assertions in the
pre-condition, ğœ‚ is closed under conditioning, and the post-condition ğœ“ is closed under mixtures,
then we can perform case analysis on ğœ‚ to derive {ğœ™ âˆ— ğœ‚} ğ‘ {ğœ“ }. Intuitively, every memory ğ‘š in the
support of the input memory distribution satisï¬es ğœ‚ğ‘ for some case ğ‘ âˆˆ ğ‘†. The main premise shows
that the output distribution of program ğ‘ from any such input ğ‘š satisï¬es ğœ“ . Then, since any distri-
bution ğœ‡ on inputs is a convex combination of such memories ğ‘š, and ğœ“ holds on each conditional
output distribution, we have ğœ“ holds on the entire output distribution by convex closure.

Bounding bad events. In addition, we present the rule ProbBound to facilitate bounding tail
probabilities. It says that if the pre-condition ğ‘’ğ‘£1 = 1 guarantees that event ğ‘’ğ‘£2 happens for at
most ğ›¿ probability after command ğ‘, then in general, event ğ‘’ğ‘£2 happens for at most probability
ğ›¿ + ğœ– after ğ‘, where ğœ– upper bounds the probability that ğ‘’ğ‘£1 is not true in the pre-condition. The
validity of this rule uses the law of total probability, which says for any two events ğ‘’ğ‘£1 and ğ‘’ğ‘£2,

Pr(ğ‘’ğ‘£1) = Pr(ğ‘’ğ‘£1 | ğ‘’ğ‘£2) Â· Pr(ğ‘’ğ‘£2) + Pr(ğ‘’ğ‘£1 | Â¬ğ‘’ğ‘£2) Â· Pr(Â¬ğ‘’ğ‘£2)

â‰¤ Pr(ğ‘’ğ‘£1 | ğ‘’ğ‘£2) + Pr(Â¬ğ‘’ğ‘£2).

As expected, the LINA proof system is sound.

Theorem 5.11. (Soundness of LINA) If âŠ¢ {ğœ™ } ğ‘ {ğœ“ } is derivable, then it is valid: |= {ğœ™ } ğ‘ {ğœ“ }.

6 EXAMPLES
Now that we have introduced LINA, we present a series of formalized case studies. Our examples
are extracted from various algorithms using hashing and balls-into-bins processes.

6.1 Preliminaries: probabilities, expectations, concentration bounds
Our examples will use a handful of standard facts about probability distributions, encoded as ax-
ioms in the assertion logic. We will generally mention these axioms before they are used, but here
we introduce one fact that we will use through all of our examples: the Chernoï¬€ bound.

In each of our examples we will establish negative dependence of a sequence of random variables
{ğ‘‹ğ‘– }ğ‘– and apply a concentration bound: a theorem showing that the sum ğ‘‹1 +Â· Â· Â·+ğ‘‹ğ‘› is usually close
to its expected value. This kind of analysis is useful for establishing high-probability guarantees

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:20

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

Bloom :

ğ‘ğ‘™ğ‘œğ‘œğ‘š â† ğ‘§ğ‘’ğ‘Ÿğ‘œ (ğ‘ );
ğ‘š â† 0;
while ğ‘š < ğ‘€ do

â„ â† 0
while â„ < ğ» do

ğ‘ğ‘–ğ‘› $â† ğ‘œâ„( [ğ‘ ]);
ğ‘¢ğ‘ğ‘‘ â† ğ‘ğ‘™ğ‘œğ‘œğ‘š || ğ‘ğ‘–ğ‘›;
ğ‘ğ‘™ğ‘œğ‘œğ‘š â† ğ‘¢ğ‘ğ‘‘;

â„ â† â„ + 1;
ğ‘š â† ğ‘š + 1;

BloomArray :

ğ‘ğ‘™ğ‘œğ‘œğ‘š â† ğ‘§ğ‘’ğ‘Ÿğ‘œ (ğ‘ );
ğ‘š â† 0;
while ğ‘š < ğ‘€ do

â„ â† 0
while â„ < ğ» do

ğ‘ğ‘–ğ‘› $â† ğ‘œâ„( [ğ‘ ]);
ğ‘› â† 0;
while ğ‘› < ğ‘ do

ğ‘¢ğ‘ğ‘‘ â† ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ‘›] || ğ‘ğ‘–ğ‘›[ğ‘›];
ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ‘›] â† ğ‘¢ğ‘ğ‘‘;
ğ‘› â† ğ‘› + 1

â„ â† â„ + 1;

ğ‘š â† ğ‘š + 1

(a) Higher-level version

(b) Array version

Fig. 5. Bloom filter examples

of randomized algorithms, e.g., showing that the error of a random estimate is at most 0.01 with
probability at least 99%.

Theorem 6.1 (Chernoff bound for NA variables [Dubhashi and Ranjan 1998]). Let ğ‘‹1, . . . , ğ‘‹ğ‘›

be a sequence of NA random variables, each bounded in [0, 1], and let ğ‘Œ =
ure probability ğ›½ âˆˆ (0, 1], we have:

ğ‘›
ğ‘–=1 ğ‘‹ğ‘–. Then for any fail-

Pr[|ğ‘Œ âˆ’ E[ğ‘Œ ] | â‰¥ ğ‘‡ (ğ›½, ğ‘›)] â‰¤ ğ›½ where ğ‘‡ (ğ›½, ğ‘›) =

Ã
(ğ‘›/2) ln(2/ğ›½).

To hide complex numerical bounds, we use the notation ğ‘‡ (ğ›½, ğ‘›) for the above function through-

p

out. In our assertion logic, the Chernoï¬€ bound can be encoded as the following axiom schema:

Theorem 6.2 (Chernoff bound, axiom). Let {ğ‘¥ğ›¼ } be a family of variables indexed by ğ›¼, where
each variable is bounded in [0, 1] and is a monotone function of its program variables. Then for any
ğ›½ âˆˆ (0, 1], the following axiom schema is sound in our model:

â‰¥ ğ‘‡ (ğ›½, ğ‘›)

â‰¤ ğ›½

#

(NA-Chernoï¬€)

ğ‘âŠ›

ğ›¼ =0

|=

hğ‘¥ğ›¼ i â†’ Pr

ğ‘¥ğ›¼ âˆ’ E

"

ğ‘

ğ‘¥ğ›¼

Ã•ğ›¼ =0

ğ‘

" (cid:12)
Ã•ğ›¼ =0
(cid:12)
(cid:12)
(cid:12)
(cid:12)

#(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

We will also use a new expression in our assertions: E[ğ‘“ ], where ğ‘“ is a non-negative and
bounded numeric expression, denotes the expected value of ğ‘“ in the current program conï¬gu-
ration. We also observe the following conventions throughout the examples: logical variables are
denoted by Greek (ğ›¼, ğ›½, ğ›¾, . . . ) and capital Roman letters (ğ‘€, ğ‘ , ğ¾, . . . ). Program variables start with
lower-case Roman letters (ğ‘¥,ğ‘¦, ğ‘§, . . . ).

6.2 Bloom filter, high-level

Next, we revisit the Bloom ï¬lter example introduced in Section 2. We show how to translate the
informal argument in Section 2 into formal proofs in our program logic. First, we will analyze
the process of adding items into a Bloom ï¬lter ğ‘ğ‘™ğ‘œğ‘œğ‘š and prove that the entries in ğ‘ğ‘™ğ‘œğ‘œğ‘š are
negatively associated at the end of the process. Second, we will analyze a program that checks the
membership of a new item in a given Bloom ï¬lter and show how to bound its false positive rate.

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:21

Last, we combine them together into one proof that bounds the false positive rate of a Bloom ï¬lter
with ğ‘€ elements.

Proving NA of ğ‘ğ‘™ğ‘œğ‘œğ‘š. We reproduce the code for Bloom in Figure 5a. This program is a higher-
level version of the program in Figure 5b, which performs array operations bit-by-bit. We align the
two versions so that the equivalent operations are side-by-side. We will demonstrate our program
logic on the higher-level version ï¬rst and analyze the array version later in Section 6.3.

Recall that the code models inserting ğ‘€ distinct elements into a Bloom ï¬lter backed by an array
ğ‘ğ‘™ğ‘œğ‘œğ‘š of length ğ‘ , where each element is hashed by ğ» functions, each producing an element of
[ğ‘ ] uniformly at random. We refer to the outer loop as outer, and the inner loop as inner. For both

the outer and the inner loop, we apply the rule Loop with the loop invariant: âŠ›ğ‘

ğ›½=0hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]i.
We consider the inner loop ï¬rst. We show that the invariant is preserved by the body of inner.
After the ğ‘œâ„ sampling command, RSamp* gives:

ğ‘âŠ›

ğ›½=0

hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]i

âˆ— OH[ğ‘ ] hğ‘ğ‘–ğ‘›i

By negative association of the one-hot distribution (OH-PNA), we get

Â«

ğ‘âŠ›

ğ›½=0

Â©

which implies

Â©

Âª
Â®
Â¬

hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]i

âˆ—

Âª
Â®
Â¬

Â©

Â«

hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]i

âŠ›

ğ‘âŠ›

ğ›¾=0

ğ‘âŠ›

ğ›¾=0

ğ‘ğ‘–ğ‘›[ğ›¾]

Âª
Â®
Â¬
ğ‘ğ‘–ğ‘›[ğ›¾]

Â«

ğ‘âŠ›

ğ›½=0

Â©
using Weak. Rearranging terms, this is equivalent to
Â«

Âª
Â®
Â¬

Â©

Â«

Âª
Â®
Â¬

ğ‘âŠ›

hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]i âŠ› hğ‘ğ‘–ğ‘›[ğ›½]i.

After the assignment to ğ‘¢ğ‘ğ‘‘, we have:

ğ›½=0

ğ‘âŠ›

ğ›½=0

hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]i âŠ› hğ‘ğ‘–ğ‘›[ğ›½]i

âˆ§ ğ‘¢ğ‘ğ‘‘ âˆ¼ ğ‘ğ‘™ğ‘œğ‘œğ‘š || ğ‘ğ‘–ğ‘›.

Because || is monotone, applying the monotone mapping axiom (Mono-Map) gives us:

Â©

Âª
Â®
Â¬

Â«

ğ‘âŠ›

ğ›½=0

hğ‘¢ğ‘ğ‘‘ [ğ›½]i.

Using the assignment rule (RAssn) on the assignment to bloom shows that the loop invariant is
preserved by the inner loop. Thus, Loop gives:

{

ğ‘âŠ›

ğ›½=0

hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]i} inner {

ğ‘âŠ›

ğ›½=0

hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]i}

Next, we turn to the outer loop. The argument showing that the invariant is preserved by the outer
loop follows by a straightforward argument, since the outer loop only modiï¬es ğ‘ğ‘™ğ‘œğ‘œğ‘š through the

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

 
 
 
 
 
 
57:22

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

inner loop, so Loop gives:

Then, we have:

{

ğ‘âŠ›

ğ›½=0

hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]i} outer {

ğ‘âŠ›

ğ›½=0

hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]i}

{âŠ¤} Bloom { ğ‘âŠ›

ğ›½=0

hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]i}

because initializing ğ‘ğ‘™ğ‘œğ‘œğ‘š to the all-zeros vector, a deterministic value, establishes the loop invari-
ant. This judgment shows that the ğ‘ğ‘™ğ‘œğ‘œğ‘š vector satisï¬es NA at the end of the program.

Bounding the false positive rate. Now, we turn to veri-
fying a bound on the false positive rate of the Bloom ï¬l-
ter. Recall that a false positive occurs if when querying
with an element that was not inserted, the ï¬lter returns
true. We can encode the membership check of a new ele-
ment as a program CheckMem (ğ», ğ‘ğ‘™ğ‘œğ‘œğ‘š), listed in Fig-
ure 6, which hashes the new element into ğ» uniformly
random positions and checks if these positions are all set
to one in the ï¬lter. If so, the Bloom ï¬lter will report that
the new element is in set, when it was never insertedâ€”a
false positive.

To verify the false positive rate, we place the program

CheckMem(ğ», ğ‘ğ‘™ğ‘œğ‘œğ‘š) :

â„ â† 0;
ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡ â† 1
while â„ < ğ» do
ğ‘ğ‘–ğ‘› $â† U[ğ‘ ] ;
â„ğ‘–ğ‘¡ â† ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ‘ğ‘–ğ‘›];
ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡ â† â„ğ‘–ğ‘¡ && ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡;
â„ â† â„ + 1;

Fig. 6. Check the membership of a new
item

CheckMem(ğ», ğ‘ğ‘™ğ‘œğ‘œğ‘š) immediately after Bloom, and then verify a bound on the probability that
ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡ is 1 at the end of the combined program. We ï¬rst apply the Chernoï¬€ bound to the NA
variables (NA-Chernoï¬€) to prove that, with high probability, the number of occupied bins in Bloom
is near its mean with high probability:

âŠ¤

Bloom

Pr

(

)

(

ğ‘

ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½] âˆ’ E

ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]

â‰¥ ğ‘‡ (ğ›¿, ğ‘ )

â‰¤ ğ›¿

.

)

ğ‘

Ã•ğ›½=0

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

ï£®
ï£¯
ï£¯
ï£¯
ï£¯
ï£°

ï£®
Ã•ğ›½=0
ï£¯
ï£¯
ï£¯
ï£¯
ï£°

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

ï£¹
ï£º
ï£º
ï£º
ï£º
ï£»

This concentration bound implies that a tail bound, which says with high probability

ğ‘
ğ›½=0 ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½] is upper bounded by its expected value plus ğ‘‡ (ğ›¿, ğ‘ ),

Ã

âŠ¤

Bloom

ğ‘

ğ‘

Pr

ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½] < E

ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]

+ ğ‘‡ (ğ›¿, ğ‘ )

â‰¥ 1 âˆ’ ğ›¿

(

)

(

ï£®
ï£¯
ï£¯
ï£¯
Then we analyze CheckMem and show in Appendix F that
ï£¯
ï£°

ï£®
Ã•ğ›½=0
ï£¯
ï£¯
ï£¯
ï£¯
ï£°

Ã•ğ›½=0

ğ‘

ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½] < ğ¾

CheckMem

ï£¹
ï£º
ï£º
ï£º
ï£º
ï£»

ï£¹
ï£º
ï£º
ï£º
ï£º
ï£»
Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤ (ğ¾/ğ‘ )ğ»

.

)

(2)

o
Then, by the ProbBound rule and basic axioms about probabilities, we have

o

n

n

Ã•ğ›½=0

ğ‘

{Pr[

ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½] < ğ¾] â‰¥ 1 âˆ’ ğ›¿} CheckMem {Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤ (ğ¾/ğ‘ )ğ» + ğ›¿}.

(3)

Ã•ğ›½=0

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

ï£¹
ï£º
ï£º
ï£º
ï£º
ï£»

.

A Separation Logic for Negative Dependence

57:23

We then use Seqn to combine the proved judgements for Bloom (2) and CheckMem (3) to derive
that, for any ğ›¿,

{âŠ¤} Bloom; CheckMem{Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤

E

ğ‘
ğ›½=0 ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]

+ ğ‘‡ (ğ›¿, ğ‘ )

(cid:2) Ã

ğ‘

(cid:3)

ğ»

+ ğ›¿}.

!

Since ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡ is 1 exactly when there is a false positive, this judgment proves an upper bound on
the false positive rate of the Bloom ï¬lter.5

6.3 Bloom filter, low-level
The previous Bloom ï¬lter uses a vector operation ğ‘ğ‘™ğ‘œğ‘œğ‘š || ğ‘ğ‘–ğ‘› to transform an array of negatively
associated values. We next consider a lower-level version of the previous example, BloomArray,
in Figure 5b, where the vector operation is replaced by a loop that applies the Boolean-or.

Let outer and mid be the outer-most and second outer-most loops, and let inner be the inner-
most loop. Again, our goal is to show that the vector ğ‘ğ‘™ğ‘œğ‘œğ‘š is negatively associated at the end of
the program. We ï¬rst prove the following judgment for inner:

{

ğ‘âŠ›

ğ›½=0

hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]i âˆ—

ğ‘âŠ›

ğ›¾=0

hğ‘ğ‘–ğ‘›[ğ›¾]i} inner {

ğ‘âŠ›

ğ›½=0

hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]i âŠ›

ğ‘âŠ›

ğ›¾=ğ‘›

hğ‘ğ‘–ğ‘›[ğ›¾]i}

We will apply the rule Loop on inner with the following loop invariant:

ğœ™ =

ğ‘âŠ›

ğ›½=0

hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]i âŠ›

ğ‘âŠ›

ğ›¾=ğ‘˜

hğ‘ğ‘–ğ‘›[ğ›¾]i

To show that the loop invariant is preserved by the body, we can ï¬rst show:

{hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ‘›],ğ‘ğ‘–ğ‘›[ğ‘›]i} ğ‘¢ğ‘ğ‘‘ â† ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ‘›] || ğ‘ğ‘–ğ‘›[ğ‘›] {ğ‘¢ğ‘ğ‘‘ âˆ¼ ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ‘›] || ğ‘ğ‘–ğ‘›[ğ‘›]}

using RAssn. Noting that the boolean-or operator is a monotone operation, we may apply the
frame rule NegFrame to obtain:

{hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ‘›],ğ‘ğ‘–ğ‘›[ğ‘›]i âŠ› ğœ‚} ğ‘¢ğ‘ğ‘‘ â† ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ‘›] || ğ‘ğ‘–ğ‘›[ğ‘›] {hğ‘¢ğ‘ğ‘‘i âŠ› ğœ‚}

hğ‘ğ‘–ğ‘›[ğ›¾]i

.

ğ‘âŠ›

ğ›¾=ğ‘›+1
Â©

Âª
Â®
Â¬

Âª
Â®
Â¬

with the framing condition

ğœ‚ =

ğ‘›âŠ›

ğ›½=0

hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]i

âŠ›

!

ğ‘âŠ›

ğ›½=ğ‘›+1

hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]i

âŠ›

Thus, by re-associating the separating conjunction and applying RAssn for the remaining two
assignments in the inner-most loop, we have:

Â«

Â©

Â«

{ğœ™ } ğ‘¢ğ‘ğ‘‘ â† ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ‘›] || ğ‘ğ‘–ğ‘›[ğ‘›]; ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ‘›] â† ğ‘¢ğ‘ğ‘‘; ğ‘› â† ğ‘› + 1 {ğœ™ }

and thus by Loop, we have:

{ ğ‘âŠ›

ğ›½=0

hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]i âŠ›

ğ‘âŠ›

ğ›¾=ğ‘›

hğ‘ğ‘–ğ‘›[ğ›¾]i} inner { ğ‘âŠ›

ğ›½=0

hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]i âŠ›

ğ‘âŠ›

ğ›¾=ğ‘›

hğ‘ğ‘–ğ‘›[ğ›¾]i}.

5The precise expected value is ğ‘ Â· (1 âˆ’ (1 âˆ’ 1/ğ‘ )ğ‘€ Â·ğ» ), a fact which can also be shown in our logic. Roughly speaking,
this fact follows because each element of ğ‘ğ‘™ğ‘œğ‘œğ‘š is the logical-or of ğ‘€ Â· ğ» probabilistically independent bits, each 1 with
probability 1/ğ‘ and 0 otherwise. This argument does not rely on negative association.

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

 
 
 
 
57:24

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

Now for loop mid, we establish the same loop invariant as we took before:

ğœ“ =

ğ‘âŠ›

ğ›½=0

hğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]i

If ğœ“ holds at the beginning of mid, then invariant for the inner-most loop ğœ™ holds after assigning
0 to ğ‘› and sampling ğ‘ğ‘–ğ‘›, since ğ‘ğ‘–ğ‘› is independent of ğœ“ (RSamp*) and ğ‘ğ‘–ğ‘› is distributed as ğ‘œâ„(ğ‘›),
which implies entries in ğ‘ğ‘–ğ‘› are negatively associated (OH-PNA). Furthermore, ğœ™ implies ğœ“ at the
exit of inner, by dropping the conjunct describing ğ‘ğ‘–ğ‘›. Thus, ğœ“ is a valid invariant for mid, and the
rest of the proof proceeds unchanged.

6.4 Permutation hashing

Our second example considers a scheme for hashing
using a random permutation. Consider the program
in Figure 7, from an algorithm for fast set intersec-
tion [Ding and KÃ¶nig 2011]. Letting ğµ be the number of
bins, and the data universe be [ğµ Â· ğ¾] = {1, . . . , ğµ Â· ğ¾ }
where ğµ Â· ğ¾ â‰¥ ğ‘ , we ï¬rst draw a uniformly random per-
mutation ğ‘” of the data universe. Then, we hash the num-
bers ğ‘› âˆˆ [ğ‘ ] into ğ‘ğ‘–ğ‘›[ğ‘›] by applying the hash function
ğ‘” and then taking the result modulo ğµ. Then, we record
whether the item landed in a speciï¬c bucket ğ‘ by com-
puting the indicator â„ğ‘–ğ‘¡ğ‘ [ğ‘›] = [ğ‘ğ‘–ğ‘›[ğ‘›] = ğ‘ ], which is 1
if ğ‘ğ‘–ğ‘›[ğ‘›] = ğ‘ and 0 otherwise, and accumulate the result
into the count ğ‘ğ‘¡.

PermHash :

ğ‘” $â† ğ‘ğ‘’ğ‘Ÿğ‘š( [ğµ Â· ğ¾]);
ğ‘› â† 0;
ğ‘ğ‘¡ â† 0;
while ğ‘› < ğ‘ do

ğ‘ğ‘–ğ‘›[ğ‘›] â† ğ‘šğ‘œğ‘‘ (ğ‘”[ğ‘›], ğµ);
â„ğ‘–ğ‘¡ğ‘ [ğ‘›] â† [ğ‘ğ‘–ğ‘›[ğ‘›] = ğ‘ ];
ğ‘ğ‘¡ â† ğ‘ğ‘¡ + â„ğ‘–ğ‘¡ğ‘ [ğ‘›];
ğ‘› â† ğ‘› + 1

Fig. 7. Permutation hashing

Our goal is to show that ğ‘ğ‘¡ is usually not far from its expected value, which is ğ‘ /ğµ. If the
quantities {[ğ‘ğ‘–ğ‘›[ğ‘›] = ğ‘ ]}ğ‘› were independent, we would be able to apply a standard concentration
bound to the sum ğ‘ğ‘¡. However, {ğ‘ğ‘–ğ‘›[ğ‘›] = ğ‘ }ğ‘› are not independent: for instance, since exactly ğ¾
elements from [ğµ Â· ğ¾] map to ğ‘ , if ğ‘ğ‘–ğ‘›[ğ‘›] = ğ‘ for ğ‘› âˆˆ {0, 1, . . . , ğ¾ âˆ’ 1}, then ğ‘ğ‘–ğ‘›[ğ¾] = ğ‘ must be
false.

Nevertheless, we can show that {[ğ‘ğ‘–ğ‘›[ğ‘›] = ğ‘ ]}ğ‘› are negatively associated random variables.
Intuitively, {ğ‘”[ğ‘›]}ğ‘› are NA random variables because the result of a uniformly random permu-
tation is NA. Then, {ğ‘ğ‘–ğ‘›[ğ‘›]}ğ‘› is computed by mapping the function ğ‘šğ‘œğ‘‘ (âˆ’, ğµ) over the array ğ‘”;
since this produces another uniform permutation distribution, the vector {ğ‘ğ‘–ğ‘›[ğ‘›]}ğ‘› is also NA. By
similar reasoning {[ğ‘ğ‘–ğ‘›[ğ‘›] = ğ‘ ]}ğ‘› is also NA, as it is obtained by mapping the function [âˆ’ = ğ‘ ]
over {ğ‘ğ‘–ğ‘›[ğ‘›]}ğ‘›. Since this example is similar to the ï¬rst Bloom ï¬lter example, except applying
the negative association of the permutation distribution (Perm-PNA) and the permutation map
axiom (Perm-Map), we defer the details to the appendix.

6.5 Fully-dynamic dictionary

For our next example, we consider a hashing scheme for a fully-dynamic dictionary, a space-
eï¬ƒcient data structure that supports insertions, deletions, and membership queries. The top level
of the data structure by Bercea and Even [2019] uses a two-level hashing scheme: elements are
ï¬rst hashed into a crate, and then hashed into a pocket dictionary within each crate. As part of the
space analysis of their scheme, Bercea and Even [2019] proves a high-probability bound on the
number of pocket dictionaries that overï¬‚ow after a given number of elements are inserted.

We extract the program FDDict in Figure 8a from the scheme in Bercea and Even [2019]. The
program models the insertion of ğ‘ elements. Each element is ï¬rst hashed into one of ğ¶ possible

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:25

FDDict :

ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ â† ğ‘§ğ‘’ğ‘Ÿğ‘œ (ğ¶, ğ‘ƒ);
ğ‘› â† 0;
while ğ‘› < ğ‘ do
ğ‘ğ‘Ÿğ‘ğ‘¡ğ‘’ [ğ‘›]
ğ‘ğ‘œğ‘ğ‘˜ğ‘’ğ‘¡ [ğ‘›]
$â† ğ‘œâ„( [ğ‘ƒ]);
ğ‘ğ‘–ğ‘›[ğ‘›] â† ğ‘ğ‘Ÿğ‘ğ‘¡ğ‘’ [ğ‘›]âŠ¤ Â· ğ‘ğ‘œğ‘ğ‘˜ğ‘’ğ‘¡ [ğ‘›];
ğ‘ â† 0;
while ğ‘ < ğ‘ƒ do

$â† ğ‘œâ„( [ğ¶]);

ğ‘ â† 0;
while ğ‘ < ğ¶ do

ğ‘¢ğ‘ğ‘‘ â† ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ‘] [ğ‘] + ğ‘ğ‘–ğ‘›[ğ‘›] [ğ‘] [ğ‘];
ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ‘] [ğ‘] â† ğ‘¢ğ‘ğ‘‘;
ğ‘ â† ğ‘ + 1;

ğ‘ â† ğ‘ + 1;

ğ‘› â† ğ‘› + 1;

ğ‘ â† 0;
while ğ‘ < ğ‘ƒ do

ğ‘ â† 0;
while ğ‘ < ğ¶ do

ğ‘œğ‘£ğ‘’ğ‘Ÿ [ğ‘] [ğ‘] â† [ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ‘] [ğ‘] > ğ‘‡ğ‘ğ‘–ğ‘›];
ğ‘¢ğ‘ğ‘‘ â† ğ‘œğ‘£ğ‘’ğ‘Ÿğ¶ğ‘¡ [ğ‘] + ğ‘œğ‘£ğ‘’ğ‘Ÿ [ğ‘] [ğ‘];
ğ‘œğ‘£ğ‘’ğ‘Ÿğ¶ğ‘¡ [ğ‘] â† ğ‘¢ğ‘ğ‘‘;
ğ‘ â† ğ‘ + 1;

ğ‘ â† ğ‘ + 1

RepeatBIB :
ğ‘Ÿ â† 0;
while ğ‘Ÿ < ğ‘… do

ğ‘› â† 0
ğ‘Ÿğ‘’ğ‘š â† 0;
while ğ‘› < ğ‘ do

ğ‘ğ‘¡ [ğ‘›] â† ğ‘ğ‘¡ [ğ‘›] âˆ’ [ğ‘ğ‘¡ [ğ‘›] > 0];
ğ‘Ÿğ‘’ğ‘š â† ğ‘Ÿğ‘’ğ‘š + [ğ‘ğ‘¡ [ğ‘›] > 0];
ğ‘› â† ğ‘› + 1;

ğ‘— â† 0;
while ğ‘— < ğ‘Ÿğ‘’ğ‘š do

ğ‘ğ‘–ğ‘›[ ğ‘— ] $â† ğ‘œâ„( [ğ‘ ]);
ğ‘˜ â† 0;
while ğ‘˜ < ğ‘ do

ğ‘¢ğ‘ğ‘‘ â† ğ‘ğ‘¡ [ğ‘˜] + ğ‘ğ‘–ğ‘›[ ğ‘— ] [ğ‘˜];
ğ‘ğ‘¡ [ğ‘˜] â† ğ‘¢ğ‘ğ‘‘;
ğ‘˜ â† ğ‘˜ + 1;

ğ‘— â† ğ‘— + 1;

ğ‘› â† 0;
ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ğ¶ğ‘¡ [ğ‘Ÿ ] â† 0;
ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ â† ğ‘–ğ‘ ğ‘ğ‘’ğ‘Ÿğ‘œ (ğ‘ğ‘¡);
while ğ‘› < ğ‘ do

ğ‘¢ğ‘ğ‘‘ â† ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ğ¶ğ‘¡ [ğ‘Ÿ ] + ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ [ğ‘›];
ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ğ¶ğ‘¡ [ğ‘Ÿ ] â† ğ‘¢ğ‘ğ‘‘;
ğ‘› â† ğ‘› + 1;

ğ‘Ÿ â† ğ‘Ÿ + 1;

(a) Fully-dynamic dictionary [Bercea and Even
2019]

(b) Repeated balls-into-bins [Becchetti et al. 2019]

Fig. 8. Larger examples

crates uniformly at random, and then hashed into one of ğ‘ƒ possible pocket dictionaries uniformly
at random. The variable ğ‘ğ‘–ğ‘›[ğ‘›] is a ğ¶ by ğ‘ƒ matrix, with all entries zero except for the entry at
(ğ‘ğ‘Ÿğ‘ğ‘¡ğ‘’ [ğ‘›], ğ‘ğ‘œğ‘ğ‘˜ğ‘’ğ‘¡ [ğ‘›]), which is set to 1. Next, the program totals up the number of elements hash-
ing to each (crate, pocket) pair, storing the result in the ğ¶ by ğ‘ƒ matrix ğ‘ğ‘–ğ‘›ğ¶ğ‘¡. Finally, the program
checks which (crate, pocket) pairs have count larger than some concrete threshold ğ‘‡ğ‘ğ‘–ğ‘› (ğ‘œğ‘£ğ‘’ğ‘Ÿ ), and
totals up the number of full pocket dictionaries in each crate (ğ‘œğ‘£ğ‘’ğ‘Ÿğ¶ğ‘¡).

Our logic can prove a judgment of the following form:

âŠ¤

FDDict

(cid:26)

(cid:27)

ğ¶

(cid:26)

Ã›ğ›¾=0

Pr[ğ‘œğ‘£ğ‘’ğ‘Ÿğ¶ğ‘¡ [ğ›¾] > ğ‘ƒ Â· ğœŒğ‘ğ‘–ğ‘› + ğ‘‡ (ğœŒğ‘œğ‘£ğ‘’ğ‘Ÿ , ğ‘ƒ)] â‰¤ ğœŒğ‘œğ‘£ğ‘’ğ‘Ÿ

,

(cid:27)

where the logical variables ğœŒğ‘ğ‘–ğ‘› and ğœŒğ‘œğ‘£ğ‘’ğ‘Ÿ represents the parametric overï¬‚ow properties. This for-
malizes a result similar to Bercea and Even [2019, Claim 21], which states that except with proba-
bility ğ›½, all crates have at most ğ‘‡ğ‘œğ‘£ğ‘’ğ‘Ÿ overfull pocket dictionaries. The core of the proof shows that
for every crate index ğ›¾, the counts ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ›½] are negatively associated, using the NegFrame
rule as in the array version of the Bloom ï¬lter example. Then, we show that vector ğ‘œğ‘£ğ‘’ğ‘Ÿ [ğ›¾] [ğ›½],
which indicates whether each pocket dictionary ğ›½ in crate ğ›¾ is overfull or not, is also negatively

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:26

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

associated. This holds because ğ‘œğ‘£ğ‘’ğ‘Ÿ [ğ›¾] [ğ›½] is obtained from ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ›½] by applying a monotone
function. Furthermore, the count of overï¬‚ows ğ‘œğ‘£ğ‘’ğ‘Ÿğ¶ğ‘¡ [ğ›¾] is obtained by another monotone func-
tion on ğ‘œğ‘£ğ‘’ğ‘Ÿ [ğ›¾] [ğ›½] and thus its entries are also negatively associated.

6.6 Repeated balls-into-bins process
Our ï¬nal example considers a probabilistic protocol proposed by Becchetti et al. [2019], imple-
mented as RepeatBIB in Figure 8b. Intuitively, the program implements a repeated balls-into-bins
process. Initially, ğ‘ balls are distributed among ğ‘ bins (ğ‘ğ‘¡ [ğ‘›]). For ğ‘… rounds, in each round a ball
is ï¬rst removed from every non-empty bin. Then, the ğ‘Ÿğ‘’ğ‘š removed balls are randomly reassigned
to bins. This process is useful for distributed protocols and scheduling algorithms, where the balls
represent tasks and the bins represent computation nodes. Becchetti et al. [2019] proposed and
analyzed this algorithm (e.g., bounding the maximum load, proving how long it takes for all balls
to visit all bins). We can verify the following lower-bound on the number of empty bins, analogous
to Becchetti et al. [2019, Lemma 1 and Lemma 2]:

ï£®
ï£¯
ï£¯
ï£¯
ï£¯
ï£°

ï£¹
ï£º
ï£º
ï£º
ï£º
ï£»

ğ‘

ğ‘ â‰¥ 2âˆ§

ğ‘ğ‘¡ [ğ›¼] âˆ¼ ğ‘

Ã•ğ›¼ =0

(

RepeatBIB

Pr

(

)

ğ‘…

Ãœğ›½=0

(ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ğ¶ğ‘¡ [ğ›½] < ğ‘ /15 âˆ’ ğ‘‡ (ğœŒğ‘’ğ‘šğ‘ğ‘¡ ğ‘¦, ğ‘ ))

â‰¤ ğ‘…Â·ğœŒğ‘’ğ‘šğ‘ğ‘¡ ğ‘¦

)

Two aspects of this program make it more diï¬ƒcult to verify. First, there is a loop with a ran-
domized guard: the number of removed balls ğ‘Ÿğ‘’ğ‘š is randomized quantity. Reasoning about such
loops is challenging, because our Loop rule is not directly applicable and only far weaker rules are
available for loops with general randomized guards. Becchetti et al. [2019] sidestep this problem
by conditioning on the number of balls in each bin, which also ï¬xes ğ‘Ÿğ‘’ğ‘š to be some value, prov-
ing the target property for every ï¬xed setting, and then combining the proofs together. LINA can
formalize this style of reasoning using the randomized case analysis rule (RCase) to condition on
ğ‘Ÿğ‘’ğ‘šâ€™s value, and then apply the Loop rule; however, the post-condition of RCase must be closed
under mixtures (CM), while independence and negative association are known not to satisfy this
side-condition. Thus, it is not possible to prove negative association by ï¬rst conditioning and then
combining. To work around this second problem, we use a technique from Becchetti et al. [2019]
and prove, on each conditional distribution, a high-probability bound using the Chernoï¬€ bound.
The beneï¬t of this approach is that high-probability bounds are CM, so we can apply RCase to com-
bine the results. In our view, the fact that LINA can handle this kind of subtle argument involving
conditioning is a strength of our approach.

7 RELATED WORK

Bunched implications. The logic of bunched implications (BI) [Oâ€™Hearn and Pym 1999; Pym 2002]
is a well-studied substructural logic. BI has a resource semantics [Pym et al. 2004], where states
are resources and the separating conjunction combines compatible resources together. We follow
Dochertyâ€™s uniform presentation and investigation of BI [Docherty 2019]; in particular, our neg-
ative association model relies on Dochertyâ€™s non-deterministic frame conditions, and we use his
duality-theoretic framework to establish ğ‘€-BIâ€™s metatheory.

Separation logics. The ï¬rst separation logic was developed to verify pointer-manipulating pro-
grams [Ishtiaq and Oâ€™Hearn 2001; Oâ€™Hearn et al. 2001; Reynolds 2001]. There is long line of work
on separation logic for concurrency, starting from [Brookes 2007; Oâ€™Hearn 2007] and continuing
to the present day (e.g., [Jung et al. 2018; Sergey et al. 2015]).

More recently, separation logics have been developed for probabilistic programs. LINA is an
extension of PSL [Barthe et al. 2020], a separation logic for probabilistic independence. Bao et al.

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:27

[2021] propose DIBI, an extension of BI with a non-commutative conjunction, and developed a
program logic with DIBI assertions that is capable of proving conditional independence. Batz et al.
[2019] propose QSL, a separation logic where assertions have a quantitative interpretation, and
used their logic to verify probabilistic and heap-manipulating programs. Tassarotti and Harper
[2019] develop a separation logic for relational reasoning about probabilistic programs, using the
coupling approach of pRHL [Barthe et al. 2012].

Verifying approximate data structures and applying concentration bounds. Bloom ï¬lters are a data
structure supporting approximate membership queries (AMQs). Ceramist [Gopinathan and Sergey
2020] is a recent framework for verifying hash-based AMQ structures in the Coq theorem prover.
Besides handling Bloom ï¬lters, Ceramist supports subtle proofs of correctness for many other
AMQs. Compared with our approach, Ceramist proofs are more precise but also more intricate,
applying theorems about Stirling numbers to achieve a precise bound on the false positive prob-
ability. In contrast, our approach reasons about negative dependence to achieve a substantially
simpler proof, albeit with less precise bounds.

Prior works in veriï¬cation have also applied the Chernoï¬€ bound to bound sums of indepen-
dent random quantities (e.g., [Chakarov and Sankaranarayanan 2013; Wang et al. 2021]). While
independence is easier to establish, the negative association property that we need is more subtle.

Negative dependence. There are multiple deï¬nitions of negative dependence in the literature,

each with their own strengths and weaknesses. We work with negative association (NA) [Dubhashi and Ranjan
1998; Joag-Dev and Proschan 1983], because it holds in many situations where negative depen-
dence should hold and it is closed under various notions of composition. Recently, the notion of
Strong Rayleigh (SR) [Borcea et al. 2009] distribution has been proposed as an ideal deï¬nition of
negative dependence. The SR condition satisï¬es more closure properties than NA does; in partic-
ular, it is preserved under various forms of conditioning. However, SR distributions have mostly
been studied for Boolean variables only, and we do not know if an analogue of the monotone maps
property of NA holds for SR.

Beyond theoretical investigations, negative dependence plays a useful role in many practical
applications. In machine learning, negative dependence can help ensure diversity in predictions
by a model [Kulesza and Taskar 2012], and fast algorithms are known to learn and sample from
negatively-dependent distributions [Anari et al. 2016]. In algorithm design, negative dependence is
a useful tool to randomly round solutions of linear programs to integral solutions [Srinivasan 2001].
Negative dependence can ensure that certain constraints are satisï¬ed exactly after rounding, while
still allowing concentration bounds to be applied to analyze the quality of the rounded solution.

8 CONCLUSION AND FUTURE DIRECTION
We introduced LINA, a probabilistic program logic that can reason about independence and nega-
tive association. Assertions in LINA are based on a novel probabilistic model of ğ‘€-BI, an extension
of the logic of Bunched Implications with multiple separating conjunctions. We demonstrated how
to use LINA to reason about probabilistic hashing schemes, and a repeated balls-into-bins process.
There are several natural directions for future work.

Other models of ğ‘€-BI, and non-deterministic frames. The assertion logic ğ‘€-BI was primarily
motivated by our NA model, but it is general enough that we believe there are likely other natural
models. Exploring these directions could allow modeling ï¬ner notions of separation, and could
further justify ğ‘€-BI as an interesting logic in its own right. It would also be interesting to see if
there are other models that use a non-deterministic operator to combine resources, as proposed
by Docherty [2019].

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:28

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

Verifying negative association for sampling algorithms. We used NA to analyze probabilistic hash-
ing schemes. Another classical application of NA is in sampling schemes, which generate a sam-
ple from a target distribution while satisfying certain constraints [BrÃ¤ndÃ©n and Jonasson 2012;
Dubhashi et al. 2007]. NA samplers are useful in algorithm design [Srinivasan 2001] and statistics,
and it would be interesting to understand how to verify these programs. Many samplers employ
rejection sampling, which is not easily analyzed in LINA but which could be expressed with an
explicit conditioning operator, as in probabilistic programming languages [Gordon et al. 2014].

ACKNOWLEDGMENTS

We thank the anonymous reviewers for their helpful feedback and suggestions. This work bene-
ï¬ted from discussions with Simon Docherty. This work was supported in part by the NSF under
Grant No. 2035314, 1943130, 2040249, 2040222 and 2152831.

REFERENCES
Nima Anari, Shayan Oveis Gharan, and Alireza Rezaei. 2016.

Monte Carlo Markov chain algorithms for
sampling Strongly Rayleigh distributions and determinantal point processes.
In Conference on Computational
Learning Theory (COLT), Vol. 49. Proceedings of Machine Learning Research, New York, New York, 103â€“115.
http://proceedings.mlr.press/v49/anari16.html

Jialu Bao, Simon Docherty, Justin Hsu, and Alexandra Silva. 2021. A Bunched logic for conditional independence. In IEEE
Symposium on Logic in Computer Science (LICS). IEEE, Rome, Italy, 1â€“14. https://doi.org/10.1109/LICS52264.2021.9470712
Probabilistic relational Hoare logics for
computer-aided security Proofs. In Mathematics of Program Construction (MPC). Springer, Madrid, Spain, 1â€“6.
https://doi.org/10.1007/978-3-642-31113-0_1

Gilles Barthe, Benjamin GrÃ©goire, and Santiago Zanella BÃ©guelin. 2012.

Gilles Barthe, Justin Hsu, and Kevin Liao. 2020. A probabilistic separation logic. Proceedings of the ACM on Programming

Languages 4, POPL (2020), 55:1â€“55:30. https://doi.org/10.1145/3371123

Kevin Batz, Benjamin Lucien Kaminski, Joost-Pieter Katoen, Christoph Matheja, and Thomas Noll. 2019. Quantitative
separation logic: a logic for reasoning about probabilistic pointer programs. Proceedings of the ACM on Programming
Languages 3, POPL (2019), 34:1â€“34:29. https://doi.org/10.1145/3290347

Luca Becchetti, Andrea Clementi, Emanuele Natale, Francesco Pasquale, and Gustavo Posta. 2019. Self-stabilizing repeated

balls-into-bins. Distributed Computing 32, 1 (2019), 59â€“68. https://doi.org/10.1007/s00446-017-0320-4

Ioana O. Bercea and Guy Even. 2019. Fully-dynamic space-eï¬ƒcient dictionaries and ï¬lters with constant number of memory

accesses. CoRR abs/1911.05060 (2019). http://arxiv.org/abs/1911.05060

Burton H. Bloom. 1970. Space/time trade-oï¬€s in hash coding with allowable errors. Commun. ACM 13, 7 (1970), 422â€“426.

https://doi.org/10.1145/362686.362692

Julius Borcea, Petter BrÃ¤ndÃ©n,
ometry of polynomials.
https://www.ams.org/journals/jams/2009-22-02/S0894-0347-08-00618-8/

and Thomas M. Liggett.
Journal

2009.

the American Mathematical

of

Negative dependence

Society

22,

2

and the ge-
521â€“567.

(2009),

Prosenjit Bose, Hua Guo, Evangelos Kranakis, Anil Maheshwari, Pat Morin, Jason Morrison, Michiel Smid, and Yi-
Inform. Process. Lett. 108, 4 (2008), 210â€“213.

On the false-positive rate of Bloom ï¬lters.

hui Tang. 2008.
https://doi.org/10.1016/j.ipl.2008.05.018

Petter BrÃ¤ndÃ©n and Johan Jonasson. 2012. Negative dependence in sampling. Scandinavian Journal of Statistics 39, 4 (2012),

830â€“838. https://doi.org/10.1111/j.1467-9469.2011.00766.x

Stephen Brookes. 2007. A semantics for concurrent separation logic. Theoretical Computer Science 375, 1â€“3 (2007), 227â€“270.

https://doi.org/10.1016/j.tcs.2006.12.034

Aleksandar Chakarov and Sriram Sankaranarayanan. 2013.

Probabilistic program analysis with martingales.
In International Conference on Computer Aided Veriï¬cation (CAV). Springer, Saint Petersburg, Russia, 511â€“526.
https://doi.org/10.1007/978-3-642-39799-8_34

Bolin Ding and Arnd Christian KÃ¶nig. 2011. Fast set intersection in memory. Proceedings of the VLDB Endowment 4, 4

(2011), 255â€“266. https://doi.org/10.14778/1938545.1938550

Simon Docherty. 2019. Bunched logics: a uniform approach. Ph.D. Dissertation. UCL (University College London).
Devdatt P. Dubhashi, Johan Jonasson, and Desh Ranjan. 2007. Positive inï¬‚uence and negative dependence. Combinatorics,

Probability and Computing 16, 1 (2007), 29â€“41. https://doi.org/10.1017/S0963548306007772

Devdatt P. Dubhashi and Desh Ranjan. 1998. Balls and bins: A study in negative dependence. Random Structures and
Algorithms 13, 2 (1998), 99â€“124. https://doi.org/10.1002/(SICI)1098-2418(199809)13:2\<99::AID-RSA1\>3.0.CO;2-M

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:29

Kiran Gopinathan and Ilya Sergey. 2020. Certifying certainty and uncertainty in approximate membership query structures.
In International Conference on Computer Aided Veriï¬cation (CAV) (Lecture Notes in Computer Science, Vol. 12225). Springer,
Los Angeles, California, 279â€“303. https://doi.org/10.1007/978-3-030-53291-8_16

Andrew D. Gordon, Thomas A. Henzinger, Aditya V. Nori, and Sriram K. Rajamani. 2014. Probabilistic programming. In
Future of Software Engineering Proceedings (FOSE). Hyderabad, India, 167â€”-181. https://doi.org/10.1145/2593882.2593900
In
ACM SIGPLANâ€“SIGACT Symposium on Principles of Programming Languages (POPL). London, England, 14â€“26.
https://doi.org/10.1145/360204.375719

BI as an assertion language for mutable data structures.

Samin Ishtiaq and Peter W. Oâ€™Hearn. 2001.

Kumar Joag-Dev and Frank Proschan. 1983. Negative association of random variables with applications. The Annals of

Statistics 11, 1 (1983), 286â€“295. https://doi.org/10.1214/aos/1176346079

Ralf Jung, Robbert Krebbers, Jacques-Henri Jourdan, Ales Bizjak, Lars Birkedal, and Derek Dreyer. 2018.

Iris from the
ground up: A modular foundation for higher-order concurrent separation logic. Journal of Functional Programming 28
(2018), e20. https://doi.org/10.1017/S0956796818000151

Dexter Kozen. 1981.

Semantics of probabilistic programs.

J. Comput. System Sci. 22, 3 (1981), 328â€“350.

https://doi.org/10.1016/0022-0000(81)90036-2

Alex Kulesza and Ben Taskar. 2012. Determinantal point processes for machine learning. Foundations and Trends in Machine

Learning 5, 2-3 (2012), 123â€“286. https://doi.org/10.1561/2200000044

Michael Mitzenmacher and Eli Upfal. 2005. Probability and computing - randomized algorithms and probabilistic analysis.

Cambridge University Press.

Peter W. Oâ€™Hearn. 2007. Resources, concurrency, and local reasoning. Theoretical Computer Science 375, 1â€“3 (2007), 271â€“307.

https://doi.org/10.1016/j.tcs.2006.12.035

Peter W. Oâ€™Hearn and David J. Pym. 1999. The logic of bunched implications. Bulletin of Symbolic Logic (1999), 215â€“244.

https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.27.4742&rep=rep1&type=pdf

Peter W. Oâ€™Hearn, John C. Reynolds, and Hongseok Yang. 2001. Local reasoning about programs that alter data structures.
In International Conference on Computer Science Logic (CSL) (Lecture Notes in Computer Science, Vol. 2142). Springer, Paris,
France, 1â€“19. https://doi.org/10.1007/3-540-44802-0_1

Jens Pagel and Florian Zuleger. 2021. Strong-Separation Logic. In European Symposium on Programming (ESOP), Lux-
embourg City, Luxembourg (Lecture Notes in Computer Science, Vol. 12648), Nobuko Yoshida (Ed.). Springer, 664â€“692.
https://doi.org/10.1007/978-3-030-72019-3_24

Robin Pemantle. 2000.

Towards a theory of negative dependence.

J. Math. Phys. 41, 3 (2000), 1371â€“1390.

David J. Pym.

https://doi.org/10.1063/1.533200
The
plied Logic Series, Vol. 26.
http://www.cantab.net/users/david.pym/BI-monograph-errata.pdf .

Kluwer Academic Publishers.

semantics and

2002.

proof

theory of

the

logic
of Bunched implications. Ap-
Errata and Remarks maintained at:

David J. Pym, Peter W. Oâ€™Hearn, and Hongseok Yang. 2004. Possible worlds and resources: The semantics of BI. Theoretical

Computer Science 315, 1 (2004), 257â€“305. https://www.sciencedirect.com/science/article/pii/S0304397503006248

John C. Reynolds. 2001. Intuitionistic reasoning about shared mutable data structure. Millennial Perspectives in Computer
Science 2, 1 (2001), 303â€“321. https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.11.5999&rep=rep1&type=pdf
Ilya Sergey, Aleksandar Nanevski, and Anindya Banerjee. 2015. Mechanized veriï¬cation of ï¬ne-grained concurrent pro-
grams. In ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI). ACM Press, Portland,
Oregon, 77â€“87. https://doi.org/10.1145/2737924.2737964

Aravind Srinivasan. 2001. Distributions on level-sets with applications to approximation algorithms. In IEEE Symposium on
Foundations of Computer Science (FOCS). IEEE, Las Vegas, Nevada, 588â€“597. https://doi.org/10.1109/SFCS.2001.959935
Joseph Tassarotti and Robert Harper. 2019. A separation logic for concurrent randomized programs. Proceedings of the

ACM on Programming Languages 3, POPL (2019), 64:1â€“64:30. https://doi.org/10.1145/3290377

Jinyi Wang, Yican Sun, Hongfei Fu, Krishnendu Chatterjee, and Amir Kafshdar Goharshady. 2021. Quantitative analysis
of assertion violations in probabilistic programs. In ACM SIGPLAN Conference on Programming Language Design and
Implementation (PLDI). ACM Press, Virtual, 1171â€“1186. https://doi.org/10.1145/3453483.3454102

A PRELIMINARIES

Lemma A.1. Say S = {ğ‘†ğ‘– | 1 â‰¤ ğ‘– â‰¤ ğ‘ } where ğ‘†ğ‘– are disjoint, ğ‘† = âˆªS and ğœ‡ âˆˆ Mem[ğ‘†],

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:30

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

Then, ğ‘†ğ‘– are independent in ğœ‡ if and only if for any family of all monotone or all antitone functions

ğ‘“ğ‘– : Mem[ğ‘†ğ‘–] â†’ R+,

Eğ‘¥âˆ¼ğœ‡

"

Ã–ğ‘†ğ‘– âˆˆS

ğ‘“ğ‘– (pğ‘†ğ‘– ğ‘¥)

=

#

Ã–ğ‘†ğ‘– âˆˆS

Eğ‘¥ âˆˆğœ‡ [ğ‘“ğ‘– (pğ‘†ğ‘– ğ‘¥)].

(4)

Proof. The forward direction is straightforward. The backward direction needs more careful
analysis. In general, zero correlation does not imply independence, but here, we have the equality
for all family of monotone or antitone functions, so that suï¬ƒces for independence.

We prove by induction on T = {ğ‘†ğ‘– | 1 â‰¤ ğ‘– â‰¤ ğ¾ } that for any family of ğ‘£ğ‘– âˆˆ Mem[ğ‘†ğ‘– ],

pğ‘†ğ‘– ğ‘¥ = ğ‘£ğ‘–

âˆ§

!

Eğ‘¥ âˆˆğœ‡

Ã›ğ‘†ğ‘– âˆˆT

ï£®
ï£¯
ï£¯
ï£¯
ï£¯
ï£°

pğ‘†ğ‘– ğ‘¥ < ğ‘£ğ‘–

=

Eğ‘¥ âˆˆğœ‡

pğ‘†ğ‘– ğ‘¥ = ğ‘£ğ‘–

Â·

Eğ‘¥ âˆˆğœ‡

pğ‘†ğ‘– ğ‘¥ < ğ‘£ğ‘–

.

Ã›ğ‘†ğ‘– âˆˆS\T
Â©

Â«

ï£¹
ï£º
ï£º
ï£º
ï£º
ï£»

Âª
Â®
Â¬

Ã–ğ‘†ğ‘– âˆˆT

(cid:2)

Ã–ğ‘†ğ‘– âˆˆS\T

(cid:3)

(cid:2)

(cid:3)

(5)

Case |T | = 1: Say T = {ğ‘† ğ‘— }. Since indicator functions ğ‘†ğ‘– < ğ‘£ğ‘– and ğ‘†ğ‘– â‰¤ ğ‘£ğ‘– are both monotoni-

cally decreasing,

Eğ‘¥ âˆˆğœ‡

pğ‘† ğ‘— ğ‘¥ = ğ‘£ ğ‘— âˆ§ (

pğ‘†ğ‘– ğ‘¥ < ğ‘£ğ‘– )

ï£®
ï£¯
ï£¯
ï£¯
ï£¯
= Eğ‘¥ âˆˆğœ‡
ï£°

= Eğ‘¥ âˆˆğœ‡

Ã›ğ‘†ğ‘– âˆˆS\T

pğ‘† ğ‘— ğ‘¥ â‰¤ ğ‘£ ğ‘— âˆ§ (

ï£¹
ï£º
ï£º
ï£º
ï£º
ï£»

pğ‘†ğ‘– ğ‘¥ < ğ‘£ğ‘– )

âˆ’ Eğ‘¥ âˆˆğœ‡

pğ‘† ğ‘— ğ‘¥ < ğ‘£ ğ‘— âˆ§ (

pğ‘†ğ‘– ğ‘¥ < ğ‘£ğ‘–)

ï£®
ï£¯
ï£¯
pğ‘† ğ‘— ğ‘¥ â‰¤ ğ‘£ ğ‘—
ï£¯
ï£¯
ï£°
(cid:2)

(cid:3)

Â·

Ã›ğ‘†ğ‘– âˆˆS\T

Eğ‘¥ âˆˆğœ‡

Ã–ğ‘†ğ‘– âˆˆS\T

(cid:2)

ï£¹
ï£º
ï£º
pğ‘†ğ‘– ğ‘¥ < ğ‘£ğ‘–
ï£º
ï£º
ï£»

ï£®
ï£¯
ï£¯
âˆ’ Eğ‘¥ âˆˆğœ‡
ï£¯
ï£¯
ï£°

(cid:3)

(cid:2)

Ã›ğ‘†ğ‘– âˆˆS\T
Â·

pğ‘† ğ‘— ğ‘¥ < ğ‘£ ğ‘—

Eğ‘¥ âˆˆğœ‡

ï£¹
ï£º
ï£º
pğ‘†ğ‘– ğ‘¥ < ğ‘£ğ‘–
ï£º
ï£º
ï£»

Ã–ğ‘†ğ‘– âˆˆS\T

(cid:3)

(cid:2)

(By Equation (4))

(cid:3)

= (Eğ‘¥ âˆˆğœ‡

pğ‘† ğ‘— ğ‘¥ â‰¤ ğ‘£ ğ‘—

âˆ’ Eğ‘¥ âˆˆğœ‡

pğ‘† ğ‘— ğ‘¥ < ğ‘£ ğ‘—

) Â·

Eğ‘¥ âˆˆğœ‡

pğ‘†ğ‘– ğ‘¥ < ğ‘£ğ‘–

= Eğ‘¥ âˆˆğœ‡

(cid:2)
pğ‘† ğ‘— ğ‘¥ = ğ‘£ ğ‘—

(cid:3)
Â·

(cid:2)
Eğ‘¥ âˆˆğœ‡

Ã–ğ‘†ğ‘– âˆˆS\T

(cid:3)
pğ‘†ğ‘– ğ‘¥ < ğ‘£ğ‘–

(cid:2)

Ã–ğ‘†ğ‘– âˆˆS\T

(cid:3)

(cid:2)

(cid:3)

(cid:2)

(cid:3)

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

 
 
A Separation Logic for Negative Dependence

57:31

Case |T | > 1 Let ğ‘† ğ‘— be an element in T .

Eğ‘¥ âˆˆğœ‡

(

pğ‘†ğ‘– ğ‘¥ = ğ‘£ğ‘– ) âˆ§ (

pğ‘†ğ‘– ğ‘¥ < ğ‘£ğ‘–)

Ã›ğ‘†ğ‘– âˆˆT

ï£®
ï£¯
ï£¯
ï£¯
ï£¯
= Eğ‘¥ âˆˆğœ‡
ï£°

pğ‘† ğ‘— ğ‘¥ â‰¤ ğ‘£ ğ‘— âˆ§ (
ï£®
ï£¯
ï£¯
ï£¯
ï£¯
pğ‘† ğ‘— ğ‘¥ < ğ‘£ ğ‘— âˆ§ (
ï£°
ï£®
ï£¯
ï£¯
ï£¯
ï£¯
ï£°
(cid:2)
pğ‘† ğ‘— ğ‘¥ < ğ‘£ ğ‘—

pğ‘† ğ‘— ğ‘¥ â‰¤ ğ‘£ ğ‘—

(cid:3)

Â·

Â·

âˆ’ Eğ‘¥ âˆˆğœ‡

= Eğ‘¥ âˆˆğœ‡

âˆ’ Eğ‘¥ âˆˆğœ‡

Ã›ğ‘†ğ‘– âˆˆS\T

ï£¹
ï£º
ï£º
ï£º
ï£º
ï£»

pğ‘†ğ‘– ğ‘¥ = ğ‘£ğ‘– ) âˆ§ (

pğ‘†ğ‘– ğ‘¥ < ğ‘£ğ‘– )

Ã›ğ‘†ğ‘– âˆˆT\{ğ‘† ğ‘— }

Ã›ğ‘†ğ‘– âˆˆS\T

pğ‘†ğ‘– ğ‘¥ = ğ‘£ğ‘– ) âˆ§ (

Ã›ğ‘†ğ‘– âˆˆT\{ğ‘† ğ‘— }

Ã›ğ‘†ğ‘– âˆˆS\T
Â·

pğ‘†ğ‘– ğ‘¥ = ğ‘£ğ‘–

Eğ‘¥ âˆˆğœ‡

Ã–ğ‘†ğ‘– âˆˆT\{ğ‘† ğ‘— }

(cid:2)
pğ‘†ğ‘– ğ‘¥ = ğ‘£ğ‘–

(cid:3)

Eğ‘¥ âˆˆğœ‡

pğ‘†ğ‘– ğ‘¥ = ğ‘£ğ‘–

Eğ‘¥ âˆˆğœ‡

(cid:2)

(cid:2)

(cid:3)

(cid:3)

Â·

Â·

Ã–ğ‘†ğ‘– âˆˆS\T

Ã–ğ‘†ğ‘– âˆˆS\T

Ã–ğ‘†ğ‘– âˆˆS\T

pğ‘†ğ‘– ğ‘¥ < ğ‘£ğ‘– )

ï£¹
ï£º
ï£º
ï£º
ï£º
ï£»
ï£¹
ï£º
ï£º
pğ‘†ğ‘– ğ‘¥ < ğ‘£ğ‘–
ï£º
ï£º
ï£»
(cid:2)
pğ‘†ğ‘– ğ‘¥ < ğ‘£ğ‘–

pğ‘†ğ‘– ğ‘¥ < ğ‘£ğ‘–

(cid:2)

(cid:2)

(cid:3)

(cid:3)

(cid:3)

Eğ‘¥ âˆˆğœ‡

Eğ‘¥ âˆˆğœ‡

Eğ‘¥ âˆˆğœ‡

(cid:2)

= Eğ‘¥ âˆˆğœ‡

pğ‘† ğ‘— ğ‘¥ = ğ‘£ ğ‘—

(cid:3)

Â·

Ã–ğ‘†ğ‘– âˆˆT\{ğ‘† ğ‘— }

When T = S, Equation (5) implies

(cid:2)

Ã–ğ‘†ğ‘– âˆˆT\{ğ‘† ğ‘— }

(cid:3)

Eğ‘¥ âˆˆğœ‡

pğ‘†ğ‘– ğ‘¥ = ğ‘£ğ‘–

=

Eğ‘¥ âˆˆğœ‡

pğ‘†ğ‘– ğ‘¥ = ğ‘£ğ‘–

Ã–ğ‘†ğ‘– âˆˆS
for any ğ‘£ğ‘–â€™s. Thus, components in S are independent.

"
Ã›ğ‘†ğ‘– âˆˆS

#

(cid:2)

(cid:3)

(cid:3)

A.1 Coarsening

We prove some properties of coarsening. In the following we will use an alternative deï¬nition of
coarsening, which will be shown to be equivalent to what we deï¬ne in the main text.

Deï¬nition A.2 (Alternative deï¬nition of coarsening). We ï¬rst index any partition S as S1, . . . , S|S | .
Say |Sâ€²| = ğ‘š, |S| = ğ‘›. We say Sâ€² coarsens a partition S there exists a function a ğ‘“ : [ğ‘š] â†’ P ( [ğ‘›])
such that 1) âˆªğ‘– âˆˆ[ğ‘š] ğ‘“ (ğ‘–) = [ğ‘›]; 2) for any ğ‘–, ğ‘— âˆˆ [ğ‘š], either ğ‘– = ğ‘— or ğ‘“ (ğ‘–), ğ‘“ ( ğ‘— ) are disjoint; 3)
Sâ€² = {âˆª{Sğ‘—

| ğ‘— âˆˆ ğ‘“ (ğ‘–)} | ğ‘– âˆˆ [ğ‘š]}.

Lemma A.3. Let S, Sâ€² be two partitions. Then Sâ€² coarsens S according to Deï¬nition A.2 if and

only if Sâ€² coarsens S according to Deï¬nition 4.6 .
Proof. We index S as S1, . . . , Sğ‘› and Sâ€² as Sâ€²
Backward direction: By that deï¬nition, we know a) for any Sâ€²

1, . . . , Sâ€²

|ğ‘š | .

b) âˆªS = âˆªSâ€².

ğ‘– âˆˆ Sâ€², Sâ€²
ğ‘–

= âˆªR for some R âŠ† S;

We deï¬ne the function ğ‘” : [ğ‘š] â†’ P ( [ğ‘›]) as ğ‘”(ğ‘–) = { ğ‘— | Sğ‘— âŠ† Sâ€²

ğ‘– }. This ğ‘” would satisï¬es all the

conditions required:

(1) By substitution, âˆªğ‘– âˆˆ[ğ‘š]ğ‘”(ğ‘–) = âˆªğ‘– âˆˆ[ğ‘š] { ğ‘—

| Sğ‘— âŠ† ğ‘  â€²}. By b), for any
| Sğ‘— âŠ† Sâ€²
ğ‘— âˆˆ [ğ‘›], Sğ‘— âŠ† âˆªSâ€². Then by a) and that S is a partition, if ğ‘  â€² covers any of Sğ‘— , it must
covers all of Sğ‘— , then Sğ‘— âŠ† âˆªSâ€² implies there exists ğ‘  â€² âˆˆ Sâ€² such that Sğ‘— âŠ† ğ‘  â€². Thus,
ğ‘— âˆˆ { ğ‘— | Sğ‘— âŠ† ğ‘  â€²} âŠ† âˆªğ‘ â€² âˆˆSâ€² { ğ‘— | Sğ‘— âŠ† ğ‘  â€²}. For any ğ‘— âˆ‰ [ğ‘›], Sğ‘— is undeï¬ned, so it is impossible
that Sğ‘— âŠ† ğ‘  â€² for some ğ‘  â€² âŠ† Sâ€². Therefore, âˆªğ‘ â€² âˆˆSâ€² { ğ‘— | Sğ‘— âŠ† ğ‘  â€²} = [ğ‘›].
ğ‘– . If ğ‘– â‰  ğ‘— , then Sâ€²
ğ‘— , and ğ‘˜ âˆ‰ ğ‘”( ğ‘— ). So for any ğ‘– â‰  ğ‘— , ğ‘”(ğ‘–), ğ‘”( ğ‘— ) are disjoint.

ğ‘— are disjoint since Sâ€² is a partition. Thus,

(2) For any ğ‘˜ âˆˆ ğ‘”(ğ‘–), Sğ‘˜ âŠ† Sâ€²

ğ‘– } = âˆªğ‘ â€² âˆˆSâ€² { ğ‘—

ğ‘– and Sâ€²

Sğ‘˜ * Sâ€²

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:32

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

(3) By substitution,

{âˆª{Sğ‘—

| ğ‘— âˆˆ ğ‘”(ğ‘–)} | ğ‘– âˆˆ [ğ‘š]} = {âˆª{Sğ‘—

| Sğ‘— âŠ† Sâ€²

ğ‘– } | ğ‘– âˆˆ [ğ‘š]} = {âˆª{Sğ‘—

| Sğ‘— âŠ† ğ‘  â€²} | ğ‘  â€² âˆˆ Sâ€²}.

Again, by a) and that S is a partition, if ğ‘  â€² âˆˆ S covers any part of of Sğ‘— , it must covers all of
Sğ‘— , so âˆª{Sğ‘—

| Sğ‘— âŠ† ğ‘  â€²} = ğ‘  â€². Thus, {âˆª{Sğ‘—

| Sğ‘— âŠ† ğ‘  â€²} | ğ‘  â€² âˆˆ Sâ€²} = Sâ€².

Forward direction: By 3), we know that Sâ€² = {âˆª{Sğ‘—

ğ‘– âˆˆ Sâ€²,
ğ‘— âˆˆ ğ‘“ (ğ‘–)}, which is a subset of Sâ€² by construction. So we proved a). Also,
| ğ‘— âˆˆ ğ‘“ (ğ‘–) | ğ‘– âˆˆ [ğ‘š]}, and by 1), that is equivalent to

| ğ‘— âˆˆ ğ‘“ (ğ‘–)} | ğ‘– âˆˆ [ğ‘š]}. So for any Sâ€²

we have ğ‘  â€² = âˆª{Sğ‘—
âˆªSâ€² = âˆª{âˆª{Sğ‘—
âˆª{Sğ‘—

| ğ‘— âˆˆ ğ‘“ (ğ‘–)} | ğ‘– âˆˆ [ğ‘š]} = âˆª{Sğ‘—
| ğ‘— âˆˆ [ğ‘›]}, which is equivalent to âˆªS.

|

(cid:3)

We can prove that coarsening commute with projections.

Lemma A.4. Given a partition S = {Sğ‘– }ğ‘– and a set ğ‘‹ , let Sğ‘‹ = {Sğ‘– âˆ© ğ‘‹ | Sğ‘– âˆˆ S}. For any T
coarsening Sğ‘‹ , there exists a coarsening Sâ€² of S such that T = {Sğ‘– âˆ© ğ‘‹ | Sğ‘– âˆˆ Sâ€²}; conversely, for
any Sâ€² coarsening S, and Sâ€²
ğ‘‹

= {Sğ‘– âˆ© ğ‘‹ | Sğ‘– âˆˆ Sâ€²}, we have Sâ€²

ğ‘‹ coarsens Sğ‘‹ .

Proof. Forward direction: By Deï¬nition A.2, there exists a coarsening function ğ‘“ such that

T = {âˆª{(Sğ‘‹ ) ğ‘—

| ğ‘— âˆˆ ğ‘“ (ğ‘–)} | ğ‘– âˆˆ [|T |]}
= {âˆª{Sğ‘— âˆ© ğ‘‹ | ğ‘— âˆˆ ğ‘“ (ğ‘–)} | ğ‘– âˆˆ [|T |]}
= {(âˆª{Sğ‘—
= {ğ‘† â€² âˆ© ğ‘‹ | ğ‘† â€² âˆˆ Sâ€²}

| ğ‘— âˆˆ ğ‘“ (ğ‘–)}) âˆ© ğ‘‹ | ğ‘– âˆˆ [|T |]}

(where Sâ€² = {âˆª{Sğ‘—

| ğ‘— âˆˆ ğ‘“ (ğ‘–)} | ğ‘– âˆˆ [|T |]})

Sâ€² has the same size as T , so Sâ€² = {âˆª{Sğ‘—

| ğ‘— âˆˆ ğ‘“ (ğ‘–)} | ğ‘– âˆˆ [|Sâ€²|]}, and thus Sâ€² coarsens S.

Backward direction: Sâ€² coarsens S, so there exists a coarsening function ğ‘“ such that

Thus,

Sâ€² = {âˆª{ğ‘† ğ‘—

| ğ‘— âˆˆ ğ‘“ (ğ‘–)} | ğ‘– âˆˆ [|Sâ€²|]}.

Sâ€²
ğ‘‹ = {(âˆª{ğ‘† ğ‘—

| ğ‘— âˆˆ ğ‘“ (ğ‘–)}) âˆ© ğ‘‹ | ğ‘– âˆˆ [|Sâ€²|]}

= {âˆª{ğ‘† ğ‘— âˆ© ğ‘‹ | ğ‘— âˆˆ ğ‘“ (ğ‘–)} | ğ‘– âˆˆ [|Sâ€²|]}
= {âˆª{ğ‘†ğ‘‹ ğ‘—

| ğ‘— âˆˆ ğ‘“ (ğ‘–)} | ğ‘– âˆˆ [|Sâ€²|]}.

Therefore, Sâ€²

ğ‘‹ coarsens Sğ‘‹ .

(cid:3)

B THE LOGIC ğ‘€-BI
Figure 9 gives a Hilbert-style proof system for ğ‘€-BI. If one erases the subscripts on âˆ— and âˆ’âˆ—, then
the rules without the last three form a Hilbert proof system for BI.

Using the M-BI rules, we can derive the rule Cut:

ğ‘„ âŠ¢ ğ‘…
ğ‘ƒ âˆ§ ğ‘„ âŠ¢ ğ‘…
ğ‘ƒ âŠ¢ ğ‘„ â†’ ğ‘…

ğ‘ƒ âŠ¢ ğ‘…

âˆ§2
â†’
Cut

ğ‘ƒ âŠ¢ ğ‘„

Lemma 3.1. The following rules are derivable in ğ‘€-BI:

ğ‘š1 â‰¤ ğ‘š2
ğ‘ƒ âˆ’âˆ—ğ‘š2 ğ‘„ âŠ¢ ğ‘ƒ âˆ’âˆ—ğ‘š1 ğ‘„

âˆ’âˆ—-Weakening

ğ‘š1 â‰¤ ğ‘š2
ğ¼ğ‘š2 âŠ¢ ğ¼ğ‘š1

UnitWeakening

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:33

ğ‘ƒ âŠ¢ ğ‘ƒ

âŠ¤

ğ‘ƒ âŠ¢ âŠ¤

âŠ¥

âŠ¥ âŠ¢ ğ‘ƒ

ğ‘ƒ âŠ¢ ğ‘…

ğ‘„ âŠ¢ ğ‘…

ğ‘ƒ âˆ¨ ğ‘„ âŠ¢ ğ‘…

âˆ¨-E

ğ‘ƒ âŠ¢ ğ‘„ğ‘–
ğ‘ƒ âŠ¢ ğ‘„1 âˆ¨ ğ‘„2

âˆ¨-I

ğ‘ƒ âŠ¢ ğ‘„

ğ‘ƒ âŠ¢ ğ‘…

ğ‘ƒ âŠ¢ ğ‘„ âˆ§ ğ‘…

âˆ§-I1

ğ‘„ âŠ¢ ğ‘…

ğ‘ƒ âˆ§ ğ‘„ âŠ¢ ğ‘…

âˆ§-I2

ğ‘ƒ âŠ¢ ğ‘„1 âˆ§ ğ‘„2
ğ‘ƒ âŠ¢ ğ‘„ğ‘–

âˆ§-E

ğ‘ƒ âˆ§ ğ‘„ âŠ¢ ğ‘…

ğ‘ƒ âŠ¢ ğ‘„ â†’ ğ‘…

â†’-I

ğ‘ƒ âŠ¢ ğ‘„ â†’ ğ‘…

ğ‘ƒ âŠ¢ ğ‘„

ğ‘ƒ âŠ¢ ğ‘…

â†’-E

ğ‘ƒ âˆ—ğ‘š ğ‘„ âŠ¢ ğ‘…
ğ‘ƒ âŠ¢ ğ‘„ âˆ’âˆ—ğ‘š ğ‘…

âˆ’âˆ—

ğ‘ƒ âŠ¢ ğ‘„ âˆ’âˆ—ğ‘š ğ‘…

ğ‘† âŠ¢ ğ‘„

ğ‘ƒ âˆ—ğ‘š ğ‘† âŠ¢ ğ‘…

âˆ’âˆ—-E

ğ‘ƒ âŠ£âŠ¢ ğ‘ƒ âˆ—ğ‘š ğ¼ğ‘š

âˆ—-Unit

ğ‘ƒ âŠ¢ ğ‘…
ğ‘„ âŠ¢ ğ‘†
ğ‘ƒ âˆ—ğ‘š ğ‘„ âŠ¢ ğ‘… âˆ—ğ‘š ğ‘†

âˆ—-Conj

ğ‘ƒ âˆ—ğ‘š ğ‘„ âŠ¢ ğ‘„ âˆ—ğ‘š ğ‘ƒ

âˆ—-Comm

(ğ‘ƒ âˆ—ğ‘š ğ‘„) âˆ—ğ‘š ğ‘… âŠ£âŠ¢ ğ‘ƒ âˆ—ğ‘š (ğ‘„ âˆ—ğ‘š ğ‘…)

âˆ—-Assoc

ğ‘š1 â‰¤ ğ‘š2
ğ‘ƒ âˆ—ğ‘š1 ğ‘„ âŠ¢ ğ‘ƒ âˆ—ğ‘š2 ğ‘„

âˆ—-Inclusion

Fig. 9. Hilbert system for ğ‘€-BI

Proof. Let ğ‘š1 â‰¤ ğ‘š2. For the ï¬rst rule, it suï¬ƒces to show that (ğ‘ƒ âˆ’âˆ—ğ‘š2 ğ‘„) âˆ—ğ‘š1 ğ‘ƒ âŠ¢ ğ‘„. By âˆ—-
Weakening, we have that (ğ‘ƒ âˆ’âˆ—ğ‘š2 ğ‘„) âˆ—ğ‘š1 ğ‘ƒ âŠ¢ (ğ‘ƒ âˆ’âˆ—ğ‘š2 ğ‘„) âˆ—ğ‘š2 ğ‘ƒ so the result follows from Cut
and âˆ’âˆ— âˆ’E.

For the second rule, âˆ—1-Unit implies ğ¼ğ‘š2 âŠ¢ ğ¼ğ‘š2 âˆ—ğ‘š1 ğ¼ğ‘š1 ; âˆ—-Weakening implies ğ¼ğ‘š2 âˆ—ğ‘š1 ğ¼ğ‘š1 âŠ¢
(cid:3)

ğ¼ğ‘š2 âˆ—ğ‘š2 ğ¼ğ‘š1 ; and âˆ—2-Unit implies ğ¼ğ‘š2 âˆ—ğ‘š2 ğ¼ğ‘š1 âŠ¢ ğ¼ğ‘š1 . Then by Cut, we have ğ¼ğ‘š2 âŠ¢ ğ¼ğ‘š1

C THE MODEL OF NEGATIVE DEPENDENCE AND INDEPENDENCE

C.1 A BI model for negative association

Theorem 4.9. For any two states ğœ‡1, ğœ‡2 âˆˆ ğ‘‹ , ğœ‡1 âŠ•ğ‘  ğœ‡2 âŠ† ğœ‡1 âŠ• ğœ‡2 âŠ† ğœ‡1 âŠ•ğ‘¤ ğœ‡2.

Proof. Let ğ‘† denote dom(ğœ‡1) and ğ‘‡ denote dom(ğœ‡2).
For any ğœ‡ âˆˆ ğœ‡1 âŠ•ğ‘  ğœ‡2, we have ğœ‹ğ‘† ğœ‡ = ğœ‡1, ğœ‹ğ‘‡ ğœ‡ = ğœ‡2, and ğœ‡ satisï¬es NA. ğœ‡ being NA implies
ğœ‡ is R-PNA for any partition R on dom(ğœ‡) So for any partition S on ğ‘†, partition T on ğ‘‡ , ğœ‡ is
S âˆª T -PNA. Therefore, ğœ‡ âˆˆ ğœ‡1 âŠ• ğœ‡2.

For any ğœ‡ âˆˆ ğœ‡1 âŠ• ğœ‡2, ğœ‹ğ‘† ğœ‡ = ğœ‡1, ğœ‹ğ‘‡ ğœ‡ = ğœ‡2, and ğœ‡ is {ğ‘†,ğ‘‡ }-PNA since ğœ‡1 is {ğ‘† }-PNA, ğœ‡2 is {ğ‘‡ }-PNA.
(cid:3)

Thus, ğœ‡ âˆˆ ğœ‡1 âŠ•ğ‘¤ ğœ‡2.

Theorem 4.11. The structure XPNA = (ğ‘‹, âŠ‘, âŠ•, ğ¸PNA) is a Down-Closed BI frame.

Proof. We sketch the conditions, using the notation from the deï¬nition:
Down-Closed. Let ğ‘‘ğ‘œğ‘š(ğ‘¥) = ğ‘†, ğ‘‘ğ‘œğ‘š(ğ‘¥ â€²) = ğ‘† â€², ğ‘‘ğ‘œğ‘š(ğ‘¦) = ğ‘‡ , ğ‘‘ğ‘œğ‘š(ğ‘¦â€²) = ğ‘‡ â€². We claim that we
can take ğ‘§â€² = ğœ‹ğ‘†â€²âˆªğ‘‡ â€²ğ‘§. We evidently have ğ‘§ âŠ’ ğ‘§â€², and ğœ‹ğ‘†â€²ğ‘§â€² = ğœ‹ğ‘†â€²ğœ‹ğ‘†ğ‘§ = ğ‘¥ â€² and ğœ‹ğ‘‡ â€²ğ‘§â€² =
ğœ‹ğ‘‡ â€²ğœ‹ğ‘‡ ğ‘§ = ğ‘¦â€².
What remains to show is that ğ‘§â€² is S âˆª T -PNA for any S, T such that ğ‘¥ â€² is S-PNA, ğ‘¦â€² is
T -PNA, and (âˆªS) âˆ© (âˆªT ) = âˆ….
If ğ‘¥ â€² is S-PNA, then ğ‘¥ is S-PNA; if ğ‘¦â€² is T -PNA, then ğ‘¦ is T -PNA; then ğ‘§ âˆˆ ğ‘¥ âŠ• ğ‘¦ must be
S âˆª T -PNA. Since ğ‘§â€² := ğœ‹ğ‘†â€²âˆªğ‘‡ â€²ğ‘§, and (âˆªS) âˆª (âˆªT ) âŠ† ğ‘† â€² âˆª ğ‘‡ â€², we have ğ‘§â€² is S âˆª T -PNA too.
And evidently, ğ‘‘ğ‘œğ‘š(ğ‘§â€²) = ğ‘† â€² âˆª ğ‘‡ â€² = ğ‘‘ğ‘œğ‘š(ğ‘¥ â€²) âˆª ğ‘‘ğ‘œğ‘š(ğ‘¦â€²). So ğ‘§â€² âˆˆ ğ‘¥ â€² âŠ• ğ‘¦â€².

Commutativity. Immediate.

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:34

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

Associativity. Let ğ‘‘ğ‘œğ‘š(ğ‘¥) = ğ‘…, ğ‘‘ğ‘œğ‘š(ğ‘¦) = ğ‘†, ğ‘‘ğ‘œğ‘š(ğ‘§) = ğ‘‡ . We can assume that these sets are
all disjoint, otherwise there is nothing to prove. We claim that we can take ğ‘  = ğœ‹ğ‘†âˆªğ‘‡ ğ‘¤. For
any ğ‘¤ in ğ‘¡ âŠ• ğ‘§, ğ‘¡ âˆˆ ğ‘¥ âŠ• ğ‘¦, we want to show that ğ‘¤ âˆˆ ğ‘¥ âŠ• ğ‘  and ğ‘  âˆˆ ğ‘¦ âŠ• ğ‘§.
â€¢ For any partition R, S such that (âˆªR) âˆ© (âˆªS) = âˆ… and ğ‘¥ is R-PNA, ğ‘  is S-PNA. For set
ğ‘‹ âˆˆ Var, write {ğ‘Œ âˆ© ğ‘‹ | ğ‘Œ âˆˆ S} as Sğ‘‹ . Then, by Lemma A.4, ğ‘  is S-PNA implies ğ‘¦ must
be Sğ‘† -PNA. Similarly, ğ‘  is S-PNA implies ğ‘§ must be Sğ‘‡ -PNA.
Then, ğ‘¡ âˆˆ ğ‘¥ âŠ• ğ‘¦ must be R âˆª (Sğ‘† )-PNA, and ğ‘¤ âˆˆ ğ‘¡ âŠ• ğ‘§ must be R âˆª Sğ‘† âˆª Sğ‘‡ -PNA. Note
that S coarsens Sğ‘† âˆª Sğ‘‡ so ğ‘¤ is R âˆª Sğ‘† âˆª Sğ‘‡ -PNA implies that ğ‘¤ is R âˆª S-PNA.
Also, ğœ‹ğ‘…ğ‘¤ = ğœ‹ğ‘…ğœ‹ğ‘…âˆªğ‘†ğ‘¤ = ğœ‹ğ‘…ğ‘¡ = ğ‘¥, and ğ‘‘ğ‘œğ‘š(ğ‘¤) = ğ‘… âˆª ğ‘† âˆª ğ‘‡ = ğ‘‘ğ‘œğ‘š(ğ‘¥) âˆª ğ‘‘ğ‘œğ‘š(ğ‘ ).
Hence, ğ‘¤ âˆˆ ğ‘¥ âŠ• ğ‘ .

â€¢ Note that ğ‘¥ is trivially {ğ‘…}-PNA. Then, for any partition S, T such that ğ‘… âˆ© (âˆªS) âˆ© (âˆªT ) =
âˆ… and ğ‘¦ is S-PNA and ğ‘§ is T -PNA, ï¬rst ğ‘¡ must be ({ğ‘…} âˆª S)-PNA, and then ğ‘¤ must be
({ğ‘…} âˆª S âˆª T )-PNA. By projection, ğ‘  = ğœ‹ğ‘†âˆªğ‘‡ must be S âˆª T ğ‘§-PNA.
Also, ğœ‹ğ‘†ğ‘  = ğœ‹ğ‘† ğœ‹ğ‘†âˆªğ‘‡ ğ‘¤ = ğœ‹ğ‘†ğ‘¤ = ğœ‹ğ‘† ğœ‹ğ‘…âˆªğ‘†ğ‘¤ = ğœ‹ğ‘†ğ‘¡ = ğ‘¦, and similarly, ğœ‹ğ‘‡ ğ‘  = ğ‘§. Also, ğ‘‘ğ‘œğ‘š(ğ‘ ) =
ğ‘† âˆª ğ‘‡ = ğ‘‘ğ‘œğ‘š(ğ‘¦) âˆª ğ‘‘ğ‘œğ‘š(ğ‘§).
Hence, ğ‘  âˆˆ ğ‘¦ âŠ• ğ‘§.

Unit Existence. Take ğ‘’ to be ğœ‡ where ğœ‡ is the (unique) distribution in D (Mem[âˆ…]).
Unit Closure. Immediate as we take ğ¸ = ğ‘€.
Unit Coherence. Immediate: ğ‘¥ âˆˆ ğ‘¦ âŠ• ğ‘’ entails ğ‘¦ = ğœ‹ğ‘‘ğ‘œğ‘š (ğ‘¦) ğ‘¥, which implies ğ‘¦ âŠ‘ ğ‘¥.

(cid:3)

Theorem C.1. Given a set of variables ğ‘†, ğ‘† satisï¬es NA in ğœ‡ iï¬€ ğœ‡ satisï¬es S-PNA for any S parti-

tioning ğ‘† iï¬€ ğœ‡ satisï¬es {{ğ‘ } | ğ‘  âˆˆ ğ‘† }-PNA.

Proof. The second equivalence is straightforward:

â€¢ {{ğ‘ } | ğ‘  âˆˆ S} is a partition of ğ‘†, so we have the backward direction.
â€¢ Any S partitioning ğ‘† coarsens {{ğ‘ } | ğ‘  âˆˆ Â§}, so we have the ï¬rst direction.

For the forward direction of the ï¬rst equivalence, it suï¬ƒces to prove that for any partition S of

ğ‘†, any family of all monotone or all antitone functions ğ‘“ğ‘– : Mem[ğ‘†ğ‘– ] â†’ R+

Eğ‘¥âˆ¼ğœ‡

ğ‘“ğ‘– (pğ‘†ğ‘–ğ‘š)

â‰¤

#

"
Ã–ğ‘†ğ‘– âˆˆS

Ã–ğ‘†ğ‘– âˆˆS

(cid:2)

(cid:3)

Eğ‘¥âˆ¼ğœ‡

ğ‘“ğ‘– (pğ‘†ğ‘–ğ‘š)

.

(6)

We prove that by induction on the size of S.
Base case |S| = 1: S-PNA is trivial.
Base case |S| = 2: S-PNA is straightforward from NA.
Inductive case: Assuming ğœ‡ satisï¬es S-PNA for any partition with size less than ğ¾, we want

to show that ğœ‡ satisï¬es S-PNA for any partition with size equals to ğ¾.
Say S = {ğ‘†1, . . . , ğ‘†ğ¾ }. For any family of all monotone or all antitone functions ğ‘“ğ‘– : Mem[ğ‘†ğ‘–] â†’
ğ¾âˆ’1
R+, either both ğ‘š â†¦â†’
ğ‘–=1 ğ‘“ğ‘– (pğ‘†ğ‘–ğ‘š) and
ğ‘“ğ¾ are antitone. Thus, by the inductive hypothesis

ğ¾âˆ’1
ğ‘–=1 ğ‘“ğ‘– (pğ‘†ğ‘–ğ‘š) and ğ‘“ğ¾ are monotone, or both ğ‘š â†¦â†’

Ã

ğ¾

Eğ‘¥âˆ¼ğœ‡

ğ‘“ğ‘– (pğ‘†ğ‘–ğ‘š)

#

"

Ã–ğ‘–=1

â‰¤ Eğ‘¥âˆ¼ğœ‡

ğ‘“ğ‘– (pğ‘†ğ‘–ğ‘š)

#

Â· Eğ‘¥âˆ¼ğœ‡

ğ‘“ğ¾ (pğ‘†ğ¾ ğ‘š)

Ã

ğ‘“ğ¾ (pğ‘†ğ¾ ğ‘š)

(cid:2)

(cid:2)

(cid:3)

(cid:3)

ğ¾âˆ’1

"

Ã–ğ‘–=1
Eğ‘¥âˆ¼ğœ‡

â‰¤

=

ğ¾âˆ’1

Ã–ğ‘–=1
ğ¾

Ã–ğ‘–=1

ğ‘“ğ‘– (pğ‘†ğ‘–ğ‘š)

Â· Eğ‘¥âˆ¼ğœ‡

(cid:3)

(cid:2)
ğ‘“ğ‘– (pğ‘†ğ‘–ğ‘š)

.

Eğ‘¥âˆ¼ğœ‡

(cid:2)

(cid:3)

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:35

The backward direction of the ï¬rst equivalence is more involved. For any two disjoint ğ´, ğµ âŠ† ğ‘†,
we know ğœ‡ satisï¬es {ğ´, ğµ}-PNA, so for every pair of both monotone or both antitone functions
ğ‘“ : Mem[ğ´] â†’ R+, ğ‘” : Mem[ğµ] â†’ R+,

Eğ‘šâˆ¼ğœ‡ [ğ‘“ (pğ´ğ‘š) Â· ğ‘”(pğµğ‘š)] â‰¤ Eğ‘šâˆ¼ğœ‡ [ğ‘“ (pğ´ğ‘š)] Â· Eğ‘šâˆ¼ğœ‡ [ğ‘”(pğµğ‘š)].

But the problem is to show this inequality when ğ‘“ , ğ‘” are not both non-negative. We prove that in
three steps:

(1) If ğ‘“ , ğ‘” are lower-bounded by âˆ’ğ¿, i.e., ğ‘“ (ğ‘¥) â‰¥ âˆ’ğ¿ and ğ‘”(ğ‘¥) â‰¥ âˆ’ğ¿ for any ğ‘¥. Then ğ‘¥ â†’ ğ‘“ (ğ‘¥) +ğ¿

and ğ‘¥ â†’ ğ‘”(ğ‘¥) + ğ¿ are both non-negative functions. Thus,

Eğ‘šâˆ¼ğœ‡ [(ğ‘“ (pğ´ğ‘š) + ğ¿) Â· (ğ‘”(pğµğ‘š) + ğ¿)] â‰¤ Eğ‘šâˆ¼ğœ‡ [ğ‘“ (pğ´ğ‘š) + ğ¿] Â· Eğ‘šâˆ¼ğœ‡ [ğ‘”(pğµğ‘š) + ğ¿].

(7)

Meanwhile,

E[(ğ‘“ (pğ´ğ‘š) + ğ¿) Â· (ğ‘”(pğµğ‘š) + ğ¿)] = E[ğ‘“ (pğ´ğ‘š) Â· ğ‘”(pğµğ‘š)] + ğ¿ Â· E[ğ‘“ (pğ´ğ‘š)] + ğ¿ Â· E[ğ‘”(pğµğ‘š)] + ğ¿2
E[ğ‘“ (pğ´ğ‘š) + ğ¿] Â· E[ğ‘”(pğµğ‘š) + ğ¿] = (E[ğ‘“ (pğ´ğ‘š)] + ğ¿) Â· (E[ğ‘”(pğµğ‘š)] + ğ¿)

= E[ğ‘“ (pğ´ğ‘š)] Â· E[ğ‘”(pğµğ‘š)] + ğ¿ Â· E[ğ‘“ (pğ´ğ‘š)] + ğ¿ Â· E[ğ‘”(pğµğ‘š)] + ğ¿2.

So Equation (7) implies that

Eğ‘šâˆ¼ğœ‡ [ğ‘“ (pğ´ğ‘š) Â· ğ‘”(pğµğ‘š)] â‰¤ Eğ‘šâˆ¼ğœ‡ [ğ‘“ (pğ´ğ‘š)] Â· Eğ‘šâˆ¼ğœ‡ [ğ‘”(pğµğ‘š)].

(2) If the codomain of ğ‘“ or ğ‘” does not range across both negative and positive numbers, then
we can also prove the desired inequality by applying the monotone convergence theorem
on the result for lower-bounded functions.
â€¢ Say ğ‘“ is non-negative and ğ‘” is non-positive. For any natural number ğ‘›, ğ‘š âˆˆ Mem[ğ´ âˆª ğµ],
we deï¬ne ğ‘”ğ‘› (pğµğ‘š) = max(ğ‘”(pğµğ‘š), âˆ’ğ‘›), â„ğ‘› (ğ‘š) = ğ‘“ (pğ´ğ‘š) Â·ğ‘”ğ‘›(pğµğ‘š). Then for any ğ‘›, ğ‘”ğ‘› and
â„ğ‘› are lower-bounded non-positive functions; and for any ğ‘š, {ğ‘”ğ‘› (ğ‘š)}ğ‘› âˆˆN is a monotoni-
cally decreasing sequence converging to ğ‘”(ğ‘š), {â„ğ‘› (ğ‘š)}ğ‘› âˆˆN is a monotonically decreasing
sequence converging to ğ‘“ (pğ´ğ‘š) Â· ğ‘”(pğµğ‘š). By the monotone convergence theorem,

Eğ‘šâˆ¼ğœ‡ ğ‘“ (pğ´ğ‘š) Â· ğ‘”(pğµğ‘š) = lim
ğ‘›â†’âˆ
Eğ‘šâˆ¼ğœ‡ğ‘”(pğµğ‘š) = lim
ğ‘›â†’âˆ

Eğ‘šâˆ¼ğœ‡â„ğ‘› (ğ‘š)

Eğ‘šâˆ¼ğœ‡ğ‘”ğ‘› (ğœ‹ğµğ‘š).

By what we proved above, for any ğ‘›, we have

Eğ‘šâˆ¼ğœ‡ [â„ğ‘› (ğ‘š)] â‰¤ Eğ‘šâˆ¼ğœ‡ [ğ‘“ (pğ´ğ‘š)] Â· Eğ‘šâˆ¼ğœ‡ [ğ‘”ğ‘› (pğµğ‘š)]

Taking that to the limit ğ‘› â†’ âˆ,

lim
ğ‘›â†’âˆ

Eğ‘šâˆ¼ğœ‡ [â„ğ‘› (ğ‘š)] â‰¤ lim
ğ‘›â†’âˆ
= lim
ğ‘›â†’âˆ

Eğ‘šâˆ¼ğœ‡ [ğ‘“ (pğ´ğ‘š)] Â· Eğ‘šâˆ¼ğœ‡ [ğ‘”(pğµğ‘š)]

Eğ‘šâˆ¼ğœ‡ [ğ‘“ (pğ´ğ‘š)] Â· lim
(cid:0)
ğ‘›â†’âˆ

Eğ‘šâˆ¼ğœ‡ [ğ‘”(pğµğ‘š)]

(cid:1)

Therefore, for any distribution ğœ‡ âˆˆ D (Mem[ğ´ âˆª ğµ]),

Eğ‘šâˆ¼ğœ‡ [ğ‘“ (pğ´ğ‘š) Â· ğ‘”(pğµğ‘š)] â‰¤ Eğ‘šâˆ¼ğœ‡ [ğ‘“ (pğ´ğ‘š)] Â· Eğ‘šâˆ¼ğœ‡ [ğ‘”(pğµğ‘š)].

â€¢ The case where ğ‘“ is non-positive and ğ‘” is non-negative is symmetric.
â€¢ The case where ğ‘“ and ğ‘” are both non-positive is also similar. We will deï¬ne ğ‘“ğ‘› (pğ´ğ‘š) =
max(ğ‘“ (pğ´ğ‘š), âˆ’ğ‘›), ğ‘”ğ‘› (pğµğ‘š) = max(ğ‘”(pğµğ‘š), âˆ’ğ‘›), â„ğ‘› (ğ‘š) = ğ‘“ğ‘› (pğ´ğ‘š) Â· ğ‘”ğ‘› (pğµğ‘š). Then we

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:36

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

have

Eğ‘šâˆ¼ğœ‡ ğ‘“ (pğ´ğ‘š) Â· ğ‘”(pğµğ‘š) = lim
ğ‘›â†’âˆ
Eğ‘šâˆ¼ğœ‡ğ‘”(pğµğ‘š) = lim
ğ‘›â†’âˆ
Eğ‘šâˆ¼ğœ‡ ğ‘“ (pğµğ‘š) = lim
ğ‘›â†’âˆ

Eğ‘šâˆ¼ğœ‡â„ğ‘› (ğ‘š)

Eğ‘šâˆ¼ğœ‡ğ‘”ğ‘› (ğœ‹ğµğ‘š)

Eğ‘šâˆ¼ğœ‡ ğ‘“ğ‘› (ğœ‹ğ´ğ‘š).

And the rest follows.

(3) Now we consider the general case where we only know both ğ‘“ and ğ‘” are either lower-

bounded or upper bounded.
â€¢ If both ğ‘“ and ğ‘” are lower-bounded, reduce to the ï¬rst case.
â€¢ If ğ‘“ is lower-bounded by ğ¿, ğ‘” is upper-bounded by ğ‘ˆ , then we can consider function ğ‘“ â€² =
ğ‘“ + ğ¿ and ğ‘”â€² = ğ‘” âˆ’ ğ‘ˆ . Then ğ‘“ â€² is non-negative and ğ‘”â€² is non-positive, so by step 2, we have

Eğ‘šâˆ¼ğœ‡ [ğ‘“ â€²(pğ´ğ‘š) Â· ğ‘”â€²(pğµğ‘š)] â‰¤ Eğ‘šâˆ¼ğœ‡ [ğ‘“ â€²(pğ´ğ‘š)] Â· Eğ‘šâˆ¼ğœ‡ [ğ‘”â€²(pğµğ‘š)].

By calculations analogous to what we did in step 1, that implies

Eğ‘šâˆ¼ğœ‡ [ğ‘“ (pğ´ğ‘š) Â· ğ‘”(pğµğ‘š)] â‰¤ Eğ‘šâˆ¼ğœ‡ [ğ‘“ (pğ´ğ‘š)] Â· Eğ‘šâˆ¼ğœ‡ [ğ‘”(pğµğ‘š)].

â€¢ If ğ‘“ is upper-bounded and ğ‘” is lower-bounded: analogous to above.
â€¢ If both ğ‘“ and ğ‘” are upper-bounded: also, analogous to above.

Thus, ğœ‡ satisï¬es {ğ´, ğµ}-PNA implies ğœ‡ satisï¬es (ğ´, ğµ)-NA. And therefore, ğœ‡ satisï¬es {ğ´, ğµ}-PNA

for any ğ´, ğµ âŠ† ğ‘† implies ğ‘† satisï¬es strong NA in ğœ‡.

(cid:3)

C.2 A 2-BI model for independence and negative association

The proof that independence implies PNA will use the following lemma.

Lemma C.2. In a distribution ğœ‡, if ğœ‡ satisï¬es {ğ‘†1, ğ‘†2}-PNA, ğœ‡ satisï¬es {ğ‘‡1,ğ‘‡2}-PNA, and ğ‘†1 âˆª ğ‘†2 is

independent from ğ‘‡1 âˆª ğ‘‡2 in ğœ‡ then ğœ‡ is {ğ‘†1 âˆª ğ‘‡1, ğ‘†2 âˆª ğ‘‡2}-PNA.

Proof. By the deï¬nition of PNA and independence, ğ‘†1, ğ‘†2 are disjoint, ğ‘‡1,ğ‘‡2 are disjoint, and
ğ‘†1 âˆª ğ‘‡1, ğ‘†2 âˆª ğ‘‡2 are disjoint. For any monotonically decreasing/increasing functions ğ‘“ : Mem[ğ‘†1 âˆª
ğ‘‡1] â†’ R+, ğ‘” : Mem[ğ‘†2 âˆª ğ‘‡2] â†’ R+,

Eğ‘šâˆ¼ğœ‡ [ğ‘“ (pğ‘†1âˆªğ‘‡1ğ‘š) Â· ğ‘”(pğ‘†2âˆªğ‘‡2ğ‘š)]
= Eğ‘ âˆ¼ğœ‹ğ‘†1âˆªğ‘†2 ğœ‡Eğ‘¡âˆ¼ğœ‹ğ‘‡1 âˆªğ‘‡2 ğœ‡ [ğ‘“ (pğ‘†1ğ‘ , pğ‘‡1ğ‘¡) Â· ğ‘”(pğ‘†2ğ‘ , pğ‘‡2ğ‘¡)]
Eğ‘¡1âˆ¼ğœ‹ğ‘‡1 ğœ‡ [ğ‘“ (pğ‘†1ğ‘ , ğ‘¡1)] Â· Eğ‘¡2âˆ¼ğœ‹ğ‘‡2 ğœ‡ [ğ‘”(pğ‘†2ğ‘ , ğ‘¡2)]
â‰¤ Eğ‘ âˆ¼ğœ‹ğ‘†1âˆªğ‘†2 ğœ‡
(cid:17)
â‰¤ Eğ‘ 1âˆ¼ğœ‹ğ‘†1 ğœ‡ Eğ‘¡1âˆ¼ğœ‹ğ‘‡1 ğœ‡ [ğ‘“ (ğ‘ 1, ğ‘¡1)] Â· Eğ‘ 2âˆ¼ğœ‹ğ‘†2 ğœ‡ Eğ‘¡2âˆ¼ğœ‹ğ‘‡2 ğœ‡ [ğ‘”(ğ‘ 2, ğ‘¡2)]
â‰¤ Eğ‘šâˆ¼ğœ‡ [ğ‘“ (pğ‘†1âˆªğ‘‡1ğ‘š)] Â· Eğ‘šâˆ¼ğœ‡ [ğ‘”(pğ‘†2âˆªğ‘‡2ğ‘š)]

(cid:16)

(By independence of ğ‘†1 âˆª ğ‘†2 and ğ‘‡1 âˆª ğ‘‡2)

(â™¦)

(â™¥)
(â™£)

where â™¦ is because ğœ‹ğ‘‡1âˆªğ‘‡2 ğœ‡ is ğ‘‡1,ğ‘‡2-PNA and ğ‘“ (pğ‘†1ğ‘ , ğ‘¡1), ğ‘”(pğ‘†2ğ‘ , ğ‘¡2) are both monotonically de-
creasing/increasing in ğ‘‡1,ğ‘‡2; â™¥ is because ğœ‹ğ‘†1âˆªğ‘†2 ğœ‡ is ğ‘†1, ğ‘†2-PNA and that Eğ‘¡1âˆ¼ğœ‹ğ‘‡1 ğœ‡ [ğ‘“ (pğ‘†1ğ‘ , ğ‘¡1)], and
Eğ‘¡2âˆ¼ğœ‹ğ‘‡2 ğœ‡ [ğ‘”(pğ‘†2ğ‘ , ğ‘¡2)] are both monotonically decreasing/increasing in ğ‘†1, ğ‘†2; â™£ is by independence
(cid:3)
of ğ‘†1 and ğ‘‡1 and the independence of ğ‘†2 and ğ‘‡2 in ğœ‡.

Theorem 4.12 (Independence implies PNA). Let ğ‘†,ğ‘‡ âŠ† Var be two disjoint sets of variables.
Suppose ğœ‡1 âˆˆ D (Mem[ğ‘†]), ğœ‡2 âˆˆ D (Mem[ğ‘‡ ]). If ğœ‡1 satisï¬es S-PNA and ğœ‡2 satisï¬es T -PNA, then
any ğœ‡ âˆˆ ğœ‡ğ‘† âŠ— ğœ‡ğ‘‡ satisï¬es S âˆª T -PNA.

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:37

Proof. Fix S and T . Say S = {ğ‘†1, . . . , ğ‘†ğ‘ } and T = {ğ‘‡1, . . . ,ğ‘‡ğ‘ }. For any R coarsening S âˆª T ,

indexing S âˆª T as {ğ‘ˆ1, . . . , ğ‘ˆğ‘+ğ‘}, indexing R as {ğ‘…1, . . . , ğ‘…ğ‘›}, we have:

Then, given a family of monotonically increasing/decreasing functions ğ‘”ğ‘– : ğ‘…ğ‘– â†’ R+

R = {âˆª{ğ‘ˆ ğ‘—

| ğ‘— âˆˆ ğ‘“ (ğ‘–)} | ğ‘– âˆˆ [ğ‘›]}.

| ğ‘— âˆˆ ğ‘“ (ğ‘–)} can be divided into the part in ğ‘† and the part in ğ‘‡ . We refer to them

Eğ‘šâˆ¼ğœ‡

"

Ã–ğ‘…ğ‘– âˆˆR

ğ‘”ğ‘– (pğ‘…ğ‘– ğ‘š)

#

= Eğ‘šâˆ¼ğœ‡

ğ‘”ğ‘– (pâˆª{ğ‘ˆ ğ‘— | ğ‘— âˆˆğ‘“ (ğ‘–) }ğ‘š)

.

ï£®
Ã–ğ‘– âˆˆ[ğ‘› ]
ï£¯
ï£¯
ï£¯
ï£¯
ï£°

ï£¹
ï£º
ï£º
ï£º
ï£º
ï£»

ğ‘– may be empty). Thus, for each ğ‘–,
ğ‘š).
1 , . . . ,ğ‘‡ â€²

ğ‘”ğ‘– (pâˆª{ğ‘ˆ ğ‘— | ğ‘— âˆˆğ‘“ (ğ‘–) }ğ‘š) = ğ‘”ğ‘– (pğ‘†â€²
ğ‘– âˆªğ‘‡ â€²
ğ‘–
ğ‘›} coarsens S, and T â€² = {ğ‘‡ â€²

For each ğ‘–, âˆª{ğ‘ˆ ğ‘—
ğ‘– and ğ‘‡ â€²
as ğ‘† â€²

ğ‘– . (Some of ğ‘† â€²

ğ‘– and ğ‘‡ â€²

By Lemma A.4, Sâ€² = {ğ‘† â€²

1, . . . , ğ‘† â€²

and T â€²-PNA.

We prove by induction on ğ‘˜ âˆˆ [ğ‘›] that

Eğ‘šâˆ¼ğœ‡

ğ‘”ğ‘– (pğ‘†â€²

ğ‘– âˆªğ‘‡ â€²
ğ‘–

ï£®
Ã–ğ‘– âˆˆ[ğ‘˜ ]
ï£¯
ï£¯
Base case When ğ‘˜ = 1, trivial.
ï£¯
ï£¯
Inductive case For ğ‘˜ < ğ‘›, assume
ï£°

Eğ‘šâˆ¼ğœ‡

ğ‘”ğ‘– (pğ‘†â€²

ğ‘– âˆªğ‘‡ â€²
ğ‘–

ğ‘š)

.

Ã–ğ‘– âˆˆ[ğ‘˜ ]

(cid:2)

(cid:3)

ğ‘š)

â‰¤

ï£¹
ï£º
ï£º
ï£º
ï£º
ï£»

Eğ‘šâˆ¼ğœ‡ [

ğ‘”ğ‘– (pğ‘†â€²

ğ‘– âˆªğ‘‡ â€²
ğ‘–

ğ‘š)] â‰¤

Eğ‘šâˆ¼ğœ‡ [ğ‘”ğ‘– (pğ‘†â€²

ğ‘– âˆªğ‘‡ â€²
ğ‘–

ğ‘š)].

ğ‘›} coarsens T . So ğœ‡ is Sâ€²-PNA

Ã–ğ‘– âˆˆ[ğ‘˜ ]
Ã–ğ‘– âˆˆ[ğ‘˜ ]
ğ‘˜+1}-PNA, and ğœ‡ is T â€²-PNA implies that
Note that ğœ‡ is Sâ€²-PNA implies that ğœ‡ is {âˆªğ‘– âˆˆ[ğ‘˜ ] (ğ‘† â€²
{âˆªğ‘– âˆˆ[ğ‘˜ ] (ğ‘‡ â€²
ğ‘– ) âˆª {âˆªğ‘– âˆˆ[ğ‘˜ ] (ğ‘‡ â€²
ğ‘˜+1}-
NA. Also, since all ğ‘”ğ‘– is monotonically increasing (decreasing) and non-negative, ğ‘š â†¦â†’
ğ‘– âˆªâˆªğ‘– âˆˆ[ğ‘˜ ]ğ‘‡ â€²
ğ‘–

ğ‘– âˆˆ[ğ‘˜ ] ğ‘”ğ‘– (ğ‘š) is also a monotonically increasing (decreasing) function from âˆªğ‘– âˆˆ[ğ‘˜ ]ğ‘† â€²

ğ‘˜+1}-NA. Thus, by Lemma C.2, ğœ‡ is also {{âˆªğ‘– âˆˆ[ğ‘˜ ] (ğ‘† â€²

ğ‘˜+1 âˆªğ‘‡ â€²

ğ‘– ),ğ‘‡ â€²

ğ‘– ), ğ‘† â€²

ğ‘– ), ğ‘† â€²

to R+. Therefore,
Ã

Eğ‘šâˆ¼ğœ‡ [

ğ‘”ğ‘– (pğ‘†â€²

ğ‘– âˆªğ‘‡ â€²
ğ‘–

Ã–ğ‘– âˆˆ[ğ‘˜+1]

ğ‘š)] â‰¤ Eğ‘šâˆ¼ğœ‡ [

ğ‘”ğ‘– (pğ‘†â€²

ğ‘– âˆªğ‘‡ â€²
ğ‘–

ğ‘š)] Â· Eğ‘šâˆ¼ğœ‡ [ğ‘”ğ‘˜+1(pğ‘†â€²

ğ‘˜+1âˆªğ‘‡ â€²

ğ‘˜+1

ğ‘š)]

Ã–ğ‘– âˆˆ[ğ‘˜ ]
Eğ‘šâˆ¼ğœ‡ [ğ‘”ğ‘– (pğ‘†â€²

ğ‘– âˆªğ‘‡ â€²
ğ‘–

ğ‘š)],

â‰¤

Ã–ğ‘– âˆˆ[ğ‘˜+1]

where the second inequality follows from the inductive hypothesis.

Thus, the desired inequality holds for any R coarsening S âˆª T and any family of monotonically
(cid:3)

increasing (decreasing) functions on R. Thus, ğœ‡ is S âˆª T -PNA.

Theorem 4.15. If X1 and X2 are two Mâˆ’ğµğ¼ frames, then X = X1 Ã— X2 is also an ğ‘€-BI frame.

Proof. Let Xğ‘–,ğ‘š = (ğ‘‹ğ‘–, âŠ‘ğ‘–, âŠ•ğ‘–,ğ‘š, ğ¸ğ‘–,ğ‘š). For any ğ‘– âˆˆ {1, 2}, ğ‘š âˆˆ ğ‘€, Xğ‘–,ğ‘š is a BI frame.
First, for any ğ‘š âˆˆ ğ‘€, we prove that (ğ‘‹, âŠ‘, âŠ•ğ‘š, ğ¸ğ‘š) is a BI frame.
Down-Closed. Let (ğ‘§1, ğ‘§2) âˆˆ (ğ‘¥1, ğ‘¥2) âŠ•ğ‘š (ğ‘¦1, ğ‘¦2) with (ğ‘¥1, ğ‘¥2) âŠ’ (ğ‘¥ â€²

1, ğ‘¦â€²
2).
Then, from the Down-Closed property of X1,ğ‘š and X2,ğ‘š respectively, we have that there
exists ğ‘§â€²
ğ‘– âŠ• ğ‘¦â€²
2) and
1, ğ‘§â€²
(ğ‘§â€²

ğ‘– for ğ‘– âˆˆ {1, 2}. Hence (ğ‘§1, ğ‘§2) âŠ’ (ğ‘§â€²

2 such that ğ‘§ğ‘– âŠ’ğ‘– ğ‘§â€²
2) âŠ•ğ‘š (ğ‘¦â€²

2) and (ğ‘¦1, ğ‘¦2) âŠ’ (ğ‘¦â€²

1 and ğ‘§â€²
1, ğ‘¦â€²
1, ğ‘¥ â€²
2).
Commutativity. Immediate.

2) âˆˆ (ğ‘¥ â€²

ğ‘– and ğ‘§â€²

ğ‘– âˆˆ ğ‘¥ â€²

1, ğ‘¥ â€²

1, ğ‘§â€²

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:38

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

Associativity. Let (ğ‘¤1, ğ‘¤2) âˆˆ (ğ‘¡1, ğ‘¡2) âŠ•ğ‘š (ğ‘§1, ğ‘§2) and (ğ‘¡1, ğ‘¡2) âˆˆ (ğ‘¥1, ğ‘¥2) âŠ•ğ‘š (ğ‘¦1, ğ‘¦2). Then for
ğ‘– âˆˆ {1, 2} there exists ğ‘ ğ‘– âˆˆ ğ‘¦ğ‘– âŠ•ğ‘–,ğ‘š ğ‘§ğ‘– such that ğ‘¤ğ‘– âˆˆ ğ‘¥ğ‘– âŠ•ğ‘–,ğ‘šğ‘ ğ‘– . Thus, (ğ‘ 1, ğ‘ 2) âˆˆ (ğ‘¦1, ğ‘¦2) âŠ•ğ‘š (ğ‘§1, ğ‘§2)
and (ğ‘¤1, ğ‘¤2) âˆˆ (ğ‘¥1, ğ‘¥2) âŠ•ğ‘š (ğ‘ 1, ğ‘ 2).

Unit Existence. Immediate.
Unit Closure. If (ğ‘’1, ğ‘’2) âˆˆ ğ¸ğ‘š and (ğ‘’ â€²
Unit Coherence. Let (ğ‘’1, ğ‘’2) âˆˆ ğ¸ğ‘š and (ğ‘¥1, ğ‘¥2) âˆˆ (ğ‘¦1, ğ‘¦2) âŠ•ğ‘š (ğ‘’1, ğ‘’2). Then ğ‘¥ğ‘– âŠ’ğ‘– ğ‘¦ğ‘– , which
(cid:3)

2) âŠ’ (ğ‘’1, ğ‘’2), then ğ‘’ â€²

ğ‘– âˆˆ ğ¸ğ‘–,ğ‘š, so (ğ‘’ â€²

2) âˆˆ ğ¸ğ‘š.

implies that (ğ‘¥1, ğ‘¥2) âŠ’ (ğ‘¦1, ğ‘¦2).

1, ğ‘’ â€²

1, ğ‘’ â€²

Second, we show if ğ‘š â‰¤ ğ‘šâ€² âˆˆ ğ‘€, then (ğœ‡1, ğœ‡â€²
X1 and X2 are ğ‘€-BI frames, so ğ‘š â‰¤ ğ‘šâ€² implies that ğœ‡1 âŠ•1,ğ‘š ğœ‡2 âŠ†1 ğœ‡1 âŠ•1,ğ‘šâ€² ğœ‡2 and ğœ‡â€²
2) âŠ† (ğœ‡1, ğœ‡â€²
1 âŠ•2,ğ‘šâ€² ğœ‡â€²
ğœ‡â€²

2. Therefore, (ğœ‡1, ğœ‡â€²

1) âŠ•ğ‘šâ€² (ğœ‡2, ğœ‡â€²
2).

1) âŠ•ğ‘šâ€² (ğœ‡2, ğœ‡â€²

1) âŠ•ğ‘š (ğœ‡2, ğœ‡â€²

1) âŠ•ğ‘š (ğœ‡2, ğœ‡â€²

2) âŠ† (ğœ‡1, ğœ‡â€²

2):

1 âŠ•2,ğ‘šâ€² ğœ‡â€²

2 âŠ†2

D PROGRAM LOGIC
D.1 The semantics of pWhile

Deï¬nition D.1 (Semantics of expressions). We assume all expressions are well-typed. We inter-
pret them as Mem[DV] Ã— Mem[ğ‘‡ ] â†’ Val, which can be naturally lifted to Mem[DV] Ã—
D (Mem[ğ‘‡ ]) â†’ D (Val). For ğœ âˆˆ Mem[DV], ğ‘š âˆˆ Mem[ğ‘‡ ],

Jğ‘¥ğ‘‘ K(ğœ, ğ‘š) = ğœ (ğ‘¥ğ‘‘ )
Jğ‘¥ğ‘Ÿ K(ğœ, ğ‘š) = ğ‘š(ğ‘¥ğ‘Ÿ )

J[ğ‘’1, . . . , ğ‘’ğ‘›]K(ğœ, ğ‘š) = [Jğ‘’1K(ğœ, ğ‘š), . . . , Jğ‘’ğ‘›K(ğœ, ğ‘š)]
Jğ‘’ + ğ‘“ K(ğœ, ğ‘š) = Jğ‘’K(ğœ, ğ‘š) + Jğ‘“ K(ğœ, ğ‘š)
Jğ‘’ âˆ§ ğ‘“ K(ğœ, ğ‘š) = Jğ‘’K(ğœ, ğ‘š) âˆ§ Jğ‘“ K(ğœ, ğ‘š)

when Jğ‘’K(ğœ, ğ‘š) and Jğ‘“ğ‘Ÿ K(ğœ, ğ‘š) are numbers
when Jğ‘’K(ğœ, ğ‘š) and Jğ‘“ğ‘Ÿ K(ğœ, ğ‘š) are booleans

Deï¬nition D.2 (Convex combination of distributions). Let the binary operator â—¦ğœŒ takes a convex

combination of two distributions, i.e., for any ğœ‡1, ğœ‡2 âˆˆ D (Mem[ğ‘†]), for any ğ‘¥ âˆˆ Mem[ğ‘†],

ğœ‡1 â—¦ğœŒ ğœ‡2 (ğ‘¥) , ğœŒ Â· ğœ‡1 (ğ‘¥) + (1 âˆ’ ğœŒ) Â· ğœ‡2 (ğ‘¥).
Deï¬nition D.3 (Semantics of pWhile). Let Unifğ‘† denotes the uniform distribution on ï¬nite set ğ‘†,

i.e., ğœ‡ : ğ‘  â†¦â†’ 1

|ğ‘† | for any ğ‘  âˆˆ ğ‘†.

We also assume that for any ğœ âˆˆ Mem[DV], any ğœ‡1 âˆˆ D (Mem[ğ‘‡1]), ğœ‡2 âˆˆ D (Mem[ğ‘‡2]) where
ğ‘‡1,ğ‘‡2 âŠ† RV, the ï¬rst component of Jğ‘K(ğœ, ğœ‡1) and Jğ‘K(ğœ, ğœ‡2) are the same. For any (ğœ, ğœ‡) âˆˆ Config,
let

JskipK(ğœ, ğœ‡) , (ğœ, ğœ‡)

Jğ‘¥ğ‘‘ â† ğ‘’ğ‘‘ K(ğœ, ğœ‡) , (ğœ [ğ‘¥ğ‘‘ â†¦â†’ Jğ‘’ğ‘‘ K(ğœ, ğœ‡)], ğœ‡)
Jğ‘¥ğ‘Ÿ â† ğ‘’ğ‘Ÿ K(ğœ, ğœ‡) , (ğœ, bind(ğœ‡, ğ‘š â†¦â†’ unit(ğ‘š[ğ‘¥ğ‘Ÿ â†¦â†’ Jğ‘’ğ‘Ÿ K(ğœ, ğ‘š)])))
Jğ‘¥ğ‘Ÿ

$â† Uğ‘† K(ğœ, ğœ‡) , (ğœ, bind(ğœ‡, ğ‘š â†¦â†’ bind(Unifğ‘†, ğ‘£ â†¦â†’ unit(ğ‘š[ğ‘¥ğ‘Ÿ â†¦â†’ ğ‘£]))))
Jğ‘ ; ğ‘ â€²K(ğœ, ğœ‡) , Jğ‘ â€²K(Jğ‘K(ğœ, ğœ‡))

Jif ğ‘ then ğ‘ else ğ‘ â€²(ğœ, ğœ‡)K ,

ï£±ï£´ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´ï£´
Jwhile ğ‘ do ğ‘K(ğœ, ğœ‡) , lim
ğ‘›â†’âˆ
ï£³

Jğ‘K(ğœ, ğœ‡)
Jğ‘ â€²K(ğœ, ğœ‡)
(ğœ, ğœ‡1 â—¦ğœŒ ğœ‡2)

if Jğ‘K(ğœ, ğœ‡) = ğ›¿ (tt)
if Jğ‘K(ğœ, ğœ‡) = ğ›¿ (ï¬€ )
otherwise, where (ğœ, ğœ‡1) = Jğ‘K(ğœ, ğœ‡ | Jğ‘Kğœ = tt),
ğœŒ = ğœ‡(Jğ‘Kğœ = tt), and (ğœ, ğœ‡2) = Jğ‘ â€²K(ğœ, ğœ‡ | Jğ‘Kğœ = ï¬€ ).

J(if ğ‘… ğ‘ then ğ‘)ğ‘›; if ğ‘… ğ‘ then abortK(ğœ, ğœ‡)

In the last case of the conditional, we write Jğ‘Kğœ for the partial evaluation of ğ‘ on the determin-
istic memory and think of it as another expression. So ğœ‡ | Jğ‘Kğœ = tt and ğœ‡ | Jğ‘Kğœ = ï¬€ are both

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:39

conditional distribution. We assume that there is no update to the deterministic memory when
branching on randomized expressions, so the deterministic memory of both Jğ‘K(ğœ, ğœ‡ | Jğ‘Kğœ = tt)
and Jğ‘K(ğœ, ğœ‡ | Jğ‘Kğœ = ï¬€ ) remains to be ğœ.

In the semantics for the while loop, we can see abort as a command that programmers does
not have access to: for any ğœ, ğœ‡, JabortK(ğœ, ğœ‡) returns the zero sub-distribution. The limit, taken
with the point-wise order, exists because the sub-distributionâ€™s mass monotonically increases as ğ‘›
increases and is upper bounded by 1. In practice, because we assumed that all loops terminates in
ï¬nite steps, the limit is always a full distribution, so all commands in pWhile can still be interpreted
as transformers from conï¬gurations to conï¬gurations.

D.2 The atomic propositions and axioms

, âŠ›,âˆ—

Deï¬nition D.4. For any operation âŠ™ âˆˆ {âˆ§, âˆ¨, âŠ›, âˆ—}, we use the corresponding big-operation
,
nÃ“

â€¢ For any constant or logical variable ğ‘ â‰¥ 1, let
Ã”

o

.

âˆˆ

Ã‡

ğ‘
ğ‘–=0 ğ‘ƒğ‘– = ğ‘ƒ0 abbreviate ((ğ‘ƒ0âŠ™ğ‘ƒ1)âŠ™Â· Â· Â· )âŠ™ğ‘ƒğ‘ âˆ’1.
ğ‘
ğ‘–=0 ğ‘ƒğ‘– ,
Ã‡

âŠ™ ğ‘ƒğ‘ âˆ’1 for ğ‘ > 1.

ğ‘ âˆ’1
ğ‘–=0 ğ‘ƒğ‘–

Formally, let

ğ‘
ğ‘–=0 ğ‘ƒğ‘– = ğ‘ƒ0 if ğ‘ = 1, and let

â€¢ For a ï¬nite multi- set of formula {ğ‘ƒğ‘– }ğ‘– âˆˆğ‘† , let

ğ‘  âˆˆğ‘† ğ‘ƒğ‘  abbreviate ((ğ‘ƒğ‘ 0 âŠ™ ğ‘ƒğ‘ 1 ) âŠ™ Â· Â· Â· ) âŠ™ ğ‘ƒğ‘ ğ‘˜ ,
Ã‡
where ğ‘ 0, . . . , ğ‘ ğ‘˜ is an arbitrary ordering of ğ‘†. The satisfaction is not ambiguous since âŠ™ is
associative and commutative.

(cid:16)Ã‡

Ã‡

Ã‡

(cid:17)

ğ‘£
ğ‘–=0 ğ‘ƒğ‘– to

Ã”

Ã‡

Ã‡

Ã‡

ğ‘–=0hğ‘¦ğ‘– i.

be equivalent to

ğ‘ âˆˆVal (ğ‘£ âˆ¼ ğ‘ âˆ§

ğ‘
ğ‘–=0 ğ‘ƒğ‘– . Formally,

â€¢ For any program variable ğ‘£ âˆˆ DV âˆª RV, for any state (ğœ, ğœ‡) |= ğ‘£ âˆ¼ ğ‘ , we want
ğ‘£
ğ‘–=0 ğ‘ƒğ‘– abbreviates

ğ‘
ğ‘–=0 ğ‘ƒğ‘– ).
Ã‡
Theorem 5.3. Let ğ‘† be any subset of RV. A set of randomized program variables ğ‘Œ = {ğ‘¦ğ‘–
| 0 â‰¤
ğ‘– < ğ¾ } satisï¬es NA in distribution ğœ‡ âˆˆ D (Mem[ğ‘†]) if and only if for any deterministic memory
ğœ âˆˆ Mem[DV], we have (ğœ, ğœ‡) |= âŠ›ğ¾
Proof. Forward direction: we ï¬x ğœ âˆˆ Mem[DV]. Let ğ‘Œğ‘— = {ğ‘¦ğ‘–
induction on ğ‘— that (ğœ, ğœ‹ğ‘Œğ‘— ğœ‡) |= âŠ› ğ‘—+1
ğ‘–=0 hğ‘¦ğ‘– i.
If ğ‘— = 0: then ğ‘¦1 âˆˆ dom(ğœ‡), and (ğœ, ğœ‹ {ğ‘¦1 }ğœ‡) |= hğ‘¦1i.
If ğ‘— â‰¥ 1: Assuming (ğœ, ğœ‹ğ‘Œğ‘— âˆ’1 ğœ‡) |= âŠ› ğ‘—1
on {ğ‘¦ ğ‘— }, ğœ‡ must be T1 âˆª T2-PNA. Thus, ğœ‹ğ‘Œğ‘— ğœ‡ âˆˆ ğœ‹ğ‘Œğ‘— âˆ’1 ğœ‡ âŠ• ğœ‹ {ğ‘¦ ğ‘— }ğœ‡. Since (ğœ, ğœ‹ğ‘Œğ‘— âˆ’1 ğœ‡) |= âŠ› ğ‘—
(ğœ, ğœ‹ {ğ‘¦ ğ‘— }ğœ‡) |= hğ‘¦ ğ‘— i, that implies (ğœ, ğœ‹ğ‘Œğ‘— ğœ‡) |= âŠ› ğ‘—+1
Thus, (ğœ, ğœ‹ğ‘Œğ‘— ğœ‡) |= âŠ› ğ‘—+1
(ğœ, ğœ‡) |= âŠ›ğ¾
ğ‘–=0hğ‘¦ğ‘– i.

ğ‘–=0hğ‘¦ğ‘– i. Since ğ‘Œ satisï¬es NA in ğœ‡, by Theorem 4.7, ğœ‡ is
T -PNA for any partition T of ğ‘Œ . In particular, for any partition T1 on ğ‘Œğ‘—âˆ’1 and any partition T2

ğ‘–=0 hğ‘¦ğ‘– i.
ğ‘–=0 hğ‘¦ğ‘– i. Take ğ‘— = ğ¾, we have (ğœ, ğœ‹ğ‘Œ ğœ‡) |= âŠ›ğ¾

| 0 â‰¤ ğ‘– â‰¤ ğ‘— } we prove by

ğ‘–=0hğ‘¦ğ‘– i. By persistence,

ğ‘–=0hğ‘¦ğ‘– i and

Backward direction: for any ğ´, ğµ being disjoint subsets of ğ‘Œ , by commutativity and associativity

âŠ› âŠ› ğ‘¦ğ‘– âˆˆ(ğ‘‡ \(ğ´âˆªğµ)) hğ‘¦ğ‘– i.
of âŠ›, we can reorder formula and get (ğœ, ğœ‡) |=
By satisfaction rules and the deï¬nition of âŠ•, there exists ğœ‡â€² âŠ‘ ğœ‡ such that (ğœ, ğœ‡â€²) |= âŠ› ğ‘¦ğ‘– âˆˆğ´ hğ‘¦ğ‘– i âŠ›
âŠ› ğ‘¦ğ‘– âˆˆğµ hğ‘¦ğ‘– i. By satisfaction rules again, there exists ğœ‡1, ğœ‡2, ğœ‡â€²â€² such that ğœ‡â€² âŠ’ ğœ‡â€²â€² âˆˆ ğœ‡1 âŠ• ğœ‡2, and
(ğœ, ğœ‡1) |= âŠ› ğ‘¦ğ‘– âˆˆğ´ hğ‘¦ğ‘– i, and (ğœ, ğœ‡2) |= âŠ›ğ‘¦ğ‘– âˆˆğµ hğ‘¦ğ‘– i. Note that ğœ‡1 is trivially {ğ´}-PNA, and ğœ‡2 is

âŠ› ğ‘¦ğ‘– âˆˆğ´ hğ‘¦ğ‘– i âŠ› âŠ› ğ‘¦ğ‘– âˆˆğµ hğ‘¦ğ‘– i

(cid:16)

(cid:17)

trivially {ğµ}-PNA. Thus, ğœ‡â€²â€² satisï¬es {ğ´, ğµ}-PNA.

Therefore, ğœ‡ satisï¬es (ğ´, ğµ)-NA for any ğ´, ğµ being disjoint subsets of ğ‘Œ , i.e., ğœ‡ satisï¬es NA on
(cid:3)

ğ‘Œ .

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:40

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

Lemma 5.4. Let ğ‘¥ğ›¾ be variables. The following axioms are valid in Xcomb.

|= OHğ‘ h[ğ‘¥0, . . . , ğ‘¥ğ‘ âˆ’1]i â†’

ğ‘âŠ›

ğ›¾=0

hğ‘¥ğ›¾ i

|= Permğ´ h[ğ‘¥0, . . . , ğ‘¥ğ‘ âˆ’1]i â†’

ğ‘âŠ›

ğ›¾=0

hğ‘¥ğ›¾ i

(OH-PNA)

(Perm-PNA)

Proof. For any state (ğœ, ğœ‡) satisfying OHğ‘ h[ğ‘¥1, . . . , ğ‘¥ğ‘ âˆ’1]i, by Theorem 2.2, {ğ‘¥1, . . . , ğ‘¥ğ‘ } sat-
isï¬es NA in ğœ‡, and by Theorem 5.3, (ğœ, ğœ‡) |= âŠ›ğ‘
ğ›¾=1hğ‘¥ğ›¾ i. Similarly, by Theorem 2.2, {ğ‘¥1, . . . , ğ‘¥ğ‘ }
satisï¬es NA in ğœ‡, and by Theorem 5.3, (ğœ, ğœ‡) |= âŠ›ğ‘

ğ›¾=1hğ‘¥ğ›¾ i.

(cid:3)

Lemma D.5. Given a distribution ğœ‡ with domain ğ‘†. Let S = {ğ‘†1, . . . , ğ‘†ğ‘ } be a partition of ğ‘†, {ğ‘“ğ‘– :
Mem[ğ‘†ğ‘– ] â†’ Mem[ğ‘‡ğ‘– ]}Sğ‘– âˆˆS be a family of non-decreasing functions (or a family of non-increasing
functions), and T = {ğ‘‡1, . . . ,ğ‘‡ğ‘ } be a partition of another set ğ‘‡ . Let

ğœ‡â€² = bind

ğœ‡, ğ‘š â†¦â†’

unit(ğ‘“ğ‘– (pğ‘†ğ‘–ğ‘š))

.

If ğœ‡ satisï¬es S-PNA, then ğœ‡â€² satisï¬es T -PNA.

(cid:16)

ÃŠğ‘†ğ‘– âˆˆS

(cid:17)

Proof. It suï¬ƒces to show that for any R = {ğ‘…1, . . . , ğ‘…ğ‘š } that coarsens T , for any family of

non-negative non-increasing (or non-decreasing) functions {ğ‘”ğ‘– : Mem[ğ‘…ğ‘– ] â†’ R+}ğ‘…ğ‘– âˆˆR ,

Eğ‘šâ€²âˆ¼ğœ‡â€²

"

#

ğ‘”ğ‘– (pğ‘…ğ‘– ğ‘šâ€²)

â‰¤

Eğ‘šâ€²âˆ¼ğœ‡â€²

ğ‘”ğ‘– (pğ‘…ğ‘–ğ‘šâ€²)

.

Ã–ğ‘–

Ã–ğ‘–
Our ï¬rst step is to show that if we can obtain a distribution on R by ï¬rst applying monotone
map and then coarsening, then we can also obtaining that by ï¬rst coarsening and then applying
monotone map: For any R that coarsens T = {ğ‘‡1, . . . ,ğ‘‡ğ‘›}, there exists some coarsening function
ğ‘” such that

(cid:2)

(cid:3)

R = {âˆª{ğ‘‡ğ‘—

| ğ‘— âˆˆ ğ‘”(ğ‘–)} | ğ‘– âˆˆ [ğ‘›]}.

Let ğ‘…ğ‘– = âˆª{ğ‘‡ğ‘—
| ğ‘— âˆˆ ğ‘”(ğ‘–)}. Since ğ‘” is a coarsening function, for each ğ‘– âˆˆ [ğ‘›], there exists exactly
one ğ‘˜ğ‘– (i.e., the index for the component in the coarsened function) such that ğ‘”(ğ‘˜ğ‘– ) âˆ‹ ğ‘–. Then,
ğ‘‡ğ‘– âŠ† âˆª{ğ‘‡ğ‘—
Let ğ‘…â€²
ğ‘–

ğ‘– ] â†’
Mem[ğ‘…ğ‘– ] by having â„ğ‘– (ğ‘š) =âŠ²âŠ³ ğ‘— âˆˆğ‘” (ğ‘–) ğ‘“ğ‘— (pğ‘† ğ‘— ğ‘š). Since each ğ‘“ğ‘– is monotone, then each â„ğ‘– also mono-
tone in the point-wise order. Then,

| ğ‘– âˆˆ [ğ‘›]}. Then R â€² coarsens S. Deï¬ne â„ğ‘– : Mem[ğ‘…â€²

| ğ‘— âˆˆ ğ‘”(ğ‘˜ğ‘– )} = ğ‘…ğ‘˜ğ‘– .
= âˆª{ğ‘† ğ‘—

| ğ‘— âˆˆ ğ‘”(ğ‘–)}, and R â€² = {ğ‘…â€²
ğ‘–

ğœ‡â€² = bind

ğœ‡, ğ‘š â†¦â†’

unit(ğ‘“ğ‘– (pğ‘†ğ‘–ğ‘š))

= bind

ğœ‡, ğ‘š â†¦â†’

ÃŠğ‘– âˆˆ[ğ‘› ]
so ğœ‡â€² is equivalent to applying â„ğ‘– on each component of R â€².

(cid:17)

(cid:16)

(cid:16)

unit(â„ğ‘– (pğ‘…â€²

ğ‘–

ğ‘š))

,

(cid:17)

ÃŠğ‘…â€²
ğ‘– âˆˆRâ€²

Also, since ğœ‡ is S-PNA and R â€² coarsens S, for any family of non-negative non-increasing (or

non-decreasing) functions {ğ‘”ğ‘– : Mem[ğ‘…â€²

ğ‘– ] â†’ R+}ğ‘…â€²

ğ‘– âˆˆRâ€²,

Our second step is to show that this inequality is preserved under monotone maps.

Eğ‘šâˆ¼ğœ‡

"

ğ‘”ğ‘– (pğ‘…â€²

ğ‘–

ğ‘š)

â‰¤

#

Ã–ğ‘–

Ã–ğ‘–

Eğ‘šâˆ¼ğœ‡ğ‘”ğ‘– (pğ‘…â€²

ğ‘–

ğ‘š).

(8)

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:41

â€¢ If every â„ğ‘– is non-increasing and {ğ‘”ğ‘–

: Mem[ğ‘…ğ‘– ] â†’ R+}ğ‘…ğ‘– âˆˆR are non-decreasing, is non-

increasing,

Eğ‘šâ€²âˆ¼ğœ‡â€² [

ğ‘”ğ‘– (pğ‘…ğ‘–ğ‘šâ€²)]

Ã–ğ‘…ğ‘– âˆˆR

Ã•ğ‘šâ€² âˆˆMem[ğ‘‡ ]

ğœ‡â€²(ğ‘šâ€²) Â·

ğ‘”ğ‘– (pğ‘…ğ‘–ğ‘šâ€²)

Ã–ğ‘…ğ‘– âˆˆR
ğœ‡(ğ‘š) Â· (

Ã•ğ‘šâ€² âˆˆMem[ğ‘‡ ] Ã•ğ‘š âˆˆMem [ğ‘† ]

ğœ‡(ğ‘š) Â·

Ã–ğ‘…â€²
ğ‘– âˆˆRâ€²
ğ‘”ğ‘– (â„ğ‘– (pğ‘…â€²

ğ‘š))

ğ‘–

=

=

=

Ã•ğ‘š âˆˆMem[ğ‘† ]

= Eğ‘šâˆ¼ğœ‡ [

Ã–ğ‘…â€²
ğ‘– âˆˆRâ€²

Ã–ğ‘…â€²
ğ‘– âˆˆRâ€²
ğ‘”ğ‘– (â„ğ‘– (pğ‘…â€²

ğ‘–

ğ‘š))].

unit(â„ğ‘– (pğ‘…â€²

ğ‘–

ğ‘š)) (pğ‘…ğ‘–ğ‘šâ€²)) Â·

ğ‘”ğ‘– (pğ‘…ğ‘–ğ‘šâ€²)

Ã–ğ‘…ğ‘– âˆˆR

Note that ğ‘”ğ‘– â—¦ ğ‘“ is non-negative non-decreasing, then since ğœ‡ satisï¬es Equation (8), we have

Eğ‘šâˆ¼ğœ‡ [

Ã–ğ‘…â€²
ğ‘– âˆˆRâ€²

ğ‘”ğ‘– (â„ğ‘– (pğ‘…â€²

ğ‘–

ğ‘š))] â‰¤

Ã–ğ‘…â€²
ğ‘– âˆˆRâ€²

Eğ‘šâˆ¼ğœ‡ [ğ‘”ğ‘– (â„ğ‘– (pğ‘…â€²

ğ‘–

ğ‘š))]

=

=

Ã–ğ‘…â€²
ğ‘– âˆˆRâ€²

ğœ‡(ğ‘š) Â· ğ‘”ğ‘– (â„ğ‘– (pğ‘…â€²

ğ‘–

ğ‘š))

Ã•ğ‘š âˆˆMem[ğ‘† ]
Eğ‘šâ€²âˆ¼ğœ‡â€²ğ‘”ğ‘– (pğ‘…ğ‘–ğ‘šâ€²).

Combined, we have Eğ‘šâ€²âˆ¼ğœ‡â€² [

Ã–ğ‘…ğ‘– âˆˆR
ğ‘– ğ‘”ğ‘– (pğ‘…ğ‘–ğ‘šâ€²)] â‰¤

ğ‘– Eğ‘šâ€²âˆ¼ğœ‡â€²ğ‘”ğ‘– (pğ‘…ğ‘–ğ‘šâ€²).

â€¢ When ğ‘“ğ‘– is non-increasing and {ğ‘”ğ‘– } are non-negative non-decreasing, or when ğ‘“ğ‘– is non-
Ã
decreasing and {ğ‘”ğ‘– } are non-negative non-decreasing/non-increasing, the proof is analo-
gous.

Ã

(cid:3)

Lemma 5.5 (Monotone map). Let ğ‘¥, ğ‘¥ğ›¾,ğ›¼ and ğ‘¦ğ›¾ be variables. The following is valid in Xcomb.

ğ‘âŠ›

ğ›¾=0

|=

ğ¾ğ›¾ +1

ğ‘

hğ‘¥ğ›¾,ğ›¼ i

âˆ§

ğ‘¦ğ›¾ = ğ‘“ğ›¾

ğ‘¥ğ›¾,0, . . . , ğ‘¥ğ›¾,ğ¾ğ›¾
(cid:16)

ğ‘âŠ›

ğ›¾=0

â†’

hğ‘¦ğ›¾ i

(cid:17)

Ã›ğ›¼ =0

Â©

Â«

Ã›ğ›¾=0

Âª
Â®
Â¬
ğ¾ğ›¾ +1
ğ›¼ =0 {ğ‘¥ğ›¾,ğ›¼ } | 1 â‰¤ ğ›¾ < ğ‘€} as ğ‘‹ğ‘€ .

when ğ‘“1, . . . , ğ‘“ğ‘ all monotone or all antitone

(Mono-Map)

Proof. Abbreviate {

Ã

ğ‘€ â‰¤ ğ‘ ,

ğ¾ğ›¾ +1
ğ›¼ =0 hğ‘¥ğ›¾,ğ›¼ i), we show by induction on ğ‘€ that: for 1 â‰¤

For any state (ğœ, ğœ‡) satisfying âŠ›ğ‘
ğ›¾=0(
â€¢ (ğœ, ğœ‡) |= âŠ›ğ‘€
ğ¾ğ›¾
ğ›¾=0 (
ğ›¼ =0hğ‘¥ğ›¾,ğ›¼ i);
â€¢ And ğœ‡ satisï¬es ğ‘‹ğ‘€ -PNA implies ğœ‡ satisï¬es ğ‘‹ğ‘ -PNA.
Assuming that it is true for ğ‘€, we show that for ğ‘€âˆ’1. By assumption, (ğœ, ğœ‡) |= âŠ›ğ‘€
ğ›¾=0(
so there exists ğœ‡â€², ğœ‡1, ğœ‡2 such that ğœ‡ âŠ’ ğœ‡â€² âˆˆ ğœ‡1 âŠ• ğœ‡2, (ğœ, ğœ‡1) |= âŠ›ğ‘€âˆ’1
ğ¾ğ›¾ +1
ğ›¼ =0 hğ‘¥ğ›¾,ğ›¼ i) and (ğœ, ğœ‡2) |=
ğ›¾=0 (
Ã“
ğ¾ğ‘€ +1
ğ›¼ =0 hğ‘¥ğ‘€,ğ›¼ i. Thus, ğœ‡â€² is ğ‘‹ğ‘€ -PNA if ğœ‡1 is ğ‘‹ğ‘€âˆ’1-PNA and ğœ‡2 is âˆªğ¾ğ‘€ +1
ğ›¼ =0 {ğ‘¥ğ‘€,ğ›¼ }-PNA. Thus,

Ã“

Ã“

ğ¾ğ›¾ +1
ğ›¼ =0 hğ‘¥ğ›¾,ğ›¼ i),

Ã“

Ã“

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

 
57:42

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

â€¢ By the deï¬nition of âŠ•, we have ğœ‡ âŠ’ ğœ‡1, and by persistence (ğœ, ğœ‡) |= âŠ›ğ‘€âˆ’1
ğ›¾=0 (
â€¢ Since (ğœ, ğœ‡1) |= âŠ›ğ‘€âˆ’1
ğ¾ğ›¾ +1
ğ›¼ =0 hğ‘¥ğ›¾,ğ›¼ i), we have âˆªğ‘‹ğ‘€âˆ’1 is inside dom(ğœ) âˆª dom(ğœ‡1). Thus,
ğ›¾=0 (
Ã“
if ğœ‡ satisï¬es ğ‘‹ğ‘€âˆ’1-PNA, then ğœ‡1 âŠ‘ ğœ‡ satisï¬es ğ‘‹ğ‘€âˆ’1-PNA. Trivially, ğœ‡2 is âˆªğ¾ğ‘€
ğ›¼ =0{ğ‘¥ğ‘€,ğ›¼ }-PNA.
Thus, ğœ‡â€² is ğ‘‹ğ‘€ -PNA, and ğœ‡ is ğ‘‹ğ‘€ -PNA. By inductive assumption, ğœ‡ is ğ‘‹ğ‘ -PNA.

ğ¾ğ›¾ +1
ğ›¼ =0 hğ‘¥ğ›¾,ğ›¼ i);

Ã“

Then, letting ğ‘€ = 1 would give us: ğœ‡ satisï¬es ğ‘‹1-PNA implies ğœ‡ satisï¬es ğ‘‹ğ‘ -PNA. ğ‘‹1 is a partition
of one component, so ğœ‡ satisfying ğ‘‹1-PNA is trivial. Therefore, ğœ‡ satisï¬es ğ‘‹ğ‘ -PNA.

Since

ğ‘
ğ›¾=0 ğ‘¦ğ›¾ = ğ‘“ğ›¾ (ğ‘¥ğ›¾,1, . . . , ğ‘¥ğ›¾,ğ¾ğ›¾ ) and ğ‘“ğ›¾ are all antitone or monotone, by Lemma D.5, ğœ‡ satisï¬es

{{ğ‘¦ğ›¾ } | 1 â‰¤ ğ›¾ < ğ‘ }-PNA. Then we can show (ğœ, ğœ‡) |= âŠ›ğ‘

ğ›¾=1hğ‘¦ğ›¾ i through another simple induc-
tion or by applying the existing theorems. If we do that by applying the theorems, Theorem 4.7
implies that if ğœ‡ satisï¬es {{ğ‘¦ğ›¾ } | 1 â‰¤ ğ›¾ â‰¤ ğ‘ }-PNA, then {{ğ‘¦ğ›¾ } | 1 â‰¤ ğ›¾ â‰¤ ğ‘ } satisï¬es NA in ğœ‡.
Then, by Theorem 5.3, (ğœ, ğœ‡) |= âŠ›ğ‘
(cid:3)

Ã“

ğ›¾=1hğ‘¦ğ›¾ i.

D.3 The restriction property
We prove the restriction on deterministic memories and on randomized memories by separate
induction, and then combine them.

Lemma D.6 (Restriction on deterministic memories). Let (ğœ, ğœ‡) be any conï¬guration in Config,

and let ğœ™ be a ğ‘€-BIrestricted formula interpreted on Xcomb, Then, for any ğ‘š âˆˆ Mem[DV \ FV(ğœ™)],
(ğœ, ğœ‡) |= ğœ™ â‡â‡’ (pFV(ğœ™ )ğœ âŠ²âŠ³ ğ‘š, ğœ‡) |= ğœ™ .

Proof. Note that the two directions are symmetric, so we only prove the forward direction.
We prove it by induction on the syntax of formula. Most cases are straightforward, so we only

show three cases.

ğœ™ = ğ‘ƒ â†’ ğ‘„: Assuming (ğœ, ğœ‡) |= ğ‘ƒ â†’ ğ‘„, that says for any (ğœ â€², ğœ‡â€²) âŠ’ (ğœ, ğœ‡), if (ğœ â€², ğœ‡â€²) |= ğ‘ƒ, then

(ğœ â€², ğœ‡â€²) |= ğ‘„.
ğœ‡) âŠ’ (pFV (ğœ™ )ğœ âŠ²âŠ³ ğ‘š, ğœ‡), it must
For any (
ğœ,
ğœ = pFV(ğœ™ )ğœ âŠ²âŠ³ ğ‘š and the inductive hypothesis, (ğœ,
(ğœ,
Thus, (pFV(ğœ™ )ğœ âŠ²âŠ³ ğ‘š, ğœ‡) |= ğ‘ƒ â†’ ğ‘„.
b

ğœ‡) |= ğ‘ƒ implies (ğœ,
b

b

ğœ‡) |= ğ‘„; and by inductive hypothesis again, (pFV (ğœ™ )ğœ âŠ²âŠ³ ğ‘š,
b

b

b

b

b

ğœ = pFV (ğœ™ )ğœ âŠ²âŠ³ ğ‘š and

ğœ‡ âŠ’ ğœ‡. If (
ğœ‡) |= ğ‘ƒ; since (ğœ, ğœ‡) |= ğ‘ƒ â†’ ğ‘„ and

ğœ,

ğœ‡) |= ğ‘ƒ, then by
ğœ‡ âŠ’ ğœ‡,
ğ‘šğ‘¢) |= ğ‘„,
b

b

|= ğ‘ƒ âŠ› ğ‘„, then there exists (

ğœ™ = ğ‘ƒ âŠ› ğ‘„: Assuming (ğœ, ğœ‡)
ğœ,

ğœ‡), (ğœ1, ğœ‡1), (ğœ2, ğœ2) such that
ğœ‡) âˆˆ (ğœ1, ğœ‡1) âŠ• (ğœ2, ğœ‡2), (ğœ1, ğœ‡1) |= ğ‘ƒ, and (ğœ2, ğœ‡2) |= ğ‘„. By the deï¬nition of

b
(ğœ, ğœ‡) âŠ’ (
the pre-order and âŠ•, it must ğœ =
By inductive hypothesis, (pFV (ğœ™ )ğœ1 âŠ²âŠ³ ğ‘š, ğœ‡1) = (pFV (ğœ™ )ğœ âŠ²âŠ³ ğ‘š, ğœ‡1) |= ğ‘ƒ, and (pFV (ğœ™ )ğœ2 âŠ²âŠ³
ğ‘š, ğœ‡2) = (pFV (ğœ™ )ğœ âŠ²âŠ³ ğ‘š, ğœ‡2) |= ğ‘„. Also,
(pFV (ğœ™ )ğœ âŠ²âŠ³ ğ‘š, ğœ‡) âŠ’ (pFV(ğœ™ )ğœ âŠ²âŠ³ ğ‘š,

ğœ‡) âˆˆ (pFV (ğœ™ )ğœ âŠ²âŠ³ ğ‘š, ğœ‡1) âŠ• (pFV (ğœ™ )ğœ âŠ²âŠ³ ğ‘š, ğœ‡2).

ğœ = ğœ1 = ğœ2, ğœ‡ âŠ’

ğœ‡ âˆˆ ğœ‡1 âŠ• ğœ‡2.
b

c

ğœ,

b

b

b

b

b

So (pFV (ğœ™ )ğœ âŠ²âŠ³ ğ‘š, ğœ‡) |= ğ‘ƒ âŠ› ğ‘„.

ğœ™ = ğ‘ƒ âˆ— ğ‘„ Analogous as the case for ğ‘ƒ âŠ› ğ‘„.
ğœ™ = ğ‘ƒ âˆ’âˆ— ğ‘„: Assuming (ğœ, ğœ‡)

b

|= ğ‘ƒ âˆ’âˆ— ğ‘„, that says for any (ğœ â€²â€², ğœ‡â€²â€²) âˆˆ (ğœ, ğœ‡) âŠ— (ğœ â€², ğœ‡â€²), if

(ğœ â€², ğœ‡â€²) |= ğ‘ƒ, then (ğœ â€²â€², ğœ‡â€²â€²) |= ğ‘„.
For any (ğœ â€²â€², ğœ‡â€²â€²) âˆˆ (pFV (ğœ™ )ğœ âŠ²âŠ³ ğ‘š, ğœ‡) âŠ— (ğœ â€², ğœ‡â€²), it must ğœ â€²â€² = ğœ â€² = pFV (ğœ™ )ğœ âŠ²âŠ³ ğ‘š, ğœ‡â€²â€² âˆˆ ğœ‡ âŠ— ğœ‡â€².
Thus, (ğœ â€², ğœ‡â€²) |= ğ‘ƒ is equivalent to (pFV (ğœ™ )ğœ âŠ²âŠ³ ğ‘š, ğœ‡â€²) |= ğ‘ƒ, and by inductive hypothesis, that
is equivalent to (ğœ, ğœ‡â€²) |= ğ‘ƒ. It also follows that (ğœ, ğœ‡â€²â€²) âˆˆ (ğœ, ğœ‡) âŠ—(ğœ, ğœ‡â€²). Since (ğœ, ğœ‡) |= ğ‘ƒ âˆ’âˆ— ğ‘„
and (ğœ, ğœ‡â€²) |= ğ‘ƒ, we have (ğœ, ğœ‡â€²â€²) |= ğ‘„. By inductive hypothesis, (pFV (ğœ™ )ğœ âŠ²âŠ³ ğ‘š, ğœ‡â€²â€²) |= ğ‘„, and
equivalently (ğœ â€²â€², ğœ‡â€²â€²) |= ğ‘„.
Thus, (pFV(ğœ™ )ğœ âŠ²âŠ³ ğ‘š, ğœ‡) |= ğ‘ƒ âˆ’âˆ— ğ‘„.

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:43

(cid:3)

Lemma D.7 (Restriction on randomized memories). Let (ğœ, ğœ‡) be any conï¬guration in Config,

and let ğœ™ be a ğ‘€-BIrestricted formula interpreted on Xcomb, Then,

(ğœ, ğœ‡) |= ğœ™ â‡â‡’ (ğœ, ğœ‹FV(ğœ™ ) ğœ‡) |= ğœ™ .

Proof. The reverse direction follows by the Kripke monotonicity, and the forward direction
follows by induction on ğœ™. The proof for most of the inductive cases is very similar to the proof
that the probabilistic model in Barthe et al. [2020] satisï¬es restriction. The new inductive case is:
â€¢ ğœ™ â‰¡ ğ‘ƒ âŠ› ğ‘„. Then, ğœ‡ |= ğœ™ iï¬€ there exists ğœ‡â€², ğœ‡1, ğœ‡2 s.t. ğœ‡ âŠ’ ğœ‡â€² âˆˆ ğœ‡1 âŠ• ğœ‡2, ğœ‡1 |= ğ‘ƒ and ğœ‡2 |= ğ‘„.
By induction, ğœ‹ğ¹ğ‘‰ (ğ‘ƒ ) ğœ‡1 |= ğ‘ƒ and ğœ‹ğ¹ğ‘‰ (ğ‘„) ğœ‡2 |= ğ‘„. Note that ğœ‹ğ¹ğ‘‰ (ğ‘ƒ ) ğœ‡1 âŠ‘ ğœ‡1 and ğœ‹ğ¹ğ‘‰ (ğ‘„) ğœ‡2 âŠ‘ ğœ‡2.
By Down-closure, there exists ğœ‡â€²â€² âŠ‘ ğœ‡â€² such that ğœ‡â€²â€² âˆˆ ğœ‹ğ¹ğ‘‰ (ğ‘ƒ ) ğœ‡1 âŠ• ğœ‹ğ¹ğ‘‰ (ğ‘„) ğœ‡2. This ğœ‡â€²â€² satisï¬es
ğ‘ƒ âŠ› ğ‘„. By deï¬nition of âŠ• in the PNA model,

ğ‘‘ğ‘œğ‘š(ğœ‡â€²â€²) = ğ‘‘ğ‘œğ‘š(ğœ‹ğ¹ğ‘‰ (ğ‘ƒ ) ğœ‡1) âˆª ğ‘‘ğ‘œğ‘š(ğœ‹ğ¹ğ‘‰ (ğ‘„) ğœ‡2) = ğ¹ğ‘‰ (ğ‘ƒ) âˆª ğ¹ğ‘‰ (ğ‘„) = ğ¹ğ‘‰ (ğ‘ƒ âŠ› ğ‘„).

Also, by the deï¬nition of the pre-order, ğœ‡â€²â€² âŠ‘ ğœ‡â€² âŠ‘ ğœ‡ implies that ğœ‡â€²â€² = ğœ‹ğ‘‘ğ‘œğ‘š (ğœ‡â€²â€²) ğœ‡ = ğœ‹ğ¹ğ‘‰ (ğœ™ ) ğœ‡.
Thus, ğœ‹ğ¹ğ‘‰ (ğœ™ ) ğœ‡ = ğœ‡â€²â€² |= ğœ™.

(cid:3)

Theorem 5.8 (Restriction). Let (ğœ, ğœ‡) be any conï¬guration, and let ğœ™ be an ğ‘€-BIrestricted formula

interpreted on Xcomb, Then, for any ğ‘š âˆˆ Mem[DV \ FV(ğœ™)],

(ğœ, ğœ‡) |= ğœ™ â‡â‡’ (pFV(ğœ™ )ğœ âŠ²âŠ³ ğ‘š, ğœ‹FV(ğœ™ ) ğœ‡) |= ğœ™ .

Proof. Based on Lemma D.6 and Lemma D.7,

(ğœ, ğœ‡) |= ğœ™ â‡â‡’ (ğœ, ğœ‹ğœ™ ğœ‡) |= ğœ™ â‡â‡’ (pFV (ğœ™ )ğœ âŠ²âŠ³ ğ‘š, ğœ‹FV (ğœ™ ) ğœ‡) |= ğœ™ .

(cid:3)

For the counterexample of the restriction property, we prove a lemma.

Lemma D.8. Let ğœ âˆˆ Mem[DV] be â€œemptyâ€ â€“ let every deterministic variable be undeï¬ned, ğœ‡ be
the uniform distribution over one hot vectors on ğ´, ğµ, and ğœ™ = (U{0,1} hğ¶i) âˆ’âŠ› (hğµi âˆ— hğ¶i). Then,
(ğœ, ğœ‡) |= ğœ™.

Proof. Fix any ğœ‡ğ¶ such that (ğœ, ğœ‡ğ¶ ) |= U{0,1} hğ¶i, which implies that ğœ‹ğ¶ ğœ‡ğ¶ (0) = 0.5 and ğœ‹ğ¶ ğœ‡ğ¶ (1) =

0.5. Fix ğœ‡ğ‘’ âˆˆ ğœ‡ âŠ• ğœ‡ğ¶ .

Since ğµ âˆˆ dom(ğœ‡), ğœ‡ is trivially {{ğµ}}-PNA. Similarly, ğœ‡ğ¶ is trivially {{ğ¶}}-PNA. Thus, ğœ‡ğ‘’ âˆˆ
:

ğœ‡ âŠ• ğœ‡ğ¶ must be {{ğµ}, {ğ¶}}-PNA. Then for any two both monotone or antitone functions ğ‘“
Mem[ğµ] â†’ R+, ğ‘” : Mem[ğ¶] â†’ R+,

Eğ‘šâˆ¼ğœ‡ğ‘’ [ğ‘“ (pğµğ‘š) Â· ğ‘”(pğ¶ğ‘š)] â‰¤ Eğ‘šâˆ¼ğœ‡ğ‘’ [ğ‘“ (pğµğ‘š)] Â· Eğ‘šâˆ¼ğœ‡ğ‘’ [ğ‘”(pğ¶ğ‘š)].

Similarly, ğœ‡ğ‘’ âˆˆ ğœ‡ âŠ• ğœ‡ğ¶ must be {{ğ´}, {ğ¶}}-PNA, and for any two both monotone or antitone
functions ğ‘“ : Mem[ğ´] â†’ R+, ğ‘” : Mem[ğ¶] â†’ R+,

Eğ‘šâˆ¼ğœ‡ğ‘’ [ğ‘“ (pğ´ğ‘š) Â· ğ‘”(pğ¶ğ‘š)] â‰¤ Eğ‘šâˆ¼ğœ‡ğ‘’ [ğ‘“ (pğ´ğ‘š)] Â· Eğ‘šâˆ¼ğœ‡ğ‘’ [ğ‘”(pğ¶ğ‘š)].

(9)

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:44

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

Suppose variables ğµ and ğ¶ are not independent in ğœ‡ğ‘’ , then by Lemma A.1, there must exists
some both monotone or both antitone functions ğ‘“ : Mem[ğµ] â†’ R+, ğ‘” : Mem[ğ¶] â†’ R+ such that

Eğ‘šâˆ¼ğœ‡ğ‘’ [ğ‘“ (pğµğ‘š) Â· ğ‘”(pğ¶ğ‘š)] < Eğ‘šâˆ¼ğœ‡ğ‘’ [ğ‘“ (pğµğ‘š)] Â· Eğ‘šâˆ¼ğœ‡ğ‘’ [ğ‘”(pğ¶ğ‘š)]
â‡â‡’ 0.5 Â· ğ‘“ (0) Â· (ğ‘”(1) Â· ğ‘ƒ (ğ¶ = 1 | ğµ = 0) + ğ‘”(0) Â· ğ‘ƒ (ğ¶ = 0 | ğµ = 0))
+ 0.5 Â· ğ‘“ (1) Â· (ğ‘”(1) Â· ğ‘ƒ (ğ¶ = 1 | ğµ = 1) + ğ‘”(0) Â· ğ‘ƒ (ğ¶ = 0, ğµ = 1))

<(0.5 Â· ğ‘“ (0) + 0.5 Â· ğ‘“ (1)) Â· (0.5 Â· ğ‘”(1) + 0.5 Â· ğ‘”(0)),

where ğ‘ƒ (. . . ) denotes the respective probability that in ğœ‡ğ‘’ . Since ğœ‡ğ‘’ âˆˆ ğœ‡ âŠ• ğœ‡ğ¶ , we have ğœ‡ğ‘’ âŠ’ ğœ‡, and
ğœ‡ being a uniform distribution over one-hot vectors on ğ´, ğµ indicates that for any ğ‘š in the support
of ğœ‡ğ‘’ , ğ´ = 1 iï¬€ ğµ = 0, and ğ´ = 0 iï¬€ ğµ = 1. Therefore, ğ‘ƒ (ğ¶ = ğ‘£ | ğµ = 0) = ğ‘ƒ (ğ¶ = ğ‘£ | ğ´ = 1) and
ğ‘ƒ (ğ¶ = ğ‘£ | ğµ = 1) = ğ‘ƒ (ğ¶ = ğ‘£ | ğ´ = 0). Also, by Bayes theorem, we have

ğ‘ƒ (ğ¶ = ğ‘£ | ğ´ = 0) Â· ğ‘ƒ (ğ´ = 0) + ğ‘ƒ (ğ¶ = ğ‘£ | ğ´ = 1) Â· ğ‘ƒ (ğ´ = 1) = ğ‘ƒ (ğ¶ = ğ‘£)

=â‡’ ğ‘ƒ (ğ¶ = ğ‘£ | ğ´ = 0) Â· 0.5 + ğ‘ƒ (ğ¶ = ğ‘£ | ğ´ = 1) Â· 0.5 = 0.5
â‡â‡’ ğ‘ƒ (ğ¶ = ğ‘£ | ğ´ = 0) = 1 âˆ’ ğ‘ƒ (ğ¶ = ğ‘£ | ğ´ = 1).

Let ğ‘‹ = ğ‘ƒ (ğ¶ = 1 | ğ´ = 1), ğ‘Œ = ğ‘ƒ (ğ¶ = 0 | ğ´ = 1), then we have

0.5 Â· ğ‘“ (0) Â· (ğ‘”(1) Â· ğ‘‹ + ğ‘”(0) Â· ğ‘Œ ) + 0.5 Â· ğ‘“ (1) Â· (ğ‘”(1) Â· (1 âˆ’ ğ‘‹ ) + ğ‘”(0) Â· (1 âˆ’ ğ‘Œ ))

<(0.5 Â· ğ‘“ (0) + 0.5 Â· ğ‘“ (1)) Â· (0.5 Â· ğ‘”(1) + 0.5 Â· ğ‘”(0))

â‡â‡’ ğ‘“ (0) Â· ğ‘”(1) Â· (ğ‘‹ âˆ’ 0.5) + ğ‘“ (0) Â· ğ‘”(0) Â· (ğ‘Œ âˆ’ 0.5) + ğ‘“ (1) Â· ğ‘”(1) Â· (0.5 âˆ’ ğ‘‹ ) + ğ‘“ (1) Â· ğ‘”(0) Â· (0.5 âˆ’ ğ‘Œ ) < 0
â‡â‡’ (ğ‘“ (0) âˆ’ ğ‘“ (1)) Â· ğ‘”(1) Â· (ğ‘‹ âˆ’ 0.5) + (ğ‘“ (0) âˆ’ ğ‘“ (1)) Â· ğ‘”(0) Â· (ğ‘Œ âˆ’ 0.5) < 0
â‡â‡’ 0.5 Â· ğ‘“ (1) Â· (ğ‘”(1) Â· ğ‘‹ + ğ‘”(0) Â· ğ‘Œ ) + 0.5 Â· ğ‘“ (0) Â· (ğ‘”(1) Â· (1 âˆ’ ğ‘‹ ) + ğ‘”(0) Â· (1 âˆ’ ğ‘Œ ))

<(0.5 Â· ğ‘“ (0) + 0.5 Â· ğ‘“ (1)) Â· (0.5 Â· ğ‘”(1) + 0.5 Â· ğ‘”(0)).

Viewing ğ‘“ as a function from Mem[ğ´] to R+, this is equivalent to

Eğ‘šâˆ¼ğœ‡ğ‘’ [ğ‘“ (pğ´ğ‘š) Â· ğ‘”(pğ¶ğ‘š)] < Eğ‘šâˆ¼ğœ‡ğ‘’ [ğ‘“ (pğ´ğ‘š)] Â· Eğ‘šâˆ¼ğœ‡ğ‘’ [ğ‘”(pğ¶ğ‘š)].

The last inequality contradicts Equation (9).

Therefore, ğµ and ğ¶ must be independent in ğœ‡ğ‘’ . Hence, ğœ‡ğ‘’ |= hğµi âˆ— hğ¶i, and ğœ‡ |= ğœ™.

(cid:3)

Theorem 5.9. There exists (ğœ, ğœ‡) âˆˆ Config and formula ğœ™ such that (ğœ, ğœ‡) |= ğœ™ but (ğœ, ğœ‹FV(ğœ™ )) 6|= ğœ™.

Proof. Let ğ´, ğµ, ğ¶ be three variables in RV. Let ğœ™ = (U{0,1} hğ¶i) âˆ’âŠ› (hğµi âˆ— hğ¶i). Let ğœ be
a deterministic memory where every deterministic variable is undeï¬ned, and ğœ‡ be the uniform
distribution over one hot vectors on ğ´, ğµ. Then, we claim (ğœ, ğœ‡) |= ğœ™ but (ğœ, ğœ‹ {ğµ,ğ¶ }ğœ‡) 6|= ğœ™. For
(ğœ, ğœ‡) |= ğœ™, it suï¬ƒces to show that for any ğœ‡ğ¶ where ğ¶â€™s value is the uniform distribution on {0, 1},
for any ğœ‡â€² âŠ’ ğœ‡, and ğœ‡ğ‘’ âˆˆ ğœ‡â€² âŠ• ğœ‡ğ¶ , ğµ and ğ¶ are independent in ğœ‡ğ‘’ according to Lemma D.8. The
intuition is that ğœ‡ğ‘’ must satisï¬es {ğµ, ğ¶}-PNA and {ğ´, ğ¶}-PNA, and since ğ´â€™s value is always the
opposite of ğµâ€™s value, (ğµ, ğ¶) has to satisfy pairwise independence in ğœ‡ğ‘’ . To show (ğœ, ğœ‹ {ğµ,ğ¶ }ğœ‡) 6|= ğœ™,
we ï¬rst note that ğœ‹ {ğµ,ğ¶ }ğœ‡ = ğœ‹ {ğµ }ğœ‡ is a uniform distribution of 0 and 1 on ğµ. Let ğœ‡â€²
ğ¶ âˆˆ D (Mem[{ğ¶}])
be the uniform distribution on {0, 1}, ğœ‡â€² âˆˆ D (Mem[{ğµ, ğ¶}]) be the uniform distribution over one-
6|= hğµi âˆ— hğ¶i. Also, ğœ‡â€² is in
hot vectors on ğµ, ğ¶. Clearly, ğµ, ğ¶ are not independent in ğœ‡â€², so ğœ‡â€²
(cid:3)
ğœ‹ {ğµ,ğ¶ }ğœ‡ âŠ• ğœ‡â€²

ğ¶ . So ğœ‹ğµ,ğ¶ ğœ‡ 6|= U{0,1} hğ¶i âˆ’âŠ› (hğ´i âˆ— hğ¶i).

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:45

D.4 The proof system of the program logic

The proof for the soundness of the frame rule relies on the following corollary of Lemma D.5.

Lemma D.9 (Monotone map closure PNA (specific case)). Let ğ‘†,ğ‘‡ âŠ† Var be two disjoint sets of
variables, and T is sub-partition of ğ‘‡ . Suppose that ğ‘“ : Mem[ğ‘†] â†’ Mem[ğ‘† â€²] is a monotonically non-
decreasing non-negative function, and ğ‘† â€² disjoint from ğ‘‡ . If ğœ‡ with domain ğ‘† âˆªğ‘‡ satisï¬es {ğ‘† }âˆªT -PNA,
then bind(ğœ‡, ğ‘š â†¦â†’ unit(ğ‘“ (ğœ‹ğ‘†ğ‘š)) âŠ• unit(ğœ‹ğ‘‡ğ‘š)) âˆˆ D (Mem[ğ‘† â€² âˆª ğ‘‡ ]) satisï¬es {ğ‘† â€²} âˆª T -PNA.

Proof. We can reduce to Lemma D.5: Let ğ‘†1 = ğ‘†, ğ‘‡1 = ğ‘† â€², and {ğ‘†2, . . . , ğ‘†ğ‘›} = {ğ‘‡2, . . . ,ğ‘‡ğ‘›} = T .
Let ğ‘“1 = ğ‘“ and the rest of ğ‘“ğ‘– to be the identity map. Note that we have assumed to only work
with non-negative values, so identity maps are also monotonically non-decreasing non-negative
(cid:3)
function.

Theorem 5.11. (Soundness of LINA) If âŠ¢ {ğœ™ } ğ‘ {ğœ“ } is derivable, then it is valid: |= {ğœ™ } ğ‘ {ğœ“ }.

Proof. We only prove the cases not already in Barthe et al. [2020].
Rule: Cond. For any conï¬guration (ğœ, ğœ‡)

|= ğœ™, by side-condition that |= ğœ™ â†’ Detmhğ‘i,
(ğœ, ğœ‡) |= Detmhğ‘i. Thus, Jğ‘K(ğœ, ğœ‡) must be a Dirac distribution. Since the commands are
well-typed, Jğ‘K(ğœ, ğœ‡) is a distribution over booleans. So Jğ‘K(ğœ, ğœ‡) is either a Dirac distribu-
tion of truthful value tt or a Dirac distribution of false value ï¬€ .
If Jğ‘K(ğœ, ğœ‡) is a Dirac distribution of truthful value tt, then for any ğ‘š in the support of ğœ‡,
Jğ‘K(ğœ, ğ‘š) = tt, and thus, (ğœ, ğœ‡) |= ğœ™ âˆ§ ğ‘ âˆ¼ tt. By the side-condition âŠ¢ {ğœ™ âˆ§ ğ‘ âˆ¼ tt} ğ‘ {ğœ“ } and
inductive hypothesis that this judgement is sound, Jğ‘K(ğœ, ğœ‡) |= ğœ“ . When Jğ‘K(ğœ, ğœ‡) = ğ›¿ (tt),
the semantics say that Jif ğ‘ then ğ‘ else ğ‘ â€²K(ğœ, ğœ‡) = Jğ‘K(ğœ, ğœ‡) |= ğœ“ .
Symmetrically, when Jğ‘K(ğœ, ğœ‡) = ğ›¿ (ï¬€ ), Jif ğ‘ then ğ‘ else ğ‘ â€²K(ğœ, ğœ‡) = Jğ‘ â€²K(ğœ, ğœ‡) |= ğœ“ .

Rule: Loop. For any (ğœ, ğœ‡) |= ğœ™, the side condition implies (ğœ, ğœ‡) |= Detmhğ‘i. We show by
induction that for any ğ‘›, J(if ğ‘… ğ‘ then ğ‘)ğ‘›K(ğœ, ğœ‡) |= ğœ™ âˆ§Detmhğ‘i, and J(if ğ‘… ğ‘ then ğ‘)ğ‘›K(ğœ, ğœ‡) |=
ğœ™ âˆ§ ğ‘ âˆ¼ ï¬€ implies J(if ğ‘… ğ‘ then ğ‘)ğ‘›+1K(ğœ, ğœ‡) |= ğœ™ âˆ§ ğ‘ âˆ¼ ï¬€ .
Say (ğœ â€², ğœ‡â€²) = J(if ğ‘… ğ‘ then ğ‘)ğ‘›K(ğœ, ğœ‡). Assuming (ğœ â€², ğœ‡â€²) |= ğœ™ âˆ§ Detmhğ‘i, there are two
possibilities:
â€¢ (ğœ â€², ğœ‡â€²) |= ğœ™ âˆ§ ğ‘ âˆ¼ ï¬€ , then

J(if ğ‘… ğ‘ then ğ‘)ğ‘›+1K(ğœ, ğœ‡) = Jif ğ‘… ğ‘ then ğ‘K(ğœ â€², ğœ‡â€²) = (ğœ â€², ğœ‡â€²) |= ğœ™ âˆ§ ğ‘ âˆ¼ ï¬€ .

â€¢ (ğœ â€², ğœ‡â€²) |= ğœ™ âˆ§ ğ‘ âˆ¼ tt, then

J(if ğ‘… ğ‘ then ğ‘)ğ‘›+1K(ğœ, ğœ‡) = Jif ğ‘… ğ‘ then ğ‘K(ğœ â€², ğœ‡â€²) = Jğ‘K(ğœ â€², ğœ‡â€²) |= ğœ™,

where the last satisfaction is guaranteed by âŠ¢ {ğœ™ âˆ§ ğ‘ âˆ¼ tt} ğ‘ {ğœ™ }. Since |= ğœ™ â†’ Detmhğ‘i,
so Jif ğ‘… ğ‘ then ğ‘K(ğœ â€², ğœ‡â€²) |= ğœ™ âˆ§ Detmhğ‘i.

Since we assumed that the loop ends in ï¬nite step, there exists a ï¬nite number ğ‘ such that
J(if ğ‘… ğ‘ then ğ‘)ğ‘ K(ğœ, ğœ‡) |= ğœ™ âˆ§ğ‘ âˆ¼ ï¬€ and also J(if ğ‘… ğ‘ then ğ‘)ğ‘ âˆ’1K(ğœ, ğœ‡) |= ğœ™ âˆ§ğ‘ âˆ¼ tt if ğ‘ > 1.
Then Jwhile ğ‘ do ğ‘K(ğœ, ğœ‡) = J(if ğ‘… ğ‘ then ğ‘)ğ‘ K(ğœ, ğœ‡) |= ğœ™ âˆ§ ğ‘ âˆ¼ ï¬€ .

Rule: RCase. For any (ğœ, ğœ‡) |= ğœ™ âˆ— ğœ‚, there exists ğœ‡â€², ğœ‡1, ğœ‡2 such that ğœ‡ âŠ’ ğœ‡â€² âˆˆ ğœ‡1 âŠ• ğœ‡2 and

(ğœ, ğœ‡1) |= ğœ™, (ğœ, ğœ‡2) |= ğœ‚.
Say ğœ‡2 is in D (Mem[ğ‘‡ ]), then for any ğ‘š in the support of ğœ‡2, the conditional distribution
ğœ‡2 | ğ‘‡ = ğ‘š is a Dirac distribution of ğ‘š, i.e., ğ›¿ (ğ‘š). Since ğœ‚ âˆˆ CC (closed under conditioning), so
ğ›¼ âˆˆğ‘† ğœ‚ğ›¼ . Then, there exists ğ›¼ such that (ğœ, ğ›¿ (ğ‘š)) |= ğœ‚ğ›¼ .
(ğœ, ğ›¿ (ğ‘š)) |= ğœ‚, and thus (ğœ, ğ›¿ (ğ‘š)) |=
Since dom(ğœ‡1) and dom(ğœ‡2) are independent in ğœ‡â€², the conditional distribution ğœ‡â€² | ğ‘‡ = ğ‘š
is in ğœ‡1 âŠ• ğ›¿ (ğ‘š). So ğœ‡â€²
| ğ‘‡ = ğ‘š |= ğœ™ âˆ— ğœ‚ğ›¼ . By the side-condition âŠ¢ ğœ™ âˆ— ğœ‚ğ›¼ and inductive
hypothesis that it is sound, we have Jğ‘K(ğœ, ğœ‡â€² | ğ‘‡ = ğ‘š) |= ğœ“ .

Ã”

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:46

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

For any command ğ‘, any condition ğ‘, let (ğœğ‘, ğœ‡ğ‘) = Jğ‘K(ğœ, ğœ‡â€² | ğ‘) and (ğœğ‘, ğœ‡Â¬ğ‘ ) = Jğ‘K(ğœ, ğœ‡â€² |
Â¬ğ‘). We can show by induction on the semantics of commands that Jğ‘K(ğœ, ğœ‡â€²) is a convex
| ğ‘) â—¦ğœ‡â€² (ğ‘=tt) (ğœ‡â€²
combination of (ğœ, ğœ‡â€²
| Â¬ğ‘)).
Thus, Jğ‘K(ğœ, ğœ‡â€²) is a convex combination of all Jğ‘K(ğœ, ğœ‡â€²
| ğ‘‡ = ğ‘š), where ğ‘š in the sup-
port of ğœ‡â€². Since each of Jğ‘K(ğœ, ğœ‡â€²
| ğ‘‡ = ğ‘š) satisï¬es ğœ“ and ğœ“ is closed under mixture, we
have Jğ‘K(ğœ, ğœ‡â€²) |= ğœ“ . We can also show by induction on the semantics of commands that
Jğ‘K(ğœ, ğœ‡) âŠ’ Jğ‘K(ğœ, ğœ‡â€²) if ğœ‡ âŠ’ ğœ‡â€². So by persistence Jğ‘K(ğœ, ğœ‡) |= ğœ“ .

| Â¬ğ‘): Jğ‘K(ğœ, ğœ‡â€²) = (ğœ, (ğœ‡â€²

| ğ‘) and (ğœ, ğœ‡â€²

Rule: ProbBound. For any program state (ğœ, ğœ‡) |= Pr[ğ‘’ğ‘£1] â‰¥ 1âˆ’ğœ–, let event ğ‘’ğ‘£ğœ

1 : Mem[dom(ğœ‡)] â†’

{0, 1} be the result of partially interpreting ğ‘’ğ‘£1 on ğœ, i.e., ğ‘’ğ‘£ğœ
1
the function ğœ†ğ‘¥ .1 âˆ’ ğ‘’ğ‘£ğœ
1 . We also write Prğœ‡ [ğ‘’ğ‘£ğœ
1 (ğ‘¥) as Â¬ğ‘’ğ‘£ğœ
1 ] for
ğ‘’ğ‘£ğœ
We can express ğœ‡ as the convex combination of two conditional distributions, i.e.,

= curry(Jğ‘’ğ‘£1K) (ğœ), and denote
ğ‘š âˆˆD (Mem [dom(ğœ‡) ]) ğœ‡(ğ‘š) Â·

1 (ğ‘š).

Ã

ğœ‡ = Pr
ğœ‡

[ğ‘’ğ‘£ğœ

1 ] Â· (ğœ‡ | ğ‘’ğ‘£ğœ

1 ) + Pr
ğœ‡

[Â¬ğ‘’ğ‘£ğœ

1 ] Â· (ğœ‡ | Â¬ğ‘’ğ‘£ğœ

1 ).

1

) = Jğ‘K(ğœ, (ğœ‡ | ğ‘’ğ‘£ğœ

Let (ğœ â€², ğœ‡ğ‘’ğ‘£ğœ
variables in the deterministic memories, there exists probabilistic memories ğœ‡Â¬ğ‘’ğ‘£ğœ
1
(ğœ â€², ğœ‡Â¬ğ‘’ğ‘£ğœ
) = Jğ‘K(ğœ, (ğœ‡ | Â¬ğ‘’ğ‘£ğœ
prove that Jğ‘K(ğœ, ğœ‡) = (ğœ â€², ğœ‡ğ‘’ğ‘£ğœ
By construction, Jğ‘’ğ‘£1K(ğœ, (ğœ‡ | ğ‘’ğ‘£ğœ
inductive hypothesis, we have |= {ğ‘’ğ‘£1} ğ‘ {Pr[ğ‘’ğ‘£2] â‰¥ 1 âˆ’ ğ›¿ }, which implies

1 )). Since assignments to deterministic memories can only use
such that
1 )). Then, by induction on the denotational semantics, we can

â—¦Prğœ‡ [ğ‘’ğ‘£ğœ
1 ] ğœ‡Â¬ğ‘’ğ‘£ğœ
1 )) = 1, so (ğœ, (ğœ‡ | ğ‘’ğ‘£ğœ

1 )) |= ğ‘’ğ‘£1. Also, by the assumption and

).

1

1

1

Jğ‘K(ğœ, (ğœ‡ | ğ‘’ğ‘£ğœ

1 )) = (ğœ â€², ğœ‡ğ‘’ğ‘£ğœ

1

) |= Pr[ğ‘’ğ‘£2] â‰¥ 1 âˆ’ ğ›¿.

By deï¬nition, that means Pr(ğœâ€²,ğœ‡ğ‘’ğ‘£ğœ

1

) [ğ‘’ğ‘£2] â‰¥ 1 âˆ’ ğ›¿. Then, by the law of total probability,

(ğœâ€²,ğœ‡ğ‘’ğ‘£ğœ
1

Pr
â—¦Prğœ‡ [ğ‘’ğ‘£ğœ
1

] ğœ‡Â¬ğ‘’ğ‘£)

[ğ‘’ğ‘£ğœ

1 ] â‰¤

Pr
(ğœâ€²,ğœ‡ğ‘’ğ‘£ğœ
1
â‰¤ ğ›¿ + Pr
ğœ,ğœ‡

â‰¤ ğ›¿ + ğœ–

[ğ‘’ğ‘£2] + Pr
ğœ‡

)

[Â¬ğ‘’ğ‘£ğœ
1 ]

[Â¬ğ‘’ğ‘£1]

(because Prğœ‡ [Â¬ğ‘’ğ‘£ğœ

1 ] = Prğœ,ğœ‡ [Â¬ğ‘’ğ‘£1])
(because (ğœ, ğœ‡) |= Pr[ğ‘’ğ‘£1] â‰¥ 1 âˆ’ ğœ–,)

Therefore, Jğ‘K(ğœ, ğœ‡) |= Pr[ğ‘’ğ‘£2] â‰¤ ğ›¿ + ğœ–.

Rule: NegFrame. For any (ğœ, ğœ‡) |= ğ‘’ğ‘£1 âˆ— ğœ‚, there exists ğ‘˜1, ğ‘˜2, ğœ‡â€² such that ğœ‡ âŠ’ ğœ‡â€² âˆˆ ğ‘˜1 âŠ• ğ‘˜2,

and (ğœ, ğ‘˜1) |= ğœ™ and (ğœ, ğ‘˜2) |= ğœ‚.
Let ğ‘†1 , dom(ğ‘˜1), and note that (ğœ, ğ‘˜1) |= ğœ™ and |= ğœ™ â†’ hRV(ğ‘)i implies (ğœ, ğ‘˜1) |= hRV(ğ‘)i,
and thus RV(ğ‘) âˆ© RV âŠ† ğ‘†1. Let ğ‘†2 , dom(ğ‘˜2) âˆ© FV(ğœ‚). Then, MV(ğ‘) is disjoint from ğ‘†2
because ğ‘†2 âŠ† FV(ğœ‚) and FV(ğœ‚) âˆ© MV(ğ‘) = âˆ…; also, by restriction, (ğœ, ğœ‹ğ‘†2ğ‘˜2) |= ğœ‚.
Since ğ‘˜1 âŠ• ğ‘˜2 is non-empty, ğ‘‘ğ‘œğ‘š(ğ‘˜1), ğ‘‘ğ‘œğ‘š(ğ‘˜2) are disjoint; since ğ‘†1 = ğ‘‘ğ‘œğ‘š(ğ‘˜1), ğ‘†2 âŠ† ğ‘‘ğ‘œğ‘š(ğ‘˜2),
ğ‘†1, ğ‘†2 are disjoint.
Let (ğœğ‘’, ğœ‡ğ‘’ ) = Jğ‘K(ğœ, ğœ‡). Denote RV(ğ‘) âˆ© DV as ğ‘…1, MV(ğ¶) âˆ© DV as ğ‘€1, RV(ğ‘) âˆ© RV as
ğ‘…2, MV(ğ¶) âˆ© RV as ğ‘€2. By the soundness of RV, WV, and MV, there exists ğº : Mem[ğ‘…1] â†’
Mem[ğ‘€1], ğ¹ : Mem[RV(ğ‘)] â†’ D (Mem[ğ‘€2]) such that:
ğœğ‘’ = ğº (pğ‘…1ğœ) âŠ²âŠ³ pD V\ğ‘€1ğœ
ğœ‡ğ‘’ = bind(ğœ‡, ğ‘š â†¦â†’ ğ¹ (pğ‘…1ğœ âŠ²âŠ³ pğ‘…2ğ‘š) âŠ— unit(pdom(ğœ‡)\ğ‘€2ğ‘š)).

Since ğ‘…2 âŠ† ğ‘†1, and ğ‘†2 is disjoint of ğ‘†1 and MV(ğ‘), we have

ğœ‹ğ‘€2âˆªğ‘†1âˆªğ‘†2 ğœ‡ğ‘’ = bind(ğœ‹ğ‘†1âˆªğ‘†2 ğœ‡, (ğ‘š1, ğ‘š2) â†¦â†’ ğ¹ (pğ‘…1ğœ âŠ²âŠ³ pğ‘…2ğ‘š1) âŠ— unit(pğ‘†1\ğ‘€2ğ‘š1) âŠ— unit(ğ‘š2)).

(10)
One implication is that (ğœğ‘’, ğœ‹ğ‘†2 ğœ‡ğ‘’ ) |= ğœ‚: Equation (10) implies that ğœ‹ğ‘†2 ğœ‡ğ‘’ = ğœ‹ğ‘†2 ğœ‡. We (ğœ, ğœ‹ğ‘†2 ğœ‡) |=
ğœ‚, so (ğœ, ğœ‹ğ‘†2 ğœ‡ğ‘’ ) |= ğœ‚. By restriction, for any ğ‘š âˆˆ Mem[DV \ FV(ğœ‚)], (pFV (ğœ‚)ğœ âŠ²âŠ³ ğ‘š, ğœ‹ğ‘†2 ğœ‡ğ‘’ ) |=

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:47

ğœ‚. Since ğœğ‘’ = ğº (pğ‘…1ğœ) âŠ²âŠ³ pD V\ğ‘€1ğœ, and FV(ğœ‚) âˆ© MV(ğ‘) = âˆ… implies that FV(ğœ‚) âˆ© DV âŠ†
DV \ ğ‘€1, and (ğœğ‘’, ğœ‹ğ‘†2 ğœ‡ğ‘’ ) |= ğœ‚.
If ğ‘¦ âˆˆ DV, then Jğ‘¦K(ğœğ‘’, ğ‘šğ¹ âŠ²âŠ³ pğ‘‹ âˆ©R Vğ‘š) = ğœğ‘’ (ğ‘¦). Thus, (ğœğ‘’, ğ‘¡) |= hğ‘¦i where ğ‘¡ is the trivial
distribution in D (Mem[âˆ…]). Also, (ğœğ‘’, ğœ‡ğ‘’ ) âˆˆ (ğœğ‘’, ğ‘¡) â—¦ (ğœğ‘’, ğœ‡ğ‘’ ), where (ğœğ‘’, ğœ‡ğ‘’ ) âŠ’ (ğœğ‘’, ğœ‹ğ‘†2 ğœ‡ğ‘’ ) |=
ğœ‚. So (ğœğ‘’, ğœ‡ğ‘’ ) |= ğœ‚.
If ğ‘¦ âˆ‰ MV(ğ‘), then {ğ‘¦} âˆª ğ‘†2 âŠ† dom(ğœ‡) \ MV(ğ‘), and thus ğœ‹ {ğ‘¦ }âˆªğ‘†2 ğœ‡ğ‘’ = ğœ‹ {ğ‘¦ }âˆªğ‘†2 ğœ‡.
â€¢ Since âŠ¢ {ğœ™ } ğ‘ {ğ‘¦ âˆ¼ ğ‘“ (ğ‘‹ )}, by inductive assumption we have Jğ‘K(ğœ, ğ‘˜1) |= ğ‘¦ âˆ¼ ğ‘“ (ğ‘‹ ). Up-
dates to deterministic variables only depend on deterministic program state, so Jğ‘K(ğœ, ğ‘˜1) =
(ğœğ‘’, ğœ‡ğ‘˜ ) for some ğœ‡ğ‘˜ . And ğ‘¦ âˆ‰ MV(ğ‘) implies that ğœ‹ {ğ‘¦ }ğœ‡ğ‘˜ = ğœ‹ {ğ‘¦ }ğœ‡ = ğœ‹ {ğ‘¦ }ğ‘˜1. The restriction
property and Jğ‘K(ğœ, ğ‘˜1) |= ğ‘¦ âˆ¼ ğ‘“ (ğ‘‹ ) implies (ğœğ‘’, ğœ‹ {ğ‘¦ }ğ‘˜1) = (ğœğ‘’, ğœ‹ {ğ‘¦ }ğœ‡ğ‘˜ ) |= hğ‘¦i.

â€¢ (ğœğ‘’, ğœ‹ğ‘†2 ğœ‡) |= ğœ‚.
â€¢ ğœ‡ âŠ’ ğœ‡â€² âˆˆ ğ‘˜1 âŠ• ğ‘˜2, so ğœ‹ {ğ‘¦ }âˆªğ‘†2 ğœ‡ âˆˆ ğœ‹ {ğ‘¦ }ğ‘˜1 âŠ• ğœ‹ğ‘†2ğ‘˜2 too.
Therefore, (ğœğ‘’, ğœ‹ {ğ‘¦ }âˆªğ‘†2 ğœ‡) |= hğ‘¦i âŠ› ğœ‚. Since (ğœğ‘’, ğœ‡ğ‘’ ) âŠ’ (ğœğ‘’, ğœ‹ {ğ‘¦ }âˆªğ‘†2 ğœ‡ğ‘’ ) = (ğœğ‘’, ğœ‹ {ğ‘¦ }âˆªğ‘†2 ğœ‡), by
persistence, (ğœğ‘’, ğœ‡ğ‘’ ) |= hğ‘¦i âŠ› ğœ‚.
If ğ‘¦ âˆˆ RV and ğ‘¦ âˆˆ MV(ğ‘), our overall strategy is to ï¬rst connect ğ¹ with ğ‘“ and show
the operation on variable ğ‘¦ is a monotone map, and then apply monotone map closure to
establish the NA between ğ‘¦ and ğœ‚.
Since (ğœ, ğœ‹ğ‘†1 ğœ‡) = (ğœ, ğ‘˜1) |= ğœ™, by persistence (ğœ, ğœ‡) |= ğœ™. By side-condition that âŠ¢ {ğœ™ }ğ‘{ğ‘¦ âˆ¼
ğ‘“ (ğ‘‹ )} and by induction that the proof rules are sound, it must Jğ‘K(ğœ, ğœ‡) = (ğœğ‘’, ğœ‡ğ‘’ ) |= ğ‘¦ âˆ¼
ğ‘“ (ğ‘‹ ). By restriction, (ğœğ‘’, ğœ‹ğ‘‹ âˆª{ğ‘¦ }ğœ‡ğ‘’ ) |= ğ‘¦ âˆ¼ ğ‘“ (ğ‘‹ ).
Since ğ‘‹ âˆ© RV âŠ† (RV(ğ‘) âˆ© RV) \ MV(ğ‘) âŠ† ğ‘†1 \ MV(ğ‘) and ğ‘¦ âˆˆ MV(ğ‘),

ğœ‹ğ‘‹ âˆª{ğ‘¦ }ğœ‡ğ‘’ = ğœ‹ğ‘‹ âˆª{ğ‘¦ }ğœ‹ğ‘†1âˆªMV(ğ‘) Jğ‘Kğœ‡

= ğœ‹ğ‘‹ âˆª{ğ‘¦ }bind(ğœ‹ğ‘†1 ğœ‡, ğ‘š â†¦â†’ ğ¹ (pğ‘…1ğœ âŠ²âŠ³ pğ‘…2ğ‘š) âŠ— unit(pğ‘†1\ğ‘€2ğ‘š))
= bind(ğœ‹ğ‘†1 ğœ‡, ğ‘š â†¦â†’ ğœ‹ {ğ‘¦ }ğ¹ (pğ‘…1ğœ âŠ²âŠ³ pğ‘…2ğ‘š) âŠ— unit(pğ‘‹ âˆ©R Vğ‘š))
Since (ğœğ‘’, ğœ‹ğ‘‹ âˆª{ğ‘¦ }ğœ‡ğ‘’ ) |= ğ‘¦ âˆ¼ ğ‘“ (ğ‘‹ ), for every ğ‘šğ‘’ in the support of ğœ‹ğ‘‹ âˆª{ğ‘¦ }ğœ‡ğ‘’ , we have Jğ‘¦K(ğœğ‘’, ğ‘šğ‘’) =
Jğ‘“ (ğ‘‹ )K(ğœğ‘’, ğ‘šğ‘’). By Equation (11), a memory ğ‘šğ‘’ is in the support of ğœ‹ğ‘‹ âˆª{ğ‘¦ }ğœ‡ğ‘’ if and only if
there exists some ğ‘š, ğ‘šğ¹ such that ğ‘š is in the support of ğœ‡, and ğ‘šğ¹ is in the support of
ğœ‹ {ğ‘¦ }ğ¹ (pğ‘…1ğœ âŠ²âŠ³ pğ‘…2ğ‘š), and ğ‘šğ‘’ = ğ‘šğ¹ âŠ²âŠ³ pğ‘‹ âˆ©R Vğ‘š. Thus, the condition we have is: for every ğ‘š
is in the support of ğœ‡ and ğ‘šğ¹ is in the support of ğœ‹ {ğ‘¦ }ğ¹ (pğ‘…1ğœ âŠ²âŠ³ pğ‘…2ğ‘š),
Jğ‘¦K(ğœğ‘’, ğ‘šğ¹ âŠ²âŠ³ pğ‘‹ âˆ©R Vğ‘š) = Jğ‘“ (ğ‘‹ )K(ğœğ‘’, ğ‘šğ¹ âŠ²âŠ³ pğ‘‹ âˆ©R Vğ‘š).

(11)

Since ğ‘“ does not depend on states and ğ‘‹ do not depend on ğ‘šğ¹ , we also have that Jğ‘“ (ğ‘‹ )K(ğœğ‘’, ğ‘šğ¹ âŠ²âŠ³
pğ‘‹ âˆ©R Vğ‘š) = Jğ‘“ (ğ‘‹ )K(ğœ, ğ‘š).
If ğ‘¦ âˆˆ RV, then Jğ‘¦K(ğœğ‘’, ğ‘šğ¹ âŠ²âŠ³ pğ‘‹ âˆ©R Vğ‘š) = ğ‘šğ¹ (ğ‘¦), so it must ğ‘šğ¹ (ğ‘¦) = Jğ‘“ (ğ‘‹ )K(ğœ, ğ‘š). so
although ğ¹ is a randomized function according to its type, for any ğ‘š in the support of ğœ‡,
ğœ‹ {ğ‘¦ }ğ¹ (pğ‘…1ğœ âŠ²âŠ³ pğ‘…2ğ‘š) is a Dirac distribution:

ğœ‹ {ğ‘¦ }ğ¹ (pğ‘…1ğœ âŠ²âŠ³ pğ‘…2ğ‘š) = ğ›¿ (Jğ‘“ (ğ‘‹ )K(ğœ, ğ‘š)).

Fixing ğœ, then there exists ğ‘“ â€² such that Jğ‘“ (ğ‘‹ )K(ğœ, ğ‘š) = ğ‘“ â€²(pğ‘‹ âˆ©R Vğ‘š) and ğ‘“ â€² is monotone as
ğ‘“ is monotone. Since ğ‘‹ âˆ© RV âŠ† ğ‘†1, we can also make ğ‘“ â€² to have type Mem[ğ‘†1] â†’ Val.
Thus,

ğœ‹ {ğ‘¦ }âˆªğ‘†2 ğœ‡ğ‘’ = bind(ğœ‹ğ‘†1âˆªğ‘†2 ğœ‡, (ğ‘š1, ğ‘š2) â†¦â†’ ğœ‹ğ‘¦ğ¹ (pğ‘…1ğœ âŠ²âŠ³ pğ‘…2ğ‘š1) âŠ— unit(ğ‘š2))
= bind(ğœ‹ğ‘†1âˆªğ‘†2 ğœ‡, (ğ‘š1, ğ‘š2) â†¦â†’ unit(Jğ‘“ (ğ‘‹ )K(ğœ, ğ‘š1)) âŠ— unit(ğ‘š2))
= bind(ğœ‹ğ‘†1âˆªğ‘†2 ğœ‡, (ğ‘š1, ğ‘š2) â†¦â†’ unit(ğ‘“ â€²(ğ‘š1)) âŠ— unit(ğ‘š2)).

Let ğœ‡ğ‘ = ğœ‹ {ğ‘¦ }âˆªğ‘†2 (ğœ‡ğ‘’ ). We will then show that (ğœğ‘’, ğœ‡ğ‘ ) |= hğ‘¦i âˆ— ğœ‚.
Let ğ‘”1 = ğœ‹ğ‘¦ (ğœ‡ğ‘’ ), ğ‘”2 = ğœ‹ğ‘†2 ğœ‡, it suï¬ƒces to show that ğœ‡ğ‘ âˆˆ ğ‘”1 âŠ• ğ‘”2. and ğ‘”1 |= hğ‘¦i, ğ‘”2 |= ğœ‚:

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:48

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

â€¢ (ğœğ‘’, ğœ‡ğ‘’ ) |= ğ‘¦ âˆ¼ ğ‘“ (ğ‘‹ ), so (ğœğ‘’, ğœ‡ğ‘’ ) |= hğ‘¦i. By restriction, (ğœğ‘’, ğ‘”1) |= hğ‘¦i.
â€¢ ğ‘”2 = ğœ‹ğ‘†2 ğœ‡ = ğœ‹ğ¹ğ‘‰ (ğœ‚)ğœ‹ğ‘‘ğ‘œğ‘š (ğ‘˜2) ğœ‡ = ğœ‹ğ¹ğ‘‰ (ğœ‚)ğ‘˜2, so (ğœ, ğ‘”2) |= ğœ‚. By Lemma D.6, for any ğ‘š âˆˆ
Mem[DV \ FV(ğœ‚)], (pFV (ğœ‚)ğœ âŠ²âŠ³ ğ‘š, ğ‘”2) |= ğœ‚. Since ğœğ‘’ = ğº (pğ‘…1ğœ) âŠ²âŠ³ pD V\ğ‘€1ğœ, and FV(ğœ‚) âˆ©
MV(ğ‘) = âˆ… implies that FV(ğœ‚) âŠ† DV \ ğ‘€1, (ğœğ‘’, ğ‘”2) |= ğœ‚.
â€¢ First, ğœ‹ {ğ‘¦ }ğœ‡ğ‘ = ğœ‹ {ğ‘¦ }ğœ‡ğ‘’ = ğ‘”1, and ğœ‹ğ‘†2 ğœ‡ğ‘ = ğœ‹ğ‘†2 ğœ‡ğ‘’ = ğœ‹ğ‘†2 ğœ‡ = ğ‘”2.

Second, ğœ‹ğ‘‘ğ‘œğ‘š (ğ‘˜1)âˆªğ‘‘ğ‘œğ‘š (ğ‘˜2) ğœ‡ âˆˆ ğ‘˜1 âŠ• ğ‘˜2 implies that ğœ‹ğ‘‘ğ‘œğ‘š (ğ‘˜1)âˆªğ‘‘ğ‘œğ‘š (ğ‘˜2) ğœ‡ is Sâ€² âˆª T â€²-PNA for any
Sâ€², T â€² such that ğ‘˜1 is Sâ€²-PNA, ğ‘˜2 is T â€²-PNA. Because ğœ‹ğ‘†1 ğœ‡ is always {ğ‘†1}-PNA, ğœ‹ğ‘†1âˆªğ‘†2 ğœ‡ is
{ğ‘†1} âˆª T -PNA for any T such that ğ‘”2 is T -PNA. Recall that

ğœ‡ğ‘ = bind(ğœ‹ğ‘†1âˆªğ‘†2 ğœ‡, (ğ‘š1, ğ‘š2) â†¦â†’ unit(ğ‘“ â€²(ğ‘š1)) âŠ— unit(ğ‘š2)).

Thus, by the monotonicity map closure Lemma D.9, ğœ‡ğ‘ is {ğ‘¦} âˆª T -PNA for any T such
that ğ‘”2 is T -PNA. Thus, ğœ‡ğ‘ âˆˆ ğ‘”1 âŠ• ğ‘”2, and therefore (ğœğ‘’, ğœ‡ğ‘ ) âˆˆ (ğœğ‘’, ğ‘”1) âŠ• (ğœğ‘’, ğ‘”2).

Therefore, (ğœğ‘’, ğœ‡ğ‘ ) |= hğ‘¦i âˆ— ğœ‚.
By persistence, (ğœğ‘’, ğœ‡ğ‘’ ) |= hğ‘¦i âˆ— ğœ‚.

(cid:3)

E COMPLETENESS OF ğ‘€-BI

E.1 ğ‘€-BI Algebras

Deï¬nition E.1 (BI Algebra). An BI algebra is an algebra A = (ğ´, âˆ§, âˆ¨, â†’, âŠ¤, âŠ¥, âˆ—, âˆ’âˆ—, âŠ¤âˆ—) such that
â€¢ (ğ´, âˆ§, âˆ¨, â†’, âŠ¤, âŠ¥) is a Heyting algebra
â€¢ (ğ´, âˆ—, âŠ¤âˆ—) is a commutative monoid
â€¢ ğ‘ âˆ— ğ‘ â‰¤ ğ‘ if and only if ğ‘ â‰¤ ğ‘ âˆ’âˆ— ğ‘

where â‰¤ is the ordering associated with the Heyting algebra.

, âŠ¤âˆ—

Deï¬nition E.2 (ğ‘€-BI Algebra). An ğ‘€-BI algebra is an algebra A = (ğ´, âˆ§, âˆ¨, â†’, âŠ¤, âŠ¥, âˆ—ğ‘š âˆˆğ‘€ , âˆ’âˆ—ğ‘š âˆˆğ‘€
ğ‘š âˆˆğ‘€ ) such that
â€¢ For each ğ‘š âˆˆ ğ‘€, the structure (ğ´, âˆ§, âˆ¨, â†’, âŠ¤, âŠ¥, âˆ—ğ‘š, âˆ’âˆ—ğ‘š, âŠ¤âˆ—
â€¢ If ğ‘š1 â‰¤ ğ‘š2 then ğ‘ âˆ—ğ‘š1 ğ‘ â‰¤ ğ‘ âˆ—ğ‘š2 ğ‘

ğ‘š) is a BI-algebra

We can interpret ğ‘€-BI in an ğ‘€-BI algebra ğ´. Let V : AP â†’ ğ´ be a map assigning atomic
propositions to elements of ğ´. We extend V to an interpretation Jâˆ’KV mapping propositions to
elements of ğ´, deï¬ned by:

Jğ‘K = V (ğ‘)
JâŠ¤K = âŠ¤
Jğ¼ğ‘šK = âŠ¤âˆ—
ğ‘š
JâŠ¥K = âŠ¥

Jğ‘ƒ âˆ§ ğ‘„KV = Jğ‘ƒKV âˆ§ Jğ‘„KV
Jğ‘ƒ âˆ¨ ğ‘„KV = Jğ‘ƒKV âˆ¨ Jğ‘„KV
Jğ‘ƒ â†’ ğ‘„KV = Jğ‘ƒKV â†’ Jğ‘„KV
Jğ‘ƒ âˆ—ğ‘š ğ‘„KV = Jğ‘ƒKV âˆ—ğ‘š Jğ‘„KV
Jğ‘ƒ âˆ’âˆ—ğ‘š ğ‘„KV = Jğ‘ƒKV âˆ’âˆ—ğ‘š Jğ‘„KV

Theorem E.3 (Algebraic Soundness). If ğ‘ƒ âŠ¢ ğ‘„ is provable, then for all V, Jğ‘ƒKV â‰¤ Jğ‘„KV.

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:49

Proof. By induction on the derivation of ğ‘ƒ âŠ¢ ğ‘„. The cases for everything except the Inclusion
rules show follow from the exact same argument as for standard BI and BI-algebra, as in Simon
Dochertyâ€™s thesis.

For the remaining case of âˆ—-inclusion, let ğ‘š1 â‰¤ ğ‘š2. Then we have

Jğ‘ƒ âˆ—ğ‘š1 ğ‘„KV = Jğ‘ƒKV âˆ—ğ‘š1 Jğ‘„KV â‰¤ Jğ‘ƒKV âˆ—ğ‘š2 Jğ‘„KV â‰¤ Jğ‘ƒ âˆ—ğ‘š2 ğ‘„KV

(cid:3)

Deï¬nition E.4 (Lindenbaum-Tarski Algebra). The Lindenbaum-Tarski algebra corresponding to
ğ‘€-BI is the set of all equivalence classes of interprovable propositions. That is, deï¬ne the equiva-
lence relation ğ‘ƒ âˆ¼ ğ‘„ as ğ‘ƒ âŠ¢ ğ‘„ and ğ‘„ âŠ¢ ğ‘ƒ. We will show that the set of equivalence classes of this
relation forms an ğ‘€-BI algebra. Let [ğ‘ƒ]âˆ¼ be the equivalence class of ğ‘ƒ under âˆ¼. Take ğ¼ğ‘š, âŠ¤, and âŠ¥
to be [ğ¼ğ‘š]âˆ¼, [âŠ¤]âˆ¼, and [âŠ¥]âˆ¼, respectively. Then we deï¬ne:

[ğ‘ƒ]âˆ¼ âˆ§ [ğ‘„]âˆ¼ = [ğ‘ƒ âˆ§ ğ‘„]âˆ¼
[ğ‘ƒ]âˆ¼ âˆ¨ [ğ‘„]âˆ¼ = [ğ‘ƒ âˆ¨ ğ‘„]âˆ¼
...
[ğ‘ƒ]âˆ¼ âˆ—ğ‘š [ğ‘„]âˆ¼ = [ğ‘ƒ âˆ—ğ‘š ğ‘„]âˆ¼
[ğ‘ƒ]âˆ¼ âˆ’âˆ—ğ‘š [ğ‘„]âˆ¼ = [ğ‘ƒ âˆ’âˆ—ğ‘š ğ‘„]âˆ¼

The fact that these operations are well-deï¬ned and form a ğ‘€-BI algebra follows almost entirely
from the corresponding result for normal BI outlined in Dochertyâ€™s thesis. The only remaining
case is to check that if ğ‘š1 â‰¤ ğ‘š2 then [ğ‘ƒ]âˆ¼ âˆ—ğ‘š1 [ğ‘„]âˆ¼ â‰¤ [ğ‘ƒ]âˆ¼ âˆ—ğ‘š2 [ğ‘„]âˆ¼. We have

[ğ‘ƒ]âˆ¼ âˆ—ğ‘š1 [ğ‘„]âˆ¼ = [ğ‘ƒ âˆ—ğ‘š1 ğ‘„]âˆ¼
â‰¤ [ğ‘ƒ âˆ—ğ‘š2 ğ‘„]âˆ¼
= [ğ‘ƒ]âˆ¼ âˆ—ğ‘š2 [ğ‘„]âˆ¼

Lemma E.5. ğ‘ƒ âŠ¢ ğ‘„ if and only if [ğ‘ƒ]âˆ¼ â‰¤ [ğ‘„]âˆ¼.

(Since ğ‘ƒ âˆ—ğ‘š1 ğ‘„ â‰¤ ğ‘ƒ âˆ—ğ‘š2 ğ‘„)

Proof. In the proof that the Lindenbaum-Tarski algebra indeed formed an ğ‘€-BI algebra, we
already showed that ğ‘ƒ âŠ¢ ğ‘„ implies [ğ‘ƒ]âˆ¼ â‰¤ [ğ‘„]âˆ¼. Consider the opposite direction. Then we have
that [ğ‘ƒ]âˆ¼ âˆ§ [ğ‘„]âˆ¼ = [ğ‘ƒ]âˆ¼, hence [ğ‘ƒ âˆ§ ğ‘„]âˆ¼ = [ğ‘ƒ]âˆ¼. This implies that ğ‘ƒ âˆ§ ğ‘„ âŠ£âŠ¢ ğ‘ƒ. Since ğ‘ƒ âˆ§ ğ‘„ âŠ¢ ğ‘„,
(cid:3)
by transitivity we have ğ‘ƒ âŠ¢ ğ‘„.

Theorem E.6 (Algebraic Completeness). If Jğ‘ƒKV â‰¤ Jğ‘„KV for all V, then ğ‘ƒ âŠ¢ ğ‘„.

Proof. Consider the valuation V which maps ğ‘ âˆˆ AP to [ğ‘]âˆ¼. Then Jğ‘ƒKV = [ğ‘ƒ]âˆ¼ and Jğ‘„KV =
(cid:3)

[ğ‘„]âˆ¼. Hence we have [ğ‘ƒ]âˆ¼ â‰¤ [ğ‘„]âˆ¼ which implies ğ‘ƒ âŠ¢ ğ‘„.

E.2 ğ‘€-BI Frames
ğ‘€-BI formulas are interpreted on Down-Closed ğ‘€-BI frames. We deï¬ne a complex algebra on
ğ‘€-BI frames.

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:50

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

Deï¬nition E.7 (Complex Algebra). If X is an ğ‘€-BI frame, then the complex algebra of X, written

Com(X) is the structure (PâŠ‘ (ğ‘‹ ), âˆ©, âˆª, â†’X, ğ‘‹, âˆ…, âˆ—ğ‘š âˆˆğ‘€ , âˆ’âˆ—ğ‘š âˆˆğ‘€ , ğ¸ğ‘š âˆˆğ‘€ ) where

PâŠ‘(ğ‘‹ ) = {ğ´ âŠ† ğ‘‹ | ğ‘ âˆˆ ğ´ âˆ§ ğ‘ âŠ‘ ğ‘ â†’ ğ‘ âˆˆ ğ´}

ğ´ â†’X ğµ = {ğ‘ | âˆ€ğ‘. ğ‘ âŠ‘ ğ‘ âˆ§ ğ‘ âˆˆ ğ´ â†’ ğ‘ âˆˆ ğµ}
ğ´ âˆ—ğ‘š ğµ = {ğ‘¥ | âˆƒğ‘¤, ğ‘¦, ğ‘§. ğ‘¤ âŠ‘ ğ‘¥ âˆ§ ğ‘¤ âˆˆ ğ‘¦ âŠ•ğ‘š ğ‘§ âˆ§ ğ‘¦ âˆˆ ğ´ âˆ§ ğ‘§ âˆˆ ğµ}
ğ´ âˆ’âˆ—ğ‘š ğµ = {ğ‘¥ | âˆ€ğ‘¤, ğ‘¦, ğ‘§. (ğ‘¥ âŠ‘ ğ‘¤ âˆ§ ğ‘§ âˆˆ ğ‘¤ âŠ•ğ‘š ğ‘¦ âˆ§ ğ‘¦ âˆˆ ğ´) â†’ ğ‘§ âˆˆ ğµ}

Lemma E.8. If X is an ğ‘€-BI frame, then Com(X) is an ğ‘€-BI algebra.

Proof. Each (ğ‘‹, âŠ‘, âŠ•ğ‘š, ğ¸ğ‘š) is a BI frame. Docherty [2019] shows that the complex of a BI frame
is a BI algebra. Thus the only thing to check is that the ordering on âˆ— respects the ordering on ğ‘€.
Let ğ‘š1 â‰¤ ğ‘š2. We must show that ğ´ âˆ—ğ‘š1 ğµ âŠ† ğ´ âˆ—ğ‘š2 ğµ. Let ğ‘¥ âˆˆ ğ´ âˆ—ğ‘š1 ğµ. Then there exists ğ‘¤, ğ‘¦, ğ‘§
such that ğ‘¤ âŠ‘ ğ‘¥ and ğ‘¤ âˆˆ ğ‘¦ âŠ•ğ‘š1 ğ‘§, with ğ‘¦ âˆˆ ğ´ and ğ‘§ âˆˆ ğµ. by the Operation Inclusion property, we
(cid:3)
have that ğ‘¤ âˆˆ ğ‘¦ âŠ•ğ‘š2 ğ‘§, hence ğ‘¥ âˆˆ ğ´ âˆ—ğ‘š2 ğµ.

Deï¬nition E.9 (Prime Filter). If (ğ¿, âˆ§, âˆ¨) is a bounded distributive lattice, a prime ï¬lter on ğ¹ is a

non-empty proper subset of ğ´ such that:
â€¢ If ğ‘¥ âˆˆ ğ¹ and ğ‘¥ â‰¤ ğ‘¦ then ğ‘¦ âˆˆ ğ¹ .
â€¢ If ğ‘¥ âˆˆ ğ¹ and ğ‘¦ âˆˆ ğ¹ then ğ‘¥ âˆ§ ğ‘¦ âˆˆ ğ¹ .
â€¢ If ğ‘¥ âˆ¨ ğ‘¦ âˆˆ ğ¹ then ğ‘¥ âˆˆ ğ¹ or ğ‘¦ âˆˆ ğ¹ .

We write Prf(ğ¿) for the set of prime ï¬lters on ğ¿.

Deï¬nition E.10 (Prime Filter Frame). If A is an ğ‘€-BI algebra, then the prime ï¬lter ğ‘€-frame of

A is deï¬ned as Prf(A) = (Prf(ğ´), âŠ†, âŠ•ğ‘š âˆˆğ‘€ , ğ¸ğ‘š âˆˆğ‘€ ) where

ğ¹1 âŠ•ğ‘š ğ¹2 = {ğ¹ âˆˆ Prf(ğ´) | âˆ€ğ‘1 âˆˆ ğ¹1. âˆ€ğ‘2 âˆˆ ğ¹2. ğ‘1 âˆ—ğ‘š ğ‘2 âˆˆ ğ¹ }
ğ‘š âˆˆ ğ¹ }

ğ¸ğ‘š = {ğ¹ âˆˆ Prf(ğ´) | âŠ¤âˆ—

Lemma E.11. If A is an ğ‘€-BI algebra, then Prf(A) is an ğ‘€-BI frame.

Proof. Docherty [2019] shows that for each ğ‘š âˆˆ ğ‘€, (Prf(ğ´), âŠ†, âŠ•ğ‘š, ğ¸ğ‘š) is a BI frame. Therefore,
we only need to check the Operation Inclusion property. Let ğ‘š1 â‰¤ ğ‘š2 and let ğ¹, ğº, ğ» âˆˆ Prf(ğ´)
with ğ¹ âˆˆ ğº âŠ•ğ‘š1 ğ» . Let ğ‘ âˆˆ ğº and ğ‘ âˆˆ ğ» . Then ğ‘ âˆ—ğ‘š1 ğ‘ âˆˆ ğ¹ . Since ğ‘ âˆ—ğ‘š1 ğ‘ â‰¤ ğ‘ âˆ—ğ‘š2 ğ‘, and ï¬lters are
upward-closed, ğ‘ âˆ—ğ‘š2 ğ‘ âˆˆ ğ¹ , hence ğ¹ âˆˆ ğº âŠ•ğ‘š2 ğ» .

(cid:3)

Theorem E.12 (Representation Theorem). Every ğ‘€-BI algebra is isomorphic to a subalgebra
of a complex algebra. In particular, if A is an ğ‘€-BI algebra, then the map ğœƒ : A â†’ Com(Prf(A))
deï¬ned as

ğœƒ (ğ‘¥) = {ğ¹ âˆˆ Prf(A) | ğ‘¥ âˆˆ ğ¹ }

is an embedding.

Proof. Docherty [2019] proves that for each ğ‘š âˆˆ ğ‘€, this map ğœƒ is an embedding of (ğ´, âˆ§, âˆ¨, â†’
, âŠ¤, âŠ¥, âˆ—ğ‘š, âˆ’âˆ—ğ‘š, âŠ¤âˆ—
ğ‘š) as a BI algebra into the complex algebra, viewed as a BI algebra for the oper-
ations indexed by ğ‘š. Hence, ğœƒ is injective and a homomorphism with respect to all of the ğ‘€-BI
(cid:3)
algebra operations.

Theorem E.13 (Eqivalence of Algebras and Frames). Let A = (ğ´, . . . ) be an ğ‘€-BI algebra
and let Va : AP â†’ ğ´ be an interpretation of atomic propositions. Let X = (ğ‘‹, . . . ) be an ğ‘€-BI
: Prop â†’ P (ğ‘‹ ) be a persistent valuation on X. Let ğœƒ be the embedding from
frame and let Vf

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:51

the previous result. Deï¬ne the persistent valuation V â€²
V â€²
f

: AP â†’ Com(X) by:

a : AP â†’ P (Prf(ğ´)) and the interpretation

V â€²
V â€²

a (ğ‘) = ğœƒ (Va(ğ‘))
f (ğ‘) = Vf (ğ‘).

Then we have

(1) ğ‘¥ |=Vf ğ‘ƒ if and only if ğ‘¥ âˆˆ Jğ‘ƒKV â€²
(2) ğ¹ |=Vâ€²

a ğ‘ƒ if and only if Jğ‘ƒKVa âˆˆ ğ¹ .

f

Proof. For the ï¬rst part, we proceed by induction on ğ‘ƒ.
â€¢ Case ğ‘ƒ = ğ‘: We have:

ğ‘¥ |=Vf ğ‘ â†” ğ‘¥ âˆˆ Vf (ğ‘)
â†” ğ‘¥ âˆˆ Vfâ€™ (ğ‘)
â†” ğ‘¥ âˆˆ Jğ‘Kfâ€™

â€¢ Case ğ‘ƒ = âŠ¤: Then ğ‘¥ |=Vf âŠ¤ holds for all ğ‘¥, and âŠ¤ in Com(X) is deï¬ned to be ğ‘‹ , so ğ‘¥ âˆˆ JâŠ¤KVâ€²

f

holds for all ğ‘¥.

â€¢ Case ğ‘ƒ = ğ¼ğ‘š: Similar to ğ‘ƒ = âŠ¤.
â€¢ Case ğ‘ƒ = âŠ¥: Similar to ğ‘ƒ = âŠ¤.
â€¢ Case ğ‘ƒ = ğ‘„1 âˆ§ ğ‘„2:

ğ‘¥ |=Vf ğ‘„1 âˆ§ ğ‘„2 â†” ğ‘¥ |=Vf ğ‘„1 and ğ‘¥ |=Vf ğ‘„2

â†” ğ‘¥ âˆˆ Jğ‘„1KVfâ€² and ğ‘¥ âˆˆ Jğ‘„2KVfâ€²
â†” ğ‘¥ âˆˆ Jğ‘„1KVfâ€² âˆ© Jğ‘„2KVfâ€²
â†” ğ‘¥ âˆˆ Jğ‘„1 âˆ§ ğ‘„2KVfâ€²

(By satisï¬cation rule)
(Vfâ€² and Vfâ€² the same)

(By the âˆ§ operation in Complex algebra and the recursive deï¬nition of V)

â€¢ Case ğ‘ƒ = ğ‘„1 âˆ¨ ğ‘„2:

ğ‘¥ |=Vf ğ‘„1 âˆ¨ ğ‘„2 â†” ğ‘¥ |=Vf ğ‘„1 or ğ‘¥ |=Vf ğ‘„2

â†” ğ‘¥ âˆˆ Jğ‘„1KVfâ€² or ğ‘¥ âˆˆ Jğ‘„2KVfâ€²
â†” ğ‘¥ âˆˆ Jğ‘„1KVfâ€² âˆª Jğ‘„2KVfâ€²
â†” ğ‘¥ âˆˆ Jğ‘„1 âˆ¨ ğ‘„2KVfâ€²
â€¢ Case ğ‘ƒ = ğ‘„1 â†’ ğ‘„2: Let ğ‘¥ |=Vf ğ‘„1 â†’ ğ‘„2. Then, for all ğ‘¦ such that ğ‘¥ âŠ‘ ğ‘¦, if ğ‘¦ |=Vf ğ‘„1,
then ğ‘¦ |=Vf ğ‘„2. Applying the induction hypothesis, we have that for all ğ‘¦ such that ğ‘¥ âŠ‘ ğ‘¦, if
ğ‘¦ âˆˆ Jğ‘„1KVfâ€² , then ğ‘¦ âˆˆ Jğ‘„2KVfâ€² . Hence, ğ‘¥ âˆˆ Jğ‘„1 â†’ ğ‘„2KVfâ€² . The reverse direction is similar.
â€¢ Case ğ‘ƒ = ğ‘„1 âˆ—ğ‘š ğ‘„2: Let ğ‘¥ |=Vf ğ‘„1 âˆ—ğ‘š ğ‘„2. Then there exists ğ‘¥ â€², ğ‘¦, and ğ‘§ such that ğ‘¥ â€² âŠ‘ ğ‘¥
and ğ‘¥ â€² âˆˆ ğ‘¦ âŠ•ğ‘š ğ‘§, where ğ‘¦ |=Vf ğ‘„1 and ğ‘§ |=Vf ğ‘„2. By the induction hypothesis, we have that
ğ‘¦ âˆˆ Jğ‘„1KVfâ€² and ğ‘§ âˆˆ Jğ‘„2KVfâ€² . Hence, ğ‘¥ âˆˆ Jğ‘„1 âˆ—ğ‘š ğ‘„2KVfâ€² .

â€¢ Case ğ‘ƒ = ğ‘„1 âˆ’âˆ—ğ‘š ğ‘„2: Let ğ‘¥ |=Vf ğ‘„1 âˆ’âˆ—ğ‘š ğ‘„2. Then for all ğ‘¥ â€², ğ‘¦, and ğ‘§ such that ğ‘¥ âŠ‘ ğ‘¥ â€² and

ğ‘§ âˆˆ ğ‘¥ â€² âŠ•ğ‘š ğ‘¦, if ğ‘¦ |=Vf ğ‘„1, then ğ‘§ |=Vf ğ‘„2.
To show that ğ‘¥ âˆˆ Jğ‘„1 âˆ’âˆ—ğ‘š ğ‘„2KVfâ€² , let ğ‘¤, ğ‘¦, and ğ‘§ be such that ğ‘¥ âŠ‘ ğ‘¤, ğ‘§ âˆˆ ğ‘¤ âŠ•ğ‘š ğ‘¦, and
ğ‘¦ âˆˆ Jğ‘„1KVfâ€² . We must show that ğ‘§ âˆˆ Jğ‘„2KVfâ€² . Applying the induction hypothesis, we have
that ğ‘¦ âˆˆ|=Vf ğ‘„1. Thus, by the preceding paragraph, we have that ğ‘§ |=Vf ğ‘„2. Applying the
induction hypothesis again, we get that ğ‘§ âˆˆ Jğ‘„2KVfâ€² .

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:52

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

For the second part, assuming ğ¹ âˆˆ Prf(A), then for any ğ‘ƒ, we have

ğ¹ |=Vâ€²

a ğ‘ƒ â†” ğ¹ âˆˆ Vaâ€² (ğ‘ƒ)

â†” ğ¹ âˆˆ Prf(A) and Va (ğ‘ƒ) âˆˆ ğ¹
â†” Va (ğ‘ƒ) âˆˆ ğ¹
â†” Jğ‘ƒKVa âˆˆ ğ¹ .

Theorem E.14 (Completeness). If ğ‘ƒ |=V ğ‘„ for all V, then ğ‘ƒ âŠ¢ ğ‘„

(cid:3)

Proof. Suppose ğ‘ƒ 0 ğ‘„. Then by algebraic completeness, there exists some ğ‘€-BI algebra A and
an interpretation Va such that Jğ‘ƒKVa (cid:2) Jğ‘„KVa . By the prime ï¬lter theorem, there exists [Docherty
2019] a prime ï¬lter ğ¹ such that Jğ‘ƒKVa âˆˆ ğ¹ and Jğ‘„KVa
a be as in the previous theorem,
(cid:3)
then we have ğ¹ |=Vâ€²
a ğ‘ƒ and ğ¹ 6|=Vâ€²

a ğ‘„ which contradicts the assumption that ğ‘ƒ |=Vâ€²

âˆ‰ ğ¹ . Let V â€²

a ğ‘„.

F EXAMPLES: OMITTED DETAILS

F.1 Bound false positive rate in Bloom filter
One detail we omitted is that, since the ï¬rst line of the program Bloom, ğ‘ğ‘™ğ‘œğ‘œğ‘š has been kept as a
bit-array throughout, i.e., all its entries are either 0 or 1. So it is easy to prove that

ğ‘

{âŠ¤} Bloom {

(ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½] = 0 âˆ¨ ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½] = 1)}.

Then, by the conjunction rule Conj, we have

Ã›ğ›½=0

{âŠ¤} Bloom {Pr

where ğ¾ = E

ğ‘
ğ›½=0 ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]

.

ï£®
Ã•ğ›½=0
ï£¯
ï£¯
ï£¯
ï£¯
ï£°

ï¬rst ğ‘ entries are one,

hÃ

ğ‘

ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½] < ğ¾ + ğ‘‡ (ğ›¿, ğ‘ )

â‰¥ 1 âˆ’ ğ›¿},

ï£¹
ï£º
ï£º
ï£º
ï£º
ï£»

In the following, we will abbreviate formulas that assert ğ‘ is a bit-array where exactly ğ½ of its

i

ğ‘

ğ‘

ğ‘ [ğ›½] = ğ½

âˆ§

(ğ‘ [ğ›½] = 0 âˆ¨ ğ‘ [ğ›½] = 1),

Ã•ğ›½=0
as bv(ğ‘, ğ½ , ğ‘ ). Similarly, we will use bv(ğ‘, < ğ½ , ğ‘ ) to abbreviate

Ã›ğ›½=0

Â©

Â«

ğ‘

ğ‘ [ğ›½] < ğ½

âˆ§

(ğ‘ [ğ›½] = 0 âˆ¨ ğ‘ [ğ›½] = 1).

ğ‘

Ã›ğ›½=0

Ã•ğ›½=0
Â©
Now we restate our goal as
Â«

Âª
Â®
Â¬

Âª
Â®
Â¬

{bv(ğ‘ğ‘™ğ‘œğ‘œğ‘š, < ğ¾, ğ‘ )} CheckMem {Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤ (ğ¾/ğ‘ )ğ» }.

CheckMem ï¬rst initializes â„ and ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡ deterministically to 1. Then, using RAssn and Frame,

we can show that

âŠ¢ {âŠ¤} â„ â† 0; ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡ â† 1 {(â„ âˆ¼ 0) âˆ— (ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡ âˆ¼ 1)}.
Using the (ProbOne) axiom and the fact that 1 â‰¤ (ğ¾/ğ‘ )0 for any ğ¾ and ğ‘ , we can show |= (â„ âˆ¼ 0) âˆ—
(ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡ âˆ¼ 1) â†’ Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤ (ğ¾/ğ‘ )â„. Thus,

âŠ¢ {âŠ¤} â„ â† 0; ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡ â† 1 {Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤ (ğ¾/ğ‘ )â„}.

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

 
 
A Separation Logic for Negative Dependence

57:53

Because the assignments â„ â† 0; ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡ â† 1 do not modify the Bloom ï¬lter array ğ‘ğ‘™ğ‘œğ‘œğ‘š, we can
then apply the frame rule Frame to derive

âŠ¢ {bv(ğ‘ğ‘™ğ‘œğ‘œğ‘š, < ğ¾, ğ‘ )} â„ â† 0; ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡ â† 1 {bv(ğ‘ğ‘™ğ‘œğ‘œğ‘š, < ğ¾, ğ‘ ) âˆ— Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤ (ğ¾/ğ‘ )â„}.

(12)

We will abbreviate bv(ğ‘ğ‘™ğ‘œğ‘œğ‘š, < ğ¾, ğ‘ ) âˆ— Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤ (ğ¾/ğ‘ )â„ as ğœ‚. Because
upper bounded by ğ‘ ,

|=Mem ğœ‚ â†’

ğœ‚ ğ½ ,

ğ‘
ğ›½=0 ğ‘ [ğ›½] is an integer

Ã

where ğœ‚ ğ½ abbreviates ğ½ < ğ¾ âˆ§

bv(ğ‘ğ‘™ğ‘œğ‘œğ‘š, ğ½ , ğ‘ ) âˆ— Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤ (ğ¾/ğ‘ )â„
We will then prove that for each ğ½ , the formula ğœ‚ ğ½ is a loop invariant of CheckMemâ€™s loop body.

.

The loop body ï¬rst uniformly sample an element from [ğ‘ ], so by RSampâˆ—,

(cid:0)

(cid:1)

Ãœ0â‰¤ğ½ <ğ¾

Together with the axiom |= ğ‘ƒ âˆ— ğ‘„ â†’ ğ‘ƒ, Equation (13) implies

ğœ‚ ğ½ âˆ— U[ğ‘ ] hğ‘ğ‘–ğ‘›i.

(13)

ğ½ < ğ¾ âˆ§

bv(ğ‘ğ‘™ğ‘œğ‘œğ‘š, ğ½ , ğ‘ ) âˆ—

Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤ (

(cid:18)

(cid:18)

ğ¾
ğ‘

)â„

(cid:19)

âˆ— U[ğ‘ ] hğ‘ğ‘–ğ‘›i

.

(cid:19)

Then, â„ğ‘–ğ‘¡ gets assigned to ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ‘ğ‘–ğ‘›], so by RAssn, we have
{bv(ğ‘ğ‘™ğ‘œğ‘œğ‘š, ğ½ , ğ‘ ) âˆ— U[ğ‘ ] hğ‘ğ‘–ğ‘›i} â„ğ‘–ğ‘¡ â† ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½] {
Since the array ğ‘ğ‘™ğ‘œğ‘œğ‘š only contains zero-one entries, when the sum of its entries is ğ½ , an entry
(cid:0)
ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ‘ğ‘–ğ‘›] drawn uniformly at random has probability ğ½
ğ‘ to be 1. If the entry is in addition chosen
independently from values in ğ‘ğ‘™ğ‘œğ‘œğ‘š, then the bit ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ‘ğ‘–ğ‘›] is distributed independent from the
distribution of ğ‘ğ‘™ğ‘œğ‘œğ‘š. The (UniformSamp) axiom encodes this fact:

bv(ğ‘ğ‘™ğ‘œğ‘œğ‘š, ğ½ , ğ‘ ) âˆ— U[ğ‘ ] hğ‘ğ‘–ğ‘›i

(cid:1)

âˆ§ â„ğ‘–ğ‘¡ âˆ¼ ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ‘ğ‘–ğ‘›]}.

|=

bv(ğ‘, ğ½ , ğ‘ ) âˆ— U[ğ‘ ] hğ‘¥i

âˆ§ â„ğ‘–ğ‘¡ âˆ¼ ğ‘ [ğ‘¥]

â†’ Bern ğ½
ğ‘

hâ„ğ‘–ğ‘¡i âˆ— bv(ğ‘, ğ½ , ğ‘ ).

Thus, we have

(cid:0) (cid:0)

(cid:1)

(cid:1)

{bv(ğ‘ğ‘™ğ‘œğ‘œğ‘š, ğ½ , ğ‘ ) âˆ— U[ğ‘ ] hğ‘ğ‘–ğ‘›i} â„ğ‘–ğ‘¡ â† ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½] {Bern ğ½

ğ‘

hâ„ğ‘–ğ‘¡i âˆ— bv(ğ‘ğ‘™ğ‘œğ‘œğ‘š, ğ½ , ğ‘ )}.

Because â„ğ‘–ğ‘¡ â† ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ‘ğ‘–ğ‘›] does not modify ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡, we can apply the frame rule for âˆ— Frame and
get

bv(ğ‘ğ‘™ğ‘œğ‘œğ‘š, ğ½ , ğ‘ ) âˆ— U[ğ‘ ] hğ‘ğ‘–ğ‘›i âˆ— Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤

(

â„ğ‘–ğ‘¡ â† ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]

ğ¾
ğ‘

(cid:18)

â„

)

(cid:19)

Bern ğ½
ğ‘

(

hâ„ğ‘–ğ‘¡i âˆ— bv(ğ‘ğ‘™ğ‘œğ‘œğ‘š, ğ½ , ğ‘ ) âˆ— Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤

ğ¾
ğ‘

(cid:18)

â„

.

)

(cid:19)

Next, with the assignment ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡ â† â„ğ‘–ğ‘¡ && ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡, by applying the axioms (IndepProb), (EqualProb)
and the RAssn rule, we get:

Bern ğ½
ğ‘

(

hâ„ğ‘–ğ‘¡i âˆ— bv(ğ‘ğ‘™ğ‘œğ‘œğ‘š, ğ½ , ğ‘ ) âˆ— Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤

ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡ â† â„ğ‘–ğ‘¡ && ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡

Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤

(  

ğ½
ğ‘

Â·

ğ¾
ğ‘

(cid:18)

â„

!

(cid:19)

âˆ— bv(ğ‘ğ‘™ğ‘œğ‘œğ‘š, ğ½ , ğ‘ )

)

ğ¾
ğ‘

(cid:18)

â„

)

(cid:19)

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:54

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

We can then apply the rule of constancy Const and get

ğ½ < ğ¾ âˆ§

bv(ğ‘ğ‘™ğ‘œğ‘œğ‘š, ğ½ , ğ‘ ) âˆ— U[ğ‘ ] hğ‘ğ‘–ğ‘›i âˆ— Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤

ğ¾
ğ‘

(cid:18)

â„

!)

(cid:19)

â„ğ‘–ğ‘¡ â† ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½]; ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡ â† â„ğ‘–ğ‘¡ && ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡

ğ½ < ğ¾ âˆ§

Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤

ğ½
ğ‘

Â·

ğ¾
ğ‘

(cid:18)

â„

!

(cid:19)

âˆ— bv(ğ‘ğ‘™ğ‘œğ‘œğ‘š, ğ½ , ğ‘ )

!)

(

(

When we have ğ½ < ğ¾, then (ğ¾/ğ‘ )â„ Â·

ğ½
ğ‘ â‰¤ (ğ¾/ğ‘ )â„+1, so the post condition implies

ğ½ < ğ¾ âˆ§

Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤

â„+1

!

ğ¾
ğ‘

(cid:18)

(cid:19)

âˆ— bv(ğ‘ğ‘™ğ‘œğ‘œğ‘š, ğ½ , ğ‘ )

!

The last step in the loop body is the assignment â„ â† â„ + 1. By the deterministic assignment rule
DAssn, we can establish the post condition ğœ‚ ğ½ afterwards:

ğ½ < ğ¾ âˆ§

bv(ğ‘ğ‘™ğ‘œğ‘œğ‘š, ğ½ , ğ‘ ) âˆ— Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤

ğ¾
ğ‘

(cid:18)

â„

.

!

(cid:19)

Thus, we have {ğœ‚ ğ½ } loop body {ğœ‚ ğ½ }

By Loop rule, we can establish {ğœ‚ ğ½ } ğ‘™ğ‘œğ‘œğ‘ {ğœ‚ ğ½ âˆ§ â„ â‰¥ ğ» }. Since ğœ‚ ğ½ âˆ§ â„ â‰¥ ğ» implies Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤

(ğ¾/ğ‘ )ğ» , we then have

{ğœ‚ ğ½ } ğ‘™ğ‘œğ‘œğ‘ {Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤

ğ»

}.

ğ¾
ğ‘

(cid:18)

(cid:19)

Because Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤ (ğ¾/ğ‘ )ğ» is closed under mixtures, and ğœ‚ is closed under conditioning, we
can then apply RCase to prove that

{ğœ‚} ğ‘™ğ‘œğ‘œğ‘ {Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤

ğ»

}.

ğ¾
ğ‘

(cid:18)

(cid:19)

(14)

Using the Seqn rule to combine the proved judgments for CheckMemâ€™s initialization (12) and
loop (14), we derive

ğ‘

{

Ã•ğ›½=0

ğ‘ğ‘™ğ‘œğ‘œğ‘š[ğ›½] < ğ¾} CheckMem {Pr[ğ‘ğ‘™ğ‘™â„ğ‘–ğ‘¡] â‰¤

ğ»

}.

ğ¾
ğ‘

(cid:18)

(cid:19)

F.2 Permutation Hashing
We sketch how to replicate the informal reasoning in LINA. For the main loop, we apply the rule
Loop with the following loop invariant:

ğ‘›

ğ‘›

â„ğ‘–ğ‘¡ğ‘ [ğ›¼] âˆ¼ [ğ‘šğ‘œğ‘‘ (ğ‘”[ğ›¼], ğµ) = ğ‘ ] âˆ§ Perm[ğµ Â·ğ¾ ] hğ‘”i âˆ§ ğ‘ğ‘¡ =

â„ğ‘–ğ‘¡ğ‘ [ğ›¼] âˆ§ (Â¬(ğ‘› < ğ‘ ) â†’ ğ‘› âˆ¼ ğ‘ )

Ã›ğ›¼ =0
The loop invariant is preserved by the body of the loop, using the assignment rule (RAssn) and
the rule of constancy (Const). Thus we can show the following judgment:

Ã•ğ›¼ =0

{ğ‘ğ‘¡ âˆ¼ 0 âˆ§ ğ‘› âˆ¼ 0} ğ‘™ğ‘œğ‘œğ‘ {

ğ‘

Ã›ğ›¼ =0

â„ğ‘–ğ‘¡ğ‘ [ğ›¼] âˆ¼ [ğ‘šğ‘œğ‘‘ (ğ‘”[ğ›¼], ğµ) = ğ‘ ] âˆ§ Perm[ğµ Â·ğ¾ ] hğ‘”i âˆ§ ğ‘ğ‘¡ âˆ¼

â„ğ‘–ğ‘¡ğ‘ [ğ›¼]}

ğ‘

Ã•ğ›¼ =0

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

 
  
  
 
A Separation Logic for Negative Dependence

57:55

Applying (Perm-Map), the post-condition implies:

â„ğ‘–ğ‘¡ğ‘ [ğ›¼] âˆ¼ [ğ‘šğ‘œğ‘‘ (ğ‘”[ğ›¼], ğµ) = ğ‘ ] âˆ§

ğ‘âˆ—

ğ›¼ =0

ğ‘

Ã›ğ›¼ =0

hâ„ğ‘–ğ‘¡ğ‘ [ğ›¼]i âˆ§ Perm[ğµ Â·ğ¾ ] hğ‘”i âˆ§ ğ‘ğ‘¡ âˆ¼

â„ğ‘–ğ‘¡ğ‘ [ğ›¼]

ğ‘

Ã•ğ›¼ =0

Applying basic axioms about expected value and the permutation distribution ((PermMarg) (ProbUnif)
(BijectUnif)), we have:

ğ‘âˆ—

ğ›¼ =0

hâ„ğ‘–ğ‘¡ğ‘ [ğ›¼]i âˆ§ ğ‘ğ‘¡ âˆ¼

â„ğ‘–ğ‘¡ğ‘ [ğ›¼] âˆ§ E[ğ‘ğ‘¡] âˆ¼ ğ‘ /ğµ

ğ‘

Ã•ğ›¼ =0

And we can apply the negative-association Chernoï¬€ bound (NA-Chernoï¬€) to conclude:

{âŠ¤} PermHash {Pr[|ğ‘ğ‘¡ âˆ’ ğ‘ /ğµ| > ğ‘‡ (ğ›½, ğ‘ )] < ğ›½}

This conclusion corresponds to Proposition A.2 in Ding and KÃ¶nig [2011] algorithm for fast set
intersection.6

F.3 Fully-Dynamic Dictionary

We outline the main steps in the formal proof; the most interesting step is the last one, where we
use negative association, but all steps can be handled in our framework.

We will refer to the two outer-most loops as (1) and (2), the next two outer-most loops as (1.1)

and (2.1), and the inner-most loop as (1.1.1).

Computing E[ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ‘] [ğ‘]]. For loop (1), we apply Loop with the following loop invariant:

ğ¶

ğ‘ƒ

Ã›ğ›¾=0

Ã›ğ›½=0

E[ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ›½]] âˆ¼ ğ‘›/(ğ‘ƒ Â· ğ¶) âˆ§ (Â¬(ğ‘› < ğ‘ ) â†’ ğ‘› âˆ¼ ğ‘ ).

To show that this invariant is preserved by the loop, by two applications of RSamp* the following
holds after the sampling commands:

OH[ğ‘ƒ ] hğ‘ğ‘œğ‘ğ‘˜ğ‘’ğ‘¡ [ğ‘›]i âˆ— OH[ğ¶ ] hğ‘ğ‘Ÿğ‘ğ‘¡ğ‘’ [ğ‘›]i âˆ§ ğ‘ğ‘–ğ‘›[ğ‘›] âˆ¼ ğ‘ğ‘Ÿğ‘ğ‘¡ğ‘’ [ğ‘›]âŠ¤ Â· ğ‘ğ‘œğ‘ğ‘˜ğ‘’ğ‘¡ [ğ‘›].

Using an axiom about independence and products of one-hot vectors (IndProdOH), this implies:

Using an axiom about the one-hot encoding (OHMarg):

OH[ğ¶ ]Ã—[ğ‘ƒ ] hğ‘ğ‘–ğ‘›[ğ‘›]i.

E[ğ‘ğ‘–ğ‘›[ğ›¼] [ğ›¾] [ğ›½]] âˆ¼ 1/(ğ‘ƒ Â· ğ¶)

for every ğ›¼, ğ›¾, and ğ›½. Standard loop invariants for loop (1.1) and (1.1.1) show that:

ğ‘›

ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ‘] [ğ‘] âˆ¼

ğ‘ğ‘–ğ‘›[ğ›¼] [ğ‘] [ğ‘],

Ã•ğ›¼ =0
and linearity of expectation establishes the invariant condition for loop (1). The invariant holds
at the start of loop (1) since ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ is zero-initialized, and it also holds at the end of loop (1). Since
ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ is not modiï¬ed further, the expectation bound also holds at the end of the program (Const).

6Ding and KÃ¶nig [2011] apply a variant of the Chernoï¬€ bound to obtain a multiplicative, rather than an additive, error
guarantee. We present the additive version since the bound is a bit simpler, but there is no diï¬ƒculty to handling the
multiplicative version in our framework.

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:56

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

ğ‘›âˆ—

ğ›¼ =0
(cid:18)

Bounding Pr[ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ‘] [ğ‘] > ğ‘‡ğ‘ğ‘–ğ‘›]. For loop (1), we apply Loop with the following loop invariant:
ğ‘

ğ¶

ğ‘ƒ

hğ‘ğ‘–ğ‘›[ğ›¼]i

âˆ§

ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ›½] âˆ¼

ğ‘ğ‘–ğ‘›[ğ›¼] [ğ›¾] [ğ›½] âˆ§ (Â¬(ğ‘› < ğ‘ ) â†’ ğ‘› âˆ¼ ğ‘ ).

(cid:19)

Ã›ğ›¾=0

Ã•ğ›¼ =0
The ï¬rst conjunction is an invariant, by applying the sampling rule Samp* and the independence
frame rule Frame from PSL. The rest of the invariant is preserved, following standard invariants
for loops (1.1) and (1.1.1). By projection (IndMap), at the end of loop (1) we can conclude:

Ã›ğ›½=0

ğ¶

ğ‘ƒ

ğ‘âˆ—

ğ›¼ =0

hğ‘ğ‘–ğ‘›[ğ›¼] [ğ›¾] [ğ›½]i

Ã›ğ›¾=0
Thus a (standard) Chernoï¬€ bound gives:

Ã›ğ›½=0  

âˆ§ ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ›½] âˆ¼

ğ‘ğ‘–ğ‘›[ğ›¼] [ğ›¾] [ğ›½].

ğ‘

Ã•ğ›¼ =0

!

ğ¶

ğ‘ƒ

Pr[ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ›½] > E[ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ›½]] + ğ‘‡ (ğœŒğ‘ğ‘–ğ‘›, ğ‘ )] â‰¤ ğœŒğ‘ğ‘–ğ‘›.

Ã›ğ›¾=0

Ã›ğ›½=0

where E[ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ›½]] is ğ‘ /(ğ‘ƒ Â·ğ¶) by the previous step. Again, property holds until the end of the
program since ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ is not modiï¬ed further (Const).

Bounding E[ğ‘œğ‘£ğ‘’ğ‘Ÿğ¶ğ‘¡ [ğ‘]]. Using standard loop invariants, at the end of loop (2) we have:

ğ¶

ğ‘ƒ

ğ¶

ğ‘ƒ

ğ‘œğ‘£ğ‘’ğ‘Ÿğ¶ğ‘¡ [ğ›¾] âˆ¼

ğ‘ğ‘–ğ‘›[ğ›¿] [ğ›½] âˆ§

ğ‘œğ‘£ğ‘’ğ‘Ÿ [ğ›¾] [ğ›½] âˆ¼ [ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ›½] > ğ‘‡ğ‘ğ‘–ğ‘›].

Ã›ğ›¾=0

Ã•ğ›½=0

Ã•ğ›¿=0

Ã›ğ›½=0

Using linearity of expectation and the fact that ğ‘œğ‘£ğ‘’ğ‘Ÿ [ğ›¾] [ğ›½] is either zero or one, we have:

E[ğ‘œğ‘£ğ‘’ğ‘Ÿğ¶ğ‘¡ [ğ›¾]] âˆ¼

E[ğ‘œğ‘£ğ‘’ğ‘Ÿ [ğ›¾] [ğ›½]] âˆ¼

Pr[ğ‘œğ‘£ğ‘’ğ‘Ÿ [ğ›¾] [ğ›½] = 1] âˆ¼

ğ‘ƒ

ğ‘ƒ

Ã•ğ›½=0

Ã•ğ›½=0

since we have bound the probability in the previous step.

Pr[ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ›½] > ğ‘‡ğ‘ğ‘–ğ‘›] â‰¤ ğ‘ƒÂ·ğœŒğ‘ğ‘–ğ‘›

ğ‘ƒ

Ã•ğ›½=0

Bounding Pr[ğ‘œğ‘£ğ‘’ğ‘Ÿğ¶ğ‘¡ [ğ‘] > ğ‘‡ğ‘œğ‘£ğ‘’ğ‘Ÿ ]. We want the following loop invariant for (1):

ğ‘ƒâŠ›

ğ›½=0

ğ¶

ğ‘ƒ

Ã›ğ›¾=0

Ã›ğ›½=0

hğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ›½]i âˆ§ (Â¬(ğ‘› < ğ‘ ) â†’ ğ‘› âˆ¼ ğ‘ ).

We want the following loop invariant for (1.1):

ğ‘ƒâŠ›

ğ›½=0

hğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ›½]i âŠ›

ğ‘ƒâŠ›

ğ›½=ğ‘

hğ‘ğ‘–ğ‘›[ğ‘›] [ğ›¾] [ğ›½]i âˆ§ (Â¬(ğ‘ < ğ‘ƒ) â†’ ğ‘ âˆ¼ ğ‘ƒ).

ğ¶

Ã›ğ›¾=0

And the following loop invariant for (1.1.1):

ğ‘ƒâŠ›

ğ›½=0

hğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ›½]i âŠ›

ğ‘ƒâŠ›

ğ›½=ğ‘+[ğ‘>ğ›¾ ]

hğ‘ğ‘–ğ‘›[ğ‘›] [ğ›¾] [ğ›½]i.

ğ¶

Ã›ğ›¾=0

We show the invariant post-conditions for a ï¬xed ğ›¾; the big conjunction then follows by apply-
ing Conj. Working from inside-to-outside, we start with loop (1.1.1). To establish the invariant
condition, the critical case is ğ‘ = ğ›¾. We can pull out:
ğ‘âŠ›
ğ‘ƒâŠ›

hğ‘ğ‘–ğ‘›[ğ‘›] [ğ›¾] [ğ›½]i âŠ› hğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ‘]i âŠ› hğ‘ğ‘–ğ‘›[ğ‘›] [ğ›¾] [ğ‘]i

hğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ›½]i âŠ›

hğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ›½]i âŠ›

ğ‘ƒâŠ›

ğ›½=0

ğ›½=ğ‘+1

ğ›½=ğ‘+1

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

|

Î¦

{z

}

                                     
                                     
A Separation Logic for Negative Dependence

57:57

Now, we can use the assignment rule to show:

{Î¦} ğ‘¢ğ‘ğ‘‘ â† ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ‘] [ğ‘] + ğ‘ğ‘–ğ‘›[ğ‘›] [ğ‘] [ğ‘] {ğ‘¢ğ‘ğ‘‘ âˆ¼ ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ‘] [ğ‘] + ğ‘ğ‘–ğ‘›[ğ‘›] [ğ‘] [ğ‘]}

Since addition is a monotone function, the NA frame rule (NegFrame) gives:

ğ‘âŠ›

ğ›½=0

hğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ›½]i âŠ›

ğ‘ƒâŠ›

ğ›½=ğ‘+1

hğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ›½]i âŠ›

ğ‘ƒâŠ›

ğ›½=ğ‘+1

hğ‘ğ‘–ğ‘›[ğ‘›] [ğ›¾] [ğ›½]i âŠ› hğ‘¢ğ‘ğ‘‘i

after the assignment to ğ‘¢ğ‘ğ‘‘. After the assignment to ğ‘ğ‘–ğ‘›[ğ‘] [ğ‘], we can fold:

ğ‘ƒâŠ›

ğ›½=0

hğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ›½]i âŠ›

ğ‘ƒâŠ›

ğ›½=ğ‘+1

hğ‘ğ‘–ğ‘›[ğ‘›] [ğ›¾] [ğ›½]i

to establish the invariant for loop (1.1.1).

To establish the invariant for loop (1.1), when the inner-most loop (1.1.1) terminates we have

ğ‘ > ğ›¾, and so we have:

ğ‘ƒâŠ›

ğ›½=0

hğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ›½]i âŠ›

ğ‘ƒâŠ›

ğ›½=ğ‘+1

hğ‘ğ‘–ğ‘›[ğ‘›] [ğ›¾] [ğ›½]i.

To establish the invariant for loop (1), note that the invariant for loop (1.1) holds on loop entry
since ğ‘§ is zero-initialized (DetInd). And the loop invariant for loop (1) is established when loop
(1.1) exits, when ğ‘ = ğ‘ƒ.

Next, we tackle loop (2). We take the invariant:

ğ‘âŠ›

ğ›½=0

ğ¶

Ã›ğ›¾=0

hğ‘œğ‘£ğ‘’ğ‘Ÿ [ğ›¾] [ğ›½]i âŠ›

ğ‘ƒâŠ›

ğ›½=ğ‘

hğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ›½]i.

For the inner loop (2.1), we take the invariant:

ğ‘+[ğ‘>ğ›¾ ]âŠ›

ğ›½=0

hğ‘œğ‘£ğ‘’ğ‘Ÿ [ğ›¾] [ğ›½]i âŠ›

ğ‘ƒâŠ›

ğ›½=ğ‘+[ğ‘>ğ›¾ ]

hğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ›½]i.

ğ¶

Ã›ğ›¾=0

Again, we show the invariant post-conditions for a ï¬xed ğ›¾. For the critical iteration ğ‘ = ğ›¾, we again
isolate ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ‘], observe that addition is monotone and the function [ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ‘] [ğ‘] > ğ‘‡ğ‘ğ‘–ğ‘›] is
monotone in ğ‘ğ‘–ğ‘›ğ¶ğ‘¡ [ğ›¾] [ğ‘], and apply the NA frame rule (NegFrame).

Finally at the end of the program, we can show:

along with the regular invariant

ğ‘ƒâŠ›

ğ›½=0

hğ‘œğ‘£ğ‘’ğ‘Ÿ [ğ›¾] [ğ›½]i

ğ‘ƒ

ğ‘œğ‘£ğ‘’ğ‘Ÿğ¶ğ‘¡ [ğ›¾] âˆ¼

ğ‘œğ‘£ğ‘’ğ‘Ÿ [ğ›¾] [ğ›½].

Ã•ğ›½=0

We can then apply the negative-dependence Chernoï¬€ bound (NA-Chernoï¬€):
Pr[ğ‘œğ‘£ğ‘’ğ‘Ÿğ¶ğ‘¡ [ğ›¾] > E[ğ‘œğ‘£ğ‘’ğ‘Ÿğ¶ğ‘¡ [ğ›¾]] + ğ‘‡ (ğœŒğ‘œğ‘£ğ‘’ğ‘Ÿ , ğ‘ƒ)] â‰¤ ğœŒğ‘œğ‘£ğ‘’ğ‘Ÿ .
Using the expectation bound from the previous step and putting everything together, we conclude:

ğ¶

{âŠ¤} FDDict {

Pr[ğ‘œğ‘£ğ‘’ğ‘Ÿğ¶ğ‘¡ [ğ›¾] > ğ‘ƒ Â· ğœŒğ‘ğ‘–ğ‘› + ğ‘‡ (ğœŒğ‘œğ‘£ğ‘’ğ‘Ÿ , ğ‘ƒ)] â‰¤ ğœŒğ‘œğ‘£ğ‘’ğ‘Ÿ },

Ã›ğ›¾=0

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

57:58

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

thus showing a high-probability upper-bound on the number of overfull pocket dictionaries within
each crate.

F.4 Repeated Balls-into-Bins

We will refer to the loops in Figure 8b using the same scheme we used before: the outer-most loop
is loop (1), the three next-outer-most loops are loops (1.1), (1.2), and (1.3), and the inner-most loop
is loop (1.2.1). Starting from the outside, we take the following invariant for loop (1):

ğ‘Ÿ

ğ‘

Pr

(ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ğ¶ğ‘¡ [ğ›½] > ğ‘‡ğ‘’ğ‘šğ‘ğ‘¡ ğ‘¦ )

â‰¤ ğ‘Ÿ Â· ğœŒğ‘’ğ‘šğ‘ğ‘¡ ğ‘¦ âˆ§

ğ‘ğ‘¡ [ğ›¼] âˆ¼ ğ‘

Ã•ğ›¼ =0
Showing the invariant condition requires some work. First, note that:

ï£®
Ãœğ›½=0
ï£¯
ï£¯
ï£¯
ï£¯
ï£°
|=Mem

ï£¹
ï£º
ï£º
ï£º
ï£º
ï£»

ğ‘

ğ‘ğ‘¡ [ğ›¼] âˆ¼ ğ‘ â†’

ğ‘

ğ‘ğ‘¡ [ğ›¼] âˆ¼ |ğœ âˆ’1(ğ›¼)|

Ã•ğ›¼ =0

Ãœğœ:[ğ‘ ]â†’[ğ‘ ]

Ã›ğ›¼ =0

where ğœ : [ğ‘ ] â†’ [ğ‘ ] ranges over all assignments of ğ‘ balls to ğ‘ bins, and where we write |=Mem
to denote that the formula is valid in all memories, rather than distributions over memories. We
write ğœ (ğ›¼) = |ğœ âˆ’1(ğ›¼)| for the number of balls in bin ğ›¼. We will show:

ğ‘

{

ğ‘ğ‘¡ [ğ›¼] âˆ¼ ğœ (ğ›¼)} ğ‘ğ‘œğ‘‘ğ‘¦ {Pr

ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ğ¶ğ‘¡ [ğ‘Ÿ ] < ğ‘‡ğ‘’ğ‘šğ‘ğ‘¡ ğ‘¦

â‰¤ ğœŒğ‘’ğ‘šğ‘ğ‘¡ ğ‘¦}

Ã›ğ›¼ =0

where ğ‘ğ‘œğ‘‘ğ‘¦ is the body of loop (1). For loop (1.1), it is straightforward to show the invariant using
the loop rule Loop:

(cid:2)

(cid:3)

ğ‘

ğ‘›

ğ‘›

(ğ‘ğ‘¡ [ğ›¼] âˆ¼ ğœ (ğ›¼))âˆ§

(ğ‘ğ‘¡ [ğ›¼] âˆ¼ ğœ (ğ›¼) âˆ’ [ğœ (ğ›¼) > 0])âˆ§ğ‘Ÿğ‘’ğ‘š âˆ¼

[ğœ (ğ›¼) > 0]âˆ§(Â¬(ğ‘› < ğ‘ ) â†’ ğ‘› âˆ¼ ğ‘ )

ğ›¼ =ğ‘›
Ã›
At the exit of loop (1.1), we have:

Ã›ğ›¼ =0

Ã•ğ›¼ =0

ğ‘âŠ›

ğ›¼ =0

hğ‘ğ‘¡ [ğ›¼]i

since counts are all equal to expressions of logical variables, so conditioning on the logical variables,
they are all deterministic; we take this formula to be the invariant for loop (1.2). Note that the loop
guard is not deterministic, since the value of ğ‘Ÿğ‘’ğ‘š is randomized. However, under our conditioning,
ğ‘Ÿğ‘’ğ‘š is deterministic under our conditioning since it is fully determined by the initial counts (i.e.,
it is the number of buckets that are initially non-empty). Hence, we may apply the loop rule Loop,
treating the loop guard as deterministic. This is the power of reasoning under conditioning.

Now to establish the invariant for loop (1.2), we reason much as in the previous examples. The

sampling rule Samp* gives:

By negative association for one-hot encoding (OH-PNA):

ğ‘âŠ›

ğ›¼ =0

hğ‘ğ‘¡ [ğ›¼]i âˆ— hğ‘ğ‘–ğ‘›[ ğ‘— ]i

This implies:

ğ‘âŠ›

ğ›¼ =0

hğ‘ğ‘¡ [ğ›¼]i âˆ—

ğ‘âŠ›

ğ›¼ =0

hğ‘ğ‘–ğ‘›[ ğ‘— ] [ğ›¼]i

ğ‘âŠ›

ğ›¼ =0

hğ‘ğ‘¡ [ğ›¼]i âŠ›

ğ‘âŠ›

ğ›¼ =0

hğ‘ğ‘–ğ‘›[ ğ‘— ] [ğ›¼]i

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

A Separation Logic for Negative Dependence

57:59

For the inner-most loop (1.2.1), we apply the same technique as for loop (1.2). Since loop (1.2) has a
randomized guard, ğ‘˜ is a random variable and loop (1.2.1) also has a randomized guard. However,
under the conditioning, we may assume that ğ‘˜ is deterministic and apply Loop on loop (1.2.1) with
the following invariant:

ğ‘˜âŠ›

ğ›¼ =0

hğ‘ğ‘¡ [ğ›¼]i âŠ›

hğ‘ğ‘¡ [ğ‘˜]i âŠ›

ğ‘âŠ›

ğ›¼ =ğ‘˜

hğ‘ğ‘–ğ‘›[ ğ‘— ] [ğ›¼]i

âŠ›

ğ‘âŠ›

ğ›¼ =ğ‘˜+1

hğ‘ğ‘¡ [ğ›¼]i âˆ§ (Â¬(ğ‘˜ < ğ‘ ) â†’ ğ‘˜ âˆ¼ ğ‘ )

Âª
Â®
Like in earlier examples, we can establish this invariant using the negative dependence frame rule
since ğ‘ğ‘¡ [ğ‘›] + ğ‘ğ‘–ğ‘›[ ğ‘— ] [ğ‘›] is monotone. Thus at exit of loop (1.2.1), we have:
Â¬

Â«

Â©

ğ‘âŠ›

ğ›¼ =0

hğ‘ğ‘¡ [ğ›¼]i

Next, three applications of the assignment rule RAssn give:

ğ‘âŠ›

ğ›¼ =0

hğ‘ğ‘¡ [ğ›¼]i âˆ§ ğ‘› âˆ¼ 0 âˆ§ ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ğ¶ğ‘¡ [ğ‘Ÿ ] âˆ¼ 0 âˆ§ ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ âˆ¼ ğ‘–ğ‘ ğ‘ğ‘’ğ‘Ÿğ‘œ (ğ‘ğ‘¡)

The function ğ‘–ğ‘ ğ‘ğ‘’ğ‘Ÿğ‘œ (ğ‘£) takes a vector of numbers ğ‘£, and returns a vector where each index ğ‘– 1 if
ğ‘£ [ğ‘–] is zero, else it holds 0. This is an antitone function: it is non-increasing in its argument. Thus,
the monotone mapping axiom (Mono-Map) gives:

Then, a standard loop invariant for loop (1.3) gives:

ğ‘âŠ›

ğ›¼ =0

hğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ [ğ›¼]i

ğ‘âŠ›

ğ›¼ =0

hğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ [ğ›¼]i âˆ§ ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ğ¶ğ‘¡ [ğ‘Ÿ ] âˆ¼

ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ [ğ›¼]

ğ‘

Ã•ğ›¼ =0

Now, we are in position to apply the negative association Chernoï¬€ bound (NA-Chernoï¬€), giving
the judgment:

ğ‘ğ‘¡ [ğ›¼] âˆ¼ ğœ (ğ›¼)} ğ‘ğ‘œğ‘‘ğ‘¦ {Pr[ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ğ¶ğ‘¡ [ğ‘Ÿ ] < E[ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ğ¶ğ‘¡ [ğ‘Ÿ ]] âˆ’ ğ‘‡ (ğœŒğ‘’ğ‘šğ‘ğ‘¡ ğ‘¦, ğ‘ )] â‰¤ ğœŒğ‘’ğ‘šğ‘ğ‘¡ ğ‘¦}

ğ‘

{

Ã›ğ›¼ =0

where ğ‘ğ‘œğ‘‘ğ‘¦ is the body of loop (1). However, we are not yet done. We want to combine these
judgmentsâ€”one for each map ğœ : [ğ‘ ] â†’ [ğ‘ ]â€”using the randomized case analysis rule RCase We
can take the trivial pre-condition ğœ™ = âŠ¤, and the case condition:

ğ‘

ğœ‚ =

ğ‘ğ‘¡ [ğ›¼] âˆ¼ ğœ (ğ›¼)

Ã›ğ›¼ =0

Since ğœ‚ asserts that the equality holds with probability 1, it is closed under conditioning. However,
our post-condition has a problem: it mentions the expected value E[ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ğ¶ğ‘¡ [ğ‘Ÿ ]], which may not
be preserved under mixtures, so the entire assertion is not CM. However, translating an argument
by Becchetti et al. [2019, Lemma 2] into our logic gives:

ğ‘ğ‘¡ [ğ›¼] âˆ¼ ğœ (ğ›¼)} ğ‘ğ‘œğ‘‘ğ‘¦ {E[ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ğ¶ğ‘¡ [ğ‘Ÿ ]] â‰¥ ğ‘ /15}

ğ‘

{

Ã›ğ›¼ =0

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

 
57:60

Jialu Bao, Marco Gaboardi, Justin Hsu, and Joseph Tassarotti

assuming that ğ‘ â‰¥ 2. The argument makes use of basic properties of expected values and the
exponential function; we omit the details. Thus, we have:

ğ‘

{

ğ‘ğ‘¡ [ğ›¼] âˆ¼ ğœ (ğ›¼)} ğ‘ğ‘œğ‘‘ğ‘¦ {Pr[ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ğ¶ğ‘¡ [ğ‘Ÿ ] < ğ‘ /15 âˆ’ ğ‘‡ (ğœŒğ‘’ğ‘šğ‘ğ‘¡ ğ‘¦, ğ‘ )] â‰¤ ğœŒğ‘’ğ‘šğ‘ğ‘¡ ğ‘¦}

Ã›ğ›¼ =0

and the post-condition is now a CM assertion. Applying RCase, we have:

ğ‘

{

ğ‘ğ‘¡ [ğ›¼] âˆ¼ ğ‘ } ğ‘ğ‘œğ‘‘ğ‘¦ {Pr[ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ğ¶ğ‘¡ [ğ‘Ÿ ] < ğ‘ /15 âˆ’ ğ‘‡ (ğœŒğ‘’ğ‘šğ‘ğ‘¡ ğ‘¦, ğ‘ )] â‰¤ ğœŒğ‘’ğ‘šğ‘ğ‘¡ ğ‘¦}

Ã•ğ›¼ =0

Recalling that we wanted the following invariant for loop (1):

ğ‘Ÿ

ğ‘

Pr

(ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ğ¶ğ‘¡ [ğ›½] < ğ‘‡ğ‘’ğ‘šğ‘ğ‘¡ ğ‘¦ )

â‰¤ ğ‘Ÿ Â· ğœŒğ‘’ğ‘šğ‘ğ‘¡ ğ‘¦ âˆ§

ğ‘ğ‘¡ [ğ›¼] âˆ¼ ğ‘

ï£¹
ï£º
ï£º
we can use the rule of constancy Const and the assignment rule RAssn to preserve the ï¬rst con-
ï£º
ï£º
junct to show:
ï£»

ï£®
Ãœğ›½=0
ï£¯
ï£¯
ï£¯
ï£¯
ï£°

Ã•ğ›¼ =0

ğ‘Ÿ âˆ’1

Pr

(ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ğ¶ğ‘¡ [ğ›½] < ğ‘‡ğ‘’ğ‘šğ‘ğ‘¡ ğ‘¦)

â‰¤ (ğ‘Ÿ âˆ’ 1) Â· ğœŒğ‘’ğ‘šğ‘ğ‘¡ ğ‘¦

Ãœğ›½=0

ï£®
ï£¯
ï£¯
ï£¯
ï£¯
ï£°

ï£¹
ï£º
ï£º
ï£º
ï£º
ï£»

at the end of the body of loop (1). Combined with the probability bound for ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ğ¶ğ‘¡ [ğ‘Ÿ ], an ap-
plication of the union bound (UnionBd) establishes the invariant for loop (1). Putting everything
together, we have:

{ğ‘ â‰¥ 2 âˆ§

ğ‘

Ã•ğ›¼ =0

ğ‘ğ‘¡ [ğ›¼] âˆ¼ ğ‘} RepeatBIB {Pr

analogous to Becchetti et al. [2019, Lemma 1 and 2].

ï£®
Ãœğ›½=0
ï£¯
ï£¯
ï£¯
ï£¯
ï£°

F.5 Axioms for Examples

ğ‘…

(ğ‘’ğ‘šğ‘ğ‘¡ğ‘¦ğ¶ğ‘¡ [ğ›½] < ğ‘ /15 âˆ’ ğ‘‡ (ğœŒğ‘’ğ‘šğ‘ğ‘¡ ğ‘¦, ğ‘ ))

â‰¤ ğ‘… Â· ğœŒğ‘’ğ‘šğ‘ğ‘¡ ğ‘¦}

ï£¹
ï£º
ï£º
ï£º
ï£º
ï£»

For completeness, we present the probability-related axioms that we need for the examples. For
simplicity we present the axioms in binary form, though most extend directly to big operations.

â€¢ Linearity of expectation. Let ğ‘’, ğ‘“ be bounded expressions.

|= E[ğ›¼ Â· ğ‘’ + ğ›½ Â· ğ‘“ ] âˆ¼ ğ›¼ Â· E[ğ‘’] + ğ›½ Â· E[ğ‘“ ]

(LinExp)

â€¢ Union bound. Let ğ‘’ğ‘£1, ğ‘’ğ‘£2 âˆˆ EV,

â€¢ Permutation marginal. Let ğ‘¥ be an array variable, and let ğ‘† be a ï¬nite set.

|= Pr[ğ‘’ğ‘£1 âˆ¨ ğ‘’ğ‘£2] â‰¤ Pr[ğ‘’ğ‘£1] + ğ‘ƒğ‘Ÿ [ğ‘’ğ‘£2]

(UnionBd)

|= Permğ‘† hğ‘¥i â†’ Uğ‘† hğ‘¥ [ğ›¼]i
â€¢ Expectation Indicator. Let ğ‘’ be a 0/1 valued expression,

|= E[ğ‘’] âˆ¼ Pr[ğ‘’ = 1]

â€¢ Bernoulli variables probabilities. Let ğ‘’ be an expression,

|= Bernğ‘ hğ‘’i â†’ Pr[ğ‘’ = 1] = ğ‘

â€¢ Probability of uniform. Let ğ‘† be a ï¬nite set.

|= Pr[Uğ‘† hğ‘¥i = ğ›¼] âˆ¼ 1/|ğ‘† |

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

(PermMarg)

(ExpectInd)

(BernProb)

(ProbUnif)

A Separation Logic for Negative Dependence

57:61

â€¢ Bijection uniform. Let ğ‘† be a ï¬nite set, and let ğ‘“ : ğ‘† â†’ ğ‘† be a bijection.

|= Uğ‘† hğ‘¥i â†’ Uğ‘† hğ‘“ (ğ‘¥)i

â€¢ One-hot marginal. Let ğ‘¥ be an array variable.

|= OHğ‘† hğ‘¥i â†’ Uğ‘† hğ‘¥ [ğ›¼]i

â€¢ Independent product one-hot.

(BijectUnif)

(OHMarg)

|= OH[ğ‘€ ] hğ‘¥i âˆ— OH[ğ‘ ] hğ‘¦i â†’ OH[ğ‘€ ]Ã—[ğ‘ ] hğ‘¥ âŠ¤ Â· ğ‘¦i

(IndProdOH)

â€¢ Independent map. Let ğ‘¥ be an array variable of length ğ‘ .

ğ›¼ =0
â€¢ Deterministic independent. Let ğ‘¥ be a variable.

ğ›¼ =0

ğ‘âˆ—

|=

hğ‘¥ [ğ›¼]i â†’

hğ‘“ (ğ‘¥ [ğ›¼])i

ğ‘âˆ—

|= Detmhğ‘¥i â†’ hğ‘¥i âˆ— hğ‘’i

â€¢ Events happen only if they have probability one. Let ğ‘’ğ‘£ âˆˆ EV,

|= ğ‘’ğ‘£ = 1 â†’ Pr(ğ‘’ğ‘£) = 1

(IndMap)

(DetInd)

(ProbOne)

â€¢ Uniform sampling from a population. We represent a population as a bit-vector, where each
entry is an individual and 1 indicates they have some feature and 0 indicates not. Then,
if we uniformly sample from the population, the probability of getting a one is equal to
population-level ratio of ones, regardless how they are distributed in the population. Let
ğ‘ â‰¥ ğ½ be constants or logical variables, ğ‘ be an array variable of length ğ‘ , and ğ‘¥, â„ğ‘–ğ‘¡ be
variables:

|=

bv(ğ‘, ğ½ , ğ‘ ) âˆ— U[ğ‘ ] hğ‘¥i

âˆ§ â„ğ‘–ğ‘¡ âˆ¼ ğ‘ [ğ‘¥]

â†’ Bernâ„ğ‘–ğ‘¡ h

ğ½
ğ‘

i âˆ—

ğ‘

ğ‘ [ğ›½] = ğ½

.

(UniformSamp)

(cid:0)(cid:0)

(cid:1)
â€¢ Independent product probabilities. Let ğ‘’ğ‘£1, ğ‘’ğ‘£2 âˆˆ EV , ğ½ , ğ¾ be two real numbers,

(cid:1)

|= Pr[ğ‘’ğ‘£1] â‰¤ ğ½ âˆ— Pr[ğ‘’ğ‘£2] â‰¤ ğ¾ â†’ Pr[ğ‘’ğ‘£1 âˆ§ ğ‘’ğ‘£2] â‰¤ ğ½ Â· ğ¾.

Â«

(IndepProb)

Ã•ğ›½=0
Â©

Âª
Â®
Â¬

â€¢ Equal probabilities. Let ğ‘1, ğ‘2 be two boolean expressions. Recall that ğ‘1, ğ‘2 âˆˆ EV too.
|= ğ‘1 âˆ¼ ğ‘2 â†’ Pr[ğ‘1] = Pr[ğ‘2]

(EqualProb)

Proc. ACM Program. Lang., Vol. 6, No. POPL, Article 57. Publication date: January 2022.

 
