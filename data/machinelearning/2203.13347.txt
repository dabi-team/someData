Multi-modal multi-objective model-based genetic programming
to find multiple diverse high-quality models

E.M.C. Sijben
Centrum Wiskunde & Informatica
Amsterdam, the Netherlands
evi.sijben@cwi.nl

T. Alderliesten
Leiden University Medical Center
Leiden, the Netherlands
t.alderliesten@lumc.nl

P.A.N. Bosman
Centrum Wiskunde & Informatica
Amsterdam, the Netherlands
peter.bosman@cwi.nl

2
2
0
2

r
a

M
4
2

]
E
N
.
s
c
[

1
v
7
4
3
3
1
.
3
0
2
2
:
v
i
X
r
a

ABSTRACT
Explainable artiï¬cial intelligence (XAI) is an important and rapidly
expanding research topic. The goal of XAI is to gain trust in a
machine learning (ML) model through clear insights into how the
model arrives at its predictions. Genetic programming (GP) is often
cited as being uniquely well-suited to contribute to XAI because of
its capacity to learn (small) symbolic models that have the poten-
tial to be interpreted. Nevertheless, like many ML algorithms, GP
typically results in a single best model. However, in practice, the
best model in terms of training error may well not be the most suit-
able one as judged by a domain expert for various reasons, includ-
ing overï¬tting, multiple diï¬€erent models existing that have simi-
lar accuracy, and unwanted errors on particular data points due to
typical accuracy measures like mean squared error. Hence, to in-
crease chances that domain experts deem a resulting model plausi-
ble, it becomes important to be able to explicitly search for multi-
ple, diverse, high-quality models that trade-oï¬€ diï¬€erent meanings
of accuracy. In this paper, we achieve exactly this with a novel
multi-modal multi-tree multi-objective GP approach that extends
a modern model-based GP algorithm known as GP-GOMEA that
is already eï¬€ective at searching for small expressions.

1 INTRODUCTION
State-of-the-art machine learning models are often diï¬ƒcult to in-
terpret. This can be caused by models having many coeï¬ƒcients,
many variables, and/or an intricate structure. The popular ï¬eld
of eXplainable Artiï¬cial Intelligence (XAI) aims to either develop
methods that enable humans to interpret the complex machine
learning model and its predictions, or to make inherently inter-
pretable models. Models are unlikely to be inherently interpretable
if they have many coeï¬ƒcients and/or variables. Therefore, it makes
sense to restrict the size of the model. However, doing so may neg-
atively aï¬€ect model performance. Ideally, one would obtain both
high performance and interpretability.

Genetic Programming (GP) is a learning algorithm that can gen-
erate expressions that are ï¬‚exible in their structure, and in the op-
erators or functions used in these expressions. This enables GP to
capture non-linear relations in a compact expression, oï¬€ering a
useful trade-oï¬€ between performance and size compared to other
methods [16]. This quality is why GP has been suggested to be
useful for XAI [9, 10, 23].

XAI approaches aim to give users insight into a model. This al-
lows users to make more informed use of the model in the real
world [4, 19]. However, if a model has (serious) shortcomings or
other problems, although now the user may be informed about
these potential problems, insight alone does not necessarily pro-
vide a solution, nor a direct way to change the model. Of course,

Figure 1: Visualization of our approach.

users can always choose not to use the model. Ideally, however,
users would be able to choose a model from a list of models that
exhibit diï¬€erent qualities, to meet their speciï¬c preferences and
prevent model rejection. Unfortunately, this is typically not possi-
ble because most machine learning algorithms generate only one
model.

In practice, due to the amount of data available (both in terms of
records and variables) and/or the complexity of the prediction task,
combined with a ï¬nite capacity of learnable models, it is unlikely
that the optimal model (in terms of minimum training or valida-
tion error) is unique. Even if it is, it might not be the best model
according to the user. The user may have certain model require-
ments, or there could be conï¬‚icts between the model and expert
knowledge about the domain. Additionally, it might not be the best
model simply because the data is limited and models with slightly
worse performance in error on the data at hand are better if we
had inï¬nite data to train on.

Therefore, it would be very useful in practice, with the vision
of a domain-expert end-user selecting the preferred model for the
task at hand, to be able to search for multiple models that are all
well-performing but are also diverse and potentially even describe
diï¬€erent parts of the data better. Allowing the user to inspect such
a set of diï¬€erent models may provide unique novel insights into the
data and the process underlying the data, and support choosing a
good model with additional expert knowledge in a powerful and
sensible way. Thereby user agency and control are increased.

In this paper, we propose exactly this: searching, in a novel way,
for sets of multiple models instead of a single model. Rather than
using (adaptive) niching or ï¬tness sharing, we use a multi-tree GP
model. This enables us to explicitly deï¬ne diversity between mod-
els and perform multi-modal search in a potentially highly multi-
modal search space by ï¬nding a ï¬xed number of modes/niches.

 
 
 
 
 
 
Moreover, by deï¬ning the search in a Multi-Objective (MO) way,
we can optimize for both diversity between models and model per-
formance. Finally, by using particular notions of diversity, we can
not only ï¬nd models that are diï¬€erent, but even focus on diï¬€erent
parts of the data in diï¬€erent ways, giving additional meaning and
potentially practically useful dimensions to the models that will be
presented to the user. We visualize our approach in Figure 1. To the
best of our knowledge, this is the ï¬rst paper to propose searching
for diverse multi-tree models with an MO approach.

Besides searching for a set of models, the ultimate goal is to
create interpretable models. While we do not directly focus on in-
terpretability here, we do consider that smaller models are likely
more interpretable than larger models. Under this assumption, it
becomes interesting to look at GP approaches that are particularly
well-suited to evolving small solutions. Results show that the GP
variant of the Gene-pool Optimal Mixing Evolutionary Algorithm
(GP-GOMEA) gives better results when searching for solutions of
limited tree size than classic GP [23]. An MO version of GP-GOMEA
does not yet exist, however. Therefore, we implement an MO vari-
ant of GP-GOMEA by leveraging the best practices previously em-
ployed in the design of MO-GOMEA [17].

The contribution of this paper is threefold. We 1) develop a
novel approach for searching for sets of high-quality and diverse
multi-tree GP models, 2) implement a version of GP-GOMEA with
multi-trees and MO optimization, and 3) show the beneï¬ts of our
approach by applying it to real-world data sets.

2 RELATED WORK
Diversity maintenance is a well-studied subject in GP that aims
to improve diversity in the whole population to prevent prema-
ture convergence. In [11] semantic diversity is promoted by using
the semantic crowding distance. The semantic crowding distance
adopts the same principles as the crowding distance except it does
not look at the distance in objective space but in semantic space.
Not only is the regular crowding distance replaced by the semantic
one, the semantic crowding distance is also added as an objective.
In [2], an extension of the age-ï¬tness Pareto optimization [20],
an MO method that optimizes age and ï¬tness, is proposed. The idea
behind this is to avoid that younger individuals, that have had less
time to become ï¬t, compete with older individuals, that have had
more time to become ï¬t. Thereby, the competition between indi-
viduals with a similar age is stimulated. A metric for tree structure
similarity (genetic marker density) is used instead of age to prevent
converging to a speciï¬c structure.

The FOCUS method [5] performs an MO search with three ob-
jectives: ï¬tness, size, and average squared overlapping tree dis-
tance to other members in the population. Individuals are stimu-
lated to move away from the central peak in the ï¬tness landscape
if the central peak becomes too crowded.

In [18] ï¬tness sharing for GP is introduced. The general idea is
to reward solutions that are diï¬€erent, i.e., the reward for each pre-
diction is divided by the number of individuals in the population
that give the same prediction. A distance function that reï¬‚ects the
structural dissimilarity of trees to extend the applicability of ï¬tness
sharing for tree-based methods is introduced in [8].

Our work distinguishes itself from the above-mentioned works
because we do not primarily aim to avoid premature convergence,

E.M.C. Sijben, T. Alderliesten, and P.A.N. Bosman

but we aim to present the user with a diverse set of potentially
interesting models. Furthermore, the approach we present in this
paper to realize this goal, is novel, for two reasons: 1) we maintain
diversity within individuals rather than diversity across the pop-
ulation by using an MO search with multi-tree individuals, and 2)
we incorporate a novel diversity objective in this approach that has
particular relevance to machine learning.

3 MULTI-MODAL MULTI-OBJECTIVE

MODEL-BASED GP

In this section, we present our approach to search for diverse high-
quality models. It has four key components: GP-GOMEA, multi-
tree individuals, MO optimization, and a particular diversity objec-
tive.

We use GP-GOMEA [23] because it is known to oï¬€er a good
trade-oï¬€ between performance and model size [16]. We implement
multi-tree individuals, which allows us to express diversity within
individuals. We choose to maintain diversity within individuals
rather than maintaining diversity across the population because
this allows us to more easily stimulate diversity and performance
at the same time. To optimize for both diversity and performance
we implement an MO variant of GP-GOMEA, where we leverage
best practices of MO-GOMEA [17], and introduce a diversity objec-
tive function, which we optimize together with an error objective.

3.1 Gene-pool Optimal Mixing Evolutionary

Algorithm (GOMEA)

GOMEA is a model-based Evolutionary Algorithm (EA) that has
been shown to be eï¬€ective in many domains such as discrete opti-
mization [17, 21], real-valued optimization [1], and, most relevant
here, GP [23]. GOMEA diï¬€ers from classic EAs in that it uses a link-
age model that is meant to capture the interdependencies within
the genotype. This information is then used during variation to
prevent building blocks (or partial solutions) from being disrupted
and to eï¬€ectively mix these blocks to create better solutions.

In GOMEA, a ï¬xed-length string is used as the genotype so that
genes at a certain location in the string always represent the same
variables in the problem. Linkage information is represented as a
Family Of Subsets (FOS). The FOS contains subsets of genes (string
indices) that are assumed to be linked.

If no linkage information is known a priori, it can be learned
from the population during search. To this end, Mutual Informa-
tion (MI) is often used to measure linkage among gene pairs and
a so-called Linkage Tree (LT) is built to represent variable depen-
dence relations in a hierarchical fashion. Computing joint MI for
more than two genes is costly and requires large population sizes
to be accurate. Therefore, the UPGMA algorithm [13] is used to
approximate linkage for larger groups of genes. UPGMA is a hi-
erarchical clustering algorithm that merges subsets, starting from
singleton sets, which in GOMEA contain the individual genes. For
the similarity measure in UPGMA, the pairwise average MI is used.
At each merge step, the newly constructed cluster is added to the
FOS, ultimately resulting in the LT. Merging is usually stopped in
GOMEA when only two clusters are left. The subset containing all
genes is typically not added to the FOS because using this subset
would result in entire solutions being cloned during variation.

Multi-modal multi-objective model-based genetic programming to find multiple diverse high-quality models

In GOMEA, every generation, each individual in the population
undergoes variation through Gene-pool Optimal Mixing (GOM).
GOM uses the information in the FOS to replace linked genes at
the same time. Suppose individual Pğ‘– undergoes GOM. First, Pğ‘–
is cloned into oï¬€spring Oğ‘–. Then, each of the subsets in the FOS is
considered in a random order. For each FOS subset anew, a donor is
randomly selected from the population. The values of the genes in
Oğ‘– are replaced with those of the donor, but only at the positions
speciï¬ed by the FOS subset. If a replacement did not result in a
worse ï¬tness, the change is kept.

After processing all FOS elements, Oğ‘– is added to the oï¬€spring
set and the next population member is considered. After process-
ing the entire population, the population is replaced by the oï¬€-
spring.

3.2 GP-GOMEA & Multi-trees
GP-GOMEA is a GP variant of GOMEA [23]. In GP-GOMEA, in-
dividuals are trees that adhere to a template with ï¬xed node po-
sitions. This enables mapping trees to strings in a ï¬xed manner,
i.e., nodes at the same position in diï¬€erent trees always map to the
same string index. Consequently, learning an FOS and GOM varia-
tion can be straightforwardly used. However, a particular form of
normalization is used on the estimated MI values to account for
suprious linkage in the initial population that may occur in the
case of GP trees because not every node in the GP tree is always
used, nor can every node represent the same thing (leaves cannot
represent functions). For more details, see [23].

Figure 2 shows an example of a variation step in GP-GOMEA,
where we variate Oğ‘– using FOS subset member {2, 6}. Elements at
indices 2 and 6 in selected individual Oğ‘– are replaced with those of
donor tree Pğ‘— , where ğ‘— is randomly selected.

1

+

2

Ã—
Ã—

5

/

3

ğ‘¥1
ğ‘¥1

4

ğ‘¥2

6

ğ‘¥1
ğ‘¥1

7

ğ‘¥3

(a) Donor tree Pğ‘— for variation with Oğ‘– .

1

+

1

+

2

âˆ’
Ã—

5

âˆ’

2

Ã—
Ã—

5

âˆ’

3

ğ‘¥1
ğ‘¥1

4

ğ‘¥1

6

ğ‘¥2
ğ‘¥2

7

ğ‘¥3

â†’

3

ğ‘¥1
ğ‘¥1

4

ğ‘¥1

6

ğ‘¥1
ğ‘¥2

7

ğ‘¥3

(b) Recipient tree Oğ‘– before
variation with Pğ‘— .

(c) Recipient tree Oğ‘– after
variation with Pğ‘— .

Figure 2: GOM step for FOS element {2, 6} applied to oï¬€-
spring Oğ‘– using donor Pğ‘— .

In our approach, we use a multi-tree representation. A multi-
tree ğ‘‡ consist of multiple trees ğ‘¡ğ‘– such that ğ‘‡ = (ğ‘¡1, . . . , ğ‘¡ğ‘›). A
multi-tree implementation of GP-GOMEA did, however, not yet
exist. To support multi-tree in GP-GOMEA, we concatenate the
string representations of the ğ‘› trees. Therefore, the indices count

onward from one tree to another tree. For a multi-tree with 2 trees
and a height of 3, this means that the ï¬rst tree has a root node with
index 1 and contains indices 1 through 7 as in Figure 2. The second
tree has a root node with index 8 and contains indices 8 through
14.

Note that GOM always replaces a gene at index ğ‘– with a gene in
a donor solution at index ğ‘–. GOM will thus not replace nodes from
tree ğ‘¡ğ‘– of a multi-tree with nodes from ğ‘¡ ğ‘— from a donor multi-tree
where ğ‘– â‰  ğ‘—. We do, however, want to be able to learn interdepen-
dencies across trees in a multi-tree. This will, for example, enable
to learn that index 2 in the ï¬rst tree is linked to index 11 in the
second tree, which allows GOM to replace these nodes simultane-
ously. This is straightforwardly achieved because we concatenate
the string representations of the ğ‘› trees to achieve the string repre-
sentation in GOMEA. Automatically, therefore, an FOS is learned
that can represent interdependencies across trees.

However, we know, by design, that we are modelling multiple
trees and that these trees separately will make a substantial contri-
bution to the objective functions. For this reason, it is also of value
to learn an FOS (an LT, to be precise) for each GP tree indepen-
dently, which we propose to do. Moreover, because these GP trees
are individual components of the larger multi-tree, we want to be
able to exchange entire trees as well. For this, when we learn an
LT for a single GP tree in the multi-tree representation, we do not
discard the FOS element with all variable indices. The ï¬nal FOS
that is used for GOM, is the union of the FOS learned for the entire
multi-tree and all of the FOSs learned for each GP tree separately.

3.3 MO-GP-GOMEA
Our goal is to search for trees that are both of high-quality and di-
verse. Using a multi-tree representation, we can explicitly express
these notions over the multi-tree and optimize for them.

By properly governing that these expressions stay diï¬€erent through-

out the search, we could design a multi-modal approach around
this representation that searches for ğ‘› local optima. However, as
stated in the introduction, the expression with the smallest train-
ing error is not necessarily the preferred one, due to noise in the
data, limited data, missing features, expert knowledge, and/or user
needs. Hence, in a user-centered XAI setting, returning only the
expression with the lowest training error, or even multiple expres-
sions with the same optimal training error, is likely not satisfactory.
It would be prudent to accept that our data is not perfect and ex-
plicitly also search for other properties of our expressions that rep-
resent potentially other things a domain expert could be interested
in. Therefore, we present an objective that stimulates searching for
such potentially interesting properties in subsection 3.4.

Firstly, however, it is important to realize that ï¬nding multiple
sets of expressions with diï¬€erent, conï¬‚icting properties, requires
MO search. However, only a Single-Objective (SO) version of GP-
GOMEA currently exists [23]. We therefore create, for the ï¬rst
time, an MO version of GP-GOMEA, which we base on the MO
version of GOMEA originally introduced for binary variables [17].
Pseudo-code for MO GP-GOMEA is shown above, which at the
top level, is essentially analogous to MO-GOMEA [17]. Every gen-
eration, the population is divided into ğ‘˜ clusters (line 6). The clus-
tering approach works on the basis of distance between solutions

MO-GP-GOMEA(population size ğ‘ , clusters ğ‘˜)

3:

1: for ğ‘– âˆˆ {0, 1, . . . , ğ‘ âˆ’ 1} do
2:

Pğ‘– â† CreateRandomSolution()
EvaluateFitness(Pğ‘– )
A â† UpdateElitistArchive(Pğ‘–)
4:
5: while Â¬TerminationCriteriaSatisï¬ed do
6:

{C0, C1, . . . , Cğ‘˜âˆ’1} â† ClusterPopulation(P)
for ğ‘— âˆˆ {0, 1, . . . , ğ‘˜ âˆ’ 1} do

Fğ‘— â† LearnLinkageModel(Cğ‘— )

for ğ‘– âˆˆ {0, 1, . . . , ğ‘ âˆ’ 1} do

Oğ‘– â† Clone(Pğ‘– )
Cğ‘— â† DetermineCluster(Oğ‘– , {C0, C1, . . . , Cğ‘˜âˆ’1})
if IsExtremeCluster(Cğ‘— ) then

Oğ‘– â† SingleObjective-GOM(Oğ‘– , Cğ‘— ,Fğ‘— ,A)

else

7:

8:

9:

10:

11:

12:

13:

14:

15:

16:

17:

Oğ‘– â† MultiObjective-GOM(Oğ‘– , Cğ‘— ,Fğ‘— ,A)

where

A â† UpdateElitistArchive(Oğ‘– )

P â† O = {O0, O1, . . . , Oğ‘ âˆ’1}

in normalized objective space, and is described in further detail in
the supplementary material. For every cluster, a separate FOS is
learned (line 8). Restricted mating is applied, meaning that donors
for an individual must come from the same cluster as the individ-
ual itself. Then, â€˜extremeâ€™ clusters are identiï¬ed (line 12): these are
the clusters that, on average, perform best on a single objective. In
extreme clusters, a single objective is optimized, that is, in GOM
only one objective is considered when testing for improvements
(line 13). A change is accepted if the oï¬€spring does not have worse
ï¬tness than the parent. In all other clusters, multi-objective opti-
mization is performed, that is, in GOM both objectives are consid-
ered when testing for improvements (line 15). A change is accepted
if the oï¬€spring either: 1) dominates the parent, 2) has equal objec-
tive values as the parent, 3) is not dominated by any member of the
elitist archive and has diï¬€erent objective values than any member
in the elitist archive, or 4) has the same objective values as a mem-
ber in the elitist archive but is diï¬€erent in semantic space. When
variation does not change the solution for one generation or does
not improve the solution for 1 + log10 (N) generations, we do an
additional round of GOM called Forced Improvements (FI). This
means that another round of variation is done with the donor be-
ing a random member from the elitist archive, or in the case of
extreme clusters, the solution from the archive that has the best
ï¬tness for the corresponding single objective. The acceptance is
the same as with regular variation, except, when the oï¬€spring has
the same objective value(s) as the parent, the change is rejected. In
addition, we stop iterating over the FOS once a change is accepted.
If it has not changed during FI, we replace the oï¬€spring with a ran-
dom member from the elitist archive, unless it originated from an
extreme cluster, in which case we replace it with the solution from
the archive that has the best ï¬tness in terms of the corresponding
single objective. After variation, the elitist archive is updated with
the oï¬€spring (line 16).

E.M.C. Sijben, T. Alderliesten, and P.A.N. Bosman

3.4 Objectives
We optimize for two objectives, error and diversiï¬ed error. For er-
ror, we use the commonplace Mean Squared Error (MSE). For diver-
siï¬ed error, we specify an objective that ï¬ts well with the concept
of GP-based XAI in practice as outlined in the introduction.

3.4.1 Error objective. The MSE is arguably the most commonly
adopted objective in machine learning, especially for (symbolic)
regression. In case of our multi-tree representation, to calculate
the error, for each tree ğ‘¡ğ‘– of the multi-tree ğ‘‡ , the MSE is calculated
between the targets ğ‘¦ associated with data points ğ‘‹ ğ‘— and the pre-
dictions of the tree ğ‘¡ğ‘– (ğ‘‹ ğ‘— ). We calculate the ï¬nal error ğ¸ of the
multi-tree by summing the MSE of the individual trees, i.e.:

ğ¸ =

ğ‘›

Ã•
ğ‘–=1

ğ‘€ğ‘†ğ¸ (ğ‘¡ğ‘–, ğ‘‹ , ğ‘¦),

ğ‘€ğ‘†ğ¸ (ğ‘¡ğ‘–, ğ‘‹ , ğ‘¦) =

1
|ğ‘‹ |

|ğ‘‹ |

Ã•
ğ‘—=1

(ğ‘¡ğ‘– (ğ‘‹ ğ‘— ) âˆ’ ğ‘¦ ğ‘— )2

,

ğ‘› is the number of trees in a multi-tree, and |ğ‘‹ | is the number of
records in the data set.

3.4.2 Diversified error objective. As all our experiments will be
done with two trees, for now, we introduce the deï¬nition for the
diversiï¬ed error objective for a multi-tree with two trees. We come
back to this in Section 7. We deï¬ne the diversiï¬ed error ğ· as the
mean of the minimum squared error of the individual trees, i.e.,:

ğ· =

1
|ğ‘‹ |

|ğ‘‹ |

Ã•
ğ‘—=1

min((ğ‘¡1(ğ‘‹ ğ‘— ) âˆ’ ğ‘¦ ğ‘— )2

, (ğ‘¡2 (ğ‘‹ ğ‘— ) âˆ’ ğ‘¦ ğ‘— )2).

We choose this objective function for three reasons. Firstly, it
enables ï¬nding expressions that together describe a data set well,
i.e., expressions that describe diï¬€erent parts of the data set. Note
that because we also optimize for error objective ğ¸, we will ï¬nd
expressions that not only predict the data set well together but are
also optimized for their individual error. In addition, describing dif-
ferent parts of a data set with diï¬€erent models can even improve
interpretability, because it resonates well with how humans intu-
itively understand things. Humans tend to categorize things [15].
In this way, they can dissect a problem and try to understand parts
of it separately. Secondly, in combination with the error objective,
we can ï¬nd sets of expressions that have a similar error but have a
diï¬€erent error distribution over the data points. Thirdly, an expert
may well prefer a model that is very good in some cases, but obvi-
ously wrong in others, over a model that is moderately right and
wrong in all cases. In practice, this may for instance mean fewer ad-
justments or further investigations: the cases in which the model
is very good do not need to be adjusted. Also, such an objective es-
sentially ï¬nds an ensemble of complementary models that would
have superior performance upon its use, when it is clear in practice
for a particular case which model to follow. In summary, with this
objective, we can ï¬nd expressions that describe the data better as a
set than a single expression would be able to, but at the same time,
we also ï¬nd sets containing expressions with a similar individual
error that are diï¬€erent from each other.

Alternatively, one could deï¬ne a diversity objective that maxi-
mizes the distance between the predictions of the trees within a

Multi-modal multi-objective model-based genetic programming to find multiple diverse high-quality models

multi-tree. However, this also stimulates expressions that do not
perform well and are just very diï¬€erent. By contrast, using ğ·, we
do not stimulate diversity merely for the sake of diversity.

Finally, while ğ· is proposed with the goal of oï¬€ering interesting
alternative models, ğ· is a non-smooth non-convex function, which
would be unsuitable for most typical machine learning approaches.
It is a key strength of GP, being an evolutionary machine learning
approach, that it can handle such functions.

4 EXAMPLES ON SYNTHETIC DATA
In this section, we present two examples of the use of our approach
on synthetic data. We generate two simple regression data sets,
with Gaussian Noise (ğºğ‘ ) added. We perform a single run with
our approach, using multi-tree individuals with ğ‘› = 2. We multi-
objectively optimize the error ğ¸ and the diversiï¬ed error ğ·. The
allowed symbols are the functions +, âˆ’, Ã—, Ã·ğ‘ , Ephemeral Random
Constants (ERCs), and the input variables that appear in the syn-
thetic data set. We use a maximum tree height of 3 (7 nodes), and
perform 30 generations with a population size of 1000. We choose
this population size because, on the one hand, these are quite sim-
ple problems, but on the other hand, we need to search in three
â€˜directionsâ€™; the two extremes and the trade-oï¬€ between those two.

4.1 Example 1: multi-modal data
We generate a multi-modal data set with one input variable ğ‘‹ , and
target variable ğ‘Œ using the following functions:

ğ‘“ (ğ‘‹ ) = ğ‘‹ 2 + ğºğ‘ (0, 10)
ğ‘”(ğ‘‹ ) = 2 Â· ğ‘‹ + ğºğ‘ (0, 10)

We generate 100 data points with ğ‘Œ = ğ‘“ (ğ‘‹ ) where ğ‘‹ is drawn
randomly from the interval ğ‘‹ [0, 10], and generate 40 data points
with ğ‘Œ = ğ‘”(ğ‘‹ ) where ğ‘‹ is drawn from the same interval.

We show the approximation front of the error and diversiï¬ed
error found by our approach on this data set in Figure 3. We also
show the predicted ğ‘Œ of the two expressions of three multi-tree
models along the front, against ğ‘‹ , as well as the expressions them-
selves. As can be observed, our approach can eï¬€ectively model
multi-modal data sets. In particular, we see that the expressions of
multi-tree C closely resemble ğ‘“ (ğ‘‹ ) and ğ‘”(ğ‘‹ ), despite the uneven
number of data points per function. The expressions of multi-tree
A fall in between ğ‘“ (ğ‘‹ ) and ğ‘”(ğ‘‹ ), because this minimizes the MSE.
Multi-tree B is somewhere in between A and C.

4.2 Example 2: hidden variable
We generate a data set with hidden variable ğ» , two input variables
ğ‘‹1 and ğ‘‹2, and target variable ğ‘Œ , i.e., ğ» itself is not in the data set.
Target variable ğ‘Œ is equal to hidden variable ğ» . Input variables ğ‘‹1
and ğ‘‹2 are ï¬‚awed â€˜estimationsâ€™ of ğ» . More speciï¬cally, the data
set is generated using the following functions:

ğ‘‹1 = ğ» + ğºğ‘ (0, 0.5)
ğ‘‹2 = ğ» + ğºğ‘ (0, 0.5)
ğ‘Œ = ğ»

We generate 100 data points by drawing ğ» randomly from the
interval [0, 10]. We show the approximation front of the error and
diversiï¬ed error found by our approach on this data set in Figure 4.
Furthermore, we show the two expressions, and their individual

Figure 3: The approximation front of our approach on the
synthetic multi-modal data set. The predictions of the ex-
pressions of multi-trees A, B and C are visualized.

MSE, of two multi-tree models along the front. The parameters are
as described above, except here we do not use ERCs. By chance, due
to the randomness of the Gaussian noise, ğ‘‹1 has a slightly smaller
error for predicting ğ‘Œ . Therefore, expressions that simply predict
ğ‘‹1 have a lower MSE than expressions that predict ğ‘‹2. However,
ğ‘‹1 and ğ‘‹2 are almost equally good. Our approach is able to retrieve
multi-tree model B that represents this, with one expression using
ğ‘‹1 and the other expression using ğ‘‹2.

The same principle applies to more elaborate data sets as well.
Data sets may have multiple input variables or combinations of
input variables that are good predictors of the target variable. Ex-
pressions using diï¬€erent combinations of the variables and func-
tions might have a similar error, but if one of the functions is only
slightly better, or if one of the solutions is easier to ï¬nd when op-
timizing for MSE only, the focus will be on this solution. Our ap-
proach explicitly stimulates to explore diï¬€erent possibilities and is
more likely to ï¬nd multiple of these solutions.

5 EVALUATION ON BENCHMARK DATA
In this section, we evaluate our approach on real-world data sets.
We ï¬rst describe our experimental setup before reporting our re-
sults.

5.1 Experimental setup
We evaluate three approaches: our multi-modal multi-tree MO-GP-
GOMEA approach, multi-tree SO optimization with GP-GOMEA,
and multi-tree NSGA-II [6]. We compare with SO optimization to
evaluate whether our approach can ï¬nd solutions at the extremes

E.M.C. Sijben, T. Alderliesten, and P.A.N. Bosman

Table 2: Algorithm parameter and experiment settings.

Setting

Functions

Terminal

Train-test split

For SO and Ours: tree height

For NSGA-II: maximum tree size

I

II

III

+, âˆ’, Ã—, Ã·ğ‘

variables, ERC

75%-25%

3

7

4

15

5

31

Time (s)

CPU

1200

7200

10800

AMD EPYC 7282

we use a crossover proportion of 0.5, a mutation proportion of 0.5,
a tournament size of 4, and ramped half-and-half initialization.

Furthermore, we use a population size of 5000 for SO optimiza-
tion, and a population size of 15000 in MO optimization. For our
approach and NSGA-II, we use a population size that is 3 times
larger than for SO, because MO needs to optimize three â€˜directionsâ€™,
namely the two extremes and the trade-oï¬€ between those two. For
our approach, we use 7 clusters in MO-GP-GOMEA.

For both objectives, we report the objective values of the ex-
treme solutions found by the three approaches. We also report the
HyperVolume (HV) of our approach and that of NSGA-II. HV is
a measure that indicates the volume covered by the approxima-
tion front with respect to a reference point. We compute the HV
by ï¬rst combining all approximation fronts found by the diï¬€erent
approaches over all runs, and then extracting the non-dominated
solutions, i.e., we take the front of fronts. Then, we take the mini-
mum and maximum values in each objective from this front, and
we use them to normalize all approximation fronts. Finally, we get
the HV by computing the surface area covered by the front with
respect to reference point [1.1, 1.1]. Note that this can mean that
HV values of 0 can be reported, indicating that the median run did
not ï¬nd any multi-tree solution near the best found solutions.

5.2 Results
We report the results of the experiment setting II in Tables 3 and
4. Table 3 shows that generally our approach has a signiï¬cantly
bigger HV than NSGA-II. Table 4 shows that the best performing
solution of our approach generally has no signiï¬cant diï¬€erence in
diversiï¬ed error ğ· compared with SO, and is signiï¬cantly better
than NSGA-II. Similar ï¬ndings can be observed in Table 4 regard-
ing error ğ¸. The supplementary material includes the results of ex-
periment I and III. These results generally show the same pattern
as in experiment II. For the error objective, however, our approach
is signiï¬cantly better than SO in experiment I, whereas SO is signif-
icantly better in many cases in experiment III. The median values
however, are similar. From the above, we conclude that we can ef-
fectively ï¬nd a high-quality approximation front that includes the
extreme solutions.

6 EXAMPLES ON REAL-WORLD DATA
In this section, we take a closer look at some results of our ap-
proach, using the yacht and the Boston housing data sets as exam-
ples. These examples illustrate how our approach could be useful
to users. For both examples, we perform a single run and describe

Figure 4: The approximation front of our approach on the
synthetic hidden variable data set. The two expressions, and
the individual MSE of multi-trees A and B are shown.

Table 1: Properties of benchmark data sets.

Data set (abbreviation)

Features

Samples

Boston housing (b)
Concrete compressive strength (c)
Yacht hydrodynamics (y)

13
9
6

506
1030
308

of the approximation front that are as good as when optimizing for
each objective individually.

NSGA-II is a state-of-the-art MO EA, and perhaps the most pop-
ular MO EA in literature. Note that the GP version of NSGA-II does
not use tree templates but has a variable tree length (with a maxi-
mum total size) like in traditional GP. We compare with NSGA-II
to evaluate whether our approach can ï¬nd approximation fronts
as good as, or better than, a state-of-the-art MO GP algorithm.

We evaluate these approaches on three well-known data sets
with a regression task, of which we show the properties in Table 1.
The Boston housing data set contains information concerning hous-
ing in the area of Boston Mass [14], where the goal is to predict the
median house value in an area. The concrete compressive strength
data set contains information concerning the components and age
of concrete [24], where the goal is to predict the strength of con-
crete. The yacht hydrodynamics data set contains information on
the characteristics of yachts [12], where the goal is to predict the
resistance of sailing yachts.

We initialize the population with multi-tree individuals with
ğ‘› = 2. We multi-objectively optimize the two objective functions
described in subsection 3.4: ğ¸ and ğ·. Algorithm parameter and ex-
periment settings are given in Table 2. Each run is repeated 30
times with a diï¬€erent random seed. We report the median over
these runs and the statistical signiï¬cance of the Wilcoxon signed-
rank test (with ğ›¼ = 0.05 and Bonferroni correction). For NSGA-II

Multi-modal multi-objective model-based genetic programming to find multiple diverse high-quality models

Table 3: Median HV results for experiment setting II. A tri-
angle symbol next to the reported median value indicates
signiï¬cant superiority (better (=bigger) HV) to the approach
with the name in the same color as the triangle.

Data set

Split

b
b
c
c
y
y

Train
Test
Train
Test
Train
Test

Ours
0.61 N
0.00
0.57 N
0.32 N
0.11 N
0.00 N

NSGA-II

0.33
0.00
0.00
0.00
0.00
0.00

Table 4: Median best diversiï¬ed error ğ· and median best er-
ror ğ¸ for experiment setting II. A down-pointing triangle
next to the reported median value indicates signiï¬cant su-
periority (better (=smaller) objective value) to the approach
with the name in the same color as the down-pointing trian-
gle.

Data set

Split

Ours

NSGA-II

SO

ğ·

6.97 H
13.29
31.98 H H
32.71 H
0.96 H
1.44 H

ğ¸

39.17 H
51.13 H
191.79 H
211.41 H
7.17 H
8.87 H

Train
Test
Train
Test
Train
Test

Train
Test
Train
Test
Train
Test

9.58
13.86
46.67
46.48
3.36
2.94

48.96
61.78
279.83
274.80
24.39
19.74

6.77
13.24
34.30
35.79
1.10
1.66

H

H
H
H
H

H
39.33
H
51.38
H
194.37
195.65 H H
H
H

7.23
8.23

b
b
c
c
y
y

b
b
c
c
y
y

the expressions found by our approach. We use the settings as de-
scribed in our experimental setup in the previous section, with tree
height 3.

6.1 Example 1: Yacht data set
In Figure 5, we show the approximation front of the error and di-
versiï¬ed error found by our approach on the yacht data set. We
also show the predicted resistance Ë†ğ‘… of the two expressions of three
multi-tree models along the front, against the Froude number ğ¹ , as
well as the expressions themselves. The Froude number is a ratio
between the speed of the yacht and the gravity, which is known to
inï¬‚uence the (wave) resistance of a yacht. ğ‘ƒ is the prismatic coef-
ï¬cient, which is a measure of how quick the breadth of the yacht
changes or in other words a measure for the fullness of the ends of
the yacht.

We see that the expressions of multi-tree C, which is an extreme
solution, having the best diversiï¬ed error ğ·, describe the data well
together: expression 1 describes the data well for ğ¹ > 0.38, while
expression 2 describes the data well for ğ¹ < 0.38. This corresponds
well to ï¬ndings in literature: according to the theory of Chapman,
as well as experimental results, the resistance increases drastically
when the Froude number exceeds approximately 0.38 [3, 22].

Figure 5: The approximation front of our approach on the
yacht data set. The predictions Ë†ğ‘… of the expressions of multi-
trees A, B, and C are visualized against ğ¹ .

The expressions of multi-tree A, on the other hand, which is
an extreme solution, having the best error ğ¸, both try to model
the whole data set, which corresponds to having the lowest MSE.
However, neither accurately describes the data for either ğ¹ < 0.38
or ğ¹ > 0.38. The predictions of the expressions of multi-tree B are
visually somewhere in between the predictions of A and C.

6.2 Example 2: Boston housing data set
In Figure 6, we show the approximation front of the error and di-
versiï¬ed error found by our approach on the Boston housing data
set. Furthermore, we show the two expressions, and their individ-
ual MSE, of three multi-tree models along the front.

Expression 2 of multi-tree A has the lowest error. However, de-
pending on the task, this expression might not be the expression
that best accommodates the needs of the user. Assume the user
is a real estate investor that is interested in the factors that inï¬‚u-
ence the house price. Now suppose that the user knows that a new
highway will be built in the near future. The user wants to take
this into account when buying new houses and wants to predict
how the highway might aï¬€ect the value of houses in that area, to
predict how much proï¬t can be made. Therefore, the user employs
expression 1 of multi-tree B, which uses ğ‘¥8, the index of the acces-
sibility to radial highways, assuming the new highway only eï¬€ects
ğ‘¥8 and not the other variables, instead of expression 2 of multi-tree
A that does not use ğ‘¥8 and is only slightly diï¬€erent in MSE. This
shows how it can be useful to search for multiple expressions that
are diï¬€erent but have a similar MSE. If the user had used SO opti-
mization to generate expressions, the user would not have had this
choice, because only one model would have been presented.

E.M.C. Sijben, T. Alderliesten, and P.A.N. Bosman

error but have a diï¬€erent error distribution over the data points.
We explain why ğ·2 stimulates a diï¬€erent kind of diversity with an
example in Figure 7. In this example, either ğ‘¡2 or ğ‘¡3 is closer to ev-
ery target value ğ‘¦1, . . . , ğ‘¦5 than ğ‘¡1. Therefore, ğ‘¡1 does not decrease
ğ·1, even though it adds diversity with respect to ğ‘¡2 and ğ‘¡3. ğ·2, in
contrast, takes into account the diversity that ğ‘¡1 adds.

Figure 7: A multi-model with ğ‘› = 3 and target values
ğ‘¦1, . . . , ğ‘¦5.

When ğ‘› > 2, there are a few options regarding how to use ğ·1
and ğ·2 alongside ğ¸. One could choose to 1) use either ğ·1 or ğ·2,
depending on their needs, 2) perform multiple runs, some of which
optimize ğ·1, and some of which optimize ğ·2, or 3) perform a run
which optimizes both ğ·1 and ğ·2 along ğ¸ with MO optimization
with three objectives. This may however make ï¬nal model selec-
tion more complicated.

Finally, an important next step is to evaluate our approach in a
real-world setting where users are provided with multiple expres-
sions to choose from. For example, it could be researched how peo-
ple interact with the solutions that our approach ï¬nds, and how
to present multiple solutions to a user. Another aspect to study
is how to aggregate and/or combine the results of our approach
with cross-validation, given that you would get multiple fronts of
models. Finally, the interleaved multi-start scheme [7] could be im-
plemented such that users do not have to choose a population size
when using our approach.

8 CONCLUSION
In this work, we have presented a novel multi-modal multi-tree
MO GP approach that extends a modern model-based GP algo-
rithm known as GP-GOMEA. We presented experimental evidence
on synthetic and real-world data that showed that our approach
can generate multiple diverse high-quality expressions that include
expressions that excel in diï¬€erent notions of quality. Our approach
could be a promising approach to allow users to inspect diï¬€erent
models, which could lead to novel insights into the data and the
process underlying the data. Providing the user with options in
this manner, possibly in combination with additional expert knowl-
edge, could help support them in choosing a good model for the
task at hand in a powerful and sensible way.

ACKNOWLEDGMENTS
This research was funded by the European Commission within the
HORIZON Programme (TRUST AI Project, Contract No.: 952060).

Figure 6: The approximation front of our approach on the
Boston housing data set. The two expressions, and the indi-
vidual MSE of multi-trees A, B, and C are shown. ğ‘¥1 is the
proportion of land with big lots, ğ‘¥5 is the average number of
rooms per residence, ğ‘¥7 is the weighted distance to ï¬ve em-
ployment centers, ğ‘¥8 is the accessibility to radial highways,
ğ‘¥10 is the ratio of pupils to teachers of a town, and ğ‘¥12 is the
percentage of adults without high school education.
7 DISCUSSION
We evaluated our approach with multi-trees where ğ‘› = 2. To use
our approach with multi-trees where ğ‘› > 2, we need to generalize
the diversiï¬ed error objective function ğ·. In principle, this can be
done by simply taking the minimum error over all trees. For the ex-
treme solution that optimizes this generalization, individual trees
will still represent diï¬€erent parts of the data more closely. Toward
the other extreme, the sum of MSE values, however, this general-
ization does not necessarily have the same eï¬€ect as for ğ‘› = 2. To
realize this also for ğ‘› > 2, we specify two diversiï¬ed error func-
tions, ğ·1 and ğ·2. ğ·1 is the aforementioned generalization, and ğ·2
is the average pairwise mean of the minimum squared error of the
trees:

min((ğ‘¡1(ğ‘‹ ğ‘— ) âˆ’ ğ‘¦ ğ‘— )2

, . . . , (ğ‘¡ğ‘› (ğ‘‹ ğ‘— ) âˆ’ ğ‘¦ ğ‘— )2)

|ğ‘‹ |

1
|ğ‘‹ |

Ã•
ğ‘—=1
2
ğ‘› Â· (ğ‘› âˆ’ 1)

ğ·1 =

ğ·2 =

where

ğ‘›âˆ’1

ğ‘›

Ã•
ğ‘–=1

Ã•
ğ‘™ =ğ‘–+1

ğ·ğ‘ (ğ‘¡ğ‘–, ğ‘¡ğ‘™ ),

ğ·ğ‘ (ğ‘¡ğ‘–, ğ‘¡ğ‘™ ) =

1
|ğ‘‹ |

|ğ‘‹ |

Ã•
ğ‘—=1

min((ğ‘¡ğ‘– (ğ‘‹ ğ‘— ) âˆ’ ğ‘¦ ğ‘— )2

, (ğ‘¡ğ‘™ (ğ‘‹ ğ‘— ) âˆ’ ğ‘¦ ğ‘— )2).

Note that for ğ‘› = 2 the objective functions are equal, i.e., ğ· =
ğ·1 = ğ·2. ğ·1 stimulates sets of expressions that describe a data set
well together. ğ·2 stimulates sets of expressions that have similar

Multi-modal multi-objective model-based genetic programming to find multiple diverse high-quality models

[21] Dirk Thierens and Peter A.N. Bosman. 2011. Optimal Mixing Evolutionary Algo-
rithms. In Proceedings of the 13th Annual Conference on Genetic and Evolutionary
Computation (Dublin, Ireland) (GECCO â€™11). Association for Computing Machin-
ery, New York, NY, USA, 617â€“624. https://doi.org/10.1145/2001576.2001661
[22] Ernest O Tuck. 1987. Wave resistance of thin ships and catamarans. Report

T8701. Applied Mathematics Department, The University of Adelaide (1987), 15.

[23] Marco Virgolin, Tanja Alderliesten, Cees Witteveen, and Peter AN Bosman. 2021.
Improving model-based genetic programming for symbolic regression of small
expressions. Evolutionary Computation 29, 2 (2021), 211â€“237.

[24] I.-C. Yeh. 1998. Modeling of strength of high-performance concrete using arti-
ï¬cial neural networks. Cement and Concrete Research 28, 12 (1998), 1797â€“1808.
https://doi.org/10.1016/S0008-8846(98)00165-3

REFERENCES
[1] Anton Bouter, Tanja Alderliesten, Cees Witteveen, and Peter A. N. Bosman.
2017. Exploiting Linkage Information in Real-Valued Optimization with the Real-
Valued Gene-Pool Optimal Mixing Evolutionary Algorithm. In Proceedings of the
Genetic and Evolutionary Computation Conference (Berlin, Germany) (GECCO
â€™17). Association for Computing Machinery, New York, NY, USA, 705â€“712.
https://doi.org/10.1145/3071178.3071272

[2] Armand R. Burks and William F. Punch. 2015. An Eï¬ƒcient Structural Diver-
sity Technique for Genetic Programming. In Proceedings of the 2015 Annual
Conference on Genetic and Evolutionary Computation (Madrid, Spain) (GECCO
â€™15). Association for Computing Machinery, New York, NY, USA, 991â€“998.
https://doi.org/10.1145/2739480.2754649

[3] R.B. Chapman. 1972. Hydrodynamic drag of semisubmerged ships. Journal of
Basic Engineering 94 (1972), 879â€“884. Issue 4. https://doi.org/10.1115/1.3425581
[4] European Commission, Content Directorate-General for Communications Net-
works, and Technology. 2019. Ethics guidelines for trustworthy AI. Publications
Oï¬ƒce. https://doi.org/10.2759/177365

[5] Edwin D. de Jong, Richard A. Watson, and Jordan B. Pollack. 2001. Reducing
Bloat and Promoting Diversity Using Multi-Objective Methods. In Proceedings
of the 3rd Annual Conference on Genetic and Evolutionary Computation (San Fran-
cisco, California) (GECCOâ€™01). Morgan Kaufmann Publishers Inc., San Francisco,
CA, USA, 11â€“18.

[6] K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan. 2002. A Fast and Elitist Multiob-
jective Genetic Algorithm: NSGA-II. Transactions on Evolutionary Computation
6, 2 (April 2002), 182â€“197. https://doi.org/10.1109/4235.996017

[7] Arkadiy Dushatskiy, Marco Virgolin, Anton Bouter, Dirk Thierens, and Peter AN
Bosman. 2021. Parameterless Gene-pool Optimal Mixing Evolutionary Algo-
rithms. arXiv preprint arXiv:2109.05259 (2021).

[8] AnikÃ³ EkÃ¡rt and Sandor Z. NÃ©meth. 2000. A Metric for Genetic Programs and Fit-
ness Sharing. In Proceedings of the European Conference on Genetic Programming.
Springer-Verlag, Berlin, Heidelberg, 259â€“270.

[9] Benjamin P. Evans, Bing Xue, and Mengjie Zhang. 2019. Whatâ€™s inside the Black-
Box? A Genetic Programming Method for Interpreting Complex Machine Learn-
ing Models. In Proceedings of the Genetic and Evolutionary Computation Confer-
ence (Prague, Czech Republic) (GECCO â€™19). Association for Computing Machin-
ery, New York, NY, USA, 1012â€“1020. https://doi.org/10.1145/3321707.3321726

[10] Leonardo Augusto Ferreira, Frederico Gadelha GuimarÃ£es, and Rodrigo Silva.
2020. Applying genetic programming to improve interpretability in machine
learning models. In 2020 IEEE Congress on Evolutionary Computation (CEC). IEEE,
1â€“8.

[11] Edgar GalvÃ¡n and Marc Schoenauer. 2019.

Promoting Semantic Diver-
sity in Multi-Objective Genetic Programming. In Proceedings of the Genetic
and Evolutionary Computation Conference (Prague, Czech Republic) (GECCO
â€™19). Association for Computing Machinery, New York, NY, USA, 1021â€“1029.
https://doi.org/10.1145/3321707.3321854

[12] J Gerritsma, R Onnink, and A Versluis. 1981. Geometry, resistance and stability
of the Delft systematic yacht hull series. International shipbuilding progress 28,
328 (1981), 276â€“297.

[13] Ilan Gronau and Shlomo Moran. 2007. Optimal implementations of UPGMA
Inform. Process. Lett. 104, 6 (2007),

and other common clustering algorithms.
205â€“210.

[14] David Harrison and Daniel L Rubinfeld. 1978. Hedonic housing prices and the
demand for clean air. Journal of Environmental Economics and Management 5, 1
(1978), 81â€“102. https://doi.org/10.1016/0095-0696(78)90006-2

J. Klausmeier.

[15] Herbert
cept
267â€“286.
arXiv:https://doi.org/10.1207/s15326985ep2703_1

1992.
Educational

Teaching.

Concept
Psychologist

and Con-
(1992),
3
https://doi.org/10.1207/s15326985ep2703_1

Learning
27,

[16] William La Cava, Patryk Orzechowski, Bogdan Burlacu, FabrÃ­cio Olivetti de
FranÃ§a, Marco Virgolin, Ying Jin, Michael Kommenda, and Jason H Moore. 2021.
Contemporary symbolic regression methods and their relative performance.
arXiv preprint arXiv:2107.14351 (2021).

[17] Ngoc Hoang Luong, Han La PoutrÃ©, and Peter A.N. Bosman. 2014. Multi-
Objective Gene-Pool Optimal Mixing Evolutionary Algorithms. In Proceedings
of the 2014 Annual Conference on Genetic and Evolutionary Computation (Van-
couver, BC, Canada) (GECCO â€™14). Association for Computing Machinery, New
York, NY, USA, 357â€“364. https://doi.org/10.1145/2576768.2598261

[18] R I (Bob) McKay. 2000. Fitness Sharing in Genetic Programming. In Proceedings
of the 2nd Annual Conference on Genetic and Evolutionary Computation (Las Ve-
gas, Nevada) (GECCOâ€™00). Morgan Kaufmann Publishers Inc., San Francisco, CA,
USA, 435â€“442.
[19] Christoph Molnar.

Interpretable Machine

Learning.

2019.

https://christophm.github.io/interpretable-ml-book/

[20] Michael D. Schmidt and Hod Lipson. 2010. Age-Fitness Pareto Optimization. In
Proceedings of the 12th Annual Conference on Genetic and Evolutionary Computa-
tion (Portland, Oregon, USA) (GECCO â€™10). Association for Computing Machin-
ery, New York, NY, USA, 543â€“544. https://doi.org/10.1145/1830483.1830584

Multi-modal multi-objective model-based genetic programming
to find multiple diverse high-quality models â€” Supplementary
materials

E.M.C. Sijben
Centrum Wiskunde & Informatica
Amsterdam, the Netherlands
evi.sijben@cwi.nl

T. Alderliesten
Leiden University Medical Center
Leiden, the Netherlands
t.alderliesten@lumc.nl

P.A.N. Bosman
Centrum Wiskunde & Informatica
Amsterdam, the Netherlands
peter.bosman@cwi.nl

1 CLUSTERING IN MO-GOMEA
We use the same clustering method in our approach as in MO-
GOMEA [1], which is Balanced K-Leader-Means (BKLM) cluster-
ing. First, ğ‘˜ leaders are selected. The ï¬rst leader is selected by tak-
ing the individual with the minimum value for a randomly chosen
objective. Next, the distances D = (D1, . . . , Dğ‘ ) between each in-
dividual and the ï¬rst leader are computed, with ğ‘ being the popu-
lation size. The individual with the maximum distance is selected
as the next leader. Then, the distances D are updated by taking
for each individual Pğ‘– the minimum of Dğ‘– and the distance be-
tween Pğ‘– and the new leader. This is repeated until ğ‘˜ leaders are
found. These ğ‘˜ leaders are used as initial cluster centers to perform
ğ‘˜-means clustering. After ğ‘˜-means clustering has converged, each
cluster is assigned the 2Â·ğ‘
solutions that are closest to its center.
ğ‘˜
For variation, however, it needs to be known for each individual
which FOS to use, which donors to choose from, and whether to
use SO GOM or MO GOM. Therefore, each individual needs to be
assigned to precisely one cluster. To do this, individuals that are not
yet assigned to a cluster, are assigned to the cluster with the clos-
est center, and individuals that are assigned to multiple clusters,
are assigned to one of these clusters at random. Figure 1 illustrates
this process.

2 EXPERIMENTAL RESULTS
In the main text, we describe three diï¬€erent settings for our experi-
ments: I, II, and III. We show results of these experiments in Tables
1, 2, and 3.

Table 1: Median HV results for experiment settings I, II, and
III. A triangle symbol next to the reported median value in-
dicates signiï¬cant superiority (better (=bigger) HV) to the ap-
proach with the name in the same color as the triangle.

Data set

Split

Ours

NSGA-II

Setting I

0.17 N
0.05 N
0.03 N
0.35 N
0.00
0.00

Setting II

0.61 N
0.00
0.57 N
0.32 N
0.11 N
0.00 N

Train
Test
Train
Test
Train
Test

Train
Test
Train
Test
Train
Test

Setting III

Train
Test
Train
Test
Train
Test

0.57 N
0.00
0.57 N
0.33 N
0.45 N
0.00

0.00
0.01
0.00
0.12
0.00
0.00

0.33
0.00
0.00
0.00
0.00
0.00

0.09
0.00
0.00
0.00
0.00
0.00

b
b
c
c
y
y

b
b
c
c
y
y

b
b
c
c
y
y

2
2
0
2

r
a

M
4
2

]
E
N
.
s
c
[

1
v
7
4
3
3
1
.
3
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
E.M.C. Sijben, T. Alderliesten, and P.A.N. Bosman

Figure 1: Example of how BKLM operates. The points represent the normalized objective values of the individuals. In â€œLeader
Selection", stars denote the positions of the leaders. In â€œK-means Clustering", stars denote the position of the cluster centers.
The color of a point indicates the cluster that the individual belongs to. If a point has multiple colors this means that the point
belongs to multiple clusters. We illustrate a very small population size to keep the ï¬gure readable.

Table 2: Median best diversiï¬ed error ğ· for experiment set-
tings I,II and III. A down-pointing triangle next to the re-
ported median value indicates signiï¬cant superiority (better
(=smaller) objective value) to the approach with the name in
the same color as the down-pointing triangle.

Table 3: Median best error ğ¸ for experiment settings I,II and
III. A down-pointing triangle next to the reported median
value indicates signiï¬cant superiority (better (=smaller) ob-
jective value) to the approach with the name in the same
color as the down-pointing triangle.

Data set

Split

Ours

NSGA-II

SO

Data set

Split

Ours

NSGA-II

SO

Setting I

10.40 H
15.17 H
63.04 H H
61.67 H
6.65 H H
7.09 H H

Setting II

6.97 H
13.29
31.98 H H
32.71 H
0.96 H
1.44 H

Setting III

5.09 H
11.83
20.70 H
20.24 H
0.63 H
1.32 H

Train
Test
Train
Test
Train
Test

Train
Test
Train
Test
Train
Test

Train
Test
Train
Test
Train
Test

14.02
18.31
83.32
81.73
14.46
11.22

9.58
13.86
46.67
46.48
3.36
2.94

6.95
13.52
30.31
32.59
1.21
1.47

10.72
15.12
68.02
65.59
13.79
13.27

6.77
13.24
34.30
35.79
1.10
1.66

5.02
12.81
21.19
21.28
0.63
1.22

H
H
H
H
H

H

H
H
H
H

H

H
H
H
H

b
b
c
c
y
y

b
b
c
c
y
y

b
b
c
c
y
y

Setting I

53.26 H H
65.37 H H
376.19 H H
399.43 H
65.89 H H
65.78 H H

Setting II

39.17 H
51.13 H
191.79 H
211.41 H
7.17 H
8.87 H

Setting III

32.32 H
47.48 H
121.25 H
122.05 H
4.99 H
6.51 H

81.54
105.70
464.92
448.56
111.09
103.78

48.96
61.78
279.83
274.80
24.39
19.74

39.54
54.19
182.77
185.57
8.65
8.21

Train
Test
Train
Test
Train
Test

Train
Test
Train
Test
Train
Test

Train
Test
Train
Test
Train
Test

55.72
69.37
385.03
410.08
89.20
83.93

H
H
H
H
H
H

H
39.33
H
51.38
H
194.37
195.65 H H
H
H

7.23
8.23

H
32.05
45.99 H H
H
119.15
H
122.42
4.20 H H
5.73 H H

b
b
c
c
y
y

b
b
c
c
y
y

b
b
c
c
y
y

REFERENCES
[1] Ngoc Hoang Luong, Han La PoutrÃ©, and Peter A.N. Bosman. 2014. Multi-Objective
Gene-Pool Optimal Mixing Evolutionary Algorithms. In Proceedings of the 2014
Annual Conference on Genetic and Evolutionary Computation (Vancouver, BC,
Canada) (GECCO â€™14). Association for Computing Machinery, New York, NY, USA,
357â€“364. https://doi.org/10.1145/2576768.2598261

