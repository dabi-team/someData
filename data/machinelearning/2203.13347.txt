Multi-modal multi-objective model-based genetic programming
to find multiple diverse high-quality models

E.M.C. Sijben
Centrum Wiskunde & Informatica
Amsterdam, the Netherlands
evi.sijben@cwi.nl

T. Alderliesten
Leiden University Medical Center
Leiden, the Netherlands
t.alderliesten@lumc.nl

P.A.N. Bosman
Centrum Wiskunde & Informatica
Amsterdam, the Netherlands
peter.bosman@cwi.nl

2
2
0
2

r
a

M
4
2

]
E
N
.
s
c
[

1
v
7
4
3
3
1
.
3
0
2
2
:
v
i
X
r
a

ABSTRACT
Explainable artiﬁcial intelligence (XAI) is an important and rapidly
expanding research topic. The goal of XAI is to gain trust in a
machine learning (ML) model through clear insights into how the
model arrives at its predictions. Genetic programming (GP) is often
cited as being uniquely well-suited to contribute to XAI because of
its capacity to learn (small) symbolic models that have the poten-
tial to be interpreted. Nevertheless, like many ML algorithms, GP
typically results in a single best model. However, in practice, the
best model in terms of training error may well not be the most suit-
able one as judged by a domain expert for various reasons, includ-
ing overﬁtting, multiple diﬀerent models existing that have simi-
lar accuracy, and unwanted errors on particular data points due to
typical accuracy measures like mean squared error. Hence, to in-
crease chances that domain experts deem a resulting model plausi-
ble, it becomes important to be able to explicitly search for multi-
ple, diverse, high-quality models that trade-oﬀ diﬀerent meanings
of accuracy. In this paper, we achieve exactly this with a novel
multi-modal multi-tree multi-objective GP approach that extends
a modern model-based GP algorithm known as GP-GOMEA that
is already eﬀective at searching for small expressions.

1 INTRODUCTION
State-of-the-art machine learning models are often diﬃcult to in-
terpret. This can be caused by models having many coeﬃcients,
many variables, and/or an intricate structure. The popular ﬁeld
of eXplainable Artiﬁcial Intelligence (XAI) aims to either develop
methods that enable humans to interpret the complex machine
learning model and its predictions, or to make inherently inter-
pretable models. Models are unlikely to be inherently interpretable
if they have many coeﬃcients and/or variables. Therefore, it makes
sense to restrict the size of the model. However, doing so may neg-
atively aﬀect model performance. Ideally, one would obtain both
high performance and interpretability.

Genetic Programming (GP) is a learning algorithm that can gen-
erate expressions that are ﬂexible in their structure, and in the op-
erators or functions used in these expressions. This enables GP to
capture non-linear relations in a compact expression, oﬀering a
useful trade-oﬀ between performance and size compared to other
methods [16]. This quality is why GP has been suggested to be
useful for XAI [9, 10, 23].

XAI approaches aim to give users insight into a model. This al-
lows users to make more informed use of the model in the real
world [4, 19]. However, if a model has (serious) shortcomings or
other problems, although now the user may be informed about
these potential problems, insight alone does not necessarily pro-
vide a solution, nor a direct way to change the model. Of course,

Figure 1: Visualization of our approach.

users can always choose not to use the model. Ideally, however,
users would be able to choose a model from a list of models that
exhibit diﬀerent qualities, to meet their speciﬁc preferences and
prevent model rejection. Unfortunately, this is typically not possi-
ble because most machine learning algorithms generate only one
model.

In practice, due to the amount of data available (both in terms of
records and variables) and/or the complexity of the prediction task,
combined with a ﬁnite capacity of learnable models, it is unlikely
that the optimal model (in terms of minimum training or valida-
tion error) is unique. Even if it is, it might not be the best model
according to the user. The user may have certain model require-
ments, or there could be conﬂicts between the model and expert
knowledge about the domain. Additionally, it might not be the best
model simply because the data is limited and models with slightly
worse performance in error on the data at hand are better if we
had inﬁnite data to train on.

Therefore, it would be very useful in practice, with the vision
of a domain-expert end-user selecting the preferred model for the
task at hand, to be able to search for multiple models that are all
well-performing but are also diverse and potentially even describe
diﬀerent parts of the data better. Allowing the user to inspect such
a set of diﬀerent models may provide unique novel insights into the
data and the process underlying the data, and support choosing a
good model with additional expert knowledge in a powerful and
sensible way. Thereby user agency and control are increased.

In this paper, we propose exactly this: searching, in a novel way,
for sets of multiple models instead of a single model. Rather than
using (adaptive) niching or ﬁtness sharing, we use a multi-tree GP
model. This enables us to explicitly deﬁne diversity between mod-
els and perform multi-modal search in a potentially highly multi-
modal search space by ﬁnding a ﬁxed number of modes/niches.

 
 
 
 
 
 
Moreover, by deﬁning the search in a Multi-Objective (MO) way,
we can optimize for both diversity between models and model per-
formance. Finally, by using particular notions of diversity, we can
not only ﬁnd models that are diﬀerent, but even focus on diﬀerent
parts of the data in diﬀerent ways, giving additional meaning and
potentially practically useful dimensions to the models that will be
presented to the user. We visualize our approach in Figure 1. To the
best of our knowledge, this is the ﬁrst paper to propose searching
for diverse multi-tree models with an MO approach.

Besides searching for a set of models, the ultimate goal is to
create interpretable models. While we do not directly focus on in-
terpretability here, we do consider that smaller models are likely
more interpretable than larger models. Under this assumption, it
becomes interesting to look at GP approaches that are particularly
well-suited to evolving small solutions. Results show that the GP
variant of the Gene-pool Optimal Mixing Evolutionary Algorithm
(GP-GOMEA) gives better results when searching for solutions of
limited tree size than classic GP [23]. An MO version of GP-GOMEA
does not yet exist, however. Therefore, we implement an MO vari-
ant of GP-GOMEA by leveraging the best practices previously em-
ployed in the design of MO-GOMEA [17].

The contribution of this paper is threefold. We 1) develop a
novel approach for searching for sets of high-quality and diverse
multi-tree GP models, 2) implement a version of GP-GOMEA with
multi-trees and MO optimization, and 3) show the beneﬁts of our
approach by applying it to real-world data sets.

2 RELATED WORK
Diversity maintenance is a well-studied subject in GP that aims
to improve diversity in the whole population to prevent prema-
ture convergence. In [11] semantic diversity is promoted by using
the semantic crowding distance. The semantic crowding distance
adopts the same principles as the crowding distance except it does
not look at the distance in objective space but in semantic space.
Not only is the regular crowding distance replaced by the semantic
one, the semantic crowding distance is also added as an objective.
In [2], an extension of the age-ﬁtness Pareto optimization [20],
an MO method that optimizes age and ﬁtness, is proposed. The idea
behind this is to avoid that younger individuals, that have had less
time to become ﬁt, compete with older individuals, that have had
more time to become ﬁt. Thereby, the competition between indi-
viduals with a similar age is stimulated. A metric for tree structure
similarity (genetic marker density) is used instead of age to prevent
converging to a speciﬁc structure.

The FOCUS method [5] performs an MO search with three ob-
jectives: ﬁtness, size, and average squared overlapping tree dis-
tance to other members in the population. Individuals are stimu-
lated to move away from the central peak in the ﬁtness landscape
if the central peak becomes too crowded.

In [18] ﬁtness sharing for GP is introduced. The general idea is
to reward solutions that are diﬀerent, i.e., the reward for each pre-
diction is divided by the number of individuals in the population
that give the same prediction. A distance function that reﬂects the
structural dissimilarity of trees to extend the applicability of ﬁtness
sharing for tree-based methods is introduced in [8].

Our work distinguishes itself from the above-mentioned works
because we do not primarily aim to avoid premature convergence,

E.M.C. Sijben, T. Alderliesten, and P.A.N. Bosman

but we aim to present the user with a diverse set of potentially
interesting models. Furthermore, the approach we present in this
paper to realize this goal, is novel, for two reasons: 1) we maintain
diversity within individuals rather than diversity across the pop-
ulation by using an MO search with multi-tree individuals, and 2)
we incorporate a novel diversity objective in this approach that has
particular relevance to machine learning.

3 MULTI-MODAL MULTI-OBJECTIVE

MODEL-BASED GP

In this section, we present our approach to search for diverse high-
quality models. It has four key components: GP-GOMEA, multi-
tree individuals, MO optimization, and a particular diversity objec-
tive.

We use GP-GOMEA [23] because it is known to oﬀer a good
trade-oﬀ between performance and model size [16]. We implement
multi-tree individuals, which allows us to express diversity within
individuals. We choose to maintain diversity within individuals
rather than maintaining diversity across the population because
this allows us to more easily stimulate diversity and performance
at the same time. To optimize for both diversity and performance
we implement an MO variant of GP-GOMEA, where we leverage
best practices of MO-GOMEA [17], and introduce a diversity objec-
tive function, which we optimize together with an error objective.

3.1 Gene-pool Optimal Mixing Evolutionary

Algorithm (GOMEA)

GOMEA is a model-based Evolutionary Algorithm (EA) that has
been shown to be eﬀective in many domains such as discrete opti-
mization [17, 21], real-valued optimization [1], and, most relevant
here, GP [23]. GOMEA diﬀers from classic EAs in that it uses a link-
age model that is meant to capture the interdependencies within
the genotype. This information is then used during variation to
prevent building blocks (or partial solutions) from being disrupted
and to eﬀectively mix these blocks to create better solutions.

In GOMEA, a ﬁxed-length string is used as the genotype so that
genes at a certain location in the string always represent the same
variables in the problem. Linkage information is represented as a
Family Of Subsets (FOS). The FOS contains subsets of genes (string
indices) that are assumed to be linked.

If no linkage information is known a priori, it can be learned
from the population during search. To this end, Mutual Informa-
tion (MI) is often used to measure linkage among gene pairs and
a so-called Linkage Tree (LT) is built to represent variable depen-
dence relations in a hierarchical fashion. Computing joint MI for
more than two genes is costly and requires large population sizes
to be accurate. Therefore, the UPGMA algorithm [13] is used to
approximate linkage for larger groups of genes. UPGMA is a hi-
erarchical clustering algorithm that merges subsets, starting from
singleton sets, which in GOMEA contain the individual genes. For
the similarity measure in UPGMA, the pairwise average MI is used.
At each merge step, the newly constructed cluster is added to the
FOS, ultimately resulting in the LT. Merging is usually stopped in
GOMEA when only two clusters are left. The subset containing all
genes is typically not added to the FOS because using this subset
would result in entire solutions being cloned during variation.

Multi-modal multi-objective model-based genetic programming to find multiple diverse high-quality models

In GOMEA, every generation, each individual in the population
undergoes variation through Gene-pool Optimal Mixing (GOM).
GOM uses the information in the FOS to replace linked genes at
the same time. Suppose individual P𝑖 undergoes GOM. First, P𝑖
is cloned into oﬀspring O𝑖. Then, each of the subsets in the FOS is
considered in a random order. For each FOS subset anew, a donor is
randomly selected from the population. The values of the genes in
O𝑖 are replaced with those of the donor, but only at the positions
speciﬁed by the FOS subset. If a replacement did not result in a
worse ﬁtness, the change is kept.

After processing all FOS elements, O𝑖 is added to the oﬀspring
set and the next population member is considered. After process-
ing the entire population, the population is replaced by the oﬀ-
spring.

3.2 GP-GOMEA & Multi-trees
GP-GOMEA is a GP variant of GOMEA [23]. In GP-GOMEA, in-
dividuals are trees that adhere to a template with ﬁxed node po-
sitions. This enables mapping trees to strings in a ﬁxed manner,
i.e., nodes at the same position in diﬀerent trees always map to the
same string index. Consequently, learning an FOS and GOM varia-
tion can be straightforwardly used. However, a particular form of
normalization is used on the estimated MI values to account for
suprious linkage in the initial population that may occur in the
case of GP trees because not every node in the GP tree is always
used, nor can every node represent the same thing (leaves cannot
represent functions). For more details, see [23].

Figure 2 shows an example of a variation step in GP-GOMEA,
where we variate O𝑖 using FOS subset member {2, 6}. Elements at
indices 2 and 6 in selected individual O𝑖 are replaced with those of
donor tree P𝑗 , where 𝑗 is randomly selected.

1

+

2

×
×

5

/

3

𝑥1
𝑥1

4

𝑥2

6

𝑥1
𝑥1

7

𝑥3

(a) Donor tree P𝑗 for variation with O𝑖 .

1

+

1

+

2

−
×

5

−

2

×
×

5

−

3

𝑥1
𝑥1

4

𝑥1

6

𝑥2
𝑥2

7

𝑥3

→

3

𝑥1
𝑥1

4

𝑥1

6

𝑥1
𝑥2

7

𝑥3

(b) Recipient tree O𝑖 before
variation with P𝑗 .

(c) Recipient tree O𝑖 after
variation with P𝑗 .

Figure 2: GOM step for FOS element {2, 6} applied to oﬀ-
spring O𝑖 using donor P𝑗 .

In our approach, we use a multi-tree representation. A multi-
tree 𝑇 consist of multiple trees 𝑡𝑖 such that 𝑇 = (𝑡1, . . . , 𝑡𝑛). A
multi-tree implementation of GP-GOMEA did, however, not yet
exist. To support multi-tree in GP-GOMEA, we concatenate the
string representations of the 𝑛 trees. Therefore, the indices count

onward from one tree to another tree. For a multi-tree with 2 trees
and a height of 3, this means that the ﬁrst tree has a root node with
index 1 and contains indices 1 through 7 as in Figure 2. The second
tree has a root node with index 8 and contains indices 8 through
14.

Note that GOM always replaces a gene at index 𝑖 with a gene in
a donor solution at index 𝑖. GOM will thus not replace nodes from
tree 𝑡𝑖 of a multi-tree with nodes from 𝑡 𝑗 from a donor multi-tree
where 𝑖 ≠ 𝑗. We do, however, want to be able to learn interdepen-
dencies across trees in a multi-tree. This will, for example, enable
to learn that index 2 in the ﬁrst tree is linked to index 11 in the
second tree, which allows GOM to replace these nodes simultane-
ously. This is straightforwardly achieved because we concatenate
the string representations of the 𝑛 trees to achieve the string repre-
sentation in GOMEA. Automatically, therefore, an FOS is learned
that can represent interdependencies across trees.

However, we know, by design, that we are modelling multiple
trees and that these trees separately will make a substantial contri-
bution to the objective functions. For this reason, it is also of value
to learn an FOS (an LT, to be precise) for each GP tree indepen-
dently, which we propose to do. Moreover, because these GP trees
are individual components of the larger multi-tree, we want to be
able to exchange entire trees as well. For this, when we learn an
LT for a single GP tree in the multi-tree representation, we do not
discard the FOS element with all variable indices. The ﬁnal FOS
that is used for GOM, is the union of the FOS learned for the entire
multi-tree and all of the FOSs learned for each GP tree separately.

3.3 MO-GP-GOMEA
Our goal is to search for trees that are both of high-quality and di-
verse. Using a multi-tree representation, we can explicitly express
these notions over the multi-tree and optimize for them.

By properly governing that these expressions stay diﬀerent through-

out the search, we could design a multi-modal approach around
this representation that searches for 𝑛 local optima. However, as
stated in the introduction, the expression with the smallest train-
ing error is not necessarily the preferred one, due to noise in the
data, limited data, missing features, expert knowledge, and/or user
needs. Hence, in a user-centered XAI setting, returning only the
expression with the lowest training error, or even multiple expres-
sions with the same optimal training error, is likely not satisfactory.
It would be prudent to accept that our data is not perfect and ex-
plicitly also search for other properties of our expressions that rep-
resent potentially other things a domain expert could be interested
in. Therefore, we present an objective that stimulates searching for
such potentially interesting properties in subsection 3.4.

Firstly, however, it is important to realize that ﬁnding multiple
sets of expressions with diﬀerent, conﬂicting properties, requires
MO search. However, only a Single-Objective (SO) version of GP-
GOMEA currently exists [23]. We therefore create, for the ﬁrst
time, an MO version of GP-GOMEA, which we base on the MO
version of GOMEA originally introduced for binary variables [17].
Pseudo-code for MO GP-GOMEA is shown above, which at the
top level, is essentially analogous to MO-GOMEA [17]. Every gen-
eration, the population is divided into 𝑘 clusters (line 6). The clus-
tering approach works on the basis of distance between solutions

MO-GP-GOMEA(population size 𝑁 , clusters 𝑘)

3:

1: for 𝑖 ∈ {0, 1, . . . , 𝑁 − 1} do
2:

P𝑖 ← CreateRandomSolution()
EvaluateFitness(P𝑖 )
A ← UpdateElitistArchive(P𝑖)
4:
5: while ¬TerminationCriteriaSatisﬁed do
6:

{C0, C1, . . . , C𝑘−1} ← ClusterPopulation(P)
for 𝑗 ∈ {0, 1, . . . , 𝑘 − 1} do

F𝑗 ← LearnLinkageModel(C𝑗 )

for 𝑖 ∈ {0, 1, . . . , 𝑁 − 1} do

O𝑖 ← Clone(P𝑖 )
C𝑗 ← DetermineCluster(O𝑖 , {C0, C1, . . . , C𝑘−1})
if IsExtremeCluster(C𝑗 ) then

O𝑖 ← SingleObjective-GOM(O𝑖 , C𝑗 ,F𝑗 ,A)

else

7:

8:

9:

10:

11:

12:

13:

14:

15:

16:

17:

O𝑖 ← MultiObjective-GOM(O𝑖 , C𝑗 ,F𝑗 ,A)

where

A ← UpdateElitistArchive(O𝑖 )

P ← O = {O0, O1, . . . , O𝑁 −1}

in normalized objective space, and is described in further detail in
the supplementary material. For every cluster, a separate FOS is
learned (line 8). Restricted mating is applied, meaning that donors
for an individual must come from the same cluster as the individ-
ual itself. Then, ‘extreme’ clusters are identiﬁed (line 12): these are
the clusters that, on average, perform best on a single objective. In
extreme clusters, a single objective is optimized, that is, in GOM
only one objective is considered when testing for improvements
(line 13). A change is accepted if the oﬀspring does not have worse
ﬁtness than the parent. In all other clusters, multi-objective opti-
mization is performed, that is, in GOM both objectives are consid-
ered when testing for improvements (line 15). A change is accepted
if the oﬀspring either: 1) dominates the parent, 2) has equal objec-
tive values as the parent, 3) is not dominated by any member of the
elitist archive and has diﬀerent objective values than any member
in the elitist archive, or 4) has the same objective values as a mem-
ber in the elitist archive but is diﬀerent in semantic space. When
variation does not change the solution for one generation or does
not improve the solution for 1 + log10 (N) generations, we do an
additional round of GOM called Forced Improvements (FI). This
means that another round of variation is done with the donor be-
ing a random member from the elitist archive, or in the case of
extreme clusters, the solution from the archive that has the best
ﬁtness for the corresponding single objective. The acceptance is
the same as with regular variation, except, when the oﬀspring has
the same objective value(s) as the parent, the change is rejected. In
addition, we stop iterating over the FOS once a change is accepted.
If it has not changed during FI, we replace the oﬀspring with a ran-
dom member from the elitist archive, unless it originated from an
extreme cluster, in which case we replace it with the solution from
the archive that has the best ﬁtness in terms of the corresponding
single objective. After variation, the elitist archive is updated with
the oﬀspring (line 16).

E.M.C. Sijben, T. Alderliesten, and P.A.N. Bosman

3.4 Objectives
We optimize for two objectives, error and diversiﬁed error. For er-
ror, we use the commonplace Mean Squared Error (MSE). For diver-
siﬁed error, we specify an objective that ﬁts well with the concept
of GP-based XAI in practice as outlined in the introduction.

3.4.1 Error objective. The MSE is arguably the most commonly
adopted objective in machine learning, especially for (symbolic)
regression. In case of our multi-tree representation, to calculate
the error, for each tree 𝑡𝑖 of the multi-tree 𝑇 , the MSE is calculated
between the targets 𝑦 associated with data points 𝑋 𝑗 and the pre-
dictions of the tree 𝑡𝑖 (𝑋 𝑗 ). We calculate the ﬁnal error 𝐸 of the
multi-tree by summing the MSE of the individual trees, i.e.:

𝐸 =

𝑛

Õ
𝑖=1

𝑀𝑆𝐸 (𝑡𝑖, 𝑋 , 𝑦),

𝑀𝑆𝐸 (𝑡𝑖, 𝑋 , 𝑦) =

1
|𝑋 |

|𝑋 |

Õ
𝑗=1

(𝑡𝑖 (𝑋 𝑗 ) − 𝑦 𝑗 )2

,

𝑛 is the number of trees in a multi-tree, and |𝑋 | is the number of
records in the data set.

3.4.2 Diversified error objective. As all our experiments will be
done with two trees, for now, we introduce the deﬁnition for the
diversiﬁed error objective for a multi-tree with two trees. We come
back to this in Section 7. We deﬁne the diversiﬁed error 𝐷 as the
mean of the minimum squared error of the individual trees, i.e.,:

𝐷 =

1
|𝑋 |

|𝑋 |

Õ
𝑗=1

min((𝑡1(𝑋 𝑗 ) − 𝑦 𝑗 )2

, (𝑡2 (𝑋 𝑗 ) − 𝑦 𝑗 )2).

We choose this objective function for three reasons. Firstly, it
enables ﬁnding expressions that together describe a data set well,
i.e., expressions that describe diﬀerent parts of the data set. Note
that because we also optimize for error objective 𝐸, we will ﬁnd
expressions that not only predict the data set well together but are
also optimized for their individual error. In addition, describing dif-
ferent parts of a data set with diﬀerent models can even improve
interpretability, because it resonates well with how humans intu-
itively understand things. Humans tend to categorize things [15].
In this way, they can dissect a problem and try to understand parts
of it separately. Secondly, in combination with the error objective,
we can ﬁnd sets of expressions that have a similar error but have a
diﬀerent error distribution over the data points. Thirdly, an expert
may well prefer a model that is very good in some cases, but obvi-
ously wrong in others, over a model that is moderately right and
wrong in all cases. In practice, this may for instance mean fewer ad-
justments or further investigations: the cases in which the model
is very good do not need to be adjusted. Also, such an objective es-
sentially ﬁnds an ensemble of complementary models that would
have superior performance upon its use, when it is clear in practice
for a particular case which model to follow. In summary, with this
objective, we can ﬁnd expressions that describe the data better as a
set than a single expression would be able to, but at the same time,
we also ﬁnd sets containing expressions with a similar individual
error that are diﬀerent from each other.

Alternatively, one could deﬁne a diversity objective that maxi-
mizes the distance between the predictions of the trees within a

Multi-modal multi-objective model-based genetic programming to find multiple diverse high-quality models

multi-tree. However, this also stimulates expressions that do not
perform well and are just very diﬀerent. By contrast, using 𝐷, we
do not stimulate diversity merely for the sake of diversity.

Finally, while 𝐷 is proposed with the goal of oﬀering interesting
alternative models, 𝐷 is a non-smooth non-convex function, which
would be unsuitable for most typical machine learning approaches.
It is a key strength of GP, being an evolutionary machine learning
approach, that it can handle such functions.

4 EXAMPLES ON SYNTHETIC DATA
In this section, we present two examples of the use of our approach
on synthetic data. We generate two simple regression data sets,
with Gaussian Noise (𝐺𝑁 ) added. We perform a single run with
our approach, using multi-tree individuals with 𝑛 = 2. We multi-
objectively optimize the error 𝐸 and the diversiﬁed error 𝐷. The
allowed symbols are the functions +, −, ×, ÷𝑝 , Ephemeral Random
Constants (ERCs), and the input variables that appear in the syn-
thetic data set. We use a maximum tree height of 3 (7 nodes), and
perform 30 generations with a population size of 1000. We choose
this population size because, on the one hand, these are quite sim-
ple problems, but on the other hand, we need to search in three
‘directions’; the two extremes and the trade-oﬀ between those two.

4.1 Example 1: multi-modal data
We generate a multi-modal data set with one input variable 𝑋 , and
target variable 𝑌 using the following functions:

𝑓 (𝑋 ) = 𝑋 2 + 𝐺𝑁 (0, 10)
𝑔(𝑋 ) = 2 · 𝑋 + 𝐺𝑁 (0, 10)

We generate 100 data points with 𝑌 = 𝑓 (𝑋 ) where 𝑋 is drawn
randomly from the interval 𝑋 [0, 10], and generate 40 data points
with 𝑌 = 𝑔(𝑋 ) where 𝑋 is drawn from the same interval.

We show the approximation front of the error and diversiﬁed
error found by our approach on this data set in Figure 3. We also
show the predicted 𝑌 of the two expressions of three multi-tree
models along the front, against 𝑋 , as well as the expressions them-
selves. As can be observed, our approach can eﬀectively model
multi-modal data sets. In particular, we see that the expressions of
multi-tree C closely resemble 𝑓 (𝑋 ) and 𝑔(𝑋 ), despite the uneven
number of data points per function. The expressions of multi-tree
A fall in between 𝑓 (𝑋 ) and 𝑔(𝑋 ), because this minimizes the MSE.
Multi-tree B is somewhere in between A and C.

4.2 Example 2: hidden variable
We generate a data set with hidden variable 𝐻 , two input variables
𝑋1 and 𝑋2, and target variable 𝑌 , i.e., 𝐻 itself is not in the data set.
Target variable 𝑌 is equal to hidden variable 𝐻 . Input variables 𝑋1
and 𝑋2 are ﬂawed ‘estimations’ of 𝐻 . More speciﬁcally, the data
set is generated using the following functions:

𝑋1 = 𝐻 + 𝐺𝑁 (0, 0.5)
𝑋2 = 𝐻 + 𝐺𝑁 (0, 0.5)
𝑌 = 𝐻

We generate 100 data points by drawing 𝐻 randomly from the
interval [0, 10]. We show the approximation front of the error and
diversiﬁed error found by our approach on this data set in Figure 4.
Furthermore, we show the two expressions, and their individual

Figure 3: The approximation front of our approach on the
synthetic multi-modal data set. The predictions of the ex-
pressions of multi-trees A, B and C are visualized.

MSE, of two multi-tree models along the front. The parameters are
as described above, except here we do not use ERCs. By chance, due
to the randomness of the Gaussian noise, 𝑋1 has a slightly smaller
error for predicting 𝑌 . Therefore, expressions that simply predict
𝑋1 have a lower MSE than expressions that predict 𝑋2. However,
𝑋1 and 𝑋2 are almost equally good. Our approach is able to retrieve
multi-tree model B that represents this, with one expression using
𝑋1 and the other expression using 𝑋2.

The same principle applies to more elaborate data sets as well.
Data sets may have multiple input variables or combinations of
input variables that are good predictors of the target variable. Ex-
pressions using diﬀerent combinations of the variables and func-
tions might have a similar error, but if one of the functions is only
slightly better, or if one of the solutions is easier to ﬁnd when op-
timizing for MSE only, the focus will be on this solution. Our ap-
proach explicitly stimulates to explore diﬀerent possibilities and is
more likely to ﬁnd multiple of these solutions.

5 EVALUATION ON BENCHMARK DATA
In this section, we evaluate our approach on real-world data sets.
We ﬁrst describe our experimental setup before reporting our re-
sults.

5.1 Experimental setup
We evaluate three approaches: our multi-modal multi-tree MO-GP-
GOMEA approach, multi-tree SO optimization with GP-GOMEA,
and multi-tree NSGA-II [6]. We compare with SO optimization to
evaluate whether our approach can ﬁnd solutions at the extremes

E.M.C. Sijben, T. Alderliesten, and P.A.N. Bosman

Table 2: Algorithm parameter and experiment settings.

Setting

Functions

Terminal

Train-test split

For SO and Ours: tree height

For NSGA-II: maximum tree size

I

II

III

+, −, ×, ÷𝑝

variables, ERC

75%-25%

3

7

4

15

5

31

Time (s)

CPU

1200

7200

10800

AMD EPYC 7282

we use a crossover proportion of 0.5, a mutation proportion of 0.5,
a tournament size of 4, and ramped half-and-half initialization.

Furthermore, we use a population size of 5000 for SO optimiza-
tion, and a population size of 15000 in MO optimization. For our
approach and NSGA-II, we use a population size that is 3 times
larger than for SO, because MO needs to optimize three ‘directions’,
namely the two extremes and the trade-oﬀ between those two. For
our approach, we use 7 clusters in MO-GP-GOMEA.

For both objectives, we report the objective values of the ex-
treme solutions found by the three approaches. We also report the
HyperVolume (HV) of our approach and that of NSGA-II. HV is
a measure that indicates the volume covered by the approxima-
tion front with respect to a reference point. We compute the HV
by ﬁrst combining all approximation fronts found by the diﬀerent
approaches over all runs, and then extracting the non-dominated
solutions, i.e., we take the front of fronts. Then, we take the mini-
mum and maximum values in each objective from this front, and
we use them to normalize all approximation fronts. Finally, we get
the HV by computing the surface area covered by the front with
respect to reference point [1.1, 1.1]. Note that this can mean that
HV values of 0 can be reported, indicating that the median run did
not ﬁnd any multi-tree solution near the best found solutions.

5.2 Results
We report the results of the experiment setting II in Tables 3 and
4. Table 3 shows that generally our approach has a signiﬁcantly
bigger HV than NSGA-II. Table 4 shows that the best performing
solution of our approach generally has no signiﬁcant diﬀerence in
diversiﬁed error 𝐷 compared with SO, and is signiﬁcantly better
than NSGA-II. Similar ﬁndings can be observed in Table 4 regard-
ing error 𝐸. The supplementary material includes the results of ex-
periment I and III. These results generally show the same pattern
as in experiment II. For the error objective, however, our approach
is signiﬁcantly better than SO in experiment I, whereas SO is signif-
icantly better in many cases in experiment III. The median values
however, are similar. From the above, we conclude that we can ef-
fectively ﬁnd a high-quality approximation front that includes the
extreme solutions.

6 EXAMPLES ON REAL-WORLD DATA
In this section, we take a closer look at some results of our ap-
proach, using the yacht and the Boston housing data sets as exam-
ples. These examples illustrate how our approach could be useful
to users. For both examples, we perform a single run and describe

Figure 4: The approximation front of our approach on the
synthetic hidden variable data set. The two expressions, and
the individual MSE of multi-trees A and B are shown.

Table 1: Properties of benchmark data sets.

Data set (abbreviation)

Features

Samples

Boston housing (b)
Concrete compressive strength (c)
Yacht hydrodynamics (y)

13
9
6

506
1030
308

of the approximation front that are as good as when optimizing for
each objective individually.

NSGA-II is a state-of-the-art MO EA, and perhaps the most pop-
ular MO EA in literature. Note that the GP version of NSGA-II does
not use tree templates but has a variable tree length (with a maxi-
mum total size) like in traditional GP. We compare with NSGA-II
to evaluate whether our approach can ﬁnd approximation fronts
as good as, or better than, a state-of-the-art MO GP algorithm.

We evaluate these approaches on three well-known data sets
with a regression task, of which we show the properties in Table 1.
The Boston housing data set contains information concerning hous-
ing in the area of Boston Mass [14], where the goal is to predict the
median house value in an area. The concrete compressive strength
data set contains information concerning the components and age
of concrete [24], where the goal is to predict the strength of con-
crete. The yacht hydrodynamics data set contains information on
the characteristics of yachts [12], where the goal is to predict the
resistance of sailing yachts.

We initialize the population with multi-tree individuals with
𝑛 = 2. We multi-objectively optimize the two objective functions
described in subsection 3.4: 𝐸 and 𝐷. Algorithm parameter and ex-
periment settings are given in Table 2. Each run is repeated 30
times with a diﬀerent random seed. We report the median over
these runs and the statistical signiﬁcance of the Wilcoxon signed-
rank test (with 𝛼 = 0.05 and Bonferroni correction). For NSGA-II

Multi-modal multi-objective model-based genetic programming to find multiple diverse high-quality models

Table 3: Median HV results for experiment setting II. A tri-
angle symbol next to the reported median value indicates
signiﬁcant superiority (better (=bigger) HV) to the approach
with the name in the same color as the triangle.

Data set

Split

b
b
c
c
y
y

Train
Test
Train
Test
Train
Test

Ours
0.61 N
0.00
0.57 N
0.32 N
0.11 N
0.00 N

NSGA-II

0.33
0.00
0.00
0.00
0.00
0.00

Table 4: Median best diversiﬁed error 𝐷 and median best er-
ror 𝐸 for experiment setting II. A down-pointing triangle
next to the reported median value indicates signiﬁcant su-
periority (better (=smaller) objective value) to the approach
with the name in the same color as the down-pointing trian-
gle.

Data set

Split

Ours

NSGA-II

SO

𝐷

6.97 H
13.29
31.98 H H
32.71 H
0.96 H
1.44 H

𝐸

39.17 H
51.13 H
191.79 H
211.41 H
7.17 H
8.87 H

Train
Test
Train
Test
Train
Test

Train
Test
Train
Test
Train
Test

9.58
13.86
46.67
46.48
3.36
2.94

48.96
61.78
279.83
274.80
24.39
19.74

6.77
13.24
34.30
35.79
1.10
1.66

H

H
H
H
H

H
39.33
H
51.38
H
194.37
195.65 H H
H
H

7.23
8.23

b
b
c
c
y
y

b
b
c
c
y
y

the expressions found by our approach. We use the settings as de-
scribed in our experimental setup in the previous section, with tree
height 3.

6.1 Example 1: Yacht data set
In Figure 5, we show the approximation front of the error and di-
versiﬁed error found by our approach on the yacht data set. We
also show the predicted resistance ˆ𝑅 of the two expressions of three
multi-tree models along the front, against the Froude number 𝐹 , as
well as the expressions themselves. The Froude number is a ratio
between the speed of the yacht and the gravity, which is known to
inﬂuence the (wave) resistance of a yacht. 𝑃 is the prismatic coef-
ﬁcient, which is a measure of how quick the breadth of the yacht
changes or in other words a measure for the fullness of the ends of
the yacht.

We see that the expressions of multi-tree C, which is an extreme
solution, having the best diversiﬁed error 𝐷, describe the data well
together: expression 1 describes the data well for 𝐹 > 0.38, while
expression 2 describes the data well for 𝐹 < 0.38. This corresponds
well to ﬁndings in literature: according to the theory of Chapman,
as well as experimental results, the resistance increases drastically
when the Froude number exceeds approximately 0.38 [3, 22].

Figure 5: The approximation front of our approach on the
yacht data set. The predictions ˆ𝑅 of the expressions of multi-
trees A, B, and C are visualized against 𝐹 .

The expressions of multi-tree A, on the other hand, which is
an extreme solution, having the best error 𝐸, both try to model
the whole data set, which corresponds to having the lowest MSE.
However, neither accurately describes the data for either 𝐹 < 0.38
or 𝐹 > 0.38. The predictions of the expressions of multi-tree B are
visually somewhere in between the predictions of A and C.

6.2 Example 2: Boston housing data set
In Figure 6, we show the approximation front of the error and di-
versiﬁed error found by our approach on the Boston housing data
set. Furthermore, we show the two expressions, and their individ-
ual MSE, of three multi-tree models along the front.

Expression 2 of multi-tree A has the lowest error. However, de-
pending on the task, this expression might not be the expression
that best accommodates the needs of the user. Assume the user
is a real estate investor that is interested in the factors that inﬂu-
ence the house price. Now suppose that the user knows that a new
highway will be built in the near future. The user wants to take
this into account when buying new houses and wants to predict
how the highway might aﬀect the value of houses in that area, to
predict how much proﬁt can be made. Therefore, the user employs
expression 1 of multi-tree B, which uses 𝑥8, the index of the acces-
sibility to radial highways, assuming the new highway only eﬀects
𝑥8 and not the other variables, instead of expression 2 of multi-tree
A that does not use 𝑥8 and is only slightly diﬀerent in MSE. This
shows how it can be useful to search for multiple expressions that
are diﬀerent but have a similar MSE. If the user had used SO opti-
mization to generate expressions, the user would not have had this
choice, because only one model would have been presented.

E.M.C. Sijben, T. Alderliesten, and P.A.N. Bosman

error but have a diﬀerent error distribution over the data points.
We explain why 𝐷2 stimulates a diﬀerent kind of diversity with an
example in Figure 7. In this example, either 𝑡2 or 𝑡3 is closer to ev-
ery target value 𝑦1, . . . , 𝑦5 than 𝑡1. Therefore, 𝑡1 does not decrease
𝐷1, even though it adds diversity with respect to 𝑡2 and 𝑡3. 𝐷2, in
contrast, takes into account the diversity that 𝑡1 adds.

Figure 7: A multi-model with 𝑛 = 3 and target values
𝑦1, . . . , 𝑦5.

When 𝑛 > 2, there are a few options regarding how to use 𝐷1
and 𝐷2 alongside 𝐸. One could choose to 1) use either 𝐷1 or 𝐷2,
depending on their needs, 2) perform multiple runs, some of which
optimize 𝐷1, and some of which optimize 𝐷2, or 3) perform a run
which optimizes both 𝐷1 and 𝐷2 along 𝐸 with MO optimization
with three objectives. This may however make ﬁnal model selec-
tion more complicated.

Finally, an important next step is to evaluate our approach in a
real-world setting where users are provided with multiple expres-
sions to choose from. For example, it could be researched how peo-
ple interact with the solutions that our approach ﬁnds, and how
to present multiple solutions to a user. Another aspect to study
is how to aggregate and/or combine the results of our approach
with cross-validation, given that you would get multiple fronts of
models. Finally, the interleaved multi-start scheme [7] could be im-
plemented such that users do not have to choose a population size
when using our approach.

8 CONCLUSION
In this work, we have presented a novel multi-modal multi-tree
MO GP approach that extends a modern model-based GP algo-
rithm known as GP-GOMEA. We presented experimental evidence
on synthetic and real-world data that showed that our approach
can generate multiple diverse high-quality expressions that include
expressions that excel in diﬀerent notions of quality. Our approach
could be a promising approach to allow users to inspect diﬀerent
models, which could lead to novel insights into the data and the
process underlying the data. Providing the user with options in
this manner, possibly in combination with additional expert knowl-
edge, could help support them in choosing a good model for the
task at hand in a powerful and sensible way.

ACKNOWLEDGMENTS
This research was funded by the European Commission within the
HORIZON Programme (TRUST AI Project, Contract No.: 952060).

Figure 6: The approximation front of our approach on the
Boston housing data set. The two expressions, and the indi-
vidual MSE of multi-trees A, B, and C are shown. 𝑥1 is the
proportion of land with big lots, 𝑥5 is the average number of
rooms per residence, 𝑥7 is the weighted distance to ﬁve em-
ployment centers, 𝑥8 is the accessibility to radial highways,
𝑥10 is the ratio of pupils to teachers of a town, and 𝑥12 is the
percentage of adults without high school education.
7 DISCUSSION
We evaluated our approach with multi-trees where 𝑛 = 2. To use
our approach with multi-trees where 𝑛 > 2, we need to generalize
the diversiﬁed error objective function 𝐷. In principle, this can be
done by simply taking the minimum error over all trees. For the ex-
treme solution that optimizes this generalization, individual trees
will still represent diﬀerent parts of the data more closely. Toward
the other extreme, the sum of MSE values, however, this general-
ization does not necessarily have the same eﬀect as for 𝑛 = 2. To
realize this also for 𝑛 > 2, we specify two diversiﬁed error func-
tions, 𝐷1 and 𝐷2. 𝐷1 is the aforementioned generalization, and 𝐷2
is the average pairwise mean of the minimum squared error of the
trees:

min((𝑡1(𝑋 𝑗 ) − 𝑦 𝑗 )2

, . . . , (𝑡𝑛 (𝑋 𝑗 ) − 𝑦 𝑗 )2)

|𝑋 |

1
|𝑋 |

Õ
𝑗=1
2
𝑛 · (𝑛 − 1)

𝐷1 =

𝐷2 =

where

𝑛−1

𝑛

Õ
𝑖=1

Õ
𝑙 =𝑖+1

𝐷𝑝 (𝑡𝑖, 𝑡𝑙 ),

𝐷𝑝 (𝑡𝑖, 𝑡𝑙 ) =

1
|𝑋 |

|𝑋 |

Õ
𝑗=1

min((𝑡𝑖 (𝑋 𝑗 ) − 𝑦 𝑗 )2

, (𝑡𝑙 (𝑋 𝑗 ) − 𝑦 𝑗 )2).

Note that for 𝑛 = 2 the objective functions are equal, i.e., 𝐷 =
𝐷1 = 𝐷2. 𝐷1 stimulates sets of expressions that describe a data set
well together. 𝐷2 stimulates sets of expressions that have similar

Multi-modal multi-objective model-based genetic programming to find multiple diverse high-quality models

[21] Dirk Thierens and Peter A.N. Bosman. 2011. Optimal Mixing Evolutionary Algo-
rithms. In Proceedings of the 13th Annual Conference on Genetic and Evolutionary
Computation (Dublin, Ireland) (GECCO ’11). Association for Computing Machin-
ery, New York, NY, USA, 617–624. https://doi.org/10.1145/2001576.2001661
[22] Ernest O Tuck. 1987. Wave resistance of thin ships and catamarans. Report

T8701. Applied Mathematics Department, The University of Adelaide (1987), 15.

[23] Marco Virgolin, Tanja Alderliesten, Cees Witteveen, and Peter AN Bosman. 2021.
Improving model-based genetic programming for symbolic regression of small
expressions. Evolutionary Computation 29, 2 (2021), 211–237.

[24] I.-C. Yeh. 1998. Modeling of strength of high-performance concrete using arti-
ﬁcial neural networks. Cement and Concrete Research 28, 12 (1998), 1797–1808.
https://doi.org/10.1016/S0008-8846(98)00165-3

REFERENCES
[1] Anton Bouter, Tanja Alderliesten, Cees Witteveen, and Peter A. N. Bosman.
2017. Exploiting Linkage Information in Real-Valued Optimization with the Real-
Valued Gene-Pool Optimal Mixing Evolutionary Algorithm. In Proceedings of the
Genetic and Evolutionary Computation Conference (Berlin, Germany) (GECCO
’17). Association for Computing Machinery, New York, NY, USA, 705–712.
https://doi.org/10.1145/3071178.3071272

[2] Armand R. Burks and William F. Punch. 2015. An Eﬃcient Structural Diver-
sity Technique for Genetic Programming. In Proceedings of the 2015 Annual
Conference on Genetic and Evolutionary Computation (Madrid, Spain) (GECCO
’15). Association for Computing Machinery, New York, NY, USA, 991–998.
https://doi.org/10.1145/2739480.2754649

[3] R.B. Chapman. 1972. Hydrodynamic drag of semisubmerged ships. Journal of
Basic Engineering 94 (1972), 879–884. Issue 4. https://doi.org/10.1115/1.3425581
[4] European Commission, Content Directorate-General for Communications Net-
works, and Technology. 2019. Ethics guidelines for trustworthy AI. Publications
Oﬃce. https://doi.org/10.2759/177365

[5] Edwin D. de Jong, Richard A. Watson, and Jordan B. Pollack. 2001. Reducing
Bloat and Promoting Diversity Using Multi-Objective Methods. In Proceedings
of the 3rd Annual Conference on Genetic and Evolutionary Computation (San Fran-
cisco, California) (GECCO’01). Morgan Kaufmann Publishers Inc., San Francisco,
CA, USA, 11–18.

[6] K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan. 2002. A Fast and Elitist Multiob-
jective Genetic Algorithm: NSGA-II. Transactions on Evolutionary Computation
6, 2 (April 2002), 182–197. https://doi.org/10.1109/4235.996017

[7] Arkadiy Dushatskiy, Marco Virgolin, Anton Bouter, Dirk Thierens, and Peter AN
Bosman. 2021. Parameterless Gene-pool Optimal Mixing Evolutionary Algo-
rithms. arXiv preprint arXiv:2109.05259 (2021).

[8] Anikó Ekárt and Sandor Z. Németh. 2000. A Metric for Genetic Programs and Fit-
ness Sharing. In Proceedings of the European Conference on Genetic Programming.
Springer-Verlag, Berlin, Heidelberg, 259–270.

[9] Benjamin P. Evans, Bing Xue, and Mengjie Zhang. 2019. What’s inside the Black-
Box? A Genetic Programming Method for Interpreting Complex Machine Learn-
ing Models. In Proceedings of the Genetic and Evolutionary Computation Confer-
ence (Prague, Czech Republic) (GECCO ’19). Association for Computing Machin-
ery, New York, NY, USA, 1012–1020. https://doi.org/10.1145/3321707.3321726

[10] Leonardo Augusto Ferreira, Frederico Gadelha Guimarães, and Rodrigo Silva.
2020. Applying genetic programming to improve interpretability in machine
learning models. In 2020 IEEE Congress on Evolutionary Computation (CEC). IEEE,
1–8.

[11] Edgar Galván and Marc Schoenauer. 2019.

Promoting Semantic Diver-
sity in Multi-Objective Genetic Programming. In Proceedings of the Genetic
and Evolutionary Computation Conference (Prague, Czech Republic) (GECCO
’19). Association for Computing Machinery, New York, NY, USA, 1021–1029.
https://doi.org/10.1145/3321707.3321854

[12] J Gerritsma, R Onnink, and A Versluis. 1981. Geometry, resistance and stability
of the Delft systematic yacht hull series. International shipbuilding progress 28,
328 (1981), 276–297.

[13] Ilan Gronau and Shlomo Moran. 2007. Optimal implementations of UPGMA
Inform. Process. Lett. 104, 6 (2007),

and other common clustering algorithms.
205–210.

[14] David Harrison and Daniel L Rubinfeld. 1978. Hedonic housing prices and the
demand for clean air. Journal of Environmental Economics and Management 5, 1
(1978), 81–102. https://doi.org/10.1016/0095-0696(78)90006-2

J. Klausmeier.

[15] Herbert
cept
267–286.
arXiv:https://doi.org/10.1207/s15326985ep2703_1

1992.
Educational

Teaching.

Concept
Psychologist

and Con-
(1992),
3
https://doi.org/10.1207/s15326985ep2703_1

Learning
27,

[16] William La Cava, Patryk Orzechowski, Bogdan Burlacu, Fabrício Olivetti de
França, Marco Virgolin, Ying Jin, Michael Kommenda, and Jason H Moore. 2021.
Contemporary symbolic regression methods and their relative performance.
arXiv preprint arXiv:2107.14351 (2021).

[17] Ngoc Hoang Luong, Han La Poutré, and Peter A.N. Bosman. 2014. Multi-
Objective Gene-Pool Optimal Mixing Evolutionary Algorithms. In Proceedings
of the 2014 Annual Conference on Genetic and Evolutionary Computation (Van-
couver, BC, Canada) (GECCO ’14). Association for Computing Machinery, New
York, NY, USA, 357–364. https://doi.org/10.1145/2576768.2598261

[18] R I (Bob) McKay. 2000. Fitness Sharing in Genetic Programming. In Proceedings
of the 2nd Annual Conference on Genetic and Evolutionary Computation (Las Ve-
gas, Nevada) (GECCO’00). Morgan Kaufmann Publishers Inc., San Francisco, CA,
USA, 435–442.
[19] Christoph Molnar.

Interpretable Machine

Learning.

2019.

https://christophm.github.io/interpretable-ml-book/

[20] Michael D. Schmidt and Hod Lipson. 2010. Age-Fitness Pareto Optimization. In
Proceedings of the 12th Annual Conference on Genetic and Evolutionary Computa-
tion (Portland, Oregon, USA) (GECCO ’10). Association for Computing Machin-
ery, New York, NY, USA, 543–544. https://doi.org/10.1145/1830483.1830584

Multi-modal multi-objective model-based genetic programming
to find multiple diverse high-quality models — Supplementary
materials

E.M.C. Sijben
Centrum Wiskunde & Informatica
Amsterdam, the Netherlands
evi.sijben@cwi.nl

T. Alderliesten
Leiden University Medical Center
Leiden, the Netherlands
t.alderliesten@lumc.nl

P.A.N. Bosman
Centrum Wiskunde & Informatica
Amsterdam, the Netherlands
peter.bosman@cwi.nl

1 CLUSTERING IN MO-GOMEA
We use the same clustering method in our approach as in MO-
GOMEA [1], which is Balanced K-Leader-Means (BKLM) cluster-
ing. First, 𝑘 leaders are selected. The ﬁrst leader is selected by tak-
ing the individual with the minimum value for a randomly chosen
objective. Next, the distances D = (D1, . . . , D𝑁 ) between each in-
dividual and the ﬁrst leader are computed, with 𝑁 being the popu-
lation size. The individual with the maximum distance is selected
as the next leader. Then, the distances D are updated by taking
for each individual P𝑖 the minimum of D𝑖 and the distance be-
tween P𝑖 and the new leader. This is repeated until 𝑘 leaders are
found. These 𝑘 leaders are used as initial cluster centers to perform
𝑘-means clustering. After 𝑘-means clustering has converged, each
cluster is assigned the 2·𝑁
solutions that are closest to its center.
𝑘
For variation, however, it needs to be known for each individual
which FOS to use, which donors to choose from, and whether to
use SO GOM or MO GOM. Therefore, each individual needs to be
assigned to precisely one cluster. To do this, individuals that are not
yet assigned to a cluster, are assigned to the cluster with the clos-
est center, and individuals that are assigned to multiple clusters,
are assigned to one of these clusters at random. Figure 1 illustrates
this process.

2 EXPERIMENTAL RESULTS
In the main text, we describe three diﬀerent settings for our experi-
ments: I, II, and III. We show results of these experiments in Tables
1, 2, and 3.

Table 1: Median HV results for experiment settings I, II, and
III. A triangle symbol next to the reported median value in-
dicates signiﬁcant superiority (better (=bigger) HV) to the ap-
proach with the name in the same color as the triangle.

Data set

Split

Ours

NSGA-II

Setting I

0.17 N
0.05 N
0.03 N
0.35 N
0.00
0.00

Setting II

0.61 N
0.00
0.57 N
0.32 N
0.11 N
0.00 N

Train
Test
Train
Test
Train
Test

Train
Test
Train
Test
Train
Test

Setting III

Train
Test
Train
Test
Train
Test

0.57 N
0.00
0.57 N
0.33 N
0.45 N
0.00

0.00
0.01
0.00
0.12
0.00
0.00

0.33
0.00
0.00
0.00
0.00
0.00

0.09
0.00
0.00
0.00
0.00
0.00

b
b
c
c
y
y

b
b
c
c
y
y

b
b
c
c
y
y

2
2
0
2

r
a

M
4
2

]
E
N
.
s
c
[

1
v
7
4
3
3
1
.
3
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
E.M.C. Sijben, T. Alderliesten, and P.A.N. Bosman

Figure 1: Example of how BKLM operates. The points represent the normalized objective values of the individuals. In “Leader
Selection", stars denote the positions of the leaders. In “K-means Clustering", stars denote the position of the cluster centers.
The color of a point indicates the cluster that the individual belongs to. If a point has multiple colors this means that the point
belongs to multiple clusters. We illustrate a very small population size to keep the ﬁgure readable.

Table 2: Median best diversiﬁed error 𝐷 for experiment set-
tings I,II and III. A down-pointing triangle next to the re-
ported median value indicates signiﬁcant superiority (better
(=smaller) objective value) to the approach with the name in
the same color as the down-pointing triangle.

Table 3: Median best error 𝐸 for experiment settings I,II and
III. A down-pointing triangle next to the reported median
value indicates signiﬁcant superiority (better (=smaller) ob-
jective value) to the approach with the name in the same
color as the down-pointing triangle.

Data set

Split

Ours

NSGA-II

SO

Data set

Split

Ours

NSGA-II

SO

Setting I

10.40 H
15.17 H
63.04 H H
61.67 H
6.65 H H
7.09 H H

Setting II

6.97 H
13.29
31.98 H H
32.71 H
0.96 H
1.44 H

Setting III

5.09 H
11.83
20.70 H
20.24 H
0.63 H
1.32 H

Train
Test
Train
Test
Train
Test

Train
Test
Train
Test
Train
Test

Train
Test
Train
Test
Train
Test

14.02
18.31
83.32
81.73
14.46
11.22

9.58
13.86
46.67
46.48
3.36
2.94

6.95
13.52
30.31
32.59
1.21
1.47

10.72
15.12
68.02
65.59
13.79
13.27

6.77
13.24
34.30
35.79
1.10
1.66

5.02
12.81
21.19
21.28
0.63
1.22

H
H
H
H
H

H

H
H
H
H

H

H
H
H
H

b
b
c
c
y
y

b
b
c
c
y
y

b
b
c
c
y
y

Setting I

53.26 H H
65.37 H H
376.19 H H
399.43 H
65.89 H H
65.78 H H

Setting II

39.17 H
51.13 H
191.79 H
211.41 H
7.17 H
8.87 H

Setting III

32.32 H
47.48 H
121.25 H
122.05 H
4.99 H
6.51 H

81.54
105.70
464.92
448.56
111.09
103.78

48.96
61.78
279.83
274.80
24.39
19.74

39.54
54.19
182.77
185.57
8.65
8.21

Train
Test
Train
Test
Train
Test

Train
Test
Train
Test
Train
Test

Train
Test
Train
Test
Train
Test

55.72
69.37
385.03
410.08
89.20
83.93

H
H
H
H
H
H

H
39.33
H
51.38
H
194.37
195.65 H H
H
H

7.23
8.23

H
32.05
45.99 H H
H
119.15
H
122.42
4.20 H H
5.73 H H

b
b
c
c
y
y

b
b
c
c
y
y

b
b
c
c
y
y

REFERENCES
[1] Ngoc Hoang Luong, Han La Poutré, and Peter A.N. Bosman. 2014. Multi-Objective
Gene-Pool Optimal Mixing Evolutionary Algorithms. In Proceedings of the 2014
Annual Conference on Genetic and Evolutionary Computation (Vancouver, BC,
Canada) (GECCO ’14). Association for Computing Machinery, New York, NY, USA,
357–364. https://doi.org/10.1145/2576768.2598261

