0
2
0
2

l
u
J

3
1

]

G
L
.
s
c
[

1
v
6
8
2
6
0
.
7
0
0
2
:
v
i
X
r
a

Beyond Graph Neural Networks
with Lifted Relational Neural Networks

Gustav Sourek ∗

Filip Zelezny

Ondrej Kuzelka

Department of Computer Science
Faculty of Electrical Engineering
Czech Technical University in Prague

Abstract

We demonstrate a declarative diﬀerentiable programming framework based on the language of
Lifted Relational Neural Networks, where small parameterized logic programs are used to encode
relational learning scenarios. When presented with relational data, such as various forms of graphs,
the program interpreter dynamically unfolds diﬀerentiable computational graphs to be used for
the program parameter optimization by standard means. Following from the used declarative
Datalog abstraction, this results into compact and elegant learning programs, in contrast with the
existing procedural approaches operating directly on the computational graph level. We illustrate
how this idea can be used for an eﬃcient encoding of a diverse range of existing advanced neural
architectures, with a particular focus on Graph Neural Networks (GNNs). Additionally, we show
how the contemporary GNN models can be easily extended towards higher relational expressiveness.
In the experiments, we demonstrate correctness and computation eﬃciency through comparison
against specialized GNN deep learning frameworks, while shedding some light on the learning
performance of existing GNN models.

1

Introduction

It has been recently proposed by several authors that incorporating logic reasoning capabilities into
neural networks is crucial to achieve more powerful AI systems (Marcus, 2020; De Raedt et al., 2020;
Lamb et al., 2020). Indeed, we see a rising interest in enriching deep learning models with certain
facets of symbolic AI, ranging from logical entailment (Evans et al., 2018), rule learning (Evans and
Grefenstette, 2017), and solving combinatorial problems (Palm et al., 2018), to proposing diﬀerentiable
versions of a whole Turing machine (Graves et al., 2014, 2016). However, similarly to the Turing-
completeness of recurrent neural networks, the expressiveness of these advanced neural architectures
is not easily translatable into actual learning performance, as their optimization tends to be often
prohibitively diﬃcult (Lipton et al., 2015).

There has been a long stream of research in neural-symbolic integration (Bader and Hitzler, 2005;
Garcez et al., 2019), traditionally focused on emulating logic reasoning within neural networks (Towell
et al., 1990; Smolensky, 1990; Botta et al., 1997; Ding and Liya Ding, 1995). The eﬀorts eventually
evolved from propositional (Towell et al., 1990; Garcez and Zaverucha, 1999) into full ﬁrst order logic
settings, mapping logic constructs and semantics into respective tensor spaces and optimization con-
straints (Seraﬁni and d’Avila Garcez, 2016; Dong et al., 2019; Marra et al., 2020). Traditionally, the

∗corresponding author: souregus@fel.cvut.cz

1

 
 
 
 
 
 
neural-symbolic works focus on providing various perspectives into the correspondence between sym-
bolic and sub-symbolic representations and computing, targeting again mostly novelty and theoretical
expressiveness rather than practical learning applications.

From the bottom-up practical perspective, there has been a continuous eﬀort of applying neural
network learning to increasingly complex relational data (Uwents et al., 2011; Dash et al., 2018; Kazemi
and Poole, 2018). While learning from relational data has been traditionally dominated by approaches
rooted in relational logic (Muggleton and De Raedt, 1994) and its probabilistic extensions (Kersting
and De Raedt, 2001; Richardson and Domingos, 2006a; De Raedt et al., 2007), the neural networks oﬀer
highly eﬃcient latent representation learning, which is beyond capabilities of the symbolic systems.
Neural networks on the other hand have traditionally been based on ﬁxed tensor representations,
which cannot explicitly capture the unbounded, dynamic and irregular nature of the relational data.
Recursive (Socher et al., 2013b) and Graph neural networks (GNNs) (Scarselli et al., 2008) intro-
duced a highly successful paradigm shift by moving from ﬁxed neural architectures to dynamically
constructed computation graphs, directly following the structural bias presented by the input exam-
ples. As opposed to the recurrent (Graves et al., 2014) and “tensorization” (Garcez et al., 2019)
neural-symbolic approaches, this enables to exploit the structural properties of the data more eﬃ-
ciently, as they are simply directly coded into the very structure of the model, similarly to the original
propositional neural-symbolic integration methods (Towell et al., 1990). Consequently, GNNS achieved
remarkable success in a wide range of tasks (Zhou et al., 2018).

In targeting integration of deep and relational learning, one of the core desired properties for an
integrated system is to keep expressiveness of both the worlds as a special case. While much focus
has been devoted to keep the expressiveness of the logic reasoning, considerably less attention was put
on the neural models, the expressiveness and modern variations of which are mostly ignored by the
integrated systems (Manhaeve et al., 2018).

In this paper, we show how to use simple relational logic programs to capture advanced convolu-
tional neural architectures in a tightly integrated and exact manner. Particularly, we use the language
of Lifted Relational Neural Networks (LRNNs) (Sourek et al., 2018), and demonstrate that a wide
range of neural models, ranging from simple perceptrons to complex GNNs, can be elegantly and eﬃ-
ciently covered – not only from the perspective of expressiveness but, importantly, from the practical
point of view 1. We further show how to easily extend the basic GNN idea into some of the most
contemporary GNN architectures, and beyond.

The paper is structured as follows. Firstly, we introduce the necessary preliminaries of logic and
deep learning in Section 2. In Section 3, we introduce the language of LRNNs, which we use throughout
the paper. Subsequently, we illustrate LRNNs on a range of example models in Section 4. Capturing
In Section 6, we demonstrate practicality and
and extending GNNs is then detailed in Section 5.
eﬃciency of the approach. We then discuss related works in Section 7 and conclude in Section 8.

2 Background

Here we introduce the necessary preliminaries of (i) logic programming and (ii) deep learning, which
we seek to integrate.

2.1 Logic

Syntax: A relational logic theory is a set of formulas formed from constants, variables, and predicates
(Smullyan, 1995). Constant symbols represent objects in the domain of interest (e.g. hydrogen1) and

1Code to reproduce experiments from this paper is available at https://github.com/GustikS/GNNwLRNNs.

The LRNNs framework itself can then be found at https://github.com/GustikS/NeuraLogic.

2

will be written in lower-case. Variables (e.g. X) range over the objects in the domain and will be
written with a capitalized ﬁrst letter. Predicate symbols represent relations among objects in the
domain or their attributes. A term may be a constant or variable. An atom is a predicate symbol
applied to a tuple of terms (e.g. bond(X, hydrogen1)). Formulas are constructed from atoms using
logical connectives of ∨ and ∧ (Smullyan, 1995). A ground term is a term containing no variables.
A ground atom, also called proposition, is an atom having only ground terms as arguments (e.g.
bond(oxygen1, hydrogen1)). A literal is an atom or a negation of an atom. A clause is a universally
quantiﬁed disjunction of literals2. A clause with exactly one positive literal is a deﬁnite clause. A
deﬁnite clause with no negative literals (i.e. consisting of just one literal) is called a fact. A deﬁnite
clause h ∨ ¬b1 ∨ · · · ∨ ¬bk can also be written as an implication h ← b1 ∧ · · · ∧ bk. The literal h is then
called head and the conjunction b1 ∧ · · · ∧ bk is called body. We will often call deﬁnite clauses, which
are not facts, rules. A set of such rules is then commonly called a logic program.

Semantics: The Herbrand base of a set of relational formulas P is the set of all ground atoms
which can be constructed using the constants and predicates that appear in this set. A Herbrand
interpretation of P, also called a possible world, is a mapping that assigns a truth value to each element
from P’s Herbrand base. We say that a possible world I satisﬁes a ground atom F , written I |= F , if
F ∈ I. The satisfaction relation is then generalized to arbitrary ground formulas in the usual way. A
set of ground formulas is satisﬁable if there exists at least one possible world in which all formulas from
the set are true; such a possible world is called a Herbrand model. Each set of deﬁnite clauses has a
unique Herbrand model that is minimal w.r.t. the subset relation, called its least Herbrand model. The
least Herbrand model of a ﬁnite set of ground deﬁnite clauses can be constructed in a ﬁnite number
of steps using the immediate-consequence operator (Van Emden and Kowalski, 1976). This immediate
consequence operator is a mapping Tp from Herbrand interpretations to Herbrand interpretations,
deﬁned for a set of ground deﬁnite clauses P as Tp(I) = {h | (h ← b1 ∧ · · · ∧ bk) ∈ P, {b1, ..., bk} ⊆ I}.
In other words, the operator Tp expands the current set of true atoms (i.e. the current Herbrand
interpretation I) with their immediate consequences as prescribed by the rules in P.

Now consider a set of non-ground deﬁnite clauses P. The grounding of a clause α from P is the
set of ground clauses G(α) = {αθ1, ..., αθn} where θ1, ..., θn is the set of all possible substitutions, each
mapping the variables occurring in α to constants appearing in P. Note that if α is already ground,
its grounding is a singleton. The grounding of P is given by G(P) = (cid:83)
α∈P G(α). The least Herbrand
model of P is then deﬁned as the least Herbrand model of G(P). In practice, most of the rules in the
grounding G(P) will be irrelevant, as their body can never be satisﬁed. The restricted grounding limits
the grounding to those rules which are “active”, i.e. whose body is satisﬁed in the least Herbrand model
H. It is deﬁned by GR(P) = {hθ ← b1θ ∧· · ·∧bkθ | (h ← b1 ∧· · ·∧bk) ∈ P and {hθ, b1θ, . . . , bkθ} ⊆ H}.

2.1.1 Logic Programming

Logic programming is a declarative programming paradigm for computation with logic programs. In
this paradigm, deﬁnite clauses are used to express facts and rules about a domain, and the computation
is then carried out by the means of logical inference. Syntactically, the rules in the program h ←
b1 ∧ · · · ∧ bk are commonly written as

1 h :- b1 , . . . , bk .

where each “, ” stands for conjunction, and “:-” replaces the implication, which reads right-to-left.
Facts are then simply rules with no body.

2Note we do not write the universal quantiﬁers explicitly in this paper.

3

Particularly, we consider the language of Datalog (Unman, 1989), a restricted function-free subset
of Prolog (Bratko, 2001). Datalog is a domain speciﬁc language used in advanced deductive database
engines. In contrast with Prolog, Datalog is a truly declarative language, where the order of clauses
does not inﬂuence execution, and it is also guaranteed to terminate. Separate eﬃcient theorem proving
engine can then be used for computing the execution inferences (Bancilhon et al., 1985).

Importantly, it is still a relational language, and one can thus use variables in the clauses, enabling

to compose general and reusable programming patterns, such as

1 h (X) :- edge ( X,Y ), node (Y) .

which will then be automatically bound to a multitude of ground data structures via diﬀerent substi-
tutions for the variables {X,Y}. We will further extensively use this non-ground expressiveness while
extending Datalog towards diﬀerentiable programming3.

Query: Similarly to querying a standard database with SQL, one provides a query atom (q) to
execute a Datalog program towards inference of a speciﬁc target, e.g.

1 h ( oxygen1 ) ?

which then drives the theorem proving engine to ﬁnd a model I |= q of the given logic program. If
successful, the result of the execution is then the query together with the possible world I used for its
derivation. Note that there may be multiple worlds that model q.

2.2 Deep Learning

Deep learning is a machine learning approach characterized by using multi-layered neural network
models. A neural network is a parameterized computation graph, particularly a data-ﬂow graph
where the data ﬂowing through the edges are being successively transformed by numeric operations
represented by the nodes (neurons). A neural layer is a set of neurons residing at the same depth in
the directed data-ﬂow graph. A multi-layered (“deep”) neural network is a graph with more than two
such layers.

The data are commonly represented as (ﬁxed-size) tensors, and the operations are commonly
diﬀerentiable non-linear functions. Owing to the diﬀerentiability of the functions, the parameters of
a graph, commonly associated with the edges, can be eﬃciently trained by gradient-descend routines.
Due to the increasingly complex nature of the computation graphs and the utilized operations, the
ﬁeld has been recently also referred to as diﬀerentiable programming 4.

Neural architectures are common design patterns used in creation of the computation graphs for
speciﬁc types of problems. Here we brieﬂy review some of the most common and successful neural
architectures used in deep learning 5.

3This is a distinguishing feature from many other procedural diﬀerentiable programming languages, such as PyTorch

or TensorFlow, which are eﬀectively propositional in this sense.

4Note however that, despite being theoretically Turing-complete (e.g. recurrent neural networks), the models them-

selves are rarely as expressive in practice as standard programming languages used for their creation.

5We introduce these architectures explicitly, despite being commonly known, as we further work with them in detail

as diﬀerentiable Datalog programs.

4

2.2.1 Multi-layer Perceptrons

A multi-layered perceptron (MLP) is the original and most common neural architecture.
It is a
directed feed-forward data-ﬂow graph. Moreover, the interconnections between nodes in subsequent
layers commonly follow the “fully-connected” pattern (a complete bipartite graph). Consequently,
assuming the common vector form of the input data, the computation graph can be eﬃciently reduced
to a linear series of dense matrix multiplications, each followed by an element-wise application of a
non-linear function, such as logistic sigmoid (σ) or rectiﬁed linear unit (ReLU ).

The main idea behind MLPs is “representation learning” of the input data, often referred to as
embedding, where one can think of outputs of the individual layers as transformed representations of
the input, each extracting gradually more expressive information w.r.t. the output learning target.

2.2.2 Convolutional Networks

A convolutional neural network (CNN) is also a feed-forward architecture, characterized by utilizing
particular operations in one or more sub-parts of the computational graph. The speciﬁc operations are
commonly referred to as “convolution” (ﬁltering) and “pooling”. Given a vector input of size n, the
convolutional ﬁlter (kernel) will also be represented by a vector of size k < n, which is then successively
element-wise multiplied with all the k-length subsequences of the input vector, to produce n − k + 1
scalar values. The resulting values are commonly referred to as “feature-maps”. The second operation
is the pooling, which aggregates values from predeﬁned spatial sub-regions of the input values (feature-
maps) into a single output through application of some (non-parameterized) aggregation function such
as mean (avg) or maximum (max). The layers of these operations can then be mixed together with
the previously introduced layers from MLPs in various combinations.

The main idea behind the convolution operation is the application of the very same parameterized
function over diﬀerent regions of the input. This enables to abstract away common patterns out of
diﬀerent sub-parts of the input representation. The main idea behind the pooling operation is to
enforce invariance w.r.t. translation of the inputs.

2.2.3 Recursive and Recurrent Networks

A Recursive Neural Network (RNN)6 is a neural architecture which diﬀers signiﬁcantly from the
previous in that the exact form of the computation graph is not given in advance.
Instead, the
computation graph structure directly follows the structure of an input example, which takes the form
of a k−regular tree. This enables to learn neural networks directly from diﬀerently-structured regular
tree examples, as opposed to the ﬁxed-size tensors which can be seen as graphs with completely regular
grid topologies.

The leaf nodes in the computation tree then represent the input data, each of which is associated
with a feature vector (embedding). Every k leaf nodes are consequently combined by a given operation
to compute the representation for their common parent node. This combining operation then continues
recursively for all interior nodes, until the representation for the root node is computed, which forms
the output of the model. Similarly to the convolution in CNNs, the parameterized combining operation
over the children nodes remains the same over the whole tree (Socher et al., 2013a)7.

The main idea behind recursive networks is that neural learning can be extended towards structured
data by generating a dynamic computation graph for each individual example tree. The learning

6Note that the abbreviation is also used for the recurrent neural networks, in this paper however, we use it solely to

refer to recursive networks.

7In some works, this architecture is further extended to use a set of diﬀerent parameterizations, depending for instance

on given types associated with the nodes, such as types of constituents in constituency-based parse trees.

5

then exploits the convolution principle to discover the underlying compositionality of the learning
representations in recursive structures.

The basic form of a commonly known Recurrent Neural Network (Lipton et al., 2015) can then
linear chains of input nodes8.
be seen as a “restriction” of the idea to sequential structures, i.e.
The computation graph is then successively unfolded along the input sequence to compute the hidden
representation for each node based on the previous node’s representation and the current node features
(current input). The main idea behind recurrent networks is that the hidden representation can store
a sort of state of the computation.

2.3 Graph Neural Networks

Graph Neural Networks (GNN)9 can be seen as a further extension of the principle to completely
irregular graph structures (Bronstein et al., 2017). Similarly to the recursive networks, they dynam-
ically unfold the computational graph from the input structure for the purpose. However, GNN is
a multi-layered feed-forward neural architecture, where the structure of each layer i exactly follows
the structure of the whole input graph. Every node v in the graph can now be associated with a
feature vector (embedding), forming the input layer h(v)(0) = f eatures(v). Interestingly, however,
this is not necessary in general, as the variance in the graph topologies of the individual examples can
already provide enough discriminative information on its own. For computation of the next layer i + 1
representations of the nodes, each node in the graph updates its own representation by aggregating
representation vectors of the adjacent nodes (“message passing”) via some parameterized update op-
eration. GNNs again exploit the convolution idea, while the same operation is again applied uniformly
over the whole graph. Note that in contrast to recursive networks, a diﬀerent parameterization is
typically used at each layer.

The computation at each layer i can be possibly divided into two steps (Xu et al., 2018a), where
we ﬁrstly aggregate the hidden representations h(u) of the node’s v neighbors u ∈ N (v) to obtain some
activation value as

act(i)(v) = aggregate(i)({h(u)(i−1) : u ∈ N (v)})

and then we combine this activation value with the node’s v own representation h(v), to obtain its
new updated representation to be used in the next layer as

h(i)(v) = combine(i)(h(v)(i−1), act(i)(v))

This general principle covers a wide variety of the proposed GNN models, which then reduces to
the choice of particular “aggregate and combine” operations. For instance in GraphSAGE (Hamilton
et al., 2017), the operations are

act(i)(v) = max{ReLU (W · h(i−1)(u))|u ∈ N (v)}

and

h(i)(v) = Wf · [(h(v)(i−1), act(i)(v)]
while in the popular Graph Convolutional Networks (Kipf and Welling, 2016), these can be even
merged into a single step as

h(i)(v) = ReLU (W · avg{h(i−1)(u)|u ∈ N (v) ∪ {v}})

8We note that modern recurrent architectures use additional computation constructs to store the hidden state, such

as the popular LSTM cells, which are more complex and do not directly follow from the input structure.

9recently more popular in the form of “Graph Convolutional Networks”, which slightly diﬀer from the original GNN

proposal (Scarselli et al., 2008), but share the general principles discussed.

6

and the same generic principle applies to many other GNN works (Xu et al., 2018b; Gilmer et al.,
2017; Xu et al., 2018a).

GNNs can be directly utilized for both graph-level as well as node-level classiﬁcation tasks. For
output prediction on the level of individual nodes, we simply apply some activation function on top
of its last layer representation query(v) = σ(h(v)(n)). For predictions on the level of the whole graph
G, all the node representations need to be aggregated by some pooling operation such as query(G) =
σ(avg{h(n)(v)|v ∈ G}).

By following the same pattern at each layer i, the computation will produce increasingly more
aggregated representations, since at layer i each node eﬀectively aggregates representations from its
“i-hops” neighborhood. Intuitively, the GNN inference can thus be seen as a continuous version of
the popular Weisfeiler-Lehman algorithm (Weisfeiler, 2006) for calculating graph ﬁngerprints used for
refutation checking in graph isomorphism testing.

A large number of diﬀerent variants of the original GNNs (Scarselli et al., 2008) have been proposed,
recently achieving state-of-the-art empirical performance in many tasks (Wu et al., 2019; Zhou et al.,
2018).
In essence, each introduced GNN variant came up with a certain combination of common
activation and aggregation functions, and/or proposed extending the architecture with additional
connections (Xu et al., 2018b) or layers borrowed from other neural architectures (Veliˇckovi´c et al.,
2017; Li et al., 2015), nevertheless they all share the same introduced idea of successive aggregation
of node representations. For a general overview, we refer to (Wu et al., 2020; Zhou et al., 2018).

Spectral GNNs: Here we discussed “spatially” represented graphs and operations. However, some
GNN approaches represent the graphs and the convolution operation in spectral, Fourier-domain (Wu
et al., 2020). There the update operation is typically conveyed in the matrix form as

H (i) = f ( ˆA × H (i−1) × Wi−1)

where ˆA is an altered10 adjacency matrix of the graph, encoding the respective neighborhoods, H (i)
contains the successive hidden node representations at layer i, and Wi are the learnable parameters at
each layer. However we note that, not considering the speciﬁc normalizations and approximations used,
these again follow the same “aggregate and combine” principles, and can be rewritten accordingly (Xu
et al., 2018a). While theoretically substantiated in graph signal processing, spectral GNN models
are generally inadvisable as they introduce substantial limitations in terms of eﬃciency, learning,
generality, and ﬂexibility (Wu et al., 2020), and we do not consider them further in this paper.

Knowledge Base Embeddings: Knowledge Base Embeddings (KBEs) are a set of approaches
designed for the task of knowledge base completion (KBC) (Kadlec et al., 2017), i.e. predicting existing
(missing) edges in large knowledge graphs. Particularly, these methods approach the task through
learning of a distributed representation (embedding) for the nodes.
In multi-relational graphs, a
representation of the edge (relation) can also be added, forming a commonly used triplet representation
of (object, relation, subject). To predict the probability of a given edge in the knowledge graph, KBEs
then choose one of a plethora of functions designed to combine 11 the three embeddings from the
underlying triplet (Kadlec et al., 2017).

10e.g. ˆA = D− 1

2 (A + I)D− 1

2 , where D is the diagonal node-degree matrix and I is an identity matrix, such as in the

original Graph Convolutional Networks (Kipf and Welling, 2016).

11Note that there is no need for the “aggregate” operation in KBEs.

7

3 The Language of Lifted Relational Neural Networks

In this paper we follow up on the work of Lifted Relational Neural Networks (LRNNs) (Sourek et al.,
2015) which have been introduced as a framework for templated modeling of diverse neural architec-
tures oriented to relational data. It can be understood as a diﬀerentiable version of simple Datalog
programming, where the templates, encoding various neuro-relational architectures, take the form of
parameterized logic programs. It diﬀers from the commonly used frameworks, such as PyTorch or
Tensorﬂow, in its declarative, relational nature, enabling one to abstract away from the procedural
details of the underlying computational graphs even further. We explain principles of this abstraction
in the following subsections.

3.1 Syntax: Weighted Logic Programs

The syntax of LRNNs is derived directly from the Datalog (Unman, 1989) language (Section 2.1),
which we further extend with numerical parameters. Note that this has been exploited in many
previous works, where the parameters can signify values associated with facts (Bistarelli et al., 2008)
or rules (Eisner and Filardo, 2010). Such extensions are typically designed to integrate standard
statistical (or probabilistic (De Raedt et al., 2007)) modelling techniques with the high expressiveness
of relational representation and reasoning. In this work we seek to integrate Datalog with deep learning,
for which we allow each literal in each clause of the logic program to be associated with a tensor weight.
A parameterized program, formed by a multitude of such weighted rules, then declaratively encodes
all computations to be performed in a given learning scenario. For clarity of correspondence with
standard (neural) learning scenarios, we here further split12 the program into unit clauses (facts),
constituting the learning examples, and deﬁnite clauses (rules), constituting the learning template.

3.1.1 Learning Examples

The learning examples contain factual description of a given world. For their representation we use
weighted ground facts. A learning example is then a set E = {(V1, e1), . . . , (Vj, ej)}, where each Vi is
a real-valued tensor and each ei is a ground fact, i.e. expression of the form

1 V1 : : p1(c1
2 . . .
3 Vj : : pn(cn

1, . . . , c1

q) .

1 , . . . , cn

r ) .

where p1, . . . , pn are predicates with corresponding arities q, . . . , r, and cj
i are arbitrary constants.
Standard logical representation is then a special case where each Vi = 113. One can either write
1::carbon(c1) or ommit the weight and write bond(c1, o2). The values do not have to be binary
and can represent a “degree of truth” to which a certain fact holds, such as 0.4::aromatic(c1).
The values are also not necessarily restricted to (0, 1), and can thus naturally represent numerical
features, such as 6::atomicN umber(c1) or 2.35::ionEnergy(c1, level2). Finally the values are not
necessarily restricted to scalars, and can thus have the form of feature vectors (tensors), such as
[1.0, −7, . . . , 3.14]::f eatures(c1).

Ground facts in examples are also not restricted to unary predicates, and can thus describe
not only properties of individual objects, but values of arbitrary relational properties. For exam-

12Note that this split is not necessary in general, and the template can also contain facts, as well as the learning

examples may contain rules, such as in ILP learning scenarios.

13Since we consider a close world assumption (CWA) and least Herbrand model, one does not enumerate false facts

with zero value.

8

ple, one can assign feature values to edges in graphs, such as describing a bond between two atoms
[2.7, −1]::bond(c1, o2).

There is no syntactical restriction on how these representations can be mixed together, and one
can thus select which parts of the data are better modelled with (sub-symbolic) distributed numerical
representations, and which parts yield themselves to be represented by purely logical means, and move
continuously along this dimension as needed.

Query: Queries (q) (Sec. 2.1.1) represent the classiﬁcation labels or regression targets associated
with an example for supervised learning. They again utilize the same weighted fact representation
such as 1::class or 4.7::target(c1). Note that the target queries again do not have to be unary, and
one can thus use the same format for diﬀerent tasks. For example, for knowledge graph completion,
we would use queries such as 1.0::coworker(alice, bob).

3.1.2 Learning Template

The weighted logic programs written in LRNNs are then often referred to as templates. Syntactically,
a learning template T is a set of weighted rules T = {αi, {W αi
k, bk)}
where each αi is a deﬁnite clause and each Wj is some real-valued tensor, i.e. expressions of the form

j }} = {(W i, c) ← (W i

1, b1), . . . , (W i

1 W1 : : h1
2 W2 : : h2
3 . . .
4 Wn : : hq

1 ( . . . ) :- W1
1 ( . . . ) :- W2

1 : b1
1 : b2

1 ( . . . ) ,
1 ( . . . ) ,

p ( . . . ) :- Wn

1 : bn

1 ( . . . ) ,

. . .
. . .

, W1
: b1
j
, W2
k : b2

i ( . . . ) .
j ( . . . ) .

. . .

, Wn
l

: bn

k ( . . . ) .

where hj
the associated tensors (also possibly reused in diﬀerent places).

i ’s are predicates forming positive, not necessarily diﬀerent, literals, and Wj

i ’s and bj

i’s are

The template constitutes roughly what neural architecture means in deep learning14 – i.e. it does
not (necessarily) encode a particular model or knowledge of the problem, but rather a generic mode
of computation.

Example 1 Consider a simple template for learning with molecular data, encoding a generic idea that
the representation of a (chemical) atom (e.g. h(h1)) is dependent on the representation of the atoms
adjacent to it. Given that a molecule can be represented by describing the contained atoms (e.g. a(h1))
and bonds between them (e.g. b(h1, o1)), we can intuitively encode this idea by a following rule

1 Wh1

: : h (X) :- Wa : a (Y), Wb : b ( X,Y ) .

Moreover, one might be interested in using the representation of all atoms (h(X)) for deducing the
representation of the whole molecule, for which we can write

1 Wq : : q :- Wh2

: h (X) .

to derive a single ground query atom (q), which can be associated with the learning target of the whole
molecule. The concrete semantics of this template then follows in the next section.

14We deliberately refrain from using the common term of neural “model”, since a single template can have multiple

logical (and neural) models.

9

Table 1: Correspondence between the logical ground model and computation graph.

Type of node
Logical construct
Notation
Atom node
Ground atom h
Ah
Ground fact h
Fact node
F(h, (cid:126)w)
Rcθ
Ground rule’s αθ body Rule node
(W c
Rule’s α ground head h Aggregation node Gh=cθi
(W c

0 cθ←W α

1 b1θ∧···∧W α

k bkθ)

0 c←W α

1 b1∧···∧W α

k bk)

3.2 Semantics: Computational Graphs Deﬁned by LRNNs

To explain the correspondence between a relational template T and a “neural architecture”, we now
describe the mapping that takes the template and a given example description, consisting of ground
facts, and produces a standard neural model. Here, “standard neural model” refers to a speciﬁc
diﬀerentiable computational graph.

First, let Nl be the set of rules and facts obtained from the template and a learning example Nl =
T ∪El by removing all the tensor weights. For instance, if we had a weighted rule W ::h :- W1:b1, W2:b2
, we would obtain h :- b1, b2. Then we construct the least Herbrand model Nl of Nl, which can
be done using standard theorem proving techniques. One simple option is to employ a bottom-up
grounding strategy by repeated application of the immediate consequence operator (Section 2.1)15.
For consequent neural learning, the target query atom q associated with El must be logically entailed
by Nl, i.e. present in Nl

16.

Having the least Herbrand model Nl containing q, we can directly construct a neural computational
graph Gl.
Intuitively, the structure of the graph contains all the logical derivations of the target
query literal q from the example evidence El through the template T . Now we formally deﬁne the
transformation mapping from Nl to a computational graph:

• For each weighted ground fact (Vi, e) occurring directly in El, there is a node F(Vi,e) in the

computational graph, called a fact node.

• For each ground atom h occurring in N \ El, there is a node Ah in the computational graph,

called an atom node.

• For every rule c ← b1 ∧ · · · ∧ bk ∈ T and every grounding substitution cθ = h ∈ N , there is a

node Gcθ=h

(c←b1∧···∧bk) in the computational graph, called an aggregation node.

• For every ground rule αiθ = (cθ ← b1θ ∧ · · · ∧ bkθ) ∈ N , there is a node R(cθ←b1θ∧···∧bkθ) in the

computational graph, called a rule node.

An overview of the correspondence between the logical and the neural model, together with the

used notation is reviewed in Table 1.

The nodes of the computational graph that we deﬁned above are then interconnected so as to
follow the derivation of the logical facts by the immediate consequence operator starting from El, i.e.
starting from the fact nodes F(Vi,e) which have no antecedent inputs in the computational graph and
simply output their associated values out(F(Vi,e)) = Vi. The fact nodes are then connected into rule
nodes Rαθ, particularly a node F(Vi,e) will be connected into every node Rαθ = R(cθ←b1θ∧···∧bkθ) where

15Another option is backward-chaining of the rules back from the associated query atom (q) through T into El. Note
that this choice is purely technical and, following proper logical inference in both cases, does not aﬀect the resulting
logical (or neural) model.

16Otherwise it is automatically considered false (or having a default value) via CWA.

10

template: α1 : Wh1 :: h(X) :- Wa : a(Y) , Wb : b(X,Y) .

α2 : Wq :: q :- Wh2 : h(X) .

sample 1:

b(o1, h1)

b(h1, o1)

H1

a(o1)

O1

a(h1)
a(h2)

b(o1, h2)

H2

b(h2, o1)

sample 2:

b(h1, h2)

H1

a(h2)

a(h1)

H2

b(h2, h1)

Fact nodes

b(o1, h1)

b(h1, o1)

a(h1)

a(o1)

a(h2)

Wb

Wa

Wa

Wa

Wa

Wb

Rule nodes

Wb

Rh(h1)
α1θ1

[X/h1, Y /o1]

∧

Rh(o1)
α1θ2

[X/o1, Y /h1]

∧

Rh(o1)
α1θ3

[X/o1, Y /h2]

∧

Rh(h2)
α1θ4

[X/h2, Y /o1]

∧

b(o1, h2)

b(h2, o1)

Wb

Aggregation nodes

Atom nodes

Rule nodes

Gh(h1)
[X/h1]
α1
∗

Gh(o1)
[X/o1]
α1
∗

Gh(h2)
[X/h2]
α1
∗

Wh1

Wh1

Wh1

Ah(h1)
∨

Ah(o1)
∨

Ah(h2)
∨

Wh2

Wh2

Wh2

Rq

α2θ5

[X/h1]
∧

Aggregation nodes

Atom nodes

Gq

α2[∅]
∗

Wq

Aq
∨

Rq

α2θ6

[X/o1]
∧

Rq

α2θ7

[X/h2]
∧

Fact nodes

b(h1, h2)

a(h2)

a(h1)

b(h2, h1)

Wb

Wa

Wa

Wb

Rule nodes

Aggregation nodes

Atom nodes

Rule nodes

Rh(h1)
α1θ1

[X/h1, Y /h2]

∧

Gh(h1)
[X/h1]
α1
∗

Rh(h2)
α1θ2

[X/h2, Y /h1]

∧

Gh(h2)
[X/h2]
α1
∗

Wh1

Wh1

Ah(h1)
∨

Ah(h2)
∨

Wh2

Wh2

Rq

α2θ3

[X/h1]
∧

Rq

α2θ4

[X/h2]
∧

Aggregation nodes

Atom nodes

Gq

α2[∅]
∗

Wq

Aq
∨

Figure 1: A simple LRNN template with 2 rules described in Example 1. Upon receiving 2 example
molecules, 2 neural computation graphs get created, as prescribed by the semantics (Section 3.2).

e = biθ for some i. Having all the inputs, corresponding to the body literals of the associated ground
rule, connected, the rule node will output a value calculated as

out(Rαθ) = g∧

(cid:0)W α

1 · out(F(V1,b1θ)), . . . , W α

k · out(F(Vi,bkθ))(cid:1).

The rule node’s activation function g∧ is up to user’s choice. For scalar inputs, it can be for example set
to mimic conjunction from Lukasiewicz logic, as in our previous work (Sourek et al., 2018). However,
one can also choose to ignore the fuzzy-logical interpretation and use completely distributed semantics
and activations utilized commonly in deep learning. In this case the computation follows the common
(matrix) calculus by ﬁrstly aggregating the node’s input values into its activation value

act(Rαθ)
(1×l)

= W α
1
(l×n)

· out(F1)
(1×n)

+ · · · + W α
j
(l×m)

· out(Fk)
(1×m)

,

followed by an element-wise application of any diﬀerentiable function, such as logistic sigmoid

out(Rαθ)
(1×l)

= σ(act(Rαθ)

) = σ(cid:0)act(Rαθ)1), . . . , σ(act(Rαθ)l

(cid:1).

(1×l)

The rule nodes are then connected into aggregation nodes. Particularly, a rule node R(cθ←b1θ∧···∧bkθ)
is connected into the aggregation node Gcθ=h
(c←b1∧···∧bk) that corresponds to the same ground head literal
cθ. Having all the inputs, corresponding to diﬀerent grounding substitutions θi of the rule c ←
(b1 ∧ · · · ∧ bk) with the same ground head h = cθ1 = · · · = cθq, connected, the aggregation node will
output the value

out(Gc

αθ = h) = g∗

(cid:0)out(Rcθ1=h

αθ1

), . . . , out(Rcθq=h

αθq

)(cid:1).

11

where g∗ is some aggregation function, such as avg or max. The aggregation nodes eﬀectively aggregate
all the diﬀerent ways by which a literal h can be derived from a single rule α. Their semantic intuitively
corresponds to a certain quantiﬁcation over free variables appearing solely in the rule’s α body. The
aggregation g∗ is then applied in each dimension of the input values as

out(Gh
α)
1×l

= g∗(out(R1)

, . . . , out(Rq)

) =

1×l

1×l

(cid:16)

(cid:0)out(R1)1, . . . , out(Rq)1(cid:1), . . . ,

g∗

. . . , g∗

(cid:0)out(R1)l, . . . , out(Rq)l(cid:1)(cid:17)

.

The aggregation nodes are then connected into atom nodes. In particular, an aggregation node Gh
α
will be connected into the atom node Ah that is associated with the same atom h. The inputs of the
atom node represent all the possible rules αi through which the same atom h can be derived. Having
them all connected, Ah will output the value

out(Ah) = g∨

(cid:0)W c

1 · out(Gh

α1), . . . , W c

m · out(Gh

αm)(cid:1).

Apart from the choice of activation function g∨, the computation of the atom node’s output follows
exactly the same scheme as for the rule nodes.

Finally, the atom nodes are connected into rule nodes in exactly the same fashion as fact nodes,
i.e. Ah will be connected into every R(cθ←b1θ∧···∧bkθ) where h = biθ for some i, and the whole process
continues recursively.

Example 2 Let us follow up on the Example 1 by extending the described template with two example
molecules of hydrogen and water. The template will then be used to dynamically unfold two computation
graphs, one for each molecule, as depicted in Figure 1. Note that the computation graphs have diﬀerent
structures, following from the diﬀerent Herbrand models derived from each molecule’s facts, but share
parameters in a scheme determined by the lifted structure of the joint template.

4 Examples of Common Neural Architectures

We demonstrate ﬂexibility of the declarative LRNN templating, stemming from the abstraction power
of Datalog, by encoding a variety of common neural architectures in very simple diﬀerentiable logic
programs. For completeness, we start from simple neural models, where the advantages of templating
are not so apparent, but continue to advanced deep learning architectures, where the expressiveness
of relational templating stands out more clearly. Note that all templates in this paper are actual
programs that can be run and trained with the LRNN interpreter.

4.1 Feed-forward Neural Networks

Multi-layer perceptrons (MLPs) form the most simple case where the weighted logic template is
restricted to propositional clauses, and its single Herbrand model thus directly corresponds to a single
neural model (Section 3.2). In this setting, the input example information can thus be encoded merely
in the values of their associated tensors, which is the standard deep learning scenario. In the vector
form, we can associate each example Ei with a fact proposition [vi
n]::f eatures(0), forming the
input (0-th) node of the neural model. Each example is further associated with a query vi

1, . . . , vi

q::q.

In particular, an MLP with 3 layers, i.e. input layer(0), 1 hidden layer(1), and output layer(2), with

the corresponding weight matrices [ W
m×n

(1), W
1×m

(2)] can be directly modelled with the following rule

(2)

1 W
1×m

: : q(2) :- W

m×n

(1)

:

f e a t u r e s (0) .

12

Ff,v

Rh1
α1θ

Gh1
α1

Ah1

W1

Rh2
α2θ

Gh2
α2

Ah2

W2

→
pruning

Ff,v

Ah1

W1

W2

Ah2

Figure 2: Demonstration of the pruning technique on a sample MLP model unfolded from a 2-rule
template of α1 = W1::h1:-f. and α2 = W2::h2:-h1.

Naturally, we can extend it to a deeper MLP by stacking more rules as

(2)

1 W
r×m

2 . . .
3 W
1×s

(k)

: : hidden (2) :- W

m×n

(1)

:

f e a t u r e s (0) .

: : q(k) :- W

s×r

(k−1)

: hidden (k−2) .

Once the template gets transformed into the corresponding neural model (Sec. 3.2), its computation
graph will consist of a linear chain of nodes (Sec. 2.2.1) corresponding to standard fully-connected
layers 1, . . . , k with associated weight matrices [W (1), W (2) . . . , W (k)], and activation functions of user’s
choice.

Note that not all the weights need to be speciﬁed, and one can thus also write, e.g., either of

1 W : : h(2) :- h(0) .

h(2) :- W : h(0) .

While each of these rules still encodes in essence a 3-layer MLP, either only the hidden (right) or only
the output (left) layer will carry learnable parameters, respectively. Moreover, following the exact
semantics (Sec 3.2) for neural model creation, an aggregation node will be created on top of a rule
node, representing the hidden layer. Since there is no need for aggregation in MLPs, i.e. only a single
rule node ever gets created from each propositional rule, this introduces unnecessary operations in
the graph. Since such nodes arguably do not improve learning of the model, we prune them out, as
depicted in Figure 2. The technique is further described in more detail in Section A.1.1. Note that we
assume application of pruning, where applicable, in the remaining examples described in this paper.

4.1.1 Knowledge-based Artiﬁcial Neural Networks

The direct correspondence between a propositional program and a neural network has been successfully
exploited in a number of previous works, particularly the original Knowledge-Based Artiﬁcial Neural
Networks (KBANN) (Towell et al., 1990), and LRNNs can be seen as a direct extension of KBANN
into relational setting. To emulate the KBANN inference and learning, we simply fall back to scalar
representation of features, e.g. 0::rain, 0.6::wet, 0.8::sunny, and consider a propositional template
encoding some background domain knowledge, such as sprinkle :- wet , sunny. One then needs
to choose a set of proper activation functions based on desired multi-valued logic semantics, e.g. the
Lukasiewicz’s fuzzy operators (Towell et al., 1990; Sourek et al., 2018). Note that, choosing proper
fuzzy logic activations, this still covers standard logical inference as a special case with the use of
binary fact values.

4.2 Convolutional Neural Networks

The CNNs can no longer be represented with a propositional template. To emulate the additional
parts w.r.t.
the convolutional ﬁlters and pooling (Sec. 2.2), we need to move to
relational rules (Sec. 2.1). Note that there is a natural, close relationship between convolutions and

the MLPs, i.e.

13

Pooling
(avg/max)

pool

Gh
α1

Aggregation
node

Filter-map
(convolution)

Features
(pixels)

wl

f 1

v1

h1

wm

wl

f 2

v2

h2

wm

wr

wl

f 3

v3

h3

wm

wr

f 4

v4

wr

f 5

v5

Rh

α1θ1

Rh

α1θ2

wl

Ff (1)

wm

wl

Ff (2)

wm

wr

wl

Ff (3)

Rh

α1θ3

wm

wr

Ff (4)

Rule
nodes

wr

Ff (5)

Fact
nodes

v1::f (1)

v2::f (2)

v3::f (3)
next(1, 2) next(2, 3) next(3, 4) next(4, 5)

v4::f (4)

v5::f (5)

image I as a vector of pixel values

image I as a set of weighted facts

Figure 3: Left: core part of a standard CNN architecture with sparse layer composed of sequential
applications of a convolutional ﬁlter (h), creating a feature-map layer, followed by a pooling operator.
Right: the corresponding computation graph derived from a LRNN template.

relational rules (or relational patterns in general), where the point of both is to exploit symmetries in
data. Moreover, the point of both the aggregation nodes and the pooling layers is to enforce certain
transformation invariance. Let us demonstrate this relationship with the following example.

For clarity of presentation, consider a simplistic one-dimensional “image” consisting of 5 pixels
i = 1, ..., 5. While the regular grid structure of the image pixels is inherently assumed in CNN, we
will need to encode it explicitly. Considering the 1-dimensional case, it is enough to deﬁne a linear
ordering of the pixels such as next(1, 2), . . . , next(4, 5). The (gray-scale) value vi of each pixel i can
then be encoded by a corresponding weighted fact vi:f (i). Next we encode a convolution ﬁlter of size
[1, 3], i.e. vector which combines the values of each three ([left,middle,right]) consecutive pixels, and
a (max/avg)-pooling layer that aggregates all the resulting values. This computation can be encoded
using the following template

1 h :- wl :

f (A), wm :

f (B), wr :

f (C), next ( A,B ), next ( B,C ) .

A visualization of the CNN and the corresponding computation graph derived from the logic model
of the template presented with some example pixel values [v1, . . . , v5] is shown in Fig 3.

While this does not seem like a convenient way to represent learning with CNNs from images,
the important insight is that convolutions in neural networks correspond to weighted relational rules
(patterns). The eﬃciency of normal CNN encoding is due to the inherent assumptions that are present
in CNNs w.r.t. topology of their application domain, i.e. grids of pixel values, and similarly complete,
ordered structures. While with LRNNs we need to state all these assumptions explicitly, it also means
that we are not restricted to them – an advantage which will become clearer in the subsequent sections.

4.3 Recursive and Recurrent Neural Networks

A recursive network also exploits the principle of convolution, however the input is no longer a grid
but a regular tree of an unknown structure. This prevents us from creating computation schemes
customized to a speciﬁc structure, as in the CNNs. Instead, we need to resort to a general convolutional
pattern that can be applied over any k-regular tree.

For that purpose, we again utilize the expressiveness of relational logic. Firstly, we encode the
k-regular tree structure itself by providing a fact connecting each parent node in the tree to its child-

14

Ff (1)

Ff (2)

. . .

Ff (k)

Wf

Wf

Wf

Ah(0)

Rh(1)
α1

Wh

Wh

Rh(2)
α1

. . .
Wh

Rh(k)
α1

. . .

F(0)
n(1)

F(0)
n(2)

F(0)
n(3)

. . .

Rn(j)(1)
α1

W1

W2

W3

Rn(i)(d−1)
α1

. . .

W1

W2

Rn(j)(d)
α1

W3

Rn(k)(d−1)
α1

Figure 4: Simple recurrent (left) and recursive (right) neural structures encoded through LRNNs.

nodes, i.e. parent(nodei+1
, nodei
with their embedding vectors [vi
to encode the recursive composition of representations in the, for instance 3-regular, tree as

l+k). Secondly, we associate all the leaf nodes in the tree
n]::n(leafi). Finally, a single relational rule can then be used

l, . . . , nodei
1, . . . , vi

j

1 n (P) :- W1 : n (C1 ), W2 : n (C3 ), W3 : n (C3 ), p a r e n t ( P,C1 ,C 2 ,C 3 ) .

which directly forms the whole learning template. Given a particular example tree, this rule translates
to a computation graph recursively combining the children node representations (n(C)) into respective
parent node representations, until the root node is reached. The root node representation (n(root))
could then be fed into a standard MLP rule (Sec. 4.1) to output the value for a given target query
associated with the whole tree example.

A simple recurrent neural network unfolded over a linear (time) structure can then be modelled
in a simpler manner, where only a single (vector) input is given at each step and a linear chain of
hidden nodes (h(X)) replaces the prescribed tree hierarchy. Assuming encoding of the linear example
structure with predicate next(X, Y ) as before, such a model can then be written as

1 h (Y) :- Wf : f (Y), Wh : h (X), next ( X,Y ) .

The ﬁnal hidden representation (h(k)) could then again be fed into a MLP for a whole sequence-level
prediction. Neural architectures of both these templated models are displayed in Figure 4.

5 Graph Neural Networks in LRNNs

Graph (convolutional) Neural Networks (GNNs) (Sec. 2.3) can be seen as a generalization of the intro-
duced neural architectures (Section 4) to arbitrary graphs, for which they combine the ideas of latent
representation learning (Sec. 4.1), convolution (Sec. 4.2), and dynamic model structure (Sec. 4.3).

While modelling CNNs in the weighted logic formalism was somewhat cumbersome (because we
had to explicitly represent the pixel grid), the encoding of GNNs is very straightforward. This is due
to the underlying general graph representation with no additional assumptions of its structure, which

15

Fn4

W2

R4
1

G4

W1 W1

Fn1

R1
4

R1
2

R1
3

A(1)

h(n4)

G1

W2

A(1)

h(n1)

Fn2

W1 W1

Fn3

W2
W1

W1

R2
1

R2
3

G2

A(1)

h(n2)

W1

W2

R3
1

R3
2

G3

. . .

A(n)

h(n4)

. . .
. . .

. . .

. . .
. . .

. . .

. . .

A(1)

h(n3)

. . .
. . .

A(n)

h(n2)

. . .

A(n)

h(n1)

Gq
αn

Aq

W (n)

A(n)

h(n3)

Figure 5: A computation graph of a sample (g-SAGE) GNN as encoded in LRNNs. Given an input
graph of 4 (fact) nodes (Fn1 . . . Fn4), neighbors of each node are ﬁrstly weighted and aggregated with
rule and aggregation nodes, respectively (reduced in size in picture). The result is then combined
with representation of the (central) node from the preceding layer, to form a new layer of 4 atom
nodes, copying the structure of the input graph. After n such layers, each with the same structure
but diﬀerent parameters, a global readout (aggregation) node aggregates all the node representations,
passing to the ﬁnal query (atom) node’s transformation.

yields itself very naturally to relational logic. The computation of the layer i update in GNNs can
then be represented by a single rule as follows

1 W(i) : : h(i) (V) :- h(i−1) (U), edge ( V,U ) .

where edge/2 is the binary relation of the given input graphs. With the choice of activation functions as
g∗ = avg, g∧ = ReLU , this simple rule can be already used to model the popular Graph Convolutional
Neural Networks (GCN) (Kipf and Welling, 2016)17. The exact same rule (up to parameterization)
is then used at each layer. For the ﬁnal output query (q) representing the whole graph we simply
aggregate representations of all the nodes as

1 W(d) : : q :- h(d−1) (U) .

A noticeable shortcoming of GCNs is that the representation of the “central” node (V) itself is not
used in the representation update. While this can be done by extending the graph (edge/2) with
self-loops, a novel18 GNN model called GraphSAGE (g-SAGE) (Hamilton et al., 2017) was proposed
to address this explicitly. To follow the architecture of g-SAGE, we thus split the template into 2 rules
accordingly

1 h(i) (V) :- W(i)
2 h(i) (V) :- W(i)

1 : h(i−1) (U), edge ( V,U ) .
2 : h(i−1) (V) .

and choose g∧ = ReLU, g∗ = max, g∨ = identity for the very model (g-SAGE), the depiction of which
can be seen in Figure 5.

17where the authors also denoted the rule as convolution, since it forms a linear approximation of a localized spectral

convolution (Kipf and Welling, 2016).

18Note that, diﬀerently from GCN with self-loops, the central node is parameterized diﬀerently from the neighbors.

16

Another popular extension taken from neural architectures for image recognition are residual (skip)
connections, where one eﬀectively adds links to preceding layers at arbitrary depth (instead of just
the preceding layer), i.e. we simply add one or more rules in the form

1 W(i)

skip : : h(i) (V) :- h(i−skip) (V) .

This technique is also used in the Graph Isomorphism Network (GIN) (Xu et al., 2018a), which
is a theoretically substantiated GNN based on the expressive power of the Weisfeiler-Lehman test
(WL) (Weisfeiler, 2006). Firstly, the GIN model diﬀers in that it adds residual connections from all
the preceding layers to the ﬁnal layer (which the authors refer to as “jumping knowledge” (Xu et al.,
2018b)). Secondly, the particularity of GIN is to add a 2-layered MLP on top of each aggregation
to harvest its universal approximation power. Particularly, update formula derived from the WL-
correspondence (Xu et al., 2018a) is

h(i)(v) = M LP (i)(cid:0)(1 + (cid:15)(i−1)) · h(i−1)(v) +

(cid:88)

h(i−1)(u)(cid:1)

u∈N (v)

where M LP is the 2-layered MLP (Sec. 2.2.1). To accommodate the extra MLP layer, we thus extend
the template as follows

1 mlp(i)
2 mlp(i)
3 W(i)
2

tmp (V) :- h (U) (i−1), edge ( V,U ) .
tmp (V) :-

(1 + (cid:15)(i−1)) : h(i−1) (V) .
1 : mlp(i)
tmp (V) .

: : h(i) (V) :- W(i)

Note that, considering that such a single rule actually already models a 2-layer19 MLP (as described
in Sec. 4.1), a very similar computation can be carried out more simply with

1 W(i)
2 W(i)

2a : : h(i) (V) :- W(i)
2b : : h(i) (V) :- W(i)

1a : h (U) (i−1), edge ( V,U ) .
1b : h(i−1) (V) .

corresponding to a GIN version without the special (1 + (cid:15)(i)) coeﬃcient, which the authors refer to as
“GIN-0” (Xu et al., 2018a) and actually ﬁnd performing better20. Finally they choose g∗ = sum as
the function to aggregate the neighborhood representations. The authors proved the GIN model to
belong to the most “powerful” class of GNN models, i.e. no other GNN model is more expressive than
GIN, and demonstrated the GIN-0 model to provide state-of-the-art performance in various graph
classiﬁcation and completion tasks (Xu et al., 2018a).

5.1 Extending GNNs

While the GIN model presents the most “powerful” version of the basic GNN idea, there is a large
number of ways in which the GNN approach can be extended. We discuss some of the direct, natural
extensions in this subsection.

19or 3-layer, depending on inclusion of the input layer in the count.
20We note there is a slight diﬀerence, where GIN-0 ﬁrstly aggregates the neighbors and weights the result, while
this template aggregates the neighbors after weighting. Nevertheless we note that GNN authors often switch this order
themselves, for instance GraphSAGE in (Dwivedi et al., 2020) performs weighting before aggregation, while it is vice-versa
in (Xu et al., 2018a).

17

5.1.1 Edge Representations

Originally aimed at single-relation graphs, GNNs do not adequately utilize the information about the
possibly diﬀerent types of edges. While it is straightforward to associate edges with scalar weights in
the adjacency matrix, instead of using just binary edge indicators (Kipf and Welling, 2016), extending
to richer edge representations is not so direct, and has only been explored recently (Kipf et al., 2018;
Gong and Cheng, 2019; Kim et al., 2019).

In the templating approach, addressing edges is very simple, since we do not operate directly on
the graph but on the ground logical model, where each edge (edge(n1, n2)) forms an atom in exactly
the same way as the actual nodes (node(n1)) in the graph itself (similarly to an extra transformation
introduced in line-GNNs (Chen et al., 2017)). We can thus directly associate edges corresponding to
diﬀerent relations with arbitrary features ([v1, . . . , vn]:: edge(n1, n2)), learn their distributed repre-
sentations, and predict their properties (or existence), just like GNNs do with the nodes. For basic
learning with edge representations, there is no need to change anything in the previously introduced
templates. However, one might want to associate extra transformations for edge and node represen-
tation learning (Gong and Cheng, 2019), in which case we would simply write

1 W(i)

: : h(i) (V) :- h (U) (i−1), We : edge ( V,U ) .

A large number of structured data then come in the form of multi-relational graphs, where the edges
can take on diﬀerent types. A straightforward extension is to learn a separate node representation of
the nodes for each of the relations, e.g. as

1 W(i)

: : h(i)

x (V) :- hx (U) (i−1), We : edge type=x ( V,U ) .

and to choose from the diﬀerent representations depending on context, such as in multi-sense word
embeddings (Li and Jurafsky, 2015), or simply directly combine (Schlichtkrull et al., 2018) these
representations in the template.

5.1.2 Heterogeneous Graphs

The majority of current GNNs then assume homogeneous graphs, and learning from heterogeneous
graphs has just been marked as one of the future directions for GNNs (Wu et al., 2020). In LRNNs,
various heterogeneous graphs (Wang et al., 2019b) can be directly covered without any modiﬁcation,
since there is no restriction to the types of nodes and relations to be used in the same template (and
so we do not have to e.g. split the graphs (Zhu et al., 2019) or perform any extra operation (Liu et al.,
2018) for such a task). In the context of heterogeneous information networks, a similar “templating”
idea has already become popular as deﬁning “meta-paths” (Dong et al., 2017; Huang and Mamoulis,
2017), which can be directly covered by a single LRNN rule and, importantly, diﬀerentiated through.
We can further represent the relations as actual objects to be operated by logical means, by reifying

them into logical constants as

1 W(i)
1

: : h(i) (V) :- h (U) (i−1), h (E) (i−1), edge ( V,U,E ) .

where variable E represents the edge object and h(E) is its hidden representation. The learned em-
beddings of the nodes and relations can then be directly used for predicting triplets of
(Object,Relation,Subject) in KBC, again with a simple template extension, e.g.
KBE (Dong et al., 2014), as

for an MLP-based

1 W : : edge ( O,R,S ) :- Wo : h (O), Wr : h (R), Ws : h ( S ) .

18

5.1.3 Hypergraphs

Naturally, the GNN idea can be extended to hypergraphs, too, as was recently also proposed (Feng
et al., 2019). While extending to hypergraphs from the adjacency matrix form used for simple graphs
can be somewhat cumbersome, in the relational Datalog, hypergraphs are ﬁrst-class citizens, so we
can just directly write

1 W(i)
1
2 . . .
3 W(i)
1

: : h(i) (U1 ) :- h (U1 ) (i−1) , . . . , h (Un)(i−1) , edge ( U1, . . . , Un ) .

: : h(i) (Un ) :- h (U1 ) (i−1) , . . . , h (Un)(i−1) , edge ( U1, . . . , Un ) .

and possibly combine with all the other extensions.

There are many other simple ways in which GNNs can be extended towards higher expressiveness
and there is a wide variety of emerging works in this area. While reaching beyond the standard,
single adjacency matrix format, each of the novel extensions typically requires extra transformations
(and libraries) to create their necessary intermediate representations (Chen et al., 2017; Dong et al.,
2017). Many of these extensions are often deemed complex from the graph (GNN) point of view, but
are rather trivial template modiﬁcations with LRNNs, as indicated in the preceding examples (and
following in Sec. 5.2). This is due to the adopted declarative relational abstraction, as opposed to
the procedural manipulations on ground graphs, deﬁned often on a per basis. On the other hand
we note that LRNNs currently cannot cover recent non-isotropic GNNs (Dwivedi et al., 2020) with
computation constructs such as attention, gating, or LSTMs (Wu et al., 2020). While such construct
could be included on an ad-hoc basis, they do not yield themselves naturally to the LRNN semantics.

5.2 Beyond GNN architectures

While we discussed possible ways for direct extensions of GNNs, there are more substantial alterations
that break beyond the core principles of GNNs. One of them is the “message passing” idea, where the
nodes are restricted to “communicate” with neighbors through the existing edges (WL label propaga-
tion (Weisfeiler, 2006)). Obviously, there is no such restriction in LRNNs, and we can design templates
for arbitrary message passing schemes, corresponding to more complex and expressive convolutional
ﬁlters. For instance, consider a simple extension beyond the immediate neighborhood aggregation by
deﬁning edges as weighted paths of length 2 (introduced as “soft edges” in (Sourek et al., 2018)):

1 W : : edge2 (U,W) :- W1 : edge ( U,V ), W2 : edge (V,W) .

We can also easily compose the edges into small subgraph patterns of interest (also known as
“graphlets” or “motifs” used in, e.g., social network analysis (ˇSourek et al., 2013)), such as triangles
and other small cliques (alternatively conveniently representable by the hyper-edges (Sec. 5.1.3)), and
operate on the level of these instead:

1 W : : node (U,V,W) :- W1 : edge ( U,V ), W2 : edge (V,W), W3 : edge(W,U ) .

Since both nodes and edges can be treated uniformly as logic atoms, we can easily alter the GNN
idea to hierarchically propagate latent representations of the edges, too. In other words, each edge
can aggregate representations of “adjacent” edges from previous layers:

1 W : : h(i)

edge (E) :- WF : h(i−1)

edge (F), WU,V : edge ( U,V,E ), WV,W : edge ( V,W,F ) .

19

Naturally, this can be further combined with the standard learning of the latent node representations
(as we do in experiments in Sec. 6).

Moreover, the messages do not have to spread homogeneously through the graph and a custom logic
can drive the diﬀusion scheme. This can be, for instance, naturally put to work in the heterogeneous
graph environments (Sec. 5.1.2) with explicit types, which can then be used to control communication
and representation learning of the nodes:

1 W : : h(i) (X) :- h(i−1) (Y), edge ( X,Y,E ), type ( E , t y p e e

1 ) .

Besides being able to represented the types explicitly as objects (as opposed to the vector em-
beddings), we can actually induce new types, for instance into latent hierarchical categories (such as
in (ˇSourek et al., 2016)):

1 ) .

1 i s a ( edge 1 , t y p e e
2 . . .
3 W(1) : :
4 W(k) : :

i s a ( s u p e r t y p e (1)
i s a ( A,C ) :- W(k−1)

, t y p e e
:

e

1

1 ) .
i s a ( A,B ), W(k−1)

2

:

i s a ( B,C ) .

Importantly, there is no need to directly follow the input graph structure in each layer. We can
completely abstract away from the graph representation in the subsequent layers and reason on the
level of the newly invented, logically derived, entities, such as, e.g., the various graphlets, latent types,
and their combinations:

1 W : : node (1)

motif (T1, T2, T3) :- W1 : n o d e (X), W2 : node (Y), W3 : node ( Z ),

2

3

W4 : ty pe ( X,T1 ), W5 : type ( Y,T2 ), W6 : type ( Z,T3 ),

edge ( X,Y ), edge ( Y,Z ), edge ( X,Z ) .

Finally, the models can be directly extended with external relational background knowledge. Note
that such knowledge can be speciﬁed declaratively, with the same expressiveness as the templates
themselves, since they are consequently simply merged together, for instance:

1 r i n g 6(A, . . . , F ) :- Ve1 : edge ( A,B ), . . . , Ve6 : edge ( F,A ),
Vn1 node (A), . . . , Vn6 node (F) .

2

3 W : : node (n) (X) :- V1 :

r i n g 6(X, . . . , F ) .

Note that this is very diﬀerent from the standard GNNs, where one can only input ground information,
in the form of numerical feature vectors along with the actual nodes (and possibly edges). Nevertheless
this does not mean that LRNNs cannot work with numerical representations. On the contrary, besides
the standard neural means, one can also directly interact with it by the logical means, e.g. by arithmetic
predicates to deﬁne learnable numerical transformations (such as in (Sourek et al., 2018)) over some
given (or learned) node similarities:

1 W : : edge sim (N1 ,N2 ) :- s i m i l a r (N1 ,N2 , S im ), W0.3 : ≥ ( Sim , 0 . 3 ) .

20

6 Experiments

The preceding examples were meant to demonstrate high expressiveness and encoding eﬃciency of
declarative LRNN templating. The main purpose of the experiments is to assess correctness and eﬃ-
ciency of the actual learning. For that purpose, we select GNNs as the most general and ﬂexible of the
commonly used neural architectures, since they encompass building blocks of all the other introduced
architectures. Given the focus on GNNs, we compare against two most popular21 GNN frameworks
of Pytorch Geometric (PyG) (Fey and Lenssen, 2019) and Deep Graph Library (DGL) (Wang et al.,
2019a). Both these frameworks contain reference implementations of many popular GNN models,
which makes them ideal for such a comparison. Note also that both these frameworks are highly con-
temporary and were speciﬁcally designed and optimized for creation and training of GNNs. For clarity
of presentation, we restrict ourselves to a single task of structure property prediction, but perform
experiments across a large number of datasets.

6.1 Modern GNN frameworks

While popular deep learning frameworks such as TensorFlow or Pytorch provide ways for eﬃcient
acceleration of standard neural architectures such as MLPs and CNNs, implementing GNNs is more
challenging due to the irregular, dynamic, and sparse structure of the input graph data. Nevertheless,
following the success of vectorization of the classic neural architectures, both PyG and DGL adopt the
standard (sparse) tensor representation of all the data to leverage vectorized operations upon these.
This includes the graphs themselves, which are then represented by their sparse adjacency matrices Gi
i.
Further, each node index i can be associated with a feature vector ([f1, . . . , fj]i) through an additional
matrix F j

i associated with each input graph.

Following the standard procedural diﬀerentiable programming paradigm, both frameworks then
represent model computations explicitly through a predeﬁned graph of tensor transformations applied
directly to the input graph matrices, creating an updated feature tensor F j(k)
at each step k. The
same tensor transformations are then applied to each input graph.

i

Both frameworks are based on similar ideas of message passing between the nodes (neighborhood
aggregation) and its respective acceleration through optimized sparse tensor operations and batch-
ing (gather-scatter). DGL then seems to support a wider range of operations (and backends), with
high-level optimizations directed towards larger scale data and models (and a larger overhead), while
PyG utilizes more eﬃcient low-level optimizations stemming from its tighter integration with Pytorch.

6.2 Model and Training Correctness

Firstly, we evaluate correctness of the templated GNN architectures via correspondence to their ref-
erence implementations in PyG and DGL. For this we select some of the most popular GNN models
introduced in previous chapters, particularly the original GCN (Kipf and Welling, 2016), highly used
GraphSAGE (g-SAGE) (Hamilton et al., 2017) and the “most powerful” GIN (Xu et al., 2018a) (par-
ticularly GIN-0). Each of the models comes with a slightly diﬀerent aggregate-combine scheme and
particular aggregation/activation functions (detailed in Sections 2.3 and 5). Moreover, we keep orig-
inal GCN and g-SAGE as 2-layered models, while we adopt 5-layers for GIN (as proposed by the
authors)22. We further use the same latent dimension d = 10 for all the weights in all the models.
Finally we set average-pooling operation, followed by a single linear layer, as the ﬁnal graph-level
readout for prediction in each of the models.

21with, as of date, PyG having 7.3K stars and DGL having 4.7K stars on Github, respectively.
22Obviously the number of layers could be increased/equalized for all of the models, however we keep them distinct to

also accentuate their learning diﬀerences further.

21

Figure 6: Alignment of training errors of the 3 models (GCN, g-SAGE, GIN), as implemented in the
3 diﬀerent frameworks (LRNNs, DGL, PyG), over 5 datasets.

While the declarative templating takes a very diﬀerent approach from the procedural GNN frame-
works, for the speciﬁc case of GNN templates it is easy to align their computations, as they are mostly
simple sequential applications of the (i) neighborhood aggregation, (ii) weighting, and (iii) non-linear
activation, which can be covered altogether by a single rule (Section 5)23.

For the comparison, we choose the NCI (Ralaivola et al., 2005) molecular datasets24, each containing
thousands of molecules labeled by their ability to inhibit growth of diﬀerent types of tumors. Note we
only use the basic (Mol2 (Tripos, 2007)) types of atoms and bonds without extra chemical features. For
visual clarity we present results only for the ﬁrst 5 of the total 73 datasets in alphabetical order (while
we note that the results are very similar over the whole set). We use the same 10-fold crossvalidation
splits for all the models. We further use Glorot initialization scheme (Glorot and Bengio, 2010) where
possible, and optimize using ADAM with a learning rate of lr = 1.5e−5 (betas and epsilon kept the
usual defaults) against binary crossentropy over 2000 epochae. Note that some other works propose a
more radical training scheme with lr = 0.01 and exponential decay by 0.5 every 50 epochae (Xu et al.,
2018a), however we ﬁnd GNN training in this setting highly unstable25, and thus unsuitable for the
alignment of the diﬀerent implementations. We then report the actual training errors (as opposed to
accuracy) as the most consistent evaluation metric for the alignment purpose in Figure 6. While it is
very diﬃcult to align the training perfectly due to the underlying stochasticity, we can see that the
performances are tightly aligned within a margin of standard deviation calculated over the folds. The
diﬀerences are generally highest for the most complex GIN model, which also exhibits most unstable
performance over the folds. Importantly, the diﬀerences between LRNNs and the other frameworks
is generally not greater than between PyG and DGL themselves, which both utilize the exact same
PyTorch modules and operations.

23However for a precise correspondence, care must be taken to respect the same order of the (i-iii) operations, which

often varies across diﬀerent reports and implementations.

24available at ftp://ftp.ics.uci.edu/pub/baldig/learning/nci/gi50/
25as is e.g. also visible in the respective Fig.4 reported in (Xu et al., 2018a).

22

Table 2: Training times per epocha across the diﬀerent models and frameworks. Additionally, the
startup model creation time (theorem proving) overhead of LRNNs is displayed.

model/engine
GCN
g-SAGE
GIN

LRNNs (s)
PyG (s)
0.25 ± 0.01
3.24 ± 0.02
3.83 ± 0.04
0.34 ± 0.01
1.41 ± 0.10 11.19 ± 0.06

DGL (s)
23.25 ± 1.94
24.23 ± 3.80
52.04 ± 0.41

LRNNs startup (s)
35.2 ± 1.3
35.4 ± 1.8
75.3 ± 3.2

6.3 Computing Performance

The main aim of the declarative LRNN framework is quick prototyping of models aiming to integrate
deep and relational learning capabilities, for which it generally provides more expressive constructs
than that of GNNs (Section 5) and does not contain any speciﬁc optimizations for computation over
graph data. Additionally, it introduces a startup model compilation overhead as the particular models
are not speciﬁed by the user but rather automatically induced by the theorem prover. Moreover,
it implements the neural training in a rather direct (but ﬂexible) fashion of actual traversal over
each network (such as in Dynet (Neubig et al., 2017)), and does so without batching, eﬃcient tensor
multiplication or GPU support26. Nevertheless, we show that the increased expressiveness does not
come at the cost of computation performance.

We evaluate the training times of a GCN over 10 folds of a single dataset (containing app. 3000
molecules) over the diﬀerent models. We set Pytorch as the DGL backend (to match PyG), and train
on CPU27 with a vanilla SGD (i.e. batch size=1) in all the frameworks. From the results in Table 2,
we see that LRNNs surprisingly train signiﬁcantly faster than PyG, which in turn runs signiﬁcantly
faster than DGL. While the performance edge of PyG over DGL generally agrees with (Fey and
Lenssen, 2019)28, the (app. 10x) edge of LRNN seems unexpected, even accounting for the startup
theorem proving overhead for the model creation (giving PyG a head start of app. 10 epochae). We
account the superior performance of LRNNs to the rather sparse, irregular, small, dynamic graphs
for which the common vectorization techniques, repeatedly transforming the tensors there and back,
often create more overhead than speedup, making it more eﬃcient to traverse the actual spatial graph
representations (Neubig et al., 2017). Additionally, LRNNs are implemented in Java, removing the
Python overhead, and contain some generic novel computation compression (Sourek and Zelezny,
2020) techniques (providing about 3x speedup for the GNN templates).

Note we also prevented the frameworks from batching over several graphs, which they do by
embedding the adjacency matrices into a block-diagonal matrix. While (mini) batching has been
shown to deteriorate model generalization (Masters and Luschi, 2018; Wilson and Martinez, 2003), it
still remains the main source of speedup in deep learning frameworks (Keskar et al., 2016), and is a
highlighted feature of PyG, too. We show the additional PyG speedup gained by batching in Figure 7.
While batching truly boosts the PyG performance signiﬁcantly, it still lacks behind the non-batched
LRNNs29. For illustration, we additionally include an inﬂated version of the GCN model by a 10x
increase of all the tensor dimensionalities. In this setting we can ﬁnally observe a performance edge
from mini-batching, due to vectorization and GPU30, over the non-batched LRNNs31.

26However it is possible to export the networks to be trained by any neural backend rather than the native Java engine.
27We evaluated the training on CPU as in this problem setting the python frameworks run slower on GPU (Figure 7).
28We note that we run both frameworks in default conﬁgurations, and there might be settings in DGL for which it
does not lag behind PyG so rapidly. Note that for the small models of GCN and g-SAGE it is 10x slower, while for the
bigger GIN model only 5x, which is in agreement with DGL’s focus on large scale optimization.

29While LRNNs currently do not support batching natively, it can be emulated by outsourcing the training to Dynet.
30Also note that we used a non-high-end Ge-Force 940m, and the performance boost could thus be even more signiﬁcant.
31On the other hand note that dim = 100 is considerably high. Most implementations we found were in range {8,16,32}

and we did not observe any test performance improvement beyond dim = 5 with the reported datasets and models.

23

Figure 7: Improving the computing performance of PyG via mini-batching and model size blow-up.
The actual GCN model (10 × 10 parameter matrices) and 10x inﬂated version (100 × 100 parameter
matrices) as run on CPU and GPU. Compared to a non-batched (batch=1) LRNN run on CPU.

6.4 Model Generalization

Finally we evaluate learning performances of the diﬀerent models. We select the discussed GNN
models of GCN, g-SAGE and GIN (we keep only the PyG implementation for clarity), and we further
include some example relational templates for demonstration. Particularly, we extend GIN with edge
(bond) representations and associate all literals in all rules with learnable matrices (Sec. 5), denoted
as “gin*”. In a second template we add a layer of graphlets (motifs) of size 3, aggregating jointly
representations of three neighboring nodes, on top of GIN, denoted as “graphlets”. Lastly, we introduce
latent bond learning (Sec. 5.2) into GIN, where bond (edge) representations are also aggregated into
latent hierarchies, denoted as “latent bonds”. Note that we restrict these new relational templates to
the same tensor dimensionalities and number of layers as GIN. For statistical soundness, we increase
the number of datasets to the ﬁrst 10 (alphabetically). We run all the models on the same 10-fold
crossvalidation splits with a 80:10:10 (train:val:test) ratio, and keep the same, previously reported,
training hyperparameters. We display the aggregated training errors in Figure 8, and the cross-
validated test errors, corresponding to the best validation errors in each split, in Figure 9.

We can observe that the training performance follows intuition about capacity of each model, where
the more complex models generally dominate the simpler ones. However, the increased capacity does
not seem to consistently translate to better test performance (contrary to the intuition stated in (Xu
et al., 2018a)). While we could certainly pick a subset of datasets to support the same hypothesis
on test sets, we can generally see that none of the models actually performs consistently better than
another, and even the simplest models (e.g. GCN) often outperform the “powerful” ones (GIN and its
modiﬁcations), and the test performances are thus generally inconclusive32. While this is in contrast
with the self-reported results accompanying the diverse GNN proposals on similar-sized graph datasets,
it is in agreement with another (much larger) recent benchmark (Dwivedi et al., 2020).

Additionally, we include results of an old LRNN template reported in (Sourek et al., 2015), denoted
as “lrnn(2015)”. It was based on small graphlets of size 3, similarly to the “graphlets” template (and

32We note that the conclusion could be diﬀerent for diﬀerent types of datasets.

24

Figure 8: Comparison of train accuracies of selected models across 10 datasets.

Figure 9: Comparison of test accuracies of selected models across 10 datasets.

25

similarly to some other works (Tu et al., 2019; Sankar et al., 2017)), however it only contained a single
layer of learnable parameters for the atom and bond representations. Note that we use results from
the original paper (Sourek et al., 2015) experiments, which were run with diﬀerent hyperparameters
and splits. Nevertheless, we can see that it is again generally on par with performance of the more
recent, deeper, and bigger GNN models.

7 Related Works

This work can be seen as a simple extension of the Lifted Relational Neural Networks (ˇSourek et al.,
2015) language by increasing the amount of (tensor) parameterization. In turn LRNNs were inspired by
lifted graphical models (Kimmig et al., 2015) such as Bayesian Logic Programs (Kersting and De Raedt,
2001) or Markov Logic Networks (Richardson and Domingos, 2006b), working in a probabilistic setting.
From another view, LRNNs can also be seen as a direct extension of KBANN (Towell et al., 1990)
into relational setting. The most closely related works naturally comprise of other diﬀerentiable
programming languages with relational expressiveness (De Raedt et al., 2020)33.

There is a number of works targeting similar abilities by extending logic programming with numeri-
cal parameters. The most prominent framework in this category is the language of Problog (De Raedt
et al., 2007), where the parameters and values further posses probabilistic interpretation. The ex-
tension of Deep-Problog (Manhaeve et al., 2018) then incorporates “neural predicates” into Problog
programs. Since probabilistic logic programs can be commonly diﬀerentiated (Fadja et al., 2017) and
trained as such, the gradients can be passed from the logic program to the neural modules and trained
jointly. While this is somewhat similar to LRNNs, Deep-Problog introduces a clear separation line
between the neural and logical parts of the program, which communicate merely through the gradient
values (and so any gradient-based learner could be used instead). The logical part with relational ex-
pressiveness is thus completely oblivious of structure of the gradient-ingesting learner and vice versa,
and it is thus impossible to model complex convolutional patterns (i.e. relational patterns in the neural
part) as demonstrated in this paper. On the other hand LRNNs do not have probabilistic interpre-
tation. Related is also a recent extension of kProblog (Orsini et al., 2017), proposing integration of
algebraic expressions into logic programs towards more general tensor-algebraic and ML algorithms.
Neural Theorem Provers (NTPs) (Rockt¨aschel and Riedel, 2017) share very similar idea by the
use of a relational logic template with a theorem prover to derive ground computation graphs, which
are diﬀerentiable under certain semantics inspired by fuzzy logic. The use of parameterization diﬀers
between the frameworks, where NTPs are focused on learning embeddings of constants and LRNNs on
embeddings of whole relational constructs34. Nevertheless NTPs represent all constants as embedding
vectors, for which the theorem prover cannot perform standard uniﬁcation, and NTPs thus resort to
“soft-uniﬁcation”, eﬀectively trying all possible constant combinations in the inference process. This
prevents from using NTPs for explicit modelling of the exempliﬁed convolutional neural architectures,
and also severely limits NTP’s scalability, where the latter has been partially addressed by some recent
NTP extensions (Minervini et al., 2018; Weber et al., 2019). LRNNs are more ﬂexible in this sense as
one can use the parameterization to specify which parts of the program keep the logical structure and
which parts should succumb themselves to the exhaustive numerical optimization (and to combine
them arbitrarily), enabling to ﬁnd a more ﬁne-grained neural-symbolic trade-oﬀ.

33Note that common diﬀerentiable programming frameworks, such as PyTorch or TensorFlow, are eﬀectively proposi-
tional. They provide sets of evaluation functions (modules), with predeﬁned hooks for backward diﬀerentiation, that can
be assembled by users into diﬀerentiable programs in a procedural fashion. In contrast, with relational programming, such
programs are ﬁrstly automatically assembled from the declarative template (by a theorem prover), and only then evalu-
ated and diﬀerentiated in the same fashion. Such approach could thus be understood as “meta-programming” (Visser,
2002; Hill and Gallagher, 1998) from the perspective of the current procedural frameworks.

34Note that this includes learning embeddings of constants, too, as demonstrated in some of the example templates.

26

Another line of work is focused on inducing Datalog programs with the help of numerical relaxation.
While such a task has traditionally been addressed by the means of Inductive Logic Programming
(ILP) (Muggleton and De Raedt, 1994), extending the rules with weights can help to relax the combi-
natorial search into a gradient descend optimization, while providing robustness to noise. An example
of such an approach is δILP (Evans and Grefenstette, 2017). Similarly to LRNNs, Datalog programs
are unfolded by chaining the rules, where the associated parameters are trained against given target to
be solved by the program. The parameterization in these approaches is used diﬀerently as its purpose
is to determine the right structure of the template. This is typically done by exhaustive enumeration
from some restricted set of possible literal combinations (particularly 2 literals with arity at most 2
and no constants for δILP), where each combination is then associated with a weight to determine its
appropriateness for the program via gradient descend. The diﬀerentiability is again based on replacing
the logical connectives with fuzzy logic operators (particularly product t-norm). Similarly, programs
in a restricted subset of Datalog are learned in a system called TensorLog (Cohen, 2016; Yang et al.,
2017), which is a diﬀerentiable probabilistic database based on belief propagation (limited to tree-like
factor graphs). Another recently proposed related system is called Diﬄog (Raghothaman et al., 2019),
where the candidate rules are also exhaustively generated w.r.t. a more narrow language bias, thanks
to which it seem to scale beyond previous systems. While we explicitly address only parameter learning
in this paper, structure learning of the LRNN programs can also be done (ˇSourek et al., 2017).

Other class of approaches target full ﬁrst order logic by providing mapping of all the logical
constructs into numerical (tensor) spaces (“tensorization” (Garcez et al., 2019)). For instance, one
can cast constants to vectors, functions terms to vector functions of the corresponding dimensionality,
and similarly predicates to tensors of the corresponding arity-dimension (Rockt¨aschel et al., 2015;
Diligenti et al., 2017). Again adopting a fuzzy logic interpretation of the logical connectives, the
learning problem can then be cast as a constrained numerical optimization problem, including works
such as Logic Tensor Networks (Seraﬁni and Garcez, 2016) or LYRICS (Marra et al., 2019). While
the distributed representation of the logical constructs is the subject of learning, in contrast with the
discussed Datalog program structure learning approaches, the weight (strength) of each rule needs to
be speciﬁed apriori – a limitation which was recently addressed in (Marra et al., 2020). Other recent
works based on the idea of fully dissolving the logic into tensors, moving even further from the logical
interpretation, include e.g. Neural Logic Machines (Dong et al., 2019). While these frameworks are
theoretically more expressive than LRNNs (lacking the function terms and non-deﬁnite clauses), the
whole logic interpretation is only approximate and completely dissolved in the tensor weights in these
frameworks. Consequently, they lack the capability of precise relational logic inference chaining which
we use to explicitly model the advanced convolutional neural structures, such as GNNs, in this paper.
Alternatively, LRNNs can be seen as an extension of GNNs, as discussed in this paper. From the
graph-level perspective, the most similar idea to the introduced relational templating has become pop-
ular in the knowledge discovery community as “meta-paths” (Dong et al., 2017; Huang and Mamoulis,
2017) deﬁned on the schema-level of a heterogeneous information network. A meta-path is simply a se-
quence of types, the concrete instantiations of which are then searched for in the ground graphs. Such
ground sequences can then be used to deﬁne node similarities (Sun et al., 2011; Shang et al., 2016),
random walks (Dong et al., 2017) as well as node embeddings (Shi et al., 2018; Fu et al., 2017). An ex-
tension from paths to small DAGs was then proposed as “meta-graph” (or “meta-structure”) (Huang
et al., 2016; Sun et al., 2018). Any meta-path or meta-graph can be understood as conjunctive a
rule in a LRNN template. Naturally, we can stack multiple meta-graphs to create deep hierarchies
and, importantly, diﬀerentiate them through to jointly learn all the parameters, and provide further
extensions towards relational expressiveness exempliﬁed in this paper.

27

8 Conclusions

We introduced a diﬀerentiable declarative programming approach for speciﬁcation of advanced re-
lational neural architectures, based on the language of Lifted Relational Neural Networks (LRNNs)
(Sourek et al., 2018). We demonstrated how simple parameterized logic programs, also called tem-
plates, can be eﬃciently used for declaration and learning of complex convolutional models, with a
particular focus on Graph Neural Networks (GNNs). In contrast with the commonly used procedural
(Python) frameworks, LRNNs abstract away the creation of the speciﬁc computation graphs, which
are dynamically unfolded from the template by an underlying theorem prover. As a result, creating a
diverse class of complex neural architectures reduces to rather trivial modiﬁcations of the templates,
distilling only the high level idea of each architecture. We illustrated versatility of the approach on a
number of examples, ranging gradually from simple neural models to complex GNNs, including very
recent GNN models and their extensions. Finally we showed how the existing models can be easily
extended to even higher relational expressiveness.

In the experiments, we then demonstrated correctness and computation eﬃciency by the means
of comparison against modern deep learning frameworks. We showed that while LRNNs are designed
with main focus on ﬂexibility and abstraction, they do not suﬀer from computation ineﬃciencies for
the simpler (GNN) models, as one might expect. On the contrary, we demonstrated that for a range of
existing GNN models and their practical parameterizations, LRNNs actually outperform the existing
frameworks optimized speciﬁcally for GNNs.

While there is a number of related works targeting the integration of deep and relational learning,
to our best knowledge, capturing advanced convolutional neural architectures in an exact manner,
as exempliﬁed in this paper, would not be possible with the other approaches. The proposed rela-
tional upgrades can then be understood as proper extensions of the existing, arguably popular, GNN
models. However, we showed that generalization performance of various state-of-the-art GNN models
is somewhat peculiar, as they actually performed with rather insigniﬁcant test error improvements,
when measured uniformly over a large set of medium-sized, molecular structure-property prediction
datasets, which is in agreement with another recent benchmark (Dwivedi et al., 2020).

28

A Appendix

A.1 Diﬀerences from LRNNs (Sourek et al., 2018)

Algorithm 1 Transforming ground neural network into vectorized form
1: function vectorize(neurons)
2:

N ← (cid:83) neurons
(depth, N ) ← topologicOrder(N )
Layers = ∅
for i = 1 : depth do

Mi ← initM atrix()
M ← neuronsAtLevel(i, N )
for neuron ∈ M do

(inputs, weights) ← inputs(neuron)
for (input, weight) ∈ (inputs, weights) do

if getLevel(input) = i + 1 then
Mi(neuron, input) = weight

else

skipConnect ← void(neuron, i + 1)
Mi(neuron, skipConnect) = 1

Layers = Layers ∪ Mi

return Layers

3:

4:

5:

6:

7:

8:

9:

10:

11:

12:

13:

14:

15:

16:

17:

The framework introduced in this paper closely follows the original LRNNs (Sourek et al., 2018).
In fact, the main semantic diﬀerence is “merely” in the parameterization of the rules, where one can
now include the weights within the bodies (conjunctions), too, e.g.

w(2)
1

:: node(2)

1 (X) ← w(1)

1

· node(0)

1 (X) ∧ w(1)

2

· node(0)

2 (X)

We note that this could be in essence emulated in the original LRNNs through the use of auxiliary
predicates, such as in (Sourek et al., 2018), as follows

w(2)
1
w(1)
1
w(1)
2

: neuron(2)
: neuron(1)
: neuron(1)

1 (X) ← neuron(1)
1 (X) ← neuron(0)
2 (X) ← neuron(0)

1 (X) ∧ neuron(1)
1 (X)
2 (X)

2 (X)

which might be more appropriate in scenarios where the neurons correspond to actual logical concepts
under fuzzy logic semantics35, while the second representation is arguably more suitable to exploit the
correspondence with standard deep learning architectures.

Another diﬀerence is that we now also allow tensor weights and values. While these could be
modeled in LRNNs, too, for instance in the “soft-clustering” (embedding) construct (ˇSourek et al.,
2015) used for atom representation learning:

wo1 : gr1(X) ← O(X)
wo2 : gr2(X) ← O(X)

...

...

wh1 : gr1(X) ← H(X)
wh2 : gr2(X) ← H(X)

35Note that any model from the original LRNNs can still be directly encoded in the new formalism.

29

Algorithm 2 Pruning linear chains of unnecessary transformations
1: function prune(neurons)
N ← (cid:83) neurons
2:
for neuron ∈ N do

3:

4:

5:

6:

7:

8:

9:

10:

11:

(inputs, weights) ← inputs(neuron)
if inputs.size = 1 ∧ weights = ∅ then

outputs ← outputs(neuron)
for output ∈ outputs do
input = inputs[0]
output.replaceInput(neuron, input)
input.replaceOutput(neuron, output)

return connectedComponent(N )

the tensor-valued weights oﬀer an arguably more elegant representation of the same construct:

[wo1, wo2] :: gr(X) ← O(X)

...

[wh1, wh2] :: gr(X) ← H(X)

In general, with the new representation we can merge scalar weights of individual neurons into tensors
used by the nodes (prev. referred to as “neurons”) in the computation graph. Note that we can
process any ground LRNN network into this form, i.e. turn individual neurons into matrix layers, in
a similar manner, as outlined in Algorithm 1.

Being heavily utilized in deep learning, such transformation can signiﬁcantly speed up the training
of the networks. However by reducing the number of rules, eﬀectively merging together semantically
equivalent rules which do not diﬀer up to their (scalar) parameterization, we can also alleviate much
of the complexity during model creation, i.e. calculation of the least Herbrand model, by avoiding
repeated calculations. This results in a signiﬁcant speedup during the model creation process.

A.1.1 Network Pruning

Following the computation graph creation procedure from Section 3.2, we might end up with unnec-
essary trivial neural transformations through auxiliary predicates in cases, where the original rules
have only a single literal in body and are unweighted. For mitigation, we can apply a straightforward
procedure for detection and removal of linear chains of these trivial operations, as described in Algo-
rithm 2. While such an operation arguably changes the inference and logical semantics of the original
model, these structures do not contribute to learning capacity of the model and, on the contrary, cause
gradient diminishing. This technique is thus particularly suited for improving training performance in
correspondence with standard deep learning architectures. While this form of pruning can be theoret-
ically performed directly in the template, it is easier to do as a post-processing step in the resulting
neural networks.

Finally, the new LRNN framework (“NeuraLogic”) presents a completely new implementation 36 of
the idea, with the whole functionality build from scratch, while aiming at ﬂexibility and modularity.

36available at https://github.com/GustikS/NeuraLogic

30

References

Bader S, Hitzler P (2005) Dimensions of Neural-symbolic Integration - A Structured Survey. arXiv

preprint 0511042

Bancilhon F, Maier D, Sagiv Y, Ullman JD (1985) Magic sets and other strange ways to implement
logic programs. In: Proceedings of the ﬁfth ACM SIGACT-SIGMOD symposium on Principles of
database systems, pp 1–15

Bistarelli S, Martinelli F, Santini F (2008) Weighted datalog and levels of trust. In: 2008 Third

International Conference on Availability, Reliability and Security, IEEE, pp 1128–1134

Botta M, A G, Piola R (1997) Combining ﬁrst order logic with connectionist learning. In: Proceedings

of the 14th International Conference on Machine Learning

Bratko I (2001) Prolog programming for artiﬁcial intelligence. Pearson education

Bronstein MM, Bruna J, LeCun Y, Szlam A, Vandergheynst P (2017) Geometric deep learning: going

beyond euclidean data. IEEE Signal Processing Magazine 34(4):18–42

Chen Z, Li X, Bruna J (2017) Supervised community detection with line graph neural networks. arXiv

preprint arXiv:170508415

Cohen WW (2016) Tensorlog: A diﬀerentiable deductive database. arXiv preprint arXiv:160506523

Dash T, Srinivasan A, Vig L, Orhobor OI, King RD (2018) Large-scale assessment of deep relational

machines. In: International Conference on Inductive Logic Programming, Springer, pp 22–37

De Raedt L, Kimmig A, Toivonen H (2007) Problog: A probabilistic prolog and its application in
link discovery. In: IJCAI 2007, Proceedings of the 20th International Joint Conference on Artiﬁcial
Intelligence, pp 2462–2467

De Raedt L, Kimmig A, Toivonen H (2007) Problog: A probabilistic prolog and its application in link

discovery. In: IJCAI, Hyderabad, vol 7, pp 2462–2467

De Raedt L, Dumanˇci´c S, Manhaeve R, Marra G (2020) From statistical relational to neuro-symbolic

artiﬁcial intelligence. arXiv preprint arXiv:200308316

Diligenti M, Gori M, Sacca C (2017) Semantic-based regularization for learning and inference. Artiﬁcial

Intelligence 244:143–165

Ding L, Liya Ding (1995) Neural Prolog-the concepts, construction and mechanism. In: 1995 IEEE
International Conference on Systems, Man and Cybernetics. Intelligent Systems for the 21st Century,
IEEE, vol 4, pp 3603–3608, DOI 10.1109/ICSMC.1995.538347, URL http://ieeexplore.ieee.
org/document/538347/

Dong H, Mao J, Lin T, Wang C, Li L, Zhou D (2019) Neural

logic machines. arXiv preprint

arXiv:190411694

Dong X, Gabrilovich E, Heitz G, Horn W, Lao N, Murphy K, Strohmann T, Sun S, Zhang W (2014)
Knowledge vault: A web-scale approach to probabilistic knowledge fusion. In: Proceedings of the
20th ACM SIGKDD international conference on Knowledge discovery and data mining, pp 601–610

31

Dong Y, Chawla NV, Swami A (2017) metapath2vec: Scalable representation learning for heteroge-
neous networks. In: Proceedings of the 23rd ACM SIGKDD international conference on knowledge
discovery and data mining, pp 135–144

Dwivedi VP, Joshi CK, Laurent T, Bengio Y, Bresson X (2020) Benchmarking graph neural networks.

arXiv preprint arXiv:200300982

Eisner J, Filardo NW (2010) Dyna: Extending datalog for modern ai. In: International Datalog 2.0

Workshop, Springer, pp 181–220

Evans R, Grefenstette E (2017) Learning Explanatory Rules from Noisy Data. To Appear in Jour-
nal of Artiﬁcial Intelligence Research Submitted 02, URL https://arxiv.org/pdf/1711.04574.
pdfhttp://arxiv.org/abs/1711.04574, 1711.04574

Evans R, Saxton D, Amos D, Kohli P, Grefenstette E (2018) Can neural networks understand logical

entailment? arXiv preprint arXiv:180208535

Fadja AN, Lamma E, Riguzzi F (2017) Deep probabilistic logic programming. In: PLP@ ILP, pp 3–14

Feng Y, You H, Zhang Z, Ji R, Gao Y (2019) Hypergraph neural networks. In: Proceedings of the

AAAI Conference on Artiﬁcial Intelligence, vol 33, pp 3558–3565

Fey M, Lenssen JE (2019) Fast graph representation learning with pytorch geometric. arXiv preprint

arXiv:190302428

Fu Ty, Lee WC, Lei Z (2017) Hin2vec: Explore meta-paths in heterogeneous information networks
for representation learning. In: Proceedings of the 2017 ACM on Conference on Information and
Knowledge Management, pp 1797–1806

Garcez Ad, Gori M, Lamb LC, Seraﬁni L, Spranger M, Tran SN (2019) Neural-symbolic computing: An
eﬀective methodology for principled integration of machine learning and reasoning. arXiv preprint
arXiv:190506088

Garcez ASA, Zaverucha G (1999) The connectionist inductive learning and logic programming system.

Applied Intelligence 11(1):59–77

Gilmer J, Schoenholz SS, Riley PF, Vinyals O, Dahl GE (2017) Neural message passing for quantum
chemistry. In: Proceedings of the 34th International Conference on Machine Learning-Volume 70,
JMLR. org, pp 1263–1272

Glorot X, Bengio Y (2010) Understanding the diﬃculty of training deep feedforward neural networks.
In: Proceedings of the thirteenth international conference on artiﬁcial intelligence and statistics, pp
249–256

Gong L, Cheng Q (2019) Exploiting edge features for graph neural networks. In: Proceedings of the

IEEE Conference on Computer Vision and Pattern Recognition, pp 9211–9219

Graves A, Wayne G, Danihelka I (2014) Neural Turing Machines. arXiv preprint URL http://arxiv.

org/abs/1410.5401, 1410.5401

Graves A, Wayne G, Reynolds M, Harley T, Danihelka I, Grabska-Barwi´nska A, Colmenarejo SG,
Grefenstette E, Ramalho T, Agapiou J, et al. (2016) Hybrid computing using a neural network with
dynamic external memory. Nature 538(7626):471–476

32

Hamilton W, Ying Z, Leskovec J (2017) Inductive representation learning on large graphs. In: Advances

in neural information processing systems, pp 1024–1034

Hill P, Gallagher J (1998) Meta-programming in logic programming. Handbook of Logic in Artiﬁcial

Intelligence and Logic Programming 5:421–497

Huang Z, Mamoulis N (2017) Heterogeneous information network embedding for meta path based

proximity. arXiv preprint arXiv:170105291

Huang Z, Zheng Y, Cheng R, Sun Y, Mamoulis N, Li X (2016) Meta structure: Computing relevance in
large heterogeneous information networks. In: Proceedings of the 22nd ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, pp 1595–1604

Kadlec R, Bajgar O, Kleindienst J (2017) Knowledge base completion: Baselines strike back. arXiv

preprint arXiv:170510744

Kazemi SM, Poole D (2018) Bridging Weighted Rules and Graph Random Walks for Statistical Rela-

tional Models. Frontiers in Robotics and AI 5:8, DOI 10.3389/frobt.2018.00008

Kersting K, De Raedt L (2001) Bayesian logic programs. arXiv preprint cs/0111058

Kersting K, De Raedt L (2001) Towards combining inductive logic programming with bayesian net-
works. In: Inductive Logic Programming, 11th International Conference, ILP 2001, Strasbourg,
France, September 9-11, 2001, Proceedings, pp 118–131

Keskar NS, Mudigere D, Nocedal J, Smelyanskiy M, Tang PTP (2016) On large-batch training for

deep learning: Generalization gap and sharp minima. arXiv preprint arXiv:160904836

Kim J, Kim T, Kim S, Yoo CD (2019) Edge-labeling graph neural network for few-shot learning. In:

Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp 11–20

Kimmig A, Mihalkova L, Getoor L (2015) Lifted graphical models: a survey. Machine Learning 99(1):1–

45

Kipf T, Fetaya E, Wang KC, Welling M, Zemel R (2018) Neural relational inference for interacting

systems. arXiv preprint arXiv:180204687

Kipf TN, Welling M (2016) Semi-supervised classiﬁcation with graph convolutional networks. arXiv

preprint arXiv:160902907

Lamb L, Garcez A, Gori M, Prates M, Avelar P, Vardi M (2020) Graph neural networks meet neural-

symbolic computing: A survey and perspective. arXiv preprint arXiv:200300330

Li J, Jurafsky D (2015) Do multi-sense embeddings improve natural language understanding? arXiv

preprint arXiv:150601070

Li Y, Tarlow D, Brockschmidt M, Zemel R (2015) Gated graph sequence neural networks. arXiv

preprint arXiv:151105493

Lipton ZC, Berkowitz J, Elkan C (2015) A critical review of recurrent neural networks for sequence

learning. arXiv preprint arXiv:150600019

Liu Z, Chen C, Yang X, Zhou J, Li X, Song L (2018) Heterogeneous graph neural networks for malicious
account detection. In: Proceedings of the 27th ACM International Conference on Information and
Knowledge Management, pp 2077–2085

33

Manhaeve R, Dumancic S, Kimmig A, Demeester T, De Raedt L (2018) Deepproblog: Neural proba-
bilistic logic programming. In: Advances in Neural Information Processing Systems, pp 3749–3759

Marcus G (2020) The next decade in ai: four steps towards robust artiﬁcial intelligence. arXiv preprint

arXiv:200206177

Marra G, Giannini F, Diligenti M, Gori M (2019) Lyrics: a general interface layer to integrate ai and

deep learning. arXiv preprint arXiv:190307534

Marra G, Diligenti M, Giannini F, Gori M, Maggini M (2020) Relational neural machines. arXiv

preprint arXiv:200202193

Masters D, Luschi C (2018) Revisiting small batch training for deep neural networks. arXiv preprint

arXiv:180407612

Minervini P, Bosnjak M, Rockt¨aschel T, Riedel S (2018) Towards Neural Theorem Proving at Scale.

Tech. rep., URL https://arxiv.org/pdf/1807.08204.pdf, arXiv:1807.08204v1

Muggleton S, De Raedt L (1994) Inductive logic programming: Theory and methods. The Journal of

Logic Programming 19

Neubig G, Dyer C, Goldberg Y, Matthews A, Ammar W, Anastasopoulos A, Ballesteros M, Chiang
D, Clothiaux D, Cohn T, et al. (2017) Dynet: The dynamic neural network toolkit. arXiv preprint
arXiv:170103980

Orsini F, Frasconi P, De Raedt L (2017) kproblog: an algebraic prolog for machine learning. Machine

Learning 106(12):1933–1969

Palm R, Paquet U, Winther O (2018) Recurrent relational networks. In: Advances in Neural Infor-

mation Processing Systems, pp 3368–3378

Raghothaman M, Si X, Heo K, Naik M (2019) Diﬄog: Learning datalog programs by continuous

optimization

Ralaivola L, Swamidass SJ, Saigo H, Baldi P (2005) Graph kernels for chemical informatics. Neural

Netw 18(8):1093–1110

Richardson M, Domingos P (2006a) Markov logic networks. Machine learning

Richardson M, Domingos P (2006b) Markov logic networks. Machine learning 62(1-2):107–136

Rockt¨aschel T, Riedel S (2017) End-to-end diﬀerentiable proving. In: Advances in Neural Information

Processing Systems

Rockt¨aschel T, Singh S, Riedel S (2015) Injecting Logical Background Knowledge into Embeddings
for Relation Extraction. Proceedings of the 2015 Conference of the North American Chapter of
the Association for Computational Linguistics: Human Language Technologies pp 1119–1129, DOI
10.3115/v1/N15-1118, URL http://aclweb.org/anthology/N15-1118

Sankar A, Zhang X, Chang KCC (2017) Motif-based convolutional neural network on graphs. arXiv

preprint arXiv:171105697

Scarselli F, Gori M, Tsoi AC, Hagenbuchner M, Monfardini G (2008) The graph neural network model.

IEEE Transactions on Neural Networks 20(1):61–80

34

Schlichtkrull M, Kipf TN, Bloem P, Van Den Berg R, Titov I, Welling M (2018) Modeling relational
data with graph convolutional networks. In: European Semantic Web Conference, Springer, pp
593–607

Seraﬁni L, Garcez A (2016) Logic tensor networks: Deep learning and logical reasoning from data and

knowledge. arXiv preprint arXiv:160604422

Seraﬁni L, d’Avila Garcez AS (2016) Logic Tensor Networks: Deep Learning and Logical Reasoning

from Data and Knowledge arXiv:1606.04422v1

Shang J, Qu M, Liu J, Kaplan LM, Han J, Peng J (2016) Meta-path guided embedding for similarity

search in large-scale heterogeneous information networks. arXiv preprint arXiv:161009769

Shi C, Hu B, Zhao WX, Philip SY (2018) Heterogeneous information network embedding for recom-

mendation. IEEE Transactions on Knowledge and Data Engineering 31(2):357–370

Smolensky P (1990) Tensor product variable binding and the representation of symbolic structures in

connectionist systems. Artiﬁcial intelligence 46(1-2):159–216

Smullyan RM (1995) First-order logic. Courier Corporation

Socher R, Chen D, Manning CD, Ng A (2013a) Reasoning with neural tensor networks for knowledge

base completion. In: Advances in neural information processing systems, pp 926–934

Socher R, Perelygin A, Wu JY, Chuang J, Manning CD, Ng AY, Potts C, et al. (2013b) Recursive deep
models for semantic compositionality over a sentiment treebank. In: Proceedings of the conference
on empirical methods in natural language processing (EMNLP), Citeseer, vol 1631, p 1642

Sourek G, Zelezny F (2020) Lossless compression of structured convolutional models via lifting. arXiv

preprint

ˇSourek G, Kuzelka O, Zelezn`y F (2013) Predicting top-k trends on twitter using graphlets and time

features. ILP 2013 Late Breaking Papers p 52

Sourek G, Aschenbrenner V, Zelezny F, Kuzelka O (2015) Lifted relational neural networks. arXiv

preprint arXiv:150805128

ˇSourek G, Aschenbrenner V, ˇZelezny F, Kuˇzelka O (2015) Lifted relational neural networks. In: Pro-
ceedings of the NIPS Workshop on Cognitive Computation: Integrating Neural and Symbolic Ap-
proaches co-located with the 29th Annual Conference on Neural Information Processing Systems
(NIPS 2015).

ˇSourek G, Manandhar S, ˇZelezn`y F, Schockaert S, Kuˇzelka O (2016) Learning predictive categories us-
ing lifted relational neural networks. In: International Conference on Inductive Logic Programming,
Springer, pp 108–119

ˇSourek G, Svatoˇs M, ˇZelezn`y F, Schockaert S, Kuˇzelka O (2017) Stacked structure learning for lifted
relational neural networks. In: International Conference on Inductive Logic Programming, Springer,
pp 140–151

Sourek G, Aschenbrenner V, Zelezny F, Schockaert S, Kuzelka O (2018) Lifted relational neural net-
works: Eﬃcient learning of latent relational structures. Journal of Artiﬁcial Intelligence Research
62:69–100

35

Sun L, He L, Huang Z, Cao B, Xia C, Wei X, Philip SY (2018) Joint embedding of meta-path and
meta-graph for heterogeneous information networks. In: 2018 IEEE International Conference on
Big Knowledge (ICBK), IEEE, pp 131–138

Sun Y, Han J, Yan X, Yu PS, Wu T (2011) Pathsim: Meta path-based top-k similarity search in

heterogeneous information networks. Proceedings of the VLDB Endowment 4(11):992–1003

Towell GG, Shavlik JW, Noordewier MO (1990) Reﬁnement of approximate domain theories by
knowledge-based neural networks. In: Proceedings of the eighth National conference on Artiﬁcial
intelligence, Boston, MA, pp 861–866

Tripos L (2007) Tripos mol2 ﬁle format. St Louis, MO: Tripos

Tu K, Li J, Towsley D, Braines D, Turner LD (2019) gl2vec: Learning feature representation using
graphlets for directed networks. In: Proceedings of the 2019 IEEE/ACM International Conference
on Advances in Social Networks Analysis and Mining, pp 216–221

Unman JD (1989) Principles of database and knowledge-base systems. Computer Science Press

Uwents W, Monfardini G, Blockeel H, Gori M, Scarselli F (2011) Neural networks for rela-
learning: an experimental comparison. Machine Learning 82(3):315–349, DOI 10.1007/

tional
s10994-010-5196-5, URL https://doi.org/10.1007/s10994-010-5196-5

Van Emden MH, Kowalski RA (1976) The semantics of predicate logic as a programming language.

Journal of the ACM (JACM) 23(4):733–742

Veliˇckovi´c P, Cucurull G, Casanova A, Romero A, Lio P, Bengio Y (2017) Graph attention networks.

arXiv preprint arXiv:171010903

Visser E (2002) Meta-programming with concrete object syntax. In:

International Conference on

Generative Programming and Component Engineering, Springer, pp 299–315

Wang M, Yu L, Zheng D, Gan Q, Gai Y, Ye Z, Li M, Zhou J, Huang Q, Ma C, et al. (2019a) Deep graph
library: Towards eﬃcient and scalable deep learning on graphs. arXiv preprint arXiv:190901315

Wang X, Ji H, Shi C, Wang B, Ye Y, Cui P, Yu PS (2019b) Heterogeneous graph attention network.

In: The World Wide Web Conference, pp 2022–2032

Weber L, Minervini P, M¨unchmeyer J, Leser U, Rockt¨aschel T (2019) Nlprolog: Reasoning with weak

uniﬁcation for question answering in natural language. arXiv preprint arXiv:190606187

Weisfeiler B (2006) On construction and identiﬁcation of graphs, vol 558. Springer

Wilson DR, Martinez TR (2003) The general ineﬃciency of batch training for gradient descent learning.

Neural networks 16(10):1429–1451

Wu Z, Pan S, Chen F, Long G, Zhang C, Yu PS (2019) A comprehensive survey on graph neural

networks. arXiv preprint arXiv:190100596

Wu Z, Pan S, Chen F, Long G, Zhang C, Philip SY (2020) A comprehensive survey on graph neural

networks. IEEE Transactions on Neural Networks and Learning Systems

Xu K, Hu W, Leskovec J, Jegelka S (2018a) How powerful are graph neural networks? arXiv preprint

arXiv:181000826

36

Xu K, Li C, Tian Y, Sonobe T, Kawarabayashi Ki, Jegelka S (2018b) Representation learning on

graphs with jumping knowledge networks. arXiv preprint arXiv:180603536

Yang F, Yang Z, Cohen WW (2017) Diﬀerentiable learning of logical rules for knowledge base reason-

ing. In: Advances in Neural Information Processing Systems, pp 2319–2328

Zhou J, Cui G, Zhang Z, Yang C, Liu Z, Wang L, Li C, Sun M (2018) Graph neural networks: A

review of methods and applications. arXiv preprint arXiv:181208434

Zhu S, Zhou C, Pan S, Zhu X, Wang B (2019) Relation structure-aware heterogeneous graph neural
network. In: 2019 IEEE International Conference on Data Mining (ICDM), IEEE, pp 1534–1539

37

