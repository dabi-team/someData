Nonparametric Hamiltonian Monte Carlo

Carol Mak 1 Fabian Zaiser 1 Luke Ong 1

1
2
0
2

n
u
J

8
1

]

G
L
.
s
c
[

1
v
8
3
2
0
1
.
6
0
1
2
:
v
i
X
r
a

Abstract

Probabilistic programming uses programs to ex-
press generative models whose posterior probabil-
ity is then computed by built-in inference engines.
A challenging goal is to develop general purpose
inference algorithms that work out-of-the-box for
arbitrary programs in a universal probabilistic
programming language (PPL). The densities de-
ﬁned by such programs, which may use stochastic
branching and recursion, are (in general) nonpara-
metric, in the sense that they correspond to mod-
els on an inﬁnite-dimensional parameter space.
However standard inference algorithms, such as
the Hamiltonian Monte Carlo (HMC) algorithm,
target distributions with a ﬁxed number of param-
eters. This paper introduces the Nonparametric
Hamiltonian Monte Carlo (NP-HMC) algorithm
which generalises HMC to nonparametric models.
Inputs to NP-HMC are a new class of measurable
functions called “tree representable”, which serve
as a language-independent representation of the
density functions of probabilistic programs in a
universal PPL. We provide a correctness proof
of NP-HMC, and empirically demonstrate signif-
icant performance improvements over existing
approaches on several nonparametric examples.

1. Introduction

Probabilistic programming is a general purpose means of
expressing probabilistic models as programs, and automati-
cally performing Bayesian inference. Probabilistic program-
ming systems enable data scientists and domain experts to
focus on designing good models; the task of developing
efﬁcient inference engines can be left to experts in Bayesian
statistics, machine learning and programming languages. To
realise the full potential of probabilistic programming, it is

1Department of Computer Science, University of Ox-
Correspondence to: Carol Mak

ford, United Kingdom.
<pui.mak@cs.ox.ac.uk>.

Proceedings of the 38 th International Conference on Machine
Learning, PMLR 139, 2021. Copyright 2021 by the author(s).

essential to automate the inference of latent variables in the
model, conditioned on the observed data.

Church (Goodman et al., 2008) introduced universal proba-
bilistic programming, the idea of writing probabilistic mod-
els in a Turing-complete functional programming language.
Typically containing only a handful of basic programming
constructs such as branching and recursion, universal prob-
abilistic programming languages (PPLs) can nonetheless
specify all computable probabilistic models (V´ak´ar et al.,
2019). In particular, nonparametric models—models with
an unbounded number of random variables—can be de-
scribed naturally in universal PPLs using recursion. These
include probabilistic models with an unknown number of
components, like Bayesian nonparametric models (Richard-
son & Green, 1997), variable selection in regression (Ratner,
2010), signal processing (Murray et al., 2018); and models
that are deﬁned on inﬁnite-dimensional spaces, such as prob-
abilistic context free grammars (Manning & Sch¨utze, 1999),
birth-death models of evolution (Kudlicka et al., 2019) and
statistical phylogenetics (Ronquist et al., 2021). Examples
of practical universal PPL include Anglican (Wood et al.,
2014), Venture (Mansinghka et al., 2014), Web PPL (Good-
man & Stuhlm¨uller, 2014), Hakaru (Narayanan & Shan,
2020), Pyro (Bingham et al., 2019), Turing (Ge et al., 2018)
and Gen (Cusumano-Towner et al., 2019).

However, because universal PPLs are expressively complete,
it is a challenging problem to design and implement general
purpose inference engines for them. The parameter space
of a nonparametric model is a union of spaces of varying
dimensions. To approximate the posterior via an Markov
chain Monte Carlo (MCMC) algorithm, the transition ker-
nel will have to efﬁciently switch between a potentially
unbounded number of conﬁgurations of different dimen-
sions. This difﬁculty explains why there are so few general
purpose MCMC algorithms for universal PPLs (Wingate
et al., 2011; Wood et al., 2014; Tolpin et al., 2015; Hur et al.,
2015). We believe it is also the reason why these algorithms
struggle with nonparametric models, as we show in Sec. 5.
A case in point is the widely used universal PPL Pyro. Even
though it allows the speciﬁcation of nonparametric mod-
els, its HMC and No-U-Turn Sampler (Hoffman & Gelman,
2014) inference engines do not support them reliably: in one
of our benchmark tests, they produced a wrong posterior
(Fig. 6).

 
 
 
 
 
 
Nonparametric Hamiltonian Monte Carlo

In this paper, we introduce the Nonparametric Hamilto-
nian Monte Carlo (NP-HMC) algorithm, which generalises
the Hamiltonian Monte Carlo (HMC) algorithm (Duane
et al., 1987) to nonparametric models. The input to NP-
HMC is what we call a tree representable (TR) function,
which is a large class of measurable functions of type
w ∶ ⋃n∈N Rn → R
≥0, designed to be a language-independent
representation for the density functions of programs written
in any universal PPL. The parameter space of the standard
HMC algorithm is Rn, a Euclidean space of a ﬁxed di-
mension. By contrast, the parameter space of NP-HMC is
⋃n∈N Rn. The key innovation of NP-HMC is a method by
which the dimension of the conﬁguration of the current sam-
ple is incremented lazily, while preserving the efﬁcacy of
HMC by keeping the Hamiltonian approximately invariant.
We prove that NP-HMC is correct, i.e., the induced Markov
chain converges to the posterior distribution. To evaluate the
practical utility of NP-HMC, we compare an implementa-
tion of the algorithm against existing out-of-the-box MCMC
inference algorithms on several challenging models with an
unbounded number of random variables. Our results suggest
that NP-HMC is applicable to a large class of probabilistic
programs written in universal PPLs, offering signiﬁcantly
better performance than existing algorithms.

Notation We write q to mean a (possibly inﬁnite) real-
valued sequence; q1...i the preﬁx of q consisting of the ﬁrst i
coordinates; qi the i-th coordinate of q; and ∣q∣ the length of
q. We write sequence as lists, such as [3.6, 1.0, 3, 55, −4.2],
and the concatenation of sequences q and q′ as q ++ q′.
We write Bn for the Borel σ-algebra of Rn; Nn for the
standard n-dimensional normal distribution with mean 0
and covariance I; ϕn(x ∣ µ, Σ) for the density of x ∈ Rn
in the n-dimensional normal distribution with mean µ and
covariance Σ. For brevity we write ϕn(x) for ϕn(x ∣ 0, I)
and ϕ for ϕ1.
For any R
≥0, we
write Supp(f ) ∶= f −1(R
>0) for the support of f ; and
Suppn(f ) ∶= Supp(f ) ∩ Rn for the support of f in Rn.
We say x ∈ X is f -supported if x ∈ Supp(f ).

≥0-valued function f ∶ Dom(f ) → R

2. Tree Representable Functions

Conventional HMC samples from a distribution with a den-
sity function w ∶ Rn → R
≥0 where the dimension of the
target (parameter) space Rn is ﬁxed. However this is too re-
strictive for probabilistic programs, because—with branch-
ing and recursion—the target space has a variable, even
unbounded, number of dimensions.

Example 1 (Working). Consider the probabilistic program
in Listing 1 where sample(normal (0, 1)) denotes sam-
pling from the standard normal distribution. The dimension
of the target space, i.e. the number of samples drawn, can

q = sample(normal(0, 1))
sum = 0
while sum < q:

sum += sample(normal(0, 1))

observe(sum, normal(q, 1))

Listing 1. A simple probabilistic program.

vary from run to run because of the branching behaviour
of the while loop. (Recall that by trace, we mean the se-
quence of samples drawn in the course of a particular run,
one for each random primitive encountered.) The density
function then records the weight of this trace, computed by
multiplying the probability densities of all sampled values
and the likelihoods of all observations during the run. For
the above program, we could have a trace [0.3, 0.5] ∈ R2
of length 2 or a trace [1.0, 0.5, 0.5] ∈ R3 of length 3, and
so on. Hence we have to consider density functions of type
w ∶ ⋃n∈N Rn → R
≥0. However, not every such function
makes sense as the density of a probabilistic program. For
example, if w([1.0, 0.5, 0.5]) > 0 then the program can exe-
cute successfully with the trace [1.0, 0.5, 0.5], but not with
[1.0, 0.5] or any other preﬁx. In other words, no proper
preﬁx of [1.0, 0.5, 0.5] is in Supp(w).

Thus we set our target space to be the measure space of
traces T ∶= ⋃n∈N Rn equipped with the standard disjoint
union σ-algebra ΣT ∶= {⋃n∈N Un ∣ Un ∈ Bn}, with mea-
sure given by summing the respective (higher-dimensional)
normals µT(⋃n∈N Un) ∶= ∑n∈N Nn(Un).
We consider density functions that are measurable functions
w ∶ T → R
≥0 satisfying the preﬁx property: whenever q ∈
Suppn(w) then for all k < n, we have q1...k /∈ Suppk(w).
We call them tree representable (TR) functions because
any such function w can be represented as a possibly inﬁnite
but ﬁnitely branching tree, which we call program tree.
This is exempliﬁed in Fig. 1 (left), where a circular node
denotes an element of the input of type R; a rectangular
node gives the condition for q ∈ Suppn(w) (with the left,
but not the right, child satisfying the condition); and a leaf
node gives the result of the function on that branch. Any
branch (i.e. path from root to leaf) in a program tree of w
represents a set of ﬁnite sequences [q1, . . . , qn] in Supp(w).
In fact, every program tree of a TR function w speciﬁes a
countable partition of Supp(w) via its branches. The preﬁx
property guarantees that for each TR function w, there are
program trees of the form in Fig. 1 (left) representing w.

We target TR functions as densities for our new sampler NP-
HMC because they are a naturally large class of functions.
In particular, every program of a universal PPL has a density
function that is tree representable.1 (See Prop. 7 in App. A
for a formal account.) For instance, the program in Listing 1

1 With (additional) suitable assumptions about the computabil-
ity of w, we can view any such tree as the abstract syntax tree of a

Nonparametric Hamiltonian Monte Carlo

q1

(w)

?

[q1]
yes

∈ Supp1
no
w([q1]) q2

[q1, q2]
yes

w([q1, q2])

?

∈ Supp2
no
q3

q1

0.3

q1 ≤ 0

ϕ(0 ∣ q1, 1)

q2

0.5

0 < q1 ≤ q2

ϕ(q2 ∣ q1, 1)

q3

(w)

[q1, q2, q3]

yes

w([q1, q2, q3])

?

∈ Supp3
no
⋮

(w)

0 < q1 and
q2 < q1 ≤ q2 + q3

ϕ(q2 + q3 ∣ q1, 1)

⋮

Figure 1. (left) Generic TR function w; (right) TR function w for
the probabilistic program in Listing 1.

has density2 w (w.r.t. the stock measure µT) given by

w(q) ∶=

i=2 qi ∣ q1, 1)

⎧⎪⎪⎪⎪
ϕ(∑n
⎪⎪⎪⎪⎩

⎨

0

if ∀k < ∣q∣
i=2 qi < q1 ≤ ∑n
∑k
otherwise

i=2 qi,

which is TR and it has a program tree as depicted in Fig. 1
(right). Notice that every element in the support of w
belongs to a branch in this tree: for example, the trace
[0.3, 0.5] belongs to the blue branch in Fig. 1 (right).

As we will explain in Sec. 3, the preﬁx property (satisﬁed by
TR functions) is essential for the correctness of NP-HMC.

3. Nonparametric HMC

Nonparametric Hamiltonian Monte Carlo (NP-HMC)
(Fig. 4) is a MCMC algorithm that, given a TR function
w, iteratively proposes a new sample q ∈ ⋃n∈N Rn and ac-
cepts it with a suitable Hastings acceptance probability, such
that the invariant distribution of the induced Markov chain
is

w dµT

ν ∶ A ↦

1
Z
with normalising constant Z ∶= ∫T w dµT. As the name
suggests, NP-HMC is a generalisation of the standard HMC
algorithm (Rem. 2.i) to nonparametric models, in the form
of TR functions whose support is a subspace of T of un-
bounded dimension.

∫

A

In this section, we ﬁrst explain our generalised algorithm,
using a version (Alg. 1) that is geared towards conceptual
clarity, and defer discussions of more efﬁcient variants.

program that computes w, but with any recursion unravelled (so
that the tree is potentially inﬁnite).

2Notice that, even though the program samples from a nor-
mal distribution, w does not factor in Gaussian densities from
those sample statements, just the observe statement, since they are
already accounted for by µT.

Idea We assume basic familiarity with the HMC algo-
rithm; see (Betancourt, 2018) for the intuition behind it and
(Neal, 2011) for details. Like the HMC algorithm, NP-HMC
views a sample q as a particle at position q, with a randomly
initialised momentum p, moving on a frictionless surface
derived from the density function w. The key innovation
lies in our treatment when the particle moves beyond the
surface, i.e. outside the support of the density function. This
procedure is called extend (Alg. 3), which we will now
illustrate.

Let’s trace the movement of a particle at position q = [−3.1]
with a randomly chosen momentum p = [1.2], on the sur-
face (a line in 1D) determined by the TR function w in
Fig. 1 (right). The ﬁrst two steps taken by the particle are
simulated according to the Hamiltonian dynamics on the
surface − log(ϕ(0 ∣ q1, 1)) ⋅ [q1 ≤ 0], which is derived from
the restriction of w to R. The positions on the surface and
states3 of the particle at each step are given in Fig. 2.

At the third time step, the particle is at the position [1.15],
which is no longer on the surface. To search for a suitable
state, NP-HMC increments the dimension of the current
surface (line) as follows.

First, the surface is extended to − log(ϕ(0 ∣ q1, 1)) ⋅ [q1 ≤
0] − log(ϕ(q2 ∣ q1, 1)) ⋅ [0 < q1 ≤ q2], which is derived from
the sum of the respective restrictions of w to R and to R2, as
depicted in Fig. 3. Since w satisﬁes the preﬁx property, the
respective supports of these restrictions, namely {[q1, q2] ∈
R2 ∣ q1 ≤ 0} and {[q1, q2] ∈ R2 ∣ 0 < q1 ≤ q2}, are disjoint;
and hence the states of the particle on the previous surface
− log(ϕ(0 ∣ q1, 1)) ⋅ [q1 ≤ 0] can be reused on the updated
surface. Notice that the respective ﬁrst coordinates of the
particle’s positions on the surface in Fig. 3 are identical to
the particle’s positions on the surface (line) in Fig. 2.

Next, the initial state (q = [−3.1], p = [1.2]) is extended by
appending a randomly chosen value to both the position and
momentum components, so that the particle is positioned
on the updated surface with an initial momentum. In our
example, −1.61 and 3.04 are sampled and the initial state of
the particle becomes (q = [−3.1, −1.61], p = [1.2, 3.04])
which is located on the surface as shown in Fig. 3. The states
at times 1, 2 and 3 are updated accordingly and are given in
the table in Fig. 3. Notice that the particle at time 3 is now
positioned on the updated surface, and hence Hamiltonian
dynamics can resume. The rest of this section is devoted to
formalising our algorithm.

Assumption. Henceforth we assume that the input TR func-
tion w satisﬁes the following:

3As in HMC, a state of the NP-HMC algorithm is a position-
momentum pair (q, p) with ∣q∣ = ∣p∣; but unlike HMC, q, p ∈ T.

Nonparametric Hamiltonian Monte Carlo

− log(ϕ(0 ∣ q1, 1)) ⋅ [q1 ≤ 0]

[-3.1]

[-2.37]

8

6

4

2

y
g
r
e
n
E

[-0.86]

0
q1

0
−4

−2

2

4

0
−4

−2

Time

0

1

2

3

Time

0

− log(ϕ(0 ∣ q1, 1)) ⋅ [q1 ≤ 0]
− log(ϕ(q2 ∣ q1, 1)) ⋅ [0 < q1 ≤ q2]

[-3.1, -1.61]

[-2.37, -0.39]

8

6

4

2

y
g
r
e
n
E

[-0.86, 0.82]

[1.15, 2.04]

0

q1

1

2

4 −4−2 0 2 4

q2

2

3

q

p

[-3.1]

[-2.37]

[-0.86]

[1.15]

[1.2]

[3.29]

[3.94]

[5.26]

q

p

[-3.1, -1.61]

[-2.37, -0.39]

[-0.86, 0.82]

[1.15, 2.04]

[1.2, 3.04]

[3.29, 3.04]

[3.94, 3.04]

[5.26, 3.04]

Figure 2. The Hamiltonian dynamics of a particle on the
surface − log(ϕ(0 ∣ q1, 1)) ⋅ [q1 ≤ 0] on R.

Figure 3. The Hamiltonian dynamics of a particle on the updated surface
− log(ϕ(0 ∣ q1, 1)) ⋅ [q1 ≤ 0] − log(ϕ(q2 ∣ q1, 1)) ⋅ [0 < q1 ≤ q2] on R2.

1 Integrability,

the normalising constant Z <
∞. (Otherwise, the inference problem would be ill-
deﬁned.)

i.e.,

2 The function w is almost everywhere continuously dif-
ferentiable on T. (Since Hamiltonian dynamics ex-
ploits the derivative of w in simulating the position of
a particle, this ensures that the derivative exists “often
enough” for the Hamiltonian integrator to be used.)
3 For almost every inﬁnite real-valued sequence q, there
is a k such that w is positive on q1...k. (This ensures the
extend subroutine in Alg. 3 terminates almost surely.)

Remark 2. (i) NP-HMC is a generalisation of HMC to non-
parametric models. Precisely, NP-HMC specialises to stan-
dard HMC (with the leapfrog integrator) in case the density
function w satisﬁes Dom(w) = Rn for some n, in addition
to Assumptions 1, 2 and 3.

(ii) All closed integrable almost surely terminating pro-
grams of a universal PPL4 induce densities that satisfy As-
sumptions 1, 2 and 3. (See App. A and Lem. 12 for an
account.)

≥0 is q ↦ ∑n

Truncations The surfaces on which the particle is posi-
tioned are derived from a sum of appropriate restrictions
of the input TR function w, deﬁned as follows. The n-th
truncation w≤n ∶ Rn → R
k=1 w(q1...k), which
returns the cumulative sum of the weight on the preﬁxes
of an n-dimensional trace q. Thanks to the preﬁx property,
for each q, at most one summand is non-zero. So any real-
valued w≤n-supported sequence q ∈ Rn has a preﬁx in the
support of w; and any w-supported sequence of length n is
also w≤n-supported.

We deﬁne a family U = {Un}n∈N of potential energies
where each Un ∶ Rn ⇀ R
≥0 is a partial function deﬁned
as Un ∶= − log w≤n with domain Dom(Un) ∶= Supp(w≤n).
These are the surfaces on which the particle is positioned.

Proposal step The nonparametric (NP) integrator ΨNP
(Alg. 2) proposes a state by simulating the Hamiltonian
motion of a particle at position q ∈ Rn, with potential energy
Un(q) and a randomly chosen momentum p ∈ Rn.5 The
simulation runs L discrete update steps (also called leapfrog
steps) of size (cid:15) > 0, or until the particle leaves the domain of
Un (i.e. the support of w≤n). At that moment, the simulation
stops and NP-HMC “extends” the state (q, p) via the extend
subroutine (Alg. 3), until the position of the particle falls
into the domain of some potential energy (i.e. support of
some higher dimensional truncation).6 Once the extended
position of the particle is settled, simulation resumes. If no
extension is necessary, the behaviour is the same as that of
the standard HMC leapfrog integrator.

Extend The heart of NP-HMC is the extend subroutine
(Alg. 3). Suppose extend is called after i position steps
and i − 1/2 momentum steps are completed, i.e., at time
t = i (cid:15). If q is in the domain of U∣q∣, extend leaves the state
unchanged; otherwise q is not long enough and the while
loop extends it as follows.

• Sample a pair (x0, y0) of real numbers from the stan-

dard normal distribution respectively.

• Trace the motion of a particle with constant potential
energy 1 for i position and i − 1/2 momentum steps,
starting from (x0, y0), to obtain (x, y). Notice that

4An almost surely terminating program (as deﬁned in App. A)

almost never observes a value with zero probability density.

5The Hamiltonian motion is almost always deﬁned, by Ass. 2.
6This happens almost surely, thanks to Ass. 3.

Nonparametric Hamiltonian Monte Carlo

Algorithm 1 NP-HMC Step

∣q0∣

Input: current sample q0, density function w, step size
(cid:15), number of steps L
Output: next sample q
p0 ∼ N
U = {Un ∶= λq. − log(w≤n(q))}n∈N
((q, p), (q0, p0)) = ΨNP((q0, p0), U, (cid:15), L)
if U(0, 1) < min (1, w≤∣q∣(q) ϕ2∣q∣(q++p)
w≤∣q∣(q0) ϕ2∣q∣(q0++p0)
return q1...k where w(q1...k) > 0

{Initialise}

) then

else

return q0

1...k where w(q0

1...k) > 0

end if

Algorithm 2 NP Integrator ΨNP

Input: current state (q0, p0), family of potential energies
U = {Un}n∈N, step size (cid:15), number of steps L
Output: new state (q, p), extended initial state (q0, p0)
(q, p) = (q0, p0)
{Initialise}
for i = 0 to L do
p = p − (cid:15)
∇U∣q∣
2
q = q + (cid:15) p
((q, p), (q0, p0)) = extend((q, p), (q0, p0), i (cid:15), U )
p = p − (cid:15)
2

{1/2 momentum step}
{1 position step}

{1/2 momentum step}

∇U∣q∣

(q)

(q)

end for
return ((q, p), (q0, p0))

Algorithm 3 extend

Input: current state (q, p), initial state (q0, p0), time t,
family of potential energies U = {Un}n∈N
Output: extended state (q, p), extended initial state
(q0, p0)
while q ∉ Dom(U∣q∣
x0 ∼ N1; y0 ∼ N1
(x, y) = (x0 + t y0, y0)
(q0, p0) = (q0 ++ [x0], p0 ++ [y0])
(q, p) = (q ++ [x], p ++ [y])

{sample from normal}
{run for time t}
{update initial}
{update current}

) do

end while
return ((q, p), (q0, p0))

Figure 4. Pseudocode for Nonparametric Hamiltonian Monte Carlo

the momentum update is simply the identity, hence we
only need to consider i position updates which takes x
to x0 + t y0.

• Append (x0, y0) to the initial state (q0, p0) and (x, y)

to the current state (q, p).

Thus the length of the position q is incremented, and by As-
sumption 3, this loop terminates almost surely at a position
q in the domain of the potential energy of dimension ∣q∣.

Putting them together A single NP-HMC iteration, as
shown in Alg. 1, produces a proposed sample q from the
current sample q0, by applying the NP integrator ΨNP to
the state (q0, p0) with a freshly sampled momentum p0.
The proposed state (q, p) is then accepted with probability
given by the Hastings acceptance ratio.
Remark 3. The preﬁx property of the input TR function w
plays an important role in the NP-HMC inference algorithm.
If Alg. 1 returns q as the next sample, then for any exten-
sion q′ of q, we have w(q′) = 0, and so, all such q′ are
(q)). If the
irrelevant for inference (because U∣q′∣
preﬁx property weren’t satisﬁed, the algorithm would fail to
account for the weight on such q′.

(q′) = U∣q∣

Other extensions and efﬁciency considerations We
have presented a version of NP-HMC that eschews run-
time efﬁciency in favour of clarity. An advantage of such
a presentation (in deliberately puriﬁed form) is that it be-
comes easy to see that the same method is just as applicable
to such HMC variants as reﬂective/refractive HMC (Afshar
& Domke, 2015) and discontinuous HMC (Nishimura et al.,
2020); we call the respective extensions NP-RHMC and
NP-DHMC. For details, see App. B.2.

Several efﬁciency improvements to NP-HMC are possible.
If the density function is given by a probabilistic program,
one can interleave its execution with extend, by gradually
extending q at every encountered sample statement. Simi-
larly, the truncations w≤n don’t require an expensive sum-
mation to compute. For details, see App. B.3.

Our implementation (Sec. 5) also improves the extend func-
tion (Alg. 3): it not only extends a trace q if necessary, it
also trims it to the unique preﬁx q′ of q with positive w(q′).
This version works better in our experiments. For details,
see App. B.3.

4. Correctness

The NP-HMC algorithm is correct in the sense that the
generated Markov chain converges to the target distribution
ν ∶ A ↦ 1
Z ∫A w dµT with normalising constant Z. We
present an outline of our proof here. The full proof can be
found in App. C.

Invariant distribution By iterating Alg. 1, the NP-HMC
algorithm generates a Markov chain {q(i)}i∈N on the tar-
get space T. The ﬁrst step to correctness is to show that
the invariant distribution of this chain is indeed the target
distribution.

This proof is non-trivial, since the length of the generated
sample depends on the values of the random samples drawn
in the extend subroutine (Alg. 3). To work around this,
we deﬁne an auxiliary algorithm, which induces the same

Nonparametric Hamiltonian Monte Carlo

Markov chain as NP-HMC, but does not increase the di-
mension dynamically. Instead, it ﬁnds the smallest N such
that all intermediate positions in the L leapfrog steps stay in
the domain of UN , and performs leapfrog steps as in stan-
dard HMC. In this algorithm, all stochastic primitives are
executed outside of the Hamiltonian dynamics simulation,
and the simulation has a ﬁxed dimension. Hence we can
proceed to identify the invariant distribution. We then show
(in Lem. 28 and Thm. 4) that the Markov chain generated by
this auxiliary algorithm has the target distribution ν as its in-
variant distribution, and hence the same holds for NP-HMC
(Alg. 1).

Theorem 4. Given Assumptions 1, 2 and 3, the target dis-
tribution ν is the invariant distribution of the Markov chain
generated by iterating Alg. 1.

Convergence
In App. C.4, we extend the proof of Can-
ces et al. (2007) to show that the chain converges for a
small enough step size (cid:15), as long as the following additional
assumptions are met:

(C1) w is continuously differentiable on a non-null set A

with measure-zero boundary.

(C2) w∣Supp(w) is bounded below by a positive constant.
(C3) For each n, the function ∇w≤n
w≤n

is uniformly bounded

from above and below on Supp(w≤n) ∩ A.

(C4) For each n, the function ∇w≤n
w≤n

is Lipschitz continuous

on Supp(w≤n) ∩ A.

Theorem 5. If Assumptions (C1)–(C4) are satisﬁed in addi-
tion to Assumptions 1, 2 and 3, the Markov chain generated
by iterating Alg. 1 converges to the target distribution ν.

5. Experiments

We implemented the NP-HMC algorithm and its variants
(NP-RHMC and NP-DHMC) in Python, using PyTorch
(Paszke et al., 2019) for automatic differentiation. We imple-
mented it from scratch rather than in an existing system be-
cause NP-DHMC needs additional information about each
sample (does the density function depend discontinuously
on it?), so it requires a deeper integration in the proba-
bilistic programming system. In our empirical evaluation,
we focus on the NP-DHMC algorithm because it inherits
discontinuous HMC’s efﬁcient handling of discontinuities:
contrary to NP-RHMC, it does not need to compute the
intersections of the particle’s trajectory with the regions of
discontinuity. Our implementation also uses the efﬁciency
improvements discussed in App. B.3. The code for our im-
plementation and experiments is available at https://
github.com/fzaiser/nonparametric-hmc and
archived as (Zaiser & Mak, 2021).

We compare our implementation with Anglican’s (Wood
et al., 2014) inference algorithms that are applicable out-of-

Table 1. Total variation distance from the ground truth for the ge-
ometric distribution, averaged over 10 runs. Each run: 103 NP-
DHMC samples with 102 burn-in, 5 leapfrog steps of size 0.1; and
5 × 103 LMH, PGibbs and RMH samples.

method

ours

LMH

PGibbs

RMH

TVD

0.0136

0.0224

0.0158

0.0196

the-box to nonparametric models: lightweight Metropolis-
Hastings (LMH), particle Gibbs (PGibbs) and random-walk
lightweight Metropolis-Hastings (RMH).7 NP-DHMC per-
forms more computation per sample than its competitors
because it evaluates the density function in each of the L
leapfrog steps, not just once like the other inference algo-
rithms. To equalise the computation budgets, we generate L
times as many samples for each competitor algorithm, and
apply thinning (taking every L-th sample) to get a compara-
ble sample size.

Geometric distribution A classic example to illustrate
recursion in a universal PPL is sampling from a geo-
metric distribution with parameter p by repeatedly ﬂip-
ping a biased coin with probability p (see e.g. Ch. 5 in
(van de Meent et al., 2018)). The pseudocode for it is:

def geometric():

if sample(uniform(0, 1)) < p: return 1
else: return 1 + geometric()

We tested our algorithm on this problem with p = 0.2. Our
implementation works well on this example and has no trou-
ble jumping between traces of different length. To quantify
this, we computed the total variation distance to the ground
truth for each approach and report it in Table 1. The result is
perhaps surprising given that the odds are “stacked against”
NP-DHMC in this model: it is a discrete model, so there is
no gradient information, and there are no observations (only
sampling from the prior). These properties should favour
the competitors, making the performance of NP-DHMC
rather remarkable.

Random walk To better evaluate our algorithm on proba-
bilistic programs with unbounded loops (such as the ex-
ample from Sec. 2), we considered the one-sided ran-
dom walk on R
≥0 described in (Mak et al., 2021): A
pedestrian starts from a random point in [0, 3] and walks
a uniformly random distance of at most 1 in either
direction, until they pass 0. Given a (noisily) mea-
sured total distance of 1.1 travelled, what is the poste-
rior distribution of the starting point? As this process
has inﬁnite expected running time, we need a stopping

7We also compared Interacting Particle MCMC (IPMCMC),
but it performed consistently worse than PGibbs in our experiments
and hence is omitted.

Nonparametric Hamiltonian Monte Carlo

method

ours

LMH PGibbs

RMH

ESS

679

526

310

508

Figure 5. Kernel density estimate (top) averaged over 10 runs and
estimated effective sample size (bottom) averaged over 10 runs.
Each run: 103 NP-DHMC samples with 102 burn-in, 50 leapfrog
steps of size 0.1; and 5 × 104 LMH, PGibbs and RMH samples.

condition if the pedestrian is too far away from zero,
(distance < 10), as shown in the following pseudocode:

start = sample(uniform(0,3))
position = start; distance = 0
while position > 0 and distance < 10:

step = sample(uniform(−1, 1))
position += step; distance += abs(step)

observe(distance, normal(1.1, 0.1))
return start

This example is interesting and challenging because the
true posterior is difﬁcult to determine precisely. Therefore
we took 107 importance samples (effective sample size ≈
4.4 × 105) and considered those as the ground truth. As one
can see from Fig. 5, NP-DHMC comes closest. Since it is
not clear what measure to use for the distance from these
“ground truth” samples, we instead computed the effective
sample size8 for each method (Fig. 5). Our method does
best in that regard as well.

The popular PPL Pyro accepts nonparametric models as
input. We therefore tried to ascertain the performance of
its HMC implementation on this example. We ran both
Pyro’s HMC sampler (with the same hyperparameters as

8We used the standard ESS estimator (based on weighted
samples) for the ground-truth importance samples, and an
autocorrelation-based MCMC ESS estimator (Sec. 11.5 in (Gel-
man et al., 2014)) for the rest.

Figure 6. Kernel density estimate for the random walk example
compared to Pyro, averaged over 10 runs. Each run: 103 samples
with 102 burn-in, 50 leapfrog steps of size 0.1.

ours) and Pyro’s No-U-Turn sampler (NUTS) (Hoffman
& Gelman, 2014), which aims to automatically infer good
hyperparameter settings. The inferred posterior distributions
(Fig. 6) are far away from the ground truth, and clearly
wrong. Pyro’s inference was very slow, sometimes taking
almost a minute to produce a single sample. For this reason,
we didn’t run more experiments with it.

Gaussian mixture model We also considered the follow-
ing mixture model adapted from (Zhou et al., 2020), where
the number of mixture components K is unbounded.

K ∼ Poisson(10) + 1
µk ∼ Uniform([0, 100]3)

for k = 1, . . . , K

xn ∼

1
K

K
∑
k=1

N3(µk, 102I3)

for n = 1, . . . , N

This model samples parameters θ = (K ∈ N, µk ∈ [0, 100]3)
and N data points X = {x1, . . . , xN } ⊆ R3. Note that this
model uses much higher standard deviations (10 instead
of 0.1) for the Gaussian mixture components compared to
(Zhou et al., 2020). This is to avoid typical problems of
MCMC algorithms with multimodal distributions, which is
an issue inherent to MCMC algorithms and tangential to
this work. We used this model to generate N = 200 training
1...K∗ ). We let our
data points for a ﬁxed θ∗ = (K ∗ = 9, µ∗
inference algorithms sample from p(θ ∣ X) and compared
the posterior on the number of mixture components K with
the other inference algorithms. The histogram (Fig. 7) shows

0.00.51.01.5starting point0.00.20.40.60.81.0posterior densitymethodoursLMHPGibbsRMHground truth0.00.51.01.52.02.5starting point0.00.20.40.60.81.01.2posterior densitymethodoursPyro HMCPyro NUTSground truthNonparametric Hamiltonian Monte Carlo

Figure 7. Histogram of the no. of mixtures for the GMM example; correct posterior = 9, averaged over 10 runs. Each run: 103 NP-DHMC
samples with 102 burn-in, 50 leapfrog steps of size 0.05; and 5 × 104 LMH, PGibbs and RMH samples.

Figure 8. LPPD for the GMM example, averaged over 10 runs.
Each run: 103 NP-DHMC samples with 102 burn-in, 50 leapfrog
steps of size 0.05; and 5 × 104 LMH, PGibbs and RMH samples.
The shaded area is one standard deviation. PGibbs (with ﬁnal
LPPD −716.85 ± 0.64) is omitted to show the top contenders
clearly.

Figure 9. LPPD for the DPMM example, averaged over 10 runs.
Each run: 102 NP-DHMC samples with 50 burn-in, 20 leapfrog
steps of size 0.05; and 2 × 103 LMH, PGibbs and RMH samples.
The shaded area is one standard deviation. PGibbs (with ﬁnal
LPPD −725.96 ± 9.83) is omitted to show the top contenders
clearly.

that NP-DHMC usually ﬁnds the correct number of mixture
components (K ∗ = 9).

In addition, we computed the log pointwise predictive
density (LPPD) for a test set with N ′ = 50 data points
Y = {y1, . . . , yN ′ }, generated from the same θ∗ as the train-
ing data. The LPPD is deﬁned as ∑N ′
i=1 log ∫ p(yi ∣ θ)p(θ ∣
X)dθ and can be approximated by ∑N ′
M ∑M
i=1 log 1
j=1 p(yi ∣
θj) where (θj)j=1...M are samples from p(θ ∣ X) (Gelman
et al., 2014). The results (Fig. 8) include the “true” LPPD
of the test data under the point estimate θ∗. As we can
see, NP-DHMC outperforms the other methods and has the
lowest variance over multiple runs.

Dirichlet process mixture model Finally, we consider
a classic example of nonparametric models: the Dirichlet
process DP(α, H) (Ferguson, 1973), which is a stochastic
process parametrised by concentration parameter α > 0 and
a probability distribution H. For practical purposes, one can
think of samples from DP(α, H) as an inﬁnite sequence
(wk, hk)n∈N where wn are weights that sum to 1 and hn
are samples from H. Conceptually, a DP Gaussian mixture
model takes the form

(wk, hk)k∈N ∼ DP(α, H)

xn ∼

∞
∑
k=1

wk ⋅ N (hk, Σ)

for n = 1, . . . , N

Sampling from a DP is usually implemented by the stick-
breaking method (Sethuraman, 1994). However, one can-

456789101112131415161718number of mixture components0.00.10.20.30.40.5posterior densitymethodoursLMHPGibbsRMH200040006000800010000number of samples−679−678−677−676−675log pointwise predictive densitymethodoursLMHRMHground truth2004006008001000number of samples−688−686−684−682−680−678−676log pointwise predictive densitymethodoursLMHRMHground truthNonparametric Hamiltonian Monte Carlo

not actually compute an inﬁnite sequence. A practical
workaround is to cap the number of mixture components
by a ﬁxed K and only consider (wk, hk)k=1,...,K.9 This
renders the model parametric, enabling the use of standard
HMC. However such a treatment is clearly unsatisfactory:
if the data actually requires more mixture components than
K, the model would be found wanting.

We propose a different approach. Instead of choosing a
ﬁxed K, we allow it to depend on the weights wk: we pick
the minimal K ∈ N such that ∑K
i=1 wi > 1 − (cid:15) for some
(cid:15) > 0. With this restriction, we only discard insigniﬁcant
mixture components (with a weight wk < (cid:15)) and allow as
many mixture components as necessary to model the data
accurately. This model is not parametric anymore, but still
tractable by our algorithm.

We implemented the above model with the parameters α = 5,
(cid:15) = 0.01, and the remaining parameters as chosen in the
previous GMM example, i.e. H = Uniform([0, 100]3) and
Σ = 102I3. We used the same training and test data as in
the previous GMM example and present the LPPD results
in Fig. 9. As we can see, NP-DHMC outperforms the other
methods and has the lowest variance over multiple runs.

6. Related Work and Conclusion

The standard MCMC algorithm for PPLs that is widely im-
plemented (for example, in Anglican, Venture, and Web
PPL) is the Lightweight Metropolis-Hastings (LMH) algo-
rithm and its extensions (Yang et al., 2014; Tolpin et al.,
2015; Ritchie et al., 2016), which performs single-site up-
dates on the current sample and re-executes the program.
Unlike NP-HMC, where Hamiltonian motion is simulated
on the resulting extended trace, LMH suffers from a lack of
predictive accuracy in its proposal (as shown in Sec. 5).

The Reversible Jump Markov chain Monte Carlo (RJM-
CMC) algorithm (Green, 1995) is similar to NP-HMC in
that it is a trans-dimensional MCMC sampler. However,
NP-HMC is a general purpose inference algorithm that
works out-of-the-box when given an input density function,
whereas RJMCMC additionally requires the user to specify
a transition kernel. Various RJMCMC transition kernels
have been suggested for speciﬁc models, e.g. split-merge
proposal for inﬁnite Gaussian mixture models.

Some PPLs such as Hakaru, Pyro and Gen give users the
ﬂexibility to hand-code the proposal in a MCMC setting.
For instance, Cusumano-Towner et al. (2020) implement
the split-merge proposal (Richardson & Green, 1997) of
RJMCMC in Gen. Though this line of research is orthog-
onal to ours, PPLs such as Gen could play a useful role in

9For

instance,

see https://pyro.ai/examples/
dirichlet process mixture.html (accessed: 2021-06-
06), the Pyro tutorial on DP mixture models.

the implementation of NP-HMC and similar extensions of
inference algorithms to nonparametric models.

The HMC algorithm and its variants, notably the No-U-
Turn Sampler, are the workhorse inference methods in the
inﬂuential PPL Stan (Gelman et al., 2015). The challenges
posed by stochastic branching in PPLs are the focus of
reﬂective/refractive HMC (Afshar & Domke, 2015); discon-
tinuous HMC (Nishimura et al., 2020); mixed HMC (Zhou,
2020); and the ﬁrst-order PPL in (Zhou et al., 2019) which
is equipped with an implementation of discontinuous HMC.
By contrast, our work is an attempt to tackle the language
constructs of branching and recursion.

Unlike Monte Carlo methods, variational inference (VI)
(Blei et al., 2017) solves the Bayesian inference problem
by treating it as an optimisation problem. When adapted
to models expressed as probabilistic programs, the score
function VI (Ranganath et al., 2014) can in principle be
applied to a large class of branching and recursive programs
because only the variational density functions need to be
differentiable. Existing implementations of VI algorithms
in probabilistic programming systems are however far from
automatic: in the main, the guide programs (that express
variational distributions) still need to be hand-coded.

Recently, Zhou et al. (2020) introduced the Divide, Conquer,
and Combine (DCC) algorithm, which is applicable to pro-
grams deﬁnable using branching and recursion. As a hybrid
algorithm, DCC solves the problem of designing a proposal
that can efﬁciently transition between conﬁgurations by per-
forming local inferences on submodels, and returning an
appropriately weighted combination of the respective sam-
ples. Thanks to a judicious resource allocation scheme, it
exhibits strong performance on multimodal distributions.

Conclusion

We have presented the NP-HMC algorithm, the ﬁrst exten-
sion of the HMC algorithm to nonparametric models. We
have proved that NP-HMC is correct. We have also empir-
ically demonstrated that it enjoys signiﬁcant performance
improvements over state-of-the-art MCMC algorithms for
universal PPLs on four nonparametric models, thereby il-
lustrating that the key advantage of HMC—the proposal of
moves to distant states with a high acceptance probability—
has been preserved by NP-HMC.

Acknowledgements We thank the reviewers for their in-
sightful feedback and pointing out important related work.
We are grateful to Hugo Paquet, Dominik Wagner and Yuan
Zhou, who gave detailed comments on an early draft, and
to Tom Rainforth and Arnaud Doucet for their helpful com-
ments and advice. We gratefully acknowledge support from
the EPSRC and the Croucher Foundation.

Nonparametric Hamiltonian Monte Carlo

References

Afshar, H. M. and Domke, J. Reﬂection, refraction, and
Hamiltonian Monte Carlo. In Cortes, C., Lawrence, N.,
Lee, D., Sugiyama, M., and Garnett, R. (eds.), Advances
in Neural Information Processing Systems (NIPS 2015),
volume 28, pp. 3007–3015. Curran Associates, Inc., 2015.

Betancourt, M. A conceptual introduction to hamilto-
arXiv, 2018. URL https://

nian monte carlo.
arxiv.org/abs/1701.02434.

Bingham, E., Chen, J. P., Jankowiak, M., Obermeyer, F.,
Pradhan, N., Karaletsos, T., Singh, R., Szerlip, P., Hors-
fall, P., and Goodman, N. D. Pyro: Deep universal prob-
abilistic programming. Journal of Machine Learning
Research, 20(28):1–6, 2019.

Blei, D. M., Kucukelbir, A., and McAuliffe, J. D. Varia-
tional inference: A review for statisticians. Journal of
the American Statistical Association, 112(518):859–877,
2017.

Borgstr¨om, J., Dal Lago, U., Gordon, A. D., and Szymczak,
M. A lambda-calculus foundation for universal proba-
bilistic programming. In Garrigue, J., Keller, G., and
Sumii, E. (eds.), Proceedings of the 21st ACM SIGPLAN
International Conference on Functional Programming
(ICFP 2016), pp. 33–46. Association for Computing Ma-
chinery, 2016.

Bou-Rabee, N. and Sanz-Serna, J. M. Geometric integra-
tors and the Hamiltonian Monte Carlo method. Acta
Numerica, 27:113–206, 2018.

Cances, E., Legoll, F., and Stoltz, G. Theoretical and numer-
ical comparison of some sampling methods for molecular
dynamics. ESAIM: Mathematical Modelling and Numer-
ical Analysis, 41(2):351–389, 2007.

Culpepper, R. and Cobb, A. Contextual Equivalence for
probabilistic programs with continuous Random Vari-
In Yang, H. (ed.), Proceedings of
ables and scoring.
the 26th European Symposium on Programming (ESOP
2017), volume 10201 of Lecture Notes in Computer Sci-
ence, pp. 368–392. Springer, 2017.

Cusumano-Towner, M., Lew, A. K., and Mansinghka, V. K.
Automating involutive MCMC using probabilistic and
differentiable programming. arXiv, 2020. URL https:
//arxiv.org/abs/2007.09871.

Cusumano-Towner, M. F., Saad, F. A., Lew, A. K., and
Mansinghka, V. K. Gen: A general-purpose probabilistic
programming system with programmable inference. In
McKinley, K. S. and Fisher, K. (eds.), Proceedings of
the 40th ACM SIGPLAN Conference on Programming
Language Design and Implementation (PLDI 2019), pp.
221–236. Association for Computing Machinery, 2019.

Duane, S., Kennedy, A., Pendleton, B. J., and Roweth, D.
Hybrid Monte Carlo. Physics Letters B, 195(2):216–222,
1987.

Ferguson, T. S. A Bayesian analysis of some nonparametric
problems. The Annals of Statistics, 1(2):209 – 230, 1973.

Ge, H., Xu, K., and Ghahramani, Z. Turing: Compos-
able inference for probabilistic programming. In Storkey,
A. J. and P´erez-Cruz, F. (eds.), Proceedings of the 21st
International Conference on Artiﬁcial Intelligence and
Statistics (AISTATS 2018), volume 84, pp. 1682–1690.
PMLR, 2018.

Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B.,
Vehtari, A., and Rubin, D. B. Bayesian data analysis.
Texts in Statistical Science Series. CRC Press, 3rd edition,
2014.

Gelman, A., Lee, D., and Guo, J. Stan: A probabilistic pro-
gramming language for Bayesian inference and optimiza-
tion. Journal of Educational and Behavioral Statistics,
40(5):530–543, 2015.

Goodman, N. D. and Stuhlm¨uller, A. The Design and Im-
plementation of Probabilistic Programming Languages.
http://dippl.org, 2014. Accessed: 2021-5-24.

Goodman, N. D., Mansinghka, V. K., Roy, D. M., Bonawitz,
K., and Tenenbaum, J. B. Church: A language for gen-
erative models. In McAllester, D. A. and Myllym¨aki, P.
(eds.), Proceedings of the 24th Conference in Uncertainty
in Artiﬁcial Intelligence (UAI 2008), pp. 220–229. AUAI
Press, 2008.

Green, P. J.

Reversible jump Markov chain Monte
Carlo computation and Bayesian model determination.
Biometrika, 82(4):711–732, 1995.

Hoffman, M. D. and Gelman, A. The No-U-turn sampler:
adaptively setting path lengths in Hamiltonian Monte
Carlo. Journal of Machine Learning Research, 15(1):
1593–1623, 2014.

Hur, C., Nori, A. V., Rajamani, S. K., and Samuel, S.
A provably correct sampler for probabilistic programs.
In Harsha, P. and Ramalingam, G. (eds.), Proceedings
of the 35th IARCS Annual Conference on Foundations
of Software Technology and Theoretical Computer Sci-
ence, (FSTTCS 2015), volume 45 of LIPIcs, pp. 475–
488. Schloss Dagstuhl - Leibniz-Zentrum f¨ur Informatik,
2015.

Kudlicka, J., Murray, L. M., Ronquist, F., and Sch¨on, T. B.
Probabilistic programming for birth-death models of evo-
lution using an alive particle ﬁlter with delayed sampling.
In Globerson, A. and Silva, R. (eds.), Proceedings of the
35th Conference on Uncertainty in Artiﬁcial Intelligence,
(UAI 2019, volume 115, pp. 679–689. AUAI Press, 2019.

Nonparametric Hamiltonian Monte Carlo

Mak, C., Ong, C. L., Paquet, H., and Wagner, D. Densities
of almost surely Terminating probabilistic programs are
differentiable almost Everywhere. In Yoshida, N. (ed.),
Proceedings of the 30th European Symposium on Pro-
gramming (ESOP 2021), volume 12648 of Lecture Notes
in Computer Science, pp. 432–461. Springer, 2021.

Manning, C. and Sch¨utze, H. Foundations of Statistical

Natural Language Processing. MIT Press, 1999.

Mansinghka, V. K., Selsam, D., and Perov, Y. N. Venture:
a higher-order probabilistic programming platform with
programmable inference. arXiv, 2014. URL http://
arxiv.org/abs/1404.0099.

Murray, L. M., Lund´en, D., Kudlicka, J., Broman, D., and
Sch¨on, T. B. Delayed sampling and automatic Rao-
blackwellization of probabilistic programs. In Storkey,
A. J. and P´erez-Cruz, F. (eds.), Proceedings of the Inter-
national Conference on Artiﬁcial Intelligence and Statis-
tics (AISTATS 2018), volume 84, pp. 1037–1046. PMLR,
2018.

Narayanan, P. and Shan, C.-c. Symbolic disintegration
with a variety of base measures. ACM Transactions on
Programming Languages and Systems, 42(2):1–60, 2020.

Neal, R. M. MCMC using Hamiltonian dynamics.

In
Brooks, S., Gelman, A., Jones, G., and Meng, X.-L. (eds.),
Handbook of Markov Chain Monte Carlo, chapter 5, pp.
113–162. Chapman & Hall CRC Press, 2011.

Nishimura, A., Dunson, D. B., and Lu, J. Discontinuous
Hamiltonian Monte Carlo for discrete parameters and
discontinuous likelihoods. Biometrika, 107(2):365–380,
2020.

Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J.,
Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga,
L., Desmaison, A., Kopf, A., Yang, E., DeVito, Z., Rai-
son, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang,
L., Bai, J., and Chintala, S. Pytorch: An imperative style,
high-performance deep learning library. In Wallach, H.,
Larochelle, H., Beygelzimer, A., d'Alch´e-Buc, F., Fox,
E., and Garnett, R. (eds.), Advances in Neural Informa-
tion Processing Systems (NeurIPS 2019), volume 32, pp.
8024–8035. Curran Associates, Inc., 2019.

Ranganath, R., Gerrish, S., and Blei, D. M. Black box vari-
ational inference. In Kaski, S. and Corander, J. (eds.),
Proceedings of the 17th International Conference on Ar-
tiﬁcial Intelligence and Statistics (AISTATS 2014), vol-
ume 33, pp. 814–822. PMLR, 2014.

Ratner, B. Variable selection methods in regression: Ig-
norable problem, outing notable solution. Journal of
Targeting, Measurement and Analysis for Marketing, 18:
65–75, 2010.

Richardson, S. and Green, P. J. On Bayesian analysis of
mixtures with an unknown number of components (with
discussion). Journal of the Royal Statistical Society: Se-
ries B (Statistical Methodology), 59(4):731–792, 1997.

Ritchie, D., Stuhlm¨uller, A., and Goodman, N. D. C3:
lightweight incrementalized MCMC for probabilistic pro-
grams using continuations and callsite caching. In Gret-
ton, A. and Robert, C. C. (eds.), Proceedings of the 19th
International Conference on Artiﬁcial Intelligence and
Statistics (AISTATS 2016), volume 51, pp. 28–37. PMLR,
2016.

Ronquist, F., Kudlicka, J., Senderov, V., Borgstr¨om, J., Lar-
tillot, N., Lund´en, D., Murray, L., Sch¨on, T. B., and
Broman, D. Universal probabilistic programming offers
a powerful approach to statistical phylogenetics. Commu-
nications Biology, 4(244), 2021.

Sch¨utte, C. Conformational dynamics: Modelling, theory,
algorithm, and application to biomolecules. Technical
report, Freie Universit¨at Berlin, 1999.

Scott, D. S. A type-theoretical alternative to ISWIM, CUCH,
OWHY. Theoretical Computer Science, 121(1&2):411–
440, 1993.

Sethuraman, J. A constructive deﬁnition of Dirichlet priors.

Statistica Sinica, 4(2):639–650, 1994.

Sieber, K. Relating full abstraction Results for different
programming languages. In Nori, K. V. and Madhavan, C.
E. V. (eds.), Proceedings of the 10th Annual Conference
on Foundations of Software Technology and Theoretical
Computer Science (FSTTCS 1990), volume 472 of Lec-
ture Notes in Computer Science, pp. 373–387. Springer,
1990.

Tierney, L. Markov Chains for exploring posterior distribu-
tions. The Annals of Statistics, 22(4):1701–1728, 1994.

Tolpin, D., van de Meent, J., Paige, B., and Wood, F. D.
Output-sensitive adaptive Metropolis-Hastings for proba-
bilistic programs. In Appice, A., Rodrigues, P. P., Costa,
V. S., Gama, J., Jorge, A., and Carlos Soares (eds.), Pro-
ceedings of Machine Learning and Knowledge Discov-
ery in Databases - European Conference Part II (ECML
PKDD 2015), volume 9285 of Lecture Notes in Computer
Science, pp. 311–326. Springer, 2015.

V´ak´ar, M., Kammar, O., and Staton, S. A domain theory for
statistical probabilistic programming. Proceedings of the
ACM on Programming Languages, 3(36):1–29, 2019.

van de Meent, J., Paige, B., Yang, H., and Wood, F. An
introduction to probabilistic programming. arXiv, 2018.
URL http://arxiv.org/abs/1809.10756.

Nonparametric Hamiltonian Monte Carlo

Verlet, L. Computer “experiments” on classical ﬂuids. i.
thermodynamical properties of lennard-jones molecules.
Physical Review, 159(1):98–103, 1967.

Wingate, D., Stuhlm¨uller, A., and Goodman, N. D.
Lightweight implementations of probabilistic program-
ming languages via transformational compilation. In Gor-
don, G. J., Dunson, D. B., and Dud´ık, M. (eds.), Proceed-
ings of the 14th International Conference on Artiﬁcial
Intelligence and Statistics (AISTATS 2011), volume 15,
pp. 770–778. PMLR, 2011.

Wood, F. D., van de Meent, J., and Mansinghka, V. A
new approach to probabilistic programming inference. In
Kaski, S. and Corander, J. (eds.), Proceedings of the 17th
International Conference on Artiﬁcial Intelligence and
Statistics (AISTATS 2014), volume 33, pp. 1024–1032.
PMLR, 2014.

Yang, L., Hanrahan, P., and Goodman, N. D. Generating
efﬁcient MCMC kernels from probabilistic programs. In
Kaski, S. and Corander, J. (eds.), Proceedings of the 17th
International Conference on Artiﬁcial Intelligence and
Statistics (AISTATS 2014), volume 33, pp. 1068–1076.
PMLR, 2014.

Zaiser, F. and Mak, C. Artifact for ”Nonparametric Hamil-
tonian Monte Carlo” (ICML 2021), June 2021. URL
https://doi.org/10.5281/zenodo.4897900.

Zhou, G. Mixed Hamiltonian Monte Carlo for mixed
discrete and continuous variables.
In Larochelle, H.,
Ranzato, M., Hadsell, R., Balcan, M. F., and Lin, H.
(eds.), Advances in Neural Information Processing Sys-
tems (NeurIPS 2020), volume 33, pp. 17094–17104. Cur-
ran Associates, Inc., 2020.

Zhou, Y., Gram-Hansen, B. J., Kohn, T., Rainforth, T., Yang,
H., and Wood, F. LF-PPL: a low-level ﬁrst order prob-
abilistic programming language for non-differentiable
models. In Chaudhuri, K. and Sugiyama, M. (eds.), Pro-
ceedings of the 22nd International Conference on Ar-
tiﬁcial Intelligence and Statistics (AISTATS 2019), vol-
ume 89, pp. 148–157. PMLR, 2019.

Zhou, Y., Yang, H., Teh, Y. W., and Rainforth, T. Divide,
conquer, and combine: a new inference strategy for proba-
bilistic programs with stochastic support. In Proceedings
of the 37th International Conference on Machine Learn-
ing, (ICML 2020), volume 119, pp. 11534–11545. PMLR,
2020.

Nonparametric Hamiltonian Monte Carlo (Appendix)

A. Statistical PCF

In this section, we present a simply-typed statistical probabilistic programming language with (stochastic) branching and
recursion, and its operational semantics.

This language serves two purposes for the NP-HMC algorithm. First, it is a puriﬁed universal probabilistic programming
language (PPL) widely considered (Borgstr¨om et al., 2016; V´ak´ar et al., 2019; Mak et al., 2021) which speciﬁes tree-
representable functions that satisﬁes Ass. 1, 2 and 3 (Prop. 7 and Lem. 12) and hence NP-HMC can be applied. Second, its
(operational) semantics is used to prove correctness of NP-HMC in App. C.

A.1. Syntax

SPCF is a simply-typed higher-order universal PPL with branching and recursion. More formally, it is a statistical
probabilistic version of call-by-value PCF (Scott, 1993; Sieber, 1990) with reals as the ground type. The terms and part of
the typing system of SPCF are presented in Fig. 10. Free variables and closed terms are deﬁned in the usual way. In the
interest of readability, we sometimes use pseudocode (e.g. Listing 1) in the style of Python to express SPCF terms.

There are two probabilistic constructs of SPCF: the sampling construct normal draws from N , the standard Gaussian
distribution with mean 0 and variance 1; the scoring construct score(M ) enables conditioning on observed data by
multiplying the weight of the current execution with the real number denoted by M . Note this is not limiting as the standard
uniform distribution with endpoints 0 and 1 can be described as cdfNormal(normal) where cdfNormal is the cumulative
distribution function (cdf) of the standard normal distribution. And any real-valued distribution with inverse cdf f can be
described as f (cdfNormal(normal)).
Remark 6. The main difference between our variant of SPCF and the others (V´ak´ar et al., 2019; Mak et al., 2021) is that our
sampling construct draws from the standard normal distribution instead of the standard uniform distribution. This does not
restrict nor extend our language and is only considered since the target (parameter) space of the standard HMC algorithm
matches that of the support of a standard n-dimensional normal distribution.

Types (typically denoted σ, τ ) and terms (typically M, N, L):

σ, τ ∶∶= R ∣ σ ⇒ τ

M, N, L ∶∶= y ∣ r ∣ λy.M ∣ M N ∣ if(L ≤ 0, M, N ) ∣ f (M1, . . . , M(cid:96)) ∣ YM ∣ normal ∣ score(M )

Typing system:

Γ ⊢ normal ∶ R

Γ ⊢ M ∶ R
Γ ⊢ score(M ) ∶ R

Γ ⊢ M ∶ (σ ⇒ τ ) ⇒ (σ ⇒ τ )
Γ ⊢ YM ∶ σ ⇒ τ

Figure 10. Syntax of SPCF, where r ∈ R, x, y are variables, and f ∶ Rn
functions.

→ R ranges over a set F of partial, measurable primitive

A.2. Operational Semantics

The small-step reduction of SPCF is standard (see Borgstr¨om et al. (2016)). We present it as a rewrite system of conﬁgura-
tions, which are triples of the form ⟨M, w, t⟩ where M is a closed SPCF term, w ∈ R
≥0 is a weight, and t ∈ T a trace, as
deﬁned in Fig. 11.

Values (typically denoted V ), redexes (typically R) and evaluation contexts (typically E):

Nonparametric Hamiltonian Monte Carlo

V ∶∶= r ∣ λy.M
R ∶∶= (λy. M ) V ∣ if(r ≤ 0, M, N ) ∣ f (r1, . . . , r(cid:96)) ∣ Y(λy. M ) ∣ normal ∣ score(r)
E ∶∶= [] ∣ E M ∣ (λy.M ) E ∣ if(E ≤ 0, M, N ) ∣ f (r1, . . . , ri−1, E, Mi+1, . . . , M(cid:96)) ∣ YE ∣ score(E)

Redex contractions:

⟨(λy.M ) V, w, t⟩ —→ ⟨M [V /y], w, t⟩

⟨f (r1, . . . , r(cid:96)), w, t⟩ —→

⎧⎪⎪
⟨f (r1, . . . , r(cid:96)), w, t⟩
⎨
⎪⎪⎩
fail

if (r1, . . . , r(cid:96)) ∈ Dom(f ),
otherwise.

⟨Y(λy.M ), w, t⟩ —→ ⟨λz.M [Y(λy.M )/y] z, w, t⟩

(for fresh variable z)

⟨if(r ≤ 0, M, N ), w, t⟩ —→

⎧⎪⎪
⟨M, w, t⟩
⎨
⎪⎪⎩
⟨N, w, t⟩

if r ≤ 0,
otherwise.

⟨normal, w, t⟩ —→ ⟨r, w, t ++ [r]⟩

⟨score(r), w, t⟩ —→

⎧⎪⎪
⟨r, r ⋅ w, t⟩
⎨
⎪⎪⎩
fail

if r > 0,
otherwise.

(for some r ∈ R)

Evaluation contexts:

⟨R, w, t⟩ —→ ⟨R′, w′, t′⟩
⟨E[R], w, t⟩ —→ ⟨E[R′], w′, t′⟩

⟨R, w, t⟩ —→ fail
⟨E[R], w, t⟩ —→ fail

Figure 11. Operational small-step semantics of SPCF

In the rule for normal, a random value r ∈ R is generated and recorded in the trace, while the weight remains unchanged:
even though the program samples from a normal distribution, the weight does not factor in Gaussian densities as they are
already accounted for by µT. In the rule for score(r), the current weight is multiplied by r ∈ R: typically this reﬂects the
likelihood of the current execution given some observed data. Similarly to (Borgstr¨om et al., 2016) we reduce terms which
cannot be reduced in a reasonable way (i.e. scoring with nonpositive constants or evaluating functions outside their domain)
to fail.

We write —→+ for the transitive closure of —→, and —→∗ for the reﬂexive and transitive closure of —→.

A.2.1. VALUE AND WEIGHT FUNCTIONS.
Recall the measure space of traces T ∶= ⋃n∈N Rn is equipped with the standard disjoint union σ-algebra ΣT ∶= {⋃n∈N Un ∣
Un ∈ Bn}, with measure given by summing the respective (higher-dimensional) normals µT(⋃n∈N Un) ∶= ∑n∈N Nn(Un).
Following Borgstr¨om et al. (2016), we write Λ to denote the set of all SPCF terms and view it as ⋃n∈N(SKn × Rn) where
SKn is the set of SPCF terms with exactly n numerals place-holders. The measurable space of terms is equipped with the
σ-algebra ΣΛ that is the Borel algebra of the countable disjoint union topology of the product topology of the discrete
topology on SKn and the standard topology on Rn. Similarly the subspace Λ0
v of closed values inherits the Borel algebra on
Λ.
Let M be a closed SPCF term. Its value function valueM ∶ T → Λ0
program, if the program terminates in a value. The weight function weightM ∶ T → R
corresponding execution. Formally:

v ∪ {(cid:150)} returns, given a trace, the output value of the
≥0 returns the ﬁnal weight of the

valueM (t) ∶=

⎧⎪⎪
V
⎨
⎪⎪⎩
(cid:150)

if ⟨M, 1, []⟩ —→∗ ⟨V, w, t⟩
otherwise

weightM (t) ∶=

⎧⎪⎪
w if ⟨M, 1, []⟩ —→∗ ⟨V, w, t⟩
⎨
⎪⎪⎩
0

otherwise

It follows already from (Borgstr¨om et al., 2016) that the functions valueM and weightM are measurable.

Finally, every closed SPCF term M has an associated value measure

Nonparametric Hamiltonian Monte Carlo

M

(cid:74)

(cid:75)

∶ ΣΛ0

v

—→ R

≥0

U z→ ∫

valueM

−1

(U )

weightM dµT

This corresponds to the denotational semantics of SPCF in the ω-quasi-Borel space model via computational adequacy
(V´ak´ar et al., 2019).

Proposition 7. Every closed SPCF term has a tree representable weight function.

Proof. Assume M is a closed SPCF term and q ∈ Suppn(weightM ). The reduction of M must be ⟨M, 1, []⟩ —→∗ ⟨V, w, q⟩
for some value V and weight w > 0. Assume for contradiction that there is some k < n where ⟨M, 1, []⟩ —→∗ ⟨V ′, w′, q1...k⟩
for some value V ′ and weight w′ > 0. Since q1...k is a preﬁx of q and —→ is deterministic if the trace is given, we must
have ⟨M, 1, []⟩ —→+ ⟨V ′, w′, q1...k⟩ —→+ ⟨V, w, q⟩ , which contradicts the fact that V ′ is a value.

A.3. Almost-sure Termination

Deﬁnition 8. We say that a SPCF term M terminates almost surely if M is closed and µT({t ∈ T ∣ ∃V, w . ⟨M, 1, []⟩ —→∗
⟨V, w, t⟩}) = 1;

The following proposition is used in Prop. 24 to support the correctness proof.

Proposition 9. The value measure
(cid:74)
score(−) as a subterm is probabilistic.

M

(cid:75)

of a closed almost surely terminating SPCF term M which does not contain

One of the main contribution of (Mak et al., 2021) is to ﬁnd a suitable class of primitive functions such that their main
theorem (Lem. 10) holds.
For our purposes, we take the set of analytic functions with co-domain R as our class F of primitive functions which, as
shown in Example 3 of (Mak et al., 2021), satisﬁes the conditions for which the following lemma holds.

Lemma 10 (Mak et al. (2021), Theorem 3). Let M be an SPCF term which terminates almost surely. Then its weight
function weightM and value function valueM are differentiable almost everywhere.
Deﬁnition 11. We say that a SPCF term M is integrable if M is closed and its value measure is ﬁnite, i.e.

(Λ0

M

v) < ∞;

(cid:74)

(cid:75)

We conclude with the following lemma which shows that NP-HMC is an adequate inference algorithm for closed SPCF
terms.

Lemma 12. The weight function of a closed integrable almost surely terminating SPCF term satisﬁes Assumptions 1, 2 and
3 of the NP-HMC algorithm.

Proof. Let M be a closed integrable almost surely terminating SPCF term, and w be its weight function. w is tree
representable by Prop. 7. Integrability of w (Assumption 1) is given as an assumption, and w is almost everywhere
continuously differentiable (Assumption 2) by Lem. 10.

Assume for contradiction that Assumption 3 does not hold. i.e. There is a non-null set U of inﬁnite real-valued sequence
where w is zero on all preﬁxes of sequences in U . Let Up ∶= {q1...k ∣ q ∈ U, k ∈ N} be the set of preﬁxes of sequences in
U . Since U is non-null, Up must also be non-null. Moreover, w is zero on all traces in Up. By the deﬁnition of weight
function, q ∈ Up implies ⟨M, 1, []⟩ /—→∗ ⟨V, w′, q⟩ for some V and w′. Hence, the probability of a non-terminating run of
M is non-zero and M is not almost surely terminating.

Remark 13. The weight function as deﬁned in App. A.2.1 is the input density function of the target distribution to which an
inference algorithm typically samples from. In this paper, we call this function the “weight function” when considering
semantics following (Culpepper & Cobb, 2017; V´ak´ar et al., 2019; Mak et al., 2021), and use the notion “density” when
referring it in an inference algorithm similar to (Zhou et al., 2019; 2020; Cusumano-Towner et al., 2020).

B. Hamiltonian Monte Carlo Algorithm and its Variants

Nonparametric Hamiltonian Monte Carlo

Hamiltonian Monte Carlo (HMC) algorithm (Duane et al., 1987; Cances et al., 2007; Neal, 2011) is a Markov chain
Monte Carlo inference algorithm that generates samples from a continuous (ﬁnite) distribution ν on the measure space
(Rn, Bn, Lebn), where Bn denotes the Borel σ-algebra.

B.1. HMC Algorithm

To generate a Markov chain {qi}i∈N of samples from ν, HMC simulates the Hamiltonian motion of a particle on the negative
logarithm of the density function of ν with some auxiliary momentum. Hence regions with high probability in ν have low
potential energy and are more likely to be visited by the simulated particle. In each iteration, the particle is given some
random momentum. We formalise the algorithm here.

B.1.1. HAMILTONIAN DYNAMICS

Say ρ ∶ Rn → R is the (not necessarily normalized) probability density function of ν. The simulated particle has two
types of energies: potential energy U ∶ Rn → R given by U (q) ∶= − log ρ(q) and kinetic energy K ∶ Rn → R given
by K(p) ∶= − log pdfD(p) where D is some momentum distribution, typically a n-dimensional normal distribution.
Henceforth, we take K(p) ∶= ∑n
i=1
The Hamiltonian H ∶ Rn × Rn → R
i.e.

p2
2 .
i
≥0 of a system is deﬁned quite simply to be the sum of the potential and kinetic energies,

H(q, p) ∶= U (q) + K(p).

The trajectories {(qt, pt)}t≥0, where qt and pt are the position and momentum of the particle at time t respectively, deﬁned
by the Hamiltonian H, can be determined by the Hamiltonian equations:

dq(t)
dt

∶=

∂H
∂p

(q(t), p(t)) = ∇K(p(t)) = p(t)

and

dp(t)
dt

∶= −

∂H
∂q

(q(t), p(t)) = −∇U (q(t)).

with initial conditions (q(0), p(0)) = (q0, p0).
The canonical distribution (also called Boltzmann-Gibbs distribution) π on the measure space (Rn × Rn, ΣRn×Rn , Leb2n)
corresponding to H is given by the probability density function

ζ(q, p) ∶=

1
Z

exp (−H(q, p)) =

1
Z

exp (−U (q) − K(p))

where Z ∶= ∫

Rn

ρ dLebn

B.1.2. THE ALGORITHM

Since computers cannot simulate continuous motions like Hamiltonian, the equations of motion are generally numerically
integrated by the leapfrog method (also called the velocity-Verlet algorithm (Verlet, 1967)):

pn+1/2 = pn − (cid:15)/2 ⋅ ∇U (qn)
qn+1 = qn + (cid:15) ⋅ pn+1/2
pn+1 = p(n+1)/2 − (cid:15)/2 ⋅ ∇U (qn+1)

where (cid:15) is the time step.
The integrator Ψn ∶ Rn × Rn → Rn × Rn as given in Alg. 4, takes a state (q, p) and performs L leapfrog steps with initial
condition (q0, p0) ∶= (q, p) and time step (cid:15), and return the state (qL, −pL).
Proposition 14 (Bou-Rabee & Sanz-Serna (2018), Theorem 4.1 and 4.2). The integrator Ψn is volume preserving
−1) on Rn × Rn.
(i.e. Ψn∗Leb2n = Leb2n) and reversible (i.e. Ψn = Ψn

k (q, p) = (q, p − k∇U (q)), and φQ

k ∶ R2n → R2n be the transition of momentum and position variables with step size k respectively,
k (q, p) = (q + k∇K(p), p). Hence, we can write the integrator Ψn as the

k , φQ

Proof. Let φP
i.e. φP
composition S ○ φP

(cid:15)/2 ○ φQ

(cid:15) ○ φP

(cid:15)/2, where S(q, p) ∶= (q, −p).

Nonparametric Hamiltonian Monte Carlo

Algorithm 5 HMC Step

Algorithm 4 HMC Integrator Ψn

Input: current state (q0, p0), potential energy U ,
step size (cid:15), number of steps L
Output: new state (q, p)
(q, p) = (q0, p0)
for i = 0 to L do
p = p − (cid:15)
2
q = q + (cid:15) p
p = p − (cid:15)
2

{1/2 momentum step}
{1 position step}
{1/2 momentum step}

{initialise}

∇U (q)

∇U (q)

end for
p = −p
return (q, p)

Input: current sample q0, potential energy U , step
size (cid:15), number of steps L
Output: next sample q
p0 ∼ Nn
(q, p) = Ψn((q0, p0), U, (cid:15), L)
if U(0, 1)a < min{1, ζ(q,p)
ζ(q0,p0)

{Kick}
{Integrate}

} then
{MH acceptance ratio}

return q

else

return q0

end if

a

U(0, 1) is the standard uniform distribution.

(cid:15) ○ φP

(cid:15)/2 ○ φQ

k ○ S and (φQ

It is easy to see that (φP
S ○ φP

k )−1 = S ○ φP
(cid:15)/2 = Ψn and Ψn is reversible.
Similarly it is easy to see that the shear transformations φP
i.e. φP
Leb2n(Ψn

k (D), φQ

k )−1

= S ○ φQ

−1(D)) = Leb2n(Ψn(D)) = Leb2n(D) and Ψn is volume preserving.

k and momentum ﬂip S preserves measure on R2n,
k (D), S(D) and D have the same measure for all measurable set D in R2n. Hence, (Ψn∗Leb2n)(D) =

k , φQ

k ○ S. Hence, Ψn

−1 = (φP

(cid:15)/2)−1 ○ (φQ

(cid:15) )−1 ○ (φP

(cid:15)/2)−1 ○ S =

Alg. 5 shows how HMC generates a sample from the current one q0. It ﬁrst performs leapfrog steps on (q0, p0) via the
integrator Ψn with a randomly chosen initial momentum p0. The result (q, p) of Ψn is then accepted with probability
min{1, ζ(q,p)
}. Note that if Hamiltonian is preserved (i.e. H(q, p) = H(q0, p0)), the acceptance probability is one and
ζ(q0,p0)
the proposal will always be accepted.

A Markov chain {qi}i∈N is generated by iterating Alg. 5.

B.1.3. CORRECTNESS

The HMC algorithm is only effective if its generated Markov chain {qi}i∈N does converge to the target distribution ν. Here
we consider the typical convergence result of the total variation norm for the probability measure generated.
Formally, we say a Markov chain {qi}i∈N converges to the target distribution ν on Rn if

∀q ∈ Rn,

lim
m→∞

∥Qm(q, −) − ν∥ = 0,

where Qm(q, A) is the probability for which the Markov chain is in A ∈ Bn after m steps starting at q ∈ Rn and ∥−∥ denotes
the total variation norm on Rn (i.e. ∥µ∥ ∶= supA∈Bn µ(A) − inf A∈Bn µ(A)).
Here we present the necessary conditions to prove such a result for the HMC algorithm. Let Q ∶ Rn × Bn → R
≥0 be the
transition kernel speciﬁed by Alg. 5, so that Q(q, A) is the probability for which the next sample returned by Alg. 5 is in
A ∈ Bn given the current sample is q ∈ Rn. We write Qm to be m compositions of Q. (i.e. Q0(q, A) ∶= [q ∈ A]; for k > 0,
Qk+1(q, A) ∶= ∫Rn Qk(q′, A) Q(q, dq′)).

First, we make sure that ν is the invariant distribution of the Markov chain.
Proposition 15 (Bou-Rabee & Sanz-Serna (2018), Theorem 5.2). ν is invariant against Q.

While showing ν is the invariant distribution for the Markov chain is relatively simple, we would be wrong to think that
convergence follows trivially. In fact, as shown in the following example, the Markov chain can easily be periodic.
Example 16 (Bou-Rabee & Sanz-Serna (2018), Example 5.1). Consider the case where the target distribution is a
(unnormalised) one-dim. normal distribution. In particular say the potential energy is U (q) ∶= q2/2. Then, the Hamiltonian
ﬂow (H(q, p) = U (q) + K(p) = q2/2 + p2/2) is a rotation in the (q, p)-plane with period 2π. If the duration of the simulation
is π, the exact ﬂow returns q1 = −q0.

There are known conditions for which HMC converges to the right distribution (Sch¨utte, 1999). Here we follow the treatment
given by Cances et al. (2007).

Nonparametric Hamiltonian Monte Carlo

Results from (Tierney, 1994; Borgstr¨om et al., 2016) tell us that it is enough to show that the transition kernel Q is strongly
ν-irreducible: for all a and B, ν(B) > 0 implies Q(a, B) > 0.
Lemma 17 (Cances et al. (2007), Lemma 2 and 3 (Strong irreducibility)). Assume U is continuously differentiable, bounded
above on Rn and ∇U is globally Lipschitz. Then the transition kernel Q is strongly ν-irreducible.
Lemma 18 (Borgstr¨om et al. (2016), Lemma 33 (Aperiodicity)). A strongly ν-irreducible transition kernel is also ν-
aperiodic.

Lemma 19 (Tierney (1994), Theorem 1 and Corollary 2). If the transition kernel Q with invariant distribution ν is
ν-irreducible and ν-aperiodic, then for all q, limn→∞
Theorem 20. If U is continuously differentiable, bounded above on Rn and ∇U is globally Lipschitz, the Markov chain
generated by iterating Alg. 5 converges to the target distribution ν.

∥Qn(q, −) − ν∥ = 0.

B.2. HMC Variants

B.2.1. REFLECTIVE/REFRACTIVE HMC

Reﬂective/refractive HMC (RHMC) (Afshar & Domke, 2015) is an extension of HMC that improves its behaviour for
discontinuous density functions. Standard HMC is correct for such distributions as well, but the acceptance probability may
be very low and convergence extremely slow.
We need to quickly discuss what discontinuities mean in our setting: In addition to discontinuities of each Un ∶ Rn → R
itself, we also regard it as a discontinuity when q leaves the support of Un, since this means that a different branch in the
tree representing function is chosen. The set of these discontinuities is ∂Supp(w), i.e. the boundary of the support of the
density function.

Fortunately, the extension of RHMC to our nonparametric setting is straightforward. The algorithm is described in Alg. 6.
The only relevant difference is the need for an extend call in the algorithm.

The rest of the algorithm is the same as (Afshar & Domke, 2015): It uses two additional functions that deal with the
discontinuities of U : decompose and nextBoundary. Just like in (Afshar & Domke, 2015), we assume that these are given
to the algorithm because their implementation depends on the kind of discontinuities in the density function. In the original
paper, they only consider discontinuities that are given by afﬁne subspaces.
The function nextBoundary(q, p, T, U ) takes a position q ∈ Rn, a momentum p ∈ Rn, a time limit T > 0, and family of
potential energies {Un}n∈N. It then checks whether a particle starting at q moving with momentum p will hit a discontinuity
of U in time ≤ T . If so, it returns the time t of “impact”, the position q
just after the
discontinuity.

just before the discontinuity and q

<

>

The function decompose(q, p, U ) takes a position q on the discontinuity, a momentum p, and U as before. It then
decomposes the momentum p into a component p

that is parallel to the discontinuity and p

that is perpendicular to it.

∥

⊥

The basic idea of the algorithm is inspired by reﬂection and refraction in physics. We simulate the trajectory of a particle
according to Hamiltonian dynamics. When hitting a discontinuity, we compute the potential difference. If the kinetic energy
is big enough to overcome it, refraction occurs: the perpendicular component of p is scaled down. Otherwise, the particle is
reﬂected.

The only difference to the original algorithm in (Afshar & Domke, 2015) is the call to extend. Why is it necessary? When
hitting a discontinuity (and only then!), we may have to switch to a different branch on the tree representing the density
function. Hence we may have to extend the position q> just after the discontinuity, which is why we call extend on it.

B.2.2. LAPLACE MOMENTUM AND DISCONTINUOUS HMC

The Hamiltonian Monte Carlo method usually uses Gaussian momentum because it corresponds to the physical interpretation
of kinetic energy being 1
i for a momentum vector p. Nishimura et al. (2020) propose to use Laplace momentum
where the kinetic energy for a momentum vector p is given by ∑i ∣pi∣. This means that the momentum vector must follow
a Laplace distribution, denoted as L(0, 1), with density proportional to ∏i exp(−∣pi∣). Hamilton’s equations have to be
changed to

2 ∑i p2

dq
dt

= sign(p),

= −∇qU.

dp
dt

Algorithm 6 NP-RHMC Integrator ΨNP−R

Nonparametric Hamiltonian Monte Carlo

Input: current state (q0, p0), family of potential energies
{Un}n∈N, step size (cid:15), number of steps L
Output: new state (q, p) computed according to Hamil-
tonian dynamics, extended initial state (q0, p0)
(q, p) = (q0, p0)
for i = 0 to L do
p = p − (cid:15)
2
t = 0
while nextBoundary(q, p, (cid:15) − t, U ) exists do
) = nextBoundary(q, p, (cid:15) − t, U )

{1/2 momentum step}
{start of position step}

{initialise}

∇U∣q0∣

(q)

0)) = extend((q

, p), (q0, p0), i(cid:15) +

>

) = decompose(q′, p′, U )
∥p

∥2 − 2∆U p⊥
∥p⊥∥

⊥

{refraction}

<

>

0, p′

(t′, q
, q
t = t + t′
((q′, p′), (q′
t, U )
∆U = (U∣q′∣
∥2 > 2∆U then
if ∥p
⊥
(p
, p
∥
=
p
⊥
q = q′

√
⊥

(q′) − U∣q<∣

(q

<

))

) = decompose(q

else
(p
, p
∥
⊥
= −p
p
⊥
q = q

<

⊥

+ p

end if
p = p
⊥
end while
q = q + ((cid:15) − t)p
p = p − (cid:15)
∇U∣q∣
2

∥

(q)

end for
p = −p
return ((q, p), (q0, p0))

, p, U )

<

{reﬂection}

{rest of position step}
{1/2 momentum step}

Algorithm 7 extend for NP-DHMC

Input: current state (q, p), initial state (q0, p0), time
t, family of potential energies U = {Un}n∈N family of
potential energies {Un}n∈N, step size (cid:15), number of steps L
Output: extended current state (q, p), extended initial
state (q0, p0)
while q /∈ Dom(U∣q∣
x0 ∼ N (0, 1)
if ∣q∣ + 1 ∈ C then
y0 ∼ N (0, 1)

{Gaussian for continuous params}

) do

Algorithm 8 NP-DHMC Integrator ΨNP−Dis

Input: current state (q0, p0), family of potential energies
{Un}n∈N, step size (cid:15), number of steps L, discontinuous
coordinates D
Output: new state (q, p) computed according to Hamil-
tonian dynamics, extended initial state (q0, p0)
(q, p) = (q0, p0)
q′ = q0
p′ = p0
N = ∣q0∣
for i = 0 to L do
pC = pC − (cid:15)
∇qC UN (q)
2
qC = qC + (cid:15)
2 pC
for j ∈ randomlyPermute(D) do

{initialise}

if j < ∣q∣ then

{∣q∣ may have changed, so must check j < ∣q∣}
((q, p), (q′, p′)) =

coordIntegrator((q, p), (q′, p′), j, i(cid:15), (cid:15))

end if
end for
N = ∣q∣
qC = qC + (cid:15)
2 pC
pC = pC − (cid:15)
∇qC UN (q)
2

end for
p = −p
return ((q, p), (q′, p′))

j + (cid:15)sign(pj)

function coordIntegrator((q, p), (q′, p′), j, t, (cid:15))
q∗ = q
j = q∗
q∗
((q∗, p∗), (q′∗, p′∗)) = extend((q∗, p∗), (q′, p′), t, U )
∆U = U (q∗) − U (q)
if ∣pi∣ > ∆U then

{enough kinetic energy to jump}

(q, p) = (q∗, p∗)
(q′, p′) = (q′∗, p′∗)
pi = pi − sign(pi)∆U

else

pi = −pi

{not enough kinetic energy, reﬂect}

else

y0 ∼ L(0, 1)

{Laplace for discontinuous ones}

end if
return ((q, p), (q′, p′))

end if
(x, y) = (x0 + t y0, y0)
(q0, p0) = (q0 ++ [x0], p0 ++ [y0])
(q, p) = (q ++ [x], p ++ [y])

{update to current time t}

{increment dimension}

end while
return ((q, p), (q0, p0))

Nonparametric Hamiltonian Monte Carlo

Note that the time derivative of q only depends on the sign of the pi’s. Hence, if the sign does not change, the change of q
(q). The integrator of discontinuous HMC (Nishimura et al.,
can be computed, irrespective of the intermediate values of U∣q∣
2020) takes advantage of this for “discontinuous parameters”, i.e. parameters that U is not continuous in. Thus it can jump
through multiple discontinuities of U without evaluating it at every boundary.

We adapt the integrator from (Nishimura et al., 2020) to NP-HMC. Following them, we assume for simplicity that each
coordinate of the position space either corresponds to a continuous or discontinuous parameter, irrespective of which
path is chosen. The set C records all the continuous parameters and D = N ∖ C the discontinuous ones. We use a
Gaussian distribution for the continuous parameters of the momentum vector and a Laplace distribution for the discontinuous
parameters. Our integrator updates the continuous coordinates by half a step size just as before, but then the discontinuous
ones are updated coordinate by coordinate, a technique called operator splitting. Afterwards, the continuous coordinates are
updated by half a step size again. Algorithm 8 contains all the details.

Again, the main difference to the original algorithm is a call to extend. Note we also have to modify the extend function
itself (given in Alg. 7) because some momentum coordinates have to be sampled from a Laplace distribution, and not a
Gaussian as before.

B.3. Efﬁciency Improvements

As touched upon in the main text, our implementation includes various performance improvements compared to the
pseudocode presentation of NP-HMC.

(i) The extend function (Alg. 3) as presented may seem inefﬁcient. While it terminates almost surely (thanks to Assump-
tion 3), the expected number of iterations may be inﬁnite. In practice, however, the density function w will arise from a
probabilistic program, such as Listing 1. Therefore, to evaluate w, it would be natural to run the program. The length of q
returned by extend is exactly the number of sample statements encountered during the program’s execution. In particular, if
the program has ﬁnite expected running time, then the same is true of extend.

(ii) On top of that, efﬁcient implementations of NP-HMC will interleave the execution of the program with extend, by
gradually extending q (if necessary) at every encountered sample statement. This way, extend increases the running time
only by a small constant factor.
(iii) In a similar vein, we do not have to compute the sum w≤n(q) = ∑n
k=1 w(q1...k) each time Un = − log w≤n is accessed.
By the preﬁx property, only one of the summands of w≤n(q) is actually nonzero. Moreover, if w is given by a probabilistic
program, then the weight computed during the execution of the program on q is exactly this nonzero summand, assuming
that the trace q is long enough for a successful run (which the extend function ensures).

(iv) Another notable way our implementation differs from the algorithm presented above is that it not only extends a trace q
in extend (if necessary), but also trims it (if necessary) to the unique preﬁx q′ of q with positive w(q′). The dimension of p
is adjusted accordingly. This seems to work much better for certain examples, such as the geometric distribution described
in Sec. 5. The reason is most likely that the unused sufﬁx (which may have been adapted to the state before the current call
of extend) is a hindrance when trying to extend to a different state later on.

C. Proof of Correctness

In this section, we show that the NP-HMC algorithm is correct, in the sense that the Markov chain generated by iterating
Alg. 1 converges to the target distribution ν ∶ A ↦ 1

Z ∫A w dµT where Z ∶= ∫T w dµT.

Henceforth, we assume that the density function w of the target distribution ν is tree-representable and satisﬁes Assumptions
1, 2 and 3.

C.1. An Equivalent Algorithm

We write Alg. 1 as the program NPHMCstep (Alg. 2 as NPint and Alg. 3 as extend) in Listing 2. We present input sample as
q0; the density function as w and deﬁne potential energy U , which is a family of partial functions, as a function U, such that
U(n) is a partial function denoting Un; step size as ep; and number of steps as L. We also assume the following primitive
functions are implemented: normal is the sampling construct in the language which samples a real number from the standard
normal distribution N1. domain(f) gives the domain of the partial function f. pdfN(x,n) gives the probability density of x

Nonparametric Hamiltonian Monte Carlo

on the standard n-dimensional normal distribution. cdfN(x) gives the cumulative distribution of x on the standard normal
distribution. grad(f,x) gives the gradient of the partial function f at x if deﬁned and None if not.
The program NPHMC generates a Markov chain on T by iterating NPHMCstep .

Instead of a direct proof, we consider an auxiliary program eNPHMC equivalent to NPHMC (in the sense of Prop. 22), which
does not increase the dimension dynamically; instead it ﬁnds the smallest N such that all intermediate positions during the
L leapfrog steps stay in the domain of UN , and performs leapfrog steps as in standard HMC.

The program eNPHMC is given in Listing 4, which iterates eNPHMCstep to generate a Markov chain on states and then
marginalise it using the helper function supported to obtain a Markov chain on T. The program validstate determines
whether the input state (q0,p0) goes beyond the domain of the potential energy U in L leapfrog steps, and the program
HMCint is the leapfrog integrator of the standard HMC algorithm.
Remark 21. Programs in Listings 2 to 4 are given in Python syntax, but they can be translated into SPCF. First, note we can
represent pairs and lists using Church encoding as follows:

Pair(σ, τ ) ∶= σ → τ → (σ → τ → R) → R

⟨M, N ⟩ ≡ λz.z M N

List(σ) ∶= (σ → R → R) → (R → R)
[M1, . . . , M(cid:96)] ≡ λf x.f M1(f M2 . . . (f M(cid:96) 0))

Hence a state (q, p) ∈ R(cid:96) × R(cid:96) can be encoded as a value [⟨q1, p1⟩, . . . , ⟨q(cid:96), p(cid:96)⟩] with type List(Pair(R, R)).
Now we look at all the primitive functions used in the programs. It is easy to see that cdfN, pdfN and log are analytic
functions. len, append and sum can be deﬁned on Church lists. grad can be deﬁned using the simple numerical differentiation
method using analytic functions like subtraction and division. We can change domain in such a way that it takes q and
w as inputs and tests whether sum([w(q[:i]) for i in range(len(q))]) is zero (instead of testing whether q is in the
domain of U(len(q))).

Now we give a formal deﬁnition of equivalence. We say two SPCF programs are equivalent if they induce the same value
and weight functions, as speciﬁed in App. A.2.1.

Proposition 22. NPHMC and eNPHMC are equivalent.

Proof. We give an informal explanation here.

First note that NPHMCstep is a Markov process on samples, and eNPHMCstep on states. However, it is easy to see that some
minor changes to NPHMCstep and NPHMC make NPHMCstep a Markov process on states. Precisely, the following does not
alter the meaning of program NPHMC:

(1) Given a state (q0,p0) in NPHMCstep , apply supported to q0 at the start of initialisation and return the state (q0,p0) or

(q,p) at the MH acceptance step.

(2) In NPHMC, add the marginalisation step just like in eNPHMC.

Hence, it is enough to show that all steps in programs NPHMCstep and eNPHMCstep are equivalent, i.e. they give the same
weight and value functions.

After the modiﬁcation, NPHMCstep and eNPHMCstep have the same initialisation and MH acceptance step. So it remains to
show that the NP-HMC integration as described in NPint behaves the same as searching for a valid initial state (step 2) and
HMC integration (step 3) in eNPHMCstep .

In NPHMCstep , ((q,p),(q0,p0)) = NPint((q0,p0),U,ep,L) “integrates” from the initial state (q0,p0) until it goes
beyond the domain of U(len(q0)), at which moment it extends.

While in eNPHMCstep , it increments the dimension of the state (q0,p0) until it has just enough dimension to “integrate” for
time ep *L through U(len(q0)) without going beyond the domain of U(len(q0)). This ensures the state (q0,p0) is safe to
be an input to the standard HMC integrator HMCint.

Notice that given the same values for the samples, the resulting initial state (q0,p0) in NPHMCstep would be the same as
that in eNPHMCstep . Hence, the proposal state (q,p) in both programs would be the same.

Remark 23. The discussion in the proof of Prop. 22 argues informally that NPHMC and eNPHMC are equivalent. We outline a
formal proof here. To show that NPHMC and eNPHMC are equivalent, we ﬁrst demonstrate that one program can be obtained

Nonparametric Hamiltonian Monte Carlo

Listing 2. Python code for NPHMC

def extend((q,p),(q0,p0),t,U):

while q not in domain(U(len(q))):

x0 = normal
y0 = normal
x = x0 + t *y0
y = y0
q0.append(x0)
p0.append(y0)
q.append(x)
p.append(y)

return ((q,p),(q0,p0))

def NPint((q0,p0),U,ep,L):

q = q0
p = p0
for i in range(L):

p = p − ep/2*grad(U(len(q0)),q)
q = q + ep *p
((q,p),(q0,p0)) =

extend((q,p),(q0,p0),i *ep,U)
p = p − ep/2*grad(U(len(q0)),q)

return ((q,p),(q0,p0))

def NPHMCstep(q0,w,ep,L):

# initialisation
p0 = [normal for i in range(len(q0))]
U = lambda n: lambda q:

−log(sum([w(q[:i]) for i in range(n)]))

# NP −HMC integration
((q,p),(q0,p0)) = NPint((q0,p0),U,ep,L)
# MH acceptance
if cdfN(normal) < accept((q,p),(q0,p0),w):

return supported(q,w)

else:

return supported(q0,w)

def NPHMC(q0,w,ep,L,M):

S = [q0]
for i in range(M):

S.append(NPHMCstep(S[i],w,ep,L))

return S

Listing 3. Python code for helper functions

# the MH acceptance ratio
def accept((q,p),(q0,p0),w):

N = len(q)
N trunc = lambda q’:

sum([w(q’[:i]) for i in range(N)])
weight = (N trunc(q) * pdfN((q,p),2N))/

(N trunc(q0) * pdfN((q0,p0),2N))

return min(1,weight)

# the w−supported prefix of q
def supported(q,w):

k = 1
while w(q[:k]) == 0 and k < len(q):

k += 1

return q[:k]

Listing 4. Python code for eNPHMC

def validstate((q0,p0),U,ep,L):

q = q0
p = p0
for i in range(L):

p = p − ep/2*grad(U,q)
q = q + ep *p
if q not in domain(U):

return False

p = p − ep/2*grad(U,q)

return True

def HMCint((q0,p0),U,ep,L):

q = q0
p = p0
for i in range(L):

p = p − ep/2*grad(U,q)
q = q + ep *p
p = p − ep/2*grad(U,q)

# momentum flip
p = −p
return (q,p)

def eNPHMCstep((q0,p0),w,ep,L):

# initialisation (step 1)
q0 = supported(q0,w)
p0 = [normal for i in range(len(q0))]
U = lambda n: lambda q:

−log(sum([w(q[:i]) for i in range(n)]))

# search (step 2)
while not validstate((q0,p0),U(len(q0)),ep

,L):

x0 = normal
y0 = normal
q0.append(x0)
p0.append(y0)

# HMC integration (step 3)
(q,p) = HMCint((q0,p0),U(len(q0)),ep,L)
# MH acceptance (step 4)
if cdfN(normal) < accept((q,p),(q0,p0),w):

return (q,p)

else:

return (q0,p0)

def eNPHMC(q0,w,ep,L,M):

mc = [(q0,0)]
for i in range(M):

mc.append(eNPHMCstep(mc[i],w,ep,L))

# marginalisation
S = [supported(q,w) for (q,p) in mc]
return S

Nonparametric Hamiltonian Monte Carlo

form another by a series of meaning-preserving transformations (i.e. transformations that preserves the value and weight
functions). After that we show that the convergence result (Thm. 5) is invariant over equivalent programs.

Since NPHMC and eNPHMC are equivalent, it is enough to show that eNPHMC is correct, i.e. generates a Markov chain that
converges to the target distribution. We present a three-step proof.
1. We ﬁrst identify the invariant distribution π of the Markov chain {(q(i), p(i))}i∈N generated by iterating eNPHMCstep .

(Eq. (1))

2. We then show that the marginalised chain {f (q(i), p(i))}i∈N is invariant under the target distribution ν, where f (q, p) is

the unique preﬁx of q that has positive weight according to w. (Thm. 4)

3. Finally, we show this chain converges for a small enough step size (cid:15). (Thm. 5)

C.2. Invariant Distribution

By iterating eNPHMCstep , a Markov chain {(q(i), p(i))}i∈N is generated. We now analyse this Markov chain by studying its
invariant distribution π and transition kernel.
Let (S, ΣS, µS) be the state space where S ∶= ⊎n∈N(Rn × Rn), ΣS ∶= {⊎n∈N Un ∣ Un ∈ B2n} and µS(⊎n∈N Un) ∶=
∑n∈N(Nn × Nn)(Un). It is easy to see that all output states in eNPHMCstep , and hence all elements of the Markov chain, is
in S.

However not all states have a positive weight. In fact not even the union of the support of invariant distributions of the ﬁxed
dimension HMC on each of the truncations works. This is because if eNPHMCstep returns (q, p) ∈ R2k, then it cannot return
states of the form (q ++ q′, p ++ p′) ∈ R2n, which is a valid returning state for the ﬁxed dimension HMC. Hence we deﬁne a
subset of states which precisely capture all possible returning states of eNPHMCstep , and deﬁne a distribution on it.

We say a state (q, p) is ((cid:15), L)-valid (or simply valid whenever the parameters (cid:15) and L are clear from the context) if a
particle starting from the state (q, p) does not “fall beyond” the domain of U∣q∣
∶= − log w≤∣q∣ in the course of L discrete
leapfrog steps of size (cid:15), and the states (q1...k, p1...k) are not ((cid:15), L)-valid for all k < n.
Let Svalid denote the set of all valid states and Svalid
The program validstate veriﬁes valid states, i.e validstate always returns True when the input state is valid.
Let π be a distribution on S with density ζ (with respect to µS) given by

∶= Svalid ∩ (Rn × Rn) denote the the set of all n-dimension valid states.

n

ζ(q, p) ∶=

(q)

⎧⎪⎪
1
Z w≤∣q∣
⎨
⎪⎪⎩
0

if (q, p) ∈ Svalid,
otherwise.

(1)

Since the the position component of all valid states must have a w-supported preﬁx, the set of valid states can be written as

Svalid =

∞
⋃
n=1

∞
⋃
m=n

{(q ++ x, y) ∈ Svalid

m ∣ q ∈ Suppn(w), x ∈ Rm−n, y ∈ Rm},

and hence the distribution π can be written as

π ∶ X ↦ ∫

X

[(q, p) ∈ Svalid] ⋅

1
Z

w≤∣q∣

(q) µS(d(q, p)) = ∫

X

[(q, p) ∈ Svalid] ⋅

1
Z

∣q∣
∑
n=1

w(q1...n) µS(d(q, p))

=

∞
∑
n=1

∞
∑
m=n

∫

Rn

∫

Rm−n

∫

Rm

[(q ++ x, y) ∈ X ∩ Svalid

m ] ⋅

1
Z

w(q) Nm(dy) Nm−n(dx) Nn(dq)

(2)

We claim that π is the invariant distribution of the Markov chain determined by eNPHMCstep . The rest of this subsection is
devoted to a proof of the claim.
For any state (q, p) ∈ S, we write
⟩] of type List(Pair(R, R)). Take a
to be the term [⟨q1, p1⟩, . . . , ⟨q
SPCF term M of type {x ∶ List(Pair(R, R))} ⊢ M ∶ List(Pair(R, R)). We deﬁne a function vM ∶ S × T → S such that
(t). Then, the transition kernel kM ∶ S × ΣS → S of M given by
vM (s, t)
(cid:86)

= valueM [
(cid:86)

(q, p)

, p

/x]

∣q∣

∣q∣

(cid:87)

(cid:87)

(cid:86)

(cid:87)

s

kM (s, U ) ∶= ∫

vM (s,−)

−1

(U )

weightM [
(cid:86)

s

(cid:87)

/x]

dµT.

Nonparametric Hamiltonian Monte Carlo

returns the probability of M returning a state in U given the input s.
We say M leaves the distribution µ on S invariant if for all U ∈ ΣS, ∫S kM (s, U ) µ(ds) = µ(U ).

C.2.1. INITIALISATION AND SEARCH (STEPS 1 AND 2)

1...n, t) ∈ X] µT(dt). Note that p0 (of the input state (q0, p0)) is ignored by eNPHMCstep .

Given (q0, p0) ∈ Svalid and X ∈ ΣS, where w(q0
1...n) > 0, the initialisation (step 1) of eNPHMCstep returns a pair of the
w-supported preﬁx of q0 and a randomly drawn momentum. Hence, its transition kernel k1 is given by k1((q0, p0), X) ∶=
∫T [(q0
If the input state (q0, p0) is not a valid state, we have k1((q0, p0), X) = 0. This is required for technical reasons but is
excluded in the program eNPHMCstep for ease of readability. At it stands in Listing 4, eNPHMCstep does not care whether the
input state is valid as long as it has a preﬁx which is w-supported. To deﬁne such a transition kernel for eNPHMCstep , we can
simply call validstate on the input state at the start of initialisation and fail this execution if the input state is not valid.
After that, given (q0, p0) ∈ S and X ∈ ΣS where w(q0
1...n) > 0, step 2 of eNPHMCstep searches for a valid state by
repeating drawing from the standard normal distribution. We can write its transition kernel k2 as k2((q0, p0), X) ∶=
∫T [(q0 ++ todd, p0 ++ teven) ∈ X ∩ Svalid] µT(dt) where todd and teven are subsequences of t containing the values of odd
and even indexes respectively.

For any X ∈ ΣT, the (combined) transition kernel k1,2 of steps 1 and 2 of eNPHMCstep is given by

k1,2((q0, p0), X) = ∫

∫
T

T

[(q0

1...n ++ t′odd, t ++ t′even) ∈ X ∩ Svalid] µT(dt′) µT(dt)

∞
∑
m=n

∫

Rm−n

∫

Rm−n

[(q0

1...n ++ t′′, t ++ t′) ∈ X ∩ Svalid] Nm−n(dt′′) Nm−n(dt′) Nn(dt)

∫

Rm

∫

Rm−n

[(q0

1...n ++ x, y) ∈ X ∩ Svalid] Nm−n(dx) Nm(dy)

= ∫

Rn

=

∞
∑
m=n

if (q0, p0) ∈ Svalid; and k1,2((q0, p0), X) = 0 otherwise.
Proposition 24. The transition kernel is probabilistic, i.e. k1,2((q0, p0), S) = k1,2((q0, p0), Svalid) = 1 for any valid state
(q0, p0) ∈ Svalid.

Proof. Let (q0, p0) ∈ Svalid. We can see k1,2((q0, p0), −) as the value measure of steps 1 and 2 of eNPHMCstep (with the
) which does not contain score(−) as a subterm. Moreover, Assumption 3 ensures
initial states substituted by
step 2 almost always terminates and returns a valid state. Hence, Prop. 9 tells us that k1,2((q0, p0), −) is probabilistic and
k1,2((q0, p0), S) = k1,2((q0, p0), Svalid) = 1.

(q0, p0)
(cid:87)
(cid:86)

Proposition 25. π is invariant with respect to step 1 and 2 of eNPHMCstep .

Proof. We aim to show: ∫S k1,2((q0, p0), X) π(d(q0, p0)) = π(X) for any measurable set X ∈ ΣS.

k1,2((q0, p0), X) π(d(q0, p0)) = ∫

∫

S

Svalid

k1,2((q0, p0), X) π(d(q0, p0))

=

{ Eq. (2), deﬁnition of k1,2 and writing (q0, p0) ∈ Svalid as (q ++ x, y) where q ∈ Supp(w) }

∞
∑
n=1

∞
∑
m=n

∫

Rn

∫

Rm−n

(

∫

Rm

∞
∑
k=n

∫

Rk

∫

Rk−n

[(q ++ x′, y′) ∈ X ∩ Svalid] Nk−n(dx′) Nk(dy′))⋅

([(q ++ x, y) ∈ Svalid] ⋅

1
Z

w(q)) Nm(dy)Nm−n(dx)Nn(dq)

=

{ Rearranging (allowed because everything is nonnegative) }

∞
∑
n=1

∞
∑
k=n

∫

Rn

∫

Rk−n

∫

Rk

[(q ++ x′, y′) ∈ X ∩ Svalid] ⋅

1
Z

w(q)

(

∞
∑
m=n

∫

Rm−n

∫

Rm

[(q ++ x, y) ∈ Svalid] Nm(dy) Nm−n(dx)) Nk(dy′)Nk−n(dx′)Nn(dq)

=

{ Deﬁnition of k1,2 where (ˆq, ˆp) is an arbitrary valid state such that ˆq1...n = q }

Nonparametric Hamiltonian Monte Carlo

∞
∑
n=1

∫

∫

∞
∑
k=n
{ Deﬁnition of ζ and Prop. 24 for some valid state (ˆq, ˆp) }

[(q ++ x′, y′) ∈ X ∩ Svalid] ⋅

Rk−n

Rn

∫

Rk

1
Z

w(q) ⋅ k1,2((ˆq, ˆp), Svalid) Nk(dy′) Nk−n(dx′) Nn(dq)

=

ζ dµS

∫

X

C.2.2. INTEGRATION AND ACCEPTANCE (STEPS 3 AND 4)

Let (q0, p0) ∈ S and X ∈ ΣS. Now we check that the HMC integration (step 3) and acceptance (step 4) preserve the invariant
distribution π.

Similar to HMC, the transition kernel for steps 3 and 4 is given by

k3,4((q0, p0), X) =

⎧⎪⎪
α(q0, p0) ⋅ [Ψ∣q0∣
⎨
⎪⎪⎩
0

(q0, p0) ∈ X] + (1 − α(q0, p0)) ⋅ [(q0, p0) ∈ X]

if (q0, p0) ∈ Svalid,
otherwise.

where α(q0, p0) = min{1, w≤N (q)⋅ϕ2N (q,p)
w≤N (q0)⋅ϕ2N (q0,p0)
Proposition 26. The HMC integrator Ψn with respect to the potential energy Un is volume preserving with respect to Leb2n
−1) on Svalid
(i.e. Ψn∗Leb2n = Leb2n) and reversible (i.e. Ψn = Ψn
n .

} for N = ∣q0∣ and (q, p) = ΨN (q0, p0).

Proof. Since measurable subsets of and states in Svalid
valid states to valid states, Prop. 14 is sufﬁcient.

n

are also in the n-dimension Euclidean Space, and Ψn always map

Proposition 27. π is invariant against integration and acceptance (steps 3 and 4) of eNPHMCstep .

Proof. We aim to show: ∫S k3,4(x, X) π(dx) = π(X) for all X ∈ ΣS. By Prop. 26, for all n, HMC integrator Ψn is volume
preserving against Leb2n and reversible on Svalid

n . Hence, we have

k3,4(x, X) π(dx) = ∫

∫
S

Svalid

k3,4(x, X) π(dx) =

∞
∑
n=1

∫

Svalid
n

k3,4(x, X) ⋅ ζ(x) (Nn × Nn)(dx)

= ∫

X

ζ dµS +

∞
∑
n=1

( ∫

Svalid
n

[Ψn(x) ∈ X ∩ Svalid

n ] ⋅ α(x) ⋅ ζ(x) ⋅ ϕ2n(x) Leb2n(dx)

− ∫

Svalid
n

[x ∈ X ∩ Svalid

n ] ⋅ α(x) ⋅ ζ(x) ⋅ ϕ2n(x) Leb2n(dx))

The second and third integrals are the same since the pushforward measure of Leb2n along the integrator Ψn is the same as
Leb2n (Ψn is volume preserving on Svalid
n ) for all n and α(x) ⋅ ζ(x) ⋅ ϕ2n(x) = α(Ψn(x)) ⋅ ζ(Ψn(x)) ⋅ ϕ2n(Ψn(x)) for all
x ∈ Svalid
(all Ψn are reversible on Svalid
n ).
n

Since the transition kernel P of eNPHMCstep is the composition of k1,2 and k3,4, i.e. P (x, X) ∶= ∫S k3,4(x′, X) k1,2(x, dx′)
for x ∈ S and X ∈ ΣS, and both k1,2 and k3,4 are invariant against π (Propositions 25 and 27), we conclude with the
following lemma.
Lemma 28. π is the invariant distribution of the Markov chain generated by iterating eNPHMCstep .

C.3. Marginalised Markov Chains

It is important to notice that the Markov chain {(qi, pi)}i∈N generated by iterating eNPHMCstep with invariant distribution
π is not the samples we are seeking. The chain we are in fact interested in is the marginalised chain {f (qi, pi)}i∈N where
the measurable10 function f ﬁnds the preﬁx of q which is w-supported, formally deﬁned as

f ∶

Svalid —→ T
(q, p) z→ q1...n

for q1...n ∈ Supp(w).

10For any measurable set A ∈ ΣT, f −1

(A) = ( ⋃

∞
n=1 ⋃

∞

m=n((A ∩ Rn

) × Rm−n

) × Rm

) ∩ Svalid is measurable in S.

This function is realised by the supported program in Listing 3.

Nonparametric Hamiltonian Monte Carlo

In this section we show that this marginalised chain has the target distribution ν as its invariant distribution. Let Q ∶
Supp(w) × ΣT → R
≥0 be the transition kernel of this marginalised chain. We can write it as Q(f (x), A) = P (x, f −1(A))
for x ∈ Svalid and A ∈ ΣT.
Remark 29. In the standard HMC algorithm, the function f would simply be the ﬁrst projection, and it is trivial to check
that the pushforward of the invariant distribution along the ﬁrst projection is exactly the target distribution. Hence this step
tends to be skipped in the correctness proof of HMC (Neal, 2011; Bou-Rabee & Sanz-Serna, 2018).
Lemma 30. Writing Svalid
given by

, we let πn be a probability distribution on measurable space (R2n, B2n, N2n)

Svalid
k

πn(X) ∶= ∫

w≤n(q) N2n(d(q, p))

where Zn ∶= ∫

Rn

w≤n dNn and X ∈ B2n.

≤n ∶= ⋃n
k=1
1
Zn

X

≤n ) → 0 as n → ∞.

(1) π(S ∖ Svalid
(2) For m ≥ n, Zn ⋅ πn = Zm ⋅ e(m,n)
(3) Z ⋅ π = Zn ⋅ g(n)

∗ πn on Svalid

∗

πm on Svalid

≤n where g(n) ∶ Rn × Rn ⇀ Svalid

n where e(m,n) ∶ Rm × Rm → Rn × Rn with e(m,n)(q, p) = (q1...n, p1...n).
≤n such that g(n)(q, p) = (q1...k, p1...k) ∈ Svalid
≤n .

Proof. (1) π is an invariant distribution, and hence it is probabilistic. The sum ∑∞

π(Svalid) must converge. Hence π(S ∖ Svalid

≤n ) = ∑∞

i=n+1 π(Svalid

i

) → 0 as n → ∞.

n=1 π(Svalid

n ) which equals π(⋃∞
n=1

Svalid
n ) =

(2) Simple to show.
(3) Let X be a measurable subset of Svalid

≤n . Then,
n
∑
k=1

Z ⋅ π(X) =

Zk ⋅ πk(X ∩ Svalid

k

) = Zn

n
∑
k=1

e(n,k)
∗

πn(X ∩ Svalid

k

)

= Zn ⋅ πn(

{(q, p) ∈ R2n ∣ (q1...k, p1...k) ∈ X ∩ Svalid

})

k

n
⋃
k=1
∗ πn(X).

= Zn ⋅ g(n)

Theorem 4. Given Assumptions 1, 2 and 3, the target distribution ν is the invariant distribution of the Markov chain
generated by iterating Alg. 1.

Proof. For any A ∈ ΣT, if (1) ν = f∗π on T and (2) µT = f∗µS on Supp(w), then

ν(A) = f∗π(A) = ∫

S

P (x, f −1(A)) µS(dx)

(Lem. 28)

= ∫

= ∫

P (x, f −1(A)) µS(dx) = ∫

Svalid

Svalid

Q(f (x), A) µS(dx)

Supp(w)

Q(q, A) f∗µS(dq) = ∫

Supp(w)

Q(q, A) µT(dq) = ∫

T

Q(q, A) µT(dq).

Hence it is enough to show (1) and (2).
(1) Let A ⊆ Rn be a measurable set on T and δ > 0. Then partitioning f −1(A) = {(q, p) ∈ Svalid ∣ q1...n ∈ A} using Svalid

,

k

we have for sufﬁciently large m,

f∗π(A) = π (

f −1(A) ∩ Svalid

k ) + π (

f −1(A) ∩ Svalid
k )

∞
⋃
k=m+1

m
⋃
k=1
⋅ g(m)

<

≤

Zm
Z
Zm
Z

f −1(A) ∩ Svalid

∗ πm (

m
⋃
k=1
⋅ πm(A × Rm−n × Rm) + δ

k ) + δ

= ν(A) + δ.

(by Lem. 30 (1) and (3))

Nonparametric Hamiltonian Monte Carlo

n=1 ν(A ∩ Rn) = ν(A). Since both ν and
For any measurable set A ∈ ΣT, we have f∗π(A) = ∑∞
π are probability distributions, we also have ν(A) = 1 − ν(T ∖ A) ≤ 1 − f∗π(T ∖ A) = 1 − (1 − f∗π(A)) = f∗π(A).
Hence f∗π = ν on T.

n=1 f∗π(A ∩ Rn) ≤ ∑∞

(2) Similarly, let A ⊆ Suppn(w) be a measurable set on T and δ > 0. Then for sufﬁciently large m, we must have

µS(⋃∞

k=m+1

Svalid
k

) = µS(Svalid ∖ Svalid

≤m ) < δ. Hence,

f∗µS(A) = µS (

k ) + µS (

f −1(A) ∩ Svalid
k )

f −1(A) ∩ Svalid

m
⋃
k=1
N2k(f −1(A) ∩ Svalid

k

) + δ

∞
⋃
k=m+1

N2m({(q, p) ∈ R2m ∣ (q1...k, p1...k) ∈ f −1(A) ∩ Svalid

k

}) + δ

<

=

m
∑
k=1
m
∑
k=1

= N2m(

m
⋃
k=1

{(q, p) ∈ R2m ∣ (q1...k, p1...k) ∈ f −1(A) ∩ Svalid

}) + δ

k

≤ N2m(A × Rm−n × Rm) + δ
= µT(A) + δ.

Then the proof proceeds as in (1).

C.4. Convergence

Last but not least, we check for the convergence of the marginalised chain to the target distribution ν.

As shown in Ex. 16, it is not trivial that the standard HMC algorithm converges. The same can be said of the NP-HMC
algorithm. Recall the conditions on the transition kernel to ensure convergence.
Lemma 19 (Tierney (1994), Theorem 1 and Corollary 2). If the transition kernel Q with invariant distribution ν is
ν-irreducible and ν-aperiodic, then for all q, limn→∞

∥Qn(q, −) − ν∥ = 0.

Recall Q is the transition kernel of the Markov chain generated by iterating Alg. 1 on Supp(w). In Thm. 4, we have shown
that Q has invariant distribution ν. Hence, most of this section is devoted to searching for sufﬁcient conditions (Def. 35) in
order to show that the transition kernel Q is ν-irreducible (Lem. 36) and aperiodic (Lem. 37). We conclude in Thm. 5 that
this Markov chain converges to the target distribution ν.

We start by extending the result in (Cances et al., 2007) in two ways:

1. The density function is only continuously differentiable almost everywhere.
2. The position space is the target space T.

Let U be the collection of measurable subsets of T with the property that their boundary has measure zero. Formally,
U ∶= {A ∈ ΣT ∣ µT(∂A) = 0}. Not every set in ΣT satisﬁes this property. A typical example would be the fat Cantor set. It is
easy to see that U is closed under complementation. Moreover, for any non-null set A in U, its interior ˚A is non-empty.
We assume the density function w ∶ T → R
that the Markov chain can almost surely move between w-supported elements in A.
Lemma 31. Assume w is continuously differentiable on a non-null set A ∈ U and {Un} is uniformly bounded above
(i.e. there is an upper bound M , where Un(q) < M for all q ∈ Dom(Un) for all n ∈ N). For almost all a, b ∈ A ∩ Supp(w),
there exists some k ≥ max {∣a∣, ∣b∣} and p ∈ Rk such that proj1(Ψk(a ++ 01...k−∣a∣, p))1...∣b∣ = b, where proj1(q, p) = q.

≥0 is continuously differentiable on a non-null set A ∈ U. We start by showing

Proof. Deﬁne a function V on the sequence space Rω, which is a Fr´echet space with a family of semi-norms {∥−∥k}k∈N
where ∥x∥k = ∣xk∣, as

V ∶ Rω —→ R

≥0

x z→ − log

w(x1...k).

∞
∑
k=1

Nonparametric Hamiltonian Monte Carlo

V is well-deﬁned thanks to Assumption 3. Since w is continuously differentiable on A, V is continuously differentiable on
n=1( ˚A ∩ Rn) × Rω. Moreover, V must be bounded above, say by some M .
the non-empty open set ˆA ∶= ⋃∞
Now we consider the minimization of the function S(cid:15) ∶ (Rω)L+1 → Rω where (cid:15) is the leapfrog step size,

(S(cid:15)(q0, . . . , qL))k ∶= (cid:15)

L−1
∑
i=0

(

1
2

(

k − qi
qi+1
k
(cid:15)

2
)

−

V (qi+1) + V (qi)
2

)

for all k ∈ N

where q0 = a ++ 0 and qL = b ++ 0. Since V is bounded above by M , for all φ ∈ (Rω)L+1, each component of S(cid:15)(φ) ∈ Rω is
bounded below by −(cid:15)(L − 1)M (i.e. ∀k ∈ N, S(cid:15)(φ)k > −(cid:15)(L − 1)M ). Hence, S(cid:15) is bounded below. By the completeness of
Rω, inf S(cid:15) ∈ Rω exists.
Consider a minimising sequence {φn}n∈N on (Rω)L+1 where S(cid:15)(φn+1)k < S(cid:15)(φn)k for all n, k ∈ N and S(cid:15)(φn) → inf S(cid:15)
as n → ∞. Writing the sequence as {(q0,n, . . . , qL,n)}n∈N, we say it is bounded on (Rω)L+1 if and only if for each
i = 0, . . . , L, {qi,n}n∈N is a bounded set on Rω which is equivalent to saying that for each i = 0, . . . , L and for all k ∈ N,
{∥qi,n∥k}n∈N is bounded on R. It is easy to see that for all n ∈ N and i = 1, . . . , L, ∥qi+1,n − qi,n∥k ≤ 2(cid:15)S(cid:15)(φ0) + 2(cid:15)2LM
and ∥q1,n∥k ≤ 2(cid:15)S(cid:15)(φ0) + 2(cid:15)2LM + ∥q0∥k, so for any i = 0, . . . , L and k ∈ N, {∥qi,n∥k}n∈N is bounded and hence the
sequence {φn}n∈N is bounded. Moreover, its closure Φ ∶= {φn}n∈N is bounded and closed.
Note that the Fr´echet space Rω is a quasi-complete nuclear space and has the Heine–Borel property, i.e. all closed and
bounded set is compact. So, the set Φ is compact. Moreover, since Rω is completely metrisable, the compact set Φ is also
sequentially compact, i.e. every sequence in Φ has a subsequence converging to a point in Φ. Hence {φn}n∈N ⊆ Φ must
have a subsequence {φnk }k∈N which converges to some point ¯φ in Φ.
We claim that ¯φ is almost surely in ˆAL+1. We show that the set (Rω)L+1 ∖ ˆAL+1 has measure zero. First note that by
Assumption 2, w is continuously differentiable almost everywhere and hence T ∖ A is a null set. Moreover, by the deﬁnition
of A ∈ U, T ∖ ˚A is also a null set. Then this implies the set of inﬁnite sequences with no preﬁxes in ˚A has measure zero,
i.e. Rω∖ ˆA is a null set. Hence (Rω)L+1∖ ˆAL+1 = {(q0, . . . , qL) ∈ (Rω)L+1 ∣ ∃i . qi /∈ ˆA} = ⋃L
i=0(Rω)i×(Rω∖ ˆA)×(Rω)L−i
has zero measure.
Since ¯φ is constrained by q0 = a ++ 0 and qL = b ++ 0, there can only be a null set of a, b ∈ A ∩ Supp(w) which induces ¯φ in
the null set (Rω)L+1 ∖ ˆAL+1. Hence ¯φ is almost surely in ˆAL+1.
Assume ¯φ is in ˆAL+1. Since V is continuously differentiable on ˆA, so is S(cid:15) on ˆAL+1. By the continuity of S(cid:15), we have
inf S(cid:15) = limk→∞ S(cid:15)(φnk ) = S(cid:15)(limk→∞ φnk ) = S(cid:15)( ¯φ), so S(cid:15) attains its inﬁmum on ˆAL+1.
By Prop. 32, the gradient of S(cid:15) at its inﬁmum ¯φ = (¯q0, . . . , ¯qL) is 0. Hence ¯q0 = a ++ 0, ¯qL = b ++ 0 and

¯qi+1 = 2¯qi − ¯qi−1 − (cid:15)2∇V (¯qi)

for i = 1, . . . , L − 1

which is the solution to the leapfrog steps. In other words, the inﬁmum ¯φ gives a path from a ++ 0 to b ++ 0 via the leapfrog
trajectory with initial momentum p = 1
(cid:15)

(¯q1 − a ++ 0) + (cid:15)
2

∇V (a ++ 0).

Last but not least, let k be the maximum of ki’s where w(¯qi1...ki ) > 0 for all i = 0, . . . , L. Then it is easy to see that
proj1(Ψk(a ++ 01...k−∣a∣), p1...k)1...∣b∣ = b.
Proposition 32. Let f ∶ Rω → Rω be a function with inﬁmumat x0 ∈ Rω and is continuously differentiable on A ⊆ Rω
where x0 ∈ A, then ∇f (x0) is the zero map, i.e. ∇f (x0)(h) = 0 for all h ∈ Rω.

Proof. First note that f is continuously differentiable at x0 ∈ A means that for any (cid:15) > 0 there exists an δ > 0 such that for
any k ∈ N and x ∈ Rω such that ∥x − x0∥k < δ implies ∥f (x)−f (x0)−L(x−x0)∥(cid:96)
< (cid:15) for all (cid:96) ∈ N, where L ∶ Rω → Rω is the
bounded linear map deﬁned as L ∶= (Df )(x0). 11
Assume for contradiction that L is not a zero map. i.e. There exists some h ∈ Rω such that Lh /= 0. Let k be the coordinate
such that (Lh)k /= 0 and (cid:15) > 0.
Since x0 is an inﬁmum of f , f (x)(cid:96) ≥ f (x0)(cid:96) for all (cid:96) ∈ N and x ∈ Rω. Moreover, f is continuously differentiable at x0 so
there exists an δ > 0 such that for any x ∈ Rω, ∥x − x0∥k < δ implies ∥f (x)−f (x0)−L(x−x0)∥(cid:96)

< (cid:15) for all (cid:96) ∈ N.

∥x−x0∥k

∥x−x0∥k

11This can be easily seen by substituting h by x−x0
∥x−x0∥k

in the standard deﬁnition of continuously differentiable functions f on A ⊆ Rω.

Nonparametric Hamiltonian Monte Carlo

Consider the sequence {yn}n∈N deﬁned as yn ∶= x0 − 1
∥ −1
n

Lh
∥Lh∥k
∥h∥k. So for large enough n, ∥yn − x0∥k < δ.

= 1
n

⋅ h∥

n

Lh
∥Lh∥k

k

⋅ h. The distance between yn and x0 is ∥yn − x0∥k =

Hence,

0 ≤

(f (yn) − f (x0))k
∥yn − x0∥k

<

L(yn − x0)k
∥yn − x0∥k

+ (cid:15) =

n
∥h∥k

⋅ (

−1
n

(Lh)2
∥Lh∥k

)
k

+ (cid:15) = −

∥Lh∥k
∥h∥k

+ (cid:15)

which implies ∥Lh∥k < ∥h∥k(cid:15). Since (cid:15) is arbitrary, we have ∥Lh∥k ≤ 0 which implies (Lh)k = 0 and contradicts our
assumption.

Now we show that the Markov chain can move to any measurable set with positive measure on A from almost all w-supported
element in A.
Lemma 33. Assuming w is continuously differentiable on a non-null set A ∈ U and {Un} is uniformly bounded above
(i.e. there is an upper bound M , where Un(q) < M for all q ∈ Dom(Un) for all n ∈ N) and ∇Un is Lipschitz on
A ∩ Dom(Un). For almost all a ∈ A ∩ Supp(w) and measurable subset B ⊆ A, ν(B) > 0 implies Q(a, B) > 0.

Proof. It is enough to prove the statement for a non-null measurable set B ⊆ A ∩ Rn where all elements of B have positive
weight since all measurable subset B of A with ν(B) > 0 must contains such a subset. Moreover we restrict B to the
elements where the statement in Lem. 31 always hold w.r.t. a.
Say m = ∣a∣ and M = max{m, n}. Let Ia(B) = {p ∈ Rk ∣ k ≥ M and all intermediate leapfrog steps starting from
(a ++ 01...k−m, p) ∈ Svalid are in A ∩ Dom(Uk) and proj1(Ψk(a ++ 01...k−m, p))1...n ∈ B}. It is enough to show that
∑∞

k=M Lebk(Ia(B) ∩ Rk) > 0.

Let θ ∶ Ia(B) → B be the function where θ(p) gives the next sample in B after L HMC leapfrog steps starting with initial
state (a ++ 01...∣p∣−m, p). By Lem. 31, θ is subjective.
a(B) = Ia(B) ∩ Rk and show that θk ∶ I k

We write I k
intermediate positions are in Dom(Uk) ∩ A. Hence, we can write θk(p) ∶= proj1(Ψk(a ++ 01...k−m, p)) = qL as

a(B) → B is Lipschitz. By assumption for any p0 ∈ I k

a(B), all the

q0 + (cid:15)Lp0 − (cid:15)2(

L
2

∇Uk(q0) +

L−1
∑
k=1

k∇Uk(qL−k)).

Let p, p′ ∈ I k
Then,

a(B), and qi, q′i be the position of the state after i leapfrog steps with momentum kick p, p′ respectively.

∣θk(p) − θk(p′)∣ = ∣qL − q′L∣ ≤ (cid:15)L∣p − p′∣ + (cid:15)2

≤ (cid:15)L∣p − p′∣ + (cid:15)2

L−1
∑
i=1
L−1
∑
i=1

i∣∇Uk(qL−i) − ∇Uk(q′L−i)∣

i∣qL−i − q′L−i∣

(Uk is Lipschitz on A ∩ Dom(Uk))

hence ∣θk(p) − θk(p′)∣ ≤ c∣p − p′∣ for some constant c and θk is Lipschitz.

Assume for contradiction that ∑∞

k=M Lebk(Ia(B) ∩ Rk) = 0 which means that for all k ≥ M , Lebk(I k

a(B)) = 0. However,

Lebn(B) = Lebn(θ(Ia(B))) = Lebn(θ(

∞
⋃
k=M

I k
a(B))) = Lebn(

∞
⋃
k=M

θk(I k

a(B)))

≤

∞
∑
k=M

Lebn(θk(I k

a(B))) ≤

∞
∑
k=M

Lip(θk)3N ⋅ Lebn(I k

a(B)) = 0

implies that Lebn(B) = 0 which gives a contradiction.

Lemma 34. Assuming w is continuously differentiable on a non-null set A where A ∈ U and {∇Un} is uniformly bounded
above and below (i.e. there are bounds M1, M2, where M1 ≤ ∇Un(q) ≤ M2 for all q ∈ Dom(∇Un) for all n ∈ N). Then
there exists a step size (cid:15) such that for any sequence q ∈ Supp(w), ν(A) > 0 implies Q(q, A) > 0.

Nonparametric Hamiltonian Monte Carlo

Proof. Let q ∈ Rm be w-supported. Since A ∈ U, its interior ˚A is an non-empty open set. Hence for some n, there is an
non-empty open subset ∏n

i=1(ai, bi) of A ∩ Rn.

Now we consider the conditions on the starting momentum p0 in order for the position qL at the end of the trajectory of
the leapfrog steps to be in A assuming that the position of the intermediate states never leave the domain of Uk for some
k ≥ M ∶= max{m, n}.

qL ∈

n
∏
i=1

(ai, bi) × Rk−n ⇔ ∀i = 1, . . . , n q0

i + (cid:15)Lp0

i − (cid:15)2(

L
2

∇Uk(q0) +

k∇Uk(qL−k)) ∈ (ai, bi)

⇐ ∀i = 1, . . . , n p0

((cid:15)L)2
2
For any p ∈ ∏n
k=M {p′ ∈ Rk−n ∣ (q ++0k−m, p++p′) ∈ Svalid} is non-null. This is because the measure of the
union can be seen as the value measure of the almost surely terminating probabilistic program which given q ∈ Suppm(w)
and p ∈ ∏n
i=1 Ii returns p′ ∈ Rk−n such that (q ++ 0k−m, p ++ p′) is a valid state,
√

i=1 Ii, the union ⋃∞

((cid:15)L)2
2

M1)) =∶ Ii

(ai − q0

(bi − q0

1
(cid:15)L

M2),

i ∈ (

i +

i +

for all i, the intervals {Ii} are non-empty and hence Q(q, A) ≥ ∑∞

k=M Nk({p′ ∈ Rk−n ∣ (q ++0k−m, p++

L−1
∑
k=1
1
(cid:15)L

2(bi−ai)
For (cid:15) < 1
M2−M1
L
p′) ∈ Svalid, p ∈ ∏n

i=1 Ii}) > 0.
Deﬁnition 35. We gather all the conditions so far.

(C1) w is continuously differentiable on a non-null set A with measure-zero boundary.
(C2) w∣Supp(w) is bounded below by a positive constant.
(C3) For each n, the function ∇w≤n
w≤n
(C4) For each n, the function ∇w≤n
w≤n

is uniformly bounded from above and below on Supp(w≤n) ∩ A.
is Lipschitz continuous on Supp(w≤n) ∩ A.

Note that

(C1) implies w is continuously differentiable on a non-null set A ∈ U.
(C2) implies {Un} is uniformly bounded above (i.e. there is an upper bound M , where Un(q) < M for all q ∈ Dom(Un)

for all n ∈ N).

(C3) implies {∇Un} is uniformly bounded above and below (i.e. there are bounds M1, M2, where M1 ≤ ∇Un(q) ≤ M2

for all q ∈ Dom(∇Un) for all n ∈ N).
(C4) implies ∇Un is Lipschitz on A ∩ Dom(Un).

Now we are ready to prove irreducibility.

Lemma 36 (Irreducible). If Assumptions (C1)–(C4) are satisﬁed, there exists a step size (cid:15) such that for any sequence
q ∈ Supp(w) and measurable set B ∈ ΣT, ν(B) > 0 implies Qi(q, B) > 0 for i ∈ {1, 2}.

Proof. Let A be the non-null set in U where w is continuously differentiable on A and µT(T ∖ A) = 0 and Lem. 33 holds
for all elements in A. Such A must exist by Assumption 2 and (C1).
First note that ν(A∩B) > 0. Otherwise, we must have ν((T∖A)∩B) > 0. But this implies µT(T∖A) ≥ µT((T∖A)∩B) > 0
which contradicts the assumption.
We do case analysis on q ∈ T.

• If q ∈ A, then by Lem. 33, Q(q, A ∩ B) > 0.

• If q /∈ A, then by Lem. 34, Q(q, A) > 0 and so

Q2(q, B) ≥ Q2(q, A ∩ B)

Q(q′, A ∩ B) Q(q, dq′)

Q(q′, A ∩ B) Q(q, dq′) > 0.

= ∫

T

≥ ∫

A

Lemma 37 (Aperiodic). If Assumptions (C1)–(C4) are satisﬁed, Q is aperiodic.

Nonparametric Hamiltonian Monte Carlo

) = 1 for all i = 0, . . . , d.

Proof. Assume for contradiction that Q is not aperiodic. Then, there exists disjoint B0, . . . , Bd for d ≥ 1 such that ν(B0) > 0
and x ∈ Bi implies Q(x, B(i+1) mod (d+1)
Let A be the non-null set in U where w is continuously differentiable on A and µT(T ∖ A) = 0 and Lem. 34 holds for all
elements in A. Such A must exist by Assumption 2 and (C1). Let Ci ∶= Bi ∩ A for all i = 0, . . . , d. Hence, ν(C0) > 0 and
x ∈ Ci implies Q(x, C(i+1) mod (d+1)
Let x ∈ C0 be a w-supported sequence. Such an x must exist as ν(C0) > 0. Then, Q(x, C1) = 1 implies Q(x, C0) ≤
Q(x, T ∖ C1) = 0 which contradicts with Lem. 36 as x ∈ A.

) = 1 for all i = 0, . . . , d.

Finally by Tierney’s Theorem (Lem. 19), the ν-irreducible (Lem. 36) and ν-aperiodic (Lem. 37) transition kernel Q with
invariant distribution ν (Thm. 4) converges to ν.

Theorem 5. If Assumptions (C1)–(C4) are satisﬁed in addition to Assumptions 1, 2 and 3, the Markov chain generated by
iterating Alg. 1 converges to the target distribution ν.

D. Experiments

D.1. Details on the Experimental Setup

For our experimental evaluation, we implemented the algorithms in Python, using PyTorch for tensor and gradient com-
putations. The source code for our implementation and experiments is available at https://github.com/fzaiser/
nonparametric-hmc and archived as (Zaiser & Mak, 2021).

Inference algorithms The four inference algorithms we compared were:

1. NP-DHMC (ours): the nonparametric adaptation of (Nishimura et al., 2020), explained in App. B.2, using the efﬁciency

improvements from App. B.3.

2. Lightweight Metropolis-Hastings (LMH),

3. Particle Gibbs (PGibbs) and

4. Random walk lightweight Metropolis-Hastings (RMH).

We used the Anglican implementations of the latter three algorithms.

Models For NP-DHMC, the models were given to the algorithm as probabilistic programs in the form of a Python function
with a context argument for NP-DHMC. The context allows probabilistic primitives and records the trace and weight for the
inference algorithms. This way, evaluating the density function w amounts to running the probabilistic programs. For LMH,
PGibbs, and RMH, the Python models were translated to Clojure programs using Anglican’s probabilistic programming
constructs. The pseudocode for the geometric example and the random walk example can be found in the main text.
The Gaussian and Dirichlet process mixture model is explained there as well, using statistical notation. Sampling from
DP(α, Uniform([0, 1]3)) is implemented using the stick-breaking procedure (Sethuraman, 1994). We use a cutoff of
(cid:15) = 0.01 for the stick size as explained in the text. In pseudocode, it looks as follows:

def dp(alpha, H):

stick = 1.0
beta = 0.0
cumulative product = 1.0
weights = []
means = []
while stick > 0.01:

cumulative product *= 1 − beta
beta = sample(Beta(1, alpha))
theta = sample(H)
weights.append(beta * cumulative product)

Nonparametric Hamiltonian Monte Carlo

Figure 12. ESS for the random walk example in terms of number of samples

means.append(theta)
stick −= beta * cumulative product

return weights, means

ESS computation For the random walk example, we computed the effective sample size. For this we used NumPyro’s
(Bingham et al., 2019) diagnostics . effective sample size function. It is designed to estimate the effective sample
size for MCMC samplers using autocorrelation (Gelman et al., 2014). For importance samples used as the ground truth, we
used the importance weights directly to compute the ESS: given importance weights w1, . . . , wn, the ESS is (∑
. We
∑
also computed the (autocorrelation-based) MCMC ESS for the importance samples and we obtained very similar results.

n
i=1 wi)
n
i=1 w2
i

2

Hyperparameter choices We produced 10 runs with 1000 samples each for every example except the last, Dirichlet
process mixture model (DPMM). For the DPMM example, we only produced 100 samples in each run because of the
forbidding computational cost. We set the number of burn-in samples that are discarded to 10% of the total number of
samples, i.e. 100 samples for each run. Since each run of the DPMM only had 100 samples, we set the burn-in higher there,
namely to 50. We did not vary this hyperparameter much because higher values did not seem to make a difference. For the
number of leapfrog steps we tried values L ∈ {5, 20, 50, 100}, and for the step size we tried values (cid:15) ∈ {0.01, 0.05, 0.1, 0.5}.
Generally, the simple geometric distribution example already works for very rough hyperparameters (L = 5, (cid:15) = 0.1).
Finer steps work as well, but are not necessary. However, more complex models generally require ﬁner steps (GMM:
L = 50, (cid:15) = 0.05). The other inference algorithms we tested don’t have any hyperparameters that need to be set.

Thinning Since NP-DHMC performs more computation than its competitors for each sample because it evaluates the
density function in each of the L leapfrog steps, not just once like the other inference algorithms. To equalise the computation
budgets, we generate L times as many samples for each competitor algorithm, and apply thinning (taking every L-th sample)
to get a comparable sample size.

D.2. Additional Plots and Data

In addition to the ESS and LPPD computations, we also plotted both as a variable of the number of samples computed.
The results can be seen in Fig. 12 and 13. As we can see, NP-DHMC performs the best consistently over the course of the
inference, not just in terms of the ﬁnal result.

Running time We report the wall-clock times for the different algorithms. Experiments were carried out on a computer
with an Intel Core i7-8700 CPU @ 3.20 GHz x 12 and 16 GB RAM, running Ubuntu 20.04. The results are presented in
Table 2.

0200040006000800010000number of samples01000200030004000500060007000effective sample sizemethodoursLMHPGibbsRMHNonparametric Hamiltonian Monte Carlo

Figure 13. LPPD for the GMM and DP mixture model in terms of the number of samples from 10 runs. The shaded area is one standard
deviation. These are the full plots of Fig. 8 and 9, respectively.

Table 2. Running times for the different inference algorithms in seconds per sample.

method

ours

LMH

PGibbs RMH

Pyro HMC Pyro NUTS

geometric example
random walk example
GMM example
DPMM example

0.0418
0.2266
0.1879
1.8516

0.0003
0.0077
1.6572
2.1491

0.0001
0.0051
1.6835
1.7855

0.0005
0.0095
1.6376
2.0584

n/a
≈ 0.41
n/a
n/a

n/a
≈ 5.7
n/a
n/a

NP-DHMC is signiﬁcantly slower than the competition in the geometric and random walk examples, faster for GMM and
comparable for DPMM. Due to the nature of the coordinate integrator of discontinuous HMC (Nishimura et al., 2020),
NP-DHMC has to run the model L × d times per sample where d is the number of discontinuous variables in the model. We
could improve the algorithm by only updating a subset of the discontinuous variables per iteration. In addition, NP-DHMC
computes gradients and simulates Hamiltonian dynamics, which is computationally expensive. On the random walk example
we also ran Pyro HMC and NUTS, as mentioned before. Both of them were a lot slower than our implementation, which
speaks to the fact that HMC methods simply have an unavoidable performance overhead. Finally, the implementation of
NP-DHMC is a research prototype, so it is not optimal and there is a lot of room for improvement.

200040006000800010000number of samples−720−710−700−690−680log pointwise predictive densitymethodoursLMHPGibbsRMHground truth2004006008001000number of samples−760−740−720−700−680log pointwise predictive densityoursLMHPGibbsRMHground truth