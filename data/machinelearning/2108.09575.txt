Automatic Diﬀerentiable Numerical Renormalization Group

Jonas B. Rigo∗ and Andrew K. Mitchell†
School of Physics, University College Dublin, Belﬁeld, Dublin 4, Ireland and
Centre for Quantum Engineering, Science, and Technology,
University College Dublin, Belﬁeld, Dublin 4, Ireland

Machine learning techniques have recently gained prominence in physics, yielding a host of new
results and insights. One key concept is that of backpropagation, which computes the exact gradient
of any output of a program with respect to any input. This is achieved eﬃciently within the
diﬀerentiable programming paradigm, which utilizes automatic diﬀerentiation (AD) of each step
of a computer program and the chain rule. A classic application is in training neural networks.
Here, we apply this methodology instead to the numerical renormalization group (NRG), a powerful
technique in computational quantum many-body physics. We demonstrate how derivatives of NRG
outputs with respect to Hamiltonian parameters can be accurately and eﬃciently obtained. Physical
properties can be calculated using this diﬀerentiable NRG scheme—for example, thermodynamic
observables from derivatives of the free energy. Susceptibilities can be computed by adding source
terms to the Hamiltonian, but still evaluated with AD at precisely zero ﬁeld. As an outlook, we
brieﬂy discuss the derivatives of dynamical quantities and a possible route to the vertex.

I.

INTRODUCTION

The Numerical Renormalization Group (NRG) [1, 2]
is a standard tool in computational physics for solving
a certain class of quantum many-body problem, known
as quantum impurity models. These comprise a few in-
teracting quantum degrees of freedom, coupled to one
or more non-interacting baths. The most famous exam-
ple is the Kondo model, which involves a single spin- 1
2
‘impurity’ coupled to a single fermionic bath [3]. The
low-energy physics is non-perturbative and controlled by
a single emergent energy scale (the Kondo temperature,
TK), below which the impurity is dynamically screened by
a spatially-extended entanglement ‘Kondo cloud’ of sur-
rounding conduction electrons [4]. Generalized quantum
impurity models describe the scattering from magnetic
impurities in metals [3, 5], semiconductor quantum dot
devices [6–9], single molecule transistors [10, 11], and are
the local eﬀective models within dynamical mean ﬁeld
theory (DMFT) for correlated materials [12–14].

NRG is a tensor network method [15] that exploits the
renormalization group structure of such quantum impu-
rity models [1]. At its core, the method involves the iter-
ative numerical diagonalization of a set of renormalized
eﬀective Hamiltonians. There is no statistical element,
as with quantum Monte Carlo impurity solvers [16].

In this paper, we apply the ‘diﬀerentiable program-
ming’ methodology to NRG, and demonstrate some ad-
vantages of its use for practical physics applications. We
show that the core eigensolver routine in NRG is well-
suited to Automatic Diﬀerentiation (AD), an emerging
programming paradigm that has its origin in Deep Learn-
ing (DL) [17].
In DL, hugely complicated neural net-
works (NN) feed their output into a loss function, which

∗ jonas.rigo@ucdconnect.ie
† andrew.mitchell@ucd.ie

must be optimized with respect to the NN parameters
(weights). This can be accomplished eﬃciently via gra-
dient descent using AD programming: the gradient of
the loss-function with respect to the NN weights can be
computed at about the cost of the evaluation of the NN
[18]. The remarkable aspect of this technique is that
the computed gradient is not approximated, but is nu-
merically exact. Without AD, derivatives can of course
be approximated using ﬁnite diﬀerence (FD) derivatives.
However, without care, FD derivatives can be inaccurate;
when treated rigorously to guarantee convergence, FD
can become computationally expensive. The eﬃciency
and accuracy of AD owes to the fact that if each step of
a computer program can be diﬀerentiated, then outputs
can be diﬀerentiated with respect to inputs via the chain
rule. Evaluating derivatives is trivial and cheap since the
program itself is diﬀerentiated.

AD has been made more accessible through the in-
troduction of AD libraries such as jax [19], tensorﬂow
[20] or PyTorch [21]. The advantage for computational
physics is that when formulated using an AD library, ex-
act derivatives can be obtained ‘for free’ [22–28]. Recent
applications in physics include optimal control in quan-
tum systems [29], mitigating the sign problem in Monte
Carlo [30], and optimizing tensor networks [31]. In ad-
dition to its use for optimization problems, AD has par-
ticular appeal in physics because physical quantities are
related to derivatives of generating functionals [32].

Here we formulate a diﬀerentiable NRG (∂NRG)
scheme. The key step is an explicit expression for the
derivative of NRG eigenvalues and eigenvectors: the ex-
act gradient of the entire eigensolver routine at any given
NRG step is determined symbolically. This eliminates
the need for full backpropagation, and when combined
with AD for the other program elements, provides highly
eﬃcient access to derivatives of program outputs with
respect to model parameters. For example, thermody-
namic observables may be obtained from derivatives of
the free energy; and the physical response of a system to

2
2
0
2

r
p
A
4

]
l
e
-
r
t
s
.
t
a
m
-
d
n
o
c
[

3
v
5
7
5
9
0
.
8
0
1
2
:
v
i
X
r
a

 
 
 
 
 
 
perturbations can be simply and cheaply determined.

II. FORWARD- AND BACKWARD-MODE AD

The AD approach is similar to symbolic diﬀerentia-
tion, with standard derivative rules applied algorithmi-
cally [17, 33]. Regarding a program as a function f that
maps a given input x to an output y, we may write
f (x) = y. This is typically achieved in practice by con-
catenating several primitive functions f (i), viz:

f = f (n)

f (n

−

1)

...

f (1) ,

(1)

◦

◦

◦
where “
” denotes the composition of two functions. We
◦
denote the number primitive functions comprising f as
ops(f ). The ﬂow of data between primitive functions
can be expressed as a compute graph [34]; for simplicity,
we consider here only programs whose graph has a chain
topology as in Eq. (1). To compute the derivative of f
with respect to x one can apply the chain rule,

∂f
∂x

=

∂f (n)
∂f (n
1)

−

∂f (n
∂f (n

−

−

1)
2) ...

∂f (1)
∂x

.

(2)

Eq. (2) can be evaluated algorithmically in either the
forward mode, or the backward mode.
In the forward
mode, we apply the recursion

∂f (i)
∂x

=

∂f (i)
∂f (i

−

1) δi

δi, with δ0 = 1, f (0) = x (3)

1 ≡
−

starting with i = 1 and increasing up to i = n, with
f (n)
f such that δn = ∂f /∂x is the desired derivative.
In backward mode (also known as backpropagation) we
use the recursion

≡

∂f
∂f (i) =

∂f (i+1)
∂f (i)

¯δi+1 ≡

¯δi, with ¯δn = 1, f (0) = x (4)

starting from i = n
with ¯δ0 = ∂f /∂x the desired derivative.

−

1 and decreasing down to i = 0,

These forward and backward mode AD recursions are
symbolically equivalent methods for calculating deriva-
tives. In the practical implementation of AD the inter-
mediate derivatives δi or ¯δi are evaluated numerically and
stored in memory. This provides a way to compute nu-
merically exact derivatives, with the true analytical re-
sult recovered when the value of δi is not truncated [35].

By contrast, the FD approximation reads,

∂f
∂x ≈

f (x + h)
h

−

f (x)

≡

Dh[f ](x) ,

(5)

with h being the FD value. The exact limit h
0± can-
not be taken numerically, and so ∂xf must be approxi-
∂xf
mated for ﬁnite h and the convergence Dh[f ](x)
checked explicitly. This may require many function eval-
uations (runs of the whole program) since for very small
h, f (x) and f (x+h) may be numerically indistinguishable

→

→

2

→

→

(truncation error). Furthermore, convergence should be
checked for both the forwards (h > 0) and backwards
(h < 0) diﬀerence quotient. The situation gets worse
for higher-order derivatives, and numerical convergence
of FD approximations can be costly and/or fraught [36].
Above we considered scalar functions of the form f :
R. However, both AD and FD approaches can be
R
straightforwardly generalized to compute the Jacobian
of vector-valued functions deﬁned over a vector space
f : Rn
Rm. The FD and forward/backward mode
AD scale diﬀerently with respect to the input dimension
n and output dimension m. The FD exhibits the most ex-
pensive scaling of computational cost with
2nm func-
tion evaluations required to compute the Jacobian of f
in the single-shot case. By contrast, AD methods do
not require the function to be evaluated in order to com-
pute the derivative, as with the symbolic approach (al-
though since many derivatives are related to their anti-
derivative, function evaluations can be reused to reduce
computational cost at the expense of increased memory
cost [37]). Instead, the computational cost of AD meth-
ods is controlled by ops(f ). Speciﬁcally, the forward
cF n ops(f ), while the backward mode
mode scales as
scales as
cBm ops(f ), with cF , cB < 6 (although the
forward mode typically outperforms the backward mode
unless m
n [37]). The computational cost of the FD
approach is therefore typically much higher than either
of the AD modes;
in this work we use forward mode
AD unless stated otherwise. A comparison of the perfor-
mance and precision of the diﬀerent methods, as applied
to NRG, is presented in Appendix A.

(cid:28)

∼

∼

∼

Through AD one can obtain the numerically exact
derivative of any program with a single run, as long as
all operations comprising the program are themselves dif-
ferentiable. Thus, one can diﬀerentiate a given physics
solver program simply by utilizing known derivatives of
its constituent operations.

On the other hand, in certain cases it may be possible
to ﬁnd the symbolic derivative of the entire solver with
respect to certain input parameters. In the following we
show how the latter can be achieved for NRG through
analysis of the backpropagation chain.

III. NRG

Wilson’s NRG is a numerical solver for quantum im-
purity models, of the type ˆH = ˆHimp + ˆHbath + ˆHhyb,
where ˆHimp is the ‘impurity’ Hamiltonian describing
interacting quantum degrees of freedom,
a few local,
while ˆHbath = (cid:80)
σ,k (cid:15)kˆc†σkˆcσk describes a non-interacting
fermionic bath. The coupling between them is given by
ˆHhyb = (cid:80)
ˆdσ), where we have assumed
for simplicity here that a single impurity orbital ˆdσ cou-
ples to the bath.

σ,k Vk ( ˆd†σˆcσk + ˆc†σk

Due to the impurity interactions, such a model is a
genuine quantum many body problem, and in general has

no exact solution [3]. NRG treats instead a discretized
version of the model, which becomes computationally
tractable through a process of iterative diagonalization
and truncation. This constitutes an RG procedure, in
which useful physical information can be extracted at
each step, as progressively lower energy scales are probed.
Full details can be found in Refs. [1, 2]; here we introduce
only the elements necessary to formulate ∂NRG.

The ﬁrst step is the logarithmic discretization of the
bath and mapping to a Wilson chain. The continuous
local density of states of the uncoupled bath at the im-
purity position is divided up into intervals of decreasing
n, where D
width, deﬁned by the points x±n =
is the half-bandwidth, Λ > 1 the discretization param-
eter, and n = 0, 1, 2, .... The spectrum is discretized by
replacing the continuous density in each interval by a
single pole of the same weight and at the average po-
sition. A semi-inﬁnite tight-binding chain (the Wilson
chain) is then deﬁned such that the spectral function at
the end is the same as the discretized bath spectrum (this
is achieved in practice by the Lanczos algorithm). The
discretized bath Hamiltonian reads,

DΛ−

±

ˆHbath (cid:55)→

ˆH disc

bath =

(cid:88)

∞(cid:88)

σ

n=0

tn(ˆc†σn+1ˆcσn + ˆc†σnˆcσn+1) ,

→

(6)
where we have assumed particle-hole symmetry here for
1.
simplicity. The original model is recovered as Λ
The speciﬁc form of the Wilson chain hopping parame-
ters tn depends on details of the dispersion relation (cid:15)k.
n/2 for large n.
However, for a metallic system, tn
For a Wilson chain of total length N , adding an extra
site N + 1 is therefore always a small perturbation. The
NRG exploits this energy scale separation down the chain
through the iterative diagonalization scheme. Starting
from the impurity, the chain is built up by successively
adding new Wilson chain sites. At each step, the system
is diagonalized, and high-energy states discarded. One
deﬁnes a sequence of rescaled Hamiltonians, comprising
the impurity and the ﬁrst N sites of the Wilson chain,

DΛ−

∼

(cid:34)

ˆHN = Λ(N

−

1)/2

ˆHimp + V

( ˆd†σˆcσ0 + ˆc†σ0

ˆdσ)

(cid:88)

σ

(cid:35)

tn(ˆc†σn+1ˆcσn + ˆc†σnˆcσn+1)

,

(7)

(cid:88)

N
1
(cid:88)
−

+

σ

n=0

with V the eﬀective impurity-bath coupling. The full
(discretized) Hamiltonian is recovered in the limit ˆH =
1)/2 ˆHN . The sequence of Hamiltonians
limN
−
ˆHN satisfy the recursion relation,

Λ−

→∞

(N

ˆHN +1 = √Λ ˆHN + ΛN/2 (cid:88)

tN (ˆc†σN +1ˆcσN + ˆc†σN ˆcσN +1) .

σ

(8)
At each step N , the Hamiltonian ˆHN is diagonalized
and eigenvalues

to ﬁnd the eigenvectors (states)

N

i
(cid:105)

{|

}

3

}
ˆHN

(energies)

EN ;i
{

that satisfy the Schr¨odinger equation,

i
|

(cid:105)N .
i

(cid:105)N = EN ;i
We denote excitation energies relative to the ground state
EN ;0, and ˆHimp ≡
1. To construct
as ∆EN ;i = EN ;i
−
ˆHN +1 we add another Wilson chain site. The Fock space
of ˆHN +1 is spanned by basis states,

ˆH
−

(9)

|

i; s
|

(cid:105)N +1 =

i
|

(cid:105)N ⊗ |

,

s
(cid:105)

(10)

comprising the tensor product of eigenstates
and the added chain site N + 1 denoted
ments of ˆHN +1 in this basis read,

s
(cid:105)
|

i
(cid:105)
|

N of ˆHN ,
. Matrix ele-

ˆHN +1(is; i(cid:48)s(cid:48)) = N +1(cid:104)

i; s
|

ˆHN +1 |

i(cid:48); s(cid:48)

(cid:105)N +1 .

(11)

Finally, ˆHN +1 is diagonalized to ﬁnd the new eigenbasis
at step N + 1, viz:

j
|

(cid:105)N +1 =

(cid:88)

is

UN +1(j, is)

i; s
|

(cid:105)N +1 .

(12)

Eq. (11) can be simpliﬁed using the energies EN ;i of ˆHN
and the tensor ηss(cid:48)σ =
(which is indepen-
dent of N ), viz

s
ˆcσN +1 |
(cid:105)

s(cid:48)

(cid:104)

|

ˆHN +1(is; i(cid:48)s(cid:48)) =√Λδss(cid:48)δii(cid:48)

EN ;i

×
1)sΛN/2tN

+ (

−

(cid:88)

σ

ηss(cid:48)σηN ;ii(cid:48)σ + H.c. ,

(13)

,

{|

=

−

for

0
(cid:105)

δ¯i¯i(cid:48)η¯s(cid:48) ¯sσ
×
.
| ↑↓(cid:105)}

where ηN ;jj(cid:48)σ = (cid:80)
1, +1, 2
0,
and s =
}
{

¯i¯s,¯i(cid:48) ¯s(cid:48) U †N (j,¯i¯s) UN (j(cid:48),¯i(cid:48)¯s(cid:48))
,
| ↑(cid:105)

,
| ↓(cid:105)

s
(cid:105)
|
When following these steps, the dimension of the Fock
space grows exponentially with the length of the chain.
This is avoided in NRG by truncating the Fock space at
each step, discarding high-energy states. In practice, one
retains MK of the lowest energy eigenstates of ˆHN at
each step. The NRG approximation [1, 38] is that the
states and energies of ˆHN approximate those of the full
ˆH. This approximation is justiﬁed by the exponential
decay of the Wilson chain coeﬃcients tn, which means
that high-energy states discarded at a given iteration do
not become low-lying states at a later iteration. Conver-
gence of the NRG calculation can be checked post hoc by
increasing MK. Hereafter it is to be understood that the
condition i
MK applies to Eq. (10) (with the eigen-
values sorted lowest to highest). The dimensionality of
the Fock space is therefore constant at each step, and
the NRG calculation scales linearly with chain length N .
With increasing N the physics on successively lower en-
ergy scales is uncovered.

≤

The entire process of going from one iteration to the

next can be summarized as an RG transformation,

ˆHN +1 = R[ ˆHN ] .

(14)

(cid:104)
|
ˆON +1(j; j(cid:48))
(cid:88)

=

The full (discretized, renormalized) Hamiltonian ˆHN can
therefore be constructed iteratively starting from the im-
purity Hamiltonian ˆHimp. Regarding the latter as a func-
tion of n physical model parameters
, the entire NRG
θ
}
{
algorithm can be viewed as a function,

)
θ
f (
}
{
f : Rn

≡

→

R◦
CMK

N +1[ ˆHimp(
θ
{
MK ,

×

)]
}

(15)

◦

R

...

N +1 = R

where we have used the shorthand notation for an N +1-
R. All
fold concatenation of functions R◦
physical quantities of interest for the original quantum
impurity model are obtained from the eigenvalues and
ˆHN
eigenvectors of the set of
Note that an operator ˆO, acting only on impurity de-
grees of freedom, can be expressed in the in the eigen-
basis of ˆHN . We denote this matrix as ˆON (i; i(cid:48)) =
N

(cid:105)N . From Eq. (12) it follows that,

[1, 2, 38].

i
|

ˆO

i(cid:48)

◦

}

{

◦

(cid:48)U †N +1(j, is) UN +1(j(cid:48), i(cid:48)s(cid:48))

is,i(cid:48)s(cid:48)
(cid:88)

is,i(cid:48)s(cid:48)

=

(cid:48)U †N +1(j, is) UN +1(j(cid:48), i(cid:48)s(cid:48))

ˆON +1(is; i(cid:48)s(cid:48))

ˆON (i; i(cid:48))δs,s(cid:48)

(16)

×

×

where the primed sum implies that i, i(cid:48)
MK, and the
second line follows from the fact that ˆO does not act on
of site N +1. Eq. (16) can be used iteratively to
states
s
(cid:105)
|
transform ˆO
1(i; i(cid:48)), evaluated explicitly in the impurity
−
basis, into the eigenbasis of any later iteration.

≤

Symbolically, we denote this process,

ˆON +1 = P [ ˆON ] ,

(17)

which we refer to as propagating forward the operator.

IV. DERIVATIVE OF EIGENVALUES AND
EIGENVECTORS IN NRG

As outlined in the previous section, NRG outputs the
eigenvalues and eigenvectors for the set of ˆHN . Since all
physical quantities for the quantum impurity model are
obtained from these, calculating their derivatives using
Eq. (2) requires the derivatives of the eigenvalues and
eigenvectors of ˆHN . From Eq. (15), we regard NRG as
a function deﬁned over an n dimensional domain, with
MK dimensional image. Since n denotes the
an MK
number of model parameters in ˆHimp, and MK
MK is
the Fock space dimension of ˆHN , we have MK
MK
(cid:29)
n and therefore forward mode AD is signiﬁcantly faster
[35]. In the following we consider only forward mode AD.
For a Hermitian matrix ˆA (such as the Hamiltonian
and distinct
, we may express

ˆHN ) with non-degenerate eigenvectors
eigenvalues λi satisfying ˆA
|

×
×

= λi

i
(cid:105)
|

i
(cid:105)
|

i
(cid:105)

×

the diﬀerentials through [39, 40],

dλi =

=

i
d
(cid:105)
|

i
(cid:104)
|
(cid:88)

i

=j

d ˆA

,
i
(cid:105)
|
d ˆA

−

j
(cid:104)
|
λi

i
|
(cid:105)
λj

4

(18a)

(18b)

.

j
|

(cid:105)

These expressions are of course well-known in the context
of non-degenerate perturbation theory [41].

However, the assumption implicit in Eq. (18) that
ˆA must be free of eigenvalue degeneracies is rather re-
strictive. Methods treating the general degenerate case
are much more computationally involved and may suf-
fer from numerical instabilities [40, 42]. Of course in
physics, where ˆA is the Hamiltonian of some system,
energy eigenvalue degeneracies are common. This may
be because of underlying non-Abelian symmetries (for
example SU(2) spin symmetry), which endow the spec-
trum of the Hamiltonian with a multiplet structure. In
this case, the Hamiltonian becomes block diagonal in the
associated conserved quantum numbers, and the diago-
nalization Eq. (12) can be done separately in each block.
Alternatively, NRG can be formulated directly in mul-
tiplet space by using the Wigner-Eckart theorem [43].
Either approach removes the problem of such degenera-
cies in Eq. (18). However, this may not fully solve the
problem, since there could be accidental degeneracies or
emergent symmetries [1, 3, 7] that lead to additional en-
ergy eigenvalue degeneracies in physical systems.

To overcome this, we make a simple approximation.
To the diagonal entries of ˆHN we add noise, with random
variables drawn from a normal distribution of width σ.
The noise lifts the eigenvalue degeneracy, meaning that
derivatives can be obtained using Eq. (18). Note that the
smallest terms in the rescaled Hamiltonian ˆHN are
(1)
[1, 2], so σ
1 constitutes a small perturbation. Care
should be taken to add the noise in such a way to respect
bare symmetries.

(cid:28)

O

10−

With a straight application of AD via Eq. (3), the
derivatives of eigenvalues and eigenvectors for ˆHN re-
quire the evaluation of Eq. (18) at every NRG step (and
hence noise must be added at every NRG step). For small
enough noise width σ, physical properties at a given it-
eration should be unaﬀected.
Indeed, in Appendix A
we show for the AIM that NRG remains highly accurate
when σ <
6. At larger noise levels, errors may prop-
∼
agate through the iterative process (and will snowball if
they introduce RG relevant perturbations), so care must
be taken to avoid this with such an AD approach. On
the other hand, forward mode AD for the AIM requires
σ >
6 to stabilize the calculation of derivatives us-
∼
ing Eq. (18). Smaller noise levels introduce more severe
numerical instabilities because of the recursive nature of
the derivative calculation in AD via Eq. (3) – derivatives
at one iteration depend on those of previous iterations.
This stability-accuracy tradeoﬀ in AD is analyzed in Ap-
pendix A.

10−

Below, we derive an alternative formulation used in

(cid:54)
∂NRG, which utilizes the symbolic derivative of the en-
tire eigensolver for ˆHN . This has the advantage that
Eq. (18) need only be applied once, at the NRG step for
which derivatives are required. Not only is this far less
computationally costly, but it also avoids accumulating
errors introduced by noise, which can then be added at
a much lower level.

A. Formulation in ∂NRG

In the context of NRG, one can formulate a diﬀeren-
tial recursion relation based on the RG transformation
Eq. (14),

d ˆHN = d ˆHN

1

−

1)

dR( ˆHN
d ˆHN

−
1

−

.

(19)

This allows derivatives of ˆHN to be computed in AD
forward or backward mode. However, one can also refor-
mulate the problem in a much more simple and eﬃcient
way. Taking derivatives with respect to model parame-
ters θ of ˆHimp, we may write from Eq. (7) the operator
identity ∂θ ˆHN
follows from
the NRG approximation). Since ∂θ ˆHimp only involves
impurity operators, it can be trivially evaluated in the
impurity basis, [∂θ ˆHimp]
1.
(cid:105)−
−
Eq. (17) can then be used to propagate this operator
forward into the basis of ˆHN . It therefore follows that,

1)/2 ∂θ ˆHimp (where
−

∂θ ˆHimp|

1(k; k(cid:48)) =

k
1(cid:104)
−

Λ(N

k(cid:48)

(cid:39)

(cid:39)

|

[∂θ ˆHN ]N

Λ(N

1)/2 P ◦

−

(cid:39)
From Eq. (18) we then obtain,

N +1([∂θ ˆHimp]
−

1) .

(20)

∂θEN ;i

(cid:39)

∂θ

i
(cid:105)N (cid:39)

|

Λ(N

1)/2 P ◦

−

1)/2 (cid:88)

Λ(N

−

1)(i; i)

N +1([∂θ ˆHimp]
P ◦

N +1([∂θ ˆHimp]
EN ;i

−
EN ;j

−

1)(j; i)

i

=j

−

(21a)

j
|

(cid:105)N

(21b)

Eq. (21) is the main result of this work. It shows how the
derivative of energies and states of the NRG Hamiltoni-
ans ˆHN can be obtained by simply forward-propagating
the impurity operators ∂θ ˆHimp. Derivatives of physi-
cal quantities can then be related to those obtained via
Eq. (21). The above can also be generalised to deal with
derivatives ∂φ of other Hamiltonian parameters φ (for ex-
ample V or tn in Eq. (7)) and higher order derivatives
(see Appendix B).

To calculate ﬁrst-order derivatives of eigenvalues and
eigenvectors in AD forward mode (assuming the simplest
NRG implementation) one must perform seven additional
operations for every NRG step. The ∂NRG approach
involves only one additional operation per NRG step and
does not require any propagation of derivatives related to
the chain rule (see Appendix C). Hence ∂NRG, utilizing
Eq. (21), is far more eﬃcient than standard forward mode
AD. Performance benchmarking is demonstrated in A.

5

Derivatives with respect to multiple parameters can be
obtained straightforwardly by propagating forward any
[∂θ ˆHimp]
1 of interest using Eq. (16) in ∂NRG. There-
−
fore, ∂NRG scales linearly with the number of derivatives
n, but is independent of ops(f ), unlike forward mode AD.
In practice, the use of Eq. (21) again requires lifting
eigenvalue degeneracies by adding a small diagonal noise
term. We found in numerical tests for the AIM that σ
(cid:39)
11 is suﬃcient for stabilizing the numerics in ∂NRG,
10−
without noticeably impacting any measurable physical
properties – see Appendix A.

If derivatives at only step N are required, such a noise
term need only be introduced at that step (rather than
adding noise at each step) and the RG ﬂow is unaﬀected.
This is typically the situation for ground-state proper-
ties or low-temperature thermodynamics. On the other
hand, if information is required from every NRG step
(for example in the calculation of dynamical quantities
[38]) noise must be introduced at each iteration. Unlike
with the straight AD implementation, ∂NRG allows us to
mitigate the possibility of snowballing errors introduced
by propagating the noise terms – if this level of accuracy
should be required (e.g. in the vicinity of a quantum crit-
ical point). This is because the eigensystem derivatives
at diﬀerent N via Eq. (21) are independent in ∂NRG.
Noise may be added to ˆHN for the purpose of evaluat-
ing Eq. (21), but the pristine ˆHN without noise can be
used for the main NRG recursion. This gives the most
accurate and reliable results, at the cost of an additional
matrix diagonalization. See Appendices A and C for per-
formance comparisons (and note that this more rigorous
approach is still faster than FD and straight AD in many
circumstances, and certainly more accurate).

V. APPLICATION TO ANDERSON IMPURITY
MODEL

We illustrate the use of Eq. (21) by applying the ∂NRG
scheme to the paradigmatic Anderson impurity model
(AIM), for which

ˆHimp = (cid:15)ˆn + U ˆn

ˆn

↓

↑

,

(22)

σ ˆnσ and ˆnσ = ˆd†σ

where ˆn = (cid:80)
ˆdσ. With ˆHimp so deﬁned,
the exact (discretized) ˆHN is given by Eq. (7). In NRG,
ˆHN is approximated through the RG procedure Eq. (14),
ˆHN = R◦

N +1( ˆHimp).

Z

i e−

tion
Z
1
β log[

N ( ¯β) = (cid:80)
N ( ¯β)].

For a given ˆHN , we obtain the partition func-
¯βEN ;i and free energy FN ( ¯β) =
In the original Wilsonian formulation
−
[1, 2], the eﬀective inverse temperature β
1/kBT is re-
lated to the NRG iteration number (Wilson chain length)
N via β = Λ(N
(1) in practice. With
this deﬁnition, the NRG free energy at inverse tempera-
ture ¯β is a good approximation to the true free energy of
the original (undiscretized) model at inverse temperature

1)/2 ¯β, with ¯β =
−

O

≡

(cid:54)
β [1, 2], F (β)
follows as,

(cid:39)

FN ( ¯β). The corresponding diﬀerential

dFN =

(N

Λ−

−

1)/2

(cid:88)

N

Z

i

e−

¯βEN ;i dEN ;i .

(23)

For the AIM, we may use Eq. (21) to obtain derivatives of
the free energy with respect to the impurity parameters
(cid:15) and U . For example,

∂(cid:15)FN =

1

(cid:88)

N

Z

i

¯βEN ;iP ◦

e−

N +1([ˆn]

1)(i; i) .

−

(24)

ˆn

ˆn
(cid:104)

(cid:105)HN , ¯β (cid:39) (cid:104)

Since ∂(cid:15)FN ( ¯β) =
H,β, Eq. (24) is precisely
(cid:105)
equivalent to the standard Wilsonian approach to calcu-
lating local thermodynamic expectation values in NRG
[2]. The above illustration demonstrates that ∂NRG is
analytically equivalent to the well-known result for such
local thermodynamic quantities.

Another commonly computed quantity for such models
is the local impurity magnetic susceptibility at zero ﬁeld,

χ(T ) =

(cid:90) β

dτ

(cid:104)

0

ˆSz(τ ) ˆSz

β

ˆSz
(cid:104)

2
(cid:105)

(cid:105) −

↓

ˆn

↑ −

2 (ˆn

where ˆSz = 1
) is the impurity spin operator and
τ is imaginary time. This can be alternatively obtained
by adding a source term B ˆSz to the Hamiltonian Eq. 22,
and then taking the second-order derivative of the free
energy with respect to B, evaluated at B = 0. That is,
(cid:12)
we can write χ(T ) = ∂2
(cid:12)B=0. Since ∂NRG is able
to deal with second (and higher) order derivatives (see
∂B2 FN ( ¯β)(cid:12)
Appendix B) we calculate χHN , ¯β = ∂2
(cid:12)B=0. This
is obtained automatically in ∂NRG, but from Eq. (B2) it
can also be expressed as,

∂B2 F

χHN , ¯β =

−

+

−

¯β

(cid:88)

N

Z
2

N

Z

i

(cid:88)

i

(cid:32)

(cid:88)

i

¯β
2
N

Z

¯βEi;N P ◦

e−

(cid:33)2

N +1([ ˆSz]
−

1)(i; i)

¯βEi;N

e−

P ◦
|

N +1([ ˆSz]
−

1)(i; i)

2
|

¯βEi;N (cid:88)

e−

P ◦
|

i

=j

N +1([ ˆSz]
−
EN ;j
EN ;i

1)(j; i)
|

−

2

.

(25)

−

(N

This form of χHN , ¯β is equivalent to the Lehmann repre-
sentation of χ(T ) evaluated in NRG Hamiltonian ˆHN at
eﬀective inverse temperature ¯β = βΛ−
1)/2 [2]. Since
all degeneracies are lifted in ∂NRG, convergence factors
typically used in the Lehmann representation of dynam-
ical quantities are not needed here. Note that χHN , ¯β can
be obtained at exactly zero magnetic ﬁeld, so no symme-
tries are broken and no limit is taken numerically. Since
the derivatives of primitive program functions are sym-
bolic, source terms added to ˆHimp may be evaluated at
zero coupling constant and still yield ﬁnite derivatives.
However, we note that such symmetry-breaking source

6

terms cannot be added to the Hamiltonian if non-Abelian
quantum numbers are implemented from the outset. In
the case of the magnetic susceptibility, we can there-
fore utilize conserved total Sz, but not conserved total
S, when adding the source term B ˆSz (even though in
the end we set B = 0). Numerical results are presented
in Appendix A, and reproduce precisely the results of
standard NRG using Eq. (25).

(cid:39)

ˆn
(cid:104)

∂2FN ( ¯β)/∂(cid:15)2 = ∂(cid:15)

Similarly, ∂NRG may be used to obtain the charge sus-
ceptibility, which in the wide-band limit is given simply
(cid:105)HN , ¯β (and can be ob-
by χC(T )
tained by replacing ˆSz by ˆn in Eq. (25)). Indeed, Maxwell
relations provide non-trivial connections between physi-
cal quantities obtained as derivatives. This was exploited
recently in Ref. [44] to extract the fractional entropy of
multi-channel Kondo states in quantum dot experiments,
comparing with NRG calculations of charge derivatives.
The above examples for the AIM demonstrate that the
∂NRG algorithm is equivalent to known expressions for
certain derived quantities. However, the power of ∂NRG
is that it does this automatically within a generalized
framework, and works equally well for any derivative in
any quantum impurity model.

VI. NUMERICAL RESULTS

For the following numerical demonstrations, we imple-
mented a basic NRG code in jax [19], using the included
AD routines to obtain derivatives via Eq. (21). The code
is available open-source at Ref. [45]. For simplicity we did
not exploit quantum numbers here, and so eigenstate de-
generacies were removed by adding Gaussian noise with a
11 (FD derivatives were calculated
small variance σ
for comparison without noise, σ = 0). In the following
we set the conduction electron half-bandwidth to D = 1
and use an NRG discretization parameter Λ = 3. Fur-
ther details on the numerical calculations and the ﬁnite
diﬀerence derivatives can be found in Appendix D and
Appendix E respectively.

10−

(cid:39)

First we use ∂NRG to compute the derivative of the
ground-state energy EN ;0 of the AIM with respect to the
interaction U . AD results in Fig. 1 (blue lines) are com-
pared with FD approximations (points), as a function of
U at iteration N = 5 (upper panel) and N = 40 (lower
0 derivatives.
panel), normalized by their respective U
The green lines show the variation of EN ;0 itself. The re-
sults show the non-trivial eﬀect of renormalization going
from N = 5 to N = 40 at intermediate U , as well as the
saturation of the ground state derivatives at both large
and small U . In this case we see excellent agreement be-
tween AD and FD results (although the former are far
less computationally expensive to obtain).

→

Fig. 2 demonstrates the use of ∂NRG to obtain ther-
modynamic quantities from derivatives of the NRG free
energy. The inset shows the impurity occupation
(cid:105) (cid:39)
5 (corresponding to
∂(cid:15)FN at a temperature T /D
N = 20 and ¯β = 0.9) for the same systems as in Fig. 1.

10−

∼

ˆn

(cid:104)

(cid:54)
7

Free energy derivatives of the AIM obtained
FIG. 2.
T ; main panel shows
ˆn
by ∂NRG. Inset shows ∂(cid:15)FN
(cid:105)
T , comparing AD (blue lines) with FD (red
∂U
∂U (∂(cid:15)FN )
points). Same parameters used as for Fig. 1, but with N = 20
and ¯β = 0.9 yielding an eﬀective temperature T /D
10−5.

(cid:39) (cid:104)

ˆn
(cid:105)

(cid:39)

3

(cid:104)

(cid:39)

×

such that we see distinct level structures associated with
the free orbital (FO), local moment (LM), and strong
coupling (SC) ﬁxed points as marked on the diagram. At
a ﬁxed point, the level structure does not change with N .
Indeed, the RG structure of the problem and resulting
universality implies that the ﬁxed point level structure is
the same, independent of the microscopic model parame-
ters U (
2(cid:15)) and V – only the crossover scales between
ﬁxed points are aﬀected.

≡ −

This is demonstrated in the bottom panel of Fig. 3,
where we plot the derivatives with respect to U of the
NRG energy levels EN ;i, again as a function of iteration
number N . As expected, the derivatives vanish at the
ﬁxed points (the level structure does not depend on U at
the ﬁxed points); but there is a strong dependence along
the crossovers, since the crossover scales depend on U .

VII. OUTLOOK: DYNAMICS
AND THE VERTEX

The above numerical results for the AIM are pro-
vided as a demonstration proof-of-principle. Future use-
ful applications exploiting the full power of ∂NRG may
be found for more complex models, situations involving
higher-order derivatives, optimization techniques requir-
ing exact gradients, or in cases where partial derivatives
of NRG outputs with respect to inputs are diﬃcult to ob-
tain by standard FD means. An example of the latter is
the derivative of frequency-dependent dynamical quanti-
ties, such as impurity Green’s functions or the conduction
electron scattering T-matrix, with respect to bare model
parameters.

In the context of dynamical mean ﬁeld theory (DMFT)

FIG. 1. Ground state energy EN ;0 of the AIM (green line) and
its normalized derivative ∂U EN ;0/ν0 obtained by ∂NRG (blue
line) and by FD (red circles) for iteration N = 5 (top panel)
and N = 40 (bottom panel). Results plotted as a function of
8V 2/U = 0.3. We deﬁne
U , with (cid:15) =
ν0 = ∂U EN ;0

U/2 and constant J
U→0 as the derivative in the limit U

0.

≡

−
|

→

(cid:105)

−

ˆn
(cid:104)

U/2, the AIM possesses an exact particle-
Since (cid:15) =
hole symmetry and hence is at half-ﬁlling,
= 1. The
AD results (blue line) satisfy this exact result precisely,
while the FD results (points) show some numerical error.
More interestingly, the ∂NRG framework allows to obtain
higher derivatives with equal ease (Eq. (B2) is used in-
stead of Eq. (18a)), as shown in the main panel of Fig. 2.
Here we calculate the corresponding second derivatives
∂2FN /∂U ∂(cid:15)
, which again show non-trivial be-
(cid:105)
haviour as a function of interaction strength U . The FD
approximations agree well, but are much more costly to
obtain [36], requiring for every point ﬁve executions of
the entire NRG code per second derivative, and an ex-
pensive convergence test. ∂NRG requires only a single
function evaluation (see Appendix C).

∂U

(cid:39)

ˆn

(cid:104)

As a ﬁnal application of ∂NRG for the AIM, we turn
to the RG energy level ﬂow diagram shown in the top
panel of Fig. 3. The excitation spectrum of the eﬀective
rescaled ˆHN plotted against iteration number N shows
the well-known ﬂow between ﬁxed points [1–3]. In the
example shown, the crossover scales are well-separated,

0.00.20.40.60.81.01ν0∂UEN;0N=510−210−1100101102U0.00.20.40.60.81.01ν0∂UEN;0DN=40−50−40−30−20−100EN;0−50−40−30−20−100EN;010−210−1100101102U−10−8−6−4−20∂U(∂(cid:15)FN)D10−21001021.00021.00011.0000−0.9999∂(cid:15)FN8

hybridization ∆ν(cid:48), viz:

δΣν
δ∆ν(cid:48)

= T [Gν(cid:48)]2F loc

νν(cid:48)(ω = 0) ,

(26)

where Gν(cid:48)
is the single-particle impurity Matsubara
Green’s function. For a precise deﬁnition and discussion
of F loc
νν(cid:48)(ω = 0), see Ref. [48, 51]. Since Gν(cid:48) and Σν can be
calculated within standard NRG [52], we argue that such
an object is obtainable within ∂NRG. We speculate that
a Keldysh version of Eq. 26 may similarly provide access
to certain information about the real-frequency vertex at
ﬁnite temperatures.

In order to calculate such derivatives of dynamical
quantities, further code development is required, since
the full-density-matrix NRG method would need to be
implemented using AD libraries such as jax [19] and inte-
grated within the ∂NRG scheme described in this paper.
We leave this for future work.

VIII. CONCLUSION

NRG is the gold-standard method of choice for solv-
ing generalized quantum impurity models [1, 2]. In this
work, we introduce a new variant of the standard al-
gorithm – ∂NRG – which makes use of the diﬀerential
programming paradigm to automatically and eﬃciently
obtain derivatives of NRG outputs with respect to input
model parameters.

We make use of the AD jax library [19], together with
a bespoke routine based on Eq. (21) which allows the
derivatives of Hamiltonian eigenvalues and eigenvectors
to be obtained at any iteration in an accurate and in-
expensive way. Our fully commented code is available
open-source [45].

We demonstrated the use of ∂NRG by application to
the Anderson impurity model, for which we obtained
the derivative of NRG energy levels with respect to
model parameters, calculated thermodynamic quantities
from derivatives of the NRG free energy, and suscep-
tibilities from derivatives of Hamiltonian source terms.
∂NRG may be useful for machine learning applications
involving NRG [47] for which gradient descent optimiza-
tion requires derivatives of a loss function;
for adap-
tive broadening schemes [53]; or for optimal control pro-
information may be ob-
tocols [29]. Richer physical
tained from derivatives of dynamical quantities. This
also opens the door to automatic diﬀerentiable DMFT,
with ∂NRG as the impurity solver. Finally, we note that
the ∂NRG methodology is compatible with interleaved-
NRG (iNRG) [54, 55] and generalizations utilising full
symmetries [43]. This is left for future work.

ACKNOWLEDGMENTS

Acknowledgments.– The authors thank Lei Wang,
Luuk Coopmans, Jan von Delft, Seung-Sup Lee, and

FIG. 3. Top panel: NRG energy level ﬂow diagram for the
AIM. The lowest 32 rescaled excitation energies ∆EN ;i above
the ground state at iteration N are plotted as a function of N
(for even N only). Plotted for model parameters U = 0.01,
8V 2/U = 0.2, with the free orbital (FO),
(cid:15) =
local moment (LM) and strong coupling (SC) regimes marked.
Bottom panel: the corresponding derivatives with respect to
U obtained by ∂NRG.

U/2, and J

≡

−

for correlated materials [12, 13, 46], model machine learn-
ing techniques [47] could be applied to optimize simpler
eﬀective models with respect to more complicated micro-
scopic ones, by comparing their Green’s functions. Given
the non-trivial dependence of such dynamical quantities
at diﬀerent energies on model parameters, the exact gra-
dient within the AD framework becomes an essential in-
gredient for gradient descent optimization.

Refs. [48, 49] recently uncovered the analytic structure
of the full local vertex and proposed a scheme to compute
it within NRG. The vertex is an important object, enter-
ing for example in extensions of DMFT beyond the local
limit [50]. It is possible that some partial information on
the vertex could also be obtained by ∂NRG. This is in-
spired by the result in Ref. [51] for the AIM which, within
the Matsubara formalism, connects the vertex at zero
bosonic frequency F loc
νν(cid:48)(ω = 0) to the functional deriva-
tive of the interaction self-energy Σν with respect to the

1020304050N−250−200−150−100−50050100150∂U∆EN;i0.00.51.01.52.0∆EN;iFOLMSC9

with mean µ = 0 and variance σ to the diagonal ele-
ments of ˆHN . We use the Kondo temperature TK as
one ﬁgure-of-merit for assessing the eﬀect of the noise
term. For simplicity we deﬁne the Kondo temperature
through the impurity entropy via Simp(T = TK) = 0.5
(suitably between the local moment and strong coupling
2
10−
ﬁxed point values). We compute TK for 10−
and diﬀerent numbers of kept states 100
500
(using ﬁxed Λ = 3). Fig. 4(a) shows clearly that for
6 the Kondo temperature does not noticeably
σ
depend on the noise level (we have conﬁrmed explicitly
15 that the results are fully converged
down to σ = 10−
for each MK). Other physical quantities computed in
standard NRG show similar behaviour.

σ
≤
MK

≤
≤

10−

≤

≤

8

(cid:104)

ˆSz

However, the eﬀect of adding noise is more pronounced
in derivatives. In Fig. 4(b) we compare ∂BFN ( ¯β)
B=0 =
|
ˆSz
(cid:105)HN , ¯β as a function of Wilson chain length N , as
(cid:104)
computed with ∂NRG and straight AD for diﬀerent
σ. Since the impurity magnetization is evaluated at
zero ﬁeld, SU (2) spin symmetry implies the exact re-
sult
(cid:105)HN , ¯β = 0. However, this spin symmetry is not
enforced, and so we see deviations due to the noise. As
Fig. 4(b) shows, ∂NRG accurately approximates the ex-
act result even at relatively high σ. By contrast, AD
yields derivatives that strongly depend on σ and have
much higher error than ∂NRG at a given σ.
Indeed,
derivatives are numerically not computable for all N in
standard forward mode AD for σ <
6; at larger noise
∼
levels, AD derivatives are computable but the accuracy
can become poor, especially at later iterations due to
the propagation and accumulation of errors through the
derivative chain rule.

10−

≤

10−

Therefore, although NRG for the AIM is insensitive to
6, the AD approach is not stable at these
noise for σ
noise levels. At higher noise levels, AD is stabilized, but
the accuracy suﬀers. On the other hand, ∂NRG avoids
such problems: a lower noise level can be used since each
derivative calculation is independent, and highly accurate
results can be obtained.

Within ∂NRG, the magnetization calculation via the
analog of Eq. (24) shown in Fig. 4(b) does not involve
eigenvector derivatives, and is therefore particularly sta-
ble. By contrast, the AD calculation of any derivative
is built up recursively via Eq. (3) and therefore does in-
volve the computation of eigenvector derivatives at each
and every step. This contributes to the relative perfor-
mance gain in ∂NRG.

In Fig. 5 we examine the magnetic susceptibility χ(T ).
The calculation of this quantity, which is obtained auto-
matically in ∂NRG via the second derivative of the NRG
free energy, is formally equivalent to the analytic expres-
sion, Eq. (25) (and does involve eigenvector derivatives).
Gaussian noise of width σ is added to the diagonal of ˆHN
at iteration N . The calculated χHN , ¯β at ¯β = 0.9 (used
hereafter) is then interpreted as the true χ(T ) at inverse
1)/2 ¯β. The numerical results from
temperature β = Λ(N
∂NRG show that χHN , ¯β is obtained reliably at all N (and
11. Only at smaller σ does
hence all T ) for σ as low as 10−

−

−

FIG. 4.
(a) Dependence of TK on the noise variance σ at
diﬀerent MK . The number of kept states ranges from 150
to 500 in steps of 50. The AIM model parameters used are
0.15, U = 0.3, V = 0.1 B = 0. (b) Zero-ﬁeld impu-
(cid:15) =
rity magnetization
computed via derivatives of the free
energy using ∂NRG and forward mode AD, as a function of
Wilson chain length N (for MK = 500). The noise variance
10−2. Same
10−8, 3
is σ = 1
×
model parameters as in (a).

10−7..., 1

10−7, 3

10−8, 1

ˆSz

×

×

×

×

(cid:104)

(cid:105)

Emma Minarelli for the helpful discussions. We acknowl-
edge funding from the Irish Research Council Laureate
Awards 2017/2018 through grant IRCLA/2017/169.

Appendix A: Numerical benchmarking: accuracy
and speedup

In this Appendix we demonstrate that: (i) NRG and
∂NRG are not aﬀected by the addition of Gaussian noise
with a small variance; and that (ii) the real-world per-
formance of ∂NRG exceeds that of basic AD and FD in
terms of both accuracy and speed.

A degeneracy-free NRG Hamiltonian is required for ap-
plication of Eq. (18). However, physical systems often do
have eigenvalue degeneracies, arising for example from
underlying symmetries. Although one can partially miti-
gate this problem by exploiting Abelian and non-Abelian
quantum numbers, some degeneracies may remain. Here
we consider the ‘worst case’ scenario in which no symme-
tries are exploited.

First we examine the eﬀect of adding Gaussian noise

1122436N10−1210−1010−810−610−410−2100|hˆSzi|b)forwardmodeAD1122436Nσ∂NRG10−810−710−610−510−410−310−210−810−610−410−2σ10−410−310−2TKMKa)15020025030035040045050010

FIG. 6. Representative calculation runtime in seconds, vs
number of kept states MK , comparing diﬀerent automatic
derivative techniques and computed quantities. In all cases
shown, blue lines correspond to ∂NRG with single diagonal-
ization, orange lines for ∂NRG with double diagonalization,
red lines for forward mode AD, and green lines for backward
ˆSz
(cid:105)HN , ¯β (solid lines)
mode AD. (a) Calculation at N = 40 of
(cid:104)
ˆSz
compared with the calculation of both
ˆn
(cid:105)HN , ¯β and
(cid:105)HN , ¯β
(cid:104)
(cid:104)
(dashed lines), obtained via the ﬁrst derivatives of the NRG
ˆSz
free energy. (b) Calculation for all N
(cid:105)HN , ¯β requir-
ing ﬁrst derivatives (solid lines), and χHN , ¯β requiring second
derivatives (dashed lines). Model parameters as in Fig. 4.

40 of

≤

(cid:104)

is only obtained in the δ
0 limit at the lowest temper-
ature scales. Finite δ at intermediate T appears to yield
rather poor results. We conclude that ∂NRG is indeed
the method of choice in this context, in terms of accuracy.

→

We now turn to an analysis of the real-world perfor-
mance of ∂NRG in terms of calculation time, compar-
ing with straight AD implemented in jax [19]. The ﬁg-
ure of merit is the runtime measured in seconds [s] of
both algorithms run on the same machine (in this case
an AMD Threadripper 2950X platform running Python
3.8.10 with the OMP_NUM_THREAD = 16 ﬂag; further pack-
age speciﬁcations can be found in [56]). We do not utilize
any quantum numbers here.

In Fig. 6(a) we compare the runtime for the calcula-

FIG. 5. (a) Magnetic susceptibility χ calculated with ∂NRG
for diﬀerent noise variances σ. (b) χ computed using forward
10−2. (c) χ computed with ∂NRG
mode AD and 10−8
σ
≤
using the pole broadening approach, with 10−15
100.
All calculations are performed with MK = 500 and with the
same AIM model parameters as in Fig. 4.

δ2

≤

≤

≤

the method break down: derivatives are then not com-
putable for earlier iterations/higher temperatures (the
correct low-T behavior is however still captured). As
demonstrated in Fig. 4 and conﬁrmed in Fig. 5(a), highly
6. Therefore in
accurate results are obtained for σ < 10−
6 over
∂NRG, we have a wide window 10−
which numerical results are fully converged and stable.

11 < σ < 10−

By contrast, in Fig. 5(b) we show results for the same
quantity obtained by straight AD. The calculation is not
numerically stable for small σ, but very inaccurate for
large σ (typical of the breakdown for higher-order deriva-
tives). As such there is no reliable regime for which ro-
bust results can be obtained by straight AD.

In Fig. 5(c) we examine the feasibility of an alterna-
tive approach to the eigenvalue-degeneracy problem that
avoids adding Gaussian noise. The method, proposed by
Liao et al in Ref. [31], consists of reformulating Eq. (18b),

=

i
d
(cid:105)
|

(cid:88)

i

=j

j
|
(cid:104)
λi

d ˆA

i
(cid:105)
|
λj

−

j
|

(cid:105) ≡

(cid:88)

i

=j

j
(cid:104)

|

d ˆA

i
|

(cid:105)

f (λi

λj)

,

j
|

(cid:105)

−

(A1)
with f (x) = 1/x. Divergences induced by eigenvalue de-
generacies can be avoided by replacing the function f (x)
x/(x2 +δ2)
with the approximate broadened form f (x)
with δ
1. This broadening approximation is known
to distort somewhat the overall results, but has the
advantage that divergences are removed without the
need to lift degeneracies. Fig. 5(c) shows numerical
results for χ(T ) obtained in this way, as a function of T
for diﬀerent broadenings δ. Although the method always
yields a computable result, the true result (dashed line)

(cid:28)

≈

10−610−410−2100T0.00.10.2Tχa)∂NRGσ=10−11σ=10−12σ=10−14σ=10−610−610−410−2100T0.000.01σb)forwardmodeAD10−610−510−410−310−210−510−310−1T0.00.10.2Tχδ2c)10−1510−1210−910−610−3100100200300400500MK1020304050t[s]a)derivativeatlargestN100200300400500MK101102103t[s]b)derivativeforallNhˆSziχhˆSzihˆSziandhˆni(cid:54)
(cid:54)
ˆSz
(cid:104)

ˆSz
(cid:104)

tion of (i)
(cid:105)HN , ¯β and
(cid:105)HN , ¯β (solid lines), and (ii)
(cid:105)HN , ¯β together (dashed lines); using ∂NRG (blue), for-
ˆn
(cid:104)
ward mode AD (red), and backward-mode AD (green),
at the last NRG iteration, N = 40. We see that for all
MK, ∂NRG performs best (with the relative speedup be-
coming more pronounced at larger MK). For straight
AD, we see that forward mode beats backward mode for
the calculation of a single derivative; but since backward
mode AD scales with the number of inputs rather than
outputs, it will overtake the forward mode when many
derivatives are calculated.

≤

ˆSz
(cid:104)

In Fig. 6(b) we compare runtimes using ∂NRG with a
single diagonalization of ˆHN (blue), ∂NRG with double
diagonalization of ˆHN (orange), and forward mode AD
(cid:105)HN , ¯β (solid lines), and χHN , ¯β
(red). We calculate
(dashed lines) at all iterations N
40. For the orange
lines, two diagonalizations of ˆHN are performed at each
step (with and without noise), which thereby eliminates
error propagation from the added noise and provides the
most accurate calculation (this may or may not be needed
in practice, depending on the situation). We see that
∂NRG with a single diagonalization per step is the fastest
in all cases. For the simpler quantity
(cid:105)HN , ¯β (which in-
volves only a ﬁrst-derivative), the ∂NRG using two diago-
nalizations and forward mode AD have similar runtimes,
although AD is slightly faster. However, for χHN , ¯β, both
versions of ∂NRG are considerably faster. This is because
the calculation of χHN , ¯β requires a second-derivative,
which is much more computationally expensive in AD,
but almost as cheap in ∂NRG. The relative performance
gain for ∂NRG also increases if several derivatives are
computed.

ˆSz

(cid:104)

11

In conclusion, in a typical setting, ∂NRG is consider-
ably more eﬃcient than AD (often by orders of magni-
tude) – while at the same time being more accurate.

Appendix B: Higher order derivatives

Eq. (18) allows us to take the derivatives of eigenval-
ues and eigenvectors of some Hermitian, non-degenerate
Hamiltonian ˆH. Consider now a Hamiltonian that can
be linearly decomposed as,

ˆH(

θ
{

) =
}

(cid:88)

θiˆhi ,

i

(B1)

where ˆhi is an operator deﬁned over the same Hilbert
space as ˆH, and with the corresponding coupling con-
stant θi a real scalar. In this case, all second order deriva-
tives of the Hamiltonian must vanish,
= 0. It is
then possible to derive a closed-form expression for the
second-order derivatives of eigenvalues and eigenvectors
with respect to the couplings θ1, θ2

∂2 ˆH
∂θi∂θj

θ
∈ {

, viz:
}

∂θ1∂θ2 Ei = 2

(cid:88)

∂θ2

i
|
(cid:104)

i

=j


∂θ1 ∂θ2|

i
(cid:105)

=

(cid:88)

=j
i

Πij

j
|

(cid:105)

where,

ˆH
j
|
Ei

∂θ1

j
|
(cid:105)(cid:104)
Ej
−

ˆH

i
(cid:105)

|

,

j
∂θ1
+ (cid:104)
|
λi

ˆH
i
|
λj

(cid:105)

(cid:88)

j

=k

(cid:104)

k
∂θ2
|
λj

ˆH
j
|
λk

−

−

(B2a)



(cid:105)

k
|

 ,
(cid:105)

(B2b)

∂θ2
i
|

(cid:104)

Πij =

−

ˆH
i
|
(λi

j
∂θ2
|
λj)2

(cid:105) − (cid:104)
−

ˆH

j
|

(cid:105)

∂θ1

ˆH

j
(cid:104)

|

+

i
(cid:105)

|

(cid:88)

j

=k

(cid:104)

j
∂θ2
|
λj

ˆH
k
|
λk

−

(cid:105)

k
(cid:104)

∂θ1
|

ˆH

+

i
(cid:105)
|

(cid:88)

k

=i

(cid:104)

k
∂θ2
|
λi

−

ˆH
i
j
(cid:105)
|
λk (cid:104)

ˆH

∂θ1
|

.

k
|

(cid:105)

(B3)

With these formulae one can compute physical observ-
ables depending on second-derivatives, such as suscepti-
bilities, using ∂NRG.

and forward tangent trace for the ∂NRG algorithm, see
Table II. For ∂NRG, we have one additional step in the
primal trace for the main algorithm (corresponding to
Eq. (16)), but a trivial tangent trace.

Appendix C: Comparing diﬀerentiation methods

The basic NRG algorithm is described in the main text,
with the key steps contained in Eq. (6)-(13). For more
details, see Ref. [2]. Assuming that degeneracies in the
NRG Hamiltonian ˆHN are lifted, we can use Eq. (18) to
compute the derivatives of eigenvectors and eigenvalues
of ˆHN . The Wengert list [37, 57] with the forward primal
trace (function evaluation) and the forward tangent trace
(function diﬀerentiation) can then be compiled, as shown
in Table I. Similarly we compile the forward primal trace

×

We can now compare the eﬃciency of the two ap-
proaches.
For forward mode AD (fAD) we have
ops(fAD) = 7N , and to compute forward primal and
tangent traces, 2
ops(fAD) operations are required. For
∂NRG by contrast, ops(∂NRG) = 8N , but no other step
is required to compute the derivative of ˆHN . However,
this does not mean that ∂NRG is twice as fast as fAD
because the bottleneck eigensolver routines [58] appear
only in the forward primal trace. Nonetheless ∂NRG
still provides a considerable performance advantage, as
established by explicit benchmarks in Appendix A

(cid:54)
(cid:54)
(cid:54)
(cid:54)
(cid:54)
Forward Primal Trace

Forward Tangent Trace

12

tn

v−3 = Λ
v−2 =
{
v−1 = η
v0 = Himp
v1 = EIGENVALUES(v0)

}

v2 = EIGENVECTORS(v0)
v3 = vT
−1
FOR n = 0 to N
v7n+4 = v7n
[v7n+5]iiss = v1/2
[v7n+6]ii(cid:48)ss(cid:48) = (
σ[v7n+3]σii(cid:48) [v−1]σss(cid:48)
[v7n+7]ii(cid:48)ss(cid:48) = [v7n+5]ii(cid:48)ss(cid:48) + [v7n+6]ii(cid:48)ss(cid:48) + [v7n+6]†
v7n+8 = EIGENVALUES(v7n+7)

−3 [v7n+1]l
1)i(cid:48)

[v−2]n

(cid:80)

−

ii(cid:48)ss(cid:48)

v7n+9 = EIGENVECTORS(v7n+7)
[v7n+10]σii(cid:48) = (cid:80)

jj(cid:48) [v7n+9]†

(cid:80)

ss(cid:48)

i;sj[v7n+9]i;s(cid:48)j(cid:48) [v−1]σss(cid:48)

dv−3 = 0
dv−2 = 0
dv−1 = 0
dv0 = dHimp
[dv1]i = [v2]†
i ·
[dv2]i = (cid:80)
j(cid:54)=i
dv3 = 0
FOR n = 0 to N

dv0
[v2]†

[v2]i
·
j ·dv0·[v2]i

[v1]i−[v1]j

[v2]j

(cid:80)

dv7n+4 = dv7n
[dv7n+5]iiss = v1/2
−3 [dv7n+2]l
1)i(cid:48)
[v−2]n
[dv7n+6]ii(cid:48)ss(cid:48) = (
−
[dv7n+8]i = [v7n+9]†
dv7n
i ·
[dv7n+8]i = [v7n+9]†
dv7n
i ·
[v7n+9]†
[dv7n+9]i = (cid:80)
[v7n+8]i−[v7n+8]j
(cid:16)
(cid:80)
[dv7n+10]σii(cid:48) = (cid:80)
[dv7n+9]†
+ [v7n+9]†

[v7n+9]i
[v7n+9]i
j ·dv7n·[v7n+9]i

i;sj[dv7n+9]i;s(cid:48)j(cid:48)

[v−1]σss(cid:48)

j(cid:54)=i

ss(cid:48)

jj(cid:48)

·
·

(cid:17)

σ[dv7n+3]σii(cid:48) [v−1]σss(cid:48)

[v7n+9]j

i;sj[v7n+9]i;s(cid:48)j(cid:48)

y0 = v7N +7

dy0 = dv7N +7

TABLE I. Wengert list for NRG with forward mode AD. Left column: the primal trace prescribes all steps to be performed to
execute an NRG calculation with N iterations. Right column: the tangent trace prescribes all steps to compute the derivative
the NRG Hamiltonian ˆHN .

Forward Primal Trace

Forward Tangent Trace

dv−4 = dHimp
dv−3 = 0
dv−2 = 0
dv−1 = 0
dv−4 = 0

}

tn

(cid:80)

v−4 = dHimp
v−3 = Λ
v−2 =
{
v−1 = η
v0 = Himp
v1 = EIGENVALUES(v0)
v2 = EIGENVECTORS(v0)
v3 = vT
−1
[v4]ii(cid:48) = (cid:80)
FOR n = 0 to N
v8n+5 = v8n
[v8n+6]iiss = v1/2
[v8n+7]ii(cid:48)ss(cid:48) = (
σ[v8n+3]σii(cid:48) [v−1]σss(cid:48)
[v8n+8]ii(cid:48)ss(cid:48) = [v8n+6]ii(cid:48)ss(cid:48) + [v8n+7]ii(cid:48)ss(cid:48) + [v8n+7]†
v8n+9 = EIGENVALUES(v8n+8)
v8n+10 = EIGENVECTORS(v8n+8)
[v8n+11]σii(cid:48) = (cid:80)
[v8n+12]ii(cid:48) = (cid:80)

(cid:80)
jj(cid:48) [v8n+10]†
jj(cid:48) [v8n+10]†

−3 [v8n+1]l
1)i(cid:48)

i;sj[v2]i;s(cid:48)j(cid:48) [v−4]jj(cid:48) δss(cid:48)

jj(cid:48) [v2]†

[v−2]n

(cid:80)

(cid:80)

−

ss(cid:48)

ss(cid:48)

ss(cid:48)

ii(cid:48)ss(cid:48)

i;sj[v8n+10]i;s(cid:48)j(cid:48) [v−1]σss(cid:48)
i;sj[v8n+10]i;s(cid:48)j(cid:48) [v8n+4]jj(cid:48) δss(cid:48)

y0 = v8N +8

dy0 = v8N +12

TABLE II. Wengert list for ∂NRG. Left column: the forward primal trace for ∂NRG outputs the NRG Hamiltonain ˆHN and its
derivative d ˆHN . Since derivatives are computed via Eq. (21) in the main algorithm, there is no corresponding forward tangent
trace in the Right column.

13

Appendix E: Details of ﬁnite diﬀerence calculations

We calculate the ﬁnite diﬀerence (FD) derivative of a

function f via,

Dh[f ](x) =

f (x + h)
h

−

f (x)

,

(E1)

→

where h is the FD value. The FD derivative is connected
to the deﬁnition of the derivative by taking the limit,
∂f
∂x = limh

0 Dh[f ](x).

In practice we compute FD derivatives for a set of ﬁnite
, and check for convergence. However, care must be
hi
{
}
taken due to the trade-oﬀ between round-oﬀ and trun-
cation errors [37]. The truncation error arises due to the
ﬁnite h > 0, which is required for the numerical evalua-
tion of Dh[f ](x), and which would diminish in the formal
limit h
0. However for very small h, the diﬀerence in
the function evaluations for f (x) and f (x + h) cannot
be distinguished numerically due to inevitable round-oﬀ
errors in any ﬁnite precision arithmetic. This leads to
increasing errors as h

→

0.

We quantify the FD error as,

→

∆(h) =

(cid:12)
(cid:12)
(cid:12)
(cid:12)

Dh[f ](x)

∂f
∂x

(cid:12)
(cid:12)
(cid:12)
(cid:12)

.

−

(E2)

ˆn

This quantity is plotted in Fig. 7 for the derivative of the
AIM impurity occupation with respect to the impurity
(cid:105)HN , ¯β. We have used the ∂NRG deriva-
interaction, ∂U
(cid:104)
tive as the true value of ∂f
∂x in Eq. (E2). Fig. 7 shows
rather typical behavior, with truncation errors dominat-
ing at large h and round-oﬀ errors dominating at small h,
with a stability plateau in between where the derivative
should be evaluated. However, comparison of the upper
and lower panels (which correspond to model parameters
2 and U = 102 respectively), demonstrates an
U = 10−
important limitation of FD diﬀerentiation: the optimal h
is not ﬁxed but depends on input model parameters. Re-
liable results therefore require such a convergence analy-
sis for each new set of model parameters and for each new
derivative. This becomes computationally costly. The
situation becomes signiﬁcantly worse when considering
higher-order derivatives.

FIG. 7. FD derivative errors ∆(h) vs FD value h for the
calculation of ∂U
(cid:105)HN , ¯β at N = 40. Shown for AIM model
ˆn
(cid:104)
U/2, V = 0.1 and B = 0 with (a) U = 0.01,
parameters (cid:15) =
−
and (b) U = 100. In all cases MK = 500.

Appendix D: Details of numerics - NRG calculations

We used standard thermodynamic NRG [1] to calcu-
late the free energy, impurity occupation and eigenvalues
of ˆHN . An NRG discretization parameter Λ = 3 was
used, and MK = 200 states were retained at each step
for Figs. (1) and (3), while MK = 600 states were re-
tained for Fig. (2). No quantum numbers were used in
this demonstration calculation.

[1] Kenneth G Wilson, “The renormalization group: Critical
phenomena and the kondo problem,” Reviews of modern
physics 47, 773 (1975).

[2] Ralf Bulla, Theo A Costi, and Thomas Pruschke, “Nu-
merical renormalization group method for quantum im-
purity systems,” Reviews of Modern Physics 80, 395
(2008).

[3] Alexander Cyril Hewson, The Kondo problem to heavy

fermions, 2 (Cambridge university press, 1997).

[4] Andrew K Mitchell, Michael Becker,

and Ralf Bulla,
“Real-space renormalization group ﬂow in quantum im-
purity systems: local moment formation and the kondo
screening cloud,” Physical Review B 84, 115120 (2011).
[5] TA Costi, Lars Bergqvist, A Weichselbaum, J Von Delft,
T Micklitz, A Rosch, P Mavropoulos, Peter H Dederichs,
Francois Mallet, Laurent Saminadayar, et al., “Kondo
decoherence: Finding the right spin model for iron im-
purities in gold and silver,” Physical review letters 102,

10−1210−910−610−3h10−2100102∆(h)round-oﬀerrortruncationerrorU=0.01a)10−1210−910−610−3100h10−710−410−1∆(h)round-oﬀerrortruncationerrorU=100b)056802 (2009).

[6] David Goldhaber-Gordon, Hadas Shtrikman, D Mahalu,
and MA Kastner,
David Abusch-Magder, U Meirav,
“Kondo eﬀect in a single-electron transistor,” Nature
391, 156–159 (1998).

[7] AJ Keller, S Amasha, I Weymann, CP Moca, IG Rau,
JA Katine, Hadas Shtrikman, G Zar´and,
and
D Goldhaber-Gordon, “Emergent su (4) kondo physics
in a spin–charge-entangled double quantum dot,” Nature
Physics 10, 145–150 (2014).

[8] Z Iftikhar, S´ebastien Jezouin, A Anthore, U Gennser,
FD Parmentier, A Cavanna, and F Pierre, “Two-channel
kondo eﬀect and renormalization ﬂow with macroscopic
quantum charge states,” Nature 526, 233–236 (2015);
Andrew K Mitchell, LA Landau, L Fritz, and E Sela,
“Universality and scaling in a charge two-channel kondo
device,” Physical review letters 116, 157202 (2016);
Z Iftikhar, A Anthore, AK Mitchell, FD Parmentier,
U Gennser, A Ouerghi, A Cavanna, C Mora, P Simon,
and F Pierre, “Tunable quantum criticality and super-
ballistic transport in a “charge” kondo circuit,” Science
360, 1315–1320 (2018).

[9] Winston Pouse, Lucas Peeters, Connie L Hsueh, Ulf
Gennser, Antonella Cavanna, Marc A Kastner, An-
drew K Mitchell, and David Goldhaber-Gordon, “Ex-
otic quantum critical point in a two-site charge kondo
circuit,” arXiv preprint arXiv:2108.12691 (2021).
[10] Wenjie Liang, Matthew P Shores, Marc Bockrath, Jef-
frey R Long, and Hongkun Park, “Kondo resonance in a
single-molecule transistor,” Nature 417, 725–729 (2002).
[11] Andrew K Mitchell, Kim GL Pedersen, Per Hedeg˚ard,
and Jens Paaske, “Kondo blockade due to quantum in-
terference in single-molecule junctions,” Nature commu-
nications 8, 1–10 (2017).

[12] Gabriel Kotliar, Sergej Y Savrasov, Kristjan Haule, Vik-
tor S Oudovenko, O Parcollet,
and CA Marianetti,
“Electronic structure calculations with dynamical mean-
ﬁeld theory,” Reviews of Modern Physics 78, 865 (2006).
[13] Antoine Georges, Gabriel Kotliar, Werner Krauth, and
Marcelo J Rozenberg, “Dynamical mean-ﬁeld theory of
strongly correlated fermion systems and the limit of in-
ﬁnite dimensions,” Reviews of Modern Physics 68, 13
(1996).

[14] KM Stadler, ZP Yin, J Von Delft, G Kotliar, and A We-
ichselbaum, “Dynamical mean-ﬁeld theory plus numer-
ical renormalization-group study of spin-orbital separa-
tion in a three-band hund metal,” Physical review letters
115, 136401 (2015).

[15] Andreas Weichselbaum, Frank Verstraete, Ulrich
Schollw¨ock, J Ignacio Cirac, and Jan von Delft, “Varia-
tional matrix-product-state approach to quantum impu-
rity models,” Physical Review B 80, 165117 (2009).
[16] Emanuel Gull, Andrew J Millis, Alexander I Licht-
enstein, Alexey N Rubtsov, Matthias Troyer,
and
Philipp Werner, “Continuous-time monte carlo meth-
ods for quantum impurity models,” Reviews of Modern
Physics 83, 349 (2011).

[17] Ian Goodfellow, Yoshua Bengio, and Aaron Courville,

Deep learning (MIT press, 2016).

[18] Michael Bartholomew-Biggs, Steven Brown, Bruce Chris-
tianson, and Laurence Dixon, “Automatic diﬀerentiation
of algorithms,” Journal of Computational and Applied
Mathematics 124, 171–190 (2000).

14

Matthew James Johnson, Chris Leary, Dougal Maclau-
rin, George Necula, Adam Paszke, Jake VanderPlas,
Skye Wanderman-Milne, and Qiao Zhang, “JAX: com-
posable transformations of Python+NumPy programs,”
(2018).

[20] Mart´ın Abadi, Ashish Agarwal, Paul Barham, Eugene
Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado,
Andy Davis, Jeﬀrey Dean, Matthieu Devin, Sanjay Ghe-
mawat, Ian Goodfellow, Andrew Harp, Geoﬀrey Irving,
Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz
Kaiser, Manjunath Kudlur, Josh Levenberg, Dande-
lion Man´e, Rajat Monga, Sherry Moore, Derek Mur-
ray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit
Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker,
Vincent Vanhoucke, Vijay Vasudevan, Fernanda Vi´egas,
Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin
Wicke, Yuan Yu, and Xiaoqiang Zheng, “TensorFlow:
Large-scale machine learning on heterogeneous systems,”
(2015), software available from tensorﬂow.org.

[21] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer,
James Bradbury, Gregory Chanan, Trevor Killeen, Zem-
ing Lin, Natalia Gimelshein, Luca Antiga, Alban Des-
maison, Andreas Kopf, Edward Yang, Zachary DeVito,
Martin Raison, Alykhan Tejani, Sasank Chilamkurthy,
Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chin-
tala, “Pytorch: An imperative style, high-performance
deep learning library,” in Advances in Neural Infor-
mation Processing Systems 32 , edited by H. Wallach,
H. Larochelle, A. Beygelzimer, F. d'Alch´e-Buc, E. Fox,
and R. Garnett (Curran Associates, Inc., 2019) pp. 8024–
8035.

[22] Teresa Tamayo-Mendoza, Christoph Kreisbeck, Roland
Lindh,
and Al´an Aspuru-Guzik, “Automatic diﬀeren-
tiation in quantum chemistry with applications to fully
variational hartree–fock,” ACS central science 4, 559–566
(2018).

[23] Shi-Xin Zhang, Zhou-Quan Wan, and Hong Yao, “Au-
tomatic diﬀerentiable monte carlo: Theory and applica-
tion,” arXiv preprint arXiv:1911.09117 (2019).

[24] Hao Xie, Jin-Guo Liu, and Lei Wang, “Automatic dif-
ferentiation of dominant eigensolver and its applications
in quantum physics,” Physical Review B 101, 245139
(2020).

[25] Nick McGreivy, Stuart R Hudson, and Caoxiang Zhu,
“Optimized ﬁnite-build stellarator coils using automatic
diﬀerentiation,” Nuclear Fusion 61, 026020 (2021).

[26] Boris Ponsioen, Fakher F Assaad,

and Philippe Cor-
boz, “Automatic diﬀerentiation applied to excitations
with projected entangled pair states,” arXiv preprint
arXiv:2107.03399 (2021).

[27] Sebastian Dick and Marivi Fernandez-Serra, “Us-
ing diﬀerentiable programming to obtain an energy
and density-optimized exchange-correlation functional,”
arXiv preprint arXiv:2106.04481 (2021).

[28] Luuk Coopmans, Di Luo, Graham Kells, Bryan K Clark,
and Juan Carrasquilla, “Protocol discovery for the quan-
tum control of majoranas by diﬀerentiable program-
ming and natural evolution strategies,” PRX Quantum
2, 020332 (2021).

[29] Rodrigo A Vargas-Hern´andez, Ricky TQ Chen, Ken-
neth A Jung, and Paul Brumer, “Fully diﬀerentiable op-
timization protocols for non-equilibrium steady states,”
arXiv preprint arXiv:2103.12604 (2021).

[19] James Bradbury, Roy Frostig,

Peter Hawkins,

[30] Zhou-Quan Wan, Shi-Xin Zhang, and Hong Yao, “Miti-

gating sign problem by automatic diﬀerentiation,” arXiv
preprint arXiv:2010.01141 (2020).

[31] Hai-Jun Liao, Jin-Guo Liu, Lei Wang, and Tao Xiang,
“Diﬀerentiable programming tensor networks,” Physical
Review X 9, 031041 (2019).

[32] Wei-Lin Tu, Huan-Kuang Wu, Norbert Schuch, Naoki
Kawashima, and Ji-Yao Chen, “Generating function for
tensor network diagrammatic summation,” Physical Re-
view B 103, 205155 (2021).

[33] Seppo Linnainmaa, “Taylor expansion of the accumu-
lated rounding error,” BIT Numerical Mathematics 16,
146–160 (1976).

[34] Gottfried Tinhofer, Rudolf Albrecht, Ernst Mayr, Hart-
and Maciej M Syslo, Computational
mut Noltemeier,
graph theory, Vol. 7 (Springer Science & Business Media,
2012).

[35] Andreas Griewank and Andrea Walther, Evaluating
derivatives: principles and techniques of algorithmic dif-
ferentiation (SIAM, 2008).

[36] Christian Grossmann, Hans-G¨org Roos,

and Martin
Stynes, Numerical treatment of partial diﬀerential equa-
tions, Vol. 154 (Springer, 2007).

[37] Atilim Gunes Baydin, Barak A Pearlmutter, Alexey An-
dreyevich Radul, and Jeﬀrey Mark Siskind, “Automatic
diﬀerentiation in machine learning: a survey,” Journal of
machine learning research 18 (2018).

[38] Andreas Weichselbaum and Jan von Delft, “Sum-rule
conserving spectral functions from the numerical renor-
malization group,” Physical review letters 99, 076402
(2007).

[39] Matthias Seeger, Asmus Hetzel, Zhenwen Dai, Eric
Meissner, and Neil D Lawrence, “Auto-diﬀerentiating
linear algebra,” arXiv preprint arXiv:1710.08717 (2017).
[40] Mike Giles, “An extended collection of matrix derivative
results for forward and reverse mode automatic diﬀeren-
tiation,” (2008).

[41] Richard Phillips Feynman, “Forces in molecules,” Phys-

ical review 56, 340 (1939).

[42] R Lane Dailey, “Eigenvector derivatives with repeated

eigenvalues,” AIAA journal 27, 486–491 (1989).

[43] Andreas Weichselbaum, “Non-abelian symmetries in ten-
sor networks: A quantum symmetry space approach,”
Annals of Physics 327, 2972–3047 (2012).

[44] Cheolhee Han, Andrew K Mitchell, Zubair Iftikhar,
Yaakov Kleeorin, Anne Anthore, Fr´ed´eric Pierre, Yi-
gal Meir, and Eran Sela, “Extracting entropy of exotic
quasiparticles from conductance measurements,” arXiv
preprint arXiv:2108.12878 (2021).

[45] https://github.com/JonasRigo/AD-Numerical-

Renormalization-Group (2021).

[46] Evan Sheridan, Christopher Rhodes, Francois Jamet,

15

Ivan Rungger, and Cedric Weber, “Data-driven dynam-
ical mean-ﬁeld theory: An error-correction approach to
solve the quantum many-body problem using machine
learning,” Physical Review B 104, 205120 (2021).
[47] Jonas B Rigo and Andrew K Mitchell, “Machine learning
eﬀective models for quantum systems,” Physical Review
B 101, 241105 (2020).

[48] Fabian B Kugler, Seung-Sup B Lee, and Jan von Delft,
“Multipoint correlation functions: spectral representa-
tion and numerical evaluation,” Physical Review X 11,
041006 (2021).

[49] Seung-Sup B Lee, Fabian B Kugler, and Jan von Delft,
“Computing local multipoint correlators using the nu-
merical renormalization group,” Physical Review X 11,
041007 (2021).

[50] G Rohringer, H Hafermann, A Toschi, AA Katanin,
AE Antipov, MI Katsnelson, AI Lichtenstein,
AN Rubtsov,
and K Held, “Diagrammatic routes
to nonlocal correlations beyond dynamical mean ﬁeld
theory,” Reviews of Modern Physics 90, 025003 (2018).
[51] Erik GCP van Loon, Friedrich Krien, and Andrey A
Katanin, “Bethe-salpeter equation at the critical end
point of the mott transition,” Physical Review Letters
125, 136402 (2020).

[52] ˇZiga Osolin et al., “Pad´e approximant approach for ob-
taining ﬁnite-temperature spectral functions of quan-
tum impurity models using the numerical renormaliza-
tion group technique,” Physical Review B 87, 245135
(2013).

[53] Seung-Sup B Lee and Andreas Weichselbaum, “Adap-
tive broadening to improve spectral resolution in the nu-
merical renormalization group,” Physical Review B 94,
235127 (2016).

[54] Andrew K Mitchell, Martin R Galpin, Samuel Wilson-
Fletcher, David E Logan, and Ralf Bulla, “Generalized
wilson chain for solving multichannel quantum impurity
problems,” Physical Review B 89, 121105 (2014).
[55] KM Stadler, AK Mitchell, J von Delft, and A Weichsel-
baum, “Interleaved numerical renormalization group as
an eﬃcient multiband impurity solver,” Physical Review
B 93, 235101 (2016).

[56] https://github.com/JonasRigo/Summer-

Wine/wiki/Build-BLAS-on-a-TR2-NUMA-platform
(2019).

[57] Robert Edwin Wengert, “A simple automatic derivative
evaluation program,” Communications of the ACM 7,
463–464 (1964).

[58] James W Demmel, Osni A Marques, Beresford N Par-
lett, and Christof V¨omel, “Performance and accuracy of
lapack’s symmetric tridiagonal eigensolvers,” SIAM Jour-
nal on Scientiﬁc Computing 30, 1508–1526 (2008).

