Minimal Cycle Representatives in Persistent Homology using
Linear Programming: an Empirical Study with User’s Guide

Lu Li *

Connor Thompson †

Gregory Henselman-Petrusek ‡

lli1@macalester.edu

thomp774@purdue.edu

henselmanpet@maths.ox.ac.uk

Chad Giusti §

Lori Ziegelmeier *

cgiusti@udel.edu

lziegel1@macalester.edu

Abstract

Cycle representatives of persistent homology classes can be used to provide descriptions of topological
features in data. However, the non-uniqueness of these representatives creates ambiguity and can lead
to many different interpretations of the same set of classes. One approach to solving this problem is to
optimize the choice of representative against some measure that is meaningful in the context of the data.
In this work, we provide a study of the effectiveness and computational cost of several (cid:96)1-minimization
optimization procedures for constructing homological cycle bases for persistent homology with rational
coefﬁcients in dimension one, including uniform-weighted and length-weighted edge-loss algorithms as
well as uniform-weighted and area-weighted triangle-loss algorithms. We conduct these optimizations via
standard linear programming methods, applying general-purpose solvers to optimize over column bases
of simplicial boundary matrices.

Our key ﬁndings are: (i) optimization is effective in reducing the size of cycle representatives, though
the extent of the reduction varies according to the dimension and distribution of the underlying data, (ii)
the computational cost of optimizing a basis of cycle representatives exceeds the cost of computing such a
basis, in most data sets we consider, (iii) the choice of linear solvers matters a lot to the computation time
of optimizing cycles, (iv) the computation time of solving an integer program is not signiﬁcantly longer
than the computation time of solving a linear program for most of the cycle representatives, using the
Gurobi linear solver, (v) strikingly, whether requiring integer solutions or not, we almost always obtain a
solution with the same cost and almost all solutions found have entries in {−1, 0, 1} and therefore, are
also solutions to a restricted (cid:96)0 optimization problem, and (vi) we obtain qualitatively different results for
generators in Erd˝os-Rényi random clique complexes than in real-world and synthetic point cloud data.

Keywords: topological data analysis, computational persistent homology, minimal cycle repre-

sentatives, generators, linear programming, (cid:96)1 and (cid:96)0 minimization

1
2
0
2

t
c
O
8
1

]
T
A
.
h
t
a
m

[

3
v
5
2
0
7
0
.
5
0
1
2
:
v
i
X
r
a

1 Introduction

Topological data analysis (TDA) uncovers mesoscale structure in data by quantifying its shape using methods
from algebraic topology. Topological features have proven effective when characterizing complex data, as
they are qualitative, independent of choice of coordinates, and robust to some choices of metrics and moderate

*Macalester College, Mathematics, Statistics, and Computer Science Department, Saint Paul, MN, USA.
†Purdue University, Department of Mathematics, West Lafayette, IN, USA.
‡Mathematical Institute, University of Oxford, UK.
§University of Delaware, Department of Mathematical Sciences, Newark, DE, USA.

1

 
 
 
 
 
 
quantities of noise [30, 9]. As such, topological features extracted from data have recently drawn attention
from researchers in various ﬁelds including, for example, neuroscience [31, 1, 53], computer graphics [8, 52],
robotics [4, 61], and computational biology [3, 59, 43] (including the study of protein structure [40, 64, 65].)
The primary tool in TDA is persistent homology (PH) [28], which describes how topological features of
data, colloquially referred to as “holes", evolve as one varies a real-valued parameter. Each hole comes with
a geometric notion of dimension which describes the shape that encloses the hole: connected components
in dimension zero, loops in dimension one, shells in dimension two, and so on. From a parameterized
topological space X = (Xt)t∈S⊂R≥0, for each dimension n, PH produces a collection Barcoden(X) of
lifetime intervals L which encode for each topological feature the parameter values of its birth, when it ﬁrst
appears, and death, when it no longer remains.

A basic problem in the practical application of PH is interpretability: given an interval L ∈ Barcoden(X),
how do we understand it in terms of the underlying data? A reasonable approach would be to ﬁnd an element
of the homology class, also known as a cycle representative, that witnesses structure in the data that has
meaning to the investigator. In the context of geometric data, this takes the form of an “inverse problem,"
constructing geometric structures corresponding to each persistent interval in the original input data. For
example, a representative for an interval L ∈ Barcode1(X) consists of a closed curve or linear combination
of closed curves which enclose a set of holes across the family of spaces (Xt)t∈L⊂S. Cycle representatives
are used in [24] to annotate particular loops as chromatin interactions, and [63] uses cycle representatives to
study and locate and reconstruct ﬁne muscle columns in cardiac trabeculae restoration.

Figure 1: Two disks (grey) — which we regard as 2-dimensional simplicial complexes, though the explicit
decomposition into simplices is not shown — with different numbers of holes (white) and cycle representatives
(solid or dotted) from [9]. The disk on the left has a single 2-dimensional “hole” (β1 = 1), and the two loops
around it are cycle representatives for the same homology class. Similarly, the disk on the right has three
“holes” (β1 = 3) and the two loops shown are cycle representatives for different homology classes.

An important challenge, however, is that cycle representatives are not uniquely deﬁned. For example, in
the left-hand image in Figure 1 from [9], two curves enclose the same topological feature and thus, represent
the same persistent homology class. We often want to ﬁnd a cycle that captures not only the existence but
also information about the location and shape of the hole that the homology class has detected. This often
means optimizing an application-dependent property using the underlying data, e.g. ﬁnding a minimal length
or bounding area/volume using an appropriate metric. The algorithmic problem of selecting such optimal
representatives is currently an active area of research [18, 19, 46, 63, 13].

There are diverse notions of optimality we may wish to consider in a given context, and which may have

signiﬁcant impact on the effectiveness or suitability of optimization, including

2

• weight assignment to chains (uniform versus length or area weighted),

• choice of loss function ((cid:96)0 versus (cid:96)1),

• formulation of the optimization problem (cycle size versus bounded area or volume), and

• restrictions on allowable coefﬁcients (rational, integral, or {0, 1, −1}).

Each has a unique set of advantages and disadvantages. For example, optimization using the (cid:96)0 norm with
{0, 1, −1}-coefﬁcients is thought to yield the most interpretable results, but (cid:96)0 optimization is NP-hard, in
general [12]. The problem of ﬁnding (cid:96)1 optimal cycles with rational coefﬁcients, can be formulated as a
more tractable linear programming problem. While some literature exists to inform this choice [18, 27, 46],
questions of basic importance remain, including:

Q1 How do the computational costs of the various optimization techniques compare? How much do these

costs depend on the choice of a particular linear solver?

Q2 What are the statistical properties of optimal cycle representatives? For example, how often does the
support of a representative form a single loop in the underlying graph? And, how much do optimized
cycles coming out of an optimization pipeline differ from the representative that went in?

Q3 To what extent does choice of technique matter? For example, how often does the length of a length-
weighted optimal cycle match the length of a uniform-weighted optimal cycle? And, how often are (cid:96)1
optimal representatives (cid:96)0 optimal?

Given the conceptual and computational complexity of these problems (see [12]), the authors expect
that formal answers are unlikely to be available in the near future. However, even where theoretical results
are available, strong empirical trends may suggest different or even contrary principles to the practitioner.
For example, while the persistence calculation is known to have matrix multiplication time complexity [44],
in practice the computation runs almost always in linear time. Therefore, the authors believe that a careful
empirical exploration of questions 1-3 will be of substantial value.

In this paper, we undertake such an exploration in the context of one-dimensional persistent homology
over the ﬁeld of rationals, Q. We focus on linear programming (LP) and mixed-integer programming (MIP)
approaches due to their ease of use, ﬂexibility, and adaptability. In doing so, we present a new treatment of
parameter-dependence (vis-a-vis selection of simplex-wise reﬁnements) relevant to common cases of rational
cycle representative optimization [46, 27], such as ﬁnding optimal cycle bases for the persistent homology of
the Vietoris-Rips complex of a point cloud. We restrict our attention to one-dimensional homology to limit
the number of reported statistics and data visualizations presented, although the methods discussed could be
applied to any homological dimension.

The paper is organized as follows. Section 2 provides an overview of some key concepts in TDA to
inform a reader new to algebraic topology and establish notation. Then, we provide a survey of previous
work on ﬁnding optimal persistent cycle representatives in Section 3, and formulate the methods used in
this paper to ﬁnd different notions of minimal cycle representatives via LP and MIP in Section 4. Section 5
describes our experiments, including overviews of the data and the hardware and software we use for our
analysis. In Section 6, we discuss the results of our experiments. We conclude and describe possible future
work in Section 7.

2 Background: Topological Data Analysis and Persistent Homology

In this section, we introduce key terms in algebraic and computational topology to provide minimal back-
ground and establish notation. For a more thorough introduction see, for example, [9, 35, 23, 29, 22, 58].

3

Given a discrete set of sample data, we approximate the topological space underlying the data by
constructing a simplicial complex. This construction expresses the structure as a union of vertices, edges,
triangles, tetrahedrons, and higher dimensional analogues [9].
Simplicial Complexes. A simplicial complex is a collection K of non-empty subsets of a ﬁnite set V . The
elements of V are called vertices of K, and the elements of K are called simplices. A simplicial complex has
the following properties: (1) {v} in K for all v ∈ V , and (2) τ ⊂ σ and σ ∈ K guarantees that τ ∈ K.

Additionally, we say that a simplex has dimension n or is an n-simplex if it has cardinality n+1. We use

Sn(K) to denote the collection of n-simplices contained in K.

While there are a variety of approaches to create a simplicial complex from data, our examples use a
standard construction for approximation of point clouds. Given a metric space X with metric d and real
number (cid:15) ≥ 0, the Vietoris-Rips complex for X, denoted by VR(cid:15)(X), is deﬁned as

VR(cid:15)(X) = {σ ∈ Sn(K) | d(x, y) ≤ (cid:15) for all x, y ∈ σ}.

That is, given a set of discrete points X and a metric d, we build a VR complex at scale (cid:15) by forming an
n-simplex if and only if n + 1 points in X are pairwise within (cid:15) distance of each other.
Chains and chain complexes. Given a simplicial complex K and an abelian group G, the group of n-chains
in K with coefﬁcients in G is deﬁned as

Cn(K; G) := GSn(K).

Formally, we regard GSn(K) as a group of functions Sn(K) → G under element-wise addition. Al-
ternatively, we may view Cn(K; G) as a group of formal G-linear combinations of n-simplices, i.e.
{(cid:80)

σ xσσ | xσ ∈ G and σ ∈ Sn(K)}.

Remark 2.1 We will focus on the cases where G is Q (the ﬁeld of rationals), Z (the group of integers),
or F2 (the 2-element ﬁeld). Since we are most interested in the case G = Q, we adopt the shorthand
Cn(K) = Cn(K, Q).

An element x = (xσ)σ∈Sn(K) ∈ GSn(K) is called an n-chain of K. As in this example, we will generally
use a bold-face symbol for the tuple x and corresponding light-face symbols for entries xσ. The support of
an n-chain is the set of simplices on which xσ is nonzero:

The (cid:96)0 norm1 and (cid:96)1 norm2 of x are deﬁned as

supp(x) := {σ ∈ Sn(K) | xσ (cid:54)= 0}.

||x||0 := |supp(x)|

||x||1 := (cid:80)

σ∈Sn(K) |xσ|

Remark 2.2 (Indexing conventions for chains and simplices) As chains play a central role in our discus-
sion, it will be useful to establish some special conventions to describe them. These conventions depend on
the availability of certain linear orders, either on the set of vertices or the set of simplices.
Case 1: Vertex set V has a linear order ≤. Every vertex set V discussed in this text will be assigned a
(possibly arbitrary) linear order. Without risk of ambiguity, we may therefore write

1The (cid:96)0 “norm” is not a real norm as it does not satisfy the homogeneous requirement of a norm. For example, scaling a vector x

by a constant factor does not change its (cid:96)0 “norm”.

2See Remark 2.1. These choices of groups have a natural notion of absolute value.

(v0, . . . , vn)

4

for the n-chain that places a coefﬁcient of 1 on σ = {v0 ≤ · · · ≤ vn} and 0 on all other simplices.
Case 2: Simplex set Sn(K) has a linear order ≤. We will sometimes deﬁne a linear order on Sn(K). This
determines a unique bijection σ(n) : {1, . . . , |Sn(K)|} → Sn(K) such that σ(n)
iff i ≤ j. This
bijection determines an isomorphism

i ≤ σ(n)

j

φ : Cn(K; G) = GSn(K) → G|Sn(K)|

such that φ(x)i = xσi for all i. Provided a linear order ≤, we will use x to denote both x and φ(x) and rely
on context to clarify the intended meaning.

For each n ≥ 1, the boundary map ∂n : Cn(K) → Cn−1(K) is the linear transformation deﬁned on a

basis vector (v0, v1, . . . , vn) by

∂n(v0, v1, . . . , vn) = (cid:80)n

i=0(−1)i(v0, . . . , ˆvi, . . . , vn)

where ˆvi omits vi from the vector. This map extends linearly from the basis of n-simplices to any n-chain in
Cn(K). By an abuse of notation, we also denote the matrix representation of this boundary map, known
as the boundary matrix, as ∂n. The boundary matrix is parametrized by the n-simplices Sn(K) along the
columns and n − 1-simplices Sn−1(K) along the rows.

The collection (Cn(K))n≥0 along with the boundary maps (∂n)n≥0 form a chain complex

. . . Cn+1(K)

∂n+1−−−→ Cn(K) ∂n−→ Cn−1(K)

∂n−1−−−→ . . . ∂3−→ C2(K) ∂2−→ C1(K) ∂1−→ C0(K) ∂0−→ 0.

Remark 2.3 (Indexing conventions for boundary matrices) In general, boundary matrix ∂n is regarded
as an element of GSn−1(K)×Sn(K), that is, as an array with columns labeled by n-simplices and rows labeled
by n − 1-simplices. However, given linear orders on Sn−1(K) and Sn(K), we may naturally regard ∂n as
an element of G|Sn−1(K)|×|Sn(K)|, see Remark 2.2.

Cycles, boundaries. The boundary of an n-chain x is ∂n(x). An n-cycle is an n-chain with zero boundary.
The set of all n-cycles forms a subspace Zn(K) := ker(∂n) of Cn(K). An n-boundary is an n-chain that
is the boundary of (n + 1)-chains. The set of all n-boundaries forms a subspace Bn(K) := im(∂n+1) of
Cn(K). We refer to Zn and Bn as the space of cycles and space of boundaries, respectively.

It can be shown that ∂n ◦ ∂n+1(x) = 0 for all x ∈ Cn+1(K); colloquially, “a boundary has no boundary”.
Equivalently, ∂n ◦ ∂n+1 is the zero map. Since the boundary map takes a boundary to 0, an n-boundary must
also be an n-cycle. Therefore, Bn(K) ⊆ Zn(K).
Homology, cycle representatives. The nth homology group of K is deﬁned as the quotient

Hn(K) := Zn(K)/Bn(K).

Concretely, elements of Hn(K) are cosets of the form [z] = {z(cid:48) ∈ Zn(K)|z(cid:48) − z ∈ Bn(K)}.3 An element
h ∈ Hn(K) is called an n-dimensional homology class. We say that a cycle z ∈ Zn(K) represents h, or that
z is a cycle representative of h if h = [z]. We say that z and z(cid:48) are homologous if [z] = [z(cid:48)].

3More generally, we denote the groups of cycles and boundaries with coefﬁcients in G as Zn(K; G) and Bn(K; G). The

(dimension-n) homology of K with coefﬁcients in G is Hn(K; G) = Zn(K; G)/Bn(K; G).

5

Figure 2: We show an example of homologous cycles in (A), taken from [58]. The 1-cycle (0, 1) + (1, 2) +
(2, 3) + (3, 4) − (0, 4) and the 1-cycle (1, 2) + (2, 3) + (3, 4) − (4, 1) are homologous because their difference
is the boundary of (0, 1, 4). Subﬁgure (B) shows an example of non-homologous cycles. The 1-cycle
((cid:80)4
i=0(i, i + 1)) − (5, 2) + (2, 6) − (0, 6) and the 1-cycle (2, 3) + (3, 4) + (4, 5) − (2, 5) are not homologous
because their difference is a cycle (0, 1) + (1, 2) + (2, 6) − (0, 6) which is not a linear combination of
boundaries of 2-simplices.

Example Consider the example in Figure 2 (A), which illustrates two homologous 1-cycles and the example
in Figure 2 (B), which illustrates two non-homologous cycles.

Remark 2.4 The term homological generator has been used differently by various authors: to refer to an
arbitrary nontrivial homology class, an element in a (ﬁnite) representation of Hn(K), as a set of cycles
which generate the homology group, or (particularly in literature surrounding optimal cycle representatives)
interchangeably with cycle representative. We favor the term cycle representative, to avoid ambiguity.

Betti numbers, cycle bases. A (dimension-n) homological cycle basis for Hn(K) is a set of cycles
B = {z1, . . . , zm} such that [zi] (cid:54)= [zj] when i (cid:54)= j, and {[z1], . . . , [zm]} is a basis for Hn(K). Modulo
boundaries, every n-cycle can be expressed as a unique linear combination in B.

Homological cycle bases have several useful interpretations. It is common, for example, to think of a
1-cycle as a type of “loop,” generalizing the intuitive notion of a loop as a simple closed curve to include
more intricate structures, and to regard the operation of adding boundaries as a generalized form of “loop-
deformation.” Framed in this light, a homological cycle basis B for H1(K) can be regarded as a basis for the
space of loops-up-to-deformation in K. Higher dimensional analogs of loops involve closed “shells” made
up of n-simplices.

Another interpretation construes each nontrivial homology class [z] (cid:54)= 0 as a hole in K. Such holes are
“witnessed" by loops or shells that are not homologous to the zero cycle. Viewed in this light, Hn(K) can
naturally be regarded as the space of (n + 1)-dimensional holes in K. The rank of the nth homology group

βn(K) := dim(Hn(K)) = dim(Zn(K)) − dim(Bn(K)),

therefore quantiﬁes the “number of independent holes” in K. We call βn the nth Betti number of K.
Example Consider the gray disks in Figure 1 (similar to a ﬁgure from [9]) with different numbers of holes
and cycle representatives.

6

Filtrations of simplicial complexes. A ﬁltration on a simplicial complex K is a nested sequence of simplicial
complexes K• = (K(cid:15)i)i∈{1,...,T } such that

K(cid:15)1 ⊆ K(cid:15)2 ⊆ · · · ⊆ K(cid:15)T = K

where (cid:15)1 < · · · < (cid:15)T are real numbers. A ﬁltered simplicial complex is a simplicial complex equipped with a
ﬁltration K•.
Example Let X be a metric space with metric d, and let (cid:15)1 < · · · < (cid:15)T be an increasing sequence of non-
negative real numbers. Then the sequence K• = (K(cid:15)i)i∈{1,...,T } deﬁned by K(cid:15)i = VR(cid:15)i(X) is a ﬁltration on
K.

The data of a ﬁltered complex is naturally captured by the birth function on simplices, deﬁned

Birth : K → R, σ (cid:55)→ min{(cid:15)i : σ ∈ K(cid:15)i}.

We regard the pair (K, Birth) as a simpilicial complex whose simplices are weighted by the birth function.
For convenience, we will implicitly identify the sequence K• with this weighted complex. Thus, for example,
when we say that σ ∈ K has birth parameter t, we mean that σ ∈ K and Birth(σ) = t.

Deﬁnition 2.5 A ﬁltration K• is simplex-wise if one can arrange the simplices of K into a sequence
(σ1, . . . , σ|K|) such that K(cid:15)i = {σ1, . . . , σi} for all i. A simplex-wise reﬁnement of K• is a simplex-wise
ﬁltration K(cid:48)

• such that each space in K• can be expressed in form {σ1, . . . , σj} for some j.

As an immediate corollary, given a simplex-wise reﬁnement of K•, we may naturally interpret each
boundary matrix ∂n as an element of G|Sn−1(K)|×|Sn(K)|, see Remark 2.3. Under this interpretation, columns
(respectively, rows) with larger indices correspond to simplices with later birth times; that is, birth time
increases as one moves left-to-right and top-to-bottom.
Filtrations of chain complexes. If we regard Cn(K(cid:15)i; G) as a family of formal linear combinations in
Sn(K(cid:15)i), then it is natural to consider Cn(K(cid:15)i; G) as a subgroup of Cn(K(cid:15)j ; G) for all i < j. In particular,
we have an inclusion map

ι : Cn(K(cid:15)i; G) → Cn(K(cid:15)j ; G), (cid:80)

Given a simplex-wise reﬁnement K(cid:48)

σ∈Sn(K(cid:15)i ) xσσ (cid:55)→ (cid:80)

σ∈Sn(K(cid:15)i ) xσσ + (cid:80)
•, one can naturally regard c as an element (c1, c2, . . .) of G|Sn(K(cid:15)i )|.

τ /∈Sn(K(cid:15)i ) 0 · τ

From this perspective, ι has a particularly simple interpretation, namely “padding” by zeros:

, 0, . . . , 0)
ι(c) = (c1, c2, . . .
(cid:124)
(cid:125)

(cid:123)(cid:122)
c

Similar observations hold when one replaces Cn with either Zn, the space of cycles, or Bn, the space of
boundaries.
Persistent homology, birth, death. The notion of birth for simplices has a natural extension to chains, as
well as a variant called death. Formally, the birth and death parameters of c ∈ Cn(K) are

Birth(c) = min{(cid:15)i : c ∈ Cn(K(cid:15)i)}

Death(c) =

(cid:40)

min{(cid:15)i : c ∈ B(K(cid:15)i)} c ∈ B(K)
∞

else.

In the special case where c is a cycle, Birth(c) is the ﬁrst parameter value where [c] represents a homology
class, and Death(c) is the ﬁrst parameter value where [c] represents the zero homology class. Thus, the
half-open lifespan interval

L(c) = [Birth(c), Death(c))

7

is the range of parameters over which c represents a well-deﬁned, nonzero homology class.

A (dimension-n) persistent homology cycle basis is a subset B ⊆ Zn(K) with the following two

properties:

1. Each z ∈ B has a nonempty lifespan interval.

2. For each i ∈ {1, . . . , T }, the set

is a homological cycle basis for Hn(K(cid:15)i).

B(cid:15)i := {z ∈ B : (cid:15)i ∈ L(z)}

Every ﬁltration of simplicial complexes (K(cid:15)i)i∈{1,...,T } admits a persistent homological cycle basis B
[67]. Moreover, it can be shown that the multiset of lifespan intervals (one for each basis vector), called the
dimension-n barcode of K•,

is invariant over all possible choices of persistent homological cycle bases B [67].

Barcoden = {L(z) : z ∈ B}

Figure 3: Examples of optimizing a cycle representative (using the notion of minimizing edges) within the
same homology class (A-D) and using a basis of cycle representatives (E), modiﬁed examples taken from [27]
and [46]. The dotted lines represent a cycle representative for the enclosed “hole”. Intuitively, we consider
x(cid:48)(cid:48) in (D) as the optimal cycle representative since it consists of the smallest number of edges. Subﬁgure
(E) shows a case where we optimize a cycle representative using a basis of cycle representatives. In (E),
{x4, x5, x6} is the original basis of cycle representatives. We can substitute x6 with ˆx6, which we can obtain
by adding x5 to x6, and thus obtain {x4, x5, ˆx6} as the new basis of cycle representatives.

Example Consider the sequence of simplicial complexes (K1, K2, K3) shown in Figure 3 (E). The set
B = {x4, x5, x6} is a (dimension-1) persistent homological cycle basis of the ﬁltration. The associated
dimension-1 barcode is Barcode1 = {[1, 2), [2, ∞), [3, ∞)} where [2, ∞) and [3, ∞) are the lifespans of x5
and x6, respectively.

Barcodes are among the foremost tools in topological data analysis [29, 22], and they contain a great
deal of information about a ﬁltration. For example, it follows immediately from the deﬁnition of persistent
homological cycle bases that βn(K(cid:15)i) = |B(cid:15)i| for all n and i. Consequently,

βn(K(cid:15)i) = |{J ∈ Barcoden : (cid:15)i ∈ J}|.

8

Computing PH cycle representatives. Barcodes and persistent homology bases may be computed via
the so-called R = DV decomposition [14] of the boundary matrices ∂n. Details are discussed in the
Supplementary Material.

3 Related work on minimizing cycle representatives

One important problem in TDA is interpreting homological features. In general, a lifetime interval L
corresponding to a feature may be represented by many different cycle representatives. As discussed in [11],
localizing homology classes can be characterized as ﬁnding a representative cycle with the most concise
geometric measure. As an illustrative example from [27], Figure 3 (A) shows a simplicial complex K
with H1(K) isomorphic to Q or equivalently, β1 = 1; it contains one hole. Figures 3 (B), (C), and (D)
display three cycle representatives, xOrig, x(cid:48), and x(cid:48)(cid:48), each of which represents the same homology class
(heuristically, they encircle the same hole). We intuitively prefer x(cid:48)(cid:48) as a representative, since it involves the
fewest edges and “hugs” the hole most tightly. Given a simplicial complex K and a nontrivial cycle xOrig on
it, we are interested in ﬁnding a cycle representative that is optimal with respect to some geometric criterion.
In this section, we discuss previous studies on optimal cycle representatives.

Minimal cycle representatives have proven useful in many applications. Hiraoka et al. [39] use TDA
to geometrically analyze amorphous solids. Their analysis using minimal cycle representatives explicitly
captures hierarchical structures of the shapes of cavities and rings. Wu et al. [63] discuss an application
of optimal cycles in Cardiac Trabeculae Restoration, which aims to reconstruct trabeculae, very complex
muscle structures that are hard to detect by traditional image segmentation methods. They propose to use
topological priors and cycle representatives to help segment the trabeculae. However, the original cycle
representative can be complicated and noisy, causing the reconstructed surface to be messy. Optimizing the
cycle representatives makes the cycle more smooth and thus, leads to more accurate segmentation results.
Emmett et al. [24] use PH to analyze chromatin interaction data to study chromatin conformation. They use
loops to represent different types of chromatin interactions. To annotate particular loops as interactions, they
need to ﬁrst localize a cycle. Thus, they propose an algorithm to locate a minimal cycle representative for a
given PH class using a breadth-ﬁrst search, which ﬁnds the shortest path that contains the edge that enters the
ﬁltration at the birth time of the cycle and is homologically independent from the minimal cycles of all PH
classes born before the current cycle.

There are several approaches used to deﬁne an optimal cycle representative. Dey et al. [18] propose an
algorithm to ﬁnd an optimal homologous 1-cycle for a given homology class via linear programming. That is,
they consider a single homology class [x] and search for a homologous cycle representative that minimizes
some geometric measure within that class, for instance, the number of 1-simplices within the representative.
Escolar and Hiraoka [27] extend this approach to ﬁnd an optimal cycle by using cycles outside of a single
homology class to “factor out" redundant information. In this approach, an optimal cycle representative is no
longer guaranteed to be homologous to the original representative, but the collection of cycle representatives
have each been independently optimized and the collection still forms a homology basis. Further, [27]
extends this approach to achieve a ﬁltered cycle basis, although we note that it is not guaranteed to be a
persistent homology basis. The two approaches in [18, 27] aim to minimize the number of 1-simplices in a
cycle representative. Obayashi [46] proposes an alternative algorithm for ﬁnding volume-optimal cycles in
persistent homology, which minimize the number of 2-simplices which the cycle representative bounds, also
using linear programming. These methods serve as the foundation for our present paper and are discussed in
more detail in the rest of this section.

In addition to linear programming, many researchers have contributed to the problem of computing
optimal cycles: Wu et al. [63] propose an algorithm for ﬁnding shortest persistent 1-cycles. They ﬁrst
construct a graph based on the given simplicial complex and then compute annotation for the given complex.

9

The annotation assigns all edges different vectors and can be used to verify if a cycle belongs to the desired
group of cycles. They then ﬁnd the shortest path between two vertices of the edge born at the birth time of
the original cycle representative using a new A∗ heuristic search strategy. Their algorithm is a polynomial
time algorithm but in the worst case, the time complexity is exponential to the number of topological features.
Dey et al. [21] propose a polynomial-time algorithm that computes a set of loops from a VR complex of the
given data whose lengths approximate those of a shortest basis of the one dimensional homology group H1.
In [19], Dey et al. show that ﬁnding optimal (minimal) persistent 1-cycles is NP-hard and then propose a
polynomial time algorithm to ﬁnd an alternative set of meaningful cycle representatives. This alternative
set of representatives is not always optimal but still meaningful because each persistent 1-cycle is a sum of
shortest cycles born at different indices. They ﬁnd shortest cycles using Dijkstra’s algorithm by considering
the 1-skeleton as a graph. This list is by no means exhaustive, and does not touch on the wide variety of
related approaches, e.g. [12], which attempts to ﬁt cycle representatives within a ball of minimum radius.

In the next subsection, we brieﬂy introduce some basic notions of linear programming, and then in the

subsequent three subsections, we survey the optimization problems on which the present work is based.

3.1 Background: Linear Programming

Linear programming seeks to ﬁnd a set of decision variables x = (x1, . . . , xη)T which optimize a linear cost
(or objective) function cT x subject to a set of linear (in)equality constraints aT
µ x = bµ. Any
linear optimization problem can be written as a Linear Program (LP) in standard form

1 x = b1, . . . , aT

minimize cT x
subject to Ax = b,

x ≥ 0

(1)

where A is the µ × η matrix with coefﬁcients of the constraints as rows and b = (b1, . . . , bµ)T . Linear
programming is well-studied and discussed in many texts [2, 60, 6].

The optimal solution x∗ satisﬁes the constraints while optimizing the objective function, yielding the
optimal cost cT x∗. The feasible set of solutions in a linear optimization problem is a polyhedron deﬁned
by the linear constraints. In general, the optimal solution of a (non-degenerate) LP will occur at a vertex of
the polyhedron and can be solved with the standard simplex algorithm, which traverses through the edges
of the polytope to vertices in a cost reducing manner, or interior point methods, which traverse along the
inside of the polytope to reach an optimal vertex. In the worst-case, the complexity of the simplex method is
exponential, yet it often runs remarkably fast, while interior point methods are polynomial time algorithms.
Standard LPs search for real-valued optimal solutions, but in some instances, a restriction of the decision
variables, such as requiring integral solutions, may be necessitated. The mixed integer programming (MIP)
problem is written

minimize cT x + dT y
subject to Ax + By = b,

x, y ≥ 0

x integer

(2)

for matrices A, B and vectors b, c, d. A standard LP has fewer constraints, and thus, will have optimal cost
less than or equal to that of the analogous MIP. MIPs are much more challenging to solve than LPs, as
they are discrete as opposed to convex optimization problems, and no efﬁcient general algorithm is known
[2]. However, LP relaxations, (exponential-time) exact, (polynomial-time) approximation, and heuristic
algorithms can be used to obtain solutions to MIPs.

10

In this paper, we determine optimal cycle representatives with both LP and MIP formulations.

3.2 Minimal cycle representatives of a homology class

Given a homology class h = [xOrig] ∈ Hn(K; G) and a function loss : Zn(K; G) → R, how does one
ﬁnd a cycle representative of h on which loss attains minimum? This problem is equivalent to solving the
following program deﬁned in [18]:

minimize loss(x)
subject to x = xOrig + ∂n+1w,

w ∈ Cn+1(K; G).

(3)

This formulation considers all cycle representatives homologous to xOrig, i.e. that differ by a boundary, and
selects the optimal representative x which minimizes loss. Program (3) is correct because the coset h can be
expressed in the form

h = xOrig + Bn(K; G) = {xOrig + ∂n+1w | w ∈ Cn+1(K; G)}

In practice, a cycle representative xOrig is almost always provided together with the initial problem data

(which consists of K, G, loss, and h), so the central challenge lies with solving Program (3).

Several variants of Program (3) have been studied, especially where loss(x) = ||x||0 or loss(x) = ||x||1.
For a survey of results when G = F2, see [12]. For a discussion of results when G = Z, see [18]. Broadly
speaking, minimizing against (cid:96)0 tends to be hard, even when K has attractive properties such as embeddability
in a low-dimensional Euclidean space [5]. Minimizing against (cid:96)1 is hard when G = F2 (since, in this case,
(cid:96)1 = (cid:96)0), but tractable via linear programming when G ∈ {Q, R}.

An interesting variant of the minimal cycle representative problem is the minimal persistent cycle
representative problem. This problem was described in [11] and may be formulated as follows: given an
interval [a, b) ∈ Barcoden(K•), solve

minimize loss(x)
subject to Birth(x) = a
Death(x) = b
x ∈ Zn(Ka; G)

(4)

for x. An advanced treatment of this problem can be found in [11] for special case where (i) G = F2, (ii) loss
is a weighted sum of incident edges, and (iii) the birth function assigns distinct values to any two simplices of
the same dimension, and (iv) n = 1.

3.3 Minimal homological cycle bases

Program (3) has a natural extension when G is a ﬁeld. This extension focuses not on the smallest representative
of a single homology class, but the smallest homological cycle basis. It may be formally expressed as follows:

minimize (cid:80)
subject to B ∈ HCBn(K; G)

x∈B loss(x)

(5)

where HCBn(K, G) is the family of dimension-n homological cycle bases of Hn(K; G). Thus, the program
is ﬁnding a complete generating set B for all of the homological cycles of dimension n where each element
has been minimized in some sense.

11

It is natural to wonder whether a solution to Program (5) could be obtained by ﬁrst calculating an arbitrary
(possibly non-minimal) homological cycle basis B = {x1, . . . , xm} and then selecting an optimal cycle
representative zi from each homology class [xi]. Unfortunately, the resulting basis need not be optimal. To
see why, consider the simplicial complex K3 shown in Figure 3 (E), taking G to be Q and loss to be the (cid:96)0
norm. Complex K• has several different homological cycle bases in degree 1, including B0 := {ˆx6, x6},
B1 := {x5, x6}, and B2 := {x5, ˆx6 + x4}. However, only B0 is (cid:96)0-minimal. Moreover, each of the cycle
representatives x5, x6, ˆx6 is already minimal within its homology class, so element-wise minimization will
not transform B1 or B2 into optimal bases, as might have been hoped.

As with the minimal cycle representative problem, the minimal homological cycle basis problem has
been well-studied in the special case where loss is the (cid:96)0 norm and G = F2. In this case, Equation (5) is
NP-hard to approximate for n > 1, but O(n3) when n = 1 [20]. Several interesting variants and special
cases have been developed in the n = 1 case, as well [21, 25, 13]. We are not currently aware of a systematic
treatment for the case G ∈ {Q, R}.

A natural variant of the minimal homological cycle basis problem in Equation (5) is the minimal persistent

homological cycle basis problem

minimize (cid:80)
subject to B ∈ PrsHCBn(K•; G)

x∈B loss(x)

(6)

where PrsHCBn(K•; G) is the set of persistent homological cycle bases. This is a stricter condition than
Program (5) in that not only does it require that the elements of B form a generating set of all cycles of
dimension n, but the barcode associated to B must match Barcoden(K•). That is, the multisets of birth/death
pairs must be identical.

Program (6) is much more recent than Program (5), and consequently appears less in the literature. In
the special case where every bar in the multiset Barcoden(K•) has multiplicity 1 (i.e. there are no duplicate
bars), Program (6) can be solved by making one call to the minimal persistent cycle representative Program
(4) for each bar. In particular, the method of [11] may be applied to obtain a minimal persistent basis when
the correct hypotheses are satisﬁed: G = F2, loss is a weighted sum of incident simplices, there are distinct
birth times for all simplices of the same dimension, and n = 1. In general, however, bars of multiplicity 2 are
possible, and in this case repeated application of Program (4) will be insufﬁcient.

3.4 Minimal ﬁltered cycle space bases

A close cousin of the minimal homological cycle basis Program (5) is the minimal ﬁltered cycle basis problem,
which may be formulated as follows

minimize (cid:80)
subject to C ∈ FCB(K•; G)

x∈C loss(x)

(7)

where FCB(K•) is the family of all bases C of Zn(K(cid:15)T ) such that C contains a basis for each subspace
Zn(K(cid:15)i), for i ∈ {1, . . . , T }.

Escolar and Hiraoka [27] provide a polynomial time solution via linear programming when

1. loss is the (cid:96)1 norm,

2. G = Q, and

3. K• is a simplex-wise ﬁltration (without loss of generality, K• = (K1, . . . , KT )).

Their key observation is that C is an optimal solution to Program (6) if and only if C can be expressed as

a collection {zj : j ∈ J} where

12

1. the the set J = {j : Zn(Kj−1) (cid:40) Zn(Kj)} that indexes the cycles is the list of ﬁltrations at which a

novel n-cycle appears, and

2. for each j ∈ J, the cycle zj ﬁrst appears in Kj and is a minimizer for the loss function among all such

cycles, i.e. zj ∈ argminz∈Zn(Kj )\Zn(Kj−1)loss(z).

The authors formulate this problem as

minimize ||x||1
subject to x = xOrig +

wrgr +

(cid:88)

r∈R

vsf s

(cid:88)

s∈S

w ∈ QR
v ∈ QS

(8)

where xOrig ∈ ZN (Kj)\ZN (Kj−1) is a novel cycle representative at ﬁltration j; {gr : r ∈ R} is a basis for
Bn(Kj−1)4; and {gr : r ∈ R} ∪ {f s : s ∈ S} is an extension of the given basis for Bn(Kj−1) to a basis for
Zn(Kj−1). That is, xOrig is a cycle that has just appeared in the ﬁltration. To optimize it, we are allowed
to consider linear combinations of both boundaries, {gr}, and cycles, {f s}, born before xOrig. The cycle
x obtained in this way cannot have a birth time before that of xOrig, but may have a different death time if
[(cid:80)

s∈S vsf s] dies later than [xOrig].
The algorithm developed in [27] is cleverly constructed to extract xOrig, {gr : r ∈ R}, and {f s : s ∈ S}

from matrices which are generated in the normal course of a barcode calculation.

Remark 3.1 It is important to distinguish between PrsHCB and FCB, hence between the optimization
Programs (6) and (7). As Escolar and Hiraoka [27] point out, given B ∈ PrsHCB and C ∈ FCB, one can
always ﬁnd an injective function φ : B → C such that Birth(z) = Birth(φ(z)) for all z. However, this
does not imply that φ(B) ∈ PrsHCB, as the deaths of each cycle may not coincide. Indeed, the question of
whether a persistent homological cycle basis can be extracted from C by any means is an open question, so
far as we are aware. We provide an example in Figure 4 where the cycle basis obtained by optimizing each
cycle using Program (7) is not a persistent homology cycle basis B.

Though Remark 3.1 is a bit disappointing for those interested in persistent homology, the machinery

developed to study Program (7) is nevertheless interesting, and we will discuss an adaptation.

3.5 Volume-optimal cycles: minimizing over bounding chains

Schweinhart [51] and Obayashi [46] consider a different notion of minimization: volume5 optimality. This
approach focuses on the “size” of a bounding chain; it is speciﬁcally designed for cycle representatives in a
persistent homological cycle basis.

Obayashi [46] formalizes the approach as follows. First, assume a simplex-wise ﬁltration K•; without
loss of generality, K• = (K1, . . . , KT ), and we may enumerate the simplices of KT such that Ki =
{σ1, . . . , σi} for all i. Since each simplex has a unique birth time, each interval in Barcoden(K•) =
{[b1, d1), . . . , [bN , dN )} has a unique left endpoint. Fix [bi, di) ∈ Barcoden(K•) such that di < ∞ (in the
case di = ∞, volume is undeﬁned). It can be shown that σbi is an n-simplex and σdi is an (n + 1)-simplex.

4Because of the assumption that K• is a simplex-wise ﬁltration, if there is a new n-cycle in Kj then there cannot also be a new

(n + 1)-simplex, so this is also a basis for Bn(Kj).

5This notion of volume differs from that of [12]. The latter refers to volume as the (cid:96)0 norm of a chain, while the former (which

we discuss in this section) refers to the (cid:96)0 norm of a bounding chain.

13

Figure 4: An example where the optimal cycles obtained from Program (8) do not form a persistent
homological cycle basis. The thickened colored cycles in Subﬁgure (A) represent a cycle representative
for the hole it encloses, and the bar with the corresponding color in Subﬁgure (B) records the lifespan of
the cycle. In Subﬁgure (A), we see L(x1) = [0, ∞), L(x2) = [1, 2). Then, {x1, x2} forms a basis for the
persistent homological cycles. The cycle representative ˆx2 is an optimal cycle representative obtained by
solving Program (7) for the ﬁltered simplicial complex K2. However, L(ˆx2) = [1, ∞), and thus {x1, ˆx2} is
no longer a persistent homological cycle basis.

14

A persistent volume v for [bi, di) is an (n + 1) chain v ∈ Cn+1(Kdi) such that6

v = σdi +

(cid:88)

αkσk

σk∈Fn+1

(∂n+1v)τ = 0 ∀τ ∈ Fn
(cid:54)= 0,
(∂n+1v)σbi

(9)

(10)

(11)

where Fn = {σk ∈ Sn(K) : bi < k < di} denotes the n-simplices alive in the window between the birth
and death time of the interval under consideration.

We interpret these equations as follows: Given a persistence interval [bi, di), condition (17) implies that
v only contains n + 1-simplices born between bi and di and must contain the n + 1-simplex born at di.
Condition (18) ensures that the boundary of v contains no n-simplex born after bi, and condition (19) ensures
that the boundary of v contains the n-simplex born at bi. This guarantees that ∂n+1v exists at step bi, does
not exist before step bi, and dies at step di.

Theorem 3.2 (Obayashi [46]) Suppose that [bi, di) ∈ Barcoden(K•) and di < ∞.

1. Interval [bi, di) has a persistent volume.

2. If v is a persistent volume for [bi, di) then L(∂n+1v) = [bi, di).

3. Suppose that B is an n-dimensional persistent homological cycle basis for K•, that xOrig ∈ B
is the basis vector corresponding to [bi, di), and that v is a persistent volume for [bi, di). Then,
(B\{xOrig}) ∪ {∂n+1v} is also a persistent homological cycle basis.

By Theorem 3.2, for any barcode composed of ﬁnite intervals, one can construct a persistent homological
cycle basis from nothing but (boundaries of) persistent volumes! Were we to build such a basis, it would be
natural to ask for volumes that are optimal with respect to some loss function; that is, we might like to solve

minimize loss(v)
subject to (17), (18), (19)
v ∈ Cn+1(Kdi)

(12)

for each barcode interval [bi, di). A solution v to Program (10) is called an optimal volume; its boundary,
x = ∂n+1v is called a volume-optimal cycle.

It is interesting to contrast (cid:96)0-minimal cycle representatives for an interval7 [bi, di) with (cid:96)0 volume-
optimal cycle for the same interval. Consider, for example, Figure 5. For the persistence interval [bi, di), the
cycle with minimal number of edges is (a, b) + (b, c) + (c, d) + (d, a). However, the volume-optimal cycle
would be found as follows: considering Kdi, we must ﬁnd the fewest 2-simplices whose boundary captures
the persistence interval. In this case, we would have an optimal volume (a, b, e) + (b, c, e) + (a, d, e) and
volume-optimal cycle (a, b) + (b, c) + (c, e) + (e, d) + (d, a).

6If we regard ∂n+1v as a function Sn(Kdi ) → Q, then (∂nv)τ is the value taken by ∂nv on simplex τ . Alternatively, if we

regard ∂nv as a linear combination of n-simplices, then (∂nv)τ is the coefﬁcient placed by ∂nv on τ .

7Technically, this notion is not well-deﬁned; to be formal, we should ﬁx a persistent homology cycle basis B, ﬁx a cycle
representative z ∈ B with lifespan interval [bi, di), and ask for an (cid:96)0 cycle representative in the same homology class, [z] ∈ Hn(Kbi ),
as per Program (3). However, in simple cases the intended meaning is clear.

15

Figure 5: A situation in which a volume-optimal cycle is different from the uniform minimal cycle. Consider
the ﬁltered simplicial complex pictured. For the persistence interval [bi, di), the cycle with minimal 0-norm
(fewest number of edges) is (a, b) + (b, c) + (c, d) + (d, a). However, the volume-optimal cycle would
be found as follows: considering Kdi, we must ﬁnd the fewest 2-simplices whose boundary captures the
persistence interval. In this case, we would have an optimal volume (a, b, e) + (b, c, e) + (a, d, e) and
volume-optimal cycle (a, b) + (b, c) + (c, e) + (e, d) + (d, a).

3.6 (cid:96)0 versus (cid:96)1-optimization

As mentioned above, it is common to choose loss(x) = ||x||0 or loss(x) = ||x||1.8 A linear program (LP)
with (cid:96)1 objective function is polynomial time solvable. However, an objective function with the (cid:96)0 norm
restricted to {0, 1, −1}-coefﬁcients is often preferred as the output of such a problem is highly interpretable:
a cycle representative with minimal number of edges or enclosing the minimal number of triangles. Yet,
(cid:96)0-optimization is known to be NP-hard [57].

The (cid:96)1 norm promotes sparsity and often gives a good approximation of (cid:96)0 optimization [56, 57], but
the solution may not be exact. Yet, if all of the coefﬁcients of the solution x are restricted to 0 or ±1 in the
optimization problem, then the (cid:96)0 and (cid:96)1 norms are identical. A looser restriction, as proposed in Escolar et
al. [27], would be to solve an optimization with (cid:96)1 objective function with integer constraints on the solution.
Requiring the solution to be integral also allows us to understand the optimal solution more intuitively than
having fractional coefﬁcients. Such an optimization problem is called a mixed integer program (MIP), which
is known to be slower than linear programming and is NP-hard [46]. Many variants of integer programming
special to optimal homologous cycles, in particular, have been shown to be hard as well [5]. In Section 4, we
discuss the optimization problems we implement, where each is solved both as an LP with an (cid:96)1-norm in the
objective function and an MIP by adding the constraint that x is integral.

Dey et al. [18] gives the totally-unimodularity sufﬁcient condition which guarantees that an LP and
MIP give the same optimal solution. A matrix is totally unimodular if the determinant of each square
submatrix is −1, 0, or 1. Dey et al. [18] give conditions for when the ∂n+1 matrix is totally unimodular. If
the totally-unimodularity condition is not satisﬁed, then an LP may not give the desired result. As totally
unimodularity is not guaranteed for all boundary matrices [36], we cannot rely on this condition.

3.7 Software implementations

Edge-minimal cycles Software implementing the edge-loss method introduced in [27] can be found at [26].
This is a C++ library specialized for 3d point clouds.

Triangle-loss optimal cycles The volume optimization technique introduced in [46] is available through

8Other choices of loss function, e.g. the (cid:96)p norm, are common throughout mathematical optimization. While we focus on (cid:96)0
and (cid:96)1 due to their tendency to produce sparse solutions, other choices may be better or worse suited, depending on the intended
application. For example, since (cid:96)2 loss imposes lighter penalties on small errors and heavier penalties on large ones (as compared to
(cid:96)1), it is especially sensitive to outliers; this makes it useful for tasks such as function estimation. On the other hand, by imposing
relatively heavy penalties on small errors, (cid:96)1 loss encourages sparsity [56, 57].

16

the software platform HomCloud, available at [47]. The code can be accessed by unarchiving the Hom-
Cloud package (for example, https://homcloud.dev/download/homcloud-3.1.0.tar.gz)
and picking the ﬁle homcloud-x.y.z/homcloud/optvol.py.

4 Programs and solution methods

The present work focuses on linear programming (LP) and mixed integer programming (MIP) optimization of
1-dimensional persistent homology cycle representatives with Q-coefﬁcients. While the methods discussed
below can be applied to any homological dimension, we limit the scope of the present work to dimension
one. As described in Section 3, we follow two general approaches: those that measure loss as a function of
n-simplices, and those that measure loss as a function of n + 1-simplices. Motivated by the n = 1 case, we
refer to the former as edge-loss methods and the latter as triangle-loss methods. For our empirical analysis,
four variations (corresponding to two binary parameters) are chosen from each approach, yielding a total of 8
distinct optimization problems.

Concerning implementation, we ﬁnd that triangle-loss methods (namely, [46]) can be applied essentially
as discussed in that paper. The greatest challenge to implementing this approach is the assumption of an
underlying simplex-wise ﬁltration. This necessitates parameter choices and preprocessing steps not included
in the optimization itself; we discuss how to execute these steps below.

Implementation of edge-loss methods is slightly more complex. For binary coefﬁcients (G = F2) a
variety of combinatorial techniques have been implemented in dimension 1 [11, 66]. Escolar and Hiraoka
[27] provide an approach for Q-coefﬁcients, but in general this may not yield a persistent homology cycle
basis, see Remark 3.1. In addition to the triangle-loss method mentioned in Section 3.5, Obayashi [46]
introduces a modiﬁed form of this edge-loss method which does guarantee a persistent homology basis, but
assumes a simplex-wise ﬁltration. We show that this approach can be modiﬁed to remove the simplex-wise
ﬁltered constraint.

Neither of the approaches presented here is guaranteed to solve the minimal persistent homology cycle
basis problem, Equation (6). In the case of triangle-loss methods, this is due to the (arbitrary) choice of a total
order on simplices. In the case of edge-loss methods, it is due to the choice of an initial persistent homology
cycle basis.

In the remainder of this section, we present the 8 programs studied, including any modiﬁcations from

existing work.

4.1 Structural parameters

Each program addressed in our empirical study may be expressed in the following form

minimize ||W x||1 =

(cid:88)

wi,i(x+ + x−)

i
subject to x = x+ − x−

x+, x− ≥ 0
x ∈ X

(13)

where X is a space of feasible solutions and W = (wi,j) is a diagonal matrix with nonnegative entries. These
programs vary along 3 parameters:

1. Chain dimension of x. If X is a family of 1-chains, then we say that (13) is an edge-loss program. If X

is a family of 2-chains, we say that (13) is a triangle-loss program.

17

2. Integrality The program is integral if each x ∈ X has integer coefﬁcients; otherwise we call the

problem non-integral.

3. Weighting For each loss type (edge vs. triangle) we consider two possible values for W : identity and
non-identity. In the identity case, all edges (or triangles) are weighted equally; we call this a uniform-
weighted problem. In the non-identity case we weigh each entry according to some measurement of
“size” of the underlying simplex (length, in the case of edges, and area, in the case of triangles).9 There
is precedent for such weighting schemes in existing literature [18, 11].

Edge-loss and triangle-loss programs will be denoted Edge and Tri, respectively. Integrality will be
indicated by a superscript I (integer) or N I (non-integer). Uniform weighting will be denoted by a subscript
U nif (uniform); non-uniform weighting will be indicated by subscript Len (for edge-loss programs) or
Area (for triangle-loss programs). Thus, for example, EdgeI
Len denotes a length-weighted edge-loss program
with integer constraints.

4.2 Edge-loss methods

Our approach to edge-loss minimization, based on work by Escolar and Hiraoka [27], is summarized in
Algorithm 3. As in [27], we obtain x by taking a linear combination of xOrig with not only boundaries but
cycles as well; consequently x need not be homologous to xOrig.

Algorithm 1 Edge-loss persistent cycle minimization
1: Compute a persistent homology basis B for homology in dimension 1, with coefﬁcients in Q, using
the standard matrix decomposition procedure described in the Supplementary Material. Arrange the
elements of B into an ordered sequence Z0 = (z0,1, . . . , z0,m).

2: for j = 0, . . . , m − 1 do
3:

Solve Program (14) to optimize the j + 1th element of Zj. Let x denote the solution to this problem,
and deﬁne Zj+1 by replacing the j + 1th element of Zj with x. Concretely, zj+1,j+1 = x, and
zj+1,k = zj,k for k (cid:54)= j.

4: end for
5: Return B∗ := {zm,1, . . . , zm,m}, the set of elements in Zm.

Our pipeline differs from [27] in three respects. First, we perform all optimizations after the persistence
calculation has run. On the one hand, this means that our persistence calculations fail to beneﬁt from the
memory advantages offered by optimized cycles; on the other hand, separating the calculations allows one
to “mix and match” one’s favorite persistence solver with one’s favorite linear solver, and we anticipate that
this will be increasingly important as new, more efﬁcient solvers of each kind are developed. Second, we
introduce additional constraints which guarantee that B∗ ∈ PrsHCB (and, moreover, L(x) = L(xOrig) for
each xOrig ∈ B). Third, we remove the hypothesis of a simplex-wise ﬁltration; this requires some technical
modiﬁcations, whose motivation is explained in the Supplementary Material. The crux of this modiﬁcation
lies with the for loop, which replaces cycles that have been optimized in the cycle basis for later cycle
optimization.

Program (14) optimizes the jth element of an ordered sequence of cycle representatives Z = (z1, . . . , zm).
In particular, it seeks to minimize xOrig := zj. To deﬁne this program, we ﬁrst construct a matrix A such

9These notions make sense due to our use of coefﬁcient ﬁeld Q. The distance used to form a simplicial complex can be used to

deﬁne length. We restrict our attention of area to points in Euclidean space.

18

that A[:, i] = zi for i = 1, . . . , m. We then deﬁne three index sets, P, Q, R such that

P = {i : Birth(zi) ≤ Birth(xOrig), Death(zi) ≤ Death(xOrig), i (cid:54)= j}
Q = {σ ∈ Sn+1(K) : Birth(σ) ≤ Birth(xOrig)}
R = {σ ∈ Sn(K) : Birth(σ) ≤ Birth(xOrig)}

That is, P indexes the set of cycles zi such that zi is born (respectively, dies) by the time that zj is
born (respectively, dies), excluding the original cycle zj itself. Set Q is the family of triangles born by
Birth(xOrig), and set R is the family of edges born by Birth(xOrig).

With these deﬁnitions in place, we now formalize the general edge-loss problem as Program (14), where
∂n+1[R, Q] denotes the submatrix of ∂n+1 indexed by triangles born by Birth(xOrig) (along columns) and
edges indexed by edges born by Birth(xOrig). Likewise A[R, P] is the column submatrix of A corresponding
to cycles that are born before the birth time of xOrig (and which die before the death time of xOrig), excluding
xOrig itself.

minimize ||W x||1 =

N
(cid:88)

(x+

i + x−
i )

subject to (x+ − x−) = xOrig[R] + ∂n+1[R, Q]q + A[R, P]p

i=1

p ∈ QP
q ∈ QQ
x ∈ GR
x+, x− ≥ 0

(14)

Recall from Section (4.1) that this program varies along two parameters (integrality and weighting).
In integral programs G = Z, whereas in nonintegral programs G = Q. The weight matrix W is always
diagonal, but in uniform-weighted programs W [i, i] = 1 for all i, whereas in length-weighted programs
W [i, i] is the length of edge i. Program 14 thus results in four variants:

EdgeN I

U nif : Nonintegral edge-loss with uniform weights.

EdgeI

U nif :

Integral edge-loss with uniform weights.

EdgeN I

Len: Nonintegral edge-loss with edges weighted by length.

EdgeI

Len:

Integral edge-loss with edges weighted by length.

Program (14) may have many more variables than needed, because ∂n+1 is often highly singular. Indeed,

in applications, ∂n+1 can have hundreds or thousands of times as many columns as rows!

A simple means to reduce the size of Program (14), therefore, is to replace Q with a subset ˆQ ⊆ Q such
that ∂n+1[R, ˆQ] is a column basis for ∂n+1[R, Q]. Replacing Q with ˆQ will not change the space of feasible
values for x in Program (14), but it can cut the number of decision variables signiﬁcantly. In particular, one
may take ˆQ := {σ : R[:, σ] (cid:54)= 0} in the R = ∂n+1V decomposition of ∂n+1 described in the Supplementary
Material. We also show correctness of this choice of ˆQ there.

19

4.3 Triangle-loss methods

Our approach to triangle-loss optimization is essentially that of Obayashi [46], plus a preprocessing step that
converts more general problem data into the simplex-wise ﬁltration format assumed in [46]. There are several
noteworthy methods for time and memory performance enhancement developed in [46] which we do not
implement (e.g. using restricted neighborhoods F (r)
to reduce problem size), but which may substantially
improve runtime and memory performance.

q

The original method makes the critical assumption that K• is a simplex-wise ﬁltration, more precisely,
that there exists a linear order σ1 ≤ · · · ≤ σ|K| such that Ki = {σ1, . . . , σi}. This hypothesis allows one
to map each ﬁnite-length interval [i, j) ∈ Barcoden(K•) to a unique pair of simplices (σi, σj), called a
birth/death pair, where σi ∈ Sn(K) and σj ∈ Sn+1(K). This mapping makes it possible to formulate
Program (10). Unlike the general edge-loss Program (13), one can formulate Program (10) without ever
needing to choose an initial (non-optimal) cycle. Thus, for simplex-wise ﬁltrations, the method of [46] has
the substantial advantage of being “parameter free.”

However, in many applied settings the ﬁltration K• is not simplex-wise. Indeed, even accessing informa-
tion about the ﬁltration can be difﬁcult in modern workﬂows. Such is the case, for example, for the ﬁltered
Vietroris-Rips (VR) construction. In many VR applications, the user presents raw data in the form of a
point cloud or distance matrix to a “black box” solver; the solver returns the barcode without ever exposing
information about the ﬁltered complex to the user. Thus, the problem of mapping intervals back to pairs of
simplices has practical challenges in common applied settings.

To accommodate this more general form of problem data, we employ Algorithm 4. This procedure works
by (implicitly) deﬁning a simplex-wise reﬁnement K(cid:48)
• of K•, applying the method of [46] to this reﬁnement,
then extracting a persistent homology cycle basis for the subspace of ﬁnite intervals from the resulting data.
More details, including recovery of a complete persistent homology cycle basis with inﬁnite intervals10, and
a proof of correctness can be found in the Supplementary Material.

Algorithm 2 Triangle-loss persistent cycle minimization
1: Place a ﬁltration-preserving linear order ≤(l) on Sl(K) for each l.
2: Compute an R = ∂n+1V decomposition as described in [14] and the Supplementary Material. We then

obtain a set Γ of birth/death pairs (σ, τ ).

3: For each (σ, τ ) ∈ Γ such that Birth(σ) < Birth(τ ), put

Fn := {σ(cid:48) ∈ Sn(K) : Birth(σ(cid:48)) ≤ Birth(τ ), σ (cid:12)(n) σ(cid:48)}
Fn+1 := {τ (cid:48) ∈ Sn+1(K) : Birth(σ) ≤ Birth(τ (cid:48)), τ (cid:48) (cid:12)(n+1) τ }

and ˆFn+1 := Fn+1 ∪ {τ }. Compute a solution to the corresponding Program (15), and denote this
solution by xσ,τ .

4: Put ˆD := {∂n+1(xσ,τ ) : (σ, τ ) ∈ Γ and Birth(σ) < Birth(τ )} and let ˆD(cid:48) := {z ∈ M : Death(z) =

∞}, where M is a persistent homology cycle basis calculated by the standard R = DV method.

5: Return D := ˆD ∪ ˆD(cid:48).

10Recall volume is undeﬁned for inﬁnite intervals.

20

A key component of Algorithm 4 is Program (15), which we refer to as the triangle-loss program.

minimize ||W v||1 =

N
(cid:88)

(v+

i + v−
i )

subject to ∂n+1[σ, ˆFn+1]v (cid:54)= 0

i=1

∂n+1[Fn, ˆFn+1]v = 0
vτ = 1
v+, v− ≥ 0

v+, v− ∈ G

ˆFn+1

(15)

This terminology is motivated by the special case n = 1, which is our focus for empirical studies. As with the
general edge-loss program, Program (15) varies along two parameters (integrality and weighting). In integral
programs G = Z, whereas in nonintegral programs G = Q. The weight matrix W is always diagonal, but in
uniform-weighted programs W [υ, υ] = 1 for all υ, whereas in area-weighted programs W [υ, υ] is the area
of triangle υ.11 Program (15) thus results in four variants:

TriN I

U nif : Nonintegral triangle-loss with uniform weights.

TriI

U nif :

Integral triangle-loss with uniform weights.

TriN I

Area: Nonintegral triangle-loss with edges weighted by area.

TriI

Area:

Integral triangle-loss with edges weighted by area.

Remark 4.1 Algorithm 4 offers an effective means to apply the methods of [46] to some of the most
common data sets in TDA. However, this is done at the cost of parameter-dependence; in particular, outputs
depend on the choice of linear orders ≤(l). A brief discussion on how the choice of a total order ≤ in
Algorithm 4 may impact the difﬁculty of the linear programs one must solve is discussed in the Supplementary
Material. In particular, we explain why the total order implicitly chosen in Algorithm 4 is reasonable, from a
computational/performance standpoint.

4.4 Acceleration techniques

We consider acceleration techniques to reduce the computational costs of Programs (14) and (15). Edge-loss

methods The technique used for edge-loss problems aims to reduce the number of decision variables in

Program (14). It does so by replacing a (large) set of decision variables indexed by Q with a much smaller
set, ˆQ. See Section 4.2 for details. Triangle-loss methods When ∂n is large, the memory and computation

time needed to construct the constraint matrix ∂n+1[Fn, ˆFn+1] can be nontrivial. In applications that require
an optimal representative for every interval in the barcode, these costs can be incurred for hundreds or even
thousands of programs. We consider two ways to generate the constraint matrices ∂n+1[Fn, ˆFn+1] for each
of the intervals in a barcode: build ∂n+1[Fn, ˆFn+1] from scratch for each program, or build the complete
boundary matrix ∂n+1 in advance; rather than recompute block submatrices for each program, we pass a slice
of the complete matrix stored in memory.

11We compute the area of a 2-simplex using Heron’s Formula. We calculate area only for VR complexes whose vertices are points

in Euclidean space, though more general metrics could also be considered.

21

The difference between these two techniques can be seen as a speed/memory tradeoff. As we will see in
Section 6.2, the ﬁrst approach is generally faster to optimize the entire basis of homology cycle representatives,
but when the data set is large, the full boundary matrix ∂n+1 may be too large to store in memory.

5 Experiments

In order to address the questions raised in Section 1, we conduct an empirical study of minimal homological
cycle representatives in dimension one — as deﬁned by the optimization problems detailed in Section 4 —
on a collection of point clouds, which includes both real world data sets and point samples drawn from four
common probability distributions of varying dimension.

5.1 Real-world data sets

We consider 11 real world data sets from [48], a widely used reference for benchmark statistics concerning
persistent homology computations. There are 13 data sets considered by [48], however, one of them (gray-
scale image) is not available, and one of them is a randomly generated data set similar to our own synthetic
data. We summarize information about the dimension, number of points, persistence computation time of
each point cloud in Table 1. Below we provide brief descriptions of each data set, but we refer the interested
reader to [48] for further details.12

1. Vicsek biological aggregation model. The Vicsek model is a dynamical system describing the motion
of particles. It was ﬁrst introduced in [62] and was analyzed using PH in [58]. We consider a snapshot
in time of a single realization of the model with each point speciﬁed by its (x, y) position and heading.
To compute distances, the positions and headings are scaled to be between 0 and 1, and then distance
is calculated on the unit cube with periodic boundary conditions. The distance between a and b is
computed as min{d(a, q) : q − b ∈ {0, 1, −1}3}. We denote this data by Vicsek.

2. Fractal networks. These networks are self-similar and are used to explore the connection patterns
of the cerebral cortex [54]. The distances between nodes in this data set are deﬁned uniformly at
random by [48]. In another data set, the authors of [48] deﬁne distances between nodes by using linear
weight-degree correlations. We consider both data sets and found the results to be similar. Therefore,
we opt to use the one with distances deﬁned uniformly at random. We denote this data set by fract r.

3. C.elegans neuronal network. This is an undirected network in which each node is a neuron, and edges
represent synapses. It was studied using PH in [50]. Each nonzero edge weight is converted to a
distance equal to its inverse by [48]. We denote this data by eleg.

4. Genomic sequences of the HIV virus. This data set is constructed by taking 1, 088 different genomic
sequences of dimension 673. The aligned sequences were studied using PH in [10] with sequences
retrieved from [42]. Distances are deﬁned using the Hamming distance, which is equal to the number
of entries that are different between two genomic sequences. We denote this data by HIV.

5. Genomic sequences of H3N2. This data set contains 1, 173 genomic sequences of H3N2 inﬂuenza
in dimension 2, 722. Distances are deﬁned using the Hamming distance. We denote this data set as
H3N2.

12We use the distance matrices found on the associated github page [49], except in two cases. For the Vicsek data, we use a
distance to account for the intended periodic boundary conditions of the model, and for the genome data, we use Euclidean distance
as the distance matrix in [49] resulted in an integer overﬂow error.

22

6. Human genome. This is a network representing a sample of the human genome studied using PH
in [50], which was created using data retrieved from [16]. Distances are measured using Euclidean
distance. We denote this data set by genome.

7. US Congress roll-call voting networks. In the two networks below, each node represents a legislator,
and the edge weight is a number in [0, 1] representing the similarity of the two legislators’ past voting
decisions. Distance between two nodes i, j are deﬁned to be 1 − wi,j.

(a) House. This is a weighted network of the House of Representatives from the 104th United States

Congress.

(b) Senate. This is a weighted network of the Senate from the 104th United States Congress.

8. Network of network scientists. This data set represents the largest connected component of a collabora-
tion network of network scientists [45]. The edge weights indicate the number of joint papers between
two authors. Distances are deﬁned as the inverse of edge weight. We denote this data set by network.

9. Klein. The Klein bottle is a non-orientable surface with one side. This data set was created in [48] by
linearly sampling 400 points from the Klein bottle using its ‘ﬁgure-8’ immersion in R3. This data set
originally contains 39 duplicate points, which we remove. Distances are measured using the Euclidean
distance. We denote this data set by Klein.

10. Stanford Dragon graphic. This data set contains 1000 points sampled uniformly at random by [48]
from 3-dimensional scans of the dragon [55]. Distances are measured using the Euclidean distance.
We denote this data set drag.

5.2 Randomly generated point clouds

We also generate a large corpus of synthetic point clouds, each containing 100 points in Rq with q = 2, . . . , 10,
drawn from normal, exponential, gamma, and logistic distributions. We produce 10 realizations for each
distribution and dimension combination, for a total of 360 randomly generated point clouds. We use Euclidean
distance to measure similarity between points and the Vietoris- Rips ﬁltered simplicial complex to compute
persistent homology.

5.3 Erd˝os-Rényi random complexes

To investigate which properties of homological cycle representatives could arise as the result of the underlying
geometry of the point clouds, we also consider a common non-geometric model for random complexes:
Erd˝os-Rényi random clique complexes. Here, we construct 100 symmetric dissimilarity matrices of size
100 × 100 by drawing entries i.i.d. from the uniform distribution on [0, 1] for each pair of distinct points. As
these dissimilarities are fully independent, they are in particular not subject to geometric constraints like the
triangle inequality. A natural ﬁltration is placed on these dissimilarity matrices by forming ﬁltered simplicial
complex K• = (K(cid:15)i)i∈{1,...,T } where 0 = (cid:15)1 < · · · < (cid:15)T = 1 to compute persistent homology.

5.4 Computations

For each of the data sets, we perform Algorithms 3 and 4 (using Vietoris-Rips complexes with Q-coefﬁcients)
to ﬁnd optimal bases B∗, D ∈ PrsHCB. For comparison to the edge-loss problem in Algorithm 3, we also
apply Program (8) to each representative in the persistent homology cycle basis to ﬁnd a basis C ∈ FCB.

23

Table 1: Summary of the experimental results of the data sets from [48] as described in Section 5.1. The
rows include the ambient dimension, number of points, the number of cycle representatives in H1, and the
time (measured in seconds) it took to compute persistent homology for each data set. We also include the
computation time taken to optimize the set of cycle representatives under six different optimization problems,
and computation time of two different implementation choices for the triangle-loss optimal cycles: building
the full ∂2 boundary matrix once and extracting the part needed, or constructing part of the ∂2 boundary
matrix for each cycle representative. In this table, T stands for computation time measured in seconds with
subscripts indicating the type of the optimal cycle and superscripts indicating whether the program was
solved using linear programming (NI) or integer programming (I). The time taken to construct the input to
the optimization problem is included in the optimization time for edge-loss minimal cycle representatives, but
is excluded and separately listed in the last two rows for the triangle-loss minimal cycle representatives. For
triangle-loss cycles, we were able to compute 115 out of the 117 cycle representatives for the Genome data
set and 52 out of 57 cycle representatives for the H3N2 data set due to memory constraints. The numbers in
the parenthesis represent the other optimization statistics corresponding to the triangle-loss optimal cycles we
were actually able to compute. The last two rows compare two ways of building the input ∂2[:, ˆF2] matrix to
the triangle-loss optimal cycle program. The penultimate row records the time of building the entire ∂2 matrix
once and then extracting columns born in the interval [bi, di] for each representative. The last row records the
total time to iteratively build the part of the boundary matrix ∂2[:, ˆF2] for each cycle representative.

Klein

Vicsek C.elegans HIV

genome fractal R network

house

senate

drag

H3N2

Ambient
dimension

# points

# representatives

3

400

257

3

300

149

202

297

107

673

688

1088

1397

174

117 (115)

259

512

438

300

379

7

Tpersistence

100.97

129.39

5.14

728.51

967.61

143.07

12.18

Edge-loss persistent homological cycle representatives (Program (14))

T I

E-Len

T N I

E-Len

T I

E-U nif

T N I

E-U nif

16.01

11.28

14.59

11.38

8.20

6.61

9.09

5.55

19.64

466.85

656.05

150.46

16.07

403.63

491.69

86.95

19.22

473.82

689.51

119.94

15.63

404.95

492.66

83.40

Edge-loss ﬁltered homological cycle represnetatives (Program (8))

T I

E-Len

T N I

E-Len

T I

E-U nif

T N I

E-U nif

16.93

10.29

15.14

11.07

8.64

5.51

8.32

5.63

20.41

468.22

1144.17

155.08

16.15

403.74

973.15

88.66

19.76

476.84

1191.44

142.4

16.23

406.97

981.72

87.59

0.17

0.13

0.23

0.12

0.17

0.13

0.24

0.12

261

445

126

9.62

63.93

48.65

63.34

48.88

62.20

48.24

61.82

48.11

Triangle-loss persistent homological cycle representatives (Program (15))

T I

T -U nif

T N I

T -U nif

T build all

Total T build part

316.33

24.52

657.53 25,402.56 16,379.86 20,440.33

2.91

234.05

154.36

19.18

540.06 23,260.12 14,535.42 18,279.82

2.47

206.63

2.16

9.18

0.32

3.51

4.88

268.57

-

138.46

28.47

1,688.10

415.79

917.42

0.06

0.28

6.23

45.02

60

103

12

3

1,173

1,000

2,722

311

28 (26)

0.10

1,053.53 71,081.77

0.31

0.22

0.33

0.22

0.30

0.22

0.31

0.22

0.29

0.18

0.03

0.05

45.14

4,732.59

34.73

4,540.55

45.51

4,714.90

33.88

4,547.37

67.77

2,999.24

50.25

2,829.12

68.63

2,937.16

54.05

2,833.06

384.91 39,140.67

277.93 36,401.50

5.94

-

106.64

1,236.80

24

5.5 Hardware and software

We test our programs on an iMac (Retina 5K, 27-inch, 2019) with a 3.6 GHz Intel Core i9 processor and 40
GB 2667 MHz DDR4 memory.

Software for our experiments is implemented in the programming language Julia; source code is available

at [41]. This code speciﬁcally implements Algorithms 313 and 4.

Since our interest lies not only with the outputs of these algorithms but with the structure of the linear
programs themselves, [41] implements a standalone workﬂow that exposes the objects built internally within
each pipeline. This library is simple by design, and does not implement the performance-enhancing techniques
developed in [27, 46]. Users wishing to work with optimal cycle representatives for applications may consider
these approaches discussed in Section 3.7.

To implement Algorithms 3 and 4 in homological dimension one, the test library [41] provides three key
functions: A novel solver for persistence with Q-coefﬁcients. To compute cycle representatives for persistent
homology with Q-coefﬁcients, we implement a new persistent homology solver adapted from Eirene [33].
The adapted version uses native Eirene code as a subroutine to reduce the number of columns in the top dimen-
sional boundary matrix in a way that is guaranteed not to alter the outcome of the persistence computation [37].

Formatting of inputs to linear programs.

Having computed barcodes and persistent homology cycle representatives, library [41] provides built-in
functionality to format the linear Programs (14) and (15) for input to a linear solver. This “connecting” step
is executed in pure Julia.

Wrappers for linear solvers.

We use the Gurobi linear solver [34] and the GLPK solver [32]. Both solvers can optimize both LPs and
MIPs. Experiments indicate that Gurobi executes much faster than GLPK on this class of problems, and thus,
we use it in the bulk of our computations. Both solvers are free for academic users.

6 Results and Discussion

In this section, we investigate each of the questions raised in Section 1 with the following analyses.

6.1 Computation time comparisons

Len, TriN I

Len, EdgeI

U nif , EdgeI

U nif , EdgeN I

Area and TriN I

We summarize results for Programs EdgeN I
U nif in
Table 1 for data described in Section 5.1 and Table 2 for data described in Section 5.2 and Section 5.3. Further,
we summarize results for Programs TriN I
Area in Table 2 for data described in Section 5.2.14 We
use Tpersistence to denote the time taken to compute all original cycle representatives and their lifespans L. We
use T ∗
• to denote the computation time for optimizing all generators found by the persistence algorithm, where
the subscript denotes the cost function e.g. E-U nif or T -U nif , and the superscript denotes the nonintegral N I
or integral I constraint. The T ∗
• computations include the time required to construct the inputs to the solver
for the edge-loss methods, and exclude the time required to construct the inputs to the triangle-loss methods,
whose computation time is separately recorded in order to compare two ways of constructing the input matrix,
as discussed in Section 4.4. In each table, rows 1-3 provide information about the data by specifying ambient

U nif , and TriI

13Program (8) is implemented analogously.
14We compute the area of a 2-simplex using Heron’s Formula for data whose distances are measured using the Euclidean distance.
For data with non-Euclidean distances, we ﬁnd that there are triangles that do not obey the triangle inequality, thus, we only compute
area-weighted triangle-loss cycles for data described in Section 5.2. As such, TriN I
Area do not appear in Table 1 and the
Er˝os Rényi column of Table 2.

Area, TriN I

25

dimension, number of points, and number of cycle representatives. Row 4, labeled as Tpersistence, gives the
total time to compute persistent homology for the data, measured in seconds. Rows 5-12 (Table 1) and rows
5-14 (Table 2) give the total time to optimize all cycle representatives that are feasible to compute using each
optimization technique. In the last two rows of each table, we provide the time of constructing the input
to the triangle-loss methods using two different approaches described in Section 4.4. The penultimate row
records the time of building the entire ∂2 matrix once and then extracting ∂2[F1, ˆF2] for each representative.
The last row records the total time to iteratively build the part of the boundary matrix ∂2[F1, ˆF2] for each
cycle representative. In Table 2, the computation times displayed average all random samples from each
dimension for each distribution.

Table 2: Summary of the experimental results for the synthetic, randomly generated data sets described in
Section 5.2. For each distribution, we sample 10 data sets each containing 100 points in ambient dimensions
from 2-10. The computation time in this table averages the 10 random samples for each dimension and
distribution combination. The number of cycle representatives is totaled over the 90 samples for each
distribution. The rows of this table are analogous to those of Table 1, excluding the penultimate row of that
table, as the time comparison is only done for the large real-world data sets.

Normal

Gamma

Logistic

Exponential

Erd˝os-Rényi

Ambient dimension

# points

Total # representatives

Average Tpersistence (seconds)

2-10

100

4,815

2.80

2-10

100

3,706

2.12

2-10

100

4,456

2.01

Edge-loss persistent homological cycle representatives (Program (14))

Average total T I

E-Len

Average total T N I

E-Len

Average total T I

E-U nif

Average total T N I

E-U nif

5.52

4.37

5.31

4.08

6.01

4.55

5.97

4.58

5.65

4.32

5.45

4.23

Edge-loss ﬁltered homological cycle representatives (Program (8))

Average total T I

E-Len

Average total T N I

E-Len

Average total T I

E-U nif

Average total T N I

E-U nif

5.32

4.07

5.23

4.17

6.46

5.05

6.46

4.94

6.27

4.78

6.25

4.61

Triangle-loss persistent homological cycle representatives (Program (15))

Average total T I

T -U nif

Average total T N I

T -U nif

Average total T I

T -Area

Average total T I

T -Area

Average total T build all

Average total T build part

6.56

5.24

6.59

5.19

1.40

3.51

9.91

7.99

10.20

7.89

1.71

1.54

7.06

5.79

7.30

5.80

1.56

1.61

2-10

100

3,788

2.63

5.91

4.47

5.90

4.51

6.88

5.11

6.66

5.29

9.68

7.75

9.99

7.57

1.07

1.56

NA

100

34,214

2.20

5.99

4.99

6.16

4.87

7.44

4.69

6.25

4.64

4.64

4.49

-

-

1.24

0.85

The two numbers in parenthesis in the third row of Table 1 indicate the actual number of representatives
we were able to optimize using the triangle-loss methods (all edge-loss representatives were optimized). For

26

the genome and H3N2 data sets, we are not able to compute all triangle-loss cycle representatives due to the
large number of 2-simplices born between the birth and death interval of some cycles. For instance, for a
particular cycle representative in the genome data set, there were 10,522,991 2-simplices born in this cycle’s
lifespan. Also, given the large number of 2-simplices in the simplicial complex, we are not able to build the
full ∂2 matrix due to memory constraints, denoted by - in the penultimate row of Table 1.
Below we describe some insights on computation time drawn from the two tables.

Persistence and optimization (Tpersistence vs. T ∗
• )
We observe that T ∗
•

15 > Tpersistence e.g. for 5 out of the 11 real-world data sets described in Section 5.1
when using the 4 edge-loss methods. The same inequality holds in 9 out of the 11 data sets when using the
two uniform-weighted triangle-loss methods. For all of the synthetic data described in Sections 5.2 and 5.3,
we have T ∗
• > Tpersistence when using all eight optimization programs. Therefore, the computational cost of
optimizing a basis of cycle representatives generally exceeds the cost of computing such a basis.

This somewhat surprising result highlights the computational complexity of the algorithms used both
to compute persistence and to optimize generators. A common feature of both the persistence computation
and linear optimization is that empirical performance typically outstrips asymptotic complexity by a wide
margin; the persistence computation, for example, has cubic complexity in the size of the complex, but
usually runs in linear time. Thus, worst-case complexity paints an incomplete picture. Moreover, naive
“back of the envelope” calculations are often hindered by lack of information. For example, the persistence
computation (which essentially reduces to Gaussian elimination) typically processes each of the m columns
of a boundary matrix ∂n in sequence. The polytope of feasible solutions for an associated linear program
(edge-loss or triangle-loss) may have many fewer or many more vertices than m, depending on the program;
moreover, even if the number of vertices is very high, the number of visited vertices (e.g., by the simplex
algorithm) can be much lower. Without knowing these numbers a priori, run times can be quite challenging to
estimate. Empirical studies, such as the present one, give a picture of how these algorithms perform in practice.

Integral and nonintegral programs (T I vs. T N I )

In Tables 1 and 2, we observe that T I > T N I , i.e., the total computation time of optimizing a basis of
cycle representatives using an integer program exceeds the computation time using a non-integer constrained
program. Yet, T I and T N I are on the same order of magnitude, for both edge-loss methods and triangle-loss
method.

tI
E-U nif
tN I
E-U nif

, where t∗

Let rE-U nif =

• represents the computation time for optimizing a single cycle represen-
tative. We deﬁne rE-Len and rT -U nif similarly. We compute each for every cycle representative for data
described in Tables 1 and 2. Let ¯r• denote the average of r• and σr• denote the standard deviation of r•. We
have ¯rE-U nif = 1.49, σrE-U nif = 1.34, ¯rE-Len = 1.55, σrE-Len = 1.38, σrT -U nif = 1.35, σrT -U nif = 2.86.
Figure 6(A, C, E) plots r• using scatter plots and Figure 6(B, D, F) displays the same data using box plots.
The vertical axis represents the ratio between the MIP time and LP time of optimizing a cycle representative.
The horizontal axis in the scatter plots represents the computation time to solve the LP. The red line in each
subﬁgure represents the horizontal line y = 1. As we can see from the box plots, the ratio between the
computation time of MIP and LP for most of the cycle representatives (> 50%) is around 1 and less than 2.
Although there are cases where the computation time of solving an MIP is 71.03 times the computation time
of solving an LP, such cases happen only for cycle representatives with a very short LP computation time.

Triangle-loss versus edge-loss programs. (TT -• vs. TE-•)

We observe that the edge-loss optimal cycles are more efﬁcient to compute than the triangle-loss cycles

15Including the time of constructing the input to the optimization programs.

27

Len, EdgeI
Len, EdgeN I

U nif , EdgeI
U nif , EdgeN I

Figure 6: Ratio between the computation time of solving an integer programming problem (Programs
TriI
U nif ) and the computation time of solving a linear programming problem (Programs
TriN I
U nif ) for all of the cycle representatives from data sets described in Sections 5.1, 5.2,
and 5.3. Subﬁgures (A), (C), (E) plot the data using scatter plots and subﬁgures (B), (D), (F) show the same
data using box plots. The vertical axis represents the ratio between the integer programming time and linear
programming time of optimizing a cycle representative and the horizontal axis represents the computation
time to solve the linear program. The red line in each subﬁgure represents the horizontal line y = 1, where the
time for each optimization is equivalent. As we can see from the box plots, the ratio between the computation
time of integer programming and linear programming for most of the cycle representatives (> 50%) center
around 1.

28

for more than 65.70% of the cycle representatives16. This aligns with our intuition because for representatives
with a longer persistence, the number of columns in the boundary matrix ∂2[F1, ˆF2] grows faster than that of
∂1[:, Q]. Consequently, the edge-loss programs are feasible for all cycle representatives we experiment with,
whereas the triangle-loss technique fails for 6 representatives due to the large problem size (with greater than
twenty million triangles born between the life span of those cycle representatives).
Different linear solvers

The choice of linear solver can signiﬁcantly impact the computational cost of the optimization problems.
We perform experiments on length/uniform-minimal cycle representatives using the GLPK [32] and Gurobi
[34] linear solvers on 90 data sets drawn from the normal distribution with dimensions from 2 to 10 with
a total of 4,815 cycle representatives. The median of the computation time ratio between using the GLPK
solver and Gurobi solver is 2.22 for Program EdgeN I
U nif , 2.28 for Program
EdgeN I
Len, and the computation time using the GLPK solver can be 30 times
larger than the computation time using the Gurobi solver for some cycles, see ﬁgure in the Supplementary
Material. Therefore, we use the Gurobi solver in all other analyses in this paper.

Len, and 1.73 for Program EdgeI

U nif , 1.68 for Program EdgeI

6.2 Performance of acceleration techniques

Edge-loss optimal cycles

As discussed in Section 4.4, we accelerate edge-loss problems by replacing ∂2[:, Q] with the column basis
submatrix of ∂2[:, ˆQ]. We further reduce the size of ∂2[:, ˆQ] by only including the rows corresponding to
1-simplices born before the birth time of the cycle, denoted as ∂2[R, ˆQ]. We perform experiments on a small-
sized data set (Senate) that consists of 103 points in dimension 60 and a medium-sized data set (House) that
contains 445 points in dimension 261. In Table 3, we report the computation time of solving the optimization
problems in Programs EdgeN I
Len using these three techniques of varying
the size of the input boundary matrix. The results align with intuition that the optimizations are faster with
fewer input variables, and thus, the third implementation is the most efﬁcient among the three.

Len, and EdgeI

U nif , EdgeN I

U nif , EdgeI

Triangle-loss optimal cycles

As discussed in Section 4.4, there are also multiple approaches to creating the input to the triangle-loss
problems. To recap, we restrict the boundary matrix ∂2 to ∂2[F1, ˆF2] for a particular cycle representative xi.
We can do so in various ways: (i) zeroing out the columns of ∂2 not in ˆF2 but maintaining the original size of
the boundary matrix, (iia) building the entire boundary matrix ∂2 once and then deleting the columns not in
ˆF2 for each representative, (iib) building the columns in ˆF2 iteratively for each representative, and (iiia/b) in
conjunction with (iia) or (iib) respectively, reducing the rows of the boundary matrix of ∂2 to only include the
rows born before the death time of the cycle F1.

In Table 3, we summarize the computation time of solving Programs TriN I

U nif to ﬁnd
triangle-loss optimal cycles with three different sized boundary matrices as input: (i) zeroing out, (iib)
deleting partial columns, and (iiib) deleting partial rows and columns. Note that (iia) and (iib) both result
in the same boundary matrix ∂2[:, ˆF2]. We again use the Senate and House data sets for analysis. We see
that deleting partial rows and columns is the most efﬁcient among the three implementations, which again
matches intuition that reducing the number of variables accelerates the optimization problem.

U nif and TriI

We also ran experiments on the real-world data sets to compare the timing of building ∂2[F1, ˆF2] via
methods (iiia) and (iiib) and summarize the results in the last two rows of Table 1. We ﬁnd that approach
(iiia), where we build the entire matrix ∂2 and then delete columns for each cycle representative, is in general
faster than approach (iiib), where the boundary matrix ∂2[F1, ˆF2] is iteratively built for each representative.
However, this latter approach can be more useful for large data sets, whose full boundary matrix ∂2 might
be too large to construct. For example, building the full boundary matrix for the Genome data set caused

16Obayashi [46] proposes a few techniques for accelerating the triangle-loss methods which we did not implement.

29

Table 3: Computation time of three differently sized input boundary matrices to edge-loss and triangle-loss
methods. The superscripts denote whether the program requires an integral solution or not, and the subscripts
indicate the type of optimal cycle. All time is measured in seconds. We perform experiments on a small-sized
data set (Senate) that consists of 103 points in dimension 60 and a medium-sized data set (House) that
contains 445 points in dimension 261. For edge-loss methods, we consider three implementations to solve
these optimization problems: using the full boundary matrix ∂2, using the basis columns and all rows ∂2[:, ˆQ],
and using the basis columns and deleting rows corresponding to edges born after the birth time of the cycle
∂2[R, ˆQ]. For triangle-loss methods, we consider three approaches to solve these optimization problems:
zeroing out the columns in the boundary matrix outside of [bi, di] denoted as ∂2zero, deleting columns outside
of this range ∂2[:, ˆF2], and deleting both columns outside of [bi, di] and rows born after di denoted ∂2[F1, ˆF2].
The House data set was too large to implement the ﬁrst method.

Edge-loss Optimal Cycles (Program (14))

Small Data Set (Senate)

Medium Data Set (House)

Small Data Set (Senate)

Medium Data Set (House)

T

T N I

E-U nif

T I

E-U nif
T N I

E-Len

T I

E-Len

T N I

E-U nif

T I

E-U nif
T N I

E-Len

T I

E-Len

T

T N I

T -U nif

T I

T -U nif

T N I

T -U nif

T I

T -U nif

∂2

1.06

1.25

1.05

1.23

184.70

188.88

184.41

193.01

∂2[:, ˆQ]

∂2[R, ˆQ]

1.03

1.23

1.05

1.19

122.72

147.27

121.80

146.46

0.41

0.60

0.41

0.65

47.10

64.64

46.02

63.87

Triangle-loss Optimal Cycles (Program (15))

∂2zero

23.25

25.31

-

-

∂2[:, ˆF2]

∂2[F1, ˆF2]

0.99

1.06

286.10

317.45

0.59

0.66

194.70

237.73

Julia to crash due to the large number of 2-simplices (453,424,290 triangles for the Genome data set and
3,357,641,440 triangles for the H3N2 data set). Whereas, by implenting (iiib) where we rebuild a part of the
boundary matrix for each representative, we were able to optimize 115 out of the 117 cycle representatives
for the Genome data set and 52 of 57 cycle representatives for the H3N2 data set.

6.3 Coefﬁcients of optimal cycle representatives in data sets from Section 5.1 and Section

5.2

As discussed in Section 3.6, the problem of solving an (cid:96)0 optimization is desirable for its interpretability but
doing so is NP-hard [57]. Often, (cid:96)0 optimization is approximated by an (cid:96)1 optimization problem, which is
solvable in polynomial time. If the coefﬁcients of a solution of the (cid:96)1 problem are in {−1, 0, 1}, then it is
in fact an (cid:96)0 solution to the restricted optimization problem where we require solutions to have entries in
{−1, 0, 1} [27, 46].

We ﬁnd that 99.50% of the original, unoptimized cycle representatives obtained from data sets described
in Section 5.1 and 99.91% of the unoptimized cycle representatives obtained from data sets described in
Section 5.2 have coefﬁcients in {−1, 0, 1}. All unoptimized cycle representatives turned out to have integral
entries.

30

U nif , TriI

We then systematically check each solution of the eight programs EdgeN I
Area, TriI
Len, TriN I

U nif , EdgeN I
Len,
EdgeI
Area across all data sets and all optimal cycle representatives
from data discussed in Sections 5.1 and 5.217 found by Algorithms 3 and 4 and Program (8) to see if the
coefﬁcients are integral or in {−1, 0, 1}. We analyze the 18,163 optimal cycle representatives and ﬁnd the
following consistent results.

U nif , and TriN I

U nif , EdgeI

All optimal solutions to Program (8) (edge-loss minimization of ﬁltered cycle bases) and all but one of
the solutions returned by Algorithm 3 (edge-loss minimization of persistent cycle bases) had coefﬁcients in
{−1, 0, 1}; see the table in the Supplementary Material for details. The exceptional representative xN I
E-U nif
occurred in the C.elegans data set, with coefﬁcients in {−0.5, 0, 0.5}. It corresponds to one of only a few
cases where two intervals with equal birth and death time occur within the same data set; see Section 6.6. An
interesting consequence of these fractional coefﬁcients is that here, unlike all other cycle representatives from
data discussed in Section 5.1 and Section 5.2, the (cid:96)0-norm and (cid:96)1-norm differ. This accounts for the sole
point that lies below the y = 1 line in the ﬁrst column of row (B) in Figure 7.

On the one hand, this exceptional behavior could bear some connection to Algorithm 3. Recall that
Algorithm 3 operates by removing a sequence of cycles from a cycle basis, replacing each cycle with a new,
optimized cycle on each iteration (that is, we swap the j + 1th element of Zj with an optimized cycle x in
order to produce Zj+1). Replacing optimized cycles in the basis is key, since without replacement it would be
possible in theory to get a set of optimized cycles that no longer form a basis. We veriﬁed that if we modify
Algorithm 3 to skip the replacement step, we achieve {−1, 0, 1} solutions for the exceptional C.elegans
cycle representative (for the other repeated intervals we obtain the same optimal cycle with and without the
replacement). On the other hand, we ﬁnd that even with replacement the GLPK solver obtains a solution with
coefﬁcients in {−1, 0, 1}. Thus, every one of the cases considered produced {−1, 0, 1} coefﬁcients for at
least one of the two solvers, and the appearance of fractional coefﬁcients may be naturally tied to the speciﬁc
implementation of the solver used.

When solving the triangle-loss problems by Algorithm 4, we obtain one solution with coefﬁcients of 2
(for both the integral and non-integral problems) for one cycle representative from the logistic distribution
data set. For that single representative, we rerun the optimizations with the additional constraint that it have
coefﬁcients with an absolute value less than or equal to one, which results in an infeasible solution.

The surprising predominance of solutions in {−1, 0, 1} suggests that in most cases, the modeler can reap
both the computational advantage of (cid:96)1 solutions and the theoretical and interpretability advantages of (cid:96)0
solutions18 by solving an (cid:96)1 optimization problem. Further, we ﬁnd that the optimum cost is the same whether
we require an integer solution or not for more than 99.97% of solutions to Program EdgeLen, 100% of
solutions to EdgeU nif , and 100% of solutions to TriU nif . Thus, the modeler can drop the integral constraint
to save computation time while still being able to achieve an integral solution in most cases.

6.4 Comparing optimal cycle representatives against different loss functions

We compare the optimal cycle representatives against different loss functions to study the extent to which the
solutions produced by each technique vary. We consider two loss functions on an H1 cycle representative
x ∈ Z1(K):

LE-Len(x) =

Length(σ)

(cid:88)

17We discuss the coefﬁcients of the Erd˝os-Rényi complexes of Section 5.3 in Section 6.7.
18Recall that, in the current discussion, (cid:96)0 optimality refers to the restricted integer problem where coefﬁcients are constrained to

lie in {−1, 0, 1}. The unrestricted problem (about which we have nothing to say) may have quite different properties.

σ∈supp(x)

31

•) and CN I

•) and CN I

•) and LSur-Area(xN I

U nif row (A), EdgeN I

E-Len, (B) LE-U nif (x∗

Figure 7: Box plots of the ratios between (A) LE-Len(x∗
E-U nif , and (C)
LSur-Area(x∗
T -Area). Within each row, the denominator is ﬁxed across all three columns,
and corresponds to the PrsHCB cycles which are solutions to Programs EdgeN I
Len row
(B), or TriN I
Area row (C). The horizontal axis of each subplot is the type of optimal representative. The cost
of the optimal solutions to programs Program (14), Program (8), and Program TriN I
Area was equal regardless
of the presence of an integer constraint in nearly all examples (as discussed in Section 6.3), resulting in two
columns in each row having ratio 1. The data used in (A) and (B) aggregate over all cycle representatives
from data described in Sections 5.1 and 5.2. The data used in (C) aggregate the 746 cycle representatives from
40 point clouds with ambient dimension of 2 from data described in 5.2. We observe that some edge-loss and
uniform-weighted-triangle-loss optimal cycles have a surveyor’s area strictly smaller than the denominator
in row (C); refer to Figure 9 and Section 6.4 to see why this may happen. It is possible for LE-U nif (x∗
•) to
be strictly smaller than CN I
E-U nif is calculated to be optimal relative to (cid:96)1 loss,
not LE-U nif , which is a measure of (cid:96)0 loss. We observe this behavior in the ﬁrst plot on the second row,
discussed in detail in Section 6.3.

E-U nif because the cycle xN I

where Length(σ) is the distance — as designated by the metric d used to deﬁne the VR complex — between
the two vertices of a 1-simplex σ, and

LE-U nif (x) = ||x||0 = |supp(x)|,
32

the number of 1-simplices (edges) in a representative.

We also consider two loss functions on 2-chains v ∈ C2(K), namely area-weighted loss:

LT -Area(v) =

(cid:88)

Area(τ )

τ ∈supp(v)

where Area(τ ) is the area of a 2-simplex as computed by Heron’s Formula, and uniform-weighted loss

LT -U nif (v) = ||v||0 = |supp(v)|.

Remark 6.1 These weighted (cid:96)0 loss functions differ from the objective functions used in the optimization
problems presented in Section 4, which measure weighted (cid:96)1 norm. However, weighted (cid:96)0 norm and weighted
(cid:96)1 norm agree on solutions with {−1, 0, 1} coefﬁcients, and (as reported in Section 6.3) nearly all cycle
representatives for the Section 5.1 and 5.2 data satisfy this condition, both pre- and post-optimization.

In the special case where supp(x) determines a simple closed polygonal curve c with vertices (p1, q1), . . . , (pn, qn) ∈

R2, we also use the Surveyor’s Area Formula [7] to quantify area of x as

LSur-Area(c) = 1
2

(cid:12)
(cid:12)(cid:80)n

i=1 piqi+1 − pi+1qi(cid:12)
(cid:12)

where, by convention, pi+1 = p1 and qi+1 = q1. We evaluate this function only when (i) the ambient point
cloud of the VR complex is a subset of R2, (ii) supp(x) forms a graph-theoretic cycle when regarded as a
subset of edges in the combinatorial graph formed by 1-skeleton of K, and (iii) no pair of distinct closed line
segments intersect one another.

• := L•(x∗

In the case when we compute the loss function of a corresponding optimal solution, we use the notation
• := L•(v∗
•) to an edge-loss problem that ﬁnds optimal solution x∗
for the cost C∗
•)
to a triangle-loss problem that ﬁnds optimal solution v∗
E-U nif ).
We will also compute the loss functions of optimal solutions from differing optimizations. For instance,
LE-Len(xN I

•, and C∗
E-U nif = LE-U nif (xN I

E-U nif ), and in that case, we do not use the C∗

•. For instance, CN I

• notation.

U nif , and TriN I

Figure 8 shows an example of various optimal cycle representatives obtained from Programs EdgeN I
Len, TriN I

U nif ,
Area on an example point cloud drawn from the normal distribution in R2. In
EdgeN I
this example, solutions obtained from Algorithm 3 and Program (8) are the same. Each subﬁgure is labeled
by program in the upper left corner. The values of different loss functions evaluated on each optimal
representative appear in the upper right corner. We do not compute LT -U nif or LT -Area of the optimal edge-
loss minimal cycle representatives, as no bounding 2-chain for this 1-cycle is speciﬁed in the optimization.19
We observe that various notions of optimality lead to differing cycle representatives, yet each solution to an
optimization problem minimizes the loss function it is intended to optimize. This will not always be the case,
as we will see momentarily.

Figure 7 reports ratios on the losses LE-U nif , LE-Len, and LSur-Area

20 for the eight PrsHCB optimization
problems detailed in Section 4 as well as the four edge-loss FCB problems from Program (8), evaluated on
the data from Sections 5.1 and 5.2. These ratios suggest that the uniform-weighted and length-weighted
edge-loss cycles do minimize what they set out to minimize, namely, the number of edges and the total length,
respectively. We also observe that intuitively the less-constrained solutions to the FCB Program (8) can have
a lower cost than the more-constrained solutions to the PrsHCB Program (14).

We also see that the edge-loss-minimal cycles have similar loss in terms of length and number of edges
(LE-Len and LE-U nif ) whereas the triangle-loss-minimal cycles can have larger losses (LE-Len(xT -U nif )

19We formulated an Obayashi-style linear program similar to Program (15) to compute the volume of edge-loss optimal cycles but

in many cases it had no feasible solution.

20Recall, we only compute LArea on the 2-dimensional distribution data.

33

Figure 8: Examples of different optimal cycles and cost against different loss functions using a point cloud of
100 points with ambient dimension 2 randomly drawn from a normal distribution. The upper left corner of
each subﬁgure labels the optimization algorithm used to optimize the original cycle representative. The upper
right corner of each subﬁgure records the different measures of the size of the optimal representative. Blue
text represents the measure an algorithm sets out to optimize.

and LE-U nif (xT -U nif )). We ﬁnd that 63.28% of the LE-U nif minimal cycle representatives are also LE-Len
minimal while 99.66% of the LE-Len minimal cycle representatives are also LE-U nif minimal across all cycle
representatives from all data sets for PrsHCB cycles. Similarly, we ﬁnd that 61.31% of the LE-U nif minimal
cycle representatives are also LE-Len minimal while 99.32% of the LE-Len minimal cycle representatives are
also LE-U nif minimal across all cycle representatives from all data sets for FCB cycles. This suggests that
modelers can often use the length-weighted minimal cycle to substitute the uniform-weighted minimal cycle.
However, the triangle-loss cycles can potentially provide very different results.

E-Len, and 23.59% of xI

Counterintuitively, the LT -Area optimal cycle representative might not be the representative that encloses
E-U nif ,
E-Len for the cycles from PrsHCB using Program (14) have an area
E-U nif ,
E-Len for the cycles from FCB using Program (8)
T -Area. Lastly, 3.22% of
T -Area for the cycles found using Program (15) have an area

the smallest surveyor’s area. As shown in Figure 7, we observe that 15.55% of xN I
23.59% of xN I
smaller than that of the triangle-loss area-weighted optimal cycle xN I
12.87% of xI
have an area smaller than that of the triangle-loss area-weighted optimal cycle xN I
T -U nif , and 2.95% of xI
T -U nif , 2.81% of xN I
xI
smaller than that of the triangle-loss area-weighted optimal cycle xN I

T -Area. Similarly, 15.55% of xN I

E-Len, and 24.53% of xI

E-U nif , 24.53% of xN I

E-U nif , 13.14% of xI

T -Area.

In Figure 9, we provide an example illustrating why the triangle-loss area-weighted optimal cycle, solving

34

Figure 9: An example illustrating when the area enclosed by the triangle-loss area-weighted optimal cycle,
solution to Program TriN I
Area, can be larger than the area enclosed by the edge-loss length-weighted minimal
Len. (A) is the original cycle of a representative point cloud in R2 drawn
cycle, solution to Program EdgeN I
from the normal distribution, (B) is the length-weighted edge-loss optimal cycle, (C) is the area-weighted
triangle-loss optimal cycle, in this example, it is the same cycle as the original cycle, (D) is the area-weighted
minimal cycle where the blue shaded area marks the triangle born at the death time of the cycle. Constraint
Equation (17) speciﬁes that the area-weighted optimal cycle must contain the 2-simplex born at the death
time of the cycle. Therefore, this cycle must contain (a, d, f ) because it was born at the death time. The
length-weighted minimal cycle does not have this constraint, and as such, can result in a smaller area.

Area, or TriI

Programs TriN I
Area, might not be the cycle that encloses the smallest surveyor’s area. Another
reason why the area-weighted triangle-loss cycles could have a larger enclosed area is that in the optimization
problems, the loss function is the sum of the triangles the cycle bounds, not the real enclosed area. Therefore,
the area-weighted triangle-loss cycle will have the optimal area-weighted optimal cost, but not necessarily
the smallest enclosed area.

6.5 Comparative performance and precision of LP solvers

Our experiments demonstrate that the choice of linear solver may impact speed, frequency of obtaining
integer solutions, and frequency of obtaining (cid:96)0 optimal solutions. While these particular results are subject

35

U nif , and EdgeN I

to change due to regular updates to each platform, they illustrate the degree to which these factors can vary.
As discussed in Section 6.1, the GLPK solver performs much slower than the Gurobi solver in an initial
set of experiments. The GLPK solver also ﬁnds non-integral solutions when solving a linear programming
problem in Programs EdgeN I
Len more often than the Gurobi solver. On the same set of
experiments as in Section 6.1, when ﬁnding the FCB using Program (8), 9.74% of the edge-loss length-
weighted minimal cycle representatives have non-integral entries, and 8.32% of the edge-loss uniform-
weighted minimal cycle representatives have non-integral entries when using the GLPK solver, whereas
when using the Gurobi solver, 0.12% of the length-weighted minimal cycle representatives have non-integral
entries, and 0.04% of the uniform-weighted minimal cycle representatives have non-integral entries. For
the length-weighted minimal cycle representatives, the non-integral solutions differ from an (cid:96)0 optimal
solution by a margin of machine error with both solvers. However, for the uniform-weighted minimal cycle
representatives, the GLPK solver has 1.83% of its non-integral solutions differing from an (cid:96)0 optimal solution
by a margin not of machine epsilon, and the Gurobi solver has 0.02% of its non-integral solutions differing
from an (cid:96)0 optimal solution by a margin greater than machine epsilon. For the GLPK solver, when solving
Program EdgeN I
U nif , instead of ﬁnding an integral solution, it occasionally ﬁnds a solution with fractional
entries that sum to 1. For example, instead of assigning an edge a coefﬁcient of 1, it sometimes assigns two
edges each with a coefﬁcient of 0.5. In that way, the solution is still (cid:96)1 optimal, but no longer (cid:96)0 optimal.
Thus, the choice of linear solver may affect the optimization results.

6.6 Statistical properties of optimal cycle representatives with regard to various other quan-

tities of interest

Support of a representative forming a single loop in the underlying graph

The support of the original cycle, supp(xOrig) ⊆ S1(K), need not be a cycle in the graph-theoretic
sense. Concretely, this means that the nullity, p, of column submatrix ∂1[:, xOrig] may be strictly greater than
1 (in Figure 9, for example, p = 2). We refer to p informally as the “number of loops” in xOrig.

We are interested in exploring how often the support of an original cycle representative forms a single
loop in the underlying graph. We analyze each of the 360 synthetic data sets of various dimensions and
distributions discussed in Section 5.2 as well as the 100 Erd˝os-Rényi random complexes discussed in Section
5.3 and display the results in Figure 10. We ﬁnd that the majority of the original cycle representatives have
one loop. After optimizing these cycle representatives with the edge-loss methods, we verify that all FCB
and PrsHCB optimal cycles only have one loop, whereas 0.13% of the triangle-loss cycles have 2 loops.
However, we observe that 91.93% of the optimal cycle representatives for Erd˝os-Rényi complexes have 1
loop, 5.81% have 2 loops, and 2.14% have more than 2 loops, with 15 as the maximum number of loops.

As shown in Figure 11 the reduction in size of the original cycle, formalized as

closely with the reduction in the number of loops by the optimization.

C∗
•

L•(xOrig) , correlates

Overall effectiveness of optimization (L•(x∗

•) vs. L•(xOrig))

We compare the optimal representatives against the original cycle representatives21 with respect to
edge-loss functions LE-U nif and LE-Len. As shown in Figure 12, we ﬁnd that the optimizations are in general
effective in reducing the size of the cycle representative, especially for representatives with larger size. On
each of the subﬁgures, the horizontal axis is the size of the original cycle representative and the vertical axis
is the ratio between the loss of each optimal representative and the loss of the original representative:

C∗
•
L•(xOrig)

.

21The remainder of this subsection excludes the Erd˝os-Rényi cycles.

36

Figure 10: (Rows 1-3) Number of loops in the original cycle representative aggregated by dimension (labeled
by subﬁgure title) in the 360 randomly generated distribution data sets discussed in Section 5.2 and (Row 4)
same for the Erd˝os-Rényi random complexes discussed in Section 5.3, where we bin cycle representatives that
have 2-5 loops, 6-10, loops, or more than 10 loops. The horizontal axis is the number of cycle representatives
and the vertical axis is the number of loops in the original representative. We observe that for the distribution
data, an original cycle representative can have up to 5 loops in higher dimensions, and in general, it is
uncommon to ﬁnd an original representative with multiple loops. However, we observe that 17.47% of the
cycle representatives for Erd˝os-Rényi complexes have more than 1 loop, with a maximum number of 17
loops in a cycle representative.

37

Figure 11: Violin plot of the effectiveness of the optimization as a function of the number of loops in the
original cycle representative. Results are aggregated over the data sets from Section 5.1 and 5.2. The x-axis
shows the size reduction in terms of number of loops, and the y-axis shows the size reduction in terms of the
length of the cycle. We see that in general, the reduction in size of the original cycle mostly comes from the
reduction in the number of loops by the optimization.

CN I

E-U nif

The average ratio

LE-U nif (xOrig) is 83.17%, aggregated over cycle representatives obtained from data
described in Section 5.1 and 90.35% aggregated over cycle representatives obtained from data described in
LE-Len(xOrig) is 87.02% over cycle
Section 5.2 for cycles obtained from Program (14). The average ratio
representatives obtained from data described in Section 5.1 and 90.41% over cycle representatives obtained

CN I

E-Len

CN I

T -U nif
from data describedra Section 5.2 for cycles obtained from Program (14). The average ratio
LT -U nif (xOrig)
is 88.34% over cycle representatives obtained from data described in Section 5.1 and 95.54% over cycle
representatives obtained from data described in Section 5.2 for cycles obtained from Program (15).
Comparing solutions to integral programs and non-integral programs ( xN I

vs. xI
•)

•

E-Len = xI

T -Area = xI

E-Len. We ﬁnd xN I

Among all cycle representatives found by solving Program (14), 66.38% of them have xN I

E-U nif =
T -U nif = xI
E-U nif , and 99.51% of them have xN I
xI
T -U nif for 74.27% of the cycle
representatives and xN I
T -Area for 100% of the cycle representatives when using the triangle-loss
Program (15). Thus, the presence or absence of integer constraints rarely impacts the result of an area- or
length-weighted program, but often impacts solutions of a uniform-weighted program. We saw in Section 6.3
that essentially all solutions had coefﬁcients in {−1, 0, 1} regardless of integer or non-integer constraints. As
such, we conjecture that the higher rate of different solutions in the uniform-weighted problems could result
from a larger number of distinct optimal solutions and be a feature of particular choice of solution selected by
the linear solvers, rather than the non-existence of a particular integer solution.
Cycle representative size for different distributions and dimensions

Figure 13 provides a summary of the size and number of cycle representatives found for each distribution
data set described in Section 5.2. We observe that there tend to be more and larger (with respect to (cid:96)0 norm)
representatives in higher dimensions.

38

Figure 12: The effectiveness of length-weighted and uniform-weighted optimization for the data sets in
Sections 5.1 and 5.2 in reducing the size of the original cycle representative found by the persistence
algorithm. In each subﬁgure, the horizontal axis is the size of the original representative and the vertical
axis is the ratio between the size of the optimal representative and the size of the original representative.
The uniform-weighted graphs appear more sparse because reductions in the cost LT -U nif (xOrig) can only
come in multiples of the reciprocal of the original length. The node size in the uniform-weighted graphs
corresponds to the number of overlapping points.

39

Figure 13: The number of original cycle representatives and the number of edges within each original
representative for data described in Section 5.2. These plots aggregate all cycle representatives for each
dimension of a particular distribution. The horizontal axis for each subplot is the dimension of the data set,
and the vertical axis is the number of cycle representatives found in each dimension. In general, we see there
are more cycle representatives in higher dimensional data sets. Each bar is partitioned by the number of edges
of the representative. We observe that as dimension increases, there tend to be more cycle representatives
with more edges.

Duplicate intervals in the barcode

Of all data sets analyzed, only Klein and C.elegans have barcodes in which two or more intervals had
equal birth and death times (that is, bars with multiplicity ≥ 2). Among the 107 total intervals of the
C.elegans data set, there are 75 unique intervals, 10 intervals with multiplicity two, and one interval each
with multiplicity three, four, and ﬁve. The duplicate bars in the C.elegans data set are noteworthy for having
produced the sole example of an optimized cycle representative xN I
E-U nif with coefﬁcients outside {−1, 0, 1}
(in particular, it had coefﬁcients in {−0.5, 0.5}).

Among the 257 total intervals of the Klein data set, there are 179 unique intervals, 1 interval that is
repeated twice, and 2 intervals that are repeated 38 times. For the Klein data set, if we replace the distance
matrix provided by [48] with the Euclidean distance matrix calculated using Julia (the maximum difference
between the two matrices is on the scale of 10−5), we obtain only one interval that is repeated twice. This
indicates that duplicate intervals are rare in practice, at least in dimension 1.

Edge-loss cycle representatives FCB vs. PrsHCB

We ﬁnd that for 84.52% of EdgeN I

Len, and 93.49% of
EdgeI
Len, the FCB edge-loss cycle representatives found by Program (8) and the PrsHCB edge-loss cycles
from Program (14) are the same, i.e. the (cid:96)1 norm of their difference is 0. As mentioned in Remark 3.1,
the FCB cycles may not have the same death time as xOrig. For the real-world data sets, 6.72% of the

U nif , 93.49% of EdgeN I

U nif , 90.84% of EdgeI

40

Len) and (EdgeI

Len), 7.65% of the (EdgeN I

(EdgeN I
xOrig. For the randomly generated distribution data sets, 7.11% of the (EdgeN I
the (EdgeN I
lifetimes different than xOrig have death time beyond that of xOrig.

U nif ) have lifetimes different than
Len), 8.06% of
U nif ) have lifetimes different than xOrig. All cycle representatives with

U nif ) and 4.48% of (EdgeI

U nif ) and 4.25% of (EdgeI

Len) and (EdgeI

6.7 Optimal cycle representatives for Erd˝os-Rényi random clique complexes

We observe qualitatively different behavior in cycle representatives from the Erd˝os-Rényi random clique
complexes. Among the 34,214 cycle representatives from the 100 dissimilarity matrices found by solving
Programs (14) and (15), we ﬁnd that 91.04% of the original cycle representatives have entries in {−1, 0, 1}
and 99.75% of the original cycle representatives have integral entries. We have 3.89% of the length-weighted
edge-loss representatives, 4.49% of the uniform-weighted edge-loss representatives, and 3.52% of the
uniform-weighted triangle-loss representatives with entries not in {−1, 0, 1}. We ﬁnd 2.66% of the length-
weighted edge-loss representatives, 3.57% of the uniform-weighted edge-loss representatives, and 1.58%
of the uniform-weighted triangle-loss representatives with non-integral entries when not requiring integral
solutions.

We ﬁnd

LE−U nif (xN I
LE−U nif (xI

E−U nif )
E−U nif )

> 1 for 1.07% of the cycle representatives and

LE−Len(xN I
LE−Len(xI

E−Len)
E−Len)

> 1 for

1.09% of the representatives. All such representatives have entries outside of {−1, 0, 1} and involve some
fractional entries. An average of 96.75% of the nonzero entries in the reduced boundary matrices are in
{−1, 1}, 2.15% in {−2, 2}, and 0.27% with an absolute value greater than or equal to 3.

Because of the non-integrality of some original cycle representatives found by the persistence algorithm,
we fail to ﬁnd an integral solution for 0.27% of the edge-loss representatives and 0.11% of the triangle-loss
representatives.

A partial explanation for this behavior can be found in the work of Costa et al. [15]. Here, the authors
show that a connected two-dimensional simplicial complex for which every subcomplex has fewer than three
times as many edges as vertices must have the homotopy type of a wedge of circles, 2-spheres, and real
projective planes. With high probability, certain ranges of thresholds for the i.i.d. dissimilarity matrices
on which the Erd˝os-Rényi random complexes are built produces random complexes with approximately
such density patterns at each vertex. Thus, some of the persistent cycles are highly likely to correspond to
projective planes. Because of their non-orientability, the corresponding minimal generators could be expected
to have entries outside of the range {−1, 0, 1}.

7 Conclusion

In this work, we provide a theoretical, computational, and empirical user’s guide to optimizing cycle
representatives against four criteria of optimality: total length, number of edges, internal volume, and area-
weighted internal volume. Utilizing this framework, we undertook a study on statistical properties of minimal
cycle representatives for H1 homology found via linear programming. In doing so, we made the following
four main contributions.

1. We developed a publicly available code library [41] to compute persistent homology with rational
coefﬁcients, building on the software package Eirene [37] and implemented and extended algorithms
from [27, 46] for computing minimal cycle representatives. The library employs standard linear solvers
(GLPK and Gurobi) and implements various acceleration techniques described in Section 4.4 to make
the computations more efﬁcient.

2. We formulated speciﬁc recommendations concerning procedural factors that lie beyond the scope of
the optimization problems per se (for example, the process used to generate inputs to a solver) but

41

which bear directly on the overall cost of computation, and of which practitioners should be aware.

3. We used this library to compute optimal cycle representatives for a variety of real-world data sets and
randomly generated point clouds. Somewhat surprisingly, these experiments demonstrate that computa-
tionally advantageous properties are typical for persistent cycle representatives in data. Indeed, we ﬁnd
that we are able to compute uniform/length-weighted optimal cycles for all data sets we considered,
and that we are able to compute triangle-loss optimal cycles for all but six cycle representatives, which
fail due to the large number of triangles (more than 20 million) used in the optimization problem.
Computation time information is summarized in Table 1 and Table 2.

Consequently, heuristic techniques may provide efﬁcient means to extract solutions to cycle represen-
tative optimization problems across a broad range of contexts. For example, we ﬁnd that edge-loss
optimal cycles are faster to compute than triangle-loss optimal cycles for cycle representatives with a
longer persistence interval, whereas for cycles with shorter persistence intervals, the triangle-loss cycle
can be less computationally expensive to compute.

4. We provided statistics on various minimal cycle representatives found in these data, such as their
effectiveness in reducing the size of the original cycle representative found by the persistence algorithm
and their effectiveness evaluated against different loss functions. In doing so, we identiﬁed consistent
trends across samples that address the questions raised in Section 1.

(a) Optimal cycle representatives are often signiﬁcant improvements in terms of a given loss function
over the initial cycle representatives provided by persistent homology computations (typically,
by a factor of 0.3 to 1.0). Interestingly, we ﬁnd that area-weighted triangle-loss optimal cy-
cle representatives can enclose a greater area than length- or uniform-weighted optimal cycle
representatives.

(b) We ﬁnd that length-weighted edge-loss optimal cycles are also optimal with respect to a uniform-
weighted edge-loss function upwards of 99% of the time in the data we studied. This suggests that
one can often ﬁnd a solution that is both length-weighted minimal and uniform-weighted minimal
by solving only the length-weighted minimal optimization problem. However, the triangle-loss
optimal cycles can have a relatively higher length-weighted edge-loss or uniform-weighted edge-
loss than the length/uniform-weighted minimal cycles. Thus, computing triangle-loss optimal
cycles might provide distinct information and insights.

(c) Strikingly, all but one (cid:96)1 optimal representatives were also (cid:96)0 optimal (that is, (cid:96)0 optimal among
cycles taking {0, 1, −1} coefﬁcients; (cid:96)0 optimality among cycles taking Z coefﬁcients was not
tested) in the real-world and synthetic point cloud data. Thus, it appears that solutions to the
NP-hard problem of ﬁnding (cid:96)0 optimal cycle representatives can often be solved using linear
programming in real data. In the Erd˝os-Rényi random complexes, qualitatively different behavior
was found; this may relate to the fact that spaces in this random family contain non-orientable
subcomplexes with high probability.

Several questions lie beyond the scope of this text and merit future investigation. For example, while
the methods discussed in Section 4 apply equally to homology in any dimension, we have focused our
empirical investigation exclusively in dimension one; it would be useful and interesting to compare
these results with homology in higher dimensions. It would likewise be interesting to compare with
different weighting strategies on simplices, and loss functions other than (cid:96)0 and (cid:96)1, e.g. (cid:96)2. Future work
may also consider whether the modiﬁed approach to edge-loss minimization Program (14) could be
incorporated into persistence solvers themselves, as pioneered in [27]. Unlike the programs formulated
in this earlier work, Program (14) requires information about the death times of cycles in addition

42

to their births; typically this information is not available until after the persistence computation has
already ﬁnished, so new innovations would probably be needed to make progress in this direction.

8 Conﬂict of Interest Statement

The authors declare that the research was conducted in the absence of any commercial or ﬁnancial relationships
that could be construed as a potential conﬂict of interest.

9 Author Contributions

G.H-P. wrote the Eirene code. L.L. and C.T. wrote the rest of the code and performed all experiments.
L.L. created all ﬁgures and tables. G.H-P. and L.Z. designed, directed, and supervised the project. G.H-P.
developed the theory in the Supplementary Material. All authors contributed to the analysis of the results and
to the writing of the manuscript.

10 Funding

This material is based upon work supported by the National Science Foundation under grants no. DMS-
1854683, DMS-1854703, and DMS-1854748.

11 Acknowledgments

The authors are grateful to David Turner for helpful advice on selection of linear solvers. They also thank
and acknowledge the initial work done by Robert Angarone and Sophia Wiedemann on this study.

12 Supplemental Data

Details regarding implementation and proofs of correctness for the algorithms discussed in Section 4 as well
as an additional ﬁgure and table may be found in the Supplementary Material.

13 Data Availability Statement

The data sets and code for this study can be found in the repository [41].

References

[1] P. Bendich, J. S. Marron, E. Miller, A. Pieloch, and S. Skwerer. Persistent homology analysis of brain artery trees.

The annals of applied statistics, 10(1):198, 2016.

[2] D. Bertsimas and J. Tsitsiklis. Introduction to linear optimization. Athena Scientiﬁc, 1997.

[3] D. Bhaskar, A. Manhart, J. Milzman, J. T. Nardini, K. M. Storey, C. M. Topaz, and L. Ziegelmeier. Analyzing
collective motion with machine learning and topology. Chaos: An Interdisciplinary Journal of Nonlinear Science,
29(12):123125, 2019.

[4] S. Bhattacharya, R. Ghrist, and V. Kumar. Persistent homology for path planning in uncertain environments. IEEE

Transactions on Robotics, 31(3):578–590, 2015.

43

[5] G. Borradaile, W. Maxwell, and A. Nayyeri. Minimum bounded chains and minimum homologous chains in
embedded simplicial complexes. Number 21, pages 21:1–21:15. 36th International Symposium on Computational
Geometry (SoCG 2020), Leibniz International Proceedings in Informatics, 2020.

[6] S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press, March 2004.

[7] B. Braden. The surveyor’s area formula. The College Mathematics Journal, 17(4):326–337, 1986.

[8] R. Brüel-Gabrielsson, V. Ganapathi-Subramanian, P. Skraba, and L. J. Guibas. Topology-aware surface recon-

struction for point clouds. Computer Graphics Forum, 39(5):197–207, 2020.

[9] G. Carlsson. Topology and data. Bulletin of the American Mathematical Society, 46:255–308, 2009.

[10] J. M. Chan, G. Carlsson, and R. Rabadan. Topology of viral evolution. Proceedings of the National Academy of

Sciences, 110(46):18566–18571, 2013.

[11] C. Chen and D. Freedman. Quantifying Homology Classes. In S. Albers and P. Weil, editors, 25th Interna-
tional Symposium on Theoretical Aspects of Computer Science, volume 1 of Leibniz International Proceedings
in Informatics (LIPIcs), pages 169–180, Dagstuhl, Germany, 2008. Schloss Dagstuhl–Leibniz-Zentrum fuer
Informatik.

[12] C. Chen and D. Freedman. Hardness results for homology localization. In Proceedings of the Twenty-First Annual
ACM-SIAM Symposium on Discrete Algorithms, SODA ’10, page 1594–1604, USA, 2010. Society for Industrial
and Applied Mathematics.

[13] C. Chen and D. Freedman. Measuring and computing natural generators for homology groups. Computational

Geometry, 43(2):169–181, 2010.

[14] D. Cohen-Steiner, H. Edelsbrunner, and D. Morozov. Vines and vineyards by updating persistence in linear time.
In Proceedings of the twenty-second annual symposium on Computational geometry, pages 119–126, 2006.

[15] A. Costa, M. Farber, and D. Horak. Fundamental groups of clique complexes of random graphs. Transactions of

the London Mathematical Society, 2(1):1–32, 2015.

[16] T. A. Davis and Y. Hu. The university of ﬂorida sparse matrix collection. ACM Trans. Math. Softw., 38(1), Dec.

2011.

[17] V. de Silva, D. Morozov, and M. Vejdemo-Johansson. Dualities in persistent (co)homology. Inverse Problems,

27(12):124003, 17, 2011.

[18] T. K. Dey, A. N. Hirani, and B. Krishnamoorthy. Optimal homologous cycles, total unimodularity, and linear

programming. SIAM Journal on Computing, 40(4):1026–1044, 2011.

[19] T. K. Dey, T. Hou, and S. Mandal. Persistent 1-cycles: Deﬁnition, computation, and its application. In International

Workshop on Computational Topology in Image Context, pages 123–136. Springer, 2019.

[20] T. K. Dey, T. Li, and Y. Wang. Efﬁcient algorithms for computing a minimal homology basis. In Latin American

Symposium on Theoretical Informatics, pages 376–398. Springer, 2018.

[21] T. K. Dey, J. Sun, and Y. Wang. Approximating loops in a shortest homology basis from point data. In Proceedings
of the Twenty-Sixth Annual Symposium on Computational Geometry, SoCG ’10, page 166–175, New York, NY,
USA, 2010. Association for Computing Machinery.

[22] H. Edelsbrunner and J. Harer. Persistent homology—a survey. Discrete & Computational Geometry - DCG, 453,

01 2008.

[23] H. Edelsbrunner and J. Harer. Computational Topology: An Introduction. Applied Mathematics. American

Mathematical Society, 2010.

[24] K. Emmett, B. Schweinhart, and R. Rabadan. Multiscale topology of chromatin folding. arXiv preprint

arXiv:1511.01426, 2015.

[25] J. Erickson and K. Whittlesey. Greedy optimal homotopy and homology generators. In SODA, volume 5, pages

1038–1046, 2005.

44

[26] E. Escolar and Y. Hiraoka. OptiPersLP - optimal cycles in persistence via linear programming. https:

//bitbucket.org/remere/optiperslp/src/master/, 2021.

[27] E. G. Escolar and Y. Hiraoka. Optimal cycles for persistent homology via linear programming. In Optimization in

the Real World, pages 79–96. Springer, 2016.

[28] R. Ghrist. Barcodes: the persistent topology of data. Bulletin of the American Mathematical Society, 45(1):61–75,

2008.

[29] R. Ghrist. Barcodes: The persistent topology of data. Bulletin (New Series) of the American Mathematical Society,

45, 02 2008.

[30] R. Ghrist. Elementary Applied Topology. CreateSpace Independent Publishing Platform, 2014.

[31] C. Giusti, R. Ghrist, and D. S. Bassett. Two’s company, three (or more) is a simplex. Journal of computational

neuroscience, 41(1):1–14, 2016.

[32] GNU Project. GLPK (GNU Linear Programming Kit). https://www.gnu.org/software/glpk/, 2012.

[33] Gregory Henselman-Petrusek. Eirene (Julia library for computational persistent homology). https://github.

com/Eetion/Eirene.jl, Commit 4f57d6a0e4c030202a07a60bc1bb1ed1544bf679, 2016.

[34] L. Gurobi Optimization. Gurobi optimizer reference manual. 2020.

[35] A. Hatcher, C. U. Press, and C. U. D. of Mathematics. Algebraic Topology. Algebraic Topology. Cambridge

University Press, 2002.

[36] G. Henselman and P. Dłotko. Combinatorial invariants of multidimensional topological network data. In 2014
IEEE Global Conference on Signal and Information Processing (GlobalSIP), pages 828–832. IEEE, 2014.

[37] G. Henselman and R. Ghrist. Matroid Filtrations and Computational Persistent Homology. ArXiv e-prints, June

2016.

[38] G. Henselman-Petrusek. Matroids and canonical forms: theory and applications. PhD thesis, University of

Pennsylvania, May 2017.

[39] Y. Hiraoka, T. Nakamura, A. Hirata, E. G. Escolar, K. Matsue, and Y. Nishiura. Hierarchical structures of
amorphous solids characterized by persistent homology. Proceedings of the National Academy of Sciences,
113(26):7035–7040, 2016.

[40] V. Kovacev-Nikolic, P. Bubenik, D. Nikoli´c, and G. Heo. Using persistent homology and dynamical distances to
analyze protein binding. Statistical Applications in Genetics and Molecular Biology, 15(1):19 – 38, 01 Mar. 2016.

[41] Li, Lu and Thompson, Connor.

ogy using Linear Programming: an Empirical Study with User’s Guide.
TDAMinimalGeneratorResearch/minimal-generator, 2021.

Source code, Minimal Cycle Representatives in Persistent Homol-
https://github.com/

[42] Los Alamos National Laboratory. HIV database. http://www.hiv.lanl.gov/content/index.

[43] M. R. McGuirl, A. Volkening, and B. Sandstede. Topological data analysis of zebraﬁsh patterns. Proceedings of

the National Academy of Sciences, 117(10):5113–5124, 2020.

[44] N. Milosavljevi´c, D. Morozov, and P. Skraba. Zigzag persistent homology in matrix multiplication time. In
Proceedings of the Twenty-Seventh Annual Symposium on Computational Geometry, SoCG ’11, page 216–225,
New York, NY, USA, 2011. Association for Computing Machinery.

[45] M. E. Newman. Finding community structure in networks using the eigenvectors of matrices. Physical review E,

74(3):036104, 2006.

[46] I. Obayashi. Volume-optimal cycle: Tightest representative cycle of a generator in persistent homology. SIAM

Journal on Applied Algebra and Geometry, 2(4):508–534, 2018.

[47] I. Obayashi, T. Wada, T. Tunhua, J. Miyanaga, and Y. Hiraoka. HomCloud: data analysis software based on

persistent homology). https://homcloud.dev/, 2021.

45

[48] N. Otter, M. A. Porter, U. Tillmann, P. Grindrod, and H. A. Harrington. A roadmap for the computation of

persistent homology. EPJ Data Science, 6(1):17, 2017.

[49] Otter, Nina and Porter, Mason A and Tillmann, Ulrike and Grindrod, Peter and Harrington, Heather A. A roadmap
for the computation of persistent homology. https://github.com/n-otter/PH-roadmap, 2017.

[50] G. Petri, M. Scolamiero, I. Donato, and F. Vaccarino. Topological strata of weighted complex networks. PloS one,

8(6):e66506, 2013.

[51] B. Schweinhart. Statistical Topology of Embedded Graphs. PhD thesis, Princeton University, 2015.

[52] G. Singh, F. Mémoli, and G. E. Carlsson. Topological methods for the analysis of high dimensional data sets and

3d object recognition. SPBG, 91:100, 2007.

[53] A. E. Sizemore, J. E. Phillips-Cremins, R. Ghrist, and D. S. Bassett. The importance of the whole: Topological

data analysis for the network neuroscientist. Network Neuroscience, 3(3):656–673, 2019.

[54] O. Sporns. Small-world connectivity, motif composition, and complexity of fractal neuronal connections. Bio

Systems, 85(1):55—64, July 2006.

[55] Stanford University Computer Graphics Laboratory. The Stanford 3D Scanning Repository. https://

graphics.stanford.edu/data/3Dscanrep/, 1999.

[56] A. Tahbaz-Salehi and A. Jadbabaie. Distributed coverage veriﬁcation in sensor networks without location

information. In 2008 47th IEEE Conference on Decision and Control, pages 4170–4176, 2008.

[57] A. Tahbaz-Salehi and A. Jadbabaie. Distributed coverage veriﬁcation in sensor networks without location

information. IEEE Transactions on Automatic Control, 55(8):1837–1849, 2010.

[58] C. M. Topaz, L. Ziegelmeier, and T. Halverson. Topological data analysis of biological aggregation models. PloS

one, 10(5), 2015.

[59] M. Ulmer, L. Ziegelmeier, and C. M. Topaz. A topological approach to selecting models of biological experiments.

PLOS ONE, 14(3):1–18, 03 2019.

[60] R. J. Vanderbei. Linear programming foundations and extensions. International series in operations research I&

management science ; v.196. Springer, New York, 4th ed. edition, 2014.

[61] R. Vasudevan, A. D. Ames, and R. Bajcsy. Human based cost from persistent homology for bipedal walking.

IFAC Proceedings Volumes, 44(1):3292–3297, 2011. 18th IFAC World Congress.

[62] T. Vicsek, A. Czirók, E. Ben-Jacob, I. Cohen, and O. Shochet. Novel type of phase transition in a system of

self-driven particles. Phys. Rev. Lett., 75:1226–1229, Aug 1995.

[63] P. Wu, C. Chen, Y. Wang, S. Zhang, C. Yuan, Z. Qian, D. N. Metaxas, and L. Axel. Optimal topological cycles
and their application in cardiac trabeculae restoration. In Information Processing in Medical Imaging, IPMI, pages
80–92, 2017.

[64] K. Xia, Z. Li, and L. Mu. Multiscale persistent functions for biomolecular structure characterization. Bulletin of

mathematical biology, 80(1):1–31, 2018.

[65] K. Xia and G.-W. Wei. Persistent homology analysis of protein structure, ﬂexibility, and folding. International

journal for numerical methods in biomedical engineering, 30(8):814–844, 2014.

[66] X. Zhang and P. Wu. Heuristic search for homology localization problem and its application in cardiac trabeculae

reconstruction. In IJCAI, 2019.

[67] A. Zomorodian and G. Carlsson. Computing persistent homology. Discrete and Computational Geometry,

33:249–274, 02 2005.

46

A Review: Standard algorithm to compute persistent homology cycle bases,

by matrix decomposition

The ﬁrst step in Algorithms 1 and 2 is to compute a persistent homology cycle basis. The standard method to
compute such a basis invokes a so-called R = DV decomposition of the boundary matrices ∂n [14]. Here
we provide a brief review of this process; further details may be found in [14, 17].

To begin, we must place a total order on each set Sn(K), in ascending order of birth. This naturally
allows us to regard ∂n as an element of G|Sn−1(K)|×|Sn(K)|. The low function on a matrix A ∈ Gk×l is
deﬁned by

low : {j : A[:, j] (cid:54)= 0}
(cid:125)

(cid:123)(cid:122)
domain(low)

(cid:124)

→ Z,

j (cid:55)→ max{i : A[i, j] (cid:54)= 0}.

We say that A is reduced if low is injective. An R = DV decomposition is a matrix equation where R is
reduced and V is invertible and upper triangular.

Suppose that Rn = ∂nVn is such a decomposition for each n. Let lown be the low function of Rn, and

let Γn = {(j, low(j)) : R[:, j] (cid:54)= 0} be the graph lown. It can then be shown ([14, 17]) that

1. Each set Sn(K) partitions into three disjoint subsets: Bn (cid:116) B∗

n (cid:116) Hn, where Bn is the image of lown+1

and B∗

n is the domain of lown.

2. If B∗

n(t) denotes the set of simplices in Bn born by time t, then ∂n[:, B∗

n(t)] is a basis for the space of

boundaries Bn(Kt).

3. Let ˆΓn denote the subset of Γn consisting of those pairs (σ, τ ) such that Birth(σ) (cid:54)= Birth(τ ), and let
En = {τ : (σ, τ ) ∈ ˆΓ} ∪ Hn. Then Vn[:, Hn] ∪ Rn[:, En] is a persistent homology cycle basis. The
lifespan of Vn[:, σ] is [Birth(σ), ∞) and the lifespan of Rn[:, τ ] is [Birth(σ), Birth(τ )), where σ is
the unique simplex such that (σ, τ ) ∈ Γ.

4. In particular, the barcode of K• may be read off from the R = DV decompositions.

B Correctness of Algorithms 1 and 2

Here we provide proofs of correctness for Algorithms 1 and 2. As the details are primarily technical in nature,
the exposition is fairly terse. The arguments are primarily self-contained, however we begin by recalling one
result from [37], which will be used in the proof of Algorithm 1.

B.1 Review: characterization of persistent homology bases

We will invoke a result from [37] and [38] which requires one new deﬁnition and one new notational
convention. For notation, let n be given, ﬁx (cid:15)i < (cid:15)j, and set

X i,j := Zn(K(cid:15)i) ∩ Bn(K(cid:15)j )

Y i,j := Zn(K(cid:15)i−1) + Bn(K(cid:15)j−1)

Qi,j :=

X i,j
X i,j ∩ Y i,j

We then deﬁne qi,j as the quotient map

qi,j : X i,j → Qi,j

Deﬁnition B.1 A subset E ⊆ X i,j is an (i, j)-basis if qi,j|E is injective and qi,j(E) is a basis of Qi,j.

47

Theorem B.2 ([37, 38]) A family of n-cycles E is a persistent homology cycle basis iff

Ei,j := E ∩ (X i,j − Y i,j)

is an (i, j) basis for all i and j.

Remark B.3 A special case of Theorem B.2 (for simplex-wise ﬁltrations) also appeared in [63, Theorem 1].
This construction is also closely related to that of pair groups, c.f. [22].

B.2 Correctness of Algorithm 3

We restate Algorithm 3 for ease of reference.

Algorithm 3 Edge-loss persistent cycle minimization
1: Compute a persistent homology basis B for homology in dimension 1, with coefﬁcients in Q, using
the standard matrix decomposition procedure described in the Supplementary Material. Arrange the
elements of B into an ordered sequence Z0 = (z0,1, . . . , z0,m).

2: for j = 0, . . . , m − 1 do
3:

Solve Program (14) to optimize the j + 1th element of Zj. Let x denote the solution to this problem,
and deﬁne Zj+1 by replacing the j + 1th element of Zj with x. Concretely, zj+1,j+1 = x, and
zj+1,k = zj,k for k (cid:54)= j.

4: end for
5: Return B∗ := {zm,1, . . . , zm,m}, the set of elements in Zm.

Recall that Program (14) optimizes the jth element of an ordered sequence of cycle representatives
Z = (z1, . . . , zm). In particular, it seeks to minimize xOrig := zj. To deﬁne this program, we ﬁrst construct
a matrix A such that A[:, i] = zi for i = 1, . . . , m. We then deﬁne three index sets, P, Q, R such that

P = {i : Birth(zi) ≤ Birth(xOrig), Death(zi) ≤ Death(xOrig), i (cid:54)= j}
Q = {σ ∈ S2(K) : Birth(σ) ≤ Birth(xOrig)}
R = {σ ∈ S1(K) : Birth(σ) ≤ Birth(xOrig)}

Program (14) can then be deﬁned as follows.

minimize ||W x||1 =

N
(cid:88)

(x+

i + x−
i )

subject to (x+ − x−) = xOrig[R] + ∂2[R, Q]q + A[R, P]p

i=1

p ∈ QP
q ∈ QQ
x ∈ GR
x+, x− ≥ 0

(14)

Theorem B.4 For each k, the family of cycles {zk,1, . . . , zk,m} constructed in Algorithm 3 is a persistent
homology cycle basis. Moreover, lifespans are preserved, in the sense that

L(z0,l) = L(zk,l)

(16)

for all k and l.

48

Proof: We proceed by induction on k, the base case k = 0 begin clear. Assume the desired conclusion holds
for k. For ease of reference, put

Z := (z1, . . . , zm) := (zk,1, . . . , zk,m) = Zk.

xOrig := zk+1

[(cid:15)i, (cid:15)j) := L(xOrig)

We may then partition P as the disjoint union S (cid:116) T , where

S = {l ∈ P : Birth(zl) < Birth(zk+1) or Death(zl) < Death(zk+1)}
T = {l ∈ P : Birth(zl) = Birth(zk+1), Death(zl) = Death(zk+1), l (cid:54)= k + 1}.

An optimal solution to Program (14) can then be expressed in form

x = zk+1 + ∂2[R, Q]q + A[R, P]q = zk+1 + ∂2[R, Q]q
(cid:125)

(cid:124)

(cid:123)(cid:122)
u

+ A[R, S]q[S]
(cid:123)(cid:122)
(cid:125)
v

(cid:124)

+ A[R, T ]q[T ]
(cid:123)(cid:122)
(cid:125)
w

(cid:124)

where

Now put

u ∈ B(K(cid:15)i) ⊆ X i,j ∩ Y i,j

v ∈ X i,j ∩ Y i,j

w ∈ span({zt : t ∈ T }).

F := {zt : t ∈ T } (cid:116) {zk+1}
F (cid:48) := {zt : t ∈ T } (cid:116) {zk+1 + w}
F (cid:48)(cid:48) := {zt : t ∈ T } (cid:116) {zk+1 + u + v + w} = {zt : t ∈ T } (cid:116) {x}

Since w ∈ span({zt : t ∈ T }), it is easily argued that span(F ) = span(F (cid:48)). Thus span(qi,j(F )) =
span(qi,j(F (cid:48))) = span(qi,j(F (cid:48)(cid:48))) = Qi,j. Dimension counting thus implies that qi,j(F (cid:48)(cid:48)) is an (i, j)-basis.
Given this observation, it is straightforward to verify that {zk+1,1, . . . , zk+1,m} is a bona-ﬁde cycle basis

and L(x) = L(xOrig). The desired conclusion follows.

This establishes our primary objective:

Theorem B.5 The set B∗ returned by Algorithm 3 is a bona ﬁde persistent homology cycle basis of the
ﬁltered simpicial complex K•.

B.3 Correctness of Algorithm 4

Recall that [46] deﬁnes a persistent volume for a birth-death pair (σbi, σdi) as an (n+1) chain v ∈ Cn+1(Kdi)
such that

where

v = σdi +

(cid:88)

αkσk

σk∈Fn+1

(∂n+1v)τ = 0 ∀τ ∈ Fn
(∂n+1v)σbi
(cid:54)= 0,

Fl := {σk ∈ Sl(K) : bi < k < di}

49

(17)

(18)

(19)

(20)

is the family of l-simplices whose birth time lies strictly between bi and di. The linear program associated to
(σbi, σdi) in [46] can then be summarized as

minimize loss(v)
subject to (17), (18), (19)
v ∈ Cn+1(Kdi)

(10)

Let us restate Algorithm 4 and the corresponding optimization problem, Program (15), for ease of

reference.

Algorithm 4 Triangle-loss persistent cycle minimization
1: Place a ﬁltration-preserving linear order ≤(l) on Sl(K) for each l.
2: Compute an R = ∂n+1V decomposition as described in [14] and the Supplementary Material. We then

obtain a set Γ of birth/death pairs (σ, τ ).

3: For each (σ, τ ) ∈ Γ such that Birth(σ) < Birth(τ ), put

Fn := {σ(cid:48) ∈ Sn(K) : Birth(σ(cid:48)) ≤ Birth(τ ), σ (cid:12)(n) σ(cid:48)}
Fn+1 := {τ (cid:48) ∈ Sn+1(K) : Birth(σ) ≤ Birth(τ (cid:48)), τ (cid:48) (cid:12)(n+1) τ }

and ˆFn+1 := Fn+1 ∪ {τ }. Compute a solution to the corresponding Program (15), and denote this
solution by xσ,τ .

4: Put ˆD := {∂n+1(xσ,τ ) : (σ, τ ) ∈ Γ and Birth(σ) < Birth(τ )} and let ˆD(cid:48) := {z ∈ M : Death(z) =

∞}, where M is a persistent homology cycle basis calculated by the standard R = DV method.

5: Return D := ˆD ∪ ˆD(cid:48).

Recall that we refer to Program (15) as the general triangle-loss problem.

minimize ||W v||1 =

N
(cid:88)

(v+

i + v−
i )

subject to ∂n+1[σ, ˆFn+1]v (cid:54)= 0

i=1

∂n+1[Fn, ˆFn+1]v = 0
vτ = 1
v+, v− ≥ 0

v+, v− ∈ G

ˆFn+1

(15)

To verify that Algorithm 4 returns a bona-ﬁde persistent homology cycle basis, let us begin by placing
the elements of K into a sequence (σ1, . . . , σ|K|) by ordering simplices ﬁrst by birth time, second (that
is, breaking ties when birth times agree) by dimension, and ﬁnally (breaking ties when birth times and
dimensions agree) by the chosen linear orders ≤(l). It is simple to verify that this rule deﬁnes a unique linear
order on K, and that the ﬁltration K(cid:48)

• deﬁned by

is a simplex-wise reﬁnement of K•.

K(cid:48)

i := {σ1, . . . , σi}

Theorem B.6 Let (σ, τ ) be a birth-death pair, and choose bi, di such that (σbi, σdi) = (σ, τ ). Then the sets
Fn and Fn+1 deﬁned in Algorithm 4 both satisfy (20). Consequently, Program (15) is a special case of
Program (10).

50

Proof: The proof is a straightforward exercise in deﬁnition checking.

Now let ˆB be a set containing the boundary of one optimal solution xσ,τ to Program (15) for each
birth-death pair (σ, τ ) = (σbi, σdi) (even if Birth(σ) = Birth(τ ))). Let N be a persistent homology cycle
•, and let ˆB(cid:48) = {z ∈ N : Death(z) = ∞} be the collection of cycle representatives in N that
basis for K(cid:48)
never die. Then, by combining Theorem B.6 with Theorem 5 of [46], we ﬁnd that B := ˆB ∪ ˆB(cid:48) is a persistent
homology cycle basis of K(cid:48)
•.

If we assume that the bounding volumes used to obtain ˆB are the same as those used to obtain ˆD in
Algorithm 4, and, likewise, that ˆB(cid:48) = ˆD(cid:48) (this will be true provided we use the order ≤(l) when ordering
columns of ∂l for the K• calculation) then

D = {z ∈ B : Birth(z) < Death(z)}

where Birth and Death are the birth and death functions of K•, not K(cid:48)
•.

From here, it remains only to verify that D is a bona ﬁde persistent homology cycle basis K•. This

follows from the following general observation.

Theorem B.7 Let L(cid:48)
homology cycle bases for L(cid:48)
Birth(z) < Death(z)}, then D is a persistent homology cycle basis of L•.

• be a reﬁnement of a ﬁltration L• on a simplicial complex L, and let B be a persistent
•. If Birth and Death are the birth and death functions of L• and D := {z ∈ B :

Proof: Recall that, by deﬁnition, a set E is a persistent homology cycle basis of K• iff two criteria hold: (i)
L(z) must be nonempty for each z ∈ E, and (ii) {[z] ∈ Hn(K(cid:15)i; G) : (cid:15)i ∈ L(z)} is a basis for Hn(K(cid:15)i; G)
for each i. Since B is a persistent homology cycle basis for L(cid:48)
•, it is a straightforward exercise in deﬁnition
checking to verify that D is a persistent homology cycle basis for L•.

This establishes our primary objective:

Theorem B.8 (Correctness of Algorithm 4) Algorithm 4 returns a bona-ﬁde persistent homology cycle
basis of K•.

C Supplementary Tables and Figures

51

Table 4: Classifying the coefﬁcients of the optimal cycles for all of the real-world data discussed in Section
5.1 as well as all of the synthetic sets discussed in Section 5.2. The rows are labeled by the coefﬁcient
type of the cycle representatives: “Integral” means the coefﬁcients for the cycle representative x are in Z
and “In {−1, 0, 1}” means the coefﬁcients for the representative x are in {−1, 0, 1}. For the columns, x
represents the optimal representative with its superscript indicating the type of optimization problem: I
for integer programming and N I for linear programming, and its subscript indicating the type of optimal
cycle: E-Len, E-U nif, T -U nif refer to edge loss length-weighted minimal (minimizing total length of 1-
simplices), edge loss uniform (minimizing total number of 1-simplices), and triangle loss uniform (minimizing
the number of 2-simplices a cycle representative bounds), respectively.

Edge-loss ﬁltered homological optimal cycles (Program (14))

Randomly Generated Data Sets

Real-World Data Sets

Coefﬁcient Type

xI

E-Len

xN I

E-Len

xI

T -U nif

xN I

E-U nif

xI

E-Len

xN I

E-Len

xI

E-U nif

xN I

E-U nif

Integral

In {−1, 0, 1}

100%

100%

100%

100%

100%

100%

100%

100%

100%

100%

100%

100%

100%

100%

100%

100%

Edge-loss persistent homological optimal cycles (Program (8))

Randomly Generated Data Sets

Real-World Data Sets

Coefﬁcient Type

xI

E-Len

xN I

E-Len

xI

T -U nif

xN I

E-U nif

xI

E-Len

xN I

E-Len

xI

E-U nif

xN I

E-U nif

Integral

In {−1, 0, 1}

100%

100%

100%

100%

100%

100%

100%

100%

100%

100%

100%

100%

100%

100%

99.94%

99.94%

Randomly Generated Data Sets

Real-World Data Sets

Triangle-loss optimal cycles (Program (15))

Coefﬁcient Type

xI

T -U nif

xN I

T -U nif

xI

T -Area

xN I

T -Area

xI

T -U nif

xN I

T -U nif

xI

T -Area

xN I

T -Area

Integral

In {−1, 0, 1}

100%

100%

99.99% 100%

99.99% 100%

100%

100%

100%

100%

100%

100%

100%

100%

100%

100%

52

Figure 14: Computation time of the GLPK linear solver (red) and the Gurobi linear solver (green) to solve
the uniform/length-weighted edge-loss minimal problems in Algorithm 1. We perform experiments on 90
data sets, 10 for each dimension 2-10, generated from the normal distribution. The horizontal axis is the
dimension of the data set, and the vertical axis is the time it takes to solve an optimization problem. We
observe that the Gurobi solver is consistently faster than the GLPK solver and that computation time seems
fairly constant across dimension.

53

