Amortized Rejection Sampling in
Universal Probabilistic Programming

2
2
0
2

r
a

M
9
2

]

G
L
.
s
c
[

3
v
6
5
0
9
0
.
0
1
9
1
:
v
i
X
r
a

Saeid Naderiparizi1, Adam ´Scibior1, Andreas Munk1, Mehrdad Ghadiri2
Atılım G¨une¸s Baydin3, Bradley Gram-Hansen3, Christian Schroeder de Witt3
Robert Zinkov3, Philip Torr3, Tom Rainforth3, Yee Whye Teh3, Frank Wood1,4,5
1University of British Columbia, 2Georgia Institute of Technology, 3University of Oxford
4MILA, 5CIFAR AI Chair

Abstract

which we discuss at length in this paper, is murkier.

Naive approaches to amortized inference in
probabilistic programs with unbounded loops
can produce estimators with inﬁnite variance.
This is particularly true of importance sam-
pling inference in programs that explicitly in-
clude rejection sampling as part of the user-
programmed generative procedure.
In this
paper we develop a new and eﬃcient amor-
tized importance sampling estimator. We
prove ﬁnite variance of our estimator and em-
pirically demonstrate our method’s correct-
ness and eﬃciency compared to existing al-
ternatives on generative programs containing
rejection sampling loops and discuss how to
implement our method in a generic proba-
bilistic programming framework.

1

INTRODUCTION

It is now understood how to apply probabilistic pro-
gramming inference techniques to generative models
written in “universal” probabilistic programming lan-
guages (PPLs) (van de Meent et al., 2018). While the
expressivity of such languages allows users to write
generative procedures naturally, this ﬂexibility intro-
duces complexities, some of surprising and subtle char-
acter. For instance there is nothing to stop users from
using rejection sampling loops to specify all or part of
their generative model, something that is quite natu-
ral to do and we have seen in practice. While existing
inference approaches may asymptotically produce cor-
rect inference results for such programs, the reality,

Proceedings of the 25th International Conference on Artiﬁ-
cial Intelligence and Statistics (AISTATS) 2022, Valencia,
Spain. PMLR: Volume 151. Copyright 2022 by the au-
thor(s).

The speciﬁc problem we address, that of eﬃcient amor-
tized importance-sampling-based inference in models
with user-deﬁned rejection sampling loops is more
prevalent than it might seem on ﬁrst consideration.
Our experience suggests that rejection sampling within
generative model speciﬁcation is actually the rule
rather than the exception when programmers use uni-
versal languages for model speciﬁcation. To generate
a single draw from anything more complex than stan-
dard distribution eﬀectively requires either adding a
new probabilistic primitive to the language (beyond
most users), hard conditioning on constraint satisfac-
tion (ineﬃcient under most forms of universal PPL
inference), or a user-programmed rejection loop. A
major example of this is sampling from a constrained
distribution, like a truncated normal or a distribution
constrained on a circle. If the model speciﬁcation lan-
guage does not have the primitive for the constrained
distribution we want, the most natural way to generate
such a variate is via user-programmed rejection. More
sophisticated examples abound in simulators used in
the physical sciences (Baydin et al., 2019a,b), chem-
istry (Cai, 2007; Ramaswamy and Sbalzarini, 2010;
Slepoy et al., 2008), and other domains (Stuhlm¨uller
and Goodman, 2014).
Implicit rejection sampling
loops also exist in models containing simulators that
guard against certain conﬁgurations and, in such cases,
must restart after re-sampling the conﬁgurations War-
rington et al. (2020). Note that the issue we address
here is not related to hard rejection via conditioning,
i.e., Ritchie et al. (2015) and related work. Ours is
speciﬁcally about rejection sampling loops within the
generative model program, whereas the latter is about
developing inference engines that are reasonably ef-
ﬁcient even when the user speciﬁed program has a
constraint-like observation that produces an extremely
peaked posterior.

The ﬁrst inference algorithms for languages that al-

 
 
 
 
 
 
Amortized Rejection Sampling in Universal Probabilistic Programming

lowed generative models containing rejection sam-
pling loops to be written revolved around Markov
chain Monte Carlo (MCMC) (Goodman et al., 2008;
Wingate et al., 2011) and sequential importance sam-
pling (SIS) (Wood et al., 2014) using the prior as the
proposal distribution and then mean-ﬁeld variational
inference (Wingate and Weber, 2013). Those methods
were very ineﬃcient, prompting extensions of PPLs
providing programmable inference capabilities (Mans-
inghka et al., 2014; ´Scibior, 2019). Eﬀorts to speed up
inference since then have revolved around amortized
inference (Gershman and Goodman, 2014), where a
slow initial oﬀ-line computation is traded against fast
and accurate test-time inference. Such methods work
by training neural networks that quickly map a dataset
either to a variational posterior (Ritchie et al., 2016)
or to a sequence of proposal distributions for SIS (Le
et al., 2017). This paper examines and builds on the
latter “Inference Compilation” (IC) approach.

Unbounded loops potentially require integrating over
inﬁnitely many latent variables. With IC each of these
variables has its own importance weight and the prod-
uct of all the weights can have inﬁnite variance, result-
ing in an importance sampler with unstable conver-
gence. Furthermore, the associated self-normalizing
importance sampler with any ﬁnite number of samples
can converge to an arbitrary point, giving wrong infer-
ence results without warning. It is therefore necessary
to take extra steps to ensure convergence of the im-
portance sampler resulting from IC when unbounded
loops are present.

In this paper we present a solution to this problem
for the common case of rejection sampling loops. We
establish, both theoretically and empirically, that com-
puting importance weights naively in this situation can
lead to arbitrarily bad posterior estimates. We develop
a novel estimator to remedy this problem. A preview
of the problem and the proposed solution is shown in
Fig. 1.

2 PROBLEM FORMULATION

Our formulation of the problem will be presented con-
cretely starting from the example probabilistic pro-
gram shown in Figure 1a. Even though both the prob-
lem and our solution are more general, applying to all
probabilistic programs with rejection sampling loops
regardless of how complicated they are, this simple ex-
ample captures all the important aspects of the prob-
lem. As a reminder, inference compilation refers to
oﬄine training of importance sampling proposal dis-
tributions for all random variables in a program (Le
et al., 2017). Existing, naive approaches to inference
compilation for the program in Figure 1a correspond

5:

1: x ∼ p(x)
2: w ← p(x)
q(x|y)
3: for k ∈ N+ do
zk ∼ p(z|x)
4:
wk ← p(zk|x)
q(zk|x,y)
w ← wwk
if c(x, zk) then

6:
7:
8:
9:
10: observe(y, p(y|z, x))

z = zk
break

x ∼ q(x|y)
w ← p(x)
q(x|y)
for k ∈ N+ do

zk ∼ q(z|x, y)
wk ← p(zk|x)
q(zk|x,y)
w ← w wk
if c(x, zk) then

z = zk
break

w ← wp(y|z, x)

(a) Original program

(b) Inference compilation

1: x ∼ p(x)
2: w ← p(x)
q(x|y)
3: z ∼ p(z|x, c(x, z))
4: w ← w p(z|x,c(x,z))
q(z|x,y,c(x,z))
5: observe(y, p(y|z, x))

x ∼ q(x|y)
w ← p(x)
q(x|y)
z ∼ q(z|x, y, c(x, z))
w ← w p(z|x,c(x,z))
q(z|x,y,c(x,z))
w ← w p(y|z, x)

(c) Equivalent to above

(d) Our IS estimator

Figure 1: (a) Illustrates the problem we are address-
ing. Existing, naive approaches to inference compila-
tion use trained proposals for the importance sampler
with proposal q shown in (b), where w can have inﬁnite
variance, even when each wk individually has ﬁnite
variance, as k is unbounded. There exists a simpliﬁed
program (c) equivalent to (a) and ideally we would like
to perform inference using the importance sampler in
(d). While this is not directly possible, since we do
not have access to the conditional densities required,
our method approximates this algorithm, without in-
troducing inﬁnite variance.

to the importance sampler shown in Figure 1b where
there is some proposal learned for every random choice
in the program. While the weighted samples produced
by this method result in unbiased estimates, the vari-
ance of the weights can be very high and potentially
inﬁnite due to the unbounded number of wks. To show
this, we start by more precisely deﬁning the meaning
of the sampler in Fig. 1b.

|

Deﬁnition 1 (Naive weighing). Let p(x, y, z) be a
probability density such that all conditional densities
exist. For each y, let q(x, z
y) be a probability density
y) is absolutely continuous with re-
such that p(x, z
|
spect to it. Let c(x, z) be a Boolean condition, and A
be the event that c is satisﬁed such that p(A
(cid:15)
x, y)
(cid:15) for all (x, y) and some (cid:15) > 0. Let
and q(A
|
x, y) and wk = p(zk
y) and let zk i.i.d.
x)
q(x
x
q(z
|
q(zk
x,y)
|
∼
|
N+. Let L = min
, z = zL and
for all k
k
∈
{
x, z) (cid:81)L
wIC = p(x)
k=1 wk.
y) p(y
q(x
|
|

c(x, zk)
}
|

x, y)

∼

≥

≥

|

|

For simplicity, in Deﬁnition 1 and the rest of this paper

Naderiparizi, ´Scibior, Munk, Ghadiri, Baydin, Gram-Hansen, Schroeder de Witt, Zinkov, Torr, Rainforth, Teh, Wood

we let A be the event that c is satisﬁed. We assert that
Deﬁnition 1 corresponds to the program in Fig. 1b.
A rigorous correspondence could be established using
formal semantics methods, such as the construction of
´Scibior et al. (2017), but this is beyond the scope of
this paper. Although, as we prove later in Theorem 3,
the resulting importance sampler correctly targets the
posterior distribution, the variance of wIC is a problem,
and it is this speciﬁc problem that we tackle in this
paper.

to Fig. 1c, where z satisfying the condition c is sam-
pled directly. Fig. 1d presents an importance sampler
targeting 1c, obtained by sampling z directly from q
under the condition c. Note that the sampling pro-
cesses in 1b and 1d are the same, only the weights are
computed diﬀerently. We now provide a deﬁnition for
the weights in 1d.

Deﬁnition 2 (Collapsed weighing). Extending Deﬁ-
nition 1, let

Intuitively, a large number of rejections in the loop
leads to a large number of wk being included in
wIC and the variance of their product tends to grow
quickly.
In the worst case, this variance may be in-
ﬁnite, even when each wk has ﬁnite variance individ-
ually. This happens when the proposed samples are
rejected too often, which is formalized in the following
theorem.
Theorem 1. Under assumptions of Deﬁnition 1, if
the following condition holds with positive probability
under x

q(x

y)

∼

|

E
z

q(z

x,y)
|

∼

(cid:20) p(z
q(z

x)2
x, y)2 (1
|
|

(cid:21)

p(A

x, z))
|

−

≥

1

(1)

then the variance of wIC is inﬁnite.

A proof of this theorem is in Appendix A.1.

Theorem 1 means that importance sampling with pro-
posals other than the prior may hurt more than help
in the case of rejection sampling loops and there is
no trivial way to ensure Eq. (1) does not hold or to
detect if it holds for a particular proposal. Further-
more, under the conditions of Theorem 1, existing IC
schemes are eﬀectively useless in practice, even though
they are still unbiased in principle. Since the cen-
tral limit theorem governs convergence of IS estima-
tors (Geweke, 1989), the convergence rates fail when
the variance of weights is inﬁnite. Consequently, it
leads to a slow to converge and unstable estimator
that may exhibit strong biases with any ﬁnite num-
ber of samples (Robert et al., 1999; Koopman et al.,
2009). Worse still, even when the variance is ﬁnite
but large, it may render the eﬀective sample size too
low for practical applications, a phenomenon we have
observed repeatedly in practice. What remains is to
derive an alternative way to compute wIC that guar-
antees avoiding such problems arising from rejection
sampling loops and in practice leads to larger eﬀective
sample sizes than existing methods.

3 APPROACH

A starting point to the presentation of our algorithm
is to observe that the program in Fig. 1a is equivalent

wC =

p(x)
y)
q(x
|

p(z
q(z
(cid:124)

x, A)
|
x, A, y)
|
(cid:123)(cid:122)
(cid:125)
T

p(y

x, z).
|

(2)

Note that E [wIC] = E [wC], as we prove in Theorem 3.
However, since wC only involves a ﬁxed number (three)
of terms, we can expect it to avoid the aforementioned
problems with exploding variance. Unfortunately, we
can not directly compute wC.

In Eq. (2) we can directly evaluate all terms except T ,
since, p(z
x, A, y) are deﬁned implicitly
|
by the rejection sampling loop. Applying Bayes’ rule
to this term gives the following equality:

x, A) and q(z
|

T =

x, y)
q(A
|
p(A
x)
|
(cid:123)(cid:122)
1

(cid:125)

(cid:124)

p(z
q(z
(cid:124)

x)
|
x, y)
|
(cid:123)(cid:122)
(cid:125)
2

(cid:24)(cid:24)(cid:24)(cid:24)(cid:24)
z, x)
p(A
(cid:24)(cid:24)(cid:24)(cid:24)(cid:24)
|
z, x, y)
q(A
|
(cid:123)(cid:122)
(cid:125)
(cid:124)
3

.

(3)

The term 2 can be directly evaluated, since we have
access to both conditional densities and the term 3 is
always equal to 1, since A only depends on x and z,
and is determined by c(z, x) which is common between
p and q. However, the term 1 , which is the ratio of
acceptance probabilities under q and p, can not be
computed directly and we need to estimate it. We
x, y) and
provide separate unbiased estimators for q(A
|

1
x) .
p(A
|
For q(A
timation of the following expectation:

x, y) we use straightforward Monte Carlo es-
|

(cid:90)

(cid:90)

x, y) =

q(A

|

=

z, x, y)q(z

q(A

|

x, y)dz
|

c(z, x)q(z

x, y)dz
|
x,y) [c(z, x)]
|

= E
z

q(z

∼

(4)

1
x) we use Monte Carlo estimation after apply-
p(A
|

For
ing the following standard lemma:

Lemma 2. Let A be an event that occurs in a trial
with probability p. The expectation of the number of
trials to the ﬁrst occurrence of A is equal to 1
p .

Amortized Rejection Sampling in Universal Probabilistic Programming

1
p(A

It is important that these estimators are constructed
independently of z being sampled to ensure that we ob-
tain an unbiased estimator for wC speciﬁed in Eq. (2).
Also, it is important to note these two values q(A
x, y)
|
x) are state-dependent, they are not only spe-
and
|
ciﬁc to a rejection sampling loop, but also depend
on the state of the program when entering the loop.
We put together all these elements to obtain our ﬁ-
nal method in Algorithm 1. More formally, the weight
obtained by our method is deﬁned as follows.

q(z

i.i.d.
∼

x, y) for i
|

Deﬁnition 3 (Our weighting). Extending Deﬁni-
tion 1, let z(cid:48)i
1, . . . , N and K
be the number of z(cid:48)i for which c(x, z(cid:48)i) holds. Let
z(cid:48)(cid:48)j = (z(cid:48)(cid:48)j,1, . . . , z(cid:48)(cid:48)j,Tj
) be sequences of potentially vary-
ing length for j
x) such
1, . . . , M with z(cid:48)(cid:48)j,l
|
that for all j, Tj is the smallest index l for which
c(x, z(cid:48)(cid:48)j,l) holds. Let T = 1
M

j=1 Tj. Finally, let

i.i.d.
∼

(cid:80)M

p(z

∈

∈

wARS =

p(x)
y)
q(x
|

KT
N

p(z
q(z

x)
|
x, y)
|

x, z).

p(y

|

(5)

Throughout this section we have only informally ar-
gued that the three importance samplers presented
target the same distribution. With all the deﬁnitions
in place we can make this argument precise in the fol-
lowing theorem.

Theorem 3. For any N
values of (x, y, z),

≥

1 and M

≥

1, and all

E [wIC|

x, y, z] = wC = E [wARS|
Proof. For the second equality, use Eq. (4), then
Lemma 2, Eq. (3), and ﬁnally Eq. (2).

x, y, z] .

(6)

x, y, z]

E [wARS|
p(x)
q(x
y)
|
p(x)
q(x
y)
|
p(x)
y)
q(x

=

=

=

|

p(y

x)
p(z
|
x, y)
q(z
|
p(z
x)
|
x, y)
q(z
|
x, A)
p(z
|
x, A, y)
q(z
|

p(y

x, z)

1
N

Ez(cid:48) [K] Ez(cid:48)(cid:48) [T ]

x, z)q(A

x, y)

|

1
p(A

|

x)

|

|

p(y

x, z) = wC
|

(7)

(8)

(9)

(10)

For the ﬁrst equality, use Eq. (21) in Appendix A.1 to
get

x, y, z]

E [wIC|
p(x)
y)
q(x

|
p(x)
y)
q(x

|

=

=

|

|

p(y

x, z) wL E

z1:L

1

−

(cid:34)L

1
(cid:89)
−

(cid:35)

wk

k=1

(11)

(12)

p(y

x, z)

p(z
q(z

x)
|
x, y)
|

x, y)
q(A
|
x)
p(A

|

= wC

(13)

Algorithm 1 Pseudocode for our algorithm applied
to the probabilistic program from Fig. 1a.

q(x

y)
|
p(x)
y)
q(x
|
N+ do
q(z

1: x
∼
2: w
←
3: for k
∈
zk
x, y)
4:
∼
|
if c(x, zk) then
5:
z = zk
6:
break
7:
w p(z
x)
8: w
|
x,y)
q(z
|

←

0

9: K
←
10: for i
∈
z(cid:48)i ←
11:
K
12:
←

1, . . . N do

x, y)
q(z
K + c(z, x)

|

Estimate q(A

x, y)

using Eq. (4)

|

13: for j
14:
15:
16:
17:
18:
19: T

1, . . . M do
∈
N+ do
for l
∈
z(cid:48)(cid:48)j,l ←
q(z
|
if c(x, z(cid:48)(cid:48)j,l) then
l
Tj ←
break
j=1 Tj

x, y)

(cid:80)M

1
M
w KT
N
w p(y

←

20: w
21: w

←
←

z, x)
|

1
Estimate
x)
p(A
|
using Lemma 2

Since all three importance samplers use the same pro-
posal distributions for (x, z), Theorem 3 shows that
they all target the same distribution, which is the pos-
terior distribution speciﬁed by the original probabilis-
tic program in Fig. 1a.

Finally, we can prove that our method handles infer-
ence in rejection sampling loops without introducing
inﬁnite variance. Note that variance may still be in-
ﬁnite for reasons not having to do with the rejection
x, y) are poorly cho-
y) and q(z
sampling loop, if q(x
|
sen.
Theorem 4. If wC from Deﬁnition 2 has ﬁnite vari-
ance, then wARS from Deﬁnition 3 has ﬁnite variance,
1.
for any N

1 and M

|

≥

≥

Proof. Note that conditionally on (x, y, z), K follows
a binomial distribution. Therefore, Var[ K
x, y, z] <
N |
. Then, note that conditionally on (x, y, z), Tjs
1 <
are independent of each other and follow a geometric
distribution. Therefore,

∞

Var[Tj|

x, y, z] =

Var[T

x, y, z] <
|

⇒

1
p(A

x)2

1

p(A
x)
x)2 <
|
|
1
(cid:15)2 <
x)2 <

−
p(A
1
p(A

|
.

∞

|

Also, conditionally on (x, y, z), K

N and T are inde-

Naderiparizi, ´Scibior, Munk, Ghadiri, Baydin, Gram-Hansen, Schroeder de Witt, Zinkov, Torr, Rainforth, Teh, Wood

pendent, so Var[ KT
N |
x)
B <
. Then see that wARS = wC
|
x,y)
|
nally, using the law of total variance, we get

x, y, z] < B for some constant
KT
N . Fi-

p(A
q(A

∞

Var[wARS] = E [Var[wARS|
+ Var[E [wARS|
(cid:19)2
p(A
Var
q(A

= E

(cid:34)(cid:18)

wC

x)
|
x, y)
|

x, y, z]]

x, y, z]]
(cid:20) KT
N

(cid:12)
(cid:12)
(cid:12)
(cid:12)

x, y, z

+ Var[wC]

(cid:20)
w2
C

E

(cid:21)

1
(cid:15)2 B

≤

+ Var[wC] <

∞

(cid:21)(cid:35)

(15)

(16)

Training proposals Our method does not concern
training the IC network. It is mainly about computing
sample weights once the network is trained. However,
an important assumption made in our method is the
x, y) is used in all iterations of a
same proposal q(z
|
rejection sampling loop. Therefore, it should be re-
ﬂected in the training process in IC as well. We follow
the approach proposed in Baydin et al. (2019a) which
discards the rejected samples at training time and only
uses the sample values that conclude the loop for train-
ing. As a result, the training samples for z are from
p(z
x, A), which means, the distribution of training
|
data obtained from the programs in Figs. 1a and 1c
are identical. We provide more details and a discus-
sion on training proposals in Appendix B.

4 EXPERIMENTS

We illustrate our method by performing inference in
three example probabilistic programs that include re-
jection sampling loops.
In each program the latent
variables are identiﬁed via sample statements. The in-
ferred posterior distribution is conditioned on observed
values, identiﬁed via observe statements. Two of our
experiments are designed so that ground truth infer-
ence results can be derived analytically.

We evaluate the eﬃcacy of our approach in several
ways including (I) computing the eﬀective sample size
(ESS) of IS estimators, (II) empirically comparing the
convergence rates of diﬀerent methods to ground truth
values, and (III) reporting the number of samples re-
quired to ensure convergence of the IS estimators. We
adopt a convergence test proposed by Chatterjee and
Diaconis (2018) and report the sample size required
for IS estimators, Kconverge. Formally, deﬁne

where wk is deﬁned as in Deﬁnition 1. According to
this convergence test, an IS estimate with K samples
is converged if E [QK] < (cid:15), for a predeﬁned (cid:15). Finally,
Kconverge is the smallest value for which the IS estima-
tor is converged.

(14)

The speciﬁc methods we compare are:

• Naive (IC): Like the approach in Fig. 1b this uses
a proposal for all iterations of rejection sampling
loops. Final importance weights are computed by
multiplying all the weights for all samples in the
trace, accepted and rejected.

• Amortized Rejection Sampling (ARSM =m): This
is our method (Algorithm 1) with M = m and
N = max(m, 10) as deﬁned in Deﬁnition 3, not
multiplying in the weights of any rejected samples
on the trace.

• Ablated (Biased): Implements the incorrect vari-
ant of ARS that does not estimate nor multiple in
x,y)
the correction factor q(A
x) . This is only shown
|
p(A
|
to see the eﬀect of correction factors in terms of
convergence speed and estimation bias.

Note that the variance and convergence of our method
depends primarily on the probabilities of rejection in
the model and proposal, and not on other features of
the rejection sampler. Therefore, our experimental re-
sults do not change signiﬁcantly for more complex pro-
grams.

4.1 Marsaglia

Marsaglia polar method (Marsaglia and Bray, 1964)
is a pseudo-random number sampling method for gen-
erating samples from a Normal distribution. It sam-
ples a point (a, b) uniformly from a unit circle and

(cid:113)

−

2 log(a2+b2)
a2+b2

and

applies change of variables x1 = a

(cid:113)

2 log(a2+b2)
a2+b2

−

. Then, x1 and x2 are two in-
x2 = b
dependent samples distributed as
(0, 1). The most
straight-forward way of sampling from a circle is by
sampling from a square and rejecting the sample if it
lies outside the circle. This is a common use case of
rejection sampling, to sample from a constrained prob-
ability space.

N

We implement a Gaussian with unknown mean model
with two observations y1 and y2. The generative
(µ, σ2)
(µ0, σ2
process is deﬁned as µ
µ
0), yi|
∼ N
(µ0, σ2
0) is implemented by the
where sampling from
Marsaglia polar method. Program 6 in Appendix D.1
shows the implementation of this model.

∼ N

N

QK :=

K wk

max1

k
≤
≤
(cid:80)K
k=1 wk

,

(17)

We train an LSTM-based inference compilation net-
work on this model to learn proposals and use them

Amortized Rejection Sampling in Universal Probabilistic Programming

Figure 2: (Top) results of Marsaglia and (bottom) Mini-SHERPA experiments. In both experiments we estimate
marginal likelihood of an observation. Left plots show how diﬀerent methods converge to the ground truth
marginal likelihood. Middle plots show the (normalized) ESS for each method. Right plots are box plots of the
required number of samples to ensure convergence. In these box plots green dashed and orange solid lines show
the mean and median, respectively. Our method with any M converges to ground truth with lower variance
compared to IC. As expected, larger M leads to faster convergence, lower variance, and higher ESS. See Fig. 11
in Appendix E for a summary of ﬁnal values reached in these plots.

in a SIS engine to estimate the marginal likelihood
p(y1, y2) for diﬀerent observations. Top row of Fig. 2
(left) shows the estimation error between the marginal
likelihood p(y1, y2) and its SIS estimation ˆp(y1, y2) =
(cid:80)K
k=1 wk. The ﬁgure shows an aggregation of 100
runs of the experiment. Estimates by our method al-
ways converge to the true marginal likelihood with any
M > 0. Further, larger M leads to faster convergence
and higher ESS. On the other hand, the ﬁgure shows
that IC fails to converge after 100,000 draws.
It is
worth mentioning that not for all observations IC fails
to converge and/or has low ESS. The main problem is
whether this happens is not identiﬁable in practice.

4.2 Mini-SHERPA

Mini-SHERPA is an event generator of a simpliﬁed
model of high-energy reactions of particles. Its nam-
ing comes from SHERPA (Gleisberg et al., 2009), the
state-of-the-art simulator of high-energy reactions of
particles. SHERPA has up to thousands of latent vari-
ables and widely uses rejection sampling loops which
is a major source of diﬃculty in inference in this model
(Baydin et al., 2019a,b). Mini-SHERPA, however, has
up to 11 latent variables (excluding variables rejected
in rejection sampling loops) and up to two rejection

sampling loops. In its simulation process, depicted in
Fig. 3, it samples a 3-dimensional momentum for a
starting particle, samples a type of decay (known as
“decay channel”), then samples momentum of each of
the resulting particles. At the end of the simulation, it
produces a noisy measurement of the energy deposited
by the resulting particles on the 2-dimensional surface
of a detector as the observation. An example observa-
tion is shown on the right side of Fig. 3. We provide
more details including a pseudocode of the simulator
in Appendix D.1.

We train an LSTM-based inference compilation net-
work on this model to learn proposals. We then use
the learned proposals in a SIS engine to estimate the
marginal likelihood of a given observation p(y). The
ground truth value of marginal likelihood is estimated
by importance sampling with prior as proposal for the
variables inside rejection sampling loops. Since sam-
pling from prior is suboptimal, we draw more than 12
million samples to estimate the ground truth value.
The results of this experiment are shown in bottom
row of Fig. 2. Similar to the previous experiment, ARS
with any M > 0 converges to the ground truth value
while larger values of M generally lead to higher ESS
and faster convergence. IC performs poorly in this ex-
periment and fails to converge after 100,000 samples.

0255075100Numberofdraws(N)×103−103.82−103.80−103.78−103.76logˆp(y)0255075100Numberofdraws(N)×1030.70.80.9ESS/NARSM=1ARSM=2ARSM=10Biased246Kconverge×102ICARSM=1ARSM=2ARSM=10BiasedGroundtruth0255075100×103−10−1−10−2010−210−1ˆp(y)−p(y)0255075100×1030.00.10.2ESS/NARSM=1ARSM=2ARSM=10Biased23Kconverge×104ARSM=1ARSM=2ARSM=10ICBiased0255075100Numberofdraws(N)×103−103.82−103.80−103.78−103.76logˆp(y)0255075100Numberofdraws(N)×1030.70.80.9ESS/NARSM=1ARSM=2ARSM=10Biased246Kconverge×102ICARSM=1ARSM=2ARSM=10BiasedGroundtruthNaderiparizi, ´Scibior, Munk, Ghadiri, Baydin, Gram-Hansen, Schroeder de Witt, Zinkov, Torr, Rainforth, Teh, Wood

Figure 3: An example of the simulation process in the
Mini-SHERPA experiment.
(Left) shows its simula-
tion process schematically. It shows decay of a start-
ing particle into three new particles. Each of the red,
blue and green lines show the trajectory of a result-
ing particle. The 2D grid on top shows the measured
energy deposited by the particles. (Right) shows the
observation in this model which is a noisy version of
the energy grid.

We provide additional results with other observations
in the appendix.

In all experiments, as expected, the Biased method
does not converge to the correct value, but it usu-
ally has high ESS. This is potentially misleading as
the samples do not have the extra weight variance in-
troduced by Monte Carlo estimate of the correction
factors for rejection sampling loops.

4.3 Beta-Bernoulli

In our last experiment, we focus on comparing ARS
with a baseline proposed by Baydin et al. (2019a),
which we term “Prior”. This baseline uses the prior
as proposal for the variables within rejection sampling
loops, ignoring the learned proposal. This approach
sidesteps the need for correction factors because they
are simply equal to 1.

Intuitively, because “Prior” does not involve the ad-
ditional Monte-Carlo estimation that ARS introduces,
it should have lower variance. On the other hand, if
the prior is far from the true posterior, the estima-
tor will have high variance. Hence, depending on the
model and observations, “Prior” might be better or
worse than ARS. To investigate this in practice, we
implement a Beta-Bernoulli experiment,

Beta(α, β)

x

∼

yi ∼

Bernoulli(x) for 1

i

≤

≤

n.

However, we explicitly implement sampling from the
Beta prior by repeatedly sampling from a Uniform dis-
tribution and accepting based on the ratio of the Beta

Figure 4: Results of the Beta-Bernoulli experiment. In
this plot, Kconverge is the required number of samples
to ensure convergence and n is the model’s parame-
ter. As n grows, the diﬀerence between the prior and
the true posterior increases, deteriorating performance
of the “Prior” approach. Our method, even with a
very limited budget to estimate the correction factors,
quickly outperforms “Prior”. The missing points of
the lines means fails to converge after 10,000 samples.

Program 1: Beta-Bernoulli

while True:
rs start ()

x = sample( Uniform (0, 1))
u = sample( Uniform (0, 1))
if c(x,u):

rs end()
break
for i in range(n):

observe( Bernoulli (x), y[i])

and Uniform distributions. Program 1 shows an im-
plementation of the model. Further details, such as
the exact form of the acceptance function, is provided
in the appendix.

This model is parametrized by the prior parameters
α, β and the number of observations n. We control the
rejection rate by changing α, β and the closeness of the
prior and posterior by changing n. In our experiments
yi = True for all i.

In this experiment, we do not train the proposals. In-
stead, since the posterior distributions are tractable,
we analytically derive the distributions that optimize
inference compilation’s objective (that is, the posterior
distributions in the “collapsed” Beta-Bernoulli pro-
gram) and manually choose the proposals accordingly.
See the appendix for more details.

In Fig. 4 we report Kconverge, the smallest value of K
for which the estimator passes the convergence test.

051015202530n0500010000KconvergeICARSM=1ARSM=10PriorAmortized Rejection Sampling in Universal Probabilistic Programming

This plot demonstrates that depending on the program
and the observations we solve inference for, the “Prior”
approach may perform better or worse than ARS. Im-
portantly where the true posterior is far from the prior
(when n is large), the “Prior” approach quickly fails
to converge in less than 10,000 draws. Note that
ARSM =1 converges quickly even with a very limited
budget to estimate the correction factors. ARS con-
verges faster with larger values of M while IC fails to
converge most of the time.

5 IMPLEMENTATION

In the previous sections we have presented and exper-
imentally validated our method on a few programs.
Our method applies much more broadly, in fact to all
probabilistic programs with arbitrary stochastic con-
trol ﬂow structures and any number of rejection sam-
pling loops. This includes nesting such loops to ar-
bitrary degree. The only constraint is that observa-
tions can not be placed inside the loops, i.e., no con-
ditioning inside rejection sampling loops. We conjec-
ture that our method produces correct weights for all
probabilistic programs satisfying this constraint, but
proving that is beyond the scope of this paper and
would require employing sophisticated machinery for
constructing formal semantics, such as developed by
´Scibior et al. (2017). Nonetheless, we provide a brief
proof sketch in Appendix A.2.

To enable practitioners to use our method in its full
generality we have implemented it in PyProb1 (Le
et al., 2017), a universal probabilistic programming
library written in Python. The particulars of such a
general purpose implementation pose several diﬃcult
but interesting problems, including identifying rejec-
tion sampling loops in the original program, addressing
particular rejection sampling loops, and engineering
solutions that allow acceptance probabilities bespoke
to each loop to be estimated by repeatedly executing
the loops with diﬀerent proposal distributions. In this
section we describe some of these challenges and dis-
cuss our initial approach to solving them.

The ﬁrst challenge is identifying rejection sampling
loops in the probabilistic program itself. One mecha-
nism for doing this is to introduce a rejection sampling
primitive, macro, or syntactic sugar into the proba-
bilistic programming language itself whose arguments
are two functions: the acceptance function and the
body of the rejection sampling loop. While this may
be feasible, our approach lies in a diﬀerent part of the
design space, given our choice to implement in PyProb
and its applicability to performing inference in exist-
ing stochastic simulators. In this setting there are two

1https://github.com/pyprob/pyprob

Program 2: Original

Program 3: Annotated

x = sample( P x )
while True:

x = sample( P x )
while True:

z = sample( P z (x))

if c(x, z):

break

rs start ()
z = sample( P z (x))

if c(x, z):
rs end()
break

observe( P y (x,z), y)
return x, z

observe( P y (x,z), y)
return x, z

Figure 5: An illustration of annotations required by
our system. To apply our method we only require that
entry and exit to each rejection sampling loop be an-
notated with rs start and rs end respectively. Our im-
plementation then automatically handles the whole in-
ference process, even if the annotated loops are nested.

other design choices: some kind of static analyzer that
automates the labelling of rejection sampling loops by
looking for rejection sampling motifs in the program
(unclear how to accomplish this in a reliable and gen-
eral way) or providing the probabilistic programmer
functions that need to be carefully inserted into the
existing probabilistic program to demarcate where re-
jection sampling loops start and end.

In the
We chose the latter approach in this paper.
programs in Section 4 we silently introduced the func-
tions rs start and rs end to tag the beginning and end
of rejection sampling loops. These functions are used
to inform an inference engine about the scope of each
rejection sampling loop, in particular so that all sample
statements in between calls to rs start and rs end can
be tracked. Fig. 5 illustrates where these primitives
have to be inserted in probabilistic programs with re-
jection loops to invoke our ARS techniques.

The speciﬁc implementation details are infeasible to
cover thoroughly and requires substantial review of
PyProb internals. However, the key functionality en-
abled by these tags includes two critical things: (I) we
need to be able to execute additional iterations of ev-
ery rejection sampling loop in the program to compute
x,y)
our estimator of q(A
x) . For every rs start we have to
|
p(A
|
be able to continue the program multiple times, exe-
cuting the rejection loop both proposing from p and q,
terminating the continuation once the matching rs end
is reached. Eﬃcient implementations of this make use
of the same forking ideas that made “probabilistic C”
possible (Paige and Wood, 2014). (II) We have to be
able to identify rejection sampler start and end pairs
and design a special addressing scheme for the sam-
ples in rejection sampling loops such that the rejected

Naderiparizi, ´Scibior, Munk, Ghadiri, Baydin, Gram-Hansen, Schroeder de Witt, Zinkov, Torr, Rainforth, Teh, Wood

samples are replaced by the latter accepted ones.

Our PyProb implementation2 addresses all of these is-
sues. We provide more details on our implementation
in Appendix C.

Our work makes it so that eﬃcient, amortized infer-
ence engines work for probabilistic programs that users
actually write and in so doing removes a major impedi-
ment to the uptake of universal probabilistic program-
ming systems in general.

6 DISCUSSION

Acknowledgements

We have addressed an issue in amortized importance-
sampling-based inference for universal probabilistic
programming languages. We have demonstrated that
even simple rejection sampling loops can cause ma-
jor problems for existing probabilistic programming
inference algorithms. Particularly, we showed empir-
ically and theoretically that SIS can perform poorly
in presence of rejection sampling loops, even in simple
models with only a few rejection sampling loops. Our
proposed method is an unbiased estimator, often with
lower variance than naive SIS estimators.

Although our method has a new source of variance,
that of additional Monte Carlo estimators which can
make its variance higher than naive SIS in some cases,
we have proved it is guaranteed to always only add a
ﬁnite variance to the estimates. The absence of this
guarantee is a major shortcoming of naive SIS meth-
ods, as there is no easy way of predicting if they will
have inﬁnite variance. As a result, incorrect estimates
can be made without warning. Therefore, they cannot
be used safely when a program that contains rejection
sampling loops.

The cost of taking our approach is somewhat subtle
but involves needing to estimate the exit probabilities
of all rejections sampling loops in the program under
both the prior and the proposal. At inference time,
once a rejection sampling loop is encountered, the in-
ference engine must “pause” and estimate them on the
ﬂy. This can be slow and increase the implementation
complexity of the probabilistic programming system.
However, using forking and multiprocessing capabil-
ities avoids the time overhead of our method as the
correction factor estimates are made in parallel with
the main inference engine.

However, this ﬁx of amortized importance-sampling-
based inference for universal probabilistic program-
ming systems is signiﬁcant, particularly as it pertains
to uptake of this kind of probabilistic programming
system. Currently, users of such systems who use re-
jection sampling in their generative models may expe-
rience the probabilistic programming system as con-
fusingly not working. This will be due to potentially
non-convergent non-diagnosable behavior we elabo-
rated on, which in turn leads to poor sample eﬃciency.

2https://github.com/plai-group/

amortized-rejection-sampling

We thank Lukas Heinrich for providing the imple-
mentation of the Mini-SHERPA simulator and helping
with its experiment in this paper. We acknowledge the
support of the Natural Sciences and Engineering Re-
search Council of Canada (NSERC), the Canada CI-
FAR AI Chairs Program, and the Intel Parallel Com-
puting Centers program. Additional support was pro-
vided by UBC’s Composites Research Network (CRN),
and Data Science Institute (DSI). Bradley Gram-
Hansen is supported by the EPSRC Autonomous
Intelligent Systems and Machines grant. Christian
Schroeder de Witt is generously supported by the
Cooperative AI Foundation. This research was en-
abled in part by technical support and computational
resources provided by WestGrid (www.westgrid.ca),
Compute Canada (www.computecanada.ca), and Ad-
vanced Research Computing at the University of
British Columbia (arc.ubc.ca).

References

Baydin, A. G., Heinrich, L., Bhimji, W., Gram-
Hansen, B., Louppe, G., Shao, L., Cranmer, K.,
Wood, F., et al. (2019a). Eﬃcient probabilistic in-
ference in the quest for physics beyond the standard
model. In Thirty-second Conference on Neural In-
formation Processing Systems (NeurIPS).

Baydin, A. G., Shao, L., Bhimji, W., Heinrich, L.,
Meadows, L., Liu, J., Munk, A., Naderiparizi, S.,
Gram-Hansen, B., Louppe, G., et al. (2019b). Eta-
lumis: Bringing probabilistic programming to scien-
tiﬁc simulators at scale. In the International Confer-
ence for High Performance Computing, Networking,
Storage and Analysis (SC ’19).

Cai, X. (2007). Exact stochastic simulation of cou-
pled chemical reactions with delays. The Journal of
chemical physics, 126(12):124108.

Chatterjee, S. and Diaconis, P. (2018). The sample
size required in importance sampling. The Annals
of Applied Probability, 28(2):1099–1135.

Gershman, S. and Goodman, N. (2014). Amortized
inference in probabilistic reasoning. In Proceedings
of the Annual Meeting of the Cognitive Science So-
ciety, volume 36.

Geweke, J. (1989). Bayesian inference in economet-
ric models using monte carlo integration. Econo-

Amortized Rejection Sampling in Universal Probabilistic Programming

metrica: Journal of the Econometric Society, pages
1317–1339.

Gleisberg, T., H¨oche, S., Krauss, F., Sch¨onherr, M.,
Schumann, S., Siegert, F., and Winter, J. (2009).
Event generation with sherpa 1.1. Journal of High
Energy Physics, 2009(02):007.

Goodman, N. D., Mansinghka, V. K., Roy, D.,
Bonawitz, K., and Tenenbaum, J. B.
(2008).
Church: A language for generative models. Pro-
ceedings of the 24th Conference on Uncertainty in
Artiﬁcial Intelligence, Uai 2008, pages 220–229.

Kingma, D. P. and Ba, J. (2014).

Adam: A
method for stochastic optimization. arXiv preprint
arXiv:1412.6980.

Koopman, S. J., Shephard, N., and Creal, D. (2009).
Testing the assumptions behind importance sam-
pling. Journal of Econometrics, 149(1):2–11.

Le, T. A., Baydin, A. G., and Wood, F. (2017). In-
ference compilation and universal probabilistic pro-
gramming. In Proceedings of the 20th International
Conference on Artiﬁcial Intelligence and Statistics,
volume 54 of Proceedings of Machine Learning Re-
search, pages 1338–1348, Fort Lauderdale, FL, USA.
PMLR.

Mansinghka, V., Selsam, D., and Perov, Y. (2014).
Venture: a higher-order probabilistic programming
arXiv
platform with programmable inference.
preprint arXiv:1404.0099.

Marsaglia, G. and Bray, T. A. (1964). A convenient
method for generating normal variables. SIAM re-
view, 6(3):260–264.

Paige, B. and Wood, F. (2014). A compilation target
In Pro-
for probabilistic programming languages.
ceedings of the 31st international conference on Ma-
chine learning, volume 32, pages 1935–1943.

Ramaswamy, R. and Sbalzarini, I. F. (2010). A partial-
propensity variant of
the composition-rejection
stochastic simulation algorithm for chemical reac-
tion networks. The Journal of chemical physics,
132(4):044102.

Ritchie, D., Horsfall, P., and Goodman, N. D. (2016).
Deep amortized inference for probabilistic programs.
arXiv preprint arXiv:1610.05735.

Ritchie, D., Mildenhall, B., Goodman, N. D., and
Hanrahan, P. (2015). Controlling procedural mod-
eling programs with stochastically-ordered sequen-
tial Monte Carlo. ACM Transactions on Graphics
(TOG), 34(4):105.

Robert, C. P., Casella, G., and Casella, G. (1999).
Monte Carlo statistical methods, volume 2. Springer.
´Scibior, A., Kammar, O., V´ak´ar, M., Staton, S., Yang,
H., Cai, Y., Ostermann, K., Moss, S. K., Heunen,
C., and Ghahramani, Z. (2017). Denotational val-
idation of higher-order bayesian inference. Pro-
ceedings of the ACM on Programming Languages,
2(POPL):60.

´Scibior, A. M. (2019). Formally justiﬁed and modular
Bayesian inference for probabilistic programs. PhD
thesis, University of Cambridge.

Slepoy, A., Thompson, A. P., and Plimpton, S. J.
(2008). A constant-time kinetic monte carlo al-
gorithm for simulation of large biochemical reac-
tion networks. The journal of chemical physics,
128(20):05B618.

Stuhlm¨uller, A. and Goodman, N. D. (2014). Reason-
ing about reasoning by nested conditioning: Mod-
eling theory of mind with probabilistic programs.
Cognitive Systems Research, 28:80–99.

van de Meent, J.-W., Paige, B., Yang, H., and Wood,
F. (2018). An introduction to probabilistic program-
ming. arXiv preprint.

Warrington, A., Naderiparizi, S., and Wood, F. (2020).
Coping with simulators that don’t always return.
In The 23rd International Conference on Artiﬁcial
Intelligence and Statistics (AISTATS).

Wingate, D., Stuhlm¨uller, A., and Goodman, N. D.
(2011).
Lightweight implementations of proba-
bilistic programming languages via transformational
compilation. Journal of Machine Learning Research,
15:770–778.

Wingate, D. and Weber, T. (2013). Automated varia-
tional inference in probabilistic programming. arXiv
preprint arXiv:1301.1299.

Wood, F., Meent, J. W., and Mansinghka, V. (2014).
A new approach to probabilistic programming infer-
ence. In Artiﬁcial Intelligence and Statistics, pages
1024–1032.

Supplementary Material:
Amortized Rejection Sampling in
Universal Probabilistic Programming

A PROOFS

A.1 Proof of Theorem 1

Theorem 1. Under assumptions of Deﬁnition 1, if the following condition holds with positive probability under
x

y)

q(x
|

∼

E
z

q(z

x,y)
|

∼

(cid:20) p(z
q(z

x)2
x, y)2 (1
|
|

(cid:21)

p(A

x, z))
|

−

1

≥

(1)

then the variance of wIC is inﬁnite.

Proof. In this proof, we carry the assumptions and deﬁnitions from Deﬁnition 1, with the exception that we use
subscript for denoting weights and samples in iterations of the loop i.e., zk

zk and wk

wk.

→

→

(cid:105)

(cid:104)(cid:81)L

1
k=1 wk
−

We ﬁrst compute the variance of the rejected sample weights. As a reminder, L is a random variable denoting
1 were rejected while the Lth iteration
the number of iterations until acceptance, hence all the iterations until L
−
is accepted. Let Eq
denote the mean value of the product of all the weights corresponding to the
rejected samples when sampling from the proposal q, and deﬁne Eq
A stands for the event of the condition c being satisﬁed (acceptance in an iteration of the rejection sampling
loop) and A stands for the event of c not being satisﬁed. As stated before, we are computing the variance of the
(cid:104)(cid:81)L
rejected sample weights which is Eq

. We start with the second term.

similarly. As another reminder,

1
k=1 w2
−
k

(cid:104)(cid:81)L

(cid:104)(cid:81)L

Eq

(cid:105)

(cid:105)

(cid:105)

1
k=1 w2
−
k

1
k=1 wk
−

−

Eq

(cid:34)L

1
(cid:89)
−

k=1

(cid:35)

wk

=

=

∞(cid:88)

l=1

∞(cid:88)

l=1

P[L = l]

l
1
(cid:89)
−

k=1

E

q(z

zk∼

A(cid:3) =

(cid:2)wk|

x,y)
|

∞(cid:88)

l=1

P[L = l]

l
1
(cid:89)
−

k=1

E
z

q(z

∼

x,y)
|

(cid:2)w

A(cid:3)
|

x, y)q(A

q(A

|

x, y)l

1

−

|

l
1
(cid:89)
−

k=1

E
z

q(z

|

∼

x,y)

(cid:2)w

A(cid:3)
|

(18)

(19)

The ﬁrst equality in Eq. (18) comes from the fact that L = l means the rejection sampling loop was iterated l
times to get the ﬁrst accepted sample and it implies that for all 1
1, zk is rejected. Hence, the inner
expectation is conditioned on A. Moreover, since the zk samples are independent given x and y, the expectation
commutes with the product. The second equality comes from the independence of zk samples too.
Now we expand the last term in Eq. (19) i.e., E
z

(cid:2)w

−

≤

≤

q(z

k

l

(cid:20) p(z
q(z

z

∼

q(z

q(z

E
z

(cid:2)w

x,y)
|

A(cid:3) = E
|

x)
|
x, y)
|
In the ﬁrst equality in Eq. (20), w = p(z
x)
x,y) and the other term accounts for conditioning on A. In the second
|
q(z
|
is the space of
equality, we have assumed q(z
possible values for z,3

x, y) is a valid importance sampling proposal for p(z
|

c(x, z)
x, y)
|

x) i.e., if
|

1
x, y)
|

x)
|
x, y)
|

p(A
q(A

1
−
q(A

c(x, z)] =

x) [1
|

x,y)
|

(20)

q(A

E
z

−

=

p(z

Z

∼

∼

3Although in all of our experiments this assumption holds, it might not be true depending on the training scheme.

Refer to Appendix B.1 for a more detailed discussion.

z
∀

∈ Z

: p(z

x) > 0
|

⇒

q(z

x, y) > 0
|

A(cid:3),
|

∼

x,y)
|

(cid:21)

Amortized Rejection Sampling in Universal Probabilistic Programming

Therefore, substituting Equation 20 into 19,

Eq

(cid:34)L

1
(cid:89)
−

k=1

(cid:35)

wk

= q(A

x, y)

|

∞(cid:88)

k=1

p(A

|

x)k

1 =

−

q(A
|
p(A

x, y)
x)
|

Next, we compute the expected value of squared of weights. It can be derived similar to Eqs. (18) and (19)

Eq

(cid:34)L

1
(cid:89)
−

k=1

(cid:35)

w2
k

=

∞(cid:88)

l=1

q(A

|

x, y)q(A

x, y)l

−

1

|

l
1
(cid:89)
−

k=1

E
z

q(z

x,y)
|

∼

(cid:2)w2

A(cid:3)
|

We now expand the last term in Eq. (22) and, similar to Eq. (20), get the following,

E
z

q(z

x,y)
|

∼

(cid:2)w2

A(cid:3) = E
|

z

q(z

∼

x,y)
|

|
For notational simplicity, deﬁne Sp,q = E
z

(cid:20) p(z
q(z

x)2
|
x, y)2

1
−
q(A

(cid:21)

=

E
z

1
x, y)
|

q(A

q(z

x,y)
|

∼

(cid:20) p(z
q(z

x)2
x, y)2 p(A
|
|

(cid:21)

x, z)
|

c(x, z)
x, y)
|
(cid:104) p(z
q(z

|

q(z

x,y)
|

∼

x)2
x,y)2 p(A
|

(cid:105)
. Hence,

x, z)
|

(cid:34)L

1
(cid:89)
−

(cid:35)

w2
k

Eq

k=1

= q(A

x, y)

|

∞(cid:88)

l=1

(Sp,q)l

−

1

Finally, according to Eqs. (21) and (24) the variance of the rejected sample weights is equal to

Eq

(cid:34)L

1
(cid:89)
−

k=1

(cid:35)

w2
k

Eq

−

(cid:34)L

1
(cid:89)
−

k=1

(cid:35)

wk

= q(A

x, y)

|

∞(cid:88)

l=1

(Sp,q)l

−

1

−

q(A
|
p(A

x, y)
x)

|

(21)

(22)

(23)

(24)

(25)

x, y) (cid:80)∞l=1(Sp,q)l
Since the second term in p(A
x,y)
x) and in Eq. (25) is ﬁnite, if q(A
|
−
p(A
|
|
the rejected weights will be inﬁnite. Additionally, since Sp,q is independent of q(A
of (cid:80)∞l=1(Sp,q)l

1.

−

1 is not ﬁnite, the variance of
x, y), it reduces to ﬁniteness
|

if Sp,q ≥

1

⇒

∞(cid:88)

(Sp,q)l

1 is inﬁnite

−

l=1

V ar

⇒

i=1

(cid:32)k

1
(cid:89)
−

(cid:33)

wi

is inﬁnite

(26)

Noting that if the variance of the weights of a subset of samples (the rejected samples in this case) is inﬁnite,
the variance of the whole weights would be inﬁnite, completes the proof.

Note that even though our proof was presented on the example program in Fig. 1a, it is not limited to it. In
general, in a program that contains multiple (even nested) rejection sampling loops, if the inequality in Eq. (1)
holds for any of its rejection sampling loops, it makes the variance of the IC weights inﬁnite.

A.2 Proof sketch of ARS providing correct weights for more complex programs

There are many ways to do it, but one would be to follow denotational semantics (´Scibior et al., 2017), which
identiﬁes probabilistic programs with functions from inputs to unnormalized measures on the outputs. This
semantics is compositional, so showing that two programs denote the same measure implies full contextual
equivalence. All four programs in Fig. 1 then deﬁne the same measure on (x, z) for all y. Finally, by Theorem 3
the program deﬁned in Algorithm 1 denotes the same measure as well, so can be substituted for the original
program in all contexts.

B A DISCUSSION ON TRAINING PROPOSALS

B.1 Naive Weighting with Perfectly Trained Proposals

In this part we investigate the validity of the existing IC weighting method (Deﬁnition 1) under perfectly trained
proposals.

Naderiparizi, ´Scibior, Munk, Ghadiri, Baydin, Gram-Hansen, Schroeder de Witt, Zinkov, Torr, Rainforth, Teh, Wood

As stated in the main text, in Baydin et al. (2019a) the proposals are trained using only the samples that
conclude the rejection loop, hence, the training data drawn from the original program (Fig. 1a) has the same
distribution as the training data from the collapsed program (Fig. 1c). Therefore, the perfect proposal is the
same for these two programs.

The proposals are trained by minimizing the expected forward KL between the posterior and the proposal,

q∗ = arg min

q

E

p(y) [KL ( p(x, z

y)
|

||

q(x, z

y))] .
|

(27)

Therefore, the perfect proposal q∗ matches the posterior of the collapsed program q∗(x, z
where
all y such that p(y) = (cid:82) (cid:82) p(x, z, y)dzdx > 0.

is the space of all observations that can be generated from the model. More formally,

Y

|

Y

y) = p(x, z

y)
|

,
y
∈ Y
∀
is the space of

|

, deﬁne γ(x, z) = γ(x)γ(z

Given an observation y
y) = γ(x) and q∗(z
q∗(x
the condition in Appendix A.1 holds with the perfect proposal:
(cid:20) p(z
q∗(z

∈ Y
x, y) = γ(z
|

z, x))
|

= E
z

p(A

E
z

q∗(z

x,y)

−

(cid:21)

∼

|

∼

x)2
x, y)2 (1
|
|

x) to be the posterior in the collapsed program. Hence,
x), in both the collapsed and original programs. Now we can investigate if
|

|

γ(z

x)

|

(cid:20) p(z
γ(z

x)2
x)2 (1
|
|

(cid:21)

p(A

|

−

z, x))

(28)

Since γ(z
c(x, z) therefore,

x) is the true posterior for the collapsed program, every sample drawn from it z
|

γ(z

|

∼

x) satisﬁes

z, x) = 1,

p(A

|

z
∀

γ(z

x)
|

∼

⇒

E
z

γ(z

x,y)
|

∼

(cid:20) p(z
γ(z

x)2
x, y)2 (1
|

|

(cid:21)

p(A

z, x))
|

−

= 0 < 1

(29)

So, if the proposals are trained perfectly, we would not have the problem of inﬁnite variance. However, note that
a perfectly trained proposal using only the accepted samples does not necessarily provide a valid importance
sampling proposal for the distribution p(z
x, y) can have zero mass on parts of the space where
p(z
x) > 0. Consequently, it can lead to biased estimates. This issue is illustrated in the following simple
|
example.
Example B.1. Consider the following original and collapsed programs with the same format as Figure 1a.

x) i.e., q(z
|

|

Program 4: Original

Program 5: Collapsed

x = sample( Uniform (low =1, high =2))
while True:

rs start ()
z = sample( Normal (mean =0, std =1))
if z < 0:

rs end()
break

x = sample( Uniform (low =1, high =2))

z = sample( TruncatedNormal (mean =0, std =1, max =0))

observe( Normal (mean=z, std=x), y)

observe( Normal (mean=z, std=x), y)

return x, z

return x, z

Both of these programs implement the following generative model:

Uniform(1, 2)
,0)(0, 1)

−∞
(z, x)

x

z

y

∼
∼ N(
∼ N

Where

,0) is a truncated normal distribution with a maximum value of zero and unbounded minimum.

N(

−∞

Since these programs are equivalent, inferences on them should have identical results4. However, under the perfect
proposal assumption, although the proposal samples have the same distribution, the weights are diﬀerent. For

4As long as it does not involve inference about the rejected samples

Amortized Rejection Sampling in Universal Probabilistic Programming

example, consider a sample xk
the original and collapsed programs as wIC and wC,

y) = γ(x) and zk

q∗(x

∼

|

q∗(z

|

∼

xk, y) = γ(z

xk), if we refer to the weights for
|

wIC =

wC =

U (xk; 0, 1)
γ(x)
U (xk; 0, 1)
γ(x)

(zk; 0, 1)
N
xk)
γ(zk
|
,0)(zk; 0, 1)
xk)
|
,0)(zk; 0, 1) = 2

γ(zk

N(

−∞

(30)

(31)

In Eq. (31), zk
to get the same result, importance sampling weights should be equal.

xk), zk < 0, therefore,
|

N(

γ(z

−∞

N

∼

(zk; 0, 1). Hence, wC = 2wIC while in order

It is worth mentioning that in this simple program because the computed weights in this program diﬀer by a
multiplicative constant, the normalized weights would be equal (in case of self-normalized importance sampling).
However, if the diﬀerence is state-dependent (i.e., the distribution of z depends on the value of x sampled at the
previous step for example z

(x, 1) instead), self-normalization would not help.

∼ N

It is important to note that in our experiments this problem of proposals having zero mass on the rejected
In the particular inference network we used, all the proposals are guaranteed to
subspace does not happen.
have a support broader than or the same as the prior. It is made possible by choosing the parametrized family
of proposal distributions from the ones that have broader support than the priors. However, because they are
trained on the accepted samples only, once trained, they can put arbitrarily small mass on the rejected subspace.
This in turn makes the quantity in Appendix A.1 larger and eventually, makes the variance inﬁnite.

B.2 An Alternative Training Scheme

Following Appendix B.1 where we showed inference with naive IC weighting (Deﬁnition 1) can be biased when
the proposals are trained only on the accepted samples, in this section we provide another training method that,
at its optimal point, provides proposals under which estimates with IC weighting are guaranteed to be unbiased
and ﬁnite variance. We argue that if the proposals are trained optimally on both the accepted and the rejected
samples, the resulting IC estimator has ﬁnite variance.

Theorem 5. Consider an inference compilation network trained on both accepted and rejected samples of a
rejection sampling loop. If it is trained optimally, Eq. (1) does not hold for it.

Proof. In this case, the perfectly trained proposal is:

x)p(z
|
Where following the notation in Appendix B.1, γ(z

x, y) = p(A
|

q∗(z

x, A) + p(A

x)γ(z

|

|

x) is the posterior p(z

|

|

x)
|
x, y). In this situation,

(32)

• If z

• If z

q∗(z

q∗(z

|

|

∼

∼

x, y) is in A (i.e., accepted), p(z

x, y) is in A (i.e., rejected), γ(z

x, A) = 0. Hence, in this region, q∗(z
|
x) = 0. Hence, in this region, q∗(z
|

x, y) = p(A
|

x)γ(z

x)

|
x)p(z
|

|

|
x, A)

x, y) = p(A
|

We abuse the notation and reuse A and A to denote the sub-spaces of accepted and rejected z, given the previous
sample x and drop the dependence on x for notational simplicity. We split the inequality in Eq. (1) to these two
accepted and rejected sub-spaces

E
z

q∗(z

|

∼

x,y)

(cid:20) p(z
q∗(z

x)2
x, y)2 (1
|
|

(cid:21)

p(A

z, x))
|

−

(cid:90)

=

x)2
x, y)2 (1
|
|
= IA(p, q∗) + IA(p, q∗)

p(z
q∗(z

A

A

∪

∈

z

p(A

z, x))q∗(z
|

x, y)dz
|

−

(33)

Where IA(p, q∗) and IA(p, q∗) denote the value of the integral on the accepted and rejected subspaces, respectively.
They can be simpliﬁed by replacing q∗(z

x, y) by their value on those regions, as stated above,
|

IA(p, q∗) =

(cid:90)

p(A

z

A

∈

x)2
p(z
|
x)2γ(z
|

x)2 (1
(cid:124)
|

−

p(A
(cid:123)(cid:122)
0

z, x))
|
(cid:125)

x)γ(z

p(A

|

x)dx = 0
|

(34)

Naderiparizi, ´Scibior, Munk, Ghadiri, Baydin, Gram-Hansen, Schroeder de Witt, Zinkov, Torr, Rainforth, Teh, Wood

IA(p, q∗) =

(cid:90)

A

z

∈

p(A

|

x)2

p(z
|
x)2p(z

x, A)2

(1
(cid:124)

−

p(A
(cid:123)(cid:122)
1

z, x))
(cid:125)

|

p(A

x)p(z
|

|

x, A)dx

p(A
(cid:124)

x)p(z
|
(cid:123)(cid:122)
=0

x, A)
|
(cid:125)

dx

x, A)2

(cid:90)

dx =

A

z

∈

x)2
p(z
|
p(z
x, z)
|
(cid:125)
(cid:123)(cid:122)
1

p(A
(cid:124)

dx

x)

|

x, A)
|

|
x)2

p(z
|
x)2p(z

|
x)2
p(z
|
x)p(z

p(A

p(A

|

|

p(z

x)dx
|

≤

1

(cid:90)

=

A

z

∈

(cid:90)

=

A

z

∈

(cid:90)

=

A

z

∈

(35)

(36)

(37)

(38)

If in Eq. (38) equality holds, it means that A =
never terminates which is an invalid rejection sampler. Therefore, E
z
the variance is ﬁnite.

, hence, p(A
∅

|

x) = 0, equivalently, the rejection sampling loop
x)2
x,y)2 (1
|
|

(cid:104) p(z
q∗(z

< 1 and

z, x))

p(A

q∗(z

x,y)

−

(cid:105)

∼

|

|

x), depending on how eﬃcient the rejection
However, since q∗ is a convex combination of p(z
x) is) q∗ can be arbitrarily far from the correct
sampling loop is implemented by the user (i.e., how small p(A
|
posterior γ(z
x) because it will generate high-likelihood
|
samples. Additionally, such a proposal can be wasteful computationally; it can have high rejection rate and it
depends on the user code and out of the control of the inference engine.

It is important to generate samples close to γ(z

x, A) and γ(z

x).
|

|

|

With all that said, we proved ﬁnite variance only at the optimal point i.e., if the inference network is imper-
fect, naive application of sequential importance sampling can still lead to an estimator with inﬁnite variance.
Therefore, even with this new training scheme, naive sequential importance sampling cannot be safely used with
guaranteed consistency guarantee.

C IMPLEMENTATION DETAILS

In this section we provide more details our implementation of ARS. In particular, we informally explain (I) our
addressing scheme for random variables in rejection loops, (II) training the network such that it is only trained
on the accepted samples, (III) running the inference network at test time.

C.1 Random variable addresses

Following the notation of Le et al. (2017), an execution trace of a probabilistic program is a sequence

(xt, at, it)T

t=1,

(39)

where xt, at, and at are respectively the sampled value, address, and instance value (call number) of the tth
random variable in a given trace. An address at is a unique identiﬁer automatically generated for each sample
statement in the program. An instance value it is a counter of how many times a sample statement is executed in
the same program trace i.e., it = (cid:80)t
1(at = aj). The inference network then learns proposal distributions qa,i
corresponding to the addresses a for all sample statements in the program and their instance values i. Therefore,
each proposal distribution is identiﬁed by (a, i). As explained in the paper, we train the same proposal distribution
for diﬀerent iterations of a rejection loop. Consequently, the addressing scheme should be modiﬁed to reﬂect this
requirement.

j=1

In our implementation, we ﬁrst extend the deﬁnition of addresses and instance values to cover rs start statements
as well. We then deﬁne a trace for rejection sampling loops (denoted by RS trace) as a sequence of (xt, at, it),
similar to the program traces, but xt denotes the iteration of the loop here. We then modify the deﬁnition of a
program trace to a sequence

(xt, rt, at, it),

(40)

rt is the identiﬁer (address and instance value) of the latest active rejection sampling loop, or
if no active
rejection sampling loop exists at time t. An active rejection sampling loop is a loop that is started but is not
concluded yet. In other words, rs start has been executed, but its corresponding rs end has not been reached yet.

∅

(cid:54)
Amortized Rejection Sampling in Universal Probabilistic Programming

To handle rejection sampling loops, we maintain a stack st of all active rejection sampling loops. At the beginning
of program execution, s0 =
. Every time the program enters a new rejection sampling loop, we push its identiﬁer
∅
to s and pop from its top when executing rs end. When running rs start at time t, in order to detect if it is the
start of new rejection sampling loop or retrying the last one, we compare the address the rs start statement at
with the top of the stack.

• If the addresses do not match, we identify this as a new rejection sampling loop and push its identiﬁer (at, it)

to the top of the stack: st = st

−

(at, it), where

1 ⊕

⊕

denotes pushing to the top of the stack.

• If the addresses match, it is a retry of the latest loop. Let (x, a, i) be the last item in RS stack (we know
at = a). We ﬁrst increase x in RS stack by one, denoting a new iteration of the loop. Then discard every
item in program trace that has a rejection sampling identiﬁer matching (a, i) i.e.,
(xj, rj, aj, ij) : j < t, rj =
{
(a, i)
}

1 and the program execution continues.

. Then we set st = st

−

With this deﬁnition, rt =

∅

if st is empty. Otherwise, it is the top element of st.

Therefore, once we execute a program, its program traces only contain accepted samples since all the rejected
samples are instantly discarded and removed from the trace. Moreover, since each execution of rs start for a
new rejection sampling loop gets a unique identiﬁer, it can uniquely identify all rejection sampling loops, even
for complicated program structures such as nested loops.

C.2 Training

With our modiﬁed deﬁnition of program traces, we can use the traces after their execution is ﬁnished as training
data for inference compilation network. Since the rejected samples are discarded, the traces are identical to the
ones sampled from the “collapsed” program.

C.3

Inference

One of the most important points to consider when performing inference is to ensure proposal distributions for
diﬀerent iterations of the same rejection sampling loop are the same. To satisfy this constraint, we should recover
the LSTM network’s state when retrying a rejection sampling loop. To accommodate it, we store the LSTM’s
In other words, we modify the
state at the time of starting a new rejection sampling loop in the RS trace.
deﬁnition of RS trace to be a sequence of (xt, at, it, ht) where ht is the LSTM state. Then, we can simply restore
LSTM’s state once a rejection sampling loop retry is detected.

D DETAILS OF EXPERIMENTS

Our experiments are implemented using PyProb. The architecture of our inference compilation network is
the LSTM-based network introduced in (Le et al., 2017) and existing in PyProb. The proposal distributions
for Normal distributions are mixtures of 10 Normals and for Uniform distributions are mixtures of 10 Beta
distributions with the same support as the prior. All the training is done by Adam optimizer (Kingma and Ba,
2014). To compute Kconverge, we choose (cid:15) = 0.01, unless otherwise speciﬁed.

D.1 Marsaglia

Training The inference compilation network trained in this experiment has a single layer, 512 dimensional
3 and batch size of
LSTM and is trained on 2 million random draws from the model with a learning rate of 10−
512. The speciﬁc distribution parameters in our model is µ0 = 0, σ0 = 1, σ = 0.1.

Model
used in the experiments are y1 = y2 = 0 in Fig. 2 (top) and Fig. 9 (top) and y1 = y2 =

Implementation of this model (including rejection sampling tags) is shown in Program 6. Observations

1 in Fig. 9 (bottom).

−

Naderiparizi, ´Scibior, Munk, Ghadiri, Baydin, Gram-Hansen, Schroeder de Witt, Zinkov, Torr, Rainforth, Teh, Wood

Program 6: The Marsaglia experiment

def GUM( mu 0 , sigma 0 , sigma , y1 , y2):

while True:

rs start ()
x1 = sample( Uniform(−1, 1))
x2 = sample( Uniform(−1, 1))
s = x2∗∗2 + x2∗∗2
if s < 1:

rs end()
break

mu = x ∗ sqrt(−2∗log(s)/s)
observe( Normal (mean=mu , std=sigma), y1)
observe( Normal (mean=mu , std=sigma), y2)
return mu

D.2 Beta-Bernoulli

D.2.1 Acceptance Function

The acceptance function c(x, u) is chosen in a way that a sample x drawn from the “base distribution” gets

accepted with probability

c(x, u) := 1
u

∈

(cid:16)

x(1 + β
α )

(cid:17)α

1(cid:16)

−

x)(1 + α
β )

(cid:17)β

1

−

, therefore,

(1

−

(cid:26)

C(x) where C(x) :

z

[0, 1] : z

∈

(cid:16)

x(1 +

β
α

≤

1(cid:16)

(cid:17)α
)

−

(1

x)(1 +

−

1(cid:27)

.

(cid:17)β
)

−

α
β

Note that c(x, u) depends on the parameters α and β, but this dependence in suppressed in the notation for
simplicity. In our experiment we assume α = β. It simpliﬁes C(x) to

(cid:26)

C(x) :

z

[0, 1] : z

∈

≤

(cid:16)

4x(1

−

(cid:17)α

−

x)

1(cid:27)

.

D.2.2 Proposal Distributions

We mentioned in the main paper that the proposals are chosen manually. Here we explain in more detail how
the proposals are chosen.

True posterior for x Consider the probabilistic program as shown in Fig. 6. We show the program in both
“original” and “collapsed” versions (with the terminology from Fig. 1.) We know the true posterior for the latent
variable x in Program 8 is Beta(α + n, β), since all the observations are “True”.

Program 7: Original

Program 8: Collapsed

while True:

x = sample(Beta(alpha , beta ))

rs start ()
x = sample( Uniform (0, 1))
u = sample( Uniform (0, 1))
if c(x, u):
rs end()
break

for i in range(n):

for i in range (n):

observe( Bernoulli (x), y[i])

observe( Bernoulli (x), y[i])

Figure 6: Probabilistic programs implementing the Beta-Bernoulli model.

Amortized Rejection Sampling in Universal Probabilistic Programming

Parameters
α = β = 2

q(x

y)
|
Beta(α + n, β)

(cid:20)

α = β = 10 Beta(α + n, β) Mixture0.99,0.01

Uniform

0,

y, x)

q(u
|
Uniform(0, 1)
(cid:18)

(cid:16)

4x(1

x)

−

(cid:17)α

1(cid:19)

−

(cid:21)

, Uniform(0, 1)

Table 1: Manually chosen proposal distributions in the Beta-Bernoulli experiment. The ﬁrst row corresponds to
Fig. 4 in the main text and Fig. 10 (left) in Appendix E. The second row corresponds to the additional results
plot in Fig. 10 (right). In this table, Mixture0.99,0.01 means a mixture of two distributions with 0.99 and 0.01
being the probabilities of each of mixtures respectively. This Mixture distribution is necessary to ensure p is
absolutely continuous with respect to q.

Figure 7: Simulation process (top row) and noisy observations (bottom row) in our Mini-SHERPA experiment.
Rows correspond to events of channel 1, 2, and 3, respectively from left to right. These are the observations
used in this paper. Fig. 2 (bottom row) corresponds to the left column and Fig. 8 corresponds to the next two
columns.

True posterior for u Considering Program 7, the true posterior of u given the set of observations y =

y, x) = Uniform
and the previously sampled latent variable x is p(u
|

(cid:18)

(cid:16)

0,

4x(1

(cid:17)α

x)

−

1(cid:19)
.

−

n
i=1

yi}
{

Having these true posterior distributions in mind, we choose (nearly) perfect proposal distributions in our
experiment, as summarized in Table 1.

D.3 Mini-SHERPA

In this experiment, the inference compilation has a 3-layer layer LSTM with dimension of 512. The network is
trained on 2 million random draws from the model with a learning rate of 10−

3 and a batch size of 512.

The observation in this experiment is a noisy measurement of the energy dispatched by the simulated particles.
Figure 7 (bottom) shows the observations used in our Mini-SHERPA experiment. Each observation is a 20
20
image. The observation noise is a zero-mean independent multivariate Gaussian on image pixels.

×

The implementation of this experiment, excluding the unnecessary simulation details is shown in Program 9.

Naderiparizi, ´Scibior, Munk, Ghadiri, Baydin, Gram-Hansen, Schroeder de Witt, Zinkov, Torr, Rainforth, Teh, Wood

Figure 8: Experimental results for the Mini-SHERPA experiment with a channel 2 (top) and channel 3 (bottom)
observation. For the convergence plot on the bottom row, since the methods are slow to converge, we choose
(cid:15) = 0.03.

Program 9: The Mini-SHERPA experiment

def rejection sample (scale ):

y max = 1/ scale
while True:

rs start ()
x = sample( Uniform(−scale , scale ))
a = sample( Uniform (0, y max ))
if a <= 1/ scale∗abs(x/scale ):

rs end()
return x

def Mini SHERPA (obs ):

channel = sample( Categorical ([1/3 , 1/3, 1/3]))
momentum x = sample( Uniform(−0.5, 0.5))
momentum y = sample( Uniform(−0.5, 0.5))
momentum z = sample( Uniform (10, 20))
thetas , phis = [], []

for i in range( channel )

thetas . append ( rejection sample (pi /4))
phis. append (sample( Uniform (0, 2∗pi)) for i in range( channel ))
deposits = simulate ( momentum x , momentum y , momentum z , thetas , phis)
likelihood = Normal (deposits , max(sqrt(deposits , 0.3)))
observe(likelihood , obs)

return momentum x , momentum y , momentum z , channel , deposits

In Program 9, the function simulate computes the resulting particle momentums, simulates the resulting par-
ticles and renders the 20

20 image of dispatched energies.

×

0200400600×103−129.0−128.5−128.0logˆp(y)0200400600×1030.00000.00250.0050ESS/NARSM=1ARSM=2ARSM=10Biased123Kconverge×105ICARSM=1ARSM=2ARSM=10BiasedGroundtruth0200400600Numberofdraws(N)×103−111−110logˆp(y)0200400600Numberofdraws(N)×1030.0000.0010.002ESS/NARSM=1ARSM=2ARSM=10Biased0.51.0Kconverge×106ICARSM=1ARSM=2ARSM=10BiasedGroundtruthAmortized Rejection Sampling in Universal Probabilistic Programming

Figure 9: Additional results from the Marsaglia experiment. (Top) is the same as Fig. 2, but includes the collapsed
weighting as well. (Bottom) has a diﬀerent observation. Observations are (y1 = y2 = 0) and (y1 = y2 =
1)
respectively for the top and bottom row.

−

E MORE EXPERIMENTAL RESULTS

E.1 Collapsed weighting

In all experiments presented in this paper, the rejection sampling loops are simple enough to admit tractable
“collapsed” distributions. The collapsed distribution is a Gaussian in the Maraglia experiment and a Beta in
the Beta-Bernoulli experiment. In Mini-SHERPA, it is a custom distribution with tractable density and CDF
function, therefore, we can implement a custom distribution for it. One might argue that we can ask the user
to implement the collapsed program instead of using rejection sampling and avoid the problems discussed in the
paper. In this section we investigate how feasible it is and provide additional results to compare performance of
collapsed weighting and ARS.

First, we remind the reader that ARS depends on the acceptance probability of the loops and not other features
of them. Therefore, ARS performs similarly in more complicated programs with intractable rejection loops.
Second, it is important to note that in many situations, the collapsed program is intractable. For example,
consider a generator of LaTeX source codes that compile without error. Therefore, it is essential for universal
PPLs to provide the tooling to handle such cases without relying on the user to implement the collapsed program.

Nonetheless, in this section we provide additional results to compare performance of ARS compared to collapsed
weighting. However, re-implementing the program in its collapsed form changes the number of random variables
and distribution types (for example, in the Marsaglia experiment, two Uniform random variables inside the
rejection loop will be replaced by one Gaussian random variable).
It will in turn reduce the variance of the
estimator due to having fewer number of random variables and usually simpler distributions. It also requires
re-training the inference network. Such diﬀerences improve performance of the collapsed model for reasons
unrelated to the weighting.

For a fair comparison, we keep the model unchanged, but estimate or analytically compute (where applicable)
the quantities of interest p(z
x, A, y) and compute collapsed weighting according to its deﬁnition
in Eq. (2). Results of this experiment are labelled “Collapsed” in Figs. 9 and 10.

x, A) and z(z
|

|

0255075100×103−10−1−10−2010−210−1ˆp(y)−p(y)0255075100×1030.00.10.2ESS/NARSM=1ARSM=2ARSM=10BiasedCollapsed23Kconverge×104ARSM=1ARSM=2ARSM=10ICBiasedCollapsed0255075100Numberofdraws(N)×103−10−1−10−2010−2ˆp(y)−p(y)0255075100Numberofdraws(N)×1030.100.150.20ESS/NARSM=1ARSM=2ARSM=10BiasedCollapsed23Kconverge×103ARSM=1ARSM=2ARSM=10ICBiasedCollapsedNaderiparizi, ´Scibior, Munk, Ghadiri, Baydin, Gram-Hansen, Schroeder de Witt, Zinkov, Torr, Rainforth, Teh, Wood

Figure 10: Additional results from the Beta experiment. (Left) is the same as Fig. 4, but includes the collapsed
weighting. (Right) has a diﬀerent set of observations and proposal distributions as explained in Table 1.

Marsaglia - a

Marsaglia - b

Mini-SHERPA - 1

Mini-SHERPA - 2

Mini-SHERPA - 3

Bias (
×
ESS/N (
Bias (
×
ESS/N (
Bias (
×
ESS/N (
Bias (
×
ESS/N (
Bias (
×
ESS/N (

10−

×
10−

×
10−

×
10−

4)
10−
4)
10−
4)
10−
2)
10−
2)
10−

3)

2)

2)

3)

4)

×
10−

×

−

−

−

IC
151
20
1285
12
102
79
38
−
1.0
42
−
0.8

ARS,M=1 ARS,M=2 ARS,M=10 Biased Collapsed

−

−

1.3
63
0.5
16
2.3
83
3.7
−
3.3
2.6
5

−

−

16
−
70
0.5
18
2.3
83
3.6
−
3.9
2.8
6

−

−

14
−
75
1447
20
2.5
84
3.7
−
4.7
2.6
9

−

−

2247
76
2.3
20
85
85
67
4.9
120
10

−

5
−
76

-
-
-
-
-
-

Figure 11: Each row block shows estimation bias and average ESS of an experiment at the right-most point
of their corresponding plot. “Marsaglia - a” corresponds to Fig. 9 (top) and Fig. 2 (top). “Marsaglia - b”
corresponds to Fig. 9 (bottom). “Mini-SHERPA - 1” corresponds to Fig. 2 (bottom). “Mini-SHERPA - 2” and
“Mini-SHERPA - 3” correspond to the top and bottom row of Fig. 8

E.2 Additional results

Here we provide additional experimental results for the three models considered in the main text, but the diﬀerent
observations. Figs. 8 to 10 show additional results for the Marsaglia, Mini-SHERPA, and Beta models.

Since the lines in evidence and ESS plots are tightly clustered, we summarize the ﬁnal mean and standard
deviation of each line for each of Marsaglia and Mini-SHERPA experiments in Fig. 11.

051015202530n025005000750010000KconvergeICARSM=1ARSM=10PriorCollapsed051015202530n025005000750010000KconvergeICARSM=1ARSM=10PriorCollapsed051015202530n02000400060008000KconvergeICARSM=1ARSM=10PriorCollapsed