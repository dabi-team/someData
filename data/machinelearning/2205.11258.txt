2
2
0
2

y
a
M
0
2

]

G
L
.
s
c
[

1
v
8
5
2
1
1
.
5
0
2
2
:
v
i
X
r
a

Neuro-Symbolic Regex Synthesis Framework via
Neural Example Splitting

Su-Hyeon Kim
Kangwon National University
tngus98207@kangwon.ac.kr

Hyunjoon Cheon
Yonsei University
hyunjooncheon@yonsei.ac.kr

Yo-Sub Han
Yonsei University
emmous@yonsei.ac.kr

Sang-Ki Ko
Kangwon National University
sangkiko@kangwon.ac.kr

Abstract

Due to the practical importance of regular expressions (regexes, for short), there has
been a lot of research to automatically generate regexes from positive and negative
string examples. We tackle the problem of learning regexes faster from positive and
negative strings by relying on a novel approach called ‘neural example splitting’.
Our approach essentially split up each example string into multiple parts using a
neural network trained to group similar substrings from positive strings. This helps
to learn a regex faster and, thus, more accurately since we now learn from several
short-length strings. We propose an effective regex synthesis framework called
‘SplitRegex’ that synthesizes subregexes from ‘split’ positive substrings and pro-
duces the ﬁnal regex by concatenating the synthesized subregexes. For the negative
sample, we exploit pre-generated subregexes during the subregex synthesis process
and perform the matching against negative strings. Then the ﬁnal regex becomes
consistent with all negative strings. SplitRegex is a divided-and-conquer framework
for learning target regexes; split (=divide) positive strings and infer partial regexes
for multiple parts, which is much more accurate than the whole string inferring,
and concatenate (=conquer) inferred regexes while satisfying negative strings. We
empirically demonstrate that the proposed SplitRegex framework substantially
improves the previous regex synthesis approaches over four benchmark datasets.

1

Introduction

Regular expressions (regexes in short) are a powerful tool for processing sequence data in NLP or
information retrieval. A regex—a ﬁnite sequence—is a formal representation of (inﬁnite) symbol
sequences. However, it is not easy to write a good regex for a set of sequences. Especially for those
who have little experience with formal expressions, a single mistake in regex composition leads to an
invalid regex or, even worse, a regex with different semantics to one’s intention. An automatic regex
synthesis tries to moderate this human error.

Examples [Oncina and García, 1992, Bartoli et al., 2014] and natural language descriptions [Locascio
et al., 2016, Zhong et al., 2018b] are the two major sources of regex synthesis. Examples are speciﬁc
in their meaning without any implicit semantics, but are hard to provide the complete user intent
described by a regex. On the other hand, natural language descriptions are ambiguous but describes
the high-level concept of a regex. As these two different types of information are complementary to
each other, there have been many studies [Chen et al., 2020, Li et al., 2021, Zhong et al., 2018a] that
suggest to use both modalities as they can use examples to ﬁx the ambiguous expressions generated
from natural language descriptions.

Preprint. Under review.

 
 
 
 
 
 
The regex synthesis problem is to make a proper regex R from both positive and negative sets such
that all the positive samples are generated by R and all the negative strings are not generated by R.
This problem is also called the regex inference or learning problem in the literature.

The traditional approaches for the regex synthesis problem are often inapplicable in practical set-
tings. For example, Angluin’s [1987] L∗ is impractical because it requires the equivalence test
between a target regex and a generated regex, which is known to be PSPACE-complete and thus
intractable [Stockmeyer and Meyer, 1973]. Gold [1978] shows that the state characterization approach
is NP-complete and thus intractable. Heuristic approaches based on state-merging DFA induction
algorithms such as RPNI [Oncina and García, 1992] and blue-fringe [Lang et al., 1998] are not
very promising on synthesizing complex regexes because it is almost impossible to obtain a concise
regex even when they are able to produce a concise DFA from examples. As recent approaches,
both AlphaRegex [Lee et al., 2016] and RegexGenerator++ [Bartoli et al., 2014, 2016] generate
candidate regexes and match against the given examples until the target regex matches all examples
successfully. While these approaches generate correct regexes when a time limit is very long, they
often fail when the example size is large. In addition, both approaches do not use any characteristics
in the given examples, which is a useful feature to speed up the process. In other words, these methods
are impractical for generating regexes within a reasonable time limit.

For practical usage, we notice that the divide-and-conquer approach is promising for synthesizing
formal representation. For example, Alur et al. [2017] synthesize a program with hierarchical partition
of the given input-output pairs. A decision tree reﬂects the hierarchical partition forms the control
ﬂow of the synthesized program. This method noticeably improves program synthesis time due
to the partitioned problem space. Farzan and Nicolet [2021a,b] propose an effective method that
converts a program into an equivalent program by splitting a problem into several subproblems. This
divide-and-conquer approach is efﬁcient since individual tasks for solving subproblems can run
simultaneously. Recently, Barke et al. [2020], Shrivastava et al. [2021] propose program synthesis
methods that ﬁrst ﬁnds partial solutions satisfying subsets of input-output examples and combines the
solutions to ﬁnd the global solution.

In this paper, we propose a novel regex synthesis framework based on the divide-and-conquer
paradigm for boosting existing regex synthesis algorithms. Given a set of positive examples, we
split examples into multiple parts by grouping similar substrings using a neural network and solve
subproblems deﬁned over the multiple parts in serial order. We train a neural network called the
NeuralSplitter that embeds a set of positive examples into a ﬁxed-size vector and produces the most
probable split for each example in the set. As far as we are aware, this is the ﬁrst work that aims to
synthesize a regex by processing given positive and negative examples with a neural network.

Our main contributions are as follows:

1. We propose a regex synthesis framework SplitRegex based on the divide-and-conquer
paradigm, which has been employed in many sequential algorithms. As far as we are aware,
this is the ﬁrst attempt to synthesize regexes in the divide-and-conquer manner.

2. We design a neural network called the NeuralSplitter—a two-stage attention-based recurrent

neural network trained to predict the most probable split of input positive strings.

3. We conduct exhaustive experiments on various benchmark datasets including random dataset
and practical regex datasets for demonstrating the effectiveness of the proposed framework.
We show that our framework can be easily combined with the off-the-shelf regex synthesis
algorithms with minor modiﬁcations.

Namely, our framework solves regex synthesis problem, which is PSPACE-complete, much faster
when applied to any existing regex synthesis models, and thus boosts the overall performance.

2 Related Work

We provide a list of related works on regex synthesis problems based on various input types including
positive and negative examples and natural language descriptions.

2

2.1 Regular Expression Inference from Examples

One approach to regular expression inference is by Angluin’s [1987]. Angluin suggests an algo-
rithm L∗ that infers an unknown DFA in teacher-student architecture. The teacher of L∗ offers
membership queries and equivalent queries on the target expression for the student. Note that this
type of algorithm generally requires an inﬁnite amount of examples to synthesize an FA. Gold [1978]
proposes a heuristic inference algorithm that inductively distinguishes random preﬁxes according to
the acceptance followed by the given examples. The preﬁxes with the same acceptance form a single
state in a DFA. The blue-fringe algorithm [Lang et al., 1998] and RPNI [Oncina and García, 1992]
are similar to the Gold’s algorithm. AlphaRegex [Lee et al., 2016] exhaustively searches through all
possible regular expressions until it identiﬁes a solution regex that satisﬁes given positive and negative
examples. A major limit of AlphaRegex is that its runtime is extremely due to the exponential increase
of search space. RegexGenerator++ [Bartoli et al., 2014, 2016] produces a regular expression using
the genetic programming approach. The produced regular expression recognizes the surroundings
(context) of the target sequence as well as the target itself. However, RegexGenerator++ entails a
huge amount of computations due to the repetitive nature of genetic approach on each inference.

2.2 Regular Expression Synthesis from Natural Language Descriptions

Ranta [1998] studies rule-based techniques for the conversion between multi-languages and regular
expressions. Kushman and Barzilay [2013] build a parsing model that translates a natural language
sentence to a regular expression, and provides a dataset, which is the most popular benchmark dataset
in recent research. Locascio et al. [2016] propose the Deep-Regex model based on Seq2Seq for
generating regular expressions from NL descriptions together with 10,000 NL-RX pair data. However,
due to the limitations of the standard Seq2Seq model, the Deep-Regex model can only generate
regular expressions similar in shape to the training data. The SemRegex model [Zhong et al., 2018b]
improves the Deep-Regex model by reinforcement learning based on the DFA-equivalence oracle,
which determines if two regular expressions deﬁne the same language, as a reward function and their
model can generate correct regular expressions even if they do not exactly look like answers. The
SoftRegex model [Park et al., 2019] further improves SemRegex based on the fast regex equivalence
test, which gives rise to a fast learning process.

2.3 Multi-modal Regular Expression Synthesis

Most multi-modal synthesis method uses natural language descriptions and positive/negative examples
simultaneously to mitigate the ambiguity in natural languages. Chen et al. [2020] introduce a
hierarchical sketch for the semantics of natural description. Chen et al.’s implementation Regel ﬁrst
deduces the hierarchical structure representing the semantics of the natural language description. This
semantic structure has some holes in which the regular expression inference algorithm enhances a
regular expression by predeﬁned rules. Regel also prunes an infeasible expression using over- and
under-approximation possible regular expressions, which replaces the holes with the most permissive
and the most restrictive expression, respectively. Li et al. [2021] propose TransRegex framework
that synthesizes a valid regular expression. TransRegex’s NLP-based synthesizer translates the given
description to a regular expression and ﬁxes the expression by rules and RFixer [Pan et al., 2019] to
increase the matching score on the examples.

2.4 Repair-base Regular Expression Synthesis

Pan et al. [2019] design a heuristic algorithm RFixer that repairs a regular expression with given
examples. RFixer improves the given regular expression by introducing or removing a hole and
approximate the target expression with over- and under-approximation method until ﬁnds a regular
expression with no holes that satisﬁes the given examples. Li et al. [2020] propose FlashRegex that
generates a deterministic regular expression, which is a subclass of regular expressions. A SAT
solver designs the basic FA structure after the given examples and FlashRegex iteratively shufﬂes the
transitions in FA model at random to ﬁnd the most suitable FA that satisﬁes the given examples.

3

Figure 1: Overview of the proposed approach.

3 Our Approach

3.1 Problem Deﬁnition

Let Σ be a ﬁnite alphabet and Σ∗ be the set of all strings over the alphabet Σ. The empty string is
denoted by λ. A regular expression (regex) over Σ is a ∈ Σ, or is obtained by applying the following
rules ﬁnitely many times. For regexes R1 and R2, the union R1 + R2, the concatenation R1 · R2, the
star R∗
1 are also regexes. We denote the set of strings (language) represented by
a regular expression R by L(R). Note that L(R?
1) is deﬁned as L(R1) ∪ {λ}.

1, and the question R?

Given positive and negative strings, we consider the problem of synthesizing a concise regex that
is consistent with the given strings. The examples are given by a pair (P, N ) of two sets of strings,
where P ⊆ Σ∗ is a set of positive strings and N ⊆ Σ∗ is a set of negative strings.

Then, our goal is to ﬁnd a regex R that accepts all positive strings in P while rejecting all negative
strings in N . Formally, R satisﬁes the following condition: P ⊆ L(R) and L(R) ∩ N = ∅.

3.2 The ‘SplitRegex’ Framework

Our approach involves the following procedure:

1. Split the input positive strings in the set P into multiple partitions P1, P2, . . . , PS, where S

is the number of splits, using the NeuralSplitter model.

2. Run the regex synthesis engine for each Pi for 1 ≤ i ≤ S with the set N of negative strings.
We will explain in more detail about how to use the set N of negative strings for ﬁnal regex
synthesis.

3. Concatenate the obtained subregexes R1, R2, . . . , RS such that Pi ⊆ L(Ri) to produce the

ﬁnal regex R.

In the ﬁrst step, NeuralSplitter splits positive examples into the same number of substrings for
‘dividing’ the entire regex synthesis problem into less complex subregex synthesis problems. In order
to train the NeuralSplitter, we generate target labels for positive examples. For instance, when we
are given P = {aabbccabca, abcbbc, bbbcabb, aabbbc} and R = a∗b∗c∗.∗, we obtain ground truth
labels for the four positive examples in P as follows: {1122330000, 123000, 2223000, 112223}. The
digits 1, 2, and 3 in the ground truth labels imply that the corresponding symbols are generated from
the ﬁrst, second, and third subregex of R: a∗, b∗, and c∗, respectively. Note that the output label for

4

aaabbaccaabccPositivesaacacabaccbbaNegativesNeuralSplitteraaabbaccaabcc1. Divide positive examples2. Synthesize subregexesaaaaaaaacacabaccbbabbbaacacabccbbaccccaacacabaccbbaRegexSynthesizerRegexSynthesizerRegexSynthesizer3. Combine into a single regexa+b*c*symbols generated from the wildcard pattern regex .∗ (capturing zero or more of any characters) is
always 0 regardless of the position of the corresponding subregex.

Note that we cannot split negative examples just as we do for positive examples using the Neu-
ralSplitter model as there may be another split (not produced by the NeuralSplitter) that results in
negative strings recognized by the synthesized regex. For instance, consider a simple case when given
P = {abbaaa, abaaa, aaa} and N = {aaaa}. The NeuralSplitter may simply predict that substrings
with the same repeated symbols should be grouped to form a subregex. Then, the ﬁrst part has positive
examples P1 = {a} and N1 = {λ}, the second part has P2 = {bb, b, λ} and N2 = {aaaa}, and
ﬁnally the last part has P3 = {aa, aaa} and N3 = {λ}. It is possible that the synthesis algorithm
generates ab∗aaa?, which accepts the negative example. Note that there is no other split admitting a
regex satisfying both P and N .

We resolve this problem by introducing the concept of preﬁx-conditioned subregex synthesis. The basic
idea of our approach is to ﬁrst synthesize n − 1 subregexes once the NeuralSplitter produces n splits
(P1, P2, . . . , Pn) from P . Then, we concatenate the resulting n − 1 regexes to be R1R2 · · · Rn−1 and
use this regex to obtain the ﬁnal regex from the last split sample Pn that satisﬁes all preﬁx subregexes
as well as the negative samples. Namely, for each regex Ri, we only consider the corresponding
split examples Pi from P . We use the negative samples to prevent a regex synthesis algorithm to
return a trivial regex such as the wildcard pattern regex .∗. One may consider using the NeuralSplitter
approach for the negative samples. Our empirical observation conﬁrms that it causes a substantially
larger amount of additional computations, and the performance becomes worsened.

When there are common strings between the split positive examples Pi and the negative examples N ,
we remove the common strings from N . If Pi has only one example (singleton set), then we simply
return the example as Ri. The proposed method generates a regex R from a set P of positive examples
and a set N of negative examples that satisfy the following conditions:

• L(Ri) ⊆ Pi and L(Ri) ∩ (N \ Pi) = ∅ for 1 ≤ i ≤ n − 1 (independent subregex synthesis).

• L(R1R2 · · · Rn) ∩ N = ∅ (preﬁx-conditioned subregex synthesis).

• L(Ri) = Pi if |Pi| = 1 for 1 ≤ i ≤ n (singleton subregex synthesis).

While the proposed method can generate a regex quickly by dividing a complex synthesis problem
into several easier problems, one limit is that it cannot generate the wildcard pattern regex, .∗, as a
subregex Ri due to the negative examples. Because the wildcard pattern is common and handy in
practice to representing complicated sequences, we treat the symbols generated from the wildcard
pattern differently compared with the rest of the symbols—we assign a special label 0 for the symbols
in the data preprocessing step. For instance, if a string abbccdd is generated from a∗b∗c∗d∗, then
the label is 1223344. However, if abbccdd is generated from a∗.∗, then the label is 1000000. When
reading these special symbol 0’s, our framework immediately generates wildcard patterns without
going through the preﬁx-conditioned subregex synthesis.

3.3 Data Preprocessing

Since both AlphaRegex and Blue-Fringe synthesize regexes at the symbol level, they cannot be used
for synthesizing raw practical regexes that cover potentially all ASCII characters. Therefore, we
preprocess or exclude regexes as described below:

• Regex simpliﬁcation: raw examples generated from practical regexes are typically very
long. In order to effectively reduce the lengths of examples for faster regex synthesis, we
replace substrings from regexes with special reserved symbols (let us denote by ‘A’–‘Z’) and
control characters with ‘!’. For example, a regex function:(public|private|protected) can be
preprocessed to A!(B|C|D) by replacing substrings function, public, private and protected
by A, B, C and D, respectively. In practice, we can ﬁnd common substrings used throughout
the given positive examples to simplify them and synthesize a regex in the simpliﬁed form.

• Backreference: we do not consider backreference for regex synthesis as some baseline
approaches such as AlphaRegex and Blue-Fringe algorithm do not support regex features
that capture non-regular languages.

5

• Lookahead/lookbehind: while regexes with these features still only capture regular languages,
we do not consider these features as they require the regex engine to perform backtracking
that causes catastrophic runtime in some extreme cases.

• Quantiﬁer with exact count ‘{n}’ or range ‘{n, m}’: we replace numerical quantiﬁers with
‘∗’ to 1) reduce the search space and 2) control the length of randomly generated strings.
• Negated class: A simple negated class [ˆx]∗ generates all strings except for x and, then, the
model outputs .∗ unless a speciﬁc negative input containing x is provided. If provided, then
the learning is very trivial because the negative set is {x} only. Thus, we do not consider
negated classes in our study.

For each regex, we randomly generate 20 positive and 20 negative examples up to certain length (10
for random dataset and 15 for the other datasets). In order to generate positive examples, we utilize a
Python library called Xeger.1 For generating negative examples, we ﬁrst generate positive examples
and randomly substitute symbols with other symbols to make the examples outside the language
represented by the regex. Then, we use Python library pyre2, which is a Python wrapper for Google’s
RE2 regex library, to perform matchings of perturbed examples against the regex. We ﬁnd this is
effective compared to the complete random generation of negative examples.

In order to guarantee that every regular expression has 20 positive and 20 negative examples, we
exclude regular expressions that do not generate more than 20 positive strings (e.g., regexes without
quantiﬁers such as ∗ and +). From the generated 40 strings, we use 10 positive/negative strings for
generating regexes and use the remaining strings for measuring the semantic accuracy of synthesized
regexes by membership queries. We utilize the fullmatch method of pyre2 to ﬁnd subregexes from
the whole regex that match corresponding substrings from given positive strings.

3.4 Architecture of the NeuralSplitter

We introduce a neural network called the NeuralSplitter that is trained to split positive examples
generated from each regex. For a set P = {p1, p2, . . . , pn} of positive examples, where pi ∈ Σ∗
for 1 ≤ i ≤ n, we embed each string pi with an RNN encoder into d dimensional space as follows:
hi = RNNenc1(pi), where hi ∈ Rd. Then, we embed the set P of positive examples with the second
RNN encoder RNNenc2 as follows: hP = RNNenc2(h1, h2, . . . , hn), where hP ∈ Rd.
From the hidden vectors hi for 1 ≤ i ≤ n and hP , the RNN decoder is trained to produce the ground
truth label for each positive string pi as follows:

o1, o2, . . . , oli = RNNdec(W (cid:62)

dec · [hi; hP ]),

where li = |pi|, oj ∈ Rd for 1 ≤ j ≤ li, Wdec ∈ R2d×d.
Finally, we retrieve the predicted label for each positive example pi as follows:yj = softmax(W (cid:62)
output·
oj), where yj ∈ R|V |, Woutput ∈ Rd×|V |, and V is the output vocab. Note that yj is the predicted
probability distribution for the label of jth symbol of the positive example pi.

During the decoding process, the RNN decoder exploits the attention mechanism to better point out
the relevant parts from the entire set of positive strings. Since the split label for a positive string relies
on the information from all positive strings, we implement two-step attention mechanism that enables
our model to attend both in set level and example level. For instance, when we have two strings
aabbbc and aabbcc, the most probable labels for these two strings are 112223 and 112233. However,
if the second string is caabbcc, where only the ﬁrst symbol c is appended in front of aabbcc, then the
most probable labels for two strings become 223334 and 1223344. In this reason we need to use the
information of all given positive strings to correctly predict the output labels.

We use bi-directional GRU network for RNN encoders and decoder of NeuralSplitter. Cross entropy
loss is used for training the neural network.

4 Experimental Setup

We describe the experimental setup of our evaluation on SplitRegex framework.

1https://pypi.org/project/xeger/

6

Datasets. We use the following benchmarks to measure the performance of the proposed approach
compared to the previous approaches.

• Random dataset: consists of 1,000,000 randomly generated regexes (784,682 unique regexes)

over various alphabet sizes 2, 4, 6, 8, and 10.

• RegExLib2: consists of regexes collected from an online regex library where 4,149 regexes
are indexed from 2,818 contributors to help regex users write their own regexes more easily.
• Snort3: an open-source intrusion detection/prevention system, contains more than 1,200

regexes in its rule set for compactly describing malicious network trafﬁc.

• Polyglot Regex Corpus [Davis et al., 2019]: consists of 537,806 regexes extracted from
193,574 software projects written in eight popular programming languages. Introduced for
the research on regex portability problem.

For training the NeuralSplitter and evaluating our framework on practical regex benchmarks including
RegExLib, Snort and Polyglot Regex Corpus, we ﬁrst generate 20 random positive and 20 negative
examples for each regex and split the data into training, validation and test set with the ratio of 8:1:1.
Then, we collect the training and validation splits for three benchmarks for training the NeuralSplitter
model and use each test set for evaluating the regex synthesis performance on each benchmark.

Hyperparameters. We use two-layer bi-directional GRU with 256 hidden units unless explicitly
mentioned otherwise. The dimension of input token embedding is four. The Adam optimizer is used
with batch size 512 and learning rate of 0.001 and weight decay of 1e-6.

Baselines. We take the following baseline methods for regex synthesis from examples.

• AlphaRegex [Lee et al., 2016, Kim et al., 2021]: a best-ﬁrst search based regex enumeration
algorithm. We use our own Python implementation of AlphaRegex algorithm, which is
originally written in OCaml4 together with the recent search space reduction techniques by
Kim et al. [2021].

• RegexGenerator++ [Bartoli et al., 2014, 2016]: a regex inference algorithm based on genetic
programming. Due to the nature of the genetic inference procedure, this is the slowest among
the baselines.

• Blue-Fringe algorithm [Lang et al., 1998]: a classical state-merging DFA induction algorithm.
We choose this algorithm to show the generality of our framework on classical synthesizers
such as L∗ [Angluin, 1987] or RPNI [Oncina and García, 1992].

Note that we also use these baselines as off-the-shelf regex synthesizers for our SplitRegex framework
to evaluate the performance boost gained by our framework.

Metrics. We evaluate the performance of the proposed approach in two main aspects: 1) the time
efﬁciency of the synthesis algorithm and 2) the accuracy of synthesized regexes. For evaluating
the time efﬁciency, we set a time budget, speciﬁed by a timeout value. We set the timeout value to
3 (seconds) for AlphaRegex and Blue-Fringe algorithm and 10 (seconds) for RegexGenerator++ in
our experiments. A regex synthesis is counted as a success if an algorithm ﬁnds a regex satisfying
given positive and negative examples within the speciﬁed timeout. We measure the success rate of
regex synthesis by counting the number of successes in n regex synthesis trials where n is the number
of target regexes in the test set.

Meanwhile, we also need to measure the accuracy of synthesized regexes as any algorithm may
generate a trivial solution that only recognizes positive examples. However, we cannot simply count
the number of cases where the synthesized regex is ‘literally’ equivalent to the target regex as
two different regexes can capture the same set of strings as there are inﬁnitely many semantically
equivalent regexes. Hence, we need to introduce a criterion that considers how two regexes are
semantically similar. While it is well-known that it is possible to algorithmically decide whether two

2https://www.regexlib.com/
3https://www.snort.org/
4https://github.com/kupl/AlphaRegexPublic

7

Table 1: Regex synthesis performance (success rate, semantic regex accuracy, and the ratio of fully
accurate regexes) of our model and baselines over three benchmark regex datasets. ‘AR’, ‘BF’, and
‘RG’ are abbreviations for AlphaRegex, Blue-Fringe, and RegexGenerator++, respectively.

Method

AlphaRegex
Ours (+ AR)
GT Split (+ AR)
RegexGenerator++
Ours (+ RG)
GT Split (+ RG)
Blue-Fringe
Ours (+ BF)
GT Split (+ BF)

Snort
RegExLib
Succ. Acc. Full.
Succ. Acc. Full.
15.74 15.29 13.31
13.87 13.41 11.80
71.23 66.83 54.45
22.87 21.33 17.24
87.53 83.20 69.35
43.48 40.62 31.49
0.00
0.00
0.00
0.00
0.00
0.00
3.28
5.42
6.09
2.06
2.29
2.34
5.72
8.47
2.25
2.89
3.00
9.18
0.00 100.00
3.61
0.09 100.00
100.00
3.87
2.44
1.22
85.66 16.68
97.47 19.93
2.91
1.97 100.00 22.04
90.72 20.16

Polyglot Corpus
Succ. Acc. Full.
50.05 49.20 46.39
64.10 62.46 56.79
70.57 67.94 59.61
0.19
0.19
0.19
17.34 17.17 16.40
17.90 17.58 16.40
0.28
7.38
1.59
97.19 15.88
1.69
99.34 16.37

regexes represent the same language, it is also well-known that the decision process is PSPACE-
complete [Stockmeyer and Meyer, 1973] and therefore probably intractable.

Therefore, we deﬁne a metric called the semantic regex accuracy that utilizes randomly generated
positive and negative examples that are not used for regex synthesis. Remark that the semantic
regex accuracy has been already employed in previous work for evaluating the generated regexes [Li
et al., 2021]. Given a pair (P, N ) of positive and negative sets reserved for evaluation, we deﬁne the
semantic regex accuracy as follows:

sem_acc(R, P, N ) =

|TP | + |TN | − |FP | − |FN |
|P | + |N |

× 100,

where TP = {w ∈ L(R) | w ∈ P }, TN = {w /∈ L(R) | w ∈ N }, FP = {w /∈ L(R) | w ∈ P } and
FN = {w ∈ L(R) | w ∈ N }.

Intuitively, the semantic regex accuracy is higher if the synthesized regex recognizes more strings
recognizable by the target regex and rejects more strings not recognizable by the target regex. Note
that we choose semantic regex accuracy as our main evaluation metric instead of other metrics
such as F1-score, Matthews correlation coefﬁcient (MCC), and Cohen’s kappa, since our dataset is
completely balanced (same number of positive and negative examples) and our metric is easier to
understand intuitively.

Finally, we deﬁne a synthesized regex to be fully accurate if the regex satisﬁes all the unseen examples.
In other words, a regex is fully accurate if the semantic regex accuracy is 1.

5 Experimental Results and Analysis

We demonstrate the experimental results to show the effectiveness of the proposed approach compared
to baselines and analyze the results.

5.1 Main Results

Table 1 shows the main result of our paper. We evaluate our approach with the baselines in terms of
success rate, semantic accuracy, and the ratio of fully accurate regexes using reserved examples.

In order to examine the upper bound on the performance of SplitRegex, we also consider a variant of
SplitRegex called ‘GT Split’ where we use ground-truth splits of regexes instead of predicted splits
by NeuralSplitter. It is readily seen that the proposed framework substantially improves all of the
success rate, semantic accuracy, ratio of fully accurate regexes in most benchmarks except some
cases. First, the success rate of the Blue-Fringe algorithm is the highest among all the considered
algorithms due to the nature of the Blue-Fringe algorithm. Note that the Blue-Fringe algorithm merges
the sufﬁxes of given positive examples while assuming that any string the expression represents is
positive unless there is a counterexample—a negative example. While the Blue-Fringe algorithm
can simply generate a regex satisfying the examples very quickly, the generated regex represents a

8

Table 2: Comparisons of different regex synthesis method using split positive examples.

Synthesis Strategy

On Random Regexes On Practical Regexes
Success Rate Accuracy Success Rate Accuracy

Baseline (AlphaRegex)
Preﬁx-conditioned synthesis
Independent parallel synthesis
Independent sequential synthesis

47.57
63.90
42.00
64.60

44.83
60.50
40.40
61.68

12.90
37.60
54.50
55.84

13.08
36.94
54.34
55.20

slightly larger set of strings than the set of positive examples in general. This means that the regex
generated by Blue-Fringe rarely accepts positive examples that are not used in the regex synthesis
process. However, when the SplitRegex framework is combined with Blue-Fringe, the semantic
accuracy is improved even though it fails to return solutions for some cases due to additional runtime
overhead and inappropriate splits caused by neural network computations. The main reason is that
the process of splitting examples already makes the resulting regexes more ﬁne-grained compared to
those generated by the vanilla Blue-Fringe.

The performance on RegexGenerator++ is very low across all experiments mostly due to the repetitive
nature of the genetic approach and class-level generation. RegexGenerator++ only supports character
classes such as [a-z] and \d, and does not support each symbol in the classes. For instance, if
we provide positive strings {a, aa} and negative strings {b, bb}, then RegexGenerator++ fails to
generate a correct answer. Indeed, RegexGenerator++ fails to generate regexes in most cases even
with a larger time limit (10 seconds). Nevertheless, we can see that the proposed framework helps
RegexGenerator++ succeed in a few more cases compared to the vanilla RegexGenerator++.

Figure 2: Results on random regular expression dataset with different alphabet sizes.

5.2 Detailed Analysis

Alphabet size. Figure 2 shows how the SplitRegex framework affects the regex synthesis per-
formance of AlphaRegex and Blue-Fringe algorithms on random dataset with different alphabet
sizes. While the success rate decreases as the alphabet size increases for AlphaRegex, SplitRegex
effectively improves the success rate as the alphabet size increases. Moreover, the semantic accuracy
of synthesized regexes is also improved when the SplitRegex is applied to both baselines. This is
because it is easier to group the similar substrings using common symbols as there are more symbols
in a string. For example, two regexes abc ∗ d?(e + f) and 000 ∗ 1?(0 + 1) are similar in terms of
length and structure but it is easier to ﬁnd correct split from the examples generated from the former
as we can infer where each symbol in the examples comes from more easily.

Subregex synthesis strategies. We conduct additional experiments to verify whether the ‘preﬁx-
conditioned synthesis’ strategy can be utilized for every subsequent subregexes while we utilize only
for synthesizing the last subregex. Moreover, we also test whether the ﬁrst n − 1 subregexes (when the
split size is n) can be synthesized in parallel if the preﬁx-conditioned synthesis is not used. Table 2
demonstrates the experimental results on random regexes and practical regexes from RegExLib, Snort,
and Polyglot corpus datasets. The results imply that the simplest approach (independent sequential

9

246810AlphabetSize5060708090100Success RatioMethodAlphaRegexBlue-FringeSplitRegex (+AR)SplitRegex (+BF)246810AlphabetSize010203040506070Semantic AccuracyMethodAlphaRegexBlue-FringeSplitRegex (+AR)SplitRegex (+BF)synthesis except for the ﬁnal subregex) achieves the best performance compared to the parallel
approach and preﬁx-conditioned synthesis approach.

6 Conclusions

In this paper, we have proposed a regex synthesis framework called the SplitRegex that synthesizes a
regex from given positive and negative examples based on the divide-and-conquer paradigm. Given a
set of positive examples, we predict the most probable splits for strings such that substrings in the
same partition exhibit similar patterns using a neural network called the NeuralSplitter. Then, we
synthesize subregexes for all partitions and derive the ﬁnal regex satisfying the input examples. Our
experimental results show that the proposed scheme is very effective in reducing the time complexity
of regex synthesis and actually yields more accurate regexes than the previous approaches.

References

Rajeev Alur, Arjun Radhakrishna, and Abhishek Udupa. Scaling enumerative program synthesis
via divide and conquer. In Axel Legay and Tiziana Margaria, editors, Tools and Algorithms for
the Construction and Analysis of Systems - 23rd International Conference, TACAS 2017, volume
10205 of Lecture Notes in Computer Science, pages 319–336, 2017.

Dana Angluin. Learning regular sets from queries and counterexamples. Information and Computa-

tion, 75(2):87–106, 1987.

Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly
learning to align and translate. In 3rd International Conference on Learning Representation, ICLR
2015, 2015.

Shraddha Barke, Hila Peleg, and Nadia Polikarpova. Just-in-time learning for bottom-up enumerative

synthesis. Proc. ACM Program. Lang., 4(OOPSLA), 2020.

A. Bartoli, G. Davanzo, A. De Lorenzo, E. Medvet, and E. Sorio. Automatic synthesis of regular
expressions from examples. Computer, 47(12):72–80, dec 2014. ISSN 1558-0814. doi: 10.1109/
MC.2014.344.

Alberto Bartoli, Andrea De Lorenzo, Eric Medvet, and Fabiano Tarlao. Inference of regular expres-
sions for text extraction from examples. IEEE Trans. on Knowl. and Data Eng., 28(5):1217—-1230,
May 2016.

Qiaochu Chen, Xinyu Wang, Xi Ye, Greg Durrett, and Isil Dillig. Multi-modal synthesis of regular
expressions. In Proceedings of the 41st ACM SIGPLAN Conference on Programming Language
Design and Implementation, pages 487–502, 2020.

James C. Davis, Louis G. Michael IV, Christy A. Coghlan, Francisco Servant, and Dongyoon Lee.
Why aren’t regular expressions a lingua franca? an empirical study on the re-use and portability
of regular expressions. In Marlon Dumas, Dietmar Pfahl, Sven Apel, and Alessandra Russo,
editors, Proceedings of the ACM Joint Meeting on European Software Engineering Conference
and Symposium on the Foundations of Software Engineering, ESEC/SIGSOFT FSE 2019, pages
443–454. ACM, 2019.

Azadeh Farzan and Victor Nicolet. Counterexample-guided partial bounding for recursive function
synthesis. In Alexandra Silva and K. Rustan M. Leino, editors, Computer Aided Veriﬁcation - 33rd
International Conference, CAV 2021, Virtual Event, July 20-23, 2021, Proceedings, Part I, volume
12759 of Lecture Notes in Computer Science, pages 832–855. Springer, 2021a.

Azadeh Farzan and Victor Nicolet. Phased synthesis of divide and conquer programs. In Stephen N.
Freund and Eran Yahav, editors, PLDI ’21: 42nd ACM SIGPLAN International Conference on
Programming Language Design and Implementation, Virtual Event, Canada, June 20-25, 20211,
pages 974–986. ACM, 2021b.

E. Mark Gold. Complexity of automaton identiﬁcation from given data. Information and Control, 37

(3):302–320, 1978.

10

Su-Hyeon Kim, Hyeonseung Im, and Sang-Ki Ko. Efﬁcient enumeration of regular expressions for
faster regular expression synthesis. In Sebastian Maneth, editor, Implementation and Application
of Automata, pages 65–76. Springer International Publishing, 2021.

Nate Kushman and Regina Barzilay. Using semantic uniﬁcation to generate regular expressions from
natural language. In Proceedings of the 2013 Conference of the North American Chapter of the
Association for Computational Linguistics: Human Language Technologies, pages 826–836, 2013.

Kevin J. Lang, Barak A. Pearlmutter, and Rodney A. Price. Results of the abbadingo one DFA
learning competition and a new evidence-driven state merging algorithm. In Vasant G. Honavar
and Giora Slutzki, editors, Grammatical Inference, 4th International Colloquium, ICGI-98, Ames,
Iowa, USA, July 12-14, 1998, Proceedings, volume 1433 of Lecture Notes in Computer Science,
pages 1–12. Springer, 1998.

Juho Lee, Yoonho Lee, Jungtaek Kim, Adam R. Kosiorek, Seungjin Choi, and Yee Whye Teh. Set
transformer: A framework for attention-based permutation-invariant neural networks. In Kamalika
Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings of the 36th International Conference
on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, volume 97 of
Proceedings of Machine Learning Research, pages 3744–3753. PMLR, 2019.

Mina Lee, Sunbeom So, and Hakjoo Oh. Synthesizing regular expressions from examples for
introductory automata assignments. In Proceedings of the 2016 ACM SIGPLAN International
Conference on Generative Programming: Concepts and Experiences, GPCE 2016, pages 70—-80,
2016.

Yeting Li, Zhiwu Xu, Jialun Cao, Haiming Chen, Tingjian Ge, Shing-Chi Cheung, and Haoren Zhao.
Flashregex: Deducing anti-redos regexes from examples. In Proceedings of the 35th IEEE/ACM
International Conference on Automated Software Engineering, ASE ’20, pages 659—-671, 2020.

Yeting Li, Shuaimin Li, Zhiwu Xu, Jialun Cao, Zixuan Chen, Yun Hu, Haiming Chen, and Shing-Chi
Cheung. TransRegex: multi-modal regular expression synthesis by generate-and-repair. In 43rd
IEEE/ACM International Conference on Software Engineering, ICSE 2021, Madrid, Spain, 22-30
May 2021, pages 1210–1222. IEEE, 2021.

Nicholas Locascio, Karthik Narasimhan, Eduardo DeLeon, Nate Kushman, and Regina Barzilay.
Neural generation of regular expressions from natural language with minimal domain knowledge.
In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,
pages 1918–1923, 2016.

J. Oncina and P. García. Inferring Regular Languages In Polynomial Updated Time, pages 49–61.

1992.

Rong Pan, Qinheping Hu, Gaowei Xu, and Loris D’Antoni. Automatic repair of regular expressions.

Proc. ACM Program. Lang., 3(OOPSLA), 2019.

Jun-U Park, Sang-Ki Ko, Marco Cognetta, and Yo-Sub Han. SoftRegex: Generating regex from
In Proceedings of the 2019
natural language descriptions using softened regex equivalence.
Conference on Empirical Methods in Natural Language Processing and the 9th International Joint
Conference on Natural Language Processing (EMNLP-IJCNLP), pages 6425–6431, 2019.

Aarne Ranta. A multilingual natural-language interface to regular expressions. In Proceedings of the
International Workshop on Finite State Methods in Natural Language Processing, pages 79–90,
1998.

Disha Shrivastava, Hugo Larochelle, and Daniel Tarlow. Learning to combine per-example solutions
for neural program synthesis. CoRR, abs/2106.07175, 2021. URL https://arxiv.org/abs/
2106.07175.

Larry J Stockmeyer and Albert R Meyer. Word problems requiring exponential time (preliminary
report). In Proceedings of the ﬁfth annual ACM symposium on Theory of computing, pages 1–9,
1973.

Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks.

In Advances in neural information processing systems, pages 3104–3112, 2014.

11

Zexuan Zhong, Jiaqi Guo, Wei Yand, Tao Xie, Jian-Guang Lou, Ting Liu, and Dongmei Zhang. Gen-
erating regular expressions from natural language speciﬁcations: Are we there yet? In Workshops
at the 32nd AAAI Conference on Artiﬁcial Intelligence, pages 791–794, 2018a.

Zexuan Zhong, Jiaqi Guo, Wei Yang, Jian Peng, Tao Xie, Jian-Guang Lou, Ting Liu, and Dongmei
Zhang. Semregex: A semantics-based approach for generating regular expressions from natural
language speciﬁcations. In Proceedings of the 2018 Conference on Empirical Methods in Natural
Language Processing, pages 1608–1618, 2018b.

12

A Background

Here we provide some background knowledge on the basic neural network architectures used in our
model.

Recurrent neural networks. An RNN is described by a function that takes an input xt and
a hidden state ht−1 at time step t − 1 and returns a hidden state ht at time step t as follows:
ht = RNN(xt, ht−1).

Given an input sentence x = (x1, x2, . . . , xn), an encoder RNNenc plays its role as follows: ht =
RNNenc(xt, ht−1) where ht ∈ Rd is a hidden state at time t. After processing the whole input
sentence, the encoder generates a ﬁxed-size context vector that represents the sequence as follows:
c = q(h1, h2, . . . , hn).

Usually, q simply returns the last hidden state hn in one of the original sequences to sequence paper
by Sutskever et al. [2014]. Since the initial hidden state h0 is usually randomly initialized, we simply
deﬁne RNN as a function that takes sequence x and produces a vector c as follows: c = RNN(x).

Now suppose that y = (y1, y2, . . . , ym) is an output sentence that corresponds to the input sentence
x in training set. Then, the decoder RNN is trained to predict the next word conditioned on all the
previously predicted words and the context vector from the encoder RNN. In other words, the decoder
computes a probability of the translation y by decomposing the joint probability into the ordered
conditional probabilities as follows:

p(y) =

m
(cid:89)

i=1

p(yi|{y1, y2, . . . , yi−1}, c).

Now our decoder RNNdec computes each conditional probability as follows:

p(yi|y1, y2, . . . , yi−1, c) = softmax(W (cid:62) · si),
where si ∈ Rd is the hidden state of decoder RNN at time i and W ∈ Rd×|V | is a linear transformation
that outputs a vocabulary-sized vector. Note that the hidden state si is computed by

si = RNNdec(yi−1, si−1, c),

where yi−1 is the previously predicted word, si−1 is the last hidden state of decoder RNN, and c is
the context vector computed from encoder RNN.

Attention mechanism.
In order to resolve the long-range dependency problem in the sequence-to-
sequence model, Bahdanau et al. [2015] deﬁned each conditional probability at time i depending on
a dynamically computed context vector ci as follows:

p(yi|y1, y2, . . . , yi−1, x) = softmax(g(si)),

where si is the hidden state of the decoder RNN at time i computed by si = RNNdec(yi−1, si−1, ci).

The context vector ci is computed as a weighted sum of the hidden states from encoder: ci =
(cid:80)n

j=1 αijsj, where

αij =

exp(score(si, hj))
k=1 exp(score(sk, hj))

(cid:80)n

.

Here the function ‘score’ is called an alignment function that computes how well the two hidden
states from the encoder and the decoder, respectively, match. For example, score(si, hj), where si is
the hidden state of the encoder at time i and hj is the hidden state of the decoder at time j implies
the probability of aligning the part of the input sentence around position i and the part of the output
sentence around position j.

B Neural Network Architecture

Figure 3 depicts the neural network architecture of the ‘NeuralSplitter’ model. Note that both RNN
encoders used in our neural network are bi-directional.

13

Figure 3: Neural network architecture of the ‘NeuralSplitter’ model.

Table 3: Statistics of four benchmark datasets. Numbers in parentheses are the numbers of regexes in
original datasets and in front of the parentheses are the numbers of regexes used in our experiments.

Dataset

# of Regexes

Alphabet Size Max Length

Random
RegExLib
Snort
Polyglot Corpus

784,682
1,422 (3,072)
375 (1,254)
199,350 (537,800)

{2, 4, 6, 8, 10}
128
128
128

81
767
203
1,903

C Experimental Details

C.1 Statistics of Datasets

We refer the readers to Table 3 for the statistics of benchmark datasets. For random dataset, we
randomly generate in total 1,000,000 regexes independently where there are 200,000 regexes for each
alphabet size in {2, 4, 6, 8, 10}. The number of unique regexes is 784,682 as we allow duplicates in a
random generation.

Environment. We conduct experiments on a server equipped with Intel Core i7-8700K processor
with 6 cores, 48GB DDR4 memory, and NVIDIA GTX 1080 Ti GPU. We use the neural network
framework PyTorch for experiments.

D Additional Results

D.1 Performance of ‘Neural Example Splitting’

The performance of the NeuralSplitter model under different settings of hyperparameters and RNN
cell types is provided in Table 4. We deﬁne two metrics, ‘string accuracy’ and ’set accuracy’, for
evaluating the performance of neural example splitting. String accuracy is the ratio of correctly
labeled examples from ten positive examples for each test sample. Set accuracy means the ratio of
correctly labeled sets as a whole. If the NeuralSplitter correctly splits ten positive examples for a test
sample, then it is regarded as ‘correctly labeled’. It is notable that the NeuralSplitter performs better
on practical dataset which is apparently more complex than random dataset.

14

Example 1Example 2Example NExample 1 VectorExample N VectorExample 2 VectorEncoder  RNN 1Encoder  RNN 2 Set VectorSet VectorSet VectorExample 1 VectorExample N VectorExample 2 VectorSet VectorSet VectorSet VectorDecoder  RNN Predicetd Label 1Predicetd Label 2Predicetd Label NEncoder: encode positive examplesDecoder: predict split labels for input positive examplesDuplicatesAttention Layer Table 4: Split performance (%) of the NeuralSplitter under different settings of hyperparameters.

Dataset

RNN Cell

Dim.

# of Layers

String Acc.

Set Acc.

# of Parameters

GRU

Random

GRU + SetTF

LSTM

Practical

GRU

GRU + SetTF

128

256

384

256

256

128

256

384

256

1
2

2

2

2

2

1
2

2

2

2

56.29
58.74

58.45

57.15

59.55

59.20

74.50
76.64

77.06

75.17

74.97

36.60
39.76

40.20

38.24

39.70

39.80

65.54
68.29

68.48

66.97

65.07

1,107,018
2,094,666

8,121,162

18,079,818

6,392,010

10,292,042

1,107,018
2,094,666

8,121,162

18,079,818

6,392,010

As we ﬁnd no notable difference in LSTM and GRU cells in terms of performance when the other
hyperparameters are equivalent, we decide to use GRU instead of LSTM as GRU is known to
execute faster than LSTM with a less number of parameters. We also ﬁnd that the performance of the
NeuralSplitter is higher as we increase the number of hidden units and the number of layers to 256
and 2, respectively. We decide not to increase the number of parameters further as the computation
efﬁciency is also a very important metric in the task of regex synthesis.

We also utilize the Set Transformer Lee et al. [2019], which is introduced to effectively encode
permutation-invariant information, in the place of the second RNN encoder RNNenc2. However, we
do not ﬁnd a notable difference in the regex synthesis performance when the Set Transformer is
employed as shown in Table 4.

D.2 Performance Comparison with Different Timeout Values

Table 5 shows how the regex synthesis performance changes as the timeout value changes. We
perform regex synthesis with various timeout values 1, 2, 3, 5, and 10 seconds and measure the
success ratio and semantic accuracy of the proposed baselines including our approach. We do not
include RegexGenerator++ for comparison as it fails to synthesize regexes in most cases even with a
timeout value of 10 seconds. The result shows that Blue-Fringe algorithm succeeds in regex synthesis
within 1 second in most cases as the success rate and semantic accuracy do not increase with higher
timeout values.

On the other hand, AlphaRegex with and without our SplitRegex framework exhibits better regex
synthesis success rate and semantic accuracy as the timeout value increases.

D.3 Split vs Non-split

We evaluate the performance of our SplitRegex framework by comparing the results of regex synthesis
model with and without the SplitRegex framework for each test case. First, we present the number
of test cases that are exclusively solved by each method. ‘Win Ratio’ means the ratio of test cases
where each method performs better (synthesizes regex faster). We do not count the cases where both
methods fail to synthesize regexes when calculating ‘Win Ratio (%)’.

We also estimate the average amount of time taken for regex synthesis in two different cases. First,
‘Runtime (seconds)’ is the average amount of time taken for synthesizing regexes in all test cases. If
the method fails to synthesize a regex, then we consider it as ‘3 seconds’ which is the timeout value
used for this experiment. Second, ’Runtime for Success Cases (seconds)’ is the average amount of
time taken for synthesizing regexes in cases where both methods succeeds in synthesizing regexes.

15

Table 5: Regex synthesis performance (success rate and semantic regex accuracy) of our model and
baselines over four benchmark regex datasets under different timeout values. ‘AR’ is abbreviations
for AlphaRegex. ‘Random’ dataset consists of regular expressions over alphabet of size ten.

Method

Time.

Random

RegExLib

Snort

Polyglot

AlphaRegex
SplitRegex (+AR)

AlphaRegex
SplitRegex (+AR)

AlphaRegex
SplitRegex (+AR)

AlphaRegex
SplitRegex (+AR)

AlphaRegex
SplitRegex (+AR)

1

2

3

5

10

Succ.
34.67
58.33

41.00
66.00

45.67
67.67

51.00
72.67

55.00
74.00

Acc.
32.03
55.21

38.20
62.20

42.47
63.79

47.14
68.47

50.94
69.54

Succ.
9.67
20.00

12.33
20.67

13.00
21.33

14.00
21.67

19.00
22.00

Acc.
9.63
19.24

12.11
19.63

12.76
19.83

13.76
20.09

18.56
21.22

Succ.
8.33
71.67

9.00
72.67

13.67
73.00

14.33
73.67

16.00
74.33

Acc.
8.01
67.47

8.46
68.27

12.79
68.56

13.43
69.07

14.84
69.51

Succ.
42.67
64.00

46.33
64.67

51.00
65.67

53.67
66.33

57.33
66.33

Acc.
42.29
62.34

45.91
62.97

50.16
63.57

52.69
63.91

56.13
63.91

Table 6: Comparisons of regex synthesis performance of AlphaRegex algorithm with and without
SplitRegex framework on practical regex datasets.

Method

Success Ratio Win Ratio Runtime Runtime for Success Cases

AlphaRegex
SplitRegex (+AR)

25.77
46.10

20.82
79.18

2.4344
1.6622

0.1250
0.0088

Experimental results on practical regex datasets (RegExLib, Snort and Polyglot Corpus dataset) are
provided in Table 6. Results show that SplitRegex sufﬁciently improves the success ratio and reduces
runtime complexity taken for regex synthesis in almost 80% of test cases.

D.4 Using Negative Examples Generated from Randomly Perturbed Regexes

As we mentioned in the second paragraph of Section 3.3, we generate negative examples by randomly
substituting symbols from positive examples. We call this method ‘Symbol Perturb’ here.

In order to generate ‘harder’ negative examples, we introduce a noise at the level of regex and call the
method ‘Regex Perturb’. We perform the ‘Regex Perturb’ by randomly choosing one of the following
three manners: 1) Randomly substitute a symbol in the target regex, 2) Randomly insert a subregex
from the target regex, and 3) Randomly delete a subregex from the target regex.

Table 7 shows the results. We observe that our method shows better performance than the baseline
(AlphaRegex) for both cases. It is also seen that the ‘Regex Perturb’ generates harder negative
examples than ‘Symbol Perturb’ as the performance is lower for negative examples generated by
‘Regex Perturb’ in general.

D.5 Performance on Datasets from TransRegex [Li et al., 2021]

We conduct additional experiments on datasets—KB13 and NL-RX-Turk—used in TransRegex Li
et al. [2021], a previous work on the multi-modal regex synthesis from both natural language
descriptions and examples. We found that regexes used in our experiments are more complex and
use a larger set of symbols. The only difference is that some regexes from KB13 and NL-RX-Turk
have ‘and’ and ‘not’ operators that are not supported by the standard regex library (pyre2) used in
our experiments. For this reason, we conduct experiments on regexes from KB13 and NL-RX-Turk
without ‘and’ and ‘not’ operators. Table 8 shows the experimental results. We can see that the
performance of the proposed method is higher for NL-RX-Turx dataset but lower for KB13 dataset.
We speculate that the main reason of the poor performance on KB13 is the size of KB13 dataset. Note

16

Table 7: Comparisons of regex synthesis performance evaluated for negative examples generated
from randomly perturbed regexes.

Method

Symbol Perturb

Regex Perturb

AlphaRegex
SplitRegex (+AR)
GT Split (+AR)

Succ.

46.20
63.20
76.40

Acc.

Full.

Succ.

Acc.

Full.

42.60
59.72
73.78

28.40
45.30
61.90

24.00
38.75
57.75

22.70
36.25
54.53

17.50
29.00
44.75

Table 8: Regex synthesis performance of our model in datasets used in TransRegex [Li et al., 2021].

Method

KB13

NL-RX-Turk

AlphaRegex
SplitRegex (+AR)
GT Split (+AR)

Succ.

77.33
67.00
80.00

Acc.

Full.

Succ.

Acc.

Full.

77.33
66.94
80.00

77.33
66.66
80.00

51.33
55.66
72.00

50.53
55.54
71.80

48.33
55.00
71.00

that there are only 814 regexes in KB13 and we use only 440 regexes among the 814 regexes as the
rest of regexes have ‘and’ or ‘not’ that are not compatible with standard regex library.

D.6 Examples of neural splitting.

We observe that the NeuralSplitter predicts appropriate splits to infer regexes by parts. For an
example (See Table 9 in Appendix) of positive examples in the ‘Snort’ dataset is generated from a
regex ‘/images.*php?t=.*/U’, we can see that our NeuralSplitter model successfully splits positive
examples into ﬁve parts where similar strings are grouped together. As a result, SplitRegex produces
the following regex for the examples which is quite similar to the target regex: ‘/images.*php?t=[0-
9]*/U’.

In Table 10, we present additional examples of neural example splitting to exhibit the upper limit
on the hardness of regexes the proposed method cannot generate. Note that here the target regex is
‘Invalid.*(account|address|email|mailbox).*. Since we rely on at most 10 positive examples to
perform neural example splitting, it is difﬁcult to ﬁnd a split corresponding to the ‘union’ operator
with many subregexes.

D.7 Generalizability to Unseen Regex Dataset

Table 11 shows how well the proposed approach generalizes to new dataset. We train NeuralSplitter
only on the Polyglot Corpus, which is the largest regex dataset, and evaluate the performance on
different datasets RegExLib and Snort. Note that each dataset may have different characteristics. For
instance, Snort consists of regexes describing URLs as it is used for network intrusion detection
system. The result in Table 11 shows that the NeuralSplitter generalizes well to unseen regexes by
learning the general properties of regexes rather than domain-speciﬁc properties.

17

Table 9: Examples of neural example splitting.

Dataset

Input String

Split Result

RegExLib

uname=&pword=9E8
uname=!&pword=
uname=Hj%}v&pword=‘Af7= uname= Hj%}v
uname= _pp}C
uname=_pp}C&pword=Ht
uname= )#
uname=)#&pword=@k

uname=
uname= !

Snort

Polyglot

/images!php?t=6153/U
/images-php?t=296/U
/images4php?t=5213/U
/images{php?t=15/U
/imagesQphp?t=165/U

Invalid!v%alias@Z
InvalidaccountD#f
Invalid{pv_address
InvalidvSemail5 C
InvalidaH2‘mailboxvb4A

/images !
/images -
/images 4
/images {
/images Q

Invalid !v%alias@Z
Invalid accountD#f
Invalid {pv_address
Invalid vSemail5 C
Invalid aH2‘mailboxvb4A

&pword= 9E8
&pword=
&pword= ‘Af7=
&pword= Ht
&pword= @k

php?t= 6153 /U
php?t= 296 /U
php?t= 5213 /U
php?t= 15
/U
php?t= 165 /U

Table 10: Additional examples of neural example splitting.

Dataset

Input String

Split Result

Polyglot

Invalid!v%alias@Z
InvalidaccountD#f
Invalid{pv_address
InvalidvSemail5 C
InvalidaH2‘mailboxvb4A

Invalid
Invalid
Invalid
Invalid
Invalid

!v%alias@Z
accountD#f
{pv_address
vSemail5 C
aH2‘mailboxvb4A

Table 11: Regex synthesis performance of our model when only trained on Polyglot Corpus.

Method

RegExLib

Snort

Polyglot Corpus

Succ.

Acc. Full.

Succ.

Acc. Full.

Succ.

Acc. Full.

AlphaRegex
Ours (+ AR)

14.1
25.0

13.71
24.46

11.5
20.6

15.9
64.8

15.56
64.06

13.5
58.2

47.4
59.7

47.05
59.26

43.4
55.2

18

