2
2
0
2

n
u
J

3
1

]
c
q
-
r
g
[

1
v
4
0
0
6
0
.
6
0
2
2
:
v
i
X
r
a

A Novel Multi-Layer Modular Approach for Real-Time Gravitational-Wave Detection

F.P. Barone
Dipartimento di Fisica e Astronomia, University of Catania, Catania, Italy∗

D. Dell’Aquila
Dipartimento di Scienze Chimiche, Fisiche, Matematiche e Naturali, University of Sassari, Sassari, Italy and
INFN-Laboratori Nazionali del Sud, Catania, Italy

M. Russo
Dipartimento di Fisica e Astronomia, University of Catania, Catania, Italy∗ and
INFN-Sezione di Catania, Catania, Italy
(Dated: June 14, 2022)

Advanced LIGO and Advanced Virgo ground-based interferometers are poised to probe an un-
precedentedly large volume of space, enhancing the discovery power of the observations to even
new sources of gravitational wave emitters. In this scenario, the development of highly optimized
gravitational wave detection algorithms is crucial. We propose a novel layered framework for real-
time detection of gravitational waves inspired by speech processing techniques and, in the present
implementation, based on a state-of-the-art machine learning approach involving a hybridization of
genetic programming and neural networks. The key aspects of the newly proposed framework are:
the well structured, layered approach, and the low computational complexity. The paper describes
the basic concepts of the framework and the derivation of the ﬁrst three layers. Even if, in the
present implementation, the layers are based on models derived using a machine learning approach,
the proposed layered structure has a universal nature. To train and test the models, we used simu-
lated binary black hole gravitational wave waveforms in synthetic Gaussian noise representative of
Advanced LIGO sensitivity design. Compared to more complex approaches, such as convolutional
neural networks, our framework, even using the simple ground model described in the paper, has
similar performance but with a much lower computational complexity and a higher degree of modu-
larity. Furthermore, the underlying exploitation of short-term features makes the results of the new
framework virtually independent against time-position of gravitational wave signals, simplifying its
future exploitation in real-time multi-layer pipelines for gravitational-wave detection with second
generation interferometers.

I.

INTRODUCTION

During the last decade, the Advanced Laser Interfer-
ometer Gravitational-Wave Observatory (aLIGO) [1] has
set in motion the era of gravitational wave astrophysics
through the ﬁrst direct detection of a gravitational wave
[2]. Gravitational waves (GWs) have now become a
new, key, means to understand our Universe, leading to
a series of fundamental discoveries. For example, the
detection of GW150914 made it possible, for the ﬁrst
time, to observe a binary black hole (BBH) merger [3–
5], giving also the unique opportunity to quantitatively
test the predictions of general relativity for the motion
of a compact-object binary in the large-velocity, highly-
nonlinear regime [4, 6–8].

Alongside with the two aLIGO interferometers, by the
end of the second aLIGO discovery campaign (O2), the
European Advanced Virgo (aVirgo) detector [9] took part
in the GW detection network. The availability of an
international, second generation, three-detector network
had a crucial role in the detection, with improved sky

∗ F.P. Barone was with the University of Catania. He is now with
the Dipartimento di Fisica e Astronomia, University of Padua.

location, of numerous GW events which were found to
be consistent with the coalescence of BBH mergers (see
e.g. GW170814, GW170823, GW171014, GW190521
[10–12]). Such recent discoveries have allowed to infer the
population of BBHs with total masses from about 19M(cid:12)
to 84M(cid:12), and component masses from 8 to 50M(cid:12). [11–
13], while events possibly consistent with heavier BBHs
were also recently reported [14–16].

Besides the identiﬁcation of GW events conﬁdentially
interpreted as due to BBH mergers, GW170817 is so
far the only GW detection linked to the coalescence of
two neutron stars (BNS) [17]. This event was followed
up by the detection of its electromagnetic counterpart,
GRB170817A [18, 19], leading to the ﬁrst direct conﬁr-
mation that neutron star mergers are the progenitors of
gamma-ray bursts. This unique joint detection has inau-
gurated the era of multi-messenger astronomy, a strongly
multi-disciplinary research ﬁeld at the interface of exper-
imental and theoretical physics.

The second generation of GW detectors is now poised
to signiﬁcantly enhance the sensitivity of the observa-
tions to a much larger search volume [20] and to pos-
In addition, one of
sibly yet unmodeled GW sources.
the major goals of the community is that of enabling fu-
ture multi-messenger observations with the joint eﬀort of
other astronomical facilities [21–25]. In this framework,

 
 
 
 
 
 
the development of new, fast, methods to detect GW
transients is crucial, not only to enable the observation
of multi-messenger events, but also to help deepen the
parameter space of astrophysical searches [26].

There are two main classes of algorithms convention-
ally used to search for GW transients in ground-based in-
terferometers: matched-ﬁltering algorithms [27–29] and
coincident excess-power searches [30–33]. The ﬁrst class
of algorithms usually relies on a number of previously
modeled waveforms, which constitute a so called tem-
plate bank. They are particularly eﬀective to detect well-
modeled GW transients, but have poor interpolation ca-
pabilities between templates and cannot eﬃciently ex-
trapolate outside of the parameter space covered by the
template bank. Furthermore, they are typically compu-
tationally costly, and their computational complexity in-
creases with the number of templates to test. For this
reasons, there are ongoing eﬀorts to try to reduce the
size of template banks, in order to accelerate the oﬄine
parameter estimation via matched-ﬁltering [26]. The sec-
ond class of methods allows instead to identify even un-
modeled or weakly modeled waveforms, as they are often
treated as free parameters of a likelihood formalism [31].
It has been recently proven that state-of-the-art deep
learning artiﬁcial intelligence techniques can help to fa-
cilitate the search for GWs with second-generation in-
terferometers [34–36]. In particular, novel convolutional
neural networks (CNNs) turned out to be ideal to model
matched-ﬁltering algorithms in the search of inspiral-
merger-ringdown BBH waveforms [34, 35, 37]. This class
of algorithms is promising as it allows to signiﬁcantly re-
duce the size of template banks while emulating the per-
formance of matched-ﬁltering searches [35]. Compared
to matched-ﬁltering, CNNs can interpolate between the
templates used to derive the model and have more robust
generalization capabilities [37]. Unfortunately, their re-
sults strongly depend on the time position of the wave-
form within the analyzed time window, making challeng-
ing their use in real applications characterized by a con-
tinuous data streams. Given that machine learning (ML)
techniques are extremely promising to help the detection
of GWs in state-of-the-art experiments, it is interesting
to try to derive new algorithms, alternative (and com-
plementary) to those based on CNNs, more suitable to
be used in continuous data stream applications and more
robust against the completeness of the template banks.
In addition, the modularity of the approach is also an el-
ement to be seriously taken into account. As well known
in other ﬁelds, such as computer internetworking and op-
erative systems, modularity simpliﬁes research and devel-
opment and makes it possible to more easily improve the
performance of the system with even continuous devel-
opments.

In this paper, we introduce a novel ML approach for
real-time detection of GWs in second generation ground-
based interferometers based, for the ﬁrst time in this re-
search ﬁeld, on a short-term, layered, approach inspired
by speech processing techniques. The paper describes the

2

basic concepts of the framework and proposes a possible
low-complexity ground model, which is ideal to be used
in the ﬁrst layer of our approach. We also describe the
detailed derivation of two possible models for the inter-
pretation of the results of the ﬁrst layer, which serve to
build two possible versions of the second layer, and dis-
cuss the possible implementation of a third (ﬁnal ) layer,
which would issue the interferometer alerts.

In the newly proposed approach, data segments from
GW detectors are suitably subdivided into smaller, over-
lapped, frames, where numerical features derived from
speech processing are calculated. ML techniques can be
then used to derive a model, exploited by the ﬁrst layer
of the approach, capable to link numerical features to a
fuzzy output that represents the presence of a GW. Each
successive layer exploits the output of the previous layer
and a dedicated model for its analysis.

To derive the ground model presented here, we adopted
state-of-the-art symbolic regression techniques [38, 39].
In this way, the derived model has an analytical formu-
lation and is particularly suitable for highly-optimized
implementations. The underlying methods rely on a hy-
bridization of evolutionary computing and Neural Net-
Such techniques are well-developed in
works (NNs).
other research ﬁelds (see e.g. Refs. [40–43]) but were
not previously proposed for GW searches. The model
described in this paper, and used in the ﬁrst layer, is
trained and tested exploiting a bank of simulated BBH
waveforms [44, 45] in synthetic Gaussian noise, produced
according to the aLIGO design sensitivity curve previ-
ously used in [35]. The choice of assuming stationary
the instrumental noise is a simpliﬁed hypothesis to facil-
itate the comparison with previous ML approaches pub-
lished in the literature [34, 35, 37]. We demonstrate that
our framework, even using the simple ground model de-
scribed in the paper, can achieve a similar performance,
in identifying GW signals, than other tools based ex-
clusively on CNNs, but with some key advantages: (1)
no hypothesis is made on the time position of the wave-
form in the stream, facilitating the future implementa-
tion of the framework in continuous searches; (2) with
the proposed ﬁrst and second layers, the framework re-
lies only on an extremely reduced number of numerical
features, making it suitable for highly-optimized imple-
mentations in real-time applications; (3) the approach is
layered, allowing a larger degree of versatility and mak-
ing the framework ideal to be integrated even in existing
pipelines for online analysis.

The paper is organized as follows, Section II contains a
general description of the proposed framework and sym-
bolism; Section III describes the derivation of the ground
model (used in the ﬁrst level of the framework), including
assumptions, dataset, numerical features and the artiﬁ-
cial intelligence approach used to derive the model, in
addition, we also provide its analytical formulation; in
Section IV, we describe the second level of the framework,
which is to analyze the results of the ground model, and
compare the accuracy of our approach against that ob-

tained by state-of-the-art models. Finally, Section V is to
summarize our ﬁndings and discuss their impact on the
design of future pipelines for real-time analysis of GWs,
including a possible implementation of a third level.

II. THE FRAMEWORK: GENERAL
OVERVIEW, SYMBOLS, APPROACH

Gravitational wave interferometer data are usually
characterized by a loud and persistent background noise,
which makes particularly challenging the identiﬁcation of
candidate GW signals. The ultimate goal of the newly
proposed framework is to perform a real-time analysis of
a continuous stream of interferometer data in a versatile
and computationally convenient way.

Let us indicate with local analysis a GW search re-
stricted to a certain frame, of ﬁxed length, of the data
stream. This could be done through a suitable model
trained, with a ML approach, to determine whether or
not a GW signal is present within the given frame. An
extension from a local to a continuous analysis, which is
more realistic for a real interferometer, usually involves
exploiting the local results on several moving windows
[37]. Local classiﬁcation is therefore a good starting point
for the successive continuous implementation using mov-
ing windows. Previous applications with ML-based tech-
niques [34, 35, 37] have mainly focused to locally distin-
guish noise-only segments from data segments containing
a gravitational wave signal, assuming that only station-
ary noise is present. The derived models had outstand-
ing classiﬁcation capabilities in local analysis cases, given
that the position of the maximum of the BBH waveform
amplitude is well-placed in a given fractional range of
the window interval, usually with a width of the order
of 20% of its entire length. For this reason, it is diﬃ-
cult to predict the outcome of these models in a real use
case, where one has a continuous timeseries analyzed in
moving windows, in which the peak amplitude is often
outside of such fractional range.

The concept proposed in this paper is a multi-layer
framework, where the ﬁrst layer relies on short-term fea-
tures, extracted from the interferometer timeseries, and
each successive layer reﬁnes the information of the previ-
ous layer. Compared to previously published CNNs mod-
els, the use of short-term information, other than com-
plex vectors of raw data, allows to avoid assumptions on
the peak amplitude position even for local analysis cases.
The layered structure of the proposed framework is in-
spired by a paradigm typically used in the engineering of
communication and/or operative systems. Layering, for
example, provides a distinct advantage in an operating
system. The inner structure of each layer can be deﬁned
separately, given that the i/o is ﬁxed, and layers can in-
teract with each other as required. This is crucial to more
easily create, maintain and update the system. Perform-
ing a change in one layer, for example an improvement
of its performance, does not aﬀect the lower lying layers,

3

FIG. 1. The basic structure of the multi-layer framework
proposed in this paper. Levels 1-3 perform an analysis of
the timeseries starting from short-term features inspired by
speech processing. Level 3 issues an interferometer alert. The
latter can be fed into a hypothetical level 4, which would
identify coincident alerts in an interferometer network, issuing
a global network alert.

the successive layers or both.
In a similar framework,
each layer virtualizes the underlying level and gives more
reﬁned information to the successive level.

Our framework is composed by several distinct layers,
as schematically described in Fig. 1. In our solution, if a
given layer is changed, only the successive (upper) levels
may be aﬀected. Level 1 performs the extraction of short
term features and utilizes a previously trained model to
predict the content of each short data frame in which the
timeseries is analyzed. For each set of short-term fea-
tures, related to a given data frame, an output value is
thus produced and passed to the second layer. Level 2 an-
alyzes a ﬁxed number of consecutive output values from
level 1 through a suitable interpretation model. This
layer, in turn, performs the local classiﬁcation of data
segments, similarly to what CNN models do starting di-
rectly from the raw timeseries in the entire moving win-
dow. The output of level 2 is a vector of moving window
predictions, which is ﬁnally analyzed by level 3 to issue
the inteferometer alert. This does not account for coin-
cident information from other interferometers. The false
alarm rate could be drastically reduced by a hypothetical
level 4, which would collect level 3 output for an inter-
ferometer network and search for coincident alerts, thus
issuing a deﬁnitive network alert.

In this paper, we mainly focus on the detailed imple-
mentation of the ﬁrst two layers of the framework, which
deal with the local analysis of the timeseries. The re-
sulting classiﬁcation capabilities, which are only valid for
local segments, can be easily compared with CNNs mod-
els. We also suggest a possible implementation for the
third level, but, for the sake of clarity, we postpone its
full description to a, future, dedicated paper. To easily

level 1level 2level 3level 4fuzzy miniframe classifiergeneral continuous moving window filternetwork coincidence analyzerfixed continuous moving window filterother interferometersinterferometer alertnetwork alertother interferometer alertcompare the capabilities of our framework with previous
CNN approaches, we restrict our analysis to BBH signals
and we assume that the interferometer noise is station-
ary. This is a simpliﬁcation previously introduced in a
number of studies (see e.g.
[34, 35, 37] and references
therein).

A. Level 1 design

The ﬁrst level exploits an approach derived from
speech processing techniques. The very ﬁrst step is
considering a continuous signal in smaller, overlapped,
short data frames of predeﬁned length (miniframes, here-
after). After preliminary tests, we settled on a opti-
mal miniframe size of ωf = 100ms, with an overlap of
σf = 50ms. Each miniframe is directly processed by
the ﬁrst level through a speciﬁc model, which we call
ground model. The ground model is a miniframe fuzzy
classiﬁer, which is trained to distinguish between noise-
only miniframes (null hypothesis, negative output of the
classiﬁer) and miniframes containing a BBH signal (al-
ternative hypothesis, positive output of the classiﬁer),
exploiting numerical features calculated from the data of
a given miniframe. The ground model is trained to re-
turn an output closer to 1 if a GW is present inside the
miniframe, and closer to 0 if that is a noise-only pattern.
A more detailed discussion of the ground model, includ-
ing all details of its derivation, is provided in Section III.

B. Upper levels design

The second level of the framework does not have di-
rect access to the original data segment coming from the
continuous stream. Instead, the signal is basically trans-
lated into a sequence of numerical values provided by the
ﬁrst layer. The stream of output values passed by the
ﬁrst level to the second level requires a dedicated inter-
pretation. In this paper, we propose two possible level
2 layers (modules, in the modular philosophy), based on
two possible interpretation models of level 1 output. The
separation of the ground model derivation from its in-
terpretation is therefore a multi-modeling procedure (see
Sect. IV A)). A strong edge of such an approach is the ab-
sence of an a priory hypothesis about the GW transient
position within the data segment.

Level 2 analyzes the sequence returned by the ﬁrst
layer in ﬁxed chunks of nf frames (local analysis).
Its
purpose is the search for a GW transient speciﬁc pattern
in the space of values of the ﬁrst layer. We call this step
moving window analysis, because, at each iteration, the
nf miniframes selection moves forward by a deﬁned num-
ber of miniframes, usually σmw = 1. This layer is crucial
to the classiﬁcation because it looks at the signal features
in a wider time span, combining information on adjacent
frames. The output of level 2 is a stream of fuzzy-like or
strong integer predictions: 1 stands for a GW transient,

4

0 for noise. Ultimately, level 3 issues an interferometer
GW alert by analyzing, in a similar manner than that
used by level 2, the output of the second layer. A possi-
ble implementation of level 3 could, for example, identify
clusters of ones after thresholding the fuzzy-like values of
level 2. It is reasonable that clusters of ones will repre-
sent a GW in the input signal, as well clusters of zeros
will mark a noise-only sequence in the original timeseries.
The framework described above is an early imple-
mentation, but promising in the continuous analysis of
data, as it will be shown in Section IV. Once trained,
each framework level performs low complexity opera-
tions, thanks to the simplicity of the underlying models.
The ground model used in the proposed implementation
leads to a level-2 accuracy slightly lower than existing
state-of-the-art CNN approach, such as [35, 37], but it is
outstandingly computationally simple. This makes the
entire framework particularly suitable to be implemented
in real-time, low-latency, searches even on a single ma-
chine, thus avoiding parallel and distributed calculations
and related complications.

III. GROUND MODEL DERIVATION: THE
UNDERLYING LEVEL 1 MODEL

The ground model is the core of the entire framework,
as it is a fuzzy classiﬁer of short GW interferometer sig-
nals. In our framework, the ground model performs the
ground predictions on short data frames. The ground
model output is a continuous variable that varies in the
range [0, 1] (see Section III D). As mentioned before, the
latter can be interpreted as the fuzzy degree of belonging,
of the individual miniframe, to the GW signal class, i.e.
it is related to how likely the short data frame contains a
GW signal. Because the typical features of a GW signal
are contained in a succession of miniframes, other than in
a single short data segment, in order to produce a trigger,
it is required to interpret the output of the ground model
over a number of successive miniframes. This is even a
more critical task because of the large instrumental noise
level. For these reasons, successive layers are required.

The ground model is initially derived by using data
samples of 1 second length, either noise-only or noise-
prevailing GW inspiral samples are used, in a similar
way as done, for example, in Refs. [35, 37]. Therefore,
each data sample is subdivided in a given number of
overlapped miniframes of ﬁxed time length. For each
miniframe, a vector of features is extracted and processed
by a ML model, which is the ground model of the ap-
proach. After interpretation of model output, the ﬁnal
outcome is a prediction over the entire 1 second segment:
as stated before, we associate 1 to GW positive samples,
0 to noise-only samples.

The key for a good ground model lies in its low compu-
tational cost. The ground model proposed in this paper
meets by design this request.

The following subsections describe the derivation of

5

and ringdown [50–52]. As proven by [53], it is advanta-
geous to project the waveform onto spin-weighted spher-
ical harmonics prior to truncating the post-Newtonian
series of the numerical simulation. Given the asymp-
ij and a orthonormal triad ( (cid:126)N , (cid:126)P , (cid:126)Q) =
totic waveform hT T
((cid:126)eR, (cid:126)eΘ, (cid:126)eΦ), the polarization waveforms are

h+ =

h× =

1
2

1
2

(PiPj − QiQj)hT T
ij

(PiQj + PjQi)hT T
ij

which can be decomposed using spin-weighted spherical
harmonics of weight -2 as

h+ − ih× =

∞
(cid:88)

(cid:96)
(cid:88)

(cid:96)=2

m=−(cid:96)

−2Y (cid:96)m(Θ, Φ).
h(cid:96)m

The polarization waveforms are then processed by an an-
tenna response function to simulate their detection from
an ideal ground-based interferometer, while no back-
ground noise is added yet. For the component masses
of the binary system, m1 and m2, we assumed a mean-
ingful astrophysical distribution, which is the canonical
logarithmic mass distribution described in [5]. m1 is
randomly extracted from 5 to 100 solar masses, so that
m2 < m1 and m1 + m2 < 100M(cid:12). The astrophysical
mass distribution used to generate the waveforms allows
not only to probe the capabilities of the model on a re-
alistic physics case, but also to perform a detailed di-
rect comparison with other, previously published, state-
of-the-art detection algorithms based on artiﬁcial intelli-
gence [35]. We considered only non-spinning black holes.
The other parameters assume an isotropic distribution of
the gravitational source in the sky:

• inclination angle is generated according to a sin

distribution in the interval [0,π];

• phase and polarization angle are generated accord-
ing to a uniform distribution in the range [0, 2π];

• a random sky location is extracted uniformly on a
sphere, and the source is placed at a ﬁxed distance
of 1 Mpc.

Because the simulated source is located at a ﬁxed dis-
tance, for a given choice of its astrophysical parameters
and a given assumption on the detector noise, signal +
noise segments would have exclusively a certain SNR.
However, to derive and test a model capable to detect
GW signals, it crucial to probe its capabilities at diﬀer-
ent SNRs. For example, testing the accuracy of a model
with diﬀerent SNRs enables to probe the generalization
capabilities of the framework and allows to evaluate the
rise in performance with more favorable SNRs. To add
detector noise to the time series, data segments contain-
ing noise only are generated according to a typical aLIGO

FIG. 2. Typical, noise only and signal + noise, whitened data
segments used to train the ground model. A noise-only sample
is interferometer-like stationary noise generated according to
the aLIGO design sensitivity curve. A GW sample is a noisy
interferometer signal with a GW transient whose amplitude
is scaled to have a target signal-to-noise ratio (SNR). The
latter requires the generation of a random BBH waveform;
in this ﬁgure, the red curve (not in scale) marks the BBH
waveform as it would appear without the background noise.
Each prototype is 1 second long and sampled at 8192Hz.

the ground model and its interpretation in a local analy-
sis case (level 2). Subsection III A describes on the data
samples used to train and test the model. Subsection
III B introduces the numerical features derived from au-
dio analysis literature and used to derive the present ver-
sion of the ground model. Finally, subsection III D is to
discuss the analytical formulation of the derived model.

A. Detector and data segments

As previously mentioned, the database used to train
and test the model contains simulated interferometer
strains, either noise-prevailing GW transients or noise-
only data samples. The duration of the simulated strains
in
was ﬁxed to 1 s, as previously done, for example,
Refs. [34, 35, 37]. Fig. 2 shows a schematic example of
time-series used to derive the model. The two key steps
required to create GW samples include the generation of
a template BBH waveform and its sum to an interfer-
ometer noise to match with a target signal-to-noise ratio
(SNR). In this way, two types of data segments are pro-
duced: noise only and signal + noise samples.

BBH template waveforms are generated through the
LALsuite library [46], a package for gravitational and rel-
ativistic astrophysics, which is used to perform a numer-
ical simulation of BBH coalescence events. To this end,
the IMRPhenomD-type waveform is adopted [44, 45].
The characteristic chirp of BBH waveforms, compris-
ing inspiral, merger and ringdown phases, is obtained
by matching together a high-order 3.5PN waveform for
the inspiral [47–49] and a numerical waveform for merger

0noise-only sample1noise-prevailing GW transient sampleat diﬀerent SNRsdesign sensitivity curve. Noise was chosen to be exclu-
sively Gaussian. Stationary noise is a simpliﬁed hypothe-
sis to facilitate the comparison with previous approaches
already published. A number of generated noise segments
were instead used to populate the dataset of noise only
samples. Finally, before summing the generated GW sig-
nals to the stationary noise, the waveform amplitude was
suitably scaled to match with the target optimal SNR.
The latter is deﬁned according to the following equation
[35]:

ρ2
opt = (cid:104)u, u(cid:105)

where u is the generated template and the inner product
(cid:104)a, b(cid:105) is the noise-weighted cross-correlation deﬁned in
Ref. [27]:

(cid:104)a, b(cid:105) = 4Re

(cid:34)(cid:90) ∞

fmin

(cid:35)

˜a(cid:63)(f )˜b(f )
Sn(f )

being ˜a(f ) (˜b(f )) the frequency-domain representation
of the strain a (b) and Sn the single-sided detector noise
PSD; fmin is the frequency of the gravitational-wave tem-
plate at the beginning of the time-series.

Before splitting the generated segments into the
datasets used to derive the models, the time series are
suitably whitened in order to ﬂatten the frequency dis-
tribution dominated by the detector noise. The station-
ary noise and the smoothness of the simulated aLIGO
noise spectrum allowed to use a short, 0.5 s, padding. To
this end, the segments had an additional 0.5 s of data
before and after each generated 1 s time series. Signal
content, after whitening, was truncated using a Tukey
window (α = 1/8) to its central 1 s of data. In addition,
similarly to previous CNNs studies and to allow a more
meaningful comparison of the local results, the peak am-
plitude of each waveform within the ﬁnal time series, was
randomly placed within the range [0.75 s, 0.95 s].

For each model derived in this paper (namely the
ground model, which serves the proposed level 1, and
two interpretation models used in two possible versions
of level 2), we build a training, a cross-validation and a
testing dataset. The cross-validation dataset was used
to make decisions on the complexity of the model, while
the ﬁnal accuracy is always estimated using testing data.
The default training and cross-validation datasets con-
sisted of 1000 noise-only data segments and 1000 signal
+ noise data segments at SNR 8. Finally, for the testing
datasets, SNR was varied from 6 to 14 in integer steps.

B. Data features: speech recognition

The frequency band of interest for GW searches with
second generation interferometers ranges usually from
about 10 Hz to several hundreds Hz. This is in good
superposition with the typical frequency band explored
in audio signal analyses. For example, the evolution of a

6

GW transient has often been compared to a bird chirp.
The general idea of our framework is thus inspired by
one-dimensional signal processing techniques usually ap-
plied for the task of speech recognition, i.e. the analysis of
audio signals for the purpose of recognizing voice from a
persistent background noise. The underlying techniques
are well-developed in the literature and are particularly
powerful to classify voiced signals even in the presence
of a particularly loud background. The mechanism be-
hind the framework is that of processing data samples
through smaller miniframes. In the ﬁeld of audio analy-
sis and speech-recognition, it is common use to consider
the sound on a short-term basis, in order to extract in-
formation from the whole audio sequence. Therefore, an
audio signal is usually divided into small segments and
then the short-term processing stage is carried out. The
short-term processing consists in the extraction of physi-
cal and perceptual features from each segment. Physical
features are measurements computed directly from the
sound wave, such as spectrum, energy, entropy, cepstral
coeﬃcients, zero crossing rate, and so on [54]. Perceptual
features are values related to the perception of sounds by
the human hearing, such as rhythm, pitch, timbre and
noisiness. The feature extraction provides the numerical
values that describe properties of an audio segment, so
the real information is derived from the analysis of such
values, depending on the desired task.

The literature written upon speech processing and au-
dio analysis algorithms is well established, and many
open-source libraries are already available for use. In this
paper, we use a number of existing libraries for speech
recognition and audio analysis to compute the short term
features used to classify GW interferometer data seg-
ments. A full mathematical description of each feature
used to derive the ground model is beyond the scope of
this paper. Instead, a short resume of the most important
libraries and features used for the ground model is re-
ported in Table I. The total number of features extracted
from the libraries is 184. In addition to the feature ex-
traction process on the original, whitened, time series,
we also added a pre-processing stage for the input wave-
form, which uses a wavelet decomposition as a low-pass
ﬁlter. To this end, the wavelet decomposition of a sig-
nal is used to partially ﬁlter the original waveform. The
reconstructed waveform depends on the speciﬁc wavelet
used at ﬁrst instance, and the spectrum of the recon-
structed signal, consequently, is diﬀerent from the origi-
nal one. It usually appears smoothed for higher frequen-
cies, while the most energetic tracks in the low-frequency
band are highlighted from the surrounding noise. Be-
cause we used 9 wavelets, 9 diﬀerent pre-processed ver-
sions of the timeseries are considered. After ﬁltering the
timeseries with the wavelet ﬁlter, the basic set of features
is again extracted for each pre-processed waveform. The
total number of features for each miniframe ﬁnally was
184 + 184 · 9 = 1840.

In terms of performance, the full feature set extrac-
tion on 2k seconds of signal took 240 seconds on average

TABLE I. The speech-processing & audio analysis libraries used for the feature extraction. For a matter of simplicity, only
the most relevant physical and perceptual features from each library are listed in this table. A default set of 184 features is
extracted from the original timeseries. Then, the latter is pre-processed through a wavelet decomposition, which returns 9
pre-processed versions of the waveform. For each pre-processed timeseries, the 184 features are again extracted, which rises the
total number of features to 184 · (1 + 9) = 1840.

7

Library

Most relevant features
Cepstral coeﬃcients: MFCC, LFCC, RFCC; SCFC, SCMC.

boba
python speech featuresb MFCC, LOGF.
Librosac
pyAudio Analysisd
Essentiae

Chromagram features, mel-scaled spectrogram, roll-oﬀ frequency, rms, various spectral features.
Zero crossing rate, energy, entropy, spectral centroid, spectral ﬂux, spectral rolloﬀ, chroma vector.
Barkbands, dynamic complexity, hfc, pitch, silence rate, various spectral features.

pywtf

bior, coif9, coif14, sym2, sym17, sym20, db4, db17, db32

Wavelets used for pre-processing stage

a https://www.idiap.ch/software/bob/
b https://python-speech-features.readthedocs.io/en/latest/
c https://librosa.org/doc/main/feature.html
d https://github.com/tyiannak/pyAudioAnalysis
e https://essentia.upf.edu/
f https://pywavelets.readthedocs.io/en/latest/

(the ratio is greater than 8:1), using a commercial 64-
core Threadripper CPU and a simple parallel processing
workaround meant to take advantage of the large num-
ber of cores. It is important to stress that this result was
obtained without a dedicated (low-level) optimization of
the feature extraction codes. This raw comparison sug-
gests that the audio feature extraction, upon which the
whole framework relies, can ideally keep up to the data
buﬀer required in a real-time situation. In addition, af-
ter the model is derived, it is no longer needed to com-
pute all the features described in this section, because
the ground model relies on a strongly reduced subset of
features, as it will be discussed in detail in Sect. III D.
In fact, one of the crucial aspects of the method used
to derive the ground model in the present implementa-
tion is the so-called feature selection. Feature selection
is the capability of a ML algorithm to suitably select a
subset of features, among those used for model training,
whose informative content is not signiﬁcantly enhanced
when additional features are included. Consequently, one
can derive a model that exploits only a reduced num-
ber of features, even without signiﬁcantly aﬀecting the
overall accuracy. Usually, a suitable trade-oﬀ between
complexity (i.e. number of features or their computa-
tional complexity) and accuracy is selected. This gives
the unique opportunity to explore a large dimensionality
feature space, which includes a large body of features de-
rived from speech processing literature, without enhanc-
ing the complexity of the resulting model. The latter is
a requirement for the ground model of a real time de-
tection algorithm for gravitational waves. To this end,
the ground model proposed in this paper is derived using
the Brain Project, a state-of-the-art tool for the formal
modeling of data based on a hybridization of genetic pro-
gramming and artiﬁcial neural networks. This software

is particularly suitable for the task of deriving a model
aimed to detect GWs in real-time because it has out-
standing capabilities of feature selection, as proven for
example in Refs. [40, 41].

C. The Brain Project

The Brain Project (BP) is a novel tool for the formal
modeling of data based on a hybridization of genetic pro-
gramming and artiﬁcial neural networks [38, 39]. Genetic
programming falls in the ﬁeld of Evolutionary Comput-
ing (EC). In computer science, EC is a branch of artiﬁ-
cial intelligence that often deals with optimization prob-
lems through algorithms inspired by the Darwinian evo-
lutionary theory [55]. Within this ﬁeld, BP deals with
the so-called symbolic regression, i.e. the process during
which some data are ﬁtted by means of a suitable ana-
lytical expression derived by the algorithm itself. Many
novel algorithms for symbolic regression tasks have re-
cently shown that genetic programming is a particularly
powerful technique to solve even extremely complex prob-
lems. Furthermore, some genetic programming imple-
mentations are also capable of feature selection, i.e. to
suitably exclude part of the input variables, thus reduc-
ing the dimensionality of the feature space.

In the framework of evolutionary computation, a solu-
tion of a given optimization problem is initially encoded
according to a predeﬁned scheme. Each solution is usu-
ally called individual, while a set of individuals forms a
population. A numerical value, called ﬁtness, is then as-
sociated to each individual in the population. The ﬁtness
function quantiﬁes how much a solution is a good solution
for the target problem. For instance, in the problem of
symbolic regression, i.e. in the task to derive a model for

the description of some data, the ﬁtness function might
account for the prediction error of the model and/or for
its computational complexity. The average ﬁtness in the
population is usually maximized (or either minimized,
depending on the deﬁnition of the ﬁtness function) ap-
plying some suitable evolutionary criteria, inspired by the
natural selection.

As previously mentioned, in the implementation of BP,
genetic programming and NNs cooperate with the aim of
deriving a proper analytical model g(x) to ﬁt a set of pre-
viously labeled input patterns {(xi, yi) : 1 ≤ i ≤ Np}.
The evolutionary computing approach followed in BP is
part of a line of genetic programming research that fore-
sees the evolution of tree structures representing formal
mathematical expressions. Roughly speaking, to max-
imize the ﬁtness function, the following steps are exe-
cuted:

1. an initial population of randomly constructed trees,
representing solutions of the modeling problem, is
generated;

2. each tree is evaluated through the ﬁtness function
and a ﬁtness value is assigned to all individuals in
the population;

3. a new population of trees is created, starting from
the population at the previous step, through some
evolutionary operators, e.g. copy, crossover, muta-
tion, selection and heuristic operators;

4. return to step 2, until the termination criterion is

met.

In the end, the best individual, i.e.
maximum ﬁtness, is returned as the output result.

the tree with the

The evolutionary computing core of BP operates a
global search for the optimal solution of the modeling
problem. Such a global search is extremely powerful to
identify a solution close to a global maximum of the ﬁt-
ness function, but is usually rather slow to converge to
the maximum itself. NNs are therefore used to serve as
a hill-climbing operator, i.e. an operator capable to per-
form a fast local search for the maximum of the ﬁtness
function by suitably varying the constants in the math-
ematical formula. This is a quite time consuming task,
thus it is executed only if an individual is particularly
promising (i.e. possibly close to a maximum of the ﬁtness
function). In the neural part of BP, each expression is ini-
tially transformed into a multi-layer feed-forward NN by
replacing operators in the original expression with spe-
cialized neurons, while all constants are treated as the
weighs of the NNs. The mathematical expression of the
error gradient in the weight space is then formally calcu-
lated and an enhanced gradient descending technique is
used to update the weights. Learning weights are usually
diﬀerent for each parameter to optimize and are dynam-
ically varied during the training.

The ﬁtness function used in BP takes into account the
prediction error and the number of features exploited by
the model (see [38] for additional details).

8

The software is written in highly optimized C and runs
on Linux 64bit environments. It has also a parallel and
distributed implementation. Each learning task is ex-
ecuted by more clients controlled by a process called
brain server and running on a server machine. More-
over, BP has also the capability, through a dedicated
evolutionary computing algorithm, to self-adapt almost
all the internal parameters (hyperparameters) required
for a learning task. This makes BP a double evolution-
ary tool [39], capable of automatically self-tuning itself
for the particular problem to solve, thus optimizing the
overall performance through, each time, a dedicated set
of hyperparameters. BP has been successfully used so far
in a number of research ﬁelds, see e.g. Refs. [40–42, 57],
but this is the ﬁrst time it is used in the ﬁeld of gravita-
tional wave physics.

D. Analytical formulation of the model

Let us summarize the main points discussed so far.
The detection of GW signals is based on the analysis
of noisy time series, in which the dominant frequency
range is typically in the audible band. Supported by this
fact, the proposed framework is inspired by audio analy-
sis techniques, and speciﬁcally by speech processing. One
of the key aspects of the newly proposed framework is its
layered implementation, which allows to easily specialize
the framework for the desired real-time analysis pipeline,
even combining diﬀerent existing algorithms. The low-
est level of the framework relies on the initial predictions
operated by the ground model. The latter are performed
for each individual miniframe, in which the strain is sub-
divided, and the successive local analysis (level 2) is per-
formed by analyzing the ground model output for a con-
tinuous stream of miniframes. In this paper, we propose
a level 1 module whose ground model is derived through
BP. BP implements a few key advantages for its use in
the derivation of real-time GW search algorithms:

• BP is capable of a particularly advanced feature se-
lection. For example, the ground model discussed
in this paper was initially derived exploiting a full
set of 1840 audio analysis features, but, at the end
of the training process, it foresees exclusively 4 fea-
tures. The strongly reduced number of features al-
lows to minimize the computational complexity of
the model, thus making it ideal for real-time appli-
cations, even if the model is derived using a large
body of information on a high-dimensional feature
space. In addition, feature selection can also serve
as a guideline towards the correct choice of features
suitable for the study of GW signals, a crucial infor-
mation even for the derivation of future algorithms.

• The resulting model has a rather simple analyt-
ical expression based on numerical features, thus
enabling a fast and easy implementation of the

9

TABLE II. The analytical formulation ultimately derived by BP for the miniframe output value y. Despite the complexity of
the problem and the large dimensionality of the feature space used to train the model, the derived formula foresees exclusively
4 features and has a particularly low computational complexity. This model is used to perform a ground prediction on each
miniframe, individually.

y = −0.07133 + 0.86274 · pyAA31 · exp [min (0.036685, db17ess3) − 1.0623 · db17ess3 + c ] + 70.47328 · pyAA33

where

c = max (0.22473 + ln (db17ess3) · erf (db32bb4) − 2.6911 · pyAA31, db17ess3)

the following 4 features have been selected:
pyAA31
pyAA33
db17ess3
db32bb4

The second last element of the chroma vector a given by the pyAA library.
The standard deviation of the 12 elements of the chroma vector given by the pyAA library.
The energy of the waveform in band ]150,800] Hz given by Essentia library on the db17 pre-processed waveform.
The energy of the waveform in band ]200,300] Hz given by Essentia library on the db32 pre-processed waveform.

a The chroma vector is a 12-element representation of the spectral energy, where the bins represent the 12 equal-tempered pitch classes

of music (in the western-type semitone spacing).

model even in low-cost systems based on commer-
cial CPUs.

In the mechanism described in Section II, every data
sample of 1 second is processed in 19 miniframes of 100
ms length each, as described in Section III A. Given that
a typical learning dataset contained 2000 data samples,
BP had in turn Np = 19 · 2000 = 38k patterns available
for the training and cross-validation tasks. Each pat-
tern consisted of 1840 inputs (the features {xi}) and a
categorical target output value, either 0, for miniframes
containing noise only, or 1, if the miniframe is in a region
where a GW signal is present. For a similar problem,
in a high-dimensionality feature space in the presence of
large noise, BP usually achieved a convergence within a
time of a few hours using a single Threadripper CPU.
With a similar procedure as described for example in
Refs. [41, 57], after a few preliminary runs, we settled to
an optimal trade-oﬀ between complexity and accuracy.
The performance of the model, for each selected trade-
oﬀ, was monitored by analyzing the prediction error on
the cross-validation dataset, which contained the same
number of patterns as in the training dataset.

The analytical implementation of the ultimately de-
rived model
is reported in Table II, together with a
brief description of the corresponding numerical features.
Only 4 features are exploited by the model, and it is
therefore not needed to compute all the features de-
scribed in Table I. The output value, yi = f (xi
1840)
is usually not deﬁned in the range [0, 1]. In order to fulﬁll
the condition f (x) ∈ [0, 1] for all possible input vectors
x, it is convenient to use the corresponding constrained
function g(x) = max(min(f (x), 1), 0).

1, ..., xi

IV. RESULTS AND DISCUSSION

A.

Interpretation of model output: multi-modeling

in the task of local analysis

One of the key aspects of the proposed method is that
the derived model has an analytical formulation, entail-

ing only a few nodes. This allows to perform a prediction
with a reduced computational complexity compared to
CNN approaches. In addition, the layered framework re-
quires suitable interpretation at each level of decision,
making the framework particularly versatile for many
real-time applications.

From a detailed inspection of the ground model equa-
tion of Table II, one can point out some interesting
points. The features exploited by the model are exclu-
sively: pyAA31, pyAA33, db17ess3, db32bb4. This indi-
cates that their informative content, for the task of iden-
tifying GW signals in noisy and short time intervals, is
equivalent to the informative content of the 1840 features
initially selected for the learning task and reported in Ta-
ble I. In other words, forcing the model to exploit all the
features of Table I would increase the complexity of the
model without a statistically signiﬁcant reduction of the
prediction error. Selected features are brieﬂy described
in Table II. The ﬁrst two features, extracted from the li-
brary pyAA, are related, respectively, to the energy of the
strain in the frequency band from about 98 Hz to about
415 Hz, and to the overall variation of energy (expressed
as the standard deviation) in the frequency domain from
30 Hz to 1000 Hz. The latter might usually exhibit lower
values if the miniframe is strongly dominated by noise, as
the noise power is equal at all frequencies after whiten-
ing the strain, but will tend towards larger values if the
miniframe contains a GW signal, whose power lies, for a
given miniframe, in a narrow frequency region. The sec-
ond two features are calculated from the signal initially
ﬁltered through the Wavelet ﬁlter. They represent, re-
spectively, the energy of the pre-processed strain in the
band ]150, 800] Hz and ]200, 300] Hz.
Interestingly, se-
lected features are related exclusively to the energetic of
the strain, suggesting that energy is the most relevant
information for the detection of GWs in a short-term
feature approach. Furthermore, it is not surprising that
all selected features are linked to a frequency range that
contains the peak amplitude of BBH waveforms, in the
mass range explored in the present paper.

Unlike previous classiﬁers based on CNNs, the ground

10

FIG. 3. A stream of n ground model output values yi for 19
consecutive miniframes of 100 ms length. Data are produced
using a signal+noise data segment extracted from the test-
ing dataset. The total duration of the segment is 1 second,
thus the miniframes are overlapped by 50% of their duration.
Model output clearly exhibits an increasing trend from left
to right, reﬂecting the peak amplitude of the BBH waveform.
By thresholding the output values with a ﬁxed threshold, one
obtains a categorical output. The latter exhibits a cluster of
positive output (i.e. 1) at the peak amplitude. This informa-
tion is suitable to local analysis of the segment and therefore
the formation of level 2 output.

model itself does not provide a ﬁnal prediction on a ﬁxed
time length segment, because it is strictly trained on lo-
cal properties of the signal. For this reason, the gener-
ation of an interferometer alert requires additional dedi-
cated layers for the reﬁned interpretation of the ground
model information. Usually, the algorithm can be suit-
ably adapted to the desired detection task, eventually
by reaching a given trade-oﬀ between sensitivity and
speciﬁcity of the classiﬁcation. For example, lower levels
should be extremely conservative in ruling out noise seg-
ments, in order to obtain the adequate level of sensitivity
required for the successive oﬄine analysis and parameter
estimation.

In the proposed framework, regardless of the tar-
get task, either local or continuous analysis, a generic
data segment from a GW interferometer is considered
through n overlapped miniframes of ﬁxed time length
(ωf = 100ms). For each miniframe, the reduced set
of speech-processing features is extracted and used to
compute a continuous output y (Table II), suitably con-
strained in the range [0, 1] as indicated in Section III D.
At this stage, the generic segment is matched to a stream
In this paper, we mostly
of n consecutive outputs yi.
focus on the local analysis, to have a more meaningful
comparison with CNN approaches [34, 35, 37]. A typi-
cal stream of ground model output for a locally analyzed
1-second frame is shown in Figure 3, for a signal+noise
segment, and in Figure 4 for a noise only segment. Both
data segments used to produce the ﬁgures are extracted
from the testing dataset, and are therefore good repre-
sentative of the typical level 1 output. By inspecting

FIG. 4.
Same as Figure 3 but obtained with a noise only
In this case, the output has lower variation and a
sample.
lower mean-value. The thresholded categorical output does
not exhibit clusters of 1 and the 0 prediction dominates the
data segment.

the ﬁgures, it is clear that the observed trends for the
model output, as a function of the miniframe, diﬀer sig-
niﬁcantly for signal+noise and noise only segments. The
ﬁrst, Figure 3, exhibits an increasing trend, with a group
of consecutive miniframes having a much larger output.
The latter has instead a more uniform output, reﬂecting
the roughly uniform behavior of the detector noise in a
short data segment.

1. L2T: a possible level-2 implementation based on a
thresholded model

A ﬁrst possible method for the interpretation of the
ground model output, for the task of local analysis (per-
formed by level 2), can be obtained by suitably threshold-
ing its output. The principle is schematically explained
in Figures 3 and 4, where a threshold of τ = 0.68 is
represented, as an example. After thresholding the out-
put, one obtains a series of 19 categorical output values
for each data segment to analyze (with values either 0
or 1). Following the diﬀerent trend of model output for
the two cases, one expects the appearance of clusters of 1
in the presence of a GW signal, while for noise only seg-
ments only some, spurious, isolated 1 is usually present,
as seen in Figures 3 and 4. One can exploit this diﬀer-
ence in the observed patterns of the categorical output to
derive a model for the thresholded interpretation of the
ground model. For the thresholded interpretation model,
we used maximum length of a cluster of 1, the maximum
length of a cluster of 0 and the total number of 1 observed
in the segment. Boundary conditions on these three vari-
ables can be derived through any ML algorithm, exploit-
ing a dataset of previously labeled segments. We name
this approach multi-modeling. To this end, we exploited
1-second data segments, previously simulated, and subdi-
vided into training, cross-validation and testing datasets,

00000000000000111110 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0threshold = 0.68miniframes0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0level 1 outputthresholded output0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 00000001000000000000threshold = 0.68miniframes0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0level 1 outputthresholded output11

cording to the required performance. For example, for an
optimal SNR of ρopt = 12, one can easily rule out 90%
of the noise-only sample, while identifying nearly-100%
of the GW signals. This value drops to about 70% for
ρopt = 8. In general, L1+L2T exhibits a good regular-
ity for increasing SNRs, with a signiﬁcant rise in perfor-
mance towards higher SNR values.

2. L2U: an alternative level-2 implementation with an
unthresholded model

An alternative way to interpret the ground model out-
put can be achieved without thresholding the values of
level 1. In fact, thresholding the output typically results
in a loss of information, being the continuous output con-
verted into a categorical one with only two possible cat-
egories. To derive the unthresholded model, we consid-
ered the ground model output values for 19 consecutive
miniframes in which the data segment is subdivided. Said
yi the output of the i-th miniframe, we constructed the
curve identiﬁed by the set of points {(i, yi) : i ∈ [1, 19]}.
A series of 260 features were suitably built to represent
the information on the presence of a GW signal in the
noisy segments. The features included simple statistical
values (mean, median, standard deviation, kurtosis) and
linear ﬁt coeﬃcients. The same set of features is also
extracted on multiple smoothed version of the continu-
ous output curve, obtained with diﬀerent smoothing, as
described in the appendix. Exploiting this set of fea-
tures, a second model was derived through BP, using the
data segments contained in the same subset of the testing
dataset previously used to derive the thresholded model.
The deriving model can be used to build an alternative
unthresholded level 2 (L2U). The analytical implemen-
tation of the unthresholded model is shown in Table III,
together with a description of the selected features. A
more detailed description of the features used by the un-
thresholded model is instead reported in the appendix.
Similarly to the case of the ground model, also the un-
thresholded model exploits an extremely reduced number
of features. Features are reduced from the initial 266, in
the training set, to only 6. The performance of the deriv-
ing L2U in the task of identifying GW data segments are
probed using the same dataset previously used to test the
performance of L2T. This time, a given trade-oﬀ between
sensitivity and false positive rate can be obtained by us-
ing a threshold η directly on the output of the unthresh-
olded model. The corresponding ROC curves, in which
each point corresponds to a given η value, are shown
in Figure 6 (solid lines), compared to those of L1+L2T
(dashed lines). Curves obtained at analogous SNR are
drawn with the same color.

An inspection of the ROC curves for the two modules
suggests that the performance of L1+L2U is signiﬁcantly
better than that obtained with L1+L2T (and therefore
by thresholding the ground model output). As an ex-
ample, for an optimal SNR ρopt = 8 and a false positive

FIG. 5.
ROC curves obtained by a local analysis of the
testing dataset with L1+L2T. The Y-axis represents the sen-
sitivity, i.e. the fraction of data segments containing a GW
signal triggering the second layer of the framework, and the
X-axis represents the false alarm probability, i.e. the fraction
of noise-only segments incorrectly producing a trigger. The
scales are logarithmic. Curves are shown, individually, for op-
timal SNR ranging from ρopt = 6 to ρopt = 14 with diﬀerent
colors. One observes, as expected, a raise in performance of
the model towards higher SNRs.

individually.

dedicated to the derivation of the interpretation models.
Using the derived boundary conditions on the above
mentioned quantities, the performance of the thresh-
olded version of level 2 (L2T) can be evaluated using
the segments of the dedicated testing dataset. Figure 5
shows the receiving operator characteristic (ROC) curves
obtained using L1 and the thresholded version of L2
(L1+L2T) for optimal SNR ranging from ρopt = 6 to
In the graph, the Y-axis is
ρopt = 14,
the speciﬁcity of the classiﬁer, i.e.
the fraction of sig-
nal+noise segments that are correctly classiﬁed as con-
taining a GW signal. This is a crucial quantity in real-
time GW detection applications. X-axis is related to the
capability of the model to rule out noisy segments.
It
corresponds to the fraction of noise-only samples incor-
rectly classiﬁed as containing a GW signal. For the lat-
ter, 0 indicates a complete, ideal, noise rejection, while 1
indicates that all noise-only segments in the dataset pro-
duce a zero-level trigger. Each point in the ROC curve
is obtained with a certain value of the threshold τ . A
threshold value τ = 1 would result in a point located at
the bottom-right corner of the graph, i.e. all segments
are identiﬁed as noise, while τ = 0 will identify all seg-
ments as containing a GW, top-right corner. An optimal
LT2 can be obtained selecting the proper threshold, ac-

1041031021011001 - Specificity [%]102101100Sensitivity [%]L1+L2T  SNR 6     "     SNR 7     "     SNR 8     "     SNR 9     "     SNR 10     "     SNR 12     "     SNR 14TABLE III. The analytical formulation of the unthresholded model derived via BP. A brief description of the selected features
is also provided. The unthresholded model foresees only 6 features. See the appendix for a detailed description of the features
selected by BP.

Y = tanh

(cid:110)

1.83 · max [ c1, max(c2, b4) ]

(cid:111)19.5073·arctan(b6)

where c1 = 1.829 · b4 · max

(cid:110)

1.829 · b4 · tan(b4), 1.732176 · b4 · sin[max(tan(b3), b4)] + 0.947062 · b2

(cid:111)

+ b2

and c2 = {1.829 · sinh[erf(b3 · b1)] · erf[tan(b4)] · b5} + b2

12

the following features have been selected:
b1 = russo83

b2 = russo95

b3 = sm2ampl

b4 = sm3weav

b5 = sm5barone72

b6 =sm5barone90

B. Comparison with the literature

The local analysis described in the previous section,
i.e. the analysis of data segments of ﬁxed length, allows
a direct comparison of L1+L2 derived in the present work
with other state-of-the-art approaches available in the lit-
erature. We compare the results achieved with L1+L2T
and L1+L2U to those of matched-ﬁltering and state-of-
the-art artiﬁcial intelligence approaches based on CNNs.
We used the CNN model described in Ref. [35]. This
model is derived and tested on data segments of 1 second
length, where the GW peak lies in the fractional range
[0.75, 0.95] of the time series. For this reason, it is ideal
to be used for the local analysis proposed in this section.
Matched-ﬁltering is a key algorithm, usually adopted for
the detection of binary coalescence signals [58, 59], which
is based on the coherence of the detected strain with a
given template waveform. The ranking statistics used for
matched-ﬁltering is the matched-ﬁltering SNR numeri-
cally maximized over arrival time, phase and distance
(see Ref. [35] for additional details). Given the ranking
statistic of each analysis algorithm, it is possible to con-
struct the ROC curves by evaluating, for each threshold,
the number of true positives and true negatives achieved
by the classiﬁer.

In Figure 7, we show the ROC curves obtained with
both level 2 modules derived in this work together with
the corresponding ROC curves obtained using standard
matched-ﬁltering and the model described in Ref. [35].
We focused the comparisons on data containing sig-
nals with optimal SNR ρopt = 6, while, for matched-
ﬁltering and the CNN model, we also show the results for
ρopt = 4. The curves obtained at ρopt = 6 with matched-
ﬁltering (blue dashed line) and the CNN model (light
blue dashed line) show similar values of sensitivity and
speciﬁcity. The sensitivity of the CNN slightly exceeds
that of matched-ﬁltering at large false alarm probability
values, while the trend is opposite at small values of false
alarm probability, i.e. at large sensitivity values. The
ROC curves for L1+L2T and L1+L2U are shown with
the red curves for ρopt = 6. Compared to the CNN model
at the same SNR, CNNs have better performance than
both our models for all values of the false alarm probabil-
ity. L1+L2U (solid red line) has a performance closer to
that of CNNs compared to the same curve for L1+L2T

FIG. 6. Local analysis ROC curves obtained with L1+L2U
(solid lines) compared to those of L1+L2T (dashed lines) at
analogous SNR. Each color represents a given SNR. Optimal
SNR values were varied from ρopt = 6 to ρopt = 12. As in
Figure 5, Y-axis represents the sensitivity of the classiﬁer and
X-axis is the false alarm probability. L2U performs better
than L2T at all SNRs.

rate of 10%, the sensitivity of L1+L2U raises to about
90%, while L1+L2T has a sensitivity of only 70%. In-
terestingly, for optimal SNR ρopt = 12, the sensitivity
of L1+L2U is almost saturated to 100% at nearly all
false alarm probability values, while, using the thresh-
olded module leads to a sensitivity below 90% when the
false alarm probability approaches 5%. This indicates
that thresholding the output of the ground model par-
tially hides the relevant information for the detection of
GW signals and that alternative interpretations of the
ground model output (and therefore other possible level
2 implementations), other than the ones proposed here,
could lead to even more accurate predictions.

0%20%40%60%80%100%1 - Specificity  [%]0%20%40%60%80%100%Sensitivity [%]L1+L2U  SNR 6L1+L2U  SNR 8L1+L2U  SNR 10L1+L2U  SNR 12L1+L2T  SNR 6L1+L2T  SNR 8L1+L2T  SNR 10L1+L2T  SNR 1213

V. CONCLUSIONS AND PERSPECTIVES

Developing fast and accurate methods for real-time de-
tection of gravitational wave signals is a crucial task in
the era of multi-messenger astrophysics.
In this foun-
dational paper, we describe a new framework designed
for the detection of GWs in real-time, low-latency, ap-
plications. The proposed framework foresees a layered
approach, in which less computationally complex opera-
tions are executed as the ﬁrst layers, to rule out regions of
the interferometer strain exclusively characterized by in-
strumental noise. The framework is constructed around
the idea of using features derived from speech process-
ing to identify GW signals in noisy time series. This is a
novelty in the research ﬁeld of gravitational wave physics.
We describe the derivation of a model suitable to serve
the ﬁrst level of the framework, i.e. the only module that
directly deals with the inferferometer timeseries. Such
level 1 relies on the ground predictions of the so-called
ground model, which performs a short-term analysis of
the time series. To this end, the strain is suitably sub-
divided into overlapped miniframes and an extremely re-
duced set of 4 state-of-the-art speech processing features
is calculated for each miniframe. The Brain Project, a
novel hybridization of genetic programming and neural
networks for the formal modeling of data, is used to de-
rive a model capable to link short-term features to the
presence of a GW signal. The model is derived using
a dataset of simulated BBH signals in synthetic Gaus-
sian noise representative of aLIGO, and an extended set
of 1840 features. One of the novelties of the approach
is that the deriving model has an analytical formula-
tion, which can be easily implemented even in systems
based on commercial CPUs. Thanks to the outstanding
feature selection capabilities of the Brain Project, the
ultimately derived model foresees only 4 features, thus
having an extremely low computational complexity. Re-
sults of the ground model are interpreted through the
second level of the framework. Two possible versions of
such level are proposed, based on two diﬀerent dedicated
interpretation models derived using artiﬁcial intelligence
supervised learning approaches, namely thresholded and
unthresholded models.

The performance of the two alternative implementa-
tions of level 2, upon level 1, is probed via a detailed
inspection of the receiving operator characteristic curves
obtained from the analysis of data segments of ﬁxed
length. We used a dataset containing signals at low
SNR and a meaningful astrophysical parameter distri-
bution suggested by the literature. Results show that
avoiding thresholding the ground model output leads to
signiﬁcantly better results. As an example, for signals
with optimal SNR ρopt = 12, at a false alarm probabil-
ity of 10%, the sensitivity (i.e. the true alarm probabil-
ity) of the unthresholded interpretation is nearly 100%,
while the thresholded one identiﬁes only about 95% of the
GWs in the dataset. Results are compared with standard
matched-ﬁltering algorithms and a recent CNN model,

FIG. 7.
ROC curves obtained with L1+L2U (solid red
curve), L1+L2T (dashed red curve), the standard matched-
ﬁltering (dark blue curves) and the CNN model of Ref. [35]
(light blue curves). The curves are produced with signals with
optimal SNR ρopt = 6. For matched-ﬁltering and the CNN
model also ρopt = 4 is shown (dash-dotted lines). ROC curves
for the latter are extracted from Ref [35], where an analogous
dataset as the one used in the present paper is adopted.

(dashed red line). For example, at a false alarm probabil-
ity of 10−2, L1+L2U is able to identify about 40% of the
GW data segments in the testing dataset, while CNNs
identify about 65% of the GW signals and L1+L2T only
slightly more than 10%. The latter has similar perfor-
mance than matched-ﬁltering and CNNs only when the
latter are tested on data containing signals at optimal
SNR ρopt = 4 (dash-dotted lines), while, in this case,
L1+L2U at ρopt = 6 performs signiﬁcantly better. Fi-
nally, it is important to stress that the situation of local
analysis, which is a particular ideal benchmark for the
CNN model of Ref. [35], is a particularly unfavorable
condition for our framework, which is instead design for
a short-term analysis of features, thus not accounting for
the duration of the strain and the position of the signal
peak within the segment. The assumptions used to de-
rive our models make them more suitable for the analysis
of a continuous strain in a realistic analysis pipeline. In
addition, as shown previously in the paper, the derived
models (for both level 1 and level 2) have the advan-
tage of an outstandingly-low computational complexity,
which makes them ideal for the integration in real-time,
low-latency, analysis pipelines.

1021011001 - Specificity  [%]102101100Sensitivity [%]SNR 6 L1+L2USNR 6 L1+L2TSNR 6 Gabbard CNNSNR 6 matched filteringSNR 4 Gabbard CNNSNR 4 matched filteringpreviously validated on data segments of ﬁxed length.
The unthresholded model leads to a performance slightly
lower than that of matched-ﬁltering and CNNs. For ex-
ample, at ρopt = 6 and a false alarm probability of 10−2,
CNNs achieve 65% sensitivity while the unthresholded
model allows to reach a sensitivity of 40%. However,
it is important to stress that the local analysis of ﬁxed
segments is a particularly unfavorable working condition
for our framework, which is instead ideal to analyze a
continuous strain of interferometer data.

The paper proves that speech processing features are
suitable to be used as short-term features for the detec-
tion of GWs in noisy time series detected by second gen-
eration interferometers, such as aLIGO. The proposed
method could help to develop new dedicated pipelines
for the real-time analysis of GW interferometer data at
extremely low-latency. Furthermore, the high-versatility
of the framework and the optimized implementation of
the underlying models makes it suitable to be integrated
even in existing analysis pipelines. In addition, these re-
sults are particularly promising also for future develop-
ment towards the third generation of gravitational wave
interferometers.

Appendix: Selected features of the unthresholded
model

14

Each point of the curve is processed by threshold, so
that every point above the threshold value τ is consid-
ered as a ’one’, otherwise as a ’zero’. Within each curve,
except for the case in which the threshold value is grater
than the minimum value of the curve, there will be a
’ﬁrst one’ and a ’last one’ in the sequence. Let ξ be the
distance between the ’ﬁrst one’ and the ’last one’ of the
curve on the X-axis.

2. Feature deﬁnitions

Considering Γ (not-smoothed curve):

b1 =

1
ξ

(cid:88)

ones

yi

where the ones are assigned using a threshold value τ =
µ + 0.8 · α.

b2 =

19
(cid:88)

(cid:16)

i=0

yi − (0.9 · α + µ)

(cid:17)

Considering a smoothed curve with p = 2:

b3 = α2

1. Standard deﬁnitions

Considering a smoothed curve with p = 3:

For each 1 second sample there are 19 continuous
miniframe outputs yi (i = 1...19), usually in the range
[0,1]. Let us call Γ the curve given by the set of points
(i, yi):

Γ = {(i, yi) : i = 1...19}.

The original curve given by the miniframe outputs can
be smoothed considering the mean value on the Y-axis
of p points, p > 1. By deﬁnition, a mean-smoothed curve
Γp is the set of points (j, Yj), for j = 1...(19 + 1 − p), in
which every point Yj is given by the mean Y-axis value
of p adjacent points of Γ:

Yj =

1
p

p−1
(cid:88)

k=0

yj+k,

Γp = {(j, Yj) : j = 1, ..., 19 + 1 − p}.

Because of this deﬁnition, the not-smoothed curve Γ is a
smoothed curve Γ1 with p = 1. For a given curve Γx, let
us consider α its amplitude, αx = max Γx − min Γx, and
its minimum value µx = min Γx

b4 =

17
(cid:88)

j=1

(Yj · wj)

(cid:44) 17
(cid:88)

wj

j=1

where {wj} is a suitable weighting vector to account for
the enhancement of the signal power from the left to the
right part of the data segment, as a result of the topology
of the BBH waveform.

Considering a smoothed curve with p = 5 and τ =
0.7 · α + µ, b5 is the length of the shortest cluster of zeros.
Considering a smoothed curve with p = 5 and τ =
0.7 · α + µ, b6 is the number of the ones within the curve.

ACKNOWLEDGMENTS

D.D. acknowledges funding support from the Italian
Ministry of Education, University and Research (MIUR)
through the ”PON Ricerca e Innovazione 2014-2020,
Azione I.2 A.I.M., D.D. 407/2018”. The authors grate-
fully acknowledge Dr. H. Gabbard (University of Glas-
gow) for fruitful discussion. The authors would like to
acknowledge the G2NET Cost Action (CA17137) for the
valuable support and stimulating discussions.

[1] J. Aasi et al., Class. Quant. Grav. 32, 074001 (2015).

[2] B. Abbott et al., Phys. Rev. Lett. 116, 131103 (2016).

[3] B. Abbott et al., Phys. Rev. Lett. 116, 061102 (2016).
[4] B. Abbott et al., Phys. Rev. Lett. 116, 221101 (2016).
[5] B. Abbott et al., Phys. Rev. X 6, 041015 (2016).
[6] B. Abbott et al., Phys. Rev. Lett. 116, 241102 (2016).
[7] T. Li et al., Phys. Rev. D 85, 082003 (2012).
[8] C. Mishra et al., Phys. Rev. D 82, 064010 (2010).
[9] F. Acernese et al., Class. Quant. Grav. 32, 024001 (2015).
[10] B. Abbott et al., (LIGO Scientiﬁc Collaboration and
Virgo Collaboration), Phys. Rev. Lett. 119, 141101
(2017).

[11] B. Abbott et al., (LIGO Scientiﬁc Collaboration and
Virgo Collaboration), Phys. Rev. X 9, 031040 (2019).
[12] R. Abbott et al., (LIGO Scientiﬁc Collaboration and
Virgo Collaboration), Phys. Rev. Lett. 125, 101102
(2020).

[13] B. Abbott et al., Astrophys. J. Lett. 882, L24 (2019).
[14] T. Venumadhav et al., Phys. Rev. D 101, 083030 (2020).
[15] A. Nitz et al., Astrophys. J. 891, 123 (2019).
[16] A. Nitz et al., Astrophys. J. 897, 2 (2020).
[17] B. Abbott et al., (LIGO Scientiﬁc Collaboration and
Virgo Collaboration), Phys. Rev. Lett. 119, 161101
(2017).

[18] B. Abbott et al., Astrophys. J. 848, L12 (2017).
[19] B. Abbott et al., Astrophys. J. Lett. 848, L13 (2017).
[20] B. Abbott et al., Living Rev. Relativity 19, 1 (2016).
[21] T. Abbott et al., (Dark Energy Survey Collaboration)

Mon. Not. R. Astron. Soc. 460, 1270 (2016).

[22] A. Abdo et al., Astrophys. J. Suppl. Ser. 208, 17 (2013).
[23] M. Aartsen et al., Astrophys. J. Lett. 898, L10 (2020).
[24] K. Abe et al., Astrophys. J. Lett. 857, L4 (2018).
[25] S. Adri´an-Martinez et al., (The ANTARES collaboration,
the LIGO scientiﬁc collaboration and the Virgo collabo-
ration) J. Cosm. Astropart. Phys. 6, 008 (2007).
[26] N. Indik et al., Phys. Rev. D 97, 124008 (2018).
[27] B. Owen et al., Phys. Rev. D 60, 022002 (1999).
[28] S. Usman et al., Class. Quant. Grav. 33, 215004 (2016).
[29] T. Adams et al., Class. Quant. Grav. 33, 175012 (2016).
[30] S. Klimenko et al., Class. Quant. Grav. 25, 114029

(2008).

15

[32] J. Sylvestre et al., Phys. Rev. D 66, 102004 (2002).
[33] S. Chatterji et al., Class. Quant. Grav. 21, S1809 (2004).
[34] D. George and E. Huerta, Phys. Rev. D 97, 044039

(2018).

[35] H. Gabbard et al., Phys. Rev. Lett. 120, 141103 (2018).
[36] M. Razzano et al., Class. Quantum Grav. 35, 095016

(2018).

[37] D. George and E. Huerta, Phys. Lett. B 778, 64 (2018).
[38] M. Russo, Swarm. Evo. Comp. 27, 145 (2016).
[39] M. Russo, Soft Comp. 24, 16885 (2020).
[40] M. Russo et al., Solar Energy 105, 264 (2014).
[41] E. Buccheri, D. Dell’Aquila, and M. Russo, Diab. Res.

Clin. Pract. 174, 108722 (2021).

[42] E. Buccheri, D. Dell’Aquila, and M. Russo, Obes.

Medicine 31, 100398 (2022).

[43] D. Dell’Aquila and M. Russo, Comp. Phys. Comm. 259,

107667 (2021).

[44] S. Husa et al., Phys. Rev. D 93, 044006 (2016).
[45] S. Khan et al., Phys. Rev. D 93, 044007 (2016).
[46] LIGO Scientiﬁc Collaboration, LIGO Algorithm Library

- LALSuite, free software (GPL) (2018).

[47] L. Blanchet, Class. Quant. Grav. 15, 1971 (1998).
[48] Blanchet et al., Phys. Rev. D 65, 061501(R) (2002).
[49] Blanchet et al., Phys. Rev. Lett. 93, 091101 (2004).
[50] F. Pretorius, Class. Quantum Grav. 22, 425 (2005).
[51] J. G. Baker et al., Phys. Rev. Lett. 96, 111102 (2006).
[52] M. Campanelli et al., Phys. Rev. D 96, 111101 (2006).
[53] L. E. Kidder, Phys. Rev. D 77, 044016 (2008).
[54] T. Giannakopoulos, pyaudioanalysis: An open-source
python library for audio signal analysis, PloS one 10
(2015).

[55] J. R. Koza, Genetic Programming: On the Programming
of Computers by Means of Natural Selection (MIT Press,
Cambridge, MA, USA, 1992).

[56] M. Russo, IEEE Trans. Evo. Comput. 4 (2000).
[57] G. Campobello, D. Dell’Aquila, M. Russo, and A. Seg-

reto, Applied Soft Comp. 94, 106488 (2020).
[58] S. Badak et al., Phys. Rev. D 87, 024033 (2013).
[59] B. Allen, W. Anderson, P. Brady, D. Brown, and

[31] S. Klimenko et al., Phys. Rev. D 93, 042004 (2016).

J. Creighton, Phys. Rev. D 85, 122006 (2012).

