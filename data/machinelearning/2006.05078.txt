0
2
0
2

t
c
O
3
2

]
L
M

.
t
a
t
s
[

3
v
8
7
0
5
0
.
6
0
0
2
:
v
i
X
r
a

Differentiable Expected Hypervolume Improvement
for Parallel Multi-Objective Bayesian Optimization

Samuel Daulton
Facebook
sdaulton@fb.com

Maximilian Balandat
Facebook
balandat@fb.com

Eytan Bakshy
Facebook
ebakshy@fb.com

Abstract

In many real-world scenarios, decision makers seek to efﬁciently optimize multiple
competing objectives in a sample-efﬁcient fashion. Multi-objective Bayesian opti-
mization (BO) is a common approach, but many of the best-performing acquisition
functions do not have known analytic gradients and suffer from high computational
overhead. We leverage recent advances in programming models and hardware
acceleration for multi-objective BO using Expected Hypervolume Improvement
(EHVI)—an algorithm notorious for its high computational complexity. We derive
a novel formulation of q-Expected Hypervolume Improvement (qEHVI), an acqui-
sition function that extends EHVI to the parallel, constrained evaluation setting.
qEHVI is an exact computation of the joint EHVI of q new candidate points (up to
Monte-Carlo (MC) integration error). Whereas previous EHVI formulations rely
on gradient-free acquisition optimization or approximated gradients, we compute
exact gradients of the MC estimator via auto-differentiation, thereby enabling efﬁ-
cient and effective optimization using ﬁrst-order and quasi-second-order methods.
Our empirical evaluation demonstrates that qEHVI is computationally tractable
in many practical scenarios and outperforms state-of-the-art multi-objective BO
algorithms at a fraction of their wall time.

1

Introduction

The problem of optimizing multiple competing objectives is ubiquitous in scientiﬁc and engineering
applications. For example in automobile design, an automaker will want to maximize vehicle
durability and occupant safety, while using lighter materials that afford increased fuel efﬁciency and
lower manufacturing cost [44, 72]. Evaluating the crash safety of an automobile design experimentally
is expensive due to both the manufacturing time and the destruction of a vehicle. In such a scenario,
sample efﬁciency is paramount. For a different example, video streaming web services commonly
use adaptive control policies to determine the bitrate as the stream progresses in real time [47]. A
decision maker may wish to optimize the control policy to maximize the quality of the video stream,
while minimizing the stall time. Policy evaluation typically requires using the suggested policy on
segments of live trafﬁc, which is subject to opportunity costs. If long evaluation times are the limiting
factor, multiple designs may be evaluated in parallel to signiﬁcantly decrease end-to-end optimization
time. For example, an automaker could manufacture multiple vehicle designs in parallel or a web
service could deploy several control policies to different segments of trafﬁc at the same time.

1.1 Background

Multi-Objective Optimization: In this work, we address the problem of optimizing a vector-valued
objective f (x) : Rd → RM with f (x) = (cid:0)f (1)(x), ..., f (M )(x)(cid:1) over a bounded set X ⊂ Rd.
We consider the scenario in which the f (i) are expensive-to-evaluate black-box functions with

34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.

 
 
 
 
 
 
no known analytical expression, and no observed gradients. Multi-objective (MO) optimization
problems typically do not have a single best solution; rather, the goal is to identify the set of
Pareto optimal solutions such that any improvement in one objective means deteriorating another.
Without loss of generality, we assume the goal is to maximize all objectives. We say a solution
f (x) Pareto dominates another solution f (x(cid:48)) if f (m)(x) ≥ f (m)(x(cid:48)) ∀ m = 1, . . . , M and
there exists m(cid:48) ∈ {1, . . . , M } such that f (m(cid:48))(x) > f (m(cid:48))(x(cid:48)). We write f (x) (cid:31) f (x(cid:48)). Let
P ∗ = {f (x) s.t. (cid:64) x(cid:48) ∈ X : f (x(cid:48)) (cid:31) f (x)} and X ∗ = {x ∈ X s.t. f (x) ∈ P ∗} denote the
set of Pareto optimal solutions and Pareto optimal inputs, respectively. Provided with the Pareto set,
decision-makers can select a solution with an objective trade-off according to their preferences.

A common approach for solving MO problems is to use evolutionary algorithms (e.g. NSGA-II),
which are robust multi-objective optimizers, but require a large number of function evaluations [14].
Bayesian optimization (BO) offers a far more sample-efﬁcient alternative [57].

Bayesian Optimization: BO [38] is an established method for optimizing expensive-to-evaluate
black-box functions. BO relies on a probabilistic surrogate model, typically a Gaussian Process
(GP) [55], to provide a posterior distribution P(f |D) over the true function values f given the
i=1. An acquisition function α : Xcand (cid:55)→ R employs the surrogate
observed data D = {(xi, yi)}n
model to assign a utility value to a set of candidates Xcand = {xi}q
i=1 to be evaluated on the true
function. While the true f may be expensive-to-evaluate, the surrogate-based acquisition function
is not, and can thus be efﬁciently optimized to yield a set of candidates Xcand to be evaluated on f .
If gradients of α(Xcand) are available, gradient-based methods can be utilized. If not, gradients are
either approximated (e.g. with ﬁnite differences) or gradient-free methods (e.g. DIRECT [37] or
CMA-ES [32]) are used.

1.2 Limitations of current approaches

In the single-objective (SO) setting, a large body of work focuses on practical extensions to BO for
supporting parallel evaluation and outcome constraints [49, 30, 66, 25, 43]. Less attention has been
given to such extensions in the MO setting. Moreover, the existing constrained and parallel MO BO
options have limitations: 1) many rely on scalarizations to transform the MO problem into a SO
one [40]; 2) many acquisition functions are computationally expensive to compute [52, 21, 6, 71]; 3)
few have known analytical gradients or are differentiable [19, 62, 33]; 4) many rely on heuristics to
extend sequential algorithms to the parallel setting [27, 62].

A natural acquisition function for MO BO is Expected Hypervolume Improvement (EHVI). Max-
imizing the hypervolume (HV) has been shown to produce Pareto fronts with excellent cover-
age [73, 12, 69]. However, there has been little work on EHVI in the parallel setting, and the
work that has been done resorts to approximate methods [71, 28, 62]. A vast body of literature has
focused on efﬁcient EHVI computation [34, 20, 67], but the time complexity for computing EHVI is
exponential in the number of objectives—in part due the hypervolume indicator itself incurring a
time complexity that scales super-polynomially with the number of objectives [68]. Our core insight
is that by exploiting advances in auto-differentiation and highly parallelized hardware [51], we can
make EHVI computations fast and practical.

1.3 Contributions

In this work, we derive a novel formulation of the parallel q-Expected Hypervolume Improvement
acquisition function (qEHVI) that is exact up to Monte-Carlo (MC) integration error. We compute the
exact gradient of the MC estimator of qEHVI using auto-differentiation, which allows us to employ
efﬁcient and effective gradient-based optimization methods. Rather than using ﬁrst-order gradient
methods, we instead leverage the sample average approximation (SAA) approach from [5] to use
higher-order deterministic optimization methods, and we prove theoretical convergence guarantees
under the SAA approach. Our formulation of qEHVI is embarrassingly parallel, and despite its
computational cost would achieve constant time complexity given inﬁnite processing cores. We
demonstrate that, using modern GPU hardware and computing exact gradients, optimizing qEHVI
is faster than existing state-of-the art methods in many practical scenarios. Moreover, we extend
qEHVI to support auxiliary outcome constraints, making it practical in many real-world scenarios.
Lastly, we demonstrate how modern auto-differentiation can be used to compute exact gradients of
analytic EHVI, which has never been done before for M > 2 objectives. Our empirical evaluation

2

shows that qEHVI outperforms state-of-the-art multi-objective BO algorithms while using only a
fraction of their wall time.

2 Related Work

Yang et al. [69] is the only previous work to consider exact gradients of EHVI, but the authors only
derive an analytical gradient for the unconstrained two-objective, sequential optimization setting.
All other works either do not optimize EHVI (e.g. they use it for pre-screening candidates [18]),
optimize it with gradient-free methods [68], or using approximate gradients [62]. In contrast, we use
exact gradients and demonstrate that optimizing EHVI using this gradient information is far more
efﬁcient.

There are many alternatives to EHVI for MO BO. For example, ParEGO [40] and TS-TCH [50]
randomly scalarize the objectives and use Expected Improvement [38] and Thompson Sampling [61],
respectively. SMS-EGO [53] uses HV in a UCB-based acquisition function and is more scalable than
EHVI [54]. ParEGO and SMS-EGO have only been considered for the q = 1, unconstrained setting.
Predictive entropy search for MO BO (PESMO) [33] has been shown to be another competitive
alternative and has been extended to handle constraints [26] and parallel evaluations [27]. MO
max-value entropy search (MO-MES) has been shown to achieve superior optimization performance
and faster wall times than PESMO, but is limited to q = 1.

Wilson et al. [65] empirically and theoretically show that sequential greedy selection of q candidates
achieves performance comparable to jointly optimizing q candidates for many acquisition functions
(including [63, 66]). The sequential greedy approach integrates over the posterior of the unobserved
outcomes corresponding to the previously selected candidates in the q-batch. Sequential greedy
optimization often yields better empirical results because the optimization problem has a lower
dimension: d in each step, rather than qd in the joint problem. Most prior works in the MO setting use
a sequential greedy approximation or heuristics [62, 71, 28, 10], but impute the unobserved outcomes
with the posterior mean rather than integrating over the posterior [30]. For many joint acquisition
functions involving expectations, this shortcut sacriﬁces the theoretical error bound on the sequential
greedy approximation because the exact joint acquisition function over x1, ..., xi, 1 ≤ i ≤ q requires
integration over the joint posterior P(f (x1), ..., f (xq)|D) and is not computed for i > 1.
Garrido-Merchán and Hernández-Lobato [27] and Wada and Hino [62] jointly optimize the q candi-
dates and, noting the difﬁculty of the optimization, both papers focus on deriving gradients to aid in
the optimization. Wada and Hino [62] deﬁned the qEHVI acquisition function, but after ﬁnding it
challenging to optimize q candidates jointly (without exact gradients), the authors propose optimizing
an alternative acquisition function instead of exact qEHVI. In contrast, our novel qEHVI formulation
allows for gradient-based parallel and sequential greedy optimization, with proper integration over
the posterior for the latter.

Feliot et al. [22] and Abdolshah et al. [1] proposed extensions of EHVI to the constrained q = 1
setting, but neither considers the batch setting and both rely on gradient-free optimization.

3 Differentiable q-Expected Hypervolume Improvement

In this section, we review HVI and EHVI computation by means of box decompositions, and explain
our novel formulation for the parallel setting.
Deﬁnition 1. Given a reference point r ∈ RM , the hypervolume indicator (HV) of a ﬁnite approxi-
mate Pareto set P is the M -dimensional Lebesgue measure λM of the space dominated by P and
i=1[r, yi](cid:1), where [r, yi] denotes the hyper-rectangle
bounded from below by r: HV(P, r) = λM
bounded by vertices r and yi.
Deﬁnition 2. Given a Pareto set P and reference point r, the hypervolume improvement (HVI) of a
set of points Y is: HVI(Y, P, r) = HV(P ∪ Y, r) − HV(P, r).1
EHVI is the expectation of HVI over the posterior P(f , D): αEHVI(Xcand) = E(cid:2)HVI(f (Xcand))(cid:3).
In the sequential setting, and assuming the objectives are independent and modeled with independent

(cid:0) (cid:83)|P|

1In this work, we omit the arguments P and r when referring to HVI for brevity.

3

GPs, EHVI can be expressed in closed form [69]. In other settings, EHVI can be approximated with
MC integration. Following previous work, we assume that the reference point is known and speciﬁed
by the decision maker [69] (see Appendix E.1.1 for additional discussion).

3.1 A review of hypervolume improvement computation using box decompositions

i=1, dominate r, and are not dominated by P.

i=1, a reference point r ∈ RM , and a non-
i=1, P, r) ⊂ RM denote the set of points (i) are dominated by

Deﬁnition 3. For a set of objective vectors {f (xi)}q
dominated set P, let ∆({f (xi)}q
{f (xi)}q
Given P, r, the HVI of a new point f (x) is the HV of the intersection of space dominated by
P ∪ {f (x)} and the non-dominated space. Figure 1b illustrates this for one new point f (x) for
M = 2. The yellow region is ∆({f (x)}, P, r) and the hypervolume improvement is the volume
covered by ∆({f (x)}, P, r). Since ∆({f (x)}, P, r) is often a non-rectangular polytope, HVI is
typically computed by partitioning the non-dominated space into disjoint axis-parallel rectangles
[12, 68] (see Figure 1a) and using piece-wise integration [18].
Let {Sk}K
k=1 be a partitioning the of non-dominated space into disjoint hyper-rectangles, where each
Sk is deﬁned by a pair of lower and upper vertices lk ∈ RM and uk ∈ RM ∪ {∞}. The high level
idea is to sum the HV of Sk ∩ ∆({f (x)}, P, r) over all Sk. For each hyper-rectangle Sk, the intersec-
tion of Sk and ∆({f (x)}, P, r) is a hyper-rectangle where the lower bound vertex is lk and the upper
bound vertex is the component-wise minimum of uk and the new point f (x): zk := min (cid:2)uk, f (x)(cid:3).

(a)

(b)

(c)

Figure 1: For M=2, (a) the dominated space (red) and the non-dominated space partitioned into
disjoint boxes (white), (b) the HVI of one new point f (x), and (c) the HVI of two new points
f (x1), f (x2).

(cid:0)Sk ∩ ∆({f (x)}, P, r)(cid:1) = (cid:81)M

(cid:1) =
Hence, the HVI of a single outcome vector f (x) within Sk is given by HVIk
(cid:2)z(m)
λM
denote
k
the mth component of the corresponding vector and [·]+ denotes the min(·, 0) operation. Summing
over rectangles yields

, f (m)(x), and z(m)

+, where u(m)

(cid:0)f (x), lk, uk

k − l(m)

, l(m)
k

m=1

(cid:3)

k

k

HVI(cid:0)f (x)(cid:1) =

K
(cid:88)

k=1

HVIk

(cid:0)f (x), lk, uk

(cid:1) =

K
(cid:88)

M
(cid:89)

k=1

m=1

(cid:2)z(m)

k − l(m)

k

(cid:3)
+

(1)

3.2 Computing q-Hypervolume Improvement via the Inclusion-Exclusion Principle

Figure 1c illustrates the HVI in the q = 2 setting. Given q new points{f (xi)}q
let
Ai := ∆({f (xi)}, P, r) for i = 1, . . . , q be the space dominated by f (xi) but not dominated by P,
independently of the other q − 1 points. Note that λM (Ai) = HVI(f (xi)). The union of the subsets
Ai is the space dominated jointly by the q new points: (cid:83)q
i=1 ∆({f (xi)}, P, r), and the
(cid:1) is the joint HVI from the q new points. Since each subspace Ai is
Lebesgue measure λM
i=1 Ai
(cid:1) using the
bounded, the restricted Lebesgue measure is ﬁnite and we may compute λM
inclusion-exclusion principle [13, 59]:

i=1 Ai = (cid:83)q

i=1 Ai

(cid:0) (cid:83)q

(cid:0) (cid:83)q

i=1,

HVI({f (xi)}q

i=1) = λM

(cid:18) q
(cid:91)

(cid:19)

Ai

=

i=1

q
(cid:88)

j=1

(−1)j+1 (cid:88)

λM

(cid:0)Ai1 ∩ · · · ∩ Aij

(cid:1)

(2)

1≤i1≤...≤ij ≤q

4

rl3S3u3u2S2l2l4S4u4u1l1S1f(2)(x)f(1)(x)f(x1)rl3S3u3u2S2l2l4S4u4u1l1S1f(2)(x)f(1)(x)f(x1)f(2)(x)f(1)(x)rl3S3u3u2S2l2l4S4u4u1l1S1f(x2)k=1 is a disjoint partition, λM (Ai1 ∩ · · · ∩ Aij ) = (cid:80)K

Since {Sk}K
k=1 λM (Sk ∩ Ai1 ∩ · · · ∩ Aij ), we
can compute λM (Ai1 ∩ · · · ∩ Aij ) in a piece-wise fashion across the K hyper-rectangles {Sk}K
k=1
as the HV of the intersection of Ai1 ∩ · · · ∩ Aij with each hyper-rectangle Sk. The inclusion-
exclusion principle has been proposed for computing HV (not HVI) [45], but it is rarely used because
complexity scales exponentially with the number of elements. However, the inclusion-exclusion
principle is practical for computing the joint HVI of q points since typically q << |P|.

This formulation has three advantages. First, while the new dominated space Ai can be a
non-rectangular polytope, the intersection Ai ∩ Sk is a rectangular polytope, which simpliﬁes
computation of overlapping hypervolume. Second, the vertices deﬁning the hyper-rectangle
Sk ∩ Ai1 ∩ · · · ∩ Aij are easily derived. The lower bound is simply the lk lower bound of Sk, and the
upper bound is the component-wise minimum zk,i1,...ij := min (cid:2)uk, f (xi1), . . . , f (xij )(cid:3). Third,
computation can be across all intersections of subsets Ai1 ∩ · · · ∩ Aij for 1 ≤ ij ≤ . . . ≤ ij ≤ q and
across all K hyper-rectangles can be performed in parallel. Explicitly, the HVI is computed as:

HVI({f (xi)}q

i=1) =

K
(cid:88)

q
(cid:88)

(cid:88)

(−1)j+1

M
(cid:89)

(cid:2)z(m)
k,Xj

− l(m)
k

(cid:3)
+

(3)

Xj ∈Xj
where Xj := {Xj ⊂ Xcand : |Xj| = j} is the superset of all subsets of Xcand of size j, and
z(m)
k,Xj

for Xj = {xi1, ..., xij }. See Appendix A for further details of the derivation.

:= z(m)

k,i1,...ij

k=1

j=1

m=1

3.3 Computing Expected q-Hypervolume Improvement

The above approach for computing HVI assumes that we know the true objective values
f (Xcand) = {f (xi)}q
i=1. In BO, we instead compute qEHVI as the expectation over the posterior
model posterior:
(cid:90) ∞

(cid:105)

HVI(f (Xcand))

=

HVI(f (Xcand))df .

(4)

(cid:104)
αqEHVI(Xcand) = E

−∞

Since no known analytical form is known [70] for q > 1 (or in the case of correlated out-
comes), we estimate (4) using MC integration with samples from the joint posterior {ft(xi)}q
i=1 ∼
P(cid:0)f (x1), ..., f (xq)|D(cid:1), t = 1, . . . N . Let z(m)
1
N

k,Xj ,t := min (cid:2)uk, minx(cid:48)∈Xj ft(x(cid:48))(cid:3). Then,
(cid:88)

HVI(ft(Xcand)) =

k,Xj ,t −l(m)

qEHVI(Xcand) =

(cid:3)
+ (5)

(−1)j+1

(cid:2)z(m)

q
(cid:88)

N
(cid:88)

K
(cid:88)

N
(cid:88)

1
N

M
(cid:89)

ˆαN

k

t=1

t=1

k=1

j=1

Xj ∈Xj

m=1

√

Provided that {Sk}K
k=1 is an exact partitioning, (5) is an exact computation of qEHVI up to the MC
estimation error, which scales as 1/
N when using iid MC samples regardless of the dimension of
the search space [18]. In practice, we use randomized quasi MC methods [8] to reduce the variance
and empirically observe low estimation error (see Figure 5a in the Appendix for a comparison of
analytic EHVI and (quasi-)MC-based qEHVI).
qEHVI requires computing the volume of 2q − 1 hyper-rectangles (the number of subsets of q) for
each of K hyper-rectangles and N MC samples. Given posterior samples, the time complexity on
a single-threaded machine is: T1 = O(M N K(2q − 1)). In the two-objective case, K = |P| + 1,
but K is super-polynomial in M [68]. The number of boxes required for a decomposition of the
non-dominated space is unknown for M ≥ 4 [68]. qEHVI is agnostic to the partitioning algorithm
used, and in F.4, we demonstrate using qEHVI in higher-dimensional objective spaces using an
approximate box decomposition algorithm [11]. Despite the daunting workload, the critical work
path—the time complexity of the smallest non-parallelizable unit—is constant: T∞ = O(1).2 On
highly-threaded many-core hardware (e.g. GPUs), our formulation achieves tractable wall times in
many practical scenarios: as is shown in Figure 11 in the Appendix, the computation time is nearly
constant with increasing q until an inﬂection point at which the workload saturates the available cores.
For additional discussion of both time and memory complexity of qEHVI see Appendix A.4.

3.4 Outcome Constraints

Our proposed qEHVI acquisition function is easily extended to constraints on auxiliary outcomes. We
consider the scenario where we receive observations of M objectives f (x) ∈ RM and V constraints

2As evident from (5), the critical path consists of 3 multiplications and 5 summations.

5

c(v) ∈ RV , all of which are assumed to be “black-box”. We assume w.l.o.g. that c(v) is feasible
iff c(v) ≥ 0. In the constrained optimization setting, we aim to identify the feasible Pareto set:
Pfeas = {f (x) s.t. c(x) ≥ 0, (cid:64) x(cid:48) : c(x(cid:48)) ≥ 0, f (x(cid:48)) (cid:31) f (x)}. The natural improvement
measure in the constrained setting is feasible HVI, which we deﬁne for a single candidate point x as
HVIC(f (x), c(x)) := HVI[f (x)] · 1[c(x) ≥ 0]. Taking expectations, the constrained expected HV
can be seen to be the HV weighted by the probability of feasibility. In Appendix A.3, we detail how
performing feasibility-weighting on the sample-level allows us to include such auxiliary outcome
constraints into our MC formulation in a straightforward way.

4 Optimizing q-Expected Hypervolume Improvement

4.1 Differentiability

While an analytic formula for the gradient of EHVI exists for the M = 2 objective case in the
unconstrained, sequential (q = 1) setting, no such formula is known in 1) the case of M > 2
objectives, 2) the constrained setting, and 3) for q > 1. Leveraging the re-parameterization trick
[39, 64] and auto-differentiation, we are able to automatically compute exact gradients of the MC-
estimator qEHVI in all of the above settings, as well as the gradient of analytic EHVI for M ≥ 2
(see Figure 5b in the Appendix for a comparison of the exact gradients of EHVI and the sample
average gradients of qEHVI for M = 3).3,4

4.2 Optimization via Sample Average Approximation

We show in Appendix C that if mean and covariance function of the GP are sufﬁciently regular, the
gradient of the MC estimator (5) is an unbiased estimate of the gradient of the exact acquisition
function (4). To maximize qEHVI, we could therefore directly apply stochastic optimization methods,
as has previously been done for single-outcome acquisition functions [64, 66]. Instead, we opt to
use the sample average approximation (SAA) approach from Balandat et al. [5], which allows us
to employ deterministic, higher-order optimizers to achieve faster convergence rates. Informally
(see Appendix C for the formal statement), if ˆx∗
qEHVI(x), we can show under
some regularity conditions that, as N → ∞, (i) ˆαN
N ) → maxx∈X αqEHVI(x) a.s., and
N , arg maxx∈X αqEHVI(x)(cid:1)→ 0 a.s.. These results hold for any covariance function
(ii) dist(cid:0)ˆx∗
satisfying the regularity conditions, including such ones that model correlation between outcomes. In
particular, our results do not require the outputs to be modeled by independent GPs.

N ∈ arg maxx∈X ˆαN

qEHVI(ˆx∗

Figure 2a demonstrates the importance of using exact gradients for efﬁciently and effectively op-
timizing EHVI and qEHVI by comparing the following optimization methods: L-BFGS-B with
exact gradients, L-BFGS-B with gradients approximated via ﬁnite differences, and CMA-ES (without
gradients). The cumulative time spent optimizing the acquisition function is an order of magnitude
less when using exact gradients rather than approximate gradients or zeroth order methods.

4.3 Sequential Greedy and Joint Batch Optimization

Jointly optimizing q candidates increases in difﬁculty with q because the problem dimension is dq.
An alternative is to sequentially and greedily select candidates and condition the acquisition function
on the previously selected pending points when selecting the next point [65]. Using a submodularity
argument similar to that in Wilson et al. [64], the sequential greedy approximation of qEHVI enjoys
regret of no more than 1

qEHVI is the optima of αqEHVI [23] (see Appendix B).

qEHVI, where α∗

e α∗

Although sequential greedy approaches have been considered for many acquisition functions [65], no
previous work has proposed a proper sequential greedy approach (with integration over the posterior)
for parallel EHVI, as this would require computing the Pareto front under each sample ft from
the joint posterior before computing the hypervolume improvement. These operations would be
computationally expensive for even modest N and non-differentiable. qEHVI avoids determining
the Pareto set for each sample by using inclusion-exclusion principle to compute the joint HVI over
the pending points x1, ..., xi−1 and the new candidate xi for each MC sample. Figure 2b empirically

3Technically, min and max are only sub-differentiable, but are known to be well-behaved [64]. In our MC

setting with GP posteriors, qEHVI is differentiable w.p. 1 if x contains no repeated points.

4For the constrained case, we replace the indicator with a differentiable sigmoid approximation.

6

(a)

(b)

Figure 2: (a) A comparison of EHVI and qEHVI (q = 2) optimized with L-BFGS-B using exact
gradients, L-BFGS-B using gradients approximated using ﬁnite differences, and CMA-ES, a gradient-
free method. (b) A comparison of joint optimization, sequential greedy optimization with proper
integration at the pending points, and sequential greedy using the posterior mean. Both plots show
optimization performance on a DTLZ2 problem (d = 6, M = 2) with a budget of 100 evaluations
(plus the initial quasi-random design). We report means and 2 standard errors across 20 trials.

demonstrates the improved optimization performance from properly integrating over the unobserved
outcomes rather than using the posterior mean or jointly optimizing the q candidates.

5 Benchmarks

We empirically evaluate qEHVI on synthetic and real world optimization problems. We compare
qEHVI5 against existing state-of-the-art methods including SMS-EGO6, PESMO6, TS-TCH5, and
analytic EHVI [68] with gradients5. Additionally, we compare against a novel extension of ParEGO
[40] that supports parallel evaluation and constraints (neither of which have been done before to our
knowledge); we call this method qPAREGO5. Additionally, we include a quasi-random baseline that
selects candidates from a scrambled Sobol sequence. See Appendix E.1 for details on all baseline
algorithms.

Synthetic Benchmarks We evaluate optimization performance on four benchmark problems in
terms of log hypervolume difference, which is deﬁned as the difference between the hypervolume of
the true (feasible) Pareto front and the hypervolume of the approximate (feasible) Pareto front based
on the observed data; in the case that the true Pareto front is unknown (or not easily approximated),
we evaluate the hypervolume indicator. All references points and search spaces are provided in
Appendix E.2. For synthetic problems, we consider the Branin-Currin problem (d = 2, M = 2,
convex Pareto front) [6] and the C2-DTLZ2 (d = 12, M = 2, V = 1, concave Pareto front), which
is a standard constrained benchmark from the MO literature [16] (see Appendix F.1 for additional
synthetic benchmarks).

Real-World Benchmarks
Structural Optimization in Automobile Safety Design (VEHICLESAFETY): Vehicle crash safety is
an important consideration in the structural design of automobiles. A lightweight car is preferable
because of its potentially lower manufacturing cost and better fuel economy, but lighter material can
fare worse than sturdier alternatives in a collision, potentially leading to increased vehicle damage and
more severe injury to the vehicle occupants [72]. We consider the problem designing the thickness of
5 reinforced parts of the frontal frame of a vehicle that considerably affect crash safety. The goal
is to minimize: 1) the mass of the vehicle; 2) the collision acceleration in a full frontal crash—a
proxy for bio-mechanical trauma to the vehicle occupants from the acceleration; and 3) the toe-board

5Acquisition functions are available as part of the open-source library BoTorch [5]. Code is available at

https://github.com/pytorch/botorch.

6We leverage existing implementations from the Spearmint library. The code is available at https://

github.com/HIPS/Spearmint/tree/PESM.

7

05000100001500020000Average Cumulative Acquisition Optimization Wall Time (s)0.400.350.300.250.200.150.10log HV differenceEHVI ­ Exact GradientEHVI ­ Approx. GradientEHVI ­ Gradient FreeqEHVI (q=2) ­ Exact GradientqEHVI (q=2) ­ Approx. GradientqEHVI (q=2) ­ Gradient Free020406080100Batch Iteration1.81.61.41.21.00.80.60.4log HV differenceqEHVI Joint q=2qEHVI Joint q=4qEHVI Joint q=8qEHVI Post. Mean q=2qEHVI Post. Mean q=4qEHVI Post. Mean q=8qEHVI Seq. Greedy q=2qEHVI Seq. Greedy q=4qEHVI Seq. Greedy q=8qEHVI q=1(a)

(c)

(b)

(d)

Figure 3: Sequential optimization performance on (a) on the Branin-Currin problem (q = 1), (b) the
C2-DTLZ2 problem, (c) the vehicle crash safety problem (q = 1), and (d) the ABR control problem
(q = 1). We report the means and 2 standard errors across 20 trials.

intrusion—a measure of the most extreme mechanical damage to the vehicle in an off-frontal collision
[44]. For this problem, we optimize the surrogate from Tanabe and Ishibuchi [60].

Policy Optimization for Adaptive Bitrate Control (ABR): Many web services adapt video playback
quality adaptively based on the receiver’s network bandwith to maintain steady, high quality stream
with minimal stalls and buffer periods [47]. Previous works have proposed controllers with different
scalarized objective functions [46], but in many cases, engineers may prefer to learn the set of optimal
trade-offs between their metrics of interest, rather than specifying a scalarized objective in advance.
In this problem, we decompose the objective function proposed in Mao et al. [46] into its constituent
metrics and optimize 4 parameters of an ABR control policy on the Park simulator [48] to maximize
video quality (bitrate) and minimize stall time. See Appendix E.2 for details.

5.1 Results

Figure 3 shows that qEHVI outperforms all baselines in terms of sequential optimization performance
on all evaluated problems. Table 1 shows that qEHVI achieves wall times that are an order of
magnitude smaller than those of PESMO on a CPU in sequential optimization, and maintains
competitive wall times even relative to qPAREGO (which has a signiﬁcantly smaller workload) for
large q on a GPU. TS-TCH has by far the fastest wall time, but this comes at the cost of inferior
optimization performance.

Figure 4 illustrates optimization performance of parallel acquisition functions for varying batch
sizes. Increasing the level of parallelism leads to faster convergence for all algorithms (Figure 4a). In
contrast with other algorithms, qEHVI’s sample complexity does not deteriorate substantially when
high levels of parallelism are used (Figure 4b).

8

020406080100Function Evaluations0.00.51.01.5log HV DifferenceSobolEHVIqEHVIqParEGOTS­TCHPESMOSMS­EGO020406080100Function Evaluations1.00.90.80.70.60.50.4log HV DifferenceSobolqEHVIqParEGO020406080100Function Evaluations0.00.51.01.52.0log HV DifferenceSobolEHVIqEHVIqParEGOTS­TCHPESMOSMS­EGO020406080100Function Evaluations3.03.13.23.33.43.53.6HV1e6SobolEHVIqEHVIqParEGOTS­TCHPESMOSMS­EGOTable 1: Acquisition Optimization wall time in seconds on a CPU (2x Intel Xeon E5-2680 v4 @
2.40GHz) and a GPU (Tesla V100-SXM2-16GB). We report the mean and 2 standard errors across
20 trials. NA indicates that the algorithm does not support constraints.

CPU

BRANINCURRIN

C2DTLZ2

ABR

VEHICLESAFETY

PESMO (q=1)
SMS-EGO (q=1)
TS-TCH (q=1)
qPAREGO (q=1)
EHVI (q=1)
qEHVI (q=1)

249.16 (±19.35)
146.1 (±8.57)
2.82 (±0.03)
1.56 (±0.16)
3.04 (±0.16)
3.63 (±0.23)

NA
NA
NA
4.01 (±0.77)
NA
5.4 (±1.18)

214.16 (±18.38)
89.54 (±5.79)
17.22 (±0.04)
7.47 (±0.67)
2.48 (±0.19)
6.15 (±0.71)

492.64 (±58.98)
115.11 (±8.21)
47.46 (±0.05)
1.74 (±0.27)
15.18 (±2.24)
67.54 (±10.45)

GPU

BRANINCURRIN

C2DTLZ2

ABR

VEHICLESAFETY

TS-TCH (q=1)
TS-TCH (q=2)
TS-TCH (q=4)
TS-TCH (q=8)
qPAREGO (q=1)
qPAREGO (q=2)
qPAREGO (q=4)
qPAREGO (q=8)
EHVI (q=1)
qEHVI (q=1)
qEHVI (q=2)
qEHVI (q=4)
qEHVI (q=8)

0.07 (±0.00)
0.07 (±0.00)
0.09 (±0.01)
0.08 (±0.00)
3.2 (±0.37)
7.12 (±0.81)
15.34 (±1.69)
32.11 (±4.14)
4.53 (±0.23)
5.98 (±0.28)
11.37 (±0.56)
25.29 (±1.51)
102.46 (±9.22)

NA
NA
NA
NA
3.85 (±0.91)
12.1 (±2.77)
39.71 (±7.40)
99.58 (±15.20)
NA
3.36 (±0.94)
21.56 (±3.45)
89.18 (±10.86)
215.74 (±15.85)

0.16 (±0.00)
0.15 (±0.00)
0.15 (±0.00)
0.16 (±0.00)
9.64 (±0.96)
21.19 (±1.53)
35.46 (±2.32)
72.52 (±5.04)
6.82 (±0.55)
7.71 (±0.67)
18.32 (±1.48)
44.44 (±3.53)
100.64 (±7.22)

0.32 (±0.0)
0.34 (±0.01)
0.31 (±0.01)
0.34 (±0.01)
3.44 (±0.51)
7.32 (±0.97)
17.2 (±2.29)
39.72 (±7.13)
8.95 (±0.64)
10.43 (±0.64)
17.67 (±1.54)
54.25 (±4.17)
255.72 (±23.73)

(a)

(b)

Figure 4: Parallel optimization performance on the ABR problem with varying batch sizes (q) by (a)
batch BO iterations and (b) function evaluations.
6 Discussion

We present a practical and efﬁcient acquisition function, qEHVI, for parallel, constrained multi-
objective Bayesian optimization. Leveraging differentiable programming, modern parallel hardware,
and the Sample Average Approximation, we efﬁciently optimize qEHVI via quasi second-order meth-
ods and provide theoretical convergence guarantees for our approach. Empirically, we demonstrate
that our method out-performs state-of-the-art multi-objective Bayesian optimization methods.

One limitation of our approach is that it currently assumes noiseless observations, which, to our
knowledge, is the case with all formulations of EHVI. Integrating over the uncertainty around the
previous observations [43] by using MC samples over the new candidates and the training points, one
may be able to account for the noise.Another limitation of qEHVI is that its scalability is limited
the partitioning algorithm, precluding its use in high-dimensional objective spaces. More scalable
partitioning algorithms, either approximate algorithms (e.g. the algorithm proposed by Couckuyt
et al. [11], which we examine brieﬂy in Appendix F.4) or more efﬁcient exact algorithms that result
in fewer disjoint hyper-rectangles (e.g. [41, 17, 69]), will improve the scalability and computation
time of of qEHVI. We hope this work encourages researchers to consider more improvements from
applying modern computational paradigms and tooling to Bayesian optimization.

9

020406080100Batch Iteration3.03.13.23.33.43.53.6HV1e6Sobol q=8TS q=1TS q=2TS q=4TS q=8qEHVI q=1qEHVI q=2qEHVI q=4qEHVI q=8qParEGO q=1qParEGO q=2qParEGO q=4qParEGO q=8020406080100Function Evaluations3.03.13.23.33.43.53.6HV1e6Sobol q=8TS q=1TS q=2TS q=4TS q=8qEHVI q=1qEHVI q=2qEHVI q=4qEHVI q=8qParEGO q=1qParEGO q=2qParEGO q=4qParEGO q=87 Statement of Broader Impact

Optimizing a single outcome commonly comes at the expense of other secondary outcomes. In some
cases, decision makers may be able to form a scalarization of their objectives in advance, but in the
researcher’s experience, formulating such trade-offs in advance is difﬁcult for most. Improvements
to the optimization performance and practicality of multi-objective Bayesian optimization have the
potential to allow decision makers to better understand and make more informed decisions across
multiple trade-offs. We expect these directions to be particularly important as Bayesian optimization
is increasingly used for applications such as recommender systems [42], where auxiliary goals such
as fairness must be accounted for. Of course, at the end of the day, exactly what objectives decision
makers choose to optimize, and how they balance those trade-offs (and whether that is done in
equitable fashion) is up to the individuals themselves.

Acknowledgments

We would like to thank Daniel Jiang for helpful discussions around our theoretical results.

References

[1] M. Abdolshah, A. Shilton, S. Rana, S. Gupta, and S. Venkatesh. Expected hypervolume improvement
with constraints. In 2018 24th International Conference on Pattern Recognition (ICPR), pages 3238–3243,
2018.

[2] Arash Asadpour, Hamid Nazerzadeh, and Amin Saberi. Stochastic submodular maximization. In Christos
Papadimitriou and Shuzhong Zhang, editors, Internet and Network Economics. Springer Berlin Heidelberg,
2008.

[3] R. Astudillo and P. Frazier. Bayesian optimization of composite functions. Forthcoming, in Proceedings of

the 35th International Conference on Machine Learning, 2019.

[4] Anne Auger, Johannes Bader, Dimo Brockhoff, and Eckart Zitzler. Theory of the hypervolume indicator:
Optimal mu-distributions and the choice of the reference point. In Proceedings of the Tenth ACM SIGEVO
Workshop on Foundations of Genetic Algorithms, FOGA ’09, page 87–102, New York, NY, USA, 2009.
Association for Computing Machinery.

[5] Maximilian Balandat, Brian Karrer, Daniel R. Jiang, Samuel Daulton, Benjamin Letham, Andrew Gordon
Wilson, and Eytan Bakshy. BoTorch: A Framework for Efﬁcient Monte-Carlo Bayesian Optimization. In
Advances in Neural Information Processing Systems 33, 2020.

[6] Syrine Belakaria, Aryan Deshwal, and Janardhan Rao Doppa. Max-value entropy search for multi-objective

bayesian optimization. In Advances in Neural Information Processing Systems 32, 2019.

[7] Eric Bradford, Artur Schweidtmann, and Alexei Lapkin. Efﬁcient multiobjective optimization employing
gaussian processes, spectral sampling and a genetic algorithm. Journal of Global Optimization, 71, 02
2018. doi: 10.1007/s10898-018-0609-2.

[8] Russel E Caﬂisch. Monte carlo and quasi-monte carlo methods. Acta numerica, 7:1–49, 1998.

[9] Mauro Cerasoli and Aniello Fedullo. The inclusion-exclusion principle. Journal of Interdisciplinary

Mathematics, 5(2):127–141, 2002.

[10] Anirban Chaudhuri, Raphael Haftka, Peter Ifju, Kelvin Chang, Christopher Tyler, and Tony Schmitz.
Experimental ﬂapping wing optimization and uncertainty quantiﬁcation using limited samples. Structural
and Multidisciplinary Optimization, 51, 11 2014. doi: 10.1007/s00158-014-1184-x.

[11] I. Couckuyt, D. Deschrijver, and T. Dhaene. Towards efﬁcient multiobjective optimization: Multiobjective

statistical criterions. In 2012 IEEE Congress on Evolutionary Computation, pages 1–8, 2012.

[12] Ivo Couckuyt, Dirk Deschrijver, and Tom Dhaene. Fast calculation of multiobjective probability of
improvement and expected improvement criteria for pareto optimization. J. of Global Optimization, 60(3):
575–594, November 2014.

[13] Daniel A. da Silva. Proprietades geraes. J. de l’Ecole Polytechnique, cah. 30. I, 1854.

10

[14] K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan. A fast and elitist multiobjective genetic algorithm:

Nsga-ii. IEEE Transactions on Evolutionary Computation, 6(2):182–197, 2002.

[15] Kalyan Deb, L. Thiele, Marco Laumanns, and Eckart Zitzler. Scalable multi-objective optimization test
problems. volume 1, pages 825–830, 06 2002. ISBN 0-7803-7282-4. doi: 10.1109/CEC.2002.1007032.

[16] Kalyanmoy Deb. Constrained Multi-objective Evolutionary Algorithm, pages 85–118. Springer Interna-

tional Publishing, Cham, 2019.

[17] Kerstin Dächert, Kathrin Klamroth, Renaud Lacour, and Daniel Vanderpooten. Efﬁcient computation of
the search region in multi-objective optimization. European Journal of Operational Research, 260(3):841 –
855, 2017.

[18] M. T. M. Emmerich, K. C. Giannakoglou, and B. Naujoks. Single- and multiobjective evolutionary opti-
mization assisted by gaussian random ﬁeld metamodels. IEEE Transactions on Evolutionary Computation,
10(4):421–439, 2006.

[19] M. T. M. Emmerich, A. H. Deutz, and J. W. Klinkenberg. Hypervolume-based expected improvement:
Monotonicity properties and exact computation. In 2011 IEEE Congress of Evolutionary Computation
(CEC), pages 2147–2154, 2011.

[20] Michael Emmerich, Kaifeng Yang, André Deutz, Hao Wang, and Carlos M. Fonseca. A Multicriteria
Generalization of Bayesian Global Optimization, pages 229–242. Springer International Publishing, 2016.

[21] Michael T. M. Emmerich and Carlos M. Fonseca. Computing hypervolume contributions in low dimensions:
Asymptotically optimal algorithm and complexity results. In Ricardo H. C. Takahashi, Kalyanmoy Deb,
Elizabeth F. Wanner, and Salvatore Greco, editors, Evolutionary Multi-Criterion Optimization, pages
121–135, Berlin, Heidelberg, 2011. Springer Berlin Heidelberg.

[22] Paul Feliot, Julien Bect, and Emmanuel Vazquez. A bayesian approach to constrained single- and multi-
objective optimization. Journal of Global Optimization, 67(1-2):97–133, Apr 2016. ISSN 1573-2916. doi:
10.1007/s10898-016-0427-3. URL http://dx.doi.org/10.1007/s10898-016-0427-3.

[23] M. L. Fisher, G. L. Nemhauser, and L. A. Wolsey. An analysis of approximations for maximizing
submodular set functions—II, pages 73–87. Springer Berlin Heidelberg, Berlin, Heidelberg, 1978.

[24] Tobias Friedrich and Frank Neumann. Maximizing submodular functions under matroid constraints by
multi-objective evolutionary algorithms. In Thomas Bartz-Beielstein, Jürgen Branke, Bogdan Filipiˇc, and
Jim Smith, editors, Parallel Problem Solving from Nature – PPSN XIII, pages 922–931, Cham, 2014.
Springer International Publishing. ISBN 978-3-319-10762-2.

[25] Jacob Gardner, Matt Kusner, Zhixiang, Kilian Weinberger, and John Cunningham. Bayesian optimization
with inequality constraints. In Proceedings of the 31st International Conference on Machine Learning,
volume 32 of Proceedings of Machine Learning Research, pages 937–945, Beijing, China, 22–24 Jun 2014.
PMLR.

[26] Eduardo C Garrido-Merchán and Daniel Hernández-Lobato. Predictive entropy search for multi-objective

bayesian optimization with constraints. Neurocomputing, 361:50–68, 2019.

[27] Eduardo C Garrido-Merchán and Daniel Hernández-Lobato. Parallel predictive entropy search for multi-

objective bayesian optimization with constraints, 2020.

[28] David Gaudrie, Rodolphe Le Riche, Victor Picheny, Benoît Enaux, and Vincent Herbert. Targeting solutions
in bayesian multi-objective optimization: sequential and batch versions. Annals of Mathematics and
Artiﬁcial Intelligence, 88(1-3):187–212, Aug 2019. ISSN 1573-7470. doi: 10.1007/s10472-019-09644-8.
URL http://dx.doi.org/10.1007/s10472-019-09644-8.

[29] Michael A. Gelbart, Jasper Snoek, and Ryan P. Adams. Bayesian optimization with unknown constraints.

In Proceedings of the 30th Conference on Uncertainty in Artiﬁcial Intelligence, UAI, 2014.

[30] David Ginsbourger, Rodolphe Le Riche, and Laurent Carraro. Kriging Is Well-Suited to Parallelize

Optimization, pages 131–162. Springer Berlin Heidelberg, Berlin, Heidelberg, 2010.

[31] P. Glasserman. Performance continuity and differentiability in monte carlo optimization. In 1988 Winter

Simulation Conference Proceedings, pages 518–524, 1988.

[32] Nikolaus Hansen. The CMA Evolution Strategy: A Comparing Review, volume 192, pages 75–102. 06

2007. doi: 10.1007/3-540-32494-1_4.

11

[33] Daniel Hernández-Lobato, José Miguel Hernández-Lobato, Amar Shah, and Ryan P. Adams. Predictive

entropy search for multi-objective bayesian optimization, 2015.

[34] Iris Hupkens, Andre Deutz, Kaifeng Yang, and Michael Emmerich. Faster exact algorithms for computing
expected hypervolume improvement. In Antonio Gaspar-Cunha, Carlos Henggeler Antunes, and Car-
los Coello Coello, editors, Evolutionary Multi-Criterion Optimization, pages 65–79. Springer International
Publishing, 2015.

[35] Hisao Ishibuchi, Naoya Akedo, and Yusuke Nojima. A many-objective test problem for visually examining
In Proceedings of the 13th Annual Conference
diversity maintenance behavior in a decision space.
on Genetic and Evolutionary Computation, GECCO ’11, page 649–656, New York, NY, USA, 2011.
Association for Computing Machinery. ISBN 9781450305570. doi: 10.1145/2001576.2001666. URL
https://doi.org/10.1145/2001576.2001666.

[36] Hisao Ishibuchi, Ryo Imada, Yu Setoguchi, and Yusuke Nojima. How to specify a reference point in
hypervolume calculation for fair performance comparison. Evol. Comput., 26(3):411–440, September
2018.

[37] Donald Jones, C. Perttunen, and B. Stuckman. Lipschitzian optimisation without the lipschitz constant.
Journal of Optimization Theory and Applications, 79:157–181, 01 1993. doi: 10.1007/BF00941892.

[38] Donald R. Jones, Matthias Schonlau, and William J. Welch. Efﬁcient global optimization of expensive

black-box functions. Journal of Global Optimization, 13:455–492, 1998.

[39] Diederik P Kingma and Max Welling. Auto-Encoding Variational Bayes.

arXiv e-prints, page

arXiv:1312.6114, Dec 2013.

[40] J. Knowles. Parego: a hybrid algorithm with on-line landscape approximation for expensive multiobjective

optimization problems. IEEE Transactions on Evolutionary Computation, 10(1):50–66, 2006.

[41] Renaud Lacour, Kathrin Klamroth, and Carlos M. Fonseca. A box decomposition algorithm to compute

the hypervolume indicator. Computers & Operations Research, 79:347 – 360, 2017.

[42] Benjamin Letham and Eytan Bakshy. Bayesian optimization for policy search via online-ofﬂine experimen-
tation. Journal of Machine Learning Research, 20(145):1–30, 2019. URL http://jmlr.org/papers/
v20/18-225.html.

[43] Benjamin Letham, Brian Karrer, Guilherme Ottoni, and Eytan Bakshy. Constrained bayesian optimization

with noisy experiments. Bayesian Analysis, 14(2):495–519, 06 2019. doi: 10.1214/18-BA1110.

[44] Xingtao Liao, Qing Li, Xujing Yang, Weigang Zhang, and Wei Li. Multiobjective optimization for crash
safety design of vehicles using stepwise regression model. Structural and Multidisciplinary Optimization,
35:561–569, 06 2008. doi: 10.1007/s00158-007-0163-x.

[45] Edgar Manoatl Lopez, Luis Miguel Antonio, and Carlos A. Coello Coello. A gpu-based algorithm for
a faster hypervolume contribution computation. In António Gaspar-Cunha, Carlos Henggeler Antunes,
and Carlos Coello Coello, editors, Evolutionary Multi-Criterion Optimization, pages 80–94. Springer
International Publishing, 2015.

[46] Hongzi Mao, Ravi Netravali, and Mohammad Alizadeh. Neural adaptive video streaming with pensieve. In
Proceedings of the Conference of the ACM Special Interest Group on Data Communication, SIGCOMM ’17,
page 197–210, New York, NY, USA, 2017. Association for Computing Machinery. ISBN 9781450346535.
doi: 10.1145/3098822.3098843. URL https://doi.org/10.1145/3098822.3098843.

[47] Hongzi Mao, Shannon Chen, Drew Dimmery, Shaun Singh, Drew Blaisdell, Yuandong Tian, Mohammad

Alizadeh, and Eytan Bakshy. Real-world video adaptation with reinforcement learning. 2019.

[48] Hongzi Mao, Parimarjan Negi, Akshay Narayan, Hanrui Wang, Jiacheng Yang, Haonan Wang, Ryan
Marcus, Ravichandra Addanki, Mehrdad Khani Shirkoohi, Songtao He, Vikram Nathan, Frank Cangialosi,
Shaileshh Bojja Venkatakrishnan, Wei-Hung Weng, Shu-Wen Han, Tim Kraska, and Mohammad Alizadeh.
Park: An open platform for learning-augmented computer systems. In NeurIPS, 2019.

[49] Sébastien Marmin, Clément Chevalier, and David Ginsbourger. Differentiating the multipoint expected
improvement for optimal batch design. In Panos Pardalos, Mario Pavone, Giovanni Maria Farinella, and
Vincenzo Cutello, editors, Machine Learning, Optimization, and Big Data, pages 37–48, Cham, 2015.
Springer International Publishing.

[50] B. Paria, K. Kandasamy, and B. Póczos. A Flexible Multi-Objective Bayesian Optimization Approach

using Random Scalarizations. ArXiv e-prints, May 2018.

12

[51] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming
Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in PyTorch. 2017.

[52] Victor Picheny. Multiobjective optimization using gaussian process emulators via stepwise uncertainty

reduction. Statistics and Computing, 25, 10 2013. doi: 10.1007/s11222-014-9477-x.

[53] Wolfgang Ponweiser, Tobias Wagner, Dirk Biermann, and Markus Vincze. Multiobjective optimization
on a limited budget of evaluations using model-assisted s-metric selection. In Günter Rudolph, Thomas
Jansen, Nicola Beume, Simon Lucas, and Carlo Poloni, editors, Parallel Problem Solving from Nature –
PPSN X, pages 784–794, Berlin, Heidelberg, 2008. Springer Berlin Heidelberg.

[54] Alma A. M. Rahat, Richard M. Everson, and Jonathan E. Fieldsend. Alternative inﬁll strategies for
expensive multi-objective optimisation. In Proceedings of the Genetic and Evolutionary Computation Con-
ference, GECCO ’17, page 873–880, New York, NY, USA, 2017. Association for Computing Machinery.
ISBN 9781450349208.

[55] Carl Edward Rasmussen. Gaussian Processes in Machine Learning, pages 63–71. Springer Berlin

Heidelberg, Berlin, Heidelberg, 2004.

[56] Jerry Segercrantz. Inclusion-exclusion and characteristic functions. Mathematics Magazine, 71(3):216–218,

1998. ISSN 0025570X, 19300980. URL http://www.jstor.org/stable/2691209.

[57] B. Shahriari, K. Swersky, Z. Wang, R. P. Adams, and N. de Freitas. Taking the human out of the loop: A

review of bayesian optimization. Proceedings of the IEEE, 104(1):148–175, 2016.

[58] Niranjan Srinivas, Andreas Krause, Sham Kakade, and Matthias Seeger. Gaussian process optimization in
the bandit setting: No regret and experimental design. In Proceedings of the 27th International Conference
on International Conference on Machine Learning, ICML’10, page 1015–1022, Madison, WI, USA, 2010.
Omnipress. ISBN 9781605589077.

[59] J. Sylvester. Note sur la théorème de legendre. Comptes Rendus Acad. Sci., 96:463–465, 1883.

[60] Ryoji Tanabe and Hisao Ishibuchi. An easy-to-use real-world multi-objective optimization problem suite.
Applied Soft Computing, 89:106078, 2020. ISSN 1568-4946. doi: https://doi.org/10.1016/j.asoc.2020.
106078.

[61] William R. Thompson. On the likelihood that one unknown probability exceeds another in view of the

evidence of two samples. Biometrika, 25(3/4):285–294, 1933.

[62] Takashi Wada and Hideitsu Hino. Bayesian optimization for multi-objective optimization and multi-point

search, 2019.

[63] Jialei Wang, Scott C. Clark, Eric Liu, and Peter I. Frazier. Parallel bayesian global optimization of

expensive functions, 2016.

[64] J. T. Wilson, R. Moriconi, F. Hutter, and M. P. Deisenroth. The reparameterization trick for acquisition

functions. ArXiv e-prints, December 2017.

[65] James Wilson, Frank Hutter, and Marc Deisenroth. Maximizing acquisition functions for bayesian
optimization. In Advances in Neural Information Processing Systems 31, pages 9905–9916. 2018.

[66] Jian Wu and Peter I. Frazier. The parallel knowledge gradient method for batch bayesian optimization. In
Proceedings of the 30th International Conference on Neural Information Processing Systems, NIPS’16,
page 3134–3142, Red Hook, NY, USA, 2016. Curran Associates Inc. ISBN 9781510838819.

[67] Kaifeng Yang, Michael Emmerich, André Deutz, and Carlos M. Fonseca. Computing 3-d expected
hypervolume improvement and related integrals in asymptotically optimal time. In 9th International
Conference on Evolutionary Multi-Criterion Optimization - Volume 10173, EMO 2017, page 685–700,
Berlin, Heidelberg, 2017. Springer-Verlag.

[68] Kaifeng Yang, Michael Emmerich, André H. Deutz, and Thomas Bäck. Efﬁcient computation of expected

hypervolume improvement using box decomposition algorithms. CoRR, abs/1904.12672, 2019.

[69] Kaifeng Yang, Michael Emmerich, André Deutz, and Thomas Bäck. Multi-objective bayesian global
optimization using expected hypervolume improvement gradient. Swarm and Evolutionary Computation,
44:945 – 956, 2019. ISSN 2210-6502. doi: https://doi.org/10.1016/j.swevo.2018.10.007. URL http:
//www.sciencedirect.com/science/article/pii/S2210650217307861.

13

[70] Kaifeng Yang, Pramudita Palar, Michael Emmerich, Koji Shimoyama, and Thomas Bäck. A multi-
point mechanism of expected hypervolume improvement for parallel multi-objective bayesian global
optimization. pages 656–663, 07 2019. doi: 10.1145/3321707.3321784.

[71] Kaifeng Yang, Pramudita Satria Palar, Michael Emmerich, Koji Shimoyama, and Thomas Bäck. A
multi-point mechanism of expected hypervolume improvement for parallel multi-objective bayesian global
optimization. In Proceedings of the Genetic and Evolutionary Computation Conference, GECCO ’19, page
656–663, New York, NY, USA, 2019. Association for Computing Machinery. ISBN 9781450361118. doi:
10.1145/3321707.3321784. URL https://doi.org/10.1145/3321707.3321784.

[72] R. J. Yang, N. Wang, C. H. Tho, J. P. Bobineau, and B. P. Wang. Metamodeling Development for Vehicle

Frontal Impact Simulation. Journal of Mechanical Design, 127(5):1014–1020, 01 2005.

[73] E. Zitzler, L. Thiele, M. Laumanns, C. M. Fonseca, and V. G. da Fonseca. Performance assessment of
multiobjective optimizers: an analysis and review. IEEE Transactions on Evolutionary Computation, 7(2):
117–132, 2003.

14

Appendix to:

Differentiable Expected Hypervolume Improvement
for Parallel Multi-Objective Bayesian Optimization

A Derivation of q-Expected Hypervolume Improvement

A.1 Hypervolume Improvement via the Inclusion-Exclusion Principle

The hypervolume improvement of f (x) within the hyper-rectangle Sk is the volume of Sk ∩ ∆({f (x)}, P, r)
and is given by:

HVIk

(cid:0)f (x), lk, uk

(cid:1) = λM

(cid:0)Sk ∩ ∆({f (x)}, P, r)(cid:1) =

M
(cid:89)

m=1

(cid:2)z(m)

k − l(m)

k

(cid:3)

,

+

where u(m)
the min(·, 0) operation. Summing over all Sk gives the total hypervolume improvement:

denote the mth component of the corresponding vector and [·]+ denotes

, f (m)(x), and z(m)

, l(m)
k

k

k

HVI(cid:0)f (x)(cid:1) =

=

=

K
(cid:88)

k=1

K
(cid:88)

k=1

HVIk

(cid:0)f (x), lk, uk

(cid:1)

λM

(cid:0)Sk ∩ ∆({f (x)}, P, r)(cid:1)

K
(cid:88)

M
(cid:89)

k=1

m=1

(cid:2)z(m)

k − l(m)

k

(cid:3)
+

.

We can extend the HVI computation to the q > 1 case using the inclusion-exclusion principle.
Principle 1. The inclusion-exclusion principle [13, 59, 9] Given a ﬁnite measure space (B, A, µ) and a ﬁnite
sequence of potentially empty or overlapping sets {Ai}i = 1n where Ai ∈ A and µ(B) < ∞, then,

(cid:18) p
(cid:91)

(cid:19)

Ai

=

λM

i=1

p
(cid:88)

j=1

(−1)j+1 (cid:88)

λM

(cid:0)Ai1 ∩ ... ∩ Aij

(cid:1)

1≤i1≤...≤ij ≤p

In the context of computing the joint HVI of q new points{f (xi)}q
i=1, each subset Ai for i = 1, . . . , q is
the set of points contained in ∆({f (xi)}, P, r) — independently of the other q − 1 points. λM (Ai) is the
hypervolume improvement from the new point f (xi): λM (Ai) = HVI(f (xi)). The union of these subsets is
the set of points in the new space dominated by the q new points: (cid:83)q
i=1 ∆({f (xi)}, P, r). The
hypervolume of (cid:83)q

i=1 ∆({f (xi)}, P, r) is the hypervolume improvement from the q new points:

i=1 Ai = (cid:83)q

HVI({f (xi)}q

i=1) = λM

(cid:18) q
(cid:91)

(cid:19)

Ai

i=1

=

q
(cid:88)

j=1

(−1)j+1 (cid:88)

λM

(cid:0)Ai1 ∩ · · · ∩ Aij

(cid:1)

1≤i1≤...≤ij ≤q

To compute λM (Ai1 ∩ · · · ∩ Aij ), we partition the space covered by Ai1 ∩ · · · ∩ Aij across the K hyper-
rectangles {Sk}K
k=1 and compute the hypervolume of the overlapping space of Ai1 ∩ · · · ∩ Aij with each Sk
independently. Since {Sk}K
k=1 is a disjoint partition, summing over K gives the hypervolume of Ai1 ∩ · · · ∩ Aij :

λM

(cid:0)Ai1 ∩ · · · ∩ Aij

(cid:1) =

K
(cid:88)

k=1

λM

(cid:0)Sk ∩ Ai1 ∩ · · · ∩ Aij

(cid:1)

This has two advantages. First, the new dominated space Ai can be a non-rectangular polytope, but the
intersection Ai ∩ Sk is a rectangular polytope, which simpliﬁes computation of overlapping hypervolume.

15

Second, the vertices deﬁning the hyper-rectangle encapsulated by Sk ∩ Ai1 ∩ · · · ∩ Aij are easily derived.
The lower bound is simply the lk lower bound of Sk and the upper bound is the component-wise minimum
zk,i1,...ij = min (cid:2)uk, f (xi1 ), . . . , f (xij )(cid:3).
Importantly, this is computationally tractable because this speciﬁc approach enables parallelizing computation
across all intersections of subsets Ai1 ∩ · · · ∩ Aij for 1 ≤ ij ≤ . . . ≤ ij ≤ q and across all K hyper-rectangles.
Explicitly, the HVI is computed as:

HVI({f (xi)}q

i=1) = λM

(cid:18) p
(cid:91)

(cid:19)

Ai

i=1

q
(cid:88)

=

(cid:88)

(−1)j+1λM

(cid:0)Ai1 ∩ · · · ∩ Aij

(cid:1)

j=1

1≤i1≤...≤ij ≤q

K
(cid:88)

q
(cid:88)

(cid:88)

k=1

j=1

1≤i1≤...≤ij ≤q

K
(cid:88)

q
(cid:88)

(cid:88)

k=1

j=1

1≤i1≤...≤ij ≤q

K
(cid:88)

q
(cid:88)

(cid:88)

k=1

j=1

1≤i1≤...≤ij ≤q

(−1)j+1λM

(cid:0)Sk ∩ Ai1 ∩ · · · ∩ Aij

(cid:1)

(−1)j+1λM

(cid:0)Sk ∩ ∆({f (xi1 )}, P, r) ∩ . . . ∩ ∆({f (xij )}, P, r)(cid:1)

(−1)j+1

M
(cid:89)

m=1

(cid:2)z(m)

k,i1,...ij

− l(m)
k

(cid:3)

+

K
(cid:88)

q
(cid:88)

(cid:88)

k=1

j=1

Xj ∈Xj

(−1)j+1

M
(cid:89)

m=1

(cid:2)z(m)
k,Xj

− l(m)
k

(cid:3)
+

=

=

=

=

where Xj is the superset all subsets of Xcand of size j: Xj = {Xj ⊂ Xcand : |Xj| = j} and z(m)
k,Xj
for Xj = {xi1 , ..., xij }.

= z(m)

k,i1,...ij

A.2 Computing Expected Hypervolume Improvement

The above approach for computing HVI assumes we know the true objective values {f (xi)}q
not know the true function values {f (xi)}q

i=1. Since we do
i=1, we compute qEHVI as the expectation over the GP posterior.

αqEHVI = E

(cid:104)

HVI({f (xi)}q

(cid:105)
i=1)

(cid:90)

=

RM

HVI({f (xi)}q

i=1)df

(6)

In the sequential setting and under the assumption of independent outcomes, qEHVI is simply EHVI and
can be expressed in closed form [69]. However when q > 1, there is no known analytical formulation
[70]. Instead, we estimate the expectation in (6) using MC integration with samples from the joint posterior
P(cid:0)f (x1), ..., f (xq)|D):

(cid:104)
αqEHVI = E

HVI({f (xi)}q

i=1)

(cid:105)

≈

=

1
N

1
N

N
(cid:88)

t=1

HVI({ft(xi)}q

i=1)

N
(cid:88)

K
(cid:88)

q
(cid:88)

(cid:88)

t=1

k=1

j=1

Xj ∈Xj

(−1)j+1

M
(cid:89)

m=1

(7)

(8)

(cid:3)

+

(cid:2)z(m)

k,Xj ,t − l(m)

k

where {ft(xi)}q
k,Xj ,t = min (cid:2)uk, minx(cid:48)∈Xj ft(x(cid:48))(cid:3).
z(m)

i=1 ∼ P(cid:0)f (x1), ..., f (xq)|X, Y (cid:1) is the tth sample from the joint posterior over Xcand and

A.3 Supporting Outcome Constraints

Recall that we deﬁned the constrained hypervolume improvement as

HVIC(f (x), c(x)) = HVI[f (x)] · 1[c(x) ≥ 0].

(9)

For q = 1 and assuming independence of the objectives and the constraints, the expected HVIC is the product of
the expected HVI and the probability of feasibility (the expectation of 1[c(x) ≥ 0]) [22]. However, requiring
objectives and constraints to be independent is unnecessary when estimating the expectation with MC integration
using samples from the joint posterior.

16

In the parallel setting, if all constraints are satisﬁed for all q candidates Xcand = {xi}q
i=1, HVIC is simply
HVI. If a subset V ⊂ Xcand, V (cid:54)= ∅ of the candidates violate at least one of the constraints, then the feasible
HVI is the HVI of the set of feasible candidates: HVIC(Xcand) = HVI(Xcand \ V). That is, the hypervolume
contribution (i.e. the marginal HVI) of an infeasible point is zero. In our formulation, HVI can be computed by
multiplying (5) with an additional factor (cid:81)

1[c(v)(x(cid:48)) ≥ 0]:

(cid:81)V

x(cid:48)∈Xj

v=1

HVIC({f (xi), c(xi)}q

i=1) =

K
(cid:88)

q
(cid:88)

(cid:88)

(cid:34)(cid:18) M
(cid:89)

(−1)j+1

k=1

j=1

Xj ∈Xj

m=1

(cid:2)z(m)
k,Xj

−l(m)
k

(cid:3)

+

(cid:19) (cid:89)

V
(cid:89)

(cid:35)
1[c(v)(x(cid:48)) ≥ 0]

.

x(cid:48)∈Xj

v=1

(10)
The additional factor (cid:81)
1[c(v)(xa) ≥ 0] indicates whether all constraints are satisﬁed for all
candidates in a given subset Xj. Thus HVIC can be computed in the same fashion as HVI, but with the
additional step of setting the HV of all subsets containing x(cid:48) to zero if x(cid:48) violates any constraint. We can now
again perform MC integration as in (5) to compute the expected constrained hypervolume improvement.

x(cid:48)∈Xj

(cid:81)V

v=1

In this formulation, the marginal hypervolume improvement from a candidate is weighted by the probability that
the candidate is feasible. The marginal hypervolume improvements are highly dependent on the outcomes of the
other candidates. Importantly, the MC-based approach enables us to properly estimate the marginal hypervolume
improvements across candidates by sampling from the joint posterior.
Note that while the expected constrained hypervolume E(cid:2)HVIC({f (xi), c(xi)}q
i=1)(cid:3) is differentiable, we may
not differentiate inside the expectation (hence we cannot expect simply differentiating (10) on the sample-level
to provide proper gradients). We therefore replace the indicator with a sigmoid function with temperature
parameter (cid:15), which provides a differentiable relaxation

1[c(v)(x(cid:48)) ≥ 0] ≈ s(c(v)(x(cid:48)); (cid:15)) :=

1
1 + exp(−c(v)(x(cid:48))/(cid:15))

(11)

that becomes exact in the limit (cid:15) (cid:38) 0.

As in the unconstrained parallel scenario, there is no known analytical expression for the expected feasible
hypervolume improvement. Therefore, we again use MC integration to approximate the expectation:
αqEHVIC (x) = E

HVIC({f (xi), c(xi)}q

(12a)

(cid:105)

(cid:104)

i=1)

≈

≈

1
N

1
N

N
(cid:88)

t=1

HVIC({ft(xi), ct(xi)}q

i=1)

N
(cid:88)

K
(cid:88)

q
(cid:88)

(cid:88)

(cid:34)(cid:18) M
(cid:89)

(−1)j+1

t=1

k=1

j=1

Xj ∈Xj

m=1

(12b)

(cid:19) (cid:89)

V
(cid:89)

(cid:35)
s(c(v)(x(cid:48)); (cid:15))

(12c)

(cid:3)

+

x(cid:48)∈Xj

v=1

(cid:2)z(m)

k,Xj ,t − l(m)

k

A.3.1

Inclusion Exclusion principle for HVIC

Equation (10) holds when the indicator function because HVIC is equivalent to HVI with the subset of feasible
points. However, the sigmoid approximation can result in non-zero error. The error function ε : 2Xcand → R can
be expressed as

ε(X) =

(cid:89)

V
(cid:89)

x(cid:48)∈X

v=1

1[c(x(cid:48)) > 0] −

(cid:89)

V
(cid:89)

x(cid:48)∈X

v=1

s(c(x(cid:48)), (cid:15))

The error function gives a value to each to each element of 2Xcand . Weight functions have been studied in
conjunction with the inclusion-exclusion principle [56], but under the assumption of that the weight of a set is
the sum of the weights of its elements: w(A) = (cid:80)
a∈A w(a). In our case, the weight function of a set A is the
product the weights of its elements. There, it is not obvious whether the inclusion-exclusion principle will hold
in this case.
k=1 of the objective space RM that is
Theorem 1. Given a feasible Pareto front Pfeas, a partitioning {(lk, uk}K
not dominated by the Pfeas, then for a set of points Xcand with objective values f (Xcand) and constraint values
c(Xcand),

HVIC(f (Xcand), c(Xcand), P, r) = HVI(f (cid:48)(Xcand), P (cid:48), r(cid:48))
where f (cid:48)(Xcand) is the set of objective-constraint vectors for each candidate point f (cid:48)(x) ∈ RM +V , P (cid:48) is the
set of vectors [f (1)(x), ..., f (M )(x), 0V ] ∈ RM +V , and r(cid:48) = [r(1), ..., r(M ), 0V ] ∈ RM +V .

Proof. Recall equation 10,

HVIC({f (xi), c(xi)}q

i=1) =

K
(cid:88)

q
(cid:88)

(cid:88)

(cid:34)(cid:18) M
(cid:89)

(−1)j+1

k=1

j=1

Xj ∈Xj

m=1

(cid:2)z(m)
k,Xj

− l(m)
k

(cid:3)

+

(cid:19) (cid:89)

V
(cid:89)

x(cid:48)∈Xj

v=1

1[c(v)(x(cid:48)) ≥ 0]

(cid:35)
.

17

Note that the constraint product

(cid:89)

V
(cid:89)

x(cid:48)∈Xj

v=1

1[c(v)(x(cid:48)) ≥ 0] =

=

=

=

V
(cid:89)

(cid:89)

v=1

x(cid:48)∈Xj

V
(cid:89)

v=1

V
(cid:89)

min
x(cid:48)∈Xj

(cid:20)

min

v=1

V
(cid:89)

(cid:34)

v=1

1[c(v)(x(cid:48)) ≥ 0]

1[c(v)(x(cid:48)) ≥ 0]

1[c(v)(x(cid:48)) ≥ 0]

(cid:21)

1, min
x(cid:48)∈Xj

(13)

(cid:20)

min

1, min
x(cid:48)∈Xj

(cid:21)
1[c(v)(x(cid:48)) ≥ 0]

− 0

(cid:35)
.

For v = 1, . . . , V , k = 1, ...K, let l(M +v)
expression from Equation 13 gives

k

= 0 and u(M +v)

k

= 1. Then, substituting into the following

(cid:20)

min

1, min
x(cid:48)∈Xj

1[c(v)(x(cid:48)) ≥ 0]

(cid:21)

(cid:20)

= min

u(M +v)
k

, min
x(cid:48)∈Xj

(cid:21)
1[c(v)(x(cid:48)) ≥ 0]

Recall from Section 4, that z is deﬁned as: zk := min (cid:2)uk, f (x)(cid:3). The high-level idea is that if we consider
the indicator of the slack constraints 1[c(v)(x(cid:48)) ≥ 0] as objectives, then the above expression is consistent with
the deﬁnition of z at the beginning of section 4. For v = 1, . . . , V ,

z(M +v)
k,Xj

= min

(cid:20)

1, min
x(cid:48)∈Xj

1[c(v)(x(cid:48)) ≥ 0]

(cid:21)

Thus,

(cid:89)

V
(cid:89)

x(cid:48)∈Xj

v=1

1[c(v)(x(cid:48)) ≥ 0] =

(cid:34)

V
(cid:89)

(cid:20)

min

1, min
x(cid:48)∈Xj

(cid:21)
1[c(v)(x(cid:48)) ≥ 0]

− 0

(cid:35)

v=1

V
(cid:89)

v=1

=

(cid:2)z(M +v)
k,Xj

− l(M +v)
k

(cid:3)

+

Returning to the HVIC equation, we have

HVIC({f (xi), c(xi)}q

i=1) =

K
(cid:88)

q
(cid:88)

(cid:88)

(−1)j+1

k=1

j=1

Xj ∈Xj

K
(cid:88)

q
(cid:88)

(cid:88)

k=1

j=1

Xj ∈Xj

K
(cid:88)

q
(cid:88)

(cid:88)

k=1

j=1

Xj ∈Xj

=

=

(cid:34)(cid:18) M
(cid:89)

m=1
(cid:34)(cid:18) M
(cid:89)

m=1

(cid:2)z(m)
k,Xj

− l(m)
k

(cid:3)

+

(cid:19) (cid:89)

V
(cid:89)

x(cid:48)∈Xj

v=1

(cid:35)

1[c(v)(x(cid:48)) ≥ 0]

(cid:2)z(m)
k,Xj

− l(m)
k

(cid:3)

+

(cid:19) M +V
(cid:89)

v=M +1

(cid:2)z(v)
k,Xj

− l(M +v)
k

(cid:3)

+

(cid:35)

(−1)j+1

(−1)j+1

(cid:34) M +V
(cid:89)

m=1

(cid:35)

(cid:2)z(m)
k,Xj

− l(m)
k

(cid:3)

+

(14)

Now consider the case when a sigmoid approximation 1[c(v)(x(cid:48)) ≥ 0] ≈ s(c(v)(x(cid:48)); (cid:15)) is used. The only
change to Equation 14 is that

z(m)
k,Xj

≈ ˆz(m)
k,Xj

= min

(cid:20)

u(M +v)
k

, min
x(cid:48)∈Xj

S[c(v)(x(cid:48)), (cid:15)]

(cid:21)

.

If S[c(v)(x(cid:48)), (cid:15)] = 1[c(v)(x(cid:48)) ≥ 0] for all v, x(cid:48), then HVI is computed exactly without approximation error. If
S[c(v)(x(cid:48)), (cid:15)]1[c(v)(x(cid:48)) ≥ 0] for any v, x(cid:48), then there is approximation error: the hypervolume improvement
from all subsets containing x(cid:48) is proportional to (cid:81)V
v=1 minx(cid:48)∈X s(c(x(cid:48)), (cid:15)). Since the constraint outcomes
are directly considered as components in the hypervolume computation, the inclusion-exclusion principle
incorporates the approximate indicator properly.

18

A.4 Complexity

Recall from Section 3.3 that, given posterior samples, the time complexity on a single-threaded machine is
T1 = O(M N K(2q − 1)). The space complexity required for maximum parallelism is also is T1 (ignoring the
space required by the models), which does limit scalability to larger M and q, but difﬁculty scaling to large M
is a known limitaiton of EHVI [69]. To reduce memory load, rectangles could be materialized and processed in
chunks at the cost of additional runtime. In addition, our implementation of qEHVI uses the box decomposition
algorithm from Couckuyt et al. [11], but we emphasize qEHVI is agnostic to the choice of partitioning algorithm
and using a more efﬁcient partitioning algorithm (e.g. [69, 17, 41]) may signiﬁcantly improve memory footprint
on GPU and enable larger using q in many scenarios.

B Error Bound on Sequential Greedy Approximation

If the acquisition function L(Xcand) is a normalized, monotone, submodular set function (where submodular
means that the increase in L(Xcand) is non-increasing as elements are added to Xcand and normalized means that
e L∗, where L∗ is the
L(∅) = 0), then the sequential greedy approximation of L enjoys regret of no more than 1
(cid:0)HVI(cid:2)f (Xcand)(cid:3)(cid:1). Since HVI is a submodular set
optima of L [23]. We have αqEHVI(Xcand) = L(Xcand) = Ef
function [24] and the expectation of a stochastic submodular function is also submodular [2], αqEHVI(Xcand)
is also submodular and therefore its sequential greedy approximation enjoys regret of no more than 1
qEHVI.
t=1 HVI(cid:2)ft(Xcand)(cid:3)
Using the result from Wilson et al. [65], the MC-based approximation ˆαqEHVI(Xcand) = (cid:80)N
also enjoys the same regret bound since HVI is a normalized submodular set function.7

e α∗

C Convergence Results

For the purpose of stating our convergence results, we recall some concepts and notation from Balandat et al.
[5]. First, consider a sample {ft(x1)}q
i=1 from the multi-output posterior of the GP surrogate model. Let
x ∈ Rqd be the stacked set of candidates Xcand and let ft(x) := [ft(x1)T , . . . , ft(xq)T ]T be the stacked set of
corresponding objective vectors. It is well known that, using the reparameterization trick, we can write

ft(x) = µ(x) + L(x)(cid:15)t,

(15)

where µ : Rqd → RqM is the mean function of the multi-output GP, L(x) ∈ RqM ×qM is a root decomposition
(typically the Cholesky decomposition) of the multi-output GP’s posterior covariance Σ(x) ∈ RqM ×qM , and
(cid:15)t ∈ RqM with (cid:15)t ∼ N (0, IqM ).

For x ∈ X , consider the MC-approximation ˆαN
ˆαN

qEHVI(x), obtained by averaging the gradients on the sample-level:

qEHVI(x) from (5). Denote by ∇x ˆαN

qEHVI(x) the gradient of

∇x ˆαN

qEHVI(x) :=

1
N

N
(cid:88)

t=1

∇xHVI({ft(xi)}q

i=1)

(16)

qEHVI := maxx∈X αqEHVI(x) denote the maximum of the true acquisition function qEHVI, and let

Let α∗
X ∗ := arg maxx∈X αqEHVI(x) denote the set of associated maximizers.
Theorem 2. Suppose that X is compact and that f has a Multi-Output Gaussian Process prior with continuously
differentiable mean and covariance functions. If the base samples {(cid:15)t}N
t=1 are drawn i.i.d. from N (0, IqM ),
and if ˆx∗
qEHVI(x), then

N ∈ arg maxx∈X ˆαN

(1) αqEHVI( ˆx∗

N ) → α∗

qEHVI a.s.

(2) dist( ˆx∗

N , X ∗) → 0 a.s.

In addition to the almost sure convergence in Theorem 2, deriving a result on the convergence rate of the
optimizer, similar to the one obtained in [5], should be possible. We leave this to future work. Moreover, the
results in Theorem 2 can also be extended to the situation in which the base samples are generated using a
particular class of randomized QMC methods (see similar results in [5]).

Proof. We consider the setting from Balandat et al. [5, Section D.5]. Let (cid:15) ∼ N (0, IqM ), so that we can write
the posterior over outcome m at x as the random variable f (m)(x, (cid:15)) = S{ij ,m}(µ(x) + L(x)(cid:15)), where µ(x)

7As noted in Wilson et al. [65], submodularity technically requires the search space X to be ﬁnite, whereas
in BO, it will typically be inﬁnite. Wilson et al. [65] note that in similar scenarios, submodularity has been
extended to inﬁnite sets X (e.g. Srinivas et al. [58]).

19

and L(x) are the (vector-valued) posterior mean and the Cholesky factor of posterior covariance, respectively,
and S{ij ,m} is an appropriate selection matrix (in particular, (cid:107)S{ij ,m}(cid:107)∞ ≤ 1 for all ij and m). Let

where

A(x, (cid:15)) =

K
(cid:88)

q
(cid:88)

(cid:88)

k=1

j=1

Xj ∈Xj

(−1)j+1

M
(cid:89)

m=1

(cid:2)z(m)
k,Xj

((cid:15)) − l(m)

k

(cid:3)

+

z(m)
k,Xj

((cid:15)) = min (cid:2)u(m)

k

, f (m)(xi1 , (cid:15)), . . . , f (m)(xij , (cid:15))(cid:3)

and Xj = {xi1 , . . . , xij }. Following [5, Theorem 3], we need to show that there exists an integrable function
(cid:96) : Rq×M (cid:55)→ R such that for almost every (cid:15) and all x, y ⊆ X , x, y ∈ Rq×d,

|A(x, (cid:15)) − A(y, (cid:15))| ≤ (cid:96)((cid:15))(cid:107)x − y(cid:107).

(17)

Let us deﬁne

˜akmjXj (x, (cid:15)) :=

(cid:104)

min (cid:2)u(m)

k

, f (m)(xi1 , (cid:15)), . . . , f (m)(xij , (cid:15))(cid:3) − l(m)

k

(cid:105)

.

+

Linearity implies that it sufﬁces to show that this condition holds for

˜A(x, (cid:15)) :=

M
(cid:89)

m=1

˜akmjXj (x, (cid:15)) =

M
(cid:89)

(cid:104)
min (cid:2)u(m)

k

m=1

, f (m)(xi1 , (cid:15)), . . . , f (m)(xij , (cid:15))(cid:3) − l(m)

k

(cid:105)

+

(18)

for all k, j, and Xj. Observe that

˜akmjXj (x, (cid:15)) ≤

(cid:12)
(cid:12)min (cid:2)u(m)
(cid:12)
k
(cid:12)
(cid:12)min (cid:2)u(m)
(cid:12)
| +

, f (m)(xi1 , (cid:15)), . . . , f (m)(xij , (cid:15))(cid:3) − l(m)

(cid:12)
(cid:12)
(cid:12)
, f (m)(xi1 , (cid:15)), . . . , f (m)(xij , (cid:15))(cid:3)(cid:12)
(cid:12)
(cid:12).

k

k

≤ |l(m)
k

Note that if u(m)
k < ∞, then min[u(m)
u(m)
Let w(m)

k
if u(m)

k = u(m)

k

k = ∞, then min[u(m)

, f (x, (cid:15))(m)
, f (m)(xi1 , (cid:15)), ...f (m)(xij , (cid:15))] < (cid:12)

, ...f (m)(xij , (cid:15))] = min[f (m)(xi1 , (cid:15)), ...f (m)(xij , (cid:15))]. If
(cid:12)
(cid:12)min[f (m)(xi1 , (cid:15)), ...f (m)(xij , (cid:15))](cid:12)
(cid:12)u(m)
(cid:12).

(cid:12) + (cid:12)

i1

k

k

k < ∞ and 0 otherwise. Then
| + (cid:12)

˜akmjXj (x, (cid:15)) ≤ |l(m)
k
≤ |l(m)
k

| + |w(m)
| + |w(m)

k

k

| +

(cid:12)min (cid:2)f (m)(xi1 , (cid:15)), . . . , f (m)(xij , (cid:15))(cid:3)(cid:12)
(cid:12)
(cid:88)
(cid:12)
(cid:12)f (m)(xij , (cid:15))(cid:12)
(cid:12).

We therefore have that

i1,...,ij

|˜akmjXj (x, (cid:15))| ≤ |l(m)

k

| + |w(m)

k

| + |Xj|(cid:0)(cid:107)µ(m)(x)(cid:107) + (cid:107)L(m)(x)(cid:107)(cid:107)(cid:15)(cid:107)(cid:1)

for all k, m, j, Xj, where |Xj| denotes the cardinality of the set Xj. Under our assumptions (compactness of X ,
continuous differentiability of mean and covariance function), both µ(x) and L(x), as well as their respective
gradients w.r.t. x, are uniformly bounded. In particular there exist C1, C2 < ∞ such that

for all k, m, j, Xj.

Dropping indices k, j, Xj for simplicity, observe that

|˜akmjXj (x, (cid:15))| ≤ C1 + C2(cid:107)(cid:15)(cid:107)

(cid:12) ˜A(x, (cid:15)) − ˜A(y, (cid:15))(cid:12)
(cid:12)

(cid:12) = (cid:12)
= (cid:12)
≤ |˜a1(x, (cid:15))|(cid:12)

(cid:12)˜a1(x, (cid:15))˜a2(x, (cid:15)) − ˜a1(y, (cid:15))˜a2(y, (cid:15))(cid:12)
(cid:12)
(cid:12)˜a1(x, (cid:15))(cid:0)˜a2(x, (cid:15)) − ˜a2(y, (cid:15))(cid:1) + ˜a2(y, (cid:15))(cid:0)˜a1(x, (cid:15)) − ˜a1(y, (cid:15))(cid:1)(cid:12)
(cid:12)
(cid:12)˜a1(x, (cid:15)) − ˜a1(y, (cid:15))(cid:12)
(cid:12).

(cid:12)˜a2(x, (cid:15)) − ˜a2(y, (cid:15))(cid:12)

(cid:12) + |˜a2(y, (cid:15))|(cid:12)

(19a)

(19b)

(19c)

Furthermore,

|˜akmjXj (x, (cid:15)) − ˜akmjXj (y, (cid:15))| ≤

(cid:88)

(cid:12)S{ij ,m}(µ(x) + L(x)(cid:15)) − S{ij ,m}(µ(y) + L(y)(cid:15))(cid:12)
(cid:12)
(cid:12)

i1,...,ij
(cid:16)

≤ |Xj|

(cid:107)µ(x) − µ(y)(cid:107) + (cid:107)L(x) − L(y)(cid:107)(cid:107)(cid:15)(cid:107)

(cid:17)
.

Since µ and L have uniformly bounded gradients, they are Lipschitz. Therefore, there exist C3, C4 < ∞ such
that

|˜akmjXj (x, (cid:15)) − ˜akmjXj (y, (cid:15))| ≤ (C3 + C4(cid:107)(cid:15)(cid:107))(cid:107)x − y(cid:107)

20

for all x, y, k, m, j, Xj. Plugging this into (19) above, we ﬁnd that

(cid:12)
(cid:12) ˜A(x, (cid:15)) − ˜A(y, (cid:15))(cid:12)

(cid:12) ≤ 2

(cid:16)

C1C3 + (C1C4 + C2C3)(cid:107)(cid:15)(cid:107) + C2C4(cid:107)(cid:15)(cid:107)2(cid:17)

(cid:107)x − y(cid:107)

for all x, y and (cid:15). For M > 2 we generalize the idea from (19), making sure to telescope the respective
expressions. It is not hard to see that with this, there exist C < ∞ such that

(cid:12)
(cid:12) ˜A(x, (cid:15)) − ˜A(y, (cid:15))(cid:12)

(cid:12) ≤ C

M
(cid:88)

m=1

(cid:107)(cid:15)(cid:107)m(cid:107)x − y(cid:107)

Letting (cid:96)((cid:15)) := C (cid:80)M
Normal distribution).

m=1 (cid:107)(cid:15)(cid:107)m, we observe that (cid:96)((cid:15)) is integrable (since all absolute moments exist for the

The result now follows from in Balandat et al. [5, Theorem 3].

Besides the above convergence result, we can also show that the sample average gradient of the MC approximation
of qEHVI is an unbiased estimator of the true gradient of qEHVI:
Proposition 1. Suppose that the GP mean and covariance function are continuously differentiable. Suppose
further that the candidate set x has no duplicates, and that the sample-level gradients ∇xHVI({ft(xi)}q
i=1)
are obtained using the reparameterization trick as in [5]. Then

E(cid:2)∇x ˆαN

qEHVI(x)(cid:3) = ∇xαqEHVI(x),

(20)

that is, the averaged sample-level gradient is an unbiased estimate of the gradient of the true acquisition function.

Proof. This proof follows the arguments Wang et al. [63, Theorem 1], which leverages Glasserman [31, Theorem
1]. We verify the conditions of Glasserman [31, Theorem 1] below. Using the arguments from [5], we know
that, under the assumption of differentiable mean and covariance functions, the samples ft(x) are continuously
differentiable w.r.t. x (since there are no duplicates, and thus the covariance Σ(x) is non-singular). Hence,
Glasserman [31, A1] is satisﬁed. Furthermore, it is easy to see from (1) that HVI({f (xi)}q
i=1) is a.s. continuous
and is differentiable w.r.t. ft(x) on RM , except on the edges of the hyper-rectangle decomposition {Sk}K
k=1 of
the non-dominated space, which satisﬁes [31, A3]. The set of points deﬁned by the union of these edges clearly
has measure zero under any non-degenerate (non-singular covariance) GP posterior on RM , so Glasserman [31,
A4] holds. Therefore Glasserman [31, Lemma 2] holds, so HVI({f (xi)}q
i=1) is a.s. piece-wise differentiable
w.r.t. x.

Lastly, we need to show that the result in Glasserman [31, Lemma 3] holds:

(cid:20)

E

sup
xci /∈ ˜D

|A(cid:48)(x, (cid:15))|

(cid:21)

< ∞.

As in Wang et al. [63, Theorem 1], we ﬁx x except for xci where xci is the cth component of the ith point, We need
to show that E(cid:2)supxci /∈ ˜D |A(cid:48)(x, (cid:15))|(cid:3) < ∞. By linearity, it sufﬁces to show that E(cid:2)supxci /∈ ˜D | ˜A(cid:48)(x, (cid:15))|(cid:3) < ∞.
We have

(cid:20)

E

sup
xci /∈ ˜D

| ˜A(cid:48)(x, (cid:15))|

(cid:21)

(cid:20)
= E

(cid:12)
(cid:12)
(cid:12)
(cid:12)

∂ ˜A(x, (cid:15))
∂xci

(cid:21)
.

(cid:12)
(cid:12)
(cid:12)
(cid:12)

sup
xci /∈ ˜D

Consider the M = 2 case. We have ˜A(x, (cid:15)) = a1(x, (cid:15))a2(x, (cid:15)), where

am(x, (cid:15)) =

(cid:104)

min (cid:2)u(m)

k

, f (m)(xi1 , (cid:15)), . . . , f (m)(xij , (cid:15))(cid:3) − l(m)

k

(cid:105)

.

+

The partial derivative of ˜A(x, (cid:15)) with respect to xci is

and therefore

∂ ˜A(x, (cid:15))
∂xci

=

∂a1(x, (cid:15))
∂xci

a2(x, (cid:15)) + a1(x, (cid:15))

∂a2(x, (cid:15))
∂xci

,

(cid:12)
(cid:12)
(cid:12)

∂ ˜A(x, (cid:15))
∂xci

(cid:12)
(cid:12)
(cid:12) ≤

(cid:12)
(cid:12)
(cid:12)

∂a1(x, (cid:15))
∂xci

(cid:12)
(cid:12)
(cid:12) ·

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12) +
(cid:12)a2(x, (cid:15))

(cid:12)
(cid:12)
(cid:12)a1(x, (cid:15))

(cid:12)
(cid:12)
(cid:12) ·

(cid:12)
(cid:12)
(cid:12)

∂a2(x, (cid:15))
∂xci

(cid:12)
(cid:12)
(cid:12)

Since we are only concerned with xci /∈ ˜D,

am(x, (cid:15)) =

(cid:104)

min (cid:2)f (m)(xi1 , (cid:15)), . . . , f (m)(xij , (cid:15))(cid:3) − l(1)

k

(cid:105)

.

+

21

As in the proof of Theorem 2, we write the posterior over outcome m at x as the random variable f (m)(x, (cid:15)) =
S{ij ,m}(µ(x) + L(x)(cid:15)), where (cid:15) ∼ N (0, IqM ) and S{ij ,m} is an appropriate selection matrix. With this,
(cid:0)µ(x) + L(x)(cid:15)(cid:1), . . . , S{ij ,1}

(cid:0)µ(x) + L(x)(cid:15)(cid:1)(cid:3) − l(1)

min (cid:2)S{i1,1}

am(x, (cid:15)) =

(cid:105)

(cid:104)

.

k

+

Since the interval X is compact and the mean, covariance, and Cholesky factor of the covariance
µ(x), C(x), L(x) are continuously differentiable, for all m we have

(cid:12)
(cid:12)
(cid:12)
(cid:12)

∂µ(m)(xa)
∂xci

(cid:12)
(cid:12)
(cid:12)
(cid:12)

sup
xci

= µ∗,(m)
a

< ∞,

(cid:12)
(cid:12)
(cid:12)
(cid:12)

∂L(m)(x)
∂xci

(cid:12)
(cid:12)
(cid:12)
(cid:12)

sup
xci

= L∗,(m)

ca < ∞.

∗∗ = maxa µ∗,(m)

Let µ(m)
is the element at row a, column b in L(m),
the Cholesky factor for outcome m. Let (cid:15)(m) ∈ Rq denote the vector of i.i.d. N (0, 1) samples corresponding to
outcome m. Then we have

∗∗ = maxa,b L∗,(m)

(x), where L(m)
ab

, L(m)

ab

a

(cid:104)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

∂
∂xci

(cid:0)µ(x) + L(x)(cid:15)(cid:1), . . . , S{ij ,1}

(cid:0)µ(x) + L(x)(cid:15)(cid:1)(cid:3) − l(1)

k

(cid:105)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

+

[min (cid:2)S{i1,1}
(cid:104)

≤

∗∗ + L(m)
µ(m)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)µ(m)
(cid:12)

∗∗ ||(cid:15)(m)||1 − l(m)
(cid:12)
(cid:12)
(cid:12) +

k

(cid:12)
(cid:12)
(cid:12)

(cid:105)

+
(cid:12)
(cid:12)
(cid:12).

≤

∗∗ + L(m)

(cid:12)
(cid:12)l(m)
(cid:12)
Under our assumptions (compactness of X , continuous differentiability of mean and covariance function)
both µ(x) and L(x), as well as their respective gradients, are uniformly bounded. In particular there exist
C (m)
1

2 < ∞ such that

∗∗ ||(cid:15)(m)||1

, C (m)

k

for all a = i1, ..., ij.

Hence,

(cid:12)
(cid:12)
(cid:12)
(cid:12)

∂ ˜A(x, (cid:15))
∂xci

(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤

+

(cid:34)

(cid:34)

(cid:12)
(cid:12)S{a,m}

(cid:0)µ(x) + L(x)(cid:15)(cid:1) − l(m)

k

(cid:12)
(cid:12) ≤ C (m)

1 + C (m)

2

(cid:12)
(cid:12)µ(1)
(cid:12)

∗∗ + C (1)

∗∗ ||(cid:15)(1)||1

C (2)

1 + C (2)

2 ||(cid:15)(2)||1

C (1)

1 + C (1)

2 ||(cid:15)(1)||1

∗∗ + C (2)

∗∗ ||(cid:15)(2)||1

(cid:35)(cid:34)

(cid:12)
(cid:12)l(1)
(cid:12)

k

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12) +
(cid:35)(cid:34)

(cid:12)
(cid:12)µ(2)
(cid:12)

||(cid:15)(m)||1

(cid:35)

(cid:35)

(cid:12)
(cid:12)
(cid:12) +

(cid:12)
(cid:12)l(2)
(cid:12)

k

(cid:12)
(cid:12)
(cid:12)

Since (cid:15) is absolutely integrable,

E

(cid:18)(cid:12)
(cid:12)
(cid:12)
(cid:12)

∂ ˜A(x, (cid:15))
∂xci

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:19)

< ∞.

Hence, E(cid:2)supxci /∈ ˜D |A(cid:48)(x, (cid:15))|(cid:3) < ∞. This can be extended to M > 2 in the same manner using the product
rule to obtain

E

(cid:18) ∂ ˜A(x, (cid:15))
∂xci

(cid:19)

≤

≤

(cid:32)(cid:34)

M
(cid:88)

(cid:32)(cid:34)

m=1

M
(cid:88)

m=1

(cid:12)
(cid:12)µ(m)
(cid:12)

∗∗ + C (m)

∗∗ E[||(cid:15)(m)||1]

(cid:12)
(cid:12)
(cid:12) +

(cid:12)
(cid:12)l(1)
(cid:12)

k

(cid:35)
(cid:12)
(cid:12)
(cid:12)

M
(cid:89)

(cid:34)
C (n)

1 + C (n)

2

(cid:35)(cid:33)

E[||(cid:15)(n)||1]

(cid:12)
(cid:12)µ(m)
(cid:12)

∗∗ +

π
2

qC (m)
∗∗

(cid:12)
(cid:12)
(cid:12) +

(cid:12)
(cid:12)l(1)
(cid:12)

k

(cid:12)
(cid:12)
(cid:12)

n=1,n(cid:54)=m
(cid:34)
C (n)

1 +

(cid:35)

M
(cid:89)

n=1,n(cid:54)=m

(cid:35)(cid:33)

qC (n)
2

]

.

π
2

Hence, E(cid:2)supxci /∈ ˜D |A(cid:48)(x, (cid:15))|(cid:3) < ∞ for M ≥ 2 and Glasserman [31, Theorem 1] holds.

22

D Monte-Carlo Approximation

Figure 5b shows the gradient of analytic EHVI and the MC estimator qEHVI on slice of a 3-objective problem.
Even using only N = 32 QMC samples, the average sample gradient has very low variance. Moreover, ﬁxing
the base samples also greatly reduces the variance without introducing bias.

(a) A comparison of the analytic EHVI acquisition function and the MC-based qEHVI for q = 1.

(b) A comparison of the exact gradient of analytic EHVI and the exact sample average gradient of the MC-based
qEHVI for q = 1.

Figure 5: A comparison of (a) the analytic EHVI and MC-based qEHVI for q = 1 and (b) a
comparison of the exact gradient ∇αEHVI of analytic EHVI and average sample gradient of the
MC-estimator ∇ˆαqEHVI over a slice of the input space on a DTLZ2 problem (q = 1, M = 3, d = 6)
[15]. x(0) is varied across 0 ≤ λ ≤ 1, while x(i) for 1, ...D are held constant. In each of (a) and (b),
the top row show qEHVI where the (quasi-)standard normal base samples are resampled for each
value of x(0). The solid line is one sample average (across (q)MC samples) and the shaded area is the
mean plus 2 standard errors across 50 repetitions. The bottom row uses the same base samples for
evaluating each test point and the sample average for each of 50 repetitions is plotted.

E Experiment Details

E.1 Algorithms

For TS-TCH, we draw a sample from the joint posterior over a discrete set of 1000d points sampled from a
scrambled Sobol sequence. For PESMO, we follow [27] and use a Pareto set of size 10 for each sampled GP,
which is optimized over a discrete set of 1000d points sampled from a scrambled Sobol sequence. The current

23

0.00.1EHVIMC, N=32analyticqMC, N=32analytic0.000.250.500.751.000.00.1EHVIMC, N=32 (fixed)analytic0.000.250.500.751.00qMC, N=32 (fixed)analytic0.10.00.1 EHVIMC, N=32analyticqMC, N=32analytic0.000.250.500.751.000.10.00.1 EHVIMC, N=32 (fixed)analytic0.000.250.500.751.00qMC, N=32 (fixed)analyticTable 2: Reference points for all benchmark problems. Assuming minimization. In our benchmarks,
equivalently maximize the negative objectives and multiply the reference points by -1.

PROBLEM

REFERENCE POINT

BRANINCURRIN
DTLZ2
ABR
VEHICLE CRASH SAFETY
CONSTRAINEDBRANINCURRIN
C2-DTLZ2

(18.0, 6.0)
(1.1, ..., 1.1) ∈ RM
(-150.0, 3500.0, 5.1)
(1864.72022, 11.81993945, 0.2903999384)
(90.0, 10.0)
(1.1, ..., 1.1) ∈ RM

Pareto front is approximated by optimizing the posterior means over a grid as is done in Garrido-Merchán and
Hernández-Lobato [26, 27]. For SMS-EGO, we use the observed Pareto front. All acquisition functions are
optimized with L-BFGS-B (with a maximum of 200 iterations); SMS-EGO [53] and PESMO [26] use gradients
approximated by ﬁnite differences and all other methods use exact gradients. For all methods, each outcome
is modeled with an independent Gaussian process with a Matern 5/2 ARD kernel. The methods implemented
in Spearmint use a fully Bayesian treatment of the hyperparameters with 10 samples from posterior over the
hyperparamters, and the methods implemented in BoTorch use maximum a posteriori estimates of the GP
hyperparameters. All methods are initialized with 2(d + 1) points from a scrambled Sobol sequence. qPAREGO
and qEHVI use N = 128 QMC samples.

E.1.1 Reference point speciﬁcation

There is a large body of literature on the effects of reference point speciﬁcation [4, 35, 36]. The hypervolume
indicator is sensitive to speciﬁed the reference point: a reference point that is far away from the Pareto front will
favor extreme points, where as reference point that is close to the Pareto front gives more weight to less extreme
points [36]. Sensitivity to the reference point is affects both the evaluation of different MO methods and the
utility function for methods that rely HV. In practice, a decision maker may be able to specify a reference point
that satisﬁes their preference with domain knowledge. If a reference point is provided by the decision maker,
previous work has suggested heuristics for choosing reference points for use in an algorithm’s utility function
[35, 53]. We follow previous work [69, 68] and assume that the reference point is known.

We also considered (but did not use in our experiments) a dynamic reference point strategy where at each BO
iteration, the reference point is selected to be a point slightly worse than the nadir (component-wise minimum)
point of the current observed Pareto front for computing the acquisition function: r = ynadir − 0.1 · |ynadir|
where ynadir = (cid:0) miny(1)∈D(1) y(1), . . . , miny(m)∈D(m) y(m)(cid:1). This reference point is used in SMS-EMOA in
Ishibuchi et al. [35]), and we ﬁnd similar average performance (but higher variance) on problems to using a
known reference point with continuous Pareto fronts. If the Pareto front is discontinuous, then it is possible not
all sections of the Pareto front will be reached.

E.1.2

qPAREGO

Previous work has only considered unconstrained sequential optimization with ParEGO [40, 7] and ParEGO
is often optimized with gradient-free methods [53]. To the best of our knowledge, qPAREGO is the ﬁrst to
support parallel and constrained optimization. Moreover, we compute exact gradients via auto-differentiation for
acquisition optimization. ParEGO is typically implemented by applying augmented Chebyshev scalarization
and modeling the scalarized outcome [40]. However, recent work has shown that composite objectives offer
improved optimization performance [3]. qPAREGO uses a MC-based Expected Improvement [38] acquisition
function, where the objectives are modeled independently and the augmented Chebyshev scalarization [40] is
applied to the posterior samples as a composite objective. This approach enables the use of sequential greedy
optimization of q candidates with proper integration over the posterior at the pending points. Importantly, the
sequential greedy approach allows for using different random scalarization weights for selecting each of the q
candidates. qPAREGO is extended to the constrained setting by weighting the EI by the probability of feasibility
[25]. We estimate the probability of feasiblity using the posterior samples and approximate the indicator function
with a sigmoid to maintain differentiablity as in constrained qEHVI. qPAREGO is trivially extended to the noisy
setting using Noisy Expected Improvement [43, 5], but we use Expected Improvement in our experiments as all
of the problems are noiseless.

E.2 Benchmark Problems

The details for the benchmark problems below assume minimization of all objectives. Table 2 provides the
reference points used for all benchmark problems.

24

Branin-Currin

f (1)(x(cid:48)

1, x(cid:48)

2) = (x2 −
(cid:20)

1 +

5.1
4π2 x2
(cid:18)

f (2)(x1, x2) =

1 − exp

−

5
π
1
(2x2)

(cid:19)(cid:21) 2300x3

1
8π
1 + 1900x2
1 + 500x2

100x3

x1 − r)2 + 10(1 −

) cos(x1) + 10

1 + 2092x1 + 60
1 + 4x1 + 20

where x1, x2 ∈ [0, 1], x(cid:48)

1 = 15x1 − 5, and x(cid:48)

2 = 15x2.

The constrained Branin-Currin problem uses the following disk constraint from [29]:

c(x(cid:48)

1, x(cid:48)

2) = 50 − (x(cid:48)

1 − 2.5)2 − (x(cid:48)

2 − 7.5)2) ≥ 0

DTLZ2 The objectives are given by [15]:

f1(x) = (1 + g(xM )) cos (cid:0) π
2
f2(x) = (1 + g(xM )) cos (cid:0) π
2
f3(x) = (1 + g(xM )) cos (cid:0) π
2

x1

x1

x1

(cid:1) · · · cos (cid:0) π
2
(cid:1) · · · cos (cid:0) π
2
(cid:1) · · · sin (cid:0) π
2

...

fM (x) = (1 + g(xM )) sin (cid:0) π
2

(cid:1)

x1

(cid:1) cos (cid:0) π
2
(cid:1) sin (cid:0) π
2
(cid:1)

xM −2

xM −2

xM −2

(cid:1)

xM −1

(cid:1)

xM −1

where g(x) = (cid:80)

xi∈xM

(xi − 0.5)2, x ∈ [0, 1]d, and xM represents the last d − M + 1 elements of x.

The C2-DTLZ2 problem adds the following constraint [16]:

c(x) = − min

(cid:20) M
min
i=1

(cid:18)

(fi(x) − 1)2 +

M
(cid:88)

(cid:19)

(f 2

j − r2)

j=1,j=i

(cid:18) M
(cid:88)

,

i=1

(cid:0)(fi(x) −

1
√
M

(cid:19)(cid:21)

)2 − r2(cid:1)

≥ 0

Vehicle Crash Safety The objectives are given by [60]:

f1(x) = 1640.2823 + 2.3573285x1 + 2.3220035x2 + 4.5688768x3 + 7.7213633x4 + 4.4559504x5
f2(x) = 6.5856 + 1.15x1 − 1.0427x2 + 0.9738x3 + 0.8364x4 − 0.3695x1x4 + 0.0861x1x5

+ 0.3628x2x4 + 0.1106x2

1 − 0.3437x2

3 + 0.1764x2
4

f3(x) = −0.0551 + 0.0181x1 + 0.1024x2 + 0.0421x3 − 0.0073x1x2 + 0.024x2x3 − 0.0118x2x4

− 0.0204x3x4 − 0.008x3x5 − 0.0241x2

2 + 0.0109x2
4

where x ∈ [1, 3]5.

(cid:80)

ti<t zbd,ti
(cid:80)

Policy Optimization for Adaptive Bitrate Control The controller is given by: at = x0 ˆzbd,t + x2zbf,t + x3,
where ˆzbd,t =
is estimated bandwidth at time t using an exponential moving average,
zbf,t is the buffer occupancy at time t, and x0, ...x3 are the parameters we seek to optimize. We evaluate each
policy on a set of 400 videos, where the number of time steps (chunks) in each video stream trajectory depends
on the size of the video.

ti<t exp(−x1ti)

exp(−x1ti)

25

Table 3: Acquisition Optimization wall time in seconds on a CPU (2x Intel Xeon E5-2680 v4 @
2.40GHz) and on a GPU (Tesla V100-SXM2-16GB). The mean and two standard errors are reported.
NA indicates that the algorithm does not support constraints.

CPU

CONSTRAINEDBRANINCURRIN

DTLZ2

PESMO (q=1)
SMS-EGO (q=1)
TS-TCH (q=1)
qPAREGO (q=1)
EHVI (q=1)
qEHVI (q=1)

NA
NA
NA
2.4 (±0.37)
NA
5.69 (±0.43)

278.53 (±25.66)
104.26 (±7.66)
52.55 (±0.06)
4.68 (±0.46)
3.58 (±0.28)
5.95 (±0.45)

GPU

CONSTRAINEDBRANINCURRIN

DTLZ2

TS-TCH (q=1)
TS-TCH (q=2)
TS-TCH (q=4)
TS-TCH (q=8)
qPAREGO (q=1)
qPAREGO (q=2)
qPAREGO (q=4)
qPAREGO (q=8)
EHVI (q=1)
qEHVI (q=1)
qEHVI (q=2)
qEHVI (q=4)
qEHVI (q=8)

NA
NA
NA
NA
3.52 (±0.34)
6.0 (±0.56)
12.07 (±0.98)
33.1 (±3.32)
NA
5.61 (±0.17)
19.06 (±5.88)
29.26 (±2.01)
91.56 (±5.51)

0.25 (±0.00)
0.27 (±0.00)
0.28 (±0.00)
0.32 (±0.01)
9.04 (±0.93)
14.23 (±1.55)
40.5 (±3.21)
84.15 (±6.9)
84.15 (±6.9)
10.21 (±0.58)
17.75 (±0.97)
40.41 (±2.78)
106.51 (±7.69)

F Additional Empirical Results

F.1 Additional Sequential Optimization Results

We include results for an additional synthetic benchmark: the DTLZ2 problem from the MO literature [15]
(d = 6, M = 2). Figure 6 shows that qEHVI outperforms all other baseline algorithms on the DTLZ2 in terms
of sequential optimization performance with competitive wall times as shown in 3.

Figure 6: Optimization performance on the DTLZ2 synthetic function (d = 6, M = 2).

F.2 Performance with Increasing Parallelism

Figure 7 shows that that the performance of qEHVI performance does not degrade substantially, whereas
performance does degrade for qPAREGO and TS-TCH on some benchmark problems. We include results for all
problems in Section 5 and Appendix F.1 as well as a Constrained Branin-Currin problem (which is described
in Appendix E.2).

26

020406080100Function Evaluations1.81.61.41.21.00.80.60.4log HV DifferenceSobolEHVIqEHVIqParEGOTS­TCHPESMOSMS­EGO(a) VEHICLESAFETY

(b) VEHICLESAFETY

(c) C2DTLZ2

(d) C2DTLZ2

(e) BRANINCURRIN

(f) BRANINCURRIN

Figure 7: Optimization performance of parallel acquisition functions over batch BO iterations (left)
and function evaluations (right) for benchmark problems in Section 5.

27

020406080100Batch Iteration0.00.51.01.52.0log HV DifferenceSobol q=8TS q=1TS q=2TS q=4TS q=8qEHVI q=1qEHVI q=2qEHVI q=4qEHVI q=8qParEGO q=1qParEGO q=2qParEGO q=4qParEGO q=8020406080100Function Evaluations0.00.51.01.52.0log HV DifferenceSobol q=8TS q=1TS q=2TS q=4TS q=8qEHVI q=1qEHVI q=2qEHVI q=4qEHVI q=8qParEGO q=1qParEGO q=2qParEGO q=4qParEGO q=8020406080100Batch Iteration1.11.00.90.80.70.60.50.4log HV DifferenceSobol q=8qEHVI q=1qEHVI q=2qEHVI q=4qEHVI q=8qParEGO q=1qParEGO q=2qParEGO q=4qParEGO q=8020406080100Function Evaluations1.11.00.90.80.70.60.50.4log HV DifferenceSobol q=8qEHVI q=1qEHVI q=2qEHVI q=4qEHVI q=8qParEGO q=1qParEGO q=2qParEGO q=4qParEGO q=8020406080100Batch Iteration0.00.51.01.5log HV DifferenceSobol q=8TS q=1TS q=2TS q=4TS q=8qEHVI q=1qEHVI q=2qEHVI q=4qEHVI q=8qParEGO q=1qParEGO q=2qParEGO q=4qParEGO q=8020406080100Function Evaluations0.00.51.01.5log HV DifferenceSobol q=8TS q=1TS q=2TS q=4TS q=8qEHVI q=1qEHVI q=2qEHVI q=4qEHVI q=8qParEGO q=1qParEGO q=2qParEGO q=4qParEGO q=8(a) CONSTRAINEDBRANINCURRIN

(b) CONSTRAINEDBRANINCURRIN

(c) DTLZ2 (M = 2, d = 6)

(d) DTLZ2 (M = 2, d = 6)

Figure 8: Optimization performance of parallel acquisition functions over batch BO iterations (left)
and function evaluations (right) for additional benchmark problems.

28

020406080100Batch Iteration0.51.01.52.02.5log HV DifferenceSobol q=8qEHVI q=1qEHVI q=2qEHVI q=4qEHVI q=8qParEGO q=1qParEGO q=2qParEGO q=4qParEGO q=8020406080100Function Evaluations0.51.01.52.02.5log HV DifferenceSobol q=8qEHVI q=1qEHVI q=2qEHVI q=4qEHVI q=8qParEGO q=1qParEGO q=2qParEGO q=4qParEGO q=8020406080100Batch Iteration1.81.61.41.21.00.80.60.4log HV DifferenceSobol q=8TS q=1TS q=2TS q=4TS q=8qEHVI q=1qEHVI q=2qEHVI q=4qEHVI q=8qParEGO q=1qParEGO q=2qParEGO q=4qParEGO q=8020406080100Function Evaluations1.81.61.41.21.00.80.60.4log HV DifferenceSobol q=8TS q=1TS q=2TS q=4TS q=8qEHVI q=1qEHVI q=2qEHVI q=4qEHVI q=8qParEGO q=1qParEGO q=2qParEGO q=4qParEGO q=8F.3 Noisy Observations

Although neither qEHVI nor any variant of expected hypervolume improvement (to our knowledge) directly
account for noisy observations, noisy observations are a practical challenge. We empirically evaluate the
performance of all algorithms on a Branin-Currin function where observations have additive, zero-mean, iid
Gaussian noise; the unknown standard deviation of the noise is set to be 1% of the range of each objective.
Fig 9 shows that qEHVI performs favorably in the presence of noise, besting all algorithms including Noisy
qPAREGO (qNParego) (described in Appendix E.1.2), PESMO and TS-TCH, all of which account for noise.

Figure 9: Sequential optimization performance on a noisy Branin-Currin problem.

F.4 Approximate Box Decompositions

EHVI becomes prohibitively computationally expensive in many scenarios with ≥ 4 objectives because of
the wall time of partitioning the non-dominated space into disjoint rectangles [11]. Therefore, in addition to
providing an exact binary partitioning algorithm, Couckuyt et al. [11] propose an approximation that terminates
the partitioning algorithm when the new additional set of hyper-rectangles in the partitioning has a total
hypervolume of less than a predetermined fraction ζ of the hypervolume dominated by the Pareto front. While
qEHVI is guaranteed to be exact when an exact partitioning of the non-dominated space is used, qEHVI is
agnostic to the partitioning algorithm used and is compatible with more scalable approximate methods.

We evaluate the performance of qEHVI with approximation of various ﬁdelities ζ on DTLZ2 problems with
3 and 4 objectives (with d = 6). ζ = 0 corresponds to an exact partitioning and the approximation is
monotonically worse as ζ increases. Larger values of ζ degrade optimization performance (Figure 10), but can
result in substantial speedups (Table 4). Even with coarser levels of approximation, qEHVI() performs better
than qPAREGO with respect to log hypervolume difference, while achieving wall time improvements of 2-7x
compared to exact qEHVI.

(a)

(b)

Figure 10: Optimization performance on DTLZ2 problems (d = 6) with approximate partitioning
using various approximation levels ζ for (a) M = 3 objectives and (b) M = 4 objectives.

29

020406080100Function Evaluations0.40.60.81.01.21.41.61.8log HV DifferenceSobolEHVIqEHVIqParEGOqNParEGOTS­TCH020406080100Function Evaluations1.00.80.60.40.2log HV DifferenceqEHVI (=103)qEHVI (=104)qEHVI (=105)qEHVI (=106)qEHVI (exact)qParEGO020406080100Function Evaluations0.70.60.50.40.30.20.1log HV DifferenceqEHVI (=103)qEHVI (=104)qEHVI (=105)qEHVI (=106)qEHVI (exact)qParEGOCPU

DTLZ2 (M = 3) DTLZ2 (M = 4)

qPAREGO
qEHVI (ζ = 10−3)
qEHVI (ζ = 10−4)
qEHVI (ζ = 10−5)
qEHVI (ζ = 10−6)
qEHVI (EXACT)

5.86 (±0.51)
6.89 (±0.41)
9.83 (±0.9)
18.99 (±2.72)
37.9 (±7.47)
45.52 (±9.83)

5.6 (±0.53)
9.53 (±0.49)
17.47 (±1.2)
60.27 (±3.57)
136.15 (±12.88)
459.33 (±77.95)

Table 4: Acquisition function optimization wall time with approximate hypervolume computation, in
seconds on a CPU (2x Intel Xeon E5-2680 v4 @ 2.40GHz). The mean and two standard errors are
reported.

F.5 Acquisition Computation Time

Figure 11 show the acquisition computation time for different M and q. The inﬂection points corresponds to
available processor cores becoming saturated. For large M an q on the GPU, memory becomes an issue, but we
discuss ways of mitigating the issue in Appendix A.4.

Figure 11: Acquisition computation time for different batch sizes q and numbers of objectives M
(this excludes the time required to compute the acquisition function given box decomposition of the
non-dominated space). This uses N = 512 MC samples, d = 6, |P| = 10, and 20 training points.
CPU time was measured on 2x Intel Xeon E5-2680 v4 @ 2.40GHz and GPU time was measured on a
Tesla V100-SXM2-16GB GPU using 64-bit ﬂoating point precision. The mean and 2 standard errors
over 1000 trials are reported.

30

2.55.07.510.012.515.017.5q0123456Acquisition Computation Time (s)M=2 (CPU)M=3 (CPU)M=4 (CPU)M=2 (GPU)M=3 (GPU)M=4 (GPU)