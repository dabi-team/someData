2
2
0
2

r
a

M
7

]

G
L
.
s
c
[

1
v
8
2
3
3
0
.
3
0
2
2
:
v
i
X
r
a

Automated Few-Shot Time Series Forecasting based on
Bi-level Programming∗

Jiangjiao Xu and Ke Li

Department of Computer Science, University of Exeter, EX4 4QF, Exeter, UK

Email: k.li@exeter.ac.uk

Abstract: New micro-grid design with renewable energy sources and battery storage systems can
help improve greenhouse gas emissions and reduce the operational cost. To provide an eﬀective short-
/long-term forecasting of both energy generation and load demand, time series predictive modeling
has been one of the key tools to guide the optimal decision-making for planning and operation. One of
the critical challenges of time series renewable energy forecasting is the lack of historical data to train
an adequate predictive model. Moreover, the performance of a machine learning model is sensitive
to the choice of its corresponding hyperparameters. Bearing these considerations in mind, this paper
develops a BiLO-Auto-TSF/ML framework that automates the optimal design of a few-shot learning
pipeline from a bi-level programming perspective. Speciﬁcally, the lower-level meta-learning helps
boost the base-learner to mitigate the small data challenge while the hyperparameter optimization
at the upper level proactively searches for the optimal hyperparameter conﬁgurations for both base-
and meta-learners. Note that the proposed framework is so general that any oﬀ-the-shelf machine
learning method can be used in a plug-in manner. Comprehensive experiments fully demonstrate
the eﬀectiveness of our proposed BiLO-Auto-TSF/ML framework to search for a high-performance
few-shot learning pipeline for various energy sources.

Keywords: Micro-grid design, bi-level programming, meta-learning, time series forecasting,

hyperparameter optimization

1

Introduction

Smart grid technology has become the driving force that enables an eﬀective management and dis-
It connects a variety of
tribution of renewable energy sources such as solar, wind and hydrogen.
distributed energy resource assets to the power grid. The relationship between the smart grid and
renewable energy revolves around gathering data. With ﬂourishing developments of the Internet of
things (IoT), utility companies are able to quickly detect and resolve service issues through contin-
uous self-assessments and self-healing by leveraging heterogeneous and time series data collected on
the smart grid. In particular, time series predictive modeling, which provides short- and/or long-term
forecasting of both energy generation and load demand, has been one of the key tools to guide optimal
decision-making for planning and operation of utility companies without over/underestimating the
capabilities of renewable energy infrastructures [1].

As discussed in some recent survey papers (e.g., [2–4]), there have been a noticeable amount of
eﬀorts on applying machine learning methods for time series renewable energy forecasting in the
past two decades and beyond. For example, neural networks (NNs) with multi-layer perceptron were
developed to forecast the daily solar radiation in time series dataset by using a transfer function of
hidden layers [5]. Recurrent neural networks (RNNs) such as long short-term memory (LSTM) [6],
which take historical time series data as the input and predict the trajectory over a certain time
horizon, have been proved to be eﬀective because they consider both the instantaneous interactions
within contiguous time steps and the long-term dependencies stored in memory cells. In [7], a K-
nearest neighbor based time weighted dot product dissimilarity measure was proposed to improve

∗This manuscript is submitted for potential publication. Reviewers can use this version in peer review.

1

 
 
 
 
 
 
the forecasting accuracy and reduce the processing time. In [8], support vector regression (SVR) was
applied to make a mid-term time series load prediction. In [9], a sparse online warped Gaussian process
regression was developed to provide a short-term probabilistic prediction of wind power generation
with a non-Gaussian predictive distribution.

To promote the further uptake of machine learning in smart grid industry, we need to address two

imperative challenges.

• Small data challenge: Fitting a time series model with an adequate statistical conﬁdence usually
requires suﬃcient data. Unfortunately, this is hardly met in real-life scenarios. For example,
when planning an island grid, due to various technical problems such as equipment failures, mea-
surement errors or restrictions on the daily power supply time [10], there may exist substantial
gaps in the collected historical power consumption data, i.e., incomplete or missing data. Even
worse, some islands may not have any historical data at all due to the laggard in infrastructure.
All these signiﬁcantly compromise the prediction performance in time series forecasting. How
to use the limited historical data of multiple islands to predict the energy of an island without
historical data is a big challenge for conventional prediction models.

• Hyperparameter tuning challenge: The performance of most, if not all, machine learning methods
are very sensitive to their hyperparameters such as neural architectures in NNs, kernel functions
and regularization methods in SVR. The optimal choice of hyperparameters also vary across
tasks and datasets [11]. The black-box nature of machine learning models leads to a considerable
barrier to domain experts, who are interested in applying machine learning methods yet have
suﬃcient time and/or resources to learn the inside out, for choosing the optimal hyperparameters
to achieve the state-of-the-art performance.

Bearing these challenges in mind, this paper develops BiLO-Auto-TSF/ML, a ﬁrst of its kind bi-level
programming framework to automate the time series forecasting in smart grid with limited historical
data. The key contributions are summarized as follow.

• To address the small data challenge, we propose to use meta-learning to improve the generation
performance of the base-learner to unseen tasks by only referring to limited historical data.
Although there have been some successful applications of meta-learning in various domains such
as object detection [12, 13], landmark prediction [14], and image/video generation [15, 16], it has
rarely been explored in the context of smart grid, to the best of our knowledge.

• Due to the nested structure between base- and meta-learners, there exist complex interactions
among their associated hyperparameters. In this paper, we hypothesize that it may not be able to
achieve a peak performance if the hyperparameters associated with the base- and meta-learners
are set independently. Although there have been some previous attempts on hyperparameter
optimization for meta-learning, they mainly consider the ones associated with the meta-learner,
such as the learning rate in the inner loop [17]. In this paper, our ambition is to automate the
optimal design of a few-shot learning1 pipeline from a bi-level programming perspective.

• In BiLO-Auto-TSF/ML, the upper-level optimization searches for the optimal hyperparameter
settings associated with both base- and meta-learners by a Monte Carlo tree search (MCTS) [18];
while the lower-level optimization implements a model-agnostic gradient-based meta-learning as
done in [19]. In other words, any oﬀ-the-shelf machine learning can be used in BiLO-Auto-TSF/ML
in a plug-in manner.

• To validate the eﬀectiveness of our proposed BiLO-Auto-TSF/ML framework, we consider some
selected real-world energy forecasting tasks for smart grid infrastructure planning in island areas
at the English Channel. In particular, three prevalent machine learning methods are used as the
base-learners for a proof-of-concept purpose. Extensive experimental results fully demonstrate
the eﬀectiveness of our proposed BiLO-Auto-TSF/ML framework for time series forecasting with
highly limited historical data.

1In this paper, we use meta-learning and few-shot learning interchangeably.

2

The rest of this paper is organized as follows. Section 2 provides a pragmatic overview of some
related works. Section 3 delineates the implementation of our proposed BiLO-Auto-TSF/ML frame-
work. Section 4 gives the experimental setup while the empirical results are presented and analyzed
in Section 5. Finally, Section 6 concludes this paper and threads some lights on potential future
directions.

2 Related Works

This section provides a pragmatic overview of some selected developments of both time series fore-
casting in smart grid and hyperparameter optimization for meta-learning.

2.1 Time Series Forecasting in Smart Grid

Electric load demand or renewable energy generation forecasting is critical to the operation and man-
agement of a smart grid. Based on the length of time period, the predictive modeling can be divided
into short-, mid-, and long-term forecasting [20]. In recent years, NNs have been widely applied to
obtain latent information to build prediction models, e.g., dynamic choice artiﬁcial neural network
model [21], generalized regression neural network [22], and nonlinear autoregressive neural network
models with exogenous input (NARX) [23]. Nevertheless, NNs are notorious for overﬁtting and are
also suﬀered from local optima in the backpropagation [24]. To mitigate the overﬁtting problem by
raising a new data dimension, Shi et al. [25] proposed to use a pooling-based deep recurrent neural
network for short-term household load forecasting. Moon et al. [26] proposed to synthesize more than
one deep neural network model with multiple hidden layers to select a model with the best prediction
performance. In [27], Aly proposed a hybrid of wavelet neural network and Kalman ﬁlter for short-
term load forecasting problems. Mid-term forecasting is used to coordinate load dispatch and balance
load demand and renewable energy generation [28]. Jiang et al. [29] proposed a dynamic Bayes net-
work for mid-term forecasting problem to predict the peak time load in a year. In [30], Grzegorz et al.
proposed a hybrid deep learning model for mid-term forecasting that combined exponential smoothing
(ETS), multi-layer LSTM and ensemble learning which have shown competitive performance against
other models like ARIMA and ETS. Long-term forecasting is used to predict the power consumption
and generation ranging from a few years to a couple of decades for the system planning and expansion
in a smart grid. In [31] and [20], variants of RNN have been proposed for long-term time series load
forecasting and have shown better results than other forecasting methods like NARX and SVR.

2.2 Hyperparameter Optimization for Meta-Learning

Meta-learning has been proven to be eﬀective in multiple tasks scenarios where task-agnostic knowl-
edge is extracted from the same distribution of tasks with small datasets and used to ﬁnd good starting
parameters of the baseline machine learning model for new tasks [32]. It has been widely appreciated
that the performance of machine learning is sensitive to the choice of the corresponding hyperpa-
rameters. For example, The existing gradient-based meta-learning usually rely on the choice of an
appropriate optimizer to ﬁne tune the parameters of the meta-learner. Furthermore, there are various
hyperparameters associated with the base-learner such as the neural architecture and the learning rate,
the conﬁguration of which can inﬂuence the predictive performance. In the past decade, there have
been many eﬀorts devoated to the hyperparameter optimization for meta-learning. For example, in or-
der to reduce the sensitivity to the hyperparameters, Li et al. [33] proposed to use a stochastic gradient
descent method to update the inner-loop learning rate for the meta-learner. The experimental results
have shown the eﬀectiveness of hyperparameter optimization for the meta-learner. In [34], Antoniou
et al. proposed an improved gradient-based meta-learning method in which the inner-loop learning
rate is updated according to the performance of the selected model. In [35], Rusu et al. proposed a la-
tent embedding optimization approach to optimize a range of hyperparameters in meta-learning. The
experimental results have shown superior performance against some gradient-based hyperparameter
adaptation. Franceschi et al. [36] proposed a bi-level programming framework to optimize the param-
eters of a neural network along with the hyperparameters of a meta learner in a concurrent manner.

3

Figure 1: The overall architecture and workﬂow of BiLO-Auto-TSF/ML.

In [37], Baik et al. proposed a fast adaptation approach to predict the adaptive hyperparameters by
using the current parameters and their gradients. The proposed method from a random initialization
with an adaptive learning of hyperparameters outperform other existing algorithms.

Remark 1. Most, if not all, existing time series forecasting models in the smart grid literature require
suﬃcient amount of historical data. Unfortunately, this can be hardly met in real-world applications
of which available data is usually scarce especially for the power system design and planning in remote
areas like an isolated island network.

Remark 2. From the above literature review, we ﬁnd that the existing studies on hyperparameter
optimization only take the hyperparameters in the inner loop of meta-learning into consideration.
However, it is not diﬃcult to envisage that there exist certain dependencies between the hyperparam-
eters associated with both base- and meta-learners. Unfortunately, the concurrent optimization w.r.t.
these two types of hyperparameters have been largely ignored in the literature.

3 Automated Few-Shot Learning for Time Series Forecasting

This section delineates the implementation of our proposed BiLO-Auto-TSF/ML framework that auto-
mates the design of a few-shot learning pipeline for time series forecasting with limited data from a
bi-level programming perspective. We start with the overarching bi-level programming problem formu-
lation considered in this paper. Then, we delineate the algorithmic implementation of the optimization
routines at both levels respectively.

3.1 Problem Formulation of Bi-level Programming

The BiLO-Auto-TSF/ML framework involves a sequence of l
1 decisions that choose the hyperpa-
rameters associated with the baseline machine learning model along with its parameters, the learning
rates of both inner and outer loop of the meta-learning, the optimization algorithms for empirical loss
function optimization and the number of shots in meta-learning, respectively. At the i-th decision
step (1
i is a ﬁnite set of possible alterna-
tive options at the i-th decision step. The space of hyperparameters associated with ci is denoted
as Θ(ci) and a complete pipeline structure is an (cid:96)-tuple c = (c1,
l where
Θ(c) = Θ(c1)
Θ(cl) is its associated hyperparameter space.

l), a design component ci

i is selected where

× · · · × C

, cl)

∈ C

∈ C

· · ·

≤

≤

≥

=

C

C

i

1

The key challenge of the automated design of a few-shot learning pipeline for time series fore-
casting considered in this paper is an intertwined optimization of the parametric optimization of the
associated hyperparameters c and the gradient-based optimization associated with the meta-learning
simultaneously. In this paper, we propose to formulate this intertwined optimization problem as the

× · · · ×

4

Upper-level optimizationCompute gradientCompute gradientLower-level optimizationNetwork structureInitial <latexit sha1_base64="XUWU/T/z7bUiyvN5Zt9VnSuGYHc=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqCcpePFYwX5AG8pmu2nXbjZhdyKU0P/gxYMiXv0/3vw3btsctPXBwOO9GWbmBYkUBl332ymsrW9sbhW3Szu7e/sH5cOjlolTzXiTxTLWnYAaLoXiTRQoeSfRnEaB5O1gfDvz209cGxGrB5wk3I/oUIlQMIpWavVwxJH2yxW36s5BVomXkwrkaPTLX71BzNKIK2SSGtP13AT9jGoUTPJpqZcanlA2pkPetVTRiBs/m187JWdWGZAw1rYUkrn6eyKjkTGTKLCdEcWRWfZm4n9eN8Xw2s+ESlLkii0WhakkGJPZ62QgNGcoJ5ZQpoW9lbAR1ZShDahkQ/CWX14lrYuqd1mt3dcq9Zs8jiKcwCmcgwdXUIc7aEATGDzCM7zCmxM7L86787FoLTj5zDH8gfP5A6Wxjy0=</latexit>✓<latexit sha1_base64="XUWU/T/z7bUiyvN5Zt9VnSuGYHc=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqCcpePFYwX5AG8pmu2nXbjZhdyKU0P/gxYMiXv0/3vw3btsctPXBwOO9GWbmBYkUBl332ymsrW9sbhW3Szu7e/sH5cOjlolTzXiTxTLWnYAaLoXiTRQoeSfRnEaB5O1gfDvz209cGxGrB5wk3I/oUIlQMIpWavVwxJH2yxW36s5BVomXkwrkaPTLX71BzNKIK2SSGtP13AT9jGoUTPJpqZcanlA2pkPetVTRiBs/m187JWdWGZAw1rYUkrn6eyKjkTGTKLCdEcWRWfZm4n9eN8Xw2s+ESlLkii0WhakkGJPZ62QgNGcoJ5ZQpoW9lbAR1ZShDahkQ/CWX14lrYuqd1mt3dcq9Zs8jiKcwCmcgwdXUIc7aEATGDzCM7zCmxM7L86787FoLTj5zDH8gfP5A6Wxjy0=</latexit>✓Update <latexit sha1_base64="okl9KbIubLy3EWaIVUEmQfgShfQ=">AAAB83icbVBNS8NAEJ3Ur1q/qh69LBbBU0lE1JMUvHisYD+gCWWz3bRLN5uwOxFK6N/w4kERr/4Zb/4bt20O2vpg4PHeDDPzwlQKg6777ZTW1jc2t8rblZ3dvf2D6uFR2ySZZrzFEpnobkgNl0LxFgqUvJtqTuNQ8k44vpv5nSeujUjUI05SHsR0qEQkGEUr+f6IYu7jiCOd9qs1t+7OQVaJV5AaFGj2q1/+IGFZzBUySY3peW6KQU41Cib5tOJnhqeUjemQ9yxVNOYmyOc3T8mZVQYkSrQthWSu/p7IaWzMJA5tZ0xxZJa9mfif18swuglyodIMuWKLRVEmCSZkFgAZCM0ZyokllGlhbyVsRDVlaGOq2BC85ZdXSfui7l3VLx8ua43bIo4ynMApnIMH19CAe2hCCxik8Ayv8OZkzovz7nwsWktOMXMMf+B8/gB8TpH6</latexit>ˆ✓<latexit sha1_base64="okl9KbIubLy3EWaIVUEmQfgShfQ=">AAAB83icbVBNS8NAEJ3Ur1q/qh69LBbBU0lE1JMUvHisYD+gCWWz3bRLN5uwOxFK6N/w4kERr/4Zb/4bt20O2vpg4PHeDDPzwlQKg6777ZTW1jc2t8rblZ3dvf2D6uFR2ySZZrzFEpnobkgNl0LxFgqUvJtqTuNQ8k44vpv5nSeujUjUI05SHsR0qEQkGEUr+f6IYu7jiCOd9qs1t+7OQVaJV5AaFGj2q1/+IGFZzBUySY3peW6KQU41Cib5tOJnhqeUjemQ9yxVNOYmyOc3T8mZVQYkSrQthWSu/p7IaWzMJA5tZ0xxZJa9mfif18swuglyodIMuWKLRVEmCSZkFgAZCM0ZyokllGlhbyVsRDVlaGOq2BC85ZdXSfui7l3VLx8ua43bIo4ynMApnIMH19CAe2hCCxik8Ayv8OZkzovz7nwsWktOMXMMf+B8/gB8TpH6</latexit>ˆ✓Update <latexit sha1_base64="/wvBd/OHux2jjOaE7mGVHNaOLw0=">AAAB8nicbVBNS8NAEN3Ur1q/qh69LBbBU0mkqCcpePFYwX5AEstmu2mXbnbD7kQooT/DiwdFvPprvPlv3LY5aOuDgcd7M8zMi1LBDbjut1NaW9/Y3CpvV3Z29/YPqodHHaMyTVmbKqF0LyKGCS5ZGzgI1ks1I0kkWDca38787hPThiv5AJOUhQkZSh5zSsBKfgAjBuQxIAb61Zpbd+fAq8QrSA0VaPWrX8FA0SxhEqggxviem0KYEw2cCjatBJlhKaFjMmS+pZIkzIT5/OQpPrPKAMdK25KA5+rviZwkxkySyHYmBEZm2ZuJ/3l+BvF1mHOZZsAkXSyKM4FB4dn/eMA1oyAmlhCqub0V0xHRhIJNqWJD8JZfXiWdi7p3WW/cN2rNmyKOMjpBp+gceegKNdEdaqE2okihZ/SK3hxwXpx352PRWnKKmWP0B87nD3mqkWE=</latexit>✓⇤<latexit sha1_base64="/wvBd/OHux2jjOaE7mGVHNaOLw0=">AAAB8nicbVBNS8NAEN3Ur1q/qh69LBbBU0mkqCcpePFYwX5AEstmu2mXbnbD7kQooT/DiwdFvPprvPlv3LY5aOuDgcd7M8zMi1LBDbjut1NaW9/Y3CpvV3Z29/YPqodHHaMyTVmbKqF0LyKGCS5ZGzgI1ks1I0kkWDca38787hPThiv5AJOUhQkZSh5zSsBKfgAjBuQxIAb61Zpbd+fAq8QrSA0VaPWrX8FA0SxhEqggxviem0KYEw2cCjatBJlhKaFjMmS+pZIkzIT5/OQpPrPKAMdK25KA5+rviZwkxkySyHYmBEZm2ZuJ/3l+BvF1mHOZZsAkXSyKM4FB4dn/eMA1oyAmlhCqub0V0xHRhIJNqWJD8JZfXiWdi7p3WW/cN2rNmyKOMjpBp+gceegKNdEdaqE2okihZ/SK3hxwXpx352PRWnKKmWP0B87nD3mqkWE=</latexit>✓⇤Evaluate performanceUpdate <latexit sha1_base64="H7Ja5/uvPuWXzVzReDwyp8pNNTg=">AAAB9HicbVBNS8NAEN3Ur1q/qh69BIvgqSRS1JMUvHisYD+giWWznbRLd5O4OymU0N/hxYMiXv0x3vw3btsctPXBwOO9GWbmBYngGh3n2yqsrW9sbhW3Szu7e/sH5cOjlo5TxaDJYhGrTkA1CB5BEzkK6CQKqAwEtIPR7cxvj0FpHkcPOEnAl3QQ8ZAzikbyPRwC0kcvUVxCr1xxqs4c9ipxc1IhORq98pfXj1kqIUImqNZd10nQz6hCzgRMS16qIaFsRAfQNTSiErSfzY+e2mdG6dthrExFaM/V3xMZlVpPZGA6JcWhXvZm4n9eN8Xw2s94lKQIEVssClNhY2zPErD7XAFDMTGEMsXNrTYbUkUZmpxKJgR3+eVV0rqoupfV2n2tUr/J4yiSE3JKzolLrkid3JEGaRJGnsgzeSVv1th6sd6tj0VrwcpnjskfWJ8/EAaSSg==</latexit>✓0<latexit sha1_base64="H7Ja5/uvPuWXzVzReDwyp8pNNTg=">AAAB9HicbVBNS8NAEN3Ur1q/qh69BIvgqSRS1JMUvHisYD+giWWznbRLd5O4OymU0N/hxYMiXv0x3vw3btsctPXBwOO9GWbmBYngGh3n2yqsrW9sbhW3Szu7e/sH5cOjlo5TxaDJYhGrTkA1CB5BEzkK6CQKqAwEtIPR7cxvj0FpHkcPOEnAl3QQ8ZAzikbyPRwC0kcvUVxCr1xxqs4c9ipxc1IhORq98pfXj1kqIUImqNZd10nQz6hCzgRMS16qIaFsRAfQNTSiErSfzY+e2mdG6dthrExFaM/V3xMZlVpPZGA6JcWhXvZm4n9eN8Xw2s94lKQIEVssClNhY2zPErD7XAFDMTGEMsXNrTYbUkUZmpxKJgR3+eVV0rqoupfV2n2tUr/J4yiSE3JKzolLrkid3JEGaRJGnsgzeSVv1th6sd6tj0VrwcpnjskfWJ8/EAaSSg==</latexit>✓0Compute gradient<latexit sha1_base64="JGTSQJOvsF3FWv0O5BZxT+0HDiw=">AAACBnicbVDLSgMxFM3UV62vUZciBIvgqsxIUVdS0IXLCvYB7Thk0kwbmmSGJCOUYVZu/BU3LhRx6ze482/MTLvQ1gOBk3Pu5d57gphRpR3n2yotLa+srpXXKxubW9s79u5eW0WJxKSFIxbJboAUYVSQlqaakW4sCeIBI51gfJX7nQciFY3EnZ7ExONoKGhIMdJG8u3DPkd6hBFLrzN/fJ8WX8lTLTNfZb5ddWpOAbhI3Bmpghmavv3VH0Q44URozJBSPdeJtZciqSlmJKv0E0VihMdoSHqGCsSJ8tLijAweG2UAw0iaJzQs1N8dKeJKTXhgKvMt1byXi/95vUSHF15KRZxoIvB0UJgwqCOYZwIHVBKs2cQQhCU1u0I8QhJhbZKrmBDc+ZMXSfu05p7V6rf1auNyFkcZHIAjcAJccA4a4AY0QQtg8AiewSt4s56sF+vd+piWlqxZzz74A+vzB8lYmfk=</latexit>DtrskSupport sets <latexit sha1_base64="S9MMr9DvS6Vjof9Ccf1RZDZCWqA=">AAACA3icbVDLSgMxFM34rPU16k43wSK4KjNS1JUUdOGygn1AO5ZMmmlDk8yQZAplGHDjr7hxoYhbf8Kdf2NmOgttPRA4Oede7r3HjxhV2nG+raXlldW19dJGeXNre2fX3ttvqTCWmDRxyELZ8ZEijArS1FQz0okkQdxnpO2PrzO/PSFS0VDc62lEPI6GggYUI22kvn3Y40iPMGLJTfqQ5B/Jkwliadq3K07VyQEXiVuQCijQ6NtfvUGIY06Exgwp1XWdSHsJkppiRtJyL1YkQniMhqRrqECcKC/Jb0jhiVEGMAileULDXP3dkSCu1JT7pjJbUs17mfif1411cOklVESxJgLPBgUxgzqEWSBwQCXBmk0NQVhSsyvEIyQR1ia2sgnBnT95kbTOqu55tXZXq9SvijhK4Agcg1PgggtQB7egAZoAg0fwDF7Bm/VkvVjv1sesdMkqeg7AH1ifP1UnmJw=</latexit>DvalValidation sets <latexit sha1_base64="gMBjoyV08FZaUjKkEo6VA27o1tQ=">AAACBnicbVDLSgMxFM34rPU16lKEYBFclRkp6koKunBZwT6gHYdMmmlDk8yYZIQyzMqNv+LGhSJu/QZ3/o2ZaRfaeiBwcs693HtPEDOqtON8WwuLS8srq6W18vrG5ta2vbPbUlEiMWniiEWyEyBFGBWkqalmpBNLgnjASDsYXeZ++4FIRSNxq8cx8TgaCBpSjLSRfPugx5EeYsTSq8wf3aXFV/JUy8y/z3y74lSdAnCeuFNSAVM0fPur149wwonQmCGluq4Tay9FUlPMSFbuJYrECI/QgHQNFYgT5aXFGRk8MkofhpE0T2hYqL87UsSVGvPAVOZbqlkvF//zuokOz72UijjRRODJoDBhUEcwzwT2qSRYs7EhCEtqdoV4iCTC2iRXNiG4syfPk9ZJ1T2t1m5qlfrFNI4S2AeH4Bi44AzUwTVogCbA4BE8g1fwZj1ZL9a79TEpXbCmPXvgD6zPH8ZOmfc=</latexit>DtrqkQuery sets SelectionBack-propagationExpansionSimulationdefault policyfollowing bi-level programming problem:

minimize

subject to

val(c, ˆθ;
L
D
ˆθ := argmin

val)

θ

tr
meta(c, θ;

L

,
tr)

D

(1)

L

L

val and

Rm
tr
meta denote the upper- and lower-level objective functions, and c
where
denote the upper- and lower-level variables. More speciﬁcally, at the upper level, we aim to identify
the best few-shot learning pipeline c∗ having the optimal hyperparameters along with the optimal
parameters ˆθ
val (i.e., the
associated with the baseline machine learning model that minimizes
validation empirical risk) at the end of meta-training where:

Θ(c) and ˆθ

L

∈

∈

∗

val(c, ˆθ;

L

val) (cid:44) 1
|D

val

D

(cid:88)

(cid:16)

(cid:17)
yi, f (xi; ˆθ)

,

(cid:96)val
c

(xi,yi)∈Dval

|

(2)

(cid:16)

(cid:17)
yi, f (xi; ˆθ)

c

where (cid:96)val
is the loss function regarding a given few-shot learning pipeline c on the
validation set. Note that this validation empirical risk requires the parameters of the baseline machine
learning model to be optimized by a meta-learning process at the lower level. The training empirical
risk associated with the lower-level meta-learning is deﬁned as:

tr
meta

L

(cid:44) (cid:88)
Dtr

k ∼Dtr L

tr(c, θ;

tr
k ),

D

where

tr(c, θ;

L

tr

k ) (cid:44) 1
tr
D
k |
|D

(cid:88)

(cid:16)

(cid:96)tr
c

yi, f (xi; θ)

(cid:17)

,

(xi,yi)∈Dtr
k

(3)

(4)

(cid:16)

(cid:17)
yi, f (xi; θ)

where (cid:96)tr
c

is the loss function regarding c on the meta-training set.
The overall architecture of BiLO-Auto-TSF/ML is given in Fig. 1. It consists of two nested levels
of optimization routines. Given the discrete nature of the upper-level hyperparameter optimization
problem, BiLO-Auto-TSF/ML applies a Monte-Carlo tree search (MCTS), as delineated in Section 3.2,
to explore the hyperparameter space thus gradually navigating the exploration towards some most
promising regions within the search tree. As for the lower-level optimization, we develop a gradient-
based meta-learning approach as in [19]. As detailed in Section 3.3, it identiﬁes the promising initial
parameters for the baseline machine learning model to adapt to the target task(s) with limited data.

3.2 Upper-level Optimization Routine

In view of the discrete nature of the search space of hyperparameters, this paper considers using a tree-
based search to implement the hyperparameter optimization at the upper level. As shown in Fig. 1,
the MCTS algorithm iterates over the following four steps.

• Selection: The MCTS algorithm starts from the root node nr and recursively selects internal
In particular, the tree-path from nr to an
nodes downward until it reaches a leaf node nl.
internal node represents a partial solution, i.e., an incomplete pipeline. As for each parent (non-
leaf) node np, its child node nc
c is selected by maximizing the upper conﬁdence bound for
trees [38]:

∈ N

nc := argmax
nc∈Nc

(cid:40)

Q(nc)
N(nc)

+ α

(cid:115)

ln N(np)
N(nc)

(cid:41)
,

(5)

where Q(nc) is the expected reward for nc, N(nc) and N(np) is the number of times that nc
and np has been visited, respectively, and α is a parameter that controls the trade-oﬀ between
exploration and exploitation.

5

• Expansion: Once a leaf node is reached, one or more child nodes will be amended to expand
the tree structure. In this paper, we apply the rapid action value estimation method [39] to
select the new nodes. The number of child nodes associated with its parent node np is selected
and constructed according to a progressive widening trick [40]. In particular, a new child node
can be amended if and only if the
increases by one, where 0 < κ < 1 is a constant
coeﬃcient.

N(np)κ

(cid:101)

(cid:100)

• Simulation: If the expansion step ﬁnishes whereas a terminal node is not yet reached (i.e., we
come up with an incomplete few-shot learning pipeline), a default policy (we use a random
sampling strategy in this paper) is applied to select the remaining options until it reaches a
terminal node. Thereafter, given the generated few-shot learning pipeline c, its reward Q(c) is
evaluated as the validation empirical risk. In particular, the parameters of the baseline machine
learning model are optimized by a meta-learning process at the lower level.

• Back-propagation: The reward value obtained in the expansion step is back-propagated to update
the N and Q values associated with all nodes along the visited tree-path until the root node. In
particular, for each visited node n, the update rule is as follows:

N(n) := N(n) + 1,
Q(n) := Q(n) + Q(c).

(6)

Note that the above four steps iterate until either the computational budget is exhausted.

3.3 Lower-level Optimization Routine

As discussed in Sections 3.1 and 3.2, the lower-level optimization aims to train a machine learning
model with limited historical data. In the following paragraphs, we will elaborate on the general setup
of our meta-learning along with the meta-training process.

• Meta-learning setup: As introduced in Section 1, when considering the planning of island grids,
a key challenge is the shortage of historical data that render the classic machine learning pipeline
largely ineﬀective. This motivates us to use meta-learning to mitigate this small data challenge.
T
i=1 to constitute the
Formally, let us denote the data collected from T islands as
}
).
training dataset. In particular, we assume that
trq
i where
For each island, the corresponding training dataset is constituted as
denote the support and query sets respectively. In this paper, we
i
∈ {
have

i
{T
is sampled from a ﬁxed distribution P(
tr
i
D

trq
i
D
80%.

trs
i
D

,
}
:=

and

:=

:=

, T

(cid:83)

1,

D

T

T

T

· · ·
trs
i

|D

|

trs
i
D
tr
i
|D

| ×

• Meta-learning process: Inspired by [19], we develop a gradient-based meta-learning process where

the parameters θ of the baseline machine learning are updated as:

−
where α is the inner-loop learning rate and
regarding the support set

L
trs
k where k is for all picked up islands.

∇

D

D

θ(cid:48) := θ

α

θ

∇

θ

tr(c, θ;

L
tr(c, θ;

trs
k ),
D
trs
k ) is the gradient of the loss function

(7)

– During the meta-training phase, we randomly pick up N

contains K data instances drawn from the corresponding island to constitute
k
ated with θ across the query sets of N islands sampled from P(

T islands, each of which
tr
k where
. the model parameters are updated by minimizing the loss function associ-
}

) deﬁned as:

∈ {

, N

· · ·

1,

≤

D

meta(c, θ(cid:48);
tr
L

trq

k ) (cid:44) (cid:88)
D

D

trq
k ∼Dtrq

tr(c, θ(cid:48);

L

D

T
trq
k ),

(8)

where equation (8) is calculated by using the updated parameters θ(cid:48) for the given query
sets

trq and the loss function regarding the k-th island is deﬁned as:

D

tr(c, θ(cid:48);

L

trq
k ) :=

D

(cid:88)

(xi,yi)∈D

trq
k

f (xi; θ(cid:48))
||

−

yi

2
2.
||

(9)

6

Algorithm 1: Model-agnostic gradient-based meta-learning at
BiLO-Auto-TSF/ML.

the lower

level of

Input: Meta training data set

tr = (

trs,

trq ), meta validation data set

D
of base learner and meta learner including α, β, γ

D

D

val, parameters

D

Output: Predicted outputs
1 Initialize model parameter θ;
1, 2, ... to do
2 for iteration
3

←

4

5

6

7

8

9

Sample N islands randomly from T ;
for all k = 1,

, N to do

· · ·

trs
;
Sample support sets
k
D
tr(c, θ;
Compute the loss
Obtain the θ(cid:48) via gradient descent in (7) ;
trq
;
Sample query sets
k
D
meta(c, θ(cid:48);
tr
Compute the loss
L

trs
k );

D

L

D
Obtain ˆθ via gradient descent using

trq
k );
meta(c, θ(cid:48);
tr

10
11 Obtain the parameters θ∗ using
12 Feed data into the machine learning model to predict the outputs for new island;
13 return Prediction results

val via (11) with a couple of gradient descent steps;

D

D

L

trq
k ) with respect to θ;

Accordingly, the parameters ˆθ of the baseline machine learning model are updated as:

ˆθ := θ

β

θ

meta(c, θ(cid:48);
tr

trq
k ),

(10)

L
where β is the outer-loop learning rate and ˆθ is the updated parameters of the baseline
machine learning model after a one-step gradient descent.

∇

−

D

– After the meta-training phase, the updated parameters ˆθ will be ﬁne-tuned on the validation

sets

D

val with a few gradient descent steps as:

θ∗ := ˆθ

γ

∇

−

meta(c, ˆθ;
val

ˆθL

val),

D

(11)

where γ is the validation learning rate.

At the end, θ∗ will be used as the optimal parameters of the baseline machine learning model for
predicting the unseen data collected from a new island. The workﬂow of the lower-level optimization
is illustrated at lower-level optimization part of Fig. 1 and the pseudo-code is given in Algorithm 1.

4 Experimental Setup

This section introduces the setup of our empirical study including the dataset, parameter settings, the
performance metric, and the statistical tests [41–79].

• Dataset: Our empirical study considers the energy forecasting tasks for smart grid infrastructure
planning in islands at the English Channel [80]. We consider three diﬀerent energy sources
including the wind generation, the photovoltaic (PV) generation, and the load demand. The
training set consists of data collected from four islands including Ushant, Molene, Sein and Isles
of Scilly while those obtained from the island Lundy constitute the validation set. As discussed
in Section 1, the key challenge here is the lack of suﬃcient historical data. In particular, for each
energy source, there is only a week’s time series data for each island.

• Parameter settings: There are (cid:96) = 5 hyperparameters considered in our automated few-shot

learning pipeline.

7

– Note that our proposed BiLO-Auto-TSF/ML is model agnostic where any oﬀ-the-shelf ma-
chine learning method can be used as the base-learner. In our experiments, we consider
three widely used machine learning models including a two-layer NN, SVR and LSTM, for a
proof of concept purpose.

– hyperparameters associated with the base-learner: the number of hidden neurons of NN
(from 128 to 1, 024), kernels used in SVR (including linear, poly, rbf, sigmoid, precomputed),
and the number of units in LSTM (from 128 to 1, 024).

– Three diﬀerent learning rates α

[0.0001, 0.5], β

[0.0001, 0.5], and γ

[0.0001, 0.5].

∈

∈

∈

– Optimization methods for the loss function: SGD [81], Adam [82], RMSprop [83], Adadelta [84]

and Adagrad [85].

• Performance metric: Here we use the widely used mean squared error (MSE) as the metric to

evaluate the predictive accuracy of a forecasting model.

MSE =

1
N

N
(cid:88)

i=1

ˆyi)2,

(yi

−

(12)

where N is number of instances in the testing set, yi and ˆyi are the ground truth and predicted
value, respectively.

• Statistical tests: For statistical interpretation of the signiﬁcance of the comparison results, we

apply the following two statistical methods in our empirical study.

– Wilcoxon signed-rank test [86]: It is a non-parametric statistical test that makes no as-
sumption about the underlying distribution of the data. In particular, the signiﬁcance level
is set to p = 0.05 in our experiments.

– A12 eﬀect size [87]: To ensure the resulted diﬀerences are not generated from a trivial eﬀect,
we apply A12 as the eﬀect size measure to evaluate the probability that one algorithm is
better than another. Speciﬁcally, given a pair of peer algorithms, A12 = 0.5 means they
are equivalent. A12 > 0.5 denotes that one is better for more than 50% of the times.
0.71
0.56
mean a medium and a large eﬀect size, respectively.

A12 < 0.64 indicates a small eﬀect size while 0.64

A12 < 0.71 and A12

≤

≤

≥

5 Results and Discussions

Our empirical study is driven by addressing the following three research questions (RQs).

• RQ1: Does BiLO-Auto-TSF/ML framework work for diﬀerent types of energy sources?

• RQ2: Does the meta-learning alone can help a base-learner handle small data challenge?

• RQ3: What is the added value of involving diﬀerent types of conﬁguration options in the

hyperparameter optimization of a few-shot learning pipeline?

• RQ4: What is the beneﬁts of the bi-level programming formulation in BiLO-Auto-TSF/ML?

• RQ5: What is the impact of the computational budget allocated to the upper-level optimization?

5.1 Performance Evaluation of the Eﬀectiveness of the Proposed BiLO-Auto-TSF/ML

Framework

5.1.1 Methods

As introduced in Section 4, by using NN, SVR, and LSTM as the base-learners, we come up with three in-
stances of our BiLO-Auto-TSF/ML framework, denoted as BiLO-Auto-TSF/ML-NN, BiLO-Auto-TSF/ML-SVR

8

Table 1: Comparison results of the MSE values obtained by diﬀerent models for forecasting tasks of
wind generation, PV generation and load demand.

NN
ML-NN
BiLO∗-NN
SVR
ML-SVR
BiLO∗-SVR
LSTM
ML-LSTM
BiLO∗-LSTM

NN
ML-NN
BiLO∗-NN
SVR
ML-SVR
BiLO∗-SVR
LSTM
ML-LSTM
BiLO∗-LSTM

NN
ML-NN
BiLO∗-NN
SVR
ML-SVR
BiLO∗-SVR
LSTM
ML-LSTM
BiLO∗-LSTM

ng = 1
1.041E-1(7.01E-3)†
5.922E-2(3.56E-3)†
5.248E-2(7.32E-5)†
1.082E-1(1.84E-3)†
6.017E-2(1.32E-4)†
5.217E-2(6.69E-5)†
7.684E-2(6.82E-3)†
5.247E-2(8.25E-4)†
4.125E-2(9.55E-5)

ng = 1
1.313E-1(2.42E-2)†
3.621E-2(1.25E-3)†
2.592E-2(3.72E-5)†
1.261E-1(3.42E-2)†
3.443E-2(3.11E-3)†
2.318E-2(1.72E-5)†
5.482E-2(1.01E-3)†
3.122E-2(6.23E-3)†
2.215E-2(6.54E-6)

ng = 1
7.518E-2(3.52E-3)†
6.338E-2(3.12E-3)†
5.231E-2(6.54E-5)†
6.945E-2(4.01E-3)†
6.229E-2(2.23E-3)†
5.317E-2(2.42E-5)†
6.853E-2(1.71E-3)†
4.828E-2(1.04E-3)†
4.254E-2(3.65E-6)

Wind generation
ng = 2
9.453E-2(5.82E-4)†
5.33E-2(5.71W-4)†
4.736E-2(2.52E-6)†
9.845E-2(8.12E-4)†
5.761E-2(4.74E-4)†
4.754E-2(2.62E-6)†
6.892E-2(9.72E-4)†
4.818E-2(7.78E-4)†
3.844E-2(6.87E-6)
PV generation
ng = 2
1.157E-1(1.92E-2)†
2.972E-2(4.82E-4)†
2.276E-2(1.26E-6)†
1.077E-1(5.67E-2)†
2.823E-2(7.25E-4)†
2.179E-2(3.85E-5)†
4.743E-2(7.72E-3)†
2.173E-2(8.45E-4)†
1.943E-2(7.25E-6)
Load demand
ng = 2
7.214E-2(2.67E-3)†
5.682E-2(6.45E-4)†
4.776E-2(9.53E-5)†
6.522E-2(6.84e-4)†
5.943E-2(3.67E-4)†
4.882E-2(6.76E-6)†
6.659E-2(4.58E-4)†
4.113E-2(5.75E-4)†
3.123E-2(5.72E-6)

ng = 10
7.845E-2(4.42E-4)†
3.925E-2(8.38E-5)†
3.624E-2(4.82E-6)†
7.919E-2(1.12E-4)†
4.233E-2(5.71E-5)†
3.546E-2(3.59E-6)†
5.622E-2(3.73E-4)†
3.232E-2(3.58E-5)†
2.476E-2(8.55E-6)

ng = 10
1.049E-1(1.15E-2)†
2.238E-2(7.48E-5)†
1.785E-2(5.34E-6)†
9.854E-2(4.39E-2)†
2.107E-2(4.65E-5)†
1.762E-2(5.36E-6)†
3.934E-2(8.25E-3)†
1.775E-2(5.58E-5)†
1.372E-2(8.66E-6)

ng = 10
6.278E-2(1.78E-4)†
5.017E-2(8.62E-5)†
3.890E-2(3.42E-6)†
6.116E-2(4.12E-4)†
5.334E-2(5.66E-5)†
3.631E-2(7.66E-6)†
4.547E-2(5.87E-4)†
3.282E-2(3.42E-6)†
2.524E-2(6.88E-6)

† indicates the better result (highlighted in bold face with a gray background) is of statistical signiﬁcance according
to the Wilcoxon’s rank-sum test at the 5% signiﬁcance level.

Figure 2: Comparison of the forecasting performance of diﬀerent models for wind generation, PV
generation and load demand, respectively. Note that BiLO∗ is short for BiLO-Auto-TSF/ML.

and BiLO-Auto-TSF/ML-LSTM respectively. As introduced in Section 4, the historical data of wind gen-
eration, PV generation, and load demand for a period of a week are used to constitute the training
dataset while the performance of diﬀerent forecasting models is validated on the island Lundy for a
period of 24 hours.

5.1.2 Results

From the comparison results shown in Table 1, we can see that the performance of all three base-
learners have been signiﬁcantly improved by being embedded into our proposed BiLO-Auto-TSF/ML
framework. To have a better visual interpretation of the performance comparison, we plot the fore-
casting results of 24 hours for wind generation, PV generation and load demand in Fig. 2. From these
trajectories, it is clear to see that the vanilla NN and SVR cannot make any meaningful forecasting at

9

369121518212400.30.60.91.21.5Time(hour)Generation(kW)WindgenerationBiLO⇤-NNNNBiLO⇤-SVRSVRBiLO⇤-LSTMLSTMGroundTruth36912151821240100200300400500Time(hour)Generation(kW)PVgeneration3691215182124120180240300Time(hour)Consumption(kW)Loaddemandall in all cases. This is anticipated as the training data at hand is extremely scarce so that neither NN
nor SVR can be appropriately trained. Although the vanilla LSTM can capture the variation of the time
series data as shown in Fig. 2, its prediction is largely oﬀset with regard to the ground truth. In con-
trast, by being equipped with our proposed BiLO-Auto-TSF/ML, the performance of all base-learners
have been signiﬁcantly improved. Especially for NN and SVR, after using few-shot learning and hyper-
parameter optimization, the performance of BiLO-Auto-TSF/ML-NN and BiLO-Auto-TSF/ML-SVR have
been leveled up to become comparable with BiLO-Auto-TSF/ML-LSTM.

Response to RQ1: From the observations in this experiment, it is clear to see that our proposed
BiLO-Auto-TSF/ML framework is able to signiﬁcantly improve the forecasting performance of a base-
learner for diﬀerent types of energy source. In particular, the adaptation to extremely scarce historical
data can be attributed to the few-shot learning in BiLO-Auto-TSF/ML.

5.2

Investigation of the Eﬀectiveness of Meta-Learning

5.2.1 Methods

The results in Section 5.1 have shown the overall superiority of our proposed BiLO-Auto-TSF/ML
framework for improving a base-learner for time series forecasting with extremely limited historical
data. To address RQ2, we directly apply the meta-learning approach introduced in Section 3.3 to
each of NN, SVR and LSTM models. The resulted forecasting models are denoted as ML-NN, ML-SVR and
ML-LSTM, respectively. Note that the hyperparameters associated with the base- and meta-learners
are ﬁxed a priori (e.g., we set the number of neurons in the NN to be 512, the kernel is set to be rbf,
and the number of cells in the LSTM to 640, three diﬀerent learning rates set as 0.01, 0.001, and 0.05,
respectively, and SGD is selected as the optimizer). In addition, we plan to investigate the inﬂuence of
the number of gradient descent steps (denoted as ng) for ﬁne-tuning the updated parameters ˆθ during
the meta training phase. Speciﬁcally, ng is set as 1, 2, and 10 in this experiment.

5.2.2 Results

From the comparison results shown in Table 1, we ﬁnd that the performance of the vanilla NN, SVR,
and LSTM can be improved by directly using the meta-learning.
In particular, it is worth noting
that the corresponding hyperparameters of ML-NN, ML-SVR, and ML-LSTM are ﬁxed a priori whereas
our proposed BiLO-Auto-TSF/ML framework is able to automatically search for an optimal few-shot
learning pipeline for the underlying base-learner. As the comparison results shown in Table 1, we ﬁnd
that the performance of ML-NN, ML-SVR, and ML-LSTM can be further improved under our proposed
BiLO-Auto-TSF/ML framework. To have a better investigation for the performance diﬀerence achieved
by using BiLO-Auto-TSF/ML framework against its vanilla version and the conventional meta-learning,
we show the statistical results of A12 in Fig. 3. From this result, it is clear to see that the better
performance achieved by using BiLO-Auto-TSF/ML framework are always classiﬁed to have a large
eﬀect size. This observation supports the importance of choosing appropriate hyperparameters in
time series forecasting for a given dataset.

Furthermore, let us look into the inﬂuence of the number of gradient descent steps. As the results
shown in Table 1, it is appreciated that the forecasting performance can be further improved by in-
creasing the number of gradient descent steps during the meta training phase. This is not diﬃcult to
understand as more gradient descent steps lead to a better ﬁne-tuned result. To have a visual illustra-
tion of the impact of ng, we plot the forecasting results of LSTM, ML-LSTM and BiLO-Auto-TSF/ML-LSTM
for diﬀerent energy sources in Figs. 4 to 6. From these trajectories, it is clear to see that the number
of gradient descent steps does not have any visible impact on the performance of the vanilla LSTM;
whereas it is able to ﬁne tune the performance of meta-learning.

10

Figure 3: Percentage of the large, medium, small, and equal A12 eﬀect size, respectively, when com-
paring our proposed BiLO-Auto-TSF/ML framework based models against their base-learners and the
one only using meta-learning.

Figure 4: Comparison of the forecasting performance of LSTM, ML-LSTM and BiLO-Auto-TSF/ML-LSTM
with diﬀerent number of gradient descent steps for the wind generation task.

Figure 5: Comparison of the forecasting performance of LSTM, ML-LSTM and BiLO-Auto-TSF/ML-LSTM
with diﬀerent number of gradient descent steps for the PV generation task.

Figure 6: Comparison of the forecasting performance of LSTM, ML-LSTM and BiLO-Auto-TSF/ML-LSTM
with diﬀerent number of gradient descent steps for the load demand task.

Response to RQ2: There are three takeaways from this experiment. First, meta-learning can en-
able a vanilla machine learning model to be capable of carrying out time series forecasting with
extremely limited historical data. Second, by using our proposed BiLO-Auto-TSF/ML framework, the
performance of the corresponding forecasting model can be further improved. This can be attributed to
the hyperparameter optimization that helps identiﬁes the most competitive few-shot learning pipeline.
Last but not the least, using more gradient descent steps can be beneﬁcial for ﬁne tuning during the
meta-training phase.

11

NNML-NNSVRML-SVRLSTMML-LSTM0%20%40%60%80%100%100%100%100%100%100%100%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%PercentageofA12eﬀectsizeLargeMediumSmallEqual369121518212400.30.60.91.21.5Time(hour)Generation(kW)LSTMng=1ng=2ng=10GroundTruth369121518212400.30.60.91.21.5Time(hour)Generation(kW)ML-LSTM369121518212400.30.60.91.21.5Time(hour)Generation(kW)BiLO-Auto-TSF/ML-LSTM36912151821240100200300400500Time(hour)Generation(kW)BiLO-Auto-TSF/ML-LSTM36912151821240100200300400500Time(hour)Generation(kW)LSTMng=1ng=2ng=10GroundTruth36912151821240100200300400500Time(hour)Generation(kW)ML-LSTM3691215182124120180240300Time(hour)Consumption(kW)ML-LSTM3691215182124120180240300Time(hour)Consumption(kW)LSTMng=1ng=2ng=10GroundTruth3691215182124120180240300Time(hour)Consumption(kW)BiLO-Auto-TSF/ML-LSTMFigure 7: Comparison of the forecasting performance of BiLO-Auto-TSF/ML-LSTM against the other
the variants BiLO-Auto-TSF/ML that involve diﬀerent number of hyperparameters in optimization,
represented as the index 1

i < 5 in the x-coordinate.

≤

Figure 8: Percentage of the large, medium, small, and equal A12 eﬀect size, respectively, when com-
paring our proposed BiLO-Auto-TSF/ML framework based models against Auto-Sklearn framework.

Table 2: Comparison results of MSE values obtained by Auto-Sklearn and BiLO-Auto-TSF/ML-LSTM

Data
Wind generation
PV generation
Load demand

MSE

Auto-Sklearn

BiLO
∗

-LSTM

5.143E-2(4.76E-6) 2.476E-2(8.55E-6)
1.745E-2(6.42E-6) 1.372E-2(8.66E-6)
3.628E-2(2.93E-6) 2.524E-2(6.88E-6)

5.3

Investigation of the Hyperparameters Optimization for Meta-Learning

5.3.1 Methods

i=1

(cid:0)5
i

(cid:1) diﬀerent variants by considering 1

As introduced in Section 4, there are more than one type of hyperparameters considered in our few-
shot learning pipeline. Another question is whether we need to optimize all those hyperparameters or
can we achieve comparable performance by only optimizing some of them? To address RQ3, we come
up with (cid:80)4
i < 5 hyperparameters in BiLO-Auto-TSF/ML.
Given the outstanding performance observed in Section 5.1.2, here we only consider LSTM as the base-
learner in this experiment without loss of generality. To address RQ4, we compare the performance of
BiLO-Auto-TSF/ML with Auto-Sklearn [88], one of the most popular tools in the automated machine
learning literature. Here we still only consider LSTM as the base-learner as before without loss of gen-
erality. Note that Auto-Sklearn does not apply a bilevel programming paradigm for hyperparameter
optimization.

≤

5.3.2 Results

≤

From the box-plots of the MSE values obtained by diﬀerent variants of BiLO-Auto-TSF/ML considering
i < 5 hyperparameters shown in Fig. 7, it is clear to see that our proposed BiLO-Auto-TSF/ML
1
constantly outperforms the other variants. It is interesting to note that the predictive accuracy can
be improved by involving more types of hyperparameters in the optimization. In other words, we can
envisage a further improvement of BiLO-Auto-TSF/ML by involving more conﬁguration options in the

12

1234Ours0.20.250.30.35Hyper-ParametersMSELoadDemand1234Ours0.20.250.30.35Hyper-ParametersMSEWindGeneration1234Ours0.10.150.20.25Hyper-ParametersMSEPVGenerationAuto-Sklearn0%20%40%60%80%100%100%0%0%0%PercentageofA12eﬀectsizeLargeMediumSmallEqualFigure 9: The trajectories of the MSE across 720 iterations in the MCTS of BiLO-Auto-TSF/ML-NN,
BiLO-Auto-TSF/ML-SVR and BiLO-Auto-TSF/ML-LSTM.

Figure 10: The trajectories of the CPU wall clock time across 720 iterations in the MCTS of
BiLO-Auto-TSF/ML-NN, BiLO-Auto-TSF/ML-SVR and BiLO-Auto-TSF/ML-LSTM.

few-shot learning pipeline.

According to the comparison results shown in Table 2, we can see that the performance of
BiLO-Auto-TSF/ML is constantly better than that of Auto-Sklearn in all three types of forecast-
ing tasks. Furthermore, as the A12 results shown in Fig. 8, it is clear to see that the better results
achieved by our proposed BiLO-Auto-TSF/ML is always classiﬁed to have a large eﬀect size. It is worth
noting that one of the key diﬀerences between BiLO-Auto-TSF/ML and Auto-Sklearn lies in the bi-
level programming perspective for coordinating the meta-learning and hyperparameter optimization
in an intertwined manner.
Response to RQ3: From the observations in this experiment, we can see that the performance of
a few-shot learning pipeline can be improved by involving more conﬁguration options in the hyperpa-
rameter optimization.

Response to RQ4: From the comparison results w.r.t. Auto-Sklearn, we conﬁrm the eﬀectiveness
of bi-level programming paradigm for handling meta-learning and hyperparameter optimization in a
concurrent manner.

5.4

Impact of Computational Budget at the Upper Level

5.4.1 Methods

In practice, it is not uncommon that the computational resource for time series forecasting, in par-
ticular the time budget, is limited. Given the iterative nature of MCTS, searching for the optimal
few-shot learning pipeline at the upper-level optimization by using a MCTS can be time consuming.
In this subsection, we are interested to investigate how is the number of iterations in MCTS (i.e., the
computational budget allocated to the upper-level optimization) related to the performance. To this
end, for each of the three instances of our proposed BiLO-Auto-TSF/ML framework, we keep a record
of the variation of the MSE across 720 iterations in MCTS for the forecasting tasks of wind generation,
PV generation and load demand, respectively.

5.4.2 Results

From the trajectories shown in Fig. 9, we can see that the overall MSE keeps on reducing with
the increase of the iterations in MCTS. However, for all three BiLO-Auto-TSF/ML instances, the
MSE trajectories does not show to be signiﬁcantly changed after around the 240-th iteration. This
suggests that we can reduce the number of iterations in MCTS without signiﬁcantly deteriorating the
performance of the identiﬁed few-shot learning pipeline. In addition, as the trajectories of CPU wall

13

08016024032040048056064072000.030.060.090.12IterationsMSEBiLO-Auto-TSF/ML-LSTM08016024032040048056064072000.030.060.090.120.15IterationsMSEBiLO-Auto-TSF/ML-NNWindgenerationPVgenerationLoaddemand08016024032040048056064072000.030.060.090.120.15IterationsMSEBiLO-Auto-TSF/ML-SVR080160240320400480560640720020406080IterationsTime(hour)BiLO-Auto-TSF/ML-LSTM080160240320400480560640720012345IterationsTime(hour)BiLO-Auto-TSF/ML-NNWindgenerationPVgenerationLoaddemand080160240320400480560640720012345IterationsTime(hour)BiLO-Auto-TSF/ML-SVRclock time shown in Fig. 10, we can see that the computational time can be signiﬁcantly reduced when
early terminating the upper-level optimization routine.

Response to RQ5: From the experiment in this subsection, we ﬁnd that the computational budget
allocated to the upper-level hyperparameter optimization of the few-shot learning pipeline can be
narrowed down without signiﬁcantly compromising the forecasting performance.

6 Conclusion

Short- and/or long-term time series forecasting of both energy generation and load demand have been
one of the key tools to guide the optimal decision-making for planning and operation of utility com-
panies without over/underestimating the capabilities of renewable energy infrastructures. Diﬀerent
from the traditional big data scenarios, one of the most challenging issues in time series renewable
energy forecasting in the real world is the short of historical data. This can render most prevalent
machine learning models ineﬀective. In addition, the performance of machine learning models are sen-
sitive to the choice of their corresponding hyperparameters w.r.t. the characteristics of the underlying
forecasting tasks. Bearing these considerations in mind, this paper developed a BiLO-Auto-TSF/ML
framework that automatically searches for a high-performance few-shot learning pipeline from a bi-
level programming perspective. More speciﬁcally, the meta-learning routine at the lower level helps
mitigate the small data challenges while the hyperparameter optimization at the upper level helps
search for the optimal conﬁguration options to achieve the peak few-shot learning performance. Ex-
tensive experiments fully demonstrate the eﬀectiveness of our proposed BiLO-Auto-TSF/ML framework
to signiﬁcantly boost the performance of three prevalent machine learning models for time series re-
newable energy forecasting with extremely limited historical data.

Acknowledgment

K. Li was supported by UKRI Future Leaders Fellowship (MR/S017062/1), Amazon Research Awards,
Royal Society International Exchange Scheme (IES/R2/212077), Alan Turing Fellowship, and EPSRC
(2404317).

References

[1] N. Amjady, F. Keynia, and H. Zareipour, “Short-term load forecast of microgrids by a new bilevel

prediction strategy,” IEEE Trans. Smart Grid, vol. 1, no. 3, pp. 286–294, 2010.

[2] M. N. Akhter, S. Mekhilef, H. Mokhlis, and N. M. Shah, “Review on forecasting of photo-
voltaic power generation based on machine learning and metaheuristic techniques,” IET Renew-
able Power Generation, vol. 13, no. 7, pp. 1009–1023, 2019.

[3] V. A. Natarajan and P. Karatampati, “Survey on renewable energy forecasting using diﬀerent
techniques,” in ICPEDC’20: Proc. of the 2020 International Conference on Power and Embedded
Drive Control, 2019, pp. 349–354.

[4] J. P. Lai, Y. M. Chang, C. H. Chen, and P. F. Pai, “A survey of machine learning models in

renewable energy predictions,” Appl. Sci., vol. 10, no. 17, 2020.

[5] C. Paoli, C. Voyant, M. Muselli, and M. L. Nivet, “Forecasting of preprocessed daily solar radia-

tion time series using neural networks,” Sol. Energy, vol. 84, no. 12, pp. 2146–2160, 2010.

[6] W. Kong, Z. Y. Dong, Y. Jia, D. J. Hill, Y. Xu, and Y. Zhang, “Short-term residential load
forecasting based on LSTM recurrent neural network,” IEEE Trans. Smart Grid, vol. 10, no. 1,
pp. 841–851, 2019.

14

[7] M. Majidpour, C. Qiu, C. P. Chu, R. Gadh, and H. R. Pota, “Fast prediction for sparse time
series: Demand forecast of EV charging stations for cell phone applications,” IEEE Trans. Ind.
Informatics, vol. 11, no. 1, pp. 242–250, 2015.

[8] B. J. Chen, M. W. Chang, and C. J. Lin, “Load forecasting using support vector machines: a
study on EUNITE competition 2001,” IEEE Trans. Power Systems, vol. 19, no. 4, pp. 1821–1830,
2004.

[9] P. Kou, F. Gao, and X. Guan, “Sparse online warped Gaussian process for wind power proba-

bilistic forecasting,” Applied Energy, vol. 108, pp. 410–428, 2013.

[10] H. McLarty, “How to reduce fossil fuel reliance in the small isles: A study into the potential of

inter-island connections,” Master’s thesis, University of Strathclyde, 2017.

[11] B. Zoph and Q. V. Le, “Neural architecture search with reinforcement learning,” in ICLR’2017:
Proc. of the 2017 International Conference on Learning Representations. OpenReview.net, 2017.

[12] J. Snell, K. Swersky, and R. S. Zemel, “Prototypical networks for few-shot learning,” in
NIPS’2017: Proc. of the 2017 Conference on Neural Information Processing Systems, 2017, pp.
4077–4087.

[13] J. M. Perez-Rua, X. Zhu, T. Hospedales, and T. Xiang, “Incremental few-shot object detection,”
in CVPR’2020: Proc. of the 2020 IEEE/CVF Conference on Computer Vision and Pattern
Recognition, 2020, pp. 13 843–13 852.

[14] L. Y. Gui, Y. X. Wang, D. Ramanan, and J. M. F. Moura, “Few-shot human motion prediction
via meta-learning,” in ECCV’2018: Proc. of the 2018 European Conference on Computer Vision,
vol. 11212, 2018, pp. 441 – 459.

[15] J. Gordon, J. Bronskill, M. Bauer, S. Nowozin, and R. Turner, “Meta-learning probabilistic
inference for prediction,” in ICLR’2019: Proc. of the 2019 International Conference on Learning
Representations. OpenReview.net, 2019.

[16] T. C. Wang, M. Y. Liu, A. Tao, G. Liu, J. Kautz, and B. Catanzaro, “Few-shot video-to-
video synthesis,” in NIPS’2019: Proc. of the 2019 Conference on Neural Information Processing
Systems, 2019, pp. 5014–5025.

[17] J. Vanschoren, “Meta-learning: A survey,” CoRR, vol. abs/1810.03548, 2018. [Online]. Available:

http://arxiv.org/abs/1810.03548

[18] C. Browne, E. J. Powley, D. Whitehouse, S. M. Lucas, P. I. Cowling, P. Rohlfshagen, S. Tavener,
D. P. Liebana, S. Samothrakis, and S. Colton, “A survey of Monte Carlo tree search methods,”
IEEE Trans. Comput. Intell. AI Games, vol. 4, no. 1, pp. 1–43, 2012.

[19] C. Finn, P. Abbeel, and S. Levine, “Model-agnostic meta-learning for fast adaptation of deep
networks,” in ICML’2017: Proc. of the 2017 International Conference on Machine Learning,
vol. 70. PMLR, 2017, pp. 1126–1135.

[20] J. Zheng, C. Xu, Z. Zhang, and X. Li, “Electric load forecasting in smart grids using long-
short-term-memory based recurrent neural network,” in CISS’2017: Proc. of the 2017 Annual
Conference on Information Sciences and Systems, 2017, pp. 1–6.

[21] J. Wang, F. Liu, Y. Song, and J. Zhao, “A novel model: Dynamic choice artiﬁcial neural network
(DCANN) for an electricity price forecasting system,” Appl. Soft Comput., vol. 48, pp. 281–297,
2016.

[22] Y. Li and J. Wang, “The load forecasting model based on Bayes-GRNN,” J. Softw., vol. 7, no. 6,

pp. 1273–1280, 2012.

15

[23] J. Buitrago and S. Asfour, “Short-term forecasting of electric loads using nonlinear autoregressive
artiﬁcial neural networks with exogenous vector inputs,” Energies, vol. 10, no. 1, pp. 1–24, 2017.

[24] A. Arif, N. Javaid, M. Anwar, A. Naeem, H. Gul, and S. Fareed, “Electricity load and price
forecasting using machine learning algorithms in smart grid: A survey,” in AINA’2020: Proc. of
the 2020 International Conference on Advanced Information Networking and Applications, vol.
1150. Springer, 2020, pp. 471–483.

[25] H. Shi, M. Xu, and R. Li, “Deep learning for household load forecasting—A novel pooling deep

RNN,” IEEE Trans. Smart Grid, vol. 9, no. 5, pp. 5271–5280, 2018.

[26] J. Moon, S. Jung, J. Rew, S. Rho, and E. Hwang, “Combination of short-term load forecasting
models based on a stacking ensemble approach,” Energy and Buildings, vol. 216, p. 109921, 2020.

[27] H. H. Aly, “A proposed intelligent short-term load forecasting hybrid models of ANN, WNN and
KF based on clustering techniques for smart grid,” Electric Power Systems Research, vol. 182, p.
106191, 2020.

[28] S. R. Khuntia, J. L. Rueda, and M. A. van der Meijden, “Forecasting the load of electrical
power systems in mid- and long-term horizons: a review,” IET Generation, Transmission &
Distribution, vol. 10, pp. 3971–3977(6), 2016.

[29] W. Jiang, H. Tang, L. Wu, H. Huang, and H. Qi, “Parallel processing of probabilistic models-
based power supply unit mid-term load forecasting with apache spark,” IEEE Access, vol. 7, pp.
7588–7598, 2019.

[30] G. Dudek, P. Pelka, and S. Smyl, “A hybrid residual dilated LSTM and exponential smoothing
model for mid-term electric load forecasting,” IEEE Trans. Neural Networks Learn. Syst, pp.
1–13, 2021.

[31] R. K. Agrawa, F. Muchahary, and M. M. Tripathi, “Long term load forecasting with hourly
predictions based on long-short-term-memory networks,” in TPEC’2020: Proc. of the 2020 IEEE
Texas Power and Energy Conference, 2018, pp. 1–6.

[32] T. Hospedales, A. Antoniou, P. Micaelli, and A. Storkey, “Meta-learning in neural networks: A

survey,” CoRR, vol. abs/2004.05439, 2020.

[33] Z. Li, F. Zhou, F. Chen, and H. Li, “Meta-SGD: Learning to learn quickly for few shot learning,”

CoRR, vol. abs/1707.09835, 2017.

[34] A. Antoniou, H. Edwards, and A. J. Storkey, “How to train your MAML,” CoRR, vol.

abs/1810.09502, 2018.

[35] A. A. Rusu, D. Rao, J. Sygnowski, O. Vinyals, R. Pascanu, S. Osindero, and R. Hadsell, “Meta-

learning with latent embedding optimization,” CoRR, vol. abs/1807.05960, 2018.

[36] L. Franceschi, P. Frasconi, S. Salzo, R. Grazzi, and M. Pontil, “Bilevel programming for hyper-

parameter optimization and meta-learning,” CoRR, vol. abs/1806.04910, 2018.

[37] S. Baik, M. Choi, J. Choi, H. Kim, and K. M. Lee, CoRR, vol. abs/2011.00209, 2020.

[38] P. Auer, “Using conﬁdence bounds for exploitation-exploration trade-oﬀs,” J. Mach. Learn. Res.,

vol. 3, pp. 397–422, 2002.

[39] S. Gelly and D. Silver, “Monte-Carlo tree search and rapid action value estimation in computer

go,” Artif. Intell., vol. 175, no. 11, pp. 1856–1875, 2011.

[40] D. Auger, A. Cou¨etoux, and O. Teytaud, “Continuous upper conﬁdence trees with polynomial
exploration – consistency,” in PKDD’2013: Proc. of the 2013 Machine Learning and Knowledge
Discovery in Databases -European Conference, vol. 8188. Springer, 2013, pp. 194–209.

16

[41] R. Chen, K. Li, and X. Yao, “Dynamic multiobjectives optimization with a changing number of

objectives,” IEEE Trans. Evol. Comput., vol. 22, no. 1, pp. 157–171, 2018.

[42] J. Zou, C. Ji, S. Yang, Y. Zhang, J. Zheng, and K. Li, “A knee-point-based evolutionary algo-
rithm using weighted subpopulation for many-objective optimization,” Swarm and Evolutionary
Computation, vol. 47, pp. 33–43, 2019.

[43] K. Li, J. Zheng, C. Zhou, and H. Lv, “An improved diﬀerential evolution for multi-objective
optimization,” in CSIE’09: Proc. of 2009 WRI World Congress on Computer Science and Infor-
mation Engineering, 2009, pp. 825–830.

[44] J. Billingsley, K. Li, W. Miao, G. Min, and N. Georgalas, “A formal model for multi-objective
optimisation of network function virtualisation placement,” in EMO’19: Proc. of the 10th Inter-
national Conference Evolutionary Multi-Criterion Optimization, 2019, pp. 529–540.

[45] K. Li, J. Zheng, M. Li, C. Zhou, and H. Lv, “A novel algorithm for non-dominated hypervolume-
based multiobjective optimization,” in SMC’09: Proc. of 2009 the IEEE International Conference
on Systems, Man and Cybernetics, 2009, pp. 5220–5226.

[46] K. Li, “Progressive preference learning: Proof-of-principle results in MOEA/D,” in EMO’19:
Proc. of the 10th International Conference Evolutionary Multi-Criterion Optimization, 2019, pp.
631–643.

[47] K. Li and S. Kwong, “A general framework for evolutionary multiobjective optimization via

manifold learning,” Neurocomputing, vol. 146, pp. 65–74, 2014.

[48] K. Li, ´A. Fialho, and S. Kwong, “Multi-objective diﬀerential evolution with adaptive control of
parameters and operators,” in LION5: Proc. of the 5th International Conference on Learning
and Intelligent Optimization, 2011, pp. 473–487.

[49] K. Li, S. Kwong, R. Wang, K. Tang, and K. Man, “Learning paradigm based on jumping genes:
A general framework for enhancing exploration in evolutionary multiobjective optimization,” Inf.
Sci., vol. 226, pp. 1–22, 2013.

[50] J. Cao, S. Kwong, R. Wang, and K. Li, “A weighted voting method using minimum square error
based on extreme learning machine,” in ICMLC’12: Proc. of the 2012 International Conference
on Machine Learning and Cybernetics, 2012, pp. 411–414.

[51] ——, “AN indicator-based selection multi-objective evolutionary algorithm with preference for
multi-class ensemble,” in ICMLC’14: Proc. of the 2014 International Conference on Machine
Learning and Cybernetics, 2014, pp. 147–152.

[52] K. Li, K. Deb, Q. Zhang, and Q. Zhang, “Eﬃcient nondomination level update method for
steady-state evolutionary multiobjective optimization,” IEEE Trans. Cybernetics, vol. 47, no. 9,
pp. 2838–2849, 2017.

[53] K. Li, S. Kwong, and K. Deb, “A dual-population paradigm for evolutionary multiobjective

optimization,” Inf. Sci., vol. 309, pp. 50–72, 2015.

[54] K. Li, S. Kwong, R. Wang, J. Cao, and I. J. Rudas, “Multi-objective diﬀerential evolution with
self-navigation,” in SMC’12: Proc. of the 2012 IEEE International Conference on Systems, Man,
and Cybernetics, 2012, pp. 508–513.

[55] K. Li, R. Wang, S. Kwong, and J. Cao, “Evolving extreme learning machine paradigm with adap-
tive operator selection and parameter control,” International Journal of Uncertainty, Fuzziness
and Knowledge-Based Systems, vol. 21, pp. 143–154, 2013.

[56] J. Cao, S. Kwong, R. Wang, X. Li, K. Li, and X. Kong, “Class-speciﬁc soft voting based multiple

extreme learning machines ensemble,” Neurocomputing, vol. 149, pp. 275–284, 2015.

17

[57] K. Li, K. Deb, and X. Yao, “R-metric: Evaluating the performance of preference-based evolution-
ary multiobjective optimization using reference points,” IEEE Trans. Evolutionary Computation,
vol. 22, no. 6, pp. 821–835, 2018.

[58] M. Wu, S. Kwong, Q. Zhang, K. Li, R. Wang, and B. Liu, “Two-level stable matching-based
selection in MOEA/D,” in SMC’15: Proc. of the 2015 IEEE International Conference on Systems,
Man, and Cybernetics, 2015, pp. 1720–1725.

[59] K. Li, S. Kwong, J. Cao, M. Li, J. Zheng, and R. Shen, “Achieving balance between proximity
and diversity in multi-objective evolutionary algorithm,” Inf. Sci., vol. 182, no. 1, pp. 220–242,
2012.

[60] K. Li, K. Deb, O. T. Altin¨oz, and X. Yao, “Empirical investigations of reference point based
methods when facing a massively large number of objectives: First results,” in EMO’17: Proc. of
the 9th International Conference Evolutionary Multi-Criterion Optimization, 2017, pp. 390–405.

[61] K. Li, K. Deb, and Q. Zhang, “Evolutionary multiobjective optimization with hybrid selection
principles,” in CEC’15: Proc. of the 2015 IEEE Congress on Evolutionary Computation, 2015,
pp. 900–907.

[62] K. Li, Z. Xiang, and K. C. Tan, “Which surrogate works for empirical performance modelling?
A case study with diﬀerential evolution,” in CEC’19: Proc. of the 2019 IEEE Congress on
Evolutionary Computation, 2019, pp. 1988–1995.

[63] H. Gao, H. Nie, and K. Li, “Visualisation of pareto front approximation: A short survey and em-
pirical comparisons,” in CEC’19: Proc. of the 2019 IEEE Congress on Evolutionary Computation,
2019, pp. 1750–1757.

[64] M. Liu, K. Li, and T. Chen, “Security testing of web applications: a search-based approach for de-
tecting SQL injection vulnerabilities,” in GECCO’19: Proc. of the 2019 Genetic and Evolutionary
Computation Conference Companion, 2019, pp. 417–418.

[65] K. Li and Q. Zhang, “Decomposition multi-objective optimisation: current developments and
future opportunities,” in GECCO’19: Proc. of the 2019 Genetic and Evolutionary Computation
Conference Companion, 2019, pp. 1002–1031.

[66] S. Kumar, R. Bahsoon, T. Chen, K. Li, and R. Buyya, “Multi-tenant cloud service composition
using evolutionary optimization,” in ICPADS’18: Proc. of the 24th IEEE International Confer-
ence on Parallel and Distributed Systems, 2018, pp. 972–979.

[67] J. Cao, H. Wang, S. Kwong, and K. Li, “Combining interpretable fuzzy rule-based classiﬁers
via multi-objective hierarchical evolutionary algorithm,” in SMC’11: Proc. of the 2011 IEEE
International Conference on Systems, Man and Cybernetics.

IEEE, 2011, pp. 1771–1776.

[68] K. Li, Z. Xiang, T. Chen, S. Wang, and K. C. Tan, “Understanding the automated parameter
optimization on transfer learning for cross-project defect prediction: an empirical study,” in
ICSE’20: Proc. of the 42nd International Conference on Software Engineering. ACM, 2020, pp.
566–577.

[69] M. Liu, K. Li, and T. Chen, “DeepSQLi: deep semantic learning for testing SQL injection,” in
ISSTA’20: Proc. of the 29th ACM SIGSOFT International Symposium on Software Testing and
Analysis. ACM, 2020, pp. 286–297.

[70] K. Li, Z. Xiang, T. Chen, and K. C. Tan, “BiLO-CPDP: Bi-level programming for automated
model discovery in cross-project defect prediction,” in ASE’20: Proc. of the 35th IEEE/ACM
International Conference on Automated Software Engineering.

IEEE, 2020, pp. 573–584.

[71] R. Wang, S. Ye, K. Li, and S. Kwong, “Bayesian network based label correlation analysis for

multi-label classiﬁer chain,” Inf. Sci., vol. 554, pp. 256–275, 2021.

18

[72] X. Shan and K. Li, “An improved two-archive evolutionary algorithm for constrained multi-
objective optimization,” in EMO’21: Proc. of the 11th International Conference on Evolutionary
Multicriteria Optimization, ser. Lecture Notes in Computer Science, vol. 12654. Springer, 2021,
pp. 235–247.

[73] G. Lai, M. Liao, and K. Li, “Empirical studies on the role of the decision maker in interactive
evolutionary multi-objective optimization,” in CEC’21: Proc. of the 2021 IEEE Congress on
Evolutionary Computation.

IEEE, 2021, pp. 185–192.

[74] L. Li, Q. Lin, K. Li, and Z. Ming, “Vertical distance-based clonal selection mechanism for the

multiobjective immune algorithm,” Swarm Evol. Comput., vol. 63, p. 100886, 2021.

[75] M. Wu, S. Kwong, Y. Jia, K. Li, and Q. Zhang, “Adaptive weights generation for decomposition-
based multi-objective optimization using gaussian process regression,” in GECCO’17: Proc. of
the 2017 Genetic and Evolutionary Computation Conference. ACM, 2017, pp. 641–648.

[76] K. Li, R. Chen, D. A. Savic, and X. Yao, “Interactive decomposition multiobjective optimization
via progressively learned value functions,” IEEE Trans. Fuzzy Syst., vol. 27, no. 5, pp. 849–860,
2019.

[77] K. Li, M. Liao, K. Deb, G. Min, and X. Yao, “Does preference always help? A holistic study on
preference-based evolutionary multiobjective optimization using reference points,” IEEE Trans.
Evol. Comput., vol. 24, no. 6, pp. 1078–1096, 2020.

[78] M. Wu, K. Li, S. Kwong, and Q. Zhang, “Evolutionary many-objective optimization based on

adversarial decomposition,” IEEE Trans. Cybern., vol. 50, no. 2, pp. 753–764, 2020.

[79] G. Pruvost, B. Derbel, A. Liefooghe, K. Li, and Q. Zhang, “On the combined impact of popu-
lation size and sub-problem selection in MOEA/D,” in EvoCOP’20: Proc. of the 20th European
Conference on Evolutionary Computation in Combinatorial Optimization, ser. Lecture Notes in
Computer Science, vol. 12102. Springer, 2020, pp. 131–147.

[80] G. S. Matthew, O. W. Fitch-Roy, P. M. Connor, B. Woodman, P. Thies, E. Hussain, H. Mah-
mood, M. Abusara, X. Yan, and J. Hardwick, “ICE report t2.1.2 - ICE general methodology,”
INTERREG, University of Exeter, Tech. Rep., 2018.

[81] S. Amari, “Backpropagation and stochastic gradient descent method,” Neurocomputing, vol. 5,

no. 4, pp. 185–196, 1993.

[82] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,” in ICLR’2015: Proc.

of the 2015 International Conference on Learning Representations, 2015.

[83] Y. Saadna, A. A. Boudhir, and M. B. Ahmed, “An analysis of resnet50 model and rmsprop
optimizer for education platform using an intelligent chatbot system,” in NISS’2021: Proc. of the
2021 Networking, Intelligent Systems and Security, vol. 237. Springer, 2021, pp. 577–590.

[84] M. D. Zeiler, “ADADELTA: an adaptive learning rate method,” CoRR, vol. abs/1212.5701, 2012.

[85] C. Traor´e and E. Pauwels, “Sequential convergence of AdaGrad algorithm for smooth convex

optimization,” CoRR, vol. abs/2011.12341, 2020.

[86] F. Wilcoxon, Individual Comparisons by Ranking Methods. Springer New York, 1992, pp. 196–

202.

[87] K. Li and R. Chen, “Batched data-driven evolutionary multi-objective optimization based on

manifold interpolation,” CoRR, vol. abs/2109.05639, 2021.

[88] M. Feurer, K. Eggensperger, S. Falkner, M. Lindauer, and F. Hutter, “Auto-Sklearn 2.0: Hands-

free AutoML via meta-learning,” CoRR, vol. abs/2007.04074, 2020.

19

