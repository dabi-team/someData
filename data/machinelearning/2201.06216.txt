2
2
0
2

n
a
J

7
1

]

C
O
.
h
t
a
m

[

1
v
6
1
2
6
0
.
1
0
2
2
:
v
i
X
r
a

Learning to Reformulate for Linear Programming

Xijun Li1,2 Qingyu Qu2 Fangzhou Zhu2 Jia Zeng2 Mingxuan Yuan2 Kun Mao3 and Jie Wang1
1MIRA Lab, USTC
2Huawei Noah’s Ark Lab
3Huawei Cloud Co.
{xijun.li, quqingyu, zhufangzhou, Zeng.Jia, Yuan.Mingxuan, maokun}@huawei.com,
jiewangx@ustc.edu.cn

Abstract

It has been veriﬁed that the linear programming
(LP) is able to formulate many real-life optimiza-
tion problems, which can obtain the optimum by
resorting to corresponding solvers such as OptVerse,
Gurobi and CPLEX. In the past decades, a serial of
traditional operation research algorithms have been
proposed to obtain the optimum of a given LP in
a fewer solving time. Recently, there is a trend of
using machine learning (ML) techniques to improve
the performance of above solvers. However, almost
no previous work takes advantage of ML techniques
to improve the performance of solver from the front
end, i.e., the modeling (or formulation).
In this
paper, we are the ﬁrst to propose a reinforcement
learning-based reformulation method for LP to im-
prove the performance of solving process. Using an
open-source solver COIN-OR LP (CLP) as an envi-
ronment, we implement the proposed method over
two public research LP datasets and one large-scale
LP dataset collected from practical production plan-
ning scenario. The evaluation results suggest that
the proposed method can effectively reduce both the
solving iteration number (25%↓) and the solving
time (15%↓) over above datasets in average, com-
pared to directly solving the original LP instances.

1 Introduction
Through many years of practices, it has been veriﬁed that the
mathematical programming (LP) [Ge et al., 2021] is capable of
formulating real-life optimization problems such as planning,
scheduling, resource allocation, etc. The LP can obtain the
optimum by resorting to corresponding solvers, such as Opt-
Verse [Huawei, 2021], Gurobi [Gurobi, 2021], CPLEX [IBM,
2021], SCIP [ZIB, 2021], etc, which provides the optimal so-
lutions to those real-life optimization problems. Government
and business corporation beneﬁt a lot from the practice of
mathematical programmings in their daily operations [Mavro-
tas and Makryvelios, 2021], which thus constantly draws in-
terests from both academics and industry. There are many
kinds of mathematical programmings, including linear pro-
gramming (LP), mixed integer programming (MIP), quadratic
programming (QP). In past decades, a collection of classical

algorithms (such as simplex [Dantzig, 1987], barrier [Ander-
sen et al., 2003], branch and bound [Wolsey, 2007], etc.) have
been proposed to solve above mathematical programmings and
meanwhile they have been implemented and been integrated in
above well-established solvers. Amongst these mathematical
programmings, LP is the foundation. Thus many performance
improvement of solver can be gained from the research of LP.
Recently, there is a trend of using machine learning (ML)
techniques to improve traditional combinatorial optimization
solvers [NeurIPS 2021 Competition, 2021] on speciﬁc prob-
lem distributions. Because in real-life scenarios, a practitioner
repeatedly solves problem instances from a speciﬁc distri-
bution, with redundant patterns and characteristics. For ex-
ample, managing a large-scale energy distribution network
requires solving very similar optimization problems on a daily
basis, with a ﬁxed power grid structure while only the de-
mand changes over time. This change of demand is hard to
capture by hand-engineered expert rules, and ML-enhanced
approaches offer a possible solution to detect typical patterns
in the demand history. A serial of machine learning-based ap-
proaches have been proposed to improve the performance
of above solvers [Khalil et al., 2016; Gasse et al., 2019;
Gupta et al., 2020; Nair et al., 2020].

It should be noted that most of above ML-enhanced ap-
proaches focus on using ML techniques to replace some key
components within solver. Almost no previous work has
thought of accelerating the solving of solver from the most
front end, i.e., the modeling from a real-life optimization
problem to a mathematical programming. Because we uncon-
sciously think that the human experts are totally responsible for
modeling and formulation for real-life optimization problems.
The expert-designed formulation is deemed as the ‘perfect’
mathematical programming model and sent to the solver to get
the optimal solution, which never thinks of how formulation
could affect the performance of corresponding solver. But
from some optimization theories and empirical studies [Ge
et al., 2021], the formulation (such as the ordering of vari-
ables and constraints) is highly related to both the accuracy
and solving speed of solver, which leaves the huge space for
improving the performance of solvers through reformulating
the mathematical programming.

In this paper, from the perspective of reformulation, we
propose a machine learning-based automatic reformulation
method for LP, in order to accelerate the solving, where a graph

 
 
 
 
 
 
convolutional neural network (GCNN) [Gasse et al., 2019;
Nair et al., 2020] is ﬁrstly utilized to capture the patterns
and characteristics of variables in the original LP. Then the
pattern of variables is sent to a pointer network (PN) [Bello
et al., 2016] from which we can get a new ordering. The new
ordering will change the formulation of original LP but still
remain its mathematical properties. The parameter of above
two neural networks is trained via reinforcement learning (RL).
The contributions of this work are summarized as follows:

• To our best knowledge, we are the ﬁrst to propose a
machine learning-based reformulation method for linear
programming and implement the method using an open
source software COIN-OR LP (CLP) as back-end solver.

• Extensive experiments have been performed over two
public research LP datasets and one large-scale LP
dataset collected from practical production planning sce-
nario. The results suggest that the proposed method
can effectively reduce both the solving iteration number
(25%↓) and the solving time (15%↓) in average, com-
pared to directly solving the original LP instances.

• Our proposed method does not restrict the type of solver,
which can be implemented over any solver as long as it
has corresponding interfaces. Thus the proposed method
is a general way to improve the performance of solver.

2 Background

2.1 Linear programming and its initial basis
A linear program is an optimization problem of the form

cT x,

min
x

s.t. Ax ≤ b, x ≥ 0

(1)

where c ∈ Rn is the objective coefﬁcient vector; A ∈ Rm×n is
the constraint coefﬁcient matrix; and b ∈ Rm is the constraint
right-hand-side vector. x ∈ Rn is the variable vector; Usually
A is with full row rank. If the condition cannot be met, appro-
priate unit columns can be added. Note that formulation (1) is
the standard form of linear programming. Other form of linear
programming can convert to the standard form.

Suppose that S is a subset of columns of A. We use AS
denote the m × |S| submatrix that contains the columns of
S. If S is with an order, then the columns of AS are taken to
appear in that order. Similarly, if d is a vector and S is a subset
of row indices, then dS is the corresponding subvector. Again,
if S is ordered, the rows of dS are also subject to that order.
With above concepts, the basis can be deﬁned as follows:

Deﬁnition 1. A basis is a pair (B, N ) which splits the vari-
ables (columns): B = (B1, ..., Bm) ⊆ {1, ..., n} is an or-
dered subset of column indices such that B = AB is nonsin-
gular. B is called the basis indices and B is the basis matrix.
The variables (columns) xj(j ∈ B) are called the basic vari-
ables. The remaining variables are nonbasic variables. We
use N = {j|j /∈ B} denote the set of indices of nonbasic
variables.

Corresponding to each basis, there exists a basic solution x

Figure 1: Bipartite graph representation of linear programming

xB = B−1(b − AN xN ) = B−1b
(3)
The basis B is called feasible if xB ≥ 0. The simplex method
requires a feasible basis as inputs. If no such basis exists, it
usually resorts to solving a auxiliary problem to get a feasible
initial basis. Then it continues to solve the original problem
with the initial basis. There are three classical methods to
construct the initial basis, i.e., all "artiﬁcial" basis, the feasible
slack and slack basis. Reader of interests can refer to classi-
cal textbook [Maros, 2002] on linear programming. Besides,
inside commercial solver CPLEX, [Bixby, 1992] proposed a
basis construction method that effectively reduces the iteration
number of solving over a class of problems. Speciﬁcally, they
ﬁrst construct a preference order for all variables including
slack variables. The preference order is obtained via compar-
ing the corresponding objective and constraint coefﬁcients of
variables. According to the preference order, m variables are
selected to construct the basis. However, there is no certain
claim what is the best preference order in selection of initial
basic variables.

2.2 Bipartite graph representation of linear

programming

The relation between variables and constraints of LP can be
represented by a bipartite graph, where a set of n nodes in the
graph represents the n variables contained in the LP and the
other set of m nodes correspond to the m constraints of the
LP. The edge between a variable node and a constraint node
represents the corresponding variable shows in the constraint.
The number of edges indicates the number of non-zeros (NNZ)
in the constraint matrix A. An example of the bipartite graph
is given in Figure 1. Other information such as the objective
coefﬁcients and constraint bounds, etc. can also be added into
the bipartite graph. In this way, the lossless representation of
the LP can be sent as an input to graph neural networks. Many
previous works adopt the representation method or related one
to extract high-order embedding information of the original
problems, such as Gasses et. al. and Nair et. al. done for mixed
integer problem [Nair et al., 2020; Gasse et al., 2019], and
Selsam et. al. done for Boolean Satisﬁability problem [Selsam
et al., 2018].

2.3 Pointer network for combinatorial

optimization problem

given by

xN = 0

Combinatorial optimization problems such as Traveling Sales-
man Problem (TSP), Convex Hull problem, Set Cover problem,

(2)

etc. play a fundamental role in the development of computer
science, which have many applications in manufacturing, plan-
ning, genetic engineering, etc. Many kinds of algorithms
have been proposed to solve above combinatorial optimiza-
tion problem, including dynamic programming [Sumita et
al., 2017; Chauhan et al., 2012], cutting plane [Applegate
et al., 2003], local search [Zhang and Looks, 2005] and
neural network-based search method [Vinyals et al., 2015;
Bello et al., 2016]. In recent years, the application of neural
networks on combinatorial optimization problem has drawn
much more attention than other methods [Vinyals et al., 2015;
Bello et al., 2016], especially after the proposal of Pointer
Network (PN). The pointer network is a sequence-to-sequence
model [Vinyals et al., 2015] originating from the domain of
natural language processing. It can learn the conditional prob-
ability of an output sequence of elements that are discrete sym-
bols corresponding to positions in an input sequence, which
dedicates to dealing with variable size of output dictionary.
Speciﬁcally, the pointer network is comprised of two recur-
rent neural networks (RNN), encoder and decoder. The entire
sequence-to-sequence output process is divides as two phases,
encoding and decoding. In the encoding phase, the encoder
reads initial representation (raw data or linear transformation
of raw data) of si of input sequence S = {s1, s2, ..., sn}, one
at a time step, and transform them into a sequence of latent
memory states {enci}n
i=1. In the decoding phase, the decoder
network also maintains a latent memory states {deci}n
i=1.
Then it utilizes the attention mechanism [Vinyals et al., 2015]
over {enci}n
i=1 to produce a probability distri-
bution over si(i = 1, ..., n). Then one si is pointed and output
according to the probability distribution and its corresponding
decoding embedding deci is sent as input to the next decoder
step. On the TSP, [Vinyals et al., 2015] trained above neural
network in a supervised manner to predict the sequence of
visited cities. [Bello et al., 2016] trained the network with
reinforcement learning method, using the negative tour length
as the reward signal.

i=1 and {deci}n

3 Proposed Solution

3.1 Overview

In this section, our reformulation method is presented. We
ﬁrstly introduce how we represent a given linear programming
and send it as input into a graph neural network. Then the em-
bedding output by the graph neural network is aggregated with
a given variable splittings and passed into a pointer network
to get a permutation of variables. The permutation is utilized
to reformulate the original linear programming, in order to
accelerate the solving process of corresponding solver. The
entire process is summarized in Figure 2.

3.2 Representation
We adopt the same method as done in [Gasse et al., 2019]
to represent a given linear programming as a bipartite graph
(G, C, E, V). Speciﬁcally, in the bipartite graph, C ∈ Rm×c
corresponds to the features of the constraints in the LP; V ∈
Rn×d denotes the features of the variables in the LP; and an
edge eij ∈ E between a constraint node i and a variable node
j if the corresponding coefﬁcient Ai,j (cid:54)= 0. For simplicity,

we just attach the value of Ai,j to the corresponding edge eij.
Readers of interest can refer to the used features in Appendix.
Next, the bipartite graph representation of LP is sent as input
into a two-interleaved graph convolutional neural network
(GCNN) [Gasse et al., 2019]. In detail, the graph convolution
is broken into two successive passes, one from variable side to
constraint side, and one from constraint side to variable side,
which can be formulated as follows:

c(l+1)
i ← fC


c(l)

i

,

(i,j)∈E
(cid:88)

gC(c(l)

i

j



, v(l)

j , eij)

 ,

v(l+1)
j ← fV


v(l)
j ,

(i,j)∈E
(cid:88)

gV(c(l)

i

i



, v(l)

j , eij)



(4)

(5)

where fC, gC, fV and gV are 2-layer perceptrons with prenorm
layer. We adopt the ReLU as the activation function. And l
represents the number of times that we perform the convolu-
tion. In our implementation, we set l = 2. The parameters
involved in above GCNN are denoted by θG.

3.3 Aggregation
The embedding information of variables can be obtained using
the GCNN. However, we perform an aggregation operation
over the embedding rather than directly sending the them to
pointer networks. There are several reasons why we need to
perform aggregation. First, the learning capability of pointer
network is limited. According to evaluation report of previous
work [Vinyals et al., 2015; Bello et al., 2016], the pointer
network can achieve closely optimal results with up to 100
nodes. It performs signiﬁcantly worse when the number of
nodes exceeds 1000. Second, considering all possible permu-
tations of variables of a given LP is intractable. The number
of variables of LP that comes from practical scenario can
easily exceeds 100. Third, many LPs have its own special
structure, which can be exploited to split the variables into
several clusters in advance. Many optimization methods such
as Benders decomposition [Mavrotas and Makryvelios, 2021;
Gharaei et al., 2020] have exploited the structure of LP model
to accelerate the searching process. Considering all above, we
perform the aggregation using the following steps:
Splitting. For a given LP as shown in (1), the variables
xi(i = 1, ..., n) are split up into k disjoint clusters Cj =
{xj1, xj2, ..., xj|Cj |}(j = 1, ..., k). Note that the ordering
of variables within one cluster is subject to the ordering of
variables in the original LP. The clustering method is not re-
stricted here. It could be speciﬁed by human experts or using
hyper-graph decomposition method [Manieri et al., 2021].
Pooling function. With above splitting clusters Cj(j =
1, ..., k) and variable embedding vi(i = 1, ..., n), we perform
the aggregation for each cluster via:

Σj = P({vi|xi ∈ Cj})

(6)

where P is a pooling function which could be maximum,
minimum, average or other appropriate functions. We still do
not restrict the kind of the pooling function here. Σj ∈ Rd
can be understood the embedding of splitting cluster.

Figure 2: Overview of our proposed machine learning-based automatic reformulation method, which can be summarized in three steps: a)
the input LP instance is represented by a bipartite graph and then the embedding of variables of the LP instance is obtained via a graph
neural network; b) the embedding of variables will be aggregated with a given splitting cluster of variables and c) taking as input the previous
embeddings, a pointer network is used to output a new ordering of variables, i.e., the reformulation of the original LP instance.

3.4 Permutation
Given an LP lp, we aim to reformulate the LP by reordering
the variables of the original LP, in order to improve the solving
performance of corresponding solver. More speciﬁcally, given
a sequence of splitting clusters {Cj}k
j=1 of lp, we would like
to ﬁnd a permutation π of these clusters to reformulate the
original LP. The reformulation is achieved by that 1) between
splitting clusters, the variables will be reordered with its clus-
ter according to the permutation π; and 2) within each cluster,
the order of variables remains the same with the original LP. In
this way, the coefﬁcients matrix A and cost coefﬁcients vector
c will correspondingly be altered. We hope the reformulation
of original LP can improve the solving performance of solver
over the LP. The solving performance can be the solving time,
iteration number, solving accuracy (i.e., primal/dual solution
violation), etc., which depends on the preference of perfor-
mance optimization. We formally deﬁne the improvement R
of solving performance gained from reformulation as:

R(π|lp) = SM(lp) − SM(lp|π)

(7)

where SM(lp) denotes that with respect to a solving perfor-
mance metric M, calling a solver to solve lp; and SM(lp|π)
refers to that with respect to the same solving metric M, call-
ing the same solver to solve lp reformulated using the variable
permutation π. Using Eq.(7), we can measure how a permu-
tation π can improve the solving performance M of solver,
compared to the original LP without reformulation.

Our aim is to learn a probability distribution p(π|{Cj}k

that given a sequence of splitting clusters {Cj}k

j=1)
j=1 of lp and

corresponding embedding {Σj}k
j=1, can assign higher prob-
abilities to "better" permutations and lower probabilities to
"worse" ones. The "better" and "worse" are measured using
Eq.(7). Similar to [Vinyals et al., 2015; Bello et al., 2016], the
probability distribution p(π|{Cj}k
j=1) utilizes the chain rule
to factorize the probability of a permutation as:

p(π|{Cj}k

j=1) =

k
(cid:89)

j=1

p(π(j)|π(< j), {Cj}k

j=1)

(8)

We parameterize p(π|{Cj}k
parameter is denoted by θP .

j=1) by a pointer network whose

3.5 Training method

In our proposed method, there are two main classes of param-
eters, θG and θP , to be learned. Theoretically, the parame-
ters could be trained using supervised learning (SL) as done
in [Vinyals et al., 2015] or reinforcement learning (RL) as
done in [Bello et al., 2016]. However, we adopt the reinforce-
ment learning method instead of supervised learning method.
First, getting high-quality labelled data (getting improvement
R gained from reformulation in our context) is expensive es-
pecially when the size of LP is large. Because we need to call
a solver to solve two LP instances (i.e., original LP and its
reformulated LP) each time we calculate the improvement R.
Besides, RL is deemed as an effective way to generate better
supervised signals, which could help ﬁnd a more competitive
solution than purely supervised learning. Thus we propose to
use model-free policy-based RL to learn θG and θP .

The training objective is to maximize the expected improve-
ment R over a given LP lp, which is formally deﬁned as:

J(θG, θP |lp) = Eπ∼pθG ,θP (.|lp)[R(π|lp)]
In our training phase, the LPs usually come from the same
practical scenario S such as production planning, bin packing,
etc. Thus the total training objective is deﬁned as:

(9)

J(θG, θP ) = Elp∼S [J(θG, θP |lp)]

(10)

We utilize stochastic gradient ascent method to optimize
Eq.(10). According to the REINFORCE algorithm, the gradi-
ent of Eq.(10) is given as:
(cid:53)θG,θP J(θG, θP |lp) =Eπ∼pθG ,θP (.|lp)[(R(π|lp) − b(lp))

(cid:53)θG,θP log pθG,θP (π|lp)]

(11)
where b(.) is a baseline function independent of π and esti-
mates the expected improvement R to reduce the learning
variances. To enhance the estimate accuracy of baseline func-
tion, we additionally introduce a critic network parameterized
by θc, which is trained with stochastic gradient descent method
over a mean squared error (MSE) between the true improve-
ment R and its prediction bθc(lp). The MSE loss is deﬁned as:

L(θc) = Elp∼S,π∼pθG ,θP (.|lp)[bθc(lp) − R(π|lp)]2

(12)

Note that in our implementation, all mentioned-above gradi-
ents are approximated using Monte Carlo sampling. We give
a snippet of pseudo codes in Algorithm 1 (see Appendix).

4 Experimental Evaluation
4.1 Setting up
Implementation detail
In our implementation, we use the open-source LP solver
COIN-OR LP (CLP) [COIN-OR Foundation, 2021a] as the
"environment" in the reinforcement learning setting, with
which the proposed method interact. To ease the interaction,
we ﬁrst adopt the well-developed CLP python interface library,
CyLP [COIN-OR Foundation, 2021b] as the interface between
the proposed reformulation method and CLP solver. Besides,
we develop a new interface that can 1) take as input a given
permutation; 2) reformulate a LP instance according to the
given permutation; and 3) solve the reformulated LP instance
and return the solving metric of interest.

With regard to the GCNN and PN involved in the proposed
method, we implemented them using PyTorch [Paszke et al.,
2019]. The corresponding hyperparameter is summarized in
Table 3 (see Appendix). Note that we use the default param-
eter of CLP solver when we call the solver to solve a given
LP. All experiments are conducted on a computing server,
which is equipped with Intel(R) Xeon(R) Platinum 8180M
CPU@2.50GHz, a V100 GPU card with 32GB graphic mem-
ory and 1TB main memory.
Dataset
The entire evaluation was performed over three sets of Mixed
Integer Linear Programming (MILP) problems. All dataset
are scenario speciﬁc, i.e., they contain problem instances from

only a single scenario. Two of them, Balanced Item Placement
(BIP) and Workload Apportionment (WA) , are from [NeurIPS
2021 Competition, 2021]. The third set is obtained from
Huawei Production Planning (HPP). The detailed description
about above dataset is summarized in Appendix. Note that
we relax the integer constraint of variables in above MILPs
to get the LP instance. Within the dataset of BIP and WA,
there are respectively in total 10000 LP instances, which are
different in the value of coefﬁcients, the size of constraints and
variables. And for the dataset of HPP, there are in total 1000
LP instances. The statistical description of above datasets is
summarized in Table 1, where m, n and N N Z represent the
number of constraints, variables and non-zero coefﬁcients of a
linear programming, respectively. For each dataset, 80%, 10%
and 10% of instances are used as the training, validation and
testing set respectively. Besides, for each dataset, we train the
neural networks involved in the proposed method separately.
In other words, we have three sets of (θG, θP , θc) to train.
Metric of interest
As deﬁned in Eq.(7), we need to specify the solving perfor-
mance metric M when we measure the improvement gained
from reformulation. In practice, people usually care about
the solving time or iteration number of search process when
the solution quality meets a given standard (for example, the
maximum of primal/dual infeasible max_inf of a solution
is less than a given primal/dual tolerance). But the solving
time might be affected by many factors such as the other
background tasks simultaneously running in the same com-
puting server. Thus we ﬁnally adopt the iteration number as
the solving performance metric M when we train our model.
Besides we also have requirement for solution quality, that is
max_inf ≤ 10−6.

4.2 Evaluation result
Learning convergence
We ﬁrst give the learning curves of neural network parameters
(i.e., θP and θG) in Figure 4 (see Appendix), which shows
that the parameter learning of neural networks involved in our
method can converge over the three datasets. However, com-
pared with small-scale LP instances from BIP, it is relatively
harder to learn neural network parameter over the large-scale
and complex LP instances from WA and HPP, since the loss
variance of former is much smaller than that of latter two.

Reduction of iteration number
We measure how our proposed reformulation method reduces
the iteration number of solving process compared to directly
solving the original LP. Speciﬁcally, we ﬁrst call the CLP
solver to directly solve LP instances from the testing set of
above three datasets and record the iteration number of solv-
ing process (here refers to the iteration number of simplex
method). Then we reformulate these LP instances using the
learned neural networks. The CLP solver is called again to
solve the reformulated LP instances and the iteration number
is recorded subsequently. We compare the iteration number
of solving reformulated LP instances against that of solving
original ones. Due to the inference randomness of neural net-
work, here we adopt a k-shot inference mechanism, which
means that the neural network will infer k times and the best

Dataset
BIP
WA
HPP

m
195.00 ± 00.00
6.43e04 ± 54.51
1.25e06 ± 6.93e04

n
1083.00 ± 00.00
6.1e04 ± 00.00
2.66e06 ± 1.83e05

N N Z
7440.00 ± 00.00
3.62e05 ± 6007.41
6.64e06 ± 4.29e05

Table 1: Statistical description of used dataset

(a) BIP training data

(b) WA training data

(c) HPP training data

(d) BIP testing data

(e) WA testing data

(f) HPP testing data

Figure 3: Reduction of the iteration number over training and testing data of three datasets

result is kept among the k times of inferences. The results
are presented in Figure 3. In these ﬁgures, the horizontal axis,
Ratio of reformulate/original, denotes the ratio of the iteration
number of solving reformulated LP instances to that of solv-
ing original ones. The vertical axis denotes the cumulative
probability distribution of the ratio over the dataset. Several
ﬁndings can be pointed out: 1) our learning-based reformu-
lation method is effective in reducing the solving iteration
number. When k ≥ 3, almost all original LP instance can be
solved with fewer solving iteration number via reformulating
by our method; 2) our method can be generalized to unseen
data since it still performs well over the testing dataset; and
3) On the LP intances from WA and HPP, our method per-
forms slightly worse than on the ones from BIP, which is in
accordance with what we observe in the learning convergence.
Reduction of solving time
We continue to measure how our proposed method reduces the
solving time. The same procedure as described in Section 4.2
is adopted in this experiment. Different from Section 4.2, we
here compare the solving time between original LP instances
and its reformulation obtained from our method, instead of the
solving iteration number. Note that for each LP instance refor-
mulated by our method, we keep the best result among 3 times
of inferences of neural networks. The results are presented
in Table 2. From observing the results, several claims can be
made: 1) the proposed method can indeed reduce the solving
time of given LP instances by reformulating them, which infer-
ably beneﬁts from the reduction of solving iteration number;
2) our method performs slightly worse over the complex and

Dataset

BIP

WA

HPP

training
testing
training
testing
training
testing

Average reduction
25.18%
22.35%
10.78%
8.35%
15.62%
10.47%

Standard error
±2.39%
±4.67%
±0.59%
±1.23%
±2.47%
±3.89%

Table 2: Reduction of solving time by our proposed method

large-scale LP instances but still can reduce at least 8.35%
the solving time over the complex LP instances from WA and
HPP. Besides, we give a visualization for the reformulation
process of our method, in order to ﬁgure out what the neural
networks have learned (see visual analysis in Appendix A).
5 Conclusion
In this paper, we propose a machine learning-based reformu-
lation method for LP, in order to improve the solving perfor-
mance. Speciﬁcally, a LP instance is ﬁrst represented by a
bipartite graph, followed by a graph neural network to out-
put the embedding of variables of the LP instance. Then a
pointer network takes as input the embedding of variables and
output a new ordering of these variables. Then the original
LP instance is reformulated according to the new ordering of
variables. The parameter of above neural networks is trained
using reinforcement learning. Extensive evaluation results
over three datasets of LP instances verify the effectiveness of
our proposed method in performance improvement of solver.

0.50.60.70.80.91.01.11.21.3Ratio of reformulate/original0.00.20.40.60.81.0Cumulative distribution functionk=1k=2k=3k=5k=100.50.60.70.80.91.01.11.21.3Ratio of reformulate/original0.00.20.40.60.81.0Cumulative distribution functionk=1k=2k=3k=5k=100.60.81.01.21.41.6Ratio of reformulate/original0.00.20.40.60.81.0Cumulative distribution functionk=1k=2k=3k=5k=100.50.60.70.80.91.01.1Ratio of reformulate/original0.00.20.40.60.81.0Cumulative distribution functionk=1k=2k=3k=5k=100.60.70.80.91.01.1Ratio of reformulate/original0.00.20.40.60.81.0Cumulative distribution functionk=1k=2k=3k=5k=100.60.81.01.21.41.61.8Ratio of reformulate/original0.00.20.40.60.81.0Cumulative distribution functionk=1k=2k=3k=5k=10References
[Andersen et al., 2003] E. D. Andersen, C. Roos, and T. Ter-
laky. On implementing a primal-dual interior-point method
for conic quadratic optimization. Mathematical Program-
ming, 95(2):249–277, 2003.

[Applegate et al., 2003] David Applegate, Robert Bixby,
Implementing the
Vašek Chvátal, and William Cook.
dantzig-fulkerson-johnson algorithm for large traveling
salesman problems. Mathematical programming, 97(1):91–
153, 2003.

[Bello et al., 2016] Irwan Bello, Hieu Pham, Quoc V Le, Mo-
hammad Norouzi, and Samy Bengio. Neural combinatorial
optimization with reinforcement learning. arXiv preprint
arXiv:1611.09940, 2016.
[Bixby, 1992] Robert E Bixby.

Implementing the simplex
method: The initial basis. ORSA Journal on Computing,
4(3):267–284, 1992.

[Chauhan et al., 2012] Chetan Chauhan, Ravindra Gupta, and
Kshitij Pathak. Survey of methods of solving tsp along
with its implementation using dynamic programming ap-
proach. International journal of computer applications,
52(4), 2012.

[COIN-OR Foundation, 2021a] COIN-OR Foundation. Coin-
or linear programming, https://github.com/coin-or/clp„
2021.

[COIN-OR Foundation, 2021b] COIN-OR Foundation. Cylp,

https://github.com/coin-or/cylp„ 2021.

[Dantzig, 1987] G. B. Dantzig. Origins of the simplex

method. 1987.

[Gasse et al., 2019] Maxime Gasse, Didier Chételat, Nicola
Ferroni, Laurent Charlin, and Andrea Lodi. Exact com-
binatorial optimization with graph convolutional neural
networks. arXiv preprint arXiv:1906.01629, 2019.

[Ge et al., 2021] D. Ge, C. Wang, Z. Xiong, and Y. Ye. From
an interior point to a corner point: Smart crossover. 2021.
[Gharaei et al., 2020] Abolfazl Gharaei, Mostafa Karimi, and
Seyed Ashkan Hoseini Shekarabi. Joint economic lot-sizing
in multi-product multi-level integrated supply chains: Gen-
eralized benders decomposition. International Journal of
Systems Science: Operations & Logistics, 7(4):309–325,
2020.

[Gupta et al., 2020] Prateek Gupta, Maxime Gasse, Elias B
Khalil, M Pawan Kumar, Andrea Lodi, and Yoshua Ben-
gio. Hybrid models for learning to branch. arXiv preprint
arXiv:2006.15212, 2020.

[Gurobi, 2021] Gurobi. Gurobi solver, https://www.gurobi.

com/„ 2021.

[Huawei, 2021] Huawei.

Optverse solver, https://www.
huaweicloud.com/product/modelarts/optverse.html„ 2021.

[IBM, 2021] IBM.

Cplex, https://www.ibm.com/hk-en/

analytics/cplex-optimizer„ 2021.

[Khalil et al., 2016] Elias Khalil, Pierre Le Bodic, Le Song,
George Nemhauser, and Bistra Dilkina. Learning to branch

in mixed integer programming. In Proceedings of the AAAI
Conference on Artiﬁcial Intelligence, volume 30, 2016.
[Manieri et al., 2021] Lucrezia Manieri, Alessandro Falsone,
and Maria Prandini. Hyper-graph partitioning for a multi-
agent reformulation of large-scale milps. IEEE Control
Systems Letters, 6:1346–1351, 2021.

[Maros, 2002] István Maros. Computational techniques of the
simplex method, volume 61. Springer Science & Business
Media, 2002.

[Mavrotas and Makryvelios, 2021] George Mavrotas and
Evangelos Makryvelios. Combining multiple criteria analy-
sis, mathematical programming and monte carlo simulation
to tackle uncertainty in research and development project
portfolio selection: A case study from greece. European
Journal of Operational Research, 291(2):794–806, 2021.
[Nair et al., 2020] Vinod Nair, Sergey Bartunov, Felix Gi-
meno, Ingrid von Glehn, Pawel Lichocki, Ivan Lobov,
Brendan O’Donoghue, Nicolas Sonnerat, Christian Tjan-
draatmadja, Pengming Wang, et al. Solving mixed in-
teger programs using neural networks. arXiv preprint
arXiv:2012.13349, 2020.

[NeurIPS 2021 Competition, 2021] NeurIPS 2021 Competi-
tion. Machine learning for combinatorial optimization,
https://www.ecole.ai/2021/ml4co-competition/„ 2021.
[Paszke et al., 2019] Adam Paszke, Sam Gross, Francisco
Massa, Adam Lerer, James Bradbury, Gregory Chanan,
Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca
Pytorch: An imperative style, high-
Antiga, et al.
performance deep learning library. Advances in neural
information processing systems, 32:8026–8037, 2019.
[Selsam et al., 2018] Daniel Selsam, Matthew Lamm,
Benedikt Bünz, Percy Liang, Leonardo de Moura, and
David L Dill. Learning a sat solver from single-bit
supervision. arXiv preprint arXiv:1802.03685, 2018.
[Sumita et al., 2017] Hanna Sumita, Yuma Yonebayashi,
Naonori Kakimura, and Ken-ichi Kawarabayashi. An im-
proved approximation algorithm for the subpath planning
problem and its generalization. In IJCAI, volume 2017,
pages 4412–4418, 2017.

[Vinyals et al., 2015] Oriol Vinyals, Meire Fortunato, and
arXiv preprint

Pointer networks.

Navdeep Jaitly.
arXiv:1506.03134, 2015.

[Wolsey, 2007] Laurence A Wolsey. Mixed integer program-
ming. Wiley Encyclopedia of Computer Science and Engi-
neering, pages 1–10, 2007.

[Zhang and Looks, 2005] Weixiong Zhang and Moshe Looks.
A novel local search algorithm for the traveling salesman
problem that exploits backbones. In IJCAI, volume 5, pages
343–384. Citeseer, 2005.

[ZIB, 2021] ZIB.

Scip solver, https://www.scipopt.org/„

2021.

Appendix A
Feature used in constructing bipartite graph
Features of constraint:

• rhs: the right-hand side coefﬁcients of LP, i.e. b, normal-

ized with constraint coefﬁcients.

• ub_cons: upper bound of constraint, normalized with all

constraints upper bound.

• lb_cons: lower bound of constraint, normalized with all

constraints lower bound.

Features of variable:

• lb_var: upper bound of variable, normalized with all

variables lower bound.

Name
Optimizer
# epochs (T )
# splitting cluster
Batch size (B)
Train size
Validation size
Learning rate
Decay ratio of learning rate
Gradient clip normalizer
Dimension of input embedding in PN
Dimension of hidden layers in PN
Dimension of input embedding in GCNN
# of times that performs convolution (l)

Used value
ADAM
40000
20
8
640
320
10−4
0.96
l2 norms
128
128
64
2

• lb_var: upper bound of variable, normalized with all

Table 3: Hyperparameters setting

variables lower bound.

• ub_var: lower bound of variable, normalized with all

variables upper bound.

Features of edge:

• coef: the constraint coefﬁcients of variables, i.e. A, nor-

malized per constraint

Pseudo code of training method

Algorithm 1 Training procedure of the proposed method

Inputs

• S: set of linear programming problems

• T : number of training steps
• B: batch size

Initializes

• θG: parameters for graph convolutional neu-

ral network

• θP : parameters for pointer network
• θc: parameters for critic network

for steps t = 1 to T do

lpi ∼ S for i ∈ {1, ..., B}
πi ∼ pθG,θP (.|lpi) for i ∈ {1, ..., B}
Calculate Ri using Eq.(7) for i ∈ {1, ..., B}
bi = bθc(lpi) for i ∈ {1, ..., B}
g ← 1
B
Lc ← 1
B
Perform a gradient ascent step to update θG and θP using
g respectively
Perform a gradient descent step to update θc using (cid:53)θcLc

i=1(Ri − bi) (cid:53)θG,θP log pθG,θP (πi|lpi)
(cid:80)B
i=1(bi − Ri)2

(cid:80)B

end for
return θG, θP and θc

Hypeparameters setting
Part of important hyperparameters involved in our method is
list in Table 3.

Description of dataset
Balanced Item Placement. This problem deals with spread-
ing items (e.g., ﬁles or processes) across containers (e.g., disks
or machines) utilizing them evenly. Items can have multiple

copies, but at most, one copy can be placed in a single bin. The
number of items that can be moved is constrained, modeling
the real-life situation of a live system for which some place-
ment already exists. Each problem instance is modeled as a
MILP, using a multi-dimensional multi-knapsack formulation.
Workload Apportionment. This problem deals with appor-
tioning workloads (e.g., data streams) across as few workers
(e.g., servers) as possible. The apportionment is required to be
robust to any one worker’s failure. Each instance problem is
modeled as a MILP, using a bin-packing with apportionment
formulation.
Huawei Production Planning. The planning and schedul-
ing optimization problems solved in the Huawei production
planning engine.

Visual analysis
In order to ﬁgure out what the neural network have learned,
we give the visualization for the reformulation process of our
method, over the three datasets of LP instances. Speciﬁcally,
from each dataset, we select two LP instances. We refor-
mulate them by the learned neural network of our proposed
method. Then we draw the coefﬁcient matrix of original LP
instances and reformulated ones respectively, which are shown
in Figure 5 to Figure 7. Observing these ﬁgures, we can ﬁnd
that 1) our proposed reformulation method indeed capture
the characteristics of LP instances originated from different
scenarios. Because the pattern of corresponding reformulated
LP instances are greatly different across different datasets but
are similar between LP instances within the same dataset; 2)
The reformulation is relatively stable when the original LP
instances are highly similar. All the original LP instances of
BIP are with the same number of constraints and variables,
which is only different in the value of coefﬁcients. Thus the
pattern of the corresponding reformulated LP instances are
almost the same (see Figure 5). However, the pattern of refor-
mulated LP instances of WA and HPP is quiet different (see
Figure 6 and Figure 7) because the corresponding original LP
instances differs in not only the value of coefﬁcients but also
the number of constraints and variables.

(a) loss curve of θP over BIP

(b) loss curve of θP over WA

(c) loss curve of θP over HPP

(d) loss curve of θG over BIP

(e) loss curve of θG over WA

(f) loss curve of θG over HPP

Figure 4: Learning convergence result of our proposed method over above three datasets

(a) original LP1

(b) reformulated LP1

(c) original LP2

(d) reformulated LP2

Figure 5: Visualization of reformulation process over BIP dataset

(a) original LP1

(b) reformulated LP1

(c) original LP2

(d) reformulated LP2

Figure 6: Visualization of reformulation process over WA dataset

(a) original LP1

(b) reformulated LP1

(c) original LP2

(d) reformulated LP2

Figure 7: Visualization of reformulation process over HPP dataset

