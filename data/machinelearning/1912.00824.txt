0
2
0
2

g
u
A
7
1

]
n
n
-
s
i
d
.
t
a
m
-
d
n
o
c
[

2
v
4
2
8
0
0
.
2
1
9
1
:
v
i
X
r
a

Capacity of the covariance perceptron

David Dahmen
Institute of Neuroscience and Medicine (INM-6) and Institute for Advanced
Simulation (IAS-6) and JARA Institut Brain Structure-Function Relationships
(INM-10), Jülich Research Centre, Jülich, Germany

Matthieu Gilson*
Center for Brain and Cognition, Universitat Pompeu Fabra, Barcelona, Spain

Moritz Helias*
Institute of Neuroscience and Medicine (INM-6) and Institute for Advanced
Simulation (IAS-6) and JARA Institut Brain Structure-Function Relationships
(INM-10), Jülich Research Centre, Jülich, Germany
Department of Physics, Faculty 1, RWTH Aachen University, Aachen, Germany

Abstract. The classical perceptron is a simple neural network that performs
a binary classiﬁcation by a linear mapping between static inputs and outputs
and application of a threshold. For small inputs, neural networks in a stationary
state also perform an eﬀectively linear input-output transformation, but of an
entire time series. Choosing the temporal mean of the time series as the
feature for classiﬁcation, the linear transformation of the network with subsequent
thresholding is equivalent to the classical perceptron. Here we show that choosing
covariances of time series as the feature for classiﬁcation maps the neural network
to what we call a ’covariance perceptron’; a mapping between covariances that
is bilinear in terms of weights. By extending Gardner’s theory of connections to
this bilinear problem, using a replica symmetric mean-ﬁeld theory, we compute
the pattern and information capacities of the covariance perceptron in the
inﬁnite-size limit. Closed-form expressions reveal superior pattern capacity in
the binary classiﬁcation task compared to the classical perceptron in the case
of a high-dimensional input and low-dimensional output. For less convergent
networks, the mean perceptron classiﬁes a larger number of stimuli. However,
since covariances span a much larger input and output space than means, the
amount of stored information in the covariance perceptron exceeds the classical
counterpart. For strongly convergent connectivity it is superior by a factor equal
to the number of input neurons. Theoretical calculations are validated numerically
for ﬁnite size systems using a gradient-based optimization of a soft-margin, as
well as numerical solvers for the NP hard quadratically constrained quadratic
programming problem, to which training can be mapped.

 
 
 
 
 
 
Capacity of the covariance perceptron

2

1. Introduction

Binary classiﬁcation is one of the standard tasks in machine learning. The simplest
artiﬁcial neural network that implements classiﬁcation is the classical perceptron [1–3].
It is a feed-forward mapping from neurons in an input layer to those of an output layer.
Neurons in the output layer receive a weighted sum of signals from the input layer,
which is passed through a Heaviside nonlinearity, implementing a decision threshold.
Inputs to the perceptron, i.e. activation levels of the input neurons, are speciﬁc
features of some data, in the simplest case the pixels of an image or the time points of
a temporal signal. Classiﬁcation is achieved by training the weights from the input to
the output layer such that the projections of diﬀerent input patterns become linearly
separable.

Classiﬁcation is also one essential task for biological neuronal networks in the
brain. However, neurons do not receive diﬀerent static features of some input signal,
but sequences of action potentials, so-called spikes, from other neurons. Biological
neural networks thus have to extract the relevant features from these temporal
sequences.

To understand biological information processing we need to ask which features
of the temporal sequences contain the relevant information. Already in the 1950s
the mean number of spikes in a given
it has been shown that the ﬁring rate, i.e.
time interval, contains information for example on the presence of a certain feature
of a stimulus, such as the orientation of a bar [4]. However, cortex also shows large
temporal variability in responses even to the same stimuli [5] which raises the question
whether this variability has some functional meaning. Evidence has accumulated that
the temporal ﬂuctuations of neuronal signals around their mean contain behaviorally
relevant information; this holds even to the level of the exact timing of spikes [6].
For example, correlations in spike times across diﬀerent neurons, such as precise
synchronization, have been shown to code expectations of the animals [7].

Like in artiﬁcial neural networks, one mechanism for learning in the brain is
implemented by changing the strengths of connections between neurons, known as
synaptic plasticity.
In the middle of the last century, Donald Hebb postulated the
principle ’Cells that ﬁre together, wire together’ [8, 9], a plasticity rule that depends
Importantly, in Hebbian plasticity it is
on the activity of the connected neurons.
not the overall level of activation of the neurons (their overall ﬁring rate) that is
relevant, but the temporal coordination of activities. Since then, several learning rules
were proposed to extract information from coordinated ﬂuctuations [10, 11]. The
model called spike-timing-dependent plasticity (STDP) [12] predicted that changes
in synaptic strengths are sensitive to even the exact spike timings of the pre- and
postsynaptic cells, which was conﬁrmed later on in experiments [13, 14]. This suggests
that temporal ﬂuctuations in neural activities and their coordination are naturally
distinguished features that shape learning and thereby the function of the neural
circuit.

The simplest measure for coordination between temporal ﬂuctuations are pairwise
In a network of m neurons, pairwise cross-
covariances between neural activities.
1)/2-dimensional space for coding information, which is a
covariances form an m(m
much larger space than the space of mean activities. This intuitively suggests that it
might be beneﬁcial for a neural system to make use of the covariances to represent and
process relevant information. In this study, using methods from statistical mechanics,
we examine the performance of such a computational paradigm which processes

−

Capacity of the covariance perceptron

3

information that is represented in ﬂuctuations: the covariance perceptron [15].

Neurons are highly nonlinear processing units. Nevertheless, in large networks
where individual inputs to the neurons are small with respect to their total input,
temporal ﬂuctuations around some stationary state can be well explained by means of
linear response theory [16]. In this setting, the network eﬀectively performs a linear
transformation between its inputs and outputs. Linear response theory has been shown
to faithfully capture the statistics of ﬂuctuations in asynchronous, irregular network
states that are observed in cortex [17, 18].

In this study, we make use of linear response theory to show that a network
that transforms temporal input signals into temporal output signals acts as a classical
perceptron if the temporal mean of the network output trajectories is chosen as the
relevant feature for a following binary classiﬁcation. Choosing, instead, covariances
as the relevant feature of the temporal signals, the same network acts as a covariance
perceptron [15], which is based on a bilinear mapping in terms of weights, but linear
from input to output covariances. The classical perceptron has been studied in the
1980s in terms of its performance for classiﬁcation [19]. Two performance measures
are the pattern capacity, the number of patterns that can be correctly classiﬁed
into two distinct classes, and the information capacity, which is the number of bits
a conventional computer requires to realize the same functionality as the neuronal
implementation.

Here we set out to study the performance of the covariance-based classiﬁcation
paradigm by calculating the pattern capacity and information capacity of the
covariance perceptron. Following Gardner’s theory of connections, we use replica
symmetric mean-ﬁeld theory with a saddle-point approximation to study the volume
of possible weight conﬁgurations for the classiﬁcation problem. The limiting capacity
is given by the maximum number of correctly classiﬁable stimuli. This analysis shows
that the covariance perceptron can store up to twice as many patterns as the classical
perceptron. Moreover, in case of strongly convergent connectivity, the information
capacity in bits largely exceeds the traditional paradigm by up to a factor 2m, with
m the number of input neurons. Our work thus provides evidence that covariance-
based information processing in a biological context can reach superior performance
compared to paradigms that have so far been used in artiﬁcial neuronal networks.

2. Model

In this study, we consider neural networks that transform patterns x(t) of m input
trajectories xk(t) into patterns y(t) of n output trajectories yi(t) (Figure 1). Using
this network transformation and a following hard decision threshold on the outputs,
we want to perform a binary classiﬁcation of patterns x(t) into classes labeled by
binary words ζ which entries can take the values +1 and
1. Patterns x(t) shall be
−
RM , and classiﬁcation shall be performed
deﬁned by an M -dimensional feature F
RN of the output patterns y(t). Possible features
on an N -dimensional feature G
could, for example, be the signals at a given time point, their temporal average or some
higher order statistics. By transforming patterns x(t) into patterns y(t), the network
maps the feature F of the inputs to the feature G of the outputs. The connection
weights of the network thereby shall be trained to optimize the classiﬁcation based
on G. In general, features F and G can describe very diﬀerent characteristics of the
patterns x(t) and y(t), respectively. However, in this study we choose the case where
F and G are of the same type, which is important for the consideration of multilayer

∈

∈

Capacity of the covariance perceptron

4

stimulus

input trajectories

network

output trajectories

behavior

time

time

-0.9

-0.7

0.1

0.8

-0.1

0.2

?

0.9

-0.1

-0.8

0.4

1

-1

-1

1

up

down

left

right

feature

mapping

feature

binary word

Figure 1. Setup. Top: Biological information processing. Sensory information
enters the system as a time series. The dynamics of the neuronal network produces
an outgoing time series of activities. Ultimately, a set of eﬀectors, for example
muscles, are controlled by the resulting signal. Bottom: Machine-learning view
of the biological system. A set of features F is extracted from the incoming time
series. These are transformed by a mapping to another set of features G, each
of which is thresholded to produce a binary output, in the example encoding
the movement direction. The input-output mapping is deﬁned implicitly by the
biological system.

networks.

An important measure for the quality of the classiﬁcation is the margin deﬁned

as

κ = min
1
N
≤

≤

s

min
1
p
r
≤
≤

(ζr

s Gr

s) ,

(1)

where r indexes the patterns and s the dimensions of the feature G. The margin
measures the smallest distance over all elements of G from the threshold, here set to
0. It plays an important role for the robustness of the classiﬁcation [20], as a larger
margin tolerates more noise in the input pattern before classiﬁcation is compromised.
The margin of the classiﬁcation is illustrated in Fig. 2, where each symbol represents
one of the p patterns and the colors and markers indicate the corresponding category
ζr. Classiﬁcation is achieved by training the connection weights of the network to
maximize κ. This optimization increases the gap and thus the separability between
red and blue symbols and the disks and squares in Fig. 2.

The classiﬁcation scheme reaches its limit for a certain pattern load p at which
the margin κ vanishes. More generally, one can ask how many patterns the scheme can
discriminate while maintaining a given minimal margin κ. This deﬁnes the pattern
capacity

(κ) = max(p

κ).

(2)

|

The information capacity is the number of bits required in a conventional computer,
if it were to realize the same classiﬁcation of the

(κ) patterns

(κ) =

(κ) (log2 K + log2 L) .

P

P

(3)

P

I

Here K denotes the number of possible conﬁgurations of a single pattern in the input,
and L denotes the number of possible binary words assigned to the output.

Capacity of the covariance perceptron

5

training

Figure 2. Training. Classiﬁcation based on two-dimensional feature (G1, G2),
here represented by shape (disks/squares) and color (red/blue). Left: Before
training, patterns are scattered randomly in the space spanned by coordinates G1
and G2. Right: After training, weights of the neural network are adjusted such
that patterns with diﬀerent features become linearly separable with thresholds
(black lines) parallel to the coordinate axes. The margin κ (gray area) quantiﬁes
the degree of separability: It is the minimal distance over all data samples to any
of the thresholds.

For any general network, one can write the output y(t) as a Volterra series
of the input x(t). Ongoing activity in cortical networks in many cases shows
weakly-ﬂuctuating activity with low correlations. It has been shown that such small
ﬂuctuations around some stationary state can be well described using linear response
theory [16, 17, 21, 22], which amounts to a truncation of the Volterra series after the
ﬁrst order. In such a scenario, the network transformation of small inputs follows the
general form

−

y(t) =

dt′W (t

t′)x(t′),

(4)

Z
with some generic linear response kernel W (t)
In the following, we will
restrict our analysis to this scenario and study the computational properties of
networks operating in the linear regime.

m.

Rn

∈

×

After having clariﬁed the setup, let us now turn to two speciﬁc examples of

features for classiﬁcation.

Scenario 1: Classical perceptron
Let’s assume that the relevant feature of input trajectories xk(t) is their temporal
. In this case, by integrating

mean which we here deﬁne as Xk =
Eq. (4) over time, we see that the network performs the mapping

dt xk(t) (Fig. 3a)
‡

Y = W X

R

(5)

with weights Wik that are given by the area under the linear response kernels
dt Wik(t). The dimension of the input feature F and output feature G is
Wik =
then M = m and N = n, respectively.

Together with the application of a hard decision threshold on Y , this network
transformation acts as n classical perceptrons. The weights Wik can be trained to

R

‡ Note that, throughout, we consider observation times T much larger than the decay time of the
linear response kernels W (t). For brevity, we also drop the trivial normalization by the duration T .

Capacity of the covariance perceptron

(a)

(b)

0.9

mean

0.1

-0.8

0.6

6

-0.9

-0.7

0.1

0.8

-0.1

0.2

covariances

time

time

Figure 3. Extraction of features from time series. (a) Mean encoding.
Each of the m channels is given by a time series. The temporal average, the mean
X, is the feature to be extracted from each time trace. This yields a vector with
one entry per time trace. (b) Covariance encoding. Representation of information
by the covariance between m time series. These represent m(m − 1)/2 cross-
covariances P ; positive covariance corresponds to ﬂuctuations in both time series
that go into the same direction; negative covariance is caused by antagonistic
ﬂuctuations between the two series.

reach optimal classiﬁcation performance. The pattern capacity of a single classical
perceptron classifying binary patterns has been shown to be [9, 19]

class(κ) = m

∞

P

κ

(cid:18)Z

−

dt
√2π

(cid:19)

2
t

e−

/2 (t + κ)2

1

−

.

(6)

Note that this capacity does not increase by having more than n = 1 outputs: all
perceptrons receive the same patterns as inputs and therefore perform the same task.
The information capacity for a classiﬁcation scheme based on temporal means follows
from Eqs. (2) and (3) with K = 2m and L = 2n as

class(κ) =

class(κ)(m + n).

(7)

I

P

Note that in practical applications, one cannot observe input and output trajectories
for inﬁnite time, but only for a ﬁnite duration T . The estimate of the mean activity
from that ﬁnite period T diﬀers from the true temporal mean. Therefore, temporal
ﬂuctuations in the input trajectories constitute a source of noise in this classiﬁcation
paradigm.

Scenario 2: Covariance perceptron
We now turn to the contrary case where temporal ﬂuctuations, quantiﬁed by
the cross-covariances Pij (τ ) of the input trajectories, shall be the relevant feature for
classiﬁcation (Fig. 3b). In this case, the feature dimensions are M = m(m
1)/2 and
1)/2. The mapping from input covariances Pij (τ ) to output covariances
N = n(n
Qij(τ ) can be derived from Eq. (4) as

−

−

Q(τ ) =

dt y(t)yT(t + τ )

Z

−

Z

=

ds

ds′ W (s)P (τ + s

dt y(t)

dtyT(t + τ )

Z

s′)W T(s′).

−

Z

Z

The network linearly ﬁlters the input covariances Pij (τ ). If we consider covariances
Qij =

dτ Qij(τ ) integrated across all time lags, we obtain the simple mapping

R

Q = W P W T,

(8)

Capacity of the covariance perceptron

7

R

which is linear in covariances but bilinear in the weights. Note that alternatively one
could consider a single frequency component ˆQij =
iωτ and derive an
analogous mapping ˆQ = ˆW ˆP ˆW †.

dτ Qij(τ )e−

Therefore, covariance-based classiﬁcation amounts to a bilinear problem unlike
the classical perceptron, which involves a linear mapping in terms of weights. In the
following, we want to study the capacity of the covariance perceptron. But before
we do so, it is important to note that the here considered network only acts as if it
were a classical or covariance perceptron. The biological network itself in both cases
receives the full input trajectories and creates the full output trajectories. However,
the mapping between trajectories can either be optimized for a following classiﬁcation
of the temporal mean of the output trajectories (classical perceptron) or a classiﬁcation
based on the covariances of the output trajectories (covariance perceptron). In this
way, the setup here is clearly diﬀerent from standard machine learning approaches
where one applies a feature selection on the inputs as a preprocessing step and only
classiﬁes this feature vector by a perceptron. The latter approach amounts to a linear
mapping from F to G rather than a mapping between the entire trajectories (Figure 1).

3. Theoretical predictions for classiﬁcation performance based on output
cross-covariances

We now derive a theory for the pattern and information capacity of the covariance
perceptron that is exact in the limit of large networks m
and that can be
compared to the seminal theory by Gardner [19] on the capacity of the classical
perceptron. Formalizing the classiﬁcation problem for a load of p patterns, for each
element Qr
independently
ij ∈ {−
for each input pattern P r with 1
p. The task of the perceptron is to ﬁnd a
suitable weight matrix W that leads to correct classiﬁcation for all p patterns. This
requirement reads, for a given margin κ > 0,

ij of the readout matrix we draw a random label ζr

→ ∞

1, 1

≤

≤

}

r

W P rW T

ζr
ij Qr

ij = ζr
ij

r

(cid:0)

1

∀

≤

≤

≤

≤

n.

p , 1

i < j

(9)
ij > κ ,
We assume the patterns P r to be drawn randomly. This random ensemble allows
(cid:1)
us to employ methods from disordered systems [23]. Closely following the computation
for the classical perceptron by Gardner [9, 19], the idea is to consider the replication
of several covariance perceptrons. The replica, indexed by α and β, have the same
task deﬁned by Eq. (9). The sets of patterns P r and labels ζr are hence the same
for all replica, but each replicon has its own readout matrix W α. If the task is not
too hard, meaning that the pattern load p is small compared to the number of free
parameters W α
ik, there are many solutions to Eq. (9). One thus considers the ensemble
of all solutions and computes the typical overlap Rαβ
jk between the
solution W α and W β in two diﬀerent replica. The overlap is the scalar product of
P
(κ), up to the intrinsic
the weight vectors of outputs i and j. At a certain load p =
W in Eq. (9), there should only be a single solution left
reﬂection symmetry W
—the overlap Rαβ
ii between solutions for identical readouts i = j, but in diﬀerent
replica α

= β, becomes unity. This pattern load deﬁnes the limiting capacity

m
k=1 W α

ikW β

ij ≡

7→ −

P

.

Technically, the computation proceeds by deﬁning the volume of all solutions for

the whole set of cross-covariances Qr

ij that fulﬁll the classiﬁcation task

p

n

V

=

dW

θ

ζr
ij

W P r W T

Z

r
Y

i<j
Y

(cid:16)

(cid:0)

κ

.

(cid:17)

ij −
(cid:1)

(10)

P

6
Capacity of the covariance perceptron

8

n
i

m
k

dW =

Here θ denotes the Heaviside function and
dWik. This equation is
the analogue to Gardner’s approach of the perceptron; see [9, Section 10.2, eq. 10.83].
The typical behavior of the system for large m is obtained by ﬁrst taking the average of
) over the ensemble of the patterns and labels. The assumption is that the system
ln(
is self-averaging; for large m the capacity should not depend much on the particular
realization of patterns. The average of ln(
) can be computed by the replica trick
q
/q [23] which amounts to considering q systems that have
ln(
0
h
identical realizations of patterns.

= limq

i −

)
i

Q

Q

V

V

V

→

1

R

R

hV
(cid:0)

(cid:1)

3.0.1. Patterns and classiﬁcation labels
In order to perform the average over the
patterns and labels, we need to specify their statistics. Here, we choose a symmetric
setting with independent and identically distributed labels ζr
1, each with
probability 1/2. In contrast to inputs to the classical perceptron which can be chosen
independently, covariances involve constraints related to the fact that a covariance
matrix is positive semideﬁnite, which implies in particular

i<j =

±

(11)

Pkl = Plk ,
Pkk ≥
Pkl| ≤
|

0 ,

Pkk Pll ,

for all indices k and l. A simple way to ensure positive semideﬁniteness is to choose
each input covariance pattern to be of the form
P r = 1m + χr ,

p

(12)
m identity matrix and a symmetric random matrix χr = (χr)T
kk = 0 and independent and identically distributed
k<l = 0 with

c, each with probability f /2, and χr

with 1m being the m
with vanishing diagonal entries χr
lower oﬀ-diagonal elements χr
k<l =
probability 1

f .

×

±

−

Here f controls the sparseness (or density) of the non-zero cross-covariances. The
constraint of Pkk = 1 ﬁrstly enforces that all information of the patterns is in the oﬀ-
diagonal elements. Secondly, it ensures the positive semideﬁniteness for a suﬃciently
broad range of values for c and f .

The speciﬁc form of the input covariances (12) implies with Eq. (8) that

m

m

Qr

ii =

(Wik)2 +

WikWilχr
kl

which, on expectation over patterns, yields

Xk

=l
Xk

i, r ,

∀

m

(Wik)2 !

= 1

Qr
iiiχ =
h

Xk

i .

∀

(13)

The magnitude of output variances is therefore given by the normalization of the
row vectors of W , which we here set to unity. This ensures that we have a self-
consistent scheme, where information in the input and the output is both encoded only
in cross-covariances. Note that this self-consistency is only reached on expectation as
each entry Qr
ii varies around 1 according to the magnitude of cross-covariances χ,
which, however, for large networks is much smaller than the variance [24–26]. Forcing
Qr
ii = 1 would unnecessarily complicate the analysis; simulation results below show
equal capacity with or without this hard constraint. Finally, note that the value of
unity for the variance does not restrict the generality of this analysis as any other
value of the variance will lead to another normalization of the weights W , which can
be absorbed in the margin κ (cf. Eq. (9)).

6
Capacity of the covariance perceptron

9

3.0.2. Pattern and label average Given the constraint on the length of the rows in
the weight matrix W , Eq. (13), we obtain for the expectation of the power of the
volume in Eq. (10)

q

hV

i

=

*

˜Qrα

ij = ζr

q

n

m

dW α

δ

α Z
(cid:16)
Y
ij(W αP rW αT)ij ,

i
Y

Xk

(W α

ik)2

1

−

p

n

θ

(cid:17)

r
Y

i<j
Y

(cid:16)

˜Qrα

ij −

κ

(14)

+

(cid:17)

ζ,χ

which we need to study in the limit q
0. Note the Dirac delta distribution δ that
describes the constraint (13) on the length of the weight vectors. The pattern average
amounts to averaging

→

q

p

n

θ

α
Y

r
Y

i<j
Y

(cid:16)

*

˜Qrα

ij −

κ

+

(cid:17)

ζ,χ

=

=

p

q

n

˜Qrα

ij −

θ

i<j
Y

(cid:16)

κ

(cid:17)
p

+

ζ,χ

r *
Y
q

α
Y
n

(15)

θ

˜Qrα
(cid:16)

ij −

κ

+

(cid:17)

ζ,χ

i<j
Y

*
α
Y
p ,

≡ G

where we used that patterns and labels are uncorrelated (ﬁrst line) and follow the same
statistics (second line). We can express
ij by rewriting
the Heaviside function

in terms of cumulants of ˜Qrα

G

˜Qrα

ij −

θ

(cid:16)

κ

=

(cid:17)

=

∞

κ
Z

∞

κ
Z

such that

dxα

ij δ

˜Qrα

xα
ij

ij −
d˜xα
ij
2πi

(cid:0)

dxα
ij

i
∞

Z

−

i
∞

(cid:1)
e˜xα

ij

˜Qrα

ij −

xα
ij

,

(cid:0)

(cid:1)

q
n
α P

i<j ˜xα

ij xα

ij

eP

q
α P

n

i<j ˜xα

ij

Dxij

D ˜xij

e− P

Z

(cid:27)

q

α ˜xαxα+ 1

2

Dx

D ˜x e− P

Z

q

α,β ˜xα

P

D
˜Qrα
ij

hh

(16)

˜Qrα
ij

ζ,χ

E

˜Qrβ

ij iiζ,χ

˜xβ

(cid:27)

(17)

=

G

=

≡

n

i<j (cid:26)Z
Y
n

i<j (cid:26)Z
Y
n

Gij .

i<j
Y

Dx

d˜xα
q
Here we used the abbreviations
2πi , where
α
≡
indices of integration variables in the second line have been dropped. We further
R
identiﬁed the moment generating function of the variables ˜Qrα
ij with respect to the
statistics of ζ and χ (ﬁrst line). The latter can be expanded in cumulants (second
line): In the large-m limit, this expansion can be truncated at the second cumulant
in a similar fashion to the classical perceptron [9]. Due to the

κ dxα and
R

i
∞
i
∞

−
R

D ˜x

Q

Q

q
α

≡

∞

R

˜Qrα
ij

˜Qrβ
kl

ζ,χ

DD
independence of labels ζij and ζkl, the second cumulants vanish if i
The diagonal elements are given by

EE

= k or j

= l.

6
6
Capacity of the covariance perceptron

˜Qrα
ij

˜Qrβ
ij

DD

ζ,χ

EE

m

m

=

W α

ikW α
jk

W β

ikW β

jk

Xk
(cid:16)
+ f c2

m

Xk
(cid:17) (cid:16)
ikW β
W α

ik

m

(cid:17)
jkW β
W α

jk

(cid:16)

Xk
m

(cid:17) (cid:16)

Xk
m

+ f c2

W α

ikW β

jk

W β

ikW α

jk

10

(18)

(cid:17)

.

Xk

Xk

(cid:17)

(cid:17) (cid:16)

(cid:16)
The ﬁrst term arises from the diagonal 1m in the patterns P r in Eq. (12), and the
third term stems from the symmetry of P r. These two terms would be absent for
completely uncorrelated i.i.d. matrices P r. In the second and third lines in Eq. (18)
we added a single term k = l which is negligible in the large-m limit. We see that the
only dependence on the sparseness f and the magnitude c of input covariances is in
the form f c2 —it does not depend on these two parameters separately. The problem
is, moreover, now symmetric in all i < j index pairs. We also observe that the product
over all p patterns has identical factors that do not depend on the pattern index r, so
that we only get this factor to the p-th power.

3.0.3. Auxiliary ﬁeld formulation Starting from Eq. (18), we now deﬁne the auxiliary
ﬁelds as

m

W α

ikW β

jk ,

(19)

for i

ij because the unit diagonal (common to all P r) is weighted by Rαα

for i < j and α
= j measures the overlap between weight
vectors to diﬀerent units in the same replicon α. It contributes to the average value
of Qrα
ij . Hence the
output Qrα
for
= β measures the overlap of weight vectors in diﬀerent replica. For α = β and
α
i = j we have Rαα
ii = 1 due to Eq. (13). The deﬁnitions Eq. (19) are enforced by
integrations over Dirac distributions

irrespective of the realization of P r. Rαβ
ij

ij will be displaced by Rαα
ij

m

δ

W α

ikW β

jk −

Rαβ
ij

=

d ˜Rαβ
ij
2πi

i
∞

i
∞

˜Rαβ

ij P

m

k W α

ikW β

jk+ ˜Rαβ

ij Rαβ

ij

e−

(20)

(cid:0)

Xk

Z
Note that the same Fourier representation can also be used for the length constraint
on the weight vectors δ
. After inserting auxiliary ﬁelds into Eq. (17),
the integration over weights W α
ik only applies to the ﬁrst term in Eq. (20) for all indices

(W αW αT)ii −
(cid:0)

1

(cid:1)

(cid:1)

−

Rαβ

ij ≡

Xk
= β. The ﬁeld Rαα
ij

q

n

m

α
Y

Yk Z

i
Y
q
n

dW α

ik exp

−

q

n

m

˜Rαβ
ij

W α

ikW β

jk

Xα,β
q

j
Xi
≤
n

Xk

(cid:1)

m

(cid:0)

−

(cid:0)

dW α

i exp

i Z
Y

=




≡ F

α
Y
m .

˜Rαβ

ij W α

i W β

j

Xα,β

j
Xi
≤


(cid:1)


(21)

Here, we used that the expression factorizes in the index k so that we get the same
integral to the m-th power, one factor for each component W α
k = 1, . . . , m, allowing

ik ∀

6
6
6
Capacity of the covariance perceptron

11

us to deﬁne a single integration variable W α
term in Eq. (20) for all indices deﬁnes

i . Gathering contributions from the second

Expressing

q

hV

i

q

n

˜Rαβ

ij Rαβ
ij .

H ≡

Xα,β
j
Xi
≤
in terms of

q

hV

i

=

Z

Z

,

F

dR

Gij and
H
d ˜R exp

then yields

n

) + p

m ln(

F

(cid:0)
dRαβ

i<j
X
d ˜R =

ln(

Gij ) +

H

,

(cid:1)

(22)

(23)

with

dR

q
α,β

n
=β
i<j
The leading order behavior for m
R

ii and
follows as a mean-ﬁeld approximation in
R
Q
ij . Therefore, we are interested in the saddle points of the

dRαβ
ij

→ ∞
R

−
R

q
α,β

n
i
≤

i
∞
i
∞

Q

Q

Q

≡

q
α

R

j

d ˜Rαβ
ij
2πi .

Q
the auxiliary variables Rαβ
integrals
dR

R

d ˜R and search for a replica-symmetric solution. We therefore set
Rαα
Rαβ

ij = R=
ij,
=
ij ,
ij = R6
= β. For replica symmetry, the exponent in

ij = ˜R=
ij = ˜R6

˜Rαα
˜Rαβ

ij
=
ij

R

(24)

for α

Rαα

ij Rββ

ij + f c2 Rαβ

ii Rαβ

Gij simpliﬁes to
˜xβ

ij Rβα

jj + f c2 Rαβ

ij

q

q

2

˜xα ˜xα + λ6

=
ij

˜xα

(cid:17)

,

(25)

α
X

ij = f c2 R=

!
=
ij = f c2 R6
jj + (1 + f c2) R=2
ij and λ6
=
ij , which renders

ii R=
with λ=
replica are coupled by the factor λ6
integral. In order to apply the limit q
performing the Hubbard-Stratonovich transformation

α
X

→

R

=
ii R6

=2
ij + f c2 R6
ij . The
Gij a q-dimensional
0, it is convenient to decouple the replica by

=
jj + R=2

D˜x in

q

˜xα

Xα,β

(cid:16)

= (λ=

ij −

=
ij )
λ6

=

Dt etqλ6=

ij P

q

α ˜xα

,

(26)

dt
√2π

/2, which turns the 2q-dimensional integral over xα and ˜xα
∞
−∞
q into a Gaussian integral over the q-th power of a function gij(t) that is
R

1

2 λ6=

ij

e

q

α ˜xα

P

(cid:16)

2

(cid:17)

Z

2
t

e−

Dt
α

with
for 1
given by a two-dimensional integral
i
∞

≡
≤

R
≤

∞

gij(t) =

dx

1
2 (λ

=
ij −

e

λ6=
ij )˜x

2

+tqλ6=
ij ˜x

˜xx

−

d˜x
2πi

i
Z
∞
erfc(aij (t)) ,

−

κ
Z
1
2

=

ln(

2(λ=

=
ij)/
λ6
ij −
0 limit by approximating
gij(t)q
h
1 + q

= ln

i
ln

exp

gij(t)
(cid:10)

q
q
→
Gij ) = ln
ln
→
= q

D

(cid:16)

(cid:0)

(cid:1)(cid:17)E

=
ij ). The resulting form of
λ6

q ln

(cid:0)

→

q
(cid:0)

gij(t)
ln

gij(t)
(cid:1)(cid:1)(cid:11)

(cid:0)
ln

(cid:10)
erfc

(cid:0)
aij(t)

(cid:1)(cid:11)(cid:1)

(cid:0)
+ ln(1/2) .

(cid:10)

(cid:1)(cid:11)

(27)

Gij allows us to take

(28)

with aij(t) = (κ
−
advantage of the q

t

6
6
 
Capacity of the covariance perceptron

12

2

0

]

1
−

0
1
[

2
=1
R

0

margin ¯κ

5

Figure 4. Overlap between weight vectors of diﬀerent outputs. Overlap
12 = ˇW 1T ˇW 2 between the pair of row vectors involved in the calculation of the
R=
readout covariance Q12. Symbols from numerical optimization (method=IPOPT,
see Section 4); error bars show standard error from 5 realizations of patterns and
10 initial conditions for the numerical solver; solid black line from theory in the
large m limit, which predicts R=
12 → 0. Other parameters: m = 50, n = 2,
f = 0.1, c = 0.5.

3.0.4. Replica limit q
a natural number. In order to ﬁnd the typical behavior of
us to study the limit q

0 So far, we considered q replica of the system, where q was
, the replica trick requires

V
(q2), we get

0. Using q(q

1) =

q +

→

= q

H

˜R=

ij R=

ij −

q

→
n

j
Xi
≤

−
n

−
=
ij,

˜R6

=
ij R6

O

j
Xi
≤

which gives rise to the following saddle point equations
m
q

=
ij =

, R6

m
q

ij =

R=

)

−

)

∂ ln(
F
=
∂ ˜R6
ij
n

˜R=

ij =

p
q

−

∂ ln(

Gkl)

∂R=
ij

,

˜R6

=
ij =

p
q

∂ ln(

Gkl)

.

∂R6

=
ij

Xk<l

The above equations show that we need to ﬁnd the contribution of ln(
0 limit.
proportional to q as this is the only term surviving in the q

F

→

∂ ln(
F
∂ ˜R=
ij
n

Xk<l

(29)

(30)

(31)

) and ln(

Gij )

(κ),

→ P

(κ) We are interested in the limit p

3.0.5. Limiting pattern load p
→ P
=
which denotes the point where only a single solution is found: the overlap R6
ii →
R=
ii = 1 of the readout between replica is identical to the length of the vector in each
individual replicon, so only a single solution is found. So we set R6
ǫ and study
[1, m] simultaneously. We need to be careful in taking this
the limit ǫ
→
limit as ln(
Gij ) is singular for ǫ = 0. The saddle-point equations relate derivatives of
Gij ) at
). A singularity in ln(
ln(
ǫ = 0 therefore implies also a singularity in ln(
). These singularities will cancel in
the following calculation of the capacity.
We ﬁrst focus on the ﬁelds R=

Gij ) to tilde-ﬁelds, which in turn are deﬁned by ln(
F

0 for all i

=
ij (see Eq. (25)). The same is true for

=
ij for i < j: The function ln Gij depends
, which can

quadratically on R=

ij and R6

ij and R6

=
ii = 1

−

F

∈

F

Capacity of the covariance perceptron

13

)

∂ ln(

R=

ij =

2 ˜R=
ij

ij = ˜R6

=
be seen by Taylor expansion around ˜R=
ij = 0 (cp. Eq. (21)): all odd
Taylor coeﬃcients vanish since they are determined by odd moments of a Gaussian
integral with zero mean. By rewriting Eq. (31) as ˜R=
and

m
ij =
q
−
=
ij = ˜R=
ij = R6

−
∂ ln(
, respectively, and analogously for ˜R6
F
∂ ˜R=2
ij
=
ij = ˜R6
R=
ij = 0 is a solution to the saddle point equations. This solution
makes sense as R=
ij represents a displacement of the Qij irrespective of the label
ζr =
1 . Thus the perceptron would lose ﬂexibility in assigning arbitrary labels
to patterns; a non-vanishing value would therefore hinder the classiﬁcation. Figure 4
shows the numerically calculated overlap R=
ij to be close to zero, as predicted by the
theory. At the point of limiting capacity all replica ﬁnd the same solution. Therefore,
=
ij across replica must vanish. Using ˜R=
ij = 0, an analogous
also the overlap R6
procedure as in Section 3.0.4 can be performed to calculate the term ln(
) in the
q

n
G
∂R=2
k<l
ij
=
ij, we see that

p
2R=
ij
q
=
ij and R6
P

ij = ˜R6

0 limit

±

kl)

F

=

→

n

)

ln(

F

→ −

1
2

q

˜R=

ii −

=
˜R6
ii

ln

(cid:16)

(cid:17)

+ ˜R6

=
ii /

=
˜R6
ii

˜R=
(cid:16)

ii −

(cid:17)(cid:17)

+ const . (32)

i (cid:16)
X

Then Eq. (30) can be easily solved to obtain

˜R=

ii =

1

m
2

−
ǫ2

2ǫ

,

−

˜R6

=
ii =

1

m
2

−
ǫ2

ǫ

.

−

Inserting this solution into Eq. (31) and using Eq. (28), we get in the limit ǫ

(33)

0

→

n

∂

ln

erfc(akl(t))

m
2

1
ǫ2 =

−

(κ)

P

(κ)

=

P

(κ)

=

P





Xk<l
n

Xk<l Z

n

Xk<l Z

D

(cid:16)

∂R6

=
kk

(cid:17)E

Dt

∂

∂akl(t) erfc(akl(t))
erfc(akl(t))

δki + (k

l)



↔


δki +

∂akl(t)
=
∂R6
kk

∂akl(t)
=
∂R6
ll

δli

!

Dt −

2

akl(t)

2
√π e−
erfc(akl(t))  

∂akl(t)
=
∂R6
kk

δki +

∂akl(t)
=
∂R6
ll

δli

.

!

2.

→

0 the function akl(t) goes to negative inﬁnity for t > κ/

For ǫ
erfc(akl(t))
vanish. Therefore, we can restrict the integration range to t
where akl(t)
erfc(akl(t))

f c2 and
In this case the numerator in the integrand makes the integral
f c2],
0, such that we can insert the limit behavior of

for ǫ
/(√πakl(t)). Using

→ ∞
akl(t)
e−

(
−∞

p
, κ/

→

→

p

∈

2

→

2

t

f r2

κ

∂akl(t)2
=
∂R6
kk

−
2f r2(1

→ (cid:16)

(1
p

−

ǫ)2)2 +
(cid:17)

O

−

1
ǫ

(cid:18)

→

(cid:19)

(¯κ

t)2
8ǫ2 +
−

1
ǫ

(cid:19)

O

(cid:18)

,(34)

where we introduced ¯κ = κ/

f r2, the limiting number of patterns

m
ǫ2 =

(κ)

P

¯κ
p

Z

−∞

dt
√2π

exp

t2
2

(cid:19)

−

(cid:18)

(¯κ

t)2

−
4ǫ2

n

Xk<l

as

(δki + δli)

(κ) follows from

P

(κ) = 4

P

m

−

n

1

∞

¯κ

(cid:18)Z

−

dt
√2π

exp

t2
2

(cid:19)

−

(cid:18)

(t + ¯κ)2

1

−

.

(cid:19)

(35)

 
Capacity of the covariance perceptron

14

4. Results

In the following, we present the key conclusions from the theoretical derivation of Eq.
(35) as well as numerical validations.

The pattern capacity grows linearly in the number of inputs.

Analogous to the classical perceptron, the pattern capacity is an extensive quantity
in the number of inputs:
m. This result is obvious as a higher-dimensional space
facilitates classiﬁcation. Formally, this is shown by the problem factorizing in the
input indices in the saddle-point approximation.

P ∼

The pattern capacity depends on the rescaled margin.

≡

κ/

W ˜ξ

In the latter case, the result is simple as,
f c2, the inequality ζi

f c2,
The pattern capacity only depends on the margin through the parameter ¯κ
which measures the margin κ relative to the standard deviation of the readout
(Figure 5). This is also true for the classical perceptron, which was originally
analyzed for f c2 = 1.
for random
i > κ is equivalent
patterns ξ with standard deviation
f c2 = ¯κ with rescaled patterns ˜ξ of unit standard deviation. In
to ζi
(cid:1)
the case of the covariance perceptron, the situation is more subtle due to the identity
matrix contained in the patterns P = 1 + χ. However, due to the orthogonality of
the weight vectors W W T = 0 (Figure 4) the same scaling arguments hold in Eq. (9).
Note that the orthogonality arises naturally as a non-zero overlap R=
ij between diﬀerent
= j) would cause a bias in outputs and therefore hinder classiﬁcation
weight vectors (i
of Qij around zero.

i > κ/
(cid:1)

W ξ

p

p

p

(cid:0)

(cid:0)

Similarly, the replica-symmetric solution is agnostic to the speciﬁcity in patterns
=
P with regard to symmetry of χ. This can be seen from the terms including R6
ij, which
only arise due to the symmetry: the replica-symmetric solution of the saddle-point
=
equations implies R6
ij = 0, i.e. orthogonality of diﬀerent weight vectors in diﬀerent
replica. Physically, it makes sense that at the limiting pattern load, all replica behave
similarly.

In addition to the fact that for both perceptrons ¯κ is the determining quantity, the
dependence of the pattern capacity on ¯κ is also identical. The derivation in Section 3
explains this structural similarity: The functions
are the same for both
perceptrons as they follow from the length constraint on the weight vectors and the
(19). The latter are identical for both
introduction of the auxiliary ﬁelds in Eq.
perceptrons. Also the structure of
and its dependence on a(t) is the same in both
cases, resulting in the integral in Eq. (35).

and

H

F

G

A single readout has a four times higher pattern capacity than the classical
perceptron.

For a single readout (N = 1
n = 2), the pattern capacity of the covariance
perceptron is four times larger than the pattern capacity of the classical perceptron
(Figure 5b)

→

cov(¯κ) = 4

class(¯κ).

(36)

P

P

The superior pattern capacity of the covariance perceptron can be understood
intuitively: For a single readout, the problem to be solved reads Q12 = ˇW 1T P ˇW 2,

6
Capacity of the covariance perceptron

15

which is bilinear in ˇW 1 and ˇW 2, the ﬁrst and second row of the weight matrix W .
Choosing ˇW 1 as a random vector can only lead to the same or worse classiﬁcation
performance than optimizing ˇW 1 for the given set of patterns: the product ˇW 1T P
ξ
can be considered a random pattern and optimizing only ˇW 2 thus amounts to a
classical perceptron. Therefore, optimizing both, ˇW 1 and ˇW 2, the performance must
1, diﬀerent rows ˇW i are not
be larger or equal to that of a linear perceptron. For N
independent, as each row determines multiple output covariances Qij . These amount
to additional constraints in the optimization and thus a reduction in pattern capacity
(see below).

≫

≡

Formally, the diﬀerent scaling (factor 4 in Eq. 35) of the pattern capacity for the
two perceptrons comes from the squared appearance of the auxiliary ﬁelds in λ= and
= (Eq. 25), as opposed to a linear fashion for the case of the classical perceptron. In
λ6
(ǫ4)
Eq. (34), the leading behavior in the limit ǫ
rather than (1

0 is therefore (1
→
ǫ2 for the classical perceptron.

4ǫ2+

ǫ)2)2

ǫ))2

→

(1

(1

O

−

−

−

−

→

A single readout uses less resources to classify the same number of patterns than the
classical perceptron.

Given the arguments above, the higher pattern capacity of the covariance perceptron
seems natural, as a single readout already implies n = 2 outputs, i.e. twice as many
tunable weights compared to a single classical perceptron. However, the pattern
capacity is not twice as high as for the classical perceptron, as would be expected
from this doubling of weights.
Instead, the joint optimization leads to a synergy
eﬀect, giving rise to an overall diﬀerence of a factor 4 in the pattern capacity, and a
doubling in the pattern capacity per synapse (Figure 5a)

cov(¯κ) = P

ˆ
P

cov(¯κ)
2m

= 2 P

class(¯κ)
m

= 2 ˆ
P

class(¯κ).

(37)

The pattern capacity per synapse is a useful measure to compare the performance of
the two perceptrons, as it accounts for the number of tunable weights, which in turn
determine the complexity of the computational paradigm.

The pattern capacity decreases with the number of outputs.

P

∼

−

cov

(n

1)−

Contrary to classical perceptrons, which have a pattern capacity independent of n, the
pattern capacity of the covariance perceptron decreases with increasing number n of
1. This can be understood as follows: For classical
outputs (Figure 5b):
perceptrons, the weights to diﬀerent readouts are independent. Therefore, adding
more readouts does not impact the determination of possible weight conﬁgurations
of the already existing readouts. The covariance perceptron, however, constitutes a
bilinear mapping in terms of weights which leads to shared weight vectors for diﬀerent
output covariances. As an example, the weight vector for neuron 1 impacts the output
Q1j for all outputs j > 1. Thus, adding one more output, let’s say the n-th output,
to the covariance perceptron thereby imposes constraints on all n
1 other weight
vectors to the already existing outputs. This causes the classiﬁcation problem to
become harder the more output covariances have to be tuned. It explains the decline
1 in Eq. (35). Overall, the covariance perceptron
in pattern capacity by a factor n
has superior pattern capacity in the case of n < 5 outputs.

−

−

Capacity of the covariance perceptron

16

ˆP
y
t
i
c
a
p
a
c

n
r
e
t
t
a
p

4

3

2

1

0

(a)

(b)

800

cov.
class.

P
y
t
i
c
a
p
a
c

n
r
e
t
t
a
p

600

400

200

n=2
n=5
n=10
n=100
class.

m=100

0

5
margin ¯κ

0

0

5
margin ¯κ

Figure 5. Pattern capacity. (a) Pattern capacity per synapse for a single
readout as a function of the margin ¯κ = κ/pf c2 relative to the typical variance
pf c2 of an element of the readout matrix (black: covariance perceptron with
(b) Pattern capacity of the
n = 2; blue: classical perceptron with n = 1).
covariance perceptron for diﬀerent numbers of readouts (solid grey lines) in
comparison to classical perceptron (blue dashed line). Parameters: f = 0.2,
c = 0.5, m = 100.

The information capacity exceeds that of the classical perceptron.

−

1)/2 vs m bits in the input and n(n

Although the covariance perceptron can classify less patterns than the classical
perceptron in the case of many outputs, one has to take into account that each
pattern has a much higher information content in the case of the covariance perceptron
1)/2 vs n bits in the output). The
(m(m
information capacity, that is the amount of bits a classical computer would need
to store a lookup table to implement the same classiﬁcation as performed by the
covariance perceptron, is (with K = 2m(m
cov(κ) (m(m
cov(κ) =

−
Note that we here, for simplicity, considered the case f = 1 (which in general breaks the
positive deﬁniteness of the covariance patterns). The general case f
= 1 is discussed
in Section 6.3. We notice that the expression for the information capacity of the
covariance perceptron grows
1), while the former for the classical
1)/(n
perceptron grows with m2 (Eq. 7).

1)/2, L = 2n(n

1)/2) given by

1)/2 + n(n

m2(m

1)/2) .

−

∝

−

−

−

P

I

−

−

In the brain, each neuron makes up to thousands of connections. Therefore,
connections are the main objects that cost space. In addition, the number of synaptic
events per time is a common measure for energy consumption. An important measure
for classiﬁcation performance is, therefore, the information capacity per synapse ˆ
I

6
Capacity of the covariance perceptron

17

(a)

(b)

3

10

class
cov

s
s
a
l
c
ˆI
/

v
o
c
ˆI

2

10

101

3

10

2

10

1

10

0

10

−1

10

−2

10

ˆI

y
t
i
c
a
p
a
c

n
o
i
t
a
m
r
o
f
n
i

2

100

outputs n

500

0

500

outputs n

2000

Figure 6. Information capacity. (a) Information capacity per synapse as a
function of the number of outputs n for the classical (blue) and covariance (gray
shades) perceptron. Solid black curve for sparsity f = 1, dashed gray curves for
other levels of sparsity f ∈ [0, 1]. (b) Ratio ˆI cov(κ)/ˆI class(κ) given by (38) as a
function of the number of outputs n. Red dotted horizontal line at ratio 2. Other
parameters: m = 500, κ = 0.

(Figure 6). For this measure, we get

m
, n
≫
, n = m
m
, n

2
2
1
2 m
−
1
n
−
2ˆ
I

cov(κ)
class(κ)

ˆ
cov(κ)
I
ˆ
class(κ)
I

m

≪

(38)

= I
I

1
≫
≈ 

For a network with m = n, we get ˆ
class(κ), i.e. a two times larger
cov(κ)

I
information capacity than for the classical perceptron (Figure 6b). The same is true
if the number of outputs is much larger than the number of inputs. However, for
m, the covariance perceptron outperforms
networks with strong convergence, i.e. n
≪
1) that can be potentially very
the classical perceptron by a factor 2(m
1)/(n
−
large (Figure 6). Note that a similar result holds for diﬀerent levels of sparsity (see
Section 6.3, Figure 6a). Therefore, in networks that perform a strong compression of
inputs, the covariance perceptron much more eﬃciently uses its connections to store
information about the stimuli.

−

≈

The numerical solution is an NP-hard problem

To check the prediction by the theory, we compare it to numerical experiments. The
problem of ﬁnding the weight vectors can be formulated as maximizing the margin
given a certain pattern load. This approach is the same as for the classical perceptron:
Here, the training can be reduced to a quadratic programming problem [27, eq. 10.3],
the minimization of the length of the readout vector under the constraints that all
patterns be classiﬁed with unit margin.

Capacity of the covariance perceptron

18

Since the margin κ is a non-analytic function due to the appearance of the
minimum operation (1), it cannot be used directly to perform a gradient descent with
regard to the weights. We thus employ an analytical approximation of the margin,
the soft-margin

κη :=

1
η

−

p

N

ln

exp

η ζr

s Gr
s

,

−

!
(cid:1)

(cid:0)

→∞

r
X

s
X
which covaries with κ = limη
κη, and can be optimized via a standard gradient
ascent (see Section 6.1). Physically this soft-margin can be interpreted as a system
at ﬁnite inverse temperature η for which we ﬁnd the set of parameters, the weight
vectors, which maximize the free energy κη. The states of the system here comprise
}r. In the limit of vanishing temperature,
a discrete set, given by the patterns
, the soft-margin approaches the true margin. It is also obvious, by Hoelder’s
η
inequality, that the soft-margin is convex in each of the two weight vectors.

ζrP r

→ ∞

{

The resulting capacity curve is shown in Figure 7a. We observe that the achieved
margin is well below the theoretical prediction. A better numerical implementation
follows from a formulation as a quadratically constrained quadratic programming
problem (cf. Section 6.2). For general constraints, these problems are typically NP-
hard. Using an approximate procedure that iteratively improves an initial guess
(alternating directions method of multipliers (ADMM), [28]), yields a margin that
is comparable to the solution obtained by the gradient ascent for low pattern loads
and slightly superior for larger pattern loads, as shown in Figure 7. As the load
increases beyond the point ˆ
& 2, the method typically does not ﬁnd a solution
P
anymore; a large fraction of patterns have a negative margin and are thus classiﬁed
wrongly (Figure 7b). Employing, instead, an interior point optimizer (IPOPT, [29])
yields a signiﬁcantly larger margin for all pattern loads up to ˆ
3, where this
scheme breaks down (Figure 7b). The result of the interior point optimizer compares
well to the theoretical prediction in the regime of low pattern load. For larger loads,
the numerically found margin, however, is still slightly smaller than predicted by the
replica-symmetric mean-ﬁeld theory. Running the optimization for diﬀerent initial
conditions results in slightly diﬀerent results for the margin (only the maximal one is
shown in Figure 7a) indicating that the optimizer does not reliably ﬁnd the unique
solution that is predicted by the theory.

P ≈

5. Discussion

In this work, we study information processing of networks that, like biological neural
networks, process temporal signals. We investigate the scenario where the input-
output mapping is dominated by the linear response, which is a good approximation
for small signals in the typical dynamical regime of cortical networks [16, 30]. Focusing
only on the temporal mean of these signals, such networks act as a classical perceptron
if a classiﬁcation threshold is applied to the outputs. Covariances of small temporal
signals, however, transform in a bilinear fashion in terms of weights, giving rise to what
we call a ’covariance perceptron’. The presented theoretical calculations focus on the
pattern and information capacities of such a covariance perceptron. The theory uses
Gardner’s theory of connections [19] in the thermodynamic limit, toward inﬁnitely
many inputs (m
). We have shown that the covariance perceptron indeed presents
an analytically solvable model in this limit and compute the pattern capacity by replica
symmetric mean-ﬁeld theory, analogous to the classical perceptron [19]. It turns out

→ ∞

 
Capacity of the covariance perceptron

19

(a)

ˆP
y
t
i
c
a
p
a
c

n
r
e
t
t
a
p

4

3

2

1

0

IPOPT
GRAD
ADMM

(b)

1.0

s
n
i
g
r
a
m
e
v
i
t
i
s
o
p

f
o

n
o
i
t
c
a
r
f

0.5

IPOPT
GRAD
ADMM

0

margin ¯κ

4

0.0

0

2
pattern capacity ˆP

Figure 7. Numerical simulations of pattern capacity. (a) Pattern capacity
per synapse for a single-readout covariance perceptron as a function of the margin
¯κ. Symbols show maximum margin across Ninit initial conditions for diﬀerent
numerical optimizations (brown: IPOPT (Ninit = 10), orange: gradient ascent of
soft-margin (Ninit = 10), red: ADMM (Ninit = 5)); solid curve from theory in
the large m limit. (b) Fraction of positive margins as a function of the pattern
capacity per synapse for diﬀerent numerical schemes. Parameters: m = 100,
n = 2, f = 0.2, c = 0.5.

that the pattern capacity exceeds that of the classical perceptron for a single readout
covariance (n = 2), whereas it decreases in the case of many outputs. The information
capacity in bits of the covariance perceptron grows with m2(m
1), whereas
it only has a dependence as m2 for the classical perceptron. The proposed paradigm
in large and strongly convergent networks can therefore reach an information capacity
that is orders of magnitude higher than that of the classical perceptron.

1)/(n

−

−

The dependence of the pattern capacity on the number of readout neurons n is
a non-trivial result in the case of the covariance perceptron, because diﬀerent entries
Qij here share the same rows of the matrix W . These partly confounding constraints
reduce the capacity from the naively expected independence of the n(n
1)/2 readouts
1. This factor signiﬁes that with increasing numbers of readouts, the
to a factor (n
number of potentially confounding requirements on the readout vectors rises. Likewise,
the capacity cannot simply be estimated by counting numbers of free parameters.

1)−

−

−

We demonstrate in [15] that the paradigm of classiﬁcation that we analyzed here
can indeed be implemented by means of a network of linear autoregressive processes.
In particular, it is possible to derive learning rules that are local in time, which tune the
readout vectors for binary classiﬁcation of covariance patterns. Estimating covariance
patterns from a time series naturally requires the observation of the process for a
certain duration. The resulting estimation noise can be shown not to be detrimental
for the performance of the classiﬁcation [15]. The gradient-based learning rule derived
in [15] does not reach as superior performance for single readouts as derived in this

Capacity of the covariance perceptron

20

manuscript. The reason is twofold: 1. Gardner’s theory predicts the theoretical
optimum for the capacity, but it is agnostic to the learning process that should
reach this optimum. Any biophysical implementation of the learning therefore is
likely to yield worse performance. 2. The non-biophysical learning by gradient-based
soft-margin optimization studied here is also incapable of reaching the theoretical
optimum, showing that gradient-based methods struggle with the non-convexity of
the optimization problem. Yet, the learning rule in [15] yields as good results as for
the classical perceptron.

The seminal work by Gardner [19] spurred many applications and extensions. For
example, the information capacity within the error regime [31] or the computation of
the distribution of synaptic weights of the Purkinje cell [32]. Recently, the theory has
been extended to the classiﬁcation of data points that possess a manifold structure
[33]. So far, these works employed a linear mapping prior to the threshold operation.
Here we turn to bilinear mappings in terms of weights and show their tight relation
to the classical perceptron, but expose also striking diﬀerences. The bilinear mapping
that we considered arose here from the mapping of covariance matrices by a linear
network dynamics.

The reduction of dimensionality of covariance patterns —from many input nodes
to a few output nodes— implements an “information compression”. For the same
number of input-output nodes in the network, the use of covariances instead of means
makes a higher-dimensional space accessible to represent input and output, which
may help in ﬁnding a suitable projection for a classiﬁcation problem.
It is worth
noting that applying a classical machine-learning algorithm, like the multinomial
linear regressor [34], to the vectorized covariance matrices corresponds to nm(m
1)/2
weights to tune, to be compared with only nm weights in our study (with m inputs
and n outputs).

−

→ ∞

The presented calculations are strictly valid only in the thermodynamic limit
. The ﬁnite-size simulations that we presented here agree well, but also show
m
diﬀerences to the theory. The discrepancies between the analytical prediction from the
replica-symmetric mean-ﬁeld theory and the numerically obtained optimization of the
margin may have diﬀerent sources. The ﬁrst are true ﬁnite-size eﬀects. Corrections
would technically correspond to taking ﬂuctuations of the auxiliary ﬁelds into account
in addition to their saddle point values. A qualitatively diﬀerent source of discrepancy
arises from the method of training that we devised here. We ﬁrst used a gradient
ascent of a soft-margin. The latter only approximately agrees to the true margin.
Also, as the training is implemented by a gradient ascent of the margin, stopping
too early at large system size may lead to an underestimation of the theoretically
possible margin. Analogous to classical perceptron learning, which, formulated as a
support vector machine, can be recast into a quadratic programming problem [27], the
covariance perceptron maps to a quadratically constrained quadratic programming
problem. These problems are in general NP hard, so that training time increases
exponentially with system size.
It is clear that the complexity of the optimization
problem increases with pattern load, because each pattern contributes one additional
& 3.
inequality constraint. The observed deviations appear at a pattern load of
It is likely that they are due to the inability of the numerical solver to identify the
unique optimal solution.

P

Another possibility is that indeed multiple solutions with similar margins exist if
the load exceeds a certain point. This situation would correspond to replica symmetry
breaking, because the existence of multiple degenerate solutions for the readout vector

Capacity of the covariance perceptron

21

would show up as diﬀerent replica settling in either of these solutions; analogous to a
disordered system, which possesses a number of nearly degenerate meta-stable ground
states [23]. In Gardner’s theory we search for the point at which the overlap between
replica becomes unity; this assumption would have to be relaxed. It is conceivable that
instead the set of these solutions vanishes together as the pattern load is increased
beyond the capacity limit. Future work should address this question, either by
the application of more powerful numerical optimizers or by analyzing the replica-
symmetric mean-ﬁeld theory with regard to instabilities of the symmetric solution.

The analysis presented here assumed the classiﬁcation of uncorrelated patterns. In
applications, however, the data to be classiﬁed typically has some internal structure.
In the simplest case, diﬀerent patterns could be correlated with correlations of a
certain order. Second order correlations between patterns, for example, would show
up in the pattern average (15) as additional quadratic terms, which would require the
introduction of additional auxiliary ﬁelds for decoupling. A detailed analysis of this
extension is left for future work.

The approximation of the network mapping in linear response theory here leads to
a straight forward relationship between input and output covariances that is bilinear
in the feed-forward connectivity matrix. In recurrent networks, linear response theory
would amount to determining the network propagator. Such mappings are of the form
1, where H(ω) is the Fourier transform of the temporal linear
W (ω) = (1 + H(ω) J)−
response kernel of a neuron and J the recurrent connectivity. This expression shows
that the mapping between input and output covariances becomes more involved in the
recurrent setting. Analyzing this situation may be possible by expressing the matrix
inversion that appears in the propagator by help of a Gaussian integral. We leave this
problem open for future work. An alternative approach ﬁrst determines the optimal
bilinear readout, as presented here, and subsequently determines the parameters of
the recurrent network, foremost its connectivity, to implement this mapping.

Another extension consists in considering patterns of higher-than-second-order
correlations. Generalizing the obtained results, higher-dimensionality may lead
to higher information capacity when large number of inputs are considered.
In
contrast, this also implies additional constraints that limit the information capacity
as shown when increasing the number of outputs for the present case of second-order
correlations. There should thus be a trade-oﬀ for optimal information capacity that
depends on the correlation order and the number of inputs and outputs.

Going beyond linear response theory is another route that may lead to a problem
of similar structure as the system studied here. Concretely, assume the simplest setting
of a static input-output mapping described by a quadratic gain function y = f (z) = z2
k wikxk, the mean
of a neuron. When mapping the summed synaptic input zi =
of the output Yi =
ii contains a bilinear term in W that maps the matrix
of second moments ˜P of the data to the ﬁrst moment of the network’s output. This
(cid:3)
mapping is similar to the one studied here. A diﬀerence is, though, the dimension of
the output, which in the latter case equals the number of units. Analyzing this system
may be an interesting route for future studies.

W ˜P W T

P

(cid:2)

A central motivation to study the current setting comes from the need to derive
a self-consistent theory of biological information processing. As learning at the
synaptic level is implemented by covariance-sensitive learning rules, using a covariance-
based representation of information thus allows the construction of a scheme that
is consistent at all levels. A further crucial ingredient would be the study of the

Capacity of the covariance perceptron

22

covariance mapping across multiple layers of processing and including the abundant
presence of recurrence.

Acknowledgments

This work was partially supported by the Marie Sklodowska-Curie Action
(Grant H2020-MSCA-656547) of the European Commission, the Helmholtz young
investigator’s group VH-NG-1028, the European Union’s Horizon 2020 research and
innovation programme under grant agreement No. 785907 (Human Brain Project
SGA2), the Exploratory Research Space (ERS) seed fund neuroIC002 (part of the
DFG excellence initiative) of the RWTH university and the JARA Center for Doctoral
studies within the graduate School for Simulation and Data Science (SSD).

6. Appendix

6.1. Optimization of the soft-margin

In order to numerically test the theoretical predictions, we need to maximize Eq. (1). A
gradient-based optimization is, however, unfeasible due to the non-analytical minimum
operation. Therefore, as an alternative, we consider the following soft-minimum as an
objective function

O(W ) :=

κη(W ) =

−

1
η

ln

η ζr

ij(W P rW T)ij

exp

−

(cid:0)

i<j
X

(39)



(cid:1)



=

1
η

ln

p





r=1
X

1
2

=j
Xi

η ζr

ij (W P rW T)ij

−

.


(cid:1)


p

r=1
X




exp

(cid:0)

This deﬁnition has the form of a scaled (scaling parameter η) cumulant-generating
function, if we consider the patterns to be drawn randomly. In the limit η
, this
objective function will be dominated by the points with the smallest margins, so we
recover

→ ∞

η

κη(W )

→∞
→

min
ij,r

ij(W P rW T)ij
ζr

.

(40)

We use this objective function O(W ) with ﬁnite η: Larger η causes stronger
contribution of patterns classiﬁed with small margin.

(cid:0)

(cid:1)

In order to check the analytical prediction for the maximum pattern capacity

(Figure 7), we need to ﬁnd

Wopt = arg min
W

O(W ).

P

(41)

We solve the minimization problem by gradient descent, which yields, with
ij (W P rW T)ij = ζr
ζr
ij

m
kl WikP r
klWjl, the gradient
p
r

1
2

=

1
η P
= exp
P

p
r

∂Ar
ij
=j
i
∂Wuv
1
=j Ar
P
ij
i
2
ij(W P rW T)ij
η ζr
P

,

,

−
(cid:0)
η ζr
ij ) (δiu

= (

−

P
∂O(W )
∂Wuv
Ar
ij
∂Ar
ij
∂Wuv

P r

vlWjl + δju

(cid:1)

m

Xl

WikP r

kv) Ar
ij .

m

Xk

6
6
6
Capacity of the covariance perceptron

23

(a)

(b)

0.5

0.0

n
i
g
r
a
m

2
1
Q

0.5

0.0

−0.5

−1.0

0

200

400
optimization step

0

200

400
optimization step

Figure 8. Numerical optimization of soft-margin. (a) Evolution of the
12 = (W P r W T)12 in the optimization by a gradient ascent
readout covariances Qr
based on the soft-margin κη in place of κ. Each curve corresponds to one of the
p = 20 input patterns: red for ζ r
12 = −1. (b) Coevolution of
the margin κ (black curve) and the soft-margin κη (orange curve). Parameters:
m = 100, f = 0.2, c = 0.5, η = 4, ι = 0.01.

12 = 1 and blue for ζ r

We update the readout vectors by

∆Wuv =

∂O(W )
∂Wuv

,

ι

−

where ι > 0 is the learning rate, here set to be ι = 0.01. The normalization of
the readout vectors is taken care of by enforcing unit length after each learning step
(Figure 8).

6.2. Formulation as quadratically-constrained quadratic programming problem

To obtain a numerical solution for the covariance perceptron, it is convenient to
reformulate the optimization problem in the form of a quadratically constrained
quadratic programming problem. These problems frequently occur in diﬀerent ﬁelds of
science and eﬃcient numerical solvers exist. The idea is analogous to the formulation
of the support vector machine learning in terms of a quadratic programming problem
[27, eqs. (10.3) and (10.4)]. For n = 2, an equivalent problem to ﬁnding the bi-linear
Rn, i = 1, 2 that maximize the margin,
readout with unit-length readout vectors wi ∈
is the optimization problem

minimize :

2

˜w1||

||

with constraints:

2 =

˜w1||

||

2,

˜w2||

||

Capacity of the covariance perceptron

24

1 P r ˜w2 ≥
The constraints can be formulated conveniently by combining the pair of readout
R2n and deﬁning for the length constraint
vectors into a single vector v = ( ˜w1, ˜w2)
a matrix

12 ˜wT
ζr

p.

≤

≤

∈

∀

1

1

r

Aij :=

δij
i
1
≤
δij n < i

n
2n

,

≤
≤

(cid:26)

−

so that a pair of quadratic form inequality constraints vTAv
0 ﬁxes
the length of the two readout vectors to be identical. Analogously one deﬁnes for each
pattern r one matrix and a bi-linear inequality constraint to enforce a margin of at
least unity as

0 and vTAv

≥

≤

Br
ij

:=

vTBv

≥

0
ζr(P r)T

ζrP r
0

,

(cid:19)

1
2

1.

(cid:18)

The transposition of the matrix (P r)T appearing in the lower left element, for
symmetric matrices (covariances), can of course be left out. But the formulation also
holds for non-symmetric matrices. The task is thus to minimize the norm of v under
p + 2 quadratic inequality constraints. Random vectors with independent Gaussian
entries, normalized to unit length, serve as initial guess. The normalized readout
.
vectors are ﬁnally obtained as wi = ˜wi/
˜wi||
We here use an interior point method implemented in the package IPOPT [29],
with a frontend provided by the python package QCQP [28] within the domain-speciﬁc
language CVXPY [35].

||

6.3. Information capacity for sparse patterns

The number of conﬁgurations of a sparse covariance pattern is

K =

M
f M

(cid:18)

(cid:19)

2f M ,

(42)

is the number of ways to position f M non-zero entries in a single

where

M
f M

(cid:18)

(cid:19)

pattern of length M , and 2f M is the number of conﬁgurations of the non-zero entries
in a single pattern. The information capacity follows as

cov(κ) =

I

P

cov(κ)

f M + log2

(cid:20)
cov(κ) [M (f

−

≈ P

(cid:18)
S(f )) + N ]

M
f M

+ N

(cid:19)

(cid:21)

M
f M

(cid:19)

(cid:18)

=

−

M S(f ) with S(f ) = (f log2(f ) + (1

where we used log2
Although the calculations in Section 3 ignore the constraint that the covariance ma-
trices P r must be positive semideﬁnite, this constraint is ensured when using not too
f c2
dense and strong entries such that f c
only determines the scale on which the margin κ is measured, the optimal capacity
can always be achieved if one allows for a suﬃciently small margin. As shown in
Figure 6b, the level of sparsity only has a minor impact on the information capacity
per synapse when comparing to the classical perceptron.

1, thanks to the unit diagonal. Since

f ) log2(1

≪

p

−

−

f )).

REFERENCES

References

25

[1] Rosenblatt F 1958 Psychol. Rev. 65 386–408
[2] Minsky M L and Papert S A 1969 Perceptrons (Cambridge: Cambridge MIT

Press)

[3] Widrow B and Hoﬀ M E 1960 Adaptive switching circuits 1960 IRE WESCON

Convention Record (Part 4) (Los Angeles, CA: IRE) pp 96–104

[4] Hubel D H and Wiesel T N 1959 J. Physiol. 148 574–591
[5] Arieli A, Sterkin A, Grinvald A and Aertsen A 1996 Science 273 1868–1871
[6] Riehle A, Grün S, Diesmann M and Aertsen A 1997 Science 278 1950–1953
[7] Kilavik B E, Roux S, Ponce-Alvarez A, Confais J, Grün S and Riehle A 2009 J.

Neurosci. 29 12653–12663

[8] Hebb D O 1949 The organization of behavior: A neuropsychological theory (New

York: John Wiley & Sons)

[9] Hertz J, Krogh A and Palmer R G 1991 Introduction to the Theory of Neural

Computation (Cambridge, MA: Perseus)

[10] Oja E 1982 J. Math. Biol. 15 267–273.
[11] Barak O and Tsodyks M 2006 Neural Comput. 18 2343–2358
[12] Gerstner W, Kempter R, van Hemmen J L and Wagner H 1996 Nature 383 76–78
[13] Markram H, Lübke J, Frotscher M and Sakmann B 1997 Science 275 213–215
[14] Bi G and Poo M 1998 J. Neurosci. 18 10464–10472
[15] Gilson M, Dahmen D, Moreno-Bote R,

Insabato A and Helias M 2019

(bioRxiv:562546)

[16] Lindner B, Doiron B and Longtin A 2005 Phys. Rev. E 72 061919
[17] Grytskyy D, Tetzlaﬀ T, Diesmann M and Helias M 2013 Front. Comput. Neurosci.

7 131

[18] Dahmen D, Grün S, Diesmann M and Helias M 2019 Proc. Natl. Acad. Sci. USA

116(26)

[19] Gardner E 1988 J. Phys. A: Math. Gen. 21 257
[20] Cortes C and Vapnik V 1995 Machine Learning 20 273–297
[21] Pernice V, Staude B, Cardanobile S and Rotter S 2011 PLOS Comput. Biol. 7

e1002059

[22] Trousdale J, Hu Y, Shea-Brown E and Josic K 2012 PLOS Comput. Biol. 8

e1002408

[23] Fischer K and Hertz J 1991 Spin glasses (Cambridge University Press)
[24] van Vreeswijk C and Sompolinsky H 1996 Science 274 1724–1726
[25] Renart A, De La Rocha J, Bartho P, Hollender L, Parga N, Reyes A and Harris

K D 2010 Science 327 587–590

[26] Tetzlaﬀ T, Helias M, Einevoll G T and Diesmann M 2012 PLOS Comput. Biol.

8 e1002596

[27] Vapnik V N 1998 Statistical learning theory (New York: Wiley)
[28] Park J and Boyd S 2017 General heuristics for nonconvex quadratically

constrained quadratic programming (arXiv:1703.07870)

REFERENCES

26

[29] Wächter A and Biegler L T 2006 Mathematical Programming vol 106 (Heidelberg,

Berlin, New York: Springer) pp 25–57

[30] Brunel N 2000 J. Comput. Neurosci. 8 183–208
[31] Brunel N, Nadal J P and Toulouse G 1992 J. Phys. A: Math. Gen. 25 5017
[32] Brunel N, Hakim V, Isope P, Nadal J P and Barbour B 2004 Neuron 43 745–757
[33] Chung S, Lee D D and Sompolinsky H 2018 Phys. Rev. X 8 031003
[34] Bishop C M 2006 Pattern Recognition and Machine Learning (New York:

Springer)

[35] Diamond S and Boyd S 2016 J. Mach. Learn. Res. 17 1–5

