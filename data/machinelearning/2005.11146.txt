Machine Learning in the Internet of Things for Industry 4.0

Tomasz Szydlo, Joanna Sendorek, Robert Brzoza-Woch, Mateusz Windak

AGH University of Science and Technology,
Department of Computer Science, Krakow, Poland

0
2
0
2

y
a
M
2
2

]
I

N
.
s
c
[

1
v
6
4
1
1
1
.
5
0
0
2
:
v
i
X
r
a

Abstract

Number of IoT devices is constantly increasing which results in greater complexity of computations and high
data velocity. One of the approach to process sensor data is dataﬂow programming. It enables the development
of reactive software with short processing and rapid response times, especially when moved to the edge of the
network. This is especially important in systems that utilize online machine learning algorithms to analyze ongoing
processes such as those observed in Industry 4.0.
In this paper, we show that organization of such systems
depends on the entire processing stack, from the hardware layer all the way to the software layer, as well as on
the required response times of the IoT system. We propose a ﬂow processing stack for such systems along with
the organizational machine learning architectural patterns that enable the possibility to spread the learning and
inferencing on the edge and the cloud. In the paper, we analyse what latency is introduced by communication
technologies used in the IoT for cloud connectivity and how they inﬂuence the response times of the system.
Finally, we are providing recommendations which machine learning patterns should be used in the IoT systems
depending on the application type.

Keywords:

Internet of Things, Edge Computing, Machine Learning, Industrial IoT

1. Introduction

Due to the advances in electronics and computer
systems, we are observing an increasingly large num-
ber of embedded devices connected to the Internet.
Handling hundreds of thousands of interactions be-
tween such devices is a very challenging task and ap-
propriate organization of data processing is necessary.
There are several aspects that have to be dealt with in
this context, including how, where and what computa-
tions should be performed.

IoT systems often assume the interaction of devices
with cloud services which makes the Service Oriented
Architecture (SOA) a suitable approach to designing
processing logic. In that concept devices expose their
features like services, which are then consumed by
other services deployed in the cloud [1, 2]. This con-
cept has since evolved into the so-called Web Of Things
[3]. Nevertheless, the large volume of streaming data
generated by IoT devices can make that approach in-
efﬁcient. The solution to this problem is to make pro-
cessing data-driven and responsive. Flow-based pro-
gramming [4] is a paradigm that deﬁnes applications
in terms of ﬂows of processes which exchange data by
passing messages across predeﬁned connections. The
execution time of operations is dependent on their or-
der in the processing ﬂow. This concept can be adapted

for IoT, where things are sources of data streams to
be processed.
There are several runtime environ-
ments that implement this concept, such as CppFBP
[4], NoFlo [5], WotKit [6] and NodeRED.

Efﬁcient ﬂow processing of streaming data in IoT is
especially important in the industry, currently undergo-
ing revolutionary changes colloquially referred to as In-
dustry 4.0 [7]. The name refers to the notion of a fourth
industrial revolution, where the focus shifts to deliver-
ing innovative services and products. Previous stages
of the industrial revolution introduced mechanization
through the use of (1) steam engines, (2) electricity (fa-
cilitating mass production), and (3) IT solutions. The
fourth step is to use digital product models developed
according to customer requirements and manufactured
by Smart Factories [8]. Such factories will be capable
of self-planning and self-adaptation using devices com-
patible with the concept of the Internet of Things and
Cyber-Physical Systems [9].

For optimal production of goods and their subse-
quent delivery, Industry 4.0 proposes the use of ma-
chine learning mechanisms to study customer require-
ments and ensure optimal use of industrial equipment
and to enforce predictive maintenance. Self-planning
and self-adaptation processes require a collection of
knowledge from the factories, development of models
In such us-
and applying them to obtain predictions.

Preprint submitted to arXiv

May 25, 2020

 
 
 
 
 
 
age, short response times are necessary. For exam-
ple, in factory automation or motion control response
times lower than 10ms are mandatory, while process
automation can be satisﬁed with 100ms response times.
Processing ﬂows which contain machine learning algo-
rithms can be executed in the cloud, offering high pro-
cessing capacity, a global view of the IoT system and
easy management; however, this also introduces addi-
tional time delay as data has to be streamed from sen-
sors to the cloud. Deploying such ﬂows only in the fog,
on the network edge, limits knowledge sharing because
sensor data is not exchanged between remote premises
but improves system response times. Lack of infor-
mation exchange between branches may result in the
situation that the system will not be able to recognize
events that have already occurred elsewhere.

In the paper, we present the generalized concept of
a ﬂow-based processing stack and how the underlying
infrastructure may inﬂuence dataﬂow execution. We
propose three architectural patterns for machine learn-
ing algorithms that can be applied to data ﬂows prior to
their deployment and execution on real hardware. As a
result, the computation is divided into a part located in
the cloud, allowing for knowledge dissemination, and
an edge part which provides high responsiveness. The
proposed patterns provide a tradeoff between the accu-
racy of machine learning models and prediction times.
In the evaluation of the concept, we are focusing on on-
line supervised learning methods. We argue that sys-
tems based on ﬂow-based programming for IoT should
take into account a holistic view of the system [10]
which perceive the system as a whole - in particular,
the interplay of conﬂicting objectives and conﬁguration
options across all subsystems i.e. underlying hardware,
communication topology, operating systems and execu-
tion environments. The scientiﬁc contribution of the
paper includes (i) a generalized concept of a ﬂow-based
processing stack for IoT, (ii) machine learning architec-
tural patterns for IoT, (iii) evaluation of the communi-
cation technologies used in the IoT systems for cloud
connectivity, and (iv) recommendations which pattern
and communication technology is appropriate for spe-
ciﬁc types of IoT systems.

The structure of the paper is as follows. Section 2
presents the state of the art of machine learning algo-
rithms for embedded devices. In section 3 dataﬂow exe-
cution is discussed. Section 4 discusses ML for IoT and
proposes delta patterns. Section 5 contains an evalua-
tion of the proposed concepts while section 6 sums up
the paper.

2. State of the art

In large-scale computing, TensorFlow [11] is among
well recognised neural network-based machine learn-
ing systems for distributed computing platforms. Due
to multi-layer design, it runs on multiple hardware plat-
forms. Its computing tasks are dispatched to many ker-
nels running on many CPU and GPU cores. The lite
version of the TensorFlow is a set of tools to run neural
network models on mobile and embedded devices but
the machine learning model has to be optimized to run
efﬁciently on resource constrained devices. The ﬁrst
group of optimization techniques is related to the neu-
ral network accelerators. Lane et al.
[12] present a
software accelerator that enhances deep learning ex-
ecution on heterogeneous hardware, including mobile
devices. An original approach to machine learning in
resource-constrained embedded systems is presented
by Bang et al.
[13] where authors describe a hard-
ware accelerator for performing deep-learning tasks
while requiring very low power to operate. The simi-
lar chips are designed by Intel and Google. The second
group of solutions is related to the methods of neural
network parameters quantization in order to diminish
the amount of computation data storage and transfer
time [14]. There are also works related to other ma-
chine learning algorithms. Shamili et al. [15] propose
the utilization of Support Vector Machine (SVM) run-
ning on networked mobile devices to detect malware.
Implementation of algorithms related to machine learn-
ing domain on extremely resource-constrained devices
has also been described, e.g. in [16, 17].

The increased interest in systems operating on the
edge of the network has resulted in the research on
machine learning solutions that combines processing
on the network edge and in the cloud. The work of Liu
[18] describes an approach for image recogni-
et al.
tion in which the process is split into two layers: local
edge layer constructed with mobile devices and remote
server (cloud) layer. In the edge, i.e. on a mobile de-
vice, an acquired image is preprocessed and segmen-
tation is performed. Then the image is classiﬁed on a
remote server running pretrained convolutional neural
network (CNN). A more general survey on employing
networked mobile devices for edge computing is pre-
sented in [19]. There is also an ongoing research aimed
at using machine learning methods to optimize energy
consumed by the devices. Peralta et al. [20] describe
the method for sending sensor data from devices to the
cloud that ﬁlters values which could be predicted by the
machine learning methods.

In Industry 4.0, due to internal processes such as
machine ageing, an important aspect is the need for dy-
namic adaptation to new patterns in the data or when

2

the data is generated as a function of time. This means
that the aforementioned methods of moving learned
machine learning models to edge devices are insufﬁ-
cient because over time they become obsolete. Mod-
els must be constantly updated to match the current
nature of the process. A comprehensive survey on in-
cremental online learning is presented in [21]. Yin et
[22] present an application of incremental learn-
al.
ing for object recognition. In contrast, [23] describes
an application of learned navigation system to control
an autonomous robot. These publications, however,
do not concern resource-constrained or embedded sys-
tems that operate at the network edge or in a fog en-
vironment. In this paper, we propose an organizational
pattern for such machine learning algorithms on the
edge and in the cloud and then discuss its usage taking
into account the hardware capabilities of IoT systems
and the available communication technologies.

3. Dataﬂow execution

The kind of systems discussed in the paper follows
the concept of fog computing which was ﬁrst described
by Cisco [24, 25]. Fig. 1 depicts the architecture of such
systems. One of the most important factors for process-
ing data in the IoT, especially for industrial IoT, is the
fast response time. Table 1 contains the required laten-
cies for critical IoT applications [26]. The processing
ﬂow can be executed in the cloud, providing virtually
unlimited computational resources (e.g. Amazon AWS,
Microsoft Azure or Google Cloud) and network band-
width (e.g. ﬁbre links in Core Internet), but the data
transmission latency (e.g. via GSM) might be unac-
ceptable for timely reception of results. On the other
hand, executing data ﬂows in the fog layer provides
responsiveness but lacks a global view of data. This
means that, for example, in a factory, the knowledge
acquired during the processing of sensor data in one
of its branches is not transferred to another branch.
Because of this, the system may not detect potentially
dangerous situations that have already occurred.

Table 1: Required latencies for critical IoT applications

Fig. 2 depicts examples of ﬂow execution where
some elements are executed on different devices.

3

Figure 1: Fog computing architecture

Fig. 2a depicts a situation where data streams from
sensors are sent to the cloud for processing. This pro-
vides the possibility to collect data from thousands of
sensors and process it at a single site, providing a high
quality of results. On the other hand, such process-
In Fig. 2b processing
ing introduces huge latencies.
is performed locally on the edge, which ensures short
processing times, but the information is not shared be-
tween edges (e.g. several factories located on differ-
ent premises). This solution can be regarded as exe-
cution in a private cloud. Finally, Fig. 2c shows a sit-
uation where the processing logic is spread between
the fog and the cloud. Sensor data is preprocessed in
the fog and only aggregated data is sent to the cloud.
This reduces processing time and allows for knowledge
sharing between geographically distributed devices de-
ployed in the fog. Machine learning algorithms can be
used to update models in the cloud, and then move
them to the fog on a regular basis. This represents a
middle ground between the previously discussed cases.
The usability of the aforementioned deployment
models depends, among others, on the type of devices
used in the fog layer, the capability for performing
learning processes, and communication technologies.
Thus, ﬂow-based processing for IoT may be analyzed in
the context of the Flow Processing Stack (FPS). FPS is
a generic model suited for IoT solutions. It is concep-
tually presented in Fig. 3. The stack consists of four
layers:

• Flows – A data ﬂow can be described as a di-
rected graph, where vertices represent compu-
tational processes while edges deﬁne the ﬂow of
messages between them. It represents a compu-
tation from the business logic perspective without
dealing with technological aspects related to data
serialization and transmission.

• Ensembles – Ensembles are the executable el-
ements that can be deployed and executed in
the execution environments. Depending on their

Use caseLatency (ms)Factory automation0.25 - 10Motion control1Tactile Internet1Smart Grids3-20Intelligent Transport Systems10 - 100Process automation50 - 100Speech recognition350Face recognition500Embedded System and SensorsFog LayerCore IPv6 NetworkData Center/CloudLocal networksBackbone networks linksBackhaul and access linksLAN, RS485, MODBUS, BLE3G, 4G, LTE, WiFiIP/MPLS, BGPEdge datacenters, Linux based devicesConstraintresources devices, FreeRTOSVirtual Machines, SDNEfficient backbone routers and switchesFigure 2: Flow execution examples

4

Fog LayerCloudSensorsensorActuatorSensormaxaveragef(x)SensorsensorActuatorSensormaxaveragef(x)CloudEmbedded systemsSensorsensorActuatorSensormaxaveragef(x)SensorsensorActuatorSensormaxaveragef(x)Embedded systemsFog LayerEmbedded systemsEmbedded systemsSensorsensorActuatorSensormaxaveragef(x)SensorsensorActuatorSensormaxaveragef(x)Embedded systemsEmbedded systemsa)b)c)type, they can assume the form of JSON ﬁles for
NodeRED software, generated source code that
can be executed in virtual machines, lightweight
containers described by dockerﬁles or ﬁrmware
for an embedded processor.

• Execution environments – An execution envi-
ronment represents a particular execution plat-
form, such as an operating system or an appli-
cation container that manages the life-cycle of
the application. Execution environments are typ-
ically part of other computing hardware or sys-
tems. Execution environment should provide op-
erating system-level services, necessary software
libraries, required memory and processing power
as needed.
In our case, the execution environ-
ment is a ﬂow-based processing engine such as
NodeRED, uFlow [27] or others.

• Hardware infrastructure – represents the hard-
ware infrastructure upon which the execution en-
vironments and ensembles are executed. It covers
not only the devices and their capabilities but also
the network topology and communication tech-
nologies.

Figure 3: Flow Processing Stack for IoT

High-level processing ﬂows have to be transformed
into a set of ensembles that can be deployed in the
execution environments. For example, data ﬂow can
be divided into several sub-ﬂows, where some will be
executed in the NodeRED execution environments in-
stalled on various Linux devices and others on uFlow
executed on embedded devices.

In the paper, we focus on machine learning algo-
rithms and how to organize the learning and predicting
processes. In the next section, the concept of machine
learning architectural patterns will be discussed. Later
on, we analyze latencies introduced by common tech-
nologies in the network core and the backhaul that may
have an impact on latency, thus determining the appli-
cability of the system.

5

4. Machine Learning for IoT

The classic approach to machine learning for IoT as-
sumes learning using cloud computing (referred to as
Big Data ML). Data from sensors is transmitted to the
cloud for analysis over the Internet. Access to histor-
ical data stored in a central repository has a number
of advantages as it enables the development of appro-
priate machine learning methods to match the needs
of speciﬁc applications. Unfortunately, centralized data
processing also suffers from a number of drawbacks:

• the ever-growing number of devices in the Inter-
net of Things generates an increasing amount of
data that must be transmitted and stored in the
cloud;

• lack of autonomy in local subsystems (due to the
requirement to transfer data to the cloud for pro-
cessing) means that such subsystems cannot per-
form their function in the absence of network con-
nectivity;

• online systems are usually slow to respond to new
events as they must ﬁrst upload data to the cloud
(which introduces delays);

• there are consumer concerns related to the pro-
tection of private data when transferring data to
the cloud or asking for personalized results.

Moving some of the machine learning computations
closer to sensors, i.e. to the network edge (referred as
Local ML) should be transparent to machine learning
algorithms providing results comparable (in terms of
quality) with the Big Data ML approach while retaining
the scalability, personalization, conﬁdentiality, respon-
siveness and autonomy characteristic of the Local ML
approach.

In contrast to the stationary problems that can be
solved ofﬂine using machine learning algorithms, in the
IoT domain most of the problems are related to data
streams. These are generated by a number of sen-
sors deployed in real-world devices. One of the im-
portant problems related to such data is concept drift
It refers to a phenomenon where the tar-
[28, 29].
get concept changes over time. For example, the be-
haviour of customers at a shop may evolve, while ma-
chines deployed in factories may change their vibration
characteristics due to the wear of their components.
These problems can be handled by online learning algo-
rithms, where the model is continuously updated with
new data. We distinguish two main groups of such al-
gorithms – those that use new data to adjust internal
models and those that retrain themselves every time
new data is received. The former group does not need

HardwareinfrastructureFlows ExecutionenvironmentsEnsemblesto keep all training data in memory, so it is better suited
to streaming data, while the latter stores all training
data. Losing et al. analyzed various incremental online
learning algorithms [21] and discussed their applicabil-
ity to data characterized by concept drift.

Figure 4: Machine learning processing block

Fig. 4 depicts the machine learning block that can
be used in the dataﬂow. The ﬁt input trains the model
based on the provided data, partial_ﬁt corrects inter-
nal models using new data and, ﬁnally, predict uses the
internal model to estimate an output value. In the fol-
lowing subsection, we discuss the internal structure of
that block, mindful of the delta architecture concept.

4.1. Delta architecture for machine learning

Delta architecture represents a framework for
machine learning algorithms where calculations are
spread on the network edge and the cloud. Two dis-
tinct architectural layers are deﬁned:

• Collective Intelligence Layer/Central Layer based
in the cloud and used to analyze and process data
representing the so-called collective intelligence.
This layer enables the discovery of general rela-
tionships and trends present in centrally stored
data.
It can also use knowledge from services
available on the Internet.

• Edge Layer comprising devices with limited re-
sources located on the network edge and usually
operating as the Internet gateway for IoT devices.
This layer is capable of online sensor data pro-
cessing. Due to the limited capabilities of its com-
ponent devices, the volume of data that can be
processed and stored locally is limited.

Fig. 5 depicts the delta patterns for machine learn-
ing algorithms. We focus on situations where pre-
dictions using estimators should be performed on the
edge. In our patterns we distinguish four types of mes-
sages:

• S - sensor data;

• S+D - sensor data and the predicted value;

• M - serialized machine learning model;

• D - prediction/decision provided by the model.

6

The following subsections present three architec-
tural patterns of the machine learning processing
block.

4.2. Pattern 0

In pattern P0, data from sensors are aggregated
and transmitted to the cloud where BigData ML mech-
anisms generate global models of behaviour based on
the received data. The central layer processes data col-
lected from a number of devices and sites. It can adapt
to various conditions and creates general models which
are then distributed to the edge layer. Predictions per-
formed in the edge layer, based on the sensor data, can
be made locally ensuring short response times. Aggre-
gated sensor data can be sent to the cloud at an ap-
propriate time optimizing resource consumption [30].
In this pattern, learning is only performed in the cloud
layer, while predictions which apply the model occur on
the edge.

4.3. Pattern 1

In the edge learning pattern, sensor data is pro-
cessed locally by machine learning modules at the
edge. On this basis, a local machine learning model
appropriate for a limited area is trained. Knowledge
is not exchanged across edge locations. In this pattern,
machine learning models used on the edge can be set in
advance based on ofﬂine learning using historical data.

4.4. Pattern 2

The cloud learning pattern uses the mechanisms of
machine learning in the cloud layer. Data from sensors
is transmitted to the cloud where BigData ML mech-
anisms generate global models of behaviour based on
the received data. Predictions based on the acquired
knowledge are performed in the cloud. The results are
accurate but these patterns introduce the highest pro-
cessing latency.

5. Evaluation of delta patterns for machine learn-

ing

In this section, we present an experimental eval-
uation of the proposed mechanisms. Our goal was
twofold: (i) measure how the delta patterns inﬂuence
the accuracy of the common ML models and (ii) de-
termine what prediction latency can be achieved using
different back-haul technologies. Comparing both the
achieved prediction accuracy and latency using differ-
ent patterns allow suggesting pattern suitable for the
given case as presented in section 5.4.1.

For the purposes of the case study, we prepared syn-
thetic data that represent typical situations observed in

Machine Learningpredictfitpartial_fitMachine Learningpredictfitpartial_fitFigure 5: Delta Patterns

the industry. We assumed a single cloud processing in-
frastructure and ﬁve independent edge environments,
e.g. ﬁve premises with newly installed product lines or
pumps. These devices are equipped with several sen-
sors that generate streams of data representing the in-
ternal parameters of each device. All devices face the
same problem, i.e. the ageing of their components. Ma-
chine learning algorithms are used to predict the state
of the machine – from problem-free operation through
various warning states all the way to failures.

The following subsections analyze the hardware in-
frastructure of devices that might be deployed on the
edge, machine learning algorithms and, ﬁnally, back-
haul communication technologies.

5.1. Hardware infrastructure analysis

Our case study involves four hardware infrastruc-
tures, as presented in Table 2. The table shows how
processing ﬂows can be mapped to ensembles for a
given hardware infrastructure which is composed of
the three elements, i.e.
sensors, gateways and the
cloud (referring to the aforementioned fog computing
concept).

C1 and C2 are the representation of the sample pro-
cessing ﬂow from Fig. 2c. In both cases the proposed
delta pattern is P0.
In C1, the sensors send data to
gateways which transmit it to the cloud. The pattern
then determines whether to send the updated model to
the edge. The machine learning algorithms on the edge
are deployed on gateways. We have analyzed various
ML libraries, such as Weka, Moa and Python Scikit-
learn, and ﬁnally decided to use the latter in our ex-
periments. Our decision was dictated by the fact that
Python is a commonly used programming language for
IoT gateways.

In C2, the sensors equipped with GSM connectivity
are able to send data directly to the cloud. Since sen-
sors have limited resources, they cannot directly run

a Python library used previously to train ML models.
In [31] we have proposed the solution that converts
the ML model to source code and then compiles it into
device ﬁrmware. Table 3 shows how the scikit-learn
decision tree model can be transformed to C source
code for an embedded microprocessor using the library
FogML1. It is interesting to note that the Python model
serialized using the Python serialization library called
pickle is 2686 bytes long, while the binary ﬁrmware of
the C code of the predict function compiled using arm-
none-eabi-gcc is only 523 bytes long.

C3 refers to the ﬂow depicted in Fig. 2b.

In this
case, the machine learning model is trained only on
the edge, on the gateway device. The recommended
pattern is P1, where learning is performed on the
data available in the particular edge environment. Of
course, it is also possible to train ML models using Big-
Data algorithms on historical data and then embed the
ﬁnal model in the device.

C4 refers to the ﬂow depicted in Fig. 2a. Currently,
this is a typical approach used in IoT solutions that rely
on machine learning. The model is trained in the cloud
on high-performance infrastructure and exposed as a
service for devices located at the network edge. Nev-
ertheless, the data from sensors has to be sent to the
cloud and predictions have to be sent back to the sen-
sors.

Integration of the ensembles deployed in various
execution environments on different devices might be
achieved using one of the IoT communication protocols
[32]. Previously we had been relying on the MQTT pro-
tocol for that purpose [27].

5.2. Data sets with concept drift

In our experiments, we use stream datasets affected
by concept drift which reﬂects various physical phe-

1https://github.com/tszydlo/FogML accessed 04.10.2019

7

partial_fitpredictfitpartial_fitpredictfitpartial_fitfitpredictpartial_fitMLCloudMLCloudfitpartial_fitMLCloudfitpartial_fitML EdgeML EdgepredictML EdgepredictSS+DMpredictfitpartial_fitpredictfitpartial_fitPattern 0Pattern 1Pattern 2Dbufferpartial_fitpredictfitpartial_fitpredictfitpartial_fitcloudfitpredictpartial_fitML EdgeML EdgepredictML EdgepredictSS+DDpartial_fitpredictfitpartial_fitfitpredictpartial_fitMLCloudMLCloudfitpartial_fitMLCloudfitpartial_fitpredictedgeSS+DDTable 2: Case study description

Table 3: Machine learning model transformation

Python scikit-learn decision tree model

node=0 test node : go to node 1 i f X[ : , 0] <= 3.881 else to node 12.

node=1 test node : go to node 2 i f X[ : , 0] <= −0.185 else to node 7.

node=2 test node : go to node 3 i f X[ : , 1] <= −1.662 else to node 4.

node=3 l e a f node .
node=4 test node : go to node 5 i f X[ : , 1] <= 0.975 else to node 6.

node=5 l e a f node .
node=6 l e a f node .

node=7 test node : go to node 8 i f X[ : , 1] <= 0.637 else to node 9.

node=8 l e a f node .
node=9 test node : go to node 10 i f X[ : , 1] <= 4.341 else to node 11.

node=10 l e a f node .
node=11 l e a f node .

node=12 l e a f node .

Decision tree estimator for embedded processor

i n t predict ( f l o a t * x){

i f

( x[0]< 3.88166737556) {

i f

( x [0] <= −0.185908049345) {

i f

( x [1] <= −1.66271317005) {
return 3;

} else {

/ / node = 0
/ / node = 1
/ / node = 2

i f

( x [1] <= 0.975374698639) {

/ / node = 4

return 5;

} else {

return 6;

}

}

}else {

i f

( x [1] <= 0.637046217918) {

/ / node = 7

return 8;

} else {

i f

( x [1] <= 4.3416762352) {

/ / node = 9

return 10;

} else {

return 11;

}

}

}

} else {

return 12;

}

}

/ / node = 12

nomena. We have two different datasets:

• Circles – dataset consisting of points in two-
dimensional space divided into seven categories
of ﬁve hundred points each. The concept drift in
this model is represented by constant-speed rota-
tion by
720×3 per iteration. Each position change,
which produces a new point in the stream, causes
entire clusters to move.

π

• RandomTree – dataset generated with the use of
the MOA data tool2. To emulate concept drift, the
data stream comes from two RandomTree gener-
ators with different seeds, used in an alternating
fashion. It is worth noting that this kind of con-
cept drift is very slow and weak.

In the experiments, we analyze two scenarios. First,
all of the symptoms and failures are observed at each
premise. In the second scenario, at each premises one
failure category is not observed, but may appear and
should be detected – e.g. a failure that has already
appeared at other facilities. The purpose of the sec-
ond scenario is to determine how knowledge can be
shared between edges via a central processing module
in the cloud. Thus, the stream data expressing physical
phenomena is divided into ﬁve streams for each edge
premises. We use two division methods when prepar-
ing test data:

• equal – initial data stream is divided in such a
way that each category is uniformly distributed
through the edge environments,

2https://moa.cms.waikato.ac.nz/ accessed 04.10.2019

8

C1C2C3C4cloudscikit-learn softwarescikit-learn software-scikit-learn softwaregatewayscikit-learn software-scikit-learn software-sensorsFirmware for a high-performance embedded microcontrollerSketch generated for Arduino IDEFirmware for a high-performance embedded microcontrollerPython language scriptcloudPython interpreterPython interpreter-Python interpretergatewayPython interpreter-Python interpreter-sensorsARM microprocessorArduino IDE (C based)ARM microprocessorMicroPython embedded interpretersensors-gatewayWi-Fi, EthernetWi-Fi, Ethernetgateway-cloud2G, 3G, LTE-cloudVirtual MachineVirtual Machine-Virtual MachinegatewayEmbedded single-board computer-Embedded single-board computer-sensorsEmbeeded microcontroller-based device, e.g. ARM Cortex-M4ESP8266 board, e.g. NodeMCUEmbeeded microcontroller-based device, e.g. ARM Cortex-M4An Arduino-compatible hardware with a mobile connectivity shieldpatternP0P0P1P2edge parton gatewayon sensorson gatewayon sensorsFlow Processing Stack elementsUse Cases – processing approachesFlowsComponent-basedEnsemblesMachine LearningExecution environmentsConnectivity2G, 3G, LTE (no gateway)Wi-FiHardware infrastructure• without-one – stream division causes one cate-
gory to be missing in each edge environment.

The without-one method was used in order to sim-
ulate the situation when none of the edge devices has
full knowledge of the data set characteristics. In this
case, only the global model trained on the data coming
from all of the devices has the ability to recognize all
categories.

5.3. Evaluation of machine learning patterns

We analyzed several machine learning algorithms
and ﬁnally decided to use the Decision Tree Classiﬁer,
Support Vectors Machine with RBF kernel and Gaus-
sian Naive Bayes. One of the deciding factors was the
processing time of algorithms on embedded devices.

Due to the fact that the data stream is affected
by concept drift, the trained model has to follow the
changes. One of the possible solutions is to train mod-
els in a moving frame regime. In this case, the oldest
data is dropped from the frame and new data is inserted
as soon as it appears in the data stream. In our experi-
ments, we decided to retrain ML models whenever the
content of the moving frame changes. At each edge fa-
cility, the procedure applied when a new point arrives
in the stream is as follows:

1. The point is classiﬁed with the currently assem-
bled learning model. A score is calculated, which
evaluates to 0 if the point has been misclassiﬁed
and 1 otherwise. The average score for the most
recent ﬁfty samples is calculated to evaluate the
accuracy of the model.

2. The point is added to the training set (moving
frame) located in the cloud (pattern P0 or P2)
or locally (pattern P1) only in the equal division
method scenario or when it is not selected to be
abandoned in the without-one scenario for the
particular edge.

Table 4 presents results achieved in experiments
conducted for patterns P1 and P2. The size of the win-
dow on which the model is trained was 50, 150 and 300
respectively. For each case, the average model size and
average score were calculated for the next 50 consecu-
tive samples. Fig. 6 presents charts summarizing gath-
ered data.

The following main conclusions can be drawn:

• For pattern P1 and both datasets, the equal di-
vision case yields clearly better results than the
without-one case. This occurs due to the fact that
storing one common training model in the cloud
allows gathering more knowledge of data coming
from many categories.

• For pattern P2 and both datasets, the results were
similar regardless of the division method. This is
due to the fact the machine learning is performed
centrally in the cloud.

• For data characterized by stronger concept drift
(Circles dataset), moderate frame sizes yielded
the best results. Lower scores for shorter frames
are caused by the training set being too small,
while longer frames cause data to retain greater
concept drift and therefore reduced separability.

Table 5 presents results obtained for pattern P0
when the edge model changes every 150 iterations. The
model score was calculated for the ﬁrst 50 classiﬁca-
tions after each model change, and similarly for further
It can be noted that two datasets be-
classiﬁcations.
have very differently depending on the frame offset af-
ter the model change. For the dataset burdened with
higher concept drift (Circles dataset), results obtained
during the ﬁrst ﬁfty iterations after the change are sig-
niﬁcantly better than in the following two frames. This
is clearly caused by relying on more up-to-date training
data, reducing the effects of concept drift. The greater
the offset from the model change, the less up to date
the model is. For the dataset with a lower concept drift
(RandomTree), this phenomenon cannot be observed.
It is also worth noting that model size remains constant
regardless of the offset chosen.

It is interesting to note that patterns P1 and P2 yield
better results than P0 for the equal division method of
the data streams i.e. when knowledge transfer is not
necessary. In the second case with the without-one di-
vision method, P2 gives more accurate results than P0,
and P0 gives more accurate results than P1. In P0 and
P1 the decision made by the machine learning model is
reached directly on the edge; thus response times are
signiﬁcantly lower than in P2 where data has to be sent
to the cloud.

Our experiments show that it is possible to use ma-
chine learning algorithms in edge computing for non-
stationary phenomena such as ageing of machines, and
achieve short response times with moderate accuracy.
The ﬁnal results depend strongly on data distribution
on the network edge. When processes are similar in
each independent edge environment, local edge pro-
cessing is sufﬁcient. Nevertheless, when the edge en-
vironments need to exchange knowledge, cloud-based
machine learning becomes mandatory. We have also
shown that estimators trained using high-level libraries
can be transformed into source code for embedded pro-
cessors that can be ﬂashed to their internal memory.
By applying technologies such as OTA (over-the-air-
programming) these processors can be reprogrammed
at runtime.

9

Table 4: ML Patterns evaluation - P1 and P2

Figure 6: Summary of the evaluation of patterns P1 and P2 for RandomTree and Circles datasets.

10

Model sizeScoreModel sizeScoreModel sizeScoretree2591,2590,8042989,8940,9253510,5530,914svm3362,1180,9754756,8240,9826541,0590,975bayes897,0000,898897,0000,967897,0000,918tree2345,7220,8082596,2630,8163000,7180,737svm2978,3370,8183931,7730,8375231,6390,845bayes833,0000,767833,0000,825833,0000,782tree1656,7160,7251973,5980,7492100,8020,802svm2423,2290,5453756,5330,6925170,5220,745bayes904,0590,714986,8820,773993,0000,788tree1444,5060,5121656,3590,5331714,2730,606svm1803,4710,4692116,9760,5692632,3590,588bayes774,1760,537851,8240,573861,0000,598tree2584,4350,8003122,7880,9163544,0590,906svm3455,5290,9734774,7060,9946568,7060,976bayes897,0000,900897,0000,961897,0000,914tree2607,4000,8413046,7410,9103605,0470,910svm3391,8820,9754644,0000,9946435,6470,980bayes897,0000,880897,0000,951897,0000,920tree2204,7650,8042452,6080,8633158,4900,880svm4390,0000,7658355,6670,80413614,0000,784bayes993,0000,706993,0000,843993,0000,804tree2204,7650,8042452,6080,8633158,4900,880svm4390,0000,7658355,6670,80413614,0000,784bayes993,0000,706993,0000,843993,0000,804equalwithout-oneRandomTreeequalwithout-oneequalwithout-oneRandomTreeequalwithout-onePatternDatasetDivision methodML methodWindow size50150300P1CirclesP2CirclesTable 5: ML Patterns evaluation - P0

5.4. Analysis of communication technologies

Data transmission capabilities play an important
role in the operation of multi-level edge-cloud architec-
tures. We have evaluated several transmission media
in terms of applicability to the use case of transferring
ML models and control-measurement data. We chose
media commonly utilized and accepted in the indus-
try: IEEE 802.3 100BASE-TX Ethernet, 802.11 Wi-Fi,
as well as 2G and 3G mobile communication.

The conducted tests evaluate the applicability of
each medium for the C1-C4 use cases and the cor-
responding P0-P2 Delta Patterns described in this pa-
per. The data transmitted and received during the tests
is synthetic but representative of actual scenarios in
which sensor data or ML models are sent over a se-
lected medium.

As previously mentioned, adequate communication
response times depend on the purpose of each system.
Overall communication efﬁciency depends on several
factors, most importantly network response time and
transfer speed (transmission time of a given amount of
data). The energy efﬁciency of the edge-layer nodes
can be equally important, because, depending on the
use case, these nodes may be powered with renew-
able sources. First, we evaluated and compared the re-
sponse times for selected communication standards by
analyzing the ﬁrst hop response time using the tracer-
oute tool. Results are shown in Fig. 7.

A rather obvious factor which signiﬁcantly affects
the response time of a connected system is the overall
transmission delay. Further on in this paper, the entire
transfer procedure will be referred to as a transaction
while the data transfer will be called data transmission.
For small chunks of data and responsiveness analysis,
the average transmission speed given in e.g. bits/s is
less important than the overall transaction time. This is
why a second evaluation was also performed, focusing

Figure 7: First hop response time for selected communication media.

on the transmission times for four different chunks of
data that correspond to typical use cases in lower lay-
ers of the proposed systems. The test data was trans-
mitted between the communication device under test
(DUT) and a remote server using a TCP-based protocol.
Thanks to custom measurement hardware we were able
to separate the connection set-up time (i.e. setting up
a connection, disconnecting) and actual data transfer.

Figure 8: Transmission time for selected communication media.

Results of time measurement are presented in
Fig. 8. The connection set-up time can be very sig-
niﬁcant, especially in slow networks, e.g.
in 2G mo-
bile communications. Ethernet network tests results

11

Model sizeScoreModel sizeScoreModel sizeScoretree3100,2000,9183100,2000,8723100,2000,818svm4746,4400,9944698,3200,9944685,7200,984bayes897,0000,906897,0000,914897,0000,846tree3004,2000,9123004,2000,8383004,2000,798svm4719,8000,9924634,4800,9924717,0520,992bayes897,0000,928897,0000,906897,0000,822tree3353,0000,8603353,0000,8903353,0000,940svm13270,0000,80013270,0000,84013270,0000,840bayes993,0000,800993,0000,860993,0000,920tree3353,0000,8603353,0000,8883353,0000,940svm13270,0000,80013270,0000,84013270,0000,840bayes993,0000,800993,0000,860993,0000,920RandomTreeequalwithout-oneML methodOffset after model change0-4950-99100-149Circlesequalwithout-oneDatasetDivision methodmaxminmedianaveragemaxminmedianaveragemaxminmedianaveragemaxminmedianaverage2G3GWi-FiEthernet0.1110100100010000Response Timestime (ms) 2G Rx  2G Tx  2G Rx  2G Tx  2G Rx  2G Tx  2G Rx  2G Tx  3G Rx  3G Tx  3G Rx  3G Tx  3G Rx  3G Tx  3G Rx  3G Tx  Wi-Fi Rx  Wi-Fi Tx  Wi-Fi Rx  Wi-Fi Tx Wi-Fi Rx  Wi-Fi Tx  Wi-Fi Rx  Wi-Fi Tx  Ethernet Rx  Ethernet Tx 0.00.11.010.0100.00102030405060708090100 Average transaction time Average transfer time onlyData chunk sizeConnection typeTime (s)Data size (kB)are shown for the maximum chunk size only due to its
very low transmission time (resulting in high speed)
and insigniﬁcant increase in power consumption during
transmission compared to an idle state. An additional
but important factor concerns the energy efﬁciency of
the communication standard. Fig. 9 presents the com-
parison of energy requirements for the same tests as in
Fig. 8.

Figure 9: Energy requirements for selected communication media.

Many industrial connected devices such as teleme-
try appliances or automated environmental sensors uti-
lize the well-established 2G mobile communication net-
work. The standard can be used when the local system
is deployed in a place which lacks a direct Internet con-
nection or more advanced (3G, LTE) mobile network
coverage. As can be noted in the presented evalua-
tion, the responsiveness of the 2G network is relatively
poor because the transaction time in every 2G trans-
fer is longer than one second. This delay would make
2G unsuitable for modern industrial requirements (re-
fer to Table 1). As in this case computing power is
much less expensive than data transmission, an obvious
need arises for more advanced computing mechanisms
which do not require any intensive communication with
remote cloud servers.

If a relatively slow connection is available, we pro-
pose the utilization of Delta Pattern P0 or P1 in which
local processing plays a more important role than the
available connection. Patterns 0 and 1 can also be ap-
plied to devices which work in low-rate networks, such
as ZigBee. Additionally, it can be noticed that in P0 a
trained model can be transferred to a local device in
one of its background tasks, hence transmission time
becomes a less important issue.
If a direct Internet
connection is available, the use of Ethernet or Wi-Fi
network is strongly encouraged. This opens new pos-
sibilities regarding the availability of critical IoT appli-
cations (see Table 1).

Another import aspect related to network commu-
nication is access to cloud resources using backbone
links. We evaluated the latency of several Amazon Web
Services (AWS) platform instances, obtaining results

between 45ms for the closest AWS location up to 350ms
for farther locations. Based on these results we may
choose the best cloud provider location, offering the
shortest latency. The overall latency for sending data
from the fog to the cloud is the sum of latency intro-
duced by the backhaul network technology and the time
necessary to send data over the core Internet links.

5.4.1. Evaluation summary

To conclude, we assigned a recommended connec-
tion type for each of the previously mentioned applica-
tion areas. A summary is presented in Table 6. As can
be noted, the use of the proposed patterns enables sys-
tem designers to consider less demanding connectivity
for applications that would require a faster and more
expensive connection.

The main differentiating factor is the need for
knowledge transfer in the cloud between edge environ-
ments. This is expressed in the table as edge/cloud
learning and edge learning only. Another interest-
ing observation is that for applications where response
times greater than 100ms are acceptable, learning and
predicting in the cloud is sufﬁcient even for the edge
learning case where there is no direct need to transfer
knowledge. Of course, in the latter case, the edge en-
vironment is not autonomous and a persistent Internet
connection is mandatory.

Table 6: Summary of the recommended connection types for each
of the described delta patterns (letters denote connection type: A:
Ethernet, B: Wi-Fi, C: 3G or LTE, D: 2G)

6. Summary and future work

In this paper, we presented the concept of a ﬂow
processing stack for IoT that covers the IoT systems on
hardware and software layers. We also proposed ar-
chitectural patterns which, when applied to machine
learning algorithms, provide the desired quality i.e.
short response times and prediction accuracy.

We showed that the decision to apply delta patterns
which involve the distribution of learning process be-
tween the edge and the cloud depends on the com-
munication technology, proving that data ﬂows can-
not be transformed to executable ensembles without

12

 2G Rx  2G Tx  2G Rx  2G Tx  2G Rx  2G Tx  2G Rx  2G Tx  3G Rx  3G Tx  3G Rx  3G Tx  3G Rx  3G Tx  3G Rx  3G Tx  Wi-Fi Rx  Wi-Fi Tx  Wi-Fi Rx  Wi-Fi Tx Wi-Fi Rx  Wi-Fi Tx  Wi-Fi Rx  Wi-Fi Tx  Ethernet Rx  Ethernet Tx 1.00E-031.00E-021.00E-011.00E+001.00E+011.00E+020102030405060708090100 Transaction energy (J)Data transmission energy only (J)Data chunk sizeConnection typeEnergy [J]Data size (kB)PatternRecommended ConnectivityPatternRecommended ConnectivityFactory automation0.25 - 10A, B, C, D-Motion control1A, B, C, D-Tactile Internet1A, B, C, D-Smart Grids3-20A, B, C, D-P0A, B, C, D-P2A-P0A, B, C, D-P2A, B, C-A, B, C-A, B, C-A, B, C-A, B, C-Use caseLatency (ms)Edge/Cloud LearningEdge Learning OnlyP0P1Process automation50 - 100Speech recognition350P2Face recognition500Intelligent Transport Systems10 - 100prior analysis of the underlying hardware infrastruc-
ture and network topology. Additional results include
transfer times and required energy for data sizes of IoT
and edge-related tasks, such as sending sensor data
and transferring machine learning models. As future
work, we plan to evaluate the monitoring metrics for
hardware infrastructures and sensor data that would
prompt the use of appropriate delta patterns for ma-
chine learning.

Acknowledgements

The research presented in this paper was partially
supported by the National Centre for Research and De-
velopment (NCBiR) under Grant No. LIDER/15/0144/L-
7/15/NCBR/2016.

References

[1] V. Rajesh, J. Gnanasekar, R. Ponmagal, P. Anbalagan, Integra-
tion of wireless sensor network with cloud, in: Recent Trends
in Information, Telecommunication and Computing (ITC), 2010
International Conference on, IEEE, 2010, pp. 321–323.

[2] R. Brzoza-Woch, P. Nawrocki, FPGA-Based Web Services–
Inﬁnite Potential or a Road to Nowhere?, IEEE Internet Com-
puting 20 (1) (2016) 44–51.

[3] D. Guinard, V. Trifa, Building the Web of Things: With Examples
in Node.Js and Raspberry Pi, 1st Edition, Manning Publications
Co., Greenwich, CT, USA, 2016.

[4] J. P. Morrison, Flow-Based Programming: A new approach to

application development, CreateSpace, 2010.

[5] H. Bergius, Noﬂo–ﬂow-based programming for javascript, URL:

http://noﬂojs. org.

[6] M. Blackstock, R. Lea, Iot mashups with the wotkit, in: Inter-
net of Things (IOT), 2012 3rd International Conference on the,
IEEE, 2012, pp. 159–166.

[7] M. Hermann, T. Pentek, B. Otto, Design principles for industrie
4.0 scenarios, in: System Sciences (HICSS), 2016 49th Hawaii
International Conference on, IEEE, 2016, pp. 3928–3937.
[8] M. Brettel, N. Friederichsen, M. Keller, M. Rosenberg, How vir-
tualization, decentralization and network building change the
manufacturing landscape: An industry 4.0 perspective, Interna-
tional Journal of Mechanical, Industrial Science and Engineer-
ing 8 (1) (2014) 37–44.

[9] E. A. Lee, Cyber physical systems: Design challenges, in: 2008
11th IEEE International Symposium on Object and Component-
Oriented Real-Time Distributed Computing (ISORC), 2008, pp.
363–369.

[10] B. Balis, R. Brzoza-Woch, M. Bubak, M. Kasztelnik, B. Kwolek,
P. Nawrocki, P. Nowakowski, T. Szydlo, K. Zielinski, Holistic ap-
proach to management of it infrastructure for environmental
monitoring and decision support systems with urgent comput-
ing capabilities, Future Generation Computer Systems 79 (Part
1) (2018) 128 – 143.

[11] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean,
M. Devin, S. Ghemawat, G. Irving, M. Isard, et al., Tensorﬂow:
A system for large-scale machine learning., in: OSDI, Vol. 16,
2016, pp. 265–283.

[12] N. D. Lane, S. Bhattacharya, P. Georgiev, C. Forlivesi, F. Kawsar,
Accelerated deep learning inference for embedded and wear-
able devices using deepx, in: Proceedings of the 14th Annual
International Conference on Mobile Systems, Applications, and
Services Companion, ACM, 2016, pp. 109–109.

[13] S. Bang, J. Wang, Z. Li, C. Gao, Y. Kim, Q. Dong, Y.-P. Chen,
L. Fick, X. Sun, R. Dreslinski, et al., 14.7 a 288µw pro-
grammable deep-learning processor with 270kb on-chip weight
storage using non-uniform memory hierarchy for mobile intelli-
gence, in: Solid-State Circuits Conference (ISSCC), 2017 IEEE
International, IEEE, 2017, pp. 250–251.

[14] H. Sharma, J. Park, N. Suda, L. Lai, B. Chau, V. Chandra, H. Es-
maeilzadeh, Bit fusion: Bit-level dynamically composable archi-
tecture for accelerating deep neural networks, in: Proceedings
of the 45th Annual International Symposium on Computer Ar-
chitecture, ISCA ’18, IEEE Press, Piscataway, NJ, USA, 2018,
pp. 764–775. doi:10.1109/ISCA.2018.00069.
URL https://doi.org/10.1109/ISCA.2018.00069

[15] A. S. Shamili, C. Bauckhage, T. Alpcan, Malware detection on
mobile devices using distributed machine learning,
in: Pat-
tern Recognition (ICPR), 2010 20th International Conference
on, IEEE, 2010, pp. 4348–4351.

[16] C. Gupta, A. S. Suggala, A. Goyal, H. V. Simhadri, B. Paran-
jape, A. Kumar, S. Goyal, R. Udupa, M. Varma, P. Jain, Protonn:
Compressed and accurate knn for resource-scarce devices, in:
International Conference on Machine Learning, 2017, pp. 1331–
1340.

[17] A. Kumar, S. Goyal, M. Varma, Resource-efﬁcient machine learn-
ing in 2 kb ram for the internet of things, in: International Con-
ference on Machine Learning, 2017, pp. 1935–1944.

[18] C. Liu, Y. Cao, Y. Luo, G. Chen, V. Vokkarane, Y. Ma, S. Chen,
P. Hou, A new deep learning-based food recognition system for
dietary assessment on an edge computing service infrastruc-
ture, IEEE Trans. Services Computing 11 (2) (2018) 249–261.

[19] T. X. Tran, M.-P. Hosseini, D. Pompili, Mobile edge comput-
ing: Recent efforts and ﬁve key research directions, MMTC
Communications-Frontiers 12 (4) (2017) 29–34.

[20] G. Peralta, M. Iglesias-Urkia, M. Barcelo, R. Gomez, A. Moran,
J. Bilbao, Fog computing based efﬁcient iot scheme for the in-
dustry 4.0, in: 2017 IEEE International Workshop of Electron-
ics, Control, Measurement, Signals and their Application to
Mechatronics (ECMSM), 2017, pp. 1–6. doi:10.1109/ECMSM.
2017.7945879.

[21] V. Losing, B. Hammer, H. Wersing, Incremental on-line learning:
A review and comparison of state of the art algorithms, Neuro-
computing 275 (2018) 1261–1274.

[22] S. Yin, X. Xie, J. Lam, K. C. Cheung, H. Gao, An improved incre-
mental learning approach for kpi prognosis of dynamic fuel cell
system, IEEE transactions on cybernetics 46 (12) (2016) 3135–
3144.

[23] A. Provodin, L. Torabi, B. Flepp, Y. LeCun, M. Sergio, L. D.
Jackel, U. Muller, J. Zbontar, Fast incremental learning for off-
road robot navigation, CoRR abs/1606.08057.

[24] F. Bonomi, R. Milito, J. Zhu, S. Addepalli, Fog computing and its
role in the internet of things, in: Proceedings of the ﬁrst edition
of the MCC workshop on Mobile cloud computing, ACM, 2012,
pp. 13–16.

[25] S. Yi, C. Li, Q. Li, A survey of fog computing: concepts, appli-
cations and issues, in: Proceedings of the 2015 Workshop on
Mobile Big Data, ACM, 2015, pp. 37–42.

[26] P. Schulz, M. Matthe, H. Klessig, M. Simsek, G. P. Fet-
tweis, J. Ansari, S. A. Ashraf, B. Almeroth, J. Voigt, I. Riedel,
A. Puschmann, A. Mitschele-Thiel, M. Muller, T. Elste,
M. Windisch, Latency critical iot applications in 5g: Perspec-
tive on the design of radio interface and network architecture,
IEEE Communications Magazine 55 (2) (2017) 70–78.

[27] T. Szydlo, R. Brzoza-Woch, J. Sendorek, M. Windak, C. Gniady,
Flow-based programming for iot leveraging fog computing, in:
2017 IEEE 26th International Conference on Enabling Tech-
nologies:
Infrastructure for Collaborative Enterprises (WET-
ICE), 2017, pp. 74–79.

[28] G. Ditzler, M. Roveri, C. Alippi, R. Polikar, Learning in non-
stationary environments: A survey, IEEE Computational Intel-

13

ligence Magazine 10 (4) (2015) 12–25.

[29] J. a. Gama, I. Žliobait˙e, A. Bifet, M. Pechenizkiy, A. Bouchachia,
A survey on concept drift adaptation, ACM Comput. Surv. 46 (4)
(2014) 44:1–44:37.

[30] T. Szydlo, P. Nawrocki, R. Brzoza-Woch, K. Zielinski, Power
aware mom for telemetry-oriented applications using gprs-
enabled embedded devices a levee monitoring use case,
in:
M. P. M. Ganzha, L. Maciaszek (Ed.), Proceedings of the 2014
Federated Conference on Computer Science and Information
Systems, Vol. 2 of Annals of Computer Science and Information
Systems, IEEE, 2014, pp. pages 1059–1064.

[31] T. Szydlo, J. Sendorek, R. Brzoza-Woch, Enabling machine learn-
ing on resource constrained devices by source code genera-
tion of the learned models, in: Y. Shi, H. Fu, Y. Tian, V. V.
Krzhizhanovskaya, M. H. Lees, J. Dongarra, P. M. A. Sloot (Eds.),
Computational Science – ICCS 2018, Springer International
Publishing, Cham, 2018, pp. 682–694.

[32] A. Al-Fuqaha, M. Guizani, M. Mohammadi, M. Aledhari,
M. Ayyash, Internet of things: A survey on enabling technolo-
gies, protocols, and applications, IEEE Communications Sur-
veys & Tutorials 17 (4) (2015) 2347–2376.

14

