Edge Learning with Unmanned Ground Vehicle:
Joint Path, Energy and Sample Size Planning

Dan Liu, Shuai Wang, Zhigang Wen, Lei Cheng, Miaowen Wen and Yik-Chung Wu

1

0
2
0
2

p
e
S
7

]
P
S
.
s
s
e
e
[

1
v
0
4
1
3
0
.
9
0
0
2
:
v
i
X
r
a

Abstract—Edge learning (EL), which uses edge computing as
a platform to execute machine learning algorithms, is able to
fully exploit the massive sensing data generated by Internet
of Things (IoT). However, due to the limited transmit power
at IoT devices, collecting the sensing data in EL systems is a
challenging task. To address this challenge, this paper proposes
to integrate unmanned ground vehicle (UGV) with EL. With such
a scheme, the UGV could improve the communication quality by
approaching various IoT devices. However, different devices may
transmit different data for different machine learning jobs and
a fundamental question is how to jointly plan the UGV path,
the devices’ energy consumption, and the number of samples
for different jobs? This paper further proposes a graph-based
path planning model, a network energy consumption model and
a sample size planning model that characterizes F-measure as a
function of the minority class sample size. With these models, the
joint path, energy and sample size planning (JPESP) problem is
formulated as a large-scale mixed integer nonlinear programming
(MINLP) problem, which is nontrivial to solve due to the high-
dimensional discontinuous variables related to UGV movement.
To this end, it is proved that each IoT device should be served only
once along the path, thus the problem dimension is signiﬁcantly
reduced. Furthermore, to handle the discontinuous variables, a
tabu search (TS) based algorithm is derived, which converges
in expectation to the optimal solution to the JPESP problem.
Simulation results under different task scenarios show that our
optimization schemes outperform the ﬁxed EL and the full path
EL schemes.

Index Terms—Edge learning, Internet of Things, mixed integer

nonlinear programming, unmanned ground vehicle.

This work was supported in part by the National Key R&D Program of
China under Grant No.2019YFF0302601, in part by the Shenzhen Funda-
mental Research Program under Grant JCYJ20190809142403596, in part by
the Guangdong Basic and Applied Basic Research Foundation under Grant
2019A1515111140, in part by the Fundamental Research Funds for the Central
Universities under Grant 2019SJ02, and in part by the Open Research Fund
from Shenzhen Research Institute of Big Data under Grant 2019ORF01012.
(Corresponding Author: Shuai Wang).

Dan Liu and Zhigang Wen are with the Beijing Key Laboratory of Work
Safety Intelligent Monitoring, Department of Electronic Engineering, Beijing
University of Posts and Telecommunications, Beijing 100876, China (e-mail:
dandanmessage@bupt.edu.cn, zwen@bupt.edu.cn).

Shuai Wang is with the Department of Electrical and Electronic Engi-
neering, Southern University of Science and Technology, Shenzhen 518055,
China, and is also with the Department of Computer Science and Technology,
Southern University of Science and Technology, Shenzhen 518055 (e-mail:
wangs3@sustech.edu.cn).

Lei Cheng is with the Shenzhen Research Institute of Big Data, Shenzhen,

Guangdong, P. R. China (e-mail: leicheng@sribd.cn).

Miaowen Wen is with the School of Electronic and Information Engineer-
ing, South China University of Technology, Guangzhou 510641, China (e-
mail: eemwwen@scut.edu.cn).

Yik-Chung Wu is with the Department of Electrical

and Elec-
tronic Engineering, The University of Hong Kong, Hong Kong (e-mail:
ycwu@eee.hku.hk).

I. INTRODUCTION

Edge learning (EL) is an emerging intelligent system that
integrates ubiquitous sensing (e.g., camera, Lidar), wireless
communication (e.g., cellular network, Wi-Fi), and machine
learning (e.g., regression, classiﬁcation) [1]. In contrast to
single-machine learning systems [2], [3] where data needs to
be centralized, EL does not have such drawbacks as sensing
devices can share resources with each other. With a growing
number of participants, the learning performance of EL can be
improved. Furthermore, the EL system uses edge computing
as a platform to train and execute deep learning algorithms.
Therefore, the enormous Internet of Things (IoT) data and
computing resources in the network become closer, which
signiﬁcantly reduces the communication latency and loading
to other part of the network. Based on the above reasons,
EL is envisioned as a necessary component
in the sixth
generation (6G) telecommunication system [4], and is believed
to accelerate the convergence of many relevant research ﬁelds
including industry electronics, unmanned systems, wireless
communications, machine learning, and automatic control.

A. Background

The development of EL is mainly based on the following

techniques:

1) Internet of Things. The IoT is envisioned as a world-wide
network infrastructure composed of numerous embedded
devices with sensors and electronics [5], [6]. In the IoT,
the devices are generally wireless-interconnected, and it
is expected that the number of connected IoT devices will
exceed 50 billion by 2020 [7]. The gigantic quantities of
IoT devices will generate zillions Bytes of data, which
consequently leads to a key challenge: The generated
massive data require intensive computation and energy
resources for signal processing, while the IoT devices
are computation and energy limited [8].

2) Edge Computing. To address the challenges in IoT, edge
computing (EC) deploys computing servers at the edge
of the network, which is in close proximity to the
data source. The vast available resources in the edge
servers can be leveraged to provide elastic data collection,
storage, and processing power to support capability-
constrained IoT devices [9], [10]. Compared to the cloud
computing paradigm, EC delivers several beneﬁts, in-
cluding shortened service delay, reduced communication
overhead, as well as increased security, and is suitable for
the scenarios involving delay-sensitive applications [11],
[12].

 
 
 
 
 
 
3) Deep Learning. Recently, deep learning has been applied
to many IoT applications, since it can extract insights for
high-quality decision making and trend prediction with
the large-scale data generated from enormous amount of
IoT devices [13], [14]. In particular, with the growing
ubiquity of camera-enabled IoT devices, a huge volume
of images are being produced everyday, and convolutional
neural networks (CNNs) have been considered as the
dominant strategy [15], [16]. However, the CNN models
in existing research works are mostly deployed at the
is necessary to push the CNN models
cloud, and it
towards the edge for IoT applications.

B. Challenges of EL and Proposed EL-UGV

In EL systems, there are three major challenges.
1) Optimizing for Learning Performance. In traditional wire-
less communications, all data are treated equally, and the
objective is to maximize the system throughput under a
variety of budget constraints (e.g., power, time, band-
width constraints). In contrast, wireless communication
in EL should maximize the learning performance. There-
fore, it is necessary to distinguish the value of data in
the context of machine learning and transmit high-valued
data with priority.

2) Pathloss in Wireless Communications. In cloud learning
systems, different devices are connected via Internet.
In contrast, the devices in EL are connected through
wireless. Due to signal attenuation during propagation of
wireless signals, the performance of EL will be limited
by the pathloss and noises of wireless channels.

3) Limited Energy at IoT Devices. Due to the huge volume
and the small size, most IoT devices cannot employ large
batteries. Therefore, their transmit powers are in the order
of mW or even uW, making it difﬁcult to collect their data
from far-away base stations.

In order to address the above challenges, this paper proposes
a novel EL framework that integrates unmanned ground ve-
hicles (UGVs) into EL. The proposed framework is therefore
termed EL with UGV (EL-UGV). The EL-UGV consists of:
1) a sample size planning module that collects more samples
for difﬁcult learning jobs and fewer samples for easy jobs; 2)
a path planning module that selects the target stopping points
and the corresponding moving routes; 3) an energy planning
module that automatically ﬁnds the best trade-off between
moving energy and communicating energy. The three modules
together contribute to a joint path, energy and sample size
planning (JPESP) optimization problem that maximizes the
learning performance of EL.

However, since the collected data samples could be im-
balanced among different classes, existing learning accuracy
model in [17], [18] is not applicable. To maximize the learning
performance under imbalanced data, the proposed sample size
model characterizes F-measure as a function of the minority
class sample size. On the other hand, a graph-based path
planning model and a network energy consumption model
are used to describe the mobility of UGV and the trans-
mission costs at IoT. With the proposed models, the JPESP

2

problem turns out to be a large-scale mixed integer nonlinear
programming (MINLP) problem, which is nontrivial to solve
due to the high-dimensional discontinuous variables related
to UGV movement. To this end, it is ﬁrst proved that each
IoT device should be served only once along the path, thus
allowing us to reduce the problem dimension by a factor of
J (i.e., the number of UGV stopping points). Furthermore, to
handle the discontinuous variables, a tabu search (TS) based
algorithm is derived, which converges to the optimal solution
of the JPESP problem. Simulation results under different task
scenarios verify our optimization scheme and show that the
performance outperforms other benchmark schemes such as
the ﬁxed EL and the full path EL schemes. To sum up, the
main contributions of the paper are listed as follows.

• First, we consider a novel UGV-enabled mobile EL com-
munication (EL-UGV) system, which supports multiple
deep learning tasks and accesses the IoT devices via time
division multiple access (TDMA) protocol. To the best
of the authors’ knowledge, currently there is no research
work focusing on the combination of UGV and EL.
• Next, considering the collected data samples are usually
imbalanced, we use F-measure instead of accuracy as
the performance metric to evaluate the EL performance.
Moreover, a novel learning performance model that char-
acterizes F-measure as a function of the minority class
sample size is proposed.

transmission time,

• Based on the proposed learning model, we then establish
a JPESP problem that is maximizing the minimum F-
measure for all tasks by jointly optimizing the UGV
path,
transmission power, and the
minimum number of samples among all classes, subject
to constraints of communication capacity, total execution
time, total energy consumption and the graph mobility.
• Finally, to solve the challenging large-scale MINLP prob-
lem, we prove that each IoT device should be served only
once along the path and derive the TS-based algorithm to
optimize the UGV path. Simulation results are presented
to validate our analysis.

C. Outline

The rest of this paper is organized as follows. Section II
presents the related works on path planning, energy planning,
and sample size planning. Section III introduces the system
model for the EL-UGV system, which consists of path plan-
ning model, energy planning model, and sample size planning
model. Section IV proposes the F-measure model and its curve
ﬁtting procedure. Section V formulates the JPESP problem,
derives the TS-based path design algorithm, and considers the
practical implementation. Simulation results are presented in
Section VI and conclusions are drawn in Section VII.

Notation. Symbol notations are summarized in Table I.

II. RELATED WORKS

A. Path Planning

For UGV [19], due to the limitation of energy resources and
the hostility of wireless channel, its path greatly inﬂuences

3

TABLE I
SUMMARY OF SYMBOL NOTATIONS

Variable
sj ∈ {0, 1}
Erj ,ri ∈ {0, 1}
tu,j ∈ [0, Tj]
pu,j ∈ [0, Pmax]
Parameter
U
R
M
Cm
A
(w, b)
J
L
R
Di,j
(γ1, γ2)
v
Tj
Pmax
ǫ ∈ (0, 1)
hu,j
Gc,m
(θ1,m, θ2,m, θ3,m)
Tall
Eall
σ2

Description
sj = 1 represents the vertex j appears in the routing path; sj = 0 otherwise.
Erj ,ri = 1 represents the edge (rj , ri) being involved in the path; Erj ,ri = 0 otherwise.
Time (in s) allocated to device u when UGV is stopping at the vertex j.
Transmit power (in Watt) allocated to device u when UGV is stopping at the vertex j.
Description
Number of IoT devices.
Number of steps.
Number of tasks.
Number of classes of image samples for task m.
The data amount (in bits) for each image sample.
Parameters of CNN model, where w is the weights and b is the biases.
Set of J vertices standing for the possible stopping points.
Set of directed edges standing for the feasible movement routes.
Routing path.
Distance between vertex i and vertex j.
Parameters related to the weight of UGV.
Constant speed (in m/s) of the UGV.
Duration when UGV stops at vertex j.
Maximum transmit power at devices.
Hyper-parameter that balances the energy consumption between UGV and devices.
Uplink channel from device u to UGV.
The set of all devices transmitting the samples for class c of task m.
Parameters to be determined by the data sets and CNN model.
Completion time (in s) including UGV moving and data transmission.
Energy budget (in Joule).
Receiver additive white Gaussian noise (AWGN) power noise power (in Watt).

the efﬁciency of data gathering and consequently affects
the system performance. While the path planning problem
is extremely difﬁcult to solve as it is NP-hard [20]–[22],
fortunately, the meta-heuristic search algorithm is a promising
way to handle the problem [23], and several meta-heuristic
algorithm based methods have been presented to design UGV’s
optimal path so far. Adam et al. [24] proposed a modiﬁed
particle swarm optimizer (PSO) to heuristically solve the
Solar-Powered UGV motion planning problem that minimizes
the travel time while considering the net energy constraint.
Mohammad et al. [25] developed an ant colony optimization
strategy called green ant for UGV path planning that jointly
considers the UGV energy consumption. You-Chiun et al. [26]
used a local search based efﬁcient path planning algorithm
for mobile sink to realize reliable data gathering. However, no
methodology of UGV’s path planning has yet been considered
in EL systems.

B. Energy Planning

An important issue for wireless communication systems is
energy planning. So far researchers have applied joint time
and power optimization approaches and energy minimization
techniques. For example, Qingqing et al. [27] jointly optimized
time allocation and power control for maximization of the
weighted sum of the user energy efﬁciencies for wireless
powered communications system. Following this, for the same

system, Qingqing et al. [28] maximized the weighted sum rate
of the devices in the consideration of downlink and uplink time
allocation and the power control at the devices. Bin et al. [29]
proposed a joint time scheduling and power allocation scheme
to optimize the sum-rate for relay assisted batteryless IoT
Networks. Qizhong et al. [30] minimized overall downlink and
uplink energy consumption in WET-enabled Networks. Thang
X et al. [31] considered a energy minimization technique
for cache-assisted content delivery networks with wireless
backhaul. However, there have been no detailed studies about
energy planning for UGV-based EL, taking into account the
motion energy and communication energy.

C. Sample Size Planning

For sample size planning,

the overall/average accuracy
(OA/AA) is commonly used to assess the effect of the dataset
size on learning performance. For example, Junghwan et al
[32] employed the AA to exam learning performance at given
training sample size in CNN-based medical image classiﬁ-
cation systems. However, in practice the collected data are
typically imbalanced (i.e., the number of training samples in
one class may be much less than that in another), and OA/AA
is not suitable for this case since it neglects the minority
class and is strongly biased towards the majority class, which
leads to misleading conclusions [33], [34]. F-measure is a
more favorable and meaningful performance measure than

OA/AA for the imbalanced data and has been widely used in
classiﬁcation performance of CNN models in recent works.
For example, Guanbin et al. [35] employed F-measure to
evaluate the performance of the proposed multiscale deep
CNN features based visual saliency model. Minghui et al.
[36] investigated a CNN-based end-to-end trainable fast scene
text detector, i.e., TextBoxes++, and used F-measure as the
performance measure to verify its accuracy and efﬁciency.
Prashant et al. [37] proposed a compact end-to-end deep CNN
for moving object detection named MSFgNet, and used F-
measure to evaluate its performance. However, very limited
research has been focused on F-measure in EL system.

III. SYSTEM MODEL

We consider an UGV-enabled mobile EL communication
(EL-UGV) system shown in Fig. 1, which consists of a
surveillance UGV and U IoT devices. In particular, the goal of
the UGV is to train m classiﬁcation models for object recog-
nition by collecting Cm classes of image samples observed
at the U devices (e.g., camera sensors). It is assumed that
each device transmits one class of images for one learning
task and the samples from each device are independently
and identically distributed. In order to achieve a satisfactory
learning performance, deep learning technique (e.g., AlexNet
shown in Fig. 1), which uses multiple layers of nonlinear
processing units such that the end-to-end model matches the
data very well, is adopted. However, the samples for tuning
the deep learning models’ parameters are generated from IoT
devices that could be far away from the UGV. Therefore, the
UGV needs to complete two steps: 1) move around to approach
various devices and 2) collect samples to learn from the data.
Below, we present the details of the two steps.

A. Path Planning Model

To model the mobility of UGV, a directed graph (J ,L) is
adopted, where J = {1, ..., J} denotes the set of J vertices
standing for the possible stopping points, and L denotes the set
of directed edges standing for the feasible movement routes.
Based on this graph, the UGV needs to determine a routing
path R = (r1, ..., rR) with ri ∈ J for any i = 1, · · · , R and
(ri, ri+1) ∈ L for any i = 1, · · · , R − 1, where R stands for
the number of steps to be taken. This path can be equivalently
described by a vertex selection variable s = [s1, · · · , sJ ]T and
a path selection matrix

E =



E1,1
· · ·
EJ,1

· · · E1,J
· · ·
· · ·
· · · EJ,J

,



(1)



where we use sj = 1 if vertex j appears in the R and sj = 0
otherwise, and Eri,ri+1 = 1 with i = 1, · · · , R − 1 and zero
otherwise. The vertex section variable and the path selection
matrix should satisfy E ∈ Q(s), where



Q(s) =

E :

(

J

i=1
X

J

Erj ,ri =

Eri,rj = sj, ∀j,

(2a)

i=1
X
J

ηi − ηj +

sr − 1

r=1
X

Erj ,ri

!

J

+

sr − 3

r=1
X
J

Eri,rj

!

≤

sr − 2 + J0(2 − si − sj),

r=1
X

∀i, j ≥ 2, i 6= j,
P

sj ≤ ηj ≤

sr − 1

sj, ∀j ≥ 2,

!

r=1
X

Erj ,ri ∈ {0, 1} , ∀i, j, Erj ,rj = 0, ∀j,

s1 = 1, sj ∈ {0, 1} , ∀j ≥ 2

.

)

4

(2b)

(2c)

(2d)

(2e)

The constraint (2a) guarantees that each vertex in the routing
path must have one edge pointing toward it and the other
edge pointing away from it. The constraints (2b) and (2c)
are subtour elimination constraints, which guarantee that the
path must be connected. The constraint (2d) represents whether
edge (rj, ri) from candidate rj to ri belongs to the routing
path, and constraint (2e) represents whether candidate vertex
j appears in the routing path. Notice that {ηj} represent slack
variables to guarantee a connected trajectory and J0 is a
constant set to J0 = 106.

B. Energy Planning Model

Having speciﬁed the path planing model, the next step
is to model the energy consumption, which consists of two
parts, i.e., UGV motion energy and users’ transmission energy.
To compute UGV motion energy, the moving distance is
computed as Tr(DT E), where Di,j is the distance between
vertex i and vertex j1. Therefore, the total motion energy in
Joule is given by

Θ(E) = Tr(DT E)

×

Distance

(cid:16)

γ1
v

+ γ2

,

(cid:17)

(3)

|

{z

where v is the UGV speed in m/s, and (γ1, γ2) are parameters
}
related to the weight of UGV (e.g., for the considered Pioneer
3DX robot, we have γ1 = 0.29 and γ2 = 7.4 [38, Sec. IV-C].
Accordingly, the total motion time of UGV along path R can
be expressed as

tUGV(E) =

Tr(DT E)
v

.

(4)

On the other hand, without loss of generality, we suppose
that the UGV stops at a particular vertex j ∈ R for a duration
of Tj. Out of this Tj, the UGV allocates tu,j ≤ Tj to collect
samples from device u ∈ [1, U ], and the transmit power at the
IoT device u for uploading its data is denoted as pu,j with
pu,j ≤ Pmax, where Pmax is the maximum transmit power of
the devices. As a result, the total transmission energy at IoT
U
is given by
u=1 pu,jtu,j. The total network energy is

J
j=1

P

P

Ψ (E, {tu,j, pu,j}) =

J

U

j=1
X

u=1
X

pu,jtu,j + ǫ Θ(E),

(5)

1Notice that Di,j = 0 if i = j and Di,j = +∞ if there is no feasible

route between i and j.

 
 
 
Zoom in

             Receiver

Information bits

Data samples

...

...

...

AlexNet model

Input

5

Output

S

j=1

UGV Edge

(Multi-task data samples)

Training data 

Validation data 

Learning 
model

Feature extraction

Classification

,3 4D

,4 3D

,3 9D

j=4

j=5

,9 5D

j=3

,3 2D

,2 3D

j=2

,1 2D

,2 9D

,1 9D
,9 1D

,7 1D

,1 7D

,5 9D

,7 9D

j=7

,5 6D

,6 7D

,7 6D

j=6

j=9

,9 7D

,8 7D

,6 8D

j=8

Trained 
AlexNet model

Classification
 results

New test data 

Stopping Point

S Start Point

Path

IoT device

Battery

Data Buffer

Convolutional layer

Pooling  layer

Fully-connected layer

Fig. 1. The EL-UGV system model.

where ǫ ∈ (0, 1) is a hyper-parameter that weights the energy
consumption at UGV and devices.

C. Sample Size Planning Model

Having speciﬁed the path and energy models, the next step
is to model the sample size planning procedure. In particular,
the number of samples xu,j being transmitted by device u at
vertex j is proportional to the transmission time, and is also
determined by the quality of wireless channel for device u. By
adopting the Shannon capacity theorem, xu,j is upper bounded
as:

is because the OA/AA merely reﬂects the overall/average
classiﬁcation performance of all classes, and ignores the
performance of the minority class (i.e., the class having the
minimum number of training samples). But since the UGV
moves according to the planned path, it is close to a part of
devices while far from the others. As a result, the number of
samples can vary signiﬁcantly for different classes, leading to
imbalanced learning performance.

To account for the imbalanced samples, with the confusion
matrix shown in Table II presented in Appendix A, the F-
measure Φm is deﬁned as:

A,

(6)

Φm =

2PmRm
Pm + Rm

.

(8)

xu,j ≤ tu,j × B log2

1 + sj ×

pu,j |hu,j|2
σ2

!

.

where B is the bandwidth available for the system, hu,j ∈ C
is the uplink channel from device u to the UGV, σ2 is the
AWGN noise power, and A is the data amount in bits for each
training sample. Notice that the channel condition {hu,j} can
be pre-determined using ray-tracing methods [39].

Based on the above sample size planning model, the total
number of samples yc,m obtained for training the class c of
task m is

yc,m =

J

xu,j ,

(7)

u∈Gc,m
X
where Gc,m denotes the set of all devices transmitting the
samples for class c of task m, with c = 1, · · · , Cm and
m = 1, · · · , M .

j=1
X

IV. MODELING LEARNING PERFORMANCE

A. F-Measure Model

With the path planning, energy planning and sample size
planning models, the remaining question is how to model
the learning performance of classiﬁers. While existing works
mostly focus on the OA/AA, these metrics are not applicable
to the considered UGV edge deep learning system. This

where Pm, Rm represents precision and recall, respectively,
and they are given by

Pm =

Rm =

TPm
TPm + FPm
TPm
TPm + FNm

,

.

(9)

(10)

Now, to model the relationship between the samples size
{yc,m} and the F-measure, it is necessary to develop a F-
measure model. However, to the best of the authors’ knowl-
edge, currently there is no analytical model for predicting the
F-measure given a certain dataset. To this end, based on the
deﬁnition in (8), it is observed that the F-measure has the
following features:

• Φm is a monotonically increasing function of TPm,
which is proportional to the minimum number of samples
minc yc,m among all classes.

• Φm is bounded as 0 ≤ Φm ≤ 1 as it represents a

percentage.

• As minc yc,m increases, ∇Φm would decrease and ap-

proach zero if minc yc,m → +∞.

Based on the above features, this paper proposes a nonlinear

 
F-measure model as:

Φm ({yc,m}) = θ1,m ×

min
c=1,··· ,Cm

(cid:18)

θ2,m

yc,m

+ θ3,m, (11)

(cid:19)

where (θ1,m, θ2,m, θ3,m) are parameters to be determined by
the data sets and deep leaning model. Particularly, θ2,m is
expected to be positive, parameters θ1,m and parameters θ2,m
have the same sign, especially, when θ1,m > 0, 0 < θ2,m < 1.
Notice that in contrast to the learning accuracy model in [32],
the proposed model in (11) adopts minc=1,··· ,Cm yc,m as the
input of function, thus allowing us to analyze the imbalanced
data set.

B. Curve Fitting of F-measure

To verify the proposed model (11), we use the AlexNet [40]
to fulﬁll two deep learning tasks, and then ﬁt the corresponding
experimental data to the model (11). More speciﬁcally, our ﬁrst
task is to classify 10 different categories (including airplane,
birds, and etc.) in the CIFAR-10 dataset consisting of 60, 000
32 × 32 color labeled images. On the other hand, our second
task is to classify 10 different categories (including T-shirts,
trousers, and etc.) in the Fashion-MNIST dataset consisting
of 70, 000 28 × 28 gray-scale labeled images. Without loss
of generality, the class “airplane” in CIFAR-10 and the class
“T-shirt” in Fashion-MNIST are chosen as the minority class,
respectively. In particular, we consider the minority classes
(i.e., airplane and T-shirt) ranges from 50 to 2600, while the
number of samples for the other classes is set to 2600. In both
experiments, for training the AlexNet model, we take 80%
of the data samples as training data to learn the parameters
(w, b), where w and b are weights and biases of the model
respectively, and take the remaining 20% as the validation data
to ﬁnetune hyperparameters and guide the design of proper
network architectures. Accordingly, we use a batch size of
32, a weight decay of 0.0005, a momentum rate of 0.9, and
a learning rate of 0.005 for 10000 iterations. Furthermore,
graphic processing units (GPUs) are used in order to speed up
the training procedure.

Under the above settings, the F-measure versus the number
of samples for the minority class (i.e., the red and blue solid
line, and the red and blue points) is shown in Fig. 2 (a).
The corresponding coefﬁcients of the F-measure model for
task 1 is given by θ1,1 = −3.742, θ2,1 = −0.3957 and
θ3,1 = 1.04. And that for task 2 is given by θ1,2 = −0.9465,
θ2,2 = −0.3852 and θ3,2 = 0.955. It can be seen that the
proposed nonlinear F-measure model (i.e. red and blue solid
line) matches the experimental data (i.e., red and blue points)
very well, no matter we use the CIFAR-10 or Fashion-MNIST
dataset. On the other hand, all curves increase signiﬁcantly
with the the number of samples for the minority class. This
corroborates the discussions in Section II-C that the F-measure
is determined by the minority class instead of the average
sample size (notice that all the other classes have ﬁxed number
of samples).

Remark. One may also adopt the OA model when the
numbers of samples for different classes of task m are the
same:

Φm({yc,m}) = ζ1,myζ2,m

1,m + ζ3,m,

(12)

6

0.95

0.85

0.75

0.65

0.55

0.45

0.35

0.25

)

%

(
e
r
u
s
a
e
m
-
F

0.95

0.9

0.85

0.8

0.75

0.7

0.65

0.6

0.55

0.5

0.45

0.4

)

%

(

)

A
O

(

y
c
a
r
u
c
c
A

l
l

a
r
e
v
O

Actual predictions
for task 1

Fitted F-measure
for task 1

Actual predictions
for task 2
Fitted F-measure
for task 2

 Fitted F-measure
(task 1)

 Fitted F-measure
(task 2)

Actual predictions
for task 1

Fitted OA model
for task 1

Actual predictions
for task 2

Fitted OA model
for task 2

0.15

50200
50200

800 1400 2000 2600
Simple Size of 
Minority Class (images)
(a)

0.35

50200
50200

800 1400 2000 2600

Simple Size of 
Each Class (images)

(b)

Fig. 2. The experimental results for the CIFAR-10 and Fashion-MNIST
datasets. For both experiments,
the test dataset contains 1000 untrained
images, each class has 100 images. (a) is the F-measure for the CIFAR-10 and
Fashion-MNIST datasets. For extrapolation, the number of historical samples
for the minority class varies from 50 to 1700. (b) is the experimental results
of OA for the CIFAR-10 and Fashion-MNIST datasets.

where {ζ1,m, ζ2,m, ζ3,m} are parameters to be ﬁtted. To verify
the proposed model (12), we consider the same learning model
and hyper-parameters in Section IV-B. By ranging the number
of samples for each class from 50 to 2600, we compute the
OA Ξm as:

Ξm =

TPm + TNm
TPm + TNm + FPm + FNm

,

(13)

where {TPm, TNm, FPm, FNm} are deﬁned in Table II.
By ﬁtting the model (12) to the experimental data, the pa-
rameters in the OA model are given by (ζ1,1, ζ2,1, ζ3,1) =
(−1.64, −0.1803, 1.263) for task 1, and (ζ1,2, ζ2,2, ζ3,2) =
(−0.5914, −0.1927, 1.05) for task 2. The OA versus the
number of samples for each class is shown in Fig. 2 (b). It can
be seen that the proposed OA model matches the experimental
data of both tasks very well.

V. JOINT PATH, ENERGY AND SAMPLE SIZE PLANNING

A. Problem Formulation

With the F-measure model, we establish a JPESP prob-
lem focusing on a max-min fairness F-measure design. The
considered problem is to maximize the minimum F-measure
Φ1, ..., ΦM for all tasks by planning the UGV path (including
vertex selection variable s and selection matrix E), scheduling
the wireless resources (including transmission time {tu,j}
and transmission power {pu,j}), and the minimum number
of samples among all classes {mincyc,m}, subjecting to con-
straints of communication capacity, total execution time, total
energy consumption and the graph mobility. To this end, an
optimization problem is formulated as:

P1 : max

s,E,{αm}
{tu,j ,pu,j }

min
∀m  

θ1,mαθ2,m

m + θ3,m

!

 
 
 
 
s.t.

αm ≤

J

tu,j

B
A

j=1
X
pu,j |hu,j|2
σ2

u∈Gc,m
X

log2

1 + sj

E ∈ Q(s),
U

J

,

∀c, m, (14a)

!

(14b)

6 Tall,

(14c)

(14d)

(14e)

(14f)

tu,j +

Tr(DT E)
v

u=1
X

j=1
X
Ψ (E, {tu,j, pu,j}) 6 Eall,
(1 − sj)tu,j = 0,
∀u, j,
tu,j ≥ 0,

pu,j ≥ 0,

∀u, j,

where αm = minc yc,m.

• The constraint (14a) is the capacity limitation; it means
that the number of training samples αm should not be
greater than the number of collected samples.

• The constraint (14b) is the mobility management con-
straint; it describes the constraint of graph-based path
[41].

• The constraint (14c) ensures that the execution including
UGV moving and data transmission to be completed in
Tall seconds [42].

• The constraint (14d) guarantees that

the total energy
consumption of the UGV and the devices cannot exceed
the energy budget Eall [19], [42].

• The constraint (14e) ensures that if the vertex j is not

visited, the transmission time {tu,j} must be zero.

• The constraint (14f) is the non-negativity constraints on

the optimization variables.

However, problem P1 is a large-scale MINLP problem,
which is nontrivial to solve due to the discontinuity of (s, E).
While a naive brute-force search can obtain the global optimal
solution, it involves exponential computational complexities.
On the other hand, existing algorithms such as local search
[43] may lead to local optimum or on plateaus where many
solutions are equally ﬁt. To this end, in the following, we will
derive an efﬁcient tabu search (TS) algorithm based UGV’s
path planning method that converges to the optimal solution
to P1 with high probability.

B. Tabu Search Algorithm

To facilitate the derivation of TS-based algorithm, we need

to reformulate P1 into a compact form. By deﬁning

Fu,j =

|hu,j|2
σ2

,

(15)

and a function

Ω(s) =

min
∀m  

(

θ1,mαθ2,m

m + θ3,m

: (14a) − (14f)

,

(16)

)

!

problem P1 can be transformed into an equivalent problem
only involving s:

P2 : max

s
s.t.

Ω(s)

s1 = 1, sj ∈ {0, 1}, ∀j ≥ 2

(17a)

7

Now, in order to address the challenge brought by the
discontinuity of s in P2, this section will consider a meta-
heuristic algorithm termed TS [44], which is based on local
search and a tabu list I. The idea of TS is to avoid getting stuck
at a local optimal point by maintaining a tabu list I. The tabu
list I records the obtained local solutions that have tabu status
and cannot be visited currently (but may be visited after a
chosen number of iterations). Moreover, the tabu restriction of
a solution can be overridden if the solution passes an aspiration
level µ, where µ is the objective value of the best solution that
has been found so far [45].

Notice that the maximum tabu list size L of I will affect the
convergence speed and performance of TS. More speciﬁcally,
a larger L will prune more solutions, which results in slow
convergence of TS. On the other hand, a smaller L will cause
cycling of solutions, which results in suboptimal performance
of TS. Therefore, the L is a hyper-parameter that needs to be
tuned carefully (e.g., L = 10 in this paper). Finally, given the
list size L, the list content is not ﬁxed, meaning that it can
either add or revoke an element based on the new solution
produced in each iteration.

Based on the above descriptions,

the TS algorithm for

solving P2 is as follows.

• Step 1. Generate an initial solution s0 (e.g., s0 =
[1, 0, . . . , 0]T ), and set the current solution sc and the
best solution s⋆ as sc = s⋆ = s0.

• Step 2. Select a neighboring solution within N (sc),
which is the non-tabu solution yielding the highest ob-
jective function value Ω or the tabu solution passing the
aspiration level µ. To reduce the computational complex-
ity, this step can be implemented via random sampling.

• Step 3. Refresh the tabu list as well as s⋆.
• Step 4. Terminate the process if the maximum number
of iterations iter has been reached (or no improvement in
s⋆ has been found after a maximum number of iterations)
and set optimal s∗ = s⋆. Otherwise go to Step 2.
Notice that N (sc) in Step 2 is the neighborhood of sc. Since
s is a binary variable, a natural N (sc) can be deﬁned as:

N (sc) = {s : ks − sck0 ≤ Z, s ∈ Π} ,

(18)

where Z is the size of its neighborhood and Π is entire
solution space. The detailed description of the TS is shown
in Algorithm 1.

C. Computing Ω with Fixed s

To execute Algorithm 1, the remaining task is to compute
Ω(s) for s = s⋄, where s⋄ is any feasible solution to P2. Based
on the expression of Ω(s) in (16), computing Ω is equivalently
to handling the following problem related to the path selection
matrix E and the wireless resources {tu,j, pu,j}:

P3 : max
E,{αm}
{tu,j ,pu,j }

min
∀m  

θ1,mαθ2,m

m + θ3,m

!

s.t.

αm ≤

tu,jB/A

J

u∈Gc,m
X

j=1
X

 
Algorithm 1 Solve JPESP proplem via TS

1: Initialize iter = 0 and I = ∅. Set L = 10 and Z = 3.
2: Initialize sc = s⋆ = s0 = [1, 0, . . . , 0]T .
3: Repeat:
4:

Generate a set A with sufﬁciently large |A| and each

element randomly sampled from N (sc).

For all x[n] in A:

Solve P3 with s = x[n] to obtain E[n].
Solve P6 with s = x[n] and E[n]

to obtain

{α[n]

m , t[n]

u,j, p[n]

u,j}.

Compute Ω(x[n]) with x[n], E[n], {α[n]

u,j}.
Permute A into B = {x[1], · · · , x[|A|]} such that

u,j, p[n]

m , t[n]

Ω(x[1]) ≥ Ω(x[2]) ≥ · · · Ω(x[|A|]).

For n = 1 to |A|:

If Ω(x[n]) > Ω(s⋆): (Update Solution)

Set s⋆ ← x[n]. (Update UGV visiting points)
Set E⋆ ← E[n]. (Update UGV path)
Set {α⋆
Set {t⋆
Set {p⋆

m }. (Update sample size)
u,j}. (Update transmission time)
u,j}. (Update transmission energy)

m ← α[n]
u,j ← t[n]
u,j ← p[n]

If x[n] /∈ I: (Update Tabu List)

If |I| < L:

Update I = I

{x[n]} and set sc ← x[n].

Else:

S
Find z = argmins∈I Ω(x[n]).
Update I = I \ {z}

{x[n]} and set sc ← x[n].

End If

Else:

If Ω(x[n]) > µ:

S

Update µ = Ω(x[n]).
Update I = I \ {x[n]} and set sc ← x[n].

End If

5:
6:

7:

8:

9:

10:

11:
12:

13:

14:

15:

16:

17:
18:

19:

20:
21:

22:
23:

24:

25:
26:

27:

28:
29:

End If
End For
Update iter ← iter + 1.

30:
31:
32: Until iter = iter.
33: Set optimal s∗ = s⋆, E∗ = E⋆, {α∗
u,j = p⋆
t⋆
u,j}, and {p∗
34: Output s∗, E∗, {α∗

u,j}.
m, t∗

u,j, p∗

u,j}.

m = α⋆

m}, {t∗

u,j =

j × Fu,j pu,j

,

∀c, m,

(19a)

1 + s⋄
log2
E ∈ Q(s⋄),
(cid:0)
(1 − s⋄
tu,j ≥ 0,

j )tu,j = 0,

(cid:1)
∀u, j,

pu,j ≥ 0,

∀u, j,

(19b)
(19c)

(19d)

tu,j +

Tr(DT E)
v

6 Tall,

(19e)

pu,jtu,j + ǫΘ(E) 6 Eall.

(19f)

and

J

U

j=1
X
J

u=1
X
U

j=1
X

u=1
X

To solve P3, the ﬁrst challenge comes from the discrete
constraint of E in (19b). Fortunately, it can be seen that the
variable E is only involved in (19b), (19e) and (19f). Fur-
thermore, decreasing Tr(DT E) in (19e) would also decrease

8

Θ(E) in (19f), which enlarges the feasible set of P3. As a
result, the optimal solution E⋄ to P3 is given by:

E⋄ = argmin

E

{Tr(DT E) : E ∈ Q(s⋄)}.

(20)

Since the above problem (20) is a travelling salesman
problem, E⋄ can be efﬁciently found by one-tree relaxation
algorithm in the CVX Mosek solver [46]. With E = E⋄,
the optimization P3 can be transformed into the following
problem involving {tu,j, pu,j, αm}:

P4 : max
{αm},
{tu,j ,pu,j }

min
∀m  

θ1,mαθ2,m

m + θ3,m

!

s.t.

αm ≤

tu,jB

A

J

u∈Gc,m
X
1 + s⋄

j=1
X
j Fu,jpu,j
pu,j ≥ 0,
(cid:1)

log2
tu,j ≥ 0,
(cid:0)
U

J

.

,

∀c, m,

∀u, j,

(21a)

(21b)

tu,jpu,j + ǫΘ(E⋄) 6 Eall,

(21c)

tu,j +

Tr(DT E⋄)
v

6 Tall,

(21d)

j )tu,j = 0,

∀u, j.

(21e)

j=1
X
J

u=1
X
U

u=1
j=1
X
X
(1 − s⋄

However, the dimension of variables in P4 is M + 2U J,
which is too large if the number of vertices J is large. To
this end, the following proposition is established to reduce the
problem dimension.

u,j, p⋄

u,j} to P4 satisﬁes:

Theorem 1. The optimal {t⋄
(i) If t⋄
u,j 6= 0, then p⋄
(ii) If j = argmaxl∈J s⋄
(iii) If j 6= argmaxl∈J s⋄
Proof. See Appendix B

u,j 6= 0.
l Fu,l, then t⋄
l Fu,l, then t⋄

u,j 6= 0.
u,j = 0.

Insights of Theorem 1. Part (i) of Theorem 1 indicates
that the UGV should leave no blank time, which is in contrast
to the ﬁxed EL systems that may have blank time for energy
saving. Part (ii) and (iii) of Theorem 1 indicates that each
IoT device should be served only once along the path, and the
corresponding position has the best channel among all selected
positions to that device.

According to Theorem 1, we can add the following equality

constraints to P4 without changing the optimal solution:

eu,

if j = argmax

l∈J

0,

if j 6= argmax

l∈J

s⋄
l Fu,l

s⋄
l Fu,l

fu,

if j = argmax

l∈J

0,

if j 6= argmax

l∈J

s⋄
l Fu,l

s⋄
l Fu,l

tu,j = 




pu,j = 


,

,

(22)

(23)

where eu > 0 according to (ii) of Theorem 1, and fu > 0
according to (i) of Theorem 1. Theorem 1 indicates that for



each m, the UGV only needs to allocate time to device u at
vertex j = argmaxl∈J s⋄
l Fu,l, and should save transmission
time and energy at other vertices. Subsequently, by putting
(22) and (23) into P7 (an equivalent form of P4, see proof
of theorem 1 in appendix B), P4 is equivalently transformed
into:

Start

End

Phase 1: Parameter estimation

Phase 3: Model training at the edge

Use trained AlexNet to predict F-
measure values based on different 
sample size of minority class

Train and test AlexNet to evaluate system 
performance based on obtained samples

9

P5 :

max
{αm},
{eu>0,fu>0}

θ1,mαθ2,m

m + θ3,m

!

s.t.

αm −

euB

A

u∈Gc,m
X

.

log2 (1 + Mu(s⋄)fu) ≤ 0,
U

Obtain fitting curves of F-measure 
based on predicted F-measure values

 Determine corresponding parameters 
}
{
  
of                         based on fitting
m
m
2,
3,
1,
curves

,

,

m

Phase 2: Data collection with J(cid:51)(cid:40)(cid:54)(cid:51)

Solve JPESP problem and obtain total 
number of samples for all classes of task m

Establish a nonlinear F-measure model 
based on the parameters and build 
JPESP problem 

∀c, m (24a)

eufu + ǫΘ(E⋄)

Fig. 3. The entire procedure for practical implementation.

u=1
X
6 βE,mEall,
U

eu +

∀m,
Tr(DT E⋄)
v

u=1
X
6 βT,mTall,
eu > 0,

fu > 0,

∀m,

(24b)

(24c)

(24d)

M

M

βE,m = 1,

βT,m = 1,

(24e)

m=1
X

m=1
X

where Mu(s⋄) := maxls⋄
l Fu,l, which is a constant with
sl = s⋄
l . However, the {eu, fu} optimization problem in the
form of P5 is still difﬁcult to solve due to the nonlinear
coupling between eu and fu in (24a) and (24b). To address this
problem, we replace {fu} with new variables {δu} such that
{δu := tufu}. As such, the optimization problem P5 becomes:

P6 :

max
{αm},
{eu>0,δu>0}

θ1,mαθ2,m

m + θ3,m

!

s.t.

αm −

euB

A

.
Mu(s⋄)

≤ 0,

∀c, m (25a)

u∈Gc,m
X
δu
eu

1 +

(cid:18)
δu + ǫΘ(E⋄) 6 βE,mEall,

(cid:19)

log2

U

u=1
X
U

eu +

Tr(DT E⋄)
v

u=1
X
6 βT,mTall,
eu > 0,

δu > 0,

∀m,

M

M

βE,m = 1,

βT,m = 1,

m=1
X

m=1
X

It can be seen that the variable dimension in problem P6 is
only 2U + M , which is reduced by a factor of J compared
with the variable dimension in problem P4. Therefore, solving
P6 requires a complexity of O
, which is

[2U + M ]3.5

(cid:16)

(cid:17)

∀m,

(25b)

(25c)
(25d)

(25e)

[2U J + M ]3.5
signiﬁcantly smaller than O
u, δ⋄
Meanwhile, the solutions {e⋄
(cid:16)
following proposition.

u, α⋄

for solving P4.
m} can be obtained by the

(cid:17)

Proposition 1. P6 is a convex optimization problem.

Proof. See Appendix C

According to Proposition 1, P6 can be solved by the
existing solvers, e.g. CVX [47]. After obtaining the solu-
tions {e⋄
u} to P6 can be computed by
u = δ⋄
{f ⋄

u}, the optimal {f ⋄
u}.

u, δ⋄
u/e⋄

D. Practical Implementation

The entire procedure of EL at UGV is shown in Fig. 3. It
can be seen from Fig. 3 that the EL at UGV is divided into
three phases: 1) parameter estimation phase; 2) data collection
with JPESP problem phase; and 3) model training at the edge
phase. The AlexNet is used in phase 1 and phase 3.

During phase 1, one may wonder how could one obtain the
ﬁtted F-measure model before the actual AlexNet model is
being trained. This can be done via extrapolation [48]. More
speciﬁcally, in real-world applications, the data is being gen-
erated everyday at the IoT infrastructures [49]. For example,
in Internet of vehicles [50], the on-board data (e.g., images,
videos, LiDAR point clouds) needs to be uploaded to the edge
or cloud platform for big data analysis. In such a scenario, it
is not likely that the data is uploaded only once. Instead, the
data is uploaded multiple times [51] (e.g., twice a day/week).
Therefore, there exist historical dataset samples at the UGV
edge and the F-measure can be obtained by ﬁtting the corre-
sponding coefﬁcients to the historical dataset. More speciﬁ-
cally, by varying the samples sizes from 50 to 1700, we can
obtain (θ1,1, θ2,1, θ3,1) = (−3.167, −0.3208, 1.149) for task 1
(the purple dashed line in Fig. 2 (a)) and (θ1,2, θ2,2, θ3,2) =
(−1.035, −0.4193, 0.9456) for task 2 (the black dashed line
in Fig. 2 (a)). It can be seen from Fig. 2 (a) that the ﬁtting
performance based on small historical dataset (i.e. the purple
and black dashed lines) is slightly worse than that based on full
dataset (i.e. the red and blue solid lines). But since our goal
is to distinguish different task difﬁculties rather than accurate
prediction of the F-measure values, the extrapolation method

 
 
can still guide the JPESP design at the UGV and the IoT
devices.

Notice that if there exist historical samples at the UGV, the
total number of samples yc,m obtained for training the class c
of task m (7) is redeﬁned as:

J

yc,m =

xu,j + ac,m,

(26)

j=1
X
where ac,m is the number of historical samples for class c of
task m at the UGV edge.

u∈Gc,m
X

Accordingly, the ﬁrst constraint of P1 becomes:

αm ≤

J

u∈Gc,m
X
Cm

j=1
X

tu,j

B
A

log2

1 + sj

pu,j |hu,j|2
σ2

!

+

ac,m,

∀c, m

(27)

c=1
X

comparing (27) with the ﬁrst constraint in P1, it can be
seen that the only difference is the additional constant term
Cm
c=1 ac,m in (27). Therefore, the convexity of the problem is
unchanged, and the proposed Algorithm 1 is still applicable.
P

VI. SIMULATION AND DISCUSSION

In this section, simulations are provided to evaluate the
system performance of the EL-UGV system. The simulation
settings are set as follows unless speciﬁed otherwise. The time
budget Tall and energy budget Eall are set to be Tall = 300 s
and Eall = 2000 Joule, respectively. The data collection map
is a 20 m × 20 m = 400 m2 square area. Within the map, J =
12 vertices are uniformly scattered wherein j = 1 is chosen
as the starting point of the UGV. The channel hu,j from IoT
device u to vertex j is modeled as ∼ CN (0, ρ0(du,j /d0)−3)
[52], where di,j is the distance between u to j and ρ0 = 10−3
is the path-loss at d0 = 1, and the channel bandwidth B is
set as 0.18 MHz. For comparison, two benchmark schemes
are simulated: 1) Fixed EL (i.e., optimal solution to P1 with
s = [1, 0, ..., 0]T ; 2) full path EL (i.e., optimal solution to P1
with s = [1, 1, ..., 1]T ).

A. Veriﬁcation of Theoretical Results

To verify the beneﬁt brought by the F-measure model, we
ﬁrst simulate the ﬁxed EL and full path EL schemes with or
without the F-measure model. For the schemes without the F-
measure model, the power and time resources are optimized
for maximizing the minimum throughput among all devices
[53]. Fig. 4 (a) shows the learning performance versus the
noise power σ2. It can be seen that the full path EL scheme
achieves better performance that that of the ﬁxed EL scheme,
and the gap quantiﬁes the beneﬁt by allowing the edge to
move. Furthermore, no matter the UGV is ﬁxed at the starting
point or moving around, the schemes based on the F-measure
model always achieves much higher learning performance
than those without F-measure model. This indicates that it is
necessary to adopt the F-measure model for energy and sample
size planning .

10

TS scheme
based on P6
TS scheme
based on P4

300

250

)
n
m

i

200

i

(
e
m
T
g
n
n
n
u
R

i

150

100

50

0.9

0.86

0.82

0.78

0.74

0.7

0.66

0.62

)

%

(

e
r
u
s
a
e
m
-
F

Full path EL without
F-measure model
Fixed EL without
F-measure model
Full path EL with
F-measure model
Fixed EL with
F-measure model

0.58

-110

-100

-90

Noise Power     (dBm)

(cid:21)s

(a)

-80

0
5

10

15

20

25

Number of Iterations
(b)

Fig. 4. Veriﬁcation of theoretical results. (a) is the comparison between
schemes with and without the F-measure model. (b) is running time versus
the number of iterations for TS scheme based on P4 and P6.

Next, to verify the signiﬁcance of Theorem 1, we consider
the following schemes: 1) TS scheme based on P6; 2) TS
scheme based on P4 for running time comparison using
Matlab on a computer equipped with Intel Core E5-26200
2GB, and 32GB RAM memory. Fig. 4 (b) shows the running
time of the two schemes versus the number of iterations, with
each point in Fig. 4 (b) averaged over 10 independent channel
realizations. From Fig. 4 (b), it is observed that TS scheme
based on P6 takes less running time than that based on P4
at the same number of iterations. On the other hand, since
P4 is equivalent to P6, the TS scheme based on P4 and P6
would require the same number of iterations for convergence.
Therefore, TS scheme based on P6 is faster than that based
on P4. Moreover, the gap of running time between the two
schemes signiﬁcantly increases as the number of iterations
increase. This corroborates the fact that the variable dimension
of P6 is reduced by using Theorem 1.

B. Single-Task Scenario

Now, we consider a single-task scenario with total U = 10
IoT devices, and classify 10 different categories using CIFAR-
10 dataset. Fig. 5 (a) shows the F-measure versus the noise
power σ2. It can be observed from Fig. 5 (a) that
the
performance of all schemes decreases when the noise power
increases, as a larger noise leads to a smaller data-rate, which
in turn decreases the learning performance. Furthermore, the
proposed UGV-based TS algorithm achieves the best learning
performance compared to the full path EL scheme and the
ﬁxed EL scheme. More speciﬁcally, when σ2 is small (e.g.,
-110 dBm), the UGV can easily collect data samples without
moving to far-away vertices (with the moving path being the
red dashed line shown in Fig. 5 (b)), which saves motion en-
ergy and time consumption compared to full path EL scheme.
Therefore, the proposed TS scheme collects more training
samples and achieves a higher F-measure. On the other hand,
when σ2 is large (e.g., -80 dBm), the proposed scheme allows

 
 
 
 
the UGV to move closer to far-away IoT devices (with the
moving path being the black line shown in Fig. 5 (b)), which
combats against the noisy channel by reducing the path-loss.
Therefore, the proposed TS scheme also collects more training
samples and outperforms the ﬁxed EL scheme.

To further evaluate the performance of the proposed algo-
rithm, practical items including the the sample size, F-measure,
the total transmission time, and the overall transmission energy
of the three schemes are shown in Fig. 5 (c). It can be
seen from Fig. 5 (c) that the proposed scheme achieves the
highest F-measure score (0.865). This is because the proposed
algorithm can automatically determine whether to move and
how far to move, and ﬁnd the best trade-off between moving
and communicating. Therefore, with the proposed algorithm,
the edge collects the most samples (2260) for the minority
class.

C. Two-Task Scenario

In such scenario, we consider the case of U = 20 and
M = 2. The ﬁrst task is to classify the CIFAR-10 dataset
into 10 categories, and the second task is to classify the
MNIST fashion dataset into 10 categories. The 20 categories
are distributed at the data of these 20 devices, with each device
providing the training samples of a particular category. We
adopt the values of {θ1,m, θ2,m, θ3,m}M

m=1 in Section IV-B.

To evaluate the superiority of the proposed algorithm, we
compare the total F-measure (i.e. we ﬁrst compute F-measure
of task 1 and F-measure of task 2 respectively, and then take
the minimum of the two F-measures as the total F-measure)
of different schemes. The performance brought by total F-
measure model is demonstrated in Figure 6 (a). It can be seen
from Fig. 6 (a) that the proposed algorithm still achieves the
largest F-measure over a wide range of noise power. Similar
to the single-task case, the UGV should increase its path
length when the noise power increases as shown in Fig. 6
(b). However, in addition to the above feature, the proposed
TS scheme always chooses the positions that are closer to
the IoT devices of task 1 (as shown in Fig. 6 (b)). This is
because the task 1 needs to classify the CIFAR-10 dataset,
which is much more challenging than the MNIST dataset in
task 2. As a result, in order to achieves the best F-measure
learning performance, more time and energy resources need
to be allocated to task 1 (the total transmission time is 209.48
s and the overall transmission energy is 2.09 Joule shown in
Fig. 6 (c)) to collect more samples of it (1526). This indicates
that the proposed TS scheme can not only ﬁnd the best trade-
off between moving and communicating, but also can adapt to
the difﬁculty and importance of different tasks. Furthermore,
it can be seen from Fig. 6 (c), for the two-task scenario, the
proposed scheme achieves the highest F-measure of 0.86, and
the sample sizes of it for both task 1 and task 2 are also the
largest (1526 for task 1 and 210 for task 2).

D. Comparison with Related Works

Existing works have studied the energy planning problem
[55] or the UGV path planning problem [56]. While [55],
[56] aim to maximize the communication throughput instead

11

of the learning performance (e.g., F-measure adopted in this
paper), they have employed the same multiple access scheme
(i.e., time division multiple access (TDMA)) as our EL system.
Therefore, the two algorithms can be applied to our considered
UGV edge learning system with some minor modiﬁcations.
Speciﬁcally,

• For problem (4a)-(4d) in [55], we set τ0 = 0 in (4a)-(4d)
and γk = pu,1|hu,1|2σ2 in (4a), and replace the constraint
K
(4b) with
k=1 pktk ≤ Eall. Then the TDMA scheme in
[55] becomes the throughput maximization scheme with
ﬁxed UGV in our EL systems.

P

i = xa

• For problem (7) in [56], we set qa

i ) in
(7) and write the data amount xai based on the Shannon
i = ta
i |2/σ2
information theory as x2
(notice that ha
i = hu,j). Then the problem (7) in [56]
becomes the throughput maximization scheme with UGV
path planning.

i Blog2(1 + sa)p2

i /log2(xa

i |h2

Based on the above descriptions, we simulate the two-task
scenario and compare our proposed EL-UGV scheme with
the throughput maximization scheme with energy planning
[55] and the throughput maximization scheme with UGV path
planning [56]. For the communication procedure, we adopt
the same parameters as those in Section VI but with the
bandwidth B = 0.3 MHz. For the learning procedure, the
AlexNet is trained with a batch size of 32, a weight decay
of 0.0005, a momentum rate of 0.9, and a learning rate of
0.005. After training for 10000 iterations, the trained AlexNet
is tested on a dataset with 1000 unseen images (each class
has 100 images). The parameters of the F-measure model are
estimated by using 1700 historical samples (the number of
historical samples of all classes is 1700), and they are given
by (θ1,1, θ2,1, θ3,1) = (−1.961, −0.09712, 1.795) for task 1
(θ1,2, θ2,2, θ3,2) = (−0.755, −0.08913, 1.302) for task 2.

Under the above setting, the total transmission time, the total
transmission energy and the minimum sample size among all
classes are obtained by executing Algorithm 1. For both deep
learning tasks, we train the AlexNet according to the sample
sizes of all classes obtained from the simulated algorithms
(including Algorithm 1, [55] and [56]) and calculate the
total F-measure scores for all the schemes. It can be seen
from Fig. 7 (a) that the proposed EL-UGV scheme achieves
the highest F-measure score. This is because the proposed
scheme “learns” that the task 1 is more difﬁcult than task
2, and allocates more transmission time and transmission
energy to task 1. In particular, with our proposed scheme,
the transmission time for task 1 is 212.0 s as in Fig. 7 (a)c
and the transmission energy for task 1 is 2.08 Joule as in
Fig. 7 (a)d. Both values are the largest among all the simulated
schemes. As a result, with the proposed scheme, the edge is
able to collect more samples for training task 1 (collecting
4210 samples as shown in Fig. 7 (a)b), and therefore the
F-measure is signiﬁcantly increased compared with [55] and
[56]. Notice that the proposed scheme achieves the smallest
total transmission time (221.2 s) and total transmission energy
the proposed scheme can also
(2.18 Joule), meaning that
beneﬁt the energy saving at IoT devices.

0.92

0.9

0.88

0.86

0.84

0.82

0.8

)

%

(

e
r
u
s
a
e
m
-
F

Proposed algorithm
Full path EL visiting all vertices
Fixed EL

0.78

-110

-105

-100

-95

-90

-85

-80

60

50

40

30

20

10

0

-10

-20

Starting point
Vertices
IoT devices
Optimal path at s 2=-80dBm
Optimal path at s 2=-110dBm
Full path EL scheme

Noise Power      (dBm)

(cid:21)s

-20

-15

-10

-5

0

5

10

15

20

(a) F-measure versus noise power σ2.

(b) The optimal path at σ2 = −80 dBm and
σ2 = −110 dBm.

Fig. 5. The system performance and optimal path for single-task scenario wherein U = 10, J = 12.

12

fixed EL scheme

full EL scheme

proposed scheme

e
z
i
s
e
l
p
m
a
S

s
s
a
l
c
y
t
i
r
o
n
m

i

r
o
f

2500

2000

1500

1000

500

0

n
o
i
s
s
i
m
s
n
a
r
t

l
a
t
o
T

)
s
(
e
m

i
t

300

200

100

0

2260

2038

1082

1

2

3

300

248.69

230.4

1

2

3

e
r
u
s
a
e
m
-
F

1

0.9

0.8

0.7

0.6

n
o
i
s
s
i
m
s
n
a
r
t

l
l
a
r
e
v
O

)
e
l
u
o
J
(
y
g
r
e
n
e

3

2

1

0

0.858

0.865

0.801

1

2

3

3

2.48

2.27

1

2

3

(c) Comparison of sample size, F-measure, total
transmission time, overall transmission energy at
σ2 = −80 dBm.

fixed EL scheme

full EL scheme

proposed scheme

0.9

0.88

0.86

0.84

0.82

0.8

)

%

(

e
r
u
s
a
e
m
-
F

l
a
t
o
T

Proposed algorithm
Full path (cid:40)(cid:47)(cid:3)visiting all vertices(cid:3)
(cid:41)(cid:76)(cid:91)(cid:72)(cid:71)(cid:3)(cid:40)(cid:47)

0.78

-110

-105

-100

-95

-90

-85

-80

Noise Power      (dBm)

(cid:21)s

(a) Total F-measure versus noise power σ2.

60

50

40

30

20

10

0

-10

-20

Starting point
Vertices
IoT devices corresponding to task 1
IoT devices corresponding to task 2
Optimal path at s 2=-80dBm
Optimal path at s2=-110dBm 
Full path EL scheme

e
z
i
s
e
l
p
m
a
S

s
s
a
l
c

y
t
i
r
o
n
m

i

r
o
f

2000

1500

1000

500

0

task 1

1526

1425

1265

task 2

152 177 210

1

2

3

4

5

6

n
o
i
s
s
i
m
s
n
a
r
t

l
a
t
o
T

)
s
(

e
m

i
t

400

task 1

300

292.13

200

100

0

209.48

195.95

task 2

1

2

3

7.87 6.43 7.45
5

6

4

e
r
u
s
a
e
m
-
F

l
a
t
o
T

1

0.9

0.8

0.7

0.6

n
o
i
s
s
i
m
s
n
a
r
t

l
l
a
r
e
v
O

)
e
l
u
o
J
(

y
g
r
e
n
e

4

3

2

1

0

0.851

0.860

0.799

1

2

3

task 1

2.91

1.96

2.09

task 2

0.09 0.06 0.08
5
6

4

1

2

3

-20

-15

-10

-5

0

5

10

15

20

(b) The optimal path at σ2 = −80 dBm and
σ2 = −110 dBm.

(c) Comparison of sample size, total F-measure,
total transmission time, overall transmission en-
ergy at σ2 = −80 dBm.

Fig. 6. The system performance and optimal path for two-task scenario when U = 20, J = 12.

VII. CONCLUSIONS

In this paper, UGV was considered in EL for collecting
data and training the deep learning models. In order to jointly
plan the UGV path, the devices’ energy consumption, and
the number of training samples for different jobs, the graph-
based path planning model, the network energy consumption
model and the sample size planning model that is based on
F-measure and minority class sample size were proposed.
With these models, a JPESP problem that maximizes the
minimum F-measure for all tasks was established. Since the
problem is a large-scale MINLP, it was proved that each IoT
device should be served only once along the path and a TS-
based algorithm for optimizing the UGV path was derived.
Simulations demonstrated that the proposed algorithm realizes
a trade-off between moving and communicating, and adapts to
the difﬁculty and importance for various tasks.

APPENDIX A
CONFUSION MATRIX

Table
II,
“negative” means

class”
“positive” means
In
and
values
“other
(TPm, FNm, FPm, TNm) represent the number of samples
under different combinations for task m. For example, TPm
is the number of samples which belongs to the minority

“minority
classes”. The

TABLE II
Confusion Matrix

Truth / Prediction
Positive
Negative

Positive Negative
TPm
FPm

FNm
TNm

class while being classiﬁed correctly; FNm is the number
of samples which belongs to the minority class while being
classiﬁed incorrectly; TNm is the number of samples which
belongs to other classes while being classiﬁed correctly.

APPENDIX B
PROOF OF THEOREM 1

We assume that αc,m = 0. To prove this theorem, we need

the following lemma.

1. There

Lemma
M
m=1 βE,m = 1 and

exist

always
{βE,m, βT,m} with
M
m=1 βT,m = 1 such that P4

is equivalent to :
P

P

P7 : max
{αm},
{tu,j ,pu,j }

θ1,mαθ2,m

m + θ3,m

!

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(ta,b, pa,b) = (t△, p△) is optimal to P7, it must satisfy the
constraints (28c) and (28d) of P7, that is:

13

throughput maximization 
with energy planning [55]

throughput maximization 
with path planning [56]

proposed
scheme

e
r
u
s
a
e
m
-
F

l
a
t
o
T

t
e
N
x
e
l
A
m
o
r
f
d
e
t
u
p
m
o
c

n
o
i
s
s
i
m
s
n
a
r
t

l
a
t
o
T

s
s
a
l
c

y
t
i
r
o
n
m

i

r
o
f

e
z
i
s

e
l
p
m
a
S

1

0.95

0.9

0.896

0.867

0.85

0.847

0.8

300

1

a

2

3

task 1

212.0

task 2

149.5

150.6

116.38

108.1

)
s
(

e
m
T

i

200

100

0

1

2

c
3

4

5

9.2
6

10000

0

3

2

1

0

n
o
i
s
s
i
m
s
n
a
r
t

l
l
a
r
e
v
O

)
e
l
u
o
J
(

y
g
r
e
n
e

8000

6000

4000

2000

task 1

4210

3020

2450

task 2

6874

4640

2280

where

t△p△ + C1 ≤ βE,mEall,
t△ + C2 ≤ βT,mTall,

∀m,

∀m,

(29)

1

2

b

4

3

5

6

task 1

2.08

task 2

1.53

1.22

1.47

1.03

C1 =

tu,jpu,j + ǫΘ(E⋄),

(30)

X X(u,j)6=(a,b)

C2 =

tu,j +

X X(u,j)6=(a,b)

Tr(DT E⋄)
v

.

Since 0 < βE,m < 1 and 0 < βT,m < 1 for any m, we

1

2

d

3

4

5

0.10
6

have:

(a) Comparison of total F-measure,
transmission energy, and sample size at σ2 = −80 dBm.

total

transmission time, overall

t△p△ + C1 ≤ Eall,
t△ + C2 ≤ Tall,

∀m.

∀m,

(31)

80

60

40

20

0

-20

-40

-40

-30

Starting point
Vertices
IoT devices corresponding to task 1
IoT devices corresponding to task 2
Proposed scheme
Throughput maximization with path planning[56]

That means the constraints (21c) and (21d) in P4 are hold.
Moreover, assuming the optimal solutions {α⋄
m} to P7 such
that {α⋄

m} = {α△

m}, then we have
m)θ2,m + θ3,m ≥ θ1,mαθ2,m

θ1,m(α△

m + θ3,m,

∀m,

(32)

which leads to
θ1,m(α△

min
m

m)θ2,m + θ3,m

(cid:16)

≥ min
m

m + θ3,m

θ1,mαθ2,m
(cid:16)

.

(33)
(cid:17)

(cid:17)

That means the objective function of P4 holds. Meanwhile,
as the constraints (21a) and (21e) of P4 are the same as
the constrains (28a) and (28e) of P7, they always hold with
a,b, p⋄
the optimal solutions
of P7. In summary,
a,b
u,j, p⋄
of P7 are also optimal
the optimal solutions
o
u,j
to P4, which means P4 can be equivalently converted into
P7.

m, t⋄
α⋄
m, t⋄
α⋄
n

(cid:8)

(cid:9)

30

40

-10

-20

0
(b) The optimal path at σ2 = −80dBm.

20

10

Fig. 7. Comparison with related works.

s.t.

αm ≤

tu,jB

A

J

A. Proof of Part (i)

u∈Gc,m
X
1 + s⋄

j=1
X
j Fu,jpu,j
pu,j ≥ 0,
(cid:1)

log2
tu,j ≥ 0,
(cid:0)
U

J

.

,

∀c, m,

∀u, j,

(28a)

(28b)

Then, we can prove this theorem based on P7. We ﬁrst
prove the ﬁrst part. Since the optimal solution {αm} must
activate the constraint (28a) of P7, which leads to:

tu,jpu,j + ǫΘ(E⋄)

u=1
j=1
X
X
6 βE,mEall,
U
J

tu,j +

u=1
j=1
X
X
6 βT,mTall,
(1 − s⋄

∀m,
Tr(DT E⋄)
v

∀m,

j )tu,j = 0,

∀u, j,

(28c)

(28d)

(28e)

where βE,m denotes the proportion of energy requirement for
completing task m to Eall, and βT,m denotes the proportion
of time requirement for completing task m to Tall.

Proof. Assume an optimal solution
a particular (a, b) such that t⋄

u,j, p⋄
t⋄
to P7 with
u,j
a,b = p△. As
a,b = t△ and p⋄
(cid:9)
(cid:8)

J

αm =

tu,jB

Alog2

1 + s⋄

j Fu,jpu,j

,

∀c, m

u∈Gc,m
X

j=1
X

.

(cid:0)

(cid:1)

(34)

then P7 can be re-expressed as:

P8 : max
{αm}

{tu,j ,pu,j } (cid:16)

θ3,m + θ1,m

tu,jB/A

J

u∈Gc,m

(cid:16) X

j=1
X
θ2,m

log2

1 + s⋄

j Fu,j pu,j

s.t.

(28b) − (28e).

(cid:16)

(cid:17)(cid:17)

,

(cid:17)

(35a)

Assume an optimal solution {t⋄

u,j} to P8 with a
v,w = ˆt 6= 0 and the corresponding
particular (v, w) such that t⋄
p⋄
v,w = 0, where user v stores samples of class c of task

u,j, p⋄

 
 
 
 
 
 
 
 
 
 
 
 
 
 
u,j + T r(DT E⋄)/v.
t⋄

A12 + ˜t 6 βT,mTall, A13 + ˜t˜p 6 βE,mEall.

(39)

m. Consider the following related problem by ﬁxing all the
variables to their optimal values except for (tv,w, pv,w):

P9 : max

tv,w ,pv,w≥0

θ1,m

A1 + tv,wB/A × log2

1

(cid:16)

(cid:16)
+ s⋄

wFv,wpv,w

θ2,m

(cid:16)
,

+ θ3,m

s.t.

where

A2 + tv,wpv,w ≤ βE,mEall,
A3 + tv,w ≤ βT,mTall,

∀m

(cid:17)(cid:17)

(cid:17)

∀m (36a)
(36b)

M

m=1
X

M

βE,m = 1,

βT,m = 1,

(36c)

m=1
X

t⋄
u,jB/A × log2

1 + s⋄

j Fu,jp⋄
u,j

,

u,jp⋄
t⋄

u,j + ǫΘ(E⋄),

(cid:0)

(cid:1)

A1 =

A2 =

A3 =

X X(u,j)6=(v,w)

X X(u,j)6=(v,w)

X X(u,j)6=(v,w)

u,j, p⋄

As {t⋄

u,j} is optimal to P8,

it can be shown that
(tv,w, pv,w) = (ˆt, 0) is optimal to P9. Then, putting (ˆt, 0)
θ2,m +
into the objective function of P9, we have θ1,mA1
θ3,m. Considering another solution (tv,w, pv,w) = (˜t, ˜p)
into the same objective function, we have
and putting it
θ2,m + θ3,m. Due to
θ1,m
(tv,w, δv,w) = (ˆt, 0) is of optimal to P9, we can obtain the
following inequality:

A1 + ˜tB/A × log2 (1 + s⋄

wFv,w ˜p)

(cid:0)

(cid:1)

A1 + ˜tB/A × log2 (1 + s⋄
wFv,w 6= 0 (as t⋄

But since s⋄

v,w 6= 0, s⋄

w = 1 from (28e)),
we have ˜t × log2 (1 + s⋄
wFv,w ˜p) > 0, which leads to A1 +
˜tB/A × log2 (1 + s⋄
wFv,w ˜p) > A1, and it contradicts to (37),
that is to say (tv,w, pv,w) = (ˆt, 0) cannot be optimal to P8.
Therefore, p⋄

v,w 6= 0. Next, we prove the second part.

B. Proof of Part (ii)

u,j, p⋄

To prove (ii), we also assume {t⋄

u,j} as an optimal
solution to P8. Suppose that there exists user v stored sam-
ples of class c for task m such that t⋄
v,w = 0 at vertex
w = argmaxl∈J s⋄
6= w such
that t⋄

v,w′ = ˜p 6= 0.
Construct a new related problem of P8 by ﬁxing
for

l Fu,l, then there must exist w

v,w′ = ˜t 6= 0 and p⋄

to their optimal values

except

′

all
the variables
(tv,w, pv,w, tv,w′ , pv,w′):

≤ βE,mEall,
M

∀m
M

βT,m = 1,

βE,m = 1,

m=1
X

m=1
X

14

(38b)

(38c)

t⋄
u,jB/A × log2

1 + s⋄

j Fu,jp⋄
u,j

,

u,j + T r(DT E⋄)/v,
t⋄

(cid:0)

(cid:1)

u,jp⋄
t⋄

u,j + ǫΘ(E⋄).

(u,j)6∈{(v,w),(v,w′
X X

)}

(u,j)6∈{(v,w),(v,w′)}
X X

(u,j)6∈{(v,w),(v,w′
X X

)}

where

A11 =

A12 =

A13 =

u,j, p⋄

Furthermore, under {t⋄

u,j} with t⋄
seen that (tv,w, pv,w, tv,w′ , pv,w′) = (0, p⋄
to problem in (38), then, (0, p⋄
(38a) and (38b), that is:

v,w = 0, it can be
v,w, ˜t, ˜p) is optimal
v,w, ˜t, ˜p) must satisfy constraints

Comparing (39) with (38a) and (38b),

is evident
that (tv,w, pv,w, tv,w′, pv,w′) = (˜t, ˜p, 0, p⋄
v,w′) is also fea-
sible for the two constraints. Then, substituting the two
(tv,w, pv,w, tv,w′, pv,w′) = (0, p⋄
and
solutions
(tv,w, pv,w, tv,w′, pv,w′) = (˜t, ˜p, 0, p⋄
v,w′) into the objective
function of problem in (38), we can obtain:

v,w, ˜t, ˜p)

it

θ1,m

A11 + ˜tB/A × log2 (1 + s⋄

w′ Fv,w′ ˜p)

θ2,m +θ3,m, (40)

and

(cid:0)

(cid:1)
θ2,m + θ3,m. (41)

(cid:0)

Since (tv,w, pv,w, tv,w′, pv,w′) = (0, p⋄

v,w, ˜t, ˜p) is optimal to
problem in (38), the following inequality is obtained from (40)
and (41):

(cid:1)

log2 (1 + s⋄

w′Fv,w′ ˜p) − log2 (1 + s⋄

wFv,w ˜p) > 0.

By using Jensens inequality, we have

w′Fv,w′ ˜p − s⋄

wFv,w ˜p)

log2 (s⋄
> log2 (1 + s⋄
which leads to s⋄
results in s⋄
argmaxl∈J s⋄
argmaxl∈J s⋄

wFv,w ˜p) > 0,

w′ Fv,w′ ˜p) − log2 (1 + s⋄
w′Fv,w′ ˜p > s⋄

wFv,w ˜p and subsequently
wFv,w, but it contradicts to w =
v,w 6= 0 at vertex w =

w′Fv,w′ > s⋄
l Fu,l. Consequently, t⋄
l Fu,l.

(42)

(43)

wFv,w ˜p) < A1.

(37)

θ1,m

A11 + ˜tB/A × log2 (1 + s⋄

wFv,w ˜p)

max
tv,w ,pv,w≥0

θ1,m

A11 + tv,wB/A × log2

1

t
v,w

′ ,p

v,w

′ ≥0 (cid:16)

(cid:16)

(cid:16)

+ s⋄

wFv,wpv,w

+ tv,w′B/A

× log2

(cid:17)
1 + s⋄
′ Fv,w′pv,w′
w

θ2,m

(cid:16)
+ θ3,m

(cid:17)(cid:17)

(cid:17)

s.t. A12 + tv,w + tv,w′ ≤ βT,mTall,
A13 + tv,wpv,w + tv,w′pv,w′

∀m (38a)

C. Proof of Part (iii)

To prove part (iii), we assume that there exists user v
6= 0
l Fu,l. In addition, based on the
v,w 6= 0 at vertex w =
l Fu,l. Accordingly, given part (i) of Theorem

stored samples of class c for task m, such that t⋄
at vertex w′ 6= argmaxl∈J s⋄
part A of this Appendix, we have t⋄
argmaxl∈J s⋄
1, we also have p⋄

v,w′

v,w 6= 0.

v,w′p⋄

Then,

the partial Lagrangian of P7 corresponding to
(tu,j, pu,j) under ﬁxed s = s⋄ and E = E⋄ can be established

15

.

(51)

as

with (47), we have

L

{tu,j, pu,j} {εc,m, κ, χ, ςu,j, τu,j, ξu,j}

(cid:16)
=

(cid:16)

θ1,mαθ2,m

m + θ3,m

+ εc,m

αm −

(cid:17)

J

tu,j

(cid:17)

(cid:16)

u∈Gc,m
X
J

U

j=1
X

B/A × log2

1 + s⋄

j Fu,jpu,j

+ κ

tu,jpu,j

(cid:16)

(cid:17)(cid:17)

U

u=1
X

j=1
X

(cid:16)
J

+ ǫΘ(E⋄) − βE,mEall

+ χ

tu,j − βT,mTall

(cid:17)
U

J

(cid:16)

u=1
X

j=1
X

+ T r(DT E⋄)/v

+

U

J

(cid:17)

u=1
X
U

j=1
X
J

ςu,j

1 − s⋄
j

tu,j

(cid:16)(cid:16)

(cid:17)

(cid:17)

−

ξu,jtu,j −

τu,jpu,j,

u=1
X

u=1
X

j=1
X

j=1
X
(44)
where {εc,m, κ, χ, ςu,j, τu,j, ξu,j } are Lagrange multipli-
ers. Because P7 is convex in {t⋄
u,j}
condi-
and vice visa, based on Karush-Kuhn-Tucker
u,j, p⋄
u,j} and
tion [54],

the optimal primal-dual point {t⋄

u,j} with ﬁxed {p⋄

must satisfy:

(cid:8)

c,m, κ⋄, χ⋄, ς ⋄
ε⋄
τ ⋄
u,jp⋄
u,j = 0,
ε⋄
c,mB/A × log2
= κ⋄p⋄

u,j, ξ⋄
u,j, τ ⋄
u,j
u,jt⋄
ξ⋄
1 + s⋄

u,j + ς ⋄(1 − s⋄
(cid:0)
Bt⋄
1 + s⋄

A

− ε⋄

c,m

− τ ⋄

u,j = 0, ∀j ∈ J ,
(cid:0)

∀u, j

u,j = 0,

(cid:9)
+ ξ⋄
j Fu,jp⋄
u,j
u,j
j ) + χ⋄, ∀j ∈ J ,
u,js⋄
j Fu,j
j × Fu,jp⋄
u,j
∀u ∈ Gc,m.

ln2 !

(cid:1)

(cid:1)

(45a)

∀u ∈ Gc,m (45b)

+ κ⋄t⋄

u,j

(45c)

Putting t⋄

v,w, p⋄
v,w′, t⋄
τ ⋄
v,w′ = τ ⋄

v,w′, p⋄
v,w = ξ⋄

v,w into (45a), it follows that

v,w′ = ξ⋄

v,w = 0.

(46)

Plugging τ ⋄
obtained by

v,w′ = 0 from (46) into (45c), the p⋄

v,w′ can be

−

p⋄
v,w′ =

ε⋄
c,mB
1
s⋄
Aκ⋄ln2
w′Fv,w′
w′ = 1 from (28e), putting ξ⋄
v,w′ = 0
w′ = 1 into (45b), the following formula can

(47)

v,w′ 6= 0, s⋄

.

Since when t⋄
from (46) and s⋄
be obtained

ε⋄
c,mB/A×log2

Fv,w′

ε⋄
c,mB
Aκ⋄ln2

−

ε⋄
c,mB
Aln2

+

κ⋄
Fv,w′

= χ⋄.

(cid:18)

(cid:19)

(48)
With simple manipulations, (48) can be re-expressed as
F (s⋄

w′Fv,w′ ) = χ⋄, where

F (x) = ε⋄

c,mB/A × log2

ε⋄
c,mB
Aκ⋄ln2
(cid:18)
(cid:19)
w′ = 1, s⋄
w′Fv,w′ 6= 0).
With a similar procedure, by using τ ⋄

with x 6= 0 (as s⋄

x

−

(46), we have F (s⋄

w′Fv,w) = χ⋄. As a results,
w′Fv,w′) = F (s⋄

wFv,w) .

F (s⋄

ε⋄
c,mB
Aln2

+

κ⋄
x

, (49)

v,w = ξ⋄

v,w = 0 from

(50)

Deriving the ﬁrst-order derivative of F (x) and combining

∇x(F ) =

p⋄
v,w′κ⋄ + κ⋄

1
x

1
s⋄
w′Fv,w′

−

1
x

it

(cid:18)

is clear

(cid:18)
v,w′ > 0,
w′Fv,w′ , s⋄

(cid:19)(cid:19)
Since p⋄
that ∇x(F ) > 0 for
any x ∈ [s⋄
wFv,w] and F (x) is a monotonically
increasing function of x in the interval. By combining
the conclusion with (50), we can obtain that s⋄
w′ Fv,w′ =
s⋄
wFv,w = argmaxl∈J s⋄
6=
argmaxl∈J s⋄
6=
argmaxl∈J s⋄

l Fu,l. But this contradicts to w′
v,w′ = 0 at vertex w′

l Fu,l. Consequently, t⋄
l Fu,l.

APPENDIX C
PROOF OF PROPOSITION 1

In this appendix, we prove the joint-convexity of problem
P6. Since ∇2f (αm) ≺ 0, ∀αm > 0, the objective function
θ1,mαθ2,m

m + θ3,m is concave with respect to αm.

To verify the convexity of the constraint (25a), we ﬁrst

deﬁne a new afﬁne function as:

f1(δu) = eu + δuMu(s⋄).

(52)

Since log2 (1/f1(δu)) is a convex function of δu [54], then
its perspective function eu × B/Alog2 (eu/f1(δu)) is convex
with respective to eu and δu, and consequently (25a) is jointly
convex with respect to αm, eu and δu as its Hessian matrix
is positive semi-deﬁnite.

Besides, since constraints (25b) and (25c) are afﬁne, both of
them are convex. Therefore, the objective function is concave
and all the constraints are convex, constituting a joint convex
optimization problem P6.

REFERENCES

[1] G. Zhu, Y. Wang, and K. Huang, “Broadband analog aggregation for
low-latency federated edge learning,” IEEE Trans. Wireless Commun.,
vol. 19, no. 1, pp. 491–506, Jan. 2020.

[2] E. Li, L. Zeng, Z. Zhou, and X. Chen, “Edge AI: On-demand acceler-
ating deep neural network inference via edge computing,” IEEE Trans.
Wireless Commun., vol. 19, no. 1, pp. 447–457, Jan. 2020.

[3] S. Dang, M. Wen, S. Mumtaz, J. Li, and C. Li, “Enabling multi-carrier
relay selection by sensing fusion and cascaded ANN for intelligent
vehicular communications,” IEEE Sensors Journal,
to be published.
DOI: 10.1109/JSEN.2020.2986322.

[4] W. Saad, M. Bennis, and M. Chen, “A vision of 6G wireless systems:
Applications, trends, technologies, and open research problems,” IEEE
Network, to be published. DOI: 10.1109/MNET.001.1900287.

[5] L. D. Xu, W. He, and S. Li, “Internet of Things in industries: A survey,”
IEEE Trans. Ind. Informat., vol. 10, no. 4, pp. 2233–2243, Nov. 2014.
[6] B. Lyu, Z. Yang, H. Guo, F. Tian, and G. Gui, “Relay cooperation
enhanced backscatter communication for Internet-of-Things,” IEEE In-
ternet Things J., vol. 6, no. 2, pp. 2860–2871, Apr. 2019.

[7] J. Gubbi, R. Buyya, S. Marusic, and M. Palaniswami, “Internet of Things
(IoT): A vision, architectural elements, and future directions,” Future
Gen. Comput. Syst., vol. 29, no. 7, pp. 1645–1660, Sep. 2013.

[8] C. You, Y. Zeng, R. Zhang, and K. Huang, “Asynchronous mobile-edge
computation ofﬂoading: Energy-efﬁcient resource management,” IEEE
Trans. Wireless Commun., vol. 17, no. 11, pp. 7590–7605, Nov. 2018.
[9] S. Yu, X. Chen, L. Yang, D. Wu, M. Bennis, and J. Zhang, “Intelligent
edge: Leveraging deep imitation learning for mobile edge computation
ofﬂoading,” IEEE Wireless Commun., vol. 27, no. 1, pp. 92–99, Feb.
2020.

[10] Y. Mao, C. You, J. Zhang, K. Huang, and K. B. Letaief, “A survey
on mobile edge computing: The communication perspective,” IEEE
Commun. Surveys Tuts., vol. 19, no. 4, pp. 2322–2358, Fourthquarter
2017.

 
[11] K. Huang, G. Zhu, C. You, J. Zhang, Y. Du, and D. Liu, “Communi-
cation, computing, and learning on the edge,”in Proc. 2018 IEEE Int.
Conf. on Commun. Syst. (ICCS), 2018, pp. 268–273.

[12] S. Yu, B. Dab, Z. Movahedi, R. Langar, and L. L. Wang, “A socially-
aware hybrid computation ofﬂoading framework for multi-access edge
computing,” IEEE Trans. Mobile Comput.,
to be published. DOI:
10.1109/TMC.2019.2908154.

[13] X. Sun, G. Gui, Y. Li, R. P. Liu, and Y. An, “ResInNet: A novel deep
neural network with feature reuse for Internet of Things,” IEEE Internet
Things J., vol. 6, no. 1, pp. 679–691, Feb. 2019.

[14] L. Zhang, G. Gui, A. M. Khattak, M. Wang, W. Gao, and J. Jia, “Multi-
task cascaded convolutional networks based intelligent fruit detection
for designing automated robot,” IEEE Access, vol. 7, pp. 56028–56038,
2019.

[15] B. Blanco-Filgueira, D. Garc´ıa-Lesta, M. Fern´andez-Sanjurjo, V. M.
Brea, and P. L´opez, “Deep learning-based multiple object visual tracking
on embedded system for IoT and mobile edge computing applications,”
IEEE Internet Things J., vol. 6, no. 3, pp. 5423–5431, Jun. 2019.
[16] S. Garg, K. Kaur, N. Kumar, G. Kaddoum, A. Y. Zomaya, and R. Ranjan,
“A Hybrid Deep Learning-Based Model for Anomaly Detection in Cloud
Datacenter Networks,” IEEE Trans. Netw. serv., vol. 16, no. 3, pp. 924–
935, Sep. 2019.

[17] M. Johnson, P. Anderson, M. Dras, and M. Steedman, “Predicting
classiﬁcation error on large datasets from smaller pilot data,” in Proc.
ACL, 2018, pp. 450–455.

[18] S. Wang, R. Wang, Q. Hao, Y.-C. Wu, and H. V. Poor, “Learning centric
power allocation for edge intelligence,” in Proc. IEEE Int. Conf. on
Commun. (ICC), 2020, pp. 1–6.

[19] S. Wang, M. Xia, K. Huang, and Y. -C. Wu, “Wirelessly powered
two-way communication with nonlinear energy harvesting model: Rate
regions under ﬁxed and mobile relay,” IEEE Trans. Wireless Commun.,
vol. 16, no. 2, pp. 8190–8204, Dec. 2017.

[20] Q. Hu, Y. Cai, G. Yu, Z. Qin, M. Zhao, and G. Y. Li, “Joint ofﬂoading
and trajectory design for UAV-enabled mobile edge computing systems,”
IEEE Internet Things J., vol. 6, no. 2, pp. 1879–1892, Apr. 2019.
[21] C. You, and R. Zhang, “Hybrid ofﬂine-online design for UAV-enabled
data harvesting in probabilistic LoS channel,” IEEE Trans. Wireless
Commun., to be published. DOI: 10.1109/TWC.2020.2978073.

[22] Y. Cai, Z. Wei, R. Li, D. W. K. Ng, and J. Yuan, “Joint trajectory
and resource allocation design for energy-efﬁcient secure UAV com-
munication systems,” IEEE Trans. Commun., to be published. DOI:
10.1109/TCOMM.2020.2982152.

[23] Y. -N. Ma, Y. -J. Gong, C. -F. Xiao, Y. Gao, and J. Zhang, “Path
planning for autonomous underwater vehicles: An ant colony algorithm
incorporating alarm pheromone,” IEEE Trans. Veh. Technol., vol. 68, no.
1, pp. 141–154, Jan. 2019.

[24] A. Kaplan, N. Kingry, P. Uhing, and R. Dai, “Time-optimal path
planning with power schedules for a solar-powered ground robot,” IEEE
Trans. Autom. Sci. Eng., vol. 14, no. 2, pp. 1235–1244, Apr. 2017.
[25] M. R. Jabbarpour, H. Zarrabi, J. J. Jung, and P. Kim, “A green ant-based
method for path planning of unmanned ground vehicles,” IEEE Access,
vol. 5, pp. 1820–1832, Jan. 2017.

[26] Y. -C. Wang, and K. -C. Chen, “Efﬁcient path planning for a mobile
sink to reliably gather data from sensors with diverse sensing rates and
limited buffers,” IEEE Trans. Mobile Comput., vol. 18, no. 7, pp. 1527–
1540, Jul. 2019.

[27] Q. Wu, W. Chen, D. W. Kwan Ng, J. Li, and R. Schober, “User-centric
energy efﬁciency maximization for wireless powered communications,”
IEEE Trans. Wireless Commun., vol. 15, no. 10, pp. 6898–6912, Oct.
2016.

[28] Q. Wu, G. Zhang, D. W. K. Ng, W. Chen, and R. Schober, “Generalized
wireless-powered communications: When to activate wireless power
transfer?,” IEEE Trans. Veh. Technol., vol. 68, no. 8, pp. 8243–8248,
Aug. 2019.

[29] B. Lyu, and D. T. Hoang, “Optimal time scheduling in relay assisted bat-
teryless IoT networks,” IEEE Wireless Commun. Lett., to be published.
DOI: 10.1109/LWC.2020.2966613.

[30] Q. Yao, T. Q. S. Quek, A. Huang, and H. Shan, “Joint downlink and
uplink energy minimization in WET-enabled networks,” IEEE Trans.
Wireless Commun., vol. 16, no. 10, pp. 6751–6765, Oct. 2017.

[31] T. X. Vu, S. Chatzinotas, B. Ottersten, and T. Q. Duong, “Energy
minimization for cache-assisted content delivery networks with wireless
backhaul,” IEEE Wireless Commun. Lett., vol. 7, no. 3, pp. 332–335,
Jun. 2018.

16

system to achieve necessary high accuracy?,” [Online]. Available:
https://arxiv.org/abs/1511.06348

[33] R. Longadge, and S. S. Dongre, “Class imbalance problem in data
mining: review,” Int. J. Comput. Sci. Netw., vol. 2, no. 1, pp. 83–87,
May 2013.

[34] W. Ng, G. Zeng, J. Zhang, D. Yeung, and W. Pedrycz, “Dual autoen-
coders features for imbalance classiﬁcation problem,” Pattern Recognit.,
vol. 60, pp. 875–889, Dec. 2016.

[35] G. Li, and Y. Yu, “Visual saliency detection based on multiscale deep
CNN features,” IEEE Trans. Image Process., vol. 25, no. 11, pp. 5012–
5024, Nov. 2016.

[36] M. Liao, B. Shi, and X. Bai, “TextBoxes++: A single-shot oriented
scene text detector,” IEEE Trans. Image Process., vol. 27, no. 8, pp.
3676–3690, Aug. 2018.

[37] P. Patil, and S. Murala, “MSFgNet: A novel compact end-to-end deep
network for moving object detection,” IEEE Trans. Intell. Transp. Syst.,
vol. 20, no. 11, pp. 4066–4077, Nov. 2019.

[38] Y. Mei, Y. H. Lu, Y. Hu, and C. Lee, “Deployment of mobile robots
with energy and timing constraints,” IEEE Trans. Robotics, vol. 22, no.
3, pp. 507–522, Jun. 2006.

[39] K. A. Remley, H. R. Anderson, and A. Weisshar, “Improving the
accuracy of ray-tracing techniques for indoor propagation modeling,”
IEEE Trans. Veh. Technol., vol. 49, no. 6, pp. 2350–2358, Nov. 2000.
[40] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classiﬁcation
with deep convolutional neural networks,” in Proc. 25th Int. Conf. on
Neural Informat. Process. Systems (NIPS), 2012, pp. 1097–1105.
[41] M. Ma, Y. Yang, and M. Zhao, “Tour planning for mobile data-gathering
mechanisms in wireless sensor networks,” IEEE Trans. Veh. Technol.,
vol. 62, no. 4, pp. 1472–1483, May 2013.

[42] S. Wang, M. Xia and Y. Wu, “Backscatter data collection with unmanned
ground vehicle: Mobility management and power allocation,” IEEE
Trans. Wireless Commun., vol. 18, no. 4, pp. 2314–2328, Apr. 2019.

[43] J. Gu, and X. Huang, “Efﬁcient local search with search space smooth-
ing: A case study of the traveling salesman problem (TSP),” IEEE Trans.
Syst., Man, Cybern., vol. 24, no. 5, pp. 728–735, May 1994.

[44] F. Glover, “Tabu search-part I,” ORSA Journal of Computing, vol. 1, no.

3, pp. 190–206, Feb. 1989.

[45] S. Salhi, “Deﬁning tabu list size and aspiration criterion within tabu
search methods,” Comput. Oper. Res., vol. 29, no. 1, pp. 67–86, Jan.
2002.

[46] G. Laporte, “The traveling salesman problem: an overview of exact and
approximate algorithms,” European Journal of Operational Research,
vol. 59, no. 2, pp. 231–247, 1992.

[47] CVXR Inc. (Mar. 2016). CVX: MATLAB Software for Disciplined

Convex Programming. [Online]. Available: http://cvxr.com/cvx

[48] S. Wang, Y. -C. Wu, M. Xia, R. Wang, and H. V. Poor, “Machine
intelligence at the edge with learning centric power allocation,” IEEE
Trans. Wireless Commun., Jul. 2020. DOI: 10.1109/TWC.2020.3010522
[49] Y. Xiao, Y. Jia, C. Liu, X. Cheng, J. Yu, and W. Lv, “Edge computing
security: State of the art and challenges,” Proceedings of the IEEE, vol.
107, no. 8, pp. 1608–1631, Aug. 2019.

[50] W. Xu, H. Zhou, N. Cheng, F. Lyu, W. Shi, J. Chen, X. Shen, “Internet
of vehicles in big data era,” IEEE/CAA Journal of Automatica Sinica,
vol. 5, no. 1, pp. 19–35, Jan. 2018.

[51] K. Zheng, H. Meng, P. Chatzimisios, L. Lei, and X. Shen, “An SMDP-
based resource allocation in vehicular cloud computing systems,” IEEE
Trans. Ind. Electron., vol. 62, no. 12, pp. 7920–7928, Dec. 2015.
[52] S. Wang, M. Xia, and Y. -C. Wu, “Multicast wirelessly powered network
with large number of antennas via ﬁrst-order method,” IEEE Trans.
Wireless Commun., vol. 17, no. 6, pp. 3781–3793, Jun. 2018.

[53] J. Park, H. Lee, S. Eom, and I. Lee, “UAV-aided wireless powered
communication networks: trajectory optimization and resource allocation
for minimum throughput maximization,” IEEE Access, vol. 7, pp.
134978–134991, Sep. 2018.

[54] S. Boyd, and L. Vandenberghe, Convex Optimization. Cambridge, U.K.:

Cambridge Univ. Press, 2004.

[55] Q. Wu, W. Chen, D. W. K. Ng, and R. Schober, “Spectral and energy-
efﬁcient wireless powered IoT networks: NOMA or TDMA?,” IEEE
Trans. Veh. Technol., vol. 67, no. 7, pp. 6663–6667, Jul. 2018.

[56] M. Zhao, D. Gong, and Y. Yang, “Network cost minimization for mobile
data gathering in wireless sensor networks,” IEEE Trans. Commun., vol.
63, no. 11, pp. 4418–4432, Nov. 2015.

[32] J. Cho, K. Lee, E. Shin, G. Choy, and S. Do.

much data is needed to train a medical

(2016). “How
image deep learning

