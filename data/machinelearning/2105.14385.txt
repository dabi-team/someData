On Centralized and Distributed Mirror Descent: Convergence
Analysis Using Quadratic Constraints

Youbang Sun1, Mahyar Fazlyab2 and Shahin Shahrampour1

2
2
0
2

n
a
J

8
1

]

C
O
.
h
t
a
m

[

2
v
5
8
3
4
1
.
5
0
1
2
:
v
i
X
r
a

Abstract—Mirror descent (MD) is a powerful ﬁrst-order op-
timization technique that subsumes several optimization algo-
rithms including gradient descent (GD). In this work, we develop
a semi-deﬁnite programming (SDP) framework to analyze the
convergence rate of MD in centralized and distributed settings
under both strongly convex and non-strongly convex assump-
tions. We view MD with a dynamical system lens and leverage
quadratic constraints (QCs) to provide explicit convergence rates
based on Lyapunov stability. For centralized MD under strongly
convex assumption, we develop a SDP that certiﬁes exponential
convergence rates. We prove that the SDP always has a feasible
solution that recovers the optimal GD rate as a special case. We
complement our analysis by providing the O(1/k) convergence
rate for convex problems. Next, we analyze the convergence of
distributed MD and characterize the rate using SDP. To the best
of our knowledge, the numerical rate of distributed MD has
not been previously reported in the literature. We further prove
an O(1/k) convergence rate for distributed MD in the convex
setting. Our numerical experiments on strongly convex problems
indicate that our framework certiﬁes superior convergence rates
compared to the existing rates for distributed GD.

I. INTRODUCTION

Over the last two decades, distributed optimization over
multi-agent networks has received a lot of attention in control,
optimization, machine learning, and signal processing. In dis-
tributed optimization, a group of n agents are connected via a
graph and can communicate locally with their neighbors. Each
agent is assigned a local objective function fi : Rd → R, and
the agents aim to collectively minimize the global objective
function,

(cid:40)
f (x) (cid:44) 1
n

min
x∈Rd

n
(cid:88)

i=1

(cid:41)

fi(x)

.

(1)

The most intuitive gradient-based algorithm to tackle the
problem above is distributed gradient descent [1], where at
each iteration k, each agent i updates its decision variables by
a (private) local gradient descent combined with an averaging
this
of its neighbors variables. In the unconstrained case,
update is given by

x(k+1)
i

= x(k)

i − η(k)∇fi(x(k)

i

) + β

(cid:88)

j∈Ni

(x(k)

j − x(k)

i

),

where η(k) > 0 is the step-size and β > 0 is the consensus
parameter. In the form given above, this update is able to
achieve optimal rates for convex problems using a diminishing

This work is supported in part by NSF ECCS-2136206 Award.
1 Y. Sun and S. Shahrampour are with the Department of Mechanical and
Industrial Engineering at Northeastern University, Boston, MA 02115, USA.
email:{sun.youb,s.shahrampour}@northeastern.edu.
2 M. Fazlyab is with the Department of Electrical and Computer Engi-
neering at Johns Hopkins University, Baltimore, MD 21218, USA. email:
mahyarfazlyab@jhu.edu.

step-size sequence. Optimality here refers to matching the
centralized convergence rate (iteration complexity) up to some
errors related to the network structure. However, when the
local functions are smooth,
the centralized GD algorithm
employs a constant step-size sequence for which the above
distributed counterpart fails to converge.

The mirror descent (MD) algorithm [2] is a primal-dual
method that has been actively studied in recent years. MD
can be seen as a generalization of GD, in which the squared
Euclidean distance is replaced by Bregman divergence as the
regularizer. The freedom in the choice of Bregman divergence
makes MD suitable for various problem geometries. MD has
been proven to have the same iteration complexity as GD
for non-strongly convex problems [3], and it may even scale
better with respect to the dimension of the decision variables
[4]. In the strongly convex scenario, MD is less studied,
and very recently its exponential convergence was established
under the Polyak-Łojasiewicz (PL) condition [5]. Inspired by
the success of MD in centralized optimization, MD has also
been studied in the distributed setting. To the best of authors’
knowledge, the convergence rate of distributed MD is not
established for strongly convex and smooth problems, and only
recently [6] provided a continuous-time analysis suggesting
local exponential rate (without explicitly characterizing the
rate).

In this paper, we leverage the framework of Quadratic
Constraints (QCs) to certify numerical exponential conver-
gence rates for centralized as well as distributed MD for
strongly convex and smooth problems using SDP. For merely
convex and smooth problems, we also establish an ergodic
O(1/k) convergence rate. We ﬁrst analyze centralized MD, for
which we derive linear matrix inequalities (LMIs) as sufﬁcient
conditions for convergence of the algorithm at a speciﬁed
rate (Theorem 2, Theorem 6 and Proposition 3). For the
strongly convex case, we prove that these LMIs always have
a feasible solution that matches the optimal convergence rate
of GD when the Bregman divergence is chosen as the squared
Euclidean distance (Proposition 4 and Corollary 5). Next, we
analyze the convergence of distributed MD and characterize
the rate using LMIs (Theorem 8, 9). To the best of our
knowledge, the exponential rate of distributed MD has not
been previously established in the literature. Our numerical
experiments on strongly convex problems indicate that our
framework certiﬁes superior convergence rates compared to
the existing rates for distributed GD.

A. Related Literature

1) Distributed Optimization: To ensure that distributed
GD (or sub-gradient descent) reach consensus, many meth-
ods [1], [7], [8] use diminishing step-size (commonly 1/k).

 
 
 
 
 
 
For distributed MD, similar studies have been conducted
for stochastic optimization [9], [10] and online optimization
[11], [12]. Doan et al. [13] provide convergence results for
both centralized and decentralized MD algorithms. However,
convergence rates obtained using diminishing step-size are
sub-exponential and sub-optimal under assumptions of strong
convexity and smoothness.

To address this issue, a number of recent works introduce an
additional variable in the state vectors to track past gradients
(see e.g., [14]–[17]). One of the earlier works in this direction
is the EXTRA algorithm proposed by Shi et al. [14], which
uses the information from past
two iterations to perform
each update. For smooth problems, EXTRA provably achieves
O(1/k) convergence rate under the convexity assumption
and exponential convergence rate under the strong convexity
assumption, respectively.

A closely relevant

literature is the continuous-time dis-
tributed GD, where the algorithms are constructed by a set
of ordinary differential equations (ODEs). These works are
mostly based on the idea of integral feedback, which can
be thought as the continuous-time analog of gradient track-
ing. In this case, each agent uses an integration term as a
part of the ODE (see e.g., [18]–[21]). In these works, the
analysis is carried out by proving the Lyapunov stability for
the corresponding continuous-time dynamics, and exponential
stability can be obtained in certain cases [20]. For MD, the
continuous-time algorithm in [6], [22] and the discrete-time
algorithm in [23] both adapt the integral feedback (or gradient
tracking) method and propose algorithms that do not suffer
from sub-optimal convergence rates. Speciﬁcally, Sun et al.
[6] propose a continuous-time distributed MD that achieves
a “local” exponential rate for strongly convex problems, and
Yu et al. [23] provide an O(1/k) convergence rate under
the convexity assumption in discrete time. Nevertheless, the
exponential rate of (discrete-time) distributed MD for strongly
convex and smooth problems remains an open problem, which
we target in the current work.

2) Integral Quadratic Constraints: Deriving convergence
rates for iterative optimization algorithms in the worst-case is
an integral part of algorithm design. However, this procedure
is not principled, requires a case-by-case analysis, and might
lead to conservative rates. To automate convergence analysis
and derive sharp convergence rates, several past works have
used Integral Quadratic Constraints (IQCs) and semideﬁnite
programming in various settings [24]–[30], pioneered by the
work in [24]. IQCs are a tool from robust control to analyze
dynamical systems that contain components that are nonlinear,
uncertain, or difﬁcult to model [31]. The basic idea is to
abstract these troublesome components by constraints on their
input and output signals. This approach to algorithm analysis
can also guide the search for parameter selection in algorithm
design. [32], [33] are of particular relevance to our work. They
both provide IQC-based analysis of distributed gradient-based
algorithms in strongly convex settings. Compared to these
works, our framework focuses on distributed mirror descent
in both strongly convex and convex settings.

II. PRELIMINARIES

A. Notations

The identity matrix of dimension n is denoted by In and the
n-dimensional vector with all entries 1 is represented by 1n.
We denote the set of n-dimensional symmetric matrices by
Sn. The positive (negative) semi-deﬁniteness of matrix M is
denoted as M (cid:23) 0 (M (cid:22) 0). We use ⊗ and (cid:107)·(cid:107) to denote the
Kronecker product and spectral norm, respectively. We deﬁne
the norm of vector v with respect to a positive semi-deﬁnite
matrix M as (cid:107)v(cid:107)M . The indicator function of a set X ⊆ Rd is
deﬁned as IX (x) = 0 if x ∈ X and IX (x) = +∞ otherwise.

Deﬁnition 1 (Strong convexity). A differentiable function f :
Rd → R is µf -strongly convex on Rd if the following inequality
is true for all x, y ∈ Rd.

f (x) + ∇f (x)(cid:62)(y − x) +

µf
2

(cid:107)y − x(cid:107)2 ≤ f (y).

Deﬁnition 2 (Lipschitz smoothness). A differentiable function
f : Rd → R is Lf -smooth on Rd if Lf
2 (cid:107)x(cid:107)2 − f (x) is convex,
which implies that for all x, y ∈ Rd.

f (y) ≤ f (x) + ∇f (x)(cid:62)(y − x) +

Lf
2

(cid:107)y − x(cid:107)2 .

We further denote the condition number of function f by

≥ 1. When µf = 0, the function is only convex.

κf (cid:44) Lf
µf

Proposition 1. Suppose f is µf -strongly convex and Lf -
smooth on Rd. Then, the following inequality holds for all
x, y ∈ Rd, and u = ∇f (x), v = ∇f (y),

(cid:20)x − y
u − v

(cid:21)(cid:62) (cid:34) −µf Lf
µf +Lf
1
2 Id

Id

1
2 Id
−1
µf +Lf

Id

(cid:21)

(cid:35) (cid:20)x − y
u − v

≥ 0.

(2)

The above QC follows from the combination of strong

convexity and Lipschitz smoothness [24], [34].

B. Centralized Mirror Descent Algorithm

We start by providing some background on the centralized
MD algorithm. For simplicity in the exposition, we study the
unconstrained case, but our analysis can also be extended to
the constrained case. Let us start with the GD algorithm, whose
update is equivalent to the following minimization,

f (x(k)) + ∇f (x(k))(cid:62)(x−x(k))

(cid:26)

x(k+1) =argmin

x

+

1
2η

(cid:107)x−x(k)(cid:107)2

(cid:27)

,

where η > 0 is the step-size. In each iteration, the algorithm
seeks to minimize a ﬁrst-order approximation of the function
with a Euclidean regularizer. As a generalization of gradient
descent, MD replaces the squared Euclidean distance with
to a
Bregman divergence, which is deﬁned with respect
distance generating function (DGF) φ : Rd → R as follows

Dφ(x, x(cid:48)) (cid:44) φ(x) − φ(x(cid:48)) − (cid:104)∇φ(x(cid:48)), x − x(cid:48)(cid:105).

(3)

Assumption 1. The distance generating function φ : Rd → R
is µφ-strongly convex and Lφ-smooth.

The centralized (unconstrained) MD algorithm with step-

size η is written as

x(k+1) = argmin

(cid:26)

f (x(k)) + ∇f (x(k))(cid:62)(x − x(k))

x

+

1
η

Dφ(x, x(k))

(cid:27)

,

(4)

where if we choose the Bregman divergence to be the squared
Euclidean distance, the update above reduces to GD.

We can also view the MD update through a different
lens using the convex conjugate of function φ. The con-
vex conjugate of function φ, denoted by φ(cid:63), is deﬁned as
φ(cid:63)(z) (cid:44) supx∈Rd {(cid:104)x, z(cid:105) − φ(x)}. Assumption 1 guarantees
that φ(cid:63) is L−1
φ -smooth. We refer
the reader to [35] for further details. Correspondingly, the
following equivalence can be established,

φ -strongly convex and µ−1

z(cid:48) = ∇φ(x(cid:48)) ⇐⇒ x(cid:48) = ∇φ(cid:63)(z(cid:48)).

Theorem 2. Let Assumption 1 hold and assume that f is µf -
strongly convex and Lf -smooth. Deﬁne matrices Msc, Mf , Mφ
as follows,

Msc =

Mf =

Mφ =









Id






1−ρ
2µφ
0
0


0
0
0 −µf Lf

µf +Lf

1
2 Id
0

Id

−1
µφ+Lφ
1
2 Id
0

0
0
−η
2 Id

Id

0
−η
2 Id
η2
Id
2µφ
0
1
2 Id
−1
µf +Lf
1
2 Id
−µφLφ
µφ+Lφ
0

Id

Id


0

 .
0
0






(6)

If there exist some ρ ∈ (0, 1), η > 0, σf ≥ 0, σφ ≥ 0, such
that the following matrix inequality holds

Msc + σf Mf + σφMφ (cid:22) 0,

(7)

the centralized MD update can be rewritten in the

Then,
following form,

then the mirror descent algorithm in (5) converges exponen-
tially fast with the rate of ρ. In particular,

z(k+1) = z(k) − η∇f (x(k))
x(k+1) = ∇φ(cid:63)(z(k+1)),

(5)

(cid:107)x(k) − x(cid:63)(cid:107)2 ≤

2Dφ(cid:63) (z(0), z(cid:63))
µφ

ρk.

or, equivalently, z(k+1) = z(k) − η(∇f ◦ ∇φ(cid:63))(z(k)), which is
reminiscent of GD. We can see that MD is more general than
GD in that we can exploit the geometry of the problem using
an appropriate choice of φ, which makes MD more suitable
for problems such as convex clustering, matrix optimization
with regularization, etc. [36], [37].

Denoting x(cid:63) and z(cid:63) as the ﬁxed points of (5), we have

z(cid:63) = z(cid:63) − η∇f (x(cid:63)) x(cid:63) = ∇φ(cid:63)(z(cid:63)),

which implies that x(cid:63) is a minimizer of f .

III. CONVERGENCE ANALYSIS OF CENTRALIZED MIRROR
DESCENT

In this section, we provide a convergence analysis of the
centralized MD using semideﬁnite programming. Our starting
point is to describe all the nonlinear functions in the algorithm,
namely ∇f and ∇φ(cid:63) by QCs on their input-output pairs,
resulting in a quadratically-constrained linear system. We
then ﬁnd a suitable “rate-generating” Lyapunov function for
this constrained system using semideﬁnite programming. We
derive exponential (respectively, sub-exponential) convergence
rate for strongly convex (respectively, convex) functions.

A. Exponential Convergence for Strongly Convex f

In the following theorem, we characterize an LMI that
depends on parameters of f (µf and Lf ), parameters of φ (µφ
and Lφ), and several decision variables (including the step-size
η and the convergence rate ρ ∈ (0, 1)). We prove that if the
LMI is satisﬁed, the iterates converge exponentially fast to the
unique ﬁxed point (x(cid:63), z(cid:63)) with the rate ρ.

Proof. Denote u(k) (cid:44) ∇f (x(k)) and deﬁne the stacked vector

e(k)(cid:62)

= (cid:2)(z(k) − z(cid:63))(cid:62) (x(k) − x(cid:63))(cid:62) (u(k) − u(cid:63))(cid:62)(cid:3) . (8)

Then, from Proposition 1, we obtain the following quadratic
inequalities

e(k)(cid:62)Mf e(k) ≥ 0, e(k)(cid:62)Mφe(k) ≥ 0 ∀k,

which are imposed by ∇f and ∇φ, respectively. Consider
the Lyapunov candidate V (k) = ρ−kDφ(cid:63) (z(k), z(cid:63)). Recall
φ -strongly convex and µ−1
that φ(cid:63) is L−1
φ -smooth, so the
Lyapunov function is indeed non-negative and continuously
differentiable. Using Lemma 10 (provided in the appendix
of [38]), we can calculate the Lyapunov function difference
between two consecutive iterations as

V (k+1) − V (k) ≤ ρ−k−1e(k)(cid:62)Msce(k).

(9)

Utilizing the two quadratic inequalities imposed by the non-
linearities, we can write

V (k+1) − V (k) ≤ ρ−k−1e(k)(cid:62)Msce(k)
≤ ρ−k−1e(k)(cid:62)(Msc + σf Mf + σφMφ)e(k).
Now if the LMI in (7) holds, the Lyapunov function is non-
increasing, which yields

Dφ(cid:63) (z(k), z(cid:63)) = ρkV (k) ≤ ρkV (0) = ρkDφ(cid:63) (z(0), z(cid:63)).

(10)

Observing Dφ(cid:63) (z(k), z(cid:63)) = Dφ(x(cid:63), x(k)) and

µφ
2

(cid:107)x(k) − x(cid:63)(cid:107)2 ≤ Dφ(x(cid:63), x(k)),

completes the proof.

Theorem 2 provides a matrix inequality feasibility problem
that establishes the exponential convergence rate of MD for a

given ρ. This matrix inequality is linear in (ρ, σf , σφ) (but not
in η), allowing us to ﬁnd the smallest ρ by the semideﬁnite
program

minimize
ρ,σφ,σf
subject to

ρ

(11)

0 < ρ ≤ 1
η, σφ, σf ≥ 0
Msc + σf Mf + σφMφ (cid:22) 0.

If in addition we want to optimize ρ over the step-size η,
we can use Schur Complements to “convexify” the matrix
inequality with respect to η. We state this result formally in
the next proposition.

Proposition 3. The optimization problem in (11) is equivalent
to the following SDP,

minimize
η,ρ,σφ,σf
subject to

ρ

0 < ρ ≤ 1
η, σφ, σf ≥ 0

µφLφσφ
µφ+Lφ

2 + µf Lf σf

µf +Lf

−σφ
2
+ µφ
−σf
2
√
µφ√
2

−

0
−σf
2
σf
µf +Lf
η√

2µφ

(12)










(cid:23) 0

−

0
√
µφ√
2
η√

2µφ
1










σφ
µφ+Lφ

+ ρ−1
2µφ

−σφ
2
0

0

We refer to the appendix of [38] for the proof of this
proposition. We now show that the SDP in (12) has a feasible
solution for which we can analytically calculate the conver-
gence rate.

Proposition 4. The following selection

η = σf =

2µφ
µf + Lf

σφ =

4µf Lf
(µf + Lf )2

(1 + κφ)
κφ(κφ − 1)

ρopt = 1 −

4µf Lf
(µf + Lf )2κ2
φ

,

(13)

is a feasible solution to the SDP in (12).

The proof of the proposition can be found in the appendix
of [38]. Note that ρopt is an upper bound on the optimal value
of (12).

The recent work of [5] also proposed an explicit rate of 1 −
1
for MD under the PL condition. Though PL condition
φκ2
5κ2
f
is weaker than strong convexity, ρopt is strictly smaller than
the rate of [5]. Furthermore, in our result we do not make
full use of strong convexity: we only require the quadratic
inequality (2) to hold for the pair (x, x(cid:63)) (x arbitrary and x(cid:63)
the ﬁxed point of the algorithm), whereas for strongly convex
f this inequality holds for all (x, y). Our rate also recovers
the optimal rate of GD as a special case.

2 (cid:107)x(cid:107)2 the optimal rate ρopt in
Corollary 5. For φ(x) = 1
(13) coincides with the optimal convergence rate of gradient
descent.

2 (cid:107)x(cid:107)2, we have that φ(cid:63)(z) = 1

2 (cid:107)z(cid:107)2 and
Proof. If φ(x) = 1
(5) is equivalent to GD. In this case, the condition number
κφ = Lφ
= 1, and ρopt reduces to the optimal convergence
µφ
rate for GD (see Theorem 2.1.15 in [34]).

B. O(1/k) Convergence for Convex f

We now propose an LMI which estbalishes subexponential
convergence rate for the MD algorithm when the objective
function is convex (µf = 0).

Theorem 6. Let Assumption 1 hold and assume that f is
convex (µf = 0) and Lf -smooth (0 < Lf < ∞), and deﬁne
the matrix Mc as follows,

0
0


0

0
0
(cid:15)−η
2 I
If there exist some η > 0, σf ≥ 0, σφ ≥ 0, (cid:15) ≥ 0, such that
the following matrix inequality holds

0
(cid:15)−η
2 I
η2
I
2µφ

Mc =


 .

(14)



Mc + σf Mf + σφMφ (cid:22) 0,

(15)

then the ergodic mean of function value at iteration K satisﬁes

f (¯x(K)) − f (x(cid:63)) ≤

Dφ(cid:63) (z(0), z(cid:63))
(cid:15)K

,

where ¯x(K) = 1
K

K
(cid:80)
i=1

x(i).

We remark that a similar analysis can be applied to Theorem
6 to ﬁnd the best step-size that maximizes (cid:15). The details are
omitted due to space limitation.

Remark 1 (Constrained Mirror Descent). Consider the con-
strained version of centralized (lazy) MD [39],

z(k+1) = z(k) − η∇f (x(k))

s(k) = ∇φ(cid:63)(z(k))
x(k) = arg min
x∈X
where X is a convex subset of Rd. By deﬁning g(x) = IX (x)
as the indicator function of the set X and denoting its sub-
differential by ∂g, the optimality condition that characterizes
x(k) is

Dφ(x, s(k)),

(16)

∇φ(x(k)) − zk ∈ ∂g(x(k)),

Using the fact that the subdifferential ∂g is monotone (since
X is convex), we can rewrite (16) as

z(k+1) = z(k) − ηu(k)
u(k) (cid:44) ∇f (x(k))
v(k) (cid:44) ∇φ(xk),

(17)

subject to the quadratic constraint

(v(k) − v(cid:63) − (z(k) − z(cid:63)))(cid:62)(x(k) −x(cid:63)) ≥ 0 ∀k,

Furthermore, we can write two separate quadratic constraints
for the relationships u(k) = ∇f (x(k)) and v(k) = ∇φ(x(k)).
We can therefore employ the same approach and derive an LMI
as a sufﬁcient condition to establish exponential and O(1/k)
convergence rates for strongly convex and convex problems,
respectively.

IV. CONVERGENCE ANALYSIS OF DISTRIBUTED MIRROR
DESCENT

In the distributed setup, we have a network of agents,
characterized by an undirected graph G = (V, E), where
each node in V = {1, . . . , n} represents an agent, and the
connection between two agents i and j is captured by the edge
{i, j} ∈ E. We use Ni (cid:44) {j ∈ V : {i, j} ∈ E} to denote the
neighborhood of agent i. The graph Laplacian is represented
by L ∈ Rn×n.

Assumption 2. The graph G is undirected and connected, i.e.,
there exists a path between any two distinct agents i, j ∈ V.

The connectivity assumption implies that L has a unique

null eigenvalue; that is, L1n = 0.

A. Distributed Mirror Descent Algorithm

We ﬁrst introduce the distributed MD update, in which
each agent i in the network implements the following iterative
algorithm,

zi

(k+1) = zi

(k) − η1

(cid:0)∇fi(xi

(k))+yi

(k)(cid:1) − η2

(zi

(k) −zj

(k)),

(cid:88)

j∈Ni

yi

(k+1) = yi

(k) +η2

(zi

(k) −zj

(k)),

(cid:88)

j∈Ni

xi

(k+1) = ∇φ(cid:63)(zi

(k+1)).

(18)
The ﬁrst update uses private gradient information as well as the
dual variables from the neighbors. It also depends on a variable
(k) which acts as an integrator. This algorithm is similar
yi
to the discretized version of the distributed MD proposed in
[22] using the idea of integral feedback. However, the method
differs slightly in the local averaging in that the algorithm
in [22] performs local averaging with respect to the primal
variable, and here the averaging is done on the dual variable
zi

(k).
It is evident that the behavior of this system relies on the
network structure through the dependence on the Laplacian of
the graph capturing the network. Since L ∈ Sn, the LMIs will
consist of matrices whose dimensions scale with n, which is
not suitable when n is large. Following the idea in [32], [33],
we transform the updates such that the dependence on the full
structure of the network is avoided. Deﬁne

W (cid:44) In − η2L = ∆W +

1
n

1n1(cid:62)
n ,

and further denote the spectral norm of ∆W by λ (cid:44) (cid:107)∆W (cid:107).
The quantity 1 − λ is also known as the spectral gap.

To represent the updates collectively for all the agents, we

deﬁne the stacked vectors

1

1

n

](cid:62)
](cid:62)

, . . . , z(k)(cid:62)
, . . . , y(k)(cid:62)

z(k) = [z(k)(cid:62)
y(k) = [y(k)(cid:62)
u(k) = ∇f (x(k)) (cid:44) [∇f1(x(k)
x(k) = [∇φ(cid:63)(z(k)
v(k) = (∆W ⊗ Id)z(k).

n

1 )(cid:62), . . . , ∇fn(x(k)
n )(cid:62)](cid:62)

n )(cid:62)](cid:62)

1 )(cid:62), . . . , ∇φ(cid:63)(z(k)

(19)

We can now rewrite (18) as

1n1(cid:62)

z(k+1) = (

1
n
y(k+1) = y(k) + ((In −

1
n
v(k) = (∆W ⊗ Id)z(k)
x(k) = ∇φ(cid:63)(z(k))
u(k) = ∇f (x(k)).

n ⊗ Id)z(k) − η1(u(k) + y(k)) + v(k)

1n1(cid:62)

n ) ⊗ Id)z(k) − v(k)

To represent (20) in state-space form, we can write

(cid:21)

(cid:20)z(k+1)
y(k+1)

=

n ⊗ Id

n 1n1(cid:62)

(cid:20)
1
(In − 1
n 1n1(cid:62)
(cid:20)0 −η1Ind
0

+

0

n ) ⊗ Id

Ind
−Ind

(cid:21)

(cid:21) (cid:20)z(k)
y(k)

−η1Ind
Ind

x(k)
u(k)
v(k)





 .

(cid:21)

(20)

(21)

Additionally, we know the following constraints on the up-
dates,

(cid:21)
(cid:20)0
0

=

(cid:20)0 1n1(cid:62)
n ⊗ Id
0
0

(cid:21) (cid:20)z(k)
y(k)

(cid:21)

(cid:20)0
0

+

(cid:21)

0
0
0 1n1(cid:62)
n ⊗ Id


.





x(k)
u(k)
v(k)

(22)
We deﬁne the state vector ξ(k)(cid:62) (cid:44) (cid:2)z(k)(cid:62) y(k)(cid:62)(cid:3) as well
as the input vector ζ (k)(cid:62) (cid:44) (cid:2)x(k)(cid:62) u(k)(cid:62) v(k)(cid:62)(cid:3). We can
rewrite (21) and (22) as

ξ(k+1) = Aξ(k) + Bζ (k)

0 = F ξ(k) + Gζ (k),

(23)

where A, B, F, G are of appropriate dimensions. For the ease
of notation we denote H (cid:44) (cid:2)F G(cid:3).

For the purpose of convergence analysis, we characterize the
ﬁxed point of (21). Deﬁne x(cid:63) (cid:44) 1n ⊗ x(cid:63), where x(cid:63) ∈ Rd is a
minimizer of (1), and let z(cid:63) (cid:44) ∇φ(x(cid:63)), u(cid:63) (cid:44) ∇f (x(cid:63)), y(cid:63) (cid:44)
−∇f (x(cid:63)) and v(cid:63) = 0. By letting z(k), y(k), v(k), x(k), u(k) in
(21) take the values of z(cid:63), y(cid:63), v(cid:63), x(cid:63), u(cid:63), it is easy to show
that z(k+1) = z(k), y(k+1) = y(k) using Assumption 2.

B. Exponential Convergence of Distributed Mirror Descent

In the following theorem, we present the main result of this
section. We provide two LMIs to characterize the convergence
rate of distributed MD. The LMIs are written in terms of
several decision variables, including the step-size η1 and the
convergence rate ρ. If we can ﬁnd a feasible solution for
these LMIs, the distributed MD is guaranteed to converge
exponentially fast.

Before stating the theorem, we state the following lemma,

which will allow us to simplify the resulting SDP.

1 = J1, J 2

Lemma 7 (Lemma 6 in [32] ). Suppose that square matrices
J1, J2 satisfy J 2
2 = J2, J1J2 = J2J1 = 0. For
square matrices Q1 and Q2, deﬁne Q (cid:44) Q1 ⊗ J1 + Q2 ⊗
J2. Then, the following are equivalent: 1) Q (cid:23) 0. 2) Q1 (cid:23)
0, Q2 (cid:23) 0.

(cid:21)

A1 =

Theorem 8. Let Assumptions 1 and 2 hold and assume all
local functions fi are µf -strongly convex and Lf -smooth.
Deﬁne the following matrices,
(cid:20)0 −η1
1
1
(cid:20)1 −η1
0
1
(cid:20)0 0 0
0 0 0

(cid:20)0 −η1
0
0
(cid:20)0 −η1
0
0

1
−1
(cid:20)0 1
0 0

0 0
0 0

, H2 =

, B1 =

, B2 =

1
−1

H1 =

A2 =

0
0

0
0

0
1

(cid:21)

(cid:21)

(cid:21)

(cid:21)

(cid:21)

,

,

.

Furthermore, deﬁne


Mf =

Mλ =

Mφ =

0
0

0 0
0 0
0 0 −µf Lf
µf +Lf
1
0 0
2
0
0 0








0
0
1
2
−1
µf +Lf
0


0
0



0


0

0









λ2
0
0
0
0

0 0
0
0
0
0

0
0
0
0 0
0
0 0
0 0
0
0 0 −1


















−1
µφ+Lφ
0
1
2
0
0

1
2
0

0
0
0 −µφLφ
µφ+Lφ
0
0
0
0



0 0

0 0


0
0


0
0

0
0

.

there exists ρ ∈ (0, 1), η1 ≥ 0, P ∈ S2, P (cid:31)
If
0, Σeq ∈ S2, σf ≥ 0, σφ ≥ 0, σλ ≥ 0, such that the following
matrix inequalities hold for i = 1, 2
i P Ai −ρP A(cid:62)
B(cid:62)
B(cid:62)

+ σf Mf + σλMλ

(cid:20)A(cid:62)

(cid:21)

(24)

i P Ai
+ σφMφ + H (cid:62)

i P Bi
i P Bi
i ΣeqHi (cid:22) 0,

then the distributed MD algorithm (18) initialized at y(0) = 0
converges exponentially with a rate of ρ as follows

(cid:107)ξ(k) − ξ(cid:63)(cid:107)2

P ⊗Ind

≤ ρk(cid:107)ξ(0) − ξ(cid:63)(cid:107)2

P ⊗Ind

.

Proof. Deﬁne the vector e(k)(cid:62) = [ξ(k)(cid:62) ζ (k)(cid:62)]. We can
establish the following (in)equalities,

e(k)(cid:62)(Mf ⊗ Ind)e(k) ≥ 0,
e(k)(cid:62)(Mφ ⊗ Ind)e(k) ≥ 0,
e(k)(cid:62)(Mλ ⊗ Ind)e(k) ≥ 0,
e(k)(cid:62)H (cid:62)(Σeq ⊗ Ind)He(k) = 0.

The ﬁrst two inequalities are derived from Proposition 1, the
third inequality is due to the fact that λ = (cid:107)∆W (cid:107), and the
equality follows from the afﬁne constraint in (22).

Deﬁne the Lyapunov function

V (k) = ρ−k(ξ(k) − ξ(cid:63))(cid:62)P (cid:48)(ξ(k) − ξ(cid:63)),

where P (cid:48) (cid:44) P ⊗ Ind. Then, using (23) we can write

V (k+1) − V (k) = ρ−k−1e(k)(cid:62)

(cid:20)A(cid:62)P (cid:48)A − ρP (cid:48) A(cid:62)P (cid:48)B
B(cid:62)P (cid:48)B

B(cid:62)P (cid:48)A

(cid:21)

e(k).

Now, if the following LMI holds
(cid:20)A(cid:62)P (cid:48)A − ρP (cid:48) A(cid:62)P (cid:48)B
B(cid:62)P (cid:48)B

B(cid:62)P (cid:48)A

(cid:21)

+ σf Mf ⊗ Ind

+ σλMλ ⊗ Ind + σφMφ ⊗ Ind + H (cid:62)(Σeq ⊗ Ind)H (cid:22) 0,

(25)

then for any e(k), we have that

ρ−k−1e(k)(cid:62)

(cid:20)A(cid:62)P (cid:48)A − ρP (cid:48) A(cid:62)P (cid:48)B
B(cid:62)P (cid:48)B

B(cid:62)P (cid:48)A

(cid:21)

e(k) ≤ 0,

or, equivalently,

(ξ(k) − ξ(cid:63))(cid:62)P (cid:48)(ξ(k) − ξ(cid:63)) ≤ ρk(ξ(0) − ξ(cid:63))(cid:62)P (cid:48)(ξ(0) − ξ(cid:63)).

In words, the squared norm of system variables decreases
exponentially fast to zero.

Next, we simplify the LMI such that the dimension is not
dependent on the agent number n. Our approach follows that
of [32]. Deﬁne J1, J2 in Lemma 7 as J1 = (In − 1
n ) ⊗
Id, J2 = 1
n ⊗ Id. It is easy to verify that these matrices
satisfy the constraints in Lemma 7. We then have that

n 1n1(cid:62)

n 1n1(cid:62)

A = A1 ⊗ J1 + A2 ⊗ J2,
B = B1 ⊗ J1 + B2 ⊗ J2,
H = H1 ⊗ J1 + H2 ⊗ J2.

Since matrices J1, J2 satisfy the conditions in Lemma 7, if
we consider Q, Q1, Q2 as the negative left hand side of (25),
(24) respectively, then a feasible set of solutions that satisfy
(24) is equivalently a feasible set of solutions for (25), which
completes our proof.

The theorem provides two LMIs that establish the expo-
nential convergence rate of distributed MD. As we can see
the LMIs are more involved compared to the centralized case,
and it is challenging to ﬁnd even a suboptimal analytical rate.
We ﬁnally remark that common analysis on distributed
MD involves general primal-dual norms [11], whereas QCs
are deﬁned with respect to the Euclidean norm. The use of
general primal-dual norms in non-strongly convex problems
helps with improving the rate up to a multiplicative factor of
√
d. However, in strongly convex case the rate is exponentially
fast, and a more general analysis can only change the iteration
complexity by at most logarithmic factors of d, which is an
interesting avenue to investigate in the future.

C. O(1/k) Convergence for Convex Functions

In the following theorem, we present the counterpart of

Theorem 8 for convex problems.

2

1

and

hold

local

and
Theorem 9. Let Assumptions
functions fi are convex (µf = 0)
assume all
and Lf -smooth. Recall
of matrices
deﬁnitions
the
A1, A2, B1, B2, H1, H2, Mf , Mλ, Mφ in Theorem 8 and
deﬁne the following additional matrices,

0
0


0


0

0

0
0
0
0
0 Lf
0
0
0
0


0
0


0


0

0

0
0


0


0

0

M2 =

0
0
1
2
0
0

0
0
0
0
0

0
0
0
1
2
0

0
0
0
0
0

0
0
0
0
0

M1 =











.

(a) Convergence rates generated from The-
orem 8 versus step-size η1.

(b) Fixed κφ = 5. Varying λ and κf ,
optimal learning rate is chosen.

(c) Comparison of the convergence rates
for different methods.

Fig. 1: Optimal convergence rate for Distributed MD obtained by solving LMIs under various assumptions.

If there exist η1 ≥ 0, P ∈ S2, P (cid:31) 0, Σeq ∈ S2,σf ≥ 0, σφ ≥
0, σλ ≥ 0, (cid:15) ≥ 0, such that the following matrix inequalities
hold for i = 1, 2

(cid:20)A(cid:62)

i P Ai − P A(cid:62)
B(cid:62)
B(cid:62)

i P Ai

i P Bi
i P Bi

(cid:21)

+σf Mf + σλMλ

(26)

+ σφMφ + (cid:15)Mi + H (cid:62)

i ΣeqHi (cid:22) 0,

then, the iterates of the distributed MD algorithm (18) initial-
ized at y(0) = 0 satisfy the following inequality,

n
(cid:88)

(cid:16)

i=1

f (¯x(K)
i

) − f (cid:63)(cid:17)

≤

V (0)
(cid:15)K

,

where ¯x(K)

i

(cid:44) 1
K

K−1
(cid:80)
k=0

x(k)
i

.

We refer to the appendix of [38] for the proof of this
theorem. Given that f (¯x(K)
)−f (cid:63) is non-negative, it is easy to
see that the function evaluated at the ergodic average of each
agent iterate converges to minimum with a rate of O(1/K).

i

D. Evaluating the Tightness of Results

For the distributed MD algorithm, we provide numerical
results based on Theorem 8. First, we demonstrate the in-
ﬂuence of the network structure, and then we compare the
rate recovered by Theorem 8 to existing theoretical rates on
distributed GD when it achieves exponential convergence.

1) Impact of the Network Structure on Convergence Rate:
We calculate the worst-case convergence rate with several
choices of λ and plot it with respect to the step-size η1. We
set the local functions to have condition number κf = 2 and
the DGF to have condition number κφ = 2. Each curve in the
plot represents a certain λ and is obtained by scanning feasible
values for the decision variables in the LMIs (24). From Fig.
1a, we can see that there exists an optimal step-size to obtain
the best convergence rate, and that as λ increases, the best
rate becomes worse. Hence, for any given network structure
and its corresponding Laplacian matrix, we should select η2
such that λ is minimized. This is consistent with results on
distributed optimization, where having a larger λ deteriorates
the performance.

In Fig. 1b, we keep κφ = 5 constant and study the optimal
convergence rate for different λ and κf . When the condition
number increases, the optimal rate worsens. This behavior
aligns with gradient descent, where κφ = 1.

2) Comparison with Distributed Gradient Descent: To the
best of our knowledge, there is currently no work that provides
an exponential convergence rate for distributed MD algorithm.
Hence, we select
two previous works on distributed GD,
namely [14] and [15], and compare our performance with
the theoretical rates provided in these works. In order to
provide a fair comparison, we must set κφ = 1 to ensure
that MD reduces to GD. We also set the local functions to
have condition number κf = 3.

2

Of the two related works above, EXTRA [14] is of particular
relevance to our algorithm. If the matrix ˜W in EXTRA is set to
be In+W
, the EXTRA algorithm coincides with our algorithm
with the exception of having a coefﬁcient difference of 1
2
for the tracking term. Note that the theoretical convergence
rate of EXTRA relies on the spectral norm of ∆W as well
as the smallest non-zero eigenvalue λn of W . We plot the
convergence rate of EXTRA under three different scenarios:

1) λn = λ, (EXTRA pos)
2) λn = −λ, (EXTRA neg)
3) λn ≈ 0, (EXTRA)
From Fig. 1c, we can see that when λ is small, the rate
recovered by Theorem 8 signiﬁcantly outperforms EXTRA.
As λ increases, the convergence rate calculated for our method
starts increasing. We also include the theoretical convergence
results from Qu et al. [15], which is consistently outperformed
by EXTRA.

Note that the point of this plot is not to declare a winner
among algorithms. The goal is to show that the richness of
the Lyapunov function and QC analysis provides a machinery
to obtain better convergence rates, especially compared to the
rates that are algorithm speciﬁc. In this case, our algorithm can
coincide with EXTRA, but still our analysis provides better
rates. Our observation is in line with empirical results of [32].

V. CONCLUSION

In this paper, we proposed a SDP framework to characterize
the convergence rate of the mirror descent algorithm for both
centralized and distributed settings, and empirical evaluations
were performed under the assumption of strongly convex and
smooth local objective functions. For the centralized case, we
derived a closed-form feasible solution to the SDP for the
convergence rate, which depends on the condition number of
the distance generating function. For the decentralized case,

0.00.20.40.60.81.01.2Step Size 10.600.650.700.750.800.850.900.951.00Convergence Rate=0.0=0.1=0.2=0.3=0.4=0.5=0.6=0.7=0.8=0.90.00.20.40.60.80.700.750.800.850.900.951.00Optimal Convergence Rate=5f=1f=2f=4f=6f=8f=100.00.10.20.30.40.50.60.70.80.91.0Convergence RateQC (our result)Theoretical rate of EXTRATheoretical rate of EXTRA negTheoretical rate of EXTRA posTheoretical rate of Qu et al.we numerically derived the convergence rates using SDP.
These SDPs do not scale with the ambient dimension and the
network size. Using the QC framework, we further proved the
O(1/k) convergence rate for centralized and distributed MD in
the convex and smooth setting. It would be interesting to derive
analytical rates for the distributed case. Another important
direction is the analysis of the mirror descent algorithm with
primal-dual norms. This is a challenging problem as current
SDP approaches rely on the Euclidean norm and they do not
lend themselves to general primal-dual norms.

REFERENCES

[1] A. Nedic and A. Ozdaglar, “Distributed subgradient methods for multi-
agent optimization,” IEEE Transactions on Automatic Control, vol. 54,
no. 1, pp. 48–61, 2009.

[2] A. S. Nemirovsky and D. B. Yudin, “Problem complexity and method

efﬁciency in optimization.” 1983.

[3] A. Beck and M. Teboulle, “Mirror descent and nonlinear projected
subgradient methods for convex optimization,” Operations Research
Letters, vol. 31, no. 3, pp. 167–175, 2003.

[4] A. Ben-Tal, T. Margalit, and A. Nemirovski, “The ordered subsets mirror
descent optimization method with applications to tomography,” SIAM
Journal on Optimization, vol. 12, no. 1, pp. 79–108, 2001.

[5] A. Radhakrishnan, M. Belkin, and C. Uhler, “Linear convergence
and implicit regularization of generalized mirror descent with time-
dependent mirrors,” arXiv preprint arXiv:2009.08574, 2020.

[6] Y. Sun and S. Shahrampour, “Linear convergence of distributed mirror
descent with integral feedback for strongly convex problems,” IEEE
Conference on Decision and Control (CDC), 2021.

[7] A. Nedic, A. Ozdaglar, and P. A. Parrilo, “Constrained consensus and
optimization in multi-agent networks,” IEEE Transactions on Automatic
Control, vol. 55, no. 4, pp. 922–938, 2010.

[8] P. Lin, W. Ren, and Y. Song, “Distributed multi-agent optimization sub-
ject to nonidentical constraints and communication delays,” Automatica,
vol. 65, pp. 120–131, 2016.

[9] D. Yuan, Y. Hong, D. W. Ho, and G. Jiang, “Optimal distributed
stochastic mirror descent for strongly convex optimization,” Automatica,
vol. 90, pp. 196–203, 2018.

[10] M. Rabbat, “Multi-agent mirror descent for decentralized stochastic
optimization,” in IEEE 6th International Workshop on Computational
Advances in Multi-Sensor Adaptive Processing (CAMSAP), 2015, pp.
517–520.

[11] S. Shahrampour and A. Jadbabaie, “Distributed online optimization in
dynamic environments using mirror descent,” IEEE Transactions on
Automatic Control, vol. 63, no. 3, pp. 714–725, 2018.

[12] D. Yuan, Y. Hong, D. W. C. Ho, and S. Xu, “Distributed mirror descent
for online composite optimization,” IEEE Transactions on Automatic
Control, pp. 1–1, 2020.

[13] T. T. Doan, S. Bose, D. H. Nguyen, and C. L. Beck, “Convergence of
the iterates in mirror descent methods,” IEEE Control Systems Letters,
vol. 3, no. 1, pp. 114–119, 2019.

[14] W. Shi, Q. Ling, G. Wu, and W. Yin, “Extra: An exact ﬁrst-order
algorithm for decentralized consensus optimization,” SIAM Journal on
Optimization, vol. 25, no. 2, pp. 944–966, 2015.

[15] G. Qu and N. Li, “Harnessing smoothness to accelerate distributed
optimization,” IEEE Transactions on Control of Network Systems, vol. 5,
no. 3, pp. 1245–1260, 2017.

[16] Y. Sun, A. Daneshmand, and G. Scutari, “Convergence rate of distributed
tracking,” arXiv preprint

optimization algorithms based on gradient
arXiv:1905.02637, 2019.

[17] S. Pu and A. Nedi´c, “Distributed stochastic gradient tracking methods,”

Mathematical Programming, pp. 1–49, 2020.

[18] B. Gharesifard and J. Cort´es, “Distributed continuous-time convex opti-
mization on weight-balanced digraphs,” IEEE Transactions on Automatic
Control, vol. 59, no. 3, pp. 781–786, 2013.

[19] X. Zeng, P. Yi, and Y. Hong, “Distributed continuous-time algorithm
for constrained convex optimizations via nonsmooth analysis approach,”
IEEE Transactions on Automatic Control, vol. 62, no. 10, pp. 5227–
5233, 2017.

[20] S. S. Kia, J. Cort´es, and S. Mart´ınez, “Distributed convex optimization
via continuous-time coordination algorithms with discrete-time commu-
nication,” Automatica, vol. 55, pp. 254–264, 2015.

[21] S. Yang, Q. Liu, and J. Wang, “A multi-agent system with a proportional-
integral protocol for distributed constrained optimization,” IEEE Trans-
actions on Automatic Control, vol. 62, no. 7, pp. 3461–3467, 2016.
[22] Y. Sun and S. Shahrampour, “Distributed mirror descent with integral
feedback: Asymptotic convergence analysis of continuous-time dynam-
ics,” IEEE Control Systems Letters, vol. 5, no. 5, pp. 1507–1512, 2020.
[23] Y. Yu and B. Ac¸ıkmes¸e, “RLC circuits-based distributed mirror descent
method,” IEEE Control Systems Letters, vol. 4, no. 3, pp. 548–553, 2020.
[24] L. Lessard, B. Recht, and A. Packard, “Analysis and design of opti-
mization algorithms via integral quadratic constraints,” SIAM Journal
on Optimization, vol. 26, no. 1, pp. 57–95, 2016.

[25] M. Fazlyab, A. Ribeiro, M. Morari, and V. M. Preciado, “Analysis of
optimization algorithms via integral quadratic constraints: Nonstrongly
convex problems,” SIAM Journal on Optimization, vol. 28, no. 3, pp.
2654–2689, 2018.

[26] B. Hu and L. Lessard, “Dissipativity theory for nesterov’s accelerated
PMLR,

method,” in International Conference on Machine Learning.
2017, pp. 1549–1557.

[27] A. B. Taylor, J. M. Hendrickx, and F. Glineur, “Smooth strongly convex
interpolation and exact worst-case performance of ﬁrst-order methods,”
Mathematical Programming, vol. 161, no. 1-2, pp. 307–345, 2017.
[28] N. K. Dhingra, S. Z. Khong, and M. R. Jovanovi´c, “The proximal
augmented lagrangian method for nonsmooth composite optimization,”
IEEE Transactions on Automatic Control, vol. 64, no. 7, pp. 2861–2868,
2018.

[29] N. S. Aybat, A. Fallah, M. Gurbuzbalaban, and A. Ozdaglar, “Robust
accelerated gradient methods for smooth strongly convex functions,”
SIAM Journal on Optimization, vol. 30, no. 1, pp. 717–751, 2020.
[30] C. Scherer and C. Ebenbauer, “Convex synthesis of accelerated gradient

algorithms,” arXiv preprint arXiv:2102.06520, 2021.

[31] A. Megretski and A. Rantzer, “System analysis via integral quadratic
constraints,” IEEE Transactions on Automatic Control, vol. 42, no. 6,
pp. 819–830, 1997.

[32] A. Sundararajan, B. Hu, and L. Lessard, “Robust convergence analysis
of distributed optimization algorithms,” in 2017 55th Annual Allerton
Conference on Communication, Control, and Computing (Allerton).
IEEE, 2017, pp. 1206–1212.

[33] A. Sundararajan, B. Van Scoy, and L. Lessard, “Analysis and design of
ﬁrst-order distributed optimization algorithms over time-varying graphs,”
IEEE Transactions on Control of Network Systems, vol. 7, no. 4, pp.
1597–1608, 2020.

[34] Y. Nesterov et al., Lectures on convex optimization.

Springer, 2018,

vol. 137.

[35] J.-B. Hiriart-Urruty and C. Lemar´echal, Fundamentals of convex anal-

ysis. Springer Science & Business Media, 2012.

[36] D. Lashkari and P. Golland, “Convex clustering with exemplar-based
models,” Advances in Neural Information Processing Systems, vol. 20,
2007.

[37] A. Benfenati, E. Chouzenoux, and J.-C. Pesquet, “Proximal approaches
for matrix optimization problems: Application to robust precision matrix
estimation,” Signal Processing, vol. 169, p. 107417, 2020.

[38] Y. Sun, M. Fazlyab, and S. Shahrampour, “On centralized and distributed
mirror descent: Exponential convergence analysis using quadratic con-
straints,” arXiv preprint arXiv:2105.14385, 2021.

[39] E. Hazan, “Introduction to online convex optimization,” Foundations and

Trends in Optimization, vol. 2, no. 3-4, pp. 157–325, 2016.

APPENDIX

A. Preliminary Lemmas for Proof of Theorems

In this section we provide a few lemmas used in the proof

of main theorems later.

Lemma 10. Let Assumption 1 hold and consider the Lya-
punov function V (k) = ρ−kDφ(cid:63) (z(k), z(cid:63)). Then, the following
inequality,

V (k+1) − V (k) ≤ ρ−k−1e(k)(cid:62)Msce(k),

is satisﬁed, where Msc is given in Theorem 2, and e(k) is
deﬁned in (8).

Proof. From the deﬁnition of Lyapunov function and Bregman
divergence, we have that

V (k+1) − V (k)

=ρ−k−1Dφ(cid:63) (z(k+1), z(cid:63)) − ρ−kDφ(cid:63) (z(k), z(cid:63))
=ρ−k−1(φ(cid:63)(z(k+1)) − φ(cid:63)(z(cid:63)) − (cid:104)∇φ(cid:63)(z(cid:63)), z(k+1) − z(cid:63)(cid:105))−

ρ−k(φ(cid:63)(z(k)) − φ(cid:63)(z(cid:63)) − (cid:104)∇φ(cid:63)(z(cid:63)), z(k) − z(cid:63)(cid:105))
=ρ−k−1φ(cid:63)(z(k+1)) − ρ−k−1(cid:104)x(cid:63), z(k) − z(cid:63) − ηu(k)(cid:105)
+ρ−k(cid:104)x(cid:63), z(k) − z(cid:63)(cid:105) − (ρ−k−1 − ρ−k)φ(cid:63)(z(cid:63)) − ρ−kφ(cid:63)(z(k)).

Since φ(cid:63) is µ−1

φ -smooth, we get

V (k+1) − V (k)

≤ ρ−k−1[φ(cid:63)(z(k)) + (cid:104)x(k), −ηu(k)(cid:105) +

η2
2µφ

(cid:107)u(k)(cid:107)2]

− ρ−k−1(cid:104)x(cid:63), z(k) − z(cid:63) − ηu(k)(cid:105) + ρ−k(cid:104)x(cid:63), z(k) − z(cid:63)(cid:105)

− (ρ−k−1 − ρ−k)φ(cid:63)(z(cid:63)) − ρ−kφ(cid:63)(z(k))

= (ρ−k−1 − ρ−k)(φ(cid:63)(z(k)) − φ(cid:63)(z(cid:63))) +

ρ−k−1η2
2µφ

(cid:107)u(k)(cid:107)2

− (ρ−k−1 − ρ−k)(cid:104)x(cid:63), z(k) − z(cid:63)(cid:105) − ρ−k−1(cid:104)x(k) − x(cid:63), ηu(k)(cid:105).

Applying smoothness again, we can bound V (k+1) − V (k) by

(ρ−k−1 − ρ−k)(∇φ(cid:63)(z(cid:63))(cid:62)(z(k) − z(cid:63)) +

1
2µφ

(cid:107)z(k) − z(cid:63)(cid:107)2)

+ ρ−k−1(cid:104)x(k) − x(cid:63), −ηu(k)(cid:105) +

ρ−k−1η2
2µφ

(cid:107)u(k)(cid:107)2

− (ρ−k−1 − ρ−k)(cid:104)x(cid:63), z(k) − z(cid:63)(cid:105)

= ρ−k−1(

1 − ρ
2µφ

(cid:107)z(k) − z(cid:63)(cid:107)2 − η(cid:104)x(k) − x(cid:63), u(k)(cid:105) +

η2
2µφ

(cid:107)u(k)(cid:107)2)

= ρ−k−1e(k)(cid:62)Msce(k),

and observing u(cid:63) = 0 ﬁnishes the proof.

Lemma 11. Let Assumption 1 hold and consider the Lyapunov
function V (k) = (cid:15) (cid:80)k−1
i=0 (f (x(i)) − f (x(cid:63))) + Dφ(cid:63) (z(k), z(cid:63)),
deﬁned for (cid:15) > 0. Then, when f is convex, the following
inequality holds

V (k+1) − V (k) ≤ e(k)(cid:62)Mce(k),
where Mc is given in Theorem 6, and e(k) is deﬁned in (8).

Proof. Following the proof of Lemma 10 and by setting ρ = 1,
we know that
Dφ(cid:63) (z(k+1), z(cid:63)) − Dφ(cid:63) (z(k), z(cid:63)) ≤ −η(cid:104)x(k) − x(cid:63), u(k)(cid:105) + η2
2µφ

(cid:107)u(k)(cid:107)2.

Therefore, we can bound V (k+1) − V (k) using the convexity
of f and observing u(cid:63) = 0, as follows

− η(cid:104)x(k) − x(cid:63), u(k)(cid:105) +

≤ − η(cid:104)x(k) − x(cid:63), u(k)(cid:105) +

=e(k)(cid:62)Mce(k).

η2
2µφ
η2
2µφ

(cid:107)u(k)(cid:107)2 + (cid:15)(f (x(k)) − f (x(cid:63)))

(cid:107)u(k)(cid:107)2 + (cid:15)(cid:104)u(k) − u(cid:63), x(k) − x(cid:63)(cid:105)

n
(cid:88)

(cid:16)

i=1
n
(cid:88)

(cid:16)

i=1
n
(cid:88)

(cid:16)

i=1
n
(cid:88)

(cid:16)

=

≤

≤

=

=

Lemma 12. Assume all local functions fi are convex (µf = 0)
and Lf -smooth. Then, the following inequality holds for the
distributed algorithm in (20)
n
(cid:88)

(k)) − f (cid:63)) ≤ e(k)(cid:62)M e(k),

(f (xi

i=1

where f (cid:63) (cid:44) minx f (x) and M ∈ R5nd×5nd is deﬁned as
0
0


0


0

0

0
0
0 Lf (In − 1
0
0

0
0
2n 1n1(cid:62)
n ⊗ Id
0
0

0
0
n 1n1(cid:62)
2n 1n1(cid:62)
n ⊗ Id
0


0
0


0


0

0

n ) ⊗ Id

M (cid:44)



1

1

.

Proof. Recall
that we denote an optimal solution of the
function in (1) as x(cid:63) ∈ Rd. From the deﬁnition of f , we
know that (cid:80)n
i=1 ∇fi(x(cid:63)) = 0. We note that the dimension of
x(cid:63) differs from that of the stationary point of the distributed
system x(cid:63) ∈ Rnd. Speciﬁcally, we have x(cid:63) (cid:44) 1n ⊗ x(cid:63).
at agent j, we have that

For any x(k)

j

n(f (xj

(k)) − f (cid:63)) =

n
(cid:88)

i=1

(fi(xj

(k)) − fi(x(cid:63)))

fi(xj

(k)) − fi(x(k)

i

) + fi(x(k)

i

) − fi(x(cid:63))

(cid:17)

∇fi(x(k)

i

)(cid:62)(xj

(k) − x(k)

i

) +

∇fi(x(k)

i

)(cid:62)(xj

(k) − x(k)

i

) +

Lf
2

Lf
2

(cid:107)xj

(cid:107)xj

(k) − x(k)

i (cid:107)2 + fi(x(k)

i

(cid:17)

) − fi(x(cid:63))

(k) − x(k)

i (cid:107)2 + ∇fi(x(k)

i

)(cid:62)(x(k)

(cid:17)
i − x(cid:63))

∇fi(x(k)

i

)(cid:62)(xj

(k) − x(k)

i + x(k)

i − x(cid:63)) +

i=1
n
(cid:88)

i=1

(cid:16)(cid:0)∇fi(x(k)

i

) − ∇fi(x(cid:63))(cid:1)(cid:62)

(xj

(k) − x(cid:63)) +

(k) − x(k)

i (cid:107)2(cid:17)

(cid:107)xj

(k) − x(k)

i (cid:107)2(cid:17)

,

(cid:107)xj

Lf
2

Lf
2

where the two inequalities are induced by the Lipschitz-
smoothness and convexity of fi, respectively. Since x(cid:63) is a
global optimal solution, we also have
n
(cid:88)

n
(cid:88)

(∇fi(x(cid:63))(cid:62)(xj

(k)−x(cid:63))) = (

∇fi(x(cid:63)))(cid:62)(xj

(k)−x(cid:63)) = 0.

i=1
Summing over j, we get
n
(cid:88)

n

(f (xj

(k)) − f (cid:63))

i=1

j=1
n
(cid:88)

n
(cid:88)

≤

(cid:0)∇fi(x(k)

i

) − ∇fi(x(cid:63))(cid:1)(cid:62)

(xj

(k) − x(cid:63))

j=1

i=1
n
(cid:88)

n
(cid:88)

+

j=1

i=1

Lf
2

(cid:107)xj

(k) − x(k)

i (cid:107)2.

Writing above in matrix form and dividing by n, we derive

n
(cid:88)

(f (xj

j=1

(k)) − f (cid:63))

=(u(k) − u(cid:63))(cid:62)(

1n1(cid:62)
+ Lf (x(k) − x(cid:63))(cid:62)(cid:16)

1
n

=e(k)(cid:62)M e(k).

n ⊗ Id)(x(k) − x(cid:63))

(In −

1n1(cid:62)

n ) ⊗ Id

(cid:17)

(x(k) − x(cid:63))

1
n

We can then remove I inside the block matrix elements in the
equation above and apply Lemma 13 to get

B. Proof of Proposition 3

We start with the following lemma, which helps with turning

the non-afﬁne constraint to an afﬁne constraint in the SDP.

Lemma 13. If matrix M ∈ Rn×n can be decomposed as
M = N + SS(cid:62), where S ∈ Rn×m, then a negative semi-
deﬁnite constraint on M can be equivalently represented by
an afﬁne constraint on N and S.

=⇒

Proof. Consider the following matrix M (cid:48) ∈ R(n+m)×(n+m)

M (cid:48) =

(cid:21)

(cid:20)−N S
S(cid:62) Im

.

By properties of Schur complement, we have that

=⇒





ρ−1
2µφ
0
0

0
µφ
2
0


0
 +
0
0


0
0


0

0
µf Lf σf
µf +Lf
−σf
2






σφ
µφ+Lφ
−σφ
2
0

+

−σφ
2
µφLφσφ
µφ+Lφ
0






 −




0

0
0

−

0
√
µφ√
2
η√

2µφ











0
−σf
2
σf
µf +Lf







(cid:62)

−

0
√
µφ√
2
η√

2µφ




(cid:23) 0















σφ
µφ+Lφ

+ ρ−1
2µφ

−σφ
2
0

µφLφσφ
µφ+Lφ

−σφ
2
+ µφ
−σf
2

2 + µf Lf σf

µf +Lf






−

−

0
√
µφ√
2
η√

2µφ











0
−σf
2
σf
µf +Lf







(cid:62)

−

0
√
µφ√
2
η√

2µφ




(cid:23) 0

σφ
µφ+Lφ

+ ρ−1
2µφ

−σφ
2
0

0

µφLφσφ
µφ+Lφ

2 + µf Lf σf

µf +Lf

−σφ
2
+ µφ
−σf
2
√
µφ√
2

−

0
−σf
2
σf
µf +Lf
η√

2µφ










(cid:23) 0,

−

0
√
µφ√
2
η√

2µφ
1

M (cid:48) (cid:23) 0 ⇐⇒ −N − SS(cid:62) (cid:23) 0 ⇐⇒ M (cid:22) 0.

thereby completing the proof.

Therefore, we can equivalently use M (cid:48) (cid:23) 0 as the constraint
(in lieu of M (cid:22) 0). This constraint is afﬁne with respect to
both N and S.

C. Proof of Proposition 4
If η = σf = 2µφ
µf +Lf

, the LMI in (11) becomes

We now provide the proof for Proposition 3.

Proof. For brevity, in this proof we use I = Id. Given the
matrices deﬁned in Theorem 2, we can write the last LMI in
(11) as

I






1−ρ
2µφ
0
0

0
0
−η
2 I

0
−η
2 I
η2
I
2µφ




 + σf

0


0
0 −µf Lf

µf +Lf

I
0
2

+σφ

I






−1
µφ+Lφ
I
2
0

which implies

I

0
I
2
−1
µf +Lf
I
2
−µφLφ
µφ+Lφ
0

I






I


0

 (cid:22) 0,
0
0

I





1−ρ
2µφ
0
0

0
−µφ
2 I
0



0
 + σf
0
0

0


0
0 −µf Lf

µf +Lf

I
0
2

I

0
I
2
−1
µf +Lf

+σφ

I






−1
µφ+Lφ
I
2
0

I
2
−µφLφ
µφ+Lφ
0

I







0

 +
0
0











−

0
√
µφI
√
2
ηI√

2µφ

−

0
√
µφI
√
2
ηI√

2µφ






I

(cid:62)






(cid:22) 0






Id

(1−ρ)
2µφ
0

0






+σφ

0
0
−µφ
µf +Lf
−1
µφ+Lφ
1
2 Id
0

Id

Id






0
−µφ
Id
µf +Lf
2µφ
(µf +Lf )2 Id

1
0
2 Id
−µφLφ

0

µφ+Lφ
0
0


Id

0
µφ
µf +Lf


0
0


0

+

2µφ
µf +Lf

0
−µf Lf
µf +Lf
Id

µφ
µf +Lf

Id

Id
−1
µf +Lf


 (cid:22) 0,

Id

2µφ
µf +Lf

which, after removing Id, simpliﬁes to




(1−ρ)
2µφ
0
0




0
−2µφµf Lf
(µf +Lf )2
0


0

 + σφ
0
0

−1
µφ+Lφ
1
2
0




1
2
−µφLφ
µφ+Lφ
0


0

 (cid:22) 0,
0
0

and we get

(cid:34) (1−ρ)
2µφ
0
(cid:34) (1−ρ)
2µφ

0
−2µφµf Lf
(µf +Lf )2

1
µφ+Lφ

− σφ
σφ
2

⇐⇒

(cid:35)

(cid:34) −1

+ σφ

µφ+Lφ
1
2
σφ
2

−2µφµf Lf
(µf +Lf )2 − σφ

1
2
−µφLφ
µφ+Lφ

(cid:35)

(cid:35)

µφLφ
µφ+Lφ

(cid:22) 0

(cid:22) 0

This is equivalent to the following constraints on the principal
minors of the matrix:

1)

2)

3)

(cid:18)

−

−

(1 − ρ)
2µφ

+ σφ

1
µφ + Lφ

≥ 0

2µφµf Lf
(µf + Lf )2 + σφ

µφLφ
µφ + Lφ

≥ 0

Summing up both sides and rearranging terms, we obtain

(cid:80)K

i=1(f (x(i)) − f (x(cid:63)))
K

≤

Dφ(cid:63) (z(0), z(cid:63))
(cid:15)K

.

The left hand side is again lower bounded by f (¯x(K))−f (x(cid:63))
due to the convexity of f , which completes the proof.

(1 − ρ)
2µφ
µφLφ
µφ + Lφ

+ σφ

(cid:19)

−

1
µφ + Lφ
σ2
φ
4

≥ 0

+ σφ

(cid:19)(cid:18) 2µφµf Lf
(µf + Lf )2

E. Proof of Theorem 9
Proof. Recalling Proposition 1, based on the assumptions, we
have that

The last constraint is the most strict of all constraints. Hence,
we will focus on the last constraint, where we can alternatively
write

ρ ≥ 1 −

2σφ
1 + κφ

+

σ2
φ
2

(cid:18) 2µf Lf
(µf + Lf )2 + σφ

κφ
1 + κφ

(cid:19)−1

.

The right-hand side can be seen as a function of σφ; it takes
its minimum when derivative of σφ is zero. We denote the
optimal σφ by σ(cid:63)

φ. Therefore,

d
dσφ

(cid:18)

1 −

2σφ
1 + κφ

+

σ2
φ
2

(cid:18) 2µf Lf
(µf + Lf )2 + σφ

κφ
1 + κφ

(cid:19)−1(cid:19)

= 0

The positive solution for the equation above is

σ(cid:63)
φ =

4µf Lf
(µf + Lf )2

(1 + κφ)
κφ(κφ − 1)

,

e(k)(cid:62)(Mf ⊗ Ind)e(k) ≥ 0,
e(k)(cid:62)(Mφ ⊗ Ind)e(k) ≥ 0.

Note that for the mapping z (cid:55)→ ∆W z, given that λ = (cid:107)∆W (cid:107),
we can write

e(k)(cid:62)(Mλ ⊗ Ind)e(k) ≥ 0.

Using Lemma 12, we know that

n
(cid:88)

i=1

(f (xi

(k)) − f (cid:63)) ≤ e(k)(cid:62)M e(k),

where M ∈ R5nd×5nd is deﬁned as

M (cid:44)


0
0


0


0

0

0
0
0 Lf (In − 1
0
0

0
0
n 1n1(cid:62)
2n 1n1(cid:62)
n ⊗ Id
0

1

n ) ⊗ Id

1

0
0
2n 1n1(cid:62)
n ⊗ Id
0
0



0
0


0


0

0

.

and the corresponding solution for ρ is
(cid:18) 2µf Lf
(µf + Lf )2 + σ(cid:63)

2σ(cid:63)
φ
1 + κφ

ρopt = 1 −

σ(cid:63)2
φ
2

+

φ

= 1 −

4µf Lf
(µf + Lf )2κ2
φ

,

thereby completing the proof.

(cid:19)−1

κφ
1 + κφ

Also, from (22), we have the following equality for any Σeq ∈
S2,

e(k)(cid:62)H (cid:62)(Σeq ⊗ Ind)He(k) = 0.

Now, let us deﬁne the Lyapunov function

V (k) = (ξ(k) − ξ(cid:63))(cid:62)P (cid:48)(ξ(k) − ξ(cid:63)),

D. Proof of Theorem 6

Proof. We consider the following Lyapunov candidate

V (k) = (cid:15)

k−1
(cid:88)

i=0

(f (x(i)) − f (x(cid:63))) + Dφ(cid:63) (z(k), z(cid:63)).

where P (cid:48) = P ⊗ Ind. Then, using (23) we can derive
(cid:21)

(cid:20)A(cid:62)P (cid:48)A − P (cid:48) A(cid:62)P (cid:48)B
B(cid:62)P (cid:48)B

B(cid:62)P (cid:48)A

e(k).

V (k+1) − V (k) = e(k)(cid:62)

If the following LMI holds

(cid:20)A(cid:62)P (cid:48)A − P (cid:48) A(cid:62)P (cid:48)B
B(cid:62)P (cid:48)B

B(cid:62)P (cid:48)A

(cid:21)

+ H (cid:62)(Σeq ⊗ Ind)H

(30)

Using Lemma 11, we can calculate an upper bound for the
following term

V (k+1) − V (k) ≤ e(k)(cid:62)Mce(k).

(27)

Combined with the two QCs, the above implies that

+ (cid:15)M + (σf Mf + σλMλ + σφMφ) ⊗ Ind (cid:22) 0,

then for any e(k), we have that

e(k)(cid:62)(

(cid:20)A(cid:62)P (cid:48)A − P (cid:48) A(cid:62)P (cid:48)B
B(cid:62)P (cid:48)B

B(cid:62)P (cid:48)A

(cid:21)

+ (cid:15)M )e(k) ≤ 0.

V (k+1) − V (k) ≤ e(k)(cid:62)Mce(k)

This inequality implies that

≤ e(k)(cid:62)Mce(k) + σf e(k)(cid:62)Mf e(k) + σφe(k)(cid:62)Mφe(k)
= e(k)(cid:62)(Mc + σf Mf + σφMφ)e(k).

(28)

If the LMI in (15) is feasible, then the Lyapunov function
satisﬁes V (k+1) ≤ V (k), which is equivalent to

Dφ(cid:63) (z(k+1), z(cid:63)) − Dφ(cid:63) (z(k), z(cid:63)) ≤ −(cid:15)(f (x(k)) − f (x(cid:63))).

(29)

V (k+1) − V (k) + (cid:15)

n
(cid:88)

(f (xi

(k)) − f (cid:63)) ≤ 0,

i=1
due to Lemma 12. By summing up both sides from k = 0 to
K − 1, applying convexity of f and rearranging, we have

n
(cid:88)

(cid:16)

i=1

f (¯x(K)
i

) − f (cid:63)(cid:17)

≤

V (0)
(cid:15)K

,

where ¯x(K)

i

(cid:44) 1
K

x(k)
i

. Again, the LMI in (30) can be

simpliﬁed by deﬁning J1, J2 in Lemma 7 similar to the proof
of Theorem 8, which completes the proof.

K−1
(cid:80)
k=0

