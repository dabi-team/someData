GSGP-CUDA - a CUDA framework for Geometric
Semantic Genetic Programming

Leonardo Trujillo1, Jose Manuel Mu˜noz Contreras1, Daniel E Hernandez1∗,
Mauro Castelli2, Juan J Tapia3
1 Tecnol´ogico Nacional de M´exico/IT de Tijuana, Tijuana, B.C., Mexico
2 NOVA Information Management School (NOVA IMS), Universidade Nova de Lisboa, Campus
de Campolide, 1070-312, Lisboa, Portugal
3 Instituto Polit´ecnico Nacional - CITEDI, Av. Instituto Polit´ecnico Nacional No. 1310 Colonia
Nueva Tijuana, C.P. 22435, Tijuana, B.C., Mexico

Abstract

Geometric Semantic Genetic Programming (GSGP) is a state-of-the-art machine
learning method based on evolutionary computation. GSGP performs search op-
erations directly at the level of program semantics, which can be done more efﬁ-
ciently then operating at the syntax level like most GP systems. Efﬁcient imple-
mentations of GSGP in C++ exploit this fact, but not to its full potential. This
paper presents GSGP-CUDA, the ﬁrst CUDA implementation of GSGP and the
most efﬁcient, which exploits the intrinsic parallelism of GSGP using GPUs. Re-
sults show speedups greater than 1, 000× relative to the state-of-the-art sequential
implementation.

Keywords: Genetic Programming, Geometric Semantic Genetic Programming,
CUDA, GPU

∗Corresponding author

1
2
0
2

n
u
J

8

]
E
N
.
s
c
[

1
v
4
3
0
4
0
.
6
0
1
2
:
v
i
X
r
a

Preprint submitted to SoftwareX

June 9, 2021

 
 
 
 
 
 
link to code/repository

Nr. Code metadata description
C1 Current code version
C2

Permanent
used for this code version
C3 Code Ocean compute capsule
C4 Legal Code License
C5 Code versioning system used
C6

Software code languages, tools, and
services used

C7 Compilation requirements, operating

environments & dependencies

C8

C9

If available Link to developer docu-
mentation/manual
Support email for questions

Please ﬁll in this column
v1.0
http://tiny.cc/0sbwjza

PENDING
GNU General Public License v3.0
None
C/C++/CUDA,CUBLAS

Toolkit CUDA v10.1 && v9.2, GCC
,Headers
v7.4.0, CUBLAS v2.0
Linux, unix-like systems
(Ubuntu
Linux18.04)
htt p : //PENDING/doc/

leonardo.trujillo@tectijuana.edu.mx;
daniel.hernandezm@tectijuana.edu.mx

aTemporary link to source code since we experienced some difﬁculties with
the submission system, github repository will be available publicly upon ac-
ceptance.

Table 1: Code metadata: General information about this code.

1. Motivation and signiﬁcance

Geometric Semantic Genetic Programming (GSGP) is a variant of Genetic
Programming (GP), a state-of-the-art machine learning algorithm [1, 2, 3, 4, 5].
GP is an evolutionary computation method that performs search and optimization
following a high-level model of natural evolution. While standard GP uses genetic
operators that produce offspring by manipulating the syntax of the parents, GSGP
performs search operations directly on semantic space, which induces a unimodal
ﬁtness landscape that simpliﬁes the search [6].

In symbolic regression problems, the application domain for GSGP-CUDA,
semantic space is S ⊆ Rn, where n is the number of training samples or ﬁtness
cases, allowing the search operators to be implemented more efﬁciently than syn-
tax manipulations. This allowed Vanneschi et al. [2] to implement an efﬁcient
version of GSGP using C++ pointers [4]; this implementation is the reference
baseline for the current work and is hereafter referred to as GSGP-C++. A newer
version of this library has been published [5], but the core search algorithm re-
mains unchanged.

2

GSGP-CUDA is a GSGP framework that exploits the parallel nature of GSGP
using Graphical Processing Units (GPUs). The goal is to allow GSGP practition-
ers to efﬁciently tackle large problems. Search operators in GSGP deﬁne linear
combinations of parent individuals, such that the semantic vector of an offspring
is deﬁned as a linear combination of the semantic vectors of the parent(s). This
operation is naively parallel, allowing for a direct implementation in GPUs. Such
architectures have been exploited in deep learning [7], but have been sparsely
used with GP [8, 9, 10]. Note that the works presented by Chitty [8], and Lang-
don and Banzhaf [9, 10] focus on implementing CUDA and other parallel tools to
accelerate the interpretation of syntax trees, since that is the representation most
commonly used in GP. Nevertheless, while GSGP can use syntax trees as well,
this is not a requirement of the main evolutionary loop, particularly since syntax
is only evaluated for the initial population. In the present work, for example, a
linear representation is used instead. GSGP creates new individuals through the
linear combination of the semantic vector of the parents, instead of combining or
modifying syntax, as traditional GP algorithms do. The main issue has been that
syntactic manipulation of individuals is not as efﬁcient in GPUs, compared to nu-
merical computations. With GSGP, on the other hand, the synergy with modern
GPU architectures is stronger.

2. Software description

GSGP can be brieﬂy summarized as follows [1, 11], focusing on the most com-
mon application domain, real-valued symbolic regression. In this problem, ﬁtness
cases (or dataset samples) are deﬁned as fc j = (x j,t j) with t j ∈ R, x j ∈ Rl and l
is the number of input features. In standard GP and GSGP individuals are usu-
ally represented using syntax trees, so we refer to individuals as programs or trees
w.l.o.g. The semantics sTi = {sTi,1, ..., sTi,n} of a tree Ti is a vector of size n, which
represents the total number of ﬁtness cases, where sTi, j is the output of the i-th tree
evaluated on the inputs from the j-th ﬁtness case. In this way, the ﬁtness of a tree
Ti is computed as the distance between sTi and the target semantics t = [t1, ...,tn].
While the original GSGP formulation included both geometric semantic crossover
(GSC) and mutation (GSM) operators, experimental work suggests that mutation
is usually sufﬁcient to perform an evolutionary search [2]. A mutated offspring of
parent T is deﬁned as TM = T + ms · (R1 + R2) with Ru, u = 1, 2 are random real
functions with range [0, 1], constructed as Ru = (1 + e−Tu)−1 with Tu is a random
GP tree, and ms is the mutation step. A useful property of both GSM and GSC
is that the semantics of an offspring is basically deﬁned by a linear combination
of the semantics of the parents and the random trees. Therefore, it is possible to
compute the semantics and ﬁtness of an offspring using only the semantic vectors.
This allows for an efﬁcient implementation of the GSGP search, by building and

3

Figure 1: GPU execution model.

updating semantic matrices Sm×n, where m is the number of individuals (in either
the population or the set of random trees), as done in GSGP-C++ [4, 5].

2.1. Software Architecture

CUDA has emerged as a general purpose parallel computing API for NVDIA
GPUs, designed to work with high-level programming languages (C, C++ and
Fortran). CUDA is the most widely used computing platform for general purpose
High Performance Computing (HPC).

CUDA programming is heterogeneous since both the GPU (device) and CPU
(host) can be used. The code on the CPU manages memory and launches kernels
that are executed on the GPU. Parallelism arises in the execution of kernels, which
are launched over multiple threads simultaneously. The CUDA execution model
relies on three main concepts: thread, blocks and grids; as shown in Figure 1.

GSGP-C++ manages the evolutionary cycle of GSGP using semantic matrices
therefore efﬁciently migrating these structures to a GPU is possible. While pre-
vious works have developed GPU-based implementations of GP [12, 9, 13, 14],
manipulating syntax trees is not efﬁcient. However, since GSGP does not require
explicit construction of program syntax, it can exploit efﬁcient matrix manipu-
lation on GPUs. The evolutionary process in GSGP-CUDA has the following
stages:

1. Calculating ranges of data and process parallelization. Depending on the
problem size (features l, ﬁtness cases n) and GSGP conﬁguration (popu-
lation size m and maximum program size k), it is necessary to deﬁne the
conﬁguration of parallel work at the thread, block and grid level.

2. Creation of memory variables. All global memory regions must be reserved
and allocated on the device. The manipulation of data is through pointer
vectors in each stage.

4

 GridExecuted byExecuted byExecuted byCoreStreaming MultiprocessorComplete GPU UnitBlockThreadBlockBlockBlock3. Initialization. Creates the initial population on the GPU, using a linear
genome representation for the programs [9, 10]. Structures are used to keep
track of the evolutionary lineage of each individual.

4. Fitness evaluation. There are two kernels used in this stage. The ﬁrst kernel
is an interpreter that computes the semantics of each individual based on
their genome (and their offspring), while the second kernel computes the
ﬁtness given by the Root Mean Squared Error (RMSE).

5. GSGP Evolution. This process includes applying GSM on the parent popu-
lation to compute the offspring semantics and the offspring ﬁtness, and per-
forming survival for the next generation. Since GSGP-CUDA is intended
for large problems, selection pressure is kept low by applying mutation to
all the individuals in the population [1].

2.2. Software Functionalities

The main evolutionary algorithm in GSGP-CUDA is controlled by the CPU
with a sequential ﬂow, which launches each of the CUDA kernels that perform
each of the evolutionary processes using Single Instruction Multiple Data (SIMD)
execution, summarized in Algorithm 1. For each kernel, Algorithm 1 speciﬁes the
level of parallelism that was implemented. This refers to what is being executed
on an individual CUDA thread. Some parameters are based on the characteris-
tics of the GPU card. Blocks and grids are three-dimensional structures of size
(threads.x,threads.y,threads.z) and (blocks.x, blocks.y, blocks.z) respectively. In
this implementation grids and blocks are one-dimensional so only threads.x and
blocks.x are considered, with the other dimensions set to 1. Therefore, we will re-
fer to variable threads and blocks to deﬁne the size of these structures. The blocks
and threads variables are set using the CUDA Occupancy API at run time. This is
done using the CUDA Occupancy API (available in CUDA 6.5 and later), namely
the cudaOccupancyMaxPotentialBlockSize function that heuristically calculates a
block size that achieves the maximum multiprocessor-level occupancy for each
kernel.

Initialization. The CreatePopulation kernel creates the population of programs
T and the set of random trees R used by the GSM kernel, based on the desired
population size and maximum program length. The individuals are represented
using a linear genome, composed of valid terminals (inputs to the program) and
functions (basic elements with which programs can be built). Terminals include
input features and ephemeral random constants, while a reduced function set of
arithmetic operators is used as suggested in [2], of +, −, × and protected division
÷. Each gene in the chromosome is determined randomly based on the following
probabilities: 0.8 for a function, 0.14 for a problem variable or feature, and 0.04
for an ephemeral random constant.

5

Algorithm 1: GSGP-CUDA Evolutionary Algorithm

Inputs: Population size m, number of random trees r, ﬁtness cases (n × l), target

semantics t, maximum program size k and number of generations g;

kernel CreatePopulation(m, k) → P;
kernel CreatePopulation(r, k) → R;
kernel ComputeSemantics(P) → ST,m×n;
kernel ComputeSemantics(R) → SR,r×n;
kernel ComputeFitness(ST,m×n, t) → FT,m×1;

1 for generation <= to g do

(cid:46) Parallelism at the gene level
(cid:46) Random Trees used for GSM
(cid:46) Parallelism at the individual level
(cid:46) Semantic matrix of the random trees
(cid:46) Parallelism at the individual level

kernel GSM(ST,m×n, SR,r×n) → SO,m×n; (cid:46) Parallelism at the semantic element level
kernel ComputeFitness(SO,n×m, t) → FO,m×1;
(cid:46) Fitness of the offspring
(cid:46) Implemented using CUBLAS and pointer aliasing
Survival with elitism;
Return: Best individual found;

Interpreter. The ComputeSemantics kernel is basically an interpreter, that decodes
each GP tree and evaluates it over all the ﬁtness cases, producing as output the se-
mantic vector of each individual. The chromosome is interpreted linearly, using
an auxiliary LIFO stack D that stores terminals from the chromosome and the out-
put from valid operations, following [15]. When a terminal gene in a chromosome
is encountered by the interpreter, a push of the value into stack D is done. Con-
versely, when a function gene is encountered, pop operations are performed on D
to obtain the arguments (operands) for the function; the number of pop operations
is equal to the arity of the function. After computing the function, the output is
pushed onto the stack D. If the number of elements in D is less then the arity of
the function, then the operation is skipped and the stacked is left in the original
state (before encountering the function gene in the chromosome). An additional
output register Out is used to store all the valid outputs from computed functions.
When the interpreter gets to the end of the chromosome, the kernel returns the
contents of Out. This is repeated for each ﬁtness case in the training dataset.

Each individual is executed over a single thread, over all the ﬁtness cases. The
ComputeSemantics kernel produces the semantic matrix of the population ST,m×n
and the semantic matrix of the random trees SR,r×n.

Fitness computation. The ComputeFitness kernel computes the RMSE between
each row of the semantic matrix ST,m×n and the target vector t, computing the
ﬁtness of each individual in the population. To account for large datasets with
many ﬁtness cases, and large populations, an efﬁcient partition of the semantic
matrix is necessary. Each thread computes the ﬁtness of a single individual.

Geometric Semantic Mutation. The search operation is performed by the GSM
kernel. The GSM operator is basically a vector addition operation, that can be
performed independently for each semantic element sTi, j. However, it is necessary

6

to select the semantics of two random trees Ru and Rv, and a random mutation
step ms. In other words, while the mutation operator is deﬁned at the individual
level, it can be efﬁciently implemented at the semantic element level, where each
thread computes a particular semantic element in the offspring. Therefore, to
synchronize this operation over multiple threads, an array of indices and an array
of mutation steps is ﬁrst constructed with two auxiliary kernels, the ﬁrst one stores
the indices u and v of the random trees used in each mutation operation while the
latter stores the corresponding mutations steps ms. Afterward, the GSM kernel
uses these arrays to compute each element of the offspring semantic vector.

Survival. Survival uses a generational strategy, with elitism of the best individual
in both the parent and offspring populations. This stage replaces the parent pop-
ulation, semantic matrix and ﬁtness vector with those of the offspring. It relies
on the CUBLAS ISAMIN function to identify the best individual. To ﬁnd the
worst individual to be replaced, in case that the elite individual is in the parent
population, the CUBLAS ISAMAX function is used.

2.3. Complexity Analysis

According to [11], the complexity of the sequential GSGP depends on the
population size (m) and number of generations (g) resulting in O(mg) time com-
plexity; since the computational cost of evaluating a new individuals at each gen-
eration is constant O(1). However, in general, this evaluation also depends on
the number of ﬁtness cases n, giving a complexity of O(mgn). The proposed
), where t is the number of threads.
implementation has a complexity of O(
For modern GPUs, t could approximate m, g or n in many cases, such that the
complexity could be reduced by one factor.

mgn
t

Similarly, the memory complexity depends on the population size (m) and the
number of ﬁtness cases (n), but since the same arrays are used in all the iterations,
the number of generations (g) does not affect the memory complexity. Never-
theless, there are two additional dimensions that impact the memory complexity,
these are: the maximum program size (k) and the number of random trees (r).
Note that the ﬁrst one is only used on the array for the syntax of the individuals in
the initial population, and the latter is constant throughout the whole evolutionary
process.

In this way, for the initialization stage, the algorithm implements an array of
ﬂoats of size O(mk) for the initial population, another one of size O(rk) for the
random trees used for the mutation operation, one more of size O(mn) that holds
the semantic vector for each individual, another of size O(rn) for the semantic
vectors of the random trees; and ﬁnally, one of size O(nl) for the input data, given
by the number of ﬁtness cases and the number of features in the problem. For
the remaining iterations of the algorithm, an additional array is used to store the

7

Features
GPU Architecture

GPU Memory

Quadro P4000
NVIDIA Pascal

8 GB GDDR5

Memory Interface
Memory Bandwidth
NVIDIA CUDA ® Cores
System Interface
Max Power Consumption

256-bit
Up to 243 GB/s
1792
PCI Express 3.0 x16
105 W

Tesla P100
NVIDIA Pascal
16GB CoWoS HBM2 at 732 GB/s or
12GB CoWoS HBM2 at 549 GB/s
4096-bit
732 GB/s or 549 GB/s
3584
NVLink
250 W

Table 2: Speciﬁcations of GPU devices.

semantic vectors of the new individuals created at each iteration, this array is of
size O(mn). Hence, the memory complexity of the proposed algorithm is O(mk +
rk +2mn+rn+nl). As it will be described in the next section, the dimensions that
present the largest values are the number of ﬁtness cases (n) and the population
size (m). Thus, the memory growth is described by O(2mn).

3. Illustrative Examples

The experimental evaluation has two goals. First, to measure the speedup of
GSGP-CUDA relative to GSGP-C++. Second, to compare the performance of
both implementations on real-world problems.

3.1. Performance speedup

The algorithms are executed on the following hardware. For GSGP-C++ we
use a Dell PowerEdge R430 server with Intel(R) Xeon(R) CPU E5-2650 v4 @
2.20 GHz processors, using virtual machines with 8 Xeon Cores and 32 GB of
RAM running on a Kernel-based Virtual Machine server. For GSGP-CUDA we
use two devices, an NVIDIA Quadro P4000 and an NVIDIA Tesla P100; see
Table 2. The Quadro card works on a Dell precision 7811 workstation with
an Intel (R) Xeon CPU E5-2603 v4 1.70Ghz and 32 GB of RAM with 64-bit
Ubuntu Linux. The Tesla card runs on IBM Power8 S822LC server for HPC, with
two Power8NVL 4.20 GHz processors with 512 GB of RAM and Ubuntu Server
16.04.

To evaluate the speedup between implementations we use dummy datasets to
measure execution times for different scenarios. Table 3 shows the ranges and
parameter values for these experiments.

The CUDA event API is used to compute the processing time, which is part of
the CUDA SDK and includes calls to create and destroy events, record events and
calculate the time elapsed in milliseconds between two events, using the event

8

Parameter
Fitness Cases
Number of features
Program size (genes)
Population Size
Number of generations
Runs

Range
n = 102, 400
l = 1, 024
k ∈ [127, 1023, 2047]
m = 10, 240
50
30

Table 3: Experimental parameters used for benchmarking GSGP-C++ and GSGP-CUDA.

functions cudaEvent t, cudaEventCreate(), cudaEventRecord(), cudaEventSyn-
chronize() and cudaEventElapsedTime(). We compute the run times of the Cre-
atePopulation, ComputeSemantics and a single GSGP generation (iteration). In
the latter case, this includes the GSM kernel, along with all auxiliary kernels, and
the survival stage. Moreover, the total run time of a each run is computed, includ-
ing load times for the training data and returning the results to the host.

Table 4 shows the speedup of GSGP-CUDA compared to GSGP-C++, for
GSGP process. Consider the case where k = 127, which are relatively large pro-
grams and a common GP setting [11, 16]. Notice that speedup is largest in the
CreatePopulation kernel, due to the CUDA parallelization and because GSGP-
CUDA uses a simpler linear chromosome. In the Tesla card there is also a sub-
stantial speedup in each GSGP generation, of nearly 1, 000. The speedup in the
total run time, however, is closer to the speedup achieved in the ComputeSeman-
tics kernel. This is due to two reasons. First, ComputeSemantics is the most
computationally expensive kernel, since each individual is interpreted linearly for
each ﬁtness case. Second, these tests only considered 50 generations. In many
real-world problems the number of generations can be as high as 2, 000 to achieve
optimal performance, which would increase the speedup in practice.

As the individual size increases, the speedup for the CreatePopulation kernel
and for the GSGP Generation either stay the same or increase. However, the
speedup of the ComputeSemantics kernel decreases.

Comparing the Quadro and Tesla cards, Figure 2 summarizes the results on a
sweep of parameter values. The plots show the run times of 30 runs (horizontal
axis) of the ComputeSemantics kernel, with 102, 400 ﬁtness cases and the Table
3 parameters. Notice that the ComputeSemantics kernel is sensitive to program
size. For these reasons, the recommended setup for GSGP-CUDA is to use small
or medium-sized programs.

3.2. Performance on real symbolic regression problems

GSGP-CUDA and GSGP-C++ were evaluated on the set of benchmark prob-
lems in Table 5, which have been widely used to evaluate GP [3, 17, 18]. The
results are summarized in Table 6 for the training performance and in Table 7 for

9

Individual size

CUDA kernel

127

1023

2047

CreatePopulation
ComputeSemantics
GSGP Generation
Total Run Time
CreatePopulation
ComputeSemantics
GSGP Generation
Total Run Time
CreatePopulation
ComputeSemantics
GSGP Generation
Total Run Time

Speed-up
Quadro
554x
96x
29x
81x
570x
23x
28x
22x
1,130x
24x
32x
23x

Speed-up
Tesla
1,177x
112x
872x
103x
2,039x
31x
850x
30x
3,525x
29x
946x
29x

Table 4: Speed-up of GSGP-CUDA compared to GSGP++, considering populations of 10,240
individuals.

(a) Quadro

(b) Tesla

Figure 2: Performance comparison of the Quadro and Tesla cards, considering the ComputeSe-
mantics kernel.

the testing performance, showing the mean, median, standard deviation (STD) and
interquartile range (IQR) over all the runs, after removing outliers. Performance
is comparable in most cases with only slight variations. One notable result is that
GSGP-CUDA outperforms GSGP-C++ on the most difﬁcult problem, Tower. This
is due to the different representation used by GSGP-CUDA. The performance of
GSGP-CUDA might be improved further, using hyperparameter optimization or
incorporating a local search method [6].

3.3. How to use the GSGP-CUDA library

The run parameters are deﬁned in a conﬁg.ini ﬁle, namely: program size,
population size, number of ﬁtness cases, number of problem features, and number

10

51015202530Number of run010002000300040005000Time (s)Individual Size1271023204751015202530Number of run010002000300040005000Time (s)Individual Size12710232047Problems
Concrete [19]

No. Instances
1030

No. Features
9

Energy Cooling [20]

Energy Heating [20]

Housing [21]
Tower [17]

Yacht [22]

768

768

506
5000

308

9

9

14
26

7

Description
The concrete compressive strength is a highly
nonlinear function of building parameters.
Assessing the cooling requirements of buildings
as a function of building parameters.
Assessing the heating requirements of buildings
as a function of building parameters.
Concerns housing values in suburbs on Boston.
An industrial data set of chromatography measurement
of the composition of a distillation tower.
Delft data set, used to predict the hydrodynamic
performance of sailing from dimensions and velocity.

Table 5: Symbolic regression real world problems.

GSGP C++
Problem Mean Median
8.97
Concrete
3.50
Cooling
3.59
Heating
4.24
Housing
157.87
Tower
8.39
Yacht

8.87
3.51
3.38
4.27
160.82
8.20

STD
0.69
0.24
0.79
0.18
30.58
1.04

GSGP CUDA

IQR Mean Median
0.46
0.24
0.52
0.26
35.53
1.17

7.89
3.30
3.01
4.25
70.04
8.34

8.12
3.25
2.97
4.26
69.16
8.35

STD IQR
1.65
0.92
0.22
0.18
0.23
0.21
0.32
0.34
7.91
5.43
0.55
0.67

Table 6: Comparison of train ﬁtness (RMSE) on the real-world benchmark problems.

of runs. To compile the gsgpCuda.cu ﬁle , simply run:

nvcc -std=c++11 -O0 gsgpCuda.cu -o gsgpCuda.x -lcublas

The program is executed with:

./gsgpCuda.x -train ﬁle train ﬁle.txt -test ﬁle test ﬁle.txt

In this case, train.txt and test.txt are the ﬁles that contain training and test
instances. The columns contain the values of the problem features while the rows
contain the instances. The last column contains the target variable. As output two
text ﬁles are created, containing the ﬁtness of the best individual on the training
set and the same individual on the test set for each generation.

4. Impact

The main contribution of this work is to propose the ﬁrst CUDA implemen-
tation of GSGP, where the fundamental elements of the evolutionary cycle are
implemented as CUDA kernels to exploit the massively parallel nature of modern
GPUs. From a practical perspective, GSGP-CUDA is the most efﬁcient imple-

11

GSGP C++
Problem Mean Median
6.87
Concrete
3.51
Cooling
3.67
Heating
4.29
Housing
156.66
Tower
8.62
Yacht

7.23
3.47
3.47
4.20
161.16
8.51

STD
1.61
0.28
0.81
0.42
26.46
1.10

GSGP CUDA

IQR Mean Median
2.54
0.37
0.63
0.68
37.87
1.84

8.41
3.25
2.99
4.33
69.88
8.79

7.89
3.24
3.05
4.29
70.89
8.71

STD IQR
1.93
1.13
0.33
0.24
0.26
0.23
0.81
0.53
8.75
5.77
1.29
1.14

Table 7: Comparison of test ﬁtness (RMSE) on the real-world benchmark problems.

Parameter
Number of Runs
Number of generations
Program size (genes)
Population Size
Range of ephemeral constant
Probability of Mutation
Probability of Crossover

Range
n = 30
l = 1, 024
k ∈ 1, 024
m = 1, 024
[1, 10]
1
0

Table 8: Experimental parameters used for benchmarking in real problems GSGP-C++ and GSGP-
CUDA.

mentation of this algorithm, and opens up the possibility of using GSGP in partic-
ular, and GP in general, on Big Data problems. This is important since GSGP has
shown great promise on small and medium-sized problems, but previous imple-
mentations scale poorly to larger datasets. GP as a machine learning method has
not been able to efﬁciently exploit modern GPU technology, and this algorithm is
a big step in this direction. Moreover, from a scientiﬁc perspective GSGP-CUDA
allows for large scale analysis of semantic space, one of the most active research
areas in GP [23].

5. Conclusions

This paper presents the ﬁrst implementation of the powerful GSGP algo-
rithm for execution on GPU cards, using CUDA programming. Given the na-
ture of GSGP, porting to an efﬁcient CUDA implementation, using a linear pro-
gram representation, was demonstrated in this work. Experimental results show
that GSGP-CUDA performs similarly to the sequential implementation (GSGP-
C++), but particularly performs better on the most difﬁcult benchmark. Moreover,
benchmarking shows that the speedups of GSGP-CUDA can be as high as 1, 177x
for some process, and over 100x for a small number of generations. Future work
will focus on integrating other search elements, such as a local search method and
extending the interpreter to allow for different data types.

12

6. Conﬂict of Interest

No conﬂict of interest exists: We wish to conﬁrm that there are no known con-
ﬂicts of interest associated with this publication and there has been no signiﬁcant
ﬁnancial support for this work that could have inﬂuenced its outcome.

Acknowledgements

We thank Perla Ju´arez-Smith for her help implementing some of the source
code used in this software. We also thank the Tecnol´ogico Nacional de M´exico/IT
de Tijuana and CITEDI-IPN for their administrative and technical assistance in
the development of this work. This research was partially supported by national
funds through FCT (Fundac¸ ˜ao para a Ciˆencia e a Tecnologia) by the projects
GADgET (DSAIPA/DS/0022/2018) and AICE (DSAIPA/DS/0113/2019). Mauro
Castelli acknowledges the ﬁnancial support from the Slovenian Research Agency
(research core funding No. P5-0410). Funding for this work was also provided
by TecNM (Mexico) 2020 through the research project ”Resoluci´on de m´ultiples
problemas de aprendizaje supervisado de manera simult´anea con programaci´on
gen´etica”.

References

[1] A. Moraglio, K. Krawiec, C. G. Johnson, Geometric semantic genetic pro-
gramming, in: Proceedings of the 12th International Conference on Parallel
Problem Solving from Nature - Volume Part I, PPSN’12, 2012, pp. 21–31.

[2] L. Vanneschi, S. Silva, M. Castelli, L. Manzoni, Geometric Semantic Ge-
netic Programming for Real Life Applications, Springer New York, New
York, NY, 2014, pp. 191–209.

[3] M. Castelli, L. Trujillo, L. Vanneschi, A. Popovic, Prediction of energy per-
formance of residential buildings: A genetic programming approach, Energy
and Buildings 102 (2015) 67 – 74.

[4] M. Castelli, S. Silva, L. Vanneschi, A c++ framework for geometric semantic
genetic programming, Genetic Programming and Evolvable Machines 16 (1)
(2015) 73–81.

[5] M. Castelli, L. Manzoni, Gsgp-c++ 2.0: A geometric semantic genetic pro-

gramming framework, SoftwareX 10 (2019) 100313.

13

[6] M. Castelli, L. Trujillo, L. Vanneschi, S. Silva, E. Z-Flores, P. Legrand, Ge-
ometric semantic genetic programming with local search, in: Proceedings
of the 2015 Annual Conference on Genetic and Evolutionary Computation,
GECCO ’15, 2015, pp. 999–1006.

[7] A. Gron, Hands-On Machine Learning with Scikit-Learn and TensorFlow:
Concepts, Tools, and Techniques to Build Intelligent Systems, 1st Edition,
O’Reilly Media, Inc., 2017.

[8] D. M. Chitty, Faster gpu-based genetic programming using a two-

dimensional stack, Soft Computing 21 (2016) 3859–3878.

[9] W. B. Langdon, W. Banzhaf, A simd interpreter for genetic programming
on gpu graphics cards, in: M. O’Neill, L. Vanneschi, S. Gustafson, A. I.
Esparcia Alc´azar, I. De Falco, A. Della Cioppa, E. Tarantino (Eds.), Ge-
netic Programming, Springer Berlin Heidelberg, Berlin, Heidelberg, 2008,
pp. 73–85.

[10] W. B. Langdon, Large-Scale Bioinformatics Data Mining with Parallel Ge-
netic Programming on Graphics Processing Units, Springer Berlin Heidel-
berg, Berlin, Heidelberg, 2013, pp. 311–347.

[11] L. Vanneschi, An Introduction to Geometric Semantic Genetic Program-

ming, Springer International Publishing, Cham, 2017, pp. 3–42.

[12] D. Robilliard, V. Marion, C. Fonlupt, High performance genetic program-

ming on gpu, in: BADS ’09, 2009.

[13] S. L. Harding, W. Banzhaf, Distributed genetic programming on gpus using

cuda, 2011.

[14] D. A. Augusto, H. J. C. Barbosa, Accelerated parallel genetic program-
ming tree evaluation with opencl, J. Parallel Distrib. Comput. 73 (1) (2013)
86–100.

[15] L. Spector, A. Robinson, Genetic programming and autoconstructive evolu-
tion with the push programming language, Genetic Programming and Evolv-
able Machines 3 (1) (2002) 7–40.

[16] R. Poli, W. B. Langdon, N. F. McPhee, A Field Guide to Genetic Program-

ming, Lulu Enterprises, UK Ltd, 2008.

[17] E. J. Vladislavleva, G. F. Smits, D. den Hertog, Order of nonlinearity as
a complexity measure for models generated by symbolic regression via

14

pareto genetic programming, IEEE Transactions on Evolutionary Compu-
tation 13 (2) (2009) 333–349.

[18] P. Ju´arez-Smith, L. Trujillo, M. Garc´ıa-Valdez, F. Fern´andez de Vega,
F. Ch´avez, Local search in speciation-based bloat control for genetic pro-
gramming, Genetic Programming and Evolvable Machines 20 (3) (2019)
351–384.

[19] I.-C. Yeh, Modeling of strength of high-performance concrete using artiﬁ-
cial neural networks, Cement and Concrete Research 28 (12) (1998) 1797 –
1808.

[20] A. Tsanas, A. Xifara, Accurate quantitative estimation of energy perfor-
mance of residential buildings using statistical machine learning tools, En-
ergy and Buildings 49 (2012) 560–567.

[21] J. R. Quinlan, Combining instance-based and model-based learning, in: Ma-
chine Learning, Proceedings of the Tenth International Conference, Univer-
sity of Massachusetts, Amherst, MA, USA, June 27-29, 1993, 1993, pp.
236–243.

[22] J. G. I. Ortigosa, R. Lopez, A neural networks approach to residuary re-
sistance of sailing yachts prediction., in: Proceedings of the International
Conference on Marine Engineering MARINE, 2007, p. 250.

[23] L. Vanneschi, M. Castelli, S. Silva, A survey of semantic methods in genetic
programming, Genetic Programming and Evolvable Machines 15 (2) (2014)
195–214.

15

