2
2
0
2

r
a

M
1
1

]

C
O
.
h
t
a
m

[

2
v
4
2
2
5
0
.
3
0
2
2
:
v
i
X
r
a

Efﬁcient MIP Techniques for Computing the
Relaxation Complexity

Gennadiy Averkov1, Christopher Hojny2, and Matthias Schymura1

1BTU Cottbus-Senftenberg,Platz der Deutschen Einheit 1, 03046
Cottbus, Germany, email {averkov,schymura}@b-tu.de
2Eindhoven University of Technology, CombinatorialOptimization
Group, PO Box 513, 5600 MB Eindhoven, The Netherlands, email
c.hojny@tue.nl

Abstract

The relaxation complexity rc(X) of the set of integer points X contained
in a polyhedron is the minimal number of inequalities needed to formulate
a linear optimization problem over X without using auxiliary variables. Be-
sides its relevance in integer programming, this concept has interpretations
in aspects of social choice, symmetric cryptanalysis, and machine learning.
We employ efﬁcient mixed-integer programming techniques to compute
a robust and numerically more practical variant of the relaxation complex-
ity. Our proposed models require row or column generation techniques
and can be enhanced by symmetry handling and suitable propagation al-
gorithms. Theoretically, we compare the quality of our models in terms of
their LP relaxation values. The performance of those models is investigated
on a broad test set and is underlined by their ability to solve challenging
instances that could not be solved previously.

Keywords: mixed-integer programming models, relaxation complexity,

branch-and-cut, branch-and-price

1 Introduction

Let X ⊆ Zd be such that X = conv(X) ∩ Zd and let Y ⊆ Zd. A fundamental
problem in various ﬁelds is to ﬁnd a polyhedron P with the minimum number
of facets such that X ⊆ P and (Y \ X) ∩ P = ∅. We call this quantity the
relaxation complexity of X w.r.t. Y , in formulae, rc(X, Y ), and any such polyhe-
dron a relaxation. In case Y = Zd, we write rc(X) instead of rc(X, Zd). In the
theory of social choice, X ⊆ {0, 1}d can be interpreted as the winning strate-
gies of a simple game, see [26, Chap. 8.3]. One is then interested in comput-
ing rc(X, {0, 1}d), i.e., the smallest number of inequalities needed to distinguish
winning and loosing strategies. In symmetric cryptanalysis, a subﬁeld of cryp-
tography, rc(X, {0, 1}d) corresponds to the minimum number of substitutions in
symmetric key algorithms [25]. In machine learning, relaxations P correspond
to polyhedral classiﬁers that distinguish two types of data points [1]. The re-
laxation complexity is then the minimum size of a polyhedral classiﬁer. Finally,

1

 
 
 
 
 
 
of course, rc(X) is the minimum number of inequalities needed to formulate a
linear optimization problem over X ⊆ Zd without using auxiliary variables.

Depending on the application, different strategies have been pursued for
computing and bounding the relaxation complexity. For example, Kaibel &
Weltge [19] introduced the notion of hiding sets for deriving lower bounds
on rc(X). Using this technique, they could show that several sets X aris-
ing from combinatorial optimization problems have superpolynomial relaxation
complexity. Moreover, rc(X, Y ) can be found by computing the chromatic num-
ber of a suitably deﬁned hypergraph; deriving lower bounds on the chromatic
number allowed Kurz & Napel [20] to ﬁnd a lower bound on rc(X, {0, 1}d) in the
context of social choice. In machine learning, algorithms have been devised to
construct polyhedral classiﬁers and thus providing upper bounds on rc(X, Y ),
see [1, 8, 21, 22]. To ﬁnd the exact value of rc(X, {0, 1}d) in the context of
symmetric cryptanalysis, mixed-integer programming models have been inves-
tigated. For higher dimensions, however, many of these models cannot com-
pute rc(X, {0, 1}d) efﬁciently in practice.

In this article, we follow the latter line of research. Given the relevance
of knowing the exact value of rc(X, Y ), our aim is to develop efﬁcient mixed-
integer programming (MIP) techniques for computing rc(X, Y ), if both X and Y
are ﬁnite. More precisely, we investigate methods to compute rcε(X, Y ), a more
robust variant of rc(X, Y ) that is numerically more practical as we discuss be-
low. To this end, we propose in Section 2 three different MIP models that allow
to compute rcε(X, Y ): a compact model as well as two more sophisticated mod-
els that require row or column generation techniques. Section 3 compares the
quality of the three models in terms of their LP relaxation value, and we discuss
several enhancements of the basic models in Section 4. These enhancements in-
clude tailored symmetry handling and propagation techniques as well as cutting
planes. Finally, we compare the performance of the three different models on
a broad test set comprised of instances with different geometric properties and
instances arising in symmetric cryptanalysis (Section 5). Our novel methods
allow to solve many challenging instances efﬁciently, which was not possible
using the basic models.

We remark that the basic versions of two models have already been used
by us in [2] to ﬁnd rcε(X, Y ) for X being the integer points in low-dimensional
cubes and crosspolytopes. These experiments helped us to prove general formu-
lae for rc(X) in these cases. For this reason, we believe that the more sophisti-
cated algorithms described in this article are not only of relevance for practical
applications, but also to develop hypotheses for theoretical results. Our code is
publicly available at github1.

Related Literature One of the earliest references on the relaxation complexity
goes back to Jeroslow [15] who showed the tight bound rc(X, {0, 1}d) ≤ 2d−1,
for any X ⊆ {0, 1}d. This result has been complemented by Weltge [28] who
showed that most X ⊆ {0, 1}d have rc(X, {0, 1}d) ≥ 2d
c·d3 , for some absolute
constant c > 0. Moreover, hiding sets proposed by Kaibel & Weltge [19] provide
a lower bound on rc(X). The bound given by hiding sets can be improved by
computing the chromatic number of a graph derived from hiding sets, see [2].
Regarding the computability of rc(X), it has been shown in [3] that there exists

1https://github.com/christopherhojny/relaxation_complexity

2

a proper subset Obs(X) of Zd \ X such that rc(X) = rc(X, Obs(X)). If Obs(X)
is ﬁnite, they show that rc(X, Obs(X)), and thus rc(X), can be computed by
solving a mixed-integer program. They also provide sufﬁcient conditions on X
that guarantee Obs(X) to be ﬁnite. Moreover, they establish that rc(X) is com-
putable if d ≤ 3; for d = 2, a polynomial time algorithm to compute rc(X) is
discussed in [2]. In general, however, it is an open question whether rc(X) is
computable.

One drawback of relaxations of X as deﬁned above is that they might be
sensitive to numerical errors. If a⊺x ≤ β is a facet deﬁning inequality of a re-
laxation of X that separates y ∈ Zd \ X, then we only know a⊺y > β. Thus,
slightly perturbing a might not separate y anymore. To take care of this, we sug-
gested in [2] to add a safety margin ε > 0 to the separation condition. That is,
if a⊺x ≤ β is a facet deﬁning inequality of a relaxation of X with kak∞ = 1 that
separates y, then we require a⊺y ≥ β+ε. In this case, we say that y is ε-separated
from X. Then, rcε(X) denotes the smallest number of facets of any relaxation
of X that satisﬁes the safety margin condition2. We call such a relaxation an ε-
relaxation of X. Analogously to rc(X, Y ), we deﬁne rcε(X, Y ) to be the smallest
number of inequalities needed to ε-separate X and Y \ X. As ε-relaxations are
more restrictive than relaxations, rcε(X) ≥ rc(X) for each ε > 0. In contrast
to rc(X), however, we show in [2] that for every ﬁnite and full-dimensional
X ⊆ Zd there is a ﬁnite set Y ⊆ Zd \ X such that rcε(X) = rcε(X, Y ).
Thus, rcε(X) is computable and the aim of this article is to develop MIP tech-
niques that allow to ﬁnd rcε(X, Y ) efﬁciently. In particular, if ε approaches 0,
then rcε(X) converges towards rcQ(X), a variant of the relaxation complex-
ity which requires the relaxations to be rational. Further variations of rc(X)
in which the size of coefﬁcients in facet deﬁning inequalities are bounded are
discussed in [10, 11].

Besides ﬁnding relaxations of X, another ﬁeld of research aims to ﬁnd outer
descriptions of P = conv(X) to be able to use linear programming techniques to
solve optimization problems over X. Since P might have exponentially many
facets, the concept of extended formulations has been introduced. Extended
formulations are polyhedra Q ⊆ Rd+k whose projection onto Rd yields P . The
smallest number of facets of an extended formulation of P is its extension com-
plexity xc(P ). We refer the reader to the surveys of Conforti et al. [7] and
Kaibel [18] as well as the references therein. Extended formulations that allow
to use integer variables have been discussed, e.g., by Bader et al. [4], Ceval-
los et al. [6], and Weltge [28, Chap. 7.1]. A combination of rc(X, {0, 1}d) and
xc(conv(X)) has been studied by Hrubeˇs & Talebanfard [14].

Basic Deﬁnitions and Notation Throughout this article, we assume that d is
a positive integer. The set {1, . . . , d} is denoted by [d], and we write e1, . . . , ed to
denote the d canonical unit vectors in Rd. Moreover, ∆d = {0, e1, . . . , ed} ⊆ Rd
is the vertex set of the standard simplex in Rd, and ♦d = {0, ±e1, . . . , ±ed} ⊆ Rd
denotes the integer points in the d-dimensional standard crosspolytope. The
afﬁne hull of a set X ⊆ Rd is denoted by aﬀ(X).

A set X ⊆ Zd is called lattice-convex if X = conv(X) ∩ Zd. For a lattice-

2Note that the deﬁnition in [2] is different, but both concepts coincide if the value of ε is deﬁned
appropriately. We follow the deﬁnition provided here, because it simpliﬁes the discussion in this
article.

3

convex set X ⊆ Zd, we say that H ⊆ (aﬀ(X) ∩ Zd) \ X is a hiding set if, for any
distinct y1, y2 ∈ H, we have conv({y1, y2}) ∩ conv(X) 6= ∅. Kaibel & Weltge [19]
proved that the cardinality of any hiding set is a lower bound on rc(X). The
maximum size of a hiding set is denoted by H(X). Moreover, if Y ⊆ Zd, we say
that H is a Y -hiding set if H is a hiding set that is contained in Y . Analogously
to H(X), H(X, Y ) denotes the maximum size of a Y -hiding set.

2 Mixed-Integer Programming Models to Compute

rcε(X, Y )

In this section, we discuss three different mixed-integer programming models
to compute rcε(X, Y ). The three different MIP formulations that we discuss
differ in the way how they model rcε(X, Y ). The ﬁrst model uses only polyno-
mially many variables and inequalities, the second model needs exponentially
many inequalities while the number of variables is still polynomial, and the
third model requires exponentially many variables but only polynomially many
inequalities. For this reason, we refer to these three models as the compact, the
cutting plane, and the column generation model, respectively. In preliminary
experiments with our code, we have already used the compact and column gen-
eration model [2]. Nevertheless, we provide the full details of these models to
make the article self-contained and to be able to explain the model enhance-
ments. For the sake of convenience, we assume for the remainder of this article
that X and Y are disjoint. This is without loss of generality, because we can re-
place Y by Y \ X, which does not change the value of rcε(X, Y ). We also refer
to X as the set of feasible points, whereas the points in Y are called infeasible.

2.1 Compact Model

Observe that lattice-convex sets are exactly those subsets of Zd that admit a re-
laxation. In [3], a mixed-integer programming formulation has been proposed
to check whether a ﬁnite lattice-convex set X admits a relaxation with k in-
equalities, and we have explained in [2] how to adapt the model to be able to
compute rcε(X, Y ).

Given an upper bound k on the number of inequalities needed to separate X
and Y , the model’s idea is to introduce variables aij and bi, (i, j) ∈ [k] × [d],
to model the k potential inequalities needed in a relaxation. Moreover, for
each y ∈ Y and i ∈ [k], a binary variable syi is introduced that indicates
whether the i-th inequality is violated by y; additional binary variables ui,
i ∈ [k], indicate whether the i-th inequality is needed in a relaxation. Using
a big-M term with M ≥ d(ρX + ρY ) + ε, with ρX = max{kxk∞ : x ∈ X}
and ρY = max{kyk∞ : y ∈ Y }, the mixed-integer programming formulation

4

for rcε(X, Y ) is as follows:

k

min

ui

i=1
X

d

(1a)

aijxj ≤ bi,

x ∈ X, i ∈ [k],

(1b)

j=1
X

k

i=1
X
d

syi ≥ 1,

y ∈ Y,

aijyj ≥ bi + ε − M (1 − syi),

y ∈ Y, i ∈ [k],

j=1
X

syi ≤ ui,
−1 ≤ aij ≤ 1,
−dρX ≤ bi ≤ dρX ,

syi, ui ∈ {0, 1},

y ∈ Y, i ∈ [k],

(i, j) ∈ [k] × [d],
i ∈ [k],

y ∈ Y, i ∈ [k].

(1c)

(1d)

(1e)

(1f)
(1g)

(1h)

Inequalities (1b) ensure that the k inequalities are valid for X and Inequali-
ties (1c) guarantee that each y ∈ Y is cut off by at least one inequality. If an
inequality is selected to separate y ∈ Y and X, Inequalities (1d) ensure that
this is consistent with the k inequalities deﬁned by the model. Finally, Inequal-
ities (1e) ensure that ui is 1 if inequality i ∈ [k] separates an infeasible point,
whereas Inequalities (1f) and (1g) scale the k inequalities without loss of gen-
erality. For details on correctness, we refer the reader to [3, Sect. 4.2].

2.2 Cutting Plane Model

To be able to ﬁnd rcε(X, Y ), Model (1) introduces two classes of variables:
variables u and s model which inequalities are used and subsets of Y that are
separated by the selected inequalities, respectively, whereas variables a and b
guarantee that the subsets deﬁned by s can be cut by valid inequalities for X.
The problem of computing rcε(X, Y ) can thus be interpreted as a two stage
problem, where the ﬁrst stage selects a set of subsets of Y and the second stage
checks whether the selected subsets correspond to feasible cut patterns. Since
the ﬁrst stage variables are binary and the second stage problem is a feasibility
problem, logic-based Benders decomposition can be used to compute rcε(X, Y ),
see [13]. While classical Benders decomposition requires the subproblem to be
a linear programming problem, logic-based Benders decomposition allows the
subproblem to be an arbitrary optimization problem.

Let C = {C ⊆ Y : C and X are not linearly ε-separable}. We refer to C as
the conﬂict set. For all (C, i) ∈ C × [k], the conﬂict inequality
y∈C syi ≤ |C| − 1
models that not all points in C can be cut by an inequality valid for X. Conse-

P

5

quently,

k

min

ui

i=1
X
k

syi ≥ 1,

y ∈ Y,

i=1
X

syi ≤ |C| − 1,

C ∈ C, i ∈ [k],

y∈C
X

syi ≤ ui,
syi, ui ∈ {0, 1},

y ∈ Y, i ∈ [k],
y ∈ Y, i ∈ [k].

(2a)

(2b)

(2c)

(2d)
(2e)

is an alternative model for computing rcε(X, Y ).

2.3 Column Generation Model

Let I = {I ⊆ Y : I and X are linearly ε-separable}. Then, rcε(X, Y ) is the
ℓ
smallest number ℓ of sets I1, . . . , Iℓ ∈ I such that Y =
i=1 Ii. Thus, instead of
using the matrix s ∈ {0, 1}Y ×[k] to encode which inequality cuts which points
from Y , we can introduce for every I ∈ I a binary variable zI ∈ {0, 1} that
encodes whether an inequality separates I or not:

S

min

zI

I∈I
X

I∈Iy
X

zI ≥ 1,

z ∈ ZI
+,

y ∈ Y,

(3a)

(3b)

(3c)

where Iy = {I ∈ I : y ∈ I}.

Remark 2.1. In contrast to Model (1), Models (2) and (3) do not directly pro-
vide an ε-relaxation of X w.r.t. Y . To ﬁnd such a relaxation, rcε(X, Y ) many
linear programs need to be solved in a post-processing step.

3 Comparison of Basic Models

While the compact model (1) can be immediately handed to an MIP solver due
to the relatively small number of variables and constraints, the cutting plane
model (2) and column generation model (3) require to implement separation
and pricing routines, respectively. At least for the column generation model,
this additional computational effort comes with the beneﬁt of a stronger LP
relaxation in comparison with the compact model. To make this precise, we
denote by v⋆
CG the optimal LP relaxation value of the compact,
cutting plane, and column generation model, respectively.

cut, and v⋆

com, v⋆

Proposition 3.1. Let X ⊆ Zd be ﬁnite and lattice-convex, let Y ⊆ Zd \ X be
ﬁnite, let ε > 0 such that rcε(X, Y ) exists, and suppose both Models (1) and (2)
are feasible.

6

com ≥ v⋆

1. Then, v⋆

cut = 1.
2. Moreover, if ε ≤ (d − 1)(ρX + ρY ), then v⋆

com = 1.

Note that 2 is a technical assumption that is almost always satisﬁed in prac-
tice, e.g., to approximate rc(X, Y ) by rcε(X, Y ), one selects ε < 1 ≤ (d−1)(ρX +
ρY ). Thus, v⋆

com = 1 in all relevant cases.

cut = v⋆

Proof. First we show v⋆
cut ≥ 1 and v⋆
(partial) feasible solution (s, u) and every ¯y ∈ Y the estimation

com ≥ 1. Observe that we get for every

k

k

k

ui ≥

max{syi : y ∈ Y } ≥

s¯yi ≥ 1,

i=1
X

i=1
X

i=1
X

where k is the upper bound used in Model (1) of (2). Hence, v⋆
cut ≥ 1 and
v⋆
com ≥ 1. If the upper bound k = 1, we thus have necessarily v⋆
cut = 1. If k ≥ 2,
we construct a feasible solution for (2) with objective value 1 by assigning all
variables value 0 except for syi, (y, i) ∈ Y × [2], u1, and u2, which get value 1
2 .
Indeed, the left-hand side of each conﬂict inequality evaluates to |C|
2 , while
the right-hand side is |C| − 1. Thus, because |C| ≥ 2 for any conﬂict as X is
lattice-convex, the ﬁnd |C|
2 ≤ |C| − 1, i.e., all conﬂict inequalities are satisﬁed.
Since the remaining inequalities hold trivially, 1 ≥ v⋆
cut follows. Consequently,
com ≥ 1 ≥ v⋆
v⋆

For the second statement, we assume k ≥ 2, because otherwise v⋆

com = 1 fol-
lows as above. We deﬁne a feasible solution with objective value 1 of Model (1)
by assigning all variables value 0 except for

cut ≥ 1.

• u1 = sy1 = ε

M for all y ∈ Y ;

• u2 = sy2 = 1 − ε

M for all y ∈ Y ;

• a11 = 1 and b1 = ρX .

⊺x ≤ bi deﬁned this way are either 0 ≤ 0 or x1 ≤ ρX , which
The inequalities ai·
are valid for X. Moreover, the Inequalities (1d) are satisﬁed, because for i = 1
and every y ∈ Y , we have

d

a1jyj − b1 = y1 − ρX ≥ −ρY − ρX ≥ −d(ρX + ρY ) + ε ≥ ε − M (1 − sy1),

j=1
X
and for the remaining i ≥ 2, we get ε − M (1 − sy2) = 0. Since one can easily
check that the remaining inequalities of (1) are also satisﬁed, v⋆
com ≤ 1 follows,
concluding the proof using the ﬁrst part of the assertion.

The value of the LP relaxations thus does not indicate whether the compact
or cutting plane model performs better in practice. An advantage of the latter is
that the conﬂict inequalities encode a hypergraph coloring problem, which is a
structure appearing frequently in practice. Hence, there might be a chance that
a solver can exploit this structure if sufﬁciently many inequalities have been
separated. The compact model, however, might have the advantage that the
a- and b-variables guide the solver in the right direction when branching on s-
or u-variables, because feasibility is already encoded in the model and does not
need to be added to the model by separating cutting planes.

7

Proposition 3.2. Let X ⊆ Zd be ﬁnite and lattice-convex, let Y ⊆ Zd \X be ﬁnite,
let ε > 0 be such that rcε(X, Y ) exists, and suppose both Models (1) and (2) are
feasible. Let k be the number of inequalities encoded in Model (1).

1. If there exists an optimal solution of the LP relaxation of (3) that assigns at

com ≥ v⋆

cut = 1.

most k variables a positive value, then v⋆

CG ≥ v⋆
CG ≥ H(X, Y ), and this can be strict.

CG ≥ v⋆

2. We have v⋆
Proof. To show v⋆
com, recall that for each I ∈ I there exists an inequal-
ity a(I)⊺x ≤ b(I) + ε separating I and X. Due to rescaling, we may assume
that a(I) ∈ [−1, 1]d and b(I) ∈ [−dρX , dρX ].
If we are given a solution z ∈ RI

+ of (3) with at most k non-zero entries,
we deﬁne a solution of the LP relaxation of (1) with the same objective value as
follows. Let I1, . . . , Iℓ ∈ I be the indices of non-zero entries in z. For each i ∈ [ℓ]
and y ∈ Y , deﬁne

syi =

zIi ,
0,

(

if y ∈ Ii,
otherwise,

and

ui = zIi.

For i ∈ {ℓ + 1, . . . , k} and y ∈ Y , we deﬁne syi = 0 and ui = 0. Finally,
let aij = a(Ii)j and bi = b(Ii) for (i, j) ∈ [ℓ] × [d]. For i ∈ {ℓ + 1, . . . , k},
Indeed, this solution adheres to (1b) since (a, b)
deﬁne aij = 0 and bi = 1.
deﬁnes valid inequalities, and also (1e)–(1g) hold trivially. By deﬁnition, s
and u also satisfy the box constraints corresponding to (1h). To see that (1c)
holds, note that for each y ∈ Y ,

k

syi =

(3b)
≥ 1,

zIi

i=1
X

Xi∈[ℓ] : y∈Ii
since z is feasible for the LP relaxation of (3). For the last constraint (1d), note
⊺x ≤ bi
that the constraint is trivially satisﬁed if syi = 0. If syi > 0, then ai·
corresponds to an inequality separating X and y, which ﬁnally shows that the
newly deﬁned solution is feasible for the LP relaxation of (1). To conclude, note
k
CG ≥ v⋆
com and the remaining estimations
that
i=1 ui =
hold by Proposition 3.1.

ℓ
i=1 zIi . Hence, v⋆

P
For the second part, let H ⊆ Y be a hiding set for X and let z ∈ RI

+ be an
optimal solution of the LP relaxation of (3). Then, for distinct y1, y2 ∈ H, we
have Iy1 ∩ Iy2 = ∅. Consequently, we can estimate

P

v⋆
CG =

zI ≥

(3b)
≥ |H|,

zI

I∈I
X

y∈H
X

I∈Iy
X

which shows v⋆

CG ≥ H(X, Y ).

To see that the inequality can be strict, consider X = {0, 1}2 and let Y be
all infeasible points in Z2 with ℓ∞-distance 1 from X. One can readily verify
that a maximum hiding set for X has size 2, while the LP relaxation of (3) has
value 8
3 .

If Y contains a hiding set of size at least 2, the column generation model is
thus strictly stronger than the compact and cutting plane model. In particular,
the gap between v⋆
com) can be arbitrarily large: if d = 2 and
Y = Obs(X), there is always a hiding set of size rc(X, Y ) − 1, see [2, Thm. 23].

cut (and v⋆

CG and v⋆

8

4 Enhancements of Basic Models and Algorithmic

Aspects

In their basic versions, the compact and cutting plane model are rather difﬁcult
to solve for a standard MIP solver, e.g., because not enough structural properties
of rcε(X, Y ) are encoded in the models that are helpful for a solver. Moreover,
the cutting plane and column generation model require to solve a separation
and pricing problem, respectively, to be used in practice.
In this section, we
discuss these aspects and suggest model improvements.

4.1 Incorporation of Structural Properties

In the following, we describe cutting planes, propagation algorithms, and tech-
niques to handle symmetries and redundancies in the compact and cutting plane
model.

In both the compact and cutting plane model, variable syi en-
Cutting Planes
codes whether a point y ∈ Y is separated by inequality i ∈ [k]. To strengthen
the compact model and the initial LP without separated inequalities in the cut-
ting plane model, we can add inequalities that rule out combinations of points
from Y that cannot be separated simultaneously.
For any hiding set H ⊆ Y , the hiding set cut

syi ≤ 1,

y∈H
X

i ∈ [k]

encodes that each inequality i ∈ [k] can separate at most one element from a
hiding set. Although these cuts are the stronger the bigger the underlying hiding
set, we add these inequalities just for hiding sets of size 2. The reason for this
is that such hiding sets can be found easily by iterating over all pairs (y1, y2)
of distinct points in Y and checking whether the line segment conv({y1, y2})
intersects conv(X) non-trivially. In our implementation, we insert the expres-
sion λy1+(1−λ)y2 in each facet deﬁning inequality of conv(X) to derive bounds
on the parameter λ. Then, the ﬁnal bounds on λ are within [0, 1] if and only
if {y1, y2} is a hiding set.

For hiding sets of arbitrary cardinality, the task is more difﬁcult, because
there might exist exponentially many hiding sets. Thus, we are relying on a
separation routine for hiding set cuts. The separation problem for hiding set
cuts, however, is at least as difﬁcult as ﬁnding a maximum hiding set for X, and
the complexity of the latter is open.

Propagation Suppose we are solving the compact and cutting plane model
using branch-and-bound. At each node of the branch-and-bound tree, there
might exist some binary variables that are ﬁxed to 0 or 1, e.g., by branching
decisions. The aim of propagation is to ﬁnd further variable ﬁxings based on
the already existing ones.

Our ﬁrst propagation algorithm is based on the following observation.

9

Observation 4.1. Suppose some s-variables have been ﬁxed and let i ∈ [k]. Then,
Fi := {y ∈ Y : syi = 1} can be separated from X if and only if F ′
i := Y ∩ conv(Fi)
can be separated from X.

The convexity propagation algorithm computes the sets F ′

i , i ∈ [k], and
ﬁxes syi to 1 for all y ∈ F ′
i such that sy′i is already
i .
ﬁxed to 0, then the algorithm prunes the node of the branch-and-bound tree.
This is indeed a valid operation, because Inequalities (1c) and (2b) allow each
point y ∈ Y to be separated by several inequalities.

If there is y′ ∈ F ′

The second propagation algorithm exploits that Fi ∩ conv(X) needs to be
empty in each feasible solution. The intersection propagation algorithm thus
iterates over all y ∈ Y \ Fi and checks whether conv(Fi ∪ {y}) ∩ conv(X) 6= ∅.
If the check evaluates positively, syi is ﬁxed to 0.

Comparing both propagation algorithms, the convexity propagator requires
to compute only a single convex hull per set Fi, whereas the intersection prop-
agator needs to compute O(|Y |) convex hulls per set Fi, which can be rather
expensive. In our experiments, we will investigate whether the additional effort
pays off in reducing the running time drastically. To avoid computing unneces-
sary convex hulls, we call both propagation algorithms in our implementation
only if the branching decision at the parent node is based on a variable syi, and
in this case only for this particular inequality index i and no further i′ ∈ [k]\ {i}.

Symmetry Handling It is well-known that the presence of symmetries slows
down MIP solvers, because symmetric solutions are found repeatedly during
the solving process leading to an exploration of unnecessary parts of the search
space. In a solution of the compact and cutting plane model, e.g., we can per-
mute the inequality labels i ∈ [k] without changing the structure of the solution.
For this reason, one can enforce that only one representative solution per set of
equivalent solutions is computed without losing optimal solutions.

One way of handling symmetric relabelings of inequalities is to require that
the columns of the matrix s ∈ {0, 1}Y ×[k] are sorted lexicographically non-
increasingly. To enforce sorted columns, we use a separation routine for or-
bisack minimal cover inequalities as suggested in [12] and the propagation al-
gorithm orbitopal ﬁxing by Bendotti et al. [5]. Both algorithms’ running time
is in O(|Y | · k). Moreover, sorting the columns of s implies that we can also
require the u-variables to be sorted, i.e., the ﬁrst rcε(X, Y ) inequalities are the
inequalities deﬁning an ε-relaxation, which can be enforced by adding

ui ≥ ui+1,

i ∈ [k − 1],

(4)

to the problem.

Besides the symmetries of relabeling inequalities, we might also be able
to relabel points in Y without changing the structure of the problem. This is
the case if we ﬁnd a permutation π of [d] such that π(X) = X and π(Y ) =
Y , where for a set T ⊆ Rd we deﬁne π(T ) = {π(t) : t ∈ T } and π(t) =
(tπ−1(1), . . . , tπ−1(d)). The permutation π gives rise to a permutation φ of Y
and ψ of X, where φ(y) := π(y) and ψ(x) := π(x).

Lemma 4.2. Let (s, u) be a (partial) solution of Model (1) or (2) for rcε(X, Y ).
If there exists a permutation π of [d] such that π(X) = X and π(Y ) = Y , then
also (s′, u) is a (partial) solution, where s′ arises from s by reordering the rows
of s according to φ.

10

Proof. Suppose (s, u) is a solution of Model (2). Then, (s, u) can be extended to
d
a solution of Model (1), i.e., there exist k inequalities
j=1 aijxj ≤ bi, i ∈ [k],
such that the i-th inequality separates the points in Fi = {y ∈ Y : syi = 1}
from X. If we apply permutation π to X and Y , we do not change the structure
d
j=1 aijπ(x)j ≤ bi, i ∈ [k], deﬁnes also a relaxation
of the problem, that is,
of X w.r.t. Y . Thus, if the original i-th inequality separated point y ∈ Y , the
permuted inequality separates φ(y). Consequently, if we deﬁne s′ by relabel-
ing the rows of s according to φ, (π(a), b, s′, u) is a solution of Model (1) and
thus (s′, u) is a solution of Model (2).

P

P

If Π = {π ∈ Sd : π(X) = X, π(Y ) = Y } and Φ is the group containing all φ
associated with the permutations π ∈ Π, Lemma 4.2 tells us that we can also
force the rows of s to be sorted lexicographically non-increasingly w.r.t. permu-
tations from Φ. In our implementation, we compute a set Γ of generators of the
group Φ and enforce for each γ ∈ Γ that matrix s is lexicographically not smaller
than the reordering of s w.r.t. γ. We enforce this property by separating minimal
cover inequalities for symresacks and a propagation algorithm, see [12]. Both
run in O(k) time per γ ∈ Γ.

To detect the symmetries Φ, we construct a colored bipartite graph G =
(V, E). The left side of the bipartition is given by X ∪ Y and the right side is
deﬁned as R = {(v, j) ∈ Z × [d] : there is z ∈ X ∪ Y with zj = v}. There is
an edge between z ∈ X ∪ Y and (v, j) ∈ R if and only if zj = v. Moreover,
each node gets a color uniquely determining its type: all nodes in X are colored
equally with color “X”, all nodes in Y are colored equally by color “Y ”, and
node (v, j) ∈ R is colored by color “v”. Then, the restriction of every automor-
phism σ of G to R corresponds to a permutation in Π, and thus, restricting σ
to Y is a permutation in Φ.

Note that the graph G deﬁned above might not allow to detect symmetries if
a symmetric arrangement of X and Y is translated asymmetrically. For example,
if X = t + ∆2, Y = t + (∆2 + ♦2) \ ∆2, and t =
, then there is no permutation
keeping X invariant. For this reason, we use in the construction of G relative
coordinates. That is, for each coordinate j ∈ [d], we compute µj = minz∈X∪Y zj
and translate X ∪ Y by −µ before building G.

1
2

(cid:0)

(cid:1)

symmetries of the inequalities

Another way of handling symmetries for the compact model (1) is to handle
d
j=1 aij xj ≤ bi deﬁned in the model. We can
d
reorder the inequalities
j=1 aij xj ≤ bi, i ∈ [k] that are (not) used in the
relaxation, to obtain another solution with the same objective value. To handle
these symmetries, we can add the inequalities

P

P

ai1 ≥ a(i+1)1 − 2(ui − ui+1),

i ∈ [k − 1].

(5)

Inequalities (5) sort the inequalities (not) present in a relaxation by their ﬁrst
coefﬁcient. The inequalities are compatible with Inequalities (4), but not neces-
sarily with the lexicographic ordering constraints. The latter is the case because
cutting the point y ∈ Y associated with the ﬁrst row of matrix s might require
a very small ﬁrst coefﬁcient in any separating inequality, whereas other points
might require a very large ﬁrst coefﬁcient. In our experiments, we will investi-
gate which symmetry handling method works best for the compact and cutting
plane model.

11

Finally, additional redundancies in Model (1) can be handled by enforcing
d
j=1 aijxj ≤ bi becomes the trivial inequality 0⊺x ≤ dρX if it is not used
that
in a relaxation of X (i.e., ui = 0). This removes inﬁnitely many equivalent
solutions from the search space, and can be modeled by replacing (1f) by

P

−ui ≤ aij ≤ ui,

(i, j) ∈ [k] × [d],

and the lower bound constraint in (1g) by

dρX ≤ bi + 2dρX ui,

i ∈ [k].

This method is compatible with both the lexicographic symmetry handling ap-
proach and Inequalities (5).

4.2 Algorithmic Aspects of the Cutting Plane Model

To be able to deal with the exponentially many conﬂict inequalities (2c) in the
cutting plane Model (2), we are relying on a separation routine. We start by
discussing the case that the point s⋆ to be separated is contained in {0, 1}Y ×[k],
i.e., for each of the k inequalities we already know which points it is supposed
to separate.

To check whether s⋆ ∈ {0, 1}Y ×[k] satisﬁes all conﬂict inequalities, we can
compute for each i ∈ [k] the set Fi = {y ∈ Y : s⋆
yi = 1}, and build a linear
program similar to Model (1) that decides whether X and Fi are ε-separable. If
the answer is yes, we know s⋆ is feasible. Otherwise, we have found a violated
syi ≤ |Fi| − 1. Of course, this inequality will
conﬂict inequality, namely
be rather weak in practice, because it excludes only the single assignment Fi.

y∈Fi

P

One way to strengthen the inequality is to search for a minimum cardinal-
ity subset Fmin of Fi, which cannot be separated from X. The corresponding
y∈Fmin syi ≤ |Fmin| − 1 then does not only cut off s⋆, but every
inequality
solution that assigns inequality i all points from Fmin. However, we do not
expect that Fmin can be computed efﬁciently, because detecting a minimum car-
dinality set of inequalities whose removal leads to a feasible LP is NP-hard, see
Sankaran [24]. Instead, we compute a minimal cardinality subset F ⊆ Fi by
initializing F = ∅, adding points y ∈ Fi to F until F and X are no longer
separable, and then iterating over all points y′ in F and checking whether their
removal leads to a separable set. In the latter case, we keep y′ in F ; otherwise,
we remove it. Although this procedure is costly as it requires to solve Θ(|Fi|) LPs
to ﬁnd F , preliminary experiments revealed that the running time of the cutting
plane model can be reduced drastically when using the sparsiﬁed inequalities.

P

Since we expect the separation problem of (2c) to be difﬁcult even for inte-
ger points, we only heuristically separate non-integral points s⋆ ∈ [0, 1]Y ×[k] in
our implementation. To this end, for each i ∈ [k], we again initialize an empty
set F and iteratively add y ∈ Y in non-increasing order w.r.t. s⋆
yi until F ∈ C
and s⋆ violates the inequality (or we know that such an inequality cannot be
violated).

4.2.1 Algorithmic Aspects of the Column Generation Model

In contrast to the compact model (1), the number of variables in (3) grows ex-
ponentially in |Y |, which makes it already challenging to solve the LP relaxation

12

of (3). In our implementation, we thus use a branch-and-price procedure for
solving (3), i.e., we use a branch-and-bound procedure in which each LP relax-
ation is solved by column generation. In the following, we discuss the different
components of the branch-and-price procedure.

Solving the Root Relaxation At the root node of the branch-and-bound tree,
we are given a subset I ′ of all possible variables in I and solve the LP relaxation
of (3) restricted to the variables in I ′. To check whether the solution obtained
for the variables in I ′ is indeed an optimal solution of the LP relaxation, we need
to solve the pricing problem, i.e., to check whether all variables in I have non-
negative reduced costs. Since the pricing problem is equivalent to the separation
problem for the dual, we determine the dual of the root node LP relaxation
of (3), which is given by

max

αy

y∈Y
X

y∈I
X

αy ≤ 1,

αy ≥ 0,

I ∈ I,

y ∈ Y.

(6a)

(6b)

(6c)

The pricing problem at the root node is thus to decide, for given dual weights αy,
y∈I αy > 1. Unfortunately, we
y ∈ Y , whether there exists a set I ∈ I with
cannot expect to solve this problem efﬁciently in general.

P

Proposition 4.3. Let X ⊆ Zd be ﬁnite and lattice-convex, let Y ⊆ Zd \ X be
ﬁnite, and let αy ≥ 0 be a rational weight for y ∈ Y . Then, the pricing problem
for the LP relaxation of (3), i.e., deciding whether there exists I ∈ I(X, Y ) with

y∈Y αy > 1, is NP-hard.

P
Proof. Note that the pricing problem is equivalent to ﬁnding a set I ∈ I(X, Y )
If all weights αy, y ∈ Y , have the same
that maximizes the value
value α > 0, the problem reduces to ﬁnd a set I ∈ I of maximum cardinality.
The latter problem is NP-hard even if X consists of a single point, in which case
it reduces to the open hemisphere problem, see Johnson & Preparata [16].

y∈I αy.

P

To solve the pricing problem, we use a mixed-integer program that is a vari-
ant of (1) with k = 1. The only difference is that instead of minimizing the
If
number of needed inequalities, we maximize the expression
this value is at most 1, we have found an optimal solution of the LP relaxation.
Otherwise, we have found a variable zI with negative reduced cost, add I to I ′,
and iterate this procedure until all reduced costs are non-negative. In our im-
plementation, we initialize the set I ′ by

y∈Y αysy1.

P

I ′ =

{y ∈ Y : a⊺y > b} : a⊺x ≤ b deﬁnes facet of conv(X)

∪

{y} : y ∈ Y

.

(cid:8)

Branching Strategy Let u be a node of the branch-and-bound tree and denote
by zu an optimal solution of the LP relaxation at node u. A classical branching
I /∈ Z and to create two child nodes u0
strategy is to select a variable zI with zu
and u1 by enforcing zI = 0 in u0 and zI = 1 in u1. While the branching
decision zI = 1 has strong implications for computing rcε(X, Y ) (we basically

(cid:9)

(cid:8)

(cid:9)

13

ﬁx an inequality used in the relaxation), branching zI = 0 only rules out one of
the exponentially many choices in I for a separated set.

I , zu

To obtain a more balanced branching rule, we use the branching rule sug-
gested by Ryan & Foster [23]. We are looking for two distinct variables zI
J /∈ Z such that both the intersection I ∩ J and symmetric dif-
and zJ with zu
ference I∆J of I and J are non-empty. Let y1 ∈ I ∩ J and y2 ∈ I∆J. Then, two
child nodes u0 and u1 of u are created as follows. In u0, variables zI ′ are ﬁxed
to 0 if I ′ contains both y1 and y2. In u1, we ﬁx zI ′ to 0 if I ′ contains either y1
or y2. That is, u0 enforces y1 and y2 to be contained in different sets, and u1
forces them to be contained in the same set I ′. This branching rule obviously
partitions the integer solutions feasible at node u. To show its validity it is thus
sufﬁcient to show that for every non-integral solution zu the sets I and J exist.

I , zu

Lemma 4.4. Let zu be a non-integral optimal solution of the LP relaxation of (3)
at node u of the branch-and-bound tree. Then, there exist two distinct sets I, J ∈ I ′
with zu

J /∈ Z such that I ∩ J 6= ∅ and I∆J 6= ∅.
I /∈ Z. Then, zu
I ∈ (0, 1), since zu is an optimal
Proof. Let I ∈ I ′ be such that zu
solution of the LP relaxation. Due to (3b), for every y ∈ I, there exists J y ∈
I ′ \ {I} with y ∈ J y such that zu
J y ∈ (0, 1),
because otherwise, we could improve the objective value of zu by setting zu
I
to 0 and still satisfying all constraints. Such a set J y together with I satisfy the
properties in the statement of the lemma: Since y is contained in both I and J y,
we have I ∩ J y 6= ∅. Moreover, as I 6= J y, I∆J y 6= ∅.

J y > 0. For at least one J y we have zu

In our implementation, we compute for each variable zu

I its fractionality
θ(I) = 1
I }. Then, we select I and J such that θ(I) + θ(J) is
maximized; the branching candidates y1 ∈ I ∩ J and y2 ∈ I∆J are selected
arbitrarily.

2 − min{zu

I , 1 − zu

Solving LP Relaxations in the Tree To not re-generate variables that have
been ﬁxed to 0 by the branching rule, we need to incorporate the branching de-
cisions active at a node of the branch-and-bound tree into the pricing problem.
This can easily be done by adding linear constraints to the root node formula-
tion of the pricing problem. If a branching decision was that y1 and y2 shall be
contained in different sets, we add sy11 + sy21 ≤ 1 to the pricing problem. The
branching decision that y1 and y2 have to be contained in the same set can be
enforced by the constraint sy11 = sy21.

5 Numerical Experiments

The aim of this section is to compare the practical performance of the three mod-
els for computing rcε(X, Y ) as well as their enhancements. To this end, we have
implemented all three models in C/C++ using SCIP 7.0.3 as modeling and
branch-and-bound framework and SoPlex 5.0.2 to solve all LP relaxations. All
branching, propagation, separation, and pricing methods are implemented us-
ing the corresponding plug-in types of SCIP. Since we are not aware of an alter-
native separation routine for hiding set cuts, we compute all hiding sets of size
two in a straightforward fashion before starting the branch-and-bound process.
During the solving process, we separate these inequalities if the corresponding

14

cuts are violated. To handle symmetries via lexicographic orderings, we use
SCIP’s internal plug-ins cons orbitope, cons orbisack, and cons symresack
that implement the methods discussed in Section 4; the branching and pricing
plug-ins for the column generation model strongly build up on the correspond-
ing plug-ins of the binpacking example provided in the SCIP Optimization Suite.
All convex hull computations have been carried out using cdd 0.94m [9] and
graph symmetries are detected using bliss 0.73 [17].
Our implementation is available online at github3.

Implementation Details All models admit some degrees of freedom that we
detail in the following. Both the compact model and the cut model require an
upper bound on the relaxation complexity. In both models, we impose the trivial
upper bound which is given by the number of facets of conv(X). We also use
the facet description to derive an initial solution for both models. In the column
generation model, we need to select a subset of I to deﬁne initial variables. We
use the sets I ∈ I that are deﬁned by the facet deﬁning inequalities of conv(X),
i.e., the sets of points in Y that are separated from X by the facet deﬁning
inequalities. Moreover, we include the singleton sets {y}, for y ∈ Y , to make
sure that the LP relaxation remains feasible after branching.

Settings To encode the different settings that we have tested, we make use of
the following abbreviations:

hiding Whether hiding set cuts are added (1) or not (0).

sym. Which symmetry method is used: none (0), simple (s), or advanced (a),
where simple is (4) and (5), and advanced uses (4) and additionally en-
forcing lexicographically maximal solutions based on symmetries of X
and Y .

prop. Whether the convexity propagator is used (1) or not (0).

Note that we do not report on results for the intersection propagation algorithm.
This is because, in preliminary experiments, we have seen that its running time
is very high, in particular, because it needs to compute in each iteration O(|Y |)
convex hulls. As a result, we could hardly solve any instance, not even small
ones.

Test Sets

In our experiments, we have used three different test sets:

basic The sets X are the vertices of the 0/1 cube, the crosspolytope, or
the standard simplex in dimensions d ∈ {3, 4, 5}. For X ⊆ Zd, the
sets Y consist of all points in Zd \ X whose ℓ1-distance to X is at
most k, where 1 ≤ k ≤ 10 − d. The reason for smaller distance in
higher dimension is that the problems get considerably more difﬁcult
to solve with increasing k.

3https://github.com/christopherhojny/relaxation_complexity (githash 4ffb6c0e was

used for our experiments)

15

downcld This test set consists of 99 full-dimensional subsets X of {0, 1}5 that
correspond to down-closed subsets (or abstract simplicial complexes)
of the Boolean lattice on 5 elements. The corresponding sets Y are
the points in Z5 \ X whose ℓ1-distance to X is at most k ∈ {1, 2, 3}.
The sets X have been generated by the natural one-to-one correspon-
dence between inclusion-maximal sets in a down-closed family and
antichains in the Boolean lattice.

sboxes The test set comprises 18 instances modeling 4-bit (12 instances)
and 5-bit (6 instances) S-boxes, which are certain non-sparse Boolean
functions arising in symmetric-key cryptography. The derived sets X
are contained in {0, 1}8 and {0, 1}10, respectively, and Y are the com-
plementary binary points. These instances have also been used by
Udovenko [27] who solved the full model (3), i.e., without column
generation.

The basic instances feature various aspects that might be relevant for comput-
ing rc(X) via computing a series of values rcε(X, Y ) for different Y and ε ac-
cording to [3]: The cube is parity complete, thus there exists a small set Y such
that rc(X) = rcε(X, Y ) (in fact, this set is {−1, 0, 1, 2}d \ X); the crosspolytope
has an interior integer point and thus there exists a (potentially large) ﬁnite
set Y with rc(X) = rcε(X, Y ); for the simplex ∆4 in R4, no ﬁnite set Y exists
with rc(∆4) = rc(∆4, Y ); see [2]. That is, rc(∆4, Y ) < rc(∆4) ≤ rcQ(X, Y ) for
all ﬁnite sets Y ⊆ Z4.

Since the standard simplex ∆d is a down-closed subset of {0, 1}d, the small-
sized downcld instances might be good candidates for further examples X such
that rcε(X, Y ) < rcQ(X), for every ﬁnite set Y ⊆ Zd and for ε > 0 small enough.
Our aim for selecting these instances is thus to identify whether there are po-
tentially further candidates for sets X whose relaxation complexity cannot be
computed via ﬁnite sets Y .

Finally, the sboxes instances are used to investigate whether our techniques
are suited to compute rcε(X, Y ) also in higher dimensions. This is relevant,
among others, in the ﬁeld of social choice or symmetric cryptanalysis, where
the aim is to ﬁnd rc(X, {0, 1}d) for sets X ⊆ {0, 1}d.

Computational Setup All experiments have been run on a Linux cluster with
Intel Xeon E5 3.5 GHz quad core processors and 32 GB memory. The code was
executed using a single thread and the time limit for all computations was 4 h
per instance.

All mean numbers are reported in shifted geometric mean

1
n − s
to reduce the impact of outliers. For mean running times, a shift of s = 10 is
used; for nodes of the branch-and-bound tree, we use s = 100. The value of ε in
computing rcε(·, ·) is set to 0.001. The upper bound on the number of inequali-
ties needed in the compact and cutting plane model is given by the number of
facets of conv(X). We also provide an initial primal solution corresponding to a
facet description of conv(X).

n
i=1(ti + s)

Q

16

Table 1: Run times for different settings for basic instances using the compact
model.

setting

cube

cross

simplex

hiding

sym.

prop.

0
0
0
0
1
1
1
1
1

0
0
a
s
0
a
a
s
s

0
1
0
0
0
0
1
0
1

time

598.7
795.3
347.3
217.7
303.6
95.2
84.8
75.9
76.9

#solved

time

#solved

13
13
14
15
13
15
15
18
18

1317.2
1395.4
476.7
283.3
682.0
206.1
221.5
151.0
158.4

8
8
12
13
10
14
14
15
16

time

232.8
237.3
165.5
118.3
69.9
49.9
67.0
61.1
64.6

#solved

14
14
14
15
15
16
16
16
16

5.1 Results for Test Set basic

Due to our choice of the sets X and Y , the basic test set comprises 18 cube,
crosspolytope, and simplex instances, respectively. Table 1 shows the results for
the compact model. For the plain compact model, we observe that SCIP can
already solve quite some instances, but, in comparison to the enhanced vari-
ants, the running times are rather high. Checking each of the enhancements
separately, handling symmetries is most important to reduce running time and
to increase the number of instances solvable within the time limit. Interestingly,
handling symmetries on the a-variables modeling the inequalities in a relax-
ation performs better than handling the symmetries of the points to separate.
Adding hiding set cuts to the problem formulation is also beneﬁcial, whereas the
convexity propagator seems to harm the solving process in particular for cube
instances. The worse performance for enabled propagation cannot be explained
on the running time of the propagator: For cube instances, e.g., the maximum
running time per instance of the propagator was 27 s, which is much smaller
than the increase of mean running time. Thus, it seems that the found reduc-
tions guide the branch-and-bound search into the wrong direction or make it
more difﬁcult for SCIP to ﬁnd other reductions.

Combining simple symmetry handling and hiding set cuts leads consistently
to the best results, reducing mean running time for cube instances by 87 %, for
crosspolytope instances by 89 %, and simplex instances by 74 %. In particular,
the combined setting can solve all cube instances and almost all crosspolytope
and simplex instances within the time limit.

Next, we discuss the column generation model for which we only compare
two variants: we either disable or enable hiding set cuts in the pricing problem.
Since the convexity propagator does not seem to be helpful for the compact mo-
del, we do not enable it when solving the pricing problem. Moreover, symmetry
handling is not important, because there is only one inequality to be identiﬁed
by the pricing model.

Comparing the column generation model with disabled hiding set cuts, we
can see that it performs for cube and crosspolytope instances much better than
the plain compact model: the running time for cubes reduces by 82 % and for
cross polytopes by 74 %. For cubes, all solvable instances are solved within
the root node which is, on the one hand, because of the strong dual bound as
described in Proposition 3.2. On the other hand, the generated sets I ∈ I allow
heuristics to ﬁnd high quality solutions yielding a matching primal bound. For

17

Table 2: Run times for different settings for basic instances using the column
generation model.

setting

cube

cross

simplex

hiding

sym.

prop.

0
1

0
0

0
0

time

109.0
73.5

#solved

15
14

time

350.4
282.1

#solved

13
12

time

455.2
312.7

#solved

13
14

Table 3: Run times for different settings for basic instances using the cut model.

setting

cube

cross

simplex

hiding

sym.

prop.

time

#solved

time

#solved

time

#solved

0
0
0
0
1
1
1
1
1

0
0
a
s
0
a
a
s
s

0
1
0
0
0
0
1
0
1

9229.1
9122.2
2549.9
4206.1
1733.0
528.0
424.8
433.6
435.9

7
7
8
7
8
10
13
10
10

9411.0
9361.5
3734.6
5488.5
994.6
382.9
350.7
435.9
378.2

3
3
9
6
7
10
10
11
12

3099.1
3072.6
1726.5
2129.0
428.5
257.8
259.8
296.3
277.0

7
7
10
8
12
11
11
11
12

crosspolytopes, all instances of 3-dimensional sets X can be solved within the
root node; for 4- and 5-dimensional sets, however, SCIP needs to start branching
to ﬁnd an optimal solution. Looking onto results on a per-instance basis reveals
that the pricing problems become considerably harder if d and k increases. For
example, SCIP is only able to process 2 nodes of the branch-and-bound tree
for d = k = 5. For the simplex instances, the column generation model needs
approximately twice as much time as the plain compact model, which is again
explained by the very high running time of the pricing problem.

Enabling also hiding set cuts helps to solve the pricing problems more ef-
ﬁciently. In comparison with the enhanced compact model, however, the en-
hanced column generation model is only competitive on the cube instances. On
the crosspolytope and simplex instances, it is much slower.

Finally, we consider the cutting plane model. In the plain version, this model
can hardly solve any instance efﬁciently. Comparing the different enhancements
with each other, we can see, analogously to the compact model, that adding hid-
ing set cuts and handling symmetries is beneﬁcial. Interestingly, the convexity
propagator helps to improve the running time if both the previous enhance-
ments are enabled by 90 %–95 %, leading to the best setting for this model. But
even this winner setting cannot compete with the enhanced compact model.

From the results using the compact and cutting plane model, we draw the
following conclusion regarding the convexity propagator.
In principle, this
method models the important aspect that the points being cut by an inequal-
ity form a lattice-convex set. The cutting plane method can thus beneﬁt from
the propagator as this property is not encoded in the model. The compact mo-
del, however, makes use of additional variables modeling the inequalities of
a relaxation. Since the convexity propagator does not improve SCIP’s perfor-
mance, we conclude that these additional variables already sufﬁciently encode
the lattice-convexity of cut points.

In summary, the column generation model provides very good primal and
If these bounds match, rcε(X, Y ) can be computed rather efﬁ-

dual bounds.

18

ciently if not too many pricing problems need to be solved. However, if the
bounds do not match, the NP-hardness of the pricing problem strikes back and
solving many further pricing problems is too expensive. In this case, the com-
pact model is a rather effective alternative that also allows to compute rcε(X, Y )
for d = 5 in many cases.

5.2 Results for Test Set downcld

In this section, we turn the focus on 5-dimensional 0/1 down-closed sets. On the
one hand, our aim is to investigate whether the ﬁndings of the previous section
carry over to a much broader test set in dimension 5. On the other hand, we
are interested in identifying further sets X ⊆ {0, 1}5 with rcε(X, Y ) < rcQ(X)
for every choice of a ﬁnite set Y ⊆ Zd and ε > 0 small enough. Because
of our results on the basic test set, we did not run any experiments using the
cutting plane model as we expect that it can hardly solve any instance. Instead,
we consider a hybrid version of the compact model and the column generation
model: We only solve the column generation model’s LP relaxation to derive a
strong lower bound on rcε(X, Y ) and to ﬁnd good primal solutions. Both are
transferred to the compact model with the hope to drastically reduce solving
time. The running times and number of nodes reported for the hybrid model
are means of the total running time and total number of nodes for solving the
LP relaxation in the column generation model and the resulting compact model.
Table 4 shows aggregated results for the 99 instances of the downcld test
set for different ℓ1-neighborhoods Y of X (radius 1–3). While the plain com-
pact model is able to solve two third of all instances for radius 1, comput-
ing rcε(X, Y ) for larger radii becomes much harder. As the plain model can
hardly solve any instance for radius at least 2, there is deﬁnitively a need for
model enhancements. In general, the same observations as in the previous sec-
tion can be made: symmetry handling and adding hiding set cuts improve the
solution process a lot. The biggest impact is achieved by symmetry handling;
the convexity propagator is not helpful in the best setting. However, sometimes
it can improve the running time, e.g., if the “wrong” symmetry handling method
is used.

For radius 2 and 3, we ﬁnd that the simple symmetry handling methods
perform much better than the advanced methods. Using hiding set cuts and
simple symmetry handling is 59 % faster than the corresponding setting with
advanced symmetry handling if the radius is 2; for radius 3, it is 45 % faster.
Moreover, simple symmetry handling can solve all 99 instances for radius 2
(resp. 69 instances for radius 3), whereas the advanced setting can only solve 75
(resp. 14) instances.
Interestingly, for radius 1, the advanced setting is 26 %
faster than the simple setting. A possible explanation is based on the nature
of the advanced setting: Each inequality deﬁning a relaxation of X w.r.t. Y
deﬁnes a pattern on the points from Y that are cut by this inequality. The
advanced method enforces that the cut patterns of the inequalities are sorted
lexicographically based on a sorting of the elements of Y . Since the results of
the lexicographic comparison is determined by the ﬁrst position in which two
vectors differ, it is unlikely that points having a late position in the ordering of Y
are very relevant for the lexicographic constraint. Thus, the symmetries are in
a certain sense mostly handled for the early points in this ordering. In contrast
to this, the simple method takes the geometry of the inequalities in a relaxation

19

Table 4: Comparison of running times for different settings for downcld instances.

setting

hiding

sym.

prop.

#solved

2
0

compact model:
0
0
0
0
1
1
1
1
1

0
0
a
s
0
a
a
s
s

column generation model:
0
1

hybrid model:
s
0
s
0
s
1
s
1

0
1
0
0
0
0
1
0
1

0
1
0
1

69
69
97
99
82
99
99
99
99

78
85

99
99
99
99

radius 1

#nodes

351 640.3
342 597.2
59 896.3
27 421.4
24 247.7
424.0
424.4
793.3
792.6

87.7
109.3

8081.0
8377.1
347.1
346.2

time

#solved

3168.5
3155.1
569.7
187.8
399.3
22.6
22.6
30.5
30.5

1223.6
644.5

89.0
99.2
22.8
22.8

5
3
18
58
34
75
78
99
99

4
6

85
84
99
99

radius 2

#nodes

149 820.2
145 207.9
201 253.6
278 139.2
103 717.2
16 209.4
14 936.4
8558.6
8789.0

19.8
48.9

375 957.5
375 309.0
4219.6
4437.3

time

#solved

13 173.5
13 237.5
12 041.9
6299.6
7077.9
1870.2
1680.6
774.2
783.0

13 424.8
11 500.4

2865.8
3406.0
339.3
347.0

0
0
2
3
2
14
14
69
68

1
1

15
11
80
79

radius 3

#nodes

29 710.1
29 539.2
37 865.0
83 758.4
13 704.6
14 882.7
15 975.0
21 696.0
24 044.2

8.4
14.5

341 632.4
377 211.9
18 162.5
18 278.0

time

14 400.0
14 400.0
14 213.4
14 033.7
14 056.9
11 990.5
11 858.9
6563.0
7172.8

14 089.9
13 949.5

11 644.5
11 959.0
3203.7
3123.0

into account by sorting inequalities based on their ﬁrst coefﬁcients. Together
with other components of the solver, this seems to have more implications on
the cut points from Y if the radius becomes larger.

In comparison to the enhanced compact model, the column generation mo-
del is again inferior. For radius at least 2, it can hardly solve any instance and,
as already discussed in the previous section, the reason for this is the long run-
ning time of the pricing models that need to be solved often at each node of
the tree. This is reﬂected by the number of processed nodes during the branch-
and-price procedure that drops drastically (as the number of solved instances)
if the radius is getting larger. However, we can again observe that the root
node can be solved relatively efﬁciently and that the obtained primal and dual
bounds are rather strong. This is reﬂected in the hybrid model, which solves
most instances and reduces the running time (in comparison to the best com-
pact model) by 52–56 % for radius 2 and 3. For radius 1, the running times are
comparable.

Regarding the usefulness of hiding set cuts in the hybrid model, we observe
that they are essential for solving the downcld instances efﬁciently. They allow
to solve all instances for radius 1 and 2 and improve on the hybrid setting with-
out cuts by 74 % and 88 %, respectively. This effect is even more dominant for
radius 3, where it signiﬁcantly increases the number of solvable instances, re-
ducing the running time by 72 %. It is also noteworthy that the hybrid setting
with hiding set cuts is the only setting allowing to solve 80 instances, which im-
proves the running time of the compact model by 51 %. In summary, based on
our experiments, the hybrid model is the best choice for computing rcε(X, Y ) as
it combines the strong bounds from the column generation model with the abil-
ity of the compact model to quickly solve LP relaxations within the branch-and-
bound tree. In particular, it beneﬁts from hiding set cuts since their implications
are very difﬁcult to be found by SCIP.

Finally, concerning our goal to identify candidates for sets X ⊆ {0, 1}5 such
that rcε(X, Y ) < rcQ(X) for all ﬁnite Y ⊆ Z5 and ε > 0 small enough, our
experiments for radius 3 revealed the following: If Y (X) are the integer points
in the ℓ1-neighborhood of X with radius 3, then there are three sets X such
that rcε(X, Y (X)) = 4. These sets are ∆5, ∆5 ∪ {e1 + e2} and ∆4 × {0, 1}.
Moreover, there are 16 sets X with rcε(X, Y (X)) = 5. It is left open for future
research to identify which other sets than ∆5 satisfy rcε(X, Y (X)) < rcQ(X).
Note that rcQ(X) ≥ 6, whenever X ⊆ {0, 1}5 is full-dimensional, because ratio-
nal relaxations must be bounded.

5.3 Results for Test Set sboxes
The results for the sboxes test set are summarized in Table 5. Note that we
do not report on results for the 10-dimensional instances in the compact mo-
del with enabled hiding set cuts, because all these experiments hit a memory
limit of 20 GB. The reason is that these models grow very large even with-
out any enhancements as we use the number of facets of conv(X) to upper
bound rcε(X, Y ); the number of facets for these instances ranges between 888
and 2395. For the largest instances, even the basic compact model hits the
memory limit. Adding hiding set cuts for the remaining instances causes that
all instances hit the memory limit. But also for the smaller instances, SCIP is

21

Table 5: Comparison of running times for different settings for sboxes instances.

setting

dimension 8

dimension 10

hiding

sym.

prop.

#solved

#nodes

time

#solved

#nodes

time

compact model:
0
0
0
0
1
1
1

0
0
a
s
0
a
s

0
1
0
0
0
0
0

column generation model:
0
1

hybrid model:
0
0
1
1

s
s
s
s

0
1
0
1

0
0
0
0
0
0
0

12
12

7
7
9
9

31 942.1
31 947.4
5497.3
3598.9
2970.5
177.5
163.5

41.7
61.8

6192.5
6180.4
14 551.0
14 551.0

14 400.0
14 400.0
14 400.0
14 400.0
14 400.0
14 400.0
14 400.0

185.7
358.2

400.8
398.9
1251.3
1243.6

0
0
3
2
—
—
—

2
1

1
1
1
1

4.1
4.1
6.6
6.0
—
—
—

7.5
3.8

7471.5
7513.8
56.0
56.0

14 400.0
14 400.0
12 046.1
12 492.2
—
—
—

6254.4
14 238.1

7153.2
7153.0
14 054.3
14 053.4

hardly able to solve any of these instances even if model enhancements are
enabled due to huge number of variables and constraints.

In contrast to this, we see that the column generation model performs ex-
tremely well for the problems in dimension 8. It can solve all twelve 8-dimen-
sional instances within the time limit, on average in 185.7 s if hiding set cuts are
disabled and in roughly twice this amount of time with enabled hiding set cuts.
An explanation for the worse behavior with enabled cuts is that the number
of hiding set cuts increases drastically in comparison with lower dimensional
problems. Thus, creating and separating these cuts is a non-trivial task. For
dimension 10, the column generation model is also able to solve 2 out of 6
instances within the time limit.

Finally, the hybrid model performs worse than the column generation model.
Although the derived bounds from solving the column generation model’s LP
relaxation yield again very good bounds on the relaxation complexity, the value
of rc(X, {0, 1}d) can still be large if d ∈ {8, 10}. Thus, also the compact model
embedded in the hybrid model is struggling with the number of variables and
constraints. For this reason, computing rc(X, {0, 1}d) via the column generation
model is most competitive.

5.4 Conclusions

Being able to compute the exact value of the quantity rcε(X, Y ) is highly rele-
vant in many areas, such as, social choice, symmetric cryptanalysis, or machine
learning. For this reason, we have proposed three different models that allow to
compute rcε(X, Y ) using mixed-integer programming techniques. As our exper-
iments reveal, each of these models comes with advantages and disadvantages.
The compact model, for example, works well in small dimensions as the number

22

of variables and inequalities is small and it encapsulates all essential informa-
tion about rcε(X, Y ). In higher dimensions, however, the dual bounds of the
compact model become weaker. In this case, the column generation model pro-
vides very good bounds that can be transferred to the compact model to still
compute rcε(X, Y ) rather efﬁciently if d = 5. But if the dimension d grows even
larger, only the column generation model seems to be competitive as it does not
scale as badly as the compact model when rcε(X, Y ) increases. The main reason
is that the compact model is relying on a good upper bound on rcε(X, Y ) to be
indeed compact.

These ﬁndings thus open the following directions for future research. Since
the compact model requires a good upper bound on rcε(X, Y ), it is natural to
investigate heuristic approaches for ﬁnding ε-relaxations of X or to develop ap-
proximation algorithms. Moreover, since the column generation model becomes
more relevant if d is large, it is essential that the pricing problem can be solved
efﬁciently. Since the pricing problem is NP-hard, also here a possible future di-
rection could be to develop heuristics or approximation algorithms for solving it.
For both the compact and column generation model, hiding set cuts turned out
to be useful. However, we are not aware of an efﬁcient routine for generating
these cutting planes. Thus, it is natural to devise an efﬁcient scheme for gener-
ating hiding set cuts on the ﬂy. Finally, as additional inequalities such as hiding
set cuts and symmetry handling inequalities drastically improved the perfor-
mance of the compact model, the development of further inequalities modeling
structural properties of relaxation complexity might allow to solve the compact
model even more efﬁciently.

Acknowledgements We thank Aleksei Udovenko for providing the sboxes

instances used by him in [27].

References

[1] Astorino, A., Gaudioso, M.: Polyhedral separability through successive LP.

J. Optim. Theory Appl. 112, 265–293 (2002)

[2] Averkov, G., Hojny, C., Schymura, M.:

relaxation complexity:
(2021).

of
Program.
https://doi.org/10.1007/s10107-021-01754-8

possibilities and limitations.
DOI 10.1007/s10107-021-01754-8.

Computational aspects
Math.
URL

[3] Averkov, G., Schymura, M.: Complexity of linear relaxations in integer
programming. Math. Program. (2021). DOI https://doi.org/10.1007/
s10107-021-01623-4

J., Hildebrand,
integer
tu-dimension of

[4] Bader,
Mixed
afﬁne
565–584
https://doi.org/10.1007/s10107-017-1147-2

R., Weismantel,
integer
of
a matrix.

reformulations

(2018).

DOI

R.,
programs

Zenklusen,
and

R.:
the
Math. Program. 169(2),
URL

10.1007/s10107-017-1147-2.

[5] Bendotti, P., Fouilhoux, P., Rottner, C.: Orbitopal ﬁxing for the full (sub-
)orbitope and application to the unit commitment problem. Math. Pro-

23

gram. 186, 337–372 (2021). DOI 10.1007/s10107-019-01457-1. URL
https://doi.org/10.1007/s10107-019-01457-1

[6] Cevallos, A., Weltge, S., Zenklusen, R.: Lifting linear extension com-
In: A. Czumaj (ed.) Pro-
plexity bounds to the mixed-integer setting.
ceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete
Algorithms, SODA 2018, New Orleans, LA, USA, January 7-10, 2018,
pp. 788–807. SIAM (2018). DOI 10.1137/1.9781611975031.51. URL
https://doi.org/10.1137/1.9781611975031.51

[7] Conforti, M., Cornu´ejols, G., Zambelli, G.:
in combinatorial optimization.

tions
97–143
DOI
http://dx.doi.org/10.1007/s10479-012-1269-0

(2013).

Extended formula-
Ann. Oper. Res. 204(1),
URL

10.1007/s10479-012-1269-0.

[8] Dundar, M.M., Wolf, M., Lakare, S., Salganicoff, M., Raykar, V.C.: Poly-
hedral classiﬁer for target detection: a case study: colorectal cancer. In:
ICML ’08: Proceedings of the 25th international conference on Machine
learning, pp. 288–295 (2008)

[9] Fukuda, K.: cdd/cdd+ reference manual.
search, ETH-Zentrum pp. 91–111 (1997)

Institute for Operations Re-

[10] Hojny, C.: Polynomial size IP formulations of knapsack may require expo-
nentially large coefﬁcients. Oper. Res. Lett. 48(5), 612–618 (2020)

[11] Hojny, C.: Strong IP formulations need large coefﬁcients. Discrete Optim.

39, 100624 (2021)

[12] Hojny, C., Pfetsch, M.E.: Polytopes associated with symmetry handling.
Math. Program. 175, 197–240 (2019). DOI 10.1007/s10107-018-1239-7.
URL https://doi.org/10.1007/s10107-018-1239-7

[13] Hooker, J.N.: Logic-Based Methods for Optimization: Combining Opti-

mization and Constraint Satisfaction. Wiley, New York (2000)

[14] Hrubeˇs,
ity
of
https://arxiv.org/abs/2105.11996 (2021)

P.,
polytopes

Talebanfard, N.:

On
subsets

separating

the
of

extension
the

Boolean

complex-
cube.

[15] Jeroslow, R.G.: On deﬁning sets of vertices of the hypercube by linear

inequalities. Discrete Math. 11, 119–124 (1975)

[16] Johnson, D., Preparata, F.: The densest hemisphere problem. Theoret.

Comput. Sci. 6, 93–107 (1978)

[17] Junttila,

Kaski,
T.,
tomorphism groups
http://www.tcs.hut.fi/Software/bliss/ (2012)

canonical

A tool

bliss:

and

P.:

for

computing

labelings

of

au-
graphs.

[18] Kaibel, V.: Extended formulations in combinatorial optimization. Optima
85, 2–7 (2011). Newsletter of the Mathematical Optimization Society

24

[19] Kaibel, V., Weltge, S.: Lower bounds on the sizes of integer programs
without additional variables. Math. Program. 154(1-2, Ser. B), 407–425
(2015)

[20] Kurz, S., Napel, S.: Dimension of the lisbon voting rules in the EU council:

a challenge and new world record. Optim. Lett. 10, 1245–1256 (2016)

[21] Manwani, N., Sastry, P.S.: Learning polyhedral classiﬁers using logis-
tic function.
In: M. Sugiyama, Q. Yang (eds.) Proceedings of 2nd
Asian Conference on Machine Learning, Proceedings of Machine Learn-
ing Research, vol. 13, pp. 17–30. PMLR, Tokyo, Japan (2010). URL
https://proceedings.mlr.press/v13/manwani10a.html

[22] Orsenigo, C., Vercellis, C.: Accurately learning from few examples with a

polyhedral classiﬁer. Comput. Optim. Appl. 38, 235–247 (2007)

[23] Ryan, D., Foster, B.: An integer programming approach to scheduling. In:
A. Wren (ed.) Computer scheduling of public transport: Urban passenger
vehicle and crew scheduling, pp. 269–280. North-Holland (1981)

[24] Sankaran, J.K.: A note on resolving infeasibility in linear programs by
constraint relaxation. Oper. Res. Lett. 13(1), 19–20 (1993). DOI 10.1016/
0167-6377(93)90079-V

[25] Sun, S., Hu, L., Wang, P., Qiao, K., Ma, X., Song, L.: Automatic security
evaluation and (related-key) differential characteristic search: Application
to simon, present, lblock, des(l) and other bit-oriented block ciphers. In:
P. Sarkar, T. Iwata (eds.) Advances in Cryptology – ASIACRYPT 2014, pp.
158–178. Springer Berlin Heidelberg (2014)

[26] Taylor, A.D., Pacelli, A.M.: Mathematics and Politics: Strategy, Voting,

Power and Proof, 2 edn. Springer New York (2008)

[27] Udovenko, A.: Milp modeling of boolean functions by minimum num-
ber of inequalities. Cryptology ePrint Archive, Report 2021/1099 (2021).
https://ia.cr/2021/1099

[28] Weltge, S.: Sizes of Linear Descriptions in Combinatorial Optimization.
Ph.D. thesis, Otto-von-Guericke-Universit¨at Magdeburg (2015). DOI http:
//dx.doi.org/10.25673/4350

25

