Instance-wise algorithm conﬁguration with graph
neural networks

Romeo Valentin
Dept. of Mathematics
ETH Zürich, Switzerland
romeo.valentin@math.ethz.ch

Claudio Ferrari
Dept. of Computer Science
ETH Zürich, Switzerland
claudio.ferrari@inf.ethz.ch

Jérémy Scheurer
Dept. of Computer Science
ETH Zürich, Switzerland
jeremys@ethz.ch

Andisheh Amrollahi
Dept. of Computer Science
ETH Zürich, Switzerland
amrollaa@ethz.ch

Chris Wendler
Dept. of Computer Science
ETH Zürich, Switzerland
chris.wendler@inf.ethz.ch

Max B. Paulus
Dept. of Computer Science
ETH Zürich, Switzerland
max.paulus@inf.ethz.ch

Abstract

We present our submission for the conﬁguration task of the Machine Learning for
Combinatorial Optimization (ML4CO) NeurIPS 2021 competition. The conﬁgura-
tion task is to predict a good conﬁguration of the open-source solver SCIP to solve a
mixed integer linear program (MILP) efﬁciently. We pose this task as a supervised
learning problem: First, we compile a large dataset of the solver performance for
various conﬁgurations and all provided MILP instances. Second, we use this data
to train a graph neural network that learns to predict a good conﬁguration for a
speciﬁc instance. The submission was tested on the three problem benchmarks of
the competition and improved solver performance over the default by 12% and
35% and 8% across the hidden test instances. We ranked 3rd out of 15 on the
global leaderboard and won the student leaderboard. We make our code publicly
available at https://github.com/RomeoV/ml4co-competition .

1

Introduction

The Machine Learning for Combinatorial Optimization (ML4CO) NeurIPS 2021 competition1
aimed at improving state-of-the-art combinatorial optimization solvers by replacing key heuristic
components with machine learning models. In particular, the competition posed three tasks to
improve the performance of the open-source solver SCIP (Achterberg, 2009) for solving mixed
integer linear programs (MILPs) efﬁciently. A MILP is a linear program maxx wT x s.t. Ax
b
0 where some entries of x are integer valued. Our submission addressed the conﬁguration
and x
task of the competition, which is an example of instance-wise algorithm conﬁguration (Kadioglu
et al., 2010). For a given MILP instance i
for
the parameters of the solver, such that the MILP can be solved efﬁciently. In particular, performance
of the solver on a given instance i and a conﬁguration c is measured by the primal-dual integral γic
after running the solver for 15 minutes.

, the task is to predict a good conﬁguration c

∈ I

∈ C

≤

≥

2
2
0
2

b
e
F
0
1

]

G
L
.
s
c
[

1
v
0
1
9
4
0
.
2
0
2
2
:
v
i
X
r
a

Choosing a good conﬁguration for the solver is challenging, because the number of potential con-
ﬁgurations for the solver is large. At the time of the competition, the SCIP solver contained
more than 2,500 parameters with binary, integer or continuous domains. The number of possi-
for the solver is exponential in the number of these parameters. Moreover,
ble conﬁgurations
many conditional dependencies exist between the solver’s parameters, which makes exploring
difﬁcult. Such dependencies may be obvious, for example using lock ﬁxings for the clique

C
|

|

C

1https://www.ecole.ai/2021/ml4co-competition/

1

 
 
 
 
 
 
Figure 1: Left: Bi-partite graph representation of a MILP instance i from Gasse et al. (2019). Right:
Our graph neural network. We follow Gasse et al. (2019), but use four convolutional layers, the graph
convolution operator from (Morris et al., 2019) and batch normalization (Ioffe et al., 2015).

heuristic (heuristics/clique/uselockfixings) is ineffective, if the heuristic is deactivated
(heuristics/clique/freq=
1). But others could be less certain or only applicable to a speciﬁc
instance i: For example the quality of pre-solving may affect the effectiveness of separation.

−

Leveraging machine learning for the conﬁguration task is difﬁcult for at least two reasons. First,
models that directly operate on the variables and constraints of a MILP should be invariant to the
order of those and able to handle MILPs of varying size. Second, the solver performance is likely a
discontinuous function of the MILP. That is, small perturbations of A, b and w can lead to jumps in
γic. For example, a slight perturbation of a constraint’s coefﬁcients could render this constraint trivial
or make the MILP infeasible, likely having a strong effect on the solving process.

We address these challenges by posing instance-wise algorithm conﬁguration as a supervised learning
problem. Firstly, we compile a large dataset of the solver performance for various conﬁgurations and
all provided MILP instances. To facilitate this, we exploit domain knowledge and use a simple greedy
search together with a metric to measure the quality of a conﬁguration space that we propose. In this
way, we reduce the number of conﬁgurations under consideration to 40 – 60 effective conﬁgurations.
Secondly, we use this data to train a graph neural network that learns to predict a good conﬁguration
for a speciﬁc instance. Our model uses the bi-partite graph representation of a MILP from Gasse
et al. (2019). It is invariant to the order of constraints and variables and can handle MILPs of
varying size. For a given instance, our model predicts the solver performance of all conﬁgurations
under consideration simultaneously. It is trained with a simple MSE loss and learns from the solver
performance of all conﬁgurations under consideration. At test time, only a single forward pass for an
instance i is required and the conﬁguration with the best predicted performance is chosen.

Our submission was evaluated on the three problem benchmarks from the competition, item placement,
load balancing and anonymous. The ﬁrst two contain 10,000 industrially-sized MILP instances for
training and validation, while the latter contains only 117 instances that differ widely in size and
are from diverse sources. The test sets were private at the time of submission and only released
subsequently. We improved solver performance over the default conﬁguration by 12%, 35% and
8% respectively across all test instances. Our submission ranked 3rd (out of 15) on the global
leaderboard and won the student leaderboard. We make the code of our submission available
at https://github.com/RomeoV/ml4co-competition and hope that it will facilitate further
research into instance-wise algorithm conﬁguration with graph neural networks.

2 Method

Our method poses instance-wise algorithm conﬁguration as a supervised learning problem. For this,
we ﬁrst collected a dataset of triplets (i, c, γic) by running the solver for a ﬁxed time limit of 15
minutes for all instances i
is a reduced conﬁguration
space to record the primal-dual integral γic. Afterwards, we used this data to train a model that
predicts the best conﬁguration for a given instance. For item placement and load balancing, we used
graph neural networks; for anonymous we used a simple model based on clusters. Below, we explain
the key components of our approach in more detail.

and all conﬁgurations c

, where

S ⊂ C

∈ S

∈ I

2

v1v2v3Variablesc1c2Constraintsx1x2x3x′1x′2xi,x′j∈R64NodeembeddingsBatchNormGraphConvolution&(cid:18)(cid:19)4×GraphConvolution:xn←θ1xn+θ2Xm∈N(n)em,n·xm646464641-dimgraphembeddingGlobalMaxPoolingAttentionPoolingγi,1γi,2......γi,60Onepredictionperconfig∈A2×Dense×3ensemblemembersv1v2v3Variablesc1c2Constraintsx1x2x3Variablefeatures:1.isbinary2....9.lowerboundx′1x′2Constraintfeatures:1.righthandsideInputrepresentationFigure 2: Instance-wise target standardization: We standardize the primal-dual integral γic for each
instance individually (here two instances i and j). In practice, we collect multiple primal-dual
integrals for each (i, c) using different random seeds.

C

Domain knowledge Running the solver for each (i, c)
is prohibitively expensive, because
the size of
is too large. Therefore, we only considered the three emphasis parameters for presolving,
heuristics and separation (each with 4 levels) and the built-in emphasis setting (11 levels). Each
emphasis parameter sets multiple parameters of the solver consistently and simultaneously. This
makes combinations of these parameters more likely to be discriminative. The Cartesian product of
these four parameters results in a conﬁguration space of size 43
11 = 704. By manual inspection,
we observed that the Cartesian product contains duplicate conﬁgurations, whose removal produces a
reduced conﬁguration space

(cid:48) of size 353. For the anonymous dataset, we chose

∈ I × C

=

×

(cid:48).

S

C

Greedy search Given our computational budget,
(cid:48) contained too many conﬁgurations to run the
solver on all pairs (i, c) when the number of instances was large. Therefore, for item placement and
(cid:48) conﬁgurations only for the ﬁrst 100
load balancing, we exhaustively collected data for all c
(cid:48) by
training instances (
the average solver performance that was achieved if the best available conﬁguration in the set S is
selected for each instance i

I100). We then measured the quality of a subset of conﬁgurations S

⊆ C

∈ C

C

C

∈ I100,

q(S) =

1
100

−

γic.

min
S
c
∈

(cid:88)i
∈I

100

(1)

(cid:48)

(cid:48)

|

∅

\

C

C

S

S

q(

(
C

Si|

Si+1,

(cid:48)). We thus chose

\
(cid:48)) and for load balancing q(S40)

We produced a sequence of subsets S0, S1, S2, . . . , S353 where S0 =
, Si ⊆
= i
(cid:48) by greedily adding a conﬁguration ci
and S353 =
Si) to Si that yields the largest
(
∈
C
quality improvement, i.e., ci = arg maxc
). We observed that for item placement
c
Si) g (Si ∪ {
}
∈
= S60 for item placement
q(
q(S60)
≈
C
≈
and
= S40 for load balancing to effectively reduce the number of conﬁgurations. Our procedure
effectively eliminates conﬁgurations that are strictly dominated by others and ensures that there is at
least one good conﬁguration for each instance i

∈ I100.
Model For item placement and load balancing, we designed a model that predicts the best conﬁg-
γic for a given instance i. Our model takes as input the bi-partite graph
uration c∗i = arg minc
R|S| where each entry
representation of an instance i from Gasse et al. (2019). It outputs ˆγi ∈
corresponds to the performance our model predicts for a speciﬁc conﬁguration c
. At test time,
a single-forward pass is performed and the conﬁguration ˆci for which our model predicts the best
performance is chosen, i.e. ˆci = arg minc
ˆγic. Our model is a graph neural network and illustrated
in Figure 1. We mostly followed Gasse et al. (2019), but use four convolutional layers, the graph
convolution operator from (Morris et al., 2019) and batch normalization (Ioffe et al., 2015) instead
of layer normalization. The processed graph is pooled (via global max and attention, separately
for variable and constraint nodes) to produce a 256-dimensional latent vector from which the ﬁnal
prediction is made via a dense neural network with a single hidden-layer. For our submission, we
produced a 3-ensemble of this model, where predictions were averaged.

∈ S

∈S

∈S

Loss For training the model, we used a simple but effective loss. For a given instance i, our model
predicts the performance for all conﬁgurations simultaneously. We compute the MSE between the
predicted and recorded (in dataset) performance for all conﬁgurations. This approach leverages
we collected for a given instance, while performing only a single forward-pass of
all

γic, i

{

∈ S}

3

betterworsebetterworse5′00010′00015′000−10+1c1c1c1c2c2c2c3c3c3c1c1c1c2c2c2c3c3c3⇒standarizationγ′ic←γic−µiσiγ′jc←γjc−µjσjc1c1c1c2c2c2c3c3c3c1c1c1c2c2c2c3c3c3instancei:instancej:rawdatainstance-wisestandarizeddataPrimal-dualintegralγicafter15minutes,withconfigc1andthreerandomseeds.Wetrytopredictthis.Table 1: Our model improves the total primal-dual integral across all hidden test instances (Γc) by
12%, 35% and 8% over the default conﬁguration for item placement, load balancing and anonymous.
It improves performance on 66, 95 and 38 out of test instances (runs) respectively.

ITEM PLACEMENT

LOAD BALANCING

ANONYMOUS

CONFIGURATION

Γc

WINS

Γc

WINS

Γc

WINS

DEFAULT
OURS

1.54 × 106
1.36 × 106

34
66

2.08 × 106
1.33 × 106

5
95

2.96 × 1010
2.73 × 1010

62
38

the model for a given instance. We did not adopt a ranking loss, because it can make optimization
harder and we observed that often there are several good conﬁgurations for a given instance with
only negligible differences, and it may be acceptable for our model to choose any of those. However,
this regression task requires our model not only to predict relative performance differences between
conﬁgurations, but also whether an instance is easy or hard (which is irrelevant for selecting the
best conﬁguration). Therefore, we decide to instance-wise standardize the primal-dual integrals
used as targets for training. Speciﬁcally, we compute the mean µi and standard deviation σi over all
conﬁgurations c

as our training targets (Figure 2).

µi

for a given instance i to use γ(cid:48)ic ←

∈ S

γic−
σi

Anonymous task The third dataset of anonymous presents unique challenges: Firstly, the dataset
is small in size; it contains only 98 and 19 instances for training and validation respectively. Secondly,
the dataset is heterogeneous, it contains instances that vary substantially in size in terms of their
number of constraints and variables. In contrast, the method we presented thus far relies on training
a high-capacity model that can leverage a large dataset of (i, c, γic) triplets and exploits structural
commonalities in the MILP instances it is trained on. Therefore, we opted for an alternative approach
that is conceptually very simple. We identiﬁed ﬁve clusters of instances across training and validation
instances that share the same number of variables and constraints. We grouped all remaining instances
into a sixth residual cluster. For each cluster, we determined the conﬁguration that resulted in the
best average primal-dual integral for all its cluster members based on the (i, c, γic)
R
we collected. At test time, for a new instance, we determine its cluster membership and predict the
conﬁguration that we identiﬁed to be best for its corresponding cluster.

∈ I × S ×

3 Results

All submissions were evaluated by the organizers of the ML4CO competition on the hidden test
instances with the same hardware set-up to determine the ﬁnal ranking of all participating teams. Item
placement and load balancing were tested on 100 instances with a single random seed; anonymous was
tested with 20 instances with ﬁve random seeds, for a total of 100 test runs. To compare our model’s
conﬁgurations against the default conﬁguration of the SCIP solver, we re-evaluated our model’s
conﬁgurations and the default conﬁguration on the hidden test instances after their release. We used
Hewlett-Packard m710x nodes equipped with a quad-core Intel Xeon E3-1585Lv5 processor in a
distributed compute cluster, for which unfortunately the residual compute load may vary during the
evaluation. However, we found that our results were comparable to the performance the competition
organizer’s reported for our model. The competition’s ranking was based on the primal-dual integral
across all test instances, i.e., Γˆc =
γiˆc. This tends to give a larger weight to instances with
a higher primal-dual integral. In addition, we therefore report statistics based on the distribution
γiˆc and compare against the primal-dual integral of the default conﬁguration γi0. In particular, we
compute for each instance i, the improvement as the reduced primal-integral γiˆc−
γi0

i
∈Itest

(cid:80)

γi0

.

When conﬁguring the solver with our model, the primal-dual integral across all test instances
improved by 12% (item placement), 35% (load balancing) and 8% (anonymous) respectively over the
default conﬁguration. We improved solver performance on 66 (for item placement) and 95 (for load
balancing) of the 100 test instances (Table 1). For the anonymous dataset, the primal-dual integral
was only reduced for 38 (out of 100) test runs. But the improvements on these instances tended to be
large in magnitude, resulting in overall better performance. On the instance-level, we found that the
effect of using our model’s conﬁguration instead of the default can vary widely. In the best-case, the
primal-dual integral was reduced by 57%, 66% and 60% respectively, while in the worst case the

4

f
o
r
e
b
m
u
n

s
e
c
n
a
t
s
n
i

20

10

0

Item placement
mean=
8%

−

better

50 %
−

+ 0 %

+ 50 %

+ 100 %

20

10

0

Load balancing
mean=
32%

−

better

50 %
−

+ 0 %

primal-dual integral
γiˆc−
γic

γic

40

20

0

Anonymous

mean=37%

better

+ 0 %

+ 200 %

+ 400 %

Figure 3: The mean (median) improvement of our model on the test instances for item placement and
load balancing is 8% (12%) and 32% (34%). But performance worsens on average (median) by 37%
(10%) for the anonymous dataset.

primal-dual integral increased by 89%, 31% and 434% (Figure 3). The mean (median) improvement
was 8% (12%) and 32% (34%) for item placement and load balancing, while performance worsened
on average (median) by 37% (10%) for the anonymous dataset.

4 Outlook

We presented our submission for the conﬁguration task of the Machine Learning for Combinato-
rial Optimization (ML4CO) NeurIPS 2021 competition. We showed that instance-wise algorithm
conﬁguration with graph neural networks is a viable approach for improving the performance of
the open-source solver SCIP to solve mixed integer linear programs. The effectiveness of our
approach ultimately depends on the quality of conﬁgurations under consideration. A promising
avenue to improve on our work is therefore to combine our model with more sophisticated methods
to explore the conﬁguration space, possibly using online methods. We make our code available
at https://github.com/RomeoV/ml4co-competition and hope that this will facilitate further
research into instance-wise algorithm conﬁguration with graph neural networks.

References

Achterberg, Tobias (2009). “SCIP: Solving Constraint Integer Programs”. In: Mathematical Program-

ming Computation 1.1, pp. 1–41.

Gasse, Maxime, Didier Chetelat, Nicola Ferroni, Laurent Charlin, and Andrea Lodi (2019). “Exact
Combinatorial Optimization with Graph Convolutional Neural Networks”. In: Advances in Neural
Information Processing Systems. Vol. 32. Curran Associates, Inc.

Ioffe, Sergey and Christian Szegedy (2015). “Batch Normalization: Accelerating Deep Network Train-
ing by Reducing Internal Covariate Shift”. In: Proceedings of the 32nd International Conference
on Machine Learning. International Conference on Machine Learning. PMLR, pp. 448–456.
Kadioglu, Serdar, Yuri Malitsky, Meinolf Sellmann, and Kevin Tierney (2010). “ISAC – Instance-
Speciﬁc Algorithm Conﬁguration”. In: Proceedings of the 2010 Conference on ECAI 2010: 19th
European Conference on Artiﬁcial Intelligence. NLD: IOS Press, pp. 751–756.

Morris, Christopher, Martin Ritzert, Matthias Fey, William L. Hamilton, Jan Eric Lenssen, Gaurav
Rattan, and Martin Grohe (Jan. 27, 2019). “Weisfeiler and Leman Go Neural: Higher-Order Graph
Neural Networks”. In: Proceedings of the Thirty-Third AAAI Conference on Artiﬁcial Intelligence.
AAAI’19/IAAI’19/EAAI’19. Honolulu, Hawaii, USA: AAAI Press, pp. 4602–4609.

5

