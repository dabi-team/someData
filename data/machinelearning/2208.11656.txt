2
2
0
2

g
u
A
4
2

]

G
L
.
s
c
[

1
v
6
5
6
1
1
.
8
0
2
2
:
v
i
X
r
a

Constraint-driven multi-task

learning

Bogdan Cretu

University of Oxford

Supervised by: Andrew Cropper

Trinity 2022

 
 
 
 
 
 
Abstract

Inductive logic programming is a form of machine learning based on mathematical

logic that generates logic programs from given examples and background knowl-

edge.

In this project, we extend the Popper ILP system to make use of multi-task learn-

ing. We implement the state-of-the-art approach and several new strategies to

improve search performance. Furthermore, we introduce constraint preservation,

a technique that improves overall performance for all approaches.

Constraint preservation allows the system to transfer knowledge between updates

on the background knowledge set. Consequently, we reduce the amount of re-

peated work performed by the system. Additionally, constraint preservation al-

lows us to transition from the current state-of-the-art iterative deepening search

approach to a more eﬃcient breadth ﬁrst search approach.

Finally, we experiment with curriculum learning techniques and show their po-

tential beneﬁt to the ﬁeld.

Contents

1 Introduction

1.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1.2 Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2 Related work

2.1 Ability to learn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1

1

7

9

9

2.2 Multi-task learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10

2.3 Multi-task learning in ILP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11

3 Problem setting

12

3.1 Logic programming syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12

3.2

Inductive logic programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14

3.3 Popper ILP System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15

4 Implementation

19

4.1 Naive approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

4.2 Knowledge transfer: iterative deepening approach . . . . . . . . . . . . . . . . . 20

4.2.1 Knowledge transfer: resetting search size

. . . . . . . . . . . . . . . . . 26

4.2.2 Knowledge transfer: removing redundant testing . . . . . . . . . . . . . 29

4.3 Preserving constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30

4.4 Automatic computation of task learning order . . . . . . . . . . . . . . . . . . . 33

4.4.1 Ordering by number of examples solved . . . . . . . . . . . . . . . . . . 34

4.4.2 Ordering by number of constraints . . . . . . . . . . . . . . . . . . . . . 35

5 Experimental Results

36

5.1 Data sets

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37

5.2 Testing environment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38

5.2.1

Speciﬁcations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38

5.2.2 Testing protocol

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38

5.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39

5.3.1 Algorithms

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39

5.3.2 Printer head . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40

5.3.3

String transformation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44

5.3.4 Robot movement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47

6 Conclusions

50

6.1 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50

6.2 Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50

6.3 Future work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52

Bibliography

54

Chapter 1

Introduction

1.1 Motivation

Recent Artiﬁcial Intelligence (AI) research has shown considerable interest in developing sys-

tems that can mimic human learning and thinking [13]. Similar to human learning, there

has been signiﬁcant success in transferring knowledge between AI systems, like a “student”

- “teacher” relationship [22]. To simulate human learning, a “student” system should also

be able to accumulate knowledge and combine the obtained information. For example, it is

not expected of a Computer Science pupil to learn how to implement quicksort without ﬁrst

understanding the notions of median and partition. We can extend this expectation to an

AI system. Instead of solving a complex task without prior knowledge, ﬁrstly, learn how to

resolve more straightforward problems from the same area. This form of Machine Learning is

referred to as multi-task learning [27].

Inductive Logic Programming is an ideal candidate for the above use case [8]. Inductive Logic

Programming (ILP) is a form of machine learning that learns logic programs (also referred to

as symbolic programs) based on given examples and background knowledge (BK). The BK

set consists of a set of logic programs given by the user. Therefore, transferring knowledge

becomes trivial [24]: if we want to reuse a solution in solving another task, it is suﬃcient to

1

append it to the given BK. Returning to the “student” - “teacher” example, the previously

mentioned approach would be equivalent to having a teacher provide his student with a new

deﬁnition.

Aside from providing support for multi-task learning, ILP has been shown to provide exten-

sive beneﬁts compared to most ML models, such as Data Eﬃciency (being able to generalise

from a small number of examples) and Explainability (providing outputs that are easily un-

derstandable by a human) [8].

We will proceed by providing the reader with an example logic program (see Figure 1.1)

written in Prolog in order to accommodate them with the syntax used throughout the project.

Afterwards, we will describe four problems that can be solved by an ILP system and which

would beneﬁt from multi-task learning.

% Background knowledge:

isFather("John", "Dan") % John is Dan's father
isFather("Paul", "John") % Paul is John's father
isWife("Alice", "Paul") % Alice is Paul's wife

isGrandmother(X,Y):-isWife(X,Z),

isGrandfather(Z,Y) % X is Y's grandmother
% if X is Z's wife and
% Z is Y's grandfather

isGrandfather(X,Y):-isFather(X,Z),

isFather(Z,Y) % X is Y's grandfather

% if X is Z's father and
% Z is Y's father

% Logic programming query:

?-isGrandmother("Alice","Dan") % Is Alice Dan's grandmother?

Figure 1.1: Logic program example

Kinship relationships. Kinship relationships allow an illustration of the problem solved

by introducing multi-task learning in ILP systems. Moreover, the trivial nature of the problem

2

allows for synthetic data generation to benchmark. In Figure 1.2 we show a situation where

a shorter program (isGrandmother(A,B) :- isWife(A,C), isGrandfather(C,B) instead

of isGrandmother(A,B) :- isWife(A,C), isFather(C, D), isFather(D,B)) is learnt to

explain the grandmother relationship.

% Background knowledge:

isFather("John","Dan")
isFather("Paul","John")

isWife("Alice","Paul")

% Given examples:

isGrandfather("Paul","Dan")

isGrandmother("Alice","Dan")

% Programs learnt:

isGrandfather(A,B) :- isFather(A,C), isFather(C,B)

isGrandmother(A,B) :- isWife(A,C), isGrandfather(C,B)

% Programs learnt without multi task learning:

isGrandfather(A,B) :- isFather(A,C), isFather(C,B)

isGrandmother(A,B) :- isWife(A,C), isFather(C, D), isFather(D,B)

Figure 1.2: Example for the kinship relationship problem

String transformation. One of the most widely used examples to benchmark ILP systems

are EXCEL type string transformation operations [8]. Through multi-task learning, an ILP

system can better capture situations where a complex transformation consists of sequential

applications of more simple operations. In Figure 1.3, we present our initial set of example

and their equivalent programs. The given functions perform the following operations:

• f0 - capitalize each word of a string

• f1 - capitalize a single word

3

• f2 - drop the ﬁrst word of a string and capitalize the second

• f3 - copy a string until the ﬁrst non-letter character is encountered

The predicates inv0 and inv2 from the example are auxiliary functions invented during the

learning process.

% Given examples:

f0('gerson zaverucha', 'Gerson Zaverucha')
f0('jesse davis', 'Jesse Davis')
f0('paolo frasconi', 'Paolo Frasconi')

f1('james', 'James')
f1('jozie', 'Jozie')
f1('paul', 'Paul')

f2('dr wilson', 'Wilson')
f2('dr brown', 'Brown')
f2('dr wright', 'Wright')

f3('artificial.', 'artificial')
f3('intelligence ', 'intelligence')
f3('systems1a', 'systems')

% Programs learnt:

f0(A,B):-f1(A,C),inv0(C,B).
inv0(A,B):-copyskip1(A,C),f1(C,B).

f1(A,B):-mk_uppercase(A,C),f3(C,B).

f2(A,B):-skip1(A,C),inv2(C,B).
inv2(A,B):-skip1(A,C),f1(C,B).
inv2(A,B):-skip1(A,C),inv2(C,B).

f3(A,B):-copyskip1(A,B),not_letter(B).
f3(A,B):-copyskip1(A,C),f3(C,B).

Figure 1.3: Example for the string transformation problem

Robot movement. Robot movement can be represented as basic movements such as going

up/down/left/right on a grid. For traversing large distances or completing complex paths

4

it would be more eﬃcient to have common patterns such as corner turns, as part of the

background knowledge.

In Figure 1.4, we show a solution where a 5 step translation is reduced to only two literals.

% Data format:

f(State(X, Y, Xnew, Ynew, Width, Height))

% Given examples:

turn(State(0, 1, 1, 2, 5, 2))
turn(State(0, 0, 1, 1, 5, 2))

jump(State(0, 1, 1, 4, 5, 2))
jump(State(0, 0, 0, 3, 5, 2))

turnAndJump(State(0, 0, 1, 4, 5, 2))

% Programs learnt:

turn(State(X, Y, Xnew, Ynew, W, H)) :- right(X, Y, X2, Y2),

down(X2, Y2, Xnew, Ynew)

jump(State(X, Y, Xnew, Ynew, W, H)) :- right(X, Y, X2, Y2),

right(X2, Y2, X3, Y3)
right(X3, Y3, Xnew, Ynew)

turnAndJump(State(X, Y, Xnew, Ynew, W, H)) :-

turn(X, Y, X2, Y2),
jump(X2, Y2, Xnew, Ynew)

Figure 1.4: Example for the robot movement problem

Drawing images. Most graphic rendering techniques are performed by decomposing scenes

into primitives such as lines, triangles or quads. Speciﬁc algorithms (such as Constructive

Solid Geometry) also make use of more complex shapes, for which the primitive decomposition

is computed in advance [18].

Based on the above, we formulate the following problem: given a set of functions that control

a printer head (moving over the four axes, returning to (1,1) coordinates or drawing a pixel)

5

the system has to learn to draw complex images. In Figure 1.5 we show how a cube can be

drawn by connecting four lines.

% Data format:

f(State(X, Y, Width, Height, Grid))

% Given examples:

topLine(State(_, _, 3, 3, [1,1,1,0,0,0,0,0,0]))
bottomLine(State(_, _, 3, 3, [0,0,0,0,0,0,1,1,1]))
leftLine(State(_, _, 3, 3, [1,0,0,1,0,0,1,0,0]))
rightLine(State(_, _, 3, 3, [0,0,1,0,0,1,0,0,1]))
isCube(State(_, _, 3, 3, [1,1,1,1,0,1,1,1,1]))

% Programs learnt:

topLine(S, S5) :- at_start(S), move_up(S, S2), move_up(S, S3),
draw1(S3), move_right(S3, S4), draw1(S4),
move_right(S4, S5), draw1(S5)

bottomLine(S, S3) :- at_start(S), draw1(S), move_right(S, S2),

draw1(S2), move_right(S2, S3) draw1(S3)

leftLine(S, S3) :- at_start(S), draw1(S), move_up(S, S2),

draw1(S2), move_up(S2, S3) draw1(S3)

rightLine(S, S5) :- at_start(S), move_right(S, S2),

move_right(S, S3), draw1(S3),
move_up(S3, S4), draw1(S4),
move_up(S4, S5), draw1(S5)

isCube(S, S4) :- topLine(S, S2), returnStart(S2, S3),

bottomLine(S3, S4), returnStart(S4, S5),
leftLine(S5, S6), returnStart(S6, S7),
rightLine(S7, S8), returnStart(S8, S9)

Figure 1.5: Example for the image drawing problem

All the above problems are solvable by an ILP system, but certain limitations exist.

ILP

systems learn by searching through a hypothesis space of possible solutions, but even the most

advanced search techniques face diﬃculties when the size of the hypothesis space increases

signiﬁcantly. The size of the hypothesis space is directly related to the maximum size a

program can have [5].

In order to better understand this statement, imagine the task of

writing down all possible programs of size n that contain a given list of predicates (allowing

duplicates). One can easily observe that the size of the result grows exponentially with n.

6

Therefore, the maximum size of possible solutions must be restricted such that searching

through it is feasible. Consequently, if the solution for a task is too large, the task will

become unsolvable.

Multi-task learning mitigates the above issue by reusing learnt solutions when learning tasks

from related domains. In the four previous examples, we can observe that several tasks can

be represented as more compact solutions by reusing the solutions from some other tasks.

The state-of-the-art approach to ILP multi-task learning is based on the Metagol [6] system

and was described by Lin et al. [14] in 2014. It has been shown to approach the performance

of commercial systems of the time and outperform an independent learning strategy (running

Metagol on each task separately). In Chapter 4 we will identify signiﬁcant drawbacks of the

current strategy that negatively impact its learning abilities.

Finally, we introduce Popper [5], an ILP system which has superseded Metagol [6]. Popper

uses a new approach to ILP, referred to as “Learn from failures”: while searching through

the hypothesis space, it generates constraints based on incorrect programs found. Those

constraints are then used to prune the search space and improve learning time. Furthermore,

in Section 4.3 we detail how constraints can be further used to improve the learning rate for

multi-task systems.

1.2 Contribution

Our contribution to the ﬁeld represents an enhanced version of Popper that supports multi-

task learning and uses knowledge transfer.

We have decided to implement our approach and re-implement the method described by Lin

et al. [14] as extensions to the Popper ILP system in order to be able to evaluate the beneﬁt

that multi-task learning can obtain by preserving constraints.

Such, we summarise our contribution as follows:

7

• MetagolDF performs iterative deepening search based on the maximum size of programs

in the hypothesis space. We identify situations where increasing search size is detrimen-

tal to the learning process, virtually blocking the system from progressing further. In

consequence, we provide an alternative search strategy that circumvents this obstacle

and has a greatly improved learning ability.

• Between each stage of iterative deepening search, the MetagolDF does not maintain any

information. Our implementation gives Popper the ability to preserve constraints when

the maximum search size is modiﬁed. Such, we improve the learning rate and allow

for a breadth ﬁrst search approach to replace the iterative deepening approach. For

example, let C be the set of constraints obtained by searching through a hypothesis

space of size n. This constraints will help prune a search space of size n + 1. Without

constraint preservation, the system would be unable to transfer information between

runs. Therefore, it must search through a space size that includes both hypotheses of

size n and size n + 1.

• We show that the performance of the system is strongly correlated to the order in which

the user inputs the list of tasks to be solved [21]. We design two methods that order tasks

based on how close the system is to solving them, aiming to achieve more consistent

and closer to optimal performance.

• MetagolDF has been tested against a limited data set of 17 string transformation oper-

ations. We reﬁne one external data set and synthetically generate two additional ones.

We then proceed to empirically evaluate the performance of all proposed techniques and

indicate how each performs in comparison to the original approach.

8

Chapter 2

Related work

2.1 Ability to learn

Programs that expand their learning abilities (“have the ability to learn”) have been an area of

interest in Machine Learning for multiple decades. In [20], Solomonoﬀ describes a system that,

given a small set of concepts, is able to learn problems of increasing diﬃculty by extracting

new, more complex concepts during each learning stage. A concept was deﬁned as a sequence

of instructions. The approach reduces most problems from science to two main categories:

Inversion problems. Given a machine M , that performs string transformation operations,

and a string s, the goal of an inversion problem is to determine a string x, such as M (x) = s.

Time limited optimisation problems. Given a machine M , that takes a string and returns

a real number, the goal of a time limited optimisation problem is to ﬁnd a string x, within a

ﬁxed time limit T , such as M (x) is as large as possible.

Furthermore, the paper concludes with an overview of areas where such a system would

beneﬁt from further research, most notably: improvements in the method used to update the

set of knowledge once a new task is learnt and designing a system that is able to work on an

unordered set of programs.

9

2.2 Multi-task learning

In this thesis, we refer to multiple Machine Learning paradigms related to multi-task learning.

Meta-learning. Meta-learning (learning to learn) focuses on how machine learning ap-

proaches perform on certain tasks and then uses information obtained from previous runs in

order to speed up learning during future tasks [23].

Curriculum learning. Curriculum learning means that tasks will be learnt in a speciﬁc

order, based on their perceived diﬃculty (similar to a human curriculum) [25].

Transfer learning. Transfer learning is a technique through which multiple learners (that

focus on related tasks) transfer knowledge to each other. [26].

The above approaches have been empirically and theoretically shown to improve performance

over traditional independent learning methods [27].

Although the fact that tasks from a similar domain may be related appears intuitive, it is nec-

essary to outline both the beneﬁts and downsides of multi-task learning. Therefore, depending

on the similarity between the given set of tasks, it is crucial to evaluate if multi-task learning

is expected to provide a guaranteed advantage over independent learning [3]. The expectation

is that multi-task learning approaches perform signiﬁcantly worse than conventional learning

methods on unrelated tasks [17]. Moreover, transfer learning systems that retain information

from all learnt tasks as part of their knowledge set face diﬃculty when used to solve large

data sets [10]. This is a consequence of the fact that search speed is usually correlated to the

size of the background knowledge. Several methods that attempt to circumvent the above

issues have been developed.

For example, neural networks have been used to recognise which programs are expected to

perform better on speciﬁc input/output pairs [9].

It has also been experimented with the idea of “forgetting”, which refers to removing data

10

from the background knowledge (or “unlearning”) with the purpose of improving search time

[4].

2.3 Multi-task learning in ILP

One of the main advantages of ILP, in the context of multi-task learning, is the fact that

ILP systems can perform knowledge transfer without signiﬁcant overhead through the fact

that outputs are reusable as inputs. Despite such considerations, very few studies explore

multi-task learning approaches for ILP.

Metagol is an ILP system based on meta-interpretive learning [6]. Lin et al. adapt the

Metagol system to make use of multi-task learning (MetagolDF ) and benchmark it against

multiple agents: a human agent, a commercial system (Microsoft FlashFill, introduced with

Excel 2013), and a version of itself, which does not make use of multi-task learning.

The system has shown promising results and consistently achieved better or equal performance

when compared with the standard approach.

The author concludes by highlighting a series of limitations of multi-task learning in the

context of ILP. Most importantly, it observes that the system will become overwhelmed when

run on multiple data sets. This claim is empirically conﬁrmed by Cropper, in [4], who also

provides a solution for such use cases: introducing Forgetgol. This system can forget programs

and reduce the background knowledge size.

In this project, we identify signiﬁcant issues with the previous approach and propose an

alternative solution. We build on the Popper ILP system [7] and introduce the following

elements of novelty: we modify how the hypothesis space is searched, we retain information

between failed search attempts, and we introduce new search strategies that focus on analysing

the diﬃculty of the tasks at run-time (similar to curriculum learning).

11

Chapter 3

Problem setting

In this chapter, we will give an overview of ILP in order to familiarise the reader with speciﬁc

terminology used throughout the project.

3.1 Logic programming syntax

We will deﬁne the syntax of Logic Programs by following deﬁnitions from [8], and [11]:

Variable. A variable is a string of characters that starts with an uppercase letter.

Function. A function symbol is a string of characters that starts with a lowercase letter.

Examples: f1, move up, draw1.

Predicate symbol. A predicate symbol is a string of characters that start with a lowercase

letter, similarly to a function.

Arity. The arity of a function/predicate symbol f is the number of arguments it takes and

is denoted as f/n.

Constant symbol A constant symbol is a predicate symbol of arity zero. Examples: alice,

bob.

12

Term. A term refers to either a variable, a constant symbol or a predicate symbol of arity n

followed by a tuple of size n.

Ground term. We say that a term is ground if it contains no variables.

Atom. An atom is a formula f (x1, .., xn), such as p is a predicate symbol of arity n and xi

is a term ∀i ∈ {1, .., n}.

Ground atom. We say that an atom is ground if all its terms are ground.

Negation. We say that an atom is false if it cannot be proven true. Throughout this paper,

we will represent negation through the symbol ¬.

Literal. A literal is either an atom or its negation.

Clause. A clause is a disjunction of atoms h1, h2, .., hn, b1, b2, .., bm, represented as:

h1, h2, .., hn :- b1, b2, .., bm

The above deﬁnition is equivalent to:

(h1 ∧ h2 ∧ .. ∧ hn) ∨ ¬b1 ∨ ¬b2.. ∨ ¬bm

We refer to h1, h2, .., hn as the head literals and b1, b2, .., bm as the body literals of the clause.

The above representation is shorthand for “h holds true if all of b1, .., bm” hold true.

Horn clause A Horn clause is a clause for which n (number of head/positive literals) is at

most 1.

We will only be concerned with Horn clauses since other types of clauses are not supported

by basic Prolog [12].

Ground clause. We say that a clause is ground if it contains no variables.

13

Deﬁnite clause. We say that a Horn clause is deﬁnite if the number of positive literals is

exactly one.

Deﬁnite logic program. A deﬁnite logic program is a set of deﬁnite clauses. We will further

refer to deﬁnite logic programs as programs.

3.2 Inductive logic programming

Inductive logic programming problems are given as triplets (B, E+, E−), where B represents

the background knowledge (BK), E+ represents the set of positive examples, and E− repre-

sents the set of negative examples.

Background knowledge. The background knowledge is a set of programs for which the

deﬁnition is given completely. By the close world assumption, anything that is not explicitly

stated true in the BK is considered false [19]. We show a specimen from the BK of the string

transformation problem:

B =






is_empty([]).

is_space([’ ’|_]).

is_number([’0’|_]).

...

is_number([’9’|_]).






Examples. Examples are given as two sets (positive and negative examples) and are repre-

sented similarly to the BK, but all clauses must be ground. Moreover, there is no assumption

on the function behaviour outside of the given use cases. Below we show examples of a

function that turns the ﬁrst letter of a string to uppercase.

14

E+ =

E− =











f([’j’, ’a’, ’m’, ’e’, ’s’],[’J’, ’a’, ’m’, ’e’, ’s’]).

f([’j’, ’o’, ’z’, ’i’, ’e’],[’J’, ’o’, ’z’, ’i’, ’e’]).

f([’b’, ’e’, ’n’],[’B’, ’e’, ’n’]).

f([’j’, ’a’, ’m’, ’e’, ’s’],[’j’, ’a’, ’m’, ’e’, ’s’]).

f([’j’, ’o’, ’z’, ’i’, ’e’],[’o’, ’z’, ’i’, ’e’]).

f([’b’, ’e’, ’n’],[’B’]).











Hypothesis space. The hypothesis space contains all the possible programs that can be built

from the predicates given in the BK. Since the hypothesis space is inﬁnite, it is important

to enforce certain restrictions to make searching through it practical. Such, many machine

learning makes use of inductive bias and language bias [15, p,64,106] to restrict the hypothesis

space.

3.3 Popper ILP System

In Chapter 4 we introduce our multi-task learning strategies, which build on the Popper ILP

system. The Popper ILP system uses an approach known as “Learning from failures” [5]. This

technique divides the learning process into three stages: generate, test, and constrain.

In the generate phase, a logic program (referred to as hypothesis) is selected, such that it

respects the currently learnt hypothesis constraints. Afterwards, the program is tested

against the given examples. If all examples are covered, Popper will return the program as

a valid answer. Otherwise, we proceed to the constrain stage, where information from the

testing stage is used in order to augment the set of hypothesis constraints. Those three

stages are repeated until either a solution is found or there are no more programs in the

hypothesis space.

Below we will describe the four types of constraints.

15

Generalisation constraints. A generalisation constraint is a constraint that eliminates

generalisations of the current hypothesis. Example:

Given the following negative examples:

E− =






f([’j’, ’a’, ’m’, ’e’, ’s’],[’J’, ’a’, ’m’, ’e’, ’s’]).

f([’b’, ’e’, ’n’],[’B’, ’e’, ’n’]).






And the hypothesis:

(cid:26)

h =

f(A, B):-mk uppercase(A,B).

(cid:27)

We observe that a negative example holds for h. Such, we can prune generalisations, such as:

h’ =






f(A, B):-mk uppercase(A,B).

f(A, B):-head(A,B).






Specialisation constraints. A specialisation constraint is a constraint that prunes out

specialisations of the current hypothesis. Example:

Given the following positive examples:

E− =






f([’j’, ’a’, ’m’, ’e’, ’s’],[’J’, ’a’, ’m’, ’e’, ’s’]).

f([’b’, ’e’, ’n’,’ ’, ’g’],[’B’, ’e’, ’n’,’ ’, ’G’]).






And the hypothesis:

(cid:26)

h =

f(A, B):-mk uppercase(A,B).

(cid:27)

We observe that the ﬁrst positive example holds for h, but not the second. Such, we conclude

16

that h is too speciﬁc and prune out specialisations of h, such as:

(cid:26)

h’ =

f(A, B):-mk uppercase(A,B),empty(B).

(cid:27)

Elimination constraints. An elimination constraint is a constraint that eliminates a hy-

pothesis h from any separable hypothesis hs that contains h. We refer to a hypothesis hs as

separable if no predicate symbol from the head of a clause in hs appears in the body of a

clause in hs. Example:

Given the following positive examples:

E− =






f([’j’, ’a’, ’m’, ’e’, ’s’],[’J’, ’a’, ’m’, ’e’, ’s’]).

f([’b’, ’e’, ’n’,’ ’, ’g’],[’B’, ’e’, ’n’,’ ’, ’G’]).






And the hypothesis:

(cid:26)

h =

f(A, B):-empty(A).

(cid:27)

We observe that the no positive example holds for h. Such, we conclude that h can be

eliminated from any separable hypothesis, such as:

h’ =






f(A, B):-mk uppercase(A,B)

f(A, B):-empty(A).






Banish constraints. A banish constraint is a constraint that rules out one speciﬁc hypoth-

esis.

To handle searching through a vast hypothesis space size, the Popper ILP system looks for

solutions in increasing order of the number of literals in a hypothesis. The formula used to

compute an upper bound on the size of the hypothesis space is given in [5]:

17

• Maximum arity a.

• Maximum number of unique variables in a clause v.

• Maximum number of body literals allowed in a clause m.

• Maximum number of clauses in a hypothesis n.

• Declaration bias D = (Dh, Db).

n
(cid:88)

j=1

(cid:18)|Dh|va (cid:80)m
i=1
j

(cid:0)|Db|va
i

(cid:1)

(cid:19)

18

Chapter 4

Implementation

In this section, we will describe several multi-task learning approaches. For each one, we will

detail the advantages and disadvantages. We begin with the naive approach, followed by the

current state-of-the-art strategy. Afterwards, we will provide a new search algorithm that

focuses on resetting the size of the search space in order to overcome the limitations of the

state-of-the-art approach. Finally, we will describe two reﬁnements that can be applied to

any of the described approaches: constraint preservation and automatic task ordering.

4.1 Naive approach

This naive approach to multi-task learning iterates through all the tasks in order and attempts

to learn them by calling an ILP system (in our case Popper) 1. Therefore, it does not make

use of the fact that tasks learned together are expected to be correlated.

Advantages. The main advantage of this approach is that it does not suﬀer from the

additional overhead introduced by increasing the number of tasks in the BK [14]. In Figure 4.1

1We note that this search strategy can get blocked when working on unsolvable tasks. This behaviour
does not impact our results as the naive approach is only used for reference and we will benchmark against
the state-of-the-art strategy (which is discussed in Section 4.2). Other approaches that do not make use of
multi-task learning can be designed to overcome this diﬃculty.

19

the system is given two independent tasks: learning the isGrandfather and isGrandmother

functions. In such a situation, transferring knowledge between the two will be redundant and

only cause unnecessary overhead. Therefore, such use-cases beneﬁt the naive approach.

% Background knowledge:

isFather("John","Dan")
isFather("Paul","John")

isMother("Alice","Dan")
isMother("Ana", "Alice")

% Given examples:

isGrandfather("Paul","Dan")

isGrandmother("Ana","Dan")

% Programs learnt:

isGrandfather(A,B) :- isFather(A,C), isFather(C,B)

isGrandmother(A,B) :- isMother(A,C), isMother(C, B)

Figure 4.1: Advantage example for naive approach

Disadvantages. Although it performs well on uncorrelated data, multi-task learning sys-

tems have been shown repeatedly to out-perform traditional systems on tasks from the same

domain [8]. In Figure 4.2 the system is given the same two tasks, but the BK is modiﬁed such

that the tasks are no longer independent:

isGrandmother can be learnt as a function of isGrandfather. The naive approach has no

provision to beneﬁt from such situations.

Finally, in Algorithm 1 we show an implementation of the naive multi-task learning approach.

4.2 Knowledge transfer: iterative deepening approach

As previously discussed, the naive approach does not make use of knowledge transfer. To

address this issue, in [14], Lin et al. propose a new multi-task learning approach based on

20

% Background knowledge:

isFather("John","Dan")
isFather("Paul","John")

isWife("Alice","Paul")

% Given examples:

isGrandfather("Paul","Dan")

isGrandmother("Alice","Dan")

% Programs learnt:

isGrandfather(A,B) :- isFather(A,C), isFather(C,B)

isGrandmother(A,B) :- isWife(A,C), isGrandfather(C,B)

% Programs learnt without multi task learning:

isGrandfather(A,B) :- isFather(A,C), isFather(C,B)

isGrandmother(A,B) :- isWife(A,C), isFather(C, D), isFather(D,B)

Figure 4.2: Disadvantage example for naive approach

Algorithm 1 Naive approach to multi-task learning through Popper

function multipoppernaive

T ← {t1, t2, .., tn}
BK ← {BACKGROUND KNOWLEDGE}
for all t in T do

S ← {}
size ← 1
while TRUE do

sol ← popper(t, BK, size)
if sol (cid:54)= null then
S ← S ∪{sol }
T ← T \ {t}
break

end if
size ← size + 1

end while

end for
return S
end function

21

the Metagol ILP system. This method is currently state-of-the-art in multi-task ILP. The

described solution uses iterative deepening search, proceeding as follows:

1. Set maxSize = 1.

2. For all tasks, try to ﬁnd a solution with size at most maxSize.

3. If all tasks are solved, return.

4. Otherwise, update the background knowledge with newly learnt tasks, increment maxSize

by 1, and return at step 2.

Pseudo-code for integrating this search strategy into the Popper ILP system is present in

Algorithm 2.

Algorithm 2 Iterative deepening search

function multipopper
T ← {t1, t2, .., tn}
BK ← {BACKGROUND KNOWLEDGE}
S ← {}
maxSize ← 1
while TRUE do
for t in T do

sol ← popper(t, BK , maxSize)
if sol (cid:54)= null then
S ← S ∪{sol }
T ← T \ {t}

end if

end for
BK ← BK ∪ S
if T = {} then
return S

end if
maxSize ← maxSize + 1

end while
end function

Advantages. Through the introduction of knowledge transfer as part of the multi-task

learning strategy, this solution improves performance over the naive approach when used on

correlated data sets. For example, assume our background knowledge contains two primitive

22

predicates bk0 and bk1 and we are given two tasks,

f0 and f1,

such that

f1(A,B,C):-f0(A),f0(B),f0(C). Learning f0 and re-using it’s deﬁnition as part of an en-

hanced background knowledge allows us to learn f1 more quickly by reducing the size of its

solution.

Disadvantages. We observe that even when the BK is augmented, the search size continues

to increase. On one hand, this particularity provides an advantage when solution sizes remain

large even with the new BK, such as in Figure 4.3. On the other hand, it gives rise to the

following disadvantages:

% Background knowledge:

isFather("John","Dan")
isFather("Paul","John")

isWife("Alice","Paul")
isMother("Mary","Alice")

% Given examples:

isGrandfather("Paul","Dan")

isGrandgrandmother("Mary","Dan")

% Programs learnt:

isGrandfather(A,B) :- isFather(A,C), isFather(C,B)

isGrandgrandmother(A,B) :- isMother(A,C), isWife(C,D),

isGrandfather(D, B)

Figure 4.3: Positive example for iterative deepening search

Firstly, after each increase of the maxSize variable, we will reevaluate all programs of size

between 1 and maxSize − 1 from the previous iteration.

Secondly, we might search through an unnecessarily large hypothesis space when a BK aug-

mentation might have allowed us to ﬁnd a solution in a smaller space.

Moreover, as a consequence of the second disadvantage, this approach does not learn the most

23

compact solution possible. We will further describe this case below:

1. We will use the BK from the robot movement problem. For simplicity, we will only be

concerned with move up(A,B).

2. Assume we have two tasks, f0(A,B) and f1(A,B), such that their solutions are:

• f0(A,B):-move up(A,C),move up(C,D),move up(D,B)

• f1(A,B):-move up(A,C),move up(C,D),move up(D,E),move up(E,B)

3. In this approach, we will ﬁnd the solution for f0 after having maxSize = 4, and then

increment maxSize to 5, before augmenting the BK.

4. When searching for programs up to size 5, we can identify two valid solutions for f1:

• f1(A,B):-move up(A,C),move up(C,D),move up(D,E),move up(E,B)

• f1(A,B):-f0(A,C),move up(C,B)

5. Such, we observe that the algorithm could return either solution, having no preference

for the more compact program.

Thirdly, this approach may lead to situations where learning does not conclude in a reasonable

time frame because of the increase in the hypothesis space size. This can be encountered in

a situation where functions a learnt in a chain, for example:

1. Deﬁne p(A,B)n:-p(A,C),p(C,B)n−1 for any predicate p and natural number n > 1.

Base case p(A,B)1:-p(A,B). Then, we have tasks f0,f1,f2,f3,f4:

• f0(A,B):-move up(A,C)6

• f1(A,B):-move up(A,C)36

• f2(A,B):-move up(A,C)216

24

• f3(A,B):-move up(A,C)1296

• f4(A,B):-move up(A,C)7776

2. By using this approach, f0 has to be learnt and added to the BK before f1, f1 before

f2, f2 before f3, f3 before f4.

3. Such, each task will be learnt by searching through hypothesis spaces of sizes as follows:

• f0 at size 7

• f1 at size 8

• f2 at size 9

• f3 at size 10

• f4 at size 11

4. But, all given tasks will have solutions of 6 body literals:

• f0(A,B):-move up(A,C)6

• f1(A,B):-f0(A,C)6

• f2(A,B):-f1(A,C)6

• f3(A,B):-f2(A,C)6

• f4(A,B):-f3(A,C)6

5. Given the formula from Section 3.3 and previous experiments we know that hypoth-

esis spaces containing programs of more than 10 literals can be generally considered

unsolvable within a reasonable time limit. Such, we observe the beneﬁt of the new

approach.

25

In the rest of this chapter, we will propose and analyze multiple search strategies and im-

provements to overcome the aforementioned disadvantages.

4.2.1 Knowledge transfer: resetting search size

We proceed by bringing forward a new search strategy and providing an argument for its

theoretical advantages over the current state-of-the-art approach.

When concerned with programs that achieve a signiﬁcant reduction in size through knowledge

transfer, the previous approach performs redundant work by continuing to search for solutions

of constantly increasing maximum size. We argue for restarting the search from maximum

size to one after a solution is found to one of the tasks.

By doing this we reduce the amount of work required when programs become “easy” after

knowledge transfer is performed. Below we will compute the diﬀerence in the number of

candidate solutions between the two approaches:

1. Let BK 0 be our initial background knowledge.

2. Let BK 1 = BK 0 ∪ {f0}.

3. Let f0, f1 be two predicates such that:

• f0 has a solution of size n in BK 0.

• f1 has a solution of size m > n in BK 0.

• f1 has a solution of size p < m in BK 1.

4. Let HS (f, size, BK ) be the size of the hypothesis space for task f, given size and the

background knowledge BK .

5. Let HS ∗(f, maxSize, BK ) =

maxSize
(cid:80)
size=1

HS (f, size, BK )

6. Then, the total number of programs generated can be computed as follows:

26

• Without reset we have:

n
(cid:88)

(HS ∗(f0, i, BK 0) + HS ∗(f1, i, BK 0)) +

i =1

max (

p
(cid:88)

i=n+1

• With reset we have:

HS ∗(f1, i, BK 1), HS ∗(f1, n + 1, BK 1))

(4.1)

n
(cid:88)

(HS ∗(f0, i, BK 0) + HS ∗(f1, i, BK 0))

(4.2)

i =1

+

p
(cid:88)

i =1

HS ∗(f1, i, BK 1)

7. Therefore, we identify two cases:

• If p ≤ n (4.1) and (4.2) can be written and compared as follows:

HS ∗(f1, n + 1, BK 1) >

p
(cid:88)

i=1

HS ∗(f1, i, BK 1)

(4.3)

• If p > n (4.1) and (4.2) can be written and compared as follows:

p
(cid:88)

i =n+1

HS ∗(f1, i, BK 1) <

p
(cid:88)

i=1

HS ∗(f1, i, BK 1)

(4.4)

8. By using the formula for HS , given in Section 3.3, we argue that the performance

increase in the case where p ≤ n overcomes the performance decrease from the case

p > n. Moreover, we can extend this argument to multiple tasks (e.g.

introduce f2

such that f2 is very diﬃcult, but has a much simpler solution that uses f1) in order to

strengthen the argument.

As a result, we can observe one use case improvement of the reset strategy.

27

A more concrete example can be seen in Figure 4.4, where the original approach would have

performed redundant work on learning the isGrandgrandmother task by evaluating solutions

of size four when a solution can be found at size three.

% Background knowledge:

isFather("John","Dan")
isFather("Paul","John")

isWife("Alice","Paul")
isMother("Olga","Alice")

% Given examples:

isGrandfather("Paul","Dan")

isGrandmother("Alice","Dan")

isGrandgrandmother("Olga","Dan")

% Programs learnt:

isGrandfather(A,B) :- isFather(A,C), isFather(C,B)

isGrandmother(A,B) :- isWife(A,C), isGrandfather(C, B)

isGrandgrandmother(A,B) :- isMother(A,C), isGrandmother(C,B)

Figure 4.4: Example for iterative deepening search with search size reset

Moreover, we will formalise this claim:

1. Assume there exists some task f , such that a solution of size n has been found, but

there exists a simpler solution, of size m, m < n. Both solutions generated from the

same BK.

2. By our approach, if a solution of size n has been found then Popper tried all solutions

of size s, s ∈ {1, 2, .., n − 1} with the current BK.

3. Then it means that no solution exists of size s, s ∈ {1, 2, .., n − 1}.

4. Contradiction with m < n.

28

5. Therefore, n is the smallest solution size that can be found with the current BK.

An Algorithm 3 we showcase pseudo-code for the reset approach.

Algorithm 3 Iterative deepening search with search size reset

function multipopperreset

T ← {t1, t2, .., tn}
BK ← {BACKGROUND KNOWLEDGE}
S ← {}
maxSize ← 1
while TRUE do

change ← false
for t in T do

sol ← popper(t, BK , maxSize)
if sol (cid:54)= null then
change ← true
S ← S ∪{sol }
T ← T \ {t}

end if

end for
if T = {} then
return S

end if
if change == true then

maxSize ← 1
BK ← BK ∪ S

else

maxSize ← maxSize + 1

end if
end while
end function

4.2.2 Knowledge transfer: removing redundant testing

Recall Algorithm 3. Any call to Popper would search all solutions up to maxSize, each time

it is incremented. We can modify the Popper algorithm to only search for programs of a ﬁxed

size. Therefore, we will no longer evaluate programs twice unless a solution has been found

to one of the tasks. An overview of this change is present in Algorithm 4.

Advantages. The main advantage of this approach is that it does not reiterate through

smaller search space sizes unless necessary (when the BK is augmented).

29

Disadvantages. Because we do not re-search the smaller hypothesis space sizes, we do not

keep constraint information between searches. This may result in a signiﬁcant increase in

the size of the hypothesis space evaluated. More speciﬁcally, if we are searching through a

hypothesis space that contains only programs of size n, we will not make use of the constraint

generated in the previous steps from programs of sizes between 1 and n − 1.

Algorithm 4 Breadth ﬁst search with size reset

function multipopperreset+

T ← {t1, t2, .., tn}
BK ← {BACKGROUND KNOWLEDGE}
S ← {}
size ← 1
while TRUE do

change ← false
for t in T do

sol ← fixedsizedpopper(t, BK , size)
if sol (cid:54)= null then
change ← true
S ← S ∪{sol }
T ← T \ {t}
break

end if

end for
if T = {} then
return S

end if
if change == true then

size ← 1
BK ← BK ∪ S

else

size ← size + 1

end if
end while
end function

4.3 Preserving constraints

Transferring knowledge between tasks requires Popper to retry hypothesis spaces that contain

programs with a smaller number of literals than the maximum tried until now (because the

30

introduction of more programs in the background knowledge creates new possible solutions at

the respective sizes). Therefore, all presented approaches will retry the same set of solutions

multiple times.

When modifying search size, the Metagol did not have the ability to transfer knowledge

through a standard form, even when working with a single task, e.g. if you have not found a

solution of maximum size up to n, you would need to restart the search from scratch when

looking for a solution of maximum size up to n + 1.

In this project, we circumvent this

limitation by extending the Popper ILP system, which has the ability to retain information

from failed attempts in the form of hypothesis constraints.

More speciﬁcally, Popper allows us to retain constraints between failed attempts and prune

the hypothesis space as soon as we begin searching with diﬀerent parameters (in our case, an

increased maximum number of literals).

To reduce the amount of repeated work caused by search size resets, we adapt all previous

methods to preserve constraints learnt by Popper for each task.

We showcase that necessary changes to implement constraint preservation in the improved

reset approach (recall Algorithm 4) in Algorithm 5.

Advantages. By making use of constraint preservation, we remove the bottleneck created

by resetting the search on a program and then retesting all candidate hypotheses. Moreover,

this technique resolves the signiﬁcant disadvantage of the breadth ﬁrst search approach. Now

that all constraints are preserved, there is no information lost by not reiterating through the

smaller hypothesis spaces.

Disadvantages. We argue that there do not exist signiﬁcant disadvantages of preserving

constraints. One could point out the fact that they may increase memory requirements and

the overhead of the reset phase. However, the expectation is that unless a solution is found

early, most of the constraints from previous stages would have also been learnt during the

31

Algorithm 5 Constraint preserving search

function multipoppercons
for i in range(n) do

rules[i] ← ∅

end for
T ← {t1, t2, .., tn}
BK ← {BACKGROUND KNOWLEDGE}
S ← ∅
size ← 1
while TRUE do

change ← false
for t in T do

(sol , cons) ← constraintpopper(t, BK , size, rules[i])
rules[i] ← rules[i] ∪ cons
if sol (cid:54)= null then
change ← true
S ← S ∪{sol }
T ← T \ {t}
break

end if

end for
if T = {} then
return S

end if
if change == true then

size ← 1
BK ← BK ∪ S

else

size ← size + 1

end if
end while
end function

current iteration.

Finally, we provide an argument for the fact that it is always correct to preserve constraints.

We are given the fact that any constraint generated by the system is sound [5].

Given a constraint C learnt during an iteration of the learning algorithm with background

knowledge BK , we show that constraint C would also hold for background knowledge BK (cid:48) =

BK ∪ N , where N is some set of valid background knowledge.

32

Let h be the hypothesis that determined C. h is generated from BK , therefore h also generated

from BK (cid:48). Therefore, during a learning process based on BK (cid:48), if h will also be tested, it will

generate the same sound constraint.

4.4 Automatic computation of task learning order

When considering large data sets where some tasks may be unsolvable, the ordering of the

tasks becomes important because the algorithm may not get to consider certain tasks that

have a solution of the current search size. Consequently, we propose the introduction of task

ordering methods, similar to curriculum learning. We focus on run-time evaluation of tasks,

aiming to order tasks by how close our system is to ﬁnding a solution. For example, take the

following scenario2:

1. We are given 100 tasks, fi with i ∈ {0, .., 99}.

2. Task f99 has a solution of size seven.

3. All other tasks have solutions of nine using the initial BK and solutions of size three if

f99 is part of their BK.

4. Recall the formula in Section 3.3. Based on it, we will approximate the number of

programs in hypothesis space of size x to 22x 3.

5. Now we will compare the solving time for the reset approach of the best case and worst

case orderings.

• Order f0, f1,..,f99

7
(cid:88)

(100 ∗ 22i

) +

3
(cid:88)

(99 ∗ 22i

)

i =1

i =1

(4.5)

2For this example we assume that the solution program is always found last in the hypothesis space
3The purpose of this approximation is to provide the reader with an overview of the rate at which the size
of the hypothesis space increases with the number of literals. Providing a more accurate result would require
a discussion around the values of other parameters from the formula in Section 3.3.

33

• Order f99, f0,f1,f2,..,f98 (f99 is computed ﬁrst)

6
(cid:88)

(100 ∗ 22i

) + 227

+

i =1

3
(cid:88)

(99 ∗ 22i

)

i =1

(4.6)

6. We obtain that when the system is given the order f0, f1,..,f99 it tests approximately

100 times more programs then when it is given the order f99, f0,f1,f2,..,f98.

Advantages. Given the above example, we know that task ordering is important for the

performance of the system. Approaches that perform automatic task ordering can overcome

this limitation, by identifying such scenarios and selecting and appropriate task sequence.

Possible disadvantages. We outline a list of possible disadvantages in order to highlight

the points we need to take into account when designing our heuristics. Firstly, the evaluation

function is not guaranteed to provide a signiﬁcant beneﬁt. For example, a heuristic that

orders by the number of examples entailed by the best program yet would have no eﬀect

on a data set where all tasks are given a single example. Secondly, wrongly estimating the

importance of size in the evaluation function may signiﬁcantly deter search time by testing

more extensive programs when not necessary. To mitigate this issue, we experiment with a

conservative evaluation function: ﬁrstly, ordering by size and then tie-breaking through our

heuristic.

Given the above considerations, we propose two solutions for this problem: one that orders

tasks by the number of examples currently solved and the other by the number of constraints

generated by the system.

4.4.1 Ordering by number of examples solved

The ﬁrst approach we experiment with is ordering tasks decreasingly by the number of ex-

amples currently solved. We motivate this ﬁnding on the fact that very often, entailing an

example is equivalent to ﬁnding a program that has at least one clause which is part of a

solution.

34

4.4.2 Ordering by number of constraints

The second approach we experiment with is ordering tasks by the number of constraints the

system has generated for them. If the system has generated more constraints for a program it

means that its hypothesis space can be pruned the most. Therefore, we expect this approach

to identify tasks that are closed to being solved.

In Algorithm 6 we provide a generic implementation of the task order approach. It makes use

of a priority queue data structure TPQ, which is initialised with the desired heuristic.

Algorithm 6 Priority searching of solutions

function multipopperprio
for i in range(n) do

rules[i] ← ∅

end for
T P Q ← {(t1, 1, 1.0), (t2, 1, 1.0), .., (tn, 1, 1.0)}
BK ← {BACKGROUND KNOWLEDGE}
S ← {}
while not TPQ is empty do
(t, size, ) ← pop(T P Q)
(partialsol , cons) ← popperpartial(t, BK, size, rules[i])
rules[i] ← rules[i] ∪ cons
if isvalidsol(partialsol ,t) then

S ← S ∪{sol }
BK ← BK ∪ S
ResetPopper(T)
T ← T \ {t}
T P Q ← {(ti, 1, 1.0)|ti ∈ T }

else

if partialsol (cid:54)= null then

priority ← computeprio(sol)
PUSH(T P Q, (t, size + 1, priority))

end if

end if
end while
return S
end function

35

Chapter 5

Experimental Results

The goal of this chapter is to determine the performance of the approaches proposed in the

previous chapter. We will perform experiments in order to obtain answers to the following

questions:

Q1. Does constraint preservation oﬀer an improvement in learning speed for approaches that

repeat searching over the same hypothesis space?

For each strategy mentioned previously, we will evaluate the running time change resulting

from enabling constraint preservation on multiple data sets that present a wide array of

speciﬁc features.

Q2. Do the advantages of resetting search size overcome its disadvantages when compared

to the state-of-the-art approach?

We will compare the two reset strategies with the current state-of-the-art iterative deepening

search approach on data sets that are expected to beneﬁt each method and compare the best

case and worst case results for each algorithm.

Q3. Is there any beneﬁt in heuristically ordering programs on the same size level during a

36

search?

We will compare the two ordering strategies against a system that selects a random ordering

at the beginning of the learning process and respects it throughout each stage. We have chosen

this benchmark in order to remove any bias from a system that takes the given original order,

which may be beneﬁcial/not beneﬁcial.

The scope of this experiment will be to determine if heuristic program ordering is either

beneﬁcial, neutral, or provides a drawback through the added overhead.

5.1 Data sets

Strings transformation. We test our system using an existing data set of string transfor-

mation operations, out of which we select the ones that have been found solvable by Popper

during previous experiments [16].

Robot movement. We generate a set of tasks that focus on robot movement. The goal of

each task is to learn to traverse a large area using only unit length movement instructions.

This task will be used to compare the performance of the reset strategy and state-of-the-art

strategy on a large set of tasks that can all be reduced to a size of three literals in a multi-task

learning setting.

Printer head. We generate a set of tasks that simulate the movement of a printer head over

a piece of paper. The printer head is able to perform one pixel size movements, ﬁll a pixel

with colour or return to an initial position.

This data set is an extension of the robot movement set, which also allows recursion. Instead

of learning to traverse ﬁxed distances, the printer head learns to work on sheets of arbitrary

size.

In Figure 5.1 and Figure 5.2 we show two examples of pixel images used in training the system.

37

Figure 5.1: Zebra pattern image

Figure 5.2: Cross pattern image

5.2 Testing environment

5.2.1 Speciﬁcations

All experiments have been run on Amazon EC2 machines (c6i.large), which have the following

speciﬁcations:

Operating system: Ubuntu 20.04.3 LTS

Software versions:

• Python 3.8.10

• PySwip 0.2.11

• Clingo 5.5.0

• SWI-Prolog 8.4.2

Processor: Intel(R) Xeon(R) Platinum 8375C CPU @ 2.90GHz

Number of cores: 2

Threads per cores: 2

RAM memory: 4 GB

5.2.2 Testing protocol

For all data sets, each strategy was run ten times with a timeout limit of 6000 seconds.

38

Before each run, the ordering of the input tasks is randomly determined. This approach

allows our results to ensure the reliability of our data and provide greater conﬁdence that the

observed performance of the system is consistent.

There are signiﬁcant sources of noise that require experiments to be run multiple times. For

example, some input orderings beneﬁt some systems over others. Furthermore, the Popper

system searches through a hypothesis space in a non-deterministic manner. Therefore, during

diﬀerent runs, speciﬁc tasks can be given diﬀerent deﬁnitions that are not necessarily reusable

in the same contexts.

5.3 Results

5.3.1 Algorithms

In this section, we will deﬁne a list of acronyms for each of our search strategies in order to

make it easier for the reader to interpret the results.

NAIVE is the naive algorithm.

ID is the state-of-the-art, iterative deepening approach.

RESET-ID is the iterative deepening reset approach.

RESET-BFS is the breadth ﬁrst search reset approach.

PRIO-EX is a version of RESET-BFS that sorts tasks on the same level decreasingly by the

number of examples solved.

PRIO-CONS is a version of RESET-BFS that sorts tasks on the same level decreasingly by

the number of constraints discovered.

If any algorithm name is followed by the PRESERVE keyword (e.g. ID PRESERVE), it means

that constraint preservation option has been set true. Otherwise, we assume that constraint

39

preservation has not been used.

Because the breadth ﬁrst search based algorithms perform poorly without constraint preserva-

tion, we will choose always to enable constraint preservation when comparing the performance

of multiple strategies.

5.3.2 Printer head

Overview

In Figure 5.3 we showcase the experimental results for all our algorithms as a percentage of

tasks solved after several minutes. This data set contains many tasks that are solved relatively

early and a few complicated tasks, such we attach an additional plot (see Figure 5.4) that

highlights the behaviour of the strategies in the ﬁrst 100 seconds. We consider that this

metric better describes the performance of the systems because it more clearly showcases

their diﬀerences and removes the redundant noise generated by task ordering in the higher

hypothesis spaces.

80

60

40

20

0

d
e
v
l
o
s

s
k
s
a
t

f
o

e
g
a
t
n
e
c
r
e
P

NAIVE
ID
ID PRESERVE
RESET-ID
RESET-ID PRESERVE
RESET-BFS
RESET-BFS PRESERVE
PRIO-EX
PRIO-EX PRESERVE
PRIO-CONS
PRIO-CONS PRESERVE

0

20

60
40
Minutes

80

100

Figure 5.3: Overview of printer head results (showing standard error)

40

60

50

40

30

20

10

0

d
e
v
l
o
s

s
k
s
a
t

f
o

e
g
a
t
n
e
c
r
e
P

NAIVE
ID
ID PRESERVE
RESET-ID
RESET-ID PRESERVE
RESET-BFS
RESET-BFS PRESERVE
PRIO-EX
PRIO-EX PRESERVE
PRIO-CONS
PRIO-CONS PRESERVE

0

20

40

60
Seconds

80

100

Figure 5.4: Zoom in of printer head results for the ﬁrst 100 seconds (showing standard error)

Algorithm
NAIVE
PRIO-CONS
ID
ID PRESERVE
RESET-ID
RESET-ID PRESERVE
RESET-BFS PRESERVE
PRIO-EX
PRIO-EX PRESERVE
PRIO-CONS PRESERVE
RESET-BFS

Min Max

1
7
11
11
11
11
11
11
11
12
11

9
10
13
13
13
13
13
13
13
13
14

Standard deviation
1.97
1.1
0.7
0.65
0.6
0.62
0.64
0.66
0.63
0.46
0.81

Table 5.1: Printer head algorithms results variance

Question 1

In Figure 5.3 and Figure 5.5 we observe that by enabling the preserve option, all algorithms

consistently outperform their default variants. Therefore, we conclude that the answer for

Q1 is yes. This result conﬁrms our expectation that constraint preservation will result in at

least a minor improvement in all use cases.

41

ID
ID PRESERVE
RESET-ID
RESET-ID PRESERVE
RESET-BFS
RESET-BFS PRESERVE

60

50

40

30

20

10

0

d
e
v
l
o
s

s
k
s
a
t

f
o

e
g
a
t
n
e
c
r
e
P

0

20

40

60
Seconds

80

100

Figure 5.5: Preserve comparison of printer head results for the ﬁrst 100 seconds (showing
standard error)

Question 2

By analysing Figure 5.6 and Figure 5.3 we observe that the reset approaches perform slightly

worse when they have to perform reset operations quite often (solving simple tasks repeatedly),

but end up performing similarly to the state-of-the-art approach in the long run. Therefore,

we determine that the answer for Q2 is no.

Question 3

We do not observe any signiﬁcant beneﬁt of the priority approaches that can not be attributed

to noise. Therefore, we conclude that the answer for Q3 is no. It is worth mentioning that

both priority algorithms compute the most diﬃcult task faster on average than the other

approaches. Their average times to learn 13 tasks are 661 and 671 seconds, whereas the

state-of-the-art approach achieves a mean of 1951 seconds and the best reset approach 1096.

Is it highly likely that these results are a consequence of variation in the initial ordering and

do not reﬂect the actual performance of the search strategies.

42

ID PRESERVE
RESET-ID PRESERVE
RESET-BFS PRESERVE

60

50

40

30

20

10

0

d
e
v
l
o
s

s
k
s
a
t

f
o

e
g
a
t
n
e
c
r
e
P

0

20

40

60
Seconds

80

100

Figure 5.6: Graph comparing state-of-the-art and reset strategies for printer data during the
ﬁrst 100 seconds (showing standard error)

ID PRESERVE
RESET-BFS PRESERVE
PRIO-EX PRESERVE
PRIO-CONS PRESERVE

60

50

40

30

20

10

0

d
e
v
l
o
s

s
k
s
a
t

f
o

e
g
a
t
n
e
c
r
e
P

0

20

40

60
Seconds

80

100

Figure 5.7: Zoom in of printer head results for the ﬁrst 100 seconds (showing standard error)

43

5.3.3 String transformation

Overview

In Figure 5.8 we present an overview of the performance of each algorithm, expressed as the

percentage of tasks solved after several minutes. We also outline the variance in Table 5.2,

by listing their worst and best performances, along with the standard deviation of the total

number of tasks solved.

We observe the fact that no algorithm was able to solve all the tasks. We attribute this to

the fact that we have used functional testing in order to validate if a generated program is

correct, whereas the original experiment did not enable this option. Functional testing refers

to evaluating predicates by disregarding their truth value and only considering their output

[2].

d
e
v
l
o
s

s
k
s
a
t

f
o

e
g
a
t
n
e
c
r
e
P

80

60

40

20

0

NAIVE
ID
ID PRESERVE
RESET-ID
RESET-ID PRESERVE
RESET-BFS
RESET-BFS PRESERVE
PRIO-EX
PRIO-EX PRESERVE
PRIO-CONS
PRIO-CONS PRESERVE

0

20

40
60
Minutes

80

100

Figure 5.8: Overview of string transformation results (showing standard error)

Question 1

For the ﬁrst question, we compare the results of the three main search strategies with the

constraint preservation option both enabled and disabled. The result of the comparison is

44

Algorithm
PRIO-CONS
PRIO-CONS PRESERVE
ID PRESERVE
NAIVE
ID
RESET-BFS
RESET-ID
PRIO-EX
RESET-BFS PRESERVE
PRIO-EX PRESERVE

Min Max
15
13
16
14
19
12
21
0
21
12
38
11
39
13
39
20
40
15
40
35

Standard deviation
0.54
0.83
2.5
6.28
2.45
11.41
9.78
7.87
10.39
1.5

Table 5.2: String transformation algorithms results variance

present in Figure 5.9. We conclude that the answer to Q1 is yes, as all strategies perform at

least as well as their default version when constraint preservation is used.

ID
ID PRESERVE
RESET-ID
RESET-ID PRESERVE
RESET-BFS
RESET-BFS PRESERVE

d
e
v
l
o
s

s
k
s
a
t

f
o

e
g
a
t
n
e
c
r
e
P

80

60

40

20

0

0

20

60
40
Minutes

80

100

Figure 5.9: Graph showing the eﬀects of the preserve option for string data (showing
standard error)

Question 2

In Figure 5.10 we compare the results of the state-of-the-art strategy, versus the two reset

strategies we suggested. Since both reset strategies perform better than the state-of-the-art

approach we conclude that the answer for Q2 is yes.

45

ID PRESERVE
RESET-ID PRESERVE
RESET-BFS PRESERVE

d
e
v
l
o
s

s
k
s
a
t

f
o

e
g
a
t
n
e
c
r
e
P

80

60

40

20

0

0

20

40
60
Minutes

80

100

Figure 5.10: Graph comparing state-of-the-art and reset strategies for string data (showing
standard error)

Question 3

In Figure 5.11 we observe the eﬀect of using a priority ordering for the breadth ﬁrst search

approach. We have also plotted the performance of the state-of-the-art system to reference

as a benchmark. The PRIO-EX algorithm, which sorts by the precision of the best program

found until now, outperforms the original reset approach. On the other hand, the PRIO-

CONS algorithm, which sorts by the number of constraints, exhibits below par performance.

We associate this with the fact that the PRIO-CONS algorithm uses a poor heuristic. Tasks

for which we have accumulated more constraints have a smaller hypothesis space size, but it

is not a good indicator of being closer to a solution. Furthermore, by analysing Table 5.2 we

observe that priority ordering results in a lower variance in the performance of the system.

We consider this a possible upside, as it improves the system’s reliability. We conclude that

the answer for Q3 is yes, but we outline the need for further research in this area, with the

purpose of developing more accurate heuristics.

46

ID PRESERVE
RESET-BFS PRESERVE
PRIO-EX PRESERVE
PRIO-CONS PRESERVE

d
e
v
l
o
s

s
k
s
a
t

f
o

e
g
a
t
n
e
c
r
e
P

80

60

40

20

0

0

20

40
60
Minutes

80

100

Figure 5.11: Graph showing the eﬀects of priority ordering for string data (showing standard
error)

5.3.4 Robot movement

This data set contains single examples for each task because any positive examples generated

would be part of the same equivalence class (e.g. moving two cells to the right is independent of

starting position). Consequently, there would be no beneﬁt in testing the PRIO-EX algorithm

against this data set. Moreover, the previous two data sets have shown that the PRIO-CONS

approach performs poorly in practice. Therefore, we decide to conclude our answer for Q3

based on the previous data and only test our claims for Q1 and Q2 against this data set.

Overview

In Figure 5.12 we present an overview of the performance of each algorithm, expressed as the

percentage of tasks solved after several minutes.

Question 1

By reviewing Figure 5.12, we observe that using constraint preservation has improved the

performance of two out of three of the tested strategies. As expected, RESET-BFS beneﬁts

47

ID
ID PRESERVE
RESET-ID
RESET-ID PRESERVE
RESET-BFS
RESET-BFS PRESERVE

d
e
v
l
o
s

s
k
s
a
t

f
o

e
g
a
t
n
e
c
r
e
P

60

40

20

0

0

20

40
60
Minutes

80

100

Figure 5.12: Overview of robot results (showing standard error)

the most from constraint preservation. On the other hand, the RESET-ID approach performs

slightly worse when constraint preservation is enabled. By manually analysing the results of

the data, we associate this ﬁnding with noise generated by order randomisation. Therefore,

the answer for Q1 is yes.

Question 2

Figure 5.13 showcases a comparison between the state-of-the-art approach and the two reset

strategies. The current state-of-the-art approach solves the ﬁrst few tasks much quicker

because it does not reset the hypothesis space size on each found solution. After the 20

minutes mark, we observe that the state-of-the-art approach stops making progress because

it has reached a large enough search size to be able to ﬁnd any more solutions in a reasonable

time frame. Whereas both reset approaches show that they are making constant progress,

with their learning rate remaining relatively constant1. Although the learning time of the ﬁrst

tasks is lower for the reset strategies, we evaluate that the ability to learn a higher percentage

of tasks is more important when evaluating the performance of a system. Therefore, we

1As mentioned in the introduction, we expect to observe a slight decay in learning rate as more tasks are

added to the BK.

48

ID PRESERVE
RESET-ID PRESERVE
RESET-BFS PRESERVE

conclude that the answer for Q2 is yes.

d
e
v
l
o
s

s
k
s
a
t

f
o

e
g
a
t
n
e
c
r
e
P

60

40

20

0

0

20

40
60
Minutes

80

100

Figure 5.13: Graph comparing state-of-the-art and reset strategies for robot data (showing
standard error)

49

Chapter 6

Conclusions

6.1 Summary

Although an area that has shown high potential, there has been little development in terms of

multi-task learning approaches in ILP. We have experimented with reﬁning the current state-

of-the-art approach with the expectation of obtaining substantially improved performance.

We presented our assumptions’ theoretical basis and then empirically conﬁrmed them against

three data sets. We have implemented both our new approach and the state-of-the-art tech-

nique based on the Popper ILP system. Our experimental results show that (1) constraint

preservation improves learning speed in multi-task settings (yes to Q1), (2) the beneﬁts

of search size reset overcome it’s disadvantages (yes to Q2), and (3) heuristic ordering of

programs can improve learning rate (yes to Q3).

In the following sections, we present the limitations of our work and suggest future work that

could improve the performance of Popper in multi-task environments.

6.2 Limitations

We have identiﬁed multiple factors that restricted the scope of our work.

50

Limited data. The use of multi-task learning is relatively new to the ﬁeld of ILP. Therefore,

we highlight the lack of publicly available data sets used to benchmark such systems. We

believe that our ﬁndings would have been better supported by testing in a wider variety

of data, which have been previously found to uncover more use cases we might not have

considered in our project.

Implementation improvement. Our implementation of multi-task Popper has one spe-

ciﬁc drawback we have encountered during testing. On each reset operation, the underlying

ILP environment is re-initialised, which often results in long reset times. There exists a simple

solution to this issue, which would enforce the system always to preserve constraints between

runs or to iterate through the constraint list and “forget” each of them one by one. Such

an approach would have introduced bias in our experimental results by favouring constraint

preservation. We argue that a more specialised implementation of Popper would circumvent

this problem and further improve learning time (especially for the reset approach, where this

part of the code is called more frequently).

Bias settings. One signiﬁcant challenge in ILP is selecting bias parameters [1]. Examples of

bias parameters are the maximum number of variables allowed in a program or the maximum

number of clauses allowed in a program. Appropriate selection of bias parameters has a

signiﬁcant impact on the learning rate by modifying the size of the possible hypothesis space.

We argue that in the case of multi-task learning, the initial bias, which was set by the user

with the initial BK in mind, may no longer be appropriate. For example, some tasks may

have three clause solutions when solved by themselves, but only two clause solutions in the

multi-task learning environment. Therefore, if our system could automatically compute bias

parameters, it would improve the learning rate by constraining the hypothesis spaces size

when the BK is augmented.

51

6.3 Future work

Explainable results. Without multi-task learning, each program learnt is built from prim-

itives, which are given in the BK and known to a human operator. When multi-task learning

is introduced, program deﬁnitions may also contain other programs. This aﬀects the ability

of a human to understand the programs in two ways. Firstly, we note that, in a multi-task

learning setting, knowledge of all the new predicates that appear in a solution is required

before reading it. Secondly, we outline the fact that it is a common occurrence for more com-

plicated tasks to be selected in favour of simpler tasks when they cannot be diﬀerentiated.

For example see Figure 6.1.

f0(A,B) :- draw1(A,B)
f0(A,B) :- move_right(A,B),f0(A,B)
% When learning a task f1(A,B), such as f1(A,B) :- draw1(A,B)
% A valid solution for f1(A,B) is:
f1(A,B) :- f0(A,B)
% But we expect that a user would prefer the trivial solution:
f1(A,B) :- draw1(A,B)

Figure 6.1: Example of two diﬀerent ways in which a program can be learnt

In the above case, both draw1 and f0 appear to behave identically for the system, in the

absence of negative examples. In consequence, we propose the development of a predicate

translator. A predicate translator would take the output of a multi-task ILP system and

transform it such that all predicates will only make use of deﬁnitions from the BK, and any

clause that does not aﬀect the correctness of the task will be pruned out.

Task ordering.

In this project, we have shown the potential of task ordering in improving

the learning capacity of multi-task ILP systems. We suggest further research in developing

more accurate heuristics to predict which tasks are closer to being solved. One of the solutions

we propose is the use of other Machine Learning techniques in order to identify more manage-

able tasks and give them priority. We also concede the fact that there are certain limitations

52

to the applicability of such an approach, especially when there are very few examples given

for each task.

Parallel computation. When searching for solutions of a speciﬁc size, one could modify

the current approach that attempts to solve tasks sequentially to try and solve multiple tasks

concurrently, in a bag of tasks manner. This method would allow one to vastly increase the

learning rate of multi-task Popper on multi-core systems. Moreover, a signiﬁcant bottleneck

observed during all experiments is that the system got stuck searching for solutions to un-

solvable tasks. This issue will be mitigated, as data sets would require as many high diﬃculty

tasks as threads to congest the system.

53

Bibliography

[1] Hilde Ad´e, Luc De Raedt, and Maurice Bruynooghe. Declarative bias for speciﬁc-to-

general ilp systems. Machine Learning, 20(1):119–154, 1995.

[2] John Ahlgren and Shiu Yin Yuen. Eﬃcient program synthesis using constraint satisfac-

tion in inductive logic programming. The Journal of Machine Learning Research, 14(1):

3649–3682, 2013.

[3] Shai Ben-David and Reba Schuller. Exploiting task relatedness for multiple task learning.

In Learning theory and kernel machines, pages 567–580. Springer, 2003.

[4] Andrew Cropper. Forgetting to learn logic programs. In Proceedings of the AAAI Con-

ference on Artiﬁcial Intelligence, volume 34, pages 3676–3683, 2020.

[5] Andrew Cropper and Rolf Morel. Learning programs by learning from failures, 2020.

[6] Andrew

Cropper

and

Stephen

H. Muggleton.

Metagol

system.

https://github.com/metagol/metagol, 2016.

URL https://github.com/metagol/

metagol.

[7] Andrew Cropper and Stephen H. Muggleton. Learning eﬃcient logic programs. Machine

Learning, 108(7):1063–1083, Jul 2019. ISSN 1573-0565. doi: 10.1007/s10994-018-5712-6.

URL https://doi.org/10.1007/s10994-018-5712-6.

54

[8] Andrew Cropper, Sebastijan Dumanˇci´c, Richard Evans, and Stephen H. Muggleton. In-

ductive logic programming at 30, 2021.

[9] Kevin Ellis, Lucas Morales, Mathias Sabl´e-Meyer, Armando Solar-Lezama, and Josh

Tenenbaum. Learning libraries of subroutines for neurally–guided bayesian program in-

duction. Advances in Neural Information Processing Systems, 31, 2018.

[10] C´esar Ferri-Ram´ırez, Jos´e Hern´andez-Orallo, and M Jos´e Ram´ırez-Quintana. Incremental

learning of functional logic programs. In International Symposium on Functional and

Logic Programming, pages 233–247. Springer, 2001.

[11] Robert Kowalski. Predicate logic as programming language. volume 74, pages 569–574,

01 1974.

[12] Robert A Kowalski. The early years of logic programming. Communications of the ACM,

31(1):38–43, 1988.

[13] Brenden M. Lake, Tomer D. Ullman, Joshua B. Tenenbaum, and Samuel J. Gershman.

Building machines that learn and think like people, 2016.

[14] Dianhuan Lin, Eyal Dechter, Kevin Ellis, Joshua B. Tenenbaum, and Stephen Muggleton.

Bias reformulation for one-shot function induction. In ECAI, 2014.

[15] Tom M. Mitchell. Machine Learning. McGraw-Hill, New York, 1997. ISBN 978-0-07-

042807-2.

[16] Rolf Morel and Andrew Cropper. Learning logic programs by explaining failures, 2021.

URL https://arxiv.org/abs/2102.12551.

[17] Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Transactions

on Knowledge and Data Engineering, 22(10):1345–1359, 2010. doi: 10.1109/TKDE.2009.

191.

55

[18] Dmitrii Pasechnik. Lecture notes in Computer Graphics, February 2021.

[19] Raymond Reiter.

On closed world data bases.

In Bonnie Lynn Webber

and Nils J. Nilsson, editors, Readings in Artiﬁcial Intelligence, pages 119–140.

Morgan Kaufmann, 1981.

ISBN 978-0-934613-03-3.

doi:

https://doi.org/10.

1016/B978-0-934613-03-3.50014-3. URL https://www.sciencedirect.com/science/

article/pii/B9780934613033500143.

[20] Ray J. Solomonoﬀ. A system for incremental learning based on algorithmic probability.

1989.

[21] Ashwin Srinivasan, Ross D. King, and Michael E. Bain. An empirical study of the use of

relevance information in inductive logic programming. J. Mach. Learn. Res., 4:369–383,

dec 2003. ISSN 1532-4435.

[22] Ivan Tyukin, Alexander Gorban, Konstantin Sofeikov, and I. Romanenko. Knowledge

transfer between artiﬁcial intelligence systems. 09 2017.

[23] Joaquin Vanschoren. Meta-learning: A survey. CoRR, abs/1810.03548, 2018. URL

http://arxiv.org/abs/1810.03548.

[24] John Wahlig. Learning logic programs from noisy failures, 2022.

[25] Xin Wang, Yudong Chen, and Wenwu Zhu. A comprehensive survey on curriculum

learning. CoRR, abs/2010.13166, 2020. URL https://arxiv.org/abs/2010.13166.

[26] Karl Weiss, Taghi M Khoshgoftaar, and DingDing Wang. A survey of transfer learning.

Journal of Big data, 3(1):1–40, 2016.

[27] Yu Zhang and Qiang Yang. An overview of multi-task learning. National Science Review,

5(1):30–43, 2018.

56

