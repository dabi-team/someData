1
2
0
2

r
p
A
2

]
I

A
.
s
c
[

1
v
3
9
1
1
0
.
4
0
1
2
:
v
i
X
r
a

Learning Description Logic Ontologies
Five Approaches. Where Do They Stand?

Ana Ozaki

University of Bergen
Department of Informatics
ana.ozaki@uib.no

Abstract. The quest for acquiring a formal representation of the knowl-
edge of a domain of interest has attracted researchers with various back-
grounds into a diverse ﬁeld called ontology learning. We highlight clas-
sical machine learning and data mining approaches that have been pro-
posed for (semi-)automating the creation of description logic (DL) on-
tologies. These are based on association rule mining, formal concept anal-
ysis, inductive logic programming, computational learning theory, and
neural networks. We provide an overview of each approach and how it
has been adapted for dealing with DL ontologies. Finally, we discuss the
beneﬁts and limitations of each of them for learning DL ontologies.

1 Introduction

The quest for acquiring a formal representation of the knowledge of a domain of
interest has attracted researchers with various backgrounds and both practical
and theoretical inquires into a diverse ﬁeld called ontology learning [33, 30]. In
this work, we focus on approaches for building description logic (DL) ontologies
assuming that the vocabulary and the language of the ontology to be created are
known. The main goal is to ﬁnd how the symbols of the vocabulary should be
related, using the logical constructs available in the ontology language. Desirable
goals of an ontology learning process include:

1. the creation of ontologies which are interpretable; expressions should not be

overly complex, redundancies should be avoided;

2. the support for learnability of DL expressions formulated in rich ontology

languages;

3. eﬃcient algorithms for creating ontologies, requiring a small amount of time

and training data;

4. limited or no human intervention requirement;
5. the support for learning in unsupervised settings;
6. handling of inconsistencies and noise.

Other properties such as explainability and trustability may also be relevant
for some approaches. Moreover, once the ontology has been created, it needs to
be checked, be maintained, and evolve. This means that other reasoning tasks
should also be feasible.

 
 
 
 
 
 
Nearly 20 years after the term “ontology learning” was coined by Maedche
and Staab [33], it is not a surprise that no approach could accomplish such am-
bitious and conﬂicting goals. However, diﬀerent approaches have addressed some
of these goals. We highlight ﬁve approaches coming from machine learning and
data mining which have been proposed for (semi-)automating the creation of DL
ontologies. These are based on association rule mining (ARM) [1], formal con-
cept analysis (FCA) [19], inductive logic programming (ILP) [35], computational
learning theory (CLT) [46], and neural networks (NNs) [34].

The adaptations of the approaches to the problem of learning DL ontologies
often come with the same beneﬁts and limitations as the original approach.
To show this eﬀect, for each of the ﬁve approaches, we start by presenting the
original proposal and then explain how it has been adapted for dealing with DL
ontologies. Before presenting them, we introduce some basic notions.

2 Deﬁnitions

Here we present the syntax and semantics of DLs and basic deﬁnitions useful to
formalise learning problems.

2.1 Description Logic Ontologies

We introduce ALC [3], a prototypical DL which features basic ingredients found
in many DL languages. Let NC and NR be countably inﬁnite and disjoint sets of
concept and role names. An ALC ontology (or TBox ) is a ﬁnite set of expressions
of the form C ⊑ D, called concept inclusions (CIs), where C, D are ALC concept
expressions built according to the grammar rule

C, D ::= A | ¬C | C ⊓ D | ∃r.C

with A ∈ NC and r ∈ NR. An EL concept expression is an ALC concept expression
without any occurrence of the negation symbol (¬). An EL TBox is a ﬁnite set
of CIs C ⊑ D, with C, D being EL concept expressions.

The semantics of ALC (and of the EL fragment) is based on interpretations.
An interpretation I is a pair (∆I , ·I ) where ∆I is a non-empty set, called the
domain of I, and ·I is a function mapping each A ∈ NC to a subset AI of ∆I
and each r ∈ NR to a subset rI of ∆I × ∆I. The function ·I extends to arbitrary
ALC concept expressions as follows:

(¬C)I := ∆I \ CI
(C ⊓ D)I := CI ∩ DI

(∃r.C)I := {d ∈ ∆I | ∃e ∈ CI such that (d, e) ∈ rI }

An interpretation I satisﬁes a CI C ⊑ D, in symbols I |= C ⊑ D, iﬀ CI ⊆ DI .
It satisﬁes a TBox T , in symbols I |= T , iﬀ I satisﬁes all CIs in T . A TBox T
entails a CI α, in symbols T |= α, iﬀ all interpretations satisfying T satisfy α.

2.2 Learning Frameworks

By learning we mean the process of acquiring some desired kind of knowledge
represented in a well-deﬁned and machine-processable form. Examples are pieces
of information that characterise such knowledge, given as part of the input of a
learning process. We formalise these relationships as follows.

A learning framework F is a triple (E, L, µ) where E is a set of examples, L
is a set of concept representations1, called hypothesis space, and µ is a function
that maps each element of L to a set of (possibly classiﬁed) examples in E. If
the classiﬁcation is into {1, 0}, representing positive and negative labels, then
µ simply associates elements l of L to all examples labelled with 1 by l. Each
element of L is called a hypothesis. The target representation (here simply called
target ) is a ﬁxed but arbitrary element of L, representing the kind of knowledge
that is aimed for in the learning process.

Example 1. To formalise the problem of learning DL ontologies from entailments,
one can deﬁne the learning framework for a given DL L as (E, L, µ) where E is
the set of all CIs C ⊑ D with C, D being L concept expressions; L is the set
of all L TBoxes; and µ is a function that maps every L TBox T to the set
{C ⊑ D ∈ E | T |= C ⊑ D}. In this case, we consider that C ⊑ D is labelled
with 1 by T iﬀ T |= C ⊑ D.

In the next ﬁve sections, we highlight machine learning and data mining ap-
proaches which have been proposed for (semi-)automating the creation of DL
ontologies. As mentioned, for each approach, we ﬁrst describe the original mo-
tivation and application. Then we describe how it has been adapted for dealing
with DL ontologies.

3 Association Rule Mining

3.1 Original Approach

Association rule mining (ARM) is a data mining method frequently used to
discover patterns, correlations, or causal structures in transaction databases, re-
lational databases, and other information repositories. We provide basic notions,
as it was initially proposed [1].

Deﬁnition 2 (Association Rule). Given a set I = {i1, i2, . . . , in} of items,
and a set D = {t1, t2, . . . , tm} of transactions (called transaction database) with
each ti ⊆ I, an association rule is an expression of the form A ⇒ B where A, B
are sets of items.

1 In the Machine Learning literature, a concept is often deﬁned as a set of examples
and a concept representation is a way of representing such set. This diﬀers from the
notion of a concept in the DL literature and a formal concept in FCA.

Table 1. Transaction Database

ID Product 1 Product 2 Product 3 Product 4

1
2
3
4
5

✓

✓
✓
✓

✓
✓
✓
✓
✓

✓
✓
✓

✓

✓
✓
✓

The task of mining rules is divided into two parts: (i) mining sets of items
which are frequent in the database, and, (ii) generating association rules based
on frequent sets of items. To measure the frequency of a set X of items in a
transaction database D, one uses a measure called support, deﬁned as:

suppD(X) =

|{ti ∈ D : X ⊆ ti}|
|D|

If a set X of items has support larger than a given threshold then it is used in
the search of association rules, which have the form A ⇒ B, with X = A ∪ B.
To decide whether an implication A ⇒ B should be in the output of a solution
to the problem, a conﬁdence measure is used. The conﬁdence of an association
rule A ⇒ B w.r.t. a transaction database D is deﬁned as:

confD(A ⇒ B) =

suppD(A ∪ B)
suppD(A)

Essentially, support measures statistical signiﬁcance, while conﬁdence measures
the ‘strength’ of a rule [1].

We parameterize the ARM learning framework FARM with the conﬁdence
threshold δ ∈ [0, 1] ⊂ R. FARM(δ) is (E, L, µ) where E is the set of all database
transactions D; L is the set of all sets S of association rules; and

µ(S) = {D ∈ E | ∀α ∈ S we have that confD(α) ≥ δ}.

ARM Problem: Given δ and D, let FARM(δ) be (E, L, µ). Find S ∈ L with
D ∈ µ(S).

Example 3. Consider the transaction database in Table 1. It contains 5 transac-
tions. For example, the ﬁrst transaction, t1, has Product1, Product3 and Product4
(ﬁrst row of Table 1). Assume that the support and conﬁdence thresholds are
resp. 60% and 70%. ARM gives the rules: {Product3, Product4} ⇒ {Product1}
(conf. 75%) and {Product2} ⇒ {Product1} (conf. 100%), among others.

3.2 Building DL ontologies

An immediate way of adapting the ARM approach to deal with DL ontologies
is to make the correspondence between a ﬁnite interpretation and a transaction

database. Assume I is a ﬁnite interpretation then the notions of support and
conﬁdence can be adapted to:

suppI (C) =

|CI |
|∆I |

confI (C ⊑ D) =

suppI(C ⊓ D)
suppI (C)

The problem of giving logical meaning to association rules is that it may
happen that C ⊑ D and D ⊑ E have conﬁdence values above a certain threshold
while C ⊑ E does not have a conﬁdence value that is above the threshold, even
though it is a logical consequence of the ﬁrst two CIs [7]. This problem also occurs
in the original ARM approach if the association rules are interpreted as Horn
rules in propositional logic. To see this eﬀect, consider Example 3. We have
that both {Product3, Product4} ⇒ {Product1} and {Product1} ⇒ {Product2}
have conﬁdence 75% but the conﬁdence of {Product3, Product4} ⇒ {Product2}
is only 50%. Another diﬃculty in this adaptation for dealing with DLs is that
the number of CIs with conﬁdence value above a given threshold may be inﬁnite
(consider e.g. EL CIs in an interpretation with a directed cycle) and a ﬁnite set
which implies such CIs may not exist.

The learning framework here is parameterized with a DL L and a conﬁdence
ARM(L, δ) is (E, L, µ) with E the set of all ﬁnite

threshold δ ∈ [0, 1] ⊂ R. Then, FDL
interpretations I; L the set of all L TBoxes T ; and

µ(T ) = {I ∈ E | ∀α ∈ T we have that confI (α) ≥ δ}.

ARM+DL Problem: Given I, L, and δ, let FDL
T ∈ L with I ∈ µ(T ).

ARM(L, δ) be (E, L, µ). Find

ARM is an eﬀective approach for extracting CIs with concept expressions
of ﬁxed length from RDF datasets. Using this technique, e.g., DeputyDirector ⊑
CivilServicePost and MinisterialDepartment ⊑ Department were extracted from
data.gov.uk [48, 14, 47] (see also [43] for expressive DLs with ﬁxed length).

More recently, ARM has been applied to mine relational rules in knowledge
graphs [16]. This approach, born in the ﬁeld of data mining, is relevant for the
task of building DL ontologies, as it can eﬀectively ﬁnd interesting relationships
between concept and role names. However, it lacks support for mining CIs with
existential quantiﬁers on the right-hand side [45].

4 Formal Concept Analysis

4.1 Original Approach

Formal Concept Analysis (FCA) is a mathematical method of data analysis
which describes the relationship between objects and their attributes [19] (see
also [18] for an introduction to this ﬁeld). In FCA, data is represented by formal
contexts describing the relationship between ﬁnite sets of objects and attributes.
The notion of a transaction database (Deﬁnition 2) is similar to the notion of a
formal context (Deﬁnition 4).

Table 2. Formal context

Objects Attribute 1 Attribute 2 Attribute 3

(cid:3)

♥
(cid:13)
♦
△

✓
✓

✓

✓

✓

✓

✓

✓

Deﬁnition 4 (Formal Context). A formal context is a triple (G, M, I), where
G is a set of objects, M is a set of attributes, and I ⊆ G × M is a binary relation
between objects and attributes.

A formal concept is a pair (A, B) consisting of a set A ⊆ G of objects (the
‘extent’) and a set B ⊆ M of attributes (the ‘intent’) such that the extent
consists of all objects that share the given attributes, and the intent consists of
all attributes shared by the given objects. A formal concept (A1, B1) is less or
equal to a formal concept (A2, B2), written (A1, B1) ≤ (A2, B2) iﬀ A1 ⊆ A2.
The set of all formal concepts ordered by ≤ forms a complete lattice.

Example 5. ({♥, ♦}, {Attribute 1, Attribute 2}) is a formal concept in the for-
mal context shown in Table 2.

In FCA, dependencies between attributes are expressed by implications—a
notion similar to the notion of an association rule (Deﬁnition 2). An implication
is an expression of the form B1 → B2 where B1, B2 are sets of attributes. An
implication B1 → B2 holds in a formal context (G, M, I) if every object having
all attributes in B1 also has all attributes in B2. A subset B ⊆ M respects an
implication B1 → B2 if B1 6⊆ B or B2 ⊆ B. An implication i follows from a set
S of implications if any subset of M that respects all implications from S also
respects i. In FCA, one is essentially interested in computing the implications
that hold in a formal context. A set S of implications that hold in a formal
context K is called an implicational base for K if every implication that holds
in K follows from S. Moreover, there should be no redundancies in S (i.e., if
i ∈ S then i does not follow from S \ {i}). Implicational bases are not unique.
A well-studied kind of implicational base (with additional properties) is called
stem (or Duquenne-Guigues) base [25, 18].

The learning framework for FCA is FFCA = (E, L, µ) with E the set of all

formal contexts K; L the set of all implicational bases S; and

µ(S) = {K ∈ E | S is an implicational base for K}.

FCA Problem: Given K, let FFCA be (E, L, µ). Find S ∈ L with K ∈ µ(S).

4.2 Building DL ontologies

Approaches to combine FCA and DL have been addressed by many authors
[42, 5, 4, 7, 41]. A common way of bridging the gap between FCA and DL [10]

is the one that maps a ﬁnite interpretation I = (∆I , ·I) and a ﬁnite set S of
concept expressions into formal context (G, M, I) in such a way that:

– each d ∈ ∆I corresponds to an object o in G;
– each concept expression C ∈ S corresponds to an attribute a in M ; and
– d ∈ CI if, and only if, (o, a) ∈ I.

The notion of an implication is mapped to the notion of a CI in a DL. Just
to give an idea, if the formal context represented by Table 2 is induced by a
DL interpretation then the CI Attribute2 ⊑ Attribute1 would be a candidate
to be added to the ontology. The notion of an implicational base is adapted
as follows. Let I be a ﬁnite interpretation and let L be a DL language with
symbols taken from a ﬁnite vocabulary. An implicational base for I and L [10]
is a non-redundant set T of CIs formulated in L (for short L-CIs) such that for
all L-CIs

– I |= C ⊑ D if, and only if, T |= C ⊑ D.

We parameterize the learning framework FDL

FCA(L)
is (E, L, µ), where E is the set of all ﬁnite interpretations I, L is the set of all
implicational bases T for I ∈ E and L, and

FCA with a DL L. Then, FDL

µ(T )={I ∈ E | T is an implicational base for I and L}.

FCA+DL Problem: Given I and L, let FDL
I ∈ µ(T ).
Similar to the diﬃculty described for the DL adaptation of the ARM approach,
there may be no ﬁnite implicational base for a given interpretation and DL.

FCA(L) be (E, L, µ). Find T ∈ L with

A, B
r

e3

A
e2

r

B
e4

e1

Fig. 1. {A ⊑ ∃r.(A ⊓ B)} is a base for ELrhs [22].

Example 6. Consider the interpretation in Figure 1. An implicational base for
ELrhs—the EL fragment that allows only conjunctions of concept names on the
left-side of CIs—is {A ⊑ ∃r.(A ⊓ B)} [22]. However, if we remove e3 from the
extension of A, B then, for all n ∈ N, the CI A ⊑ ∃rn.⊤ holds and there is no
ELrhs ﬁnite base that can entail all such CIs. More expressive languages can be
useful for the computation of ﬁnite bases. It is known that, for EL with greatest
ﬁxpoints semantics, a ﬁnite implicational base always exists [10].

Classical FCA and ARM assume that all the information about the individu-
als is known and can be represented in a ﬁnite way. A ‘✓’ in a table representing

a formal context means that the attribute holds for the corresponding object and
the absence means that the attribute does not hold. In contrast, DL makes the
‘open-world’ assumption, and so, the absence of information indicates a lack of
knowledge, instead of negation. To deal with the lack of knowledge, the authors
of [5] introduce the notion of a partial context, in which aﬃrmative and nega-
tive information about individuals is given as input and an expert is required to
decide whether a given concept inclusion should hold or not.

The need for a ﬁnite representation of objects and their attributes hinders
the creation of concept inclusions expressing, for instance, that ‘every human
has a parent that is a human’, in symbols

Human ⊑ ∃hasParent.Human

or ‘every natural number has a successor that is a natural number’, where ele-
ments of a model capturing the meaning of the relation are linked by an inﬁnite
chain. This limitation is shared by all approaches which mine CIs from data,
including ARM, but in FCA this diﬃculty is more evident as it requires 100%
of conﬁdence. This problem can be avoided by allowing the system to interact
with an expert who can assert domain knowledge that cannot be conveyed from
the ﬁnite interpretation given as input [42].

5 Inductive Logic Programming

5.1 Original Approach

ILP is an area between logic programming and machine learning [35]. In the gen-
eral setting of ILP, we are given a logical formulation of background knowledge
and some examples classiﬁed into positive and negative [35]. The background
knowledge is often formulated with a logic program—a non-propositional ver-
sion of Horn clauses where all variables in a clause are universally quantiﬁed
within the scope of the entire clause. The goal is to extend the background
knowledge B with a hypothesis H in such a way that all examples in the set of
positive examples can be deduced from the modiﬁed background knowledge and
none of the elements of the set of negative examples can be deduced from it.

We introduce the syntax of function-free ﬁrst-order Horn clauses. A term t
is either a variable or a constant. An atom is an expression of the form P (~t)
with P a predicate and ~t a list of terms t1, . . . , ta where a is the arity of P . An
atom is ground if all terms occurring in it are constants. A literal is an atom α
or its negation ¬α. A ﬁrst-order clause is a universally quantiﬁed disjunction of
literals. It is called Horn if it has at most one positive literal. A Horn expression
is a set of (ﬁrst-order) Horn clauses. A classiﬁed example in this setting is a pair
(e, ℓ(e)) where e is a ground atom and ℓ(e) (the label of e) is 1 if e is a positive
example or 0 if it is negative.

Deﬁnition 7 (Correct Hypothesis). Let B be a Horn expression and S a set
of pairs (e, ℓ(e)) with e a ground atom and ℓ(e) ∈ {1, 0}. A Horn expression H
is a correct hypothesis for B and S if

∀(e, 1) ∈ S, B ∪ H |= e and ∀(e, 0) ∈ S, B ∪ H 6|= e.

Table 3. Background knowledge and classiﬁed examples

Background Knowledge
∀x(MedicalDomain(x) → Domain(x))
Person(John), MedicalDomain(Allergy)
isExpert(John, Allergy)

Classiﬁed Examples
(DomainExpert(John), 1)
(DomainExpert(Allergy), 0)

Example 8. Suppose that we are given as input the background knowledge B 2
and a set S of classiﬁed examples presented in Table 3. In this example, one
might conjecture a hypothesis H which states that:

∀xy(isExpert(x, y) ∧ Domain(y) → DomainExpert(x)).

This form of inference is not sound in the logical sense since H does not
necessarily follow from B and S. Another hypothesis considered as correct by
this approach would be

∀x(Person(x) → DomainExpert(x)),

even though one could easily think of an interpretation with a person not being
a domain expert. One could also create a situation in which there are inﬁnitely
many hypotheses suitable to explain the positive and negative examples. For
this reason, it is often required a non-logical constraint to justify the choice of
a particular hypothesis [35]. A common principle is the Occam’s razor principle
which says that the simplest hypothesis is the most likely to be correct (simplicity
can be understood in various ways, a naive way is to consider the length of the
Horn expression as a string).

We parameterize the learning framework for ILP with the background knowl-
edge B, given as part of the input of the problem. We then have that FILP(B) is
the learning framework (E, L, µ) with E the set of all ground atoms; L the set of
all Horn expressions H; and

µ(H) = {e ∈ E | B ∪ H |= e}.

Classiﬁed examples help to distinguish a target unknown logical theory for-
mulated as a Horn expression from other Horn expressions in the hypothesis
space. In the learning framework FILP(B), positive examples for a Horn expres-
sion H are those entailed by the union of H and the background theory B.

ILP Problem: Given B and S (as in Deﬁnition 7), let FILP(B) be (E, L, µ). Find
H ∈ L such that H is a correct (and simple) hypothesis for B and S. That is,
for all (e, ℓ(e)) ∈ S, e ∈ µ(H) iﬀ ℓ(e) = 1.

2 We use the equivalent representation of Horn clauses as implications.

5.2 Building DL Ontologies

In the DL context, ILP has been applied for learning DL concept expressions [12,
13, 21, 26, 29, 27] and for learning logical rules for ontologies [31]. We describe
here the problem setting for learning DL concept expressions, which can help
the designer to formulate the concept expressions in an ontology. As in the
classical ILP approach, the learner receives as input some background knowledge,
formulated as a knowledge base K = (T , A), where T is a TBox and A is a set of
assertions, that is, expressions of the form A(a), r(a, b) where A ∈ NC, r ∈ NR,
and a, b are taken from a set NI of individual names. Assertions can be seen as
ground atoms and A, in DL terms, is called an ABox. A set S of pairs (e, ℓ(e))
with e an assertion and ℓ(e) ∈ {1, 0} is also given as part of the input. In the
mentioned works, e is of the form Target(a), with Target a concept name in NC
not occurring in K and a ∈ NI.

As in the original ILP approach, given K = (T , A) and S, a concept expres-
sion C (in the chosen DL) is correct for K and S if, for all (Target(a), ℓ(Target(a))) ∈
S, we have that (T ∪ {Target ≡ C}, A) |= Target(a) iﬀ ℓ(Target(a)) = 1.

Example 9. The background knowledge in Table 3 can be translated into (T , A),
with

T = {MedicalDomain ⊑ Domain}

and A the set of ground atoms given as background knowledge in Table 3. As-
suming that the target concept name is DomainExpert and the set S of clas-
siﬁed examples is the one in Table 3, correct concept expressions would be
∃isExpert.Domain and Person.

The learning framework and problem statement presented here is for learning
ALC and EL concept expressions based on the ILP approach [28, 29]. Here the
learning framework is parameterized by a knowledge base (T , A) and a DL L.
Then, FDL
ILP((T , A), L) is (E, L, µ) where E is the set of all ground atoms; L is the
set of all L concept expressions C such that Target does not occur in it; and

µ(C) = {e ∈ E | (T ∪ {Target ≡ C}, A) |= e}.

ILP+DL Problem: Given K, L, and S (the classiﬁed examples), let FDL
ILP(K, L)
be (E, L, µ). Find C ∈ L such that C is correct (and simple) for K and S. That
is, for all (e, ℓ(e)) ∈ S, e ∈ µ(C) iﬀ ℓ(e) = 1.

6 Learning Theory

6.1 Original Approach

We describe two classical learning models in CLT which have been applied for
learning DL concept expressions and ontologies. We start with the classical PAC
learning model and then describe the exact learning model3.
3 The expression “Probably Approximately Correct” was coined by Angluin in the

paper [2], where she shows the connection between the two learning models.

In the PAC learning model, a learner receives classiﬁed examples drawn ac-
cording to a probability distribution and attempts to create a hypothesis that
approximates the target. The aim is to bound the probability that a hypothe-
sis constructed by the learner misclassiﬁes an example. This approach can be
applied to any learning framework. Within this model, one can investigate the
complexity of learning an abstract target, such as a DL concept, an ontology, or
the weights of a NN.

We now formalise this model. Let F = (E, L, µ) be a learning framework. A
probability distribution D over E is a function mapping events in a σ-algebra E
of subsets of E to [0, 1] ⊂ R such that D(Si∈I Xi) = Pi∈I D(Xi) for mutually
exclusive Xi, where I is a countable set of indices, Xi ∈ E, and D(E) = 1.
Given a target t ∈ L, let EXD
F,t be the oracle that takes no input, and outputs a
classiﬁed example (e, ℓt(e)), where e ∈ E is sampled according to the probability
distribution D, ℓt(e) = 1, if e ∈ µ(t), and ℓt(e) = 0, otherwise. An example query
is a call to the oracle EXD
F,t is a (multi-)set of
indexed classiﬁed examples, independently and identically distributed according
to D, sampled by calling EXD

F,t. A sample generated by EXD

A learning framework F is PAC learnable if there is a function f : (0, 1)2 →
N and a deterministic algorithm such that, for every ǫ, δ ∈ (0, 1) ⊂ R, every
probability distribution D on E, and every target t ∈ L, given a sample of size
m ≥ f (ǫ, δ) generated by EXD
F,t, the algorithm always halts and outputs h ∈ L
such that with probability at least (1 − δ) over the choice of m examples in E,
we have that D(µ(h) ⊕ µ(t)) ≤ ǫ. If the number of computation steps used by
the algorithm is bounded by a polynomial function p(|t|, |e|, 1/ǫ, 1/δ), where e is
the largest example in the sample generated by EXD
F,t, then F is PAC learnable
in polynomial time.
Example 10. Let E = {(cid:3), ♥, (cid:13), ♦, △} and let D be a probability distribution
on E, deﬁned, e.g., by the pairs

F,t.

({(cid:3)}, 0.2), ({♥}, 0.1), ({(cid:13)}, 0.3), ({♦}, 0.2), ({△}, 0.2).

Assume h, t ∈ L, µ(h) = {♥, (cid:13)}, and µ(t) = {♥, △}. Then, the probability
D(µ(h) ⊕ µ(t)) that h misclassiﬁes an example according to D is 0.5.

PAC Problem: Given a learning framework decide whether it is PAC learnable
in polynomial time.

In the classical PAC approach, the probability distribution D is unknown to
the learner. The algorithm should provide a probabilistic bound for any possible
D. We now describe the exact learning model. In this model, a learner tries to
identify an abstract target known by a teacher, also called an oracle, by inter-
acting with the teacher [2]. The most successful protocol is based on membership
and equivalence queries. As it happens with the PAC learning model, this model
can be used to formulate learning problems within the context of any kind of
learning framework.

We formalise these notions as follows. Given a learning framework F =
(E, L, µ), we are interested in the exact identiﬁcation of a target concept rep-
resentation t ∈ L by posing queries to oracles. Let MQF,t be the oracle that

takes as input some e ∈ E and returns ‘yes’ if e ∈ µ(t) and ‘no’ otherwise. A
membership query is a call to the oracle MQF,t. For every t ∈ L, we denote by
EQF,t the oracle that takes as input a hypothesis concept representation h ∈ L
and returns ‘yes’ if µ(h) = µ(t) and a counterexample e ∈ µ(h) ⊕ µ(t) otherwise,
where ⊕ denotes the symmetric set diﬀerence. There is no assumption regarding
which counterexample in µ(h) ⊕ µ(t) is chosen by the oracle. An equivalence
query is a call to the oracle EQF,t. In this model, if examples are interpretations
or entailments, the notion of ‘equivalence’ coincides with logical equivalence.

A learning framework F is exactly learnable if there is a deterministic algo-
rithm such that, for every t ∈ L, it eventually halts and outputs some h ∈ L with
µ(h) = µ(t). Such algorithm is allowed to call the oracles MQF,t and EQF,t. If the
number of computation steps used by the algorithm is bounded by a polynomial
p(|t|, |e|), where t ∈ L is the target and e ∈ E is the largest counterexample seen
so far, then F is exactly learnable in polynomial time.

Exact Problem: Given a learning framework decide whether it is exactly learn-
able in polynomial time.

In Theorem 11, we recall an interesting connection between the exact learn-
ing model and the PAC model extended with membership queries. If there is a
polynomial time algorithm for a learning framework F that is allowed to make
membership queries then F is PAC learnable with membership queries in poly-
nomial time.

Theorem 11. [2] If a learning framework is exactly learnable in polynomial
time then it is PAC learnable with membership queries in polynomial time. If
only equivalence queries are used then it is PAC learnable (without membership
queries) in polynomial time.

The converse of Theorem 11 does not hold [6]. That is, there is a learning
framework that is PAC learnable in polynomial time (even without membership
queries) but not exactly learnable in polynomial time.

6.2 Building DL Ontologies

The PAC learning model has been already applied to learn DL concept expres-
sions formulated in DL CLASSIC [9, 15] (see also [36]). The main diﬃculty in
adapting the PAC approach for learning DL ontologies is the complexity of this
task. In the PAC learning model, one is normally interested in polynomial time
complexity, however, many DLs, such as ALC, have superpolynomial time com-
plexity for the entailment problem and entailment checks are often important to
combine the information present in the classiﬁed examples.

It has been shown that the EL fragments ELlhs and ELrhs—the EL fragments
that allow only conjunctions of concept names on the right-side and on the
left-side of CIs, respectively—are polynomial time exactly learnable from en-
tailments [23, 24, 38, 37]4, however, this is not the case for EL. The learning
4 The result for ELrhs (allowing conjunctions of concept names on the left-side of CIs)

appears in [23, Section 4]

framework is the one in Example 1 and the problem statement is the same as
in the original approach. By Theorem 11, the results for ELlhs and ELrhs are
transferable to the PAC learning model extended with membership queries. The
results show how changes in the ontology language can impact the complexity
of searching for a suitable ontology in the hypothesis space. The main diﬃculty
of implementing this model is that it is based on oracles, in particular, on an
equivalence query oracle. Fortunately, as already mentioned, such equivalence
queries can be simulated by the sampling oracle of the PAC learning model to
achieve PAC learnability (Theorem 11)[2].

7 Neural Networks

7.1 Original Approach

NNs are widespread architectures inspired by the structure of the brain [34].
They may diﬀer from each other not only regarding their weight and activation
functions but also structurally, e.g., feed-forward NNs are acyclic while recurrent
NNs have cycles. One of the simplest models is the one given by Deﬁnition 12.

Deﬁnition 12 (Neural Network). An NN is a triple (G, σ, w) where G =
(V, E) is a graph, with V a set of nodes, called neurons, and E ⊆ V × V a set
of (directed) edges; σ : R → R is the activation function; and w : E → R is the
weight function.

Other parameters that can be part of the deﬁnition of an NN are the propa-
gation function and biases. A widely used propagation function is the weighted
sum. The propagation function speciﬁes how the outputs of the neurons con-
nected to a neuron n are combined to form the input of n. Given an input to a
neuron, the activation function maps it to the output of the neuron. In symbols,
the input in(n) of a neuron n is

X
m:(m,n)∈E

σ(in(m)) · w((m, n)).

The structure of an NN is organized in layers, basically, an input, an output,
and (possibly several) hidden layers. The input of an NN is a vector of numbers
in R, given as input to the neurons in the input layer. The output of the NN is
also a vector of numbers in R, constructed using the outputs of the neurons in
the output layer. The dimensionality of the input and output of an NN varies
according to the learning task. One can then see an NN as a function mapping
an input vector ~x to an output vector ~y. In symbols, (G, σ, w)(~x) = ~y.

The main task is to ﬁnd a weight function that minimizes the risk of the NN
N , modelled by a function LD(N ), with D a probability distribution on a set
of pairs (~x, ~y) of input/output vectors [44]. The risk of an NN represents how
well we expect the NN to perform while predicting the classiﬁcation of unseen
examples.

The learning framework can be deﬁned in various ways. Here we parameterize
it by a graph structure and an activation function σ. We have that FNN(G, σ),
with G = (V, E), is (E, L, µ) where E is a set of pairs (~x, ~y) representing input
and output vectors of numbers in R (respectively, and with appropriate dimen-
sionality); L is the set of all weight functions w : E → R; and

µ(w) = {(~x, ~y) ∈ E | (G, σ, w)(~x) = ~y}.

One can formulate the NN problem as follows.

NN Problem: Given G and σ, let FNN(G, σ) be (E, L, µ). Find w ∈ L that
minimizes the risk LD(N ) of N = (G, σ, w), where D is a ﬁxed but arbitrary
and unknown probability distribution on E.

Classiﬁed examples for training and validation can be obtained by calling
the sampling oracle EXD
F,t from Section 6), where t ∈ L is the
(unknown) target weight function. One of the main challenges of this approach
is that ﬁnding an optimal weight function is computationally hard. Most works
apply a heuristic search based on the gradient descent algorithm [44].

F,t (recall EXD

7.2 Building DL Ontologies

NNs have been applied to learn CIs from sentences expressing deﬁnitions, called
deﬁnitorial sentences [39] (see also [32] for more work on deﬁnitorial sentences
in a DL context, and, e.g. [8, 50], for work on learning assertions based on NNs).
More speciﬁcally, the work on [39] is based on recurrent NNs, which are useful
to process sequential data. The structure of the NN, in this case, takes the form
of a grid. The authors learn ALCQ CIs, where ALCQ is the extension of ALC
with qualiﬁed number restrictions. For example, “A car is a motor vehicle that
has 4 tires and transport people.” corresponds to

Car ⊑ MotorVehicle ⊓ = 4has.Tires ⊓ ∃transport.People.

The main beneﬁts of this approach is that NNs can deal with natural language
variability. The authors provide an end-to-end solution that does not even require
natural language processing techniques. However, the approach is based on the
syntax of the sentences, not on their semantics, and they cannot capture portions
of knowledge across diﬀerent sentences [39]. Another diﬃculty of adapting this
approach for learning DL ontologies is the lack of datasets available for training.
Such dataset should consist of a large set of pairs of deﬁnitorial sentences and
their corresponding CI. The authors created a synthetic dataset to perform their
experiments.

The learning framework and problem statement for learning DL CIs based
on the NN approach [39] can be formulated as follows. The learning framework
for a DL L can be deﬁned as FDL
NN(G, σ, L) = (E, L, µ) where E is a set of pairs
(~x, ~y) with ~x a vector representation of a deﬁnitorial sentence and ~y a vector
representation of an L CI; and L and µ are as in the original NN approach.

NN+DL Problem: Given G, L and σ, let FDL
NN(G, σ, L) be (E, L, µ). Find w ∈ L
that minimizes the risk LD(N ) of N = (G, σ, w), where D is a ﬁxed but arbitrary
and unknown probability distribution on E.

8 Where Do They Stand?

We now discuss the main beneﬁts and limitations of ARM, FCA, ILP, CLT, and
NNs for building DL ontologies, considering the goals listed in the Introduction.

Interpretability. refers to the easiness of understanding the learned DL ontol-
ogy/concept expressions and obtaining insights about the domain. In ARM, the
requirement for computing CIs with high support often results in highly inter-
pretable CIs (at the cost of ﬁxing the length of concept expressions). The FCA
approach classically deals with redundancies, which is often not considered in
ARM approaches. However, the CIs generated with this approach can be diﬃcult
to interpret [7]. The ILP approach follows the Occam’s razor principle, which
contributes to the generation of interpretable DL expressions, although there is
no guarantee for the quality of the approximation. Such guarantees can be found
in CLT, where the goal is to approximate or exactly identify the target. How-
ever, the focus of these approaches is on accuracy rather than interpretability.
Regarding NNs, the complex models can deal with high variability in the data
but may lose on interpretability.

Expressivity. refers to the expressivity of the DL language supported by the
learning process. As we have seen, many previous approaches for learning DL
ontologies focus on Horn fragments such as EL [23, 24, 11, 28, 4, 7] (or Horn-
like fragments such as FLE [42]). Non-horn fragments have been investigated for
learning DL ontologies [48, 43] and concept expressions [13, 21, 29] (ﬁxing the
length of concept expressions). As mentioned, ALCQ CIs can be learned with
NNs [39] (see also [51]).

Eﬃciency. refers to the amount of time and memory consumed by algorithms in
order to build a DL ontology (or concept expressions) in the context of a partic-
ular approach or a learning model. In CLT one can formally establish complexity
results for learning problems. In ARM the search space is heavily constrained
by the support function, which means that usually large portions of the search
space can be eliminated in this approach. The Next-closure algorithm used in
FCA is polynomial in the output and has polynomial delay, meaning that from
the theoretical point of view it has interesting properties regarding eﬃciency.
However, in practice, there may be diﬃculties in processing large portions of
data provenient of knowledge graphs, such as DBpedia [7].

Human interactions. may be required to complete the information given as
input or to validate the knowledge that cannot be represented in a ﬁnite dataset
or in a ﬁnite interpretation (recall the case of an inﬁnite chain of objects in
Subsection 4.2). Since the input is simply a database or an interpretation, the
ARM and FCA approaches require limited or no human intervention. It is worth

to point out that some DL adaptations of the FCA approach depend on an
expert which resembles a membership oracle. The diﬀerence is that in the exact
learning model the membership oracle answers with ‘yes’ or ‘no’, whereas in
FCA the oracle also provides a counterexample if the answer is ‘no’ [42]. In ILP,
examples need to be classiﬁed into positive and negative, which may require
human intervention to classify the examples before learning takes place. The
same happens with the CLT models presented. The exact learning model is
purely based on interactions with an oracle, which can be an expert (or even a
neural network [49]).

Unsupervised learning. is supported by the ARM and FCA approaches, as
well as some NNs (but not by the DL adaptation we have seen in the litera-
ture [39]). As already mentioned, the approaches based on ILP and CLT fall in
the supervised setting. That is, examples receive some sort of (usually binary)
classiﬁcation.

Inconsistencies and noise. are often present in the data. The ARM approach
deals with them by only requiring that the conﬁdence of the CI is above a
certain threshold (instead of requiring that the CI is fully satisﬁed, as in FCA).
ILP and CLT classically do not support inconsistencies and noise, though, the
PAC model has an agnostic version in which it may not be possible to construct a
hypothesis consistent with the positive and negative examples (due e.g. to noise
in the classiﬁcation). NNs can deal very well with data variability, including
cases in which there are inconsistencies and noise.

9 Conclusion

We discussed beneﬁts and limitations of, namely, ARM, FCA, ILP, CLT, and
NNs for DL settings. Not many authors have applied NNs for learning DL on-
tologies (when the focus is on building the logical expressions), even though
NNs are widespread in many areas. We believe that more works exploring this
approach are yet to come. One of the challenges is how to capture the seman-
tics of the domain. Promising frameworks for capturing the semantics of logical
expressions [17, 40] and modelling logical rules [20] have been recently proposed.
Finally, we have seen that each approach addresses some of the desired prop-
erties of an ontology learning process. An interesting question is whether they
can be combined so as to obtain the best of each approach. Indeed, recent works
have proposed ways of combining FCA with the exact and PAC learning mod-
els [36]. Moreover, the support and conﬁdence measures from ARM could also
be applied in FCA for dealing with noisy and incomplete data [7].

Acknowledgements. This work is supported by the Free University of Bozen-
Bolzano through the projects PACO and MLEARN.

Bibliography

[1] Agrawal, R., Imieliński, T., Swami, A.: Mining association rules between
sets of items in large databases. Special Interest Group on Management Of
Data SIGMOD 22(2), 207–216 (1993)

[2] Angluin, D.: Queries and concept learning. Machine Learning 2(4), 319–342

(1988)

[3] Baader, F., Calvanese, D., McGuinness, D., Nardi, D., Patel-Schneider, P.
(eds.): The Description Logic Handbook: Theory, Implementation, and Ap-
plications, second edn. Cambridge University Press (2007)

[4] Baader, F., Distel, F.: Exploring ﬁnite models in the description logic. In:

ICFCA, pp. 146–161 (2009)

[5] Baader, F., Ganter, B., Sertkaya, B., Sattler, U.: Completing description
logic knowledge bases using formal concept analysis. In: IJCAI, vol. 7, pp.
230–235 (2007)

[6] Blum, A.L.: Separating distribution-free and mistake-bound learning mod-

els over the boolean domain. SIAM J. Comput. 23(5) (1994)

[7] Borchmann, D., Distel, F.: Mining of EL-GCIs. In: The 11th IEEE Interna-
tional Conference on Data Mining Workshops. Vancouver, Canada (2011)
[8] Bordes, A., Usunier, N., García-Durán, A., Weston, J., Yakhnenko, O.:
Translating embeddings for modeling multi-relational data. In: Advances
in Neural Information Processing Systems. NeurIPS, pp. 2787–2795 (2013)
[9] Cohen, W.W., Hirsh, H.: Learning the CLASSIC description logic: Theo-

retical and experimental results. In: KR, pp. 121–133 (1994)

[10] Distel, F.: Learning description logic knowledge bases from data using meth-
ods from formal concept analysis. Ph.D. thesis, Dresden University of Tech-
nology (2011)

[11] Duarte, M.R.C., Konev, B., Ozaki, A.: Exactlearner: A tool for exact learn-

ing of EL ontologies. In: KR, pp. 409–414 (2018)

[12] Funk, M., Jung, J.C., Lutz, C., Pulcini, H., Wolter, F.: Learning description
logic concepts: When can positive and negative examples be separated? In:
IJCAI, pp. 1682–1688 (2019)

[13] Fanizzi, N., d’Amato, C., Esposito, F.: DL-FOIL concept learning in de-

scription logics. In: ILP, pp. 107–121 (2008)

[14] Fleischhacker, D., Völker, J., Stuckenschmidt, H.: Mining RDF data for
property axioms. In: On the Move to Meaningful Internet Systems: OTM
2012, pp. 718–735. Springer (2012)

[15] Frazier, M., Pitt, L.: Classic learning. Machine Learning 25(2-3), 151–193

(1996)

[16] Galárraga, L., Teﬂioudi, C., Hose, K., Suchanek, F.M.: Fast rule mining in
ontological knowledge bases with AMIE+. VLDB J. 24(6), 707–730 (2015)
[17] Galliani, P., Kutz, O., Porello, D., Righetti G., and Troquard, N.: On Knowl-
edge Dependence in Weighted Description Logic In: GCAI, pp. 68–80 (2019)

[18] Ganter, B., Rudolph, S., Stumme, G.: Explaining data with formal concept

analysis. In: RW, pp. 153–195 (2019)

[19] Ganter, B., Wille, R.: Formal Concept Analysis: Mathematical Foundations.

Springer (1997)

[20] Gutiérrez-Basulto, V., Schockaert, S.: From knowledge graph embedding to
ontology embedding? an analysis of the compatibility between vector space
representations and rules. In: KR, pp. 379–388 (2018)

[21] Iannone, L., Palmisano, I., Fanizzi, N.: An algorithm based on counterfac-
tuals for concept learning in the semantic web. Appl. Intell. 26, 139–159
(2007)

[22] Klarman, S., Britz, K.: Ontology learning from interpretations in lightweight

description logics. In: ILP (2015)

[23] Konev, B., Lutz, C., Ozaki, A., Wolter, F.: Exact learning of lightweight

description logic ontologies. JMLR 18(201), 1–63 (2018)

[24] Konev, B., Ozaki, A., Wolter, F.: A model for learning description logic
ontologies based on exact learning. In: AAAI, pp. 1008–1015 (2016)
[25] L., G.J., V., D.: Familles minimales d’implications informatives résultant
d’un tableau de données binaires. Mathématiques et Sciences Humaines
95, 5–18 (1986)

[26] Lehmann, J.: DL-learner: learning concepts in description logics. JMLR 10,

2639–2642 (2009)

[27] Lehmann, J.: Learning OWL class expressions, vol. 6. IOS Press (2010)
[28] Lehmann, J., Haase, C.: Ideal downward reﬁnement in the EL description

logic. In: ILP, pp. 73–87 (2009)

[29] Lehmann, J., Hitzler, P.: Concept learning in description logics using re-

ﬁnement operators. Machine Learning 78(1-2), 203–250 (2010)

[30] Lehmann, J., Völker, J.: Perspectives on Ontology Learning, vol. 18. IOS

Press (2014)

[31] Lisi, F.A.: Al-quin: An onto-relational learning system for semantic web

mining. Int. J. Semantic Web Inf. Syst. 7, 1–22 (2011)

[32] Ma, Y., Distel, F.: Learning formal deﬁnitions for Snomed CT from text.

In: AIME, pp. 73–77 (2013)

[33] Maedche, A., Staab, S.: Ontology learning for the semantic web.

IEEE

Intelligent Systems 16, 72–79 (2001)

[34] McCulloch, W.S., Pitts, W.: A logical calculus of the ideas immanent in
nervous activity. In: Neurocomputing: Foundations of Research, pp. 15–27.
MIT Press (1988)

[35] Muggleton, S.: Inductive logic programming. New generation computing

8(4), 295–318 (1991)

[36] Obiedkov, S., Sertkaya, B., Zolotukhin, D.: Probably approximately correct

completion of description logic knowledge bases. In: DL, (2019)

[37] Ozaki, A.: On the Complexity of Learning Description Logic Ontologies In:

RW, (2020)

[38] Ozaki, A., Persia, C., Mazzullo, A.: Learning Query Inseparable ELH On-

tologies In: AAAI, (2020)

[39] Petrucci, G., Ghidini, C., Rospocher, M.: Ontology learning in the deep. In:

EKAW, pp. 480–495 (2016)

[40] Porello, D., Kutz, O., Righetti, G., Troquard, N., Galliani, P., Masolo, C.: A
Toothful of Concepts: Towards a Theory of Weighted Concept Combination.
In: DL (2019)

[41] Guimarães, R., Ozaki, A., Persia, C., Sertkaya, B.: Mining EL Bases with

Adaptable Role Depth. In: AAAI, (to appear) (2021)

[42] Rudolph, S.: Exploring relational structures via FLE. In: ICCS. Springer

(2004)

[43] Sazonau, V., Sattler, U.: Mining hypotheses from data in OWL: advanced
evaluation and complete construction. In: ISWC, pp. 577–593 (2017)
[44] Shalev-Shwartz, S., Ben-David, S.: Understanding machine learning: From

theory to algorithms. Cambridge university press (2014)

[45] Stepanova, D., Gad-Elrab, M.H., Ho, V.T.: Rule induction and reasoning

over knowledge graphs. In: RW, pp. 142–172 (2018)

[46] Valiant, L.G.: A theory of the learnable. Commun. ACM 27(11), 1134–1142

(1984)

[47] Völker, J., Fleischhacker, D., Stuckenschmidt, H.: Automatic acquisition of

class disjointness. Journal of Web Semantics 35, 124–139 (2015)

[48] Völker, J., Niepert, M.: Statistical schema induction.

In: The Semantic

Web: Research and Applications, pp. 124–138. Springer (2011)

[49] Weiss, G., Goldberg, Y., Yahav, E.: Extracting automata from recurrent
neural networks using queries and counterexamples. In: Proceedings of the
35th International Conference on Machine Learning, ICML 2018, Stock-
holmsmässan, Stockholm, Sweden, July 10-15, 2018, pp. 5244–5253 (2018)
[50] Yang, B., Yih, W., He, X., Gao, J., Deng, L.: Embedding entities and rela-
tions for learning and inference in knowledge bases. In: ICLR (2015)
[51] Zhu, M., Gao, Z., Pan, J.Z., Zhao, Y., Xu, Y., Quan, Z.: Tbox learning
from incomplete data by inference in belnet+. Knowl.-Based Syst. 75, 30–
40 (2015)

