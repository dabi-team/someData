1
2
0
2

v
o
N
1

]
S
M

.
s
c
[

1
v
5
4
9
0
0
.
1
1
1
2
:
v
i
X
r
a

Escaping the abstraction: a foreign function interface
for the Uniﬁed Form Language [UFL]

Nacime Bouziani
Department of Mathematics
Imperial College London
London, UK
n.bouziani18@imperial.ac.uk

David A. Ham
Department of Mathematics
Imperial College London
London, UK
david.ham@imperial.ac.uk

Abstract

High level domain speciﬁc languages for the ﬁnite element method underpin high
productivity programming environments for simulations based on partial differen-
tial equations (PDE) while employing automatic code generation to achieve high
performance. However, a limitation of this approach is that it does not support
operators that are not directly expressible in the vector calculus. This is critical
in applications where PDEs are not enough to accurately describe the physical
problem of interest. The use of deep learning techniques have become increas-
ingly popular in ﬁlling this knowledge gap, for example to include features not
represented in the differential equations, or closures for unresolved spatiotemporal
scales. We introduce an interface within the Firedrake ﬁnite element system that
enables a seamless interface with deep learning models. This new feature composes
with the automatic differentiation capabilities of Firedrake, enabling the automated
solution of inverse problems. Our implementation interfaces with PyTorch and can
be extended to other machine learning libraries. The resulting framework supports
complex models coupling PDEs and deep learning whilst maintaining separation
of concerns between application scientists and software experts.

1

Introduction

The design of efﬁcient and composable software relying on high-level languages and automatic
differentiation (AD) tools is a major and rapidly growing aspect of modern scientiﬁc computing and
is of great interest for the machine learning (ML) community. The development of such software
requires a vast range of knowledge spanning several disciplines, ranging from applications expertise
to mathematical analysis to high performance computing and low-level code optimisation. Software
projects relying on automatic code generation have grown in prominence, as their design enables a
separation of concerns, increases productivity, and facilitates the collaboration between scientists
with different specialisations. Examples of such projects include: Firedrake [22], FEniCS [16] and
FreeFEM++ [11], in the domain of ﬁnite element methods (FEM); and the ML frameworks PyTorch
[20], TensorFlow [1], Theano [25] and MXNet [7]. The Uniﬁed Form Language (UFL) [3] is a
domain speciﬁc language (DSL) embedded in Python for the ﬁnite element method forming the
mathematical programming interface of the Firedrake and FEniCS ﬁnite element systems. UFL equips
Firedrake and FEniCS with a highly expressive interface to specify the variational forms of PDEs
and discrete function spaces, providing the abstractions needed for code generation. Finite element
problems are solved using gradient-based methods to minimise the problem residual. Consequently,
UFL is a fully differentiable language, with inbuilt automatic differentiation.

Domain-speciﬁc languages for PDEs are by deﬁnition very speciﬁc to partial differential equations.
The models of real phenomena of interest to scientists and engineers are, regrettably, seldom so

First Workshop on Differentiable Programming (NeurIPS 2021).

 
 
 
 
 
 
straightforward. Alongside the fundamental physical laws expressed as PDEs are various empirical
parametrisations, closures, and regularisation terms which represent aspects of the system for which
a more fundamental model is either not known or is practically infeasible for some reason. This
scenario is ubiquitous in science and engineering, ranging from geoscience [5, 13, 24, 4, 27] to
structural mechanics [21, 8, 19] to name but two ﬁelds. In order to extend the high productivity, high
performance capabilities of UFL and Firedrake to these scenarios, we introduce a foreign function
interface to UFL in the form of external operators, by which we mean any operator which is not
directly expressible in the vector calculus notation of the existing UFL language.

Machine learning (ML) is a natural tool for creating empirical model components from observed
data, and provides the motivating example for the external operator concept. ML also demonstrates
the criticality of a differentiable programming approach, since backpropagating the neural network
involves the differentiation of both the neural net itself and the PDE to which it is coupled. The work
presented here allows deep learning frameworks to be coupled directly into Firedrake as external
operators, creating common environment for developing PDE models with deep learning components.
The external operator feature composes seamlessly with the dolﬁn-adjoint library [9, 18] enabling
automatic differentiation. It interfaces with the PyTorch library and its automatic differentiation
engine (torch.autograd), and interfaces to other ML frameworks would be straightforward.

2 The Uniﬁed Form Language (UFL)

The Uniﬁed Form Language (UFL) [3] is an embedded domain-speciﬁc language in Python which
provides symbolic representations of ﬁnite element simulations. UFL forms are compiled by a
domain-speciﬁc compiler, which takes the high-level description of the weak form of PDEs provided
by UFL and translates this representation into low-level code that assembles the sparse matrices and
vectors of the ﬁnite element problem.

2.1 Forms

UFL is organised around representing ﬁnite element variational forms, and in particular multilinear
forms. A multi-linear form (or linear k-forms) is a map from the product of a given sequence {Vj}k−1
j=0
of function spaces to a space K:

Vk−1 × Vk−2 × · · · × V0 → K

(1)

that is linear in each argument. The arity of a form k is the number of argument spaces. Variational
forms with arity k = 0, 1, and 2 are respectively named functionals, linear forms and bilinear forms.
These can be assembled to produce a scalar, a vector and a matrix, respectively. The UFL variational
forms can be parametrised by coefﬁcient functions. In this case, the form is expressed as a mapping
from a product of a sequence {Wj}n

j=1 of coefﬁcient spaces and the argument spaces:

W1 × W2 × · · · × Wn × Vk−1 × Vk−2 × · · · × V0 → K.

(2)

We refer to (2) as a linear k-form with n coefﬁcients. While the multilinear form is necessarily
linear in each argument, it can be nonlinear in each coefﬁcient function. An argument is an unknown
function in a ﬁnite element space, while a coefﬁcient is a known function in a ﬁnite element space.

The multilinear forms represented in UFL constitute the weak form of PDEs and comprise a sum of
integrals over subspaces of the problem domain.

Example 1 Let V be a suitable function space and f a given function in V . The modiﬁed Helmholtz
problem is given by: ﬁnd u ∈ V such that:

(cid:90)

Ω

u v + ∇u · ∇v dx =

(cid:90)

Ω

f v dx ∀v ∈ V.

(3)

The left-hand side of (3) is a 2-form, with u and v as the arguments, and the right-hand side is a
1-form with one coefﬁcient f and one argument v.

2

Listing 1: Firedrake code deﬁning the variational forms in (3) using UFL. Note the similarity between
lines 9 and 10, and (3).

1 from firedrake import *
2 mesh = UnitSquareMesh(10, 10)
3 V = FunctionSpace(mesh, "Lagrange", 1)
4 u = TrialFunction(V)
5 v = TestFunction(V)
6
7 f = Function(V)
8
9 a = (u * v + inner(grad(u), grad(v))) * dx
10 L = f * v * dx

The symbolic representation of forms in UFL is sufﬁcient to generate the code for matrix and vector
assembly, however the execution of that code also requires the simulation data: mesh topology
and coordinates, and the value of each coefﬁcient at each ﬁnite element node. This is provided by
ﬁnite element frameworks such as Firedrake and FEniCS, which subclass UFL objects and attach
problem data to them, as well as orchestrating the (parallel) assembly and solution operations using
the assembly code generated from UFL.

2.2 The limited scope of UFL

As a domain speciﬁc language, UFL is specialised to the particular application domain it was built for:
the symbolic representation of ﬁnite element forms. The vector calculus syntax of UFL can represent
the weak form of essentially any partial differential equation. However, realistic applications often
augment PDEs with terms not readily expressible in vector calculus. In particular, where the physical
basis for part of a model is not well understood it may be advantageous to represent this using a
neural network trained on suitable data. These terms could not hitherto be represented in UFL.

3 External operators: opening a closed language

We present an expressive, ﬂexible and powerful interface for incorporating arbitrary operators in UFL,
and providing their implementation to Firedrake. This is achieved by deﬁning symbolic external
operator objects at the UFL level, and equipping them with the appropriate mathematical properties,
such as the ability to be differentiated, so that they can be incorporated directly in UFL expressions,
and hence be incorporated directly into the operator assembly and problem solution operations
provided by Firedrake.

Deﬁnition 1 Let (Vi)1≤i≤l, (Wi)1≤i≤k and X be ﬁnite element spaces. An external operator N
mapping k operands to X is deﬁned as

N : W1 × · · · × Wk × Vl × · · · × V1 (cid:55)−→ X
u1, . . . , uk, vl, . . . , v1

−→ N (u1, . . . , uk; vl, . . . , v1)

or equivalently,

N : W1 × · · · × Wk × Vl × · · · V1 × X ∗ (cid:55)−→ IR

u1, . . . , uk, vl, . . . , v1, v∗ −→ N (u1, . . . , uk; vl, . . . , v1, v∗)

(4)

(5)

where X ∗ is the dual space to X. That is, the space of bounded linear functionals over X. N can
be nonlinear with respect to its operands u1, . . . , uk but it is linear with respect to its arguments
vl, . . . , v1, v∗. The numerical evaluation of N is not speciﬁed in the UFL language but left to the
speciﬁc implementation of the external operator N .

The equivalence of (4) and (5) follows from the reﬂexivity of X. That is, the canonical injection from
X into X ∗∗ is surjective. As a consequence, we can identify X and X ∗∗, the space of bounded linear
functionals on X ∗. In other words, X ≡ X ∗ (cid:55)−→ IR.

3

Equation (4) suggests that external operators behave like operators between ﬁnite element spaces
whereas deﬁnition (5) suggests that they act as forms in the sense that they are multilinear and
scalar-valued. There is no contradiction, both points of view are complementary: they are two
different ways to see external operator that are reﬂected in the implementation. Using (4), an external
operator can be used in a form anywhere where a coefﬁcient or argument could be used, while using
(5) it is possible to have whole form terms which are simply external operators.

We deﬁne a symbolic UFL object representing external operators, the ExternalOperator, whose
implementation is left to be speciﬁed in Firedrake by the user. In other words, the user can build their
own external operator by subclassing the external operator class and providing an implementation of
the evaluation of the operator and its derivatives. In the case of neural networks, that can be achieved
by calling the evaluation and backpropagation of the neural network using the machine learning
framework considered by the user (e.g. PyTorch or TensorFlow). Since Firedrake is embedded in
Python, the coupling to these frameworks is straightforward. The m hyperparameters of the neural
net can be represented in UFL as a coefﬁcient in the very simple ﬁnite element space IRm, which is
constant in space over the problem domain.

4 Differentiation

Solving a partial differential equation and training a neural network with a PDE constraint are
problems that require the evaluation of the gradient of a form. In UFL, the derivative of a form is
based on the Gâteaux derivative. Because external operators can be used in variational forms, we
need to extend UFL automatic differentiation rules to handle external operators.

Let N be an external operator of the following form:

N : V × V × X ∗ (cid:55)−→ IR

u, m, v∗ −→ N (u, m; v∗)

and consider a PDE, deﬁned by the residual form F linear with respect to v, such that:

F (u, m, N (u, m; v∗); v) = 0 ∀v ∈ V.

(6)

(7)

In order to solve (7) we need to compute the Jacobian of the residual form, i.e. we need to take the
Gâteaux derivative in the direction ˆu ∈ V :

dF (u, m, N (u, m; v∗); ˆu, v)
du

=

∂F (u, m, N ; ˆu, v)
∂u

+

∂F (u, m, N ; (cid:98)N , v)
∂N

·

∂N (u, m; ˆu, v∗)
∂u

(8)

where ˆN ∈ X is an argument (unknown function). In UFL, ∂N (u,m;ˆu,v∗)
is a new external operator
representing the Gâteaux derivative of N . It is evaluated using the derivative evaluation implemen-
tation provided by the user. Listing 2 shows the UFL code deﬁning and differentiating an external
operator and a form containing that operator.

∂u

Automatic differentiation is also employed to compute the gradient in the task of training a neural
network constrained by a PDE. In this case, we would have an external operator of the form
N (u, m; v∗) where u would be the input feeding the model and m the parameters. The training
would be performed with respect to a cost functional computed from u, the solution to the PDE, (7)
in the cost function. The computation of the gradient of the functional with respect to the neural
net parameters m requires the solution of the adjoint PDE. This in turn requires taking the adjoint
of ∂F
∂m . This last stage is implemented
using backpropagation. In fact, evaluating the adjoint of the gradient of the external operator with
respect to the parameters will call the evaluation implementation from the external operator subclass
representing the model, which itself delegates evaluation to the machine learning framework in which
the model is implemented. At the UFL level, this can be simply achieved via the code in Listing 3.

∂m , which by chain rule necessitates taking the adjoint of ∂N

4

Listing 2: Compute ∂F

∂u and ∂N

∂u using UFL automatic differentiation

1 V = FunctionSpace(...)
2 u = Coefficient(V)
3 m = Coefficient(V)
4 v = TestFunction(V)
5 uhat = TrialFunction(V)
6
7 # N : V × V × X ∗ (cid:55)−→ R
8 #
9 N = ExternalOperator(u, m, function_space=X)
10
11 # Define a given form F
12 F = u * N * v * dx
13

u, m, v∗ −→ N (u, m; v∗)

14 # Symbolically compute the derivative ∂N (u,m;ˆu,v∗)
15 dNdu = derivative(N, u, uhat)
16
17 # Symbolically compute the derivative dF
du
18 dFdu = derivative(F, u, uhat)

∂u

Listing 3: Assembling ∂N
∂m

∗

· y in Firedrake

1 # Symbolically compute the derivative ∂N
∂m
2 dNdm = derivative(N, m)
3
4 # Symbolic operation: ∂N
∂m
5 backprop_y = action(adjoint(dNdm), y)
6
7 # Evaluation
8 assemble(backprop_y)

∗ · y

5 Example: seismic inversion

Seismic inversion is the use of seismic reﬂection data to infer the material properties of the Earth’s
subsurface. In this process, waves are used to interrogate a medium, and the medium’s response is
recorded and processed to obtain a description of the subsurface. The problem arises predominantly
in exploration geophysics (e.g. oil and gas prospection) [10, 15, 23] and geotechnical site characteri-
sation [12]. This problem can be formulated as an inverse wave problem. This problem is invariably
ill-posed: various solution artifacts result in indistinguishable functionals but nonphysical solutions.
A simple model problem can be formulated as follows:

min
c∈P

1
2

(cid:13)ϕ(c) − ϕobs(cid:13)
(cid:13)
2
V + αR(c)
(cid:13)

(9)

where ϕobs are the observed data, c the scalar wave speed, α the regularisation factor and ϕ ∈ V is
the wave displacement of the medium such that:

−

∂2ϕ
∂t2 − c2∆ϕ = f

ϕ(t = 0) = ϕ0.

in Ω

(10)

Equation (10) is referred to as the forward problem. In practice, one may use a more complex formu-
lation of this equation to take into account additional physical effects such as elasiticy, acousticity or
anisotropy. More realistic applications may also have complex boundary conditions.

Equation (9) is the function to optimise. The ﬁrst term accounts for the mismatch error between the
solution obtained by the forward problem (the PDE) and the observed data. We refer to this term as

5

the ﬁdelity term. R is a regularisation operator which attempts to counter from noisy observations
and to help making the problem well-posed. The PDE is based on fundamental physical laws but
the regulariser is more heuristic in nature. A number of recent works have employed deep learning
to build regularisers for inverse problems, especially for seismic inversion [13, 24, 27] and medical
imaging [17, 14, 2]. External operators in UFL provide a high-level programming abstraction for
this problem. The cost function simply contains an external operator representing the neural network
2 (cid:107)N (c)(cid:107)2, with N an external operator. Listing 4 illustrates this in Firedrake.
model, i.e. R(c) = 1

Listing 4: Outline of seismic inversion using a neural net regulariser implemented as an ExternalOp-
erator in Firedrake.

1 from firedrake import *
2 from firedrake_adjoint import *
3
4 ...
5 # Get a pre-trained PyTorch model
6 model = ...
7 # Define the external operator from the model
8 pytorch_op = neuralnet(model, function_space=...)
9 N = pytorch_op(vel)
10
11 # Solve the forward problem defined by equation (10)
12 phi = F(c)
13 # Assemble the cost function: J = 1
+ α
2
14 J = assemble(0.5*(inner(phi-phi_obs, phi-phi_obs) +
15

(cid:13)ϕ(c) − ϕobs(cid:13)
(cid:13)
2
(cid:13)

alpha*inner(N, N))*dx)

2 (cid:107)N (c)(cid:107)2

16
17 # Optimise the problem
18 Jhat = ReducedFunctional(J, Control(c))
19 c_opt = minimize(Jhat, method="L-BFGS-B", tol=1.0e-7,
20

options={"disp": True, "maxiter" : 20})

Figure 1: Recovered wave speed c as a function of position (x, z) obtained for the model (9)-(10):
exact velocity (upper left), without regularisation (upper right), Tikhonov regulariser (lower left),
neural network-based regulariser (lower right).

The exact version of Firedrake (including UFL) used in this paper is archived in [26] while the code
used to run the example and generate the output ﬁgure is archived in [6]

Acknowledgement

This work was funded by a President’s PhD Scholarship at Imperial College London.

6

References

[1] Martin Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu
Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, Manjunath Kudlur, Josh Levenberg,
Rajat Monga, Sherry Moore, Derek G. Murray, Benoit Steiner, Paul Tucker, Vijay Vasudevan,
Pete Warden, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow: A system for
large-scale machine learning. In 12th USENIX Symposium on Operating Systems Design and
Implementation (OSDI 16), pages 265–283, 2016.

[2] Jonas Adler and Ozan Öktem. Solving ill-posed inverse problems using iterative deep neural
networks. Inverse Problems, 33(12):124007, November 2017. Publisher: IOP Publishing.

[3] Martin S. Alnæs, Anders Logg, Kristian B. Ølgaard, Marie E. Rognes, and Garth N. Wells.
Uniﬁed form language: A domain-speciﬁc language for weak formulations of partial differential
equations. ACM Trans. Math. Softw., 40(2), Mar 2014.

[4] Amir Asnaashari, Romain Brossier, Stéphane Garambois, François Audebert, Pierre Thore,
and Jean Virieux. Regularized seismic full waveform inversion with prior model information.
GEOPHYSICS, 78(2):R25–R36, March 2013. Publisher: Society of Exploration Geophysicists.

[5] Thomas Bolton and Laure Zanna. Applications of Deep Learning to Ocean Data Inference and
Subgrid Parameterization. Journal of Advances in Modeling Earth Systems, 11(1):376–399,
2019. _eprint: https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2018MS001472.

[6] Nacime Bouziani and David A. Ham. Seismic inversion using neural network regularisa-
tion implemented as an ExternalOperator in Firedrake. https://github.com/nbouziani/
seismic-inversion, September 2021.

[7] Tianqi Chen, Mu Li, Yutian Li, Min Lin, Naiyan Wang, Minjie Wang, Tianjun Xiao, Bing
Xu, Chiyuan Zhang, and Zheng Zhang. MXNet: A Flexible and Efﬁcient Machine Learning
Library for Heterogeneous Distributed Systems. arXiv:1512.01274 [cs], December 2015. arXiv:
1512.01274.

[8] Patrick E. Farrell, Pablo Alexei Gazca-Orozco, and Endre Süli. Numerical Analysis of Unsteady
Implicitly Constituted Incompressible Fluids: Three-Field Formulation. arXiv:1904.09136 [cs,
math], December 2019. arXiv: 1904.09136.

[9] Patrick E. Farrell, David A. Ham, Simon F. Funke, and Marie E. Rognes. Automated derivation
of the adjoint of high-level transient ﬁnite element programs. SIAM Journal on Scientiﬁc
Computing, 35(4):C369–C393, January 2013. arXiv: 1204.5577.

[10] Andreas Fichtner, Jeannot Trampert, Paul Cupillard, Erdinc Saygin, Tuncay Taymaz, Yann
Capdeville, and Antonio Villaseñor. Multiscale full waveform inversion. Geophysical Journal
International, 194(1):534–556, July 2013.

[11] Frédéric Hecht. New development in freefem++. Journal of Numerical Mathematics, 20(3-4):1–

14, 2012. Publisher: De Gruyter.

[12] L. F. Kallivokas, A. Fathi, S. Kucukcoban, K. H. Stokoe, J. Bielak, and O. Ghattas. Site
characterization using full waveform inversion. Soil Dynamics and Earthquake Engineering,
47:62–82, April 2013.

[13] Winston Lewis and Denes Vigh. Deep learning prior models from seismic images for full-
waveform inversion. In SEG Technical Program Expanded Abstracts 2017, SEG Technical
Program Expanded Abstracts, pages 1512–1517. Society of Exploration Geophysicists, August
2017.

[14] Housen Li, Johannes Schwab, Stephan Antholzer, and Markus Haltmeier. NETT: Solving
Inverse Problems with Deep Neural Networks. arXiv:1803.00092 [cs, math], December 2019.
arXiv: 1803.00092.

[15] Q. Liu and Y. J. Gu. Seismic imaging: From classical to adjoint tomography. Tectonophysics,

566-567:31–66, September 2012.

[16] Anders Logg, Kent-Andre Mardal, and Garth Wells, editors. Automated Solution of Differential
Equations by the Finite Element Method: The FEniCS Book. Lecture Notes in Computational
Science and Engineering. Springer-Verlag, Berlin Heidelberg, 2012.

7

[17] Sebastian Lunz, Ozan Öktem, and Carola-Bibiane Schönlieb. Adversarial Regularizers in
Inverse Problems. In Proceedings of the 32nd International Conference on Neural Information
Processing Systems, NIPS’18, pages 8516–8525, Red Hook, NY, USA, December 2018. Curran
Associates Inc.

[18] Sebastian Mitusch, Simon Funke, and Jørgen Dokken. dolﬁn-adjoint 2018.1: automated adjoints

for FEniCS and Firedrake. Journal of Open Source Software, 4(38):1292, June 2019.

[19] Atsuya Oishi and Genki Yagawa. Computational mechanics enhanced by deep learning. Com-
puter Methods in Applied Mechanics and Engineering, 327:327–351, December 2017.
[20] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan,
Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas
Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy,
Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An Imperative Style,
High-Performance Deep Learning Library. In Advances in Neural Information Processing
Systems, volume 32. Curran Associates, Inc., 2019.

[21] K. R. Rajagopal. On Implicit Constitutive Theories. Applications of Mathematics, 48(4):279–

319, August 2003.

[22] Florian Rathgeber, David A. Ham, Lawrence Mitchell, Michael Lange, Fabio Luporini, Andrew
T. T. Mcrae, Gheorghe-Teodor Bercea, Graham R. Markall, and Paul H. J. Kelly. Firedrake:
Automating the Finite Element Method by Composing Abstractions. ACM Transactions on
Mathematical Software, 43(3):1–27, January 2017.

[23] N. Rawlinson, S. Pozgay, and S. Fishwick. Seismic tomography: A window into deep Earth.

Physics of the Earth and Planetary Interiors, 178(3):101–135, February 2010.

[24] Yunzhi Shi, Xinming Wu, and Sergey Fomel. Deep learning parameterization for geophysical
inverse problems. In SEG 2019 Workshop: Mathematical Geophysics: Traditional vs Learning,
Beijing, China, 5-7 November 2019, SEG Global Meeting Abstracts, pages 36–40. Society of
Exploration Geophysicists, January 2020.

[25] The Theano Development Team, Rami Al-Rfou, Guillaume Alain, Amjad Almahairi, Christof
Angermueller, Dzmitry Bahdanau, Nicolas Ballas, Frédéric Bastien, Justin Bayer, Anatoly
Belikov, Alexander Belopolsky, Yoshua Bengio, Arnaud Bergeron, James Bergstra, Valentin
Bisson, Josh Bleecher Snyder, Nicolas Bouchard, Nicolas Boulanger-Lewandowski, Xavier
Bouthillier, Alexandre de Brébisson, Olivier Breuleux, Pierre-Luc Carrier, Kyunghyun Cho,
Jan Chorowski, Paul Christiano, Tim Cooijmans, Marc-Alexandre Côté, Myriam Côté, Aaron
Courville, Yann N. Dauphin, Olivier Delalleau, Julien Demouth, Guillaume Desjardins, Sander
Dieleman, Laurent Dinh, Mélanie Ducoffe, Vincent Dumoulin, Samira Ebrahimi Kahou, Du-
mitru Erhan, Ziye Fan, Orhan Firat, Mathieu Germain, Xavier Glorot, Ian Goodfellow, Matt
Graham, Caglar Gulcehre, Philippe Hamel, Iban Harlouchet, Jean-Philippe Heng, Balázs Hidasi,
Sina Honari, Arjun Jain, Sébastien Jean, Kai Jia, Mikhail Korobov, Vivek Kulkarni, Alex Lamb,
Pascal Lamblin, Eric Larsen, César Laurent, Sean Lee, Simon Lefrancois, Simon Lemieux,
Nicholas Léonard, Zhouhan Lin, Jesse A. Livezey, Cory Lorenz, Jeremiah Lowin, Qianli Ma,
Pierre-Antoine Manzagol, Olivier Mastropietro, Robert T. McGibbon, Roland Memisevic, Bart
van Merriënboer, Vincent Michalski, Mehdi Mirza, Alberto Orlandi, Christopher Pal, Razvan
Pascanu, Mohammad Pezeshki, Colin Raffel, Daniel Renshaw, Matthew Rocklin, Adriana
Romero, Markus Roth, Peter Sadowski, John Salvatier, François Savard, Jan Schlüter, John
Schulman, Gabriel Schwartz, Iulian Vlad Serban, Dmitriy Serdyuk, Samira Shabanian, Éti-
enne Simon, Sigurd Spieckermann, S. Ramana Subramanyam, Jakub Sygnowski, Jérémie
Tanguay, Gijs van Tulder, Joseph Turian, Sebastian Urban, Pascal Vincent, Francesco Visin,
Harm de Vries, David Warde-Farley, Dustin J. Webb, Matthew Willson, Kelvin Xu, Lijun Xue,
Li Yao, Saizheng Zhang, and Ying Zhang. Theano: A Python framework for fast computation
of mathematical expressions. arXiv:1605.02688 [cs], May 2016. arXiv: 1605.02688.

[26] The Firedrake developers. Software used in ‘Escaping the abstraction: a foreign function
interface for the Uniﬁed Form Language [UFL]’. https://doi.org/10.5281/zenodo.
5526458, September 2021.

[27] Zhen-Dong Zhang and Tariq Alkhalifah. Regularized elastic full-waveform inversion using
deep learning. GEOPHYSICS, 84(5):R741–R751, September 2019. Publisher: Society of
Exploration Geophysicists.

8

