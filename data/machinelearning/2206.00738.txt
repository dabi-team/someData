2
2
0
2

n
u
J

1

]

G
L
.
s
c
[

1
v
8
3
7
0
0
.
6
0
2
2
:
v
i
X
r
a

Composition of Relational Features

Composition of Relational Features with an Application to
Explaining Black-Box Predictors

Ashwin Srinivasan∗
Department CS & IS and APPCAIR
BITS Pilani, K.K. Birla Goa Campus
Zuarinagar, Goa 403726, India

A. Baskar
Department CS & IS
BITS Pilani, K.K. Birla Goa Campus
Zuarinagar, Goa 403726, India

Tirtharaj Dash
Department CS & IS and APPCAIR
BITS Pilani, K.K. Birla Goa Campus
Zuarinagar, Goa 403726, India

Devanshu Shah
Department CS & IS
BITS Pilani, K.K. Birla Goa Campus
Zuarinagar, Goa 403726, India

Editor: Editors

ashwin@goa.bits-pilani.ac.in

abaskar@goa.bits-pilani.ac.in

tirtharaj@goa.bits-pilani.ac.in

f20180240@goa.bits-pilani.ac.in

Abstract

Three key strengths of relational machine learning programs like those developed in In-
ductive Logic Programming (ILP) are: (1) The use of an expressive subset of ﬁrst-order
logic that allows models that capture complex relationships amongst data instances; (2)
The use of domain-speciﬁc relations to guide the construction of models; and (3) The
models constructed are human-readable, which is often one step closer to being human-
understandable. The price for these advantages is that ILP-like methods have not been able
to capitalise fully on the rapid hardware, software and algorithmic developments fuelling
current developments in deep neural networks. In this paper, we treat relational features
as functions and use the notion of generalised composition of functions to derive complex
functions from simpler ones. Motivated by the work of McCreath and Sharma (McCreath
and Sharma, 1998a; McCreath, 1999) we formulate the notion of a set of M-simple features
in a mode language M and identify two composition operators (ρ1 and ρ2) from which all
possible complex features can be derived. We use these results to implement a form of
“explainable neural network’ called Compositional Relational Machines, or CRMs. CRMs
are labelled directed-acyclic graphs. The vertex-label for any vertex j in the CRM contains
a feature-function fj and an continuous activation function gj. If j is a “non-input” vertex,
then fj is the composition of features associates with vertices in the direct predecessors of
j. Our focus is on CRMs in which input vertices (those without any direct predecessors)

∗. AS is currently visiting TCS Research. He is also a Visiting Professor at the Centre for Health Informatics,
Macquarie University, Sydney; and a Visiting Professorial Fellow at the School of CSE, University of
New South Wales, Sydney.

1

 
 
 
 
 
 
Srinivasan, Baskar, Dash, Shah

all have M-simple features in their vertex-labels. We provide a randomised procedure for
constructing the structure of such CRMs, and a procedure for estimating the parameters
(the wij’s). using back-propagation and stochastic gradient descent. Using a notion of
explanations based on the compositional structure of features in a CRM, we provide em-
pirical evidence on synthetic data of the ability to identify appropriate explanations; and
demonstrate the use of CRMs as ‘explanation machines’ for black-box models that do not
provide explanations for their predictions.
Keywords: Explainable Neural Networks, Relational Features, Inductive Logic Program-
ming

1. Introduction

It has long been understood that choice of representation can make a signiﬁcant diﬀerence to
the eﬃcacy of machine-based induction. A seminal paper by Quinlan (1979) demonstrates
the increasing complexity of models constructed for a series of problems deﬁned on a chess
endgame, using a ﬁxed representation consisting of 25 features (called properties in the
paper). These features were identiﬁed manually (by him), and captured relations between
the pieces and their locations in the endgame. Commenting on the increasing complexity
of the models, he concludes: “This immediately raises the question of whether these and
other properties used in the study were appropriate. The answer is that they were probably
not; it seems likely that a chess expert could develop more pertinent attributes . . . If the
expert does his job well the induction problem is simpliﬁed; if a non-expert undertakes the
deﬁnition of properties (as was the case here) the converse is true.”

Although Quinlan assumed the representation would be identiﬁed manually, the possi-
bility of automatic identiﬁcation of an appropriate representation was already apparent to
Amarel (1968) a decade earlier: “An understanding of the relationship between problem
formulation and problem solving eﬃciency is a prerequisite for the design of procedures that
can automatically choose the most ‘appropriate’ representation of a problem (they can ﬁnd
a ‘point of view’ of the problem that maximally simpliﬁes the process of ﬁnding a solution)”.
In fact, by ‘choose’ what is probably meant is ‘construct’, if we are to avoid kicking Feigen-
baum’s famous knowledge-acquisition bottleneck down the road from extracting models to
extracting representations.

It has also been known that one way to construct representations automatically is
through the use of neural networks. But extraction and re-use of these representations
for multiple tasks have become substantially more common only recently, with the routine
availability of specialised hardware. This has allowed the construction of networks in which
adding layers of computation are assumed to result in increasingly complex representations
(10s of layers are now common, but 100s are also within computational range). In principle,
while a single additional layer is all that is needed, it is thought that the main beneﬁt of the
additional layers lies in constructing representations that are multiple levels of abstractions,
allowing more eﬃcient modelling. There are however 3 important issues that have surfaced:
(1) Automatic construction of abstractions in this way requires a lot of data, often 100s
of 1000s of examples; (2) The kinds of neural networks used for constructing abstractions
depends on the type of data. For example, certain kinds of networks are used for text, oth-
ers for images and so on: there is apparently no single approach for representation learning
that can automatically adjust to the data type; and (3) The internal representations of data

2

Composition of Relational Features

are opaque to human-readability, making it diﬃcult to achieve the kind of understanding
identiﬁed by Amarel.

Recent results with neural-based learning suggest the possibility of viewing represen-
tation learning as program synthesis. Of particular interest are methods like Dreamcoder
(Ellis et al., 2021) that automatically construct programs for generating data, given some
manually identiﬁed primitive functions represented in a symbolic form (Dreamcoder uses
λ-expressions for the primitive functions). A combination of generative and discriminative
network models are used to direct the hierarchical construction of higher-level functions
by compositions of lower-level ones. Compositions are generated and assessed for util-
ity in inter-leaved phases of generate-and-test (called “Dream” and “Wake” phases), until
the neural-machinery arrives at a small program, consisting the sequential composition of
primitive- and invented functions. The ﬁnal result is some approximation to the Bayesian
MAP program for generating the data provided, assuming a prior preference for small pro-
grams. There are good reasons to look at this form of program-synthesis as a mechanism for
automated representation learning: (a) Empirical results with programs like Dreamcoder
show that it is possible to identify programs with small numbers of examples (the need for
large numbers of examples is side-stepped by an internal mechanism for generating data
in the Dream phase); (b) In principle, the symbolic language adopted for primitive func-
tions (λ-expressions) and the mechanism of function composition is suﬃciently expressive
for constructing programs for data of any type; (c) The intermediate representations have
clearly deﬁned interpretations, based on functional composition. There are however some
shortcomings. First, the primitive functions have to be manually identiﬁed. Secondly, the
construction of new representations requires a combinatorial discrete search that is usually
less eﬃcient than those based on continuous-valued optimisation. Thirdly, the representa-
tion of λ-expressions, although mathematically powerful, can prove daunting as a language
for encoding domain-knowledge or for interpreting the results. Finally, the Dreamcoder-like
approach for representation learning has only been demonstrated on very simple generative
tasks of a geometric nature.

In this paper, we partially address these shortcomings by drawing on, and extending
some results on representation developed in the area of Inductive Logic Programming (ILP).
The main contributions of this paper are as follows: (a) Conceptual: We develop the
conceptual basis for a class of ‘simple’ relational features using a well-known speciﬁcation
language in ILP (mode-declarations). Additionally, we develop composition operators for
deriving more complex relational features, and prove some completeness properties that
apply to the use of the operators; (b) Implementation: We use the concepts developed to
specify and implement a form of neural network called Compositional Relational Machines,
or CRMs. An important feature of these networks is that each node is identiﬁed with a
clearly deﬁned relational feature. This allows us to associate structured ‘explanations’ with
each node in the network; (c) Application: we present empirical results on 2 synthetic data
that demonstrate the ability of CRMs to construct appropriate explanations; and results
on using CRMs to act as ‘explanation machines’ for a state-of-the-art black-box predictor
on 10 real-world datasets.

The rest of the paper is organised as follows: In section 2 we provide a conceptual frame-
work for relational features and their compositions. We use this framework to implement
CRMs in section 3. We provide empirical evaluation of CRMs as explanation machines in

3

Srinivasan, Baskar, Dash, Shah

section 4. Related work of immediate relevance to this paper are presented in section 5.
Concluding remarks are in in section 6. The paper has several appendices that act as
supporting material.

2. Relational Features and their Composition

In this paper we are principally interested in specifying and combining relational features.
For us, relational features will be functions of the form f : A1 × A2 × · · · × Ak → B. For
the most part in this paper, we will restrict ourselves to k = 1 and B = {0, 1}, although the
results here can be generalised. We will denote this setting as f : A → {0, 1}, and deﬁne
a relational feature in 2 steps. First, we represent the conditions under which the feature
takes the value 1 using a clause of the form:1

or, simply:

C : ∀X (p(X) ← ∃YBody(X, Y))

C :

(p(X) ← Body(X, Y))

to mean the quantiﬁcation as shown earlier. Here, the ﬁxed predicate symbol p(X) is called
the head of C, and Body(·)–the body of clause C–is a conjunction of literals l2, l3 . . . , lk
containing some existentially quantiﬁed variables collectively represented here as Y. We
assume the body of C does not contain a literal of the form p(·) (that is, C is not self-
recursive) and call clauses like these feature-clauses.2 The clausal representation does not
tell us how to obtain the value (0 or 1) of the feature itself for any X = a. For this we
assume an additional set of clausal formulae B (“background”) which does not contain any
occurrence of the predicate-symbol p/1 and deﬁne the feature-function associated with the
clause C as follows. Let θa denotes the substitution {X/a} for a ∈ A. Then:

fC,B(a) = 1
= 0

if B ∪ (Cθa) |= p(a)
otherwise

In general, given feature-clauses C1, C2, . . . , Cj We will write fCi,B(·) as fi(·) (1 ≤ i ≤ j),
when the context is obvious. If fi(x) = 1 for x = a, we will say “the feature fi is true for
x = a”.

Example 1 An early example of a problem requiring relational features was the problem
of discriminating amongst goods trains (Michalski, 1980), which has subsequently served
as a touchstone for the construction and use of relational features (see for example, the
“East-West Challenge” (Michie et al., 1994)). In its original formulation, the task is to

1. See Appendix A for a summary of logical syntax and concepts needed for this paper. We assume a logic

with equality (= /2).

2. This clause is equivalent to the disjunct l1 ∨ ¬l2 ∨ · · · ∨ ¬lk. It will sometimes also be written as the set
of literals {l1, ¬l2, . . . , ¬lk}. The literals can contain predicate symbols representing relations: hence the
term “relational”. The requirement that all feature-clauses have the same predicate symbol p/1 in the
head is a convenience that will be helpful in what follows. It may be helpful to read the symbol p/1 as
a proposition deﬁned on X.

4

Composition of Relational Features

distinguish eastbound trains from westbound ones using properties of the carriages and their
loads (the engine’s properties are not used), using pictorial descriptions like these (T1 is
eastbound and T2 is westbound):

Examples of feature-clauses are:

C1: p(X) ← (has car(X, Y ), short(Y ))

C2: p(X) ← (has car(X, Y ), closed(Y ))

C3: p(X) ← (has car(X, Y ), short(Y ), closed(Y ))

C4: p(X) ← (has car(X, Y ), has car(X, Z), short(Y ), closed(Z))

Here, we will assume that predicates like has car/2, short/1, closed/1, long/1 and has load/3
are deﬁned as part of the background B, and capture the situation shown diagrammati-
cally. That is, B = { has car(t1, c1 1), has car(t1, c1 2), . . ., long(c1 1), closed(c1 1),
has load(c1 1, square, 3), . . ., has car(t2, c2 1), has car(t2, c2 2), . . . }. Then the corre-
sponding feature-function values are:

fC1,B(t1) = f1(t1) = 1; f1(t2) = 1;

fC2,B(t1) = f2(t1) = 1; f2(t2) = 1;

fC3,B(t1) = f3(t1) = 1; f3(t2) = 0;

fC4,B(t1) = f4(t1) = 1; f4(t2) = 1

Although not used in this paper, feature-clauses need not be restricted to descriptions of

single objects. An example of a feature-clause about train-pairs for example is:

C5: p((X1, X2)) ← (has length(X1, L1), has length(X2, L2), L1 ≥ L2)

(The corresponding feature-function will then also be deﬁned over pairs of objects.)

We intend to describe a mechanism for automatically enumerating feature-clauses like
these, as well as mechanisms for combining simpler feature-clauses to give more complex
ones. We start with some preliminary deﬁnitions needed.

2.1 Preliminaries

It will be necessary for what follows to assume an ordering over literals in a feature-clause.

Deﬁnition 1 (Ordered Clause) Let C be a feature-clause with 1 head literal and k − 1
body literals. We assume an ordering over the literals that maps the set of literals in the
clause to a sequence (cid:104)C(cid:105) = (cid:104)λ1, λ2, λ3, . . . , λk(cid:105), where λ1 is the head literal and the λ2, . . . , λk
are literals in the body of the feature-clause.

5

Srinivasan, Baskar, Dash, Shah

Deﬁnition 2 (Ordered Subclause) Let (cid:104)C(cid:105) = (cid:104)λ1, λ2, λ3, . . . , λk(cid:105) be an ordered clause.
Then an ordered subclause (cid:104)C(cid:48)(cid:105) is any clause (cid:104)λ(cid:48)
2, . . . , λ(cid:48)
j(cid:105)
is a sub-sequence of (cid:104)λ2, . . . , λk(cid:105).

1 = λ1 and (cid:104)λ(cid:48)

j(cid:105) where λ(cid:48)

2, , . . . , λ(cid:48)

1, λ(cid:48)

From now on, we will use the term “ordered clause” to emphasise an ordering on the literals
is assumed. For simplicity, we will assume that the intended ordering is reﬂected in a left-
to-right reading of the clause. Given an ordered clause, it is possible to recover trivially
the set of literals constituting the feature-clause. We use Set((cid:104)C(cid:105)) = Set((cid:104)λ1, . . . , λk(cid:105)
= {λ1, ¬λ2, . . . , ¬λk}. Usually, we will further use the set-notation interchangeably with
λ1 ← λ2, . . . , λk to denote the feature-clause C.

2.2 Feature-Clauses in a Mode Language

The ﬁeld of Inductive Logic Programming (ILP) has extensively used the idea of a mode
language to specify a set of acceptable clauses.3 We use this approach here to specify
the set of feature-clauses. We provide details of mode-declarations and the deﬁnition of a
mode-language based on such declarations in Appendix B. We need the following concepts
from the Appendix: (a) type-names and their deﬁnitions; (b) set of mode declarations and
clauses in the mode-language; (c) input term of type γ in some literal; and (d) output term
of type γ in some literal. With these notions in place, we will require the mode-language
for specifying feature-clauses to satisfy the following constraints:

MC1. The set of modes M contains exactly one mode-declaration for every predicate oc-

curring in a feature-clause;

MC2. All modes in M for predicates which appear in the body of a feature-clause contain

at least 1 “input” argument; and

MC3. If µ = modeh(p) ∈ M, then p is an unary predicate and modeb(p) does not occur in

M.

These constraints extend to p/k if the features are deﬁned over a product-space. Given a set
of mode-declarations, feature-clauses in the mode-language are therefore more constrained
than we have presented thus far. Now, variables (and ground-terms) are constrained by the
type-restrictions.4 Henceforth we will use M is a set of “constrained mode-declarations” to
mean that M satisfy MC1–MC3.
The categorisation of variables in a literal as being inputs or outputs allows a natural
association of an ordered clause with a graph.

3. The notion of associating modes for predicates has its origins in typed logics and functional programming.
Even in ILP, modes are not the only way of specifying acceptable sets of clauses: they are used here
as they provide a straightforward way of specifying the notion of simple features that follows in a later
section.

4. That is, a feature-clause of the form ∀X(p(X) ← ∃YBody(X, Y)) should be read as ∀X ∈ A [p(X) ←
∃Y ∈ YBody(X, Y)] where A and Y informally denote the sorts of x and the Y’s. For simplicity, we
will not refer to the type-restrictions on variables and terms when we say that a feature-clause is in a
mode-language. The restrictions are taken as understood, and to be enforced during inference.

6

Composition of Relational Features

Deﬁnition 3 (Clause Dependency-Graph) Let M be a set of constrained mode-declarations
and T be a set of type deﬁnitions for the type-names in M. Let (cid:104)C(cid:105) be an ordered clause
(λ1 ← λ2, . . . , λk) in the mode-language LM,T (see Appendix B) The clause dependency-
graph GM((cid:104)C(cid:105)) associated with (cid:104)C(cid:105) is the labelled directed graph (V, E, ψ) deﬁned as follows:

• V = {v1, v2 . . . , vk};

• for each i, ψ(vi) = λi;

• (vi, vj) ∈ E iﬀ:

– i = 1, 2 ≤ j ≤ k, and there exists a variable X such that λi has X as an input
variable of type γ in M and λj has X as an input variable of type γ in M; or
– 1 < i < j, λi has an output variable X of type γ in M and X occurs in λj as an

input variable of type γ in M.

Example 2 Let us assume the set of mode-declarations M contain at least the following: {
modeh(p(+train)), modeb(has car(+train, −car)), modeb(short(+car)), modeb(closed(+car))
} where train and car are type-names, with deﬁnitions in T. The ordered clause p(X) ←
(has car(X, Y ), has car(X, Z), short(Y ), closed(Z))) is in the mode-language LM,T. The
clause dependency-graph for this ordered clause is given below and ψ is deﬁned as fol-
lows: ψ(v1) = p(X), ψ(v2) = has car(X, Y ), ψ(v3) = has car(X, Z), ψ(v4) = short(Y ),
ψ(v5) = closed(Z).

Remark 4 We note the following about the clause dependency-graph:

• The clause dependency-graph for an ordered clause is a directed acyclic graph. This

is evident from the deﬁnition: if (vi, vj) ∈ E then i < j.

• The clause dependency-graph for an ordered clause is unique.

Given a set of modes M we introduce the notion M-simple clauses in a manner similar

to (McCreath, 1999).

Deﬁnition 5 (Source- and Sink- Vertices and Literals) Given a set of constrained
mode-declarations M, type-deﬁnitions T, and an ordered clause (cid:104)C(cid:105) in LM,T, let GM((cid:104)C(cid:105)) =
(V, E, ψ) be the clause dependency-graph of (cid:104)C(cid:105). A vertex v ∈ V is said to be a sink vertex
if there is no outgoing edge from v. The corresponding literal, ψ(v), is called a sink lit-
eral. A vertex v ∈ V is said to be a source vertex if there is no incoming edge to v. The
corresponding literal, ψ(v), is called a source literal.

7

Srinivasan, Baskar, Dash, Shah

Example 3 The clause in Example 2 has one source vertex v1 and two sink vertices: v4
and v5. Correspondingly, there is one source literal p(X), and two sink literals: short(Y ),
closed(Y ).

Remark 6 Let M satisfy MC1–MC3. Then:

• The clause dependency-graph of any ordered clause in LM,T will have exactly 1 source-

vertex v1 (and exactly 1 source-literal).

• For every vertex v in the clause dependency-graph, there exists at least one path from
v1 to v. Also the union of all the paths from v1 to v will be a directed acyclic graph
and this is unique. We will denote this directed acyclic graph by DAG(cid:104)C(cid:105)(v).

• For every vertex v in the clause dependency-graph, either v will be a sink vertex or it

will be on a path from the source vertex (v1) to a sink vertex.

Of these the third observation is not obvious. Suppose a vertex v is not a sink vertex. Then
it will have at least one outgoing edge from it. By following outgoing edges forward, we will
end in a sink vertex. If v (cid:54)= v1, then there is at least one incoming edge to v. By following
incoming edges backward, we will end in a source vertex. Since there is only one source
vertex, this will be v1. So v will be a sink vertex or it will be on a path from v1 to a sink
vertex.

Deﬁnition 7 (M-Simple Feature-Clause) Given a set of constrained mode-declarations
M, type-deﬁnitions T , an ordered feature-clause (cid:104)C(cid:105) in the mode-language LM,T is said to
be an M-simple feature-clause, or simply a M-simple clause iﬀ the clause dependency-graph
GM((cid:104)C(cid:105)) has exactly one sink literal.

Example 4 We continue Example 2. The ordered clauses p(X) ← has car(X, Y ), short(Y )
and p(X) ← has car(X, Y ) are M-simple clauses as both have only one sink literals short(Y )
and has car(X, Y ) respectively. The ordered clause p(X) ← has car(X, Y ), short(Y ), closed(Y )
is not a M-simple clause as it has two sink literals short(Y ) and closed(Y ).

Deﬁnition 8 (Maximal M-simple subclause) Given a set of constrained mode-declarations
M, type-deﬁnitions T, an ordered clause (cid:104)C(cid:48)(cid:105) in the mode-language LM,T is said to be a max-
imal M-simple subclause of an ordered clause (cid:104)C(cid:105) in LM,T iﬀ: (a) (cid:104)C(cid:48)(cid:105) is an ordered sub-
clause of (cid:104)C(cid:105); and (b) there is an isomorphism from the clause dependency-graph GM((cid:104)C(cid:48)(cid:105))
to DAG(cid:104)C(cid:105)(v) for some sink vertex v in GM((cid:104)C(cid:105)).

Example 5 Continuing Example 2, the ordered clause p(X) ← has car(X, Y ), short(Y )
is a maximal M-simple subclause of p(X) ← has car(X, Y ), short(Y ), closed(Y ). The
ordered clause p(X) ← has car(X, Y ) is not a maximal M-simple subclause of p(X) ←
has car(X, Y ), short(Y ), closed(Y ).

Deﬁnition 9 (Basis) Let M be a set of constrained mode-declarations, T be a set type-
deﬁnitions, (cid:104)C(cid:105) be an ordered clause in the mode-language LM,T. Then Basis((cid:104)C(cid:105)) = {
(cid:104)C(cid:48)(cid:105) | (cid:104)C(cid:48)(cid:105) is a maximal M-simple subclause of (cid:104)C(cid:105) }.

8

Composition of Relational Features

Example 6 The basis for p(X) ← has car(X, Y ), has car(X, Z), short(Y ), closed(Z) is
{p(X) ← has car(X, Y ), short(Y ), p(X) ← has car(X, Z), closed(Z)}.

Remark 10 For given an ordered clause C in LM,T, Basis((cid:104)C(cid:105)) is unique. Moreover, if the
number of sink vertices in the clause dependency-graph of (cid:104)C(cid:105) is k, then |Basis((cid:104)C(cid:105))| = k.

Lemma 11 (Basis Lemma) Let M be a set of constrained mode-declarations, T be a set
of type-deﬁnitions. Let (cid:104)C(cid:105) be an ordered clause in the mode-language LM,T with k sink-
literals. If Basis((cid:104)C(cid:105)) = {(cid:104)S1(cid:105), (cid:104)S2(cid:105), . . . , (cid:104)Sk(cid:105)} then (cid:83)k

i=1 Si = C.

i=1 Si ⊆ C and C ⊆ (cid:83)k
i=1 Si ⊆ C. Assume the contrary. That is, there exists some l ∈ (cid:83)k

Proof Let GM((cid:104)C(cid:105)) = (V, E, ψ) be the clause dependency-graph for the ordered clause
(cid:104)C(cid:105) and Basis((cid:104)C(cid:105)) = { (cid:104)S1(cid:105), (cid:104)S2(cid:105), . . . , (cid:104)Sk(cid:105)}. We prove (cid:83)k
i=k Si. We
consider ﬁrst (cid:83)k
i=1 Si but
l (cid:54)∈ C. Since l is a literal in (cid:83)k
j=1 Sj, then l ∈ Sj for some j. Since every (cid:104)Sj(cid:105) is an ordered
subclause of (cid:104)C(cid:105), by deﬁnition every literal in Sj occurs in C. Therefore l ∈ C which is a
contradiction.

Next we consider C ⊆ (cid:83)k

i=1 Si. Let l be a literal in C. There exists a vertex vj in the
clause dependency-graph GM((cid:104)C(cid:105)) such that ψ(vj) = l. Either vj is a sink vertex or not a
sink vertex in GM((cid:104)C(cid:105)). If it is a sink vertex, then there exists maximal M-simple subclause
(cid:104)Sj(cid:105) with vj as a sink vertex. Hence l is in Sj. If vj is not a sink vertex, then it will be
on the path from v1 to some sink vertex vm (see Remark 6). Then the directed acyclic
sub-graph DAG(cid:104)C(cid:105)(vm) will have this vertex vj. Hence l ∈ Sm. So in both cases l is in
(cid:83)k

i=1 Si. Hence C ⊆ (cid:83)k

i=1 Si.

Let M be a set of constrained mode-declarations, and T be a set of type deﬁnitions. Let
M(cid:48) be M extended with an additional mode-declarations allowing body-literals of the form
+γ = +γ (that is, M(cid:48) allows equality between variables of the same type γ: if this is not
already allowed in M); the deﬁnition of = /2 is provided by axioms of the equality logic.
For more details see Appendix A). We note that if the ordered clause (cid:104)C(cid:105) is in LM,T, then
(cid:104)C(cid:105) is in LM(cid:48),T.

We deﬁne operators ρ1, ρ2 as follows:

1. Let (cid:104)C(cid:105) be in LM(cid:48),T s.t. (cid:104)C(cid:105) : (p(X) ← Body(X, Y). Then ρ1((cid:104)C(cid:105)) = { p(X) ←
Body(X, Y), Y1 = Y2) | Y1, Y2 are output variables of the same type in Body };

2. Let (cid:104)C1(cid:105), (cid:104)C2(cid:105) be in LM(cid:48),T s.t. (cid:104)C1(cid:105) : (p(X) ← Body1(X, Y) and (cid:104)C2(cid:105) : (p(X) ←

Body2(X, Y(cid:48)). Then ρ2((cid:104)C1(cid:105), (cid:104)C2(cid:105)) = { p(X) ← Body1(X, Y), Body2(X, Y(cid:48)) }

These operators allows us to establish a link between the derivability of clauses in LM(cid:48),T
using {ρ1, ρ2} and clauses in LM,T.

Deﬁnition 12 (Derivation of Feature-Clauses) Let M be a set of mode-declarations,
and M(cid:48) be an extension of M as above. Let T be a set of type-deﬁnitions, and Ω ⊆ {ρ1, ρ2}.
Let Φ be a set of feature-clauses in LM(cid:48),T. A sequence of feature-clauses (cid:104)C1(cid:105), (cid:104)C2(cid:105), . . . , (cid:104)Cn(cid:105)
is said to be a derivation sequence of (cid:104)Cn(cid:105) from Φ using Ω iﬀ each clause (cid:104)Ci(cid:105) in the sequence
is either : (a) an instance of an element of Φ such that no variables other than X occur

9

Srinivasan, Baskar, Dash, Shah

earlier in this sequence; or (b) an element of the set ρ1((cid:104)Cj(cid:105)) (j < i), if ρ1 ∈ Ω; or (c) an
element of the set ρ2((cid:104)Cj(cid:105), (cid:104)Ck(cid:105)) (j, k < i), if ρ2 ∈ Ω. We will say (cid:104)Cn(cid:105) is derivable from Φ
using Ω if there exists a derivation sequence of (cid:104)Cn(cid:105) from Φ using Ω.

Example 7 Let us assume the set of mode-declarations M contain the following: { modeh(p(+train)),
modeb(has car(+train, −car)), modeb(short(+car)), modeb(closed(+car)) modeb(smaller(+car, +car)
} where train and car are type-names, with deﬁnitions in T. Here is a derivation sequence of
p(X) ← has car(X, U ), has car(X, V ), smaller(U, V ), U = V, has car(X, Y ), short(Y ), U =
Y from {p(X) ← has car(X, Y ), short(Y ), p(X) ← has car(X, U ), has car(X, V ), smaller(U, V )}
using {ρ1, ρ2}.

1
2
3
4

5

p(X) ← has car(X, U ), has car(X, V ), smaller(U, V )
p(X) ← has car(X, U ), has car(X, V ), smaller(U, V ),U=V
p(X) ← has car(X, Y ), short(Y )
p(X) ← has car(X, U ), has car(X, V ), smaller(U, V ), U = V,

has car(X, Y ), short(Y )

p(X) ← has car(X, U ), has car(X, V ), smaller(U, V ), U = V,
has car(X, Y ), short(Y ), U = Y

Given
1, ρ1, U, V
Given

2, 3, ρ2

4, ρ1, U, Y

It is useful to deﬁne the notion of a ρ-derivation graph from a set of feature-clauses Φ.

Deﬁnition 13 (ρ-derivation graph given Φ) Let γ = (V, E, φ) be a labelled DAG with
vertices V , edges E and vertex-labelling function φ. Let P red(v) denote the set of immediate
predecessors of any v ∈ V . Let FM be a set of feature-clauses given modes M and I ⊆ FM.
Then γ is a ρ-derivation graph given Φ iﬀ:

• For each vertex vi ∈ V , φ(vi) = Ci, where Ci ∈ FM;

• 0 ≤ |P red(v)| ≤ 2 for all v ∈ V ;

• For each v ∈ V :

– If P red(v) = ∅ then φ(v) ∈ Φ;
– If P red(v) = {u} then φ(v) ∈ ρ1(φ(u));
– If P red(v) = {u1, u2} then φ(v) ∈ ρ2(φ(u1), φ(u2))

Since we are only concerned with ρ1,2 in this paper, we will usually call this the derivation
graph given Φ or even just the derivation graph, when Φ is understood.

Remark 14 We note that ρ1 and ρ2 preserve equivalence, in the following sense:

• If C(cid:48) ≡ C then ρ1(C) ≡ ρ1(C(cid:48)); and

• if C(cid:48)

1 ≡ C1 and C(cid:48)

2 ≡ C2 then ρ2(C1, C2) ≡ ρ2(C(cid:48)

1, C(cid:48)
2)

Here, equivalence across sets has the usual conjunctive meaning. That is, for sets A, B,
A ≡ B iﬀ (cid:86)
y. Two ordered clauses (cid:104)C1(cid:105) and (cid:104)C2(cid:105) iﬀ the Set((cid:104)C1(cid:105)) is equivalent
x∈A

x ≡ (cid:86)
y∈B

to the Set((cid:104)C2(cid:105)).

10

Composition of Relational Features

Deﬁnition 15 (Closure) Let Φ be a set of feature-clauses and Ω ⊆ {ρ1, ρ2}. We deﬁne
ClosureΩ(Φ) as the set of ordered clauses (cid:104)C(cid:105) which has a derivation sequence from Φ using
Ω. We call ClosureΩ(Φ) as the closure of Φ using Ω.

We will say θ is a type-consistent substitution if for every variable U , the substitution
U/t ∈ θ (that is, θ(U ) = t), then U, t have the same type in M. It follows that if θ is a
type-consistent substitution for variables in an ordered clause (cid:104)C(cid:105) in LM,T and θ(u) = θ(v)
for u, v in (cid:104)C(cid:105), then u, v have the same type in M.

Lemma 16 (Derivation Lemma) Given M, M(cid:48) and Ω = {ρ1, ρ2} as before. Let (cid:104)C(cid:105) be
an ordered clause in LM,T, with head p(X). Let S be a set of ordered simple clauses in
LM,T, with heads p(X) and all other variables of clauses in S standardised apart from each
other and from C. If there exists a substitution θ s.t. Basis((cid:104)C(cid:105)) ⊆ Sθ then there exists an
equivalent (cid:104)C(cid:48)(cid:105) in LM(cid:48),T that is derivable from S using Ω.

Proof See Appendix C.

Remark 17 Let (cid:104)C1(cid:105), (cid:104)C2(cid:105), . . . , (cid:104)Cn(cid:105) be a derivation from a set of ordered clauses S using
{ρ1, ρ2}. Also, for any clause (cid:104)Ci(cid:105) in the derivation sequence, let fi denote the corresponding
feature-function as deﬁned in Sec. 2 using background knowledge B. Let a denote a data-
instance. We note the following consequences for 1 ≤ i < j ≤ n:

1. Ci subsumes Cj;5

2. If fi(a) = 0 then fj(a) = 0;

3. If fj(a) = 1 then fi(a) = 1; and

4. If (cid:104)Ci+1(cid:105) ∈ ρ1((cid:104)Ci(cid:105)), fi(a) = 1 and fi+1(a) = 0 then there exists a clause C(cid:48)

i+1 s.t.

Ci ≡ Ci+1 ∨ C(cid:48)

i+1 and fB,C(cid:48)

(a) = 1

i+1

(1) follows straightforwardly since for any (cid:104)Ci(cid:105), subsequent clauses in the derivation only
result in the addition of literals (that is, Ci ⊂ Cj for i < j). For (2), we note that since Ci ⊂
Cj and both Ci, Cj have the same head literal (p(X)) we can take Ci = ∀(p(X)∨l1∨· · · lk) and
Cj = ∀(p(X)∨l1 ∨· · · lk ∨lk+1 ∨· · · lm). If fi(a) = 0 then B ∪Ci (cid:54)|= p(a). That is, there exists
some interpretation I that is a model for B ∪ Ci s.t. p(a) is false in I. If I is a model for
B ∪Ci then it is a model for Ci. Further, if I is a model for Ci and p(a) is false in I then I is
a model for ∀(l1 ∨ · · · lk). But then I is a model for Cj = ∀(p(X) ∨ l1 ∨ . . . lk ∨ lk+1 ∨ · · · lm).
Thus I is a model for B ∪ Cj and not a model for p(a). That is, B ∪ Cj (cid:54)|= p(a) and
fj(a) = 0. (3) follows from the fact that if Ci subsumes Cj then Ci |= Cj (Gottlob, 1987).
Therefore, if B ∪ Cj |= p(a) then B ∪ Ci |= p(a). That is, if fj(a) = 1 then fi(a) = 1.
For (4), let Ci : p(X) ← Bodyi(X, Y). Then Ci+1 : p(X) ← Bodyi(X, Y), Yi = Yj for
yi,j ∈ Y. Since fi(a) = 1 and fi+1(a) = 0, it must be the case that Yi = Yj does not hold
for x = a. Let C(cid:48)
(a) = 1 and
Ci ≡ Ci+1 ∨ C(cid:48)
i+1.

i+1 : p(X) ← Bodyi(X, Y), Yi (cid:54)= Yj. It is evident that, fB,C(cid:48)

i+1

5. Here subsumption is used in the sense described by Plotkin (1972). That is, representing clauses of as

sets of literals, clause C subsumes clause D iﬀ there exists a substitution θ s.t. Cθ ⊆ D.

11

Srinivasan, Baskar, Dash, Shah

A specialised form of derivation results from the repeated use of ρ2 ﬁrst, followed by the
repeated use of ρ1. We call this form of derivation a linear derivation. We describe this
next (relevant proofs are in Appendix D).

Deﬁnition 18 (Linear Derivation of Feature-Clauses) Let M be a set of mode-declarations,
and M(cid:48) be an extension M as earlier. Let T be a set of type-deﬁnitions. Let Φ be a set of
feature-clauses in LM(cid:48),T and ρ1,2 be the operators deﬁned earlier. A sequence of feature-
clauses (cid:104)C1(cid:105), (cid:104)C2(cid:105), . . . , (cid:104)Cn(cid:105) is said to be a linear derivation sequence of (cid:104)Cn(cid:105) from Φ using
{ρ1, ρ2} iﬀ there exists j such that 1 ≤ j ≤ n and:

• For i ≤ j:

– Clause (cid:104)Ci(cid:105) in the sequence is either an element of Φ or an element of the set

ρ2((cid:104)Ci−1(cid:105), (cid:104)Ck(cid:105)) where (cid:104)Ck(cid:105) ∈ Φ and k < i.

• For i > j:

– Clause (cid:104)Ci(cid:105) is an element of the set ρ1((cid:104)Ci−1(cid:105)).

We will say (cid:104)Cj(cid:105) is linearly derivable from Φ using {ρ2}; and Cn is linearly derivable from
Φ using {ρ1, ρ2}.

Example 8 We continue Example 7. Below is a linear derivation sequence of p(X) ←
has car(X, U ), has car(X, V ), smaller(U, V ), has car(X, Y ), short(Y ), U = V, U = Y from
{p(X) ← has car(X, Y ), short(Y ), p(X) ← has car(X, U ), has car(X, V ), smaller(U, V )}
using {ρ1, ρ2}.

1
2
3

4

5

p(X) ← has car(X, U ), has car(X, V ), smaller(U, V )
p(X) ← has car(X, Y ), short(Y )
p(X) ← has car(X, U ), has car(X, V ), smaller(U, V )
has car(X, Y ), short(Y )
p(X) ← has car(X, U ), has car(X, V ), smaller(U, V ),

has car(X, Y ), short(Y ), U = V

p(X) ← has car(X, U ), has car(X, V ), smaller(U, V ),
has car(X, Y ), short(Y ), U = V, U = Y

Given
Given

1, ρ2

3, ρ1, U, V

4, ρ1, U, Y

Though there is no way to derive the clause p(X) ← has car(X, U ), has car(X, V ),
smaller(U, V ), U = V, has car(X, Y ), short(Y ), U = Y using linear derivation from the
given set, but we can derive an equivalent clause p(X) ← has car(X, U ), has car(X, V ),
smaller(U, V ), has car(X, Y ), short(Y ), U = V, U = Y using linear derivation.

Lemma 19 (Linear Derivation Lemma) Given M, M (cid:48) and a set of ordered clauses Φ.
An ordered clause (cid:104)C(cid:105) is derivable from Φ using {ρ1, ρ2} then there exists an equivalent
ordered clause (cid:104)C(cid:48)(cid:105) and it is linearly derivable from Φ using {ρ1, ρ2}.

Proof See Appendix C.

Feature-clauses and their composition using the ρ-operators provide the tools for the

development of a particular kind of neural network that we describe next.

12

Composition of Relational Features

3. Compositional Relational Machines (CRMs)

Formally, a CRM is deﬁned as follows:

Deﬁnition 20 (CRM) A CRM is a 7-tuple (V, I, O, E, φ, ψ, h) where:

• V denotes a set of vertices;

• I ⊆ V is a set of “input” vertices;

• O ⊆ V is a set of “output” vertices;

• E ⊆ {(vi, vj) : vi, vj ∈ V, vi (cid:54)∈ O, vj (cid:54)∈ I};

• A vertex-labelling function φ : V → FM × G, where FM is the set of feature-clauses
given a set of modes M; and G denotes a set of activation functions.6 In this paper,
we will further, if v ∈ I then we restrict φ(v) = (·, 1), where 1(·) = 1;

• An edge labelling function ψ : E → R, assigns some real-valued labels to edges in the

graph; and

• h : R|O| → Rn is a computation function, for some ﬁxed n

such that (V, E, φ(cid:48)) is a derivation graph given Φ where φ(cid:48)(v) = C if φ(v) = (C, ·) and
Φ = {φ(cid:48)(v) | v ∈ I}.

We note 2 important features of CRMs: (1) Each vertex has a feature-clause associated
with it; and (2) Edges between vertices in a CRM are required to satisfy the constraints on
edges imposed by a derivation graph. That is, the only edges allowed are those that result
from ρ1 or ρ2 operations on the feature-clauses associated with the vertices.

3.1 CRMs as Explainable Neural Networks

We describe a use of CRMs as a form of neural network capable of generating logical
explanations relevant to its prediction. The architecture of the neural network is inspired
by Turing’s idea of unorganised machines (Turing, 1948) (see Fig. 1). Each “neuron” has 2
parts, implementing the vertex-label speciﬁcation of a CRM’s node: (i) An arithmetic part
that is concerned with the g-function in the CRM’s vertex-label; and (ii) A logical part that
acts as switch, depending on the feature-clause associated with the CRM’s vertex-label. We
call neurons in such a network “arithmetic-logic neurons” or ALNs for short.

In the rest of the paper, we will use “CRM” synonymously with this form of neural-
network implementation. The 7-tuple deﬁning a CRM (V, I, O, E, φ, ψ, h) corresponds to
the following aspects of the neural implementation: (a) The structure of the network is
deﬁned by V, I, O, E, and φ; (b) The parameters of the network is deﬁned by ψ; and (c) the
computation of the network is deﬁned by h. We consider each of these in turn.

13

Srinivasan, Baskar, Dash, Shah

Figure 1: A neural network implementation of a CRM inspired by Turing’s gated neural
networks (Turing, 1948). A neuron ni corresponds to a vertex vi in the CRM, with vertex-
label ψ(vi) = (Ci, gi). In the ﬁgure, ni is connected to neurons nj and nk, implying (vj, vi)
and (vk, vi) are in the edge-set of the CRM. fi (correctly fCi,B) is the feature-function
obtained from the feature-clause Ci (see Sec. 2), and acts as a gate. For a data instance a,
gi(wjihj(a) + wkihk(a)) passes through the gate if and only fi(a) = 1. In general, hi(a) is
thus gi((cid:80)
k=P red(ni) wkihk(a)) or 0, where P red(ni) is the set of immediate predecessors of
ni in the neural network.

3.1.1 Structure Selection

Procedure 1 is an enumerative procedure for obtaining a 5-tuple (V, I, O, E, φ), given a set
of feature-clauses Φ. For simplicity, the procedure assumes a single activation function g.

Procedure 1 has an important practical diﬃculty:

• We are interested in a class of CRMs that we call in which {C1, . . . , Cn} consists
of M-simple feature-clauses. Now, it may be impractical to obtain all possible M-
simple feature-clauses in a mode-language. Even if this were not the case, it may be
impractical to derive all non-simple clauses in the manner shown in Procedure 1.

Procedure 2 describes a randomised implementation to address this. The procedure also
uses the result in the Linear Derivation Lemma to construct a CRM structure that ﬁrst
uses the ρ2 operator, followed by the ρ1 operator.
In the rest of the paper, we will use the term Simple CRM to denote a CRM constructed by
either Procedure 1 or Procedure 2 in which the input clauses C1, C2, . . . , Cn are M-simple
feature-clauses.

3.1.2 Parameter Estimation

Procedure 2 does not completely specify a CRM. Speciﬁcally, neither the edge-labelling ψ
nor h are deﬁned. We now describe a procedure that obtains a ψ given the partial-speﬁcation
returned by Procedure 2 and a pre-speciﬁed h suitable for the usual task of using the neural
network for function approximation. That is, given a partial speciﬁcation of an unknown
function δ : A → Y of in the form of sample data D = {(ai, yi)}N
1 . We want the the neural
network to construct an approximation ˆδ : A → Y that is reasonably consistent with D. In

6. We assume activation functions in G are R → R.

14

Composition of Relational Features

Procedure 1: (ConstructCRM) Depth-bounded construction of a CRM’s struc-
ture

Input: A set Φ of feature-clauses {C1, C2, . . . , Cn} with heads p(X) and all other
variables are standardised apart from each other; an activation function g;
and a bound d on the depth of composition

Output: A CRM structure

1 I = {v1, v2, . . . , vn};
2 V = I;
3 E = ∅;
4 for i = 1 to n do
φ(vi) = (Ci, 1)
5
6 for j = 1 to d do
7

8

9

10

11

12

13

Vj,1 = {(C(cid:48), v) : v ∈ V, φ(v) = (C, ·), C(cid:48) = ρ1(C)};
Vj,2 = {(C(cid:48), v1, v2) : v1,2 ∈ V, φ(v1) = (C1, ·), φ(v2) = (C2, ·), C(cid:48) = ρ2(C1, C2)};
Let V1 be a set of new vertices v s.t. there exists (C(cid:48), v(cid:48)) ∈ Vj,1 and
φ(v) = (C(cid:48), g);
Let V2 be a set of new vertices v s.t. there exists (C(cid:48), v1, v2) ∈ Vj,2 and
φ(v) = (C(cid:48), g);
Let V (cid:48) = V1 ∪ V2;
V = V ∪ V (cid:48);
E = E ∪ {(v1, v) : (C, v1) ∈ Vj,1, φ(v) = (C, g)} ∪
{(v1, v), (v2, v) : (C, v1, v2) ∈ Vj,2, φ(v) = (C, g)};

14 O = {v : v ∈ V, (cid:64)v(cid:48)s.t.(v, v(cid:48)) ∈ E};
15 return (V, I, O, E, φ)

order to estimate the goodness of the approximation, we need to deﬁne a loss function, that
computes the penalty of using ˆδ. We will take ˆδ to be synonymous with h, the computation
function of the CRM. Recall h : R|O| → Rn for some ﬁxed n. In this paper, we will therefore
take Y = Rn and deﬁne h in the usual manner adopted by neural networks, namely as a
function of “local” computations performed at each of the O vertices of the CRM:

Deﬁnition 21 (Local Computation in a CRM) Let (V, I, O, E, φ, ψ) be a partially-speciﬁed
CRM, where O = {o1, o2, . . . , ok}. For each vertex vi ∈ V let φ(vi) = (Ci, gi) and for each
edge (vi, vj) ψ((vi, vj)) = wij. Let fi denote fCi. For any a ∈ A we deﬁne hi : A → R as
follows:

hi(a) = fi(a)

if vi ∈ I

= fi(a)gi





(cid:88)

(vj ,vi)∈E



wjihj(a)



if vi (cid:54)∈ I

Then ˆδ(a) = h(ho1(a), . . . , hok (a)). For the task of classifying instances from A into one

of n classes, an example h computes the probability vector for the classes.

15

Srinivasan, Baskar, Dash, Shah

Procedure 2: (RandomCRM) Randomised construction of a CRM structure,
with linear derivation of feature-clauses.

Input: A set Φ of feature-clauses {C1, C2, . . . , Cn} with heads p(X) and all other
variables are standardised apart from each other; an activation function g;
a sample size s; bounds dρ1, dρ2 on the depth of application of the ρ1 and
ρ2 operators
Output: A CRM structure

1 I = {v1, v2, . . . , vn};
2 V0 = I;
3 V = V0;
4 E = ∅;
5 for i = 1 to n do
φ(vi) = (Ci, 1);
6
7 for j = 1 to dρ1 + dρ2 do
8

Vj = ∅;
Ej = ∅;
if j ≤ dρ2 then
op = ρ2;

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

else

op = ρ1;
for i = 1 to s do

if op = ρ2 then

Sample a vertex v1 from I using a uniform distribution and sample a
vertex v2 from Vj−1 using the uniform distribution;
Create a vertex v(cid:48) such that φ(v(cid:48)) = (C(cid:48), g) where C(cid:48) = ρ2(C1, C2),
φ(v1) = (C1, g) and φ(v2) = (C2, g);
Vj = Vj ∪ {v(cid:48)};
Ej = Ej ∪ {(v1, v(cid:48)), (v2, v(cid:48))};

else

Sample a vertex v from Vj−1 using the uniform distribution;
Create a vertex v(cid:48) such that φ(v(cid:48)) = (C(cid:48), g) where C(cid:48) = ρ1(C) and
φ(v) = (C, g);
Vj = Vj ∪ {v(cid:48)};
Ej = Ej ∪ {(v, v(cid:48))};

V = V ∪ Vj;
E = E ∪ Ej;

26
27 O = {v : v ∈ V, (cid:64)v(cid:48)s.t.(v, v(cid:48)) ∈ E};
28 return (V, I, O, E, φ);

Procedure 3 estimates the parameters of the neural-network using a standard weight-
update procedure based on stochastic gradient descent (SGD) (Rumelhart et al., 1986),
given the structure obtained from Procedure 2 and a pre-deﬁned h

16

Composition of Relational Features

Procedure 3: (TrainCRM) Parameter estimation of a CRM, given its structure,
using stochastic gradient descent (SGD). The training is done until some stopping
criterion is reached, which refers to the condition when the number of training
epochs reaches some pre-speciﬁed maximum value.

Input: A CRM structure γ = (V, I, O, E, φ), a dataset D = {(ai, yi)}N

1 , where

ai ∈ A and yi ∈ Rn, a computation function h : R|O| → Rn, a loss function
L : Rn × Rn → R.

Output: A CRM
1 Let O = {o1, . . . , ok};
2 Initialise ψ;
3 while stopping criterion is not met do
4

5

6

Randomly draw an instance (ai, yi) from D;
Let ˆyi = h(ho1(a), . . . , hok (a)) (see Defn. 21);
Error = L(yi, ˆyi);
Update ψ using SGD to minimise Error;

7
8 return (V, I, O, E, φ, ψ, h);

3.1.3 Predictions and Explanations
We denote the prediction of a CRM γ = (V, I, O, E, φ, ψ, h) by ˆδ(a) = h(ho1(a), . . . , hok (a)),
where O = {o1, . . . , ok} and the hoi are as deﬁned in Defn. 21.

The association of feature-clauses with every vertex of the CRM allows us to construct
“explanations” for predictions. For this we introduce the notion of ancestral graph of a
vertex in a CRM.

Deﬁnition 22 (Ancestral Graph of a Vertex) Let γ = (V, I, O, E, φ, ψ, h) be a CRM.
The ancestors of a vertex v ∈ V in γ is

Ancestors(v, γ) =

(cid:40)

(cid:83)

{v}

if v ∈ I
(u,v)∈E Ancestors(u, γ) ∪ {v} otherwise

The ancestral graph of a vertex v in γ is (V (cid:48), E(cid:48)) where V (cid:48) = Ancestors(v, γ) and

E(cid:48) = {(u(cid:48), u(cid:48)(cid:48)) : u(cid:48), u(cid:48)(cid:48) ∈ V (cid:48), (u(cid:48), v(cid:48)(cid:48)) in E}.

We can now associate an ‘explanation graph’ with any of an output vertex.

Deﬁnition 23 (Explanation Graph) Let γ = (V, I, O, E, φ, ψ, h) be a CRM, and a ∈
A be a data instance. Let O = {o1, . . . , ok} and let ˆδ(a) = h(ho1(a), . . . , hok (a)) be the
prediction of the CRM for a. For oi ∈ O, let Ci be the feature-clause associated with oi
(that is, φ(oi) = (Ci, ·)). Let fi be the corresponding feature-function (as deﬁned in Sec.2),
and (V (cid:48), E(cid:48)) be an ancestral graph of oi in γ. Then the explanation graph a from o, denoted
by Explainγ,o(a), is as follows:

Explainγ,o(a) =

(cid:40)

(V (cid:48), E(cid:48), φ(cid:48))
∅

if fi(a) = 1
otherwise

17

Srinivasan, Baskar, Dash, Shah

where φ(cid:48) : V (cid:48) → FM is a vertex-labelling function. φ(cid:48)(v) = Cθa, where θa the substitution

{X/a} for the variable X in the head literal and φ(v) = (C, ·).

Remark 24 Explainγ,o(a) consists of a (labelled) tree of feature-clauses extracted from the
derivation graph of feature-clauses. The root of the tree is the feature-clause at o and sub-
trees contain simpler feature-clauses. If the CRM is a Simple CRM, then the leaves of the
explanation-tree are M-simple feature-clauses.

Example 9 In the Trains problem, suppose the data instance is the train shown on the left
below. The explanation graph associated with an output vertex of the CRM is shown on the
right.

(Train t1)

(additionally requires the substitution {X/t1}
to be applied)

By deﬁnition, we know that the feature-function value associated with p(t1) ← has car(t1, A),

short(A), has car(t1, B), closed(B) has the value 1. Also, we know that feature-function
values with all other clauses in the explanation will also be 1.

The notion of an explanation graph from a vertex extends naturally to the explanation graph
from a set of vertices which we do not described here. It will be useful in what follows to
introduce the notion of a feature-clause being “contained in an explanation graph.

Deﬁnition 25 (Feature-clause Containment) Let γ be a CRM, o be an output vertex
of γ, Let a be a data instance, Let Explainγ,o(a) = (V, E, α), and Fγ,o(a) = {α(v) | v ∈ V }
be the set of feature-clauses in the explanation graph. We will say a feature-clause C is
contained in the Explainγ,o(a), or C (cid:118) Explainγ,o(a) iﬀ there exists C(cid:48) ∈ Fγ,o(a) s.t.
Cθa ≡ C(cid:48) (where θa = {X/a}, is a substitution for the variable X in the head of C).

(This naturally extends to the containment of a set of clauses.)

Example 10 The feature-clause C : p(X) ← has car(X, Y ), short(X), closed(X) is con-
tained in the explanation graph shown for train t1 in Fig. 6 because:

18

Composition of Relational Features

• Fγ,o(t1) = {C1, C2, C3, C4} where:

C1 : (p(t1) ← (has car(t1, A), short(A), has car(t1, B), closed(B), A = B);
C2 : (p(t1) ← (has car(t1, A(cid:48)), short(A(cid:48)), has car(t1, B(cid:48)), closed(B(cid:48)));
C3 : (p(t1) ← (has car(t1, A(cid:48)(cid:48)), short(A(cid:48)(cid:48))); and
C4 : (p(t1) ← (has car(t1, A(cid:48)(cid:48)), closed(A(cid:48)(cid:48))

• With θa = {X/t1}, Cθa = (p(t1) ← (has car(t1, A), short(A), closed(A)); and

• Cθa ≡ C1

Explanatory Fidelity

Explanatory ﬁdelity refers to how closely the CRM’s explanation matches the “true expla-
nation”. Of course, in practice, explanatory ﬁdelity will be a purely notional concept, since
the true explanation will not be known beforehand. However it is useful for us to calibrate
the CRM’s explanatory performance when it is used for problems where true explanations
are known (the synthetic problems considered in experiments below are in this category).
For a prediction ˆδ(hoi(a), . . . , hok (a)) by a CRM, suppose we have a relevance ordering
over the output vertices o1, . . . , ok. Let o∗ be the most relevant vertex in this ordering.
Then we will call the explanation graph from o∗ as the most-relevant explanation graph for
a given the CRM.7

For a classiﬁcation task, we use clause containment and the most-relevant explanation
graph to arrive at a notion of explanatory ﬁdelity of a CRM to a set of feature-clauses Tc
that are known to be ‘acceptable’ feature-clauses for class c (if no such acceptable clauses
exist for class c, then Tc = ∅). Let γ be a CRM used to predict the class-labels for a set
of data-instances. For any instance a, let o∗ denote the most relevant output vertex of the
CRM. We will say that the a data instance a is consistently explained iﬀ: (i) the CRM
predicts that a has the class-label c; and (ii) there exists a C ∈ Tc s.t. C (cid:118) Explainγ,o∗(a);
and (iii) for c(cid:48) (cid:54)= c, there does not exist C(cid:48) ∈ Tc(cid:48) s.t. C(cid:48) (cid:118) Explainγ,o∗(a).

Given a set of data-instances E, let CE denote the set of instances in E consistently
explained and IE denote the set of instances in E not explained consistently. Then the
explanatory ﬁdelity of the CRM (correctly, this is only deﬁnable w.r.t. the Tc’s) is taken to
be

|CE|+|IE| , provided (|CE| + |IE|) (cid:54)= 0 (and undeﬁned otherwise).

|CE|

3.2 CRMs as Explanation Machines

CRMs can be used as ‘explanation machines’ for black-box predictors that do not intrinsi-
cally include an explanatory component. The approach, sometimes called post hoc expla-
nation generation, is shown in Fig. 2.

To assess the utility of using the CRM in this manner, we will change the usual from
the usual assessment of predictive accuracy to one of ‘predictive ﬁdelity’, which refers to
how closely the CRM matches the prediction of the target model.

7. In implementation terms, one way to obtain such a relevance ordering over output vertices of the CRM
is to use the hi(·) values for vertices in O to select a vertex o∗ that has the highest magnitude (this is
the same as selecting the best vertex after one iteration of the layer-wise relevance propagation, or LRP,
procedure).

19

Srinivasan, Baskar, Dash, Shah

Figure 2: Using a CRM as an explanation machine. The target model is a “black box”
that does not have an explanatory output. The CRM model is trained using training data
labelled with the prediction from the black box (and not the ‘true label’). The multi-
plexer (MUX) selects between the CRM’s explanation graph and the “empty” explanation
∅ depending on whether the CRM’s prediction does or does not match the target model’s
prediction. By using the setup as shown here, we are able to get a prediction P and a
corresponding explanation E.

4. Empirical Evaluation of CRMs as Explanation Machines

4.1 Aims

We consider two kinds for experiments with Simple CRMs:

Synthetic data. Using tasks for which both target-model predictions and acceptable feature-

clauses are available, we intend to investigate the hypothesis that: (a) Simple CRMs
can construct models with high predictive ﬁdelity to the target’s prediction; and (b)
Simple CRMs have high explanatory ﬁdelity to the set of acceptable feature-clauses.

Real data. Using real-world datasets, for which we have predictions from a state-of-the-art
black-box target model, we investigate the hypothesis that Simple CRMS can con-
struct models with high predictive ﬁdelity to the target’s prediction. We also provide
illustrative examples of using the CRM to provide explanations for the predictions.

We clarify what is meant by ‘acceptable feature-clauses’ for the synthetic data in Sec. 4.3.
For real data, the target-model is the state-of-the-art (SOTA, which in this case is a graph-
based neural network). That is, the CRM is being used here to match the SOTA’s pre-
dictions (and not the ‘true value’), and to provide proxy explanations. No acceptable
feature-clauses are known for classes in the real data.8

4.2 Materials

4.2.1 Data and Background Knowledge

Synthetic Data. We use 2 well-known synthetic datasets. The ﬁrst dataset is the “Trains”
problem of discriminating between eastbound (class = +) and westbound trains (class

8. The CRM can of course be used to predict the true value directly. We will comment on this later, but

that is not the primary goal of the experiment here.

20

Composition of Relational Features

= −) (Michalski, 1980). The original data consists only of 10 instances (5 in each
class). We generate a dataset of 1000 instances with a class-disitribution of approx-
imately 50% + and 50% −, using the data generator (Michie et al., 1994). We use
700 instances as training data and 300 instances as test-data. The second dataset
consists of the task of discriminating between illegal (class = +) and legal (class =
−) chess positions in the King-Rook-King endgame (Bain, 1994; Michie, 1976). The
class-distribution is approximately 33% + and 67% negatives. We use 10000 instances
of board-positions as training data and 10000 instances as test-data. Examples of +
instances are showed pictorially in Fig.3.

Trains

Chess

Figure 3: Pictorial examples of positive instances in the synthetic data. The actual data are
logical encodings of examples like these. The instance on the left is an example of a train
classiﬁed as “eastbound” (+). The instance on the right is of a board position classiﬁed as
“illegal” (+), given that it is White’s turn to move. For both problems, we have a target
model that complete and correct. We also know a set of feature-clauses that are acceptable
as explanations for instances that are correctly predicted as +.

Real Data. Our real data consists of 10 datasets obtained from the NCI9. Each dataset
represents extensive drug evaluation with the concentration parameter GI50, which
is the concentration that results in 50% growth inhibition of cancer cells Marx et al.
(2003). A summary of the dataset is presented in Fig. 4. Each relational data-instance
in a dataset describes a chemical compound (molecule) with atom-bond representa-
tion: a set of bond facts. The background-knowledge consists of logic programs deﬁn-
ing almost 100 relations for various functional groups (such as amide, amine, ether,
etc.) and various ring structures (such as aromatic, non-aromatic etc.). There are
also higher-level domain-relations that determine presence of connected, fused struc-
tures. Some more details on the background-knowledge can be seen in these recent
studies: (Dash et al., 2021, 2022).

9. The National Cancer Institute (https://www.cancer.gov/)

21

Srinivasan, Baskar, Dash, Shah

# of

Avg. # of

Avg. # of

Avg. # of

% of

datasets

instances

atoms per instance

bonds per instance

positives

10

3018

24

51

50–75

Avg.= 57

Figure 4: Summary of the NCI-50 datasets (Total no. of instances is approx. 30,200). The
graph neural network predictor described in Dash et al. (2021) is taken as the target model.
No acceptable feature-clauses are known for these tasks.

4.2.2 Algorithms and Machines

We use Prolog for constructing the feature-clauses. The CRMs are implemented using
PyTorch (Paszke et al., 2019). The parameter learning of CRMs has been done with the
autograd engine available within PyTorch for implementation of backpropagation. Our
Layerwise-Relevance Propagation (LRP) implementation is based on (Bach et al., 2015;
Binder et al., 2016).

The CRM implementation and experiments are conducted on a workstation running with
Ubuntu (Linux) operating system, 64GB main-memory, Intel CPU with 12-Xeon processors.

4.3 Method

The experiments are in two parts: an investigation on synthetic data to examine the pre-
dictive performance and explanatory ﬁdelity of CRMs; and an investigation on real data, to
compare the predictive performance of CRMs against state-of-the-art deep networks. Some
examples are also provided of the kinds of explanations generated on real data. We describe
the method use for each part in turn.

4.3.1 Experiments with Synthetic Data

For both synthetic datasets, we have access to symbolic descriptions of the true concepts
involved. The ‘target model’ in each case is taken to be equivalent to a classiﬁer that labels
instances consistent with the corresponding true concept. This allows us judge the ﬁdelity
of explanations generated. The method used in each case is straightforward:

For each problem:

(a) Construct the dataset D of instances labelled by the target model;

(b) Generate a subset of M-simple feature-clauses in the mode-language for the prob-

lem;

(c) Randomly split D into training and test samples;

(d) Construct a CRM using Procedure 2 with the M-simple features. The weights for
the CRM are obtained using the training data and the SGD-based weight-update
procedure described earlier (see below for additional details);

(e) Obtain an estimate of the predictive and the explanatory ﬁdelity of the CRM

using the test data (again, see below for details)

22

Composition of Relational Features

The following additional details are relevant to the method just described:

• For both datasets, the composition depth of CRMs is at most 3. Also, the mode-
declarations for Chess allow the occurrence of equalities in M-simple features Ap-
pendix F), additional compositions using ρ1 are not used this problem;

• We use Adam optimiser (Kingma and Ba, 2015) to minimise the training cross-entropy

loss between the true classes and the predicted classes by the network;

• We provide as input feature-clauses only a subset of all possible M-simple feature-
clauses. The subset is constrained by the following: (i) At most 2 body literals; (ii)
Minimum support of at least 10 instances; and (iii) Minimum precision of at least 0.5.
All subsequent feature-clauses obtained by composition are also required to satisfy the
same support and precision constraints. The learning rate for the Adam optimiser is
set to 0.001 while keeping other hyperparameters to their defaults within PyTorch;

• The number of training epochs is set to 5 for the Trains dataset and 10 for the Chess

dataset;

• Both synthetic problems are binary classiﬁcation tasks. We call the classes + and −
for convenience. Predictive accuracy is estimated in the usual manner, namely as the
proportion of correctly predicted test-instances;

• Explanatory ﬁdelity is estimated as described in earlier. For this, we need to pre-
deﬁne sets of feature-clauses that are acceptable in explanations. For the synthetic
datasets, we are able to identify sets of acceptable feature-clauses from the literature:
These feature-clauses are obtained from a target model that is known to be complete
and correct (see (Michie et al., 1994) for the target model for Trains and (Bain, 1994)
for Chess). The acceptable clauses in T+ are as follows;

Problem Acceptable Feature Clause

Trains

p(X) ← has car(X, Y ), short(X), closed(X)

Chess

p((A, B, C, D, C, E)) ← true

p((A, B, C, D, E, D)) ← true

p((A, B, A, B, C, D)) ← true

p((A, B, C, D, E, F )) ← adj(A, E), adj(B, F )

In Trains, the feature clauses apply to descriptions of trains. For Chess these are de-
scriptions of the board in an endgame. The board is a 6-tuple that denotes the ﬁle and
rank of the position of the White King, White Rook and Black King respectively. In all
cases T− = ∅. Explanatory ﬁdelity will be estimated by checking clause-containment
of the feature-clauses above in the explanation graph for the most-relevant output
vertex of the CRM (see Sec.3.1.3);

• The acceptable feature-clause for the Trains is a direct rewrite of the function used
to generate the labels. For Chess, the (set of) feature-clauses are direct rewrites
of an approximate symbolic description taken from (Srinivasan et al., 1992). These

23

Srinivasan, Baskar, Dash, Shah

approximate description isn’t identical to the correct description, but is very closely
related to it (the approximation diﬀer from the correct description only in about 40
of 10,000 cases). For our purposes therefore, high explanatory ﬁdelity w.r.t. the set
of feature-clauses shown will taken to be suﬃcient; and

• We provide a baseline comparison for predictive ﬁdelity against a ‘majority class’
predictor. A baseline comparison is also provided for explanatory ﬁdelity against ran-
dom selection of a feature-clauses from the set of feature-clauses that have a feature-
function value of 1 for the data instance being predicted.

4.3.2 Experiments with Real Data

For the real-world datasets, the current state-of-the-art predictions are from a Graph Neural
Network (GNN) constructed using the background knowledge described earlier (Dash et al.,
2022). However, the GNN model constitutes a black-box model, since it does not produce
any explanations for its predictions. We investigate equipping this black-box model with
CRM model for explanation. The method is as follows:

For each problem:

(a) Construct the dataset D consisting of problem instances and their predictions of

the target model;

(b) Generate a subset of M-simple feature-clauses in the mode-language for the prob-
lem. The restrictions used for synthetic data are used to constrain the subset;

(c) Construct a CRM using Procedure 2 with the M-simple features and the data
D. The weights for the CRM are obtained using the training data used by the
state-of-the-art methods and the SGD-based weight-update procedure; and

(d) Obtain the predictive ﬁdelity of the CRM model to the predictions of the target

model.

The following additional details are relevant:

• As with the synthetic data, the compositional depth for the CRMs is 3. Again, we do
not use ρ1 operations, since the mode-declarations allow equalities. The constraints
on input feature-clauses is the same as those used for synthetic data;

• The CRM implementation is the same as the one used for synthetic data. We perform
a grid-search of the learning rate for the Adam optimiser using the parameter grid:
{0.01, 0.001, 0.005, 0.0001}. The total number of training epochs is 10, with early-
stopping mechanism (Prechelt, 1998) with a patience period of 3;

• As with the synthetic data, we provide a baseline comparison against the ‘majority

class’ predictor;

• Unlike the synthetic data, no pre-deﬁned set of acceptable feature-clauses exists, and
therefore no estimate of explanatory ﬁdelity is possible. Correspondingly, there is no
baseline provided either.

24

Composition of Relational Features

4.4 Results

Figure 5 tabulates the results used to compute estimates of predictive and explanatory ﬁ-
delity on synthetic and real data. The main details in these tabulations are these: (a) For
the synthetic data, Simple CRMs models able to match the target’s prediction perfectly
(predictive ﬁdelity of 1.0); (b) The high explanatory ﬁdelity values show that for instances
labelled +, the maximal explanation for the most-relevant vertex contains at least 1 clause
from the set of acceptable feature-clauses; and for instances labelled −, the maximal ex-
planation of the most relevant vertex does not contain any clauses from the target theory;
and (c) On the real datasets predictive ﬁdelity of CRMs is reasonably high: suggesting that
about 81% of the time, the CRM prediction will match that of the state-of-the-art model.

Dataset

Pred. Fidelity

CRM

Baseline

786 0

A498

Dataset

Fidelity

A549 ATCC

CRM

Baseline

Pred. Expl. Pred. Expl.

Trains

Chess

1.0

1.0

1.0

0.9

0.5

0.7

0.4

0.7

(a) Synthetic data

ACHN

BT 549

CAKI 1

CCRF CEM

COLO 205

DLD 1

DMS 114

0.77

0.79

0.85

0.73

0.78

0.81

0.82

0.77

0.90

0.89

0.53

0.59

0.63

0.58

0.51

0.69

0.68

0.53

1.00

0.91

Avg.

0.81 (0.05)

0.66 (0.17)

(b) Real data

Figure 5: Estimates of ﬁdelity for Simple CRMs on the synthetic datasets and real datasets.
Explanatory ﬁdelity is assessable on synthetic data since we have access to the “correct”
explanation. Baseline for prediction is the majority class predictor. For explanations,
Baseline refers to random selection of a feature-clause with function-value 1 for instances
consistently explained by the CRM.

We now turn to examine the results in greater detail.

4.4.1 Predictive Fidelity

Although we obtain perfect predictive ﬁdelity to the target model on synthetic data, ﬁdelity
on the real data sets clearly has room for improvement. Improvements in ﬁdelity are possible
simply by considering ensembles of CRMs, obtained simply due to the sampling variation
arising in Step (3). Below, we tabulate changes in predictive ﬁdelity on 1 of the real-world
problems (786 0), using a sample consisting of upto 3 CRMs. With multiple CRMs, for a
data-instance to be correctly predicted it is suﬃcient for any one of the CRMs to predict the

25

Srinivasan, Baskar, Dash, Shah

same class as the target-model. Recall the primary purpose of the CRM is to explain the
target-model’s prediction in terms of its feature-clauses. Any CRM that matches the target-
model’s prediction can be used to explain the prediction. More on this under “Explanation”
below.

No. of Predictive

CRMs

Fidelity

1

2

3

0.75

0.83

0.85

4.4.2 Explanatory Fidelity

For the synthetic datasets we show below in Fig. 6 a representative + instance (shown
pictorially or ease of understanding), along with the predictions of both target and the CRM.
The last column shows an acceptable feature-clause along with a stylised English translation.
In both instances, an equivalent form of the acceptable feature-clause is contained in the
CRM’s explanation graph.

For the Chess data, the CRM’s explanatory ﬁdelity is less than 1. This means that there
are instances for which the CRM’s explanation graph does not contain an acceptable feature-
clause. We ﬁnd 19 diﬀerent kinds of ‘buggy’ explanations are found by the CRM: a full
listing is in Appendix F. Here we provide illustrative instances of two kinds of errors: those
that are close to the correct explanation; and those that are an artifact of the speciﬁc data
instance being explained (Fig. 7). Besides these, in many cases, we ﬁnd explanation errors
arise from the fact that deﬁnitions in background knowledge of ﬁle and rank adjacency holds
when ranks and ﬁles are the same (that is, if A and B are ranks (or ﬁles) and A = B, then
adj(A, B) is true).10 In many instances inconsistent explanations result from feature-clauses
contain literals that use equality instead of adjacency (that is, the CRM’s explanation
contains A = E, rather than adj(A, E): see Section F.2)). However, even accounting for
this, the CRM’s explanations can be more speciﬁc than the correct explanation; and in
some cases, incorrect (an example of each is shown in Fig. 7).

What about explanations on real data? At this point, we do not have any independent
source of acceptable feature-clauses for this data. We nevertheless show a representative
example of the explanation for a test-instance (Fig. 8).

We close this examination by drawing the reader’s attention to an important aspect
of a CRM’s explanation. The feature-clauses are deﬁned in terms of relations provided as
prior knowledge. This makes them potentially intelligible to a person familiar with the
meanings of these relations. This makes it easier–in principle at least–to perform a human-
based assessment of the feature-clauses in the explanation graph (this is apparent from the
‘debugging’ of explanations that we have been to accomplish with the Chess data).

10. M. Bain, the author of the background deﬁnitions, conﬁrms that this is the intended meaning of the

adj/2 predicate for this problem (personal communication).

26

Composition of Relational Features

Instance

Explanation

Graph

Acceptable

Feature Clause

Train t1

(With the substitution {X/t1})

p(X) ← has car(X, Y ),
aaa short(Y ), closed(Y )

Train X has a car Y and
Y is short and closed.

p((A, B, C, D, C, E)) ←

White Rook and Black
King are on the same ﬁle
(column)

Board
(d, 7, e, 1, e, 6)

(With the substitution {A/d, B/7, . . . , F/6})

Figure 6: Explanations from the CRMs for a + prediction by both target-model and the
CRM for two instances in the synthetic data. In both cases, the CRM’s explanation graph
contains an acceptable feature-clause (circled).

27

Srinivasan, Baskar, Dash, Shah

Instance

Explanation

Graph

Acceptable

Feature-Clause

p((A, B, C, D, E, F )) ←
aaaadj(A, E), adj(B, F )

White King’s ﬁle is adja-
cent to Black King’s ﬁle
and White King’s rank is
adjacent to Black King’s
rank

Figure 7: Examples where the target model and the CRM’s prediction are both +, but the
CRM’s explanation graph does not contain an acceptable feature-clause. For simplicity, we
do not show the substitutions for A . . . F .

4.4.3 Additional Results: CRMs as Prediction Machines

The tabulations of ﬁdelity and the subsequent assessments above provide a measure of
conﬁdence in the use of CRMs as explanation machines. But it is evident that CRMs can
be used as ‘white-box’ predictors in their own right. We provide an indicative comparison
of a CRM predictor against the state-of-the-art predictors (for the real-data, the prediction
is by majority-vote from an ensemble of 3 CRMs):

The results in Fig. 9 indicate that Simple CRMs perform approximately as well as
CILP++, but are worse than either the GNN or DRM. However, Fig. 9 are best treated
as preliminary. Variations in CRMs arise in Procedure 2 purely due to sampling, of course.
However, the CRM obtained is also aﬀected by the following: (1) The subset constraints on
support and precision all feature-clauses in the CRM; (2) bounds on the depth of composi-
tions ρ2 followed by ρ1 operators; (3) The number of feature-clauses drawn in each layer of
the CRM. Additional variation can arise from the initialisation of weights for the SGD-based
estimation of parameters. This suggests that substantially more experimentation is needed
to see if the predictive performance of Simple CRMs can be improved. We note also that
that the DRM uses substantially more complex features than the Simple CRM, and that

28

Composition of Relational Features

Instance

Explanation Graph

Figure 8: A CRM explanation for a prediction on the real data. The class-label predicted
by both CRM and the black-box model for this data instance is +.

Dataset

Predictive accuracy

CRM

GNN

DRM

(500)

CILP++

Baseline

786 0

A498

0.66 (0.01)

0.69 (0.01)

0.69 (0.01)

0.67 (0.01)

0.55 (0.01)

0.67 (0.01)

0.72 (0.01)

0.70 (0.01)

0.66 (0.01)

0.52 (0.01)

A549 ATCC 0.64 (0.01)

0.67 (0.01)

0.70 (0.01)

0.60 (0.01)

0.51 (0.01)

ACHN

0.64 (0.01)

0.70 (0.01)

0.70 (0.01)

0.64 (0.01)

0.51 (0.01)

BT 549

CAKI 1

0.66 (0.01)

0.68 (0.01)

0.70 (0.01)

0.65 (0.01)

0.53 (0.01)

0.63 (0.01)

0.68 (0.01)

0.66 (0.01)

0.64 (0.01)

0.54 (0.01)

CCRF CEM 0.65 (0.01)

0.71 (0.01)

0.71 (0.01)

0.68 (0.01)

0.63 (0.01)

COLO 205

0.60 (0.01)

0.69 (0.01)

0.67 (0.01)

0.66 (0.01)

0.56 (0.01)

DLD 1

0.69 (0.02)

0.69 (0.02)

0.70 (0.02)

0.72 (0.02)

0.69 (0.02)

DMS 114

0.68 (0.02)

0.74 (0.02)

0.75 (0.02)

0.75 (0.02)

0.76 (0.02)

Figure 9: Predictive performance comparison of an ensemble of 3 Simple CRMs against
some leading black-box predictors. The numbers are estimates of predictive accuracy ob-
tained on test data. The number in parentheses is the estimated standard deviation. The
techniques being compared are: GNN, the graph-based neural network approach described
in (Dash et al., 2022); DRM (500), is a form of MLP called a Deep Relational Machine that
has as input Boolean feature-vectors resulting from a stochastic selection of 500 relational
features (Dash et al., 2019); and CILP++, an MLP that has input Boolean feature-vectors
resulting from an exhaustive feature construction technique called Bottom-Clause Proposi-
tionalisation. Baseline is the majority class predictor.

CILP++ constructs substantially more features than the Simple CRM (anywhere between
30,000 to 50,000 compared to about 330 M-simple features for the CRMs). Of course none

29

Srinivasan, Baskar, Dash, Shah

of GNN, DRM or CILP++ have any intrinsic mechanism of associating explanations with
their prediction.

5. Related Work

We note ﬁrst that ρ1 and ρ2 are closely related to the notion of reﬁnement operators which
have been studied extensively in ILP, in the context of the search through a hypothesis
space (see (Nienhuys-Cheng et al., 1997)). Our motivation in this paper is however in the
use of these operators to derive relational features. Consequently, we describe connections
to related work in 3 categories: conceptual work on relational features; implementation and
applied work on propositionalisation in ILP; and work on explainable deep networks.

On the conceptual understanding of relational features, perhaps the most relevant single
summary is in (Saha et al., 2012). There the authors identify several feature-classes, based
on somewhat similar notions of source- and sink-literals. The relationship between the
diﬀerent classes in that paper is shown in Fig. 10(a). The relationship to these sets of
the class of M-simple feature-clauses, denoted here as FM, is shown in Fig. 10(b) (see
Appendix E for more details).

Figure 10: The feature classes proposed in (Saha et al., 2012): (a) and the relationship to
the class of M-simple features (b).

Simple clauses in (McCreath, 1999) and the corresponding set of features in Fs are
restricted to determinate predicate-deﬁnitions11 Results in McCreath (1999) show that fea-
tures from Fs can be used to derive the subset of feature-clauses in Fd that only contain
determinate predicate-deﬁnitions. There is no such restriction imposed on FM and all
clauses in Fd (and therefore all other classes shown) can be derived using some composition
of ρ1 and ρ2. No corresponding operators or completeness results are known for Fr.

Relational features have been shown to be an extremely eﬀective form of learning with
relational objects (Kramer et al., 2001; Lavraˇc et al., 2021). Methods that construct and use
relational features, guided by some form of mode-declarations can be found in (Srinivasan
and King, 1999; Lavraˇc et al., 2002; Ramakrishnan et al., 2007; Joshi et al., 2008; Specia
et al., 2009; Faruquie et al., 2012; Saha et al., 2012; Fran¸ca et al., 2014; Vig et al., 2017;
Dash et al., 2018). Of these, the features in Lavraˇc et al. (2002) are from the feature class

11. Informally, a determinate predicate is one whose deﬁnition encodes a function. That is, for a given set

of values for input arguments, there is exactly one set of values for output arguments.

30

Composition of Relational Features

Fr. There are no reports on the class of features used in the other reports, although the
procedures for obtaining the features suggest that they are not restricted to any speciﬁc
sub-class (that is, they are simply from Fd). Given our results on derivation of features in Fd
from features in FM, and the class-inclusions shown, we would expect at least some features
in a super-class would require additional composition operations to those in a sub-class. In
terms of a CRM structure, we would expect features in Fi, for example, would usually be
associated with vertices at a greater depth than those in Fr. Empirical results tabulated for
some statistical learners in Saha et al. (2012) suggest that relational features from the class
Fi were most useful for statistical learners. If this empirical trend continues to hold, then
we would expect the performance of CRMs to improve as depth increases (and features in
Fi are derived), and then to ﬂatten or decrease (as features in Fd \ Fi are derived).

The development and application of CRMs is most closely related to the area of self-
explainable deep neural networks (Alvarez Melis and Jaakkola, 2018; Angelov and Soares,
2020; Ras et al., 2022). The structure of the CRM enforces a meaning to each node in
the network, and in turn, we have shown here how to extract one form of explanation
from these meanings. A diﬀerent kind of neural network, also with meanings associated
nodes is described in (Sourek et al., 2018). Those networks are also explainable, although
not in the manner described here. In (Srinivasan et al., 2019), a symbolic proxy-explainer
is constructed using ILP for a form of multi-layer perceptron (MLP) that uses as input
values of relational features. The features there drawn from the class Fd, and the expla-
nations are logical rules constructed by ILP using the feature-deﬁnitions provided to the
MLP. There are at least two important diﬀerences to the explanations constructed there
and the ones obtained with a CRM: (i) The rules constructed in (Srinivasan et al., 2019)
eﬀectively only perform the ρ2 operation on relational features. This can result in a form of
incompleteness: some features in Fd cannot be represented by the rules, unless they are al-
ready included as input to the MLP; and (ii) The structuring of explanations in (Srinivasan
et al., 2019) requires relevance information: here, the structuring is from usual functional
(de)composition.

6. Conclusion

It has been long-understood in machine learning that the choice of representation can make
a signiﬁcant diﬀerence to the performance and eﬃciency of a machine learning technique.
Representation is also clearly of relevance when we are interested in constructing human-
understandable explanations for predictions made by the machine learning technique. A
form of machine learning that has paid particular attention to issues of representation is
the area of Inductive Logic Programming (ILP). A form of representation that has been of
special interest in ILP is that of a relational feature. These are Boolean-valued functions de-
ﬁned over objects, using deﬁnitions of relations provided as prior- or background-knowledge.
The use of relational features forms the basis of an extremely eﬀective form of ILP called
propositionalisation. This obtains a Boolean-vector description of objects in the data, us-
ing the deﬁnition of the relational features and the background-knowledge. Despite the
obvious successes of propositionalisation, surprising little is known, conceptually, about the
space of relational features. In this paper, we have sought to address this by examining
relational features within a mode-language M, introduced in ILP within the setting of mode-

31

Srinivasan, Baskar, Dash, Shah

directed inverse entailment (Muggleton, 1995). Within a mode-language, we identify the
notion ofM-simple relational features, and 2 operations ρ1 and ρ2 that allows us to com-
pose progressively more complex relational feature in the mode-language. In the ﬁrst half
the paper, we show that ρ1 and ρ2 are suﬃcient to derive all relational features within a
mode-language M. This generalises a previous result due to McCreath and Sharma (1998b),
which was restricted to determinate deﬁnitions for predicates in the background knowledge,
albeit starting from a diﬀerent deﬁnition of simple features to that work.

In the second half of the paper, we use the notion of M-simple features and the com-
position operators ρ1,2 to construct a kind of deep neural network called a Compositional
Relational Machine, or CRM. A special aspect of CRMs is that we are able to associate
a relational feature with each node in the network. The structure of the CRM allows us
to identify further how the feature at the node progressively decomposes into simpler fea-
tures, until an underlying set of M-simple features are reached. This corresponds well to
the intuitive notion of a structured explanation, that is composed of increasingly simpler
components. We show how this aspect of CRMs allows them to be used as “explanation
machines” for black-box models. Our results on synthetic and real-data suggest that CRMs
can reproduce target-predictions with high ﬁdelity; and the explanations constructed on
synthetic data suggest that CRM’s explanatory structure usually also contains an accept-
able explanation.

We have not explored the power of CRMs as “white-box” predictors in their own right,
but early results suggest that it may be possible to obtain CRMs with good predictive
accuracy. Although still signiﬁcantly lower than the state-of-the-art, we believe this can
change. We have also not explored other forms of CRMs, both simpler and more elaborate.
For example, the identiﬁcation of M-simple features and their subsequent compositions
It
using the ρ-operators suggests an even simpler CRM structures than that used here.
is possible for example, simply to obtain all possible compositions to some depth, and use
a Winnow-like parameter estimation (Littlestone, 1988) to obtain a self-explainable linear
model. Equally, more complex CRMs are possible by incorporating weights on the M-simple
features (this could be implemented simply by changing the activation function at the input
nodes of the network). Taking this one step further, it is possible to associate weights with
all the relational features, which will allow the use of the inference machinery of probabilistic
logic programs (De Raedt et al., 2019). We think an investigation of these other kinds of
compositional relational machines would contribute positively to the growing body of work
in human-intelligible machine learning.

Data and Code Availability

Our data and code are available publicly at https://github.com/Devanshu24/crm.

Acknowledgments

AS is a Visiting Professor at Macquarie University, Sydney and a Visiting Professorial
Fellow at UNSW, Sydney. He is also the Class of 1981 Chair Professor at BITS Pilani,
Goa and a Research Associate at TCS Research. AS and TD would like to thank Lovekesh

32

Composition of Relational Features

Vig and Gautam Shroﬀ at TCS Research for interesting discussions on explainable neural
networks; and Michael Bain at UNSW for discussions on the use of ILP for constructing
symbolic explanations.

Appendix A. Logic Terminology

In this section we cover only terminology used in the paper, and further conﬁned largely to
logic programming. For additional background and further terminology see (Lloyd, 2012;
Chang and Lee, 2014; Nilsson, 1991; Muggleton and de Raedt, 1994). The summary below
is adapted from (Srinivasan et al., 2019).

A language of ﬁrst order logic programs has a vocabulary of constants, variables, function
symbols, predicate symbols, logical implication ‘←’, and punctuation symbols. A function or
predicate can have a number of arguments known as terms. Terms are deﬁned recursively. A
constant symbol (or simply “constant”) is a term. A variable symbol (or simply “variable”)
is a term. If f is an m-ary function symbol, and t1, . . . , tm are terms, then the function
f (t1, . . . , tm) is a term. A term is said to be ground if it contains no variables.

We use the convention used in logic programming when writing clauses. Thus, predicate,
function and constant symbols are written as a lower-case letter followed by a string of lower-
or upper-case letters, digits or underscores (’ ’). Variables are written similarly, except that
the ﬁrst letter must be upper-case. This is diﬀerent to the usual logical notation, where
predicate-symbols start with upper-case, and variables start with lower-case: however the
logic programming syntax is useful for the implementation of CRMs. Usually, predicate
symbols will be denoted by symbols like p, q, r etc. and symbols like X, Y, Z to denote
variables. If p is an n-ary predicate symbol, and t1, . . . , tn are terms, then the predicate
p(t1, . . . , tn) is an atom. Predicates with the same predicate symbol but diﬀerent arities are
distinguished by the notation p/n where p is a predicate of arity n.

A literal is either an atom or the negation of an atom.

If a literal is an atom it is
referred to as a positive literal, otherwise it is a negative literal. A clause is a disjunction
of the form A1 ∨ . . . ∨ Ai ∨ ¬Ai+1 ∨ . . . ∨ ¬Ak, where each Aj is an atom. Alternatively,
such a clause may be represented as an implication (or “rule”) A1, . . . , Ai ← Ai+1, . . . , Ak.
A deﬁnite clause A1 ← A2, . . . , Ak has exactly one positive literal, called the head of the
clause, with the literals A2, . . . , Ak known as the body of the clause. A deﬁnite clause with
a single literal is called a unit clause, and a clause with at most one positive literal is called
a Horn clause. A set of Horn clauses is referred to as a logic program. It is often useful to
represent a clause as a set of literals.

A substitution θ is a ﬁnite set {v1/t1, . . . , vn/tn} mapping a set of n distinct variables
vi, 1 ≤ i ≤ n, to terms tj, 1 ≤ j ≤ n such that no term is identical to any of the variables.
A substitution containing only ground terms is a ground substitution. For substitution θ
and clause C the expression Cθ denotes the clause where every occurrence C of a variable
from θ is replaced by the corresponding term from θ. If θ is a ground substitution then Cθ
is called a ground clause. Since a clause is a set, for two clauses C, D, the set inclusion
Cθ ⊆ D is a partial order called subsumption, usually written C θ-subsumes D and denoted
by C (cid:22) D. For a set of clauses S and the subsumption ordering (cid:22), we have that for every
pair of clauses C, D ∈ S, there is a least upper bound and greatest lower bound, called,
respectively, the least general generalisation (lgg) and most general uniﬁer (mgu) of C and

33

Srinivasan, Baskar, Dash, Shah

D, which are unique up to variable renaming. The subsumption partial ordering on clauses
enables the deﬁnition of a lattice, called the subsumption lattice.

We assume the logic contains axioms allowing for inference using the equality predicate
= /2. This includes axioms for reﬂexivity (∀x(x = x)), substitution (∀x(φ(x) ∧ (x = y) −→
φ(y))).

Appendix B. Mode Language

We borrow some of the following deﬁnitions from (Dash et al., 2022). The deﬁnition of
λµ sequence is simpliﬁed as we are dealing only with feature clauses here and all other
deﬁnitions are same as in (Dash et al., 2022).

Deﬁnition 26 (Term Place-Numbering) Let π = (cid:104)i1, . . . , ik(cid:105) be a sequence of natural
numbers. We say that a term τ is in place-number π of a literal λ iﬀ: (1) π (cid:54)= (cid:104)(cid:105); and (2)
τ is the term at place-number (cid:104)i2, . . . , ik(cid:105) in the term at the ith
1 argument of λ. τ is at a
place-number π in term τ (cid:48): (1) if π = (cid:104)(cid:105) then τ = τ (cid:48); and (2) if π = (cid:104)i1, . . . , ik(cid:105) then τ (cid:48) is
a term of the form f (t1, . . . , tm), i1 ≤ m and τ is in place-number (cid:104)i2, . . . , ik(cid:105) in ti1.

Deﬁnition 27 (Type-Names and Type-Deﬁnitions) Let Γ be a set of types and T be
a set of ground-terms. For γ ∈ Γ we deﬁne a set of ground-terms Tγ = {τ1, τ2, . . .}, where
τi ∈ T. We will say a ground-term τi is of type γ if τi ∈ Tγ, and denote by TΓ the set
{Tγ : γ ∈ Γ}. TΓ will be called a set of type-deﬁnitions.

Deﬁnition 28 (Mode-Declaration) (a) Let Γ be a set of type names. A mode-term is

deﬁned recursively as one of: (i) +γ, −γ or #γ for some γ ∈ Γ; or (ii) φ(mt(cid:48)
where φ is a function symbol of arity j, and the mt(cid:48)

ks are mode-terms.

1, mt(cid:48)

2, . . . , mt(cid:48)

j),

(b) A mode-declaration µ is of the form modeh(λ(cid:48)) or modeb(λ(cid:48)). Here λ(cid:48) is a ground-literal
of the form p(mt1, mt2, . . . , mtn) where p is a predicate name with arity n, and the mti
are mode-terms. We will say µ is a modeh-declaration (resp. modeb-declaration) for
the predicate-symbol p/n. In general there can be several modeh or modeb-declarations
for a predicate-symbol p/n. We will use M odeLit(µ) to denote λ(cid:48).

(c) µ is said to be a mode-declaration for a literal λ iﬀ λ and M odeLit(µ) have the same

predicate symbol and arity.

(d) Let τ be the term at place-number π in µ, We deﬁne

M odeT ype(µ, π) =






(+, γ)

(−, γ)

(#, γ)

unknown

if τ = +γ

if τ = −γ

if τ = #γ

otherwise

(e) If µ is a mode-declaration for literal λ, M odeT ype(µ, π) = (+, γ) for some place-number
π, τ is the term at place π in λ, then we will say τ is an input-term of type γ in λ

34

Composition of Relational Features

given µ (or simply τ is an input-term of type γ). Similarly we deﬁne output-terms and
constant-terms.
We will also say that mode µ contains an input argument of type γ if there exists some

term-place π of µ s.t. M odeT ype(µ, π) = (+, γ). Similarly for output arguments.

Deﬁnition 29 (λµ-Sequence) Assume a set of type-deﬁnitions TΓ, modes M. Let (cid:104)C(cid:105) =
(cid:104)l1, ¬l2, l3 . . . , ¬lk(cid:105) be an ordered clause. Then (cid:104)(λ1, µ1), (λ2, µ2), . . . , (λk, µk)(cid:105) is said to be
a λµ-sequence for (cid:104)C(cid:105) iﬀ it satisﬁes the following constraints:

Match. (i) λi = li; (ii) For j = 1, . . . , k, µj is a mode-declaration for λj s.t. µj = modeh(·)

(j = 1) and µj = modeb(·) (j > 1).

Terms. (i) If τ is an input- or output-term in λj given µj, then τ is a variable in λj; (ii)

Otherwise if τ is a constant-term in λj given µj then τ is a ground term.

Types. (i) If there is a variable v in both λi, λj then the type of v in λi given µi is same
as the type of v in λj given µj; (ii) If τ is a constant-term in λi and the type of τ in
λi given µi is γ, then τ ∈ Tγ.

Ordering. (i) If τ is an input-term in λj given µj and j > 1 then there is an input-term
τ in λ1 given µ1; or there is an output-term τ in λi (m < i < j) given µi. (ii) If τ is
an output-term in λ1 given µ1, then τ is an output-term of some λi (1 < i ≤ k) given
µi.

Deﬁnition 30 (Mode-Language) Assume a set of type-deﬁnitions T and modes M. The
mode-language LM,T is {(cid:104)C(cid:105) : either C = ∅ or there exists a λµ-sequence for (cid:104)C(cid:105)}.

Appendix C. Proof of the Derivation Lemma

Lemma 31 (Derivation Lemma) Given M, M(cid:48) and Ω = {ρ1, ρ2} as before. Let (cid:104)C(cid:105) be
an ordered clause in LM,T, with head p(X). Let S be a set of ordered simple clauses in
LM,T, with heads p(X) and all other variables of clauses in S standardised apart from each
other and from C. If there exists a substitution θ s.t. Sθ = Basis((cid:104)C(cid:105)) then there exists an
equivalent (cid:104)C(cid:48)(cid:105) in LM(cid:48),T that is derivable from S using Ω.

Proof We prove this in 3 parts:

1. We ﬁrst show: if Sθ = Basis((cid:104)C(cid:105)), then θ is a type-consistent substitution for clauses

in S.

Let Basis((cid:104)C(cid:105)) = {(cid:104)C1(cid:105), . . . , (cid:104)Ck(cid:105)} and S = {(cid:104)S1(cid:105), . . . , (cid:104)Sk(cid:105)}. Without loss of
generality, let (cid:104)Si(cid:105)θ = (cid:104)Ci(cid:105). Let θ = {Y1/t1, Y2/t2, . . . , Yn/tn} where the Yi
are variables in S and the ti are terms in Basis((cid:104)C(cid:105)). In general, the ti’s are
variables, constants, or functional terms. Let tj be a constant. Suppose clause
Si has the variable Yj in some location in Si and clause Ci has the constant tj in
the corresponding location. Since both Si, Ci are in LM,T, this is only possible
if there are multiple mode-declarations for the corresponding literals in Si and

35

Srinivasan, Baskar, Dash, Shah

Ci. But constraint M C2 ensures that there is exactly 1 mode-declaration for
any literal. Therefore ti cannot be a constant. Reasoning similarly, ti cannot
be a functional term. Therefore ti has to be a variable in Ci. Since Yj and tj
are in the same locations for some literal l in Si and Ci, and there is only 1
mode-declaration for l in M, it follows that the types of Yj and tj must be the
same.

2. If there exists a type-consistent substitution θ for clauses in S, then there is an ordered

clause (cid:104)C(cid:48)(cid:48)(cid:105) in Closure{ρ2}(S) s.t. C(cid:48)(cid:48)θ ≡ C

Let us ﬁx an ordering among the simple clauses in S: S1, . . . , Sk, where Si =
p(X) ← Bodyi(X, Yi). Let us deﬁne a sequence of ordered clauses (cid:104)C1(cid:105), (cid:104)C2(cid:105)
. . . (cid:104)Ck(cid:105) where (cid:104)C1(cid:105) is (cid:104)S1(cid:105) and (cid:104)Ci(cid:105) is in ρ2((cid:104)Ci−1(cid:105), (cid:104)Si(cid:105)) for i = 2 to k.
It
is easy to see that the above sequence is a derivation sequence of (cid:104)Ck(cid:105) from
{(cid:104)S1(cid:105), (cid:104)S2(cid:105), . . . , (cid:104)Sk(cid:105)} using {ρ2}. That is, (cid:104)Ck(cid:105) is in Closure{ρ2}(S). (cid:104)Ck(cid:105) is
of the form p(X) ← Body1(X, Y1), Body2(X, Y2), . . . , Bodyk(X, yk). That is
Ck = (cid:83)k
i=1 Siθ. Let (cid:104)C(cid:48)(cid:48)(cid:105) = (cid:104)Ck(cid:105)
That is, C(cid:48)(cid:48)θ = C. Hence C(cid:48)(cid:48)θ ≡ C. Also, since θ is a type-consistent substitution
for clauses Si ∈ S, and C(cid:48)(cid:48) = (cid:83)

i=1 Si. Since Sθ = Basis((cid:104)C(cid:105)), then C = (cid:83)k

i Si, θ is a type-consistent substitution for C(cid:48)(cid:48).

3. From above (cid:104)C(cid:48)(cid:48)(cid:105) and θ, we construct an ordered clause (cid:104)C(cid:48)(cid:105) in LM(cid:48),T s.t. (cid:104)C(cid:48)(cid:105) is in

Closure{ρ1}({(cid:104)C(cid:48)(cid:48)(cid:105)} and C(cid:48)(cid:48)θ ≡ C(cid:48).

l }.

1, . . . , Yl/Y (cid:48)

Let (cid:104)C(cid:48)(cid:48)(cid:105) = (p(X) ← Body(X, Y)), and θ = {Y1/Y (cid:48)
It is easy
to see that θ induces an equivalence relation on the variables in C(cid:48)(cid:48). Vari-
ables Yi, Yj are in the same equivalence class if both variables map to the same
variable Y (cid:48)
m. For each equivalence class [U ], we earmark one element in the
class as representative of the class. This element is denoted by rep([U ]). Let
C(cid:48)(cid:48) be p(X) ← Body(X, Y). Let us ﬁx on order among the variables occur-
ring in (cid:104)C(cid:48)(cid:48)(cid:105): Y1, Y2, . . . , Yl. Consider the following sequence of ordered clauses
(cid:104)C0(cid:105), (cid:104)C1(cid:105), . . . (cid:104)Cl(cid:105) where (cid:104)C0(cid:105) = (cid:104)C(cid:48)(cid:48)(cid:105), and (cid:104)Ci(cid:105) = p(X) ← Body(X, Y), Y1 =
rep([Y1]), Y2 = rep([Y2]), . . . , Yi = rep([Yi]) for i = 1 to l. The above sequence is a
derivation of (cid:104)Cl(cid:105) from (cid:104)C(cid:48)(cid:48)(cid:105) using only ρ1. That is (cid:104)Cl(cid:105) is in Closure{ρ1}({(cid:104)C(cid:48)(cid:48)(cid:105)}).
Let (cid:104)C(cid:48)(cid:105) be (cid:104)Cl(cid:105) and it is of the form p(X) ← Body(X, Y), Y1 = rep([Y1]), . . . , Yl =
rep([Yl]). It is easy to see that (cid:104)C(cid:48)(cid:105) ∈ LM(cid:48),T. We now show C(cid:48)(cid:48)θ ≡ C(cid:48). θ = θ(cid:48)(cid:48) ◦θ(cid:48),
where θ(cid:48)(cid:48) = {Y1/rep([Y1]), . . . , Yl/rep([Yl]} and θ(cid:48) = {rep([Y1])/Y (cid:48)
The variables rep([Yi]) are in S and the variables Y (cid:48)
i are in C. Since the variables
in S are standardised apart from the variables in C, θ(cid:48) is a renaming substitution.
Therefore C(cid:48)(cid:48)θ(cid:48) ≡ C(cid:48)(cid:48). Therefore C(cid:48)(cid:48)θ ≡ C(cid:48)(cid:48)θ(cid:48)(cid:48). By the substitution axiom in the
equality logic C(cid:48)(cid:48)θ(cid:48)(cid:48) ≡ C(cid:48). Therefore C(cid:48)(cid:48)θ ≡ C(cid:48).

1, . . . , rep([Yl])/Y (cid:48)

l }.12

From (1)–(3) above, the result follows.

12. Correctly, θ(cid:48) and θ(cid:48)(cid:48) have to be functions. It is evident that θ(cid:48)(cid:48) is a function, since each variable maps to
the representative of its equivalence class. We argue informally that θ(cid:48) is a function as follows. If Yi and
Yj are in the same equivalence class, then rep([Yi]) and rep([Yj]) are the same variables. But according
to our θ(cid:48), they are mapped to Y (cid:48)
j . One might think θ(cid:48) is not a function. But the variables in the
same equivalence class mapped to same variable. So Y (cid:48)

j and hence θ(cid:48) is a function.

i is same as Y (cid:48)

i and Y (cid:48)

36

Composition of Relational Features

Appendix D. Properties of Derivations using ρ1, ρ2

Lemma 32 (Reordering Lemma) Given M, M (cid:48) and a set of ordered clauses Φ. If an
ordered clause (cid:104)C(cid:105) is derivable from Φ using {ρ1, ρ2} then: (a) there is a derivation for (cid:104)Cj(cid:105)
from Φ using {ρ2}; (b) there is a derivation for (cid:104)Ck(cid:105) from {(cid:104)Cj(cid:105)} using {ρ1}; and (c) (cid:104)C(cid:105)
is equivalent to (cid:104)Ck(cid:105).

Proof Let us assume there is a derivation τ for (cid:104)C(cid:105) from Φ using {ρ1, ρ2}. There exists
an ordered clause (cid:104)Ck(cid:105) equivalent to (cid:104)C(cid:105) = p(X) ← l1, l2, . . . , lj, lj+1, lj+2, . . . , lk such that
• the sequence of literals l1, . . . lj can be split into Body(X, Y1), . . . Body(X, Ym) such

that p(X) ← Body(X, Yi) ∈ Φ for each i = 1, . . . , m, and

• lj+1 . . . lk are equality predicates introduced using ρ1 operator in the derivation τ . Let

(cid:104)Cj(cid:105) be p(X) ← Body(X, Y1), . . . Body(X, Ym).

It is easy to see that there is derivation τ1 for (cid:104)Cj(cid:105) from Φ using ρ2 operator. Now we can
apply ρ1 operator on (cid:104)Cj(cid:105) repeatedly to derive (cid:104)Ck(cid:105).

Lemma 33 Given M, M (cid:48) and a set of ordered clauses Φ. An ordered clause (cid:104)C(cid:105) is derivable
from Φ using {ρ2} then it is linearly derivable from Φ using {ρ2}.

Proof Let us assume that (cid:104)C(cid:105) is derivable from Φ using {ρ2}. Hence there exists a
derivation sequence ξ of ordered clauses (cid:104)C1(cid:105), (cid:104)C2(cid:105), . . . , (cid:104)Cn(cid:105) from Φ using {ρ2} and (cid:104)Cn(cid:105) =
(cid:104)C(cid:105). Now we use mathematical induction to prove that for each 1 ≤ i ≤ n, there exists a
linear derivation of (cid:104)Ci(cid:105) from Φ using {ρ2}.

[Base step:] The base step (when n = 1) is easy as (cid:104)C1(cid:105) should be in Φ and hence

there is a linear derivation for (cid:104)C1(cid:105) from Φ using {ρ2}.

[Induction step:] We assume there exists a linear derivation for (cid:104)Ci(cid:105) from Φ using
{ρ2} for each i < j (induction hypothesis) and prove that there exists a linear derivation
for (cid:104)Cj(cid:105). The clause (cid:104)Cj(cid:105) occurs in the derivation sequence ξ. There are two cases to be
considered: it is in Φ or it is in ρ2((cid:104)Cl(cid:105), (cid:104)Cm(cid:105)) where l, m < j. If (cid:104)Cj(cid:105) is in Φ, there exists a
linear derivation sequence for (cid:104)Cj(cid:105) from Φ (just the one step derivation containing itself).
Now we prove the claim for the second case. Since l, m < j, by induction hypothesis,
there exist linear derivation sequences ξl for (cid:104)Cl(cid:105) and ξm for (cid:104)Cm(cid:105) from Φ using {ρ2}. Let
2(cid:105), . . . , (cid:104)C(cid:48)
(cid:104)C(cid:48)
k(cid:105) be the clauses in Φ and occurring in ξm. Now consider the following
sequence ξj containing ξl, (cid:104)C(cid:48)
1(cid:105))
and (cid:104)C(cid:48)(cid:48)
a (cid:105) ∈ ρ2((cid:104)C(cid:48)(cid:48)
1(cid:105)). It is easy to see that ξj is a
linear derivation sequence for (cid:104)Cj(cid:105) from Φ using ρ2. Hence there exists a linear derivation
sequence for (cid:104)Cn(cid:105) from Φ using {ρ2}.

a(cid:105)) for a = 2 to k. ρ2((cid:104)Cl(cid:105), (cid:104)C(cid:48)

1 (cid:105) ∈ ρ2((cid:104)Cl(cid:105), (cid:104)C(cid:48)

k (cid:105) where (cid:104)C(cid:48)(cid:48)

2 (cid:105),. . . , (cid:104)C(cid:48)

a−1(cid:105), (cid:104)C(cid:48)

1(cid:105), (cid:104)C(cid:48)(cid:48)

2(cid:105), (cid:104)C(cid:48)(cid:48)

1 (cid:105), (cid:104)C(cid:48)

k(cid:105),(cid:104)C(cid:48)(cid:48)

1(cid:105), (cid:104)C(cid:48)

Lemma 34 (Linear Derivation Lemma) Given M, M (cid:48) and a set of ordered clauses Φ.
An ordered clause (cid:104)C(cid:105) is derivable from Φ using {ρ1, ρ2} then there exists an equivalent
ordered clause (cid:104)C(cid:48)(cid:105) and (cid:104)C(cid:48)(cid:105) is linearly derivable from Φ using {ρ1, ρ2}.

37

Srinivasan, Baskar, Dash, Shah

Appendix E. Relationship of M-Simple Feature-Clauses to Known

Feature Classes

We note the following about the sets of feature-clauses in Fig. 10(b) and the set FM of
M-simple feature clauses:

The set Fd. This is identical to the set of ordered feature-clauses in the mode-language

M;

The set Fi. This set is deﬁned based on a given mode language M (but without constraints
MC–MC3). An ordered feature clause (cid:104)C(cid:105) is in Fi iﬀ the number of connected com-
ponents after removing the source vertex (corresponding to the head literal) from the
clause dependency graph of (cid:104)C(cid:105) is exactly one. Since the clause dependency graph of
a clause in FM has exactly one sink literal and any vertex in that graph has a path to
that sink vertex (Remark 6). So the number of connected components after removing
the source vertex is one. Hence FM ⊆ Fi. It is easy to see that Fi (cid:54)⊆ FM (see the
counterexample given for Fs ⊆ FM).

The set Fs. This set is deﬁned based on the class of simple clauses identiﬁed by McCreath

(1999) who proposed simple clauses. We note:

1. Feature-clause deﬁnitions in Fs do not refer to a mode-language. The clause
dependency-graph is constructed using a procedure described in (McCreath,
1999), and is based on the re-occurrence of variables (without any reference
to input or output variables or types). M-simple feature-clauses require a mode-
language, with the constraints MC1–MC3;

2. FM (cid:54)⊆ Fs. For example assume a mode language p(+int), q(+int, −int), r(+int)
and the feature-clause p(X) ← q(X, X), r(X). The clause dependency-graph of
this clause has only one sink vertex and so it is in FM. But this is not in Fs since
the directed graph associated with this clause has two sink literals.

3. Fs (cid:54)⊆ FM. For example assume a mode language p(+int), q(+int, −int), r(+int, −int)
and the feature-clause p(X) ← q(X, Y ), r(X, Y ). This is in Fs, but is not in FM.
The cause dependency-graph described in this paper doesn’t have an edge be-
tween the vertices for q and r resulting in two sink vertices. But the dependency
graph constructed in (McCreath, 1999) will have an edge between the vertices
for q and r because of the shared variable y.

The set Fr. The set Fr consist of feature-clauses designed for subgroup discovery in rela-

tional data (Lavraˇc et al., 2002). Then:

1. Feature-clauses in Fr do require a mode-language, and we can construct a clause
dependency-graph as described here. The clause dependency-graph for feature-
clauses in Fr have exactly one component, and all new existential variables in-
troduced by a source literal appear in source or sink literals.

2. FM (cid:54)⊆ Fr. For example assume a mode language p(+int), q(+int, −int) and the
clause p(X) ← q(X, Y ). This is a M-simple clause but not in Fr as the existential
variable introduced at the source literal q but it is not appearing later.

38

Composition of Relational Features

3. Fr (cid:54)⊆ FM. For example assume a mode language p(+train), has car(+train, −car),

short(+car), closed(+car) and the clause p(X) ← has car(X, Y ), short(Y ), closed(Y ).
This is not M-simple clause there are two sink literals in it but it is in Fr.

Appendix F. Additional Details Relevant to the Experiments

F.1 Examples of Mode Declarations and Simple Feature-Clauses

Figures 11–13 show examples of mode declarations used for the experiments. Also shown are
examples of M-simple feature-clauses constructed automatically from the mode-declarations.

Modes

M-simple feature clauses

modeh(p(+tr))
modeb(short(+car))
modeb(closed(+car))
modeb(long(+car))
modeb(open car(+car))
modeb(double(+car))
modeb(jagged(+car))
modeb(shape(+car,#shape))
modeb(load(+car,#shape,#int))
modeb(wheels(+car,#int))
modeb(has car(+tr,-car))

p(A) ← has car(A, B)
p(A) ← has car(A, B), short(B)
p(A) ← has car(A, B), closed(B)
p(A) ← has car(A, B), long(B)
p(A) ← has car(A, B), open car(B)
p(A) ← has car(A, B), double(B)
p(A) ← has car(A, B), jagged(B)
p(A) ← has car(A, B), shape(B, u shaped)
p(A) ← has car(A, B), shape(B, rectangle)
p(A) ← has car(A, B), shape(B, hexagon)
p(A) ← has car(A, B), wheels(B, 3)
p(A) ← has car(A, B), wheels(B, 2)
p(A) ← has car(A, B), load(B, circle, 3)
p(A) ← has car(A, B), load(B, rectangle, 3)
p(A) ← has car(A, B), load(B, hexagon, 3)
p(A) ← has car(A, B), load(B, circle, 2)
...

Figure 11: Examples of mode-deﬁnitions and simple feature-clauses for the Trains problem.

39

Srinivasan, Baskar, Dash, Shah

Modes

M-simple feature clauses

modeh(p((+wkfile,+wkrank,+wrfile,

+wrrank,+bkfile,+bkrank))

modeb(lt(+wkrank,+wrrank))
modeb(lt(+wkrank,+bkrank))
modeb(lt(+wrrank,+wkrank))
modeb(lt(+wrrank,+bkrank))
modeb(lt(+bkrank,+wkrank))
modeb(lt(+bkrank,+wrrank))
modeb(lt(+wkfile,+wrfile))
modeb(lt(+wkfile,+bkfile))
modeb(lt(+wrfile,+wkfile))
modeb(lt(+wrfile,+bkfile))
modeb(lt(+bkfile,+wkfile))
modeb(lt(+bkfile,+wrfile))
modeb(adj(+wkrank,+wrrank))
modeb(adj(+wkrank,+bkrank))
modeb(adj(+wrrank,+bkrank))
modeb(adj(+wkfile,+wrfile))
modeb(adj(+wkfile,+bkfile))
modeb(adj(+wrfile,+bkfile))
modeb((+wkrank = +wrrank))
modeb((+wkrank = +bkrank))
modeb((+wrrank = +bkrank))
modeb((+wkfile = +wrfile))
modeb((+wkfile = +bkfile))
modeb((+wrfile = +bkfile))

p((A, B, C, D, E, F )) ← C = E
p((A, B, C, D, E, F )) ← B = D
p((A, B, C, D, E, F )) ← B = F
p((A, B, C, D, E, F )) ← D = F
p((A, B, C, D, E, F )) ← adj(A, C)
p((A, B, C, D, E, F )) ← adj(A, E)
p((A, B, C, D, E, F )) ← adj(C, E)
p((A, B, C, D, E, F )) ← adj(B, D)
p((A, B, C, D, E, F )) ← adj(B, F )
p((A, B, C, D, E, F )) ← adj(D, F )
p((A, B, C, D, E, F )) ← lt(A, C)
p((A, B, C, D, E, F )) ← lt(C, A)
p((A, B, C, D, E, F )) ← lt(A, E)
p((A, B, C, D, E, F )) ← lt(E, A)
p((A, B, C, D, E, F )) ← lt(C, E)
p((A, B, C, D, E, F )) ← lt(E, C)
p((A, B, C, D, E, F )) ← lt(B, D)
p((A, B, C, D, E, F )) ← lt(D, B)
p((A, B, C, D, E, F )) ← lt(B, F )
p((A, B, C, D, E, F )) ← lt(F, B)
p((A, B, C, D, E, F )) ← lt(D, F )
p((A, B, C, D, E, F )) ← lt(F, D)
p((A, B, C, D, E, F )) ← A = E
p((A, B, C, D, E, F )) ← C = E
p((A, B, C, D, E, F )) ← B = D
p((A, B, C, D, E, F )) ← B = F
p((A, B, C, D, E, F )) ← D = F
p((A, B, C, D, E, F )) ← adj(A, C)
p((A, B, C, D, E, F )) ← adj(A, E)
p((A, B, C, D, E, F )) ← adj(C, E)
...

Figure 12: Examples of mode-deﬁnitions and simple feature-clauses for the Chess problem.

F.2 Debugging Inconsistent Explanations from the CRM

For the Chess problem, 1044 instances (out of 10,000) are inconsistently explained. That is,
the explanation graph from the most relevant output vertex does not contain an acceptable
feature-clause. Further examination reveals: (a) for all 1044 instances, the predictions made
by the CRM are correct; (b) a majority (1033/1044) of the inconsistently instances are +
examples for which the White King and Black King are on adjacent ﬁles and ranks (the
corresponding acceptable feature-clause is p((A, B, C, D, E, F )) ← adj(A, E), adj(B, F )).
We ﬁnd there are 19 distinct ‘buggy explanations’ produced by the CRM for the inconsis-
tently explained data. The corresponding feature-clauses at the ‘root’ in the explanation
graph are listed below (for simplicity, we do not show the simpler features and the full graph
structure):

40

Composition of Relational Features

Modes

M-simple feature clauses

modeh(class(+mol,+class))
modeb(symbond(+mol,+atomid,+atomid,#bondtype))
modeb(bond(+mol,-atomid 1,-atomid 2,
#atomtype,#atomtype,#bondtype))

modeb(atom(+mol,-atomid,#element))
modeb(has struc(+mol,-atomids,-length,#structype))
modeb(connected(+mol,+atomids,+atomids))
modeb(fused(+mol,+atomids,+atomids))
modeb(gteq(+length,#length))
modeb(lteq(+length,#length))
modeb((+atomid = +atomid))
modeb((+atomidids = +atomidids))
modeb((+length = +length))

p(A) ← has struc(A, B, C, amine), gteq(C, 1)
p(A) ← has struc(A, B, C, ammonium ion), gteq(C, 1)
p(A) ← has struc(A, B, C, benzene ring), gteq(C, 1)
p(A) ← has struc(A, B, C, benzene ring), gteq(C, 2)
p(A) ← has struc(A, B, C, benzene ring), gteq(C, 3)
p(A) ← has struc(A, B, C, benzene ring), gteq(C, 4)
p(A) ← has struc(A, B, C, benzene ring), gteq(C, 5)
p(A) ← has struc(A, B, C, benzene ring), gteq(C, 6)
p(A) ← has struc(A, B, C, conjug base car), gteq(C, 1)
p(A) ← has struc(A, B, C, conjug base car), gteq(C, 2)
p(A) ← has struc(A, B, C, conjug base car), gteq(C, 3)
p(A) ← has struc(A, B, C, diazo group), gteq(C, 1)
p(A) ← has struc(A, B, C, diazo group), gteq(C, 2)
p(A) ← has struc(A, B, C, dithio ester car), gteq(C, 1)
p(A) ← has struc(A, B, C, dithio ester car), gteq(C, 2)
p(A) ← has struc(A, B, C, dithio ester car), gteq(C, 3)
...

Figure 13: Examples of mode-deﬁnitions and simple feature-clauses for the NCI problem.

1.

2.

3.

4.

5.

6.

7.

8.

9.

10.

11.

12.

13.

14.

15.

16.

17.

18.

19.

p((A, B, C, D, E, F )) ← adj(B, F )), lt(D, B), adj(C, E)

p((A, B, C, D, E, F )) ← adj(D, F )), B = D, lt(A, E)

p((A, B, C, D, E, F )) ← adj(A, E), lt(A, C), lt(F, D)

p((A, B, C, D, E, F )) ← lt(E, C), A = C, lt(B, F ))

p((A, B, C, D, E, F )) ← lt(E, A), A = C, adj(A, C)

p((A, B, C, D, E, F )) ← lt(E, A), lt(D, B), adj(A, E)

p((A, B, C, D, E, F )) ← B = D, A = C, adj(A, E)

p((A, B, C, D, E, F )) ← B = F, A = E, lt(E, C)

p((A, B, C, D, E, F )) ← lt(A, C), lt(B, D), adj(A, C)

p((A, B, C, D, E, F )) ← lt(D, F )), A = E, lt(E, C)

p((A, B, C, D, E, F )) ← A = E, adj(D, F )), adj(B, F ))

p((A, B, C, D, E, F )) ← lt(B, F )), lt(E, C), adj(D, F ))

p((A, B, C, D, E, F )) ← adj(B, D), lt(E, A), adj(A, C)

p((A, B, C, D, E, F )) ← adj(A, E), lt(C, E), adj(B, F ))

p((A, B, C, D, E, F )) ← A = E, A = C, adj(B, F ))

p((A, B, C, D, E, F )) ← lt(A, C), lt(F, B), adj(B, F ))

p((A, B, C, D, E, F )) ← lt(D, B), lt(A, E), adj(A, E)

p((A, B, C, D, E, F )) ← lt(E, A), A = C, adj(B, D)

p((A, B, C, D, E, F )) ← adj(A, E), B = F, lt(A, E)

41

Srinivasan, Baskar, Dash, Shah

References

David Alvarez Melis and Tommi Jaakkola. Towards robust interpretability with self-
explaining neural networks. Advances in neural information processing systems, 31, 2018.

Saul Amarel. On representations of problems of reasoning about actions. In Donald Michie,

editor, Machine Intelligence 3, pages 131–171. American Elsevier Publisher, 1968.

Plamen Angelov and Eduardo Soares. Towards explainable deep neural networks (xdnn).

Neural Networks, 130:185–194, 2020.

Sebastian Bach, Alexander Binder, Gr´egoire Montavon, Frederick Klauschen, Klaus-Robert
M¨uller, and Wojciech Samek. On pixel-wise explanations for non-linear classiﬁer decisions
by layer-wise relevance propagation. PloS one, 10(7):e0130140, 2015.

Michael Bain. Learning logical exceptions in chess. PhD thesis, University of Strathclyde,

1994.

Alexander Binder, Sebastian Bach, Gregoire Montavon, Klaus-Robert M¨uller, and Woj-
ciech Samek. Layer-wise relevance propagation for deep neural network architectures. In
Information science and applications (ICISA) 2016, pages 913–922. Springer, 2016.

Chin-Liang Chang and Richard Char-Tung Lee. Symbolic logic and mechanical theorem

proving. Academic press, 2014.

Tirtharaj Dash, Ashwin Srinivasan, Lovekesh Vig, Oghenejokpeme I Orhobor, and Ross D
King. Large-scale assessment of deep relational machines. In International Conference
on Inductive Logic Programming, pages 22–37. Springer, 2018.

Tirtharaj Dash, Ashwin Srinivasan, Ramprasad S Joshi, and A Baskar. Discrete stochastic
search and its application to feature-selection for deep relational machines. In Interna-
tional Conference on Artiﬁcial Neural Networks, pages 29–45. Springer, 2019.

Tirtharaj Dash, Ashwin Srinivasan, and Lovekesh Vig.

Incorporating symbolic domain

knowledge into graph neural networks. Machine Learning, 110(7):1609–1636, 2021.

Tirtharaj Dash, Ashwin Srinivasan, and A Baskar. Inclusion of domain-knowledge into gnns

using mode-directed inverse entailment. Machine Learning, 111(2):575–623, 2022.

Luc De Raedt, Robin Manhaeve, Sebastijan Dumancic, Thomas Demeester, and Angelika
Kimmig. Neuro-symbolic= neural+ logical+ probabilistic. In NeSy’19@ IJCAI, the 14th
International Workshop on Neural-Symbolic Learning and Reasoning, pages 1–4, 2019.

Kevin Ellis, Catherine Wong, Maxwell Nye, Mathias Sabl´e-Meyer, Lucas Morales, Luke
Hewitt, Luc Cary, Armando Solar-Lezama, and Joshua B Tenenbaum. Dreamcoder:
Bootstrapping inductive program synthesis with wake-sleep library learning. In Proceed-
ings of the 42nd ACM SIGPLAN International Conference on Programming Language
Design and Implementation, pages 835–850, 2021.

42

Composition of Relational Features

Tanveer A Faruquie, Ashwin Srinivasan, and Ross D King. Topic models with relational
In International conference on inductive logic programming,

features for drug design.
pages 45–57. Springer, 2012.

Manoel VM Fran¸ca, Gerson Zaverucha, and Artur S d’Avila Garcez. Fast relational learn-
ing using bottom clause propositionalization with artiﬁcial neural networks. Machine
learning, 94(1):81–104, 2014.

Georg Gottlob. Subsumption and implication. Inf. Process. Lett., 24(2):109–111, jan 1987.
ISSN 0020-0190. doi: 10.1016/0020-0190(87)90103-7. URL https://doi.org/10.1016/
0020-0190(87)90103-7.

Sachindra Joshi, Ganesh Ramakrishnan, and Ashwin Srinivasan. Feature construction using
theory-guided sampling and randomised search. In International Conference on Inductive
Logic Programming, pages 140–157. Springer, 2008.

Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR

(Poster), 2015. URL http://arxiv.org/abs/1412.6980.

Stefan Kramer, Nada Lavraˇc, and Peter Flach. Propositionalization Approaches to Re-
lational Data Mining, pages 262–291. Springer Berlin Heidelberg, Berlin, Heidelberg,
doi: 10.1007/978-3-662-04599-2 11. URL https:
2001.
//doi.org/10.1007/978-3-662-04599-2_11.

ISBN 978-3-662-04599-2.

Nada Lavraˇc, Filip ˇZelezn`y, and Peter A Flach. Rsd: Relational subgroup discovery through
ﬁrst-order feature construction. In International Conference on Inductive Logic Program-
ming, pages 149–165. Springer, 2002.

Nada Lavraˇc, Vid Podpeˇcan, and Marko Robnik-ˇSikonja. Propositionalization of relational

data. In Representation Learning, pages 83–105. Springer, 2021.

Nick Littlestone. Learning quickly when irrelevant attributes abound: A new linear-

threshold algorithm. Machine learning, 2(4):285–318, 1988.

John W Lloyd. Foundations of logic programming. Springer Science & Business Media,

2012.

Kenneth A Marx, Philip O’Neil, Patrick Hoﬀman, and ML Ujwal. Data mining the nci
cancer cell line compound gi50 values:
identifying quinone subtypes eﬀective against
melanoma and leukemia cell classes. Journal of chemical information and computer sci-
ences, 43(5):1652–1667, 2003.

Eric McCreath. Induction in ﬁrst order logic from noisy training examples and ﬁxed example

set size. PhD thesis, The University of New South Wales, 1999.

Eric McCreath and Arun Sharma. L ime: a system for learning relations. In International

Conference on Algorithmic Learning Theory, pages 336–374. Springer, 1998a.

43

Srinivasan, Baskar, Dash, Shah

Eric McCreath and Arun Sharma. Lime: A system for learning relations. In Michael M.
Richter, Carl H. Smith, Rolf Wiehagen, and Thomas Zeugmann, editors, Algorithmic
Learning Theory, pages 336–374, Berlin, Heidelberg, 1998b. Springer Berlin Heidelberg.
ISBN 978-3-540-49730-1.

Ryszard S Michalski. Pattern recognition as rule-guided inductive inference. IEEE Trans-

actions on Pattern Analysis and Machine Intelligence, PAMI-2(4):349–361, 1980.

Donald Michie. King and Rook Against King. 1. Historical Background and a Problem on
the Inﬁnite Board. University of Edinburgh. Machine Intelligence Research Unit, 1976.

Donald Michie, Stephen Muggleton, David Page, and Ashwin Srinivasan. To the interna-
tional computing community: A new east-west challenge. Distributed email document
available from https: // www. doc. ic. ac. uk/ ~ shm/ Papers/ ml-chall. pdf , 1994.

Stephen Muggleton. Inverse entailment and progol. New generation computing, 13(3-4):

245–286, 1995.

Stephen Muggleton and Luc de Raedt. Inductive logic programming: Theory and meth-
ISSN 0743-1066. doi:
ods. The Journal of Logic Programming, 19-20:629–679, 1994.
https://doi.org/10.1016/0743-1066(94)90035-3.
URL https://www.sciencedirect.
com/science/article/pii/0743106694900353. Special Issue: Ten Years of Logic Pro-
gramming.

Shan-Hwei Nienhuys-Cheng, Ronald De Wolf, et al. Foundations of inductive logic pro-

gramming, volume 1228. Springer Science & Business Media, 1997.

Nils J Nilsson. Logic and artiﬁcial intelligence. Artiﬁcial intelligence, 47(1-3):31–56, 1991.

Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan,
Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imper-
ative style, high-performance deep learning library. In Advances in Neural Information
Processing Systems, pages 8024–8035, 2019.

Gordon Plotkin. Automatic methods of inductive inference. PhD Thesis, The University

of Edinburgh, 1972.

Lutz Prechelt. Early stopping-but when? In Neural Networks: Tricks of the trade, pages

55–69. Springer, 1998.

J Ross Quinlan. Discovering rules by induction from large collections of examples. Expert

systems in the micro electronics age, 1979.

Ganesh Ramakrishnan, Sachindra Joshi, Sreeram Balakrishnan, and Ashwin Srinivasan.
Using ilp to construct features for information extraction from semi-structured text. In
International Conference on Inductive Logic Programming, pages 211–224. Springer, 2007.

Gabrielle Ras, Ning Xie, Marcel van Gerven, and Derek Doran. Explainable deep learning:
A ﬁeld guide for the uninitiated. Journal of Artiﬁcial Intelligence Research, 73:329–397,
2022.

44

Composition of Relational Features

David E Rumelhart, Geoﬀrey E Hinton, and Ronald J Williams. Learning representations

by back-propagating errors. nature, 323(6088):533–536, 1986.

Amrita Saha, Ashwin Srinivasan, and Ganesh Ramakrishnan. What kinds of relational
In International Conference on Inductive

features are useful for statistical learning?
Logic Programming, pages 209–224. Springer, 2012.

Gustav Sourek, Vojtech Aschenbrenner, Filip Zelezny, Steven Schockaert, and Ondrej
Kuzelka. Lifted relational neural networks: Eﬃcient learning of latent relational struc-
tures. Journal of Artiﬁcial Intelligence Research, 62:69–100, 2018.

Lucia Specia, Ashwin Srinivasan, Sachindra Joshi, Ganesh Ramakrishnan, and Maria das
Gra¸cas Volpe Nunes. An investigation into feature construction to assist word sense
disambiguation. Machine Learning, 76(1):109–136, 2009.

Ashwin Srinivasan and Ross D King. Feature construction with inductive logic program-
ming: A study of quantitative predictions of biological activity aided by structural at-
tributes. Data Mining and Knowledge Discovery, 3(1):37–57, 1999.

Ashwin Srinivasan, Stephen Muggleton, and Michael Bain. Distinguishing exceptions from
noise in non-monotonic learning. In Proceedings of the 2nd International Workshop on
Inductive Logic Programming, pages 97–107. Citeseer, 1992.

Ashwin Srinivasan, Lovekesh Vig, and Michael Bain. Logical explanations for deep relational
machines using relevance information. Journal of Machine Learning Research, 20(130):
1–47, 2019.

Alan Turing. Intelligent machinery. In The Essential Turing. Oxford University Press, 1948.

Lovekesh Vig, Ashwin Srinivasan, Michael Bain, and Ankit Verma. An investigation into
the role of domain-knowledge on the use of embeddings. In Nicolas Lachiche and Chris-
tel Vrain, editors, Inductive Logic Programming - 27th International Conference, ILP
2017, Orl´eans, France, September 4-6, 2017, Revised Selected Papers, volume 10759
of Lecture Notes in Computer Science, pages 169–183. Springer, 2017. doi: 10.1007/
978-3-319-78090-0\ 12. URL https://doi.org/10.1007/978-3-319-78090-0_12.

45

