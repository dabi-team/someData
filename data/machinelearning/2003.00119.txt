0
2
0
2

b
e
F
8
2

]
S
D
.
s
c
[

1
v
9
1
1
0
0
.
3
0
0
2
:
v
i
X
r
a

COMMUNICATION-OPTIMAL TILINGS FOR PROJECTIVE NESTED LOOPS WITH
ARBITRARY BOUNDS

GRACE DINH∗ AND JAMES DEMMEL†

ABSTRACT. Reducing communication - either between levels of a memory hierarchy or between
processors over a network - is a key component of performance optimization (in both time and en-
ergy) for many problems, including dense linear algebra [BCD+14], particle interactions [DGK+13],
and machine learning [DD18, GAB+18]. For these problems, which can be represented as nested-
loop computations, previous tiling based approaches [CDK+13, DR16] have been used to ﬁnd both
lower bounds on the communication required to execute them and optimal rearrangements, or block-
ings, to attain such lower bounds. However, such general approaches have typically assumed the
problem sizes are large, an assumption that is often not met in practice. For instance, the classical
(# arithmetic operations)/(cache size)1/2 lower bound for matrix multiplication [HK81, BCD+14] is
not tight for matrix-vector multiplications, which must read in at least O(# arithmetic operations)
words of memory; similar issues occur for almost all convolutions in machine learning applications,
which use extremely small ﬁlter sizes (and therefore, loop bounds).

In this paper, we provide an efﬁcient way to both ﬁnd and obtain, via an appropriate, efﬁciently
constructible blocking, communication lower bounds and matching tilings which attain these lower
bounds for nested loop programs with arbitrary loop bounds that operate on multidimensional arrays
in the projective case, where the array indices are subsets of the loop indices. Our approach works on
all such problems, regardless of dimensionality, size, memory access patterns, or number of arrays,
and directly applies to (among other examples) matrix multiplication and similar dense linear alge-
bra operations, tensor contractions, n-body pairwise interactions, pointwise convolutions, and fully
connected layers.

1. INTRODUCTION

Many structured computations, including dense linear algebra, n-body problems, and many
machine learning kernels, can be expressed as a collection of nested loops, where each iteration
accesses elements from several multidimensional arrays, indexed by some function of the current
loop iteration function:
for x1 ∈

[L1] , ..., for xd ∈

[Ld] :

(1.1)

.

perform operations on A1 [φ1 (x1, ..., xd)] , ..., An [φn (x1, ..., xd)]

{

1, ..., L1}

where [L1] represents the set

. For many such problems, the time and energy costs
of communication - that is, moving data between different levels of the memory hierarchy, or
between different cores or processors - can signiﬁcantly outweigh the cost of computation in
practice [BCD+14]. For example, communication-optimized implementations of matrix multiply
[HK81, BCD+14], n-body problems [DGK+13], and convolutional neural nets [GAB+18], among
others, have signiﬁcantly outperformed their non-communication-optimized counterparts. There-
fore, rearranging the order in which we perform these operations by dividing the nested loops
into subsets called tiles which are executed in sequence can lead to signiﬁcantly improved results
in practice.

Date: March 3, 2020.
∗Computer Science Division, Univ. of California, Berkeley, CA 94720 dinh@berkeley.edu.
†Computer Science Div. and Mathematics Dept., Univ. of California, Berkeley, CA 94720 demmel@berkeley.edu.
1

 
 
 
 
 
 
COMMUNICATION-OPTIMAL TILINGS FOR PROJECTIVE NESTED LOOPS WITH ARBITRARY BOUNDS

2

Most previous applied work, including that cited above, has been focused on ﬁnding communication-

optimal tilings and lower bounds for speciﬁc problems. While this is useful for commonly used
kernels whose optimizations can impact performance across a large number of applications (e.g.
matrix multiply, convolutions), it is less practicable to develop new theory for and hand-optimize
algorithms whose applications fall into smaller niches. This has stymied research into, for in-
stance, unconventional neural net architectures such as capsule networks [HSF18], which require
optimized kernels to test at scale but lack such kernels due to being unproven and not widely used
[BI19].

Progress has also been made [CDK+13, DR16] in generalizing some of these techniques by con-
sidering communication patterns via the Brascamp-Lieb inequalities, which apply to any loop nest
where the array indices are afﬁne functions of the loop indices (i.e. the φi above are afﬁne). These
methods provide both communication lower bounds and constructions for tilings for such prob-
lems.

Unfortunately, the above lines of work have largely ignored situations when certain loop bounds
(Li, above) are small. In this case, the methods can produce weak lower bounds and infeasible
tilings. Take, for instance, the case of matrix multiplication:

for

[L2]
x1, x2, x3} ∈
×
{
A1(x1, x3)+ = A2(x1, x2)

[L1]

×

[Ld]

A3(x2, x3)

×

Existing combinatorial and geometric [BCD+14], techniques states that a lower bound on the
communication between a cache of size M and main memory required to execute this set of in-
structions is

Ω

L1L2L3/M1/2

(cid:16)
words of memory, and may be attained by rewriting the nested loops as follows:
1]
[0..L1/B1 −
[B2]
[B1]
×

(cid:17)
[0..L2/B2 −
×
[Bd]

o1, o2, o3} ∈
{
for

[0..L3/B3 −

for

1]

1]

×

×

i1, i2, i3} ∈
{
x1 = B1o1 + i1
x2 = B2o2 + i2
x2 = B2o2 + i2
A(x1, x3)+ = A2(x1, x2)

A3(x2, x3)

×

where the tile (the three inner loops) has dimensions B1 = B2 = B3 / √M/3.

However, when L1 < √M/3, this tiling becomes infeasible. Furthermore, the lower bound also
ceases to be useful. For instance, when L3 = 1, corresponding to a matrix-vector multiplication,
the minimum communication needed to evaluate this multiplication is at least L1L2, since A2 must
be read in its entirety. However, the previous lower bound evaluates to Ω
, which is
clearly unachievable.

L1L2/M1/2

[DD18] addresses this situation for convolutions, ﬁnding a separate lower bound (and a corre-
sponding, feasible, tiling) for the case when the ﬁlter size is small (as they often are in most CNNs).
In this paper, we apply the techniques from [DD18] to ﬁnd a general communication lower bound
and optimal tiling for arbitrary loop bounds in the case where the array accesses are all subsets of
the loop bounds (the so-called “projective case”, which applies to most dense linear algebra ap-
plications, as well as point convolutions), and in doing so we prove that the optimal tile shape
for a projective loop nest is always a rectangle. We review the proof in the large-bound case in
Section 3, present a stronger communication lower bound that encompasses bounds of arbitrary
size in Section 4, and present a linear program that gives the actual tiling required to achieve this
lower bound (proving that it is tight) in Section 5. We then conclude with several examples and a
discussion in Sections 6 and 7.

(cid:0)

(cid:1)

COMMUNICATION-OPTIMAL TILINGS FOR PROJECTIVE NESTED LOOPS WITH ARBITRARY BOUNDS

3

2. PROBLEM SETUP, PRELIMINARIES, NOTATION, AND DEFINITIONS

1, 2, ..., n], and [m, n] to be the set [m, m + 1, ..., n
Deﬁne [n] to be the set
Formally, we will concern ourselves with the following d-level nested-loop program, which
consists of operations on the elements of the d1, ..., dn-dimensional arrays A1, ..., An indexed by
afﬁne functions φi : Zd

Zdi for i

1, n].

[n]:

−

{

→

∈

(2.1)

for x1 ∈

[L1] , ..., for xd ∈

[Ld] :

perform operations on A1 [φ1 (x1, ..., xd)] , ..., An [φn (x1, ..., xd)]

This representation includes many commonly used matrix and tensor operations, including

most linear algebra operations, tensor contractions, and convolutional neural nets.

We will assume that each xi is present in the support of at least one of the φj; this assumption

may be made without loss of generality as in [CDK+13].

Let us formally model the machine as follows: suppose we have a processor attached to a cache
of size M, which is in turn connected to a slow memory of unlimited size. The processor may
only perform operations on elements of the arrays present in the cache, and we wish to ﬁnd a
reordering of the operations in (2.1) that minimizes the amount of communication between the
cache and the slow memory.

[CDK+13] provides a tight lower bound for communication complexity in this model when
L1, ..., Ld are sufﬁciently large, as follows: First, represent each operation in (2.1), indexed by
Zd . As a result, the entire set of op-
x1, ..., xd, as the point indexed by the vector (x1, ..., xd)
erations represented by (2.1) can be treated as the hyper-rectangle of x
[Ld]. Fur-
[L1]
thermore, note that the element of array Ai of memory required for the operation indexed by
Zd of operations, the elements of Ai it re-
(x1, ..., xd) is φi(x1, ..., xd); in particular, given a set S
quires are indexed by φi(S). As a result, it sufﬁces to ﬁnd a lower bound on the number of subsets
(or an upper bound on the size of a single subset) needed to tile the hyper-rectangle, with each
one corresponding to a segment of the program that can be executed without going back to main
memory. To satisfy this condition, we require that each subset (“tile”) S satisfy the condition:

⊂

×

×

...

∈

∈

as we cannot use more than M words memory in a computation without going to slow memory.
Invoking the discrete Brascamp-Lieb inequality [BCCT10, CDK+13], we get that any such tile

has volume at most M∑i

[n] si, where the si are the solutions to the linear program:

∈

φi(S)

|

| ≤

M

(2.2)

min ∑
[1..n]
i
∈

si s.t.

n
∑
i=1

sirank(φi(H))

rank(H)

≥

∀

subgroups H

Zd

≤

This implies that the minimum number of tiles needed to cover the entire hyper-rectangle is at
[n] si. Since each tile corresponds to an execution of a subset of operations
least ∏i
without going back to slow memory, and we must complete all operations in the ’hypercube’, the
total number of words transferred between slow and fast memory must be at least

[1..d] Li/M∑i

∈

∈

∏i
∈
M∑i

∈

[d] Li
[n] si−

.

1

(cid:19)

Ω

(cid:18)

An explicit construction of a tile shape that achieves this lower bound is described in [RD16].

We will review this later in the paper for the projective case.

COMMUNICATION-OPTIMAL TILINGS FOR PROJECTIVE NESTED LOOPS WITH ARBITRARY BOUNDS

4

3. LARGE INDICES

{

}

In this section, we review the techniques used to construct optimal tilings and ﬁnd communi-
cation lower bounds for nested-loop programs with large indices. Our approach in this section
will be the building block for what we do in Sections We limit our attention to cases where the
index functions, φi, are projections: that is, their output is a subset of the input. For convenience,
let the indices of the output of φi be denoted supp(φi). For instance, if φ(x1, ..., x5) = (x1, x4), then
supp(φ) =

1, 4

.

In order to ﬁnd the communication lower bound, it sufﬁces to solve the LP (2.2). This linear
Zd; since the number of such subgroups is
program has one constraint for each subgroup H
inﬁnite, determining a ﬁnite closed form for inequalities using a brute-force enumeration of all
possible H is impossible. Note, however, that since rank(φi(H))
rank(H) = d, the number of
non-unique constraints is at most (d + 1)n+1 . In the general, continuous case - that is, for arbi-
trary afﬁne φ, with H ranging over subgroups of Rd rather than Zd - an algorithm guaranteed to
terminate in ﬁnite (but unbounded) time was given by Valdimarrson [Val10]. A separation oracle
for the resulting polytope was given in [GGdOW16], which immediately implies an algorithm for
enumerating the relevant constraints in double-exponential time.

≤

≤

In the case where φi are projections, however, a simple, closed-form listing of the constraints
is given by Theorem 6.6 of [CDK+13], which states that it sufﬁces to check that the inequality
∑n
, where ei is the
subgroup comprised of all vectors with zero entries at all indices except for i.

rank(H) holds for all H in the set of subgroups

i=1 sirank(φi(H))

e1, ..., ed}

≥

{

Therefore, this LP reduces to:

(3.1)

min ∑ sj s.t.
1

∑
j s.t. supp(φj)
Thinking of the φi as 0-1 vectors with 1s in the indices contained in its support, and letting ~s
denote the vector [s1, ..., sn]T, we can rewrite the linear program as (omitting nonnegativity con-
straints) as follows: minimize~1

T~s subject to:

[1..d]

≤

∈

sj

∀

∋

i

i

(3.2)

|
φ1



· · ·

|
φn

~s



≥

~1 .

|
The solution to this linear program, which we denote kHBL, immediately gives us the commu-





|

nication lower bound ∏i Li/MkH BL−

1.

...

Now that we have a lower bound, we would like to ﬁnd an actual tiling that attains it in order
to show that it is tight. Let us ansatz (following Loomis-Whitney, etc.) that the optimal tile is a
bd, where the bi are constants which we wish to determine.
hyperrectangle of dimensions b1 ×
We wish to select a tile whose volume (that is, ∏i
bi) is as large as possible, but we are subject
∈{
to memory limitations: the subsets of each array that are used must ﬁt in cache. Since the subsets
of array Ai required to complete the operations in this hyperrectangle are of size ∏j
supp(φi) bj, we
∈
obtain the constraint (again, ignoring constant factors) ∏j
M. Taking logs base M and
letting λi denote logM bi, we obtain the following linear program: maximize ~1
to:

[λ1, ..., λd] subject

supp(φi) bj ≤

×

1..d

∈

T

}

(3.3)

φ1 −...
φn −
Taking the dual gives us (3.2), which implies that this tiling obtains the lower bound.

λ1
...
λd

~1 .







−

≤

−













COMMUNICATION-OPTIMAL TILINGS FOR PROJECTIVE NESTED LOOPS WITH ARBITRARY BOUNDS

5

Notice that we did not encode the constraint that bi ≤

Li in this linear program. Although this
does not change the result when Li is assumed to be very large, this does not always hold, and
the lower bound computed by 3.2 is not always tight. In the following section, we modify this
approach to give tight lower bounds for arbitrarily-sized inputs.

4. THE LOWER BOUND

4.1. One Small Index. We will start our approach to small loop bounds by considering the case
when all loop indices but one are assumed to be bounded by arbitrarily large values. Our ap-
proach will be to (a) ﬁnd an upper bound for a tile restricted to single “slice” of the iteration space
formed by ﬁxing the loop index with a small bound, (b) calculate an upper bound for the entire tile
by summing individual slice bounds together over all possible values of the same index, and (c)
divide the total number of operations by the aforementioned quantity to achieve a communication
lower bound.

Let us ﬁrst consider the case where a single loop bound - say, L1, the upper bound on x1 - is
M; if the
small, and the others are large. We may assume without loss of generality that L1 ≤
opposite is true, then L1 would be large enough for the analysis of Section 3 to apply, as any
tile whose memory footprint is at most M would ﬁt in the L1 dimension. Furthermore, suppose
without loss of generality that φ1, ..., φp (for some integer p) all contain x1 and φp+1, ..., φn do not.
We will now ﬁnd a communication lower bound for the subset of instructions whose x1 index is
ﬁxed (since the loop bounds are constant and therefore independent of x1, the result is the same
for all possible values of x1).

Let φ′1, ..., φ′p be the functions with x1 removed. For instance, if φ1 = (x1, x2, x3), then φ′1 =
(x2, x3). A communication lower bound for a single “slice” of operations with x1 ﬁxed can be
found by using LP 3.1, with the φ replaced with φ′, to compute an upper bound for the max tile
size...

min ∑ ˆsj s.t.
1

≤

∑
j s.t. supp(φ′j)

ˆsj

i

∋

[1..d]

i

∀

∈

This amounts to removing the ﬁrst row in the constraint matrix of the LP (3.2):

[remove ﬁrst row]



|
φ1





|

· · ·

ˆs1
...
ˆsd

~1



≥

|
φn





|











To ﬁnd a upper bound for the size of a tile, we sum over the upper bounds for the size each of
its slices, each of which corresponds to a single value of x1. Let φ1
x1=k be the functions
with x1 ﬁxed to k. Then, the maximum tile size is found by maximizing the following quantity
(with V representing the tile):

x1=k, ..., φn|

|

(4.1)

∑
[L1] |
∈

i

subject to:

(4.2)

|

φ1

x1=i(V)

ˆs1 . . .

|

|

φn|

x1=i(V)

|

ˆsn = M∑i

∈

[p+1,n] ˆsi ∑

[L1] |

i

∈

|

φ1

x1=i(V)

ˆs1 . . .

|

|

φp|

x1=i(V)

ˆs p

|

|

φj

x1=i(V)

M

| ≤

[p] .

j

∀

∈

∑
[L1] |
∈

i

We bound (4.1) subject to the constraints (4.2), and compute the maximum tile size, as follows:

COMMUNICATION-OPTIMAL TILINGS FOR PROJECTIVE NESTED LOOPS WITH ARBITRARY BOUNDS

6

Lemma 1. The maximum tile size for a tile V, subject to the constraints that (a) that φi(V)
M for all
i and (b) the set of all distinct x1-coordinates of elements of V is at most L1 in cardinality (i.e. the tile ﬁts
inside the loop bounds), is bounded above by Mκ, where

≤

κ = max

n
∑
i=1

(

ˆsi + β1

p
∑
i=1

,

n
∑
i=1

ˆsi

!

1

−

.

ˆsi

)

Proof. There are three cases:

(1) If ∑i

[p] ˆsi < 1, the maximum of the quantity (4.1) is achieved when we distribute the

∈

weight across terms in the sum, i.e. for all j
[1..L1], which leads to a tile size of Mκ where

[1..p], let

φj

|

∈

x1=i(V)

|

= M/L1 for all i

∈

|

(4.3)

κ :=

n
∑
i=1

ˆsi + β1

p
∑
i=1

ˆsi

!

1

−

and β1 = logM L1.

(2) If ∑i

∈

[p] ˆsi > 1,the maximum is achieved when we concentrate the entire weight into one
= 0

= M for some i′ and let

[1..p], let

φj

x1=i(V)

|

|

term of the sum (i.e. for all j
for i

= i′), which leads to a tile size of Mκ where

x1=i′ (V)

φj

∈

|

|

|

|

(4.4)

κ :=

n
∑
i=1

ˆsi .

(3) If ∑i

∈

[p] ˆsi = 1, then both (4.3) and (4.4) are equal. Furthermore, since the only difference
between ˆs and s is that the latter must satisfy the additional constraint ∑i
1
in the constraint (which is satisﬁed in this case by ˆs as well), we get an upper bound of
M∑n

i=1 ˆsi = M∑n

si ≥

1..p

∈{

}

For convenience, denote
maximize

|

i=1 si immediately from (3.1).
(V)

|

φi

x1=x′i

|

, the slice of V corresponding to x′1, as yi,x′1

. We want to

subject to

L1
∑
x1=1

yˆs1
1,x1

. . . y

ˆs p
p,x1

L1
∑
x1=1

yi,x1 −

M

≤

0

[p] .

i

∀

∈

Without loss of generality, assume all the ˆsi are positive; if ˆsi = 0, then we can remove yi,x1 from
both the statement of the maximization problem (e.g. by setting it to 1 for all xi) and from the
quantities (4.3) and (4.4) without affecting the rest of the proof.

Since any slack in any one of the above inequalities can be removed by increasing one of the
yi,xi , and doing so will only increase the quantity we’re trying to maximize, we can take these
inequalities to be equalities. The Lagrange multipliers for this problem are:

=

L

L1
∑
x1=1

yˆs1
1,x1

. . . y

ˆs p
p,x1

λ1

−
...

λp

−

L1
∑
x1=1

L1
∑
x1=1

y1,x1 −

M

!

yp,x1 −

M

.

!

 
 
6
 
 
COMMUNICATION-OPTIMAL TILINGS FOR PROJECTIVE NESTED LOOPS WITH ARBITRARY BOUNDS

7

Setting the gradient (with respect to both yi,j and λi) to 0, and looking at the derivative with respect
to yi,j, we get:

(4.5)

ˆsiyˆs1

1,j...yˆsi

i

1

1,jyˆsi−

i,j yˆsi+1

i+1,j...y

1

ˆs p
p,j = λi .

−
−

As a result, we may assume λi 6

These equations are invariant in j: that is, no matter which value j we ﬁx x1 to, the set of
equations that yi,j must satisfy are identical (this intuitively follows from symmetry across the xi).
= 0; if it is in fact zero, then the quantity we’re trying to maximize
would be zero, which clearly cannot be the case since we can construct a tile containing only
one element (i.e. with our objective being 1) that satisﬁes all the constraints of the maximization
problem.

In particular, λiyi,j/ˆsi = yˆs1

1,j...y

ˆs p
p,j must remain invariant as i varies (with a ﬁxed j), which implies

that for any i1, i2, j,

λi1 yi1,j
ˆsi1

=

λi2 yi2,j
ˆsi2

implying that the ratio between yi,j for two different values of i is independent of the j (i.e. slice)
we choose, remaining ﬁxed at

yi1,j
yi2,j

=

λi2 ˆsi1
λi1 ˆsi2

Therefore, the point we’re trying to solve for satisﬁes this relationship:

(4.6)

yi,j =

λ1 ˆsi
λi ˆs1

y1,j

For any given j, one of two cases must hold: either yi,j = 0 for all i (in which case the tile does not
intersect at all with the slice x1 = j) or all yi,j are nonzero, and we can substitute (4.6) into (4.5) to
get:

λi
ˆsi

= yˆs1

1

1,jyˆsi−

i,j yˆsi+1

i+1,j...y

1

ˆs p
p,j

i

−
−

1,j...yˆsi
∏p
k=1 yˆsk
yi,j

k,j

∏p

k=1

y1,j

λ1 ˆsk
λk ˆs1
y1,j

(cid:16)
λ1 ˆsi
λi ˆs1

ˆsk

(cid:17)

=

=

1+∑k ˆsk

= y−
1,j

λi ˆs1
λ1 ˆsi

1+∑k ˆsk

= y−
1,j

ˆsk

λ1 ˆsk
λk ˆs1 (cid:19)
∑k ˆsk

p
∏
k=1 (cid:18)
λ1
ˆs1 (cid:19)

λi ˆs1
λ1 ˆsi (cid:18)

p
∏
k=1 (cid:18)

ˆsk

ˆsk
λk (cid:19)

Canceling λi
ˆsi
get

from both sides, and moving the ﬁrst term in the last expression over to the left, we

∑k ˆsk

y1
−
1,j

ˆsk
λk (cid:19)
k=1 ˆsk is nonzero, as the case when it is zero is covered by case (3)
above. Therefore, since the right hand side is independent of j, it follows that all nonzero values
of y1,j are equal. Since y1,j determines the value of yi,j for all i via (4.6), it follows that each yi,j must

We may assume that 1

λ1
ˆs1 (cid:19)

∑p

−

=

(cid:18)

.

1 p
∏
k=1 (cid:18)

∑k ˆsk−

ˆsk

COMMUNICATION-OPTIMAL TILINGS FOR PROJECTIVE NESTED LOOPS WITH ARBITRARY BOUNDS

8

either be (a) equal to some nonzero constant independent of j or (b) be equal to zero, if and only if
all yi′,j for the same j must also be zero.
Let the number of j such that y1,j

= 0 be ϑ, which must fall between 1 and L1 inclusive (since
the number of slices is at most equal to the loop bound corresponding to the dimension we’re
summing over). Therefore, in order to satisfy (a), the remaining yi,j must be equal to

yi,j =

M
ϑ

.

Substituting this into (4.1), we get that the max tile size is:

M∑i

∈

[p+1,n] ˆsi ϑ

ˆsi

p
∏
i=1 (cid:18)

M
ϑ

(cid:19)

= M∑n

i=1 ˆsi ϑ1

−

∑p

i=1 ˆsi

so the log (base M) of tile size is:

n
∑
i=1

Therefore, either 1
giving (recall that β1 = logM L1):

−

∑p

ˆsi +

logM ϑ

(cid:0)

(cid:1)

p
∑
i=1

1

−

.

ˆsi

!

i=1 ˆsi is positive, in which case the maximum occurs when we set ϑ to L1,

n
∑
i=1

ˆsi + β1

p
∑
i=1

1

−

,

ˆsi

!

∑p

i=1 ˆsi is negative, in which case the maximum occurs at ϑ = 1, in which case we get

n
∑
i=1

ˆsi .

or 1

−

as desired.

(cid:3)

4.2. Multiple small bounds. We now generalize the proof Section 4.1 to the case where multiple
loop bounds are taken to be small.

i such that supp(φi) contains xj.

Suppose that the loops indexed by xi have bounds Li. Let Rj ⊆ {
As before, our approach considers the communication lower bound for a “slice” - that is, a
subset of the iteration polytope formed by restricting certain loop indices to ﬁxed values - and
summing these slice lower bounds over all possible values of the ﬁxed indices. This time, however,
each slice will be formed by simultaneously ﬁxing multiple indices, which we assume without loss
of generality are x1 through xq (the following argument holds for any q, and is independent of the
actual value of q). As was the case in the single-variable case, an upper bound on max tile size for
a single slice is given by M∑j

ˆsj,where ˆsj are any nonnegative numbers that satisfy:

denote the set of indices

1..n

}

1..n

∈{

}

(4.7)

1

≤

∑
j s.t. supp(φ′j)

ˆsj

xi

∋

where φ′j now corresponds to removing x1, ..., xq from φj (or, alternatively, chopping off the ﬁrst
q rows of the HBL LP constraint matrix (3.2)).We now develop an analog to Lemma 1 in order
x1, ..., xq} ∈ {
. Our main result is as
to maximize the sum of the slices over
follows:

1..L1} ×

1..Lq}

× {

...

{

Theorem 2. Let q

∈

[1..d], and ˆsi be any nonnegative numbers satisfying

1

≤

∑
j s.t. supp(φ′j)

ˆsj

xi

∋

6
 
 
COMMUNICATION-OPTIMAL TILINGS FOR PROJECTIVE NESTED LOOPS WITH ARBITRARY BOUNDS

9

where φ′j is obtained by removing x1, ..., xq from φj. Then Mk, where

k =

n
∑
i=1

ˆsi +

∑
[q] s.t. ∑i

j

∈

Rj

∈

1

ˆsi≤

represents an upper bound on the tile size.

1

−

∑
Rj
∈

i

βj 






ˆsi






Notice that this theorem holds for all possible q, as well as reorderings of the variables. As a
result, this lemma in fact generates 2d separate upper bounds for tile size (one for each subset
Q of indices that we hold to be small). Therefore, the smallest upper bound on tile size (which
corresponds to the largest lower bound on communication) we can achieve in this manner is M ˆk
for

ˆk = min
Q
[d]

⊆

n
∑
i=1

ˆsQ,i +

∑
Q s.t. ∑i

∈

j

∈

Rj

ˆsi≤

1

−

∑
Rj
i
∈

βj 


1 


ˆsQ,i






where ˆsQ,i is the solution to the HBL LP (3.2) with the rows indexed by elements of Q removed.

Proof. By induction on q. The base case, for q = 1, is simply Lemma 1.

Let ˆs′i be deﬁned as ˆs[q

−

1],i. Suppose for induction that Mk, for

k =

n
∑
i=1

ˆs′i +

∑
1] s.t. ∑i

[q

j

∈

−

Rj

∈

1

ˆsi≤

represents an upper bound on the tile size.

1

−

∑
Rj
i
∈

βj 






ˆs′i






We start by ﬁnding an upper bound on the tile size, as before, by summing over several “slices”,

each being deﬁned as the subset of the elements where x1 through xq are set to ﬁxed values.

We begin by generalizing the notion of slices to the case where multiple indices may be small.
[q]. By deﬁnition, as φi only depends

As before, let φi
on indices in its support, φi

denote φi with xj ﬁxed to ˆxj for all j
|
must be identical to φi

ˆx1,..., ˆxq}

{

|

|

supp(φi).

We wish to maximize the size of the entire tile - that is, the sum of all the sizes of the slices:

∈
x1,...,xq}∩

{

x1,...,xq}

{

∑
[1..L1],...,xq∈
subject to the memory constraints

x1∈

[1..Lq] |

|

φ1

x1,...,xq}

{

(V)

|

ˆs1 . . .

φn|

|

x1,...,xq}

{

(V)

ˆsn

|

∑

|

φi

x1,...,xq}

{

(V)

M

| ≤

i

∀

∈

supp(φi) |

Rj .

[1..q]

[j
∈

[1..Lk] for k

[1..q]

xk∈

∈
As before, we will simplify our notation by deﬁning yj,
tion problem therefore can be rewritten as maximizing:

∩

x1,...,xq}

{

:=

|

φj

|

x1,...,xq}

{

(V)

|

. Our optimiza-

(4.8)

∑
[1..L1],...,xq∈

x1∈

[1..Lq]

yˆs1
1,
{

x1,...,xq}

. . . yˆsn
n,

x1,...,xq}

{

subject to the constraints:

(4.9)

1

≤

∑
[1..Lk] for k

∈

xk∈

[q]

∩

supp(φi)

yi,

x1,...,xq} ≤

{

M

i

∀

∈

Rj .

[q]
[j
∈

The deﬁnition of φi

|

ditional constraint on the solution: for all i, the value of yi,

ˆx1,..., ˆxq}

{

(and therefore of yj,

x1,...,xq}

{

) requires us to further impose an ad-
must remain independent of

x1,...,xq}

{

COMMUNICATION-OPTIMAL TILINGS FOR PROJECTIVE NESTED LOOPS WITH ARBITRARY BOUNDS

10

indices not in the support of φi. Formally, if xk /
∈
= yi,

(4.10)

yi,

x1,...xk

{

1,a,xk+1,...,xq}

−

supp(φi), then

x1,...xk

1,,b,xk+1,....,xq}

−

{

for any a, b. Our approach will be to ﬁnd a candidate solution which ignores this constraint, and
then to show that this candidate solution actually does satisfy (4.10) (i.e. that this constraint is
redundant).

Furthermore, in order to make it easier to reason about the constraints (4.9), we will multiply
them all by the appropriate values in order to ensure that the sum is over the same set of variables:
x1 through xq:

(4.11)

∏
supp(φi)
\

[q]

j

∈

Lj ≤

∑
[1..L1],...,xq∈

x1∈

[1..Lq]

yi,

x1,...,xq} ≤

{

M ∏
[q]
∈

\

j

supp(φi)

Lj

i

∀

∈

Rj .

[q]
[j
∈

Since our goal is to ﬁnd an upper bound on the tile size, which is the result of this constrained
x1,...,xq}

maximization problem, we can remove the lower bound constraints on ∑x1∈
(i.e. the leftmost inequality in (4.11)) without affecting correctness.

[1..L1],...,xq∈

[1..Lq] yi,

{

The resulting problem is almost identical to that of Lemma 1, except with different limits (one
may think of this ’ﬂattening’ the q-dimensional tensor x1, ..., xq into a single vector in order to get
a single sum as we did in the previous section). Recall that none of the steps we used to compute
the maximum in our proof of Lemma 1 actually used the value of the right sides of the constraints,
since all those constants were all differentiated away as a constant factor when taking gradients;
as a result, the same result applies here. Speciﬁcally, the maximum is obtained at a point speciﬁed
as follows: select some subset S
of integer tuples, which represent xi-
...
indices for which yi,
must be equal to
. In order to maximize (4.8), we set constraint (4.9) to
a constant value independent of
obtain:

⊆ {
× {
will be nonzero. For each
x1, ..., xq}

1..Lq}
{

x1, .., xq}

1..L1} ×

in S , yi,

x1,..,xq}

x1,..,xq}

{

{

{

(4.12)

x1,...,xq}
where Si is φi (restricted to x1...xq) applied to S .

{

yi,

For indices not in S , set yi,

=

M
Si|

|

i

∀

x1,...,xq}

{

to zero for all i. The resulting upper bound for tile size is

therefore:

(4.13)

∑
x1,...,xq∈

S

∏
i (cid:18)

ˆsi

M
Si| (cid:19)

|

=

=

ˆsi

M
Si| (cid:19)
|
M∑i ˆsi

S

|

|

∏
i (cid:18)

S
|
|
Si|
∏i |

ˆsi

|
Cq for some sets Ci ⊆

where the ﬁrst equality is a result of the independence of the summand with x, with the number
of nonzero terms in the sum being

Claim: without loss of generality, we can assume that S is a rectangle; that is, it can be written

S

|

.

[Li]

as set C1 × · · · ×
S such there exists some point
Proof of claim: Suppose not. Then there exist points x′, x′′ ∈
S , where each x∗j is equal to x′j for all j except a single value j∗, at which it takes on the
x∗ /
∈
S , and repeatedly change one
value of x′′j . To see why this is true, take any two distinct x′, x′′ ∈
component of x′ to match the corresponding component of x′′, stopping when either x′ = x′′, or
S . In the latter case, set x∗ = x′, and let x′ denote its immediate predecessor in this process.
x′ /
∈
If we never end up with an x∗ for any distinct pairs of x′ and x′′ in S , then S must be a rectangle.

COMMUNICATION-OPTIMAL TILINGS FOR PROJECTIVE NESTED LOOPS WITH ARBITRARY BOUNDS

11

Our goal will be to show that this conﬁguration is suboptimal. Consider the set of functions φi

for i

Rj∗, that is, the set of functions containing xj∗.

∈

= φi(x′′). Notice that replacing x′′ with x∗ in S either reduces

Let us consider the following categories, distinguished by how φi maps x′, x′′, and x∗.
Si|
(1) φi(x′) = φi(x∗)

by one
(if there is no other x† such that φi(x†) = φi(x′′)) or keeps it the same (if such an x† exists);
notice that in the latter case, adding x∗ to S keeps
constant. We denote these cases
(1a) and (1b) respectively.

Si|
|
= φi(x′). Analogously to case (1), replacing x′ with x∗ either reduces Si

(2) φi(x′′) = φi(x∗)

|

(case (2a)) or keeps it the same (case (2b)).
(3) φi maps x′, x′′, and x∗ to three distinct points.
(4) φi(x′) = φi(x′′) = φi(x∗).
(5) φi(x′) = φi(x′′)

= φi(x∗). Notice that this category must be empty: If x′′j = x′j, then by
from ′′ can only make the number

deﬁnition this quantity is also x∗; therefore, going to
of agreements better under any projection.

∗

In the above categories, i satisfying (1) and (4) implies that i /
∈
implies that i

Rj∗. We will show that S is suboptimal by providing strict improvements on it.

Rj∗, while i satisfying (2) and (3)

∈

(1) If there are any i in category (1a), we replace x′′ with x∗ in S , reducing

see how this change affects the values of Si for other i, we ﬁrst note that for other i /
∈
φi(x′) = φi(x∗), so this change can only keep constant or decrease
i in any of the other categories - (1b), (2ab), (3), or (4) -
as the value of
S
and

Si|
. In order to
Rj∗,
for such i. For all
remains the same. Therefore,
either remains the same or decreases (with at least one strict decrease),

remains constant, we obtain a strict increase in the value of (4.13).

Si|

Si|

Si|

|

|

|

|

(2) If some i falling into category (3): Denote the set of i such that φi maps x′, x′′, and x∗ onto

different values as Q. We will split into two cases, based on the values of ∑i
(a) Suppose ∑i
(4.13) is:

1. Consider the assignment to the yi,x given by S ; its objective

ˆsi ≥

Rj∗

Rj∗

ˆsi:

∈

∈

|

|

x1∈

[L1],...,xj∗−

1∈

[Lj∗−

∑
1],xj∗+1∈

[Lj∗+1],...,xq∈

∑
[Lj∗
xj∗ ∈

]

yˆs1
1,
{

[Lq] 


. . . yˆsn
n,

x1,...,xq}

x1,...,xq}

{



Factoring the innermost term into terms that are constant w.r.t. xj∗ and those that are
not, we can rewrite this as:

x1∈

[L1],...,xj∗−

1∈

[Lj∗−

[Lj∗+1],...,xq∈

∑
1],xj∗+1∈

∏
[n]
\

yˆsi
i,
{

R∗j

x1,...,xq}

∑
[Lj∗
xj∗ ∈

]

∏
R∗j
i
∈

yˆsi
i,
{

.

x1,...,xq}


Let us restrict our attention a single “slice”: that is, an instance of the term

[Lq] 


i

∈

(4.14)

∑
[Lj∗
xj∗ ∈

∏
Rj∗
∈

]

i

yˆsi
i,
{

x1,...,xq}

with ﬁxed values for x1 through xq, excluding xj∗. By equality constraints, we get that
all the nonzero values of yˆsi
must be equal to a constant independent of x1, ..., xq
i,
x1,...,xq}
{
(but dependent on i). Let mi = ∑x∗i ∈
, and σ denote the number of xj∗ such
{
that (x1, ..., xq), with all coordinates except xj∗ set to our ﬁxed values, are in S (and
therefore, nonzero terms in the above sum (4.14)); this restricts the nonzero values of

x1,...,xq}

] yi,

[Lj∗

6
6
6
COMMUNICATION-OPTIMAL TILINGS FOR PROJECTIVE NESTED LOOPS WITH ARBITRARY BOUNDS

12

yi,

x1,...,xq}

{

to mi/σ. Therefore, we may rewrite the above sum as:

∑
[Lj∗
xj∗ ∈

∏
Rj∗
∈

]

i

yˆsi
i,
{

x1,...,xq}

= σ ∏
i

∈

Rj∗ (cid:16)
∑i
Rj∗
−

∈

1

= σ

ˆsi

mi
σ

(cid:17)
ˆsi ∏
Rj∗

i

∈

m ˆsi
i

As ∑i
this term is bounded above by

ˆsi ≥

Rj∗

∈

1, the exponent of σ in the above expression is nonpositive; therefore,

m ˆsi
i

∏
Rj∗
∈

i

which we get when we set σ to 1. As this upper bound holds individually for each
“slice”, the value of the objective (4.13) is upper bounded by setting σ to 1 for every
slice, i.e. adding an additional constraint forcing Lj∗ to 1, which is equivalent to re-
moving xj
from the problem entirely. Applying our inductive hypothesis, we get that
an upper bound is Mk′ where

∗

k′ =

n
∑
i=1

ˆs′i +

∑
s.t. ∑i

j∗}

Rj

∈

1

ˆs′i≤

[1..q]

j

∈

\{

1

−

∑
Rj
i
∈

βj 






.



ˆs′i




(b) Now suppose ∑i

∈

∈

∈

∈

Rj∗

Rj∗

Rj∗

Rj∗

ˆsi ≥

Since ∑i
1, there is no difference between ˆs′i and ˆsi for all i, as the only con-
straint that the former must satisfy that the latter is not required to is ∑i
1,
which holds regardless in this case. Therefore, we can replace ˆs′i with ˆsi in order to
completing the induction for the entire proof of Lemma 2 in this particular case.

ˆsi ≥

ˆsi < 1. As Q

Rj∗, it immediately follows that ∑i

Q ˆsi ≤
ˆsi < 1. Consider the values of yi,x′, yi,x′′, and yi,x∗; we will show that a reas-

∑i
signment of these three values strictly increases the objective.
Without loss of generality, we will assume ∏i/
may be taken as nonzero. Why?
∈
Given some i′ is not in Q, then by deﬁnition φi′ must map x′, x∗ to the same point, or
x′′, x∗ to the same point. In the former case, we can set yi′,x∗ = yi′,x′ without violating
any constraint, as we can substitute the two terms freely in any constraint-sum involv-
S , both
ing them; in the latter case, the same applies if we set yi′,x∗ = yi′,x′′. As x′, x′′ ∈
yi′,x′ and yi′,x′′ must be nonzero, so yi′,x∗ must be nonzero as well. As nonzero values
of yi,x are independent of x for all i, we must have

Q yˆsi
i,x∗

⊆

∈

(4.15)

yi′,x∗ = yi′,x′′ = yi′,x′

For all i, let the value of yi,x′ + yi,x′′ + yi,x∗ be denoted µi, and deﬁne k′, k′′, k∗ such that
yi,x′ = k′µi (and likewise for k′′, k∗); our starting conﬁguration, with S containing
x′, x′′ but not x∗, is k′ = k′′ = 1/2, k∗ = 0. So as not to break any constraints, we will
require that the value of yi,x′ + yi,x′′ + yi,x∗ stay constant, so we will enforce k′ + k′′ +
k∗ = 1. The contribution of these three tiles to the objective (4.8) is:

yˆsi
i,x′

∏
Q
i
∈

=

∏
Q
i/
∈
yˆsi
i,x′

∏
Q
i
∈

yˆsi
i,x′

+ ∏
Q
i
∈

yˆsi
i,x′′

+ ∏
Q
i
∈

yˆsi
i,x′′

∏
Q
i/
∈
+ ∏
Q
i
∈

yˆsi
i,x∗

yˆsi
i,x∗

∏
Q
i/
∈

yˆsi
i,x′′

+ ∏
Q
i
∈
∏
Q
i/
∈

yˆsi
i,x∗ !

yˆsi
i,x′

 
COMMUNICATION-OPTIMAL TILINGS FOR PROJECTIVE NESTED LOOPS WITH ARBITRARY BOUNDS

13

with equality following from (4.15). We substitute yi,x′ = k′µi and the corresponding
deﬁnitions for yi,x′′, yi,x∗ to rewrite the above expression as:

k′µi

∏
Q
i
∈

(cid:0)

=

∑i

k′

∈

i

k′′µi

Q

ˆsi + ∏
∈
(cid:0)
µ ˆsi
i + k′′

(cid:1)
∑i

(cid:1)
Q ˆsi ∏
Q
i
∈
Q ˆsi + k′′

∑i

∈

Q ˆsi + k∗

i

Q

ˆsi + ∏
∈
Q ˆsi ∏
Q
i
∈
Q ˆsi

∑i

∈

∈

=

∑i

∈

k′

(cid:16)

(k∗µi) ˆsi

!

µ ˆsi
i + k∗

∑i

yˆsi
i,x′

∏
Q
i/
∈
Q ˆsi ∏
i
Q
∈
µ ˆsi
i

∈

yˆsi
i,x′

∏
Q
i/
∈

∏
Q
i
∈

µ ˆsi
i

∏
Q
i/
∈

!

yˆsi
i,x′

We will leave yi,x′ constant for all i /
∈
and yi,x∗, so it sufﬁces to maximize

(cid:17)
Q, and we will not vary µi, the sum of yi,x′, yi,x′′,

subject to

∑i

Q ˆsi + k′′

∈

∑i

Q ˆsi + k∗

∈

k′

∑i

∈

Q ˆsi

k′ + k′′ + k∗ = 1.

∈

Q ˆsi < 1, the solution to this maximization problem is obtained by setting
As ∑i
k′ = k′′ = k∗ = 1/3; all other assignments (including the current one) are subopti-
Q and any x, this change does not affect the
mal. As we do not vary any yi,x for i /
∈
constraints corresponding to any other φi than those in Q, which all must be still sat-
isﬁed as we do not vary µi; therefore, both these assignments satisfy the constraints
(4.9). Therefore the current assignment under S , with k∗ set to 0 and k′, k′′ set to 1/2,
must be suboptimal, providing us with our contradiction in this case.

(3) If there exists i in category (2a), but none in (1a) and (3), we will replace x′ with x∗ in S ,
for other i, in this case, either also decrease (for
decreasing
other is falling in case (2a)), remain the same (for is falling in cases (1b), (2b), (4)), therefore
corresponding to a strict improvement in the value of (4.13).

by one. The values of

Si|

Si|

|

|

(4) If we have i in categories (1b), (2b), or (4) (but none in categories (1a), (2a), or (3), all of
which were dealt with in earlier cases) add x∗ to S ; this does not change any value of Si,
but increases S by 1, leading to a strictly improved solution.

Each of these cases (except case (3a), which uses the inductive hypothesis), presents a strict im-
provement to the value of (4.13). Therefore, S must not be optimum, providing a contradiction.
We can therefore conclude that optimum value of S must have no triple x′, x′′ ∈
S such
that x∗ agrees with x′ everywhere except one coordinate where it agrees with x′′, and therefore S
must be a rectangle, as desired. (cid:4)

S , x∗ /
∈

Now that we’ve shown that S is a rectangle, let us assume that its dimensions are ρ1, ..., ρq.
supp(φi) ρj. Substituting into (4.13),

[q] ρi, and Si has cardinality ∏j

[q]

Then S has cardinality ∏i
we get:

∈

∈

∩

S
|
|
Si|
∏i |

ˆsi

M∑i ˆsi =

∏i

∈

M∑i ˆsi

ˆsi

(cid:17)

∏i

∈

[q] ρi

supp(φi) ρj

∩

M∑i ˆsi

[q]

∏j
∈
[q] ρi

[d]
(cid:16)
∏i
∈
∏i
(cid:16)
∑i
−

[q]

1

∈

ρ

j

Rj ρˆsi
ˆsi

j

∈
Rj

(cid:17)
M∑i ˆsi

=

∏j

∈
= ∏
[q]
j
∈

 
 
COMMUNICATION-OPTIMAL TILINGS FOR PROJECTIVE NESTED LOOPS WITH ARBITRARY BOUNDS

14

Since we have full control over the value of ρi, we can maximize the value of this expression
by setting the ρi to their maximum possible value, Li if 1
0, and to their minimum
Rj ˆsi ≤
possible value, 1, if 1

0.
Therefore, the maximum value of our objective (4.8) is obtained at:

Rj ˆsi ≥

∑i

∑i

−

−

∈

∈

M∑i ˆsi

∏
[q] s.t. ∑i

∈

j

∈

Rj

1

ˆsi≤

∑i

−

Rj

∈

ˆsi

1

j

L

or equivalently, Mk where

(4.16)

as desired.

k =

n
∑
i=1

ˆsi +

∑
[q] s.t. ∑i

j

∈

Rj

∈

1

ˆsi≤

1

βj 






−

∑
Rj
i
∈

.

ˆsi






Finally, we need to modify our solution to satisfy (4.10) with no change to the objective value.
Let y′i,

if there is some
nonzero element of S that matches (x1, ..., xq) at the indices in the support of φi, and is zero
otherwise. In order to show that this modiﬁcation does not change the value of objective (4.8), it
sufﬁces to show that

, which takes on the value M
S
i|

be maxxj s.t. j

supp(φi) yi,

x1,...,xq}

x1,...,xq}

∈

{

{

|

(4.17)

yˆs1
1,
{

x1,...,xq}

. . . yˆsn
n,

x1,...,xq}

{

=

y′1,

x1,...,xq}

{

ˆs1

. . .

y′n,

(cid:17)

(cid:16)

x1,...,xq}

{

ˆsn

(cid:17)

(cid:16)

S . Both sides are nonzero, and by equality constraint it is obvious that

/
∈

x1, ..., xq

Suppose

S . Clearly the left is zero. Recall that S is a rectangle; that is, it can
[Li]. By deﬁnition, there must exist
Ck. There must be some some j′ such that φj′ contains xk; by deﬁnition,

for some sets Ci ⊆
- and therefore, the entire right-hand-side of (4.17) - must be zero as well.
x1,...,xk,...,xj}
{
Furthermore, in order to show that this solution does not violate any of the constraints, consider

be written as set
(cid:0)
(cid:1)
some k such that xk /
∈
y′j′,

(x1, ..., xn) : xi ∈

Ci∀

{

}

i

∑
[1..Lk] for k

∈

xk∈

[q]

∩

supp(φi)

y′i,

x1,...,xq}

{

|

M/

, this term must be at most M, as desired.

By deﬁnition, at most Si of these terms may be nonzero, and each since must have value
Si|
Notice that this proof works if we ﬁx any subset of 1..q rather than the entire set. In other words,
we can freely replace the sum from 1 to q with a sum over any subset of 1 to q and still get a valid
[q] to summing over a subset of [q] in equation
upper bound (by changing the sum from j
(cid:3)
(4.16)).

∈

5. TILING CONSTRUCTION

In this section, we describe an explicit construction of a tiling that achieves the upper bound on

tile size (and therefore achieves the lower bound on computation) from section 4.

Consider the LP that gives us the tiling in this case. We start with the linear program (3.3) and
βi):

add constraints requiring that the blocks be no larger than the loop bounds (in log-space, λi ≤

Suppose

x1, ..., xq

they must be the same.
(cid:0)

(cid:1)

∈

COMMUNICATION-OPTIMAL TILINGS FOR PROJECTIVE NESTED LOOPS WITH ARBITRARY BOUNDS

15

(5.1)

λi s.t.

max ∑
i
d
∈
∑
supp(φj)
i s.t. xi∈

λi ≤

1

[n]

j

∀

∈

λi ≤
λi ≥
Theorem 3. The rectangular tile with dimensions given by the solution to (5.1) has cardinality equal to
one of the upper bounds for tile size from Section 4 for a loop program deﬁned by the φj; in other words, the
solution to (5.1) equals

∈
∈

∀
i
∀

βi
0

[q]
[d]

i

n
∑
i=1

ˆsQ,i +

βj 

[q], where ˆsQ,i satisﬁes the constraints of the HBL LP (3.2) with the rows indexed by elements

ˆsQ,i


1 


ˆsi≤

−





1

Rj

∈

∈

j

∑
Q s.t. ∑i

∑
Rj
i
∈

remove rows not in Q



|
φ1

· · ·

|
φn







ˆs1
...
ˆsn

1
...
1






≥ 





|

Let us write the constraints of (5.1) in the following fashion:











|

(5.2)

for some Q
⊆
of Q removed:

(5.3)

(5.4)

−

−
0
1
...
0

· · ·
· · ·
. . .

· · ·
q

φ1
...
φn
0
0
...
1

−

−
· · ·
· · ·
. . .

· · ·

0
0
...
0

0
0
...
0

λ1
...
λd











≤

1
...
1
β1
...
βq








































1
0
...
0













|

q



The dual of this linear program, with variables ζ1, ..., ζq, s1, ..., sn is to minimize

{z

}

(5.5)

subject to

(5.6)

q




· · ·
(as well as nonnegativity constraints ζi ≥
the matrix for brevity)

βiζi +

∑
[q]

∈

i

n
∑
j=1

sj

0
...
|
1 φ1
...
0

|

· · ·

0 for all i

∈





|
φn

ζ1
...
ζq

s1




...






sn




[q], si ≥

|



1
...
1






≥ 











0 for all i

[n], which we omit from

∈

· · ·
. . .

· · ·

1
...
0
...
0











We now show that the optimal value of (5.5) is equivalent to (5.2) for some ˆsi satisfying (5.3).

COMMUNICATION-OPTIMAL TILINGS FOR PROJECTIVE NESTED LOOPS WITH ARBITRARY BOUNDS

16

Proof. By induction on q.

For the base case, suppose q = 0. This is just the case in Section 3.
Suppose for induction that the solution to

(5.7)

takes the form

λi s.t.

max ∑
i
∑
supp(φj)
i s.t. xi∈

λi ≤

λi ≤

1

βi

[n]

j

∀

∈

[q

i

∀

∈

−

1]

n
∑
i=1

ˆsQ,i +

∑
Q s.t. ∑i

∈

j

∈

Rj

ˆsi≤

1] and ˆsi satisfying (5.3).

1

−

∑
Rj
i
∈

βj 


1 


ˆsQ,i






for some Q

[q

⊆

−

Consider the LP: minimize (5.5) subject to (5.6). Denote its solution by ζ′i, s′i; we wish to discover

the minimum value of the objective (5.5).

We will rewrite the LP (5.6) in such a way that preserves the optimal value of the objective. First,
we remove one variable - say, ζq - from it. Since there is no beneﬁt to setting ζq any larger than
necessary (it increases the objective (5.5), and does not come into play in any other constraints) we
can ﬁx its value as necessary to ensure that either the qth constraint or the nonnegativity constraint
ζq ≥

0 is tight. We have two cases:

1. In this case, the qth constraint is satisﬁed at the optimal point regardless of

Case 1: ∑i

Rq s′i ≥

∈

the value of ζ′q, so we may set ζq to 0. Now, the objective (5.5) becomes:

q
1
−
∑
i=1

βiζi +

n
∑
j=1

sj

Since the qth constraint is the only one containing ζq, we can delete the qth column on the left
block of the constraint matrix (5.6) and remove ζq from the LP entirely. Therefore, the resulting LP
is therefore exactly the dual of (5.7), which, by inductive hypothesis, has optimal objective value
of the form:

n
∑
i=1

∑
Q s.t. ∑i

ˆsQ,i +

βj 

[q], and ˆsQ,i satisfying (5.3) as desired.
< 1. Without loss of generality, assume this holds for R1 through Rq

ˆsQ,i


1 


ˆsi≤

−





1

Rj

∈

∈

j

∑
Rj
i
∈

1 as well
1, permute the LP to swap the positions of ζj and ζq, and proceed

−

for Q

[q

1]
⊂
Rq s′i

−
⊆
Case 2: ∑i
∈
(if not, ﬁnd j such that ∑x
to case 1).

Rj s′i ≥
Therefore, we may modify the LP by setting ζ1 to 1

∈

R1 si to keep it tight, and do the same
with ζ2 through ζq; this does not change the optimal objective value. Removing those constraints
(since they’ve all been encoded into the objective), we get a new objective to replace (5.5) in our
linear program:

−

∈

∑i

min

n
∑
i=1

si +

q
∑
j=1 


βj 


1

−

∑
Rj
i
∈

si






COMMUNICATION-OPTIMAL TILINGS FOR PROJECTIVE NESTED LOOPS WITH ARBITRARY BOUNDS

17

Furthermore, since ∑i

equal to

< 1 for all j

Rj s′i

∈

∈

[q] this objective at its optimizer, s′1, ..., s′q, is precisely

n
∑
i=1

s′i +

∑
[q] s.t. ∑i

j

∈

Rj

∈

1

ˆsi≤

which is of the same form as (5.2).

1

−

∑
Rj
i
∈

βj 






s′i






Furthermore, we may remove the ﬁrst q constraints from (5.6), since our choices for values of

ζ1, ..., ζq guarantee that they will be satisﬁed. The resulting constraint matrix is identical to (5.3).

Therefore, the tile whose dimensions are given by 5.1 attains the lower bound given by Lemma
(cid:3)

2 with Q = [q], as desired.

We demonstrate several applications of our theory below.

6. EXAMPLES

6.1. Matrix-Matrix and Matrix-Vector Multiplication. We start by re-deriving the classical lower
bound [HK81] for the triply-nested-loop matrix multiplication

for

[L2]
x1, x2, x3} ∈
{
×
A1(x1, x3)+ = A2(x1, x2)

[L1]

×

[Ld]

A3(x2, x3)

×

Our memory accesses are given by the functions:

φ1(x1, x2, x3) = (x1, x3)
φ2(x1, x2, x3) = (x1, x2)
φ3(x1, x2, x3) = (x2, x3)

Therefore, the HBL LP is to minimize s1 + s2 + s3 subject to

(6.1)

1 1 0
0 1 1
1 0 1







s1
s2
s2

1
1
1

.





≥ 


The optimal value of this LP is obtained when all the si are 1/2, giving a tile size upper bound of
M1/2+1/2+1/2 = M3/2, which provides the standard L1L2L3/M1l2 lower bound.











Now let us consider the case where L3 may be small, which corresponds to problem sizes ap-
proaching matrix-vector multiplications (which occurs L3 = 1). In this case, our tile, which has
length M1/2 in the L3 dimension, cannot ﬁt in our iteration space.s

We ﬁrst ﬁnd a lower bound. Removing the row corresponding to x3 from (6.1), we get that

given any ˆsi satisfying

(6.2)

raising M to the power

1 1 0
0 1 1

(cid:20)

ˆs1
ˆs2
ˆs3

(cid:21)





1
1
1





≥ 







max

ˆs1 + ˆs2 + ˆs3, ˆs1 + ˆs2 + ˆs3 + (logM L3)(1

represents a valid upper bound on the tile size.

(cid:8)

ˆs1 −

−

ˆs3)

(cid:9)

Since (6.2) is satisﬁed when ˆs2 = 1 and ˆs1, ˆs3 = 0, this term becomes

max

1, 1 + logM L3

(cid:8)

(cid:9)

COMMUNICATION-OPTIMAL TILINGS FOR PROJECTIVE NESTED LOOPS WITH ARBITRARY BOUNDS

18

giving an upper bound of max
{
nication lower bound is given by

M, ML3}

= ML3 (as L3 is always positive); therefore the commu-

L1L2L3
ML3

M = L1L2 .

This is as expected, since we need to read at least L1L2, the size of A2, into fast memory to perform
the operation.

Now let us consider the question of ﬁnding the tile. Instantiating LP (5.1) with the relevant

values of φ1,2,3, we get:

(6.3)

maxλ1 + λ2 + λ3 s.t.
λ1 + λ3 ≤
λ1 + λ2 ≤
λ2 + λ3 ≤
λ3 ≤

1
β3 = logM L3

1
1

1, then the last constraint is of no relevance, so the solution

There are two cases here: if β3 ≥
becomes 3/2, as in the case above .
On the other hand, if β3 ≤

1, then adding the second and fourth inequalities gives

(6.4)
We again split based on whether or not β3 ≥
whether the L3 is sufﬁciently large (at least √M) to ﬁt the √M
or whether we must modify the tile’s shape to get it to ﬁt in the L3 dimension.

λ1 + λ2 + λ3 ≤

1/2; intuitively, we may consider this a question of
√M tile derived above,

1 + λ3 ≤

1 + β3 .

√M

×

×

If β3 ≥

1/2, then the optimum for the LP without the fourth constraint, λ1 = λ2 = λ3 = 1/2,
√M as

satisﬁes the fourth constraint and is therefore optimal, leading to the same √M
in the “large loop bound” cases discussed above.

√M

×

×

1/2, then we can set λ3 = β3 to make the fourth inequality tight, and then set λ1 =
If β3 ≤
β3 and λ2 = β3 to tighten 6.4 in addition to the ﬁrst inequality in the LP; as three irredundant
1
−
inequalities are tight and we only have three variables, this solution must be optimal as well. This
L3 = ML3 (with a communication cost of L1L2, a quantity that
obtains a tile size of M/L3 ×
is equal to the size of A2 and therefore must be optimal) as expected.

L3 ×

Alternatively, we could achieve the same tile size with a tile of size √M

L3 (corre-
sponding to λ = λ2 = 1/2, λ3 = β3). In fact, the LP is optimized by any point between the two
solutions we found previously; speciﬁcally, for any α

√M

×

×

1,

λ1 = α/2 + (1
λ2 = α/2 + (1
λ3 = β3

−
−

optimizes LP (6.3); this corresponds to a tile size of:

≤
α)(1
α)β3

β3)

−

α/2

M1
−
L1
3

−

α

×

Mα/2L1

α
−
3 ×

L3 .

When attempting to optimize this matrix multiplication on a real-world system, we may select
any tiling from the above α-parameterized family of optimal tilings in order to ﬁnd one that runs
well in practice (e.g. inner loops being multiples of cache line lengths or vector units).

As the communication cost’s derivation is symmetrical (i.e. it continues to be valid when we
swap the subscripts) and the tile for the small-L3 case above remains be a legal tiling if L3 is
the smallest loop index, we obtain the following tight lower bound for matrix multiplication’s
communication cost:

max(L1L2L3/√M, L1L2, L2L3, L1L3)

COMMUNICATION-OPTIMAL TILINGS FOR PROJECTIVE NESTED LOOPS WITH ARBITRARY BOUNDS

19

6.2. Tensor Contraction. Let 1

j < k

−

≤

1 < d. Let us consider a tensor contraction of the form

for

x1, ..., xd} ∈
{
×
A1(x1, ..., xj, xk, ..., xd)+ = A2(i1, ..., ik

[Ld]

[L1]

×

...

1)

−

×

A3(xj+1, xd)

This nested-loop model encapsulates several machine learning applications. For instance, point-
wise convolutions - convolutions with 1
1 ﬁlters, often used along depth-separable convolutions
[HZC+17] to mimic the effect of standard machine learning convolutions with less memory usage,
may be represented as tensor contractions:

×

(6.5)

for

b, c, k, w, h
{
} −
Out(k, h, w, b)+ = Image(w, h, c, b)

B, C, K, W, H

= 0 :

{

}

1

×

Filter(k, c)

The same holds for fully connected convolutional layers.

The communication lower bound for the large-loop bound case is, as derived in [CDK+13], is

L1...Ld/√M.

We instantiate the LP 5.1 to get:

subject to

max λ1 + ... + λd

−

λ1 + ... + λj + λk + .... + λd ≤
λ1 + ... + λk
1 ≤
λj+1 + ... + λd ≤
λ1 ≤
...
λd ≤

1
1
1
β1 = logM L1

βd = logM Ld

The structure of this linear program is much like that of matrix multiplication, and it can be trans-
formed into one identical to that for matrix multiplication. Let γ1 = ∑i
1] λi,
and γ3 = ∑i
[k,d] λi. Then we can rewrite the linear program as maximizing γ1 + γ2 + γ3 subject
to:

[j] λi, γ2 = ∑i

[j+1,k

−

∈

∈

∈

γ1 + γ3 ≤
γ1 + γ2 ≤
γ2 + γ3 ≤
γ1 ≤

γ2 ≤

γ3 ≤

βi

1
1
1
∑
[j]
i
∑
[j+1,k
∈
∑
[k,d]
∈

∈

i

i

−
βi

βi

1]

As this linear program is identical to that for matrix multiplication, it immediately follows that its
optimum is either 3/2 or 1 + min
given program.

, whichever is smaller for the

[j] βi, ∑i

1] βi, ∑i

[k,d] βi

[j+1,k

∑i

−

∈

∈

∈

n

o

COMMUNICATION-OPTIMAL TILINGS FOR PROJECTIVE NESTED LOOPS WITH ARBITRARY BOUNDS

20

6.3. n-body Pairwise Interactions. Suppose we have a list of n objects, and each object interacts
with every other object. This comes up frequently in many scientiﬁc computing applications (e.g.
particle simulations), as well as database joins.

The nested loops for this problem are (for some arbitrary function f ):

for

Instantiating 5.1, we get:

[L1]
x1, x2} ∈
{
A1[x1] = f (A2[x1], A3[x3])

[L2]

×

maxλ1 + λ2 s.t.
λ1 ≤
λ2 ≤
λ1 ≤
λ2 ≤

1
1
β1 = logM L1
β2 = logM L2

which gives us a maximum tile size of min
and a maximum communica-
. The last term, M, is a result of the assumption in our model
tion cost of min
(cid:9)
that each tile carries M words of memory into cache. Therefore, it is important to note that if total
amount of memory required to execute the program without going back to main memory is less than M, the
output of the program will still be M, when in the actual cost is in fact the sum of the sizes of the matrices.

L1L2/M, L2, L1, M

M2, L1M, L2M, L1L2

(cid:8)

{

}

7. DISCUSSION AND FUTURE WORK

In this paper, we have shown a systematic, efﬁciently computable way of determining optimal
tilings for projective loop nests of arbitrary size, and used it to rederive several tight lower bounds
that have hitherto largely been computed by a problem-speciﬁc approach.

Our approach reveals some structural properties of the tile as well: All such loop nests share
an optimal tile shape (rectangles). Furthermore, as the optimal tile’s dimension for any projective
loop nest is the solution to a linearly parameterized linear program, its cardinality for a given loop
nest must be of the form M f (L1,...,Ld) for some piecewise linear function f . In fact, for a given loop
nest, we may programmatically ﬁnd a closed form of f by feeding LP (5.1), which calculates the
dimensions of the tile, into a multiparametric linear program solver, e.g. that of [BBM03], as in
[DD18]. This piecewise-linear structure has also been previously shown to hold for convolutions
[DD18], and we conjecture that this property holds even in the general, non-projective case as well.

The immediate application we see for our approach is as compiler optimization to automatically
block projective nested loops. While many such common loops have already been extensively op-
timized in high-performance libraries (and some of these optimizations have been implemented
in compilers, e.g. icc’s –opt-matmul ﬂag), our techniques are fully general - applying to appli-
cations (e.g. pairwise interactions) that do not ﬁt this mold - and do not require programmers to
have any familiarity with speciﬁc high performance libraries, only access to a compiler with the
right optimizations.

Furthermore, as the memory model we use can be generalized to multiprocessor machines (as
in [Kni15], following the approach of [ITT04]), our work also provides evidence for the intuition
that the best way to split projective loop-nest tasks up on a multiprocessor system is to assign each
processor a rectangular subset of the iteration space.

Our work is intended as a ﬁrst step towards generally optimizing non-projective nested loops,
such as those found in neural nets, image processing, and other similar structured computations,
many of which lack well-studied high-performance implementations [BI19]. Algorithms to ﬁnd

COMMUNICATION-OPTIMAL TILINGS FOR PROJECTIVE NESTED LOOPS WITH ARBITRARY BOUNDS

21

such tilings - and the shapes thereof - are known1 for problems with large indices [DR16, CDK+13];
however, a general method for addressing the small-bound case, which occurs in many applica-
tions (including most machine learning ones, where, for instance, ﬁlter sizes tend to vary), is still
unknown, and is left to future work.

ACKNOWLEDGEMENTS

We would like to thank Tarun Kathuria for helpful discussions.
This material is based upon work supported by the US Department of Energy, Ofﬁce of Science
under Award Numbers 7081675 and 1772593; Cray, under Award Number 47277; and DARPA,
under Award Number FA8750-17-2-0091.

REFERENCES

[BBM03]

[BCCT10]

[BCD+14]

[BI19]

F. Borrelli, A. Bemporad, and M. Morari. Geometric algorithm for multiparametric linear programming.
Journal of Optimization Theory and Applications, 118(3):515–540, Sep 2003.
J. Bennett, A. Carbery, M. Christ, and T. Tao. Finite bounds for H ¨older-Brascamp-Lieb multilinear inequal-
ities. Math. Res. Lett., 17(4):647–666, 2010.
G. Ballard, E. Carson, J. Demmel, M. Hoemmen, N. Knight, and O. Schwartz. Communication lower
bounds and optimal algorithms for numerical linear algebra. Acta Numerica, 23:1–155, 2014.
Paul Barham and Michael Isard. Machine learning systems are stuck in a rut. In Proceedings of the Workshop
on Hot Topics in Operating Systems, HotOS ’19, pages 177–183, New York, NY, USA, 2019. ACM.

[CDK+13] M. Christ, J. Demmel, N. Knight, T. Scanlon, and K. Yelick. Communication lower bounds and optimal

[DD18]

algorithms for programs that reference arrays - part 1. arxiv.org/abs/1308.0068, 2013.
James Demmel and Grace Dinh. Communication-optimal
abs/1802.06905, 2018.

convolutional neural nets. CoRR,

[DR16]

[DGK+13] M. Driscoll, E. Georganas, P. Koanantakool, E. Solomonik, and K. Yelick. A communication-optimal n-
body algorithm for direct interactions. In 2013 IEEE 27th International Symposium on Parallel and Distributed
Processing, pages 1075–1084, May 2013.
James Demmel and Alex Rusciano. Parallelepipeds obtaining HBL lower bounds. Technical Report
UCB/EECS-2016-162, EECS Department, University of California, Berkeley, Nov 2016.
Evangelos Georganas, Sasikanth Avancha, Kunal Banerjee, Dhiraj D. Kalamkar, Greg Henry, Hans Pabst,
and Alexander Heinecke. Anatomy of high-performance deep learning convolutions on SIMD architec-
tures. CoRR, abs/1808.05567, 2018.

[GAB+18]

[GGdOW16] Ankit Garg, Leonid Gurvits, Rafael Mendes de Oliveira, and Avi Wigderson. Algorithmic aspects of

[HK81]

[HSF18]

brascamp-lieb inequalities. CoRR, abs/1607.06711, 2016.
Jia-Wei Hong and H. T. Kung. I/O complexity: The red-blue pebble game. In Proceedings of the Thirteenth
Annual ACM Symposium on Theory of Computing, STOC ’81, page 326–333, New York, NY, USA, 1981.
Association for Computing Machinery.
Geoffrey E Hinton, Sara Sabour, and Nicholas Frosst. Matrix capsules with EM routing. In International
Conference on Learning Representations, 2018.

[ITT04]

[HZC+17] Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand,
Marco Andreetto, and Hartwig Adam. Mobilenets: Efﬁcient convolutional neural networks for mobile
vision applications, 2017.
Dror Irony, Sivan Toledo, and Alexander Tiskin. Communication lower bounds for distributed-memory
matrix multiplication. J. Parallel Distrib. Comput., 64(9):1017–1026, September 2004.
Nick Knight. Communication-Optimal Loop Nests. PhD thesis, EECS Department, University of California,
Berkeley, Aug 2015.
A. Rusciano and J. Demmel. Parallelepipeds obtaining HBL lower bounds. arxiv.org/abs/1611.05944,
2016.
S. Valdimarsson. The Brascamp-Lieb polyhedron. Canadian J. Math., 62(4):870–888, 2010.

[Kni15]

[RD16]

[Val10]

1Such algorithms, which enumerate all the constraints of the HBL linear program, are in general hard (double expo-
nential in n and d, as of the time of publication of this paper). However, as the cost only needs to be incurred once (e.g.
during a computation of a highly performance sensitive kernel), and as n and d tend to be relatively small in practice,
this is less of an impediment than it might appear at ﬁrst glance.

