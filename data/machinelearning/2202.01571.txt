2
2
0
2

b
e
F
3

]

C
O
.
h
t
a
m

[

1
v
1
7
5
1
0
.
2
0
2
2
:
v
i
X
r
a

Toric Geometry of Entropic Regularization

Bernd Sturmfels, Simon Telen,
Fran¸cois-Xavier Vialard, and Max von Renesse

Abstract

Entropic regularization is a method for large-scale linear programming. Geometrically,
one traces intersections of the feasible polytope with scaled toric varieties, starting at
the Birch point. We compare this to log-barrier methods, with reciprocal linear spaces,
starting at the analytic center. We revisit entropic regularization for unbalanced op-
timal transport, and we develop the use of optimal conic couplings. We compute the
degree of the associated toric variety, and we explore algorithms like iterative scaling.

1

Introduction

Linear programming in standard form is the optimization problem

Minimize c · x subject to Ax = b and x ≥ 0.

(1)

Here A is a nonnegative d × n matrix of rank d with no zero column, c ∈ Rn is a row vector,
and b ∈ Rd is a column vector. This program is feasible if and only if b lies in pos(A), which
is the convex polyhedral cone spanned by the columns of A. If c is ﬁxed and generic, and b
ranges over pos(A), then the set of optimal bases of (1) deﬁnes a regular triangulation of the
cone pos(A). This classical result due to Walkup and Wets is explained geometrically in [7,
Theorem 1.2.2]. The triangulation is replaced by a continuous shape under a regularization

Minimize c · x + (cid:15)

n
(cid:88)

i=1

H(xi) subject to Ax = b and x ≥ 0.

(2)

Here, H is a strictly convex smooth function on R≥0, and (cid:15) is a positive parameter. For
interior point methods, H is taken as a barrier function, meaning that its limit at 0 is +∞.
This enables us to remove the constraint x ≥ 0 in (2). The dual formulation of (1) reads:

Maximize b · p − (cid:15)

n
(cid:88)

i=1

H ∗

(cid:18) 1
(cid:15)

(cid:19)

(cid:2)A(cid:62)p − c(cid:3)

i

over all p ∈ Rd.

(3)

Here, H ∗(s) = supt∈R(st − H(t)) denotes the Legendre-Fenchel transform of the convex
function H, after the latter has been extended to all of R by setting H(t) = +∞ for t < 0.

1

 
 
 
 
 
 
The feasible set PA,b := {x ∈ Rn

≥0 : Ax = b } for (1) is a polytope. For every (cid:15) > 0, the
regularized problem (2) has a unique optimal solution x∗((cid:15)) in the relative interior of PA,b,
provided the function H is a barrier. The curve CA,b,c = {x∗((cid:15)) : 0 ≤ (cid:15) ≤ ∞} connects the
distinguished point x∗(∞) in PA,b to an optimal solution x∗(0) of the linear program (1).
The equations that cut out this curve have the following determinantal representation:

Ax = b

and

rank





A
c
H (cid:48)(x)



 ≤ d + 1.

(4)

The matrix on the right has d+2 rows and n columns. Its last row is the vector of derivatives
H (cid:48)(x) = (cid:0)H (cid:48)(x1), H (cid:48)(x2), . . . , H (cid:48)(xn)(cid:1).

For generic cost vectors c, the number of constraints in (4) equals d+(n−d−1) = n−1, so we
expect these to cut out an analytic curve in Rn. The distinguished interior point x∗(∞), at
(cid:19)
≤ d. For any ﬁxed (cid:15) ∈ R>0, the point x∗((cid:15)) on

which our curve starts, satisﬁes rank

(cid:18) A

H (cid:48)(x)

(cid:18)

(cid:19)

A
c + (cid:15)H (cid:48)(x)

the curve satisﬁes rank
then the curve is algebraic, and we can study its deﬁning ideal in R[x1, x2, . . . , xn].

≤ d. Moreover, if H and c satisfy certain hypotheses

We compare two widely used regularizations. The ﬁrst is the logarithmic barrier function
H(t) = −log(t), where (2) is the standard formulation of an interior point method for (1).
This function is self-concordant, which is a key property in convex optimization. The rank
condition in (4) translates into polynomials by taking numerators of all maximal minors.
These deﬁne an algebraic curve CR,+
A,b,c in the polytope PA,b. This is known as the central path.
Its starting point x∗(∞) is the analytic center of PA,b. The algebraic complexity of these
objects are governed by the bounded regions in certain hyperplane arrangements. See [1, 8].
Next consider the entropy function H(t) = t·log(t)−t, whose Legendre-Fenchel transform
equals H ∗(s) = exp(s). Here, (2) is the entropic regularization of (1). This approach is
popular in machine learning, especially for optimal transport problems [5, 11, 19]. Note that
H(t) is strictly convex but not strongly convex. It is not a barrier function since H(t) does
not diverge for t → 0. But, its derivative does, and this ensures the minimizer x∗((cid:15)) to be in
the relative interior of PA,b. To highlight algebraic features, we assume that the cost vector
c has integer coordinates. The rank condition in (4) is a system of Z-linear equations in
log(x1), . . . , log(xn). These translate into diﬀerences of monomials in R[x1, . . . , xn]. Indeed,
(4) speciﬁes the toric variety of the integer matrix (cid:0)A
A,b,c
by intersecting that toric variety with the linear space {Ax = b}. Its degree is bounded by
the normalized volume of a polytope given by (cid:0)A

(cid:1), and x∗(∞) is the Birch point of PA,b.

(cid:1). We obtain the entropic curve CT

c

c

Example 1 (d = 4, n = 6). We consider the transportation problem of format 2 × 3, as in
[8, Examples 2 and 14]. We here represent this by a matrix with linearly independent rows:







A =

1 1 1 0 0 0
0 0 0 1 1 1
1 0 0 1 0 0
0 1 0 0 1 0







2

.

(5)

To explore the generic behavior for this A, we ﬁx b = (7, 8, 4, 5)(cid:62) and c = (1, 0, 1, 0, 2, 5).
The transportation polytope PA,b is a hexagon in the plane {Ax = b} in R6. We use coordi-
nates (x1, x2), as these determine x3, x4, x5, x6. First consider its log-barrier geometry. The
edges of PA,b specify seven bounded regions, so the analytic center has algebraic degree seven:

x∗(∞) = (1.895889342, 2.337573614, 2.766537044, 2.104110658, 2.662426386, 3.233462956).

For generic cost vectors c, the central path has degree ﬁve. Two pictures are shown in [8,
Figure 1]. For the speciﬁc c above, the quintic polynomial deﬁning the central path equals

10x4

1x2 + 22x3

1x2

2 + 8x2

1x3

2 − 4x1x4

2 − 25x4

1 − 180x3

1x2 − 183x2

1x2

2 + · · · + 376x2

2 + 700x1 − 280x2.

Now compare this to entropic regularization. The Birch point has rational coordinates:

x∗(∞) =

1
15

(28, 35, 42, 32, 40, 48) = (1.8666, 2.3333, 2.8000, 2.1333, 2.6666, 3.2000).

The rank constraint in (4) translates into the binomial equation x2
6. The
degree drops from ten to nine when we intersect with {Ax = b}. The entropic curve equals

5 = x5

4x3

3x5

2x2

1x3

25x5

1x4

2+85x4

1x5

2+87x3

1x6

2+19x2

1x7

2−8x1x8

2−250x5

1x3

2−1275x4

1x4

2+· · ·+1531250x2

1x2−1071875x2
1.

As the vector c ranges over Z6, the degree of this curve can be arbitrarily large. For non-
rational c, the entropic curve is no longer algebraic. This is a general feature of toric geometry.
Note that pos(A) is the cone over a triangular prism, and c determines a triangulation
of that prism into three tetrahedra. There are six such triangulations, one for each vertex
of PA,b. Think of the triangulation as the union of three P3’s in P5. Regularization replaces
the triangulation by a nearby smooth variety. For the entropic regularization, this is a Segre
variety P1 × P2. For the log-barrier regularization, it is the reciprocal linear space for A. (cid:5)

The distinction between our two regularizations mirrors that between toric geometry and
matroid theory. In statistics, this is the distinction between toric models and linear models
[14, Section 1.2]. These objects are central in the study of positive geometries in combina-
torics and physics (cf. [18, Section 6]). In Section 2 we develop a comparative theory. After
a review of known facts in Proposition 2 and 3, we present our ﬁndings in Theorem 5 and 7.
They concern the algebraic curves and positive varieties arising from linear programming.

In Section 3 we turn to the optimal transport problem. This is ubiquitous in data science,
where entropic regularization is a method of choice [5]. Geometrically, PA,b is a transportation
polytope, and Segre varieties regularize triangulations of products of simplices, as seen in
Example 1. Our contribution is an extension of this theory to unbalanced regime, which was
studied in [3, 4]. We formulate the discrete conic coupling in eqn. (22), in the spirit of [12].
Section 4 is devoted to the toric geometry and combinatorics of our new variant. The
main result is a formula for the algebraic degree of conic optimal transport (Theorem 15).
In Section 5 we discuss numerical algorithms for the entropic regularization (2). The task is
to compute the points x∗((cid:15)) along the entropic curve CT
A,b,c, and to solve (1) by letting (cid:15) → 0.
.

3

2 Varieties and Positivity

1 , . . . , v−1

Let A be a d × n matrix of rank d with nonnegative integer entries and no zero column. We
write LA for the row space of A in Rn. We associate two aﬃne algebraic varieties with the
matrix A. Both have strong positivity properties that makes them relevant for statistics and
optimization. The reciprocal linear space RA is the Zariski closure in Cn of the set of points
v−1 = (v−1
n ) where v ranges over vectors in LA whose n coordinates are nonzero. The
toric variety TA is the Zariski cosure in Cn of the set of points exp(v) = (exp(v1), . . . , exp(vn))
where v ranges over LA. Both RA and TA are irreducible varieties of dimension d, deﬁned over
the ﬁeld Q of rational numbers. Their prime ideals live in the polynomial ring Q[x1, . . . , xn].
The prime ideal of RA has a distinguished universal Gr¨obner basis. It consists of the
circuit polynomials. A circuit of A is a non-zero vector u of minimal support in kernel(A),
assumed to have relatively prime integer coordinates. The corresponding circuit polynomial
is the numerator of the rational function (cid:80)n
i=1 ui/xi. This is due to Proudfoot and Speyer
(cf. [8, Proposition 12]). The prime ideal of TA is a toric ideal. It is generated by binomials
(cid:89)

(cid:89)

xu+ − xu− =

xui
i −

x−uj
j

,

i:ui>0

j:uj <0

where u runs over a ﬁnite set of integer vectors in kernel(A). This set is known in statistics
as a Markov basis for the matrix A. Here it usually does not suﬃce to consider only circuits.
We record the well-known formulas for the degrees of our two d-dimensional varieties.

Proposition 2. The degree of the reciprocal linear space RA is the M¨obius number of the
rank d matroid deﬁned by the matrix A. This is bounded above by (cid:0) n
(cid:1), with equality when
all d × d minors of A are non-zero. The degree of the toric variety TA equals the normalized
volume of the lattice polytope conv(A ∪ 0). There is no upper bound in terms of d and n.

d+1

We refer to [8, Section 3] for the deﬁnition of the M¨obius number. The fact that it gives
the degree of RA follows from the result of Proudfoot and Speyer stated above. The formula
for the degree of an aﬃne toric variety can be found in any text book on toric geometry. For
both varieties, consider the semialgebraic set of points with nonnegative real coordinates:

R+

A := RA ∩ Rn

≥0

and

A := TA ∩ Rn
T +

≥0.

(6)

Our hypotheses on A ensure that these sets are Zariski dense in RA and TA respectively, so
they have dimension d as well. We now identify A with the linear map Rn → Rd, v (cid:55)→ Av.

Proposition 3. Restricting the linear map A to the two sets in (6) deﬁnes homeomorphisms

R+

A (cid:39) pos(A)

and

T +
A (cid:39) pos(A).

The inverse map from the polyhedral cone on the right to the positive variety R+
on the left takes b ∈ pos(A) to the analytic center resp. Birch point of the polytope PA,b.
Proof. For each scenario, consider the map that takes b ∈ pos(A) to the point x∗(∞) in PA,b.
This was deﬁned in the Introduction as the solution to a convex optimization problem whose
critical equations are polynomials. The map is well-deﬁned and algebraic in both cases. The
image equals T +
A. Furthermore, we have A · x∗(∞) = b, so the composition with the
linear map A is the identity on pos(A). This gives the desired homeomorphisms in (7).

A resp. R+

(7)
A resp. T +

A

4

We now ﬁx a suﬃciently generic vector c ∈ Zn that serves as cost function in the linear
program (1). We augment the matrix A by the row c to obtain a (d + 1) × n matrix (cid:0)A
(cid:1).
c) be the associated reciprocal variety, and
This has rank d + 1, since c is generic. Let R(A
c) be the associated toric variety. Both of these live in Cn, and they have dimension
let T(A
d + 1. Propositions 2 and 3 hold for these varieties, with A replaced by (cid:0)A
(cid:1). We note that
c) was called the central sheet in [8]. Its degree was computed in [8, Theorem 11]: it is the
R(A
M¨obius number |µ(A, c)|. By contrast, Proposition 2 refers to the M¨obius number |µ(A)|.

c

c

The toric variety T(A

c) is the total space of the Gr¨obner degeneration of TA given by c,
c) is the normalized volume of the convex hull of the
(cid:1) together with the origin in Rd+1. This volume is a subtle invariant which

as in [7, Section 9.4]. The degree of T(A
n columns of (cid:0)A
incorporates both geometric and arithmetic properties of the integer entries of A and c.

c

In our set-up,
Example 4 (d = 2, n = 4). We consider the matrix A =
TA is a toric surface in C4, namely the cone over the twisted cubic curve. Its prime ideal is
(cid:104)x1x3 − x2
3(cid:105). The reciprocal surface RA happens to be isomorphic to
TA. Its prime ideal is (cid:104)x1x2 − 3x1x4 + 2x2x4, 2x1x3 − 3x1x4 + x3x4, x2x3 − 2x2x4 + x3x4(cid:105).

2, x1x4 − x2x3, x2x4 − x2

(cid:18)3 2 1 0
0 1 2 3

(cid:19)
.

We now augment A by the cost vector c = (c1, c2, c3, c4). The resulting varieties are

hypersurfaces in C4. The reciprocal variety R(A

c) is the aﬃne cubic threefold deﬁned by

x1x2x3x4
3

· det



 =





A
c
x−1

(c1 − 3c3 + 2c4)x1x3x4 + (c1 − 2c2 + c3)x1x2x3
−(c2 − 2c3 + c4)x2x3x4 − (2c1 − 3c2 + c4)x1x2x4.

(8)

The toric variety T(A

c) is an aﬃne threefold in C4, deﬁned by an irreducible binomial such as

xc1−3c3+2c4
2

xc1−2c2+c3
4

− xc2−2c3+c4
1

x2c1−3c2+c4
3

.

(9)

The coeﬃcients in (8) are the exponents in (9). The equation (9) is correct if and only if
c) equals
these exponents are relatively prime and nonnegative. In that case the degree of T(A
(cid:5)
2(c1 − c2 − c3 + c4). Thus the degree depends on sign conditions and divisibilities in c.

We now deﬁne the curves of interest in linear programming by intersecting our varieties
with the aﬃne-linear spaces {x ∈ Cn : Ax = b}, for b ∈ Rd. The resulting curves are denoted

CR
A,b,c = R(A

c) ∩ {x : Ax = b}

and

CT
A,b,c = T(A

c) ∩ {x : Ax = b}.

(10)

Theorem 5. For generic vectors b and c, the intersections in (10) are curves in Cn, namely
the central curve and the entropic curve of the LP (1). Their degrees satisfy
A,b,c) ≤ vol(conv((cid:0)A

A,b,c) = |µ(A, c)| ≤ (cid:0)n−1

and degree(CT

degree(CR

(cid:1) ∪ 0)).

(11)

(cid:1)

d

c

Proof. The formula for the degree of the central curve CR
The upper bound is attained when all maximal minors of the matrix (cid:0)A

A,b,c appears in [8, Theorem 13].
(cid:1) are non-zero. The

c

5

A,b,c is the intersection of the toric variety T(A

entropic curve CT
of T(A
inequality can be strict, even when b and c are generic. See Proposition 9.

c) with {x : Ax = b}. The degree
(cid:1) ∪ 0)). Hence the inequality follows from B´ezout’s Theorem. This

c) equals vol(conv((cid:0)A

c

Remark 6. If n = d + 1 then Theorem 5 is trivial because and R(A
is a line segment. The curves are straight lines, and all numbers in (11) are equal to 1.

c) = T(A

c) = Cn and PA,b

For applications in linear programming, we restrict our curves to the positive orthant:

CR,+
A,b,c = R+
c)
(A

∩ {x : Ax = b}

and

CT,+
A,b,c = T +
c)
(A

∩ {x : Ax = b}.

(12)

These are real algebraic curves inside the polytope PA,b. Following [8], we call CR,+
A,b,c the central
path of the linear program (1), and we call CT,+
A,b,c the entropic path of (1). A slight distinction
to [1, 8] is that our central path travels from the vertex of PA,b where c is minimized to
the vertex where c is maximized, passing through the analytic center of PA,b. For instance,
Figure 1 in [8] shows all real points on the central curve. The central path is the piece inside
the shaded hexagon PA,b. That diagram illustrates the transportation problem in Example 1.
We now come to the parametrizations of our curves. These are understood by introducing
scaled versions of the varieties RA and TA. We ﬁx a cost vector c ∈ Rn which is generic in
the sense that (1) has a unique optimal solution for all b ∈ pos(A). Let (cid:15) be a positive real
parameter, also assumed to be ﬁxed for now. We consider the scaling 1
(cid:15) c of the cost vector c.
(cid:15) c of Rn. The reciprocal aﬃne space RA,c,(cid:15) is the
n ) where v ranges over vectors in
(cid:15) c whose n coordinates are nonzero. The scaled toric variety TA,c,(cid:15) is the Zariski cosure

Zariski closure in Cn of the set of points v−1 = (v−1
LA − 1
in Cn of the set of points exp(v) = (exp(v1), . . . , exp(vn)) where v ranges over LA − 1

Fix the aﬃne-linear subspace LA − 1

1 , . . . , v−1

Both RA,c,(cid:15) and TA,c,(cid:15) are irreducible aﬃne varieties of dimension d. They are deﬁned
over appropriate subﬁelds of the real numbers R, namely the ﬁeld Q((cid:15)) for RA,c,(cid:15), and the
ﬁeld Q(z) for TA,c,(cid:15), where z = exp(−1/(cid:15)). If we abbreviate zc = (zc1, zc2, . . . , zcn), then

(cid:15) c.

TA,c,(cid:15) = zc (cid:63) TA.

(13)

Here (cid:63) denotes the Hadamard product, so TA,c,(cid:15) is a torus translate of our toric variety TA.
We now present a generalization of Proposition 3, pertaining to the nonnegative varieties

R+

A,c,(cid:15) := RA,c,(cid:15) ∩ Rn

≥0

and

A,c,(cid:15) := TA,c,(cid:15) ∩ Rn
T +

≥0.

(14)

These sets are Zariski dense in RA,c,(cid:15) and TA,c,(cid:15) respectively, so they have dimension d.

Theorem 7. Restricting the linear map A to the two sets in (14) deﬁnes homeomorphisms

R+

A,c,(cid:15) (cid:39) pos(A)

and

T +
A,c,(cid:15) (cid:39) pos(A).

(15)

The inverse map from the polyhedral cone on the right to the positive variety on the left takes
b ∈ pos(A) to the optimal point x∗((cid:15)) of (2), where H(t) = log(t) resp. H(t) = t · log(t) − t.
For (cid:15) → 0, the homeomorphism approaches the regular triangulation of pos(A) given by c.

6

Proof. The strict convexity of the objective function in (2) ensures that the optimal solution
x∗((cid:15)) is the unique critical point of that function in PA,b. The critical equations are those that
deﬁne our varieties, and hence the singleton {x∗((cid:15))} is equal to R+
A,c,(cid:15) ∩PA,b.
These two singletons are diﬀerent, but they both converge to the same optimal vertex x∗(0)
of (1). The regular triangulation given by c is given combinatorially by the optimal bases as
b ranges over pos(A). Each optimal basis speciﬁes a d-dimensional face of the orthant Rn
≥0,
A,c,(cid:15) and T +
and the images of these cones triangulate pos(A). Both semialgebraic sets R+
A,c,(cid:15)
converge, in the Hausdorﬀ sense, to the fan that consists of these faces of Rn
≥0. The linear
map A induces a piecewise-linear isomorphism between that fan and the cone pos(A).

A,c,(cid:15) ∩PA,b resp. T +

3 Optimal Transport

This section features a case study that is inspired by applications in machine learning [5, 11].
The classical Monge optimal transportation (OT) problem deals with the construction of
optimal couplings for two given probability distributions. We explain how this problem, in
its simplest version, can be written as a linear program (1). Many generalizations can be
treated analogously; see e.g. [9, 10]. In Subsection 3.2 we carry this out for unbalanced OT.

3.1 The Classical Case

Given probability distributions µ ∈ Rd1
and [d2] = {1, . . . , d2}, and a cost matrix c = (cκ,λ)κ∈[d1],λ∈[d2] ∈ Rd1×d2, we aim to

≥0 and ν ∈ Rd2

≥0 on the ﬁnite sets [d1] = {1, . . . , d1}

minimize

(cid:88)

cκ,λ · xκ,λ

subject to x ≥ 0 and

(16)

(κ,λ)∈[d1]×[d2]

(cid:88)

λ∈[d2]

xκ,λ = µκ for all κ ∈ [d1] and

(cid:88)

κ∈[d1]

xκ,λ = νλ for all λ ∈ [d2].

(17)

We interpret µκ as the number of units of a product stored at κ ∈ [d1] and νλ as the number
of units desired at λ ∈ [d2]. Our goal is to transport all units from [d1] to [d2] with minimal
transportation cost. The matrix entry cκ,λ is the cost of transporting one unit from κ to λ.
The feasible solutions x = (xκ,λ) are known as transportation plans, or as couplings of µ and
ν. Since (cid:107)µ(cid:107)1 = (cid:107)ν(cid:107)1 = 1, any such solution x is a probability distribution on [d1] × [d2].

The matrix A for the linear program above has d = d1 + d2 − 1 rows and n = d1d2
columns, and its entries are in {0, 1}.
It represents the linear map that takes a d1 × d2
matrix x to its vector b = (µ, ν) of row sums and column sums. Here νd2 is deleted, so the
rows of A are linearly independent. In OT theory it is customary to keep this redundancy.
We saw the matrix A for d1 = 2, d2 = 3 in (5). The feasible region PA,b is a transportation
polytope, consisting of all nonnegative d1 × d2 matrices with ﬁxed row and column sums.
Every transportation polytope contains a unique rank one matrix x, namely the Birch point
x = (µκ · νλ) of PA,b. This corresponds to an independent joint distribution.

The polytope underlying the cone pos(A) is the product ∆d1−1 × ∆d2−1 of two simplices.
The triangulations of pos(A) are studied in [7, Section 6.2]. The toric variety TA is the cone

7

over the Segre variety Pd1−1 × Pd2−1. Its points are the d1 × d2 matrices of rank ≤ 1. The
prime ideal of TA is generated by the 2 × 2 minors of a d1 × d2 matrix; see [17, Example 5.1].
The positive variety T +
A represents the independence model for distributions on [d1] and [d2].
We know from Proposition 3 that the linear map A identiﬁes T +

A with the cone pos(A).

The same holds for the positive part R+

A of the reciprocal variety RA. From a combinato-
rial perspective, it would be interesting to study this variety for OT in more detail. However,
in the remainder of this paper we focus on the toric variety TA instead. Here is the reason:

Remark 8. In machine learning one uses entropic regularization rather than logarithmic
barrier regularization in (2). The former is more eﬃcient than the latter. Thus, when d1
and d2 are large, the entropic path CT,+
A,b,c. We refer to
[5] for an explanation. Example 16 and the introduction of [19] oﬀer details and references.

A,b,c is preferred to the central path CR,+

We next explain the degree drop which was observed for the entropic curve in Example 1.

Proposition 9. Let b ∈ pos(A) and c ∈ Zd1×d2 where A is the matrix for OT. If d2 ≥ 3
then the upper bound in (11) for the degree of the entropic curve CT

A,b,c is always strict.

Proof. The trivial case d1 = d2 = 2 is covered by Remark 6. We have d2 ≥ 3, so n = d1d2 is
c) are aﬃne toric varieties in Cn, we consider their
larger than d+1 = d1+d2. Since TA and T(A
c) in Pn. We write {x0 = 0} for the hyperplane at inﬁnity Pn\Cn. We are
closures T A and T (A
T
interested in the closure in Pn of the entropic curve. This projective curve is denoted C
A,b,c.
The upper bound on the right in (11) is the degree of the (d+1)-dimensional toric variety
c) with the codimension d linear space {x ∈ Pn : Ax = x0b}. One
c) in Pn. We intersect T (A
T (A
T
A,b,c. By the general B´ezout
of the irreducible components of this intersection is the curve C
Theorem, the equation degree(cid:0) C
(cid:1) = degree(cid:0) T (A
(cid:1) means that there is no component
c)
other than the entropic curve. Our goal is therefore to identify an extraneous component in
c) ∩ (cid:8)x ∈ Pn : Ax = x0b(cid:9).

T
A,b,c

T (A

(18)

Restricting to the hyperplane at inﬁnity, we see that (18) contains

T A ∩ (cid:8)x ∈ Pn : Ax = 0(cid:9) ⊇ TA ∩ (cid:8)x ∈ Cn : Ax = 0(cid:9).

(19)

The aﬃne variety on the right consists of all d1 × d2 matrices of rank ≤ 1 whose rows
and columns sum to zero. Such matrices have the form x = (µκ · νλ) where µ ∈ Cd1 and
ν ∈ Cd2 satisfy (cid:80)d1
λ=1 νλ = 0. This variety has dimension d1 + d2 − 3 ≥ 2, so the
intersection (18) has an extraneous component whose dimension exceeds that of CT

κ=1 µκ = (cid:80)d2

A,b,c.

Remark 10. Our proof reﬂects the special behavior we already know from the intersection
T A ∩ (cid:8)x ∈ Pn : Ax = x0b(cid:9) ⊇ TA ∩ (cid:8)x ∈ Cn : Ax = b(cid:9).

(20)

The toric variety TA has degree (cid:0)d1+d2−2
(cid:1), but the intersection on the right has degree one.
It is a single point, which is rational over b = (µ, ν), namely the Birch point x = (µκ · νλ).

d1−1

8

3.2 Unbalanced Case: Conic Coupling

Problem (16) is infeasible for optimal transport between measures µ and ν with (cid:107)µ(cid:107)1 (cid:54)= (cid:107)ν(cid:107)1.
This unbalanced case is relevant in the statistical analysis of partial or incomplete data sets.
One remedy is to replace the hard constraint (17) by a penalty function, e.g. Kullback-Leibler
[3]. We here follow [4, 12] and present a linear programming formulation (1). In particular,
this formulation can be understood as a moment constrained optimal transport problem.

Let us assume that, after discretization and scaling, the entries of the margins µ and ν
are integers. This can be achieved up to arbitrary numerical precision. More precisely, we
ﬁx positive integers e1 and e2 such that µκ ∈ [e1] for all κ ∈ [d1] and νλ ∈ [e2] for all λ ∈ [d2].
We ﬁx the state spaces [d1]×[e1] and [d2]×[e2]. A joint probability distribution x =

(xκ,i,λ,j) on their product ([d1]×[e1]) × ([d2]×[e2]) is called a conic coupling for µ and ν if

d2(cid:88)

e1(cid:88)

e2(cid:88)

λ=1

i=1

j=1

i xκ,i,λ,j = µκ for κ ∈ [d1] and

d1(cid:88)

e1(cid:88)

e2(cid:88)

κ=1

i=1

j=1

j xκ,i,λ,j = νλ for λ ∈ [d2].

(21)

We also assume that the cost function is extended to c : ([d1]×[e1]) × ([d2]×[e2]) → R. The
value cκ,i,λ,j is interpreted as the cost of generating j units of mass at λ ∈ [d2] from i units
of mass at κ ∈ [d1]. We propose the following relaxation of OT in the unbalanced case:

Minimize

(cid:88)

cκ,i,λ,j · xκ,i,λ,j subject to x ≥ 0 and (21).

(22)

(κ,i,λ,j) ∈
[d1]×[e1]×[d2]×[e2]

In the context of statistics, one can (but need not) impose the normalization constraint

(cid:88)

xκ,i,λ,j = 1.

(κ,i,λ,j) ∈
[d1]×[e1]×[d2]×[e2]

(23)

The minimizers x for the problem (22)-(23) are called optimal conic couplings of µ and ν.
They deﬁne a cost-optimal random sampling mechanism of particle cluster pairs in [d1] and
[d2] whose mean marginal empirical distributions are µ and ν, respectively. We next show
that our formulation makes sense, meaning that conic couplings always exist.
Lemma 11. The linear program (22)-(23) is feasible for all µ ∈ [e1]d1 and all ν ∈ [e2]d2.
Proof. Let µ = 1
ν be the induced probability distributions on [d1] and [d2].
(cid:107)µ(cid:107)1
We deﬁne a probability distribution x = (xκ,i,λ,j) on the space [d1]×[e1]×[d2]×[e2] by setting

µ and ν = 1
(cid:107)ν(cid:107)1

xκ,i,λ,j = µκ · δ(cid:107)µ(cid:107)1,i · νλ · δ(cid:107)ν(cid:107)1,j.
Here we use Kronecker delta notation, i.e. δa,b = 1 if a = b and δa,b = 0 if a (cid:54)= b. The
numbers in (24) are nonnegative. One checks that they satisfy both (21) and (23).

(24)

To connect to our general set up we write the linear program (22) in the standard form (1).
In what follows we assume that d1, d2, e1, e2 ≥ 2. The matrix A has n = d1e1d2e2 columns and
d = d1 + d2 linearly independent rows. We identify Cn with the space of tensors x = (xκ,i,λ,j)
of format d1×e1 × d2×e2. The column of A indexed by (κ, i, λ, j) is the vector ieκ ⊕ jeλ in
Nd = Nd1 ⊕ Nd2, where eκ and eλ denote unit vectors. If we set b = (µ, ν)T ∈ Rd then the
polytope PA,b consists of all nonnegative tensors x that satisfy the linear constraints (21).

9

Figure 1: The 4-dimensional cone pos(A) in Example 12 has a slanted cube for its base.

Example 12 (d1 = e1 = d2 = e2 = 2). Our matrix has d = 4 rows and n = 16 columns:

A =






1 1 1 1 2 2 2 2 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 1 1 1 1 2 2 2 2
1 2 0 0 1 2 0 0 1 2 0 0 1 2 0 0
0 0 1 2 0 0 1 2 0 0 1 2 0 0 1 2




 .

(25)

We identify C16 with the space of 2 × 2 × 2 × 2-tensors x = (xκ,i,λ,j). The coordinates
x1111, x1112, . . . , x2222 are ordered lexicographically, which matches the column ordering of A.
The toric variety XA has dimension 4 and degree 72 in C16. The prime ideal of XA is
homogeneous with respect to the column sum grading (2, 3, 3, 4, 2, 3, 3, 4, 2, 3, 3, 4, 2, 3, 3, 4).
It is minimally generated by 39 binomials: 5 of degree 4, 8 of degree 5, 18 of degree 6, and 8
of degree 7. The polyhedral cone pos(A) is spanned by 8 rays, and it has 6 facets. Explicitly,

pos(A) = (cid:8) b ∈ R4

≥0 : b1 + b2 ≤ 2b3 + 2b4 and b3 + b4 ≤ 2b1 + 2b2

(cid:9).

(26)

This is the cone over a polytope combinatorially isomorphic to a 3-cube, shown in Figure 1.
(cid:5)
The vertices of that cube correspond to the eight columns of A with entries 0, 0, 1, 2.

4 Polytopes and their Volumes

The entropic method for solving the linear program (1) is a two-step process. First, the
solution x∗((cid:15)) to the regularized problem (2) is computed. Here, (cid:15) > 0 and H(t) = t log(t)−t.
Second, one lets (cid:15) → 0 and tracks the minimizer x∗((cid:15)) to the optimal vertex x∗(0) of PA,b.

Step 1 amounts to solving the polynomial system given by A x = b and x ∈ TA,c,(cid:15). For
linear programming, one wants the unique positive solution x∗((cid:15)). But, for other applica-
tions, e.g. scattering amplitudes in particle physics [18], all complex solutions are needed. A
standard method for ﬁnding them all is homotopy continuation [16]. We expect the number
of solutions to be deg TA,c,(cid:15) = vol(conv(A∪0)), and this is the number of paths to be tracked.
This number is also the algebraic degree of x∗((cid:15)), over the ground ﬁeld Q(z) in (13).

Numerical algebraic geometry interfaces gracefully with interior point methods in opti-
mization. In a scenario where the matrix A is ﬁxed and (2) must be solved for many diﬀerent
vectors b and c, it makes sense to initialize by computing all complex solutions. This needs
to be done only once. Indeed, for new parameters b(cid:48), c(cid:48), one can use x∗((cid:15)) ∈ TA,c,(cid:15) ∩ {A x = b}

10

as a start solution to ﬁnd the positive point in TA,c(cid:48),(cid:15) ∩ {A x = b(cid:48)}. We will come back to
continuation methods at the end of Section 5, in our discussion of step 2, in which (cid:15) → 0.

Given an interesting matrix A, the reasons above motivate the combinatorial problem of
ﬁnding the degree of TA,c,(cid:15). This means ﬁnding the volume of the polytope conv(A ∪ 0). We
here solve this problem for unbalanced optimal transport, as formulated Subsection 3.2.

Let A be the d × n matrix for conic coupling (22), where d = d1 + d2 and n = d1e1d2e2.
For any right hand side b = (b1, . . . , bd1, bd1+1, . . . , bd2)T , the set of feasible solutions is the
polytope PA,b. We know that PA,b (cid:54)= ∅ if and only if b ∈ pos(A), and dim(PA,b) = n − d if
and only if b is in the interior of pos(A). Our next result characterizes that cone, as in (26).

Proposition 13. The feasibility cone pos(A) for the conic coupling problem (22) equals

(cid:8) y ∈ Rd

≥0 : y1 + · · · + yd1 ≤ e1(yd1+1 + · · · + yd1+d2), yd1+1 + · · · + yd1+d2 ≤ e2(y1 + · · · + yd1)(cid:9).

This d-dimensional cone has 2d1d2 rays and d1 + d2 + 2 facets. It is the cone over a simple
(d − 1)-dimensional polytope which is combinatorially isomorphic to the product of simplices

∆1 × ∆d1−1 × ∆d2−1.

Proof. Let K be the polyhedral cone given in the assertion. Every column vector ieκ ⊕ jeλ
of the matrix A lies in K because 0 ≤ i ≤ je1 and 0 ≤ j ≤ ie2. Hence pos(A) ⊆ K. For the
reverse inclusion, we identify the extreme rays of K. Every vector in K must have at least
one positive coordinate among the ﬁrst d1 coordinates and ditto for the last d2 coordinates.
We see that at most d − 2 of the nonnegativity constraints can be attained. Thus every
extreme ray must attain equality in at least one of the other inequalities. This implies that
the extreme rays are eκ ⊕ e2eλ for some κ ∈ [d1] and e1eκ ⊕ e2eλ for some λ ∈ [d2].

The following result pertains to the aﬃne variety TA. Its proof is analogous to that above.

Proposition 14. The d-dimensional polytope conv(A ∪ 0) has d + 4 facets, given by the d + 2
inequalities deﬁning pos(A), together with y1 + · · · + yd1 ≤ e1 and yd1+1 + · · · + yd1+d2 ≤ e2.

Solving the entropic regularization (2) for (22) means intersecting the polytope PA,b with
the scaled toric variety TA,c,(cid:15) = zc (cid:63) TA, where z = exp(−1/(cid:15)). Algebraically, we compute
the unique positive solution x = x∗((cid:15)) to the following equations, with H(t) = t · log(t) − t:

Ax = b

and

rank

(cid:18)

(cid:19)

A
c + (cid:15)H (cid:48)(x)

≤ d + 1.

(27)

The algebraic degree of (27) is the number of solutions in Cn. This is the degree over Q of the
ﬂoating point numbers that are output by any numerical algorithm. It is bounded above by

degree(TA,c,(cid:15)) = degree(TA) = vol(cid:0)conv(A ∪ 0)(cid:1) .

(28)

Our main result is a formula in terms of d1, e1, d2, e2 for this algebraic complexity measure:
in other words, we generalize the number 72, which is the degree of TA ⊂ C16 in Example 12.

11

Theorem 15. The algebraic degree of the constraints (27) for optimal conic coupling is

degree(TA) =

(cid:19)(cid:18)

(cid:18)d1+d2
d1

(ed1

1 − 1)(ed2

2 − 1) +

d1
d1+d2

(ed2

2 − 1) +

d2
d1+d2

(cid:19)

(ed1

1 − 1)

. (29)

2

To illustrate our formula, consider the binary case (d1 = d2 = 2), where it gives (cid:0)4

43) = 72, and the ternary case (d1 = d2 = 3), where (cid:0)6

43 + 2
Proof. We compute the volume in (28). Fix integers d, e ≥ 2 and consider the d-polytope

626) = 14040.

(cid:1)(262 + 3

626 + 3

3

2

(cid:1)(9 +

Pd,e = conv(cid:8) kei : i = 1, . . . , d and k = 1, . . . , e(cid:9).

The normalized volume of this polytope is ed −1. The convex hull of the columns of A equals

The normalized volume of a direct product is multiplicative up to a binomial coeﬃcient, so

conv(A) = Pd1,e1 × Pd2,e2.

vol(conv(A)) = (cid:0)d1+d2
d1

(cid:1) vol(Pd1,e1) vol(Pd2,e2) = (cid:0)d1+d2

d1

(cid:1)(ed1

1 − 1)(ed2

2 − 1).

(30)

This explains the ﬁrst summand in (29). It remains to determine the volume of the region
conv(A ∪ 0)\conv(A). To this end, we consider the facets of conv(A) that are visible from
the origin 0. There are precisely two such facets, and they are deﬁned respectively by

y1 + · · · + yd1 = 1 and yd1+1 + · · · + yd2 = 1.

(31)

These two facets are the (d1+d2−1)-dimensional polytopes ∆d1−1×Pd2,e2 and Pd1,e1 ×∆d2−1.
Since the origin has lattice distance one from the hyperplanes (31), the volume of the region
conv(A ∪ 0)\conv(A) coincides with the sum of the volumes of the two polytopes:

vol(cid:0)∆d1−1 × Pd2,e2

(cid:1) + vol(cid:0)Pd1,e1 × ∆d2−1

(cid:1) = (cid:0)d1+d2−1

(cid:1)(de2

2 − 1) + (cid:0)d1+d2−1

(cid:1)(de1

1 − 1).

d2

d1

This gives the last two summands in (29), and the proof is complete.

5 Computational Schemes

We now turn to convex optimization methods for solving (2). Recall that H(t) = t · log(t) − t
and hence H ∗(s) = exp(s) in the dual formulation. We can solve (3) using coordinate ascent,
i.e. by iteratively optimizing each variable pi in (3) in a cyclic order. In statistics, this is
known as iterative proportional scaling (IPS, see [6, 15]). This method converges linearly [13].
Randomized iterations over the pi can further improve the performance. When each one-
dimensional optimization is computationally cheap, this method is particularly interesting.

Example 16 (Sinkhorn iterations). For classical optimal transport (16), coordinate ascent is
the well-known Sinkhorn algorithm [2, 5, 11]. It uses highly eﬃcient matrix-vector products.

12

Writing (fκ)κ∈[d1] and (gλ)λ∈[d2] for the dual variables, the dual OT problem (3) reads:

Maximize

d1(cid:88)

κ=1

µκfκ +

d2(cid:88)

λ=1

νλgλ − (cid:15) ·

d1(cid:88)

d2(cid:88)

κ=1

λ=1

exp(cid:0) (fκ + gλ − cκ,λ)/(cid:15) (cid:1).

(32)

It is easy to solve this for each variable separately. Equating derivatives to zero, we ﬁnd

fκ = − (cid:15) · log

exp(cid:0)(gλ − cκ,λ)/(cid:15)(cid:1)

(cid:33)

(cid:32) d2(cid:88)

λ=1

+ (cid:15) · log(µκ) and similarly for gλ.

(33)

Sinkhorn iteration means executing these assignments. A useful reformulation is obtained
by setting Fκ = exp(fκ/(cid:15)), Gλ = exp(fλ/(cid:15)), and Kκ,λ = exp(−cκ,λ/(cid:15)). With this, the
update rules are Fκ = µκ/[K · G]κ and Gλ = νλ/[F · K]λ. The primal solution is the matrix
x = diag(F ) · K · diag(G). These steps are highly parallelizable, so large-scale problems can
be solved eﬀectively. This explains the preference for entropic regularization in Remark 8. (cid:5)

Coordinate ascent can be applied for any matrix A, but in general there is no simple
formula for the one-variable updates. But, we can resort to non-linear optimization for this.

Example 17 (Coordinate ascent for entropic conic transport). The dual problem for (22) is

Maximize h +

d1(cid:88)

κ=1

µκfκ +

d2(cid:88)

λ=1

νλgλ − (cid:15) ·

(cid:88)

κ,λ,i,j

exp(cid:0) (h + ifκ + jgλ − cκ,i,λ,j)/(cid:15) (cid:1).

(34)

Here we also assumed (23), and h is the dual variable for that normalization constraint.
Coordinate ascent means that we compute, for each κ, the unique positive solution Fκ to

d1(cid:88)

i=1

i · γκ,i · (Fκ)i = µκ ,

(35)

where γκ,i = (cid:80)

λ,j exp(cid:0)(h + jgλ − cκ,i,λ,j)/(cid:15)(cid:1). This step is more costly than applying (33). (cid:5)
Solving polynomials is costly. One prefers cheap iterations, inspired by ﬁrst-order meth-
ods. Of special interest is the Darroch-Ratcliﬀ algorithm [6], which is also known as gen-
eralized iterative scaling (GIS). This was recognized in [15] as an instance of majorization-
minimization on the dual formulation (3). GIS is a remarkably simple iterative process. As
with Sinkhorn, each step involves d matrix-vector products. See [2, Figure 4] for the connec-
tion. Theorem 18 below shows that GIS can be used1 eﬀectively for conic coupling (22)-(23).
Before starting the iteration, we modify A, b and c slightly. To match [6], we formulate
an equivalent linear program where all columns of A have the same sum. For this conversion,
we require that the all-ones vector (1, . . . , 1) is in the row space LA. In geometric terms, this
means that TA is the aﬃne cone over a projective toric variety. The matrix A for classical OT
satisﬁes this assumption. In the unbalanced case, it holds after we add the constraint (23).

1An illustration of entropic conic unbalanced OT, for numerical comparison between GIS, IPS and general

purpose convex optimization, is implemented at https://github.com/fxv27/EntropicConicUOT

13

We now assume (1, . . . , 1) ∈ LA. Fix b ∈ pos(A). Then s = (cid:80)n

i=1 xi is ﬁxed for x ∈ PA,b.
Let a be the maximum among the column sums of A. To each column aj, we append the
entry ad+1,j = a − |aj|, where |aj| = (cid:80)d
i=1 aij. Prepending the column (0, . . . , 0, a), we obtain

A =

(cid:20) 0

a ad+1,1

(cid:21)

A
· · · ad+1,n

∈ N(d+1)×(n+1).

Note that the entries in each column of A sum to a. Let sc = 1 + (cid:80)n

i=1 exp(−ci/(cid:15)), and

β =

(cid:18) b

s + 1

, a −

(cid:19)(cid:62)

|b|
s + 1

and γ = (cid:0)(cid:15) log(sc), c1 + (cid:15) log(sc), . . . , cn + (cid:15) log(sc)(cid:1).

These data deﬁne the following variant of the regularized linear program (2):

Minimize γ · y + (cid:15)

n
(cid:88)

i=0

H(yi) subject to A y = β and y ≥ 0.

(36)

We now rephrase the result of Darroch and Ratcliﬀ [6] in the geometric setting of Section 2.
An essentially equivalent formulation was presented recently in [2, Proposition 5.1].

Theorem 18. If (2) is feasible, then the solution x∗((cid:15)) is given by (y1/y0, . . . , yn/y0), where
y = y∗((cid:15)) ∈ Rn+1
A,γ,(cid:15) ∩
≥0
{A y = β}. It satisﬁes (cid:80)n
i=0 yi = 1 and is obtained as the unique limit point of the iteration

is the unique solution to (36). That is, y is the unique point in T +

y(0) = zγ := exp(−γ/(cid:15)),

y(k+1)
i

= y(k)
i

(A y(k))ai
i=0 βi = a, every solution y to (36) satisﬁes (cid:80)n

(cid:18) βai

(cid:19) 1

a

Proof. Since (cid:80)n
ι : (x1, . . . , xn) (cid:55)→ 1

|x|+1(1, x1, . . . , xn). The map sending b to β is such that the diagram

i=0 yi = 1. Consider the map

for k → ∞.

(37)

T +

A,c,(cid:15)

ι

T +
A,γ,(cid:15) ∩ ∆n

pos(A)

b (cid:55)→β

conv(A)

is commutative. Here the vertical maps correspond to the isomorphism T +
A,c,(cid:15) (cid:39) pos(A)
in Theorem 7. The diagram shows that (36) has the solution y = y∗((cid:15)) = ι(x∗((cid:15))). The
iteration (37) and its convergence can be derived from the proof of [6, Theorem 1].

The geometric interpretation of Theorem 18 is shown in Figure 2. The linear map given
by A sends the probability simplex ∆n onto the polytope conv(A). Note that zγ lies in ∆n.
The polytope PA,β is the set of all points in ∆n that map to β ∈ conv(A) under A. It is
shown as a green triangle. The toric variety TA,γ,(cid:15) inside ∆n is shown in blue, and conv(A)
is the red line segment. The point zγ = y(0) lies on TA,γ,(cid:15) and is updated throughout the
iteration. The solution y = y∗((cid:15)) = limk→∞ y(k) to (36) is the unique point in TA,γ,(cid:15) ∩ PA,β.

14

Figure 2: Illustration of the GIS algorithm from Theorem 18.

We now turn to the second step of the entropic interior point method, which consists of
tracking x∗((cid:15)) to the optimal vertex x∗(0) of PA,b. We assume that c is suﬃciently generic, so
that x∗(0) is indeed a vertex. Observe that, for all µ ∈ (0, (cid:15)], we have x∗(µ) > 0, A x∗(µ) = b
and x∗(µ) ∈ TA,c,µ. Equivalently, x∗(µ) = (t(µ)aj )j=1,...,n, where t(µ) ∈ Rd

>0 is such that

n
(cid:88)

j=1

aij exp(−cj/µ) t(µ)aj = bi

for i = 1, . . . , d.

(38)

The resulting functions t(µ)aj parametrize the entropic path for µ ∈ (0, (cid:15)]. The starting point
t((cid:15)) is found by solving the binomial equations x∗((cid:15))j = t((cid:15))aj , j = 1, . . . n. This can be done
by a Smith normal form computation. The tracking for µ → 0+ is carried out with standard
predictor-corrector techniques from numerical homotopy continuation [16, Section 2.3].

We conclude with a toric interpretation of the homotopy (38). For µ = (cid:15) > 0, each of
the Laurent polynomials in (38) deﬁnes a hypersurface in the projective toric variety YP
associated to the polytope P = conv(A ∪ 0). There are vol(P ) many solutions to (38) in
YP , one of which gives x∗((cid:15)). For µ → 0, this positive solution drifts to a lower dimensional
torus orbit in YP , indicating which inequalities in x∗(0) ≥ 0 are active. Identifying this orbit
can be done by tracking the homotopy path t(µ) in homogeneous coordinates on YP .

References

[1] X. Allamigeon, P. Benchimol, S. Gaubert and M. Joswig: Log-barrier interior point methods

are not strongly polynomial, SIAM J. Appl. Algebra Geom. 2 (2018) 140–178.

[2] C. Am´endola, K. Kohn, P. Reichenbach and A. Seigal: Toric invariant theory for maximum

likelihood estimation in log-linear models, Algebraic Statistics 12 (2021) 187–211.

15

[3] L. Chizat, G. Peyr´e, B. Schmitzer and F.-X. Vialard: Scaling algorithms for unbalanced optimal

transport problems, Mathematics of Computation 87 (2018) 2563–2609.

[4] L. Chizat, G. Peyr´e, B. Schmitzer and F.-X. Vialard: Unbalanced optimal transport: dynamic

and Kantorovich formulations, Journal of Functional Analysis 274 (2018) 3090–3123.

[5] M. Cuturi: Sinkhorn distances:

lightspeed computation of optimal transport, Advances in

Neural Information Processing Systems 26 (NIPS 2013).

[6] J. Darroch and D. Ratcliﬀ: Generalized iterative scaling for log-linear models, Ann. Math.

Statist. 43 (1972) 1470–1480.

[7] J. De Loera, J. Rambau and F. Santos: Triangulations: Structures for Algorithms and Appli-

cations, Algorithms and Computation in Mathematics, 25, Springer, Berlin, 2010.

[8] J. De Loera, B. Sturmfels and C. Vinzant: The central curve in linear programming, Founda-

tions of Computational Mathematics 12 (2012) 509–540.

[9] Y. Dolinsky and H. Mete Soner: Martingale optimal transport and robust hedging in continuous

time, Probab. Theory Related Fields 160 (2014) 391–427.

[10] G. Guo and J. Ob(cid:32)l´oj: Computational methods for martingale optimal transport problems,

Ann. Appl. Probab. 29 (2019) 3311–3347.

[11] J. Karlsson and A. Ringh: Sinkhorn iterations for regularizing inverse problems using optimal

mass transport, SIAM J. Imaging Sciences 10 (2017) 1935–1962.

[12] M. Liero, A. Mielke and G. Savar´e: Optimal entropy-transport problems and a new Hellinger-

Kantorovich distance between positive measures, Invent. Math. 211 (2018) 969–1117.

[13] Z. Luo and P. Tseng: On the convergence of the coordinate descent method for convex diﬀer-
entiable minimization, Journal of Optimization Theory and Applications 72 (1992) 7–35.

[14] L. Pachter and B. Sturmfels: Algebraic Statistics for Computational Biology, Cambridge Uni-

versity Press, 2005.

[15] Y. She and S. Tang: Iterative proportional scaling revisited: a modern optimization perspective,

Journal of Computational and Graphical Statistics 28 (2019) 48–60.

[16] A. Sommese and C. Wampler: The Numerical Solution of Systems of Polynomials Arising in

Engineering and Science, World Scientiﬁc Publishing, Hackensack, 2005.

[17] B. Sturmfels: Gr¨obner Bases and Convex Polytopes, American Mathematical Society, Univ.

Lectures Series, No 8, Providence, Rhode Island, 1996.

[18] B. Sturmfels and S. Telen: Likelihood equations and scattering amplitudes, Algebraic Statistics

12 (2021) 167–186.

[19] J. Weed: An explicit analysis of the entropic penalty in linear programming, 31st Annual
Conf. on Learning Theory, Proceedings of Machine Learning Research 75 (2018) 1–15.

Authors’ addresses:

Bernd Sturmfels, MPI-MiS Leipzig and UC Berkeley
Simon Telen, MPI-MiS Leipzig
Fran¸cois-Xavier Vialard, LIGM, Universit´e Gustave Eiﬀel
Max von Renesse, Universit¨at Leipzig

bernd@mis.mpg.de
simon.telen@mis.mpg.de
vialard@ceremade.dauphine.fr
renesse@uni-leipzig.de

16

