1
2
0
2

c
e
D
0
2

]

R
C
.
s
c
[

1
v
4
1
2
1
1
.
2
1
1
2
:
v
i
X
r
a

Vulnerability Analysis of the Android Kernel

Joseph R. Barr
AI Group
Acronis SCS
Scottsdale, Arizona, United States of America
joe.barr@acronisscs.com

Peter Shaw
Department of AI
Nanjing Uni. of Information Science & Technology
JiangSu, China
peter.shaw.cs@gmail.com

Tyler Thatcher
AI Group
Acronis SCS
Scottsdale, Arizona, United States of America
tyler.thatcher@acronisscs.com

December 22, 2021

Abstract

We describe a workflow used to analyze the source code of the Android OS kernel and rate
for a particular kind of bugginess that exposes a program to hacking. The workflow represents
a novel approach for components’ vulnerability rating. The approach is inspired by recent work
on embedding source code functions. The workflow combines deep learning with heuristics and
machine learning. Deep learning is used to embed function/method labels into a Euclidean space.
Because the corpus of Android kernel source code is rather limited (containing approximately 2
million C/C++ functions & Java methods), a straightforward embedding is untenable. To overcome
the challenge of the dearth of data, it’s necessary to go through an intermediate step of the Byte-
Pair Encoding. Subsequently, we embed the tokens from which we assemble an embedding of
function/method labels. Long short-term memory networks (LSTM) are used to embed tokens
into vectors in Rd from which we form a cosine matrix consisting of the cosine between every
pair of vectors. The cosine matrix may be interpreted as a (combinatorial) ‘weighted’ graph whose
vertices represent functions/methods and ‘weighted’ edges correspond to matrix entries. Features
that include function vectors plus those defined heuristically are used to score for risk of bugginess.

Keywords Cybersecurity · Common Exposures and Vulnerabilities (CVE) · CVE detection · software supply chain ·
static code analysis · BPE, token embedding · LSTM, heuristics · imbalanced data · classification · risk score

1 Introduction

Software is complex and invariably almost undoubtedly susceptible to exploitation by attackers who strive to penetrate
computer systems, steal sensitive data, and cause significant harm. Therefore, it is important and, in some cases
crucial to identify, triage, and fix vulnerabilities before attackers find and exploit them.

The insatiable appetite for software as a vehicle for productivity & economic growth has created a software global
software supply chain, which by its very nature is fragmented, unregulated, with spotty standards, having a vast
number of open source-software modules that are plugged into numerous commercial products, applications as well
as various vital computer and electronic systems. Managing a rather haphazard supply chain system is challenging
and occasionally fails to identify problems at the source code level.

Furthermore, it’s generally difficult to ascertain whether bugs are intentional. Regardless of whether deliberate or not,
they create vulnerabilities that open the door for exploitation by garden-variety hackers, state-sponsored actors, and
organized crime syndicates. Arguably, the most worrisome vulnerabilities are those which are continually exploited

 
 
 
 
 
 
Vulnerability Analysis

by state-sponsored actors to threaten our critical infrastructure: sectors like healthcare, energy, transportation,
government, and the financial system. Accordingly, this analysis is a step developing a workflow designed to help
identify vulnerabilities and, strengthen the global software supply chain.

1.1 Terminology

In order to simplify, we use the generic term function to mean both function and method (i.e., function bounded to a
class.) Sometimes we use the term component to signify a function (or method.) We use the term deep learning as
a stand-in for any type of neural network architecture. In this context a classifier is a function which estimate the
conditional probability P(y = 1 | x) for each x ∈ X in the input set. Sometime we add the adjective soft and call such
classifier soft classifier to distinguish from hard classifier which assigns a class membership to each x ∈ X ⊂ Rd.

2 Related work

Once software is deployed a production system may already be at risk. Consequently a major software supply chain
issue involves vetting source code for vulnerability prior to a deployment. With the SolarWinds attack the problem of
the software supply chain was recently greatly amplified, but in fact, the problem has a long history. A well-known
instance is the 2013 attack against US retail giant Target is a good example of lateral movement where hackers
compromised Target’s HVAC system, then used the application’s trusted status to gain access to the retailer’s sensitive
data.

A somewhat similar technique addressing a different problem is found in a 2020 paper by Tian, et al. [1] where
the authors compare the three types of NLP contextualized word embedding CODE2VEC, CC2VEC and BERT to
differentiate between buggy code fragments and fixed and patched code. However, our aim is quite different, it is to
develop tools that can identify buggy, especially malicious code in a supervised manner. For this reason we have used
tagged functions from Mitre’s CVE database [2]. This CVE dataset however, has other challenges to be address such
as the sparseness tagged data.

Previous work by the authors [3], [4] Android’s Bluetooth module Fluoride was analyzed using earlier-versioned
workflow which produced results at the AUC in the 90 percent range.

3 Methodology, a high-level view

This empirical study of the Android kernel stack demonstrates the feasibility of static code analysis workflow to help
identify vulnerability in source code. The workflow has several parts including function embedding, which comes in
two parts: compression and deep-learning, features extraction with heuristics, and regression & classifications. A
variant of the workflow was proved effective to classify natural language [5]. Written in standard C, C++, and in Java,
the Android kernel may be regarded as bags of words consisting of tokens, one bag of tokens per function. Much like
a natural language, tokens consist of names like variables, functions, literal strings, delimiters, and punctuation.

The data, or specifically each function, is appended by a (0,1)-tag. The tags represent the presence or absence of
Common Vulnerabilities & Exposures, CVEs [2]. Tags are quite imbalanced; less than one percent of the records are
tagged as +1 for CVEs.
A challenge we had encountered in learning an embedding of labels, i.e., function names, is that function names are
too imbalanced to effectively learn an embedding in the Android kernel. Thus the reason for the circuitous route that
goes through a ‘Claude Shannon-type’ data compression phase that ultimately leads to the embedding. We’ve used
the Byte-Pair Encoding (BPE) [6] algorithm to tokenize or break up functions into tokens. BPE results in much ’richer,’
less imbalanced data, which can improve the capability of learning an embedding (see details below.) Although a
high dimensional encoder, e.g., d = 256 many have produced a better performance, our embedding in R64 had better
performance in terms of accuracy and perplexity, for practical reasons, we have selected a vector of length d = 128 to
embed functions. In fact, we tried higher values d but with R128, performance of classifier, i.e., CVE prediction, seems
more than adequate. It is always important to consider the balance between bias and variance. Thus simply increasing
the model complexity without noticeable improvement seems unwise. We should also mention that parsimony is
always a consideration, especially for certain model frameworks some of which we have considered (e.g., Logit.) Still,
we can’t rule out the possibility that a higher dimensional embedding out-performs a lower dimension embedding
and we indeed intend to conduct further empirical studies with higher dimension encoding in subsequent projects.
The comparative performance of these embeddings are shown later in Figure 7 discuss in detail later in the text after
some needed discussion.

2

Vulnerability Analysis

The embedding results in a ‘tall-and-thin’ matrix with 128 columns and number of rows which equal to the number
of functions.

f1 →
f2 →
f3 →
.
.
.
.
fN →



s1,1
s2,1
s3,1
.
.
.
.
sN,1

s1,2
s2,2
s3,2
.
.
.
.
sN,2

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.



s1,128
s2,128
s3,128
.
.
.
.
sN,128

S =










where si, j is the jth component of the embedding of the function fi and N is much larger than 128.
Heuristics-based features are extracted from the cosine matrix S and the source code itself. The amalgamation of the
rows of the matrix S and various other features form the basis for a classifier that predict CVE tags. The artifacts of
the workflow are:











(1)

1. Data compression with Byte-Pair Encoding results in a bag of tokens; one bag of tokens for each function.
2. An embedding, or auto-encoding with LSTM; a vector in R128 for each function.
3. Heuristics-based feature a vector, one for each function.
4. Risk rating, a collection ( f , p f ), where f is a function of Android and p f represents the level of risk, or

exposure associated with the function f .

4 The process workflow

Figure 1 describes the toolchain used to classify the code extracted from the code repositories. This tool chain modifies
one previously developed by the authors [5]. The more recent one being [7].

The toolchain begins with input from the code repository, which is the entry point shown in Figure 1. This raw
code is merged with the CVE database and then tokenization using our Byte-Pair Encoding algorithm to produce
new tokens followed by embedding which embed [sic] ‘sub-tokens’ using the LSTM network, which is then used to
‘assemble’ our function embedding. You can find LSTM tools at [8].

The embedding consists of 128-dimensional vectors, one for each function. Thus, embedding results in a matrix A,
say, whose rows represent the functions and columns are the embedding ‘directions’. The matrix is ‘very tall and
skinny,’ having as many rows as there are functions, and by design, it has 128 columns. We’ve experimented with
various embedding and opted for 128 dimensions for practical reasons.
Having produced the matrix A we then compute a pairwise-similarity matrix S where the (i, j)-entry si j is

cos(ai, a j) =

aT
i a j
(cid:107)ai(cid:107)(cid:107)a j(cid:107)

(2)

where ak is the kth row of A. Since the number of functions is 1,154,416, the matrix S is of order 1,154,416-by-1,154,416.
Recall that every row of A is a function embedding. Thus, we may think of the input space X as the space of all
1,154,416 R128-vectors.
Heuristically-inspired features are extracted, which result in a feature vector, one for each function. A list of features
is:

• Function length; the number of tokens per function.
• The length of longest line in a function. (Since we’re in the C/C++ domain a line is well defined.)
• The density of tokens shared with the aggregates of CVEs.
• Row sums of the cosine matrix. (This feature is a stand-in for the degree of the vertex.)
• The number of parameters of the function.

Append those five heuristically-derived features to the R128 auto-encoded features. This nets a 133 feature vector
which forms a basis for the classifier.

3

Vulnerability Analysis

Figure 1: Process tool chain.

The final phase is modeling for vulnerabilities, i.e., calculating the conditional probability φ (x) = P(y = 1 (cid:107) x), that a
function is vulnerable given feature vector x. We estimate φ (x) from training pairs (x, y) where x ∈ R133 and y = 0 if
the function is not CVE and y = 1 otherwise. There are 133 features, which include the 128 auto-encoded features
plus, five which were produced heuristically.

Since CVE tags are imbalanced, we employ SMOTE, an up-sampling technique [9]. SMOTE has a parameter that
controls the percentage of synthetic positive examples. We tried various values, and a 20% synthetic positive example
is optimal.

The outputs of the workflow are:

1. vector representation of functions,

2. features vector, and

3. vulnerability rating.

5 The data

This analysis is an empirical study using the Android OS Stack v.10, which is written in C, C++, and Java. Android is
an open-source project; download instructions are found in [10] and with Android components in [11].

4

Code RepositoriesRaw dataWeb Scraping / ETLJoin with CVE DatabaseFunction EmbeddingBPE & LSTMComputing pairwise cosine MatrixFeature ExtractionUp-Sampling with SMOTEClassifiersRisk ScoresVectorsWeighted MatrixVectorsTagged dataVulnerability Analysis

The code is spread over 103,111 *.c, *.cc, *.cpp and *.h files, and with Java consists of 83,437 files. The total number of
functions is 1,154,416. The number of *.java files is 83,437 and the number of functions (methods) is 1,266,073.

There are 6,775 CVE associated with the C and C++ code, while only 680 CVEs are associated with the Java code.

A summary in tables below in table 1 and a link to the source code in the reference [12].

Table 1: Representative languages sizes in the sample code

.c

.cpp

.cc

Java

No. of Files
Total Size (approx. MB)

36,887 51,172 15,052 83,437
891

974

295

595

An itemized list of the code composition is provided in Table 2 below.

Table 2: Sample code statistics

C & C++ code

Lines of code
Number of files
Size (approx. in MB)
Number of functions
Tokens count
Unique tokens count
Number of CVEs

Totals

39,353,232
103,111
1,864
1,154,416
204,777,237
3,964,717
6,775

Java

No. of Files
Total Size (in MB)
Number of functions (methods)
Number of CVEs

Totals

83,437
891
1,266,073
680

6 Common vulnerability exposures

Common Vulnerabilities & Exposures (CVE) is a database of publicly-disclosed software & firmware vulnerabilities,
i.e., risky for exposure to malware [2]. To illustrate, below are a few examples of functions tagged as CVEs. Example
1. CVE-2017-0781 Code inspection of [13].
void b n e p u _ r e l e a s e _ b c b ( tBNEP_CONN ∗ p_bcb )
{

/ ∗ E n s u r e
a l a r m _ f r e e ( p_bcb −> c o n n _ t i m e r ) ;

s t o p p e d ∗ /

t i m e r

i s

. . . .
. . . .

while ( ! f i x e d _ q u e u e _ i s _ e m p t y ( p_bcb −> x m i t _ q ) )
{

o s i _ f r e e ( f i x e d _ q u e u e _ t r y _ d e q u e u e (
p_bcb −> x m i t _ q ) ) ;

}
f i x e d _ q u e u e _ f r e e ( p_bcb −> xmit_q , NULL ) ;
p_bcb −> x m i t _ q = NULL ;

}

A plausible argument why CVE-2017-0781 might pose a vulnerability is that the free commands have different
names, but seem to free the same memory block. The similarity was evident in the cos distances between the
corresponding vectors in our embedding. These similarities are shown in Figure 2.

Based on the ‘commit’ message which says Free p_pending_data from tBNEP_CONN to avoid
potential memory leaks, i.e., CVE-2017-0781 cause was a memory leak.

5

Vulnerability Analysis

Figure 2: The pairwise similarity between function present in CVE-2017-0781.

Example 2. CVE-2020-0240 [14]
For CVE-2020-0240, the ‘commit’ message “Fix integer overflow in NewFixedDoubleArray” says it all.
Handle < F i x e d A r r a y B a s e > F a c t o r y : : NewFixedDoubleArray (

i n t

l e n g t h ,
P r e t e n u r e F l a g p r e t e n u r e )

{

l e n g t h ) ;

DCHECK_LE ( 0 ,
i f
/ /
/ /
i f

( l e n g t h == 0 ) return e m p t y _ f i x e d _ a r r a y ( ) ;
S h o u l d b e

( l e n g t h < 0

l e n g t h >

i f

| |

F i x e d D o u b l e A r r a y : : kMaxLength )

( l e n g t h > F i x e d D o u b l e A r r a y : : kMaxLength )

{

i s o l a t e () − > heap ( ) − > F a t a l P r o c e s s O u t O f M e m o r y (

" i n v a l i d ␣ a r r a y ␣ l e n g t h " ) ;

s i z e = F i x e d D o u b l e A r r a y : : S i z e F o r ( l e n g t h ) ;

}
i n t
Map ∗ map = ∗ f i x e d _ d o u b l e _ a r r a y _ m a p ( ) ;
H e a p O b j e c t ∗

r e s u l t =

A l l o c a t e R a w W i t h I m m o r t a l M a p ( s i z e , p r e t e n u r e , map ,

k D o u b l e A l i g n e d ) ;

Handle < F i x e d D o u b l e A r r a y > a r r a y ( F i x e d D o u b l e A r r a y : : c a s t (

r e s u l t ) ,

i s o l a t e ( ) ) ;

a r r a y −> s e t _ l e n g t h ( l e n g t h ) ;
return a r r a y ;

}

Example 3.
For CVE-2019-20636 the ‘commit’ message is

CVE-2019-20636 [15]

“If we happen to have a garbage in input device’s

keycode table with values too big we’ll end up doing

clear_bit() with offset way outside of our

bitmaps, damaging other objects within an input device

or even outside of it. Let’s add sanity checks to the

returned old keycodes.”

s t a t i c i n t

i n p u t _ d e f a u l t _ s e t k e y c o d e (

s t r u c t

i n p u t _ d e v ∗ dev ,
const s t r u c t
unsigned i n t

i n p u t _ k e y m a p _ e n t r y ∗ ke ,
∗ o l d _ k e y c o d e )

{

i n d e x ;

unsigned i n t
i n t e r r o r ;
i ;
i n t
i f

( ! dev −> k e y c o d e s i z e )
return −EINVAL ;

i f

( ke −> f l a g s & INPUT_KEYMAP_BY_INDEX )

{

i n d e x = ke −> i n d e x ;

} e l s e {

}

e r r o r = i n p u t _ s c a n c o d e _ t o _ s c a l a r ( ke ,& i n d e x ) ;
i f

( e r r o r )

return e r r o r ;

6

Vulnerability Analysis

i f

( i n d e x >= dev −> keycodemax )

return −EINVAL ;

i f

( dev −> k e y c o d e s i z e < s i z e o f ( ke −> k e y c o d e ) &&
( ke −> k e y c o d e >> ( dev −> k e y c o d e s i z e ∗

8 ) ) )

return −EINVAL ;

switch ( dev −> k e y c o d e s i z e )

{

c a s e 1 :

{

u8 ∗ k = ( u8 ∗ ) dev −> k e y c o d e ;
∗ o l d _ k e y c o d e = k [ i n d e x ] ;
k [ i n d e x ] = ke −> k e y c o d e ;
break ;

}
c a s e 2 :

{

u16 ∗ k = ( u16 ∗ ) dev −> k e y c o d e ;
∗ o l d _ k e y c o d e = k [ i n d e x ] ;
k [ i n d e x ] = ke −> k e y c o d e ;
break ;

}
d e f a u l t :

{

u32 ∗ k = ( u32 ∗ ) dev −> k e y c o d e ;
∗ o l d _ k e y c o d e = k [ i n d e x ] ;
k [ i n d e x ] = ke −> k e y c o d e ;
break ;

}

}

\ \ c l e a r _ b i t ( ) may have out − of − bounds memory a c c e s s
\ \ i f
\ \ i n a s a n i t y c h e c k :

( ∗ o l d \ _ k e y c o d e <= KEY_MAX )

t o o b i g . Wrap c l e a r _ b i t ( )

t h e k e y c o d e v a l u e

i s

i f

_ _ c l e a r _ b i t ( ∗ o l d _ k e y c o d e , dev −> k e y b i t ) ;
_ _ s e t _ b i t ( ke −> keycode , dev −> k e y b i t ) ;
f o r
i f

( i = 0 ;
( i n p u t _ f e t c h _ k e y c o d e ( dev ,

i < dev −> keycodemax ;

i ++ )

{

i ) == ∗ o l d _ k e y c o d e )

{

_ _ s e t _ b i t ( ∗ o l d _ k e y c o d e , dev −> k e y b i t ) ;
/ ∗ S e t t i n g t h e b i t

i s u s e l e s s ,

t w i c e

s o b r e a k ∗ /

break ;
}

}
return 0 ;
}

}

Example 4. CVE-2020-0103[16]
For CVE-2020-0103 the ‘commit’ message is ‘Memory allocated by osi_malloc() should be freed by osi_free().’
void a 2 d p _ a a c _ d e c o d e r _ c l e a n u p ( void )

{

i f

( a 2 d p _ a a c _ d e c o d e r _ c b . h a s _ a a c _ h a n d l e )

a a c D e c o d e r _ C l o s e ( a 2 d p _ a a c _ d e c o d e r _ c b . a a c _ h a n d l e ) ;

f r e e ( a 2 d p _ a a c _ d e c o d e r _ c b . d e c o d e _ b u f ) ;
memset (& a 2 d p _ a a c _ d e c o d e r _ c b , 0 ,

s i z e o f ( a 2 d p _ a a c _ d e c o d e r _ c b ) ) ;

}

Our goal is to classify CVE tags; however, since CVEs are incredibly imbalanced, the challenge of finding the proverbial
needles in a haystack is significant.

7 Embedding

Word embedding forms the basis for natural language processing. Sometimes the term auto-encoding is used to describe
embedding, so an algorithm associated with embedding is referred to as an auto-encoder. Embedding a vocabulary
means to map words or tokens into a Euclidean space of dimension much smaller than the size of the vocabulary:
j ∈ R. The mapping preserves relation between
w → x = (xw
words; vectors representing words having syntactic relation tend to be ‘close,’ and conversely, vectors of words with
little or no syntactic relation do not. In general, word embedding employs a supervised algorithm that involves
constructing of a neural network of one kind or another [17].

k )T where w is a word in the vocabulary and xw

2 , ..., xw

1 , xw

7.1 Background

Word embedding with word2vec [18] is a standard technique in text analysis. Word2vec is an implementation of neural
networks to represent words as dense vectors. The adjective ‘dense’ refers to the fact that the vector’s dimensionality
is an order of magnitude smaller than the size of the dictionary. With negative sampling, text may be trained efficiently,
and when coupled with an appropriate prepossessing and standardization, embedding with word2vec effectively
represent relations between words. Since its inception, word2vec has brought about a myriad of applications of word

7

Vulnerability Analysis

embedding to practical problems, from application to indexing & searching in a corpus of documents, to document
classification, and even to real estate valuation e.g., [19], [7].

Neural networks or ‘deep learning’ are standard tools for dealing with natural languages. The idea goes back to work
by Bengio et al. [20], and later Mikolov et al. [17]. Subsequently, deep learning was applied to static code analysis in
2019 by Alon et al., [21] who used neural network techniques to embed code into a Euclidean space of an appropriate
dimension.

7.2 Function Embedding

Figure 3: Function embedding.

This section introduces the idea of generating function embedding. A function embedding is a ‘summary’ of a function’s
body; it’s a fixed-length vector x ∈ Rk preserving the syntactic and semantic meaning of a function. Alternatively,
function embedding is a mapping f → x f ∈ Rk. We treat programming languages (Java, C, C++, Python, etc.) as
natural languages; therefore, using a natural language model (NLM) is apt. To generate a function embedding, we
first tokenize the source code of a function via Byte Pair Encoding (BPE), a data compression algorithm (See Figure 3.)
With long short-term memory networks (LSTM), tokens are then transformed into ‘dense’ vectors, which in turn are
rolled up to form function embedding. While numerous LSTM models are now available. For this work we used the
standard LSTM model (as defined by [22] section 2) Schematically,

7.3 Byte-Pair Encoding

In natural language processing (NLP) models, the inputs are sequences of sentences where each sentence consists of
whitespace-delimited words or tokens. Whitespace tokenizer works well for language models because the number of
distinct words in a vocabulary is rather limited, or fixed, at the least. However, when it comes to computer languages,
in source code processing, the vocabulary isn’t constrained; there are potentially infinitely many unique variable
names and strings. This leads to the out-of-vocabulary (OOV) problem where rare tokens (those occurring once or
twice in the entire corpus) aren’t learnable.

Experimentation shows that even with a rather small vocabulary size, e.g., a vocabulary of 10,000, about half of the
tokens are out of the vocabulary. After comparing multiple tokenization approaches, Karampatsis et al. [23] showed
that Byte-Pair Encoding (BPE) [6] results in good performance across various evaluations. This is the main reason
why in this project, we have used BPE to tokenize source code.

Originally Gage [6] applied a BPE algorithm for data compression. We use a slightly modified Byte-Pair Encoding
algorithm [24] to merge frequent sub-word pairs instead of replacing those with another byte. At a high-level, each
word is split into characters; then, the most frequent consecutive characters pair up into a single token. This merge
process repeats until it reaches the desired number of merge operations or until the desired vocabulary size is achieved.
Details and examples are found in [24]. Consequently, a variable name like “dwReadSize” is likely split into tokens
[“dw”, “Read”, “Size”]. While “dw” may or may not in the vocabulary, the rest are almost certainly in the vocabulary.
Thus the procedure preserves the ‘meaning’ of that particular variable name.

We’ve noticed that for 897 functions, the tokenizer failed to yield consistent results. It turned out that the reason for
that is that a comma occurs naturally in a ‘template-scoping’ operator. (Templates are C++ constructs.) The following
example demonstrates the phenomenon

8

LSTMCode Repositories (Android)BPEPAggregate<latexit sha1_base64="7nC7hAYd7oQI3cLylUss0f4kbXs=">AAAB+XicbVBNSwMxEM3Wr1q/Vj16CbaCp7JbBT1WvHisYD+gXUo2nW5Dk+ySZAtl6T/x4kERr/4Tb/4b03YP2vpg4PHeDDPzwoQzbTzv2ylsbG5t7xR3S3v7B4dH7vFJS8epotCkMY9VJyQaOJPQNMxw6CQKiAg5tMPx/dxvT0BpFssnM00gECSSbMgoMVbqu26lp1NRwXdRpCAiBvpu2at6C+B14uekjHI0+u5XbxDTVIA0lBOtu76XmCAjyjDKYVbqpRoSQsckgq6lkgjQQba4fIYvrDLAw1jZkgYv1N8TGRFaT0VoOwUxI73qzcX/vG5qhrdBxmSSGpB0uWiYcmxiPI8BD5gCavjUEkIVs7diOiKKUGPDKtkQ/NWX10mrVvWvqrXHWrl+ncdRRGfoHF0iH92gOnpADdREFE3QM3pFb07mvDjvzseyteDkM6foD5zPH30ikt8=</latexit>PAggregate<latexit sha1_base64="7nC7hAYd7oQI3cLylUss0f4kbXs=">AAAB+XicbVBNSwMxEM3Wr1q/Vj16CbaCp7JbBT1WvHisYD+gXUo2nW5Dk+ySZAtl6T/x4kERr/4Tb/4b03YP2vpg4PHeDDPzwoQzbTzv2ylsbG5t7xR3S3v7B4dH7vFJS8epotCkMY9VJyQaOJPQNMxw6CQKiAg5tMPx/dxvT0BpFssnM00gECSSbMgoMVbqu26lp1NRwXdRpCAiBvpu2at6C+B14uekjHI0+u5XbxDTVIA0lBOtu76XmCAjyjDKYVbqpRoSQsckgq6lkgjQQba4fIYvrDLAw1jZkgYv1N8TGRFaT0VoOwUxI73qzcX/vG5qhrdBxmSSGpB0uWiYcmxiPI8BD5gCavjUEkIVs7diOiKKUGPDKtkQ/NWX10mrVvWvqrXHWrl+ncdRRGfoHF0iH92gOnpADdREFE3QM3pFb07mvDjvzseyteDkM6foD5zPH30ikt8=</latexit>Function VectorVulnerability Analysis

IntraPredBppFuncs_C<block_width,
block_height, bitdepth, Pixel>::DcFill.
This template form isn’t an anomalous code. Indeed, the aforementioned template function takes three parameters,
and the scope of the function DcFill dictates its behaves precisely as specified in the class template. It’s amply clear
that this is a feature of C++, not an anomaly or an unusual coding standards. To recover from “embedded” commas,
we’ve used a tab (ASCII DEC-9) as a delimiter, which reduced ‘misfires’ to a manageable number of approximately 30.

As is the case with any natural or human language, anomalies are inevitable. Still, it seems that in our case, using a
tab as a delimiter (in function names, exclusively) is as optimal as one would reasonably tolerate.

7.4 Long Short-Term Memory (LSTM) Networks

Once the Byte-Code Encoding is implemented on the corpus, each token is represented by a unique integer, a token id.
This integer encoding represents the natural ordering of words, which, in our case, is not ideal. Instead, we use a
learnable embedding layer to convert token IDs to ‘dense’ vectors.

Figure 4: LSTM language model for generating function embedding
As Figure 4 demonstrates, the dense vectors are fed to an LSTM layer [25], which generates a hidden state h for each
token t. Roughly, if t is the ‘pivot’ token, then the learning process takes into account all the token information
corresponding to t. Finally, averaging is used to aggregate all the hidden states to generate the function embedding.
Training this kind of LSTM network is not dissimilar to other language models. In virtually all language models
involving a neural network, a (properly encoded, e.g., ‘one-hot’) sequence of tokens is fed to the language model,
where the target output of each input token is the next token of that input.
In our case, given a token sequence w, at time step i, the model calculates a hidden state hi based on the word
embedding xi of wi and the previous hidden state hi−1.
The ‘hidden state’ goes through a fully-connected layer or decoder and is activated by the SOFTMAX function
to produce a probability vector of a token to be predicted. We proceed recursively and use the ‘true’ next token
information to train the model parameters, which maximize the accuracy of the following token predictions. Cross-
entropy is the standard cost function.

7.5 A brief note on code2vec

Although we didn’t use the code2vec embedding technique, we find it worthy of mention because it is state-of-the-art
technology relating to function embedding. Since code2vec requires large corpora consisting of multiple projects (See
[21]) and since ours is a corpus consisting of a single project, the code2vec technique didn’t quite fit our needs.

Developed in 2018 by Alon et al., the Code2vec model framework assigns vectors to functions aiming to capture
subtle differences between syntactically similar functions [26]. The model first parses a function and constructs an
abstract syntax tree (AST). Then, the AST is traversed, and paths between terminal nodes, or leaves, are extracted.
Each path and its corresponding terminal nodes is mapped to an embedding, a vector in Rd. The model also has a

9

Statistical Pooling<latexit sha1_base64="kMchovKrHfRRQ3zLdWPrLhjxFcI=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5IUUY8FLx4rmLbQhrLZbtqlm03YnQil9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSqFQdf9dgobm1vbO8Xd0t7+weFR+fikZZJMM+6zRCa6E1LDpVDcR4GSd1LNaRxK3g7Hd3O//cS1EYl6xEnKg5gOlYgEo2glvzrqe9V+ueLW3AXIOvFyUoEczX75qzdIWBZzhUxSY7qem2IwpRoFk3xW6mWGp5SN6ZB3LVU05iaYLo6dkQurDEiUaFsKyUL9PTGlsTGTOLSdMcWRWfXm4n9eN8PoNpgKlWbIFVsuijJJMCHzz8lAaM5QTiyhTAt7K2EjqilDm0/JhuCtvrxOWvWad11zH+qVxlUeRxHO4BwuwYMbaMA9NMEHBgKe4RXeHOW8OO/Ox7K14OQzp/AHzucPqJqN4Q==</latexit>h1<latexit sha1_base64="kMchovKrHfRRQ3zLdWPrLhjxFcI=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5IUUY8FLx4rmLbQhrLZbtqlm03YnQil9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSqFQdf9dgobm1vbO8Xd0t7+weFR+fikZZJMM+6zRCa6E1LDpVDcR4GSd1LNaRxK3g7Hd3O//cS1EYl6xEnKg5gOlYgEo2glvzrqe9V+ueLW3AXIOvFyUoEczX75qzdIWBZzhUxSY7qem2IwpRoFk3xW6mWGp5SN6ZB3LVU05iaYLo6dkQurDEiUaFsKyUL9PTGlsTGTOLSdMcWRWfXm4n9eN8PoNpgKlWbIFVsuijJJMCHzz8lAaM5QTiyhTAt7K2EjqilDm0/JhuCtvrxOWvWad11zH+qVxlUeRxHO4BwuwYMbaMA9NMEHBgKe4RXeHOW8OO/Ox7K14OQzp/AHzucPqJqN4Q==</latexit>h1<latexit sha1_base64="fPUY3AZK/IU/UU2N8kd8rlC5dtI=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5IUUY8FLx4rmLbQhrLZbtulm03YnQgl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSKFQdf9dgobm1vbO8Xd0t7+weFR+fikZeJUM+6zWMa6E1LDpVDcR4GSdxLNaRRK3g4nd3O//cS1EbF6xGnCg4iOlBgKRtFKfnXcr1f75Ypbcxcg68TLSQVyNPvlr94gZmnEFTJJjel6boJBRjUKJvms1EsNTyib0BHvWqpoxE2QLY6dkQurDMgw1rYUkoX6eyKjkTHTKLSdEcWxWfXm4n9eN8XhbZAJlaTIFVsuGqaSYEzmn5OB0JyhnFpCmRb2VsLGVFOGNp+SDcFbfXmdtOo177rmPtQrjas8jiKcwTlcggc30IB7aIIPDAQ8wyu8Ocp5cd6dj2VrwclnTuEPnM8fqh+N4g==</latexit>h2<latexit sha1_base64="fPUY3AZK/IU/UU2N8kd8rlC5dtI=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5IUUY8FLx4rmLbQhrLZbtulm03YnQgl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSKFQdf9dgobm1vbO8Xd0t7+weFR+fikZeJUM+6zWMa6E1LDpVDcR4GSdxLNaRRK3g4nd3O//cS1EbF6xGnCg4iOlBgKRtFKfnXcr1f75Ypbcxcg68TLSQVyNPvlr94gZmnEFTJJjel6boJBRjUKJvms1EsNTyib0BHvWqpoxE2QLY6dkQurDMgw1rYUkoX6eyKjkTHTKLSdEcWxWfXm4n9eN8XhbZAJlaTIFVsuGqaSYEzmn5OB0JyhnFpCmRb2VsLGVFOGNp+SDcFbfXmdtOo177rmPtQrjas8jiKcwTlcggc30IB7aIIPDAQ8wyu8Ocp5cd6dj2VrwclnTuEPnM8fqh+N4g==</latexit>h2<latexit sha1_base64="jXK3R8BHOSoOE/mutLx3Ywfpk+k=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5IUUY8FLx4rmLbQhrLZbtqlm03YnQil9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSqFQdf9dgobm1vbO8Xd0t7+weFR+fikZZJMM+6zRCa6E1LDpVDcR4GSd1LNaRxK3g7Hd3O//cS1EYl6xEnKg5gOlYgEo2glvzrqu9V+ueLW3AXIOvFyUoEczX75qzdIWBZzhUxSY7qem2IwpRoFk3xW6mWGp5SN6ZB3LVU05iaYLo6dkQurDEiUaFsKyUL9PTGlsTGTOLSdMcWRWfXm4n9eN8PoNpgKlWbIFVsuijJJMCHzz8lAaM5QTiyhTAt7K2EjqilDm0/JhuCtvrxOWvWad11zH+qVxlUeRxHO4BwuwYMbaMA9NMEHBgKe4RXeHOW8OO/Ox7K14OQzp/AHzucPpxWN4A==</latexit>h0<latexit sha1_base64="jXK3R8BHOSoOE/mutLx3Ywfpk+k=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5IUUY8FLx4rmLbQhrLZbtqlm03YnQil9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSqFQdf9dgobm1vbO8Xd0t7+weFR+fikZZJMM+6zRCa6E1LDpVDcR4GSd1LNaRxK3g7Hd3O//cS1EYl6xEnKg5gOlYgEo2glvzrqu9V+ueLW3AXIOvFyUoEczX75qzdIWBZzhUxSY7qem2IwpRoFk3xW6mWGp5SN6ZB3LVU05iaYLo6dkQurDEiUaFsKyUL9PTGlsTGTOLSdMcWRWfXm4n9eN8PoNpgKlWbIFVsuijJJMCHzz8lAaM5QTiyhTAt7K2EjqilDm0/JhuCtvrxOWvWad11zH+qVxlUeRxHO4BwuwYMbaMA9NMEHBgKe4RXeHOW8OO/Ox7K14OQzp/AHzucPpxWN4A==</latexit>h0<latexit sha1_base64="Qs/8xtC9l+qGP9fv2SPnsGFE3ZU=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5JUUY8FLx4rmFpoQ9lsJ+3SzSbsboRS+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MBVcG9f9dgpr6xubW8Xt0s7u3v5B+fCopZNMMfRZIhLVDqlGwSX6hhuB7VQhjUOBj+HoduY/PqHSPJEPZpxiENOB5BFn1FjJrw57F9VeueLW3DnIKvFyUoEczV75q9tPWBajNExQrTuem5pgQpXhTOC01M00ppSN6AA7lkoaow4m82On5MwqfRIlypY0ZK7+npjQWOtxHNrOmJqhXvZm4n9eJzPRTTDhMs0MSrZYFGWCmITMPid9rpAZMbaEMsXtrYQNqaLM2HxKNgRv+eVV0qrXvKuae1+vNC7zOIpwAqdwDh5cQwPuoAk+MODwDK/w5kjnxXl3PhatBSefOYY/cD5/AKukjeM=</latexit>h3<latexit sha1_base64="Qs/8xtC9l+qGP9fv2SPnsGFE3ZU=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5JUUY8FLx4rmFpoQ9lsJ+3SzSbsboRS+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MBVcG9f9dgpr6xubW8Xt0s7u3v5B+fCopZNMMfRZIhLVDqlGwSX6hhuB7VQhjUOBj+HoduY/PqHSPJEPZpxiENOB5BFn1FjJrw57F9VeueLW3DnIKvFyUoEczV75q9tPWBajNExQrTuem5pgQpXhTOC01M00ppSN6AA7lkoaow4m82On5MwqfRIlypY0ZK7+npjQWOtxHNrOmJqhXvZm4n9eJzPRTTDhMs0MSrZYFGWCmITMPid9rpAZMbaEMsXtrYQNqaLM2HxKNgRv+eVV0qrXvKuae1+vNC7zOIpwAqdwDh5cQwPuoAk+MODwDK/w5kjnxXl3PhatBSefOYY/cD5/AKukjeM=</latexit>h3Embedding LayerLSTMLSTMLSTMLSTMFunctionEmbeddingBPEBPEBPEBPEPageCHECK==NumberPage==Number<latexit sha1_base64="d+pjV+BR/0kgeV7Qkxb5toy/MN0=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5IUUY8FLx4rmFZoQ9lsp+3SzSbsbsQS+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MBFcG9f9dgpr6xubW8Xt0s7u3v5B+fCopeNUMfRZLGL1EFKNgkv0DTcCHxKFNAoFtsPxzcxvP6LSPJb3ZpJgENGh5APOqLGSX33qudVeueLW3DnIKvFyUoEczV75q9uPWRqhNExQrTuem5ggo8pwJnBa6qYaE8rGdIgdSyWNUAfZ/NgpObNKnwxiZUsaMld/T2Q00noShbYzomakl72Z+J/XSc3gOsi4TFKDki0WDVJBTExmn5M+V8iMmFhCmeL2VsJGVFFmbD4lG4K3/PIqadVr3mXNvatXGhd5HEU4gVM4Bw+uoAG30AQfGHB4hld4c6Tz4rw7H4vWgpPPHMMfOJ8/v4WN8A==</latexit>x0++<latexit sha1_base64="HRiWLX+a9IOukiAxbgbMza7a+Tc=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5IUUY8FLx4rmFZoQ9lsp+3SzSbsbsQS+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MBFcG9f9dgpr6xubW8Xt0s7u3v5B+fCopeNUMfRZLGL1EFKNgkv0DTcCHxKFNAoFtsPxzcxvP6LSPJb3ZpJgENGh5APOqLGSX33qedVeueLW3DnIKvFyUoEczV75q9uPWRqhNExQrTuem5ggo8pwJnBa6qYaE8rGdIgdSyWNUAfZ/NgpObNKnwxiZUsaMld/T2Q00noShbYzomakl72Z+J/XSc3gOsi4TFKDki0WDVJBTExmn5M+V8iMmFhCmeL2VsJGVFFmbD4lG4K3/PIqadVr3mXNvatXGhd5HEU4gVM4Bw+uoAG30AQfGHB4hld4c6Tz4rw7H4vWgpPPHMMfOJ8/wQqN8Q==</latexit>x1<latexit sha1_base64="mLy5CHkuiVITj3oWUYVlKIuRNas=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5IUUY8FLx4rmFZoQ9lsp+3SzSbsbsQS+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MBFcG9f9dgpr6xubW8Xt0s7u3v5B+fCopeNUMfRZLGL1EFKNgkv0DTcCHxKFNAoFtsPxzcxvP6LSPJb3ZpJgENGh5APOqLGSX33q1au9csWtuXOQVeLlpAI5mr3yV7cfszRCaZigWnc8NzFBRpXhTOC01E01JpSN6RA7lkoaoQ6y+bFTcmaVPhnEypY0ZK7+nshopPUkCm1nRM1IL3sz8T+vk5rBdZBxmaQGJVssGqSCmJjMPid9rpAZMbGEMsXtrYSNqKLM2HxKNgRv+eVV0qrXvMuae1evNC7yOIpwAqdwDh5cQQNuoQk+MODwDK/w5kjnxXl3PhatBSefOYY/cD5/AMKPjfI=</latexit>x2<latexit sha1_base64="TTGZe29MINdb9JOAnV323cxmyeM=">AAAB7HicbVBNTwIxEJ3FL8Qv1KOXRjDxRHbRqEcSLx4xcYEENqRbutDQdjdt10g2/AYvHjTGqz/Im//GAntQ8CWTvLw3k5l5YcKZNq777RTW1jc2t4rbpZ3dvf2D8uFRS8epItQnMY9VJ8Saciapb5jhtJMoikXIaTsc38789iNVmsXywUwSGgg8lCxiBBsr+dWn/kW1X664NXcOtEq8nFQgR7Nf/uoNYpIKKg3hWOuu5yYmyLAyjHA6LfVSTRNMxnhIu5ZKLKgOsvmxU3RmlQGKYmVLGjRXf09kWGg9EaHtFNiM9LI3E//zuqmJboKMySQ1VJLFoijlyMRo9jkaMEWJ4RNLMFHM3orICCtMjM2nZEPwll9eJa16zbuquff1SuMyj6MIJ3AK5+DBNTTgDprgAwEGz/AKb450Xpx352PRWnDymWP4A+fzB8QUjfM=</latexit>x3<latexit sha1_base64="fbx3+ZSIehUVdbA0zYtKUf+gshY=">AAAB7HicbVBNTwIxEJ3FL8Qv1KOXRjDxRHbRqEcSLh4xcYEENqRbutDQdjdt14Rs+A1ePGiMV3+QN/+NBfag4EsmeXlvJjPzwoQzbVz32ylsbG5t7xR3S3v7B4dH5eOTto5TRahPYh6rbog15UxS3zDDaTdRFIuQ0044ac79zhNVmsXy0UwTGgg8kixiBBsr+dXm4Ko6KFfcmrsAWideTiqQozUof/WHMUkFlYZwrHXPcxMTZFgZRjidlfqppgkmEzyiPUslFlQH2eLYGbqwyhBFsbIlDVqovycyLLSeitB2CmzGetWbi/95vdREd0HGZJIaKslyUZRyZGI0/xwNmaLE8KklmChmb0VkjBUmxuZTsiF4qy+vk3a95t3U3Id6pXGdx1GEMziHS/DgFhpwDy3wgQCDZ3iFN0c6L86787FsLTj5zCn8gfP5A3Mhjb4=</latexit>C3<latexit sha1_base64="y8LFvqmTy4SskdN8Qk6y2BsUbv0=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5IUUY+FXjxWMLXQhrLZTtqlm03Y3Qgl9Dd48aCIV3+QN/+N24+Dtj4YeLw3w8y8MBVcG9f9dgobm1vbO8Xd0t7+weFR+fikrZNMMfRZIhLVCalGwSX6hhuBnVQhjUOBj+G4OfMfn1BpnsgHM0kxiOlQ8ogzaqzkV5v9erVfrrg1dw6yTrwlqcASrX75qzdIWBajNExQrbuem5ogp8pwJnBa6mUaU8rGdIhdSyWNUQf5/NgpubDKgESJsiUNmau/J3Iaaz2JQ9sZUzPSq95M/M/rZia6DXIu08ygZItFUSaIScjsczLgCpkRE0soU9zeStiIKsqMzadkQ/BWX14n7XrNu6659/VK42oZRxHO4BwuwYMbaMAdtMAHBhye4RXeHOm8OO/Ox6K14CxnTuEPnM8fcZyNvQ==</latexit>C2<latexit sha1_base64="SnQ7/YGNJjEX7kHx5/O1nnWmiSU=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5IUUY+FXjxWMLXQhrLZTtqlm03Y3Qil9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSq4Nq777RQ2Nre2d4q7pb39g8Oj8vFJWyeZYuizRCSqE1KNgkv0DTcCO6lCGocCH8Nxc+4/PqHSPJEPZpJiENOh5BFn1FjJrzb7XrVfrrg1dwGyTrycVCBHq1/+6g0SlsUoDRNU667npiaYUmU4Ezgr9TKNKWVjOsSupZLGqIPp4tgZubDKgESJsiUNWai/J6Y01noSh7YzpmakV725+J/XzUx0G0y5TDODki0XRZkgJiHzz8mAK2RGTCyhTHF7K2EjqigzNp+SDcFbfXmdtOs177rm3tcrjas8jiKcwTlcggc30IA7aIEPDDg8wyu8OdJ5cd6dj2VrwclnTuEPnM8fcBeNvA==</latexit>C1<latexit sha1_base64="DQAeUdj6K7ylgCSwQ/5PPZJyoHA=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5IUUY+FXjxWMLXQhrLZTtqlm03Y3Qil9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSq4Nq777RQ2Nre2d4q7pb39g8Oj8vFJWyeZYuizRCSqE1KNgkv0DTcCO6lCGocCH8Nxc+4/PqHSPJEPZpJiENOh5BFn1FjJrzb7brVfrrg1dwGyTrycVCBHq1/+6g0SlsUoDRNU667npiaYUmU4Ezgr9TKNKWVjOsSupZLGqIPp4tgZubDKgESJsiUNWai/J6Y01noSh7YzpmakV725+J/XzUx0G0y5TDODki0XRZkgJiHzz8mAK2RGTCyhTHF7K2EjqigzNp+SDcFbfXmdtOs177rm3tcrjas8jiKcwTlcggc30IA7aIEPDDg8wyu8OdJ5cd6dj2VrwclnTuEPnM8fbpKNuw==</latexit>C0<latexit sha1_base64="i0jqLP//nZ2k42PA36kwURXwb78=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5IUUY8FLx4rmlpoQ9lsJ+3SzSbsboRS+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MBVcG9f9dgpr6xubW8Xt0s7u3v5B+fCopZNMMfRZIhLVDqlGwSX6hhuB7VQhjUOBj+HoZuY/PqHSPJEPZpxiENOB5BFn1FjJr9733GqvXHFr7hxklXg5qUCOZq/81e0nLItRGiao1h3PTU0wocpwJnBa6mYaU8pGdIAdSyWNUQeT+bFTcmaVPokSZUsaMld/T0xorPU4Dm1nTM1QL3sz8T+vk5noOphwmWYGJVssijJBTEJmn5M+V8iMGFtCmeL2VsKGVFFmbD4lG4K3/PIqadVr3mXNvatXGhd5HEU4gVM4Bw+uoAG30AQfGHB4hld4c6Tz4rw7H4vWgpPPHMMfOJ8/hwKNyw==</latexit>S0<latexit sha1_base64="L2zzXSEdb0lsCl7auuawJo//XZg=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5IUUY8FLx4rmlpoQ9lsJ+3SzSbsboRS+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MBVcG9f9dgpr6xubW8Xt0s7u3v5B+fCopZNMMfRZIhLVDqlGwSX6hhuB7VQhjUOBj+HoZuY/PqHSPJEPZpxiENOB5BFn1FjJr973vGqvXHFr7hxklXg5qUCOZq/81e0nLItRGiao1h3PTU0wocpwJnBa6mYaU8pGdIAdSyWNUQeT+bFTcmaVPokSZUsaMld/T0xorPU4Dm1nTM1QL3sz8T+vk5noOphwmWYGJVssijJBTEJmn5M+V8iMGFtCmeL2VsKGVFFmbD4lG4K3/PIqadVr3mXNvatXGhd5HEU4gVM4Bw+uoAG30AQfGHB4hld4c6Tz4rw7H4vWgpPPHMMfOJ8/iIeNzA==</latexit>S1<latexit sha1_base64="L115JkVaK0NWdq5Vo7L5yCnI5O8=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5IUUY8FLx4rmlpoS9lsJ+3SzSbsboQS+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8IBFcG9f9dgpr6xubW8Xt0s7u3v5B+fCopeNUMfRZLGLVDqhGwSX6hhuB7UQhjQKBj8H4ZuY/PqHSPJYPZpJgL6JDyUPOqLGSX73v16v9csWtuXOQVeLlpAI5mv3yV3cQszRCaZigWnc8NzG9jCrDmcBpqZtqTCgb0yF2LJU0Qt3L5sdOyZlVBiSMlS1pyFz9PZHRSOtJFNjOiJqRXvZm4n9eJzXhdS/jMkkNSrZYFKaCmJjMPicDrpAZMbGEMsXtrYSNqKLM2HxKNgRv+eVV0qrXvMuae1evNC7yOIpwAqdwDh5cQQNuoQk+MODwDK/w5kjnxXl3PhatBSefOYY/cD5/AIoMjc0=</latexit>S2<latexit sha1_base64="rV4A0D3XjgeQr5fw4D/OAiAFky4=">AAAB7HicbVBNTwIxEJ3FL8Qv1KOXRjDxRHbRqEcSLx4xukACG9ItXWjotpu2a0I2/AYvHjTGqz/Im//GAntQ8CWTvLw3k5l5YcKZNq777RTW1jc2t4rbpZ3dvf2D8uFRS8tUEeoTyaXqhFhTzgT1DTOcdhJFcRxy2g7HtzO//USVZlI8mklCgxgPBYsYwcZKfvWhf1HtlytuzZ0DrRIvJxXI0eyXv3oDSdKYCkM41rrruYkJMqwMI5xOS71U0wSTMR7SrqUCx1QH2fzYKTqzygBFUtkSBs3V3xMZjrWexKHtjLEZ6WVvJv7ndVMT3QQZE0lqqCCLRVHKkZFo9jkaMEWJ4RNLMFHM3orICCtMjM2nZEPwll9eJa16zbuquff1SuMyj6MIJ3AK5+DBNTTgDprgAwEGz/AKb45wXpx352PRWnDymWP4A+fzB4uRjc4=</latexit>S3Vulnerability Analysis

path-attention network to assign a score to each embedding and aggregate embedded vectors into a function vector
using the attention score. During the evaluation phase, the model computes similarities between the function vector
and every function name embedding and predicts a possible function name.

8 Calibration of hyper-parameters

In the following subsections, we describe how to optimized the hyperparameters of the LSTM network.

For the LSTM model, we first bootstrapped a training set and formed a ‘set difference’ of the dataset, which resulted
in training and test datasets. We’ve tried several combinations of token embedding sizes and evaluated the token
prediction accuracy and perplexity.

As Figure 5 shows, if the size of the token embedding and the output vector was too large, the perplexity on the test
set first decreased and later increased, indicating an overfit. We’ve tested embedding between R128 and embedding
into R128. The latter (R128) seems appropriate to ‘splitting the difference’ on accuracy and perplexity.

9 Classification

As was mentioned in the ‘terminology’ section, a classifier is a mapping Φ : X → [0, 1] that estimates the conditional
probability φ (x) = P(y = +1(cid:107)x) which is often referred to as a score, or the score of x. We’ll stick with that terminology.
As we noted earlier, the Android data is extremely imbalanced; of the 2,420,489 functions (C, C++, and Java functions),
7,455 approximately 0.3% are positively tagged while the remaining 99.7% are negatively tagged. For practical reasons
we’re focused attention on the 1,154,416 C/C++ functions, of, which 6,775 are tagged as CVEs, i.e only approximately
0.6 of a percent of the lines were tagged.

The goal is to predict CVEs from feature vector x, i.e., to estimate P(y = 1 | x) where

y =

1
0

(cid:26)

if y is CVE
else

In order to train a classifier which is based extreme imbalance we employ an up-sampling technique SMOTE: Synthetic
Minority Over-sampling Technique [9]. SMOTE simulates positively-labeled tags based on similarity to positively
tagged examples.

9.1 Baseline classifier

To establish a rough baseline, we use function embedding, the R128 function-vectors as a basis for a classifier. We use
GBM as a baseline with performance in the table 3 below. Also, see Figure 6.

Table 3: Baseline classifier performance

Metric Performance

AUC
Precision
Specifity
Lift

0.813
0.243
0.986
0.868

9.2 Heuristics-based features

We introduce six additional features.

1. Function length, i.e., number of tokens.
2. Token prevalence, i.e., percentage of ‘bad’ tokens in a function.
3. Row sums of cosine matrix.
4. Length of the longest line, i.e., number of tokens.
5. Number of function parameters (parameters passed to function.)

10

Vulnerability Analysis

Figure 5: Comparison of Embedding Metrics for R32, R64 and R128.

The first feature, Function length, list item 1 above, aligns with the ‘long-method’ code-smell of Kent Beck and Martin
Fowler [27, 28]. The value used for this feature is summarized in the Function Length Algorithm 1. The number of
tokens used refers to the number of ‘bag’ tokens, i.e., the size of a multi-sets. Every token is counted as many times as
it appears in the function. If, for example, a token myNum occurs seven times, it increments the count seven times.
The second feature listed as item 2, Token prevalence is the most frequent ‘meaningful’ token occurring in CVE functions,
i.e., in the sense of the tokens which are common to CVEs, but less common in non-CVEs. The algorithm used to obtain
the token prevalence is presented in Algorithm 2. The fifth feature, the Number of function parameters, is indicative
of the code-smell “Too many parameters” is a nominal value; say the function myFunc, void myFunc(int,

11

Vulnerability Analysis

Figure 6: Baseline classifier: using R128 embedding with GBM.

int, double, char*) has four (4) parameters, although char* could very well pass a long array of type
char characters.

9.3 A trimmed CVE lexicon

To amplify the generation of feature 2, we construct a table of all CVE tokens, i.e., a bag of tokens appearing in
functions labeled as CVEs, and their frequency. Clearly, tokens like delimiters and punctuation invariably are the
most frequent, and arguably those provide little or no information about the nature of the function. The lexicon is
constructed by trimming the most and the least frequent tokens. Those tokens in the ‘middle’ consist of trimmed
CVE lexicon L . The size of the intersection of the lexicon with a function is feature 2), ‘token prevalence’.

Figure 7: Gains and lift across different embedding dimensions.

12

Vulnerability Analysis

10 CVE Classification

As noted, the transformed data consists of approximately 1.1 million (X, y)-pairs with X ∈ R133 and y ∈ {+1, −1}.
The vector X = (x1, ..., x128, x129, ..., x133) with x1, ..., x128 are auto-encoded and the last five x129, ..., x133 are heuristics-
based features. Although one could try other model frameworks like support-vector machines, for practical reasons
gradient boosting (GBM), random forests and neural networks were at play. To ensure consistency of results two
approaches were investigated.

1. SMOTE which was optimized the size of up-sampled positive examples, a 20 percent up-sample rate was

found optimal for the given data.

2. The bootstrap which re-samples data with replacement, was also deployed. The training set for The
bootstrap consisted of all the positive labels together with an equal number of negative labels sampled
uniformly with replacements. We iterated the process five times. In fact, this variant of the bootstrap was done
solely as a ‘sanity check’ to ensure that results didn’t significantly deviate from what was expected. However,
SMOTE had consistently outperformed the bootstrap and consequently we abandoned the methodology in
favor of SMOTE.

10.1 CVE classifier performance summary

Figure 8: Prediction across multiple embedding dimensions.

The training data (X, y), where X is a R133 vector consisted of R128 auto-encoded embedding, and the five ‘custom-
made’ features described above. We implemented upsampling with SMOTE at 20 percent level and used random
forests, GBM and two layer neural networks (all optimally calibrated.)

Performance across the three model frameworks is summarized in the Table 4 and the lattice plot Figure 7.

A neural network model upsampled with SMOTE at 20 percent yields a slightly better AUC of 0.962. See Figure 8 for
more details. The lift, however, is much more pronounced at 0.846. Also a recall of 0.733 is a great improvement over
competing models.

Algorithm 1 Function Length

INPUT: A corpus C of functions

Let F( f ) ← bag of tokens in f
Let f Size ← 0
foreach t ∈ F( f ) do
f Size ← f Size + 1

1: foreach function f ∈ C do
2:
3:
4:
5:
6:
7:
8: end foreach

end foreach
Return f Size

13

Vulnerability Analysis

Algorithm 2 Token Prevalence

INPUT: A corpus C of functions, and

A trimmed lexicon L of CVE Tokens

1: foreach function f ∈ C do
F( f ) ← bag of tokens in f
2:
N(F( f )) ← token count of F( f )
3:
4:
k ← 0
foreach t ∈ L do token t appears in F( f )
5:
6:
7:

k/N(F( f ))

k ← k + 1
Return
end foreach

8:
(cid:16)
9: end foreach
For each function f , Algorithm 2 returns the frequency of tokens in L lying in the bag of tokens F( f ).

(cid:17)

Table 4: Classifier performance across different embeddings

Embedding

R32

R64

R128

GBM
Lift
AUC
Accuracy
Precision
Recall

Random Forest
Lift
AUC
Acc
Prec
Recall

Neural Network
Lift
AUC
Acc
Prec
Recall

0.792
0.938
0.986
0.244
0.475

0.720
0.909
0.954
0.086
0.574

0.779
0.942
0.980
0.184
0.534

0.821
0.950
0.987
0.269
0.525

0.728
0.918
0.962
0.105
0.587

0.825
0.956
0.984
0.232
0.560

0.846
0.957
0.988
0.297
0.518

0.726
0.915
0.962
0.101
0.613

0.846
0.962
0.975
0.176
0.733

Note Fig. 5 the misbehavior at a single epoch where performance drops over a single epoch. There are a few plausible
explanations of this mystery. One plausible explanation is instability of the gradient, another is that the network is
stuck in a faux minimum but able to subsequently recover. Since this paper is not about neural networks, and since
we observe long-term stability (with respect to AUC, accuracy, recall and perplexity,) we didn’t find it necessary to go
into the painful details.

11 Conclusion

This empirical analysis demonstrates that static code analysis with machine learning might indeed prove to be
effective in identifying malicious or sloppy code that contains bugs that expose computers and the data to unnecessary
costly risks.

This scoring method of the Android kernel demonstrates that most known vulnerable function lie in the top tier of the
score distribution. This suggests that the procedure could be generalized and may be used to identify vulnerabilities
and improve the code vetting process.

14

Vulnerability Analysis

To wrap ones head around this outcome, with approximately 1.1 million functions, 1 percent consists of 11,000
functions, of which 1,915 are known to be CVEs; that is, approximately 17.4% of the top 1% of scores are known to be
bad. One would be amiss not to contemplate the consequences of having information about a cohort’s risk of causing
major disruption and how one should respond to such information.

12 Declaration of Competing Interests

The authors declare that they have no known competing financial interests or personal relationships that could have
appeared to influence the work in this paper.

13 Credit authorship contribution

Joe Bar: Conception, methodology, writing-original draft, resources and supervision. Peter Shaw: Writing, method-
ology, review & editing. Tyler Thatcher: Experimentation and investigation.

14 Acknowledgements

Special thanks to Acronis SCS (USA) for supporting this project, and our gratitude for the support and advice we’ve
received from our friends including Sergey Ulasen and Sanjeev Solanki of Acronis (Singapore), Neil Proctor and
Katerina Archangorodskaja of Acronis SCS (USA). Peter Shaw was supported in part by the Jiangsu province, China,
100 Talent project fund (BX2020100).

References

[1] Haoye Tian, Kui Liu, Abdoul Kader Kaboré, Anil Koyuncu, Li Li, Jacques Klein, and Tegawendé F Bissyandé.
Evaluating representation learning of code changes for predicting patch correctness in program repair. In 2020
35th IEEE/ACM International Conference on Automated Software Engineering (ASE), pages 981–992. IEEE, 2020.

[2] Mitre Corporation. https://cve.mitre.org/cve/, june 2020.
[3] Joseph R Barr, Peter Shaw, Faisal N Abu-Khzam, Tyler Thatcher, and Sheng Yu. Vulnerability rating of source code
with token embedding and combinatorial algorithms. International Journal of Semantic Computing, 14(04):501–
516, 2020.

[4] Joseph R Barr, Peter Shaw, Faisal N Abu-Khzam, Sheng Yu, Heng Yin, and Tyler Thatcher. Combinatorial code
classification & vulnerability rating. In 2020 Second International Conference on Transdisciplinary AI (TransAI),
pages 80–83. IEEE Computer Society, 2020.

[5] J. R. Barr, P. Shaw, F. N. Abu-Khzam, and J. Chen. Combinatorial text classification: the effect of multi-
parameterized correlation clustering. In 2019 First International Conference on Graph Computing (GC), pages
29–36, 2019.

[6] Philip. Gage. A new algorithm for data compression. C Users Journal., 12.2:23–38., 1994.

[7] Joseph R Barr, Peter Shaw, Faisal N Abu-Khzam, Sheng Yu, Heng Yin, and Tyler Thatcher. Combinatorial code
classification & vulnerability rating. In 2020 Second International Conference on Transdisciplinary AI (TransAI),
pages 80–83. IEEE, 2020.

[8] SRCML. Srcml SciML. https://www.srcml.org/.
[9] Nitesh V. Chawla, Kevin W. Bowyer, Lawrence O. Hall, and W. Philip Kegelmeyer. Smote: Synthetic minority

over-sampling technique. Journal of Artificial Intelligence Research 16, 2002.

[10] Open-source. https://source.android.com/setup/build/downloading, june 2020.
[11] Open-source. https://android.googlesource.com/platform, june 2020.
[12] Google & The Open Handset Alliance. Android kernel stack. https://android.googlesource.

com/platform/system/, June 2020.

[13] Mitre Corporation. CVE-2017-0781. https://cve.mitre.org/cgi-bin/cvename.cgi?name=

CVE-2017-0781, june 2017.

[14] Mitre Corporation Rubin Xu. Android platform external v8. https://android.googlesource.com/
platform/external/v8/+/cb30bc6720cb3864d1a9f9c55b7d53ab2d9a5f7a, 2020.

15

Vulnerability Analysis

[15] Mitre Corporation Dmitry Torokhov. Android kernel common. https://android.googlesource.

com/kernel/common/+/cb222aed03d798fc074be55e59d9a112338ee784, 2020.

[16] Mitre Corporation Hansong Zhang. Android platform system bt. https://android.googlesource.
com/platform/system/bt/+/89321d6f0d47724dc7f0c17f7d7302d1fe75086b, 2020.

[17] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. Distributed representations of words

and phrases and their compositionality. In Advances in neural information proc. sys., pages 3111–3119, 2013.

[18] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in
vector space. In Yoshua Bengio and Yann LeCun, editors, 1st International Conference on Learning Representations,
ICLR 2013, Scottsdale, Arizona, USA, May 2-4, 2013, Workshop Track Proceedings, 2013.

[19] Moloud Shahbazi, Joseph R. Barr, Vagelis Hristidis, and Nani Narayanan Srinivasan. Estimation of the investability
of real estate properties through text analysis. In Tenth IEEE International Conference on Semantic Computing,
ICSC 2016, Laguna Hills, CA, USA, February 4-6, 2016, pages 301–306. IEEE Computer Society, 2016.

[20] Y. Bengio, R. Ducharme, P. Vincent, and C. Jauvin. A neural probabilistic language model. Journal of machine

learning research, 3(Feb):1137–1155, 2003.

[21] Uri Alon, Meital Zilberstein, Omer Levy, and Eran Yahav. code2vec: Learning distributed representations of

code. Proceedings of the ACM on Programming Languages, 3(POPL):1–29, 2019.

[22] Rafal Jozefowicz, Wojciech Zaremba, and Ilya Sutskever. An empirical exploration of recurrent network

architectures. In International conference on machine learning, pages 2342–2350. PMLR, 2015.

[23] et al. Karampatsis, Rafael-Michael. Big code!= big vocabulary: Open-vocabulary models for source code. arXiv

preprint arXiv:2003.07914, 2020.

[24] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words with subword

units. arXiv., 1508.07909, 2015.

[25] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural Computations, 9.8:1735–1780., 1997.
[26] Uri Alon, Shaked Brody, Omer Levy, and Eran Yahav. code2seq: Generating sequences from structured represen-

tations of code. In International Conference on Learning Representations, pages 1 – 22, 2019.

[27] Martin Fowler, Kent Beck, J Brant, W Opdyke, and D Roberts. Refactoring: improving the design of existing

code, ser. In Addison Wesley object technology series., pages 11–21. Addison-Wesley, 1999.

[28] Martin Fowler. Refactoring: improving the design of existing code. Addison-Wesley Professional, 2018.

15 Appendix

Author biographies

Joseph R. Barr is Senior Director of Research at Acronis SCS (USA), (www.acronisscs.com)
an industry leader in anti-ransomware and cybersecurity solutions. As head of research
Joe’s responsibility is to develop the methodology and the tools to help automate the pro-
cess of identifying vulnerabilities in source code. Earlier Joe was Chief Analytics Officer
at HomeUnion (www.homeunion.com) (sold to www.Mynd.co) where he was respon-
sible for analytics and back-office quantitative analysis. Prior to that he was Chief Data
Scientist at ID Analytics (now part of Lexis-Nexis https://risk.lexisnexis.com/
corporations-and-non-profits/credit-risk-assessment) where he was
responsible for the development of fraud-prevention and consumer credit risk products. Joe has
begun his career as a mathematics professor at California Lutheran University. Joe has a Doctorate
in mathematics from the University of New Mexico. He publishes extensively in the area of machine learning and
combinatorics.

Peter Shaw was born in Australia in 1969. He received the B.CompSci. Hon I and PhD degree in
computer science from the Newcastle University Australia. He lectured in software engineering at
Charles Darwin University between 2010 and 2018. He is currently a professor in the AI department
at Nanjing University of Information Science and Technology (NUIST), China, and a Honoree
Research Fellow at Menzies School of Child Health, Australia. His core research is fundamental
advantages in AI using Fixed Parameter Tractable algorithms.

16

Vulnerability Analysis

Tyler Thatcher is a Master’s student at NAU. He Currently works at Acronis SCS as a Machine
Learning Engineer, researching and developing innovative ways to leverage machine learning in
the cyber security domain. Previously, he worked as a researcher for USGS Astrogeology and NAU
SICCS.

17

