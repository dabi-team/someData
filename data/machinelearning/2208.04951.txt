Programming Nonlinear Propagation for 

Efficient Optical Learning Machines  

Ilker Oguz1,2, Jih-Liang Hsieh1,2, Niyazi Ulas Dinc1,2, Uğur Teğin1,2, Mustafa Yildirim1, Carlo Gigli2, 

Christophe Moser1 and Demetri Psaltis2 

1 Laboratory of Applied Photonics Devices, Ecole Polytechnique Fédérale de Lausanne (EPFL), Switzerland 

2 Optics Laboratory, Ecole Polytechnique Fédérale de Lausanne (EPFL), Switzerland 

Abstract 

The ever-increasing demand for processing data with larger machine learning models requires more 

efficient hardware solutions due to limitations such as power dissipation and scalability. Optics is a 

promising contender for providing lower power computation since light propagation through a non-

absorbing medium is a lossless operation. However, to carry out useful and efficient computations with 

light, generating and controlling nonlinearity optically is a necessity that is still elusive. Multimode fibers 

(MMF) have been shown that they can provide nonlinear effects with microwatts of average power while 

maintaining parallelism and low loss. 

In this work, we propose an optical neural network architecture, which performs nonlinear optical 

computation by controlling the propagation of ultrashort pulses in MMF by wavefront shaping. With a 

surrogate model, optimal sets of parameters are found to program this optical computer for different tasks 

with minimal utilization of an electronic computer. We show a remarkable decrease of 97% in the number of 

model parameters, which leads to an overall 99% digital operation reduction compared to an equivalently 

performing digital neural network. We further demonstrate that a fully optical implementation can also be 

performed with competitive accuracies.  

Introduction 

Machine learning architectures have come to be dominated by artificial neural networks (ANN). There are 

several reasons why this architecture is used so broadly. Initially, their similarity with biological neural 

networks1 has provided strong motivation to explore ANNs. At the same time, the fact that ANNs are 

universal machines2, which are able to approximate any function, breeds confidence that ANNs can carry 

out useful and difficult tasks. Perhaps most significantly, the fact that error back propagation3 has proven 

1 

 
 
 
very effective in training such networks catapulted their application to a wide variety of problems. Ever-

larger networks4 have been adopted for tackling challenging tasks5. Empirically it has been found that larger 

networks tend to perform better given a sufficiently large database of training examples. This has led to a 

“bigger is better” mentality6 even though theoretically we expect that networks with as few degrees of 

freedom as possible to generalize better7.  However, the disadvantage of this mentality is the energy 

required to train and use very large networks. For instance, only training the language model GPT-3, which 

has 175 billion parameters, consumed 1.3 GWh of electricity which is the energy required to fully charge 

13’000 Tesla Model S cars8. Optics can help overcome this downside since light propagation through a 

non-absorbing, non-scattering medium is a lossless linear operation.  

Several approaches have been reported for the optical realization of ANNs. Wavefront shaping by 

diffractive surfaces or modulators, followed by propagation can implement ANNs and perform different 

tasks such as classification and imaging 9–13. Silicon photonics technology also allows the realizations of 

reconfigurable optical computing with much smaller dimensions. Control structures such as Mach-Zehnder 

modulators14 and micro-ring resonators15 can precisely manipulate light inside waveguides as in building 

blocks of ANNs, performing operations such as multiplication or addition.  However, their constraint to two 

dimensions diminishes the intrinsic three-dimensional scalability of optics16. Additionally, in both of those 

domains, nonlinearity is obtained generally by optoelectronic devices, which impairs energy efficiency and 

speed.  

Contrary to the update of individual weights of ANNs, the reservoir computing approach requires a very 

large number of neurons with random and fixed weights without their precise control, combined with only a 

single layer of reconfigurable readout weights (RW) trained to map the output of this complex transform to a 

desired output17. This paradigm of computing fits well with optics and was implemented with different optical 

devices18–32. The necessary nonlinearity between neurons could be introduced by electronic feedback18, 

optoelectronic conversions27, saturable absorption30, and second-harmonic generation33. Moreover, the 

Kerr effect inside both single-mode 25 and multi-mode34 fibers was shown recently to be an effective 

reservoir for computing systems. Another set of studies showed also that the nonlinear interactions inside 

MMFs are tunable by wavefront shaping35–37.  

In this paper, we present an optical ANN architecture, which combines a relatively small number of digitally 

implemented parameters to control the very complex spatiotemporal transformation realized in an MMF. 

Our experimental studies show that with a spatial light modulator (SLM) by simultaneously shaping light 

with data and a fixed programming pattern, we can induce the non-linear transformation inside the MMF to 

perform desired computations. We find that the optimization of a small number of programming parameters 

(PP), around 50 in our experiments, results in a remarkable performance of the optical computer. For 

instance, we will show that the system with approximately 2000 total parameters (TP), PPs and RWs 

combined, performs as well as a digital ANN with over 400,000 parameters for the face classification task38. 

2 

 
Moreover, we demonstrate that the same method can be used to program the propagation inside MMF to 

perform all-optical classification without the digital readout stage. In this case, the classification can be 

directly read out with a simple beam location sensor, further decreasing the number of TPs.  

Results 

Programming Fiber Transform for Higher Classification Performance 

Our method consists of a nonlinear optical transformation and a programming algorithm. The transform is 

the propagation of spatially modulated laser pulses through a graded-index MMF. The nonlinear 

propagation of an ultrashort pulse inside an MMF is a highly complex process that entails spatial and 

temporal interactions of electromagnetic waves coupled to hundreds of different propagation modes (see 

Supplementary Note 1), such that modelling the transform of a single pulse on the setup provided in 

Figure1 would take 50 minutes with a graphics processing unit (GPU)39. The physical optical system carries 

out this complex spatiotemporal transformation “effortlessly”. The transformation is programmed with a 

relatively small number of PPs. PPs are selected to customize the MMF processor for the specific task by 

wavefront shaping, controlling the optical power, and the placement of the data and diffraction angle on the 

SLM. The combination of wavefront shaping and data encoding as shown in Figure 1 can be formalized as 

follows, where the complex encoded value on the SLM 

 is given by: 

𝑘𝑘
𝐸𝐸𝑆𝑆𝑆𝑆𝑆𝑆

(𝑥𝑥, 𝑦𝑦)

  Eqn.1 

𝑘𝑘
𝐸𝐸𝑆𝑆𝑆𝑆𝑆𝑆

(𝑥𝑥, 𝑦𝑦) = 𝑊𝑊𝐹𝐹(𝑥𝑥, 𝑦𝑦) ∗ exp �𝑖𝑖𝐷𝐷

𝑘𝑘

(𝑥𝑥, 𝑦𝑦)� =   |𝑊𝑊𝐹𝐹(𝑥𝑥, 𝑦𝑦)| ∗ exp�𝑖𝑖(𝐷𝐷

𝑘𝑘

(𝑥𝑥, 𝑦𝑦) + 𝐴𝐴𝐴𝐴𝐴𝐴(𝑊𝑊𝐹𝐹(𝑥𝑥, 𝑦𝑦)))�

The amplitude modulation with the phase-only SLM is realized by modifying the strength of a blazed grating 

(see Methods), whereas the data (

) is encoded as a phase pattern. The wavefront controlling shape 

(

) is a complex combination of N different linearly polarized fiber modes

𝑘𝑘

𝐷𝐷

(𝑥𝑥, 𝑦𝑦)

, and the 

coefficient of each mode is controlled by two parameters, for real and imaginary parts. Therefore, the 
𝑊𝑊𝐹𝐹(𝑥𝑥, 𝑦𝑦)
portion of the wavefront shape that contains the 2N PPs (

, 𝐹𝐹𝑛𝑛(𝑥𝑥, 𝑦𝑦)

) is    

𝑎𝑎𝑛𝑛

. 

Eqn.2 

𝑊𝑊𝐹𝐹(𝑥𝑥, 𝑦𝑦) =   ∑

(𝑎𝑎2𝑛𝑛−1 + 𝑖𝑖 ∗ 𝑎𝑎2𝑛𝑛) ∗ 𝐹𝐹𝑛𝑛(𝑥𝑥, 𝑦𝑦)

𝑁𝑁
𝑛𝑛=1

During the programming, the system processes the data for different selections of PPs, determines the 

output stage (RWs) and a surrogate optimization algorithm finds the best performing set of PPs. This 

optimization is similar to the hyperparameter optimization process in ANNs.   

3 

 
 
 
 
 
 
Figure 1 The experiment flow for programming optical propagation for a computational task 

The peak intensity of the pulsed laser beam is treated as one of the PPs, whose experimental effect is 

analyzed in Supplementary Note 3, and is optimized through the surrogate model. The laser beam is sent 

onto a reflective SLM which encodes the data to be transformed by the optical system and combines them 

with a complex pattern containing the PPs as described in Equation 1. Even though other bases for 

controlling the wavefront can also be effective, we used the fact that the fiber, 

 since they are 

interpretable, orthonormal, and guaranteed to be within the fiber’s numerical aperture. 
𝐹𝐹𝑛𝑛(𝑥𝑥, 𝑦𝑦),

Once the PPs are determined, the data portion of the modulation is changing with every sample, while the 

programming part stays the same. The nonlinear nature of the optical transform implies that the PPs modify 

the nonlinear transform that the dataset undergoes. Upon exiting the fiber, the beam is collimated with a 

lens and sent to a blazed grating. The dispersion due to the grating leads to a camera recording in which 

both spatial and temporal characteristics of the output beam are present.  

The classification accuracies are calculated by training a simple regularized linear regression algorithm on 

the pixel intensity values of the recorded images on the camera in Figure 1. The linear regression maps the 

recorded image to classification results by pointwise multiplication with RWs and summation. Finally, the 

pairs of PPs and corresponding task performance of the system are supplied to the surrogate algorithm that 

optimizes the optical transform. After acquiring the performance metric for different sets of PPs, the 

surrogate optimization algorithm creates mappings between the performance of the system and any given 

set of PPs. The surrogate algorithm continuously refines the model and increases the performance on the 

4 

 
 
task at the same time. Fig 2. illustrates such an experiment, where the data transform with the MMF was 

programmed for a higher classification accuracy on a small subset (2%) of the Fashion-MNIST Dataset, 

which consists of 1200 training images and 300 test images of 10 different classes of fashion items40. 

Figure 2 Programming the MMF propagation for higher classification performance on Fashion-

MNIST dataset. a. The training accuracy during the progress of the programming procedure. The 

horizontal line labeled "Without Programming” shows the accuracy level when PPs are set to zero and 

"With Programming” indicates the level when the PPs found by the programming algorithm are used. The 

colors of circles indicate their sequence in the training.  b. Relation between wavefront shaping parameters 

and training accuracy. 46 different wavefront shaping parameters are shown in two dimensions by means 

of random projection into 2 dimensions for visibility. c. The  peak power of pulses during the programming 

procedure d. The change of the diffraction angle on the SLM, in horizontal and vertical directions. e. The 

shift of image on the SLM in horizontal and vertical directions f. Confusion matrix and average accuracy on 

the test set, without and with the programming of the transform 

5 

 
 
 
As shown in Figure 2, for the first 105 iterations, the surrogate optimization algorithm broadly samples the 

parameter space to create the initial mapping between PPs and the performance metric. After this phase, 

an area with the potential of yielding the best result is selected and sampled in finer steps. Gradually, the 

changes become smaller, and the algorithm converges to a solution. Figure 2b provides a closer look at the 

progression of the process, where each data point represents an iteration, the 2-dimensional random 

projection of 46 wavefront shaping parameters versus the training accuracy. The initial homogenous 

sampling of the parameter space and final fine-tuning can be observed. Similarly, Figure 2c shows that 

after exploring various levels of optical intensity, hence nonlinearity, the convergence led to a higher light 

intensity for obtaining a more efficient nonlinear optical transform. This is also made possible by converging 

to a preferred oblique excitation of the fiber as shown in Figure 2d, allowing for stronger coupling to higher 

order fiber modes as well, hence benefiting from the multimodality of the fiber. Overall, programming the 

optical propagation by optimized PPs improved the classification accuracy both on the training and the test 

sets by about 5% and reached 77% accuracy on the test set. This result is on par with the 79.1% accuracy 

of the 5-layers digital convolutional neural network(CNN) LeNet-541, which is trained with the same dataset 

on a GPU (for details see Supplementary Method). Later we present another approach for programming 

the propagation, in which PPs are combined with data through convolution, and 79.0% test accuracy is 

reached on the same task. 

All-Optical Computing with Propagation in Optical Fiber  

In Figure 2 the PPs were optimized to modify the optical transform inside the MMF to improve the 

performance of the combination of the optical system and the digital readout layer. To further demonstrate 

the programming capacity of our approach, the inference on input samples was done all-optically without 

any RWs by only using the center location of the output speckles as shown in Figure 3. For a binary 

classification problem, the input is classified as either “0” or “1” depending on which side of the 

classification line the center of the output beam resides. Hence, only 3 parameters are required at the 

output for defining any line in two dimensions. Figure 3 illustrates the programming procedure for all-optical 

classification of the dataset consisting of 1200 training and 300 test chest radiography images, equally 

sampled from patients with and without COVID-19 diagnosis42.   

6 

 
 
 
 
Figure 3 Programming procedure for all-optical classification of chest radiographs. a. The schematic 

of the experiment, the data, and the control pattern are sent together to the SLM, the fiber output pattern is 

imaged onto a camera. b,c. The distribution of the beam center locations and corresponding confusion 

matrices for the test set, without and with the programming of the transform. d. The distribution of training 

accuracies with respect to the selection of wavefront shaping parameters. e. Selected power levels for each 

iteration of the programming procedure. f.  Progression of training accuracy during training. The colormap 

relates the color of circles to their sequence in the training, it applies to d-e-f.  

Before programming the system, a linear classifier received the distribution of center locations without any 

control patterns and drew a classification boundary between positive and negative samples. As the 

transform is random, the classifier could only produce training and test accuracies around 50%. Then, the 

decision boundary is kept the same and the training accuracy is improved by optimizing the PPs on the 

SLM with the surrogate model to separate the center location distributions for samples with positive and 

negative labels. This procedure improved the accuracy on the test set from 46% to 77%, as shown in Table 

1. This performance compares favorably to LeNet-5, which uses about 82,000 parameters. This is 

especially significant considering that the proposed method can be realized all-optically with only 55 TPs. 

Similarly on a new task of classifying skin lesions of equally sampled benign (nevus) and malignant 

(melanoma) case images43, 61.3% test accuracy could be achieved. 

7 

 
 
Table 1 Comparison between neural networks and all-optical classification system 

Network Structure 

Total Number 

Operations per 

Accuracy on 

Accuracy 

of Parameters 

Sample on Digital 

Melanoma dataset 

on COVID- 

Computer (FLOP) 

(%) 

19 dataset 

(%) 

LeNet-5 

82826 

1175640 

64.9 ± 2.0 

74.6 ± 3.0 

MMF + classification with 

55 

2029 

61.3 

77.0 

output location 

(with programming)   

Different Wavefront Shaping Approaches for Programming the Optical Transform  

For the two experiments shown previously, the optical transform was programmed through the 

multiplication of fields by encoding data and PPs (i.e., 

 and 

 terms in Eqn.2, respectively) as shown in 

Figure 2 and detailed in Figure 4.a. In this section, we demonstrate that the transform can be achieved with 

𝐷𝐷

𝑊𝑊𝐹𝐹

two additional ways of wavefront shaping as depicted in Figure 4. 

For the modification of the phase, the control pattern was again formed as described in Eqn.2. Thus, this 

function is elementwise digitally multiplied with the input image from the dataset and placed on the SLM as 

visualized in Figure 4.f. For the N-th sample of the dataset, the field diffracted by the SLM becomes  

. After optimization of the PPs, the test accuracy on the 

𝑁𝑁
𝑁𝑁
subset of Fashion-MNIST reached 78%.  
𝐸𝐸𝑆𝑆𝑆𝑆𝑆𝑆

(𝑥𝑥, 𝑦𝑦) ∗ 𝐴𝐴𝐴𝐴𝐴𝐴(𝑊𝑊𝐹𝐹(𝑥𝑥, 𝑦𝑦))))

(𝑥𝑥, 𝑦𝑦) = exp(𝑖𝑖(𝐷𝐷

Alternatively, convolutional filters can be used to amplify or attenuate different parts of the angular 

spectrum of the field, hence its mode decomposition inside the MMF. Importantly, convolutional filters can 

be applied fully optically by filtering in the Fourier plane44.  Figure 4.k. depicts that convolution can also 

program the nonlinear propagation and could reach 79% test accuracy on the same dataset when each 

element of the convolution kernel is set as PPs. Hence, the 

 convolution kernel could be written as  

 in terms of programming 

𝑐𝑐  ×  𝑐𝑐

 PPs. Then, the field modulated by the convolution 

⋯ 𝑎𝑎𝑐𝑐
𝑎𝑎1
⋮
⋮
⋱
−𝑐𝑐+1 ⋯ 𝑎𝑎𝑐𝑐

𝐴𝐴 =   �
filtered N-th sample of the dataset is 

2�

2

𝑎𝑎𝑐𝑐

2

𝑐𝑐

. Similarly on the 1200 training and 

300 test samples from the MNIST-digits dataset 94.3% accuracy, which is comparable to the 94.9% 
(𝑥𝑥, 𝑦𝑦) = exp�𝑖𝑖(𝐴𝐴⊛𝐷𝐷
accuracy of a 7-layer digital ANN with ~420,000 parameters, could be reached with the same approach 

(𝑥𝑥, 𝑦𝑦))�

𝑁𝑁
𝐸𝐸𝑆𝑆𝑆𝑆𝑆𝑆

𝑁𝑁

demonstrating that different wavefront shaping strategies could realize the enhanced interactions within the 

optical fiber.  

8 

 
 
Figure 4 Programming the optical transform by using phase addition and amplitude modulation(a), 

multiplication with phase(f), and convolution(k,p).b,g,l,q shows an example of programmed patterns on 

the SLM, for g,l and q the intensity is not modulated. c,h,m,r shows recorded intensity patterns after the 

propagation inside the optical fiber for the given input pattern. d, i, n, s depicts the progression of training 

accuracies during programming iterations. The confusion matrices on e, j, o, t illustrate the classification 

performance of the programmed optical transform with different methods.  

Transferring Programming Parameters Across Different Tasks and Datasets 

The optimization of PPs from scratch requires processing the selected dataset on the experimental system 

more than 100 times while modifying the PPs. With the approximately 50 frames per second rate, this 

process takes a few hours for a dataset of 1500 images. In addition to switching to faster optoelectrical 

devices, the ability to transfer previously optimized PPs to new tasks or datasets would boost the practical 

utility of this approach as a general-purpose component that can be quickly deployed on different problems. 

This ability is first demonstrated with the reusability of PPs on different tasks for the same dataset. After 

9 

 
 
finding the set of optimal PPs for the task of classifying the gender of the person in an image from Celebrity 

Face Attributes Dataset(CelebA)38, the same set of PPs is used for determining the age of the person. The 

only training required for the transfer between tasks is the determination of RWs without any new surrogate 

optimizations involving the optical system. Table 2 compares the performances of the PP transfer between 

age and gender tasks with fully programming the system for each task separately, showing that the test 

accuracy with the parameter transfer follows the accuracy of programming from scratch. Without 

programming the fiber, the test accuracy on the age classification task is 59.0% and 2026 RWs are used. 

After optimizing an additional 52 PPs (wavefront shaping and experimental parameters, reaching 2078 

TPs), the test accuracy reaches 67.0%, performing better than a digital 7-layer CNN with about 412,000 

parameters. When these optimized 52 PPs are used on the gender classification task on the same dataset 

only with re-training of the RWs, the accuracy on the new task is 76.0%, which is similar to the 76.3% 

achieved by programming the system from scratch with the gender database. The same findings hold true 

when the initial programming is done on the gender task and parameters are transferred to the age task. 

Table 2 The performances of different CNNs and optical computing methods on the CelebA dataset 

Network Structure 

Total 

Operations per 

Test Accuracy on 

Test Accuracy on 

Number of 

Sample on Digital 

Age Task 

Gender Task 

Parameters 

Computer (FLOP) 

LeNet-1 

914 

149132 

61.7±0.2 

67.3±0.4 

LeNet-5 

82146 

1174248 

63.0±0.4 

75.2±1.6 

7-layer Convolutional 

411794 

65163532 

65.3±0.1 

80.1±0.7 

NN   

MMF + linear output 

2026 

4050 

layer 

Programmed MMF for 

2078 

6075 

59.0 

67.0 

69.0 

76.0 

Age Task + linear 

output layer (trained for 

the corresponding test 

task) 

Programmed MMF for 

2078 

6075 

64.7 

76.3 

Gender Task + linear 

output layer (trained for 

the corresponding test 

task) 

10 

 
 
 
Furthermore, we find that the optimized PPs can also be transferred to a different dataset requiring only a 

short corrective programming. The PPs optimized for the COVID-19 classification dataset with the all-

optical approach are transferred to the task of classifying skin lesions between benign (nevus) and 

malignant (melanoma) case images43  (Figure 5). However, directly transferring the PPs from former to 

latter resulted in a test accuracy of 47.67%, which is similar to a random prediction. In corrective 

programming, a smaller set of parameters (11 in total) are designated for optimizing the previously acquired 

set of PPs. These 11 parameters are combined with 52 PPs by repetition of each element multiple times 

and element-wise addition. Thus, an optimal set of PPs is found in the proximity of the initial expectation by 

optimizing in a lower dimensional search space. Decreasing the dimensionality enables a convergence in 

fewer iterations. Compared to the complete programming of the system in 300 iterations, corrective 

programming starts from a similar initial accuracy and after 80 iterations instead of 300, reaches the same 

final test accuracy.  

Figure 5 Using previously dedicated parameters on a new dataset with corrective programming. a, 
The procedure of transferring the PPs. b,c,d,h,I, belongs to the experiment when the PPs fully programmed 
without any prior knowledge. e,f,g,j,k, belongs to the corrective programming of parameters. b,e, Relation 
between wavefront shaping parameters projected to 2 dimensions and the training accuracy. c,f, The peak 
power of pulses at the fiber entrance. d,g, The color bar for coding the iteration number related to each 

11 

 
 
data point on b,c,h and e,f,j. h,j, The training accuracy during the progress of the programming procedure. 
i,k, Confusion matrix and average accuracy on the test set. 

Discussion 

Computation Speed and Energy 

The speed of inferences is limited by the refresh rate of the liquid crystal (LC) SLM. This limitation can be 

overcome by switching to a faster wavefront shaping method, for instance utilizing commercial digital 

micromirror devices, which can reach 30000 frames per second45. Since the number of modes in the MMF 

is much smaller than the number of pixels on commercial SLMs, different lines of the SLM could be 

scanned with the beam by a resonant mirror, allowing up to 25 million samples per second data input rate. 

Moreover, the fixed complex modulation or convolution operations can be implemented with optical phase 

masks, bringing the digital operation count further down. Similarly, instead of the digital readout layer, a 

broadband diffractive element can realize the linear projection step. As it is analyzed in detail in 

Supplementary Note 4 and visualized in Figure 6, implementing the same optical computer with a selection 

of commercially available, high-speed equipment such as digital micromirror devices and quadrant 

photodiodes, 25 TFLOP/s performance could be reached with a total power consumption of 12.6 W, which 

is significantly lower than 300 W consumption of a GPU with a comparable performance46. 

Figure 6 The power efficiency and speed comparison between different computational approaches. 
The possible optimization refers to incorporating a digital micromirror device, a resonant mirror, and an 
optical phase mask in the optical computer. 

12 

 
 
 
Stability and Reproducibility 

The reproducibility of experiments is crucial for consistent comparison between different sets of PPs during 

programming and long-term usability of determined PPs. To investigate reproducibility, the inference 

experiment is repeated every 5 minutes for the same PPs and RWs on the same task over 15 hours. As 

shown in Supplementary Figure 1, the first and final test accuracy is the same, and the standard deviation 

of the test accuracy over time is 0.3%, indicating a very stable experimental inference.  

In conclusion, programming nonlinear propagation inside MMFs with wavefront shaping techniques can 

exploit complex optical interactions for computation purposes and achieve results on par with multi-layer 

neural networks while decreasing the number of parameters by more than 97% and potentially consuming 

orders of magnitude less energy. This shows the capacity of nonlinear optics for providing a solution for the 

exponentially increasing energy cost of the machine learning algorithms. Our work also shows that the 

performance of a reservoir computer can be improved dramatically through the programming methods we 

describe in this paper, which can be applied to other modalities as well.  

Methods 

Experimental setup 

The experimental system shapes the wavefront of a pulsed IR laser beam, couples it into a graded-index 

fiber, then collimates and sends it to two different imaging arms. The laser pulses with 10 ps length, 125 

kHz repetition rate, and 1030 nm center wavelength are provided by a mode-locked ytterbium fiber laser 

(Amplitude Laser, Satsuma). The intensity of the laser beam is controlled from the computer via a half-

wave plate mounted on a motorized rotation stage (Thorlabs PRM1) followed by a polarizing beam splitter. 

Then, the beam is incident on the reflective phase-only two-dimensional spatial light modulator with 1920-

by-1152 pixels and the pitch size (Meadowlark HSP1920-600-1300). The 8-bit SLM is calibrated to provide 

phase modulation between 0 to 2π at each pixel location, for transmitted pixel values between 0 to 255. 

The laser beam has a circular shape with approximately 6.7 mm diameter on the SLM surface, therefore all 

images shown on the SLM are converted to grayscale, upsampled to 520-by-520 to reach the size of the 

beam, and has the format of 8-bit unsigned integer. To isolate diffracted beam from the undiffracted portion, 

all images are shown on the SLM after elementwise addition with a blazed grating phase pattern and its 

phase depth is varied over the beam area to control the diffraction efficiency for each location, hence 

achieving amplitude modulation on the diffracted beam. The first-order diffracted beam is clearly separated 

from the undiffracted beam after propagating 150 mm and focused by a plano-convex lens with a focal 

length of 15 mm. The input facet of commercially available graded-index MMF (OFS, bend-insensitive 

OM2) of 50 µm core diameter, 0.20 NA, 5 m long, is placed in the focal plane of the lens and its position is 

fine-tuned with a 3-dimensional alignment stage. After propagating through the fiber, the beam is collimated 

with a 20 mm focal length plano-convex lens. Then, it is separated into two beams by a non-polarizing 50-

50 beam splitter. The transmitted beam is imaged onto a monochrome CMOS camera (FLIR BFS-U3-

13 

 
31S4M-C) with an achromatic doublet lens of 100 mm focal length. This camera is used for directly 

inspecting the beam shape and for calculating the center location of the beam. The reflected beam again 

goes through a beamsplitter, one of the branches arrive at an InGaAs power sensor (Thorlabs S145C), and 

the other branch is reflected from the diffraction grating (600 lines/mm, Thorlabs GR25-0610) and is 

incident onto the same model of CMOS camera. Neutral density filters are placed before the cameras in the 

optical setup to avoid saturation. The detailed schematic of the experiment is shown on Supp. Fig 5. All the 

electrical equipment is connected to the same general-purpose computer via USB and PCI-E ports. 

Implementation of Programming Parameters 

During this study, the programming of propagation is combined with the data on a digital computer, and the 

combinations were converted to optical signals, even though the combination of PP-controlled shaping and 

data is also realizable in a fully optical manner by means of a fixed 2-dimensional plate with a pre-

determined spatially-varying distribution of phase and magnitude transfer properties.  Three ways to 

program the propagation are presented. In addition to those programming methods based on wavefront 

shaping, for each experiment, 6 additional parameters controlling light intensity (

), displacement of the 

data on the SLM (

x, 

), diffraction angle on the SLM with respect to the optical axis of the system (

𝐼𝐼

, 

), and focal length of defocusing (
𝛥𝛥

𝛥𝛥y

)  are optimized.  

𝛥𝛥𝛥𝛥

𝛥𝛥𝛥𝛥
The first programming method is illustrated in Figure 4.a. and performs an elementwise multiplication of 

𝑓𝑓

fields due to the data and programming. The programming pattern is formed by the linear combination of 

analytically calculated propagation modes of the GRIN MMF. For determining the programming pattern as 

a combination of 

 modes, 

 parameter pairs are selected each for real and imaginary coefficients. 

Therefore the programming complex pattern is formed as 
𝑁𝑁

𝑁𝑁

, where   

and 

 are the coefficients for the 

 -th mode and 

23
 is the scalar field of the 
𝑃𝑃(𝑥𝑥, 𝑦𝑦) =   ∑ 𝐹𝐹𝑖𝑖
𝑖𝑖=1

(𝑥𝑥, 𝑦𝑦) ∗ (𝐴𝐴𝑖𝑖 + 𝑗𝑗𝐵𝐵𝑖𝑖)

 -th mode. These mode 

fields could be expressed in terms of Laguerre polynomials47, 
𝐴𝐴𝑖𝑖 

𝐹𝐹𝑖𝑖(𝑥𝑥, 𝑦𝑦)

𝐵𝐵𝑖𝑖

𝑖𝑖

: 

𝑖𝑖

𝑝𝑝!
𝜋𝜋(𝑝𝑝+|𝑚𝑚|)!

|𝑚𝑚|
𝜌𝜌
|𝑚𝑚|
|𝑚𝑚|+1 
𝐿𝐿𝑝𝑝
�
is the radius of the fiber, 

2
−𝜌𝜌/2𝜌𝜌0

𝜌𝜌0

e

2

𝑖𝑖𝑚𝑚𝑖𝑖

𝜌𝜌
2
�
𝜌𝜌0
 is the wavenumber for the center of the fiber, and  

� e

𝑚𝑚

𝑝𝑝

2
𝜌𝜌0

𝑅𝑅
𝑘𝑘√2Δ 

𝑅𝑅
=
, relative refractive 

.  

 and 

 are radial and angular numbers of the modes, 

𝐿𝐿𝑝𝑝

(𝑥𝑥)

𝐹𝐹𝑖𝑖(𝜌𝜌, 𝛥𝛥) =

,  

2
n1

2
−  n0
2
2𝑛𝑛1

number difference. The input data, 

𝑘𝑘

, is scaled to be between 0 and 

Δ =
, then the combination of the 

programming pattern and other PPs constitutes the diffracted electric field: 

𝐷𝐷(𝑥𝑥, 𝑦𝑦)

2𝜋𝜋

𝛥𝛥𝑦𝑦)| exp  �𝑗𝑗(𝐷𝐷(𝑥𝑥 − 𝛥𝛥𝑥𝑥, 𝑦𝑦 − 𝛥𝛥𝑦𝑦) + arg�𝑃𝑃(𝑥𝑥 − 𝛥𝛥𝑥𝑥, 𝑦𝑦 − 𝛥𝛥𝑦𝑦)� +

 . 

(𝑥𝑥−Δ𝑥𝑥

)

2

2

+(𝑦𝑦−Δ𝑦𝑦)
𝑓𝑓

𝐸𝐸(𝑥𝑥, 𝑦𝑦) = √𝐼𝐼  |𝑃𝑃(𝑥𝑥 − 𝛥𝛥𝑥𝑥, 𝑦𝑦 −

+ 𝑘𝑘 cos(𝛥𝛥𝛥𝛥) sin(𝛥𝛥𝛥𝛥) 𝑥𝑥 +

𝑘𝑘 sin(𝛥𝛥𝛥𝛥) sin(𝛥𝛥𝛥𝛥) 𝑥𝑥�
In the second case, shown in Figure 4.f, the phase of the programming pattern is pointwise multiplied with 

the data, in this case, the diffracted electric field is 

(𝑥𝑥−Δ𝑥𝑥

)

2

2

+(𝑦𝑦−Δ𝑦𝑦)
𝑓𝑓

𝛥𝛥𝑦𝑦)� +

(𝑥𝑥, 𝑦𝑦) = √𝐼𝐼   exp  �𝑗𝑗(𝐷𝐷(𝑥𝑥 − 𝛥𝛥𝑥𝑥, 𝑦𝑦 − 𝛥𝛥𝑦𝑦) arg�𝑃𝑃(𝑥𝑥 − 𝛥𝛥𝑥𝑥, 𝑦𝑦 −

. 

+ 𝑘𝑘 cos(𝛥𝛥𝛥𝛥) sin(𝛥𝛥𝛥𝛥) 𝑥𝑥 + 𝑘𝑘 sin(𝛥𝛥𝛥𝛥) sin(𝛥𝛥𝛥𝛥) 𝑥𝑥�

14 

 
 
 
 
 
 
For the convolutional programming (the third case) in Figure 4.k, the 

 convolution kernel, 

 is 

formed with 

 PPs. Then, the total field is 

𝑐𝑐 𝑥𝑥 𝑐𝑐

𝐶𝐶(𝑥𝑥, 𝑦𝑦)

2

𝑐𝑐

𝐸𝐸(𝑥𝑥, 𝑦𝑦) = √𝐼𝐼   exp  �𝑗𝑗(∑ ∑ (𝐷𝐷(𝑥𝑥 − 𝛥𝛥𝑥𝑥 − 𝑥𝑥𝑚𝑚, 𝑦𝑦 − 𝛥𝛥𝑦𝑦 − 𝑦𝑦𝑚𝑚)𝐶𝐶(𝑥𝑥𝑚𝑚, 𝑦𝑦𝑚𝑚)

) 

.  

𝑐𝑐
𝑥𝑥𝑚𝑚

𝑐𝑐
𝑦𝑦𝑚𝑚

(𝑥𝑥−Δ𝑥𝑥

)

+

2

2

+(𝑦𝑦−Δ𝑦𝑦)
𝑓𝑓

+

𝑘𝑘 cos(𝛥𝛥𝛥𝛥) sin(𝛥𝛥𝛥𝛥) 𝑥𝑥 + 𝑘𝑘 sin(𝛥𝛥𝛥𝛥) sin(𝛥𝛥𝛥𝛥) 𝑥𝑥�
Programming Procedure 

The experiment is considered as a whole with the final digital classifier for the determination of PPs. 

Therefore, the surrogate model is formed directly for the relationship between the PPs and classification 

accuracy on the training dataset. This computational framework is realized in Python by using scikit-learn 

and Python Surrogate Optimization Toolbox(pySOT). In the case of training the digital readout layer for 

classifying according to the output images, the grating dispersed beam is recorded by the camera and 

downsampled to 45 x 45 by average pooling. Then these downsampled images are flattened to 2025 

features, and the ridge classification algorithm is used for the determination of RWs. For all-optical 

classification experiments, the output beam shape is imaged onto the camera without grating dispersion 

and the center of mass,

, of the beam shape, 

,  is calculated by 

. This is the same information as the one provided by simple beam location sensors.  

(𝑥𝑥𝑐𝑐, 𝑦𝑦𝑐𝑐)

𝐺𝐺(𝑥𝑥, 𝑦𝑦)

, 

∞
𝑥𝑥=−∞
∞
𝑥𝑥=−∞

∑
∑

𝑥𝑥 𝐺𝐺(𝑥𝑥)
 𝐺𝐺(𝑥𝑥)

𝑥𝑥𝑐𝑐 =

𝑦𝑦𝑐𝑐 =

∑

∞
𝑦𝑦=−∞
∞
𝑦𝑦=−∞

𝑦𝑦 𝐺𝐺(𝑦𝑦)

 𝐺𝐺(𝑦𝑦)

∑
The surrogate model based on the radial basis function is initiated by sampling 2M+1 Latin Hypercube 

points, M being the number of parameters to be optimized. Then the search algorithm employing the 

DYCORS 48 strategy explores the parameter space for the optimal set of parameters. 

References 

1.  Fasel, B. An introduction to bio-inspired artificial neural network architectures. Acta Neurol. Belg. 103, 

6–12 (2003). 

2.  Kilian, J. & Siegelmann, H. T. The Dynamic Universality of Sigmoidal Neural Networks. Inf. Comput. 

128, 48–56 (1996). 

3.  Rumelhart, D. E., Hinton, G. E. & Williams, R. J. Learning representations by back-propagating errors. 

Nature 323, 533–536 (1986). 

4.  Fedus, W., Zoph, B. & Shazeer, N. Switch Transformers: Scaling to Trillion Parameter Models with 

Simple and Efficient Sparsity. Preprint at http://arxiv.org/abs/2101.03961 (2022). 

5.  Reed, S. et al. A Generalist Agent. Preprint at http://arxiv.org/abs/2205.06175 (2022). 

6.  Bernstein, L. et al. Freely scalable and reconfigurable optical hardware for deep learning. Sci. Rep. 

2021 111 11, 1–12 (2021). 

7.  Solomonoff, R. J. A formal theory of inductive inference. Part I. Inf. Control 7, 1–22 (1964). 

15 

 
 
 
8.  Ulrich, L. GM bets big on batteries: A new $2.3 billion plant cranks out Ultium cells to power a future 

line of electric vehicles. IEEE Spectr. 57, 26–31 (2020). 

9.  Lin, X. et al. All-optical machine learning using diffractive deep neural networks. Science 361, 1004–

1008 (2018). 

10. Luo, Y. et al. Design of task-specific optical systems using broadband diffractive neural networks. Light 

Sci Appl 8, 112 (2019). 

11. Zhou, T. et al. Large-scale neuromorphic optoelectronic computing with a reconfigurable diffractive 

processing unit. Nat. Photonics 15, 367–373 (2021). 

12. Kulce, O., Mengu, D., Rivenson, Y. & Ozcan, A. All-optical information-processing capacity of diffractive 

surfaces. Light Sci Appl 10, 25 (2021). 

13. Wang, T. et al. An optical neural network using less than 1 photon per multiplication. Nat. Commun. 13, 

123 (2022). 

14. Shen, Y. et al. Deep learning with coherent nanophotonic circuits. Nat. Photonics 11, 441–446 (2017). 

15. Huang, C. et al. Demonstration of scalable microring weight bank control for large-scale photonic 

integrated circuits. APL Photonics 5, 040803 (2020). 

16. Dinc, N. U., Psaltis, D. & Brunner, D. Optical neural networks: The 3D connection. Photoniques 34–38 

(2020) doi:10.1051/photon/202010434. 

17. Tanaka, G. et al. Recent advances in physical reservoir computing: A review. Neural Networks vol. 115 

100–123 (2019). 

18. Duport, F., Schneider, B., Smerieri, A., Haelterman, M. & Massar, S. All-optical reservoir computing. 

Opt. Express 20, 22783 (2012). 

19. Larger, L. et al. Photonic information processing beyond Turing: an optoelectronic implementation of 

reservoir computing. Opt. Express 20, 3241 (2012). 

20. Paquot, Y. et al. Optoelectronic reservoir computing. Sci. Rep. 2, 1–6 (2012). 

21. Brunner, D., Soriano, M. C., Mirasso, C. R. & Fischer, I. Parallel photonic information processing at 

gigabyte per second data rates using transient states. Nat. Commun. 2013 41 4, 1–7 (2013). 

22. Vandoorne, K. et al. Experimental demonstration of reservoir computing on a silicon photonics chip. 

Nat. Commun. 5, 1–6 (2014). 

23. Bueno, J. et al. Reinforcement learning in a large-scale photonic recurrent neural network. Optica 5, 

756 (2018). 

24. Katumba, A. et al. Neuromorphic Computing Based on Silicon Photonics and Reservoir Computing. 

IEEE J. Sel. Top. Quantum Electron. 24, (2018). 

25. Pauwels, J., Verschaffelt, G., Massar, S. & Van der Sande, G. Distributed Kerr Non-linearity in a 

Coherent All-Optical Fiber-Ring Reservoir Computer. Front. Phys. 0, 138 (2019). 

26. Lugnan, A. et al. Photonic neuromorphic information processing and reservoir computing. APL 

Photonics 5, 020901 (2020). 

16 

 
27. Rafayelyan, M., Dong, J., Tan, Y., Krzakala, F. & Gigan, S. Large-Scale Optical Reservoir Computing 

for Spatiotemporal Chaotic Systems Prediction. Phys. Rev. X 10, 041037 (2020). 

28. Valley, G. C., Pilawa, J., Luengo-Kovac, M., Ashner, M. N. & Paudel, U. Photonic reservoir computer 

using speckle in multimode waveguide ring resonators. Opt. Express Vol 29 Issue 13 Pp 19262-19277 

29, 19262–19277 (2021). 

29. Valley, G. C., Pilawa, J., Luengo-Kovac, M., Shaw, T. J. & Paudel, U. Classification of time-domain 

waveforms using a speckle-based optical reservoir computer. Opt. Express Vol 28 Issue 2 Pp 1225-

1237 28, 1225–1237 (2020). 

30. Dejonckheere, A. et al. All-optical reservoir computer based on saturation of absorption. Opt. Express 

22, 10868–10881 (2014). 

31. Bueno, J. et al. Reinforcement learning in a large-scale photonic recurrent neural network. Optica 5, 

756–760 (2018). 

32. Gao, C., Gaur, P., Rubin, S. & Fainman, Y. Thin liquid film as an optical nonlinear-nonlocal medium and 

memory element in integrated optofluidic reservoir computer. Adv. Photonics 4, 046005 (2022). 

33. Wright, L. G. et al. Deep physical neural networks trained with backpropagation. Nature 601, 549–555 

(2022). 

34. Teğin, U., Yıldırım, M., Oğuz, İ., Moser, C. & Psaltis, D. Scalable optical learning operator. Nat. 

Comput. Sci. 2021 18 1, 542–549 (2021). 

35. Tzang, O., Caravaca-Aguirre, A. M., Wagner, K. & Piestun, R. Adaptive wavefront shaping for 

controlling nonlinear multimode interactions in optical fibres. Nat. Photonics 12, (2018). 

36. Deliancourt, E. et al. Wavefront shaping for optimized many-mode Kerr beam self-cleaning in graded-

index multimode fiber. Opt. Express 27, 17311–17321 (2019). 

37. Teğin, U. et al. Controlling spatiotemporal nonlinearities in multimode fibers with deep neural networks. 

APL Photonics 5, 030804 (2020). 

38. Liu, Z., Luo, P., Wang, X. & Tang, X. Deep Learning Face Attributes in the Wild. in 2015 IEEE 

International Conference on Computer Vision (ICCV) 3730–3738 (2015). doi:10.1109/ICCV.2015.425. 

39. Teğin, U., Dinç, N. U., Moser, C. & Psaltis, D. Reusability report: Predicting spatiotemporal nonlinear 

dynamics in multimode fibre optics with a recurrent neural network. Nat. Mach. Intell. 3, 387–391 

(2021). 

40. Xiao, H., Rasul, K. & Vollgraf, R. Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine 

Learning Algorithms. ArXiv170807747 Cs Stat (2017). 

41. LeCun, Y. et al. Backpropagation Applied to Handwritten Zip Code Recognition. Neural Comput. 1, 

541–551 (1989). 

42. Rahman, T. et al. Exploring the effect of image enhancement techniques on COVID-19 detection using 

chest X-ray images. Comput. Biol. Med. 132, 104319 (2021). 

43. Rotemberg, V. et al. A patient-centric dataset of images and metadata for identifying melanomas using 

clinical context. Sci. Data 8, 34 (2021). 

17 

 
44. Psaltis, D., Casasent, D., Neft, D. & Rlotto, M. C. Accurate Numerical Computation By Optical 

Convolution. in 1980 Intl Optical Computing Conf II vol. 0232 151–156 (SPIE, 1980). 

45. DLP7000 data sheet, product information and support | TI.com. https://www.ti.com/product/DLP7000. 

46. Yao, C. et al. Evaluating and analyzing the energy efficiency of CNN inference on high-performance 

GPU. Concurr. Comput. Pract. Exp. 33, e6064 (2021). 

47. Mafi, A. Bandwidth Improvement in Multimode Optical Fibers Via Scattering From Core Inclusions. J. 

Light. Technol. 28, 1547–1555 (2010). 

48. Regis, R. G. & Shoemaker, C. A. Combining radial basis function surrogates and dynamic coordinate 

search in high-dimensional expensive black-box optimization. Eng. Optim. 45, 529–555 (2013). 

18 

 
 
 
Supplementary Information for 

Programming Nonlinear Propagation for 

Efficient Optical Learning Machines  

Ilker Oguz1,2, Jih-Liang Hsieh1,2, Niyazi Ulas Dinc1,2, Uğur Teğin1,2, Mustafa Yildirim1, Carlo Gigli2, 

Christophe Moser1 and Demetri Psaltis2 

1 Laboratory of Applied Photonics Devices, Ecole Polytechnique Fédérale de Lausanne (EPFL), Switzerland 

2 Optics Laboratory, Ecole Polytechnique Fédérale de Lausanne (EPFL), Switzerland 

Contents 

Supplementary Note 1: Physical Explanation of the Transform Dynamics .................................................... 2 

Supplementary Note 2: The Stability of the Experiment over Time ............................................................... 3 

Supplementary Note 3: Dependence of the Performance on Pulse Length and Power Level ....................... 5 

Supplementary Note 4: Operation Speed and Power Consumption Analysis of the Computation Method .... 7 

Dimensions and Operation Count ............................................................................................................. 7 

Optical Power Consumption ...................................................................................................................... 7 

Power Consumption for Optoelectrical Conversion ................................................................................... 7 

High-Speed Low-Power Consumption System .......................................................................................... 9 

Discussion on Scalability of the Approach ............................................................................................... 11 

Supplementary Method: Comparison with Digital Neural Networks ............................................................ 12 

Supplementary Figure: Detailed Experimental Setup .................................................................................. 13 

Supplementary References ........................................................................................................................ 14 

1 

 
 
 
 
 
 
 
 
Supplementary Note 1: Physical Explanation of the Transform Dynamics 

As described in the main text, spatial modulation of the input beam controls the amplitude and phase of the 

light to be coupled to the different propagation modes of the optical fiber. During propagation, the phase 

and amplitude of these modes change due to different linear and nonlinear interactions. Multi-mode 

generalized nonlinear Schrodinger equation provides a comprehensive analysis of these effects (Supp. 

Eqn. 1) even for ultrashort pulses1.  The multidimensionality and nonlinearity of these interactions also 

provide an understanding of why this physical phenomenon can perform as an efficient computer. 

𝑝𝑝
= 𝑖𝑖𝑖𝑖𝛽𝛽0

𝐴𝐴𝑝𝑝
𝑝𝑝 ∂𝐴𝐴𝑝𝑝
Dispersion 
2
���������������������
∂𝑡𝑡

𝐴𝐴𝑝𝑝 − 𝑖𝑖𝛽𝛽1

− 𝑖𝑖

𝑝𝑝
𝛽𝛽2
2

2
∂
∂𝑡𝑡

∂𝐴𝐴𝑝𝑝
∂𝑧𝑧

+ 𝑖𝑖 �  

𝐶𝐶𝑝𝑝,𝑛𝑛𝐴𝐴𝑛𝑛
Linear mode coupling  + 𝑖𝑖
���������

𝑛𝑛

𝑛𝑛2𝜔𝜔0
∗
𝜂𝜂𝑝𝑝,𝑙𝑙,𝑚𝑚,𝑛𝑛𝐴𝐴𝑙𝑙𝐴𝐴𝑚𝑚𝐴𝐴𝑛𝑛
  �  
Nonlinear mode coupling 
𝐴𝐴 
𝑙𝑙,𝑚𝑚,𝑛𝑛
�������������������

Supp. 

Eqn.1 

Supp. Eqn. 1 provides a simplified explanation of multimode interactions occurring in the proposed system. 

Here 

 is the complex coefficient of the p-th normalized mode, where

 is the k-th order propagation 

constant for this mode. 

𝐴𝐴𝑝𝑝

 is the linear coupling coefficient between mode p and n, which becomes 

𝑝𝑝
 𝛽𝛽𝑘𝑘

nonzero when there are non-idealities in the waveguiding structure such as ellipticity, bending, or 

𝐶𝐶𝑝𝑝,𝑛𝑛

impurities.

 is the nonlinear refractive index of the material, 

 is the center angular frequency and A is 

the area of fiber core. Since the propagation length is limited to 5 meters, the higher-order dispersion 

 𝑛𝑛2

𝜔𝜔0

effects are not shown. Similarly, in the experiment, the Raman scattering is not observed dominantly, 

hence in the nonlinear mode coupling part, only the part related to the Kerr effect is shown. There, 

 is 

the nonlinear coupling coefficient between modes, it mainly depends on the similarity between spatial 

𝜂𝜂𝑝𝑝,𝑙𝑙,𝑚𝑚,𝑛𝑛

shapes of modes, and can be calculated as follows1,2: 

∗
𝜂𝜂𝑝𝑝,𝑙𝑙,𝑚𝑚,𝑛𝑛 = ∫ 𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝐹𝐹𝑝𝑝

∗
𝐹𝐹𝑙𝑙𝐹𝐹𝑚𝑚𝐹𝐹𝑛𝑛

Supp. 

Eqn.2 

Considering the varying strength of interactions between different sets of modes, controlling their coupling 

explains how implicitly the proposed programming scheme can program the propagation for better 

performance of the task. In other words, the PPs modify the mapping between input images and mode 

distributions, where each set of modes has fixed nonlinear coupling weights. This way, PPs select an 

optimal combination of high-dimensional weights stored already in the medium. Therefore, with a much 

smaller number of PPs the performance of digital neural networks could be reached.  

2 

 
 
 
 
 
 
 
 
 
  
Supplementary Note 2: The Stability of the Experiment over Time 

Due to the fluctuation in environmental conditions and other noise factors, fluctuation in the laser output 

power is expected. To decouple this fluctuation from the optical computing setup, light intensity at the 

output of the multimode fiber is tracked with a power meter and corrections to the angle of polarization 

before the polarizing beamsplitter are applied according to this reading. This way the light intensity inside 

the optical fiber can be kept stable. Moreover, when wavefront shaping is applied, the same reading is also 

used for making sure the intensity of light coupled inside the MMF is directly controlled by the intensity 

programming parameter. To investigate reproducibility, the inference experiment is redone for the same 

PPs and RWs on the same task over 15 hours continuously by sending the samples to the optical system. 

During those experiments, the inference accuracy, the stabilized power level, as well as the average 

correlation between samples are recorded. This correlation is calculated by the average of correlation 

coefficients for each input sample, between the initial output beam shape and the output beam shape for 

the current experiment. As shown in Supplementary Figure 1, the fluctuation in the correlation values and 

power levels resemble each other closely, and they are both much smaller than 1% over 14 hours. The 

average beam correlation in 14 hours is 99.9% with a 0.04% standard deviation and compared to its 

maximum, the power level is 99.7% on average with a 0.14% standard deviation. Consequently, the 

accuracy fluctuations are minimal, with the first and final test accuracy being exactly the same at 83.7%, 

the average value is 83.8% and the standard deviation is 0.35%. Moreover, single-step readout weight 

training allows lightweight recalibration, which can further decrease fluctuations by applying once in many 

experiments. 

3 

 
 
Supplementary Figure 1 Coupled power, output pattern correlation, and classification accuracy of 

the system over time 

4 

 
 
 
 
 
 
 
 
 
 
Supplementary Note 3: Dependence of the Performance on Pulse Length 

and Power Level 

As the main determining factor for the strength of the nonlinear effects, the peak power also modifies the 

nature of the data transform through the optical fiber. As it was previously shown2, there is an optimal peak 

power level for a given task, while there is not enough nonlinearity below this level, above this level beam 

cleaning effects start to become prominent and hinder the efficiency of data processing.   

Supplementary Figure 2 The dependence of training accuracy on pulse peak power and pulse 

length on the CelebA dataset, the age classification task 

Our findings in Supplementary Figure 2, without programming the propagation inside MMF, corroborates 

those findings, showing that for different pulse lengths, the optimal level of peak power and corresponding 

training classifications stay about the same. Moreover, in this case, the length of the fiber is not scaled with 

the pulse length, so the strength of dispersion effects on those pulses are different. This difference can be 

one of the reasons for the small discrepancy observed between different experiments. In addition, the 

output beam shapes shown on Supplementary Figure 3, which corresponds to the same set of experiments 

with Supplementary Figure 2, indicates that the dynamics of transform stay similar at different pulse lengths 

as long as the peak power is also scaled.  

5 

 
 
Supplementary Figure 3 The output beam shapes for the same input image for different power and 

pulse length levels 

6 

 
 
 
 
 
 
 
 
 
 
Supplementary Note 4: Operation Speed and Power Consumption 

Analysis of the Computation Method 

Dimensions and Operation Count 

The experimental results on different datasets indicate that programming MMF propagation can achieve 

similar accuracies with digital NNs requiring ~1 MFLOP/sample. Therefore, for the rest of the document for 

each image processed with the optical system, this process will be accounted as equivalent to 1 MFLOP of 

operation on the GPU. And for each operation, the input is assumed to be 22x22 pixels with 8 bit-depth and 

the output is 45x45 pixels with 8 bit-depth. These resolutions are determined by the supported modes on 

the fiber. On the input side, the diffraction-limited resolution is sampled by 2 input pixels and on the output 

side, the sampling is about 4 pixels per diffraction-limited point size because of the spatially displayed 

temporal information thanks to the diffraction grating. 

Optical Power Consumption 

For optimal performance, the optical system requires 10 ps long pulses with about 10 kW peak optical 

power inside the fiber. Therefore with 100 nJ(=10-11x104nJ) per pulse, the optical power efficiency for the 

equivalent digital computation is 0.1 pJ/FLOP.  

Power Consumption for Optoelectrical Conversion  

Currently, the data is encoded to optical pulses via a liquid crystal phase modulator controlled by an analog 

high-speed circuitry, it has 1920 x 1152 pixels with 8-bit precision, each pixel sized 9.2 µm x 9.2 µm 

working at ~ 50 Hz or 20 ms per frame. The SLM consumes in total (24V,1A) 24 W continuously. Therefore, 

each refresh consumes around 0.5 J (=24Wx20ms), or 217nJ/pixel (0.5/(1920x1152)). For optimal 

utilization of the SLM, in which all pixel information couples to a fiber, by using multiple fibers or only 

activating the subgroup of pixels with light incident on them, the consumption could be brought to 22x22 

pixels x217 nJ/pixel = 105 µJ/image. 

We can replace the phase-only LC SLM with a DMD, for instance, Texas Instruments DLP9500, which can 

show 23148 patterns per second with a 1920x1080 resolution and 4.5 W electrical consumption4. 

Therefore, the power consumption per frame is 196 µJ and per mirror is 94 pJ.  For modulation of 22x22x8 

bits per input image, the energy cost of modulation would be 0.4 µJ.  

For recording output beam shapes, a commercial CMOS camera is used, the camera has a resolution of 

720 x 540 pixels and can reach 522 frames per second, consuming 3W. This amounts to 5.7 mJ for each 

full frame recording and 15 nJ per each pixel readout, or for 45x45 pixel output images, 30 µJ /image. 

Again, this camera can be replaced with another commercially available, but more power-efficient version; 

for instance, LUX 1310, can read out with 1.4nJ/pixel, which can decrease the consumption down to 

2.8µJ/image. 

The energy consumption of laser is calculated by taking fiber coupling, SLM diffraction, and laser efficiency 

into consideration. The efficiency of coupling into MMF is around 50%, for both the LC SLM and the DMD 

7 

 
light diffraction efficiency greater than 70% and a Yb-doped fiber-based femtosecond laser can convert the 

electrical energy to light pulses with about 3.3% efficiency5. Therefore, the electrical power cost of a 100 nJ 

pulse inside the fiber is calculated to be 8.7 µJ. 

Supplementary Table 1 The energy budget breakdown of the proposed optical computing method 

Optoelectronic Device 

Energy Consumption per 

Energy Consumption per 

Image-Consumption of All 

Image-Consumption Scaled to 

Pixels on the Device 

Required Pixels 

LC SLM 

DMD 

Camera 

Laser Consumption 

Total Consumption-LC SLM 

Total Consumption-DMD 

0.5 J  

196 µJ 

5.7 mJ 

8.7 µJ 

506 mJ 

5.9 mJ 

105 µJ 

0.4 µJ 

30 µJ 

8.7 µJ 

144 µJ 

39 µJ 

The energy consumption of each component of the experiment is provided on Supplementary Table 1. In 

the two columns of the table, two different ways of accounting for the energy are presented, the first column 

accounts for the case where consumption due to all of the possible pixels is included. In the second 

column, the energy consumption of the device is scaled to the proportion which is actually used. Moreover, 

in the calculation of total consumption two alternatives are presented, the one with the LC SLM is the 

current experimental setting, while the DMD option is the case when LC SLM is switched with a DMD while 

keeping the experiment exactly the same. In the latter, by turning on only the necessary pixels per image 

energy consumption could be lowered to 39 µJ per image, corresponding to 39 pJ/FLOP. In comparison, 

benchmark results show that an NVIDIA V100 GPU provides inferences with ResNet-50 neural network at 

an energy consumption rate of 46 pJ/FLOP6. 

Switching from an LC SLM to a DMD could improve the inference speed by nearly 3 orders of magnitude, 

reaching up to 23000 frames/second, and allowing 23GFLOP/s. However, as it can be observed in the 

optical telecommunication systems, the transfer and manipulation of information in the optical domain 

supports conveniently GHz-level rates. To demonstrate that this potential indeed encompasses the 

proposed computation method, in the following section we describe an implementation that can reach the 

processing speed of state-of-the-art GPUs, with a favorable efficiency. 

8 

 
 
 
 
 
 
 
High-Speed Low-Power Consumption System 

The energy efficiency and high-performance computing potential of the proposed method can be realized 

with a high-speed system as shown in Supplementary Figure 4. 

Supplementary Figure 4 The experimental schematic of a high-speed implementation of the 

proposed method 

For reaching high data processing speed efficiently, some of the system parameters and components 

should be changed without changing the main principle of computation. These changes are: 

1-  Pulse length 

2-  Spatial modulation device 

3-  Fiber length 

4-  Readout device. 

As the strength of optical nonlinearities is proportional to the peak power of the optical pulse, the required 

average optical power for the same strength of the nonlinearity could be decreased by working with a 

shorter pulse. Moreover, with the shorter pulse, the nonlinear interactions happen at a shorter length scale 

and the fiber length could be scaled proportionately, creating a more compact setup. In the high-speed 

system, instead of the current 10 ps pulses, 300 fs can be used. Then the fiber length can be scaled down 

9 

 
 
 
 
to 17 cm instead of 5 m. This can decrease the light source related consumption by 33 times, down to 264 

nJ/image. 

In our current proof-of-principle system a liquid-crystal SLM is utilized. Even though their ability to directly 

control the phase makes them ideal prototyping tools, the slow response of liquid crystals (a few 

milliseconds) limits the modulation speed with the LC SLMs. On the other hand, digital micromirror devices 

offer a much faster alternative with their millions of fast switchable mirrors (few microseconds). To benefit 

fully from DMD’s speed and the high number of pixels, while only a few hundreds of channels exist in the 

multimode fiber, we propose using a narrow beam and sweeping the lines of the DMD with a resonant 

scanner as shown in Supplementary Figure 4. For instance, the utilization of a ~11.5 kHz resonant mirror 

(Novanta Photonics, CRS 12) whose upwards and downwards cycles are synchronized to 23148 Hz rate 

refreshing with a DMD (TI DLP9500), could achieve the processing of individual lines on the DMD, each 

line consisting of 1920 pixels would encode an input to be processed by the system. Therefore, 1920/240 = 

8 bits of information can be coupled to each one of the 240 channels of the fiber and 23148x1080 ≈25 

million samples per second can be shown. For the conversion of 1-dimensional data and programming to 

2-dimensions, a scattering phase mask can be used7. After coupling into the fiber and propagation, the 

output beam location, which was shown to be programmable to directly provide inference results without 

any need for a digital readout layer, can be tracked with a sectioned photodiode such as Excelitas 

C30665GH-4. Therefore, 25 million inferences per second could be performed, and equivalently 25 

TFLOP/s processing speed could be reached. In comparison, during the benchmarking on the ResNet50 

neural network, as NVIDIA V100 GPU has a peak consumption of 300 W6, with 46 pJ/FLOP, it can provide 

6.5 TFLOP/s. 

Supplementary Table 2 The energy budget breakdown of the high-speed implementation of the 

optical computing method 

Optoelectronic Device 

Power Consumption (W) 

DMD 

Resonant Mirror 

Quadrant Photodiode 

Femtosecond Laser  

Total Consumption 

4.4  

1.5  

0.1 

6.6 

12.6 

In addition to the high-speed computation, the proposed implementation is power efficient. As the 

breakdown can be seen in Supplementary Table 2, while performing inferences with 25 million samples per 

second and the power consumption would be 12.6 W, corresponding to 0.5 pJ/FLOP efficiency.  

In summary, the overall energy consumption of the system depends on the energy cost of input modulation 

and reading out of pixels, in addition to the energy required to create a pulsed laser beam. As the pulse 

repetition rates of femtosecond lasers can reach up to GHz levels, the computation speed is effectively 

limited by the slowest of the optoelectronic conversion devices. The proof-of-principle system with a 

10 

 
 
selection of optoelectronic equipment not being optimized for power consumption can achieve computing 

with power consumption similar to the GPU. Replacing only the SLM of this setup with a DMD is expected 

to improve further the energy efficiency to an advantageous level and speed, since DMD is faster than LC 

SLMs and per bit modulation cost is lower. Scanning different locations of the DMD with the laser beam 

and reading out the inference result all-optically is expected to bring down the energy consumption 2 orders 

of magnitude while providing significantly faster computation. 

The potential of this computing system can be further explored by decreasing the dominant power 

expenditure on optoelectronic modulation by employing silicon photonics based modulation, which can 

achieve an efficiency of 0.1 pJ/bit at 10 Gbit/s 8. In addition to further improving the per bit efficiency 3 

orders of magnitude compared to the DMD, with its high speed, it removes the need for the resonant mirror. 

In this case, the dominant power expenditure would be from the femtosecond laser and this expenditure 

could be again decreased with an optimal fiber, with which nonlinearities could be enhanced more than 10 

times for the same peak power level or could provide the same amount of nonlinearities with 10 times lower 

peak powers9.  

Furthermore, for the proposed improvements, fiber mode number, hence the input and output resolutions 

are assumed to be kept the same. However, as we discuss in the next section, the efficiency of the system 

can be increased by scaling the number of modes. 

Discussion on Scalability of the Approach 

In the previous sections, different implementations are proposed to improve the speed and power efficiency 

while the fiber dimensions are kept the same. Another possible approach would be to increase the number 

of propagation modes, 

  1. This number scales with the square of the core radius, 

, with 

𝑁𝑁  =
the square of the numerical aperture of the fiber (

𝑅𝑅

Δ

𝑘𝑘

𝛼𝛼
2
𝛼𝛼+2 𝑛𝑛0

2

2

), and the inverse square of the light 

2

𝑅𝑅

wavelength (

2
). As N could be increased with simply a different selection of the fiber and light 
= 2Δ𝑛𝑛0

2
𝑁𝑁𝐴𝐴

source, the number of effective calculations is expected to scale with at least 

𝜆𝜆 = 2𝜋𝜋/𝑘𝑘

 and potentially even 

steeper. This expectation stems from the interaction terms in the Multimode Generalized Nonlinear 

2

𝑁𝑁

Schrodinger Equation (Supp. Eqn. 1). Even in the absence of nonlinear interactions, linear interactions 

create some amount of coupling from each mode to every other mode for each infinitesimal propagation 

step. With nonlinear interactions, these interactions become products of four mode coefficients, which 

create a number of interactions on the 

 order. On the other hand, the sample input rate and energy 

consumption are proportional to N, for instance, if modulation with M features takes t time, with the 

4

𝑁𝑁

proposed laser scanning method, modulation with 2M features for 2N modes will take 2t. Similarly, for the 

same level of nonlinearity the optical peak power per mode (P/N) should be kept the same, so for a 2N 

mode fiber, the optical power consumption should be 2P, while the number of operations should scale to at 

least 4C from C. Then, increasing the dimensionality as much as possible should clearly improve the power 

efficiency and operation speed. Even with the same wavelength, a 100-fold increase in the dimensionality 

and an improvement in the operation speed and power efficiency at the same ratio can easily be achieved 

11 

 
by switching the current fiber with the core diameter of 50 µm to another commercially available fiber with a 

500 µm core diameter. 

Supplementary Method: Comparison with Digital Neural Networks 

To create a one-to-one comparison between the presented optical computation method and electronics-

based digital implementations, we used the same portions of the same dataset for training and testing. The 

digital neural networks were implemented with the Keras software library. In addition to LeNet-1 and LeNet-

5 3 implementations, a larger version of LeNet-5 with 7 layers and higher numbers of filters per layer was 

benchmarked. This neural network has the same input size and nonlinear activations as the LeNet-5 while 

it consists of 2 consecutive 2-dimensional convolution layers with 48, 3x3 kernels, a 2-dimensional Max 

Pooling, 2 consecutive 2-dimensional convolution layers with 96, 3x3 kernels, a 2-dimensional Max 

Pooling, a 2-dimensional convolution layers with 192, 3x3 kernels, a 2-dimensional Max Pooling, a dense 

layer with 512 neurons, and finally a dense layer with neurons as many as output classes.  

For each one of the models and datasets, the training is done with 5 different random starting of the neural 

network, the test set accuracies are recorded, and the mean and the standard deviation of these trials are 

reported. 

12 

 
 
 
 
 
 
 
 
 
 
 
 
Supplementary Figure: Detailed Experimental Setup 

Supplementary Figure 5 The detailed schematic of the experimental setup 

13 

 
 
 
 
 
 
 
 
 
 
 
 
 
Supplementary References 

1. Mafi, A. Pulse Propagation in a Short Nonlinear Graded-Index Multimode Optical Fiber. J. Light. Technol. 

Vol 30 Issue 17 Pp 2803-2811 30, 2803–2811 (2012). 

2. Teğin, U., Yıldırım, M., Oğuz, İ., Moser, C. & Psaltis, D. Scalable optical learning operator. Nat. Comput. 

Sci. 2021 18 1, 542–549 (2021). 

3. LeCun, Y. et al. Backpropagation Applied to Handwritten Zip Code Recognition. Neural Comput. 1, 541–

551 (1989). 

4. DLP9500 data sheet, product information and support | TI.com. https://www.ti.com/product/DLP9500. 

5. PHAROS Lasers. LIGHT CONVERSION https://lightcon.com/product/pharos-femtosecond-lasers/. 

6. Yao, C. et al. Evaluating and analyzing the energy efficiency of CNN inference on high-performance 

GPU. Concurr. Comput. Pract. Exp. 33, e6064 (2021). 

7. Whitehead, J. E. M. et al. 2D beam shaping via 1D spatial light modulator using static phase masks. Opt. 

Lett. 46, 2280–2283 (2021). 

8. Asghari, M. & Krishnamoorthy, A. V. Energy-efficient communication. Nat. Photonics 5, 268–270 (2011). 

9. Hirano, M., Nakanishi, T., Okuno, T. & Onishi, M. Silica-Based Highly Nonlinear Fibers and Their 

Application. IEEE J. Sel. Top. Quantum Electron. 15, 103–113 (2009). 

14 

 
 
 
 
 
