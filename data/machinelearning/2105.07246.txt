An End-to-End Framework for Molecular Conformation Generation
via Bilevel Programming

Minkai Xu 1 2 Wujie Wang 3 Shitong Luo 4 Chence Shi 1 2
Yoshua Bengio 1 2 5 Rafael Gomez-Bombarelli 3 Jian Tang 1 5 6

1
2
0
2

n
u
J

2

]

G
L
.
s
c
[

2
v
6
4
2
7
0
.
5
0
1
2
:
v
i
X
r
a

Abstract

Predicting molecular conformations (or 3D struc-
tures) from molecular graphs is a fundamental
problem in many applications. Most existing ap-
proaches are usually divided into two steps by
ﬁrst predicting the distances between atoms and
then generating a 3D structure through optimizing
a distance geometry problem. However, the dis-
tances predicted with such two-stage approaches
may not be able to consistently preserve the ge-
ometry of local atomic neighborhoods, making
the generated structures unsatisfying. In this pa-
per, we propose an end-to-end solution for molec-
ular conformation prediction called ConfVAE
based on the conditional variational autoencoder
framework. Speciﬁcally, the molecular graph is
ﬁrst encoded in a latent space, and then the 3D
structures are generated by solving a principled
bilevel optimization program. Extensive experi-
ments on several benchmark data sets prove the
effectiveness of our proposed approach over ex-
isting state-of-the-art approaches. Code is avail-
able at https://github.com/MinkaiXu/
ConfVAE-ICML21.

1. Introduction

Recently we have witnessed much success of deep learning
for molecule modeling in a variety of applications ranging
from molecule property prediction (Gilmer et al., 2017) and
molecule generation (You et al., 2018; Shi et al., 2020b) to
retrosynthesis planning (Shi et al., 2020a). In these applica-
tions, molecules are generally represented as graphs with
atoms as nodes and covalent chemical bonds as edges. Al-

*Equal contribution 1Mila - Qu´ebec AI Institute, Canada
2Universit´e de Montr´eal, Canada 3Massachusetts Institute of Tech-
nology, USA 4Peking University, China 5Canadian Institute for
Advanced Research (CIFAR), Canada 6HEC Montr´eal, Canada.
Correspondence to: Minkai Xu <minkai.xu@umontreal.ca>.

Proceedings of the 38 th International Conference on Machine
Learning, PMLR 139, 2021. Copyright 2021 by the author(s).

though this is empirically effective, in reality molecules are
better represented as 3D structures (also known as confor-
mations), where each atom is characterized by 3D Cartesian
coordinates. Such 3D structures are also more intrinsic
and informative, determining many chemical and biolog-
ical properties such as chemical sensing and therapeutic
interactions with proteins.

However, determining the 3D structures from experiments is
challenging and costly. Effectively predicting valid and low-
energy conformations has been a very important and active
topic in computational chemistry. Traditional computational
approaches are typically based on Markov chain Monte
Carlo (MCMC) or molecular dynamics (MD) (De Vivo et al.,
2016) to propose conformations combined with simulations
to assign energies through cheap empirical potentials or
expensive quantum chemical simulations (Ballard et al.,
2015). Recently, there is growing interest in developing
machine learning approaches (Mansimov et al., 2019; Simm
& Hern´andez-Lobato, 2020; Xu et al., 2021) to model the
conditional distribution p(R|G) of stable conformations R
given the molecular graph G by training on a collection of
molecules with available stable conformations. Speciﬁcally,
two recent works (Simm & Hern´andez-Lobato, 2020; Xu
et al., 2021) propose to ﬁrst predict the distances between
atoms and then generate molecular conformations based
on the predicted distances by solving a distance geometry
problem (Liberti et al., 2014). Such approaches based on
distance geometry effectively take into account the rotation
and translation invariance of molecular conformations and
have hence achieved very promising performance.

However, there is still a signiﬁcant limitation for these two-
stage approaches, which predict the distances and confor-
mations separately: the predicted distances might not be
able to properly preserve the 3D geometry of local atomic
neighborhoods. Some invalid combinations of distances
could be assigned a high likelihood according to the distance
prediction model. The errors in these distances could be sig-
niﬁcantly exaggerated by the distance geometry program of
the second stage, yielding unrealistic outlier samples of 3D
structures. This is not surprising as the distance prediction
model is trained by maximizing the factorized likelihood

 
 
 
 
 
 
An End-to-End Framework for Molecular Conformation Generation via Bilevel Programming

of distances while our end goal is to predict valid and sta-
ble conformations. We propose to effectively address this
issue with an end-to-end solution which directly predicts
the conformation given the molecular graph. Indeed, in
a related problem of predicting 3D structures of proteins
(a.k.a. protein structure prediction) based on amino-acid
sequences, the recent huge success of the AlphaFold2 algo-
rithm shows the importance and effectiveness of developing
an end-to-end solution compared to the previous AlphaFold
algorithm (though exact details of AlphaFold2 algorithm
are still lacking) (Senior et al., 2020a; Jumper et al., 2020).

In this paper, we propose such an end-to-end solution called
ConfVAE for molecular conformation generation, based on
bilevel programming. To model the rotational and transla-
tional invariance of conformations, we still take the pairwise
distances among atoms as intermediate variables. However,
instead of learning to predict distances by minimizing er-
rors in the space of distance, we formulate the whole prob-
lem as bilevel programming (Franceschi et al., 2018), with
the distance prediction problem and the distance geometry
problem for conformation generation being simultaneously
optimized. The whole framework is built on the condi-
tional variational autoencoder (VAE) framework (Kingma
& Welling, 2013), in which the molecular graph is ﬁrst en-
coded into the VAE latent space, and the conformations
are generated based on the latent variable and molecular
graph. During training, we iteratively sample a set of dis-
tances from the distance prediction model, generate the 3D
structures by minimizing an inner objective (deﬁned by the
distance geometry problem), and then update the distance
prediction model by optimizing the outer objective, i.e., the
likelihood directly deﬁned on the conformations.

To the best of our knowledge, ConfVAE is the ﬁrst method
for molecular conformation generation which can be trained
in an end-to-end fashion and at the same time keep the
property of rotational and translational invariance. Extensive
experiments demonstrate the superior performance of the
proposed method over existing state-of-the-art approaches
on several widely used benchmarks including conformation
generation and distance distribution modeling. We also
verify that the end-to-end objective is of vital importance
for generating realistic and meaningful conformations.

2. Background

2.1. Problem Deﬁnition

Notations. Following existing work (Simm & Hern´andez-
Lobato, 2020; Xu et al., 2021), each molecule is represented
as an attributed atom-bond graph G = (cid:104)V, E(cid:105), where V
is the set of vertices representing atoms and E is the set
of edges representing inter-atomic bonds. Each node v in
V describes the chosen atomic features such as element

type. Each edge euv in E describes the corresponding chem-
ical bond connecting u and v, and is labeled with its bond
type. Since the distances of bonds existing in the molecular
graph are not sufﬁcient to determine an unique conformation
(e.g.due to so-called internal rotations around the axis of the
bond), we adopt the common pre-processing methodology
in existing works (Simm & Hern´andez-Lobato, 2020; Xu
et al., 2021) to expand the graphs by incorporating auxiliary
edges, which force multi-hop distance constraint eliminat-
ing some ambiguities in the 3D conformation, as elaborated
in Appendix A.

For the geometry R, each atom in V is represented by a
3D coordinate vector r ∈ R3, and the full set of positions
{rv}v∈V is represented by the matrix R ∈ R|V|×3. Let
duv denote the Euclidean distance (cid:107)ru − rv(cid:107)2 between the
uth and vth atom, then all the distances between connected
nodes {duv}euv∈E can be summarized as a vector d ∈ R|E|.
Problem Deﬁnition. The problem of molecular conforma-
tion generation is a conditional generation process, where
the goal is to model the conditional distribution of molecular
conformations R given the graph G, i.e., p(R|G).

2.2. Bilevel Optimization

Bilevel programs are deﬁned as optimization problems
where a set of variables involved in the (outer) objective
function are obtained by solving another (inner) optimiza-
tion problem (Colson et al., 2007). Formally, given the outer
objective function F and the inner objective H, and the cor-
responding outer and inner variables θ and w, a bilevel
program can be formulated by

min
θ

F (wθ) such that wθ ∈ arg min

w

H(w, θ).

(1)

Bilevel programs have shown effectiveness in a variety of
situations such as hyperparameter optimization, adversarial
and multi-task learning, as well as meta-learning (Maclaurin
et al., 2015; Bengio, 2000; Bennett et al., 2006; Flamary
et al., 2014; Mu˜noz-Gonz´alez et al., 2017; Franceschi et al.,
2018).

Typically solving equation 1 is intractable since the solu-
tion sets of wθ may not be available in closed form (Ben-
gio, 2000). A common approach is to replace the exact
minimizer of the inner object H with an approximation
solution, which can be obtained through an iterative opti-
mization dynamics Φ such as stochastic gradient descent
(SGD) (Domke, 2012; Maclaurin et al., 2015; Franceschi
et al., 2017). Starting from the initial parameter w0, we
can get the approximate solution wθ,T by running T iter-
ations of the inner optimization dynamics Φ, i.e., wθ,T =
Φ(wθ,T −1, θ) = Φ(Φ(wθ,T −2, θ), θ), and so on. In the gen-
eral case where θ and w are real-valued and the objectives
and optimization dynamics is smooth, the gradient of the

An End-to-End Framework for Molecular Conformation Generation via Bilevel Programming

object F (wθ,T ) w.r.t. θ, named hypergradient ∇θF (wθ,T ),
can be computed by:

∇θF (wθ,T ) = ∂wF (wθ,T )∇θwθ,T

(2)

where ∂ denotes the partial derivative to compute the Jaco-
bian on immediate variables while ∇ denotes a total deriva-
tive taking into account the recursive calls to F . The above
gradient can be efﬁciently calculated by unrolling the op-
timization dynamics with back-propagation, i.e., reverse-
mode automatic differentiation (Griewank & Walther, 2008),
where we repeatedly substitute wΦ,t = Φ(wθ,t−1, θ) and
apply the chain rule.

3. Implicit Distance Geometry

In this section we elaborate on the proposed end-to-end
framework. We ﬁrst present a high-level description of our
bilevel formulation in Sec. 3.1. Then we present the model
schematic and training objectives in Sec. 3.2. Finally we
show how to learn the model via hypergradient descent in
Sec. 3.3 and how to draw samples in Sec. 3.4.

3.1. Overview

Since a molecule can have multiple stable conformations,
we model the distribution of conformations R condition-
ing on molecular graph G (i.e. p(R|G)) with a conditional
variational autoencoder (CVAE) (Kingma & Welling, 2013),
in which a latent variable z is introduced to model the un-
certainty in molecule conformation generation. The CVAE
model includes a prior distribution of latent variable pψ(z|G)
and a decoder pθ(R|z, G) to capture the conditional dis-
tribution of R given z. During training, we also involve
an additional inference model (encoder) qφ(z|R, G). The
encoder and decoder are jointly trained to maximize the
evidence lower bound (ELBO) of the data log-likelihood:

log P (R|G) ≥Ez∼qφ(z|R,G) [log pθ(R|z, G)]
− DKL [qφ(z|R, G)(cid:107)pψ(z|G)]

(3)

(cid:44)LELBO(θ, φ, ψ),

The ELBO can be interpreted as the sum of the negative
reconstruction error Lrecon (the ﬁrst term) and a latent
space prior regularizer Lprior (the second term). In practice,
qφ(z|R, G) and pψ(z|G) are all modeled as diagonal Gaus-
sians N (z|µφ(R, G), σφ(R, G)) and N (z|µψ(G), σψ(G)),
whose mean and standard deviation are predicted by graph
neural networks. To efﬁciently optimize the ELBO during
training, sampling from qφ(z|R, G) is done by reparametriz-
ing z as zφ = µφ(R, G) + σφ(R, G) · (cid:15), where (cid:15) ∼ N (0, I).

With similar encoder and prior models, the key differences
among different methods lie in the architecture and learning
method of the decoder (generator) model pθ(R|z, G), i.e.,

how to parameterize the decoder and train it with respect
to the reconstruction loss Lrecon. Let Dθ(z, G) denote the
decoder function taking prior z and graph G to obtain a
distance vector, we now elaborate how we formulate the
optimization problem of the decoder as a bilevel program:

Inner objective: Directly generating conformations as
Cartesian coordinates heavily depends on the arbitrary ro-
tation and translation. Therefore, previous effective ap-
proaches (Simm & Hern´andez-Lobato, 2020; Xu et al.,
2021) instead make the decoder generate inter-atomic dis-
tances d, i.e., dθ,φ = Dθ(zφ, G). The distances d are taken
as intermediate variables to generate conformations, which
are invariant to rotation and translation. To generate a con-
formation R, one needs to ﬁrst generate the set of distances
d, and then post-process d to obtain the 3D positions R, by
solving a distance geometry optimization problem:

Rθ,φ = arg min
R
= arg min
R

= arg min
R

H(R, Dθ(zφ, G))

H(R, dθ,φ)
(cid:110) (cid:88)

(cid:0)(cid:107)ru − rv(cid:107)2 − duv

(4)

(cid:1)2(cid:111)
,

euv∈E

which we take as the inner loop objective.

Outer objective: Ultimately, we are interested in di-
rectly minimizing the generalization error on 3D struc-
tures to make the generated conformation consistent with
the ground-truth up to rotation and translation. The
post-alignment Root-Mean-Square Deviation (RMSD) is
a widely used metric for this purpose. To calculate this
metric, another conformation ˆR is ﬁrst obtained by an align-
ment function ˆR = A(R, R∗), which rotates and translates
the reference conformation R∗ to have the smallest distance
to the generated one R according to the RMSD metric:

RMSD(R, ˆR) =

(cid:16) 1
n

n
(cid:88)

i=1

(cid:107)Ri − ˆRi(cid:107)2(cid:17) 1

2

.

(5)

where n is the number of atoms. Then the reconstruction
objective Lrecon can be written as:

F (Rθ,φ) = log pθ(R|z, G)

= −

n
(cid:88)

3
(cid:88)

i=1

j=1

(Rij − A(R, R∗)ij)2 ,

(6)

which is the outer loop objective for computing the recon-
struction loss and maximize the log-likelihood.

Bilevel program: Now we can consider equation 4 and
equation 6 as the inner and outer objectives of a bilevel pro-
gramming problem. In this formulation, the outer objective
aims to model the true conditional distribution p(R|G), and
the inner objective solves for the conformation given a set

An End-to-End Framework for Molecular Conformation Generation via Bilevel Programming

Figure 1. The overall framework of ConfVAE. At training time, given the graph G and conformation R, we: 1) compute the distributions
of qφ(z|G, R) and pψ(z|G), and calculate Lprior; 2) sample z from qφ by reparameterization, and feed it into the decoder (generator) pθ
to generate inter-atomic distances d, after which we can obtain an auxiliary objective Laux from the true distances ˆd derived from R; 3)
run the inner loop (distance geometry) to recover the 3D structure from d, and compute the reconstruction RMSD loss Lrecon. The model
is trained end-to-end by optimizing the sum of three object components Lprior, Laux and Lrecon.

of predicted distances. By taking the expectation over latent
variable z, the resulting bilevel program for calculating the
reconstruction term Lreconin equation 3 can be written as:

ﬂow (Chen et al., 2018) (CNF) for the decoder pθ(R|z, G),
which has constant memory cost. We describe the details of
our decoder model below.

max
θ,φ

Ez∼qφ(z|R,G) [F (Rθ,φ, θ)]

such that Rθ,φ = arg min
R

H(R, Dθ(zφ, G)).

(7)

(8)

The derived bilevel problem is still challenging because: 1)
the solution of conformation structure in the inner problem is
not available in closed form; 2) computing this expectation
exactly over the continuous latent space is intractable. Thus,
in practice we compute an empirical estimation of the output
with a variational inference model and the reparametrization
trick. We elaborate on how we address these issues in the
following parts.

3.2. Generative Model

We now have the tools needed to deﬁne our conditional gen-
erative model of molecular conformation. The cornerstone
of all modules (encoder, prior and decoder) is message-
passing neural networks (MPNNs) (Gilmer et al., 2017),
which is a variant of graph neural networks that achieves
state-of-the-art performance in representation learning for
molecules (Scarselli et al., 2008; Bruna et al., 2013; Du-
venaud et al., 2015; Kipf & Welling, 2016; Kearnes et al.,
2016; Sch¨utt et al., 2017). The MPNN directly operates
on the graph representation G and is invariant to graph iso-
morphism. In each convolutional (message passing) layer,
atomic embeddings are updated by aggregating the informa-
tion from neighboring nodes.

For the encoder qφ(z|R, G) and prior pψ(z|G), we use the
same MPNN architecture as Mansimov et al. (2019); Simm
& Hern´andez-Lobato (2020). Since bilevel optimization
has a relatively high memory cost, we use an ordinary
differential equation (ODE)-based continuous normalizing

Decoder Architecture. As illustrated in Sec. 3.1, our de-
coder is composed of two cascaded levels: a distance pre-
diction model Dθ(z, G) that decodes z back into a set of
distances d, and a differentiable distance geometry proce-
dure to recover geometry R from distances d. The model
Dθ(z, G) is implemented as a conditional extension of the
CNF which transforms noise variables d(t0) (also the initial
distances in the CNF ODE trajectory) sampled from the
prior distribution N (0, I) to ﬁnal distances d = d(t1). The
transformation is conditioned on the latent variable z as well
as the graph G:

d = Dθ(z, G)

= d(t0) +

(cid:90) t1

t0

gθ(d(t), t, G, z)dt,

(9)

where gθ is an MPNN that deﬁnes the continuous-time dy-
namics of the ﬂow Dθ conditioned on z and G. Note that,
given the true distances d(t1) = d, d(t0) can also be eas-
ily computed by reversing the continuous dynamics Dθ:
D−1
gθ(d(t), t, z, G)dt. And thus the
exact conditional log-likelihood of distances given G can be
computed by:

θ (z, G) = d(t1) + (cid:82) t0

t1

Laux = log pθ(d|z, G)

= log p(d(t0)) −

(cid:90) t1

t0

Tr

(cid:19)

(cid:18) ∂gθ
∂d(t)

dt.

(10)

An ODE solver can then be applied to estimate the gradi-
ents on parameters for optimization. In practice, Laux can
be taken as an auxiliary objective deﬁned on distances to
supervise the training. In summary, the training objective
can be interpreted as the sum of three parts:

L(θ, φ, ψ) = Lrecon + λLprior + αLaux,

(11)

*+InnerLoopTrainingObjectsNeuralModulesAn End-to-End Framework for Molecular Conformation Generation via Bilevel Programming

Figure 2. Schematic illustration of the forward and backward computational graph through the inner loop (distance geometry optimization).
We repeatedly update R with the gradient ∇RH during the forward computation, and accumulate hypergradients ∇θ,φR to update
parameters θ and φ from backward computation.

where λ and α are hyperparameters to reweight each com-
ponent. The overall framework is illustrated in Fig. 1.

3.3. End-to-end Learning via Hypergradient Descent

We now discuss how to optimize the bilevel problem de-
ﬁned by equation 8 and equation 7 through a practical al-
gorithm. The inner problem in equation 8 is a classic dis-
tance geometry problem about how to infer 3D coordinates
from pairwise distances (Anand & Huang, 2018; Simm &
Hern´andez-Lobato, 2020; Xu et al., 2021). Others have
used a semi-deﬁnite program (SDP) to infer protein struc-
ture from nuclear magnetic resonance data (Alipanahi et al.,
2013), or an Alternating Direction Method of Multipliers
(ADMM) algorithm to fold the protein into the 3D Cartesian
coordinates (Anand & Huang, 2018). In this initial work
we choose gradient descent (GD), with tractable learning
dynamics Φ, to approximately solve for the geometry:

Rθ,φ,t+1 = Φ(Rθ,φ,t, dθ,φ) = Rθ,φ,t−η∇H(Rθ,φ,t, dθ,φ),

(12)
where η is the learning rate and dθ,φ is the distance set
generated from the distance prediction model. Under ap-
propriate assumptions and for a number of updates t → ∞,
GD can converge to a proper geometry Rθ,φ that depends
on the predicted pairwise distances (Bottou, 2010).

Now we consider how to calculate the hypergradient
∇θ,φEz∼qφ(z|R,G) [F (Rθ,φ)] from the outer loop recon-
struction objective (equation 7) to train the model. Let
Rθ,φ,T denote the conformation generated by approxi-
mately solving for the distance geometry with T steps gra-
dient descent. Now we can write the hypergradient as:

∇θ,φEz∼qφ(z|R,G) [F (Rθ,φ,T )]

(13)

= Ez∼qφ(z|R,G)∂R [F (Rθ,φ,T )] ∇θ,φRθ,φ,T ,

where the gradient ∇θ,φRθ,φ,T can be computed by fully
unrolling the dynamics of inner loop from RT to R0.
Speciﬁcally, in the forward computation, successive geome-
tries R0,··· ,T resulting from the optimization dynamics are

cached. In the backward call, the cached geometries are used
to compute gradients in a series of Vector-Jacobian Products
(VJPs). During the reverse computation, the gradient start-
ing from the ∂RT F can be propagated to the intermediate
geometries Rt through ∇RtRt+1:

∇RtRt+1 = ∇Rt

(cid:0)Rt − η∇RtH(dφ,θ, Rt)(cid:1)
H(dφ,θ, Rt)

= 1 − η∇2
Rt

(14)

where ∇2
denotes the Hessian w.r.t. Rt. With iteratively
Rt
computed derivatives ∇Rt RT , the adjoints on dφ,θ can be
computed in forms of VJPs and further backpropagated to
the parameters of encoder qφ and decoder pθ. Formally,
∇dRT is computed by:

∇dθ,ψ RT =

0
(cid:88)

[∇Rt+1RT ]∇dRt+1

t=T −1

= −η

0
(cid:88)

t=T −1

[∇Rt+1RT ]∇d

(cid:0)∇RtH(dφ,θ, Rt)(cid:1),

(15)
where ∇Rt+1RT can be substituted by equation 14. The
computation can be done efﬁciently with reverse-mode au-
tomatic differentiation software such as PyTorch (Paszke
et al., 2019). A schematic illustration of the forward and
backward computational graph through distance geometry
is presented in Fig. 2. We provide a detailed algorithm of
the training procedure in Appendix. B.

3.4. Sampling

Given the graph G, to generate a conformation R, we
ﬁrst draw the latent variable ˜z from the prior distribution
pψ(z|G). Then we sample the random initial distances d(t0)
from a Gaussian distribution, then pass ˜d(t0) through the
invertible Neural ODE Gθ conditioned on ˜z and G to obtain
the distance set ˜d = Gθ( ˜d(t0); z, G). Then we produce the
conformation R by solving the distance geometry optimiza-
tion problem arg minR H(R, dθ,φ) as deﬁned in equation 4.

ForwardComputationBackwardComputationAn End-to-End Framework for Molecular Conformation Generation via Bilevel Programming

Table 1. Comparison of different methods on the conformation generation task. Top 5 rows: deep generative models for molecular
conformation generation. Bottom 6 rows: different methods with an additional rule-based force ﬁeld to further optimize the generated
structures. We report the COV and MAT scores, where Mean and Median are calculated over different molecular graphs in the test set of
GEOM. In practice, the size of the generated set is sampled as two times of the reference set following Xu et al. (2021).

Dataset

Metric

CVGAE
GraphDG
CGCF
ConfVAE-
ConfVAE

RDKit

CVGAE + FF
GraphDG + FF
CGCF + FF
ConfVAE- + FF
ConfVAE + FF

GEOM-QM9

GEOM-Drugs

COV∗ (%)

MAT ( ˚A)

COV∗ (%)

MAT ( ˚A)

Mean Median Mean Median Mean Median Mean Median

8.52
55.09
69.60
75.57
77.98

79.94

63.10
70.67
73.52
77.95
81.46

5.62
56.47
70.64
80.76
82.82

87.20

60.95
70.82
72.75
79.14
83.80

0.7810
0.4649
0.3915
0.3873
0.3778

0.7811
0.4298
0.3986
0.3850
0.3770

0.00
7.76
49.92
51.24
52.59

0.00
0.00
41.07
46.36
56.41

2.5225
1.9840
1.2698
1.2487
1.2330

2.4680
2.0108
1.3064
1.2609
1.2270

0.3238

0.3195

65.43

70.00

1.0962

1.0877

0.3939
0.4168
0.3131
0.2851
0.2702

0.4297
0.3609
0.3251
0.2817
0.2709

83.08
84.68
92.28
91.48
91.88

95.21
93.94
98.15
99.21
100.00

0.9829
0.9129
0.7740
0.7743
0.7634

0.9177
0.9090
0.7338
0.7436
0.7312

* For COV, the threshold δ is set as 0.5 ˚A for QM9 and 1.25 ˚A for Drugs following Xu et al. (2021).

4. Experiments

4.1. Experiment Setup

Evaluation Tasks. Following previous work on conforma-
tion generation (Mansimov et al., 2019; Simm & Hern´andez-
Lobato, 2020; Xu et al., 2021), we conduct extensive exper-
iments by comparing our method with the state-of-the-art
baseline models on several standard tasks. Conformation
Generation is formulated by Xu et al. (2021), who con-
centrate on the models’ capacity to generate realistic and
diverse molecular conformations. Distance distribution
modeling is ﬁrst proposed by Simm & Hern´andez-Lobato
(2020), who evaluate whether the methods can model the
underlying distribution of distances.

Baselines. We compared our proposed model with the fol-
lowing state-of-the-art conformation generation methods.
CVGAE (Mansimov et al., 2019) is a conditional VAE-
based model, which applied a few layers of graph neural
networks to learn the atom representation from the molec-
ular graph, and then directly predicts the 3D coordinates.
GraphDG (Simm & Hern´andez-Lobato, 2020) also em-
ploys the conditional VAE framework. Instead of directly
generating the conformations in 3D coordinates, they in-
stead learn the distribution over distances. Then the dis-
tances are converted into conformations with a distance
geometry algorithm. CGCF (Xu et al., 2021), another two-
stage method, uses continuous normalizing ﬂows to predict
the atomic pairwise distances. Following the baselines, we
also compare our model with RDKit (Riniker & Landrum,
2015), a classical distance geometry approach built upon an

extensive calculation collection of edge lengths by compu-
tational chemistry.

Featurization and Implementation. The MPNNs used for
the encoder, prior and decoder are all implemented as Graph
Isomorphism Networks (Xu et al., 2018; Hu et al., 2019).
For the input features of the graph representation, we only
derive the atom and bond types from molecular graphs. As a
default setup, the MPNNs are all implemented with 3 layers,
and the hidden embedding dimension is set as 256. For the
training of ConfVAE, we train the model on a single Tesla
V100 GPU with a batch size of 128 and a learning rate of
0.001 until convergence, with Adam (Kingma & Welling,
2013) as the optimizer.

4.2. Conformation Generation

Datasets. Following Xu et al. (2021), we use the recent
proposed GEOM-Drugs and GEOM-Drugs (Axelrod &
Gomez-Bombarelli, 2020) datasets for the conformation
generation task. The Geometric Ensemble Of Molecules
(GEOM) dataset contains millions of high-quality stable
conformations, which is suitable for the conformation gener-
ation task. The GEOM-Drugs dataset consists of generally
medium-sized organic compounds, containing an average
of 44.2 atoms. We follow the setting from Xu et al. (2021)
to randomly take 50000 conformation-molecule pairs as the
training set, and another 9161 conformations (covering 100
molecular graphs) as the test split. By contrast, GEOM-
QM9 is a much smaller dataset limited to small molecules
with 9 heavy atoms. Similarly, we randomly draw 50000
conformation-molecule pairs to constitute the training set,

An End-to-End Framework for Molecular Conformation Generation via Bilevel Programming

Figure 3. Visualization of generated conformations from state-of-the-art baselines, our method and the reference set, where four molecular
graphs are randomly taken from the test set of GEOM-Drugs. C, O, H, S and Cl are colored gray, red, white, yellow and green respectively.

and another 17813 conformations covering 150 molecular
graphs as the test set.

Evaluation metrics. In this task we hope the generated
samples to be of both high quality and diversity. We follow
previous work (Hawkins, 2017; Mansimov et al., 2019; Xu
et al., 2021) to calculate the RMSD of the heavy atoms
between generated samples and reference ones. Given
the generated conformation R and the reference R∗, we
take the same alignment function A(R, R∗) deﬁned in
equation 5 to obtain the aligned conformation ˆR, and
then calculate the evaluation metric by RMSD(R, ˆR) =
(cid:16) 1
n

, where n is the number of heavy
atoms. Built upon the RMSD metric, Xu et al. (2021) de-
ﬁned Coverage (COV) and Matching (MAT) scores to mea-
sure the diversity and quality respectively. COV counts
the fraction of conformations in the reference set that are
covered by at least one conformation in the generated set:

i=1 (cid:107)Ri − ˆRi(cid:107)2(cid:17) 1

(cid:80)n

2

1
|Sr|

R ∈ Sr

COV(Sg(G), Sr(G)) =
(cid:12)
(cid:110)
(cid:12)
(cid:12) RMSD(R, R(cid:48)) < δ, ∃R(cid:48) ∈ Sg
(cid:12)
(cid:12)

(cid:111)(cid:12)
(cid:12)
(cid:12).
(16)
where Sg(G) and Sr(G) denote the generated and the ref-
erence conformations set respectively. Typically, a higher
COV score indicates a better diversity performance to cover
the complex true distribution.

While COV is able to detect mode-collapse, there is no guar-
antee for the quality of generated samples. Thus, the MAT
score is deﬁned as a complement metric that concentrates
on the quality (Xu et al., 2021):

MAT(Sg(G), Sr(G)) =

1
|Sr|

(cid:88)

R(cid:48)∈Sr

min
R∈Sg

RMSD(R, R(cid:48)).

(17)
Generally, more realistic generated samples lead to a lower
MAT score.

Results. We calculate the COV and MAT evaluations on

both GEOM-QM9 and GEOM-Drugs datasets for all base-
lines, and summarize the results in Tab. 1. We visualize
several representative examples in Fig. 3. Our ConfVAE out-
performs all existing strong baselines with an obvious mar-
gin (top 5 rows). By incorporating an end-to-end training
objective via bilevel optimization, we consistently achieved
a better result on all four metrics. By contrast, current state-
of-the-art models GraphDG and CGCF suffer much worse
performance due to the two-stage generation process, where
the extra error caused by the distance geometry cannot be
taken into account during training. CVGAE enjoys the same
training and testing objective, but still shows inferior perfor-
mance since it fails to keep the vital translation and rotation
invariant property.

Similar to previous work (Mansimov et al., 2019; Xu et al.,
2021), we also further test all models by incorporating a rule-
based empirical force ﬁeld (Halgren, 1996b) and compare
the performance with the classic RDKit toolkit. Speciﬁcally,
we ﬁrst generate the conformations with the generative mod-
els as initial structures, and then utilize the force ﬁeld to
further optimize the generated structures. The additional
results are reported in Tab. 1 (bottom 6 rows). As shown
in the table, ConfVAE still achieves the best results among
all generative models. More importantly, our method out-
performs RDKit on 7 out of 8 evaluations and achieves
competitive results on the other one, making our method
the ﬁrst generative model that already practically useful for
real-world applications.

Ablation Study. So far we have demonstrated the supe-
rior performance of the proposed method. However, be-
cause we adopt a slightly different architecture, it remains
unclear where the effectiveness comes from. In this part,
we carefully conduct an ablation study by removing the
bilevel component deﬁned in equation 7 during training,
i.e., remove Lrecon and learn the model with only Laux and
Lprior. We denote this variant of ConfVAE as ConfVAE-.
and summarize the additional results in Tab. 1.

An End-to-End Framework for Molecular Conformation Generation via Bilevel Programming

Table 2. Comparison of different models on the distance distribu-
tion modeling task. We compare the marginals (p(duv|G)), pairs
(p(duv, dij|G)) and joint distribution (p(d|G)) of edges connect-
ing C and O atoms. We report the Median and Mean of the MMD
metric. Molecular graphs G are taken from the test set of ISO17.

Single

Pair
Mean Median Mean Median Mean Median

All

RDKit
CVGAE
GraphDG
CGCF

ConfVAE-
ConfVAE

3.4513
4.1789
0.7645
0.4490

0.2551
0.1809

3.1602
4.1762
0.2346
0.1786

0.1352
0.1153

3.8452
4.9184
0.8920
0.5509

0.2719
0.1946

3.6287
5.1856
0.3287
0.2734

0.1742
0.1455

4.0866
5.9747
1.1949
0.8703

0.2968
0.2113

3.7519
5.9928
0.5485
0.4447

0.2132
0.2047

As shown in the table, removing the bilevel component hurts
performance. These results verify that only learning from
distances will introduce an extra bias for the generated con-
formations, and our end-to-end method for directly learning
on the 3D structure helps to overcome this issue. Another
observation is that as a combination of ﬂow-based and VAE-
based model, ConfVAE- still achieves signiﬁcantly better re-
sults than the Flow-based CGCF and VAE-based GraphDG,
with exactly the same training and sampling process. This
result indicates that incorporating both global (z) and local
d(t0) latent variables will contribute to the generated con-
formations, which can help to capture both the global and
local geometric structure and atomic interactions.

4.3. Distance Distribution Modeling

Dataset. For the distances modeling task, we follow Simm
& Hern´andez-Lobato (2020); Xu et al. (2021) and use the
ISO17 dataset (Simm & Hern´andez-Lobato, 2020). ISO17
is constructed from the snapshots of ab initio molecular
dynamics simulations, where the coordinates are not just
equilibrium conformations but are samples that reﬂect the
underlying density around equilibrium states. We follow
previous work to split ISO17 into a training set with 167
molecules and a test set with the other 30 molecules.

Evaluation metrics. To obtain a distribution over distances
from a distribution over conformations, we sample a set
of conformations R and then calculate the corresponding
atomic lengths between C and O atoms (H atoms are usually
ignored). Let p(duv|G) denote the conditional distribution
of distances on each edge euv given a molecular graph G.
To evaluate the distance distributions, we use the maxi-
mum mean discrepancy (MMD) (Gretton et al., 2012) to the
ground-truth distributions. More speciﬁcally, we evaluate
against the ground truth the MMD of marginal distributions
of each individual edge’s distance p(duv|G), pairs of dis-
tances p(duv, dij|G) and the joint distance p(d|G). For this
benchmark, the size of the generated sample set is the same
as the reference set.

Results. The results of MMDs are summarized in Tab. 2.
The statistics show that the generated distance distribution
of ConfVAE is signiﬁcantly closer to the ground-truth dis-
tribution compared with the baseline models. These results
demonstrate that our method can not only generate realistic
conformations, but also model the density around equilib-
rium states. By contrast, though RDKit shows competi-
tive performance for conformation generation, it seems to
struggle with the distribution modeling benchmark. This
is because RDKit is only designed to ﬁnd the equilibrium
states by using the empirical force ﬁeld (Halgren, 1996a),
and thus it lacks the capacity to capture the underlying dis-
tribution. The further ablation study between ConfVAE
and ConfVAE- also veriﬁes the effectiveness of the bilevel
optimization components.

5. Related Work

In recent years, deep learning has shown signiﬁcant progress
for 3D structure generation. There have been works using
neural networks to derive energy prediction models, which
then are taken as faster alternatives to quantum mechanics-
based energy calculations (Sch¨utt et al., 2017; Smith et al.,
2017) for molecular dynamics simulation or molecule op-
timization (Wang et al., 2020). However, though acceler-
ated by neural networks, these approaches are still time-
consuming due to the lengthy sampling process. Recently,
(Gebauer et al., 2019) and (Hoffmann & No´e, 2019) provide
methods to generate new 3D molecules with deep genera-
tive models, while (Simm et al., 2020a) and (Simm et al.,
2020b) employ reinforcement learning to search the vast
geometric space. However, none of these methods is de-
signed to generate the conformations from the molecular
graph structure, making them orthogonal to our framework.
(Gogineni et al., 2020) proposes TorsionNet, which uses
RL for conformation search by determining torsional an-
gles, and takes a classical force ﬁeld for state transition
and reward evaluation. However, this model is speciﬁcally
designed for larger molecules, and incapable of modeling
other complex geometric structures such as bond angles and
lengths. Therefore, it is also not comparable in our setting.

Many other works (Lemke & Peter, 2019; AlQuraishi, 2019;
Ingraham et al., 2019; No´e et al., 2019) also learn to di-
rectly predict 3D structures, but focus on the protein folding
problem. Speciﬁcally, Senior et al. (2020b); Jumper et al.
(2020) signiﬁcantly advance this ﬁeld with an end-to-end
attention-based model called AlphaFold. Unfortunately, pro-
teins are amino-acid sequences with low chemical diversity,
much larger scale and for which abundant structural exists
while general molecules are highly structured graphs with a
variety of cycles and much broader chemical composition,
making it unclear whether these methods are transferable to
the general conformation generation task.

An End-to-End Framework for Molecular Conformation Generation via Bilevel Programming

6. Conclusion

In this paper, we propose ConfVAE, an end-to-end frame-
work for molecular conformation generation via bilevel pro-
gramming. Our generative model can overcome signiﬁcant
errors of previous two-stage models, thanks to the end-to-
end training based on bilevel programming, while keeping
the property of rotational and translational invariance. Ex-
perimental results demonstrate the superior performance
of our method over all state-of-the-art baselines on several
standard benchmarks. Future work includes combining our
bilevel optimization framework with other kinds of genera-
tive models, and extending our method to other challenging
structures such as proteins.

Acknowledgments

This project is supported by the Natural Sciences and Engi-
neering Research Council (NSERC) Discovery Grant, the
Canada CIFAR AI Chair Program, collaboration grants be-
tween Microsoft Research and Mila, Samsung Electronics
Co., Ldt., Amazon Faculty Research Award, Tencent AI
Lab Rhino-Bird Gift Fund and a NRC Collaborative R&D
Project (AI4D-CORE-06). This project was also partially
funded by IVADO Fundamental Research Project grant PRF-
2019-3583139727.

References

Alipanahi, B., Krislock, N., Ghodsi, A., Wolkowicz, H.,
Donaldson, L., and Li, M. Determining protein structures
from noesy distance constraints by semideﬁnite program-
ming. Journal of Computational Biology, 20(4):296–310,
2013.

AlQuraishi, M. End-to-end differentiable learning of protein

structure. Cell systems, 8(4):292–301, 2019.

Bennett, K. P., Hu, J., Ji, X., Kunapuli, G., and Pang, J.-S.
Model selection via bilevel optimization. In The 2006
IEEE International Joint Conference on Neural Network
Proceedings, pp. 1922–1929. IEEE, 2006.

Bottou, L. Large-scale machine learning with stochastic
gradient descent. In Proceedings of COMPSTAT’2010,
pp. 177–186. Springer, 2010.

Bruna, J., Zaremba, W., Szlam, A., and LeCun, Y. Spec-
tral networks and locally connected networks on graphs.
arXiv preprint arXiv:1312.6203, 2013.

Chen, R. T., Rubanova, Y., Bettencourt, J., and Duvenaud,
D. K. Neural ordinary differential equations. In Advances
in neural information processing systems, pp. 6571–6583,
2018.

Colson, B., Marcotte, P., and Savard, G. An overview of
bilevel optimization. Annals of operations research, 153
(1):235–256, 2007.

Crippen, G. M., Havel, T. F., et al. Distance geometry and
molecular conformation, volume 74. Research Studies
Press Taunton, 1988.

De Vivo, M., Masetti, M., Bottegoni, G., and Cavalli, A.
Role of molecular dynamics and related methods in drug
discovery. Journal of medicinal chemistry, 59(9):4035–
4061, 2016.

Domke, J. Generic methods for optimization-based model-
ing. In Artiﬁcial Intelligence and Statistics, pp. 318–326,
2012.

Duvenaud, D., Maclaurin, D., Aguilera-Iparraguirre, J.,
G´omez-Bombarelli, R., Hirzel, T., Aspuru-Guzik, A.,
and Adams, R. P. Convolutional networks on graphs
arXiv preprint
for learning molecular ﬁngerprints.
arXiv:1509.09292, 2015.

Anand, N. and Huang, P.-S. Generative modeling for pro-
tein structures. In Proceedings of the 32nd International
Conference on Neural Information Processing Systems,
pp. 7505–7516, 2018.

Flamary, R., Rakotomamonjy, A., and Gasso, G. Learning
constrained task similarities in graphregularized multi-
task learning. Regularization, Optimization, Kernels, and
Support Vector Machines, pp. 103, 2014.

Axelrod, S. and Gomez-Bombarelli, R. Geom: Energy-
annotated molecular conformations for property pre-
arXiv preprint
diction and molecular generation.
arXiv:2006.05531, 2020.

Ballard, A. J., Martiniani, S., Stevenson, J. D., Somani, S.,
and Wales, D. J. Exploiting the potential energy landscape
to sample free energy. Wiley Interdisciplinary Reviews:
Computational Molecular Science, 5(3):273–289, 2015.

Bengio, Y. Gradient-based optimization of hyperparameters.

Neural computation, 12(8):1889–1900, 2000.

Franceschi, L., Donini, M., Frasconi, P., and Pontil, M.
Forward and reverse gradient-based hyperparameter opti-
mization. arXiv preprint arXiv:1703.01785, 2017.

Franceschi, L., Frasconi, P., Salzo, S., Grazzi, R., and Pontil,
M. Bilevel programming for hyperparameter optimization
and meta-learning. arXiv preprint arXiv:1806.04910,
2018.

Gebauer, N., Gastegger, M., and Sch¨utt, K. Symmetry-
adapted generation of 3d point sets for the targeted dis-
covery of molecules. In Advances in Neural Information
Processing Systems, pp. 7566–7578, 2019.

An End-to-End Framework for Molecular Conformation Generation via Bilevel Programming

Gilmer, J., Schoenholz, S. S., Riley, P. F., Vinyals, O., and
Dahl, G. E. Neural message passing for quantum chem-
istry. arXiv preprint arXiv:1704.01212, 2017.

Kipf, T. N. and Welling, M. Semi-supervised classiﬁca-
tion with graph convolutional networks. arXiv preprint
arXiv:1609.02907, 2016.

Gogineni, T., Xu, Z., Punzalan, E., Jiang, R., Kammeraad,
J., Tewari, A., and Zimmerman, P. Torsionnet: A re-
inforcement learning approach to sequential conformer
search. arXiv preprint arXiv:2006.07078, 2020.

Lemke, T. and Peter, C. Encodermap: Dimensionality reduc-
tion and generation of molecule conformations. Journal
of chemical theory and computation, 15(2):1209–1215,
2019.

Gretton, A., Borgwardt, K. M., Rasch, M. J., Sch¨olkopf, B.,
and Smola, A. A kernel two-sample test. The Journal of
Machine Learning Research, 13(1):723–773, 2012.

Liberti, L., Lavor, C., Maculan, N., and Mucherino, A.
Euclidean distance geometry and applications. SIAM
review, 56(1):3–69, 2014.

Griewank, A. and Walther, A. Evaluating derivatives:
principles and techniques of algorithmic differentiation.
SIAM, 2008.

Halgren, T. A. Merck molecular force ﬁeld. i. basis, form,
scope, parameterization, and performance of mmff94.
Journal of computational chemistry, 17(5-6):490–519,
1996a.

Halgren, T. A. Merck molecular force ﬁeld. v. extension
of mmff94 using experimental data, additional computa-
tional data, and empirical rules. Journal of Computational
Chemistry, 17(5-6):616–641, 1996b.

Hawkins, P. C. Conformation generation: the state of the
art. Journal of Chemical Information and Modeling, 57
(8):1747–1756, 2017.

Hoffmann, M. and No´e, F. Generating valid euclidean dis-
tance matrices. arXiv preprint arXiv:1910.03131, 2019.

Hu, W., Liu, B., Gomes, J., Zitnik, M., Liang, P., Pande, V.,
and Leskovec, J. Strategies for pre-training graph neural
networks. arXiv preprint arXiv:1905.12265, 2019.

Ingraham, J., Riesselman, A. J., Sander, C., and Marks, D. S.
Learning protein structure with a differentiable simulator.
In International Conference on Learning Representations,
2019.

Jumper, J., Evans, R., Pritzel, A., Green, T., Figurnov, M.,
Tunyasuvunakool, K., Ronneberger, O., Bates, R., Zidek,
A., Bridgland, A., et al. High accuracy protein structure
prediction using deep learning. Fourteenth Critical As-
sessment of Techniques for Protein Structure Prediction
(Abstract Book), 22:24, 2020.

Kearnes, S., McCloskey, K., Berndl, M., Pande, V., and
Riley, P. Molecular graph convolutions: moving beyond
ﬁngerprints. Journal of computer-aided molecular design,
30(8):595–608, 2016.

Kingma, D. P. and Welling, M. Auto-encoding variational

bayes. arXiv preprint arXiv:1312.6114, 2013.

Maclaurin, D., Duvenaud, D., and Adams, R. Gradient-
based hyperparameter optimization through reversible
learning. In International Conference on Machine Learn-
ing, pp. 2113–2122, 2015.

Mansimov, E., Mahmood, O., Kang, S., and Cho, K. Molec-
ular geometry prediction using a deep generative graph
neural network. arXiv preprint arXiv:1904.00314, 2019.

Mu˜noz-Gonz´alez, L., Biggio, B., Demontis, A., Paudice,
A., Wongrassamee, V., Lupu, E. C., and Roli, F. Towards
poisoning of deep learning algorithms with back-gradient
optimization. In Proceedings of the 10th ACM Workshop
on Artiﬁcial Intelligence and Security, pp. 27–38, 2017.

No´e, F., Olsson, S., K¨ohler, J., and Wu, H. Boltzmann gener-
ators: Sampling equilibrium states of many-body systems
with deep learning. Science, 365(6457):eaaw1147, 2019.

Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J.,
Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga,
L., et al. Pytorch: An imperative style, high-performance
deep learning library. arXiv preprint arXiv:1912.01703,
2019.

Riniker, S. and Landrum, G. A. Better informed distance
geometry: using what we know to improve conforma-
tion generation. Journal of chemical information and
modeling, 55(12):2562–2574, 2015.

Scarselli, F., Gori, M., Tsoi, A. C., Hagenbuchner, M., and
Monfardini, G. The graph neural network model. IEEE
transactions on neural networks, 20(1):61–80, 2008.

Sch¨utt, K., Kindermans, P.-J., Felix, H. E. S., Chmiela, S.,
Tkatchenko, A., and M¨uller, K.-R. Schnet: A continuous-
ﬁlter convolutional neural network for modeling quantum
interactions. In Advances in neural information process-
ing systems, pp. 991–1001, 2017.

Senior, A. W., Evans, R., Jumper, J., Kirkpatrick, J., Sifre,
L., Green, T., Qin, C., ˇZ´ıdek, A., Nelson, A. W., Bridg-
land, A., et al.
Improved protein structure prediction
using potentials from deep learning. Nature, 577(7792):
706–710, 2020a.

An End-to-End Framework for Molecular Conformation Generation via Bilevel Programming

Senior, A. W., Evans, R., Jumper, J., Kirkpatrick, J., Sifre,
L., Green, T., Qin, C., ˇZ´ıdek, A., Nelson, A. W., Bridg-
land, A., et al.
Improved protein structure prediction
using potentials from deep learning. Nature, 577(7792):
706–710, 2020b.

Xu, M., Luo, S., Bengio, Y., Peng, J., and Tang, J. Learning
neural generative dynamics for molecular conformation
In International Conference on Learning
generation.
Representations, 2021. URL https://openreview.
net/forum?id=pAbm1qfheGk.

Shi, C., Xu, M., Guo, H., Zhang, M., and Tang, J. A
graph to graphs framework for retrosynthesis prediction.
In International Conference on Machine Learning, pp.
8818–8827. PMLR, 2020a.

You, J., Liu, B., Ying, Z., Pande, V., and Leskovec, J. Graph
convolutional policy network for goal-directed molecular
In Advances in neural information
graph generation.
processing systems, pp. 6410–6421, 2018.

Shi, C., Xu, M., Zhu, Z., Zhang, W., Zhang, M., and Tang,
J. Graphaf: a ﬂow-based autoregressive model for molec-
ular graph generation. arXiv preprint arXiv:2001.09382,
2020b.

Simm, G., Pinsler, R., and Hern´andez-Lobato, J. M. Rein-
forcement learning for molecular design guided by quan-
tum mechanics. In International Conference on Machine
Learning, pp. 8959–8969. PMLR, 2020a.

Simm, G. N. and Hern´andez-Lobato, J. M. A generative
model for molecular distance geometry. In International
Conference on Machine Learning, 2020.

Simm, G. N., Pinsler, R., Cs´anyi, G., and Hern´andez-Lobato,
J. M. Symmetry-aware actor-critic for 3d molecular de-
sign. arXiv preprint arXiv:2011.12747, 2020b.

Smith, D. G., Burns, L. A., Simmonett, A. C., Parrish,
R. M., Schieber, M. C., Galvelis, R., Kraus, P., Kruse,
H., Di Remigio, R., Alenaizan, A., et al. Psi4 1.4: Open-
source software for high-throughput quantum chemistry.
The Journal of chemical physics, 152(18):184108, 2020.

Smith, J. S., Isayev, O., and Roitberg, A. E. Ani-1: an
extensible neural network potential with dft accuracy at
force ﬁeld computational cost. Chemical science, 8(4):
3192–3203, 2017.

Chemical Communications,

Wang, W., Yang, T., Harris, W. H., Gomez-Bombarelli,
R., and G´omez-Bombarelli, R.
Active learning
and neural network potentials accelerate molec-
screening of ether-based solvate ionic liq-
ular
56(63):8920,
uids.
URL https://
aug 2020.
pubs.rsc.org/en/content/articlehtml/
2020/cc/d0cc03512bhttps://pubs.rsc.
org/en/content/articlelanding/2020/
cc/d0cc03512bhttp://pubs.rsc.org/
en/Content/ArticleLanding/2020/CC/
D0CC03512B.

ISSN 1359-7345.

Xu, K., Hu, W., Leskovec, J., and Jegelka, S. How
arXiv preprint

powerful are graph neural networks?
arXiv:1810.00826, 2018.

An End-to-End Framework for Molecular Conformation Generation via Bilevel Programming

A. Data Preprocess

Inspired by classic molecular distance geometry (Crippen
et al., 1988), in our framework we also generate the con-
ﬁrmations by taking the inter-atomic distances as the inter-
mediate variables, which enables the invariant property to
rotation and translation. In practice, the chemical bonds ex-
isting in the molecular graph are not sufﬁcient to determine
a conformation, and thus we follow existing works (Simm
& Hern´andez-Lobato, 2020; Xu et al., 2021) to ﬁrst expand
the graphs by extending auxiliary edges. Speciﬁcally, the
atoms that are 2 or 3 hops away are connected with virtual
bonds, labeled differently from the real bonds in the vanilla
molecule. These extra bonds contribute to reducing the de-
grees of freedom in the 3D coordinates and characterizing
the unique graph, with the edges between 2-hop neighbors
helping to ﬁx the angles between atoms, and those between
3-hop neighbors ﬁxing dihedral angles.

B. Training Algorithm

Algorithm 1 Training Algorithm of ConfVAE.
Input: objective reweighting coefﬁcients α and λ; the inner
loop optimization iterations T and learning rate η; alignment
function A(·, ·); data samples {Gt, R∗
Initial: prior pψ(z|G), decoder pθ(R|z, G) and its dynamics
deﬁned as gθ, encoder qφ(z|R, G)

t }.

while θ, φ, ψ have not converged do

{Reparameterization}

{Calculate d from R∗}
gθ(d∗(t), t, G, z)dt

−

q +(µq−µ)2
σ2
2σ2

µ, σ ← qφ(z|Gt, R∗
t )
z ← (cid:15) (cid:12) σ + µ
µq, σq ← pψ(z|Gt)
Lprior = 1
2 log σ
σq
d∗ ← R∗
t
θ (z, G) = d∗ + (cid:82) t0
0 = D−1
d∗
t1
(cid:16) ∂gθ
0) − (cid:82) t1
Laux = log p(d∗
dt
Tr
∂d(t)
Initialize R0, sample d(t0) ∼ N (0, I)
d = Dθ(z, G) = d(t0) + (cid:82) t1
t0
for t = 1, 2, · · · , T do

(cid:17)

t0

gθ(d(t), t, G, z)dt

Rt+1 = Rt − η∇H(Rt, d)

{Inner loop}

end for
R ← RT
Lrecon = − (cid:80)n
i=1
L = Lrecon + λLprior + αLaux
θ, φ, ψ ← Adam(L; θ, φ, ψ)

(cid:80)3

j=1 (Rij − A(R, R∗)ij)2

end while
return qφ, pθ, pψ

C. Additional Comparisons

C.1. Property Prediction

This task is ﬁrst proposed in Simm & Hern´andez-Lobato
(2020), which estimates the expected molecular properties
for molecular graphs by a set of generated conformations.
This task can further demonstrate the effectiveness and qual-
ity of generated samples, and is important for many real-
world applications such as drug and material design.

Dataset. Following Simm & Hern´andez-Lobato (2020),
we also employ the ISO17 dataset. More details about the
dataset can be found in Sec. 4.3.

Evaluation metrics. For comparison, we calculate the en-
semble properties of each molecular graph by averaging
over a set of generated conformations. Speciﬁcally, we cal-
culate the total electronic energy Eelec, the energy of HOMO
(cid:15)HOMO and the LUMO (cid:15)LUMO, and the dipole moment µ, us-
ing the quantum chemical calculation package Psi4 (Smith
et al., 2020). In practice, we generate 50 samples from dif-
ferent methods to estimate the property, and report median
error of averaged properties to measure the accuracy of pre-
dicted properties. Similar to Simm & Hern´andez-Lobato
(2020), we exclude CVGAE from this analysis due to its
poor generated quality.

Results. The results are shown in Tab. 3. As shown in the
table, ConfVAE outperforms all other generative models,
and shows competitive results compared with RDKit. Close
observation indicates that CGCF struggles with this task
since the generated conformations suffer a extremely high
variance. By contrast, our proposed method enjoys the
best performance thanks to the high quality of generated
samples.

Table 3. Median difference in averaged properties between ground-
truth and generated conformations from different methods. Unit:
Eelec(kJ/mol), (cid:15)HOMO(eV), (cid:15)LUMO(eV), µ(debye).

Eelec

(cid:15)HOMO

(cid:15)LUMO

µ

RDKit
GraphDG
CGCF
ConfVAE

42.7
58.0
208.2
40.2

0.08
0.10
0.80
0.10

0.15
0.09
1.11
0.08

0.29
0.33
0.46
0.29

C.2. More Results of Coverage Score

In this section, we give more results about Coverage score
with different thresholds δ. The details about the COV score
can be found in Sec. 4.2. Results are shown in Fig. 4. As
shown in the ﬁgure, ConfVAE consistently achieves better
performance than previous state-of-the-art models, which
demonstrates our proposed method is capable to generate

An End-to-End Framework for Molecular Conformation Generation via Bilevel Programming

Figure 4. Curves of the Coverage score with different thresholds δ on GEOM-QM9 (left two) and GEOM-Drugs (right two) datasets. The
ﬁrst and third curves evaluates the generated conformations from different generative models, while the other two are further optimized
with the empirical force ﬁeld.

Figure 5. Marginal distributions p(duv|G) of ground-truth and generated conformations from generative models. We study the edges
between C and O atoms, and omit the H atoms for clarity. In each subplot, the annotation (u − v) denotes the corresponding atoms
connected by the chemical bond duv.

more realistic samples.

C.3. Visualization of Distributions

In Fig. 5, we investigate the accuracy of generated confor-
mations by visualizing the marginal distributions p(duv|G)
for all pairwise distances between C and O atoms of a molec-
ular graph in the ISO17 test set. As shown in the ﬁgure,
though primarily designed for learning the 3D structures
via an end-to-end framework, our method can still make a
much better estimation of the distance distributions than the
state-of-the-art model for molecular geometry modeling. As
a representative element of the pairwise property between
atoms, the inter-atomic distances demonstrate the capacity
of our model to capture the inter-atomic interactions.

QM9QM9(+FF)DrugDrug(+FF)Coverage(%)RMSDRMSDRMSDRMSD023461578Ground-truthGraphDGCGCFConfVAE