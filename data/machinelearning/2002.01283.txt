0
2
0
2

b
e
F
4

]

M

I
.
h
p
-
o
r
t
s
a
[

1
v
3
8
2
1
0
.
2
0
0
2
:
v
i
X
r
a

CHIPP: INAF pilot project for HTC, HPC and HPDA

Giuliano Taﬀoni,1 Ugo Becciani,2 Bianca Garilli,3 Gianmarco Maggio,1
Fabio Pasian,1 Grazia Umana,2 Riccardo Smareglia,1 and Fabio Vitello2

1INAF - OATs, Trieste, Friuli Venezia Giulia, Italy; giuliano.taffoni@inaf.it

2INAF - OACt, Catania, Catania, Italy

3INAF - IASF, Milano, Milano, Italy

Abstract.
CHIPP (Computing HTC in INAF Pilot Project) is an Italian project
funded by the Italian Institute for Astrophysics (INAF) and promoted by the ICT oﬃce
of INAF. The main purpose of the CHIPP project is to coordinate the use of, and access
to, already existing high throughput computing and high–performance computing and
data processing resources (for small/medium size programs) for the INAF community.
Today, Tier–2/Tier–3 systems (1,200 CPU/core) are provided at the INAF institutes at
Trieste and Catania, but in the future, the project will evolve including also other com-
puting infrastructures. During the last two years more than 30 programs have been
approved for a total request of 30 Million CPU-h. Most of the programs are HPC,
data reduction and analysis, machine learning. In this poster, we describe in details the
CHIPP infrastructures and the results of the ﬁrst two years of activity.

1.

Introduction

Astronomy and Astrophysics (AA) is one of the research areas in Physics that needs
more and more high performing software and infrastructures, as the necessity for super-
computers arises both in the observational and theoretical realms of AA. The amount of
data produced by the upcoming generation of surveys and scientiﬁc instruments (e.g.
Square Kilometer Array, Cherenkov Telescope Array, Extremely Large Telescope E-
ELT, James Webb Space Telescope, Euclid satellite, and eROSITA All-Sky Survey),
needs more and more resources to be eﬃciently post-processed, analyzed and stored.
Moreover, numerical simulations, a theoretical counterpart capable of reproducing the
formation and evolution of the cosmic structures of our Universe, must reach both larger
volumes and higher resolutions to cope with a large amount of data of the upcoming
surveys.

In the last decade, the National Institute of Astrophysics in Italy (INAF) con-
tributed to a number of HPC and HTC projects (e.g. ExaNeSt (Katevenis et al. 2018;
Ammendola et al. 2017), EuroExa, EGI-Engage (Bertocco et al. 2018), EOSC-Pilot,
DHTCS-IT). Moreover, INAF recognized the importance to oﬀer computing facilities
of medium size to its user community and to invest in developing know-how in com-
puting and data analytic.

1

 
 
 
 
 
 
2

Taﬀonietal.

In this paper, we present the experiment to coordinate the use of, and access to,
high throughput computing (HTC) and high-performance computing (HPC) and data
processing resources.

2. Scope and objective of the project

CHIPP is a coordinated action supported by INAF and based on existing infrastructure
and beneﬁt of the know-how oﬀered by the involved centres. CHIPP main objectives
are:

• Investigate to what extent the Italian astronomical community is interested in

using a distributed computing infrastructure;

• Investigate whether the infrastructure meets the Astronomers requirements and

collect comment and suggestions to optimize it;

• Investigate the best approach to oﬀer the resources (e.g. periodic call, rolling

based, on-demand access)

• Implement eﬃcient user support and investigate which support level is required
(system management, support for software development, support for optimiza-
tion and debugging)

This project is the prototype and test case for the development of an extensive
distributed computing infrastructure for astronomers able to oﬀer multiple resources:
HPC, HTC, Cloud.

3. CHIPP computing resources

The CHIPP project beneﬁts of two computing centres located at INAF–OATs and
INAF–OACt.

The HOTCAT Cluster at INAF–OATs (Bertocco 2020) is an HPC infrastructure
with 1400 INTEL Haswell E5-4627v3 cores with 6GB RAM per Core (8.5TB RAM
total) and 500 TB parallel storage based on BeeGFS. The interconnect is Inﬁniband
ConnectX -3 Pro Dual QSFP+ 54Gbs. Beside the HPC cluster, INAF–OATs is also
providing an OpenStack based cloud stack with 200INTEL Westmere E5620 cores with
8GB RAM per Core and 75 TB Swift ObjectStorage.

INAF–OACt MUP cluster is a HTC infrastructure with 384 INTEL E5-2620V2
with 5.2GB RAM per Core (1TB RAM total) and 70 TB parallel storage (NFS). The
interconnect is a 10 Gbs Ethernet network.

All the computing infrastructures are equipped with more than 60 software envi-
ronment for Astronomical data reduction and analysis. They oﬀer tools for software
development, proﬁling and debugging.

4. CHIPP Implementation

CHIPP pilot is coordinating the services oﬀered by the two computing centres, and it
is verifying that the INAF community is proﬁting successfully of the computing re-
sources.

CHIPP:INAFpilotproject forHTC,HPCandHPDA

3

The computing centres provide the system support and the installation and main-
tenance of libraries and tools. During this ﬁrst implementation of the pilot project, the
computing centres are not providing any support to optimize and debug users codes.
Due to a large number of requests for this type of service, in the new implementation of
the project, we will extend our support towards software optimization and debugging.
CHIPP collects the requirements and suggestions from the users to improve the
platforms. Computing centres provide customized environments based on the collected
requirements.

The results of the four calls for proposals. For each call we present the
Table 1.
number of submitted proposals, the number of accepted proposals, the total amount
of core hours reserved for all the projects. We report also the completion rate, i.e the
percentage of core hours actually consumed.

I Call

II Call

III Call

IV call

Date
# of proposals
# of proposal accepted
Core hours allocated
Completion rate

15 May 2017
25
16
2.5x106
33%

15 Jan 2018
14
14
1.8x106
50%

30 July 2018
9
9
1.2x106
55%

30 May 2019
13
13
1.4x106
on-going

The main CHIPP activity is promoting periodic competitive calls for computing re-
sources, one every 6 months for large projects ( 80000 core hours) and rolling open calls
for small projects (<10000 core hours) of one month. Projects supported by CHIPP are
chosen based on innovation potential, scientiﬁc excellence and relevance criteria.

In Table 1, we show the results of the 4 call for proposals. The number of pro-
posals presented during the ﬁrst call was extremely high compared to the others; then
it is steadily around 10 to 15 proposals each call. According to our experience, that
corresponds to greater user awareness of what a computing resource can oﬀer in terms
of capabilities and environment.

During the project, we also modify the way a user can ask for computing re-
sources, thanks to the introduction of the rolling open calls. This kind of calls allows
astronomers with an un-planned need of computing resources to access to the infras-
tructure eﬃciently.

5. Conclusion and future activities

The INAF CHIPP pilot project is oﬀering a distributed computing and storage resources
to astronomers and projects on a call based approach.

CHIPP is a successful experiment that aims to help grow a community of experts
in numerical AA and consolidate know–how in usage, maintenance and support of
computing resources.

The use of distributed computing infrastructure instead of a single computing cen-
tre is an architectural choice, in line with the architecture of the European Open Science

4

Taﬀonietal.

Cloud. That allows us to experiment with the operations and services activities neces-
sary in more signiﬁcant projects as the SKA Regional Center networks.

The small or middle-sized resources oﬀered in CHIPP, are excellent for developing
and debugging codes, medium-size production activities, data analysis, and according
to our experience, they respond to a speciﬁc community requirement, not covered by
supercomputing centres. CHIPP resources can also be beneﬁcial for small (and large)
projects during their start-up when they need computing resources that are not oﬀered
by the project yet.

CHIPP is a successful experiment to deﬁne requirements, investigate the type of
use and necessities of a broad astronomical community. It is oﬀering support to as-
tronomers for the use of the resources and building science platforms based singularity
containers, Jupyter notebooks and/or remote desktop.

The experience gained during the project and the requisites collected are the foun-
dations for the design and development of an extensive distributed computing infras-
tructure for astronomy in Italy (Tier-1 like): the Data-Star project.

References

Ammendola, R., Biagioni, A., Cretaro, P., Frezza, O., Cicero, F. L., Lonardo, A., Martinelli, M.,
Paolucci, P. S., Pastorelli, E., Simula, F., Vicini, P., Taﬀoni, G., Pascual, J. A., Navaridas,
J., LujÃ ˛an, M., Goodacree, J., Chrysos, N., & Katevenis, M. 2017, in 2017 Euromicro
Conference on Digital System Design (DSD), 510

Bertocco, S. 2020, in ADASS XXIX, edited by R. Pizzo, E. Deul, J.-D. Mol, J. de Plaa, H. Verk-
outer, & R. Williams (San Francisco: ASP), vol. 524 of ASP Conf. Ser., 999 TBD
Bertocco, S., Dowler, P., Gaudet, S., Major, B., Pasian, F., & Taﬀoni, G. 2018, Astronomy and
Computing, 24, 36 . URL http://www.sciencedirect.com/science/article/
pii/S2213133718300428

Katevenis, M., Ammendola, R., Biagioni, A., & et. al 2018, Microprocessors and Microsystems,

61, 58

