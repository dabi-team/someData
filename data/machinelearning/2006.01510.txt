Recht–R´e Noncommutative Arithmetic-Geometric Mean Conjecture is False

Zehua Lai 1 Lek-Heng Lim 1

0
2
0
2

n
u
J

2

]

C
O
.
h
t
a
m

[

1
v
0
1
5
1
0
.
6
0
0
2
:
v
i
X
r
a

Abstract

Stochastic optimization algorithms have become
indispensable in modern machine learning. An
unresolved foundational question in this area is
the difference between with-replacement sam-
pling and without-replacement sampling — does
the latter have superior convergence rate com-
pared to the former? A groundbreaking re-
sult of Recht and R´e reduces the problem to
a noncommutative analogue of the arithmetic-
geometric mean inequality where n positive num-
bers are replaced by n positive deﬁnite matrices.
If this inequality holds for all n, then without-
replacement sampling indeed outperforms with-
replacement sampling. The conjectured Recht–
R´e inequality has so far only been established
for n = 2 and a special case of n = 3. We
will show that the Recht–R´e conjecture is false
for general n. Our approach relies on the non-
commutative Positivstellensatz, which allows us
to reduce the conjectured inequality to a semidef-
inite program and the validity of the conjecture
to certain bounds for the optimum values, which
we show are false as soon as n = 5.

1. Introduction

The breathtaking reach of deep learning, permeating ev-
ery area of science and technology, has led to an outsize
role for randomized optimization algorithms. It is probably
fair to say that in the absence of randomized algorithms,
deep learning would not have achieved its spectacular
level of success. Fitting an exceedingly high-dimensional
model with an exceedingly large training set would have
been prohibitively expensive without some form of ran-
dom sampling, which in addition provides other crucial
beneﬁts such as saddle-point avoidance (Fang et al., 2019;

*Equal contribution 1Computational and Applied Mathematics
Initiative, University of Chicago, Chicago, IL 60637, USA. Cor-
respondence to: Zehua Lai <laizehua@uchicago.edu>.

Proceedings of the 37 th International Conference on Machine
Learning, Vienna, Austria, PMLR 108, 2020. Copyright 2020 by
the author(s).

Jin et al., 2017). As such, in machine learning computa-
tions, stochastic variants of gradient descent (Bottou, 2010;
Johnson & Zhang, 2013; Nemirovski et al., 2008), alternat-
ing projections (Strohmer & Vershynin, 2009), coordinate
descent (Nesterov, 2012), and other algorithms have largely
overtaken their classical deterministic counterparts in rele-
vance and utility.

There are numerous random sampling strategies but the
most fundamental question, before all other considerations,
is deciding between sampling with replacement or sam-
pling without replacement. In the vast majority of random-
ized algorithms, a random sample is selected or a random
action is performed with replacement from a pool, making
the randomness in each iteration independent and thus eas-
ier (often much easier) to analyze. However, when it comes
to practical realizations of these algorithms, one invariably
sample without replacement, since they are easier (often
much easier) to implement. Take the ubiquitous stochas-
tic gradient descent for example, many if not most imple-
mentations would pass through each item exactly once in
a random order — this is sampling without replacement.
Likewise, in implementations of randomized coordinate de-
scent, coordinates are usually just chosen in a random order
— again sampling without replacement.

Apart from its ease of implementation, there are other rea-
sons for favoring without-replacement sampling. Empiri-
cal evidence (Bottou, 2009) suggests that in stochastic gra-
dient descent, without-replacement sampling regularly out-
performs with-replacement sampling. Theoretical results
also point towards without-replacement sampling: Under
standard convexity assumptions, the convergence rate of a
without-replacement sampling algorithm typically beats a
1/2) or
with-replacement sampling one by a factor of O(n−
1). This has been established for stochastic gradient
O(n−
descent (Shamir, 2016; Nagaraj et al., 2019) and for coor-
dinate descent (Beck & Tetruashvili, 2013; Wright, 2015).

Recht & Re (2012) proposed a matrix theoretic approach
to compare the efﬁcacy of with- and without-replacement
sampling methods. Since nearly every common optimiza-
tion algorithm, deterministic or randomized, works with a
linear or quadratic approximation of the objective function
locally, it sufﬁces to examine the two sampling strategies
on linear or quadratic functions to understand their local

 
 
 
 
 
 
Noncommutative Arithmetic-Geometric Mean Conjecture is False

convergence behaviors. In this case, the iteration reduces to
matrix multiplication and both sampling procedures are lin-
early convergent (often called “exponential convergence”
in machine learning). The question of which is better
then reduces to comparing their linear convergence rates.
In this context, Recht & Re (2012) showed that without-
replacement sampling outperforms with-replacement sam-
pling provided the following noncommutative version of
the arithmetic-geometric mean inequality holds.

Current status: Recht & Re (2012) applied results from
random matrix theory to show that Conjecture 1 holds with
high probability for (i) independent Wishart matrices, and
(ii) the incremental gradient method. To date, extensive
numerical simulations have produced no counterexample.
Conjecture 1 has been rigorously established only in very
special cases, notably for (m, n) = (2, 2) (Recht & Re,
2012) and (m, n) = (3, 3k) (Zhang, 2018).

k · k

1
nm

Conjecture 1 (Recht & Re 2012). Let n be a positive inte-
ger, A1, . . . , An be symmetric positive semideﬁnite matri-
ces, and

be the spectral norm. Then for any m

n,

≤

Aj1 · · ·

Ajm

≥

m)!

−
n!

n
≤
(n

Aj1 · · ·

(cid:13)
X1
j1,...,jm
(cid:13)
≤
(cid:13)
(cid:13)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
X1
n,
j1,...,jm
(cid:13)
≤
j1,...,jm distinct
(cid:13)
(cid:13)
While one may also ask if (1) holds for other norms, the
most natural and basic choice is the spectral norm, i.e., the
operator 2-norm. Unless speciﬁed otherwise,
will al-
ways denote the spectral norm in this article.

.
(cid:13)
(cid:13)
(cid:13)
(cid:13)

Ajm

k · k

(1)

≤

To give an inkling of how (1) arises, consider the Kacz-
marz algorithm (Strohmer & Vershynin, 2009) where we
attempt to solve an overdetermined linear system Cx = b,
Rd.
C
For k = 1, 2, . . . , the (k + 1)th iterate is formed with a
randomly chosen i and

d, p > d, with ith row vector1 cT

i where ci ∈

Rp

∈

×

x(k+1) = x(k) +

i

ci.

ci, x(k)
bi − h
2
cik
k
x∗ is then

The kth error e(k) = x(k)

×

(cid:19)

−

d,

e(k+1) =

I
(cid:18)
Rd

e(k) =: Pci e(k),

−
cicT
i
2
cik
k
the orthogonal projector onto
where Pc ∈
⊥, is clearly symmetric positive semideﬁnite. A
span
c
}
{
careful analysis would show that the relative efﬁcacy of
with- and without-replacement sampling depends on a mul-
A4 + B4 + AB2A + BA2B
titude of inequalities like
k ≥
AB2A + BA2B
, which are difﬁcult to analyze on a
2
k
case-by-case basis. Nevertheless, more general heuristics
(Recht & Re, 2012) would lead to (1) — if it holds, then
without-replacement sampling is expected to outperform
with-replacement sampling. In fact, the gap can be signif-
icant — for random Wishart matrices, Recht & Re (2012)
showed that the ratio between the two sides of (1) increases
exponentially with m.

k

k

Our contributions: We show how to transform Conjec-
ture 1 into a form where the noncommutative Positivstel-
lensatz applies, which implies in particular that for any spe-
ciﬁc values of m and n, the conjecture can be checked via
two semideﬁnite programs. This allows us to show in Sec-
tion 3 that the conjecture is false as soon as m = n = 5.
We also establish in Section 2 that the conjecture holds for
m = 2 and 3 with arbitrary n by extending the approach
in Zhang (2018). While the conjectured inequality (1) is
clearly sharp (as we may choose all Ai’s to be equal) when-
ever it is true, we show in Section 5 that the m = 2 case
may nonetheless be improved in a different sense, and we
do likewise for m = 3 in Section 2. The m = 4 case re-
mains open but our noncommutative Positivstellensatz ap-
proach permits us to at least check that it holds for n = 4
and 5 in Section 3.

Over the next two sections, we will transform Recht and
R´e’s Conjecture 1 into a “Loewner form” (Conjecture 1A),
a “sum-of-squares form” (Conjecture 1B), and ﬁnally a
“semideﬁnite program form” (Conjecture 1C). All four con-
jectures are equivalent but the correctness of the last one for
any m, n can be readily checked as a semideﬁnite program.

2. Recht–R´e inequality for m = 2 and 3

Our goal here is to establish (1) for a pair and a triple of
matrices. In so doing, we take Conjecture 1 a step closer
to a form where noncommutative Positivstellensatz applies.
There is independent value in establishing these two special
cases given that the classical noncommutative arithmetic-
geometric-harmonic mean inequality (Bhatia & Holbrook,
2006) is only known for a pair of matrices but nonetheless
attracted a lot of interests from linear algebraists. These
special cases also have implications on randomized algo-
rithms — take the Kaczmarz algorithm for example, the
fact that Conjecture 1 holds for m = 2 and 3 implies that if
we randomly choose two or three distinct samples, perform
the iterations, and sample again, then this “replacing after
every two or three samples” strategy will converge faster
than a “replacing after every sample” strategy.

1We adopt standard convention that any vector x ∈ R

column vector; a row vector will always be denoted xT.

d is a

We begin by providing some context for the inequality (1).
The usual arithmetic-geometric mean inequality for n non-

Noncommutative Arithmetic-Geometric Mean Conjecture is False

negative real numbers a1, . . . , an, i.e.,

(a1 +

· · ·

+ an)/n

(a1 · · ·

≥

an)1/n,

is a special case of Maclaurins inequality (Hardy et al.,
1988): If we deﬁne

sm :=

1
n
m

(cid:0)

(cid:1)
√s2 ≥ · · · ≥

n

≤

<jm

X1
j1<
···
≤
n√sn. So s1 ≥

aj1 · · ·

ajm,

m√sm gives us

+ an)m

≥

· · ·

(n

−
n!

m)!

aj1 · · ·

ajm,

X1
n,
j1,...,jm
≤
j1,...,jm distinct

≤

then s1 ≥
1
nm (a1 +

which is just (1) for 1-by-1 positive semideﬁnite matrices.

For real symmetric or complex Hermitian matrices A, B,
the Loewner order is deﬁned by A
B is positive
semideﬁnite. The Maclaurins inequality has several non-
commutative extensions but we regard the following as the
starting point for all noncommutative arithmetic-geometric
mean inequalities.

B iff A

(cid:23)

−

Proposition 1. For any unitary invariant norm
Hermitian matrices A, B,
2

(A + B)2

AB + BA

AB + BA

k ≤ k

k · k
A2 + B2
k

k

.

and
and

k

k ≤ k

k

A2

A2 + B2, by
Proof. Since
Lemma 2.1 in Bhatia & Kittaneh (2008), the desired in-
equalities hold for any unitary invariant norm.

AB + BA

B2

−

(cid:22)

−

(cid:22)

k

The result was extended to compact operators on a separa-
ble Hilbert space and strengthened to 2
A∗A +
in Bhatia & Kittaneh (1990), with yet other exten-
B∗B
In Recht & Re
sions in Bhatia & Kittaneh (2008; 2000).
(2012), Conjecture 1 was also formulated as an extension
of Proposition 1, with the second inequality corresponding
to the m = n = 2 case.

k ≤ k

A∗B

k

Straightforward counterexamples for n = 3 show that we
cannot simply drop the norm in (1) and replace the inequal-
ity
. Nevertheless Conjecture 1
(cid:23)
may be written as two Loewner inequalities, as demon-
strated by Zhang (2018).

with the Loewner order

≥

Conjecture 1A (Loewner form). Let A1, . . . , An be sym-
metric positive semideﬁnite and A1 +
nI. Then
for any m

+ An (cid:22)

· · ·

n,

≤

n!

−

(n

m)!

−

I

(cid:22)

Aj1 · · ·

X1
n,
j1,...,jm
≤
j1,...,jm distinct

≤

Ajm (cid:22)

(n

n!

m)!

−

I. (2)

We prefer this equivalent formulation (2) as the original for-
mulation (1) hides an asymmetry — note that there is an

upper bound and a lower bound in (2) and there is no rea-
son to expect that they should have the same magnitude.
In fact, as we will see in the later sections, the upper and
lower bounds have different magnitudes in every case that
we examined.

We will next prove Conjecture 1 in its equivalent form Con-
jecture 1A for m = 2 and 3. Our proofs rely on techniques
introduced by Zhang (2018) in his proof for the case m = 3,
n = 3k, but our two additional contributions are that (i) we
will obtain better lower bounds (deferred to Section 5), and
(ii) our proof will work for arbitrary n (not necessarily a
multiple of 3).

Theorem 1 (Recht–R´e for m = 2). Let A1, . . . , An be
symmetric positive semideﬁnite and A1 +
nI.
Then

+ An (cid:22)

· · ·

n(n

1)I

−

(cid:22)

−

=j
Xi

AiAj (cid:22)

n(n

−

1)I.

(3)

Proof. The right inequality in (3) follows from

(n

1)

−

i,j
X

AiAj −

n

AiAj

=j
Xi

= (n

1)

−

i
X

and so

A2

i −

AiAj =

=j
Xi

i<j
X

(Ai −

Aj)2

0,

(cid:23)

AiAj (cid:22)

n

1

−
n

=j
Xi

i,j
X

AiAj (cid:22)

n(n

−

1)I.

For the left inequality in (3), expand (

i Ai)2

(cid:23)

0 to get

A2

i (cid:23) −

P
AiAj.

=j
Xi

i
X
i Ai (cid:23)

0 and Bi := Ai + 1

n B

0. So

(cid:23)

Let B := nI

−

i Bi = nI. Then
P

P

n

−

=j
Xi

AiAj =

(n

−

−

1)

AiAj −

AiAj

=j
Xi
AiAj

Bj)2

=j
Xi

(Bi −

i<j
X

BiBj

=j
Xi
A2

i −

Aj)2 =

(n

(cid:22)

=

1)

−

i
X
(Ai −

i<j
X
= (n

1)

−

B2

i −

i
X

B2

i −

B2

i −

=j
Xi
2
Bi

i
(cid:16)X
n2I.

(cid:17)

= n

= n

i
X

i
X

6
6
6
6
6
6
6
6
6
6
Noncommutative Arithmetic-Geometric Mean Conjecture is False

nBi).

(cid:22)

l)

Ei1,...,il

c(Ai1 +

+ Ail ) + dI

· · ·

(cid:2)

e
I,

(cid:3)

1
l2(n

−
cl + d

(cid:22)

l2(n

l)

−

Therefore

−

AiAj −

(n

−

1)nI

(cid:22)

n2I =

B2

i −

(B2

i −

=j
Xi

i
X
The eigenvalues of Bi fall between 0 and n, so the eigen-
values of B2
0.
Hence

nBi are all nonpositive, i.e., B2
1)nI

nBi (cid:22)

i
X

i −

(n

0.

i −
=j AiAj −
i

−

−

(cid:22)

P

1)/4.

The right inequality of (3) is clearly sharp. In Section 5, we
will prove a stronger result, improving the constant in the
left inequality of (3) to n(n

−
Following Zhang (2018), we write Ei1,...,ik for expectation
or average over all indices 1
Ei1,...,ik
≤
for that over distinct indices 1
Theorem 2 (Recht–R´e for m = 3). Let A1, . . . , An be
symmetric positive semideﬁnite and A1 +
nI.
Then

i1, . . . , ik ≤
≤

e
+ An (cid:22)

i1, . . . , ik ≤

n, and
n.

· · ·

I

−

(cid:22)

Ei,j,kAiAjAk (cid:22)
e

I.

(4)

Proof. Let A, B, C be positive semideﬁnite. Then ABC +
CBA

ABA + CBC. If B

C, then ABA

ACA.

(cid:22)

(cid:22)

(cid:22)

We start with the right inequality of (4),

Ei,j,kAiAj Ak =

e

(cid:22)
=

1
2
1
2
Ei,j,kAiAjAi.

e

Ei,j,k(AiAj Ak + AkAj Ai)

Ei,j,k(AiAj Ai + AkAjAk)
e

Fix a positive integer l < n whose value we decide later.

e

where the ﬁrst inequality follows from the fact that it holds
for each eigenvalue. Note that if we choose A1 =
=
An = I, all inequalities above as well as the right inequal-
ity of (4) hold with equality. So as long as 1/2
2/3, l, c, d will give us

l/n

· · ·

≤

≤

1
l2(n

−

l)

(cl + d) = 1

and thus the right inequality of (4).

For the left inequality of (4), we start by noting

(A1 +

+ An

−

· · ·

1)An(A1 +

· · ·

Taking expectation, we have
Ei,j,kAiAj Ai and thus

(n

−

−

+ An

1)

0.

2)

−

(cid:23)
Ei,j,kAiAjAk (cid:22)
e

e
−

Ei,j,kAiAjAk

e

=

−

(cid:22)

n

n
n
1

−
−

1
−
1

(cid:22)

2(n

−

2
Ei,j,kAiAjAk −
1
e
Ei,j,k(AiAjAi −
e
(Ai −
1)
(cid:2)

Ei,j,k

Ei,j,kAiAjAk

1

n

1

−
e
AiAj Ak)

Aj)Ak(Ai −

Aj)

.

e
As in the proof of Theorem 1, set B := nI
and Bi := Ai + 1

0. Then

n B

(cid:23)

(cid:3)
i Ai (cid:23)

0

−

P

Ei,j,kAiAj Ak (cid:22)
=
e

Ei,j,k

1
l

1

−

AiAj Ak +

1
l

AiAjAi

−

Ei,j,kAiAjAk
1

(cid:17)

Ei1,...,in

(Ai1 +

· · ·
+ Ain )(Ai1 +

(cid:2)

i

+ Ail )

e

(cid:22)

=

.

2(n
1

n

h(cid:16)

1
e
l2(n
l)
−
(Ail+1 +
e
· · ·
nI

·

+ Ain (cid:22)
1
l2(n
(Ai1 +

−

+ Ail )

· · ·
+ Ail ),

(cid:3)

Since Ail+1 +

· · ·

(Ai1 +

−

· · ·

Ei,j,kAiAj Ak (cid:22)
e

nI

·

−

Ei1,...,il

l)
+ Ail )
e

(Ai1 +

+ Ail )

· · ·

(cid:2)
(Ai1 +

+ Ail )

.

· · ·

· · ·

(cid:3)

(cid:0)

≤

cx + d for 0

(cid:1)
Consider the function f (x) = x2(n
x). Let the line y =
−
cx + d be tangent to f at x = l. We require that c
0
n. Elementary calculation
and f (x)
2/3.
shows that such a line exists as long as 1/2
Let A = Ai1 +
A)A
are simultaneous diagonalizable, each eigenvalue of cA +
A)A can be obtained by applying the function
A(nI
dI
x) to an eigenvalue of A. Hence
g(x) = cx + d

l/n
+ Ail . As cA + dI and A(nI

x2(n

≤
−

· · ·

≤

−

−

≤

≤

≥

x

−
Ei,j,kAiAj Ak

−

Bj)Bk(Bi −

Bj)

e

1)

Ei,j,k

(Bi −
−
(cid:2)
Ei,j,kBiBjBi −
−
e
Bi)Bi and Yi := (nI
−

n

1

1

(cid:3)

Ei,j,kBiBjBk.

1

e
Bi)Bi(nI

Bi).

−

−

−
Let Xi := Bi(nI
Routine calculations give

EiXi = (n

EiYi = (n
e

e

1)

Ei,j,kBiBjBi,

−

−

1)

Ei,j,kBiBjBi
e
+ (n
e

1)(n

−

−

2)

Ei,j,kBiBjBk,

to
allows
which
Ei,j,kBiBjBk in terms of

us

express
EiXi and

Ei,j,kBiBjBi
e
EiYi. Then

and

Ei,j,kAiAjAk

e

e
−

e

(cid:22)

n

1

−

1

Ei,j,kBiBjBi −
1
e
Ei[(n
1)2(n

2)

−

=

(n

−

e

e
1

Ei,j,kBiBjBk

n

−

1
−
e
1)Xi −

Yi]

e

e

6
6
Noncommutative Arithmetic-Geometric Mean Conjecture is False

=

(n

−
n)(x

n
1)2(n

−

Ei[

Bi(Bi −

nI)(Bi −

−

2)

I)].

1)

As

x(x

−

−

−

≤
Ei,j,kAiAjAk (cid:22)
e
When n

3, we have n/

−

≥

1)2x/4 for 0

EiBi =

(n

e
−
n

4(n

2)

−

≤

x

n

≤

n,

I.

4(n

2)

−

e
2)

4(n

−

1.

≤

(cid:0)

(cid:1)

Our proof in fact shows that the constant in the left inequal-
ity of (4) can be improved to n/
. Nevertheless,
we will see in the next section (Table 1) that this is not
sharp.

4(n

2)

−

(cid:0)

(cid:1)

3. Noncommutative Positivstellensatz

In a seminal paper (Helton, 2002), Helton proved an as-
tounding result: Every positive polynomial in noncommu-
tative variables can be written as a sum of squares of poly-
nomials. The corresponding statement for usual polynomi-
als, i.e., in commutative variables, is well-known to be false
and is the subject of Hilbert’s 17th Problem. Subsequent
developments ultimately led to a noncommutative version
of the Positivstellensatz for semialgebraic sets. We refer
interested readers to Pascoe (2018) for an overview of this
topic.

Stating noncommutative Positivstellensatz will require that
we introduce some terminologies. Let X1, . . . , Xn be n
= XjXi whenever
noncommutative variables, i.e., XiXj 6
= j. A monomial of degree d or a word of length d is an
i
Xid . The monomials span
expression of the form Xi1 · · ·
a real inﬁnite-dimensional vector space R
,
X1, . . . , Xni
h
called the space of noncommutative polynomials. For
N, the ﬁnite-dimensional subspace of noncom-
any d
d will be denoted
mutative polynomials of degree
≤
X1, . . . , Xnid. The transpose of f
X1, . . . , Xni
R
∈
h
h
is denoted f T and is deﬁned on monomials by reversing
Xid )T = Xid · · ·
Xi1 and ex-
the order of variables (Xi1 · · ·
. If f T = f , then f
tended linearly to all of R
is called symmetric.

X1, . . . , Xni
h

R

∈

The bottom line is that noncommutative polynomials may
be evaluated on square matrices of the same dimensions,
i.e., they deﬁne matrix-valued functions of matrix variables.
For our purpose, if A1, . . . , An are real symmetric matrices,
then f (A1, . . . , An) is also a matrix, but it may not be a
symmetric matrix unless f is a symmetric polynomial.

Let L =
X1, . . . , Xni1 be a set of k
ℓ1, . . . , ℓk} ⊆
R
h
linear polynomials, i.e., d = 1. We will refer to ℓ1, . . . , ℓk
as linear constraints and

{

BL :=

{

(A1, . . . , An)

|

ℓ1(A1, . . . , An)

0, . . . ,

(cid:23)

ℓk(A1, . . . , An)

0

}

(cid:23)

as the feasible set. Note that elements of
ples of symmetric matrices. We say that
there exists r > 0 such that all (A1, . . . , An)
A1k ≤

Ank ≤

r. Let d

r, . . . ,

k

k

N. We write

BL are n tu-
BL is bounded if
∈ BL satisfy

∈
fij ∈

R

X1, . . . , Xnid,
h
k, p1, . . . , pk ∈

N

k

pi

Σd(L) :=

f T
ijℓifij

(cid:26)

i=1
X

j=1
X

(cid:12)
(cid:12)
(cid:12)
for the set of noncommutative sum-of-squares generated
(cid:12)
by L. The following theorem is a simpliﬁed version of
the noncommutative Positivstellensatz, i.e., Theorem 1.1 in
Helton et al. (2012), that will be enough for our purpose.

(cid:27)

Theorem 3 (Noncommutative Positivstellensatz). Let f be
2d + 1 and the
a symmetric polynomial with deg(f )
BL be bounded with nonempty interior. Then
feasible set
0 for all (A1, . . . , An)

f (A1, . . . , An)

≤

∈ BL

if and only if f

∈

(cid:23)
Σd(L).

Readers familiar with the commutative Positivstellsatz
(Lasserre, 2015) would see that the noncommutative ver-
sion is, surprisingly, much simpler and neater.

To avoid notational clutter, we introduce the shorthand

:=

=jk
Xji

X1
n,
j1,...,jm
≤
j1,...,jm distinct

≤

for sum over distinct indices. Applying Theorem 3 with
linear constraints X1 (cid:23)
+ Xn (cid:22)
0, . . . , Xn (cid:23)
nI, Conjecture 1A becomes the following.
Conjecture 1B (Sum-of-squares form). Let m
N and d =
⌊
X1, . . . , ℓn = Xn, ℓn+1 = n

∈
. For the linear constraints ℓ1 =

0, X1 +

Xn, let

m/2

· · ·

≤

n

⌋

X1 − · · · −

−

,
(cid:27)

λ1 = argmin

λ

R

λ

∈

−

Xj1 · · ·

Xjm ∈

Σd(L)

λ

∈

R

(cid:26)

(cid:26)

λ +

m)!.

.
(cid:27)

n!/(n

=jk
Xji

=jk
Xji

Σd(L)

Xjm ∈

Xj1 · · ·

λ2 = argmin

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
Then both λ1 and λ2 ≤
In polynomial optimization (Lasserre, 2015), the commuta-
tive Positivstellsatz is used to transform a constrained opti-
mization problem into a sum-of-squares problem that can
in turn be transformed into a semideﬁnite programming
(SDP) problem. Helton (2002) has observed that this also
applies to noncommutative polynomial optimization prob-
lems, i.e., we may further transform Conjecture 1B into an
SDP form.

−

The vector space R
1 + n + n2 +
als of degree

X1, . . . , Xnid has dimension q :=
h
+ nd and a basis comprising all q monomi-
d. We will assemble all basis elements into

· · ·
≤

6
6
6
6
Noncommutative Arithmetic-Geometric Mean Conjecture is False

a q-tuple of monomials that we denote by β. With respect
X1, . . . , Xnid may be represented
to this basis, any f
h
Rq. Therefore a non-
uniquely as f = βTu for some u
commutative square may be expressed as

R

∈

∈

p

p

p

f T
j ℓfj =

jβℓβTuj = tr
uT

βℓβT

ujuT
j

(cid:18)

j=1
X

j=1
X

(cid:20)
j=1
X
Rq, j = 1, . . . , p.
by simply writing fj = βTuj, uj ∈
Since a symmetric matrix Y is positive semideﬁnite iff it
j, we obtain the follow-
can be written as Y =
ing one-to-one correspondence between noncommutative
squares and positive semideﬁnite matrices:

p
j=1 ujuT

(cid:19)(cid:21)

P

p

j=1
X

f T
j ℓfj ∈

R

X1, . . . , Xni2d+1, fj ∈
h

R

X1, . . . , Xnid
h

p

j=1
X

ujuT

j ∈

~
Rq
×
w
(cid:127)

q, uj ∈

Rq.

With this correspondence, the two minimization problems
in Conjecture 1B become two SDPs.

N and d =

Conjecture 1C (Semideﬁnite program form). Let m
n
∈
⌊
X1, . . . , Xnid and let Xn+1 = n
R
−
h
λ1 be the minimum value of the SDP:

≤
. Let β be a monomial basis of
Xn. Let

X1 − · · · −

m/2

⌋

minimize
subject to

λ
λ

Xjm =

Xj1 · · ·
=jk
Xji
0, . . . , Yn+1 (cid:23)

−
Y1 (cid:23)

0;

and λ2 be that of the SDP:

minimize

λ

subject to

λ +

Xjm =

Xj1 · · ·
=jk
Xji
0, . . . , Yn+1 (cid:23)
n!/(n

0.

Y1 (cid:23)

n+1

i=1
X

n+1

i=1
X

tr(βXiβTYi),

(5)

tr(βXiβTYi),

(6)

−

m)!.

Then both λ1 and λ2 ≤
Note that the minimization is over the scalar variable λ
and the matrix variables Y1, . . . , Yn+1; the equality con-
straint equating two noncommutative polynomials is sim-
ply saying that the coefﬁcients on both sides are equal, i.e.,
for each monomial, we get a linear constraint involving
λ, Y1, . . . , Yn+1 — the Xi’s play no role other than to serve
as placeholders for these linear constraints. We may ex-
press (5) and (6) as SDPs in standard form with a single
matrix variable Y := diag(λ, Y1, . . . , Yn+1), see (7) for
example.

Readers acquainted with (commutative) polynomial opti-
mization (Lasserre, 2015) would be familiar with the above

m = 2, n = 2
m = 2, n = 3
m = 2, n = 4
m = 2, n = 5
m = 3, n = 3
m = 3, n = 4
m = 3, n = 5
m = 4, n = 4
m = 4, n = 5
m = 5, n = 5

m)!

λ1
2.0000
6.0000
12.0000
20.0000
6.0000
24.0000
60.0000
24.0000
120.0000
120.0000

λ2
0.5000
1.5000
3.0000
5.0000
3.4113
8.5367
17.3611
22.4746
80.2349
144.6488

n!/(n
−
2
6
12
20
6
24
60
24
120
120

Table1. Results from the SDPs in Conjecture 1C for m ≤ n ≤ 5.
The bold entry for λ2 shows that the Recht–R´e conjecture is false
for m = n = 5 since 144.6488 > 120.

discussions. In fact, the only difference between the com-
d
i=0 ni, the
mutative and noncommutative cases is that
size of a noncommutative monomial basis, is much larger
than

, the size of a commutative monomial basis.

P

d+n
d

(cid:1)

(cid:0)

For any ﬁxed values of m and n, Conjecture 1C is in a form
that can be checked by standard SDP solvers. The dimen-
sion of the SDP grows exponentially with m, and without
access to signiﬁcant computing resources, only small val-
ues of m, n are within reach. Fortuitously, m = n = 5 al-
ready yields the required violation 144.6488 (cid:2) 120, show-
ing that Conjecture 1C and thus Conjecture 1 is false in
5 in Table 1.
general. We tabulate our results for m

n

≤

≤

The fact that the SDP in (6) for m = n = 5 has a minimum
λ2 > 144 > 120 = 5! shows that there are uncountably
many instances with A1 (cid:23)
0,
0, A4 (cid:23)
5I such that the
A5 (cid:23)
matrix

0, and A1 + A2 + A3 + A4 + A5 (cid:22)

0, A2 (cid:23)

0, A3 (cid:23)

Aσ(1)Aσ(2)Aσ(3)Aσ(4)Aσ(5)

S5
Xσ
∈

has an eigenvalue that is less than
5!.
Here Sn is the symmetric group on n elements. We em-
phasize that neither (6) nor its dual would give us ﬁve such
matrices explicitly, although the dual does provide another
way to verify our result, as we will see in Section 4.

144 <

120 =

−

−

−

Indeed, the beauty of the noncommutative Positivstellen-
satz approach is that it allows us to show that Conjecture 1
is false for m = n = 5 without actually having to produce
ﬁve positive semideﬁnite matrices A1, . . . , A5 that violates
the inequality (1). It would be difﬁcult to ﬁnd A1, . . . , A5
explicitly as one does not even know the smallest dimen-
sions required for these matrices to give a counterexample
to (1). Our approach essentially circumvents the issue by
replacing them with noncommutative variables X1, . . . , X5
— the reader may have observed that the dimensions of the
matrices A1, . . . , A5 did not make an appearance anywhere
in this article.

6
6
Noncommutative Arithmetic-Geometric Mean Conjecture is False

×
minimize
subject to

4. Veriﬁcation via Farkas

We take a closer look at the m = n = 5 case that provided
a refutation to the Recht–R´e conjecture. In this case, the
basis β has 1 + 5 + 52 = 31 monomials; the SDP in (6)
has 1 + 5 + 52 + 53 + 54 + 55 = 3906 linear constraints,
312
6 + 1 = 5767 variables, and takes the form:

While this is a consequence of Farkas Lemma for SDP
(Lasserre, 1995), all we need is the following trivial ver-
sion.

Lemma 1. Let m, n
b

Rm+1. If there exists a y

N. Let C0, C1, . . . , Cm ∈
Rm+1 with

∈

Sn and

∈

∈

y0C0 +

+ ymCm (cid:22)

0,

· · ·

bTy > 0,

tr(C0Y )
tr(CiY ) = bi,
Y = diag(λ, Y1, . . . , Y6)

i = 1, . . . , 3906,

then there does not exist a Y

(7)

Sn with

∈

0.

(cid:23)

tr(C0Y ) = b0, . . . , tr(CmY ) = bm,

Y

0.

(cid:23)

∈

R3096, λ is a scalar
S187
++ , b
Here C0, C1, . . . , C3906 ∈
variable, and Y1, . . . , Y6 are 31-by-31 symmetric matrix
variables. To put (7) into standard form, the block diago-
nal structure of Y may be further encoded as linear con-
straints requiring that off-diagonal blocks be zero. The out-
put of our program gives a minimizer of the form Y ∗ =
S187
++ with
diag(λ∗, Y ∗1 , . . . , Y ∗6 )

∈

Proof. If such a Y exists, then

tr

(y0C0 +

0

≥

· · ·

(cid:0)
a contradiction.

+ymCm)Y

= y0b0+

+ymbm > 0,

· · ·

(cid:1)

Hence a matrix of the form

λ∗ = 144.6488, Y ∗1 , . . . , Y ∗6 ∈

S31
++.

(8)

Y = diag(120, Y1, . . . , Y6)

S187

∈

The actual numerical entries of the matrices appearing in
(7) and (8) are omitted due to space constraints; but they
can be found in the output of our program (code in supple-
ment).

The values in (8) are of course approximate because of the
inherent errors in numerical computations. In our opinion,
the gap between the computed 144.6488 and the conjec-
tured 120 is large enough to override any concerns of a
mistaken conclusion resulting from numerical errors. Nev-
ertheless, to put to rest any lingering doubts, we will di-
rectly show that the conjectured value λ = 120 is infeasible
by producing a Farkas certiﬁcate. Consider the feasibility
problem:

minimize
subject to

0
tr(CiY ) = bi,
tr(C0Y ) = 120,
Y

0,

(cid:23)

i = 1, . . . , 3906,

(9)

S187
++ and b

R3096 as in (7).
with C0, C1, . . . , C3906 ∈
∈
Note that C0 = e1eT
1 is the matrix with one in the (1, 1)th
entry and zero everywhere else. So (9) is the feasibility
problem of the optimization problem (7) with the additional
linear constraint y11 = 120 and where we have disregarded
the block diagonal constraints2 on Y . The dual of (9) is

maximize
subject to

120y0 + bTy
y0C0 + y1C1 +

+ y3906C3906 (cid:22)

0.

· · ·

Our program produces a Farkas certiﬁcate y
120y0 + bTy

R3096 with
47.3 > 0, implying that (9) is infeasible.

∈

≈

2If (9) is already infeasible, then adding these block diagonal

constraints just makes it even more infeasible.

is infeasible for (7), providing another refutation of Con-
jecture 1C and thus Conjecture 1. In particular, showing
that λ = 120 is infeasible for (7) does not require any of
the values computed in (8). Of course, aside from being
the conjectured value of λ2, there is nothing special about
λ = 120 — for any λ < 144.6488, we may similarly com-
pute a Farkas certiﬁcate y to show that such a value of λ is
infeasible for (7).

We conclude with a few words on the computational costs
of the SDPs in this and the last section. Our resulting dense
linear system for m = n = 5 requires 3906
22
million ﬂoating point storage. Using a personal computer
with an Intel Core i7-9700k processor and 16GB of RAM,
our SeDuMi (Sturm, 1999) program in Matlab takes 150
seconds. For m = n = 6, storage alone would have taken
26 billion ﬂoating numbers, beyond our modest computing
resources.

5767

≈

×

5. Improving the Recht–R´e inequality

An unexpected beneﬁt of the noncommutative Positivstel-
lensatz approach is that it leads to better bounds for the
m = 2 and 3 cases that we know are true. Observe that the
values for λ2 in Table 1 for m = 2 are exactly smaller than
the values for n!/(n
m)! by a factor of 1/4. This suggests
that the Recht–R´e inequality (3) for m = 2 in Theorem 1
may be improved to

−

1
4

−

n(n

1)I

−

(cid:22)

AiAj (cid:22)

n(n

1)I.

−

=j
Xi
Table 1 only shows this for n = 2, 3, 4, 5 but in this section,
2. Although our
we will give a proof for arbitrary n

≥

6
Noncommutative Arithmetic-Geometric Mean Conjecture is False

proof below does not depend on the SDP formulation in (6),
the correct coefﬁcients in (11) for arbitrary n would have
been impossible to guess without solving (6) for m = 2
and some small values of n.

So far we have not explored the symmetry evident in our
formulations of the Recht–R´e inequality: In Conjecture 1A,
the matrix expression

λI

±

Aj1 · · ·

Ajm

=jk
Xji
0, . . . , An (cid:23)

and the constraints A1 (cid:23)
+ An (cid:22)
· · ·
Sn. In
nI are clearly invariant under any permutation σ
∈
Conjecture 1C, the noncommutative sum-of-squares

0, A1 +

λ

±

Xj1 · · ·

n+1

Xjm =

tr(βXiβTYi),

(10)

−

=jk
Xji

X1 − · · · −

i=1
X
Xn, is also invariant under
where Xn+1 = n
Sn and so we may average over all permutations to get a
symmetrized sum-of-squares. For commutative polynomi-
als, results from classical invariant theory are often used to
take advantage of symmetry (Gatermann & Parrilo, 2004).
We will see next that such symmetry may also be exploited
for noncommutative polynomials.

Consider the case m = 2, n = 3. The monomial basis
X1, X2, X3i1 is β = (1, X1, X2, X3). The sym-
of R
h
metry imposes linear constraints on the matrix variables
Y1, Y2, Y3, Y4 in (6), requiring them to take the following
forms:

a b
d
b
e
c
e
c

a
c
c
b

c
f
g
e

c
e
f
g

c
g
f
e

Y1 = 





Y3 = 





c
e
g
f

b
e
e
d











,

Y2 = 



,

Y4 = 

a
c
b
c

c
f
e
g

b
e
d
e

c
g
e
f



,




y
y
x y
y
z w w
y w z w
y w w z















These symmetries allow us to drastically reduce the degree
of freedom in our SDP: For any m = 2, n
2, the matrices
Y1, . . . , Yn are always determined by precisely 11 variables
that we label a, b, c, d, e, f, g, x, y, z, w. We computed their
values explicitly for n = 2, 3, 4. For n = 2,

≥

and Y2, Y3 can be determined from Y1. For n = 4,

Y1 =

Y5 =

15
4 −
9
8
1
8
1
8
1
8

−
−
−
−

9
8 −
3
8
1
8
1
8
1
8

1
8 −
1
8
3
8
1
8
1
8

1
8 −
1
8
1
8
3
8
1
8

3
4 −
3
8
3
8
3
8
3
8

3
8 −
3
8
1
8
1
8
1
8

3
8 −
1
8
3
8
1
8
1
8

3
8 −
1
8
1
8
3
8
1
8

−
−
−
−





















,

,

1
8
1
8
1
8
1
8
3
8

3
8
1
8
1
8
1
8
3
8





















and Y2, Y3, Y4 can be determined from Y1. The rational
numbers above are all chosen by observing the ﬂoating
numbers output of the SDP (6).

The values of the matrices Yi’s for n = 2, 3, 4 allow us to
guess that the variables a, b, c, d, e, f, g, x, y, z, w are:

a =

5(n

1)

,

−
4

d = f = z =

2(n

3(n

−
2n

1)

,

c =

e = g = w =

3

n

n

2

,

,

−
2n

−
n2

(11)

−
1)

,

n

x =

,

y =

1

.

n

−
2n

−

b =

−
n2
1

−
4

The proof of our next theorem will ascertain that these
choices are indeed correct — they yield the sum-of-squares
decomposition in (10) for m = 2.
Theorem 4 (Better Recht–R´e for m = 2). Let A1, . . . , An
be positive semideﬁnite matrices. If A1 +
nI,
then

+ An (cid:22)

· · ·

.

1
4

−

n(n

1)I

−

(cid:22)

AiAj (cid:22)

n(n

−

1)I.

=j
Xi

Proof. The upper bound has already been established in
Theorem 1. It remains to establish the lower bound. We
start from the following readily veriﬁable inequalities

1
2n(n

(Aj −

1)
−
6
5n

−

Ai +

Ak)Ai(Aj −
n)
2(3
1)
5n(n

Y1 = 

1
4
0

1
2
and Y2 can be determined from Y1. For n = 3,

5
4 −
3
4
1
4

1
4 −
1
4
1
4

Y3 = 

3
4
1
2
0

−
−










−

,

1
4 −
1
2
0

,

1
4
0

1
2




5(n

1)

−
4

I

(cid:16)

Ai

I

(cid:16)

5
1
2 −
4
1
9
1
0
9
1
0
9

−

Y1 = 





0
1
9
4
9
1
2

0
1
9
1
9
4
9

1
2 −
1
3
1
3
1
3

1
3 −
4
9
1
9
1
9

1
3 −
1
9
4
9
1
2

1
3
1
9
1
9
4
9



,













, Y4 = 





−
−
−

−
−

−
−

6
5n

−

Ai +

2(3
5n(n

n)
1)

n
1
−
5n2

Ai +

(cid:16)

Ai

Ai +

(cid:16)

2n
n

1
−
1
−

2n
n

1
−
1
−

Ak)

(cid:23)

0,

(12)

(13)

(14)

Aj

Aj

Aj

Aj

(cid:17)

(cid:17)

(cid:17)

(cid:17)

0,

(cid:23)

0,

(cid:23)

=i
Xj

=i
Xj

=i
Xj

=i
Xj

6
6
6
6
6
6
6
Noncommutative Arithmetic-Geometric Mean Conjecture is False

1
2n2 (Aj −
1
n

−
4

(cid:16)

Ak)

n

(cid:16)
2
n

I

−

Ak)

(cid:23)

0,

(15)

1
nm

−

i
X
Ai

Ai

(Aj −
(cid:17)
n

i
X

(cid:17)(cid:16)
I

−

(cid:16)

(16)

Ai

Ai

(cid:17)

(cid:17)

0.

(cid:23)

−

2
n

i
X

i
X

Sum (12) over all distinct i, j, k; sum (13) over all i; sum
(14) over all i; sum (15) over all distinct j, k; add all results
to (16). The ﬁnal inequality is our required lower bound.

For n = m = 2, the new lower bound is sharp. Take

A1 =

3
2
0

"

0
0#

,

A2 =

1
6
√2
3

"

√2
3
4
3 #

,

= 2 and the smallest eigenvalue of A1A2 +
1/2. We conjecture that this bound is sharp for

then
k
A2A1 is
all m = 2, n

A1 +A2k
−

2.

≥

The method in this section also extends to higher m. For
example, we may impose symmetry constraints for m =
n = 3 and see if the Y1, Y2, Y3, Y4 obtained have rational
values, and if so write down a sums-of-squares proof by
factoring the Yi’s.

6. Conclusion and open problems

We conclude our article with a discussion of some open
problems and why we think the Recht–R´e conjecture, while
false as it is currently stated, only needs to be reﬁned.

An immediate open question is whether the conjecture is
true for m = 4: Table 1 shows that it holds for (m, n) =
(4, 4) and (4, 5); we suspect that it is true for all n

4.

≥

As we pointed out after Conjecture 1A, the Recht–R´e in-
equality as stated in (1) conceals an asymmetry — it actu-
ally contains two inequalities, as shown in (2). What we
have seen is that the lower bound is never attained in any of
the cases we have examined. For m = 2 and 3, the lower
bound is too large, and we improved it in Theorem 4 and
the proof of Theorem 2 respectively. For m = 5, the lower
bound is too small, which is why the Recht–R´e inequality
is false. A natural follow-up question is then: “What is the
correct lower bound?” On the other hand, we conjecture
that the remaining half of the Recht–R´e inequality, i.e., the
upper bound in (2), holds true for all m

n

N.

≤

∈

Recht & Re (2012) has another conjecture similar to Con-
jecture 1 but where the norms appear after the summation.

Conjecture 2 (Recht & Re 2012). Let A1, . . . , An be pos-
itive semideﬁnite matrices. Then

Aj1 · · ·

Ajm k ≥

k
X1
j1,...,jm
≤

n

≤

(n

m)!

−
n!

Aj1 · · ·

k
X1
j1,...,jm
n,
≤
≤
j1,...,jm distinct

Ajm k

.

This has been established for m = 2 and 3 for any unitary
invariant norm in Israel et al. (2016). It is not clear to us if
the noncommutative Positivstellensatz might perhaps also
shed light on this related conjecture.

Lastly, if our intention is to analyze the relative efﬁcacies
of with- and without-replacement sampling strategies in
randomized algorithms, then it is more pertinent to study
these inequalities for random matrices, i.e., we do not just
assume that the indices are random variables but also the en-
tries of the matrices. For example, if we want to analyze the
Kaczmarz algorithm, then we ought to take expectation not
only with respect to all permutations but also with respect
to how we generate the entries of the matrices. This would
provide a more realistic platform for comparing with- and
without-replacement sampling strategies.

References

Beck, A. and Tetruashvili, L. On the convergence of block
coordinate descent type methods. SIAM J. Optim., 23(4):
2037–2060, 2013.

Bhatia, R. and Holbrook, J. Noncommutative geometric

means. Math. Intelligencer, 28(1):32–39, 2006.

Bhatia, R. and Kittaneh, F. On the singular values of a
product of operators. SIAM J. Matrix Anal. Appl., 11(2):
272–277, 1990.

Bhatia, R. and Kittaneh, F. Notes on matrix arithmetic-
geometric mean inequalities. Linear Algebra Appl., 308
(1-3):203–211, 2000.

Bhatia, R. and Kittaneh, F.

The matrix arithmetic-
geometric mean inequality revisited. Linear Algebra
Appl., 428(8-9):2177–2191, 2008.

Bottou, L. Curiously fast convergence of some stochastic
gradient descent algorithms. In Proceedings of the sym-
posium on learning and data science, Paris, 2009.

Bottou, L. Large-scale machine learning with stochas-
In Proceedings of COMP-
tic gradient descent.
STAT’2010, pp. 177–186. Physica-Verlag/Springer, Hei-
delberg, 2010.

Fang, C., Lin, Z., and Zhang, T. Sharp analysis for non-
convex sgd escaping from saddle points.
In Beygelz-
imer, A. and Hsu, D. (eds.), Proceedings of the Thirty-
Second Conference on Learning Theory, volume 99 of

Noncommutative Arithmetic-Geometric Mean Conjecture is False

Pascoe, J. E. Positivstellens¨atze for noncommutative ratio-
nal expressions. Proc. Amer. Math. Soc., 146(3):933–
937, 2018.

Recht, B. and Re, C. Toward a noncommutative arithmetic-
geometric mean inequality: Conjectures, case-studies,
and consequences.
In Mannor, S., Srebro, N., and
Williamson, R. C. (eds.), Proceedings of the 25th Annual
Conference on Learning Theory, volume 23 of Proceed-
ings of Machine Learning Research, pp. 11.1–11.24, Ed-
inburgh, Scotland, 2012.

Shamir, O. Without-replacement sampling for stochastic
In Advances in neural information

gradient methods.
processing systems, pp. 46–54, 2016.

Strohmer, T. and Vershynin, R. A randomized Kaczmarz
algorithm with exponential convergence. J. Fourier Anal.
Appl., 15(2):262–278, 2009.

Sturm, J. F. Using SeDuMi 1.02, a MATLAB toolbox for
optimization over symmetric cones. Optimization meth-
ods and software, 11(1-4):625–653, 1999.

Wright, S. J. Coordinate descent algorithms. Math. Pro-

gram., 151(1, Ser. B):3–34, 2015.

Zhang, T. A note on the matrix arithmetic-geometric mean
inequality. Electron. J. Linear Algebra, 34:283–287,
2018.

Proceedings of Machine Learning Research, pp. 1192–
1234, Phoenix, USA, 2019.

Gatermann, K. and Parrilo, P. A.

Symmetry groups,
semideﬁnite programs, and sums of squares. J. Pure
Appl. Algebra, 192(1-3):95–128, 2004.

Hardy, G. H., Littlewood, J. E., and P´olya, G. Inequalities.
Cambridge Mathematical Library. Cambridge University
Press, Cambridge, 1988. Reprint of the 1952 edition.

Helton, J. W. “Positive” noncommutative polynomials are
sums of squares. Ann. of Math. (2), 156(2):675–694,
2002.

Helton, J. W., Klep, I., and McCullough, S. The convex
Positivstellensatz in a free algebra. Adv. Math., 231(1):
516–534, 2012.

Israel, A., Krahmer, F., and Ward, R. An arithmetic-
geometric mean inequality for products of three matrices.
Linear Algebra Appl., 488:1–12, 2016.

Jin, C., Ge, R., Netrapalli, P., Kakade, S. M., and Jordan,
M. I. How to escape saddle points efﬁciently. In Precup,
D. and Teh, Y. W. (eds.), Proceedings of the 34th Interna-
tional Conference on Machine Learning, volume 70 of
Proceedings of Machine Learning Research, pp. 1724–
1732, International Convention Centre, Sydney, Aus-
tralia, 2017.

Johnson, R. and Zhang, T. Accelerating stochastic gradient
descent using predictive variance reduction. In Advances
in neural information processing systems, pp. 315–323,
2013.

Lasserre, J. B. A new Farkas lemma for positive semidef-
IEEE Trans. Automat. Control, 40(6):

inite matrices.
1131–1133, 1995.

Lasserre, J. B. An introduction to polynomial and semi-
algebraic optimization, volume 52. Cambridge Univer-
sity Press, 2015.

Nagaraj, D., Jain, P., and Netrapalli, P. SGD without
replacement: Sharper rates for general smooth convex
In International Conference on Machine
functions.
Learning, pp. 4703–4711, 2019.

Nemirovski, A., Juditsky, A., Lan, G., and Shapiro, A. Ro-
bust stochastic approximation approach to stochastic pro-
gramming. SIAM J. Optim., 19(4):1574–1609, 2008.

Nesterov, Y. Efﬁciency of coordinate descent methods on
huge-scale optimization problems. SIAM J. Optim., 22
(2):341–362, 2012.

