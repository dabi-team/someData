Machine learning manuscript No.
(will be inserted by the editor)

Learning higher-order logic programs

Andrew Cropper · Rolf Morel · Stephen
Muggleton

9
1
0
2

l
u
J

5
2

]

G
L
.
s
c
[

1
v
3
5
9
0
1
.
7
0
9
1
:
v
i
X
r
a

the date of receipt and acceptance should be inserted later

Abstract A key feature of inductive logic programming (ILP) is its ability to learn ﬁrst-
order programs, which are intrinsically more expressive than propositional programs.
In this paper, we introduce techniques to learn higher-order programs. Speciﬁcally, we
extend meta-interpretive learning (MIL) to support learning higher-order programs by
allowing for higher-order deﬁnitions to be used as background knowledge. Our theoret-
ical results show that learning higher-order programs, rather than ﬁrst-order programs,
can reduce the textual complexity required to express programs which in turn reduces
the size of the hypothesis space and sample complexity. We implement our idea in two
new MIL systems: the Prolog system Metagolho and the ASP system HEXMILho. Both sys-
tems support learning higher-order programs and higher-order predicate invention, such
as inventing functions for map/3 and conditions for filter/3. We conduct experiments
on four domains (robot strategies, chess playing, list transformations, and string decryp-
tion) that compare learning ﬁrst-order and higher-order programs. Our experimental
results support our theoretical claims and show that, compared to learning ﬁrst-order
programs, learning higher-order programs can signiﬁcantly improve predictive accura-
cies and reduce learning times.

1 Introduction

Suppose you have intercepted encrypted messages and you want to learn a general de-
cryption program from them. Figure 1 shows such a scenario with three example encrypt-
ed/decrypted strings. In this scenario the underlying encryption algorithm is a simple

A. Cropper
University of Oxford, UK
E-mail: andrew.cropper@cs.ox.ac.uk

R. Morel
University of Oxford, UK
E-mail: rolf.morel@cs.ox.ac.uk

S. H. Muggleton
Imperial College London, UK
E-mail: s.muggleton@imperial.ac.uk

 
 
 
 
 
 
2

Andrew Cropper et al.

Caesar cipher with a shift of +1. Given these examples, most inductive logic program-
ming (ILP) approaches, such as meta-interpretive learning (MIL) [34,35], would learn
a recursive ﬁrst-order program, such as the one shown in Figure 2a. Although correct,
this ﬁrst-order program is overly complex in that most of the program is concerned with
manipulating the input and output, such as getting the head and tail elements. In this
paper, we introduce techniques to learn higher-order programs that abstract away this
boilerplate code. Speciﬁcally, we extend MIL to support learning higher-order programs
that use higher-order constructs such as map/3, until/4, and ifthenelse/5. Using this
new approach, we can learn an equivalent1 yet smaller decryption program, such as
the one shown in Figure 2b, which uses map/3 to abstract away the recursion and list
manipulation.

Encrypted
joevdujwf
mphjd
qsphsbnnjoh

Decrypted
inductive
logic
programming

Fig. 1: Example encrypted and decrypted messages.

decrypt(A,B):-

empty(A),
empty(B).

decrypt(A,B):-
head(A,C),
char_to_int(C,D),
prec(D,E),
int_to_char(E,F),
head(B,F),
tail(A,G),
tail(B,H),
decrypt(G,H).

(a)

decrypt(A,B):-

map(A,B,decrypt1).

decrypt1(A,B):-

char_to_int(A,C),
prec(C,D),
int_to_char(D,B).

(b)

Fig. 2: Decryption programs. Figure (a) shows a ﬁrst-order program. Figure (b) shows a
higher-order program, where decrypt1/2 is an invented predicate symbol. The predicate
prec/2 represents preceding/2, i.e. the inverse of successor/2. The programs are success
set equivalent when restricted to the target predicate decrypt/2 but the higher-order
program is much smaller and requires half the number of literals (6 vs 12).

We claim that, compared to learning ﬁrst-order programs, learning higher-order pro-
grams can improve learning performance. We support our claim by showing that learning
higher-order programs can reduce the textual complexity required to express programs
which in turn reduces the size of the hypothesis space and sample complexity.

1 Success set equivalent when restricted to the target predicate decrypt/2.

Learning higher-order logic programs

3

We implement our idea in Metagolho, which extends Metagol [9], a MIL implemen-
tation based on a Prolog meta-interpreter. Metagolho extends Metagol to support inter-
preted BK (IBK). In this approach, meta-interpretation drives both the search for a hy-
pothesis and predicate invention, allowing for higher-order arguments to be invented,
such as the predicate decrypt1/2 in Figure 2b. The key novelty of Metagolho is the
combination of abstraction (learning higher-order programs) and invention (predicate
invention), i.e. inventions inside of abstractions. Metagolhosupports the invention of con-
ditions and functions to an arbitrary depth, which goes beyond anything in the literature.
We also introduce HEXMILho, which likewise extends HEXMIL [23], an answer set pro-
gramming (ASP) MIL implementation, to support learning higher-order programs. As far
as we are aware, HEXMILho is the ﬁrst ASP-based ILP system that has been demonstrated
capable of learning higher-order programs.

We further support our claim that learning higher-order programs can improve learn-
ing performance by conducting experiments in four domains: robot strategies, chess play-
ing, list transformations, and string decryption. The experiments compare the predictive
accuracies and learning times when learning ﬁrst and higher-order programs. In all cases
learning higher-order programs leads to substantial increases in predictive accuracies
and lower learning times in agreement with our theoretical results.

Our main contributions are:

– We extend the MIL framework to support learning higher-order programs by extend-

ing it to support higher-order deﬁnitions (Section 3.2).

– We show that the new higher-order approach can reduce the textual complexity of
programs which in turn reduces the size of the hypothesis space and also sample
complexity (Section 3.3).

– We introduce Metagolho and HEXMILho which extend Metagol and HEXMIL respec-
tively. Both systems support learning higher-order programs with higher-order pred-
icate invention (Section 4).

– We show that the ASP-based HEXMIL and HEXMILho have an additional factor de-
termining the size of their search space, namely the number of constants (Section
4.5).

– We conduct experiments in four domains which show that, compared to learning
ﬁrst-order programs, learning higher-order programs can substantially improve pre-
dictive accuracies and reduce learning times (Section 5).

2 Related work

2.1 Program induction

Program synthesis is the automatic generation of a computer program from a speci-
ﬁcation. Deductive approaches [27] deduce a program from a full speciﬁcation which
precisely states the requirements and behaviour of the desired program. By contrast,
program induction approaches induce (learn) a program from an incomplete speciﬁca-
tion, usually input/output examples. Many program induction approaches learn speciﬁc
classes of programs, such as string transformations [20]. By contrast, MIL is general-
purpose, shown capable of grammar induction [34], learning robot strategies [7], and
learning efﬁcient algorithms [10]. In addition, MIL supports predicate invention, which
has been repeatedly stated as an important challenge in ILP [32,42,33]. The idea behind
predicate invention is for an ILP system to introduce new predicate symbols to improve

4

Andrew Cropper et al.

learning performance. In program induction, predicate invention can be seen as invent-
ing auxiliary functions/predicates, as one does when manually writing a program, for
example to reduce code duplication or to improve the readability of a program.

2.2 Inductive functional programming

Functional program induction approaches often support learning higher-order programs.
MagicHaskeller [24] is a general-purpose system which learns Haskell functions by se-
lecting and instantiating higher-order functions from a pre-deﬁned vocabulary. Igor2
[25] also learns recursive Haskell programs and supports auxiliary function invention
but is restricted in that it requires the ﬁrst k examples of a target theory to generalise
over a whole class. The L2 system [16] synthesises recursive functional algorithms. The
MYTH [36] and MYTH2 [18] systems use type systems to synthesise programs. Frankle
et al. [18] show how example-based speciﬁcations can be turned into type speciﬁcations.
In this work we go beyond these approaches by (1) learning higher-order programs with
invented predicates, (2) giving theoretical justiﬁcations and conditions for when learn-
ing higher-order programs can improve learning performance (Section 3.3), and (3) ex-
perimentally demonstrating that learning higher-order programs can improve learning
performance.

2.3 Inductive logic programming

ILP systems, including the popular systems FOIL [37], Progol [31], ALEPH [41], and
TILDE [1], usually learn ﬁrst-order programs. Given appropriate mode declarations [31]
for higher-order predicates such as map/3, Progol and Aleph could learn higher-order
programs such as f(A,B):-map(A,B,f1). However, because Progol and Aleph do not
support predicate invention they would be unable to invent the predicate f1/2 in the
above example. Similarly, existing MIL implementations, such as Metagol, could learn
a similar program to the one above when map/3 is provided as background knowledge.
However, even though Metagol supports predicate invention, it is unable to invent the
predicate f1/2 in the example above because Metagol deductively proves BK by dele-
gating the proofs to Prolog. To overcome this limitation we introduce the notion of in-
terpreted BK (IBK), where map/3 can be deﬁned as IBK. The new MIL system Metagolho
proves IBK through meta-interpretation, which allows for predicate arguments such as
f1/2 to be invented.

2.4 Meta-interpretive learning

MIL was originally based on a Prolog meta-interpreter, although the MIL problem has
also been encoded as an ASP problem [23]. The key difference between a MIL learner and
a standard Prolog meta-interpreter is that whereas a standard Prolog meta-interpreter
attempts to prove a goal by repeatedly fetching ﬁrst-order clauses whose heads unify
with a given goal, a MIL learner additionally attempts to prove a goal by fetching higher-
order existentially quantiﬁed formulas, called metarules, supplied as BK, whose heads
unify with the goal. The resulting predicate substitutions are saved and can be reused
later in the proof. Following the proof of a set of goals, a logic program is induced by

Learning higher-order logic programs

5

projecting the predicate substitutions onto their corresponding metarules. A key feature
of MIL is the support for predicate invention. MIL uses predicate invention for automatic
problem decomposition. As we will demonstrate, the combination of predicate invention
and abstraction leads to compact representations of complex programs.

Cropper and Muggleton [8] introduced the idea of using MIL to learn higher-order
programs by using IBK. This paper is an extended version of that paper. In addition,
we go beyond that work in several ways. First, we generalise their preliminary theo-
retical results, principally in Section 3.3. We also provide more explanation as to why
abstracted MIL can improve learning performance compared to unabstracted MIL (end
of Section 3.3). Second, we introduce the HEXMILho system, which, as mentioned, ex-
tends HEXMIL to support learning higher-order programs with higher-order predicate
invention. Our motivation for this extension is to show the generality of our work, i.e.
to demonstrate that it is not speciﬁc to Metagol and Prolog. We also study the compu-
tational complexity of both Metagolho and HEXMILho. We show that the ASP approach
is highly sensitive to the number of constant symbols, which leads to scalability issues.
Furthermore, we corroborate the experimental results of Cropper and Muggleton by re-
peating the robot waiter, chess, and list transformation experiments with Metagolho. We
provide additional experimental evidence by repeating the experiments with HEXMILho.
Finally, we add further evidence by conducting a new experiment on the string decryp-
tion problem mentioned in the introduction.

2.5 Higher-order logic

McCarthy [28] advocated using higher-order logic to represent knowledge. Similarly,
Muggleton et al. [33] argued that using higher-order representations in ILP provides
more ﬂexible ways of representing BK. Lloyd [26] used higher-order logic in the learning
process but the approach focused on learning functional programs and did not support
predicate invention. Early work in ILP [17,38,14] used higher-order formulae to specify
the overall form of programs to be learned, similar to how MIL uses metarules. However,
these works did not consider learning higher-order programs. By contrast, we use higher-
order logic as a learning representation and to represent learned hypotheses. Feng and
Muggleton [15] investigated inductive generalisation in higher-order logic using a re-
stricted form of lambda calculus. However, their approach does not support ﬁrst-order
nor higher-order predicate invention. By contrast, we introduce higher-order deﬁnitions
which allow for invented predicate symbols to be used as arguments in literals.

2.6 Abstraction and invention

Predicate invention has been repeatedly stated as an important challenge in ILP [32,42,
33]. Popular ILP systems, such as FOIL, Progol, and ALEPH, do not support predicate
invention, nor do most program induction systems. Meta-level abduction [22] uses ab-
duction and meta-level reasoning to invent predicates that represent propositions. By
contrast, MIL uses abduction to invent predicates that represent relations, i.e. relations
that are not in the initial BK nor in the examples. For instance, MIL was shown [35] able
to invent a predicate corresponding to the parent/2 relation when learning a grandpar-
ent/2 relation. In this paper we extend MIL and the associated Metagol implementation
to support higher-order predicate invention for use in higher-order constructs, such as

6

Andrew Cropper et al.

map/3, reduce/3, and fold/4. This approach supports a form of abstraction which goes
beyond typical ﬁrst-order predicate invention [39] in that the use of higher-order deﬁ-
nitions combined with meta-interpretation drives both the search for a hypothesis and
predicate invention, leading to more accurate and compact programs.

3 Theoretical framework

3.1 Preliminaries

1 and (cid:86)

We assume familiarity with logic programming. However, we restate key terminology.
Note that we focus on learning function-free logic programs, so we ignore terminology
to do with function symbols. We denote the predicate and constant signatures as (cid:80)
and (cid:67) respectively. A variable is ﬁrst-order if it can be bound to a constant symbol or
another ﬁrst-order variable. A variable is higher-order if it can be bound to a predicate
symbol or another higher-order variable. We denote the sets of ﬁrst-order and higher-
order variables as (cid:86)
2 respectively. A term is a variable or a constant symbol. A
term is ground if it contains no variables. An atom is a formula p(t1, . . . , tn
), where p is a
predicate symbol of arity n and each ti is a term. An atom is ground if all of its terms are
ground. A higher-order term is a higher-order variable or a predicate symbol. An atom
is higher-order if it has at least one higher-order term. A literal is an atom A (a positive
literal) or its negation ¬A (a negative literal). A clause is a disjunction of literals. The
variables in a clause are universally quantiﬁed. A Horn clause is a clause with at most
one positive literal. A deﬁnite clause is a Horn clause with exactly one positive literal. A
clause is higher-order if it contains at least one higher-order atom. A logic program is a
set of Horn clauses. A logic program is higher-order if it contains at least one higher-order
Horn clause.

3.2 Abstracted meta-interpretive learning

We extend MIL to the higher-order setting. We ﬁrst restate metarules [6]:

Deﬁnition 1 (Metarule) A metarule is a higher-order formula of the form:

∃π∀µ l0

← l1, . . . , lm

where each li is a literal, π ⊆ (cid:86)
1

∪ (cid:86)

2, µ ⊆ (cid:86)
1

∪ (cid:86)

2, and π and µ are disjoint.

In contrast to a higher-order Horn clause, in which all the variables are all universally
quantiﬁed, the variables in a metarule can be quantiﬁed universally or existentially2.
When describing metarules, we omit the quantiﬁers. Instead, we denote existentially
quantiﬁed higher-order variables as uppercase letters starting from P and universally
quantiﬁed ﬁrst-order variables as uppercase letters starting from A. Figure 3 shows ex-
ample metarules.

To extend MIL to support learning higher-order programs we introduce higher-order

deﬁnitions:

2 Existentially quantiﬁed ﬁrst-order variables do not appear in this work, but do in existing work on

MIL [11].

Learning higher-order logic programs

7

Name Metarule
ident
precon
curry
chain

P(A, B) ← Q(A, B)
P(A, B) ← Q(A), R(A, B)
P(A, B) ← Q(A, B, R)
P(A, B) ← Q(A, C), R(C, B)

Fig. 3: Example metarules. The letters P, Q, and R denote existentially quantiﬁed higher-
order variables. The letters A, B, and C denote universally quantiﬁed ﬁrst-order variables.

Deﬁnition 2 (Higher-order deﬁnition) A higher-order deﬁnition is a set of higher-
order Horn clauses where the head atoms have the same predicate symbol.

Three example higher-order deﬁnitions are:

Example 1 (Map deﬁnition)

map([],[],F) ←
map([A|As],[B|Bs],F) ← F(A,B), map(As,Bs)

In Example 1 the symbol F is a universally quantiﬁed higher-order variable. The other
variables are universally quantiﬁed ﬁrst-order variables.

Example 2 (Until deﬁnition)

until(A,A,Cond,F) ← Cond(A)
until(A,B,Cond,F) ← not(Cond(A)), F(A,C), until(C,B,Cond,F)

Example 3 (Fold deﬁnition)

fold([],Acc,Acc,F) ←
fold([A|As],Acc1,B,F) ← F(A,Acc1,Acc2), fold(As,Acc2,B,F)

We frequently refer to abstractions. In computer science code abstraction [4] involves
hiding complex code to provide a simpler interface. In this work, we deﬁne an abstraction
as a higher-order Horn clause that contains at least one atom which takes a predicate
symbol an argument. In the following abstraction example, the ﬁnal argument of map/3
is ground to the predicate symbol succ/2:

Example 4 (Abstraction)

f(A,B) ← map(A,B,succ)

Likewise, in the higher-order decryption program in the introduction (Figure 2b), the
ﬁnal argument of map/3 is ground to the predicate symbol decrypt1/2.

We deﬁne the abstracted MIL input, which extends a standard MIL input [6] (and

problem) to support higher-order deﬁnitions:

Deﬁnition 3 (Abstracted MIL input) An abstracted MIL input is a tuple (B, E+, E−, M )
where:
– B = BC

∪ BI where BC is a set of Horn clauses and BI is (the union of) a set of

higher-order deﬁnitions

– E+ and E− are disjoint sets of ground atoms representing positive and negative ex-

amples respectively
– M is a set of metarules.

8

Andrew Cropper et al.

There is little declarative difference between BC and BI . There is, however, a procedu-
ral difference between the two. We therefore call BC compiled BK and BI interpreted
BK (IBK). The procedural distinction between BC and BI is that whereas a clause from
BC is proved deductively (by calling Prolog), a clause from BI is proved through meta-
interpretation, which allows for predicate invention to be combined with abstractions
to invent higher-order predicates. The distinction between BI and M is that the clauses
in BI are all universally quantiﬁed, whereas the metarules in M contain existentially
quantiﬁed variables whose substitutions form the induced program. We discuss these
distinctions in more detail in Section 4 when we describe the MIL implementations.

We deﬁne the abstracted MIL problem:

Deﬁnition 4 (Abstracted MIL problem) Given an abstracted MIL input (B, E+, E−, M ),
the abstracted MIL problem is to return a logic program hypothesis H such that:

– ∀h ∈ H, ∃m ∈ M such that h = mθ , where θ is a substitution that grounds all the

existentially quantiﬁed variables in m

– H ∪ B |= E+
– H ∪ B (cid:54)|= E−

We call H a solution to the MIL problem.

The ﬁrst condition ensures that a logic program hypothesis is an instance of the given
metarules. It is this condition that enforces the strong inductive bias in MIL.

MIL supports inventions:

Deﬁnition 5 (Invention) Let (B, E+, E−, M ) be a MIL input and H be a solution to the
MIL problem. Then a predicate symbol p/a is an invention if and only if it is in the
predicate signature (i.e. the set of all predicate symbols with their associated arities) of
H and not in the predicate signature of B ∪ E+ ∪ E−.

A MIL learner uses abstractions to generate inventions:

Example 5 (Invention)

f(A,B) ← map(A,B,f1)
f1(A,B) ← succ(A,C),succ(C,B)

In this program, a MIL learner has invented the predicate f1/2 for use in a map/3 deﬁni-
tion. Likewise, in the higher-order decryption program in the introduction (Figure 2b),
the ﬁnal argument of map/3 is ground to the invented predicate symbol decrypt1/2.

3.3 Language classes, expressivity, and complexity

We claim that increasing the expressivity of MIL from learning ﬁrst-order programs to
learning higher-order programs can improve learning performance. We support this
claim by showing that learning higher-order programs can reduce the size of the hy-
pothesis space which in turn reduces sample complexity and expected error. In MIL the
size of the hypothesis space is a function of the number of metarules m and their form,
the number of background predicate symbols p, and the maximum program size n (the
maximum number of clauses allowed in a program). We restrict metarules by their body
size and literal arity:

Learning higher-order logic programs

9

Deﬁnition 6 (Metarule fragment (cid:77) i
most j literals in the body and each literal has arity at most i.

j ) A metarule is in the fragment (cid:77) i

j if it has at

For instance, the chain metarule in Figure 3 restricts clauses to be deﬁnite with two body
literals of arity two, i.e. is in the fragment (cid:77) 2
2 . By restricting the form of metarules we
can calculate the size of a MIL hypothesis space. The following result is essentially the
same as in [12]. The only difference is that we drop the redundant Big O notation:

Proposition 1 (MIL hypothesis space) Given p predicate symbols and m metarules in
(cid:77) i

j , the number of programs expressible with n clauses is at most (mp j+1)n.

Proof The number of clauses which can be constructed from a (cid:77) i
j metarule given p
predicate symbols is at most p j+1 because for a given metarule there are at most j + 1
predicate variables with at most p j+1 possible substitutions. Therefore the number of
clauses that can be formed from m distinct metarules in (cid:77) i
j using p predicate symbols
is at most mp j+1. It follows that the number of programs which can be formed from a
selection of n such clauses is at most (mp j+1)n.
(cid:117)(cid:116)

Proposition 1 shows that the MIL hypothesis space grows exponentially both in the size
of the target program and the number of body literals in a clause. For instance, for the
(cid:77) 2
2 fragment, the MIL hypothesis space contains at most (mp3)n programs, where m is
the number of metarules and n is the number of clauses in the target program.

We update this bound for the abstracted MIL framework:

Proposition 2 (Number of abstracted (cid:77) i
metarules in (cid:77) i
the number of abstracted (cid:77) i

j programs) Given p predicate symbols and m
j with at most k additional existentially quantiﬁed higher-order variables,
j programs expressible with n clauses is at most (mp j+1+k)n.
Proof As with Proposition 1, the number of clauses which can be constructed from a (cid:77) i
j
metarule given p predicate symbols is at most p j+1 because for a given metarule there
are at most j + 1 predicate variables with at most p j+1 possible substitutions. Given a
metarule in (cid:77) i
j with at most k additional existentially quantiﬁed higher-order variables
there are therefore potentially j + 1 + k predicate variables with p j+1+k possible substi-
tutions. Therefore the number of clauses expressible with m such metarules is at most
mp j+1+k. By the same reasoning as for Proposition 1, it follows that the number of pro-
grams which can be formed from a selection of n such clauses is at most (mp j+1+k)n. (cid:117)(cid:116)
We use this result to develop sample complexity [29] results for unabstracted MIL:

Proposition 3 (Sample complexity of unabstracted MIL) Given p predicate symbols,
m metarules in (cid:77) i
j , and a maximum program size nu, unabstracted MIL has sample com-
plexity:

su

≥ 1
ε

(nu ln(m) + ( j + 1)nu ln(p) + ln( 1
δ

))

Proof According to the Blumer bound, which appears as a reformulation of Lemma 2.1
in [2], the error of consistent hypotheses is bounded by ε with probability at least (1 −
δ) once su
δ )), where |H| is the size of the hypothesis space. From
Proposition 1, |H| = (mp j+1)nu for unabstracted MIL. Substituting and applying logs
gives:

ε (ln(|H|) + ln( 1

≥ 1

su

≥ 1
ε

(nu ln(m) + ( j + 1)nu ln(p) + ln( 1
δ

))

(cid:117)(cid:116)

10

Andrew Cropper et al.

We likewise develop sample complexity results for abstracted MIL:

Proposition 4 (Sample complexity of abstracted MIL) Given p predicate symbols, m
metarules in (cid:77) i
j augmented with at most k higher-order variables, and a maximum pro-
gram size na, abstracted MIL has sample complexity:

sa

≥ 1
ε

(na ln(m) + ( j + 1 + k)na ln(p) + ln( 1
δ

))

Proof Analogous to Proposition 3 using Proposition 2.

(cid:117)(cid:116)

We compare these bounds:

Theorem 1 (Unabstracted and abstracted bounds) Let m be the number of (cid:77) i
nu and na be the minimum numbers of clauses necessary to express a target theory with un-
abstracted and abstracted MIL respectively, su and sa be the bounds on the number of training
examples required to achieve error less than ε with probability at least 1 − δ with unab-
stracted and abstracted MIL respectively, and k ≥ 1 be number of additional higher-order
variables used by abstracted MIL. Then su

> sa when:

j metarules,

nu

− na

> k

j + 1

na

Proof From Proposition 3 it holds that:

su

≥ 1
ε

(nu ln(m) + ( j + 1)nu ln(p) + ln( 1
δ

))

From Proposition 4 it holds that:

sa

≥ 1
ε

(na ln(m) + ( j + 1 + k)na ln(p) + ln

)

1
δ

If we cancel 1

ε then su

> sa follows from:

nu ln(m) + ( j + 1)nu ln(p) > na ln(m) + ( j + 1 + k)na ln(p)

Because k ≥ 1, the inequality su

> sa holds when:

and:

nu ln(m) > na ln(m)

(1)

( j + 1)nu ln(p) > ( j + 1 + k)na ln(p)
Because k ≥ 1 the inequality (2) implies the inequality (1). The inequality (2) holds
> ( j + 1 + k)na.
when ( j + 1)nu
(cid:117)(cid:116)
Rearranging terms leads to su

> ( j + 1 + k)na. Therefore su
> sa when nu

> sa follows from ( j + 1)nu
− na

> k

(2)

j+1 na.

The results from this section motivate the use of abstracted MIL, and help explain the
experimental results (Section 5). To illustrate these theoretical results, reconsider the
decryption programs shown in Figure 2. Consider representing these programs in (cid:77) 2
2 .
Figure 4a shows that the ﬁrst-order program would require seven clauses. By contrast,
Figure 4b shows that the higher-order program requires only three clauses and one extra
= 7 be the number of metarules, back-
= 6, and nu
higher-order variable. Let mu
ground relations, and clauses needed to express the ﬁrst-order program shown in Figure

= 4, pu

Learning higher-order logic programs

11

= pu

= mu

+ 1, na

4a. Plugging these values into the formula in Proposition 1 shows that the hypothesis
space of unabstracted MIL contains approximately 1021 programs. By contrast, suppose
we allow an abstracted MIL learner to additionally use the higher-order deﬁnition map/3
+ 1,
and the corresponding curry metarule P(A, B) ← Q(A, B, R). Therefore ma
= 3, and k = 1, where k is the number of additional higher-order
pa
variables used in the curry metarule. Then plugging these values into the formula from
Proposition 2 shows that the hypothesis space of abstracted MIL contains approximately
1013 programs, which is substantially smaller than the ﬁrst-order hypothesis space, de-
spite using more metarules and more background relations. The Blumer bound [2] says
that given two hypothesis spaces of different sizes, then searching the smaller space will
result in less error compared to the larger space, assuming that the target hypothesis is
in both spaces. In this example, the target hypothesis, or a hypothesis that is equivalent3
to the target hypothesis, is in both hypothesis spaces but the abstracted MIL space is
smaller. Therefore, our results imply that in this scenario, given a ﬁxed number of ex-
amples, abstracted MIL should improve predictive accuracies compared to unabstracted
MIL. In Section 5.5 we experimentally explore whether this result holds.

decrypt(A,B):-

decrypt1(A,B),
decrypt5(A,B).

decrypt1(A,B):-

head(A,C),
decrypt2(C,B).

decrypt2(A,B):-

head(B,C),
decrypt3(A,C).

decrypt3(A,B):-

char_to_int(A,C),
decrypt4(C,B).

decrypt4(A,B):-

prec(A,C),
int_to_char(C,B),

decrypt5(A,B):-

tail(A,C),
decrypt6(C,B).

decrypt6(A,B):-

tail(B,C),
decrypt(A,C).

(a)

decrypt(A,B):-

map(A,B,decrypt1).

decrypt1(A,B):-

char_to_int(A,C),
decrypt2(C,B).

decrypt2(A,B):-

prec(A,C),
int_to_char(C,B).

(b)

Fig. 4: Decryption programs. Figure (a) shows a ﬁrst-order program represented in (cid:77) 2
2 .
Figure (b) shows a higher-order program represented in (cid:77) 2
2 with one extra higher-order
variable (the third argument of map/3).

3 Success set equivalent when restricted to the target predicate decrypt/2. The success set of a logic
program P is the set of ground atoms {A ∈ hb(P)|P ∪{¬A} has a SLD-refutation}, where hb(P) represents
the Herband base of the logic program P. The success set restricted to a speciﬁc predicate symbol p is
the subset of the success set restricted to atoms of the predicate symbol p.

12

4 Algorithms

Andrew Cropper et al.

We now introduce Metagolho and HEXMILho, both of which implement abstracted MIL
and which extend Metagol and HEXMIL respectively. For self-containment, we also de-
scribe Metagol and HEXMIL.

4.1 Metagol

Metagol [9] is a MIL learner based on a Prolog meta-interpreter. Figure 5 shows Metagol’s
learning procedure described using Prolog. Metagol works as follows. Given a set of
atoms representing positive examples, Metagol tries to prove each atom in turn. Metagol
ﬁrst tries to deductively prove an atom using compiled BK by delegating the proof to Pro-
log (call(Atom)), where the compiled BK contains standard Prolog deﬁnitions. Metagol
uses prim statements to allow a user to specify what predicates are part of the com-
piled BK. Prim statements of the form prim(P/A), where P is a predicate symbol and A
is the associated arity, and are similar to determinations used by Aleph [41], except that
Metagol only requires prim statements for predicates that may appear in the body. If
this deductive step fails, Metagol tries to unify the atom with the head of a metarule
(metarule(Name,Subs,(Atom:-Body))) and tries to bind the existentially quantiﬁed
higher-order variables in a metarule to symbols in the predicate signature, where Subs
contains the substitutions. Metagol saves the resulting substitutions and tries to prove
the body of the metarule. After proving all atoms, a Prolog program is formed by project-
ing the substitutions onto their corresponding metarules. Metagol checks the consistency
of the learned program with the negative examples. If the program is inconsistent, then
Metagol backtracks to explore different branches of the SLD-tree.

Metagol uses iterative deepening to ensure that the ﬁrst consistent hypothesis re-
turned has the minimal number of clauses. The search starts at depth 1. At depth d the
search returns a consistent hypothesis with at most d clauses if one exists; otherwise
it continues to depth d + 1. At each depth d, Metagol introduces d − 1 new predicate
symbols4.

4.2 Metagolho

Figure 6 shows the Prolog code for Metagolho. The key difference between Metagolho and
Metagol is the introduction of the second prove_aux/3 clause in the meta-interpreter,
denoted in boldface. This clause allows Metagolho to prove an atom by fetching a clause
from the IBK (such as map/3) whose head uniﬁes with a given atom. The distinction
between compiled and interpreted BK is that whereas a clause from the compiled BK
is proved deductively by calling Prolog, a clause from the IBK is proved through meta-
interpretation. Meta-interpretation allows for predicate invention to be driven by the
proof of conditions (as in filter/3) and functions (as in map/3). IBK is different to
metarules because the clauses are all universally quantiﬁed and, importantly, does not

4 Metagol forms new predicate symbols by taking the name of the task and adding underscores and
numbers. For example, if the task is f and the depth is 4 then Metagol will add the predicate symbols
f_3, f_2, and f_1 to the predicate signature. Note that in this paper we remove the underscore symbols
from any learned programs to save space, but the experimental code contains the original underscore
symbols.

Learning higher-order logic programs

13

learn(Pos,Neg,Prog):-

prove(Pos,[],Prog),
\+ prove(Neg,Prog,Prog).

prove([],Prog,Prog).
prove([Atom|Atoms],Prog1,Prog2):-

prove_aux(Atom,Prog1,Prog3),
prove(Atoms,Prog3,Prog2).

prove_aux(Atom,Prog,Prog):-

prim(Atom),!,
call(Atom).

prove_aux(Atom,Prog1,Prog2):-

member(sub(Name,Subs),Prog1),
metarule(Name,Subs,(Atom:-Body)),
prove(Body,Prog1,Prog2).

prove_aux(Atom,Prog1,Prog2):-

metarule(Name,Subs,(Atom:-Body)),
prove(Body,[sub(Name,Subs)|Prog1],Prog2).

Fig. 5: Metagol’s learning procedure described using Prolog. Note that this code is the
barebones code for Metagol and the actual code differs. The actual code has slightly
different syntax and includes more code, such as code to perform the iterative deepening
and code to invent new predicate symbols. For instance, in this Figure prim(Atom) is not
of the form prim(P/A), as described in the text.

require any substitutions. By contrast, metarules contain existentially quantiﬁed vari-
ables whose substitutions form the hypothesised program. Figure 7 shows examples of
the three forms of BK used by Metagolho.

Metagolho works in the same way as Metagol except for the use of IBK. Metagolho
ﬁrst tries to prove an atom deductively using compiled BK by delegating the proof to
Prolog (call(Atom)), exactly how Metagol works. If this step fails, Metagolho tries to
unify the atom with the head of a clause in the IBK (ibk((Atom:-Body))) and tries to
prove the body of the matched deﬁnition. Metagol does not perform this additional step.
Failing this, Metagolho continues to work in the same way as Metagol. Metagolho uses
negation as failure [5] to negate predicates in the compiled BK. Negation of invented
predicates is unsupported and is left for future work5.

To illustrate the difference between Metagol and Metagolho, suppose you have com-
piled BK containing the succ/2, int_to_char/2, and map/3 predicates and the curry1
(P(A, B) ← Q(A, B, R)) and chain (P(A, B) ← Q(A, C), R(C, B)) metarules. Suppose you
are given the examples f([1,2,3],[c,d,e]) and f([1,2,1],[c,d,c]) where the un-
derlying target hypothesis is to add two to each element of the list and ﬁnd the cor-
responding letter in an a-z index. Given these examples Metagol would try to prove
each atom in turn. Metagol cannot prove any example using only the compiled BK so it
would need to use a metarule. Suppose it uniﬁes the atom f([1,2,3],[c,d,e]) with
the curry metarule. Then the new atom to prove would be Q([1,2,3],[c,d,e],R).

5 Metagol could support the negation of invented predicates but it is non-trivial to efﬁciently negate
an invented predicate that itself contains an invented predicate. This limitation could be addressed by
allowing Metagol to alternatively perform a generate and test approach. However, a generate-and-test
approach is impractical for non-trivial situations.

14

Andrew Cropper et al.

learn(Pos,Neg,Prog):-

prove(Pos,[],Prog),
\+ prove(Neg,Prog,Prog).

prove([],Prog,Prog).
prove([Atom|Atoms],Prog1,Prog2):-

prove_aux(Atom,Prog1,Prog3),
prove(Atoms,Prog3,Prog2).

prove_aux(Atom,Prog,Prog):-

prim(Atom),!,
call(Atom).

prove_aux(Atom,Prog1,Prog2):-

ibk((Atom:-Body)),
prove(Body,Prog1,Prog2).

prove_aux(Atom,Prog1,Prog2):-

member(sub(Name,Subs),Prog1),
metarule(Name,Subs,(Atom:-Body)),
prove(Body,Prog1,Prog2).

prove_aux(Atom,Prog1,Prog2):-

metarule(Name,Subs,(Atom:-Body)),
prove(Body,[sub(Name,Subs)|Prog1],Prog2).

Fig. 6: Prolog code for Metagolho.

To prove this atom Metagol could unify map/3 with Q and then try to prove the atom
map([1,2,3],[c,d,e],R). However, the proof of map([1,2,3],[c,d,e],R) would fail
because there is no suitable substitution for R. The only possible substitution for R is
succ/2, which will clearly not allow the proof to succeed. The only way Metagol can
learn a consistent hypothesis is by successively chaining calls to map(A,B,succ) and
map(A,B,int_to_char) using the chain metarule to learn:

f(A,B):-f1(A,C),f3(C,B)
f1(A,B):-f2(A,C),f2(C,B).
f2(A,B):-map(A,B,succ).
f3(A,B):-map(A,B,int_to_char).

By contrast, suppose we had the same setup for Metagolho but we allowed map/3 to be de-
ﬁned as IBK. In this case, Metagolho would unify the atom f([1,2,3],[c,d,e]) with the
curry1 metarule. The new atom to prove would therefore be Q([1,2,3],[c,d,e],R). In
contrast to Metagol, Metagolho can unify this atom with map/3 deﬁned as IBK. Metagolho
will then try to prove map([1,2,3],[c,d,e],R) through meta-interpretation. This step
would result in a sequence of new atoms to prove R(1,c), R(2,d), R(3,e). These
new atoms can also be proven though meta-interpretation which allows for Metagolho
to invent and deﬁne the suitable symbol for R. Therefore, in this scenario, Metagol would
learn:

f(A,B):-map(A,B,f1).
f1(A,B):-succ(A,C),f2(C,B).
f2(A,B):-succ(A,C),int_to_char(C,B).

Learning higher-order logic programs

15

empty([]).
head([H|_],H).
tail([_|T],T).
last([A],A):-!.
last([_|T],A):-last(T,A).

Compiled BK

ibk(([map,[],[],F]:-[])).
ibk(([map,[A|As],[B|Bs],F]:-[[F,A,B],[map,As,Bs,F]])).
ibk(([fold,[],Acc,Acc,F]:-[])).
ibk(([fold,[A|As],Acc1,B,F]:-[[F,A,Acc1,Acc2],[fold,As,Acc2,B,F]])).
ibk([ifthenelse,A,B,Cond,Then,_],[[Cond,A],[Then,A,B]]).
ibk([ifthenelse,A,B,Cond,_,Else],[[not,Cond,A],[Else,A,B]]).

Interpreted BK

metarule(monadic,[P,Q],([P,A,A]:-[[Q,A]])).
metarule(identity,[P,Q],([P,A,B]:-[[Q,A,B]])).
metarule(inverse,[P,Q],([P,A,B]:-[[Q,B,A]])).
metarule(didentity,[P,Q],([P,A,B]:-[[Q,A,B],[R,A,B]])).
metarule(precon,[P,Q,R],([P,A,B]:-[[Q,A],[R,A,B]])).
metarule(postcon,[P,Q,R],([P,A,B]:-[[Q,A,B],[R,B]])).
metarule(curry1,[P,Q,R],([P,A,B]:-[[Q,A,B,R]])).
metarule(curry2,[P,Q,R,S],([P,A,B]:-[[Q,A,B,R,S]])).
metarule(curry3,[P,Q,R,S,T],([P,A,B]:-[[Q,A,B,R,S,T]])).
metarule(chain,[P,Q,R],([P,A,B]:-[[Q,A,C],[R,C,B]])).
metarule(tailrec,[P,Q],([P,A,B]:-[[Q,A,C],[P,C,B]])).

Metarules

Fig. 7: Three forms of BK used by Metagolho described in Prolog syntax. The curry rules
are slightly unusual but are necessary to use the interpreted BK (e.g. curry1 allows us to
use the map/3 deﬁnition).

As this scenario illustrates, the real power and novelty of Metagolho is the combination
of abstraction (learning higher-order programs) and invention (predicate invention). In
this scenario, abstraction has allowed the atom Q([1,2,3],[c,d,e],R) to be decom-
posed into the sub-problems R(1,c), R(2,d), R(3,e). Further abstraction and in-
vention allows for Metagolho to solve these sub-problems by inventing and deﬁning the
necessary predicate for R. By successively interleaving these two steps, Metagolho sup-
ports the invention of conditions and functions to an arbitrary depth, which goes beyond
anything in the literature.

4.3 HEXMIL

Before describing HEXMILho, which supports learning higher-order logic programs, ﬁrst
we discuss HEXMIL, on which HEXMILhois based.

16

Andrew Cropper et al.

HEXMIL is an answer set programming (ASP) encoding of MIL introduced by Kamin-
ski et al. [23]. Whereas Metagol searches for a proof (and thus a program) using a
meta-interpreter and SLD-resolution, HEXMIL searches for a proof by encoding the MIL
problem as an ASP problem. As argued by Kaminski et al., an ASP implementation can be
more efﬁcient than a Prolog implementation because ASP solvers employ efﬁcient con-
ﬂict propagation, which is important for detecting the derivability of negative examples
early during ASP search.

The HEXMIL encoding speciﬁes constraints on possible hypotheses derived from the
examples, in addition to rules specifying the available BK. An ASP solver performs a com-
binatorial search for solutions satisfying these constraints. ASP solvers typically work in
two phases: (1) a grounding phase, where rules are grounded, and (2) a solving phase,
where reasoning on (propositional) rules leads to answer sets [19]. A straightforward
ASP encoding of the MIL problem is infeasible in many cases, for reasons such as the
grounding bottleneck of ASP and the difﬁculty in manipulating complex structures such
as lists [23]. To mitigate these difﬁculties HEXMIL uses the HEX formalism [13] which
allows ASP programs to interface with external sources. External sources are predicate
deﬁnitions given by programs outside of the ASP language. For instance, HEXMIL inter-
faces with external sources described as a Python program. HEX programs can access
these deﬁnitions via external atoms. HEXMIL beneﬁts from external atoms by allowing
for arbitrary encodings of complex structures (e.g. we encode lists as strings, thereby re-
ducing the number of variables needed in the encoding). Another beneﬁt is that external
atoms allow for the incremental introduction of new constants (i.e. symbols not in the
initial ASP program).

To improve efﬁciency, Kaminski et al. introduced a forward-chained HEXMIL-encoding

which requires forward-chained metarules:

Deﬁnition 7 (Forward-chained metarule) A metarule is forward-chained when it can
be written in the form:

P(A, B) ← Q1

(A, C1

), Q2

(C1, C2

), . . . , Qi

(Ci−1, B), R1

(D1

), . . . , R j

(Dj

)

where D1, . . . , Dj are all contained in {A, C1, . . . , Ci−1, B}.

In the forward-chained HEXMIL encoding, compiled (ﬁrst-order) BK is encoded using the
external atoms &bkUnary[P,A]() and &bkBinary[P,A](B). These two atoms represent
all BK predicates of the form P(A) and P(A,B), where P and A are input arguments to
the external source and B is an output argument. Using the input/output ordering of the
external binary atoms, grounding of variables in forward-chained metarules occurs from
left to right. HEXMIL uses the forward-chained encoding:

deduced(P,A) ← &bkUnary[P,A](), state(A)
deduced(P,A,B) ← &bkBinary[P,A](B), state(A)
state(A) ← for each P(A,B) ∈ E+ ∪ E−
state(B) ← deduced(P,A,B)

HEXMIL uses the deduced predicate to represent facts that hypotheses could entail. In
this encoding, the import of BK is guarded by the predicate state/1. A solution for MIL
problem (Deﬁnition 4) must entail all positive examples (i.e ground atoms). Therefore,
in HEXMIL, every positive examples must appear in the head of a grounded metarule. It
follows that ground terms in atoms can be seen as the states that can be reached from
the examples. Therefore, HEXMIL initially marks the ground terms that appear in the

Learning higher-order logic programs

17

examples as state. As new ground terms are introduced by the external atoms, HEXMIL
marks these values as state as well.

To support metarules HEXMIL employs two encoding rules. The ﬁrst rule encodes the
possible instantiations of a metarule. Let mr be the name of an arbitrary forward-chained
metarule (Def. 7), then for each such metarule, the ﬁrst encoding rule is:

met a(mr, P, Q1, . . . , Qi, R1, . . . , R j
), . . . , si g(Qi

si g(P), si g(Q1
or d(P, Q1
deduced(Q1, A, C1
deduced(R1, D1

), . . . , or d(P, Qi

), . . . , deduced(Qi, Ci−1, B),

), . . . , deduced(R j, Dj

)

) ∨ neg_met a(mr, P, Q1, . . . , Qi, R1, . . . , R j
), . . . , si g(R j
), si g(R1
),
), . . . , or d(P, R j
), or d(P, R1

),

) ←

Note that the head in this rule allows for choosing whether to deduce the metarule
instantiation. Also note that the disjunction in the head means that this is not a Horn
clause, yet it encodes a Horn clause metarule. This encoding rule relies on two other
rules:

sig(p) ← for each p ∈ (cid:80)
ord(p,q) ← for all p,q ∈ (cid:80) s.t. p (cid:22) q

The si g relation denotes predicate symbols available, both invented and given as part
of the BK. The or d relation denotes an ordering (cid:22) over the predicate symbols. This
ordering disallows certain instantiations6, e.g. recursive instantiations.

The second metarule encoding allows for metarule instantiations to be generated in

order to derive facts:

deduced(P, A, B) ←

met a(mr, P, Q1, . . . , Qi, R1, . . . , R j
deduced(Q1, A, C1
deduced(R1, D1

), . . . , deduced(R j, Dj

), . . . , deduced(Qi, Ci−1, B),

),

)

The generation of metarule instantiations are then checked by the solver for consistency
with the examples. This checking step relies on constraints derived from positive and
negative examples:

← not deduce(P, A, B) for each P(A, B) ∈ E+
← deduce(P, A, B) for each P(A, B) ∈ E−

Similar to Metagol, HEXMIL searches for solutions using iterative deepening on the num-
ber of allowed metarule instantiations and the number of predicate symbols. We omit
the details of the ASP constraints that restrict the number of metarule instantiations.

4.4 HEXMILho

We now describe the extension of HEXMIL to HEXMILho, which adds support for higher-
order deﬁnitions, i.e. interpreted background knowledge (IBK). This extension allows
HEXMIL to search for programs in abstracted forward-chained hypothesis spaces. To ex-
tend HEXMIL, we introduce a new predicate i bk to encode the higher-order atoms that
occur in IBK. Note that i bk is a normal ASP predicate and not an external atom. This

6 Details on the (cid:22)-relation can be found in the paper on HEXMIL [23] as well as in the ﬁles on our

experimental work.

18

Andrew Cropper et al.

predicate allows us to encode higher-order clauses as a mix of deduced atoms for ﬁrst-
order predicates and i bk atoms for those that involve predicates as arguments.

Let the following be a clause of an arbitrary (forward-chained) higher-order deﬁni-

tion:

h(A, B, P0,1, . . . , P0,k0

) ← h1

(A, C1, P1,1, . . . , P1,k1

), . . . , h j

(C j−1, B, Pj,1, . . . , Pj,k j

)

Every atom in this clause can have 0 ≤ ki higher-order terms. The higher-order clauses
(cid:54)= 0. For each clause in a higher-order
of the deﬁnition will have at least one atom with ki
= B:
deﬁnition we give a rule encoding the clause, where C0

= A and C j

i bk(h, A, B, P0,1, . . . , P0,k0

) ←

st at e(A),
), . . . , si g(P0,k0
si g(P0,1
i bk(hi, Ci−1, Ci, Pi,1, . . . , Pi,ki
deduced(hi, Ci−1, Ci

),

)

), si g(Pi,1

), . . . , si g(Pi,ki

)

if ki
if ki

> 0
= 0

Figure 8 shows an example of this encoding for the until/4 predicate. Figure 8 also con-
tains a deﬁnition for map/3 (which is slightly more involved). This approach to higher-
order deﬁnitions also applies to metarules involving higher-order atoms. For instance,
Figure 8 also shows the encoding of the curry2 metarule.

Our extension is sufﬁcient7 to learn higher-order programs. Note that in this set-
ting higher-order deﬁnitions are required to be forward-chained in their ﬁrst-order ar-
guments, meaning that left-to-right grounding of these arguments is still valid. The re-
maining (higher-order) arguments can be ground by the si g predicate, which contains
all the predicate names. As predicate symbols were already arguments in the HEXMIL
encoding, we can easily make a predicate argument occur as an atom’s predicate symbol,
e.g. see the variable F in until/4 and map/3 in Figure 8.

4.5 Complexity of the search

The experiments in the next section use both Metagol and HEXMIL, and their higher-
order extensions. The purpose of the experiments is to test our claim that learning higher-
order programs, rather than ﬁrst-order programs, can improve learning performance.
Although we do not directly compare them, the experimental results show a signiﬁcant
difference in the learning performances of Metagol and HEXMIL, and their higher-order
variants. The experimental results also show that HEXMIL and HEXMILho do not scale
well, both in terms of the amount of BK and the number of training examples. To help ex-
plain these results, we now contrast the theoretical complexity of Metagol and HEXMIL.
For simplicity we focus on the (cid:77) 2
2 hypothesis space, although our results can easily be
generalised. Our main observation is that the performance of HEXMIL is a function of
the number of constant symbols, which is not the case for Metagol.

From Proposition 1 it follows that the (cid:77) 2

2 MIL hypothesis space contains at most
(mp3)n programs. For Metagol, this bound is an over-approximation on the number of
programs that will be considered during the search. Given a training example, Metagol
learns a program by trying different substitutions for the existentially quantiﬁed pred-
icate symbols in metarules, where the search is driven by the example. Metagol only

7 Kaminski, et al. [23] proposed an additional ﬁrst-order state-abstraction encoding that improved the

efﬁciency of the learning. It is currently unclear as how to integrate IBK into this encoding.

Learning higher-order logic programs

19

meta(curry2,P,Q,R,S) ∨ neg_meta(curry2,P,Q,R,S):-

sig(P),sig(Q),sig(R),sig(S),
ord(P,Q),ord(P,R),ord(P,S),
ibk(Q,A,B,R,S).

deduced(P,A,B):-

meta(curry2,P,Q,R,S),
ibk(Q,A,B,R,S).

curry2 metarule

ibk(until,A,A,Cond,F):-

state(A),
sig(Cond),
sig(F),
deduced(Cond,A).
ibk(until,A,B,Cond,F):-

state(A),
sig(Cond),
sig(F),
not deduced(Cond,A),
deduced(F,A,C),
ibk(until,C,B,Cond,F).

until/4

ibk(map,"[]","[]",F):-

sig(F).

ibk(map,L1,L2,F):-
state(L1),
sig(F),
deduced(head,L1,H1),
deduced(tail,L1,T1),
deduced(F,H1,H2),
ibk(map,T1,T2,F),
&prepend[H2,T2](L2).

map/3

Fig. 8: HEXMILho code examples. The "[]" symbol in the map/3 deﬁnition is special syntax
we use to represent lists. Note that due to lists being encoded as strings, the prepend
external atom is required to manipulate the lists in the map/3 deﬁnition.

considers constants that it encounters when it evaluates whether a hypothesis covers an
example, in which case it only considers the constant symbols pertaining to that particu-
lar example (in fact it delegates this step to Prolog). It follows that the search complexity
of Metagol is independent of the number of constant symbols and is the same8 as Propo-
sition 1.

By contrast, HEXMIL searches for a program by instantiating metarules in a bottom-
up manner where the body atoms of metarules need to be grounded. This approach
means that the number of options that HEXMIL considers is not only a function of the
number of metarules and predicate symbols (as is the case for Metagol), but it is also a
function of the number of constant symbols because it needs to ground the ﬁrst-order
variables in a metarule. Even in the more efﬁcient forward-chained MIL encoding, which
incrementally imports new constants, body atoms are ground using many constant sym-
bols unrelated to the examples. Any constant that can be marked as a state will be used
to ground atoms. Therefore, the search complexity of HEXMIL is bounded by (mp3c6)n,

8 Metagol is sensitive to the size of the examples and to the computational complexity of a hypothesis
because, as Schapire showed [40], if checking whether a hypothesis H covers an example e cannot be
performed in time polynomial in the size of e and H then H cannot be learned in time polynomial in the
size of e and H, i.e. Metagol needs to execute a learned program on the example.

20

Andrew Cropper et al.

where m is the number of metarules, p is the number of predicate symbols, n is a maxi-
mum program size, and c is the number of constant symbols.

For simplicity, the above complexity reasoning was for the ﬁrst-order systems. We

can easily apply the same reasoning to the abstracted MIL setting.

5 Experiments

Our main claim is that compared to learning ﬁrst-order programs, learning higher-order
programs can improve learning performance. Theorem 1 supports this claim and shows
that, compared to unabstracted MIL, abstraction in MIL reduces sample complexity pro-
portional to the reduction in the number of clauses required to represent hypotheses. We
now experimentally9 explore this result. We describe four experiments which compare
the performance when learning ﬁrst-order and higher-order programs. We test the null
hypotheses:

Null hypothesis 1 Learning higher-order programs cannot improve predictive accura-

cies

Null hypothesis 2 Learning higher-order programs cannot reduce learning times

To test these hypotheses we compare Metagol with Metagolho and HEXMIL with HEXMILho,
i.e. we compare unabstracted MIL with abstracted MIL.

5.1 Common materials

In the Prolog experiments we use the same metarules and IBK in each experiment, i.e.
the only variable in the Prolog experiments is the system (Metagol or Metagolho). We use
the metarules shown in Figure 7. We use the higher-order deﬁnitions map/3, until/4,
and ifthenelse/5 as IBK. We run the Prolog experiments using SWI-Prolog 7.6.4 [43].
We tried to use the same experimental methodology in the ASP HEXMIL experiments
as in the Prolog experiments but HEXMIL failed to learn any programs (ﬁrst or higher-
order) because of scalability issues. Therefore, in each ASP experiment we use the exact
metarules and background relations necessary to represent the target hypotheses. We run
the ASP experiments using Hexlite 1.0.010. We run Hexlite with the ﬂpcheck disabled.
We also set Hexlite to enumerate a single model.

5.2 Robot waiter

Imagine teaching a robot to pour tea and coffee at a dinner table, where each setting
has an indication of whether the guest prefers tea or coffee. Figure 9 shows an example
in terms of initial and ﬁnal states. This experiment focuses on learning a general robot
waiter strategy [7] from a set of examples.

9 All the experimental code and materials, including the code for Metagol, HEXMIL, and their higher-

order extensions, is available at https://github.com/andrewcropper/mlj19-metaho
10 https://github.com/hexhex/hexlite

Learning higher-order logic programs

21

(a) Initial state

(b) Final state

Fig. 9: Figures (a) and (b) show initial/ﬁnal state waiter examples respectively. In the
initial state, the cups are empty and each guest has a preference for tea (T) or coffee (C).
In the ﬁnal state, the cups are facing up and are full with the guest’s preferred drink.

5.2.1 Materials

Examples are f/2 atoms where the ﬁrst argument is the initial state and the second is
the ﬁnal state. A state is a list of ground Prolog atoms. In the initial state, the robot starts
at position 0, there are d cups facing down at positions 0, . . . , d − 1; and for each cup
there is a preference for tea or coffee. In the ﬁnal state, the robot is at position d; all the
cups are facing up; and each cup is ﬁlled with the preferred drink. We allow the robot
to perform the ﬂuents and actions (deﬁned as compiled BK) shown in Figure 10.

at_end/1
wants_coffee/1
move_right/2
pour_tea/2

wants_tea/1
move_left/2
turn_cup_over/2
pour_coffee/2

Fig. 10: Compiled BK in the robot waiter experiment. We omit the deﬁnitions for brevity.

We generate positive examples as follows. For the Prolog experiments, for the initial state
we select a random integer d from the interval [1, 20] as the number of cups. For the
ASP experiments the interval is [1, 5]. For each cup, we randomly select whether the
preferred drink is tea or coffee and set it facing down. For the ﬁnal state, we update
the initial state so that each cup is facing up and is ﬁlled with the preferred drink. To
generate negative examples, we repeat the aforementioned procedure but we modify
the ﬁnal state so that the drink choice is incorrect for a random subset of k > 0 drinks.

5.2.2 Method

Our experimental method is as follows. For each learning system s and for each m in
{1, 2, . . . , 10}:

1. Generate m positive and m negative training examples
2. Generate 1000 positive and 1000 negative testing example
3. Use s to learn a program p using the training examples
4. Measure the predictive accuracy of p using the testing examples

If no program is found in 10 minutes then we deem that every testing example is false.
We measure mean predictive accuracies, mean learning times, and standard errors of
the mean over 10 repetitions.

TTCTC22

5.2.3 Results

Andrew Cropper et al.

Figure 11 shows that in all cases Metagolho learns programs with higher predictive ac-
curacies and lower learning times than Metagol. Figure 12 shows similar results when
comparing HEXMIL with HEXMILho. We can explain these results by looking at example
programs learned by Metagol and Metagolho shown in Figures 13 and 14 respectively. Al-
though both programs are general and handle any number of guests and any assignment
of drink preferences, the program learned by Metagolho is smaller than the one learned
by Metagol. Whereas Metagol learns a recursive program, Metagolho avoids recursion
and uses the higher-order abstraction until/4. The abstraction until/4 essentially re-
moves the need to learn a recursive two clause deﬁnition to move along the dinner table.
Likewise, Metagolho uses the abstraction ifthenelse/5 to remove the need to learn two
clauses to decide which drink to pour. The compactness of the higher-order program
affects predictive accuracies because, whereas Metagolho almost always ﬁnds the tar-
get hypothesis in the allocated time, Metagol often struggles because the programs are
too large, as explained by our theoretical results in Section 3.3. The results from this
experiment suggest that we can reject null hypotheses 1 and 2.

Although we are not directly comparing the Prolog and ASP implementations of MIL,
it is interesting to note that despite having more irrelevant BK, more irrelevant metarules,
and having larger training instances, Metagolho outperforms HEXMILho in all cases, both
in terms of predictive accuracies and learning times. Figure 12 also shows that both
HEXMIL and HEXMILho do not scale well in the number of training examples, especially
the learning times. Our results in Section 4.5 help explain the poor scalability of HEXMIL
and HEXMILho because more training examples typically means more constant symbols
which in turn means a larger search complexity for both HEXMIL and HEXMILho, al-
though this issue can be mitigated using state abstraction [23].

100

80

)

%

(

y
c
a
r
u
c
c
A

60

40

20

0

2

400

300

200

s
d
n
o
c
e
S

100

0

2

Metagol
Metagolho
default

4

6

8

10

12

14

16

18

20

No. training examples

(a) Predictive accuracies

Metagol
Metagolho

4

6

8

10

12

14

16

18

20

No. training examples

(b) Learning times

Fig. 11: Prolog robot waiter experiment results which show learning performance when
varying the number of training examples.

Learning higher-order logic programs

23

100

80

)

%

(

y
c
a
r
u
c
c
A

60

40

20

0

2

600

400

s
d
n
o
c
e
S

200

HEXMIL
HEXMILho
default

HEXMIL
HEXMILho

4

6

8

10

12

14

16

18

20

0

2

4

6

8

10

12

14

16

18

20

No. training examples

(a) Predictive accuracies

No. training examples

(b) Learning times

Fig. 12: ASP robot waiter experiment results which show learning performance when
varying the number of training examples.

f(A,B):-turn_cup_over(A,C),f1(C,B).
f1(A,B):-move_right(A,B),at_end(B).
f1(A,B):-f2(A,C),f1(C,B).
f2(A,B):-wants_coffee(A),pour_coffee(A,B).
f2(A,B):-move_right(A,C),turn_cup_over(C,B).
f2(A,B):-wants_tea(A),pour_tea(A,B).

Fig. 13: An example ﬁrst-order waiter program learned by Metagol.

f(A,B):-until(A,B,at_end,f1).
f1(A,B):-turn_cup_over(A,C),f2(C,B).
f2(A,B):-f3(A,C),move_right(C,B).
f3(A,B):-ifthenelse(A,B,wants_coffee,pour_coffee,pour_tea).

Fig. 14: An example higher-order waiter program learned by Metagolho.

5.3 Chess strategy

Programming chess strategies is a difﬁcult task for humans [3]. For example, consider
maintaining a wall of pawns to support promotion [21]. In this case, we might start by
trying to inductively program the simple situation in which a black pawn wall advances
without interference from white. Figure 15 shows such an example, where in the initial
state the pawns are at different ranks and in the ﬁnal state all the pawns have advanced
to rank 8 but the other pieces have remained in the initial positions. In this experiment,
we try to learn such strategies.

5.3.1 Materials

Examples are f/2 atoms where the ﬁrst argument is the initial state and the second is
the ﬁnal state. A state is a list of pieces, where a piece is denoted as a tuple of the form
(Type,Id,X,Y), where Type is the type (king=k, pawn=p, etc.), Id is a unique identiﬁer,

24

Andrew Cropper et al.

(a) Initial state

(b) Final state

Fig. 15: Chess initial/ﬁnal state example.

X is the ﬁle, and Y is the rank. We generate a positive example as follows. For the initial
state for the Prolog experiments, we select a random subset of n pieces from the interval
[1, 16] and randomly place them on the board. For the ASP experiments the interval
is [1, 5]. For the ﬁnal state, we update the initial state so that each pawn ﬁnishes at
rank 8. To generate negative examples, we repeat the aforementioned procedure but we
randomise the ﬁnal state positions whilst ensuring that the input/output pair is not a
positive example. We use the compiled BK shown in Figure 16.

rank8((_,_,_,8)).
not_rank8(A):-
\+rank8(A).

pawn((p,_,_,_)).
not_pawn(A):-
\+pawn(A).
head([A|_],A).
tail([_|T],T).
empty([]).
hold(A,A).
forward((Type,Id,X,Y1),(Type,Id,X,Y2)):-

Y1 < 8,
Y2 is Y1+1.

Fig. 16: Compiled BK used in the chess experiment.
.

5.3.2 Method

The experimental method is the same as in Experiment 1.

5.3.3 Results

Figure 17 shows that in all cases Metagolho learns programs with higher predictive ac-
curacies and lower learning times than Metagol. Figure 17 shows that Metagolho learns
programs approaching 100% accuracy after around six examples. By contrast, Metagol

Learning higher-order logic programs

25

learns programs with around default accuracy. Figure 18 shows similar results when
comparing HEXMIL with HEXMILho. The poor performance of Metagol and HEXMIL is
because they both rarely ﬁnd solutions in the allocated time. By contrast, Metagolho and
HEXMILho typically learn programs within two seconds.

We can again explain the performance discrepancies by looking at example learned
programs in Figure 19. Figure 19b shows the compact higher-order program typically
learned by Metagolho. This program is compact because it uses the abstractions map/3
and until/4, where map/3 decomposes the problem into smaller sub-goals of moving a
single piece to rank eight and until/4 solves the sub-problem of moving a pawn to rank
eight. These sub-goals are solved by the invented f1/2 predicate. By contrast, Figure 19a
shows the large target ﬁrst-order program that Metagol struggled to learn. As shown in
Proposition 1, the MIL hypothesis space grows exponentially in the size of the target
hypothesis, which is why the larger ﬁrst-order program is more difﬁcult to learn. The
results from this experiment suggest that we can reject null hypotheses 1 and 2.

100

80

)

%

(

y
c
a
r
u
c
c
A

60

40

20

0

2

600

Metagol
Metagolho

400

s
d
n
o
c
e
S

200

Metagol
Metagolho
default

4

6

8

10

12

14

16

18

20

0

2

4

6

8

10

12

14

16

18

20

No. training examples

(a) Predictive accuracies

No. training examples

(b) Learning times

Fig. 17: Prolog chess experimental results which show predictive accuracy when varying
the number of training examples. Note that Metagolho typically learns a program in under
two seconds.

5.4 Droplast

In this experiment, the goal is to learn a program that drops the last element from each
sublist of a given list-of-lists – a problem frequently used to evaluate program induction
systems [25]. In this experiment, we try to learn a program that drops the last character
from each string in a list of strings. Figure 20 shows input/output examples for this
problem described using the f/2 predicate.

5.4.1 Materials

Examples are f/2 atoms where the ﬁrst argument is the initial list and the second is the
ﬁnal list. We generate positive examples as follows. For the Prolog experiments, to form
the input, we select a random integer i from the interval [1, 10] as the number of sublists.

26

100

80

)

%

(

y
c
a
r
u
c
c
A

60

40

20

0

2

Andrew Cropper et al.

600

HEXMIL
HEXMILho

400

s
d
n
o
c
e
S

200

HEXMIL
HEXMILho
default

4

6

8

10

12

14

16

18

20

0

2

4

6

8

10

12

14

16

18

20

No. training examples

(a) Predictive accuracies

No. training examples

(b) Learning times

Fig. 18: ASP chess experimental results which show predictive accuracy when varying the
number of training examples. Note that HEXMILho typically learns a program in under
two seconds.

f(A,A):-empty(A).
f(A,B):-f1(A,B),f4(A,B).
f(A,B):-f7(A,B),f4(A,B).
f1(A,B):-f2(A,C),head(B,C).
f2(A,B):-f3(A,C),f6(C,B).
f3(A,B):-head(A,B),pawn(B).
f4(A,B):-f5(A,C),tail(B,C).
f5(A,B):-tail(A,C),f(C,B).
f6(A,A):-rank8(A).
f6(A,B):-forward(A,C),f6(C,B).
f7(A,B):-f8(A,C),head(B,C).
f8(A,B):-head(A,B),not_pawn(B).

(a)

f(A,B):-map(A,B,f1).
f1(A,B):-not_pawn(A),hold(A,B).
f1(A,B):-until(A,B,rank8,forward).

(b)

Fig. 19: Figure (a) shows the target ﬁrst-order chess program, which Metagol could not
learn within 10 minutes. Figure (b) shows the higher-order program often learned by
Metagolho. The higher-order program is clearly smaller than the ﬁrst-order program,
which is why Metagolho could typically learn it within a couple of seconds.

For each sublist i, we select a random integer k from the interval [1, 10] and then sample
with replacement a sequence of k letters from the alphabet a-z to form the sublist i. To
form the output, we wrote a Prolog program to drop the last element from each sublist.
For the ASP experiments the interval for i and k is [1, 5].We generate negative examples
using a similar procedure, but instead of dropping the last element from each sublist, we
drop j random elements (but not the last one) from each sublist, where 1 < j < k. We
use the compiled BK shown in Figure 21.

Learning higher-order logic programs

27

f([alice,bob,carol],[alic,bo,caro]).
f([inductive,logic,programming],[inductiv,logi,programmin]]).
f([ferrara,orleans,london,kyoto],[ferrar,orlean,londo,kyot]).

Fig. 20: Examples of the droplast problem. Note that in the experimental code we treat
strings as lists of individual symbols, e.g. alice is represented as [a,l,i,c,e].

head([H|_],H).
tail([_|T],T).
empty([]).
reverse(A,B):- ...

Fig. 21: Compiled BK used in the droplast experiment.

5.4.2 Method

The experimental method is the same as in Experiment 1.

5.4.3 Results

Figure 22 shows that Metagolho achieved 100% accuracy after two examples at which
point it learned the program shown in Figure 24a. This program again uses abstractions
to decompose the problem. The predicate f/2 maps over the input list and applies f1/2 to
each sublist to form the output list, thus abstracting away the reasoning for iterating over
a list. The invented predicate f1/2 drops the last element from a single list by reversing
the list, calling tail/2 to drop the head element, and then reversing the shortened list
back to the original order. By contrast, Metagol was unable to learn any solutions because
the corresponding ﬁrst-order program is too long and the search is impractical, similar
to the issues in the chess experiment.

Figure 23 shows slightly unexpected results for the ASP experiment. The ﬁgure shows
that HEXMILho learns programs with higher predictive accuracies than HEXMIL when
given up to 14 training examples. However, the predictive accuracies of HEXMILho pro-
gressively decreases given more examples. This performance degradation is because, as
we have already explained, HEXMIL and HEXMILho do not scale well given more exam-
ples. This inability to scale given more examples is clearly shown in Figure 23, which
shows that the learning times of HEXMILho increase signiﬁcantly given more training
examples.

We repeated the droplast experiment but replaced reverse/2 in the BK with the
higher-order deﬁnition reduceback/3 and the compiled clause concat/3. In this sce-
nario, Metagolho learned the higher-order program shown in Figure 24b. This program
now includes the invented predicate f3/2 which reverses a given list and is used twice
in the program. This more complex program highlights invention through the repeated
calls to f3/2 and abstraction through the use of higher-order functions.

5.4.4 Further discussion

To further demonstrate invention and abstraction, consider learning a double droplast
program which extends the droplast problem so that, in addition to dropping the last

28

Andrew Cropper et al.

100

80

)

%

(

y
c
a
r
u
c
c
A

60

40

20

0

2

600

Metagol
Metagolho

400

s
d
n
o
c
e
S

200

Metagol
Metagolho
default

4

6

8

10

12

14

16

18

20

0

2

4

6

8

10

12

14

16

18

20

No. training examples

(a) Predictive accuracies

No. training examples

(b) Learning times

Fig. 22: Prolog droplast experimental results which show predictive accuracy when vary-
ing the number of training examples. Note that Metagolho typically learns a program in
under two seconds.

100

80

)

%

(

y
c
a
r
u
c
c
A

60

40

20

0

2

600

400

s
d
n
o
c
e
S

200

HEXMIL
HEXMILho
default

HEXMIL
HEXMILho

4

6

8

10

12

14

16

18

20

0

2

4

6

8

10

12

14

16

18

20

No. training examples

(a) Predictive accuracies

No. training examples

(b) Learning times

Fig. 23: ASP droplast experimental results which show predictive accuracy when varying
the number of training examples.

f(A,B):-map(A,B,f1).
f1(A,B):-f2(A,C),reverse(C,B).
f2(A,B):-reverse(A,C),tail(C,B).

f(A,B):-map(A,B,f1).
f1(A,B):-f2(A,C),f3(C,B).
f2(A,B):-f3(A,C),tail(C,B).
f3(A,B):-reduceback(A,B,concat).

(a)

(b)

Fig. 24: Figure (a) shows the higher-order program often learned by Metagolho. Figure
(b) shows a more complex program learned by Metagolho when we repeated the experi-
ment but disallowed Metagolho to use reverse/2 and instead gave it reduceback/3 and
concat/3.

element from each sublist, it also drops the last sublist. Figure 25 shows examples of
this problem, again represented as the target predicate f/2. Given two examples of this
problem, Metagolho learns the program shown in Figure 26a. For readability Figure 26b
shows the folded program where non-reused invented predicates are removed. This pro-
gram is similar to the program shown in Figure 24b but it makes an additional ﬁnal call

Learning higher-order logic programs

29

to the invented predicate f1/2 which is used twice in the program, once as a higher-
order argument in map/3 and again as a ﬁrst-order predicate. This form of higher-order
abstraction and invention goes beyond anything in the existing literature.

f([alice,bob,carol],[alic,bo]).
f([inductive,logic,programming],[inductiv,logi]]).
f([ferrara,orleans,london,kyoto],[ferrar,orlean,londo]).

Fig. 25: Examples of the more complex double droplast problem.

f(A,B):-f1(A,C),f2(C,B).
f1(A,B):-map(A,B,f2).
f2(A,B):-f3(A,C),f4(C,B).
f3(A,B):-f4(A,C),tail(C,B).
f4(A,B):-reduceback(A,B,concat).

(a)

f(A,B):-map(A,C,f1),f1(C,B).
f1(A,B):-f2(A,C),tail(C,D),f2(D,B).
f2(A,B):-reduceback(A,B,concat).

(b)

Fig. 26: Figure (a) shows a the higher-order double droplast program learned by
Metagolho. For readability Figure (b) shows the folded program in which non-reused
invented predicates are removed. Note how in Figure (b) the predicate symbol f1/2 is
used both as an argument to map/3 and as a standard literal in the clause deﬁned by the
head f(A,B).

5.5 Encryption

In this ﬁnal experiment, we revisit the encryption example from the introduction.

5.5.1 Materials

Examples are f/2 atoms where the ﬁrst argument is the encrypted string and the sec-
ond is the unencrypted string. For simplicity we only allow the letters a-z. We generate
a positive example as follows. For the Prolog experiments we select a random integer
k from the interval [1, 20] to denote the unencrypted string length. For the ASP exper-
iments we select k from the interval [1, 5]. We sample with replacement a sequence y
of length k from the set {a, b, . . . , z}. The sequence y denotes the unencrypted string.
We form the encrypted string x by shifting each character in y two places to the right,
e.g. a (cid:55)→ c, b (cid:55)→ d, . . . , z (cid:55)→ b. The atom f (x, y) thus represents a positive example.
To generate negative examples we repeat the aforementioned procedure but we shift
each character by n places where 0 ≤ n < 25 and n (cid:54)= 2. For the BK we use the relations
char_to_int/2, int_to_char/2, succ/2, and prec/2, where, for simplicity, succ(25,0)
and prec(0,25) hold.

30

5.5.2 Method

Andrew Cropper et al.

The experimental method is the same as in Experiment 1.

5.5.3 Results

Figure 27 shows that, as with the other experiments, Metagolho learns programs with
higher predictive accuracies and lower learning times than Metagol. These results are as
expected because, as shown in Figure 4a, to represent the target encryption hypothesis as
a ﬁrst-order program (cid:77) 2
2 requires seven clauses. By contrast, as shown in Figure 4b, to
represent the target hypothesis as a higher-order program in (cid:77) 2
2 requires three clauses
with one additional higher-order variable in the map/3 abstraction.

We attempted to run the experiment using HEXMIL and HEXMILho. However, both
systems failed to ﬁnd any programs within the timelimit. In fact, even in an extremely
simple version of the experiment (where the alphabet contained only 10 letters, each
string had at most 3 letters, and the character shift was +1) both systems failed to learn
anything in the allocated time. Our theoretical results in Section 4.5 explain these empir-
ical results. In this scenario, the number of ways that the BK predicates can be chained
together and instantiated is no longer tractable for HEXMIL. The experiment suggests
that HEXMIL needs to be better at determining which groundings are relevant to consis-
tent hypotheses.

100

80

)

%

(

y
c
a
r
u
c
c
A

60

40

20

0

2

600

Metagol
Metagolho

400

s
d
n
o
c
e
S

200

Metagol
Metagolho
default

4

6

8

10

12

14

16

18

20

0

2

4

6

8

10

12

14

16

18

20

No. training examples

(a) Predictive accuracies

No. training examples

(b) Learning times

Fig. 27: Prolog encryption experiment results which show learning performance when
varying the number of training examples.

5.6 Discussion

Our main claim is that compared to learning ﬁrst-order programs, learning higher-order
programs can improve learning performance. Our experiments support this claim and
show that learning higher-order programs can signiﬁcantly improve predictive accura-
cies and reduce learning times.

Although it was not our purpose, our experiments also implicitly (implicitly because
we do not directly compare the systems) show that Metagol outperforms HEXMIL, and

Learning higher-order logic programs

31

similarly Metagolho outperforms HEXMILho. Our empirical results contradict those by
Kaminski et al. [23], but support those by Morel et al. [30]. There are multiple explana-
tions for this discrepancy. We think that the main problem is the ASP grounding problem
faced by HEXMIL: in most of our experiments, HEXMIL timed out during the grounding
(and not solving) stage. To alleviate this issue, future work could consider using state
abstraction [23] to mitigate the grounding issues.

Also, by adjusting the experimental methodology, some of the results may change.
For instance, Kaminski et al. showed that HEXMIL can sometimes learn solutions quicker
than Metagol because of conﬂict propagation in ASP. They claim that this performance
improvement is because Metagol only considers negative examples after inducing a
program from the positive examples (as described in Section 4.1). Therefore, HEXMIL
should beneﬁt from more negative examples, but may suffer from fewer.

To summarise, although our empirical results suggest that Metagol outperforms HEXMIL,

future work should more rigorously compare the two approaches on multiple domains
along multiple dimensions (e.g. varying the numbers of examples, size of BK, etc.).

6 Conclusions and further work

We have extended MIL to support learning higher-order programs by allowing for higher-
order deﬁnitions to be included as background knowledge. We showed that learning
higher-order programs can reduce the textual complexity required to express target
classes of programs which in turn reduces the hypothesis space. Our sample complexity
results show that learning higher-order programs can reduce the number of examples
required to reach high predictive accuracies. To learn higher-order programs, we intro-
duced Metagolho, a MIL learner which also supports higher-order predicate invention,
such as inventing predicates for the higher-order abstractions map/3 and until/4. We
also introduced HEXMILho, an ASP implementation of MIL that also supports learning
higher-order programs. Our experiments showed that, compared to learning ﬁrst-order
programs, learning higher-order programs can signiﬁcantly improve predictive accura-
cies and reduce learning times.

6.1 Limitations and future work

6.1.1 Metarules

There are at least two limitations with our work regarding the choice of metarules when
learning higher-order programs.

One issue is deciding which metarules to use. Figure 7 shows the 11 metarules used
in our experiments. Of these metarules, eight of them (the ones with only monadic or
dyadic literals) are a subset of a derivationally irreducible set of monadic and dyadic
metarules [12]. We can therefore justify their selection because they are sufﬁcient to
learn any program in a slightly restricted subset of Datalog. However, we have addi-
tionally used three curry metarules with arities three, four, and ﬁve, which were not
considered in the work on identifying derivationally irreducible metarules. In addition,
the curry metarules also include existentially quantiﬁed predicate arguments (e.g. R in
P(A, B) ← Q(A, B, R)). Although these metarules seem intuitive and sensible to use, we

32

Andrew Cropper et al.

have no theoretical justiﬁcation for using them. Future work should address this issue,
such as by extending the existing work [12] to include such metarules.

A second issue regarding the curry metarules is that when used with abstractions
they each require an extra clause in the learned program. Our motivation for learning
higher-order programs was to reduce the number of clauses necessary to express a target
theory. Although our theoretical and experimental results support this claim, further
improvements can be made. For instance, suppose you are given examples of the concept
f (x, y) where x is a list of integers and y is x but reversed, where each element has had
one added to it, and then doubled, such as f ([1, 2, 3], [8, 6, 4]). Then Metagolho could
learn the following program given the metarules used in Figure 7:

f(A,B):-f1(A,C),f5(C,B).
f1(A,B):-f3(A,C),f4(C,B).
f3(A,B):-reduceback(A,B,concat).
f4(A,B):-map(A,B,succ).
f5(A,B):-map(A,B,double).

This program requires ﬁve clauses. By contrast, a more compact representation would
be:

f(A,B):-reduceback(A,C,concat),

map(C,D,succ),
map(D,B,double).

This more compact program is formed of a single clause and four literals, so should
therefore be easier to learn. Future work should try to address this limitation of the
current approach11.

6.1.2 Higher-order deﬁnitions

Our experiments rely on a few higher-order deﬁnitions, mostly based on higher-order
programming concepts, such as map/3 and until/4. Future work should consider other
higher-order concepts. For instance, consider learning regular grammars, such as a∗ b∗c∗.
To improve learning efﬁciency it would be desirable to encode the concept of Kleene star
operator12 as a higher-order deﬁnition, such as:

kstar(P,A,A).
kstar(P,A,B):-

call(P,A,C),
kstar(P,C,B).

Similarly, we have used abstracted MIL to invent functional constructs. Future work
could consider inventing relational constructs. For instance, consider this higher-order
deﬁnition of a closure:

11 This limitation is not speciﬁc to when learning higher-order programs. Curry metarules can also
be used when learning ﬁrst-order programs, where existentially quantiﬁed argument variables could be
bound to constant symbols, rather than predicate symbols. In other words, this issue is a limitation of
MIL but manifests itself clearly when learning higher-order programs.
12 The Kleene star operator represents zero-or-more repetitions (here applications) of its argument.

Learning higher-order logic programs

33

closure(P,A,B) ← P(A,B)
closure(P,A,B) ← P(A,C), closure(P,C,B)

We could use this deﬁnition to learn compact abstractions of relations, such as:

ancestor(A,B) ← closure(parent,A,B)
lessthan(A,B) ← closure(increment,A,B)
subterm(A,B) ← closure(headortail,A,B)

6.1.3 Learning higher-order abstractions

One clear limitation of the current approach is that we require user-provided higher-
order deﬁnitions, such as map/3. In future work we want to learn or invent such deﬁni-
tions. For instance, when learning a solution to the decryption program in the introduc-
tion it may be beneﬁcial to learn and invent a sub-deﬁnition that corresponds to map/3.
The program below shows such a scenario, where the deﬁnition decrypt1/3 corresponds
to map/3.

decrypt(A,B):-

decrypt1(A,B,decrypt2).

decrypt1(A,B,C):-
empty(A),
empty(B).
decrypt1(A,B,C):-
head(A,D),
call(C,D,E),
head(B,E),
tail(A,F),
tail(B,G),
decrypt1(F,G,C).

decrypt2(A,B):-

char_to_int(A,C),
prec(C,D),
int_to_char(D,B).

Our preliminary work suggests that learning such deﬁnitions is possible.

6.2 Summary

In summary, our primary contribution is a demonstration of the value of higher-order
abstractions and inventions in MIL. We have shown that the techniques allow us to learn
substantially more complex programs using fewer examples with less search.

Acknowledgements We thank Stassa Patsantzis and Tobias Kaminski for helpful feedback on the paper.

34

References

Andrew Cropper et al.

1. Hendrik Blockeel and Luc De Raedt. Top-down induction of ﬁrst-order logical decision trees. Artif.

Intell., 101(1-2):285–297, 1998.

2. Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K. Warmuth. Occam’s razor. Inf.

Process. Lett., 24(6):377–380, 1987.

3. Ivan Bratko and Donald Michie. A representation for pattern-knowledge in chess endgames. Ad-

vances in Computer Chess, 2:31–56, 1980.

4. Luca Cardelli and Peter Wegner. On understanding types, data abstraction, and polymorphism. ACM

Comput. Surv., 17(4):471–522, 1985.

5. K.L. Clark. Negation as failure. In M. L. Ginsberg, editor, Readings in Nonmonotonic Reasoning, pages

311–325. Kaufmann, Los Altos, CA, 1987.

6. Andrew Cropper. Efﬁciently learning efﬁcient programs. PhD thesis, Imperial College London, UK,

2017.

7. Andrew Cropper and Stephen H. Muggleton. Learning efﬁcient logical robot strategies involving
In Qiang Yang and Michael Wooldridge, editors, Proceedings of the Twenty-
composable objects.
Fourth International Joint Conference on Artiﬁcial Intelligence, IJCAI 2015, Buenos Aires, Argentina,
July 25-31, 2015, pages 3423–3429. AAAI Press, 2015.

8. Andrew Cropper and Stephen H. Muggleton. Learning higher-order logic programs through abstrac-
tion and invention. In Subbarao Kambhampati, editor, Proceedings of the Twenty-Fifth International
Joint Conference on Artiﬁcial Intelligence, IJCAI 2016, New York, NY, USA, 9-15 July 2016, pages
1418–1424. IJCAI/AAAI Press, 2016.

9. Andrew

Cropper

and

Stephen

H.

Muggleton.

Metagol

system.

https://github.com/metagol/metagol, 2016.

10. Andrew Cropper and Stephen H. Muggleton. Learning efﬁcient logic programs. Machine Learning,

Apr 2018.

11. Andrew Cropper, Alireza Tamaddoni-Nezhad, and Stephen H. Muggleton. Meta-interpretive learn-
ing of data transformation programs. In Katsumi Inoue, Hayato Ohwada, and Akihiro Yamamoto,
editors, Inductive Logic Programming - 25th International Conference, ILP 2015, Kyoto, Japan, August
20-22, 2015, Revised Selected Papers, volume 9575 of Lecture Notes in Computer Science, pages 46–59.
Springer, 2015.

12. Andrew Cropper and Sophie Tourret. Derivation reduction of metarules in meta-interpretive learn-
In Fabrizio Riguzzi, Elena Bellodi, and Riccardo Zese, editors, Inductive Logic Programming
ing.
- 28th International Conference, ILP 2018, Ferrara, Italy, September 2-4, 2018, Proceedings, volume
11105 of Lecture Notes in Computer Science, pages 1–21. Springer, 2018.

13. Thomas Eiter, Michael Fink, Giovambattista Ianni, Thomas Krennwallner, Christoph Redl, and Peter
Schüller. A model building framework for answer set programming with external computations.
TPLP, 16(4):418–464, 2016.

14. Werner Emde, Christopher Habel, and Claus-Rainer Rollinger. The discovery of the equator or con-
cept driven learning. In Alan Bundy, editor, Proceedings of the 8th International Joint Conference on
Artiﬁcial Intelligence. Karlsruhe, FRG, August 1983, pages 455–458. William Kaufmann, 1983.

15. Cao Feng and Stephen Muggleton. Towards inductive generalization in higher order logic.

In
Derek H. Sleeman and Peter Edwards, editors, Proceedings of the Ninth International Workshop on
Machine Learning (ML 1992), Aberdeen, Scotland, UK, July 1-3, 1992, pages 154–162. Morgan Kauf-
mann, 1992.

16. John K. Feser, Swarat Chaudhuri, and Isil Dillig. Synthesizing data structure transformations from
input-output examples. In Proceedings of the 36th ACM SIGPLAN Conference on Programming Lan-
guage Design and Implementation, Portland, OR, USA, June 15-17, 2015, pages 229–239, 2015.
17. Pierre Flener and Serap Yilmaz. Inductive synthesis of recursive logic programs: Achievements and

prospects. J. Log. Program., 41(2-3):141–195, 1999.

18. Jonathan Frankle, Peter-Michael Osera, David Walker, and Steve Zdancewic. Example-directed syn-
thesis: a type-theoretic interpretation. In Rastislav Bodík and Rupak Majumdar, editors, Proceedings
of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL
2016, St. Petersburg, FL, USA, January 20 - 22, 2016, pages 802–815. ACM, 2016.

19. Michael Gelfond and Vladimir Lifschitz. Classical negation in logic programs and disjunctive

databases. New Generation Comput., 9(3/4):365–386, 1991.

20. Sumit Gulwani. Automating string processing in spreadsheets using input-output examples.

In
Proceedings of the 38th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,
POPL 2011, Austin, TX, USA, January 26-28, 2011, pages 317–330, 2011.

21. Larry Harris. The heuristic search and the game of chess. a study of quiescence, sacriﬁces, and plan

oriented play. In Computer Chess Compendium, pages 136–142. Springer, 1988.

Learning higher-order logic programs

35

22. Katsumi Inoue, Andrei Doncescu, and Hidetomo Nabeshima. Completing causal networks by meta-

level abduction. Machine Learning, 91(2):239–277, 2013.

23. Tobias Kaminski, Thomas Eiter, and Katsumi Inoue. Exploiting answer set programming with exter-

nal sources for meta-interpretive learning. TPLP, 18(3-4):571–588, 2018.

24. Susumu Katayama. Efﬁcient exhaustive generation of functional programs using monte-carlo search
with iterative deepening. In PRICAI 2008: Trends in Artiﬁcial Intelligence, 10th Paciﬁc Rim Interna-
tional Conference on Artiﬁcial Intelligence, Hanoi, Vietnam, December 15-19, 2008. Proceedings, pages
199–210, 2008.

25. Emanuel Kitzelmann. Data-driven induction of functional programs. In ECAI 2008 - 18th European
Conference on Artiﬁcial Intelligence, Patras, Greece, July 21-25, 2008, Proceedings, pages 781–782,
2008.

26. J.W. Lloyd. Logic for Learning. Springer, Berlin, 2003.
27. Zohar Manna and Richard J. Waldinger. A deductive approach to program synthesis. ACM Trans.

Program. Lang. Syst., 2(1):90–121, 1980.

28. John McCarthy. Making robots conscious of their mental states. In Machine Intelligence 15, Intelligent

Agents [St. Catherine’s College, Oxford, July 1995], pages 3–17, 1995.

29. Tom M. Mitchell. Machine learning. McGraw Hill series in computer science. McGraw-Hill, 1997.
30. Rolf Morel, Andrew Cropper, and C.-H. Luke Ong. Typed meta-interpretive learning of logic pro-
In Francesco Calimeri, Nicola Leone, and Marco Manna, editors, Logics in Artiﬁcial Intel-
grams.
ligence - 16th European Conference, JELIA 2019, Rende, Italy, May 7-11, 2019, Proceedings, volume
11468 of Lecture Notes in Computer Science, pages 198–213. Springer, 2019.

31. Stephen Muggleton. Inverse entailment and progol. New Generation Comput., 13(3&4):245–286,

1995.

32. Stephen Muggleton and Wray L. Buntine. Machine invention of ﬁrst order predicates by inverting
resolution. In Machine Learning, Proceedings of the Fifth International Conference on Machine Learn-
ing, Ann Arbor, Michigan, USA, June 12-14, 1988, pages 339–352, 1988.

33. Stephen Muggleton, Luc De Raedt, David Poole, Ivan Bratko, Peter A. Flach, Katsumi Inoue, and
Ashwin Srinivasan. ILP turns 20 - biography and future challenges. Machine Learning, 86(1):3–23,
2012.

34. Stephen H. Muggleton, Dianhuan Lin, Niels Pahlavi, and Alireza Tamaddoni-Nezhad. Meta-
interpretive learning: application to grammatical inference. Machine Learning, 94(1):25–49, 2014.
35. Stephen H. Muggleton, Dianhuan Lin, and Alireza Tamaddoni-Nezhad. Meta-interpretive learning of
higher-order dyadic datalog: predicate invention revisited. Machine Learning, 100(1):49–73, 2015.
36. Peter-Michael Osera and Steve Zdancewic. Type-and-example-directed program synthesis. In David
Grove and Steve Blackburn, editors, Proceedings of the 36th ACM SIGPLAN Conference on Program-
ming Language Design and Implementation, Portland, OR, USA, June 15-17, 2015, pages 619–630.
ACM, 2015.

37. J. Ross Quinlan. Learning logical deﬁnitions from relations. Machine Learning, 5:239–266, 1990.
38. Luc De Raedt and Maurice Bruynooghe. Interactive concept-learning and constructive induction by

analogy. Machine Learning, 8:107–150, 1992.

39. Lorenza Saitta and Jean-Daniel Zucker. Abstraction in artiﬁcial intelligence and complex systems.

Springer, 2013.

40. Robert E. Schapire. The strength of weak learnability. Machine Learning, 5:197–227, 1990.
41. A. Srinivasan. The ALEPH manual. Machine Learning at the Computing Laboratory, Oxford University,

2001.

42. Irene Stahl. The appropriateness of predicate invention as bias shift operation in ILP. Machine

Learning, 20(1-2):95–117, 1995.

43. Jan Wielemaker, Tom Schrijvers, Markus Triska, and Torbjörn Lager. SWI-Prolog. Theory and Practice

of Logic Programming, 12(1-2):67–96, 2012.

