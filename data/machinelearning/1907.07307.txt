0
2
0
2

l
u
J

1
2

]

C
O
.
h
t
a
m

[

2
v
7
0
3
7
0
.
7
0
9
1
:
v
i
X
r
a

Dynamic optimization with side information

Dimitris Bertsimas, Christopher McCord, Bradley Sturt
Operations Research Center, Massachusetts Institute of Technology,
dbertsim@mit.edu, mccord@mit.edu, bsturt@mit.edu

We develop a tractable and ﬂexible approach for incorporating side information into dynamic optimization

under uncertainty. The proposed framework uses predictive machine learning methods (such as k-nearest

neighbors, kernel regression, and random forests) to weight the relative importance of various data-driven

uncertainty sets in a robust optimization formulation. Through a novel measure concentration result for a

class of machine learning methods, we prove that the proposed approach is asymptotically optimal for multi-

period stochastic programming with side information. We also describe a general-purpose approximation for

these optimization problems, based on overlapping linear decision rules, which is computationally tractable

and produces high-quality solutions for dynamic problems with many stages. Across a variety of examples

in inventory management, ﬁnance, and shipment planning, our method achieves improvements of up to 15%

over alternatives and requires less than one minute of computation time on problems with twelve stages.

Key words : Distributionally robust optimization; machine learning; dynamic optimization.

History : This paper was ﬁrst submitted in May 2019. A revision was submitted in May 2020.

1.

Introduction

Dynamic decision making under uncertainty forms the foundation for numerous fundamental prob-

lems in operations research and management science. In these problems, a decision maker attempts

to minimize an uncertain objective over time, as information incrementally becomes available. For

example, consider a retailer with the goal of managing the inventory of a new short life cycle prod-

uct. Each week, the retailer must decide an ordering quantity to replenish its inventory. Future

demand for the product is unknown, but the retailer can base its ordering decisions on the remain-

ing inventory level, which depends on the realized demands in previous weeks. A risk-averse investor

faces a similar problem when constructing and adjusting a portfolio of assets in order to achieve

a desirable risk-return tradeoﬀ over a horizon of many months. Additional examples abound in

energy planning, airline routing, and ride sharing, as well as in many other areas.

To make high quality decisions in dynamic environments, the decision maker must accurately

model future uncertainty. Often, practitioners have access to side information or auxiliary covari-

ates, which can help predict that uncertainty. For a retailer, although the future demand for a

newly introduced clothing item is unknown, data on the brand, style, and color of the item, as well

1

 
 
 
 
 
 
2

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

as data on market trends and social media, can help predict it. For a risk-averse investor, while

the returns of the assets in future stages are uncertain, recent asset returns and prices of relevant

options can provide crucial insight into upcoming volatility. Consequently, organizations across

many industries are continuing to prioritize the use of predictive analytics in order to leverage vast

quantities of data to understand future uncertainty and make better operational decisions.

In this paper, we address these applications by studying the following class of multi-period

stochastic decision problems. Speciﬁcally, we consider problems faced by organizations in which
decisions x1 ∈ X1 ⊆ Rd1
ξ , . . . , ξT ∈ ΞT ⊆ RdT
Rd1

x, . . . , xT ∈ XT ⊆ RdT
x are chosen sequentially, as random vectors ξ1 ∈ Ξ1 ⊆
ξ become incrementally available at each temporal period. Before selecting
any decisions, we observe side information, γ ∈ Γ ⊆ Rdγ , which may be predictive of the uncertain

quantities observed in the subsequent periods. The goal is to choose a decision rule (policy) which

minimizes the conditional expected cost over the entire problem horizon:

v∗(¯γ) (cid:44)

minimize
xt:Ξ1×···×Ξt−1→Xt

(cid:20)
c (cid:0)ξ1, . . . , ξT , x1, x2(ξ1), . . . , xT (ξ1, . . . , ξT −1)(cid:1)

E

(cid:21)

.

γ = ¯γ

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(1)

However, the only insight into the joint probability distribution (γ, ξ1, . . . , ξT ) comes from historical
data, (γ 1, ξ1
T ), which are assumed to be independent and identically
distributed (i.i.d.) realizations of the underlying joint distribution. Throughout the paper, we do

T ), . . . , (γ N , ξN

1 , . . . , ξN

1, . . . , ξ1

not impose any parametric structure on the correlations across (γ, ξ1, . . . , ξT ), and presume that
the structure of optimal decision rules to (1) is unknown. The aim of the present paper is to develop

general-purpose approaches to harness this data to approximately solve the stochastic problem (1).

Such dynamic optimization problems with an initial observation of side information arise in

many operational contexts. For example, fashion retailers have access to data on the brand, style,

and color of a new clothing item prior to any sales, which are predictive of demand for the product

in each week of its lifecycle. Similarly, in ﬁnance, important economic data (such as the consumer

price index CPI and key numbers from the US Bureau of Labor Statistics report) are released

monthly on a ﬁxed schedule, and this data serves as side information for a fund manager who seeks

to balance the risk of a portfolio in each day of the ensuing month. Consequently, from a modeling

perspective, (1) encompasses the variety of decision problems faced by organizations in which side

information does not change over time (e.g., the fashion retailer) or varies on a much longer time

scale than the length of the decision horizon (e.g., the fund manager).

A recent body of work has aimed to leverage predictive analytics to address (1) in the particular

case of single-period problems (T = 1). For example, Hannah et al. (2010), Ban and Rudin (2018),

Bertsimas and Kallus (2020), Ho and Hanasusanto (2019) investigate prescriptive approaches, based

on sample average approximation, that use local machine learning to assign weights to the historical

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

3

data based on side information. Bertsimas and Van Parys (2017) propose adding robustness to

those weights to achieve optimal asymptotic budget guarantees. Elmachtoub and Grigas (2017)

develop an approach for linear optimization problems in which a machine learning model is trained

to minimize the decision cost. Unfortunately, prescriptive approaches designed for single-period

problems do not generally extend to (1), as illustrated by the following example.

Example 1. Suppose a decision maker attempted to approximate (1) by solving

minimize
xt:Ξ1×···×Ξt−1→Xt

N
(cid:88)

i=1

N (¯γ)c (cid:0)ξi
wi

1, . . . , ξi

T , x1, x2(ξi

1), . . . , xT (ξi

1, . . . , ξi

T −1)(cid:1) ,

(2)

where wi

N (·) are weight functions (satisfying (cid:80)N

i=1 wi
N (¯γ) = 1) derived from machine learning meth-
ods applied to historical data. When T = 1 and the weight functions are constructed using a suitable

class of machine learning methods, Bertsimas and Kallus (2020) show under certain conditions that

the above optimization problem is asymptotically optimal, and will thus provide a near-optimal

approximation of (1) in big data settings. However, it is readily observed that approaches such as

(2) will result in a poor approximation of the underlying multi-period stochastic decision problem

with side information when T ≥ 2, as the optimal decision rules produced by (2) will generally be

“anticipative” with respect to the historical data.1 Such anticipativity (a form of overﬁtting) is ulti-

mately of practical importance, as it implies that the (2) can provide an unsuitable approximation

of (1) even in the presence of big data.

To circumvent overﬁtting in the context of multi-period problems with side information, recent

literature have aimed to address (1) by constructing scenario trees. Scenario trees have been long

studied in the stochastic programming literature, and essentially address overﬁtting by encoding

the various ways that uncertainty can unfold across time. For a class of multi-period inventory

management problems with side information, Ban et al. (2019) propose ﬁtting historical data and

side information to a parametric regression model, and establish asymptotic optimality when the

model is correctly speciﬁed. Bertsimas and McCord (2019) propose a diﬀerent approach based on

dynamic programming that uses nonparametric machine learning methods to handle auxiliary side

information. These papers also extend to problems where side information is observed at multiple

periods. However, these dynamic approaches require scenario tree enumeration and suﬀer from the

curse of dimensionality. As a result, and despite their asymptotic optimality, the existing approaches

for addressing (1) can require hours or days to obtain high-quality solutions for problems with ten

or fewer time periods.

1.1. Contributions

The aim of the present paper, in a nutshell, is to develop a machine learning-based approach

for addressing (1) which remains computationally tractable for operational problems with many

4

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

periods. To this end, we develop a new approach to (1) by a natural combination of prescriptive

analytics (2) with recent techniques from robust optimization to avoid overﬁtting (Bertsimas et al.

2018a), and the present paper uniﬁes our understanding of these disparate models through a novel

asymptotic theory.

Our proposed combination of two streams of literature (prescriptive analytics and robust opti-

mization) is ultimately viewed as attractive from a practical standpoint. Across multi-period and

single-period problems from several applications (shipment planning, inventory management, and

ﬁnance), the proposed approach produces solutions with up to 15% improvement in average out-

of-sample cost compared to alternatives. In particular, the approach does not require a scenario

tree, and as a result, is signiﬁcantly more tractable compared to existing approaches for dynamic

optimization with side information. To the best of our knowledge, this is the ﬁrst approach to

address (1) which oﬀers asymptotic optimality guarantees while remaining practically tractable for

problems with many periods, thus oﬀering organizations a general-purpose tool for better decision

making with predictive analytics.

In greater detail, the key results of this paper are the following:

(a) We propose addressing (1) by combining the prescriptive analytics approach (2) with a tech-

nique of Bertsimas et al. (2018a) to avoid overﬁtting in multi-period problems.

(b) We prove under mild conditions that this combination of machine learning and robust opti-

mization is asymptotically optimal for (1) for general spaces of decision rules (Theorem 1).

(c) To establish the above guarantee, we show for the ﬁrst time that an empirical conditional

probability distribution that is constructed from machine learning methods will, as more data

is obtained, converge to the underlying conditional probability distribution with respect to the

type-1 Wasserstein distance (Theorem 2).

(d) As a byproduct of the new measure concentration result, we show how side information and

machine learning can be tractably incorporated into (single-period) Wasserstein-based distri-

butionally robust optimization problems while maintaining its attractive asymptotic optimal-

ity.

(e) To ﬁnd high quality solutions for problems with many stages in practical computation times,

we develop a tractable approximation algorithm for these robust optimization problems by

extending an approach of Bertsimas et al. (2019), Chen et al. (2020) to multi-period problems.

(f) Across multi-period and single-period problems from several applications (shipment planning,

inventory management, and ﬁnance), we show that the proposed combination of machine

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

5

learning and robust optimization outperforms alternatives with up to 15% improvement in

average out-of-sample cost. In particular, the proposed approach is practical and scalable,

requiring less than one minute on examples with up to twelve stages.

The paper is organized as follows. Section 2 introduces the problem setting and notation. Sec-

tion 3 proposes the new framework for incorporating machine learning into dynamic optimization.

Section 4 develops theoretical guarantees on the proposed approach. Section 5 discusses impli-

cations of these results in the context of single-period distributionally robust optimization with

the type-1 Wasserstein ambiguity set. Section 6 presents the general multi-policy approximation

scheme for dynamic optimization with side information. Section 7 presents a detailed investiga-

tion and computational simulations of the proposed methodology in shipment planning, inventory

management, and ﬁnance. We conclude in Section 8.

1.2. Comparison to related work

This paper follows a recent body of literature on data-driven optimization under uncertainty in

operations research and management science. Much of this work has focused on the paradigm of

distributionally robust optimization, in which the optimal solution is that which performs best

in expectation over a worst-case probability distribution from an ambiguity set. Motivated by

probabilistic guarantees, distributionally robust optimization has found particular applicability in

data-driven settings in which the ambiguity set is constructed using historical data, such as Delage

and Ye (2010), Xu et al. (2012), Mohajerin Esfahani and Kuhn (2018), Van Parys et al. (2017).

In particular, the ﬁnal steps in our convergence result (Section 4.4) draw heavily from similar

techniques from Mohajerin Esfahani and Kuhn (2018) and Bertsimas et al. (2018a). In contrast

to previous work, this paper develops a new measure concentration result for the empirical condi-

tional probability distribution (Section 4.3) which enables machine learning and side information

to be incorporated into sample robust optimization and Wasserstein-based distributionally robust

optimization for the ﬁrst time.

To the best of our knowledge, the proposed combination of machine learning and robust opti-

mization for addressing (1) is novel and its theoretical justiﬁcation does not follow from the existing

literature. With respect to prescriptive analytics, Bertsimas and Kallus (2020) establish asymptotic

optimality guarantees for problems of the form (2) in the case of T = 1. Their result requires that

the cost function is equicontinuous. Their proof relies on results from the machine learning litera-

ture (Walk 2010), which show that an appropriately constructed empirical conditional probability
N (¯γ)} assigned to each historical observation ξi) weakly converges

distribution (with weights {wi

6

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

to the true conditional probability distribution of ξ given γ = ¯γ, under certain assumptions. How-

ever, the asymptotic optimality and proof techniques do not apply to (2) when T ≥ 2, since the

cost function resulting from decision rules is not equicontinuous in general. For problems without

side information, Bertsimas et al. (2018a) circumvent the requirement of equicontinuity by adding

robustness to the historical data. To establish asymptotic optimality, they use the fact that the

empirical probability distribution of the uncertainties concentrates around the true distribution

with respect to the type-1 Wasserstein distance. In the present paper, we unify these proof tech-

niques by developing a new measure concentration result for machine learning which shows that the

empirical conditional probability distribution produced by appropriate weight functions concen-

trates around the true conditional probability distribution with respect to the type-1 Wasserstein

distance. This establishes the asymptotic optimality of our robustiﬁcation of (2) for multi-stage

stochastic decision problems with side information.

Several recent papers have focused on tractable approximations of two- and multi-stage distribu-

tionally and sample robust optimization. Many approaches are based around policy approximation

schemes, including lifted linear decision rules (Bertsimas et al. 2018b), K-adaptivity (Hanasu-

santo et al. 2016), and ﬁnite adaptability (Bertsimas et al. 2018a). Alternative approaches include

tractable approximations of copositive formulations (Natarajan et al. 2011, Hanasusanto and Kuhn

2018). Closest related to the approximation scheme in this paper are Chen et al. (2020) and Bert-

simas et al. (2019), which address two-stage problems via overlapping decision rules. Chen et al.

(2020) propose a scenario-wise modeling approach that leads to novel approximations of various

distributionally robust applications, including two-stage distributionally robust optimization using

Wasserstein ambiguity sets and expectations of piecewise convex objective functions in single-stage

problems. Independently, Bertsimas et al. (2019) investigate a multi-policy approximation of two-

stage sample robust optimization by optimizing a separate linear decision rule for each uncertainty

set and prove that this approximation gap converges to zero as the amount of data goes to inﬁnity.

In Section 6 of this paper, we show how to extend similar techniques to dynamic problems with

many stages for the ﬁrst time.

2. Problem Setting

As described in the introduction, we consider ﬁnite-horizon discrete-time stochastic decision prob-

lems. The uncertain quantities observed in each stage are denoted by random variables ξ1 ∈ Ξ1 ⊆
Rd1
x, . . . , xT ∈
XT ⊆ RdT

ξ , and the decisions made in each stage are denoted by x1 ∈ X1 ⊆ Rd1
x . Given realizations of the uncertain quantities and decisions, we incur a cost of

ξ , . . . , ξT ∈ ΞT ⊆ RdT

c (ξ1, . . . , ξT , x1, . . . , xT ) ∈ R.

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

7

Let a decision rule π = (π1, . . . , πT ) denote a collection of measurable functions πt : Ξ1 × · · · ×

Ξt−1 → Xt which specify what decision to make in stage t based of the information observed up to

that point. For notational convenience, let Π denote the space of all measurable non-anticipative

decision rules. Given realizations of the uncertain quantities and choice of decision rules, the result-

ing cost is

cπ (ξ1, . . . , ξT ) (cid:44) c(ξ1, . . . , ξT , π1, π2(ξ1), . . . , πT (ξ1, . . . , ξT −1)).

Before selecting the decision rules, we observe auxiliary side information γ ∈ Γ ⊆ Rdγ . For example,

in the aforementioned fashion setting, the side information may contain information on the brand,

style, and color of a new clothing item and the remaining uncertainties representing the demand

for the product in each week of the lifecycle.

Given a realization of the side information γ = ¯γ, our goal is to ﬁnd decision rules which minimize

the conditional expected cost:

v∗(¯γ) (cid:44) minimize

π∈Π

(cid:20)
cπ(ξ1, . . . , ξT )

E

(cid:21)

.

γ = ¯γ

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(1)

We refer to (1) as dynamic optimization with side information. The optimization takes place over a

collection Π which is any subset of the space of all non-anticipative decision rules. In this paper, we

assume that the joint distribution of the side information and uncertain quantities (γ, ξ1, . . . , ξT )

is unknown, and our knowledge consists of historical data of the form

(γ 1, ξ1

1, . . . , ξ1

T ), . . . , (γ N , ξN

1 , . . . , ξN

T ),

where each of these tuples consists of a realization of the side information and the following realiza-

tion of the random variables over the stages. For example, in the aforementioned fashion setting,

each tuple corresponds to the side information of a past fashion item as well as its demand over

its lifecycle. We will not assume any parametric structure on the relationship between the side

information and future uncertainty.

The goal of this paper is a general-purpose, computationally tractable, data-driven approach for

approximately solving dynamic optimization with side information. In the following sections, we

propose and analyze a new framework which leverages nonparametric machine learning, trained

from historical data, to predict future uncertainty from side information in a way that leads to

near-optimal decision rules to (1).

8

2.1. Notation

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

The joint probability distribution of the side information γ and uncertain quantities ξ = (ξ1, . . . , ξT )
is denoted by P. For the purpose of proving theorems, we assume throughout this paper that the

historical data are independent and identically distributed (i.i.d.) samples from this distribution
P. In other words, we assume that the historical data satisﬁes

((γ 1, ξ1), . . . , (γ N , ξN )) ∼ PN ,

where PN (cid:44) P × · · · × P is the product measure. The set of all probability distributions supported
on Ξ (cid:44) Ξ1 × · · · × ΞT ⊆ Rdξ is denoted by P(Ξ). For each of the side information ¯γ ∈ Γ, we assume
that its conditional probability distribution satisﬁes P¯γ ∈ P(Ξ), where P¯γ(·) is shorthand for P(· |
γ = ¯γ). We use “i.o.” as shorthand for “inﬁnitely often”. We sometimes use subscript notation

for expectations to specify the underlying probability distribution; for example, the following two

expressions are equivalent:

Eξ∼P¯γ [f (ξ1, . . . , ξT )] ≡ E [f (ξ1, . . . , ξT ) | γ = ¯γ] .

Finally, we say that the cost function resulting from a policy π is upper semicontinuous if

lim sup
ζ→¯ζ

cπ(ζ1, . . . , ζT ) ≤ cπ(¯ζ1, . . . , ¯ζT )

for all ¯ζ ∈ Ξ.

3. Sample Robust Optimization with Side Information

In this section, we present our approach for incorporating machine learning in dynamic optimiza-

tion. We ﬁrst review sample robust optimization, and then we introduce the proposed sample robust

optimization with side information approach to (1).

3.1. Preliminary: sample robust optimization

Consider a stochastic dynamic optimization problem of the form (1) in which there is no side

information. The underlying joint distribution of the random variables ξ ≡ (ξ1, . . . , ξT ) is unknown,
but we have data consisting of sample paths, ξ1 ≡ (ξ1
T ). For this
setting, sample robust optimization can be used to ﬁnd approximate solutions in stochastic dynamic

T ), . . . , ξN ≡ (ξN

1 , . . . , ξN

1, . . . , ξ1

optimization. To apply the framework, one constructs an uncertainty set around each sample path

in the training data and then chooses the decision rules that optimize the average of the worst-

case realizations of the cost. Formally, this framework results in the following robust optimization

problem:

minimize
π∈Π

N
(cid:88)

i=1

1
N

sup
ζ∈U i
N

cπ(ζ1, . . . , ζT ),

(3)

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

9

where U i

N ⊆ Ξ is an uncertainty set around ξi. Intuitively speaking, (3) chooses the decision rules
by averaging over the historical sample paths which are adversarially perturbed. Under mild proba-

bilistic assumptions on the underlying joint distribution and appropriately constructed uncertainty

sets, Bertsimas et al. (2018a) show that sample robust optimization converges asymptotically to

the underlying stochastic problem and that (3) is amenable to approximations similar to dynamic

robust optimization.

3.2.

Incorporating side information into sample robust optimization

We now present our new framework, based on sample robust optimization, for solving dynamic

optimization with side information. In the proposed framework, we ﬁrst train a machine learning

algorithm on the historical data to predict future uncertainty (ξ1, . . . , ξT ) as a function of the
side information. From the trained learner, we obtain weight functions wi
N (¯γ), for i = 1, . . . , N ,
each of which captures the relevance of the ith training sample to the new side information, ¯γ.

We incorporate the weights into sample robust optimization by multiplying the cost associated

with each training example by the corresponding weight function. The resulting sample robust

optimization with side information framework is as follows:

ˆvN (¯γ) (cid:44) minimize

π∈Π

N
(cid:88)

i=1

wi

N (¯γ) sup
ζ∈U i
N

cπ(ζ1, . . . , ζT ),

(4)

where the uncertainty sets are deﬁned

U i
N

(cid:44) (cid:8)ζ ∈ Ξ : (cid:107)ζ − ξi(cid:107) ≤ (cid:15)N

(cid:9) ,

and (cid:107) · (cid:107) is some (cid:96)p norm with p ≥ 1.

The above framework provides the ﬂexibility for the practitioner to construct weights from a

variety of machine learning algorithms. We focus in this paper on weight functions which come from

nonparametric machine learning methods. Examples of viable predictive models include k-nearest

neighbors (kNN), kernel regression, classiﬁcation and regression trees (CART), and random forests

(RF). We describe these four classes of weight functions.

Definition 1. The k-nearest neighbor weight functions are given by:

wi

N,kNN(¯γ) (cid:44)






1
kN
0,

,

if γ i is a kN -nearest neighbor of ¯γ,

otherwise.

Formally, γ i is a kN -nearest neighbor of ¯γ if |{j ∈ {1, . . . , N } \ i : (cid:107)γ j − ¯γ(cid:107) < (cid:107)γ i − ¯γ(cid:107)}| < kN . For

more technical details, we refer the reader to Biau and Devroye (2015).

10

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

Definition 2. The kernel regression weight functions are given by:

N,KR(¯γ) (cid:44) K((cid:107)γ i − ¯γ(cid:107)/hN )
wi

(cid:80)N

j=1 K((cid:107)γ j − ¯γ(cid:107)/hN )

,

include the Gaussian kernel, K(u) = 1√
2π

where K(·) is the kernel function and hN is the bandwidth parameter. Examples of kernel functions
e−u2/2, the triangular kernel, K(u) = (1 − u)1{u ≤ 1}, and
4 (1 − u2)1{u ≤ 1}. For more information on kernel regression,

the Epanechnikov kernel, K(u) = 3

see Friedman et al. (2001, Chapter 6).

The next two types of weight functions we present are based on classiﬁcation and regression trees

(Breiman et al. 1984) and random forests (Breiman 2001). We refer the reader to Bertsimas and

Kallus (2020) for technical implementation details.

Definition 3. The classiﬁcation and regression tree weight functions are given by:

wi

N,CART(¯γ) (cid:44)






1
|lN (¯γ)|
0,

,

i ∈ lN (¯γ),

otherwise,

where lN (¯γ) is the set of indices i such that γ i is contained in the same leaf of the tree as ¯γ.

Definition 4. The random forest weight functions are given by:

N,RF(¯γ) (cid:44) 1
wi
B

B
(cid:88)

b=1

wi,b

N,CART(¯γ),

where B is the number of trees in the ensemble, and wi,b

N,CART(¯γ) refers to the weight function of

the bth tree in the ensemble.

All of the above weight functions come from nonparametric machine learning methods. They are

highly eﬀective as predictive methods because they can learn complex relationships between the

side information and the response variable without requiring the practitioner to state an explicit

parametric form. Similarly, as we prove in Section 4, solutions to (4) with these weight functions are

asymptotically optimal for (1) without any parametric restrictions on the relationship between γ

and ξ. In other words, incorporating side information into sample robust optimization via (4) leads

to better decisions asymptotically, even without speciﬁc knowledge of how the side information

aﬀects the uncertainty.

4. Asymptotic Optimality

In this section, we establish asymptotic optimality guarantees for sample robust optimization with

side information. We prove that, under mild conditions, (4) converges to (1) as the number of

training samples goes to inﬁnity. Thus, as the amount of data grows, sample robust optimization

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

11

with side information becomes an optimal approximation of the underlying stochastic dynamic

optimization problem. Crucially, our convergence guarantee does not require parametric restrictions

on the space of decision rules (e.g., linearity) or parametric restrictions on the joint distribution of

the side information and uncertain quantities.

4.1. Main result

We begin by presenting our main result. The proof of the result depends on some technical assump-

tions and concepts from distributionally robust optimization. For simplicity, we defer the statement

and discussion of technical assumptions regarding the underlying probability distribution and cost

until Sections 4.3 and 4.4, and ﬁrst discuss what is needed to apply the method in practice. The

practitioner needs to select a weight function, parameters associated with that weight function, and

the radius, (cid:15)N , of the uncertainty sets. While these may be selected by cross validation, we show

that the method will in general converge if the parameters are selected to satisfy the following:

Assumption 1. The weight functions and uncertainty set radius satisfy one of the following:

1. {wi

N (·)} are k-nearest neighbor weight functions with kN = min((cid:100)k3N δ(cid:101), N − 1) for constants

k3 > 0 and δ ∈ ( 1

2 , 1), and (cid:15)N =

for constants k1 > 0 and 0 < p < min

(cid:16) 1−δ
dγ

, 2δ−1
dξ+2

(cid:17)
.

k1
N p

2. {wi

N (·)} are kernel regression weight functions with the Gaussian, triangular, or Epanechnikov
for

kernel function and hN = k4N −δ for constants k4 > 0 and δ ∈

, and (cid:15)N =

(cid:17)

(cid:16)

0, 1
2dγ

k1
N p

constants k1 > 0 and 0 < p < min

(cid:16)

δ, 1−δdγ
2+dξ

(cid:17)

.

Given Assumption 1, our main result is the following.

Theorem 1. Suppose the weight function and uncertainty sets satisfy Assumption 1, the joint

probability distribution of (γ, ξ) satisﬁes Assumptions 2-4 from Section 4.3, and the cost function

satisﬁes Assumptions 5-6 from Section 4.4. Then, for every ¯γ ∈ Γ,

lim
N→∞

ˆvN (¯γ) = v∗(¯γ), P∞-almost surely.

The theorem says that objective value of (4) will converge almost surely to the optimal value of

the full-information problem, (1), as N goes to inﬁnity. The assumptions of the theorem require

that the joint distribution and the feasible decision rules are well behaved. We will discuss these

technical assumptions in more detail in the following sections.

In order to prove the asymptotic optimality of sample robust optimization with side information,

we view (4) through the more general lens of Wasserstein-based distributionally robust optimiza-

tion. We ﬁrst review some properties of the Wasserstein metric and then prove a key intermediary

result, from which our main result follows.

12

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

4.2. Review of the Wasserstein metric

The Wasserstein metric provides a distance function between probability distributions. In particu-
lar, given two probability distributions Q, Q(cid:48) ∈ P(Ξ), the type-1 Wasserstein distance is deﬁned as

the optimal objective value of a minimization problem:

(cid:40)

d1 (Q, Q(cid:48)) (cid:44) inf

E(ξ,ξ(cid:48))∼Π

(cid:13)ξ − ξ(cid:48)(cid:13)
(cid:13)
(cid:13) :

Π is a joint distribution of ξ and ξ(cid:48)

with marginals Q and Q(cid:48), respectively

(cid:41)

.

The Wasserstein metric is particularly appealing because a distribution with ﬁnite support can

have a ﬁnite distance to a continuous distribution. This allows us to construct a Wasserstein ball

around an empirical distribution that includes continuous distributions, which cannot be done with

other popular measures such as the Kullback-Leilbler divergence (Kullback and Leibler 1951). We

remark that the type-1 Wasserstein metric satisﬁes the axioms of a metric, including the triangle

inequality (Clement and Desch 2008):

d1(Q1, Q2) ≤ d1(Q1, Q3) + d1(Q3, Q2),

∀Q1, Q2, Q3 ∈ P(Ξ).

Important to this paper, the type-1 Wasserstein metric admits a dual form, as shown by Kan-

torovich and Rubinstein (1958),

d1(Q, Q(cid:48)) = sup

|Eξ∼Q[h(ξ)] − Eξ∼Q(cid:48)[h(ξ)]| ,

Lip(h)≤1

where the supremum is taken over all 1-Lipschitz functions. Note that the absolute value is optional

in the dual form of the metric, and the space of Lipschitz functions can be restricted to those which

satisfy h(0) = 0 without loss of generality. Finally, we remark that Fournier and Guillin (2015) prove

under a light-tailed assumption that the 1-Wasserstein distance between the empirical distribution

and its underlying distribution concentrates around zero with high probability. Theorem 2 in the

following section extends this concentration result to the setting with side information.

4.3. Concentration of the empirical conditional probability distribution

Given a local predictive method, let the corresponding empirical conditional measure be deﬁned

as

ˆPN

¯γ :=

N
(cid:88)

i=1

wi

N (¯γ)δξi,

where δξ denotes the Dirac probability distribution which places point mass at ξ. In this section,
we prove under mild assumptions that the empirical conditional measure ˆPN
¯γ concentrates quickly
to P¯γ with respect to the 1-Wasserstein metric. We introduce the following assumptions on the

underlying joint probability distribution:

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

13

Assumption 2 (Conditional Subgaussianity). There exists a parameter σ > 0 such that

P ((cid:107)ξ(cid:107) − E[(cid:107)ξ(cid:107) | γ = ¯γ] > t | γ = ¯γ) ≤ exp

(cid:19)

(cid:18)

−

t2
2σ2

∀t > 0, ¯γ ∈ Γ.

Assumption 3 (Lipschitz Continuity). There exists 0 < L < ∞ such that

d1(P¯γ, P¯γ(cid:48)) ≤ L(cid:107)¯γ − ¯γ (cid:48)(cid:107),

∀¯γ, ¯γ (cid:48) ∈ Γ.

Assumption 4 (Smoothness of Side Information). The set Γ is compact, and there exists

g > 0 such that

P((cid:107)γ − ¯γ(cid:107) ≤ (cid:15)) ≥ g(cid:15)dγ ,

∀(cid:15) > 0, ¯γ ∈ Γ.

Let us reﬂect on the conditions on the underlying joint distribution. Assumption 2 requires that

the distribution of the uncertainty is not heavy-tailed, conditional on the side information. This

is satisﬁed, for example, if ξ has bounded support or follows a Gaussian distribution, conditional

on ¯γ. Assumption 3 requires that the conditional distribution of ξ is a smooth function of γ. This
ensures we can actually learn about the conditional distribution P¯γ from historical data with side

information that are similar (but not identical) to ¯γ. Assumption 4 ensures the side information

are distributed in such a way that every possible ¯γ ∈ Γ has nearby observations in the historical

data, as N → ∞.

With these assumptions, we are ready to prove the concentration result, which is proved using a

novel technique that relies on the dual form of the Wasserstein metric and a discrete approximation

of the space of 1-Lipschitz functions.

Theorem 2. Suppose the weight function and uncertainty sets satisfy Assumption 1 and the

joint probability distribution of (γ, ξ) satisﬁes Assumptions 2-4. Then, for every ¯γ ∈ Γ,

P∞ (cid:16)(cid:110)

d1(P¯γ, ˆPN

¯γ ) > (cid:15)N

(cid:111)

(cid:17)

i.o.

= 0.

Proof. Without loss of generality, we assume throughout the proof that all norms (cid:107) · (cid:107) refer to

the (cid:96)∞ norm.2 Fix any ¯γ ∈ Γ. It follows from Assumption 1 that

N (¯γ)} are not functions of ξ1, . . . , ξN ;

wi

N (¯γ) = 1 and w1

N (¯γ), . . . , wN

N (¯γ) ≥ 0,

{wi
N
(cid:88)

i=1

(cid:15)N =

k1
N p

,

∀N ∈ N;

∀N ∈ N,

(5)

(6)

(7)

14

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

for constants k1, p > 0. Moreover, Assumption 1 also implies that there exist constants k2 > 0 and

η > p(2 + dξ) such that

1
(cid:15)N

lim
N→∞
(cid:34)

N
(cid:88)

i=1
(cid:32)

EPN

exp

wi

N (¯γ)(cid:107)γ i − ¯γ(cid:107) = 0,

P∞-almost surely;

−θ
i=1 wi

(cid:80)N

N (¯γ)2

(cid:33)(cid:35)

≤ exp(−k2θN η),

∀θ ∈ (0, 1), N ∈ N.

(8)

(9)

The proof of the above statements under Assumption 1 is found in Appendix EC.1. Now, choose

any ﬁxed q ∈ (0, η/(2 + dξ) − p), and let

bN (cid:44) N q,

BN (cid:44) (cid:8)ζ ∈ Rdξ : (cid:107)ζ(cid:107) ≤ bN

(cid:9) ,

IN (cid:44) 1 (cid:8)ξ1, . . . , ξN ∈ BN

(cid:9) .

Finally, we deﬁne the following intermediary probability distributions:

ˆQN
¯γ

(cid:44)

N
(cid:88)

i=1

wi

N (¯γ)P

γi,

ˆQN

¯γ|BN

(cid:44)

N
(cid:88)

i=1

wi

N (¯γ)P

γi|BN ,

where P

γi|BN (·) is shorthand for P(· | γ = γ i, ξ ∈ BN ).

Applying the triangle inequality for the 1-Wasserstein metric and the union bound,

P∞ (cid:16)

{d1(P¯γ, ˆPN

¯γ ) > (cid:15)N } i.o.

(cid:17)

≤ P∞ (cid:16)(cid:110)

d1(P¯γ, ˆQN

(cid:111)

(cid:15)N
3

¯γ ) >
¯γ , ˆQN

d1( ˆQN

d1( ˆQN

¯γ|BN

) >

¯γ|BN
, ˆPN

¯γ ) >

(cid:17)

(cid:111)

(cid:111)

i.o.
(cid:15)N
3
(cid:15)N
3

(cid:17)

i.o.
(cid:17)

i.o.

.

+ P∞ (cid:16)(cid:110)
+ P∞ (cid:16)(cid:110)

We now proceed to bound each of the above terms.

Term 1: d1(P¯γ, ˆQN

¯γ ): By the dual form of the 1-Wasserstein metric,

d1(P¯γ, ˆQN

¯γ ) = sup

Lip(h)≤1

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

E[h(ξ)|γ = ¯γ] −

N
(cid:88)

i=1

wi

(cid:12)
(cid:12)
N (¯γ)E[h(ξ)|γ = γ i]
(cid:12)
(cid:12)
(cid:12)

,

where the supremum is taken over all 1-Lipschitz functions. By (6) and Jensen’s inequality, we can

upper bound this by

d1(P¯γ, ˆQN

¯γ ) ≤

=

N
(cid:88)

i=1
N
(cid:88)

i=1

(cid:32)

wi

N (¯γ)

sup
Lip(h)≤1

(cid:12)E[h(ξ)|γ = ¯γ] − E[h(ξ)|γ = γ i](cid:12)
(cid:12)
(cid:12)

(cid:33)

wi

N (¯γ)d1

(cid:0)P¯γ, P

γi

(cid:1)

≤ L

N
(cid:88)

i=1

wi

N (¯γ)(cid:107)¯γ − γ i(cid:107),

where the ﬁnal inequality follows from Assumption 3. Therefore, it follows from (8) that

P∞ (cid:16)(cid:110)

d1(P¯γ, ˆQN

¯γ ) >

(cid:111)

(cid:17)

i.o.

= 0.

(cid:15)N
3

(10)

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

15

Term 2: d1( ˆQN

¯γ , ˆQN

¯γ|BN

¯N ∈ N satisfy b ¯N ≥ σ + sup¯γ∈Γ
all N ≥ ¯N , and all ¯γ (cid:48) ∈ Γ,

): Consider any Lipschitz function Lip(h) ≤ 1 for which h(0) = 0, and let
E[(cid:107)ξ(cid:107)|γ = ¯γ] (which is ﬁnite because of Assumption 4). Then, for

E[h(ξ)|γ = ¯γ (cid:48)] − E[h(ξ) | γ = ¯γ (cid:48), ξ ∈ BN ]

= E[h(ξ)1{ξ /∈ BN } | γ = ¯γ (cid:48)] + E[h(ξ)1{ξ ∈ BN } | γ = ¯γ (cid:48)] − E[h(ξ) | γ = ¯γ (cid:48), ξ ∈ BN ]

= E[h(ξ)1{ξ /∈ BN } | γ = ¯γ (cid:48)] + E[h(ξ) | γ = ¯γ (cid:48), ξ ∈ BN ]P (ξ ∈ BN | γ = ¯γ (cid:48)) − E[h(ξ) | γ = ¯γ (cid:48), ξ ∈ BN ]

= E[h(ξ)1{ξ /∈ BN } | γ = ¯γ (cid:48)] − E[h(ξ) | γ = ¯γ (cid:48), ξ ∈ BN ]P(ξ /∈ BN | γ = ¯γ (cid:48))

≤ E[(cid:107)ξ(cid:107)1{ξ /∈ BN } | γ = ¯γ (cid:48)] + bN P(ξ /∈ BN | γ = ¯γ (cid:48))

=

(cid:90) ∞

bN

P ((cid:107)ξ(cid:107) > t | γ = ¯γ (cid:48)) dt + bN P ((cid:107)ξ(cid:107) ≥ bN | γ = ¯γ (cid:48))

≤ (σ + bN ) exp

−

(cid:32)

(cid:18)

1
2σ2

bN − sup
¯γ(cid:48)∈Γ

(cid:19)2(cid:33)

E[(cid:107)ξ(cid:107)|γ = ¯γ (cid:48)]

.

The ﬁrst inequality follows because |h(ξ)| ≤ bN for all ξ ∈ BN and |h(ξ)| ≤ (cid:107)ξ(cid:107) otherwise. For the
second inequality, we used the Gaussian tail inequality (cid:82) ∞
x e−t2/2dt ≤ e−x2/2 for x ≥ 1 (Vershynin
2018) along with Assumption 2. Because this bound holds uniformly over all h, and all ¯γ (cid:48) ∈ Γ, it

follows that

d1( ˆQN

¯γ , ˆQN

¯γ|BN

) =

sup
Lip(h)≤1,h(0)=0

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

N
(cid:88)

i=1

N (¯γ) (cid:0)E[h(ξ) | γ = γ i] − E[h(ξ) | γ = γ i, ξ ∈ BN ](cid:1)
wi

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

N
(cid:88)

≤

wi

N (¯γ)

i=1
≤ sup
¯γ(cid:48)∈Γ

sup
Lip(h)≤1,h(0)=0

(cid:12)E[h(ξ) | γ = γ i] − E[h(ξ) | γ = γ i, ξ ∈ BN ](cid:12)
(cid:12)
(cid:12)

sup
Lip(h)≤1,h(0)=0

|E[h(ξ) | γ = ¯γ (cid:48)] − E[h(ξ) | γ = ¯γ (cid:48), ξ ∈ BN ]|

(cid:32)

≤ (σ + bN ) exp

−

(cid:18)

1
2σ2

bN − sup
¯γ(cid:48)∈Γ

(cid:19)2(cid:33)

E[(cid:107)ξ(cid:107)|γ = ¯γ (cid:48)]

,

for all N ≥ ¯N . It is easy to see that the right hand side above divided by (cid:15)N /3 goes to 0 as N goes
to inﬁnity, so

P∞ (cid:16)(cid:110)

d1( ˆQN

¯γ , ˆQN

¯γ|BN

) >

(cid:15)N
3

(cid:111)

(cid:17)

i.o.

= 0.

Term 3: d1( ˆQN

¯γ|BN

, ˆPN

¯γ ): By the law of total probability,

PN (cid:16)

d1( ˆQN

¯γ|BN

, ˆPN

¯γ ) >

(cid:17)

(cid:15)N
3

≤ PN (IN = 0) + PN

(cid:18)

d1( ˆQN

¯γ|BN

, ˆPN

¯γ ) >

(cid:19)

IN = 1

.

(cid:15)N
3

(cid:12)
(cid:12)
(cid:12)
(cid:12)

We now show that each of the above terms have ﬁnite summations. First,

∞
(cid:88)

N =1

PN (IN = 0) ≤

∞
(cid:88)

N =1

N sup
¯γ(cid:48)∈Γ

P(ξ /∈ BN | γ = ¯γ (cid:48)) ≤

(cid:32)

N sup
¯γ(cid:48)∈Γ

exp

−

(bN − E [(cid:107)ξ(cid:107) | γ = ¯γ (cid:48)])2
2σ2

(cid:33)

< ∞.

∞
(cid:88)

N =1

16

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

The ﬁrst inequality follows from the union bound, the second inequality follows from Assumption 2,

and the ﬁnal inequality follows because sup¯γ(cid:48)∈Γ

E[(cid:107)ξ(cid:107)|γ = ¯γ (cid:48)] < ∞ and the deﬁnition of bN .

Second, for each l ∈ N, we deﬁne several quantities. Let Pl be the partitioning of BN =
[−bN , bN ]dξ into 2ldξ translations of (−bN 2−l, bN 2−l]dξ . Let Hl be the set of piecewise constant
functions which are constant on each region of the partition Pl, taking values on {kbN 2−l : k ∈
ldξ . Then, we observe that for all Lipschitz
{0, ±1, ±2, ±3, . . . , ±2l}}. Note that |Hl| = (2l+1 + 1)2
functions Lip(h) ≤ 1 which satisfy h(0) = 0, there exists a ˆh ∈ Hl such that

|h(ζ) − ˆh(ζ)| ≤ bN 2−l+1.

sup
ζ∈BN

Indeed, within each region of the partition, h can vary by no more than bN 2−l+1. The possible
function values for ˆh are separated by bN 2−l. Because h is bounded by ±bN , this implies the
existence of ˆh ∈ Hl such that ˆh has a value within bN 2−l+1 of h everywhere within that region. The
identical reasoning holds for all other regions of the partition.

Therefore, for every l ∈ N,

, ˆPN

¯γ ) >

(cid:19)

IN = 1

(cid:15)N
3

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:18)

PN

d1( ˆQN


¯γ|BN

= PN


 sup

Lip(h)≤1
h(0)=0

≤ PN

(cid:32)

sup
ˆh∈Hl

≤ |Hl| sup
ˆh∈Hl

PN

i=1

(cid:32) N
(cid:88)

i=1

N
(cid:88)

i=1

N (¯γ) (cid:0)h(ξi) − E[h(ξ) | γ = γ i, ξ ∈ BN ](cid:1) >
wi



IN = 1




(cid:15)N
3

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

N
(cid:88)

wi

N (¯γ)

(cid:16)ˆh(ξi) − E

(cid:104)ˆh(ξ) | γ = γ i, ξ ∈ BN

(cid:105)(cid:17)

>

(cid:15)N
3

− 2 · bN 2−l+1

(cid:33)

IN = 1

(cid:12)
(cid:12)
(cid:12)
(cid:12)

wi

N (¯γ)

(cid:16)ˆh(ξi) − E

(cid:104)ˆh(ξ) | γ = γ i, ξ ∈ BN

(cid:105)(cid:17)

>

(cid:15)N
3

− bN 2−l+2

(cid:33)

IN = 1

,

(cid:12)
(cid:12)
(cid:12)
(cid:12)

where the ﬁnal inequality follows from the union bound. We choose l =

(cid:108)
2 + log2

6bN
(cid:15)N

(cid:109)

, in which

case

Furthermore, for all suﬃciently large N ,

(cid:15)N
3

− bN 2−l+2 ≥

(cid:15)N
6

.

|Hl| = (2l+1 + 1)2

ldξ ≤

(cid:18)

96

bN
(cid:15)N

(cid:19)24

dξ (bN /(cid:15)N )

dξ

(cid:32)

= exp

24dξ

(cid:19)dξ

(cid:18) bN
(cid:15)N

log

96bN
(cid:15)N

(cid:33)

.

Applying Hoeﬀding’s inequality, and noting |ˆh(ξi)| is bounded by bN when ξi ∈ BN , we have the
following for all ˆh ∈ Hl:

(cid:32) N
(cid:88)

PN

i=1

wi

N (¯γ)

(cid:17)
(cid:16)ˆh(ξi) − E[ˆh(ξ)|ξ ∈ BN , γ = γ i]

>

(cid:33)

IN = 1

(cid:15)N
6

(cid:12)
(cid:12)
(cid:12)
(cid:12)

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

17

wi

N (¯γ)

(cid:17)
(cid:16)ˆh(ξi) − E[ˆh(ξ)|ξ ∈ BN , γ = γ i]

>

(cid:15)N
6

(cid:12)
(cid:12)
(cid:12)
(cid:12)

IN = 1, γ 1, . . . , γ N

(cid:35)

IN = 1

(cid:33) (cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:34)

= E

PN

(cid:34)

(cid:32) N
(cid:88)

i=1

(cid:32)

≤ E

exp

−

(cid:34)

(cid:32)

= E

exp

−

(cid:34)

(cid:32)

≤ 2E

exp

−

(cid:18)

≤ 2 exp

−

k2N η(cid:15)2
N
72b2
N

,

(cid:35)

IN = 1

(cid:35) (cid:18)

(cid:19)

1
PN (IN = 1)

(cid:33) (cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:33)

IN

(cid:33)(cid:35)

72 (cid:80)N

72 (cid:80)N

(cid:15)2
N
i=1(wi
N (¯γ))2b2
N
(cid:15)2
N
N (¯γ))2b2
i=1(wi
N
(cid:15)2
N
72 (cid:80)N
N (¯γ))2b2
i=1(wi
N
(cid:19)

for N suﬃciently large that P(IN = 1) ≥ 1/2 and (cid:15)2

N /72b2

N < 1. Note that (9) was used for the ﬁnal

inequality. Combining these results, we have

(cid:18)

PN

d1(ˆPN

¯γ , ˆQN

¯γ|BN

) > (cid:15)N /3

(cid:19)

IN = 1

≤ 2 exp

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:32)

24dξ

(cid:19)dξ

(cid:18) bN
(cid:15)N

log

96bN
(cid:15)N

−

k2(cid:15)2
N N η
72N b2
N

(cid:33)

,

for N suﬃciently large. For some constants c1, c2 > 0, and suﬃciently large N , this is upper bounded

by

2 exp (cid:0)−c1N η−2(p+q) + c2N dξ(q+p) log N (cid:1) .

Since 0 < dξ(p + q) < η − 2(p + q), we can conduct a limit comparison test with 1/N 2 to see that
this term has a ﬁnite sum over N , which completes the proof. (cid:3)

4.4. Proof of main result

Theorem 2 provides the key ingredient for the proof of the main consistency result. We state our

ﬁnal two assumptions on the dynamic optimization problem to establish our main result.

Assumption 5 (Regularity of robust problem). For all ¯γ ∈ Γ, there exists M ≥ 0 such that

the objective value of (4) would not change if we restricted its optimization to the decision rules

π ∈ Π which satisfy

|cπ(ζ1, . . . , ζT )| ≤ M

1 + max

(cid:107)ζ(cid:107) ,

(cid:32)

(cid:40)

(cid:41)(cid:33)

(cid:107)ζ(cid:48)(cid:107)

,

∀ζ ∈ Ξ.

sup
i=1U i
N

ζ(cid:48)∈∪N

Assumption 6 (Regularity of stochastic problem). For all ¯γ ∈ Γ, there exists M (cid:48) ≥ 0 such

that the objective value of (1) would not change if we restricted the optimization to the decision

rules π ∈ Π for which cπ(ζ1, . . . , ζT ) is upper semicontinuous and |cπ(ζ1, . . . , ζT )| ≤ M (cid:48)(1 + (cid:107)ζ(cid:107))
for all ζ ∈ Ξ.

18

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

Assumption 5 is a minor modiﬁcation to Bertsimas et al. (2018a, Assumption 3), and can be veriﬁed

by decision makers through performing a static analysis; see Bertsimas et al. (2018a, Appendix A).

Assumption 6 is a condition on structure of optimal decision rules of the stochastic problem, which

is nearly identical to the assumptions of Mohajerin Esfahani and Kuhn (2018, Theorem 3.6(i))

which are used to establish asymptotic optimality for distributionally robust optimization with the

type-1 Wasserstein ambiguity set.

Under these assumptions, the proof of Theorem 1 follows from Theorem 2 via arguments similar

to those used by Mohajerin Esfahani and Kuhn (2018) and Bertsimas et al. (2018a). We state the

proof fully in Appendix EC.2.

5.

Implications for Single-Period Distributionally Robust
Optimization

Beyond its utility in the context of multi-period problems, the measure concentration result of the

previous section (Theorem 2) has potentially valuable implications for distributionally robust opti-

mization with the type-1 Wasserstein ambiguity set. Indeed, consider a single-period optimization

problem of the form

minimize
x∈X ⊆Rdx

EP [c(x, ξ)] ,

(11)

where ξ ∈ Ξ ⊆ Rdξ is a random vector with a probability distribution P. When the distribution
is unknown and observable only through limited historical data (ξ1, . . . , ξN ) ∼ PN , there has been

recent interest in approximating the above problems by distributionally robust optimization with

the type-1 Wasserstein ambiguity set:

minimize
x∈X ⊆Rdx

sup
Q∈P(Ξ): d1(Q,ˆPN )≤(cid:15)N

EQ [c(x, ξ)] .

(12)

Due to several attractive properties, (12) and its relatives have received considerable recent

interest in a variety of single-period operational and statistical applications. Indeed, when the

robustness parameter is chosen appropriately and other mild assumptions hold, (12) is guaranteed

to be asymptotically optimal (Mohajerin Esfahani and Kuhn 2018, Theorem 3.6) and the worst-

case cost can often be reformulated as a tractable optimization problem (Mohajerin Esfahani and

Kuhn 2018, Blanchet and Murthy 2019, Gao and Kleywegt 2016). Moreover, there is growing

empirical evidence that (12) with a positive choice of the robustness parameter ((cid:15)N > 0) can ﬁnd

solutions with signiﬁcantly better average out-of-sample cost compared to those obtained by the

sample average approximation ((cid:15)N = 0), particularly when the number of data points is small; see,

for example, Mohajerin Esfahani and Kuhn (2018, Section 7.2) and Hanasusanto and Kuhn (2018,

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

19

Section 4.2). Theoretical results which aim to explain this improved average out-of-sample cost,

both for (12) as well as related robust approaches, are found in Gotoh et al. (2018) and Anderson

and Philpott (2019).

In the remainder of this section, using the results from Section 4.3, we now show how side

information and machine learning can be easily incorporated into any problem of the form (12),

without foregoing its asymptotic optimality or computational tractability. Indeed, consider a single-

period optimization problem of the form

v∗(¯γ) (cid:44) minimize
x∈X ⊆Rdx

EP [c(x, ξ) | γ = ¯γ] ,

(13)

where ξ ∈ Ξ ⊆ Rdξ and γ ∈ Γ ⊆ Rdγ are random vectors with a joint probability distribution P.

Assume that the distribution is unknown and observable only through limited historical data
((γ 1, ξ1), . . . , (γ N , ξN )) ∼ PN . We address these problems by a modiﬁcation of distributionally

robust optimization with the type-1 Wasserstein ambiguity set, wherein the empirical probability
distribution ˆPN is replaced with an empirical conditional probability distribution ˆPN

¯γ (see Sec-

tion 4.3):

vN (¯γ) (cid:44) minimize
x∈X ⊆Rdx

sup

EQ [c(x, ξ)] .

Q∈P(Ξ): d1(Q,ˆPN

¯γ )≤(cid:15)N

(14)

As discussed previously, the empirical conditional probability distribution can be constructed using

a variety of machine learning methods, such as k-nearest neighbor regression or kernel regression.

For this modiﬁcation, we obtain the following asymptotic optimality guarantee which is analogous

to (12) developed by Mohajerin Esfahani and Kuhn (2018).

Theorem 3. Suppose the weight function and uncertainty sets satisfy Assumption 1 and the

joint probability distribution of (γ, ξ) satisﬁes Assumptions 2-4. Assume that ˆxN represents an

optimizer of (14). Then the following hold for every ¯γ ∈ Γ:

(i) If c(x, ξ) is upper semicontinuous in ξ and there exists L ≥ 0 with |c(x, ξ)| ≤ L(1 + (cid:107)ξ(cid:107)) for

all x ∈ X and ξ ∈ Ξ, then P∞-almost surely we have ˆvN (¯γ) ↓ v∗(¯γ) as N → ∞.

(ii) If the assumptions of assertion (i) hold, X is closed, and c(x, ξ) is lower semicontinuous in
x for every ξ ∈ Ξ, then any accumulation point of {ˆxN }N ∈N is P∞-almost surely an optimal

solution for (13).

Proof. The proof follows from identical reasoning as Mohajerin Esfahani and Kuhn (2018,

Theorem 3.6), in which the measure concentration result of Fournier and Guillin (2015, Theorem
2) is replaced by Theorem 2 of the present paper. (cid:3)

20

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

From the perspective of computational tractability, it is readily observed that (14) retains an

identical computational tractability as (12), except where terms of the form 1

N are replaced with
N (¯γ); see, for example, Mohajerin Esfahani and Kuhn (2018, Theorem 4.2). As a result of Theorem
3, we conclude that side information can be tractably incorporated into the variety of operational

wi

applications that utilize (single-period) Wasserstein-based distributionally robust optimization.

6. Tractable Approximations

In the previous sections, we presented the new framework of sample robust optimization with side

information and established its asymptotic optimality in the context of (1) without any signiﬁcant

structural restrictions on the space of decision rules. In this section, we focus on tractable meth-

ods for approximately solving the robust optimization problems that result from this proposed

framework. Speciﬁcally, we develop a formulation which uses auxiliary decision rules to approxi-

mate the cost function. In combination with linear decision rules, this approach enables us to ﬁnd

high-quality decisions for real-world problems with more than ten stages in less than one minute,

as we demonstrate in Section 7.

We focus in this section on dynamic optimization problems with cost functions of the form

c (ξ1, . . . , ξT , x1, . . . , xT )

(cid:32)

=

T
(cid:88)

t=1

t xt + g(cid:124)
f (cid:124)

t ξt + min
yt∈Rdt

y

(cid:40)

h(cid:124)
t yt :

t
(cid:88)

s=1

At,sxs +

t
(cid:88)

s=1

(cid:41)(cid:33)

Bt,sξs + Ctyt ≤ dt

.

(15)

Such cost functions appear frequently in applications such as inventory management and sup-

ply chain networks. Unfortunately, it is well known that these cost functions are convex in the

uncertainty ξ1, . . . , ξT . Thus, even evaluating the worst-case cost over a convex uncertainty set is
computationally demanding in general, as it requires the maximization of a convex function.

As an intermediary step towards developing an approximation scheme for (4) with the above

cost function, we consider the following optimization problem:

˜vN (¯γ) (cid:44)

minimize

π∈Π, yi

t∈Rt ∀i,t

subject to

N
(cid:88)

i=1

t
(cid:88)

s=1

wi

N (¯γ) sup
ζ∈U i
N

T
(cid:88)

t=1

(cid:0)f (cid:124)

t πt(ζ1, . . . , ζt−1) + g(cid:124)

t ζt + h(cid:124)

t yi

t(ζ1, . . . , ζt)(cid:1)

At,sπs(ζ1, . . . , ζs−1) +

t
(cid:88)

s=1

Bt,sζs + Ctyi

t(ζ1, . . . , ζt) ≤ dt

(16)

∀ζ ∈ U i

N , i ∈ {1, . . . , N }, t ∈ {1, . . . , T },

where Rt is the set of all functions y : Ξ1 × · · · × Ξt → Rdt
auxiliary decision rules which capture the minimization portion of (15) in each stage. We refer to

y . In this problem, we have introduced

(16) as a multi-policy approach, as it involves diﬀerent auxiliary decision rules for each uncertainty

set. The following theorem shows that (16) is equivalent to (4).

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

21

Theorem 4. For cost functions of the form (15), ˜vN (¯γ) = ˆvN (¯γ).

Proof. See Appendix EC.3. (cid:3)

We observe that (16) involves optimizing over decision rules, and thus is computationally challeng-

ing to solve in general. Nonetheless, we can obtain a tractable approximation of (16) by further

restricting the space of primary and auxiliary decision rules. For instance, we can restrict all pri-

mary and auxiliary decision rules as linear decision rules of the form

πt

(cid:0)ζ1, . . . , ζt−1

(cid:1) = xt,0 +

t−1
(cid:88)

s=1

Xt,sζs,

t(ζ1, . . . , ζt) = yi
yi

t,0 +

t
(cid:88)

s=1

Yi

t,sζs.

One can alternatively elect to use a richer class of decision rules, such as lifted linear decision rules

(Chen and Zhang 2009, Georghiou et al. 2015). In all cases, feasible approximations that restrict

the space of decision rules of (16) provide an upper bound on the cost ˆvN (¯γ) and produce decision

rules that are feasible for (16).

The key beneﬁt of the multi-policy approximation scheme is that it oﬀers many degrees of

freedom in approximating the nonlinear cost function. Speciﬁcally, in (16), a separate auxiliary

decision rule yi

We approximate each yi

t captures the value of the cost function for each uncertainty set in each stage.
t with a linear decision rule, which only needs to be locally accurate, i.e.,
accurate for realizations in the corresponding uncertainty set. As a result, (16) with linear decision

rules results in signiﬁcantly tighter approximations of (4) compared to using a single linear decision

rule, yt, for all uncertainty sets in each stage. Moreover, these additional degrees of freedom come

with only a mild increase in computation cost, and we substantiate these claims via computational

experiments in Section 7.1. In Appendix EC.4, we provide the reformulation of the multi-policy

approximation scheme with linear decision rules into a deterministic optimization problem using

standard techniques from robust optimization.

7. Computational Experiments

We perform computational experiments to assess the out-of-sample performance and computational

tractability of the proposed methodologies across several applications. These examples are dynamic

inventory management (Section 7.1), portfolio optimization (Section 7.2), and shipment planning

(Section 7.3).

We compare several methods using diﬀerent machine learning models. These methods include

the proposed sample robust optimization with side information, sample average approximation

(SAA), the predictions to prescriptions (PtP) approach of Bertsimas and Kallus (2020), and sample

robust optimization without side information (SRO). In Table 1, we show that each of the above

22

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

Table 1

Relationship of four methods.

(cid:15)N

wi

N (¯γ) = 1

N for all i

wi

N (¯γ) from machine learning

= 0 Sample average approximation Bertsimas and Kallus (2020)
> 0

Bertsimas et al. (2018a)

This paper

methods are particular instances of (4) from Section 3. The methods in the left column ignore

side information by assigning equal weights to each uncertainty set, and the methods in the right

column incorporate side information by choosing the weights based on predictive machine learning.

The methods in the top row do not incorporate any robustness ((cid:15)N = 0), and the methods in the

bottom row incorporate robustness via a positive choice of the robustness parameter ((cid:15)N > 0) in the

uncertainty sets. In addition, for the dynamic inventory management example, we also implement

and compare to the residual tree algorithm described in Ban et al. (2019). In each experiment,

the relevant methods are applied to the same training datasets, and their solutions are evaluated

against a common testing dataset. Further details are provided in each of the following sections.

7.1. Dynamic inventory management

We ﬁrst consider a dynamic inventory control problem over the ﬁrst T = 12 weeks of a new prod-

uct. In each week, a retailer observes demand for the product and can replenish inventory via

procurement orders to diﬀerent suppliers with lead times. Our problem setting closely follows Ban

et al. (2019), motivated by the fashion industry in which retailers have access to auxiliary side

information on the new product (color, brand) which are predictive of how demand unfolds over

time.

Problem Description. In each stage t ∈ {1, . . . , T }, the retailer procures inventory from multiple

suppliers to satisfy demand for a single product. The demands for the product across stages are

denoted by ξ1, . . . , ξT ≥ 0. In each stage t, and before the demand ξt is observed, the retailer places

procurement orders at various suppliers indexed by J = {1, . . . , |J |}. Each supplier j ∈ J has per-

unit order cost of ctj ≥ 0 and a lead time of (cid:96)j stages. At the end of each stage, the ﬁrm incurs a

per-unit holding cost of ht and a backorder cost of bt. Inventory is fully backlogged and the ﬁrm

starts with zero initial inventory. The cost incurred by the ﬁrm over the time horizon is captured

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

23

by

c(ξ1, . . . , ξT , x1, . . . , xT ) =

T
(cid:88)

(cid:88)

t=1

j∈J

ctjxtj +

T
(cid:88)

t=1

minimize
yt∈R

yt

subject to yt ≥ ht



(cid:88)



j∈J


t−(cid:96)j
(cid:88)

s=1

xsj −



ξs



t
(cid:88)

s=1

yt ≥ −bt

(cid:88)



t−(cid:96)j
(cid:88)

xsj −

j∈J

s=1



ξs

 .

t
(cid:88)

s=1

Experiments. The parameters of the procurement problem were chosen based on Ban et al.

(2019). Speciﬁcally, we consider the case of two suppliers where ct1 = 1.0, ct2 = 0.5, ht = 0.25, and

bt = 11 for each stage. The ﬁrst supplier has no lead time and the second supplier has a lead time of

one stage. We generate training and test data from the same distribution as a shipment planning

problem of Bertsimas and Kallus (2020, Section EC.6), with the exception that we generate the side

information as i.i.d. samples as opposed to an ARMA process (but with the same marginal distri-

bution). In this case, the demands produced by this data generating process are interpreted as the

demands over the T = 12 stages. We perform computational experiments comparing the proposed

sample robust optimization with side information and the residual tree algorithm proposed by Ban

et al. (2019). In particular, we compare sample robust optimization with side information with the

multi-policy approximation as well as without the multi-policy approximation (in which we use a

single auxiliary linear decision rule for yt for all uncertainty sets in each stage). The uncertainty
sets from Section 3 are deﬁned with the (cid:96)2 norm and Ξ = R12

+ . The out-of-sample cost resulting from
the decision rules were averaged over 100 training sets of size N = 40 and 100 testing points, and

sample robust optimization with side information used k-nearest neighbors with varying choices of

k and radius (cid:15) ≥ 0 of the uncertainty sets.

Results. In Table 2, we show the average out-of-sample cost resulting from sample robust opti-

mization with side information using linear decision rules, with and without the multi-policy

approximation from Section 6. In both settings, we used k-nearest neighbors as the machine learn-

ing method and evaluated the out-of-sample performance by applying the linear decision rules for

the ordering quantities. The results of these computational experiments in Table 2 demonstrate

that signiﬁcant improvements in average out-of-sample performance are found when combining

the multi-policy approximation with side information via k-nearest neighbors. We show in Table 3

that these results are statistically signiﬁcant. For comparison, we also implemented the residual

tree algorithm from Ban et al. (2019). When using their algorithm with a binning of B = 2 in

each stage, their approach resulted in an average out-of-sample cost of 27142. We were unable to

24

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

Table 2

Average out-of-sample cost for dynamic inventory problem.

Method
Sample robust optimization
Linear decision rules

no side information
k-nearest neighbors

Linear decision rules with multi-policy

no side information
k-nearest neighbors

k

0

100

200

300

400

500

600

700

(cid:15)

9669
9600
9640
9862

8783
8566
8544
8561

8590 8789 9150 9604 10102 10614
8411 8642 9030 9494 10001 10528
10505
8375 8603 8996 9464
10473
8365 8573 8960 9433

9974
9943

26
20
13

7360 7320 7460 7716
8967
7651 7269 7241 7381
26 11346
7925 7328 7195 7289
20 13012
13 16288 10975 8576 7585 7243 7236

7759
8728
9460

8038
7636
7519
7412

8412
7966
7835
7697

Average out-of-sample cost for the dynamic inventory problem using sample robust optimization with N = 40. For each
uncertainty set radius (cid:15) and parameter k, average was taken over 100 training sets and 100 test points. Optimal is indicated
in bold. The residual tree algorithm with a binning of B = 2 in each stage gave an average out-of-sample cost of 27142.

Table 3

Method
Sample robust optimization

Linear decision rules

no side information
k-nearest neighbors

Linear decision rules with multi-policy

no side information
k-nearest neighbors

Statistical signiﬁcance for dynamic inventory problem.
(cid:15)
400

0 100 200 300

k

500

600 700

*
26 *
20 *
13 *

*
26 *
20 *
13 *

*
*
*
*

*
*
*
*

*
*
*
*

*
*
*
*

*
*
*
*

*
*
*
*

*
*
*
*

*
∗
-

*
*
*
*

*
*
*

5.8 × 10−3 1 × 10−3

*
*
*
*

*
*
*
*

*
*
*
*

*
*
*
*

The p-values of the Wilcoxon signed rank test for comparison with sample robust optimization using linear decision rules
with multi-policy, k = 20, and (cid:15) = 400. An asterisk denotes that the p-value was less than 10−8. After adjusting for multiple
hypothesis testing, each result is signiﬁcant at the α = 0.05 signiﬁcance level if its p-value is less than 0.05
63

≈ 7.9 × 10−4.

run with a binning of B = 3 in each stage due to time limitations of 103 seconds, as the size of

the resulting linear optimization problem scales on the order O(BT ). Such results are consistent

with the estimations of computation times presented in (Ban et al. 2019, Section 6.3). The running

times of the various methods are displayed in Table 4.

7.2. Portfolio optimization

The guarantees developed in this paper (Theorem 1) and the above numerical experiment shows

that (4) is practically tractable and performs well in problems where T ≥ 1. In the current and the

following section, we provide numerical evidence that (4) can also outperform existing approaches

on single-period problems.

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

25

Table 4

Average computation time (seconds) for dynamic inventory problem.

Method
Sample robust optimization

Linear decision rules

no side information
k-nearest neighbors

Linear decision rules with multi-policy

no side information
k-nearest neighbors

k

0

100

200

300

400

500

600

700

(cid:15)

3.86 25.04 24.75 25.82 28.70 35.37 31.13 31.95
26 4.02 25.43 23.39 25.15 27.88 33.42 30.87 31.60
20 3.99 25.98 23.56 24.93 27.41 32.67 30.69 31.50
13 4.19 26.53 24.89 24.99 26.79 31.64 30.23 31.32

0.16 28.31 30.01 29.05 31.13 36.03 35.57 36.09
26 0.15 27.74 28.69 27.78 30.54 34.44 35.50 36.15
20 0.15 27.87 28.51 27.74 30.60 34.36 35.65 36.99
13 0.14 27.78 28.30 27.27 30.00 33.67 35.91 37.76

Average computation time (seconds) for the dynamic inventory problem using sample robust optimization with N = 40.
For each choice of uncertainty set radius (cid:15) and parameter k, average was taken over 100 training sets. The residual tree
algorithm of Ban et al. (2019) with a binning of B = 2 in each stage had an average computation time of 23.20 seconds.
We were unable to run this algorithm with binning of B = 3 in each stage.

Speciﬁcally, in this section we consider a single-stage portfolio optimization problem in which

we wish to ﬁnd an allocation of a ﬁxed budget to n assets. Our goal is to simultaneously maximize

the expected return while minimizing the the conditional value at risk (cVaR) of the portfolio.

Before selecting our portfolio, we observe auxiliary side information which include general market

indicators such as index performance as well as macroeconomic numbers released by the US Bureau

of Labor Statistics.

(cid:80)n

Problem Description. We denote the portfolio allocation among the assets by x ∈ X (cid:44) {x ∈ Rn
+ :
j=1 xj = 1}, and the returns of the assets by the random variables ξ ∈ Rn. The conditional value
at risk at the α ∈ (0, 1) level measures the expected loss of the portfolio, conditional on losses

being above the 1 − α quantile of the loss distribution. Rockafellar and Uryasev (2000) showed that

the cVaR of a portfolio can be computed as the optimal objective value of a convex minimization

problem. Therefore, our portfolio optimization problem can be expressed as a convex optimization
problem with an auxiliary decision variable, β ∈ R. Thus, given an observation ¯γ of the auxiliary

side information, our goal is to solve

minimize
x∈X , β∈R

(cid:20)

β +

E

1
α

max(0, −x(cid:124)ξ − β) − λx(cid:124)ξ

(cid:21)

,

γ = ¯γ

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(17)

where λ ∈ R+ is a trade-oﬀ parameter that balances the risk and return objectives.

Experiment. Our experiments are based on a similar setting from Bertsimas and Van Parys

(2017, Section 5.2). Speciﬁcally, we perform computational experiments on an instance with param-

eters α = 0.05 and λ = 1, and the joint distribution of the side information and asset returns are

chosen the same as Bertsimas and Van Parys (2017, Section 5.2). In our experiments, we compare

sample robust optimization with side information, sample average approximation, sample robust

26

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

optimization, and predictions to prescriptions. For the robust approaches (bottom row of Table 1),

we construct the uncertainty sets from Section 3 using the (cid:96)1 norm. For each training sample size,

we compute the out-of-sample objective on a test set of size 1000, and we average the results over

100 instances of training data.

In order to select (cid:15)N and other tuning parameters associated with the machine learning weight

functions, we ﬁrst split the data into a training and validation set. We then train the weight

functions using the training set, compute decisions for each of the instances in the validation set,

and compute the out-of-sample cost on the validation set. We repeat this for a variety of parameter

values and select the combination that achieves the best cost on the validation set.

Following a similar reformulation approach as Mohajerin Esfahani and Kuhn (2018), we solve

the robust approaches exactly by observing that

minimize
x∈X , β∈R

= minimize
x∈X , β∈R

= minimize
x∈X , β∈R

=

minimize
x∈X , β∈R,v∈RN

subject to

(cid:26)

β +

1
α

max{0, −x(cid:124)ζ − β} − λx(cid:124)ζ

(cid:27)

(cid:26)

max

(cid:26)

β − λx(cid:124)ζ,

(cid:19)

x(cid:124)ζ

+ λ

(cid:27)(cid:27)

(cid:18) 1
α

(cid:40)

sup
ζ∈U i
N

{β − λx(cid:124)ζ} , sup
ζ∈U i
N

(cid:19)

(cid:41)

x(cid:124)ζ

,

+ λ

(cid:18) 1
α

N
(cid:88)

i=1

N
(cid:88)

i=1

N
(cid:88)

i=1

N
(cid:88)

i=1

wi

N (¯γ) sup
ζ∈U i
N

wi

N (¯γ) sup
ζ∈U i
N

wi

N (¯γ) max

wi

N (¯γ)vi

vi ≥ β − λx(cid:124)ζ
(cid:19)
(cid:18) 1
α
∀ζ ∈ U i

vi ≥

+ λ

x(cid:124)ζ

N , i ∈ {1, . . . , N }.

The ﬁnal expression can be reformulated as a deterministic optimization problem by reformulating

the robust constraints.

Results. In Figure 1, we show the average out-of-sample objective values using the various meth-

ods. Consistent with the computational results of Mohajerin Esfahani and Kuhn (2018) and Bert-

simas and Van Parys (2017), the results underscore the importance of robustness in preventing

overﬁtting and achieving good out-of-sample performance in the small data regime. Indeed, we

observe that the sample average approximation, which ignores the auxiliary data, outperforms

PtP-kNN and PtP-CART when the amount of training data is limited. We believe this is due

to the fact the latter methods both throw out training examples, so the methods overﬁt when

the training data is limited, leading to poor out-of-sample performance. In contrast, our meth-

ods (SRO-kNN and SRO-CART) typically achieve the strongest out-of-sample performance, even

though the amount of training data is limited.

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

27

Figure 1

Out-of-sample objective for the portfolio optimization example.

7.3. Shipment planning

We ﬁnally consider a shipment planning problem in which a decision maker seeks to satisfy demand

in several locations from several production facilities while minimizing production and transporta-

tion costs. Our problem setting closely follows Bertsimas and Kallus (2020), in which the decision

maker has access to auxiliary side information (promotions, social media, market trends), which

may be predictive of future sales in each retail location.

Problem Description. The decision maker ﬁrst decides the quantity of inventory xf ≥ 0 to pro-
duce in each of the production facilities f ∈ F (cid:44) {1, . . . , |F|}, at a cost of p1 per unit. The demands
ξ(cid:96) ≥ 0 in each location (cid:96) ∈ L (cid:44) {1, . . . , |L|} are then observed. The decision maker fulﬁlls these

demands by shipping sf (cid:96) ≥ 0 units from facility f ∈ F to location (cid:96) ∈ L at a per-unit cost of cf (cid:96) > 0.

Additionally, after observing demand, the decision maker has the opportunity to produce addi-

tional units yf ≥ 0 in each facility at a cost of p2 > p1 per unit. The fulﬁllment of each unit of

demand generates r > 0 in revenue. Given the above notation and dynamics, the cost incurred by

the decision maker is

c(ξ, x) =

(cid:88)

f ∈F

p1xf −

(cid:88)

(cid:96)∈L

rξ(cid:96) + minimize
s∈RL×F
, y∈RF
+
+

subject to

p2yf +

(cid:88)

(cid:88)

f ∈F

(cid:96)∈L

cf (cid:96)sf (cid:96)

sf (cid:96) ≥ ξ(cid:96)

∀(cid:96) ∈ L

sf (cid:96) ≤ xf + yf

∀f ∈ F.

(cid:88)

f ∈F
(cid:88)

f ∈F
(cid:88)

(cid:96)∈L

Experiments. We perform computational experiments using the same parameters and data gener-

ation procedure as Bertsimas and Kallus (2020). Speciﬁcally, we consider an instance with |F| = 4,

28

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

Figure 2

Out-of-sample proﬁt for the shipment planning example.

Note. The proﬁts for SRO and SAA are overlapping.

|L| = 12, p1 = 5, p2 = 100, and r = 90. The network topology, transportation costs, and the joint
distribution of the side information γ ∈ R3 and demands ξ ∈ R12 are the same as Bertsimas and

Kallus (2020), with the exception that we generate the side information as i.i.d. samples as opposed

to an ARMA process (but with the same marginal distribution).

In our experiments, we compare sample robust optimization with side information, sample aver-

age approximation, sample robust optimization, and predictions to prescriptions. For the robust

approaches (bottom row of Table 1), we construct the uncertainty sets from Section 3 using the
(cid:96)1 norm and Ξ = R12

+ , solve these problems using the multi-policy approximation with linear deci-

sion rules described in Section 6, and consider uncertainty sets with radius (cid:15) ∈ {100, 500}. For the

approaches using side information (right column of Table 1), we used the kN -nearest neighbors

with parameter kN = 2N

5 . All solutions were evaluated on a test set of size 100 and the results were

averaged over 100 independent training sets.

Results. In Figure 2, we present the average out-of-sample proﬁts of the various methods. The

results show that the best out-of-sample average proﬁt is attained when using the proposed sam-

ple robust optimization with side information. Interestingly, we observe no discernible diﬀerences

between sample average approximation and sample robust optimization in Figure 2, suggesting

the value gained by incorporating side information in this example. Compared to the approach of

Bertsimas and Kallus (2020), sample robust optimization with side information achieves a better

out-of-sample average performance for each choice of (cid:15). Table 5 shows that these diﬀerences are

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

29

Table 5

Statistical signiﬁcance for shipment planning

problem.
(cid:15)

N
50
75
100
125
150
200
250
300

100
4.6 × 10−13
1.3 × 10−14
1.2 × 10−13
2.6 × 10−15
3.4 × 10−12
1.4 × 10−12
3.4 × 10−10
1.8 × 10−6

500
5.3 × 10−16
6.4 × 10−12
1.1 × 10−7
1.5 × 10−11
1.2 × 10−6
1.0 × 10−8
1.0 × 10−4
5.2 × 10−4

The p-values from the Wilcoxon signed rank test for
comparison with the predictive to prescriptive analytics
method (PtP-kNN) and sample robust optimization with
side information (SRO-kNN). After adjusting for multiple
hypothesis testing, all results are signiﬁcant at the α =
0.05 signiﬁcance level because all p-values are less than
0.05
16

≈ 3.1 × 10−3.

statistically signiﬁcant. This example demonstrates that, in addition to enjoying asymptotic opti-

mality guarantees, sample robust optimization with side information provides meaningful value

across various values of N .

8. Conclusion

In this paper, we introduced sample robust optimization with side information, a new approach for

solving dynamic optimization problems with side information. Through three computational exam-

ples, we demonstrated that our method achieves signiﬁcantly better out-of-sample performance

than scenario-based alternatives. We complemented these empirical observations with theoretical

analysis, showing our nonparametric method is asymptotically optimal via a new concentration

measure result for local learning methods. Finally, we showed our approach inherits the tractability

of robust optimization, scaling to problems with many stages via the multi-policy approximation

scheme.

Acknowledgements

The authors thank the associate editor and two referees for many helpful suggestions that greatly

improved the manuscript.

30

Endnotes

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

1. If the random vectors are continuous and T ≥ 2, it is readily observed that (2) resolves to an

optimization problem of the form

x1∈X1; xi

minimize
2∈X2,...,xi

T ∈XT ∀i

N
(cid:88)

i=1

N (¯γ)c (cid:0)ξi
wi

1, . . . , ξi

T , x1, xi

2, . . . , xi

T

(cid:1) .

2. To see why this is without loss of generality, consider any other (cid:96)p norm where p ≥ 1. In this

case,

By the deﬁnition of the 1-Wasserstein metric, this implies

(cid:107)ξ − ξ(cid:48)(cid:107)p ≤ d1/p

ξ (cid:107)ξ − ξ(cid:48)(cid:107)∞.

1(P¯γ, ˆPN
dp

¯γ ) ≤ d1/p

ξ d∞

1 (P¯γ, ˆPN

¯γ ),

where dp

1 refers to the 1-Wasserstein metric with the (cid:96)p norm. If (cid:15)N satisﬁes Assumption 1, (cid:15)N /d1/p
also satisﬁes Assumption 1, so the result for all other choices of (cid:96)p norms follows from the result

ξ

with the (cid:96)∞ norm.

References

Anderson E, Philpott A (2019) Improving sample average approximation using distributional robustness

URL http://www.optimization-online.org/DB_FILE/2019/10/7405.pdf.

Ban GY, Gallien J, Mersereau AJ (2019) Dynamic procurement of new products with covariate information:

The residual tree method. Manufacturing & Service Operations Management 21(4):798–815.

Ban GY, Rudin C (2018) The big data newsvendor: practical insights from machine learning. Operations

Research 67(1):90–108.

Bertsimas D, Kallus N (2020) From predictive to prescriptive analytics. Management Science 66(3):1025–

1044.

Bertsimas D, McCord C (2019) From predictions to prescriptions in multistage optimization problems. arXiv

preprint arXiv:1904.11637 .

Bertsimas D, Shtern S, Sturt B (2018a) A data-driven approach to multi-stage stochastic linear optimization

URL http://www.optimization-online.org/DB_FILE/2018/11/6907.pdf.

Bertsimas D, Shtern S, Sturt B (2019) Two-stage sample robust optimization. arXiv preprint

arXiv:1907.07142 .

Bertsimas D, Sim M, Zhang M (2018b) Adaptive distributionally robust optimization. Management Science

65(2):604–618.

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

31

Bertsimas D, Van Parys B (2017) Bootstrap robust prescriptive analytics. arXiv preprint arXiv:1711.09974

.

Biau G, Devroye L (2015) Lectures on the Nearest Neighbor Nethod (Springer).

Blanchet J, Murthy K (2019) Quantifying distributional model risk via optimal transport. Mathematics of

Operations Research 44(2):565–600.

Breiman L (2001) Random forests. Machine Learning 45(1):5–32.

Breiman L, Friedman JH, Olshen RA, Stone CJ (1984) Classiﬁcation and Regression Trees (Chapman &

Hall/CRC).

Chen X, Zhang Y (2009) Uncertain linear programs: extended aﬃnely adjustable robust counterparts. Oper-

ations Research 57(6):1469–1482.

Chen Z, Sim M, Xiong P (2020) Robust stochastic optimization made easy with rsome. Forthcoming in

Management Science .

Clement P, Desch W (2008) An elementary proof of the triangle inequality for the wasserstein metric.

Proceedings of the American Mathematical Society 136(1):333–339.

Delage E, Ye Y (2010) Distributionally robust optimization under moment uncertainty with application to

data-driven problems. Operations Research 58(3):595–612.

Elmachtoub AN, Grigas P (2017) Smart “predict, then optimize”. arXiv preprint arXiv:1710.08005 .

Fournier N, Guillin A (2015) On the rate of convergence in wasserstein distance of the empirical measure.

Probability Theory and Related Fields 162(3-4):707–738.

Friedman J, Hastie T, Tibshirani R (2001) The Elements of Statistical Learning, volume 1 (Springer).

Gao R, Kleywegt AJ (2016) Distributionally robust stochastic optimization with wasserstein distance. arXiv

preprint arXiv:1604.02199 .

Georghiou A, Wiesemann W, Kuhn D (2015) Generalized decision rule approximations for stochastic pro-

gramming via liftings. Mathematical Programming 152(1-2):301–338.

Gotoh Jy, Kim MJ, Lim AE (2018) Robust empirical optimization is almost the same as mean–variance

optimization. Operations Research Letters 46(4):448–452.

Hanasusanto GA, Kuhn D (2018) Conic programming reformulations of two-stage distributionally robust

linear programs over wasserstein balls. Operations Research 66(3):849–869.

Hanasusanto GA, Kuhn D, Wiesemann W (2016) K-adaptability in two-stage distributionally robust binary

programming. Operations Research Letters 44(1):6–11.

Hannah L, Powell W, Blei DM (2010) Nonparametric density estimation for stochastic optimization with an

observable state variable. Advances in Neural Information Processing Systems, 820–828.

32

Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

Ho CP, Hanasusanto G (2019) On data-driven prescriptive analytics with side information: a regularized

nadaraya-watson approach URL http://www.optimization-online.org/DB_FILE/2019/01/7043.

pdf.

Kantorovich L, Rubinstein G (1958) On a space of totally additive functions. Vestn Lening. Univ 13:52–59.

Kullback S, Leibler RA (1951) On information and suﬃciency. The Annals of Mathematical Statistics

22(1):79–86.

Mohajerin Esfahani P, Kuhn D (2018) Data-driven distributionally robust optimization using the wasserstein

metric: Performance guarantees and tractable reformulations. Mathematical Programming 171(1):115–

166.

Natarajan K, Teo CP, Zheng Z (2011) Mixed 0-1 linear programs under objective uncertainty: A completely

positive representation. Operations Research 59(3):713–728.

Rockafellar RT, Uryasev S (2000) Optimization of conditional value-at-risk. Journal of Risk 2:21–42.

Van Parys BP, Esfahani PM, Kuhn D (2017) From data to decisions: distributionally robust optimization is

optimal. arXiv preprint arXiv:1704.04118 .

Vershynin R (2018) High-Dimensional Probability: An Introduction with Applications in Data Science, vol-

ume 47 (Cambridge University Press).

Walk H (2010) Strong laws of large numbers and nonparametric estimation. Recent Developments in Applied

Probability and Statistics, 183–214 (Springer).

Xu H, Caramanis C, Mannor S (2012) A distributional interpretation of robust optimization. Mathematics

of Operations Research 37(1):95–110.

e-companion to Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

ec1

Electronic Companion

EC.1. Properties of Weight Functions

In this section, we show that the k-nearest neighbor and kernel regression weight functions satisfy

several guarantees. These results are used in the proof of Theorem 2, found in Section 4.3. The

main result of this section is the following. For convenience, the equations below are numbered the

same as in the proof of Theorem 2.

Theorem EC.1. If Assumptions 1 and 4 hold, then

N (¯γ)} are not functions of ξ1, . . . , ξN ;

{wi
N
(cid:88)

wi

N (¯γ) = 1 and w1

N (¯γ), . . . , wN

N (¯γ) ≥ 0,

∀N ∈ N.

i=1

Moreover, there exists constants k2 > 0 and η > p(2 + dξ) such that

1
(cid:15)N

lim
N→∞
(cid:34)

N
(cid:88)

i=1
(cid:32)

EPN

exp

−θ
i=1 wi

(cid:80)N

N (¯γ)2

wi

N (¯γ)(cid:107)γ i − ¯γ(cid:107) = 0,

P∞-almost surely;

(cid:33)(cid:35)

≤ exp(−k2θN η),

∀θ ∈ (0, 1), N ∈ N.

(5)

(6)

(8)

(9)

Proof. We observe that (5) and (6) follow directly from the deﬁnitions of the weight functions.

The proofs of (8) and (9) are split into two parts, one for the k-nearest neighbor weights and one

for kernel regression weights.

k-Nearest Neighbors: For the proof of (8), we note

N
(cid:88)

i=1

wi

N (¯γ)(cid:107)γ i − ¯γ(cid:107) ≤ (cid:107)γ (kN )(¯γ) − ¯γ(cid:107),

where γ (kN )(¯γ) denotes the kN th nearest neighbor of ¯γ out of γ 1, . . . , γ N . Therefore, for any λ > 0,

(cid:32) N
(cid:88)

PN

i=1

wi

N (¯γ)(cid:107)γ i − ¯γ(cid:107) > λ(cid:15)N

(cid:33)

≤ PN (cid:0)(cid:107)γ (kN )(¯γ) − ¯γ(cid:107) > λ(cid:15)N

(cid:1)

≤ PN (cid:0)(cid:12)
(cid:12)

(cid:8)i : (cid:107)γ i − ¯γ(cid:107) ≤ λ(cid:15)N

(cid:9)(cid:12)
(cid:12) ≤ kN − 1(cid:1) .

By Assumption 4,

this probability is upper bounded by P(β ≤ kN − 1), where β ∼

Binom(N, g(λ(cid:15)N )dγ ). By Hoeﬀding’s inequality,

(cid:32) N
(cid:88)

PN

i=1

wi

N (¯γ)(cid:107)γ i − ¯γ(cid:107) > λ(cid:15)N

≤ exp

(cid:33)

(cid:18) −2(N g(λk1/N p)dγ − kN + 1)2
N

(cid:19)

,

ec2

e-companion to Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

for kN ≤ N g(λk1/N p)dγ + 1. We note that this condition on kN is satisﬁed for N suﬃciently large

because δ + pdγ < 1 by Assumption 1. Because the right hand side in the above inequality has a

ﬁnite sum over N , (8) follows by the Borel Cantelli lemma.

For the proof of (9), it follows from Assumption 1 that

N
(cid:88)

i=1

wi

N (¯γ)2 ≤ k−2

3 N 1−2δ

deterministically (for all suﬃciently large N such that (cid:100)k3N δ(cid:101) ≤ N − 1) and 2δ − 1 > p(dξ + 2).

Thus, (9) follows with η = 2δ − 1.

Kernel regression: Assumption 1 stipulates that the kernel function K(·) is Gaussian, triangu-

lar, or Epanechnikov, which are deﬁned in Section 3. It is easy to verify that these kernel functions

satisfy the following:

1. K is nonnegative, ﬁnite valued, and monotonically decreasing (for nonnegative inputs).
2. uαK(u) → 0 as u → ∞ for any α ∈ R.

3. ∃u∗ > 0 such that K(u∗) > 0.

For the proof of (8), deﬁne q > 0 such that p < q < δ. Letting D be the diameter of Γ and gN (¯γ) =
(cid:80)N

i=1 K((cid:107)γ i − ¯γ(cid:107)/hN ), we have

N
(cid:88)

i=1

wi

N (¯γ)(cid:107)γ i − ¯γ(cid:107)

=

N
(cid:88)

i=1

wi

N (¯γ)1{(cid:107)γ i − ¯γ(cid:107) ≤ N −q}(cid:107)γ i − ¯γ(cid:107) +

1
gN (¯γ)

N
(cid:88)

i=1

K

(cid:19)

(cid:18) (cid:107)γ i − ¯γ(cid:107)
hN

1{(cid:107)γ i − ¯γ(cid:107) > N −q}(cid:107)γ i − ¯γ(cid:107)

≤ N −q +

N DK(N −q/hN )
gN (¯γ)

,

where the inequality follows from the monotonicity of K. By construction, N −q/(cid:15)N → 0, so we just

need to handle the second term. We note, for any λ > 0,

PN

(cid:18) N DK(N −q/hN )
gN (¯γ)

(cid:19)

≤ PN

(cid:32) N
(cid:88)

> λ(cid:15)N

Z N

i K(u∗) <

i=1

N DK(N −q/hN )
λ(cid:15)N

(cid:33)

,

where Z N

i = 1{(cid:107)γ i − ¯γ(cid:107) ≤ u∗hN }. To achieve this inequality, we lower bounded each term in gN (¯γ)

by K(u∗) or 0, because of the monotonicity of K. By Hoeﬀding’s inequality,

(cid:32) N
(cid:88)

PN

i=1

Z N

i K(u∗) <

N DK(N −q/hN )
λ(cid:15)N

(cid:33)



(cid:16)

2

≤ exp


−

N EZ N

i − N D

λ(cid:15)N K(u∗) K(N −q/hN )

N

(cid:17)2



+




e-companion to Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information



(cid:16)

2

≤ exp


−

N g(u∗hN )dγ − N D

λ(cid:15)N K(u∗) K(N −q/hN )
N

ec3

(cid:17)2



+




(cid:16)

= exp

− (cid:0)k5N 1/2−δdγ − k6N 1/2+pK(k4N −q+δ)(cid:1)2

+

(cid:17)

,

for some constants k5, k6 > 0 that do not depend on N . We used Assumption 4 for the second
inequality. Because δ > q, the second kernel property implies N 1/2+pK(k4N −q+δ) goes to 0 as N

goes to inﬁnity, so that term is irrelevant. Because 1/2 − δdγ > 0 by Assumption 1, the right hand

side of the inequality has a ﬁnite sum over N , and thus (8) follows from the Borel Cantelli lemma.

For the proof of (9), deﬁne

vN =

We note that






K((cid:107)γ 1 − ¯γ(cid:107)/hN )
...
K((cid:107)γ N − ¯γ(cid:107)/hN )




 .

N
(cid:88)

i=1

wi

N (¯γ)2 =

(cid:107)vN (cid:107)2
2
(cid:107)vN (cid:107)2
1

≤

(cid:107)vN (cid:107)∞
(cid:107)vN (cid:107)1

≤

K(0)
K(u∗) (cid:80)N

i=1 Z N

i

,

is deﬁned above. The ﬁrst inequality follows from Holder’s inequality, and the second

where Z N
i
inequality follows from the monotonicity of K. Next, we deﬁne ¯Z N
i

to be a Bernoulli random

variable with parameter g(u∗hN )dγ for each i. For any θ ∈ (0, 1),

(cid:34)

(cid:32)

EPN

exp

−θ
i=1 wi

(cid:80)N

N (¯γ)2

(cid:33)(cid:35)

(cid:34)

(cid:32)

≤ EPN

exp

−θK(u∗) (cid:80)N
K(0)

i=1

(cid:33)(cid:35)

¯Z N
i

= (cid:0)1 − g(u∗hN )dγ + g(u∗hN )dγ exp(−θK(u∗)/K(0))(cid:1)N
≤ exp (cid:0)−N g(u∗hN )dγ (1 − exp(−θK(u∗)/K(0)))(cid:1)

≤ exp

= exp

(cid:18)

(cid:19)

−N g(u∗hN )dγ θK(u∗)
2K(0)
(cid:18)
θK(u∗)g(k4u∗)dγ N 1−δdγ
2K(0)

−

(cid:19)

.

The ﬁrst inequality follows because g(u∗hN )dγ is an upper bound on P((cid:107)γ i − ¯γ(cid:107) ≤ u∗hN ) by
Assumption 4. The ﬁrst equality follows from the deﬁnition of the moment generating function for

a binomial random variable. The next line follows from the inequality ex ≥ 1 + x and the following

from the inequality 1 − e−x ≥ x/2 for 0 ≤ x ≤ 1. Because 1 − δdγ > p(2 + dξ), this completes the
proof of (9) with η = 1 − δdγ and k2 = K(u∗)g(k4u∗)dγ /2K(0). (cid:3)

EC.2. Proof of Theorem 1

In this section, we present our proof of Theorem 1. We make use of the following result from

Bertsimas et al. (2018a) (their Lemma EC.2), which bounds the diﬀerence in worst case objective

ec4

e-companion to Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

values between distributionally robust optimizatoin with the type-1 Wasserstein ambiguity set and

sample robust optimization3 problems. We note that Bertsimas et al. (2018a) proved the following
result for the case that Q(cid:48) is the unweighted empirical measure, but their proof carries through for
the case here in which Q(cid:48) is a weighted empirical measure.

Lemma EC.1. Let Z ⊆ Rd, f : Z → R be measurable, and ζ1, . . . , ζN ∈ Z. Suppose that

Q(cid:48) =

N
(cid:88)

i=1

wiδζi

for given weights w1, . . . , wN ≥ 0 that sum to one. If θ2 ≥ 2θ1 ≥ 0, then

sup
Q∈P(Z): d1(Q(cid:48),Q)≤θ1

Eξ∼Q[f (ξ)] ≤

N
(cid:88)

i=1

wi

sup
ζ∈Z:(cid:107)ζ−ζi(cid:107)≤θ2

f (ζ) +

4θ1
θ2

sup
ζ∈Z

|f (ζ)|.

We now restate and prove the main result, which combines the new measure concentration result

from this paper with similar proof techniques as Bertsimas et al. (2018a) and Mohajerin Esfahani

and Kuhn (2018).

Theorem 1. Suppose the weight function and uncertainty sets satisfy Assumption 1, the joint

probability distribution of (γ, ξ) satisﬁes Assumptions 2-4 from Section 4.3, and the cost function

satisﬁes Assumptions 5-6from Section 4.4. Then, for every ¯γ ∈ Γ,

lim
N→∞

ˆvN (¯γ) = v∗(¯γ), P∞-almost surely.

Proof. We break the limit into upper and lower parts. The proof of the lower part follows from

an argument similar to that used by Bertsimas et al. (2018a). The proof of the upper part follows

from the argument used by Mohajerin Esfahani and Kuhn (2018).

Lower bound. We ﬁrst show that

lim inf
N→∞

ˆvN (¯γ) ≥ v∗(¯γ), P∞-almost surely.

(EC.1)

Indeed, it follows from Assumptions 1-2 and the union bound that there exists N0 ∈ N such that

(cid:32)

PN

sup
i=1U i
N

ζ∈∪N

(cid:33)

(cid:107)ζ(cid:107) > log N

< exp(−(log N )1.99),

∀N ≥ N0.

Therefore, the Borel-Cantelli lemma implies that there exists N1 ∈ N, P∞-almost surely, such that

∪N

i=1U i

N ⊆ DN (cid:44) {ζ : (cid:107)ζ(cid:107) ≤ log N },

∀N ≥ N1.

(EC.2)

e-companion to Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

ec5

Consider any r > 0 such that (cid:15)N N −r satisﬁes Assumption 1, and let ΠN denote the set of decision
rules which satisfy the conditions of Assumption 5. Then, the following holds for all N ≥ N1 (cid:44)
max{N0, 2 1

r } and π ∈ ΠN :

sup

Q∈P(DN ∩Ξ): d1(Q,ˆPN

¯γ )≤

(cid:15)N
N r

Eξ∼Q[cπ(ξ1, . . . , ξT )]

N
(cid:88)

≤

wN

i (¯γ)

sup
ζ∈DN ∩Ξ: (cid:107)ζ−ξi(cid:107)≤(cid:15)N

cπ(ζ1, . . . , ζT ) +

4
N r

sup
ζ∈DN ∩Ξ

|cπ(ζ1, . . . , ζT )|

i=1
N
(cid:88)

i=1

N
(cid:88)

i=1

N
(cid:88)

i=1

=

≤

≤

wN

i (¯γ) sup
ζ∈U i
N

wN

i (¯γ) sup
ζ∈U i
N

wN

i (¯γ) sup
ζ∈U i
N

cπ(ζ1, . . . , ζT ) +

cπ(ζ1, . . . , ζT ) +

4
N r

4
N r

sup
ζ∈DN ∩Ξ
(cid:32)

|cπ(ζ1, . . . , ζT )|

(cid:40)

(cid:41)(cid:33)

M

1 + max

(cid:107)ζ(cid:107) ,

sup
i=1U i
N

ζ(cid:48)∈∪N

(cid:107)ζ(cid:48)(cid:107)

cπ(ζ1, . . . , ζT ) +

4M
N r

(1 + log N ).

(EC.3)

Indeed, the ﬁrst inequality follows from Lemma EC.1 since N ≥ 2 1

r , the equality follows from

N ≥ N1, the second inequality holds because π ∈ ΠN , and the third and ﬁnal inequality follows

from the deﬁnition of DN and N ≥ N1. We observe that the second term in (EC.3) converges to

zero as N → ∞.

We now observe that

E[cπ(ξ1, . . . , ξT ) | γ = ¯γ] (cid:44) Eξ∼P¯γ [cπ(ξ1, . . . , ξT )]

= Eξ∼P¯γ [cπ(ξ1, . . . , ξT )1{ξ /∈ DN }] + Eξ∼P¯γ [cπ(ξ1, . . . , ξT )1{ξ /∈ DN }].

We handle the ﬁrst term with the Cauchy-Schwartz inequality,

Eξ∼P¯γ [cπ(ξ1, . . . , ξT )1{ξ /∈ DN }] ≤

(cid:113)

Eξ∼P¯γ [cπ(ξ1, . . . , ξT )2]P¯γ(ξ /∈ DN ).

By Assumption 2, the above bound is ﬁnite and converges to zero as N → ∞ uniformly over π ∈ ΠN .

We handle the second term by the new concentration measure from this paper. Speciﬁcally, it
follows from Theorem 2 that there exists an N2 ≥ N1, P∞-almost surely, such that

d1(P¯γ, ˆPN

¯γ ) ≤

(cid:15)N
N r

∀N ≥ N2.

Therefore, for all N ≥ N2 and decision rules π ∈ ΠN :

Eξ∼P¯γ [cπ(ξ1, . . . , ξT )1{ξ ∈ DN }]

(cid:20)(cid:18)

= Eξ∼P¯γ

cπ(ξ1, . . . , ξT ) − inf

ζ∈DN ∩Ξ

cπ(ζ1, . . . , ζT )

(cid:19)

(cid:21)

1{ξ ∈ DN }

+ P¯γ(ξ ∈ DN )

(cid:124)

inf
ζ∈DN ∩Ξ
(cid:123)(cid:122)
αN

cπ(ζ1, . . . , ζT )
(cid:125)

ec6

e-companion to Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

≤

=

=

sup

Q∈P(Ξ): d1(Q,ˆPN

¯γ )≤

(cid:15)N
N r

sup

Q∈P(Ξ∩DN ): d1(Q,ˆPN

¯γ )≤

sup

Q∈P(Ξ∩DN ): d1(Q,ˆPN

¯γ )≤

(cid:15)N
N r

(cid:15)N
N r

(cid:20)(cid:18)

Eξ∼Q

cπ(ξ1, . . . , ξT ) − inf

ζ∈DN ∩Ξ

cπ(ζ1, . . . , ζT )

(cid:19)

(cid:21)
1{ξ ∈ DN }

+ αN

Eξ∼Q

(cid:20)
cπ(ξ1, . . . , ξT ) − inf

ζ∈DN ∩Ξ

(cid:21)
cπ(ζ1, . . . , ζT )

+ αN

Eξ∼Q[cπ(ξ1, . . . , ξT )] − P¯γ(ξ /∈ DN )

inf
ζ∈DN ∩Ξ

cπ(ζ1, . . . , ζT ),

where the inequality follows from N ≥ N2. It follows from (EC.2) that the second term in the ﬁnal

equality converges to zero as N → ∞ uniformly over π ∈ ΠN .

Combining the above, we conclude that

lim inf
N→∞

ˆvN (¯γ) = lim inf
N→∞

inf
π∈Π

N
(cid:88)

i=1

wN

i (¯γ) sup
ζ∈U i
N

cπ(ζ1, . . . , ζT )

= lim inf
N→∞

inf
π∈ΠN

≥ lim inf
N→∞

inf
π∈ΠN

N
(cid:88)

i=1

wN

i (¯γ) sup
ζ∈U i
N

cπ(ζ1, . . . , ζT )

E[cπ(ξ1, . . . , ξT ) | γ = ¯γ], P∞-almost surely

E[cπ(ξ1, . . . , ξT ) | γ = ¯γ]

≥ inf
π∈Π
= v∗(¯γ),

(EC.4)

(EC.5)

where (EC.4) follows from Assumption 5 and (EC.5) follows because ΠN ⊆ Π for all N ∈ N. This

completes the proof of (EC.1).

Upper bound. We now prove that

lim sup
N→∞

ˆvN (¯γ) ≤ v∗(¯γ), P∞-almost surely.

(EC.6)

Indeed, for any arbitrary δ > 0, let πδ ∈ Π be a δ-optimal solution for (1). Moreover, without

any loss of generality, we assume that the decision rule is chosen to satisfy the conditions of

Assumption 6. Then it follows from Mohajerin Esfahani and Kuhn (2018, Lemma A.1) that there
exists a non-increasing sequence of functions f j(ζ1, . . . , ζT ), j ∈ N, such that

lim
j→∞

f j(ζ1, . . . , ζT ) = cπδ (ζ1, . . . , ζT ),

∀ζ ∈ Ξ

and f j is Lj-Lipschitz continuous. Furthermore, for each N ∈ N, choose any probability distribution
ˆQN ∈ P(Ξ) such that d1( ˆQN , ˆPN

¯γ ) ≤ (cid:15)N and

sup

Q∈P(Ξ): d1(Q,ˆPN

¯γ )≤(cid:15)N

Eξ∼Q[cπδ (ξ1, . . . , ξT )] ≤ E

ξ∼ ˆQN [cπδ (ξ1, . . . , ξT )] + δ.

e-companion to Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

ec7

For any j ∈ N,

lim sup
N→∞

ˆvN (¯γ) ≤ lim sup
N→∞

= lim sup
N→∞

≤ lim sup
N→∞

N
(cid:88)

i=1

wN

i (¯γ) sup
ζ∈U i
N

sup

Q∈P(Ξ): d∞(Q,ˆPN

¯γ )≤(cid:15)N

cπδ (ζ1, . . . , ζT )

Eξ∼Q[cπδ (ξ1, . . . , ξT )]

sup

Eξ∼Q[cπδ (ξ1, . . . , ξT )]

Q∈P(Ξ): d1(Q,ˆPN
E

¯γ )≤(cid:15)N
ξ∼ ˆQN [cπδ (ξ1, . . . , ξT )] + δ

E

ξ∼ ˆQN [f j(ξ1, . . . , ξT )] + δ
Eξ∼P¯γ [f j(ξ1, . . . , ξT )] + Ljd1(P¯γ, ˆQN ) + δ

Eξ∼P¯γ [f j(ξ1, . . . , ξT )] + Lj(d1(P¯γ, ˆPN

¯γ ) + d1( ˆQN , ˆPN

¯γ )) + δ

Eξ∼P¯γ [f j(ξ1, . . . , ξT )] + Lj(d1(P¯γ, ˆPN
= EP¯γ [f j(ξ1, . . . , ξT )] + δ, P∞-almost surely,

¯γ ) + (cid:15)N ) + δ

≤ lim sup
N→∞
≤ lim sup
N→∞
≤ lim sup
N→∞
≤ lim sup
N→∞
≤ lim sup
N→∞

where we have used the relationship between sample robust optimization and distributionally

robust optimization with the type-∞ Wasserstein ambiguity set for the ﬁrst equality (Bertsimas
et al. 2018a, Section 6), the fact d1(P, Q) ≤ d∞(P, Q) for the second inequality, the dual form of
the 1-Wasserstein metric for the ﬁfth inequality (because f j is Lj-Lipschitz), and Theorem 2 for

the equality. Taking the limit as j → ∞, and applying the monotone convergence theorem (which
is allowed because Eξ∼P¯γ |f 1(ξ1, . . . , ξT )| ≤ L1Eξ∼P¯γ (cid:107)ξ(cid:107) + |f 1(0)| < ∞ by Assumption 4), gives

lim sup
N→∞

ˆvN (¯γ) ≤ Eξ∼P¯γ [cπδ (ξ1, . . . , ξT )] + δ ≤ v∗(¯γ) + 2δ, P∞-almost surely.

Since δ > 0 was chosen arbitrarily, the proof of (EC.6) is complete. (cid:3)

EC.3. Proof of Theorem 4

In this section, we present our proof of Theorem 4 from Section 6. We restate the theorem here for

convenience.

Theorem 4. For cost functions of the form (15), ˜vN (¯γ) = ˆvN (¯γ).

Proof. We ﬁrst show that ˜vN (¯γ) ≥ ˆvN (¯γ). Indeed, consider any primary decision rule ¯π and

auxiliary decision rules ¯yi

1, . . . , ¯yi

T for each i ∈ {1, . . . , N } which are optimal for (16).4 Then, it

follows from feasibility to (16) that

h(cid:124)
t ¯yi

t(ζ1, . . . , ζt) ≥ min
yt∈Rdt

y

(cid:40)

h(cid:124)
t yt :

t
(cid:88)

s=1

At,s ¯πs(ζ1, . . . , ζs−1) +

(cid:41)

Bt,sζs + Ctyt ≤ dt

t
(cid:88)

s=1

ec8

e-companion to Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

for each i ∈ {1, . . . , N }, ζ ∈ U i

N , and t ∈ {1, . . . , T }. Thus,

ˆvN (¯γ) = min
π∈Π

N
(cid:88)

i=1

wi

N (¯γ)cπ(ζ1, . . . , ζT )

≤

≤

N
(cid:88)

i=1
N
(cid:88)

i=1

wi

N (¯γ)c ¯π(ζ1, . . . , ζT )

wi

N (¯γ) sup
ζ∈U i
N

T
(cid:88)

t=1

(cid:0)f (cid:124)

t ¯πt(ζ1, . . . , ζt−1) + g(cid:124)

t ζt + h(cid:124)

t ¯yi

t(ζ1, . . . , ζt)(cid:1) = ˜vN (¯γ).

The other side of the inequality follows from similar reasoning. Indeed, let ¯π be an optimal solution

to (4). For each i ∈ {1, . . . , N } and t ∈ {1, . . . , T }, deﬁne ¯yi

t ∈ Rt as any decision rule that satisﬁes

¯yi

t(ζ1, . . . , ζt) ∈ arg min
yt∈Rdt

y

(cid:40)

h(cid:124)
t yt :

t
(cid:88)

s=1

At,s ¯πs(ζ1, . . . , ζs−1) +

(cid:41)

Bt,sζs + Ctyt ≤ dt

t
(cid:88)

s=1

for every ζ ∈ U i

N . Then,

˜vN (¯γ) ≤

=

N
(cid:88)

i=1

N
(cid:88)

i=1

wi

N (¯γ) sup
ζ∈U i
N

T
(cid:88)

t=1

(cid:0)f (cid:124)

t ¯πt(ζ1, . . . , ζt−1) + g(cid:124)

t ζt + h(cid:124)

t ¯yi

t(ζ1, . . . , ζt)(cid:1)

wi

N (¯γ) sup
ζ∈U i
N

c ¯π(ζ1, . . . , ζT ) = ˆvN (¯γ).

Combining the above inequalities, the proof is complete. (cid:3)

EC.4. Tractable Reformulation of the Multi-Policy Approximation

For completeness, we now show how to reformulate the multi-policy approximation scheme with

linear decision rules from Section 6 into a deterministic optimization problem using standard

techniques from robust optimization.

We begin by transforming (16) with linear decision rules into a more compact representation.

First, we combine the primary linear decision rules across stages as

x0 =






x1,0
...
xT,0


 ∈ Rdx,


X =













0
0

0
0
0
...

0
· · ·
X2,1
· · ·
X3,1 X3,2
· · ·
...
...
. . .
XT −2,1 XT −2,2 XT −2,3 · · ·
XT −1,1 XT −1,2 XT −1,3 · · · XT −1,T −2
XT,1 XT,2 XT,3

0
0
0
...
0
0
· · · XT,T −2 XT,T −1 0

0
0
0
...
0
0

0
0
0
...
0













∈ Rdx×dξ .

e-companion to Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

ec9

We note that the zero entries in the above matrix are necessary to ensure that the linear deci-

sion rules are non-anticipative. Similarly, for each i ∈ {1, . . . , N }, we represent the auxiliary linear

decision rules as

yi

0 =

1,0






yi
...
yi

T,0


 ∈ Rdy ,


Yi =









2,2

Yi
0
· · ·
1,1
2,1 Yi
Yi
· · ·
...
...
. . .
T −1,1 Yi
Yi
T −1,2 · · · Yi
T,1 Yi
Yi
T,2

· · · Yi

0
0
...

0
0
...
0
t,t−1 Yi

T −1,T −1

T,T









∈ Rdy ×dξ .

We now combine the problem parameters. Let d = (d1, . . . , dT ) ∈ Rm and

0
0
...
0









∈ Rm×dx,

∈ Rm×dx,

f =

g =

h =


 ∈ Rdx,







f1
...
fT


 ∈ Rdξ ,



 ∈ Rdy ,







g1
...
gT






h1
...
hT

A =

B =

C =

























0

A1,1
A2,1 A2,2
...
...

· · ·
· · ·
. . .

0
0
...









0

0
0
...

AT −1,1 AT −1,2 · · · AT −1,T −1
AT,1 AT,2
B1,1
B2,1 B2,2
...
...

· · · At,t−1 AT,T
0
· · ·
0
· · ·
...
. . .
BT −1,1 BT −1,2 · · · BT −1,T −1 0
BT,1 BT,2
0
0
C1,1 0 · · ·
0
0
0 C2,2 · · ·
...
...
...
...
. . .
0 · · · CT −1,T −1 0
0
0 · · ·
0

· · · Bt,t−1 BT,T







CT,T



0

∈ Rm×dx.

Therefore, using the above compact notation, we can rewrite the multi-policy approximation with

linear decision rules as

minimize
x0∈Rdx ,X∈Rdx×dξ
0∈Rdy , Yi∈Rdy ×dξ
yi
subject to

N
(cid:88)

i=1

wi

N (¯γ) sup
ζ∈U i
N

(cid:8)f (cid:124)(x0 + Xζ) + g(cid:124)ζ + h(cid:124) (cid:0)yi

0 + Yiζ(cid:1)(cid:9)

A(x0 + Xζ) + Bζ + C (cid:0)yi

0 + Yiζ(cid:1) ≤ d

(EC.7)

x0 + Xζ ∈ X

∀ζ ∈ U i

N , i ∈ {1, . . . , N },

where X (cid:44) X1 × · · · × XT and the matrices X and Y are non-anticipative. Note that the linear

decision rules in the above optimization problem are represented using O(dξ max{dx, N dy}) decision
variables, where dx (cid:44) d1
y + · · · + dT
y . Thus, the complexity of representing the
primary and auxiliary linear decision rules scales eﬃciently both in the size of the dataset and the

x and dy (cid:44) d1

x + · · · + dT

number of stages. For simplicity, we present the reformulation for the case in which there are no

constraints on the decision variables and nonnegativity constraints on the random variables.

ec10

e-companion to Bertsimas, McCord, and Sturt: Dynamic Optimization with Side Information

Theorem EC.2. Suppose Ξ = Rdξ

+ and X = Rdx. Then, (EC.7) is equivalent to

minimize
x0∈Rdx ,X∈Rdx×dξ
0∈Rdy , Yi∈Rdy ×dξ
yi
dξ
Λi∈R
+

m×dξ
+
subject to

, si∈R

N
(cid:88)

i=1

N (¯γ) (cid:0)f (cid:124) (cid:0)x0 + Xξi(cid:1) + g(cid:124)ξi + h(cid:124) (cid:0)yi
wi

0 + Yiξi(cid:1) + (si)(cid:124)ξi + (cid:15)N

(cid:13)X(cid:124)f + g + (Yi)(cid:124)h + si(cid:13)
(cid:13)
(cid:13)∗

(cid:1)

A (cid:0)x0 + Xξi(cid:1) + Bξi + C (cid:0)yi

0 + Yiξi(cid:1) + Λiξi + (cid:15)N

(cid:13)AX + B + CYi + Λi(cid:13)
(cid:13)
(cid:13)∗

≤ d

∀i ∈ {1, . . . , N }.

where (cid:107)Z(cid:107)∗ (cid:44) ((cid:107)z1(cid:107)∗, . . . , (cid:107)zr(cid:107)∗) ∈ Rr for any matrix Z ∈ Rr×n.

Proof.

For any c ∈ Rdξ and ξ ∈ Ξ, it follows directly from strong duality for conic optimization

that

max
ζ≥0

{c(cid:124)ζ : (cid:107)ζ − ξ(cid:107) ≤ (cid:15)} = min
λ≥0

{(c + λ)(cid:124)ξ + (cid:15) (cid:107)c + λ(cid:107)∗} .

We use this result to reformulate the objective and constraints of (EC.7). First, let the j-th rows
of A, B, C and the j-th element of d be denoted by aj ∈ Rdx, bj ∈ Rξ, cj ∈ Rdy , and dj ∈ R. Then,
each robust constraint has the form

j(x0 + Xζ) + b(cid:124)
a(cid:124)

jζ + c(cid:124)

j(yi

0 + Yiζ) ≤ dj ∀ζ ∈ U i
N .

Rearranging terms,

(a(cid:124)

jX + b(cid:124)

j + c(cid:124)

jYi)ζ ≤ dj − a(cid:124)

jx0 − c(cid:124)

jyi

0 ∀ζ ∈ U i
N ,

which applying duality becomes

∃λi

j ≥ 0 : (cid:0)X(cid:124)aj + bj + (Yi)(cid:124)cj + λi

j

(cid:1)(cid:124)

ξi + (cid:15)N

(cid:13)
(cid:13)X(cid:124)aj + bj + (Yi)(cid:124)cj + λi

j

(cid:13)
(cid:13)∗

≤ dj − a(cid:124)

jx0 − c(cid:124)

jyi
0.

Rearranging terms, the robust constraints for each i ∈ {1, . . . , N } are satisﬁed if and only if

∃Λi ≥ 0 : A (cid:0)x0 + Xξi(cid:1) + Bξi + C (cid:0)yi

0 + Yiξi(cid:1) + Λiξi + (cid:15)N

(cid:13)AX + B + CYi + Λi(cid:13)
(cid:13)
(cid:13)∗

≤ d,

where the dual norm for a matrix is applied separately for each row. Similarly, the objective function

takes the form

N
(cid:88)

i=1

=

=

=

N
(cid:88)

i=1

N
(cid:88)

i=1
N
(cid:88)

i=1

wi

N (¯γ) sup
ζ∈U i
N
(cid:32)

(cid:8)f (cid:124)(x0 + Xζ) + g(cid:124)ζ + h(cid:124) (cid:0)yi

0 + Yiζ(cid:1)(cid:9)

wi

N (¯γ)

f (cid:124)x0 + h(cid:124)yi

0 + sup
ζ∈U i
N

(cid:0)f (cid:124)X + g(cid:124) + h(cid:124)Yi(cid:1) ζ

(cid:33)

(cid:18)

(cid:18)

wi

N (¯γ)

wi

N (¯γ)

f (cid:124)x0 + h(cid:124)yi

0 + inf
si≥0

(cid:8)(cid:0)X(cid:124)f + g + (Yi)(cid:124)h + si(cid:1)(cid:124)

ξi + (cid:15)N

(cid:13)X(cid:124)f + g + (Yi)(cid:124)h + si(cid:13)
(cid:13)
(cid:13)∗

(cid:1)

(cid:27)

f (cid:124) (cid:0)x0 + Xξi(cid:1) + g(cid:124)ξi + h(cid:124) (cid:0)yi

0 + Yiξi(cid:1) + inf

si≥0

(cid:8)(si)(cid:124)ξi + (cid:15)N

(cid:13)X(cid:124)f + g + (Yi)(cid:124)h + si(cid:13)
(cid:13)
(cid:13)∗

(cid:9)

(cid:19)

.

Combining the reformulations above, we obtain the desired reformulation. (cid:3)

