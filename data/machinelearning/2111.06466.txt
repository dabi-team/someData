1
2
0
2

v
o
N
1
1

]

C
D
.
s
c
[

1
v
6
6
4
6
0
.
1
1
1
2
:
v
i
X
r
a

Molecular Dynamics Simulations on Cloud Computing and Machine Learning Platforms

Prateek Sharma1, ∗ and Vikram Jadhao1, †
1Intelligent Systems Engineering, 700 N. Woodlawn Avenue, Indiana University, Bloomington, Indiana 47408

Scientiﬁc computing applications have beneﬁted greatly from high performance computing infrastructure
such as supercomputers. However, we are seeing a paradigm shift in the computational structure, design, and
requirements of these applications. Increasingly, data-driven and machine learning approaches are being used to
support, speed-up, and enhance scientiﬁc computing applications, especially molecular dynamics simulations.
Concurrently, cloud computing platforms are increasingly appealing for scientiﬁc computing, providing “inﬁ-
nite” computing powers, easier programming and deployment models, and access to computing accelerators
such as TPUs (Tensor Processing Units). This conﬂuence of machine learning (ML) and cloud computing rep-
resents exciting opportunities for cloud and systems researchers. ML-assisted molecular dynamics simulations
are a new class of workload, and exhibit unique computational patterns. These simulations present new chal-
lenges for low-cost and high-performance execution. We argue that transient cloud resources, such as low-cost
preemptible cloud VMs, can be a viable platform for this new workload. Finally, we present some low-hanging
fruits and long-term challenges in cloud resource management, and the integration of molecular dynamics sim-
ulations into ML platforms (such as TensorFlow).

I.

INTRODUCTION

Scientiﬁc computing applications play an important
role in the analysis and understanding of a wide variety
of natural and synthetic processes. These applications
are typically implemented as large-scale parallel pro-
grams that use communication frameworks such as MPI,
and are largely deployed on high performance computing
(HPC) infrastructure such as supercomputers. Molecular
dynamics (MD) simulations are among the most ubiq-
uitous scientiﬁc computing applications. These simula-
tions have been used extensively by materials scientists,
chemical engineers, and physicists to investigate the mi-
croscopic origins of the macroscopic behavior of mate-
rials such as self-assembled nanoparticles, viral capsids,
electrolytes, lubricants, and polymers [1–4].

A key goal for MD simulations is to explore the de-
sign space associated with the material attributes, and
establish the links between the design parameters and
the material response (generally, encoded in the struc-
tural and dynamical properties). To this end, simulations
are deployed as a collection or “bag” of jobs. Collec-
tively, a bag of jobs “sweeps” a multi-dimensional design
space and furnishes the links between the material design
parameters (inputs) and the material response (outputs).
These links provide a reliable guide to experiments for a
rational discovery of regions of the material design space
exhibiting interesting structural and dynamical proper-
ties.

The bags of jobs approach is also central to the rapidly
developing area of using machine learning (ML) to en-
hance MD simulations and expedite the exploration of
the material design space [5–14]. Large collections of

∗ prateeks@iu.edu
† vjadhao@iu.edu

jobs with independent parameter sets are launched in or-
der to train and test the ML models designed to enhance
the predictive power or reduce the computational costs
of MD simulations. For example, artiﬁcial neural net-
work based regression models, trained on data from MD
simulations of soft materials, can successfully predict the
relationships between the input parameters and the sim-
ulation outcomes [12, 15]. These ML surrogates accu-
rately predicted the distributions of ions for a variety of
conﬁned electrolyte systems with 95% accuracy and an
inference time 10000× less than the corresponding MD
simulation runtime [12, 15]. As the utility of MD simula-
tions and their ML-enhanced versions in the rational de-
sign of materials is further demonstrated, it will be neces-
sary for accurate and fast simulations to be performed for
larger sets of parameters in order to efﬁciently explore
the material design space. To this end, it is important to
leverage diverse advanced cyberinfrastructure platforms
to perform low-cost simulations.

II. MOLECULAR DYNAMICS ON CLOUD
PLATFORMS

Increasingly, cloud computing platforms have begun
to supplement and complement conventional HPC infras-
tructure to meet the large computing and storage require-
ments of simulations [16]. Public clouds offer many ben-
eﬁts: on-demand resource allocation, convenient pay-
as-you-go pricing models, and ease of deployment on
an “inﬁnite” resource pool. An important objective in
cloud deployments is to optimize for cost in addition to
performance. Costs can be reduced through the use of
transient computing resources that can be unilaterally re-
voked and preempted by the cloud provider, but their pre-
emptible nature results in frequent job failures. The con-
siderations of cost, frequent job failures, and server con-
ﬁguration heterogeneity intrinsic to the system present

 
 
 
 
 
 
multiple challenges in deploying applications on cloud
platforms. These challenges are fundamentally different
from those that appear in using HPC clusters as the exe-
cution environment for simulations.

Systems such as SciSpot [17, 18], a framework that
uses a new reliability model for constrained preemptions
of Google Preemptible Virtual Machines (VMs), can op-
timize the deployment of scientiﬁc computing applica-
tions on transient cloud servers and enable low-cost MD
simulations. SciSpot uses an empirical and analytical
model of transient server availability to predict expected
running times and costs associated with jobs of different
types and durations. Considering an entire bag of jobs
as an execution unit enables simple and powerful poli-
cies for optimizing cost, makespan, and ease of deploy-
ment. SciSpot’s cost-minimizing server selection and job
scheduling policies reduce costs by up to 5× compared
to conventional cloud deployments.

III. MOLECULAR DYNAMICS ON ML SYSTEMS

The use of ML systems such as TensorFlow and Py-
Torch has been largely limited for designing ML-based
enhancements (e.g., surrogates, integrators, force ﬁelds)
for MD simulations [6, 12, 13]. Some recent studies have
explored the utilization of ML platforms for “non-ML”
tasks related to MD simulations [19–23]. However, the
use of ML systems to develop and execute MD simula-
tions and integrate them with ML-based enhancements is
unexplored. In the following, we outline advantages of
ML systems as environments for executing MD simula-
tions and integrating them with data-driven models. We
also discuss the associated systems challenges.

MD simulations are typically coded in C/C++ and par-
allelized using OpenMP and MPI [24]. However, more
modern MD software packages such as HOOMD-Blue
[25] have demonstrated that MD simulations can be eas-
ily written in high-level languages such as Python. ML
platforms such as TensorFlow are based on Python and
the associated high-level data-ﬂow abstraction can en-
able rapid prototyping of MD simulations. We highlight
a few key advantages of utilizing ML systems for execut-
ing MD simulations:

• High-performance simulations: ML systems offer
automatic parallelization of simulations and en-
able seamless use of next-generation cloud and
HPC hardware such as GPUs and TPUs.

• One-stop platform: ML systems offer extensive
support for debugging, data analytics, and post-
processing tasks that can be leveraged to perform
all simulation-related tasks at a single platform.

• Large ecosystem: Developers have access to a
much bigger data science and ML community.

2

• Better software engineering: Associated tools are
richer and are actively developed and improved
(compared to, for example, MPI).

• Reproducibility and ease of sharing: Users and
developers can easily share all simulation models
and methods in one notebook that can be run on
ML system backends such as Google Colab (com-
pared to cumbersome conﬁguring of simulations
on different HPC systems).

• Integration with data-driven approaches: Data op-
erations in ML systems are ﬁrst-class operations,
instead of being a separate stage of the simulation
workﬂow aimed at exploring the material design
space.

The seamless integration of simulations and data-
driven models on a single platform offers many oppor-
tunities for a rational and expedited exploration of the
material design space. We now illustrate a set of these
opportunities using ML surrogates as an example. An
ML surrogate is a model trained on data from MD sim-
ulations that is used to approximate the relationships be-
tween the input parameters and the simulation outcomes,
bypassing part or all of the explicit evolution of the simu-
lated components. For instance, the ML surrogate in [12]
can reduce the inference time from 30 minutes to 0.2
seconds—a 10, 000× speedup! This surrogate model
was trained using a bag of jobs of size N = 6, 000, each
job representing a unique set of parameters discretizing
the high-dimensional input design space.

In the conventional, un-integrated approach, the bag of
jobs (of size N ) is run sequentially on HPC systems, with
a long wait time until a surrogate is trained. N is chosen
a priori (usually informed by domain expertise) such that
the generated data is sufﬁcient to train an ML model (typ-
ically a deep neural network). In contrast, an integrated
approach utilizing ML systems for simulation facilitates
a rapid transition from simulation to surrogate. The sur-
rogate training can now begin with a smaller number n
of simulations and the training progress can be monitored
in a seamless fashion. When surrogates are designed in
an integrated manner on ML systems, a number of new
opportunities emerge:

• A uniﬁed approach to executing simulations and
training ML models to approximate input-output
relationships enables the development of the sur-
rogate during the exploration of the material de-
sign space with a bag of n < N jobs. ML systems
can facilitate the automation of the switch to de-
riving outputs using surrogates when the training
and testing errors become small and surrogate ac-
curacy reaches a high value.

• On-the-ﬂy development of the surrogates enables
a principled approach to quantify the completion
of the material design space exploration.

• Surrogate accuracy and inferences times can be
readily improved with minimal overhead associ-
ated with the one-stop platform that enables a
seamless accumulation of training data resulting
from more simulation executions.

• The ease of designing surrogates in parallel with
the simulation-driven exploration of the material
design space enables efﬁcient new simulation code
development (e.g., writing new pair interaction
potentials). The trained surrogates can be used
as benchmarks of existing understanding that can
guide code updates.

IV. OPEN QUESTIONS AND FUTURE DIRECTIONS

The conﬂuence of ML, MD simulations, and cloud
computing presents the broader cloud and HPC research
communities with several exciting challenges, and also
provides a unique opportunity to bring these commu-
nities together. ML-assisted MD simulations impose a
unique set of computational requirements which will re-
quire advances in cloud resource allocation, such as:

• Abstractions: Our bags-of-jobs abstraction is the
ﬁrst step towards a “cloud-native” abstraction for
ML-assisted MD workloads. Easier ways to de-
ploy such applications on the cloud will lower
costs and will make it easier for domain scientists
to rapidly iterate.

• Rethinking performance metrics: Conventional
metrics such as parallel speedups will be insufﬁ-

3

cient for ML-assisted workloads that use a combi-
nation of training and inference, where the answer
can be provided by a trained ML-model. We be-
lieve that cost will remain a ﬁrst-level metric in
the cloud, and must be a core part of performance
and resource optimizations.

We also claim that ML platforms can provide a single,
uniﬁed framework for future applications that will inte-
grate ML and MD simulations in new ways. Fundamen-
tally, we are proposing to use systems in ways that they
are not designed for, which leads to many natural per-
formance challenges. For instance, the dataﬂow model
used by TensorFlow provides suboptimal performance
for ﬁne-grained parallelism required for MD simulations
on GPU and TPU clusters, and new performance opti-
mizations and abstractions are necessary.

Finally, bringing a “classic” HPC workload such as
MD simulations into an entirely new cloud+ML ecosys-
tem will require the HPC, cloud, and ML communities
to work together with domain scientists and engineers in
new ways. The conﬂuence will provide opportunities for
the next generation of domain scientists to be trained in
practical ML and cloud skills. At the same time, cloud
researchers should be more cognizant of this new class
of workload, which is radically different from the “en-
terprise” and “big-data” workloads that cloud platforms
have traditionally been optimized for.

ACKNOWLEDGMENTS

V.J. was partially supported by NSF through Award

1720625.

[1] Ryan L Marson, Trung Dac Nguyen,

and Sharon C
Glotzer, “Rational design of nanomaterials from assembly
and reconﬁgurability of polymer-tethered nanoparticles,”
MRS Communications 5, 397–406 (2015).

[2] Michael F Hagan and Roya Zandi, “Recent advances
in coarse-grained modeling of virus assembly,” Current
opinion in virology 18, 36 (2016).

[3] JP Ewen, DM Heyes, and Daniele Dini, “Advances in
nonequilibrium molecular dynamics simulations of lubri-
cants and additives,” Friction 6, 349–386 (2018).

[4] Nasim Anousheh, Francisco J Solis, and Vikram Jadhao,
“Ionic structure and decay length in highly concentrated
conﬁned electrolytes,” AIP Advances 10, 125312 (2020).
[5] Andrew L Ferguson, “Machine learning and data science
in soft materials engineering,” Journal of Physics: Con-
densed Matter 30, 043002 (2017).

[6] Jiang Wang, Simon Olsson, Christoph Wehmeyer, Adri`a
P´erez, Nicholas E Charron, Gianni De Fabritiis, Frank
No´e, and Cecilia Clementi, “Machine learning of coarse-
grained molecular dynamics force ﬁelds,” ACS central
science 5, 755–767 (2019).

[7] Lorenzo Casalino, Abigail C Dommer, Zied Gaieb,
Emilia P Barros, Terra Sztain, Surl-Hee Ahn, Anda Tri-
fan, Alexander Brace, Anthony T Bogetti, Austin Clyde,
Heng Ma, Hyungro Lee, Matteo Turilli, Syma Khalid,
Lillian T Chong, Carlos Simmerling, David J Hardy,
Julio DC Maia, James C Phillips, Thorsten Kurth, Abra-
ham C Stern, Lei Huang, John D McCalpin, Mahidhar
Tatineni, Tom Gibbs, John E Stone, Shantenu Jha, Arvind
Ramanathan,
and Rommie E Amaro, “Ai-driven mul-
tiscale simulations illuminate mechanisms of sars-cov-2
spike dynamics,” The International Journal of High Per-
formance Computing Applications 35, 432–451 (2021).
[8] Alireza Moradzadeh and Narayana R Aluru, “Molecular
dynamics properties without the full trajectory: A denois-
ing autoencoder network for properties of simple liquids,”
The journal of physical chemistry letters 10, 7568–7576
(2019).

[9] Florian H¨ase, Ignacio Fdez. Galv´an, Al´an Aspuru-Guzik,
Roland Lindh,
and Morgane Vacher, “How machine
learning can assist the interpretation of ab initio molec-
ular dynamics simulations and conceptual understanding

of chemistry,” Chem. Sci. 10, 2298–2307 (2019).

[10] Yangzesheng Sun, Robert F DeJaco, and J Ilja Siepmann,
“Deep neural network learning of complex binary sorp-
tion equilibria from molecular simulation data,” Chemical
science 10, 4377–4388 (2019).

[11] JCS Kadupitiya, Geoffrey C Fox, and Vikram Jadhao,
“Machine learning for parameter auto-tuning in molecu-
lar dynamics simulations: Efﬁcient dynamics of ions near
polarizable nanoparticles,” The International Journal of
High Performance Computing Applications 34, 357–374
(2020).

[12] JCS Kadupitiya, Fanbo Sun, Geoffrey Fox, and Vikram
Jadhao, “Machine learning surrogates for molecular dy-
namics simulations of soft materials,” Journal of Compu-
tational Science 42, 101107 (2020).
[13] JCS Kadupitiya, Geoffrey C Fox,

and Vikram Jad-
hao, “Deep learning based integrators for solving new-
ton’s equations with large timesteps,” arXiv preprint
arXiv:2004.06493 (2020).

[14] JCS Kadupitiya and Vikram Jadhao, “Probing the rheo-
logical properties of liquids under conditions of elasto-
hydrodynamic lubrication using simulations and machine
learning,” Tribology Letters 69, 1–19 (2021).

[15] JCS Kadupitiya, Geoffrey C Fox,

learning

“Machine

Jadhao,
hancement of molecular dynamics
International Conference on Computational Science
(2019) pp. 116–130.

performance

for

and Vikram
en-
simulations,” in

[16] Marco A. S. Netto, Rodrigo N. Calheiros, Eduardo R. Ro-
drigues, Renato L. F. Cunha, and Rajkumar Buyya, “Hpc
cloud for scientiﬁc and business applications: Taxonomy,
vision, and research challenges,” ACM Comput. Surv. 51,
8:1–8:29 (2018).

[17] JCS Kadupitiya, Vikram Jadhao,

teek

Sharma,

“Modeling

the

and
temporally

Pra-
con-

4

strained preemptions of
High-Performance Parallel and Distributed Computing
(2020) pp. 41–52.

transient cloud vms,” in

[18] “Scispot:

Scientiﬁc computing on transient cloud

servers,” https://github.com/prateek-s/scispot.

[19] Kun Yao, John E Herr, David W Toth, Ryker Mckintyre,
and John Parkhill, “The tensormol-0.1 model chemistry:
a neural network augmented with long-range physics,”
Chemical science 9, 2261–2269 (2018).

[20] Samuel Schoenholz and Ekin Dogus Cubuk, “Jax md: a
framework for differentiable physics,” Advances in Neu-
ral Information Processing Systems 33 (2020).

[21] Xiang Gao, Farhad Ramezanghorbani, Olexandr Isayev,
Justin S Smith, and Adrian E Roitberg, “Torchani: A
free and open source pytorch-based deep learning im-
plementation of the ani neural network potentials,” Jour-
nal of chemical information and modeling 60, 3408–3415
(2020).

[22] Stefan Doerr, Maciej Majewski, Adri´a P´erez, Andreas
Kramer, Cecilia Clementi, Frank Noe, Toni Giorgino, and
Gianni De Fabritiis, “Torchmd: A deep learning frame-
work for molecular simulations,” Journal of chemical the-
ory and computation 17, 2355–2363 (2021).

[23] Rainier Barrett, Maghesree Chakraborty, Dilnoza B
Amirkulova, Heta A Gandhi, Geemi P Wellawatte, and
Andrew D White, “Hoomd-tf: Gpu-accelerated, online
machine learning in the hoomd-blue molecular dynamics
engine,” Journal of Open Source Software 5, 2367 (2020).
[24] Steve Plimpton, “Fast parallel algorithms for short-range
molecular dynamics,” Journal of Computational Physics
117, 1 – 19 (1995).

[25] Joshua A Anderson, Jens Glaser, and Sharon C Glotzer,
“Hoomd-blue: A python package for high-performance
molecular dynamics and hard particle monte carlo sim-
ulations,” Computational Materials Science 173, 109363
(2020).

