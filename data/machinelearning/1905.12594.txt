9
1
0
2

y
a
M
9
2

]
L
P
.
s
c
[

1
v
4
9
5
2
1
.
5
0
9
1
:
v
i
X
r
a

Fuzzi: A Three-Level Logic for Differential Privacy

HENGCHU ZHANG, University of Pennsylvania, USA
EDO ROTH, University of Pennsylvania, USA
ANDREAS HAEBERLEN, University of Pennsylvania, USA
BENJAMIN C. PIERCE, University of Pennsylvania, USA
AARON ROTH, University of Pennsylvania, USA

Curators of sensitive datasets sometimes need to know whether queries against the data are differentially
private [Dwork et al. 2006]. Two sorts of logics have been proposed for checking this property: (1) type
systems and other static analyses, which fully automate straightforward reasoning with concepts like “program
sensitivity” and “privacy loss,” and (2) full-blown program logics such as apRHL (an approximate, probabilistic,
relational Hoare logic) [Barthe et al. 2016], which support more flexible reasoning about subtle privacy-
preserving algorithmic techniques but offer only minimal automation.

We propose a three-level logic for differential privacy in an imperative setting and present a prototype
implementation called Fuzzi. Fuzzi’s lowest level is a general-purpose logic; its middle level is apRHL; and its
top level is a novel sensitivity logic adapted from the linear-logic-inspired type system of Fuzz, a differentially
private functional language [Reed and Pierce 2010]. The key novelty is a high degree of integration between
the sensitivity logic and the two lower-level logics: the judgments and proofs of the sensitivity logic can be
easily translated into apRHL; conversely, privacy properties of key algorithmic building blocks can be proved
manually in apRHL and the base logic, then packaged up as typing rules that can be applied by a checker for
the sensitivity logic to automatically construct privacy proofs for composite programs of arbitrary size.

We demonstrate Fuzzi’s utility by implementing four different private machine-learning algorithms and

showing that Fuzzi’s checker is able to derive tight sensitivity bounds.

Additional Key Words and Phrases: Differential privacy, typechecking, static analysis, apRHL, Fuzz, Fuzzi

ACM Reference Format:
Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth. 2019. Fuzzi: A Three-Level
Logic for Differential Privacy. Proc. ACM Program. Lang. 1, 1 (June 2019), 42 pages. https://doi.org/10.1145/
nnnnnnn.nnnnnnn

1 INTRODUCTION

Differential privacy [Dwork et al. 2006] has become the gold standard for privacy-preserving statis-
tical analysis in the academic community, and it is being adopted by a growing number of industry
and government organizations, including Apple [Apple 2017], Google [Erlingsson et al. 2014],
Microsoft [Microsoft 2017] and the US Census Bureau [N. Dajani et al. 2017]. Differential privacy
makes minimal assumptions about an adversary’s knowledge, allowing analysts to quantitatively
estimate privacy loss. However, the reasoning needed to correctly achieve differential privacy can

Authors’ addresses: Hengchu Zhang, University of Pennsylvania, USA, hengchu@seas.upenn.edu; Edo Roth, University of
Pennsylvania, USA, edoroth@seas.upenn.edu; Andreas Haeberlen, University of Pennsylvania, USA, ahae@cis.upenn.edu;
Benjamin C. Pierce, University of Pennsylvania, USA, bcpierce@cis.upenn.edu; Aaron Roth, University of Pennsylvania,
USA, aaroth@cis.upenn.edu.

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee
provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and
the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires
prior specific permission and/or a fee. Request permissions from permissions@acm.org.
© 2019 Association for Computing Machinery.
2475-1421/2019/6-ART $15.00
https://doi.org/10.1145/nnnnnnn.nnnnnnn

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

 
 
 
 
 
 
2

Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth

be rather subtle, as multiple errors in published algorithms attest [Chen and Machanavajjhala 2015;
Lyu et al. 2016].

Barthe et al. [2016] developed the first program logic for formalizing proofs of differential privacy
for imperative programs, called apRHL (Approximate, Probabilistic, Relational Hoare Logic). The
abstractions provided by apRHL are expressive enough to capture the essence of many complex
differentially private algorithms, allowing experts to prove differential privacy for small, tricky
code sequences at a fairly high level of abstraction. However, proving differential privacy in apRHL
for large programs can be a rather tedious endeavor. Fortunately, in many proofs for larger private
data analysis programs (either in apRHL or on paper), the expert knowledge of differential privacy
is concentrated in the analysis of small differentially private subroutines, while the rest of the
proof basically just propagates “sensitivity” information and aggregate privacy costs between
subroutines. This suggests that one could considerably increase the range of possible use cases,
especially for analysts who are not privacy experts, by combining a small but extensible set of
building blocks (and the corresponding manual proofs) with a largely automated analysis that
mechanically completes the proof for a given program.

To enable this approach, we build a new layer of abstraction over apRHL to automate the
mechanical parts of this process. This layer tracks sensitivities for program variables and privacy
costs of commands using Hoare-triple-style proof rules. This information about sensitivity and
privacy cost has a direct translation to lower-level apRHL assertions. This allows information in
the higher-level logic to seamlessly interact with expert proofs of differential privacy that have
been carried out using the two lower layers. Since the top layer is entirely automated, we will often
refer to it as a type system (and to its proof rules as typing rules).

We use the term mechanisms to refer to building blocks of differentially private programs. Many
differentially private mechanisms can be viewed as parameterized program templates, where the
differential privacy properties depend on properties of the instantiation parameters, which can
themselves be program expressions or commands. In order to integrate expert reasoning about such
mechanisms, we develop a framework for expressing program templates and the corresponding
parameterized proofs of differential privacy. This allows experts to extend the sensitivity type
system with a specialized typing rule for each template, allowing non-expert programmers to write
application programs that combine these templates in straightforward ways. This framework uses
apRHL directly to give structured proofs of privacy property, while using the general-purpose base
logic to establish lower-level semantic properties that go beyond the capabilities of apRHL.

We instantiate these ideas in the design and implementation of Fuzzi, a small imperative language
for differentially private queries with automatic and extensible typechecking. Following a brief
review of technical background on differential privacy (Section 2) and a high-level overview of
Fuzzi’s design (Section 3), we offer the following contributions:

(1) We propose a high-level sensitivity logic for tracking differential privacy (Section 4). This
logic is expressive enough to capture detailed sensitivity properties for a simple imperative
core language; its soundness is established via a straightforward embedding into apRHL.
(2) We show how to connect manual proofs for privacy properties of algorithmic building
blocks to the sensitivity logic and develop proofs for several mechanisms that transform
private datasets, plus a mechanism that aggregates privacy costs better than straightforward
composition (Section 5).

(3) Using a prototype implementation of Fuzzi (Section 6), we implement private machine
learning algorithms from four different classes of learning methods (discriminative models,
ensemble models, generative models and instance-based learning) and show that Fuzzi’s
checker is able to derive tight sensitivity bounds (Section 7).

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

Fuzzi: A Three-Level Logic for Differential Privacy

3

Section 8 discusses limitations of the current design. Sections 9 and 10 survey related and future
work.

2 BACKGROUND

2.1 Differential Privacy

Differential privacy is an indistinguishability property of randomized programs on neighboring
input datasets. Informally, a function is differentially private if removing or adding a single row in
the input results in at most a small change in the output distribution.

Definition 1 (Neighboring Dataset). Two datasets are neighbors if one can be transformed into

the other by adding or removing a single row of data.

Let D and D ′ be two neighboring datasets, and let f be a randomized program. The output of f
is a sample from some distribution parameterized by the input datasets. We write f (D) and f (D ′)
for these two distributions.

Definition 2 ((ϵ, δ )-Differential Privacy [Dwork et al. 2006]). The program f is (ϵ, δ )-
differentially private if, for any set of possible outputs E, the probability of observing E satisfies the
relation Px ∼f (D)[x ∈ E] ≤ eϵ Px ∼f (D′)[x ∈ E] + δ .

The parameters ϵ and δ quantify different aspects of the privacy cost of a differentially private
computation. Informally, the value of ϵ measures the ability of an observer to distinguish whether
f was run with D or D ′ after observing E in the “common case”, while δ serves as an upper bound
on the probability that f fails to provide the privacy guarantee implied by ϵ. The parameter ϵ is
typically taken to be a small constant (say, 1), whereas δ must be set so that δ ≪ 1/n, where n is
the number of dataset rows, in order for the privacy guarantees to be non-trivial (otherwise an
algorithm which outputs a dataset row uniformly at random satisfies (0, δ )-differential privacy).

2.2 Sensitivity
The notion of sensitivity is crucial to differential privacy. Many differentially private mechanisms
release data by adding noise proportional to the sensitivity of a private value. In Fuzzi, the term
“sensitivity” specifically refers to an upper bound on the distance between the values held by some
variable between any two runs.

Distance may be calculated differently for values of different types. For primitive values with type
int and real, distance is the magnitude of the two values’ difference. However, for arrays, there
are two important distance definitions for differential privacy: database distance and L1 distance.
The database distance measures the number of rows that need to be added or removed in order to
make two datasets indistinguishable up to permutation; while the L1 distance measures the sum of
element-wise distance between vectors. To avoid confusion in later discussions, we refer to arrays
for which distance is intended to be measured as database distance as bags and arrays with L1
distance as vectors. When we come to defining the type system, we will write {τ } for the type of
bags holding values of type τ and [τ ] for vectors of τ (Figure 1). As an example, the two arrays
[1, 2, 5] and [1, 3, 4] have vector distance 2, but they have bag distance 4, since we need to remove
elements 2 and 5 and add elements 3 and 4 to the first bag in order to make it a permutation of the
second one.1

1Database distance can actually be viewed as just L1 distance on a different representation of datasets. The differential
privacy literature sometimes uses the “histogram representation” for datasets. For a universe of possible elements U ,
the histogram representation maps each x ∈ U to a count of how many times x appears, and the L1 distance of this
representation corresponds to the database distance. However, in order to keep Fuzzi’s semantics minimal as a core language,
we choose to represent datasets as arrays, rather than maps from records to counts.

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

4

Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth

σ := int | real | bool
:= σ | [τ ] | {τ }
τ
op := + | − |
·

| / | && |
< | ≤ | > | ≥ | ¬

||

|

e, i

:= x | lit | e op e | e[i] | e.lenдth

c

:= x = e | x[i] = e | x .lenдth = e |

x = Lb (e) |
if e then c else c end |
while e do c end | c; c

Fig. 1. Core Language Syntax

Formally, we write dτ for the distance function at type τ , with type τ × τ → R+ ∪ {∞}—i.e., it

maps two values of type τ to a non-negative real number or infinity.

Definition 3 (Vector distance). If a1 and a2 are two vectors of the same length and their elements
i=0 dτ (a1[i], a2[i]) where L is the

have type τ , then the vector distance is defined as d[τ ](a1, a2) = (cid:205)L−1
length of both vectors. Vectors of different lengths are assigned the distance ∞.

Definition 4 (Bag distance). Let a1 and a2 be two bags; their distance is defined as d {τ }(a1, a2) =

|a1 \ a2| + |a2 \ a1|.

The backslash operator is multiset difference. Note that bag distance (unlike vector distance) is

meaningful for bags of different sizes. This is the same database distance introduced earlier.

2.3 Laplace Mechanism
The Laplace mechanism is an essential tool for releasing private data with bounded sensitivi-
ties [Dwork et al. 2006; Dwork and Roth 2014]. Fuzzi provides access to the Laplace mechanism
through the sampling assignment command x = Lb (e), which adds noise to the value of e and
assigns that value to the variable x, with the constant literal b determining the scale of the noise.
Adding noise scaled with b to a value with sensitivity s incurs a privacy cost of (s/b, 0). Fuzzi’s
type system will statically keep track of each usage of the Laplace mechanism and report an upper
bound of the total privacy cost as part of a program’s type.

3 OVERVIEW

3.1 Core Language

The core of Fuzzi is a simple imperative programming language with while loops, conditionals, and
assignments (Figure 1). It has just a few built-in data types: reals, integers, booleans, and arrays
(whose elements can be reals, integers, booleans, or nested arrays). Programs can modify the length
of arrays through assignments of the form x .length = e. When the value of e is less than the current
length of x, the array is truncated; and when the value of e is greater than the length of x, the array
is padded with default values that are of the same data type as elements in x. If e evaluates to a
negative number, the length assignment diverges.

One slightly unusual feature of Fuzzi is that all assignments are copying assignments, including
assignments to array variables. For example, if x holds an array value, then the assignment y = x
sets y to a copy of x, instead of making both x and y point to the same underlying array. We make
this choice to avoid reasoning about sharing, which we consider as out of scope for this work.

The special command x = Lb (e) performs probabilistic assignment to x by sampling from a
Laplace distribution centered at the value of e, with width equal to the value of b (which must be a
real-valued literal).

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

Fuzzi: A Three-Level Logic for Differential Privacy

5

3.2 Type System
From now on, we refer to the sensitivity logic as a type system to emphasize that it is a specialized
and automated layer that tracks sensitivity and privacy cost as types. The main data structure
manipulated by Fuzzi’s type system is typing contexts—maps from program variables to sensitivities,
represented as non-negative reals extended with infinity.

ϕ := r ∈ R≥0 ∪ {∞}

τ := σ | [τ ] | {τ }

Γ := ∅ | x :ϕ τ , Γ

A typing context Γ should be interpreted as a relation between two different run-time stores—
intuitively, the stores arising from two “neighboring” executions starting with neighboring initial
states. For each variable x with sensitivity Γ(x), the values in the two stores must be no more than
Γ(x) apart.

Typing judgements for commands have the form {Γ} c {Γ′, (ϵ, δ )}, meaning that, if the distance
of the values in two run-time stores are described by the initial typing context Γ, then executing c
will either both diverge or else both terminate with two final stores described by Γ′, along the way
incurring a privacy cost of (ϵ, δ ).

For example, the typing rule for commands of the form x = e computes the sensitivity of e using

sensitivities of its free variables, and maps x to this sensitivity of e in the output context.

Assign

Γ ⊢ e ∈s τ
{Γ} x = e {Γ[x (cid:55)→ s], (0, 0)}

The typechecker also computes the privacy cost (ϵ, δ ) incurred by the analyzed command. In the
case of assignment, no privacy cost is incurred, so the output from the typechecker after processing
x = e is the updated typing context Γ[x (cid:55)→ s] and the pair of privacy costs (0, 0), where s is the
derived sensitivity of e under Γ.

A more interesting typing rule is the one for sequence commands of the form c1; c2. This rule
chains together the typing judgements for each of the commands, using the output context Γi from
analyzing ci as the input context for processing the next command ci+1. The privacy cost incurred
by the whole program is the sum of privacy costs (ϵi , δi ) incurred by each ci , following the “simple
composition theorem” for differential privacy [Dwork et al. 2006].

Seqence
{Γ1} c1 {Γ2, (ϵ1, δ1)}

{Γ2} c2 {Γ3, (ϵ2, δ2)}

{Γ1} c1; c2 {Γ3, (ϵ1 + ϵ2, δ1 + δ2)}
There are also core typing rules for simple loops and conditionals that do not branch on sensitive
data; we will see these in Section 4.1.

3.3 Typing Differentially Private Mechanisms

The privacy properties of interesting differentially private mechanisms are generally too subtle to
be tracked by the core type system. In Fuzzi, such mechanisms can be defined as extensions and
equipped with specialized typing rules whose soundness is proved manually. Such proofs typically
involve reasoning about relational properties for distributions, as well as aggregating privacy costs.
The program logic apRHL is tailored to tackle both problems, making it a good choice for rigorous
manual proofs of differential privacy.

An apRHL judgement has the form ⊢ c1 ∼(ϵ,δ ) c2 : Φ ⇒ Ψ, where c1 and c2 are two commands
to be related, Φ and Ψ are relational assertions that state pre- and post-conditions relating the
program states before and after executing c1 and c2. A sound apRHL judgement can be roughly
interpreted as: if (1) some pair of program states satisfy the pre-condition Φ, and (2) executing
c1 in the first state terminates iff executing c2 in the second state does, then the pair of states

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

6

Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth

after executing c1 and c2 will satisfy the post-condition Ψ, incurring privacy cost (ϵ, δ ). To express
differential privacy as a post-condition, we can simply state out⟨1⟩ = out⟨2⟩ for the output of the
programs.

Given a typing context Γ, we can interpret Γ as a relation on program states. Writing ⟨1⟩ and ⟨2⟩
after variables to refer to their values in the first or second execution, we translate x :σ τ ∈ Γ to
the assertion dτ (x ⟨1⟩, x ⟨2⟩) ≤ σ ; the conjunction of all these pointwise distance assertions forms
an apRHL assertion that corresponds to Γ.

Conversely, to connect manual proofs in apRHL with the type system, we phrase their premises
and conclusions as typing judgements. Indeed, we use apRHL not only for extensions but also for
the soundness proofs of the core typing rules. As a result, the privacy proofs implicitly constructed
by the typechecker are combinations of apRHL proof objects, some of them generated by the
typechecker, others written manually by experts.

3.4 Example

To give a first taste of Fuzzi’s differential privacy typechecking process, we present a simple
program that computes a private approximation for the average income of a group through private
estimations of the group’s size and sum. First, we estimate the group’s size with the Laplace
mechanism.

size = L1.0(group.length);

Assuming that group is a dataset with sensitivity 1, Fuzzi’s typechecker deduces its size is 1-sensitive.
Applying the Laplace mechanism then incurs a (1.0, 0)-privacy cost.

Next, we sum the group’s incomes using the mechanism bsum, pronounced “bag sum”, which

clips each income value so that its magnitude is at most a given constant (here 1000).

bsum ( group , sum , i , temp , 1000) ;

This clipping step ensures the sum does not vary too much on neighboring datasets. Without
clipping, a single outlier could sway the sum substantially, revealing the outlier’s existence, and
violating differential privacy. The parameters sum, i, and temp specify the names of variables that
bsum can use for internal purposes. It is the programmer’s responsibility to make sure they do not
clash with variables used elsewhere in the program. (It should not be hard to fix this infelicity by
making extensions themselves deal with fresh variable generation, but doing so will introduce a
few additional technicalities so we leave it for future work.)

The command bsum(...) refers to an extension that expands to a sequence of plain core-language

commands implementing summing up a bag of numbers with clipping:

extension bsum (in , out , idx , t_in , bound ) {

idx = 0;
out = 0.0;
while idx < in . length do

t_in = in [ idx ];
if t_in < -1.0 * bound then

out = out - bound ;

else

if t_in > bound then
out = out + bound ;

else

out = out + t_in ;

end

end ;
idx = idx + 1;

end

};

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

Fuzzi: A Three-Level Logic for Differential Privacy

7

This specifies the name of the extension, the names of its parameters (which range over Fuzzi
expressions and commands), and how it expands to core Fuzzi commands. During typechecking,
extension applications are replaced by their expansions, with extension variables substituted by
the snippets of Fuzzi syntax provided as parameters. )

The typing rule for bsum is:

ϕ = Γ(in)

literal bound
Γout = Γ[out (cid:55)→ ϕ · bound][i, tin (cid:55)→ ∞]

bound ≥ 0

{Γ} bsum(in, out, i, tin, bound) {Γout, (0, 0)}

It requires the last parameter bound to be a non-negative literal value—non-negative because bound
specifies the clipping magnitude, and literal because the sensitivity of the output variable depends
on bound. The inference rule updates the sensitivity of the output sum variable to the product of
bound and the sensitivity of Γ(in). Intuitively, since up to ϕ elements may be added or removed
from in, and each can contribute up a value with magnitude up to bound toward the sum, the sum
value itself will vary by at most ϕ · bound. This intuition can be made rigorous, as we show in
Appendix D.4.

The Haskell implementation of the Fuzzi typechecker is likewise extended with a piece of code
implementing the typing rule as a function that transforms an input typing context to an output
typing context and privacy costs.

Continuing the example, we next compute differentially private estimates of the clipped sums

and calculate the group’s average income using the size and sum estimates:

noised_sum = L1000.0(sum);
avg = noised_sum / size ;

The sum variable is 1000-sensitive, so releasing noised_sum incurs another (1.0, 0)-privacy cost. The
typechecker reports an aggregate privacy cost of (2.0, 0).

4 SENSITIVITY TYPE SYSTEM

4.1 Notation and definitions
Throughout the paper, we will use the operator [[·]] to denote the semantic function for commands
and expressions in Fuzzi. We use the notation ⃝ S to denote sub-distributions over values in S. We
will use the letter M, N to stand for program states, which are finite maps from variable names to
the values they hold, and use the letter M to stand for the set of all program states.

The semantics of a Fuzzi program c is a function from program states to sub-distributions
over program states [[c]] : M → ⃝ M. Each type in Fuzzi is associated with a set of values: int
with the set Z, real with the set R, and [τ ] and {τ } with the set of finite sequences of values
associated with τ . The meaning of a Fuzzi expression e with type τ is a partial function from
program states to associated values of that type [[e]] : M ⇀ τ . Partiality of expressions stems from
invalid operations such as arithmetic between incompatible values, and out-of-bound indexing.
The complete definition of Fuzzi semantics can be found in Appendix A. Recall from Section 3.1
that Fuzzi assignments are copy-assignments for all values, including vectors and bags.

Fuzzi’s semantics directly follows from the work of Barthe et al. [2016]. It is worth noting that the
original apRHL developed by Barthe et al. [2016] only reasons with discretized Laplace distributions,
and Fuzzi shares this restriction in its semantic model. A later model based on category theory
enhances apRHL’s proof rules for continuous distributions [Sato 2016]. However, the underlying
proof method of this model is not compatible with Fuzzi’s development, and only recently have
new abstractions been proposed to generalize the original apRHL proof methods to continuous
distributions [Sato et al. 2019].

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

8

Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth

Plus
Γ ⊢ el ∈s τ

Γ ⊢ er ∈t τ

τ = int ∨ τ = real
+ er ∈s+t τ
Γ ⊢ el

Mult-L-Constant
literal k

Γ ⊢ er ∈t τ

τ = int ∨ τ = real
Γ ⊢ k · er ∈k ·t τ

Mult
Γ ⊢ el ∈s τ

Γ ⊢ er ∈t τ

τ = int ∨ τ = real
Γ ⊢ el · er ∈approx(s,t ) τ

Fig. 2. Arithmetic Expression Typing Rules

Fuzzi’s typing context Γ tracks both the data type and the sensitivity of variables. Typechecking
involves checking data types as well as computing sensitivities. We refer to data typechecking
as shape checking and sensitivity computations as sensitivity checking. We will elide details of
shape checking since it is the standard typechecking that rules out operations between values of
incompatible types. To emphasize sensitivity checking in Fuzzi, and to reduce clutter in syntax,
we will write Γ(x) for the sensitivity of the variable x under the typing context Γ, and we write
Γ[x (cid:55)→ s] for a typing context which updates variable x’s sensitivity to s, but does not alter its
data type. We overload this syntax when we update a set of variables xs to the same sensitivity
Γ[xs (cid:55)→ s]. We also overload the notation Γ(e) to denote the derived sensitivity of expression e
under typing context Γ. When we need to refer to the data type of expression e, we will use the full
typing judgment of an expression Γ ⊢ e ∈ϕ τ , which we pronounce “expression e has sensitivity ϕ
and type τ under context Γ.”

We use the notation shape(Γ) to extract the shape checking context from a typing context Γ,

dropping all sensitivity annotations.

4.2 Typing Expressions

In order to compute sensitivity updates throughout sequences of commands, the type system needs
to first compute sensitivities for expressions used within each command. We discuss the typing rules
for addition and multiplication here as examples. Intuitively, if the values of two expressions el and
er can each vary by 1, then their sum can vary by at most 2 (the sum of their individual sensitivities)
by the triangle inequality; and if the value of e can vary by at most 1, then multiplying e by a literal
constant k results in a value that can vary by at most k. The rules Plus, and Mult-L-Constant
in Figure 2 capture these cases.

There are also expressions for which we cannot give precise sensitivity bounds. For instance, if
one of the operands for a multiplication between el and er is sensitive, then, without knowing the
exact value of the other operand, we cannot a priori know how much the value of entire product
can change. This case is captured by the Mult rule, where the function approx is defined by the
equations

approx (0, 0)
approx (s1, s2)

= 0
if s1 + s2 > 0 = ∞

which conservatively take the sensitivity to be ∞ if at least one side of the expression is sensitive.
Fuzzi provides bag and vector index operations, and Fuzzi’s typechecker supports sensitivity
checking for lookup expressions on bags and vectors. These typing rules use the definition of bag
and vector distances to establish sound upper bounds of sensitivities on lookup expressions.

Vector-Index
Γ ⊢ e ∈ϕ [τ ]

Γ ⊢ i ∈0 int

ϕ < ∞
Γ ⊢ e[i] ∈ϕ τ

Bag-Index
Γ ⊢ e ∈0 {τ }

Γ ⊢ i ∈0 int

Γ ⊢ e[i] ∈∞ τ

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

Fuzzi: A Three-Level Logic for Differential Privacy

9

Assign

Γ ⊢ e ∈ϕ′ τ
{Γ} x = e (cid:8)Γ[x (cid:55)→ ϕ ′], (0, 0)(cid:9)

Assign-Vector-Index
Γ ⊢ x ∈ϕ [τ ]

Γ ⊢ e ∈σ τ

ϕ < ∞ Γ ⊢ i ∈0 int
{Γ} x[i] = e {Γ[x (cid:55)→ ϕ + σ ], (0, 0)}

Assign-Vector-Length
Γ ⊢ e ∈0 int
Γ ⊢ x ∈ϕ [τ ]
{Γ} x .lenдth = e {Γ, (0, 0)}

Assign-Bag-Length
Γ ⊢ x ∈ϕ {τ }

Γ ⊢ e ∈0 int

{Γ} x .lenдth = e {Γ[x (cid:55)→ ∞], (0, 0)}

Laplace

Γ, x :ϕ real ⊢ e ∈ϕ′ real
(cid:8)Γ, x :ϕ real(cid:9) x = Lb (e) (cid:8)Γ, x :0 real, (ϕ ′/b, 0)(cid:9)

Skip

{Γ} skip {Γ, (0, 0)}

Seqence
{Γ1} c1 {Γ2, (ϵ1, δ1)}

{Γ2} c2 {Γ3, (ϵ2, δ2)}

{Γ1} c1; c2 {Γ3, (ϵ1 + ϵ2, δ1 + δ2)}

If
{Γ} ct {Γt , (ϵt , δt )}

{Γ} cf
ϵ ′ = max(ϵt , ϵf )

(cid:8)Γf , (ϵf , δf )(cid:9)
δ ′ = max(δt , δf )

Γ ⊢ e ∈0 bool

{Γ} if e then ct else cf end (cid:8)max(Γt , Γf ), (ϵ ′, δ ′)(cid:9)

While
Γ ⊢ e ∈0 bool
{Γ} c {Γ, (0, 0)}
{Γ} while e do c end {Γ, (0, 0)}

Fig. 3. Core Typing Rules

The Vector-Index rule applies when the lookup expression is 0-sensitive. A 0-sensitive index
value must be the same across two executions, and the distance between two values at the same
position must be bounded by the overall sensitivity of the vector itself according to Definition 3. As
an example, given two vectors [1, 2, 3] and [1, 2, 4], if we indexed both vectors at the last position,
then the resulting values 3 and 4 are at distance 1 apart, which is bounded by the distance between
the original vectors. The premise ϕ < ∞ is necessary to ensure the indexed arrays have the same
length in both executions, so that the lookup expression terminates in one execution if and only if
it terminates in the other. We refer to this property as co-termination. It is discussed in Section 4.4.
It may be surprising that Fuzzi’s typechecker only accepts bag lookup operations over non-
sensitive bags. This is due to requirement of co-termination and the fact that bags with non-zero
sensitivities may have different lengths in neighboring runs. To see why the bag lookup expression
has sensitivity ∞, consider two bags [1, 100, 2] and [1, 2, 100]; these are at distance 0, but if we
access both bags with index 1, the resulting values 100 and 2 are distance 98 apart.

4.3 Typing Commands
The typing judgments for commands has the form {Γ} c {Γ′, (ϵ, δ )}. We can think of these judg-
ments as a Hoare-triple—Γ is a pre-condition of the program c, and Γ′ is a post-condition for
c—annotated with (ϵ, δ ), the total privacy cost of running c.

There are three forms of assignment in Fuzzi: (1) direct assignment to variables, (2) indexed
assignment to vectors and bags, and (3) length assignments to vectors and bags. There is a separate
typing rule for each form of assignment (Figure 3). The Assign rule updates the LHS variable’s
sensitivity to the derived sensitivity of the RHS expression. The Assign-Vector-Index rule adds
the derived sensitivity of RHS expression to a vector’s sensitivity provided the index itself is non-
sensitive. (For example, consider the vectors xs ⟨1⟩ = [1, 2, 3] and xs ⟨2⟩ = [1, 2, 4]. If we perform
the assignment xs[1] = e where e ⟨1⟩ = 1 and e ⟨2⟩ = 10, then the two vectors become [1, 1, 3] and
[1, 10, 4], increasing the distance between them by 9. We require finite sensitivity of the vector
variable on the left-hand-side to ensure co-termination—only vectors with finite sensitivities must
have the same length.)

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

10

Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth

We have separate rules for vector and bag length updates. In the Assign-Vector-Length rule,
since the RHS length expression is non-sensitive, the two vectors will be truncated or padded to
the same length. In the case of truncation, the distance between the two vectors will decrease or
remain the same; on the other hand, if both vectors were padded, since the pad will be the same,
they will not introduce any additional distance. Thus, the LHS vector variable’s sensitivity remains
the same.

In the Assign-Bag-Length rule, it may be surprising that updating the lengths bags—even with
a 0-sensitive new length—can result in ∞-sensitivity for the bag. Consider two subsequences of the
same length X and Y , let L be their identical length. We can choose X and Y such that their bag
distance is 2L. Now, the two bags XY and YX have distance 0 since they contain the same elements,
but if we truncated both bags to length L, then their distance grows to 2L. The Assign-Bag-Length
rule must account for this worst case scenario by setting the sensitivity of x to ∞.

The core typing rules for operations that involve bags are rather restrictive. We will see in

Section 5 how to operate more flexibly over bags using extensions.

The Laplace rule computes the privacy cost of releasing a single sensitive real value. The Laplace
rule sets the sensitivity of x to 0 after noise is added, which may seem surprising since x’s value is
randomized. Intuitively, the 0-sensitivity expresses that x’s value is now public information and
can be used in the clear. We justify 0-sensitivity as an upper bound on the distance between x ⟨1⟩
and x ⟨2⟩ in Appendix B. However, readers do not need to look there to understand the Fuzzi’s type
sytem design.

The no-op command skip does not alter the program state at all: given any pre-condition Γ, we
can expect the same condition to hold after skip. Also since skip does not release any private data,
it has a privacy cost of 0. This is described by the Skip rule.

As described in Section 3, the Seqence rule chains together the intermediate Γs for two

commands c1 and c2 and adds up the individual privacy costs for each command.

The control flow command if may modify the same variable with different RHS expressions
in each branch; if we allowed expressions with arbitrary sensitivities as the branch condition, we
would not be able to derive valid sensitivities for modified variables due to different execution
paths. Consider the following example, where e is a sensitive boolean expression: if e then x =
y else x = z end. In one execution, control flow may follow the true branch, assigning y to x,
while, on the other execution, control flow follows the false branch, assigning z to x. Since the
typing context Γ does not provide any information on the distance between y and z, we cannot
derive a useful upper bound on |x ⟨1⟩ − x ⟨2⟩| after the if statement.

On the other hand, if the branch condition is a non-sensitive boolean, then we know that
control will go through the same branch in both executions. In this case, we can take the pointwise
maximum of the sensitivities from the post-condition of both branches to derive a sound sensitivity
for variables modified by the if statement. Similarly, the privacy cost of the entire if statement is
bounded by the maximum of the two branches’ privacy costs.

The core typing rule for while loops require Γ to be a loop invariant of the loop body c, the loop
guard e a non-sensitive boolean value under Γ, and the loop body c incur no privacy cost. Had we
allowed e be a sensitive boolean, then the while loop may diverge in one execution but terminate
in the other. In order to ensure that the two executions co-terminate, we must force the values of
e ⟨1⟩ and e ⟨2⟩ before each iteration. We achieve this by checking that the invariant Γ of the loop
induces a 0 sensitivity on the loop guard e.

The Simple Composition Theorem [Dwork et al. 2006] implies that the total privacy cost of a
while loop is bounded by the sum of individual privacy cost from each iterations. Even though we
can ensure the two executions of while loops co-terminate, we cannot always statically tell for
how many iterations both loops will run. In order to ensure the soundness of the total privacy cost

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

Fuzzi: A Three-Level Logic for Differential Privacy

11

estimation, we conservatively forbid loop bodies from using any commands that will increase ϵ
or δ .

These core typing rules place rather heavy restrictions on Fuzzi programs operating over vectors
and bags, or programs using conditionals and loops; for example, the core rules grossly overestimate
sensitivities for vectors and bags and forbid sensitive booleans in branch and loop conditions. The
core rules are designed for chaining together blocks of differentially private mechanisms, and these
typing rules are often not enough to typecheck the implementation of interesting differentially
private algorithms. We will see how to teach Fuzzi’s typechecker to derive more precise sensitivities
for differentially private mechanisms involving all these constructs in Section 5.

4.4 Soundness

There has been a rich line of work on developing type systems and language safety properties using
foundational methods [Ahmed 2006; Appel and McAllester 2001; Appel et al. 2007; Frumin et al.
2018; Jung et al. 2017, etc.]. The foundational approach develops the typing rules of a language as
theorems in an expressive logic. Type systems developed using foundational methods benefit from
the soundness of the underlying logic: if a typing rule is proven true as a theorem, then adding new
rules as theorems to the type system will not break validity of existing rules. Most importantly,
the foundational approach allows Fuzzi to mix typing rules for an automated typechecker with
specialized typing rules extracted from manual proofs of differential privacy.

We choose apRHL [Barthe et al. 2016] as the foundational logic to build Fuzzi’s type system upon.
The apRHL logic extends Floyd-Hoare Logic [Hoare 1969] with relational assertions, reasoning
of probabilistic commands, and differential privacy cost accounting. An apRHL judgment has the
form ⊢ c1 ∼(ϵ,δ ) c2 : Ψ ⇒ Φ. The metavariables c1 and c2 stand for two programs related by this
judgment, the annotations ϵ and δ stand for the quantitative “cost” of establishing this relation,
and Ψ and Φ are both assertions over pairs of program states, standing for the pre-condition and
the post-condition of this judgment respectively.

We have seen two kinds of rules in the Fuzzi type system so far: expression typing rules and
core typing rules for commands. Although both are presented in the form of inference rules, these
two typing judgments are very different in nature. The expression typing rules are defined as an
inductive relation, while the typing rules for commands are theorems to be proven. This choice is
motivated more by practicality and less by theory—foundational proofs are more difficult to work
with than inductive relations, since we do not plan on mixing the typing rules for expressions with
manual proofs, there is no need to use the foundational methods for expressions.

Because expression typing rules of the form Γ ⊢ e ∈ϕ τ are instances of an inductive relation,
we need to prove a few soundness properties that will make these expression typing rules useful
in the development of command typing rule proofs. In particular, we care about soundness with
respect to sensitivity and co-termination. We elide proofs by straightforward induction.

Lemma 1 (Expression Sensitivity Sound). Given Γ ⊢ e ∈ϕ τ and two program states M1 and M2

related by Γ, if [[e]]M1 = v1 and [[e]]M2 = v2, then dτ (v1, v2) ≤ ϕ.

Lemma 2 (Expression Co-termination). Given Γ ⊢ e ∈ϕ τ and two program states M1 and M2
related by Γ, evaluating the expression [[e]]M1 yields some value v1 if and only if [[e]]M2 yields some
value v2.

The command typing rules have the form {Γ} c {Γ′, (ϵ, δ )}. And earlier, we described Γ and
Γ′ as pre-condition and post-conditions. What does it mean to treat a typing context as pre- and
post-conditions?

Recall the translation from typing contexts to apRHL assertions in Section 3. This translation
naturally induces a relation on each program variable: each variable’s type information x :ϕ τ

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

12

Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth

becomes the relation dτ (x ⟨1⟩, x ⟨2⟩) ≤ ϕ. The entire typing context Γ is translated to conjunctions
of the pointwise relation for each program variable. As an example, the context x :1 int, y :2 real
corresponds to the relation dint(x ⟨1⟩, x ⟨2⟩) ≤ 1 ∧dreal(y⟨1⟩, y⟨2⟩) ≤ 2. We also use the [[·]] function
to denote the translation of typing contexts.

So a typing rule is in fact an apRHL judgement in disguise: ⊢ c ∼(ϵ,δ ) c : [[Γ]] ⇒ [[Γ′]]. To prove
these judgments valid, we need to use the apRHL proof rules. In fact, many of Fuzzi’s core typing
rules are specialized versions of the corresponding apRHL rule for that command. We list all apRHL
proof rules used in this paper in Appendix B, but readers do not need to look there to understand
the following content in the main body of the paper.

As an example, the soundness of the Assign rule is justified by the following lemma:
Lemma 3. Given Γ ⊢ e ∈ϕ′ τ , the judgement ⊢ x = e ∼(0,0) x = e : [[Γ]] ⇒ [[Γ[x (cid:55)→ ϕ ′]]] is true.
We define one such lemma for each of the typing rules given in Figure 3, and justify them using

corresponding apRHL proof rules.

One important technical subtlety is that the original presentation of apRHL only reasons over
terminating programs. Requiring Fuzzi’s typechecker to prove termination for all programs would
unavoidably rule out some useful ones. Fortunately, we actually need only a subset of apRHL’s
proof rules, and these are all sound even if programs only co-terminate [Hsu 2018]; we can thus we
relax the “all programs terminate” assumption of apRHL in the development of Fuzzi.

Remark. Although we carry out privacy proofs in apRHL, the logic apRHL does not fully isolate
its user from the underlying semantics of the language. For example, some of the apRHL proof
rules used to develop Fuzzi require us to prove termination of commands, but apRHL does not give
proof rules for termination. So we develop our own sound termination typing rules that match
apRHL’s termination definition, using the semantics of Fuzzi. This necessitates an even lower-level
logic L to formalize the parts not specified by apRHL. In the following sections, we will explicitly
call out objects defined in L.2

5 EXTENSIONS

In this section, we discuss how to integrate the core Fuzzi type system with specialized typing
rules for Fuzzi extensions; we then introduce several concrete extensions that will be used later for
our case studies: operations for mapping a piece of code over all the cells in a bag or vector, an
operation for partitioning a bag into a collection of smaller bags according to some criterion, an
operation for summing the elements of a bag, and an operation for sequencing several commands
using an “advanced composition theorem” from the differential privacy literature to obtain a lower
privacy cost than the one given by the plain sensitivity typing rule for sequencing.

Definition 5. An extension is a 4-tuple (ext, f , rule, proof ). The first field ext is the name of
the extension. The second field is a function f that maps Fuzzi expressions or commands to a Fuzzi
command, we will call f the syntax expansion function. Let v1, . . . , vi be the syntactic variables bound
in f ; the third field is a typing rule, parameterized by the same v1, . . . , vi syntactic variables. The
typing rule may contain premises over any combination of v1, . . . , vi , and the typing rule’s conclusion
has the shape of a Fuzzi typing triple for the expanded code of the extension. Finally, the last field
proof is a proof of the soundness of the typing rule.

We will use the notation ext(p1, p2, . . . , pi ) for the syntax of invoking an extension. These exten-
sion commands are replaced by the expanded body f (p1, p2, . . . , pi ) with each pi substituting for
each syntax variable vi .
2The proof assistant Coq [Coq Development Team 2018] is a suitable candidate of L; indeed, we have already formalized
some parts of Fuzzi in Coq.

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

Fuzzi: A Three-Level Logic for Differential Privacy

13

Bag-Map

Termination, Deterministic:
Γ ⊢ c term
Should Not Modify:

determ c

tin, in, out, i (cid:60) mvs c

Abbreviation:
σ = [mvs c, i, in, out (cid:55)→ ∞]
σ ′ = [mvs c, i, tin, tout (cid:55)→ ∞]

Dependency:
{stretch Γ[tin (cid:55)→ 0]σ } c {Γ1, (0, 0)}
{stretch Γ[tin (cid:55)→ ∞]σ } c {Γ2, (0, 0)}
Γ1(tout ) = 0
{x | x ∈ mvs c ∧ Γ2(x) > 0} ⊆ {tout }
Output Sensitivity:

Γ1(tout ) = 0

Γout = Γ[out (cid:55)→ Γ(in)]σ ′

i = 0;
out . length = in. length ;
while i < in. length do

tin = in[i];
c;
out [i] = tout ;
i = i + 1;

end

{Γ} bmap(in, out, tin, i, tout, c) {Γout, (0, 0)}

Fig. 4. Bag-Map typing rule and extension code pattern

Expressing the typing rule requires the full generality of the lowest level logic L, since extension
typing rules contain side conditions (such as termination) that are not captured by apRHL. The
general shape of this theorem is of the form

∀ v1, . . . , vi , P1 ∧ · · · ∧ Pj ⇒ {Γ} ext(v1, . . . , vi ) {Γ′, (ϵ, δ )}

Each Pj is a premise of the typing rule, and all premises may bind any combination of v1, . . . , vi .
The conclusion of the theorem is always of the shape of a Fuzzi typing triple, so that proofs of the
typing rule can mix with the soundness proofs of the core typing rules introduced in Section 4.1.
The final component of an extension is a soundness proof of the typing rule theorem.

Some of these premises are Fuzzi typing judgments, while some others are auxiliary judgments
that asserts termination or describes a linear scaling relationship between the pre-condition sen-
sitivities and the post-condition sensitivities. These two extra kinds of auxiliary judgments are
defined in L, we will give definitions for these auxiliary judgments as we encounter them. We will
describe their proof rules in Appendix C.

We will provide an overview of the use case for each extension, and only provide a sketch of
the proof of soundness to conserve space. Detailed soundness proofs for all the extensions can be
found in Appendix D.

5.1 Bag Map

Our first extension, Bag-Map, takes an input bag variable, an output bag variable, a few auxiliary
variables used by the expanded loop, and finally a “bag-map body” c that reads from a single bag
entry and outputs a mapped value for that bag entry. This command c represents a single step of
the “map” operation. Bag-Map applies this operation uniformly for all entries in a bag.

The premises of Bag-Map’s typing rule use a few new ingredients—the function mvs collects
the set of modified variables from a command c, and the function stretch “expands” a typing
context. The stretch function takes a typing context Γ, and for each variable x ∈ Γ, if Γ(x) > 0,
sets Γ(x) = ∞, otherwise leaves Γ(x) as 0.

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

14

Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth

= ∅
(x :0 τ , Γ) = x :0 τ , stretch Γ
(x :σ τ , Γ) = x :∞ τ , stretch Γ
The function stretch is used when we need to verify that some output variable’s sensitive value
derives solely from some input variable.3

stretch ∅
stretch
stretch

if σ > 0

Since a variable can only become sensitive if its value derives from another sensitive variable, it
is perhaps not surprising that Fuzzi’s sensitivity type system is capable of tracking dependency
as well. We will use the function stretch to help uncover this dependency analysis part of the
sensitivity type system.

Consider any program fragment c, for which we want to verify that for a single variable t,
after executing c, the sensitive data held in t must only come from s. If we had the following
typing judgment about c: {stretch Γ1[s (cid:55)→ 0]} c {Γ2, (0, 0)} where Γ2(t) = 0, then we know if s is
non-sensitive, t is also non-sensitive. This implies that the only sensitive dependency of t is at most
the singleton set {s}.

However, this typing judgment only tells us the dependency of t when all sensitive variables
are ∞-sensitive before executing c. Does the same result hold when those variables have finite
sensitivity? To arrive at this conclusion, we need to apply the Conseq rule from apRHL after
unfolding our previous typing judgment into an apRHL judgement.

Conseq
⊢ c1 ∼ϵ ′,δ ′ c2 : Φ′ ⇒ Ψ′
⊨ Ψ′ ⇒ Ψ ⊨ ϵ ′ ≤ ϵ

⊨ Φ ⇒ Φ′
⊨ δ ′ ≤ δ

⊢ c1 ∼(ϵ,δ ) c2 : Φ ⇒ Ψ

The Conseq rule allows us to strengthen the pre-condition. Now, in the context stretchΓ1[s (cid:55)→ 0],
if we change any other variable’s sensitivity to some finite value, then we have a stronger statement,
since ∞-sensitivity is implied by finite sensitivity. Thus, the Conseq rule allows us to change the
pre-condition to one that implies the stretched typing context.

This technique allows us to verify t’s dependency is at most {s} through sensitivity analysis.
However, the program c may modify variables other than t. In order to make sure there are no
other sensitive output variables from the program fragment c, we also want to verify the lack of
dependency on s. Can we re-use the sensitivity type system to check some other modified variable
v does not depend on the variable s? Indeed we can, using the stretch function again in a slightly
different way. Consider the typing judgment {stretch Γ1[s (cid:55)→ ∞]} c {Γ2, (0, 0)} where Γ2(v) = 0.
This typing judgment tells us that no matter how much s and the other sensitive values changes
between two executions of c, the value held in v remains the same at the end of the execution. So
indeed v does not depend on s or any other sensitive variable. Again Conseq rule allows us to
strengthen the ∞-sensitivity to any finite sensitivity.

The Bag-Map typing rule applies this technique to check that, on each iteration of c, the value
of tout derives only from the corresponding input bag entry tin. The program fragment c should
not access the original bag value directly, and neither should it write directly to the output bag.
Furthermore, each iteration of the bag map body should be independent of each other, so the values
of its modified variables should not carry over to the next iteration. For these reasons, we set the
sensitivity of modified variables of c, the variable i, and the input and outputs bags variables in and
out to ∞ in the judgment {stretch Γ[tin (cid:55)→ 0]σ } c {Γ1, (0, 0)}, and check Γ1(tout) = 0. We use the
letter σ to abbreviate the update expression [mvs c, i, in, out (cid:55)→ ∞].

3This kind of dependency analysis is one of the motivating examples for Benton’s seminal work on relational Hoare
logic [Benton 2004].

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

Fuzzi: A Three-Level Logic for Differential Privacy

15

We also want to verify that none of the modified variables, except for tout, has any dependency
on sensitive data. This is why we check the only variable that can potentially hold sensitive data is
tout in the judgment {stretch Γ[tin (cid:55)→ ∞]σ } c {Γ2, (0, 0)} The variables mvs c, i, in, out are again
set to ∞ to ensure these variables do not leak information across iterations as discussed above.

We use the judgment determ c to assert that c is a deterministic Fuzzi program. It is easy to
show that any program c that do not contain the Laplace mechanism is deterministic. We use the
judgment Γ ⊢ c term to denote that command c terminates for any program state that is well-typed
according to shape(Γ). That is, for all M in shape(Γ), running the program c with the well-typed
program state [[c]]M terminates with probability 1.

Since the apRHL judgment that corresponds to the conclusion of this typing rule implies co-
termination of Bag-Map programs, we need to prove the expanded while loops actually co-terminate.
However, because these two while loops may have different number of iterations due to bags
having different sizes, thus executing c for different number of times, we cannot simply show c
co-terminates. So, we take the extra step of requiring termination of c on all well-shaped inputs,
which ensures both loops will always terminate.

The soundness proof for the Bag-Map typing rule applies dependency analysis to ensure the
map body c maps the input value tin deterministically to tout, and that c does not store sensitive
data in any of its other modified variables. This allows us to ensure in[i] maps deterministically
and uniformly to out[i] through each iteration of c. Now, adding or removing any entry from the
input bag will correspondingly add or remove the mapped value from the output bag. So the output
bag must have the same sensitivity as the input bag.

5.2 Vector Map

Our second example, the Vector-Map extension is, very similar to Bag-Map in that it also requires
the “map” command to restrict its flow of sensitive data from tin to only tout. However, Vector-Map
has an additional requirement that map body must be “linear”:

Definition 6 (Linear Commands). We write kΓ to denote a typing context Γ′ where Γ′(x) = kΓ(x).
A deterministic and terminating command c is linear with respect to Γ1 and Γ2, if for any k > 0, the
scaled typing judgment {kΓ1} c {kΓ2, (0, 0)} is true. We define k · ∞ = ∞ for k > 0, and 0 · ∞ = 0.

This definition tells us that the updates in sensitivity in the post-condition scale linearly with
respect to the sensitivities in the pre-condition. An example of a linear command is x = 2y + 1 with
typing context Γ1 = x :0 real, y :1 real and Γ2 = x :2 real, y :1 real.

A counterexample is if x > 0 then x = x + 1 else x = x + 2 end with Γ1 = x :1 real and
Γ2 = x :2 real. This command conditionally increments x by a constant of 1 or 2, so if x was 1
sensitive before executing this command, then we can show in apRHL that x is 2 sensitive after
this conditional command. Now, if we scaled x’s sensitivity by 0.5, then x is 1.5 sensitive after this
conditional increment, rather than 2 · 0.5 = 1. So this command is not linear with respect to the
chose Γ1 and Γ2. However, had we chosen Γ2 = x :∞ real, then this command is linear with respect
to the new post-condition, because k · ∞ = ∞, and no matter what the values of x ⟨1⟩ and x ⟨2⟩
are, their difference is always bounded by ∞. We present the proof rules for linear commands in
Appendix C.

For vector map, we need to know the scaling relationship between the sensitivity of tout and
the sensitivity of tin in order to derive the sensitivity of the output vector. With c being a linear
command for the chosen pre-condition Γ[tin (cid:55)→ 1]σ and post-condition Γ3, by the definition, for any
scale factor k > 0 we know if d(tin⟨1⟩, tin⟨2⟩) ≤ k before executing c, then d(tout ⟨1⟩, tout ⟨2⟩) ≤ sk
after executing c, where s = Γ3(tout). Recall the definition of vector distance, by instantiating k with
the actual distance for each pair of ith entries from the input vectors d(in⟨1⟩[i], in⟨2⟩[i]), we know

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

16

Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth

Vector-Map

Termination, Deterministic:
Γ ⊢ c term
Should Not Modify:

determ c

tin, in, out, i (cid:60) mvs c

Abbreviation:
σ = [mvs c, i, in, out (cid:55)→ ∞]
σ ′ = [mvs c, i, tin, tout (cid:55)→ ∞]

Dependency:
{stretch Γ[tin (cid:55)→ 0]σ } c {Γ1, (0, 0)}
{stretch Γ[tin (cid:55)→ ∞]σ } c {Γ2, (0, 0)}
Γ1(tout ) = 0
{x |x ∈ mvs c ∧ Γ2(x) > 0} ⊆ {tout }
Linear:
{Γ[tin (cid:55)→ 1]σ } c {Γ3, (0, 0)} linear
Output Sensitivity:

Γout = Γ[out (cid:55)→ Γ(in) · Γ3(tout )]σ ′

{Γ} vmap(in, out, tin, i, tout, c) {Γout, (0, 0)}

i = 0;
out . length = in. length ;
while i < in. length do

tin = in[i];
c;
out [i] = tout ;
i = i + 1;

end

Fig. 5. Vector-Map typing rule and extension code pattern

the distance between the output vectors satisfy the following condition:
d[τ ](out⟨1⟩, out⟨2⟩) = (cid:213)

dτ (out⟨1⟩[i], out⟨2⟩[i])

≤

i
(cid:213)

i

s dτ (in⟨1⟩[i], in⟨2⟩[i])

= sd[τ ](in⟨1⟩, in⟨2⟩).

This justifies the sensitivity derived by the typing rule for vector map.

5.3 Partition

Our third extension, Partition, allows programmers to break apart a larger bag into a vector of
smaller bags. Partition is parameterized by an input bag variable, an output vector variable, a few
auxiliary variables for storing results from intermediate computations, and finally a command that
maps each input bag entry to a partition index.

The Partition extension is similar to Bag-Map in that it maps each bag item to some value,
but they differ in how the output value from the each iteration is used. With Bag-Map, the output
value from each iteration is collected into the output bag as is. Partition uses the output value as
an assignment index into the output bag out, and appends the bag entry at current iteration to the
sub-bag at out[tidx]. As an example, if the input bag is [1.2, 2.3, 3.4], and the map operation simply
rounds down each value to the nearest integer, then the output bag will be [[], [1.2], [2.3], [3.4]].
It may seem redundant that Partition takes the number of partitions as a parameter. Shouldn’t
Partition be able to compute the number of partitions as it processes the input bag values? It
should not, because a computed number of partitions is a sensitive value that depends on the
contents of the input bag. Taking the previous example, if we add a value of 100.1 to the input
bag and do not fix the number of partitions ahead of time, then the output vector will have 97
more sub-bags than the original output vector—i.e., the distance between the output vectors can be

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

Fuzzi: A Three-Level Logic for Differential Privacy

17

Partition

Termination, Deterministic:
Γ ⊢ c term determ c
Should Not Modify:

tin, in, out, i, outidx (cid:60) mvs c

Abbreviation:

σ = [mvs c, i, in, outidx (cid:55)→ ∞]
σ ′ = [mvs c, i, tin, tidx, outidx, tpart (cid:55)→ ∞]

Number of Partitions Non-Sensitive:
Γ ⊢ nParts ∈0 int
fvs nParts ∩ mvs c = ∅
i, tin, tidx, outidx, tpart (cid:60) fvs nParts

Dependency:
{stretch Γ[tin (cid:55)→ 0]σ } c {Γ1, 0}
{stretch Γ[tin (cid:55)→ ∞]σ } c {Γ2, 0}
Γ1(tout ) = 0
{x |x ∈ mvs c ∧ Γ2(x) > 0} ⊆ {tout }
Output Sensitivity:

Γout = Γ[out (cid:55)→ Γ(in)]σ ′

{Γ} partition(in, out, tin, i, tout, tidx, outidx, tpart, nParts, c) {Γout, 0}

i = 0;
out . length = nParts;
while i < nParts do

out [i ]. length = 0;
i = i + 1;

end ;
bmap (in, outidx , tin , i , tout , c);
i = 0;

while i < outidx . length do

tidx = outidx [i ];
if 0 <= tidx && tidx < out . length then

tpart = out [tidx ];
tpart . length = tpart . length + 1;
tpart [tpart . length - 1] = in[i ];
out [tidx ] = tpart ;

else

skip ;

end ;
i = i + 1;

end

Fig. 6. Partition typing rule and extension expansion

made arbitrarily large by adding a single item to the input bag. This is why we fix the number of
partitions and drop the items whose partition indices are out of range.

The soundness of the sensitivity check for partition comes from the fact that each index is derived
only from its corresponding bag entry, thus adding or removing one bag entry can cause at most
one sub-bag in the output vector to vary by distance 1. Generalizing this fact shows that the output
vector has the same sensitivity as the input bag does to partition.

5.4 Bag Sum

Our fourth extension, Bag-Sum, works with bags of real-valued data and adds these values up with
clipping. The clipping process truncates a value s such that its magnitude is no larger than bound.
This is important to ensure the output of Bag-Sum has finite sensitivity. Recall that the sensitivity
definition on a bag places no constraints on the distance of values held by the bag. If we naïvely
summed the two bags [1, 2] and [1, 2, 100], although their bag distance is bounded by 1, their sums
have distance 100. Using only the bag distance, the typechecker will have no information on the
sensitivity of the sum. Truncating each value into the range [−bound, bound] allows us to bound

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

18

Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth

Bag-Sum

ϕ = Γ(in)

literal bound
Γout = Γ[out (cid:55)→ ϕ · bound][i, tin (cid:55)→ ∞]

bound ≥ 0

{Γ} bsum(in, out, i, tin, bound) {Γout, 0}

i = 0;
out = 0;
while i < in . length do

tin = in [i ];
if tin < −bound then

out = out - bound ;

else

if tin > bound then

out = out + bound ;

else

out = out + tin ;

end

end
i = i + 1;

end

Fig. 7. Bag-Sum typing rule and expansion

Adv-Comp
Loop body:
{Γ} c {Γ, (ϵ, δ )}
Privacy cost:
(cid:112)
ϵ ∗ = ϵ
δ ∗ = nδ + ω

2n ln(1/ω) + nϵ(eϵ − 1)

Should Not Modify:
i (cid:60) mvs c
Adv-Comp Parameters:
ω > 0
n > 0
literal ω
{Γ} ac(i, n, ω, c) (cid:8)Γ, (ϵ ∗, δ ∗)(cid:9)

literal n

i = 0;
while i < n do

c ;
i = i + 1;

end

Fig. 8. Adv-Comp typing rule and expansion

the total sensitivity of the sum value—if up to ϕ bag items may be added or removed, and each can
contribute up to bound towards the total sensitivity of out, then at the end of the loop, out must be
(ϕ · bound)-sensitive.

5.5 Advanced Composition
Our fifth extension, Adv-Comp, simply expands to a loop that runs the supplied command c for n
times. However, this extension provides a special privacy cost accounting mechanism known as
Advanced Composition [Dwork et al. 2010]. Compared to Simple Composition, Adv-Comp gives an
n), at the cost of a small increase in δ . Simple
asymptotically better ϵ that grows at the rate of O(
composition of loop iterations will give privacy costs that grow at the rate of O(n) instead. The
programmer chooses the increase in δ by providing a positive real number ω, which is used to
compute the aggregated privacy cost for the entire loop.

√

The Adv-Comp extension is useful for programs that iteratively release data, and it also allows
programs to be run for more iterations while staying under the same privacy budget. We use
Adv-Comp in our implementation of logistic regression in Section 7.

It is worth noting that Adv-Comp does not always give a better privacy cost than simple
composition: when the ϵ cost of c is large, the term nϵ(eϵ − 1) becomes the dominating term. This

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

Fuzzi: A Three-Level Logic for Differential Privacy

19

term again grows linearly with n, and it has a multiplicative factor of eϵ − 1. When Adv-Comp
gives worse privacy cost in both ϵ and δ in comparison to simple composition, the type system
falls back to simple composition for the expanded loop for privacy cost accounting.

6 IMPLEMENTATION

Our prototype Fuzzi checker expands extensions before typechecking, leaving hints in the expanded
abstract syntax tree so that it can tell when to apply the macro-typing rules that accompany each
extension. The typechecking algorithm includes three major components: 1) a checker that computes
sensitivity, 2) a checker for termination, and 3) a checker for linear properties of commands.

The implementation uses three separate ASTs types—called Imp, ImpExt, and ImpTC—to represent
a Fuzzi program in different phases of checking. The Imp AST is what the parser produces—i.e., the
constructs of the core language plus extension applications. ImpExt is a convenient language for
entering extension declarations for Fuzzi. Finally, ImpTC represents programs expanded from Imp
—while-language with no extension application nor extension definition, but contains typechecker
hints, and the typechecker expects terms from ImpTC. The ImpTC language is not accepted by
the parser, as we do not anticipate users wanting to enter typechecker hints directly. We use the
extensible sum encoding described in data types à la carte [Swierstra 2008] to represent these ASTs
in order to avoid code duplication. We depend on the compdata package [Bahr and Hvitved 2011]
to manipulate ASTs in this encoding.

The three checkers are implemented separately. A checker composition function takes results

from each checker, and produces the final type information for a Fuzzi program.

To efficiently execute Fuzzi code, we compile Fuzzi programs to Python and use fast numeric

operations from the numpy library [Oliphant 2015] whenever appropriate.

7 EVALUATION

To evaluate Fuzzi’s effectiveness, we implement four differentially private learning algorithms
from four diverse classes of learning methods—discriminative models, ensemble models, generative
models, and instance-based learning. The algorithms and datasets are both taken from canonical
sources. We want to know (1) whether Fuzzi can express these algorithms adequately, (2) whether
the typechecker derives sensitivity bounds comparable to results of a careful manual analysis, and
(3) whether the final privacy costs are within a reasonable range.

We use datasets obtained from the UCI Machine Learning repository [Dheeru and Karra Taniski-
dou 2017] and the MNIST database of handwritten digits [LeCun and Cortes 2010]. We focus on
evaluating Fuzzi’s usability on prototyping differentially private learning tasks in these experiments,
rather than trying to achieve state-of-the-art learning performance.

We find that Fuzzi can indeed express all four examples and that it correctly derives sensitivity
bounds comparable to results from a manual analysis. The examples also demonstrate that the
extensions described in Section 5 are useful for real-world differential privacy programming, since
each of the learning algorithms can be expressed as a straightforward combination of extensions.
On the other hand, the privacy costs that Fuzzi derives are arguably a bit disappointing. One
reason for this is that we ran the experiments on fairly small datasets. A deeper reason is that Fuzzi
focuses on accurate automatic inference of sensitivities, an important building block in differential
privacy. Tracking sensitivities is somewhat orthogonal to the question of how to most tightly
track privacy costs, which is achieved via composition theorems that sit on top of the sensitivity
calculations. Our focus in this work has been mainly on tracking sensitivity; in particular, we
implement only simple composition theorem in the core type system. The result is that Fuzzi
may report a larger privacy cost than is optimal, even when it optimally computes sensitivities.
However, stronger composition theorems can be added as extensions: we give an example of this

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

20

Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth

by demonstrating an “advanced composition” [Dwork et al. 2010] extension in Section 5. We view
adding extensions for more sophisticated methods of tracking privacy costs as future work (see
Section 9 and Section 10).

7.1 Logistic Regression

We first investigate a binary classification problem. The dataset contains 12,665 digits (either 0 or 1)
from the MNIST database. (We only work with 0 and 1 digits because it simplifies our presentation.
A 10-class logistic regression model that classifies all 10 digits can be implemented using the same
methods we show here.) We use 11,665 digits for training and leave 1,000 digits on the side for
evaluation. Each digit is represented by a 28 × 28 grayscale image plus a label indicating whether
it is a 0 or a 1. The image and its label are flattened into a 785-dimensional vector. We then use
gradient descent, a simple and common machine learning technique to train a standard logistic
regression model that classifies these two shapes of digits. We apply differential privacy here to
protect the privacy of each individual image of the digits. In other words, differential privacy limits
an adversary’s ability to tell whether a particular image was used in training the classification
model. In particular, we modify gradient descent with a gradient clipping step to achieve differential
privacy. Gradient clipping is a common technique for implementing differentially private gradient
descent [Abadi et al. 2016; McMahan et al. 2018].

The logistic regression model is parameterized by a vector (cid:174)w of the same dimension as the input
data and a scalar b. A “loss function” L( (cid:174)w, b, (cid:174)xi ) quantifies the mistakes the model makes given a
pair of (cid:174)w and b, and an input image xi . In ordinary (non-private) gradient descent, we compute
the gradients ∂ L
∂ b for each image xi , and we move the current parameters (cid:174)w and b in
the direction of the average of these gradients, decreasing the value of the loss function L (i.e.,
improving the quality of model parameters). To set the initial values of (cid:174)w and b, we take random
samples from a normal distribution centered at 0 and with variance 1.

∂ (cid:174)w and ∂ L

Since the gradients here are computed from private images, the model parameters modified with
these gradients are also sensitive information that cannot be released directly. Instead, we release
noised estimations of the average gradients and use these values to update model parameters. We
apply bmap over the input dataset, computing a bag of both gradients for each image. We then
use bsum and the Laplace mechanism to release the sum of the gradients. We also use the Laplace
mechanism to compute a noised estimate of the size of the dataset, and then update the model
parameter with the noised average gradient. The bsum extension clips each gradient value so that
the final sum has a bounded sensitivity.

We iterate the gradient descent calculation with the ac (advanced composition) extension. With
100 passes over the training set, we reach a training accuracy of 0.933, and test accuracy of 0.84. We
measure accuracy as the fraction of images the trained model correctly classifies. The differentially
private model’s accuracy is comparable to the accuracy of 0.88 for a logistic regression model
without differential privacy [Lecun et al. 1998]. Training the model with 100 passes incurs privacy
cost ϵ = 11.02 and δ = 10−6. Our ϵ privacy cost is larger than the results achieved by Abadi et al.
[2016] (ϵ = 2.55, δ = 10−5) on MNIST, due to our use of a simpler privacy composition theorem;
Abadi et al. invented a specialized “moments accountant” method to derive tighter aggregated
privacy costs given the same sensitivity analysis.

7.2 Teacher Ensemble

Next, we build on the logistic regression from above, together with ideas from Papernot et al. [2016],
to design an ensemble model—a collection of models—that classifies 0 and 1 digits from the MNIST
dataset. Papernot et al. demonstrated a general approach for providing privacy guarantees with

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

Fuzzi: A Three-Level Logic for Differential Privacy

21

respect to the training data: first partition the private training data into k partitions, then apply a
training procedure to each partition to build a private model for it. These k private models form a
Private Aggregation of Teacher Ensembles (PATE). The PATE then predicts labels using differential
privacy for another unlabeled public data set. Since the resulting public dataset and its labels are not
private information, they can be used to train any other model, effectively transferring knowledge
from the PATE to a public model while preserving privacy. Note that we do not require that the
models used internally in creating the PATE to be differentially private: only the aggregation step
(used to predict labels for the public dataset) involves differential privacy.

We split the training input dataset of MNIST digits into a bag of five parts. Using the extension
bmap for each part, we independently train a logistic regression model with non-private gradient
descent. Assuming the input dataset has sensitivity 1, only one part of training data can change.
Fuzzi correctly derives the fact that therefore at most 1 trained logistic regression model will change,
resulting in a bag of model parameters with sensitivity 1.

We use the private ensemble of models to label another 100 test images; with privacy cost
ϵ = 20.0, and δ = 0.0, we are able to reach an accuracy of 0.82. The large ϵ value here is related
to the small size of the training set. To release a public label for a given image, the private scores
are collected from the PATE with bmap and then a noised average of the private scores is released
by bsum with the Laplace mechanism. Since we only have 5 private scores for each image, the
noise variance must be small so as not to destroy the utility of the scores, resulting in big ϵ. To
increase the stability of the released label (and hence decrease the privacy cost) we could increase
the number of models, thus increasing the number of private scores and the scale of the summed
score, thereby allowing more noise added to their average. However, the result would be that each
model would have been trained on correspondingly fewer images, resulting in worse classification
performance on this dataset. On larger datasets, our Fuzzi implementation of PATE would provide
the same level of classification performance with lower ϵ cost.

7.3 Naïve Bayes

We next implement a simple spam detection algorithm using the Spambase dataset from UCI
Machine Learning Repository [Dheeru and Karra Taniskidou 2017]. The binary-labeled dataset
(spam or non-spam) consists of 57 features, mostly of word frequencies for a set of given words,
with additional features describing run lengths of certain sequences. We binarize all features from
the data set to simplify the probability model described below (i.e., instead of how frequently a
word appears on a scale of [0, 100], we only know whether the word was used (1) or not (0)). We can
implement a more sophisticated Gaussian Na¨ve Bayes model that takes advantage of the frequency
data using the same principles as in this experiment, but we chose to simplify the features to present
a simpler model. We use 4500 samples for training and 100 samples for evaluation. Our privacy
goal in this experiment is to limit an adversary’s ability to guess whether a particular document
was used to train the classification model.

A key assumption of the Naïve Bayes model is that given the class y of a data point (cid:174)x, all features
are conditionally independent of each other. This assumption allows us to decompose the joint
probability P((cid:174)x, y) into the product P(y) · Πj P(xj |y), where xj represents the j-th coordinate of
the binary vector (cid:174)x. In our experimental setup, the j-th coordinate of a data point represents
the presence of a word in the document. The goal of the Naïve Bayes model is to estimate the
probabilities of P(y = 1) and P(xj = 1|y = 1) and P(xj = 1|y = 0) given the training data. Thus,
when we get a new document (cid:174)x ′, we can compare the probabilities

P(y = 1)Πj P(xj = x ′

j |y = 1) ≤? P(y = 0)Πj P(xj = x ′

j |y = 0)

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

22

Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth

to make a prediction on whether the document is spam or not (y = 1 or y = 0). Since we have 57
features, this gives us 57 · 2 + 1 = 115 parameters to estimate.

Estimating the parameter P(y = 1) simply involves adding noise to the number of spam docu-
ments in the training set and dividing that count by the noised size of the training data set. We
achieve this by first applying bmap to map each training data point to either 1 or 0 depending on its
label, followed by bsum and Laplace mechanism to get a noised count. We can get a noised size of
the training set through applying Laplace mechanism the training set’s size.

Estimating the parameters P(xj = 1|y = 1) and P(xj = 1|y = 0) follows an essentially identical
procedure. We first apply bmap to each training data point to map them to either 1 or 0 based on the
values of xj and y, followed by a bsum operation to get the value of these conditional counts. We
already computed the noised count of training samples with y = 1 when estimating P(y = 1), but
we perform the same procedure to compute a noised count of y = 0. Dividing the noised conditional
counts by the noised counts of y = 1 and y = 0 gives us the final estimates of the model parameters.
We achieve a training accuracy of 0.70 and test accuracy of 0.69, with privacy costs ϵ = 7.70 and
δ = 0. This classification accuracy is only slightly worse than the accuracy 0.72 of a non-private
Naïve Bayes model that we implemented using binarized features from the same dataset.

7.4 K-Means

Finally, we perform a K-Means clustering experiment to evaluate Fuzzi’s usability for an un-
supervised learning task on the iris dataset from Fisher [1936]. This dataset contains three classes
of iris flowers, with 50 flowers from each class. Each flower comes with four numeric features of
petal and sepal dimensions and a label representing its class. Our experiment randomly selected
one data point from each of the three classes as the initial public centroids; the Fuzzi program uses
partition to map each data point to its closest centroid and create partitions accordingly. Other
than the three data points used to initialize centroids, we used all other data for unsupervised
training. (This experiment assumes a small part—in this case, three data points—of the training
set is given as public information. Past work implementing differentially private K-Means made a
similar assumption [Reed and Pierce 2010].)

On each pass over the training set, we first compute a noised sum of data points within each
partition; we also compute noised sizes of each partition. We use these values to compute each
partition’s average point as the new centroids for the next pass. For evaluation, we classify all
points within a partition with the majority label, and we obtain the accuracy of the clustering with
these classifications. We do not use the labels for unsupervised training.

We found that the performance of the clustering algorithm varies depending on the initial
centroids selected: running the experiment 100 times, all within 5 passes over the data set, we reach
lowest accuracy of 0.55 and highest accuracy of 0.9, with a median accuracy of 0.69. Increasing
the iteration count does not reduce this spread. We implemented a non-private version of the
same algorithm, and achieved lowest accuracy 0.59, highest accuracy 0.96 and median accuracy of
0.59 on 100 experiments. Similar to Naïve Bayes, we see a slight drop in classification accuracy
compared to the non-private implementation.

Each run has privacy cost ϵ = 21.0 and δ = 0.0. The large ϵ cost here is again related to the
small size of the training set. In a small dataset, each data point has a larger impact on the released
centroids; in order to reach a reasonable level of classification accuracy, we chose to apply the
Laplace mechanism with a smaller noise level, resulting in larger ϵ cost.

8 LIMITATIONS

We briefly discuss some limitations and shortcomings of Fuzzi.

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

Fuzzi: A Three-Level Logic for Differential Privacy

23

Limitation of sensitivity. Fuzzi’s type system interface strikes a careful balance between expres-
siveness and complexity. Our approach is sufficient for expressing sensitivities of primitive values
such as int and real and can capture a top-level sensitivity for vectors and bags; however, typing
contexts cannot express sensitivities for individual values within a vector. For example, McSherry
and Mironov developed a differentially private version of the recommender system based on Netflix
user ratings [McSherry and Mironov 2009], where the sensitivity of inputs to the system is defined
by the changes that may happen to a single row within a matrix, rather than the whole matrix.
Fuzzi currently cannot carry out automatic inter-structure sensitivity derivation and cannot provide
automatic differential privacy checking for McSherry and Mironov’s algorithm.

Lack of support for abstraction. Vectors and bags are well studied objects in the differential
privacy literature, and they have first class support in Fuzzi. However, Fuzzi does not provide
facilities to specify general abstract data types and their neighboring relations. Fuzzi must know
how to translate neighboring relation into an apRHL assertion, and this translation is not currently
extensible. This limitation may force programmers to contort their code in order to represent a
high-level concept through arrays. An example algorithm that cannot be adequately expressed in
Fuzzi due to lack of abstraction is the binary mechanism [Chan et al. 2011], which builds a tree of
partial sums of the input data and accumulates a statistic whose sensitivity is proportional to the
depth of the tree.

Potential Vulnerabilities. Fuzzi’s semantics uses real numbers as a model for the type real.
However, the implementation uses floating point numbers. As shown by Mironov [2012], using
the Laplace mechanism in this setting may result in vulnerable distributions that can compromise
the original sensitive data. Although Fuzzi guarantees co-termination over neighboring data, it is
vulnerable to timing channel attacks [Haeberlen et al. 2011]. A Fuzzi program that uses sensitive
loop conditions may result in vastly different execution duration. This side channel allows an
attacker to distinguish runs with high confidence. The first issue can be alleviated by a careful
implementation of Laplace mechanism that incorporates Mironov’s mitigation strategy, while
the second issue is more fundamental—Fuzzi’s type system needs to approximately measure the
execution time, which we did not address in this work.

Performance concern due to copy assignments. Fuzzi uses copy assignments for arrays. We have
worked with relatively small datasets in the experiments, and the sizes of these arrays have not
caused severe performance problems in our experiments. However, today’s machine learning tasks
typically operate on datasets that are many orders of magnitude larger, and Fuzzi likely cannot
handle computations over these datasets efficiently. To adapt Fuzzi’s theory for a semantics that
allows sharing, we need to create a new flavor of apRHL that can reason about heaps. One potential
direction is to integrate separation logic [Reynolds 2002] into apRHL.

9 RELATED WORK

Query languages. McSherry introduced Privacy Integrade Queries (PINQ) as an embedded query
language extension for the C# programming language [McSherry 2009]. PINQ pioneered language-
level support for differential privacy by analyzing sensitivities for SQL-like queries and releasing
noised results of these queries using the Laplace mechanism. Fuzzi’s partition extension takes
inspiration from PINQ’s partition operator, adapting it to an imperative program that computes
over arrays.

The FLEX framework [Johnson et al. 2018] allows programmers to run differentially private
SQL queries against a private database. FLEX uses an elastic sensitivity technique to support SQL
queries with joins based on equality. Fuzzi focuses on adding support of Differential Privacy to a

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

24

Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth

general-purpose imperative language; however, the theory around elastic sensitivities could inspire
future extensions to the Fuzzi type system.

DJoin [Narayan and Haeberlen 2012] runs SQL queries over databases distributed over many
machines. The distributed nature of the data is not just a question of size, but may be due to the
fact that different databases may be owned by different organizations that do not wich to share
them; there simply is no single way to get all the data in the same place. (For example, analysts
may want to correlate travel data with illness diagnosis data, with the former provided by airline
companies while the latter provided by hospitals.) Fuzzi does not address distributed computations:
it runs on a single machine and assumes data is already in the memory of this machine.

Fuzz and related languages. Fuzz is a higher-order functional programming language with a
sensitivity-tracking type system and differentially private primitives [Reed and Pierce 2010]. Fuzzi’s
sensitivity type system is inspired by Fuzz, but differs in that Fuzzi separately tracks the sensitivity
of each value in the store (which may be change as the program assigns to variables), while Fuzz
tracks only function sensitivity. Also, Fuzz’s type system is restricted to (ϵ, 0)-differential privacy,
while Fuzzi generalizes this to (ϵ, δ )-differential privacy.

DFuzz [Gaboardi et al. 2013] extends Fuzz with linear indexed types and dependent types,
allowing programmers to abstract types over sensitivity annotations. Compared to DFuzz, both
Fuzz and Fuzzi only allow purely numeric values as sensitivity annotations in types. This additional
level of expressiveness admits programs whose sensitivities and privacy costs scale with input
sensitivities. Although Fuzzi does not allow such indexed types, the extension mechanism does
allow language developers to add typing rules quantified over unknown constants (such as the
loop count in Adv-Comp for advanced composition); this provides another way for programmers
to write programs whose privacy costs scale with program constants.

AdaptiveFuzz [Winograd-Cort et al. 2017] extends Fuzz by using staged computation and stream
semantics to implement a powerful composition mechanism called Privacy Filters [Rogers et al.
2016]. These give programmers the freedom to run future computations based on results released
from earlier differentially private computations. This allows, for example, programmers to stop a
private gradient descent loop as soon as accuracy reaches a desired threshold, rather than fixing the
number of iterations ahead of time. Fuzzi implements advanced composition for improved privacy
cost aggregation, but privacy filters are not yet formalized in either apRHL or Fuzzi.

Duet [Near et al. 2019] is a higher-order functional language that provides (ϵ, δ )-differential
privacy. Fuzz’s original type system relies on composition properties that break down when
generalized to cases where δ > 0. As an example, an (ϵ, 0)-DP Fuzz function f that takes a 1-
sensitive dataset as input has the property that, when f runs on a 2-sensitive dataset, the privacy
costs scales accordingly to (2ϵ, 0)-DP. However, if f is a general (ϵ, δ )-DP computation on 1-sensitive
datasets, it is not true that running f on a 2-sensitive dataset is (2ϵ, 2δ )-DP. Duet solves this problem
by separating its type system into two disjoint parts: one that keeps track of sensitivities and allows
scaling and another that keeps track of privacy costs and disallows scaling. In Fuzzi, we have
a similar separation: the typing contexts of a command sequence are strict pre-conditions and
post-conditions and do not allow scaling, except for commands typechecked with the linear
typing judgements that explicitly allow scaling of sensitivities in the pre- and post-condition. These
linear commands are deterministic and cannot use the Laplace mechanism by definition, so scaling
their typing judgements’ sensitivities does not bring up the same issues that Fuzz has.

Verification systems. Albarghouthi and Hsu [2017] developed an automated differential privacy
proof synthesis system based on the idea of coupling. Fuzzi and apRHL use the same mathemati-
cal device to simplify relational reasoning between non-deterministic outputs from the Laplace
mechanism.

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

Fuzzi: A Three-Level Logic for Differential Privacy

25

LightDP is an imperative language with semi-automatic typechecking that uses dependent types
to prove differential privacy properties of a program [Zhang and Kifer 2017]. LightDP’s type system
also keeps track of distances of variables between executions on neighboring inputs. A major
difference from Fuzzi is that LightDP’s type system tracks the exact distance between variables
through a dependent type system, while Fuzzi tracks upper bounds on the distance between
variables. LightDP elaborates the source code into a slightly extended language that explicitly keeps
track of privacy costs in a distinguished variable and then uses a MaxSMT solver to discharge the
generated verification conditions in the process of typechecking. Fuzzi typing rules’ soundness
are proven ahead of time, and Fuzzi’s sensitivity checking process does not generate new proof
obligations. Due to this design, Fuzzi does not require a constraint solver to aid in typechecking.
The EasyCrypt toolset allows developers to construct machine-checkable proofs of relational
properties for probabilistic computations [EasyCrypt Development Team 2018]. EasyCrypt has a
development branch that focuses on Differential Privacy verification through apRHL. EasyCrypt
provides built-in support of apRHL proof rules, and also supports termination analysis through a
compatible program logic pHL (Probabilistic Hoare Logic). Fuzzi’s development does not connect
with EasyCrypt’s apRHL implementation, but this is a potential future direction for rigorously
checking Fuzzi’s theories.

Testing Differential Privacy. Ding et al. [2018] developed a statistical testing framework for
detecting violations of differential privacy of Python programs. This framework performs static
analysis on Python code and generates inputs that seem likely to violate differential privacy based
on this analysis. It also repeatedly executes the program to collect statistical evidence of violations
of differential privacy. This framework demonstrates the potential for a lighter-weight approach to
providing differential privacy guarantees; we could potentially apply the same methodology to aid
Fuzzi extension designers by testing typing rules before formally proving their soundness.

High-level frameworks. The PSI private data sharing interface [Gaboardi et al. 2016] is designed
to enable non-expert users and researchers to both safely deposit private data and apply a select set
of differentially private algorithms to collect statistics from the deposited data. Fuzzi, on the other
hand, is designed only for the task of implementing differentially private algorithms. It expects its
users to have some familiarity with key concepts such as sensitivity and privacy budget, and it
allows power users to extend its typechecker for more sophisticated programs.

The ϵKTELLO Framework [Zhang et al. 2018] provides a set of expressive high-level combi-
nators for composing algorithms, with the guarantee that any algorithm composed of ϵKTELLO
combinators automatically satisfies differential privacy. The ϵKTELLO framework allows users to
customize differentially private algorithms in order to achieve higher utility from querying private
data. Fuzzi, by contrast, is an attempt at building a rather low-level core language with support for
Differential Privacy. A future direction could be to build a high-level framework like ϵKTELLO over
Fuzzi, providing both expressive combinators and automatic verification of Differential Privacy for
the implementation of these combinators in the same system.

10 CONCLUSION AND FUTURE WORK

The rise of Differential Privacy calls for reliable, yet familiar tools that help programmers control
privacy risks. Fuzzi gives programmers a standard imperative language with automated privacy
checking, which can be enriched by expert users with extensions whose privacy properties are
proved in a special-purpose relational logic.

Many avenues for improvement still remain. (1) We can enrich the set of Fuzzi extensions to
further increase Fuzzi’s utility. For example, adding Report Noisy Max would allow an analyst
to find the largest value in a vector with small privacy cost; the Exponential mechanism would

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

26

Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth

allow programs to release categorical data (as opposed to numerical) with differential privacy
guarantees [Dwork and Roth 2014]. We expect both mechanisms can be formalized in apRHL [Barthe
et al. 2016] and added to Fuzzi. (2) We can engineer typechecker plugins that dynamically load
new extension typing rules to make Fuzzi’s implementation more flexible. (At the moment, adding
an extension typing rule requires editing the typechecker sources.) (3) We can formalize Privacy
Filters [Rogers et al. 2016] in apRHL and add adaptive composition to Fuzzi. This would allow
programmers to use the adaptive aggregation mechanism from AdaptiveFuzz in Fuzzi. (4) We can
implement Fuzzi as a formalized framework in Coq [Coq Development Team 2018]. This would allow
power users to write machine-checked proofs of extension typing rules. (5) We can incorporate
proof synthesis techniques to automatically search for privacy proofs for extensions, following
Albarghouthi and Hsu [2017], who demonstrated the effectiveness of synthesizing privacy proofs
for interesting differential privacy mechanisms. Proof synthesis could streamline prototyping new
Fuzzi extensions and their typing rules.

11 ACKNOWLEDGMENTS

We are grateful to Justin Hsu, David Darais, and Penn PLClub for their comments, and we thank
the anonymous ICFP reviewers for their detailed and helpful feedback. This work was supported in
part by the National Science Foundation under grants CNS-1065060 and CNS-1513694.

REFERENCES
Martin Abadi, Andy Chu, Ian Goodfellow, H. Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. 2016. Deep
Learning with Differential Privacy. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications
Security (CCS ’16). ACM, New York, NY, USA, 308–318. https://doi.org/10.1145/2976749.2978318

Amal Ahmed. 2006. Step-Indexed Syntactic Logical Relations for Recursive and Quantified Types. In Programming Languages

and Systems, Peter Sestoft (Ed.). Springer Berlin Heidelberg, Berlin, Heidelberg, 69–83.

Aws Albarghouthi and Justin Hsu. 2017. Synthesizing Coupling Proofs of Differential Privacy. Proc. ACM Program. Lang. 2,

POPL, Article 58 (Dec. 2017), 30 pages. https://doi.org/10.1145/3158146

Andrew W. Appel and David McAllester. 2001. An Indexed Model of Recursive Types for Foundational Proof-carrying Code.

ACM Trans. Program. Lang. Syst. 23, 5 (Sept. 2001), 657–683. https://doi.org/10.1145/504709.504712

Andrew W. Appel, Paul-André Melliès, Christopher D. Richards, and Jérôme Vouillon. 2007. A Very Modal Model of a
Modern, Major, General Type System. In Proceedings of the 34th Annual ACM SIGPLAN-SIGACT Symposium on Principles
of Programming Languages (POPL ’07). ACM, New York, NY, USA, 109–122. https://doi.org/10.1145/1190216.1190235
Apple. 2017. Apple Differential Privacy Whitepaper. https://images.apple.com/privacy/docs/Differential_Privacy_Overview.

pdf

Patrick Bahr and Tom Hvitved. 2011. Compositional Data Types. In Proceedings of the Seventh ACM SIGPLAN Workshop on

Generic Programming (WGP ’11). ACM, New York, NY, USA, 83–94. https://doi.org/10.1145/2036918.2036930

Gilles Barthe, Marco Gaboardi, Benjamin Grégoire, Justin Hsu, and Pierre-Yves Strub. 2016. Proving Differential Privacy via
Probabilistic Couplings. In Proceedings of the 31st Annual ACM/IEEE Symposium on Logic in Computer Science (LICS ’16).
ACM, New York, NY, USA, 749–758. https://doi.org/10.1145/2933575.2934554

Nick Benton. 2004. Simple Relational Correctness Proofs for Static Analyses and Program Transformations. In Proceedings
of the 31st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL ’04). ACM, New York, NY,
USA, 14–25. https://doi.org/10.1145/964001.964003

T.-H. Hubert Chan, Elaine Shi, and Dawn Song. 2011. Private and Continual Release of Statistics. ACM Trans. Inf. Syst.

Secur. 14, 3, Article 26 (Nov. 2011), 24 pages. https://doi.org/10.1145/2043621.2043626

Yan Chen and Ashwin Machanavajjhala. 2015. On the Privacy Properties of Variants on the Sparse Vector Technique. CoRR

abs/1508.07306 (2015). arXiv:1508.07306 http://arxiv.org/abs/1508.07306

The Coq Development Team. 2018. The Coq Proof Assistant Reference Manual, version 8.8. http://coq.inria.fr
Dua Dheeru and Efi Karra Taniskidou. 2017. UCI Machine Learning Repository. http://archive.ics.uci.edu/ml
Zeyu Ding, Yuxin Wang, Guanhong Wang, Danfeng Zhang, and Daniel Kifer. 2018. Detecting Violations of Differential
Privacy. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security (CCS ’18). ACM,
New York, NY, USA, 475–489. https://doi.org/10.1145/3243734.3243818

Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. 2006. Calibrating Noise to Sensitivity in Private Data
Analysis. In Proceedings of the Third Conference on Theory of Cryptography (TCC’06). Springer-Verlag, Berlin, Heidelberg,

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

Fuzzi: A Three-Level Logic for Differential Privacy

27

265–284. https://doi.org/10.1007/11681878_14

Cynthia Dwork and Aaron Roth. 2014. The Algorithmic Foundations of Differential Privacy. Found. Trends Theor. Comput.

Sci. 9, 3&#8211;4 (Aug. 2014), 211–407. https://doi.org/10.1561/0400000042

Cynthia Dwork, Guy Rothblum, and Salil Vadhan. 2010. Boosting and Differential Privacy. In Proceedings of the 51st
Annual IEEE Symposium on Foundations of Computer Science (FOCS ‘10). IEEE, IEEE, Las Vegas, NV, 51–60. http:
//dx.doi.org/10.1109/FOCS.2010.12

The EasyCrypt Development Team. 2018. EasyCrypt Reference Manual, version 1.x.

https://www.easycrypt.info/

documentation/refman.pdf

Úlfar Erlingsson, Vasyl Pihur, and Aleksandra Korolova. 2014. RAPPOR: Randomized Aggregatable Privacy-Preserving
Ordinal Response. In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security (CCS
’14). ACM, New York, NY, USA, 1054–1067. https://doi.org/10.1145/2660267.2660348

R. A. Fisher. 1936. The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics 7, 7 (1936), 179–188.
Dan Frumin, Robbert Krebbers, and Lars Birkedal. 2018. ReLoC: A Mechanised Relational Logic for Fine-Grained Concurrency.
In Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science (LICS ’18). ACM, New York, NY,
USA, 442–451. https://doi.org/10.1145/3209108.3209174

Marco Gaboardi, Andreas Haeberlen, Justin Hsu, Arjun Narayan, and Benjamin C. Pierce. 2013. Linear Dependent Types for
Differential Privacy. In Proceedings of the 40th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming
Languages (POPL ’13). ACM, New York, NY, USA, 357–370. https://doi.org/10.1145/2429069.2429113

Marco Gaboardi, James Honaker, Gary King, Kobbi Nissim, Jonathan Ullman, and Salil P. Vadhan. 2016. PSI (Ψ): a Private

data Sharing Interface. CoRR abs/1609.04340 (2016). arXiv:1609.04340 http://arxiv.org/abs/1609.04340

Andreas Haeberlen, Benjamin C. Pierce, and Arjun Narayan. 2011. Differential Privacy Under Fire. In Proceedings of the 20th
USENIX Conference on Security (SEC’11). USENIX Association, Berkeley, CA, USA, 33–33. http://dl.acm.org/citation.cfm?
id=2028067.2028100

C. A. R. Hoare. 1969. An Axiomatic Basis for Computer Programming. Commun. ACM 12, 10 (Oct. 1969), 576–580.

https://doi.org/10.1145/363235.363259

Justin Hsu. 2017. Probabilistic Couplings for Probabilistic Reasoning. CoRR abs/1710.09951 (2017). arXiv:1710.09951

http://arxiv.org/abs/1710.09951

Justin Hsu. 2018. Private Communication.
Noah Johnson, Joseph P. Near, and Dawn Song. 2018. Towards Practical Differential Privacy for SQL Queries. Proc. VLDB

Endow. 11, 5 (Jan. 2018), 526–539. https://doi.org/10.1145/3187009.3177733

Ralf Jung, Jacques-Henri Jourdan, Robbert Krebbers, and Derek Dreyer. 2017. RustBelt: Securing the Foundations of the
Rust Programming Language. Proc. ACM Program. Lang. 2, POPL, Article 66 (Dec. 2017), 34 pages. https://doi.org/10.
1145/3158154

Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner. 1998. Gradient-based learning applied to document recognition. Proc. IEEE 86,

11 (Nov 1998), 2278–2324. https://doi.org/10.1109/5.726791

Yann LeCun and Corinna Cortes. 2010. MNIST handwritten digit database. http://yann.lecun.com/exdb/mnist/. (2010).

http://yann.lecun.com/exdb/mnist/

Min Lyu, Dong Su, and Ninghui Li. 2016. Understanding the Sparse Vector Technique for Differential Privacy. CoRR

abs/1603.01699 (2016). arXiv:1603.01699 http://arxiv.org/abs/1603.01699

H. Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li Zhang. 2018. Learning Differentially Private Recurrent
Language Models. In International Conference on Learning Representations. https://openreview.net/forum?id=BJ0hF1Z0b
Frank McSherry and Ilya Mironov. 2009. Differentially Private Recommender Systems: Building Privacy into the Netflix
Prize Contenders. In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data
Mining (KDD ’09). ACM, New York, NY, USA, 627–636. https://doi.org/10.1145/1557019.1557090

Frank D. McSherry. 2009. Privacy Integrated Queries: An Extensible Platform for Privacy-preserving Data Analysis. In
Proceedings of the 2009 ACM SIGMOD International Conference on Management of Data (SIGMOD ’09). ACM, New York,
NY, USA, 19–30. https://doi.org/10.1145/1559845.1559850
Collecting telemetry data privately.

https://www.microsoft.com/en-us/research/blog/

Microsoft. 2017.

collecting-telemetry-data-privately/

Ilya Mironov. 2012. On Significance of the Least Significant Bits for Differential Privacy. In Proceedings of the 2012
ACM Conference on Computer and Communications Security (CCS ’12). ACM, New York, NY, USA, 650–661. https:
//doi.org/10.1145/2382196.2382264

Aref N. Dajani, Amy D. Lauger, Phyllis E. Singer, Daniel Kifer, Jerome P. Reiter, Ashwin Machanavajjhala, Simson L. Garfinkel,
Scot A. Dahl, Matthew Graham, Vishesh Karwa, Hang Kim, Philip Leclerc, Ian M. Schmutte, William N. Sexton, Lars
Villhuber, and John M. Abowd. 2017. The modernization of statistical disclosure limitation at the U.S. Census Bureau.
(September 2017). https://www2.census.gov/cac/sac/meetings/2017-09/statistical-disclosure-limitation.pdf [Online;
posted September-2017].

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

28

Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth

bind :: ⃝ A → (A → ⃝ B) → ⃝ B
ret :: A → ⃝ A

Fig. 9. Operations over the distribution monad

Arjun Narayan and Andreas Haeberlen. 2012. DJoin: Differentially Private Join Queries over Distributed Databases.
In Proceedings of the 10th USENIX Conference on Operating Systems Design and Implementation (OSDI’12). USENIX
Association, Berkeley, CA, USA, 149–162. http://dl.acm.org/citation.cfm?id=2387880.2387895

Joseph P. Near, David Darais, Tim Stevens, Paranav Gaddamadugu, Lun Wang, Neel Somani, Mu Zhang, Nikhil Sharma,

Alex Shan, and Dawn Song. 2019. (2019). http://david.darais.com/assets/papers/duet/duet.pdf

Travis E. Oliphant. 2015. Guide to NumPy (2nd ed.). CreateSpace Independent Publishing Platform, USA.
Nicolas Papernot, MartÃŋn Abadi, ÃŽlfar Erlingsson, Ian Goodfellow, and Kunal Talwar. 2016. Semi-supervised Knowledge
Transfer for Deep Learning from Private Training Data. arXiv:1610.05755 [cs, stat] (Oct. 2016). http://arxiv.org/abs/1610.
05755 arXiv: 1610.05755.

Jason Reed and Benjamin C. Pierce. 2010. Distance Makes the Types Grow Stronger: A Calculus for Differential Privacy.

SIGPLAN Not. 45, 9 (Sept. 2010), 157–168. https://doi.org/10.1145/1932681.1863568

John C. Reynolds. 2002. Separation Logic: A Logic for Shared Mutable Data Structures. In Proceedings of the 17th Annual
IEEE Symposium on Logic in Computer Science (LICS ’02). IEEE Computer Society, Washington, DC, USA, 55–74. http:
//dl.acm.org/citation.cfm?id=645683.664578

Ryan M Rogers, Aaron Roth, Jonathan Ullman, and Salil Vadhan. 2016.

you-Go Composition.
Luxburg, I. Guyon, and R. Garnett (Eds.). Curran Associates, Inc., 1921–1929.
6170-privacy-odometers-and-filters-pay-as-you-go-composition.pdf

Privacy Odometers and Filters: Pay-as-
In Advances in Neural Information Processing Systems 29, D. D. Lee, M. Sugiyama, U. V.
http://papers.nips.cc/paper/

Tetsuya Sato. 2016. Approximate Relational Hoare Logic for Continuous Random Samplings. Electronic Notes in Theoretical
Computer Science 325 (2016), 277 – 298. https://doi.org/10.1016/j.entcs.2016.09.043 The Thirty-second Conference on the
Mathematical Foundations of Programming Semantics (MFPS XXXII).

Tetsuya Sato, Gilles Barthe, Marco Gaboardi, Justin Hsu, and Shin-ya Katsumata. 2019. Approximate Span Liftings. CoRR

abs/1710.09010 (2019). arXiv:1710.09010 http://arxiv.org/abs/1710.09010

Wouter Swierstra. 2008. Data Types à La Carte. J. Funct. Program. 18, 4 (July 2008), 423–436. https://doi.org/10.1017/

S0956796808006758

Daniel Winograd-Cort, Andreas Haeberlen, Aaron Roth, and Benjamin C. Pierce. 2017. A Framework for Adaptive Differential

Privacy. Proc. ACM Program. Lang. 1, ICFP, Article 10 (Aug. 2017), 29 pages. https://doi.org/10.1145/3110254

Danfeng Zhang and Daniel Kifer. 2017. LightDP: Towards Automating Differential Privacy Proofs. SIGPLAN Not. 52, 1 (Jan.

2017), 888–901. https://doi.org/10.1145/3093333.3009884

Dan Zhang, Ryan McKenna, Ios Kotsogiannis, Michael Hay, Ashwin Machanavajjhala, and Gerome Miklau. 2018. Ektelo: A

Framework for Defining Differentially-Private Computations. In SIGMOD Conference.

A SEMANTICS

Fuzzi’s semantics directly follows from the work of Barthe et al. [2016], but we extend the language
with operations over vectors and bags (Figure 10). Due to the possibility of out-of-bounds indexing,
Fuzzi’s semantics for expression accounts for partiality by modeling expressions with partial
functions. We use a list structure to model arrays in Fuzzi. The function length v returns the
length of the list v. The function resize len v updates the list v such that it has length equal to len
and pads the list with well-shaped default values if necessary. The function update b i v returns
another list whose i-th element is set to b, or ⊥ if i is out of bounds. We elide an implicit coercion
from ⊥ to the special distribution distr0. The distribution distr0 is the empty distribution; it is
used to model non-termination.

The semantics of Fuzzi commands are given as probabilistic functions from program states
to sub-distributions over program states. We write ⃝ A for the set of sub-distributions over A.
Sub-distributions forms a monad with two operators ret and bind (Figure 9). The ret operator
takes a value and produces a distribution whose entire mass is concentrated on that single value;

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

Fuzzi: A Three-Level Logic for Differential Privacy

29

[[x = e]] =

λM.let v = [[e]] M in ret(M[x (cid:55)→ v])

[[x[i] = e]] =

λM.let v = [[e]] M in

let idx = [[i]] M in
ret(M[x (cid:55)→ update v idx M(x)])

[[x .lenдth = e]] =

λM.let len = [[e]] M in

ret(M[x (cid:55)→ resize len M(x)])

[[if e then c1 else c2 end]] =
λM.let cond = [[e]] M in

if cond then [[c1]] M else [[c2]] M

[[while e do c end]]n
λ M.if n ≤ 0

=

then distr0
else if [[e]] M
then bind ([[c]] M) ([[while e do c end]]n−1)
else ret M
[[while e do c end]] = (cid:195)

n [[while e do c end]]n

Fig. 10. Semantics of Fuzzi

the bind operator builds conditional distributions through compositions between distributions and
functions from samples to distributions.

B PROOF RULES FOR APRHL

Reasoning about programs that implement differentially private mechanisms involves both rela-
tional and probablistic reasoning. The authors of apRHL combined ingredients from program logic
and probability theory to create a proof system that manages the complexity of such proofs. The
union of two key ingredients— relational Hoare logic and approximate liftings—results in a proof
system that is very well suited for differential privacy proofs.

Benton [2004] established relational Hoare logic (RHL). RHL provides a system for writing down
proofs of properties between two executions of deterministic while-programs. This proof system
would allow us to embed a type system that tracked sensitivity (but not privacy costs) for the
deterministic fragment of Fuzzi; however, RHL lacks the reasoning facility for distributions.

Distributions over program states have complicated structures that arise from branches and
loops; proofs that directly manipulated these distributions may get unwieldy due to the complexity
of these distributions’ structures. Fortunately, apRHL applies “approximate liftings” to significantly
simplify such proofs over distributions.

An approximate lifting is characterized by a relation R between two distributions’ support: given
µA a distribution in ⃝ A and µB in ⃝ B, the relation R is a subset of A × B. This approximate lifting
based on R allows us to only consider elements linked by R while proving relational properties on
µA and µB , and apRHL applies this abstraction to simplify proofs of probabilistic programs.

An apRHL judgment has the form ⊢ c1 ∼(ϵ,δ ) c2 : Φ ⇒ Ψ. The assertions Φ and Ψ are relations
over program states. The pre-condition Φ is a deterministic relation that the input program states
to c1 and c2 satisfies. Since c1 and c2 are probabilistic programs, the output program states after
running c1 and c2 are distributions of program states, and the post-condition is used to construct an
approximate lifting between the two output program state distributions. The validity of an apRHL
judgment implies a valid approximate lifting of the post-condition Ψ over [[c1]]M1 and [[c2]]M2. The

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

30

Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth

Fig. 11. Approximate lifting of R between two Laplace distributions

relations Φ and Ψ may describe properties as x ⟨1⟩ = x ⟨2⟩—the value held in x is the same in both
executions.

An approximate lifting of R ⊆ A1 × A2 that relates two distributions µ1 : ⃝ A1 and µ2 : ⃝ A2 is
justified by two witness distributions and two cost parameters (ϵ, δ ). Let ⋆ be a distinct element
not in A1 ∪ A2, and write the extended relation R⋆ = R ∪ A1 × {⋆} ∪ {⋆} × A2. Let A⋆
2 be
A1 and A2 extended with ⋆, respectively. We define the ϵ-distance between µL and µR as following:

1 and A⋆

dϵ (µL, µR ) = max
S ⊆A⋆

1 ×A⋆
2

(µL(S) − exp(ϵ) · µR (S))

Then the two witness distributions µL and µR should satisfy the following properties [Hsu 2017]:

supp(µL) ∪ supp(µR ) ⊆ R⋆

1. π1(µL) = µ1 and π2(µR ) = µ2 Marginal
Support
2.
3. dϵ (µL, µR ) ≤ δ
Distance
In the Marginal condition, π1 and π2 are first and second projections of distributions that
2 , this condition requires the

produces the first and second marginal distributions on A⋆
witnesses to “cover” the original µ1 and µ2 on their respective projections.

1 × A⋆

The Support condition requires support of both witnesses to reside within the relation R⋆.
The Distance condition gives bounds on the exp(ϵ) multiplicative difference and the δ additive
difference between these two witness distributions, and this distance definition matches up with
the definition of privacy costs used in differential privacy.

We can gain some intuition of approximate liftings from Figure 11. Here we visualize an approxi-
mate lifting of the equality relation over two Laplace distributions. The validity of the approximate
lifting gives a global bound on the difference in probability of the linked elements in this plot, and
this bound can be naturally interpreted as privacy costs for differential privacy.

The proof rules from apRHL constructs these witness distributions for probabilistic imperative
programs. In particular, the Seq rule allows us to treat the approximate lifting of a post-condition
as the pre-condition of the next command. The resulting proof system effectively abstracts away
explicit reasoning of distributions. The relational assertions of apRHL allows us to naturally
express predicates over pairs of program states, and approximate liftings cleverly hides much of
the plumbing for probabilistic reasoning. We have listed a subset of apRHL proof rules used in the
development of Fuzzi in Figure 12 and Figure 13.

The structural apRHL proof rules relate programs that are structurally similar: assignments are
related with assignments, conditionals are related with conditionals by relating their corresponding

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

Fuzzi: A Three-Level Logic for Differential Privacy

31

true and false branches, and loops are related by synchronizing their loop bodies. Among the
structural rules, the Lap rule formalizes the Laplace mechanism—the pre-condition states that a
value to be released has sensitivity k, and releasing this private value with noise scaled with 1/ϵ is
(kϵ, 0)-DP.

An important quirk of apRHL is that it does not have a conjunction rule like this:

⊢ c1 ∼(ϵ,δ ) c2 : Φ ⇒ Ψ
⊢ c1 ∼(ϵ,δ ) c2 : Φ ⇒ Θ
⊢ c1 ∼(ϵ,δ ) c2 : Φ ⇒ Ψ ∧ Θ
Since an apRHL judgement is justified by the existence of witness distributions for the approximate
lifting of the post-condition, the two judgements above the inference bar tells us there exists
witnesses separately justifying the approximate liftings of Ψ and Θ. However, this does not guarantee
the existence of an approximate lifting for their conjunction. Thus, this rule is not valid. However,
apRHL does have a Frame rule, which allows us to conjunct Θ with the pre- and post-conditions,
as long as Θ does not mention any modified variables of the two related programs.

Sometimes structural apRHL rules are not enough, since sensitive values may steer program
control flow towards different sequences of code. The authors of apRHL account for reasoning of
these programs through one-sided proof rules, as shown in Figure 13.

The rules While-L and While-R deserve some special attention: it allows us to relate a while loop
with the skip command using a one-sided loop invariant. This allows us to carry out standard Floyd-
Hoare logic reasoning on a single while loop. We will use these one-sided loop rules extensively
later in the proof of extension typing rules. These one-sided loop rules require a side-condition of
lossless-ness for the loop body—a program c is lossless if executing c results in a proper distribution,
i.e., the probability distribution sums up to 1. Although apRHL gives the definition of lossless, it does
not provide proof rules for lossless-ness. In the development of Fuzzi, we developed a termination
type system compatible with this definition of lossless. Details can be found in Appendix C.

C RULES FOR term AND linear
C.1 Justifying term rules
In Section 5, we defined two auxiliary properties of Fuzzi programs—term and linear—in order to
typecheck various extensions. The typing rules for these auxillary properties share a similar design
as the typing rules for sensitivity—we give the definition of each auxillary property in the base
logic L and give the typing rules as theorems to be justified in L. However, for expressions, we
again use inductive relations instead of foundational definition since we do not plan on extending
the rules for expressions.

Definition 7. The well-shaped judgment M ∈ shape(Γ) for memories is defined as: for any x ∈σ τ

in Γ, there exists some v, such that M(x) = v and v ∈ τ .

Lemma 4 (Termination for expressions). For an expression e, given the termination judgment

Γ ⊢ e term, then for any program state M ∈ shape(Γ), evaluating [[e]] M results in some value v.

Definition 8 (Termination for commands). For a command c, the judgment Γ ⊢ c term is
defined as: given any program state M ∈ shape(Γ), evaluating [[c]] M results in a proper distribution.

In order to prove the soundness of termination rules for commands, we need a lemma of the

“preservation” property for well-shaped commands.

Lemma 5 (Preservation). If M ∈ shape(Γ) and c is well-shaped according to Γ, then for any

M ′ ∈ supp([[c]] M), the program state M ′ ∈ shape(Γ).

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

32

Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth

Skip

Assn

⊢ skip ∼(0,0) skip : Φ ⇒ Φ

⊢ x1⟨1⟩ = e1⟨1⟩ ∼(0,0) x2⟨2⟩ = e2⟨2⟩ : Φ[e1⟨1⟩, e2⟨2⟩/x1⟨1⟩, x2⟨2⟩] ⇒ Φ

Lap

Φ ≜ |e1⟨1⟩ − e2⟨2⟩| ≤ k
⊢ x1⟨1⟩ = L1/ϵ (e1⟨1⟩) ∼(kϵ,0) x2⟨2⟩ = L1/ϵ (e2⟨2⟩) : Φ ⇒ x ⟨1⟩ = x ⟨2⟩

Seq
⊢ c1 ∼(ϵ,δ ) c2 : Φ ⇒ Ψ ⊢ c ′

⊢ c1; c ′

1 ∼(ϵ +ϵ ′,δ +δ ′) c2; c ′

1 ∼(ϵ ′,δ ′) c ′
2 : Φ ⇒ Θ

2 : Ψ ⇒ Θ

Cond

⊨ Φ ⇒ e1⟨1⟩ = e2⟨2⟩
⊢ c1 ∼(ϵ,δ ) c2 : Φ ∧ e1⟨1⟩ ⇒ Ψ
⊢ c ′
2 : Φ ∧ ¬e1⟨1⟩ ⇒ Ψ
⊢ if e1 then c1 else c ′

1 ∼(ϵ,δ ) c ′
1 end ∼(ϵ,δ ) if e2 then c2 else c ′

2 end : Φ ⇒ Ψ

While*

⊨ Φ ⇒ e1⟨1⟩ = e2⟨2⟩
⊢ c1 ∼(0,0) c2 : Φ ∧ e1⟨1⟩ ⇒ Φ
⊢ while e1 do c1 end ∼(0,0) while e2 do c2 end : Φ ⇒ Φ ∧ ¬e1⟨1⟩

Conseq

⊨ Φ ⇒ Φ′

⊢ c1 ∼(ϵ ′,δ ′) c2 : Φ′ ⇒ Ψ′
⊨ Ψ′ ⇒ Ψ ⊨ ϵ ′ ≤ ϵ
⊢ c1 ∼(ϵ,δ ) c2 : Φ ⇒ Ψ

⊨ δ ′ ≤ δ

Eqiv
⊢ c ′

1 ∼(ϵ,δ ) c ′

2 : Φ ⇒ Ψ c1 ≡ c ′
1
⊢ c1 ∼(ϵ,δ ) c2 : Φ ⇒ Ψ

c2 ≡ c ′
2

Frame
⊢ c1 ∼(ϵ,δ ) c2 : Φ ⇒ Ψ fvs Θ ∩ mvs (c1, c2) = ∅
⊢ c1 ∼(ϵ,δ ) c2 : Φ ∧ Θ ⇒ Ψ ∧ Θ

Fig. 12. Proof rules for apRHL (Structural Rules)

Lemma 5 tells us that well-shaped commands do not change the data type of variables. In the
sequence case, we know that both commands c1 and c2 terminates if executed under program states
in shape(Γ). With the preservation property, we know all variables in the resulting program state
after c1 still have the same data type, so executing c2 in the resulting program state still terminates.
For extensions, if the extension takes a command as an argument, then the termination of the
expanded program certainly relies on the termination of the argument. In the case of bag map and
vector map, the while loop executes the supplied map body c for a finite number of iterations—the
length of the input bag or vector. Array accesses within the while loops are safe because the index
is bounded by the array length. So, requiring c to terminate makes the entire loop terminate.

For partition, the first while loop terminates because it’s bounded by the value of the supplied
nParts expression. The following bag map terminates due to the same arguments as above. The
next while loop also terminates, because the loop is bounded by the number of entries in outidx,
and the index variable i is in range; the modification to tpart also uses an index expression that’s in
range.

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

Fuzzi: A Three-Level Logic for Differential Privacy

33

While-L

⊢ c1 ∼(0,0) skip : Φ ∧ e1⟨1⟩ ⇒ Φ
⊨ Φ ⇒ Φ1⟨1⟩ Φ1⟨1⟩ ⊨ while e1 do c1 end lossless
⊢ while e1 do c1 end ∼(0,0) skip : Φ ⇒ Φ ∧ ¬e1⟨1⟩

While-R

⊢ skip ∼(0,0) c2 : Φ ∧ e2⟨2⟩ ⇒ Φ
⊨ Φ ⇒ Φ2⟨2⟩ Φ2⟨2⟩ ⊨ while e2 do c2 end lossless
⊢ skip ∼(0,0) while e2 do c2 end : Φ ⇒ Φ ∧ ¬e2⟨2⟩

Assn-L

⊢ x1 = e1 ∼(0,0) skip : Φ[e1⟨1⟩/x1⟨1⟩] ⇒ Φ

Assn-R

⊢ skip ∼(0,0) x2 = e2 : Φ[e2⟨2⟩/x2⟨2⟩] ⇒ Φ

Cond-L
⊢ c1 ∼(ϵ,δ ) c : Φ ∧ e1⟨1⟩ ⇒ Ψ

⊢ c ′

1 ∼(ϵ,δ ) c : Φ ∧ ¬e1⟨1⟩ ⇒ Ψ

⊢ if e1 then c1 else c ′

1 end ∼(ϵ,δ ) c : Φ ⇒ Ψ

Cond-R
⊢ c ∼(ϵ,δ ) c2 : Φ ∧ e2⟨2⟩ ⇒ Ψ

⊢ c ∼(ϵ,δ ) c ′

2 : Φ ∧ ¬e2⟨2⟩ ⇒ Ψ

⊢ c ∼(ϵ,δ ) if e2 then c2 else c ′

2 end : Φ ⇒ Ψ

Fig. 13. Proof rules for apRHL (One-sided Rules)

x ∈ Γ
Γ ⊢ x term

lit ∈ int ∨ lit ∈ real ∨ lit ∈ bool
Γ ⊢ lit term

Γ ⊢ e1 term

Γ ⊢ e2 term

Γ ⊢ e1 op e2 term

Γ ⊢ e term
Γ ⊢ e.length term

Γ ⊢ skip term

Γ ⊢ e term
Γ ⊢ x = e term

Γ ⊢ c1 term

Γ ⊢ c2 term

Γ ⊢ c1; c2 term

Γ ⊢ e term

Γ ⊢ c1 term
Γ ⊢ if e then c1 else c2 end term

Γ ⊢ c2 term

Γ ⊢ c term
Γ ⊢ bmap(in, out, tin, i, tout, c) term

Γ ⊢ c term
Γ ⊢ vmap(in, out, tin, i, tout, c) term

Γ ⊢ c term

Γ ⊢ nParts term

Γ ⊢ partition(in, out, tin, i, tout, tidx, outidx, tpart, nParts, c) term

Γ ⊢ bsum(in, out, i, tin, bound) term

Fig. 14. Rules for term

The bag sum extension terminates since its loop is bounded by the input bag’s size, and the index

variable i is in range when accessing in.

C.2 Justifying linear rules
We will discuss the first 4 linear rules here and delay the linear rules for extensions to Appendix D.1
because the linear property of extensions are intimately tied to the proof of their sensitivity
properties.

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

34

Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth

{Γ} skip {Γ, (0, 0)} linear

Γ ⊢ e ∈σ τ
{Γ} x = e {Γ[x (cid:55)→ σ ], (0, 0)} linear

{Γ1} c1 {Γ2, (0, 0)} linear

{Γ2} c2 {Γ3, (0, 0)} linear

{Γ1} c1; c2 {Γ3, (0, 0)} linear

{Γ} c1 {Γ1, (0, 0)} linear

{Γ} c2 {Γ2, (0, 0)} linear

Γ ⊢ e ∈0 bool

{Γ} if e then c1 else c2 end {max(Γ1, Γ2), (0, 0)} linear

Termination, Deterministic:
Γ ⊢ c term
Should Not Modify:

determ c

tin, in, out, i (cid:60) mvs c

Abbreviation:
σ = [mvs c, i, in, out (cid:55)→ ∞]
σ ′ = [mvs c, i, tin, tout (cid:55)→ ∞]

Dependency:
{stretch Γ[tin (cid:55)→ 0]σ } c {Γ1, (0, 0)}
{stretch Γ[tin (cid:55)→ ∞]σ } c {Γ2, (0, 0)}
Γ1(tout ) = 0
{x | x ∈ mvs c ∧ Γ2(x) > 0} ⊆ {tout }
Output Sensitivity:

Γ1(tout ) = 0

Γout = Γ[out (cid:55)→ Γ(in)]σ ′

Termination, Deterministic:
Γ ⊢ c term
Should Not Modify:

determ c

tin, in, out, i (cid:60) mvs c

Abbreviation:
σ = [mvs c, i, in, out (cid:55)→ ∞]
σ ′ = [mvs c, i, tin, tout (cid:55)→ ∞]

Dependency:
{stretch Γ[tin (cid:55)→ 0]σ } c {Γ1, (0, 0)}
{stretch Γ[tin (cid:55)→ ∞]σ } c {Γ2, (0, 0)}
Γ1(tout ) = 0
{x |x ∈ mvs c ∧ Γ2(x) > 0} ⊆ {tout }
Linear:
{Γ[tin (cid:55)→ 1]σ } c {Γ3, (0, 0)} linear
Output Sensitivity:

Γout = Γ[out (cid:55)→ Γ(in) · Γ3(tout )]σ ′

{Γ} bmap(in, out, tin, i, tout, c) {Γout, (0, 0)} linear

{Γ} vmap(in, out, tin, i, tout, c) {Γout, (0, 0)} linear

Fig. 15. Rules for linear (Part 1)

Recall Definition 6: a deterministic and terminating command c is linear with respect to Γ1 and

Γ2, if for any k ≥ 0, the scaled typing judgment {kΓ1} c {kΓ2, (0, 0)} is true.

The rule for skip is true because for any fixed k, we can show {kΓ} skip {kΓ, (0, 0)} by reusing

the core typing rule for skip.

For assignment, we first prove a lemma that shows the typing relation on expressions is linear.

Lemma 6. Given Γ ⊢ e ∈σ τ and any k > 0, the judgment kΓ ⊢ e ∈k σ τ is also true.

Now, if we scale the pre-condition Γ by k, we know e has sensitivity kσ under kΓ. Applying the

core assignment rule concludes the proof.

For sequence of commands, since the two commands to be sequenced together are linear with
Γ1, Γ2 and Γ2, Γ3 respectively. We know that for any k > 0 we pick, the typing judgments {kΓ1}
c {kΓ2, (0, 0)} and {kΓ2} c {kΓ3, (0, 0)} hold. Now, applying the core sequence rule concludes the
proof.

In the case of conditional commands, we need another lemma that allows us to change the

post-condition in a linear typing judgment.

Lemma 7. Given {Γ1} c {Γ2, (0, 0)} linear and Γ2 ≤ Γ3, then {Γ1} c {Γ3, (0, 0)} linear also holds.

Proof. We need to show that for any k > 0, the typing judgement {kΓ1} c {kΓ3, (0, 0)} is true.

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

Fuzzi: A Three-Level Logic for Differential Privacy

35

Termination, Deterministic:
Γ ⊢ c term determ c
Should Not Modify:

tin, in, out, i, outidx (cid:60) mvs c

Abbreviation:

σ = [mvs c, i, in, outidx (cid:55)→ ∞]
σ ′ = [mvs c, i, tin, tidx, outidx, tpart (cid:55)→ ∞]

Number of Partitions Non-Sensitive:
Γ ⊢ nParts ∈0 int
fvs nParts ∩ mvs c = ∅
i, tin, tidx, outidx, tpart (cid:60) fvs nParts

Dependency:
{stretch Γ[tin (cid:55)→ 0]σ } c {Γ1, 0}
{stretch Γ[tin (cid:55)→ ∞]σ } c {Γ2, 0}
Γ1(tout ) = 0
{x |x ∈ mvs c ∧ Γ2(x) > 0} ⊆ {tout }
Output Sensitivity:

Γout = Γ[out (cid:55)→ Γ(in)]σ ′

{Γ} partition(in, out, tin, i, tout, tidx, outidx, tpart, nParts, c) {Γout, (0, 0)} linear

literal bound
bound ≥ 0

Γout = Γ[out (cid:55)→ ϕ · bound][i, tin (cid:55)→ ∞]

ϕ = Γ(in)

{Γ} bsum(in, out, i, tin, bound) {Γout, (0, 0)}

Fig. 16. Rules for linear (Part 2)

From the premise, we know that {kΓ1} c {kΓ2, (0, 0)} is true. Since Γ2 ≤ Γ3, scaling both by
k preserves the pointwise order kΓ2 ≤ kΓ3. We are only weakening the post-condition here, so
□
applying the Conseq rule from apRHL concludes this proof.

Using Lemma 7, we know both branches are linear with respect to Γ and max(Γ1, Γ2). Then, since

e is 0-sensitive under Γ, this allows us to apply the Cond rule from apRHL concludes this case.

D SOUNDNESS PROOFS FOR EXTENSIONS

D.1 Bag-Map

To prove Bag-Map’s typing rule is sound, we need to show the apRHL judgement corresponding
to the conclusion is true. This apRHL judgement relates two instances of the bag map program

bmap(in, out, tin, i, tout , c) ∼ bmap(in, out, tin, i, tout , c)

Our general strategy for proving the soundness of these extensions is to first prove some specifica-
tion f in the logic L specifies the computation of the expanded extension code and then separately
reason about the sensitivity of the output from the specification f .

Our first step is to apply the Eqiv rule and rewrite the pair of related programs with an extra

skip:

bmap(in, out, tin, i, tout , c); skip ∼ skip; bmap(in, out, tin, i, tout , c)
And apply Seq followed by While-L and While-R rule to perform one-sided reasoning. Since the
two one-sided cases are symmetric, we only discuss the case for bmap(in, out, tin, i, tout , c) ∼ skip.

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

36

Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth

Since our goal is to give a specification of bag map, a natural choice would be to model bag map
with the map operator over lists, which applies a function over each value in a bag and returns a
new bag. However, we need to find a function f that adequately describes the semantics of c as an
argument to map.

We know, from the typing rule of bmap, that c is a deterministic and terminating command. Here,
we state an important lemma about deterministic and terminating commands that will help us find
such a function f .

Lemma 8 (Semantics of Deterministic Terminating Programs). Given determ c and Γ ⊢
c term, then there exists a total function f[[c]] : M → M such that [[c]]M = ret (f[[c]] M) for any
program state M in shape(Γ).

From Lemma 8, we know that the semantics of c can be described by a total function f[[c]] mapping
program states to program states. However, the dependency analysis we performed reveals more
about f[[c]]. First, consider an arbitrary iteration in the bag map loop; let’s divide the program state
right before executing c into 4 parts: 1) the value of tin, 2) the values of all modified variables in c,
3) the values of all other non-sensitive variables, and 4) the values of all other sensitive variables.
From the dependency analysis, we know c’s modified variables have no dependency on 2) and 4).
The variables that hold values from 3) are not modified, so their values remain constant throughout
the entire loop, and are also the same in both executions. Using this information, we can build a
function f[[c]]spec that takes the value of tin as the sole input, but calculates the same program state
as f[[c]]: let v be the input to f[[c]]spec , we first create a fictitious program state M ′ by instantiating
variables of 1), 2), and 4) in M ′ with well-shaped default values, and copying 3) from M into M ′.
Now, by feeding M ′[tin (cid:55)→ v] to f[[c]], and accessing its value at tout, we get what c would have
computed for tout.

Knowing these properties of f[[c]]spec , we can choose the one-sided invariant as:

out[0 . . . i] = map f[[c]]spec in[0 . . . i]

where f[[c]]spec v = f[[c]]M ′[tin (cid:55)→ v].

The notation v[i . . . j] selects a sub-array from v in the range [i, j); if j ≤ i, the it selects an empty
sub-array. Thus, at the end of both execution of bag map with c, we know the output bags are
computed by mapping the semantic function of c over the values of the input array.

Having established this specification of bag map, we now need to consider its sensitivity proper-

ties. We can prove the following lemma for map:

Lemma 9. For any function f : τ → σ , and two input lists x1 and x2, if the bag distance between x1

and x2 is d, then the values of map f x1 and map f x2 have bag distance up to d.

Proof. By induction on d.
When d = 0, the two bags must be permutations of each other. So the mapped values are also

permutations of each other. Thus, the mapped values also have bag distance 0.

In the inductive case, if the two input bags have distance d + 1, without loss of generality, assume
x1 has an element that is missing from x2. Then, it must be the case that f applied to this element
is also missing from map f x2. From the induction hypothesis, we know the mapped values of x1
without this extra element and that of x2 have bag distance up to d. Thus, adding an extra element
□
will increase the bag distance up to d + 1.

We also need to show that the bag map extension is linear with respect to the pre-condition
and post-condition in the conclusion of its typing rule. First, we note that our sensitivity analysis
of the bag map specification reveals the input and output bags have the same sensitivity. So, if

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

Fuzzi: A Three-Level Logic for Differential Privacy

37

input bag’s sensitivity is scaled by k, then the output bag’s sensitivity will be scaled by the same k
according to this typing rule. Next, we note that all other modified variables have sensitivity ∞, for
any k > 0, multiplying k with ∞ still results in ∞. For the variables not modified by bag map, their
sensitivities are not changed in this typing rule, using the Frame rule from apRHL we can show
their sensitivities are also scaled by k. This accounts for the linear scaling of all the variables in the
pre- and post-conditions.

D.2 Vector-Map
We follow the same strategy applied in the proof of bag map and first build the function f[[c]]spec
that characterizes c behavior using just tin and the values of non-modified non-sensitive variables
before entering the vector map loop. We also establish the same loop invariant:

out[0 . . . i] = map f[[c]]spec in[0 . . . i]
From the premises of the vector map typing rule, we know c is a linear command. So, by
Definition 6, we know that if v ⟨1⟩ and v ⟨2⟩ have distance d, then f[[c]]spec v ⟨1⟩ and f[[c]]spec v ⟨2⟩ have
distance sd, where s = Γ3(tout), and Γ3 is the typing context as specified in the typing rule for vector
map. In fact, we give the following definition to characterize functions like f[[c]]spec :

Definition 9. Given a function f : τ → σ , if there is a number s ∈ R>0 ∪ {∞} such that for any
x1, x2 ∈ τ , the distance dσ (f x1, f x2) ≤ sdτ (x1, x2), then we call f a linear function with scale factor
s with the chosen distance functions dτ and dσ .

We remark that functions as defined by Definition 9 are also called lipschitz functions with
lipschitz constant s. However, in the usual mathematical definition of s-lipschitz functions, the
value of s does not include ∞.

We then prove the following lemma for such functions:

Lemma 10. If f : τ → σ is a linear function with scale factor s, then map f is also a linear function

with scale factor s with distance functions chosen as the array distances on [τ ] and [σ ].

Proof. We first case analyze on whether the two input arrays have the same length.
If they have different lengths, then their distance is ∞, so for any positive s, the scaled distance

s · ∞ = ∞ is still infinite. And we are done.

If they have the same length, then we proceed by induction on the length of these arrays.
When the length is 0, the two arrays have distance 0, and so do the mapped arrays. The inequality

0 ≤ s · 0 = 0 holds, so we are done.

In the inductive case, assume both input arrays x1 and x2 have length n + 1. Consider the
prefix sub-arrays of length n. Let dprefix be the distance between the two prefix sub-arrays, and let
dlast = d[τ ](x1, x2) − dprefix. Let the distance between the mapped prefix sub-arrays be d ′

prefix.

From the induction hypothesis, we know d ′

≤ sdprefix. Now, let d ′

= dσ (f x1[n], f x2[n]).

last

prefix

Since f is a linear function with scale factor s, we know d ′

last
Combining this inequality with the previous one, we get d ′

≤ s(dprefix + dlast). By the
definition of array distances, we know the distance between the mapped arrays is less than the
□
distance between the input arrays scaled with s.

prefix

last

≤ sdlast.
+ d ′

Applying Lemma 10 together with the loop invariant we established concludes the proof for

array map.

The vector map program is also linear with respect to the pre- and post-conditions produced by
its sensitivity typing rule. Since the output array has a sensitivity in the post-condition that is a
multiple of the input array’s sensitivity in the pre-condition, scaling the input array’s sensitivity by

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

38

Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth

some k > 0 will scale the output array’s sensitivity by the same factor. The other modified and
non-modified variables follow the same argument from bag map.

D.3 Partition
We use the same reasoning from bag map to show that outidx = map f[[c]]spec in — that is, the partition
indices are computed by mapping the semantics f[[c]]spec over the input bag.

For the second while loop that places each input bag element into the corresponding partition,

we will specify it using the combinator foldl over bags:

foldl : (b → a → b) → b → {a} → b

The first argument to foldl will be a function that specifies how to place one element from the
input bag into the output partitions. We will use the function place to build this argument:

place : [{τ }] → ( int * τ ) → [{τ }]
place parts ( idx , elmt ) =

match nth idx parts with

Some part → update ( part ++ [ elmt ]) idx parts
None

→ parts

The place function takes the partitions, followed by a pair of partition index and the bag element,
and produces new partitions such that for pairs whose indices are in range, the bag element will be
inserted at the end of the indexed partition. The pairs whose indices are out of range are simply
ignored.

The specification of the second while loop is then

out[0 . . . i] = foldl place empty (zip outidx[0 . . . i] in[0 . . . i])

The right hand side can be expanded into

foldl place empty (zip (map f[[c]]spec in[0 . . . i]) in[0 . . . i])

using the specification established the first while loop. The empty value is the initial empty partition—
an array of empty bag values, whose length is equal to the value of the specified nParts parameter.
The zip operator takes two lists and produces a list of pairs.

We prove this specification characterizes the behavior of the second loop using the one-sided

apRHL rules.

Next, we need to consider the sensitivity of out using the foldl specification. Our typing rule
claims that the distance between out⟨1⟩ and out⟨2⟩ is at most the distance between the input bags
in⟨1⟩ and in⟨2⟩. Let d be the bag distance between in⟨1⟩ and in⟨2⟩.

But first, we will need to establish a few more properties about values in Fuzzi.

Definition 10 (Eqivalence). Two values v1 and v2 of type τ are equivalent if their distance

dτ (v1, v2) is 0.

Lemma 11. The equivalence definition is a proper equivalence relation: it is symmetric, reflexive

and transitive.

Proof. By induction on the type.

□

Lemma 12. Given two values x1 and x ′

1 of type τ that are equivalent, for any x2 of the same type,

dτ (x1, x2) = dτ (x ′

1, x2).

Proof. By induction on the type.

□

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

Fuzzi: A Three-Level Logic for Differential Privacy

39

For bags, two bags are equivalent if they are permutations of each other.
For arrays, two arrays are equivalent if they have the same length and each pair of elements in

their corresponding positions are equivalent.

So, two arrays of bags are equivalent if these two arrays have the same length and each pair of

bags at every position are permutations of each other.

Let’s establish a notation for writing down permutations. We will use a sequence of integers to
express a permutation. For example, given the bag {a, b, c}, an equivalent bag under the permutation
312 is {c, a, b}.

Next, we show that the partition specification respects the equivalence relation.

Lemma 13. Given two bags x1 and x2 and any total function f , if x1 and x2 are equivalent, then

and

are also equivalent.

foldl place empty (zip (map f x1) x1)

foldl place empty (zip (map f x2) x2)

Proof. Let σ be the permutation such that σ (x1) = x2.
We call i, j an inversion in σ if i appears before j, but i > j. We proceed by induction on the

number of inversions in σ .

In the base case, σ is identity, so x1 = x2, and we are done.
In the inductive case, let there be k + 1 inversions in σ . There must be an adjacent inversion in σ .
An adjacent inversion is a length-2 subsequence ij in σ such that i appears immediately before j,
but i > j. If there were no such adjacent inversions, then σ must be identity again, and this would
be a contradiction with the number of inversions k + 1.

We produce a new permutation σ ′ by swapping i and j. The new permutation σ ′ must have k

inversions. Consider the following illustration:

σ ′ = σ1σ2 . . . ji . . . σn

For all numbers σ1 upto σk right before i, their relative position did not change with respect to i or
j, so we did not introduce nor eliminate inversions by swapping i and j. The same argument goes
for all numbers after j.

Since ij itself is an inversion, the total number of inversions must have decreased by 1.
So, by induction hypothesis, the output from folding x1 and σ ′(x1) must be equivalent.
Now, we just need to show the output from folding σ ′(x1) and x2 must be equivalent as well,

then we are done. Recall x2 = σ (x1).

The only difference between these two bags is that x1[i] and x1[j] appears in swapped orders in

σ ′(x1) and σ (x1).

Let’s do a case analysis on whether f x1[i] = f x1[j]. Let the partition index computed by

applying f to x1[i] and x1[j] be m and n.

If m (cid:44) n, then the output from foldl will in fact be identical. This is because since x1[i] is placed
into the m-th output bag, and x1[j] is placed into the n-th output bag, but the order in which they
are processed have not changed with respect to other elements in their respective output bags. So
the output remains identical.

If m = n, then only the m-th output bag will be impacted. And in that output bag, the values
x1[i] and x1[j] will be swapped since the order in which they are processed is changed. But
this just permutes the m-th output bag. So, the output arrays from folding σ ′(x1) and x2 remain
□
equivalent.

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

40

Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth

By Lemma 12 and Lemma 13, we know that for any two inputs x1 and x2, permuting them does

not change the distance on their output from the specification of partition.

Knowing this, we are ready to prove the sensitivity condition for partition.

Lemma 14. Given two bags x1 and x2 with distance d and a total function f , the distance between
foldl place empty (zip (map f x1) x1)

and

is also d.

foldl place empty (zip (map f x2) x2)

Proof. Since we know permuting x1 and x2 does not change the distance on the outputs, with
1 and x2 = px ′
2,
2 is

out loss of generality, we can assume that x1 and x2 are arranged such that x1 = px ′
where p is a common prefix, and x ′
the multiset difference between x2 and x1. This implies d = |x ′

1 is the multiset difference between x1 and x2, and similarly x ′
1| + |x ′
2|.

Proceed by induction on d.
In the base case, we know x1 = x2 = p, and we are done.
In the inductive case, assume the bag distance is d + 1, and x1 = px ′

the last element in the multiset difference between x1 and x2.

1v and x2 = px ′

2, where v is

Since d + 1 = |x ′

1v | + |x ′

distance between folding px ′
x1 changes the distance.

2|, which implies d = |x ′

2|. By induction hypothesis, we know the
1 and x2 is d. We just need to consider how adding the last value v to

1| + |x ′

Let i = f v. So v will be placed at the end of the i-th output bag. Since we are only adding v
1 and nothing is added to the output from x2, this implies the distance must
□

to the output from px ′
increase by 1. This concludes the proof.

D.4 Bag-Sum

We again deploy the same strategy used so far. We can establish a specification that models bag
sum with the one-sided loop invariant

out = foldl (λ sum v. sum + clip bound v) 0 in[0 . . . i]

where clip returns a value whose magnitude is within the bound set by its first argument.

We also show that this specification respects equivalence relations on bags.
Lemma 15. Given two equivalent bags x1 and x2, the values foldl (λ sum v. sum+clip bound v) 0 x1

and foldl (λ sum v. sum + clip bound v) 0 x2 are the same.

Proof. The proof again proceeds by induction on the number of inversions in the permutation

σ where x2 = σ (x1).

In the inductive case, we apply commutativity of addition to conclude the proof.

□

So, by Lemma 12 and Lemma 15, we can again permute the inputs without changing the distance

on the outputs.

Finally, to reason about the sensitivity of the specification, we consider the following lemma.

Lemma 16. Given two bags x1 and x2 of distance d and a non-negative real number bound, then dis-
tance between foldl (λ sum v. sum+clip bound v) 0 x1 and foldl (λ sum v. sum+clip bound v) 0 x2
is at most d · bound.

Proof. With out loss of generality, we can again assume x1 = px ′

1 and x2 = px ′

2 just like we did

for partition. We know d = |x ′

1| + |x ′
2|.

Proceed by induction on d. The base case follows directly from x1 = x2 = p.

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

Fuzzi: A Three-Level Logic for Differential Privacy

41

In the inductive case, we assume x1 = px ′

by induction hypothesis, we know the distance between bag summing px ′
The bag sum of x1 simply adds clip bound v to the bag sum of px ′

1| + |x ′
2|,
1 and x2 is at most d ·bound.
1. But the absolute value
of clip bound v is at most bound. So, the distance between the bag sum of x1 and x2 is at most
□
(d + 1) · bound. This concludes the proof.

1v, where v is the last element of x1. Since d = |x ′

The bag sum program is also linear with respect to the typing contexts admitted by its sensitivity
rules. Scaling the pre-condition by k > 0 will correspondingly cause the output sum’s sensitivity
to be scaled by k in the post-condition. The other modified variables have ∞-sensitivity, and the
scaled post-condition also has their sensitivity as ∞.

D.5 Advanced Composition

The advanced composition rule is a straightforward application of the apRHL advanced composition
rule.

E FUZZI IMPLEMENTATION OF DIFFERENTIALLY PRIVATE GRADIENT DESCENT

We show the full implementation of differentially private gradient descent for logistic regression (as
discussed in Section 7.1) here. This code shown here is largely comprised of three parts: (1) a bmap
application that preprocesses the input data, (2) a second bmap application that computes the private
gradients, (3) and a final step that releases noised gradients and updates model parameter. The code
also uses a special extension called repeat. This extension takes a loop index variable, a constant
literal integer and a Fuzzi command as parameters, and expands to a while loop that executes the
command for the specified number of times. The typing rule for this extension simply unrolls the
loop for the specified number of times, but perform no special deduction on the sensitivities and
privacy cost for the entire loop. We had elided this extension from the main body of the paper
because it only provides a better programming experience (one could simply copy the loop body
for the specified number of times to reach same result), but does not provide additional insight to
Fuzzi’s design.

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

42

Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, and Aaron Roth

lamb = 0.1;
rate = 0.1;
epoch = 0;
size $= lap (10.0 , fc ( length ( db )));
/* used advanced composition for 100 total passes */
ac ( epoch , 100 , 1.0 e -6 ,

/* extend each row to account for bias */
bmap (db , db1 , trow , i , trow1 ,

trow1 = zero_786 ;
trow1 [0] = 1.0;
repeat (j , 785 , trow1 [j +1] = trow [ j ];) ;
j = 0;

) ;
/* compute the gradient for each row */
i = 0;
trow1 = zero_786 ;
bmap ( db1 , dws , trow1 , i , twout ,

twout = zero_785 ;
repeat (j , 785 , twout [j] = trow1 [ j ];) ;
j = 0;
dt = clip ( dot ( twout , w) , 100.0) ;
temp = exp ( -1.0 * trow1 [785] * dt );
prob = 1.0 / (1.0 + temp );
sc = (1.0 - prob ) * trow1 [785];
twout = scale (sc , twout );
dt = 0.0;
temp = 0.0;
prob = 0.0;
sc = 0.0;

) ;
/* compute noised gradient and update model parameter */
repeat (j , 785 ,

i = 0; twout = zero_785 ; tf_out = 0.0;
bmap ( dws , dws_j , twout , i , tf_out , tf_out = twout [j ];) ;
i = 0; tf_out = 0.0;
bsum ( dws_j , j_sum , i , tf_out , 1.0) ;
j_sum $ = lap (5000.0 , j_sum );
w [ j ] = w [j] + ( j_sum / size - 2.0 * lamb * w[j ]) * rate ;

);
/* clear aux variables */
db1 = {}; dt = 0.0;
dws = {}; dws_j = {};
i = 0; j = 0;
prob = 0.0; sc = 0.0; temp = 0.0; tf_out = 0.0;
trow = zero_785 ; trow1 = zero_786 ; twout = zero_785 ;

);

Proc. ACM Program. Lang., Vol. 1, No. 1, Article . Publication date: June 2019.

