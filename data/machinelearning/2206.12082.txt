Genetic Programming and Evolvable Machines

Symbolic-Regression Boosting

Moshe Sipper · Jason H. Moore

Received: June 27, 2022/ Accepted: date

Abstract Modifying standard gradient boosting by replacing the embed-
ded weak learner in favor of a strong(er) one, we present SyRBo: Symbolic-
Regression Boosting. Experiments over 98 regression datasets show that by
adding a small number of boosting stages—between 2–5—to a symbolic re-
gressor, statistically signiﬁcant improvements can often be attained. We note
that coding SyRBo on top of any symbolic regressor is straightforward, and
the added cost is simply a few more evolutionary rounds. SyRBo is essentially
a simple add-on that can be readily added to an extant symbolic regressor,
often with beneﬁcial results.

1 Introduction

In machine learning, a weak learner is deﬁned as a learner that can produce
an hypothesis that performs only slightly better than random guessing, while
a strong learner can with high probability output an hypothesis that is correct
on all but an arbitrarily small fraction of the instances.

In his seminal paper, “The strength of weak learnability”, Schapire [15]
described a method “for converting a weak learning algorithm into one that
achieves arbitrarily high accuracy.” Over the years, a plethora of highly suc-
cessful boosting algorithms that transform weak learners into strong ones have
been devised [1,3,4,9].

M. Sipper
Department of Computer Science, Ben-Gurion University, Beer Sheva 84105, Israel
E-mail: sipper@gmail.com

J. H. Moore
Institute for Biomedical Informatics, University of Pennsylvania, Philadelphia, PA 19104-
6021, USA
This
Evolvable Machines. The
https://link.springer.com/10.1007/s10710-021-09400-0

in Genetic Programming

authenticated

published

available

preprint

and
at

version

article

online

ﬁnal

an

of

is

is

a

2
2
0
2

n
u
J

4
2

]
E
N
.
s
c
[

1
v
2
8
0
2
1
.
6
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
2

Moshe Sipper, Jason H. Moore

A recent rigorous benchmarking study of four symbolic regression algo-
rithms versus nine machine learning approaches found that “symbolic regres-
sion performs strongly compared to state-of-the-art gradient boosting algo-
rithms” (they also found that “in terms of running times [symbolic regression]
is among the slowest of the available methodologies”) [12]. Herein we wish to
combine boosting with symbolic regression, asking whether gradient boosting
might improve a strong(er) learner in the form of a symbolic regressor. We
answer in the aﬃrmative, demonstrating that improved results can be readily
obtained, at relatively little added cost.

In the next section we describe our method and discuss related work. Sec-
tion 3 presents the experimental setup and our results, followed by concluding
remarks in Section 4.

2 Symbolic-Regression Boosting (SyRBo)

For our experiments we used the popular scikit-learn Python package [14,16]
due to its superb ability to handle much of the tedious desiderata of machine
learning coding and experimentation. We then chose the GPLearn package [5],
which implements tree-based genetic programming (GP) symbolic regression,
is relatively fast, and—importantly—interfaces seamlessly with scikit-learn.

The main idea behind SyRBo is simple: we replace the boosted weak learner
of gradient boosting (typically a decision tree) with a (possibly) strong learner,
speciﬁcally, a GP-based symbolic regressor.

Algorithm 1 provides the pseudocode (the code is available at https:
//github.com/moshesipper). SyRBo receives the number of boosting stages
as a parameter (one might consider the actual number of stages to be one less,
as the ﬁrst stage performs the initial prediction). Fitting a model to data is
done in a standard gradient-boosting manner, through successive stages, where
each stage ﬁts a learner to the pseudo-residuals of the previous stage; predic-
tion is performed by summing up all learner predictions. The only change
involves the learners themselves, which are not decision trees but rather sym-
bolic regressors, evolved by calling the SymbolicRegressor function with the
given population size and generation count (both set to 200). The function
set used by SymbolicRegressor is given in Table 1. To facilitate the symbolic
regressor’s handling of diverse features scales, the dataset rows undergo L2
normalization (i.e., the feature values in a row have a unit L2 norm).

We note that our aim herein was to demonstrate SyRBo’s being an add-on
that can be added to any symbolic regressor. As such, this paper is not about
symbolic regression per se, but about performance beneﬁts to be gained if
one is using it. We thus contented ourselves with the standard function set of
gplearn (adding only 2 conditionals), with all other parameters set to defaults
(except for population size and generation count).

Regarding previous work, it would seem that by and large the emphasis in
boosting techniques has been on weak learners, typically decision trees. Works
using strong learners in the context of boosting employed mainly AdaBoost-

Symbolic-Regression Boosting

3

Algorithm 1 SyRBo.

Input:

stages ← number of boosting stages
population size ← 200
generations ← 200

1: function init(stages, population size, generations)
2:
3:

Initialize an empty SyRBo object with given parameters
boosters = {} # Initialize an empty list of boosters

4: function fit(X, y) # X : training inputs, y: target values
5:
6:

for stage ← 0 to stages-1 do

gp = SymbolicRegressor(population size, generations) # Initialize a GP regres-

sor

7:
8:
9:

gp.ﬁt(X,y) # Fit regressor to (training) data
Add gp to boosters # Add the ﬁtted GP regressor to the list of boosters
y = y - gp.predict(X) # Compute pseudo-residuals

10: function predict(X ) # X : inputs
11:
12:
13:
14:

Return prediction

prediction = 0 # Vector of zeros whose length equals number of instances in dataset
for i ← 0 to stages-1 do

prediction = prediction + boosters[i].predict(X)

Table 1 Function set used by SymbolicRegressor.

Function Arity Description

add
sub
mul
div
sqrt
log
abs
neg
inv
max
min
if3
if4

2
2
2
2
1
1
1
1
1
2
2
3
4

addition
subtraction
multiplication
protected division (near-zero denominator returns 1)
protected square root (uses absolute value of argument)
protected log (uses absolute value of argument, near-zero argument returns 0)
absolute value
negative
protected inverse (near-zero argument returns 0)
maximum
minimum
if 3(x1, x2, x3) returns x2 if x1 ≥ 0 else returns x3
if 4(x1, x2, x3, x4) returns x3 if x1 ≥ x2 else returns x4

like [3] boosting. Modest success was attained by [2, 6]. [17] showed that boost-
ing a strong learner with AdaBoost may, in fact, contribute to performance
degradation. Within the domain of GP, AdaBoost-like boosting of dataset
sample weights has been used with some success [7, 8, 10, 13]. Perhaps closest
to our work is that of [11], who presented an interesting iterative approach,
Sequential Symbolic Regression, wherein each iteration applies a transforma-
tion based on a geometric semantic crossover operator. In contrast, our work
is based on gradient boosting, is more generic in that it can work with any
form of symbolic regression, and is also easier to code and apply to any extant
project.

4

Moshe Sipper, Jason H. Moore

Fig. 1 A “bird’s-eye view” of the 98 datasets used in this study: number of instances (left)
and number of features (right).

3 Experimental Setup and Results

Can this (fairly) simple gradient boosting-like setup improve symbolic regres-
sion? We tested SyRBo on regression datasets from the PMLB repository [12],
using our cluster of Intel® Xeon® E5-2650L servers. Of the 120 datasets we
selected the 98 with 3000 instances or less. Figure 1 shows a “bird’s-eye view”
of the datasets.

The pseudo-code for the experimental setup is given in Algorithm 2. For
each dataset we performed 30 replicate runs, with 5-fold cross validation per
replicate. SyRBo and SymbolicRegressor (with equal population size and gen-
erations) were trained on 4 folds and tested on the left-out test fold.

Algorithm 2 Experimental setup.

Input:

dataset ← dataset to be used
algorithms ← {SyRBo, SymbolicRegressor}

Output:

Performance measures (over test sets)

Shuﬄe dataset and generate 5 folds
for fold ← 1 to 5 do

1: for rep ← 1 to 30 do
2:
3:
4:
5:
6:
7:

Use alg to ﬁt a model to training set
Test resultant model on test set

Split dataset into training and test sets according to fold
for alg in algorithms do

For each of the 98 datasets we recorded the mean absolute error attained
per algorithm over each of the 30 replicate runs, per each of the 5 test folds
(i.e., following training). We ran 4 separate experiments, over all 98 datasets,
with number of stages equal to 2, 3, 4, and 5, respectively.

Symbolic-Regression Boosting

5

Table 2 Results. Datasets: number of datasets. Stages: number of stages. Wins: number of
datasets for which SyRBo’s result was better than SymbolicRegressor’s. Signiﬁcant: number
of datasets for which SyRBo’s win was signiﬁcant according to permutation testing. Losses:
number of datasets for which SyRBo’s result was worse than SymbolicRegressor’s. Insigniﬁ-
cant: number of datasets for which SyRBo’s loss was insigniﬁcant according to permutation
testing.

Datasets
98
98
98
98

Stages Wins

2
3
4
5

78
83
84
87

Signiﬁcant
48
63
71
70

Losses
20
15
14
11

Insigniﬁcant
16
13
12
9

Table 2 shows a summary of our results (detailed results can be found in
the Appendix). For each dataset we computed the median of the test scores of
all 30 replicates, with 5 folds per replicate (a total of 150 test-score values). A
win for SyRBo was then a better (lower) median value than SymbolicRegres-
sor. To assess whether a win for a speciﬁc dataset was signiﬁcant or not, we
performed a 10,000-round permutation test, comparing the scores of SyRBo
with SymbolicRegressor; if the p-value was < 0.05 the win was considered
signiﬁcant, else it was not (in which case SyRBo was at least not performing
worse than SymbolicRegressor). In addition, when SyRBo “lost” to Symboli-
cRegressor we performed a 10,000-round permutation test, comparing the two
algorithms’ scores; if the p-value was >= 0.05 the loss was considered insignif-
icant.

As seen in the table, statistically signiﬁcant improvements can often be
attained, and, moreover, rarely does SyRBo result in statistically signiﬁcant
worse results. Using SyRBo is thus a good bet, and, furthermore, it is easily
coded and the added computational cost is not high.

4 Concluding Remarks

We presented SyRBo, a gradient boosting-style algorithm, wherein the deci-
sion tree is replaced by a symbolic regressor. Testing the merits of our new
method we showed that symbolic regression results can be consistently im-
proved. Moreover, as can be seen in Algorithm 1, coding SyRBo on top of any
symbolic regressor is straightforward, and the added cost is simply a few more
evolutionary rounds. SyRBo is essentially a simple add-on that can be readily
added to a symbolic regressor, often with beneﬁcial results.

There are a number of avenues we can oﬀer for future exploration:

– Add known boosting tricks of the trade, such as a learning rate and dy-
namic early stopping (similar to XGBRegressor’s ‘early stopping rounds’
parameter).

– Our focus herein was on regression. It would seem worthwhile to examine

SyRBo for classiﬁcation.

– We used a rather basic symbolic regressor. The GP literature is rife with
many other types of regressors, which might be used in conjunction with

6

Moshe Sipper, Jason H. Moore

SyRBo. More generally, other types of GP might oﬀer productive ways to
evolve programs that might serve as strong learners.

– Comparison to non-symbolic-regressor methods.
– While we focused on gradient boosting, other types of boosting techniques
might be examined as to whether they might be a good ﬁt for SyRBo.

Acknowledgments

This work was supported by National Institutes of Health (USA) grants LM010098,
LM012601, AI116794. We thank Hagai Ravid for spotting an error in an earlier
version of the code.

References

1. Chen, T., Guestrin, C.: XGBoost: A scalable tree boosting system. In: Proceedings of
the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data
Mining, KDD ’16, pp. 785–794. ACM, New York, NY, USA (2016). DOI 10.1145/
2939672.2939785. URL http://doi.acm.org/10.1145/2939672.2939785

2. Fink, M., Perona, P.: Mutual boosting for contextual inference. In: Advances in neural

information processing systems, pp. 1515–1522 (2004)

3. Freund, Y., Schapire, R.E.: A decision-theoretic generalization of on-line learning and
an application to boosting. Journal of computer and system sciences 55(1), 119–139
(1997)

4. Friedman, J.H.: Greedy function approximation: a gradient boosting machine. Annals

of statistics pp. 1189–1232 (2001)

5. GPLearn. https://gplearn.readthedocs.io/ (2020). Accessed: 2020-11-20
6. Harries, M.B.: Boosting a strong learner: Evidence against the minimum margin. In:
Proceedings of the Sixteenth International Conference on Machine Learning, ICML ’99,
p. 171–180. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA (1999)

7. Iba, H.: Bagging, boosting, and bloating in genetic programming. In: Proceedings of
the 1st Annual Conference on Genetic and Evolutionary Computation-Volume 2, pp.
1053–1060 (1999)

8. Karakatiˇc, S., Podgorelec, V.: Building boosted classiﬁcation tree ensemble with genetic
programming. In: Proceedings of the Genetic and Evolutionary Computation Confer-
ence Companion, pp. 165–166 (2018)

9. Ke, G., Meng, Q., Finley, T., Wang, T., Chen, W., Ma, W., Ye, Q., Liu, T.Y.: LightGBM:
A highly eﬃcient gradient boosting decision tree. In: Proceedings of the 31st Interna-
tional Conference on Neural Information Processing Systems, NIPS’17, p. 3149–3157.
Curran Associates Inc., Red Hook, NY, USA (2017)

10. Oliveira, E., Pozo, A., Vergilio, S.R.: Using boosting techniques to improve software
In: 2006 18th IEEE International
reliability models based on genetic programming.
Conference on Tools with Artiﬁcial Intelligence (ICTAI’06), pp. 643–650. IEEE (2006)
11. Oliveira, L.O.V., Otero, F.E., Pappa, G.L., Albinati, J.: Sequential symbolic regression
with genetic programming. In: R. Riolo, W.P. Worzel, M. Kotanchek (eds.) Genetic
Programming Theory and Practice XII, pp. 73–90. Springer International Publishing,
Cham (2015)

12. Orzechowski, P., La Cava, W., Moore, J.H.: Where are we now? a large benchmark study
of recent symbolic regression methods. In: Proceedings of the Genetic and Evolutionary
Computation Conference, pp. 1183–1190 (2018)

13. Paris, G., Robilliard, D., Fonlupt, C.: Applying boosting techniques to genetic program-
ming. In: International Conference on Artiﬁcial Evolution (Evolution Artiﬁcielle), pp.
267–278. Springer (2001)

Symbolic-Regression Boosting

7

14. Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel,
M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau,
D., Brucher, M., Perrot, M., Duchesnay, E.: Scikit-learn: Machine learning in Python.
Journal of Machine Learning Research 12, 2825–2830 (2011)

15. Schapire, R.E.: The strength of weak learnability. Machine learning 5(2), 197–227 (1990)
16. Scikit-learn: Machine learning in Python. https://scikit-learn.org/ (2020). Ac-

cessed: 2020-11-20

17. Wickramaratna, J., Holden, S., Buxton, B.: Performance degradation in boosting. In:
International Workshop on Multiple Classiﬁer Systems, pp. 11–21. Springer (2001)

Appendix: Detailed Results

The results of all experiments over all datasets are given in Tables 3, 4, 5,
and 6 for number of stages equal to 2, 3, 4, and 5, respectively. As noted in
Section 3, for each of the 98 datasets we recorded the mean absolute error
attained per algorithm over each of the 30 replicate runs, per each of the 5
test folds. We then computed the median of these scores, which are presented
under ‘mean absolute error’ in the tables. Under ‘pval’ we show the results of
the 10,000-round permutation tests between the scores of SyRBo and Symbol-
icRegressor, with a ‘!’ denoting a signiﬁcant win for SyRBo and a ‘=’ denoting
an insigniﬁcant loss for SyRBo. Under ‘run times’ we show the median run
times for SyRBo and SymbolicRegressor. ‘SR’ denotes SymbolicRegressor.

8

Moshe Sipper, Jason H. Moore

Table 3 2-stage SyRBo: Results of all datasets.

dataset
1027 ESL
1028 SWD
1029 LEV
1030 ERA
1089 USCrime
1096 FacultySalaries
192 vineyard
195 auto price
207 autoPrice
210 cloud
228 elusage
229 pwLinear
230 machine cpu
4544 GeographicalOriginalofMusic
485 analcatdata vehicle
505 tecator
519 vinnie
522 pm10
523 analcatdata neavote
527 analcatdata election2000
542 pollution
547 no2
556 analcatdata apnea2
557 analcatdata apnea1
560 bodyfat
561 cpu
579 fri c0 250 5
581 fri c3 500 25
582 fri c1 500 25
583 fri c1 1000 50
584 fri c4 500 25
586 fri c3 1000 25
588 fri c4 1000 100
589 fri c2 1000 25
590 fri c0 1000 50
591 fri c1 100 10
592 fri c4 1000 25
593 fri c1 1000 10
594 fri c2 100 5
595 fri c0 1000 10
596 fri c2 250 5
597 fri c2 500 5
598 fri c0 1000 25
599 fri c2 1000 5
601 fri c1 250 5
602 fri c3 250 10
603 fri c0 250 50
604 fri c4 500 10
605 fri c2 250 25
606 fri c2 1000 10
607 fri c4 1000 50
608 fri c3 1000 10
609 fri c0 1000 5
611 fri c3 100 5
612 fri c1 1000 5
613 fri c3 250 5
615 fri c4 250 10
616 fri c4 500 50
617 fri c3 500 5
618 fri c3 1000 50
620 fri c1 1000 25
621 fri c0 100 10
622 fri c2 1000 50
623 fri c4 1000 10
624 fri c0 100 5
626 fri c2 500 50
627 fri c2 500 10
628 fri c3 1000 5
631 fri c1 500 5
633 fri c0 500 25
634 fri c2 100 10
635 fri c0 250 10
637 fri c1 500 50
641 fri c1 500 10
643 fri c2 500 25
644 fri c4 250 25
645 fri c3 500 50
646 fri c3 500 10
647 fri c1 250 10
648 fri c1 250 50
649 fri c0 500 5
650 fri c0 500 50
651 fri c0 100 25
653 fri c0 250 25
654 fri c0 500 10
656 fri c1 100 5
657 fri c2 250 10
658 fri c3 250 25
659 sleuth ex1714
663 rabe 266
665 sleuth case2002
666 rmftsa ladata
678 visualizing environmental
687 sleuth ex1605
690 visualizing galaxy
695 chatfield 4
706 sleuth case1202
712 chscase geyser1

mean absolute error and pval
SyRBo: 1.02, SR: 1.04, pval: 9.5E-02
SyRBo: 0.61, SR: 0.62, pval: 2.2E-01
SyRBo: 0.62, SR: 0.65, pval: 0.0E+00 !
SyRBo: 1.45, SR: 1.46, pval: 3.9E-01
SyRBo: 25.59, SR: 27.52, pval: 2.3E-01
SyRBo: 3.56, SR: 3.63, pval: 6.2E-01
SR: 2.44, SyRBo: 2.52, pval: 2.1E-01 =
SR: 1990.78, SyRBo: 2090.58, pval: 8.9E-02 =
SR: 1955.88, SyRBo: 2093.54, pval: 2.8E-02
SR: 0.51, SyRBo: 0.52, pval: 4.1E-01 =
SyRBo: 12.97, SR: 13.72, pval: 3.2E-01
SyRBo: 1.56, SR: 1.66, pval: 1.2E-02 !
SyRBo: 43.04, SR: 45.95, pval: 1.2E-01
SR: 0.49, SyRBo: 0.5, pval: 8.2E-02 =
SyRBo: 151.48, SR: 179.22, pval: 1.5E-03 !
SR: 5.17, SyRBo: 5.83, pval: 1.0E-02
SR: 1.27, SyRBo: 1.31, pval: 1.3E-02
SyRBo: 0.68, SR: 0.69, pval: 2.1E-01
SR: 0.51, SyRBo: 0.52, pval: 7.6E-01 =
SR: 38724.65, SyRBo: 39617.02, pval: 7.8E-01 =
SR: 176.33, SyRBo: 185.12, pval: 5.9E-01 =
SR: 0.58, SyRBo: 0.58, pval: 8.7E-01 =
SR: 825.75, SyRBo: 840.89, pval: 7.3E-01 =
SyRBo: 828.37, SR: 844.69, pval: 7.1E-01
SR: 4.21, SyRBo: 4.64, pval: 4.0E-04
SyRBo: 30.99, SR: 34.95, pval: 8.4E-02
SyRBo: 0.42, SR: 0.45, pval: 0.0E+00 !
SyRBo: 0.71, SR: 0.72, pval: 2.3E-03 !
SyRBo: 0.7, SR: 0.72, pval: 3.8E-02 !
SyRBo: 0.73, SR: 0.74, pval: 1.5E-02 !
SyRBo: 0.7, SR: 0.71, pval: 3.6E-02 !
SyRBo: 0.69, SR: 0.71, pval: 6.7E-03 !
SyRBo: 0.73, SR: 0.73, pval: 8.7E-01
SyRBo: 0.7, SR: 0.71, pval: 2.2E-02 !
SyRBo: 0.39, SR: 0.4, pval: 1.0E-02 !
SyRBo: 0.71, SR: 0.73, pval: 1.6E-01
SyRBo: 0.72, SR: 0.72, pval: 2.2E-01
SyRBo: 0.65, SR: 0.71, pval: 0.0E+00 !
SyRBo: 0.64, SR: 0.68, pval: 1.9E-02 !
SyRBo: 0.39, SR: 0.44, pval: 0.0E+00 !
SyRBo: 0.63, SR: 0.68, pval: 0.0E+00 !
SyRBo: 0.61, SR: 0.67, pval: 0.0E+00 !
SyRBo: 0.41, SR: 0.43, pval: 2.0E-04 !
SyRBo: 0.57, SR: 0.67, pval: 0.0E+00 !
SyRBo: 0.58, SR: 0.65, pval: 0.0E+00 !
SyRBo: 0.69, SR: 0.72, pval: 7.3E-03 !
SyRBo: 0.4, SR: 0.4, pval: 9.6E-01
SyRBo: 0.68, SR: 0.72, pval: 0.0E+00 !
SyRBo: 0.69, SR: 0.69, pval: 7.7E-01
SyRBo: 0.64, SR: 0.67, pval: 0.0E+00 !
SyRBo: 0.72, SR: 0.73, pval: 1.7E-01
SyRBo: 0.66, SR: 0.7, pval: 0.0E+00 !
SyRBo: 0.41, SR: 0.44, pval: 0.0E+00 !
SyRBo: 0.64, SR: 0.66, pval: 3.1E-01
SyRBo: 0.59, SR: 0.69, pval: 0.0E+00 !
SyRBo: 0.59, SR: 0.62, pval: 0.0E+00 !
SyRBo: 0.67, SR: 0.7, pval: 5.6E-03 !
SyRBo: 0.74, SR: 0.74, pval: 9.6E-01
SyRBo: 0.58, SR: 0.65, pval: 0.0E+00 !
SyRBo: 0.72, SR: 0.73, pval: 1.0E-01
SyRBo: 0.72, SR: 0.74, pval: 1.5E-03 !
SyRBo: 0.44, SR: 0.47, pval: 2.9E-02 !
SyRBo: 0.72, SR: 0.73, pval: 1.4E-01
SyRBo: 0.64, SR: 0.69, pval: 0.0E+00 !
SR: 0.46, SyRBo: 0.46, pval: 9.3E-01 =
SyRBo: 0.73, SR: 0.73, pval: 2.6E-01
SyRBo: 0.63, SR: 0.69, pval: 0.0E+00 !
SyRBo: 0.59, SR: 0.66, pval: 0.0E+00 !
SyRBo: 0.6, SR: 0.68, pval: 0.0E+00 !
SyRBo: 0.4, SR: 0.42, pval: 0.0E+00 !
SyRBo: 0.68, SR: 0.69, pval: 9.0E-01
SyRBo: 0.44, SR: 0.52, pval: 0.0E+00 !
SyRBo: 0.75, SR: 0.76, pval: 1.1E-01
SyRBo: 0.67, SR: 0.74, pval: 0.0E+00 !
SyRBo: 0.74, SR: 0.75, pval: 1.8E-01
SyRBo: 0.73, SR: 0.74, pval: 4.2E-01
SyRBo: 0.7, SR: 0.7, pval: 8.6E-01
SyRBo: 0.64, SR: 0.68, pval: 1.0E-04 !
SyRBo: 0.65, SR: 0.73, pval: 0.0E+00 !
SyRBo: 0.72, SR: 0.73, pval: 3.8E-01
SyRBo: 0.4, SR: 0.46, pval: 0.0E+00 !
SyRBo: 0.38, SR: 0.39, pval: 2.7E-02 !
SyRBo: 0.52, SR: 0.53, pval: 4.9E-01
SyRBo: 0.4, SR: 0.41, pval: 8.7E-03 !
SyRBo: 0.42, SR: 0.46, pval: 0.0E+00 !
SyRBo: 0.57, SR: 0.66, pval: 0.0E+00 !
SyRBo: 0.63, SR: 0.7, pval: 0.0E+00 !
SyRBo: 0.73, SR: 0.75, pval: 1.6E-01
SyRBo: 6745.19, SR: 8208.12, pval: 2.2E-02 !
SR: 19.76, SyRBo: 20.19, pval: 4.7E-01 =
SR: 5.08, SyRBo: 5.33, pval: 6.8E-02 =
SR: 1.64, SyRBo: 1.64, pval: 9.2E-01 =
SyRBo: 2.46, SR: 2.51, pval: 4.4E-01
SR: 13.26, SyRBo: 14.33, pval: 5.4E-02 =
SyRBo: 259.23, SR: 461.52, pval: 0.0E+00 !
SR: 17.47, SyRBo: 17.81, pval: 4.0E-01 =
SR: 48.76, SyRBo: 52.21, pval: 8.1E-02 =
SyRBo: 8.3, SR: 9.0, pval: 1.0E-04 !

run times
SyRBo: 59.89s, SR: 31.17s
SyRBo: 46.61s, SR: 23.87s
SyRBo: 54.6s, SR: 26.46s
SyRBo: 61.8s, SR: 30.06s
SyRBo: 123.68s, SR: 73.81s
SyRBo: 61.05s, SR: 36.83s
SyRBo: 66.24s, SR: 37.82s
SyRBo: 316.35s, SR: 195.05s
SyRBo: 424.44s, SR: 176.55s
SyRBo: 44.47s, SR: 22.64s
SyRBo: 126.28s, SR: 89.94s
SyRBo: 65.29s, SR: 35.59s
SyRBo: 166.36s, SR: 92.74s
SyRBo: 62.38s, SR: 36.86s
SyRBo: 220.1s, SR: 135.99s
SyRBo: 92.7s, SR: 51.74s
SyRBo: 64.34s, SR: 35.1s
SyRBo: 44.3s, SR: 22.12s
SyRBo: 59.63s, SR: 35.95s
SyRBo: 562.68s, SR: 230.48s
SyRBo: 215.87s, SR: 141.38s
SyRBo: 57.51s, SR: 29.23s
SyRBo: 164.27s, SR: 68.58s
SyRBo: 130.15s, SR: 50.06s
SyRBo: 59.26s, SR: 33.41s
SyRBo: 115.22s, SR: 77.02s
SyRBo: 53.18s, SR: 26.01s
SyRBo: 43.32s, SR: 21.5s
SyRBo: 53.82s, SR: 26.82s
SyRBo: 61.81s, SR: 30.2s
SyRBo: 53.68s, SR: 26.69s
SyRBo: 54.44s, SR: 27.13s
SyRBo: 41.83s, SR: 21.16s
SyRBo: 53.3s, SR: 26.58s
SyRBo: 55.05s, SR: 28.77s
SyRBo: 55.02s, SR: 26.14s
SyRBo: 52.62s, SR: 26.27s
SyRBo: 54.59s, SR: 26.25s
SyRBo: 55.12s, SR: 27.14s
SyRBo: 54.06s, SR: 27.02s
SyRBo: 45.99s, SR: 22.61s
SyRBo: 55.13s, SR: 26.54s
SyRBo: 53.61s, SR: 27.51s
SyRBo: 55.04s, SR: 26.24s
SyRBo: 55.37s, SR: 26.62s
SyRBo: 52.95s, SR: 25.94s
SyRBo: 42.83s, SR: 22.17s
SyRBo: 43.33s, SR: 21.33s
SyRBo: 44.26s, SR: 21.92s
SyRBo: 54.98s, SR: 26.73s
SyRBo: 43.72s, SR: 21.98s
SyRBo: 57.53s, SR: 28.12s
SyRBo: 42.59s, SR: 20.94s
SyRBo: 56.53s, SR: 27.55s
SyRBo: 56.08s, SR: 26.31s
SyRBo: 54.03s, SR: 26.4s
SyRBo: 51.54s, SR: 25.62s
SyRBo: 52.4s, SR: 26.34s
SyRBo: 54.41s, SR: 26.8s
SyRBo: 51.91s, SR: 26.01s
SyRBo: 42.36s, SR: 21.08s
SyRBo: 43.37s, SR: 21.4s
SyRBo: 44.87s, SR: 22.63s
SyRBo: 53.96s, SR: 26.17s
SyRBo: 43.75s, SR: 21.15s
SyRBo: 42.0s, SR: 21.23s
SyRBo: 52.34s, SR: 25.3s
SyRBo: 56.7s, SR: 27.28s
SyRBo: 55.86s, SR: 26.53s
SyRBo: 51.78s, SR: 26.37s
SyRBo: 54.48s, SR: 26.52s
SyRBo: 43.65s, SR: 21.72s
SyRBo: 44.14s, SR: 22.12s
SyRBo: 54.06s, SR: 26.39s
SyRBo: 42.11s, SR: 20.85s
SyRBo: 41.93s, SR: 20.77s
SyRBo: 41.84s, SR: 20.81s
SyRBo: 52.88s, SR: 25.77s
SyRBo: 54.08s, SR: 25.95s
SyRBo: 52.98s, SR: 26.88s
SyRBo: 52.84s, SR: 25.93s
SyRBo: 52.92s, SR: 27.49s
SyRBo: 51.51s, SR: 25.99s
SyRBo: 53.46s, SR: 27.13s
SyRBo: 52.64s, SR: 26.29s
SyRBo: 55.37s, SR: 27.63s
SyRBo: 53.59s, SR: 25.96s
SyRBo: 51.63s, SR: 25.6s
SyRBo: 366.9s, SR: 179.81s
SyRBo: 95.03s, SR: 54.36s
SyRBo: 53.61s, SR: 31.3s
SyRBo: 45.69s, SR: 25.33s
SyRBo: 50.56s, SR: 28.09s
SyRBo: 90.32s, SR: 51.23s
SyRBo: 263.2s, SR: 137.71s
SyRBo: 112.3s, SR: 57.87s
SyRBo: 120.17s, SR: 77.54s
SyRBo: 71.33s, SR: 47.21s

Symbolic-Regression Boosting

9

Table 4 3-stage SyRBo: Results of all datasets.

dataset
1027 ESL
1028 SWD
1029 LEV
1030 ERA
1089 USCrime
1096 FacultySalaries
192 vineyard
195 auto price
207 autoPrice
210 cloud
228 elusage
229 pwLinear
230 machine cpu
4544 GeographicalOriginalofMusic
485 analcatdata vehicle
505 tecator
519 vinnie
522 pm10
523 analcatdata neavote
527 analcatdata election2000
542 pollution
547 no2
556 analcatdata apnea2
557 analcatdata apnea1
560 bodyfat
561 cpu
579 fri c0 250 5
581 fri c3 500 25
582 fri c1 500 25
583 fri c1 1000 50
584 fri c4 500 25
586 fri c3 1000 25
588 fri c4 1000 100
589 fri c2 1000 25
590 fri c0 1000 50
591 fri c1 100 10
592 fri c4 1000 25
593 fri c1 1000 10
594 fri c2 100 5
595 fri c0 1000 10
596 fri c2 250 5
597 fri c2 500 5
598 fri c0 1000 25
599 fri c2 1000 5
601 fri c1 250 5
602 fri c3 250 10
603 fri c0 250 50
604 fri c4 500 10
605 fri c2 250 25
606 fri c2 1000 10
607 fri c4 1000 50
608 fri c3 1000 10
609 fri c0 1000 5
611 fri c3 100 5
612 fri c1 1000 5
613 fri c3 250 5
615 fri c4 250 10
616 fri c4 500 50
617 fri c3 500 5
618 fri c3 1000 50
620 fri c1 1000 25
621 fri c0 100 10
622 fri c2 1000 50
623 fri c4 1000 10
624 fri c0 100 5
626 fri c2 500 50
627 fri c2 500 10
628 fri c3 1000 5
631 fri c1 500 5
633 fri c0 500 25
634 fri c2 100 10
635 fri c0 250 10
637 fri c1 500 50
641 fri c1 500 10
643 fri c2 500 25
644 fri c4 250 25
645 fri c3 500 50
646 fri c3 500 10
647 fri c1 250 10
648 fri c1 250 50
649 fri c0 500 5
650 fri c0 500 50
651 fri c0 100 25
653 fri c0 250 25
654 fri c0 500 10
656 fri c1 100 5
657 fri c2 250 10
658 fri c3 250 25
659 sleuth ex1714
663 rabe 266
665 sleuth case2002
666 rmftsa ladata
678 visualizing environmental
687 sleuth ex1605
690 visualizing galaxy
695 chatfield 4
706 sleuth case1202
712 chscase geyser1

mean absolute error and pval
SyRBo: 1.01, SR: 1.04, pval: 1.1E-02 !
SyRBo: 0.61, SR: 0.62, pval: 1.7E-01
SyRBo: 0.62, SR: 0.64, pval: 0.0E+00 !
SyRBo: 1.43, SR: 1.46, pval: 2.0E-02 !
SyRBo: 25.31, SR: 27.01, pval: 1.8E-01
SR: 3.57, SyRBo: 3.6, pval: 7.5E-01 =
SR: 2.42, SyRBo: 2.54, pval: 5.9E-02 =
SyRBo: 1955.32, SR: 2049.73, pval: 2.0E-01
SyRBo: 1945.66, SR: 1968.41, pval: 8.6E-01
SyRBo: 0.5, SR: 0.51, pval: 5.9E-01
SyRBo: 12.68, SR: 14.45, pval: 2.9E-03 !
SyRBo: 1.49, SR: 1.63, pval: 1.9E-03 !
SyRBo: 40.74, SR: 44.23, pval: 1.2E-01
SyRBo: 0.49, SR: 0.49, pval: 9.7E-01
SyRBo: 155.87, SR: 184.07, pval: 5.8E-03 !
SR: 5.02, SyRBo: 5.35, pval: 1.8E-01 =
SR: 1.26, SyRBo: 1.27, pval: 5.5E-01 =
SyRBo: 0.67, SR: 0.69, pval: 3.1E-02 !
SyRBo: 0.49, SR: 0.5, pval: 5.4E-01
SR: 42367.13, SyRBo: 42794.6, pval: 8.7E-01 =
SR: 179.19, SyRBo: 183.2, pval: 6.9E-01 =
SyRBo: 0.57, SR: 0.59, pval: 8.1E-03 !
SR: 838.3, SyRBo: 841.71, pval: 9.2E-01 =
SR: 838.25, SyRBo: 871.41, pval: 4.8E-01 =
SR: 4.23, SyRBo: 4.34, pval: 2.1E-01 =
SyRBo: 30.41, SR: 33.93, pval: 1.8E-01
SyRBo: 0.4, SR: 0.45, pval: 0.0E+00 !
SyRBo: 0.7, SR: 0.72, pval: 3.1E-03 !
SyRBo: 0.68, SR: 0.72, pval: 0.0E+00 !
SyRBo: 0.72, SR: 0.74, pval: 0.0E+00 !
SyRBo: 0.68, SR: 0.71, pval: 0.0E+00 !
SyRBo: 0.68, SR: 0.7, pval: 0.0E+00 !
SyRBo: 0.72, SR: 0.73, pval: 1.7E-01
SyRBo: 0.68, SR: 0.71, pval: 0.0E+00 !
SyRBo: 0.37, SR: 0.41, pval: 0.0E+00 !
SyRBo: 0.71, SR: 0.74, pval: 3.9E-02 !
SyRBo: 0.7, SR: 0.72, pval: 1.0E-04 !
SyRBo: 0.61, SR: 0.71, pval: 0.0E+00 !
SyRBo: 0.64, SR: 0.71, pval: 0.0E+00 !
SyRBo: 0.35, SR: 0.44, pval: 0.0E+00 !
SyRBo: 0.6, SR: 0.68, pval: 0.0E+00 !
SyRBo: 0.58, SR: 0.68, pval: 0.0E+00 !
SyRBo: 0.36, SR: 0.43, pval: 0.0E+00 !
SyRBo: 0.56, SR: 0.66, pval: 0.0E+00 !
SyRBo: 0.56, SR: 0.67, pval: 0.0E+00 !
SyRBo: 0.68, SR: 0.72, pval: 0.0E+00 !
SyRBo: 0.39, SR: 0.41, pval: 7.3E-03 !
SyRBo: 0.66, SR: 0.71, pval: 0.0E+00 !
SyRBo: 0.69, SR: 0.7, pval: 5.3E-01
SyRBo: 0.59, SR: 0.67, pval: 0.0E+00 !
SyRBo: 0.71, SR: 0.73, pval: 1.4E-02 !
SyRBo: 0.61, SR: 0.7, pval: 0.0E+00 !
SyRBo: 0.37, SR: 0.44, pval: 0.0E+00 !
SyRBo: 0.61, SR: 0.67, pval: 8.0E-03 !
SyRBo: 0.55, SR: 0.69, pval: 0.0E+00 !
SyRBo: 0.58, SR: 0.64, pval: 0.0E+00 !
SyRBo: 0.66, SR: 0.7, pval: 0.0E+00 !
SyRBo: 0.74, SR: 0.74, pval: 6.5E-01
SyRBo: 0.57, SR: 0.65, pval: 0.0E+00 !
SyRBo: 0.71, SR: 0.73, pval: 4.0E-04 !
SyRBo: 0.7, SR: 0.73, pval: 0.0E+00 !
SyRBo: 0.41, SR: 0.45, pval: 8.0E-03 !
SyRBo: 0.71, SR: 0.73, pval: 3.0E-04 !
SyRBo: 0.62, SR: 0.68, pval: 0.0E+00 !
SyRBo: 0.42, SR: 0.47, pval: 0.0E+00 !
SyRBo: 0.71, SR: 0.72, pval: 4.6E-01
SyRBo: 0.61, SR: 0.69, pval: 0.0E+00 !
SyRBo: 0.59, SR: 0.66, pval: 0.0E+00 !
SyRBo: 0.56, SR: 0.66, pval: 0.0E+00 !
SyRBo: 0.37, SR: 0.43, pval: 0.0E+00 !
SyRBo: 0.64, SR: 0.68, pval: 9.0E-04 !
SyRBo: 0.39, SR: 0.52, pval: 0.0E+00 !
SyRBo: 0.76, SR: 0.76, pval: 7.5E-01
SyRBo: 0.62, SR: 0.73, pval: 0.0E+00 !
SyRBo: 0.74, SR: 0.76, pval: 2.1E-02 !
SyRBo: 0.72, SR: 0.74, pval: 2.0E-01
SyRBo: 0.7, SR: 0.71, pval: 3.6E-01
SyRBo: 0.63, SR: 0.69, pval: 0.0E+00 !
SyRBo: 0.64, SR: 0.73, pval: 0.0E+00 !
SyRBo: 0.74, SR: 0.74, pval: 8.4E-01
SyRBo: 0.37, SR: 0.46, pval: 0.0E+00 !
SyRBo: 0.37, SR: 0.4, pval: 0.0E+00 !
SyRBo: 0.5, SR: 0.53, pval: 1.7E-02 !
SyRBo: 0.37, SR: 0.41, pval: 0.0E+00 !
SyRBo: 0.37, SR: 0.46, pval: 0.0E+00 !
SyRBo: 0.55, SR: 0.65, pval: 0.0E+00 !
SyRBo: 0.64, SR: 0.69, pval: 0.0E+00 !
SyRBo: 0.73, SR: 0.74, pval: 1.4E-01
SyRBo: 7231.48, SR: 7604.58, pval: 5.2E-01
SR: 19.49, SyRBo: 20.01, pval: 2.4E-01 =
SR: 5.3, SyRBo: 5.3, pval: 9.7E-01 =
SyRBo: 1.58, SR: 1.62, pval: 3.0E-01
SR: 2.44, SyRBo: 2.46, pval: 8.1E-01 =
SR: 13.04, SyRBo: 14.99, pval: 1.0E-04
SyRBo: 212.82, SR: 440.08, pval: 1.0E-04 !
SR: 16.79, SyRBo: 18.34, pval: 9.0E-03
SR: 49.57, SyRBo: 51.69, pval: 1.8E-01 =
SyRBo: 8.2, SR: 8.88, pval: 0.0E+00 !

run times
SyRBo: 70.24s, SR: 24.65s
SyRBo: 70.79s, SR: 25.03s
SyRBo: 69.2s, SR: 22.65s
SyRBo: 72.45s, SR: 24.73s
SyRBo: 134.46s, SR: 57.85s
SyRBo: 74.28s, SR: 30.96s
SyRBo: 72.9s, SR: 30.64s
SyRBo: 558.45s, SR: 164.11s
SyRBo: 465.0s, SR: 133.33s
SyRBo: 68.09s, SR: 23.48s
SyRBo: 127.75s, SR: 64.49s
SyRBo: 73.73s, SR: 27.64s
SyRBo: 244.09s, SR: 101.61s
SyRBo: 91.17s, SR: 38.4s
SyRBo: 363.3s, SR: 144.26s
SyRBo: 140.1s, SR: 60.43s
SyRBo: 92.19s, SR: 35.46s
SyRBo: 81.01s, SR: 27.42s
SyRBo: 91.61s, SR: 39.44s
SyRBo: 782.84s, SR: 187.09s
SyRBo: 323.15s, SR: 137.38s
SyRBo: 84.6s, SR: 28.94s
SyRBo: 253.91s, SR: 91.68s
SyRBo: 209.53s, SR: 55.88s
SyRBo: 104.88s, SR: 41.81s
SyRBo: 208.96s, SR: 89.89s
SyRBo: 79.88s, SR: 25.77s
SyRBo: 79.92s, SR: 26.46s
SyRBo: 77.19s, SR: 25.52s
SyRBo: 75.06s, SR: 25.16s
SyRBo: 75.45s, SR: 24.92s
SyRBo: 79.06s, SR: 26.17s
SyRBo: 78.02s, SR: 26.38s
SyRBo: 79.93s, SR: 26.46s
SyRBo: 80.78s, SR: 28.43s
SyRBo: 79.19s, SR: 25.39s
SyRBo: 81.93s, SR: 27.1s
SyRBo: 82.54s, SR: 26.59s
SyRBo: 80.74s, SR: 26.65s
SyRBo: 82.43s, SR: 27.34s
SyRBo: 80.88s, SR: 26.18s
SyRBo: 81.55s, SR: 26.48s
SyRBo: 80.75s, SR: 27.68s
SyRBo: 83.39s, SR: 26.86s
SyRBo: 81.61s, SR: 26.23s
SyRBo: 78.76s, SR: 25.62s
SyRBo: 77.87s, SR: 27.07s
SyRBo: 79.58s, SR: 26.2s
SyRBo: 79.46s, SR: 26.31s
SyRBo: 82.15s, SR: 26.38s
SyRBo: 78.32s, SR: 26.14s
SyRBo: 82.63s, SR: 26.62s
SyRBo: 79.77s, SR: 25.95s
SyRBo: 84.03s, SR: 28.26s
SyRBo: 82.23s, SR: 26.03s
SyRBo: 79.23s, SR: 25.57s
SyRBo: 79.95s, SR: 26.18s
SyRBo: 80.63s, SR: 26.95s
SyRBo: 80.92s, SR: 26.7s
SyRBo: 78.7s, SR: 26.25s
SyRBo: 79.9s, SR: 26.4s
SyRBo: 78.91s, SR: 25.96s
SyRBo: 66.25s, SR: 22.17s
SyRBo: 81.44s, SR: 26.48s
SyRBo: 78.17s, SR: 25.11s
SyRBo: 78.22s, SR: 26.39s
SyRBo: 85.52s, SR: 27.54s
SyRBo: 86.2s, SR: 27.97s
SyRBo: 82.42s, SR: 26.2s
SyRBo: 78.32s, SR: 26.68s
SyRBo: 80.8s, SR: 26.22s
SyRBo: 61.06s, SR: 20.16s
SyRBo: 79.6s, SR: 26.58s
SyRBo: 81.02s, SR: 26.14s
SyRBo: 78.8s, SR: 26.08s
SyRBo: 80.38s, SR: 26.48s
SyRBo: 80.26s, SR: 26.57s
SyRBo: 80.1s, SR: 26.1s
SyRBo: 80.7s, SR: 26.13s
SyRBo: 77.4s, SR: 26.33s
SyRBo: 76.0s, SR: 24.91s
SyRBo: 82.74s, SR: 28.93s
SyRBo: 77.58s, SR: 26.06s
SyRBo: 62.56s, SR: 21.2s
SyRBo: 63.3s, SR: 20.95s
SyRBo: 87.52s, SR: 28.95s
SyRBo: 84.08s, SR: 27.15s
SyRBo: 77.71s, SR: 25.61s
SyRBo: 660.4s, SR: 183.78s
SyRBo: 167.69s, SR: 72.88s
SyRBo: 97.79s, SR: 38.17s
SyRBo: 83.81s, SR: 32.08s
SyRBo: 72.36s, SR: 28.73s
SyRBo: 130.96s, SR: 46.48s
SyRBo: 408.21s, SR: 125.28s
SyRBo: 155.94s, SR: 57.64s
SyRBo: 172.97s, SR: 75.44s
SyRBo: 100.15s, SR: 47.06s

10

Moshe Sipper, Jason H. Moore

Table 5 4-stage SyRBo: Results of all datasets.

dataset
1027 ESL
1028 SWD
1029 LEV
1030 ERA
1089 USCrime
1096 FacultySalaries
192 vineyard
195 auto price
207 autoPrice
210 cloud
228 elusage
229 pwLinear
230 machine cpu
4544 GeographicalOriginalofMusic
485 analcatdata vehicle
505 tecator
519 vinnie
522 pm10
523 analcatdata neavote
527 analcatdata election2000
542 pollution
547 no2
556 analcatdata apnea2
557 analcatdata apnea1
560 bodyfat
561 cpu
579 fri c0 250 5
581 fri c3 500 25
582 fri c1 500 25
583 fri c1 1000 50
584 fri c4 500 25
586 fri c3 1000 25
588 fri c4 1000 100
589 fri c2 1000 25
590 fri c0 1000 50
591 fri c1 100 10
592 fri c4 1000 25
593 fri c1 1000 10
594 fri c2 100 5
595 fri c0 1000 10
596 fri c2 250 5
597 fri c2 500 5
598 fri c0 1000 25
599 fri c2 1000 5
601 fri c1 250 5
602 fri c3 250 10
603 fri c0 250 50
604 fri c4 500 10
605 fri c2 250 25
606 fri c2 1000 10
607 fri c4 1000 50
608 fri c3 1000 10
609 fri c0 1000 5
611 fri c3 100 5
612 fri c1 1000 5
613 fri c3 250 5
615 fri c4 250 10
616 fri c4 500 50
617 fri c3 500 5
618 fri c3 1000 50
620 fri c1 1000 25
621 fri c0 100 10
622 fri c2 1000 50
623 fri c4 1000 10
624 fri c0 100 5
626 fri c2 500 50
627 fri c2 500 10
628 fri c3 1000 5
631 fri c1 500 5
633 fri c0 500 25
634 fri c2 100 10
635 fri c0 250 10
637 fri c1 500 50
641 fri c1 500 10
643 fri c2 500 25
644 fri c4 250 25
645 fri c3 500 50
646 fri c3 500 10
647 fri c1 250 10
648 fri c1 250 50
649 fri c0 500 5
650 fri c0 500 50
651 fri c0 100 25
653 fri c0 250 25
654 fri c0 500 10
656 fri c1 100 5
657 fri c2 250 10
658 fri c3 250 25
659 sleuth ex1714
663 rabe 266
665 sleuth case2002
666 rmftsa ladata
678 visualizing environmental
687 sleuth ex1605
690 visualizing galaxy
695 chatfield 4
706 sleuth case1202
712 chscase geyser1

mean absolute error and pval
SyRBo: 1.0, SR: 1.04, pval: 2.0E-04 !
SyRBo: 0.61, SR: 0.62, pval: 1.3E-02 !
SyRBo: 0.62, SR: 0.65, pval: 0.0E+00 !
SyRBo: 1.42, SR: 1.45, pval: 2.0E-04 !
SyRBo: 25.17, SR: 25.74, pval: 7.2E-01
SR: 3.51, SyRBo: 3.53, pval: 8.4E-01 =
SR: 2.34, SyRBo: 2.55, pval: 4.0E-02
SyRBo: 1881.2, SR: 2047.73, pval: 8.4E-03 !
SyRBo: 1883.63, SR: 2046.39, pval: 6.0E-02
SyRBo: 0.49, SR: 0.5, pval: 9.4E-01
SyRBo: 12.45, SR: 14.36, pval: 6.0E-04 !
SyRBo: 1.49, SR: 1.59, pval: 1.4E-02 !
SyRBo: 43.28, SR: 47.09, pval: 7.9E-02
SyRBo: 0.49, SR: 0.49, pval: 2.9E-01
SyRBo: 151.23, SR: 186.52, pval: 8.0E-04 !
SR: 5.01, SyRBo: 5.05, pval: 9.0E-01 =
SR: 1.26, SyRBo: 1.3, pval: 9.1E-02 =
SyRBo: 0.66, SR: 0.69, pval: 2.0E-04 !
SyRBo: 0.5, SR: 0.5, pval: 9.4E-01
SR: 41409.25, SyRBo: 43867.25, pval: 4.9E-01 =
SyRBo: 180.88, SR: 188.26, pval: 4.4E-01
SyRBo: 0.56, SR: 0.59, pval: 4.0E-04 !
SR: 869.07, SyRBo: 881.56, pval: 8.6E-01 =
SyRBo: 861.47, SR: 869.01, pval: 9.1E-01
SR: 4.24, SyRBo: 4.37, pval: 3.0E-01 =
SyRBo: 29.33, SR: 35.67, pval: 3.6E-03 !
SyRBo: 0.38, SR: 0.45, pval: 0.0E+00 !
SyRBo: 0.68, SR: 0.72, pval: 0.0E+00 !
SyRBo: 0.66, SR: 0.72, pval: 0.0E+00 !
SyRBo: 0.7, SR: 0.74, pval: 0.0E+00 !
SyRBo: 0.67, SR: 0.72, pval: 0.0E+00 !
SyRBo: 0.66, SR: 0.71, pval: 0.0E+00 !
SyRBo: 0.72, SR: 0.72, pval: 6.5E-01
SyRBo: 0.67, SR: 0.71, pval: 0.0E+00 !
SyRBo: 0.36, SR: 0.4, pval: 0.0E+00 !
SyRBo: 0.68, SR: 0.74, pval: 6.6E-03 !
SyRBo: 0.69, SR: 0.72, pval: 0.0E+00 !
SyRBo: 0.58, SR: 0.71, pval: 0.0E+00 !
SyRBo: 0.62, SR: 0.7, pval: 0.0E+00 !
SyRBo: 0.33, SR: 0.44, pval: 0.0E+00 !
SyRBo: 0.59, SR: 0.69, pval: 0.0E+00 !
SyRBo: 0.57, SR: 0.67, pval: 0.0E+00 !
SyRBo: 0.35, SR: 0.43, pval: 0.0E+00 !
SyRBo: 0.54, SR: 0.67, pval: 0.0E+00 !
SyRBo: 0.53, SR: 0.66, pval: 0.0E+00 !
SyRBo: 0.66, SR: 0.73, pval: 0.0E+00 !
SyRBo: 0.39, SR: 0.4, pval: 2.9E-02 !
SyRBo: 0.63, SR: 0.71, pval: 0.0E+00 !
SyRBo: 0.68, SR: 0.7, pval: 6.7E-02
SyRBo: 0.57, SR: 0.68, pval: 0.0E+00 !
SyRBo: 0.72, SR: 0.73, pval: 6.9E-02
SyRBo: 0.59, SR: 0.7, pval: 0.0E+00 !
SyRBo: 0.34, SR: 0.44, pval: 0.0E+00 !
SyRBo: 0.62, SR: 0.65, pval: 1.3E-02 !
SyRBo: 0.54, SR: 0.69, pval: 0.0E+00 !
SyRBo: 0.56, SR: 0.64, pval: 0.0E+00 !
SyRBo: 0.64, SR: 0.7, pval: 0.0E+00 !
SyRBo: 0.73, SR: 0.74, pval: 7.3E-01
SyRBo: 0.55, SR: 0.66, pval: 0.0E+00 !
SyRBo: 0.7, SR: 0.72, pval: 0.0E+00 !
SyRBo: 0.68, SR: 0.74, pval: 0.0E+00 !
SyRBo: 0.4, SR: 0.45, pval: 0.0E+00 !
SyRBo: 0.71, SR: 0.73, pval: 6.0E-04 !
SyRBo: 0.6, SR: 0.69, pval: 0.0E+00 !
SyRBo: 0.41, SR: 0.47, pval: 0.0E+00 !
SyRBo: 0.72, SR: 0.73, pval: 8.7E-02
SyRBo: 0.58, SR: 0.69, pval: 0.0E+00 !
SyRBo: 0.58, SR: 0.66, pval: 0.0E+00 !
SyRBo: 0.54, SR: 0.67, pval: 0.0E+00 !
SyRBo: 0.34, SR: 0.42, pval: 0.0E+00 !
SyRBo: 0.67, SR: 0.71, pval: 7.3E-03 !
SyRBo: 0.37, SR: 0.52, pval: 0.0E+00 !
SyRBo: 0.74, SR: 0.76, pval: 5.0E-04 !
SyRBo: 0.59, SR: 0.74, pval: 0.0E+00 !
SyRBo: 0.71, SR: 0.76, pval: 0.0E+00 !
SyRBo: 0.72, SR: 0.75, pval: 4.9E-03 !
SR: 0.7, SyRBo: 0.7, pval: 7.6E-01 =
SyRBo: 0.61, SR: 0.69, pval: 0.0E+00 !
SyRBo: 0.61, SR: 0.74, pval: 0.0E+00 !
SyRBo: 0.72, SR: 0.75, pval: 2.1E-03 !
SyRBo: 0.34, SR: 0.46, pval: 0.0E+00 !
SyRBo: 0.36, SR: 0.39, pval: 0.0E+00 !
SyRBo: 0.51, SR: 0.53, pval: 4.4E-02 !
SyRBo: 0.36, SR: 0.41, pval: 0.0E+00 !
SyRBo: 0.35, SR: 0.46, pval: 0.0E+00 !
SyRBo: 0.54, SR: 0.64, pval: 0.0E+00 !
SyRBo: 0.63, SR: 0.69, pval: 0.0E+00 !
SyRBo: 0.72, SR: 0.75, pval: 8.2E-03 !
SyRBo: 6437.7, SR: 7641.02, pval: 7.0E-03 !
SR: 19.85, SyRBo: 20.79, pval: 6.7E-02 =
SR: 5.06, SyRBo: 5.15, pval: 4.3E-01 =
SyRBo: 1.58, SR: 1.65, pval: 3.1E-02 !
SR: 2.44, SyRBo: 2.46, pval: 8.1E-01 =
SR: 13.27, SyRBo: 15.03, pval: 1.5E-03
SyRBo: 219.9, SR: 470.38, pval: 0.0E+00 !
SR: 16.84, SyRBo: 17.27, pval: 4.3E-01 =
SR: 46.85, SyRBo: 48.25, pval: 2.8E-01 =
SyRBo: 8.27, SR: 9.11, pval: 0.0E+00 !

run times
SyRBo: 93.37s, SR: 24.88s
SyRBo: 93.66s, SR: 24.91s
SyRBo: 92.83s, SR: 22.9s
SyRBo: 96.63s, SR: 24.49s
SyRBo: 168.69s, SR: 59.24s
SyRBo: 87.13s, SR: 27.14s
SyRBo: 97.59s, SR: 31.41s
SyRBo: 606.2s, SR: 156.64s
SyRBo: 759.26s, SR: 155.12s
SyRBo: 89.57s, SR: 23.4s
SyRBo: 176.15s, SR: 77.55s
SyRBo: 111.62s, SR: 33.75s
SyRBo: 273.04s, SR: 91.55s
SyRBo: 117.26s, SR: 38.11s
SyRBo: 391.71s, SR: 131.13s
SyRBo: 161.8s, SR: 58.38s
SyRBo: 118.67s, SR: 35.63s
SyRBo: 111.11s, SR: 28.72s
SyRBo: 114.11s, SR: 37.29s
SyRBo: 865.92s, SR: 160.52s
SyRBo: 367.71s, SR: 141.35s
SyRBo: 109.17s, SR: 28.85s
SyRBo: 238.22s, SR: 75.84s
SyRBo: 215.12s, SR: 54.48s
SyRBo: 129.35s, SR: 40.74s
SyRBo: 254.82s, SR: 95.29s
SyRBo: 83.29s, SR: 20.24s
SyRBo: 107.74s, SR: 26.62s
SyRBo: 83.86s, SR: 20.72s
SyRBo: 107.04s, SR: 26.75s
SyRBo: 106.2s, SR: 26.11s
SyRBo: 106.28s, SR: 26.3s
SyRBo: 105.29s, SR: 26.7s
SyRBo: 89.31s, SR: 22.21s
SyRBo: 107.96s, SR: 28.67s
SyRBo: 107.71s, SR: 26.22s
SyRBo: 104.6s, SR: 25.92s
SyRBo: 84.35s, SR: 20.31s
SyRBo: 86.38s, SR: 21.38s
SyRBo: 110.51s, SR: 27.53s
SyRBo: 106.65s, SR: 26.23s
SyRBo: 106.16s, SR: 26.2s
SyRBo: 106.81s, SR: 27.65s
SyRBo: 110.59s, SR: 26.69s
SyRBo: 106.99s, SR: 26.05s
SyRBo: 107.64s, SR: 26.21s
SyRBo: 104.74s, SR: 27.57s
SyRBo: 105.4s, SR: 25.79s
SyRBo: 103.7s, SR: 25.76s
SyRBo: 110.65s, SR: 26.65s
SyRBo: 111.03s, SR: 27.78s
SyRBo: 118.4s, SR: 28.63s
SyRBo: 116.25s, SR: 28.29s
SyRBo: 106.5s, SR: 26.92s
SyRBo: 95.28s, SR: 22.96s
SyRBo: 85.81s, SR: 20.96s
SyRBo: 103.59s, SR: 25.5s
SyRBo: 101.64s, SR: 25.4s
SyRBo: 106.97s, SR: 26.56s
SyRBo: 106.08s, SR: 26.47s
SyRBo: 109.58s, SR: 27.21s
SyRBo: 103.48s, SR: 25.55s
SyRBo: 106.03s, SR: 26.9s
SyRBo: 109.83s, SR: 26.66s
SyRBo: 110.93s, SR: 26.78s
SyRBo: 104.49s, SR: 26.41s
SyRBo: 106.73s, SR: 25.88s
SyRBo: 108.33s, SR: 26.76s
SyRBo: 107.88s, SR: 26.04s
SyRBo: 104.15s, SR: 26.69s
SyRBo: 106.29s, SR: 26.07s
SyRBo: 102.86s, SR: 25.5s
SyRBo: 104.06s, SR: 26.12s
SyRBo: 108.72s, SR: 26.43s
SyRBo: 105.35s, SR: 26.16s
SyRBo: 104.33s, SR: 25.79s
SyRBo: 103.7s, SR: 25.8s
SyRBo: 91.22s, SR: 22.33s
SyRBo: 103.42s, SR: 25.12s
SyRBo: 108.59s, SR: 27.71s
SyRBo: 112.89s, SR: 27.46s
SyRBo: 85.82s, SR: 22.59s
SyRBo: 111.2s, SR: 28.12s
SyRBo: 83.61s, SR: 21.3s
SyRBo: 84.78s, SR: 21.04s
SyRBo: 86.37s, SR: 21.66s
SyRBo: 105.03s, SR: 25.64s
SyRBo: 103.48s, SR: 25.53s
SyRBo: 723.0s, SR: 171.93s
SyRBo: 188.09s, SR: 66.1s
SyRBo: 125.81s, SR: 37.11s
SyRBo: 110.41s, SR: 31.81s
SyRBo: 116.57s, SR: 35.84s
SyRBo: 187.9s, SR: 58.29s
SyRBo: 599.04s, SR: 171.58s
SyRBo: 245.5s, SR: 82.54s
SyRBo: 286.46s, SR: 95.73s
SyRBo: 114.63s, SR: 43.05s

Symbolic-Regression Boosting

11

Table 6 5-stage SyRBo: Results of all datasets.

dataset
1027 ESL
1028 SWD
1029 LEV
1030 ERA
1089 USCrime
1096 FacultySalaries
192 vineyard
195 auto price
207 autoPrice
210 cloud
228 elusage
229 pwLinear
230 machine cpu
4544 GeographicalOriginalofMusic
485 analcatdata vehicle
505 tecator
519 vinnie
522 pm10
523 analcatdata neavote
527 analcatdata election2000
542 pollution
547 no2
556 analcatdata apnea2
557 analcatdata apnea1
560 bodyfat
561 cpu
579 fri c0 250 5
581 fri c3 500 25
582 fri c1 500 25
583 fri c1 1000 50
584 fri c4 500 25
586 fri c3 1000 25
588 fri c4 1000 100
589 fri c2 1000 25
590 fri c0 1000 50
591 fri c1 100 10
592 fri c4 1000 25
593 fri c1 1000 10
594 fri c2 100 5
595 fri c0 1000 10
596 fri c2 250 5
597 fri c2 500 5
598 fri c0 1000 25
599 fri c2 1000 5
601 fri c1 250 5
602 fri c3 250 10
603 fri c0 250 50
604 fri c4 500 10
605 fri c2 250 25
606 fri c2 1000 10
607 fri c4 1000 50
608 fri c3 1000 10
609 fri c0 1000 5
611 fri c3 100 5
612 fri c1 1000 5
613 fri c3 250 5
615 fri c4 250 10
616 fri c4 500 50
617 fri c3 500 5
618 fri c3 1000 50
620 fri c1 1000 25
621 fri c0 100 10
622 fri c2 1000 50
623 fri c4 1000 10
624 fri c0 100 5
626 fri c2 500 50
627 fri c2 500 10
628 fri c3 1000 5
631 fri c1 500 5
633 fri c0 500 25
634 fri c2 100 10
635 fri c0 250 10
637 fri c1 500 50
641 fri c1 500 10
643 fri c2 500 25
644 fri c4 250 25
645 fri c3 500 50
646 fri c3 500 10
647 fri c1 250 10
648 fri c1 250 50
649 fri c0 500 5
650 fri c0 500 50
651 fri c0 100 25
653 fri c0 250 25
654 fri c0 500 10
656 fri c1 100 5
657 fri c2 250 10
658 fri c3 250 25
659 sleuth ex1714
663 rabe 266
665 sleuth case2002
666 rmftsa ladata
678 visualizing environmental
687 sleuth ex1605
690 visualizing galaxy
695 chatfield 4
706 sleuth case1202
712 chscase geyser1

mean absolute error and pval
SyRBo: 0.99, SR: 1.04, pval: 0.0E+00 !
SyRBo: 0.6, SR: 0.62, pval: 3.2E-02 !
SyRBo: 0.61, SR: 0.65, pval: 0.0E+00 !
SyRBo: 1.41, SR: 1.46, pval: 0.0E+00 !
SR: 25.79, SyRBo: 26.52, pval: 6.2E-01 =
SR: 3.44, SyRBo: 3.66, pval: 2.0E-01 =
SR: 2.45, SyRBo: 2.53, pval: 2.7E-01 =
SyRBo: 1846.49, SR: 1984.64, pval: 2.5E-02 !
SyRBo: 1917.2, SR: 2004.04, pval: 3.0E-01
SyRBo: 0.5, SR: 0.51, pval: 5.9E-01
SyRBo: 11.83, SR: 13.25, pval: 8.6E-03 !
SyRBo: 1.49, SR: 1.58, pval: 4.6E-02 !
SyRBo: 41.55, SR: 47.64, pval: 6.6E-03 !
SyRBo: 0.49, SR: 0.5, pval: 5.6E-01
SyRBo: 152.36, SR: 185.49, pval: 6.0E-04 !
SyRBo: 5.03, SR: 5.42, pval: 9.3E-02
SR: 1.26, SyRBo: 1.28, pval: 2.0E-01 =
SyRBo: 0.66, SR: 0.69, pval: 0.0E+00 !
SyRBo: 0.5, SR: 0.51, pval: 2.4E-01
SyRBo: 41978.87, SR: 42335.38, pval: 9.2E-01
SyRBo: 184.53, SR: 186.47, pval: 8.6E-01
SyRBo: 0.56, SR: 0.59, pval: 1.2E-03 !
SyRBo: 831.42, SR: 837.88, pval: 9.0E-01
SR: 833.02, SyRBo: 845.73, pval: 7.5E-01 =
SyRBo: 4.26, SR: 4.28, pval: 9.1E-01
SyRBo: 28.02, SR: 32.76, pval: 2.5E-02 !
SyRBo: 0.38, SR: 0.45, pval: 0.0E+00 !
SyRBo: 0.68, SR: 0.72, pval: 0.0E+00 !
SyRBo: 0.66, SR: 0.71, pval: 0.0E+00 !
SyRBo: 0.7, SR: 0.74, pval: 0.0E+00 !
SyRBo: 0.66, SR: 0.71, pval: 0.0E+00 !
SyRBo: 0.67, SR: 0.7, pval: 0.0E+00 !
SyRBo: 0.72, SR: 0.72, pval: 5.1E-01
SyRBo: 0.67, SR: 0.71, pval: 0.0E+00 !
SyRBo: 0.35, SR: 0.4, pval: 0.0E+00 !
SyRBo: 0.68, SR: 0.74, pval: 1.1E-02 !
SyRBo: 0.68, SR: 0.72, pval: 0.0E+00 !
SyRBo: 0.55, SR: 0.71, pval: 0.0E+00 !
SyRBo: 0.61, SR: 0.68, pval: 0.0E+00 !
SyRBo: 0.31, SR: 0.44, pval: 0.0E+00 !
SyRBo: 0.58, SR: 0.69, pval: 0.0E+00 !
SyRBo: 0.55, SR: 0.67, pval: 0.0E+00 !
SyRBo: 0.33, SR: 0.43, pval: 0.0E+00 !
SyRBo: 0.53, SR: 0.67, pval: 0.0E+00 !
SyRBo: 0.52, SR: 0.66, pval: 0.0E+00 !
SyRBo: 0.63, SR: 0.72, pval: 0.0E+00 !
SyRBo: 0.38, SR: 0.41, pval: 0.0E+00 !
SyRBo: 0.62, SR: 0.72, pval: 0.0E+00 !
SyRBo: 0.67, SR: 0.7, pval: 5.1E-03 !
SyRBo: 0.56, SR: 0.68, pval: 0.0E+00 !
SyRBo: 0.71, SR: 0.73, pval: 3.3E-02 !
SyRBo: 0.57, SR: 0.7, pval: 0.0E+00 !
SyRBo: 0.33, SR: 0.44, pval: 0.0E+00 !
SyRBo: 0.61, SR: 0.66, pval: 3.3E-03 !
SyRBo: 0.53, SR: 0.68, pval: 0.0E+00 !
SyRBo: 0.56, SR: 0.65, pval: 0.0E+00 !
SyRBo: 0.64, SR: 0.7, pval: 0.0E+00 !
SyRBo: 0.73, SR: 0.74, pval: 3.6E-01
SyRBo: 0.55, SR: 0.64, pval: 0.0E+00 !
SyRBo: 0.71, SR: 0.73, pval: 1.8E-03 !
SyRBo: 0.66, SR: 0.74, pval: 0.0E+00 !
SyRBo: 0.39, SR: 0.47, pval: 0.0E+00 !
SyRBo: 0.7, SR: 0.73, pval: 0.0E+00 !
SyRBo: 0.58, SR: 0.69, pval: 0.0E+00 !
SyRBo: 0.41, SR: 0.47, pval: 0.0E+00 !
SyRBo: 0.71, SR: 0.73, pval: 8.3E-02
SyRBo: 0.58, SR: 0.69, pval: 0.0E+00 !
SyRBo: 0.57, SR: 0.66, pval: 0.0E+00 !
SyRBo: 0.54, SR: 0.68, pval: 0.0E+00 !
SyRBo: 0.33, SR: 0.43, pval: 0.0E+00 !
SyRBo: 0.64, SR: 0.7, pval: 8.9E-03 !
SyRBo: 0.36, SR: 0.51, pval: 0.0E+00 !
SyRBo: 0.75, SR: 0.76, pval: 1.6E-01
SyRBo: 0.57, SR: 0.73, pval: 0.0E+00 !
SyRBo: 0.72, SR: 0.75, pval: 8.3E-03 !
SyRBo: 0.7, SR: 0.74, pval: 2.5E-03 !
SyRBo: 0.69, SR: 0.71, pval: 2.4E-02 !
SyRBo: 0.58, SR: 0.69, pval: 0.0E+00 !
SyRBo: 0.6, SR: 0.74, pval: 0.0E+00 !
SyRBo: 0.73, SR: 0.74, pval: 5.4E-01
SyRBo: 0.34, SR: 0.46, pval: 0.0E+00 !
SyRBo: 0.34, SR: 0.39, pval: 0.0E+00 !
SyRBo: 0.51, SR: 0.53, pval: 4.6E-02 !
SyRBo: 0.35, SR: 0.41, pval: 0.0E+00 !
SyRBo: 0.34, SR: 0.46, pval: 0.0E+00 !
SyRBo: 0.55, SR: 0.64, pval: 0.0E+00 !
SyRBo: 0.62, SR: 0.68, pval: 0.0E+00 !
SyRBo: 0.73, SR: 0.74, pval: 1.2E-01
SyRBo: 6464.12, SR: 7876.73, pval: 5.2E-02
SR: 19.33, SyRBo: 20.57, pval: 1.4E-02
SR: 5.18, SyRBo: 5.37, pval: 4.0E-01 =
SyRBo: 1.59, SR: 1.63, pval: 1.6E-01
SR: 2.42, SyRBo: 2.49, pval: 6.4E-01 =
SR: 13.24, SyRBo: 14.84, pval: 1.1E-03
SyRBo: 205.0, SR: 444.22, pval: 0.0E+00 !
SR: 17.49, SyRBo: 18.39, pval: 6.1E-02 =
SR: 48.42, SyRBo: 52.14, pval: 1.5E-01 =
SyRBo: 8.32, SR: 8.9, pval: 3.0E-04 !

run times
SyRBo: 138.45s, SR: 30.02s
SyRBo: 112.18s, SR: 24.21s
SyRBo: 108.52s, SR: 21.54s
SyRBo: 114.87s, SR: 23.88s
SyRBo: 244.05s, SR: 70.49s
SyRBo: 137.41s, SR: 36.12s
SyRBo: 145.21s, SR: 37.57s
SyRBo: 1136.73s, SR: 181.96s
SyRBo: 840.85s, SR: 146.49s
SyRBo: 136.83s, SR: 28.6s
SyRBo: 168.85s, SR: 59.4s
SyRBo: 147.58s, SR: 35.66s
SyRBo: 302.39s, SR: 89.29s
SyRBo: 139.81s, SR: 37.08s
SyRBo: 402.2s, SR: 123.11s
SyRBo: 192.01s, SR: 56.36s
SyRBo: 144.14s, SR: 34.81s
SyRBo: 109.71s, SR: 22.76s
SyRBo: 145.96s, SR: 40.78s
SyRBo: 1276.47s, SR: 189.6s
SyRBo: 482.44s, SR: 152.25s
SyRBo: 149.77s, SR: 32.23s
SyRBo: 374.25s, SR: 108.94s
SyRBo: 333.67s, SR: 66.34s
SyRBo: 127.64s, SR: 31.6s
SyRBo: 268.56s, SR: 94.84s
SyRBo: 127.54s, SR: 24.79s
SyRBo: 105.16s, SR: 20.78s
SyRBo: 104.49s, SR: 20.64s
SyRBo: 109.61s, SR: 21.76s
SyRBo: 131.15s, SR: 26.05s
SyRBo: 111.2s, SR: 21.99s
SyRBo: 109.24s, SR: 21.66s
SyRBo: 131.08s, SR: 26.12s
SyRBo: 130.53s, SR: 27.88s
SyRBo: 108.96s, SR: 21.35s
SyRBo: 106.21s, SR: 20.99s
SyRBo: 108.31s, SR: 20.94s
SyRBo: 111.13s, SR: 22.03s
SyRBo: 106.28s, SR: 21.17s
SyRBo: 104.44s, SR: 20.42s
SyRBo: 106.51s, SR: 20.93s
SyRBo: 107.87s, SR: 22.01s
SyRBo: 107.85s, SR: 20.91s
SyRBo: 132.58s, SR: 25.88s
SyRBo: 103.12s, SR: 19.87s
SyRBo: 104.63s, SR: 21.89s
SyRBo: 107.77s, SR: 21.26s
SyRBo: 100.7s, SR: 20.1s
SyRBo: 132.9s, SR: 25.78s
SyRBo: 128.27s, SR: 25.68s
SyRBo: 137.65s, SR: 26.7s
SyRBo: 137.83s, SR: 26.65s
SyRBo: 133.97s, SR: 27.56s
SyRBo: 142.24s, SR: 27.26s
SyRBo: 138.42s, SR: 27.06s
SyRBo: 105.66s, SR: 20.78s
SyRBo: 129.48s, SR: 25.82s
SyRBo: 134.39s, SR: 26.93s
SyRBo: 128.38s, SR: 25.71s
SyRBo: 128.35s, SR: 25.35s
SyRBo: 125.76s, SR: 24.98s
SyRBo: 130.39s, SR: 26.39s
SyRBo: 137.99s, SR: 26.69s
SyRBo: 132.62s, SR: 25.69s
SyRBo: 127.3s, SR: 25.7s
SyRBo: 129.13s, SR: 25.24s
SyRBo: 108.94s, SR: 21.41s
SyRBo: 136.54s, SR: 26.34s
SyRBo: 101.34s, SR: 20.79s
SyRBo: 135.04s, SR: 26.73s
SyRBo: 132.75s, SR: 26.19s
SyRBo: 132.3s, SR: 26.57s
SyRBo: 128.61s, SR: 25.01s
SyRBo: 105.24s, SR: 20.85s
SyRBo: 129.54s, SR: 25.53s
SyRBo: 125.64s, SR: 24.97s
SyRBo: 134.8s, SR: 26.19s
SyRBo: 105.11s, SR: 20.46s
SyRBo: 128.78s, SR: 26.5s
SyRBo: 129.74s, SR: 25.21s
SyRBo: 128.54s, SR: 27.19s
SyRBo: 131.91s, SR: 26.73s
SyRBo: 127.19s, SR: 26.07s
SyRBo: 108.92s, SR: 21.67s
SyRBo: 141.71s, SR: 28.99s
SyRBo: 129.88s, SR: 25.33s
SyRBo: 125.15s, SR: 24.64s
SyRBo: 976.99s, SR: 183.76s
SyRBo: 212.59s, SR: 60.57s
SyRBo: 148.57s, SR: 37.37s
SyRBo: 134.26s, SR: 32.33s
SyRBo: 138.89s, SR: 34.34s
SyRBo: 217.53s, SR: 61.9s
SyRBo: 739.6s, SR: 171.47s
SyRBo: 253.22s, SR: 80.88s
SyRBo: 331.85s, SR: 85.21s
SyRBo: 178.29s, SR: 57.9s

