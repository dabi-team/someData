Inference and Optimization for Engineering and

Physical Systems

Doctoral Thesis
by

Mikhail Krechetov

Doctoral Program in Engineering Systems

Supervisor
Yury Maximov, Assistant Professor

© Mikhail Krechetov, 2021. All rights reserved.

2
2
0
2

g
u
A
9
2

]

G
L
.
s
c
[

1
v
0
8
8
3
1
.
8
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
Inference and Optimization for Engineering and Physical

Systems

by

Mikhail Krechetov

Wednesday 31st August, 2022 00:23

Submitted to the Skoltech Center for Energy Science and Technology
on August 2022, in partial fulfillment of the requirements for the
Doctoral Program in Engineering Systems

Abstract

The central object of this thesis is known under different names in the fields of
computer science and statistical mechanics. In computer science, it is called the
Maximum Cut problem, one of the famous twenty-one Karp’s original NP-hard
problems, while the same object from Physics is called the Ising Spin Glass model.
This model of a rich structure often appears as a reduction or reformulation of real-
world problems from computer science, physics and engineering. However, solving
this model exactly (finding the maximal cut or the ground state) is likely to stay
an intractable problem (unless P = NP) and requires the development of ad-hoc
heuristics for every particular family of instances.

One of the bright and beautiful connections between discrete and continuous
optimization is a Semidefinite Programming-based rounding scheme for Maximum
Cut. This procedure allows us to find a provably near-optimal solution; moreover,
this method is conjectured to be the best possible in polynomial time. In the first
two chapters of this thesis, we investigate local non-convex heuristics intended to
improve the rounding scheme.

In the last chapter of this thesis, we make one step further and aim to control
the solution of the problem we wanted to solve in previous chapters. We formulate
a bi-level optimization problem over the Ising model where we want to tweak the
interactions as little as possible so that the ground state of the resulting Ising model
satisfies the desired criteria. This kind of problem arises in pandemic modeling.
We show that when the interactions are non-negative, our bi-level optimization is
solvable in polynomial time using convex programming.

2

Publications

Main author

1. M. Krechetov, A. M. E. Sikaroudi, A. Efrat, V. Polishchuk, and M. Chertkov.

Prediction and prevention of pandemics via graphical model inference and

convex programming. Scientific Reports, 12(1), pages 1–11, 2021

2. M. Krechetov, Y. Maximov, J. Mareček, and M. Takáč. Entropy-penalized

semidefinite programming. IJCAI International Joint Conference on Artificial

Intelligence, pages 1123–1129, 2019

Co-author

1. I. Luchnikov, M. Krechetov, and S. Filippov. Riemannian geometry and

automatic differentiation for optimization problems of quantum physics and

quantum technologies. New Journal of Physics, 2021

2. R. Pogodin, M. Krechetov, and Y. Maximov. Efficient rank minimization to

tighten semidefinite programming for unconstrained binary quadratic opti-

mization. 55th Annual Allerton Conference on Communication, Control, and

Computing (Allerton), pages 1153–1159, 2017

3

4

Contents

1 Introduction

2 Background and Thesis Objective

9

11

3 Rank Constraints and Their Relaxations

3.1

13
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
3.1.1
Semidefinite relaxation . . . . . . . . . . . . . . . . . . . . . . 15
3.1.2 Related work . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
3.2 Rank Minimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
3.2.1 Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
3.2.2 Objective function’s relaxations . . . . . . . . . . . . . . . . . 17
3.2.3 Constraint relaxation . . . . . . . . . . . . . . . . . . . . . . . 19
3.3 Solving Rank Relaxation . . . . . . . . . . . . . . . . . . . . . . . . . 19
3.3.1 Efficient first-order procedure . . . . . . . . . . . . . . . . . . 20
3.3.2 Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
. . . . . . . . . . . . . . . . . . . . . . . 24
3.4.1
Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
3.4.2 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
3.5 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28

3.4 Computational experiments

4 Entropy-Penalized Semidefinite Programming

29
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
4.1
4.2 Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
4.2.1 Low-rank Relaxations and Penalized Problem . . . . . . . . . 32
4.2.2 Entropy Viewpoint . . . . . . . . . . . . . . . . . . . . . . . . 34
4.3 Exact Recovery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
4.4 MAP Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
. . . . . . . . . . . . . . . . . . . . . . . 38
4.5 Case Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
4.6 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43

4.4.1 Numerical Method.

5 Ising Model Control

45
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
5.1
5.2
Ising Model of Pandemic . . . . . . . . . . . . . . . . . . . . . . . . . 49
5.3 Prevention Challenge . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
. . . . . . . . . . . . . . . . . . . . . . 52
5.4 Geometry of the MAP States
5.5 Two Polarized Modes . . . . . . . . . . . . . . . . . . . . . . . . . . . 55

5

Contents

Contents

5.6 Projecting to the Safe Polytope . . . . . . . . . . . . . . . . . . . . . 58
5.7 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
5.7.1
Seattle data . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
5.7.2 Convex projection . . . . . . . . . . . . . . . . . . . . . . . . . 60
5.8 Conclusions and Path Forward . . . . . . . . . . . . . . . . . . . . . . 61

Bibliography

64

6

List of Figures

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
4-1 Rank decrement.
4-2 Rank decrement with multistart.
. . . . . . . . . . . . . . . . . . . . 42
4-3 Time complexity for Erdos-Renyi graphs (chart) . . . . . . . . . . . . 43

5-1 Ising model of pandemic . . . . . . . . . . . . . . . . . . . . . . . . . 48
5-2 Geometry of the attractive Ising model
. . . . . . . . . . . . . . . . . 54
5-3 The safe polytope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
5-4 Proportion of the mixed states in all samples . . . . . . . . . . . . . . 56
5-5 Proportion of the mixed-to-polarized states . . . . . . . . . . . . . . . 57
. . . . . . . . . . . . . . . . . . . . . . . . . 60
5-6 Seattle case study areas

7

List of Tables

3.1 SDPLR improvement on Gset graphs . . . . . . . . . . . . . . . . . . 26
3.2 CVX improvement on Gset graphs
. . . . . . . . . . . . . . . . . . . 27
3.3 CVX improvement on the Biq Mac graph collection (250 nodes) . . . 27
3.4 CVX improvement on the Biq Mac graph collection (500 nodes) . . . 28

4.1 Comparison between SDP, EP-SDP and the MIP solver . . . . . . . . 40
4.2 The comparison results between and other methods on MAP instances 41
4.3 Time complexity for Erdos-Renyi graphs (table) . . . . . . . . . . . . 44

5.1 Summary of our pandemic prevention experiments on the Seattle data 61

8

Chapter 1

Introduction

The thesis is devoted to designing efficient numerical optimization methods for discrete

optimization problems focusing mainly on NP-hard quadratic (binary) optimization

and its tractable cases. Although being demanded in various applications, such

as energy systems, epidemiology, and statistical physics, efficient algorithms for

tractable cases of NP-hard optimization problems are mainly an open question.

The thesis employs the power of semidefinite and conic programming, regular-

ization, rounding, and sampling techniques to design time and memory-efficient

numerical algorithms for tractable instances of NP-hard optimization problems. We

demonstrate that these techniques allow for faster and more reliable methods in

theory and for a wide range of practical problems.

The structure of the thesis is as follows:

Chapter 2 - Background and Thesis objective presents overview of thesis-related

state-of-the-art results and outlines the main problems resolved in the thesis;

Chapter 3 - Rank Constraints and Their Relaxations presents efficient ways

of rank constraints relaxation that proving exactness of the semidefinite pro-

gramming to some instances of NP-hard problems;

Chapter 4 - Entropy-Penalized Semidefinite Programming expands the ideas

of the previous chapter through the objective regularization;

Chapter 5 - Ising Model Control applies designed algorithms for modeling COVID-

9

Chapter 1.

Introduction

19 pandemic and access the epidemic pattern.

10

Chapter 2

Background and Thesis Objective

The computational complexity of optimization problems is active research topic for

several decades Karp [1975], Gill et al. [2019].Despite the significant progress in the

theory and practice of tractable optimization settings, where convex optimization

is probably the most important Boyd et al. [2004]. Similarly, on a number of

problems were proved to be computationally hard and unlikely to have polynomial-

time algorithms for solving them Arora and Barak [2009]; however, NP-hardness

of the problem does not imply absence of its tractable instances. Bounded tree-

width instances are probably the most well-known examples of tractable instances of

NP-hard problems Cygan et al. [2015].

Practical engineering and physics problems, however, can be approximated far

beyond their hardness thresholds and often solved exactly. Furthermore, such problem

often do not have bounded tree-width and as such do not tractable parameterized

algorithms Cygan et al. [2015]. A notable example of such problem instance are

planar Schraudolph and Kamenetsky [2008] or 𝐾3,3–free Likhosherstov et al. [2020]
Ising models that admit 𝑂(𝑛3/2) exact solution in polynomial time.

The thesis proposes an alternative path to approach tractability of certain in-

stances of NP-hard binary optimization problems. The latter approach is based on

representing the optimization problem in matrix form with the rank one constraint

on the matrix variable and deriving flexible approximations and relaxations the latter

constraint. The approach lead to new tractable exact and approximate algorithms

for tractable instances of NP-hard optimization problems. These algorithms provide

11

Chapter 2. Background and Thesis Objective

state-of-the-art results for a number of practical problems in statistical physics,

energy systems, and epidemic modeling.

12

Chapter 3

Rank Constraints and Their

Relaxations

3.1

Introduction

Binary quadratic optimization is a classical combinatorial optimization problem,

which finds a wide range of applications in computer vision Wang et al. [2017], Ren

et al. [2014], circuit layout design Barahona [1988], Kleinhans et al. [1991], computing

ground states of Ising Model Liers et al. [2004], as well as a number of combinatorial

favors Parker and Rardin [2014], Garey and Johnson [2002], Cormen [2009]. For

comprehensive list of applications we refer to Deza and Laurent [2009], Kochenberger

[2014].

A special case of this problem is unconstrained binary quadratic programming

(UBQP). It is a classical NP-hard problem, hardly possible to be solved exactly in

polynomial time. A number of relaxation techniques substituting the original problem

to a convex one has been proposed. Linear, second-order cone and semidefinite

relaxations are among them.

Semidefinite Programming (SDP) relaxation has been shown to lead to tighter

approximation than other relaxation methods for many combinatorial optimization

problems including binary quadratic optimization ones (Goemans and Williamson

[1995] and Khot [2002]). Still, SDP reduces the problem to convex optimization over

the cone of Positive Semidefinite (PSD) matrices and outputs a full-rank matrix

13

Chapter 3. Rank Constraints and Their Relaxations

3.1.

Introduction

requiring to be rounded to obtain a vector valued solution.

In this chapter we address the question of Low-Rank Burer-Monteiro SDP (LR-

SDP), which is aimed at strengthening results of the standard SDP relaxation. While

a number of methods has been proposed (see Lemon et al. [2016] for a survey), we

discuss direct rank minimization of an obtained SDP solution. We use smoothed rank

approximations in order to reduce the rank of the SDP solution without significant loss

in the optimal value. For this purpose we propose an efficient first-order optimization

procedure which does not require projecting on the feasible set. This will potentially

lead to more accurate rounding procedure allowing to obtain a better vector solution.

In the rest of the chapter we discuss problems of the form

max 𝑥⊤𝐴𝑥,

s.t. 𝑥 ∈ {−1, 1}𝑛,

(3.1)

where 𝐴 is an arbitrary symmetric 𝑛 × 𝑛 matrix.

There are many well-known problems that can be naturally written in this form:

the maximum cut problem, the 0-1 knapsack problem, the linear quadratic regulator

and many others.

Not all of these formulations appear in the form 3.1. Instead, some problems

might have a linear term of the from 𝑏⊤𝑥 and a 0-1 constraint, that is 𝑥 ∈ {0, 1}𝑛.

Nevertheless, such problems might be converted to the form 3.1, as showed in

Helmberg et al. [1995].

For instance, in the maximum cut (max-cut) problem we want to find a partition

of graph’s vertices into two disjoint sets such that the sum of edges between these

sets is maximal. This problem is NP-hard Karp [1972], however, it can be solved

approximately. For small instances (up to 50 vertices) the maximum cut may

be solved efficiently with the branch-and-bound algorithm Krislock et al. [2014],

Rendl et al. [2010]. For bigger problems (around 1000 vertices) the semidefinite

relaxation discussed below gives the best known approximations. It is crucial for many

applications to improve existing approximations or to extend them on large-scale

instances.

Quadratic boolean programming (3.1) is a particular case of Quadratically Con-

14

Chapter 3. Rank Constraints and Their Relaxations

3.1.

Introduction

strained Quadratic Problems (QCQP), so general heuristics for this class of problems

may be applied.

3.1.1 Semidefinite relaxation

Standard SDP relaxation leads to the following matrix problem:

max tr(𝐴𝑋),

s.t. diag 𝑋 = 1𝑛,

𝑋 ⊤ = 𝑋, 𝑋 ⪰ 0.

(3.2)

This problem is convex and thus could be efficiently solved (we will discuss the

particular method below).

To get a binary solution of the initial problem 3.1, we decompose the solution

of the SDP relaxation 𝑋 = 𝑉 ⊤𝑉 (via Cholesky decomposition), then take a unit
vector with uniformly distributed direction 𝑟. For each column of 𝑉 , which is 𝑣𝑖, we
𝑖 𝑟. If 𝐴 ⪰ 0, the mean result of this procedure is not worse than
take 𝑥𝑖 = sign 𝑣⊤
2/𝜋 of the maximum value Nesterov [1998]. In a special case when 𝐴 is a Laplacian

of a graph with non-negative weights this bound can be further improved to ≈ 0.878

Goemans and Williamson [1995]. Note that this famous results cannot be improved

if the Unique Games Conjecture is true Khot [2002].

However, this relaxation is exact, when rank 𝑋 = 1. Moreover, low-rank solutions

lead to a fewer number of possible binary sets in the rounding procedure described

above. This idea becomes more clear if one considers half-space classifiers in R𝑟 and 𝑛

points. The maximum number of different labellings is controlled by Sauer’s lemma,

and grows as (𝑛 + 1)𝑟. Hence, if we lie in the vicinity of a correct solution, we would

get the correct result from the rounding procedure more likely. This motivation

brings us to the idea of low-rank semidefinite programming.

3.1.2 Related work

The existence of low-rank solutions of the problem 3.2 is a fundamental fact discussed

in P. [1998] and Barvinok [1995]. From these works we know that for such problems

15

Chapter 3. Rank Constraints and Their Relaxations

3.1.

Introduction

there exist solutions of the rank at most 𝑟, where 𝑟(𝑟 + 1) ≤ 2𝑛.

Knowing about the existence of low-rank solutions, we may discuss popular

approaches in low-rank semidefinite programming. This section is mostly based on

the book Lemon et al. [2016].

Firstly, the existence of low-rank solutions is used in Burer and Monteiro method

Burer and Monteiro [2003]. It is based on the factorization 𝑋 = 𝑉 𝑉 ⊤, where 𝑉 is an

arbitrary matrix of size 𝑛 × 𝑟. This problem is non-convex, though it requires much

less computations and performs well in practice. However, finding the minimum rank

solution of multiple runs of the algorithm with different 𝑟 (one increments 𝑟 until

resulting point satisfies particular conditions) might be computationally ineffective.

Another approach implies relaxation of the equality constraint So et al. [2008]. It

can be written as following:

tr (𝐴𝑋) = 𝑏 ⇒ 𝛽𝑏 ≤ tr (𝐴𝑋) ≤ 𝛼𝑏,

where 𝛼 and 𝛽 control the rank of the solution. In our case the problem 3.2 has
𝑛 equality constraints of the form tr (𝑋𝐸𝑖𝑖) = 1, where 𝐸𝑖𝑖 is a zero matrix with
unit in the position 𝑖, 𝑖. All 𝑛 constraints together form diag 𝑋 = 1. Though this

approach allows to reduce the rank, the resulting solution satisfies our constraints

only approximately.

The next approach implies that we have already got a solution of the problem

3.2. This allows us to reduce its rank via some kind of rank minimization procedure

keeping the value of tr (𝐴𝑋) optimal. Note that rank minimization is NP-hard, so

this formulation needs to be further relaxed to be efficiently solvable. This approach

has been discussed in the literature, but we have not found a comparison of different

ways to minimize the rank in application to boolean quadratic programming.

In this chapter we propose an efficient first-order algorithm, which performs rank

minimization. It starts from the solution of the SDP relaxation. This solution is

provided by either CVX interior-point algorithm Grant and Boyd [2014], Grant and

Boyd [2008] or Burer-Monteiro low-rank procedure, implemented in SDPLR Burer

and Monteiro [2003].

16

Chapter 3. Rank Constraints and Their Relaxations

3.2. Rank Minimization

3.2 Rank Minimization

In this section we introduce the problem of rank minimization for the SDP relaxation.

After that we describe existing approaches for rank minimization, and discuss their

pros and cons.

3.2.1 Problem

Let 𝑋 * be a solution of 3.2 and let 𝑆𝐷𝑃 be its value and 𝑊 * be the value of the

binary solution obtained by the rounding procedure. Starting from 𝑋 *, we want to

solve the following problem:

min rank 𝑋

s.t. diag 𝑋 = 1𝑛,

𝑋 ⊤ = 𝑋, 𝑋 ⪰ 0,

tr(𝐴𝑋) = 𝑆𝐷𝑃,

(3.3)

3.2.2 Objective function’s relaxations

However, minimizing the rank is NP-hard. In order to solve the problem 3.3, we

replace rank 𝑋 with a smooth surrogate, usually non-convex. There is a number of

rather popular ways to do that, discussed below.

First of all, the so-called trace norm (or nuclear), defined as

‖𝑋‖* =

∑︁

𝜎𝑖,

𝑖

(3.4)

where 𝜎𝑖 is the 𝑖-th singular value Lemon et al. [2016]. In our case, every feasible
point of the problem has tr 𝑋 = ‖𝑋‖* = 𝑛, hence this relaxation does not make
sense.

Next, the so-called log-det heuristic is to replace rank 𝑋 with the concave function

log det (𝑋 + 𝜀𝐼) .

(3.5)

This heuristic is discussed, for example, in Lemon et al. [2016], Fazel et al. [2003].

17

Chapter 3. Rank Constraints and Their Relaxations

3.2. Rank Minimization

Though it performs well in practice, it requires an iterative procedure (described in

Fazel et al. [2003]) with an SDP problem on each iteration. This problem allows

to use Burer-Monteiro method Burer and Monteiro [2003], but it still needs several

runs of this algorithm (at least one for each iteration), which is compatible with rank

increment in the original Burer-Monteiro procedure.

The next two relaxations are singular value-based, and in the next section we

show that, in fact, they allow an efficient first-order procedure, that does not require

projections on the semidefinite cone and hence is computationally efficient.

The first one is the non-convex function of the following form

Φ(𝑋, 𝜀) = (1 + 𝜀𝑞) tr (︀𝑋 ⊤(𝑋𝑋 ⊤ + 𝜀𝐼)−1𝑋)︀ .

(3.6)

for 𝑞 ∈ Q ∩ [0, 1]. Its properties are discussed in Li [2014]. An important fact is that

this relaxation is quite close to the rank:

|rank 𝑋 − Φ(𝑋, 𝜀)| ≤
{︃

≤ 𝜀𝑞 max

rank 𝑋,

rank 𝑋
∑︁

𝑖=1

⃒
⃒
⃒
⃒

𝜀1−𝑞
𝜎2
𝑖 (𝑋)

⃒
⃒
− 1
⃒
⃒

}︃

.

The second relaxation utilizes so-called smoothed Schatten p-norms. They are

defined as following:

‖𝑋‖𝑝

𝑆𝑝,𝜀

=

∑︁

𝑖≥1

(︀𝜎2

𝑖 + 𝜀)︀ 𝑝

2 = tr (︀𝑋 ⊤𝑋 + 𝜀𝐼)︀ 𝑝
2 .

(3.7)

With 𝑝 → 0 and 𝜀 = 0 we get the rank function exactly. Note that for 𝑝 < 1 this

function is non-convex, and for 𝑝 = 1 it is identical to the nuclear norm. Applications

of this relaxation can be found in Nie et al. [2012] and Mohan and Fazel [2012]. Both

papers introduce an iteratively reweighted least squares (IRLS) algorithm in order

to solve this problem. However, in our case it requires solving of an SDP problem

with quadratic objective function at each iteration. Hence, it cannot be applied to

large-scale problems.

18

Chapter 3. Rank Constraints and Their Relaxations

3.3. Solving Rank Relaxation

3.2.3 Constraint relaxation

If we omit the last constraint in the problem 3.3, which is tr (𝐴𝑋) = 𝑆𝐷𝑃 , rank

minimization might occasionally converge to a solution of rank one. Moreover, it

may converge to a low-rank vicinity of such solution. If the SDP relaxation is not

tight, then this constraint prevents the procedure from such behavior.

We can also obtain a binary solution after solving the SDP relaxation. If we

denote the objective value at this point 𝑊 *, then this value would be a natural

lower bound on tr (𝐴𝑋). It means that all solutions of rank one above this value are

actually better, than the one we got.

This motivation allows us to relax the problem further, and solve (along with

rank approximations) the following one:

min rank 𝑋

s.t. diag 𝑋 = 1𝑛,

𝑋 ⊤ = 𝑋, 𝑋 ⪰ 0,

𝑊 * ≤ tr(𝐴𝑋) ≤ 𝑆𝐷𝑃.

(3.8)

Obviously, the binary solution, that gives 𝑊 *, is also a solution of the last problem.

However, the typical procedure for solving 3.8 would start from the SDP matrix

in order to improve the resulting cut. Since the rank of this matrix is not unit in

general, we need to optimize the objective function further.

An important consequence of this relaxation will be clear in the next section as

it allows to avoid projecting on the feasible set.

For completeness we emphasize that our approach cannot be generalized to

QCQP problems. To avoid projecting on the set, it relies significantly on the special

structure of constraints that occur in the problem 3.8.

3.3 Solving Rank Relaxation

In this section we introduce an efficient first-order procedure that solves the problem

3.8 without projecting on the positive-semidefinite cone. It can be applied to the

19

Chapter 3. Rank Constraints and Their Relaxations

3.3. Solving Rank Relaxation

singular value relaxation 3.6 and smoothed Schatten p-norm 3.7.

3.3.1 Efficient first-order procedure

The problem 3.8 allows a natural reparametrization to a vector problem of dimension

𝑛(𝑛 − 1)/2. To do that, we consider the upper triangular part of the matrix:

⎛

⎜
⎜
⎜
⎝

𝑋 =

1

𝑥1

𝑥1

. . . 𝑥𝑛−1

1

𝑥𝑛

. . .

. . .

. . .

. . .

. . .

⎞

⎟
⎟
⎟
⎠

.

(3.9)

In this case for indices 𝑖, 𝑗 we get 𝑋𝑖,𝑗 = 𝑥𝑑, where 𝑑 = ∑︀𝑖−1
satisfies two constraints immediately: 𝑋 ⊤ = 𝑋 and diag 𝑋 = 1𝑛.

𝑘=1(𝑛 − 𝑘) + 𝑗 − 𝑖. This

Such reparametrization changes the gradient of the matrix function 𝑓 (𝑋):

𝜕 𝑓 (𝑋(𝑥))
𝜕 𝑥(𝑑)

∑︁

=

𝜕 𝑓 (𝑋)
𝜕 𝑥𝑖,𝑗

𝜕 𝑥𝑖,𝑗
𝜕 𝑥(𝑑)

=

𝜕 𝑓 (𝑋)
𝜕 𝑥𝑖′,𝑗′

𝜕 𝑥𝑖′,𝑗′
𝜕 𝑥(𝑑)

+

𝑖,𝑗
𝜕 𝑓 (𝑋)
𝜕 𝑥𝑗′,𝑖′

+

𝜕 𝑥𝑗′,𝑖′
𝜕 𝑥(𝑑)

=

𝜕 𝑓 (𝑋)
𝜕 𝑥𝑖′,𝑗′

+

𝜕 𝑓 (𝑋)
𝜕 𝑥𝑗′,𝑖′

,

where 𝑖′, 𝑗′ relate to the vector of index 𝑑.

Obviously, the upper bound tr(𝐴𝑋) ≤ 𝑆𝐷𝑃 is always satisfied. Moreover,

violation of the lower one 𝑊 * ≤ tr(𝐴𝑋) implies that we got the point that could

not improve our binary solution, hence we need to stop.

The last constraint is 𝑋 ⪰ 0. We show that proper choice of the gradient step

results in a feasible point in case of singular value relaxation and Schatten norms.

First of all, the gradient of the singular value relaxation is

𝜕 Φ(𝑋, 𝜀)
𝜕 𝑋

= 2𝜀(1 + 𝜀𝑞) (︀𝑋𝑋 ⊤ + 𝜀𝐼)︀−2

𝑋.

(3.10)

For Schatten p-norms we have

𝑑 ‖𝑋‖𝑝
𝑑 𝑋

𝑆𝑝,𝜀

= 𝑝𝑋 (︀𝑋 ⊤𝑋 + 𝜀𝐼)︀ 𝑝−2

2

.

(3.11)

If 𝑋 is symmetric and PSD, then from SVD factorization both gradients are

20

Chapter 3. Rank Constraints and Their Relaxations

3.3. Solving Rank Relaxation

symmetric. Thus in vector parametrization we simply need to multiply the gradient

by 2, and then force diagonal elements to be unit.

For further convenience we denote a symmetric matrix with unit diagonal, upper

triangular part of which is constructed from the vector 𝑥, as 𝑋(𝑥). Finally, we show

the following:

Theorem 1. Let 𝑓 (𝑥) be the vector-parametrized singular value relaxation 3.6 of the

matrix 𝑋(𝑥) ⪰ 0. Then for 𝛼 ≤ 𝜀

4(1+𝜀𝑞) we get 𝑋(𝑥 − 𝛼∇𝑓 (𝑥)) ⪰ 0.

Proof. The gradient step in upper-triangular parametrization is equivalent to the

ordinary gradient step (multiplied by 2), and then substituting diagonal elements to

units. We are going to show that the first step results in a PSD matrix and then the

second step keeps matrix PSD.

Consider a symmetric PSD point and its SVD decomposition 𝑋 = 𝑈 𝑆𝑈 ⊤. Hence

for a step 𝛼 and 𝐶 = 2𝜀(1 + 𝜀𝑞) the new point is

𝑋 − 2𝛼𝐶(𝑋𝑋 ⊤ + 𝜀𝐼)−2𝑋 =
= 𝑈 𝑆𝑈 ⊤ − 2𝛼𝐶 (︀𝑈 𝑆2𝑈 ⊤ + 𝜀𝐼)︀−2
𝑆 − 2𝛼𝐶 (︀𝑆2 + 𝜀𝐼)︀−2 𝑆

= 𝑈

(︁

)︁

𝑈 ⊤.

𝑈 𝑆𝑈 ⊤ =

Hence the positive-semidefiniteness of the resulting matrix is equivalent to such

characteristic of the expression in brackets. It is a diagonal matrix.

If 𝑆𝑖𝑖 = 0, then the corresponding diagonal elements are obviously zero. Otherwise

we need it to be positive:

𝑆𝑖𝑖 − 2𝛼𝐶 (︀𝑆2

𝑖𝑖 + 𝜀𝐼)︀−2 𝑆𝑖𝑖 ≥ 0 ⇒
𝑖𝑖 + 𝜀𝐼)2
(𝑆2
4𝜀(1 + 𝜀𝑞)

𝑖𝑖 + 𝜀𝐼)2
2𝐶

=

.

(𝑆2

⇒ 𝛼 ≤

Therefore, it is enough to take

𝛼 ≤

𝜀
4(1 + 𝜀𝑞)

.

Now we want to show that substituting diagonal elements with units is equivalent

21

Chapter 3. Rank Constraints and Their Relaxations

3.3. Solving Rank Relaxation

to adding a diagonal matrix with non-negative entries. In this case, a sum of two

PSD matrices is PSD.

It is also equivalent to the fact that all diagonal elements of the gradient are

non-negative. This is always true for a symmetric and PSD matrix 𝑋 = 𝑈 𝑆𝑈 ⊤:

(︀(𝑋𝑋 ⊤ + 𝜀𝐼)−2𝑋)︀

𝑖𝑖 =

(︁

𝑈 (︀𝑆2 + 𝜀𝐼)︀−2 𝑆𝑈 ⊤)︁

=

𝑖𝑖

=

=

∑︁

𝑗
∑︁

𝑗

𝑈𝑖𝑗𝑈𝑖𝑗

(︀𝑆2

𝑗𝑗 + 𝜀𝐼)︀−2 𝑆𝑗𝑗 =

𝑈 2
𝑖𝑗

(︀𝑆2

𝑗𝑗 + 𝜀𝐼)︀−2 𝑆𝑗𝑗 ≥ 0.

This observation completes the proof.

The same technique allows us to get a similar result for smoothed Schatten

p-norms:

Theorem 2. Let 𝑓 (𝑥) be vector-parametrized smoothed Schatten p-norm of a matrix

𝑋(𝑥) ⪰ 0. Then for 𝛼 ≤ 1

2𝑝 𝜀(2−𝑝)/𝑝 we get 𝑋(𝑥 − 𝛼∇𝑓 (𝑥)) ⪰ 0.

Proof. The gradient step in the upper-triangular parametrization is equivalent to

the ordinary gradient step (multiplied by 2) with substitution of diagonal elements

with units. We are going to show that the first step results in a PSD matrix and the

second step keeps matrix PSD.

Consider a symmetric PSD point and its SVD decomposition 𝑋 = 𝑈 𝑆𝑈 ⊤. Hence

for the step 𝛼 the new point is

𝑋 − 2𝛼𝑝𝑋 (︀𝑋 ⊤𝑋 + 𝜀𝐼)︀(𝑝−2)/2
= 𝑈 𝑆𝑈 ⊤ − 2𝛼𝑝𝑈 𝑆𝑈 ⊤ (︀𝑈 𝑆2𝑈 ⊤ + 𝜀𝐼)︀(𝑝−2)/2
𝑆 − 2𝛼𝑝𝑆 (︀𝑆2 + 𝜀𝐼)︀(𝑝−2)/2)︁

𝑈 ⊤.

= 𝑈

=

(︁

=

Hence positive-semidefiniteness of the resulting matrix is equivalent to such

characteristic of the expression in brackets. It is a diagonal matrix.

If 𝑆𝑖𝑖 = 0, then the corresponding diagonal elements are obviously zero. Otherwise

22

Chapter 3. Rank Constraints and Their Relaxations

3.3. Solving Rank Relaxation

we need them to be positive:

𝑆𝑖𝑖 − 2𝛼𝑝𝑆𝑖𝑖

𝑖𝑖 + 𝜀𝐼)︀(𝑝−2)/2 ≥ 0 ⇒

(︀𝑆2
𝑖𝑖 + 𝜀𝐼)(2−𝑝)/2
2𝑝

.

(𝑆2

⇒ 𝛼 ≤

Therefore, it suffices to take

𝛼 ≤

𝜀(2−𝑝)/2
2𝑝

.

Now we want to show that substituting diagonal elements with units is equivalent

to adding a diagonal matrix with non-negative entries. In this case a sum of two

PSD matrix is PSD.

It is also equivalent to the fact that all diagonal elements of the gradient are

non-negative. This is always true for a symmetric and PSD matrix 𝑋 = 𝑈 𝑆𝑈 ⊤:

(︁

=

=

=

𝑋 (︀𝑋 ⊤𝑋 + 𝜀𝐼)︀(𝑝−2)/2)︁
(︁

𝑈 𝑆 (︀𝑆2 + 𝜀𝐼)︀(𝑝−2)/2 𝑈 ⊤)︁
∑︁

𝑖𝑖

𝑈𝑖𝑗𝑈𝑖𝑗𝑆𝑗𝑗

(︀𝑆2

𝑗𝑗 + 𝜀𝐼)︀(𝑝−2)/2 =

=

𝑖𝑖

𝑗
∑︁

𝑗

𝑈 2

𝑖𝑗𝑆𝑗𝑗

(︀𝑆2

𝑗𝑗 + 𝜀𝐼)︀(𝑝−2)/2 ≥ 0.

This observation completes the proof.

In practice, the singular value relaxation bound is much better, since the step

bound tends to be larger.

3.3.2 Algorithm

The results above allow us to introduce a gradient descent method, summarized

in the algorithm 1 (for singular values relaxation). In this algorithm an abstract

procedure ChooseStep returns the appropriate step, which is less or equal to

𝜀
4(1+𝜀𝑞)
The second procedure RoundSolution corresponds to the rounding method, described

.

in the introduction.

23

Chapter 3. Rank Constraints and Their Relaxations

3.4. Computational experiments

Algorithm 1: Gradient descent for singular values relaxation.

begin

𝑋0 = 𝑋𝑆𝐷𝑃 ;
𝐾 = {︀𝑋 ⃒
for 𝑛 = 1:max_iter do

⃒𝑋 = 𝑋 ⊤, 𝑋 ⪰ 0, 𝑊 ≤ tr(𝐴𝑋) ≤ 𝑆𝐷𝑃 }︀;

𝛼 = ChooseStep(𝑋𝑛);
𝑋𝑛 = 𝑋𝑛−1 − 4𝛼𝜀(1 + 𝜀𝑞) (︀𝑋𝑋 ⊤ + 𝜀𝐼)︀−2 𝑋;
(𝑋𝑛)𝑖𝑖 = 1;
if 𝑋𝑛 ̸∈ 𝐾 then

break;

end
if ‖4𝛼𝜀(1 + 𝜀𝑞) (︀𝑋𝑛𝑋 ⊤

break;

𝑛 + 𝜀𝐼)︀−2 𝑋𝑛‖𝐹 < tol then

end

end
x, 𝑊 ** = RoundSolution(𝐴, 𝑋𝑛);

end
Return: x, 𝑊 **.;

3.4 Computational experiments

3.4.1 Setup

We have tested both CVX and SDPLR solvers followed by our algorithm on Gset

graphs collection https://web.stanford.edu/~yyye/yyye/Gset/ (originally in-
troduced in Helmberg and Rendl [1997]). We also tested the Biq Mac library

http://biqmac.uni-klu.ac.at/biqmaclib.html (namely on Beasley instances
Beasley [1998]). The latter is a collection of {0, 1} problems, which are converted to

{−1, 1} ones as mentioned in the introduction.

For each solver we first applied it to the problem. Then we computed the maximum

cut based on the 1 × 105 rounding operation. The number of rounding operations was

chosen to be completely sure that the solution provides better results compared to

others. After that we chose 𝜀 = 0.005 (smaller values led to ill-conditioned gradients),

𝑞 = 0.8 for the singular values relaxation (this value is used by the authors of Li

[2014]), 𝑝 = 0.1 and 𝑝 = 0.01 for Schatten norms. The stopping criteria for the

gradient descent were 100 iterations and Frobenius norm of the gradient (less than

1 × 10−5). After that a new cut was obtained after 1 × 105 rounding operations.

24

Chapter 3. Rank Constraints and Their Relaxations

3.4. Computational experiments

Rank tolerance was chosen to be 1 × 10−4. For Schatten norms the step size was at

most 𝜀, which is larger than the theoretical value. Nevertheless, for such steps we

have not observed any violations of the PSD constraint.

We tested all methods on the first 21 Gset graphs. These graphs have 800 nodes

and are solvable with CVX. Another 10 graphs of size 2000 were tested with SDPLR

only.

We also tested all methods on the Beasley instances from the Biq Mac library.

We chose relatively large {0, 1} problems with 250 and 500 nodes. They were tested

for CVX only.

3.4.2 Discussion

Results are shown in tables 3.1 for SDPLR and 3.2 for CVX.

Our approach outperforms both solvers in terms of the maximum cut on ap-

proximately half of the graphs (bold numbers). Moreover, for the first 21 graphs, it

outperforms them on almost the same set of graphs. Among tested rank relaxations

the best performance was shown by Schatten norm relaxation with 𝑝 = 0.1. Probably,

𝑝 = 0.01 was a worse choice as it resulted in bigger influence of the smoothing

parameter 𝜀 as it is included in the gradient in order of 𝜀(𝑝−2)/2.

The same result is observed for the {0, 1} problems, but the singular values

relaxation showed the best performance. All methods performed well for rank

reduction. However, some runs resulted in extremely large ranks. It show, that

the resulting point has a lot of relatively small singular values, which are however

not thresholded by 1 × 10−4 (note that all singular values sum to the graph’s size).

This behavior might be considered a drawback of the Schatten norms relaxation and

might be caused by the minimization of the sum of singular values (compared to the

sum of fractions in the singular values relaxation). Note that small singular values

have little effect in the rounding procedure, so this drawback does not have great

influence on the method’s performance and be further applied to practical problems

in statistical physics and power systems Mikhalev et al. [2020], Lukashevich et al.

[2021], Stulov et al. [2020].

25

Chapter 3. Rank Constraints and Their Relaxations

3.4. Computational experiments

#

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31

SDP

rank

cut

singular
values
rank

14
15
14
14
13
13
12
12
12
12
22
13
11
14
16
16
16
11
10
9
10
18
20
19
19
19
18
20
18
17
19

11466
11436
11446
11487
11462
2026
1833
1834
1879
1841
538
532
562
2994
2979
2978
2978
924
850
888
868
13008
13010
13000
13006
12971
2988
2956
3044
3076
2947

13
13
14
14
12
13
12
11
12
12
138
27
8
13
99
14
13
10
9
8
33
18
52
18
19
132
17
20
17
17
18

Schatten
p=0.1
rank

15
13
461
319
18
105
12
11
12
12
718
190
24
22
173
195
152
12
9
8
52
18
78
22
196
181
17
54
23
17
18

Schatten
p=0.01
rank

13
14
26
14
12
13
12
12
12
12
273
41
8
14
122
15
15
11
9
8
41
18
55
19
19
120
18
20
17
17
18

cut

11459
11430
11453
11497
11471
2012
1822
1831
1875
1820
536
534
562
2999
2983
2984
2974
929
851
884
863
13025
13004
13010
12987
12990
2989
2956
3038
3067
2958

cut

11451
11456
11455
11511
11451
2013
1834
1840
1869
1818
538
534
562
2992
2986
2984
2974
921
854
889
862
13003
13010
13005
13026
12969
3027
2947
3050
3076
2959

cut

11448
11438
11445
11475
11462
1989
1821
1833
1872
1829
538
536
560
2995
2982
2981
2975
930
846
882
864
13006
12985
13004
12988
12985
2988
2948
3056
3081
2955

Table 3.1: SDPLR improvement on Gset graphs

26

Chapter 3. Rank Constraints and Their Relaxations

3.4. Computational experiments

SDP

rank

cut

singular
values
rank

13
13
14
14
12
13
13
12
12
12
10
9
8
13
13
14
13
10
9
9
9

11462
11436
11446
11487
11462
2024
1833
1835
1879
1841
534
532
562
2994
2979
2982
2978
924
847
882
862

13
13
14
14
12
13
12
12
12
12
6
8
8
13
13
14
13
10
9
9
9

Schatten
p=0.1
rank

15
13
502
304
18
108
12
109
12
12
6
29
76
22
51
589
439
11
9
222
9

cut

11451
11456
11446
11511
11451
2013
1828
1846
1869
1820
534
536
562
2994
2987
2979
2973
920
850
888
867

cut

11448
11438
11445
11471
11464
1994
1821
1856
1872
1825
534
534
560
2995
2982
2981
2978
930
846
887
865

Schatten
p=0.01
rank

13
13
28
14
12
13
12
13
12
12
7
8
8
13
13
61
24
10
9
20
9

Table 3.2: CVX improvement on Gset graphs

SDP

rank

cut

singular
values
rank

6
6
6
7
5
7
6
7
6
6

45369
44579
48857
41094
47685
40519
46605
35076
48454
39944

6
6
6
7
5
7
6
7
6
6

Schatten
p=0.1
rank

60
7
13
17
16
9
6
8
9
15

Schatten
p=0.01
rank

173
47
81
88
75
70
38
75
59
77

cut

45369
44571
48833
41094
47679
40475
46659
35076
48447
39974

cut

45369
44513
48857
41116
47738
40545
46563
35000
48570
39990

cut

11456
11433
11453
11497
11471
2016
1822
1839
1875
1836
534
536
560
2999
2981
2986
2976
929
846
886
865

cut

45369
44515
48857
41116
47685
40469
46671
35079
48364
39944

#

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21

#

1
2
3
4
5
6
7
8
9
10

Table 3.3: CVX improvement on the Biq Mac graph collection (250 nodes)

27

Chapter 3. Rank Constraints and Their Relaxations

3.5. Conclusion

SDP

rank

cut

singular
values
rank

cut

Schatten
p=0.1
rank

cut

Schatten
p=0.01
rank

cut

9
8
9
9
8
8
9
9
9
7

114540
127280
129080
128000
123570
119770
120210
121940
118700
129220

9
8
9
9
8
8
9
9
9
7

37
114440
8
127230
17
129210
128040
43
123860 8
120350 8
15
119920
12
121650
26
118570
7
129100

246
113880
16
127080
148
129130
273
127940
35
123430
8
119750
177
120100
121980 101
209
118360
26
129120

114100
127370
129400
128170
123480
119590
120070
121920
118420
129040

#

1
2
3
4
5
6
7
8
9
10

Table 3.4: CVX improvement on the Biq Mac graph collection (500 nodes)

3.5 Conclusion

We developed an efficient first-order procedure which is aimed at improvement of SDP

relaxation solutions for quadratic binary programming. We relax rank minimization

in terms of the objective function and the linear constraint that controls optimality

of the initial SDP objective. Rank function relaxation is performed by either

singular value relaxation or Schatten p-norms. The latter approach showed the best

performance on Gset graphs, while the singular values relaxation performed best on

the Beasley instances.

28

Chapter 4

Entropy-Penalized Semidefinite

Programming

4.1

Introduction

Semidefinite Programming (SDP) has become a key tool in solving numerous problems

across operations research, machine learning, and artificial intelligence. While there

are too many applications of SDP to present even a representative sample, inference in

graphical models Wainwright and Jordan [2008], Erdogdu et al. [2017], multi-camera

computer vision Torr [2003], and applications of polynomial optimization Parrilo

[2003], Lasserre [2015] in power systems Ghaddar et al. [2016] stand out. Under some

assumptions Madani et al. [2014], the rank at the optimum of the SDP relaxation is

bounded from above by the tree-width of a certain hypergraph, plus one. When a

rank-one solution is not available, it is often not needed Mareček and M. [2017], as

one should like to construct a stronger SDP relaxation.

Penalization of the objective is a popular approach for obtaining low-rank so-

lutions, at least in theory Recht et al. [2010], Lemon et al. [2016], Zhou [2019],

Fawzi et al. [2019]. Notice that without a further penalization, an interior-point

method for SDP provides a solution on the boundary of the feasible set, where

SDP corresponds to the optimum of the highest rank, whenever there are optima of

multiple ranks available. The use of a penalization provides a counter-balance in this

respect. In practice, however, the penalties are often ignored, as it is believed that

29

Chapter 4. Entropy-Penalized Semidefinite Programming

4.1.

Introduction

their computation is too demanding for large-scale problems and does not guarantee

low-rank solutions in general.

An alternative approach develops numerical optimization methods that seek a

priori low-rank solutions. This approach, widely attributed to Burer and Monteiro

[2003], considers a factorization of a semidefinite matricial variable 𝑋 = 𝑉 · 𝑉 ⊤

with 𝑉 ∈ R𝑛×𝑘 for increasing 1 ≤ 𝑘 ≪ 𝑛. In general, the resulting problems are

non-convex. Early analyses required determinant-based penalty terms Burer and

Monteiro [2005], although no efficient implementations were known. Under mild

assumptions, for large-enough 𝑘, there is a unique optimum over such a factorization

even without a penalization and it recovers the optimum of the initial SDP problem

Boumal et al. [2016]. For smaller values of 𝑘, it is known that the low-rank relaxation

achieves 𝒪(1/𝑘) relative error Song et al. [2017]. Much more elaborate analyses

Erdogdu et al. [2021] are now available. Especially when combined with efficient

gradient computation, e.g. within low-rank coordinate descent [Mareček and M.,

2017, e.g.], this approach can tackle sufficiently large instances and is increasingly

popular.

In this chapter, we aim to develop a method combining both approaches, i.e.,

utilize an efficient low-rank-promoting penalty in the Burer-Monteiro approach. We

present efficient first-order numerical algorithms for solving the resulting penalized

problem, with (almost) linear-time per-iteration complexity. This makes the combined

approach applicable to a wide range of practical problems.

In a case study, we focus on certain combinatorial optimization problems and

inference in graphical models. We show that despite the non-convexity of the

penalized problem, our approach successfully recovers rank-one solutions in practice.

We compare our solutions against non-penalized SDP, belief propagation, and state-

of-the-art branch-and-bound solvers of Krislock et al. [2014].

Contribution. Our contributions can be summarized as follows. We show

1. convergence properties of optimization methods employing a wide class of

penalty functions that promote low-rank solutions;

2. linear-time algorithms for computing the gradient of these penalty functions;

30

Chapter 4. Entropy-Penalized Semidefinite Programming

4.2. Background

3. computational results on the penalized SDP relaxation of Maximum A-Posteriori

(MAP) estimates in Markov random fields (MRF), which considerably improve

upon the results obtained by interior-point methods and randomized rounding.

This allows for both well-performing and easy-to-analyze low-rank methods for

SDPs coming from graphical models, combinatorial optimization, and machine

learning.

Chapter structure. This chapter is organized as follows. First, we define the

conic optimization problem together with a penalized form with a list of suitable

penalization functions. Next, we present theoretical guarantees for solution recovery.

These extend known results for solution recovery to the penalty case. Then, we

consider the MAP problem in Markov random fields (MRF) and introduce an iterative

procedure for it, together with a first-order method for solving a subproblem at each

step; we also show how to compute the gradients efficiently. Finally, we provide

computational experiments for different inference problems in MRF.

4.2 Background

SDP is the following conic optimization problem:

min
𝑋∈S𝑛
+

∑︁

𝑖∈𝐼

𝑓𝑖(tr 𝑋𝑆𝑖)

s.t.: 𝑔𝑗(tr 𝑋𝐶𝑗) ≤ 0,

𝑗 ∈ 𝐽,

(SDP)

where 𝑊 ∈ S𝑛
denotes that the 𝑛 × 𝑛 matrix variable 𝑊 is symmetric positive
+
semidefinite, 𝐼 and 𝐽 are finite index sets, each 𝑓𝑖 and 𝑔𝑗 are convex functions
R𝑛×𝑛 → R, and 𝐶𝑗 ∈ 𝑅𝑛×𝑛 and 𝑆𝑖 ∈ R𝑛×𝑛 are constant matrices.

In the context of combinatorial optimization, one may also consider even more

powerful methods such as Sum-of-Squares hierarchies of Parrilo [2003]. However,

even an SDP relaxation, which is, in fact, the first step of this hierarchy, may be too

computationally challenging. It is usually solved by interior-point methods in the

dimension that is quadratic in the number of variables and thus becomes intractable

31

Chapter 4. Entropy-Penalized Semidefinite Programming

4.2. Background

even for medium-scale problems (with a few thousand variables). The problem

becomes even less scalable for higher orders of the hierarchy since it requires one to

solve SDP with 𝑛Θ(𝑑) variables, where 𝑑 is the level of the hierarchy.

4.2.1 Low-rank Relaxations and Penalized Problem

First, let us formally define our notion of a penalty function and explain related work

on first-order methods for SDP.

Assumption 1. Eq. (SDP) has an optimum solution with rank 𝑟.

Let us consider the following proxy problem:

𝑃𝑞,𝜆

.
= min

𝑉 ∈𝑅𝑛×𝑞

∑︁

𝑖∈𝐼

𝑓𝑖(tr(𝑉 ⊤𝑆𝑖𝑉 )) + 𝑅𝑞,𝜆(𝑉 )

(P-SDP)

s.t.: 𝑔𝑗(tr(𝑉 ⊤𝐶𝑗𝑉 )) ≤ 0, 𝑗 ∈ 𝐽.

Where 𝑞 > 𝑟 and 𝑅𝑞,𝜆(𝑉 ) satisfies the following:

Definition 1 (Strict penalty function). A function ℛ𝑞,𝜆(𝑉 ) : R𝑛×𝑛 → R is a penalty
function that promotes low-rank solutions if for some integers 𝑞′ ≤ 𝑞 and a multiplier

𝜆 ∈ R+:

lim
𝜆→∞

ℛ𝑞,𝜆(𝑉 ) =

⎧
⎪⎨

⎪⎩

0

if rank (𝑉 ) < 𝑞′,

∞ if rank (𝑉 ) = 𝑞.

Moreover, if 𝑞′ = 𝑞 and the rank (𝑋) < 𝑞, then ℛ𝑞,𝜆(𝑉 ) = 0, ∀𝜆, 𝑅(𝑉 ) is a strict
penalty function.

We use the word penalty instead of penalty function that promotes low-rank

solutions, where there is no risk of confusion. This notion of a penalty is rather wide.

When multiplied by 𝜆, a determinant is a prime example. One may also consider

functions of the following quasi-norms.

1. The nuclear norm:

‖𝑋‖* =

∑︁

𝜎𝑖,

𝑖

32

(4.1)

Chapter 4. Entropy-Penalized Semidefinite Programming

4.2. Background

where 𝜎𝑖 is the 𝑖-th singular value, cf. Lemon et al. [2016]. The norm is also
known as a trace norm, Schatten 1-norm, and Ky Fan norm. As shown by

Srebro et al. [2004], in the method of Burer and Monteiro [2003], one can

benefit from a bi-Frobenius reformulation:

‖𝑋‖* =

min
𝑈 ∈R𝑛×𝑑
𝑉 ∈R𝑛×𝑑:𝑋=𝑈 𝑉 𝑇

‖𝑈 ‖𝐹 ‖𝑉 ‖𝐹

= min

𝑈,𝑉 :𝑋=𝑈 𝑉 𝑇

‖𝑈 ‖2

𝐹 + ‖𝑉 ‖2
𝐹

2

.

There are also truncated Hu et al. [2013] and capped variants Sun et al. [2013].

2. Schatten-𝑝 quasi-norm for 𝑝 > 0:

‖𝑋‖𝑆𝑝 =

)︃1/𝑝

𝜎𝑝
𝑖 (𝑋)

,

(︃ 𝑛

∑︁

𝑖=1

(4.2)

where 𝜎𝑖(𝑋) denotes the 𝑖-th singular value of 𝑋.

3. A smoothed variant of Schatten-𝑝 quasi-norm by Pogodin et al. [2017] defined

in the previous chapter, see eq. 3.7.

4. Tri-trace quasi-norm of Shang et al. [2018]:

‖𝑋‖Tri-tr = min

𝑋=𝑈 𝑉 ϒ⊤

‖𝑈 ‖*‖𝑉 ‖*‖Υ‖*,

which is also the Schatten-1/3 quasi-norm.

5. Bi-nuclear (BiN) quasi-norm of Shang et al. [2018]:

‖𝑋‖BiN = min
𝑋=𝑈 𝑉 𝑇

‖𝑈 ‖*‖𝑉 ‖*,

which is also the Schatten-1/2 quasi-norm.

6. Frobenius/nuclear quasi-norm of Shang et al. [2018]:

‖𝑋‖F/N = min
𝑋=𝑈 𝑉 𝑇

‖𝑈 ‖*‖𝑉 ‖𝐹 ,

33

(4.3)

(4.4)

(4.5)

Chapter 4. Entropy-Penalized Semidefinite Programming

4.3. Exact Recovery

which is also the Schatten-2/3 quasi-norm.

We also note there has been considerable interest in the analysis of low-rank

approaches without penalization, especially in matrix-completion applications. Much

of the analysis goes back to the work of Keshavan et al. [2010]. For further important

contributions, see Sanjeev et al. [2012].

4.2.2 Entropy Viewpoint

One could see the penalty functions introduced above from the entropy-penalization

perspective. This is useful not only from a methodological standpoint, but also from

a computational one. To this end, we consider the Tsallis entropy:

𝒮 𝑇

𝛼(𝑋) =

1
1 − 𝛼

)︂
(︂ tr 𝑋 𝛼
(tr 𝑋)𝛼 − 1

.

The Tsallis entropy is crucial in our study because it generalizes many popular

penalties considered earlier. The Schatten 𝑝-norm coincides with the Tsallis entropy

𝒮 𝑇
𝑝

over a set of matrices with a fixed trace norm, so that the tri-quasi norm and

bi-nuclear norm (2–6) are covered as well. The Log-Det function, − log det 𝑋, which

is also used in low-rank SDP, is up to an additive constant factor relative (Shannon)

entropy taken concerning a unit matrix, while Renyi (𝒮 𝑅) and von Neumann (𝒮 𝑁 )

entropies,

𝒮 𝑅

𝛼 (𝑋) =

log tr(𝑋/ tr 𝑋)𝛼
1 − 𝛼

and

𝑆𝑁

𝛼 (𝑋) = − tr(log(𝑋/ tr 𝑋) · 𝑋/ tr(𝑋)),

respectively, can also be used as penalties to promote a low-rank solution. To the

best of our knowledge, neither Renyi, von Neumann, nor Tsallis entropies have been

studied in the context of low-rank SDP.

4.3 Exact Recovery

Let us now present a unified view of the penalties and their properties:

34

Chapter 4. Entropy-Penalized Semidefinite Programming

4.3. Exact Recovery

Lemma 3. Any of:

1. 𝜆 det(𝑋);

2. 𝜆𝜎𝑞(𝑋), where 𝜎𝑖(𝑋) denotes the 𝑖-th singular value of 𝑋;

3. Tsallis, Renyi, and von Neumann entropies defined on the last 𝑛−𝑞 +1 singular

values;

4. 𝜆 max

{︁

0,

‖𝑋‖*

max{𝜎min(𝑋),𝜎𝑞(𝑋)} − 𝑞

}︁

,

is a penalty function that promotes low-rank solutions. Moreover, penalties 1–3 are

strict.

Proof. Sketch. (1.) The proof is by simple algebra. (2.) If 𝜎𝑞(𝑋) is 0, we know the
rank is 𝑞 − 1 or less. Otherwise, for large values of 𝜆, the value of the penalties

goes to infinity, and hence 𝑞′ = 𝑞. (3.) The definition of entropy assumes that

𝑆(0, ..., 0) = 0, thus all entropies are strict penalty functions by definition. (4.)

First, consider the case where all non-zero singular values are equal. In that case,

‖𝑋‖*/𝜎min(𝑋) = rank (𝑋), and subtracting 𝑞 results either in a non-positive number
when the rank is less than 𝑞 or a positive number otherwise. If the singular values
are non-equal, ‖𝑋‖*/𝜎min(𝑋) provides an upper bound on the rank of 𝑋, which can
be improved as suggested. The use of the upper bound results in the value of the

penalty tending to infinity for values between 𝑞′ and 𝑞 in the large limit of 𝜆.

Crucially, under mild assumptions, any penalty allows for the recovery of the

optimum of a feasible instance of (SDP) from the iterations of an algorithm on the

non-convex problem in variable 𝑉 ∈ R𝑛×𝑟, such as in the methods of Frostig et al.

[2014] or Burer and Monteiro [2003]. In contrast to the traditional results of Burer

and Monteiro [2005], who consider the det penalty, we allow for the use of any strict

penalty function.

Theorem 4. Assume that we solve the proxy problem (P-SDP) iteratively and

ℛ𝑞,𝜆(𝑉 ) is a strict penalty function that promotes low-rank solutions.

In each

iteration, if ℛ𝑞,𝜆(𝑉 ) ̸= 0, we increase 𝜆 (e.g., set 𝜆𝑡+1 = 𝛾𝜆𝑡, with 𝑢 > 1 as some

fixed parameter). Furthermore, let us assume that the solution we found is denoted

35

Chapter 4. Entropy-Penalized Semidefinite Programming

4.3. Exact Recovery

some factorization of
(such factorization exists because rank ( ˜𝑉𝑞) = 𝑞′). Also assume that we have

by ˜𝑉𝑞 with rank ( ˜𝑉𝑞) = 𝑞′ < 𝑞. Let us also denote ˜𝑉𝑞′ ∈ R𝑛×𝑞′
˜𝑉𝑞
an optimal solution of (SDP), 𝑋 * with a rank (𝑋 *) = 𝑟.

˜𝑉 ⊤
𝑞

If

𝑉𝑞′+𝑟+1 (cid:44) [ ˜𝑉𝑞′, 0𝑛×𝑟, 0𝑛×1]

(4.6)

is a local minimum of 𝑃𝑞′+𝑟+1,𝜆, then ( ˜𝑉𝑞′) ˜𝑉 ⊤
𝑞′

is a global solution of SDP.

Proof. Let us define a family of matrices for 𝜏 ∈ [0, 1] as follows:

√

𝑉 (𝜏 ) (cid:44) [

𝜏 ˜𝑉𝑞′, √︀(1 − 𝜏 )𝑉*, 0𝑛×1],

where (𝑉*)⊤(𝑉*) is some factorization of 𝑋 * with 𝑉* ∈ R𝑛×𝑟.

Note that ∀𝜏 , we have rank (𝑋(𝜏 )) < 𝑟+𝑞′+1, and hence ∀𝜆, 𝜏 : 𝑅𝑞′+𝑟+1,𝜆(𝑉 (𝜏 )) =
0. Now, assume the contradiction, that is, 𝑉𝑞′+𝑟+1 is a local optimum solution but
˜𝑉𝑞′ is not a global solution.

We show that ∀𝜏 ∈ [0, 1], 𝑉 (𝜏 ) is a feasible solution. Indeed, for any 𝑗 ∈ 𝐽 we

have

𝑔𝑗(tr(𝑉 (𝜏 )𝑇 𝐶𝑗 tr(𝑉 (𝜏 )) ≤

𝜏 𝑔𝑗(tr([ ˜𝑉𝑞′, 0𝑛×𝑟+1]⊤𝐶𝑗[ ˜𝑉𝑞′, 0𝑛×𝑟+1]))+

(1 − 𝜏 ) tr([0𝑛×𝑞′, 𝑉*, 0𝑛×1]⊤𝐶𝑗[0𝑛×𝑞′, 𝑉*, 0𝑛×1])) =

𝜏 𝑔𝑗(tr( ˜𝑉 ⊤

𝑞′ 𝐶𝑗

˜𝑉𝑞′)) + (1 − 𝜏 ) tr(𝑋 *𝐶𝑗)) ≤ 0.

We just showed that for each 𝑉 (𝜏 ), 𝜏 ∈ [0, 1] is a feasible point. Now, let us

compute the objective value at this point. For all 𝜏 ∈ [0, 1], we have

tr(𝑉 (𝜏 )⊤𝑆𝑖𝑉 (𝜏 )) ≤ 𝜏

∑︁

𝑖∈𝐼

∑︁

𝑖∈𝐼

tr( ˜𝑉 ⊤

𝑞′ 𝑆𝑖

˜𝑉𝑞′) + (1 − 𝜏 )

tr(𝑋 *𝑆𝑖) <

∑︁

𝑖∈𝐼

tr( ˜𝑉 ⊤

𝑞′ 𝑆𝑖

˜𝑉𝑞′)

∑︁

𝑖∈𝐼

which is a contradiction under the assumption that ˜𝑉𝑞 is a local optimum.

36

Chapter 4. Entropy-Penalized Semidefinite Programming

4.4. MAP Inference

4.4 MAP Inference

A pairwise Markov random fields (MRF) is defined for an arbitrary graph 𝐺 = (𝑉, 𝐸)
with 𝑛 vertices. We associate a binary variable 𝑥𝑖 ∈ {−1, +1} with each vertex 𝑖 ∈ 𝑉 .
Let 𝜃𝑖 : {±1} → R and 𝜃𝑖𝑗 : {±1}2 → R defined for each vertex and edge of the
graph be vertex and pairwise potential, respectively. Thus, a posteriori distribution

of 𝑥 follows the Gibbs distribution:

𝑝(𝑥|𝜃) =

1
𝑍(𝜃)

𝑒𝑈 (𝑥|𝜃),

with 𝑈 (𝑥; 𝜃) = ∑︀
estimate is then

𝑖∈𝑉 𝜃𝑖(𝑥𝑖) + ∑︀

(𝑖,𝑗)∈𝐸 𝜃𝑖𝑗(𝑥𝑖, 𝑥𝑗). The Maximum A-Posteriori (MAP)

ˆ𝑥 = argmax
𝑥∈{−1,1}𝑛

𝑝(𝑥|𝜃) = argmax
𝑥∈{−1,1}𝑛

𝑈 (𝑥; 𝜃),

(MAP)

which is its turn an NP-hard binary quadratic optimization problem,

ˆ𝑥 = argmax
𝑥∈{−1,1}𝑛

𝑥⊤𝑆𝑥,

with indefinite matrix 𝑆. The SDP relaxation for this problem is given by Goemans

and Williamson [1995], Nesterov [1998]:

tr 𝑆𝑋,

s.t.: 𝑋𝑖𝑖 = 1,

min
𝑋∈S+
𝑛

(4.7)

which also covers the Ising model in statistical physics and a number of combinatorial

optimization problems. We believe that the approach can be extended to a general

setup given by Eq. (SDP).

An Entropy-Penalized SDP (EP-SDP) relaxation of (4.7) has the form

tr 𝑉 ⊤𝑆𝑉 + 𝑅𝜆(𝑉 ),

s.t.: ‖𝑉 𝑖‖2

2 = 1,

(EP-SDP)

min
𝑋∈S+
𝑛

where 𝑉 𝑖 is the 𝑖-th column of matrix 𝑉 ∈ R𝑛×𝑘, 𝑋 = 𝑉 𝑉 ⊤.

37

Chapter 4. Entropy-Penalized Semidefinite Programming

4.4. MAP Inference

4.4.1 Numerical Method.

To solve Problem (EP-SDP), we use the Augmented Lagrangian method starting

from a sufficiently small value of the penalty parameter 𝜆 > 0 and increasing it in
geometric progression, 𝜆𝑘+1 = 𝜆𝑘𝛾, with 𝛾 > 1, as summarized in Algorithm 2. The
efficiency of the method is due to the efficient computability of gradients of Tsallis,

Renyi, and von Neumann entropies:

Algorithm 2: Entropy-Penalized SDP.

Data: Quadratic matrix 𝑆 of the MAP inference problem, staring point 𝜆0,

𝛾 > 1, step size policy {𝜂𝑘}𝑘≥1 accuracy parameters 𝜀, 𝜖

Result: Solution 𝑉* as a local minimum of (EP-SDP) of unit rank
begin

𝑉0 ← random initialization in R𝑛×𝑘;
while tr(𝑉 ⊤

𝑡 𝑉𝑡) − 𝜆max𝑉𝑡 > 𝜀 do

Find local minimum of EP-SDP(𝑆, 𝜆𝑡) starting from 𝑉𝑡−1, assign it to
𝑉𝑡;
while ∇(tr 𝑉 ⊤𝑆𝑉 + 𝑅𝜆(𝑉 )) ≤ 𝜖 do

𝑉 = 𝑉 − 𝜂𝑘∇(tr 𝑉 ⊤𝑆𝑉 + 𝑅𝜆(𝑉 ))/‖∇(tr 𝑉 ⊤𝑆𝑉 + 𝑅𝜆(𝑉 ))‖2;
𝑉𝑖 ← 𝑉𝑖/‖𝑉𝑖‖2 for each row 𝑉𝑖;

end
𝜆𝑡+1 = 𝜆𝑡 · 𝛾;

end

end
Return: first singular vector of 𝑉𝑡.;

Lemma 5. For any matrix 𝑉 ∈ R𝑛×𝑘 with 𝑘 = 𝒪(1), let 𝑋(𝑉 ) = 𝑉 ⊤𝑉 . Then,
𝛼(𝑋), 𝒮 𝑅(𝑋), and 𝒮 𝑁 (𝑋) can be computed in 𝒪(𝑛) time. Moreover,
if the number of non-zero elements in matrix 𝐴 is 𝒪(𝑛), then the iteration complexity

gradients of 𝒮 𝑇

of Algorithm 2 is 𝒪(𝑛).

Proof. We start our analysis with Tsallis entropy. First, compute the gradient of 𝒮 𝑇
𝛼

in 𝑉 :

𝜕 𝒮 𝑇
𝛼(𝑋)
𝜕𝑉

=

𝛼
1 − 𝛼

(︂ 𝑋 𝛼−1
(tr 𝑋)𝛼 −

tr 𝑋 𝛼
(tr 𝑋)𝛼+1 𝐼

)︂

𝑉.

Similarly for Renyi, 𝒮 𝑅(𝑋), and von Neumann, 𝒮 𝑁 (𝑋), entropies we have

𝜕 𝒮 𝑅
𝛼 (𝑋)
𝜕𝑉

=

𝛼
1 − 𝛼

𝑋 𝛼−1
tr 𝑋 𝛼

(︂

𝐼 −

)︂

𝑉

𝑋
tr 𝑋

38

Chapter 4. Entropy-Penalized Semidefinite Programming

4.5. Case Study

and

𝜕 𝒮 𝑁
𝛼 (𝑋)
𝜕𝑉

=

tr 𝑋𝐼 − 𝑋
(tr 𝑋)2

(︂

𝐼 + log

)︂

𝑉.

𝑋
tr 𝑋

Following Holmes et al. [2007], the singular-value decomposition of matrix 𝑉 = 𝑈1𝐷𝑈2
with 𝑈1 ∈ R𝑛×𝑛, 𝐷 ∈ R𝑛×𝑘, and 𝑈2 ∈ R𝑘×𝑘 can be performed in 𝒪(min (𝑛𝑘2, 𝑛2𝑘)) =
𝒪(𝑛𝑘2) time.

For any 𝛼 > 1, the product 𝑋 𝛼−1 · 𝑉 = 𝑈1𝐷2𝛼−1𝑈2 can be computed in time 𝒪(𝑛)
together with tr 𝑋 𝛼 = tr 𝐷2𝛼 and tr 𝑋 = tr 𝐷2. Thus, for a fixed 𝑘, the gradient
𝜕 𝒮𝑇 (𝑋)
𝜕𝑉

computation time is linear in its dimension. (Here, for any 𝛼 ∈ (0, 1), we
⊤𝜕𝑋vi.) To finish the proof of the statement, it remains to
use the identity 𝜕𝜆𝑖 = vi
note that matrix-vector multiplication takes 𝒪(𝑛) time for any matrix with 𝒪(𝑛)

non-zero entries.

4.5 Case Study

In this section, we compare our penalized algorithm with other conventional ap-

proaches to MAP problems. We fix the width of factorization to 𝑘 = 10, since there is

no significant gain in practice for larger values of 𝑘, cf. Song et al. [2017]. We choose
2𝜂𝑘𝛽 = 1, where 𝛽 is the Lipschitz constant of the gradient in ℓ2 norm and 𝛾 = 3/2.
Parameters 𝜆0 and 𝛾 of Algorithm 2 are usually chosen by a few iterations of random
search. It is usually enough to have about 35 iterations for penalty updates and a few

hundred iterations to find a local minimum using Algorithm 2. We emphasize that

matrices we obtain by solving EP-SDP are rank-one solutions on all MAP instances

presented. Thus, we do not need any further rounding procedure.

First, in Table 1, we show the performance of our algorithm on selected hard

MAP inference problems from the BiqMac collection1. We selected a few of the

hardest instances ("gkaif" among them)—dense quadratic binary problems of 500

variables.

We compared our algorithm (EP-SDP with Tsallis entropy and 𝛼 = 2) with the

plain-vanilla semidefinite programming instance solved by the interior-point method,

possibly with rounding using the best of one thousand roundings of Goemans and

1http://biqmac.uni-klu.ac.at/biqmaclib.html

39

Chapter 4. Entropy-Penalized Semidefinite Programming

4.5. Case Study

Instance

gka1f

gka2f

gka3f

gka4f

gka5f

objective
upper bound
time [s]

59426
66783
669

objective
upper bound
time [s]

60840
n/a
3.3

SDP

1347603
152758
592

97809
109826
673
EP-SDP

185090
168616
out of
out of
memory memory

99268 136567 170669 189762

n/a
5.0

n/a
5.3

Gurobi

n/a
5.2

n/a
5.7

objective
upper bound
time [s].

64678
73267
70

97594
112223
70

131898
153726
71

162875
190073
70

189324
218428
70

Table 4.1: The comparison between the standard SDP relaxation, Entropy-Penalized
SDP (EP-SDP) and the MIP solver (Gurobi) for the MAP instances from BiqMac
collection.

Williamson [1995] and also with Gurobi Gurobi Optimization, LLC [2021], a Mixed-

Integer Problem (MIP) solver. To avoid any confusion, we solve the corresponding

maximization problems; by the objective value, we mean the value at a feasible

solution produced by the method (e.g., rounded solution of SDP relaxation), which

is a lower bound for the corresponding problem. Because these problems are of the

same size (but varying density), the running time of each method is almost constant.

It took around 10 minutes for CVXPY [2021] to solve the SDP relaxation, and it

runs out of memory for the two problems with higher density. Within five seconds,

EP-SDP obtains results that are better than what Gurobi can produce in 70 seconds.

In our study, parameter 𝛼 of entropies 𝒮 𝑇
𝛼
grid from 1 to 10 with a step 1.1. After experimentation, we note that 𝛼 = 1.1 and

is chosen on an exponential

, and 𝒮 𝑅
𝛼

, 𝒮 𝑁
𝛼

𝛼 = 5.0 seem to improve the results the best for the LR-SDP with Tsallis and Renyi

entropies, respectively, although the difference between different 𝛼 ∈ (1, 10) is not

very significant for either of the (Tsallis and Renyi) entropies.

Table 2 summarizes the results of solving the Max-Cut problem over a GSET

40

Chapter 4. Entropy-Penalized Semidefinite Programming

4.5. Case Study

GSET Instance

1

2

3

4

EP-SDP
(T, 𝛼 = 2.0)
(T, 𝛼 = 1.1)
(R, 𝛼 = 5)
(R, 𝛼 = 10)
SDP
Loopy BP
Mean-Field

11485
11454
11508
11520
11372
10210
11493

11429
11469
11444
11463
11496
11519
11523
11420
11279
11363
10415
10687
11515
11525
GSET Instance

11442
11508
11531
11523
11355
10389
11512

EP-SDP
(T, 𝛼 = 2)
(T, 𝛼 = 1.1)
(R, 𝛼 = 5)
(R, 𝛼 = 10)
SDP
Loopy BP
Mean-Field

EP-SDP
(T, 𝛼 = 2)
(T, 𝛼 = 1.1)
(R, 𝛼 = 5)
(R, 𝛼 = 10)
SDP
Loopy BP
Mean-Field

5

6

7

8

11427
11506
11527
11538
11313
10143
11528

2059
2075
2127
2112
1945
1076
2096

1888
1858
1942
1940
1728
964
1906

1866
1895
1954
1958
1727
731
1912

GSET Instance
12
10

11

13

9

1882
1933
1861
1969
1992
1960
2006 1982
1784
1767
820
1021
1902
1940

560
530
532
544
536
568
550 548 568
564
546
544
540
514
524
482
412
424
564
538
542

Table 4.2: The comparison results between Entropy-Penalized SDP (EP-SDP) and
other heuristics for solving MAP such as SDP, Loopy Belief Propagation and Mean-
field method. Under the umbrella term Entropy-Penalized SDP (EP-SDP) we evaluate
here Tsallis and Renyi entropy regularisers for different values of the parameter 𝛼.

collection of sparse graphs2. As we see from the experiments, the results of applying

suitable entropy often outperform both the plain-vanilla SDP with the classical

Goermans-Williamson rounding, the mean-field approximation, as well as the results

of UGM solver3 for loopy belief propagation and mean-field inference. It is worth not-

ing that for several instances of the GSET graph collection, loopy belief propagation

2https://sparse.tamu.edu/Gset
3https://www.cs.ubc.ca/ schmidtm/Software/UGM.html

41

Chapter 4. Entropy-Penalized Semidefinite Programming

4.5. Case Study

𝛼 = 2 and 𝛾 = 2
𝛼 = 2 and 𝛾 = 1.5
𝛼 = 5 and 𝛾 = 2

2

4

6

8

10

power of 𝛾

Figure 4-1: Rank decrement.

𝜆0 = 10 and 𝛾 = 1.5
𝜆0 = 40 and 𝛾 = 1.5
𝜆0 = 100 and 𝛾 = 1.5

𝑉

f
o

e
u
l
a
V
r
a
l
u
g
n
i
S

d
n
o
c
e
S

𝑉

f
o

e
u
l
a
V
r
a
l
u
g
n
i
S

d
n
o
c
e
S

10

8

6

4

2

0

10

8

6

4

2

0

2

4

6

8

10

Power of 𝛾

Figure 4-2: Rank decrement with multistart.

provides rather weak results. Usually, strong results of the loopy belief propagation

are complementary to those of the mean-field approximation, which is supported

by our empirical results. Results of both loopy belief propagation and mean-field

approximation can be substantially improved using the linear-programming belief-

propagation approach (LP-BP).

We also want to point out that our iterative algorithm successfully decreases the

rank of the solution. The higher the penalization parameter, the lower the rank. We

illustrate this in Figure 4-1, where for Tsallis entropies with 𝛼 = 2 and 𝛼 = 5, we

plot the second singular value of matrix 𝑉 . For this plot, we considered the Max-Cut

problem for the first graph from the GSET collection and the Tsallis entropy as

the penalization function. In Figure 4-2, we illustrate the same concept for fixed

penalization (Tsallis entropy with 𝛼 = 2) and different initial values of the multiplier

𝜆. We observe that for different penalization functions and update schemes, the rank

of the solution decreases gradually with each step. In practice, our iterative algorithm

could be seen as a universal rounding procedure for SDP relaxations. Indeed, if we

42

Chapter 4. Entropy-Penalized Semidefinite Programming

4.6. Conclusions

EP-SDP
LR-SDP
SDP

s
d
n
o
c
e
S

n
i

e
m
T

i

80

60

40

20

0

100

200
Number of Vertices

300

400

500

Figure 4-3: Run time comparison for Erdos-Renyi random graphs of different size.
Here we compare only SDP-based approaches and show that the EP-SDP is the
fastest and it’s time complexity is linear in the number of vertices.

choose a large-enough penalization update (e.g., 𝛾 = 2 as in Figure 1), we easily

obtain a rank-one solution that is not worse and often is substantially better than

solutions obtained by randomized rounding.

Similar problems to the one considered in the chapter appear in a variety of

applications such as recommender systems Sidana et al. [2021], Anikin et al. [2020],

machine learning Amini et al. [2022], Chertkov et al. [2020], Maximov et al. [2018],

and statistical physics Likhosherstov et al. [2019a,b].

Overall, we would like to stress that Algorithm 2 is very fast. This is shown

in Figure 3 and Table 3, where we compare run times of EP-SDP, Low-Rank

Burer-Monteiro SDP (LR-SDP), and interior-point method solvers (SDP) for various

Erdos-Renyi random graphs. From the data, we see that (assuming the fixed width

of factorization 𝑘 = 10) EP-SDP run time increases linearly with the number of

vertices. Indeed, throughout the benchmark instances tested, the run time does not

exceed a few seconds per each of the test cases. At the same time, the bound is often

almost as good as that of the Branch and Bound Biq-Mac Solver of Krislock et al.

[2014], which requires a significant amount of time.

4.6 Conclusions

This chapter presented a unified view of the penalty functions used in low-rank

semidefinite programming using entropy as a penalty. This makes it possible to find a

43

Chapter 4. Entropy-Penalized Semidefinite Programming

4.6. Conclusions

Instance
E-R(50, 0.2)
E-R(100, 0.2)
E-R(200, 0.2)
E-R(300, 0.2)
E-R(400, 0.2)
E-R(500, 0.2)

EP-SDP LR-SDP SDP
0.4s
1.4s
7.6s
21.0s
45.0s
85.0s

0.2s
0.3s
0.5s
0.8s
1.0s
1.3s

0.1s
0.4s
1.6s
3.9s
6.0s
8.9s

Table 4.3: Run time comparison for Erdos-Renyi random graphs of different size (the
number of vertices). Here we compare only SDP-based approaches and show that
the EP-SDP is the fastest. The results are averaged over 500 samples for every row.

low-rank optimum, where there are optima of multiple ranks. Semidefinite programs

with an entropy penalty can be solved efficiently using first-order optimization

methods with linear-time per-iteration complexity, which makes them applicable to

large-scale problems that appear in machine learning and polynomial optimization.

Our case study illustrated the practical efficiency on binary MAP inference problems.

The next step in this direction is to consider the structure of the SDP, which seems

to be crucial for further scalability.

44

Chapter 5

Ising Model Control

5.1

Introduction

We follow the previous work Chertkov et al. [2021] in justification for the use of the

Graphical Models (GM) to study and mitigate pandemics. Therefore, we start from

providing a brief recap of the prior literature on modeling of the epidemics, describe

the logic which led us in Chertkov et al. [2021] to the Ising Model (IM) formulation,

and then state formally the inference and prevention problems addressed in the

manuscript.

Difficulty in both predicting and neutralizing the spread of pandemics is a major

social challenge of humanity. Technically speaking, we are yet to design a coherent

data lifecycle for modeling and prevention both in terms of the global strategies and

local tactics. To address the challenge, we must devise a hierarchy of spatio-temporal

models with different resolutions – from individual to community, county to the

city, and from the moment a pathogen first enters our bodies, to days of disease

development and to community transmission. Importantly, the models should be

efficient in computing probabilistic predictions (for instance, offering the marginal

probability heat map for the city neighborhoods to transition from the current/prior

state of infection to the projected/a-posteriori state in two weeks).

Epidemiology and Mathematical Biology experts have relied in the past on a

number of modeling approaches. The Agent-Based-Model (ABM), introduced in

epidemiology in 2004-2008 Eubank et al. [2004], Longini et al. [2005], Ferguson et al.

45

Chapter 5.

Ising Model Control

5.1.

Introduction

[2005, 2006], Germann et al. [2006], Halloran et al. [2008], have complemented the

earlier compartmental models Ross [1910], Kermack et al. [1927], Anderson and May

[1991], Hethcote [2000]. Using ABMs, even though not exclusive to epidemiology

Wikipedia [2020], Downey [2018], became a breakthrough in the field, as they allowed

to make a significant improvement in the quality of predictions, especially in the

spatio-temporal resolution of how the disease spreads and how one can mitigate its

spread. The models became and remained a core part of the epidemiology data

life-cycle. (See for instance Lovasi and et.al. [2020], Kerr et al. [2021] for most recent

bibliography.) The ABMs provide a detailed prediction of how pandemics spread

within counties, cities, and regions. A majority of the country-, city- or county- scale

testbeds testing various mitigation strategies are resolved nowadays with ABMs. In

particular, recently ABMs have been used extensively to inform public health in

(non-pharmaceutical) interventions against the spread of COVID-19 Ferguson et al.

[2020], Eubank et al. [2020], LANL [2020], Maziarz and Zach [2020], Kaxiras and

Neofotistos [2020], and verify new strategies like test-trace-quarantine Kerr et al.

[2021], among many other applications.

There are two major problems with the modeling of pandemic. First, many

parameters need to be calibrated on data. Second, even when calibrated for the

current state of pandemic the models which are too detailed become impractical for

making a forecast and for developing prevention strategies – both requiring checking

multiple (forecast and/or prevention) scenarios. Using ABMs, which are clearly

over-modeled (too detailed) is especially problematic in the context of the latter.

For example, the open-source ABM solver FLUTE Chao et al. [2010] developed

originally for modeling influenza, works with data that are acquired through Geo-

graphic Information Systems (GIS) on the scale of census tracts or communities,

which is a very reasonable scale of spatial resolution to understand the dynamics

of pandemics on a local scale. FLUTE populates each of the communities with

thousands to millions of inhabitants in order to account for their daily patterns of

travel. We believe that constructing effective Graphical Models (GM) of Pandemics

with community-scale spatial resolution and then modeling pairwise (and possibly

higher-order) epidemic interactions between communities directly, without introduc-

46

Chapter 5.

Ising Model Control

5.1.

Introduction

ing the thousands-to-millions of dummy agents, will complement (as discussed in the

next paragraph), but also improve upon ABMs by being more efficient, robust and

easier to calibrate.

An important, and possibly one of the first, Graphical Models (GM) of the

COVID-19 pandemic was proposed in Chang et al. [2020]. Dynamic bi-partite GMs

connecting census tracts to specific Points Of Interest (non-residential locations that

people visit such as restaurants, grocery stores and religious establishments) within

the city and studying dynamics of the four-state (Susceptible, Exposed, Infectious

and Removed) of a census tract (graph node) on the graph, were constructed in

Chang et al. [2020] for major metro-area in USA based on the SafeGraph mobility

data SafeGraph [2021b].

In fact, similar dynamic GMs, e.g. of the Independent Cascade Model (ICM) type

Kempe et al. [2003], Netrapalli and Sanghavi [2012], Gomez-Rodriguez et al. [2012],

Khalil et al. [2013], Rosenfeld et al. [2016], were introduced even earlier in the CS/AI

literature in the context of modeling how the rumors spread over social networks

(with a side reference on using ICM in epidemiology). As argued in Chertkov et al.

[2021] the Independent Cascade Model (ICM) can be adapted to modeling pandemics.

(Another interesting use of the ICM to model COVID-19 pandemic was discussed

in Chen et al. [2020].) In its minimal version, an ICM of Pandemic can be built as

follows. Assume that the virus spreads in the community (census tract) sufficiently

fast, say within five days – which is the estimate for the early versions of COVID-19

median incubation period. If an infected person enters a community/neighborhood

but does not stay there, he infects others with some probability. If a single resident

of the community becomes infected, all other residents are assumed infected as well

(instantaneously). The model is a discrete-time dynamic model in which nodes

in a network are in one of the three states: Susceptible, Infected, or Removed.

The nodes represent communities/neighborhoods. A contact between an Infected

community/node and another community which is Susceptible has an assigned

probability of disease transmission, which can also be interpreted as the probability

of turning the S state into I state. Consistently with what was described above, the

network is represented as a graph, where nodes are tracts and edges, connecting two

47

Chapter 5.

Ising Model Control

5.1.

Introduction

Figure 5-1: An exemplary random sequence (top-left to top-right to bottom-left to
bottom-right) of the Independent Cascade Model (ICM) dynamics over 3 × 3 grid.
Nodes colored red, blue, and black are Infected, Susceptible, and Removed at the
respective stage of the dynamical process. This (shown) sample of the dynamic
process terminates in 3 steps. Ising Model of Pandemic (IMP), which is the focal
point of this manuscript, describes a regularized version of the ICM terminal state,
where only two states (S-blue and R-black) are left. (See text for details.)

tracts, have an associated strength of interaction representing the probability for the

infection to spread from one node to its neighbor. A seed of the infection is injected

initially at random, for example, mimicking an exogenous super-spreader infection

event in the area; examples could include political or religious gatherings. See

Figure 5-1 illustrating dynamics of the cascade model over 3-by-3 grid graph. Color

coding of nodes is according to Susceptible=blue, Infected=red, Removed=black.

Given the starting infection configuration, each infected community can infect its

graph-neighbor community during the next time step with the probability associated

with the edge connecting the two communities. Then the infected community moves

into the removed state. The attempt to infect each neighbor is independent of all

other neighbors. This creates a cascading spread of the virus across the network.

The cascade stops in a finite number of steps, thereby generating a random Removed

pattern, shown in black in the Fig. 5-1, while other communities which were never

infected (remain Susceptible) are shown in blue.

It was shown in Chertkov et al. [2021] that with some regularization applied,

statistics of the terminal state of the Cascade Model of Pandemic turns into a

Graphical Model of the attractive Ising Model type.

This chapter Road Map. Working with the Ising Model of Pandemic, we

start the technical part of the manuscript by posing the Inference/Prediction

Challenge in Section 5.2. Here, the problem is stated, first, as the Maximum

A-Posteriori over an attractive Ising Model, and we argue, following the approach

which is classic in the GM literature, that problem can be re-stated as a tractable

48

Chapter 5.

Ising Model Control

5.2.

Ising Model of Pandemic

LP. We then proceed to Section 5.3 to pose the main challenge addressed in the

manuscript – the Prevention Challenge – as the two-level optimization with inner

step requiring resolution of the aforementioned Prediction Challenge. Aiming to

reduce the complexity of the Prevention problem, we turn in Section 5.4 to the

analysis of the conditions in the formulation of the Prediction Challenge, describing

the Safety domain in the space of the Ising Model parameters. We show the Safety

domain is actually a polytope, even though exponential in the size of the system.

We proceed in Section 5.6 with analysis of the Prevention Challenge, discussing

the interpretation of the problem as a projection to the Safety Polytope from the

polytope exterior, needed when the bare prediction suggests that system will be

found with high probability outside of the Safety Polytope. Section 5.5 is devoted

to approximation which allows an enormous reduction in the problem complexity.

We suggest here that if the graph of the system is sufficiently dense, the resulting

MAP solution may only be in one of the two polarized states (a) completely safe (no

other nodes except the initially infected) pick the infection, or (b) the infection is

spread over the entire system. We support this remarkable simplification by detailed

empirical analysis and also by some theoretical arguments. Section 5.7 is devoted

to the experimental illustration of the methodology on the practical example of the

Graphical Model of Seattle. The manuscript is concluded in Section 5.8 with a brief

summary and discussion of the path forward.

5.2

Ising Model of Pandemic

As argued in Chertkov et al. [2021] the terminal state of a dynamic model generalizing

the ICM model can be represented by the Ising Model of Pandemic (IMP), defined

over graph 𝒢 = (𝒱, ℰ), where 𝒱 is the set of 𝑁 = |𝒱| nodes and ℰ is the set of

undirected edges. The IMP, parameterized by the vector of the node-local biases,

ℎ = (ℎ𝑎|𝑎 ∈ 𝒱) ∈ R𝒩 , and by the vector of the pair-wise (edge) interactions,
𝐽 = (𝐽𝑎𝑏|{𝑎, 𝑏} ∈ ℰ), describes the following Gibbs-like probability distribution for a

49

Chapter 5.

Ising Model Control

5.2.

Ising Model of Pandemic

state, 𝑥 = (𝑥𝑎 = ±1|𝑎 ∈ 𝒱) ∈ 2|𝒱|, associated with 𝒱:

𝑃 (𝑥 | 𝐽, ℎ) =

exp (−𝐸(𝑥 | 𝐽, ℎ))
𝑍(𝐽, ℎ)

,

(5.1)

where any node, 𝑎 ∈ 𝒱 can be found in either S- (susceptable, never infected) state,
marked as 𝑥𝑎 = −1, or R- (removed, i.e. infected prior to the termination) state,
marked as 𝑥𝑎 = +1. In Eq. (5.1), 𝐸(𝑥|𝐽, ℎ) and 𝑍(𝐽, ℎ) are model’s energy function
and partition function respectively:

𝐸(𝑥 | 𝐽, ℎ) =

𝑍(𝐽, ℎ) =

∑︁

𝑎∈𝒱

∑︁

ℎ𝑎𝑥𝑎 −

∑︁

𝑎,𝑏∈𝒱

𝐽𝑎𝑏𝑥𝑎𝑥𝑏,

(︃

∑︁

)︃

𝐽𝑎𝑏𝑥𝑎𝑥𝑏

.

ℎ𝑎𝑥𝑎 −

∑︁

𝑎,𝑏∈𝒱

𝑥

𝑎∈𝒱

(5.2)

(5.3)

In what follows, we will focus on finding the Maximum A-Posteriori (MAP) state

of the IMP conditioned to a particular initialization – setting a subset of nodes,

ℐ ∈ 𝒱, to be infected. We coin the MAP problem Inference Challenge:

𝑥(MAP)(ℐ | 𝐽, ℎ) = arg min

𝑥

𝐸(𝑥 | 𝐽, ℎ)

⃒
⃒
⃒∀𝑎∈ℐ:

,

𝑥𝑎=+1

(5.4)

where we emphasize dependence of the MAP solution on the set of the initially

infected nodes, ℐ.

Note that in general finding 𝑥(MAP) is NP-hard Barahona [1982]. However if

𝐽 > 0 element-wise, i.e. the Ising Model is attractive (also called ferromagnetic

in statistical physics), Eq. (5.4) becomes equivalent to a tractable (polynomial in

𝑁 ) Linear Programming (see Živný et al. [2014] and references therein). Notice a

few other tractable cases for graphs with specific topology Chertkov et al. [2020],

Likhosherstov et al. [2020, 2019b,a] In fact, the IMP is attractive, reflecting the fact

that the state of a node is likely to be aligned with the state of its neighbor.

Let us also emphasize some other features of the IMP:

1. 𝒢 should be thought of as an "interaction" graph of a city, reflecting trans-

portation, commutes, and other forms of interactions between populations with

the homes at the two nodes (census tracts) linked by an edge. The strength of

50

Chapter 5.

Ising Model Control

5.3. Prevention Challenge

a particular 𝐽𝑎𝑏 shows the level of interaction associated with the edge {𝑎, 𝑏}.

2. A component, ℎ𝑎, of the vector of local biases, ℎ, is reflecting 𝑎-node specific
factors such as immunization level, imposed quarantine, and degree of com-

pliance with the public health measures (e.g., wearing masks and following

other rules). Large negative/positive ℎ𝑎 shows that residents of the census
tract associated with the node 𝑎 are largely healthy/infected.

If solution of the Inference Challenge problem is such that the R-subset of the MAP

solution, 𝑥(MAP)(ℐ|𝐽, ℎ), i.e.

ℛ(ℐ, 𝐽, ℎ) =

{︁

𝑎 ∈ 𝒱 | 𝑥(MAP)

𝑎

(ℐ|𝐽, ℎ) = +1

}︁
,

(5.5)

is sufficiently large, we would like to mitigate the infection, therefore setting the

Prevention Challenge discussed in the next Section.

5.3 Prevention Challenge

Let us assume that modification of 𝐽 and ℎ are possible and consider the space of

all feasible 𝐽 and ℎ. We will then identify Safe Domain as a sub-space of feasible 𝐽

and ℎ such that for all the initial sets of the initially infected nodes, ℐ, considered

the resulting "infected" subset, ℛ(ℐ, 𝐽, ℎ), is sufficiently small. A more accurate

definition of the Safe Domain follows. Then, we rely on the definition to formulate

the control/mitigation problem coined Prevention Challenge. At this stage, we would

also like to emphasize that studying the geometry of the Safe Domain is one of the

key contributions of this manuscript.

Definition. Consider IMP over 𝒢 = (𝒱, ℰ) and with the parameters (𝐽, ℎ). Let

us also assume that the set of initially infected nodes, ℐ, is drawn from the list, Υ.

We say that (𝐽, ℎ) is in the 𝑘-Safe Domain if for every ℐ from Υ the number of

R-nodes in the MAP solution (5.4), is at most 𝑘, i.e.

∀ℐ ∈ Υ :

|ℛ(ℐ, 𝐽, ℎ)| ≤ 𝑘,

(5.6)

51

Chapter 5.

Ising Model Control

5.4. Geometry of the MAP States

where ℛ(ℐ, 𝐽, ℎ) is defined in Eq. (5.5).

Prevention Challenge: Given (𝐽 (0), ℎ(0)) describing the bare status of the

system (city) which is not in the 𝑘-Safe Domain, and given the cost of the (𝐽, ℎ)
change, 𝐶 (︀(𝐽, ℎ); (𝐽 (0), ℎ(0)))︀, what is least expensive change to (𝐽 (0), ℎ(0)) state of
the system which is in the the 𝑘-Safe Domain? Formally, we are interested to solve

the following optimization:

(𝐽 (corr), ℎ(corr)) = arg min
(𝐽,ℎ)

𝐶 (︀(𝐽, ℎ); (𝐽 (0), ℎ(0)))︀

Eq. (5.6) .

(5.7)

Expressing it informally, the Prevention Challenge seeks to identify a minimal

correction (thus "corr" as the upper index) (𝐽 (corr), ℎ(corr)), which will move the system

to the safe regime from the unsafe bare one, (𝐽 (0), ℎ(0)). The measures may include

limiting interaction along some edges of the graph, thus modifying some components

of 𝐽, or enforcing local biases, e.g., increasing level of vaccination, at some component

of ℎ.

Given that condition in Eq. (5.6) also requires solving Eq. (5.4) for each candidate

(𝐽, ℎ), the Prevention Challenge formulation is a difficult two-level optimization.

However, as we will see in the next Section, the condition in Eq. (5.6) (and thus

the inner part of the aforementioned two-level optimization) can be re-stated as the

requirement of being inside of a polytope in the (𝐽, ℎ) space. In other words, the

(𝑘)-Safe Domain is actually a polytope in the (𝐽, ℎ) space.

5.4 Geometry of the MAP States

Before solving the Prevention Challenge problem, we want to shed some light on the

geometry of the MAP states. We work here in the space of all the Ising models over

a graph 𝒢 = (𝒱, ℰ), where each of the models is specified by (𝐽, ℎ).

Proposition. Safe Domain of a graph 𝒢 = (𝒱, ℰ) with 𝑁 = |𝒱| nodes is a

polytope in the space of all feasible parameters, (𝐽, ℎ), defined by an exponential in

𝑁 number of linear constraints.

52

Chapter 5.

Ising Model Control

5.4. Geometry of the MAP States

Remark. The Proposition allows us, from now on, to use Safe Polytope instead

of the Safe Domain.

Proof of the Proposition. The space of all the Ising models is divided into 2𝑁

regions by the corresponding MAP states. Moreover, the boundary between any pair

of neighboring regions is linear: consider two states 𝑥(𝑖) and 𝑥(𝑗), and denote (𝐽, ℎ)(𝑖)

(resp. (𝐽, ℎ)(𝑗)) the set of all the Ising models with the MAP state 𝑥(𝑖) (resp. 𝑥(𝑗)),

then (𝐽, ℎ)(𝑖) and (𝐽, ℎ)(𝑗) are separated by the equation, 𝐸(𝑥(𝑖) | 𝐽, ℎ) = 𝐸(𝑥(𝑗) | 𝐽, ℎ),

which is linear in (𝐽, ℎ). For a subset, 𝑅 ⊆ 𝒱, of nodes, let 𝑥(𝑅) be the state in which,
𝑥𝑎 = +1, ∀𝑎 ∈ 𝑅, 𝑥𝑎 = −1, ∀𝑎 /∈ 𝑅. Let 𝑋 (𝑅) be the set of all the MAP states, 𝑥,
such that ∀𝑎 ∈ 𝑅, 𝑥𝑎 = +1 (while other nodes, i.e. 𝑏 ∈ 𝒱 ∖ 𝑅, are not constrained,
𝑥𝑏 = ±1). Then the 𝑘-Safe Polytope, which we denote, SP(𝑘), is defined by at most
𝑘
∑︀
𝑘′=1

)︀ · (2𝑁 −𝑘′ − 1) linear inequalities:

(︀𝑁
𝑘′

SP(𝑘) =

⋂︁

{︀(𝐽, ℎ) | 𝐸(𝑥(𝑅)|𝐽, ℎ) > 𝐸(𝑥 | 𝐽, ℎ)}︀ ,

(5.8)

∀𝑅, |𝑅| ≤ 𝑘;

∀𝑥 ∈ 𝑋 (𝑅) ∖ 𝑥(𝑅)

were some of these linear inequalities on the rand hand side may be redundant.

Remark. In the case of 𝑘 = 1 (which, obviously, applies only if all the initial

infections are at a single nodes, i.e. ∀ℐ ∈ Υ, |ℐ| = 1), there are at most, 𝑁 ·(2𝑁 −1 −1)

linear inequalities.

We illustrate the geometry of the Ising model over the triangle graph (three

nodes connected in a loop, 𝐾3) in Fig. 5-2 and Fig. 5-3. For both illustrations, we
fix the ℎ value to −1 at all the nodes, and we are thus exploring the remaining three
degrees of freedom, 𝐽12, 𝐽13, 𝐽23 (since 𝐽 is symmetric), which corresponds to exploring
interactions within the class of attractive Ising models, ∀𝑎, 𝑏 = 1, 2, 3 : 𝐽𝑎𝑏 ∈ R+.

First, we consider the case when the only node 𝑎 = 1 is infected. In this simple

setting there are four possible MAP states,

(𝑥1, 𝑥2, 𝑥3) ∈ {(+1, −1, −1), (+1, −1, +1), (+1, +1, −1), (+1, +1, +1)}

shown in Fig. (5-2) as green, blue, yellow and red, respectively. Finally, in the figure

53

Chapter 5.

Ising Model Control

5.4. Geometry of the MAP States

Figure 5-2: Geometry of the attractive Ising model illustrated on the example of a
triangle graph (𝐾3) when a single node is infected. See explanations in the text.

Fig. (5-3) we plot the Safe Polytope SP(1). We observe that the two "polarized"

MAP states, (+1, −1, −1) and (+1, +1, +1), are seen most often among the samples,

while domain occupied by the other two "mixed" MAP states, (+1, −1, +1) and

(+1, +1, −1) is much smaller, with the two modes positioned on the interface between

the two polarized states.

As will be shown below in the next Section, the polarization phenomena with

only two "polarized" MAP states, which we coin in the following the two polarized

modes, which we see on this simple triangle example, is generic for the attractive

Ising model.

54

Chapter 5.

Ising Model Control

5.5. Two Polarized Modes

Figure 5-3: The Safe Polytope illustrated on the example of a triangle graph (𝐾3)
with field vector ℎ = [−1, −1, −1]. See explanations in the text.

5.5 Two Polarized Modes

Definition. Consider a particular subset of the initially infected nodes, ℐ (where
thus, ∀𝑎 ∈ ℐ : 𝑥𝑎 = +1). We call the MAP state of the model polarized when one
of the following is true: (i) only initially infected nodes show +1 within the MAP
solution, ∀𝑎 ∈ ℐ : 𝑥𝑎 = +1, ∀𝑏 ∈ 𝒱 ∖ ℐ : 𝑥𝑏 = −1 or (ii) all nodes within the MAP
state show +1, ∀𝑎 ∈ 𝒱 : 𝑥𝑎 = +1. We call a MAP state mixed otherwise.

Experimenting with many dense graphs, which are typical in the pandemic

modeling of modern cities with extended infrastructures and multiple destinations

visited by many inhabitants, we observe that the two polarized MAP states dominate

generically, while the mixed states are extremely rare.

55

Chapter 5.

Ising Model Control

5.5. Two Polarized Modes

Figure 5-4: Proportion of the mixed states in all samples for an ensemble of the
(attractive) Ising Model of Pandemic over graphs with 𝑁 nodes, shown as a function
of the varying number of edges, 𝑀 . Each shown point is the result of the averaging
over 500 random instances of the (𝐽, ℎ) over the same graph. (See text for additional
details.)

Fig. 5-4 illustrates results of one our ensemble of random IMPs’ experiments. We,

first, fix 𝑁 to 20, pick 𝑀 such that 𝑀 ≤ 𝑁 (𝑁 − 1)/2 = 190 and then generate at

random 𝑀 edges connecting the 20 nodes. Then, for each of the random graphs

(characterized by its own 𝑀 ) we generate 500 random samples of (𝐽, ℎ), representing

attractive Ising models. Finally, we find the MAP state for each IMP instance, count

the number of mixed states and show the dependence of the fractions of the mixed

states (in the sample set) in the Fig. (5-4). A fast decrease of the proportion of the

mixed states is observed with an increase in 𝑀 .

Extension of these experiments (see Fig. (5-5)) suggests that when we consider

an ensemble of IMPs over graphs with 𝑁 nodes and the average degree 𝛼 = 𝑂(1)

which is sufficiently large (so that the graph is sufficiently dense) and increase 𝑁 ,

we observe that the Mixed State Probability (MSP), or equivalently proportion

of the mixed-to-polarized states, decreases dramatically. Moreover, based on the

experiments, we conjecture that the MSP decays to zero at 𝛼 > 𝛼𝑐, but it saturates

56

Chapter 5.

Ising Model Control

5.5. Two Polarized Modes

Figure 5-5: Proportion of the mixed-to-polarized states for an ensemble of the
(attractive) Ising Model of Pandemic over 𝑑-regular graphs with 𝑁 nodes, shown as
a function of 𝑑. Each point is the result of averaging over 100 random instances of
the (𝐽, ℎ) over different random graphs with the same node degree. (See text for
additional details.)

at 𝛼 < 𝛼𝑐, where 𝛼𝑐 is the threshold depending on the ensemble details. This
threshold behavior is akin to the phase transition that occurred in many models

of the spin glass theory Mezard et al. [1986] and many models of the Computer

Science and Theoretical Engineering defined over random graphs and considered

in the thermodynamic limit, i.e. at 𝑁 → ∞. See e.g. Richardson and Urbanke

[2008] (application in the Information Theory, and specifically in the theory of the

Low Density Parity Check Codes) Mezard and Montanari [2009] (applications in

the Computer Science, and specifically for random SAT and related models) and

references therein. We postpone further discussions of the conjecture for a future

publication (see also brief discussion in Section 5.8).

We will continue discussion of the two-mode solution in the next Section.

57

Chapter 5.

Ising Model Control

5.6. Projecting to the Safe Polytope

5.6 Projecting to the Safe Polytope

In this Section we aim to summarize all the findings so far to resolve the Prevention

Challenge formulated in Section 5.3, specifically in Eq. (5.7) stating the problem as

finding a minimal projection to the Safety Domain/Polytope from its exterior. The

task is well defined, but in general, and as shown in Section 5.4, it is too complex –

as the description of the Safety Polytope (number of linear constraints, required to

define it) is exponential in the system size (number of nodes in the graph). However,

the two-mode approximation, introduced in Section 5.5, suggests a path forward:

use the two-mode approximation and therefore remove all the linear constraints but

one, separating the two polarized states.

Let us denote the two-mode approximation of the Safe Polytope by ̂︁𝑆𝑃 (Υ), where
thus 𝑘 in the original Safe Polytope, 𝑆𝑃 (𝑘), is replaced by the set Υ of all the initial

infection patters. Then we write,

̂︁𝑆𝑃 (Υ) =

⋂︁

ℐ∈ϒ

{︀(𝐽, ℎ) | 𝐸(+12𝑁 | 𝐽, ℎ) ≥ 𝐸(𝑥(ℐ) | 𝐽, ℎ)}︀,

(5.9)

𝑎 = +1 and ∀𝑏 ∈ 𝒱 ∖ ℐ : 𝑥(ℐ)
where, ∀𝑎 ∈ ℐ : 𝑥(ℐ)
a polytope stated in terms of the |Υ| constraints.
for all the initial infections, ℐ, of size not large than 𝑘, then |Υ| = ∑︀𝑘
number of constraints grows exponentially in the maximal size of the initial infections,

𝑏 = −1. Eq. (5.9) represents
In particular, if Υ accounts
)︀: the

(︀𝑁
𝑘′

𝑘′=1

however the number of the constraints remains tractable for any 𝑘 = 𝑂(1). Replacing
conditions in Eq. (5.7) by ̂︁𝑆𝑃 (Υ), defined in Eq. (5.9), one arrives at the following
tractable (in the case of 𝑘 = 𝑂(1)) convex optimization expression answering the

Prevention Challenge approximately (within the two-mode approximation):

( ̂︀𝐽 (corr), ̂︀ℎ(corr)) = arg min

(𝐽,ℎ)

𝐶 (︀(𝐽, ℎ); (𝐽 (0), ℎ(0)))︀

Eq. (5.9) .

(5.10)

This formula is the final result of this manuscript analytic evaluation. In the next

Section we use Eq. (5.10), with 𝐶(·; ·) substituted by the 𝑙1-norm, to present the result
of our experiments in a quasi-realistic setting describing a (hypothetical) pandemic

attack and optimal defense, i.e., prevention scheme.

58

Chapter 5.

Ising Model Control

5.7. Experiments

5.7 Experiments

5.7.1 Seattle data

We illustrate our methodology on a case study of the city of Seattle. Seattle has

131 Census Tracts. (Each Census Tract includes 1 to 10 Census Block Groups with

600 to 3000 residents.) Each Census Tract represents 1200 to 8000 population, and

its boundaries are designed to represent natural or urban landmarks and also to

be persistent over a long period United States Census Bureau [2019]. To reduce

complexity, we merge census tracts into 20 regions. See Fig. 5-6. To prepare this

splitting of Seattle into 20 regions/nodes, we utilize geo-spatial information from

the TIGER/Line Shapefiles project provided by U.S. Census Bureau United States

Census Bureau [2021]. The travel data of Seattle was extracted from the Safegraph

dataset SafeGraph [2021a], which provides anonymized mobile tracking data. Each

data point in the Safegraph database describes the number of visits from a Census

Block to a specific point of interest represented by latitude and longitude. Mobility

data associated with travelers crossing the boundaries of Seattle was ignored. We

then follow the methodology developed in Chertkov et al. [2021] to combine the

aggregated travel data with the epidemiological data, representing current state of

infection in the area. This results in the estimation of the pair-wise interactions, 𝐽,

parameterizing the Ising Model of Pandemic. We also come up with an exemplary

(uniform over the system) local biases, ℎ, completing the definition of the model. (We

remind that the prime focus of the manuscript is on developing methodology which

is AI sound and sufficiently general. Therefore, the data used in the manuscript are

roughly representative of the situation of interest, however not fully practical.) We

consider a situation with different levels of infection and chose (𝐽 (0), ℎ(0)) stressed

enough, that is resulting in the prediction (answer to our Prediction Challenge),

which lands the system in the dangerous domain – outside of the Safety Polytope.

59

Chapter 5.

Ising Model Control

5.7. Experiments

Figure 5-6: Seattle case study areas and census tracts Office of Planning & Community
Development, Seattle [2010].

5.7.2 Convex projection

In all of our experiments, we have used the general-purpose Gurobi optimization

solver Gurobi Optimization, LLC [2021] to compute the MAP states and thus to

validate the two-mode assumption. (We have also experimented with CVXPY [2021],

but found it performing slower than Gurobi, at least over the relatively small samples

considered in this proof of principles study. In the future, we plan to use existing, or

developing new, LP solvers designed specifically for finding the MAP state of the

attractive Ising model.) To illustrate our Prevention strategy, we took the Seattle

data described above, and fed it as an input into the optimization (5.10), describing

projection to the Safety Polytope, where 𝐶(·; ·) is substituted by the 𝑙1 norm. CVXPY

60

Chapter 5.

Ising Model Control

5.8. Conclusions and Path Forward

k LP Constraints Runtime Cost
41.69
1
43.62
2
44.30
3
44.56
4

1.65s
3.04s
10.90s
100.08s

801
991
2131
6976

Table 5.1: Summary of our prevention experiments on the Seattle data. 𝑘, in the
first column, is the maximal number of nodes in the initially infected patterns (all
accounted for to construct the 𝑘-Safe Polytope). The second column shows number
of linear constraints characterizing the 𝑘-Safe Polytope. Respective Run Time and
Cost are shown in the 3rd and 4th column, where Cost shows the difference in 𝑙1
norm between the (𝐽 (0), ℎ(0)), characterizing stressed but unmitigated regime, and
the optimal prevention regime, resulting in ( ̂︀𝐽 (corr), ̂︀ℎ(corr)) computed according to
Eq. (5.10).

solver was used for this convex optimization task. Our code (python within jupyter

notebook) is available at https://github.com/mkrechetov/IsingMitigation.

Table 5.1 shows results of our Prevention experiments on the Seattle data. We

analyze 𝑙1 projection to ̂︁𝑆𝑃 (Υ) where Υ consists of all the initial infection patterns
consisting of up to 𝑘 nodes. In all of our experiments, the values of the field vector

ℎ (uniform across the system) was fixed to −1. We observe that the number of

constraints grows exponentially with 𝑘; however, the cost of intervention remains

roughly the same. We intend to analyze the results of this and other (more realistic)

experiments in future publications aimed at epidemiology experts and public health

officials.

5.8 Conclusions and Path Forward

In this manuscript, written specifically for the AI community, we follow our prior work

Chertkov et al. [2021], aimed at a broader interdisciplinary community, and explain

respective inference (prediction) and control (prevention) questions/challenges. We

use the language of GMs, which is one powerful tool in the modern arsenal of

AI, and state the Prediction Challenge as a MAP optimization over an attractive

Ising model, which can be expressed generically as a solution of a tractable Linear

Programming (LP). We then turn to the analysis of the prevention problem, which

is set if the aforementioned prediction solution suggests that the probability of

61

Chapter 5.

Ising Model Control

5.8. Conclusions and Path Forward

significant infection is above a pre-defined (by the public health experts) tolerance

threshold. We show that in its simplest formulation, the prevention problem is

equivalent to finding minimal 𝑙1 projection to the safety polytope, where the latter is
defined by solving the aforementioned prediction problem. In general, the polytope

does not allow a description non-exponential in the size of the system. However, we

suggested an approximation that allows to approximate the safety polytope efficiently

- that is, linearly in the number of the initial infection patterns. The approximation

is justified (empirically, with supporting theoretical arguments, however not yet

backed by a mathematically rigorous theory) in the case when the interaction graph

of the system (e.g., related to the system/city transportation and human-to-human

interaction network) is sufficiently dense. We conclude by providing a quasi-realistic

experimental demonstration on the GM of Seattle.

We conclude the manuscript with an incomplete list of AI challenges, presented in

the order of importance (subjective), which need to be resolved to make the powerful

GM approach to pandemic prediction and prevention practical:

• Build a hierarchy of Probabilistic Graphical Models which allow more accurate

(than Ising model) representation of the infection patterns over geographical

and community graphs. The models may be both of the static (like Ising) or

dynamic (like Independent Cascade Model) types. Extend the notion of the

Safety Region (polytope) to the new GM of pandemics.

• Consider the case when the resolution of the Prediction Challenge problem

returns a positive answer - most likely future state of the system is safe, and then

develop the methodology which allows estimating the probability of crossing

the safety boundary. In other words, we envision formulating and solving in the

context of the GM a problem which is akin to the one addressed in Owen et al.

[2019], Lukashevich et al. [2021], Lukashevich and Maximov [2021]: estimate

the probability of finding the system outside of the Safety Polytope.

• Construct other (than two-mode) approximations to the Safety Polytope.

Approximations built on sampling of the boundaries of the safety polytope and

learning (possibly reinforcement learning) are needed.

62

Chapter 5.

Ising Model Control

5.8. Conclusions and Path Forward

• Develop the asymptotic (thermodynamic limit) theory which allows validating

(and/or correcting systematically) the efficient (two-mode and other) approxi-

mations of the Safety Polytope.

63

Bibliography

Massih-Reza Amini, Vasilii Feofanov, Loic Pauletto, Emilie Devijver, and Yury

Maximov. Self-training: A survey. arXiv preprint arXiv:2202.12040, 2022.

R.M. Anderson and R.M. May. Infectious Disease of Humans: Dynamics and Control.

Oxford University Press, Oxford, 1991.

Anton Anikin, Alexander Gasnikov, Alexander Gornov, Dmitry Kamzolov, Yury
Maximov, and Yurii Nesterov. Efficient numerical methods to solve sparse linear
equations with application to pagerank. Optimization Methods and Software, pages
1–29, 2020.

Sanjeev Arora and Boaz Barak. Computational complexity: a modern approach.

Cambridge University Press, 2009.

F. Barahona. On the computational complexity of ising spin glass models.
Journal of Physics A: Mathematical and General, 15(10):3241–3253, oct 1982.
doi:10.1088/0305-4470/15/10/028. URL https://doi.org/10.1088/0305-4470/
15/10/028.

F. Barahona. An application of combinatorial optimization to statistical physics and

circuit layout design. Operations Research, pages 493–513, 1988.

A. Barvinok. Problems of distance geometry and convex properties of quadratic
maps. Discrete & Computational Geometry, 13(2):189–202, 1995. ISSN 1432-0444.
doi:10.1007/BF02574037.

J. Beasley. Heuristic algorithms for the unconstrained binary quadratic programming
problem. Technical Report December, Management School, Imperial College,
London, UK, 1998.

N. Boumal, V. Voroninski, and A. Bandeira. The non-convex Burer-Monteiro ap-
proach works on smooth semidefinite programs. In Advances in Neural Information
Processing Systems, pages 2757–2765, 2016.

Stephen Boyd, Stephen P Boyd, and Lieven Vandenberghe. Convex optimization.

Cambridge university press, 2004.

S. Burer and R. Monteiro. A nonlinear programming algorithm for solving semidefinite
programs via low-rank factorization. Mathematical Programming, 95:329–357, 2003.

64

Bibliography

Bibliography

S. Burer and R. Monteiro. Local minima and convergence in low-rank semidefinite

programming. Mathematical Programming, 103(3):427–444, 2005.

S. Chang, E. Pierson, P. Koh, J. Gerardin, B. Redbird, D. Grusky, and J. Leskovec.
Mobility network models of COVID-19 explain inequities and inform reopening.
Nature, November 2020. ISSN 1476-4687. doi:10.1038/s41586-020-2923-3. URL
https://doi.org/10.1038/s41586-020-2923-3.

D. Chao, M. Halloran, V. Obenchain, and Ira M. Longini J. Flute, a publicly
available stochastic influenza epidemic simulation model. PLoS Comput Biol, 6(1):
e1000656, 2010.

Y.C. Chen, P.E. Lu, C.S. Chang, and T.H. Liu. A time-dependent sir model
for covid-19 with undetectable infected persons.
IEEE Transactions on Net-
ISSN 2334-329X.
work Science and Engineering, 7(4):3279–3294, Oct 2020.
doi:10.1109/tnse.2020.3024723. URL http://dx.doi.org/10.1109/TNSE.2020.
3024723.

M. Chertkov, R. Abrams, A. M. Esmaieeli Sikaroudi, M. Krechetov, CNP Slagle,
A. Efrat, R. Fulek, and E. Oren. Graphical models of pandemic. https: // www.
medrxiv. org/ content/ 10. 1101/ 2021. 02. 24. 21252390v1. full , 2021.

Michael Chertkov, Vladimir Chernyak, and Yury Maximov. Gauges, loops, and
polynomials for partition functions of graphical models. Journal of Statistical
Mechanics: Theory and Experiment, 2020(12):124006, 2020.

T. Cormen. Introduction to algorithms. MIT press, 2009.

CVXPY. Convex Optimization for Everyone. https: // www. cvxpy. org/ , 2021.

Marek Cygan, Fedor V Fomin, Łukasz Kowalik, Daniel Lokshtanov, Dániel Marx,
Marcin Pilipczuk, Michał Pilipczuk, and Saket Saurabh. Parameterized algorithms,
volume 5. Springer, 2015.

M. Deza and M. Laurent. Geometry of cuts and metrics. Springer, 2009.

A. Downey. Think Complexity: Complexity Science and Computational Modeling.

O’Reilly Media, Inc., 2nd edition, 2018. ISBN 1549761749.

M. Erdogdu, Y. Deshpande, and A. Montanari.

Inference in graphical models
via semidefinite programming hierarchies. In Advances in Neural Information
Processing Systems, pages 416–424, 2017.

M. Erdogdu, A. Ozdaglar, P. Parrilo, and N. Vanli. Convergence rate of block-
coordinate maximization Burer-Monteiro method for solving large sdps. Mathe-
matical Programming, pages 1–39, 2021.

S. Eubank, H. Guclu, V.S. Anil Kumar, M. Marathe, A. Srinivasan, Z. Toroczkai, and
N. Wang. Modelling disease outbreaks in realistic urban social networks. Nature,
429(6988):180–184, May 2004. ISSN 1476-4687. doi:10.1038/nature02541. URL
https://doi.org/10.1038/nature02541.

65

Bibliography

Bibliography

S. Eubank, I. Eckstrand, B. Lewis, S. Venkatramanan, M. Marathe, and C.L. Barrett.
Commentary on ferguson, et al., “impact of non-pharmaceutical interventions
(NPIs) to reduce COVID-19 mortality and healthcare demand”. Bulletin of
Mathematical Biology, 82(4):52, 2020. ISSN 1522-9602. doi:10.1007/s11538-020-
00726-x. URL https://doi.org/10.1007/s11538-020-00726-x.

H. Fawzi, J. Saunderson, and P. Parrilo. Semidefinite approximations of the matrix
logarithm. Foundations of Computational Mathematics, 19(2):259–296, Apr 2019.
ISSN 1615-3383. doi:10.1007/s10208-018-9385-0. URL https://doi.org/10.
1007/s10208-018-9385-0.

M. Fazel, H. Hindi, and S. Boyd. Log-det heuristic for matrix rank minimization
with applications to Hankel and Euclidean distance matrices. In Proceedings of
the 2003 American Control Conference, 2003., volume 3, pages 2156–2162, 2003.
ISBN 0-7803-7896-2. doi:10.1109/ACC.2003.1243393.

N. Ferguson, D. Cummings, S. Cauchemez, C. Fraser, S. Riley, A. Meeyai, S. Iam-
sirithaworn, and D. Burke. Strategies for containing an emerging influenza pan-
demic in Southeast Asia. Nature, 437(7056):209–214, September 2005. ISSN 1476-
4687. doi:10.1038/nature04017. URL https://doi.org/10.1038/nature04017.

N. Ferguson, D. Cummings, C. Fraser, J.C. Cajka, P. Cooley, and D. Burke. Strategies
for mitigating an influenza pandemic. Nature, 442(7101):448–452, July 2006.
ISSN 1476-4687. doi:10.1038/nature04795. URL https://doi.org/10.1038/
nature04795.

N. Ferguson, D. Laydon, G. Nedjati-Gilani, N. Imai, K. Ainslie, M. Baguelin, S. Bha-
tia, A. Boonyasiri, Z. Cucunubá, G. Cuomo-Dannenburg, A. Dighe, I. Dorigatti,
H. Fu, K. Gaythorpe, W. Green, A. Hamlet, W. Hinsley, L. Okell, S. van Elsland,
and A. Ghani. Report 9: Impact of non-pharmaceutical interventions (npis) to
reduce covid-19 mortality and healthcare demand. https: // www. imperial.
ac. uk/ media/ imperial-college/ medicine/ sph/ ide/ gida-fellowships/
Imperial-College-COVID19-NPI-modelling-16-03-2020. pdf , 2020.

R. Frostig, S. Wang, P. Liang, and C. Manning. Simple MAP inference via low-
rank relaxations. In Advances in Neural Information Processing Systems, pages
3077–3085, 2014.

M. Garey and D. Johnson. Computers and intractability, volume 29. wh freeman

New York, 2002.

Timothy C. Germann, Kai Kadau, Ira M. Longini, and Catherine A. Macken. Mitiga-
tion strategies for pandemic influenza in the united states. Proceedings of the Na-
tional Academy of Sciences, 103(15):5935–5940, 2006. doi:10.1073/pnas.0601266103.
URL https://www.pnas.org/content/103/15/5935.

B. Ghaddar, J. Marecek, and M. Mevissen. Optimal power flow as a polynomial
optimization problem. IEEE Transactions on Power Systems, 31(1):539–546, Jan
2016. ISSN 0885-8950. doi:10.1109/TPWRS.2015.2390037.

66

Bibliography

Bibliography

Philip E Gill, Walter Murray, and Margaret H Wright. Practical optimization. SIAM,

2019.

M. Goemans and D. Williamson. Improved approximation algorithms for maximum
cut and satisfiability problems using semidefinite programming. Journal of the
ACM, 42(6):1115–1145, 1995.

M. Gomez-Rodriguez, J. Leskovec, and A. Krause. Inferring networks of diffusion
and influence. ACM Trans. Knowl. Discov. Data, 5(4), February 2012. ISSN 1556-
4681. doi:10.1145/2086737.2086741. URL https://doi.org/10.1145/2086737.
2086741.

M. Grant and S. Boyd. Graph implementations for nonsmooth convex programs. In
Recent Advances in Learning and Control, Lecture Notes in Control and Information
Sciences, pages 95–110. Springer-Verlag Limited, 2008.

M. Grant and S. Boyd. CVX: Matlab software for disciplined convex programming,

version 2.1. http://cvxr.com/cvx, March 2014.

Gurobi Optimization, LLC. Gurobi Optimizer Reference Manual. https: // www.

gurobi. com , 2021.

M. Halloran, N. Ferguson, S. Eubank, I. Longini, D. Cummings, B. Lewis, S. Xu,
C. Fraser, A. Vullikanti, T. Germann, D. Wagener, R. Beckman, K. Kadau, C. Bar-
rett, C. Macken, D. Burke, and P. Cooley. Modeling targeted layered containment of
an influenza pandemic in the united states. Proceedings of the National Academy of
Sciences, 105(12):4639–4644, 2008. ISSN 0027-8424. doi:10.1073/pnas.0706849105.
URL https://www.pnas.org/content/105/12/4639.

C. Helmberg and F. Rendl. A Spectral Bundle Method for Semidefinite Program-
ming. SIAM Journal on Optimization, 10(August):673–696, 1997. ISSN 10526234.
doi:10.1137/S1052623497328987.

C. Helmberg, S. Poljak, and F. Rendl. Combining semidefinite and polyhedral
relaxations for integer programs. Integer Programming and Combinatorial Opti-
mization, pages 124–134, 1995. ISSN 16113349. URL http://www.springerlink.
com/index/F377K847M974R422.pdf.

H.W. Hethcote. The mathematics of infectious diseases. SIAM Rev., 42(4):599–653,
December 2000. ISSN 0036-1445. doi:10.1137/S0036144500371907. URL https:
//doi.org/10.1137/S0036144500371907.

M. Holmes, A. Gray, and C. Isbell. Fast SVD for large-scale matrices. Workshop on

Efficient Machine Learning at NIPS, 58:249–252, 2007.

Y. Hu, D. Zhang, J. Ye, X. Li, and X. He. Fast and accurate matrix completion via
truncated nuclear norm regularization. IEEE Transactions on Pattern Analysis
and Machine Intelligence, pages 2117–2130, 2013.

R. Karp. Reducibility among Combinatorial Problems, pages 85–103. Springer US,
Boston, MA, 1972. ISBN 978-1-4684-2001-2. doi:10.1007/978-1-4684-2001-2_9.

67

Bibliography

Bibliography

Richard M Karp. On the computational complexity of combinatorial problems.

Networks, 5(1):45–68, 1975.

E. Kaxiras and G. Neofotistos. Multiple epidemic wave model of the covid-19
pandemic: Modeling study. Journal of Medical Internet Research, 22(7):e20912,
2020.

D. Kempe, J. Kleinberg, and E. Tardos. Maximizing the spread of influence through
a social network. In Proceedings of the Ninth ACM SIGKDD International Con-
ference on Knowledge Discovery and Data Mining, KDD ’03, page 137–146, New
York, NY, USA, 2003. Association for Computing Machinery. ISBN 1581137370.
doi:10.1145/956750.956769. URL https://doi.org/10.1145/956750.956769.

W. Kermack, A.G. McKendrick, and G. Walker. A contribution to the mathemat-
ical theory of epidemics. Proceedings of the Royal Society of London. Series A,
Containing Papers of a Mathematical and Physical Character, 115(772):700–721,
1927. doi:10.1098/rspa.1927.0118.

C. Kerr, R. Stuart, D. Mistry, R.G. Abeysuriya, K. Rosenfeld, G. Hart, R. Nunez,
J. Cohen, P. Selvaraj, B. Hagedorn, L. George, M. Jastrzebski, A. Izzo, G. Fowler,
A. Palmer, D. Delport, N. Scott, S. Kelly, C. Bennette, B. Wagner, S. Chang,
A. Oron, E. Wenger, J. Panovska-Griffiths, M. Famulare, and D. Klein. Covasim:
An agent-based model of covid-19 dynamics and interventions. PLOS Compu-
tational Biology, 17(7):1–32, 07 2021. doi:10.1371/journal.pcbi.1009149. URL
https://doi.org/10.1371/journal.pcbi.1009149.

R. Keshavan, A. Montanari, and S. Oh. Matrix completion from a few entries. IEEE

Transactions on Information Theory, 56(6):2980–2998, 2010.

E. Khalil, B. Dilkina, and L. Song. Cuttingedge: Influence minimization in networks.
In Workshop on Frontiers of Network Analysis: Methods, Models, and Applications
at NIPS, 2013. URL files/papers/CuttingEdge.pdf.

S. Khot. On the power of unique 2-prover 1-round games.

In Proceedings of
the Thiry-fourth Annual ACM Symposium on Theory of Computing, STOC
’02, pages 767–775, New York, NY, USA, 2002. ACM.
ISBN 1-58113-495-9.
doi:10.1145/509907.510017.

J. Kleinhans, G. Sigl, F. Johannes, and K. Antreich. Gordian: Vlsi placement by
quadratic programming and slicing optimization. IEEE Transactions on Computer-
Aided Design of Integrated Circuits and Systems, 10(3):356–365, 1991.

G. Kochenberger. The unconstrained binary quadratic programming problem: a

survey. Journal of Combinatorial Optimization, pages 58–81, 2014.

M. Krechetov, Y. Maximov, J. Mareček, and M. Takáč. Entropy-penalized semidefi-
nite programming. IJCAI International Joint Conference on Artificial Intelligence,
pages 1123–1129, 2019.

68

Bibliography

Bibliography

M. Krechetov, A. M. E. Sikaroudi, A. Efrat, V. Polishchuk, and M. Chertkov.
Prediction and prevention of pandemics via graphical model inference and convex
programming. Scientific Reports, 12(1), pages 1–11, 2021.

N. Krislock, J. Malick, and F. Roupin. Improved semidefinite bounding procedure
for solving max-cut problems to optimality. Mathematical Programming, 143(1-2):
61–86, 2014.

LANL. Covid-19 confirmed and forecasted case data.

bsvgateway. org/ , 2020.

https: // covid-19.

J.B. Lasserre. An introduction to polynomial and semi-algebraic optimization, vol-

ume 52. Cambridge University Press, 2015.

A. Lemon, A. So, and Y. Ye. Low-rank semidefinite programming: Theory and

applications. Foundations and Trends® in Optimization, 2016.

C. Li. Approximation of Matrix Rank Function and Its Application to Matrix Rank
Minimization. Journal of Optimization Theory and Applications, pages 569–594,
2014.

F. Liers, M. Jünger, G. Reinelt, and G. Rinaldi. Computing exact ground states of
hard ising spin glass problems by branch-and-cut. New optimization algorithms in
physics, pages 47–69, 2004.

Valerii Likhosherstov, Yury Maximov, and Michael Chertkov. A new family of

tractable ising models. arXiv preprint arXiv:1906.06431, 2019a.

Valerii Likhosherstov, Yury Maximov, and Misha Chertkov. Inference and sampling
of 𝑘_33-free ising models. In International Conference on Machine Learning, pages
3963–3972. PMLR, 2019b.

Valerii Likhosherstov, Yury Maximov, and Michael Chertkov. Tractable minor-free
generalization of planar zero-field ising models. Journal of Statistical Mechanics:
Theory and Experiment, 2020(12):124007, 2020.

I. Longini, A. Nizam, S. Xu, K. Ungchusak, W. Hanshaoworakul, D. Cummings, and
M. Halloran. Containing pandemic influenza at the source. Science, 309(5737):
1083–1087, August 2005. ISSN 0036-8075. doi:10.1126/science.1115717.

G. Lovasi and et.al.

eling, 2020.
population-health-methods/agent-based-modeling.

Population health methods: Agent based mod-
URL https://www.publichealth.columbia.edu/research/

I. Luchnikov, M. Krechetov, and S. Filippov. Riemannian geometry and auto-
matic differentiation for optimization problems of quantum physics and quantum
technologies. New Journal of Physics, 2021.

Aleksander Lukashevich and Yury Maximov. Power grid reliability estimation via
adaptive importance sampling. IEEE Control Systems Letters, 6:1010–1015, 2021.

69

Bibliography

Bibliography

Aleksander Lukashevich, Vyacheslav Gorchakov, Petr Vorobev, Deepjyoti Deka, and
Yury Maximov. Importance sampling approach to chance-constrained dc optimal
power flow. arXiv preprint arXiv:2111.11729, 2021.

R. Madani, G. Fazelnia, S. Sojoudi, and J. Lavaei. Low-rank solutions of matrix
inequalities with applications to polynomial optimization and matrix completion
problems. In 53rd IEEE Conference on Decision and Control, pages 4328–4335,
Dec 2014.

J. Mareček and Takáč M. A low-rank coordinate-descent algorithm for semidefi-
nite programming relaxations of optimal power flow. Optimization Methods and
Software, 32(4):849–871, 2017. doi:10.1080/10556788.2017.1288729.

Yury Maximov, Massih-Reza Amini, and Zaid Harchaoui. Rademacher complexity
bounds for a penalized multi-class semi-supervised algorithm. Journal of Artificial
Intelligence Research, 61:761–786, 2018.

M. Maziarz and M. Zach. Agent-based modelling for sars-cov-2 epidemic prediction
and intervention assessment: A methodological appraisal. Journal of Evaluation
in Clinical Practice, 26(5):1352–1360, 2020. doi:10.1111/jep.13459. URL https:
//onlinelibrary.wiley.com/doi/abs/10.1111/jep.13459.

M. Mezard and A. Montanari. Information, physics, and computation. Oxford

University Press., 2009.

M. Mezard, G. Parisi, and M. Virasoro. Spin Glass Theory and Beyond. WORLD
SCIENTIFIC, 1986. doi:10.1142/0271. URL https://www.worldscientific.
com/doi/abs/10.1142/0271.

Artem Mikhalev, Alexander Emchinov, Samuel Chevalier, Yury Maximov, and Petr
Vorobev. A bayesian framework for power system components identification. In
2020 IEEE Power & Energy Society General Meeting (PESGM), pages 1–5. IEEE,
2020.

K. Mohan and M. Fazel. Iterative reweighted algorithms for matrix rank minimization.

Journal of Machine Learning Research, 13(Nov):3441–3473, 2012.

Y. Nesterov. Semidefinite relaxation and nonconvex quadratic optimization. Optimiza-
tion Methods and Software, 9(1-3):141–160, 1998. doi:10.1080/10556789808805690.

P. Netrapalli and S. Sanghavi. Learning the graph of epidemic cascades. In Proceedings
of the 12th ACM SIGMETRICS/PERFORMANCE Joint International Conference
on Measurement and Modeling of Computer Systems, SIGMETRICS ’12, page
211–222, New York, NY, USA, 2012. Association for Computing Machinery. ISBN
9781450310970. doi:10.1145/2254756.2254783. URL https://doi.org/10.1145/
2254756.2254783.

F. Nie, H. Huang, and C. Ding. Low-rank matrix recovery via efficient schatten
p-norm minimization. In Proceedings of the Twenty-Sixth AAAI Conference on
Artificial Intelligence, AAAI’12, pages 655–661. AAAI Press, 2012.

70

Bibliography

Bibliography

Office of Planning & Community Development, Seattle. Census tract map of seat-
tle, https://www.seattle.gov/Documents/Departments/OPCD/Demographics/
GeographicFilesandMaps/2010CensusTractMap.pdf, 2010.

A.B. Owen, Y. Maximov, and M. Chertkov. Importance sampling the union of
rare events with an application to power systems analysis. Electronic Journal of
Statistics, 13(1):231 – 254, 2019. doi:10.1214/18-EJS1527. URL https://doi.
org/10.1214/18-EJS1527.

Gábor P. On the rank of extreme matrices in semidefinite programs and the
multiplicity of optimal eigenvalues. Mathematics of Operations Research, 23(2):
339–358, 1998. ISSN 0364-765X.

R. Parker and R. Rardin. Discrete optimization. Elsevier, 2014.

P. Parrilo. Semidefinite programming relaxations for semialgebraic problems. Mathe-

matical programming, page 293–320, 2003.

R. Pogodin, M. Krechetov, and Y. Maximov. Efficient rank minimization to tighten
semidefinite programming for unconstrained binary quadratic optimization. 55th
Annual Allerton Conference on Communication, Control, and Computing (Aller-
ton), pages 1153–1159, 2017.

B. Recht, M. Fazel, and P. Parrilo. Guaranteed minimum-rank solutions of linear
matrix equations via nuclear norm minimization. SIAM Review, 52(3):471–501,
2010.

J. Ren, X. Jiang, J. Yuan, and G. Wang. Optimizing lbp structure for visual
recognition using binary quadratic programming. IEEE Signal Processing Letters,
21(11):1346–1350, 2014.

F. Rendl, G. Rinaldi, and A. Wiegele. Solving max-cut to optimality by intersecting
semidefinite and polyhedral relaxations. Mathematical Programming, pages 307–
335, 2010.

T. Richardson and R. Urbanke. Modern Coding Theory. Cambridge University Press,

USA, 2008. ISBN 0521852293.

N. Rosenfeld, M. Nitzan, and A. Globerson. Discriminative learning of infection mod-
els. In Proceedings of the Ninth ACM International Conference on Web Search and
Data Mining, WSDM ’16, page 563–572, New York, NY, USA, 2016. Association
for Computing Machinery. ISBN 9781450337168. doi:10.1145/2835776.2835802.
URL https://doi.org/10.1145/2835776.2835802.

R. Ross. The Prevention of Malaria. John Murray, London, 1910.

SafeGraph. SafeGraph COVID-19 Data Consortium. San Francisco, CA: SafeGraph

Inc., https://www.safegraph.com/covid-19-data-consortium, 2021a.

SafeGraph. Safegraph social distancing metrics. san francisco, ca: Safegraph inc.,
https://docs.safegraph.com/docs/social-distancing-metrics, 2021b.

71

Bibliography

Bibliography

A. Sanjeev, R. Ge, R. Kannan, and A. Moitra. Computing a nonnegative matrix
factorization–provably. In Proceedings of the forty-fourth annual ACM Symposium
on Theory of Computing, pages 145–162. ACM, 2012.

Nicol Schraudolph and Dmitry Kamenetsky. Efficient exact inference in planar ising

models. Advances in Neural Information Processing Systems, 21, 2008.

F. Shang, J. Cheng, Y. Liu, Z. Luo, and Z. Lin. Bilinear factor matrix norm
minimization for robust PCA: Algorithms and applications. IEEE Transactions
on Pattern Analysis and Machine Intelligence, 40(9):2066–2080, 2018.

Sumit Sidana, Mikhail Trofimov, Oleh Horodnytskyi, Charlotte Laclau, Yury Max-
imov, and Massih-Reza Amini. User preference and embedding learning with
implicit feedback for recommender systems. Data Mining and Knowledge Discov-
ery, 35(2):568–592, 2021.

A.M.-C. So, Y. Ye, and J. Zhang. A unified theorem on sdp rank reduction.
ISSN 0364-765X.

Mathematics of Operations Research, 33(4):910–920, 2008.
doi:10.1287/moor.1080.0326.

M. Song, T. Misiakiewicz, A. Montanari, and R. Oliveira. Solving SDPs for syn-
chronization and MaxCut problems via the Grothendieck inequality. In 2017
Conference on Learning Theory, volume 65 of Proceedings of Machine Learning
Research, pages 1476–1515, 07–10 Jul 2017.

N. Srebro, J. Rennie, and T. Jaakkola. Maximum-margin matrix factorization. In
Advances in Neural Information Processing Systems, NIPS’04, pages 1329–1336,
2004.

Nikolay Stulov, Dejan J Sobajic, Yury Maximov, Deepjyoti Deka, and Michael
Chertkov. Learning model of generator from terminal data. Electric Power
Systems Research, 189:106742, 2020.

Q. Sun, S. Xiang, and J. Ye. Robust principal component analysis via capped norms.
In Proceedings of the 19th ACM SIGKDD international conference on Knowledge
discovery and data mining, pages 311–319, 2013.

P. Torr. Solving Markov random fields using semidefinite programming. In Proceed-
ings of the Ninth International Workshop on Artificial Intelligence and Statistics,
AISTATS, pages 1–8, 2003.

United States Census Bureau. United states census bureau glossary, https:

//www.census.gov/programs-surveys/geography/about/glossary.html,
2019. URL https://www.census.gov/programs-surveys/geography/about/
glossary.html.

United States Census Bureau. United states census bureau. tiger line shapefiles

technical documentation, 2021.

M. Wainwright and M. Jordan. Graphical models, exponential families, and varia-

tional inference. Foundations and Trends® in Machine Learning, 2008.

72

Bibliography

Bibliography

P. Wang, C. Shen, A. van den Hengel, and P. Torr. Large-scale binary quadratic
optimization using semidefinite relaxation and applications. IEEE transactions on
pattern analysis and machine intelligence, 39(3):470–485, 2017.

Wikipedia. Agent Based Models, https://en.wikipedia.org/wiki/Agent-based_

model, 2020.

C. Zhou. Entropy, optimization and coding theory. PhD thesis, University of Notre

Dame, Notre Dame, Indiana, 2019.

S. Živný, T. Werner, and D. Průša. The power of lp relaxation for map inference.
Advanced Structured Prediction, The MIT Press, pages 19–42, December 2014.

73

