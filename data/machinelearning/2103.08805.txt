DDUO: General-Purpose Dynamic Analysis for
Differential Privacy

Chike Abuah1, Alex Silence1, David Darais2, and Joe Near1

1Computer Science Department, University of Vermont
2Galois, Inc.

1
2
0
2

r
a

M
6
1

]
L
P
.
s
c
[

1
v
5
0
8
8
0
.
3
0
1
2
:
v
i
X
r
a

Abstract—Differential privacy enables general statistical anal-
ysis of data with formal guarantees of privacy protection at
the individual
level. Tools that assist data analysts with uti-
lizing differential privacy have frequently taken the form of
programming languages and libraries. However, many existing
programming languages designed for compositional veriﬁcation
of differential privacy impose signiﬁcant burden on the program-
mer (in the form of complex type annotations). Supplementary
library support for privacy analysis built on top of existing
general-purpose languages has been more usable, but incapable
of pervasive end-to-end enforcement of sensitivity analysis and
privacy composition.

We introduce DDUO, a dynamic analysis for enforcing differen-
tial privacy. DDUO is usable by non-experts: its analysis is auto-
matic and it requires no additional type annotations. DDUO can
be implemented as a library for existing programming languages;
we present a reference implementation in Python which features
moderate runtime overheads on realistic workloads. We include
support for several data types, distance metrics and operations
which are commonly used in modern machine learning programs.
We also provide initial support for tracking the sensitivity of data
transformations in popular Python libraries for data analysis.

We formalize the novel core of the DDUO system and prove
it sound for sensitivity analysis via a logical relation for metric
preservation. We also illustrate DDUO’s usability and ﬂexibility
through various case studies which implement state-of-the-art
machine learning algorithms.

I. INTRODUCTION

Differential privacy has achieved prominence over the past
decade as a rigorous formal foundation upon which diverse
tools and mechanisms for performing private data analysis
can be built. The guarantee of differential privacy is that
it protects privacy at the individual level: if the result of
a differentially private query or operation on a dataset is
publicly released, any individual present in that dataset can
claim plausible deniability. This means that any participating
individual can deny the presence of their information in
the dataset based on the query result, because differentially
private queries introduce enough random noise to make the
result indistinguishable from that of the same query run on
a dataset which actually does not contain the individual’s
information. Additionally, differential privacy guarantees are
resilient against any form of linking attack in the presence of
auxiliary information about individuals.

High proﬁle tech companies such as Google have shown
a commitment to differential privacy by developing projects
such as RAPPOR [53] as well as several open-source privacy-

preserving technologies [27], [28], [47]. Facebook recently
released an unprecedented social dataset, protected by differen-
tial privacy guarantees, which contains information regarding
people who publicly shared and engaged with about 38 million
unique URLs, as an effort to help researchers study social
media’s impact on democracy and the 2020 United States pres-
idential election [38], [32], [33], [22], [23]. The US Census
Bureau has also adopted differential privacy to safeguard the
2020 census results [2].

Both static and dynamic tools have been developed to help
non-experts write differentially private programs. Many of the
static tools take the form of statically-typed programming
languages, where correct privacy analysis is built into the
soundness of the type system. However, existing language-
oriented tools for compositional veriﬁcation of differential
privacy impose signiﬁcant burden on the programmer (in the
form of additional type annotations) [40], [25], [39], [17], [52],
[49], [8], [10], [11], [9], [43], [4], [51], [46], [13], [18], [45]
(see Section IX for a longer discussion).

The best-known dynamic tool is PINQ [35], a dynamic anal-
ysis for sensitivity and privacy. It features an extensible system
which allows non-experts in differential privacy to execute
SQL-like queries against relational databases. However, PINQ
comes with several restrictions that limit its applicability. For
example, PINQ’s expressiveness is limited to a subset of the
SQL language for relational databases. Methods in PINQ are
assumed to be side-effect free, which is necessary to preserve
their privacy guarantee.

We introduce DDUO, a dynamic analysis for enforcing dif-
ferential privacy. DDUO is usable by non-experts: its analysis
is automatic and it requires no additional type annotations.
DDUO can be implemented as a library for existing program-
ming languages; we present a reference implementation in
Python. Our goal in this work is to answer the following four
questions, based on the limitations of PINQ:

• Can a PINQ-style dynamic analysis extend to base types
in the programming language, to allow its use pervasively?

• Is the analysis sound in the presence of side effects?
• Can we use this style of analysis for complex algorithms

like differentially private gradient descent?

• Can we extend the privacy analysis beyond pure ǫ-

differential privacy?

We answer all four questions in the afﬁrmative, building on

1

 
 
 
 
 
 
PINQ in the following ways:

• DDUO provides a dynamic analysis for base types in
a general purpose language (Python). DDUO supports
general language operations, such as mapping arbitrary
functions over lists, and tracks the sensitivity (stability)
and privacy throughout.

• Methods in DDUO are not required to be side-effect
free and allow programmers to mutate references inside
functions which manipulate sensitive values.

• DDUO supports for various notions of sensitivity and
arbitrary distance metrics (including L1 and L2 distance).
• DDUO is capable of leveraging advanced privacy variants

such as (ǫ, δ) and Rényi differential privacy.

Privacy analysis is reliant on sensitivity analysis, which de-
termines the scale of noise an analyst must add to values in
order to achieve any level of privacy. Dynamic analysis for
differential privacy is thus a dual challenge:

Dynamic sensitivity analysis. Program sensitivity is a (hy-
per)property quantiﬁed over two runs of a program with related
inputs (sources). A major challenge for dynamic sensitivity
analysis is the ability to bound sensitivity, ensuring that the
metric preservation property is satisﬁed, by only observing a
single run of the program. In addition, an analysis which is
performed on a speciﬁc input to the program must generalize
to future possible arbitrary inputs.

The key insight

to our solution is attaching sensitivity
environments and distance metric information to values rather
than variables. Our approach provides a sound upper bound
on global sensitivity even in the presence of side effects,
conditionals, and higher-order functions. We present a proof
using a step-indexed logical relation which shows that our
sensitivity analysis is sound.

Dynamic privacy analysis. To implement a dynamic pri-
vacy analysis, we leverage prior work on privacy ﬁlters and
odometers [41]. This work, originally designed for the adaptive
choice of privacy parameters, can also be used as part of a dy-
namic analysis for privacy analysis. We view each application
of a privacy mechanism (e.g. the Laplace mechanism) as a
global privacy effect on total privacy cost, and use privacy
ﬁlters and odometers to track total privacy cost.

We implemented these features in a Python prototype of
DDUO via object proxies and other pythonic idioms. We
implement several case studies to showcase these features and
demonstrate the usage of DDUO in practice. We also provide
integrations with several popular Python libraries for data and
privacy analysis.

Contributions. In summary, this paper makes the following
contributions:

- We introduce DDUO, a dynamic analysis for enforcing
differential privacy, and a reference implementation as a
Python library 1.

1The (non-anonymized) implementation is available to reviewers on request

- We formalize a subset of DDUO in a core language model,
and prove the soundness of DDUO’s dynamic sensitivity
analysis (as encoded in the model) using a step-indexed
logical relation.

- We present several case studies demonstrating the use of
DDUO to build practical, veriﬁed Python implementations
of complex differentially private algorithms.
The rest of the paper is organized as follows. First we
provide some background knowledge regarding the ﬁeld of
differential privacy (Section II). We provide an overview of our
work and the necessary tradeoffs (Section III). We illustrate
the usefulness and power of DDUO through some worked
examples (Section IV). We then discuss some of the nuances of
dynamic sensitivity (Section V) and dynamic privacy tracking
(Section VI). We present the formalization of DDUO and prove
the soundness of our sensitivity analysis (Section VII). We
provide several case studies demonstrating the usefulness of
DDUO in practice (Section VIII). Finally we outline related
work (Section IX) and conclude (Section X).

II. BACKGROUND

Differential Privacy. Differential privacy is a formal notion
of privacy; certain algorithms (called mechanisms) can be said
to satisfy differential privacy. Intuitively, the idea behind a
differential privacy mechanism is that: given inputs which
differ in the data of a single individual, the mechanism should
return statistically indistinguishable answers. This means that
the data of any one individual should not have any signiﬁcant
effect on the outcome of the mechanism, effectively protecting
privacy on the individual level. Formally, differential privacy
is parameterized by the privacy parameters ǫ, δ which control
the strength of the guarantee.

When we say "neighboring" inputs, this implies two inputs
that differ in the information of a single individual. However,
formally we can defer to some general distance metric which
may take several forms. We then say that according to the
distance metric, the distance between two databases must have
an upper bound of 1. Variation of the distance metric has led to
several other useful, non-standard forms of differential privacy
in the literature.

Deﬁnition II.1 (Differential privacy). Given a distance metric
dA ∈ A × A → R, a randomized algorithm (or mechanism)
M ∈ A → B satisﬁes (ǫ, δ)-differential privacy if
for all
x , x ′ ∈ A such that dA(x , x ′) ≤ 1 and all possible sets S ⊆ B
of outcomes, Pr[M(x ) ∈ S ] ≤ eǫPr[M(x ′) ∈ S ] + δ.

Differential privacy is compositional: running two mecha-
nisms M1 and M2 with privacy costs of (ǫ1 , δ1 ) and (ǫ2 , δ2 )
respectively has a total privacy cost of (ǫ1 + ǫ2 , δ1 + δ2 ). Ad-
vanced composition [19] improves on this composition bound
for iterative algorithms; several variants of differential privacy
(e.g. Rényi differential privacy [36] and zero-concentrated
differential privacy [15]) have been developed that improve
the bound even further. Importantly, sequential composition
theorems for differential privacy do not necessarily allow the

2

privacy parameters to be chosen adaptively, which presents
a special challenge in our setting—we discuss this issue in
Section VI.

III. OVERVIEW OF DDUO

DDUO is a dynamic analysis for enforcing differential
privacy. Our approach does not require static analysis of
programs, and allows DDUO to be implemented as a library
for programming languages like Python. DDUO’s dynamic
analysis has complete access to run-time information, so it
does not require the programmer to write any additional type
annotations—in many cases, DDUO can verify differential
privacy for essentially unmodiﬁed Python programs (see the
case studies in Section VIII). As a Python library, DDUO
is easily integrated with popular libraries like Pandas and
NumPy.

assume

an “honest but

Threat model. We
fallible”
programmer—that is, the programmer intends to produce a
differentially private program, but may unintentionally intro-
duce bugs. We assume that the programmer is not intentionally
attempting to subvert DDUO’s enforcement approach. Our ref-
erence implementation is embedded in Python, an inherently
dynamic language with run-time features like reﬂection. In
this setting, a malicious programmer or privacy-violating third-
party libraries can bypass our dynamic monitor and extract
sensitive information directly. Data-independent exceptions
can be safely used in our system, however our model must
explicitly avoid data-dependent exceptions such as division-by-
zero errors. Terminated programs can be rerun safely (while
consuming the privacy budget) because our analysis is inde-
pendent of any sensitive information (our metatheory implies
that sensitivity of a value is itself not sensitive). We also do not
address side-channels, including execution time. Like existing
enforcement approaches (PINQ, OpenDP, Diffprivlib), DDUO
is intended as a tool to help well-intentioned programmers
produce correct differentially private algorithms.

Soundness of the analysis. We formalize our dynamic sen-
sitivity analysis and prove its soundness in Section VII. Our
formalization includes the most challenging features of the
dynamic setting—conditionals and side effects—and provides
evidence that our Python implementation will be effective
in catching privacy bugs in real programs. DDUO relies on
existing work on privacy ﬁlters and odometers (discussed in
Section VI), whose soundness has been previously established,
for tracking privacy cost.

IV. DDUO BY EXAMPLE

vector). Or, data sources be created automatically upon loading
data through DDUO’s custom-wrapped third party APIs, such
as pandas. Note that our API can be easily modiﬁed to account
for initial sensitivities greater than 1 when users have multiple
datapoints in the input data.

from dduo import pandas as pd
df = pd.read_csv("data.csv")
df

Sensitive(<'DataFrame'>, {data.csv 7→ 1}, L∞)

A Sensitive value is returned. Sensitive values
represent sensitive information that cannot be viewed by the
analyst. When a Sensitive value is printed out, the analyst
sees (1) the type of the value, (2) its sensitivity environment,
and (3) its distance metric. The latter two components are
described next. The analyst is prevented from viewing the
value itself.

Sensitivity & distance metrics. Function sensitivity is a scalar
value which represents how much a change in a function’s
input will change the function’s output. For example, the
binary addition function f (x , y) = x + y is 1-sensitive in both
x and y, because changing either input by n will change the
sum by n. The function f (x ) = x + x , on the other hand, is 2-
sensitive in its argument x , because changing x by n changes
the function’s output by 2n. Sensitivity is key to differential
privacy because it is directly proportional to the amount of
noise we must add to the output of a function to make it
private.

DDUO tracks the sensitivity of a value to changes in the
program’s inputs using a sensitivity environment mapping
input data sources to sensitivities. Our example program
returned a Sensitive value with a sensitivity environment
of {data.csv 7→ 1 }, indicating that the underlying value is
1-sensitive in the data contained in data.csv. The DDUO
library tracks and updates the sensitivity environments of
Sensitive objects as operations are applied to them. For
example, adding a constant value to the elements of the
DataFrame results in no change to the sensitivity environment.

df + 5 # no change to sensitivity environment

Sensitive(<'DataFrame'>, {data.csv 7→ 1}, L∞)

Adding the DataFrame to itself doubles the sensitivity, in the
same way as the function f (x ) = x + x .

This section introduces the DDUO system via examples

df + df # doubles the sensitivity

written using our reference Python implementation.

Sensitive(<'DataFrame'>, {data.csv 7→ 2}, L∞)

Data Sources. Data sources are wrappers around sensitive
data that enable tracking of privacy information in the DDUO
python library. Each data source is associated with an identify-
ing string, such as the name of the input ﬁle the data was read
from. Data sources can be created manually by attaching an
identifying string (such as a ﬁlename) to a raw value (such as a

Finally, multiplying the DataFrame by a constant scales the
sensitivity, and multiplying the DataFrame by itself results in
inﬁnite sensitivity.

( df * 5, df * df)

3

( Sensitive(<'DataFrame'>, {data.csv 7→ 5}, L∞),
Sensitive(<'DataFrame'>, {data.csv 7→ ∞}, L∞) )

The distance metric component of a Sensitive value
describes how to measure sensitivity. For simple numeric
functions like f (x ) = x + x , the distance between two pos-
sible inputs x and x ′ is simply |x − x ′| (this is called the
cartesian metric). For more complicated data structures (e.g.
DataFrames), calculating the distance between two values is
more involved. The L∞ metric used in our example calculates
the distance between two DataFrames by measuring how many
rows are different (this is one standard way of deﬁning “neigh-
boring databases” in differential privacy). DDUO’s handling of
distance metrics is detailed in Section V-B.

Privacy. DDUO also tracks the privacy of computations. To
achieve differential privacy, programs add noise to sensitive
values. The Laplace mechanism described earlier is one basic
mechanism for achieving differential privacy by adding noise
drawn from the Laplace distribution (DDUO provides a num-
ber of basic mechanisms, including the Gaussian mechanism).
The following expression counts the number of rows in our ex-
ample DataFrame and uses the Laplace mechanism to achieve
ǫ-differential privacy, for ǫ = 1 .0 .

dduo.laplace(df.shape[0], ǫ=1.0)

9.963971319623278

The result is a regular Python value—the analyst is free to
view it, write it to a ﬁle, or do further computation on it. Once
the correct amount of noise has been added, the principle of
post-processing applies, and so DDUO no longer needs to track
the sensitivity or privacy cost of operations on the value.

When the Laplace mechanism is used multiple times, their
privacy costs compose (i.e.
the ǫs “add up” as described
earlier). DDUO tracks total privacy cost using objects called
privacy odometers [41]. The analyst can interact with a privacy
odometer object to learn the total privacy cost of a complex
computation.

with dduo.EpsOdometer() as odo:

_ = dduo.laplace(df.shape[0], ǫ = 1.0)
_ = dduo.laplace(df.shape[0], ǫ = 1.0)
print(odo)

Odometer_ǫ({data.csv 7→ 2.0})

Printing the odometer’s value allows the analyst to view the
privacy cost of the program with respect
to each of the
data sources used in the computation. In this example, two
differentially private approximations of the number of rows
in the dataframe df are computed, each with a privacy cost
of ǫ = 1 .0 . The total privacy cost of running the program is
therefore 2 ·ǫ = 2 .0 .

DDUO also allows the analyst

to place upper bounds
on total privacy cost (i.e. a privacy budget) using privacy
ﬁlters [41]. Privacy odometers and ﬁlters are discussed in detail
in Section VI.

V. DYNAMIC SENSITIVITY TRACKING

DDUO implements a dynamic sensitivity analysis by wrap-
ping values in Sensitive objects and calculating sensitivi-
ties as operations are performed on these objects. Type systems
for sensitivity [40], [25] construct a sensitivity environment
for each program expression; in the static analysis setting,
a sensitivity environment records the expression’s sensitivity
with respect to each of the variables currently in scope.

DDUO attaches sensitivity environments to values at run-
time: each Sensitive object holds both a value and its sen-
sitivity environment. As described earlier, DDUO’s sensitivity
environments record a value’s sensitivity with respect to each
of the program’s data sources. Formally, the sensitivity of a
single-argument function f in its input is deﬁned as:

sens(f ) , argmaxx,y

d(f (x), f (y))
d(x, y)

(cid:16)

(cid:17)

Where d is a distance metric over the values x and y could
take (distance metrics are discussed in Section V-B). Thus, a
sensitivity environment {a 7→ 1 } means that if the value of
the program input a changes by n, then the value of f (a) will
change by at most n.

A. Bounding the Sensitivity of Operations

Operations on Sensitive objects are deﬁned to perform
the same operation on the underlying values, and also con-
struct a new sensitivity environment for the operation’s result.
For example, DDUO’s __add__ operation sums both the
underlying values and their sensitivity environments:
def __add__(self, other):

assert self.metric == other.metric
return dduo.Sensitive(self.value + other.value,
self.senv + other.senv,
self.metric)

The sum of two sensitivity environments is deﬁned as the
element-wise sum of their items. For example:

{a 7→ 2, b 7→ 1} + {b 7→ 3, c 7→ 5} = {a 7→ 2, b 7→ 4, c 7→ 5}

The DDUO library provides sensitivity-aware versions of
Python’s basic numeric operations (formalized in Section VII).
We have also deﬁned sensitivity-aware versions of commonly-
used library functions, including the Pandas functions used in
Section IV, and subsets of NumPy and Scikit-learn.

B. Distance Metrics

At the core of the concept of sensitivity is the notion of
distance: how far apart we consider two information sources
to be from each other. For scalar values, the following two
distance metrics are often used:

• Cartesian (absolute difference) metric: d (x , y) = |x − y|
• Discrete metric: d (x , y) = 0 if x = y; 1 otherwise
For more complex structures—like lists and dataframes—
we can use distance metrics on vectors. Two commonly-used
metrics for vectors x and y of equal length are:
di (xi , yi )

• L1 (di ) metric: d (x , y) =

Pxi ,yi ∈x ,y

4

• L2 (di ) metric: d (x , y) =

di (xi , yi )2

r Pxi ,yi ∈x ,y

Both metrics are parameterized by di , a metric for the vector’s
elements. In addition to these two, we use the shorthand L∞
to mean L1 (d ), where d is the cartesian metric deﬁned above.
The L∞ metric works for any space with equality (e.g. strings),
and measures the number of elements where x and y differ.

The deﬁnition of differential privacy is parameterized by
a distance metric that is intended to capture the idea of two
inputs that differ in one individual’s data. Database-oriented
algorithms typically assume that each individual contributes
exactly one row to the database, and use the L∞ metric to
deﬁne neighboring databases (as we did in Section IV).

Distance metrics can be manipulated manually through op-
erations such as clipping, a technique commonly employed in
differentially private machine learning. DDUO tracks distance
metrics for Sensitive information, which can allow for
automatic conservation of the privacy budget while providing
more accurate query analysis.

Lists and arrays are compared by one of the L1 , L2 , or L∞
distance metrics. The choice of distance metric is important
when deﬁning sensitivity and thus privacy. For example, the
Laplace mechanism can only be used with the L1 metric, while
the Gaussian mechanism can be used with either L1 or L2 .

C. Conditionals & Side Effects

Conditionals and other branching structures are challenging
for any sensitivity analysis, but
they present a particular
challenge for our dynamic analysis. Consider the following
conditional:

if df.shape[0] == 10:
return df.shape[0]

else:

return df.shape[0] * 10000

Here, the two branches have different sensitivities (the else
branch is 10,000 times more sensitive in its data sources than
the then branch). Static sensitivity analyses handle this situa-
tion by taking the maximum of the two branches’ sensitivities
(i.e. they assume the worst-case branch is executed), but this
approach is not possible in our dynamic analysis.

In addition, special care must be taken when a sensitive
value appears in the guard position (as in our example).
Static analyses typically scale the branches’ sensitivity by the
sensitivity of the guard; in practice, this approach results in
inﬁnite sensitivity for conditionals with a sensitive guard.

To retain soundness in our dynamic analysis, DDUO re-
quires that conditional guards contain no sensitive values. A
run-time error is thrown if DDUO ﬁnds a sensitive value in
the guard position (as in our example above). Disallowing
sensitive guards makes it possible to ignore branches that
are not executed: the guard’s value remains the same under
neighboring program inputs, so the program follows the same
branch for neighboring executions. This approach does not
limit the set of useful programs we can write, since condition-
als with sensitive guards yield inﬁnite sensitivities even under
a precise static analysis.

5

Since DDUO attaches sensitivity environments to values
(instead of variables), the use of side effects does not affect the
soundness of the analysis. When a program variable is updated
to reference a new value, that value’s sensitivity environment
remains attached. DDUO handles many common side-effect-
based patterns used in Python this way; for example, DDUO
the following program results in the
correctly infers that
variable total holding a value that is 20 times more sensitive
than df.shape[0].

total = 0
for i in range(20):

total = total + df.shape[0]

For side effects, our dynamic analysis is more capable than
type-based static analysis, due to the additional challenges aris-
ing in the static setting (e.g. aliasing). We have formalized the
way DDUO handles side effects and conditionals, and proved
the soundness of our sensitivity analysis; our formalization
appears in Section VII.

VI. DYNAMIC PRIVACY TRACKING

DDUO tracks privacy cost dynamically, at runtime. Dy-
namic privacy tracking is challenging because the dynamic
analysis has no visibility into code that is not executed. For
example, consider the following conditional:
if dduo.gauss(ǫ=1.0, δ=1e-5, x) > 5:

print(dduo.gauss(ǫ=1.0, δ=1e-5, y))

else:

print(dduo.gauss(ǫ=100000000000.0, δ=1e-5, y))

The executed branch of this conditional depends on the result
of the ﬁrst call to dduo.gauss , which is non-deterministic.
The two branches use different privacy parameters for the
remaining calls to dduo.gauss ; in other words, the privacy
parameter for the second use of the Gaussian mechanism
is chosen adaptively, based on the results of the ﬁrst use.
Sequential composition theorems for differential privacy [19]
are typically stated in terms of ﬁxed (i.e. non-adaptive) privacy
parameters, and do not apply if the privacy parameters are
chosen adaptively.

A static analysis of this program will consider both branches,
and most analyses will produce an upper bound on the
program’s privacy cost by combining the two (i.e. taking the
maximum of the two ǫ values). This approach avoids the issue
of adaptively-chosen privacy parameters.

A dynamic analysis, by contrast, cannot consider both
branches, and must bound privacy cost by analyzing only the
branch that is executed. Sequential composition does not apply
directly when privacy parameters are chosen adaptively, so
ignoring the non-executed branch in a dynamic analysis of
privacy would be unsound.

A. Privacy Filters & Odometers

Privacy ﬁlters and odometers were originally developed by
Rogers et al. [41] speciﬁcally to address the setting in which
privacy parameters are selected adaptively. Winograd-Cort et
al. [49] used privacy ﬁlters and odometers as part of the

Adaptive Fuzz framework, which integrates both dynamic anal-
ysis (for composing privacy mechanisms) and static analysis
(for bounding the cost of individual mechanisms). Recently,
Feldman and Zrnic [24] developed ﬁlters and odometers for
Rényi differential privacy [36].

Privacy odometers can be used to obtain a running upper
bound on total privacy cost at any point in the sequence of
adaptive mechanisms, and to obtain an overall total at the
≥0 → R ∪ {∞}
end of the sequence. A function COMPδg : R2k
is called a valid privacy odometer [41] for a sequence of
mechanisms M1 , . . . , Mk if for all (adaptively-chosen) set-
tings of (ǫ1 , δ1 ), . . . , (ǫk , δk ) for the individual mechanisms
in the sequence, their composition satisﬁes (COMPδg (·), δg )-
differential privacy. In other words, COMPδg (·) returns a value
for ǫ that upper-bounds the privacy cost of the adaptive
sequence of mechanisms. A valid privacy odometer for sequen-
tial composition in (ǫ, δ)-differential privacy can be deﬁned as
follows (Rogers et al. [41], Theorem 3.6):

COMPδg (ǫ1, δ1, . . . , ǫk, δk) =

k

if

δi > δg

Pi=1
otherwise

ǫi

∞

k

Pi=1





B. Filters & Odometers in DDUO

DDUO’s API allows the programmer to explicitly create
privacy odometers and ﬁlters, and make them active for a
speciﬁc part of the program (using Python’s with syntax).
When an odometer is active, it records a running total of
the total privacy cost, and it can be queried to return this
information to the programmer.

with dduo.EdOdometer(delta = 10e-6) as odo:

_ = dduo.gauss(df.shape[0], ǫ = 1.0, δ = 10e-6)
_ = dduo.gauss(df.shape[0], ǫ = 1.0, δ = 10e-6)
print(odo)

Odometer_(ǫ, δ)({data.csv 7→ (2.0, 20−6)})

When a ﬁlter is active, it tracks the privacy cost for individual
mechanisms, and halts the program if the ﬁlter’s upper bound
on privacy cost is violated.
with dduo.EdFilter(ǫ = 1.0, δ = 10e-6) as odo:

print('1:', dduo.gauss(df.shape[0], ǫ=1.0, δ=10e-6))
print('2:', dduo.gauss(df.shape[0], ǫ=1.0, δ=10e-6))

1: 10.5627
Traceback (most recent call last):

...
dduo.PrivacyFilterException

if

Privacy ﬁlters allow the analyst

to place an upper
bound (ǫg , δg ) on the desired privacy cost, and halt
the bound is violated.
the computation immediately if
A function COMPǫg ,δg : R2k
≥0 → {HALT, CONT} is called a
valid privacy ﬁlter [41]
for a sequence of mechanisms
(adaptively-chosen) settings of
for all
M1 , . . . , Mk
(ǫ1 , δ1 ), . . . , (ǫk , δk ) for the individual mechanisms in the
sequence, COMPǫg ,δg (ǫ1 , δ1 , . . . , ǫk , δk ) outputs CONT only if
the sequence satisﬁes (ǫg , δg )-differential privacy (otherwise,
it outputs HALT for the ﬁrst mechanism in the sequence that
violates the privacy cost bound). A valid privacy ﬁlter for
sequential composition in (ǫ, δ)-differential privacy can be
deﬁned as follows (Rogers et al. [41], Theorem 3.6):

COMPǫg,δg (ǫ1, δ1, . . . , ǫk, δk) =

HALT if

k

δi > δg or

CONT otherwise

Pi=1

k

Pi=1

ǫi > ǫg






It is clear from these deﬁnitions that the odometer and ﬁlter
for sequential composition under (ǫ, δ)-differential privacy
yield the same bounds on privacy loss as the standard theorem
for sequential composition [19] (i.e. there is no “cost” to
picking the privacy parameters adaptively).

Rogers et al. [41] also deﬁne ﬁlters and odometers for
advanced composition under (ǫ, δ)-differential privacy ([41],
§5 and §6); in this case, there is a cost. In exchange for the
ability to set privacy parameters adaptively, ﬁlters and odome-
ters for advanced composition have slightly worse constants
than the standard advanced composition theorem [19] (but are
asymptotically the same).

6

under

In addition to odometers and ﬁlters

for
(ǫ, δ)-differential privacy

sequential
composition
as
(such
EdFilter and EdOdometer), DDUO provides odometers
advanced composition (AdvEdFilter
and ﬁlters
and AdvEdOdometer) and Rényi differential privacy
(RenyiFilter and RenyiOdometer, which follow the
results of Feldman and Zrnic [24]).

for

C. Loops and Composition

Iterative algorithms can be built in DDUO using Python’s
standard looping constructs, and DDUO’s privacy odometers
and ﬁlters take care of ensuring the correct form of compo-
sition. Parallel composition is also available—via functional
mapping. Advanced composition can be achieved via special
advanced composition ﬁlters and odometers exposed in the
DDUO API. For example, the following simple loop runs
the Laplace mechanism 20 times, and its total privacy cost
is reﬂected by the odometer:

with dduo.EpsOdometer() as odo:

for i in range(20):

dduo.laplace(df.shape[0], ǫ = 1.0)

print(odo)

Odometer_ǫ({data.csv 7→ 20.0})

To use advanced composition instead of sequential composi-
tion, we simply replace the odometer with a different one:
with dduo.AdvEdOdometer() as odo:

for i in range(20):

dduo.gauss(df.shape[0], ǫ = 0.01, δ = 0.001)

D. Mixing Variants of Differential Privacy

The DDUO library includes support for pure ǫ-differential
privacy, (ǫ, δ)-differential privacy, and Rényi differential pri-
vacy (RDP). Programs may use all three variants together,
convert between them, and compose mechanisms from each.
We demonstrate execution of a query while switched to
the Rényi differential privacy variant using pythonic "with"
syntax blocks. For programs that make extensive use of
composition, this approach yields signiﬁcant improvements
in privacy cost. For example, the following program uses
the Gaussian mechanism 200 times, using Rényi differential
privacy for sequential composition; the total privacy cost is
automatically converted into an (ǫ, δ)-differential privacy cost
after the loop ﬁnishes.

with dduo.RenyiDP(1e-5):
for x in range(200):

noisy_count = dduo.renyi_gauss(α = 10,

ǫ=0.2, df.shape[0])
dduo.print_privacy_cost()

Odometer_(ǫ, δ)({data.csv 7→ (41.28, 1e − 05)})

VII. FORMAL DESCRIPTION OF SENSITIVITY ANALYSIS

In DDUO we implement a novel dynamic analysis for func-
tion sensitivity, which is a relational (hyper)property quantiﬁed
over two runs of the program with arbitrary but related inputs.
In particular, our analysis computes function sensitivity—a
two-run property—after only observing one execution of the
program. Only observing one execution poses challenges to the
design of the analysis, and signiﬁcant challenges to the proof,
all of which we overcome. To overcome this challenge in the
design of the analysis, we ﬁrst disallow branching control
ﬂow which depends on any sensitive inputs;
this ensures
that any two runs of the program being considered for the
purposes of privacy will take the same branch observed by
the dynamic analysis. Second, we disallow sensitive input-
dependent arguments to the “scalar” side of multiplication;
this ensures that the dynamic analysis’ use of that argument
in analysis results is identical for any two runs of the program
being considered for the purposes of privacy. Our dynamic
analysis for function sensitivity is sound—meaning that the
true sensitivity of a program is guaranteed to be equal or less
than the sensitivity reported by DDUO’s dynamic monitor—
and we support this claim with a detailed proof.

Formalism Approach. We formalize the correctness of our
dynamic analysis for function sensitivity using a step-indexed
big-step semantics to describe the dynamic analysis, a step-
indexed logical relation to describe the meaning of func-
tion sensitivity, and a proof by induction and case analysis
on program syntax to show that dynamic analysis results
soundly predict function sensitivity. A step-indexed relation
is a relation R ∈ A → B → prop whose deﬁnition is strat-
iﬁed by a natural number index n, so for each level n
the relation R0
there is a new relation Rn . Typically,

T

is deﬁned R0 (x , y) , true, and the ﬁnal relation of inter-
est is ˆR ,
n Rn , i.e., ˆR(x , y) ⇐⇒ ∀n. Rn (x , y). Step-
indexing is typically used—as we do in our formalism—when
the deﬁnition of a relation would be not well founded in its
absence. The most common reason a relation deﬁnition might
be not well-founded is the use of self-reference without any
decreasing measure. When a decreasing measure exists, self-
reference leads to well-founded recursion, however when a
decreasing measure does not exist, self-reference is not well-
founded. When using step-indexing, self-reference is allowed
in the deﬁnition of Rn , but only for the relation at strictly
lower levels, so Rn ′ when n ′ < n;
this is well-founded
because the index n becomes a decreasing measure for the
self-reference. In this way, step-indexing enables self-reference
without any existing decreasing measure by introducing a new
decreasing measure, and maintains well-foundedness of the
relation deﬁnition.

A logical relation is one where the deﬁnition of relation
on function values (or types) is extensional, essentially saying
“when given related inputs, the function produces related out-
puts”. This deﬁnition is self-referrential and not well-founded,
and among common reasons to introduce step-indexing in pro-
gramming language proofs. As the relation R is stratiﬁed with
a step-index to Rn , so must the deﬁnition of the semantics,
so for a big-step relation e ⇓ v (relating an expression e to
its ﬁnal value v after evaluation) we stratify as e ⇓n v . Also,
because the deﬁnition of a logical relation decrements the
step-index for the case of function values, we increment the
step-index in the semantic case for function application. These
techniques are standard from prior work [3], and we merely
summarize the key ideas here to give background to our reader.

Formal Deﬁnition of Dynamic Analysis. We model lan-
guage features for arithmetic operations (e ⊙ e), conditionals
(if0(e){e}{e}), pairs (he, ei and πi (e)), functions (λx . e
and e(e)) and references (ref(e), !e and e ← e); the full
language is shown in Figure 1. There is one base value:
r @Σ
m for a real number result r tagged with dynamic analysis
information Σ —the sensitivity analysis for the expression
which evaluated to r —and m—the metric associated with
the resulting value r . The sensitivity analysis Σ —also called
a sensitivity environment—is a map from sensitive sources
o ∈ source to how sensitive the result is w.r.t. that source. Our
formalism includes two base metrics m ∈ metric: diff and
disc for absolute difference (|x − y|) and discrete distance
(0 if x = y and 1 otherwise) respectively—and two derived
metrics: ⊤ and ⊥ for the smallest metric larger than each base
metric and largest metric smaller than each base metric, re-
spectively. Each metric is commonly used when implementing
differentially private algorithms. Pair values (hv , v i), closure
values (hλx . e | ρi) and reference values (ℓ) do not contain
dynamic analysis information.

Our dynamic analysis is described formally as a big-
q
p
q
p
σ, vy
σ, ey
where ρ ∈ var ⇀ value is
step relation ρ ⊢ x
⇓n x
the lexical environment mapping lexical variables to values,
σ ∈ loc ⇀ value is the dynamic environment (i.e., the heap, or

7

store) mapping dynamically allocated references to values, e
is the expression being executed, and v is the resulting runtime
value which also includes dynamic analysis information. We
q
p
σ, ey
write gray box corners around the “input” conﬁguration x

q
p
σ, vy
and the “output” conﬁguration x
to aid readability. The
index n is for step-indexing, and tracks the number of function
applications which occurred in the process of evaluation. We
show the full deﬁnition of the dynamic analysis in Figure 2.

Consider the following example:

{x 7→ 21@{o7→1}

diff } ⊢ ∅, (x + x) ⇓0 42@{o7→2}

diff

This relation corresponds to a scenario where the program
to evaluate and analyze is x + x , the variable x represents
a sensitive source value o, we want to track sensitivity w.r.t.
the absolute difference metric, and the initial value for x is
21 . This information is encoded in an initial environment
ρ = {x 7→ 21 @{o7→1 }
. The result value is 42 , and the result-
ing analysis reports that e is 2 -sensitive in the source o w.r.t.
the absolute difference metric. This analysis information is
encoded in the return value 42 @{o7→2 }
. Because no function
applications occur during evaluation, the step index n is 0.

diff

diff

Formal Deﬁnition of Function Sensitivity. Function sensitiv-
ity is encoded through multiple relation deﬁnitions:

1) ρ1 , σ1 , e1 ∼Σ

n ρ2 , σ2 , e2 holds when the input triples
ρ1 , σ1 , e1 and ρ2 , σ2 , e2 evaluate to output stores and
values which are related by Σ . Note this deﬁnition
decrements the step-index n, and is the constant relation
when n = 0 .

2) r1 ∼r

m r2 holds when the difference between real num-

bers r1 and r2 w.r.t. metric m is less than r .

3) v1 ∼Σ

n v2 holds when values v1 and v2 are related for
initial distance Σ and step-index n. The deﬁnition is by
case analysis on the syntactic category for values, such
as:
a) The relation on base values r1 @Σ1

m2 holds
when Σ1 , Σ2 , m1 and m2 are pairwise equal, and
when r1 and r2 are related by Σ ·Σ1 , where Σ is the
initial distances between each input source o, and Σ1
is how much r1 and r2 are allowed to differ as a linear
function of input distances Σ , and where this function
is applied via vector dot product ·.

n r2 @Σ2

m1 ∼Σ

b) The relation on pair values hv11 , v12 i ∼Σ

m hv21 , v22 i
holds when each element of the pair are pairwise
related.

on

c) The

values
relation
hλx . e1 | ρ1 i ∼Σ
n hλx . e2 | ρ2 i holds when each
closure returns related output conﬁgurations when
evaluated with related inputs.
d) The relation on locations ℓ1 ∼Σ

n ℓ2 holds when the two

function

locations are equal.

4) ρ1 ∼Σ

n ρ2 holds when lexical environments ρ1 and ρ2

map all variables to related values.

5) σ1 ∼Σ

n σ2 holds when dynamic environments σ1 and σ2

map all locations to related values.

8

the deﬁnitions of ρ1 , σ1 , e1 ∼Σ

n ρ2 , σ2 , e2 and
Note that
v ∼Σ
n v are mutually recursive, but are well founded due to
the decrement of the step index in the former relation. We
show the full deﬁnition of these relations in Figure 1.

The function sensitivity of an expression is encoded ﬁrst as a
statement about expressions respecting relatedness, that is, re-
turning related outputs when given related inputs, i.e., (assum-
∅, v1
n ρ2 and ρ1 ⊢ ∅, e ⇓n1
ing no use of the store) if ρ1 ∼Σ
∅, v2 then n1 = n2 and v1 ∼Σ
and ρ2 ⊢ ∅e ⇓n2
n−n1 v2 .
When instantiated to base types, we have: if ρ1 ∼Σ
n ρ2 and
∅, r2 @Σ2
ρ1 ⊢ ∅, e ⇓n1
then
m2
n1 = n2 , Σ1 = Σ2 , m1 = m2 and r1 ∼Σ ·Σ1
r2 . The fully
general form of this property is called metric preservation,
which is the main property we prove in our formal develop-
ment.

m1 and ρ2 ⊢ ∅e ⇓n2
m1

∅, r1 @Σ1

Metric Preservation. Metric preservation states that when
given related initial conﬁgurations and evaluation outputs, then
those outputs are related. Outputs include result values, as well
as dynamic analysis results, and the relationship that holds
demonstrates the soundness of the analysis results.

Theorem VII.1 (Metric Preservation).

n ρ2
n σ2

If: ρ1 ∼Σ
And: σ1 ∼Σ
Then: ρ1 , σ1 , e ∼Σ
That is, either n = 0 or n = n ′ + 1 and. . .

n ρ2 , σ2 , e

If: n1 ≤ n ′
q
p
σ1 , ey
And: ρ1 ⊢ x
q
p
σ2 , ey
And: ρ2 ⊢ x
Then: n1 = n2
And: σ′
And:

1 ∼Σ
v1 ∼Σ

n ′−n1 σ′
2
v2
n ′−n1

q
p
σ′
1 , v1y
⇓n1 x
q
p
σ′
2 , v2y
⇓n2 x

Proof. See detailed proof in the appendix.

Instantiating Metric Preservation. Metric preservation is not
enough on its own to demonstrate sound dynamic analysis of
function sensitivity. Suppose we execute the dynamic analysis
on program e with initial environment ρ, yielding a ﬁnal store
σ, base value r , sensitivity environment Σ , metric m and step-
index n as a result:

ρ ⊢ ∅, e ⇓n σ, r @Σ
m

To know the sensitivity of e is to know a bound on two
arbitrary runs of e, that is, using two arbitrary environments
ρ1 and ρ2 . Does Σ tell us this? Remarkably, it does, with
one small condition: ρ1 and ρ2 must agree with ρ on all non-
sensitive values. This is not actually limiting: a non-sensitive
value is essentially auxiliary information; they are constants
and ﬁxed for the purposes of sensitivity and privacy.

We can encode the relationship that environments ρ and
ρ1 agree on all non-sensitive values as ρ ∼Σ ′
ρ1 for any
Σ ′, and we allow for environments ρ and ρ1 to differ on

b ∈ B

n ∈ N

i ∈ Z

r ∈ R

x ∈ var

o ∈ source
ℓ ∈ loc
e ∈ expr

sensitive sources
reference locations
::= x
variables
real numbers
| r
arith. operations
| e ⊙ e
| if0(e){e}{e} cond. branching
| he, ei
| πi(e)
| λx. e
| e(e)
| ref(e)
|
!e
| e ← e

pair creation
pair access
function creation
function application
reference creation
reference read
reference write

::= r | ∞

q ∈ ˆR
⊙ ∈ binop ::= + | ⋉ | ⋊
m ∈ metric ::= diff
| disc
| ⊥
| ⊤

ext. reals
operations
absolute difference
discrete
bot metric
top metric
v ∈ value ::= r@Σ
tagged base value
m
pair
| hv, vi
function (closure)
| hλx. e | ρi
location (pointer)
| ℓ
, var ⇀ value value environment

ρ ∈ env
σ ∈ store , loc ⇀ value mutable store
Σ ∈ senv , source ⇀ ˆR sens. environment

ρ1, σ1, e1 ∼Σ
ρ1, σ1, e1 ∼Σ

0 ρ2, σ2, e2
n+1 ρ2, σ2, e2

△

△

⇐⇒ true
⇐⇒ ∀n1 ≤ n, n2, σ′
q
p
ρ1 ⊢ x
σ1, e1y

⇒ n1 = n2 ∧ σ′

1, σ′
2, v1, v2.
q
p
σ′
⇓n1 x
1, v1y
1 ∼Σ
n−n1 σ′

q
p
σ2, e2y
∧ ρ2 ⊢ x
2 ∧ v1 ∼Σ
n−n1 v2

q
p
σ′
2, v2y
⇓n2 x

ρ, σ, e ∼Σ

n ρ, σ, e

r1 ∼r
r1 ∼r

diff r2

disc r2

△

⇐⇒ |r1 − r2| ≤ r
0 ≤ r
1 ≤ r

△
⇐⇒

if
if

(cid:26)

r1 = r2
r1 6= r2

r1 ∼r
r1 ∼r

⊥ r2
⊤ r2

△

⇐⇒ r1 ∼r
⇐⇒ r1 ∼r

diff r2 ∧ r1 ∼r
diff r2 ∨ r1 ∼r

disc r2
disc r2

△

r ∼r

m r

hv11, v12i ∼Σ

r1@Σ1

m1 ∼Σ

n r2@Σ2
m2
n hv21, v22i
n hλx. e2 | ρ2i

hλx. e1 | ρ1i ∼Σ

△

△

⇐⇒ Σ1 = Σ2 ∧ m1 = m2 ∧ r1 ∼Σ·Σ1
⇐⇒ v11 ∼Σ
n v21 ∧ v21 ∼Σ
⇐⇒ ∀n′ ≤ n, v1, v2, σ1, σ2. σ1 ∼Σ
⇒ σ1, {x 7→ v1} ⊎ ρ1, e1 ∼Σ
△

n v22

m1

△

n′ σ2 ∧ v1 ∼Σ
n′ v2
n′ σ2, {x 7→ v2} ⊎ ρ2, e2

r2

v ∼Σ

n v

ℓ1 ∼Σ

n ℓ2

⇐⇒ ℓ1 = ℓ2

ρ1 ∼Σ
σ1 ∼Σ

n ρ2
n σ2

△

⇐⇒ ∀x ∈ (dom(ρ1) ∪ dom(ρ2)). ρ1(x) ∼Σ
⇐⇒ ∀ℓ ∈ (dom(σ1) ∪ dom(σ2)). σ1(ℓ) ∼Σ

△

n ρ2(x)
n σ2(ℓ)

ρ ∼Σ
σ ∼Σ

n ρ
n σ

Fig. 1. Formal Syntax & Step-indexed Logical Relation.

any sensitive value while agreeing on non-sensitive values as
ρ ∼{o7→∞} ρ1 . Under such an assumption, Σ and m are sound
dynamic analysis results for two arbitrary runs of e, i.e., under
environments ρ1 and ρ2 , so long as one of those environments
agrees with ρ—the environment used to compute the dynamic
analysis. We encode this property formally as the following
corollary to metric preservation:

If: n1 < n, n2 < n and n3 < n (H1)
(H2)

ρ1

q
p
σ, r @Σ
⇓n1 x
my

And: ρ ∼{o7→∞}
n
q
p
∅, ey
And: ρ ⊢ x
And: ρ1 ∼Σ ′
n ρ2
q
p
q
p
∅, ey
σ1 , r1 @Σ1
And: ρ1 ⊢ x
⇓n2 x
m1y
q
p
q
p
∅, ey
σ2 , r2 @Σ2
And: ρ2 ⊢ x
⇓n3 x
m2y
r1 ∼Σ ′
r2
Then:
m1

·Σ

(H3)

(H4)

(H5)

(H6)

(C1)

Corollary VII.1.1 (Sound Dynamic Analysis for Sensitivity).

Proof.
By Metric Preservation, (H2), (H1), (H3) and (H5) we have
Σ1 = Σ and m1 = m. By Metric Preservation, (H4), (H1),
(H5) and (H6) we have proved the goal (C1).

9

⌉ ⌈r ∈ ˆR → ˆR
⌉ ⌈r ∈ senv → sens

⌉r′⌈r ,

if
if
⌉Σ⌈r(o) , ⌉Σ(o)⌈r

0
r
(cid:26)

r′ = 0
r′ 6= 0

alloc(L) /∈ L ∈ ℘(loc)

Z = {o 7→ 0}

q
p
σ, ey
ρ ⊢ x

q
p
σ, vy
⇓n x

VAR

REAL

FUN

q
p
σ, xy
ρ ⊢ x

q
p
σ, ρ(x)y
⇓0 x

q
p
σ, ry
ρ ⊢ x

p
σ, r@Z
⇓0 x

q
discy

q
p
σ, λx. ey
ρ ⊢ x

q
p
σ, hλx. e | ρiy
⇓0 x

PLUS

q
p
ρ ⊢ x
σ , e1y
q
p
σ′, e2y
ρ ⊢ x
q
p
σ, e1 + e2y
ρ ⊢ x

q
p
σ′ , r1@Σ1
⇓n1 x
m1y
q
p
σ′′, r2@Σ2
⇓n2 x
m2y
q
p
σ′′, (r1 + r2)@Σ1+Σ2
⇓n1+n2 x
m1⊔m2y

TIMES-L

q
p
ρ ⊢ x
σ , e1y
q
p
σ′, e2y
ρ ⊢ x
q
p
σ, e1 ⋉ e2y
ρ ⊢ x

p
q
σ′ , r1@Z
⇓n1 x
m1y
q
p
σ′′, r2@Σ2
⇓n2 x
m2y
q
p
σ′′, (r1 × r2)@r1Σ2
⇓n1+n2 x
m2 y

TIMES-R

q
p
σ , e1y
ρ ⊢ x
q
p
σ′, e2y
ρ ⊢ x
q
p
σ, e1 ⋊ e2y
ρ ⊢ x

q
p
σ′ , r1@Σ1
⇓n1 x
m1y
q
p
σ′′, r2@Z
⇓n2 x
m2y
q
p
σ′′, (r1 × r2)@r2Σ1
⇓n1+n2 x
m1 y

q
m1y

p
σ′ , r1 @Z
⇓n1 x
q
p
σ′′, v2y
⇓n2 x

IFZ-T
q
p
σ , e1y
ρ ⊢ x
q
p
σ′, e2y
ρ ⊢ x
q
p
σ, if0(e1){e2}{e3}y
ρ ⊢ x

r1 = 0
q
p
σ′′, v2y
⇓n1+n2 x

q
m1y

IFZ-F
q
p
σ , e1y
ρ ⊢ x
q
p
σ′, e3y
ρ ⊢ x
q
p
σ, if0(e1){e2}{e3}y
ρ ⊢ x

p
σ′ , r1 @Z
⇓n1 x
q
p
σ′′, v3y
⇓n2 x

r1 6= 0

q
p
σ′′, v3y
⇓n1+n2 x

PAIR

q
p
σ , e1y
ρ ⊢ x
q
p
σ′, e2y
ρ ⊢ x
q
p
σ, he1, e2iy
ρ ⊢ x

q
p
σ′ , v1y
⇓n1 x
q
p
σ′′, v2y
⇓n2 x
q
p
σ′′, hv1, v2iy
⇓n1+n2 x

PROJ
q
p
q
p
σ′, hv1, v2iy
⇓n x
σ, ey
ρ ⊢ x
q
p
q
p
σ′, vn′y
⇓n x
σ, πn′ (e)y
ρ ⊢ x

REF

q
p
q
p
σ′, vy
⇓n x
σ, ey
ρ ⊢ x
ℓ = alloc(dom(σ))

q
p
σ, ref(e)y
ρ ⊢ x

q
p
{ℓ 7→ v} ⊎ σ′, ℓy
⇓n x

READ

q
p
σ, ey
ρ ⊢ x
q
p
σ, !ey
ρ ⊢ x

q
p
σ′, ℓy
⇓n x
q
p
σ′, σ′(ℓ)y
⇓n x

WRITE

q
p
σ , e1y
ρ ⊢ x
q
p
σ′, e2y
ρ ⊢ x
q
p
σ, e1 ← e2y
ρ ⊢ x

q
p
σ′ , ℓy
⇓n1 x
q
p
σ′′, vy
⇓n2 x
q
p
σ′′[ℓ 7→ v], vy
⇓n x

APP

q
p
ρ ⊢ x
σ, e1y

q
p
σ′, hλx. e | ρiy
⇓n1 x

q
p
σ′′, vy
⇓n2 x

q
p
σ′′, ey
{x 7→ v} ⊎ ρ ⊢ x

q
p
σ′′′, v′
⇓n3 x
y

q
p
σ′, e2y
ρ ⊢ x
q
p
σ, e1(e2)y
ρ ⊢ x

q
p
σ′′′, v′
⇓n1+n2+n3+1 x
y

Fig. 2. Formal Big-step, Step-indexed Semantics and Metafunctions.

Note that the ﬁnal results are related using Σ —the analysis
result derived from an execution under ρ—while r1 and r2
are derived from executions under unrelated (modulo auxiliary
information) environments ρ1 and ρ2 .

In simpler terms, this corollary shows that even though the
dynamic analysis only sees one particular execution of the
program, it is accurate in describing the sensitivity of the
program—even though the notion of sensitivity considers two
arbitrary runs of the program, including those whose inputs
differ entirely from those used in the dynamic analysis.

VIII. IMPLEMENTATION & CASE STUDIES

We have developed a reference implementation of DDUO
as a Python library, using the approaches described in Sec-
tions IV, V, and VI.

A major goal in the design of DDUO is seamless integration
with other libraries. Our reference implementation provides ini-
tial support for NumPy, Pandas, and Sklearn. DDUO provides
hooks for tracking both sensitivity and privacy, to simplify
integrating with additional libraries.

We present the case studies which focus on demonstrating
DDUO’s (1) similarity to regular Python code, (2) applicability

10

Name Type
laplace : (ǫ : R, value : R)
gauss : (ǫ : R, δ : R, value : R)

ed_odo : (f : A → B, in : A)
renyi_odo : (f : A → B, in : A)

ed_ﬁlter : (f : A → B, in : A, (ǫ, δ) : (R, R)) → (out : B)
renyi_ﬁlter : (f : A → B, in : A, (α, ǫ) : (R, R)) → (out : B)
conv_renyi : (f : A → B, in : A, δ : R)
→ (out : B)

svt : (ǫ : R, qs : [A → B], data : [A], t : R) → N

exp : (ǫ : R, q : A → B, data : [A])
map : (f : A → B, in : [A])

→ R
where
→ R
where
→ (out : B, (ǫ, δ) : (R, R)) where
→ (out : B, (α, ǫ) : (R, R)) where
where
where
where
and
where
and
where
where

→ N
→ [B]

Conditions

priv(laplace(ǫ, value)) , ǫ
priv(gauss(ǫ, δ, value)) , (ǫ, δ)

priv(ed_odo(f, in)) , priv(f (in))
priv(renyi_odo(f, in)) , priv(f (in))
(ǫ, δ) ≥ priv(f (in))
(α, ǫ) ≥ priv(f (in))

priv(f (...)) = (α, ǫ)
conv(α, ǫ, δ) = (ǫ, δ)

for q in qs, sens(q) = 1
priv(svt(ǫ, qs, data, t)) , ǫ
priv(exp(ǫ, q, data)) , ǫ

sens(map(f,

)) , sens(f ( ))

priv: denotes the privacy leakage of a program given by dynamic analysis; sens: denotes the sensitivity of a program given by dynamic analysis; conv:
represents the conversion equation from renyi to approximate differential privacy
Types are written as follows: the → symbol is used to seperate the domain and range of a function, either of which may be given as an atomic type such as a
natural number (N), or as a tuple which is a comma-seperated list of types surrounded by parentheses, or as a symbol (A) indicating parametric polymorphism
(generics). In some cases, types may also be accompanied with a placeholder name (ǫ : R) for further qualiﬁcation in the where clause.

Fig. 3. Core API Methods

to complex algorithms, (3) easy integration with existing
libraries. In this section we focus on the Noisy Gradient
Descent case study, other case studies have been moved to
the appendix due to space requirements. We introduce new
adaptive variants of algorithms that stop early when possible to
conserve privacy budget. These variants cannot be veriﬁed by
prior work using purely static analyses, because their privacy
parameters are chosen adaptively.

Run-time overhead. Run-time overhead is a key concern in
DDUO’s instrumentation for dynamic analysis. Fortunately,
experiments on our case studies suggest that the overhead
of DDUO’s analysis is generally low. Table I presents the
run-time performance overhead of DDUO’s analysis as a
percentage increase of total runtime. The worst overhead time
observed in our case studies was less than 60%.

In certain rare cases, DDUO’s overhead can be much higher.
For example, mapping the function lambda x: x + 1 over
a list of 1 million numbers takes 160x longer under DDUO
than in standard Python. The overhead in this case comes from
a combination of factors: ﬁrst, DDUO’s map function, itself
implemented in Python, is much slower than Python’s built-
in map operator; second, DDUO’s map function requires the
creation of a new Sensitive object for each element of the
list—a slow operation in Python.

Fortunately,

the same strategies

for producing high-
performance Python code without privacy also help reduce
DDUO’s overhead. Python’s performance characteristics have
prompted the development of higher-performance libraries like
NumPy and Pandas, which essentially provide data-processing
combinators that programmers compose. By providing sensi-
tivity annotations for these libraries, we can re-use these high-
performance implementations and avoid creating extra objects.
As a result, none of our case studies demonstrates the worst-

Technique
Noisy Gradient Descent
Multiplicative Weights (MWEM)
Private Naive Bayes Classiﬁcation
Private Logistic Regression

Ref.
[12]
[29]
[44]
[16]

Libraries Used Overhead
NumPy
Pandas
DiffPrivLib
DiffPrivLib

6.42%
14.90%
12.44%
56.33%

TABLE I
LIST OF CASE STUDIES INCLUDED WITH THE DDUO IMPLEMENTATION.

case performance overhead described above.

Case study: gradient descent with NumPy. Our ﬁrst case
study (Figure 4) is a simple machine learning algorithm
based on [12] implemented directly with DDUO-instrumented
NumPy primitives. The remaining case studies appear in the
Appendix.

Given a dataset X which is a list of feature vectors repre-
senting training examples, and a vector y which classiﬁes each
element of X in a ﬁnite set, gradient descent is the process
of computing a model (a linear set of weights) which most
accurately classiﬁes a new, never seen before training example,
based on our pre-existing evidence represented by the model.
Gradient descent works by ﬁrst specifying a loss function
that computes the effectiveness of a model in classifying a
given dataset according to its known labels. The algorithm then
iteratively computes a model that minimizes the loss function,
by calculating the gradient of the loss function and moving
the model in the opposite direction of the gradient.

One method of ensuring privacy in gradient descent involves
adding noise to the gradient calculation, which is the only
part of the process that is exposed to the private training
data. In order to add noise to the gradient, it is convenient
to bound its sensitivity via clipping to some L2 norm. In
this example, clipping occurs in the gradient_sum function
before summation.

The original implementation of this algorithm [12] was

11

def dp_gradient_descent(iterations, alpha, eps):

eps_i = eps/iterations
theta = np.zeros(X.shape[1])
with dduo.RenyiFilter(alpha,eps_max):

with dduo.RenyiOdometer((alpha, eps)) as odo:

noisy_count = dduo.renyi_gauss(α=alpha,

ǫ=eps,X.shape[0])
priv_acc = 0
acc_diff = 1

while acc_diff > 0.05:

grad_sum = gradient_sum(theta,

X_train, y_train, sensitivity)

noisy_grad_sum = dduo.gauss_vec(grad_sum,

α=alpha,ǫ=eps_i)

noisy_avg_grad = noisy_grad_sum/noisy_count
theta = np.subtract(theta, noisy_avg_grad)
priv_acc_curr = dduo.renyi_gauss(alpha,

eps_acc, accuracy(theta))

acc_diff =
priv_acc = priv_acc_curr

priv_acc_curr - priv_acc

print(odo)
return theta

theta = dp_gradient_descent(iterations,

α=alpha, ǫ=epsilon)

acc = dduo.renyi_gauss(alpha,
eps_acc, accuracy(theta))

print(f"final accuracy: {acc}")

Odometer_(α, ǫ)({data.csv 7→ (10.0, 2.40)})
final accuracy: 0.753

Fig. 4. Gradient Descent with NumPy

based on the advanced composition theorem. Advanced com-
position improves on sequential composition by providing
much tighter privacy bounds over several iterations, but re-
quires the analyst to ﬁx the number of iterations up front, re-
gardless of how many iterations the gradient descent algorithm
actually takes to converge to minimal error.

We present a modiﬁed version based on adaptive Renyi
differential privacy which provides not only a tighter analysis
of the privacy leakage over several iterations, but also allows
the analyst to halt computation adaptively (conserving the
remaining privacy budget) once a certain level of model
accuracy has been reached, or loss has been minimized. We
obscure the accuracy calculation because it is a computation
on the sensitive input training dataset in this case.

IX. RELATED WORK

Dynamic Enforcement of Differential Privacy. The ﬁrst
approach for dynamic enforcement of differential privacy was
PINQ [35]. Since then several works have been based on
PINQ, such as Featherweight PINQ [20] which models PINQ
formally and proves that any programs which use its simpliﬁed
PINQ API are differentially private. ProPer [21] is a system
(based on PINQ) designed to maintain a privacy budget for
each individual in a database system, and operates by silently
dropping records from queries when their privacy budget is ex-
ceeded. UniTrax [37] follows up on ProPer: this system allows
per-user budgets but gets around the issue of silently dropping
records by tracking queries against an abstract database as
opposed to the actual database records. These approaches are

limited to an embedded DSL for expressing relational database
queries, and do not support general purpose programming.

A number of programming frameworks for differential
privacy have been developed as libraries for existing pro-
gramming languages. DPELLA [34] is a Haskell library that
provides static bounds on the accuracy of differentially pri-
vate programs. Diffprivlib [31] (for Python) and Google’s li-
brary [48] (for several languages) provide differentially private
algorithms, but do not track sensitivity or privacy as these
algorithms are composed. ǫktelo [50] executes programmer-
speciﬁed plans that encode differentially private algorithms
using framework-supplied building blocks.

Dynamic Information Flow Control. Our approach to dy-
namic enforcement of differential privacy can be seen as
similar to work on dynamic information ﬂow control (IFC)
and taint analysis [6]. The sensitivities that we attach to values
are comparable to IFC labels. However, dynamic IFC typically
allows the programmer to branch on sensitive information and
handles implicit ﬂows dynamically. DDUO prevents branching
on sensitive information, similar to an approach taken for
preventing side-channels in the "constant time" programming
discipline for cryptographic code [7]. Another connection with
this line of work is that our use of the logical relations proof
technique for a differential privacy theorem is similar to the
usage of this technique for noninterference theorems [42], [30],
[1], [14], [5], [26].

Static Veriﬁcation of Differential Privacy. The ﬁrst approach
for static veriﬁcation of differential privacy was FUZZ [40],
which used linear types to analyze sensitivity. DFUZZ [25]
adds dependent types, and later work [17], [39] extends the
approach to (ǫ, δ)-differential privacy. FUZZI [52] integrates
a FUZZ-like type system with an expressive program logic.
Adaptive Fuzz [49] combines a FUZZ-style static type system
for sensitivity analysis with a dynamic privacy analysis using
privacy ﬁlters and odometers; Adaptive Fuzz is most similar
to our approach, but uses a static sensitivity analysis. All of
these approaches require additional type annotations.

A second category is based on approximate couplings [8].
The APRHL [10], [11], APRHL+ [9], and SPAN-APRHL [43]
relational logics are extremely expressive, but less amenable
to automation. Albarghouthi and Hsu [4] use an alternative
approach based on constraint solving to synthesize approx-
imate couplings. A third approach is based on randomness
alignments; LightDP [51] and ShadowDP [46] take this ap-
proach. Randomness alignments are effective for verifying low-
level mechanisms like the sparse vector technique. The latter
two categories are generally restricted to ﬁrst order imperative
programs.

Dynamic Testing for Differential Privacy. A recent line
of work [13], [18], [45], [48] has resulted in approaches
for testing differentially private programs. These approaches
generate a series of neighboring inputs, run the program many
times on the neighboring inputs, and raise an alarm if a
counterexample is found. These approaches do not require

12

type annotations, but do require running the program many
times.

X. CONCLUSION

We have presented DDUO, a dynamic analysis that sup-
ports general-purpose differentially private programming with
an emphasis on machine learning. We have formalized the
sensitivity analysis of DDUO and proven its soundness using a
step-indexed logical relation. Our case studies demonstrate the
utility of DDUO by enforcing adaptive variants of several dif-
ferentially private state-of-the-art machine learning algorithms
from the ground up, while integrating with some of Python’s
most popular libraries for data analysis.

13

REFERENCES

[1] Martín Abadi, Anindya Banerjee, Nevin Heintze, and Jon G. Riecke. A
core calculus of dependency. In Proceedings of the 26th ACM SIGPLAN-
SIGACT Symposium on Principles of Programming Languages, POPL
’99, pages 147–160, New York, NY, USA, 1999. Association for
Computing Machinery.

[2] John M. Abowd. The u.s. census bureau adopts differential privacy.
In Proceedings of the 24th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, KDD ’18, page 2867, New
York, NY, USA, 2018. Association for Computing Machinery.

[3] Amal Ahmed. Step-indexed syntactic logical relations for recursive
and quantiﬁed types. In Peter Sestoft, editor, Programming Languages
and Systems, pages 69–83, Berlin, Heidelberg, 2006. Springer Berlin
Heidelberg.

[4] Aws Albarghouthi and Justin Hsu. Synthesizing coupling proofs of

differential privacy. PACMPL, 2(POPL):58:1–58:30, 2018.

[5] Maximilian Algehed and Jean-Philippe Bernardy. Simple noninterfer-
ence from parametricity. Proc. ACM Program. Lang., 3(ICFP), July
2019.

[6] Thomas H. Austin and C. Flanagan. Efﬁcient purely-dynamic informa-

tion ﬂow analysis. In PLAS ’09, 2009.

[7] Gilles Barthe, Gustavo Betarte, Juan Diego Campo, and Carlos Luna.
System-level non-interference of constant-time cryptography. part I:
model. J. Autom. Reason., 63(1):1–51, 2019.

[8] Gilles Barthe, Thomas Espitau, Justin Hsu, Tetsuya Sato, and Pierre-
Yves Strub. Relational ⋆⋆\star-liftings for differential privacy. Logical
Methods in Computer Science, 15(4), 2019.

[9] Gilles Barthe, Marco Gaboardi, Benjamin Grégoire, Justin Hsu, and
Pierre-Yves Strub. Proving differential privacy via probabilistic cou-
In Proceedings of the 31st Annual ACM/IEEE Symposium on
plings.
Logic in Computer Science, LICS ’16, pages 749–758, New York, NY,
USA, 2016. Association for Computing Machinery.

[10] Gilles Barthe, Boris Köpf, Federico Olmedo,

and Santiago
Probabilistic relational reasoning for differential
Zanella Béguelin.
In Proceedings of the 39th Annual ACM SIGPLAN-SIGACT
privacy.
Symposium on Principles of Programming Languages, POPL ’12,
pages 97–110, New York, NY, USA, 2012. Association for Computing
Machinery.

[11] Gilles Barthe, Boris Köpf, Federico Olmedo, and Santiago Zanella-
Béguelin. Probabilistic relational reasoning for differential privacy. ACM
Trans. Program. Lang. Syst., 35(3), November 2013.

[12] Raef Bassily, Adam Smith, and Abhradeep Thakurta. Private empirical
risk minimization: Efﬁcient algorithms and tight error bounds.
In
Foundations of Computer Science (FOCS), 2014 IEEE 55th Annual
Symposium on, pages 464–473. IEEE, 2014.

[13] Benjamin Bichsel, Timon Gehr, Dana Drachsler-Cohen, Petar Tsankov,
and Martin Vechev. Dp-ﬁnder: Finding differential privacy violations by
sampling and optimization. In Proceedings of the 2018 ACM SIGSAC
Conference on Computer and Communications Security, pages 508–524,
2018.

[14] William J. Bowman and Amal Ahmed. Noninterference for free.

SIGPLAN Not., 50(9):101–113, August 2015.

[15] Mark Bun and Thomas Steinke. Concentrated differential privacy: Sim-
pliﬁcations, extensions, and lower bounds. In Theory of Cryptography
Conference, pages 635–658. Springer, 2016.

[16] K. Chaudhuri and C. Monteleoni. Privacy-preserving logistic regression.

In NIPS, 2008.

[17] Arthur Azevedo de Amorim, Marco Gaboardi, Justin Hsu, and Shin-ya
Katsumata. Probabilistic relational reasoning via metrics. In 2019 34th
Annual ACM/IEEE Symposium on Logic in Computer Science (LICS),
pages 1–19. IEEE, 2019.

[18] Zeyu Ding, Yuxin Wang, Guanhong Wang, Danfeng Zhang, and Daniel
In Proceedings of
Kifer. Detecting violations of differential privacy.
the 2018 ACM SIGSAC Conference on Computer and Communications
Security, pages 475–489, 2018.

[19] Cynthia Dwork, Aaron Roth, et al. The algorithmic foundations of
differential privacy. Foundations and Trends® in Theoretical Computer
Science, 9(3–4):211–407, 2014.

[20] Hamid Ebadi and David Sands. Featherweight pinq, 2015.
[21] Hamid Ebadi, David Sands, and Gerardo Schneider. Differential privacy:

Now it’s getting personal. volume 50, 01 2015.

[22] Georgina Evans and Gary King. Statistically valid inferences from
differentially private data releases, with application to the facebook urls
dataset, Working Paper.

[23] Georgina Evans, Gary King, Margaret Schwenzfeier, and Abhradeep
Thakurta. Statistically valid inferences from privacy protected data,
Working Paper.

[24] Vitaly Feldman and Tijana Zrnic. Individual privacy accounting via a

renyi ﬁlter. arXiv preprint arXiv:2008.11193, 2020.

[25] Marco Gaboardi, Andreas Haeberlen, Justin Hsu, Arjun Narayan, and
Benjamin C Pierce. Linear dependent types for differential privacy. In
Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on
Principles of programming languages, pages 357–370, 2013.

[26] Simon Oddershede Gregersen, Johan Bay, Amin Timany, and Lars
Birkedal. Mechanized logical relations for termination-insensitive non-
interference. Proc. ACM Program. Lang., 5(POPL), January 2021.
[27] Miguel Guevara. Enabling developers and organizations to use differen-

tial privacy, Sep 2019.

[28] Miguel Guevara, Mirac Vuslat Basaran, Sasha Kulankhina, and Badih

Ghazi. Expanding our differential privacy library, Jun 2020.

[29] Moritz Hardt, Katrina Ligett, and Frank McSherry. A simple and
practical algorithm for differentially private data release. In Advances
in Neural Information Processing Systems, pages 2339–2347, 2012.
[30] Nevin Heintze and Jon G. Riecke. The slam calculus: Programming
with secrecy and integrity. In Proceedings of the 25th ACM SIGPLAN-
SIGACT Symposium on Principles of Programming Languages, POPL
’98, pages 365–377, New York, NY, USA, 1998. Association for
Computing Machinery.

[31] Naoise Holohan, Stefano Braghin, Pól Mac Aonghusa, and Killian
Levacher. Diffprivlib: the ibm differential privacy library. arXiv preprint
arXiv:1907.02444, 2019.

[32] Daniel Kifer, Solomon Messing, Aaron Roth, Abhradeep Thakurta, and
Danfeng Zhang. Guidelines for implementing and auditing differentially
private systems, 2020.

[33] Gary King and Nathaniel Persily. Unprecedented facebook urls dataset
now available for academic research through social science one, Feb
2020.

[34] Elisabet Lobo-Vesga, Alejandro Russo, and Marco Gaboardi. A program-
ming framework for differential privacy with accuracy concentration
bounds. In 2020 IEEE Symposium on Security and Privacy (SP), pages
411–428. IEEE, 2020.

[35] Frank D. McSherry. Privacy integrated queries: An extensible platform
for privacy-preserving data analysis. In Proceedings of the 2009 ACM
SIGMOD International Conference on Management of Data, SIGMOD
’09, pages 19–30, New York, NY, USA, 2009. Association for Comput-
ing Machinery.

[36] Ilya Mironov. Rényi differential privacy.

In 30th IEEE Computer
Security Foundations Symposium, CSF 2017, Santa Barbara, CA, USA,
August 21-25, 2017, pages 263–275. IEEE Computer Society, 2017.
[37] Reinhard Munz, Fabienne Eigner, Matteo Maffei, Paul Francis, and
Deepak Garg. Unitrax: Protecting data privacy with discoverable biases.
In Lujo Bauer and Ralf Küsters, editors, Principles of Security and Trust,
pages 278–299, Cham, 2018. Springer International Publishing.
[38] Chaya Nayak. New privacy-protected facebook data for independent

research on social media’s impact on democracy, Feb 2020.

[39] Joseph P Near, David Darais, Chike Abuah, Tim Stevens, Pranav
Gaddamadugu, Lun Wang, Neel Somani, Mu Zhang, Nikhil Sharma,
Alex Shan, et al. Duet: an expressive higher-order language and linear
type system for statically enforcing differential privacy. Proceedings of
the ACM on Programming Languages, 3(OOPSLA):1–30, 2019.
[40] Jason Reed and Benjamin C Pierce. Distance makes the types grow
stronger: a calculus for differential privacy. In Proceedings of the 15th
ACM SIGPLAN international conference on Functional programming,
pages 157–168, 2010.

[41] Ryan M. Rogers, Salil P. Vadhan, Aaron Roth, and Jonathan Ullman.
Privacy odometers and ﬁlters: Pay-as-you-go composition. In Daniel D.
Lee, Masashi Sugiyama, Ulrike von Luxburg, Isabelle Guyon, and
Roman Garnett, editors, Advances in Neural Information Processing
Systems 29: Annual Conference on Neural Information Processing
Systems 2016, December 5-10, 2016, Barcelona, Spain, pages 1921–
1929, 2016.

[42] Andrei Sabelfeld and David Sands. A per model of secure information
ﬂow in sequential programs. In S. Doaitse Swierstra, editor, Program-
ming Languages and Systems, pages 40–58, Berlin, Heidelberg, 1999.
Springer Berlin Heidelberg.

14

[43] T. Sato, G. Barthe, M. Gaboardi, J. Hsu, and S. Katsumata. Approximate
span liftings: Compositional semantics for relaxations of differential
In 2019 34th Annual ACM/IEEE Symposium on Logic in
privacy.
Computer Science (LICS), pages 1–14, June 2019.

[44] J. Vaidya, B. Shaﬁq, A. Basu, and Y. Hong. Differentially private
naive bayes classiﬁcation. In 2013 IEEE/WIC/ACM International Joint
Conferences on Web Intelligence (WI) and Intelligent Agent Technologies
(IAT), volume 1, pages 571–576, 2013.

[45] Yuxin Wang, Zeyu Ding, Daniel Kifer, and Danfeng Zhang. Checkdp:
An automated and integrated approach for proving differential privacy
In Proceedings of the 2020 ACM
or ﬁnding precise counterexamples.
SIGSAC Conference on Computer and Communications Security, pages
919–938, 2020.

[46] Yuxin Wang, Zeyu Ding, Guanhong Wang, Daniel Kifer, and Danfeng
Zhang. Proving differential privacy with shadow execution. In Proceed-
ings of the 40th ACM SIGPLAN Conference on Programming Language
Design and Implementation, pages 655–669, 2019.

[47] Royce J. Wilson, Celia Yuxin Zhang, William Lam, Damien Des-
fontaines, Daniel Simmons-Marengo, and Bryant Gipson. Differentially
private SQL with bounded user contribution. CoRR, abs/1909.01917,
2019.

[48] Royce J Wilson, Celia Yuxing Zhang, William Lam, Damien Des-
fontaines, Daniel Simmons-Marengo, and Bryant Gipson. Differentially
private sql with bounded user contribution. Proceedings on Privacy
Enhancing Technologies, 2020(2), 2020.

[49] Daniel Winograd-Cort, Andreas Haeberlen, Aaron Roth, and Ben-
jamin C. Pierce. A framework for adaptive differential privacy. Proc.
ACM Program. Lang., 1(ICFP):10:1–10:29, 2017.

[50] Dan Zhang, Ryan McKenna, Ios Kotsogiannis, Michael Hay, Ashwin
Machanavajjhala, and Gerome Miklau. Ektelo: A framework for deﬁning
differentially-private computations. In Proceedings of the 2018 Interna-
tional Conference on Management of Data, pages 115–130, 2018.
[51] Danfeng Zhang and Daniel Kifer. Lightdp: towards automating dif-
In Proceedings of the 44th ACM SIGPLAN
ferential privacy proofs.
Symposium on Principles of Programming Languages, pages 888–901,
2017.

[52] Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C Pierce,
and Aaron Roth. Fuzzi: A three-level
logic for differential privacy.
Proceedings of the ACM on Programming Languages, 3(ICFP):1–28,
2019.

[53] Úlfar Erlingsson, Vasyl Pihur, and Aleksandra Korolova. Rappor:
Randomized aggregatable privacy-preserving ordinal response. In Pro-
ceedings of the 21st ACM Conference on Computer and Communications
Security, Scottsdale, Arizona, 2014.

APPENDIX A
LEMMAS, THEOREMS & PROOFS

Lemma A.1
(r1 + r3 ) ∼r

m (r2 + r3 ).

(Plus Respects).

If

r1 ∼r

m r2

Then

Proof. By unfolding deﬁnitions and simple arithmetic.

Lemma A.2
(r1 × r3 ) ∼r3 r

m (r2 × r3 ).

(Times Respects).

If

r1 ∼r

m r2

then

Proof. By unfolding deﬁnitions and simple arithmetic.

Lemma A.3 (Triangle). If r1 ∼rA
r1 ∼rA+rB

mA⊔mB r3 .

mA r2 and r2 ∼rB

mB r3 then

Proof. By unfolding deﬁnitions, simple arithmetic, and the
standard triangle inequality property for real numbers.

Lemma A.4 (Real Metric Weakening). If r1 ∼r mr2 , r ≤ r ′
and m ⊑ m ′ then r1 ∼r ′

m ′ r2 .

Proof. By unfolding deﬁnitions and simple arithmetic.

Lemma A.5 (Step-index Weakening). For n ′ ≤ n:
If ρ1 ∼Σ

then ρ1 ∼Σ

If σ1 ∼Σ

(2):

n ′ ρ2 ;

n σ2

n ρ2

(1):
then

15

n ′ σ2 ; and (3):

σ1 ∼Σ
ρ1 , σ1 , e1 ∼Σ

n ′ ρ2 , σ2 , e2 .

If ρ1 , σ1 , e1 ∼Σ

n ρ2 , σ2 , e2

then

Proof. By mutual induction on n for all three properties, and
additionally case analysis on e1 and e2 for property (3).

Theorem A.6 (Metric Preservation).

n ρ2
n σ2

If: ρ1 ∼Σ
And: σ1 ∼Σ
Then: ρ1 , σ1 , e ∼Σ
That is, either n = 0 or n = n ′ + 1 and. . .

n ρ2 , σ2 , e

(H1)
(H2)

If: n1 ≤ n ′
q
p
σ1 , ey
And: ρ1 ⊢ x
q
p
σ2 , ey
And: ρ2 ⊢ x
Then: n1 = n2
And: σ′
And:

1 ∼Σ
v1 ∼Σ

n ′−n1 σ′
2
v2
n ′−n1

q
p
σ′
1 , v1y
⇓n1 x
q
p
σ′
2 , v2y
⇓n2 x

(H3)

(H4)

(H5)

(C1)
(C2)
(C3)

Proof. See detailed proof later in this section.

Corollary A.6.1 (Sound Dynamic Analysis for Sensitivity).

If: n1 < n, n2 < n and n3 < n (H1)
(H2)

ρ1

q
p
σ, r @Σ
⇓n1 x
my

And: ρ ∼{o7→∞}
n
q
p
∅, ey
And: ρ ⊢ x
And: ρ1 ∼Σ ′
n ρ2
q
p
q
p
∅, ey
σ1 , r1 @Σ1
And: ρ1 ⊢ x
⇓n2 x
m1y
q
p
q
p
∅, ey
σ2 , r2 @Σ2
And: ρ2 ⊢ x
⇓n3 x
m2y
r1 ∼Σ ′
r2
Then:
m1

·Σ

(H3)

(H4)

(H5)

(H6)

(C1)

Proof.

By Metric Preservation, (H2), (H1), (H3) and (H5) we have
Σ1 = Σ and m1 = m.
By Metric Preservation, (H4), (H1), (H5) and (H6) we have
proved the goal (C1).

Proof of Metric Preservation.
By strong induction on n and case analysis on e:
- Case n = 0 : Trivial by deﬁnition.
- Case n = n + 1 and e = x :

By inversion on (H4) and (H5) we have: n1 = n2 = 0 ,
σ′
1 = σ1 , σ′
2 = σ2 , v1 = ρ1 (x ) and v2 = ρ2 (x ). To show:
(C1): 0 = 0 ; (C2): σ1 ∼Σ
n ρ2 (x ).
(C1) is trivial. (C2) is immediate by (H2). (C3) is immediate
by (H1).

n σ2 ; and (C3): ρ1 (x ) ∼Σ

- Case n = n + 1 and e = r:

By inversion on (H4) and (H5) we have n1 = n2 = 0 ,
v1 = v2 = r @Z
1 = σ1 and σ′
disc, σ′
2 = σ2 . To show: (C1):
0 = 0 ; (C2): σ1 ∼Σ
n σ2 ; and (C3): r ∼0
disc r . (C1) is
trivial. (C2) is immediate by (H2). (C3) is immediate by
deﬁnition of relation ∼r

m .

- Case n = n + 1 and e = e1 + e2 :

m11

(H3),

(H2),

(H5.2)

(H4.2)

(H4.1)

(H5.1)

(H4.1)

1 ∼Σ

follows

(F2).
(F2)

(H5.1) we

(IH.1.C3), we

(F1)
follows

(IH.1.C1); σ′

(IH.1.C2);
By

m11 ∼Σ
deﬁnition

and
n−n11 σ′
2
(IH.1.C3).

n−n11 r21 @Σ21
m21
in

By inversion on (H4) and (H5) we have:
q
p
q
p
1 , r11@Σ11
σ′
⇓n11 x
σ1, e1y
ρ1 ⊢ x
m11y
q
p
q
p
1 , r12@Σ12
σ′′
σ′
⇓n12 x
1, e2y
ρ1 ⊢ x
m12y
q
p
q
p
2 , r21@Σ21
σ′
⇓n21 x
σ2, e1y
ρ2 ⊢ x
m21y
q
p
q
p
2 , r22@Σ22
σ′′
σ′
ρ2 ⊢ x
⇓n22 x
2, e2y
m22y
and we also have: n1 = n11 + n12 , n2 = n21 + n22 ,
v1 = (r11 + r12 )@Σ11 +Σ12
2 = σ′′
σ′
1 = σ′′
σ′
and
2 ,
1 ,
m11 ⊔m12
v2 = (r21 + r22 )@Σ21 +Σ22
m21 ⊔m22 . By IH (n = n decreasing),
(H1),
have:
n11 = n21
and
r11 @Σ11
unfolding
have: Σ11 = Σ21
the
(IH.1.C3.1); m11 = m21 (IH.1.C3.2); and r11 ∼Σ ·Σ11
r21
(IH.1.C3.3). Note the following facts: n12 ≤ n − n11
(F1); and ρ1 ∼Σ
from (H3)
n−n11
and n1 = n11 + n12 .
and
Step-index Weakening.1. By IH (n = n − n11 decreasing),
(H4.2) and (H5.2) we have:
(F2),
(IH.1.C2),
1 ∼Σ
n12 = n22 (IH.2.C1); σ′′
2 (IH.2.C2); and
n11 −n12 r22 @Σ22
r12 @Σ12
unfolding
m22
have: Σ12 = Σ22
the
in
(IH.2.C3.1); m12 = m22 (IH.2.C3.2); and r12 ∼Σ ·Σ12
r22
(C1): n11 + n12 = n21 + n22 ;
(IH.2.C3.3). To show:
1 ∼Σ
σ′′
(C3):
(C2):
and
n−n11 −n12 (r21 + r22 )@Σ21 +Σ22
(r11 + r12 )@Σ11 +Σ12
m11 ⊔m12 ∼Σ
m21 ⊔m22 .
from (IH.1.C1)
(IH.2.C1).
(C1)
immediate
from (IH.2.C2). To show (C3)
(C2)
immediate
(C3.1): Σ11 + Σ12 = Σ21 + Σ22 ;
show:
we must
(C3.3):
(C3.2):
(r11 + r12 ) ∼Σ ·(Σ11 +Σ12 )
(r21 + r22 ). (C3.1) is immediate
from (IH.1.C3.1) and (IH.2.C3.1). (C3.2) is immediate
from (IH.1.C3.2)
and (IH.2.C3.2).
as
follows: By Plus Respects, (IH.1.C3.3) and (IH.2.C3.3):
(r21 + r12 ) ∼Σ ·Σ12
(r11 + r12 ) ∼Σ ·Σ11
(r21 + r22 ). By
Triangle: (r11 + r12 ) ∼Σ ·Σ11 +Σ ·Σ12
(r21 + r22 ). By basic
algebra: (r11 + r12 ) ∼Σ ·(Σ11 +Σ12 )
(r21 + r22 ) We have
shown the goal.

m11 ⊔ m12 = m21 ⊔ m22 ;

m12 ∼Σ
deﬁnition

n−n11 −n12 σ′′
2 ;

n−n11 −n12 σ′′

(IH.2.C3). By

(IH.2.C3), we

(C3.3) holds

from (H1)

m11 ⊔m12

m11 ⊔m12

m11 ⊔m12

(F1),

is
is

and

and

m12

m12

m11

- Case n = n + 1 and e = e1 ⋉ e2 :

(H4.2)

(H4.1)

By inversion on (H4) and (H5) we have:
p
1 , r11@Z
σ′
⇓n11 x
p
1 , r12@Z
σ′′
⇓n12 x
p
2 , r21@Σ1
σ′
⇓n21 x
p
2 , r22@Σ2
σ′′
⇓n22 x

q
p
q
σ1, e1y
ρ1 ⊢ x
m11y
q
p
q
σ′
1, e2y
ρ1 ⊢ x
m12y
q
p
q
σ2, e1y
ρ2 ⊢ x
m21y
q
q
p
σ′
ρ2 ⊢ x
2, e2y
m22y
and we also have: n1 = n11 + n12 , n2 = n21 + n22 ,
v1 = (r11 × r12 )@r11 Σ12
σ′
1 = σ′′
and
1 ,
v2 = (r21 × r22 )@r21 Σ22
. By IH (n = n decreasing),
(H1),
have:
1 ∼Σ
n11 = n21
and
r11 @Σ11
m21 (IH.1.C3). By unfolding the

(IH.1.C1); σ′
n−n11 −n12 r21 @Σ21

2 = σ′′
σ′
2 ,
m22

and
n−n11 σ′
2

(H5.1) we

(IH.1.C2);

m11 ∼Σ

(H4.1)

(H5.1)

(H5.2)

(H2),

(H3),

m12

16

m12 ∼Σ

deﬁnition in (IH.1.C3), we have: Σ11 = Σ21 (IH.1.C3.1);
m11 = m21 (IH.1.C3.2); and r11 ∼0
m11 r21 (IH.1.C3.3).
As a consequence of (IH.1.C3), we have: r11 = r21 . Note
the following facts: n12 ≤ n − n11 (F1); and ρ1 ∼Σ
n−n11
(F2). (F1) follows from (H3) and n1 = n11 + n12 . (F2)
follows from (H1) and Step-index Weakening.1. By IH
(n = n − n11 decreasing), (F2), (IH.1.C2), (F1), (H4.2) and
1 ∼Σ
n−n11 −n12 σ′′
(H5.2) we have: n12 = n22 (IH.2.C1); σ′′
2
n11 −n12 r22 @Σ22
(IH.2.C2); and r12 @Σ12
m22 (IH.2.C3). By
unfolding the deﬁnition in (IH.2.C3), we have: Σ12 = Σ22
(IH.2.C3.1); m12 = m22 (IH.2.C3.2); and r12 ∼Σ ·Σ12
r22
(C1): n11 + n12 = n21 + n22 ;
(IH.2.C3.3). To show:
1 ∼Σ
σ′′
(C3):
(C2):
and
m12 ∼Σ
(r11 × r12 )@r11 Σ12
.
(C1) is immediate from (IH.1.C1) and (IH.2.C1). (C2) is
immediate from (IH.2.C2). To show (C3) we must show:
(C3.1): r11 Σ12 = r21 Σ22 ; (C3.2): m12 = m22 ; and (C3.3):
(r11 × r12 ) ∼Σ ·r11 Σ12
(r21 × r22 ). (C3) holds as follows:
(C3.1)
and (IH.2.C3.1).
(C3.2) is immediate from (IH.2.C3.2). (C3.3) holds as
follows: By Times Respects, r11 = r21 and (IH.2.C3.3):
(r11 × r12 ) = (r21 × r12 ) ∼r11 (Σ ·Σ11 )
(r21 × r22 ). By ba-
m21
sic algebra: (r11 × r12 ) = (r21 × r12 ) ∼Σ ·r11 Σ11
We have shown the goal.

n−n11 −n12 (r21 × r22 )@(r21 Σ22 )

is immediate from r11 = r21

n−n11 −n12 σ′′
2 ;

m22

m12

m12

m21

(r21 × r22 ).

- Case n = n + 1 and e = e1 ⋊ e2 : Analogous to previous

case.

- Case n = n + 1 and e = if0(e1 ){e2 }{e3 }:

(H4.1)

(H5.1)
(H1),

p
1, r1@Z
σ′
⇓n11 x
p
2, r2@Z
σ′
⇓n21 x

By inversion on (H4) and (H5) we have 4 subcases, each
which induce:
q
p
q
σ1, e1y
ρ1 ⊢ x
m1y
q
q
p
σ2, e1y
ρ2 ⊢ x
m2y
By IH (n = n decreasing),
(H4.1)
n−n11 σ′
and (H5.1) we have: n11 = n21 (IH.1.C1); σ′
2
(IH.1.C2); and r1 ∼0
m1 ⊓m2 r2 (IH.1.C3). As a consequence
of (IH.1.C3), we have: r1 = r2 . The 4 subcases initially are
for: (1): r1 = 0 and r2 = 0 ; (2): r1 = 0 and r2 6= 0 ; (3):
r1 6= 0 and r2 = 0 ; and (4): r1 6= 0 and r2 6= 0 . However
2 are absurd given r1 = r2 , so these 4 subcases collapse to
2:
- Subcase r1 = r2 = 0 :

(H3),
1 ∼Σ

(H2),

inversion on (H4) and (H5) and fact

From prior
r1 = r2 = 0 , we also have:
q
p
σ′
1, e2y
ρ1 ⊢ x
q
p
σ′
ρ2 ⊢ x
2, e2y
and we also have: n1 = n11 + n12 , n2 = n21 + n22 ,
1 = σ′′
σ′
2 , v1 = v1 and v2 = v2 . We continue
reasoning in a generic way outside this subcase. . .

q
p
σ′′
1 , v1y
⇓n12 x
q
p
σ′′
2 , v2y
⇓n22 x

2 = σ′′

(H4.2)

(H5.2)

1 , σ′

- Subcase r1 6= 0 and r2 6= 0 :

inversion on (H4) and (H5) and fact

From prior
r1 = r2 6= 0 , we also have:
q
p
σ′
1, e3y
ρ1 ⊢ x
q
p
σ′
2, e3y
ρ2 ⊢ x

q
p
σ′′
1 , v1y
⇓n12 x
q
p
σ′′
2 , v2y
⇓n22 x

(H4.2)

(H5.2)

and we also have: n1 = n11 + n12 n2 = n21 + n22
σ′
1 = σ′′
2 v1 = v1 v2 = v2 We continue reason-
ing in a generic way outside this subcase. . .

2 = σ′′

1 σ′

n−n11

(F2)

(F2).

follows

following

(IH.1.C2),

from (H1)

facts:
(F1)

the
ρ1 ∼Σ

n12 ≤ n − n11
follows

(F1);
Note
from (H3)
and
and n1 = n11 + n12 .
and
Step-index Weakening.1. By IH (n = n − n11 decreasing),
(F1),
(H4.2) and (H5.2) we have:
(F2),
1 ∼Σ
σ′′
n21 = n22
(IH.2.C2);
(IH.2.C1);
n−n11 −n21 v2
(C1):
(IH.2.C3). To
and
(C2): σ′′
n11 + n12 = n21 + n22 ;
2 ; and
(C3): v1 ∼Σ
n−n11 −n12 v2 . (C1) is immediate from (IH.1.C1)
and (IH.2.C1). (C2) is immediate from (IH.2.C2). (C3) is
immediate from (IH.2.C3)

show:
n−n11 −n12 σ′′

n−n11 −n21 σ′′
2

v1 ∼Σ

1 ∼Σ

- Case n = n + 1 and e = he1 , e2 i:

(H4.1)

(H5.2)

(H4.2)

(H5.1)

1 , σ′

By inversion on (H4) and (H5) we have:
q
p
σ′
1 , v11y
⇓n11 x
q
p
σ′′
1 , v12y
⇓n12 x
q
p
σ′
2 , v21y
⇓n21 x
q
p
σ′′
⇓n22 x
2 , v22y

q
p
σ1, e1y
ρ1 ⊢ x
q
p
σ′
1, e2y
ρ1 ⊢ x
q
p
σ2, e1y
ρ2 ⊢ x
q
p
σ′
ρ2 ⊢ x
2, e2y
and we also have: n1 = n11 + n12 , n2 = n21 + n22 ,
2 = σ′′
1 = σ′′
σ′
2 , v1 = hv11 , v12 i and v2 = hv21 , v22 i.
By IH (n = n decreasing),
(H4.1)
n−n11 σ′
and (H5.1) we have: n11 = n21 (IH.1.C1); σ′
2
(IH.1.C2); and v11 ∼Σ
n−n11 v21 (IH.1.C3). Note the fol-
lowing facts: n12 ≤ n − n11 (F1); and ρ1 ∼Σ
(F2).
(F1) follows from (H3) and n1 = n11 + n12 . (F2) fol-
from (H1) and Step-index Weakening.1. By IH
lows
(n = n − n11 decreasing), (F2), (IH.1.C2), (F1), (H4.2) and
n−n11 −n12 σ′′
(H5.2) we have: n12 = n22 (IH.2.C1); σ′′
2
(IH.2.C2); and v12 ∼Σ
n−n11 −n12 v22 (IH.2.C3). To show:
n−n11 −n12 σ′′
(C1): n11 + n12 = n21 + n22 ; (C2): σ′′
2 ;
and (C3): hv11 , v12 i ∼Σ
n−n11 −n12 hv21 , v22 i. (C1) is imme-
diate from (IH.1.C1) and (IH.2.C1). (C2) is immediate from
(IH.2.C2). (C3) is immediate from (IH.1.C3) and (IH.2.C3).

(H3),
1 ∼Σ

1 ∼Σ

1 ∼Σ

(H2),

(H1),

n−n11

- Case n = n + 1 and e = πi (e):

By inversion on (H4) and (H5) we have:

(H4.1)

(H5.1)

q
p
σ′
1, hv11, v12iy
⇓n1 x
q
p
σ′
2, hv21, v22iy
⇓n2 x

q
p
σ1, ey
ρ1 ⊢ x
q
p
ρ2 ⊢ x
σ2, ey
2 = σ′
and we also have: n1 = n1 , n2 = n2 , σ′
2 ,
v1 = v1i and v2 = v2i . By IH (n = n decreasing), (H1),
(H2), (H3), (H4.1) and (H5.1) we have: n1 = n2 (IH.1.C1);
2 (IH.1.C2); and hv11 , v12 i ∼Σ
1 ∼Σ
σ′
n−n1 hv21 , v22 i
n−n1 σ′
(IH.1.C3). To show: (C1): n1 = n2 ; (C2): σ′
2 ;
and (C3): v1n ′ ∼Σ
n−n1 v2n ′ .
immediate from
(IH.1.C1). (C2) is immediate from (IH.1.C2). (C3) is im-
mediate from (IH.1.C3).

n−n1 σ′

1 = σ′

1 ∼Σ

1 , σ′

(C1)

is

- Case n = n + 1

(H4) and (H5) we have: n1 = 0 , n2 = 0 , σ′
σ′
2 = σ2 ,
To show:

and e = λx . e: By inversion on
1 = σ1 ,
v2 = hλx . e | ρ2 i.
n σ2 ; and (C3):

v1 = hλx . e | ρ1 i
(C1): 0 = 0 ;

and
(C2): σ1 ∼Σ

17

the

1, σ′

is
holds

(C1)
(C3)

(C2)
follows:
(C3):

n hλx . e | ρ2 i.
from (H2).

hλx . e | ρ1 i ∼Σ
is
immediate
Unfolding

deﬁnition, we must
1 ∼Σ
n′ σ′

trivial.
as
show:
2 ∧ v1 ∼Σ
n′ σ′
n′ v2
2, {x 7→ v2} ⊎ ρ2, e
n ′ σ′
2
(C3.H2). And we must
n ′ σ′
facts:

∀n′ ≤ n, v1, v2, σ′
2. σ′
1, {x 7→ v1} ⊎ ρ1, e ∼Σ
⇒ σ′
To show (C3), we assume: σ′
v1 ∼Σ
1 , {x 7→ v1 } ⊎ ρ1 , e ∼Σ
σ′
and
Note
the
{x 7→ v1 } ⊎ ρ1 ∼Σ
holds
from H1 and Step-index Weakening.1. (F2) holds from
(F1), (C3.H2) and the deﬁnition of ρ ∼Σ
n ′ ρ. (C3.1) then
holds by IH (n = n ′ decreasing), F2 and C3 .H1 .

(C3.H1); and
(C3.1):
show:
2 , {x 7→ v2 } ⊎ ρ2 , e.

n ′ {x 7→ v2 } ⊎ ρ2

(F1);
(F1)

n ′ ρ1
(F2).

following

ρ1 ∼Σ

1 ∼Σ

n ′ v2

.

- Case n = n + 1 and e = e1 (e2 ):

By inversion on (H4) and (H5) we have:

1 | ρ′

q
1iy

2 | ρ′

q
2iy

q
p
σ1 , e1y
ρ1 ⊢ x
q
p
σ′
1 , e2y
ρ1 ⊢ x
q
p
2 , e′
σ′′
1 ⊢ x
1y
q
p
σ2 , e1y
ρ2 ⊢ x
q
p
σ′
2 , e2y
ρ2 ⊢ x
q
p
2 , e′
σ′′
2 ⊢ x
2y

p
1 , hλx. e′
σ′
⇓n11 x
q
p
σ′′
1 , v1y
⇓n12 x
q
p
1 , v′
σ′′′
⇓n13 x
1y
p
2 , hλx. e′
σ′
⇓n21 x
q
p
σ′′
2 , v2y
⇓n22 x
q
p
2 , v′
σ′′′
⇓n23 x
2y

(H4.1)

(H4.2)

(H4.3)

(H5.1)

(H5.2)

(H5.3)

{x 7→ v1} ⊎ ρ′

{x 7→ v2} ⊎ ρ′

we

the

n−n11

(F1),

have:

1 , σ′

1 ∼Σ

n1 = n11 + n12 + n13 + 1 ,
and
also
2 , v1 = v ′
2 = σ′′′
1 = σ′′′
n2 = n21 + n22 + n23 + 1 , σ′
1
and v2 = v ′
2 . By IH (n = n decreasing),
(H2),
(H1),
(H3), (H4.1) and (H5.1) we have: n11 = n21 (IH.1.C1);
1 ∼Σ
n−n11 σ′
σ′
(IH.1.C2); and hλx . e′
1 | ρ′
n−n11 v21
2
following facts: n12 ≤ n − n11
(IH.1.C3). Note
(F1); and ρ1 ∼Σ
(F2). (F1) follows from (H3) and
n1 = n11 + n12 + n13 + 1 . (F2) follows from (H1) and
Step-index Weakening.1. By IH (n = n − n11 decreasing),
(H4.2) and (H5.2) we have:
(H2),
(IH.1.C2),
1 ∼Σ
n12 = n22 (IH.2.C1); σ′′
2 (IH.2.C2); and
v1 ∼Σ
n−n11 −n12 v2 (IH.2.C3). Note the following facts, each
of which follow from (H3) and n1 = n11 + n12 + n13 + 1 :
n13 ≤ n − n11 − n12 (F3); and n − n11 − n12 − n13 > 0
(F4). Also note
following facts which follow
(F3) and (F4):
from (IH.1.C3),
n13 = n23 (F4.C1); σ′′′
(F4.C2);
n−n11 −n12 −n13 −1 v ′
and
show:
2
n11 + n12 + n13 + 1 = n21 + n22 + n23 + 1 ;
(C1):
1 ∼Σ
σ′′′
(C3):
(C2):
1 ∼Σ
n−n11 −n12 −n13 −1 v ′
v ′
from
2 .
(IH.1.C1), (IH.2.C1) and (F4.C1). (C2) is immediate from
(F4.C2) and Step-index Weakening.2. (C3) is immediate
from (F4.C3) and Step-index Weakening.3.

n−n11 −n12 −n13 −1 σ′′′
2
(F4.C3).
To

n−n11 −n12 −n13 −1 σ′′′
2 ;
is

(IH.2.C2),
1 ∼Σ

and
immediate

n−n11 −n12 σ′′

(IH.2.C3),

1 ∼σ
v ′

(C1)

the

- Case n = n + 1 and e = ref(e):

By inversion on (H4) and (H5) we have:

q
p
σ1, ey
ρ1 ⊢ x

q
p
σ′
1, v1y
⇓n1 x
ℓ1 = alloc(dom(σ′
q
p
σ2, ey
ρ2 ⊢ x

(H4.1)
1))(H4.2)

(H5.1)
2))(H4.2)

q
p
σ′
2, v2y
⇓n2 x
ℓ2 = alloc(dom(σ′
n2 = n2 ,
n1 = n1 ,
have:
and
also
we
2 = {ℓ 7→ v2 } ⊎ σ′
σ′
1 = {ℓ 7→ v1 } ⊎ σ′
σ′
v1 = ℓ1
2 ,
1 ,
and v2 = ℓ2 . By IH (n = n decreasing),
(H2),
(H3), (H4.1) and (H5.1) we have: n1 = n2 (IH.1.C1);
(IH.1.C2); and v1 ∼Σ
1 ∼Σ
n−n1 σ′
σ′
(IH.1.C3).
2
Because σ1 ∼Σ
n−n1 σ′
2 , we know dom(σ1 ) = dom(σ2 )
(C1): n1 = n2 ;
and
therefore
(C2): {ℓ 7→ v1 } ⊎ σ′
2 ; and (C3):
ℓ1 ∼Σ
n−n1 ℓ2 . (C1) is immediate from (IH.1.C1). (C2) is
immediate from (IH.1.C2), (IH.1.C3) and the deﬁnition of
σ ∼Σ
n σ. (C3) is immediate by deﬁnition of v ∼Σ
n v and
ℓ1 = ℓ2 .

ℓ1 = ℓ2 . To
1 ∼Σ

n−n1 {ℓ 7→ v2 } ⊎ σ′

n−n1 v2

show:

(H1),

- Case n = n + 1 and e = !e:

By inversion on (H4) and (H5) we have:

(H4.1)

(H5.1)

1 (ℓ1 ) and v2 = σ′

q
p
q
p
σ′
1, ℓ1y
⇓n1 x
σ1, ey
ρ1 ⊢ x
q
p
q
p
σ′
ρ2 ⊢ x
2, ℓ2y
⇓n2 x
σ2, ey
2 = σ′
and we also have: n1 = n1 , n2 = n2 , σ′
2 ,
v1 = σ′
2 (ℓ2 ). By IH (n = n decreasing),
(H1), (H2), (H3), (H4.1) and (H5.1) we have: n1 = n2
(IH.1.C1); σ′
n−n1 ℓ2
(IH.1.C3). Because ℓ1 ∼Σ
n−n1 ℓ2 , we know ℓ1 = ℓ2 by
deﬁnition of v ∼Σ
n v . To show:
(C2):
1 (ℓ1 ) ∼Σ
1 ∼Σ
n−n1 σ′
σ′
2 (ℓ2 ). (C1) is im-
mediate from (IH.1.C1). (C2) is immediate from (IH.1.C2).
(C3) is immediate from (IH.1.C2) and ℓ1 = ℓ2 .

(IH.1.C2); and ℓ1 ∼Σ

2 ; and (C3): σ′

(C1): n1 = n2 ;

n−n1 σ′
2

n−n1 σ′

1 = σ′

1 ∼Σ

1 , σ′

- Case n = n + 1 and e = e1 ← e2 :

(H5.2)

(H4.1)

(H4.2)

(H5.1)

By inversion on (H4) and (H5) we have:
q
p
σ′
⇓n11 x
1 , ℓ1y
q
p
σ′′
1 , ℓ2y
⇓n12 x
q
p
σ′
2 , v1y
⇓n21 x
q
p
σ′′
2 , v2y
⇓n22 x

q
p
σ1, e1y
ρ1 ⊢ x
q
p
σ′
1, e2y
ρ1 ⊢ x
q
p
σ2, e1y
ρ2 ⊢ x
q
p
σ′
2, e2y
ρ2 ⊢ x
and we also have: n1 = n11 + n12 , n2 = n21 + n22 ,
σ′
2 = σ′′
1 , σ′
1 = σ′′
and v2 = v2 . By IH
v1 = v1
2 ,
(n = n decreasing),
(H1),
and
n−n11 σ′
(H5.1) we have: n11 = n21
2
(IH.1.C2);
Because
and
ℓ1 ∼Σ
n−n11 ℓ2 we know ℓ1 = ℓ2 . Note the following
(F2).
facts:
and n1 = n11 + n12 .
(F2)
(F1)
and Step-index Weakening.1. By
follows
IH (n = n − n11
(F1),
decreasing),
and (H5.2) we have: n12 = n22
(H4.2)
(IH.2.C1);
1 ∼Σ
v1 ∼Σ
σ′′
n−n11 −n12 v2
(IH.2.C2);
(C1): n11 + n12 = n21 + n22 ;
(IH.2.C3). To
(C2):
(C3):
v1 ∼Σ
n−n11 −n12 v2 . (C1) is immediate from (IH.1.C1) and

n−n11 −n12 σ′′
2
show:
1 [ℓ 7→ v1 ] ∼Σ
σ′′

(H2),
(IH.1.C1); σ′
(IH.1.C3).

n−n11 −n12 σ′′

(H4.1)
1 ∼Σ

n12 ≤ n − n11

2 [ℓ 7→ v2 ];

from (H1)

from (H3)

(IH.1.C2),

n−n11 ℓ2

ρ1 ∼Σ

ℓ1 ∼Σ

follows

(H3),

(F1);

(F2),

n−n11

and

and

and

18

(IH.2.C1). (C2) is immediate from (IH.2.C2) and (IH.2.C3).
(C3) is immediate from (IH.2.C3).

APPENDIX B
ADDITIONAL CASE STUDIES

A. MWEM with Pandas

The MWEM algorithm [29] constructs a differentially pri-
vate synthetic dataset that approximates a real dataset. MWEM
produces competitive privacy bounds by utilizing a combina-
tion of the exponential mechanism, Laplacian/Gaussian noise,
and the multiplicative weights update rule. The algorithm uses
these mechanisms iteratively, providing a tight analysis of
privacy leakage via composition.

The inputs to the MWEM are as follows: some uniform
or random distribution over a domain (syn_data), some
sensitive dataset (age_counts), a query workload, a number
of iterations i, and a privacy budget ǫ.

The algorithm works by, at each iteration:
• privately selecting a query from the query workload
(using the exponential mechanism) whose result on the
synthetic dataset greatly differs from the real dataset

for t in range(i):

q = exponential(q_workload,score_fn,eps/(2*i))
...

• and then privately using the query result on the real
dataset to adjust the synthetic dataset towards the truth
using the multiplicative weights update rule

for t in range(i):

...
syn_data = mwem_step(q, age_counts, syn_data)

We present a modiﬁed, adaptive MWEM algorithm (Fig-
ure 5) which privately halts execution if the error of the
synthetic dataset reaches an acceptably low level before the
entire privacy budget is exceeded, conserving the remainder
of the budget for other private analyses.

B. DiffPrivLib

DiffPrivLib is library for experimenting with analytics and
machine learning with differential privacy in Python by IBM.
It provides a comprehensive suite of differentially private
mechanisms, tools, and machine learning models.

While DiffPrivLib provides several mechanisms, models
and tools for developing private applications, as well as a
basic privacy accountant, it lacks the ability to perform a tight
privacy analysis in the context of more sophisticated forms of
composition with dynamic and adaptive privacy tracking. Via
integration with DDUO we are able to gain these abilities with
minimal changes to library and program code.

Figure 6 shows an example of a modiﬁed DiffPrivLib
program: a private naive Bayes classiﬁer run on the standard
iris dataset. The original program has been modiﬁed with
DDUO hooks to detect sensitivity violations and track privacy
cost.

def mwem_step(query, real_data, syn_data):

lower, upper = query
sm = [v for k, v in syn_data.items()]
total = np.sum(sm)
q_ans = range_query(real_data, lower, upper)
real = dduo.renyi_gauss(α=alpha,ǫ=eps,q_ans,sens)
syn = range_query(syn_data, lower, upper)
l = [(k, mwem_update(k, x, lower, upper,

real, syn, total))

for k, x in syn_data.items()]

return dict(l)

with dduo.RenyiFilter(alpha,20.0):

with dduo.RenyiOdometer((alpha,2.0)) as odo:

while stable < stability_thresh:
e = err(age_counts,curr_syn)
curr_noisy_err=dduo.renyi_gauss(α=alpha,ǫ=1.0,e)
if (curr_noisy_err < thresh):

stable += step

else:

stable = 0

for t in range(iterations):

q = exponential(q_workload,score_fn,eps/(2*i))
curr_syn = mwem_step(q,age_counts,curr_syn)

acc = dduo.renyi_gauss(alpha, eps_acc,

accuracy(age_counts,curr_syn))

print(f"final accuracy: {acc}")

Odometer_(α, ǫ)({data.csv 7→ (10.0, 0.5)})
final accuracy: 0.703

Fig. 5. MWEM with Pandas

from dduo import sklearn as sk
from dduo import DiffPrivLib as dpl
with dduo.AdvEdOdometer() as odo:

while noisy_acc < thresh or iters < max_iters:

prev_bounds = bounds
bounds = update_bounds(bounds)
clf = dpl.GNB(bounds=bounds, epsilon=epsilon)
clf.fit(X_train, y_train)
prev_acc = noisy_acc
accuracy = dpl.score(y_test, clf.predict(X_test))
noisy_acc = dduo.gauss(epsilon_acc,delta,accuracy)
if noisy_acc < prev_acc:
bounds = prev_bounds

iters += 1

dduo.print_privacy_cost()

Odometer_(ǫ, δ)({data.csv 7→ (0.82, 0.0035)})

Fig. 6. DiffPrivLib: Naive Bayes Classiﬁcation

We also present a DDUO instrumented example of differen-

tially private logistic regression with DiffPrivLib (Figure 7).
Both of these programs have been modiﬁed to perform
adaptively private clipping. Over several iterations, clipping
parameters are gradually modiﬁed to optimize model accu-
racy. This form of control ﬂow on probabilistic values is
only sound following the adaptive composition strategies that
DDUO provides. In order to preserve the privacy budget, such
hyperparameter optimization procedures should normally be
run on artiﬁcial datasets based on domain knowledge.

The changes required for the integration with the Diff-
PrivLib library consist of 15 lines of DDUO instrumentation
code.

19

from dduo import sklearn as sk
from dduo import DiffPrivLib as dpl
with dduo.AdvEdOdometer() as odo:

while noisy_acc < thresh or norm > 0.0:

dp_clf = dpl.LogisticRegression(epsilon=epsilon,

data_norm = norm)

dp_clf.fit(X_train, y_train)
accuracy = dp_clf.score(X_test, y_test)
noisy_acc = dduo.gauss(epsilon_acc,delta,accuracy)
norm -= step

dduo.print_privacy_cost()

Odometer_(ǫ, δ)({data.csv 7→ (0.53, 0.0015)})

Fig. 7. DiffPrivLib: Logistic Regression

