0
2
0
2

n
a
J

3
2

]

G
L
.
s
c
[

1
v
6
5
0
0
1
.
1
0
0
2
:
v
i
X
r
a

Explainable Machine Learning Control - robust control
and stability analysis

Markus Quade

Ambrosys GmbH, David-Gilly Straße 1, 14469 Potsdam, Germany

Thomas Isele

4Cast GmbH & Co. KG, Parkstraße 1, 14469 Potsdam, Germany

Markus Abel∗

Ambrosys GmbH, David-Gilly Straße 1, 14469 Potsdam, Germany

4Cast GmbH & Co. KG, Parkstraße 1, 14469 Potsdam, Germany

Universit¨at Potsdam, Institut f¨ur Physik und Astronomie, Karl-Liebknecht-Straße 24/25,
14476 Potsdam, Germany

Abstract

Recently, the term explainable AI became known as an approach to produce
models from artiﬁcial intelligence which allow interpretation. Since a long time,
there are models of symbolic regression in use that are perfectly explainable
and mathematically tractable: in this contribution we demonstrate how to use
symbolic regression methods to infer the optimal control of a dynamical system
given one or several optimization criteria, or cost functions. In previous publi-
cations, network control was achieved by automatized machine learning control
using genetic programming. Here, we focus on the subsequent analysis of the
analytical expressions which result from the machine learning. In particular, we
use AUTO to analyze the stability properties of the controlled oscillator system
which served as our model. As a result, we show that there is a considerable
advantage of explainable models over less accessible neural networks.

Keywords: Explainable AI, Machine Learning Control, Dynamical systems,
Synchronization Control, Genetic programming

1. Introduction

Machine learning and artiﬁcial intelligence have recently rediscovered so-
called explainable methods [1]. Whereas this sounds appealing, researchers

∗Corresponding author
Email address: markus.abel@ambrosys.de (Markus Abel)

Preprint submitted to Physica D

January 29, 2020

 
 
 
 
 
 
agree that explainability and interpretability is neither a new concept nor new
in artiﬁcial intelligence or machine learning. The wish for it arose in recent
years with the understanding that the very successful methods of deep learn-
ing with neural networks are not directly interpretable. On the other hand,
symbolic regression methods are not so new but very explainable, in particular
genetic programming methods are extremely general, but their convergence and
solutions are not as performant as are neural network methods. Generalized
regression methods, on the other hand are very performant, but not so ﬂexible.
Here, we demonstrate the power such models reveal by extending a previous
analysis of network machine learning control by a subsequent stability analysis.
As an example for the control of dynamical systems in physics [2, 3] or
medicine [4, 5] we chose the control of synchronization. Synchronization is a
widespread phenomenon observed in many natural and engineered complex sys-
tems whereby locally interacting components of a complex system tend to coor-
dinate and exhibit collective behavior [6, 7]. In [8] synchronization in networks
is investigated by multiple weakly coupled independent oscillating systems; the
control then inﬂuences the overall dynamics of the system. The role control
is to drive the system into or out of synchronization by applying an external
control signal [6] that in turn depends on the state itself. The realization of this
technique resembles reinforcement learning and diﬀerences and similarities are
discussed elsewhere. There are signiﬁcant implications for numerous domains
in engineering and science, including communications [9], teleoperations [10, 11]
and brain modeling [12]. The special topic, especially phase oscillators, is re-
viewed in [13]. Depending on the system, control may be those based on control
theory [14], mathematical and numerical optimization [15] and computational
intelligence [16] techniques. The “optimal control” methods [17] aim at driv-
ing and maintaining a dynamical system in a desired state. This is typically
achieved by ﬁnding a control law, in the form of a set of diﬀerential equations,
which optimizes (by maximizing or minimizing) a cost function related to the
control task. If the control is useful is decided heavily by the stability of the
controlled system.

This stability can be determined by standard mathematical methods for
linear theory can be used [18, 19]. However, for nonlinear, extended and con-
sequently complex systems, linear theory to determine a control may fail. In
such cases, the more general methods used here can be of use, where analytical
expressions are determined in a deterministic or evolutionary way. I.e. control
laws are inferred from an arbitrary domainusing evolutionary machine learning
methods as a suitable source of algorithms. Speciﬁcally, we refer to genetic pro-
gramming (GP) [20] to control synchronization in coupled networks, including
a hierarchical network of coupled oscillators. Unlike neural networks and other
black-box artiﬁcial intelligence methods, GP allows dynamically learning com-
plex control laws in an interpretable symbolic form — a method that is referred
as symbolic regression [21, 22, 23]. In particular, we focus on the subsequent
rigorous analysis of the optimal laws found. In contrast to previous works a full
expression is optimized, and not only parameters [11, 24].

Based on the previous results, we demonstrate the eﬀectiveness of the con-

2

trol and rigorous analysis exemplary by the analysis of control solutions for two
oscillators found by symbolic regression to synchronize or de-synchronize the os-
cillators. Further application to the control of entire networks is straightforward
and is to be included in the future in the fully automatized software framework
Glyph [25]. The motivation is not only motivated by brain disorder problems
in the medical domain like body tremors occur when ﬁring neurons synchronize
in regions of brain [4], but may ﬁnd broad application in any control setup, e.g.
in machinery [26]. In the case of brain states, if the ﬁring of neurons is periodic,
which may appear due to the inherent dynamics of the excitable neurons, a
mutual inﬂuence may give rise to synchronization [6, 27]. If the coupling term
is very large, this synchronization may extend over a whole region in our brain
and thus over many neurons. Eventually this collective ﬁring leads to shaky
movements of hands, arms or the head, and is treated as a brain disorder. One
remedy to this problem is to implant a control device which resets the neurons
and counteracts the collective synchronization. An evident question then is how
to design such a controller which also minimizes design cost, energy consump-
tion, or other medical constraints but is as stable and reliable as possible. We
analyze the found control technically by the well-known package AUTO [28].

To the best of our knowledge, this is the is ﬁrst demonstration of machine
learning control followed by automatized stability analysis. The extension and
generalization is straightforward subject of an extension of existing software. GP
is used to learn a control that brings a network of self-sustained oscillators in a
desired, synchronized or de-synchronized state and back. In Sec. 3, the results
of our study of GP application to networked dynamic systems is presented with
focus on the stability analysis.

This publication is structured as follows:

in Sec. 2 we recall the methods
used and previous insights, in Sec. 3 we reiterate results for machine learning
control and discuss in great detail the stability analysis and thereby robustness
of control for an exemplary control term, the publication ends with a discussion
and conclusion in Sec. 4. In the appendix we provide details on the parameters
used for system integration and GP setup.

2. Methods

In this section, we brieﬂy recall the concept of MLC (machine learning con-
trol) and the method used here to solve the problem.To control a dynamical
system, one determines a manipulation of the trajectory of the system in phase
space to drive it to and keep it in a desired state. This control problem is typi-
cally formulated as an optimization problem with an objective function that is
to be minimized. In the control setup, this objective is formulated as the devi-
ation of the state of the system from its desired one. Consequently, an optimal
control problem is formulated as a mathematical model of the system, a cost
function or performance index, a speciﬁcation of boundary conditions on states,
and additional constraints. According to the type of problem, it is classiﬁed
roughly according to Fig. 1

3

2.1. Machine Learning Control

Figure 1: An overview of diﬀerent types of optimal control.

Here, we focus on continuous-time optimal control.

If there are no con-
straints on the states or the control variables, and if the initial and ﬁnal condi-
tions are ﬁxed, it reads: Find the control vector (cid:126)u : Rnx
Rnu that
minimizes the cost function

[ts, tf ]

(cid:55)→

×

subject to

Γ = ϕ((cid:126)x(tf )) +

(cid:90) tf

ts

L((cid:126)x(t), (cid:126)u((cid:126)x, t), t)dt,

˙(cid:126)x =

(cid:126)˜f ((cid:126)x, (cid:126)u, t), (cid:126)x(ts) = (cid:126)xs,

(1)

(2)

R is a terminal cost function; L:Rnx

Rnx is the state vector;
where [ts, tf ] is the time interval of interest; (cid:126)x:[ts, tf ]
Rnu
ϕ : Rnx
R is an intermediate
(cid:55)→
Rnx is a vector ﬁeld. Eq. (2) represents
cost function; and
(cid:55)→
the dynamics of the system and its initial state. This problem deﬁnition is
known as the Bolza problem; which for ϕ(x(tf )) = 0 and (cid:126)u = ˙(cid:126)x(t) it is known
as the Lagrange problem [29]. The cost function (or performance index) Γ is a
functional, which assigns a real value to each control function (cid:126)u.

(cid:126)˜f : Rnx

(cid:55)→
R
×

Rnu

(cid:55)→

×

×

×

R

Often, the solution to a control problems cannot be found by analytical
means. Then, computational methods are used to solve such problems. De-
pending on the types of cost functions, time domain, and constraints in Eqs.
(1)-(2) diﬀerent methods may be applied, cf. Fig. 1. The direct methods use
a discretization of the control problem and solve it using nonlinear program-
ming approaches. Other methods involve the discretization of the diﬀeren-
tial equations by deﬁning a grid of N points covering the time interval [ts, tf ],
ts = t1 < t2 < . . . < tN = tf , and solving these equations using suitable
numerical methods [30]. Thereby, the diﬀerential equations become equality
constraints of the nonlinear programming problem. Other direct methods in-
volve the approximation of control and states using basis functions, such as
splines or Lagrange polynomials.

Dynamic programming is an alternative to the variational approach to op-
timal control.
It was proposed by Bellman in the 1950s and is an extension
of Hamilton–Jacobi theory. A number of books exist on these topics including

4

OptimalControlContinuoustimeoptimalcontrolComputationaloptimalcontrolDynamicpro-grammingDiscretetimeoptimalcontrol[31, 18, 32]. A general overview of the optimal control methods for dynamical
systems can be found in [17]. For further details, see [33].

Our approach to solve a control problem uses machine learning to determine
the optimal control. Therefore, we adopt the continuous-time formulation given
in Eqs. (1) and (2). For multi-objective optimization, the reader is referred
to [8]. In real-worl problems, often the derivatives are not given and one has to
reconstruct them; then it is particularly important to respect the accuracy of
measured data as described in [34]. For the particular control scheme considered

here,

(cid:126)˜f and (cid:126)u are slightly reformulated, as will be described next.

Similar to reinforcement learning, a feedback control scheme [35] is used here
to implement the control. In Fig. 2 the architecture is depicted. To follow this
scheme, we rewrite Eq. (2):

˙(cid:126)x = (cid:126)f ((cid:126)x, t) + (cid:126)a, (cid:126)x(ts) = (cid:126)xs,

such that the uncontrolled system ˙(cid:126)x = (cid:126)f ((cid:126)x, t) is controlled by an additive ac-
tuator term (cid:126)a, and the control function (cid:126)u depends on sensor measurements
(cid:126)s

Rns:

∈

(cid:126)a = (cid:126)u((cid:126)s, t).

These measurements might be nonlinear functions of the state (cid:126)x. For simplicity,
external perturbations to the dynamic system are not considered here.

Figure 2: Sketch of the feedback control loop. The output of the dynamical system (cid:126)x is mea-
sured by sensors (cid:126)s which are used as input to the control function (cid:126)u. The control function, in
turn, acts on the system via actuators (cid:126)a = (cid:126)u((cid:126)s, t) in order to achieve a desired state. (Exter-
nal disturbances which can be incorporated explicitly as additional inputs to the dynamical
system and the control function are not shown here.)

2.2. Genetic Programming

To obtain a solution for the control, we use the fairly general genetic pro-
gramming (GP). This choice is motivated by its generality: in contrast to, e.g.,
generalized linear regression, no additive structure is needed as used already 20

5

˙x=f(x)+au(s,t)sayears ago in [36, 37]. GP [20, 38] is an evolutionary algorithm for global opti-
mization. Similar to a genetic algorithm (GA), GP uses the natural selection
metaphor to evolve a set of solutions using a cost-based selection mechanism.
Often the bio-inspired terms population and individual are used correspondingly.
The evolution occurs over a number of iterations (generations). GP diﬀers from
GA mainly in the representation of a solution: In GP, it is generally repre-
sented using lists or expression trees. Expression trees are constructed from the
elements of two predeﬁned primitive sets: a function set consisting of mathe-
, and a terminal
matical operators and functions, such as
+, -, *, cos, sin
}
{
set consisting of variables and constants, such as
. Function sym-
x, y, b
}
bols represent the internal nodes of a tree; and terminal symbols are used in
the leaf nodes. For example, 3 shows the tree representation for the expression
x + cos(y). All elements of the tree are drawn from the aforementioned prim-
b
itive sets: the variables and constants in the terminal set (x, y, and b) form the
leaves of the tree and the mathematical symbols in the functional set (
, +, and
·
cos) are used in forming the tree’s internal nodes.

{

·

Figure 3: Tree representation of the mathematical expression b · x + cos(y). The symbols b,
x, and y are taken from the terminal set and make up the leaf nodes of the tree, whereas the
symbols *, +, and cos, are symbols taken from the function set, they make up the internal
nodes.

Algorithm 1 Top level description of a GP algorithm

procedure main

random(λ)

1

←

G0
evaluate(G0)
t
←
repeat
Ot
evaluate(Ot)
Gt
t

t + 1

←

←

breed(Gt−1, λ)

select(Ot, Gt−1, µ)

←

until t > T or Gt = good()

end procedure

The GP algorithm is described below ( 1): it starts with the initial gener-
ation of a population of random solutions G0. A random solution is generated
with a set maximum tree depth by choosing randomly operators, functions and

6

+*bxcosyvariables. Each solution is then evaluated using the cost function that belongs
to the problem. This cost is assigned to each solution, typically how closely a
solution predicted the target function output. A new population of solutions
Ot is then generated by: (i) probabilistic selection of parent solutions from the
existing population using a cost-proportional selection mechanism, and (ii) cre-
ation of oﬀsprings by recombination (or crossover) and variation (or mutation)
operators (see 4). This procedure is repeated until the cost is reasonably low
(the exact deﬁnition of low depends on the problem) or a certain preset num-
ber of solutions (a ﬁxed population size) is reached. The validity of generated
solutions is ensured by a closure property, both for the initialization and breed-
ing operations. Often, convergence is sped-up choosing a reproduction of the
best N solutions (elitist approach), then these best solutions are copied to the
next-generation population Gt+1. The selection, evaluation and reproduction
processes are repeated until one of the above criteria is met. For further details
about GP operation, see [39, 40].

Figure 4: Breeding: Mutation and crossover operations on expression trees. Source: Adapted
from [23]; used with permission.

To solve a general control problem with GP, it is formulated as a learning
and optimization task. That is, we learn a control function using GP which
drives and keeps a dynamical system in a desired state. The typical choice
for the cost function ((cid:126)Γ) is the diﬀerence between a given state in time and
the desired state. This function (cid:126)Γ can possess complex properties, like non-
linearity, multi-modality, multi-variability and discontinuity. Many traditional
direct and gradient methods can not handle such properties, however, meta-
heuristic methods, such as GP, are suitable candidates for this task. In Fig. 5 a
GP-based dynamic controller within a feedback control loop is sketched, shown
in 2.

7

exp+asinxexp+sinx+xyexp+asinx+cos*yxbexp+a*xb+cossinyxMutationCrossoverFigure 5: Sketch of the machine learning loop. By its evolutionary strategy, the GP algorithm
generates a set of candidate control solutions (cid:126)u, called the population. The candidate solutions
are then evaluated in many realizations of the control loop; the performance in each iteration
is rated via a cost functional Γ and fed back as a cost index into the GP algorithm. The
performance rating is used to select the best solutions and to evolve them into the next
generation of candidate solutions. This learning loop repeats until at least one satisfactory
control law is found (or other break conditions are met).

The treatment of multiobjectivity and constant optimization is explained
in [8] and will not be touched here. Rather we focus on the analysis of the
analytical expressions resulting from our control optimization. To reproduce
the results shown below, we have given the concrete setup for GP used here in
the appendix 5.

3. Results

In this section, we explain the concrete application we use to illustrate the
power of our explainable GP: in a previous publication, GP-based control has
been used for the control of networks of oscillators [8]. Such networks are used
to model highly nonlinear complex systems, including the human brain. For our
purposes, we systematically investigate the results of our method starting using
two coupled oscillators. The extension to many oscillators is straightforward
and subject of ongoing implementation activities to include a stability analysis
automatically into Glyph [41].

The aim, of our consideration is to control the synchronization behavior
of the coupled oscillators. This can be done in two ways: starting from a
synchronization regime and forcing the system into de-synchronization or vice
versa, i.e., starting from a de-synchronized regime and forcing the system into
synchronization. Both control goals are evaluated in [8]. Here, we focus on
synchronization control, since we mainly want to demonstrate the power of
symbolic regression methods as explainable, rigorously treatable models and
control terms, respectively.

Let us ﬁrst and brieﬂy discuss synchronization again. The synchronization of
dynamical systems is well-known exhibited by a huge variety of oscillators and

8

˙x=f(x)+au(s,t)saGPΓFigure 6: Single van der Pol oscillator (with parameters ω = e2, α = 3, and initial conditions
x(0) = −0.25, ˙x(0) = 2.5.)

oscillatory media [6]. Here, we use a popular model, the van der Pol oscillator,
also used as a simple model for neurons:

¨x =

ω2x + α ˙x (cid:0)1

βx2(cid:1) =: fvdP(x, ˙x),

(3)

−

−
where x is the state and ω, α, β > 0 are model parameters. The parameter ω
is the frequency at which the system oscillates without any driving or damping
force. The parameter α controls the non-linearity of the system:
if α = 0,
Eq. (3) is a harmonic oscillator equation. The damping parameter β controls
the nonlinear deformation of the trajectory in phase space. See Fig. 6. In our
setup, we reproduce the results of [8] and use linear coupling. An uncontrolled
system of N coupled van der Pol oscillators can be stated as follows:

¨xi = fvdP(xi, ˙xi) + c1

N −1
(cid:88)

j=0

κijxj + c2

N −1
(cid:88)

j=0

εij ˙xj

(i = 0, . . . , N

1)

−

(4)

with initial conditions

xi(t0) = xi,0,

˙xi(t0) = ˙xi,0,

where c1,2 are the global coupling constants and (κij) and (εij) are the respective
coupling matrices. This allows for several types of coupling such as direct,
diﬀusive, and global coupling, or any other kind of network-like coupling. In
the following experiments, we will use diﬀusive coupling in ˙xi. For GP, we use
the same setup described above (Sec. 5).

9

0123456−3−2−10123x0123456periods−8−6−4−202468˙x−3−2−10123x−8−6−4−202468˙xβ=1β=3β=91
−
1

1
1

−

3.1. Two Coupled Oscillators

For our further investigations we use the simplest system showing synchro-

nization: two diﬀusively coupled van der Pol oscillators:

¨x0 = fvdP(x0, ˙x0) + c ( ˙x1
¨x1 = fvdP(x1, ˙x1) + c ( ˙x0

˙x0) ,
˙x1) .

−

−

(5)

The coupling is restricted to ˙xi, in which case the coupling constants from (4)
are set to c1 = 0, c2 = c, and the remaining coupling matrix reads (εij) =
(cid:20)

(cid:21)

. In the case of zero coupling, c = 0, some parameter combinations

(α, β) allow stable limit cycles with characteristic frequencies ω0,1. If the cou-
= ω1 exists, where both
pling constant c
oscillators oscillate with exactly the same frequency Ω in a common mode. This
range of frequencies is called the synchronization region. With variation of the
coupling constant this region changes in width.

= 0, a range of frequencies with ω0

For an illustration, we chose quite arbitrary α = 0.1, β = 1, with ω0 =
1.386. The harmonic frequency ω1 of the second oscillator is varied in the range
[ω0
0.06, ω0 + 0.06]. By the above explanation, one expects a range where
both oscillators have a common, observed frequency Ω0 = Ω1 = Ω, such that
∆Ω = Ω1
= 0. This frequency Ω is determined
numerically by Fourier transform.

Ω0 = 0, and a range with ∆Ω

−

−

−

For a visualization, ∆Ω, is plotted against the diﬀerence in their charac-
teristic frequencies, ∆ω := ω1
ω0, cf. Fig. 7. Regions of synchronization
show up as horizontal segments at ∆Ω = 0 (also, note the symmetry about
∆ω = 0). If we do this for several values c in the range [0, 0.4] we can trace
out the regions of synchronization: The result is a typical V-shaped plateau,
the Arnold tongue. Reading oﬀ suitable parameters from Fig. Fig. 7 allows to
choose appropriate parameters ω1 and c to setup the system for control, such
that, in its uncontrolled state, it follows either the synchronization regime or the
de-synchronization regime. This same approach is taken for all the experiments
presented in this section, but will not be explicitly stated beyond this point.
We show results only for a control of the state into synchronization, the desyn-
chronization way works very similar, however the tracing of the stability of the
solution becomes more tedious, because the solution is generically quasiperiodic
and no longer periodic (if the two frequencies ω0, ω1 are incommensurate).

Let us add the control function, u, to the equations (5) of the uncontrolled

system:

¨x0 = fvdP(x0, ˙x0) + c ( ˙x1

¨x1 = fvdP(x1, ˙x1) + c ( ˙x0

˙x0) + u( ˙(cid:126)x),
˙x1) + u( ˙(cid:126)x).

−

−

(6)

The actuation u may depend on ˙x0 and ˙x1, summarized in vector notation as
˙(cid:126)x = ( ˙x0, ˙x1); it is added as a global actuator term with equal inﬂuence on both
oscillators, this role may be changed into more complex scenarios.

10

(cid:54)
(cid:54)
(cid:54)
Figure 7: Synchronization plot of two coupled van der Pol oscillators with varying coupling
strength c. The horizontal V-shaped plateau is referred to as the Arnold tongue, it represents
regions of synchronization. (The parameter set and initial conditions used are stated in the
left part of Tab. 4.)

3.1.1. Forced Synchronization

The system setup for forced synchronization of the two coupled van der Pol
oscillators is presented in the appendix, Tab.Tab. 4. The parameters ω1 and
c are chosen according to Fig. 7, such that the uncontrolled system follows a
de-synchronization regime at a distance, ∆ω, approximately half the plateau
from the closest synchronization point. The initial conditions are the same for
both oscillators.

The degree of de-synchronization is encompassed by the cost functional

Γ1 :=

Ω0

|

Ω1

.

|

−

(7)

It measures the diﬀerence in observed frequencies exhibited by the two oscilla-
tors: smaller diﬀerences reduce the cost on this objective.

As stated in the previous section, the actual frequencies, Ω0 and Ω1, are
numerically determined by counting zero crossings of the trajectory x
.
(cid:105)
This requires a careful choice of the time range [t0, tn] of observation, since the
number of periods, NP , ﬁtting into this interval determines an upper bound in
absolute accuracy (
) of measuring Ω0, Ω1. Here, NP = 2000 to yield an
absolute accuracy well below 10−3 in the frequency range of interest.

1
2NP

− (cid:104)

∼

x

The top six control laws found are given in Tab. Tab. 1. The algorithm
stopped after one generation, providing six simple results optimally satisfying
Γ1, the synchronization criterion. At this point we can start already to explain
the results. First, one notes that for each term in x0 we ﬁnd a counterpart in
x1. This can be explained by the symmetry in Eqs. (6). But why, then, are
the control terms not symmetric themselves, in the frequencies? This is at ﬁrst

11

sight not logical, however, if we check our cost functional, we recognize that we
only enforce synchronization, and not symmetry of the solution. In particular,
we note that the amplitude of one oscillator might vanish while the other one is
controlling it. That way, the result makes sense. A deep learning result would
not allow immediately such a simple and clear insight. To demonstrate the

Table 1: Two Coupled Oscillators: Optimal solutions for forced synchronization.

Ω0
|

Ω1

−
0.0
0.0
0.0
0.0
0.0
0.0

length

expression

|

2
2
2
2
2
2

cos( ˙x1)
cos( ˙x0)
˙x0
−
sin( ˙x1)
˙x1
−
sin( ˙x0)

control eﬀect Fig. 8 shows the Kuramoto order parameter, r, for the particular
solution u( ˙(cid:126)x) =
˙x0. The parameter represents phase-coherence over time
[42, 43] and is deﬁned as

−

r =

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
N

N −1
(cid:88)

j=0

eiϕj

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

,

≈

with ϕj being the continuous phase of the j-th oscillator. This continuous
phase is computed from the analytic signal of the trajectory using the Hilbert
[44]. The plot shows, that the controlled system completely
transform, cf.
synchronizes (r
const.) after passing through a short initial period of de-
synchronization; whereas the uncontrolled system exhibits a permanent phase
shift resulting in an oscillating graph. Now it is of highest interest to under-
stand how robust the found control law is against perturbation. This is a serious
study one has to do. Using explainable MLC we can use the well understood
and rigorous mathematical framework of stability analysis.
In particular for
nonlinear and complex systems that leads us onto safe ground whereas a neu-
ral network solution would require more, mor complicated and very expensive
studies. Before going into detail with stability in Sec. Sec. 3.1.3 we reiterate
results for forced de-synchronization.

3.1.2. Forced De-Synchronization

The system setup for forced de-synchronization is given in the appendix in
Tab. Tab. 4. The parameters ω1 and c are, again, chosen according to Fig. 7.
This time, such that the uncontrolled system follows a synchronization regime
well inside the plateau. The measure for the degree of synchronization is now
reciprocal to the previous case

Γ1 := exp(

Ω0

−|

Ω1

),

|

−

(8)

12

Figure 8: Two Coupled Oscillators: Kuramoto order parameter, r, for forced synchronization.
Green: the controlled, and blue: the uncontrolled system.

and penalizes synchronization of the two oscillators. Other GP parameters are
the same as for forced synchronization.

In Tab. Tab. 2, we show results from the GP run. These results are, again,
exact reproductions of [8]. Interestingly, of the 8 solutions found, only the best
two are worth being called desynchronized. It indicates that it is much harder
to synchronize a desynchronized solution than vice versa. Then, the control
term is a long expression in contrast to the ones found for synchronization. As
a further fact, constant optimization seems to fail in all cases where a constant
is present (this is expressed by a value k = 1, which corresponds to the initial
guess of the optimization procedure). Still, the oscillating Kuramoto parameter,
r, of the controlled system in Fig. 9 shows, that the best solution with respect
to Γ1 performs well in de-synchronizing the oscillators.

˜k ˙x0, with ˜k

Now let us interpret this solution. A look shows u( ˙(cid:126)x) =

exp(exp(k) +
26. This term has the same structure as one of
cos(k)) =
the best solutions found to enforce synchronization, namely the control law
u( ˙(cid:126)x) =
k ˙x0, with coeﬃcient k = 1. Both are analyzed in more detail in
−
Sec. 3.1.3.

˙x0

−

≈

−

·

Table 2: Two Coupled Oscillators: Pareto-front solutions for forced de-synchronization.

exp(

−|

Ω0

−
0.248
0.258
0.875
0.912
0.999
1.000
1.000
1.000

Ω1

)
|

length

expression

9
7
4
3
2
1
1
1

·

˙x0

exp(exp(k) + cos(k))
−
cos(exp( ˙x1 + cos(cos( ˙x0))))
cos(exp(exp( ˙x0)))
sin(exp( ˙x0))
exp(k)
˙x1
˙x0
k

constant

k = 1

k = 1

k = 1

13

0500100015002000timeinunitsofT0.00.20.40.60.81.0runcontrolledwithu(˙x)=−˙x0·

−

˙x0

The simpliﬁcation u( ˙(cid:126)x) =

exp(exp(k) + cos(k)) to u( ˙(cid:126)x) =

˙x0,
suggests the question, why the GP algorithm did not directly generate this
simpler solution. One reason is the stop criterion which prevents solutions to
converge further to simpliﬁed version. On the other hand, on failure, the least
squares algorithm returns the result of the last internal iteration. This return
value might be entirely inadequate for k, which, in turn, could lead to an large
cost Γ1, and by further integration of the dynamic system (6) the corresponding
solution is discarded.

26

−

·

Figure 9: Two Coupled Oscillators: Kuramoto order parameter, r, for forced synchronization.
Green: the controlled, and blue: the uncontrolled system. The horizontal axis is scaled to a
limited time window in order to make the oscillations visible.

3.1.3. Control Terms and Bifurcation Analysis

k

−

The objective of this section is to analyze the eﬀect of control exhibited
by the particular results u( ˙(cid:126)x) =
˙x0 found on the synchronization (and
·
desynchronization) of the two oscillators. To study synchronization, we ﬁrst
note that it is adequate to reduce Eqs. 5 by one dimension. This is done by
splitting oﬀ the fast oscillation and averaging methods [6]. The result is a system
of three ﬁrst order ODEs which can be studied with respect to stability. We use
the well-known package [28] to track branches of their solutions. This would
not be possible at all for a neural network control due to the complex network
structure and high dimension.

Let us ﬁrst dwell on the analytical work we can do now. One plugs u( ˙(cid:126)x) =

k ˙x0 into the ﬁrst oscillator equation from (6):

−

¨x0 =
=

=

(cid:0)1
c

−

−

ω2
ω2
ω2

0x0 + α ˙x0
0x0 + (α
−
0x0 + a0 ˙x0

−

βx2
0
k) ˙x0
−
b ˙x0x2

−

0 + c0 ˙x1,

(cid:1) + c ( ˙x1

˙x0)
−
−
αβ ˙x0x2
0 + c ˙x1

k ˙x0

(9)

−
k, b := αβ, and c0 := c. For the second oscillator equation

−

with a0 := α

c

−

−

14

900902904906908910912914916918timeinunitsofT0.00.20.40.60.81.0runcontrolledwithu(˙x)=−˙x0·exp(−˙x0)·exp(exp(k))−exp(˙x0)one obtains

¨x1 =
=

=

−

−

−

ω2
ω2
ω2

1x1 + α ˙x1
1x1 + (α
−
1x1 + a1 ˙x1

(cid:0)1
−
c) ˙x1

(cid:1) + c ( ˙x0
βx2
1
αβ ˙x1x2
1 + c1 ˙x0,

−
b ˙x1x2

−
1 + (c

˙x1)

k ˙x0

−
k) ˙x0

−

−

(10)

where a1 := α
coupled van der Pol oscillators, however, with direct coupling in place.

k. This way, one obtains another system of two

c and c1 := c

−

−

As indicated, this system can be analyzed in the framework of synchroniza-
tion theory which uses the method of averaging [6] under the assumption that
the system is weakly nonlinear. We repeat the calculations here for our system.
In essence, the second-order equations are rewritten as two ﬁrst-order equations
˙xj = y,
˙yj = r.h.s. (j = 0, 1), where r.h.s. denotes the right hand side of (9)
and (10) respectively. Next, the transformation

xj =

yj =

1
2
1
2

(Ajeiωt + A∗

j e−iωt),

(iωAjeiωt

−

iωA∗

j e−iωt),

(11)

(12)

is applied, where j = 0, 1, and Aj(t) = Rj(t)eiΘj (t) is the time-dependent com-
plex amplitude. This ansatz yields diﬀerential equations for the real amplitude
R and the phase Θ, which are both slowly varying. They result from the col-
lection of terms with vanishing fast oscillation.

When one writes the equations (9) and (10) as

˙y0 =
˙y1 =

ω2
ω2

0x0 + a0y0
1x1 + a1y1

−

−

by0x2
by1x2

0 + c0y1,
1 + c1y0,

−

−

(13)

(14)

with the corresponding approximations (ﬁrst order nonlinearities, slow dynam-
ics) one arrives at new equations for A

˙A0 =

˙A1 =

−

−

i∆0A0 +

i∆1A1 +

a0
2
a1
2

A0

A1

−

−

b
8 |
b
8 |

A0

A1

|

|

2A0 + c0A1,

2A1 + c1A0,

(15)

(16)

with ∆j = ωj
then obtains a system of four real equations

−

ω (j = 0, 1). For the real phases and amplitudes of A(t) one

2R0 + c0R1 cos(Θ1
|
2R1 + c1R0 cos(Θ0
|

−

−

Θ0),

Θ1),

(17)

˙R0 =

˙R1 =

˙Θ0 =

˙Θ1 =

a0
2
a1
2

R0

R1

−

−

∆0 + c0

∆1 + c1

−

−

R0

R1

b
8 |
b
8 |
R1
R0
R0
R1

sin(Θ1

sin(Θ0

Θ0),

Θ1).

−

−

15

Θ0 an asymmetric so-called Adler-type equation
For the phase diﬀerence Θ1
results, which may or may not show synchronization for the given parameters:

−

∆ ˙Θ =

∆ω

−

−

(c0

R1
R0

+ c1

R0
R1

) sin(Θ1

Θ0).

−

(18)

ω0. If the stationary state for the phase diﬀerence ∆ ˙Θ = 0 has
with ∆ω := ω1
a solution, one can ﬁnd synchronization, else not. A special solution where also
the amplitudes are stationary ( ˙R0 = ˙R1 = 0) has to be determined numerically.

−

Thus, the full coupled system for stationary solutions of (17) reads:

0 =

0 =

0 =

a0
2
a1
2

R0

R1

−

−

b
8 |
b
8 |

∆ω + (c0

−

2R0 + c0R1 cos(∆Θ),

R0

|

R1

2R1 + c1R0 cos(∆Θ),

|
R1
R0 −

c1

R0
R1

) sin(∆Θ),

(19)

−

−
−

with parameters a0 = α
k and ∆Θ = Θ0
c1 = c

c
−
Θ1.

k, a1 = α

c, b0 = α

·

−

β, b1 = α

·

β, c0 = c,

First one can observe, that the term k ˙xi (i = 0, 1) introduces an asymmetry
in the equations (17), such that one or the other oscillator might be “favored” by
the dynamics, since it may have a diﬀerent damping depending on the parameter
settings. In an uncoupled system (c = 0) this is of course relevant if one needs
to study a real application. For a better understanding of the implications of
the control term k ˙x1 we note that in the uncoupled case, the ﬁrst equation of
(19) reduces to

0 =

a
2

R0

−

b
8 |

R0

2R0,
|

(20)

β. This is the normal form of a
k, b = α
with rescaled parameters a = α
pitchfork bifurcation. In the original, non-averaged system, this corresponds to
a Hopf-bifurcation because the full system shows oscillations.

−

·

To this end, we use the path-following and bifurcation analysis package
AUTO-07p [28]. In the scope of this work, this analysis has been done manu-
ally, it is however straightforward to extend the MLC software to do this in an
automated fashion for any control term found.

The paths of stationary solutions, as observed in the following, are inter-
preted by comparing to the standard textbook examples, as can be found in
e.g.
[45]. First, we consider the uncoupled case (c = 0) for varying k. Next,
solutions for R0, R1, ∆Θ are tracked against varying k, or c, respectively, for sev-
eral values of c, or k, respectively, cf.Fig. Fig. 12 and Fig. Fig. 11, respectively.
Finally, contour lines for ﬁxed component values of the stationary solution to
(19) are shown demonstrating that a wide variety of choices of particular syn-
chronization details is possible by tuning the k and c parameters to the right
values (Fig. 13).

16

The uncoupled case (c = 0). of (19) is shown in Fig. 10 Since the radius equa-
tions are cubic, one obtains three solutions until the damping (introduced by
k) becomes stronger than energy input and no nontrivial solution is possible.
The control term introduces a coupling “through the backdoor” into the second
equation of the system via the term c1R0 cos(∆Θ). So, when varying k, the
bifurcation diagram of R0 shows a plain pitchfork bifurcation, the one for R1
shows a distorted version of the pitchfork bifurcation due to this quasi-coupling.

(a)

(b)

(c)

Figure 10: Stationary solutions for the system (19) without coupling (c = 0). (a) R0, (b)
R1, (c) ∆Θ vs k are plotted. Here, both trivial (R0 = R1 = ∆Θ = 0) and non-trivial solution
are shown. Beyond k = α no nontrivial solution is possible. Physically this reﬂects the fact
that the damping is so large that no oscillation is possible.

The coupled case (c
= 0). is visualized for varying parameter c in Fig. 11 and
for varying k in Fig. 12. Note that even in the case of vanishing control k and
non-zero coupling c, there is an asymmetry between R0 and R1 that is mediated
= 0. In Fig. 11, one can see a transition from
by the third equation when ∆ω
the uncontrolled system to the controlled, pushing the right bifurcation point
to higher values of c with increasing coupling k. At the same time, stationary
solutions for the low end of c cease to exist somewhere between k = 0.04 and
k = 0.06. The exact mechanism of this transition is out of the scope of this
publication and will done in subsequent work together with a full bifurcation
and stability analysis of this system.

An understanding comes from the following argument: In a three-dimensional
system with cubic terms one can obtain, in principle, more than three solutions.
Since we have no additional objective in the GP run, it is clear that the partic-
ular choice of k in such a simple control term as k ˙xi is just a representative of a
larger class of control laws. To ﬁx it to a speciﬁc value, or to enforce a symmet-
ric situation, one has to add the corresponding terms in the cost function. Since

17

(cid:54)
(cid:54)
the control term is asymmetric, with increasing k, one changes the bifurcation
scenario from perfect to imperfect. This qualitative behavior is found in all
graphs shown hereafter.

(a)

(b)

(c)

Stationary solutions for the system (19). Solution variables a R0, b R1 and c
Figure 11:
∆Θ are plotted against varying coupling c and a set of ﬁxed control parameters k. The trivial
solution (R0 = R1 = ∆Θ = 0) has been omitted in the plot for better overview.

The behavior of R0 and R1 with increasing coupling and ﬁxed control can
be also be understood with a close look at Fig. 11. At highest values of c where
stationary solutions exist, the values of R0 and R1 are approximately equal. As
the coupling strength diminuishes, the two radii take increasingly diﬀerent values
as for low values of c, the coupling is dominated by the asymmetric terms with
k. As the control strength k is increased, stationary solutions at higher coupling
strenghts exist and this behavior becomes more and more strongly pronounced
where high c values dominate the coupling which is thus symmetric.

However, beyond a certain control, k, no synchronization can be found at all
– the sudden stop of the curves is no artifact, but rather a true dynamical eﬀect,
this is seen in Fig. 12. The overall behavior is clearly correct as the benchmark
graph c = 0 shows that the solution is lost at k = α. A similar observation
holds for Fig. 11, where stationary solutions of (19) cease to exist above some
critical value of c.

These observations explain also, why the simple control term k ˙xi can push
dynamics from synchronized to de-synchronized: it adds a damping of one os-
cillator i that desynchronizes the two oscillators. The value can be read oﬀ of
the ﬁgures Fig. 12 for a given coupling strength.

The GP-algorithm yields a value of k = 1, clearly this is larger than the
critical value of approximately 0.05 (For c = 0.022, see Tab. 5), read oﬀ Fig. 12.
Now, one may ask why this value is chosen and not another one k > 0.05. The
reason is simple, but it is hidden in the problem formulation: The objective

18

(a)

(b)

(c)

Figure 12: Stationary solutions for the coupled system (19). Solution variables a R0, b R1
and c ∆Θ are plotted against varying control k and a set of ﬁxed couplings c. For c = 0
the scenario of Fig. 10 is recovered (black line). With increasing coupling, the control term
becomes relatively weaker and eventually coupling dominates the dynamics.

function only requires that synchronization be destroyed. This is possible for
many functions and in particular for many simple functions with complexity
2. Among them, the control function k ˙x is particularly appealing due to its
simplicity. The algorithm is now free to choose any k > 0.05 and so it does.
The value 1 is probably appearing because it is the ﬁrst guess for a constant
in the constant-optimization step of the algorithm and because it satisﬁes the
objective.

−

The mathematical analysis also allows ﬁne-tuning the control by varying
the control parameter k e.g. when the coupling strength changes and certain
characteristics of the solution are to be kept. Such adjustments could for exam-
ple be read oﬀ Fig. 13 where the height lines of certain values of the solutions
parameters are tracked in the c

k plane.

As a consequence, one can conclude that a careful formulation of the objec-
tive helps in obtaining a unique answer. In the following we will not comment
further on these details. They must be considered in any application of the
method, though. We demonstrated that the symbolic regression performed by
the GP algorithm produces results which are interpretable and tractable with
mathematical methods, here within the framework of dynamical systems. This
allows the subsequent step of exactly understanding the implications of a partic-
ular choice of control and choosing the one that is best suited to the needs of the
particular problem at hand. Moreover, once the dynamics with included con-
trol have been understood, the method allows tweaks to the control term (like
adjusting the value of k) while understanding what will be happening. Neither
the analytical interpretation of the control nor the possibility of tweaking the
control would not have been possible for a control achieved by a neural network

19

due to its black box nature.

(a)

(b)

(c)

Figure 13: The bifurcation scenario in the parameter plane. The contour lines correspond to
lines of equal height of the solutions.

4. Discussion and Conclusion

In this work we demonstrate the use of explainable MLC methods -symbolic
regression by GP- for rigorous analysis. We found several control laws results
with similar score lead to diﬀerent results with respect to stability analysis. In
a general context, this result means that we can automatize analysis of the top
models with rigorous mathematical methods, where stability is just one among
others. For the big questions, though, like climate change, vehicle optimization
(e.g. fuel reduction or predictive, automatized maintenance ), autonomous drive
and alike this is of primordial importance.

We analyzed explainable MLC using a well-known control problem in dy-
namical systems: coupled self-sustained oscillators which exhibit synchronized
behaviour or desynchronized one, depending on the system parameters. In a
previous study, we applied our control approach to dynamical systems com-
posed of networks of coupled oscillators, starting from two coupled van der Pol
oscillators up to a hierarchical network consisting of a few hundred oscillators.
In this work, we reproduced and used these results for a subsequent stability
analysis. Such rigorous analyses are deﬁnitely not accessible using black-box
or qualitative methods like, e.g., neural networks. The comparatively complex
handling of GP in comparison with other symbolic methods like generalized re-
gression is paid oﬀ if explainable solutions are needed. Due to the evolutionary
nature of the method, it is not guaranteed that the global optimum is found,
consequently a subsequent rigorous analysis is of great value.

20

As a result we ﬁnd terms of diﬀerent complexity leading to diﬀerent levels
of synchronization control, where synchronization is measured using the Ku-
ramoto parameter. In both cases, synchronization and desynchronisaton, the
found control laws are tested for stability. In Section 3.1.3, we demonstrate the
potential of the methods by following the solutions numerically. We do not even
touch a detailed analysis of eigenvalues and Lyapunov exponents which play a
very important role in the dynamics of dynamical systems in general.

Current eﬀorts go to an automatization of this analysis following an ex-
plainable method, as well the fast sparse methods of generalized regression. To
this end we plan to extend our existing framework Glyph. Using this kind of
analysis will extend the range of explainable MLC to result in robust and in-
terpretable control laws, a fact which is a unique selling point for explainable
MLC. Clearly, this can end in a round trip where better objective functions
are designed, taking into consideration the rigorous analysis and possibly prior
domain knowledge, e.g. in the form of additive symmetry terms. In conclusion,
we state that in terms of mathematical rigor, versatility and adaptability, the
crystal-box method of GP is superior to other rather black-box methods, as
artiﬁcial neural networks or support vector machines.

Acknowledgements

We thank A. Pikovsky for synchronization wisdom, M. Rosenblum for pro-

viding input with respect to an application to human brain dynamics.

References

[1] R. Goebel, A. Chander, K. Holzinger, F. Lecue, Z. Akata, S. Stumpf,
P. Kieseberg, A. Holzinger, Explainable ai: The new 42?, in: A. Holzinger,
P. Kieseberg, A. M. Tjoa, E. Weippl (Eds.), Machine Learning and Knowl-
edge Extraction, Springer International Publishing, Cham, 2018, pp. 295–
303 (2018).

[2] E. Ott, C. Grebogi, J. A. Yorke, Controlling chaos, Phys. Rev. Lett. 64 (11)
(1990) 1196–1199 (Mar. 1990). doi:10.1103/physrevlett.64.1196.
URL https://doi.org/10.1103/physrevlett.64.1196

[3] Chaos Control, Springer Berlin Heidelberg, 2003 (2003). doi:10.1007/

b79666.
URL https://doi.org/10.1007/b79666

[4] H. Haken, Brain Dynamics: Synchronization and Activity Patterns in
Pulse-Coupled Neural Nets with Delays and Noise, Springer Series in Syn-
ergetics, Springer Berlin Heidelberg, 2006 (2006).
URL https://books.google.de/books?id=8elDAAAAQBAJ

21

[5] J. M. Schwalb, C. Hamani, The history and future of deep brain stimula-
tion, Neurotherapeutics 5 (1) (2008) 3–13 (Jan. 2008). doi:10.1016/j.
nurt.2007.11.003.
URL https://doi.org/10.1016/j.nurt.2007.11.003

[6] A. Pikovsky, M. Rosenblum, J. Kurths, Synchronization, Cambridge Uni-

versity Press, 2001 (2001). doi:10.1017/cbo9780511755743.
URL https://doi.org/10.1017/cbo9780511755743

[7] S. H. Strogatz, Sync: How order emerges from chaos in the universe, nature,

and daily life, Hyperion, 2003 (2003).

[8] J. Gout, M. Quade, K. Shaﬁ, R. K. Niven, M. Abel, Synchronization control
of oscillator networks using symbolic regression, Nonlinear Dynamics 91 (2)
(2018) 1001–1021 (Jan 2018). doi:10.1007/s11071-017-3925-z.
URL https://doi.org/10.1007/s11071-017-3925-z

[9] Impulsive stabilization for control and synchronization of chaotic systems:
Theory and application to secure communication, IEEE Trans. Circuits
Syst. I 44 (10) (1997) 976–988 (1997). doi:10.1109/81.633887.
URL https://doi.org/10.1109/81.633887

[10] Z. Li, X. Cao, N. Ding, Adaptive fuzzy control for synchronization of
nonlinear teleoperators with stochastic time-varying communication de-
lays, IEEE Trans. Fuzzy Syst. 19 (4) (2011) 745–757 (Aug. 2011). doi:
10.1109/tfuzz.2011.2143417.
URL https://doi.org/10.1109/tfuzz.2011.2143417

[11] H. Shokri-Ghaleh, A. Alﬁ, Optimal synchronization of teleoperation sys-
tems via cuckoo optimization algorithm, Nonlinear Dyn 78 (4) (2014) 2359–
2376 (Aug. 2014). doi:10.1007/s11071-014-1589-5.
URL https://doi.org/10.1007/s11071-014-1589-5

[12] C. Hammond, H. Bergman, P. Brown, Pathological synchronization in
Parkinson’s disease: Networks, models and treatments, Trends in Neu-
rosciences 30 (7) (2007) 357–364 (Jul. 2007). doi:10.1016/j.tins.2007.
05.004.
URL https://doi.org/10.1016/j.tins.2007.05.004

[13] F. Dorﬂer, M. Chertkov, F. Bullo, Synchronization in complex oscillator
networks and smart grids, Proceedings of the National Academy of Sciences
110 (6) (2013) 2005–2010 (Jan. 2013). doi:10.1073/pnas.1212134110.
URL https://doi.org/10.1073/pnas.1212134110

[14] D. E. Kirk, Optimal control theory: An introduction, Courier Corporation,

2012 (2012).

[15] Numerical Optimization, Springer-Verlag, 1999 (1999).

doi:10.1007/

b98874.
URL https://doi.org/10.1007/b98874

22

[16] S. Sra, S. Nowozin, S. J. Wright, Optimization for Machine Learning, MIT

Press, Cambridge, USA, 2011 (2011).

[17] V. Becerra, Optimal control, Scholarpedia 3 (1) (2008) 5354 (2008). doi:

10.4249/scholarpedia.5354.
URL https://doi.org/10.4249/scholarpedia.5354

[18] Optimal Control Theory, Springer-Verlag, 2000 (2000). doi:10.1007/

0-387-29903-3.
URL https://doi.org/10.1007/0-387-29903-3

[19] Handbook of Chaos Control, Wiley-VCH Verlag GmbH & Co. KGaA, 2007

(Oct. 2007). doi:10.1002/9783527622313.
URL https://doi.org/10.1002/9783527622313

[20] J. R. Koza, Genetic Programming: On the Programming of Computers by

Means of Natural Selection, MIT Press, 1992 (1992).

[21] M. Schmidt, H. Lipson, Distilling free-form natural laws from experimental
data, Science 324 (5923) (2009) 81–85 (Apr. 2009). doi:10.1126/science.
1165893.
URL https://doi.org/10.1126/science.1165893

[22] E. Vladislavleva, G. Smits, D. den Hertog, Order of nonlinearity as a com-
plexity measure for models generated by symbolic regression via Pareto
genetic programming, IEEE Trans. Evol. Computat. 13 (2) (2009) 333–349
(Apr. 2009). doi:10.1109/tevc.2008.926486.
URL https://doi.org/10.1109/tevc.2008.926486

[23] M. Quade, M. Abel, K. Shaﬁ, R. K. Niven, B. R. Noack, Prediction of
dynamical systems by symbolic regression, Phys. Rev. E 94 (1) (Jul. 2016).
doi:10.1103/physreve.94.012214.
URL https://doi.org/10.1103/physreve.94.012214

[24] H. Shokri-Ghaleh, A. Alﬁ, A comparison between optimization algorithms
applied to synchronization of bilateral teleoperation systems against time
delay and modeling uncertainties, Applied Soft Computing 24 (2014) 447–
456 (Nov. 2014). doi:10.1016/j.asoc.2014.07.020.
URL https://doi.org/10.1016/j.asoc.2014.07.020

[25] M. Quade, J. Gout, M. Abel, Ambrosys/glyph: V0.3.2 (Jun. 2017). doi:

10.5281/zenodo.801819.
URL https://doi.org/10.5281/zenodo.801819

[26] Y. E. S. M., P. Oswald, S. Sattler, P. Kumar, R. Radespiel, C. Behr,
M. Sinapius, J. Petersen, P. Wierach, M. Quade, M. Abel, B. R. Noack,
investigations of unsteady
R. Semaan, Open- and closed-loop control
Coanda actuation on a high-lift conﬁguration. arXiv:https://arc.aiaa.
org/doi/pdf/10.2514/6.2018-3684, doi:10.2514/6.2018-3684.
URL https://arc.aiaa.org/doi/abs/10.2514/6.2018-3684

23

[27] D. A. Wiley, S. H. Strogatz, M. Girvan, The size of the sync basin, Chaos

16 (1) (2006) 015103 (Mar. 2006). doi:10.1063/1.2165594.
URL https://doi.org/10.1063/1.2165594

[28] E. J. Doedel, T. F. Fairgrieve, B. Sandstede, A. R. Champneys, Y. A.
Kuznetsov, X. Wang, Auto-07p: Continuation and bifurcation software for
ordinary diﬀerential equations, Tech. rep. (2007).

[29] H. H. Goldstine, A History of the Calculus of Variations from the 17th
through the 19th Century, Springer New York, 1980 (1980). doi:10.1007/
978-1-4613-8106-8.
URL https://doi.org/10.1007/978-1-4613-8106-8

[30] W. H. Press, Numerical recipes 3rd edition: The art of scientiﬁc computing,

Cambridge university press, 2007 (2007).

[31] F. L. Lewis, D. L. Vrabie, V. L. Syrmos, Optimal Control, John Wiley &

Sons, Inc., 2012 (Jan. 2012). doi:10.1002/9781118122631.
URL https://doi.org/10.1002/9781118122631

[32] A. E. Bryson (Jr), Y. Ho, Applied Optimal Control, Halsted Press, 1975

(1975).

[33] M. Athans, P. L. Falb, Optimal Control: An Introduction to the Theory

and Its Applications, Dover Publications, 2006 (2006).

[34] K. Ahnert, M. Abel, Numerical diﬀerentiation of experimental data: local
versus global methods, Computer Physics Communications 177 (10) (2007)
764 – 774 (2007). doi:https://doi.org/10.1016/j.cpc.2007.03.009.
URL
S0010465507003116

http://www.sciencedirect.com/science/article/pii/

[35] G. F. Franklin, J. D. Powell, A. Emami-Naeini, Feedback Control of Dy-

namic Systems, 7th Edition, Pearson, 2014 (2014).

[36] H. U. Voss, P. Kolodner, M. Abel, J. Kurths, Amplitude equations from
spatiotemporal binary-ﬂuid convection data, Phys. Rev. Lett. 83 (1999)
3422–3425 (Oct 1999). doi:10.1103/PhysRevLett.83.3422.
URL https://link.aps.org/doi/10.1103/PhysRevLett.83.3422

[37] H. Voss, M. J. B¨unner, M. Abel, Identiﬁcation of continuous, spatiotem-
doi:

poral systems, Phys. Rev. E 57 (1998) 2820–2823 (Mar 1998).
10.1103/PhysRevE.57.2820.
URL https://link.aps.org/doi/10.1103/PhysRevE.57.2820

[38] N. L. Cramer, A representation for the adaptive generation of simple se-
quential programs, in: J. J. Grefenstette (Ed.), Proceedings of an Interna-
tional Conference on Genetic Algorithms and the Applications, Psychology
Press, 1985, pp. 183–187 (1985).

24

[39] Genetic Programming, Springer Berlin Heidelberg, 1999 (1999). doi:10.

1007/3-540-48885-5.
URL https://doi.org/10.1007/3-540-48885-5

[40] X.-S. Yang, Metaheuristic optimization, Scholarpedia 6 (8) (2011) 11472

(2011). doi:10.4249/scholarpedia.11472.
URL https://doi.org/10.4249/scholarpedia.11472

[41] M. A. M Quade, J Gout, Glyph: Symbolic regression tools, Journal of

Open Research Software 1 (7).

[42] Y. Kuramoto, Lecture notes in physics, in: H. Araki (Ed.), International
Symposium on Mathematical Problems in Theoretical Physics, Vol. 39,
Springer, 1975, p. 420 (1975).

[43] Y. Kuramoto, Chemical Oscillations, Waves, and Turbulence, Springer
Berlin Heidelberg, 1984 (1984). doi:10.1007/978-3-642-69689-3.
URL https://doi.org/10.1007/978-3-642-69689-3

[44] L. Cohen, Time Frequency Analysis: Theory and Applications, 1st Edition,

Prentice Hall, 1994 (1994).

[45] S. H. Strogatz, Nonlinear Dynamics And Chaos, 2nd Edition, Westview

Press, 2015 (2015).

[46] M. Matsumoto, T. Nishimura, Mersenne twister: A 623-dimensionally
equidistributed uniform pseudo-random number generator, ACM Trans.
Model. Comput. Simul. 8 (1) (1998) 3–30 (Jan. 1998). doi:10.1145/
272991.272995.
URL https://doi.org/10.1145/272991.272995

[47] SymPy Dev Team, SymPy: Python library for symbolic mathematics

(2016).
URL http://www.sympy.org

5. Appendix

In this section, we give a brief summary of the implementation details and the
parameters used in our setup. Hyperparameters have been chosen empirically
such that they lead to plausible and interpretable results on the chosen set of
examples. We did not optimize the hyperparameters for convergence.

Our software is based on Glyph, a package developed by ourselves [41], which
in turn uses other, standard python packages, e.g., constant optimization is
conducted using the Levenberg-Marquardt least squares algorithm (scipy) and
numerical integration using the dopri5 solver (also scipy). Random numbers
are generated using the Mersenne Twister pseudo-random number generator
provided by the random module [46]. Finally, the sympy module is used for

25

the simpliﬁcation of symbolic mathematical expressions generated from the GP
runs [47], for more details see [41].

Tab. 3 gives an overview of the methods and parameters used for the GP
runs. Actual implementations can be found under the same name in the deap
module.

Table 3: General setup of the GP runs.

Function set
Population size
Max. generations
MOO algorithm

Tree generation
Min. height
Max. height

Selection
Tournament size

, sin, cos, exp
·

,

−

+,
{
500
20
NSGA-II

}

halfandhalf
1
4

selTournament
2

Breeding

varOr

Recombination
Crossover probability
Crossover max. height

cxOnePoint
0.5
20

Mutation
Mutation probability
Mutation max. height

mutUniform
0.2
20

Constant optimization

leastsq

The following tables 4 and 5 list the setup used for two coupled oscillators

forced to to synchronization and de-synchronization, respectively.

Table 4: Two Coupled Oscillators: System setup for forced synchronization.

dynamic system

GP

Ω1
Ω0
|
|
−
length(u)
˙x0, ˙x1
k

}

{
{
3464542173339676227

}

ω0
ω1
α, β, c
(cid:126)x(t0)
˙(cid:126)x(t0)
t0, tn
n

ln(4)
ln(4) + 0.04
0.1, 1, 0.022
(1, 1)
(0, 0)
0, 2000 2π
ω0
40000

cost functionals

argument set
constant set
seed

26

Table 5: Two Coupled Oscillators: System setup for forced de-synchronization.

dynamic system

GP

−

)
|

Ω1

Ω0
exp(
−|
length(u)
˙x0, ˙x1
{
k
{
2590675513212712687

}

}

ω0
ω1
α, β, c
(cid:126)x(t0)
˙(cid:126)x(t0)
t0, tn
n

ln(4)
ln(4) + 0.015
0.1, 1, 0.022
(1, 1)
(0, 0)
0, 2000 2π
ω0
40000

cost functionals

argument set
constant set
seed

27

