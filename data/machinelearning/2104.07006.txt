2
2
0
2

r
a

M
3
2

]
h
p
-
t
n
a
u
q
[

4
v
6
0
0
7
0
.
4
0
1
2
:
v
i
X
r
a

Fast quantum state reconstruction
via accelerated non-convex programming

Junhyung Lyle Kim1, George Kollias2, Amir Kalev3, Ken X. Wei2, Anastasios Kyrillidis1
1 Computer Science, Rice University, Houston, TX 77098, USA
2 IBM Quantum, IBM T.J. Watson Research Center, Yorktown Heights, NY 10598, USA
3 Information Sciences Institute, University of Southern California, Arlington, VA 22203, USA

March 24, 2022

Abstract

We propose a new quantum state reconstruction method that combines ideas from compressed sensing,
non-convex optimization, and acceleration methods. The algorithm, called Momentum-Inspired Factored
Gradient Descent (MiFGD), extends the applicability of quantum tomography for larger systems. Despite
being a non-convex method, MiFGD converges provably close to the true density matrix at an accelerated
linear rate, in the absence of experimental and statistical noise, and under common assumptions. With
this manuscript, we present the method, prove its convergence property and provide Frobenius norm
bound guarantees with respect to the true density matrix. From a practical point of view, we benchmark
the algorithm performance with respect to other existing methods, in both synthetic and real experiments
performed on an IBM’s quantum processing unit. We ﬁnd that the proposed algorithm performs orders
of magnitude faster than state of the art approaches, with the same or better accuracy. In both synthetic
and real experiments, we observed accurate and robust reconstruction, despite experimental and statistical
noise in the tomographic data. Finally, we provide a ready-to-use code for state tomography of multi-qubit
systems.

Introduction

Quantum tomography is one of the main procedures to identify the nature of imperfections and deviations
in quantum processing unit (QPU) implementation [9, 27]. Generally, quantum tomography is composed
of two main parts: i) measuring the quantum system, and ii) analyzing the measurement data to obtain an
estimation of the density matrix (in the case of state tomography [9]), or of the quantum process (in the case
of process tomography [66]). In this manuscript, we focus on the case of state tomography.

As the number of free parameters that deﬁne quantum states and processes scale exponentially with the
number of subsystems, generally quantum tomography is a non-scalable protocol [38]. In particular, quan-
tum state tomography (QST) suffers from two bottlenecks related to its two main parts. The ﬁrst concerns
with the large data one needs to collect to perform tomography; the second concerns with numerically
searching in an exponentially large space for a density matrix that is consistent with the data.

There have been various approaches over the years to improve the scalability of QST, as compared to
full QST [98, 48, 11]. Focusing on the data collection bottleneck, to reduce the resources required, prior in-
formation about the unknown quantum state is often assumed. For example, in compressed sensing QST
[38, 49], it is assumed that the density matrix of the system is low-rank. In neural network QST [93, 12, 94],
one assumes real and positive wavefunctions, which occupy a restricted place in the landscape of quan-
tum states. Extensions of neural networks to complex wave-functions, or the ability to represent density
matrices of mixed states, have been further considered in the literature, after proper reparameterization of
the Restricted Boltzmann machines [93]. The prior information considered in these cases is that they are
characterized by structured quantum states, which is the reason for the very high performances of neural

1

 
 
 
 
 
 
network QST [93].1 Similarly, in matrix-product-state tomography [23, 58], one assumes that the state-to-
be-estimated can be represented with low bond-dimension matrix-product state.

Focusing on the computational bottleneck, several works introduce sophisticated numerical methods
to improve the efﬁciency of QST. Particularly, variations of gradient descent convex solvers—e.g., [35, 16,
86, 44]—are time-efﬁcient in idealized (synthetic) scenarios [44], and only after a proper distributed system
design [42]. The problem is that achieving such results seems to require utilizing special-purpose hardware
(like GPUs). Thus, going beyond current capabilities requires novel methods that efﬁciently search in the
space of density matrices under more realistic scenarios. Importantly, such numerical methods should come
with guarantees on their performance and convergence.

The setup we consider here is that of an n-qubit state, under the prior assumption that the state is
close to a pure state, and thus its density matrix is of low-rank. This assumption is justiﬁed by state-of-
the-art experiments, where our aim is to manipulate the pure states by unitary maps. From a theoretical
perspective, the low-rank assumption means that we can use compressed sensing techniques, which allow
the recovery of the density matrix from relatively few measurement data [63].

Indeed, by now, compressed sensing QST is widely used for estimating highly-pure quantum states, e.g.,
[83, 54, 28, 38]. However, compressed sensing QST usually relies on convex optimization for the estimation
part [49]; this limits the applicability to relatively small system sizes [38]. On the other hand, non-convex
optimization can preform much faster than its convex counterpart [57]. Although non-convex optimization
typically lacks convergence guarantees, it was recently shown that one can formulate compressed sensing
QST as a non-convex problem and solve it with rigorous convergence guarantees (under certain but generic
conditions), allowing state estimation of larger system sizes [57].

Following the non-convex path, we introduce a new algorithm to the toolbox of QST—the Momentum-
Inspired Factored Gradient Descent (MiFGD). Our approach combines ideas from compressed sensing,
non-convex optimization, and acceleration techniques, to allow pushing QST beyond current capabilities.
MiFGD includes acceleration motions per iteration, that non-trivially complicate theoretical convergence
analysis. Nevertheless, we justify the efﬁcacy of the algorithm both in theory – by achieving an accelerated
linear rate – and in practice.

The contributions of the paper are summarized as follows:

i) We prove that the non-convex MiFGD algorithm has indeed accelerated linear convergence rate, in terms

of iterate distance, in the noiseless measurement data case and under common assumptions.

ii) We provide QST results based on real data from IBM’s quantum computers up to 8-qubits, contributing
to recent efforts on testing QST algorithms in real quantum data [83]. Our synthetic examples scale up
to 12-qubits effortlessly, leaving the space for an efﬁcient, hardware-aware implementation open for
future work.

iii) We show in practice that MiFGD allows faster estimation of quantum states compared to state-of-the-art
convex and non-convex algorithms, including recent deep learning approaches [93, 12, 94, 31], even in
the presence of statistical noise in the measurement data.

iv) We exploit parallel computations in MiFGD by extending its implementation to enable efﬁcient, parallel
execution over shared and distributed memory systems. This way, we experimentally showcase the
scalability of this work, which is particularly critical for tackling larger quantum system sizes.

v) We provide implementation of our approach, compatible to the open-source software Qiskit [81], at

https://github.com/gidiko/MiFGD.

1[93] considers also the case of a completely unstructured case and test the limitation of this technique, which does not perform

as expected due to lack of structure.

2

Results

Setup

We consider the estimation of a low-rank density matrix ρ(cid:63)
through the following (cid:96)2-norm reconstruction objective:

∈

Cd×d on an n-qubit Hilbert space, d = 2n,

min
ρ∈Cd×d

subject to ρ

(cid:23)

f (ρ) := 1

(ρ)

2 (cid:107)A
0, rank(ρ)

−

y

2
2
(cid:107)
r.

≤
) : Cd×d
·

(1)

∈

A

(cid:28)

(ρ))i = Tr(Aiρ), where Ai

Rm is the measured data2 (observations), and

Rm is the linear sensing map, where
(
Here, y
A
d2. The sensing map relates the density matrix ρ(cid:63) to (expected, noiseless) observations through the
m
Cd×d, i = 1, . . . , m, are matrices closely related to the mea-
Born rule, (
sured observable or the POVM elements of appropriate dimensions. For concreteness, we focus on the least
squares objective function.3 The constraint that a density matrix is a non-negative matrix, ρ
0, is a convex
constraint. In contrast, the constraint on its rank, rank(ρ)
r, is a non-convex constraint that promotes a
low-rank solution. Following compressed sensing QST results [49], the constraint Tr(ρ) = 1 (that should be
satisﬁed, by deﬁnition, by any density matrix) can be ignored, without affecting the scaling of the precision
of the ﬁnal estimation.

→

≤

(cid:23)

∈

A pivotal assumption is that the linear map

A

satisﬁes the restricted isometry property:

Deﬁnition 1 (Restricted Isometry Property (RIP) [82]). A linear operator
on rank-r matrices, with parameter δr
probability:

∈

(0, 1), if the following holds for any rank-r matrix X

→

A

∈

: Cd×d

Rm satisﬁes the RIP
Cd×d, with high

(X)
(cid:107)
Such maps (almost) preserve the Frobenius norm of low-rank matrices, and, as an extension, of low-
) behaves as almost a bijection between the
(
rank Hermitian matrices. The intuition behind RIP is that
·
A
subspaces Cd×d and Rm, when we focus on low rank matrices.

(1 + δr)

δr)

(2)

· (cid:107)

· (cid:107)

(1

X

X

−

(cid:107)

2
F ≤ (cid:107)A
(cid:107)

2
2 ≤

2
F .

Following recent works [57], instead of solving Eq. (1), we propose to solve a factorized version of it:

min
U ∈Cd×r

(U U †)

1
2 (cid:107)A

y

2
2,
(cid:107)

−

(3)

∈

Cr×d denotes the adjoint of U . The motivation for this reformulation is as follows: instead of
where U †
d Hermitian matrix, and imposing the low-rank constraint as in
representing the density matrix ρ as a d
Cd×r.
Eq. (1), we work in a space where low-rank density matrices are represented through factors U
The low-rankness of ρ is enforced through the factorization of the density matrix into a outer product of
r. By rewriting
such a rectangular matrix representation U
ρ = U U †, for U
r) are
directly satisﬁed, leading to the non-convex formulation (3). Working in the factored space was shown [57,
79, 78, 96, 102, 103] to improve time and space complexities.

Cd×r with its Hermitian conjugate, where d

0) and the low-rankness constraint (rank(ρ)

Cd×r, both the PSD constraint (ρ

(cid:29)

×

(cid:23)

≤

∈

∈

∈

A common approach to solve (3) is to use gradient descent on the parameter U , with iterates generated

by the rule:4

Ui+1 = Ui

= Ui

−

−

η

η

Ui

f (UiU †
i )
·
∇
(UiU †
†
i )
A

A

·
(cid:17)
Cd×d is the adjoint of

−

(cid:16)

y

Ui.

(4)

(5)

∈

Cd×r,

i. The operator

m
i=1 xiAi, for
Here, Ui
Rm. The hyperparameter η > 0 is the step size. This algorithm has been studied in [14, 103, 96, 80, 32, 43].
x
(cid:80)
We will refer to the above iteration as the Factored Gradient Descent (FGD) algorithm, as in [79]. In what
follows, we will study the MiFGD algorithm, a momentum-inspired factored gradient descent.

, deﬁned as

†(x) =

† : Rm

→

A

A

A

∈

∀

2Speciﬁc description on how y is generated and what it represents will follow.
3Our results rely on standard optimization assumptions (restricted smoothness and restricted strong convexity assumptions [68]).
4We assume cases where ∇f (·) = ∇f (·)†. If this does not hold, the theory still holds by carrying around ∇f (·) + ∇f (·)† instead

of just ∇f (·), after proper scaling.

3

Momentum-Inspired Factored Gradient Descent and Main Results

The MiFGD algorithm is given in the Methods section. It is a two-step variant of FGD:

Ui+1 = Zi

−
Zi+1 = Ui+1 + µ (Ui+1

A

(cid:16)

η

†
A

(ZiZ †
i )

Zi,

y

·

(cid:17)

(6)

(7)

−
Ui) .

−

Here, Zi is a rectangular matrix (with the same dimension as Ui) that accumulates the “momentum” of the
iterates Ui. µ is the momentum parameter that weighs how the previous estimates Ui will be mixed with
the current estimate Ui+1 to generate Zi+1. The above iteration is an adaptation of Nesterov’s accelerated
ﬁrst-order method for convex problems [69]. We borrow this momentum formulation, and we study how
constant µ selections behave in non-convex problem formulations, such as in (3). We note that the theory and
algorithmic conﬁgurations in [69] do not generalize to non-convex problems, which is one of the contributions of
this work. Albeit being a non-convex problem, we show that MiFGD converges at an accelerated linear rate
around a neighborhood of the optimal value, akin to convex optimization problems [69].

An important observation is that the factorization ρ = U U † is not unique. For instance, suppose that
U (cid:63) is an optimal solution for (3); then, for any rotation matrix R
Cr×r satisfying RR† = I, the matrix
U = U (cid:63)R is also optimal for (3). 5 To resolve this ambiguity, we use the distance between a pair of matrices
as the minimum distance minR∈O
. In
}
words, we want to track how close an estimate U is to U (cid:63), up to the minimizing rotation matrix.
(cid:98)

(cid:107)F up to rotations, where

RR† = I

U (cid:63)R

Cr×r

U
(cid:107)

O

=

−

R

∈

∈

{

|

We are now ready to state the main theorem regarding the MiFGD algorithm:

Theorem 1 (MiFGD convergence rate (Informal)). Assume that
satisﬁes the RIP for some constant 0 <
(ρ(cid:63)) denote a data set obtained by measuring a quantum system in a state ρ(cid:63). Given a
δ2r < 1. Let y =
good initialization point U0 and setting step size η and momentum µ appropriately, MiFGD converges with
an accelerated linear rate to a region—with radius that depends on O(µ)—around ρ(cid:63).

A

A

“Accelerated linear rate” intuitively means that MiFGD (provably) enjoys smaller contraction factor com-
pared to that of vanilla FGD. We refer to Theorem 2 of the Methods section for a formal statement. There,
we state the conditions under which the simple MiFGD recursion in Eqs. (14)-(15) has an accelerated linear
convergence rate in iterate distance, up to a constant error level proportional to the momentum parameter
(ρ(cid:63)), where
µ. The theorem assumes that the observations are noiseless; that is, the observed data is y =
ρ(cid:63) is the state of the system. Nevertheless, our experiments suggest that MiFGD is robust to statistical errors
and noise in the data. The formal analysis of robustness to noisy data can be derived from our analysis and
considered future work; here, for clarity, we consider this work as the basis for that analysis.

A

Experimental setup

ρ(cid:63) density matrices and quantum circuits6

In our numerical and real experiments, we have considered (different subsets of) the following n-qubit pure
quantum states:

1. The (generalized) GHZ state:

GHZ(n)
|

(cid:105)

0
= |

⊗n +
|
(cid:105)
√2

⊗n
1
(cid:105)

, n > 2.

2. The (generalized) GHZ-minus state:

GHZ−(n)
(cid:105)

|

0
(cid:105)

= |

⊗n

− |
√2

⊗n

1
(cid:105)

, n > 2.

5To see this, observe that ρ(cid:63) = U (cid:63)U (cid:63)† = U (cid:63)IU (cid:63)† = U (cid:63)RR†U (cid:63)† = (cid:98)U (cid:98)U †.
6The content in this subsection is implemented in the states.py component of our complementary software package.

4

3. The Hadamard state:

Hadamard(n)
|

(cid:105)

=

|

1
+
0
(cid:105)
|
√2

(cid:105)

⊗n

.

(cid:19)

(cid:18)

.

4. A random state

Random(n)
(cid:105)
|

|

−

−

GHZ(n)
(cid:105)
|

GHZ−(n)
(cid:105)

1 CNOT gates between this qubit (as a control) and the remaining n

We have implemented these states (on the IBM quantum simulator and/or the IBM’s QPU) using the fol-
is generated by applying the Hadamard gate to one of the qubits,
lowing circuits. The GHZ state
1 qubits (as
and then applying n
is generated by applying the X gate to one of the qubits (e.g., the
targets). The GHZ-minus state
1 CNOT gates
1 qubits, followed by applying n
ﬁrst qubit) and the Hadamard gate to the remaining n
1 qubits (as controls). Finally, we apply the Hadamard
between the ﬁrst qubit (as a target) and the other n
is a separable state, and it is generated by
gate to all of the qubits. The Hadamard state
applying the Hadamard gate to all of the qubits. The random state
is generated by a random
quantum gate selection: In particular, for a given circuit depth, we uniformly select among generic single-
qubit rotation gates with 3 Euler angles, and controlled-X gates, for every step in the circuit sequence. For
the rotation gates, the qubits involved are selected uniformly at random, as well as the angles from the
range [0, 1]. For the controlled-X gates, the source and target qubits are also selected uniformly at random.
. For clarity,
|
Random(n)
GHZ−(n)
.
we will drop the bra-ket notation when we refer to
,
(cid:105)
|
(cid:105)
n basis, the density matrix
While the density matrices of the GHZ(n) and GHZ−(n) are sparse in the
of Hadamard(n) state is fully-dense in this basis, and the sparsity of the density matrix that of Random(n)
may be different form one state to another.

as ρ(cid:63) =
|
Hadamard(n)
|
(cid:105)
0
{|

We generically denote the density matrix that correspond to pure state

Hadamard(n)
(cid:105)

Random(n)
(cid:105)

GHZ(n)
(cid:105)

ψ
(cid:105) (cid:104)
and

1
(cid:105)}

ψ
|

−

−

−

ψ

(cid:105)

(cid:105)

|

|

,

|

|

|

,

Measuring quantum states7

The quantum measurement model. In our experiments (both synthetic and real) we measure the qubits in the
Pauli basis [3].8 A Pauli basis measurement on an n-qubit system has d = 2n possible outcomes. The Pauli
basis measurement is uniquely deﬁned by the measurement setting. A Pauli measurement is a string of n
[n]. Note that there are at most 3n distinct
letters α := (α1, α2, . . . , αn) such that αk
Pauli strings. To deﬁne the Pauli basis measurement that associated with a given measurement string α, we
ﬁrst deﬁne the the following three bases on C2×2:

for all k

x, y, z

∈ {

∈

}

B

(cid:26)

+

:=

(
|

0
(cid:105)

x =

x, 0
(cid:105)
|

1
√2
1
√2
0
,
(cid:105)
|
These are the eigenbases of the single-qubit Pauli operators, σx, σy, and σz, whose 2
is given by:

)
(cid:27)
)
1
(cid:105)
|
(cid:27)

1
(cid:105)
|
1
:=
(cid:105)}
|

1
√2
1
√2

0
(
|
(cid:105)
z, 1
(cid:105)
|

y, 0
|
(cid:105)
z, 0

0
(cid:105) −
|

x, 1
(cid:105)

0
(
|

(cid:105) − |

),
(cid:105)

y =

z =

1
(cid:105)

y, 1

+ i

1
|

|
.

:=

:=

:=

:=

{|

(cid:26)

),

B

B

(

(cid:105)

(cid:105)

i

|

,

,

2 matrix representation

×

σx =

0 1
1 0

,

σy =

0
i

(cid:20)

i
−
0

(cid:21)

,

σz =

1
0
(cid:20)

0
1
(cid:21)

−

.

(cid:21)

(cid:20)

Given a Pauli setting α, the Pauli basis measurement Πα is deﬁned by the 2n projectors:

Πα =

(cid:40)

v(α)
(cid:96)

v(α)
(cid:96)

=

(cid:12)
(cid:12)
(cid:12)

(cid:69) (cid:68)

(cid:12)
(cid:12)
(cid:12)

n

k=1
(cid:79)

αk, (cid:96)k
|

αk, (cid:96)k

(cid:105) (cid:104)

: (cid:96)k

|

∈ {

0, 1

k

[1, n]

,

(cid:41)

∈

} ∀

where (cid:96) denotes the bit string ((cid:96)k1 , (cid:96)k2, . . . , (cid:96)kn ). Since there are 3n distinct Pauli measurement settings, there
are the same number of possible Pauli basis measurements.

7The content in this subsection is implemented in the measurements.py component of our complementary software package.
8This is the non-commutative analogue of the Fourier basis, for the case of sparse vectors [84, 19].

5

Technically, this set forms a positive operator-valued measure (POVM). The projectors that form Πα
v(α)
(cid:96)

v(α)
are the measurement outcomes (or POVM elements) and the probability to obtain an outcome
(cid:96)
|
ρ(cid:63)
–when the state of the system is ρ(cid:63)– is given by the Born rule:
.

= Tr

(cid:105)(cid:104)

|

v(α)
(cid:96)

ρ(cid:63)
|

v(α)
(cid:96)
|

(cid:105)

(cid:104)

v(α)
(cid:96)

|

(cid:105)(cid:104)

v(α)
(cid:96)

| ·

The RIP and expectation values of Pauli observables. Starting with the requirements of our algorithm, the sens-
(cid:1)
Cd×d, i = 1, . . . , m
ing mapping
matrices, such that yi = Tr(Aiρ(cid:63)). We denote the vector (y1, . . . , ym) by y.

(cid:0)
Rm we consider is comprised of a collection of Ai

) : Cd×d

(
·
A

→

∈

When no prior information about the quantum state is assumed, to ensure its (robust) recovery, one
must choose a set m sensing matrices Ai, so that d2 of them are linearly independent. One example of such
choice is the POVM elements of the 3n Pauli basis measurements.

Yet, when it is known that the state-to-be-reconstructed is of low-rank, theory on low-rank recovery
problems suggests that Ai could just be “incoherent” enough with respect to ρ(cid:63) [37], so that recovery is
d2. In particular, it is known [63, 37, 38] that
possible from a limited set of measurements, i.e., with m
poly (log d)) Ai’s are
if the sensing matrices correspond to random Pauli monomials, then m = O (r
d
sufﬁcient for a successful recovery of ρ(cid:63), using convex solvers for (1).9 A Pauli monomial Pi is an operator in
⊗n, that is, an n-fold tensor product of single-qubit Pauli operators (including the
the set Pi
identity operator). For convenience we relabel the single-qubit Pauli operators as σ0 := 1, σ1 := σx, σ2 :=
[n]. These
σy, and σ3 := σz, so that we can also write Pi =
∈ {
) obeys the RIP property, as
results [63, 37, 38] are feasible since the Pauli-monomial-based sensing map
(cid:78)
in Deﬁnition 1.10 For the rest of the text, we will use the term “Pauli expectation value” to denote Tr(Aiρ(cid:63)) =
Tr(Piρ(cid:63)).

n
k=1 σik with ik

0, . . . , 3
(
·
A

1, σx, σy, σz

for all k

∈ {

(cid:28)

∈

}

}

·

·

From Pauli basis measurements to Pauli expectation values. While the theory for compressed sensing was proven
for Pauli expectation values, in real QPUs, experimental data is obtained from Pauli basis measurements.
Therefore, to make sure we are respecting the compressed sensing requirements on the sensing map, we
follow this protocol:

i) We sample m = O (r

d

poly (log d)) or m = measpc

d2 Pauli monomials uniformly over

[0, 1] represents the percentage of measurements out of full

·

σi
{

⊗n
}

with i
tomography.

∈ {

, where measpc
0, . . . , 3
}

∈

·

·

ii) For every monomial, Pi, in the generated set, we identify an experimental setting α(i) that corre-
sponds to the monomial. There, qubits, for which their Pauli operator in Pi is the identity operator,
are measured, without loss of generality, in the σ3 basis. For example, for n = 3 and Pi = σ0
σ1,
we identify the measurement setting α(i) = (z, x, x).

σ1

⊗

⊗

iii) We measure the quantum state in the Pauli basis that corresponds to α(i), and record the outcomes.

To connect the measurement outcomes to the expectation value of the Pauli monomial, we use the relation:

Tr(Piρ(cid:63)) =

(

1)χ

−

f ((cid:96))

Tr

·

(cid:16)

v(α(i))
(cid:96)
|

(cid:105)(cid:104)

v(α(i))
(cid:96)

| ·

ρ(cid:63)

,

(cid:17)

(cid:88)(cid:96)∈{0,1}n

(8)

n

n is a mapping that takes a bit string (cid:96) and returns a new bit string ˜(cid:96) (of the
where f ((cid:96)) :
0, 1
}
{
same size) such that ˜(cid:96)k = 0 for all k’s for which ik = 0 (that is, the locations of the identity operators in Pi),
and χ˜(cid:96) is the parity of the bit string ˜(cid:96).

0, 1
}

→ {

Algorithmic setup

In our implementation, we explore a number of control parameters, including the maximum number of
iterations maxiters, the learning rate η, the relative error from successive state iterates reltol, the ac-
celeration parameter µ, the percentage of the complete set of measurements (i.e. over all possible Pauli

9The main difference between [37, 38] and [63] is that the former guarantees recovery for almost all choices of m =
O (r · d · poly (log d)) random Pauli monomials, while the latter proves that there exists a universal set of m = O (r · d · poly (log d))
Pauli monomials Ai that guarantees successful recovery.

10In particular, the RIP is satisﬁed for the sensing mechanisms that obeys (A(ρ(cid:63)))i = d√
m

Tr(A∗

i ρ(cid:63)), i = 1, . . . , m. Further, the case

considered in [63] holds for a slightly larger set than the set of rank-r density matrices: for all ρ ∈ Cd×d such that (cid:107)ρ(cid:107)∗ ≤

6

√

r(cid:107)ρ(cid:107)F .

×

monomials) measpc, and the seed. In the sequel experiments we set maxiters = 1000, η = 10−3,
10−4 unless stated differently. Regarding acceleration, µ = 0 when acceleration is muted;
reltol = 5
4 , 1
3 , 3
we experiment over the range of values µ
when investigating the acceleration effect, be-
4 }
yond the theoretically suggested µ(cid:63). In order to explore the dependence of our approach on the number
; seed is used for
of measurements available, measpc varies over the set of
}
differentiating repeating runs with all other parameters kept ﬁxed.11

5%, 10%, 15%, 20%, 40%, 60%

8 , 1

∈ {

{

1

Denoting

ρ the estimate of ρ(cid:63) by MiFGD, we report on outputs including:

ρ
• The evolution with respect to the distance between
(cid:107)
• The number of iterations to reach reltol to ρ(cid:63) for various µ’s.
• The ﬁdelity of
(cid:98)
default set.

ρ, deﬁned as Tr

ρ(cid:63)

(cid:98)

(cid:98)

ρ

ρ and ρ(cid:63):

ρ(cid:63)

−

F , for various µ’s.
(cid:107)

(for rank-1 ρ(cid:63)), as a function of the acceleration parameter µ in the

In our plots, we sweep over our default set of measpc values, repeat 5 times for each individual setup,
varying supplied seed, and depict their 25-, 50- and 75-percentiles.

(cid:98)

(cid:0)

(cid:1)
(cid:98)

Experimental setup on quantum processing unit (QPU)

We show empirical results on 6- and 8-qubit real data, obtained on the 20-qubit IBM QPU ibmq boeblingen.
The layout/connectivity of the device is shown in Figure 1. The 6-qubit data was from qubits [0, 1, 2, 3, 8, 9],
and the 8-qubit data was from [0, 1, 2, 3, 8, 9, 6, 4]. The T1 coherence times are [39.1, 75.7, 66.7, 100.0, 120.3, 39.2, 70.7, 132.3]
µs, and T2 coherence times are [86.8, 94.8, 106.8, 63.6, 156.5, 66.7, 104.5, 134.8] µs. The circuit for generating
6-qubit and 8-qubit GHZ states are shown in Fig 1. The typical two qubit gate errors measured from ran-
domized benchmarking (RB) for relevant qubits are summarized in Table 1.

C0X1
0.0072

C1X2
0.0062

C2X3
0.0087

C3X8
0.0077

C8X9
0.0152

C3X4
0.0167

C1X6
0.0133

Table 1: Two qubit error rates for the relevant gates used in generating 6-qubit and 8-qubit GHZ states on
ibmq boeblingen.

Figure 1: Left panel: Layout connectivity of IBM backend ibmq boeblingen; Middle and right panels:
Circuits used to generate 6-qubit state (left) and 8-qubit GHZ state (right). qbit refers to the quantum regis-
ters used in qiskit, and q corresponds to qubits on the real device.

The QST circuits were generated using the tomography module in qiskit-ignis.12 For complete
QST of a n-qubits state 3n circuits are needed. The result of each circuit is averaged over 8192, 4096 or
2048, for different n-qubit scenarios. To mitigate for readout errors, we prepare and measure all of the 2n
computational basis states in the computation basis to construct a calibration matrix C. C has dimension
2n by 2n, where each column vector corresponds to the measured outcome of a prepared basis state. In the
ideal case of no readout error, C is an identity matrix. We use C to correct for the measured outcomes of the
experiment by minimizing the function:

min
vcal∈Rd

Cvcal
(cid:107)

−

vmeas

2
(cid:107)

subject to

11maxiters

num iterations
complete measurements percentage.

is

in

the

code;

also

12https://github.com/Qiskit/qiskit-ignis.

7

i = 1, vcal
vcal

i ≥

0,

i = 1, . . . , d

∀

(9)

is

relative error tolerance,

measpc

is

i
(cid:88)
reltol

Here vmeas and vcal are the measured and calibrated outputs, respectively. The minimization problem is then
formulated as a convex optimization problem and solved by quadratic programming using the package
cvxopt [97].

MiFGD on 6- and 8-qubit real quantum data

We realize two types of quantum states on IBM QPUs, parameterized by the number of qubits n for each
case: these are the GHZ−(n) and Hadamard(n) circuits. We collected measurements over all possible Pauli
settings by repeating the experiment for each setting a number of times: these are the number of shots for
each setting. The (circuit, number of shots) measurement conﬁgurations from IBM Quantum devices are
summarized in Table 2.

(cid:107)

(cid:98)

−

ρ(cid:63)

# shots

In the Appendix, we provide target error list plots for the evolution
2
ρ
of
F for reconstructing all the settings in Table 2, both for real
(cid:107)
data and for simulated scenarios. Further, we provide plots that relate
the effect of momentum acceleration on the ﬁnal ﬁdelity observed for
these cases. For clarity, in Figure 2, we summarize the efﬁciency of mo-
mentum acceleration, by showing the reconstruction error only for the
10−4,
following settings: maxiters = 1000, η = 10−3, reltol = 5
and measpc = 20%. In the plots, µ = 0 corresponds to the FGD algo-
rithm in [79], µ(cid:63) corresponds to the value obtained through our theory,
to study the acceleration effect. For µ(cid:63), per
while we use µ
∈
our theory, we follow the rule µ(cid:63)
(0, 1]; see also the
≈
Methods section for more details.13 Note that, in most of the cases, the
µ(cid:63). We run each QST ex-
curve corresponding to µ = 0 is hidden behind the curve corresponding to µ
2
periment for 5 times for random initializations. We record the evolution of the
F error at each step,
(cid:107)
and stop when the relative error of successive iterates gets smaller than reltol or the number of iterations
exceeds maxiters (whichever happens ﬁrst). To implement measpc = 20%, we follow the description
given above Eq. (8) with m = measpc

Circuit
GHZ−(6)
GHZ−(6)
GHZ−(8)
GHZ−(8)
Hadamard(6)
Hadamard(8)

2048
8192
2048
4096
8192
4096

Table 2: QPU settings.

ε/2211 for ε

≈
ρ
(cid:107)

3 , 3

8 , 1

4 , 1

d2.

ρ(cid:63)

×

−

∈

(cid:9)

(cid:8)

(cid:98)

4

1

To highlight the level of noise existing in real quantum data, in Figure 3, we repeat the same setting
using the QASM simulator in qiskit-aer. This is a parallel, high performance quantum circuit simulator
written in C++ that can support a variety of realistic circuit level noise models.

Figure 2 summarizes the performance of our proposal on different ρ(cid:63), and for different µ values on
ρ
real IBM QPU data. All plots show the evolution of
F across iterations, featuring a steep dive to
(cid:107)
(cid:107)
convergence for the largest value of µ we tested: we report that we also tested µ = 0, which shows only
slight worse performances than µ(cid:63). Figure 2 highlights the universality of our approach: its performance is
oblivious to the quantum state reconstructed, as long as it satisﬁes purity or it is close to a pure state. Our
method does not require any additional structure assumptions in the quantum state.

ρ(cid:63)

−

(cid:98)

To highlight the effect of real noise on the performance of MiFGD, we further plot its performance on the
same settings but using measurements coming from an idealized quantum simulator. Figure 3 considers the
exact same settings as in Figure 2. It is obvious that MiFGD can achieve better reconstruction performance
when data are less erroneous. This also highlights that, in real noisy scenarios, the radius of the convergence
region of MiFGD around ρ(cid:63) is controlled mostly by the the noise level, rather than by the inclusion of
momentum acceleration.

Finally, in Figure 4, we depict the ﬁdelity of

, versus various
µ values and for different circuits (ρ(cid:63)). Shaded area denotes standard deviation around the mean over
repeated runs in all cases. The plots show the signiﬁcant gap in performance when using real quantum
data versus using synthetic simulated data within a controlled environment.

ρ achieved using MiFGD, deﬁned as Tr

(cid:1)
(cid:98)

(cid:98)

ρ

(cid:0)

ρ(cid:63)

13For this application, σr(ρ(cid:63)) = 1, τ (ρ(cid:63)) = 1, and r = 1 by construction; we also approximated κ = 1.223, which, for user-deﬁned
ε = 1, results in µ(cid:63) = 4.5 · 10−4. Note that smaller ε values result into a smaller radius of the convergence region; however, more
pessimistic ε values result into small µ, with no practical effect in accelerating the algorithm.

8

·

2
F versus method iterations using real IBM QPU data. Top-left:
Figure 2: Target error list plots
(cid:107)
GHZ−(6) with 2048 shots; Top-middle: GHZ−(6) with 8192 shots; Top-right: GHZ−(8) with 2048 shots;
Bottom-left: GHZ−(8) with 4096 shots/copies of ρ(cid:63); Bottom-middle: Hadamard(6) with 8192 shots; Bottom-
right: Hadamard(8) with 4096 shots. All cases have measpc = 20%. Shaded area denotes standard devia-
tion around the mean over repeated runs in all cases.

ρ
(cid:107)

ρ(cid:63)

−

(cid:98)

Performance comparison with full tomography methods in Qiskit

We compare MiFGD with publicly available implementations for QST reconstruction. Two common tech-
niques for QST, included in the qiskit-ignis distribution [81], are: i) the CVXPY ﬁtter method, that uses
the CVXPY convex optimization package [26, 5]; and ii) the lstsq method, that uses least-squares ﬁtting
[88]. Both methods solve the full tomography problem14 according to the following expression:

min
ρ∈Cd×d

subject to ρ

(cid:23)

f (ρ) := 1

(ρ)

2 (cid:107)A
−
0, Tr(ρ) = 1.

y

2
2
(cid:107)

(10)

(cid:23)

0, where U

We note that MiFGD is not restricted to “tall” U scenarios to encode PSD and rank constraints: even without
rank constraints, one could still exploit the matrix decomposition ρ = U U † to avoid the PSD projection,
ρ is rescaled using the method
ρ
proposed in [88]. For CVXPY, the convex constraint makes the optimization problem a semideﬁnite pro-
gramming (SDP) instance. By default, CVXPY calls the SCS solver that can handle all problems (including
SDPs) [73, 74]. Further comparison results with matrix factorization techniques from the machine learning
community is provided in the Appendix for n = 12.

Cd×d. For the lstsq ﬁtter method, the putative estimate

∈

(cid:98)

14In Ref. [49] it was sown that the minimization program (10) yields a robust estimation of low-rank states in the compressed
sensing. Thus, one can use CVXPY ﬁtter method to solve (10) with m (cid:28) d2 Pauli expectation value to obtain a robust reconstruction
of ρ(cid:63).

9

05001000Iterations6×10−11.2×100kbρ−ρ?k2Fµ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?05001000Iterations6×10−11.2×100kbρ−ρ?k2Fµ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?0100200Iterations1006×10−1kbρ−ρ?k2Fµ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?0100200Iterations1006×10−1kbρ−ρ?k2Fµ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?05001000Iterations100kbρ−ρ?k2Fµ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?0100200Iterations4×10−11.2×100kbρ−ρ?k2Fµ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?2
Figure 3: Target error list plots
F versus method iteration using synthetic IBM’s quantum simu-
lator data. Top-left: GHZ−(6) with 2048 shots; Top-middle: GHZ−(6) with 8192 shots; Top-right: GHZ−(8)
with 2048 shots; Bottom-left: GHZ−(8) with 4096 shots; Bottom-middle: Hadamard(6) with 8192 shots;
Bottom-right: Hadamard(8) with 4096 shots. All cases have measpc = 20%. Shaded area denotes standard
deviation around the mean over repeated runs in all cases.

ρ
(cid:107)

ρ(cid:63)

−

(cid:98)

(cid:107)

ρ to ρ(cid:63). From left to right: i) GHZ−(6) with
Figure 4: Fidelity list plots where we depict the ﬁdelity of
2048 shots; ii) GHZ−(6) with 8192 shots; iii) GHZ−(8) with 2048 shots; iv) GHZ−(8) with 4096 shots; v)
Hadamard(6) with 8192 shots; vi) Hadamard(8) with 4096 shots. All cases have measpc = 20%. Shaded
area denotes standard deviation around the mean over repeated runs in all cases.

(cid:98)

The settings we consider for full tomography are the following: GHZ(n), Hadamard(n) and Random(n)
quantum states (for n = 3, . . . , 8). We focus on ﬁdelity of reconstruction and computation timings perfor-
mance between CVXPY, lstsq and MiFGD. We use 100% of the measurements. We experimented with states

10

05001000Iterations10−1100kbρ−ρ?k2Fµ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?05001000Iterations10−1100kbρ−ρ?k2Fµ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?0100200Iterations10−1100kbρ−ρ?k2Fµ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?0100200Iterations10−1100kbρ−ρ?k2Fµ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?05001000Iterations10−1100kbρ−ρ?k2Fµ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?0100200Iterations10−1100kbρ−ρ?k2Fµ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?µ?18141334Momentumµ0.900.95Fidelityµ?18141334Momentumµ0.930.960.99µ?18141334Momentumµ0.800.88µ?18141334Momentumµ0.800.880.96µ?18141334Momentumµ0.00.40.8µ?18141334Momentumµ0.940.96QiskitsimulatorIBMQdevicesimulated in QASM and measured taking 2, 048 shots. For MiFGD, we set η = 0.001, µ = 3
4 , and stopping
criterion/tolerance reltol = 10−5. All experiments are run on a Macbook Pro with 2.3 GHz Quad-Core
Intel Core i7CPU and 32GB RAM.

The results are shown in Figure 5; higher-dimensional cases are provided in Table 3. Some notable
remarks: i) For small-scale scenarios (n = 3, 4), CVXPY and lstsq attain almost perfect ﬁdelity, while being
comparable or faster than MiFGD. ii) The difference in performance becomes apparent from n = 6 and on:
while MiFGD attains 98% ﬁdelity in < 5 seconds, CVXPY and lstsq require up to hundreds of seconds to
ﬁnd a good solution. iii) Finally, while MiFGD gets to high-ﬁdelity solutions in seconds for n = 7, 8, CVXPY
and lstsq methods could not ﬁnish tomography as their memory usage exceeded the system’s available
memory.

It is noteworthy that the reported ﬁdelities for MiFGD are the ﬁdelities at the last iteration, before the
stopping criterion is activated, or the maximum number of iterations is exceeded. However, the reported
ﬁdelity is not necessarily the best one during the whole execution: for all cases, we observe that MiFGD
ﬁnds intermediate solutions with ﬁdelity > 99%. Though, it is not realistic to assume that the iteration with
the best ﬁdelity is known a priori, and this is the reason we report only the ﬁnal iteration ﬁdelity.

Time (secs)
Fidelity
Method
Circuit
MiFGD
GHZ(7)
10.6709
0.969397
Hadamard(7) MiFGD
10.4926
0.969397
MiFGD
Random(7)
9.59607
0.968553
lstsq, CVXPY Memory limit exceeded
All above
MiFGD
GHZ(8)
35.0666
0.940389
Hadamard(8) MiFGD
37.5331
0.940390
MiFGD
Random(8)
36.3251
0.942815
lstsq, CVXPY Memory limit exceeded
All above

Table 3: Fidelity of reconstruction and computation timings using 100% of the complete measurements.
8), synthetic circuit, and tomographic method
Rows correspond to combinations of number of qubits (7
(MiFGD, Qiskit’s lstsq and CVXPY ﬁtters. 2048 shots per measurement circuit. For MiFGD, η = 0.001, µ = 3
4 ,
reltol = 10−5. All experiments are run on a 13” Macbook Pro with 2.3 GHz Quad-Core Intel Core i7 CPU
and 32 GB RAM.

∼

Figure 5: Fidelity versus time plots using synthetic IBM’s quantum simulator data. Left panel: GHZ−(n) for
n = 3, 4; Middle panel: Hadamard−(n) for n = 3, 4; Right panel: Random−(n) for n = 3, 4.

11

34567Numberofqubits0.970.980.991.00FidelityGHZ/MiFGDGHZ/CVXPYGHZ/lstsq34567Numberofqubits0.970.980.991.00FidelityHadamard/MiFGDHadamard/CVXPYHadamard/lstsq34567Numberofqubits0.970.980.991.00FidelityRandom/MiFGDRandom/CVXPYRandom/lstsq34567Numberofqubits05001000Time(secs)GHZ/MiFGDGHZ/CVXPYGHZ/lstsq34567Numberofqubits0200400Time(secs)Hadamard/MiFGDHadamard/CVXPYHadamard/lstsq34567Numberofqubits0200400Time(secs)Random/MiFGDRandom/CVXPYRandom/lstsqPerformance comparison of MiFGD with neural-network quantum state tomography

We compare the performance of MiFGD with neural network approaches. Per [93, 12, 94, 31], we model
a quantum state with a two-layer Restricted Boltzmann Machine (RBM). RBMs are stochastic neural net-
works, where each layer contains a number of binary stochastic variables: the size of the visible layer cor-
responds to the number of input qubits, while the size of the hidden layer is a hyperparameter controlling
the representation error. We experiment with three types of RBMs for reconstructing either the positive-real
wave function, the complex wave function, or the density matrix of the quantum state. In the ﬁrst two cases
the state is assumed pure while in the last, general mixed quantum states can be represented. We leverage
the implementation in QuCumber [12], PositiveRealWaveFunction (PRWF), ComplexWaveFunction
(CWF), and DensityMatrix (DM), respectively.

We reconstruct GHZ(n), Hadamard(n) and Random(n) quantum states (for n = 3, . . . , 8), by training

PRWF, CWF, and DM neural networks15 with measurements collected by the QASM Simulator.

For our setting, we consider measpc = 50% and shots = 2048. The set of measurements is presented
to the RBM implementation, along with the target positive-real wave function (for PRWF), complex wave-
function (for CWF) or the target density matrix (for DM) in a suitable format for training. We train Hadamard
and Random states with 20 epochs, and GHZ state with 100 epochs.16 We set the number of hidden variables
(and also of additional auxilliary variables for DM) to be equal to the number of input variables n and we use
100 data points for both the positive and the negative phase of the gradient (as per the recommendation for
the defaults). We choose k = 10 contrastive divergence steps and ﬁxed the learning rate to 10 (per hyperpa-
rameter tuning). Lastly, we limit the ﬁtting time of Qucumber methods (excluding data preparation time)
to be three hours. To compare to the RBM results, we run MiFGD with η = 0.001, µ = 3
4 , reltol = 10−5
and using measpc = 50%, keeping previously chosen values for all other hyperparameters.

We report the ﬁdelity of the reconstruction as a function of elapsed training time for n = 3, 4 in Figure
6 for PRWF, CWF, and DM. We observe that for all cases, Qucumber methods are orders of magnitude slower
than MiFGD. E.g., for n = 8, for all three states, CWF and DM did not ﬁnish a single epoch in 3 hours, while
MiFG achieves high ﬁdelity in less than 30 seconds. For the Hadamard(n) and Random(n), reaching rea-
sonable ﬁdelities is signiﬁcantly slower for both CWF and DM, while PRWF hardly improves its performance
throughout the training. For the GHZ case, CWF and DM also shows non-monotonic behaviors: even after a few
thousands of seconds, ﬁdelities have not “stabilized”, while PRWF stabilizes in very low ﬁdelities. In compar-
ison MiFGD is several orders of magnitude faster than both CWF and DM and ﬁdelity smoothly increases to
comparable or higher values. Further, in Table 4, we report ﬁnal ﬁdelities (within the 3 hour time window),
and reported times.

The effect of parallelization

We study the effect of parallelization in running MiFGD. We parallelize the iteration step across a number
of processes, that can be either distributed and network connected, or sharing memory in a multicore envi-
ronment. Our approach is based on Message Passing Interface (MPI) speciﬁcation [30], which is the lingua
franca for interprocess communication in high performance parallel and supercomputing applications. A
MPI implementation provides facilities for launching processes organized in a virtual topology and highly
tuned primitives for point-to-point and collective communication between them.

We assign to each process a subset of the measurement labels consumed by the parallel computation.
At each step, a process ﬁrst computes the local gradient-based corrections due only to its assigned Pauli
monomials and corresponding measurements. These local gradient-based corrections will then (i) need to
be communicated, so that they can be added, and (ii) ﬁnally, their sum will be shared across all processes
to produce a global update for U for next step. We accomplish this structure in MPI using MPI Allreduce
collective communication primitive with MPI SUM as its reduction operator: the underlying implementa-
tion will ensure minimum communication complexity for the operation (e.g. log p steps for p processes
organized in a communication ring) and thus maximum performance.17 We leverage mpi4py [25] bindings
to issue MPI calls in our parallel Python code.

15We utilize GPU (NVidia GeForce GTX 1080 TI,11GB RAM) for faster training of the neural networks.
16We experimented higher number of epochs (up to 500) for all cases, but after the reported number of epochs, Qucumber methods

did not improve, if not worsened.

17This communication pattern can alternatively be realized in two stages, as naturally suggested in its structure: (i) ﬁrst invoke

12

Circuit

GHZ(3)

Hadamard(3)

Random(3)

GHZ(4)

Hadamard(4)

Random(4)

GHZ(5)

Hadamard(5)

Random(5)

GHZ(6)

Hadamard(6)

Random(6)

GHZ(7)

Hadamard(7)

Random(7)

GHZ(8)

Hadamard(8)

Random(8)

Fidelity
Time (secs)
Fidelity
Time (secs)
Fidelity
Time (secs)
Fidelity
Time (secs)
Fidelity
Time (secs)
Fidelity
Time (secs)
Fidelity
Time (secs)
Fidelity
Time (secs)
Fidelity
Time (secs)
Fidelity
Time (secs)
Fidelity
Time (secs)
Fidelity
Time (secs)
Fidelity
Time (secs)
Fidelity
Time (secs)
Fidelity
Time (secs)
Fidelity
Time (secs)
Fidelity
Time (secs)
Fidelity
Time (secs)

MiFGD
0.997922
0.348652
0.997229
0.706872
0.991063
1.447057
0.996029
0.733128
0.996078
0.852895
0.998850
0.713302
0.992105
0.946350
0.992102
1.183290
0.995126
0.988173
0.984352
3.829866
0.984384
2.500354
0.989543
1.991154
0.969174
6.174129
0.969156
6.324469
0.967640
6.802577
0.940601
21.16011
0.940638
22.30246
0.939418
22.81059

FGD
0.997857
1.061421
0.994191
2.399405
0.988746
3.431218
0.996041
2.081035
0.996083
2.368223
0.998876
2.380326
0.992106
3.287358
0.992100
3.895312
0.995109
3.407487
0.984340
13.306954
0.984377
8.661999
0.989536
7.604232
0.969168
15.895504
0.969156
16.283301
0.967619
16.594162
0.940600
36.892739
0.940638
41.472961
0.939416
41.193810

Method
PRWF
0.314167
42.27607
0.912268
8.492405
0.074774
8.345135
0.204313
126.2749
0.894883
25.15520
0.152971
26.18863
0.132725
395.3379
0.869603
79.39444
0.015913
79.22450
0.089355
1167.985
0.842515
246.0011
0.143145
237.7037
0.058387
3633.082
0.818174
713.9404
0.141745
746.2630
0.0400391
> 3h
0.794892
2344.796
0.050521
2196.259

CWF
0.401737
1649.224
0.997914
325.7040
0.997493
322.4730
0.276491
10756.87
0.998071
2087.540
0.984164
2185.091
0.274665
> 3h
0.998246
9319.140
0.623273
9275.836
0.437323
> 3h
0.990849
> 3h
0.784873
> 3h
0.080648
> 3h
0.996586
> 3h
0.06568
> 3h
N/A
> 3h
N/A
> 3h
N/A
> 3h

DM
0.005389
3279.118
0.997222
656.6696
0.989754
640.8185
0.138459
> 3h
0.997389
4613.964
0.972877
4802.495
0.005138
> 3h
0.996516
> 3h
0.086777
> 3h
0.310067
> 3h
0.998077
> 3h
0.302534
> 3h
N/A
> 3h
N/A
> 3h
N/A
> 3h
N/A
> 3h
N/A
> 3h
N/A
> 3h

Table 4: Fidelity of reconstruction and computation timings using measpc = 50% and shots = 2048.
Rows correspond to combinations of number of qubits (3
8), ﬁnal ﬁdelity within the 3h time limit, and
computation time. For MiFGD, η = 0.001, µ = 3
4 , tol = 10−5. For FGD, η = 0.001, tol = 10−5. “N/A”
indicates that the method could not complete a single epoch in 3 hour training time limit, and thus could
not provide any ﬁdelity result. All experiments are run on a NVidia GeForce GTX 1080 TI, 11GB RAM.

∼

13

Figure 6: Fidelity versus time plots on MiFGD, PRWF, CWF, and DM, using synthetic IBM’s quantum simulator
data. Left panel: GHZ(n) for n = 3, 4; Middle panel: Hadamard(n) for n = 3, 4; Right panel: Random(n) for
n = 3, 4.

We conducted our parallel experiments on a server equipped with 4 x E7-4850 v2 CPUs @ 2.30GHz
(48/96 physical/virtual cores), 256 GB RAM, using shared memory multiprocessing over multiple cores.
We experimented with states simulated in QASM and measured taking 8, 192 shots; parallel MiFGD runs
with default parameters and using all measurements (measpc=100%). Reported times are wall-clock com-
putation time. These exclude initialization time for all processes to load Pauli monomials and measure-
ments: we here target parallelizing computation proper in MiFGD.

In our ﬁrst round of experiments, we investigate the scalability of our approach. We vary the number p of
parallel processes (p = 1, 2, 4, 8, 16, 32, 48, 64, 80, 96), collect timings for reconstructing GHZ(4), Random(6)
and GHZ−(8) states and report speedups Tp/T1 we gain from MiFGD in Figure 7(Left panel). We observe
that the beneﬁts of parallelization are pronounced for bigger problems (here: n = 8 qubits) and maximum
scalability results when we use all physical cores (48 in our platform).

Further, we move to larger problems (n = 10 qubits: reporting on reconstructing Hadamard(10) state)
and focus on the effect parallelization to achieving a given level of ﬁdelity in reconstruction. In Figure
7(Middle panel) we illustrate the ﬁdelity as a function of the time spent in the iteration loop of MiFGD for
(p = 8, 16, 32, 48, 64): we observe the smooth path to convergence in all p counts which again minimizes
compute time for p = 48. Note that in this case we use measpc = 10% and µ = 1
4 .

Finally, in Figure 7(Right panel), we ﬁx the number of processes to p = 48, in order to minimize compute
time and increase the percentage of used measurements to 20% of the total available for Hadamard(10). We
vary the acceleration parameter, µ = 0 (no acceleration) to µ = 1
4 and conﬁrm that we indeed get faster
convergence times in the latter case while the ﬁdelity value remains the same (i.e. coinciding upper plateau
value in the plots). We can also compare with the previous ﬁdelity versus time plot, where the same µ but
half the measurements are consumed: more measurements translate to faster convergence times (plateau is
reached roughly 25% faster; compare the green line with the yellow line in the previous plot).

MPI’s MPI Reduce primitive, with MPI SUM as its reduction operator, which results in the element-wise accumulation of local cor-
rections (vector sum) at a single, designated root process, and (ii) ﬁnally, send a “copy” of this sum from root process to each pro-
cess participating in the parallel computation (broadcasting); MPI Bcast primitive can be utilized for this latter stage. However,
MPI Allreduce is typically faster, since its actual implementation is not constrained by the requirement to have the sum available at
a speciﬁc, root process, at an intermediate time point - as the two-stage approach implies.

14

10−1101103Time(secs)0.000.250.500.751.00FidelityGHZ(3)/MiFGDGHZ(3)/PRWFGHZ(3)/CWFGHZ(3)/DM10−1101103Time(secs)0.40.60.81.0FidelityHadamard(3)/MiFGDHadamard(3)/PRWFHadamard(3)/CWFHadamard(3)/DM10−1101103Time(secs)0.250.500.751.00FidelityRandom(3)/MiFGDRandom(3)/PRWFRandom(3)/CWFRandom(3)/DM10−1101103Time(secs)0.000.250.500.751.00FidelityGHZ(4)/MiFGDGHZ(4)/PRWFGHZ(4)/CWFGHZ(4)/DM10−1101103Time(secs)0.40.60.81.0FidelityHadamard(4)/MiFGDHadamard(4)/PRWFHadamard(4)/CWFHadamard(4)/DM100102Time(secs)0.20.40.60.81.0FidelityRandom(4)/MiFGDRandom(4)/PRWFRandom(4)/CWFRandom(4)/DMFigure 7: Left panel: Scalability of our approach as we vary the number p of parallel processes. Middle
panel: Fidelity function versus time consumed for different number of processes p. Right panel: The effect
of momentum for a ﬁxed scenario with Hadamard(10) state, p = 48, and varying momentum from µ = 0 to
µ = 1
4 .

Discussion

We have introduced the MiFGD algorithm for the factorized form of the low-rank QST problems. We proved
that, under certain assumptions on the problem parameters, MiFGD converges linearly to a neighborhood
of the optimal solution, whose size depends on the momentum parameter µ, while using acceleration mo-
tions in a non-convex setting. We demonstrate empirically, using both simulated and real data, that MiFGD
outperforms non-accelerated methods on both the original problem domain and the factorized space, con-
tributing to recent efforts on testing QST algorithms in real quantum data [83]. These results expand on
existing work in the literature illustrating the promise of factorized methods for certain low-rank ma-
trix problems. Finally, we provide a publicly available implementation of our approach, compatible to the
open-source software Qiskit [81], where we further exploit parallel computations in MiFGD by extending
its implementation to enable efﬁcient, parallel execution over shared and distributed memory systems.

Despite our theory does not apply to the Pauli basis measurement directly (i.e., using randomly selected
Pauli bases Πα, does not lead to the (cid:96)2-norm RIP), using the data from random Pauli basis measurements
directly could provide excellent tomographic reconstruction with MiFGD. Preliminary results suggest that
log d) random Pauli bases should be taken for a reconstruction, with the same level of accuracy
only O(r
as with O(r
log d) expectation values of random Pauli matrices. We leave the analysis of our algorithm
in this case for future work, along with detailed experiments.

d

·

·

·

Related Work

Matrix sensing. The problem of low-rank matrix reconstruction from few samples was ﬁrst studied within
the paradigm of convex optimization, using the nuclear norm minimization [82, 60, 64]. The use of non-
convex approaches for low-rank matrix recovery—by imposing rank-constraints—has been proposed in
[47, 61, 56]. In all these works, the convex and non-convex algorithms involve a full, or at least a truncated,
singular value decomposition (SVD) per algorithm iteration. Since SVD can be prohibitive, these methods
are limited to relatively small system sizes.

Momentum acceleration methods are used regularly in the convex setting, as well as in machine learning
practical scenarios [53, 92, 53, 13, 72, 17, 34]. While momentum acceleration was previously studied in non-
convex programming setups, it mostly involve non-convex constraints with a convex objective function [55,
56, 52, 101]; and generic non-convex settings but only considering with the question of whether momentum
acceleration leads to fast convergence to a saddle point or to a local minimum, rather than to a global
optimum [33, 59, 20, 4].

The factorized version for semi-deﬁnite programming was popularized in [18]. Effectively the factor-
ization of a the set of PSD matrices to a product of rectangular matrices results in a non-convex setting.
This approach have been heavily studied recently, due to computational and space complexity advantages
[46, 21, 102, 103, 96, 78, 80, 89, 14, 15, 79, 32, 43, 57]. None of the works above consider the inclusion and anal-
ysis of momentum. Moreover, the Procrustes Flow approach [103, 96] uses certain initializations techniques,
and thus relies on multiple SVD computations. Our approach on the other hand uses a single, unique, top-r

15

0255075100Numberofprocesses051015SpeedupGHZ(4)Random(6)GHZMinus(8)020406080Time(secs)0.00.20.40.60.8Fidelity8procs16procs32procs48procs64procs010203040Time(secs)0.00.20.40.60.8Fidelity48procs,µ=048procs,µ=1/4SVD computation. Comparison results beyond QST are provided in the appendix.

Compressed sensing QST using non-convex optimization. There are only few works that study non-convex
optimization in the context of compressed sensing QST. The authors of [86] propose a hybrid algorithm
that i) starts with a conjugate-gradient (CG) algorithm in the factored space, in order to get initial rapid
descent, and ii) switch over to accelerated ﬁrst-order methods in the original ρ space, provided one can
determine the switch-over point cheaply. Using the multinomial maximum likelihood objective, in the ini-
tial CG phase, the Hessian of the objective is computed per iteration (i.e., a 4n
4n matrix), along with its
eigenvalue decomposition. Such an operation is costly, even for moderate values of qubit number n, and
heuristics are proposed for its completion. From a theoretical perspective, [86] provide no convergence or
convergence rate guarantees.

×

From a different perspective, [71] relies on spectrum estimation techniques [39, 22] and the Empirical
Young Diagram algorithm [8, 51] to prove that O(rd/ε) copies sufﬁce to obtain an estimate ˆρ that satisﬁes
ˆρ
ε; however, to the best of our knowledge, there is no concrete implementation of this technique
(cid:107)
to compare with respect to scalability.

2
F ≤

ρ(cid:63)

−

(cid:107)

Ref. [95] proposes an efﬁcient quantum tomography protocol by determining the permutationally in-
variant part of the quantum state. The authors determine the minimal number of local measurement set-
tings, which scales quadratically with the number of qubits. The paper determines which quantities have
to be measured in order to get the smallest uncertainty possible. See [67] for a more recent work on permu-
tationally invariant tomography. The method has been tested in a six-qubit experiment in [85].

Ref. [83] presented an experimental implementation of compressed sensing QST of a n = 7 qubit sys-
tem, where only 127 Pauli basis measurements are available. To achieve recovery in practice, the authors
proposed a computationally efﬁcient estimator, based on gradient descent method in the factorized space.
The authors of [83] focus on the experimental efﬁciency of the method, and provide no speciﬁc results on
the optimization efﬁciency, neither convergence guarantees of the algorithm. Further, there is no available
implementation publicly available.

Similar to [83], Ref. [57] also proposes a non-convex projected gradient decent algorithm that works on
the factorized space in the QST setting. The authors prove a rigorous convergence analysis and show that,
under proper initialization and step-size, the algorithm is guaranteed to converge to the global minimum
of the problem, thus ensuring a provable tomography procedure. Our results extend these results by including
acceleration techniques in the factorized space. The key contribution of our work is proving convergence of the
proposed algorithm in a linear rate to the global minimum of the problem, under common assumptions.
Proving our results required developing a whole set of new techniques, which are not based on a mere
extension of existing results.

Compressed sensing QST using convex optimization. The original formulation of compressed sensing QST [38]
is based on convex optimization methods, solving the trace-norm minimization, to obtain an estimation of
the low-rank state. It was later shown [49] that essentially any convex optimization program can be used to
robustly estimate the state. In general, there are two drawbacks in using convex optimization optimization
in QST. Firstly, as the dimension of density matrices grow exponentially in the number of qubits, the search
space in convex optimization grows exponentially in the number of qubits. Secondly, the optimization
requires projection onto the PSD cone at every iteration, which becomes exponentially hard in the number
of qubits. We avoid these two drawbacks by working in the factorized space. Using this factorization results in
a search space that is substantially smaller than its convex counterpart, and moreover, in a single use of
top-r SVD during the entire execution algorithm. Bypassing these drawbacks, together with accelerating
motions, allows us to estimate quantum states of larger qubit systems than state-of-the-art algorithms.

Full QST using non-convex optimization. The use of non-convex algorithms in QST was studied in the con-
text of full tomography as well. By “full tomography” we refer to the situation where an informationally
complete measurement is performed, so that the input data to the algorithm is of size 4n. The exponential
scaling of the data size restrict the applicability of full tomography to relatively small system sizes. In this
setting non-convex algorithms which work in the factored space were studied [10, 77, 99, 36, 91]. Except of
the work [36], we are not aware of theoretical results on the convergence of the proposed algorithm due
to the presence of spurious local minima. The authors of [36] characterize the local vs. the global behav-
ior of the objective function under the factorization ρ = U U † and discuss how existing methods fail due
to improper stopping criteria or due to the lack of algorithmic convergence results. Their work highlights

16

the lack of rigorous convergence results of non-convex algorithms used in full quantum state tomography.
There is no available implementation publicly available for these methods as well.

Full QST using convex optimization. Despite the non-scalability of full QST, and the limitation of convex op-
timization, a lot of research was devoted to this topic. Here, we mention only a few notable results that
extend the applicability of full QST using speciﬁc techniques in convex optimization. Ref [88] shows that
for given measurement schemes the solution for the maximum likelihood is given by a linear inversion
scheme, followed by a projection onto the set of density matrices. More recently, the authors of [42] used
a combination of the techniques of [88] with the sparsity of the Pauli matrices and the use of GPUs to per-
form a full QST of 14 qubits. While pushing the limit of full QST using convex optimization, obtaining full
tomographic experimental data for more than a dozen qubits is signiﬁcantly time-intensive. Moreover, this
approach is highly centralized, in comparison to our approach that can be distributed. Using the sparsity
pattern property of the Pauli matrices and GPUs is an excellent candidate approach to further enhance the
performance of non-convex compressed sensing QST.

QST using neural networks. Deep neural networks are ubiquitous, with many applications to science and
industry. Recently, [93, 12, 94, 31] show how machine learning and neural networks can be used to perform
QST, driven by experimental data. The neural network architecture used is based on restricted Boltzmann
machines (RBMs) [90], which feature a visible and a hidden layer of stochastic binary neurons, fully con-
nected with weighted edges. Test cases considered include reconstruction of W state, magnetic observables
of local Hamiltonians, the unitary dynamics induced by Hamiltonian evolution. Comparison results are
provided in the Main Results section. Alternative approaches include conditional generative adversarial
networks (CGANs) [7, 6]: in this case, two dueling neural networks, a generator and a discriminator, learn
to generate and identify multi-modal models from data.

QST for Matrix Product States (MPS). This is the case of highly structured quantum states where the state
is well-approximated by a MPS of low bond dimension [23, 58]. The idea behind this approach is, in or-
der to overcome exponential bottlenecks in the general QST case, we require highly structured subsets of
states, similar to the assumptions made in compressed sensing QST. MPS QST is considered an alternative
approach to reduce the computational and storage complexity of QST.

Direct ﬁdelity estimation. Rather than focusing on entrywise estimation of density matrices, the direct ﬁ-
delity estimation procedure focuses on checking how close is the state of the system to a target state, where
closeness is quantiﬁed by the ﬁdelity metric. Classic techniques require up to 2n/(cid:15)4 number of samples,
where (cid:15) denotes the accuracy of the ﬁdelity term, when considering a general quantum state [76, 45], but
can be reduced to almost dimensionality-free 1/(cid:15)2 number of samples for speciﬁc cases, such as stabilizer
states [29, 24, 50]. Shadow tomography is considered as an alternative and generalization of this technique
[1, 2]; however, as noted in [45], the procedure in [1, 2] requires exponentially long quantum circuits that
act collectively on all the copies of the unknown state stored in a quantum memory, and thus has not been
implemented fully on real quantum machines. A recent neural network-based implementation of such in-
direct QST learning methods is provided here [87].

The work in [76, 45], goes beyond simple ﬁdelity estimation, and utilizes random single qubit rotations
to learn a minimal sketch of the unknown quantum state by which one that can predict arbitrary linear
function of the state. Such methods constitute a favorable alternative to QST as they do not require number
of samples that scale polynomially with the dimension; however, this, in turn, implies that these methods
cannot be used in general to estimate the density matrix itself.

Methods

MiFGD algorithm. Algorithm 1 contains the details of the Momentum-Inspired Factored Gradient Descent.
The initial point U0 is either randomly selected [15, 80], or set according to Lemma 4 in [57] to:

ρ0 = U0U †

0 = ΠC

−1
1+δ2r · ∇

f (0)

= 1

1+δ2r

ΠC

(cid:0)

(cid:1)

m

yiAi

(cid:18)

i=1
(cid:88)

(cid:19)

(11)

17

Algorithm 1 Momentum-Inspired Factored Gradient Descent

, y, r, µ, and # iterations J.

A

Input:
Set U0 randomly or as in (11).
Set Z0 = U0.
Set η as in (12).
1 do
for i = 0 to J
−
†
Ui+1 = Zi
η
A
−
Zi+1 = Ui+1 + µ (Ui+1

(ZZ †)

A

−
Ui)

(cid:0)

−

end for
Output: ρ = UJ U †
J

y

Zi

·

(cid:1)

) is the projection onto the set of PSD matrices, δ2r
·

where ΠC(
f (0) denoted
the gradient of f evaluated at the all-zero matrix. Since computing the RIP constants is NP-hard, in practice
we compute U0 through ρ0 = −1
(1, 11/10], see Theorem 2 below. Compared to
, where
(cid:98)L
randomly selecting U0, Eq. 11 involves a gradient descent computation and a top-r eigenvalue calculation.
As for the step size in algorithm 1, following Lemma 4 below, it is set to

(0, 1) is the RIP constant and

m
i=1 yiAi

(cid:0) (cid:80)

ΠC

∇

L

∈

∈

(cid:98)

(cid:1)

η =

4((1+δ2r)(cid:107)Z0Z†

0 (cid:107)2+(cid:107)A†(A(Z0Z†

0 )−y)(cid:107)2)

1

,

(12)

where Z0 = U0. Here as well, in practice we replace δ2r by
L. The step size η remains constant at every
iteration step of the algorithm, and requires only two top-eigenvalue computations to calculate the spectral
norms
2. These computations can be efﬁciently implemented by any off-
(cid:107)
the-shelf eigenvalue solver, such as the Power Method or the Lanczos method.
(cid:1)

Z0Z †
0(cid:107)
(cid:107)

(Z0Z †

2 and

0 −

(cid:107)A

A

(cid:98)

y

(cid:0)

†

We now present the formal convergence theorem, where under certain conditions, MiFGD achieves an

accelerated linear rate.

Theorem 2 (Accelerated convergence rate). Assume that
U−1 be such that minR∈O (cid:107)U0 − U (cid:63)R(cid:107)F , minR∈O (cid:107)U−1 − U (cid:63)R(cid:107)F ≤
103
rank-r ρ, and σi(ρ) is the ith singular value of ρ. Set step size η such that

A

√

satisﬁes the RIP with constant δ2r
, where κ := 1+δ2r
1−δ2r

σr (ρ(cid:63))
√

κτ (ρ(cid:63))

1/10. Let U0 and
σr (ρ) for

≤
, τ (ρ) := σ1(ρ)

and the momentum parameter µ =
MiFGD returns a solution such that
(cid:18)

(cid:107)UJ+1 − U (cid:63)R(cid:107)F ≤

1 −

min
R∈O

√

√
1+δ2r−
√
√
2+1)
(

1−δ2r
1+δ2r

4

·

(cid:21)

1
(cid:20)

−

(cid:16)

ε

2·103rτ (ρ(cid:63))

(cid:17)
κ , for user-deﬁned ε

√

10
4σr(ρ(cid:63))(1−δ2r) ≤

η

≤

10
4σr(ρ(cid:63))(1−δ2r) ,

(0, 1]. For y =

∈

(ρ(cid:63)) where rank(ρ(cid:63)) = r,

A

(cid:19)J+1 (cid:18)

(cid:113) 1−δ2r
1+δ2r

min
R∈O

(cid:107)U0 − U (cid:63)R(cid:107)2

F + min
R∈O

(cid:107)U−1 − U (cid:63)R(cid:107)2
F

(cid:19)1/2

+ ξ · |µ| · σ1(ρ(cid:63))1/2 · r ·

(cid:32)

(cid:18)

1 −

1 −

(cid:113) 1−δ2r
1+δ2r

(cid:19)J+1(cid:33) (cid:18)

1 −

(cid:113) 1−δ2r
1+δ2r

(cid:19)−1

(cid:18)

1 −

(cid:47)

(cid:113) 1−δ2r
1+δ2r

(cid:19)J+1 (cid:18)

min
R∈O

(cid:107)U0 − U (cid:63)R(cid:107)2

F + min
R∈O

(cid:107)U−1 − U (cid:63)R(cid:107)2
F

(cid:19)1/2

+ O(µ),

(13)

where ξ =
up to a constant proportional to the momentum parameter µ.

−

1

4ησr(ρ(cid:63))(1−δ2r)
10

(cid:113)

. That is, the algorithm has an accelerated linear convergence rate in iterate distances

The interpretation of the theorem is that the right hand side of Eq. (13) depends on the initial distances

minR∈O

U0
(cid:107)

−

U (cid:63)R

F and minR∈O
(cid:107)

U−1
(cid:107)

−

U (cid:63)R

F as in convex optimization, where
(cid:107)

1

−

(cid:113)
as a contraction constant. In contrast, the contraction factor of vanilla FGD [57] is of the form
ignoring some constants.

(cid:16)

1−δ2r
1+δ2r

1

(cid:17)
−

(cid:16)

appear

1−δ2r
1+δ2r

,

(cid:17)

18

As we assume the sensing map
1+δ
1−δ , since the eigenvalues of the Hessian of f ,

satisﬁes RIP, the condition number of f depends on the RIP constants
δ such that L
δ and 1 + δ, when
restricted to low-rank matrices. Hence, MiFGD has better dependency on the (inverse) condition number
of f than FGD. Such improvement of the dependency on the condition number is called “acceleration” in
convex optimization [70, 20].

), lie between 1
·

µ ∝

†A(

A

A

−

Thus, assuming that the initial points U0 and U−1 are close enough to the optimum, as stated in the
theorem, MiFGD decreases its distance to U (cid:63) with an accelerated linear rate, up to an “error” level that
depends on the momentum parameter µ and it is bounded by

√

1

2·103rτ (ρ(cid:63))

κ .

Theorem 2 requires a strong assumption on the momentum parameter µ, which depends on quantities
that might not be known a priori for general problems. However, we note that for the special case of QST,
we know these quantities exactly: r is the rank of density matrix—thus, for pure states this value is equal
to r = 1; τ (ρ(cid:63)) is the (rank-restricted) condition number of the density matrix ρ—for pure states, τ (ρ(cid:63)) =
σr(ρ) = σ1(ρ)
σ1(ρ)
σ1(ρ) = 1; and, ﬁnally, κ is the condition number of the sensing map, where, given the constraint
ε/2211. However,
δ2r
as we show in the numerical experiments, the theory is conservative; much larger values of µ lead to stable,
improved performance. Finally, the bound on the condition number in Theorem 2 is not strict, and comes
out of the analysis we follow; we point the reader to similar assumptions made where τ (ρ(cid:63)) is assumed
constant O(1) [62].

11/9. The above lead to a momentum value µ

1/10, leads to the following bound: κ

≈

≤

≤

The detailed proof is provided in the supplementary material. To the best of our knowledge, this is the
ﬁrst proof for momentum-inspired factorization technique, under common assumptions: both regarding
the problem setting, and the assumptions made for its completion. The proof differs from state of the art
proofs for non-accelerated factored gradient descent: due to the inclusion of the memory term, three differ-
ent terms –Ui+1, Ui, Ui−1– need to be handled simultaneously. Further, the proof differs from recent proofs
on non-convex, but non-factored, gradient descent methods, as in [52]: the distance metric over rotations
minR∈O
F , where Zi includes estimates from two steps in history, is not amenable to simple
triangle inequality bounds, and a careful analysis is required. The analysis requires the design of two-
dimensional dynamical systems, where we require to characterize and bound the eigenvalues of a 2
2
contraction matrix.

Zi
(cid:107)

U (cid:63)R

×

−

(cid:107)

Acknowledgements

Anastasios Kyrillidis and Amir Kalev acknowledge funding by the NSF (CCF-1907936). Anastasios Kyril-
lidis thanks Mads Mikkelsen for his performance in “Jagten” and “Druk”.

Data availability

The empirical results were obtained via synthetic and real experiments; the algorithm’s implementation is
available at https://github.com/gidiko/MiFGD.

Competing interests

The authors declare no competing ﬁnancial or non-ﬁnancial interests.

Author contribution

All authors have made substantial contributions to the paper: design of the work, drafting the manuscript,
ﬁnal approval and accountability for all aspects of the work.

19

References

[1] Scott Aaronson. Shadow tomography of quantum states.

In Proceedings of the 50th Annual ACM

SIGACT Symposium on Theory of Computing, pages 325–338, 2018.

[2] Scott Aaronson and Guy N Rothblum. Gentle measurement of quantum states and differential pri-
vacy. In Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing, pages 322–333,
2019.

[3] P. Achuthan and K. Venkatesan. General principles of quantum mechanics. Handbuch der Physik,

5(Part 1), 1958.

[4] N. Agarwal, Z. Allen-Zhu, B. Bullins, E. Hazan, and T. Ma. Finding approximate local minima for

nonconvex optimization in linear time. arXiv preprint arXiv:1611.01146, 2016.

[5] A. Agrawal, R. Verschueren, S. Diamond, and S. Boyd. A rewriting system for convex optimization

problems. Journal of Control and Decision, 5(1):42–60, 2018.

[6] S. Ahmed, C. Mu ˜noz, F. Nori, and A. Kockum. Classiﬁcation and reconstruction of optical quantum

states with deep neural networks. arXiv preprint arXiv:2012.02185, 2020.

[7] S. Ahmed, C. S´anchez Mu ˜noz, F. Nori, and A. Kockum. Quantum state tomography with conditional

generative adversarial networks. arXiv preprint arXiv:2008.03240, 2020.

[8] Robert Alicki, Sl/awomir Rudnicki, and Sl/awomir Sadowski. Symmetry properties of product states

for the system of n n-level atoms. Journal of mathematical physics, 29(5):1158–1162, 1988.

[9] Joseph B Altepeter, Daniel FV James, and Paul G Kwiat. 4 qubit quantum state tomography.

In

Quantum state estimation, pages 113–145. Springer, 2004.

[10] K. Banaszek, G. M. D’Ariano, M. G. A. Paris, and M. F. Sacchi. Maximum-likelihood estimation of

the density matrix. Physical Review A, 61(1):010304, 1999.

[11] Konrad Banaszek, Marcus Cramer, and David Gross. Focus on quantum tomography. New Journal of

Physics, 15(12):125020, 2013.

[12] Matthew JS Beach, Isaac De Vlugt, Anna Golubeva, Patrick Huembeli, Bohdan Kulchytskyy, Xiuzhe
Luo, Roger G Melko, Ejaaz Merali, and Giacomo Torlai. Qucumber: wavefunction reconstruction
with neural networks. SciPost Physics, 7(1):009, 2019.

[13] A. Beck and M. Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse prob-

lems. SIAM journal on imaging sciences, 2(1):183–202, 2009.

[14] Srinadh Bhojanapalli, Anastasios Kyrillidis, and Sujay Sanghavi. Dropping convexity for faster semi-

deﬁnite optimization. In Conference on Learning Theory, pages 530–582, 2016.

[15] Srinadh Bhojanapalli, Behnam Neyshabur, and Nati Srebro. Global optimality of local search for low
rank matrix recovery. In Advances in Neural Information Processing Systems, pages 3873–3881, 2016.

[16] E. Bolduc, G. Knee, E. Gauger, and J. Leach. Projected gradient descent algorithms for quantum state

tomography. npj Quantum Information, 3(1):44, 2017.

[17] S. Bubeck, Y. T. Lee, and M. Singh. A geometric alternative to Nesterov’s accelerated gradient descent.

arXiv preprint arXiv:1506.08187, 2015.

[18] Samuel Burer and Renato DC Monteiro. A nonlinear programming algorithm for solving semideﬁnite

programs via low-rank factorization. Mathematical Programming, 95(2):329–357, 2003.

[19] E. Candes and T. Tao. Near-optimal signal recovery from random projections: Universal encoding

strategies? IEEE transactions on information theory, 52(12):5406–5425, 2006.

20

[20] Y. Carmon, J. Duchi, O. Hinder, and A. Sidford. Accelerated methods for non-convex optimization.

arXiv preprint arXiv:1611.00756, 2016.

[21] Yudong Chen and Martin J Wainwright. Fast low-rank estimation by projected gradient descent:

General statistical and algorithmic guarantees. arXiv preprint arXiv:1509.03025, 2015.

[22] Matthias Christandl and Graeme Mitchison. The spectra of quantum states and the kronecker coefﬁ-

cients of the symmetric group. Communications in mathematical physics, 261(3):789–797, 2006.

[23] M. Cramer, M. B. Plenio, S. T. Flammia, R. Somma, D. Gross, S. D. Bartlett, O. Landon-Cardinal,

D. Poulin, and Y.-K. Liu. Efﬁcient quantum state tomography. Nat. Comm., 1:149, 2010.

[24] Marcus P da Silva, Olivier Landon-Cardinal, and David Poulin. Practical characterization of quantum

devices without tomography. Physical Review Letters, 107(21):210404, 2011.

[25] Lisandro D Dalcin, Rodrigo R Paz, Pablo A Kler, and Alejandro Cosimo. Parallel distributed comput-

ing using python. Advances in Water Resources, 34(9):1124–1139, 2011.

[26] Steven Diamond and Stephen Boyd. CVXPY: A Python-embedded modeling language for convex

optimization. Journal of Machine Learning Research, 17(83):1–5, 2016.

[27] Jens Eisert, Dominik Hangleiter, Nathan Walk, Ingo Roth, Damian Markham, Rhea Parekh,
arXiv preprint

Ulysse Chabaud, and Elham Kasheﬁ. Quantum certiﬁcation and benchmarking.
arXiv:1910.06343, 2019.

[28] Steven T Flammia, David Gross, Yi-Kai Liu, and Jens Eisert. Quantum tomography via com-
pressed sensing: error bounds, sample complexity and efﬁcient estimators. New Journal of Physics,
14(9):095022, 2012.

[29] Steven T Flammia and Yi-Kai Liu. Direct ﬁdelity estimation from few pauli measurements. Physical

review letters, 106(23):230501, 2011.

[30] The MPI Forum. Mpi: A message passing interface. In Proceedings of the 1993 ACM/IEEE Conference
on Supercomputing, Supercomputing ’93, page 878–883, New York, NY, USA, 1993. Association for
Computing Machinery.

[31] Xun Gao and Lu-Ming Duan. Efﬁcient representation of quantum many-body states with deep neural

networks. Nature communications, 8(1):1–6, 2017.

[32] Rong Ge, Chi Jin, and Yi Zheng. No spurious local minima in nonconvex low rank problems: A

uniﬁed geometric analysis. arXiv preprint arXiv:1704.00708, 2017.

[33] S. Ghadimi and G. Lan. Stochastic ﬁrst-and zeroth-order methods for nonconvex stochastic program-

ming. SIAM Journal on Optimization, 23(4):2341–2368, 2013.

[34] G. Goh. Why momentum really works. Distill, 2017.

[35] D. Gonc¸alves, M. Gomes-Ruggiero, and C. Lavor. A projected gradient method for optimization over

density matrices. Optimization Methods and Software, 31(2):328–341, 2016.

[36] D. Gonc¸alves, M. Gomes-Ruggiero, C. Lavor, O. J. Farias, and P. Ribeiro. Local solutions of maxi-
mum likelihood estimation in quantum state tomography. Quantum Information & Computation, 12(9-
10):775–790, 2012.

[37] D. Gross. Recovering low-rank matrices from few coefﬁcients in any basis.

IEEE Transactions on

Information Theory, 57(3):1548–1566, 2011.

[38] D. Gross, Y.-K. Liu, S. Flammia, S. Becker, and J. Eisert. Quantum state tomography via compressed

sensing. Physical review letters, 105(15):150401, 2010.

21

[39] Masahito Hayashi and Keiji Matsumoto. Quantum universal variable-length source coding. Physical

Review A, 66(2):022311, 2002.

[40] Bingsheng He and Xiaoming Yuan. On the convergence rate of douglas–rachford operator splitting

method. Mathematical Programming, 153(2):715–722, 2015.

[41] R. Horn and Ch. Johnson. Matrix analysis. Cambridge university press, 1990.

[42] Zhibo Hou, Han-Sen Zhong, Ye Tian, Daoyi Dong, Bo Qi, Li Li, Yuanlong Wang, Franco Nori, Guo-
Yong Xiang, Chuan-Feng Li, et al. Full reconstruction of a 14-qubit state within four hours. New
Journal of Physics, 18(8):083036, 2016.

[43] Ya-Ping Hsieh, Yu-Chun Kao, Rabeeh Karimi Mahabadi, Yurtsever Alp, Anastasios Kyrillidis, and
Volkan Cevher. A non-euclidean gradient descent framework for non-convex matrix factorization.
Technical report, Institute of Electrical and Electronics Engineers, 2017.

[44] Zhilin Hu, Kezhi Li, Shuang Cong, and Yaru Tang. Reconstructing pure 14-qubit quantum states in
three hours using compressive sensing. IFAC-PapersOnLine, 52(11):188 – 193, 2019. 5th IFAC Confer-
ence on Intelligent Control and Automation Sciences ICONS 2019.

[45] Hsin-Yuan Huang, Richard Kueng, and John Preskill. Predicting many properties of a quantum sys-

tem from very few measurements. arXiv preprint arXiv:2002.08953, 2020.

[46] Prateek Jain and Inderjit S Dhillon.

Provable inductive matrix completion.

arXiv preprint

arXiv:1306.0626, 2013.

[47] Prateek Jain, Raghu Meka, and Inderjit S Dhillon. Guaranteed rank minimization via singular value

projection. In Advances in Neural Information Processing Systems, pages 937–945, 2010.

[48] Miroslav Jeˇzek, Jarom´ır Fiur´aˇsek, and Zdenˇek Hradil. Quantum inference of states and processes.

Physical Review A, 68(1):012305, 2003.

[49] A. Kalev, R. Kosut, and I. Deutsch. Quantum tomography protocols with positivity are compressed

sensing protocols. NPJ Quantum Information, 1:15018, 2015.

[50] Amir Kalev, Anastasios Kyrillidis, and Norbert M Linke. Validating and certifying stabilizer states.

Physical Review A, 99(4):042337, 2019.

[51] Michael Keyl and Reinhard F Werner. Estimating the spectrum of a density operator. In Asymptotic

Theory Of Quantum Statistical Inference: Selected Papers, pages 458–467. World Scientiﬁc, 2005.

[52] R. Khanna and A. Kyrillidis. IHT dies hard: Provable accelerated iterative hard thresholding. arXiv

preprint arXiv:1712.09379, 2017.

[53] D. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980,

2014.

[54] Martin Kliesch, Richard Kueng, Jens Eisert, and David Gross. Guaranteed recovery of quantum pro-

cesses from few measurements. Quantum, 3:171, 2019.

[55] A. Kyrillidis and V. Cevher. Recipes on hard thresholding methods. In Computational Advances in
Multi-Sensor Adaptive Processing (CAMSAP), 2011 4th IEEE International Workshop on, pages 353–356.
IEEE, 2011.

[56] A. Kyrillidis and V. Cevher. Matrix recipes for hard thresholding methods. Journal of mathematical

imaging and vision, 48(2):235–265, 2014.

[57] A. Kyrillidis, A. Kalev, D. Park, S. Bhojanapalli, C. Caramanis, and S. Sanghavi. Provable quantum

state tomography via non-convex methods. npj Quantum Information, 4(36), 2018.

22

[58] BP Lanyon, C Maier, Milan Holz¨apfel, Tillmann Baumgratz, C Hempel, P Jurcevic, Ish Dhand,
AS Buyskikh, AJ Daley, Marcus Cramer, et al. Efﬁcient tomography of a quantum many-body system.
Nature Physics, 13(12):1158–1162, 2017.

[59] J. Lee, M. Simchowitz, M. Jordan, and B. Recht. Gradient descent only converges to minimizers. In

Conference on Learning Theory, pages 1246–1257, 2016.

[60] Kiryung Lee and Yoram Bresler. Guaranteed minimum rank approximation from linear observations
by nuclear norm minimization with an ellipsoidal constraint. arXiv preprint arXiv:0903.4742, 2009.

[61] Kiryung Lee and Yoram Bresler. Admira: Atomic decomposition for minimum rank approximation.

IEEE Transactions on Information Theory, 56(9):4402–4416, 2010.

[62] Yuanxin Li, Cong Ma, Yuxin Chen, and Yuejie Chi. Nonconvex matrix factorization from rank-one

measurements. In International Conference on Artiﬁcial Intelligence and Statistics, 2019.

[63] Y.-K. Liu. Universal low-rank matrix recovery from Pauli measurements. In Advances in Neural Infor-

mation Processing Systems, pages 1638–1646, 2011.

[64] Zhang Liu and Lieven Vandenberghe. Interior-point method for nuclear norm approximation with
application to system identiﬁcation. SIAM Journal on Matrix Analysis and Applications, 31(3):1235–1256,
2009.

[65] L. Mirsky. A trace inequality of John von Neumann. Monatshefte f ¨ur mathematik, 79(4):303–306, 1975.

[66] Masoud Mohseni, AT Rezakhani, and DA Lidar. Quantum-process tomography: Resource analysis

of different strategies. Physical Review A, 77(3):032322, 2008.

[67] T. Moroder, P. Hyllus, G. T ´oth, C. Schwemmer, A. Niggebaum, S. Gaile, O. G ¨uhne, and H. Weinfurter.

Permutationally invariant state reconstruction. New Journal of Physics, 14(10):105001, 2012.

[68] S. Negahban and M. Wainwright. Restricted strong convexity and weighted matrix completion: Op-

timal bounds with noise. The Journal of Machine Learning Research, 13(1):1665–1697, 2012.

[69] Y. Nesterov. A method of solving a convex programming problem with convergence rate O( 1

k2 ). In

Soviet Mathematics Doklady, volume 27, pages 372–376, 1983.

[70] Y. Nesterov. Introductory lectures on convex optimization: A basic course, volume 87. Springer Science &

Business Media, 2013.

[71] Ryan O’Donnell and John Wright. Efﬁcient quantum tomography. In Proceedings of the forty-eighth

annual ACM symposium on Theory of Computing, pages 899–912, 2016.

[72] B. O’Donoghue and E. Candes. Adaptive restart for accelerated gradient schemes. Foundations of

computational mathematics, 15(3):715–732, 2015.

[73] B. O’Donoghue, E. Chu, N. Parikh, and S. Boyd. Conic optimization via operator splitting and homo-
geneous self-dual embedding. Journal of Optimization Theory and Applications, 169(3):1042–1068, June
2016.

[74] B. O’Donoghue, E. Chu, N. Parikh, and S. Boyd. SCS: Splitting conic solver, version 2.1.2. https:

//github.com/cvxgrp/scs, November 2019.

[75] Brendan O’Donoghue. Operator splitting for a homogeneous embedding of the linear complemen-

tarity problem. SIAM Journal on Optimization, 31:1999–2023, August 2021.

[76] Marco Paini, Amir Kalev, Dan Padilha, and Brendan Ruck. Estimating expectation values using ap-

proximate quantum states. Quantum, 5:413, Mar 2021.

[77] M. Paris, G. D’Ariano, and M. Sacchi. Maximum-likelihood method in quantum estimation. In AIP

Conference Proceedings, volume 568, pages 456–467. AIP, 2001.

23

[78] Dohyung Park, Anastasios Kyrillidis, Srinadh Bhojanapalli, Constantine Caramanis, and Sujay Sang-
havi. Provable burer-monteiro factorization for a class of norm-constrained matrix problems. arXiv
preprint arXiv:1606.01316, 2016.

[79] Dohyung Park, Anastasios Kyrillidis, Constantine Caramanis, and Sujay Sanghavi. Finding low-rank

solutions to matrix problems, efﬁciently and provably. arXiv preprint arXiv:1606.03168, 2016.

[80] Dohyung Park, Anastasios Kyrillidis, Constantine Caramanis, and Sujay Sanghavi. Non-square
arXiv preprint

matrix sensing without spurious local minima via the burer-monteiro approach.
arXiv:1609.03240, 2016.

[81] QISKit Development Team. Qiskit.

[82] Benjamin Recht, Maryam Fazel, and Pablo A Parrilo. Guaranteed minimum-rank solutions of linear

matrix equations via nuclear norm minimization. SIAM review, 52(3):471–501, 2010.

[83] C. Riofr´ıo, D. Gross, S.T. Flammia, T. Monz, D. Nigg, R. Blatt, and J. Eisert. Experimental quantum

compressed sensing for a seven-qubit system. Nature Communications, 8, 2017.

[84] M. Rudelson and R. Vershynin. On sparse reconstruction from Fourier and Gaussian measurements.
Communications on Pure and Applied Mathematics: A Journal Issued by the Courant Institute of Mathematical
Sciences, 61(8):1025–1045, 2008.

[85] C. Schwemmer, G. T ´oth, A. Niggebaum, T. Moroder, D. Gross, O. G ¨uhne, and H. Weinfurter. Ex-
perimental comparison of efﬁcient tomography schemes for a six-qubit state. Physical review letters,
113(4):040503, 2014.

[86] Jiangwei Shang, Zhengyun Zhang, and Hui Khoon Ng. Superfast maximum-likelihood reconstruc-

tion for quantum tomography. Phys. Rev. A, 95:062336, Jun 2017.

[87] A. Smith, Johnnie Gray, and M. Kim. Efﬁcient approximate quantum state tomography with basis

dependent neural-networks. arXiv preprint arXiv:2009.07601, 2020.

[88] J. A. Smolin, J. M. Gambetta, and G. Smith. Efﬁcient method for computing the maximum-likelihood
quantum state from measurements with additive Gaussian noise. Physical review letters, 108(7):070502,
2012.

[89] Ruoyu Sun and Zhi-Quan Luo. Guaranteed matrix completion via non-convex factorization. IEEE

Transactions on Information Theory, 62(11):6535–6579, 2016.

[90] Ilya Sutskever, Geoffrey E Hinton, and Graham W Taylor. The recurrent temporal restricted boltz-

mann machine. In Advances in neural information processing systems, pages 1601–1608, 2009.

[91] Y. S. Teo, J. ˇReh´aˇcek, and Z. Hradil.

Informationally incomplete quantum tomography. Quantum

Measurements and Quantum Metrology, 1, 2013.

[92] T. Tieleman and G. Hinton. Lecture 6.5-RMSPro: Divide the gradient by a running average of its

recent magnitude. COURSERA: Neural networks for machine learning, 4(2):26–31, 2012.

[93] Giacomo Torlai, Guglielmo Mazzola, Juan Carrasquilla, Matthias Troyer, Roger Melko, and Giuseppe

Carleo. Neural-network quantum state tomography. Nat. Phys., 14:447–450, May 2018.

[94] Giacomo Torlai and Roger Melko. Machine-learning quantum states in the NISQ era. Annual Review

of Condensed Matter Physics, 11, 2019.

[95] G. T ´oth, W. Wieczorek, D. Gross, R. Krischek, C. Schwemmer, and H. Weinfurter. Permutationally

invariant quantum tomography. Physical review letters, 105(25):250403, 2010.

[96] S. Tu, R. Boczar, M. Simchowitz, M. Soltanolkotabi, and B. Recht. Low-rank solutions of linear ma-
trix equations via Procrustes ﬂow. In Proceedings of the 33rd International Conference on International
Conference on Machine Learning-Volume 48, pages 964–973. JMLR. org, 2016.

24

[97] L. Vandenberghe. The CVXOPT linear and quadratic cone program solvers. Online: http://cvxopt.

org/documentation/coneprog. pdf, 2010.

[98] K Vogel and H Risken. Determination of quasiprobability distributions in terms of probability distri-

butions for the rotated quadrature phase. Physical Review A, 40(5):2847, 1989.

[99] J. ˇReh´aˇcek, Z. Hradil, E. Knill, and A. I. Lvovsky. Diluted maximum-likelihood algorithm for quan-

tum tomography. Phys. Rev. A, 75:042108, 2007.

[100] Andrew E Waters, Aswin C Sankaranarayanan, and Richard Baraniuk. Sparcs: Recovering low-rank
In Advances in neural information processing

and sparse matrices from compressive measurements.
systems, pages 1089–1097, 2011.

[101] Peng Xu, Bryan He, Christopher De Sa, Ioannis Mitliagkas, and Chris Re. Accelerated stochastic

power iteration. In International Conference on Artiﬁcial Intelligence and Statistics, pages 58–67, 2018.

[102] Tuo Zhao, Zhaoran Wang, and Han Liu. A nonconvex optimization framework for low rank matrix

estimation. In Advances in Neural Information Processing Systems, pages 559–567, 2015.

[103] Qinqing Zheng and John Lafferty. A convergent gradient descent algorithm for rank minimization
and semideﬁnite programming from random linear measurements. In Advances in Neural Information
Processing Systems, pages 109–117, 2015.

25

Appendix

IBM Quantum system experiments: GHZ−(6) circuit, 2048 shots

Figure 8: Target error list plots for reconstructing GHZ−(6) circuit using real measurements from IBM Quan-
tum system experiments.

Figure 9: Target error list plots for reconstructing GHZ−(6) circuit using synthetic measurements from IBM’s
quantum simulator.

Figure 10: Convergence iteration plots for reconstructing GHZ−(6) circuit using using real measurements
from IBM Quantum system experiments and synthetic measurements from Qiskit simulation experiments.

Figure 11: Fidelity list plots for reconstructing GHZ−(6) circuit using using real measurements from IBM
Quantum system experiments and synthetic measurements from Qiskit simulation experiments.

26

01000Iterations1.2×1001.4×100kbρ−ρ?k2F01000Iterations6×10−11.2×10001000Iterations6×10−11.2×10001000Iterations6×10−11.2×1000250Iterations6×10−11.2×1000200Iterations6×10−11.2×100µ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?01000Iterations1.2×1001.4×100kbρ−ρ?k2F01000Iterations1001.25×10001000Iterations1001.25×10001000Iterations10−11000500Iterations10−11000250Iterations10−1100µ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?µ?18141334Momentumµ8009001000Iterationsµ?18141334Momentumµ7008009001000µ?18141334Momentumµ6008001000µ?18141334Momentumµ200400600800µ?18141334Momentumµ100200300400µ?18141334Momentumµ50100150200GHZMinus/QiskitsimulatorGHZMinus/IBMQdeviceµ?18141334Momentumµ0.000.050.10Fidelityµ?18141334Momentumµ0.00.40.8µ?18141334Momentumµ0.00.40.8µ?18141334Momentumµ0.900.95µ?18141334Momentumµ0.920.96µ?18141334Momentumµ0.920.96GHZMinus/QiskitsimulatorGHZMinus/IBMQdeviceIBM Quantum system experiments: GHZ−(6) circuit, 8192 shots

Figure 12: Target error list plots for reconstructing GHZ−(6) circuit using real measurements from IBM
Quantum system experiments.

Figure 13: Target error list plots for reconstructing GHZ−(6) circuit using synthetic measurements from
IBM’s quantum simulator.

Figure 14: Convergence iteration plots for reconstructing GHZ−(6) circuit using using real measurements
from IBM Quantum system experiments and synthetic measurements from Qiskit simulation experiments.

Figure 15: Fidelity list plots for reconstructing GHZ−(6) circuit using using real measurements from IBM
Quantum system experiments and synthetic measurements from Qiskit simulation experiments.

27

01000Iterations1.2×1001.4×100kbρ−ρ?k2F01000Iterations1001.25×10001000Iterations1001.25×10001000Iterations6×10−11.2×1000250Iterations6×10−11.2×1000200Iterations6×10−11.2×100µ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?01000Iterations1.2×1001.4×100kbρ−ρ?k2F01000Iterations1001.25×10001000Iterations1001.25×10001000Iterations10−11000500Iterations10−11000250Iterations10−1100µ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?µ?18141334Momentumµ8009001000Iterationsµ?18141334Momentumµ7008009001000µ?18141334Momentumµ6008001000µ?18141334Momentumµ200400600800µ?18141334Momentumµ100200300400µ?18141334Momentumµ50100150200GHZMinus/QiskitsimulatorGHZMinus/IBMQdeviceµ?18141334Momentumµ0.000.040.08Fidelityµ?18141334Momentumµ0.00.10.20.3µ?18141334Momentumµ0.000.050.10µ?18141334Momentumµ0.930.960.99µ?18141334Momentumµ0.940.960.98µ?18141334Momentumµ0.940.960.98GHZMinus/QiskitsimulatorGHZMinus/IBMQdeviceIBM Quantum system experiments: GHZ−(8) circuit, 2048 shots

Figure 16: Target error list plots for reconstructing GHZ−(8) circuit using real measurements from IBM
Quantum system experiments.

Figure 17: Target error list plots for reconstructing GHZ−(8) circuit using synthetic measurements from
IBM’s quantum simulator.

Figure 18: Convergence iteration plots for reconstructing GHZ−(8) circuit using using real measurements
from IBM Quantum system experiments and synthetic measurements from Qiskit simulation experiments.

Figure 19: Fidelity list plots for reconstructing GHZ−(8) circuit using using real measurements from IBM
Quantum system experiments and synthetic measurements from Qiskit simulation experiments.

28

01000Iterations1006×10−1kbρ−ρ?k2F0500Iterations1006×10−10200Iterations1006×10−10200Iterations1006×10−10100Iterations1006×10−1050Iterations1006×10−1µ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?01000Iterations100kbρ−ρ?k2F0500Iterations1000200Iterations10−11000200Iterations10−11000100Iterations10−1100050Iterations10−1100µ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?µ?18141334Momentumµ4006008001000Iterationsµ?18141334Momentumµ200400µ?18141334Momentumµ100200300µ?18141334Momentumµ100150200µ?18141334Momentumµ406080100µ?18141334Momentumµ4060GHZMinus/QiskitsimulatorGHZMinus/IBMQdeviceµ?18141334Momentumµ0.70.80.9Fidelityµ?18141334Momentumµ0.80.9µ?18141334Momentumµ0.80.9µ?18141334Momentumµ0.80.9µ?18141334Momentumµ0.80.9µ?18141334Momentumµ0.80.9GHZMinus/QiskitsimulatorGHZMinus/IBMQdeviceIBM Quantum system experiments: GHZ−(8) circuit, 4096 shots

Figure 20: Target error list plots for reconstructing GHZ−(8) circuit using real measurements from IBM
Quantum system experiments.

Figure 21: Target error list plots for reconstructing GHZ−(8) circuit using synthetic measurements from
IBM’s quantum simulator.

Figure 22: Convergence iteration plots for reconstructing GHZ−(8) circuit using using real measurements
from IBM Quantum system experiments and synthetic measurements from Qiskit simulation experiments.

Figure 23: Fidelity list plots for reconstructing GHZ−(8) circuit using using real measurements from IBM
Quantum system experiments and synthetic measurements from Qiskit simulation experiments.

29

01000Iterations1006×10−1kbρ−ρ?k2F0500Iterations1006×10−10200Iterations1006×10−10200Iterations1006×10−10100Iterations1006×10−1050Iterations1006×10−1µ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?01000Iterations10−1100kbρ−ρ?k2F0500Iterations10−11000200Iterations10−11000200Iterations10−11000100Iterations10−1100050Iterations10−1100µ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?µ?18141334Momentumµ4006008001000Iterationsµ?18141334Momentumµ200400µ?18141334Momentumµ100200µ?18141334Momentumµ50100150200µ?18141334Momentumµ406080100µ?18141334Momentumµ4060GHZMinus/QiskitsimulatorGHZMinus/IBMQdeviceµ?18141334Momentumµ0.80.9Fidelityµ?18141334Momentumµ0.80.9µ?18141334Momentumµ0.800.880.96µ?18141334Momentumµ0.800.880.96µ?18141334Momentumµ0.800.880.96µ?18141334Momentumµ0.800.880.96GHZMinus/QiskitsimulatorGHZMinus/IBMQdeviceIBM Quantum system experiments: Hadamard(6) circuit, 8192 shots

Figure 24: Target error list plots for reconstructing Hadamard(6) circuit using real measurements from IBM
Quantum system experiments.

Figure 25: Target error list plots for reconstructing Hadamard(6) circuit using synthetic measurements from
IBM’s quantum simulator.

Figure 26: Convergence iteration plots for reconstructing Hadamard(6) circuit using using real measure-
ments from IBM Quantum system experiments and synthetic measurements from Qiskit simulation.

Figure 27: Fidelity list plots for reconstructing Hadamard(6) circuit using using real measurements from
IBM Quantum system experiments and synthetic measurements from Qiskit simulation experiments.

30

01000Iterations1.2×1001.4×100kbρ−ρ?k2F01000Iterations1.2×1001.4×10001000Iterations10001000Iterations1000500Iterations10−11000200Iterations10−1100µ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?01000Iterations1.2×1001.4×100kbρ−ρ?k2F01000Iterations1.2×1001.4×10001000Iterations10−110001000Iterations10−11000250Iterations10−11000200Iterations10−1100µ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?µ?18141334Momentumµ8009001000Iterationsµ?18141334Momentumµ6008001000µ?18141334Momentumµ4006008001000µ?18141334Momentumµ2505007501000µ?18141334Momentumµ200400µ?18141334Momentumµ100200Hadamard/QiskitsimulatorHadamard/IBMQdeviceµ?18141334Momentumµ0.000.050.10Fidelityµ?18141334Momentumµ0.000.050.10µ?18141334Momentumµ0.250.500.751.00µ?18141334Momentumµ0.00.51.0µ?18141334Momentumµ0.9850.9900.995µ?18141334Momentumµ0.9880.9920.996Hadamard/QiskitsimulatorHadamard/IBMQdeviceIBM Quantum system experiments: Hadamard(8) circuit, 4096 shots

Figure 28: Target error list plots for reconstructing Hadamard(8) circuit using real measurements from IBM
Quantum system experiments.

Figure 29: Target error list plots for reconstructing Hadamard(8) circuit using synthetic measurements from
IBM’s quantum simulator.

Figure 30: Convergence iteration plots for reconstructing Hadamard(8) circuit using using real measure-
ments from IBM Quantum system experiments and synthetic measurements from Qiskit simulation.

Figure 31: Fidelity list plots for reconstructing Hadamard(8) circuit using using real measurements from
IBM Quantum system experiments and synthetic measurements from Qiskit simulation experiments.

31

01000Iterations6×10−11.2×100kbρ−ρ?k2F0500Iterations6×10−11.2×1000200Iterations6×10−11.2×1000200Iterations6×10−11.2×1000100Iterations6×10−11.2×100050Iterations6×10−11.2×100µ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?01000Iterations10−1100kbρ−ρ?k2F0500Iterations10−11000200Iterations10−11000200Iterations10−11000100Iterations10−1100050Iterations10−1100µ=0µ=1/8µ=1/4µ=1/3µ=3/4µ=µ?µ?18141334Momentumµ4006008001000Iterationsµ?18141334Momentumµ200400µ?18141334Momentumµ100200300µ?18141334Momentumµ100150200µ?18141334Momentumµ406080100µ?18141334Momentumµ405060Hadamard/QiskitsimulatorHadamard/IBMQdeviceµ?18141334Momentumµ0.80.9Fidelityµ?18141334Momentumµ0.920.940.96µ?18141334Momentumµ0.940.96µ?18141334Momentumµ0.940.96µ?18141334Momentumµ0.940.96µ?18141334Momentumµ0.940.96Hadamard/QiskitsimulatorHadamard/IBMQdeviceSynthetic experiments for n = 12

We compare MiFGD with i) the Matrix ALPS framework [56], a state of the art projected gradient descent
algorithm, and an optimized version of matrix iterative hard thresholding, operating on the full matrix variable
ρ, with adaptive step size η (we note that this algorithm has outperformed most of the schemes that work
on the original space ρ; see [56]); ii) the plain Procrustes Flow/FGD algorithm [96, 14, 57], where we use
the step size as reported in [14], since the later has reported better performance than vanilla Procrustes
Flow. We note that the Procrustes Flow/FGD algorithm is similar to our algorithm without acceleration. Further, the
original Procrustes Flow/FGD algorithm relies on performing many iterations in the original space ρ as an
initialization scheme, which is often prohibitive as the problem dimensions grow. Both for our algorithm
and the plain Procrustes Flow/FGD scheme, we use random initialization.

To properly compare the algorithms in the above list, we pre-select a common set of problem parameters.
We ﬁx the dimension d = 4096 (equivalent to n = 12 qubits), and the rank of the optimal matrix ρ(cid:63)
Rd×d
to be r = 10 (equivalent to a mixed quantum state reconstruction). Similar behavior has been observed for
other values of r, and are omitted. We ﬁx the number of observables m to be m = c
. In
}
all algorithms, we ﬁx the maximum number of iterations to 4000, and we use the same stopping criterion:
(cid:107)ρi+1 − ρi(cid:107)F /(cid:107)ρi(cid:107)F ≤ tol = 10−3. For the implementation of MiFGD, we have used the momentum parameter
µ = 2

3 , as well as the theoretical µ value.

r, where c

3, 5

∈ {

∈

d

·

·

Figure 32: Synthetic example results on low-rank matrix sensing in higher dimensions (equivalent to n = 12
qubits). Top row: Convergence behavior vs. time elapsed. Bottom row: Convergence behavior vs. number
of iterations. Left panel: c = 5, noiseless case; Center panel: c = 3, noiseless case; Right panel: c = 5, noisy
case,

w
(cid:107)

2 = 0.01.
(cid:107)

A

The procedure to generate synthetically the data is as follows: The observations y are set to y =

(ρ(cid:63))+w
for some noise vector w; while the theory holds for the noiseless case, we show empirically that noisy cases
are robustly handled by the same algorithm. We use permuted and subsampled noiselets for the linear
Rd×r such
[100]. The optimal matrix ρ(cid:63) is generated as the multiplication of a tall matrix U (cid:63)
operator
that ρ(cid:63) = U (cid:63)U (cid:63)(cid:62), and
F = 1, without loss of generality. The entries of U (cid:63) are drawn i.i.d. from a
Gaussian distribution with zero mean and unit variance. In the noisy case, w has the same dimensions
2 = 0.01. The random
with y, its entries are drawn from a zero mean Gaussian distribution with norm
initialization is deﬁned as U0 drawn i.i.d. from a Gaussian distribution with zero mean and unit variance.
The results are shown in Figure 32. Some notable remarks: i) While factorization techniques might take
more iterations to converge compared to non-factorized algorithms, the per iteration time complexity is
much less, such that overall, factorized gradient descent converges more quickly in terms of total execution

ρ(cid:63)
(cid:107)

A

w

∈

(cid:107)

(cid:107)

(cid:107)

32

05010015020010-310-210-11000500100010-310-210-11000500100010-310-210-110005010015020025010-310-210-1100020040060010-310-210-1100020040060010-310-210-1100time. ii) Our proposed algorithm, even under the restrictive assumptions on acceleration parameter µ, performs
better than the non-accelerated factored gradient descent algorithms, such as Procrustes Flow. iii) Our
theory is conservative: using a much larger µ we obtain a faster convergence; the proof for less strict as-
sumptions for µ is an interesting future direction. In all cases, our ﬁndings illustrate the effectiveness of the
proposed schemes on different problem conﬁgurations.

Asymptotic complexity comparison of lstsq, CVXPY, and MiFGD

We ﬁrst note that lstsq can be only applied to the case we have a full tomographic set of measure-
ments; this makes lstsq algorithm inapplicable in the compressed sensing scenario, where the number
of measurements can be signiﬁcantly reduced. Yet, we make the comparison by providing information-
theoretically complete set of measurements to lstsq and CVXPY, as well as to MiFGD, to highlight the
efﬁciency of our proposed method, even in the scenario that is not exactly intended in our work. Given
this, we compare in detail the asymptotic scailing of MiFGD with lstsq and CVXPY below:

• lstsq is based on the computation of eigenvalues/eigenvector pairs (among other steps) of a matrix
of size equal to the density matrix we want to reconstruct. Based on our notation, the density matrices
2n. Here, n is the number of qubits in the quantum system.
are denoted as ρ with dimensions 2n
Standard libraries for eigenvalue/eigenvector calculations, like LAPACK, reduce a Hermitian matrix
to tridiagonal form using the Householder method, which takes overall a O
computational
complexity. The other steps in the lstsq procedure either take constant time, or O(2n) complexity.
Thus, the actual run-time of an implementation depends on the eigensystem solver that is being used.

(2n)3

×

(cid:0)

(cid:1)

• CVXPY is distributed with the open source solvers; for the case of SDP instances, CVXPY utilizes the
Splitting Conic Solver (SCS)18, a general numerical optimization package for solving large-scale con-
vex cone problems. SCS applies Douglas-Rachford splitting to a homogeneous embedding of the
quadratic cone program. Based on the PSD constraint, this again involves the computation of eigen-
values/eigenvector pairs (among other steps) of a matrix of size equal to the density matrix we want
to reconstruct. This takes overall a O
computational complexity, not including the other steps
performed within the SCS solver. This is an iterative algorithm that requires such complexity per iter-
ation. Douglas-Rachford splitting methods enjoy O( 1
ε ) convergence rate in general [40, 73, 75]. This
1
leads to a rough O((2n)3
ε ) overall iteration complexity.19

(2n)3

(cid:1)

(cid:0)

·

• For MiFGD, and for sufﬁciently small momentum value, we require O(√κ

ε )) iterations to get
close to the optimal value. Per iteration, MiFGD does not involve any expensive eigensystem solvers,
but relies only on matrix-matrix and matrix-vector multiplications. In particular, the main computa-
tional complexity per iteration origins from the iteration:

·

log( 1

Ui+1 = Zi

−
Zi+1 = Ui+1 + µ (Ui+1

A

(cid:16)

η

†
A

(ZiZ †
i )

Zi,

y

·

(cid:17)

−
Ui) .

(14)

(15)

∈

(ZiZ †

(ZiZ †
i )
i ))j = Tr(AjZiZ †

R2n×r for all i. Observe that
[m], (

Here, Ui, Zi
dently. For an index j
computing
† : Rm

−
Rm where each element is computed indepen-
i ) requires O((2n)2
r) complexity, and thus
r) complexity, overall. By deﬁnition the adjoing operation
−
†
is still domi-
satisﬁes:
A
r) complexity. Finally, we perform one more matrix-matrix multiplication with Zi,
(cid:16)
r) complexity. The rest of the operations involve adding
r matrices, which does not dominate the overall complexity. Combining the iteration complexity

A
nated by O((2n)2
(cid:80)
which results into an additional O((2n)2
2n
with the per-iteration computational complexity, MiFGD has a O((2n)2

∈
A
y requires O((2n)2
·
m
i=1 xiAi; thus, the operation

(ZiZ †
i )
A
C2n×2n

(ZiZ †
i )

†(x) =

log( 1

→

A

A

A

−

×

∈

(cid:17)

y

·

·

·

ε )) complexity.

√κ

r

·

·

·

18https://github.com/cvxgrp/scs
19This is an optimistic complexity bound since we have skipped several details within the Douglas-Rachford implementation of

CVXPY.

33

Combining the above, we summarize the following complexities:

O((2n)3)

vs

lstsq

O((2n)3

1
ε )

·

CVXPY

vs

O((2n)2

·

r

√κ

·
MiFGD

log( 1

ε ))

·

Observe that i) MiFGD has the best dependence on the number of qubits and the ambient dimension
of the problem, 2n; ii) MiFGD applies to cases that lstsq is inapplicable; iii) MiFGD has a better iteration
complexity than other iterative algorithms, while has a better polynomial dependency on 2n.

(cid:123)(cid:122)

(cid:123)(cid:122)

(cid:124)

(cid:125)

(cid:125)

(cid:124)

(cid:124)

(cid:123)(cid:122)

(cid:125)

Detailed proof of Theorem 2

Ui−1 and Z

Zi. Let us start with the following equality. For

We ﬁrst denote U+
RZ

≡

as the minimizer of minR∈O

≡

Ui, U−
Z

Ui+1, U

≡
U (cid:63)R

∈ O

U+

U (cid:63)RZ

U (cid:63)RZ
Z
(cid:107)
The proof focuses on how to bound the last part on the right-hand side. By deﬁnition of U+, we get:

2
F
(cid:107)
U (cid:63)RZ

2
F =
=

Z, U (cid:63)RZ

2
F −

2
(cid:104)

U+

U+

−

−

−

−

−

−

Z

Z

(cid:107)

(cid:107)

(cid:107)

(cid:107)

(cid:107)

(cid:105)

−

(cid:107)
U+

≡

F , we have:
(cid:107)
Z + Z
2
F +
(cid:107)

−

U+
(cid:104)

−

Z, U (cid:63)RZ

Z

(cid:105)

−

=

Z

= η
(cid:10)

−
†
A
(cid:10)

(ZZ †)

η

†
A

A

A
(ZZ †)
(cid:0)

y

−

y

Z

−
Z, Z
(cid:1)

−

Z, U (cid:63)RZ

−
U (cid:63)RZ

Z

−

(cid:11)

(cid:0)

(cid:1)

(cid:11)

Observe the following:
A† (cid:16)

A(ZZ †) − y

(cid:68)

(cid:17)

Z, Z − U (cid:63)RZ

(cid:69)

(cid:68)

(cid:68)

=

=

= 1
2

= 1
2

By Lemmata 5 and 6, we have:

2 U (cid:63)U (cid:63)† − U (cid:63)RZ Z †(cid:69)

A† (cid:16)
A† (cid:16)
A† (cid:16)
(cid:68)
(cid:68)

A(ZZ †) − y

(cid:17)

, ZZ † − U (cid:63)RZ Z †(cid:69)

A(ZZ †) − y

(cid:17)

A(ZZ †) − y

2 U (cid:63)U (cid:63)† + 1

, ZZ † − 1
, ZZ † − U (cid:63)U (cid:63)†(cid:69)
(cid:17)
(cid:17)

A† (cid:16)

(cid:68)

A(ZZ †) − y
(cid:17)

+
A† (cid:16)
A(ZZ †) − y
A† (cid:16)
(cid:68)

A(ZZ †) − y

+ 1
2

2 (ZZ † + U (cid:63)U (cid:63)†) − U (cid:63)RZ Z †(cid:69)
, 1

, ZZ † − U (cid:63)U (cid:63)†(cid:69)

(cid:17)

, (Z − U (cid:63)RZ )(Z − U (cid:63)RZ )†(cid:69)

(cid:107)U+ − U (cid:63)RZ (cid:107)2

F + (cid:107)Z − U (cid:63)RZ (cid:107)2

F − 2(cid:104)U+ − Z, U (cid:63)RZ − Z(cid:105)

F = (cid:107)U+ − Z(cid:107)2
= η2(cid:107)A† (cid:16)
(cid:68)

− η

(cid:17)

A(ZZ †) − y
A† (cid:16)
(cid:68)

A(ZZ †) − y
A† (cid:16)

F + (cid:107)Z − U (cid:63)RZ (cid:107)2
Z(cid:107)2
F
, ZZ † − U (cid:63)U (cid:63)†(cid:69)
(cid:17)

A(ZZ †) − y

(cid:17)

, (Z − U (cid:63)RZ )(Z − U (cid:63)RZ )†(cid:69)

− η
≤ η2(cid:107)A† (cid:16)

A(ZZ †) − y

Z(cid:107)2

(cid:17)

− 1.0656η2 (cid:13)
(cid:13)A†(A(ZZ †) − y)Z
(cid:13)

F + (cid:107)Z − U (cid:63)RZ (cid:107)2
F
(cid:13)
(cid:13)
(cid:13)

− η 1−δ2r

2

2

F

(cid:32)

(cid:107)U (cid:63)U (cid:63)† − ZZ †(cid:107)2
F

+ η

θσr(ρ(cid:63)) · (cid:107)Z − U (cid:63)RZ (cid:107)2
F

+ 1

200 β2 · (cid:98)η ·

(cid:18)

Next, we use the following lemma:

(cid:19)2

+2|µ|

(cid:19)2 · (cid:107)A†(A(ZZ †) − y) · Z(cid:107)2

F

(cid:33)

(cid:18) 3
2
(cid:18) 3
2

1−

+2|µ|

(cid:19) 1
103

34

(16)

(17)

(18)

(19)

(20)

(21)

(22)

(23)

(24)

(25)

(26)

(27)

(28)

(29)

(30)

(31)

(32)

(33)

Lemma 1. [96, Lemma 5.4] For any W, V

Cd×r, the following holds:

∈
(cid:107)W W † − V V †(cid:107)2
F ≥ 2(

√

2 − 1) · σr(V V †) · min
R∈O

(cid:107)W − V R(cid:107)2
F .

From Lemma 1, the quantity
√

(cid:107)U (cid:63)U (cid:63)† − ZZ †(cid:107)2

F ≥ 2(

ZZ †

U (cid:63)U (cid:63)†
(cid:107)
−
2 − 1) · σr(ρ(cid:63)) · min
R∈O

2
F satisﬁes:
(cid:107)

(cid:107)Z − U (cid:63)R(cid:107)2

F = 2(

√

2 − 1) · σr(ρ(cid:63)) · (cid:107)Z − U (cid:63)RZ (cid:107)2
F ,

which, in our main recursion, results in:

(cid:107)U+ − U (cid:63)RZ (cid:107)2

F ≤ η2(cid:107)A† (cid:16)

A(ZZ †) − y

Z(cid:107)2

(cid:17)

− 1.0656η2 (cid:13)
(cid:13)A†(A(ZZ †) − y)Z
(cid:13)

F + (cid:107)Z − U (cid:63)RZ (cid:107)2
F
√
(cid:13)
(cid:13)
(cid:13)

− η(

2

F

2 − 1)(1 − δ2r)σr(ρ(cid:63))(cid:107)Z − U (cid:63)RZ (cid:107)2
F

(cid:32)

(cid:32)

+ η

θσr(ρ(cid:63)) · (cid:107)Z − U (cid:63)RZ (cid:107)2
F

+ 1

200 β2 · (cid:98)η ·

(cid:18)

(cid:19)2

+2|µ|

(cid:19)2 · (cid:107)A†(A(ZZ †) − y) · Z(cid:107)2

F

(cid:33)

(cid:18) 3
2
(cid:18) 3
2

1−

+2|µ|

(cid:19) 1
103

(i)

≤ η2(cid:107)A† (cid:16)

A(ZZ †) − y

(cid:17)

Z(cid:107)2

− 1.0656η2 (cid:13)
(cid:13)A†(A(ZZ †) − y)Z
(cid:13)

F + (cid:107)Z − U (cid:63)RZ (cid:107)2
F
√
(cid:13)
(cid:13)
(cid:13)

− η(

2

F

2 − 1)(1 − δ2r)σr(ρ(cid:63))(cid:107)Z − U (cid:63)RZ (cid:107)2
F

+ η

θσr(ρ(cid:63)) · (cid:107)Z − U (cid:63)RZ (cid:107)2
F

+ 1

200 β2 · 10

9 η ·

(cid:18)

(cid:19)2

+2|µ|

(cid:19)2 · (cid:107)A†(A(ZZ †) − y) · Z(cid:107)2

F

(cid:33)

(cid:18) 3
2
(cid:18) 3
2

1−

+2|µ|

(cid:19) 1
103


1 + 1

200 β2 · 10
9 ·

(cid:18)

(ii)
=

(cid:19)2 − 1.0656


 η2(cid:107)A†(A(ZZ †) − y) · Z(cid:107)2

F

(cid:18) 3
2
(cid:18) 3
2

1−

(cid:19)2

+2|µ|

(cid:19) 1
103

+2|µ|
√

(cid:16)

+

1 + ηθσr(ρ(cid:63)) − η(

2 − 1)(1 − δ2r)σr(ρ(cid:63))

(cid:17)

(cid:107)Z − U (cid:63)RZ (cid:107)2
F

where (i) is due to Lemma 4, and (ii) is due to the deﬁnition of U+.
√

Under the facts that µ = σr (ρ(cid:63))1/2
κτ (ρ(cid:63))

4·σ1(ρ(cid:63))1/2·r , for ε

103

·

ε

∈

constant quantities in our proof so far simplify into:

(0, 1) user-deﬁned, and δ2r

1
10 , the main

≤

by Corollary 3. Thus:

β =

1 +
1

−

(cid:0)
(cid:0)

3
2 + 2
3
2 + 2

µ
|
|
µ
|
|

1
103
1
103

·
·

(cid:1)
(cid:1)

= 1.003,

and β2 = 1.006,

1 + 1

200 β2

10
9 ·

·

(cid:16)

1−

(cid:17)2

(cid:16) 3

2 +2|µ|
2 +2|µ|

(cid:16) 3

(cid:17) 1
103

1.0656

(cid:17)2 −

0.0516,

≤ −

and our recursion becomes:
(cid:107)U+ − U (cid:63)RZ (cid:107)2

F ≤ −0.0516 · η2 · (cid:107)A†(A(ZZ †) − y) · Z(cid:107)2
F

(cid:16)
1 + ηθσr(ρ(cid:63)) − η(

+

(cid:17)
2 − 1)(1 − δ2r)σr(ρ(cid:63))

(cid:107)Z − U (cid:63)RZ (cid:107)2
F

√

Finally,

θ =

(cid:18)

(1−δ2r )

1+

+2|µ|

(cid:19) 1
103

(cid:19)2

+ (1 + δ2r) (cid:0)2 + (cid:0) 3

2 + 2|µ|(cid:1) · 1

103

(cid:18) 3
2
103

(cid:18)

(cid:1) (cid:0) 3

2 + 2|µ|(cid:1) · 1
103


(i)
= (1 − δ2r) ·



1+(

3
2

+2|µ|)

(cid:19)2

1
103

103

+ κ (cid:0)2 + (cid:0) 3

2 + 2|µ|(cid:1) · 1

103

(cid:1) (cid:0) 3

2 + 2|µ|(cid:1) · 1

103



≤ 0.0047 · (1 − δ2r).

35

(34)

(35)

(36)

(37)

(38)

(39)

(40)

(41)

(42)

(43)

(44)

(45)

(46)

(47)

(48)

(49)

(50)

(51)

(52)

where (i) is by the deﬁnition of κ := 1+δ2r
our main inequality, we obtain:

1−δ2r ≤

1.223 for δ2r

≤

1
10 , by assumption. Combining the above in

(cid:107)U+ − U (cid:63)RZ (cid:107)2

F ≤ −0.0516 · η2 · (cid:107)A†(A(ZZ †) − y) · Z(cid:107)2
F

(cid:16)
1 + ησr(ρ(cid:63))(1 − δ2r) · (0.0047 −

+

(cid:16)

≤

1 − 4ησr (ρ(cid:63))(1−δ2r )

10

(cid:17)

(cid:107)Z − U (cid:63)RZ (cid:107)2
F

√

(cid:17)

2 + 1)

(cid:107)Z − U (cid:63)RZ (cid:107)2
F

Taking square root on both sides, we obtain:

(cid:107)U+ − U (cid:63)RZ (cid:107)F ≤

(cid:113)

1 − 4ησr (ρ(cid:63))(1−δ2r )

10

· (cid:107)Z − U (cid:63)RZ (cid:107)F

4ησr(ρ(cid:63))(1−δ2r)
10

. Using the deﬁnitions Z = U + µ(U

U−) and RZ

−

∈

Let us deﬁne ξ =
U (cid:63)R

F , we get
(cid:107)

1

(cid:113)

−

(53)

(54)

arg min

Z

R∈O (cid:107)

−

(cid:107)U+ − U (cid:63)RZ (cid:107)F ≤ ξ · min
R∈O

(cid:107)Z − U (cid:63)R(cid:107)F = ξ · min
R∈O

(cid:107)U + µ(U − U−) − U (cid:63)R(cid:107)F

= ξ · min
R∈O

(cid:107)U + µ (U − U−) − (1 − µ + µ)U (cid:63)R(cid:107)F

(i)
≤ ξ · |1 + µ| · min
R∈O

(cid:107)U − U (cid:63)R(cid:107)F + ξ · |µ| · min
R∈O

(cid:107)U− − U (cid:63)R(cid:107)F + ξ · |µ| · rσ1(ρ(cid:63))1/2

where (i) follows from steps similar to those in Lemma 3. Further observe that minR∈O
U+
(cid:107)

U (cid:63)RZ

−

U+
(cid:107)

−

U (cid:63)R

F
(cid:107)

≤

F , thus leading to:
(cid:107)
(cid:107)U+ − U (cid:63)R(cid:107)F ≤ ξ · |1 + µ| · min
R∈O

min
R∈O

(cid:107)U − U (cid:63)R(cid:107)F + ξ · |µ| · min
R∈O

(cid:107)U− − U (cid:63)R(cid:107)F + ξ · |µ| · rσ1(ρ(cid:63))1/2

(55)

Including two subsequent iterations in a single two-dimensional ﬁrst-order system, we get the following
characterization:

(cid:20)minR∈O (cid:107)Ui+1 − U (cid:63)R(cid:107)F
minR∈O (cid:107)Ui − U (cid:63)R(cid:107)F

(cid:21)

(cid:20)ξ · |1 + µ|
1

≤

ξ · |µ|
0

(cid:21)

(cid:20) minR∈O (cid:107)Ui − U (cid:63)R(cid:107)F
minR∈O (cid:107)Ui−1 − U (cid:63)R(cid:107)F

·

(cid:21)

Now, let xj = minR∈O

(cid:21)

(cid:20)1
0

+

· ξ · |µ| · σ1(ρ(cid:63))1/2 · r.

U (cid:63)R

−

F . Then, we can write the above relation as
(cid:107)

1 + µ
|
1

· |

ξ

≤

(cid:20)

ξ

µ
|

· |
0

xi
xi−1

(cid:20)

+

1
0
(cid:21)

(cid:20)

(cid:21)

·

(cid:21)

ξ

·

µ

| ·

· |

σ1(ρ(cid:63))1/2

r,

·

:=A

Uj
(cid:107)
xi+1
xi

(cid:20)

(cid:21)

where we denote the “contraction matrix” by A. Taking norms on both sides, we get

(cid:123)(cid:122)

(cid:125)

(cid:124)

(56)

(57)

xi+1
xi

(cid:20)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

2 ≤
(cid:21)(cid:13)
(cid:13)
(i)
(cid:13)
(cid:13)

A

A

·

·

≤

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
≤ (cid:107)

(ii)

xi
xi−1

(cid:20)

(cid:21)

+

xi
xi−1

(cid:20)

2
(cid:21)(cid:13)
(cid:13)
xi
(cid:13)
(cid:13)
xi−1

A

(cid:107)2 ·

(cid:20)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
0
(cid:20)

+

(cid:21)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
2
(cid:21)(cid:13)
(cid:13)
(cid:13)
(cid:13)

ξ

·

µ

| ·

· |

σ1(ρ(cid:63))1/2

r

·

1
0
(cid:21)
(cid:20)

+

ξ

·

µ

| ·

· |

2
(cid:13)
(cid:13)
(cid:13)
σ1(ρ(cid:63))1/2
(cid:13)

r

·

2
(cid:13)
(cid:13)
(cid:13)
σ1(ρ(cid:63))1/2
(cid:13)

·

ξ

·

µ

| ·

· |

1
0
(cid:21)
(cid:20)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

r

,

(58)

where (i) is by triangle inequality, and (ii) is by Cauchy–Schwarz inequality.

Therefore, the convergence rate will be determined by the (maximum) eigenvalue of the contraction

matrix A, which is given by

λ1,2 =

ξ

· |

1 + µ
|
2

± (cid:114)

ξ2(1 + µ)2
4

+ ξ

µ
|

· |

(i)
=
⇒

max

λ1, λ2
{

}

= λ1 =

ξ

· |

1 + µ
|
2

+

(cid:114)

ξ2(1 + µ)2
4

+ ξ

,

µ
|

· |

36

where (i) follows since every term in λ1,2 is positive.

To show accelerated convergence rate, we want the above eigenvalue (which determines the conver-

gence rate) to be bounded by 1
follows:

−

(cid:113)

1−δ2r
1+δ2r

. To show this, ﬁrst note that this term is bounded above as

λ1 =

ξ

· |

1 + µ
|
2

+

ξ2(1 + µ)2
4

+ ξ

µ
|

· |

(cid:114)

(i)

≤
(ii)

≤
(ii)

≤

ξ +

ξ2 + ξ

(cid:112)

ξ +

2ξ

(cid:112)
(√2 + 1)

ξ,

where (i) is by the conventional bound on momentum: 0 < µ < 1, and (ii) is by the relation ξ2
0

1. Therefore, to show the accelerated rate of convergence, we want the following relation to hold:

√ξ for

≤

≤

ξ

ξ

(cid:112)

≤

≤

(√2 + 1)

ξ

1

−

≤

(cid:112)

1−δ2r
1+δ2r ⇐⇒

ξ

≤

(cid:112)

(cid:113)

√1 + δ2r

√1

−
(√2 + 1)√1 + δ2r

−

δ2r

.

(59)

Recalling our deﬁnition of ξ =
, the problem boils down to choosing the right step size
η such that the above inequality on ξ in Eq. (59) is satisﬁed. With simple algebra, we can show the following
lower bound on η:

(cid:113)

−

1

4ησr(ρ(cid:63))(1−δ2r)
10

1

(cid:34)

−

(cid:18)

√1 + δ2r
√1
−
(√2 + 1)√1 + δ2r (cid:19)

δ2r

−

4

10
4σr(ρ(cid:63))(1

(cid:35) ·

η

δ2r) ≤

−

Finally, the argument inside the √
the following upper bound on η:

·

term of ξ =

1

(cid:113)

4ησr(ρ(cid:63))(1−δ2r)
10

−

> 0 has to be non-negative, yielding

10
4σr(ρ(cid:63))(1

η

≤

.

δ2r)

−

Combining two inequalities, and noting that the term

arrive at the following bound on η:

1
(cid:20)

−

(cid:16)

√

√
1+δ2r−
√
√
2+1)
(

1−δ2r
1+δ2r

is bounded above by 1, we

4

(cid:21)

(cid:17)

√1 + δ2r
√1
−
(√2 + 1)√1 + δ2r (cid:19)
In sum, for the speciﬁc η satisfying the above bound, we have shown that

10
4σr(ρ(cid:63))(1

δ2r) ≤

(cid:35) ·

δ2r

≤

−

−

−

(cid:18)

(cid:34)

1

η

10
4σr(ρ(cid:63))(1

4

λ1 =

ξ

· |

1 + µ
|
2

+

ξ2(1 + µ)2
4

(cid:114)

+ ξ

µ

| ≤

· |

1

− (cid:114)

1
δ2r
−
1 + δ2r

Above translates our original recursion in (58) as:

xi+1
xi

(cid:20)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

2 ≤ (cid:107)
(cid:21)(cid:13)
(cid:13)
(cid:13)
(cid:13)

A

(cid:107)2 ·

≤

=

1

1

−

−

(cid:18)

(cid:18)

xi
xi−1

(cid:20)
1−δ2r
1+δ2r

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:113)

2
(cid:21)(cid:13)
(cid:13)
(cid:13)
(cid:13)
·
(cid:19)

1−δ2r
1+δ2r

·

(cid:19)

(cid:113)

(cid:13)
(cid:20)
(cid:13)
xi
(cid:13)
(cid:13)
xi−1

xi
xi−1

+

(cid:20)

(cid:20)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
0
(cid:21)

ξ

·

· |

+

(cid:13)
(cid:13)
(cid:13)
+ ξ
(cid:13)

2
(cid:21)(cid:13)
(cid:13)
(cid:13)
(cid:13)
2
(cid:21)(cid:13)
(cid:13)
(cid:13)
(cid:13)

| ·
1
0
(cid:21)

(cid:20)

µ

σ1(ρ(cid:63))1/2

r

·

2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

σ1(ρ(cid:63))1/2

ξ

·

µ

| ·

· |

µ

| ·

· |

σ1(ρ(cid:63))1/2

r,

·

where the last equality is by the deﬁnition of (cid:96)2-norm.

.

δ2r)

−

(60)

r

·

2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(61)

37

Unrolling the recursion in Eq. (61) for J iterations, we get

xJ+1
xJ

(cid:20)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

2 ≤
(cid:21)(cid:13)
(cid:13)
(cid:13)
(cid:13)

=

=

1
(cid:18)

1
(cid:18)

1
(cid:18)

J+1

J+1

J+1

1−δ2r
1+δ2r

1−δ2r
1+δ2r

1−δ2r
1+δ2r

(cid:19)

(cid:19)

(cid:19)

−

(cid:113)

−

−

(cid:113)

(cid:113)

x0
x−1

x0
x−1

x0
x−1

(cid:20)

(cid:20)

(cid:20)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

2
(cid:21)(cid:13)
(cid:13)
(cid:13)
(cid:13)

2
(cid:21)(cid:13)
(cid:13)
(cid:13)
(cid:13)
2
(cid:21)(cid:13)
(cid:13)
(cid:13)
(cid:13)

+ ξ

µ

| ·

· |

σ1(ρ(cid:63))1/2

+ ξ

µ

| ·

· |

σ1(ρ(cid:63))1/2

·

·

+ O(µ)

J

r

·

1
i=0 (cid:18)
(cid:88)

−

(cid:113)

1−δ2r
1+δ2r

i

(cid:19)

J+1

−1

r

1
· (cid:32)

−

1
(cid:18)

−

(cid:113)

1−δ2r
1+δ2r

(cid:19)

(cid:33) (cid:18)

1

−

1−δ2r
1+δ2r

(cid:113)

(cid:19)

Finally, computing the (cid:96)2-norm explicitly and resubstituting xj = minR∈O

Uj
(cid:107)

−

U (cid:63)R

(cid:107)

F , we get

1/2

min
R∈O (cid:107)

UJ+1

−

U (cid:63)R

F

(cid:107)

≤

1−δ2r
1+δ2r

1

−

(cid:18)

(cid:113)

(cid:19)

(cid:18)

min
R∈O (cid:107)

U0

−

U (cid:63)R

J+1

2
F + min
(cid:107)

R∈O (cid:107)

U−1

U (cid:63)R

2
F
(cid:107)

−

(cid:19)

+ O(µ).

Supporting lemmata

In this section, we present a series of lemmata, used for the main result of the paper.

Lemma 2. Let U

Cd×r and U (cid:63)

∈

∈

ρ(cid:63) = U (cid:63)U (cid:63)†, κ := 1+δ2r
1−δ2r

> 1, for δ2r

≤
σ1(ρ(cid:63))1/2
σr(ρ(cid:63))1/2

Cd×r, such that
−
10 , and τ (ρ(cid:63)) := σ1(ρ(cid:63))

U
≤
(cid:107)
σr(ρ(cid:63)) > 1. Then:

U (cid:63)R

(cid:107)

F

1

σr(ρ(cid:63))1/2
103√κτ (ρ(cid:63))

for some R

, where

∈ O

1

1

(cid:0)

−

−

1
103
1
103

(cid:1)

≤

≤

σ1(U )

σr(U )

≤

≤

σ1(ρ(cid:63))1/2
σr(ρ(cid:63))1/2

1 + 1
103
1 + 1
(cid:0)
103

(cid:1)

(62)

(63)

F and using Weyl’s inequality for perturbation of singular values [41, Theorem

(cid:1)

(cid:1)

(cid:0)

(cid:0)

≤ (cid:107) · (cid:107)

Proof. By the fact
3.3.16], we have:

2

(cid:107) · (cid:107)

Then,

Similarly:

σi(U )
|

−

σi(U (cid:63))

| ≤

σr(ρ(cid:63))1/2
103√κτ (ρ(cid:63)) ≤

σr(ρ(cid:63))1/2
103

,

1

i

≤

≤

r.

−

σ1(ρ(cid:63))1/2

−
σ1(ρ(cid:63))1/2

(cid:0)

−

σr(ρ(cid:63))1/2

−
σr(ρ(cid:63))1/2

σr(ρ(cid:63))1/2
103
σr(ρ(cid:63))1/2
103
1
103

1

−

(cid:1)

σr(ρ(cid:63))1/2
103
σr(ρ(cid:63))1/2
103
1
103

1

−

σ1(U )

σ1(U )

σ1(U )

σr(U )

σr(U )

σr(U )

−

≤

≤

−

≤

≤

≤

≤

≤

≤

≤

≤

≤

σr(ρ(cid:63))1/2

σ1(U (cid:63))
103 ⇒
σ1(ρ(cid:63))1/2 + σr(ρ(cid:63))1/2
103 ⇒
σ1(ρ(cid:63))1/2
1 + 1
.
103

(cid:0)

(cid:1)

≤

σr(ρ(cid:63))1/2

σr(U (cid:63))
103 ⇒
σr(ρ(cid:63))1/2 + σr(ρ(cid:63))1/2
103 ⇒
σr(ρ(cid:63))1/2
1 + 1
.
103

(64)

(65)

(66)

(67)

(68)

(69)

(70)

σj(ρ(cid:63))1/2, for

≥

In the above, we used the fact that σi(U (cid:63)) = σi(ρ(cid:63))1/2, for all i, and the fact that σi(ρ(cid:63))1/2
(cid:1)
i

(cid:0)

(cid:1)

(cid:0)

j.

≤

Cd×r, U−

Lemma 3. Let U
∈
U (cid:63)R(cid:107)F ≤ σr (ρ(cid:63))1/2
κτ (ρ(cid:63))
tum parameter as µ = σr (ρ(cid:63))1/2
κτ (ρ(cid:63))

103

103

√

√

∈

Cd×r, and U (cid:63)

∈

Cd×r, such that minR∈O (cid:107)U −U (cid:63)R(cid:107)F ≤ σr (ρ(cid:63))1/2
κτ (ρ(cid:63))

√

, where ρ(cid:63) = U (cid:63)U (cid:63)†, and κ := 1+δ2r
1−δ2r

> 1, for δ2r ≤ 1

10 , and τ (ρ(cid:63)) := σ1(ρ(cid:63))

and minR∈O (cid:107)U−−

103
σr (ρ(cid:63)) > 1. Set the momen-

·

ε

4·σ1(ρ(cid:63))1/2·r , for ε

∈

(0, 1) user-deﬁned. Then,

U (cid:63)RZ

Z

(cid:107)

−

F

(cid:107)

≤

3
2 + 2

(cid:0)

38

σr(ρ(cid:63))1/2
103√κτ (ρ(cid:63))

.

µ
|
|
(cid:1)

·

(71)

Proof. Let RU
distance function:

∈

arg minR∈O

U
(cid:107)

−

U (cid:63)

F and RU− ∈

(cid:107)

arg minR∈O

U−
(cid:107)

−

U (cid:63)R

(cid:107)

F . By the deﬁnition of the

U (cid:63)RZ

Z
(cid:107)

−

F = min
(cid:107)

R∈O (cid:107)

Z

F = min

U + µ(U

U (cid:63)R

−
U + µ(U

(cid:107)

R∈O (cid:107)
(1

U−)

µ + µ)U (cid:63)R

U−)

U (cid:63)R

F
(cid:107)

−

−

−
U ∗RU
U ∗RU
U ∗RU
U

−
F +
(cid:107)
F +
(cid:107)
F +
(cid:107)
U (cid:63)R

−

−
µ
|
µ
|
µ
|
F +
(cid:107)
F +
(cid:107)

| · ||

| · (cid:107)

| · (cid:107)
µ
|
µ
|

U

U (cid:63)R

−

F

F
(cid:107)
U ∗RU− ||
U ∗RU
−
U ∗RU− ) + U ∗(RU− −
U (cid:63)R
F +
µ
U−
| · (cid:107)
(cid:107)
|
F + 2
µ
(cid:107)

U ∗RU− + U ∗RU− (cid:107)
RU )
F
(cid:107)
U (cid:63)(RU

U (cid:63)R

U−

−

−

| ·

F

|

U−
U−
(U−

−

−

−
min
R∈O (cid:107)
min
R∈O (cid:107)

| ·

| ·

−
σ1(ρ(cid:63))1/2r

| · (cid:107)

| · (cid:107)

| · (cid:107)

U

U

−

−

−

U
min
R∈O (cid:107)
min
R∈O (cid:107)

| ·

| ·

RU− )
F
(cid:107)

= min

R∈O (cid:107)
1 + µ
1 + µ
|
1 + µ
|
1 + µ

1 + µ

≤ |
=

=

≤ |

≤ |
(i)

(72)

(73)

(74)

(75)

(76)

(77)

(78)

(79)

3
2 + 2

µ
|
|

·

(cid:1)

≤

(cid:0)

σr(ρ(cid:63))1/2
103√κτ (ρ(cid:63))

σr(ρ(cid:63))1/2
103√κτ (ρ(cid:63)) ·

≤

where (i) is due to the fact that µ

clarity for the rest of the proof.

1

4·σ1(ρ(cid:63))1/2·r . We keep µ in the expression, but we use it for

Corollary 1. Let Z

∈
and ρ(cid:63) = U (cid:63)U (cid:63)†. Then:

Cd×r and U (cid:63)

Cd×r, such that

U (cid:63)R

Z

(cid:107)

−

F
(cid:107)

≤

3
2 + 2

µ
|
|

∈

(cid:0)

σr(ρ(cid:63))1/2
103√κτ (ρ(cid:63))

for some R

,

∈ O

·

(cid:1)

σ1(ρ(cid:63))1/2
σr(ρ(cid:63))1/2

1

1

(cid:0)

3
2 + 2
3
2 + 2

(cid:0)

µ
|
|
µ
|
|

(cid:1)

−

−

1
103
1
103

(cid:1)

≤

≤

σ1(Z)

σr(Z)

≤

≤

σ1(ρ(cid:63))1/2
σr(ρ(cid:63))1/2

1 +

1 +
(cid:0)

Given that µ = σr (ρ(cid:63))1/2
κτ (ρ(cid:63))

103

√

·

(cid:0)
ε
4·σ1(ρ(cid:63))1/2·r

(cid:0)

(cid:1)
≤ 1

103 , we get:

(cid:1)

(cid:0)

3
2 + 2
3
2 + 2

µ
|
(cid:1)

|
µ
|
|

(cid:1)

(cid:0)

(cid:0)

0.998

0.998

·

·

σ1(ρ(cid:63))1/2
σr(ρ(cid:63))1/2

σ1(Z)

σr(Z)

1.0015

1.0015

·

·

≤

≤

≤

≤

σ1(ρ(cid:63))1/2
σr(ρ(cid:63))1/2.

1
103
1
103

.

(cid:1)

(cid:1)

(80)

(81)

(82)

(83)

Proof. The proof follows similar motions as in Lemma 2.

Corollary 2. Under the same assumptions of Lemma 2 and Corollary 1, and given the assumptions on µ, we have:

2

ρ(cid:63)
99
100 · (cid:107)
ρ(cid:63)
99
100 · (cid:107)

(cid:107)

(cid:107)
2

ZZ †
2
(cid:107)
Z0Z †
2
0(cid:107)

101
100 · (cid:107)
101
100 · (cid:107)

ρ(cid:63)
ρ(cid:63)

2
(cid:107)
2
(cid:107)

≤

≤

≤ (cid:107)

≤ (cid:107)

and

Z0Z †
2
0(cid:107)
Proof. The proof is easily derived based on the quantities from Lemma 2 and Corollary 1.

Z0Z †
2
0(cid:107)

101
99 · (cid:107)

99
101 · (cid:107)

ZZ †

≤ (cid:107)

≤

(cid:107)

2

(84)

(85)

(86)

Corollary 3. Let Z
∈
∈
and ρ(cid:63) = U (cid:63)U (cid:63)†. Deﬁne τ (W ) = σ1(W )

Cd×r and U (cid:63)

σr(W ) . Then:

Cd×r, such that

U (cid:63)R

Z

(cid:107)

−

F
(cid:107)

≤

3
2 + 2

µ
|
|

(cid:0)

·

(cid:1)

σr(ρ(cid:63))1/2
103√κτ (ρ(cid:63))

for some R

,

∈ O

where β :=

1+

1−

(cid:16) 3

(cid:16) 3

(cid:17)
·
2 +2|µ|
(cid:17)
2 +2|µ|

·

τ (ZZ †)

≤

β2τ (ρ(cid:63)),

1
103
1
103

> 1. for µ

σr(ρ(cid:63))1/2
103√κτ (ρ(cid:63)) ·

≤

1
4·σ1(ρ(cid:63))1/2·r .

(87)

Proof. The proof uses the deﬁnition of the condition number τ (
·
Corollary 1.

) and the results from Lemma 2 and and

39

Lemma 4. Consider the following three step sizes:

(1 + δ2r)
(cid:107)

Z0Z †
0(cid:107)

2 +

1

†
(cid:107)A
1

(cid:16)

(Z0Z †
0)

A

(1 + δ2r)
(cid:107)

ZZ †

2 +
(cid:107)

† (

(ZZ †)

(cid:107)A

A

−

η =

η =

(cid:98)
η(cid:63) =

4

4

(cid:16)

(cid:16)

y

−

2
(cid:107)

(cid:17)
(cid:17)
y) QZQ†

2
Z(cid:107)

.

(88)

(89)

(90)

(cid:17)

1
2 +
(cid:107)

Cd×r is the initial point, Z

Here, Z0
∈
denotes a basis of the column space of Z. Then, under the assumptions that minR∈O

∈

∈

4 ((1 + δ2r)

† (

ρ(cid:63)(cid:62)
2)
(cid:107)
(cid:107)
(cid:107)A
Cd×r is the current point, ρ(cid:63)

(ρ(cid:63))

y)

A

−

and minR∈O

parameter ε

Z
(cid:107)

U (cid:63)R

F
(cid:107)

−

≤
(0, 1), we have:
(cid:0)

σr(ρ(cid:63))1/2
103√κτ (ρ(cid:63))

3
2 + 2

|

µ
|
(cid:1)

·

∈

, and assuming µ = σr (ρ(cid:63))1/2
κτ (ρ(cid:63))

103

√

Cd×d is the optimal solution, and QZ
,

σr(ρ(cid:63))1/2
U
103√κτ (ρ(cid:63))
(cid:107)
4·σ1(ρ(cid:63))1/2·r , for the user-deﬁned

U (cid:63)R

−
ε

F
(cid:107)

≤

·

10
9 η

η

≥

≥

10
10.5 η,

and

100

102 η(cid:63)

η

≤

≤

102

100 η(cid:63)

(91)

Proof. The assumptions of the lemma are identical to that of Corollary 2. Thus, we have: 99
101
2
U (cid:63)
Z
2 ≤
100 · (cid:107)
(cid:107)
(cid:107)
η
the inequality
(cid:13)A† (cid:16)

2, 99
U (cid:63)
2
2
Z0
2 ≤ (cid:107)
100 · (cid:107)
(cid:107)
10
10.5 η. Observe that:
(cid:13)
(cid:13)

2, and 99
2

2
2 ≤ (cid:107)
(cid:107)

A(ZZ †) − y

(cid:98)
2
2 ≤
(cid:107)

101
99 · (cid:107)

101
100 · (cid:107)

2
2 ≤
(cid:107)

QZ Q†
Z

101 · (cid:107)

(cid:107)
≥

U (cid:63)

A(ZZ †) − y
(cid:98)

(cid:13)
(cid:13)
(cid:13)2

Z0

Z0

(cid:13)
(cid:13)

Z

≤

(cid:107)

(cid:17)

2
U (cid:63)
2 ≤
100 · (cid:107)
(cid:107)
2
2. We focus on
(cid:107)

(cid:13)A† (cid:16)
(cid:13)A† (cid:16)

(cid:13)
(cid:13)

=

A(ZZ †) − y

(cid:17)(cid:13)
(cid:13)
(cid:13)2
− A† (cid:16)

(cid:17)

(i)
≤ (1 + δ2r)

≤ (1 + δ2r)

0

(cid:13)
(cid:13)
(cid:13)ZZ † − Z0Z †
(cid:13)
(cid:13)
(cid:13)F
(cid:13)ZZ † − U (cid:63)U (cid:63)†(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)F
(cid:13)A† (cid:16)
A(Z0Z †
0 ) − y

(cid:13)
(cid:13)

+

A(Z0Z †
(cid:13)A† (cid:16)

(cid:13)
(cid:13)

+

+ (1 + δ2r)
(cid:17)(cid:13)
(cid:13)
(cid:13)2

0 ) − y

(cid:17)

+ A† (cid:16)

A(Z0Z †

0 ) − y

(cid:17)(cid:13)
(cid:13)
(cid:13)2

0 ) − y

A(Z0Z †
(cid:13)
(cid:13)Z0Z †
(cid:13)

(cid:17)(cid:13)
(cid:13)
(cid:13)2
0 − U (cid:63)U (cid:63)†(cid:13)
(cid:13)
(cid:13)F

where (i) is due to smoothness via RIP constants of the objective and the fact
two terms on the right-hand side, where RZ is the minimizing rotation matrix for Z, we obtain:

2
(cid:107) · (cid:107)

≤ (cid:107) · (cid:107)

F . For the ﬁrst

ZZ †
(cid:107)

−

U (cid:63)U (cid:63)†

F =
(cid:107)

=

ZZ †
(cid:107)
(Z
(cid:107)
Z

U (cid:63)RZZ † + U (cid:63)RZZ †
−
U (cid:63)RZ)Z † + U (cid:63)RZ(Z
−
U (cid:63)
Z
2
(cid:107)
(cid:107)
· (cid:107)
(cid:107)
U (cid:63)RZ
2 +
Z
(cid:107)
(cid:107)
101
99 +

U (cid:63)RZ
2)
(cid:107)
100
99

F +
(cid:107)
Z

−
U (cid:63)

Z0

· (cid:107)

−

Z

(cid:107)

2
(cid:107)

· (cid:107)

≤ (cid:107)
(
(cid:107)

≤
(i)

U (cid:63)U (cid:63)†
F
−
(cid:107)
U (cid:63)RZ)†
Z

F
(cid:107)
U (cid:63)RZ

−
2

−

· (cid:107)
F

(cid:107)

U (cid:63)RZ

F
(cid:107)

−

F

(cid:107)

≤
(ii)

(cid:18)(cid:113)

≤

(cid:18)(cid:113)

(cid:113)

(cid:19)

101
99 +

100
99

101
99 +

100
99

(cid:113)

(cid:113)

Z0
(cid:107)

2
(cid:107)

·

0.001σr(ρ(cid:63))1/2

0.001

·

(cid:113)

100
99 · (cid:107)

Z0

2
2
(cid:107)

(cid:19)

·

(cid:19)

where (i) is due to the relation of

≤

(cid:18)(cid:113)

Z
(cid:107)

2 and
(cid:107)

(cid:107)

U (cid:63)

(cid:107)

2 derived above, (ii) is due to Lemma 3. Similarly:

Z0Z †
(cid:107)

0 −

U (cid:63)U (cid:63)†

F

(cid:107)

≤

101
99 +

100
99

(cid:18)(cid:113)

(cid:113)

0.001

·

(cid:19)

·

(cid:113)

100
99 · (cid:107)

Z0

2
2
(cid:107)

Using these above, we obtain:

(cid:13)
(cid:13)

(cid:13)A† (cid:16)

A(ZZ †) − y

(cid:17)

QZ Q†
Z

(cid:13)
(cid:13)
(cid:13)2

≤ 4.1(1+δ2r )
103

(cid:107)Z0Z †

0 (cid:107)2 +

(cid:13)
(cid:13)

(cid:13)A† (cid:16)

A(Z0Z †

0 ) − y

(cid:17)(cid:13)
(cid:13)
(cid:13)2

40

(92)

(93)

(94)

(95)

(96)

(97)

(98)

(99)

(100)

(101)

(102)

(103)

(104)

(105)

Thus:

η =

4

(cid:98)

≥

4

1

ZZ †
(1 + δ2r)
(cid:107)

2 +
(cid:107)

(cid:107)A

(cid:16)
(1 + δ2r) 101
99 (cid:107)

Z0Z0

2+
(cid:107)

† (

(ZZ †)

A

−
1
+ 4.1(1+δ2r)
103

y) QZQ†

Z(cid:107)

2

(cid:17)

Z0Z †
0(cid:107)
(cid:107)

2 +

†
A

(cid:0)

≥

4

(cid:16)
10
10.5 η

≥

10.5
10 ·

Z0Z †
(1 + δ2r)
0(cid:107)
(cid:107)

1
(cid:1)
2 +

(Z0Z †
0)

A

†

(cid:107)A

(cid:16)

y

−

(cid:17)

(cid:13)
(cid:13)
(cid:13)
2
(cid:107)

(cid:17)

(Z0Z †
0)

A

y

−

(cid:16)

2
(cid:17)(cid:13)
(cid:13)
(cid:13)

(106)

(107)

(108)

(109)

Similarly, one gets

η

10
9 η.

≤

For the relation between η and η(cid:63), we will prove here the lower bound; similar motions lead to the upper

bound also. By deﬁnition, and using the relations in Corollary 2, we get:

(cid:98)

η =

4

(cid:16)

≥

4

Z0Z †
(1 + δ2r)
0(cid:107)
(cid:107)

2 +

1

†
(cid:107)A
1

(cid:16)

(Z0Z †
0)

A

y

−

(1 + δ2r) 101
100 (cid:107)

ρ(cid:63)(cid:62)

2 +
(cid:107)

†
(cid:107)A

(cid:16)

(Z0Z †
0)

A

−

(cid:17)

y

2

(cid:107)

(cid:17)

2
(cid:107)

(cid:17)

(cid:17)

(cid:16)
For the gradient term, we observe:

(Z0Z †
0)

A

y

−

†
A

(cid:13)
(cid:13)
(cid:13)

(cid:16)

2 ≤
(i)
=

(cid:17)(cid:13)
(cid:13)
(cid:13)

† (

(ρ(cid:63))

− A

A

† (

(ρ(cid:63))

A

− A

(cid:17)
U (cid:63)U (cid:63)†

† (

(ρ(cid:63))

A

A

(cid:13)
(cid:13)

+

−

−

y)

2
(cid:13)
(cid:13)
y)
(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

U (cid:63)
2 +
(cid:107)
(cid:107)
101
100 + 1

F

(cid:13)
(cid:13)
2)
(cid:13)
(cid:107)
U (cid:63)

(cid:107)

Z

· (cid:107)

−

U (cid:63)RZ

0.001

2
(cid:107)

·

· (cid:107)

F
(cid:107)
U (cid:63)

2
2
(cid:107)

y

(cid:17)
y

†
A

A

(Z0Z †
0)

−

(cid:16)

A

†
A

(Z0Z †
0)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:16)
(cid:13)
(1 + δ2r)
(cid:13)

−
Z0Z †
(cid:13)
(cid:13)
(1 + δ2r) (
Z0
(cid:13)
(cid:107)

0 −

(1 + δ2r)

0.002

(cid:18)(cid:113)
ρ(cid:63)
(1 + δ2r)
(cid:107)

·

2

(cid:107)

(cid:19)

(ii)

≤
(iii)

≤
(iv)

≤

≤
y)

† (

(ρ(cid:63))

where (i) is due to

2 = 0, (ii) is due to the restricted smoothness assumption and the RIP,
Z0Z †
(iii) is due to the bounds above on
2, as
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

Z
(cid:107)
Thus, in the inequality above, we get:

(cid:13)
(cid:13)
well as the bound on

, (iv) is due to the bounds on

2, w.r.t.
(cid:107)

U (cid:63)U (cid:63)†

U (cid:63)R

0 −

U (cid:63)

(cid:13)
(cid:13)
(cid:13)

Z0

F .

A

A

−

−

(cid:107)

(cid:107)

(cid:107)

(cid:107)

F

η

≥

4

≥

4

(1 + δ2r) 101
100 (cid:107)

(cid:16)
(1 + δ2r) 101
100 (cid:107)

ρ(cid:63)(cid:62)

(cid:0)

≥

4

(1 + δ2r) 102
100 (cid:107)

ρ(cid:63)(cid:62)

1

ρ(cid:63)(cid:62)

2 +
(cid:107)

†
(cid:107)A

(cid:16)
2 + 0.001
(cid:107)
1
2 +
(cid:107)

(cid:107)A

† (

A

(Z0Z †
0)
1

y

−

(1 + δ2r)
(cid:107)

ρ(cid:63)

·

2
(cid:107)

(cid:17)
(cid:17)
2 +
(cid:107)

(ρ(cid:63))

A

y)

2
(cid:107)

−

≥

(cid:1)

(118)

(119)

(120)

y)

2
(cid:107)

−

(cid:1)

† (

(ρ(cid:63))

A

(cid:107)A
102 η(cid:63)
100

Similarly, one can show that 102

100 η(cid:63)

(cid:0)

η.

≥
Cd×r, and U (cid:63)

Lemma 5. Let U
∈
U (cid:63)R(cid:107)F ≤ σr (ρ(cid:63))1/2
κτ (ρ(cid:63))

103

√

Cd×r, U−

∈

, where ρ(cid:63) = U (cid:63)U (cid:63)†, and κ := 1+δ2r
1−δ2r

∈

Cd×r, such that minR∈O (cid:107)U −U (cid:63)R(cid:107)F ≤ σr (ρ(cid:63))1/2
κτ (ρ(cid:63))
10 , and τ (ρ(cid:63)) := σ1(ρ(cid:63))
σr(ρ(cid:63)) > 1. By Lemma

> 1, for δ2r

and minR∈O (cid:107)U−−

103

√

1

≤

41

y)

2

−

(cid:13)
(cid:13)

(110)

(111)

(112)

(113)

(114)

(115)

(116)

(117)

3, the above imply also that: (cid:107)Z − U (cid:63)RZ (cid:107)F ≤ (cid:0) 3

2 + 2|µ|(cid:1) · σr (ρ(cid:63))1/2

√

103

κτ (ρ(cid:63))

. Then, under RIP assumptions of the mapping

, we have:

A

A†(A(ZZ †) − y), (Z − U (cid:63)RZ )(Z − U (cid:63)RZ )†(cid:69)
(cid:68)

(cid:32)

≥ −

θσr(ρ(cid:63)) · (cid:107)Z − U (cid:63)RZ (cid:107)2

F + 10.1

100 β2 · (cid:98)η ·

(cid:18)

(1+2|µ|)2
1
200

1−(1+2|µ|)

(cid:19)2 · (cid:107)A†(A(ZZ †) − y) · Z(cid:107)2

F

(121)

(cid:33)

where

and

η =

θ =

(1−δ2r)

(cid:16)

1+(1+2|µ|)

(cid:17)2

1
200

103

1

4((1+δr)(cid:107)ZZ†(cid:107)2+(cid:107)A†(A(ZZ†)−y)QZ Q†

Z (cid:107)2)

+ (1 + δ2r)

2 + (1 + 2
µ
|
|

)

·

1
200

(1 + 2

)
µ
|

|

·

1
200 ,

.

(cid:0)

(cid:1)

Proof. First, denote ∆ := Z

(cid:98)

U (cid:63)RZ. Then:
A†(A(ZZ †) − y), (Z − U (cid:63)RZ )(Z − U (cid:63)RZ )†(cid:69)

−

(cid:68)

(cid:68)

(i)
=

≥ −

A†(A(ZZ †) − y) · Q∆Q†
(cid:12)
(cid:12)
(cid:12)Tr

A†(A(ZZ †) − y) · Q∆Q†

(cid:16)

∆, ∆Z ∆†

Z

∆ · ∆Z ∆†

Z

(cid:17)(cid:12)
(cid:12)
(cid:12)

(cid:69)

(ii)
≥ −(cid:107)A†(A(ZZ †) − y) · Q∆Q†

∆(cid:107)2 · Tr(∆Z ∆†
Z )

(iii)
≥ −

(cid:16)

(cid:107)A†(A(ZZ †) − y) · QZ Q†

Z (cid:107)2 + (cid:107)A†(A(ZZ †) − y) · QU (cid:63) Q†

U (cid:63) (cid:107)2

(cid:17)

(cid:107)Z − U (cid:63)RZ (cid:107)2
F

(122)

Note that (i) follows from the fact ∆Z = ∆ZQ∆Q†
(ii) follows from
transformation in (iii), we use that fact that the row space of ∆Z, SPAN(∆Z), is a subset of SPAN(Z
as ∆Z is a linear combination of U and U (cid:63).

∆, for a matrix Q that spans the row space of ∆Z, and
2 TR(B), for PSD matrix B (Von Neumann’s trace inequality [65]). For the
(cid:107)
U (cid:63)),

Tr(AB)
|

| ≤ (cid:107)

A

∪

To bound the ﬁrst term in equation (122), we observe:

(cid:107)A†(A(ZZ †) − y) · QZ Q†
(cid:16)
(1 + δ2r)(cid:107)ZZ †(cid:107)2

(i)

= (cid:98)η · 4

Z (cid:107)2 · (cid:107)Z − U (cid:63)RZ (cid:107)2

F

+ (cid:107)A†(A(ZZ †) − y) · QZ Q†

Z (cid:107)2

(cid:17)

· (cid:107)A†(A(ZZ †) − y) · QZ Q†

Z (cid:107)2 · (cid:107)Z − U (cid:63)RZ (cid:107)2

F

= 4(cid:98)η(1 + δ2r)(cid:107)ZZ †(cid:107)2(cid:107)A†(A(ZZ †) − y) · QZ Q†

Z (cid:107)2 · (cid:107)Z − U (cid:63)RZ (cid:107)2
F
(cid:125)

(cid:124)

(cid:123)(cid:122)
:=A

+ 4(cid:98)η(cid:107)A†(A(ZZ †) − y) · QZ Q†

Z (cid:107)2

2 · (cid:107)Z − U (cid:63)RZ (cid:107)2
F

where (i) is due to the deﬁnition of

η.
To bound term A, we observe that
(cid:98)

(1−δ2r)σr(ZZ†)
103

QZQ†

2
Z(cid:107)
. This results into bounding A as follows:

(cid:107)A

A

−

·

†(

(ZZ †)

y)

QZQ†

2
Z(cid:107)

≥

(1−δ2r)σr(ZZ†)
103

or

≤

(cid:107)A

†(

A

(ZZ †)

4(cid:98)η(1 + δ2r)(cid:107)ZZ †(cid:107)2(cid:107)A†(A(ZZ †) − y) · QZ Q†
(cid:110) 4·(cid:98)η·(1+δ2r )(cid:107)ZZ†(cid:107)2·(1−δ2r )σr (ZZ†)
103

≤ max

Z (cid:107)2 · (cid:107)Z − U (cid:63)RZ (cid:107)2
· (cid:107)Z − U (cid:63)RZ (cid:107)2
F ,

F

≤ 4·(cid:98)η·(1−δ2

2r )(cid:107)ZZ†(cid:107)2·σr (ZZ†)

(cid:98)η · 4 · 103κτ (ZZ †)(cid:107)A†(A(ZZ †) − y) · QZ Q†
· (cid:107)Z − U (cid:63)RZ (cid:107)2
F
+ (cid:98)η · 4 · 103κτ (ZZ †)(cid:107)A†(A(ZZ †) − y) · QZ Q†

Z (cid:107)2

103

2 · (cid:107)Z − U (cid:63)RZ (cid:107)2
F

(cid:111)

Z (cid:107)2

2 · (cid:107)Z − U (cid:63)RZ (cid:107)2
F .

y)

·

−

(123)

(124)

(125)

(126)

(127)

42

Combining the above inequalities, we obtain:

(cid:107)A†(A(ZZ †) − y) · QZ Q†

Z (cid:107)2 · (cid:107)Z − U (cid:63)RZ (cid:107)2

F

(i)

≤ (1−δ2r )σr (ZZ†)
103

· (cid:107)Z − U (cid:63)RZ (cid:107)2
F

+ (103κτ (ZZ †) + 1) · 4 · (cid:98)η(cid:107)A†(A(ZZ †) − y) · QZ Q†

Z (cid:107)2

2 · (cid:107)Z − U (cid:63)RZ (cid:107)2
F

1

106 σr(ρ(cid:63))

(cid:19)2 σr(ZZ †)

(ii)

≤ (1−δ2r )σr (ZZ†)
103

· (cid:107)Z − U (cid:63)RZ (cid:107)2
F

+ (103β2κτ (ρ(cid:63)) + 1) · 4 · (cid:98)η(cid:107)A†(A(ZZ †) − y) · QZ Q†

Z (cid:107)2
2 ·

(iii)

≤ (1−δ2r )σr (ZZ†)

103

· (cid:107)Z − U (cid:63)RZ (cid:107)2
F

(cid:19)2

+2|µ|

(cid:18) 3
2
κτ (ρ(cid:63))

+ 4 · 1001β2 · (cid:98)η · (cid:107)A†(A(ZZ †) − y) · QZ Q†

Z (cid:107)2
2 ·

(cid:18)

106

(iv)

≤ (1−δ2r )σr (ZZ†)

103

· (cid:107)Z − U (cid:63)RZ (cid:107)2
F

(cid:18) 3
2
(cid:18) 3
2

1−

(cid:19)2

+2|µ|

+2|µ|

(cid:19) 1
103

+ 4 · 1001β2 · (cid:98)η ·

106

(cid:18)

1−

(cid:18) 3
2
(cid:18) 3
2

(cid:19)2

+2|µ|

+2|µ|

(cid:19) 1
103

(cid:19)2 · (cid:107)A†(A(ZZ †) − y) · Z(cid:107)2

F

(cid:18)

(1−δ2r )

1+(

(v)
≤

3
2

+2|µ|)

(cid:19)2

1
103

σr (ρ(cid:63))

103

· (cid:107)Z − U (cid:63)RZ (cid:107)2
F

+ 1

200 β2 · (cid:98)η ·

(cid:18)

(cid:19)2

+2|µ|

(cid:18) 3
2
(cid:18) 3
2

1−

+2|µ|

(cid:19) 1
103

(cid:19)2 · (cid:107)A†(A(ZZ †) − y) · Z(cid:107)2

F

where (i) follows from
where ρ :=

3
2 + 2

η

≤

1
4(1+δ2r)(cid:107)ZZ†(cid:107)2
1
103√κτ (ρ(cid:63))
(cid:98)

µ
|
|
Corollary 1, (iv) is due to the fact σr(ZZ †)
(cid:1)
due to Corollary 1.

(cid:0)

, (ii) is due to Corollary 3, bounding

Z
(cid:107)
by Lemma 3, (iii) is due to (103β2κτ (ρ(cid:63)) + 1)

ρσr(ρ(cid:63))1/2,
U (cid:63)RZ
1001β2κτ (ρ(cid:63)), and by

F
(cid:107)

≤

†(

(ZZ †)

(cid:107)A

A

y)

·

−

QZQ†

2
2 ≤ (cid:107)A
Z(cid:107)

†(

A

y)Z

(cid:107)

−

2
F , and (v) is

−
≤
(ZZ †)

Next, we bound the second term in equation (122):

†(

(ZZ †)

(cid:107)A

A

y)

−

QU (cid:63) Q†
U (cid:63)
·
(i)

†(

Z

2

(cid:107)
· (cid:107)
(ZZ †)

≤ (cid:107)A
(ii)

A
(1 + δ2r)

U (cid:63)RZ

−

2
F

(cid:107)
†(

y)

−
ZZ †

A
− A
U (cid:63)U (cid:63)†

· (cid:107)

−

(1 + δ2r)(2 + ρ)

·

ρ

≤
(iii)

≤
(iv)

(ρ(cid:63))

2

Z

y)
· (cid:107)
(cid:107)
U (cid:63)RZ

−

Z

U (cid:63)RZ

2
F

(cid:107)

−
2
F
(cid:107)

F
(cid:107)
σ1(U (cid:63))

· (cid:107)
−
σr(U (cid:63))

Z

−

U (cid:63)RZ

2
F
(cid:107)
U (cid:63)RZ
Z
−
103 σr(ρ(cid:63))
1

2
F
(cid:107)

1

·
· (cid:107)
103 σr(ρ(cid:63))
3
2 + 2
µ
|
|
(cid:1)
(ZZ †)

·
3
2 + 2
µ
|
(cid:1)
2
(cid:107)

≤

(1 + δ2r)(2 + ρ)
3
2 + 2
(cid:0)
|
QU (cid:63) Q†
(cid:0)
where (i) follows from
U (cid:63)
−
is due to smoothness of f and the RIP constants, (iii) follows from [14, Lemma 18], for ρ =

(cid:1) (cid:0)
≤ (cid:107)A
µ
·
|
, (iv) follows from substituting ρ above, and observing that τ (ρ(cid:63)) = σ1(U (cid:63))2/σr(U (cid:63))2 > 1 and
(cid:1)

2
F ,
(cid:107)
y) = 0, (ii)
3
2 + 2

y)
2 and
(cid:107)

µ
·
|
|
1
(cid:1)
103

(1 + δ2r)

(cid:0)
y)
−

U (cid:63)RZ

(ZZ †)

≤
†(

(ρ(cid:63))

2 +

(cid:107)A

· (cid:107)

· (cid:107)

†(

†(

A

A

A

A

−

−

Z

(cid:0)

·

|

·

·

1
103√κτ (ρ(cid:63))
κ = (1 + δ2r)/(1

−
Combining the above we get:

δ2r) > 1.

A†(A(ZZ †) − y), (Z − U (cid:63)RZ )(Z − U (cid:63)RZ )†(cid:69)
(cid:68)

(cid:32)

≥ −

θσr(ρ(cid:63)) · (cid:107)Z − U (cid:63)RZ (cid:107)2

F + 1

200 β2 · (cid:98)η ·

(cid:18)

(cid:19)2

+2|µ|

(cid:19)2 · (cid:107)A†(A(ZZ †) − y) · Z(cid:107)2

F

(128)

(cid:33)

(cid:18) 3
2
(cid:18) 3
2

1−

+2|µ|

(cid:19) 1
103

(1−δ2r)

(cid:16)

1+

where θ =

(cid:16) 3

2 +2|µ|
103

(cid:17) 1
103

(cid:17)2

+ (1 + δ2r)

2 +

3
2 + 2

(cid:0)

(cid:0)
43

|

µ
|
(cid:1)

·

1
103

3
2 + 2

(cid:1) (cid:0)

1
103 .

|

µ
|
(cid:1)

·

Lemma 6. Under identical assumptions with Lemma 5, the following inequality holds:

(cid:68)

A†(A(ZZ †) − y), ZZ † − U (cid:63)U (cid:63)†(cid:69)

≥ 1.1172η

(cid:13)
(cid:13)A†(A(ZZ †) − y)Z
(cid:13)

(cid:13)
(cid:13)
(cid:13)

2

F

+ 1−δ2r

2

(cid:107)U (cid:63)U (cid:63)† − ZZ †(cid:107)2
F

(129)

Proof. By smoothness assumption of the objective, based on the RIP assumption, we have:

1

2 (cid:107)A(ZZ †) − y(cid:107)2

2 ≥ 1

+) − y(cid:107)2

2

2 (cid:107)A(U+U †
(cid:68)
−

A†(A(ZZ †) − y), U+U †

+ − ZZ †(cid:69)

1

2 (cid:107)A(ZZ †) − y(cid:107)2

2 ≥ 1

2 (cid:107)A(U (cid:63)U (cid:63)†) − y(cid:107)2
−

(cid:68)

2

A†(A(ZZ †) − y), U+U †

+ − ZZ †(cid:69)

− 1+δ2r

2

− 1+δ2r

2

(cid:107)U+U †

+ − ZZ †(cid:107)2

F ⇒

(cid:107)U+U †

+ − ZZ †(cid:107)2

F

(130)

(131)

(132)

(133)

(U (cid:63)U (cid:63)†)
due to the optimality
strong convexity with RIP, we get:

(cid:107)A

y

2
2 = 0
(cid:107)

−

(V V †)

y

(cid:107)

−

≤ (cid:107)A

2
2, for any V

∈

Cd×r. Also, by the restricted

1

2 (cid:107)A(U (cid:63)U (cid:63)†) − y(cid:107)2

2 ≥ 1

2 (cid:107)A(ZZ †) − y(cid:107)2
+

2

A†(A(ZZ †) − y), U (cid:63)U (cid:63)† − ZZ †(cid:69)
(cid:68)

+ 1−δ2r

2

(cid:107)U (cid:63)U (cid:63)† − ZZ †(cid:107)2
F

Adding the two inequalities, we obtain:

(cid:68)

A†(A(ZZ †) − y), ZZ † − U (cid:63)U (cid:63)†(cid:69)

≥

(cid:68)

A†(A(ZZ †) − y), ZZ † − U+U †
+

(cid:69)

To proceed we observe:

− 1+δ2r

2

(cid:107)U+U †

+ − ZZ †(cid:107)2

F + 1−δ2r

2

(cid:107)U (cid:63)U (cid:63)† − ZZ †(cid:107)2
F

U+U †

+ =

A(ZZ †) − y

(cid:17)

(cid:17)

·

Z

(cid:16)

Z − ηA† (cid:16)
= ZZ † − ηZZ † · A† (cid:16)
+ η2A† (cid:16)
(cid:16)

(i)
= ZZ † −

I − η

2 QZ Q†

A(ZZ †) − y

A(ZZ †) − y
(cid:17)

Z − ηA† (cid:16)
(cid:16)
− ηA† (cid:16)
(cid:17)

A(ZZ †) − y
(cid:17)

A(ZZ †) − y

(cid:17)

(cid:17)†

Z

· ZZ †

· ZZ † · A† (cid:16)

A(ZZ †) − y

(cid:17)

− ηA† (cid:16)

A(ZZ †) − y

· ZZ † ·

I − η

2 QZ Q†

Z A† (cid:16)
(cid:17)

A(ZZ †) − y
(cid:16)

(cid:17)(cid:17)

A(ZZ †) − y

(cid:17)

· ηZZ † · A† (cid:16)
Z A† (cid:16)

A(ZZ †) − y

(cid:17)(cid:17)

(134)

(135)

(136)

(137)

(138)

(139)

(140)

(141)

(142)

(ZZ †)

†
Z · A

where (i) is due to the fact
QZQ†
identity matrix whose dimension is apparent from the context. Thus:
Z A† (cid:16)
Z A† (cid:16)

A(ZZ †) − y

2 QZ Q†
(cid:98)η

2 QZ Q†

(cid:22) 10.5
10

· A

A

A

−

−

(cid:17)

y

(cid:1)

(cid:0)

(cid:0)

(cid:0)

(cid:1)

·

η

†
A

(ZZ †)

ZZ †
·
−
, for QZ a basis matrix whose columns span the column space of Z; also, I is the

(ZZ †)

(ZZ †)

ZZ †

†
A

Z ·

A

A

=

−

y

y

y

·

†

QZQ†

(cid:1)

(cid:0)

(cid:1)

A(ZZ †) − y

(cid:17)

,

(143)

(144)

1

≤

4(cid:107)QZ Q†

Z A†(A(ZZ†)−y)(cid:107)2

(145)

,

and, hence,

Deﬁne Ψ = I

and thus:

−

I − η

2 QZ Q†

Z A† (cid:16)

A(ZZ †) − y

(cid:17)

(cid:23) I − 10.5
10

2 QZ Q†
(cid:98)η

Z A† (cid:16)

A(ZZ †) − y

(cid:17)

.

η

2 QZQ†

†
ZA

(ZZ †)

A

−

y

. Then, using the deﬁnition of

η, we know that

η

(cid:0)

(cid:1)
Ψ (cid:31) 0, σ1(Ψ) ≤ 1 + 21
160 ,

and σn(Ψ) ≥ 1 − 21
160 .

(cid:98)

(cid:98)

44

Going back to the main recursion and using the above expression for U+U †

+, we have:

(cid:68)

A†(A(ZZ †) − y),ZZ † − U (cid:63)U (cid:63)†(cid:69)

− 1−δ2r

2

(cid:107)U (cid:63)U (cid:63)† − ZZ †(cid:107)2
F

(cid:68)

≥

A†(A(ZZ †) − y), ZZ † − U+U †
+

(cid:69)

− 1+δ2r

2

(cid:107)U+U †

+ − ZZ †(cid:107)2

F

(i)
≥ 2η

(cid:68)

A†(A(ZZ †) − y), A†(A(ZZ †) − y) · ZZ † · Ψ

(cid:69)

− 1+δ2r

2

(cid:107)2ηA†(A(ZZ †) − y) · ZZ † · Ψ(cid:107)2
F

(cid:13)
(cid:13)
(cid:13)

2

F

· (cid:107)Z(cid:107)2

2 · (cid:107)Ψ(cid:107)2
2

(ii)

≥ 2 (cid:0)1 − 21

2

F

160

(cid:1) η

(cid:13)
(cid:13)A†(A(ZZ †) − y)Z
(cid:13)

(cid:13)
(cid:13)
(cid:13)
− 2(1 + δ2r)η2 (cid:13)
(cid:13)A†(A(ZZ †) − y)Z
(cid:13)
(cid:13)
(cid:13)
(cid:13)
− 2(1 + δ2r)η2 (cid:13)
(cid:13)A†(A(ZZ †) − y)Z
(cid:13)

(cid:13)
(cid:13)A†(A(ZZ †) − y)Z
(cid:13)

(cid:1) η

160

2

(iii)

≥ 2 (cid:0)1 − 21

= 2 (cid:0)1 − 21

160

(cid:1) η

(iv)

≥ 2 (cid:0)1 − 21

(cid:1) η

160

(cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:13)A†(A(ZZ †) − y)Z
(cid:13)
(cid:13)
(cid:13)A†(A(ZZ †) − y)Z
(cid:13)

2

F

(cid:13)
(cid:13)
(cid:13)

2

F
(cid:13)
(cid:13)
(cid:13)
F
(cid:18)

·

2

F

·

(cid:18)

· (cid:107)Z(cid:107)2

2 · (cid:0)1 + 21

160

(cid:1)2

1 − 2(1 + δ2r)η · (cid:107)Z(cid:107)2

2 · (cid:0)1 + 21

160

(cid:1)2 ·

(cid:19)

)

1

21
160

2(1−

1 − 2(1 + δ2r) 10.5

10 (cid:98)η · (cid:107)Z(cid:107)2

2 · (cid:0)1 + 21

160

(cid:1)2 ·

1

21
160

2(1−

(v)

≥ 2 (cid:0)1 − 21

160

(cid:1) η

(cid:13)
(cid:13)A†(A(ZZ †) − y)Z
(cid:13)

(cid:13)
(cid:13)
(cid:13)

2

F


1 − 10.5

10

·

= 1.0656η

(cid:13)
(cid:13)A†(A(ZZ †) − y)Z
(cid:13)

(cid:13)
(cid:13)
(cid:13)

2

F

(cid:18)

1+





(cid:19)2

21
160
21
160

4(1−

)

(146)

(147)

(148)

(149)

(150)

(151)

(152)

(153)

(154)

(cid:19)

)
(155)

(156)

(157)

where (i) is due to the symmetry of the objective; (ii) is due to Cauchy-Schwarz inequality and the fact:

(cid:68)

A†(A(ZZ †) − y), A†(A(ZZ †) − y) · ZZ † · Ψ
(cid:68)

A†(A(ZZ †) − y), A†(A(ZZ †) − y) · ZZ †(cid:69)

=

(cid:69)

(cid:68)

− η
2

A†(A(ZZ †) − y), A†(A(ZZ †) − y) · ZZ † · A†(A(ZZ †) − y)

(cid:69)

(i)
≥

(cid:68)

A†(A(ZZ †) − y), A†(A(ZZ †) − y) · ZZ †(cid:69)

(cid:68)

− 10.5
10

(cid:98)η
2

A†(A(ZZ †) − y), A†(A(ZZ †) − y) · ZZ † · A†(A(ZZ †) − y)

(cid:69)

(cid:16)

≥

1 − 10.5
10

≥ (cid:0)1 − 21

160

Z A†(A(ZZ †) − y)(cid:107)2

2

2 (cid:107)QZ Q†
(cid:98)η
(cid:1) (cid:13)
(cid:13)A†(A(ZZ †) − y)Z
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

F

(cid:17)

(cid:13)
(cid:13)A†(A(ZZ †) − y)Z
(cid:13)

·

(cid:13)
2
(cid:13)
(cid:13)

F

(158)

(159)

(160)

(161)

(162)

(163)

(164)

10.5
10

≤

where (i) is due to η
(iii) is due to the upper bound on
above lead to the desiderata:
(cid:98)
A†(A(ZZ †) − y), ZZ † − U (cid:63)U (cid:63)†(cid:69)

η and its upper bound;
η, and the last inequality comes from the deﬁnition of the
1
η; (v) is due to
η
. The
4(1+δ2r)(cid:107)ZZ†(cid:107)2
(cid:98)
(cid:98)

2 above; (iv) is due to η
(cid:107)

≥ 1.0656η

(cid:107)U (cid:63)U (cid:63)† − ZZ †(cid:107)2
F

(cid:98)
(cid:13)
(cid:13)
(cid:13)A†(A(ZZ †) − y)Z
(cid:13)
(cid:13)
(cid:13)

+ 1−δ2r

10.5
10

(165)

≤

≤

Ψ

(cid:68)

(cid:107)

2

2

F

45

