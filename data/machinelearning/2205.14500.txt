2
2
0
2

y
a
M
8
2

]

G
L
.
s
c
[

1
v
0
0
5
4
1
.
5
0
2
2
:
v
i
X
r
a

Optimal Decision Diagrams for Classiﬁcation

Alexandre M. Florio
CIRRELT & SCALE-AI Chair in Data-Driven Supply Chains
Department of Mathematical and Industrial Engineering, Polytechnique Montréal, Canada
aflorio@gmail.com

Pedro Martins
Department of Computer Science, Pontiﬁcal Catholic University of Rio de Janeiro, Brazil
pmartins@inf.puc-rio.br

Maximilian Schiffer
School of Management & Munich Data Science Institute
Technical University of Munich, Germany
schiffer@tum.de

Thiago Serra
Freeman College of Management
Bucknell University, USA
thiago.serra@bucknell.edu

Thibaut Vidal
CIRRELT & SCALE-AI Chair in Data-Driven Supply Chains
Department of Mathematical and Industrial Engineering, Polytechnique Montréal, Canada
Department of Computer Science, Pontiﬁcal Catholic University of Rio de Janeiro, Brazil
thibaut.vidal@polymtl.ca

Abstract

Decision diagrams for classiﬁcation have some notable advantages over decision
trees, as their internal connections can be determined at training time and their width
is not bound to grow exponentially with their depth. Accordingly, decision diagrams
are usually less prone to data fragmentation in internal nodes. However, the inherent
complexity of training these classiﬁers acted as a long-standing barrier to their
widespread adoption. In this context, we study the training of optimal decision
diagrams (ODDs) from a mathematical programming perspective. We introduce a
novel mixed-integer linear programming model for training and demonstrate its
applicability for many datasets of practical importance. Further, we show how this
model can be easily extended for fairness, parsimony, and stability notions. We
present numerical analyses showing that our model allows training ODDs in short
computational times, and that ODDs achieve better accuracy than optimal decision
trees, while allowing for improved stability without signiﬁcant accuracy losses.

1

Introduction

Decision diagrams, also known as decision graphs or decision streams, have a long history in logic
synthesis and formal circuit veriﬁcation [36, 17, 18] as well as in optimization [7, 9, 35] and artiﬁcial
intelligence topics such as planning [46, 21], knowledge compilation [1, 34, 47], and constraint
propagation [6, 44, 49]. In machine learning, decision diagrams have recurrently emerged as a
possible classiﬁcation model [42, 41, 39, 48, 30] or as a by-product of model compression algorithms
applied on decision trees [16, 27, 23]. A decision diagram for classiﬁcation is represented as a rooted
directed acyclic graph in which each internal node represents a splitting hyperplane, and each terminal
node is uniquely associated to a class. The topology of the graph remains a free parameter of the

Preprint. Under review.

 
 
 
 
 
 
model, such that decision diagram learning requires to jointly determine the splitting hyperplanes and
the node-connecting arcs.

Decision diagrams possess notable advantages over decision trees. Firstly, their width is not bound to
grow exponentially with their depth, which allows training deep but narrow decision diagrams without
quickly facing issues of data fragmentation [48, 30]. Moreover, additional degrees of freedom in their
topology design permit to express a richer set of concepts and to achieve better model compression in
memory-constrained computing environments [16, 33].

Despite these advantages, decision diagrams have been more rarely used than decision trees, as
learning them remains inherently complex. A decision diagram topology cannot be easily optimized
by construction or local optimization algorithms based on impurity measures. However, recent
enhancements in global optimization techniques for decision tree training motivate us to reevaluate
this issue. Indeed, optimal decision tree training through mathematical programming is becoming
practical due to the formidable progress of hardware and mixed-integer linear programming solvers,
which collectively led to speed-ups as high as 1011 between 1991 and 2015—most of which due to
algorithmic improvements rather than hardware [12]. In view of this, we reevaluate the problem of
searching for optimal decision diagrams (ODDs) through modern combinatorial optimization lenses
and propose new mathematical models and efﬁcient solution techniques to learn optimal decision
diagrams. Speciﬁcally, our contributions are threefold:

1. We propose the ﬁrst mixed-integer linear program (MILP) to train decision diagrams for classiﬁ-
cation. This model effectively represents the decision diagram topology and the ﬂow of samples
within it, employing a limited number of binary variables. In practice, it includes exponentially
fewer binary variables than [10] when applied to decision tree topologies. Furthermore, we include
additional symmetry-breaking constraints that speed up the solution process, and provide efﬁcient
heuristic search strategies to obtain good primal solutions quickly.

2. We conduct an extensive computational study to evaluate our approach’s scalability and compare
the resulting decision diagrams with classical decision trees. We observe that training optimal
decision diagrams requires a computational effort comparable to optimal decision-tree training
but leads to more parsimonious and accurate models.

3. As our MILP semantic permits to express various additional constraints with minimal adaptation,
we discuss possible extensions to capture additional fairness, parsimony and stability requirements.
We show the efﬁcacy of such extensions in our numerical experiments for the stability case.

2 Related work

Optimal training of decision trees. Standard construction algorithms for decision-tree training
based on local impurity measures are not guaranteed to ﬁnd the most accurate tree of a given size. To
circumvent this issue, several works have been focused on global optimization algorithms. Optimal
decision-tree training is known to be NP-hard [29], but solution methods for this problem went
a long way from early dynamic programming algorithms [38, 43] to modern solution approaches.
Nowadays, these algorithms can ﬁnd optimal trees for datasets with thousands of samples and
hundreds of features [10, 24, 26].

Carrizosa et al. [20] recently conducted a comprehensive survey of mathematical programming
approaches for optimal decision-tree training. Among the works surveyed, the paper of Bertsimas
and Dunn [10] represents a turning point, as it proposed a compact MILP formulation that could be
solved within reasonable time for a wide range of datasets from the UCI machine learning repository.
Subsequent methodological improvements occurred through sophisticated model reformulations and
decomposition methods [3, 26], permitting to achieve better linear programming bounds and quickly
prune sub-optimal regions of the search space. Among other beneﬁts, MILP-based approaches can
handle combinatorial splits on categorical features, and they can easily include notions of fairness
[2, 52] and parsimony [13] through additional global objectives and constraints. Research in this
ﬁeld strives towards more effective solution approaches, based on combinations of branch-and-bound
with dynamic programming [4, 24], constraint programming [50], or exploiting Boolean satisﬁability
(SAT) problem solvers [40]. Some of these solution approaches also open new perspectives for other
related training tasks, for example, in model compression [51].

2

Decision diagrams. Decision diagrams for classiﬁcation have regularly reappeared in the machine
learning domain. Early studies on the topic [42, 32, 41, 5] followed a minimum description length
perspective and led to a ﬁrst generation of learning algorithms – often transforming an initial decision
tree into a decision diagram. Oliver [42] argued that decision diagrams are particularly suitable to
express disjunctive concepts (e.g., exclusive OR) and proposed an iterative node-merging algorithm.
Kohavi [31] and Kohavi and Li [32] ﬁrst designed a bottom-up learning approach and then opted to
train an oblivious decision tree and post-process it into a decision diagram through iterative merging.
Oliveira and Sangiovanni-Vincentelli [41] exploited efﬁcient algorithms known from logic synthesis
[17, 18] to manipulate ordered decision diagrams. They design an iterative greedy approach that
merges nodes with similar sub-graphs to achieve a greater reduction of message length. An extension
of support vector machines towards multi-class settings through decision diagrams was also presented
in [45]. Decision diagrams have also been used for model compression [16, 27] and as a surrogate
model for neural networks in Chorowski and Zurada [22]. They were generalized into ensembles
called decision jungles in Shotton et al. [48]. Ignatov and Ignatov [30] considered training deep
decision diagrams, called decision streams, and reported a good performance on a range of datasets
for credit scoring, aircraft control, and image classiﬁcation. Recently, Cabodi et al. [19] studied
binary decision diagrams in the context of interpretable machine learning, while Hu et al. [28] focused
on optimizing binary decision diagrams via MaxSAT.

Most likely, the biggest obstacle towards the effective use of decision diagrams remains the ability
to learn them efﬁciently. Indeed, most aforementioned learning algorithms ﬁrst generate a decision
tree and then transform it into a decision diagram. Unfortunately, these methods also often ﬁx the
order of the predicates through the tree, as this choice is known to lead to a difﬁcult combinatorial
optimization problem [14]. Accordingly, design decisions related to the graph topology (permitting
to learn complex concepts) are ineffectively learned through trial and error. Our approach closes this
signiﬁcant methodological gap and, for the ﬁrst time, allows to derive efﬁcient algorithms for training
decision diagrams.

3 Mathematical formulation

In this section, we mathematically formulate the ODD training problem as a MILP. We assume
i=1 in which each xi ∈ Rd corresponds to a sample
that we have a training dataset {(xi, ci)}n
characterized by a d-dimensional feature vector and a class ci ∈ C. Our formulation takes as input
the diagram’s depth D, i.e., the diagram’s number of decision layers, and the width wl of each layer
l ∈ {0, . . . , D − 1}. This input constitutes the skeleton of the decision diagram, and it guarantees
that any ﬁnal topology found during training (i.e., number of activated nodes per layer and their
mutual connections) is contained in the skeleton. W.l.o.g., we can assume that wl+1 ≤ 2wl for all l.
The MILP optimizes the decision diagram’s topology and the splitting hyperplane of each internal
node. We allow connections between internal nodes of consecutive layers and direct connections via
long arcs to terminal nodes representing the classes, as this permits to progressively assign a ﬁnal
classiﬁcation for speciﬁc samples without necessarily passing through the complete decision diagram.
Accordingly, the training algorithm can progressively send samples to the ﬁnal leaves to fully exploit
the remaining layers for classifying the other samples.

We designed our approach for numerical data, such that processing other data types requires prior
transformation, e.g., one-hot encoding for categorical data, which is a common practice in decision-
tree-based models. For numerical stability, we assume that each feature has been normalized
within [0, 1]. Our model handles multiclass classiﬁcation with a dedicated leaf for each class. It also
naturally ﬁnds optimal multivariate (i.e., diagonal) splits without extra computational burden. We
further show how it can be restricted to produce only univariate splits if necessary.

3.1 Canonical formulation

To represent the decision diagram, as illustrated on Figure 1, we deﬁne an acyclic graph G = (V, A)
with V = V I ∪ V C. Each node v ∈ V I represents an internal node, and each node v ∈ V C represents
a terminal node corresponding to a class cv. We represent nodes by indices V = {0, . . . , |V I| +
|V C| − 1}; node 0 ∈ V I represents the root of the decision diagram and the remaining nodes are
listed by increasing depth (from left to right on the ﬁgure). Let V I
l be the set of nodes at depth
l, and let δ−(v) and δ+(v) be the predecessors and successors of each node v ∈ V. With these

3

Thick edges represent a pos-
sible decision-graph topology
(selected by the training algorithm)

Flow variables w−
iuv
indicate the trajectory of sample i.
The following conditions always hold:

iu and z−

iu, w+

(w−
(w+

iu = 1) ⇒ (aT
iu = 1) ⇒ (aT

uxi < bu)
uxi ≥ bu)

0

w−
iu

u

w+
iu

z−
iuv

v

The blue path corresponds to
the possible trajectory of a
sample classiﬁed as Class 1

Class 1

Class 2

V I
0

V I
1

V I
2

V C

Figure 1: Example of a graph G with three layers of internal nodes (w1 = 2 and w2 = 3) and two
terminal nodes. The thick edges indicate a possible decision diagram. The black connectors permit to
illustrate ﬂow-conservation within the graph. For clarity, the long arcs between the black connectors
of layers V I

1 and the terminal nodes of V C are not displayed.

0 and V I

deﬁnitions, δ−(0) = ∅ and δ+(0) = V I
and δ+(v) = V I
produced by our model will be a subgraph of G.

l+1 ∪ V C. Finally, for v ∈ V C, δ−(v) = V I and δ+(v) = ∅. The decision diagram

1 ∪ V C. For v ∈ V I

l with 1 ≤ l < D − 1, δ−(v) = V I

l−1

To formulate the training problem as a MILP, we start by deﬁning the ﬂow variables that represent
the trajectory of the samples within the graph. We then connect these ﬂows to the design variables
deﬁning the structure of the decision diagram and to those characterizing the splits.

iu ∈ [0, 1] and w+

iu ∈ [0, 1]. A non-zero value in w−

Flow variables. Each sample i and internal node u ∈ V I is associated to a pair of ﬂow variables
w−
iu) means that sample i passes
through node u on the negative side of the separating hyperplane (on the positive side, respectively).
Moreover, variables z−
iuv ∈ [0, 1]) characterize the ﬂow going from the
negative and positive sides of u to other nodes v. With these deﬁnitions, we can express ﬂow
conservation within the graph G through the following conditions:

iuv ∈ [0, 1] (respectively z+

iu (respectively w+

u∈δ−(v)(z+

iuv + z−

iuv) otherwise

if v = 0

(cid:40)

w+

iv + w−

iv =

1
(cid:80)

w−

iu =

(cid:88)

w+

iu =

v∈δ+(u)
(cid:88)

v∈δ+(u)

z−
iuv

z+
iuv

v ∈ V I, i ∈ {1, . . . , n}

u ∈ V I, i ∈ {1, . . . , n}

u ∈ V I, i ∈ {1, . . . , n}

(1)

(2)

(3)

However, due to the interaction of the constraints coming from the hyperplanes (described later in this
section), integrality of the ﬂow variables is not guaranteed. To obtain integer sample ﬂows, we add an
additional binary variable λil ∈ {0, 1} for each sample i ∈ {1, . . . , n} and level l ∈ {0, . . . , D − 1},
along with the following constraints:
(cid:88)

l ∈ {0, . . . , D − 1}, i ∈ {1, . . . , n}

(4)

w−

iu ≤ 1 − λil

u∈V I
l
(cid:88)

u∈V I
l

w+

iu ≤ λil

l ∈ {0, . . . , D − 1}, i ∈ {1, . . . , n}

(5)

With these constraints, sample i can only go to the negative (respectively positive) side of any node u
of level V I
l if λil = 0 (respectively λil = 1). This allows us to use fewer binary variables compared
to a direct deﬁnition of the w−
iu as binary (see Theorem 2), which is a desirable characteristic
to allow for efﬁciently solving the MILP.

iu and w+

4

Decision diagram topology. We now connect the ﬂow variables to the binary design variables that
characterize the topology of the diagram. Here, we deﬁne one binary variable du ∈ {0, 1} for each
u ∈ V that takes value 1 if this node is used in the classiﬁcation (i.e., samples can pass through it).
The terminal nodes and the root are always activated, so we impose du = 1 for u ∈ 0 ∪ V C. For
the negative and positive sides of each node u ∈ V I, we create binary design variables y−
uv ∈ {0, 1}
and y+
uv ∈ {0, 1} taking value 1 if and only if u links towards v on the negative and positive sides,
respectively. The following constraints connect the design variables and the sample ﬂows:

du =

(cid:88)

y+
uv =

(cid:88)

y−
uv

v∈δ+(u)
(cid:88)

dv ≤

(y+

uv + y−
uv)

v∈δ+(u)

u∈δ−(v)

uv + y−
y+
uv ≤ dv
z+
iuv ≤ y+
uv,
z−
iuv ≤ y−
uv

u ∈ V I

v ∈ V I − {0}

u ∈ V I, v ∈ δ+(u)
u ∈ V I, v ∈ δ+(u), i ∈ {1, . . . , n}
u ∈ V I, v ∈ δ+(u), i ∈ {1, . . . , n}

(6)

(7)

(8)

(9)

(10)

Symmetry-breaking constraints. Without any constraint for breaking symmetry, 2|V I| equivalent
topologies can be obtained by switching the positive- and negative-side arcs of each internal node and
using opposite hyperplanes. Such symmetry has a dramatic negative impact on branch-and-bound-
based MILP solution approaches. To circumvent this issue, we impose that arcs (u, v) and (u, w)
such that y−
uw = 1 satisfy v < w for each internal node u ∈ V I. This corresponds to the
logical constraint (y−

uw = 0 ∀w ≤ v), formulated as

uv = 1) ⇒ (y+

uv = 1 and y+

y−
uv +

(cid:88)

y+
uw ≤ 1

w∈δ+(u),w≤v

u ∈ V I, v ∈ δ+(u)

(11)

To further reduce model symmetry and the number of equivalent topologies, we impose that the
nodes along each layer must respect a weak in-degree ordering:

(cid:88)

(y+

wu + y−

wu) ≥

(cid:88)

(y+

wv + y−

wv)

l ∈ {2, . . . , D − 1}, u, v ∈ V I

l , u < v

(12)

w∈δ−(u)

w∈δ−(v)

Linear separator variables and consistency with the sample ﬂows. We associate to each internal
node v ∈ V I a vector of variables av ∈ [−1, 1]d and a variable bv ∈ [−1, 1] to characterize
the splitting hyperplane. Samples i ∈ {1, . . . , n} following the negative-side path should satisfy
aT
v xi ≥ bv. This is done by
v xi < bv, whereas samples taking the positive-side path should satisfy aT
including indicator constraints in our MILP that express the following implication logic:

(w−
(w+

iv = 1) ⇒ (aT
iv = 1) ⇒ (aT

v xi + ε ≤ bv)
v xi ≥ bv)

i ∈ {1, . . . , n}, v ∈ V I
i ∈ {1, . . . , n}, v ∈ V I

(13)

(14)

In Constraint (13), ε should be a small constant greater than the numerical precision of the solver
(set to ε = 10−4 in our experiments) that permits to express strict inequality. These logical
constraints could be reformulated as linear constraints using a big-M transformation, leading to
v xi ≥ bv − M (1 − w+
v xi + ε ≤ bv + M (1 − w−
aT
iv). However, as seen in [8], modern
MILP solvers generally beneﬁt from directly specifying the implication logic and apply a big-M
reformulation with tailored bound tightening.

iv) and aT

Constraints (13–14) represent general multivariate, i.e., oblique, splits. We can further restrict the
model to produce univariate splits by adding for each feature j ∈ {1, . . . , d} and internal node v ∈ V I
a binary variable evj ∈ {0, 1}, along with constraints that impose the selection of a single feature:

d
(cid:88)

j=1

evj = 1

v ∈ V I

− evj ≤ ajv ≤ evj

j ∈ {1, . . . , d}, v ∈ V I

(15)

(16)

5

Objective function.
In a similar fashion as in [10], we optimize accuracy and an additional regu-
larization term that favors simple decision diagrams with fewer internal nodes. The accuracy of the
model can be computed by means of variables wiv ∈ [0, 1] for each sample i ∈ {1, . . . , n} and leaf
v ∈ V C expressing the amount of ﬂow of i reaching terminal node v with class cv. These variables
must satisfy the following constraints:

wiv =

(cid:88)

u∈δ−(v)

(z+

iuv + z−

iuv)

v ∈ V C, i ∈ {1, . . . , n}

(17)

With the help of these variables, we state our objective as

min

1
n

n
(cid:88)

(cid:88)

i=1

v∈V C

φivwiv +

α
|V I| − 1

(cid:88)

dv,

v∈V I−{0}

(18)

where φiv represents the mismatch penalty when assigning sample i to terminal node v (typically
deﬁned as 0 if ci = cv and 1 otherwise), while α is a regularization parameter. The ﬁrst term of the
objective penalizes misclassiﬁed samples, whereas the second term penalizes complex models. With
those conventions, the objective lies in [0, 1 + α] and an hypothetical value of 0 would correspond to
a model that achieves perfect classiﬁcation with a single split at the root node.

Theorem 1 Formulation (1–18) produces solutions in which all variables w and z take binary
values, leading to a feasible and optimal decision diagram.

Theorem 2 Our formulation includes O(n log |V|) binary decision variables when applied to
decision-tree skeletons.

While Theorem 1 establishes optimality for our MILP formulation, Theorem 2 highlights its efﬁciency,
illustrated in the context of decision tree skeletons where it improves upon the formulation of [10],
which requires O(n|V|) binary decision variables. We give proofs to Theorems 1 and 2 in the
supplemental material.

3.2 Discussion

Whereas classical training algorithms are often tailored to a speciﬁc setting and difﬁcult to adapt
to new requirements, our MILP approach for ODD training provides an extensible mathematical
framework for expressing new requirements. We show how our MILP can be extended to fairness,
parsimony, or stability measures. All extensions require minimal effort and only require extra linear
constraints over the existing variables.

Fairness. The confusion matrix can be directly calculated from the binary variables wiv of our
model, which take value one if and only if sample i reaches terminal node v with class cv. Hence, we
can introduce classical fairness metrics into our MILP, either as an additional term in the objective
or as a constraint, without signiﬁcantly changing its complexity. To illustrate this, consider a binary
classiﬁcation dataset in which outcome 1 is the most desirable. For any subgroup g ⊂ {1, . . . , n},
the number of samples classiﬁed as 1 by the ODD can be calculated as Z P
i∈g wivP , where vP is
the terminal node associated to the positive class. This permits to express demographic parity [see,
e.g., 37] with the following linear constraints:

g = (cid:80)

(cid:88)

i∈g1

wivP ≥ ξ

(cid:88)

i∈g2

wivP ,

(19)

where g1 and g2 are two (non-necessarily disjoint) subgroups and ξ represents a minimal discrepancy
ratio between two subgroups. Compliance with the classic four-ﬁfths rule [11, 53] is achieved
with ξ = 0.8. In a similar fashion, the number of false-positives and false-negatives for any subgroup
g can be calculated as Z FP
i∈g,ci=P(1 − wivP ), permitting in turn to
express most other classical fairness notions. e.g., equal opportunity or predictive equality [37].

i∈g,ci(cid:54)=P wivP and Z FN

g = (cid:80)

g = (cid:80)

Parsimony and stability. Our MILP’s ﬂexibility for ODD training is not limited to fairness. It is
possible to bound the number of activated nodes to a predeﬁned limit D to ensure parsimony by

6

imposing (cid:80)
i∈V I di ≤ D. Finally, it is possible to impose that a minimum number S of samples
passes through each activated internal node to enhance stability, through the following conditions:

n
(cid:88)

(cid:88)

(z+

iuv + z−

iuv) ≥ Sdv

v ∈ V I.

(20)

i=1

u∈δ−(v)

4 Training strategy

We introduce a two-step search strategy, which permits to train an initial decision diagram quickly,
and then reﬁne it to eventually reach an optimal topology. First, we use an efﬁcient multi-start
construction and improvement heuristic to derive an initial topology. Then, we solve the complete
MILP using an off-the-shelf branch-and-cut implementation (Gurobi in our case), where the value of
the solution obtained in the ﬁrst step is used as a cutoff value in the branch-and-bound search.

Step 1—Initial construction and improvement. We use a top-down construction approach that
shares some common traits with CART [15]. For each layer l ∈ {0, . . . , D − 2} and internal node
u ∈ V I
l , we select the univariate split that maximizes the information gain. In contrast to CART, we
determine the internal connections of the decision diagram at the training stage. Therefore, additional
decisions need to be taken regarding the destination of the sample ﬂows emerging from each layer.
To this end, we adopt a greedy merging policy: as long as the number of sample ﬂows is greater
than wl+1, we merge the pair of ﬂows that least decreases the information gain. In the last layer
connecting to the terminal nodes V C, we ﬁnally directly connect each sample ﬂow to the terminal
node of its most represented class.

To obtain a better initial diagram, we repeat the construction process for 60 seconds and consider
only a random subset of 60% of the features during each split selection. Additionally, we apply a
bottom-up pruning strategy that consists of iteratively eliminating any internal (i.e., splitting) node
that is (i) connected only to terminal nodes, and (ii) such that the removal improves Objective (18).

Step 2—Solution of the MILP.
In this step, we apply Gurobi on the complete MILP described
in Section 3. Gurobi is a state-of-the-art solver for MILPs that utilizes a branch-and-cut process to
derive lower and upper bounds on the objective value and to prune regions of the search space that
have no chance to contain an optimal solution. To further guide the branch-and-bound search towards
promising regions of the feasible space, we set an objective cutoff value equal to the value of the
solution found in Step 1. The completion of this process gives a global optimum of the training model
for the considered objective and regularization parameter. We set a CPU time limit of TMAX = 600
seconds for this phase. The process terminates with the best solution found so far if TMAX is attained.

5 Experimental analyses

We focus our experiments on the same selection of 54 datasets as in Bertsimas and Dunn [10]. All
these datasets are publicly available from the UCI machine learning repository [25]. They reﬂect
a wide range of classiﬁcation applications and contain between 47 to 6435 data points with 2 to
484 features. The list of datasets is accessible along with our detailed experimental results in the
supplemental material. We split each dataset into a training, validation, and testing subset of samples
with respective proportions of 50%, 25%, and 25%. We repeat all our experiments ﬁve times for each
dataset, using a different seed and thus a different random separation of the samples for each run.

All our algorithms have been implemented in Python 3.8 and can be readily executed from a single
script. We use Gurobi 9.1.0 (via gurobipy) for solving the mathematical models. Each validation
and test experiment has been run on a single thread of an Intel Gold 6148 Skylake @2.40GHz CPU.
Overall, the experiments of this paper took eight hours on 10 CPUs of the mentioned type for ﬁve
seeds. All data, source code, and additional details on the computational results are provided in the
supplemental material and will be provided as a public Git repository upon publication.

We divide our computational experiments into two stages. Firstly, we conduct a calibration experiment
using only the training and validation sets, considering different decision diagram skeletons and
different levels of the regularization parameter α. The goal of this experiment is twofold: it permits
to ﬁnd the best skeleton and α hyperparameter for each dataset, and allows us to evaluate our

7

Table 1: Performance of the MILP-based training method

Proven optimality

Improved solution

Total

Skeleton α = 0.01

I
II
III
IV
I (tree)

Total

152
150
148
149
155

754

0.1

155
154
152
156
158

775

0.2

162
162
161
163
163

811

0.5

179
179
177
178
177

890

1.0

225
227
223
226
225

0.01

35
36
38
62
30

1126

201

0.1

91
91
89
124
98

493

0.2

134
124
129
150
131

668

0.5

202
194
200
226
208

1.0

202
193
205
221
207

1537
1510
1522
1655
1552

1030

1028

7776

methodology’s computational performance, scalability, and sensitivity for different parameters.
Finally, in the second stage of experiments, we use the test set to compare our optimal decision
diagram models against the optimal decision tree model, using the best-found α hyperparameter for
each model and dataset.

5.1 Hyperparameters calibration and computational performance

We study the computational tractability of our approach for α ∈ {0.01, 0.1, 0.2, 0.5, 1} and for four
decision diagram skeletons: (1–2–4–8), (1–2–4–4–4), (1–2–3–3–3–3–3) and (1–2–2–2–2–2–2–2),
hereby referred to as Skeletons I to IV, respectively. All these skeletons have 15 internal nodes;
therefore, the ﬁnal trained decision diagrams will contain no more than 15 active nodes. We further
employ Skeleton (1–2–4–8) to ﬁnd optimal decision trees (ODTs). To this end, we specialize our
model by ﬁxing the decision variables representing the internal topology to match a decision tree;
hence, generating optimal ODT solutions similar to Bertsimas and Dunn [10].

Computational performance. We run our algorithm for each dataset, split type (univariate and
multivariate), random seed, skeleton, and value of α. First, we evaluate our ability to ﬁnd either the
global optimum or an improved solution to the training problem, compared to the solution found
in Step 1. Table 1 shows, for each skeleton and α combination, the number of runs (out of 54
datasets × 5 seeds = 270 runs) for which a global optimum or an improved solution was found. Our
algorithm can ﬁnd optimal topologies in 32% of all runs (4356 out of 13500 runs). Model difﬁculty
is inversely proportional to α values, as large values of the regularization parameter discourages
complex topologies with many active nodes. The difﬁculty of the training problem is generally
sensitive to the number of samples in the dataset but relatively insensitive to the number of features
(see results in the supplemental material). Because of the large size of some datasets and their
resulting training models, in many cases optimality is not achieved within the short computational
budget of 600 seconds used in our experiments. Still, Step 2 of our methodology improves upon
the initial heuristic solution in 58% of all runs, which demonstrates the value of the mathematical
programming-based training approach and indicates that it might be possible to solve more instances
to optimality when allocating larger computational budgets to each instance.

5.2 Performance analyses and model comparison

Accuracy of ODDs. We now compare the performance and structure of ODDs with those of ODTs.
We use the best skeleton for each ODD, as obtained during the hyperparameter calibration phase of
Section 5.1. We apply the same α hyperparameter calibration process for ODTs. To compare both
methods based on near-optimal topologies, we focus on a subset of 18 datasets for which optimal
ODDs and ODTs can be consistently obtained, and for which the ﬁnal topologies are non-trivial (i.e.,
use at least two internal nodes). We refer the interested reader to the supplemental material for a
more detailed discussion on the selection of those datasets. Moreover, we note that we do not extend
this analysis to other heuristic tree models such as CART, since the superior performance of ODTs
over CART has already been discussed for the same dataset collection in Bertsimas and Dunn [10].

Overall, ODDs and ODTs with univariate splits exhibit comparable accuracy as can be seen in the
detailed numerical results in the supplemental material. With multivariate splits, however, ODDs
show a higher accuracy compared to their ODT counterparts. Figure 2 shows the distribution of

8

the classiﬁcation accuracy on the test data over the selected datasets for the respective best ODT
and ODD models, highlighting that the respective ODDs show fewer low-accuracy outliers. Their
accuracy distribution is generally more compact and exhibits higher ﬁrst, second, and third quartiles.
Figure 3 complements this analysis by representing the accuracy of all 18 × 5 instances for ODD
and ODT in the multivariate splits case, sorted in ascending order. The sorted accuracy of the ODDs
superposes that of the best ODTs, which points towards a better classiﬁcation performance.

y
c
a
r
u
c
c
a

a
t
a
d
t
s
e
T

1

0.8

0.6

0.4

ODD

ODT

y
c
a
r
u
c
c
a

a
t
a
d
t
s
e
T

1

0.8

0.6

0.4

0

ODT
ODD

80

20

40

60

Dataset × run

Figure 2: Test data accuracy

Figure 3: Accuracy per dataset × run, ascending order

The improved performance of ODDs over ODTs results from the additional freedom in its topology,
which permits to express more complex concepts and generally avoids data fragmentation. Figure 4
illustrates the resulting different topologies and visualizes the data fragmentation for an ODT and an
ODD trained on the “teaching-assistant evaluation” dataset. Both models contain seven internal nodes,
but the ODD has a much more balanced data fragmentation, i.e., the share of samples processed
through each node is more balanced for the ODD.

(a) ODT structure

(b) ODD structure

Figure 4: Fragmentation of an ODT and an ODD trained on the “teaching-assist. evaluation” dataset

Stability of ODDs. Stability is a desirable characteristic of tree and diagram classiﬁers, as it
preserves effective classiﬁcation rules in face of new data and enhances model interpretability.
Table 2 measures the impact on accuracy when enforcing a certain level of stability when training
ODDs with our MILP approach. This is achieved by activating Constraints (20) and varying the
minimum number of samples S required to pass through any active node in the optimal topology. A
tradeoff is expected as tighter stability constraints reduce the solution space when constructing the
ODD. As observed, more stable ODDs can be obtained at a marginal out-of-sample accuracy loss.

6 Conclusions

We studied the training of optimal decision diagrams from a combinatorial optimization perspective.
Speciﬁcally, we proposed the ﬁrst MILP that allows to train optimal decision diagrams for classi-

9

Table 2: Test accuracy when enforcing minimum ﬂow of samples through active nodes

Split

S = 0.05n 0.10n 0.15n 0.20n

Multivariate
Univariate

0.828
0.840

0.827
0.838

0.823
0.837

0.823
0.835

ﬁcation. We conducted an extensive numerical study on 54 benchmark datasets reﬂecting a wide
variety of practical classiﬁcation tasks. The degrees of freedom of the model permit to ﬁnd good
ODD topologies that exhibit less data fragmentation than ODTs. Concerning out-of-sample accuracy,
we showed that ODDs perform favorably when compared to ODTs for the case of multivariate splits.

The ﬂexibility of our mathematical programming approach permits to extend the proposed model
to address a variety of important side requirements. Therefore, we believe that it can serve as an
important building block for more elaborate models, suited for a variety of application domains.
The proposed optimization model ﬁnds its limits in very large datasets with several thousands of
data points. As future research perspective, we suggest the investigation of heuristic construction
techniques that permit to generate decision diagrams for classiﬁcation independently of dataset size.

Acknowledgments and Disclosure of Funding

This research was enabled in part by support provided by Calcul Québec and Compute Canada.

References

[1] Abío, I., R. Nieuwenhuis, A. Oliveras, E. Rodríguez-Carbonell, V. Mayer-Eichberger. 2012. A new look at

BDDs for pseudo-boolean constraints. Journal of Artiﬁcial Intelligence Research 45 443–480.

[2] Aghaei, S., M.J. Azizi, P. Vayanos. 2019. Learning optimal and fair decision trees for non-discriminative
decision-making. Proceedings of the AAAI Conference on Artiﬁcial Intelligence, vol. 33. 1418–1426.

[3] Aghaei, S., A. Gomez, P. Vayanos. 2020. Learning optimal classiﬁcation trees: Strong max-ﬂow formula-

tions. arXiv preprint arXiv:2002.09142 .

[4] Aglin, G., S. Nijssen, P. Schaus. 2020. Learning optimal decision trees using caching branch-and-bound

search. Proceedings of the AAAI Conference on Artiﬁcial Intelligence 34(4) 3146–3153.

[5] Akers, Sheldon B. 1978. Binary decision diagrams. IEEE Transactions on computers 27(06) 509–516.

[6] Andersen, H.R., T. Hadzic, J.N. Hooker, P. Tiedemann. 2007. A constraint store based on multivalued
decision diagrams. International Conference on Principles and Practice of Constraint Programming.
Springer, 118–132.

[7] Behle, M. 2007. Binary Decision Diagrams and Integer Programming. Ph.D. thesis, Saarland University.

[8] Belotti, P., P. Bonami, M. Fischetti, A. Lodi, M. Monaci, A. Nogales-Gómez, D. Salvagnin. 2016.
On handling indicator constraints in mixed integer programming. Computational Optimization and
Applications 65(3) 545–566.

[9] Bergman, D., A.A. Cire, W.-J. Van Hoeve, J. Hooker. 2016. Decision diagrams for optimization. Springer

International Publishing.

[10] Bertsimas, Dimitris, Jack Dunn. 2017. Optimal classiﬁcation trees. Machine Learning 106(7) 1039–1082.

[11] Biddle, D. 2006. Adverse impact and test validation: A practitioner’s guide to valid and defensible

employment testing. Gower Publishing, Ltd.

[12] Bixby, R.E. 2012. A brief history of linear and mixed-integer programming computation. Documenta

Mathematica 107–121.

[13] Blanquero, R., E. Carrizosa, C. Molero-Río, D. Romero Morales. 2020. Sparsity in optimal randomized

classiﬁcation trees. European Journal of Operational Research 284 255–272.

[14] Bollig, B., I. Wegener. 1996. Improving the variable ordering of OBDDs is NP-complete. IEEE Transac-

tions on Computers 45(9) 993–1002.

10

[15] Breiman, L., J.H. Friedman, R.A. Olshen, C.J. Stone. 1984. Classiﬁcation and regression trees.

[16] Breslow, L.A., D.W. Aha. 1997. Simplifying decision trees: A survey. Knowledge Engineering Review

12(1) 1–40.

[17] Bryant, R.E. 1986. Graph-based algorithms for boolean function manipulation. IEEE Transactions on

Computers C-35(8) 677–691.

[18] Bryant, R.E. 1992. Symbolic boolean manipulation with ordered binary-decision diagrams. ACM

Computing Surveys 24(3) 293–318.

[19] Cabodi, Gianpiero, Paolo E Camurati, Alexey Ignatiev, Joao Marques-Silva, Marco Palena, Paolo Pasini.
2021. Optimizing binary decision diagrams for interpretable machine learning classiﬁcation. 2021 Design,
Automation & Test in Europe Conference & Exhibition (DATE). IEEE, 1122–1125.

[20] Carrizosa, E., C. Molero-Río, D.R. Morales. 2021. Mathematical optimization in classiﬁcation and

regression trees. Top 29(1) 5–33.

[21] Castro, M.P., C. Piacentini, A.A. Cire, J.C. Beck. 2019. Relaxed bdds: An admissible heuristic for delete-
free planning based on a discrete relaxation. Proceedings of the International Conference on Automated
Planning and Scheduling, vol. 29. 77–85.

[22] Chorowski, J., J.M. Zurada. 2011. Extracting rules from neural networks as decision diagrams. IEEE

Transactions on Neural Networks 22(12) 2435–2446.

[23] Choudhary, T., V. Mishra, A. Goswami, J. Sarangapani. 2020. A comprehensive survey on model

compression and acceleration. Artiﬁcial Intelligence Review 1–43.

[24] Demirovi´c, E., A. Lukina, E. Hebrard, J. Chan, J. Bailey, C. Leckie, K. Ramamohanarao, P.J. Stuckey.
2020. Murtree: Optimal classiﬁcation trees via dynamic programming and search. arXiv preprint
arXiv:2007.12652 .

[25] Dua, D., C. Graff. 2017. UCI machine learning repository.

[26] Firat, M., G. Crognier, A.F. Gabor, C.A.J. Hurkens, Y. Zhang. 2020. Column generation based heuristic

for learning classiﬁcation trees. Computers and Operations Research 116 104866.

[27] Gossen, F., B. Steffen. 2019. Large random forests: Optimisation for rapid evaluation. arXiv preprint

arXiv:1912.10934 .

[28] Hu, Hao, Marie-José Huguet, Mohamed Siala. 2022. Optimizing binary decision diagrams with maxsat for

classiﬁcation .

[29] Hyaﬁl, L., R.L. Rivest. 1976. Constructing optimal decision trees is NP-complete. Information Processing

Letters 5(1) 1–3.

[30] Ignatov, D., A. Ignatov. 2018. Decision stream: Cultivating deep decision trees. Proceedings - International

Conference on Tools with Artiﬁcial Intelligence, ICTAI 905–912.

[31] Kohavi, R. 1994. Bottom-up induction of oblivious read-once decision graphs: strengths and limitations.

Proceedings of AAAI 613–618.

[32] Kohavi, R., C.-H. Li. 1995. Oblivious decision trees, graphs, and top-down pruning. Proceedings of IJCAI.

1071–1079.

[33] Kumar, A., S. Goyal, M. Varma. 2017. Resource-efﬁcient machine learning in 2 KB RAM for the Internet

of Things. 34th International Conference on Machine Learning, ICML 2017 4 3062–3071.

[34] Lai, Y., D. Liu, S. Wang. 2013. Reduced ordered binary decision diagram with implied literals: A new

knowledge compilation approach. Knowledge and Information Systems 35 665–712.

[35] Lange, Jan-Hendrik, Paul Swoboda. 2020. Efﬁcient message passing for 0-1 ILPs with binary decision

diagrams .

[36] Lee, C. Y. 1959. Representation of Switching Circuits by Binary-Decision Programs. Bell System Technical

Journal 38(4) 985–999.

[37] Mehrabi, N., F. Morstatter, N. Saxena, K. Lerman, A. Galstyan. 2019. A survey on bias and fairness in

machine learning. arXiv preprint arXiv:1908.09635 .

11

[38] Meisel, W.S., D.A. Michalopoulos. 1973. A partitioning algorithm with application in pattern classiﬁcation

and the optimization of decision trees. IEEE Transactions on Computers C-22(1) 93–103.

[39] Mues, Christophe, Bart Baesens, Craig M. Files, Jan Vanthienen. 2004. Decision diagrams in machine
learning: An empirical study on real-life credit-risk data. Expert Systems with Applications 27(2) 257–264.

[40] Narodytska, N., A. Ignatiev, F. Pereira, J. Marques-Silva. 2018. Learning optimal decision trees with SAT.
Proceedings of the Twenty-Seventh International Joint Conference on Artiﬁcial Intelligence, IJCAI-18.
1362–1368.

[41] Oliveira, A.L., A. Sangiovanni-Vincentelli. 1996. Using the minimum description length principle to infer

reduced ordered decision graphs. Machine Learning 25(1) 23–50.

[42] Oliver, J. 1993. Decision graphs – An extension of decision trees. Proceedings of the 4th international

workshop on artiﬁcial intelligence and statistics (AISTATS). 343––350.

[43] Payne, H.J., W.S. Meisel. 1977. An algorithm for constructing optimal binary decision trees. IEEE

Computer Architecture Letters 26(09) 905–916.

[44] Perez, G., J.-C. Régin. 2015. Efﬁcient operations on mdds for building constraint programming models.

IJCAI 2015.

[45] Platt, J.C., N. Cristianini, J. Shawe-Taylor. 2000. Large margin DAGs for multiclass classiﬁcation.

Advances in Neural Information Processing Systems 547–553.

[46] Sanner, S., W.T.B. Uther, K.V. Delgado. 2010. Approximate dynamic programming with afﬁne adds.

AAMAS. 1349–1356.

[47] Serra, T. 2020. Enumerative branching with less repetition. International Conference on Integration of

Constraint Programming, Artiﬁcial Intelligence, and Operations Research. Springer, 399–416.

[48] Shotton, J., S. Nowozin, T. Sharp, J. Winn, P. Kohli, A. Criminisi. 2013. Decision jungles: Compact and

rich models for classiﬁcation. Advances in Neural Information Processing Systems 1–9.

[49] Verhaeghe, H., C. Lecoutre, P. Schaus. 2018. Compact-MDD: Efﬁciently ﬁltering (s)MDD constraints

with reversible sparse bit-sets. IJCAI. 1383–1389.

[50] Verhaeghe, H., S. Nijssen, G. Pesant, C.-G. Quimper, P. Schaus. 2020. Learning optimal decision trees using
constraint programming. Proceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial
Intelligence, IJCAI-20. 4765–4769.

[51] Vidal, T., M. Schiffer. 2020. Born-Again Tree Ensembles. Hal Daumé III, Aarti Singh, eds., Proceedings
of the 37th International Conference on Machine Learning, Proceedings of Machine Learning Research,
vol. 119. PMLR, Virtual, 9743–9753.

[52] Ye, Q., W. Xie. 2020. Unbiased subdata selection for fair classiﬁcation: A uniﬁed framework and scalable

algorithms. arXiv preprint arXiv:2012.12356 .

[53] Zafar, M.B., I. Valera, M.G. Rodriguez, K.P. Gummadi. 2017. Fairness constraints: Mechanisms for fair
classiﬁcation. Proceedings of the 20th International Conference on Artiﬁcial Intelligence and Statistics,
AISTATS 2017 54.

A Proof of Theorems

Theorem 1. Formulation (1–18) produces solutions in which all variables w and z take binary
values, leading to a feasible and optimal decision diagram.

Proof of Theorem 1. The proof goes by induction. More precisely, we ﬁrst demonstrate the
following statement:
For each sample i and each layer l ∈ {0, . . . , D − 1}, at most a single u ∈ V I
from this sample, i.e., in such a way that w+
such that w+
iu = 0.

l receives a unit of ﬂow
iu = 1, while the other nodes receive no ﬂow, i.e.,

iu + w−

iu + w−

We start with the base case of layer 0 containing a single node, the root node, which immediately
satisﬁes w+
iu = 1 due to Equation (1). The induction step then goes as follows. Suppose that
there exists a single node ¯u at layer l such that w+

iu + w−

i¯u = 1, as a consequence:

i¯u + w−

12

• If λil = 1, then (cid:80)

w−

u∈V I
l

i¯u + w−

i¯u = 0. Since w+

iu ≤ 0 due to Equation (4) and therefore w−

i¯u = 1,
i¯u = 1. Next, since variables y+ are binary and due to Equation (6), at most one design
¯u¯v takes value 1 for one speciﬁc ¯v. Along with Equation (9), this implies z+
i¯uv = 0 for
i¯uv and therefore z+
i¯u¯v =
l+1 ∪ V C. Next, observe that
l+1 ∪ V C, and therefore

we have w+
variable y+
all v (cid:54)= ¯v. Finally, due to Equation (3), we have w+
1. This means that ¯u ∈ V I
w+
iu = 0 for u (cid:54)= ¯u implies that z+
the other nodes from layer l do not send any ﬂow.
w+

l sends exactly one unit of ﬂow to ¯v ∈ V I
iuv = 0 and z−

i¯u = 1,
i¯u = 1. The rest of the reasoning is identical to the previous case, using the negative-side

we have w−
instead of the positive-side ﬂow along with the corresponding equations.

iu ≤ 0 due to Equation (5) and therefore w+

iuv = 0 for all v ∈ V I

i¯u = 0. Since w+

i¯u = 1 = (cid:80)

v∈δ+(¯u) z+

iu + w−

i¯u + w−

u∈V I
l

• If λil = 0, then (cid:80)

iu and w−

iuv = 1 if and only if w+

l+1 with one unit of ﬂow for sample i,

Overall, this means that ¯v is the only possible node in layer V I
therefore completing the induction step.
Observe that variables w+
iu take binary values in both cases discussed in the induction step.
Moreover, we have z+
iuv = 0. As such, the
integrality of the z variables is implied by the integrality of the w variables. As a consequence, each
sample i follows a single path within the decision diagram down to a terminal node determined by
the w and z variables. Finally, the branch choice at each node (negative-side or positive-side path)
represented by the w and λ variables is directly determined by the position of the sample relative
to the hyperplane due to Equations (13) and (14). Overall, this ensures that the MILP represents
the space of all possible valid models and, in the meanwhile, correctly evaluates the trajectory of
the samples within them to obtain the correct accuracy. An optimal solution of this MILP using
state-of-the-art branch-and-cut solvers therefore permits to train the model to global optimality.

iu = 1 and yuv = 1, otherwise z+

Theorem 2. Our formulation includes O(n log |V|) binary decision variables when applied to
decision-tree skeletons.

Proof of Theorem 2. Our model contains only two families of decision variables which must be
deﬁned as integer (and require possible branching in a branch-and-cut based algorithm): the binary
design variables y and the branch variables λ. The integrality of the rest of the variables directly
derives from the integrality of the former ones, as seen in Theorem 1.
l | = 2l for each layer l ∈ {0, . . . , D − 1}. For such a case, the
A decision-tree skeleton is such that |V I
number of y variables of our model is 2 (cid:80)D−1
l=0 (2l(2l+1+|C|)) = O(4D +2D|C|) = O(|V|(|V|+|C|),
whereas the number of λ variables is in O(nD) = O(n log |V |). We can reasonably assume that the
number of samples is largely superior to |V| and |C|, such that nD (cid:29) |V|(|V| + |C|). As such, the
overall number of integer variables is O(n log |V |).
In comparison, the formulation of [10] creates a complete layer containing 2D terminal nodes, and
associates to each terminal node and sample a binary variable to determine if the sample reaches this
node. This leads to O(n|V|) binary decision variables deﬁning the samples trajectories. In a similar
fashion, there exists other integer variables in the model (e.g., variables deﬁning the class of each
terminal node) which are less numerous under the assumption that n (cid:29) |C| and n (cid:29) |V|.

B Detailed Computational Results

In this section, we provide more details about the numerical study. In particular, we present the list
of datasets used in the experiments, additional results regarding computational performance and
hyperparameters tuning, and an accuracy comparison of ODTs and ODDs per dataset.

B.1 Dataset list

Table 3 lists the 54 datasets on which we conducted the numerical experiments. These datasets are
the same as considered by Bertsimas and Dunn [10]. The 18 datasets indicated with bold font satisfy
the following conditions:

13

Table 3: The 54 datasets used in the computational experiments

Dataset

n

d

|V C|

Dataset

acute-inﬂam-nephritis
acute-inﬂam-urinary
balance-scale
banknote-auth
blood-transfusion
breast-cancer-diag
breast-cancer-prog
breast-cancer-wisconsin
car-evaluation
chess-kr-vs-kp
climate-simul-crashes
congressional-voting
connect-mines-rocks
connect-vowel
contraceptive-method
credit-approval
cylinder-bands
dermatology
echocardiogram
fertility-diagnosis
habermans-survival
hayes-roth
heart-disease-cleveland
hepatitis
image-segmentation
indian-liver-patient
ionosphere

120
120
625
1372
748
569
194
699
1728
3196
540
435
208
990
1473
653
277
366
61
100
306
160
297
80
2310
579
351

6
6
4
4
4
30
33
9
15
37
18
16
60
10
11
37
484
34
9
12
3
4
18
19
18
10
33

2
2
3
2
2
2
2
2
4
2
2
2
2
11
3
2
2
6
2
2
2
3
5
2
7
2
2

iris
mammographic-mass
monks1
monks2
monks3
optical-recognition
ozone-eighthr
ozone-onehr
parkinsons
pima-indians-diab
planning-relax
qsar-biodegradation
seeds
seismic-bumps
soybean-small
spambase
spect-heart
spectf-heart
statlog-german-credit
statlog-landsat-sat
teaching-assist-eval
thoracic-surgery
thyroid-ann
thyroid-new
tic-tac-toe
wall-following-robot-2
wine

n

150
830
556
601
554
5620
1847
1848
195
768
182
1055
210
2584
47
4601
267
267
1000
6435
151
470
3772
215
958
5456
178

d

4
10
11
11
11
64
72
72
22
8
12
41
7
20
35
57
22
44
48
36
52
24
21
5
18
2
13

|V C|

3
2
2
2
2
10
2
2
2
2
2
2
3
2
4
2
2
2
2
6
3
2
3
3
2
4
3

1. Datasets where the MILP model can consistently improve upon the solution found in Step 1
of the training strategy. Speciﬁcally, we select datasets where the model produced a better
solution in at least 125 out of the 250 model runs, considering all combinations of split type
(univariate and multivariate), random seed, skeleton, and value of α.

2. Datasets where the best topology found after Step 2 of the training strategy contains at

least |V C| internal nodes.

Finding ODTs and ODDs in the datasets that do not satisfy condition 1 is a signiﬁcant challenge,
considering also the short computational budget allowed (600 seconds of CPU time). Furthermore,
datasets that do not satisfy condition 2 are less interesting because the training data can be separated
in many cases with a single split at the root node. Hence, the 18 selected datasets allow a more
faithful comparison of the accuracy of ODTs and ODDs, as shown in Figures 2 and 3. We also
provide detailed accuracy comparison over all 54 datasets in Section B.4.

B.2 Computational performance

The proposed MILP for training ODDs is effective in either ﬁnding optimal topologies or improving
the topology found in Step 1 of the training strategy. Figure 5 illustrates the number of model runs
that resulted in a proven optimal topology as a function of the number of samples and features of
each dataset. Note that the MILP is solved 250 times for each dataset (two split types, ﬁve alpha
values, ﬁve topologies – including the tree topology – and ﬁve seeds). Similarly, Figure 6 shows the
number of datasets where the MILP improves upon the solution found in Step 1. As observed, the
difﬁculty of the training problem generally increases with the number of samples. Most distinctly,
the method is able to ﬁnd optimal or improved topologies in high-dimensional datasets with tens or
hundreds of features.

14

Figure 5: Optimal topologies

Figure 6: Improved topologies

B.3 Hyperparameters tuning

The hyperparameter α controls overﬁtting by penalizing the activation of nodes and, consequently,
complex topologies. Whereas ODTs are regularized by tuning only α, ODDs are regularized by tuning
α and also selecting the best skeleton for each dataset and split type, via the same cross-validation
procedure.

Table 4 shows, out of the 108 combinations of datasets and split type, how many are regularized by
each combination of α and skeleton. As seen, a lower α value (which leads to richer topologies) is
preferable for both ODTs and ODDs. Furthermore, each considered skeleton for ODDs is selected in
at least 21% of all runs, which shows that, for a given number of internal nodes, the best conﬁguration
depends largely on the target dataset.

Table 4: Hyperparameters tuning: number of datasets × split type per skeleton and value of α

Skeleton

ODD/ODT α = 0.01

0.1

0.2

0.5

1.0 Total

(1-2-4-8)
(1-2-4-4-4)
(1-2-3-3-3-3)
(1-2-2-2-2-2-2-2)

(1-2-4-8)

Total

ODD
ODD
ODD
ODD

ODT

9
14
8
7

37

75

8
6
6
7

21

48

8
3
2
5

16

34

4
2
4
3

14

27

4
2
3
3

20

32

33
27
23
25

108

216

B.4 Accuracy results

Table 5 shows the out-of-sample accuracy obtained by ODTs and ODDs in all 54 datasets, after
the hyperparameters tuning phase. A paired Wilcoxon signed-rank test indicates that in the case
of multivariate splits ODDs are more accurate than ODTs (p-value of 0.000895). In the case of
univariate splits, both ODDs and ODTs are equally accurate within a signiﬁcance level of 0.05. A
focused analysis on the 18 selected datasets (see Section B.1) also reveals a higher accuracy of ODDs
in the multivariate splits case (p-value of 0.000567): the average accuracy gain in those datasets
amounts to 1.9 percentage points.

B.5 Data fragmentation

Low data fragmentation is a desirable characteristic of tree and diagram classiﬁers, as it improves
model interpretability and stability when confronted with changing data. In general, ODDs are less
prone to data fragmentation, as they allow nodes along an internal layer to consolidate sample ﬂow
from the layer immediately above. Figures 7-11 illustrate several datasets where ODDs lead to
considerably less data fragmentation than ODTs, as observed in our experiments.

15

3103010030010030010003000SamplesFeaturesOptimal0501001502002503103010030010030010003000SamplesFeaturesImproved050100150200250Table 5: Out-of-sample accuracy of ODTs and ODDs, per dataset

ODTs

ODDs

Split

Avg

Split

Avg

Dataset

acute-inﬂammations-nephritis
acute-inﬂammations-urinary
balance-scale
banknote-authentication
blood-transfusion-service
breast-cancer-diagnostic
breast-cancer-prognostic
breast-cancer-wisconsin
car-evaluation
chess-kr-vs-kp
climate-simulation-crashes
congressional-voting
connectionist-mines-vs-rocks
connectionist-vowel
contraceptive-method-choice
credit-approval
cylinder-bands
dermatology
echocardiogram
fertility-diagnosis
habermans-survival
hayes-roth
heart-disease-cleveland
hepatitis
image-segmentation
indian-liver-patient
ionosphere
iris
mammographic-mass
monks1
monks2
monks3
optical-recognition
ozone-eighthr
ozone-onehr
parkinsons
pima-indians-diabetes
planning-relax
qsar-biodegradation
seeds
seismic-bumps
soybean-small
spambase
spect-heart
spectf-heart
statlog-german-credit
statlog-landsat-satellite
teaching-assistant-evaluation
thoracic-surgery
thyroid-ann
thyroid-new
tic-tac-toe
wall-following-robot-2
wine

Multi

1.000
1.000
0.904
0.993
0.774
0.930
0.688
0.952
0.880
0.975
0.890
0.932
0.715
0.381
0.491
0.840
0.667
0.913
0.880
0.768
0.758
0.645
0.549
0.800
0.915
0.706
0.820
0.911
0.817
0.409
0.651
0.403
0.697
0.923
0.938
0.788
0.742
0.526
0.833
0.919
0.928
0.967
0.913
0.627
0.728
0.705
0.809
0.521
0.797
0.993
0.937
0.963
1.000
0.914

Uni

1.000
1.000
0.690
0.969
0.773
0.918
0.721
0.947
0.751
0.939
0.910
0.956
0.731
0.381
0.480
0.872
0.609
0.891
0.933
0.824
0.734
0.555
0.546
0.890
0.915
0.716
0.886
0.947
0.822
0.445
0.545
0.461
0.694
0.935
0.970
0.837
0.726
0.652
0.811
0.885
0.929
0.983
0.899
0.737
0.755
0.684
0.798
0.400
0.831
0.993
0.944
0.807
1.000
0.923

1.000
1.000
0.797
0.981
0.774
0.924
0.704
0.950
0.816
0.957
0.900
0.944
0.723
0.381
0.486
0.856
0.638
0.902
0.907
0.796
0.746
0.600
0.547
0.845
0.915
0.711
0.853
0.929
0.820
0.427
0.598
0.432
0.695
0.929
0.954
0.812
0.734
0.589
0.822
0.902
0.928
0.975
0.906
0.682
0.742
0.694
0.804
0.461
0.814
0.993
0.941
0.885
1.000
0.918

Multi

1.000
0.993
0.901
0.997
0.793
0.941
0.717
0.957
0.881
0.977
0.902
0.943
0.727
0.399
0.483
0.843
0.655
0.900
0.933
0.832
0.753
0.655
0.549
0.730
0.910
0.703
0.852
0.932
0.816
0.471
0.699
0.449
0.740
0.926
0.937
0.829
0.742
0.609
0.829
0.908
0.929
0.950
0.918
0.660
0.737
0.707
0.796
0.505
0.839
0.995
0.948
0.962
1.000
0.932

Uni

1.000
1.000
0.729
0.985
0.778
0.917
0.708
0.939
0.781
0.954
0.895
0.956
0.727
0.340
0.493
0.872
0.661
0.915
0.947
0.792
0.713
0.670
0.549
0.850
0.913
0.716
0.902
0.958
0.814
0.476
0.533
0.467
0.698
0.935
0.971
0.857
0.716
0.652
0.808
0.877
0.929
0.983
0.905
0.737
0.734
0.683
0.803
0.432
0.836
0.994
0.926
0.798
1.000
0.918

1.000
0.997
0.815
0.991
0.785
0.929
0.713
0.948
0.831
0.966
0.899
0.950
0.727
0.370
0.488
0.858
0.658
0.908
0.940
0.812
0.733
0.663
0.549
0.790
0.912
0.710
0.877
0.945
0.815
0.473
0.616
0.458
0.719
0.931
0.954
0.843
0.729
0.630
0.818
0.892
0.929
0.967
0.912
0.699
0.736
0.695
0.800
0.468
0.837
0.995
0.937
0.880
1.000
0.925

Average

0.799

0.795

0.797

0.809

0.799

0.804

16

(a) ODT structure

(b) ODD structure

Figure 7: Fragmentation of an ODT and an ODD trained on the “credit approval” dataset

(a) ODT structure

(b) ODD structure

Figure 8: Fragmentation of an ODT and an ODD trained on the “monks3” dataset

(a) ODT structure

(b) ODD structure

Figure 9: Fragmentation of an ODT and an ODD trained on the “parkinsons” dataset

17

(a) ODT structure

(b) ODD structure

Figure 10: Fragmentation of an ODT and an ODD trained on the “spect-heart” dataset

(a) ODT structure

(b) ODD structure

Figure 11: Fragmentation of an ODT and an ODD trained on the “statlog german credit” dataset

18

