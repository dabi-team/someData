Scaling Guarantees for Nearest Counterfactual Explanations

Kiarash Mohammadi1, Amir-Hossein Karimi2, Gilles Barthe3, Isabel Valera4
1MPI for Intelligent Systems and Ferdowsi University of Mashhad, 2MPI for Intelligent Systems and ETH-Z¨urich
3MPI for Security and Privacy and IMDEA Software Institute, 4MPI for Software Systems and Saarland University
{kiarash.mohammadi, amir}@tue.mpg.de, gjbarthe@gmail.com, ivalera@cs.uni-saarland.de

1
2
0
2

b
e
F
8

]

G
L
.
s
c
[

2
v
5
6
9
4
0
.
0
1
0
2
:
v
i
X
r
a

Abstract

Counterfactual explanations (CFE) are being widely used
to explain algorithmic decisions, especially in consequential
decision-making contexts (e.g., loan approval or pretrial bail).
In this context, CFEs aim to provide individuals affected by
an algorithmic decision with the most similar individual (i.e.,
nearest individual) with a different outcome. However, while
an increasing number of works propose algorithms to com-
pute CFEs, such approaches either lack in optimality of dis-
tance (i.e., they do not return the nearest individual) and per-
fect coverage (i.e., they do not provide a CFE for all individ-
uals); or they do not scale to complex models such as neu-
ral networks. In this work, we provide a framework based on
Mixed-Integer Programming (MIP) to compute nearest coun-
terfactual explanations for the outcomes of neural networks,
with both provable guarantees and runtimes comparable to
gradient-based approaches. Our experiments on the Adult,
COMPAS, and Credit datasets show that, in contrast with pre-
vious methods, our approach allows for efﬁciently computing
diverse CFEs with both distance guarantees and perfect cov-
erage.

Introduction
Machine learning models are increasingly being used to
assist in semi-automated prediction and decision-making
for consequential scenarios such as pretrial bail and loan
approval. Speciﬁcally, end-to-end trained models such as
(deep) neural networks (LeCun, Bengio, and Hinton 2015)
(with non-linearities such as ReLU) have proven effective
at learning and discovering complex non-linear patterns and
relations in the data, and hence are becoming widely de-
ployed. However, predictive power often comes at the cost
of loss in interpretability (Rudin 2018), i.e., our ability to un-
derstand not only the decision made, but also the process by
which the decision was deduced. Importantly, interpretabil-
ity can assay the safe, robust, privacy-preserving, fair, and
causally consistent nature of this decision-making (Doshi-
Velez and Kim 2017).

Inspired by this, Counterfactual Explanations (CFEs) are
introduced to provide individuals with an understanding of
their situation in relation to a close hypothetical scenario in
which they would have been treated favorably. As for the

Copyright © 2021, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

process of generating CFEs, a number of criteria are of con-
cern: i) optimal distance, i.e., nearest explanation; ii) per-
fect coverage, i.e., providing all individuals with an expla-
nation; iii) support for expressive models (e.g. neural net-
works); iv) efﬁcient runtime; v) support for heterogeneous
input spaces; and, vi) qualitative features such as actionabil-
ity, plausibility, diversity, sparsity, etc. While all these cri-
teria have been discussed in previous works on CFE gen-
eration (Verma, Dickerson, and Hines 2020; Karimi et al.
2020b), existing approaches however lack in at least one of
them.

On one hand, providing the explanations with provable
guarantees on the objectives (e.g., the proximity to the fac-
tual sample) has been studied by reducing the problem to
a Satisﬁability Modulo Theories (SMT) problem (Karimi
et al. 2020a; Karimi, Sch¨olkopf, and Valera 2020) or to a
Mixed-Integer Programming (MIP) problem (Russell 2019;
Kanamori et al. 2020; Ustun, Spangher, and Liu 2019).
These approaches could theoretically be extended to sup-
port many classes of models, however, in practice this has
only been demonstrated for simple classes of models, being
high runtimes their main bottleneck. As an example, Karimi
et al. (2020a) show that even for reasonably small Neural
Networks (NNs) (e.g. 20 neurons) the backend SMT solver
might never terminate. In contrast, MIP-based approaches,
however, so far ignore the class of NN models but instead
work with simple linear (Russell 2019; Ustun, Spangher,
and Liu 2019) or tree-based (Kanamori et al. 2020) mod-
els, emphasizing qualitative metrics of the explanations. On
the other hand, counterfactual explanations can be efﬁciently
generated for (differentiable) NN models using gradient-
based optimization techniques (Mothilal, Sharma, and Tan
2020). However, while such approaches do work efﬁciently
for NNs, they do not provide any guarantees in terms of
distance or coverage. Moreover, they also suffer from lim-
itations to incorporate qualitative aspects of CFE such as
actionability constraints–e.g., an input feature capturing in-
dividuals’ age is only actionable in one direction, i.e., an
individual can only increase her age. Conclusively, previ-
ous approaches for CFE generation either ignore the class of
neural models or cannot provide the aforementioned guaran-
tees; the exception being MACE (Karimi et al. 2020a) which
suffers from exponentially high runtimes. While NNs are be-
coming increasingly popular to adopt by stake-holders as a

 
 
 
 
 
 
ﬂexible non-linear model, an efﬁcient approach with guar-
antees is necessary for explaining their decisions.

A similar problem to CFEs, in terms of formulation as a
constrained optimization problem, is the generation of ad-
versarial examples for NNs. This problem has been broadly
addressed by the NN veriﬁcation community (Liu et al.
2019), where both SMT- and MIP-based approaches have
been explored to efﬁciently solve the problem of ﬁnding ad-
versarial examples in ReLU-activated NNs which is, in fact,
shown to be NP-complete (Katz et al. 2017). It is, however,
important to note that while these two problems are formally
similar and ideas can be exchanged among them, they are
semantically and practically different (Wachter, Mittelstadt,
and Russell 2017). Thus, approaches to handle adversar-
ial examples in NNs cannot be directly applied to generate
CFEs (Freiesleben 2020).

In this work, we extend the ideas and tools from the NN
veriﬁcation community to develop an efﬁcient framework to
compute CFEs for ReLU-activated NN models, to provide
distance and coverage guarantees, as well as to accommo-
date for previously discussed qualitative features. Speciﬁ-
cally, we ﬁrst propose three efﬁcient approaches to search
for a CFE within a given interval in the input feature space:
whereas the ﬁrst approach relies on SMT solvers as the back-
end, the other two approaches formulate the problem as a
MIP and differ in the way that the CFE distance is optimized.
All the three approaches make use of a linear approximation
of the ReLU-NNs (Ehlers 2017) to compute bounds on the
hidden units of the NN, given bounds on both the input fea-
ture space and/or distance. We then describe how to incor-
porate several qualitative features in our framework, includ-
ing heterogeneous distance functions, as well as diversity
and plausibility constraints (Kanamori et al. 2020; Russell
2019).

Finally, we experiment our approaches on the before-
mentioned criteria and compare against SMT- and gradient-
based approaches that support NNs. Table 1 summarizes the
fulﬁllment of different criteria in CFE generation by our ap-
proach in comparison with previous (SMT-, gradient-, and
MIP-based) approaches. Our empirical results conﬁrm a sig-
niﬁcant improvement in runtime efﬁciency, yielding novel
MIP-based approaches for CFE generation on the class of
NN models. Importantly, in addition to efﬁciently generating
CFEs, our presented approaches are optimal in distance and
perfect in coverage. This efﬁciency even allows for generat-
ing sets of counterfactuals meeting different criteria, as we
show by generating sets of diverse CFEs. Hence, while up to
date, runtimes were the main bottleneck for CFE generation
with guarantees for NN architectures, our MIP approach per-
forms even faster than gradient-based optimization for NNs
at the scale of consequential decision-making scenarios.

Background
We ﬁrst introduce counterfactual explanations and two ways
of formulating the problem, through optimization and veri-
ﬁcation. We then explain how the neural network model can
be encoded within frameworks capable of solving the coun-
terfactual explanation generation problem exactly and with
guarantees.

Counterfactual Explanations
Assume that we are given a trained binary classiﬁer h : X →
IR that determines a positive outcome when h(x) ≥ 0 and
a negative outcome when h(x) < 0, deciding, e.g., whether
an individual is eligible to receive a loan or not. Consider
an individual xF where h(xF ) < 0 (loan denial); for this
individual, we would like to offer an answer to the question
”What would have to be different for you to achieve a posi-
tive outcome next time?” 1 Answers to this question may be
offered as a feature vector corresponding to an (hypotheti-
cal) individual on the other side of the decision boundary,
and is referred to as a counterfactual explanation (CFE).

There are a number of criteria/constraints that a CFE
should satisfy to be useful for the individual (Wachter, Mit-
telstadt, and Russell 2017). A CFE should ideally be as sim-
ilar as possible to the individual’s current scenario (the fac-
tual instance), corresponding to the smallest change in the
individual’s situation that would favorably alter their pre-
diction. Furthermore, the change in features and the result-
ing counterfactual instance must satisfy additional feasibil-
ity and plausibility constraints, respectively. For instance, a
change in features that would require the individual to de-
crease their age would be infeasible (a.k.a. non-actionable).
Relatedly, we must make sure that the alternative scenario
lies within the heterogeneous input space (i.e., is plausi-
ble) since in the consequential decision-making domains,
we typically work with mixed data types with a variety of
statistical properties, such as age, race, bank balance, etc.

These requirements can be made more precise by assum-
ing a notion of distance dist between inputs, as well as pred-
icates P lausible and Actionable for plausibility and action-
ability.

CFE Optimization Formulation Counterfactual expla-
nations can be modelled as a constrained optimization prob-
lem:

xCF E ∈ arg min

dist(x, xF )

x∈X

s.t.

h(x) ≥ 0
x ∈ P lausible
x ∈ Actionable

(1)

The above optimization problem can be solved using Gradi-
ent Decent (GD) or linear programming, depending on the
objective function and the constraints, and yields the closest
input xCF E (with respect to xF ) that is plausible, action-
able, and makes the decision of h ﬂip.

CFE Veriﬁcation Formulation Counterfactual explana-
tions can be modelled as a satisfaction problem:

∃x.dist(x, xF ) ≤ δ
h(x) ≥ 0
x ∈ P lausible
x ∈ Actionable

(2)

1It is commonly assumed that the model is ﬁxed and does not

change over time.

Method

Opt. Distance

100% Coverage

Efﬁciency Neural Models Qualitative Features Complex Constraints

Our approach
MACE 1
DiCE 2
Efﬁcient Search 3

(cid:88)
(cid:88)

(cid:88)

(cid:88)
(cid:88)

(cid:88)

(cid:88)

(cid:88)
(cid:88)

(cid:88)
(cid:88)
(cid:88)

(cid:88)
(cid:88)
(cid:88)
(cid:88)

(cid:88)
(cid:88)

(cid:88)

Table 1: Comparison of related work with our approach.
1 Karimi et al. (2020a), 2 Mothilal, Sharma, and Tan (2020), 3 Russell (2019)

where δ is a distance threshold. The above satisfaction prob-
lem guarantees the existence of a counterfactual that is plau-
sible, actionable, and within distance δ of xF . Using a
suitable search strategy over δ, it is then also possible to
minimize δ (to an arbitrary precision) and ﬁnd the near-
est counterfactual explanation. For example, MACE (Karimi
et al. 2020a) encodes the above formulation using First-
order logic and uses an SMT solver to ﬁnd a series of coun-
terfactuals within a binary search that minimizes δ.

The precise formulation of the satisfaction problem de-
pends on an encoding of h. Speciﬁcally, one must encode
the classiﬁer h in the language of logic. While the encod-
ings are theoretically well-understood, it is crucial to choose
an encoding that guarantees the scalability of the method.
Indeed, even for the simplest models, such as decision trees,
naive encodings lead to veriﬁcation tasks that exceed the ca-
pabilities of current tools. An important challenge is thus to
develop efﬁcient encodings of other models, and in particu-
lar of NNs.

Encoding NNs using SMT and MIP
Outside of the domain of consequential decision-making,
similar formulations to the CFE problem can be seen in
the problem of adversarial examples (Papernot et al. 2017;
Moosavi-Dezfooli et al. 2017; Carlini and Wagner 2017).
Here, there is a well-studied line of research towards verify-
ing different properties of neural networks (Liu et al. 2019),
such as robustness towards adversarial examples. In this re-
gard, many works focus on proving that a property holds or
a counterexample exists. Among these works, many rely on
SMT solvers, MIP-based optimization, or both (Ehlers 2017;
Katz et al. 2017; Bunel et al. 2018).

Neural network veriﬁcation task (for ReLU-activated
NNs) is shown to be NP-complete (Katz et al. 2017). Dif-
ferent works, thus, try to make use of some properties and
guide the search process in a way to work better than con-
ventional off-the-shelf solvers or optimizers. Subsequently,
we try to do the same for CFE generation and extend the
previous work, MACE (Karimi et al. 2020a), to work better
than using off-the-shelf solvers in a straight-forward manner.
This happens through, e.g., guiding the search process by
gradually increasing the distance within which we are look-
ing for a counterfactual explanation, keeping the distance
interval as small as possible to prune domains efﬁciently.

In the following, we explain how to represent NNs using
First-order predicate logic formulae and as an MIP that pro-
vide bounds on the optimization variables, later resulting in
efﬁcient domain pruning within the search for CFEs.

First-order Logic (SMT) Encoding of Neural Networks
It is rather straight-forward to encode neural networks us-
ing a First-order logic representation that is acceptable by
Satisﬁability Modulo Theories (SMT) oracles (Karimi et al.
2020a). Figure 1 shows this through an example (ˆz1 and ˆz2
represent the post-ReLU values).
x1

1

2

− 1

0

0
− 1

x2

x3

z1

ˆz
1,−1

z3

1

z2

ˆz

φf (x) =

2 ,
(z1 = x1 − x2) ∧ (z2 = 2x1 − x3)
∧((ˆz1 = z1 ∧ z1 ≥ 0) ∨ (ˆz1 = 0 ∧ z1 < 0))
∧((ˆz2 = z2 ∧ z2 ≥ 0) ∨ (ˆz2 = 0 ∧ z2 < 0))
∧(z3 = − ˆz1 + ˆz2)

Figure 1: A ReLU-activated neural network and its corre-
sponding logic formula

Unbounded Mixed-integer Program Encoding of Neural
Networks We try to be faithful to the notation from Liu
et al. (2019). Consider an n-layer single-output feed-forward
neural network (NN) with ReLU activations after each hid-
den layer that represents the function h(x). The width of
each layer is ki and zi is the vector of dimension ki which
represents layer i where i ∈ {1, 2, ..., n}. While zi repre-
sents the pre-ReLU activations, ˆzi is the values after ReLUs
have been applied. Finally, δi are vectors of binary variables
indicating the state of each ReLU; 0 for inactive and 1 for
activated ReLUs.

There are multiple ways to encode neural networks as
MIPs in the NN veriﬁcation literature, each proposing dif-
ferent encodings for ReLU activations. A generic form is as
follows. For i ∈ {1, ..., n} and j ∈ {1, ..., ki}:

zi = Wiˆzi−1 + bi

δi ∈ {0, 1}ki, ˆzi = zi · δi,
δi,j = 1 ⇒ zi,j ≥ 0,
δi,j = 0 ⇒ zi,j < 0

(3a)

(3b)

The ﬁrst part (3a) is simply the linear afﬁne of weights and
the second part (3b) encodes the following ReLUs using the
introduced binary variables for each ReLU. We refer to this
as the unbounded MIP encoding.

Bounded Mixed-integer Program Encoding of Neural
Networks Bunel et al. (2018) suggest that most NN ver-
iﬁers, based on either SMT or MIP solvers, are indeed a

variation of Branch-and-Bound (B&B) optimization. This
understanding implies that limiting the bounds of the vari-
ables of the optimization problem is a very effective heuris-
tic. Moreover, the extra constraints of the CFE generation
problem – making the veriﬁcation formulation difﬁcult to
solve – might actually help tightening the bounds, and thus,
result in an effective pruning of the domains of the optimiza-
tion problem. We will thus, change the generic ReLU for-
mulation (3b) and adopt the bounded encoding proposed by
Tjeng and Tedrake (2017), i.e., for i ∈ {1, ..., n}:

δi ∈ {0, 1}ki,
ˆzi (cid:62) zi,

zi = Wiˆzi−1 + bi
ˆzi (cid:62) 0,
ˆzi (cid:54) ui · δi,
ˆzi (cid:54) zi − li · (1 − δi)

(4a)

(4b)

Note that the linear part (4a) is the same as (3a) and also
note that this is still an exact encoding of NNs using MIP
since δi,j = 0 ⇔ ˆzi,j = 0 and δi,j = 1 ⇔ ˆzi,j = zi,j. This
encoding relies on li and ui, vectors indicating the lower
and upper bounds of the values of the hidden units at layer i.
We remind that tight bounds can be very effective in domain
pruning when solving the mixed-integer program. Here, we
introduce two ways to obtain such bounds and complete the
MIP formulation (4) for CFEs: ﬁrst, using interval arithmetic
(Hickey, Ju, and Van Emden 2001), and second, using an ap-
proximation of ReLUs that results in tighter bounds. In both
cases, we assume that we have initial lower/upper bounds on
the values of the input layer (e.g., derived from the dataset).
This is a valid assumption since real-world features such as
age or income do have bounds.

Interval arithmetic. By using interval arithmetic (Hickey,
Ju, and Van Emden 2001), having the bounds at layer i − 1,
we can compute the bounds for the j-th neuron from the i-th
layer (zi,j) as:

li,j = Σki−1

t=1 (max(Wi,j,t, 0) · li−1,t

+ min(Wi,j,t, 0) · ui−1,t) + bi,j

ui,j = Σki−1

t=1 (max(Wi,j,t, 0) · ui−1,t

+ min(Wi,j,t, 0) · li−1,t) + bi,j

(5)

The post-ReLU bounds (for ˆzi,j) are obtained simply by ap-
plying a ReLU on these bounds.

This is applied layer-by-layer and the bounds for all hid-
den units are computed recursively starting from the input
layer. Unfortunately, although better than having no bounds
at all, these bounds quickly become loose as we go deeper in
the network. The reason is that in each layer i, each neuron
is choosing a worst-case bound (lower or upper) from the
neurons of the previous layer i − 1, independently from the
rest of the neurons in layer i, causing conﬂicts in the choice
of the lower or upper bound for some neurons in layer i−1.2

Linear over-approximation of ReLUs. To compute
tighter bounds than interval arithmetic, we ﬁrst adopt the lin-
ear over-approximation of ReLUs proposed in (Ehlers 2017)
to replace (3b), i.e., for i ∈ {1, ..., n} and j ∈ {1, ..., ki}:
zi = Wiˆzi−1 + bi

(6a)

2Refer to the Appendix for more explanation by an example.

ˆzi (cid:62) zi,

ˆzi (cid:62) 0,

ˆzi,j (cid:54) ui,j

zi,j − li,j
ui,j − li,j

(6b)

Again, the linear part (6a) is the same as (3a). For the
ReLU part (3b), the binary variables encoding the ReLUs
in an exact way are removed and, instead, a linear over-
approximation term has been replaced (6b). This results in
a fully linear MIP system without the ReLU binary vari-
ables, whose optimization for different objectives can be
performed efﬁciently.

As before, the bounds are recursively computed in a layer-
by-layer manner, and the constraints of the linearized net-
work (6) are added to the MIP system progressively. At each
layer i, ﬁrst, (6a) is added with bounds of the variables com-
puted using simple interval arithmetic from the tight bounds
computed for the previous layer. Then, to ﬁnd better bounds
than simple interval arithmetic, having included all the con-
straints up until this layer, two MIPs are solved for each hid-
den unit: one with the objective of maximizing the value of
the unit to compute an upper bound, and a similar one for
computing the lower bound. Finally, the ReLU constraints
(6b) for this layer are added with the just-computed tight
bounds.2 Note that while we have opted for the ReLU acti-
vation function as a common source of non-linearity, any ac-
tivation function that can be approximated by piece-wise lin-
ear functions is applicable, e.g., Max-Pooling (Ehlers 2017).
We build upon an implementation from Bunel et al.
(2018) for this purpose. Obtaining tight bounds here relies
on how small the domains of the input variables are; keeping
the input domains small enough will result in tighter bounds
for other variables. This will be discussed in more detail in
the next section.

CFE Generation
In this section, we propose three approaches towards CFE
generation for neural networks. All the approaches rely on
the linearized network approximations described in the pre-
vious section, which provide tight lower and upper bounds
on the values of the hidden units. Below, we ﬁrst explain the
search strategy on the distance of the nearest CFE and the
way lower/upper bounds on the input and hidden units are
computed within this search. Then, we introduce three ap-
proaches towards efﬁcient nearest CFE generation for neural
networks.

Preliminaries
Exponential Search Strategy.
In order to optimize the
distance towards ﬁnding the nearest CFE, we implement
an exponential search strategy (Baeza-Yates and Salinger
2010). W.l.o.g., we assume here that the input space is nor-
malized and lies within the [0, 1] interval. Because the inter-
val of the input layer determines those of later layers, we ini-
tiate our search with a small distance interval, whose lower
and upper bound are set respectively to 0 and an (arbitrarily)
small (cid:15). We then exponentially increase the search interval
until a CFE is found. Finally, a simple binary search is per-
formed on the interval where the CFE was found to look
for the nearest CFE. The overall scheme for the exponential
search is summarized in Algorithm 1.

Algorithm 1: Exponential Search Strategy
Input: N, xF , (cid:15)
Output: closest CFE
[lbdist, ubdist] ← [0, (cid:15)];
while findCFE(N, xF , lbdist, ubdist) is None do

lbdist ← ubdist;
ubdist ← ubdist × 2;

end
closest CFE
← binarySearch(N, xF , (cid:15), lbdist, ubdist);
return closest CFE;

Next, we discuss how to compute bounds on both the in-
put and hidden units of the network, which are necessary to
efﬁciently implement the CFE search function, findCFE in
Algorithm 1.

Computing Bounds for Input and Hidden Units. We
leverage the network approximator based upon equation (6)
to compute the bounds of the network input and hidden
units for a given distance interval [lbdist, ubdist]. To this
end, we ﬁrst obtain the MIP encoding of the distance. Then,
we optimize the MIP-encoded distance for each input vari-
able, maximizing/minimizing each variable to obtain the
lower/upper bounds of the input layer for the given distance
interval. Then, the input bounds are propagated in the NN
to compute the bounds of hidden units. We include the dis-
tance constraints in the initial constraint set of the linearized
network to help ﬁnding tighter bounds for the hidden units.
Algorithm 2 shows the overall scheme for this.

Algorithm 2: Bounds Computation
Input: N, xF , lbdist, ubdist
Output: LBnet, UBnet
φdist ←
getDistanceConstraints(N, xF , lbdist, ubdist);

lbinp, ubinp ← optimizeInputVars(N, φdist);
LBnet, UBnet ←
linearizedNetApproximator(N, lbinp, ubinp, φdist);

return LBnet, UBnet;

Approaches
In this section, we propose three efﬁcient approaches to
implement the CFE search function, findCFE in Algo-
rithm 1, for neural networks. The ﬁrst approach relies on
SMT solvers as backend and uses the bounds computation
as a heuristic within each iteration of the exponential search
(Algorithm 1). The second and third approaches instead
rely on MIP solving to search for CFEs. The difference be-
tween them lies on the optimization of the distance – while
the second approach minimizes the CFE distance using the
exponential search described above, the third approach in-
cludes the distance as objective within the MIP optimization

framework. Next, we provide further details on the three ap-
proaches.

ReLU Elimination (MIP-SAT).
In this approach, we
build upon MACE (Karimi et al. 2020a) (SMT solving in
the backend) and use the bounds computation as a heuristic.
Within each iteration of the exponential search (Algorithm
1), and given the distance interval, the bounds on the input
and hidden units are computed using Algorithm 2 and Re-
LUs with a ﬁxed state are determined. A ReLU has a ﬁxed
state iff the value of the neuron before applying ReLU has
either a lower bound greater than or equal to zero, or an up-
per bound less than or equal to zero.

The neural network, distance functions, as well as addi-
tional constraints are primarily encoded as SMT formulae.
For the NN bound computation, the NN and distance con-
straints are encoded as MIPs, as described before. Next,
the ReLUs with a ﬁxed-state are removed from the initial
SMT formula representing the NN. This means that, for
an always-active ReLU, we will have ˆzi = zi and for an
always-inactive ReLU we will have ˆzi = 0, instead of the
initial ReLU clause: (ˆzi = zi ∧ zi ≥ 0) ∨ (ˆzi = 0 ∧ zi < 0).
This is, basically, removing the disjunction associated to the
ReLU states by ﬁxing its value, saving the SMT solver the
effort to branch over its cases. Finally, the SMT solver (Z3
solver (de Moura and Bjørner 2008) in our case) is called
with the new formula to verify the existence of a CFE within
the given distance interval.

Note that the ReLU clauses in the SMT representation of
the neural network are exponentially expensive to handle for
the SMT solver since it needs to branch over the cases. Thus,
removing a subset of the RELU activations will reduce the
run-time exponentially (as empirically shown in the experi-
ments). Algorithm 3 shows the overall scheme for the pro-
posed mixed MIP-SAT approach.

Algorithm 3: The MIP-SAT approach – findCFE
in Algorithm 1
Input: N, xF , lbdist, ubdist
Output: CFE or None
φdist ←
getDistanceFormula(N, xF , lbdist, ubdist);
φpls ← getPlausibilityFormula(N);
φN ← getModelFormula(N);
LBnet, UBnet ←
computeBounds(N, xF , lbdist, ubdist);
φN ← eliminateRelus(φN , LBnet, UBnet);
if SAT(φN ∧ φdist ∧ φpls) then

return CFE;

else

return None;

Output Optimization (MIP-EXP).
In this approach, we
purely use a MIP-based optimization process (no SMT or-
acle), for which we deploy an optimization engine (Gurobi
(Gurobi Optimization 2020) in this case), building upon an
implementation of (4) from Bunel et al. (2018).

As before, we assume that we are within an iteration of
the exponential search (Algorithm 1) with a ﬁxed distance
interval [lbdist, ubdist]. First, Algorithm 2 is called to com-
pute tight lower/upper bounds for the input and hidden units
of the network. Next, these bounds are used to obtain MIP
encoding of the neural network as in (4). Then the distance,
as well as any other additional constraints (all explained in
the next section), are added to MIP formulation. Finally, de-
pending on the (predicted) label of the factual sample xF ,
the single output of the network is optimized. For instance,
for a factual sample with a positive label, the output of the
network will be minimized with a callback that interrupts the
optimization as soon as a counterfactual with a negative out-
put value is found. Otherwise, the lower bound of the output
of the network for this factual sample and distance interval
is greater than zero and no counterfactual exists. The over-
all scheme of the proposed MIP-EXP approach is shown in
Algorithm 4.

Note that this approach no longer uses an SMT oracle, but
instead relies on an optimization engine to solve a mixed-
integer program with the single output of the network as
its objective function. Thus, it can naturally be extended to
multi-class classiﬁcation by introducing a new variable in
the MIP that preserves the maximum logit among class out-
puts on which the optimization objective is deﬁned.

Algorithm 4: The MIP-EXP approach – findCFE
in Algorithm 1
Input: N, xF , lbdist, ubdist
Output: CFE or None
φdist ←
getDistanceConstraints(N, xF , lbdist, ubdist);

φpls ← getPlausibilityConstraints(N);
LBnet, UBnet ←
computeBounds(N, xF , lbdist, ubdist);
φN ←
getModelConstraints(N, LBnet, UBnet) ;
// MIP encoding 4
if optimize(φN , φdist, φpls, xF ) then

return CFE;

else

return None;

Distance Optimization (MIP-OBJ). This is similar to the
MIP-EXP approach except that we remove the outer loop
(the exponential search of Algorithm 1) and the distance
function is introduced as the objective function of the MIP
to be minimized.

In this approach, which we refer to as MIP-OBJ, Algo-
rithm 2 is called to compute the bounds with the distance in-
terval being [0, 1]. The computed bounds are placed within
MIP encoding (4). Since now the objective of the MIP is the
distance function, we need to add a constraint as the counter-
factual constraint determining the single output of the net-
work being negative or positive based on the (predicted) la-
bel of the factual sample. The whole problem is optimized

(with an optimality gap of (cid:15) for the distance objective to be
analogous to the other approaches) and the nearest CFE is
found. Algorithm 5 shows the overall scheme of the MIP-
OBJ approach.

Algorithm 5: The MIP-OBJ approach
Input: N, xF , lbdist, ubdist
Output: CFE or None
obj ← getDistanceConstraints(N, xF );
φpls ← getPlausibilityConstraints(N);
φCF E ←
getCounterfactualConstraint(N, xF );
LBnet, UBnet ← computeBounds(N, xF , 0, 1) ;
// No distance limit
φN ←
getModelConstraints(N, LBnet, UBnet) ;
// MIP encoding 4
CF E ← optimize(φN , φpls, φCF E, obj, xF );
return CFE;

Distance Functions and Qualitative Features
In this section ,we describe how the distance metric, as
well qualitative features–such as plausibility, sparsity and
diversity–can be encoded within the MIP framework. First,
we provide details on the encoding of distance functions
suitable for heterogeneous input features. Second, in the
context of plausibility, we describe how to handle hetero-
geneous input spaces, i.e., input features with mixed data
types. Finally, we focus on a broadly studied qualitative
property of CFEs, diversity. We would like to emphasize that
previous MIP-based approaches have recognized the ﬂexi-
bility of mixed-integer programming in regards to encode a
wide range of complex constraints and different qualitative
features (Russell 2019; Kanamori et al. 2020), however, this
cannot be directly leveraged for NN models. We defer to fu-
ture work to address a wider range of qualitative features for
NN class of models.

Distance Functions
In this section, we provide more details on the MIP en-
coding of heterogeneous distance functions.3 We provide
details on an (cid:96)1 distance function (analogous to previous
works (Wachter, Mittelstadt, and Russell 2017)) while zero-,
two-, and inﬁnity-norms are supported in an analogous
manner, each providing a different practical intuition for
the proximity of the CFEs, e.g., (cid:96)0 used for sparsity. As
described before, the distances are all range normalized and
within the [0, 1] interval.

Integer-valued and real-valued features. For an input vec-
tor x and factual sample xF with such a feature at the i-
th dimension, the normalized (cid:96)1 distance is computed in a
straight-forward manner:

3For conciseness, the intermediate variables used to practically

encode the functions within the MIP model are excluded here.

distreal(xi, xF

i ) =

|xi − xF
i |
ubi − lbi

(7)

where lbi, ubi are the scalar lower/upper bounds for xi.

Ordinal features. For an input vector x and factual sample
xF with an ordinal feature xi having k levels, the normal-
ized (cid:96)1 distance is computed in the following manner:

distord(xi, xF

i ) =

| (cid:80)k

j=1 xi,j − (cid:80)k
k

j=1 xF

i,j|

(8)

Categorical features. For an input vector x and factual sam-
ple xF with a categorical feature xi having k categories, the
normalized (cid:96)1 distance is computed in the following manner:

distcat(xi, xF

i ) = max
1≤j≤k

(xi,j − xF

i,j)

(9)

In the end, the total normalized (cid:96)1 distance between in-
put vector x and factual sample xF would be the normal-
ized sum over distances of different data types (7), (8), (9),
nreal, nord, ncat being the number of features in each of the
three groups above:

dist(x, xF) =

1
nreal + nord + ncat
nord(cid:88)

distord(xi, xF

i ) +

+

i=1

nreal(cid:88)
(

distreal(xi, xF
i )

i=1

ncat(cid:88)

i=1

distcat(xi, xF

i ))

(10)

Sparsity. Sparsity can be interpreted as the (cid:96)0 distance func-
tion. It is encoded by introducing a number of intermedi-
ate binary variables each retaining whether or not a feature
has changed its value and then summed over and normalized
analogous to the described (cid:96)1 distance.

Plausibility Constraints
In this section we explain plausibility constraints that
guarantee the CFE lying within the same heterogeneous
space as input. Plausibility constraints for integer-valued,
real-valued, and binary variables are naturally preserved
by deﬁning the right kind of variables within the MIP (or
SMT) model.

Ordinal features. To guarantee that the CFEs are plausi-
ble in terms of ordinality of the ordinal features, for each
such feature f with k levels, we deﬁne k binary variables
f1, ..., fk ∈ {0, 1} in the MIP model. For each set of these
variables, the following constraints are added to the MIP
model:

f1 ≥ f2, f2 ≥ f3, ..., fk−1 ≥ fk

(11)

This will guarantee that: (cid:54) ∃ i s.t. fi+1 > fi.

Categorical features. We want to guarantee that in the pro-
duced CFE, for each categorical feature, only one category
is chosen. For a categorical feature f with k categories, we
deﬁne k binary variables f1, . . . , fk ∈ {0, 1} in the MIP
model. For each set of these variables, the following con-
straint is added to the MIP model:

f1 + f2 + · · · + fk = 1
(12)
Since fi’s are binary variables, this will guarantee that only
one of them is 1 and others are 0, meaning that at most one
category is active as desired.

Diversity Constraints
Providing individuals with different, preferably diverse,
counterfactuals can be beneﬁcial in terms of providing al-
ternative ways for the individuals to improve their outcome.
Having different diverse (and close) counterfactuals, the in-
dividuals may ﬁnd the most suitable way to achieve the pre-
ferred outcome while considering their own personal con-
straints, about which the explanation-provider might not be
aware of.

As with other qualitative features, there are different ways
for encoding diversity in the literature of CFE generation.
Within the MIP-based approaches, Russell (2019) encodes
diversity simply as the newly generated CFE not being equal
to the previously generated ones. Based on the evaluation
criteria, this could fail to generate diverse CFEs, for ex-
ample when the evaluation criteria is the mean of the pair-
wise distances of the (k) generated CFEs as DiCE (Mothilal,
Sharma, and Tan 2020) suggests. Among the gradient-based
approaches, DiCE (Mothilal, Sharma, and Tan 2020) ac-
counts for diversity using determinantal point processes, i.e.,
it includes the determinant of the kernel matrix given the
counterfactuals in the objective.

It is important to also take into account the distance of the
generated set of diverse counterfactuals since it is necessary
for this set to also be close to the individual for which it is
being generated. Thus, it can be seen that there is an inherent
tradeoff between diversity and distance. To account for this,
we encode diversity as a set of constraints for each newly
generated counterfactual to have a distance above a ﬁxed
threshold from each of the previously generated counterfac-
tuals, while minimizing the distance to the factual sample.
More speciﬁcally, the following set of constraints will be
added before the search for the i-th CFE:

dist(xCF E

1

, xCF E
i

) ≥ δ
. . .

(13)

) ≥ δ

dist(xCF E

i−1 , xCF E
i
Note that solving the MIP becomes progressively more
expensive for each new counterfactual. We have imple-
mented a version of our approach called MIP-DIVERSE for
generating diverse counterfactuals using the above formula-
tion.

Experiments
We conduct a number of quantitative and qualitative ex-
periments to demonstrate our frameworks abilities relative

to existing approaches: MACE (Karimi et al. 2020a) 4
and DiCE (Mothilal, Sharma, and Tan 2020).5 Following
the motivation explained in the Introduction, we generate
counterfactual explanations for ﬁxed-width ReLU-activated
fully-connected NN models of various sizes, having N ×
W +(D−1)·W 2+(D+1)×W total parameters, N being the
input size, W width, and D depth. To support consequential
decision-making settings, we employ three widely used real-
world datasets from the counterfactual explanations litera-
ture: Adult (d = 51) (Adult data 1996), COMPAS (d = 7)
(Larson et al. 2016), and Credit (d = 20) (Bache and Lich-
man 2013). Finally, all approaches are evaluated and com-
pared on their optimality of distance, coverage, and runtime
efﬁciency over a total of 500 instances. All implementations
of the approaches will be shared publicly.

Performance of the MIP-framework

In the ﬁrst set of experiments, we aim to showcase the abil-
ity of the proposed MIP-based approaches (i.e., MIP-SAT,
MIP-EXP, MIP-OBJ) in diverse settings. Speciﬁcally, we
generate CFEs for a two-layer ReLU-activated NN with 10
neurons in each layer and evaluate generated counterfactual
explanations using the metrics above on three datasets and
four norm distances: (cid:96)0, (cid:96)1, (cid:96)2, (cid:96)∞. As expected, the CFE
distances for all presented methods are similar to those of
SAT (Karimi et al. 2020a), which we use here as oracle, and
coverage is perfect by design for all presented methods. Fig-
ure 2 presents a comparison of runtime for these methods,
where we observe signiﬁcant improvement in runtime com-
pared to SAT-oracle. Similar comparison for distances may
be found in Figure 7 in the Appendix. Importantly, the pre-
sented MIP-based methods are able to generate CFEs in set-
tings in which neither MACE (SAT) nor MIP-SAT are able
(e.g., Adult or Credit dataset on (cid:96)2 norm).

In a second experiment, we compare the proposed MIP-
based approaches, not only with the SAT-oracle but also with
DiCE (Mothilal, Sharma, and Tan 2020) (i.e., gradient-based
optimization) on the same NN model as above. 5 Here we
adapt our experimental setting to DiCE, as it only supports
the (cid:96)1-norm distance, and does not provide support for ordi-
nal and real-valued features. Moreover, since DiCE assumes
that the model has been trained using range-normalized data,
we build additional support in our implementation to encode
the normalization term in the MIP-based approaches, which
in turn could negatively affect runtime and numeric stability.
Nonetheless, in this setting, we observe in Figure 3 relatively
smaller distances and signiﬁcantly smaller runtimes for the
former. Furthermore, where MIP-OBJ has perfect coverage
by design, DiCE dips slightly below perfect coverage on the
Adult dataset, failing to offer an explanation for 2/500 in-
stances.

4We use an improved version of MACE obtained from the of-

ﬁcial GitHub repository.

5We use default hyperparameters for DiCE, as obtained from
the ofﬁcial GitHub repository of DiCE (commit @92530c7). In all
but the diversity experiments that will follow, we set the diversity
weight to zero since we are searching for only one CFE and want
the focus only on proximity and ﬂipping of the output.

Scalablity Experiments
The experiments above were presented on NN models that
were able to sufﬁciently discriminate between the classes
of the supervised learning task (with test accuracy in the
range of 67-82% for different datasets). Complementing the
demonstrations above, we investigate the scalibility of our
approaches for the sake of completeness. In this regard, Fig-
ure 4 (and Figure 8 in the Appendix) compare the runtime,
distance, and coverage for SMT-based (Karimi et al. 2020a)
and gradient-based (Mothilal, Sharma, and Tan 2020) ap-
proaches with our proposed approaches for a NN model with
growing width and/or depth (as well as growing input size by
incorporating different datasets).

It can be seen that the SMT-based approaches quickly
reach their limit while MIP-based and gradient-based ap-
proaches scale well with both increasing width and depth.
As MIP-based approaches do not scale polynomially w.r.t.
network size, they do not scale as well as the gradient-based
DiCE (this can be seen for the bigger Credit and Adult
datasets in Figure 8 in the Appendix), however, they produce
much smaller distances. While MIP-based approaches have
perfect coverage and minimum distance in theory, in prac-
tice numerical instabilities may be incurred in the backend
tool as the number of intermediate variables in the mixed-
integer program becomes large and their relations become
deep due to the nested nature of NNs (the analysis of such
numerical instabilities is beyond the scope of this work and
deferred for future work). This causes failure to generate ex-
planations for some samples or an increase in distances. In
this context, having two MIP-based approaches is beneﬁcial
to verify results–for example, MIP-EXP behaves more sta-
ble in terms of distances than MIP-OBJ.

Qualitative Experiments
In this section, we show that how the expressiveness of SMT
and MIP can be used to easily encode qualitative features
and/or user-deﬁned constraints for the explanations.

Diversity. We report on experiments showing the diversity
feature of our approach as presented in the previous section,
and compare against DiCE’s implementation of diversity.

We follow the authors of DiCE, and evaluate the k di-
versely generated CFEs by measuring the mean of pairwise
distances among the CFEs (the higher the better):

k−diversity({xCF E

j

}k) :

1
(cid:1)
(cid:0)k
2

k−1
(cid:88)

k
(cid:88)

i=1

j=i+1

dist(xCF E
i

, xCF E
j

)

(14)
Expectedly, diversity is traded-off with distance. Thus, in
addition to the diversity metric above, the distance of the
diverse set of CFEs to the original factual instance, xF , is
measured as follows (the lower the better):

k−distance(xF , {xCF E

j

}k) :

1
k

k
(cid:88)

i=1

dist(xF , xCF E

i

)

(15)

Figure 2: Full-setting runtime comparison of two-layer ReLU-activated NN with 10 neurons in each layer among our approach
and MACE (SAT) (Karimi et al. 2020a). Note that coverage is perfect by design. Each setting has been evaluated on 500
instances, however, SAT and MIP-SAT timed out on some samples. For such cases, only the samples for which all approaches
have successfully ﬁnished running are included.

Sparsity. As described in the previous section, maximiz-
ing the sparsity of explanations is equivalent to minimizing
the (cid:96)0 distance to the factual sample. To show the ability of
our approach in maximizing sparsity, we refer the reader to
the ﬁrst column of ﬁgure 7 in the Appendix where all ap-
proaches succeed in maximizing sparsity. Indeed, it would
also be possible to optimize for a convex combination of (cid:96)0
and e.g., (cid:96)1 norms to generate more realistic sparse explana-
tions that allow more features to vary while staying close to
the factual sample.

We would like to also remark, once more, the role of
the expressive power of SMTs and MIPs, in increasing the
quality of explanations through handling different types of
constraints. For example, deﬁning different types of action-
ability on the features (e.g., increase/decrease-only, non-
actionable, etc.) are as simple as adding a few inequality
constraints to the MIP model. This ease of encoding may
give stake-holders and explanation-providers the possibility
to take into account individual-speciﬁc situations where an
individual might ask for her personal constraints to be con-
sidered within the provided explanation.

Conclusion and Future Work
In this work, we have proposed efﬁcient approaches based
on mixed-integer programming to generate counterfactual
explanations with guarantees for the widely-used class of
neural network models. We have empirically demonstrated
the efﬁciency and guarantees of the proposed framework by
comparing it, in terms of distance, runtime and coverage
with previous SMT- and gradient-based approaches for CFE
generation. We have also provided qualitative results on the
generation of diverse counterfactuals, showing the ﬂexibility
of our approach, as well as efﬁciency in handling complex
qualitative features.

As future work, we plan to explore other qualitative fea-
tures, such as other plausibility constraints beyond data
types and ranges. Moreover, although in this work we have
focused on NN architectures with ReLU activations, similar
approaches can be deployed for any piece-wise linear acti-
vation function (e.g., Max-Pooling). Moreover, other classes

Figure 3: Distance and time comparison against DiCE as a
gradient-based optimization approach. The model is a two-
layered ReLU-activated NN with 10 neurons in each layer.
MIP-OBJ coverage is perfect by design and DiCE coverage
is also perfect except for Adult dataset (99.6%).

Figure 5 shows diversities generated by MIP-DIVERSE
compared to DiCE for which the default hyperparameters
are used. MIP-DIVERSE succeeds in ﬁnding the closest set
of CFEs given a ﬁxed distance threshold for diversity. The
initial threshold has been set to 0.01 for this experiment, in-
creasing it would result in the k−diversity and k−distance
graph of Figure 5 to move upward, providing the possibil-
ity to choose the desired diversity-distance trade-off. Our re-
sults show that at a similar level of diversity (i.e., k = 6), the
counterfactual set of MIP-DIVERSE is much closer to the
factual instance. As k increases further, in DiCE, while still a
subset of the CFEs are diverse (and thus increase the average
distance), the remaining ones are very similar to the previous
as they minimally change a subset of the continuous vari-
ables. As a result, the average diversity and distance of the
generated CFEs decreases. The runtimes of MIP-DIVERSE
is again faster than the gradient-based opponent, however,
MIP-DIVERSE is more sensitive to increasing the input size
due to the added distance constraints, making it more or less
as slow as DiCE on larger datasets.

Figure 4: Scalability experiments comparing SMT-, MIP-, and gradient-based approaches on the COMPAS dataset. The upper
row shows the results for increasing depth and the lower row for increasing width; both in terms of runtime and distance. For
each approach and architecture 50 samples are evaluated, however, some fail to produce valid CFEs either because of imperfect
coverage (i.e., DiCE) or numeric instabilities (i.e., MIP-OBJ and MIP-EXP); thus, only the instances for which all approaches
have generated valid CFEs are included in the comparison. In general, for increasing depth, the average coverage across all the
architectures is 99.1% and 93.7% for MIP-OBJ and MIP-EXP, and 96.4% for DiCE. For increasing width, the average coverage
across all the architectures is 100% and 100% for MIP-OBJ and MIP-EXP, and 100% for DiCE. Similar experiments on the
Credit and Adult datasets may be found in Figure 8 in the Appendix.

Figure 5: Diversity, distance, and runtime for generating sets of counterfactuals on the COMPAS dataset and NN model with
two hidden layers of size 10. For each counterfactual set size k ∈ [2, 10], each approach has been tested on 100 instances.

of models (e.g., Support Vector Machines with RBF kernel)
could also be encoded or approximated by linear constraints,
and thus be similarly handled by our MIP-framework. Fi-
nally, as stake-holders increasingly adopt more complex
neural models for consequential decision-making, it be-
comes critical to have access to reliable and efﬁcient tools
to explain algorithmic decisions. Thus, as venue for future

work, it would be interesting to further investigate the scal-
ability and numeric stability issues, which also arise in the
NN veriﬁcation.

References

Adult data. 1996. https://archive.ics.uci.edu/ml/datasets/adult.

Bache, K.; and Lichman, M. 2013. UCI machine learning
repository.
Baeza-Yates, R.; and Salinger, A. 2010. Fast Intersection
Algorithms for Sorted Sequences, 45–61. Berlin, Heidel-
berg: Springer Berlin Heidelberg. ISBN 978-3-642-12476-
1. doi:10.1007/978-3-642-12476-1 3. URL https://doi.org/
10.1007/978-3-642-12476-1 3.
Bunel, R.; Turkaslan, I.; Torr, P. H.; Kohli, P.; and Kumar,
M. P. 2018. A Uniﬁed View of Piecewise Linear Neural
Network Veriﬁcation. In Proceedings of the 32nd Interna-
tional Conference on Neural Information Processing Sys-
tems, NIPS’18, 4795–4804. Red Hook, NY, USA: Curran
Associates Inc.
Carlini, N.; and Wagner, D. 2017. Towards evaluating the
robustness of neural networks. In 2017 ieee symposium on
security and privacy (sp), 39–57. IEEE.
de Moura, L.; and Bjørner, N. 2008. Z3: An Efﬁcient SMT
Solver. In Ramakrishnan, C. R.; and Rehof, J., eds., Tools
and Algorithms for the Construction and Analysis of Sys-
tems, 337–340. Berlin, Heidelberg: Springer Berlin Heidel-
berg. ISBN 978-3-540-78800-3.
Doshi-Velez, F.; and Kim, B. 2017. Towards a rigorous
science of interpretable machine learning. arXiv preprint
arXiv:1702.08608 .
Ehlers, R. 2017. Formal Veriﬁcation of Piece-Wise Lin-
ear Feed-Forward Neural Networks. CoRR abs/1705.01320.
URL http://arxiv.org/abs/1705.01320.
Freiesleben, T. 2020. Counterfactual Explanations & Adver-
sarial Examples – Common Grounds, Essential Differences,
and Potential Transfers.
Gurobi Optimization, L. 2020. Gurobi Optimizer Reference
Manual. URL http://www.gurobi.com.
Interval
Hickey, T.; Ju, Q.; and Van Emden, M. H. 2001.
J. ACM
Arithmetic: From Principles to Implementation.
48(5): 1038–1068. ISSN 0004-5411. doi:10.1145/502102.
502106. URL https://doi.org/10.1145/502102.502106.
Kanamori, K.; Takagi, T.; Kobayashi, K.; and Arimura, H.
2020. DACE: Distribution-Aware Counterfactual Explana-
tion by Mixed-Integer Linear Optimization.
In Bessiere,
C., ed., Proceedings of the Twenty-Ninth International Joint
Conference on Artiﬁcial Intelligence, IJCAI-20, 2855–2862.
International Joint Conferences on Artiﬁcial Intelligence Or-
ganization. doi:10.24963/ijcai.2020/395. URL https://doi.
org/10.24963/ijcai.2020/395. Main track.
Karimi, A.-H.; Barthe, G.; Balle, B.; and Valera, I. 2020a.
Model-Agnostic Counterfactual Explanations for Conse-
quential Decisions. In Chiappa, S.; and Calandra, R., eds.,
Proceedings of the Twenty Third International Conference
on Artiﬁcial Intelligence and Statistics, volume 108 of Pro-
ceedings of Machine Learning Research, 895–905. Online:
PMLR. URL http://proceedings.mlr.press/v108/karimi20a.
html.
Karimi, A.-H.; Barthe, G.; Sch¨olkopf, B.; and Valera, I.
2020b. A survey of algorithmic recourse: deﬁnitions, for-
mulations, solutions, and prospects.

Karimi, A.-H.; Sch¨olkopf, B.; and Valera, I. 2020. Algo-
rithmic Recourse: from Counterfactual Explanations to In-
terventions.

Katz, G.; Barrett, C.; Dill, D. L.; Julian, K.; and Kochen-
derfer, M. J. 2017. Reluplex: An Efﬁcient SMT Solver
for Verifying Deep Neural Networks.
In Majumdar, R.;
and Kunˇcak, V., eds., Computer Aided Veriﬁcation, 97–117.
Cham: Springer International Publishing.

Larson, J.; Mattu, S.; Kirchner, L.; and Angwin, J. 2016.
https://github.com/propublica/compas-analysis.

LeCun, Y.; Bengio, Y.; and Hinton, G. 2015. Deep learn-
ing. Nature 521(7553): 436–444. doi:10.1038/nature14539.
URL https://doi.org/10.1038/nature14539.

Liu, C.; Arnon, T.; Lazarus, C.; Barrett, C. W.; and Kochen-
derfer, M. J. 2019. Algorithms for Verifying Deep Neural
Networks. CoRR abs/1903.06758. URL http://arxiv.org/abs/
1903.06758.

Moosavi-Dezfooli, S.-M.; Fawzi, A.; Fawzi, O.; and
In
Frossard, P. 2017. Universal adversarial perturbations.
Proceedings of the IEEE conference on computer vision and
pattern recognition, 1765–1773.

Mothilal, R. K.; Sharma, A.; and Tan, C. 2020. Explaining
Machine Learning Classiﬁers through Diverse Counterfac-
tual Explanations. In Proceedings of the 2020 Conference
on Fairness, Accountability, and Transparency, FAT* ’20,
607–617. New York, NY, USA: Association for Computing
Machinery. ISBN 9781450369367. doi:10.1145/3351095.
3372850. URL https://doi.org/10.1145/3351095.3372850.

Papernot, N.; McDaniel, P.; Goodfellow, I.; Jha, S.; Celik,
Z. B.; and Swami, A. 2017. Practical black-box attacks
against machine learning. In Proceedings of the 2017 ACM
on Asia conference on computer and communications secu-
rity, 506–519.

Rudin, C. 2018. Stop Explaining Black Box Machine Learn-
ing Models for High Stakes Decisions and Use Interpretable
Models Instead.

Russell, C. 2019. Efﬁcient Search for Diverse Coherent
In Proceedings of the Conference on Fair-
Explanations.
ness, Accountability, and Transparency, FAT* ’19, 20–28.
New York, NY, USA: Association for Computing Machin-
ery. ISBN 9781450361255. doi:10.1145/3287560.3287569.
URL https://doi.org/10.1145/3287560.3287569.

Tjeng, V.; and Tedrake, R. 2017. Verifying Neural Networks
with Mixed Integer Programming. CoRR abs/1711.07356.
URL http://arxiv.org/abs/1711.07356.

Action-
Ustun, B.; Spangher, A.; and Liu, Y. 2019.
In Proceedings
able Recourse in Linear Classiﬁcation.
of the Conference on Fairness, Accountability, and Trans-
parency, FAT* ’19, 10–19. New York, NY, USA: Associa-
tion for Computing Machinery. ISBN 9781450361255. doi:
10.1145/3287560.3287566. URL https://doi.org/10.1145/
3287560.3287566.

Verma, S.; Dickerson, J.; and Hines, K. 2020. Counterfac-
tual Explanations for Machine Learning: A Review.

Wachter, S.; Mittelstadt, B.; and Russell, C. 2017. Counter-
factual explanations without opening the black box: Auto-
mated decisions and the GDPR. Harv. JL & Tech. 31: 841.

Illustrations for the Bounds Computation

[−1, 2]

x1

1

−

1

[−1, 2]

1

−1

x2

z1

z2

1

1

z3

[−1, 2]

[−2, 4]

x1

1

z1

−

1

[−1, 2]

1

[−4, 2]

−1

x2

z2

1

1

z3

[−1, 2]

[−2, 4]

x1

1

z1

−

1

[−6, 6]

1

[−1, 2]

1

[−4, 2]

−1

x2

z2

1

z3

Initial network

Step 1

Step 2

Figure 6: Computing bounds using interval arithmetic

We use a very simple example to demonstrate how bounds of the hidden units are computed using interval arithmetic and
why using MIPs we can obtain better bounds. Consider the simple initial network without ReLUs and biases in Figure 6. In
step 1, we wish to compute the bounds for the ﬁrst (and only) hidden layer. Starting by z1, computing its lower bound means
choosing the bounds from neurons of the previous layer which result in the minimum value for z1. Thus, considering the sign
of its weights, for both of the neurons in the previous layer the lower bound is chosen and the lower bound of z1 is set to
1 ∗ (−1) + 1 ∗ (−1) = −2. Similarly, the upper bound is 1 ∗ 2 + 1 ∗ 2 = 4. For z2, however, since the weights connected
to it are negative, for computing lower bound, the upper bounds of previous layer are chosen and its lower bound is set to
−1 ∗ 2 + −1 ∗ 2 = −4. Similarly, the upper bound is −1 ∗ (−1) + −1 ∗ (−1) = 2. Finally, in step 2, the bounds of the single
output is computed in a similar way ([−6, 6]).

It can be seen that, in order to compute the bounds of the hidden layer, each neuron has chosen lower/upper bounds from
the previous layer separately and without considering the relations among neurons, causing conﬂicts which result in loose
bounds for the next layer (the output). On the other hand, considering the straight-forward MIP for this network, we simply
have z1 = x1 + x2 and z2 = −x1 − x2 for the hidden layer and z3 = z1 + z2 for the next layer. maximizing/minimizing z1
and z2 variables gives the same bounds as the ones by interval arithmetic for the hidden layer, however, for the next layer (the
output) we will have the bounds [0, 0] since the deeper relations among neurons are considered in the MIP i.e., z3 = z1 + z2 =
x1 + x2 − x1 − x2 = 0.

This example was for a network without the ReLU activation. The ReLUs can also be encoded by associating them with
binary variables in the MIP encoding (e.g., encoding (3)) and compute exact bounds similarly by solving MIPs layer-by-layer.
However, this would be inefﬁcient as the ReLU binary variables incur an exhaustive search. Thus, a linear (over-)approximation
for ReLUs (6b) is suggested to ﬁnd looser than exact but tighter than interval arithmetic bounds in an efﬁcient way.

Additional Experiments
The results in Figure 7 complement those in Figure 3 in the main body, by comparing instead the distance norm obtained by
every method. Additionally, Figure 8 presents additional scalability results (similar to Figure 4) but for the Adult and Credit
datasets. These results mimic the same trends seen earlier in the main body.

Figure 7: Full-setting distance comparison of two-layer ReLU-activated NN with 10 neurons in each layer among our approach
and MACE (SAT) (Karimi et al. 2020a). Note that coverage is perfect by design. Each setting has been evaluated on 500
instances, however, SAT and MIP-SAT timed out on some samples. For such cases, only the samples for which all approaches
have successfully ﬁnished running are included.

Figure 8: Scalability experiments comparing SMT-, MIP-, and gradient-based approaches. The ﬁrst two rows show the results
for Credit dataset and the second two rows are for the Adult dataset. In each two rows, the upper row demonstrates increasing
depth while the lower row demonstrates increasing width; both in terms of runtime and distance. For each approach and
architecture 50 samples are evaluated, however, some fail to produce valid CFEs (only for DiCE in this case); thus, only the
instances for which all approaches have generated valid CFEs are included in the comparison. In general, for the Credit dataset,
increasing depth results in 100.0%, 100.0%, and 98.2% average coverage and increasing width results in 100%, 100%, and
100.0% average coverage for MIP-OBJ, MIP-EXP, and DiCE, respectively. For the Adult dataset, increasing depth results in
100.0%, 100.0%, and 96.8% average coverage and increasing width results in 100%, 100%, and 99.1% average coverage for
MIP-OBJ, MIP-EXP, and DiCE, respectively.

