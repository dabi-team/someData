1
2
0
2

c
e
D
2
2

]

O
C
.
h
p
-
o
r
t
s
a
[

1
v
1
2
1
2
1
.
2
1
1
2
:
v
i
X
r
a

Domain Adaptation for Simulation-Based Dark Matter Searches
Using Strong Gravitational Lensing

Stephon Alexander,1 Sergei Gleyzer,2 Pranath Reddy,3 Marcos Tidball,4 and Michael W. Toomey1
1Brown Theoretical Physics Center and Department of Physics, Brown University, Providence, RI 02912, USA
2Department of Physics & Astronomy, University of Alabama, Tuscaloosa, AL 35401, USA
3Birla Institute of Technology & Science, Pilani - Hyderabad Campus, Telangana, India
4Departamento de F´ısica, Universidade Federal do Rio Grande do Sul, Porto Alegre, Brazil
(Dated: December 23, 2021)

Clues to the identity of dark matter have remained surprisingly elusive, given the scope of ex-
perimental programs aimed at its identiﬁcation. While terrestrial experiments may be able to nail
down a model, an alternative, and equally promising, method is to identify dark matter based on
astrophysical or cosmological signatures. A particularly sensitive approach is based on the unique
signature of dark matter substructure on galaxy-galaxy strong lensing images. Machine learning
applications have been explored in detail for extracting just this signal. With limited availability of
high quality strong lensing data, these approaches have exclusively relied on simulations. Naturally,
due to the diﬀerences with the real instrumental data, machine learning models trained on simula-
tions are expected to lose accuracy when applied to real data. This is where domain adaptation can
serve as a crucial bridge between simulations and real data applications. In this work, we demon-
strate the power of domain adaptation techniques applied to strong gravitational lensing data with
dark matter substructure. We show with simulated data sets of varying complexity, that domain
adaptation can signiﬁcantly mitigate the losses in the model performance. This technique can help
domain experts build and apply better machine learning models for extracting useful information
from strong gravitational lensing data expected from the upcoming surveys.

I.

INTRODUCTION

tribution of dark matter [47–50].

One of the great achievements of astrophysics in the
last century was the realization by Zwicky, Rubin and
others that the observed baryonic mass (stars, galaxies,
etc.) was not consistent with the dynamics of galaxies
and clusters. A natural solution to this problem was
to consider some unseen matter that compensated for
this discrepancy, or so-called dark matter. Presently, all
eﬀorts aimed at extracting a non-gravitational signature
of dark matter have come up empty [1–20]. While this
does not mean that dark matter can not communicate
with Standard Model (SM) particles, as it may be the
case that its SM couplings are strongly suppressed, there
is also the possibility that such interactions do not exist.
Since its discovery, subsequent evidence for particle
dark matter from its coupling to gravity is almost ir-
refutable [21–23]. However, the list of possible models
that ﬁt current constraints is still quite broad. A partic-
ularly well suited signature that can be used to distin-
guish among dark matter models is the morphology and
distribution of its substructure within dark matter halos.
Some promising directions for inferring the properties of
substructure include tidal streams [24–29] and astromet-
ric observations [30–36]. A particularly sensitive probe
will be strong gravitational lensing [37–39] for which we
restrict ourselves in this article.

Strong lensing has already seen some promising suc-
cess in extracting information about dark matter sub-
structure, from lensed quasars [40–42], observations with
ALMA [43], and extended lensing images [44–46]. Var-
ious works have considered the expected signatures and
methods to extract information about the underlying dis-

More recently, there has been a plethora of applica-
tions of machine learning to this challenge, ranging from
classiﬁcation [51–53], regression [54], segmentation anal-
ysis [55, 56], and anomaly detection [57]. To date, all
works have exclusively focused on the application of these
techniques to simulations, in large part due to the lim-
ited availability of strong lensing data; something that is
anticipated to change in the near future with the com-
missioning of the Vera C. Rubin Observatory and the
launch of Euclid [58, 59]. However, not unexpectedly,
naively applying a model trained on simulations to real
data is not likely to be very successful, as the data id-
iosyncrasies relative to simulations will signiﬁcantly di-
minish the accuracy of the model. A promising method
to bridge the gap between a model trained on simulations
and real world data is based on the technique of domain
adaptation (DA) [60].

A subset of transfer learning, domain adaptation is fo-
cused on the generalization of the model across diﬀerent
domains or data sets drawn from diﬀerent underlying dis-
tributions. Concretely, the goal of domain adaptation is
to adapt a model trained on one data set (source) by
generalizing it to another domain (target), where the ob-
In practice domain
jective of the model is unchanged.
adaptation can be realized in several ways,
including
supervised, semi-supervised, and unsupervised fashions
[61–63].

Domain adaptation techniques have been used in a
wide variety of applications related to computer vision,
such as adapting a model trained on synthetic images
to real images [64], simple to complex images [65] and
virtual worlds with controlled data to the real world [66].

 
 
 
 
 
 
Recently, [67] used unsupervised domain adaptation
(UDA) to classify merging galaxies. Doing so achieved
promising results, with an increase of up to 19% in accu-
racy when compared to a model trained only on simula-
tions. This work also showed that models trained with-
out domain adaptation, achieved a poor accuracy on real
data. In another work [56] used domain adaptation to
generalize an image segmentation algorithm to diﬀerent
gravitational lensing systems for subhalo detection.

In this work, we consider several domain adaptation
algorithms to establish a proof-of-concept application
for dark matter searches in strong gravitational lensing.
Given the present lack of suﬃcient real data, we use two
datasets with diﬀering levels of complexity of strong lens-
ing simulations to carefully test the performance of do-
main adaptation prior to eventual applications to real
data. We evaluate the application of models trained on
the source data set to identify various types of dark mat-
ter substructure on the target data set. We compare the
performance of several domain adaptation algorithms, to
ﬁnd the best model. We additionally investigate equiv-
ariant neural network models that incorporate a known
group symmetry, to further enhance the performance of
domain adaptation.

We begin with a brief review of dark matter substruc-
ture and also discuss several lensing signatures in Sec-
tion II. We then focus on the details of strong lensing
simulations in Section III, followed by a summary of do-
main adaptation algorithms in Section IV. We present
our main results in Section V, followed by the discussion
and outlook in Section VI.

II. DARK MATTER DETECTION AND
STRONG GRAVITATIONAL LENSING

A. Dark Matter Substructure

The Λ Cold Dark Matter (ΛCDM) model envisions
near scale invariant density ﬂuctuations, present in the
early universe, serving as seeds of large-scale structure via
hierarchical structure formation. Concretely, structures
such as dark matter halos are formed from the coales-
cence of smaller halos [68]. Evidence for such merges has
been observed in our Galaxy [69–71] and is a general pre-
diction of N-body simulations where evidence of mergers
should remain largely in tact. The distribution of subha-
los masses is expected to follow a power law distribution,

dN
dm

∝ mβ,

(1)

where β ∼ −1.9 has been found from simulations [72, 73].
Comparison between simulation and observation indi-
cates good agreement with ΛCDM on large-scales [21–
23]. However, discrepancies begin to arise on smaller,
sub-galactic scales. These include the core-vs-cusp [74,

2

75], too big to fail [76], missing satellite [77–79],1 and
diversity problems [75]. While it may be the case that
these problems can be addressed with a better under-
standing of the astrophysics, e.g. baryonic feedback [81],
it is imperative that we consider the manifestations of
other theories beyond ΛCDM.

Two natural directions to consider are a modiﬁcation
to the general theory of relativity, such as BF coupled
[82–84] or Chern-Simons gravity [85, 86], or alternatives
to cold non-interactive dark matter.
In the context of
this paper, we will focus on the latter. An example of
a dark matter model that addresses several of the ten-
sions mentioned above is condensate dark matter, which
can be realized in the context of Bose-Einstein (BEC)
[87–93] or Bardeen-Cooper-Schreifer(BCS) [94–96] con-
densates. A concrete and well motivated model is the
axion. As the Goldstone boson of a broken U(1) symme-
try, axions were originally introduced as a solution to the
Strong-CP problem [97–99]. Shortly thereafter, it was
recognized that they were a promising dark matter can-
didate [100–102]. Very light axions are particularly well
suited to address some of the issues with structure on
sub-galactic scales. Axions with masses ∼ 1 × 10−23 eV
have a de Broglie wavelength on kpc scales, which real-
izes a natural solution to the core-vs-cusp problem. Ad-
ditionally, light axions can form subhalos but can also
form substructures quite diﬀerent from standard CDM.
These include vortices, disks, and interference patterns
[103–107].

While we will not consider their impact in this work,
it is important to also consider line of sight halos, i.e.
interlopers [108–111]. In some cases their inﬂuence may
dominate the signal of substructure, so it is important to
take care that they are not incorrectly associated with
the dark matter halo when working with real data sets
(see for example [112]).

B. Strong Lensing Theory

A powerful probe of dark matter substructure is strong
gravitational lensing; an eﬀect which is most pronounced
near extended lensing arcs. Any over or under densities
along the line of sight for an observer yields the lens equa-
tion, realized as an integral over an induced gravitational
potential [113],

(cid:126)β = (cid:126)θ −

(cid:90)

2
c2

DLS
DSDL

(cid:126)∇

dz Ψ((cid:126)r),

(2)

where DLS, DL, DS are the angular diameter distances
from the lens to the source, the lens to the observer, and
the source to observer. The last term on the r.h.s. of
Equation 2 is known as the deﬂection angle, (cid:126)α, and is
related via a perpendicular derivative to the the lensing

1 See [80] for a diﬀering perspective.

3

FIG. 1. Example images from the source (left) and target (right) data set.

potential, Ψ;⊥ = α. The lensing potential can be shown
to be related to matter density via a Poisson equation for
gravitational lensing,

∇2Ψ = 2κ,

(3)

implying that lensing from separate sources, a DM halo
and its subhalos, is a sum of deﬂection angles,

(cid:126)α =

(cid:88)

(cid:126)αi,

all matter

(4)

where (cid:126)αi could represent a DM halo, subhalos, vortices,
external shear, interlopers etc.

III. STRONG LENSING SIMULATIONS

Similar to [51, 57] we consider data sets of three sub-
structure classes; no substructure, subhalos of CDM,
and vortex substructure of superﬂuid type dark mat-
ter. The parameters for the simulations are complied
in Table I. The strong lensing images are simulated with
PyAutolens [114, 115]. The data are sized 150 × 150 pix-
els with a scale 0.5(cid:48)(cid:48)/pixel. The light from lensed back-
ground galaxies is modeled as a simple Sersic proﬁle and
the signal-to-noise ratio (SNR) of the lensing arcs are
consistent with real lensing data – SN R ∼ 20 [116] – by
appropriate inclusion of backgrounds and noise. We fur-
ther consider the modiﬁcations induced by a point-spread
function (PSF), modeled as an Airy disk with ﬁrst zero-
crossing σpsf (cid:46) 1(cid:48)(cid:48).

We ensure that the total fraction of mass in substruc-
ture, fsub, is of O(1%). We constrain the simulations
such that the total mass of the halo, including substruc-
ture, is always equal to 1 × 1012 M(cid:12). This is done to en-
sure that classiﬁcation algorithms don’t simply recognize
simulations without substructure as less massive on av-
erage. When simulating substructure for CDM we draw

subhalo masses from from Equation 1 for a total num-
ber of sources taken from a Poisson draw with µ = 25,
consistent with the expected number of subhalos for our
ﬁeld of view and redshift range [117]. We model vortices
of superﬂuid dark matter as uniform density strings of
mass of varying length and orientation – a valid approx-
imation at cosmological distances. Beyond the eﬀects of
substructure, we also include the impact of external shear
due to large-scale structure.

The inclusion of the eﬀects of substructure in our sim-
ulations can be understood from the linearity of the Pois-
son equation, Equation 3, which implies the total lensing
is just the sum of the individual contributions,

α = αLSS + αhalo + αhalo−sub,

(5)

where αLSS is the external shear from large-scale-
structure, αhalo the lensing from the halo and αhalo−sub
for halo substructure. It then follows that the location of
an image can be found from a modiﬁed form of the lens
equation, Equation 2,

βi = θi − αi

LSS − αi

halo − αi

halo−sub.

(6)

Domain adaptation requires at least two data sets, the
source and the target. In this work we consider two dis-
tinct simulations as source and target data sets. The
biggest diﬀerence between source and target data sets is
that source images are held at ﬁxed redshift, while the
target data set allows the redshifts to ﬂoat over a range of
values for both the lensed and lensing galaxy. Addition-
ally, the SNR in the target data set varies over a larger
range of values, 10 (cid:46) SNR (cid:46) 30, consistent with the chal-
lenges associated with variable source distances. Thus,
the target data set constitutes a more challenging sample
for identifying dark matter substructure - this diﬀerence
is easy to see by eye in Figure 1 for example lenses from
both classes. Thus, it will be our goal to successfully

TABLE I. Parameters with distributions and priors used in
the simulation of strong lensing images. Parameters with sub-
script s & t correspond to parameters for source and target
data sets respectively. Note that only a single type of sub-
structure was used per image.

4

DM Halo

Param.
θx
θy
zs
zt
MTOT
Ext. Shear

Param.
γext
φext
Lensed Gal.

Param.
r
φbk
zs
zt
e
φ
n
R

Vortex

Param.
θx
θy
l
φvort
mvort
Subhalo

Param.
r
N
φsh
msh
βsh

Dist.
ﬁxed
ﬁxed
ﬁxed

Priors
0
0
0.5

uniform [0.4,0.6]

ﬁxed

1e12

Details
x position
y position
redshift
redshift
total halo mass in M(cid:12)

Dist.

Priors
uniform [0.0, 0.3]
uniform

[0, 2π]

Details
magnitude
angle

Dist.

Priors
uniform [0, 0.5]
[0, 2π]
uniform
1.0
ﬁxed

uniform [0.8,1.2]
uniform [0.4, 1.0]
uniform
ﬁxed

[0, 2π]
1.5

uniform [0.25,1]

Details
radial distance from center
orientation from y axis
redshift
redshift
axis ratio
orientation to y axis
Sersic index
eﬀective radius

Priors
Dist.
[0.0, 0.5]
normal
normal
[0.0, 0.5]
uniform [0.5,2.0]
uniform
[0, 2π]
uniform [3.0,5.5]

Details
x position
y position
length of vortex
orientation from y axis
% of mass in vortex

Dist.

Priors
uniform [0, 2.0]
µ=25
Poisson
[0, 2π]
uniform

power law [1e6,1e10]

ﬁxed

-1.9

Details
radial distance from center
number of subhalos
orientation from y axis
subhalo mass in M(cid:12)
power law index

adapt and evaluate the algorithms trained on the source
data set to the target data set.

IV. DOMAIN ADAPTATION

Our goal is to train a supervised model on a source
data set and adapt it to a target data set. For this task
we use ResNet-18 [118], a Convolutional Neural Network
(CNN), as our base architecture. This is the same ar-
chitecture that has achieved top performance in previ-
ous applications to lensing data sets [34, 51, 57]. More
generally, CNNs are known to outperform other meth-
ods of classiﬁcation for strong gravitational lenses [119],
nonetheless, as noted by [67], a model trained on simula-
tions can perform poorly on real data.

To improve the performance of models trained on sim-
ulated data, we use unsupervised domain adaptation,
which attempts to mitigate the eﬀects of the domain shift
between the source and the target domains. It enables a
transfer of knowledge gained from a labeled source data
set to a distinct unlabeled target data set, within the
constraint that the objective remains the same [120]. Ex-

FIG. 2. Depiction of target and source representations in the
latent space of the encoder in ADDA. Images in blue are from
the source domain and images in orange are from the target
domain.

ample source and target data are shown in Fig. 1. For
our analysis we consider three UDA algorithms described
below.

A. Unsupervised Domain Adaptation Techniques

We ﬁrst consider Adversarial Discriminative Domain
Adaptation (ADDA) [65], an adversarial adaptation
method with the goal of minimizing the domain discrep-
ancy distance through an adversarial objective with re-
spect to a discriminator. Ideally the discriminator will be
unable to distinguish between the source and the target
distributions. We consider that we have access to source
images Xs and labels Ys that come from a source distri-
bution ps(x, y) and also target images Xt from a target
distribution pt(x, y). Our objective is to learn a target
encoder Mt and classiﬁer Ct that classiﬁes Xt into K
classes.

Due to the fact that it is not possible to perform su-
pervised learning on the target distribution, we learn a
source encoder Ms and a source classiﬁer Cs. The en-
coder learns to map the input samples to a latent vector
whose dimensionality is lower than the dimensionality
of the input samples. With these networks trained, the
distance between Ms(Xs) and Mt(Xt) is minimized, as
illustrated in Fig. 2. Since we’re only minimizing the
encoders, we can assume that Cs = Ct = C.

We train Ms and C using a standard supervised loss.
Then, we train a discriminator D that classiﬁes if the en-
coded vector represents an image from the source domain
or from the target domain using a standard supervised
loss, where the labels indicate the origin domain. Finally,
we train the Mt using D. To evaluate a target image Xt
we perform C(Mt(Xt)).

We additionally evaluate two DA algorithms derived
from semi-supervised learning. The ﬁrst makes use of
self-ensembling (Self-Ensemble) [120] and is based on the

5

TABLE II. Hyperparameters and augmentations used to train the UDA algorithms.

Method

Hyperparameters

Hyperparameter values Augmentations

Learning rate
Supervised Weight decay

ADDA

AdaMatch

Cyclic scheduler

Learning rate target encoder
Learning rate target encoder
Weight decay
Cyclic scheduler

Learning rate
Tau
Weight decay
Cyclic scheduler

Learning rate
Self-Ensemble Weight of unsupervised loss
Weight decay
Cyclic scheduler

1 × 10−3
5 × 10−5
True
1 × 10−5
1 × 10−4
5 × 10−5
False
1 × 10−3
0.9
5 × 10−5
False

1 × 10−3
3.0
5 × 10−5
False

Horizontal ﬂips
Vertical ﬂips

Horizontal ﬂips
Vertical ﬂips

Horizontal ﬂips
Vertical ﬂips
Random autocontrast
Gaussian blur
Random invert
Random adjust sharpness
Random solarize
Random aﬃne transformations

Horizontal ﬂips
Vertical ﬂips
Gaussian blur

mean teacher semi-supervised model [121]. There are
two networks in this method: a student network that
is trained using gradient descent and a teacher network
whose weights are an exponential moving average of the
student’s. During training, the labeled source inputs
are passed through the student network and the cross-
entropy loss is taken. However, the unlabeled target in-
puts pass through both the student and teacher networks
and the self-ensembling loss is used. It is computed as the
mean-squared diﬀerence between the predictions created
by the student and the teacher networks with diﬀerent
augmentations, dropout and noise parameters, and pe-
nalizes the diﬀerence in class prediction between the stu-
dent and the teacher. This method also makes use of con-
ﬁdence thresholding and a class balancing loss term. The
second semi-supervised method, AdaMatch [122], uses
weak and strong augmentations on both the source and
target input images. During training the method also
uses random logit interpolation, distribution alignment
and relative conﬁdence thresholding to achieve a better
performance.

In additional to the baseline CNN models, we also con-
sider an Equivariant Neural Network (ENN) [123] for
substructure classiﬁcation. ENNs can be thought of a
generalization of a CNN that encode the representation
of a useful symmetry, both global or local, such that its
group convolutions are invariant symmetries present in
the data. This is useful if there is a known symmetry in
the problem. As we expect lensing images to have sym-
metries beyond simple translation, for example rotations,
the ﬂexibility of choosing diﬀerent group representations

is expected to improve the performance.

The ENN we use consists of a group equivariant con-
volutional neural network [124] with six equivariant con-
volution blocks. We utilize the dihedral group D2, whose
symmetry mappings include the identity, rotations by ±π
and horizontal/vertical reﬂections. The D2 group struc-
ture can be visualized in Fig. 3. Each block is composed
of a convolutional layer, a batch normalization layer and
a ReLU activation function. After each pair of layers we
perform channel-wise average-pooling and in the end we
use a fully connected layer for multiclass classiﬁcation. A
schematic of the ENN architecture is presented in Fig. 4.

B. Network Training

For training we use 30, 000 images for the source do-
main and 30, 000 images for the target domain; in both
cases there are 10, 000 images per class. For validation we
use 7, 500 images for the source domain and 7, 500 images
for the target; in both cases there are 2, 500 images per
class. We used the Adam optimizer [125] to minimize our
losses. We trained both ResNet-18 and the ENN for 200
epochs, training with a patience of 15 epochs, such that if
the accuracy of the model does not improve in 15 epochs
we stop training. For ﬁnal results, we considered the
epoch that achieved the largest accuracy. Learning rate,
weight decay and other hyperparameters were optimized
through a hyperparameters search, and are available in
Table II.

We used random horizontal and random ﬂips augmen-

FIG. 3. Visualization of the D2 group structure for a real
gravitational lens. Lensing image credit: ESA/Hubble &
NASA.

6

tations for both the source and target dataset. We also
found that the best results were obtained after random
zooming (in a range of [0.8, 1.2]) and random rotations (in
a range of [0, 90] degrees) on the source dataset. Two of
the UDA algorithms, Self-Ensemble and AdaMatch, are
also highly dependent on augmentations, and diﬀerent
augmentations were tested to ﬁnd the optimal conﬁgura-
tions. We utilize the area under the ROC curve (AUC)
on the target validation set as the metric for classiﬁer
performance for all the models. All quoted AUC values
are macro-averaged unless stated otherwise. All machine
learning models were implemented using PyTorch [126]
and are run on a single NVIDIA Tesla P100 GPU.

V. RESULTS

We compare three diﬀerent UDA techniques in the con-
text of multi-class classiﬁcation of three types of sub-
structure: no substructure, CDM subhalos, and super-
ﬂuid DM vortices. We employ two diﬀerent base classi-
ﬁers for each technique - ResNet-18 and an ENN.2 The
parameters for our source and target data sets are shown
in Table I. Better results on all methods were achieved
when starting UDA training with models that were pre-
trained in a supervised fashion using source data, as dis-
cussed in [67]. As such, our models were trained starting
from models pre-trained on the source simulation data.
Results from our analysis are shown in Tables III and IV
for ResNet-18 and the ENN respectively. ROC curves
for both architectures are presented in Figure 5.

A. Domain Adaptation

We ﬁrst train ResNet-18 on the source data set where
it achieved a macro-averaged AUC ≈ 0.996 and an ac-
curacy of ≈ 97%. Applying this model to the target data
set naively, i.e. without domain adaptation, results in an
AUC of ≈ 0.880 and accuracy of ≈ 59%, a signiﬁcantly
degraded performance, as anticipated.

Following the application of UDA techniques, we ob-
serve a signiﬁcant improvement when applied to the tar-
get data set. AdaMatch and Self-Ensemble achieve an
AUC of ≈ 0.919 and 0.917, respectively, which shows
good improvement over the results obtained without do-
main adaptation. The top performing ResNet-18 based
UDA model is ADDA. With a ≈ 9% improvement in
AUC, at ≈ 0.955, and accuracy of ≈ 86%, ADDA sig-
niﬁcantly improves the performance of our model on the
target data set.

Considering the performance for individual classes, we
ﬁnd that ADDA achieves consistent AUC scores of ≈ 0.95

FIG. 4. Schematic of the equivariant (ENN) architecture.

2 The code used in our analysis can be found here.

ImageBlock 1representations=24; kernel size=7; padding=1 Block 2 representations=48; kernel size=5; padding=2 Antialiased average-poolingstride=2; sigma=0.66 Block 3 kernel size=5; padding=2 Block 4 kernel size=5; padding=2 Antialiased average-poolingstride=2; sigma=0.66 Block 5 kernel size=5; padding=2 Block 6 kernel size=5; padding=1Antialiased average-poolingstride=1; sigma=0.66 Fully connected layerOutputtrivial_reprR2 convolution kernel size=7; padding=1 Batch normalization ReLU activation Field typerepresentations=24 Block 3 representations=48; kernel size=5; padding=2 Block 4 representations=96; kernel size=5; padding=2 Block 5 representations=96; kernel size=5; padding=2 Block 6 representations=64; kernel size=5; padding=1 trivial_reprLinear layer input=61504; output=256 Batch normalization ELU activation Linear layerinput=256; output=256 Linear layerinput=256; output=3 7

FIG. 5. ROC-AUC curves for ResNet-18 (left) and ENN (right) based algorithms applied to our data set.

for all three classes. This is in contrast to the perfor-
mance on naive application, where no substructure and
subhalos classiﬁcation each had an AUC of ≈ 0.90 and
classiﬁcation of vortices was severely degraded to an AUC
of ≈ 0.80. The baseline model applied to the source data
set, on the other hand, had consistent performance on a
class by class basis at ≈ 0.99 AUC.

tween the target ROC curve (blue) with the three UDA
algorithms in Figure 5 between ResNet-18 (left) and the
ENN (right). Finally, ADDA again achieves impressive
top performance with an AUC of ≈ 0.980. Thus, the
equivariant model with ADDA is the top performing al-
gorithm relative to the baseline source model.

TABLE III. Accuracy and macro-averaged area under the
ROC curve (AUC) for the ResNet-18 classiﬁer.

TABLE IV. Accuracy and macro-averaged area under the
ROC curve (AUC) for the ENN classiﬁer.

Method

Accuracy (%) AUC

ADDA
AdaMatch
Self-Ensemble
Supervised (target)
Supervised (source)

85.84
75.55
76.71
59.19
96.84

0.955
0.919
0.917
0.880
0.996

B. Equivariant Domain Adaptation

With an AUC of ≈ 0.996 and accuracy of ≈ 91%, the
ENN performance is commensurate with ResNet-18 on
the source data set. The naive application to the test
data set (i.e. no domain adaption) again results in de-
graded performance, realized with an AUC ≈ 0.856 and
accuracy of ≈ 68%.

The Self-Ensemble and AdaMatch equivariant models
again show improved performance relative to the naive
case and with AUC scores of ≈ 0.939 and ≈ 0.960 re-
spectively show a notable performance boost relative to
the same UDA algorithms with ResNet-18. This is eas-
ily visualized by comparing the increased separation be-

Method

Accuracy (%) AUC

ADDA
AdaMatch
Self-Ensemble
Supervised (target)
Supervised (source)

91.47
85.81
80.09
67.53
97.09

0.980
0.960
0.939
0.856
0.996

Let us again investigate the performance of the ADDA
augmented equivariant model on a class by class basis.
Performance of the original classiﬁer was near perfect,
achieving AUC scores of ≈ 0.99 for all three classes (e.g.
subhalos vs. vortices and no substructure, etc.) on the
source data set. Applied naively to the target data set
it achieved a respectable performance of ≈ 0.92 for sub-
halos but only managed AUC scores of ≈ 0.83 and 0.82
for no substructure and vortices respectively. Note that
this is actually worse than the comparable ResNet-18 ap-
plication. ADDA dramatically increases the algorithm’s
performance, managing consistent classiﬁcation across all
classes with AUC scores of ≈ 0.98. Considering the naive
performance was worse than ResNet-18, it is impressive
that our equivariant model ENN was augmented more
eﬀectively with ADDA, a feature that is shared with the
other two UDA methods.

0.00.20.40.60.81.0False Positive Rate0.00.20.40.60.81.0True Positive RateSource (0.996)Target (0.880)ADDA (0.955)AdaMatch (0.919)Self-En. (0.917)0.00.20.40.60.81.0False Positive Rate0.00.20.40.60.81.0True Positive RateSource (0.996)Target (0.856)ADDA (0.980)AdaMatch (0.960)Self-En. (0.939)Now let us consider the performance of the ENN rela-
tive to ResNet-18. We can see from Figure 5 that there
was a notable increase in the ability of AdaMatch and
Self-Ensemble to improve performance for the ENN. This
is likely related to the fact that both AdaMatch and Self-
Ensemble are highly dependent on augmentations. Thus,
the additional symmetries manifest in the ENN, relative
to CNNs, can be thought of as negating the redundancies
of augmentation. Concretely, data augmentation is less
important for the ENN, since augmented data (rotations,
translation, reﬂections, etc.) are invariant under a gauge
transformation. On the other hand, CNNs only realize
translational invariance, which means they are suscepti-
ble to idiosyncrasies induced in training.

VI. DISCUSSION & CONCLUSION

With the upcoming arrival of strong lensing data from
Euclid and the Vera Rubin Observatory, it is imperative
to assess how algorithms trained on simulations can be
adapted to study real world data. To this goal, in this
work we studied how unsupervised domain adaptation
algorithms can be used to adapt a model trained on one
set of data (the source) to another, more complex, data
set (the target). To make a precise quantitative evalu-
ation, we based it on two sets of simulations, with the
more complex simulation as a proxy for real data.

We have demonstrated that the naive application of
substructure classiﬁcation models have diminished per-
formance when applied to a more complex target data
set. We then tested the implementation of several UDA
techniques (ADDA, AdaMatch, and Self-Ensemble) for a
popular convolutional (ResNet-18 ) classiﬁer and a sym-
metry equivariant (ENN) classiﬁer. We found that UDA
consistently increases the performance of all models on
the target data set. The ENN-based ADDA algorithm
achieved top performance, achieving performance com-
petitive with the original source trained and evaluated
algorithm.

8

Investigating performance on a class by class basis, we
found that classiﬁcation performance is consistent be-
tween classes. This is despite the fact that the naive
application of the source-trained ENN has signiﬁcantly
degraded AUC scores for no substructure and vortices
relative to subhalos. This observation, UDA aside, is en-
couraging as the base architectures are relatively robust
to the signature of subhalos lensing data, a common ob-
servable among many dark matter models. This result
is not surprising as the lensing signature of vortices is
inherently more diﬃcult relative to subhalos since they
induce no magniﬁcation of the background source (see
[51] and references therein for details). Nonetheless, it is
impressive that UDA can completely compensate for this
extra diﬃculty.

With the upcoming arrival of high quality strong lens-
ing data, domain adaptation techniques will be critical
for real world applications of machine learning based dark
matter analyses. Possible performance degradations for
a simulation trained model naively applied to real data
sets can be more signiﬁcant than what was realized here,
making the need for further development and applica-
tion of UDA methods even more critical. While we have
restricted ourselves to substructure classiﬁcation in this
work, domain adaptation techniques can be additionally
useful in the broader context of studying dark matter,
from regression to image segmentation, in applications
to real world strong gravitational lensing data sets.

VII. ACKNOWLEDGEMENTS

M. T. was a participant in the Google Summer of Code
(GSoC) 2021 program. S. G. was supported in part by
the National Science Foundation Award No. 2108645.
S. A. and M. W. T. were supported in part by U.S. Na-
tional Science Foundation Award No. 2108866. This
work made use of these additional software packages:
Matplotlib [127], NumPy [128], PyTorch [129], and SciPy
[130].

[1] A. K. Drukier, K. Freese, and D. N. Spergel, Phys. Rev.

D33, 3495 (1986).

[2] M. W. Goodman and E. Witten, Phys. Rev. D31, 3059

(1985).

[3] D. S. Akerib et al. (LUX), Phys. Rev. Lett. 118, 021303

(2017), arXiv:1608.07648 [astro-ph.CO].

[4] X. Cui et al. (PandaX-II), Phys. Rev. Lett. 119, 181302

(2017), arXiv:1708.06917 [astro-ph.CO].

[8] A. Geringer-Sameth, S. M. Koushiappas, and M. G.
91, 083535 (2015), arXiv:1410.2242 [astro-

Walker,
ph.CO].

[9] A. Albert, R. Alfaro, C. Alvarez, J. D. ´Alvarez,
and et al., ApJ 853, 154 (2018),

R. Arceo,
arXiv:1706.01277 [astro-ph.HE].

[10] VERITAS Collaboration, Phys. Rev. D 95, 082001

(2017), arXiv:1703.04937 [astro-ph.HE].

[5] E. Aprile et al. (XENON), Phys. Rev. Lett. 121, 111302

[11] J. Rico, Galaxies 8, 25 (2020), arXiv:2003.13482 [astro-

(2018), arXiv:1805.12562 [astro-ph.CO].

ph.HE].

[6] F. Froborg and A. R. Duﬀy, arXiv e-prints

arXiv:2003.04545
ph.CO].

(2020),

arXiv:2003.04545

,
[astro-

[7] Fermi LAT Collaboration,

2015,

008

(2015),

arXiv:1501.05464 [astro-ph.CO].

[12] MAGIC Collaboration,

2016,

039

(2016),

arXiv:1601.06590 [astro-ph.HE].

[13] IceCube

Collaboration,

arXiv

e-prints

,

arXiv:1705.08103 (2017), arXiv:1705.08103 [hep-ex].
[14] The Super-Kamiokande Collaboration, arXiv e-prints ,
arXiv:1503.04858 (2015), arXiv:1503.04858 [hep-ex].

[15] N. Du, N. Force, R. Khatiwada, E. Lentz, R. Ottens,
L. J. Rosenberg, G. Rybka, G. Carosi, N. Woollett,
D. Bowring, A. S. Chou, A. Sonnenschein, W. Wester,
C. Boutan, N. S. Oblath, R. Bradley, E. J. Daw, A. V.
Dixit, J. Clarke, S. R. O’Kelley, N. Crisosto, J. R. Glea-
son, S. Jois, P. Sikivie, I. Stern, N. S. Sullivan, D. B.
Tanner, G. C. Hilton, and ADMX Collaboration, Phys.
Rev. Lett 120, 151301 (2018), arXiv:1804.05750 [hep-
ex].

[16] P. W. Graham, I. G. Irastorza, S. K. Lamoreaux,
A. Lindner,
and K. A. van Bibber, Annual Re-
view of Nuclear and Particle Science 65, 485 (2015),
arXiv:1602.00039 [hep-ex].

[17] K. Kannike, M. Raidal, H. Veerm¨ae, A. Strumia, and
D. Teresi, arXiv e-prints , arXiv:2006.10735 (2020),
arXiv:2006.10735 [hep-ph].

[18] J. Buch, M. A. Buen-Abad, J. Fan,

and J. S.
Chau Leung, arXiv e-prints , arXiv:2006.12488 (2020),
arXiv:2006.12488 [hep-ph].

[19] M. Aaboud et al. (ATLAS), JHEP 05, 142 (2019),

arXiv:1903.01400 [hep-ex].

[20] Sirunyan, A. M. and Tumasyan, A. and Adam, W. and
Asilar, E. and Bergauer, T., and et al., Journal of High
Energy Physics 2017, 73 (2017), arXiv:1706.03794 [hep-
ex].

[21] Planck Collaboration, A&A 594, 63 (2016), arXiv.
[22] L. Anderson, E. Aubourg et al., MNRAS 441, 24 (2014),

MNRAS.

[23] C. Heymans, L. van Waerbeke et al., MNRAS 427, 146

(2012), MNRAS.

9

[38] A. Drlica-Wagner

et
Group), arXiv e-prints
arXiv:1902.01055 [astro-ph.CO].

al.
(LSST Dark Matter
, arXiv:1902.01055 (2019),

[39] J. Simon et al., Bull. Am. Astron. Soc 51, 153 (2019),

arXiv:1903.04742 [astro-ph.CO].

[40] S. Mao and P. Schneider, MNRAS 295, 587 (1998),

arXiv.

[41] J.W. Hsueh et al., MNRAS 469, 3713 (2017), arXiv.
[42] N. Dalal and C.S. Kochanek, ApJ 572, 25 (2002), arXiv.
[43] Y.D. Hezaveh et al., ApJ 823, 37 (2016), arXiv.
[44] S. Vegetti and L.V.E. Koopmans, MNRAS 392, 945

(2009), arXiv.

[45] L.V.E. Koopmans, MNRAS 363, 1136 (2005), Oxford

Journals.

[46] S. Vegetti and L.V.E. Koopmans, MNRAS 400, 1583

(2009), arXiv.

[47] T. Daylan, F.-Y. Cyr-Racine, A. Diaz Rivero,
C. Dvorkin, and D. P. Finkbeiner, Astrophys. J. 854,
141 (2018), arXiv:1706.06111 [astro-ph.CO].

[48] S. Vegetti, L. V. E. Koopmans, A. Bolton, T. Treu, and
R. Gavazzi, MNRAS 408, 1969 (2010), arXiv:0910.0760
[astro-ph.CO].

[49] T. Daylan et al., ApJ 854, 141 (2018), arXiv:1706.06111

[astro-ph.CO].

[50] S. Vegetti

et al., MNRAS 408,

1969

(2010),

arXiv:0910.0760 [astro-ph.CO].

[51] S. Alexander, S. Gleyzer, E. McDonough, M. W.
Toomey, and E. Usai, Astrophys. J. 893, 15 (2020),
arXiv:1909.07346 [astro-ph.CO].

[52] A. Diaz Rivero and C. Dvorkin, Phys. Rev. D 101,

[24] W.-H. W. Ngan and R. G. Carlberg, Astrophys. J. 788,

023515 (2020), arXiv:1910.00015 [astro-ph.CO].

181 (2014), arXiv:1311.1710 [astro-ph.CO].

[25] R. G. Carlberg, Astrophys. J. 820, 45 (2016),

arXiv:1512.01620 [astro-ph.GA].

[26] J. Bovy, Phys. Rev. Lett. 116, 121301 (2016),

arXiv:1512.00452 [astro-ph.GA].
[27] D. Erkal, V. Belokurov, J. Bovy,

and J. L. Sand
ers, MNRAS 463, 102 (2016), arXiv:1606.04946 [astro-
ph.GA].

[53] S. Varma, M. Fairbairn,

and J. Figueroa, arXiv
e-prints , arXiv:2005.05353 (2020), arXiv:2005.05353
[astro-ph.CO].

[54] J. Brehmer, S. Mishra-Sharma, J. Hermans, G. Louppe,
and K. Cranmer, Astrophys. J. 886, 49 (2019),
arXiv:1909.02005 [astro-ph.CO].

[55] B. Ostdiek, A. Diaz Rivero, and C. Dvorkin, (2020),

arXiv:2009.06639 [astro-ph.CO].

[28] D. Shih, M. R. Buckley, L. Necib, and J. Tamanas,

[56] B. Ostdiek, A. Diaz Rivero, and C. Dvorkin, (2020),

(2021), arXiv:2104.12789 [astro-ph.GA].

arXiv:2009.06663 [astro-ph.CO].

[29] M. Benito, J. C. Criado, G. H¨utsi, M. Raidal,
and H. Veerm¨ae, Phys. Rev. D 101, 103023 (2020),
arXiv:2001.11013 [astro-ph.CO].
[30] S. Mishra-Sharma, K. Van Tilburg,

and N. Weiner,
Phys. Rev. D 102, 023026 (2020), arXiv:2003.02264
[astro-ph.CO].

[31] K. Van Tilburg, A.-M. Taki, and N. Weiner, JCAP 07,

041 (2018), arXiv:1804.01991 [astro-ph.CO].

[57] S. Alexander, S. Gleyzer, H. Parul, P. Reddy, M. W.
Toomey, E. Usai, and R. Von Klar, arXiv:2008.12731
[astro-ph, physics:hep-ph] (2020), arXiv: 2008.12731.

[58] A. Verma, T. Collett, G. P. Smith, Strong Lensing Sci-
ence Collaboration, and the DESC Strong Lensing Sci-
ence Working Group, arXiv e-prints , arXiv:1902.05141
(2019), arXiv:1902.05141 [astro-ph.GA].

[59] M. Oguri and P. J. Marshall, MNRAS 405, 2579 (2010),

[32] R. Feldmann and D. Spolyar, MNRAS 446, 1000 (2015),

arXiv:1001.2037 [astro-ph.CO].

arXiv:1310.2243 [astro-ph.GA].

[33] R. E. Sanderson, C. Vera-Ciro, A. Helmi,

and
J. Heit, arXiv e-prints , arXiv:1608.05624 (2016),
arXiv:1608.05624 [astro-ph.GA].

[34] K. Vattis, M. W. Toomey,
appas, arXiv e-prints
arXiv:2008.11577 [astro-ph.CO].

and S. M. Koushi-
, arXiv:2008.11577 (2020),

[35] S. Mishra-Sharma, in 35th Conference on Neural In-
formation Processing Systems (2021) arXiv:2110.01620
[astro-ph.CO].

[36] K. Pardo and O. Dor´e, Phys. Rev. D 104, 103531

(2021), arXiv:2108.10886 [astro-ph.CO].

[37] M. R. Buckley and A. H. G. Peter, Phys. Rept. 761, 1

(2018), arXiv:1712.06615 [astro-ph.CO].

[60] S. Ben-David, J. Blitzer, K. Crammer, A. Kulesza,
F. Pereira, and J. Vaughan, Machine Learning 79, 151
(2010).

[61] S. Motiian, M. Piccirilli, D. A. Adjeroh,

and
G. Doretto, arXiv e-prints , arXiv:1709.10190 (2017),
arXiv:1709.10190 [cs.CV].

[62] J. Donahue, J. Hoﬀman, E. Rodner, K. Saenko, and
T. Darrell, in 2013 IEEE Conference on Computer Vi-
sion and Pattern Recognition (2013) pp. 668–675.

[63] A. Farahani, S. Voghoei, K. Rasheed,

and H. R.
Arabnia, arXiv e-prints , arXiv:2010.03978 (2020),
arXiv:2010.03978 [cs.LG].

[64] X. Peng, B. Usman, N. Kaushik, J. Hoﬀman, D. Wang,
(2017), arXiv:

and K. Saenko, arXiv:1710.06924 [cs]

10

1710.06924.

[65] E. Tzeng, J. Hoﬀman, K. Saenko,

and T. Darrell,

arXiv:1702.05464 [cs] (2017), arXiv: 1702.05464.
[66] V. Schmidt, A. S. Luccioni, M. Teng, T. Zhang,
A. Reynaud, S. Raghupathi, G. Cosne, A. Juraver,
V. Vardanyan, A. Hernandez-Garcia, and Y. Bengio,
arXiv:2110.02871 [cs]
(2021), arXiv: 2110.02871 ver-
sion: 1.

[67] A. ´Ciprijanovi´c, D. Kafkes, K. Downey, S. Jenkins,
G. N. Perdue, S. Madireddy, T. Johnston, G. F. Snyder,
and B. Nord, Monthly Notices of the Royal Astronomi-
cal Society 506, 677 (2021), arXiv: 2103.01373.

[68] G. Kauﬀmann, S. D. M. White, and B. Guiderdoni,

MNRAS 264, 201 (1993).

[69] A. Chiti, A. Frebel, J. D. Simon, D. Erkal, L. J. Chang,
L. Necib, A. P. Ji, H. Jerjen, D. Kim, and J. E. Nor-
ris, Nature Astronomy 5, 392 (2021), arXiv:2012.02309
[astro-ph.GA].

[70] L. Necib, B. Ostdiek, M. Lisanti, T. Cohen, M. Freytsis,
and S. Garrison-Kimmel, Astrophys. J. 903, 25 (2020),
arXiv:1907.07681 [astro-ph.GA].

[71] L. Necib, B. Ostdiek, M. Lisanti, T. Cohen, M. Freyt-
sis, S. Garrison-Kimmel, P. F. Hopkins, A. Wetzel,
and R. Sanderson, Nature Astron. 4, 1078 (2020),
arXiv:1907.07190 [astro-ph.GA].

[72] V. Springel, J. Wang, M. Vogelsberger, A. Lud-
low, A. Jenkins, A. Helmi, J. F. Navarro, C. S.
Frenk, and S. D. White, MNRAS 391, 1685 (2008),
arXiv:0809.0898 [astro-ph].

[73] P. Madau, J. Diemand, and M. Kuhlen, Astrophys. J.

[87] S.-J. Sin, Phys. Rev. D50, 3650 (1994), arXiv:hep-

ph/9205208 [hep-ph].

[88] M. P. Silverman and R. L. Mallett, Gen. Rel. Grav. 34,

633 (2002).

[89] W. Hu, R. Barkana, and A. Gruzinov, Phys. Rev. Lett.
85, 1158 (2000), arXiv:astro-ph/0003365 [astro-ph].
[90] P. Sikivie and Q. Yang, Phys. Rev. Lett. 103, 111301

(2009), arXiv:0901.1106 [hep-ph].
[91] L. Hui, J. P. Ostriker, S. Tremaine,

and E. Wit-
ten, Phys. Rev. D95, 043541 (2017), arXiv:1610.08297
[astro-ph.CO].

[92] L. Berezhiani and J. Khoury, Phys. Rev. D92, 103510

(2015), arXiv:1507.01019 [astro-ph.CO].

[93] E. G. Ferreira, G. Franzmann, J. Khoury, and R. Bran-
denberger, JCAP 08, 027 (2019), arXiv:1810.09474
[astro-ph.CO].

[94] S. Alexander and S. Cormack, JCAP 1704, 005 (2017),

arXiv:1607.08621 [astro-ph.CO].

[95] S. Alexander, E. McDonough, and D. N. Spergel, JCAP

1805, 003 (2018), arXiv:1801.07255 [hep-th].

[96] S. Alexander, E. McDonough, and D. N. Spergel, Phys.
Lett. B 822, 136653 (2021), arXiv:2011.06589 [astro-
ph.CO].

[97] R. D. Peccei and H. R. Quinn, Phys. Rev. Lett. 38, 1440

(1977).

[98] F. Wilczek, Phys. Rev. Lett. 40, 279 (1978).
[99] S. Weinberg, Phys. Rev. Lett. 40, 223 (1978).

[100] J. Preskill, M. B. Wise,
Lett. B120, 127 (1983),
PHLTA,B120,127 .

and F. Wilczek, Phys.
[,URL(1982)]CITATION =

679, 1260 (2008), arXiv:0802.2265 [astro-ph].

[101] L. F. Abbott and P. Sikivie, Phys. Lett. B120, 133

[74] A. Burkert, ApJL 447, L25 (1995), arXiv:astro-

(1983), [,URL(1982)].

ph/9504041 [astro-ph].

[102] M. Dine and W. Fischler, Phys. Lett. B120, 137 (1983),

[75] S.-H. Oh, D. A. Hunter, E. Brinks, B. G. Elmegreen,
A. Schruba, F. Walter, M. P. Rupen, L. M. Young, C. E.
Simpson, M. C. Johnson, and et al., The Astronomical
Journal 149, 180 (2015).

[76] M. Boylan-Kolchin, J. S. Bullock,

and M. Kapling-
hat, Monthly Notices of the Royal Astronomical Society:
Letters 415, L40–L44 (2011).

[77] B. Moore, S. Ghigna, F. Governato, G. Lake, T. Quinn,
J. Stadel, and P. Tozzi, The Astrophysical Journal 524,
L19–L22 (1999).

[78] A. Klypin, A. V. Kravtsov, O. Valenzuela,

and
F. Prada, The Astrophysical Journal 522, 82–92 (1999).
[79] J. S. Bullock and M. Boylan-Kolchin, ARA&A 55, 343

(2017), arXiv:1707.04256 [astro-ph.CO].

[80] S. Y. Kim, A. H. G. Peter and J. R. Hargis, Phys. Rev.

Lett. 121, 211302 (2018), arXiv.

[81] A. Ben´ıtez-Llambay, C. S. Frenk, A. D. Ludlow,
and J. F. Navarro, MNRAS 488, 2387 (2019),
arXiv:1810.04186 [astro-ph.GA].

[82] S. Alexander and R. Carballo-Rubio, Phys. Rev. D 101,

024058 (2020), arXiv:1810.02159 [gr-qc].

[83] S. Alexander, G. Herczeg, J. Liu, and E. McDonough,
Phys. Rev. D 102, 083526 (2020), arXiv:2003.08416 [gr-
qc].

[84] S. Alexander, S. J. Clark, G. Herczeg,

and M. W.

[,URL(1982)].

[103] T. Rindler-Daller, P. R. Shapiro, MNRAS 422, 135

(2012), arXiv:1106.1256.

[104] L. Hui, (2021), arXiv:2101.11735 [astro-ph.CO].
[105] L. Hui, A. Joyce, M. J. Landry, and X. Li, JCAP 01,

011 (2021), arXiv:2004.01188 [astro-ph.CO].

[106] S. Alexander, J. J. Bramburger, and E. McDonough,
Phys. Lett. B 797, 134871 (2019), arXiv:1901.03694
[astro-ph.CO].

[107] S. Alexander, C. Capanelli, E. G. M. Ferreira,

and
(2021), arXiv:2111.03061 [astro-

E. McDonough,
ph.CO].
[108] A. C¸ a˘gan

arXiv:2006.07383
ph.CO].

S¸eng¨ul

et
(2020),

arXiv
al.,
arXiv:2006.07383

e-prints

,
[astro-

[109] C. McCully, C. R. Keeton, K. C. Wong,

and A. I.
Zabludoﬀ, The Astrophysical Journal 836, 141 (2017).
[110] G. Despali, S. Vegetti, S. D. M. White, C. Giocoli, and
F. C. van den Bosch, Monthly Notices of the Royal As-
tronomical Society 475, 5424–5442 (2018).
[111] D. Gilman, S. Birrer, T. Treu, A. Nierenberg,

and
A. Benson, Monthly Notices of the Royal Astronomi-
cal Society 487, 5721–5738 (2019).

[112] A. c. S¸eng¨ul, C. Dvorkin, B. Ostdiek, and A. Tsang,

(2021), arXiv:2112.00749 [astro-ph.CO].

Toomey, (2021), arXiv:2110.09503 [gr-qc].

[113] R. Narayan and M. Bartelmann, (1997), arXiv:9606001

[85] R. Jackiw and S. Y. Pi, Phys. Rev. D 68, 104012 (2003),

[astro-ph.CO].

arXiv:gr-qc/0308071.

[114] J. W. Nightingale and S. Dye, MNRAS 452, 2940

[86] S. Alexander and N. Yunes, Phys. Rept. 480, 1 (2009),

(2015), arXiv:1412.7436 [astro-ph.IM].

arXiv:0907.2562 [hep-th].

[115] J. W. Nightingale, S. Dye, and R. J. Massey, MNRAS
478, 4738 (2018), arXiv:1708.07377 [astro-ph.CO].

[116] A. S. Bolton, S. Burles, L. V. E. Koopmans, T. Treu,
R. Gavazzi, L. A. Moustakas, R. Wayth,
and D. J.
Schlegel, ApJ 682, 964 (2008), arXiv:0805.1931 [astro-
ph].

[117] A. D´ıaz Rivero, C. Dvorkin, F.-Y. Cyr-Racine,
and M. Vogelsberger, Phys. Rev. D 98,

J. Zavala,
103517 (2018), arXiv:1809.00004 [astro-ph.CO].
[118] K. He, X. Zhang, S. Ren, and J. Sun, arXiv:1512.03385

[cs] (2015), arXiv: 1512.03385.

[119] R. B. Metcalf, M. Meneghetti, C. Avestruz, F. Bel-
lagamba, C. R. Bom, E. Bertin, R. Cabanac,
F. Courbin, A. Davies, E. Decenci`ere, R. Flamary,
R. Gavazzi, M. Geiger, P. Hartley, M. Huertas-
Company, N. Jackson, E. Jullo, J.-P. Kneib, L. V. E.
Koopmans, F. Lanusse, C.-L. Li, Q. Ma, M. Mak-
ler, N. Li, M. Lightman, C. E. Petrillo, S. Serjeant,
C. Sch¨afer, A. Sonnenfeld, A. Tagore, C. Tortora,
D. Tuccillo, M. B. Valent´ın, S. Velasco-Forero, G. A. V.
Kleijn,
and G. Vernardos, A&A 625, A119 (2019),
arXiv: 1802.03609.

[120] G. French, M. Mackiewicz,

and M. Fisher,

arXiv:1706.05208 [cs] (2018), arXiv: 1706.05208.

[121] A. Tarvainen and H. Valpola, arXiv e-prints
arXiv:1703.01780 (2017), arXiv:1703.01780 [cs.NE].

,

[122] D. Berthelot, R. Roelofs, K. Sohn, N. Carlini,

and
(2021), arXiv:

A. Kurakin, arXiv:2106.04732 [cs]
2106.04732 version: 1.

[123] M. Weiler and G. Cesa, arXiv:1911.08251 [cs, eess]

(2021), arXiv: 1911.08251.

[124] T. Cohen and M. Welling, in International conference
on machine learning (PMLR, 2016) pp. 2990–2999.
[125] D. P. Kingma and J. Ba, arXiv:1412.6980 [cs] (2017),

arXiv: 1412.6980.

[126] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury,
G. Chanan, T. Killeen, Z. Lin, N. Gimelshein, L. Antiga,

11

A. Desmaison, A. K¨opf, E. Yang, Z. DeVito, M. Rai-
son, A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang,
and S. Chintala, arXiv:1912.01703 [cs, stat]
J. Bai,
(2019), arXiv: 1912.01703.

[127] J. D. Hunter, Computing in Science & Engineering 9,

90 (2007).

[128] C. R. Harris, K. J. Millman, S. J. van der Walt, R. Gom-
mers, P. Virtanen, D. Cournapeau, E. Wieser, J. Taylor,
S. Berg, N. J. Smith, R. Kern, M. Picus, S. Hoyer, M. H.
van Kerkwijk, M. Brett, A. Haldane, J. F. del R’ıo,
M. Wiebe, P. Peterson, P. G’erard-Marchant, K. Shep-
pard, T. Reddy, W. Weckesser, H. Abbasi, C. Gohlke,
and T. E. Oliphant, Nature 585, 357 (2020).

[129] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury,
G. Chanan, T. Killeen, Z. Lin, N. Gimelshein, L. Antiga,
A. Desmaison, A. Kopf, E. Yang, Z. DeVito, M. Raison,
A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai,
and S. Chintala, in Advances in Neural Information Pro-
cessing Systems 32 , edited by H. Wallach, H. Larochelle,
A. Beygelzimer, F. d‘ Alch´e-Buc, E. Fox, and R. Gar-
nett (Curran Associates, Inc., 2019) pp. 8024–8035.
[130] P. Virtanen, R. Gommers, T. E. Oliphant, M. Haber-
land, T. Reddy, D. Cournapeau, E. Burovski, P. Pe-
terson, W. Weckesser, J. Bright, S. J. van der Walt,
M. Brett, J. Wilson, K. J. Millman, N. Mayorov,
A. R. J. Nelson, E. Jones, R. Kern, E. Larson, C. J.
Carey, ˙I. Polat, Y. Feng, E. W. Moore, J. VanderPlas,
D. Laxalde, J. Perktold, R. Cimrman, I. Henriksen,
E. A. Quintero, C. R. Harris, A. M. Archibald, A. H.
Ribeiro, F. Pedregosa, P. van Mulbregt, and SciPy 1.0
Contributors, Nature Methods 17, 261 (2020).

