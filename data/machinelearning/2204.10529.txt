2
2
0
2

r
p
A
2
2

]

G
L
.
s
c
[

1
v
9
2
5
0
1
.
4
0
2
2
:
v
i
X
r
a

Exploring Hidden Semantics in Neural Networks with Symbolic
Regression

Yuanzhen Luo
Beijing Key Laboratory of Petroleum
Data Mining, China University of
Petroleum-Beijing
Beijing, China

Qiang Lu∗
Beijing Key Laboratory of Petroleum
Data Mining, China University of
Petroleum-Beijing
Beijing, China
luqiang@cup.edu.cn

Xilei Hu
College of Artificial Intelligence ,
China University of
Petroleum-Beijing
Beijing, China

Jake Luo
Department of Health Sciences and
Administration, University of
Wisconsin Milwaukee, Milwaukee,
WI, United States
Beijing, China

Zhiguang Wang
Beijing Key Laboratory of Petroleum
Data Mining, China University of
Petroleum-Beijing
Beijing, China

ABSTRACT
Many recent studies focus on developing mechanisms to explain
the black-box behaviors of neural networks (NNs). However, lit-
tle work has been done to extract the potential hidden semantics
(mathematical representation) of a neural network. A succinct and
explicit mathematical representation of a NN model could improve
the understanding and interpretation of its behaviors. To address
this need, we propose a novel symbolic regression method for neu-
ral works (called SRNet) to discover the mathematical expressions
of a NN. SRNet creates a Cartesian genetic programming (NNCGP)
to represent the hidden semantics of a single layer in a NN. It then
leverages a multi-chromosome NNCGP to represent hidden seman-
tics of all layers of the NN. The method uses a (1+𝜆) evolutionary
strategy (called MNNCGP-ES) to extract the final mathematical
expressions of all layers in the NN. Experiments on 12 symbolic
regression benchmarks and 5 classification benchmarks show that
SRNet not only can reveal the complex relationships between each
layer of a NN but also can extract the mathematical representation
of the whole NN. Compared with LIME and MAPLE, SRNet has
higher interpolation accuracy and trends to approximate the real
model on the practical dataset.

KEYWORDS
symbolic regression, neural network, Cartesian genetic program-
ming

1 INTRODUCTION
Neural networks (NNs) have been successfully applied in many
problems, such as CNN for object recognition [26], RNN for time
series analysis [11], and Bert for natural language processing (NLP)
[5]. However, neural networks are often seen as black-boxes be-
cause their input-output (IO) relationships are difficult for a human
to understand [12]. Sometimes, it is almost impossible to interpret
the NN behaviours when models make unexpected predictions on
some datasets, such as adversarial examples [31] and white noise

∗Corresponding author.

images [22]. Some of the recent work has been centred on research-
ing and explaining the black box behaviours, as summarized in
several survey papers [1, 29].

𝑥 (𝑖), 𝑦 (𝑖) (cid:17)
(cid:16)

In this paper, we aim to develop a new symbolic regression-based
method to explore hidden semantics in NNs. Here, a typical hidden
semantics interpretation method refers to explaining a NN with an
explicit math function. If a function 𝑓 (𝑥 (𝑖) ) explains a single hidden
layer ℎ(𝑥 (𝑖) ) on a certain input-output
or a small range
of inputs-outputs, it is called local explanation [35], such as LIME
[27] and MAPLE [24]. If a function 𝑓 (𝑥) is able to explain a hidden
layer ℎ(𝑥) on the whole dataset, it is called global explanation,
such as Visualization method [3, 17] and Net2vec [10]. Although
these methods show some degree of success in extracting hidden
semantics from NN, they have the following three limitations. (1)
Local explanation methods can give a mathematical expression,
such as a linear model and a decision tree, for each (𝑥 (𝑖), 𝑦 (𝑖) ).
However, they cannot obtain a general expression for the whole
dataset. Although most global explanation methods can visualize
NNs on the whole dataset, they cannot give a mathematical expres-
sion for explaining the dataset. (2) These local or global methods
often leverage pre-defined interpretable models to explain the hid-
den semantics of NNs. For example, LIME can use linear models,
decision trees, or falling rule lists as interpretable models. How-
ever, these pre-defined models may not capture hidden semantics
in some situations because the real characteristics of a NN model
are often unknown, and applying a predefined model to explain the
networks may be inappropriate. (3) These methods cannot generate
a mathematical expression that can represent the hidden semantics
of all layers in a NN.

To overcome these limitations, this paper leverages the sym-
bolic regression (SR) method to explain a NN. In SR, for a given
dataset {𝑥, 𝑦}, the algorithm can find a symbolic function 𝑓 (𝑥) = 𝑦 ′
that minimizes the distance between 𝑦 and 𝑦 ′ in the mathematical
expression space. SR has great flexibility in generating mathemat-
ical expressions; hence, it does not need a predefined model to
capture the relationships in the dataset. However, classical SR meth-
ods, such as GP [14, 30], GEP [8], and linear GP [2], usually handle

 
 
 
 
 
 
Conference’22, ,

Yuanzhen Luo, Qiang Lu, Xilei Hu, Jake Luo, and Zhiguang Wang

the symbolic function 𝑓 (𝑥) with a single output 𝑦 ′, i.e., 𝑦 ′ is a
number and not a vector. They cannot represent the relationship
𝑔(𝑊𝑖ℎ𝑖−1 + 𝑏) of each layer 𝑖 in a NN because each layer’s output
is a vector, matrix, or tensor. Therefore, when these GPs explain
NN [6, 9], they can only give a mathematical expression to show
the semantics of the whole NN with a single output value, not each
layer in the NN. Although Cartesian Genetic Programming (CGP)
[21] supports multiple outputs, CGP cannot represent semantics
in a NN. Because each CGP output corresponds to a hidden node,
and it cannot provide a general model 𝑓 that represents hidden se-
mantics in the layer. To obtain a general model, we assume that the
relationship between input and output in a layer (or a NN) has the
mathematical expression format 𝑤𝑠
𝑖−1) + 𝑏𝑖 , where 𝑤𝑖 and 𝑏𝑖
may be a number, vector, matrix, or tensor, and 𝑓𝑖 is a mathematical
function that represents the hidden semantics of the layer.

𝑖 𝑓𝑖 (ℎ𝑠

The remainder of this paper is organized as follows. In Section 2,
we introduce the background knowledge about Cartesian Genetic
Programming. Then, we propose SRNet to explore hidden semantics
in NNs in Section 3. Section 4 and 5 report the experimental results.
We conclude the paper in Section 6.

2 CARTESIAN GENETIC PROGRAMMING
CGP is a directed acyclic graph-based genetic programming algo-
rithm for addressing the SR problem [21]. In CGP, the graph consists
of a two-dimensional grid of computational nodes, as shown in Fig-
ure 2. These nodes are classified into three categories: input, output,
and function. The input (or output) nodes represent the input (or
output) values 𝑥 (or 𝑜), which is encoded into an integer, such as
𝑥0 encoded by "1" and 𝑂𝐴 encoded by "4". The function nodes are
computational expressions. Each function node has three parts,
input, computational expression, and output, encoded by a series of
integers. As each node has only one output, the output code is used
to index the node. For example, a function node "+" is regarded
as the code "⟨0012⟩". In this code, the first integer 0 is the code of
the function "+". The two middle integers "0" and "1" represent two
inputs of the function "+", and they are also the outputs of two
previous nodes. The last integer "2" is the index of the node.

Figure 1: SRNet for exploring hidden semantics in NN.

Based on the above assumption, this paper proposes a novel SR
method (called SRNet) to mine hidden semantics of all layers in a
NN simultaneously, as shown in Figure 1. SRNet is an evolutionary
computing algorithm. In each evolution, SRNet first leverages the
Cartesian Genetic Programming (CGP) [19, 20] to find each layer’s
mathematical function 𝑓𝑖 (ℎ𝑠
𝑖−1). It then uses the Newton-Raphson
method [28] (or L-BFGS method [16]) for few (or many) variables
𝑖 = 𝑤𝑠
to obtain 𝑤𝑠
𝑖−1) + 𝑏𝑖 approximates
the output ℎ𝑖 of the layer 𝑖 in a NN. At the end of the evolution,
SRNet will capture hidden semantics of all layers in a NN when
ℎ𝑠
𝑖 ≈ ℎ𝑖 (including 𝑦𝑠 ≈ 𝑦). The main contributions in the paper are
summarized as follows:

𝑖 and 𝑏𝑖 so that ℎ𝑠

𝑖 𝑓𝑖 (ℎ𝑠

• The paper proposes a new method called SRNet to explain
hidden semantics of all layers in a NN. SRNet generates a
mathematical expression in the format of 𝑤𝑠
𝑖−1) + 𝑏𝑖
that can be used to explain a NN.

𝑖 𝑓𝑖 (ℎ𝑠

• To speed up SRNet, we create a multi-chromosome CGP [33]
evolutionary strategy embedded in the Newton-Raphson
method.

• Experiments show that the proposed SRNet can capture hid-
den semantics in NN in 12 SR benchmarks and 5 classification
benchmarks. Compared with LIME and MAPLE, SRNet has
higher interpolation accuracy and trends to approximate the
real model on the practical dataset.

Figure 2: An example of CGP. a) genotype. b) phenotype.

In the example CGP diagram, there is no edge between any two
nodes in the same column. Two nodes at different columns can
be linked if one’s input code equals the other’s output code. A
genotype is used to represent a CGP, as shown in Figure 2. The
genotype contains two categories of nodes: the functional nodes
and the output nodes. As the genotype has multiple output nodes,
the genotype can describe multiple computational expressions. For
example, the genotype in Figure 2 generates three mathematical
expressions, 𝑂𝐴 = −𝑥1, 𝑂𝐵 = 2𝑥0𝑥1 + 𝑥 2

1 , and 2𝑥0 + 𝑥1.

CGP usually leverages the (1 + 𝜆) evolutionary strategy [13, 25]
to find the best fitted mathematical expression. In each evolution,
(1 + 𝜆) EA utilizes mutation to generate 𝜆 offsprings. For CGP, the
mutation randomly chooses a gene location and changes the allele
at the location to another valid random value. A valid value is from
the function look-up table if a computational expression gene is
chosen for mutation. If an input gene is chosen, a valid value is from
the output set of its previous nodes. The mutation does not change

Exploring Hidden Semantics in Neural Networks with Symbolic Regression

Conference’22, ,

the output gene. For example, in Figure 2, a mutation changes the
input gene "1" of the node "7" to "3". Then, the output 𝑂𝐵 becomes
"0".

The multi-chromosome Cartesian genetic programming (MCGP)
[33] encodes multiple chromosomes into a single genotype. Each
chromosome code is similar to the genotype of CGP. So, MCGP
can provide a solution to a large problem by dividing it into many
smaller sub-problems. For simultaneously exploring hidden seman-
tics of all layers in a NN, MCGP encodes each layer semantics as
a chromosome into a genotype. Thus, a chromosome represents
the semantics of one layer, and the genotype represents all NN
layers’ semantics. After MCGP uses the (1 + 𝜆) multi-chromosome
evolutionary strategy [34] to acquire a best-fitted individual, it also
obtains these semantics.

3 SRNET
This section proposes the SRNet, a method based on MCGP [33] to
simultaneously explain the hidden semantics of layers in a NN. As
shown in Figure 1, SRNet can find a group of ℎ𝑠
𝑖−1) + 𝑏𝑖
that approximates each NN layer output ℎ𝑖 , i.e.,

𝑖 = 𝑤𝑠

𝑖 𝑓𝑖 (ℎ𝑠

{ℎ𝑠
0

, ..., ℎ𝑠

𝑛 } = arg𝑚𝑖𝑛
ℎ𝑠
𝑖 ∈ F

𝑛
∑︁

𝑖=0

L (ℎ𝑖, ℎ𝑠

𝑖 ).

(1)

To find the group {ℎ𝑠
𝑖 } quickly, SRNet needs to address the following
problems: 1) how to encode these ℎ𝑠
𝑖 s, and 2) how to find functions
to explain hidden semantics in a NN. Section 3.1 shows our solu-
tion to the first problem, and section 3.2 provides a multi-NNCGP
evolutionary strategy to address the second problem.

3.1 SRNet Encoding
The hidden semantics ℎ𝑠

𝑖 of each layer in a NN are represented as
𝑤𝑠
𝑖 𝑓𝑖 (ℎ𝑠

𝑖−1) + 𝑏𝑖,

(2)

where 𝑓𝑖 (ℎ𝑠
general semantics in the layer 𝑖, and 𝑤𝑠
matrix, or a tensor, as shown in Figure 3.

𝑖−1) is a mathematical expression that represents the
𝑖 and 𝑏𝑖 are a weight vector,

To capture a NN layer’s semantics ℎ𝑠

𝑖 , we define that the neural
network CGP (NNCGP) consists of three components, including
general semantic model, constant, and operator. The general seman-
tic model is used to generate 𝑓𝑖 (ℎ𝑠
𝑖−1). It has three parts, 𝑘 inputs,
𝑐 × 𝑟 functions and an output. 2) The constant component includes
the weight vector 𝑤𝑠
𝑖 | = |𝑏𝑖 | = |ℎ𝑠
𝑖 |.
3) The operator component consists of the two functions, "×" and
"+".

𝑖 and the bias vector 𝑏𝑖 , where |𝑤𝑠

SRNet uses multiple NNCGPs (called MNNCGP) to encode geno-
type. Since a NNCGP can represent one layer’s semantic, multiple
NNCGPs can be used to capture hidden semantics of all layers in a
NN. These NNCGPs are regarded as chromosomes that constitute
a genotype. In the genotype, each NNCGP𝑖 ’s output ℎ𝑠
𝑖 is the input
of its next NNCGP𝑖+1.

3.2 Evolution Strategy
SRNet leverages a multi-NNCGP evolutionary strategy embedded
by the Newton-Raphson method (called MNNCGP-ES) to find the
best-fitted genotype that represents hidden semantics of all layers
in a NN. MNNCGP-ES is similar to the (1 + 𝜆) multi-chromosome
evolutionary strategy [34]. MNNCGP-ES includes the following
operations: mutation, fitness evaluation, and selection. Mutation,
with a certain probability, change each allele in MMCGP to another
valid random value [21].

Fitness Evaluation. To evaluate a genotype encoded by MN-

3.2.1
NCGP, the fitness function is defined as the following equation,

fitness =

1
𝑁

𝑁 −1
∑︁

𝑖=0

L (ℎ𝑖, ℎ𝑠

𝑖 ) + L𝑜 (𝑦, 𝑦𝑠 )

(3)

where L is the mean squared error (MSE) of each middle layer. L𝑜
is an error function of the output layer. It is a cross-entropy loss in
the classification task, while it is MSE in the regression task. ℎ𝑖 (ℎ𝑠
𝑖 )
is the output of the 𝑖th layer in a NN (NNCGP𝑖 ). 𝑦 and 𝑦𝑠 are the
outputs of the NN and SRNet, respectively.
Equation 2 indicates that obtaining ℎ𝑠

𝑖 needs two computations,
as shown in Figure 3. One is 𝑓 (ℎ𝑠
𝑖−1) that generates an output by the
CGP code. The other is the parameter computation that obtains the
constant vectors, 𝑤𝑠
𝑖 and 𝑏𝑖 , by the Newton-Raphson method that
performs an update operation according to the following equation.
𝑝 = 𝑝 − 𝐻 −1 (𝑝)∇𝑙 (𝑝),

(4)
where 𝑝 is 𝑤𝑠
𝑖 or 𝑏𝑖 , 𝐻 (𝑝) is Hessian, ∇𝑙 (𝑝) is the gradient of the
loss function ℎ𝑖 − (𝑤𝑠
𝑖−1) + 𝑏𝑖 ). The Hessian is difficult to
obtain if it is a high-dimensional matrix (i.e., many neurons). There-
fore, to solve this problem, the Limited-memory Broyden-Fletcher-
Goldfarb-Shanno algorithm (L-BFGS) [16] is used for limited mem-
ory and time-saving.

𝑖 𝑓 (ℎ𝑠

Figure 3: SRNet encoded by Multiple NNCGPs

Selection. Selection aims at generating a ’super’ individual
3.2.2
from the population. The ’super’ individual consists of a set of super
chromosomes that have the best fitness at each position from all
individuals, i.e., 𝑚𝑖𝑛 L (ℎ𝑖, ℎ𝑠
𝑖 ), as shown in Figure 4. Since these
chromosomes constitute an input-output sequence where each
chromosome output is the input of its next chromosome, they need
to be selected in the order of their positions in the population. After
evaluating the finesses of the chromosomes at a certain position

Conference’22, ,

Yuanzhen Luo, Qiang Lu, Xilei Hu, Jake Luo, and Zhiguang Wang

4 EXPERIMENTS
To validate the SRNet’s ability to explain hidden semantics in the
neural network (NN), we tested the SRNet on the built NNs of 12
symbolic regression benchmarks as well as 5 classification bench-
marks, listed in Table 1. Moreover, the sample sizes and feature
sizes of the 17 benchmarks are illustrated in Figure 5.

Figure 4: Selecting chromosomes at each points from all in-
dividuals as a "super" individual.

(𝑐0) of the population, the selection picks up the chromosome that
has the best fitness score as the super chromosome (𝑠0). Then, it
evaluates chromosome at the next position(𝑐1) with 𝑠0 as input.
Moreover, it obtains a chromosome with the best fitness as the next
super chromosome (𝑠1). Repeating the above evaluation policies re-
sults in a group of selected chromosomes {𝑠0, 𝑠1, ...}. These selected
chromosomes form a super individual.

However, for high-dimensional problems, evaluating the finesses
of the chromosomes is very time-consuming when using the Newton-
Raphson method. So, L-BFGS is used to replace the Newton-Raphson
method to compute the two weight vectors (𝑤𝑠
𝑖 and 𝑏𝑖 ) of all indi-
viduals. L-BFGS can speed up the fitness evaluation.

3.2.3 MNNCGP-ES. The MNNCGP-ES pseudocode is listed in Al-
gorithm 1. MNNCGP-ES combines the fitness evaluation and the
selection method mentioned before, using the (1 + 𝜆) evolution
strategy to evolve generation-by-generation to obtain the optimal
individual.

Algorithm 1 MNNCGP-ES
Input: D𝑠 (𝒉0, 𝒉1, . . . , 𝒉𝒏), 𝜆
Output: a best-fitted individual

5:

4:

1: randomly initializes 𝜆 individuals with MNNCGP
2: while 𝑓 𝑖𝑡𝑛𝑒𝑠𝑠 > 1𝑒 − 4 and max generation not reached do
//obtain an new parent 𝑠 by the selection operation
3:
𝑠 ← NULL
calculate each chromosome’s output ℎ𝑠
cording to Equations 2 and 4;
obtain the chromosome 𝑐𝑘
𝑠 ← 𝑠 ∪ 𝑐𝑘
𝑖
execute 𝜆 mutations on 𝑠 to generate 𝜆 offsprings.

𝑖 by Equation 3

8:
9: end while
10: Return the best-fitted parent 𝑠 according to the fitness com-

𝑖 at the position 𝑖 ac-

7:

6:

puted by Equation 3.

Figure 5: The sizes of samples and features in 17 benchmarks

Alias
𝐾0
𝐾1
𝐾2
𝐾3

𝐾4

𝐾5

𝐹 0

𝐹 1
𝐹 2
𝐹 3

𝐹 4

𝐹 5

𝑃0
𝑃1

𝑃2
𝑃3
𝑃4

Function/Name
𝑠𝑖𝑛(𝑥) + 𝑠𝑖𝑛(𝑥 + 𝑥 2)
2𝑠𝑖𝑛(𝑥)𝑐𝑜𝑠 (𝑦)
3 + 2.13𝑙𝑛 |𝑥 |
1+𝑥 −4 + 1
1+𝑦4
30𝑥 𝑦
(𝑥−10)𝑧2

1

𝑥𝑦 + 𝑠𝑖𝑛((𝑥 − 1)
(𝑦 − 1))

−6.4

)

√︃

− 1
𝑟1

𝑚0
1− 𝑣2
𝑐2
𝑟
𝑞1𝑞2
4𝜋𝜖𝑟 3
𝐺𝑚1𝑚2 ( 1
𝑟2
1
𝑘𝑥 2
2
𝐺 4
𝑟 5 (𝑚1𝑚2)2
1
𝑐5
(𝑚1 + 𝑚2)
𝑞
4𝜋𝜖𝑦2 [4𝜋𝜖𝑉𝑒𝑑−
𝑞𝑑𝑦3
(𝑦2−𝑑 2) 2 ]
adult
analcatdata_aids

Training Dataset
[−1, 1, 200]
[−1, 1, 200]
[−50, 50, 200]
[−5, 5, 104]
𝑥, 𝑦 : [−1, 1, 103]
𝑧 : [1, 2, 103]

[−3, 3, 20]
𝑚0 : [1, 5, 104]
𝑣 : [1, 2, 104]
𝑐 : [3, 10, 104]
[1, 5, 104]
[1, 5, 104]
[1, 5, 104]
𝑚1, 𝑚2 : [1, 5, 104]
𝐺, 𝑐, 𝑟 : [1, 2, 104]
𝑞, 𝑉𝑒, 𝜖 : [1, 5, 104]
𝑑 : [4, 6, 104]
𝑦 : [1, 3, 104]
48842
50

agaricus_lepiota
breast
car

8145
699
1728

MLP
[3, 3] s0.01
[3, 3] s0.1
[5, 5] s0.03
[4, 4, 4] a0.03

[4, 4] a0.003

[5, 5] a0.003

[3, 3] a0.01

[3, 3] a0.01
[3, 3] a0.01
[3, 3] a0.01

[5, 5] a0.03

[3, 3] a0.03

[100, 100] s0.01
[200, 100, 100]
s0.01
[100, 100] s0.01
[100, 100] s0.03
[100, 100, 100]
s0.01

Table 1: The dataset of training 17 MLPs. In each cell of the
column ’MLP’, the integer list is the number of neurons in
each hidden layer, ’a’ or ’s’ is the Adam or SGD optimization
method, respectively, float number being the learning rate.

01000020000300004000050000No. of Samples05101520No. of FeaturesRegressionClassificationExploring Hidden Semantics in Neural Networks with Symbolic Regression

Conference’22, ,

Name

LIME

MAPLE

SRNet

Parameter
Number of Features
Number of Samples
Distance Metric
Regressor Model
Number of Estimators
Max Features
Min Samples Leafs
Regularization
Ensemble Model
Regressor Model
Classifier Model
Number of Rows
Number of Cols
Function Set
Number of Constants
Population Size
Max Generations
Mutation Probability

Value
10
5000
Euclidean
Ridge
200
0.5
10
0.001
Random Forest
Ridge
Logistic Regressor
10
10
+, −, ×, ÷, 𝑠𝑞𝑟𝑡, 𝑠𝑞𝑢𝑎𝑟𝑒, sin, cos, 𝑙𝑛, tan, 𝑒𝑥𝑝
1
200
5000
0.4

Table 2: Algorithm parameters

Table 2 lists the parameters of the three algorithms, LIME, MAPLE,
and SRNet. All parameters of the three algorithms are fixed on all
benchmarks.

4.1 Regression Task
To validate the SRNet’s ability to explore hidden semantics of NN in
the regression task, we chose 12 symbolic regression benchmarks
𝐾0 − 𝐾5 and 𝐹 0 − 𝐹 5. The benchmarks 𝐾0 − 𝐾5 were chosen from
the commonly used SR Benchmarks [18], while 𝐹 0 − 𝐹 5 are from
physical laws [32]. We generated 12 datasets (called true datasets)
according to these benchmarks. Each of these datasets has different
sample sizes (see ’Training Dataset’ in Table 1). For example, for the
𝐾1 problem in Table 1, we randomly sampled 200 𝑥 and 𝑦 values
in the range of [−1, 1], respectively. Moreover, combining these
values can generate 200 samples for the 𝐾1 dataset. For each of the
12 datasets, we randomly took 80% samples from it as the training
dataset, and the other as the test dataset. Then, we built 12 Multi-
Layer Perception neural networks (MLP) with a sigmoid activation
function using the training datasets. The training parameters are
listed in Table 1. For example, for 𝐾1, we created an MLP with two
hidden layers where each layer had three hidden nodes. The MLP
was trained by the SGD optimization method with a learning rate
of 0.01.

After each MLP was trained, we collected each NN layer’s input
and output data of the 12 MLPs as the NN explanation datasets. We
then ran the MNNCGP-ES, LIME, and MAPLE 30 times on each NN
explanation dataset.

4.2 Classification Task
To validate the SRNet’s ability to explore hidden semantics of NN in
the classification task, we chose 5 classification benchmarks named
𝑃0 − 𝑃4 from the PMLB [23] with the different number of samples
and features (see Figure 5). The column ’Training Dataset’ on the
rows "P0-P4" indicates the number of samples, as shown in Table
1. Training 5 MLPs is similar to the regression task except for the
function "softmax" that replaces their output functions.

Figure 6: (a) The decision boundary of a classification model
with 4 classes. (b) sampling around decision boundaries. The
marker ’X’ is represented as the new sample around the de-
cision boundaries.

After training these classification MLPs, we need to compare
SRNet with their decision boundaries, not their outputs. Because
the MLP’s outputs on the training datasets are sparse and do not
fully represent the NN’s classification ability, as shown in Figure
6(a). Using these outputs to train SRNet may result in wrong results.
To obtain the decision boundaries of the trained MLP, we leverage
a uniform sample method around its decision boundary (called
USDB). USDB first evaluates the range of the training dataset. It
then randomly samples 𝑛 points in the range. It finally selects 𝑠
points with the shortest distance to the decision boundary according
to Equation 5 [7, 15].

𝑑 (𝑥𝑖, 𝐵) =

𝐶
∑︁

|𝑝𝑘 (𝑥𝑖 ) −

1
𝐶

|

(5)

𝑘
, where 𝑥𝑖 is a sample, 𝐵 is the decision boundary of a NN, and 𝐶 is
the number of sample classifications. 𝑝𝑘 is the probability that the
𝑥𝑖 belongs to the 𝑘th classification, which is the NN output owing
to its activation function "softmax".

After each classification MLP was trained, we utilized USDB to
generate samples around the decision boundary of the MLP. We
then fed these samples into the MLP and collected each NN layer’s
input and output as the MLP explanation dataset. We finally ran
the MNNCGP-ES, LIME, and MAPLE 30 times on the explanation
dataset.

5 RESULT AND ANALYSIS
5.1 Regression Task
In the following regression tasks we only show results on the six
benchmarks, 𝐾0 − 𝐾3, 𝐹 0, and 𝐹 1. The regression results on all
benchmarks are in the appendix.

Fitness Convergence. Figure 7 illustrates the convergence
5.1.1
curve of the fitness scores of MNNCGP-ES on each MLP for the
regression tasks. The blue line is the average fitness score in 30
experiments. It gradually decreases at the beginning and trends to
a flat curve. It means that, statistically, MNNCGP-ES could find the

−2−1012−2−1012(a)−2−1012(b)Conference’22, ,

Yuanzhen Luo, Qiang Lu, Xilei Hu, Jake Luo, and Zhiguang Wang

Dataset

𝐾0

𝐾1

𝐾2

𝐾3

𝐹 0

𝐹 1

𝑶𝒔 (𝒙)
0.29 − 4.01𝑠𝑖𝑛((𝑠𝑖𝑛((2.36𝑐𝑜𝑠 ((0.41𝑠𝑖𝑛((0.26𝑥+
sin (sin (𝑥)) − 0.068)) + 0.49)) − 2.03))))
(6.11e-04)
−0.01𝑥1 + 1.69 sin (𝑥0) + 0.0021
(9.62e-02)
𝑥 2 log (𝑥 2)
𝑥 +1.20

−0.044+

0.061

0.084

1−

0.19

(cid:33) 2

√

√

(cid:32)

(cid:18)

1− 0.19

√

𝑥 2 log (𝑥 2)
𝑥 +1.20

(cid:19) 2

−0.044+ 0.084

√

𝑥 2 log (𝑥 2)
𝑥 +1.20

(cid:33)

0.51 tan (cid:169)
6.70(cid:169)
(cid:173)
(cid:173)
(cid:171)
(cid:171)
(cid:32)
0.061

tan

(cid:32)

4.49 sin

(cid:169)
(cid:173)
(cid:173)
(cid:173)
(cid:173)
(cid:171)

𝑥 2 log (𝑥 2)
𝑥 +1.20

+0.27(cid:170)
(cid:174)
(cid:172)

(cid:33) 2

(cid:170)
(cid:174)
(cid:172)
+0.63

(cid:170)
(cid:174)
(cid:174)
(cid:174)
(cid:174)
(cid:172)

+7.90
(2.22e-01)
Too long (See appendix for details)
(2.73e-02)
(cid:16)
3.05 − 7.00𝑡𝑎𝑛((𝑡𝑎𝑛((0.58 cos
(cid:17)
log (𝑚0) + 0.67𝑣
𝑐
(1.05e-01)
(cid:32)

0.22 cos

log (𝑚0) + 0.67𝑣
𝑐
(cid:17)
− 1.01

(cid:16)

(cid:16)

(cid:17)

−

+ 0.35)) − 0.11))

0.76 cos

(cid:18)

0.022

0.46 log

(cid:19)

(cid:18) 𝑞1𝑞2
𝑒𝑟 3
2

(cid:19)4

+ 1

(cid:18)

0.46 log

(cid:18) 𝑞1𝑞2
𝑒𝑟 3
2

(cid:19)

(cid:19)4

+ 1

− 0.00072

(cid:33)

+ 3.22 sin

0.0068

+0.0059
(6.37e-03)

Table 4: The mathematical expression of each whole NN.

(a) K0-h1

(b) K1-h1

Figure 7: MNNCGP-ES convergence curve.

mathematical expressions that approximate the hidden semantics
of each layer in NNs according to Equation 3, as shown in Table
3. It also indicates the feasibility to use the combination of these
mathematical expressions to represent the whole semantics of each
MLP, as shown in Table 4.

Dataset

𝐾0

𝐾1

𝐾2

𝐾3

𝐹 0

𝐹 1

𝒉𝒔
(𝒙)
0
𝑠𝑖𝑛(0.26𝑥+
𝑠𝑖𝑛(𝑠𝑖𝑛(𝑥))−
0.068)
(6.74e-04)
5.15e-05𝑥1−
0.0072𝑠𝑖𝑛(𝑥0)−
5.15e-05
(5.34e-02)

√

𝑥 2 log (𝑥 2)
𝑥+1.20
(3.26e-02)

−𝑠𝑖𝑛((0.24𝑥0+
sin (0.23𝑥1)))
(3.86e-02)
𝑐𝑜𝑠 (( 0.67𝑥1
𝑥2
log (𝑥0)))
(6.35e-03)
(cid:33)

+

(cid:32)

log

𝑥0𝑥1
3
𝑥2𝑥
2
3
(9.59e-03)

𝒉𝒔
1

(𝒉𝒔
0

)

𝒉𝒔
2

(𝒉𝒔
1

)

0.88 − cos (ℎ𝑠
(7.54e-05)

0)0

−(ℎ𝑠

0)0 + (ℎ𝑠
(1.39e-03)

0)2

−𝑡𝑎𝑛(((ℎ𝑠
0)2+
(ℎ𝑠
0)2
3−
(ℎ𝑠
0)3))
(1.04e-02)
0)1 (ℎ𝑠
(ℎ𝑠
0)2
2
(cid:17)
(cid:16)
(ℎ𝑠
0)1
sin
(3.64e-03)
−(ℎ𝑠
0)1+
(cid:16)
(ℎ𝑠
0)2
cos
(1.04e-02)

(cid:17)

(ℎ𝑠
0)4
1
(2.46e-04)

−

−

−

(ℎ𝑠

1)2+

1)0 (−(ℎ𝑠
(ℎ𝑠
1)3)
(2.87e-04)

−

−

0)0

𝒚𝒔
−𝑠𝑖𝑛(𝑠𝑖𝑛((ℎ𝑠
−0.36))
(2.37e-04)
−(ℎ𝑠
1)0+
(ℎ𝑠
1)2+
0.0011
(6.88e-02)
(cid:18) (ℎ𝑠
(cid:19)
(ℎ𝑠
(2.00e-01)

1)0
1) 2
2

sin

(ℎ𝑠
2)3
−0.99 +
(ℎ𝑠
2)0
(1.32e-02)

𝑡𝑎𝑛((𝑡𝑎𝑛(((ℎ𝑠
1)0
−0.33)) + 0.11))
(9.63e-02)

(cid:16)

(ℎ𝑠

1)0 + sin

(ℎ𝑠
(1.45e-03)

1)0

(c) K2-h1

(d) K3-h1

(cid:17)

Table 3: The mathematical expressions of each layer in NNs.

(e) F0-h1

(f) F1-h1

Not all ranges of fitness scores (light blue areas) become smaller
as the MNNCGP-ES runs, such as 𝑘1. However, the low bounds
of these lines always become smaller and trend to be zero at the
later stage. It means that the more episodes the MNNCGP-ES runs,
the more likely MNNCGP-ES is able to find the mathematical ex-
pressions that can be used to explain the hidden semantics of a
NN. The slow decrease of fitness curves also indicates the need
to run MNNCGP-ES with sufficient times to obtain the best-fitted
mathematical expressions.

Figure 8: The outputs of the SRNet layer vs the NN layer with
9 random input values.

Semantics Evaluation. The results show that the proposed
5.1.2
SRNet method can acquire a fitted mathematical expression to
explain hidden semantics of each layer, as shown in Table 3. Each of
these mathematical expressions represents the general semantics 𝑓𝑖
in the expression 𝑤𝑠
𝑖−1) + 𝑏𝑖 (Equation 2). The number below
each 𝑓𝑖 is its fitness. For example, for 𝐾1, MNNCGP-ES finds the
general semantics −(ℎ𝑠
0)2 at the second hidden layer ℎ1. The

0)0 + (ℎ𝑠

𝑖 𝑓𝑖 (ℎ𝑠

𝑖 × (−(ℎ𝑠

0)0 + (ℎ𝑠

fitness of 𝑤𝑠
0)2) + 𝑏𝑖 is 1.39𝑒 − 03. All fitness values
in the hidden layers are less than 0.1. It means that 𝑓𝑖 captured by
MNNCGP-ES can represent (approximate) the semantics of each
hidden layer in a NN.

Figure 8 shows the details of mathematical expressions that
MNNCGP-ES finds. The expressions approximate the output of each
layer in a NN. To evaluate each layer, we input 9 random values

050000.20550.10280.0000K0050000.94980.47490.0000K10500036.3118.160.00K2050001.0120.5060.000K3050002.8621.4310.000F0050000.042060.021030.00000F1NNSR0.00.70.20.00.70.20.30.60.30.30.60.30.00.70.20.00.70.2NNSR0.10.60.20.10.60.20.00.70.20.00.60.20.00.70.20.00.70.2012NNSR0.00.70.20.00.60.20120.80.50.40.70.50.40120.00.70.20.00.70.2NNSR0.60.60.30.90.90.30.30.60.60.20.91.00.50.60.50.50.90.7NNSR0.40.60.50.60.90.70.40.60.60.50.90.80.30.60.70.30.90.9012NNSR0.20.60.70.20.91.00120.60.60.40.80.90.40120.50.60.40.70.90.5NNSR0.60.60.50.80.70.60.60.50.70.60.50.50.40.70.60.50.50.40.70.70.50.50.40.70.60.50.50.40.70.7NNSR0.60.60.50.80.70.60.60.50.70.60.60.60.50.80.70.60.60.50.70.60.00.10.00.30.30.30.40.30.80.701234NNSR0.50.50.40.70.60.50.50.40.70.7012340.30.40.21.01.00.20.30.20.80.8012340.00.20.10.90.90.20.30.20.80.8NNSR0.50.40.70.40.40.50.60.50.50.40.70.40.40.50.60.50.50.40.70.40.40.40.60.5NNSR0.50.40.70.40.40.50.60.50.50.40.60.40.50.50.50.50.60.50.50.40.60.50.40.50123NNSR0.80.60.20.40.70.60.30.401230.70.60.30.50.70.60.30.401230.40.50.50.60.50.50.50.5NNSR0.10.00.50.10.00.50.20.00.90.30.10.80.30.01.00.30.10.9NNSR0.40.01.00.40.10.90.30.01.00.40.10.90.10.00.80.20.00.7012NNSR0.30.01.00.40.10.90120.00.00.40.00.00.40120.10.00.80.20.00.7NNSR0.00.00.00.10.10.10.00.00.00.10.10.10.20.20.00.20.20.1NNSR0.00.00.00.10.10.10.00.00.00.10.10.10.00.00.00.10.10.1012NNSR0.00.00.00.10.10.10120.00.00.00.10.10.10120.00.10.00.10.20.1Exploring Hidden Semantics in Neural Networks with Symbolic Regression

Conference’22, ,

0)0 + (ℎ𝑠

0)2" in Table 3.

into the mathematical expression and the hidden nodes in the NN,
respectively. We then obtained 9 heat maps to show the difference
between the output of the mathematical expression and that of the
NN hidden nodes. For example, the sub-figure "𝐾1 − ℎ1" represents
the 𝐾1 outputs of SRNet vs NN in the layer ℎ1 with 9 random input
values. In the first heat map in "𝐾1−ℎ1", [0.6, 0.6, 0.3] are the outputs
of three hidden nodes in the NN layer ℎ1 with the first input value,
while [0.9, 0.9, 0.3] are the output of the mathematical expression
in the SRNet layer ℎ1. So, Figure 8 explains why a mathematical
expression has low fitness, and another has high fitness. Comparing
𝐾1−ℎ1 with 𝐾0−ℎ1 in Figure 8, the outputs between NN and SRNet
in 𝐾0−ℎ1 are closer than the output between them in 𝐾1−ℎ1. Thus,
the fitness "7.54𝑒 − 05" of "0.88 − 𝑐𝑜𝑠 (ℎ𝑠
0)0" is less than "1.39𝑒 − 03"
of " −(ℎ𝑠
For the output layers in the NNs, the last column 𝑦𝑠 in Table
3 lists the mathematical expressions to present the outputs. Their
fitness scores of the output layer are better than the scores of the
previous layers. There are two formulas of 𝐾5 and 𝐹 5 whose fitness
scores are greater than 1. The reason causing the higher scores
at the output layers is that, in a NN, the network structure of the
outer layer is different from the hidden layers. The computation
function on the output layer is 𝑦 = 𝑊𝑖+1ℎ𝑖 + 𝑏𝑖+1, while that on the
hidden layer is ℎ𝑖 = 𝑊𝑖ℎ𝑖−1 + 𝑏𝑖 . Since 𝑦 is a number and ℎ𝑖 is a
vector, 𝑦 = 𝑊𝑖+1ℎ𝑖 +𝑏𝑖+1 is a multivariate linear equation. However,
𝑦𝑠 = 𝑤𝑠
𝑓𝑖+1 (ℎ𝑠
𝑖 )+𝑏𝑖+1 on the output layer in SRNet is one-variable
linear equation because 𝑤𝑠
𝑖+1 and 𝑏𝑖+1 are two numbers, not vectors.
Although MNNCGP-ES can find a fitted mathematical function
𝑓𝑖+1 to represent the NN layers, the one-variable linear equation is
still hard to approximate the multi-variable linear equation in the
layers.

𝑖+1

Table 4 lists the mathematical expressions that represent the
whole NN semantics for the regression tasks. Each of final expres-
sions is obtained by combining the mathematical expressions in
different layers shown in Table 3. The complexity and length of
the mathematical expressions could increase substantially, such
as the mathematical expression in 𝐾3, due to the combination of
expressions on every layer. If there are more layers in a NN, the
length of the mathematical expression could be longer. Although
the math representation generated by SRNet could be lengthy, it
provides a straightforward expression to show all layers’ hidden
semantics of the whole NN.

5.1.3 Performance Comparison. To evaluate the SRNet performance
on regression tasks, we ran and compared SRNet, LIME [27], and
MAPLE [24] on an interpolation dataset and an extrapolation dataset.
The interpolation dataset consists of the NN input-output values.
In contrast, the extrapolation dataset consists of the data sampled
directly from the original symbolic expression in the column "Func-
tion" in Table 1. The interpolation domain is the same as the range of
the training dataset shown in Table 1. The size of the extrapolation
domain is five times that of the interpolation domain.

Figure 9 illustrates the curves (or distribution points) of the
true dataset, as well as the results of NN(MLP)s, SRNet, LIME, and
MAPLE, on different symbolic regression benchmarks. For the high
dimension datasets, it is not easy to visualize the curves. So, the
curves are projected into samples on multiple planes. The curves

between two vertical blue lines represent interpolated results, while
those outside the two lines are the extrapolated results.

(a) K0

(b) K1

(c) K2

(d) K3

(e) F0

(f) F1

Figure 9: SRNet vs LIME vs MAPLE on the interpolation and
extrapolation domain. The area between two blue vertical
lines is the interpolation domain. The other area is the ex-
trapolation domain

The interpolated results show that SRNet can find the mathemat-
ical expressions close to MLP on most of these benchmarks. SRNet
can find smoother results than LIME, while it can find results closer
to MLP compared with MAPLE. The extrapolated results show
that LIME can find the model closest to MLP because LIME is the
local explanation method that generates a model for local (sev-
eral) samples. For a extrapolate dataset, LIME divides the datasets
into many groups of local samples and generates a model for each
group of samples. Therefore, it needs many local models to explain
the extrapolated dataset and cannot provide a general model to
describe the whole dataset. Unlike LIME, SRNet finds the mathe-
matical expression that represents the whole dataset. In addition,
it can trend towards the true dataset generated by the symbolic
regression benchmark. Therefore, SRNet has better extrapolation
results in our evaluation [4]. The ability of SRNet extrapolation
could help SRNet judge why a NN fails to predict some test data.
Under the assumption that the mathematical expression found by
SRNet can represent the real model on the practical dataset. For
example, on the benchmark 𝐾1, if a NN is unable to predict certain
output, the prediction result could be compared with the output
of −0.01𝑥1 + 1.69 sin (𝑥0) + 0.0021 found by SRNet. The difference
between the NN output and SRNet can be used to analyze the gap
between the NN and the real model.

5.2 Classification Task
In the following classification tasks we only show the results on
the two benchmarks, 𝑃0, and 𝑃1. The classification results on all
classification benchmarks are included in the appendix.

Fitness Convergence. Figure 10 shows the fitness conver-
5.2.1
gences curves of the SRNet for the classification tasks on the two
benchmarks, 𝑃0 and 𝑃2. SRNet converges rapidly, especially within
about 100th generations. As MNNCGP-ES runs L-BFGS to obtain
𝑖 and 𝑏𝑖 ) of all individuals (𝑤𝑠
weight vectors (𝑤𝑠
𝑖−1) + 𝑏𝑖 ) every

𝑖 𝑓𝑖 (ℎ𝑠

−4−2024X−2−1012TrueMLPSRNetLIMEMAPLE−4−2024X−2.0−1.5−1.0−0.50.00.51.01.52.0TrueMLPSRNetLIMEMAPLE−200−1000100200X−8−6−4−202TrueMLPSRNetLIMEMAPLE−20−1001020X−6−4−202TrueMLPSRNetLIMEMAPLE01020x0−3−2−1012324x1020x2TrueMLPSRNetLIMEMAPLE05101520x00102005101520x105101520x20102005101520x3TrueMLPSRNetLIMEMAPLEConference’22, ,

Yuanzhen Luo, Qiang Lu, Xilei Hu, Jake Luo, and Zhiguang Wang

50 generations, MNNCGP-ES only runs L-BFGS two times, and it
can converge to an accurate result. The reason is that SRNet does
not need a whole dataset to be trained, but a thousand samples
around the decision boundary of a NN. For example, on the bench-
mark 𝑃0, although it has 48842 points, these points are only used to
train a classification NN. After training the NN, USDB ( Section 4.2)
randomly samples 1000 points around the classification NN. Then,
the 1000 points are used to train SRNet. So, the process of training
SRNet in the classification task is fast.

Dataset

𝑃0

𝑃2

𝑶𝒔 (𝒙)
𝑃𝑟 0 = −14.16 − 0.00043𝑥6−0.00043𝑥7−0.00043𝑥9+0.42
−0.0025𝑥6+0.0025𝑥7+0.0025𝑥9+0.489
𝑃𝑟 1 = 14.57 + 0.00047𝑥6−0.00047𝑥7−0.00047𝑥9+0.46
−0.0025𝑥6+0.0025𝑥7+0.0025𝑥9+0.49
(8.05e-03)
𝑃𝑟 0 = 0.66𝑥10 + 0.66𝑥20 − 0.66𝑥8 − 0.66𝑥9 − 1.57
𝑃𝑟 1 = −0.53𝑥10 − 0.53𝑥20 + 0.53𝑥8 + 0.53𝑥9 + 1.17
(3.04e-01)

Table 6: The mathematical expressions of the whole NN.

Dataset

𝑃0(adult)

𝑃1(analcatdata_aids)

𝑃2(agaricus_lepiota)

𝑃3(breast)

𝑃4(car)

Method
LIME
MAPLE
SRNet
LIME
MAPLE
SRNet
LIME
MAPLE
SRNet
LIME
MAPLE
SRNet
LIME
MAPLE
SRNet

Train
84.47 ± 2.3%
98.47 ± 1.51%
100 ± 0%
85.18 ± 0.11%
93.78 ± 0.23%
91.89 ± 8.11%
88.28 ± 0.16%
99.22 ± 0.04%
75.82 ± 0%
100 ± 0%
100 ± 0%
100 ± 0%
100 ± 0%
100 ± 0%
100 ± 0%

Test
71.33 ± 1.78%
92.11 ± 0.80%
100 ± 0%
90.89 ± 0.62%
100 ± 0%
100 ± 0%
93.81 ± 0.30%
98.16 ± 0.12%
75.60 ± 0%
100 ± 0%
100 ± 0%
100 ± 0%
100 ± 0%
100 ± 0%
100 ± 0%

Table 7: LIME vs MAPLE vs SRNet.

Figure 11: LIME vs MAPLE vs SRNet on 𝑃2 decision bound-
ary.

1000 points sampled by USDB very sparse in the high-dimensional
space. However, SRNet still shows better or competitive accuracy
in the other four classification tasks than LIME and MAPLE.

Although LIME and MAPLE have good performance in explain-
ing local classification samples, their decision boundaries cannot
approximate the MLP’s decision boundary. The reason is that they
only leverage a linear model to explain several local samples, as
shown in red lines and purple lines in Figure 11. So, once the MLP’s
decision boundary is a complex curve at some local samples, the line
generated by LIME or MAPLE cannot approximate it. In contrast,
SRNet can approximate the complex decision boundary of MLP on
all samples. Therefore, SRNet is more suitable for explaining NN
on the classification task than LIME and MAPLE.

Figure 10: MNNCGP-ES convergence curve.

Semantics Evaluation. Table 5 lists a mathematical expres-
5.2.2
sion of each NN layer obtained by SRNet for the two classification
tasks, 𝑃0 (adult) and 𝑃2 (agaricus_lepiota). Moreover, Table 6 shows
the final mathematical expressions obtained by SRNet. For the adult
dataset, the two mathematical expressions, 𝑃𝑟 0 and 𝑃𝑟 1, represent
the prediction probability of SRNet for class 0 (adult makes over
$50K a year) and class 1 (adult makes below $50k a year), respec-
tively. Moreover, 𝑃𝑟 0 and 𝑃𝑟 1 indicate that the classification results
only depends on the three features, 𝑥6 (relationship), 𝑥7 (race), and
𝑥9 (capital-gain). In addition, they provide a mathematical explana-
tion of how the trained NN classifies data. For the agaricus_lepiota
dataset, SRNet gives a simple linear model as the explanation of the
classification NN, as shown in 𝑃2 in Table 6. According to 𝑃𝑟 0 and
𝑃𝑟 1, the classification NN mainly focused on the four features, 𝑥10
(stalk-root), 𝑥20 (population), 𝑥8 (gill-color) and 𝑥9 (stalk-shape). In
this case, SRNet degenerates into a simple linear model. So, when
SRNet explains a NN on the classification task, it not only shows
how the NN computes on the dataset, but also represents which
features (variables) the NN focuses on.

Dataset

𝑃0

𝑃2

𝒉𝒔
(𝒙)
0
−𝑥6 + 𝑥7 + 𝑥9
(1.58e-02)
−𝑥10 − 𝑥20 + 𝑥8 + 𝑥9
(2.08e-02)

(𝒉𝒔
𝒉𝒔
)
0
1
(ℎ𝑠
0)85
(3.09e-04)
(ℎ𝑠
0)63
(5.58e-03)

𝒉𝒔
2

(𝒉𝒔
1

)

-

-

𝒚𝒔
(ℎ𝑠
1)41
(ℎ𝑠
1)31
(0.0)
(ℎ𝑠
1)33
(2.91e-01)

Table 5: The mathematical expression of each layer in NNs.

5.2.3 performance comparison. Table 7 lists their average (+ std)
prediction accuracy on the train and test dataset. Interestingly,
SRNet is better than LIME and MAPLE on most classification tasks
and only fails on the ’agaricus_lepiota’ (𝑃2) task. The fail reason
is that the dataset ’agaricus_lepiota’ has 22 input features, making

0250050001.0360.5180.000P00250050001.4050.7020.000P2Exploring Hidden Semantics in Neural Networks with Symbolic Regression

Conference’22, ,

[21] Julian F. Miller and Peter Thomson. 2000. Cartesian Genetic Programming. In
Genetic Programming. Springer Berlin Heidelberg, Berlin, Heidelberg, 121–132.
[22] Anh Nguyen, Jason Yosinski, and Jeff Clune. 2015. Deep neural networks are easily
fooled: High confidence predictions for unrecognizable images. In Proceedings of
the IEEE conference on computer vision and pattern recognition. 427–436.

[23] Patryk Orzechowski, William La Cava, and Jason H Moore. 2018. Where are
we now? A large benchmark study of recent symbolic regression methods. In
Proceedings of the Genetic and Evolutionary Computation Conference. 1183–1190.
[24] Gregory Plumb, Denali Molitor, and Ameet Talwalkar. 2018. Model agnostic

supervised local explanations. arXiv preprint arXiv:1807.02910 (2018).

[25] Ingo Rechenberg. 1978. Evolutionsstrategien. In Simulationsmethoden in der

Medizin und Biologie. Springer, 83–114.

[26] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. 2015. Faster r-cnn:
Towards real-time object detection with region proposal networks. Advances in
neural information processing systems 28 (2015), 91–99.

[27] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. " Why should i
trust you?" Explaining the predictions of any classifier. In Proceedings of the 22nd
ACM SIGKDD international conference on knowledge discovery and data mining.
1135–1144.

[28] Victor S Ryaben’kii and Semyon V Tsynkov. 2006. A theoretical introduction to

numerical analysis. Chapman and Hall/CRC.

[29] Wojciech Samek and Klaus-Robert Müller. 2019. Towards explainable artificial
In Explainable AI: interpreting, explaining and visualizing deep

intelligence.
learning. Springer, 5–22.

[30] Michael Schmidt and Hod Lipson. 2009. Distilling Free-Form Natural Laws from

Experimental Data. Science 324, 5923 (2009), 81–85.

[31] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
Ian Goodfellow, and Rob Fergus. 2013. Intriguing properties of neural networks.
arXiv preprint arXiv:1312.6199 (2013).

[32] Silviu-Marian Udrescu and Max Tegmark. 2020. AI Feynman: A physics-inspired
method for symbolic regression. Science Advances 6, 16 (2020), eaay2631.
[33] James Alfred Walker, Julian Francis Miller, and Rachel Cavill. 2006. A multi-
chromosome approach to standard and embedded cartesian genetic programming.
In Proceedings of the 8th annual conference on Genetic and evolutionary computa-
tion. 903–910.

[34] James Alfred Walker, Julian F. Miller, Paul Kaufmann, and Marco Platzner. 2011.
Problem Decomposition in Cartesian Genetic Programming. Springer Berlin Hei-
delberg, Berlin, Heidelberg, 35–99. https://doi.org/10.1007/978-3-642-17310-3_3
[35] Yu Zhang, Peter Tiňo, Aleš Leonardis, and Ke Tang. 2020. A survey on neural

network interpretability. arXiv preprint arXiv:2012.14261 (2020).

6 CONCLUSION
This paper proposes a new evolutionary algorithm called SRNet to
address the NN’s black box problem. SRNet leverages MNNCGP-
ES to find the mathematical expressions that can represent each
NN layer’s hidden semantics. The combination of every layer’s
expression represents the whole NN. Compared with the models
found by LIME and MAPLE, the mathematical expression provided
by SRNet is closer to the NNs in the interpolated domain. The
experiment also shows the SRNet models trend to approximate the
real data model that used trains NN. The close alignment of SRNet
with the real model and its explicit mathematical expression can
be used to facilitate the explanation of NN prediction behaviours,
such as regression and classification.

REFERENCES
[1] Francesco Bodria, Fosca Giannotti, Riccardo Guidotti, Francesca Naretto, Dino Pe-
dreschi, and Salvatore Rinzivillo. 2021. Benchmarking and survey of explanation
methods for black box models. arXiv preprint arXiv:2102.13076 (2021).

[2] Markus F Brameier and Wolfgang Banzhaf. 2007. Linear genetic programming.

Springer Science & Business Media.

[3] Shan Carter, Zan Armstrong, Ludwig Schubert, Ian Johnson, and Chris Olah.

2019. Exploring neural networks with activation atlases. Distill. (2019).

[4] Flor A Castillo, Carlos M Villa, and Arthur K Kordon. 2013. Symbolic Regres-
In Genetic

sion Model Comparison Approach Using Transmitted Variation.
Programming Theory and Practice X. Springer, 139–154.

[5] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert:
Pre-training of deep bidirectional transformers for language understanding. arXiv
preprint arXiv:1810.04805 (2018).

[6] Benjamin P Evans, Bing Xue, and Mengjie Zhang. 2019. What’s inside the black-
box? a genetic programming method for interpreting complex machine learning
models. In Proceedings of the Genetic and Evolutionary Computation Conference.
1012–1020.

[7] Alhussein Fawzi, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard, and Stefano
Soatto. 2018. Empirical study of the topology and geometry of deep networks. In
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.
3762–3770.

[8] Candida Ferreira. 2001. Gene expression programming: a new adaptive algorithm

for solving problems. arXiv preprint cs/0102027 (2001).

[9] Leonardo Augusto Ferreira, Frederico Gadelha Guimarães, and Rodrigo Silva.
2020. Applying genetic programming to improve interpretability in machine
learning models. In 2020 IEEE Congress on Evolutionary Computation (CEC). IEEE,
1–8.

[10] Ruth Fong and Andrea Vedaldi. 2018. Net2vec: Quantifying and explaining how
concepts are encoded by filters in deep neural networks. In Proceedings of the
IEEE conference on computer vision and pattern recognition. 8730–8738.

[11] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep learning. MIT

press.

[12] Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Franco Turini, Fosca
Giannotti, and Dino Pedreschi. 2018. A survey of methods for explaining black
box models. ACM computing surveys (CSUR) 51, 5 (2018), 1–42.

[13] Thomas Jansen. 2013. Analyzing evolutionary algorithms: The computer science

perspective. Springer Science & Business Media.

[14] John R Koza. 1992. Genetic Programming II, Automatic Discovery of Reusable

Subprograms. MIT Press, Cambridge, MA.

[15] Yu Li, Lizhong Ding, and Xin Gao. 2018. On the decision boundary of deep neural

networks. arXiv preprint arXiv:1808.05385 (2018).

[16] Dong C Liu and Jorge Nocedal. 1989. On the limited memory BFGS method for
large scale optimization. Mathematical programming 45, 1 (1989), 503–528.
[17] Aravindh Mahendran and Andrea Vedaldi. 2015. Understanding deep image rep-
resentations by inverting them. In Proceedings of the IEEE conference on computer
vision and pattern recognition. 5188–5196.

[18] James McDermott, David R White, Sean Luke, Luca Manzoni, Mauro Castelli,
Leonardo Vanneschi, Wojciech Jaskowski, Krzysztof Krawiec, Robin Harper,
Kenneth De Jong, et al. 2012. Genetic programming needs better benchmarks. In
Proceedings of the 14th annual conference on Genetic and evolutionary computation.
791–798.

[19] Julian Francis Miller. 2019. Cartesian genetic programming: its status and future.

Genetic Programming and Evolvable Machines (Aug. 2019), 1–40.

[20] Julian Francis Miller and Simon L. Harding. 2008. Cartesian Genetic Program-
ming. In Proceedings of the 10th Annual Conference Companion on Genetic and
Evolutionary Computation (GECCO ’08). ACM, New York, NY, USA, 2701–2726.

