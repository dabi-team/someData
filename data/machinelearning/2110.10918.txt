Deep Learning Model of Dock by Dock Process 

Significantly Accelerate the Process of Docking-based 

Virtual Screening 

Wei Ma1† , Qin Xie1,2† , Jianhang Zhang2, Shiliang Li1, Youjun Xu2,3 , Xiaobing 
Deng3 and Weilin Zhang2* 
1. Shanghai Key Laboratory of New Drug Design, State Key Laboratory of Bioreactor Engineering, 

School of Pharmacy, East China University of Science and Technology, Shanghai 200237, China 

2. Infinite Intelligence Pharma, Beijing 100083, China 

3. College of Chemistry and Molecular Engineering, Peking University,Beijing 100871, China 

† Equal contribution 

Abstract 

Docking-based virtual screening (VS process) selects ligands with potential 

pharmacological  activities  from  millions  of  molecules  using  computational 

docking  methods,  which  greatly  could  reduce  the  number  of  compounds  for 

experimental screening,  shorten the research period and save the research cost. 

Howerver, a majority of compouds with low docking scores could waste most of 

the  computational  resources.  Herein,  we  report  a  novel  and  practical  docking-

based machine learning method called MLDDM (Machince Learning Docking-

by-Docking Models). It is composed of a regression model and a classification 

model that simulates a classical docking by docking protocol ususally applied in 

many  virtual  screening  projects.  MLDDM  could  quickly  eliminate  compounds 

with low docking scores and the retained compounds with potential high docking 

scores would be examined for further real docking program. We demonstrated that 

MLDDM has a good ability to identify active compounds in the case studies for 

10  specific  protein  targets.  Compared  to  pure  docking  by  docking  based  VS 

protocol,  the  VS  process  with  MLDDM  can  achieve  an  over  120  times  speed 

increment  on  average  and  the  consistency  rate  with  corresponding  docking  by 

docking VS protocol is above 0.8. Therefore, it would be promising to be used for 

examing ultra-large compound libraries in the current big data era.

1.Introduction 

Drug discovery is a costly, complex, and time-consuming process. According 

to relevant statistics, the cost for development of drugs approved from 2009 to 

2018 raised from $300 million to $2.8 billion, depending on different diseases and 
methods.1 Computer-aided drug design (CADD) can significantly accelerate the 

process  of  drug  discovery. Virtual  Screening  (VS  process)  as  a  typical  CADD 

technique  has  been  widely  applied  in  the  early  stage  of  drug  discovery  for 

accelerating 

lead  discovery.2  Docking-based  virtual  screening  aims 

to 

computationally place and evaluate small molecule compounds one by one at the 

binding  site  of  a  target  protein  with  three  dimensional  structure.  After 

continuously  optimizing  the  poses  of  the  compounds,  molecular  docking 

explicitly recommend possible potential compounds with high docking scores. 

Currently,  there  are  many  protein-small  molecule  docking  programs 

available.  A  summary  of  them  is  listed  in  Supplimentary  (Supp  Table  S1), 
including their release years, release organizations, descriptions, and licenses3-19. 

Since the forms of scoring functions and the sampling methods they used are quite 

divergent,  for  certain  system  different  docking  program  would  yield  variant 

docking results. Applying multiple docking programs sequentially in VS process 

is quite usual in many publications which is drawn as a well-known funnel like 
workflow. 20-31 In such docking by docking protocol, the first docking process used 

in this workflow could be the one with very fast screening speed and the second 

could be more accurate by somehow slowly. Therefore, the balance between speed 

and quality of the final result are achieved.  

Recently, it has been reported that docking based VS process on ultra-large 
databases  can  significantly  increase  the  success  rate  of  finding  active  hits.32 

Meanwhile  the  sizes  of  compound  databases  also  increased  significantly.  For 

example, the widely used ZINC database, has exceeded 1.3 billion in 2019 from 
700 thousand in 2005.33-35 Marco Capuccini et al36 carried out VS process on a 

large-scale compounds library by running existing docking programs on parallel 

distributed cloud computational resources. This parallel strategy was based on the 

Apache Spark engine and achieved an overall efficiency of 87%. 

However, only a small proportion of the compounds will have high docking 

scores, and most of the computational time was  wasted on the vast majority  of 

‘low-scoring’  compounds.  Even  the  improvement  of  computational  resources 

make it possible to perform VS process on an ultra-large compound library, it is 

desireable  to  identify  high-score  compounds  using  reliable  machine  learning 

filters in advance as the computational time and resources on docking could be 

significantly reduced. 

P. B. Jayaraj et al37 developed a classification model based on random forest 

and applied this model to VS process. It can realize accelerated calculations on 

GPU,  which  significantly  reduce  the  running  time  of  the  entire  process  of VS 
process.  Francesco  Gentile  et  al38  reported  the  application  of  a  deep  learning 

framework  to  train  classification  models  on  the  docking  scores  of  a  subset  of 

compounds, then the model was used to predict compounds that have not been 

docked. Their method realized rapid VS process on a billion compounds library—

ZINC-15, which greatly reduced the computational cost of VS on an ultra-large 

compounds library with an acceptable recall rate.  

It would be promising to examine whether a workflow by two tandem models 

could mimic the above docking by docking protocol and applied for the scenairo 

when the absolute number of compounds to be examined increased in one or two 

orders.  In  this  paper,  we  setup  such  a  machine  learning  model:  MLDDM 

(Machince Learning Docking-by-Docking Models), by training on two docking 

programs' results. With comprehensive evaluation of the method, MLDDM was 

proved to have a good ability to identify known active compounds on 10 specific 

protein targets. Further evaluation on protein target BRAF showed that the speed 

of the protocol could gain 120 times increment on average. These results show 

that MLDDM can quickly filter out compounds with low docking scores with high 

confidence. It is believed to be a good and practical filter in daily docking based 

virtual screening protocols with ultra large libraries. 

2.Methods and Dataset  

2.1 Model Construction and Usage 

 
 
 
Figure 1: The workflow of MLDDM construction and usage. 

The framework of the MLDDM model construction and usage is illustrated 

in  Figure  1.  For  certain  protein  Target,  two  supervised  training  processes  are 

implemented.  For  the  first  training  process,  the  compounds  from  the  training 

library (N compounds) were docked into given target. Dock-1 was used as the first 

docking  program,  all  the  docking  results  are  perserved  as  the  first  training  set 

(Training Set1) for this target. The compounds with docking score ranking in the 

top  20%  from  first  docking  were  selected  for  second  docking  process  and  the 

docking results from this setup are used as the second training set for this target 

(Training  Set2).  We  then  labeled  these  training  sets  acccoding  to  the  docking 

results.  For  the  second  regression  task,  the  rank  percentage  values  of  the 

compounds  in  Training  Set1  are  calculated  were  used  as  labels.  For  the 

classification task, the top 20% ranked compounds within the Training Set2 were 

selected as the positive samples and the rest compounds were used as the negative 

samples.The regression model and the classification model were trained seperately. 

After evaluation of the models, they could be used for ultra-large library filtering. 

When doing ultra-large library filtering, the regression model are used first which 

mimics the first step of docking by docking protocol and the high ranking score 

compounds are selected for the second prediction. The compounds with a positive 

 
 
sign suggested by the classification model could be used for further examination. 

2.2 Programs and parameter settings for molecular docking 

Two open-source and freely available docking programs, namely Vina39 and 
rDock16, were selected for multiple docking VS process in this research. Vina is a 

molecular docking program based on an experience scoring function developed 

by the MGL Tools laboratory. Compare with AutoDock 4.0, Vina improves the 

average  accuracy  of  combined  mode  prediction,  greatly  accelerates  the  search 

speed  by  using  a simpler  scoring  function  and  can  still  provide reproducibility 

when dealing with a system with about 20 rotatable bonds. rDock is a fast and 

versatile Open Source docking program that can be used to dock small molecules 

against  proteins  and  nucleic  acids.  Both  of  the  programs  can  be  installed  on  a 

computation cluster server and deployed on an almost unlimited number of CPUs, 

allowing HTVS process campaigns to be carried out in a matter of days. 

In our cases, the protein structures were pre-processed using ADTools, and 
the small molecules were prepared using openbabel.40 For parameters used in vina, 

the grid center was defined as the native ligand center in the crystal structure, a 

cubic grid was used with dimension (20,20,20). For rDock, the rbcavity program 

are  used  to  determine  a  grid  parameter  from  the  navtive  ligand  with  default 

parameters.  Vina  was  selected  as  the  first  docking  program  (Docking-1)  and 

rDock was selected as the second docking program (Docking-2). Both docking 

results  of  Docking-1  and  Docking-2  were  saved  as  csv  files  (Supplementary 

materials 5). 

2.3 Deep learning models 

A  open  souce  toolkit,  Chemprop  (http://github.com/chemprop/chemprop), 

which  is  a  deep  learning  based  molecular  property  modeling  and  prediction 
toolkit,41 was used to develop our docking-based machine learning models. The 

architecture of Chemprop is based on graph convolutional networks, termed as the 

Directed Message Passing Neural Network (D-MPNN), which treats molecules as 

an  attributed  graph  with  node  features  (atom)  and  edge  features  (bond)  for 

processing. D-MPNN was used to train regression and classification models with 

basic  RDkit  molecular  descriptors.  The  default  hyperparameters  of  Chemprop 

were  used 

for  model 

training.  Besides, 

the  setting  parameters  of 

rdkit_2d_normalized and no_features_scaling are added to the training process to 

improve the stability of the models. 

Both the regression and the classification models were trained on 80% of the 

random split set and then validated and tested on the remaining 20% of the datasets. 

The hyperparameters of the D-MPNN, such as hidden_size, depth, dropout, and 

ffn_num_layers  were  optimized  by  10-fold  cross  validation.  The  optimal 

hyperparameters were used to construct the VS-based models. The construction 

of these models were implemented with Pytorch and RDkit packages. 

2.4 Datasets and their usages 

In this study, several datasets were used for different purposes. Firstly, for the 

compoud library to be docked into each target, a ChemDiv (ChemDiv Inc) library 

with  1.25  million  purchasable  compounds  were  clustered  with  a  tanimoto 

similarity threshold 0.4 to obtain a clustered subset of 287,216 compounds (named 

as  ChemDiv  subset,  and  the  SMILES  file  of  the  compounds  are  available  in 

Supplementary materials 2). Secondly, the description of target proteins used to 

build  the  MLDDMs  are  listed  in  Table  1. The  nubmer  of  their  experimentally 

validated active compounds as well as decoy compounds selected from the DUD-
E  database42  are  also  listed  here.  They  are  used  to  act  as  validation  sets  for 

MLDDM's  valibility. All  these  compounds  were  docked  with  two  programs  to 

corresponding targets and not used in the training process. (Their smiles strings 

are  list  in  Supplementary  materials  3).  Thirdly,  we  tested  MLDDM's 

performance  in  Expanded  prediciton  stage  by  constructing  two  datasets.  For 

evalution of those regression models, a relative small dataset are constructed by a 

subset of 500,000 compounds randomly selected from the ChEMBL database to 

allievate the actual docking load while keeping the generality of the result. (Their 

smiles strings are listed in Supplementary materials 4) The consistency of the 

regression model will be evaluated. For evaluation of those classification modes, 

for each targets, the compounds from the ChEMBL database are labeld as active 

or 

inactive  depends  on  whether 

their  IC50s  are 

less 

than  50μM  or 

not.(Supplementary  materials  5).  The  whole  ChEMBL  database  (about  19M 

molecules) were predicted by the regression model, and those passed this filter 

will  be  used  as  the  input  to  the  classifcation  model.  The  number  of  active 

 
compounds  are  evaluated.  Finally,  ZINC-15  dataset  was  used  to  illustrate  the 

speed of MLDDM on a large dataset for target BARF as example. 

Table1: Detailed information of the selected targets (from DUD-E) and their 

active/decoy compounds numbers 

Num 

Target 

PDB-ID 

Type 

Actives 

Decoys 

1 

2 

3 

4 

5 

6 

7 

8 

9 

ACE 

ADRB1 

BRAF 

CDK2 

DRD3 

DPP4 

EGFR 

JAK2 

LCK 

10 

VGFR2 

3BKL 

4BVN 

3D4Q 

1H00 

3PBL 

2I78 

2RGP 

3LPB 

2OF2 

2P2I 

Protease 

GPCR 

Kinase 

Kinase 

GPCR 

808 

458 

251 

798 

877 

Protease 

1079 

Kinase 

Kinase 

Kinase 

Kinase 

832 

153 

683 

620 

17144 

15958 

10098 

28328 

34188 

41373 

35442 

6590 

27856 

25280 

3.Results and discussion 

3.1 Model construction of MLDDM 

To reflect the consistency of the model’s performance and its generalizability, 

we  summerized  the  the  training  statistical  metrics  of  those  models  for  the  10 

selected targets in Figure S1. The AUC and RMSE on the internal test sets of the 

D-MPNN models for each target are presented in Table 2. For those regression 

models, the RMSE values ranges from 0.14 to 0.11, illustrating an acceptable error 

in ranking percentage prediction. For those classification models, the AUC values 

ranges from 0.89 to 0.96, indicating a good ability to distinguish between positive 

data  (top  20%  ranked  compounds  by  Dock-2)  and  negative  data  (the  rest 

compounds by Dock-2). 

Table 2: Performance on of D-MPNN regression and classification models 
based on the ChemDIV subset against 10 protein targets. 

 
 
Target 

ACE 

ADRB1 

BRAF 

CDK2 

DRD3 

DPP4 

EGFR 

JAK2 

LCK 

VGFR2 

Regression RMSE 

Classification AUC 

0.1237+/-0.0008 

0.1210+/-0.0008 

0.1323+/-0.0007 

0.1177±0.0009 

0.1118+/-0.0010 

0.1210+/-0.0006 

0.1235+/-0.0006 

0.1340+/-0.0007 

0.1220+/-0.0008 

0.1425+/-0.0005 

0.9601+/-0.0030 

0.9478+/-0.0043 

0.9473+/-0.0047 

0.9448+/-0.0028 

0.9478+/-0.0037 

0.9257+/-0.0027 

0.9611+/-0.0035 

0.9124+/-0.0039 

0.9604+/-0.0014 

0.9556+/-0.0071 

3.2 Evaluations of regression models  

3.2.1 Regression model evaluation on DUD-E dataset 

Considering  there  may  be  some  topology  bias  in  DUD-E,  we  do  not 

intentionally  incorporate  compounds  into  training  set  and  use  it  as  one-time 
validation only.43Since the DUD-E dataset also used in succed classifcation model 

We  labeled  these  as  follows:  DUD-E  actives/decoys  were  docked  by  vina  and 

compounds with docking score above the top 20% percentile of the Training-Set-

1  were  selected.  The  number  of  compounds  selected  were  compared  with  the 

number  of  compounds  that  selected  by  the  regression  model.  Next,  these dock 

selected compounds were used for the classification model in 3.3.1. The results 

are listed in Table 3.It is shown that among the 10 targets, except for those of ACE, 

the  consistency  rates  between  the  docking  regression  and  MLVS  classification 

were 75.0%, with the highest consistency rate of 98% for the CDK2. This suggests 

that the regression model from MLDDM achieved an acceptable performance as 

corresponding docking methods.  

Table 3: Performance of MLDDM regression models and docking results on 
DUD-E compounds 

Model 

Compounds 

Number of compounds Selected 
by Dock-1 top20%  

Number of compounds 
Selected by MLDDM 
Regression1 

Consistency rate3 

ACE 

ADRB1 

BRAF 

actives 

decoys 

Actives 

decoys 

actives 

decoys 

55 

745 

60 

679 

98 

949 

31 

643 

51 

575 

88 

779 

56.4% 

86.3% 

85.0% 

84.7% 

89.8% 

82.1% 

CDK2 

DRD3 

DPP4 

EGFR 

JAK2 

LCK 

VGFR2 

actives 

decoys 

actives 

decoys 

actives 

decoys 

actives 

decoys 

actives 

decoys 

actives 

decoys 

actives 

decoys 

245 

1341 

170 

1437 

84 

1500 

225 

2788 

34 

395 

291 

2096 

158 

1312 

240 

1091 

136 

1214 

66 

1190 

216 

2308 

26 

302 

253 

1737 

120 

1086 

98.0% 

81.4% 

80.0% 

84.5% 

78.6% 

79.3% 

96.0% 

82.8% 

76.5% 

76.5% 

86.9% 

82.9% 

76.0% 

82.8% 

1. Consistency rate equals the Number of compounds Selected by MLDDM Regression over 

Number of compounds Selected by Dock-1 top20% 

3.2.2 Regression model evaluation on the ChEMBL subset 

We used regression models in MLDDM to predict the ranking percentage of 

the compoounds in the ChEMBL subset. The compounds with top 20% percentage 

ranking prediction were further docked to their targets using Vina to test their real 

distribution.  

Figure 3 shows the superposition of the vina docking score distributions from 

four representative tagets as examples. The figures for other 6 targets are shown 

in  Figure  S2.  The  vina  docking  score  from  those  selected  compounds  from 

ChEMBL subset, the whole ChemDiv dataset and the top 20% scored ChemDiv 

compounds are illustrated as follows:   

 
Figure 3: Vina docking score distribution for D-MPNN regression model selected 
ChEMBL compounds and ChemDiv compounds for a) BARF b) LCK c) VGFR2 and d) 
DPP4. 

the yellow bins represent the Vina docking score distribution for ChemDiv, the blue bins 
represent the top 20% of them, and the red bins represent the vina score distribution 
from the regression model prediction results of the selected ChEMBL subset 
compounds. 

In Figure 3, we can see that most of the selected ChEMBL compounds were 
located in the top20% docked ChemDiv compounds region. This suggests that the 
our  regression  models  have  a  strong  ability  to  enrich  compounds  with  a  high 
docking score, therefore, the models can distinguish compounds with potentially 
high docking scores for specific targets in a quickly manner without docking. 

3.3 Evaluation of classification models on the DUD-E sets  

In  section  3.2.1,  previously  docked  DUD-E  actives/decoys  by  vina  and 

selected  compounds  with  docking  score  above  the  top20%  percentile  of  the 

Training  Set1. These  compounds  were  then  docked  by  rDock. The  compounds 

whose rDock docking score is above the top20% percentile of the Training Set2 

was  labeled  as  positive  while  the  rest  of  them  were  labeld  as  negative.  These 

 
 
compounds were further predicted by the classification model from MLDDM. 

Table 4 shows the statistical results of the various metrics of the classification 

model on the DUD-E external data set. The statistical results show that, except for 

the target DPP4, the accuracies of the other 9 targets on the DUD-E external data 

set are above 70%. Except for the targets DPP4 and BRAF, the specificity values 

of the other 8 targets on the DUD-E external data set are above 72%. The false-

positive rates of the targets EGFR, DPP4, and BRAF are overall higher than other 

targets,  24.8%,  46.9%,  and  37.9%,  respectively,  for  the  rest  targets,  the  false-

positive rates are all less than 20%. As for the true positive rate, the maximum and 

minimum  values  were  89.5%  of  BRAF  and  27.5%  of  JAK2.  Obviously,  for 

different targets, the performances of the MLDDM are different here. In general, 

on the external test sets, the models showed a good performance of accuracy and 

specificity. 

Table 4: Statistics of various indicators of the model on external data sets 

Num  Target  Accuracy 

Precision 

Specificity 

FPR 

TPR 

F1-score 

Prevalence 

1 

2 

3 

4 

5 

6 

7 

8 

9 

ACE 

ADRB1 

BRAF 

CDK2 

DRD3 

DPP4 

EGFR 

JAK2 

LCK 

73.9% 

79.9% 

82.8% 

73.3% 

76.0% 

60.4% 

72.9% 

74.3% 

77.5% 

10 

VGFR2 

72.9% 

52.0% 

66.5% 

87.9% 

59.3% 

60.2% 

41.8% 

49.7% 

46.3% 

63.4% 

62.2% 

84.0% 

85.5% 

62.1% 

82.2% 

89.7% 

53.1% 

75.2% 

89.5% 

90.3% 

90.7% 

15.9% 

14.5% 

37.9% 

17.8% 

10.3% 

46.9% 

24.8% 

10.5% 

9.7% 

9.3% 

46.3% 

54.6% 

89.5% 

53.8% 

40.4% 

77.2% 

66.3% 

27.5% 

44.1% 

33.8% 

49.0% 

60.0% 

88.7% 

56.4% 

48.3% 

54.3% 

56.8% 

34.5% 

52.0% 

43.8% 

27.1% 

30.1% 

67.6% 

32.2% 

27.8% 

32.5% 

27.0% 

24.7% 

27.6% 

31.2% 

3.4 Overall performance of MLDDM to retrieve all active compounds 

To further verify whether the model can identify active compounds for specific 
targets after the whole MLDDM process, the active compounds of the 10 targets 
were selected from ChEMBL for verification. The active compounds for 10 targets 
were  filtered  and  considering  a  relative  loose  threshold.  If  a  compound  has  an 
activity of IC50 less than 50μM, it would be kept as a positive sample.  

To  explore  the  models’  ability  of  recalling  actives,  the  whole  19  million 
molecules from the ChEMBL database were predicted with the regression model 
from the correponding MLDDM and the compounds which passed the top20% 
percentile of the training set were selected to make the second prediction. After 
using the classification model, we count the number of activies recalled. 

In Table 5, it shows the percentage of recalled compounds in the total positive 

 
sample with the different activity cutoff. The statistical results showed that most 
of the models can identify over 50% of active compounds for specific targets, for 
example,  the  proportions  of ADRB1,  BRAF,  EGFR,  JAK2,  LCK,  and VGFR2 
were 65.78%, 79.30%, 68.63%, 51.88%, 74.61%, 52.72%, respectively. That is to 
say,  for  most  targets,  the  potential  active  compounds  could  be  recalled  by  our 
models.  

Table 5: Active compounds prediction statistics of the model 

Threshold of active compounds from ChEMBL (IC50) 

Target 

<50nM 

<100nM 

<200nM 

<500nM 

<1μM 

<10μM 

<20μM 

<50μM 

ACE 

30.00% 

31.56% 

32.73% 

34.46% 

33.42% 

32.35% 

31.83% 

31.10% 

ADRB1 

44.62% 

55.81% 

60.68% 

62.89% 

64.44% 

66.81% 

65.34% 

65.78% 

BRAF 

CDK2 

DPP4 

DRD3 

EGFR 

JAK2 

LCK 

79.01% 

79.18% 

79.37% 

79.26% 

79.14% 

79.23% 

79.32% 

79.30%  

23.29% 

23.08% 

23.34% 

24.22% 

24.35% 

29.41% 

29.41% 

28.80% 

34.81% 

34.64% 

34.24% 

33.12% 

32.55% 

32.18% 

32.34% 

32.34% 

28.97% 

29.45% 

33.51% 

35.68% 

38.91% 

42.17% 

42.04% 

42.43% 

74.45% 

74.30% 

73.17% 

72.46% 

69.84% 

68.88% 

68.96% 

68.63% 

55.95% 

55.03% 

53.59% 

52.39% 

51.97% 

51.78% 

51.82% 

51.88% 

77.97% 

78.19% 

78.94% 

78.31% 

77.74% 

74.77% 

74.66% 

74.61% 

VGFR2 

36.53% 

40.93% 

43.62% 

46.96% 

48.65% 

52.58% 

52.59% 

52.72% 

To  test  the  generalization  of  our  framework,  we  used  the  MLDDM  trained 
from  current  chemDiv  training  set  and  calculated  EF0.04  on  ChEMBL. As  the 
current MLDDM would retrieve top4% (0.2 x 0.2 =0.04) of the training set, the 
enrichment facotr EF0.04 could be calculated and evaluated.  

The summarized results of the enrichment factors for 10 targets are listed in 
Table 6. From this table, the enrichment factors against 10 targets range from the 
lowest  5.86  (CDK2)  to  the  highest  17.03  (ADRB1).  However,  the  predictive 
ability of the model does not show a strong correlation with activity, which may 
be related to the way our training datasets were acquired.  

Target 

ACE 

ADRB1 

BRAF 

CDK2 

DPP4 

DRD3 

EGFR 

LCK 

JAK2 

VGFR2 

Table 6: Enrichment factor statistics of 10 targets 
True positive 
Actives 

Recall Comps 

Total 

553 

529 

5222 

1684 

3779 

337 

8232 

1713 

5181 

9329 

1941964 

1941940 

1946633 

1943095 

1945190 

1941748 

1949643 

1943124 

1946592 

1950740 

72638 

74995 

94479 

95447 

87247 

85286 

134286 

93253 

108679 

71504 

172 

348 

4141 

485 

1222 

143 

5650 

1278 

2688 

4918 

EF4% 

8.32 

17.03 

16.34 

5.86 

7.21 

9.66 

9.96 

15.55 

9.29 

14.38 

 
 
3.3 Computation speed comparison 

To  demonstrate the  advantage of our MLDDM  models in speed, the target 
BRAF was selected as an example of the prediction test. The drug-like molecules 
(containing 981,247,974 compounds) from the ZINC-15 were selected in this case. 

Table 7: Comparison of running time 

Num 
Compounds 
(k) 
5 

Time Cost-
Calculate 
Desciptors (h) 
0.065 

10 

20 

50 

100 

200 

500 

1,000 

2,000 

5,000 

10,000 

20,000 

50,000, 

98,124 

Notes: 

0.111 

0.202 

0.509 

1.101 

2.393 

6.009 

12.111 

24.323 

59.319 

122.851 

254.803 

638.009 

1249.044 

Time Cost-
Prediction (h) 

0.005 

0.009 

0.018 

0.041 

0.079 

0.157 

0.391 

0.779 

1.557 

3.891 

7.779 

15.557 

38.891 

77.586 

Estimated 
Time of 
Docking(h)1 
8.20 

16.41 

32.82 

82.04 

164.08 

328.16 

820.40 

1640.80 

3281.60 

8204.00 

16408.00 

32816.00 

82040.25 

Recall 
Compounds 

— 

— 

— 

5 

11 

19 

446 

1143 

2364 

8979 

33305 

111281 

686365 

161002.35 

6213291 

Recall 
Rate 
(%) 
— 

— 

— 

0.001 

0.001 

0.001 

0.009 

0.011 

0.012 

0.018 

0.033 

0.056 

0.130 

0.633 

Times2 

117 

137 

149 

149 

139 

129 

128 

127 

127 

129 

125 

121 

121 

121 

Model prediction computing resource: 10 * CPUs (Xeon Gold 5118 ) +1 * GPU(Tesla V100）; 

Molecular docking computing resources: 20 * CPUs (Xeon E5-2670 V2); 

1.  The docking time is linearly predicted according to the docking speed of 300,000 ChemDiv compounds; 

2. 

Speed improvement based on the above resource allocation; 

The  statistical  results  in  Table  7  show  that  based  on  the  above  available 
computing resources, the prediction speed of the machine learning VS model is 
greatly improved compared to traditional dock by dock process with an average 
speed increament of >120 times. A  large  amount  of time  was  used to calculate  the 
descriptors  with  single-core  CPU  are  included  in  case every  time  a  unique  compound 
library is used. It means that the MLDDM we built here could greatly increase the 
speed  of  dock-by-dock  process.  This  framework  could  quickly  filter  out  low-
scoring compounds against the specific targets, at the same time, the compounds 
with high docking score were recalled quickly. Therefore, the calculation time and 
resources of VS on ultra-large compounds library can be greatly reduced. 

4 Discussion 

To explore the reasonable top threshold in the process of obtaining the training 
dataset,  the  DUD-E  active  compounds  were  selected  to  make  a  statistic  of  the 

relationship between the enrichment ratio of the active compounds and the top value 
of  the  two  docking  programs  for  the  10  selected  targets  respectively. 
Representative results of 4 targets were listed in Figure 4, others are shown in 
Figure S3. The X-axis represents the top value of the compounds sorted by the 
docking  score,  and  the  Y-axis  represents  the  proportion  of  DUD-E  active 
compounds enriched for the corresponding target. The statistical results showed 
that there is a logarithmic growth relationship between enrichment ratio and top 
value, and the enrichment ratio has the maximum profit in the top20% for most of 
the targets. Besides, the active compounds enrichment ability of rDock is better 
than Vina overall. In addition to the target DPP4, the enrichment ratios of active 
compounds  in  the  top20%  compounds  of  the  two  docking  programs  are 
both  >20%.  It  showed  that  the  two  selected  docking  programs  have  a  certain 
ability to enrich active compounds. Thus, top20% was selected for the preparation 
of the training dataset.  

Figure 4: Enrichment ratio of DUD-E active compound for two docking 
programs 

To  further  explore  whether  the  strategy  using  two  docking  programs  and 
adjusting their order can obtain a higher enrichment ratio, the enrichment ratio of 
different combinations of the two docking programs were summarized in Figure 
4. The red curve in Figure 4 represents the enrichment ratio of the corresponding 
target by the rDock program, the blue one represents that of the Vina program, and 
the purple one represents the re-docking of the Top_20% of the compounds using 
the  rDock  after  docking  with  Vina,  accordingly,  the  beige  one  represents  the 
enrichment ratio in the order of rDock first and then Vina. 

 
The  statistical  result  showed  that  for  most  targets,  the  enrichment  ratio  of 
using rDock alone is higher than the other three methods. Besides, choosing to use 
the  Vina  program  for  first  docking  and  then  using  the  rDock  program  for  re-
docking  of  the  top20%  can  make  the  enrichment  ratio  further  improved.  This 
means  that the strategy  of combing two docking programs can get more active 
compounds  in  the  training  dataset  compared  with  using Vina  alone.  Moreover, 
considering  the  speed  and  the  consumption  of  computing  resources  of  the  two 
docking programs, we choose a combination of using Vina for the first step quick 
screening  and  then  using  the  rDock  program  to  run  a  more  precise  multi-
conformations search for re-docking. This strategy ensures that there are enough 
active compounds in the training dataset we obtained while reducing the time to 
obtain the training dataset.  

Due to the avability of the docking software we could access, we only tested 
vina  and  rDock  combination  which  tends  to  be  orthogonal  to  each  other. 
Conceptionally,  this  framework  should  be  general  to  other  docking  programs' 
combination and make it very flexible to accommodate different requirements in 
variant project. 

5. Conclusion 

In the current work, we demonstrated a framework MLDDM which mimics 
the dock-by-dock screening process powered by deep learning. We implemented 
it by utilizing the docking results of certain target on a commercially purchasable 
chemDiv subsets with open access  docking program vina and  rdock as  well as 
deep learning toolkit Chemprop. Various statistical results showed that the models 
could  have  a  good  performance  of  VS  process.  Moreover,  compared  with  the 
traditional dock by dock process, the MLDDM we constructed here can realize 
screening on an ultra-large compounds library, and the speed is over 120 times 
faster. These models can quickly identify molecules with potentially high docking 
scores and filter out molecules with low docking scores, which greatly reducing 
the consumption of computing resources on ultra-large compound library virtual 
screening.  In  addition,  it  is  found  that  the  reasonable  combination  of  the  two 
docking programs can further increase the enrichment ratio of the screening and 
make the obtained training dataset more reliable.  

With  the  applications  of  compound  generative  models  in  the  field  of  drug 
development in  recent  years, it is believed that the models would be used as  a 
rapid  scoring  metric  for  generative  models  to  generate  compounds  with  high 
docking scores for a specific target. 

 
 
References: 

1.  Wouters, O. J.; McKee, M.; Luyten, J. Estimated Research and Development 

Investment Needed to Bring a New Medicine to Market, 2009-2018. JAMA 2020, 

323, 844-853. 

2.  BAN F, D. K., LI H, et al. Best Practices of Computer-Aided Drug Discovery: 

Lessons Learned from the Development of a Preclinical Candidate for Prostate 

Cancer with a New Mechanism of Action. Journal of Chemical Information And 

Modeling 2017, 57, 1018-1028. 

3.  Mateusz;  Kurcinski;  Maciej;  Pawel;  Ciemny;  Tymoteusz;  Oleniecki; 

Aleksander; Kuriata; Aleksandra. CABS-dock standalone: a toolbox for flexible 

protein-peptide docking. Bioinformatics 2019. 

4.  Mateusz, K.; Michal, J.; Maciej, B.; Andrzej, K.; Sebastian, K. CABS-dock 

web  server  for  the  flexible  docking  of  peptides  to  proteins  without  prior 

knowledge of the binding site. Nucleic Acids Research 2015, 419-24. 

5.  Function, I.; Japan, S.; Center, J.; Japan, S.; Biomaterialsbioengineering, I. O.; 

University, M.; Japan, C. K. Identifying the receptor subtype selectivity of retinoid 

X and retinoic acid receptors via quantum mechanics. FEBS Open Bio 2016. 

6.  Grosdidier, A.; Zoete, V.; Michielin, O. EADock: Docking of small molecules 

into protein active sites with a multiobjective evolutionary optimization. Proteins: 

Structure, Function, and Bioinformatics 2007, 67. 

7.  Campagna-Slater, V.;  Pottel,  J.; Therrien,  E.;  Cantin,  L.  D.;  Moitessier,  N. 

Development of a Computational Tool to Rival Experts in the Prediction of Sites 

of  Metabolism  of  Xenobiotics  by  P450s.  Journal  of  Chemical  Information  & 

Modeling 2012, 52, 2471-83. 

8.  Hasup, L.; Lim, H.; Sup, L. M.; Chaok, S. GalaxyPepDock: a protein–peptide 

docking  tool  based  on  interaction  similarity  and  energy  optimization.  Nucleic 

Acids Research 2015, 43, 431-5. 

9.  Shin, W.  H.;  Lee,  G.  R.;  Heo,  L.;  Lee,  H.;  Seok,  C.  Prediction  of  Protein 

Structure and Interaction by GALAXY Protein Modeling Programs. 2014. 

10.  G C P van Zundert, J. P. G. L. M. R., M Trellet, C Schmitz, P L Kastritis, E 

Karaca, A  S  J  Melquiond,  M  van  Dijk,  S  J  De  Vries, A  M  J  J,  Bonvin  The 

HADDOCK2.2  webserver:  User-friendly  integrative  modeling  of  biomolecular 

complexes. J Mol Biol 2015, 428, 720-725. 

11.  Dominguez,  C.;  Boelens,  R.;  Bonvin,  A.  HADDOCK:  a  protein-protein 

docking approach based  on biochemical or biophysical information. Journal of 

the American Chemical Society 2003, 125, 1731-1737. 

12.  Brian, J. G.; Jorge, R. T.; Miguel, R. D.; Miquel, V.; Daniel, J. G.; Juan, F. R. 

LightDock:  a  new  multi-scale  approach 

to  protein–protein  docking. 

Bioinformatics, 1. 

13.  Me  ier,  R.;  Pippel,  M.;  Brandt,  F.;  Sippl,  W.;  Baldauf,  C.  ParaDockS  : A 

Framework  for  Molecular  Docking  with  Population-Based  Metaheuristics. 

Journal of Chemical Information and Modeling 2010, 50, 879-889. 

14.  Pei, J.; Wang, Q.; Liu, Z.; Li, Q.; Yang, K.; Lai, L. PSI-DOCK: towards highly 

efficient and accurate flexible ligand docking. Proteins 2006, 62, 934-46. 

15.  Mcmartin, C.; Bohacek, R. S. QXP: Powerful, rapid computer algorithms for 

structure-based drug design. J Comput Aided Mol Des 1997, 11, 333-344. 

16.  Ruiz-Carmona, S.; Alvarez-Garcia, D.; Foloppe, N.; Garmendia-Doval, A. B.; 

Juhos, S.; Schmidtke, P.; Barril, X.; Hubbard, R. E.; Morley, S. D. rDock: a fast, 

versatile  and  open  source  program  for  docking  ligands  to  proteins  and  nucleic 

acids. PLOS Computational Biology 2014, 10, e1003571-e1003578. 

17.  Morley,  S.  D.; Afshar,  M.  Validation  of  an  empirical  RNA-ligand  scoring 

function  for  fast  flexible  docking  using  RiboDock.  Journal  of  computer-aided 

molecular design 2004, 18, 189. 

18.  N Majeux, M. S., J Apostolakis, C Ehrhardt, A Caflisch. Exhaustive docking 

of  molecular  fragments  on  protein  binding  sites  with  electrostatic  solvation. 

Proteins: Structure. Function and Genetics 1999, 37, 88-105. 

19.  DR Koes, M. B., CJ Camacho. Lessons Learned in Empirical Scoring with 

smina from the CSAR 2011 Benchmarking Exercise. J Chem Inf Model 2011, 53, 

1893-1904. 

20.  Onawole, A. T.;  Kolapo, T. U.; Sulaiman, K. O.; Adegoke, R. O. Structure 

based virtual screening of the Ebola virus trimeric glycoprotein using consensus 

scoring. Comput Biol Chem 2018, 72, 170-180. 

21.  Feher,  M.  Consensus  scoring  for  protein-ligand  interactions.  Drug  Discov 

Today 2006, 11, 421-8. 

22.  Mavrogeni‡,  M.  E. A  facile  consensus  ranking  approach  enhances  virtual 

screening robustness and identifies a cell-active DYRK1α inhibitor. FutureMed. 

Chem 2018, 10, 2411–2430. 

23.  Houston,  D.  R.;  Walkinshaw,  M.  D.  Consensus  docking:  improving  the 

reliability of docking in a virtual screening context. J Chem Inf Model 2013, 53, 

384-90. 

24.  Berenger,  F.;  Vu,  O.;  Meiler,  J.  Consensus  queries  in  ligand-based  virtual 

screening experiments. J Cheminform 2017, 9, 60. 

25.  Masters, L.; Eagon, S.; Heying, M. Evaluation of consensus scoring methods 

for AutoDock Vina, smina and idock. J Mol Graph Model 2020, 96, 107532. 

26.  Onawole, A. T.; Sulaiman, K. O.; Adegoke, R. O.; Kolapo, T. U. Identification 

of potential inhibitors against the Zika virus using consensus scoring. J Mol Graph 

Model 2017, 73, 54-61. 

27.  Wang,  R.  x.  How  Does  Consensus  Scoring  Work  for  Virtual  Library 

Screening? An Idealized Computer Experiment. J. Chem. Inf. Comput. Sci 2001, 

41, 1422-1426. 

28.  Yang, J. M.; Chen, Y. F.; Shen, T. W.; Kristal, B. S.; Hsu, D. F. Consensus 

scoring criteria for improving enrichment in virtual screening. J Chem Inf Model 

2005, 45, 1134-46. 

29.  Clark,  R.  D.;  Strizhev,  A.;  Leonard,  J.  M.;  Blake,  J.  F.;  Matthew,  J.  B. 

Consensus scoring for ligand/protein interactions. J Mol Graph Model 2002, 20, 

281-95. 

30.  Liu, S.; Fu, R.; Zhou, L. H.; Chen, S. P. Application of consensus scoring and 

principal component analysis for virtual screening against beta-secretase (BACE-

1). PLoS One 2012, 7, e38086. 

31.  Paul, N.; Rognan, D. ConsDock: A new program for the consensus analysis 

of protein-ligand interactions. Proteins 2002, 47, 521-33. 

32.  GORGULLA  C,  B. A.,  WANG  Z  F,  et  al. An  open-source  drug  discovery 

platform enables ultra-large virtual screens. Nature 2020, 580, 663-668. 

33.  Sterling, T.; Irwin, J. J. ZINC 15--Ligand Discovery for Everyone. Journal of 

Chemical Information And Modeling 2015, 55, 2324-37. 

34.  Irwin, J. J. ZINC – A Free Database of Commercially Available Compounds 

for Virtual Screening.  Journal of Chemical Information And Modeling 2005, 1, 

177-182. 

35.  Irwin,  J.  J.; Sterling, T.;  Mysinger,  M.  M.;  Bolstad,  E.  S.;  Coleman,  R.  G. 

ZINC:  a  free  tool  to  discover  chemistry  for  biology.  Journal  of  Chemical 

Information And Modeling 2012, 52, 1757-68. 

36.  Capuccini,  M.; Ahmed,  L.;  Schaal,  W.;  Laure,  E.;  Spjuth,  O.  Large-scale 

virtual  screening  on  public  cloud  resources  with  Apache  Spark.  Journal  of 

Cheminformatics 2017, 9, 15. 

37.  Jayaraj,  P.  B.;  Ajay,  M.  K.;  Nufail,  M.;  Gopakumar,  G.;  Jaleel,  U. 

GPURFSCREEN:  a  GPU  based  virtual  screening  tool  using  random  forest 

classifier. Journal of Cheminformatics 2016, 8. 

38.  Gentile, F.; Agrawal, V.; Hsing, M.; Ton, A. T.; Cherkasov, A. Deep Docking: 

A Deep Learning Platform for Augmentation of Structure Based Drug Discovery. 

ACS Central Science 2020, 6, 939-949. 

39.  Trott, O.; Olson, A. J. AutoDock Vina: improving the speed and accuracy of 

docking with a new scoring function, efficient optimization, and multithreading. 

Journal of Computational Chemistry 2010, 31, 455-61. 

40.  O'Boyle,  N.  M.  e.  a.  Open  Babel: An  open  chemical  toolbox.  Journal  of 

cheminformatics 2011, 3. 

41.  Yang, K.; Swanson, K.; Jin, W.; Coley, C.; Eiden, P.; Gao, H.; Guzman-Perez, 

A.; Hopper, T.; Kelley, B.; Mathea, M.; Palmer, A.; Settels, V.; Jaakkola, T.; Jensen, 

K.;  Barzilay,  R.  Analyzing  Learned  Molecular  Representations  for  Property 

Prediction. Journal of Chemical Information And Modeling 2019, 59, 3370-3388. 

42.  Mysinger, M. M.; Carchia, M.; Irwin, J. J.; Shoichet, B. K. Directory of useful 

decoys, enhanced (DUD-E): better ligands and decoys for better benchmarking. 

Journal of Medicinal Chemistry 2012, 55, 6582-94. 

43.  Yang, J.; Shen, C.; Huang, N. Predicting or Pretending: Artificial Intelligence 

for Protein-Ligand Interactions Lack of Sufficiently Large and Unbiased Datasets. 

Frontiers in Pharmacology 2020, 11, 69. 

44. Morris, G. M., Huey, R., Lindstrom, W., Sanner, M. F., Belew, R. K., Goodsell, 

D. S. and Olson, A. J. Autodock4 and AutoDockTools4: automated docking with 

selective receptor flexiblity. Journal of Computational Chemistry 2009, 16, 2785-

2791. 

45.  DOCK 6: Impact of new features and current docking performance. Journal 

of Computational Chemistry 2015, 36, 1132-1156. 

46.  Rarey, M.; Kramer, B.; Lengauer, T.; Klebe, G. A fast flexible docking method 

using an incremental construction algorithm. Journal of Molecular Biology 1996, 

261, 470-489. 

47.  McGann;  Mark.  FRED  pose  prediction  and  virtual  screening  accuracy. 

Journal of Chemical Information & Modeling 2011, 51, 578-96. 

48.  Halgren, T. A.; Murphy, R. B.; Friesner, R. A.; B Ea Rd, H. S.; Frye, L. L.; 

Pollard, W. T.; Banks, J. L. Glide: a new approach for rapid, accurate docking and 

scoring.  2.  Enrichment  factors  in  database  screening.  Journal  of  Medicinal 

Chemistry 2004, 47, 1750-1759. 

49.  Curt  D . Haffner; James M. Lenhard; Aaron B. Miller; Darryl L. McDougald. 

Structure-based  design  of  potent  retinoid  X  receptor  alpha  agonists.  Journal  of 

Medicinal Chemistry 2004, 47, 2010-2029. 

50. Liu, N.; Xu, Z. Using LeDock as a docking tool for computational drug design. 

IOP Conference Series Earth and Environmental Science 2019, 218. 

51.  Venkatachalam,  C.  M.;  Jiang,  X.;  Oldfield,  T.;  Waldman,  M.  LigandFit:  a 

novel  method  for  the  shape-directed  rapid  docking  of  ligands  to  protein  active 

sites. Journal of Molecular Graphics & Modelling 2003, 21, 289-307. 

52.  Spitzer, R.; Jain, A. N. Surflex-Dock: Docking  benchmarks  and real-world 

application. Journal of Computer-Aided Molecular Design 2012, 26, 687-699. 

53.  Hetényi, C.; Spoel, D. Toward prediction of functional protein pockets using 

blind docking and pocket search algorithms. Protein Science 2011, 20. 

 
 
Supplementary materials 

Table S1: Summary of common molecular docking programs 

Program 

Year Published 

Organisation 

Description 

Webservice 

License 

AutoDock44 

1990 

The Scripps Research 
Institute 

Automated docking of ligand to 
macromolecule by Lamarckian 
Genetic Algorithm and Empirical 
Free Energy Scoring Function 

No 

Open source 
(GNU GPL) 

AutoDock 
Vina39 

UCSF 
DOCK45 

2010 

1988 

The Scripps Research 
Institute 

New generation of AutoDock 

No 

University of California-San 
Francisco 

Based on Geometric Matching 
Algorithm 

No 

Open source 
(Apache 
License) 

Freeware for 
academic 
use 

FlexX46 

2001 

BioSolveIT 

Incremental build based docking 
program 

No 

Commercial 

FRED47 

2003 

OpenEye Scientific 

Systematic,exhaustive,nonstochast
ic examination of all possible poses 
within the protein active site 
combined with scoring Function 

No 

Freeware for 
academic 
use 

Glide48 

2004 

Schrödinger 

Exhaustive search based docking 
program 

No 

Commercial 

GOLD49 

1995 

Collaboration between 
the University of 
Sheffield, GlaxoSmithKlinepl
c and CCDC 

LeDock50 

2016 

Lephar 

Genetic algorithm based, flexible 
ligand, partial flexibility for protein 

No 

Commercial 

Program for fast and accurate 
flexible docking of small molecules 
into a protein 

No 

Freeware for 
academic 
use 

LigandFit51 

2003 

BioVia 

CHARMm based docking program 

No 

Commercial 

MOE 

2008 

Chemical Computing Group 

PSI-DOCK14 

2006 

Peking University 

rDock16 

1998 
(commercial)20
06 
(academic)[14]20
12 (open 
source)[15] 

Vernalis 
R&D(commercial)University 
of 
York (academic)University 
of Barcelona (open source) 

SEED18 

1999 

University of Zurich 

smina19 

2012 

University of Pittsburgh 

Surflex-
Dock52 

2003 

Tripos 

Docking application within MOE; 
choice of placement methods 
(including alpha sphere methods) 
and scoring functions (including 
London dG) 

Pose-Sensitive Inclined (PSI)-
DOCK 

HTVS process of small molecules 
against proteins and nucleic acids, 
binding mode prediction 

Automated docking of fragments 
with evaluation of free energy of 
binding including electrostatic 
solvation effects in the continuum 
dielectric approximation 
(generalized Born) 

A customized fork of AutoDock 
Vinawith a better support scoring 
function and a high-performance 
energy minimization 

Based on an idealized active site 
ligand (a protomol) 

No 

Commercial 

No 

Academic 

No 

No 

No 

Open source 
(GNU LGPL) 
(formerly 
commercial, 
academic) 

Open source 
(GNU GPL) 

Open source 
(Apache 
License) 

No 

Commercial 

SwissDock53 

2011 

Swiss Institute of 
Bioinformatics 

Webservice to predict interaction 
between a protein and a small 
molecule ligand 

Available 

Free to use 
webservice 
for academic 
usage 

 
 
Figure S1 

Figure S1: The train Loss(classification model), validation AUC(classification 
model), train MSE(regression model) and validation RMSE(regression model) 
of 10 selected targets 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure S2 

Figure S2: Docking score distribution of ChEMBL recalled and ChemDiv 
compounds. 

 
 
 
 
 
 
 
 
 
 
 
 
 
Figure S3 

Figure S3: Enrichment ratio of DUD-E active compound for two docking 
programs. 

 
 
