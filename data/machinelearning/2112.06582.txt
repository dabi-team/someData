Geometric Path Enumeration for Equivalence
Veriﬁcation of Neural Networks

Samuel Teuber∗, Marko Kleine B¨uning†, Philipp Kern‡ and Carsten Sinz§
Department of Theoretical Computer Science
Karlsruhe Institute of Technology (KIT), Germany
Email: ∗samuel@samweb.org, †marko.kleinebuening@kit.edu, ‡philipp.kern@kit.edu, §carsten.sinz@kit.edu

1
2
0
2

c
e
D
3
1

]

G
L
.
s
c
[

1
v
2
8
5
6
0
.
2
1
1
2
:
v
i
X
r
a

Abstract—As neural networks (NNs) are increasingly intro-
duced into safety-critical domains, there is a growing need to
formally verify NNs before deployment. In this work we focus
on the formal veriﬁcation problem of NN equivalence which aims
to prove that two NNs (e.g. an original and a compressed version)
show equivalent behavior. Two approaches have been proposed
for this problem: Mixed integer linear programming and interval
propagation. While the ﬁrst approach lacks scalability, the latter
is only suitable for structurally similar NNs with small weight
changes.

The contribution of our paper has four parts. First, we show a
theoretical result by proving that the epsilon-equivalence problem
is coNP-complete. Secondly, we extend Tran et al.’s single NN
geometric path enumeration algorithm to a setting with multiple
NNs. In a third step, we implement the extended algorithm for
equivalence veriﬁcation and evaluate optimizations necessary for
its practical use. Finally, we perform a comparative evaluation
showing use-cases where our approach outperforms the previous
state of the art, both, for equivalence veriﬁcation as well as for
counter-example ﬁnding.

Index Terms—Neural Network Veriﬁcation; Compression;

Equivalence; Geometric Path Enumeration

I. INTRODUCTION

With the success of deep neural networks (NNs) in recent
years, there has been an increasing trend to introduce machine
learning based approaches into many domains – including
safety-critical areas, such as airborne collision avoidance [1]
and autonomous cars [2]. Therefore, there is a growing in-
terest in veriﬁcation of NNs. This spurred research on new
veriﬁcation methods [3]–[9]. The literature can broadly be
classiﬁed into adversarial robustness veriﬁcation (e.g. the work
by Singh et al. [4]), functional property veriﬁcation (e.g. the
work by Katz et al. [3] on the veriﬁcation of ACAS Xu)
and equivalence veriﬁcation (e.g. Kleine B¨uning et al. [7]
and Paulsen et al. [8]). The main application of equivalence
veriﬁcation is in the space of NN compression. As NNs grow
ever larger and computing becomes ever more ubiquitous, re-
source restrictions require to compress large NNs into smaller
models. Cheng et al. [10] give an extensive survey of such
compression techniques. Furthermore, equivalence veriﬁcation
can be deployed to examine the inﬂuence of certain NN-based
pre-processing steps (cf. [9]) or in cases where performing
multiple veriﬁcation tasks on a large NNs would be too
expensive (cf. [7]). In what follows, we refer to the current

method of Paulsen et al. [11] by RELUDIFF and that of Kleine
B¨uning et al. [7] by MILPEQUIV.

One approach which has previously been shown to yield
good results for adversarial and functional veriﬁcation on NNs
is Geometric Path Enumeration (GPE) [6], [12]. However, this
algorithm was initially devised as an approach operating on a
single NN. In this work we extend GPE to a setting with
multiple NNs and implement its extension for the problem
of equivalence veriﬁcation. We explore which (sometimes
previously used) optimizations yield good results when applied
to the equivalence problem. While our work in this paper
the
is speciﬁc to the problem of equivalence veriﬁcation,
extended GPE algorithm can also be used for other veriﬁcation
tasks involving multiple NNs.

A. Contribution

In this work, we focus on the problem of equivalence
veriﬁcation for (potentially) structurally differing NNs. Our
contributions are as follows:
(C1) We prove that
coNP-complete.

the (cid:15)-equivalence problem for NNs is

(C2) We extend the GPE algorithm (Tran et al. [6]) to a
setting with multiple NNs and apply it to the equivalence
veriﬁcation problem.

(C3) We evaluate several optimizations for this setting which

increase efﬁciency on practical problems.

(C4) We perform a comparative evaluation of our algorithm
(on ACAS Xu and modiﬁed MNIST benchmarks) and
show that it outperforms MILPEQUIV in four of our ﬁve
(cid:15)-equivalence benchmarks and in counterexample ﬁnding.

B. Overview

The structure of our paper is as follows: In Section II,
we present related work in the ﬁeld of NN equivalence and
introduce the basic notions of GPE relevant to our paper.
Before explaining the idea behind our extension of GPE to
multiple NNs in Section IV, we show that the (cid:15)-equivalence
problem is coNP-complete in Section III. Starting from a naive
algorithm, we then evaluate optimizations to enable efﬁcient
equivalence veriﬁcation using GPE in Section V. We further
explore these optimizations, in particular the question of good
reﬁnement heuristics, in Section VI. Finally, in Section VII, we
evaluate our algorithm and show advantages and disadvantages
to the current state of the art represented by MILPEQUIV [7].

©2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including
reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or
reuse of any copyrighted component of this work in other works.

 
 
 
 
 
 
II. PRELIMINARIES & RELATED WORK

A. Feed-Forward NNs

NNs consist of interconnected units called neurons. A
neuron j computes a non-linear function of its input values
x1, . . . , xn according to yj = σ(∑n
i=1 wijxi + bj) where σ
is called the activation function and wij are the weights.
is commonly referred to as bias of neuron j. In this
bj
paper, we focus on the rectiﬁed linear unit activation function,
ReLU(x) = max(0, x), which is one of the most commonly
used activation functions in modern NNs [13]. Outputs of
neurons are connected as input to other neurons, resulting in a
directed graph. In this paper, we focus on feed-forward NNs,
where the underlying graph is acyclic. Neurons are organized
in layers, where neurons in layer l take inputs only from the
directly preceding layer l − 1. The ﬁrst layer—called input
layer—is just a place holder for the inputs to be fed into
the NN, the subsequent layers are called hidden layers, while
the last
layer—holds the function value
computed by the NN. We refer to the input space dimension
as I ∈ N and to the output dimension as O ∈ N.

layer—the output

B. Veriﬁying NN Equivalence

There has recently been a line of work which proposes
various compression techniques for NNs (for a full review
see Cheng et al. [10]). While such techniques have been
shown to be useful in practice, most lack a formal proof of
correctness and only rely on empirical evidence. The usage of
such techniques thus raises the question of how to prove that
two NNs R (reference) and T (test) and their corresponding
mathematical functions gR ∶ RI → RO, gT ∶ RI → RO are
equivalent, i.e. that they produce the same results.

Kleine B¨uning et al. [7] examined three possible deﬁnitions
of equivalence on a given subset of inputs I ⊆ RI , two of
which we review here:

Deﬁnition 1 ((cid:15)-Equivalence [7]
/ Differential Equiva-
lence [11]). Two NNs R and T are (cid:15)-equivalent with respect
to a norm ∥⋅∥, if ∥gR (x) − gT (x)∥ < (cid:15) for all x ∈ I

Deﬁnition 2 (Top-1-Equivalence [7]). Two NNs R and T
are top-1-equivalent, if arg maxi ri = arg maxj tj where r =
gR (x) and t = gT (x) for all x ∈ I

While Deﬁnition 1 is particularly suitable for regression
tasks as it can show a very strong form of equivalence, the
latter deﬁnition is more relaxed and especially useful for
classiﬁcation tasks.

Paulsen et al. [8] and Kleine B¨uning et al. [7] proposed
two fundamentally different approaches to NN equivalence
veriﬁcation. While Paulsen et al. [8] proposed a technique
called RELUDIFF/NEURODIFF which uses (symbolic) interval
propagation on NNs with similar weight conﬁgurations (e.g.
produced through ﬂoat truncation) to prove (cid:15)-equivalence, the
MILPEQUIV technique [7] is based on mixed integer linear
programming (MILP) and encodes (potentially) structurally
different NNs together with the desired equivalence property
into an optimization problem. RELUDIFF/NEURODIFF was

shown to be efﬁcient for cases where a NN’s weights had
been truncated. However, this approach does not work at all
for structurally differing NNs and suffers in performance when
weight differences are larger. For such NNs MILPEQUIV was
shown to work well for a number of small instances. (e.g. two
64 pixel input MNIST NNs with a total of 84 ReLU nodes).
In particular, MILPEQUIV is able to provide a maximal radius
around a datapoint for which the property still holds.

C. Geometric Path Enumeration

GPE is a methodology originally proposed by Tran et al. [6]
for verifying safety properties in NNs. Given a NN N , a set of
input instances I ⊆ RI and an unsafe output speciﬁcation U ⊆
RO deﬁned as a set of linear constraints, safety veriﬁcation is
concerned with the question whether there exist any instances
i ∈ I such that gN (i) ∈ U.

Instead of pushing single data points through the NN and
checking whether they satisfy the required safety property,
GPE feeds an entire set
into the NN and then evaluates
whether any parts of the output sets lie inside U. The sets are
represented through generalized star sets or zonotopes which
we deﬁne below:

Deﬁnition 3 (Generalized Star Set [6]). A generalized star
set Θ is a tuple ⟨c, G, P ⟩ where c ∈ Rn is the center, G =
(g1⋯gm) ∈ Rn×m is the generator matrix, and P ⊆ Rm is a
set deﬁned through a conjunction of linear constraints (i.e. a
polytope). The set represented by Θ is then deﬁned as:

= {x ∈ Rn ∣ ∃α ∈ P ∶ x = c + Gα}

Θ
(cid:75)

(cid:74)

Alternatively, it is possible to use zonotopes which further

restrict the type of predicate allowed:

Deﬁnition 4 (Zonotopes [12]). A zonotope Ψ is a generalized
star set ⟨c, G, P ⟩ with the further restriction that P may only
be deﬁned through interval constraints (i.e. P only enforces a
lower and upper bound for each dimension).

We refer to zonotopes and generalized star sets as set data
structures. Initially, the GPE algorithm converts the provided
input space into either of these data structures and then prop-
agates the sets through the NN. The transformation deployed
through the dense layer of a NN can be exactly represented
by zonotopes and generalized star sets through application
of the weight matrices to G and c. ReLU nodes require a
different type of transformation since they are only piece-wise
linear functions: To this end, the data structures can either be
split by introduction of an additional hyperplane to the linear
constraint predicate (exact GPE) or the ReLU function can
be over-approximated [4], [14] (approximate GPE). Note that
optimization for generalized star sets is much more expensive
than optimization for zonotopes, which can be computed with
a closed form solution.

III. NN EQUIVALENCE AND NP COMPLETENESS
Katz et al. [3] have previously shown that the satisﬁability
problem for linear input and output constraints of a single

2

NN with ReLU nodes is NP-complete. We refer to this
decision problem as NET-VERIFY. In this section, we show
that the (cid:15)-equivalence problem for NNs is coNP-complete.
Since disproving (cid:15)-equivalence is NP-complete, the task of
proving (cid:15)-equivalence is coNP-complete.

Theorem 1 ((cid:15)-NET-EQUIV is NP-complete). Let R, T be two
arbitrary ReLU NNs and let I be some common input space
of the two NNs. Determining whether ∃x ∈ I ∶ ∥gR (x) −
gT (x)∥p ≥ (cid:15) is NP-complete for any p-norm ∥⋅∥p.

The full proof can be found in Appendix A. In essence, the
proof consists of a reduction from NET-VERIFY to (cid:15)-NET-
EQUIV. In order to reduce a NET-VERIFY instance consisting
of a NN N and a linear constraint speciﬁcation ψ, we encode
it as follows: The ﬁrst NN R only consists of N . The second
NN T consists of N and a suitable encoding of the linear
constraints ψ. We then show that we only can disprove (cid:15)-
equivalence iff N satisﬁes the given speciﬁcation ψ.

IV. EXTENDING GPE TO MULTIPLE NNS

The most trivial approach to extend GPE to multiple NNs
would be to stitch multiple NNs into a single composite NN
and then execute regular GPE on this composite NN. However,
the composite NN’s weight matrices would be considerably
larger which would increase the computational load. Further-
more, NNs with a different number of layers would have to be
padded for this approach. This would nullify any performance
gains which could otherwise be achieved through the reduced
NN size.

Instead, we propose to propagate star sets through both NNs
sequentially. By carefully selecting the constraint sets of the
propagated sets, we can ensure that there remains a point-wise
correspondence between the output data structures of GPE for
the two (or more) NNs considered. To make our approach
clear, we introduce transfer functions as a way of reasoning
about exact propagation of set data structures.

Deﬁnition 5 (Transfer Function). Let N be a NN. A transfer
function TN is a function which, given an input data structure
Θ = ⟨c, G, P ⟩, produces a set of output data structures s.t.

∀⟨c′, G′, P ′⟩ ∈ TN (Θ) . ∀α ∈ P ′ . gN (c + Gα) = c′ + G′α

and that the union of all P ′ within TN (Θ) equals P .

Using these transfer functions, we show that there is a
correspondence between the output sets of two NNs in GPE:

Theorem 2 (NN Output Correspondence). Let R, T be two
NNs with their corresponding transfer functions TR, TT and
let Θ = ⟨c, G, P ⟩ be some input data structure. For any
ΘR = ⟨cR, GR, PR⟩ ∈ TR (Θ) and ΘT = ⟨cT , GT , PT ⟩ ∈
TT (⟨c, G, PR⟩):

{(gR (x) , gT (x)) ∣ x ∈

⟨c, G, PT ⟩
} =
(cid:75)
{(cR + GRα, cT + GT α) ∣ ∃α ∈ PT } .

(cid:74)

An over-approximation would produce additional, spurious
points in the output of T (Θ) and may therefore produce

3

spurious output tuples. In this case the right side of Theorem 2
becomes a superset. This in turn gives rise to the modiﬁed
GPE algorithm outlined in Algorithm 1. We begin by feeding
our input data structure ⟨c, G, P ⟩ into the ﬁrst NN. The
propagation step function for the data structures (step) is
the same as in the single NN GPE algorithm in Section II-C.
For every output star set ⟨cR, GR, PR⟩, we restrict the input
data structure according to the predicate of the output of the
ﬁrst NN, i.e. ⟨c, G, PR⟩. Then we feed this data structure
into the second NN to obtain ⟨cT , GT , PT ⟩. In the end, we
can compare the two output tuples ⟨cR, GR⟩ and ⟨cT , GT ⟩
constrained by the predicate PT .

Note that both considered output sets are therefore con-
strained by PT (not PR). This is the essential insight, that
allows our approach to produce point-wise correspondences
between the outputs of the two NNs.

Algorithm 1 High-level path enumeration algorithm for equiv-
alence checking. LP indicates the step uses LP solving.
Input: Input Θ = ⟨c, G, P ⟩, NNs ⟨R, T ⟩
Output: Veriﬁcation result (equiv or nonequiv)

s ← ⟨nn ∶ R, layer ∶ 0, neuron ∶ None,

Θ ∶ Θ, ΘR ∶ (cid:150), ΘT ∶ (cid:150)⟩

i ← Θ
W ← List() {Working list of set data structures}
W.put (s)
while ¬W.empty() do

s ← W.pop()
steps.nn (s, W)LP {Propagate s.Θ by one neuron}
if s ﬁnished network R then

s.ΘR ← s.Θ {Store output from R for comparison}
s.nn ← T
s.Θ ← ⟨i.c, i.G, s.Θ.P ⟩
s.layer, s.neuron ← 0, None

end if
if s ﬁnished network T then

s.ΘR.P ← s.Θ.P {Output of R}
s.ΘT ← s.Θ {Output of T }
if ¬is_equiv (s.ΘR, s.ΘT )LP then

return not equivalent

end if

else

W.push (s)

end if
end while
return equivalent

A. Equivalence on Set Data Structures

For our equivalence veriﬁcation approach it is necessary
to deﬁne an equivalence check is_equiv which veriﬁes
whether two set data structures ΘR, ΘT satisfy (cid:15)-equivalence
or top-1 equivalence. First, we present how (cid:15)-equivalence
with Chebyshev norm ∥⋅∥∞ can be proven for zonotopes.
Afterwards, we show how Star Sets can be used to prove (cid:15)-
equivalence and top-1 equivalence.

a) (cid:15)-Equivalence: In order to prove (cid:15)-equivalence with
the Chebyshev norm, we need to bound the maximum de-
viation between the two NN outputs by (cid:15). That is, given
the two output zonotopes ΨR = ⟨cR, GR, PT ⟩ and ΨT =
⟨cT , GT , PT ⟩ we want to ﬁnd the maximal deviation:

max
α∈PT
= max
i

∥(cR + GT α) − (cT + GT α)∥∞

max
α∈PT

∣(cR − cT )i + (GR − GT )i α∣ .

As can be seen by the reformulation above, we can ﬁnd the
maximal deviation over the output by solving optimization
problems for each dimension of the differential zonotope

∂Ψ = ⟨(cR − cT ) , (GR − GT ) , PT ⟩).

Recalling that zonotopes can be optimized with a closed form
solution,
this enables a quick check for the adherence of
the desired (cid:15)-equivalence property. However, since zonotopes
only approximate the output set, one may need to fall back
to the use of Star Sets if equivalence cannot be established
using zonotopes. In this case, we can reuse the same formula
from above to obtain a differential star set ∂Θ which is then
optimized using LP solving.

b) Top-1 Equivalence: For top-1 equivalence there are
two possible approaches which both rely on propapagated star
sets. We can reuse the MILPEQUIV encoding and employ a
MILP solver. Alternatively, we can use a simplex (LP) solver.
In the latter case we split up the output star set ΘT :

For every output dimension 1 ≤ j ≤ O we generate a
polytope Pj. Additional constraints rj ≥ ri ∀i ≠ j ensure
that output rj is the maximum among the outputs of R in
⟨cR, GR, PT ∩Pj⟩. Note that the union of P1 to PO covers all
of PT . We then examine the outputs of Θj = ⟨cT , GT , PT ∩Pj⟩
for every 1 ≤ j ≤ O. Since j is always the maximum of R
for this part of the output space, we want to ensure that j
is also always the maximum of T . Therefore, we compute
the maximal difference between output dimension j and the
other dimensions in Θj. If all of these differences are below 0,
we can guarantee top-1 equivalence. This procedure produces
O (O) star sets and O (O2) optimization operations in total.

B. Challenges and Limitations of the approach

While the techniques outlined above permit a straightfor-
ward extension of GPE to multiple NNs, and thus allow
achieving equivalence veriﬁcation, the approach comes with a
number of pitfalls which should be avoided. The most obvious
is probably the possibility of exponential growth in the number
of star sets. As previously noted, the exact GPE approach
based on star sets splits the star sets on ReLU nodes. Tran et
al. [6] rightly note that the observed growth usually drastically
falls behind the worst case, however the increase in ReLU
nodes through the processing of two NNs at once certainly
leads to an increase in necessary splits. This is particularly the
case for ReLU nodes which cut off very similar hyperplanes
(such as the two ReLU nodes in a NN at the same position
with truncated weights). This can not only double the work,
but it may also lead to precision problems with LP solvers

which tend to show problematic behavior when encountering
a problem which has a very small feasible set1. To avoid
such numerical problems we thus use 64-bit ﬂoats by default
and always ensure that feasibility is checked at least once by
an exact (i.e. rational) LP solver before a branch is declared
infeasible. While this can mitigate most numerical problems,
the approach is weaker than RELUDIFF/NEURODIFF for the
speciﬁc use case of weight truncation for structurally similar
NNs (e.g. truncation from 32-bit to 16-bit ﬂoats) – this is
best left
to the approach presented by Paulsen et al. [8].
Although these initial improvements help in making GPE for
equivalence possible, this approach is not yet scalable. Hence,
we devote the next section to various optimizations.

V. OPTIMIZING GPE FOR TWO NNS

The approach presented above is not yet scalable. In par-
ticular, we identify two bottlenecks: The number of splits and
the time taken for LP optimization. Therefore, we consider a
number of optimizations, some of which have previously been
used by Bak [14].

A. Zonotope Propagation

As an initial optimization we reused the zonotope propa-
gation technique presented by Bak et al. [12], which reduces
the number of LP optimizations necessary through a zonotope
based bounds computation. We refer to this ﬁrst version of
the algorithm as NNEQUIV-E (for exact). As can be seen in
Figure 3 later on, this approach produces a total runtime of
54,390s on our 9 benchmark instances.

B. Zonotope Over-Approximation

To further optimize the algorithm we can either reduce
the time spent per zonotope or we can try to reduce the
number of zonotopes which have to be considered. In order
to achieve the second objective, we can over-approximate
certain ReLU splits through a methodology ﬁrst presented
by Singh et al. [4] and later reused by Bak [14]: The idea
is to introduce an additional dimension to the zonotope and
use it to over-approximate the ReLU node by a parallelogram.
Over-approximation errors accumulate across layers (Bak [14]
refer to this as error snowball). To make the parallelogram as
tight as possible and minimize the over-approximation error,
we use the bounds computed through LP solving (instead of
the looser zonotope bounds) if there were any exact splits
beforehand. In an abstraction-reﬁnement setting, we would
start by propagating over-approximating zonotopes through
both NNs and then check, whether the equivalence property
can be established. If the property does not hold, we reﬁne
one over-approximated ReLU node by splitting the zonotope
and propagating the split zonotopes further through the NNs.
In Figure 1 we compare the share of nodes per layer whose
bounds contain the value 0 for an exact approach in compar-
ison to the propagation of an over-approximating zonotope.

1In one case the solver would return drastically differing maximum values
for the same optimization problem depending on the previous requests or
would suddenly deem the problem infeasible.

4

and can be used to reduce the number of dimensions the LP
solver has to handle despite the over-approximation of the
zonotope.Note that we need to take this over-approximation
into account for minimization/maximization tasks. Since the
LP solver only optimizes the ﬁrst I dimensions, we need to
add the optimization result of the over-approximating zonotope
for the remaining dimensions. We refer to this version as
NNEQUIV-A (for approximate LP). Figure 3 shows that this
approach reduces the runtime to 1,631s.

VI. THE BRANCH TREE EXPLORATION PROBLEM

turns out

Given the introduced over-approximations over ReLU
splits, it becomes necessary to deﬁne a strategy that decides
which over-approximations are reﬁned if it
that
the property cannot be established with the current over-
approximation. The problem of reﬁnement heuristics has
previously been studied for single NNs by Bak [14] who
experimentally showed that a classic reﬁnement loop approach
which over-approximates everything and step by step reﬁnes
over-approximations starting at the beginning of the NN (i.e.
NNEQUIV-F/A) sometimes performs worse than exact analy-
sis. While we were able to reproduce this problem for some
benchmark instances, we observed an improvement for others.
It seems like a good approach to begin propagation with an ex-
act strategy which splits on every encountered neuron, which,
however, eventually transitions into over-approximation.

We proceed with a formal analysis on different strategies
and their (dis)advantages. For this we consider binary trees that
are implicitly explored by a GPE algorithm: For given NNs
and input space I, the implicit tree explored by GPE consists
of vertices V = N ⊎ L where N are the inner nodes of the
tree representing ReLU splits and L are the leafs of the tree
representing the output set data structures. The execution of an
exact GPE algorithm implicitly produces a set of paths of the
form p ∈ N ∗ × L that are (for now) explored sequentially. We
denote this set of paths as P . For the exact case, the number
of explored paths is ﬁxed to the number of leafs. Since GPE
produces a partitioning of the input space I, we can associate
a part of the input space to every leaf and to every inner node.
For its execution GPE needs to descend into each leaf and
execute a check function on each leaf to prove equivalence.
descend refers to the operations necessary to process a star
set up to its next ReLU split. check refers to the operations
necessary to prove equivalence on an output star set. Since the
descend function is executed once for each of the 2 ∣P ∣ − 2
edges of the tree and the check function is executed once
for each of the ∣P ∣ leaves, the execution time of NNEQUIV-E
is bounded by O (∣P ∣ ∗ (tcheck + 2tdescend)).

Omitting the option of reordering the inner nodes and thus
producing a smaller tree, we must either reduce tcheck and
tdescend or ∣P ∣ to reduce solving times. In many cases, the
considered property E cannot only be proven on part of the
input space associated to the leaf, but there also exists some
inner node n ∈ N with an associated part of the input space
which is already sufﬁciently partitioned to show E using over-
approximation. For a given equivalence property E we can

Fig. 1. Comparison of exact star set propagation (Exact) and propagation
of an over-approximating zonotope (Overapprox) for (cid:15)-equivalence over
ACAS 1 1: Net1 corresponds to R and Net2 corresponds to T (Overapprox
Net2 is hidden behind Overapprox Net1)

Any such node can be considered a split candidate which
could be used for reﬁnement. Each reﬁnement can then help in
reducing the over-approximation error and in establishing the
desired property. As can clearly be seen in the plot, the over-
approximation approach produces a lot more split candidates
than the exact approach. Not all of the splits candidates
encountered for the over-approximation would actually have to
be reﬁned in the worst case. This is, because many of the split
candidates are only artifacts of previous over-approximations.
We refer to these split candidates as ghost splits. These ghost
splits cannot be easily distinguished from actual, necessary
splits. The only guaranteed non-ghost split, is the ﬁrst split
candidate encountered, while all later split candidates might
be artifacts of over-approximation.

Thus, the simplest reﬁnement strategy would be to reﬁne
only this node. We refer to this strategy as NNEQUIV-F (First),
and it reduces the runtime on our benchmark set to 2,489s
(c.f. Figure 3). However, this approach still leaves room for
improvement as we explain in Section VI.

C. LP approximation

With the introduction of over-approximation we encounter
an additional problem: Splitting hyperplanes are no longer
dependent on the input variables only, but also depend on
the dimensions introduced through the over-approximation.
This raises the question how to handle the additional di-
mension in the propagated star set: Since equally increasing
the dimensionality of the LP problem leads to increased
solver runtimes, we instead opted to over-approximate the
LP problem. Classically, for an m dimensional zonotope with
initial input dimensionality I we observe a hyperplane cut of
the following form:

I
∑
i=1

giαi +

m
∑
i=I+1

giαi ≤ c

(1)

We can now over-approximate this inequality by computing
µ = minα ∑m
through zonotope optimization and
constraining the LP problem with the following inequality:

i=I+1 giαi

I
∑
i=1

giαi ≤ c − µ

(2)

Since any solution for Equation (1) implies a solution for
Equation (2) the second inequality is an over-approximation

5

Fig. 2. ACAS 1 1-retrain: Descend depth at point of successful equivalence
proof for (cid:15) = 0.05 (Running percentile window width: 479)

deﬁne a function minE ∶ N ∗×L → N which returns the number
of necessary steps in the given path p for the property E to
be veriﬁable on the input space part associated to element
minE (p) of path p. The exploration of the tree induced by
the set of paths

P ∗ = {p′ ∈ N ∗ ∪ N ∗ × L ∣ ∃p ∈ P ∶ p′ = p1∶minE (p)}

would then be sufﬁcient
denotes the preﬁx path of p from step 1 to step minE (p)).

to prove equivalence (p1∶minE (p)

NNEQUIV-F/A manages to obtain this minimal number of
paths – however at the cost of a much higher time spent
on each path. In particular, check is not only executed for
each leaf, but also for each inner node. Ignoring the over-
approximation costs, this produces the following lower bound
for the cost of NNEQUIV-F/A:

Ω (∣P ∗∣ ∗ (2tcheck + 2tdescend))

Even when assuming the omitted over-approximation steps
to be free, NNEQUIV-F/A becomes less effective than
NNEQUIV-E if asymptotically ∣P ∣ < ∣P ∗∣ 2(tcheck+tdescend)
, i.e.
tcheck+2tdescend
if the reduction of paths in P ∗ is insigniﬁcant in comparison to
the check time for the additional paths. While there are cases
where NNEQUIV-F/A is effective, this is not guaranteed to
be the case – especially for larger NNs with higher values for
minE (which increases ∣P ∗∣) and expensive check functions.
However, this formal framework allows us to deﬁne the
(virtual) optimal run which takes the minimal amount of work
for a given tree: An algorithm which has an oracle for minE
and always over-approximates at the right node. This approach
has a runtime of O (∣P ∗∣ ∗ (tcheck + 2tdescend)).

Since ∣P ∗∣ ≤ ∣P ∣ and the omitted over-approximation time
tends to be smaller than the descend time, this approach can
provide the optimum achievable through heuristics for minE .
In fact, we simulated such virtual runs using a pre-computed
oracle by computing minE using NNEQUIV-A and descending
only the minimum necessary number of steps for each path.
In our evaluation we refer to this approach as NNEQUIV-O.
As expected, NNEQUIV-O produced the best results of all
variants considered in our work running only 635s on our
benchmark set. This is not a practical algorithm, but provides
a lower bound for the time taken using minE heuristics.

It is thus important to ﬁnd a good heuristic which estimates
minE . These heuristics are much more difﬁcult to analyze
theoretically because they are particularly dependent on the
distribution of the encountered paths. Therefore, we only ex-
plore two heuristics experimentally which show that heuristics
have a signiﬁcant impact on the runtime.

Figure 2 plots the depth at which GPE was successful in
proving equivalence for a path in an ACAS Xu NN (i.e. the
values of minE ). Besides the data in grey, we plotted a number
of running percentiles over the depth values.

A strategy which we have found to be inefﬁcient is the use
of a running maximum over the number of reﬁnements needed
by previous paths. This strategy is referred to as NNEQUIV-M
(for maximum) and drastically increases runtime to 19,191s,
presumably by over-estimating the number of reﬁnements, thus
increasing the number of paths considered.

Since Figure 2 suggest that there are phases in which the NN
needs deeper or less deep reﬁnement depths, we considered
a heuristic which predicts a reﬁnement depth equal to the
depth of the previous path minus 1. This accounts for the
possible phases of the depth and also ensures that the algorithm
is optimistic in the sense that it always tries to reduce the
number of reﬁnement steps.This can then reduce the number
of considered paths. We refer to this heuristic as NNEQUIV-
L which reduces runtime on the benchmark set by another
5% to 1,553s. While the methodology of over-approximation
using Zonotopes is the same for NNEQUIV-A and NNEQUIV-
O/L/M the approaches differ in the strategy deciding where
the over-approximation is reﬁned.

VII. EXPERIMENTAL EVALUATION

To evaluate our approach, we implemented the GPE based
equivalence veriﬁcation technique using parts of a pre-existing
(single NN) GPE implementation by Bak et al. [12] in Python.
We will refer to our implementation as NNEQUIV2. Our
evaluation aims at answering the following questions:
(E1) Do the proposed optimizations make the algorithm more

efﬁcient?

(E2) How does NNEQUIV compare to previous work such as

MILPEQUIV [7] and RELUDIFF [11]?3

(E3) How does the tightness of the (cid:15)-equivalence constraint

inﬂuence solving behavior?

A. Experimental Setup

The benchmark landscape for the task of equivalence ver-
iﬁcation is still very limited. Paulsen et al. [11] proposed
a number of benchmark NNs consisting of pairs of NNs
differing only in the bit-width of the weights (32 bit vs. 16
bit). As discussed before, we see this as a restricted use case
and are more interested in generic NNs with varying structures
and weights. This is why we omit a comparison on these NNs
where the approach by Paulsen et al. [8] is clearly faster and
more precise. Structurally differing NNs have been previously
proposed by Kleine B¨uning et al. [7] who examined 3 NNs of
differing layer depths for digit classiﬁcation on an MNIST [15]
data set with reduced resolution [16] (8x8 pixels).

In order to evaluate and compare the approaches we thus
proceeded as follows: First, we decided to look at two types

2Our implementation is available on GitHub: https://github.com/samysweb/

nnequiv

3Unfortunately, there is no artifact for NEURODIFF [8] which we could

have evaluated.

6

TABLE I
RUNTIME COMPARISON (IN SECONDS) FOR NNEQUIV-L AND MILPEQUIV

Benchmark
ACAS 1 1-retrain
ACAS 1 1-student
ACAS 1 2-retrain
ACAS 1 2-student
MNIST large-epsilon
MNIST small-top
MNIST medium-top
MNIST large-top
MNIST larger-top

Property
(cid:15) = 0.05
(cid:15) = 0.05
(cid:15) = 0.05
(cid:15) = 0.05
(cid:15) = 15
top-1
top-1
top-1
top-1

NNEQUIV-L MILPEQUIV

167.45
84.85
326.59
109.46
35.90
14.39
94.51
13.02
706.56

TO
TO
TO
320.07
19.97
3.51
3.85
25.85
386.04

run in parallel, up to 24 processes at once. All times given in
the subsequent sections are the median of 3 runs.

B. Comparison of NNEQUIV versions

Figure 3 shows that the proposed optimizations help in
reducing the runtime of the algorithm (note that the upper half
of the y-axis has a logarithmic scale for improved visibility of
the results). On the one hand, we can observe, that heuristics
for minE can, in principle, improve and worsen the result of
the approach (as seen with NNEQUIV-L and NNEQUIV-M).
On the other hand, we see that there is still signiﬁcant room
for improvement through the development of better reﬁnement
heuristics – this optimization would be supplementary to
further optimizations which could be developed.

C. Comparison to previous work

The comparison to MILPEQUIV is shown in Table I.
NNEQUIV outperforms MILPEQUIV on the ACAS instances,
where MILPEQUIV even runs into a timeout for three of the
four veriﬁcation tasks. In particular, this seems to be the case
for larger NNs with low-dimensional inputs. The superior per-
formance of MILPEQUIV for the case of MNIST large-epsilon
seems to be caused by the LP solver in NNEQUIV which is a
magnitude slower for solving optimizations tasks for MNIST
in comparison to ACAS Xu. As this cannot be explained by
the number of constraints, we suspect this is a problem related
to the larger input dimensionality for the MNIST case (64
inputs in comparison to 5 inputs for ACAS Xu). The ACAS-
retrain NNs have the same structure as the original ACAS
NN, allowing us to compare NNEQUIV to RELUDIFF. While
RELUDIFF was able to quickly verify equivalence for the
truncated NNs, where the mean absolute weight difference was
≈ 9.37 ∗ 10−5, it was signiﬁcantly slower than our approach
on the retrain instances, with a mean weight difference of
≈ 0.48, for (cid:15) ≤ 5 and even timed out for smaller values of (cid:15).
This suggests that the applicability of RELUDIFF is not only
restricted to structurally similar NNs, but that its performance
also heavily depends on small weight differences. Regarding
question (E2) we note that our approach is applicable to a
broader class of NNs than RELUDIFF and solved instances
where both other approaches timed out.

D. Inﬂuence of (cid:15)-equivalence tightness

Concerning question (E3) we evaluated the performance of
the approaches as we vary the tightness of (cid:15)-equivalence for

Fig. 3. Time in seconds taken for our equivalent benchmarks per version.
Note that the upper half of the y-axis has a logarithmic scale for improved
visibility of the results.

of NNs: Image classiﬁcation on the 8x8 pixel MNIST data set
and NNs used in control systems in the context of an Airborne
Collision Avoidance System (ACAS Xu [1]). Then, based
on the original ACAS Xu NNs 1 1 and 1 2, we contructed
a total of 4 mirror NNs through retraining (ACAS 1 1-
retrain, ACAS 1 2-retrain) and student teacher training [17]
for smaller NNs (ACAS 1 1-student, ACAS 1 2-student). In
additon to the smallest and largest MNIST 8x8 NNs consid-
ered in previous work (MNIST small-top, MNIST medium-
top), we constructed two larger MNIST models using stu-
dent teacher training (MNIST large-top, MNIST larger-top).
Moreover, we constructed a second version of MNIST large-
top for (cid:15)-equivalence veriﬁcation (MNIST large-epsilon). All
NNs were trained using variants of student teacher training and
were trained in such a way that they were likely to be top-1
or (cid:15)-equivalent in some parts of the input space. More details
on the properties of the 9 considered benchmark NNs are
available online.4 The input space considered for veriﬁcation
is a sensitive choice, as it can have signiﬁcant and varying
impact on the performance of different veriﬁcation techniques.
For the case of GPE, the algorithm’s performance tends to
degrade with increasing input space size due to the growth
in necessary splits. Therefore, for each individual benchmark,
we decided to look at an input size which was hard to handle
for NNEQUIV-E. This has two reasons. First, it allows us
to evaluate the impact of the optimizations presented above
in their ability to decrease runtimes. Secondly, it permits to
compare the performance of NNEQUIV to the performance of
MILPEQUIV on instances which are difﬁcult for our approach.
The entire experimental setup can be found online.5

We used a machine with 4 AMD EPYC 7281 16-Core
processors (i.e. 64 cores in total) and a total of 64GBs of RAM.
All experiments were run with a single thread, a memory limit
of 512MB6, and a timeout of 3 hours. The experiments were

4An overview table of all benchmarks is available at https://github.com/

samysweb/nnequiv-experiments/blob/main/benchmarks.md

5On GitHub: https://github.com/samysweb/nnequiv-experiments
6The memory limit was irrelevant in practice, as no experiment hit this

limit.

7

TABLE II
COMPARISON OF COUNTEREXAMPLE FINDING CAPABILITIES OF
NNEQUIV-L, MILPEQUIV AND MILPEQUIV-B (NO ReLU NODE BOUNDS)

#Solved
Time (incl.TO)
Time/Solved (excl.TO)

NNEQUIV-L MILPEQUIV MILPEQUIV-B
305
75,989s
14.91s

315
72,515s
7.21s

890
3,597s
2.69s

Fig. 4. Solving time in seconds for (cid:15)-equivalence with varying (cid:15): Solving
times increase with tighter properties, however NNEQUIV-L outperforms
MILPEQUIV. RELUDIFF is outperformed by NNEQUIV-L for retrained NNs.

(cid:15) ∈ [0.005, 500]. Note that we did not prove equivalence for
(cid:15) = 0.005 for ACAS 1 2-student as we found this NN not
to be 0.005-equivalent to the original NN. Intuitively, a proof
for a tighter (cid:15) bound will require more work as the approach
either needs to reﬁne more over-approximations (in the case
of NNEQUIV-L) or do further branch-and-bound operations
(in the case of MILPEQUIV). We can observe this behavior
in Figure 4 which plots the runtime of MILPEQUIV and
NNEQUIV-L as we tighten the (cid:15) bound. Taking into account
the log scales on both axes, we can observe that NNEQUIV-
L is at least one magnitude faster in proving equivalence
for ACAS Xu NNs for (cid:15) ≤ 0.05. In particular, MILPEQUIV
produces time-outs for 3 of the 4 considered NNs once
(cid:15) ≤ 0.05. We therefore suspect that our approach is better
at handling very tight (cid:15) constraints in large NNs with low
dimensional input. This could potentially be due to the fact that
GPE can use additional NN information (layer structure etc.)
for its reﬁnement decisions which is not readily available in the
branch-and-bound algorithm in the backend of MILPEQUIV.
For comparison, we plotted the performance of RELUDIFF
on NNs for truncated weights and retrained NNs: As can be
seen in Figure 4 the approach by Paulsen et al. [11] behaves
similarly with respect to (cid:15) tightness. Additionally, we see that
the approach is less efﬁcient for retrained NNs where the
equivalence for (cid:15) ≤ 0.05 cannot be established.

E. Finding Counterexamples

Our technique can also be used to ﬁnd counterexamples,
showing that two NNs are not equivalent at a certain point.
This information can be interesting to further train NNs after
a failed equivalence proof. To this end, we compared the
capabilities of NNEQUIV-L in counterexample ﬁnding with
the capabilities of MILPEQUIV. To account for possibly easy
instances, we looked at a large number of non-equivalent
input spaces for each of our benchmark NNs which we
know to be equivalent on other parts of the input space. To
generate counterexamples, we randomly sampled input points
and selected the points with differing NN outputs. Using
this technique, we produced 100 distinct non-equivalent input
points for each of our 9 benchmarks. These points were used
as center for L∞-balls which represented our input spaces.

We then evaluated NNEQUIV-L and MILPEQUIV on the
same input space radii as in Section VII-B with the objective
of ﬁnding counterexamples. Since counterexample extraction
is much faster than equivalence proofs, we set a timeout of 2
minutes. We found that NNEQUIV-L was signiﬁcantly faster
and extracted a counterexample for 890 of the 900 considered
benchmarks, while even a version without expensive ReLU
bounds computation7 executed in the initialization (named
MILPEQUIV-B) was only able to ﬁnd 315 counterexamples.
Also, the time per counterexample was signiﬁcantly lower
for NNEQUIV-L, making this approach an interesting tech-
nique for retraining NNs via counterexamples. Looking at the
behavior of MILPEQUIV’s solver backend, it seems that the
reason for our superior performance lies in the time needed by
MILPEQUIV to ﬁnd an initial feasible solution. MILPEQUIV
ﬁrst needs to resolve the integer based ReLU node encodings,
which are automatically resolved by NNEQUIV-L through the
propagation of sets. NNEQUIV-L has the potential to extract
polytopes of non-equivalent input space subsets which could
allow for even more efﬁcient sampling.

VIII. CONCLUSION AND FUTURE WORK

We proposed an approach extending Geometric Path Enu-
meration [6] to multiple NNs. Employing this method, we
presented an equivalence veriﬁcation algorithm which was
optimized by four techniques: Zonotope propagation, zonotope
over-approximation, LP approximation, and reﬁnement heuris-
tics. Our evaluation shows that
the optimizations increase
the approach’s efﬁciency and that it can verify equivalence
of NNs which were not veriﬁable by MILPEQUIV [7] and
RELUDIFF [11]. Our approach signiﬁcantly outperforms the
state of the art in counterexample ﬁnding by solving 890
instances in comparison to 315 instances solved by MILPE-
QUIV. In addition, we proved the coNP-completeness of the (cid:15)-
equivalence problem, and presented a formal way of reasoning
about reﬁnement heuristics in the context of GPE.

In terms of efﬁciency, one could further explore possible
reﬁnement heuristics and consider parallelized (possibly GPU
based) implementations. Moreover, while GPE can increase
the conﬁdence in NNs, the role of numerical stability for the
veriﬁcation approach has to be further investigated. Further-
more, an integration of MILP constraints into GPE propaga-
tion could be explored resulting in an algorithm inbetween
NNEQUIV and MILPEQUIV. Additionally, we see a need for

7While this optimization step improves performance for equivalence proofs,

it may degrade performance for counterexample ﬁnding.

8

a larger body of equivalence benchmarks which allows the
conclusive evaluation of equivalence veriﬁcation algorithms.

REFERENCES

[1] K. D. Julian, J. Lopez, J. S. Brush, M. P. Owen, and M. J. Kochenderfer,
“Policy compression for aircraft collision avoidance systems,” in 2016
IEEE/AIAA 35th Digital Avionics Systems Conference (DASC).
IEEE,
2016, pp. 1–10.

[2] M. Bojarski, D. Del Testa, D. Dworakowski, B. Firner, B. Flepp,
P. Goyal, L. D. Jackel, M. Monfort, U. Muller, J. Zhang, and others, “End
to end learning for self-driving cars,” arXiv preprint arXiv:1604.07316,
2016.

[3] G. Katz, C. Barrett, D. L. Dill, K. Julian, and M. J. Kochenderfer,
“Reluplex: An efﬁcient SMT solver for verifying deep neural networks,”
in International Conference on Computer Aided Veriﬁcation. Springer,
2017, pp. 97–117.

[4] G. Singh, T. Gehr, M. Mirman, M. P¨uschel, and M. Vechev, “Fast
and effective robustness certiﬁcation,” Advances in Neural Information
Processing Systems, vol. 2018-Decem, no. Nips, pp. 10 802–10 813,
2018.

[5] S. Wang, K. Pei, J. Whitehouse, J. Yang, and S. Jana, “Efﬁcient formal
safety analysis of neural networks,” in Advances in Neural Information
Processing Systems, 2018, pp. 6367–6377.

[6] H.-D. Tran, D. M. Lopez, P. Musau, X. Yang, L. V. Nguyen, W. Xiang,
and T. T. Johnson, “Star-based reachability analysis of deep neural
networks,” in International Symposium on Formal Methods. Springer,
2019, pp. 670–686.

[7] M. Kleine B¨uning, P. Kern, and C. Sinz, “Verifying Equivalence
Properties of Neural Networks with ReLU Activation Functions,” in
Principles and Practice of Constraint Programming - 26th International
Conference, CP 2020, Louvain-la-Neuve, Belgium, Proceedings, 2020.
[8] B. Paulsen, J. Wang, J. Wang, and C. Wang, “NEURODIFF: scalable
differential veriﬁcation of neural networks using ﬁne-grained approx-
imation,” in 35th IEEE/ACM International Conference on Automated
Software Engineering, ASE 2020, Melbourne, Australia.
IEEE, 2020,
pp. 784–796.

[9] N. Narodytska, S. P. Kasiviswanathan, L. Ryzhyk, M. Sagiv, and
T. Walsh, “Verifying Properties of Binarized Deep Neural Networks,”
in AAAI, 2018.

[10] Y. Cheng, D. Wang, P. Zhou, and T. Zhang, “A Survey of Model
Compression and Acceleration for Deep Neural Networks,” 2020.
[11] B. Paulsen, J. Wang, and C. Wang, “Reludiff: differential veriﬁcation of
deep neural networks,” in ICSE ’20: 42nd International Conference on
Software Engineering, Seoul, South Korea, G. Rothermel and D. Bae,
Eds. ACM, 2020, pp. 714–726.

[12] S. Bak, H.-D. Tran, K. Hobbs, and T. T. Johnson, “Improved Geometric
Path Enumeration for Verifying ReLU Neural Networks,” in Interna-
tional Conference on Computer Aided Veriﬁcation. Springer, 2020, pp.
66–96.

[13] I. Goodfellow, Y. Bengio, and A. Courville, Deep Learning. MIT Press,

2016, http://www.deeplearningbook.org.

[14] S. Bak, “nnenum: Veriﬁcation of relu neural networks with optimized
abstraction reﬁnement,” in NASA Formal Methods - 13th Interna-
tional Symposium, NFM 2021, Proceedings, A. Dutle, M. M. Moscato,
L. Titolo, C. A. Mu˜noz, and I. Perez, Eds., vol. 12673. Springer, 2021,
pp. 19–36.

[15] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning
applied to document recognition,” Proceedings of the IEEE, vol. 86,
no. 11, pp. 2278–2324, 1998.

[16] D. Dua and C. Graff, “UCI machine learning repository,” 2017. [Online].
Available: https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+
of+Handwritten+Digits

[17] G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural

network,” arXiv preprint arXiv:1503.02531, 2015.

APPENDIX

A. NN Equivalence and NP Completeness
Theorem ((cid:15)-NET-EQUIV is NP-complete). Let R, T be two
arbitrary ReLU NNs and let I be some common input space
of the two NNs. Determining whether ∃x ∈ I ∶ ∥gR (x) −
gT (x)∥p ≥ (cid:15) is NP-complete for any p-norm ∥⋅∥p.

Proof. Since all p-norms are equivalent up to some multiplica-
tive factor, we show this theorem for p = ∞. (cid:15) and d∗ can be
suitably modiﬁed for any other p.

We begin by showing that the problem is in NP. Assuming
a witness x for a given instance of (cid:15)-NET-EQUIV, we can
easily check whether the witness is violating the (cid:15) equivalence
property by computing ∥gR (x) − gT (x)∥∞.

Next, we demonstrate a reduction from NET-VERIFY to (cid:15)-
NET-EQUIV. An instance of NET-VERIFY is given by a con-
junction of linear constraints on the input (ψ1 (x)) and on the
output (ψ2 (y)) as well as a NN N . ψ (x, y) = ψ1 (x) ∧ ψ2 (y)
is said to be satisﬁable if there is an x such that N returns y
for input x and ψ (x, y) holds. Note that we can represent ψ1
and ψ2 as a matrices of linear constraints of the form:

C1x ≤ b1

C2y ≤ b2

Reusing N and denoting gN (x) as the output of N for input
x we can then construct a NN with the following outputs:

max (0, C1x − b1 + (cid:15))
max (0, C2gN (x) − b2 + (cid:15))
gN (x)

(3)

(4)

(5)

Equation (3) has as many dimensions as ψ1 has constraints and
Equation (4) has as many dimensions as ψ2 has constraints.
Note that outputs of both (3) and (4) are only larger 0 if an
assignment is closer than (cid:15) to a constraint or violates it.

We now make use of an additional ReLU gadget which

computes the non-negative maximum of two values:

relu max (a, b) = max (0, a + max (0, b − a))

We can then construct a pyramid of relu max gadgets on top
of (3) and (4) which outputs the maximum deviation dmax.
Note that this pyramid of maxima is polynomially bounded in
the problem size. dmax > (cid:15) iff there exists a constraint on in-
or output which is violated. This follows from the observation
that dmax > (cid:15) iff the maximum value of (3) and (4) is larger
than (cid:15). (3) and (4) contain a value larger than (cid:15) iff there is
some constraint (c, b) and some input i ∈ {x, y} such that:

ci − b + (cid:15) > (cid:15) ⇐⇒ ci > b

Conversely, dmax ≤ (cid:15) iff all constraints are satisﬁed. We now
deﬁne d∗ = max (0, 2(cid:15) − dmax) and our NN’s ﬁnal output is:
gN (x) + d∗
By checking (cid:15)-equivalence on N and the output deﬁned in
Equation (6) we can solve our original NET-VERIFY instance:

(6)

∥(gN (x) + d∗) − gN (x)∥∞ ≥ (cid:15)

⇐⇒ ∥d∗∥∞ ≥ (cid:15)
⇐⇒ 2(cid:15) − dmax ≥ (cid:15)
⇐⇒ (cid:15) ≥ dmax
⇐⇒ all constraints are satisﬁed

I.e. any input which violates (cid:15) equivalence, is a solution to
the NET-VERIFY instance. It follows that (cid:15)-NET-EQUIV is
NP-complete.

9

