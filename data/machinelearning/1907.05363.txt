0
2
0
2

t
c
O
6
2

]

M
Q
.
o
i
b
-
q
[

4
v
3
6
3
5
0
.
7
0
9
1
:
v
i
X
r
a

WARFARIN DOSE ESTIMATION ON MULTIPLE DATASETS WITH

AUTOMATED HYPERPARAMETER OPTIMISATION AND A NOVEL

SOFTWARE FRAMEWORK

A PREPRINT

Gianluca Truda
Department of Computer Science
University of Cape Town
Cape Town, South Africa
trdgia001@myuct.ac.za

Patrick Marais
Department of Computer Science
University of Cape Town
Cape Town, South Africa
patrick@cs.uct.ac.za

October 28, 2020

ABSTRACT

Warfarin is an effective preventative treatment for arterial and venous thromboembolism, but requires
individualised dosing due to its narrow therapeutic range and high individual variation. Many machine
learning techniques have been demonstrated in this domain. This study evaluated the accuracy of the
most promising algorithms on the International Warfarin Pharmacogenetics Consortium dataset and a
novel clinical dataset of South African patients. Support vectors and linear regression were amongst
the top performers in both datasets and performed comparably to recent stacked ensemble approaches,
whilst neural networks were one of the worst performers in both datasets. We also introduced genetic
programming to automatically optimise model architectures and hyperparameters without human
guidance. Remarkably, the generated models were found to match the performance of the best models
hand-crafted by human experts. Finally, we present a novel software framework (Warﬁt-learn) for
warfarin dosing research. It leverages the most successful techniques in preprocessing, imputation,
and parallel evaluation, with the goal of accelerating research and making results in this domain more
reproducible.

Keywords Warfarin · machine learning · genetic programming · Python · supervised learning · anticoagulant ·
pharmacogenetics · software

1

Introduction

Many individuals suffer from blood clots that lead to arterial and venous thromboembolism. The standard method for
treating these conditions is the use of anticoagulant drugs such as vitamin K antagonists, the most widely used of which
is warfarin. Whilst effective, the drug has a narrow therapeutic range and severe side-effects at extreme concentrations.
This makes the precise dosing of warfarin an important concern for clinicians. Unfortunately, warfarin metabolism
differs across individuals based on age, weight, genetics, diet, drug interactions, and various pre-existing conditions
[1, 2]. To standardise the process of anticoagulant monitoring, the World Health Organisation adopted the international

 
 
 
 
 
 
A PREPRINT - OCTOBER 28, 2020

normalised ratio (INR) [3]. INR has become the standard measurement for anticoagulation monitoring around the world
[4].

Many studies [5, 6, 7, 8, 9, 10, 11, 12] have looked at applying statistical models to the problem of individualised
warfarin dosing. Accurate models improve the ability of clinicians to prescribe the correct warfarin doses to their
patients, whilst minimising the time required to do so. They also reduce the risk of severe haemorrhaging in patients
and the number of visits required to establish a therapeutic dose [13, 14, 15]. Unfortunately, warfarin datasets are small
and noisy, requiring the use of specialised data transformations and highly-optimised learning algorithms. Breakthrough
techniques are of signiﬁcance to the medical research community and could lead to improvements in decision support
for those administering warfarin therapy.

The learning algorithm chosen to produce the dosing model has a notable impact on accuracy and robustness. Moreover,
the precise hyperparameters chosen for the algorithm can drastically affect performance.

Unfortunately, replicating the precise methodology of previous studies has proven difﬁcult, as the methods for
preprocessing, imputation, data stratiﬁcation, and evaluation vary. Moreover, these methods are typically described
textually, with open-sourced software implementations being unavailable prior to this study. We introduce a new
software framework (Warﬁt-learn) that implements the best available techniques. We validate the framework by using it
to compare a variety of established and novel algorithms on two different warfarin datasets.

1.1 Related work

1.1.1 International warfarin pharmacogenetics consortium (IWPC)

The seminal work in warfarin dose estimation with pharmacogenetic data made use of 5052 patient records from the
initial version of the dataset utilised by later studies [16]. Researchers split the dataset randomly with an 80/20 ratio
into derivation and validation sets. The study selected the two key metrics that would come to be used in almost all
future work – mean absolute error (MAE) and percentage of patients within 20% of the therapeutic dose (PW20). They
found that a multiple linear regression technique yielded better results than the existing clinical algorithms, with an
MAE of 8.5 ± 1.7 mg/week in the validation cohort [16].

1.1.2 Liu et al. 2015

A notable study is that of Liu et al. in 2015 [5], which compared the average performance of 9 learning algorithms on
the IWPC dataset [17]. They removed patients missing height, weight, age, or genotype data, and patients not at a stable
warfarin dose – leaving 4798 patients remaining. Using libraries in the R language, they implemented 9 algorithms.
They obtained the average performance of each algorithm in terms of PW20 and MAE with 100 rounds of 80/20
re-sampling from the ﬁltered dataset. The focus of their study was evaluating a range of off-the-shelf algorithms across
dosage ranges and racial groups, but their top results (PW20 = 46.35%, MAE = 8.84) in the combined cohort set an
initial benchmark for performance on the IWPC data. This result was achieved with a multivariate adaptive regression
splines algorithm, though the authors note that Bayesian additive regression trees and support vector machines were
also high-performing algorithms.

1.1.3 Ma et al. 2018

Another notable study is that of Ma et al. in late 2018 [12], which made advances using ensemble techniques and
improved imputation of missing data. Utilising the same IWPC dataset [17], Ma et al. imputed missing weight and
height values using a linear regression model. For imputing height, the variables were weight, race, and sex. For
imputing weight, they were height, race, and sex. They imputed missing values for the VKORC1 rs9923231 genotype
using the IWPC’s formula [18] based on race and linkage disequilibrium in VKORC1. Even after excluding outliers,
5743 subjects remained in the data set, resulting in a cohort nearly 20% greater than that of Liu et al. The raw warfarin

2

A PREPRINT - OCTOBER 28, 2020

dose was square rooted to compensate for the skewed distribution of the variable. The researchers made use of a stacked
generalisation (stacking) framework to implement heterogeneous ensembles. Results were obtained through 100 rounds
of 80/20 re-sampling. Their ﬁndings suggest that stacked generalisation ensembles are signiﬁcantly more accurate than
the existing isolated models on the IWPC dataset. Crucially, however, these high-performing stacked ensembles were
given extra input parameters that were not accessible to the other algorithms. In addition to the 11 common parameters
used in the IWPC and Liu et al. models [17, 5], their stacked ensembles included indicators for diabetes mellitus,
heart failure, valve replacement, use of statins, and additional VKORC1 genotypes. Despite acknowledging the use of
additional parameters in their methodology, the authors still claim to have performed a direct comparison. Although
they appear to have successfully utilised these additional parameters, the inconsistency of the methodology renders
their ﬁndings inconclusive. Considering that hyperparameter tuning was performed on the entire dataset, it is hard to
differentiate their reported accuracy improvements from possible overﬁtting effects. With our open-sourced Warﬁt-learn
framework, we hope to reduce the possibility of such inconsistencies in future work.

1.2 Model optimisation

The most common approach to model development is for an expert to repeatedly train models with various learning
algorithms and tweak their hyperparameters until performance is maximised. Ensemble methods – such as bagging,
boosting, and stacking – combine the outputs from several models to obtain better overall performance on unseen data.
This has been found to increase model performance in a number of warfarin dosing studies [5, 19, 8, 12]. Another
approach is the use of automatic machine learning (autoML), which employs meta-algorithms to automate the task of
optimisation.

In the past, autoML approaches have focused on optimising subsets of the machine learning pipeline [20]. Grid
search is a common form of hyperparameter optimisation based on a brute-force search of algorithm hyperparameters,
with the drawback of computational complexity. Conversely, random evaluation within the search space typically
discovers an effective hyperparameter set more quickly than exhaustive search [21]. A trade-off between the expensive
(but comprehensive) exhaustive search and the efﬁcient (but uncertain) random evaluation is desired. A well-known
approach to this trade-off is evolutionary algorithms. Indeed, the use of genetic programming – a subset of evolutionary
algorithms – has been found to produce better models than human experts in a number of tasks [22, 23, 24, 25, 26, 27].
This promising avenue to autoML was explored in our paper.

1.3 Genetic programming

Genetic programming emulates the process of natural selection as an optimisation strategy. In the context of this
study, the smallest components are machine learning algorithms and data processors. Each is encoded as a gene, with
parameters changing according to deﬁned mutation and crossover rates. As with biological evolution, successful genes
propagate through the population and the most successful combinations of those genes seed the next generation [28].
This increases performance over time. By simulating many generations with well-chosen evolutionary hyperparameters
and population sizes, novel meta-algorithms with high accuracy can be produced. Genetic programming has been
shown to develop effective systems in a number of mathematical and computational domains [24, 25, 26, 27].

This study made use of the open-sourced Tree-based Pipeline Optimisation Tool (TPOT) to generate high-performing
models through genetic programming [23]. The TPOT framework was developed atop the Distributed Evolutionary
Algorithms in Python framework [29]. Each individual in the population is a tree-based machine learning pipeline.
Each node in the tree is a pipeline operator, which can be (1) a preprocessor, (2) a decomposer, (3) a feature selector,
or (4) a supervised learning algorithm. All of these operators are based on Scikit-learn [30] implementations. These
pipelines handle the data from feature extraction through to hyperparameter optimisation. The pipeline operators (and
their parameters) are encoded as a gene sequence, which evolves through the genetic programming process [23].

3

A PREPRINT - OCTOBER 28, 2020

To prevent a tendency toward overly-complex pipelines, TPOT makes use of Pareto optimisation to optimise two
objectives simultaneously – maximising pipeline ﬁtness, whilst minimising pipeline complexity (measured as the
number of operators). Over many generations of evolution, TPOT’s implementation of the genetic programming
algorithm evolves the pipelines by adding new pipeline operators that improve ﬁtness, and by removing redundant
or detrimental pipeline operators. The ﬁttest overall pipeline is saved as the representative pipeline at the end of a
TPOT run [23]. In other domains, TPOT has been shown to produce a signiﬁcant improvement over basic machine
learning methods, with little involvement from users [23]. This study utilised TPOT to automatically evolve optimal
architectures and hyperparameters for warfarin dose estimation. The resulting estimators performed on par with those
manually optimised by machine learning experts.

2 Materials and methods

An illustration of the study’s methodology can be found in Figure 1 and highlights where our Warﬁt-learn software
framework was applied.

2.1 Datasets

Two datasets of warfarin records were used for this study. The standard IWPC dataset was used primarily for comparing
new techniques to those in existing literature, whilst a novel dataset from South Africa was used to evaluate how well
estimators generalised to a different clinical context and parameter set. Both datasets have similar distributions of
weekly warfarin dose, INR, and age (see Table 1).

The International Warfarin Pharmacogenetics Consortium (IWPC) dataset [17] of 6256 patients has been used in a
number of notable studies [5, 7, 16, 12] and is the standard reference point for new approaches to automated warfarin
dosing. The dataset was compiled collaboratively and includes data from 22 research groups from 9 countries [16]. The
dataset is publicly available at pharmgkb.org/downloads.

The novel dataset was provided by PathCare, a private pathology group in South Africa. Unlike the IWPC dataset, no
pharmacogenetic data is available and very limited clinical data is present. A total of 4621 patients from the dataset
achieved their target INR range and were considered in this study (see Table 1). As with the IWPC dataset, patients
were de-identiﬁed prior to distribution. To guarantee the conﬁdentiality of the data, only the authors had access to it
during the study. Ethical approval was obtained from the Science Research Ethics Committee at the University of Cape
Town and the project was sanctioned by the PathCare Research Committee. To protect the patients, the data is not
publicly available.

4

A PREPRINT - OCTOBER 28, 2020

Figure 1: An illustration of the methodology applied in this study, highlighting where our Warﬁt-learn software
framework was utilised and how a collection of estimators were evaluated across multiple datasets.

5

IWPC	DatasetPathCare	Dataset(pre-transformed)Warfit-learnPreprocessing,	imputation,	cleaningTPOTHyperparameter	and	architectureoptimisation	with	geneticprogramming	Group	all	evolved	estimators	(blue	and	orange)	together	with	the	best	learning	algorithmsfrom	previous	studies	(green)Warfit-learn100	rounds	of	parallel	Monte-Carlocross-validation	for	all	modelsacross	both	datasetsIWPC	ResultsPathCare	ResultsTable 1: Analysis of the characteristics of the International Warfarin Pharmacogenetics Consortium (IWPC) subjects
and subjects from a novel South African dataset (PathCare) included in this study.

A PREPRINT - OCTOBER 28, 2020

IWPC
5741

PathCare
4621

29.63
27.50
0.0 – 210.0
16.04

2.46
2.40
1.8 – 3.9
0.33

Size
Warfarin dose (mg/week)
31.97
Mean
28.0
Median
2.1 – 230.0
Range
Standard deviation
16.77
Therapeutic INR
Mean
Median
Range
Standard deviation
Age
10 - 19
20 - 29
30 - 39
40 - 49
50 - 59
60 - 69
70 - 79
80 - 89
90+
Sex
Females
Males
Missing

2.15
2.34
0.0 – 6.1
0.82
Count % Count %
0.0
15
0.7
130
2.3
249
6.0
580
10.6
1133
20.4
1401
24.7
1539
24.4
660
34
4.4
Count % Count %
2466
3275
0

2
31
106
276
490
942
1143
1127
204

0.3
2.3
4.3
10.1
19.7
24.4
26.8
11.5
0.6

2443
2178
0

43.0
57.0
0

52.9
47.1
0

Note: These are the cohorts after the preprocessing and imputation stages.

2.2 Data cleaning

For the IWPC dataset, this study replicated the work of Ma et al. [12] for ﬁltering the patient records into a viable
cohort. This was done to verify their approach and to provide a consistent methodology for performance comparisons.
The process is detailed in their paper and in the source code of this study. In this domain, missing data has typically
been handled by either dropping whole records [5] or imputing missing values [12, 11, 16]. Because the IWPC data is
limited in size, dropping missing values leads to signiﬁcant data loss and is detrimental to performance. This study
leveraged the most successful imputation techniques from previous work – missing values for VKORC1 rs9923231 were
imputed using the IWPC’s formula [18] based on race and linkage disequilibrium, whilst missing height and weight
were imputed with a regression model as per the work of Ma et al. [12]. This process is built into the Warﬁt-learn
preprocessing module.

2.3 Parameter selection

For the purposes of direct comparison to baseline, this study used the same parameter set deﬁned by the IWPC [17]
and utilised by Liu et al. [5]. For the PathCare dataset, three parameter sets were evaluated using standard regression
techniques. The top-performing parameter set was selected and used for further evaluation. This set included the sex
and age of the patients; as well as records of their aspirin, paracetamol, and amiodarone use; and their history of atrial
ﬁbrillation, deep vein thrombosis, and heart-valve replacement. All categorical parameters were vectorised into sparse
format so that the resulting feature set was purely numerical.

6

A PREPRINT - OCTOBER 28, 2020

Table 2: Continued: Analysis of the characteristics of the International Warfarin Pharmacogenetics Consortium (IWPC)
subjects and subjects from a novel South African dataset (PathCare) included in this study.
PathCare

IWPC

-
-
-
-

-
-
-
-

-
-
-
-

-
-
-
-

53.9
26.4
11.6
8.1

167.98
167.64
125 – 202
10.58

78.79
76.0
30 – 238
22.32
Count % Count %
3095
1515
665
466

Height (cm)
Mean
Median
Range
Standard deviation
Weight (kg)
Mean
Median
Range
Standard deviation
Race (OMB)
White
Asian
Black
Missing / mixed race
VKORC1 Genotype (Imputed) Count % Count %
A/A
A/G
G/G
Unknown
CYP2C9 Genotype
*1/*1
1/*2
1/*3
1/*5
1/*6
2/*2
2/*3
3/*3
Unknown
Indications
Enzyme inducer*
Amiodarone
Smoker

1695
2058
1884
104
Count % Count %
4230
755
482
0
0
58
68
20
128
Count % Count %
61
280
482

73.7
13.2
8.4
0.0
0.0
1.0
1.2
0.3
2.2

29.5
35.8
32.8
1.8

-
131
-

1.1
4.9
8.4

-
-
-
-
-
-
-
-
-

-
-
-
-
-
-
-
-
-

-
-
-
-

-
-
-
-

-
2.8
-

Notes: These are the cohorts after the preprocessing and imputation stages. The OMB racial categories were used in the
IWPC dataset and are deﬁned by the 1997 Ofﬁce of Management and Budget (OMB) standards for the U.S. Census
Bureau. * = carbamazepine, phenytoin, rifampin, rifampicin.

7

A PREPRINT - OCTOBER 28, 2020

2.4 Preprocessing

The input features were scaled prior to training using the Scikit-learn implementation of StandardScaler – which
scales the data to unit variance. This desensitised the algorithms to the magnitudes of features. In both datasets, the
weekly dose (in mg) was transformed to its square root in order to correct for the skewed distributions. This was then
set as the target feature during training. During evaluation, the model predictions were squared and compared with the
original values – maintaining clinical relevance. Warﬁt-learn provides the option to perform this rooting and squaring
automatically.

2.5 Learning algorithms used

A basic linear regression model – similar to that of the IWPC [16] – was required as a baseline for model performance.
This was compared against many of the best-performing algorithms described by Liu et al. [5] and Ma et al. [12]. All
algorithms were implemented using the Scikit-learn library [30] in Python 3, with the use of MLxtend [31] to implement
stacked ensembles. The implementation details and key hyperparameters can be found in Table 3. Additionally, a naïve
algorithm was implemented to establish a lower bound on what could be considered as legitimate modelling. This
algorithm simply learns the median of the training data and then predicts that value for all subsequent cases.

2.6 Clinical and statistical metrics

Appropriate metrics were chosen to assess both the clinical and statistical accuracy of the models. An important clinical
consideration is that INR has a therapeutic range of ±0.5 in most patients [32] and using tighter target ranges for
maintenance dosing does not achieve any therapeutic advantage [33]. The chosen metrics accounted for that, and were
consistent with metrics used in related studies – allowing direct results comparisons. Moreover, the use of multiple
metrics for performance (one clinically-relevant, the other statistically-relevant) is a worthwhile methodology to employ
as it prevents the kind of systemic overﬁtting that occurs in other domains where a single metric is dominant.

1. Mean absolute error (MAE) is used widely across warfarin estimation studies [5, 6, 7, 34, 8, 9, 10, 11, 12].

M AE =

(cid:80)n

i=1 |yi − ˆyi|
n

(1)

where yi is the actual dose and ˆyi is the predicted dose.

2. Percentage of patients with dose estimates within 20% of the actual therapeutic dose (PW20) was used
by a number of notable studies [16, 10, 9, 5, 12]. It reﬂects the fact that being within 0.5 points of the target
INR is clinically sufﬁcient [33].

i=1 f (pi)
n
where f (pi) for patient pi is 1 if 0.8yi < ˆyi < 1.2yi, else 0; ˆyi is the predicted dose, and yi is the true
therapeutic dose.

P W 20 =

× 100%

(2)

(cid:80)n

2.7 Evaluation protocol

Monte Carlo Cross-Validation (MCCV) was performed using the standard train_test_split function in Scikit-learn.
This performs resampling without replacement. All models were trained and evaluated using 100 iterations of MCCV
for each ﬁltered dataset. In each iteration, the data was randomly split into a training set and a testing set in an 80/20
ratio. The model was then ﬁt on the training set and evaluated in terms of PW20 and MAE on the testing set. The means
of these results and 95% conﬁdence intervals were calculated for each model on each dataset based on the percentile
method.

8

A PREPRINT - OCTOBER 28, 2020

.
]
2
1
[

.
l
a

t
e

a

M

f
o

y
g
o
l
o
d
o
h
t
e
m
e
h
t

r
e
p

s
a

,
e
m
a
n

e
m
a
s

e
h
t

f
o

s
r
o
t
a
m

i
t
s
e

e
n
o
l
a
d
n
a
t
s

e
h
t

s
a

s
r
e
t
e
m
a
r
a
p
r
e
p
y
h

e
m
a
s

e
h
t

d
a
h

s
e
l
b
m
e
s
n
e

d
e
k
c
a
t
s

e
h
t

n
i

d
e
s
u

s
r
o
t
a
m

i
t
s
e

e
h
T

=
N
N

,
s
e
e
r
t

d
e
t
s
o
o
b
-
t
n
e
i
d
a
r
g
=
T
B
G

,
s
e
e
r
t

n
o
i
s
s
e
r
g
e
r

d
e
t
s
o
o
b
=
T
R
B

,

n
o
i
s
s
e
r
g
e
r

e
g
d
i
r
=
R
R

,
)
n
o
i
s
s
e
r
g
e
r
(

r
o
t
c
e
v

t
r
o
p
p
u
s
=
)

(

R
V
S

,
n
o
i
s
s
e
r
g
e
r

r
a
e
n
i
l

)
e
l
p
i
t
l
u
m

(
=
R
L

e
r
o
m
n
o
i
t
a
t
n
e
m
e
l
p
m

i

c
i
r
e
n
e
g
a
g
n
i
w
o
l
l
o
f
(

R
V
S
d
n
a

)
n
o
i
t
a
t
n
e
m
e
l
p
m

i

.
l
a

t
e

a

M

e
h
t
g
n
i
w
o
l
l
o
f
(

V
S
n
e
e
w
t
e
b
s
e
c
n
e
r
e
f
f
i
d
n
o
i
t
a
t
n
e
m
e
l
p
m

i

t
h
g
i
l
s

e
h
t

e
t
o
N

.

k
r
o
w
t
e
n
l
a
r
u
e
n

)
.
l
a

t
e

u
i
L
f
o

t
a
h
t

o
t

r
a
l
i

m
i
s

.

y
d
u
t
s

s
i
h
t

n
i

d
e
r
a
p
m
o
c

e
r
e
w

t
a
h
t

]
2
1
[

.
l
a

t
e

a

M
d
n
a

,
]
5
[

.
l
a

t
e

u
i
L

,
]
6
1
[

C
P
W

I

e
h
t

f
o

k
r
o
w
e
h
t

g
n
i
t
a
c
i
l
p
e
r

s
m
h
t
i
r
o
g
l
a

g
n
i
n
r
a
e
L

:
3
e
l
b
a
T

’
s
g
f
b
l
’
=
r
e
v
l
o
s

,
’
c
i
t
s
i
g
o
l
’
=
n
o
i
t
a
v
i
t
c
a

,
)

,
0
0
1
(
=
s
e
z
i
s
_
r
e
y
a
l
_
n
e
d
d
i
h

5
=
v
c

,

R
R
=
r
o
s
s
e
r
g
e
r
_
a
t
e
m

,
}
N
N

,

R
R

,

T
B
G
{
=
s
r
o
s
s
e
r
g
e
r

5
=
v
c
V,
S
=
r
o
s
s
e
r
g
e
r
_
a
t
e
m

,
}
N
N
V,
S

,

T
B
G
{
=
s
r
o
s
s
e
r
g
e
r

r
o
s
s
e
r
g
e
R
V
C
g
n
i
k
c
a
t

S
.
r
o
s
s
e
r
g
e
r
.

d
n
e
t
x
l
m

r
o
s
s
e
r
g
e
R
V
C
g
n
i
k
c
a
t

S
.
r
o
s
s
e
r
g
e
r
.

d
n
e
t
x
l
m

r
o
s
s
e
r
g
e
R
P
L
M
.
k
r
o
w
t
e
n
_
l
a
r
u
e
n

.

n
r
a
e
l
k
s

0
0
1
=
s
r
o
t
a
m

i
t
s
e
_
n

,

1

.

0
=
e
t
a
r
_
g
n
i
n
r
a
e
l

,
’
s
e
r
a
u
q
s

t
s
a
e
l
’
=
s
s
o
l

r
o
s
s
e
r
g
e
R
g
n
i
t
s
o
o
B
t
n
e
i
d
a
r
G
.
e
l
b
m
e
s
n
e
.

n
r
a
e
l
k
s

4
=
h
t
p
e
d
_
x
a
m

,
’
d
a
l
’
=
s
s
o
l

,
1
.
0
=
e
t
a
r
_
g
n
i
n
r
a
e
l

r
o
s
s
e
r
g
e
R
g
n
i
t
s
o
o
B
t
n
e
i
d
a
r
G
.
e
l
b
m
e
s
n
e
.

n
r
a
e
l
k
s

’
e
v
i
t
i
s
n
e
s
n
i
_
n
o
l
i
s
p
e
’
=
s
s
o
l

,

0

.

1
=
C

,
1
0
0
0
.
0
=
l
o
t

,
0
.
0
=
n
o
l
i
s
p
e

0
0
0
1
=
e
z
i
s
_
e
h
c
a
c

,
’
r
a
e
n
i
l
’
=
l
e
n
r
e
k

0
.
1
=
a
h
p
l
a

e
g
d
i
R

.
l
e
d
o
m
_
r
a
e
n
i
l
.

n
r
a
e
l
k
s

R
V
S
r
a
e
n
i
L
m
v
s
.

.

n
r
a
e
l
k
s

R
V
S
m
v
s
.

.

n
r
a
e
l
k
s

e
u
r
T
=
t
p
e
c
r
e
t
n
i
_
t

ﬁ

,
e
s
l
a
F
=
e
z
i
l
a
m
r
o
n

n
o
i
s
s
e
r
g
e
R
r
a
e
n
i
L

.
l
e
d
o
m
_
r
a
e
n
i
l
.

n
r
a
e
l
k
s

V
S
_
d
e
k
c
a
t
S

R
R
_
d
e
k
c
a
t
S

R
V
S

R
L

V
S

R
R

T
R
B

T
B
G

N
N

s
r
e
t
e
m
a
r
a
p
r
e
p
y
h
y
e
K

n
o
i
t
a
t
n
e
m
e
l
p
m

I

e
m
a
N

9

A PREPRINT - OCTOBER 28, 2020

2.8 Warﬁt-learn software library

Extending past studies in warfarin dose prediction required the development of a host of data cleaning and preprocessing
tools, evaluation routines, and scoring functions. To remove the need for repeating this effort in future work, this study
implements a new software framework for Python-based development of warfarin dose estimation models. The aim
of this library is to allow researchers to more easily replicate and extend the work of their colleagues in this domain.
This can help to reduce confusion about methodology and enhance reproducibility. The library focuses on four areas,
namely:

1. Seamless dataset loading, cleaning, and preprocessing.

2. Standardised implementations of scoring functions.

3. Multithreaded model training and evaluation using standardised resampling techniques.

4. Full interoperability with the Python scientiﬁc stack [35], Pandas [36], and Scikit-learn [30].

This makes it possible to replicate studies on the IWPC data with only a beginner’s level of Python experience.
Supervised learning models can be constructed using the popular Scikit-learn implementations, which are handled
natively by the framework. Libraries that extend the Scikit suite – such as MLxtend [31] – can be used directly with
minimal conﬁguration. Parallel processing on a user-deﬁned number of CPU cores is used to achieve speedup on the
resampling performed during evaluation and is wrapped in a user-friendly function. Functions for metrics like percentage
of patients within 20% of therapeutic dose (PW20) are implemented and automatically called during evaluation. Final
results are produced as Pandas dataframes, which can be exported to CSV ﬁles or LaTeX tables with a single command.
The entire framework is available as open source software at http://pypi.org/project/warfit-learn under a
GNU GPLv3 license. All results for this study were obtained using the above tools in version 0.2 of Warﬁt-learn.

2.9 Optimisation with genetic programming

TPOT [23] was used to generate high-performing machine learning pipelines through genetic programming. In each
run, a preprocessed version of the dataset was given as input to TPOT and many generations of computation yielded the
best performers. TPOT accepts bespoke scoring functions as its evolutionary ﬁtness function. The functions for PW20
and MAE were trialled independently as ﬁtness functions. We also explored a combination of these metrics. Attempting
to both maximise PW20 and minimise MAE simultaneously would have transformed the task into a multi-objective
optimisation. A popular approach to overcome these complexities is scalarisation, which numerically combines
both objectives into a single optimisation function [37]. However, this requires a top-down deﬁnition of appropriate
weightings for both the PW20 and MAE. To avoid introducing additional hyperparameters, we deﬁned a new hybrid
function as the ratio of the maximised (PW20) to minimised (MAE) objectives:

hybrid =

PW20
MAE2

(3)

Because PW20 was encoded as a percentage, typical values were in the range [20, 50], whilst MAE was usually below
15. We thus squared the MAE denominator so that the two values would be more similar in range, whilst also boosting
the effects of variations in the error component.

Many instances of TPOT were run on a multi-core machine using different evolutionary hyperparameters. The number
of generations ranged from 50 to 1000, the number of offspring from 5 to 100, and the k used in k-fold cross-validation
from 5 to 30. Some runs used the raw weekly dose as the target feature and others used the square root of weekly dose.
Over all the instances run on both datasets, the best performers (according to ﬁnal validation scores within TPOT) were
evaluated against the human-optimised algorithms described in other studies.

10

A PREPRINT - OCTOBER 28, 2020

3 Results and discussion

The performance of all estimators is compared across datasets in Table 4. For easy comparison with previous studies,
the mean and 95% conﬁdence intervals are reported for both the MAE and PW20 metrics. In order to more clearly
illustrate and compare the distributions of the results, box plots are presented in Figure 2.

Figure 2: Box plots showing the distributions of all estimators after 100 rounds of MCCV evaluation on both the IWPC
(top row) and PathCare (bottom row) datasets. Each box marks the ﬁrst and third quartiles with a line at the median. The
whiskers extend to the full range of the data. Results outside 1.5 times the interquartile range are considered outliers and
marked with circles. The dotted vertical lines delineate the traditional algorithms, the stacked ensembles from Ma et al.
[12], the IWPC-optimised TPOT architectures, and the PathCare-optimised architectures. The dashed blue lines on the
PathCare plots (bottom row) indicate the mean performance of a naïve estimator. The axes are automatically scaled to
best illustrate the variation between estimators. BRT = boosted regression trees, GBT = gradient-boosted trees, LR =
(multiple) linear regression, NN = neural network, RR = ridge regression, SV(R) = support vector (regression). The
naïve estimator always predicted the median of the training data and was used as a lower bound on what is considered
genuine modelling. See the implementation details for each estimator in Table 3. Details of the pipelines generated by
TPOT can be found with the published source code for this project.

11

A PREPRINT - OCTOBER 28, 2020

p
u
o
r
g
h
c
a
e
n
i

s
r
e
m
r
o
f
r
e
p
t
s
e
b
e
h
t
h
t
i

w

,
s
t
e
s
a
t
a
d
)
e
r
a
C
h
t
a
P
(

l
e
v
o
n
d
n
a
C
P
W

I

e
h
t
h
t
o
b
n
o
n
o
i
t
a
u
l
a
v
e
V
C
C
M

f
o
s
d
n
u
o
r
0
0
1
r
e
t
f
a

s
r
o
t
a
m

i
t
s
e

l
l
a

f
o
s
t
l
u
s
e
R

:
4
e
l
b
a
T

.
d
e
s
i
s
a
h
p
m
e

e
r
a
C
h
t
a
P
n
o

d
e
v
l
o
v
E
=
†

.
t
e
s
a
t
a
d
C
P
W

I

n
o

d
e
v
l
o
v
E
=
*

.
]
6
1
[

y
d
u
t
s
C
P
W

I

l
a
n
i
m
e
s

e
h
t

y
b

d
e
n
ﬁ
e
d

s
a

,
a
t
a
d
C
P
W

I

e
h
t

r
o
f

t
e
s

r
e
t
e
m
a
r
a
p
e
m
a
s

e
h
t

d
e
s
i
l
i
t
u
s
r
o
t
a
m

i
t
s
e

R
L

,
s
e
e
r
t

d
e
t
s
o
o
b
-
t
n
e
i
d
a
r
g
=
T
B
G

,
s
e
e
r
t

n
o
i
s
s
e
r
g
e
r

d
e
t
s
o
o
b
=
T
R
B

.
e
s
o
d

y
l
k
e
e
w

f
o

t
o
o
r

e
r
a
u
q
s

g
n
i
s
u

t
e
s
a
t
a
d

e
r
a
C
h
t
a
P
n
o

d
e
v
l
o
v
E
=
‡

.
e
s
o
d

y
l
k
e
e
w
w
a
r

g
n
i
s
u

t
e
s
a
t
a
d

f
o

n
a
i
d
e
m
e
h
t

d
e
t
c
i
d
e
r
p

s
y
a
w
l
a

r
o
t
a
m

i
t
s
e

e
v
ï
a
n

e
h
T

.
)
n
o
i
s
s
e
r
g
e
r
(

r
o
t
c
e
v

t
r
o
p
p
u
s
=
)

(

R
V
S

,

n
o
i
s
s
e
r
g
e
r

e
g
d
i
r
=
R
R

,

k
r
o
w
t
e
n

l
a
r
u
e
n
=
N
N

,
n
o
i
s
s
e
r
g
e
r

r
a
e
n
i
l

)
e
l
p
i
t
l
u
m

(
=

e
h
t

f
o

s
l
i
a
t
e
D

.
3

e
l
b
a
T
n
i

r
o
t
a
m

i
t
s
e

h
c
a
e

r
o
f

s
l
i
a
t
e
d

n
o
i
t
a
t
n
e
m
e
l
p
m

i

e
h
t

e
e
S

.
g
n
i
l
l
e
d
o
m
e
n
i
u
n
e
g

d
e
r
e
d
i
s
n
o
c

s
i

t
a
h
w
n
o

d
n
u
o
b

r
e
w
o
l

a

s
a

d
e
s
u

s
a
w
d
n
a

a
t
a
d

g
n
i
n
i
a
r
t

e
h
t

l
l

A

.
s
l
a
v
r
e
t
n
i

e
c
n
e
d
ﬁ
n
o
c
%
5
9

h
t
i

w
s
n
a
e
m
s
a
d
e
d
i
v
o
r
p

e
r
a

s
e
u
l
a
V

.
e
s
o
d

c
i
t
u
e
p
a
r
e
h
t

f
o
%
0
2

n
i
h
t
i

w
s
t
n
e
i
t
a
p

f
o

e
g
a
t
n
e
c
r
e
p
=
0
2
W
P

.
r
o
r
r
e

e
t
u
l
o
s
b
a
n
a
e
m
=
E
A
M

.
t
c
e
j
o
r
p

s
i
h
t

r
o
f

e
d
o
c

e
c
r
u
o
s

d
e
h
s
i
l
b
u
p

e
h
t

h
t
i

w
d
n
u
o
f

e
b
n
a
c
T
O
P
T
y
b

d
e
t
a
r
e
n
e
g

s
e
n
i
l
e
p
i
p

)
2
5

.

1
1
–
0
4
0
1
(

.

)
0
6

.

1
1
–
7
3
0
1
(

.

)
7
6

.

1
1
–
9
3
0
1
(

.

)
7
6

.

1
1
–
6
5
0
1
(

.

)
3
5

.

1
1
–
5
4
0
1
(

.

)
5
4

.

1
1
–
6
3
0
1
(

.

)
0
6

.

1
1
–
3
3
0
1
(

.

)
4
5

.

1
1
–
9
3
0
1
(

.

)
7
5

.

1
1
–
6
2
0
1
(

.

)
6
6

.

1
1
–
8
5
0
1
(

.

)
9
6

.

1
1
–
4
4
0
1
(

.

)
3
5

.

1
1
–
9
4
0
1
(

.

9
9
0
1

.

9
9
0
1

.

8
9
0
1

.

7
0
1
1

.

8
9
0
1

.

3
9
0
1

.

5
9
0
1

.

5
9
0
1

.

3
9
0
1

.

5
0
1
1

.

1
0
1
1

.

3
0
1
1

.

)
7
2
.
6
3
–
9
1
.
1
3
(

)
0
6
.
6
3
–
2
4
.
0
3
(

)
2
8
.
6
3
–
1
8
.
0
3
(

)
4
1
.
7
3
–
9
1
.
1
3
(

)
2
9
.
6
3
–
9
1
.
1
3
(

)
1
8
.
6
3
–
8
8
.
1
3
(

)
4
1
.
7
3
–
7
7
.
1
3
(

)
5
5
.
6
3
–
6
8
.
0
3
(

)
2
6
.
7
3
–
8
7
.
1
3
(

)
4
5
.
6
3
–
9
2
.
1
3
(

)
9
4
.
6
3
–
3
8
.
1
3
(

)
5
8
.
5
3
–
3
0
.
1
3
(

1
6
.
3
3

5
3
.
3
3

8
0
.
4
3

9
7
.
3
3

9
9
.
3
3

0
4
.
4
3

6
4
.
4
3

3
8
.
3
3

5
4
.
4
3

5
6
.
3
3

1
9
.
3
3

3
5
.
3
3

)
8
1
.
9
–
5
3
.
8
(

)
7
0
.
9
–
2
3
.
8
(

)
5
0
.
9
–
1
1
.
8
(

)
0
8
.
9
–
0
9
.
8
(

)
3
0
.
9
–
6
1
.
8
(

)
6
9
.
8
–
2
1
.
8
(

)
0
0
.
9
–
5
0
.
8
(

)
4
1
.
9
–
9
1
.
8
(

)
9
9
.
8
–
1
2
.
8
(

)
6
0
.
9
–
7
1
.
8
(

)
6
0
.
9
–
6
1
.
8
(

)
2
0
.
9
–
4
1
.
8
(

5
7
.
8

7
6
.
8

9
5
.
8

6
3
.
9

7
5
.
8

8
5
.
8

8
5
.
8

3
6
.
8

5
5
.
8

1
6
.
8

9
5
.
8

6
5
.
8

)
0
7
.
7
4
–
7
4
.
2
4
(

)
4
7
.
9
4
–
3
7
.
3
4
(

)
2
2
.
8
4
–
8
3
.
3
4
(

)
7
8
.
5
4
–
9
6
.
0
4
(

)
0
3
.
8
4
–
3
3
.
3
4
(

)
4
7
.
8
4
–
7
0
.
4
4
(

)
3
1
.
9
4
–
0
6
.
4
4
(

)
0
3
.
8
4
–
9
2
.
3
4
(

)
8
4
.
8
4
–
1
8
.
3
4
(

)
6
2
.
8
4
–
3
0
.
3
4
(

)
3
8
.
8
4
–
6
5
.
3
4
(

)
3
5
.
8
4
–
3
7
.
3
4
(

2
3
.
5
4

1
3
.
6
4

9
9
.
5
4

2
1
.
3
4

6
9
.
5
4

1
4
.
6
4

6
5
.
6
4

1
0
.
6
4

2
3
.
6
4

3
0
.
6
4

3
0
.
6
4

8
0
.
6
4

)
8
9

.

1
1
–
5
7
0
1
(

.

9
2

.

1
1

)
5
7
.
5
3
–
2
3
.
0
3
(

6
8
.
2
3

)
8
8
.
9
–
3
9
.
8
(

8
3
.
9

)
8
8
.
5
4
–
5
5
.
0
4
(

9
0
.
3
4

)
9
2

.

2
1
–
3
0
1
1
(

.

3
6

.

1
1

)
9
9
.
4
3
–
2
6
.
9
2
(

2
3
.
2
3

)
3
9

.

1
1
–
4
7
0
1
(

.

5
3

.

1
1

)
0
2
.
5
3
–
5
9
.
9
2
(

7
3
.
2
3

)
5
9

.

1
1
–
3
8
0
1
(

.

9
3

.

1
1

)
5
2
.
5
3
–
1
2
.
0
3
(

3
5
.
2
3

)
7
0

.

2
1
–
0
8
0
1
(

.

3
3

.

1
1

)
9
8

.

1
1
–
5
7
1
1
(

.

2
8
1
1

.

)
1
4
.
5
3
–
3
8
.
9
2
(

7
6
.
2
3

)
1
6
.
7
2
–
0
1
.
7
2
(

5
3
.
7
2

)
7
1
.
0
1
–
7
0
.
9
(

9
5
.
9

)
6
8
.
0
1
–
8
2
.
9
(

6
9
.
9

)
8
5
.
0
1
–
5
0
.
9
(

4
6
.
9

)
9
8
.
9
–
9
9
.
8
(

3
4
.
9

)
0
5
.
2
1
–
9
3
.
2
1
(

5
4
.
2
1

)
0
3
.
4
4
–
9
1
.
8
3
(

4
4
.
1
4

)
8
7
.
3
4
–
8
3
.
6
3
(

4
5
.
0
4

)
2
9
.
4
4
–
8
6
.
8
3
(

5
7
.
1
4

)
0
6
.
5
4
–
4
6
.
0
4
(

2
8
.
2
4

)
5
3
.
4
3
–
5
8
.
3
3
(

0
1
.
4
3

R
R
_
d
e
k
c
a
t
S

V
S
_
d
e
k
c
a
t
S

*
A
T
O
P
T

*
B
T
O
P
T

*
C
T
O
P
T

†

D
T
O
P
T

†
E
T
O
P
T

†
F
T
O
P
T

‡

G
T
O
P
T

‡

H
T
O
P
T

e
v
ï
a
N

T
R
B

T
B
G

R
L

N
N

R
R

V
S

R
V
S

t
e
s
a
t
a
D
e
r
a
C
h
t
a
P

t
e
s
a
t
a
D
C
P
W

I

)
I
C
%
5
9
(

E
A
M

)
I
C
%

5
9
(

0
2

W
P

)
I
C
%

5
9
(

E
A
M

)
I
C
%

5
9
(

0
2

W
P

r
o
t
a
m

i
t
s
E

12

A PREPRINT - OCTOBER 28, 2020

3.1 Validation of methodology

The methodology of this study was validated by referencing the results of previous work on warfarin dose estimation.
The original IWPC study reported an MAE of 8.5 mg/week (95% CI: 8.1–8.6) for their linear regression (LR) model
[16]. However, they processed the cohort differently.

The study by Ma et al. evaluated models on an identical dataset to our study, reporting an MAE of 8.53 (95% CI:
8.08–8.99) for their LR model [12]. By comparison, the MAE for the LR model in this study was 8.59 mg/week (95%
CI: 8.11–9.05). This indicates that our preprocessing and evaluation methodology were valid. It also justiﬁes the
original IWPC ﬁnding that, when adequate preprocessing is performed, linear regression produces outstanding results
on the IWPC dataset [16]. This, coupled with its easy interpretability, makes LR hard to rule out as the default warfarin
estimation model. However, as datasets grow in size and variety, LR can fail to model some relationships that more
complex approaches succeed in capturing. It also tends to be less robust to outliers than ensemble approaches [38],
which could challenge its clinical applicability.

The shapes of the performance distributions in Figure 2 are quite symmetric and consistent with normal distributions,
which afﬁrms the use of conﬁdence intervals based on the percentile method. Despite some large differences in average
performance over the 100 resamplings, the distributions still overlap considerably, highlighting how much performance
can vary depending on the speciﬁc patients in the training and testing sets. With few exceptions, the ranges of PW20
and MAE scores for even the most consistent algorithms were considerably greater than the differences between the
mean scores, suggesting that both datasets have a high degree of inter-patient variation that is unaccounted for in the
available parameters.

The purpose of mirroring our methodology on the PathCare dataset was to evaluate how well the estimators generalise
to a different clinical context and parameter set. The relationships of the IWPC results are certainly reﬂected in the
PathCare results, both in terms of relative scores (Table 4) and variance (Figure 2). However, they are much less
pronounced.

To verify that effective modelling took place, we made use of a naïve estimator that simply predicted the median of its
training set for each resampling. On the IWPC dataset, it had a PW20 of 34.10 (95% CI: 33.85–34.35) and an MAE of
12.45 (95% CI: 12.39–12.50), making it the lowest performer by a considerable amount. On the PathCare dataset, it
achieved a PW20 of 27.35 (95% CI: 27.10–27.61) and an MAE of 11.82 (95% CI: 11.75–11.89). The other estimators
only marginally outperformed the naïve baseline on the PathCare dataset in terms of MAE, but well outperformed
it in terms of PW20 – the clinically-relevant metric. This afﬁrms that even a limited number of clinical parameters
are sufﬁcient for the estimators to learn some relationships from the data and make meaningful predictions. For the
PathCare dataset, the mean performance of the naïve baseline is overlaid in the box plots of Figure 2 for visual reference.

3.2 Performance of traditional techniques

Support vector regression (SV and SVR) was a top-performing algorithm, whilst the neural network (NN) was one of
the worst performing algorithms. The relative performance of the NN and SVR models was similar to that reported by
Liu et al. [5]. Their NN (MAE 9.82, PW20 41.27) was by far their worst performer, whilst their SVR (MAE 8.96, PW20
45.88) was one of their best performers. Similarly, this study’s NN (MAE 9.36, PW20 43.12) was the worst-performing
standalone algorithm by a considerable margin, whilst our SVR (MAE 8.58, PW20 46.56) was the best.

Unlike most statistical models, neural networks are considered to be good at learning feature representations automati-
cally, which is especially useful when there are many features. The IWPC dataset has very few parameters compared
to typical deep learning datasets. Moreover, these parameters are heavily-engineered during the preprocessing stage,
which likely minimises any effects of the representation learning. It is also widely held that NN performance scales
with the size of the dataset and the number of hidden layers [39]. Because the IWPC dataset contains very few records

13

A PREPRINT - OCTOBER 28, 2020

(by deep learning standards) using more than one hidden layer has little-to-no effect. These factors may explain why
the NN consistently failed to perform on both datasets.

Our results replicate the ﬁndings of Ma et al. [12] for LR, SV, and ridge regression (RR) algorithms, with very similar
conﬁdence intervals. But, despite replicating the implementations outlined in their methodology, our results for NN,
gradient boosting trees (GBT), Stacked SV, and Stacked RR were notably dissimilar. In the case of the ensemble
estimators, this was likely due to their decision to use a much larger parameter set on their stacked implementations
than they fed to other models. In contrast, our study made use of the same parameter set across all estimators (as
standardised by notable previous works [16, 5]). Another factor may have been the difference in GBT implementations
(Scikit-learn vs. LightGBM) between studies. This discrepancy once again afﬁrms the need for a standardised set of
tools for replicating and evaluating warfarin dosing models.

Despite the difference in absolute scores between studies, the stacked ensembles were still among the top performers on
the IWPC data, with the Stacked SV in particular achieving an MAE of 8.55 and a PW20 of 46.32. This supports the
use of the stacked generalisation approach to improve warfarin dose estimation. However, with a much smaller effect
size than Ma et al. reported, it may be difﬁcult to justify the use of these techniques over the more-explainable linear
regression model in clinical deployment.

Despite the absence of pharmacogenetic data and many clinical parameters in the PathCare dataset, the traditional
algorithms performed reasonably well. LR (MAE 10.98, PW20 34.08) and SV (MAE 10.93, PW20 34.40) topped
the list, along with the Stacked SV ensemble (MAE 10.93, PW20 34.45). However, there was very little difference in
performance on the PathCare dataset amongst the traditional algorithms. The range of the distributions were also much
wider on the PathCare dataset than the IWPC dataset (see Figure 2). The fact that all the estimators still outperformed
the naïve baseline indicates that there were indeed predictive relationships to be found in the PathCare dataset, but it
seems that the precise choice of algorithm was of much less importance with so few parameters available. Algorithms
with higher bias, like LR and SV, performed marginally better, whereas algorithms with lower bias, like the ensembles,
appear to have generalised less well.

3.3 Performance of evolved architectures

The architectures developed using a genetic programming approach (TPOT) had extremely varied results depending on
which dataset they were evolved on. TPOT C was an estimator pipeline evolved on the IWPC dataset that produced
the best results of the evolved models (MAE 8.56, PW20 46.08). It was only marginally outperformed by the SV and
Stacked SV approaches (with highly similar CIs), but outperformed the Stacked RR estimator on the IWPC dataset.
The structure and hyperparameters of the estimator are illustrated in Figure 3.

Architectures evolved on the IWPC dataset (A, B, and C) performed well on the IWPC dataset, with almost identical
distributions. This is remarkable when considering that they were generated with no human tuning. It is also notable
that three different evolutionary histories converged to have such consistent performance. This result concurs with
previous ﬁndings [22, 23] that autoML can attain results comparable to those of models engineered by experts with
domain knowledge.

Generally, the TPOT architectures that performed well on the IWPC data also performed well on the PathCare data.
This could indicate that the IWPC dataset captures sufﬁcient information about the parameter-target relationships to
generalise, but may also be a result of limitations in the PathCare dataset.

14

A PREPRINT - OCTOBER 28, 2020

Figure 3: Illustration of the highest-performing architecture and hyperparameters evolved on the IWPC dataset using
TPOT. The Python implementation of this architecture can be found along with the project source code.

The architectures evolved on the PathCare dataset (D through H) performed signiﬁcantly worse than those evolved on the
IWPC dataset (A through C) regardless of which dataset they were trained and evaluated on. Moreover, the distributions
of results were much wider, indicating low generalisation. These performance differences are best illustrated by the
jarring shift in distributions seen in the top row of Figure 2. These results suggest that the PathCare dataset has a
lower ratio of signal to noise compared to the IWPC dataset and support prior claims [40, 41, 42] that pharmacogenetic
parameters yield more generalised models.

All but one of the architectures evolved with TPOT utilised stacking at some point in their pipelines. This may reﬂect
a general tendency within the TPOT implementation but, when considered with the high performance of Ma et al.’s
stacked ensembles, may indicate the robustness of stacking for warfarin dose estimation. Only TPOT C (the best overall)
and TPOT E included SVR in their pipelines. This is strange considering the high level of performance seen with SVR
across both datasets. TPOTs B and C (high performers on the IWPC dataset) made use of trees (with boosting) and/or
lasso regression. TPOTs D-H (evolved on PathCare) all relied on a KNN regressor somewhere in their pipeline, but
performed poorly across datasets.

15

LinearSVRElasticNetCVRobustScalerRidgeCVExtraTreesRegressorC=1.0,dual=True,									epsilon=0.01,loss="epsilon_insensitive",tol=0.001l1_ratio=0.6,tol=0.01,cv=5bootstrap=True,max_features=1.0,min_samples_leaf=20,min_samples_split=2,n_estimators=100with_centering=True,with_scaling=True,quantile_range=(25.0,	75.0)alphas=(0.1,	1.0,	10.0),fit_intercept=True,normalize=FalseDosage	EstimationPreprocessed	dataA PREPRINT - OCTOBER 28, 2020

3.4 Limitations

The IWPC dataset was compiled by 22 research groups, each with different protocols and equipment. This resulted in
noisy data and some missing values, which lower the predictive accuracy of models. It is also known that the impact
of CYP2C9 and VKORC1 genes varies across races [5]. Current pharmacogenetic data is mostly derived from White
and Asian OMB racial groups in developed nations (where genetic testing is available), so it is likely that current
pharmacogenetic implementations impart bias upon models.

The PathCare dataset did not include clinical information such as height, weight, and race – all of which have been
shown to improve dosing accuracy. It would, therefore, be imprudent to extrapolate very much from the performance
differences of models on this dataset. Nevertheless, it served as a useful validation that top-performing algorithms can
generalise to novel clinical contexts with different parameter sets. Because of these different parameters, it was not
possible to directly train models on one dataset and evaluate their performance on another. It was, however, possible to
evolve the architectures and hyperparameters on one dataset and then train and evaluate models on the other dataset –
which was done and is presented in Table 4 and Figure 2.

There are also technical limitations in the performance of the genetic programming tools. As Olson et al. point out
themselves, TPOT becomes quite slow as the size of a dataset increases. Even on the tiny (by machine learning
standards) IWPC dataset, a single run could take days to complete. There are plans to integrate other autoML libraries
and heuristics to seed the populations with strong pipelines and reduce the number of computations to convergence [23].
Additionally, the use of highly-parallel hardware, such as graphics processing units (GPUs), offers enormous potential
for speedup in execution. Because TPOT is built atop the popular, open-source Scikit-learn framework, it beneﬁts
from modularity and standardisation. Both the H2O4GPU project and Nvidia’s cuML suite mirror the Scikit-learn
interface, but move computations to the GPU. At the time of writing, there is at least one ongoing project to bring this
functionality into TPOT.

Unlike linear regression, the other models do not produce human-interpretable formulae for clinical warfarin dosing.
However, trained models could be used to run inference on real patient data and produce dosage recommendations
to help guide clinicians. Further work is needed to produce robust models that can be deployed as decision-support
systems in a clinical context.

4 Conclusions

This study presented the Warﬁt-learn software framework, which implements the best published techniques for warfarin
dosage modelling. The framework was validated by replicating the results of several prior studies on the same IWPC
dataset. Warﬁt-learn’s parallel evaluation methodology was utilised to compare the performance of several estimators
across both the IWPC dataset and a novel dataset of South African patients provided by PathCare. The estimators
included traditional learning algorithms that have shown promise in warfarin dosing, two stacked generalisation
ensembles described in previous work, and a collection of learning pipelines evolved using a genetic programming
approach to architecture and hyperparameter optimisation.

As in previous studies, linear regression was shown to be a reliable technique. Support vector regression was the best
performing traditional algorithm, whilst neural networks performed poorly. Recent ensemble approaches – namely
stacked generalisation – were shown to be effective across datasets, but the effect size was not as large as previously
reported.

This study found that genetic programming was effective at evolving robust architectures and hyperparameters for
warfarin dosage modelling. All three of the estimators evolved on the IWPC dataset were amongst the top-performing
models, performing on par with the best expert-designed ensembles. Inspection of the architectures revealed a preference
for stacked ensembles. If these results are not unique to warfarin dosing, they suggest that automated machine learning
may be a promising method for the future of software-assisted dosing. These ﬁndings should be explored on other

16

A PREPRINT - OCTOBER 28, 2020

dosage estimation problems in future work. Other advances in this domain can be made by compiling comprehensive
warfarin dosing datasets from more diverse cohorts, and using them to train robust models for safe clinical deployment.

In addition to the performance comparisons and evolutionary optimisation techniques, this paper presented a much-
needed software framework for evaluating new techniques on the IWPC dataset. Warﬁt-learn eliminates the need for
future researchers to re-create tools, and maintains consistency by providing a standardised testbed. It is our hope that
Warﬁt-learn will make future studies signiﬁcantly easier and more reproducible.

References

[1] Daniel E. Jonas and Howard L. McLeod. Genetic and clinical factors relating to warfarin dosing. Trends in

Pharmacological Sciences, 30(7):375–386, 2009.

[2] P S Wells, A M Holbrook, N R Crowther, and J Hirsh. Interactions of warfarin with drugs and food, nov 1994.

[3] T B L Kirkwood and S M Lewis. Requirements for thromboplastins and plasma used to control oral anticoagulant

therapy. WHO Tech Rep Ser, 687:81–99, 1983.

[4] L. Poller. International Normalized Ratios (INR): The ﬁrst 20 years. Journal of Thrombosis and Haemostasis,

2(6):849–860, 2004.

[5] Rong Liu, Xi Li, Wei Zhang, and Hong Hao Zhou. Comparison of nine statistical model based warfarin
pharmacogenetic dosing algorithms using the racially diverse international warfarin pharmacogenetic consortium
cohort database. PLoS ONE, 10(8), 2015.

[6] Yu Liu, Jie Yang, Qiang Xu, Bin Xu, Lei Gao, Yuxiao Zhang, Yan Zhang, Hongjuan Wang, Caiyi Lu, Yusheng
Zhao, and Tong Yin. Comparative performance of warfarin pharmacogenetic algorithms in Chinese patients.
Thrombosis Research, 130(3):435–440, 2012.

[7] Ashkan Sharabiani, Adam Bress, Elnaz Douzali, and Houshang Darabi. Revisiting warfarin dosing using machine

learning techniques. Computational and Mathematical Methods in Medicine, 2015, 2015.

[8] Ya Han Hu, Fan Wu, Chia Lun Lo, and Chun Tien Tai. Predicting warfarin dosage from clinical data: A supervised

learning approach. Artiﬁcial Intelligence in Medicine, 56(1):27–34, 2012.

[9] Qin Zhou, Joey Kwong, Jie Chen, Wenzhe Qin, Jin Chen, and Li Dong. Use of artiﬁcial neural network to predict
warfarin individualized dosage regime in Chinese patients receiving low-intensity anticoagulation after heart valve
replacement. International Journal of Cardiology, 176(3):1462–1464, oct 2014.

[10] Enzo Grossi, Gian Marco Podda, Mariateresa Pugliano, Silvia Gabba, Annalisa Verri, Giovanni Carpani, Massimo
Buscema, Giovanni Casazza, and Marco Cattaneo. Prediction of optimal warfarin maintenance dose using
advanced artiﬁcial neural networks. Pharmacogenomics, 15(1):29–37, jan 2014.

[11] Ashkan Sharabiani, Houshang Darabi, Adam Bress, Larisa Cavallari, Edith Nutescu, and Katarzyna Drozda.
Machine learning based prediction of warfarin optimal dosing for African American patients. In Automation
Science and Engineering (CASE), 2013 IEEE International Conference on, pages 623–628, 2013.

[12] Zhiyuan Ma, Ping Wang, Zehui Gao, Ruobing Wang, and Koroush Khalighi. Ensemble of machine learning
algorithms using the stacked generalization approach to estimate the warfarin dose. Plos One, 13(10):e0205872,
2018.

[13] Leon Poller, M. Keown, S. Ibrahim, G. Lowe, M. Moia, A. G. Turpie, C. Roberts, A. M.H.P. Van Den Besselaar,
F. J.M. Van Der Meer, A. Tripodi, G. Palareti, C. Shiach, S. Bryan, M. Samama, M. Burgess-Wilson, A. Heagerty,
P. Maccallum, D. Wright, and J. Jespersen. An international multicenter randomized study of computer-assisted
oral anticoagulant dosage vs. medical staff dosage. Journal of Thrombosis and Haemostasis, 6(6):935–943, jun
2008.

17

A PREPRINT - OCTOBER 28, 2020

[14] S. McDonald, C. Xydeas, and P. Angelov. A retrospective comparative study of three data modelling techniques in
anticoagulation therapy. BioMedical Engineering and Informatics: New Development and the Future - Proceedings
of the 1st International Conference on BioMedical Engineering and Informatics, BMEI 2008, 1:219–225, 2008.

[15] Y. K. Kim, R. Nieuwlaat, S. J. Connolly, S. Schulman, K. Meijer, N. Raju, S. Kaatz, and J. W. Eikelboom. Effect
of a simple two-step warfarin dosing algorithm on anticoagulant control as measured by time in therapeutic range:
A pilot study. Journal of Thrombosis and Haemostasis, 8(1):101–106, 2010.

[16] B.F. Klein, T.E., Altman, R.B., Eriksson. Estimation of the Warfarin Dose with Clinical and Pharmacogenetic

Data. Archives of Internal Medicine, 360(8):753–764, 2009.

[17] M Whirl-Carrillo, EM McDonogh, J Herbet, L Gong, K Sangkuhl, C Thotn, R Altman, and E Klein. Pharma-
cogenomics Knowledge for Personlized Medicine. Clinical Pharmacology and Therpeutics, 92(4):414–417,
2012.

[18] B.F. Klein, T.E., Altman, R.B., Eriksson. Supplement to: The International Warfarin Pharmacogenetics Consortium.
Estimation of the warfarin dose with clinical and pharmacogenetic data. Journal of Medicine (Cincinnati), 2006.

[19] Erdal Cosgun, Nita A. Limdi, and Christine W. Duarte. High-dimensional pharmacogenetic prediction of a
continuous trait using machine learning techniques with application to warfarin dose prediction in African
Americans. Bioinformatics, 27(10):1384–1389, 2011.

[20] Frank Hutter, Jörg Lücke, and Lars Schmidt-Thieme. Beyond manual tuning of hyperparameters. KI-Künstliche

Intelligenz, 29(4):329–337, 2015.

[21] James Bergstra and Yoshua Bengio. Random search for hyper-parameter optimization. Journal of Machine

Learning Research, 13(Feb):281–305, 2012.

[22] Jason Zutty, Daniel Long, Heyward Adams, Gisele Bennett, and Christina Baxter. Multiple objective vector-based
genetic programming using human-derived primitives. In Proceedings of the 2015 Annual Conference on Genetic
and Evolutionary Computation, pages 1127–1134. ACM, 2015.

[23] Randal S Olson, Nathan Bartley, Ryan J Urbanowicz, and Jason H Moore. Evaluation of a Tree-based Pipeline
Optimization Tool for Automating Data Science. In Proceedings of the Genetic and Evolutionary Computation
Conference 2016, GECCO ’16, pages 485–492, New York, NY, USA, 2016. ACM.

[24] Gregory S Hornby, Jason D Lohn, and Derek S Linden. Computer-automated evolution of an X-band antenna for

NASA’s space technology 5 mission. Evolutionary computation, 19(1):1–23, 2011.

[25] Erik M Fredericks and Betty H C Cheng. Exploring automated software composition with genetic programming.
In Proceedings of the 15th annual conference companion on Genetic and evolutionary computation, pages
1733–1734. ACM, 2013.

[26] Stephanie Forrest, ThanhVu Nguyen, Westley Weimer, and Claire Le Goues. A genetic programming approach to
automated software repair. In Proceedings of the 11th Annual conference on Genetic and evolutionary computation,
pages 947–954. ACM, 2009.

[27] Lee Spector, David M Clark, Ian Lindsay, Bradford Barr, and Jon Klein. Genetic programming for ﬁnite algebras.
In Proceedings of the 10th annual conference on Genetic and evolutionary computation, pages 1291–1298. ACM,
2008.

[28] Wolfgang Banzhaf, Peter Nordin, Robert E Keller, and Frank D Francone. Genetic programming: an introduction,

volume 1. Morgan Kaufmann San Francisco, 1998.

[29] Félix-Antoine Fortin, François-Michel De Rainville, Marc-André Gardner, Marc Parizeau, and Christian Gagné.

DEAP: Evolutionary algorithms made easy. Journal of Machine Learning Research, 13(Jul):2171–2175, 2012.

[30] F Pedregosa, G Varoquaux, A Gramfort, V Michel, B Thirion, O Grisel, M Blondel, P Prettenhofer, R Weiss,
V Dubourg, J Vanderplas, A Passos, D Cournapeau, M Brucher, M Perrot, and E Duchesnay. Scikit-learn: Machine
Learning in Python. Journal of Machine Learning Research, 12:2825–2830, 2011.

18

A PREPRINT - OCTOBER 28, 2020

[31] Sebastian Raschka. MLxtend: Providing machine learning and data science utilities and extensions to Python’s

scientiﬁc computing stack. The Journal of Open Source Software, 3(24), apr 2018.

[32] G. W. Albers, J. E. Dalen, A. Laupacis, W. J. Manning, P. Petersen, and D. E. Singer. Antithrombotic therapy in

atrial ﬁbrillation. Chest, 119(1 SUPPL.), 2001.

[33] D. J. Meier, S. Seva, and William P. Fay. A comparison of anticoagulation results of patients managed with
narrow vs. standard international normalized ratio target ranges [6]. Journal of Thrombosis and Haemostasis,
5(6):1332–1334, 2007.

[34] S. L. Tan, Z. Li, G. B. Song, L. M. Liu, W. Zhang, J. Peng, T. Zhang, F. F. Jia, G. Zhou, H. H. Zhou, and X. M.
Zhou. Development and comparison of a new personalized warfarin stable dose prediction algorithm in Chinese
patients undergoing heart valve replacement. Pharmazie, 67(11):930–937, 2012.

[35] K. Jarrod Millman and Michael Aivazis. Python for Scientists and Engineers. Computing in Science & Engineering,

13(2):9–12, mar 2011.

[36] Wes McKinney. Data Structures for Statistical Computing in Python, 2010.

[37] Agoston E Eiben and James E Smith. Introduction to evolutionary computing. Springer, 2015.

[38] Christopher M Bishop. Pattern recognition and machine learning. springer, 2006.

[39] Anna Choromanska, Mikael Henaff, Michael Mathieu, Gérard Ben Arous, and Yann LeCun. The Loss Surfaces of

Multilayer Networks. arXiv, 38, 2014.

[40] Munir Pirmohamed, Girvan Burnside, Niclas Eriksson, Andrea L. Jorgensen, Cheng Hock Toh, Toby Nicholson,
Patrick Kesteven, Christina Christersson, Bengt Wahlström, Christina Stafberg, J. Eunice Zhang, Julian B. Leathart,
Hugo Kohnke, Anke H. Maitland-van der Zee, Paula R. Williamson, Ann K. Daly, Peter Avery, Farhad Kamali,
and Mia Wadelius. A Randomized Trial of Genotype-Guided Dosing of Warfarin. New England Journal of
Medicine, 369(24):2294–2303, 2013.

[41] Elizabeth A. Sconce, Tayyaba I. Khan, Hilary A. Wynne, Peter Avery, Louise Monkhouse, Barry P. King, Peter
Wood, Patrick Kesteven, Ann K. Daly, and Farhad Kamali. The impact of CYP2C9 and VKORC1 genetic
polymorphism and patient characteristics upon warfarin dose requirements: Proposal for a new dosing regimen.
Blood, 106(7):2329–2333, 2005.

[42] Mia Wadelius, Leslie Y. Chen, Niclas Eriksson, Suzannah Bumpstead, Jilur Ghori, Claes Wadelius, David Bentley,
Ralph McGinnis, and Panos Deloukas. Association of warfarin dose with genes involved in its action and
metabolism. Human Genetics, 121(1):23–34, 2007.

19

