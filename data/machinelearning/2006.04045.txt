A Generic First-Order Algorithmic Framework for Bi-Level Programming
Beyond Lower-Level Singleton

0
2
0
2

l
u
J

2

]

G
L
.
s
c
[

2
v
5
4
0
4
0
.
6
0
0
2
:
v
i
X
r
a

Risheng Liu 1 2 Pan Mu 1 2 Xiaoming Yuan 3 Shangzhi Zeng 3 Jin Zhang 4

Abstract
In recent years, a variety of gradient-based bi-
level optimization methods have been developed
for learning tasks. However, theoretical guaran-
tees of these existing approaches often heavily
rely on the simpliﬁcation that for each ﬁxed upper-
level variable, the lower-level solution must be a
singleton (a.k.a., Lower-Level Singleton, LLS).
In this work, by formulating bi-level models from
the optimistic viewpoint and aggregating hier-
archical objective information, we establish Bi-
level Descent Aggregation (BDA), a ﬂexible and
modularized algorithmic framework for bi-level
programming. Theoretically, we derive a new
methodology to prove the convergence of BDA
without the LLS condition. Furthermore, we im-
prove the convergence properties of conventional
ﬁrst-order bi-level schemes (under the LLS sim-
pliﬁcation) based on our proof recipe. Extensive
experiments justify our theoretical results and
demonstrate the superiority of the proposed BDA
for different tasks, including hyper-parameter op-
timization and meta learning.

1. Introduction

Bi-Level Programs (BLPs) are mathematical programs with
optimization problems in their constraints and recently have
been recognized as powerful theoretical tools for a variety of
machine learning applications. Mathematically, BLPs can
be (re)formulated as the following optimization problem:

min
x∈X ,y∈Rm

F (x, y), s.t. y ∈ S(x),

(1)

1DUT-RU International School of Information Science and
2Key Labora-
Engineering, Dalian University of Technology.
tory for Ubiquitous Network and Service Software of Liaoning
Province. 3Department of Mathematics, The University of Hong
Kong. 4SUSTech International Center for Mathematics and Depart-
ment of Mathematics, Southern University of Science and Technol-
ogy. Correspondence to: Jin Zhang <zhangj9@sustech.edu.cn>.

Proceedings of the 37 th International Conference on Machine
Learning, Vienna, Austria, PMLR 119, 2020. Copyright 2020 by
the author(s).

where the Upper-Level (UL) objective F is a jointly contin-
uous function, the UL constraint X is a compact set, and the
set-valued mapping S(x) indicates the parameterized solu-
tion set of the Lower-Level (LL) subproblem. Without loss
of generality, we consider the following LL subproblem:

S(x) = arg min

y

f (x, y),

(2)

where f is another jointly continuous function.
Indeed,
the BLPs model formulated in Eqs. (1)-(2) is a hierar-
chical optimization problem with two coupled variables
(x, y) ∈ Rn × Rm. Speciﬁcally, given the UL variable x
from the feasible set X (i.e., x ∈ X ), the LL variable y
is an optimal solution of the LL subproblem governed by
x (i.e., y ∈ S(x)). Due to the hierarchical structure and
the complicated dependency between UL and LL variables,
solving the above BLPs problem is challenging in general,
especially when the LL solution set S(x) in Eq. (2) is not
a singleton (Jeroslow, 1985; Dempe, 2018). In this work,
we always call the condition that S(x) is a singleton as
Lower-Level Singleton (or LLS for short).

1.1. Related Work

Although early works on BLPs can date back to the nineteen
seventies (Dempe, 2018), it was not until the last decade
that a large amount of bi-level optimization models were
established to formulate speciﬁc machine learning problems,
include meta learning (Franceschi et al., 2018; Rajeswaran
et al., 2019; Z¨ugner & G¨unnemann, 2019), hyper-parameter
optimization (Franceschi et al., 2017; Okuno et al., 2018;
MacKay et al., 2019), reinforcement learning (Yang et al.,
2019), generative adversarial learning (Pfau & Vinyals,
2016), and image processing (Kunisch & Pock, 2013; De los
Reyes et al., 2017), just to name a few.

A large number of optimization techniques have been devel-
oped to solve BLPs in Eqs. (1)-(2). For example, the works
in (Kunapuli et al., 2008; Moore, 2010; Okuno et al., 2018)
aimed to reformulate the original BLPs in Eqs. (1)-(2) as a
single-level optimization problem based on the ﬁrst-order
optimality conditions. However, these approaches involve
too many auxiliary variables, thus are not applicable for
complex machine learning tasks.

 
 
 
 
 
 
A Generic First-Order Algorithmic Framework for Bi-Level Programming Beyond Lower-Level Singleton

Table 1. Comparing the convergence results (together with properties required by the UL and LL subproblems) between BDA and the
existing bi-level FOMs in different scenarios (i.e., BLPs with and without LLS condition). Here s−→ and u−→ represent the subsequential
and uniform convergence, respectively. The superscript ∗ denotes that it is the true optimal variables/values.

Alg.

Existing
bi-level FOMs

BDA

UL
LL

UL

LL

LLS
F (x, ·) is Lipschitz continuous.
{yK (x)} is uniformly bounded on X , yK (x) u−→ y∗(x).

Main results: xK

s−→ x∗, inf x∈X ϕK (x) → inf x∈X ϕ(x).

w/o LLS

Not Available

F (x, ·) is Lipschitz continuous.
{yK (x)} is uniformly bounded on X , f (x, yK (x)) u−→ f ∗(x),
f (x, y) is level-bounded in y locally uniformly in x ∈ X .

F (x, ·) is Lipschitz continuous,
LF -smooth, and σ-strongly convex.
f (x, ·) is Lf -smooth and convex,
S(x) is continuous.

Main results: xK

s−→ x∗, inf x∈X ϕK (x) → inf x∈X ϕ(x).

Recently, gradient-based First-Order Methods (FOMs) have
also been investigated to solve BLPs. The key idea under-
lying these approaches is to hierarchically calculate gra-
dients of UL and LL objectives. Speciﬁcally, the works
in (Maclaurin et al., 2015; Franceschi et al., 2017; 2018)
ﬁrst calculate gradient representations of the LL objective
and then perform either reverse or forward gradient compu-
tations (a.k.a., automatic differentiation, based on the LL
gradients) for the UL subproblem. It is known that the re-
verse mode is related to the back-propagation through time
while the forward mode actually appears to the standard
chain rule (Franceschi et al., 2017). In fact, similar ideas
have also been used in (Jenni & Favaro, 2018; Z¨ugner &
G¨unnemann, 2019; Rajeswaran et al., 2019), but with dif-
ferent speciﬁc implementations. In (Shaban et al., 2019), a
truncated back-propagation scheme is adopted to improve
the scale issue for the LL gradient updating. Furthermore,
the works in (Lorraine & Duvenaud, 2018; MacKay et al.,
2019) trained a so-called hyper-network to map LL gradi-
ents for their hierarchical optimization.

Although widely used in different machine learning appli-
cations, theoretical properties of these bi-level FOMs are
still not convincing (summarized in Table 1). Indeed, all
of these methods require the LLS constraint in Eq. (2) to
simplify their optimization process and theoretical analysis.
For example, to satisfy such restrictive condition, existing
works (Franceschi et al., 2018; Shaban et al., 2019) have to
enforce a (local) strong convexity assumption to their LL
subproblem, which is actually too tough to be satisﬁed in
real-world complex tasks.

1.2. Our Contributions

This work proposes Bi-level Descent Aggregation (BDA),
a generic bi-level ﬁrst-order algorithmic framework that is
ﬂexible and modularized to handle BLPs in Eqs. (1)-(2).
Unlike the above existing bi-level FOMs, which require
the LLS assumption on Eq. (2) and separate the original
model into two single-level subproblems, our BDA inves-

tigates BLPs from the optimistic viewpoint and develop a
new hierarchical optimization scheme, which consists of a
single-level optimization formulation for the UL variable
x and a simple bi-level optimization formulation for the
LL variable y. Theoretically, we establish a general proof
recipe to analyze the convergence behaviors of these bi-
level FOMs. We prove that the convergence of BDA can
be strictly guaranteed in the absence of the restrictive LLS
condition. Furthermore, we demonstrate that the strong
convexity of the LL objective (required in previous theo-
retical analysis (Franceschi et al., 2018)) is actually non-
essential for these existing LLS-based bi-level FOMs, such
as (Domke, 2012; Maclaurin et al., 2015; Franceschi et al.,
2017; 2018; Shaban et al., 2019). Table 1 compares the con-
vergence results of BDA and the existing approaches. It can
be seen that in LLS scenario, BDA and the existing meth-
ods share the same requirements for the UL subproblem.
However, for the LL subproblem, assumptions required in
previous approaches are essentially more restrictive than
that in BDA. More importantly, when solving BLPs with-
out LLS, no theoretical results can be obtained for these
classical methods. Fortunately, BDA can still obtain the
same convergence properties as that in LLS scenario. The
contributions can be summarized as:

• A counter-example (i.e., Example 1) explicitly indi-
cates the importance of the LLS condition for the exist-
ing bi-level FOMs. In particular, we investigate their
iteration behaviors and reach the conclusion that using
these approaches in the absence of the LLS condition
may lead to incorrect solutions.

• By formulating BLPs in Eqs. (1)-(2) from the view-
point of optimistic bi-level, BDA provides a generic
bi-level algorithmic framework. Embedded with a
speciﬁc gradient-aggregation-based iterative module,
BDA is applicable to a variety of learning tasks.

• A general proof recipe is established to analyze the
convergence behaviors of bi-level FOMs. We strictly

A Generic First-Order Algorithmic Framework for Bi-Level Programming Beyond Lower-Level Singleton

prove the convergence of BDA without the LLS as-
sumption. Furthermore, we revisit and improve the
convergence properties of the existing bi-level FOMs
in the LLS scenario.

2. First-Order Methods for BLPs

2.1. Solution Strategies with Lower-Level Singleton

As aforementioned, a number of FOMs have been proposed
to solve BLPs in Eqs. (1)-(2). However, these existing meth-
ods all rely on the uniqueness of S(x) (i.e., LLS assump-
tion). That is, rather than considering the original BLPs in
Eqs. (1)-(2), they actually solve the following simpliﬁcation:

min
x∈X

F (x, y), s.t. y = arg min

y

f (x, y),

(3)

where the LL subproblem only has one single solution for a
given x. By considering y as a function of x, the idea be-
hind these approaches is to take a gradient-based ﬁrst-order
scheme (e.g, gradient descent, stochastic gradient descent,
or their variations) on the LL subproblem. Therefore, with
the initialization point y0, a sequence {yk}K
k=0 parameter-
ized by x can be generated, e.g.,

yk+1 = yk − sl∇yf (x, yk), k = 0, · · · , K − 1,

(4)

where sl > 0 is an appropriately chosen step size. Then
by considering yK(x) (i.e., the output of Eq. (4) for a
given x) as an approximated optimal solution to the LL
subproblem, we can incorporate yK(x) into the UL ob-
jective and obtain a single-level approximation model, i.e.,
minx∈X F (x, yK(x)). Finally, by unrolling the iterative
update scheme in Eq. (4), we can calculate the derivative
of F (x, yK(x)) (w.r.t. x) to optimize Eq. (3) by automatic
differentiation techniques (Franceschi et al., 2017; Baydin
et al., 2017).

2.2. Fundamental Issues and Counter-Example

It can be observed that the LLS condition fairly matters
for the validation of the existing bi-level FOMs. However,
such singleton assumption on the solution set of the LL sub-
problem is actually too restrictive to be satisﬁed, especially
in real-world applications. In this subsection, we design
an interesting counter-example (Example 1 below) to illus-
trate such invalidation of these conventional gradient-based
bi-level schemes in the absence of the LLS condition.
Example 1. (Counter-Example) With x ∈ [−100, 100] and
y ∈ R2, we consider the following BLPs problem:

min
x∈[−100,100]

1

2 (x − [y]2)2 + 1
2 [y]2

2 ([y]1 − 1)2,
1 − x[y]1,

1

s.t. y ∈ arg min
y∈R2

is x∗ = 1, y∗ = (1, 1). However, if adopting the exist-
ing gradient-based scheme in Eq. (4) with initialization
y0 = (0, 0) and varying step size sk
l ∈ (0, 1), we have that
[yK]1 = (1 − (cid:81)K−1
k=0 (1 − sk
l ))x and [yK]2 = 0. Then the
approximated problem of Eq. (5) amounts to

min
x∈[−100,100]

F (x, yK) =

1
2

x2+

1
2

((1−

K−1
(cid:89)

k=0

(1−sk

l ))x−1)2.

By deﬁning ϕK(x) = F (x, yK), we have

x∗

K = arg

min
x∈[−100,100]

φK(x) =

It is easy to check that

(1 − (cid:81)K−1
1 + (1 − (cid:81)K−1

k=0 (1 − sk
l ))
k=0 (1 − sk
l ))2

.

0 ≤ lim inf
K→∞

K−1
(cid:89)

k=0

(1 − sk

l ) ≤ lim sup
K→∞

K−1
(cid:89)

(1 − sk

l ) ≤ 1,

k=0

(1−(cid:81)K−1
1+(1−(cid:81)K−1

k=0 (1−sk
l ))
k=0 (1−sk

2 . So

l ))2 ≤ 1
then we have lim supK→∞
x∗
K cannot converge to the true solution (i.e., x∗ = 1).
Remark 1. The UL objective F is indeed a function of both
the UL variable x and the LL variable y. Conventional
bi-level FOMs only use the gradient information of the LL
subproblem to update y. Thanks to the LLS assumption,
for ﬁxed UL variable x, the LL solution y can be uniquely
determined. Thus the sequence {yk}K
k=0 could converge to
the true optimal solution, that minimizes both the LL and
UL objectives. However, when LLS is absent, {yk}K
k=0 may
easily fail to converge to the true solution. Therefore, x∗
K
may tend to be incorrect limiting points. Fortunately, we
will demonstrate in Sections 3 and 5 that the example in
Eq. (5) can be efﬁciently solved by our proposed BDA.

3. Bi-level Descent Aggregation

In contrast to previous works, which only consider simpli-
ﬁed BLPs with the LLS assumption in Eq. (3), we propose a
new algorithmic framework, named Bi-level Descent Aggre-
gation (BDA), to handle more generic BLPs in Eqs. (1)-(2).

3.1. Optimistic Bi-level Algorithmic Framework

In fact, the situation becomes intricate if the LL subproblem
is not uniquely solvable for each x ∈ X . In this work,
we consider BLPs from the optimistic bi-level viewpoint1,
thus for any given x, we expect to choose the LL solution
y ∈ S(x) that can also lead to the best objective function
value for the UL objective (i.e., F (x, ·)). Inspired by this
observation, we can reformulate Eqs. (1)-(2) as

where [·]i denotes the i-th element of the vector. By simple
calculation, we know that the optimal solution of Eq. (5)

1For more theoretical details of optimistic BLPs, we refer

to (Dempe, 2018) and the references therein.

(5)

min
x∈X

ϕ(x), with ϕ(x) = inf

y∈S(x)

F (x, y).

(6)

A Generic First-Order Algorithmic Framework for Bi-Level Programming Beyond Lower-Level Singleton

Such reformulation reduces BLPs to a single-level problem
minx∈X ϕ(x) w.r.t. the UL variable x. While for any given
x, ϕ actually turns out to be the value function of a simple
bi-level problem w.r.t. the LL variable y, i.e.,

min
y

F (x, y), s.t. y ∈ S(x), (with ﬁxed x).

(7)

demonstrate that BDA algorithmic framework is ﬂexible
enough to incorporate a variety of numerical schemes. For
example, in Supplemental Material, we also design an ap-
propriate Tk to handle BLPs with nonsmooth LL objective
while its convergence is still strictly guaranteed within our
framework.

Based on the above analysis, we actually could update y by

4. Theoretical Investigations

yk+1(x) = Tk+1(x, yk(x)), k = 0, · · · , K − 1,

(8)

where Tk(x, ·) stands for a schematic iterative module orig-
inated from a certain simple bi-level solution strategy on
Eq. (7) with a ﬁxed UL variable x.2 Let y0 = T0(x) be
the initialization of the above scheme and denote yK(x) as
the output of Eq. (8) after K iterations (including the initial
calculation T0). Then we can replace ϕ(x) by F (x, yK(x))
and obtain the following approximation of Eq. (6):

min
x∈X

ϕK(x) = F (x, yK(x)).

(9)

With the above procedure, the BLPs in Eqs. (1)-(2) is ap-
proximated by a sequence of standard single-level opti-
mization problems. For each approximation subproblem
in Eq. (9), its descent direction is actually implicitly rep-
resentable in terms of a certain simple bi-level solution
strategy (i.e., Eq. (8)). Therefore, these existing automatic
differentiation techniques all can be involved to achieve op-
timal solutions to Eq. (9) (Franceschi et al., 2017; Baydin
et al., 2017).

3.2. Aggregated Iteration Modules

Now optimizing BLPs in Eqs. (1)-(2) reduces to the problem
of designing proper Tk for Eq. (8). As discussed above, Tk
is related to both the UL and LL objectives. So it is natural
to aggregate the descent information of these two subprob-
lems to design Tk. Speciﬁcally, for a given x, the descent
directions of the UL and LL objectives can be deﬁned as

dF
df

k (x) = su∇yF (x, yk),
k(x) = sl∇yf (x, yk),

where su, sl > 0 are their step size parameters. Then we
formulate Tk as the following ﬁrst-order descent scheme:

Tk+1 (x, yk(x)) = yk −

(cid:16)

αkdF

k (x) + (1 − αk)df

k(x)

(cid:17)

,
(10)

In this section, we ﬁrst derive a general convergence proof
recipe together with two elementary properties to system-
atically investigate the convergence behaviors of bi-level
FOMs (Section 4.1). Following this roadmap, the conver-
gence of our BDA can successfully get rid of depending
upon the LLS condition (Section 4.2). We also improve the
convergence results for the existing bi-level FOMs in the
LLS scenario (Section 4.3). To avoid triviality, hereafter
we always assume that S(x) is nonempty for any x ∈ X .
Please notice that all the proofs of our theoretical results are
stated in the Supplemental Material.

4.1. A General Proof Recipe

We ﬁrst state some deﬁnitions, which are necessary for our
analysis.3 A series of continuity properties for set-valued
mappings and functions can be deﬁned as follows.
Deﬁnition 1. A set-valued mapping S(x) : Rn ⇒ Rm is
Outer Semi-Continuous (OSC) at ¯x if lim supx→¯x S(x) ⊆
S(¯x) and Inner Semi-Continuous
(ISC) at ¯x if
lim inf x→¯x S(x) ⊇ S(¯x). S(x) is called continuous
at ¯x if it is both OSC and ISC at ¯x, as expressed by
limx→¯x S(x) = S(¯x). Here lim supx→¯x S(x) and
lim inf x→¯x S(x) are deﬁned as

lim sup
x→¯x
lim inf
x→¯x

S(x) = {y| ∃xν → ¯x, ∃yν → y, yν ∈ S(xν)} ,

S(x) = {y| ∀xν → ¯x, ∃yν → y, yν ∈ S(xν)} ,

where ν ∈ N.
Deﬁnition 2. A function ϕ(x) : Rn → R is Upper Semi-
Continuous (USC) at ¯x if lim supx→¯x ϕ(x) ≤ ϕ(¯x), or
equivalently lim supx→¯x ϕ(x) = ϕ(¯x), and USC on Rn
if this holds for every ¯x ∈ Rn. Similarly, ϕ(x) is Lower
Semi-Continuous (LSC) at ¯x if lim inf x→¯x ϕ(x) ≥ ϕ(¯x),
or equivalently lim inf x→¯x ϕ(x) = ϕ(¯x), and LSC on Rn
if this holds for every ¯x ∈ Rn. Here lim supx→¯x ϕ(x) and
lim inf x→¯x ϕ(x) are respectively deﬁned as

where αk ∈ (0, 1) denotes the aggregation parameter.
Remark 2. In this part, we just introduce a gradient aggre-
gation based Tk to handle the simple bi-level subproblem
in Eq. (7). Indeed, our theoretical analysis in Section 4 will

and

lim sup
x→¯x

ϕ(x) = lim
δ→0

(cid:104)
supx∈Bδ(¯x) ϕ(x)

(cid:105)

lim inf
x→¯x

ϕ(x) = lim
δ→0

(cid:2)inf x∈Bδ(¯x) ϕ(x)(cid:3)

2It can be seen that Tk actually should integrate the information
from both the UL and LL subproblems in Eqs. (1)-(2). We will
discuss speciﬁc choices of Tk in the following subsection.

3Please also refer to (Rockafellar & Wets, 2009) for more

details on these variational analysis properties.

A Generic First-Order Algorithmic Framework for Bi-Level Programming Beyond Lower-Level Singleton

where Bδ(¯x) = {x(cid:12)

(cid:12)(cid:107)x − ¯x(cid:107) ≤ δ}.

Then for a given function f (x, y), we state the property that
it is level-bounded in x locally uniform in y in the following
deﬁnition.
Deﬁnition 3. Given a function f (x, y) : Rn × Rm → R, if
for a point ¯x ∈ X ⊆ Rn and c ∈ R, there exist δ > 0 along
with a bounded set B ∈ Rm, such that

{y ∈ Rm | f (x, y) ≤ c} ⊆ B, ∀x ∈ Bδ(¯x) ∩ X ,

then we call f (x, y) is level-bounded in y locally uniformly
in ¯x ∈ X . If the above property holds for each ¯x ∈ X , we
further call f (x, y) level-bounded in y locally uniformly in
x ∈ X .

Now we are ready to establish the general proof recipe,
which describes the main steps to achieve the converge guar-
antees for our bi-level updating scheme (stated in Eqs. (8)-
(9), with a schematic Tk). Basically, our proof methodology
consists of two main steps:

(1) LL solution set property: For any (cid:15) > 0, there exists

k((cid:15)) > 0 such that whenever K > k((cid:15)),

dist(yK(x), S(x)) ≤ (cid:15).

sup
x∈X

(2) UL objective convergence property: ϕ(x) is LSC on

X , and for each x ∈ X ,

lim
K→∞

ϕK(x) → ϕ(x).

Equipped with the above two properties, we can establish
our general convergence results in the following theorem
for the schematic bi-level scheme in Eqs. (8)-(9).
Theorem 1. Suppose both the above LL solution set and
UL objective convergence properties hold. Then we have

(1) suppose xK ∈ arg minx∈X ϕK(x), then any limit
point ¯x of the sequence {xK} satisﬁes that ¯x ∈
arg minx∈X ϕ(x).

(2) inf x∈X ϕK(x) → inf x∈X ϕ(x) as K → ∞.

Remark 3. Indeed, if xK is a local minimum of ϕK(x)
with uniform neighborhood modulus δ > 0, we can still
have that any limit point ¯x of the sequence {xK} is a local
minimum of ϕ(x). Please see our Supplemental Material
for more details on this issue.

4.2. Convergence Properties of BDA

The objective here is to demonstrate that our BDA meets
these two elementary properties required by Theorem 1.
Before proving the convergence results for BDA, we ﬁrst
take the following as our blanket assumption.

Assumption 1. For any x ∈ X , F (x, ·) : Rm → R is L0-
Lipschitz continuous, LF -smooth, and σ-strongly convex,
f (x, ·) : Rm → R is Lf -smooth and convex.

Please notice that Assumption 1 is quite standard for BLPs
in machine learning areas (Franceschi et al., 2018; Shaban
et al., 2019). As can be seen, it is satisﬁed for all the ap-
plications considered in this work. We ﬁrst present some
necessary variational analysis preliminaries. Denoting

˜S(x) = arg min
y∈S(x)

F (x, y),

under Assumption 1, we can quickly obtain that ˜S(x) is
nonempty and unique for any x ∈ X . Moreover, we can
derive the boundedness of ˜S(x) in the following lemma.
Lemma 1. Suppose F (x, y) is level-bounded in y locally
uniformly in x ∈ X . If S(x) is ISC on X , then ∪x∈X ˜S(x)
is bounded.

Thanks to the continuity of f (x, y), we further have the
following result.
Lemma 2. Denote f ∗(x) = miny f (x, y). If f (x, y) is
continuous on X × Rm, then f ∗(x) is USC on X .

Now we are ready to establish our fundamental LL solution
set and UL objective convergence properties required in
Theorem 1. In the following proposition, we ﬁrst derive
the convergence of {yK(x)} in the light of the general fact
stated in (Sabach & Shtern, 2017).

Proposition 1. Suppose Assumption 1 is satisﬁed and let
{yK} be deﬁned as in Eq. (10), sl ∈ (0, 1/Lf ], su ∈
(0, 2/(LF + σ)],

αk = min {2γ/k(1 − β), 1 − ε} ,

with k ≥ 1, ε > 0, γ ∈ (0, 1], and

β = (cid:112)1 − 2suσLF /(σ + LF ).

Denote ˜yK(x) = yK(x) − sl∇yf (x, yK(x)), and

Cy∗(x) = max

(cid:26)

(cid:107)y0 − y∗(x)(cid:107),

su
1 − β

(cid:107)∇yF (x, y∗(x))(cid:107)

(cid:27)

,

with y∗(x) ∈ ˜S(x) and x ∈ X . Then we have

(cid:107)yK(x) − y∗(x)(cid:107) ≤ Cy∗(x),

(cid:107)yK(x) − ˜yK(x)(cid:107) ≤

f (x, ˜yK(x)) − f ∗(x) ≤

2Cy∗(x)(J + 2)
K(1 − β)
y∗(x)(J + 2)
K(1 − β)sl

2C 2

,

,

where J = (cid:98)2/(1 − β)(cid:99). Furthermore, for any x ∈ X ,
{yK(x)} converges to ˜S(x) as K → ∞.

A Generic First-Order Algorithmic Framework for Bi-Level Programming Beyond Lower-Level Singleton

Proposition 1, together with Lemma 1, shows that {˜yK(x)}
is a bounded sequence and {f (x, ˜yK(x))} uniformly con-
verges. We next prove the uniform convergence of {˜yK(x)}
towards the solution set S(x) through the uniform conver-
gence of {f (x, ˜yK(x))}.
Proposition 2. Let Y ⊆ Rm be a bounded set and (cid:15) > 0.
If S(x) is ISC on X , then there exists δ > 0 such that for
any y ∈ Y,

weakening the required assumptions, we improve the con-
vergence results in (Franceschi et al., 2018; Shaban et al.,
2019) for these conventional bi-level FOMs in the LLS sce-
nario. Speciﬁcally, we ﬁrst introduce an assumption on the
LL objective f (x, y), which is needed for our analysis in
this subsection.
Assumption 2. f (x, y) : Rn × Rm → R is level-bounded
in y locally uniformly in x ∈ X .

dist(y, S(x)) ≤ (cid:15),

sup
x∈X

in case supx∈X {f (x, y) − f ∗(x)} ≤ δ is satisﬁed.

Combining Lemmas 1 and 2, together with Proposition 2,
the LL solution set property required in Theorem 1 can be
eventually derived. Let us now prove the LSC property of ϕ
on X in the following proposition.

Proposition 3. Suppose F (x, y) is level-bounded in y lo-
cally uniformly in x ∈ X . If S(x) is OSC at x ∈ X , then
ϕ(x) is LSC at x ∈ X .

Then the UL objective convergence property required in
Theorem 1 can be obtained subsequently based on Proposi-
tion 3, In summary, we present the main convergence results
of BDA in the following theorem.

Theorem 2. Suppose Assumption 1 is satisﬁed and let
{yK} be deﬁned as in Eq. (10), sl ∈ (0, 1/Lf ], su ∈
(0, 2/(LF + σ)],

αk = min {2γ/k(1 − β), 1 − ε} ,

with k ≥ 1, ε > 0, γ ∈ (0, 1], and

β = (cid:112)1 − 2suσLF /(σ + LF ).

Assume further that S(x) is continuous on X . Then we have
that both the LL solution set and UL objective convergence
properties hold.

Remark 4. Our proposed theoretical results are indeed
general enough for BLPs in different application scenar-
ios. For example, when the LL objective takes a nonsmooth
form, e.g., h = f + g with smooth f and nonsmooth g, we
can adopt the proximal operation based iteration module
(Beck, 2017) to construct Tk within our BDA framework.
The convergence proofs are highly similar to that in Theo-
rem 2. More details on such extension can be found in our
Supplemental Material.

4.3. Improving Existing LLS Theories

Although with the LLS simpliﬁcation on BLPs in Eqs. (1)-
(2), the theoretical properties of the existing bi-level FOMs
are still not very convincing. Their convergence proofs in
essence depend on the strong convexity of the LL objective,
which may restrict the use of these approaches in com-
plex machine learning applications. In this subsection, by

In fact, Assumption 2 is mild and satisﬁed by a large number
of bi-level FOMs, when the LL subproblem is convex but not
necessarily strongly convex. In contrast, theoretical results
in existing literature (Franceschi et al., 2018; Shaban et al.,
2019) require the more restrictive (local) strong convexity
property on the LL objective to meets the LLS condition.

Under Assumption 2, the following lemma veriﬁes the con-
tinuity of S(x) in the LLS scenario.
Lemma 3. Suppose S(x) is single-valued on X and As-
sumption 2 is satisﬁed. Then S(x) is continuous on X .

As can be seen from the proof of Theorem 3 in our Sup-
plemental Material, Lemma 3 and the uniform convergence
of {f (x, yK(x))} actually imply the LL solution set and
UL objective convergence properties. Hence Theorem 1 is
applicable, which inspires an improved version of the con-
vergence results for the existing bi-level FOMs as follows.
Theorem 3. Suppose S(x) is single-valued on X and As-
sumption 2 is satisﬁed, {yK(x)} is uniformly bounded on
X , and {f (x, yK(x))} converges uniformly to f ∗(x) on X
as K → ∞. Then we have that both the LL solution set and
UL objective convergence properties hold.
Remark 5. Theorem 3 actually improves the converge re-
sults in (Franceschi et al., 2018). In fact, the uniform con-
vergence assumption of {yK(x)} towards y∗(x) required
in (Franceschi et al., 2018) is essentially based on the strong
convexity assumption (see Remark 3.3 of (Franceschi et al.,
2018)). Instead of assuming such strong convexity, we only
need to assume a weaker condition that {f (x, yK(x))}
converges uniformly to f ∗(x) on X as K → ∞.

It is natural for us to illustrate our improvement in terms
of concrete applications. Speciﬁcally, we take the gradient-
based bi-level scheme summarized in Section 2.1 (which
has been used in (Franceschi et al., 2018; Jenni & Favaro,
2018; Shaban et al., 2019; Z¨ugner & G¨unnemann, 2019;
Rajeswaran et al., 2019)). In the following two propositions,
we assume that f (x, ·) : Rm → R is Lf -smooth and convex,
and sl ≤ 1/Lf .

Inspired by Theorems 10.21 and 10.23 in (Beck, 2017), we
ﬁrst derive the following proposition.
Proposition 4. Let {yK} be deﬁned as in Eq. (4). Then it
holds that

(cid:107)yK(x) − y∗(x)(cid:107) ≤ (cid:107)y0 − y∗(x)(cid:107),

A Generic First-Order Algorithmic Framework for Bi-Level Programming Beyond Lower-Level Singleton

and

f (yK(x)) − f ∗(x) ≤

(cid:107)y0 − y∗(x)(cid:107)2
2slK

,

with y∗(x) ∈ S(x) and x ∈ X .

Then in the following proposition we can immediately verify
our required assumption on {f (x, yK(x))} in the absence
of the strong convexity property on the LL objective.
Proposition 5. Suppose that S(x) is single-valued on X
and Assumption 2 is satisﬁed. Let {yK} be deﬁned as
in Eq. (4). Then {yK(x)} is uniformly bounded on X
and {f (x, yK(x))} converges uniformly to f ∗(x) on X
as K → ∞.
Remark 6. When the LL subproblem is convex, but not
necessarily strongly convex, a large number of gradient-
based methods, including accelerated gradient methods
such as FISTA (Beck & Teboulle, 2009) and block coordi-
nate descent method (Tseng, 2001), automatically meet our
assumption, i.e., the uniform convergence of optimal values
{f (x, yK(x))} towards f ∗(x) on X .

5. Experimental Results

In this section, we ﬁrst verify the theoretical ﬁndings and
then evaluate the performance of our proposed method on
different problems, such as hyper-parameter optimization
and meta learning. We conducted these experiments on a
PC with Intel Core i7-7700 CPU (3.6 GHz), 32GB RAM
and an NVIDIA GeForce RTX 2060 6GB GPU.

5.1. Synthetic BLPs

Our theoretical ﬁndings are investigated based on the syn-
thetic BLPs described in Section 2.2. As stated above, this
deterministic bi-level formulation satisﬁes all the assump-
tions required in Section 4, but it cannot meet the LLS
condition considered in (Finn et al., 2017; Franceschi et al.,
2017; 2018; Shaban et al., 2019). Here, we ﬁx the learning
rate parameters su = 0.7 and sl = 0.2 in this experiment.

In Figure 1, we plotted numerical results of BDA and one of
the most representative bi-level FOMs (i.e., Reverse Hyper-
Gradient (RHG) (Franceschi et al., 2017; 2018)) with differ-
ent initialization points. We considered different numerical
metrics, such as |F − F ∗|, |f − f ∗|, (cid:107)x − x∗(cid:107)2/(cid:107)x∗(cid:107)2, and
(cid:107)y − y∗(cid:107)2/(cid:107)y∗(cid:107)2, for evaluations. It can be observed that
RHG is always hard to obtain correct solution, even start
from different initialization points. This is mainly because
that the solution set of the LL subproblem in Eq. (5) is not a
singleton, which does not satisfy the fundamental assump-
tion of RHG. In contrast, our BDA aggregated the UL and
LL information to perform the LL updating, thus we are able
to obtain true optimal solution in all these scenarios. The ini-
tialization actually only slightly affected on the convergence
speed of our iterative sequences.

Figure 2 further plotted the convergence behaviors of BDA
and RHG with different LL iterations (i.e., K). We observed
that the results of RHG cannot be improved by increas-
ing K. But for BDA, the three iterative sequences (with
K = 8, 16, 64) are always converged and the numerical per-
formance can be improved by performing relatively more
LL iterations. In the above two ﬁgures, we set αk = 0.5/k,
k = 1, · · · , K.

Figure 3 evaluated the convergence behaviors of BDA with
different choices of αk. By setting αk = 0, we was unable
to use the UL information to guide the LL updating, thus
it is hard to obtain proper feasible solutions for the UL
subproblem. When choosing a ﬁxed αk in (0, 1) (e.g., αk =
0.5), the numerical performance can be improved but the
convergence speed was still slow. Fortunately, we followed
our theoretical ﬁndings and introduced an adaptive strategy
to incorporate UL information into LL iterations, leading to
nice convergence behaviors for both UL and LL variables.

5.2. Hyper-parameter Optimization

Hyper-parameter optimization aims choosing a set of
optimal hyper-parameters for a given machine learning
task.
In this experiment, we consider a speciﬁc hyper-
parameter optimization example, known as data hyper-
cleaning (Franceschi et al., 2017; Shaban et al., 2019), to
evaluate our proposed bi-level algorithm. In this task, we
need to train a linear classiﬁer on a given image set, but part
of the training labels are corrupted. Following (Franceschi
et al., 2017; Shaban et al., 2019), here we consider softmax
regression (with parameters y) as our classiﬁer and intro-
duce hyper-parameters x to weight samples for training.

Speciﬁcally, let (cid:96)(y; ui, vi) be the cross-entropy function
with the classiﬁcation parameter y and data pairs (ui, vi)
and denote Dtr and Dval as the training and validation sets,
respectively. Then we can deﬁne the LL objective as the
following weighted training loss:

f (x, y) =

(cid:88)

[σ(x)]i(cid:96)(y; ui, vi),

(ui,vi)∈Dtr

where x is the hyper-parameter vector to penalize the objec-
tive for different training samples. Here σ(x) denotes the
element-wise sigmoid function on x and is used to constrain
the weights in the range [0, 1]. For the UL subproblem,
we deﬁne the objective as the cross-entropy loss with (cid:96)2
regularization on the validation set, i.e.,

F (x, y) =

(cid:88)

(cid:96)(y(x); ui, vi) + λ(cid:107)y(x)(cid:107)2,

(ui,vi)∈Dval

where λ > 0 is the trade-off parameter and ﬁxed as 10−4.

We applied our BDA together with the baselines, RHG
and Truncated RHG (T-RHG) (Shaban et al., 2019), to

A Generic First-Order Algorithmic Framework for Bi-Level Programming Beyond Lower-Level Singleton

Figure 1. Illustrating the numerical performance of ﬁrst-order BLPs algorithms with different initialization points. Top row: ﬁx x0 = 0
and vary y0 = (0, 0), (2, 2). Bottom row: ﬁx y0 = (2, 2) and vary x0 = 0, 2. We ﬁx K = 16 for UL iterations. The dashed and solid
curves denote the results of RHG and BDA, respectively. The legend is only plotted in the ﬁrst subﬁgure.

Figure 2. Illustrating the numerical performance of ﬁrst-order BLPs algorithms with different LL iterations (i.e., K = 8, 16, 64). We ﬁx
initialization as x0 = 0 and y0 = (2, 2). The dashed and solid curves denotes the results of RHG and BDA, respectively. The legend is
only plotted in the ﬁrst subﬁgure.

Table 2. Data hyper-cleaning accuracy of the compared meth-
ods with different number of LL iterations (i.e., K =
50, 100, 200, 400, 800) on MNIST.

Figure 3. Illustrating the numerical performance of BDA with ﬁxed
αk (e.g., αk = 0, 0.5) and adaptive αk (e.g., {αk = 0.9/k},
denoted as “Adap. α”). The initialization and LL iterations are
ﬁxed as x0 = 0, y0 = (2, 2), and K = 16, respectively.

Method

50
RHG
88.96
T-RHG 87.90
89.12
BDA

No. of LL Iterations (K)
200
90.13
88.50
90.57

400
90.19
88.52
90.81

100
89.73
88.28
90.12

800
90.15
89.99
90.86

solve the above BLPs problem on MNIST database (Le-
Cun et al., 1998). Both the training and the validation sets
consist of 7000 class-balanced samples and the remain-
ing 56000 samples are used as the test set. We adopted
the architectures used in RHG as the feature extractor for
all the compared methods. For T-RHG, we chose 25-step
truncated back-propagation to guarantee its convergence.
Table 2 reported the averaged accuracy for all these com-

pared methods with different number of LL iterations (i.e.,
K = 50, 100, 200, 400, 800). We observed that RHG out-
performed T-RHG. While BAD consistently achieved the
highest accuracy. Our theoretical results suggested that most
of the improvements in BDA should come from the aggre-
gations of the UL and LL information. The results also
showed that more LL iterations are able to improve the ﬁnal
performances in most cases.

A Generic First-Order Algorithmic Framework for Bi-Level Programming Beyond Lower-Level Singleton

Table 3. The averaged few-shot classiﬁcation accuracy on Om-
niglot (N = 5, 20 and M = 1, 5).

Method

MAML
Meta-SGD
Reptile
RHG
T-RHG
BDA

5-way

20-way

1-shot
98.70
97.97
97.68
98.60
98.74
99.04

5-shot
99.91
98.96
99.48
99.50
99.52
99.62

1-shot
95.80
93.98
89.43
95.50
95.82
96.50

5-shot
98.90
98.40
97.12
98.40
98.95
99.10

Table 4. The few-shot classiﬁcation performances on MiniIma-
geNet (N = 5 and M = 1). The second column reported the
averaged accuracy after converged. The rightmost two columns
compared the UL Iterations (denoted as “UL Iter.”), when achiev-
ing almost the same accuracy (≈ 44%). Here “Ave. ± Var. (Acc.)”
denotes the averaged accuracy and the corresponding variance.

Acc.
Method
48.89
RHG
T-RHG 47.67
49.08
BDA

Ave. ± Var. (Acc.) UL Iter.

44.46 ± 0.78
44.21 ± 0.78
44.24 ± 0.79

3300
3700
2500

5.3. Meta Learning

The aim of meta learning is to learn an algorithm that should
work well on novel tasks. In particular, we consider the few-
shot learning problem (Vinyals et al., 2016; Qiao et al.,
2018), where each task is a N -way classiﬁcation and it is
to learn the hyper-parameter x such that each task can be
solved only with M training samples (i.e., N -way M -shot).

Following the experimental protocol used in recent works,
we separate the network architecture into two parts: the
cross-task intermediate representation layers (parameterized
by x) outputs the meta features and the multinomial logistic
regression layer (parameterized by yj) as our ground classi-
ﬁer for the j-th task. We also collect a meta training data set
D = {Dj}, where Dj = Dj
val is linked to the j-th
task. Then for the j-th task, we consider the cross-entropy
function (cid:96)(x, yj; Dj
tr) as the task-speciﬁc loss and thus the
LL objective can be deﬁned as

tr ∪ Dj

f (x, {yj}) = (cid:80)
j

(cid:96)(x, yj; Dj

tr).

As for the UL objective, we also utilize cross-entropy func-
tion but deﬁne it based on {Dj

val} as

F (x, {yj}) = (cid:80)
j

(cid:96)(x, yj; Dj

val).

Our experiments are conducted on two widely used bench-
marks, i.e., Ominglot (Lake et al., 2015), which contains
1623 hand written characters from 50 alphabets and Mini-
ImageNet (Vinyals et al., 2016), which is a subset of Ima-
geNet (Deng et al., 2009) and includes 60000 downsampled
images from 100 different classes. We followed the exper-
imental protocol used in MAML (Finn et al., 2017) and
compared our BDA to several state-of-the-art approaches,
such as MAML (Finn et al., 2017), Meta-SGD (Li et al.,
2018), Reptile (Nichol et al., 2018), RHG, and T-RHG.

It can be seen in Table 3 that BDA compared well to these
methods and achieved the highest classiﬁcation accuracy
except in the 5-way 5-shot task. In this case, practical perfor-
mance of BDA was slightly worse than MAML. We further

Figure 4. Illustrating the validation loss (i.e., UL objectives
F (x, y)) for three BLPs based methods on few-shot classiﬁca-
tion task. The curves in left and right subﬁgures are based on
5-way 1-shot results in Tables 3 and 4, respectively.

conducted experiments on the more challenging MiniIma-
geNet data set. In the second column of Table 4, we reported
the averaged accuracy of three ﬁrst-order BLPs based meth-
ods (i.e., RHG, T-RHG and BDA). Again, the performance
of BDA is better than RHG and T-RHG. In the rightmost
two columns, we also compared the number of averaged
UL iterations when they achieved almost the same accuracy
(≈ 44%). These results showed that BDA needed the fewest
iterations to achieve such accuracy. The validation loss on
Omnglot and MiniImageNet about 5-way 1-shot are plotted
in Figure. 4

6. Conclusions

The proposed BDA is a generic ﬁrst-order algorithmic
scheme to address BLPs. We ﬁrst designed a counter-
example to indicate that the existing bi-level FOMs in the
absence of the LLS condition may lead to incorrect solutions.
Considering BLPs from the optimistic bi-level viewpoint,
BDA could reformulate the original models in Eqs. (1)-
(2) as the composition of a single-level subproblem (w.r.t.
x) and a simple bi-level subproblem (w.r.t., y). We estab-
lished a general proof recipe for bi-level FOMs and proved
the convergence of BDA without the LLS assumption. As
a nontrivial byproduct, we further improved convergence
results for those existing schemes. Extensive evaluations
showed the superiority of BDA for different applications.

A Generic First-Order Algorithmic Framework for Bi-Level Programming Beyond Lower-Level Singleton

Acknowledgements

This work was supported by the National Natural Science
Foundation of China (Nos. 61922019, 61672125, 61733002,
61772105 and 11971220), LiaoNing Revitalization Tal-
ents Program (XLYC1807088), the Fundamental Research
Funds for the Central Universities and the Natural Science
Foundation of Guangdong Province 2019A1515011152.
This work was also supported by the General Research
Fund 12302318 from Hong Kong Research Grants Council.

References

Baydin, A. G., Pearlmutter, B. A., Radul, A. A., and Siskind,
J. M. Automatic differentiation in machine learning: a
survey. The Journal of Machine Learning Research, 18
(1):5595–5637, 2017.

Beck, A. First-order methods in optimization. SIAM, 2017.

Beck, A. and Teboulle, M. A fast iterative shrinkage-
thresholding algorithm for linear inverse problems. SIAM
Journal on Imaging Sciences, 2(1):183–202, 2009.

Bonnans, J. F. and Shapiro, A. Perturbation analysis of
optimization problems. Springer Science & Business
Media, 2013.

De los Reyes, J. C., Sch¨onlieb, C.-B., and Valkonen, T.
Bilevel parameter learning for higher-order total variation
regularisation models. Journal of Mathematical Imaging
and Vision, 57(1):1–25, 2017.

Dempe, S. Bilevel optimization: theory, algorithms and ap-
plications. TU Bergakademie Freiberg Mining Academy
and Technical University, 2018.

Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei,
L. Imagenet: A large-scale hierarchical image database.
In CVPR, pp. 248–255, 2009.

Domke, J. Generic methods for optimization-based model-

ing. In AISTATS, pp. 318–326, 2012.

Finn, C., Abbeel, P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In ICML,
pp. 1126–1135, 2017.

Franceschi, L., Donini, M., Frasconi, P., and Pontil, M.
Forward and reverse gradient-based hyperparameter opti-
mization. In ICML, pp. 1165–1173, 2017.

Franceschi, L., Frasconi, P., Salzo, S., Grazzi, R., and Pontil,
M. Bilevel programming for hyperparameter optimization
and meta-learning. In ICML, pp. 1563–1572, 2018.

Jenni, S. and Favaro, P. Deep bilevel learning. In ECCV, pp.

618–633, 2018.

Jeroslow, R. G. The polynomial hierarchy and a simple
model for competitive analysis. Mathematical Program-
ming, 32(2):146–164, 1985.

Kunapuli, G., Bennett, K. P., Hu, J., and Pang, J.-S. Classi-
ﬁcation model selection via bilevel programming. Opti-
mization Methods & Software, 23(4):475–489, 2008.

Kunisch, K. and Pock, T. A bilevel optimization approach
for parameter learning in variational models. SIAM Jour-
nal on Imaging Sciences, 6(2):938–983, 2013.

Lake, B. M., Salakhutdinov, R., and Tenenbaum, J. B.
Human-level concept learning through probabilistic pro-
gram induction. Science, 350(6266):1332–1338, 2015.

LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., et al.
Gradient-based learning applied to document recognition.
Proceedings of the IEEE, 86(11):2278–2324, 1998.

Li, Z., Zhou, F., Chen, F., and Li, H. Meta-sgd: Learning to
learn quickly for few-shot learning. In ICML, 2018.

Lorraine, J. and Duvenaud, D.

Stochastic hyperpa-
rameter optimization through hypernetworks. CoRR,
abs/1802.09419, 2018.

MacKay, M., Vicol, P., Lorraine, J., Duvenaud, D., and
Grosse, R. Self-tuning networks: Bilevel optimization of
hyperparameters using structured best-response functions.
ICLR, 2019.

Maclaurin, D., Duvenaud, D., and Adams, R. Gradient-
based hyperparameter optimization through reversible
learning. In ICML, pp. 2113–2122, 2015.

Moore, G. M. Bilevel programming algorithms for ma-
chine learning model selection. Rensselaer Polytechnic
Institute, 2010.

Nichol, A., Achiam, J., and Schulman, J. On ﬁrst-order
meta-learning algorithms. CoRR, abs/1803.02999, 2018.

Okuno, T., Takeda, A., and Kawana, A. Hyperparame-
ter learning via bilevel nonsmooth optimization. CoRR,
abs/1806.01520, 2018.

Pfau, D. and Vinyals, O. Connecting generative adversarial
networks and actor-critic methods. In NeurIPS Workshop
on Adversarial Training, 2016.

Qiao, S., Liu, C., Shen, W., and Yuille, A. L. Few-shot im-
age recognition by predicting parameters from activations.
In CVPR, pp. 7229–7238, 2018.

Rajeswaran, A., Finn, C., Kakade, S. M., and Levine, S.
Meta-learning with implicit gradients. In NeurIPS, pp.
113–124, 2019.

A Generic First-Order Algorithmic Framework for Bi-Level Programming Beyond Lower-Level Singleton

Rockafellar, R. T. and Wets, R. J.-B. Variational analysis.

Therefore, for any x ∈ X , we have

Springer Science & Business Media, 2009.

Sabach, S. and Shtern, S. A ﬁrst order method for solving
convex bilevel optimization problems. SIAM Journal on
Optimization, 27(2):640–660, 2017.

Shaban, A., Cheng, C.-A., Hatch, N., and Boots, B. Trun-
cated back-propagation for bilevel optimization. In AIS-
TATS, pp. 1723–1732, 2019.

Tseng, P. Convergence of a block coordinate descent method
for nondifferentiable minimization. Journal of Optimiza-
tion Theory and Applications, 109(3):475–494, 2001.

Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et al.
Matching networks for one shot learning. In NeurIPS, pp.
3630–3638, 2016.

Wang, S., Fidler, S., and Urtasun, R. Proximal deep struc-

tured models. In NeurIPS, pp. 865–873, 2016.

Yang, Z., Chen, Y., Hong, M., and Wang, Z. Provably global
convergence of actor-critic: A case for linear quadratic
regulator with ergodic cost. In NeurIPS, pp. 8351–8363,
2019.

Z¨ugner, D. and G¨unnemann, S. Adversarial attacks on graph

neural networks via meta learning. ICLR, 2019.

Appendix

This supplemental material is organized as follows. In Sec-
tion A, we present the detailed proof of subsection 4.1.
Section B and Section C provide detailed proofs of subsec-
tion 4.2 and subsection 4.3 respectively. Section D then
proves some extended theoretical results, including the local
convergence behaviors of BDA, the algorithmic scheme and
convergence properties of BDA for BLPs with nonsmooth
LL objective.

A. Proof of Section 4.1

A.1. Proof of Theorem 1

Proof. Since X is compact, we can assume without loss of
generality that xK → ¯x ∈ X . For any (cid:15) > 0, there exists
k((cid:15)) > 0 such that whenever K > k((cid:15)), we have

dist(yK(x), S(x)) ≤

sup
x∈X

(cid:15)
2L0

.

Thus, for any x ∈ X , there exists y∗(x) ∈ S(x) such that

(cid:107)yK(x) − y∗(x)(cid:107) ≤

(cid:15)
L0

.

ϕ(x) = inf

y∈S(x)

F (x, y)

≤ F (x, y∗(x))
≤ F (x, yK(x)) + L0(cid:107)yK(x) − y∗(x)(cid:107)
≤ ϕK(x) + (cid:15).

This implies that, for any (cid:15) > 0, there exists k((cid:15)) > 0 such
that whenever K > k((cid:15)),it holds

ϕ(xK) ≤ ϕK(xK) + (cid:15) ≤ ϕK(x) + (cid:15),

∀x ∈ X .

Taking K → ∞ and by the LSC of ϕ, we have

ϕ(¯x) ≤ lim inf
K→∞
≤ lim inf
K→∞

ϕ(xK)

ϕK(xK) + (cid:15)

≤ lim
K→∞

ϕK(x) + (cid:15) = ϕ(x) + (cid:15),

∀x ∈ X .

By taking (cid:15) → 0, we have

ϕ(¯x) ≤ ϕ(x),

∀x ∈ X ,

which implies ¯x ∈ arg minx∈X ϕ(x).

We next show that inf x∈X ϕK(x) → inf x∈X ϕ(x) as K →
∞. If this is not true, then there exist δ > 0 and sequence
{l} ⊆ N such that

(cid:12)
(cid:12)
(cid:12)
(cid:12)

inf
x∈X

ϕl(x) − inf
x∈X

ϕ(x)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

> δ,

∀l.

(11)

For each l, there exists xl ∈ X such that

ϕl(xl) ≤ inf
x∈X

ϕl(x) + δ/2.

Since X is compact, we can assume without loss of general-
ity that xl → ˜x ∈ X . For any (cid:15) > 0, there exists k((cid:15)) > 0
such that whenever l > k((cid:15)), the following holds

ϕ(xl) ≤ ϕl(xl) + (cid:15)
≤ inf
x∈X

ϕl(x) + δ/2 + (cid:15)

≤ ϕl(x) + δ/2 + (cid:15),

∀x ∈ X .

By taking l → ∞ and with the LSC of ϕ, we have

ϕ(˜x) ≤ lim inf
l→∞

≤ lim inf
l→∞

ϕ(xl)
(cid:18)

inf
x∈X
(cid:18)

(cid:19)

ϕl(x)

+ δ/2 + (cid:15)

(cid:19)

≤ lim sup

l→∞

inf
x∈X

ϕl(x)

+ δ/2 + (cid:15)

≤ ϕ(x) + δ/2 + (cid:15),

∀x ∈ X .

A Generic First-Order Algorithmic Framework for Bi-Level Programming Beyond Lower-Level Singleton

Then, by taking (cid:15) → 0, we have

B.3. Proof of Proposition 2

inf
x∈X

ϕ(x) ≤ lim inf
l→∞

(cid:18)

inf
x∈X
(cid:18)

(cid:19)

ϕl(x)

+ δ/2

(cid:19)

≤ lim sup

l→∞

inf
x∈X

ϕl(x)

+ δ/2

≤ inf
x∈X

ϕ(x) + δ/2,

which implies a contradiction to Eq. (11). Thus we have
inf x∈X ϕK(x) → inf x∈X ϕ(x) as K → ∞.

B. Proofs of Section 4.2

B.1. Proof of Lemma 1

Proof. We prove this result by providing a contradiction,
that is, we have {xt} ⊆ X and yt ∈ ˜S(xt) such that
(cid:107)yt(cid:107) → +∞. As X is compact, we can assume without
loss of generality that xt → ¯x ∈ X . Since F (x, y) is level-
bounded in y locally uniformly in x ∈ X , we must have
ϕ(xt) = F (xt, yt) → +∞. On the other hand, for any
(cid:15) > 0, let ¯y ∈ S(¯x) satisfy F (¯x, ¯y) ≤ ϕ(¯x) + (cid:15). As F is
continuous at (¯x, ¯y), there exists δ0 > 0 such that

Proof. We are going to prove this statement by a contra-
diction. We assume that there exist bounded set Y ⊆ Rm,
(cid:15) > 0, sequences {(xt, yt)} ⊆ X × Y and {δk} with
δk → 0 satisfying

f (xt, yt) − f ∗(xt) ≤ δk and dist(yt, S(xt)) > (cid:15).

Without loss of generality, we can assume that xt → ¯x ∈ X
and yt → ¯y ∈ Rm as t → ∞. According to the continuity
of f and the USC of f ∗ from Lemma 2, we have

0 ≤ f (¯x, ¯y) − f ∗(¯x) ≤ lim inf
t→∞

f (xt, yt) − f ∗(xt) ≤ 0,

which implies ¯y ∈ S(¯x). However, as dist(yt, S(xt)) >
(cid:15), following from the ISC of S(x) at ¯x and Proposition 5.11
of (Rockafellar & Wets, 2009), we have

dist(¯y, S(¯x)) ≥ lim sup

t→∞

= lim sup

dist(¯y, S(xt))
(cid:0)dist(yt, S(xt)) + (cid:107)yt − ¯y(cid:107)(cid:1)

t→∞
≥ lim inf
t→∞

dist(yt, S(xt)) ≥ (cid:15),

F (x, y) ≤ F (¯x, ¯y) + (cid:15), ∀(x, y) ∈ Bδ0(¯x, ¯y).

which contradicts to ¯y ∈ S(¯x).

As S(x) is ISC at ¯x relative to X , then it follows that there
exists

√
2
2 δ0 ≥ δ > 0 satisfying
S(x) ∩ B √

2
2 δ0

(¯y) (cid:54)= ∅, ∀x ∈ Bδ(¯x) ∩ X .

Therefore, for any x ∈ Bδ(¯x)∩X , there exists y ∈ S(x) sat-
isfying (x, y) ∈ Bδ0 (¯x, ¯y) and thus F (x, y) ≤ F (¯x, ¯y)+(cid:15).
Consequently, for any x ∈ Bδ(¯x) ∩ X , we have

ϕ(x) = min

y∈S(x)

F (x, y) ≤ F (¯x, ¯y) + (cid:15) = ϕ(¯x) + 2(cid:15),

which contradicts to ϕ(xt) → ∞.

B.2. Proof of Lemma 2

Proof. For any sequence {xt} ⊆ X satisfying xt → ¯x ∈
X , given any (cid:15) > 0, let ¯y ∈ Rm satisfy f (¯x, ¯y) ≤ f ∗(¯x)+(cid:15).
As f is continuous at (¯x, ¯y), there exists T > 0 such that

f ∗(xt) ≤ f (xt, ¯y) ≤ f (¯x, ¯y)+(cid:15) ≤ f ∗(¯x)+2(cid:15),

∀t > T,

and thus

lim sup
t→∞

f ∗(xt) ≤ f ∗(¯x) + 2(cid:15).

By taking (cid:15) → 0, we get lim supk→∞ f ∗(xt) ≤ f ∗(¯x).

We next prove the uniform convergence of {˜yK(x)} to-
wards the solution set S(x) through the uniform conver-
gence of {f (x, ˜yK(x))}.

B.4. Proof of Proposition 3

Proof. We assume that there exists ¯x ∈ X satisfying xt →
¯x as t → ∞, then the following

lim inf
x→¯x

ϕ(x) < ϕ(¯x),

holds. Next, there exist (cid:15) > 0 and sequences xt → ¯x ∈ X
and yt ∈ S(xt) satisfying

F (xt, yt) ≤ ϕ(xt) + (cid:15) < ϕ(¯x) − (cid:15).

Furthermore, since F (x, y) is level-bounded in y locally
uniformly in x ∈ X , we have that {yt} is bounded. Take a
subsequence {yν} of {yt} such that yν → ˆy and it follows
from the OSC of S that ˆy ∈ S(¯x). Then we have

ϕ(¯x) ≤ F (¯x, ˆy) ≤ lim sup

t→∞

F (xt, yt) = lim sup
t→∞
≤ ϕ(¯x) − (cid:15),

ϕ(xt)

which implies a contradiction. Thus

ϕ(¯x) ≤ lim inf
x→¯x

ϕ(x)

and we get the conclusion.

B.5. Proof of Theorem 2

Proof. We ﬁrst show that F (x, y) is level-bounded in y
locally uniformly in x ∈ X . For any ¯x ∈ X , let {xt} ⊆ X

A Generic First-Order Algorithmic Framework for Bi-Level Programming Beyond Lower-Level Singleton

with xt → ¯x and {yt} ∈ Rm with (cid:107)yt(cid:107) → +∞. Then,
with Assumption 1 we have

that for any (cid:15) > 0, there exists k((cid:15)) > 0 such that whenever
K > k((cid:15)),

F (xt, yt) ≥F (xt, y1) + (cid:104)∇yF (xt, y1), yt − y1(cid:105)
(cid:107)yt − y1(cid:107)2.

+

σ
2

As F (x, ·) : Rm → R is Lipschitz continuous with uniform
constant L0 for any x ∈ X , we have (cid:107)∇yF (xt, y1)(cid:107) ≤ L0.
Then, by the continuity of F , with xt → ¯x ∈ X , and
(cid:107)yt(cid:107) → +∞, we have F (xt, yt) → +∞. Thus F (x, y) is
level-bounded in y locally uniformly in x ∈ X . Then with
Proposition 3 and assumptions in Theorem 2, we get the
LSC property of ϕ on X . And according to Lemma 1, there
exists M > 0 such that Cy∗(x) ≤ M for any y∗(x) ∈ ˜S(x)
and x ∈ X . Following Proposition 1, there exists C > 0
such that for any x ∈ X we have

(cid:107)yK(x)(cid:107) ≤ C,

∀K ≥ 0,

(cid:107)yK(x) − ˜yK(x)(cid:107) ≤

C
K

,

and

f (˜yK(x)) − f ∗(x) ≤

C
K

,

∀K ≥ 0.

Next, according to Proposition 2, for any (cid:15) > 0, there exists
k((cid:15)) > 0 such that whenever K > max{2C/(cid:15), k((cid:15))} we
have

dist(yK(x), S(x))

sup
x∈X

≤ (cid:107)yK(x) − ˜yK(x)(cid:107) + sup
x∈X

dist(˜yK(x), S(x)) ≤ (cid:15).

Then it follows from Proposition 1 that ϕK(x) → ϕ(x)
when K → ∞ for any x ∈ X .

C. Proofs of Section 4.3

C.1. Proof of Lemma 3

Proof. First, according to Proposition 4.4 of (Bonnans &
Shapiro, 2013), we know that if f (x, y) : Rn × Rm →
R is continuous on X × Rm, level-bounded in y locally
uniformly in x ∈ X , then f ∗(x) is continuous on X , S(x)
is OSC on X and locally bounded at ¯x. Thus, for any ¯x ∈ X ,
f ∗(x) is locally bounded at ¯x. As S(x) is a single-valued
mapping on X and S(x) is OSC at ¯x ∈ X and locally
bounded at ¯x, Upon Proposition 5.20 of (Rockafellar &
Wets, 2009), we conclude that S(x) is ISC at ¯x, and thus
continuous at ¯x. This completes the proof.

C.2. Proof of Theorem 3

Proof. First, we get the continuity of S(x) on X from
Lemma 3. Then, by Proposition 3, we obtain the LSC
of ϕ(x) on X . From Proposition 2 and Lemma 3, we have

dist(yK(x), S(x)) ≤ (cid:15).

sup
x∈X

As S(x) is a single-valued mapping on X , we have
ϕK(x) → ϕ(x) for any x ∈ X as K → ∞.

In the following two propositions, we assume that f (x, ·) :
Rm → R is Lf -smooth and convex, sl ≤ 1/Lf .

C.3. Proof of Proposition 4

Proof. This proposition can be directly obtained from The-
orem 10.21 and Theorem 10.23 of (Beck, 2017).

Then in the following proposition we can immediately verify
our required assumption on {f (x, yK(x))} in the absence
of the strong convexity property on the LL objective.

C.4. Proof of Proposition 5

Proof. By the same arguments given in proof of Lemma 3,
we can show that S(x) is locally bounded at each point on
X under Assumption 2. As X is compact, thus ∪x∈X S(x)
is bounded. Then the conclusion follows from Proposition 4
directly.

D. Extended Theoretical Results

D.1. Local Convergence Results

In this part, we analyze the local convergence behaviors of
BDA. In fact, even if xK is a local minimum of ϕK(x) with
uniform neighborhood modulus δ > 0, we can still obtain
similar convergence results as that in Theorem 1. Such
properties are summarized in the following theorem.
Theorem 4. Suppose both the LL solution set and UL ob-
jective convergence properties (stated in Section ??) hold
and let xK be a local minimum of ϕK(x) with uniform
neighborhood modulus δ > 0. Then we have that any limit
point ¯x of the sequence {xK} is a local minimum of ϕ, i.e.,
there exists ˜δ > 0 such that

ϕ(¯x) ≤ ϕ(x),

∀x ∈ B˜δ(¯x) ∩ X .

Proof. Since X is compact, we can assume without loss
of generality that xK → ¯x ∈ X and xK ∈ Bδ/2(¯x) by
considering a subsequence of {xK}. For any (cid:15) > 0, there
exists k((cid:15)) > 0 such that whenever K > k((cid:15)), we have

dist(yK(x), S(x)) ≤

sup
x∈X

(cid:15)
2L0

.

Thus, for any x ∈ X , there exists y∗(x) ∈ S(x) such that

(cid:107)yK(x) − y∗(x)(cid:107) ≤

(cid:15)
L0

.

A Generic First-Order Algorithmic Framework for Bi-Level Programming Beyond Lower-Level Singleton

Therefore, for any x ∈ X , we have

ϕ(x) = inf

y∈S(x)

F (x, y)

≤ F (x, y∗(x))
≤ F (x, yK(x)) + L0(cid:107)yK(x) − y∗(x)(cid:107)
≤ ϕK(x) + (cid:15).

This implies that, for any (cid:15) > 0, there exists k((cid:15)) > 0 such
that whenever K > k((cid:15)), we have

ϕ(xK) ≤ ϕK(xK) + (cid:15) ≤ ϕK(x) + (cid:15),

∀x ∈ X .

Next, as xK is a local minimum of ϕK(x) with uniform
neighborhood modulus δ, it follows

ϕK(xK) ≤ ϕK(x), ∀x ∈ Bδ(xK) ∩ X .

Since Bδ/2(¯x) ⊆ Bδ/2+(cid:107)xk−¯x(cid:107)(xK) ⊆ Bδ(xK), we have
that for any (cid:15) > 0, ∀x ∈ Bδ/2(¯x) ∩ X , there exists k((cid:15)) > 0
such that whenever K > k((cid:15)),

ϕ(xK) ≤ ϕK(xK) + (cid:15) ≤ ϕK(x) + (cid:15).

Taking K → ∞ and by the LSC of ϕ, ∀x ∈ Bδ/2(¯x) ∩ X ,
we have

ϕ(¯x) ≤ lim inf
K→∞
≤ lim inf
K→∞

ϕ(xK)

ϕK(xK) + (cid:15)

≤ lim
K→∞

ϕK(x) + (cid:15) = ϕ(x) + (cid:15).

By taking (cid:15) → 0, we have

ϕ(¯x) ≤ ϕ(x),

∀x ∈ Bδ/2(¯x) ∩ X ,

which implies ¯x ∈ arg minx∈Bδ/2(¯x)∩X ϕ(x), i.e, ¯x is a
local minimum of ϕ.

D.2. Nonsmooth LL Objective

It is well-known that a variety of nonsmooth regularization
techniques (e.g., (cid:96)1-norm regularization) have been utilized
in learning and vision areas. So in this section, we brieﬂy
discuss a potential extension of BDA for BLPs with the
nonsmooth LL objective, e.g.,

extended to address BLPs with the nonsmooth LL objective
in Eq. (12). Speciﬁcally, we ﬁrst write the descent direction
of the LL subproblem as

dh
k(x) = yk − proxslg(x,·)(yk − sl∇yf (x, yk)),

where proxslg(x,·) denotes the proximal operator w.r.t. the
nonsmooth function g(x, ·) and step size sl. Then by ag-
gregating dF
k(x), we derive a new Tk to handle
BLPs with the nonsmooth composite LL objective h, i.e.,

k (x) and dh

k(x) + (1 − αk)dF

Tk+1(x, yk(x)) = yk − (cid:0)αkdh

k (x)(cid:1) ,
(13)
where αk ∈ (0, 1]. In fact, since explicitly estimating the
subgradient information of some proximal operators may
be computationally infeasible in practice, one may apply
automatic differentiation through the dynamical system with
approximation techniques (Wang et al., 2016; Rajeswaran
et al., 2019) to obtain dϕK
dx , where ϕK(x) = F (x, yK(x)).
We are now in the position to extend the converge proper-
ties of BDA for BLPs in Eq. (13) from smooth LL case to
nonsmooth LL case. Similar to the discussion in the smooth
case, our analysis could follow the following roadmap:
Step 1: Denoting ˜S(x) = arg miny∈S(x) F (x, y) and fur-
ther h∗(x) = miny h(x, y), as extensions to Lemma 1 and
Lemma 2, we shall derive the boundedness of ˜S(x) and the
USC of h∗(x) for the nonsmooth LL case, respectively. The
proofs are indeed straightforward and purely technical, thus
omitted here.

Step 2: As an extension to Proposition 1 which focuses on
the smooth case, we may derive the following convergence
results regarding {yK(x)} in the light of the general fact
stated in (Sabach & Shtern, 2017).

Proposition 6. Suppose Assumption 1 is satisﬁed, g is con-
tinuous and convex w.r.t. y, and let {yK} be deﬁned as in
Eq. (13), sl ∈ (0, 1/Lf ], su ∈ (0, 2/(LF + σ)],

αk = min {2γ/k(1 − β), 1 − ε} ,

with k ≥ 1, ε > 0, γ ∈ (0, 1] and

β = (cid:112)1 − 2suσLF /(σ + LF ).

S(x) = arg min

y

h(x, y) = f (x, y) + g(x, y).

(12)

Denoting

Here we consider f as a function with the same properties
as that in our above analysis, while g is convex but not nec-
essarily smooth, w.r.t. y and continuous w.r.t. (x, y). Since
g is not necessarily differentiable w.r.t. y, these existing
gradient-based ﬁrst-order BLP methods are not available for
this problem. Fortunately, we demonstrate that by slightly
modifying our inner updating rule, BDA can be directly

˜yK(x) = proxslg(x,·)(yK(x) − sl∇yf (x, yK(x))),

and

Cy∗(x) = max

(cid:26)

(cid:107)y0 − y∗(x)(cid:107),

su
1 − β

(cid:107)∇yF (x, y∗(x))(cid:107)

(cid:27)

,

A Generic First-Order Algorithmic Framework for Bi-Level Programming Beyond Lower-Level Singleton

with y∗(x) ∈ ˜S(x) and x ∈ X . Then it holds that

(cid:107)yK(x) − y∗(x)(cid:107) ≤ Cy∗(x),

(cid:107)yK(x) − ˜yK(x)(cid:107) ≤

h(x, ˜yK(x)) − h∗(x) ≤

2Cy∗(x)(J + 2)
K(1 − β)
y∗(x)(J + 2)
K(1 − β)sl

2C 2

,

,

where J = (cid:98)2/(1 − β)(cid:99). Further, yK(x) converges to ˜S(x)
as K → ∞ for any x ∈ X .

Step 3: Taking a closer look at the proofs for Proposition 2
and Proposition 3, we observe that the techniques we used
barely rely on the smoothness of the LL objective. There-
fore, straightforward extensions of Proposition 2 and Propo-
sition 3 to the nonsmooth case can yield the desired uniform
convergence of ˜yK(x) and the UL objective convergence,
respectively.

Step 4: Similar to the arguments in the proof of Theorem 2,
by combining Step 1 and Step 2, we eventually meet the LL
solution set and UL objective convergence properties, and
hence the analysis framework in Theorem 1 has been acti-
vated. Therefore, the same convergence results concerning
{xK}K∈N and {ϕK(x)} can be achieved as following.
Theorem 5. Suppose Assumption 1 is satisﬁed, g is con-
tinuous and convex w.r.t. y, and let {yK} be deﬁned as in
Eq. (13), sl ∈ (0, 1/Lf ], su ∈ (0, 2/(LF + σ)],

αk = min {2γ/k(1 − β), 1 − ε} ,

with k ≥ 1, ε > 0, γ ∈ (0, 1] and

β = (cid:112)1 − 2suσLF /(σ + LF ).

Assume further that S(x) is nonempty for any x ∈ X and
S(x) is continuous on X . Then

(1) if xK ∈ arg minx∈X ϕK(x), we have the same results

as in Theorem 1;

(2) if xK is a local minimum of ϕK(x) with uniform neigh-
borhood modulus δ > 0, we have that any limit point
¯x of the sequence {xK} is a local minimum of ϕ.

