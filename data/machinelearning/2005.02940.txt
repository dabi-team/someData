OPTIMAL COVID-19 POOL TESTING WITH A PRIORI INFORMATION

Marc Beunardeau(cid:63), Éric Brier2, Noémie Cartier1, Aisling Connolly1,2, Nathanaël Courant1,
Rémi Géraud-Stewart1,2, David Naccache1,3, and Ofer Yifrach-Stav1

1 ÉNS (DI), Information Security Group, CNRS, PSL Research University, 75005, Paris, France.
given_name.family_name@ens.fr
2 Ingenico Laboratories, 75015, Paris, France.
given_name.family_name@ingenico.com
3 School of Cyber Engineering, Xidian University, Xi’an, 710071, PR China
david@xidian.edu.cn

Abstract As humanity struggles to contain the global COVID-19 infection, prophylactic actions are grandly
slowed down by the shortage of testing kits.
Governments have taken several measures to work around this shortage: the FDA has become more liberal on
the approval of COVID-19 tests in the US. In the UK emergency measures allowed to increase the daily number
of locally produced test kits to 100,000. China has recently launched a massive test manufacturing program.
However, all those efforts are very insufﬁcient and many poor countries are still under threat.
A popular method for reducing the number of tests consists in pooling samples, i.e. mixing patient samples and
testing the mixed samples once. If all the samples are negative, pooling succeeds at a unitary cost. However, if a
single sample is positive, failure does not indicate which patient is infected.
This paper describes how to optimally detect infected patients in pools, i.e. using a minimal number of tests to
precisely identify them, given the a priori probabilities that each of the patients is healthy. Those probabilities
can be estimated using questionnaires, supervised machine learning or clinical examinations.
The resulting algorithms, which can be interpreted as informed divide-and-conquer strategies, are non-intuitive
and quite surprising. They are patent-free. Co-authors are listed in alphabetical order.

1

Introduction and motivation

1.1 Testing for COVID-19 infection

The current COVID-19 (Coronavirus Disease 2019) pandemic is rapidly spreading and signiﬁcantly
impacts healthcare systems. Stay-at-home and social distancing orders enforced in many countries are
supporting the control of the disease’s spread, while causing turmoil in the economic balance and in social
structures [BBD+20]. Rapid detection of cases and contacts is an essential component in controlling the
spread of the pandemic. In the US, the current estimation is that at least 500,000 Covid-19 tests will need
to be performed daily in order to successfully reopen the economy [LVLM20]

Unfortunately, as humanity attempts to limit the global COVID-19 infection, prophylactic actions are

grandly slowed-down by the severe shortages of COVID-19 testing kits [BEF20].

There are currently two types of tests for COVID-19:

– Molecular diagnostic tests that detect the presence of SARS-COV-2 nucleic acids in human samples. A

positive result of these tests indicates the presence of the virus in the body.

– Serological diagnostic tests that identify antibodies (e.g., IgM, IgG) to SARS-COV-2 in clinical
specimens [WKLT20]. Serological tests, also known as antibody tests, can be helpful in identifying
not only those who are ill, but also those who have been infected, as antibodies are still present in
their blood. This identiﬁcation may be important for several reasons. First, this test can differentiate
those who are immune to the virus and those who are still at risk. Secondly, identifying populations
who have antibodies can facilitate research on the use of convalescent plasma in the development of a
cure for COVID-19 [FA20].

(cid:63) Work done when the author was with ÉNS and Ingenico Laboratories.

0
2
0
2

y
a
M
1
1

]
I

A
.
s
c
[

2
v
0
4
9
2
0
.
5
0
0
2
:
v
i
X
r
a

 
 
 
 
 
 
As mentioned, both tests are in very short supply. Governments have taken several measures to work
around this shortage: the FDA4 has become more liberal on the approval of COVID-19 tests via the EUA
(Emergency Use Authorization) [FA20]; in the US and the UK there are attempts to boost the number of
locally produced test kits to reach a throughput of 100,000 kits per day. Those efforts cannot, however, be
followed by many countries and there remains entire swaths of Africa, Asia and Latin America that are
under concrete threat.

1.2 Pool testing

To optimize the use of available tests, reduce costs and save time, pool testing (or group testing) can be
considered. The concept is credited to Dorfman [Dor43] who wished to test US servicemen for syphilis.
In pool testing, multiple samples are mixed, and the resulting ‘pool’ is tested using the same amount of
material or equipment that would have been required to test one individual sample. [Ste57, SG59] are
important reﬁnements of Durfman’s work.

However, when at least one sample in the pool is positive, then the pool test fails. This means that
(at least) one sample in the pool is positive, but gives no information about which one. The most naive
approach is then to re-test individually each sample, which can be costly and time consuming.

The area has seen numerous developments. [AJS19] provides a recent survey of the topic and [boo93]

is the reference book on the topic.

It is important to distinguish between two types of pool tests: Adaptive tests where the tested samples

depend on previously tested ones and Nonadaptive tests, where all the tests are planned in advance.

Pool tests are also classiﬁed as either probabilistic or combinatorial. In essence, probabilistic models
assume a probability distribution and seek to optimize the average number of tests required to test all the
patients. By opposition, combinatorial algorithms seek to minimize the worst-case number of tests when
the probability distribution governing the infection is unknown.

This paper deals with adaptive probabilistic tests.

1.3 Related Research

Pool testing has already been used to screen large portions of the population in scarcely-infected areas
(or as a best-effort measure, when test availability was low). Pool testing has been successfully used
to identify viral diseases, such as HIV [NABB19], ZIKA [BMBM17], and INFLUENZA [VMW+12]. In
addition, Pool testing has been suggested as a screening method for routine HCV, HBV, and HIV -1 PCR
donors for a blood-bank [RWS99]. In light of the recent pandemic and the urging need to test vast number
of subjects, the idea of Pool testing is becoming more and more appealing.

It is currently the ofﬁcial testing procedure in Israel [BAKS+20], Germany, South Korea [Cw20],
and some US5 [Haa20] and Indian6 states7 [Tod20]. Field research focusing on reducing the number
of tests [FTO+20, AWD20, GG20] did not analyse prior information strategies but instead provided
simulation (or small sample) results showing the beneﬁts of pool testing. In most cases, the existing
literature only uses pooling as a way to screen the infection in an emerging context, not as a precise
approach to identify which individuals are infected and which are not.

We also note projects meant to reduce the amount of work required for pool testing: e.g. the Origami
Assays [Woo20] Project, a collection of open source pool testing designs for standard 96 well plates. The
Origami XL3 design tests 1120 patients in 94 assay wells.

Yelin et al. [YAST+20] demonstrated that pool testing can be used effectively to identify one positive
SARS-COV-2 result within 32 samples, and possibly within 64 samples if the cycles are ampliﬁed, with

4 United States Food and Drug Administration
5 e.g Nebraska.
6 e.g. Uttar Pradesh, West Bengal, Punjab, Chhattisgarh, Maharashtra.
7 Indian Council of Medical Research, Advisory on feasibility of using pooled samples for molecular testing of COVID-19 ,

April 13, 2020.

2

an estimated false-negative rate of 10%. [Täu20] uses a strategy consisting in running ‘cross batches’,
where the same individuals are tested several times but in different pools, which eventually leads to
positive sample identiﬁcation. The resulting approach ends up using more tests overall (since it tests
every individual more than once) than the strategy proposed in this work and does not exploit prior
information. Similarly, Sinnott-Armstrong et al. [SAKH20] suggested to identify low-risk individuals (i.e.
asymptomatic and mild cases) and to test them as a pool using a matrix-based method, so as to reduce the
number of tests required by up to eight-fold, depending on the prevalence.

It is hence plausible to assume that a successful emergency application of the reﬁned pool testing

procedures described in this paper would improve the COVID-19 testing capacity signiﬁcantly.

1.4 Our Contribution

This paper departs from the above approaches by assuming the availability of extra information: the a
priori probability that each given test is negative. In practice, we may either assume that such probabilities
are given, estimated from patient trust metrics, or are learned from past COVID-19 tests. We assume in
this work that these probabilities are known.

We show that it is possible to ﬁnd positive samples in an optimal way, i.e., by performing on average
the minimum number of tests. This turns out to be faster than blind divide-and-conquer testing in the vast
majority of settings.

A concrete consequence of this research is the design of testing procedures that are faster and more

cost-effective.

2

Intuition

Before introducing models and general formulae, let us provide the intuition behind our algorithms.

Let us begin by considering the very small case of two samples. These can be tested individually
or together, in a pool. Individual COVID-19 testing claims a minimum two units of work—check one
sample, then check the other. Pool-checking them requires a minimum of one COVID-19 test. If it is
highly probable that both samples are negative, then pool testing is interesting: If both samples are indeed
negative, we can make a conclusion after one test and halve the COVID-19 test’s cost. However, if that
fails, we are nearly back to square one: One of these samples (at least) is positive, and we don’t know
which one.

In this paper, we identify when to check samples individually, and when to pool-check them instead—
including all possible generalizations when there are more than 2 samples. We assume that the probability
of a sample being positive is known to us in advance. The result is a testing ‘metaprocedure’ that offers
the best alternative to sequential and individual testing.

To demonstrate: the testing procedure that always works is to test every sample individually, one
after the other: This gives the ‘naive procedure’, which always performs 2 COVID-19 tests, as illustrated
in Figure 1. In this representation, the numbers in parentheses indicate which samples are being tested
at any given point. The leaves indicate which samples are negative (denoted 1) or positive (denoted 0),
for instance the leaf 01 indicates that only the second sample is healthy. Note that the order in which
each element is tested does not matter: There are thus 2 equivalent naive procedures, namely the one
represented in Figure 1, and the procedure obtained by switching the testing order of (1) and (2).

Alternatively, we can leverage the possibility to test both samples together as the set {1, 2}. In this
case, pooling the pair {1, 2} must be the ﬁrst step: Indeed, testing {1, 2} after any other test would be
redundant, and the deﬁnition of testing procedures prevents this from happening. If the test on {1, 2} is
negative, both samples are negative and the procedure immediately yields the outcome 11. Otherwise, we
must identify which of the samples 1 or 2 (or both) is responsible for the test’s positiveness. There are
thus two possible procedures, illustrated in Figure 2.

Intuitively, the possibility that this procedure terminates early indicates that, in some situations at least,
only one test is performed, and is thus less costly than the naive procedure. However, in some situations
up to three tests can be performed, in which case it is more costly than the naive procedure.

3

(1)

(2)

(2)

11

10

01

00

Figure 1. The “naive procedure” for n = 2 consists in testing each entity separately and sequentially.

(1,2)

(1,2)

11

(1)

11

(2)

10

(2)

01

(1)

01

00

10

00

Figure 2. Two pooling testing procedures having (1, 2) as root.

Concretely, we can compute how many COVID-19 tests are performed on average by each approach,
depending on the probability x1 that the ﬁrst sample is positive, and x2 that the second is positive. To each
procedure, naive, pool-left, pool-right, we associate the following polynomials representing the expected
stopping time:

– Lnaive = 2
– Lpool-left = (1 − x1)(1 − x2) + 2(1 − x1)x2 + 3x1(1 − x2) + 3x1x2
– Lpool-right = (1 − x1)(1 − x2) + 3(1 − x1)x2 + 2x1(1 − x2) + 3x1x2

It is possible to see analytically which of these polynomials evaluates to the smallest value as a function
of (x1, x2). Looking at Figure 3, we use these expectations to deﬁne zones in [0, 1]2 where each algorithm
is optimal (i.e. the fastest on average). More precisely, the frontier between zones C and B has equation
x1 = x2, the frontier between A and B has equation x2 = (x1 − 1)/(x1 − 2), the frontier between A and C
has equation x2 = (2x1 − 1)/(x1 − 1), and the three zones meet at x1 = x2 = (3 −
5)/2, a well-known
cutoff value observed as early as 1960 [Ung60].

√

x2

1

0

0

C

A

B

x1

1

Figure 3. Optimality zones for n = 2. A : naive procedure; B : pooling procedure (right); C : pooling procedure (left).

Having identiﬁed the zones, we can write an algorithm which, given x1 and x2, identiﬁes in which
zone of Figure 3 (x1, x2) lies, and then apply the corresponding optimal testing sequence. In the speciﬁc
case illustrated above, three algorithms out of three were needed to deﬁne the zones; however, for any
larger scenario, we will see that only a very small portion of the potential algorithms will be carefully
selected.

4

Our objective is to determine the zones, and the corresponding testing algorithms, for arbitrary n, so as
to identify which samples in a set are negative and which are not, while minimizing the expected number
of testing operations.

3 Preliminaries

This section will formalize the notion of a testing procedure, and the cost thereof, so that the problem
at hand can be mathematically described. We aim at the greatest generality, which leads us to introduce
‘and-tests’, a special case of which are samples that can be pool tested.

3.1 Testing procedures

We consider a collection of n samples. Let [n] denote {1, . . . , n}, and Ω = P([n])\{ /0}, where P is the
power set (ie. P(X) is the set of subsets of X).

Deﬁnition 1 (Test). A test is a function φ : Ω → {0, 1}, that associates a bit to each subset of Ω .

We focus in this work on the following:

Deﬁnition 2 (And-Tests). An and-test φ : Ω → {0, 1} is a test satisfying the following property:

∀T ∈ Ω ,

φ (T ) = (cid:94)

φ ({t}).

t∈T

In other terms, the result of an and-test on a set is exactly the logical and of the test results on individual
members of that set.

Remark 1. Note that ‘or-tests’, where ∧ is replaced by ∨ in the deﬁnition, are exactly dual to our setting.
‘xor-tests’ can be deﬁned as well but are not investigated here. Although theoretically interesting by their
own right, we do not address the situation where both and-tests and or-tests are available, since we know
of no concrete application where this is the case.

Elements of Ω can be interpreted as n-bit strings, with the natural interpretation where the i-th bit indicates
whether i belongs to the subset. We call selection an element of Ω .

Deﬁnition 3 (Outcome). The outcome Fφ (T ) of a test φ on T ∈ Ω is the string of individual test results:

When T = [n], Fφ will concisely denote Fφ ([n]).

Fφ (T ) = {φ (x), x ∈ T } ∈ {0, 1}n.

Our purpose is to determine the outcome of a given test φ , by minimizing in the expected number of
queries to φ . Note that this minimal expectation is trivially upper bounded by n.

Deﬁnition 4 (Splitting). Let T ∈ Ω be a selection and φ be a test. Let S be a subset of Ω . The positive
part of S with respect to T , denoted S (cid:62)
T , is deﬁned as the set

S (cid:62)

T = {S|S ∈ S , S ∧ T = T } .

where the operation ∧ is performed element-wise. This splits S into two. Similarly the complement
S ⊥

T is called the negative part of S with respect to T .

T = S − S (cid:62)

We are interested in algorithms that ﬁnd Fφ . More precisely, we focus our attention on the following:
Deﬁnition 5 (Testing procedure). A testing procedure is a binary tree T with labeled nodes and leaves,
such that:

5

1. The leaves of T are in one-to-one correspondence with Ω in string representation;
2. Each node of T which is not a leaf has exactly two children, (S⊥, S(cid:62)), and is labeled (S, T ) where

S ⊆ Ω and T ∈ Ω , such that
(a) S⊥ ∩ S(cid:62) = /0
(b) S⊥ (cid:116) S(cid:62) = S
(c) S⊥ = S⊥

T and S(cid:62) = S(cid:62)
T .

Remark 2. It follows from the deﬁnition 5 that a testing procedure is always a ﬁnite binary tree, and that
no useless calls to φ are performed. Indeed, doing so would result in an empty S for one of the children
nodes. Furthermore, the root node has S = Ω .

3.2

Interpreting and representing pooling procedures

S = Ω ,
T = (1, 2)

(3)

(1)

111

110

(3)

(2)

101

100

(3)

(3)

011

010

001

000

[3] = {1, 2, 3}, Ω =
Figure 4. Graphical
{{1}, {2}, {3}, {1, 2}, {1, 3}, {2, 3}, {1, 2, 3}}, the initial set of selections is S = Ω . Only the T labels are written on
nodes. Only the S labels are written for leaves.

procedure. The

representation

collection

testing

of

is

a

Consider a testing procedure T , deﬁned as above. T describes the following algorithm. At each node
(S, T ), perform the test φ on the selection T of samples. If φ (T ) = 0, go to the left child; otherwise go to
the right child. Note that at each node of a testing procedure, only one invocation of φ is performed.

The tree is ﬁnite and thus this algorithm reaches a leaf Sﬁnal in a ﬁnite number of steps. By design,

Sﬁnal = Fφ .

Remark 3. From now on, we will ﬁx φ and assume it implicitly.

Remark 4. We represent a testing procedure graphically as follows: Nodes (in black) are labeled with T ,
whereas leaves (in blue) are labeled with S written as a binary string. This is illustrated in Figure 4 for
n = 3.

This representation makes it easy to understand how the algorithm unfolds and what are the outcomes:
Starting from the root, each node tells us which entity is tested. If the test is positive, the right branch is
taken, otherwise the left branch is taken. Leaves indicate which samples tested positive and which samples
tested negative from now on.

Remark 5. The successive steps of a testing procedure can be seen as imposing new logical constraints.
These constraints ought to be satisﬁable (otherwise one set S is empty in the tree, which cannot happen).
The formula at a leaf is maximal in the sense that any additional constraint would make the formula
unsatisﬁable. This alternative description in terms of satisﬁability of Boolean clauses is in fact strictly
equivalent to the one that we gave.

In that case, T is understood as a conjunction (cid:86)

T [i]=1 ti, S is a proposition formed by a combination of
terms ti, connectors ∨ and ∧, and possibly ¬. The root has S = (cid:62). The left child of a node labeled (T, S)
is labeled S⊥
T = S ∧ T . At each node and leaf, S must be
satisﬁable.

T = S ∧ (¬T ); while the right child is labeled S(cid:62)

6

3.3 Probabilities on trees

To determine how efﬁcient any given testing procedure is, we need to introduce a probability measure,
and a metric that counts how many calls to φ are performed.

We consider the discrete probability space (Ω , Pr). The expected value of a random variable X is

classically deﬁned as:

E[X] = ∑
ω∈Ω

X(ω) Pr(ω)

Let T a testing procedure, and let S ∈ Ω be one of its leaves. The length (cid:96)T (S) of T over S is the distance
on the tree from the root of T to the leaf S. This corresponds to the number of tests required to ﬁnd S if S
is the outcome of φ . The expected length of a testing procedure T is deﬁned naturally as:
LT = E [(cid:96)T ] = ∑
ω∈Ω

(cid:96)T (ω) Pr(ω)

It remains to specify the probabilities Pr(ω), i.e. for any given binary string ω, the probability that ω is
the outcome.

If the different tests are independent, we can answer this question directly with the following result:

Lemma 1. Assume that the events ‘φ ({i}) = 1’ and ‘φ ({ j}) = 1’ are independent for i (cid:54)= j. Then,
∀ω ∈ Ω , Pr(ω) can be written as a product of monomials of degree 1 in x1, . . . , xn, where

Thus LT is a multivariate polynomial of degree n with integer coefﬁcients.

xi = Pr(φ ({i}) = 1) = Pr(i-th bit of ω = 1).

In fact, or-tests provide inherently independent tests. Therefore we will safely assume that the independ-
ence assumption holds.
Example 1. Let n = 5 and ω = 11101, then Pr(ω) = x1x2x3(1 − x4)x5.
Remark 6. LT is uniquely determined as a polynomial by the integer vector of length 2n deﬁned by all its
lengths: (cid:96)(T ) = ((cid:96)T (0...0), . . . , (cid:96)T (1...1)).

4 Optimal pool tests

We have now introduced everything necessary to state our goal mathematically. Our objective is to identify
the best performing testing procedure T (i.e. having the smallest LT ) in a given situation, i.e. knowing
Pr(ω) for all ω ∈ Ω .

4.1 Generating all procedures

We can now explain how to generate all the testing procedures for a given n ≥ 2.

One straightforward method is to implement a generation algorithm based on the deﬁnition of a testing
procedure. Algorithm 1 does so recursively by using a coroutine. The complete list of testing procedures
is recovered by calling FindProcedure(Ω , Ω \ { /0}).

Algorithm 1: FindProcedure

Input: S ∈ Ω , C ∈ Ω .
Output: A binary tree.

if |S| == 1 then return S
1.
(cid:62) = C(cid:48) = /0
⊥ = S(cid:48)
2. S(cid:48)
3. for each c ∈ C
S⊥ = S⊥
4.
c
S(cid:62) = S(cid:62)
5.
c
if S⊥ /∈ S(cid:48)
6.
⊥ = S(cid:48)
S(cid:48)
7.
S(cid:48)
(cid:62) = S(cid:48)
8.
C(cid:48) = C(cid:48) ∪ {c}
9.

⊥ and S(cid:62) /∈ S(cid:48)
(cid:62)
⊥ ∪ {S⊥}
(cid:62) ∪ {S(cid:62)}

7

C = C −C(cid:48)[i]
for each T⊥ ∈ FindProcedure(S(cid:48)

10. for i ∈ {1, . . . , |C(cid:48)|}
11.
12.
13.
14.

yield (C(cid:48)[i], T⊥, T(cid:62))

for each T(cid:62) ∈ FindProcedure(S(cid:48)

(cid:62)[i],C)

⊥[i],C)

We implemented this algorithm (in Python, source code available upon request). The result of testing
procedure generations for small values of n is summarized in Table 1. The number of possible testing
procedures grows very quickly with n.

Table 1. Generation results for some small n

n Number of procedures

Time

1
2
3
4

1
4
312

0
∼ 0
∼ 0
36585024 ∼ 30 mn

An informal description of Algorithm 1 is the following. Assuming that you have an unﬁnished
procedure (i.e. nodes at the end of branches are not all leaves). For those nodes S, compute for each T
the sets S(cid:62)
T . If either is empty, abort. Otherwise, create a new (unﬁnished) procedure, and launch
recursively on nodes (not on leaves, which are such that S has size 1).

T and S⊥

Algorithm 1 terminates because it only calls itself with strictly smaller arguments. We will discuss

this algorithm further after describing some properties of the problem at hand.

4.2 Metaprocedures

Once the optimality zones, and the corresponding testing procedures, have been identiﬁed, it is easy to
write an algorithm which calls the best testing procedure in every scenario. At ﬁrst sight, it may seem
that nothing is gained from doing so — but as it turns out that only a handful of procedures need to be
implemented.

This construction is captured by the following deﬁnition:

Deﬁnition 6 (Metaprocedure). A metaprocedure M is a collection of pairs (Zi, Ti) such that:
1. Zi ⊆ [0, 1]n, Zi ∩ Z j = /0 whenever i (cid:54)= j and (cid:70)
i Zi = [0, 1]n.
2. Ti is a testing procedure and for any testing procedure T ,

∀x ∈ Zi, LTi(x) ≤ LT (x).

A metaprocedure is interpreted as follows: Given x ∈ [0, 1]n ﬁnd the unique Zi that contains x and run
the corresponding testing procedure Ti. We extend the notion of expected length accordingly:LM =
mini LTi ≤ n.

One way to ﬁnd the metaprocedure for n, is to enumerate all the testing procedures using Algorithm 1,

compute all expected lengths LT from the tree structure, and solve polynomial inequalities.

Surprisingly, a vast majority of the procedures generated are nowhere optimal: This is illustrated in
Table 2. Furthermore, amongst the remaining procedures, there is a high level of symmetry. For instance,
in the case n = 3, 8 procedures appear 6 times, 1 a procedure appears 3 times, and 1 procedure appears
once. The only difference between the occurrences of these procedures — which explains why we count
them several times — is the action of the symmetric group S6 on the cube (see Appendix B for a complete
description).

The metaprocedure for n = 3 cuts the unit cube into 52 zones, which correspond to a highly symmetric
and intricate partition, as illustrated in Figures 5, 6, and 7. An STL model was constructed and is available
upon request.

8

Figure 5. Slices of the cube decomposition for the n = 3 metaprocedure, each colour corresponds to a different strategy, which
is optimal at this position. The slices are taken orthogonally to the cube’s main diagonal, with the origin at the center of each
picture. Each color corresponds to a procedure. The symmetries are particularly visible.

The large number of suboptimal procedures shows that the generate-then-eliminate approach quickly
runs out of steam: Generating all procedures for n = 6 seems out of reach with Algorithm 18. The number
of zones, which corresponds to the number of procedures that are optimal in some situation, is on the
contrary very reasonable.

Lemma 2 (Number of naive procedures). Let n ≥ 1, then there are

P(n) =

k2n−k

n
∏
k=1

equivalent naive procedures.

Proof. By induction on n: There are (n + 1) choices of a root node, P(n) choices for the left child, and
P(n) choices for the right child. This gives the recurrence P(n + 1) = (n + 1)P(n)2, hence the result.

This number grows rapidly and constitutes a lower bound for the total number of procedures (e.g. for
n = 8 we have P(n) > 2184). On the other hand, the naive procedure is the one with maximal multiplicity,
which yields a crude upper bound C2k P(n) on the number of procedures, where Ct is the t-th Catalan
number deﬁned by:

Ct =

(cid:19)

1
t + 1

(cid:18)2t
t

∼

4n
√
n3/2

π

The zones can be determined by sampling precisely enough the probability space. Simple arguments
about the regularity of polynomials guarantee that this procedure succeeds, when working with inﬁnite
numerical precision. In practice, although working with inﬁnite precision is feasible (using rationals),
we opted for ﬂoating-point numbers, which are faster. The consequence is that sometimes this lack of
precision results in incorrect results on the zone borders — however this is easily improved by increasing
the precision or checking manually that there is no sub-zone near the borders.

8 n = 6 is still very far from the current SARS-COV-2 test pooling capacity of n = 32 or n = 64 mentioned in the introduction.

9

Figure 6. Slices through the cube at the z = 0.17 (left) and the z = 0.33 (right) planes, showing the metaprocedure’s rich structure.
Each colour corresponds to a different strategy, which is optimal at this position. The origin is at the top left.

Figure 7. A 3D visualisation of the cube. Left: exterior, where it is visible that each face has the same decomposition as the 2D
problem; Middle: with the naive algorithm region slightly removed, showing that it accounts for slightly less than half of the
total volume; Right: exploded view of the 52 substructures (looking from (−1, −1, −1)).

10

n Number of procedures

Zones

1
2
3
4
5
6

1
4
312
36585024
8.926 · 1020
2.242 · 1055

1
3
52
181
?
?

Table 2. Procedures and metaprocedures for some values of n. The number of zones for n = 5 and 6 cannot be determined in a
reasonable time with the generate-then-eliminate approach.

5 Pruning the generation tree

We now focus on some of the properties exhibited by testing procedures, which allows a better understand-
ing of the problem and interesting optimizations. This in effect can be used to prune early the generation
of procedures, and write them in a more compact way by leveraging symmetries. We consider in this
section a testing procedure T .

Lemma 3. Let B0 and B1 be two binary strings of size n, that only differ by one bit (i.e. B0[i] = 0 and
B1[i] = 1 for some i). Then (cid:96)T (B0) ≤ (cid:96)T (B1).

Proof. First notice that for all T , T (cid:48), and b, b(cid:48) ∈ {(cid:62), ⊥} we have (Sb
Sbb(cid:48)
T T (cid:48).

We have the following : If there exists k, T1, . . . , Tk, and β1, . . . , βk such that

T )b(cid:48)

T (cid:48) = (Sb(cid:48)

T (cid:48))b

T . We will denote both by

then there exists i ≤ k such that

(Ω )β1···βk
T1···Tk

= {B1}

(Ω )β1···¬βi···βk
T1···Ti···Tk

= {B0}

Indeed there exists i ≤ k such that βi = (cid:62) and Ti = {i0} ∪ E where for all j in E, B0[ j] = B1[ j] = 0. This
yields

(Ω )β1···βi−1βi+1···βk
T1···Ti−1Ti+1···Tk

= {B0, B1}

and the result follows.

Remark 7. Proposition 3 indicates that testing procedures are, in general, unbalanced binary trees: The
only balanced procedure being the naive one.

Lemma 4. If N is the naive procedure, then for any testing procedure T and for all x1, . . . , xn such that
xi > 1
2 ,

LN (x1, . . . , xn) ≤ LT (x1, . . . , xn) .

In other terms {∀i ∈ [n], 1

2 ≤ xi ≤ 1} is contained in the naive procedure’s optimality zone.

Proof. An immediate corollary of Proposition 3 is that for all i ∈ [n], we have ∂xiLT (x1, . . . , xn) ≥ 0,
where ∂xi indicates the derivative with respect to the variable xi. Since the native procedure has a constant
length, it sufﬁces to show that it is optimal at the point { 1
2 }. Evaluating the length polynomials at
this point gives

2 , . . . , 1

LT

1
2n ∑
Now remember that the naive procedure gives the only perfect tree. It sufﬁces to show that unbalancing
this tree in any way results in a longer sum in the equation above. Indeed, to unbalance the tree one needs
to:

(cid:96)T (ω) =

LT dx.

, . . . ,

[0,1]n

ω∈Ω

1
2

=

(cid:18) 1
2

(cid:19)

(cid:90)

11

– Remove two bottom-level leaves, turning their root node into a leaf
– Turn one bottom-level leaf into a node
– Attach two nodes to this newly-created leaf

The total impact on the sum of lengths is +1. Hence the naive algorithm is minimal at { 1
therefore, in the region {∀i ∈ [n], 1

2 ≤ xi ≤ 1}.

2 , . . . , 1

2 }, and

Remark 8. This also show that if we assume that the probabilities are supposed uniform (ie. we assume
no a priori knowledge) the optimal procedure is the naive one. Therefore we can see that the gain for
n = 3 is aprroximately 0, 34 since the optimal procedure in average gives 2, 66. In percentage the gain is
15%. If the probabilites are very low we have a gain of almost 2 which is 3 times faster. As expected it is
much more interesting if we think that the samples have a good chance to be negative, which is the case in
most real life scenarii.

Lemma 5. If the root has a test of cardinality one, then the same algorithms starting at both sons have
same expected stopping time. This applies if the next test is also of cardinal one.

Proof. Without loss of generality we can assume that the test is {1}. We have {0, 1}n(cid:62)
{0, 1}n−1} and {0, 1}n⊥
{1} = {1b2 · · · bn|b2 · · · bn ∈ {0, 1}n−1}. A test T that doesn’t test 1 applied on
those sets will give the same split for both, and the probability that the test answers yes or no is
the same. This is also true for the sets and the tests T such that i is not in T for i in {1, . . . , k}.
{0kb2 · · · bn|b2 · · · bn ∈ {0, 1}n−k} and {01kb2 · · · bn|b2 · · · bn ∈ {0, 1}n−k}. A test T such that there exists i
in T {1, . . . , k} brings no information for the set of possibilities {01kb2 · · · bn|b2 · · · bn ∈ {0, 1}n−k}, but
testing this i is useless for the set {0kb2 · · · bn|b2 · · · bn ∈ {0, 1}n−k}. So we can apply the test T − {1, . . . , k}.

{1} = {0b2 · · · bn|b2 · · · bn ∈

Corollary 1. If the root has a test of cardinal one, then an optimal algorithm can always apply the same
test for the right and left child. If this test is also of cardinal one then the property is still true.

This result helps in identifying redundant descriptions of testing procedures, and can be used to narrow
down the generation, by skipping over obvious symmetries of the naive procedure (see Figure 8).

(1)

(2)

(3)

(3)

(3)

(2)

(2)

111

110

101

100

011

001

010

000

Figure 8. Naive algorithm, where the order of tests are unimportant in the left and right branches.

To further accelerate generation we can only keep one representative of each algorithms that have the

same expected length for all xi.

Lemma 6. If a node labeled T1 has two children that are both labeled T2, then we can interchange T1
and T2 without changing the testing procedure’s expected length.

Yet another simple observation allows to reduce the set of subsets T at each step:
Lemma 7. Consider a node labeled (T, S ). Assume that there is i ∈ [n] such that, for all S in S , i /∈ S.
Then we can replace T by T ∪ {i}.

Proof. We can easily see that S(cid:62)

T = S(cid:62)

T ∪{i} and S⊥

T = S⊥

T ∪{i}.

Finally we can leverage the fact that the solutions exhibit symmetries, which provides both a compact
encoding of testing procedures, and an appreciable reduction in problem size.

12

Lemma 8. Let σ ∈ Sn be a permutation on n elements. If we apply σ to each node and leaf of T , which
we can write σ (T ), then

Lσ (T )(x1, . . . , xn) = LT (σ (x1, . . . , xn)) .
(cid:1) = S(cid:62)

Proof. Note that for any S ∈ Ω and T ∈ Ω \ { /0} we have σ (cid:0)S(cid:62)
σ (T ), where σ
T
operates on each binary string. It follows that for any leaf S, (cid:96)T (S) becomes (cid:96)T (σ (S)) under the action
of σ , hence the result.
Lemma 9. Let S be a simplex of the hypercube, T a procedure, E = {σ (T )|σ ∈ Sn}, then there exists
T0 in E, such that for all x in S, T1 in E we have

σ (T ) and σ (cid:0)S⊥

(cid:1) = S⊥

T

Moreover we have for all σ in Sn, x in σ (S), T1 in E

LT0(x) ≤ LT1(x).

Lσ (T0)(x) ≤ LT1(x).

Remark 9. The last two propositions allow us to solve the problem on a simplex of the hypercube (of
volume 1/n!) such as {p1, . . . , pn | 1 ≥ p1 · · · ≥ pn ≥ 0}.

6 Best testing procedure at a point

We examine the following problem: Find the testing procedure T for a given k ≤ n, (pi1, . . . , pik ) ∈ [0, 1]n,
and a selection P ⊆ 2[k] that satisﬁes:
– ST = P,
– T is optimal at point (pi1, . . . , pik )
This can be computed using a dynamic programming technique, by examining the outcome of each
possible test that is the root node of the testing procedure T , which gives Algorithm 2.

The same dynamic programming algorithm can also be used to compute the number of testing
procedures (including those leading to duplicate polynomials) that exist in a given dimension. It is actually
even easier, since there is a huge number of symmetries that can be exploited to count.9

Deﬁnition 7 (Decided point). We say that x is a decided point for S a set of selections if either of the
following is true:
– x ∈ S for all S ∈ S
– x (cid:54)∈ S for all S ∈ S

In the ﬁrst case, we will say that x is a positive decided point, and a negative decided point in the second
case.

We denote by D +
S ∪ D −

DS = D +

S its set of decided points.

S the set of positive decided points of S , D −

S its set of negative decided points, and

Input: k ≥ 0, (p1, . . . , pk) ∈ [0, 1]k, S ⊂ 2[k].
Output: The optimal testing procedure T at point (p1, . . . , pk) which satisﬁes ST = S .

Algorithm 2: FindOptimal

U ← {u1, . . . , u(cid:96)} = [k] \ DS

if k == 0 then return the naive algorithm
if |DS | > 0

1.
2.
3.
4. R ← {{r1, . . . , rp} | {ur1 , . . . , urp } ∪ D +
S }
T ← FindOptimal ((cid:96), (pu1 , . . . , pu(cid:96) ), R)
5.
replace {t1, . . . ,tr} by {ut1 , . . . , utr } in T
6.
replace {(cid:96)1, . . . , (cid:96)r} by {u(cid:96)1 , . . . , u(cid:96)r } ∪ D +
7.
8. else

S in T

9 Indeed, we can apply the algorithm to an even higher dimension than our solution to the given point problem.

13

9. W ← /0
10.
11.
12.
13.
14.
15.
16.
17.

for each T ⊆ [k]
S⊥ ← S ⊥
T
S(cid:62) ← S (cid:62)
T
if S⊥ = /0 or S(cid:62) = /0 then continue
T⊥ ← FindOptimal(k, (p1, . . . , pk), S⊥)
T(cid:62) ← FindOptimal(k, (p1, . . . , pk), S(cid:62))
W ← W ∪ {(T , T⊥, T(cid:62))}

return the best algorithm in W at point (p1, . . . , pn)

Counting the number of algorithms in a given dimension works the same way; the only difference is that
there is no need to look at the probabilities, and thus, the resulting Algorithm 3 does fewer recursive calls
and is faster.10

Input: k ≥ 0, S ⊂ 2[k].
Output: The number of testing procedures which satisfy ST = S .

Algorithm 3: CountAlgorithms

U ← {u1, . . . , u(cid:96)} = [k] \ DS

if k == 0 then return 1
if |DS | > 0

1.
2.
3.
4. R = {{r1, . . . , rp} | {ur1 , . . . , urp } ∪ D +
S }
return CountAlgorithms((cid:96), R)
5.
6. c ← 0
7. for each T ⊆ [k]
8. S⊥ ← S ⊥
T
9. S(cid:62) ← S (cid:62)
T
10.
11.
12.
13.
14. return c

if S⊥ = /0 or S(cid:62) = /0 then continue
c⊥ ← CountAlgorithms(k, (p1, . . . , pk), S⊥)
c(cid:62) ← CountAlgorithms(k, (p1, . . . , pk), S(cid:62))
c ← c + c(cid:62)c⊥

7 Enumerating procedures for n = 3

All the procedures for n = 3 that are optimal at some point, up to symmetries, are represented in Figure 9.

8 Conclusion and open questions

We have introduced the question of optimal pool testing with a priori probabilities, where one is given a
set of samples and must determine in the least average number of operations which samples are negative,
and which are not. We formalized this problem and pointed out several interesting combinatorial and
algebraic properties that speed up the computation of an optimal sequence of operations — which we call
a metaprocedure. We determined the exact solution for up to 4 samples.

For larger values, our approach requires too many computation to be tractable, and thus an exact
solution is out of reach; however we gave several heuristic algorithms that scale well. We showed that
these heuristics are sub-optimal in all cases, but they always do better than standard screening. The
existence of a polynomial-time algorithm that ﬁnds optimal metaprocedures for large value of n is an open
question — although there is probably more hope in ﬁnding better heuristics. An alternative would be to
modify our generation algorithm to kill branches when the resulting expected lengths are all worse than
some already-known procedure.

Once the metaprocedure for a given n is known, which only needs to be computed once, implementa-

tion is straightforward and only invokes a handful of (automatically generated) cases.

10 We are not aware of a closed-form formula providing the same values as this algorithm.

14

(1,2)

(1,2,3)

111

(1,2)

(3)

(1,3)

(1,2)

110

(1)

(1)

111

110

101

(1)

(3)

(1)

(3)

(2,3)

(2)

(2)

100

(2)

111

110

(3)

(2)

101

100

011

(2)

(3)

(3)

(3)

(3)

(3)

(3)

101

100

(3)

(3)

010

(3)

111

110

101

100

011

010

001

000

011

010

001

000

011

010

001

000

001

000

(1,2,3)

111

(1,2)

(1,2,3)

(1,2)

111

(1,2)

110

(1,3)

(1,3)

(3)

(1,3)

110

(1,3)

101

(2,3)

(2)

(2,3)

111

110

101

(1)

101

(1)

011

(1)

111

101

011

(1)

100

(2,3)

100

(2,3)

100

(2)

(2)

(3)

011

(2)

011

(2)

010

(3)

110

100

001

(2)

010

(3)

010

(3)

001

000

100

000

001

000

001

000

(1,2)

(1,2,3)

(3)

(1)

111

(1)

111

110

(3)

(2,3)

(2)

(2,3)

101

100

011

(2)

110

(3)

011

(2)

010

(3)

101

100

010

(3)

001

000

001

000

Figure 9. Optimal procedures (without permutations) for each zone when n = 3.

15

Finally, in our model we do not consider false positives and false negatives. In other words, tests are
assumed to be 100% accurate. Integrating in the model false positive and false negative probabilities is an
interesting research challenge.

Besides the performance gain resulting from implementing metaprocedures for sample testing, the

very general framework allows for applications in medical and engineering tests.

References

AJS19.

AWD20.

Matthew Aldridge, Oliver Johnson, and Jonathan Scarlett. Group testing: an information theory perspective. CoRR,
abs/1902.06002, 2019.
Assif Assad, Muzafar Ahmad Wani, and Kusum Deep. A Comprehensive Strategy to Lower Number of COVID-
19 Tests. 2020.

BAKS+20. Roni Ben-Ami, Agnes Klochendler, Matan Seidel, Tal Sido, Ori Gurel-Gurevich, Moran Yassour, Eran Meshorer,
Gil Benedek, Irit Fogel, Esther Oiknine-Djian, Asaf Gertler, Zeev Rotstein, Bruno Lavi, Yuval Dor, Dana G Wolf,
Maayan Salton, and Yotam Drier. Pooled rna extraction and pcr assay for efﬁcient sars-cov-2 detection. medRxiv,
2020.
Scott Baker, Nicholas Bloom, Steven J Davis, Kyle Kost, Marco Sammon, and Tasaneeya Viratyosin. The
unprecedented stock market reaction to COVID-19. COVID Economics: Vetted and Real-Time Papers, 1(3), 2020.
Melanie Hicken Blake Ellis and Ashley Fantz. CNN Investigates: Coroners worry COVID-19 test shortages could
lead to uncounted deaths, 2020 (accessed April 23, 2020). https://tinyurl.com/COVID19-BEF20.
BMBM17. Damien Bierlaire, Sylvie Mauguin, Julien Broult, and Didier Musso. Zika virus and blood transfusion: the experience

BBD+20.

BEF20.

boo93.
Cw20.

Dor43.

FA20.

of french polynesia. Transfusion, 57(3pt2):729–733, 2017.
Combinatorial group testing and its applications. World Scientiﬁc, Singapore, 1993.
Lim Chang-won. [Coronavirus] Veriﬁed ’sample pooling’ introduced to prevent herd infection in S. Korea - Aju
Business Daily, 2020 (accessed April 26, 2020). https://tinyurl.com/COVID19-CW20a.
Robert Dorfman. The detection of defective members of large populations. The Annals of Mathematical Statistics,
14(4):436–440, December 1943.
Food and Drug Administration. Coronavirus (COVID-19) Update: serological test validation and education efforts,
2020 (accessed April 23, 2020). https://tinyurl.com/COVID19-FA20.

FTO+20. Mauricio J Farfan, Juan P Torres, Miguel ORyan, Mauricio Olivares, Pablo Gallardo, and Carolina Salas. Optimizing

GG20.
Haa20.

RT-PCR detection of SARS-COV-2 for developing countries using pool testing. medRxiv, 2020.
Christian Gollier and Olivier Gossner. Group testing against COVID-19 . COVID Economics, 1(2):32–42, 2020.
Matthew Haave. [Gov. Ricketts provides update on coronavirus testing - 3KMTV, 2020 (accessed April 26, 2020).
https://tinyurl.com/COVID19-HAA20.

LVLM20. By Ethan Lee and The Harvard Crimson Virginia L. Ma. [At Least 500,000 Tests Needed Per Day to Reopen
Economy, Harvard Researchers Say, 2020 (accessed April 27, 2020). https://tinyurl.com/COVID19-LVLM20.
NABB19. Ngoc T Nguyen, Hrayer Aprahamian, Ebru K Bish, and Douglas R Bish. A methodology for deriving the sensitivity
of pooled testing, based on viral load progression and pooling dilution. Journal of translational medicine, 17(1):252,
2019.

RWS99. Willi Kurt Roth, Marijke Weber, and Erhard Seifried. Feasibility and efﬁcacy of routine pcr screening of blood
donations for hepatitis c virus, hepatitis b virus, and hiv-1 in a blood-bank setting. The Lancet, 353(9150):359–363,
1999.

SAKH20. Nasa Sinnott-Armstrong, Daniel Klein, and Brendan Hickey. Evaluation of group testing for SARS-COV-2 RNA.

SG59.

Ste57.

Täu20.
Tod20.

medRxiv, 2020.
Milton Sobel and Phyllis A. Groll. Group testing to eliminate efﬁciently all defectives in a binomial sample. Bell
System Technical Journal, 38(5):1179–1252, September 1959.
Andrew Sterrett. On the detection of defective members of large populations. The Annals of Mathematical Statistics,
T28(4):1033–1036, December 1957.
Matthias Täufer. Rapid, large-scale, and effective detection of COVID-19 via non-adaptive testing. bioRxiv, 2020.
India Today. Centre allows COVID-19 pool testing, plasma therapy in Maharashtra, 2020 (accessed April 26, 2020).
https://tinyurl.com/COVID19-TOD20.
Peter Ungar. The cutoff point for group testing. Comm. Pure Appl. Math., 13(1):49–54, 1960.

Ung60.
VMW+12. Tam T. Van, Joseph Miller, David M. Warshauer, Erik Reisdorf, Daniel Jernigan, Rosemary Humes, and Peter A.
Shult. Pooling nasopharyngeal/throat swab specimens to increase testing capacity for inﬂuenza viruses by pcr.
Journal of Clinical Microbiology, 50(3):891–896, 2012.

WKLT20. Yishan Wang, Hanyujie Kang, Xuefeng Liu, and Zhaohui Tong. Combination of RT-qPCR testing and clinical
features for diagnosis of COVID-19 facilitates management of SARS-COV-2 outbreak. Journal of medical virology,
2020.
Peter Woolf. Origam Essays, 2020. https://tinyurl.com/COVID19-WOO20.
Idan Yelin, Noga Aharony, Einat Shaer-Tamar, Amir Argoetti, Esther Messer, Dina Berenbaum, Einat Shafran,
Areen Kuzli, Nagam Gandali, Tamar Hashimshony, et al. Evaluation of COVID-19 RT-qPCR test in multi-sample
pools. medRxiv, 2020.

Woo20.
YAST+20.

16

A Approximation heuristics

The approach consisting in generating many candidates, only to select a few, is wasteful. In fact, for large
values of n (even from 10), generating all the candidates is beyond reach, despite the optimizations we
described.

Instead, one would like to obtain the optimal testing procedure directly. It is a somewhat simpler
problem, and we can ﬁnd the solution by improving on our generation-then-selection algorithm (see
Appendix 6). However if we wish to address larger values of n, we must relax the constraints and use the
heuristic algorithms described below, which achieve near-optimal results. This would be usefull in real
life scenarii for COVID-19 tests since we would like to test hundreds or more samples to have real gain.

A.1

Information-Based Heuristic

We ﬁrst associate a ‘cost’ to each outcome S, and set of outcomes S :

cost(S, S ) = f (S, S ) + g(S, S )

f (S, S ) = #{i ∈ [n] s.t. s[i] = 1 and ∃S ∈ S , S(cid:48)[i] = 0}

g(S, S ) =

(cid:40)

1 if ∃i ∈ {i ∈ [n] s.t. S[i] = 0}, ∃S(cid:48) ∈ S , S(cid:48)[i] = 1
0 otherwise

This function approximates the smallest integer n such that there exists n calls to φ with arguments
T1, . . . , Tn, and β1, . . . , βn in {⊥, (cid:62)} with S β1,...,βn
= {S}. This function is used to deﬁne a ‘gain’ function
T1···Tn
evaluating how much information is gathered when performing a test knowing the set of outcomes:

gain(T, S ) = ∑
S∈S (cid:62)
T

(cid:18)

1 −

(cid:19)

cost(S, S (cid:62)
T )
cost(S, S )

Pr(S) + ∑
S∈S ⊥
T

(cid:18)

1 −

(cid:19)

cost(S, S ⊥
T )
cost(S, S)

Pr(S)

Intuitively, we give higher gains to subsets T on which testing gives more information. Note that, if a call
to φ doesn’t give any information (i.e. S(cid:62)

T is empty), then gain(T, S) = 0.

T or S⊥

This heuristic provides us with a greedy algorithm that is straightforward to implement. For given

values x1, . . . , xn we thus obtain a testing procedure TH.

Testing the heuristic. We compared numerically TH to the metaprocedure found by exhaustion in the
case n = 3. The comparison consists in sampling points at random, and computing the sample mean of
each algorithm’s length on this input. The heuristic procedure gives a mean of 2.666, which underperform
the optimal procedure (2.661) by only 1%.

Counter-example to optimality. In some cases, the heuristic procedure behaves very differently from the
metaprocedure. For instance, for n = 3, x1 = 0.01, x2 = 0.17, x3 = 0.51, the metaprocedure yields a tree
which has an expected length of 1.889. The heuristic however produces a tree which has expected length
1.96. Both trees are represented in Figure 10.

Beyond their different lengths, the main difference between the two procedures of Figure 10 begin
at the third node. At that node the set S is the same, namely {010, 011, 100, 101, 110, 111}, but the two
procedures settle for a different T : The metaprocedure splits S, with T = {1, 3}, into S⊥
T = {010} and
S(cid:62)
T = {011, 100, 101, 110, 111}; while the heuristic chooses T = {1} instead, and gets S⊥
T = {010, 011}
and S(cid:62)

T = {100, 101, 110, 111}.

To understand this difference, ﬁrst notice that besides 010 and 011, all leaves are associated to a very
low probability. The heuristic fails to capture that by choosing T = {1, 3} early, it could later rule out the
leaf 010 in one step and 011 in two. There does not seem to be a simple greedy way to detect this early on.

17

(1,2,3)

111

(1,2)

(1,2,3)

110

(1,3)

111

(1,2)

101

(1)

110

(1)

100

(2,3)

(3)

(2,3)

011

(2)

101

100

011

(2)

010

(3)

010

(3)

001

000

001

000

Figure 10. The optimal metaprocedure tree (left), and heuristic metaprocedure (right) for the same point x = (0.01, 0.17, 0.51).
The optimal procedure has expected length 1.889, as compared to 1.96 for the heuristic procedure.

A.2 Pairing heuristic

Another approach is to use small metaprocedures on subsets of the complete problem. Concretely, given
n samples to test, place them at random into k-tuples (from some small value k, e.g. 5). Then apply the
k-metaprocedure on these tuples. While sub-optimal, this approach does not yield worst results than the
naive procedure.

In cases where it makes sense to assume that all the xi are equal, then we may even recursively use the
metaprocedures, i.e. the metaprocedures to be run are themselves places into k-tuples, etc. Using lazy
evaluation, only the necessary tests are performed.

B Equivalences and symmetries for n = 3

A procedure can undergo a transformation that leaves its expected length unchanged. Such transforma-
tions are called equivalences. On the other hand, Lemma 8 shows that some transformations operate a
permutation σ on the variables xi — such transformations are called symmetries.

Equivalences and symmetries are responsible for a large part of the combinatorial explosion observed
when generating all procedures. By focusing on procedures up to symmetry, we can thus describe the
complete set in a more compact way and attempt a ﬁrst classiﬁcation.

In the following representations (Figures 11, 12, and 13), blue indicates a ﬁxed part, and red indicate a
part undergoing some permutation. Double-headed arrows indicate that swapping nodes is possible. The
number of symmetries obtained by such an operation is indicated under the curly brace below.

18

(1)

(2)

(2)

(3)

(3)

(3)

(3)

2

2

22

(1)

(2)

(2,3)

(3)

(3)

(2)

(3)

2
(3)

(3)

(3)

2

22

(1)

(2,3)

(2)

(2)

(3)

(3)

(3)

(3)

2
(3)

(3)

2

(1)

22

(2,3)

(2,3)

(2)

(2)

(3)

(3)

(3)

(3)

2

2

22

Figure 11. Trees representation with a grouping by one element on the root. For a ﬁxed element, we have 22 possible permutations.
Since we have 4 patterns, we get 22 × 4 possible permutations for one grouping. Hence, we ﬁnally have 22 × 4 × 3 for all possible
groupings by one element.

19

(1,2)

(3)

(1)

(1,2)

(3)

(1)

(3)

(2)

45

46

(3)

(3)

47

48

2

(3)

(2,3)

(1,2)

(1,2)

(3)

(2)

45

46

(2)

(3)

(2)

(3)

(1,3)

47

48

45

46

(3)

(3)

2

(1,2)

(3)

(1)

45

46

(1)

45

46

(3)

(3)

47

48

2

47

48

45

46

(3)

(3)

2

(1,2)

(3)

(3)

(1)

(1)

(2)

(2)

(2)

(2)

(1,2)

(3)

(1,3)

(3)

(1,3)

(1)

(1)

45

46

(2,3)

45

46

(2)

47

48

45

46

(2)

(1,2)

(3)

(1,3)

(2)

2

45

46

(3)

(1)

47

48

(2)

(3)

2

2

47

48

45

46

(3)

(3)

2

22

(1,2)

(3)

(1,3)

(1,2)

(1,2)

(3)

(2,3)

(2,3)

(3)

(2,3)

(3)

(2,3)

(3)

(3)

2

22

(1,2)

2

(2)

45

46

(1)

(1)(2)(3)

(1)

(2)

45

46

(1,3)

47

48

45

46

(1)

(2)(1)(1)

45

46

(3)

(2)

45

46

(3)

(1)

47

48

45

46

(1)

(3)

(3)(3)(2)

47

48

(2)

(3)

47

48

(3)

(3)

3 × 2

2

2

2

(1,2)

(2)

(2)

2

(1,2)

(3)

(2,3)

(3)

(2,3)

(1,3)

(3)

45

46

(1)

(1)(2)(3)

45

46

(1)

(1)

47

48

45

46

(1)

(2)(1)(1)

47

48

(1)

46

(2)

(2)

2

(3)

(3)(3)(2)

3 × 2

2

Figure 12. Tree representations with a grouping by two elements on the root. For 10 ﬁxed elements, we have 2 possible
permutations, for 2 ﬁxed elements, we have 2 possible permutations, and for 2 possible permutations, we have 6 possible
permutations. Hence, we ﬁnally have 2 × 10 + 4 × 2 + 6 × 2 for all possible groupings by two elements.

(1,2,3)

(1,2,3)

(3)

(1)(2)(3)

(3)

(1)(2)(3)

(2)

(2,3)

(2)

(2)

45

(3)

(3)

(2)

(5)

(3)

(3)

(3)

2

2
46

45

22

(3)

2
(3)

(3)

(3)

(3)

(3)

2

(1,2,3)

22

(3)

All permutations with g = 2

Figure 13. Trees representation with a grouping by three elements on the root. For a ﬁxed element at the upper left corner side,
we have 22 possible permutations. For the upper right corner side, we get 22. We replace the subroot of the ﬁxed trees and get
(22 + 22) × 3. We also have the 40 × 3 trees from the grouping of two (g = 2). Hence, we have 40 × 3 + (22 + 22) × 3

20

