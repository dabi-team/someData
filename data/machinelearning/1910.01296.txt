9
1
0
2

t
c
O
3

]
S
D
.
s
c
[

1
v
6
9
2
1
0
.
0
1
9
1
:
v
i
X
r
a

Best-ﬁrst Search Algorithm for Non-convex Sparse Minimization

Shinsaku Sakaue
NTT Communication Science Laboratories

Naoki Marumo
NTT Communication Science Laboratories

November 1, 2021

Abstract

Non-convex sparse minimization (NSM), or (cid:96)0-constrained minimization of convex loss functions, is an im-
portant optimization problem that has many machine learning applications. NSM is generally NP-hard, and
so to exactly solve NSM is almost impossible in polynomial time. As regards the case of quadratic objective
functions, exact algorithms based on quadratic mixed-integer programming (MIP) have been studied, but no
existing exact methods can handle more general objective functions including Huber and logistic losses; this is
unfortunate since those functions are prevalent in practice. In this paper, we consider NSM with (cid:96)2-regularized
convex objective functions and develop an algorithm by leveraging the eﬃciency of best-ﬁrst search (BFS). Our
BFS can compute solutions with objective errors at most ∆ ≥ 0, where ∆ is a controllable hyper-parameter that
balances the trade-oﬀ between the guarantee of objective errors and computation cost. Experiments demon-
strate that our BFS is useful for solving moderate-size NSM instances with non-quadratic objectives and that
BFS is also faster than the MIP-based method when applied to quadratic objectives.

1 INTRODUCTION

We consider non-convex sparse minimization (NSM) problems formulated as follows:

minimize
x∈Rd

P (x)

subject to

x
(cid:107)

0
(cid:107)

≤

k,

(1)

x
(cid:107)

Z>0 is a sparsity parameter. We assume P : Rd

0 is the number of non-zeros in x and k
(cid:107)

R to be
where
a convex function (e.g., quadratic, Huber, and logistic losses) with (cid:96)2-regularization as detailed in Section 3. The
feasible region of NSM is non-convex due to the (cid:96)0-constraint, hence NSM generally is NP-hard (Natarajan, 1995).
NSM is important since it arises in many real-world scenarios including feature selection (Hocking and Leslie, 1967)
and robust regression (Bhatia et al., 2017). Due to the NP-hardness, most studies on NSM have been devoted to
inexact polynomial-time algorithms, which are not guaranteed to ﬁnd optimal solutions: E.g., orthogonal matching
pursuit (OMP) (Pati et al., 1993; Elenberg et al., 2018), iterative hard thresholding (IHT) (Blumensath and Davies,
2009; Jain et al., 2014), and hard thresholding pursuit (HTP) (Foucart, 2011; Yuan et al., 2016).

→

∈

When solving moderate-size NSM instances to make a vital decision, the demand for exact algorithms increases.1
Moreover, to exactly solve NSM is useful for revealing the performance and limitation of the inexact algorithms,
which helps advance research into NSM. These facts motivate us to develop eﬃcient exact algorithms for NSM.
The main diﬃculty of exactly solving NSM stems from the fact that there are Θ(dk) non-zero patters, or supports;
to examine them one by one is prohibitively costly. For the case where P (x) is quadratic, i.e., P (x) = 1
2
2
(cid:107)
Rn×d, Bertsimas et al. (2016) have developed an exact algorithm based on quadratic mixed-
where b
integer programming (MIP). Since MIP solvers (e.g., Gubori and CPLEX) employ sophisticated search strategies
such as the branch-and-bound (BB) method, their method works far more eﬃciently than the exhaustive search.

Rn and A

b
2n (cid:107)

Ax

−

∈

∈

In practice, non-quadratic objective functions are very common; e.g., if observation vector b includes outliers,
we use the Huber loss function to alleviate the eﬀect of outliers. The MIP-based method is inapplicable to such
NSM instances since they cannot be formulated as quadratic MIP. To the best of our knowledge, no existing exact
NSM algorithms can handle general convex functions such as Huber and logistic losses.

In this paper, we develop the ﬁrst exact NSM algorithm that can deal with (cid:96)2-regularized convex objective
functions. Our algorithm searches for an optimal support based on the best-ﬁrst search (BFS) (Pearl, 1984), which
is a powerful search strategy including the A* search (Hart et al., 1968). Since there are few studies on NSM in

1We say an optimization algorithm is exact if it is guaranteed to achieve optimal objective values, where we admit small errors such

as those arising from the machine epsilon.

1

 
 
 
 
 
 
the ﬁeld of search algorithms, a BFS framework and its several key components for NSM remain to be developed;
the most important is an admissible heuristic, which appropriately prioritizes candidate supports. We develop such
a prioritization method, called SubtreeSolver, and some additional techniques by utilizing the latest studies on
continuous optimization methods (Liu et al., 2017; Malitsky and Pock, 2018). Although the two main building
blocks of our algorithm, BFS and continuous optimization methods, are well studied, to develop an NSM algorithm
by utilizing them requires careful discussion as in Sections 2 and 3. Below we detail our contributions:

•

•

•

In Section 2, assuming that SubtreeSolver is available, we show how to search for an optimal support via
BFS. Our BFS outputs solutions with objective errors at most ∆
0, where ∆ is an input that controls the
trade-oﬀ between the accuracy and computation cost; BFS is exact if ∆ = 0, and BFS empirically speeds up
as ∆ increases.

≥

In Section 3, we develop SubtreeSolver that works with (cid:96)2-regularized convex functions. We also develop two
techniques that accelerate BFS: Pruning of redundant search space and warm-starting of SubtreeSolver. Al-
though pruning is common in the area of heuristic search, how to apply it to NSM is non-trivial. Experiments
in Appendix C conﬁrm that BFS greatly speeds up thanks to the combination of the two techniques.

In Section 4, we validate our BFS via experiments. We conﬁrm that BFS can exactly solve NSM instances
with non-quadratic objectives, which inexact algorithms fail to solve exactly; this implies optimal solutions of
some NSM instances cannot be obtained with other methods than BFS. We also demonstrate that to exactly
solve NSM is beneﬁcial in terms of support recovery. Experiments with quadratic objectives show that BFS
is more eﬃcient than the MIP-based method that uses the latest commercial solver, Gurobi 8.1.0.

1.1 Related Work

We remark that BFS is diﬀerent from BB-style methods, which MIP solvers often employ. While BB needs to
examine or prune every possible support to guarantee the optimality of output solutions, BFS can output optimal
solutions without examining the whole search space. This property is obtained from the admissibility of heuristics;
in our case, it holds thanks to the design of SubtreeSolver. In Section 4.2, we conﬁrm that our BFS can run
faster than the MIP-based method

Our work is also diﬀerent from previous studies that consider similar settings. Huang et al. (2018) studied the
(cid:96)0-penalized minimization of quadratic objectives, while we consider (cid:96)0-constrained minimization with (cid:96)2-regularized
convex objectives. MIP approaches to other penalized settings are studied in (Miyashiro and Takano, 2015; Sato et
al., 2016), but the (cid:96)0-constrained setting is not considered. Bourguignon et al. (2016) studied Big-M -based MIP
formulations of sparse optimization whose objective functions are given by the (cid:96)p-norm. Unlike our BFS and the
MIP approach (Bertsimas et al., 2016), their method requires the assumption that no entry of an optimal solution
is larger in absolute value than predetermined M > 0. Furthermore, our BFS accepts objective functions other
than those written with the (cid:96)p-norm. Bertsimas and Van Parys (2017) in a preprint have recently proposed a
cutting-plane-based MIP approach; as with the previous MIP approach (Bertsimas et al., 2016), however, it is
accepts only quadratic objectives. Karahanoglu and Erdogan (2012) and Arai et al. (2015) proposed A* algorithms
for compressed sensing and column subset selection, respectively; our problem setting and design of the heuristic
are diﬀerent from those in their works.

2 BFS FRAMEWORK

We ﬁrst deﬁne the state-space tree, on which we search for an optimal support, and we then show how to perform
BFS on the tree. The state-space tree is often used in reverse search (Avis and Fukuda, 1996), and similar notions
are used for submodular maximization (Chen et al., 2015; Sakaue and Ishihata, 2018).

1, . . . , d
{

Let [d] :=
< d. Given any S

Rd; we take the elements in [d] to be totally ordered as 1 < 2 <
[d]
· · ·
denote the support of x, which is the set of indices corresponding to the non-zero entries of x. We let x∗ be an
optimal solution to problem (1).

be the index set of x
[d], we let max S

[d] denote the largest element in S. For any x

Rd, we let supp(x)

}
⊆

⊆

∈

∈

∈

2.1 State-space Tree

We deﬁne the state-space tree G = (V, E) as follows. The node set is given by

V :=

S
{

⊆

[d]

S

| |

| ≤

k and k

S

− |

| ≤

d

−

max S

,
}

2

∅

1
}

{

2
{

}

1, 2
}

{

1, 3
{

}

2, 3
}

{

1, 2, 3
}

{

1, 2, 4
}

{

1, 3, 4
}

{

2, 3, 4
{

}

Figure 1: State-space Tree with (d, k) = (4, 3). The nodes in the area shaded in red form desc({1}). If supp(x∗) = {1, 4},
V ∗ comprises the nodes with the underlined labels.

∈

V are connected by directed edge (S, T )

and S, T
V
represents an index subset such that the corresponding entries are allowed to be non-zero. Since V includes all S
V denote a node subset that
of size k, any support of size at most k is included in some S
comprises S and all its descendants. Figure 1 shows an example state-space tree. While the size of the tree,
, is
exponential in k, BFS typically requires only a very small fraction of V on-demand, which we will experimentally
conﬁrm in Section 4.1.1.

. Roughly speaking, each S
}

V . Let desc(S)

E iﬀ S = T

max T

\{

⊆

∈

∈

∈

V

|

|

2.2 Best-ﬁrst Search on State-space Tree

For any S

V , we deﬁne

∈

U (S) :=
which comprises all feasible solutions whose support is included in some S(cid:48)

supp(x)

⊆

∈

∈

x

{

|

S(cid:48)
∃

S(cid:48),

Rd

desc(S)

,
}

desc(S). Note that

∈

V ∗ :=

S

V

x∗

{
|
∈
V satisfy

∈
S
|

U (S)
}

F (S) := min

x∈Rd{

P (x)

x

U (S)
}

∈

|

→
.

= k (see, Figure 1); we use this fact to prove the
and leaves S
induces a subtree whose root is
V , we search for (a superset of) the optimal support, supp(x∗),
exactness of BFS. With BFS, starting from root
in G in a top-down manner. Since it is too expensive to examine all nodes in G, we reduce the search eﬀort by
appropriately prioritizing candidate nodes. We deﬁne set function F : V

∈
∅ ∈

R as

∅

|

(2)

(3)

(4)

(5)

Note that F (S)

≥

P (x∗) holds for any S

V and that

∈

F (S) = P (x∗)

V ∗

S

∀

∈

V , we could ﬁnd x∗ without examining any redundant
holds. Ideally, if we could use F (S) as a priority value of S
search space. However, to compute F (S) is NP-hard in general. Thus we consider using an estimate of F (S) that can
be computed eﬃciently. As is known in the ﬁeld of heuristic search (Dechter and Pearl, 1985), such estimates must
satisfy certain conditions to guarantee the exactness of BFS. We assume that such estimates, as well as candidate
solutions, can be computed via SubtreeSolver that satisﬁes the following requirements: SubtreeSolver(S) must
output an estimate LowS

R of F (S) and a feasible solution SolS

k) that satisfy

Rd (i.e.,

∈

0

∈

F (S)

LowS
≤
P (SolS)

LowS + ∆

≤

∈

≤

SolS
(cid:107)
S

∀

∃

S

∈

∈

(cid:107)
V ,
V ∗.

Algorithm 1 describes BFS that uses SubtreeSolver. Akin to the admissible heuristics of A* search, LowS must
lower bound F (S) as in (4). Condition (5) guarantees that BFS terminates in Step 7. In Section 3, we develop
V , as well as LowS and SolS, are
SubtreeSolver satisfying (4) and (5). As in Algorithm 1, all examined S
maintained with MinHeap, and they are prioritized with their LowS values. In each iteration, S, the maintained
node with the smallest LowS, is popped from MinHeap, and then all its children are examined and pushed onto
MinHeap if not pruned in Step 10.

∈

As in (Hansen and Zhou, 2007), we can use Solmin, the best current solution, to prune redundant search space.
More precisely, in Steps 10 and 11, if LowT > Pmin is detected while executing SubtreeSolver(T ), we force-quit
SubtreeSolver to reduce computation cost, and we never examine the redundant search space, desc(T ). How to
detect LowT > Pmin depends on the design of SubtreeSolver; we explain it in Section 3.2.

Assuming that SubtreeSolver is available, the exactness of Algorithm 1 can be proved as follows:

3

Algorithm 1 BFS for NSM

return SolS

(cid:104)LowS, SolS, S(cid:105) ← MinHeap.pop()
if P (SolS) ≤ LowS + ∆ then

1: Low∅, Sol∅ ← SubtreeSolver(∅)
2: MinHeap.push(Low∅, (cid:104)Low∅, Sol∅, ∅(cid:105))
3: Solmin ← Sol∅ and Pmin ← P (Solmin)
4: while MinHeap is not empty do
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:

for each T such that (S, T ) ∈ E do

else

Start SubtreeSolver(T ) to get LowT and SolT .
if LowT > Pmin is detected then
Force-quit SubtreeSolver(T ).

MinHeap.push(LowT , (cid:104)LowT , SolT , T (cid:105))
if P (SolT ) < Pmin then

Solmin ← SolT and Pmin ← P (Solmin)

(cid:46) Pruning

Theorem 1. For any ∆ > 0, Algorithm 1 outputs a feasible x that satisﬁes P (x)

P (x∗) + ∆.

≤

Proof. Since Solmin is always feasible, for any T

V ∗,

∈

P (Solmin)

P (x∗)
≥
= F (T )
LowT

≥

∵ Solmin is feasible
∵ P (x∗) = F (T ) from (3)
∵ F (T )
LowT from (4)

≥

holds. Therefore, no T
∅
V ∗ until all nodes in V ∗ are popped.
and its leaves S
Therefore, thanks to (5), BFS always terminates in Step 7 and returns a solution. For any SolS obtained in Step 7,
we have

V ∗ is pruned in Step 10. Furthermore, since V ∗ induces a subtree such that its root is

= k, MinHeap always maintains some S∗

∈
V ∗ satisfy

k and

S
|

∈

∈

|

SolS
(cid:107)

0
(cid:107)

≤

≤

P (SolS)
LowS + ∆
LowS∗ + ∆
F (S∗) + ∆
≤
= P (x∗) + ∆.

≤

∵ Termination condition in Step 6
∵ LowS is the smallest in MinHeap
∵ LowS∗
F (S∗) from (4)
∵ F (S∗) = P (x∗) from (3)

≤

Thus the theorem holds.

By using ∆

0 that is as small as the machine epsilon, we can obtain an exact BFS. As ∆ becomes larger,
BFS can terminate earlier. Therefore, we can use ∆ as a hyper-parameter that controls the trade-oﬀ between the
running time and accuracy. Similar techniques are considered in the ﬁeld of heuristic search (Ebendt and Drechsler,
2009; Valenzano et al., 2013).

≥

3 SUBTREE SOLVER

We develop SubtreeSolver that satisﬁes requirements (4) and (5). Although the BFS framework does not require
us to specify the form of P (x), we here assume it can be written as follows for designing SubtreeSolver:

P (x) = L(Ax) +

λ
2 (cid:107)

x
(cid:107)

2,

(6)

) is a convex function, A

denotes
where L(
·
the (cid:96)2-norm. Since (cid:96)2-regularization is often used to prevent over-ﬁtting and L(
) accepts various convex loss
·
functions, P (x) of form (6) appears in many practical problems (see, e.g., (Liu et al., 2017)). In Section 3.3, we list
some examples of loss functions. We also assume that the following minimization problem can be solved exactly
for any S

Rn×d is a design matrix, λ > 0 is a regularization parameter, and

(cid:107)·(cid:107)

V :

∈

∈

minimize
x∈Rd

P (x)

subject to supp(x)

S,

⊆

(7)

4

Algorithm 2 SubtreeSolver(S)

1: if |S| = k then
2:

SolS ← argmin
supp(x)⊆S

P (x) and LowS ← P (SolS)

3: else if |S| + |S>| ≤ k then
SolS ← argmin
4:

P (x) and LowS ← P (SolS)

supp(x)⊆S∪S>

5: else
6:
7: return LowS, SolS

Compute LowS and SolS with Algorithm 3.

which can be seen as unconstrained minimization of a strongly convex function with
S
|
quadratic, we can solve it by computing a pseudo-inverse matrix. Given more general P (
·
methods such as (Shalev-Shwartz and Zhang, 2016) to solve problem (7).

3.1 Computing LowS and SolS

variables.

) is
|
), we can use iterative

If P (
·

∈

S
|

, S≤ :=

V be any node and deﬁne s :=

Let S
(S≤, S>) forms a partition of [d]. For any x
Similarly, AS
positive integers j, m, and z
∈
an non-increasing order of
zi
|
|
Given any convex function f : Rm
deﬁne proxf (x) := argminy∈Rm

; note that
i
i
}
{
∈
{
R (i
Rd, xS
S).
∈
∈
Rn×d whose column indices are restricted to S. Given any
Rn×s denotes a sub-matrix of A
Rm as follows:
j(z) preserves (up to) j entries of z chosen in
j(z)
j(z)
.
(cid:107)T
(cid:107)
. We
f (y)
}

∈
Rm, we deﬁne
T
and sets the rest at 0. We let

[d]
i > max S
Rs denotes a restricted vector consisting of xi

R, we denote its convex conjugate by f ∗(β) := supy∈Rm

j,2 denote the top-j (cid:96)2-norm; i.e.,

, and S> :=
}

z
(cid:107)
(cid:107)
β, y
(cid:105) −

→
f (y) + 1

max S

j,2 :=

∈
∈

(cid:107)·(cid:107)

[d]

{(cid:104)

≤

∈

∈

∈

T

y

i

2

|

.

|

|

A high-level sketch of SubtreeSolver is provided in Algorithm 2, which consists of three parts: Steps 1–2,
Steps 3–4, and Steps 5–6. Every part computes LowS and SolS that satisfy (4) and
k, and the ﬁrst
part is needed to satisfy (5). While the ﬁrst two parts consider some easy cases, the last part deals with the most
important case and requires careful discussion. Below we explain each part separately.

SolS
(cid:107)

0
(cid:107)

≤

(cid:8)

(cid:9)

x
2 (cid:107)

−

(cid:107)

If

Steps 1–2.
SolS
(cid:107)
guarantee that SubtreeSolver satisﬁes (5).

k and F (S) = P (SolS) = LowS

S
|

0
(cid:107)

≤

|

≤

= k, F (S) = minsupp(x)⊆S P (x) holds. Therefore, SolS and LowS obtained in Step 2 satisfy
LowS + ∆. Since V ∗ always includes some S of size k, we can

If

S(cid:48)
S(cid:48)
Steps 3–4.
∪
| ≤
|
Therefore, SolS and LowS obtained in Step 4 satisfy
SolS
(cid:107)
equality.

k, then desc(S) =

S
{

S>

+

S

|

|

|

(cid:107)

, and thus F (S) = minsupp(x)⊆S∪S> P (x) holds.
S>
k and F (S) = P (SolS) = LowS; i.e., (4) holds with

}

⊆
0

≤

Steps 5–6. We consider the case where neither
k holds. Note that F (S) is deﬁned as
= k nor
the minimum value of non-convex minimization problem (2), whose lower bound cannot be obtained with standard
convex relaxation; e.g., an (cid:96)1-relaxation-like approach does not always give lower bounds. For the case of (cid:96)0-
k), Liu et al. (2017) has provided a technique for deriving a lower bound.
constraint minimization (i.e.,
(cid:107)
Unlike their case, the constraint in (2) is given by x
U (S), but we can leverage their idea to obtain a lower bound
of F (S). From the Fenchel–Young inequality, L(Ax) + L∗(β)

, we obtain

S>
|

Ax, β

x
(cid:107)

S
|

S
|

| ≤

+

≤

∈

0

|

|

(cid:105)

≥ (cid:104)

λ
2 (cid:107)

x

2
(cid:107)

(cid:111)
L∗(β) +

F (S) = min

x∈U (S)

L(Ax) +

(cid:110)

min
x∈U (S)

Ax, β
(cid:104)
(cid:110)
L∗(β)

≥

=

(cid:105) −

−

1
2λ (cid:107)

A(cid:62)

S β

2

(cid:107)

−

1
2λ (cid:107)

A(cid:62)
S>

−

(cid:111)
β

2
k−s,2
(cid:107)

λ
2 (cid:107)

x

2
(cid:107)

=: D(β; S)

Rn. Therefore, once β is ﬁxed, we can use LowS = D(β; S) as a lower bound of F (S). In practice,
for any β
BFS becomes faster as the lower bound becomes larger. Thus we consider obtaining a large D(β; S) value by
(approximately) solving the following non-smooth concave maximization problem:

∈

maximize
β∈Rn

D(β; S).

5

(8)

Algorithm 3 Computation of LowS and SolS
1: Initialize β0, y0, τ0, and ρ0.
2: Let θ0 ← 1 and ﬁx γ > 0.
3: Dmax ← D(β0; S)
4: for t = 1, 2, . . . do
5:

βt ← proxτt−1L∗ (βt−1 − τt−1Ayt−1)
Dmax ← max{Dmax, D(βt; S)}
ρt ← ρt−1(1 + γτt−1)
τt ← τt−1
loop

(cid:113) ρt−1
ρt

(1 + θt−1)

θt ← τt
τt−1
¯yt ← yt−1 + ρtτtA(cid:62)(βt + θt(βt − βt−1))
yt
¯yt
yt
S ← 1
S≤\S ← 0,
S,
1+λρtτt
k−s,2)∗ (¯yt
yt
S> ← proxρtτt( 1
ρtτt(cid:107)A(cid:62)(yt − yt−1)(cid:107) ≤ (cid:107)yt − yt−1(cid:107) then
if

2λ (cid:107)·(cid:107)2

S> )

and

√

break
τt ← 0.5 × τt
if converged then
LowS ← Dmax
SolS ←

argmin
supp(x)⊆supp(Tk(yt))

P (x)

return LowS, SolS

6:
7:

8:

9:
10:

11:

12:

13:
14:
15:
16:
17:
18:

19:

(cid:46) Warm-start

(cid:46) Linesearch loop

) holds, while larger γ makes PDAL faster. How to compute prox(
·
·

Algorithm 3 presents a maximization method for problem (8), which is based on the primal-dual algorithm with
linesearch (PDAL) (Malitsky and Pock, 2018). We may also use the supergradient ascent as a simple alternative to
PDAL; we here employ PDAL to enhance scalability of BFS. (see, Appendix B for details). If better methods for
problem (8) are available, we can use them. Below we detail Algorithm 3. In Step 1, we initialize the parameters
with the warm-start method detailed in Section 3.2. In Step 2, we let γ > 0 be suﬃciently small so that the 1/γ-
smoothness of L(
) (Steps 5 and 12) is detailed in
Appendix A. In Step 18, we compute a feasible solution SolS from the primal solution, yt. We now explain how to
detect convergence in Step 16, which requires us to consider the following two issues: (I) It would be ideal if we could
D(βt−1; S))/ maxβ∈Rn D(β; S), for detecting convergence, but the denominator is
use the relative error, (D(βt; S)
unavailable. (II) D(βt; S) does not always increase with t, while we want to make the output, LowS = Dmax, as large
as possible. We ﬁrst address (I). Let Pmin be the best current objective value when SubtreeSolver(S) is invoked,
which we maintain as in Algorithm 1. If Algorithm 3 is not force-quitted by the pruning procedure, we always
have D(β; S) < Pmin as detailed in Section 3.2. Furthermore, Algorithm 3 aims to maximize D(β; S). These facts
suggest that Pmin would be a good surrogate of maxβ∈Rn D(β; S). Hence we use (D(βt; S)
(cid:15)
as a termination condition, where (cid:15) > 0 is a small constant that controls the accuracy of SubtreeSolver. This
D(βt−1; S) can be negative even though
condition alone is, however, insuﬃcient due to issue (II); i.e., D(βt; S)
LowS = Dmax is small. To resolve this problem, we employ an additional termination condition, D(βt; S)
Dmax,
which prevents Algorithm 3 from outputting small LowS. If both conditions are satisﬁed, we regard the for loop as
having converged.

D(βt−1; S))/Pmin

≤

−

≥

−

−

3.2 Acceleration Techniques

We present two acceleration techniques: a warm-start method and pruning via force-quit, which is mentioned in
Section 2.2. In Appendix C, ablation experiments conﬁrm that the combination of the two acceleration techniques
greatly speeds up BFS.

(cid:107)

A
(cid:107)

at the beginning of BFS, we set β0
2 is the largest singular value of A. We now suppose that S(cid:48)

Warm-start by Inheritance. We detail how to initialize β0, y0, τ0, and ρ0 with the warm-start method. When
executing Algorithm 3 with S =
1,
1/
(cid:107)
←
∅
where
V is popped from MinHeap and that we
∈
are about to compute LowS and SolS with Algorithm 3, where (S(cid:48), S)
E. Since S is obtained by adding only one
element, max S, to S(cid:48), D(β; S(cid:48)) and D(β; S) are expected to have similar maximizers. Taking this into account, we
set β0, y0, τ0, and ρ0 at those obtained in the last iteration of Algorithm 3 invoked by SubtreeSolver(S(cid:48)). Namely,
Algorithm 3 inherits β0, y0, τ0, and ρ0 from the parent node to become warm-started. We can easily conﬁrm that
D(β0; S(cid:48))

D(β0; S) holds for any β0

2, and ρ0
(cid:107)

0, y0

0, τ0

Rn.

←

←

←

A

∈

≤

∈

6

Pruning via Force-quit. As mentioned in Section 2.2, force-quitting SubtreeSolver(T ) can accelerate BFS, but
it involves detecting LowT > Pmin; we explain how to do this. Since problem (7) is assumed to be solved eﬃciently,
detecting LowT > Pmin for the cases of Steps 1–2 and Steps 3–4 in Algorithm 2 is easy; i.e., we check whether
LowT = P (SolT ) > Pmin holds or not. Below we focus on the case of Steps 5–6. While executing Algorithm 3,
once D(βt; T ) > Pmin occurs for some t, then we have LowT > Pmin due to Step 6. In this case, we force-quit
Algorithm 3, and continue BFS without pushing T onto MinHeap.

3.3 Examples of Loss Functions

We detail three examples of convex loss functions L(
·
use them in the experiments. All of the functions are deﬁned with design matrix A = [a1, . . . , an](cid:62)
observation vector b = [b1, . . . , bn](cid:62)

): quadratic, Huber, and logistic loss functions. We will
Rn×d and

Rn.

∈

∈

Quadratic Loss. The quadratic loss function is a widely used loss function deﬁned as Lquadratic(Ax) := 1
Ax

) is 1/n-smooth, and so we can set γ = n in Algorithm 3.
·

2. Note that Lquadratic(
(cid:107)

b
2n (cid:107)

−

Huber Loss. When observation vector b contains outliers, the Huber loss function is known to be eﬀective. Given
δ and
parameter δ
δ

n
i=1 l(a(cid:62)
i x
≥
) is also 1/n-smooth.
otherwise. We can conﬁrm that LHuber(
·
(cid:80)

0, the function is deﬁned as LHuber(Ax) := 1
n

bi), where l(r) is r2/2 if

δ/2

| ≤

r
|

| −

−

r

|

(cid:1)

(cid:0)
, the following
1, 1
Logistic Loss. When each entry of the observation vector is dichotomous, i.e., b1, . . . , bn
}
logistic loss function is often used: Llogistic(Ax) := 1
) is 1
a(cid:62)
i x)). Note that Llogistic(
4n -smooth.
n
·
Although the proximal operator of this function required in Algorithm 3 has no closed expression, we can eﬃciently
(cid:80)
compute it by solving a 1D minimization problem with Newton’s method as in (Defazio, 2016, Appendix A).

n
i=1(1 + exp(

∈ {−

−

bi

·

4 EXPERIMENTS

We evaluate our BFS via experiments.
In Section 4.1, we use synthetic instances with Huber and logistic loss
functions; we thus conﬁrm that our BFS can solve NSM instances to which the MIP-based method is inapplicable.
With the instances, we examine the computation cost of BFS. We also demonstrate that our BFS is useful in
terms of support recovery; this is the ﬁrst experimental study that examines the support recovery performance of
exact algorithms for NSM instances with non-quadratic loss functions. In Section 4.2, we use two real-world NSM
instances with quadratic loss functions, and we demonstrate that BFS can run faster than the MIP-based method
(Bertsimas et al., 2016) with the latest commercial solver, Gurobi 8.1.0, which we denote simply by MIP in what
follows.

For comparison, we employed three inexact methods: OMP (Elenberg et al., 2018), HTP (Yuan et al., 2014),
and dual IHT (DIHT) (Liu et al., 2017). The precision, (cid:15), used for detecting convergence in Algorithm 3 (see,
the last paragraph in Section 3.1), as well as those of those of HTP and DIHT, were set at 10−5. When solving
problem (7) with non-quadratic objectives, we used a primal-dual method based on (Shalev-Shwartz and Zhang,
2016); with this method we obtained solutions whose primal-dual gap was at most 10−15. We regarded numerical
errors smaller than 10−12 as 0.

All experiments were conducted on a 64-bit Cent6.7 machine with Xeon 5E-2687W v3 3.10GHz CPUs and 128
GB of RAM. All methods were executed with a single thread. BFS, OMP, HTP, and DIHT were implemented in
Python 3, and MIP used Gurobi 8.1.0.

4.1 Synthetic Instances

Rd, which has a support of size
We consider synthetic NSM instances of sparse regression models; we estimate x
at most k, from a sample of size n. Speciﬁcally, we created the following instances with Huber and logistic loss
functions, which we simply call Huber and logistic instances, respectively, in what follows.

∈

Huber Instance: Sparse Regression with Noise and Outliers. We created Strue
[d] by randomly sam-
pling k elements from [d], which forms the support of the true sparse solution, xtrue. We set the ith entry of xtrue at
Rn×d from a lightly correlated d-dimensional normal dis-
1 if i
tribution, whose mean and correlation coeﬃcient were set at 0 and 0.2, respectively. We normalized each column of

Strue and 0 otherwise. We drew each row of A

⊆

∈

∈

7

(a) Huber, Running Time

(b) Huber, Solver Call

(c) Logistic, Running Time

(d) Logistic, Solver Call

Figure 2: Running Times and Solver Calls. (cid:0)d

k

(cid:1) corresponds to the solver call of exhaustive search.

(a) Huber, PSSR

(b) Huber, Running Time

(c) Logistic, PSSR

(d) Logistic, Running Time

Figure 3: PSSR and Running Times.

N

Rd from the standard normal distribution, de-
A so that its (cid:96)2-norm became 1. We then drew each entry of xnoise
∈
, became 10. We let b∗ = A(xtrue +xnoise).
noted by
xnoise
/
, and rescaled it so that the signal-noise ratio,
xtrue
(cid:107)
(cid:107)
(cid:107)
Analogously, we drew each entry of bnoise
= 10 held. We then
and rescaled it so that
(cid:107)
entries from bnoise and multiplied them by 10; we let b = b∗ + bnoise. Namely, about 10%
randomly chose
0.1n
entries of b are outliers. We used the regularized Huber loss function, P (x) = LHuber(Ax) + λ
2, as an objective
x
2 (cid:107)
function, where we let δ = 1 and λ = 0.001.

bnoise
(cid:107)

Rn from

b∗
(cid:107)

/
(cid:107)

N

∈

(cid:107)

(cid:107)

(cid:98)

(cid:99)

(cid:100)

k/2
(cid:101)

elements from Strue and

Rn×d as in (Jain et al., 2014): We obtained ˆS

Logistic Instance: Ill-conditioned Sparse Regression with Dichotomous Observation. As with the
Strue and 0 otherwise. We employed
above setting, we created Strue and set the ith entry of xtrue at 10 if i
ill-conditioned design matrix A
[d] of size k by randomly
choosing
Strue. We then drew each row of A ˆS from a
elements from [d]
\
heavily correlated k-dimensional normal distribution with mean 0 and correlation coeﬃcient 0.5, and each row of
A[d]\ ˆS was drawn from the above lightly correlated normal distribution of dimension d
k. We then normalized
n from a Bernoulli distribution such that bi = 1 with a
each column of A. We drew each entry of b
a(cid:62)
i xtrue)); i.e., Strue represents features that aﬀect the dichotomous outcomes. We used
probability of 1/(1 + exp(
the regularized logistic loss function P (x) = Llogistic(Ax)+ λ
2 as an objective function, where we let λ = 0.0002.
x
2 (cid:107)

k/2
(cid:99)

1, 1
}

∈ {−

−

⊆

−

∈

∈

(cid:107)

(cid:98)

4.1.1 Computation Cost

(cid:99)

d
k

10k log d
(cid:98)

We created 100 random Huber and logistic instances with d = 50, 100, . . . , 300 and d = 50, 60, . . . , 100, respectively.
We let k = 0.1k and n =
. Figure 2 shows the running time and solver call, which indicates the number
of times SubtreeSolver is executed, of each method. The solver calls of the inexact methods are regarded as 1.
Each curve and error bar indicate the mean and standard deviation calculated over 100 instances. For comparison,
values, which correspond to the solver calls of a naive exhaustive search that solves problem (7)
we present the
d
times. We see that BFS is far more eﬃcient than the exhaustive search, which is too expensive to be used in
k
; hence the results of solver calls conﬁrm that
, is at least
practice. Note that the size of the state-space tree,
(cid:0)
BFS examines only a very small fraction of the tree. Furthermore, although BFS is slower than the inexact methods
on average, BFS can sometimes run very fast as indicated by the error bars. We also counted the number of solved
instances for each method: While BFS solved all the 600 Huber instances and 600 logistic instances, OMP, HTP,
and DIHT solved 598, 172, and 233 Huber instance, respectively, and 464, 7, and 82 logistic instances, respectively.
Note that these results regarding the inexact methods are obtained thanks to BFS, which always provides optimal
solutions and enables us to see whether solutions obtained with inexact methods are optimal or not.

d
k

V

(cid:1)

(cid:0)

(cid:1)

(cid:0)

(cid:1)

|

|

8

100200300d10−1101103Runningtime(s)BFSOMPHTPDIHT100200300d107101710271037SolvercallBFSOMPHTPDIHT(cid:0)dk(cid:1)6080100d10−1100101102103Runningtime(s)BFSOMPHTPDIHT6080100d1021051081011SolvercallBFSOMPHTPDIHT(cid:0)dk(cid:1)5060708090100n20406080100PSSRBFS(∆=0)BFS(∆=0.005)OMPHTPDIHT5060708090100n10−1100101102Runningtime(s)BFS(∆=0)BFS(∆=0.005)OMPHTPDIHT100200300400500n020406080PSSRBFS(∆=0)BFS(∆=0.005)OMPHTPDIHT100200300400500n10−1100101102Runningtime(s)BFS(∆=0)BFS(∆=0.005)OMPHTPDIHT(a) Diabetes, Running Time

(b) Diabetes, Solver Call

(c) Diabetes, Objective Error

(d) Boston, Running Time

(e) Boston, Solver Call

(f) Boston, Objective Error

Figure 4: Running Times, Solver Calls, and Objective Errors. Upper and lower ﬁgures show those of the Diabetes and
Boston instances, respectively. We provide the results of OMP, HTP, and DIHT for comparison.

4.1.2 Support Recovery

We used Huber and logistic instances with (d, k) = (50, 5). We randomly generated 100 Huber instances with
n = 50, 60, . . . , 100 and 100 logistic instances with n = 100, 200, . . . , 500. We applied the algorithms used in the
above section and BFS that accepts ∆ = 0.005 objective errors to the instances. We evaluated them with the
percentage of successful support recovery (PSSR) as in (Liu et al., 2017), which counts the number of instances
such that output solution x satisﬁes supp(x) = supp(x∗) among the 100 instances. We also measured running times
of the algorithms. Figure 3 summarizes the results. BFS achieved higher PSSR performances than the inexact
methods with both Huber and logistic instances. In particular, the performance gaps in Huber instances with small
n are signiﬁcant as in Figure 3a. Namely, to exactly solve NSM can be beneﬁcial in terms of support recovery
when only small samples are available. On the other hand, BFS tends to get faster as n increases. This is because
the condition of NSM instances typically becomes better as n increases, which often makes the gap between F (S)
and LowS smaller; i.e., LowS can accurately estimate F (S), and so BFS terminates quickly. To conclude, given
moderate-size NSM instances whose true supports can hardly be recovered with inexact methods, BFS can be
useful for recovering them at the expense of computation time. In Appendix D, we see that, given NSM instances
with stronger regularization, BFS becomes faster while the PSSR performance deteriorates.

4.2 Real-world Instances

∈

∈

Rn and matrix A

We compare BFS and MIP by using NSM instances with quadratic objectives, P (x) = Lquadratic(Ax) + 1
2.
λ
2 (cid:107)
(cid:107)
Rn×d were obtained from two scikit-learn datasets: Diabetes and Boston
The vector b
house-price, which for simplicity we call Boston. We normalized b and each column of A so that their (cid:96)2-norm
became 1. As in (Efron et al., 2004; Bertsimas et al., 2016), we considered the interaction and square eﬀects of
the original columns of A; any square eﬀect whose original column had identical non-zeros was removed since they
Rn×d with (n, d) = (442, 65) and (506, 103) for the Diabetes and
are redundant. Consequently, we obtained A
Boston datasets, respectively. We let λ = 0.001 and k = 10. We applied BFS and MIP that accept various values of
10−5. The ∆ value of MIP was controlled with the Gurobi
objective errors: ∆ = 0, 2.0
parameter, MIPGapAbs. For comparison, we also applied the inexact methods to the instances, whose behavior is
independent of ∆ values. We evaluated the methods in terms of running times, solver calls, and objective errors,
P (x∗) with output solution x. The solver call of MIP is the number of nodes explored
which are deﬁned by P (x)
by Gurobi.

∈
10−6, . . . , 1.0

10−6, 4.0

×

−

×

×

Figure 4 summarizes the results. Both BFS and MIP become faster as ∆ increases, and BFS is faster than MIP

9

04×10−68×10−6∆10−310−210−1Runningtime(s)BFSOMPHTPDIHTMIP04×10−68×10−6∆100101102103SolvercallBFSOMPHTPDIHTMIP04×10−68×10−6∆04×10−58×10−5ObjectiveerrorBFSOMPHTPDIHTMIP04×10−68×10−6∆10−2100102Runningtime(s)BFSOMPHTPDIHTMIP04×10−68×10−6∆101103105107SolvercallBFSOMPHTPDIHTMIP04×10−68×10−6∆02×10−66×10−610−51.4×10−5ObjectiveerrorBFSOMPHTPDIHTMIP4

≥

×

with every ∆ value; in Boston instance with ∆ = 0, BFS is more than 300 times faster than MIP. Comparing the
results with the two datasets (d = 65 and 103), we see that BFS is more scalable to large instances than MIP. For
10−6, BFS invoked SubtreeSolver only once. Namely, BFS detected that the solutions obtained by a
∆
single invocation of SubtreeSolver were guaranteed to have at most ∆ errors without examining the descendant
nodes. In contrast, MIP examined more nodes to obtain the ∆-error guarantees, resulting in longer running times
than those of BFS. This result is consistent with what we mentioned in Section 1.1. We see that BFS found optimal
10−6, while none of the inexact methods succeeded in
solutions except for the case of Boston instance with ∆ = 2
exactly solving both instances. We remark that the objective error of BFS does not always increase with ∆ since
the priority value, LowS, is not completely correlated with F (S); i.e., a better solution can be obtained earlier.

×

5 CONCLUSION

We proposed a BFS algorithm for NSM with (cid:96)2-regularized convex objective functions. Experiments conﬁrmed
that our BFS existing exact methods are inapplicable, and that BFS can run faster than MIP with the latest
commercial solver, Gurobi 8.1.0.

References

H. Arai, C. Maung, and H. Schweitzer. Optimal column subset selection by A-star search. In Proceedings of the

29th AAAI Conference on Artiﬁcial Intelligence. AAAI Press, 2015.

D. Avis and K. Fukuda. Reverse search for enumeration. Discrete Appl. Math., 65(1):21 – 46, 1996.

D. Bertsimas and B. Van Parys. Sparse high-dimensional regression: Exact scalable algorithms and phase transi-

tions. arXiv preprint arXiv:1709.10029, 2017.

D. Bertsimas, A. King, and R. Mazumder. Best subset selection via a modern optimization lens. Ann. Statist.,

44(2):813–852, 2016.

K. Bhatia, P. Jain, P. Kamalaruban, and P. Kar. Consistent robust regression. In Advances in Neural Information

Processing Systems 30, pages 2110–2119. Curran Associates, Inc., 2017.

T. Blumensath and M. E. Davies. Iterative hard thresholding for compressed sensing. Appl. Comput. Harmon.

Anal., 27(3):265–274, 2009.

S. Bourguignon, J. Ninin, H. Carfantan, and M. Mongeau. Exact sparse approximation problems via mixed-integer
programming: Formulations and computational performance. IEEE Trans. Signal Process., 64(6):1405–1419,
2016.

W. Chen, Y. Chen, and K. Weinberger. Filtered search for submodular maximization with controllable approx-
imation bounds. In Proceedings of the 18th International Conference on Artiﬁcial Intelligence and Statistics,
volume 38, pages 156–164. PMLR, 2015.

R. Dechter and J. Pearl. Generalized best-ﬁrst search strategies and the optimality of A*. J. ACM, 32(3):505–536,

1985.

A. Defazio. A simple practical accelerated method for ﬁnite sums. In Advances in Neural Information Processing

Systems 29, pages 676–684. Curran Associates, Inc., 2016.

R. Ebendt and R. Drechsler. Weighted A∗ search — unifying view and application. Artiﬁcial Intelligence,

173(14):1310 – 1342, 2009.

B. Efron, T. Hastie, I. Johnstone, and R. Tibshirani. Least angle regression. Ann. Statist., 32(2):407–499, 2004.

E. R. Elenberg, R. Khanna, A. G. Dimakis, and S. Negahban. Restricted strong convexity implies weak submodu-

larity. Ann. Statist., 46(6B):3539–3568, 2018.

S. Foucart. Hard thresholding pursuit: An algorithm for compressive sensing. SIAM J. Optim., 49(6):2543–2563,

2011.

E. A. Hansen and R. Zhou. Anytime heuristic search. J. Artif. Int. Res., 28(1):267–297, 2007.

10

P. E. Hart, N. J. Nilsson, and B. Raphael. A formal basis for the heuristic determination of minimum cost paths.

IEEE Trans. Syst. Sci. Cybernet., 4(2):100–107, 1968.

R. R. Hocking and R. N. Leslie. Selection of the best subset in regression analysis. Technometrics, 9(4):531–540,

1967.

J. Huang, Y. Jiao, Y. Liu, and X. Lu. A constructive approach to L0 penalized regression. J. Mach. Learn. Res.,

19(1):403–439, 2018.

P. Jain, A. Tewari, and P. Kar. On iterative hard thresholding methods for high-dimensional M-estimation. In

Advances in Neural Information Processing Systems 27, pages 685–693. Curran Associates, Inc., 2014.

N. B. Karahanoglu and H. Erdogan. A* orthogonal matching pursuit: Best-ﬁrst search for compressed sensing

signal recovery. Digit. Signal Process., 22(4):555 – 568, 2012.

B. Liu, X.-T. Yuan, L. Wang, Q. Liu, and D. N. Metaxas. Dual iterative hard thresholding: From non-convex
sparse minimization to non-smooth concave maximization. In Proceedings of the 34th International Conference
on Machine Learning, volume 70, pages 2179–2187. PMLR, 2017.

Y. Malitsky and T. Pock. A ﬁrst-order primal-dual algorithm with linesearch. SIAM J. Optim., 28(1):411–432,

2018.

R. Miyashiro and Y. Takano. Mixed integer second-order cone programming formulations for variable selection in

linear regression. European J. Oper. Res., 247(3):721 – 731, 2015.

B. K. Natarajan. Sparse approximate solutions to linear systems. SIAM J. Optim., 24(2):227–234, 1995.

Y. C. Pati, R. Rezaiifar, and P. S. Krishnaprasad. Orthogonal matching pursuit: recursive function approximation
with applications to wavelet decomposition. In Proceedings of the 27th Asilomar Conference on Signals, Systems
and Computers, pages 40–44 vol.1, 1993.

J. Pearl. Heuristics: Intelligent Search Strategies for Computer Problem Solving. Addison-Wesley Longman Pub-

lishing Co., Inc., Boston, MA, USA, 1984.

S. Sakaue and M. Ishihata. Accelerated best-ﬁrst search with upper-bound computation for submodular function

maximization. In Proceedings of the 32nd AAAI Conference on Artiﬁcial Intelligence, 2018.

T. Sato, Y. Takano, R. Miyashiro, and A. Yoshise. Feature subset selection for logistic regression via mixed integer

optimization. Comput. Optim. Appl., 64(3):865–880, 2016.

S. Shalev-Shwartz and T. Zhang. Accelerated proximal stochastic dual coordinate ascent for regularized loss

minimization. Math. Program., 155(1):105–145, 2016.

R. Valenzano, S. J. Arfaee, J. Thayer, R. Stern, and N. R. Sturtevant. Using alternative suboptimality bounds in
heuristic search. In Proceedings of the 23rd International Conference on Automated Planning and Scheduling,
pages 233–241. AAAI Press, 2013.

X. Yuan, P. Li, and T. Zhang. Gradient hard thresholding pursuit for sparsity-constrained optimization.

In
Proceedings of the 31st International Conference on Machine Learning, volume 32, pages 127–135. PMLR, 2014.

X. Yuan, P. Li, and T. Zhang. Exact recovery of hard thresholding pursuit. In Advances in Neural Information

Processing Systems 29, pages 3558–3566. Curran Associates, Inc., 2016.

11

Appendix

A Computing Proximal Operator in Algorithm 3

We ﬁrst introduce Moreau’s identity:

x = α proxα−1f (α−1x) + proxαf ∗ (x)

for any α > 0, x
proxτt−1L∗ (βt−1
for convex loss function L(

R. With this equality, the computation of
Rm, and (proper closed) convex function f : Rm
∈
τt−1Ayt−1) in Step 5 of Algorithm 3 can be reduced to the computation of the proximal operator
−

→

), which can be performed eﬃciently with various L(
·
·

).

) in Step 12. Thanks to Moreau’s identity, it can be written

We next see how to compute proxρtτt( 1

2λ (cid:107)·(cid:107)2

k−s,2)∗ (¯yt
S>

as

Therefore, if we can compute the proximal operator for the top-(k
Below we show that it can be computed in O(d) time.

−

¯yt
S> −

ρtτt prox 1

2λρtτt

(cid:107)·(cid:107)2

k−s,2

1
ρtτt

(cid:18)

¯yt
S>

.

(cid:19)

s) (cid:96)2-norm, then we can perform Step 12.

Proximal-operator Computation for the Top-k (cid:96)2-norm. Given any positive integer k, d (k
v

Rd, and parameter µ > 0, we show how to eﬃciently compute

∈

d), vector

≤

prox µ

2 (cid:107)·(cid:107)2

k,2

(v) = argmin

µ
2 (cid:107)

x

2
k,2 +
(cid:107)
2
k,2 +

1
2 (cid:107)

x

2

v

(cid:107)

−

x

2

v

(cid:107)

−

.

(cid:27)

(cid:107)

= argmin

x∈Rd (cid:26)
x
µ
(cid:107)

x∈Rd

(cid:107)

|

1, 1
v

d denote a vector whose ith entry is 1 if vi
Let sign(v)
}
∈ {−
)(cid:62) =:
, where
vd
, . . . ,
v1
(
|
|
|
|
that rearranges the entries of
permutated vector for any given x
permutation that satisﬁes x = σ−1
increasing. Note that, once we obtain

Rd; note that σ|v|(
v
|
|
Rd. Let u := σ|v|(
|

is the Hadamard (element-wise) product. We deﬁne σ|v| : [d]
(cid:12)
v
|

in a non-increasing order. We abuse the notation and take σ|v|(x)
) is non-increasing. We also deﬁne σ−1

v =
(cid:12)
[d] as a permutation
Rd to be a
|v| as the inverse
) , which is non-negative and non-
|

|v| (σ|v|(x)) for any x

0 and

→

≥

−

∈

∈

∈

v

|

|

(cid:9)
1 otherwise. We have sign(v)

(cid:8)

then the desired solution, prox µ
to compute ˜x.

2 (cid:107)·(cid:107)2

k,2

˜x := argmin

x∈Rd

x
µ
(cid:107)

2
k,2 +
(cid:107)

x
(cid:107)

2
u
(cid:107)

−

,

(cid:8)
(v), can be computed as sign(v)

(cid:9)
σ−1
|v| (˜x). Therefore, below we discuss how

(cid:12)

We deﬁne f (x) := µ
x
(cid:107)
minimizer. We let jstart
i.e., it holds that

x

u
k,2 +
(cid:107)
−
(cid:107)
[k] and jend
∈

2. Since u1
(cid:107)
k, . . . , d
}
∈ {

ud

0; otherwise ˜x is not a
≥ · · · ≥
≥ · · · ≥
be the smallest and largest indices such that ˜xjstart = ˜xjend = ˜xk;

0, we have ˜x1

˜xd

≥

≥

We deﬁne ¯ui := ui

1+µ for i

∈

˜x1

= ˜xjend >
· · ·
[k]. If jstart = jend = k, we can readily obtain

> ˜xjstart =

= ˜xk =

≥ · · ·

· · ·

˜xd.

· · · ≥

˜xi =

¯ui
ui

(cid:40)

for i = 1, . . . , k,
for i = k + 1, . . . , d.

Note that this case occurs iﬀ ¯uk
jstart < jend. Since f is convex and ˜x is a minimizer, we have 0

uk+1; in this case, ˜x can be obtained as above. We then consider the case
∂f (˜x), which implies

≥

∈

˜xi =

¯ui
ui

(cid:40)

for i = 1, . . . , jstart
−
for i = jend + 1, . . . , d.

1,

Namely, ˜x1, . . . , ˜xjstart−1 and ˜xjend+1, . . . , ˜xd can readily be obtained. Below we discuss how to compute jstart, jend,
and ξ := ˜xjstart =
[k]

= ˜xjend . Since ˜x is a minimizer of f , our aim is to ﬁnd an optimal triplet, (jstart, jend, ξ)

· · ·
R, that satisﬁes

k, . . . , d

∈

× {

} ×

[ujend+1, ¯ujstart−1]

ξ

∈

12

(9)

Algorithm 4 Computation of prox µ

2 (cid:107)·(cid:107)2

k,2

(v)

˜x ← (¯u1, . . . , ¯uk, uk+1, . . . , ud)(cid:62)
return sign(v) (cid:12) σ−1

1: u ← σ|v|(|v|)
2: ¯ui ← ui/(1 + µ) for i ∈ [k]
3: if ¯uk ≥ uk+1 then
4:
5:
6: ˆj ← k, gmin ← +∞, and Examined ← ∅
7: for jstart = 1, . . . , k do
8:
9:

|v| (˜x)

Endpoints ← {j ∈ [d] | uj > ¯ujstart and j ≥ ˆj}
for jend ∈ Endpoints do
ui

(cid:80)jend

10:

11:
12:
13:
14:

˜ξ ←
i=jstart
µ(k−jstart+1)+jend−jstart+1
ξ ← min{¯ujstart−1, max{ujend+1, ˜ξ}}
if g(jstart, jend, ξ) < gmin then

(j∗
start, j∗
gmin ← g(j∗

end, ξ∗) ← (jstart, jend, ξ)
end, ξ∗)

start, j∗

Examined ← Examined ∪ Endpoints
if Examined (cid:54)= ∅ then
ˆj ← max Examined

15:
16:
17:
18: ˜x ← (¯u1, . . . , ¯uj∗
19: return sign(v) (cid:12) σ−1

start−1, ξ∗, . . . , ξ∗, uj∗

|v| (˜x)

end+1, . . . , ud)(cid:62)

and minimizes

g(jstart, jend, ξ) := (1 + µ)

k

i=jstart
(cid:88)

¯ui)2 +

(ξ

−

jend

(ξ

i=k+1
(cid:88)

ui)2,

−

and ud+1 = 0, and we take the second term on the RHS to be 0 if jend = k. Note that,
where we regard ¯u0 = +
once (jstart, jend) is ﬁxed, computing optimal ξ reduces to a one-dimensional quadratic minimization problem with
constraint (9), whose solution ξ can be written as follows:

∞

¯ujstart−1, max
ξ = min
{
{

ujend+1, ˜ξ

}}

,

where

˜ξ =

µ(k

jend
i=jstart

ui
jstart + 1) + jend

(cid:80)

−

.

jstart + 1

−

In what follows, we discuss how to ﬁnd (jstart, jend) that constitutes an optimal triplet.

We ﬁrst show that triplet (jstart, jend, ξ) that satisﬁes (9) is sub-optimal if ξ < ¯ujstart holds. In this case, we

have

and triple (jstart + 1, jend, ξ) satisﬁes constraint (9), i.e.,

g(jstart + 1, jend, ξ)

g(jstart, jend, ξ)

≤

[ujend+1, ¯ujstart],

ξ

∈

since ξ < ¯ujstart. Namely, (jstart + 1, jend, ξ) is feasible and achieves at least as small g value as (jstart, jend, ξ).
Below we focus on the case where ¯ujstart ≤

ξ holds.

We then prove that triple (jstart, jend, ξ) satisfying (9) and ¯ujstart ≥

ujend is sub-optimal. In this case, we have

g(jstart, jend

1, ξ)

−

≤

g(jstart, jend, ξ)

and triple (jstart, jend

−

1, ξ) satisﬁes constraint (9), i.e.,

[ujend, ¯ujstart−1],

ξ

∈

since ujend ≤
Therefore, to ﬁnd an optimal triplet, we only need to examine (jstart, jend, ξ) that satisﬁes constraint (9) and

1, ξ) is feasible and achieves at least as small g value as (jstart, jend, ξ).

ξ. Namely, (jstart, jend

¯ujstart ≤

−

ujend > ¯ujstart.

13

(10)

Algorithm 5 SGA for computing LowS and SolS
1: Initialize β0 and η0.
2: Fix (cid:15) > 0.
3: for t = 1, 2, . . . do
4:
5:
6:
7:
8:
9:
10:
11:

Compute a supergradient gt−1 ∈ ∂D(βt−1; S).
ηt ← 2 × ηt−1
loop

βt ← PF (βt−1 + ηtgt−1)
if D(βt; S) ≥ D(βt−1; S) then

if (D(βt; S) − D(βt−1; S))/Pmin ≤ (cid:15) then

break
ηt ← 0.5 × ηt

12:

13:
14:

15:

λ A(cid:62)
xt
S βt,
S≤\S ← 0,
S> βt)
λ Tk−s(A(cid:62)

xt
S ← − 1
xt
S> ← − 1
LowS ← D(βt; S)
SolS ← argmin

P (x)

and

supp(x)⊆supp(xt)

return LowS, SolS

We ﬁx jstart

∈

[k] and deﬁne

Then,

ˆj := max
j
{

k, . . . , d

∈ {

} |

(cid:46) (cid:15) = 10−5 in the experiments

(cid:46) Backtracking of step-size ηt

uj > ¯ujstart−1

.

}

must hold for the following reason: If jend + 1
constraint (9).

≤

jend

ˆj

(i.e., ujend ≤
≥
ˆj holds, we have ujend+1

uˆj)

uˆj > ¯ujstart−1, which means no ξ satisﬁes

≥

(11)

Taking (10) and (11) into account, once jstart

[k] is ﬁxed, endpoint jend to be examined satisﬁes

ujend > ¯ujstart

and jend

∈
ˆj = max
{

j

≥

k, . . . , d

uj > ¯ujstart−1

.
}

} |

∈ {

Therefore, by examining jstart = 1, . . . , k sequentially and maintaining Examined =
as in Algorithm 4, we can ﬁnd an optimal triplet (j∗

uj > ¯ujstart}
.
We examine the complexity of Algorithm 4. Let Endpointsi be the list of endpoints constructed in the ith
i∈[k] Endpointsi
1) = d. Namely, Algorithm 4

k, . . . , d
end, ξ∗), with which we can obtain prox µ

[k]. Since Endpointsi and Endpointsi+1 have at most one common element and

includes at most d
examines at most d candidate triplets, hence Algorithm 4 runs in O(d) time.

Endpointsi| ≤

k + 1 elements, we have

iteration for i

k + 1 + (k

start, j∗

k
i=1 |

} |
2 (cid:107)·(cid:107)2

j
{

∈ {

(cid:83)

−

−

−

∈

d

k,2

(cid:80)

B Comparison of Supergradient Ascent and Primal-dual Algorithm

with Linesearch

As mentioned in Section 3.1, we can use the supergradient ascent (SGA) for solving

instead of PDAL. We ﬁrst describe the details of SGA based on (Liu et al., 2017), and then we experimentally
compare two BFS algorithms that use SGA and PDAL as their subroutines.

maximize
β∈Rn

D(β; S)

B.1 Details of SGA

:=

Let
β
operator onto

F

{

∈
F

D(β; S) >

Rn
. If ∂L∗(β)

|

−∞}

⊆

Rn is the super-diﬀerential of L∗(β), the super-diﬀerential of D(β; S) is given by

F (

) be the Euclidean projection
·

P

be the eﬀective domain of D(β; S) and

With these deﬁnitions, the SGA procedure for computing LowS and SolS can be described as in Algorithm 5. We
can use the warm-start and pruning techniques as in Section 3.2, but the details of the warm-start technique for

∂D(β; S) =

A˜x(β; S)

{

˜g

˜g

|

∈

−

∂L∗(β)

.
}

14

(a) Running Time

(b) Solver Call

Figure 5: Running Times and Solver Calls of BFS-SGA and BFS-PDAL.

(a) Running Time

(b) Solver Call

Figure 6: Running Times and Solver Calls of BFS with and without Pruning and Warm-start Techniques.

∅

at the beginning of BFS, we set β0

initializing β0 and η0 are slightly diﬀerent from those of PDAL as explained below. When executing SGA with
S =
V is popped from MinHeap
and that we are about to compute LowS and SolS, where (S(cid:48), S)
E. Let βS(cid:48) be a dual solution obtained in the
last iteration of SGA executed for S(cid:48); i.e., LowS(cid:48) = D(βS(cid:48); S(cid:48)). When executing SGA to maximize D(β; S), we let
β0

ηS(cid:48), where ηS(cid:48) is a step-size used to obtain β1 in SGA executed for S(cid:48).

βS(cid:48). Furthermore, we set η0

1. We now suppose that S(cid:48)

0 and η0

←

←

∈

∈

←

←

B.2 Experimental Comparison

We experimentally compare two BFS algorithms with SGA and PDAL, which we call BFS-SGA and BFS-PDAL,
respectively. The experimental setting used here is the same as the Huber instance in Section 4.1.1. We observed
the running times and solver calls of BFS-SGA and BFS-PDAL. As with BFS-PDAL, BFS-SGA used warm-start
and pruning techniques.

Figure 5 shows the results, where each curve and error bar indicate the mean and standard deviation calculated
over 100 random instances. While the running times of the two methods are almost the same, BFS-PDAL is more
eﬃcient in terms of solver calls. This result implies that LowS values computed by PDAL and SGA are diﬀerent
even though D(β; S) is concave; in fact, due to the non-smoothness of D(β; S), SGA sometimes fails to maximize
D(β; S). As a result, BFS-SGA tends to require more solver calls than BFS-PDAL on average. Note that, while
the computation costs of SGA and PDAL are polynomial in d, the number of solver calls can increase exponentially
in k; i.e., it is more important to reduce the number of solver calls than to reduce the running time of subroutines
(SGA and PDAL). To conclude, BFS-PDAL is expected to be more scalable to larger instances than BFS-SGA,
which motivates us to employ PDAL.

C Ablation Study

We experimentally study the degree to which the pruning and warm-start techniques speed up BFS. We used the
; for each k value we generated
Huber instances (Section 4.1) with d = 50, k = 5, 10, . . . , 30, and n =
100 random instances.

10k log d
(cid:99)
(cid:98)

Figure 6 presents running times and solver calls. Each value and error bar are mean and standard deviation
calculated over 100 instances. We see that the warm-start technique alone does not always accelerate BFS, but
the combination of pruning and warm-start greatly reduces the running time. This is because, if a good solution
is available thanks to warm-start at the beginning of SubtreeSolver, then it can be force-quitted quickly via the
pruning procedure. We also see that, while the size of the state-space tree increases exponentially in k, the running
time and solver call grow sub-linearly in k in the semi-log plots, which implies that the search space is eﬀectively
reduced thanks to our prioritization method with SubtreeSolver.

15

100200300d100101102103Runningtime(s)BFS-PDALBFS-SGA100200300d102103104105SolvercallBFS-PDALBFS-SGA102030k100101102103Runningtime(s)NonePruningWarm-startBoth102030k2×1023×1024×1026×102SolvercallNonePruningWarm-startBoth(a) Huber, PSSR

(b) Huber, Running Time

(c) Logistic, PSSR

(d) Logistic, Running Time

Figure 7: PSSR and Running Times.

D Additional Experimental Results

We examine how the PSSR performances and running times change with stronger regularization. The experimental
settings used here are almost the same as those of Section 4.1.2. The only diﬀerence is the λ value: We let λ = 0.01
and 0.002 for Huber and logistic instances, respectively.

Figure 7 presents the PSSR values and running times. Relative to the results shown in Section 4.1.2, BFS
became faster and the PSSR performance gap between BFS and the inexact methods became smaller. The reason
for this result is as follows: When strongly regularized, objective functions become convex more strongly. This
typically reduces the gap, F (S)
LowS, and so BFS terminates more quickly. Furthermore, it becomes easier to
solve NSM instances exactly with inexact methods. Namely, it tends to be easy to exactly solve NSM instances
with strong regularization. On the other hand, due to the over regularization, optimal solutions to such NSM
instances often fail to recover the true support, hence the PSSR performance of BFS deteriorates; consequently, the
gap between BFS and inexact methods became smaller. To conclude, if we are to achieve high support recovery
performance, we need to solve NSM instances with moderate regularization, which is often hard for inexact methods
as implied by the experimental results in Section 4.1.2. This observation emphasizes the utility of our BFS, which
is empirically eﬃcient enough for exactly solving moderate-size NSM instances.

−

16

5060708090100n20406080100PSSRBFS(∆=0)BFS(∆=0.005)OMPHTPDIHT5060708090100n10−210−1100Runningtime(s)BFS(∆=0)BFS(∆=0.005)OMPHTPDIHT100200300400500n02040PSSRBFS(∆=0)BFS(∆=0.005)OMPHTPDIHT100200300400500n10−1100Runningtime(s)BFS(∆=0)BFS(∆=0.005)OMPHTPDIHT