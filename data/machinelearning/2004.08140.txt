0
2
0
2

r
p
A
7
2

]
E
N
.
s
c
[

2
v
0
4
1
8
0
.
4
0
0
2
:
v
i
X
r
a

GEVO: GPU Code Optimization using Evolutionary
Computation

JHE-YU LIOU, Arizona State University, jhe-yu.liou@asu.edu
XIAODONG WANG, Facebook
STEPHANIE FORREST, Arizona State University and Santa Fe Institute
CAROLE-JEAN WU, Arizona State University and Facebook

GPUs are a key enabler of the revolution in machine learning and high performance computing, functioning
as de facto co-processors to accelerate large-scale computation. As the programming stack and tool support
have matured, GPUs have also become accessible to programmers, who may lack detailed knowledge of the
underlying architecture and fail to fully leverage the GPU’s computation power. GEVO (Gpu optimization
using EVOlutionary computation) is a tool for automatically discovering optimization opportunities and
tuning the performance of GPU kernels in the LLVM representation. GEVO uses population-based search to
find edits to GPU code compiled to LLVM-IR and improves performance on desired criteria while retaining
required functionality. We demonstrate that GEVO improves the execution time of the GPU programs in the
Rodinia benchmark suite and the machine learning models, SVM and ResNet18, on NVIDIA Tesla P100. For
the Rodinia benchmarks, GEVO improves GPU kernel runtime performance by an average of 49.48% and by as
much as 412% over the fully compiler-optimized baseline. If kernel output accuracy is relaxed to tolerate up to
1% error, GEVO can find kernel variants that outperform the baseline version by an average of 51.08%. For
the machine learning workloads, GEVO achieves kernel performance improvement for SVM on the MNIST
handwriting recognition (3.24X) and the a9a income prediction (2.93X) datasets with no loss of model accuracy.
GEVO achieves 1.79X kernel performance improvement on image classification using ResNet18/CIFAR-10,
with less than 1% model accuracy reduction.

1 INTRODUCTION
The fields of large-scale machine learning and
scientific algorithms are expanding quickly and
pushing the limits of high performance com-
puting. Continued advances in these fields will
require orders-of-magnitude improvements in
computing power [28, 42, 106]. GPUs help ad-
dress this challenge and have become de-facto
co-processors [2, 6, 38, 93, 114] for accelerat-
ing the performance of general-purpose, large-
scale parallel workloads [5, 45, 84]. At the same
time, the GPU programming interface has ma-
tured, making GPUs accessible to amateur pro-
grammers. However, it is challenging to opti-
mize and fine-tune the performance of general-purpose GPU programs without platform- and
domain-specific knowledge. For example, programmers may be excessively cautious in their use of
synchronization which incurs a performance penalty. It is well known that the lack of concurrency
semantics adds to the challenge of optimizing parallel programs such as GPU codes [10]. To continue
the synchronization example, a compiler cannot perform additional optimization passes to eliminate
unnecessary synchronization primitives without concurrency semantics. Figure 1 illustrates the
size of this effect for one of the Rodinia benchmarks: Eliminating unneeded synchronization nearly
doubles the performance gain over O2 optimization for nw.

Fig. 1. Performance improvements for nw with no com-
piler optimization (clang -O0), with full compiler op-
timization (clang -O2), and when unneeded synchro-
nization primitives are removed manually.

Under Review of ACM TACO

 
 
 
 
 
 
2

Jhe-Yu Liou, Xiaodong Wang, Stephanie Forrest, and Carole-Jean Wu

Many research projects have investigated automated compilation optimization methods to reduce
the burden on application programmers, including peephole [9], loop-unrolling using machine
learning techniques [54], auto-vectorization [69], auto phase ordering [35], link-time [103], and
profile-guided optimization [76], but additional efficiencies can be found by tailoring the binary
to particular classes of inputs or particular architectures. For example, STOKE is a stochastic
program synthesizer that uses random search to explore the high-dimensional space of possible
program transformations and is an example of this performance tuning approach [86]. A related
approach uses Evolutionary Computation (EC) to morph existing code from the target program to
code that improves run-time and other non-functional program properties. In this work we use
EC, also known as Genetic Improvement, because earlier work showed that it scales well with
program size [53, 90]. Some earlier work reports optimizations of specific GPU programs using
EC [46–49], but these approaches are not easily extensible to large design spaces, in part because
the representation of each program is customized and requires manual program translation before
the search for optimizations can be performed.

We propose compiler post-pass performance tuning—GEVO—GPU code optimization using
EVOlutionary computation [57, 58]. GEVO encodes optimization objectives, such as execution time,
energy use or accuracy, in its fitness function and implements a set of mutation and recombination
operators for GPU kernel transformations in the LLVM-IR representation. We demonstrate GEVO
first on the single-objective problem of reducing GPGPU kernel execution time (GEVO-default).
Second, we show how GEVO can simultaneously tune GPU code to meet two independent objectives,
such as performance and accuracy (GEVO-mO), using multi-objective search.

To assess the general applicability of GEVO, we evaluate on NVIDIA Tesla P100 using the Rodinia
benchmark suite [76], which covers a set of important application domains such as medical imaging
and data mining. Each application provides unique characteristic in terms of parallelism, data
sharing, memory access patterns, and so forth. The results vary significantly across the Rodinia
benchmarks, but on average GEVO-default improves GPU kernel runtime performance by 49.48%
over the fully compiler-optimized baseline, and by as much as 412% in one case. If output accuracy
is relaxed to tolerate up to 1% error, GEVO-mO can find kernel variants that outperform the baseline
version by an average of 51.08%.

Although GEVO can be applied to any GPU program, we are particularly interested in machine
learning programs, because machine learning tasks are computationally intensive and are by
nature error-tolerant. For example, deep neural networks often require hours or days to train a
single model, and training time is often traded off against model accuracy [38, 39, 81, 85, 115].
We present results for GEVO on supervised machine learning code from two production-level
frameworks, ThunderSVM [108] and Caffe2 [31], considering standard handwriting recognition,
income prediction, and image classification datasets.

To summarize, the key contributions of this paper are:

• We present GEVO, a tool for automatically tuning the performance of GPU kernels repre-
sented in the LLVM intermediate representation (LLVM-IR) to meet multiple criteria. Our
infrastructure scales to arbitrarily large program sizes. We demonstrate GEVO on the single
objective of runtime optimization and on the multi-objective optimization criteria of runtime
and accuracy.

• Empirical evaluation on the Rodinia benchmark suite, which includes 13 applications covering
a wide range of application domains, is performed. On average, GEVO improves kernel
runtime by 49.48% with the output fidelity enforced, or by 51.08% if the output fidelity can be
relaxed by 1%.

Under Review of ACM TACO

GEVO: GPU Code Optimization using Evolutionary Computation

3

• Empirical evaluation of two machine learning kernels, using Thunder SVM and Caffe2 on
standard machine learning benchmark datasets, is performed. In these experiments, model
accuracy is interpreted as output fidelity. Compared to the original baseline, we find that
GEVO can improve kernel runtime performance by 1.79X to 3.24X. In most cases, these
runtime improvements are achieved without loss of accuracy, and in some cases model
accuracy actually improves.

• In-depth analysis of GEVO optimizations identified several architectural-, domain-, and
dataset-specific improvements. We provide explanations for many of the performance opti-
mizations discovered by GEVO, such as eliminating conservative synchronization primitives
(Section 5.2.1), removing redundant store instructions (Section 5.1.2), reducing conditional
executions (Section 5.2.1), loop perforation (Section 5.2.3), memoization (Section 5.2.4), and
algorithm improvements (Section 6.1.2 and 6.2).

• Multi-objective optimization: We demonstrate that when output fidelity is relaxed, solu-
tions can be found that improve both optimization criteria—runtime and output fidelity—
simultaneously. These optimization points are not accessible to the search when output
fidelity is strictly enforced.

The remainder of the paper is organized as follows. Section 2 provides relevant background
and places the paper in the context of earlier work. Section 3 describes the GEVO design in detail;
and Section 4 describes the system environment and benchmarks we used to evaluate GEVO.
Experimental results for GEVO-default and GEVO-mO are reported in Section 5 and Section 6
respectively. We discuss limitations and future directions in Section 7 and conclude the paper in
Section 8.

2 RELATED WORK
This section discusses related work from program synthesis, superoptimization, to evolutionary
computation. It also reviews the few earlier works that have applied EC to GPUs, and the growing
body of work using EC to improve machine learning.

2.1 Program Synthesis and Superoptimization
Program synthesis methods automatically generate computer programs based on programmer-
defined specifications. In some cases, the goal is to produce programs that run faster, which is known
as superoptimization. Early work on superoptimization dates back to Massalin’s superoptimizer [65]
in 1987, which exhaustively searched and tested a subset of the Motorola 68020 assembly instruction
set against testing inputs, and synthesized the shortest instruction sequence, for a target function.
Since the number of possible code sequences in most programming languages is enormous,
finding an optimal sequence is usually intractable, and all recent program synthesis techniques
use some form of search to cut down the search space. Such search algorithms can be roughly
divided into two categories, deductive synthesis and inductive synthesis. Deductive synthesis
encodes a given program into a Boolean formula and searches for a logically equivalent formula
using an SAT/SMT solver. Developing such encodings is challenging and time-consuming, and
significant research effort has been been devoted to making such processes more approachable
to programmers, ranging from Rosette, a symbolic framework language interpreter [101, 102]
to Z3, an efficient SMT solver with C and Python binding [73]. Synthesized programs using the
deductive approach are provably correct and do not require verification. However, as the length
of the computer program increases linearly, the size of the corresponding Boolean expressions
grows exponentially. Therefore, program that are synthesized using the deductive approach are
relatively small, and often have additional constraints. For example, the largest, loop-free program
synthesized by Gulwani in 2011 [34] has only 16 lines in the pseudo assembly.

Under Review of ACM TACO

4

Jhe-Yu Liou, Xiaodong Wang, Stephanie Forrest, and Carole-Jean Wu

Instead of represent the program’s specification as a Boolean formula, inductive synthesis relies
on the original program and a set of input/output examples (test cases). In this case, the search
usually begins by sampling local deviations from the given program or by generating random code
combinations from scratch. Each variant is then checked against the test cases to verify functionality.
Depending on the particular search method, new code recombinations are tried based on previous
observations using statistical models such as Markov Chain Monte Carlo (MCMC) sampling, or
heuristic search methods are used, as in the case of Evolutionary Computation (EC). Schkufza et al.
proposed STOKE [24, 86, 87, 94] using MCMC sampling for X86-64 assembly codes to improve run
time. STOKE has the same overarching goal as GEVO, which is to search for program optimizations
without guaranteeing exact program semantics as deductive synthesis requires. However, STOKE
does not naturally scale up to large code sizes because it considers the entire X86-64 instruction
set, even vector instructions, and it focuses on synthesizing instruction sequences from scratch. EC
differs from STOKE in two ways: It modifies existing programs using existing instructions, and it
can scale to arbitrarily large program sizes (over a hundred thousand instructions [90]), whereas
the test programs in STOKE are only a few hundred instructions [24].

We elected to use EC primarily because of its scalability to realistic program sizes. In addition to
scalability, an inductive method was appropriate because many applications on parallel accelera-
tors, e.g., image processing and machine learning, do not require an exact result. Instead, these
applications often have domain specific metrics for assessing an acceptable result. This feature of
many GPU program mitigates the requirement to preserve exact program semantics.

2.2 Evolutionary Computation (EC)
Earlier work developed EC methods to improve computer programs, e.g., to automatically repair
bugs in legacy software [27, 32, 33, 52, 107], and this class of applications is sometimes referred to
as genetic improvement. Transitions to industrial practice include Facebook’s SapFix tool [30] and
the Janus Manager deployment [37]. Although most work has been conducted at the source-code
level using abstract syntax trees, similar methods have been applied to assembly programs [89]
and object code [92].

Subsequent analysis showed that the applied mutations often have no observable effect on
program behavior [11, 15, 36, 91, 104]. These neutral mutations occur frequently (20 − 40% of the
time), even when the mutations are restricted to sections of code covered by the tests. Although it
is surprising that the rate of neutral mutations is so high, equivalent mutations are well-known
in mutation testing, e.g., [63]. These results suggested the possibility of using EC to optimize
non-functional properties of software by finding modifications that are neutral with respect to the
test suite but improve the non-functional property in question.

White et al. proposed the idea of using EC to improve program performance [109], and Schulte
et al. achieved significant energy reductions for several Parsec benchmarks [90]. Bruce et al.
applied a similar technique for MiniSAT to reduce energy consumption [15]. Other works [18, 64]
constrain EC’s search space for improved energy consumption of Java programs by asking users to
provide predefined locations or equivalent functions or class implementations. These, and several
subsequent works [16, 29], demonstrate the potential for stochastic search methods such as EC to
improve a program’s performance or energy efficiency through machine- or architecture-specific
optimizations. However, these methods are not yet mature or carefully analyzed. In contrast with
our work, they focus on energy reduction rather than run-time, typically target the CPU; and their
general applicability is not well understood. The results reported here address these limitations.

2.3 Evolutionary Computation for GPU Programs

Under Review of ACM TACO

GEVO: GPU Code Optimization using Evolutionary Computation

5

There is some previous work applying EC to GPU kernels, including a graphics shader program [96].
This work began with a basic lighting algorithm and used EC to gradually modify the shader program
into a form that resembles an advanced algorithm proposed by domain specific experts. In the
GPGPU domain, Langdon et al. used EC to reduce the runtime of a CUDA program, reporting results
for two specific programs: gzip [46] and an RNA analysis program [49]. This prior work targets a
single program operating in a specific domain, and the methodology used in [46–49] represents the
program object as a custom-designed, line-based Backus Normal Form (BNF) grammar. We seek a
method that is generalizable across multiple programs with minimal manual intervention and uses
modern tooling, which is Clang/LLVM.

Clang/LLVM is a widely-used, multi-language,
and highly modular compiler infrastructure.
Schulte’s thesis is the only work we are
aware of that has experimented with evolving
the LLVM intermediate representation (LLVM-
IR) [88], but this was a preliminary proof-of-
concept rather than a robust implementation,
and no significant experiments were conducted.
Now that Clang/LLVM supports CUDA com-
pilation, it is feasible to compile GPU kernels
into LLVM-IR, but this has only been available since 2016 [110]. Thus, we adopt the Clang/LLVM
infrastructure for GEVO including the LLVM-IR, as shown in Figure 2. This avoids developing novel
parsing and syntax manipulating infrastructure, but it introduces new challenges for implementing
the basic mutation and recombination operations.

Fig. 2. GEVO in the LLVM/Clang compilation flow.

2.4 Genetic Improvement of Machine Learning (ML)
While EC can be applied to any computer program, machine learning is a particularly attractive
domain, because of its popularity and its high computational cost. Moreover, most ML applications
can be accelerated using GPUs. Although no prior work is known that uses EC to accelerate ML
programs on GPUs, EC has often been used to improve neural network designs and to optimize
weights. This work dates back at least to an 1989 [72] paper that used EC train a neural network.
The most established and popular approach in this domain is NEAT [98], proposed by Stanley et
al. in 2002, which uses EC to simultaneously learn the neural network connection topology and
the weight of each neuron. The original NEAT design performed well in a comparatively small yet
homogeneous neural network where the network consists of common neurons, and the following
works expanded its scalability to larger networks and more complex tasks [80, 97, 105].

More recently, convolution neural networks (CNNs) have achieved extraordinary performance
in image classification tasks by providing additional convolution layers as filters. These layers are
used to determine important spatial pattern in the image so that the number of features can be
reduced before being fed into a traditional neural network. Many approaches for identifying good
architectures (topologies) for CNNs have been proposed [13, 43, 59, 60, 62, 77, 112, 117], and these
have outperformed manually designed architectures in several tasks. Similar to NEAT, Reak et al.
proposed using EC to design CNNs in a limited search space of convolution layers composed by
common arithmetic operations [79]. This work achieves state-of-the-art classification performance
on the ImageNet dataset compared to other network architecture searches, which use random
search and reinforcement learning.

In state-of-the-art machine learning programming frameworks, deep learning models are rep-
resented as computational graphs of various types of operators. This exposes opportunities for
operator-level optimization, such as operator fusion, using domain-specific compilers. For example,

Under Review of ACM TACO

CUDA Program SourceClang CUDA FrontendDevice  LLVM-IRKernel CallcudaLaunchKernel()Host Code (Pure C++)GEVOC++ CompilerNVPTX Code Generator PTXHost BinaryExecute / Evaluation6

Jhe-Yu Liou, Xiaodong Wang, Stephanie Forrest, and Carole-Jean Wu

XLA [1] is developed for TensorFlow [3], Glow [83] for PyTorch [75], TVM [22] for MXnet [21], and
so forth. Domain-specific compilers can perform further optimization when lowering high-level,
neural-network operators onto machine-specific implementations using optimized libraries. These
optimizations differ from the aforementioned neural architecture searches in that the functional
behavior of a given network is preserved. Built on top of the prior superoptimization approach [65],
TASO [41] was recently proposed to automatically optimize the computational graph. Given a
small computational graph, TASO enumerates all combinations of operator implementations and
selects the operator graph implementation that minimizes runtime. The functional behavior of
the original graph is preserved with satisfiability verification using a SAT solver. TASO shares
the scalability limitation discussed earlier for deductive program synthesis (Section 2.1), and the
referenced work does not scale beyond graphs of size 4 operators.

Our approach to optimizing NNs is complementary to this earlier work. GEVO explores joint
optimization opportunities by (1) discovering better-performing operator implementations and (2)
changing neural network architectures, which extends previous work (Section 6.2.2).

3 GEVO DESIGN
We propose GEVO—a tool for automatically
improving kernel implementations for GPUs.
GEVO enables GPU code optimization using
EVOlutionary computation. It is a post-pass
performance tuning approach to optimizing
GPGPU kernel implementations.

Algorithm 1 The main loop of GEVO.

Parameter: PopSize, CrossRate, MutateRate, InitDist
Input: GPU kernel Program, P

Mutate(individual)*InitDist

offspring ← SelTournament(pop, rank, PopSize)
elites ← SelBest(pop, rank, PopSize /4)

1: pop ← Initialize(PopSize, P)
2: for all individual in pop do
3:
4: rank ← NonDominatedSort(pop)
5: while not interrupt do
6:
7:
8:
9:
10:
11:

GEVO takes as input a GPGPU program,
user-defined test cases that specify required
functionality, and a fitness function to be
optimized. GEVO attempts to maximize the
fitness function by evolving and evaluat-
ing mutated kernel variants in an iterative
population-based search. Figure 2 presents
GEVO in the context of the LLVM/Clang
compilation flow. Kernels in a GPGPU pro-
gram that will run on GPU are first separated
and compiled into the LLVM intermediate
representation (LLVM-IR) using the Clang
compiler. GEVO then takes kernels in LLVM-
IR format as inputs, modifies them to pro-
duce different kernel variants, and translates
the variants into PTX files. The host code running on CPU is modified to load the generated PTX file
into the GPU. GEVO then evaluates how the kernel variant performs as defined by the objectives
encoded in the fitness function.

rank ← NonDominatedSort(elites + offspring)
pop ← SelBest(elites + offspring, rank, PopSize)

if random() < CrossRate then
Crossover(ind1, ind2)

for every 2 individual (ind1, ind2) in offspring do

for all individual in offspring do

if random() < MutateRate then

Mutate(individual)

12:
13:
14:

15:
16:
17:

As shown in Algorithm 1, the search begins with an initial population of PopSize individuals
(LLVM-IR kernel variants) that is formed by taking the original program, making PopSize copies
and applying random mutations to each (Line 3 where InitDist, the number of mutations applied
to each individual, defaults to 3), giving the initial population some diversity. GEVO then forms
the next generation of individuals by ranking individuals according to the objectives, recombin-
ing instructions between kernel variants (Crossover), and randomly adding, deleting or moving
instructions in each variant (Mutation). Finally, GEVO compares the new variants to a set of elites
retained from the previous generation (Selection), eliminating low-fitness individuals and retaining

Under Review of ACM TACO

GEVO: GPU Code Optimization using Evolutionary Computation

7

those with higher fitness for the next generation. The next few subsections give details of how we
implemented these operations for GPGPU optimization.

3.1 Individual Representation
GI methods typically use either a program-based (each variant consists of the entire program) or a
patch-based (each variant is a list of mutations (edits) applied to the original program) representation.
For large programs, the patch-based representation is convenient because it is more space efficient.
GEVO uses both representations. That is, each individual kernel variant contains both the LLVM-IR
code and the set of the mutations that produced it from the original.

This design decision relates to the many data dependencies built into the LLVM-IR. Because of
the repair process that is required after most mutations, it would be expensive to reapply all the
mutations for a variant each time it is evaluated. Similarly, crossover exchanges subsections of the
kernel code. Doing this naively can break a large number of data dependencies, so it is more efficient
to implement crossover using the patch representation. Because the number of mutations applied
to any kernel variant tends to be low, and because kernels are relatively small-sized programs, the
memory requirement of storing both representations is reasonable.

3.2 Fitness Evaluation
Although GEVO can optimize any desired fitness function, we first focus on the problem of reducing
kernel execution time (GEVO-default). In this case, the fitness function is simply the runtime of the
kernel variant without tolerating any output variation. When we consider approximate computing,
where output accuracy can be relaxed to improved execution time, we include output accuracy in
the fitness function as multi-objective (GEVO-mO), i.e., arдmin(time, error ).

Using these fitness criteria each kernel variant is evaluated by running it against all available
test cases. To protect against overfitting, we also evaluate at the end of the search against a set of
held-out test cases, generated randomly. The fitness value is reported as a vector corresponding
to the number of objectives. Each element in the vector is a single scalar value, i.e., the mean
performance on that objective across the test cases (see Section 4.3).

3.3 Selection
GEVO uses the Non-dominated Sorting Genetic Algorithm (NSGA-II) [26] to select individuals
according to multi-objective fitness criteria. Figure 3 illustrates a set of kernel variants, plotted
according to two dimensions of the fitness function, say error and run-time, where the goal is to
minimize both objectives, retaining individuals that represent the best tradeoffs between the two
objectives (shown in blue in the Figure). NSGA-II uses Pareto dominance, where individual i is said
to dominate individual j if i is better than j on at least one objective and no worse on the others.
NSGA-II calculates the Pareto fronts, and ranks individuals according to which front they belong.
Then a crowding factor is calculated for each individual based on the density of other individuals
along its Pareto front, and these two values are combined to produce a single fitness value for each
kernel variant. See [26] for details. Finally, based on this single fitness value, NSGA-II uses a popular
EC selection method known as tournament selection [70] to choose kernel variants for the next
generation (Line 6 of Algorithm 1). GEVO retains the top quarter of the population at time t and
copies it unchanged to the population at time t + 1 (Lines 7, 16, and 17 of Algorithm 1), a method
known as elitism [8]. It then chooses the remaining 3/4 of the population using the tournament
selection.

3.4 Mutation Operators
Mutation modifies the linear array of instructions stored for each variant using one of the following
operations:

Under Review of ACM TACO

8

Jhe-Yu Liou, Xiaodong Wang, Stephanie Forrest, and Carole-Jean Wu

Fig. 3. Non-dominated sorting with a crowding
method to enforce diversity.

Fig. 4. Mutate-Copy: Operand dependency is re-
built to preserve LLVM-IR program validity. Since
LLVM-IR is strongly typed, the constant value 1.0
is used if no other value in the requested type is
available.

• Mutate-Copy: Duplicate an instruction and insert it in another location.
• Mutate-Delete: Remove an instruction.
• Mutate-Move: Move an instruction to a different location.
• Mutate-Replace: Replace an instruction with another instruction. This can occur either at
the instruction or the operand level. In the second case, a single operand is replaced with
another operand.

• Mutate-Swap: Swap the location of two instructions.
Since the LLVM-IR is based on Static Single Assignment (SSA) where each variable (like %0,
%1 in Figure 4) can be assigned only once at creation, our mutations are likely to create invalid
programs by breaking the SSA constraint. Thus, we introduce an extra repair step. As illustrated
in Figure 4, the instruction mul is copied, and we see that the first operand relies on %3 which is
invalid in the new location. GEVO repairs it with the constant 1.0 as the two existing values (%0,
%1) are not of the proper type. To our knowledge, only one other work [88] has attempted to design
mutation operations for SSA. GEVO implements similar mutations to this earlier work, although
our mutations repair SSA dependencies more robustly, and we have introduced two new mutation
operations.

The operators Mutate-Copy and Mutate-Move insert new instructions, which has no effect
unless a subsequent instruction can use the result of the inserted instruction. Figure 4 illustrates
how GEVO enforces this by changing the first operand of the fifth instruction to use the value
from second instruction. This instruction was selected because its types agree with the mutated
instruction. In addition to the type checking shown in the above repair procedure, dominator
analysis weeds out values if the creator and the user of that value are in separated basic blocks that
do not share the same execution path.

As depicted in Line 14 of Algorithm 1, when mutation is called, one of the aforementioned
mutation operations is selected randomly (with equal probability) and applied as an edit to generate
a new kernel variant. Since GEVO does not use domain-specific knowledge to select a mutation
or rely on program semantics, we immediately evaluate the individual by running the available
test cases, as Section 3.2 describes, and eliminate invalid modifications (sanity check). Mutation is
iteratively applied to the same individual until a valid kernel variant is identified. Depending on
the kernels, the acceptance rate of any single mutation is typically 5% - 30%.

3.5 Crossover
GEVO uses the patch-based representation for crossover, because combining two random program
slices would require more extensive repair. GEVO implements one-point messy crossover, which
combines shuffle [17] and variable-length [55] crossover operations. Figure 5 illustrates the process.

Under Review of ACM TACO

ACBRankCABObjective 1Objective 2HighLowFunction(int %0)%1 = load int, %0%4i = mulfloat, %3, 1.0%2 = add int, %1, %1%3 = conv float int %2%4 = mulfloat, %3, 1.0Function(int %0)%1 = load int, %0%4i= mulfloat, 1.0, 1.0%2 = add int, %1, %1%3 = conv float int, %2%4 = mulfloat, %4i, 1.0CopyRebuildGEVO: GPU Code Optimization using Evolutionary Computation

9

Beginning with a list of mutations (edits) associated with each individual, GEVO combines them
into a single sequence, shuffles the sequence, and randomly separates it back into two distinct patch
sequences. Finally, GEVO reapplies each patch sequence to the original GPU kernel and generates
two new individuals. This form of crossover was selected because it generates a wide diversity of
recombinations from a minimal number of mutations, and our mutations are relatively expensive.

Similar to mutation, after crossover,
each new individual is evaluated to test
if the combinations are valid. Otherwise,
GEVO repeats the process until it finds a
successful recombination. The acceptance
rate of crossover is as high as 80% because
each individual mutation has already been
validated.

4 EXPERIMENTAL SETUP
This section describes our experimental
setup for the empirical evaluation on real GPUs.

Fig. 5. One-point messy crossover.

4.1 Infrastructure and Configurations
We developed GEVO using an existing python framework for evolutionary algorithms, called
DEAP [25], implementing the genetic operators described in Section 3, and integrating them into
the DEAP framework.1 We instrument the LLVM compiler (LLVM 8.0) to implement the mutation
operations in C++ as a LLVM pass. For each optimization, GEVO was given a 48-hour wall-clock
budget. We evaluate GEVO using NVIDIA Tesla P100 GPUs, under CUDA 10.1 and NVIDIA GPU
driver 418.87. The Nvidia profiler (nvprof) was used to collect kernel execution time, which became
the runtime metric used by the fitness function. In our experiments, nvprof introduced no overhead
to kernel execution time but only to application execution time which is not the optimization target
in this study. Also, the collected kernel execution time consistently varies less than 1% through
multiple profiling run on the same GPU kernel.

All GEVO experiments were conducted with population size of 256, crossover rate of 80% (80% of
individuals in population are selected for crossover), and a mutation rate of 30% (every individual
has 30% chance to receiving one mutation). The 48-hour budget for each GEVO run translates into
a variable number of generations (shown in the last column of table 1), depending on the program,
the test cases, and the success rate of the mutation operation. For our experiments, the number of
generations ranged from a low of 12 to over 80. For example, for the NN benchmark, GEVO spent
the majority of its time searching for valid mutations and was able to complete only 18 generations
within 48 hours. We speculate that in cases where GEVO was unable to find useful optimizations
it is partially because the runs did not complete enough iterations of the search, and providing a
larger search budget could improve results for these programs.

4.2 Benchmarks
Table 1 summarizes the benchmarks we used to evaluate GEVO: the Rodinia benchmark suite and
ML workloads on ThunderSVM and Caffe2. Rodinia includes a wide range of general-purpose
deterministic workloads for heterogeneous computing, representing diverse parallel communication
patterns, synchronization techniques and power consumption. ML models are a natural application
for exploring accuracy/efficiency tradeoffs because the algorithms are intrinsically error-tolerant,

1The GEVO code is available at https://github.com/lioujheyu/cuda_evolve

Under Review of ACM TACO

Individual 1PatchCPKernel Variant 1Combine & ShuffleRandom Point SeparationPatch ReapplyOriginal kernelIndividual 2CPMVKernel Variant 2CPDELSWPCPMVNew Individual 1New Kernel Variant 1New Individual 2New Kernel Variant 2PatchPatchPatchDELSWPCPDELSWPCPMVCPCPDELSWPMVCPCPDELSWPMV10

Jhe-Yu Liou, Xiaodong Wang, Stephanie Forrest, and Carole-Jean Wu

Table 1. Benchmarks used for evaluation.

Application
Breadth first Search
B+Tree
CFD Euler3D
Gaussian elimination
Heart Wall
Hotspot
LU decomposition
Nearest Neighbor
Needleman-Wunsch
Particlefilter
Pathfinder
SRAD_v2
Stream Cluster
Handwriting recognition (C=5, g=0.05) mnist
Income prediction (C=32, g=0.0078125)
Image classfication

Abbr.
bfs
b+t
cfd
gau
hw
hot
lud
nn
nw
pf
path
sv2
sc

a9a
cifar-10

GPU Kernel

Line of LLVM-IR Generation
18
72
63
168
53
1079
29
186
36
3806
28
189
81
2491
18
32
21
715
55
1442
25
109
16
446
12
231
27
(c_smo_solve) 256
61
(c_smo_solve) 256
15
(momentumSGD) 39

and they require significant time overhead for training, e.g., the training time of state-of-the-art
language translation models is on the order of days [38].

For the first set of benchmarks, we validate optimized kernel variants using the default inputs
provided with the Rodinia benchmarks. For each benchmark, we then generate additional tests
by randomly generating three sets of input values using the Rodinia built-in input generator.
Depending on the benchmark, each input set contains from tens of thousands to millions of input
values. Each test is run with the original, unmodified kernel and its output is used as an oracle to
validate the output of the candidate kernel variants. GEVO rejects variants that fail to produce
outputs that are identical to the oracle (GEVO-default) or exceed the default 1% error tolerance
(GEVO-mO). After evolution, we validate the highest fitness kernel variant found during the search
on held-out tests. We generate the held-out tests by rerunning the test-generation process. This step
helps ensure that GEVO does not overfit the kernel to the existing test cases during the evolution.
For the ML benchmarks, we focused on a Support Vector Machine (SVM) and Stochastic Gradient
Descent. Because GEVO searches the optimization space at the granularity of instructions, it
requires full access to the intermediate representation and the corresponding optimized library
implementations. This consideration led us to a supervised ML framework, ThunderSVM, which is
a support vector machine library that is fully open-sourced and optimized for GPU implementation.
We evaluate GEVO on ThunderSVM (refered to as SVM) with two standard datasets: handwriting
recognition using MNIST [51] and income prediction using a9a [78]. We downloaded the datasets
from libsvm [20]’s data repository, which consists of 60,000 training and 10,000 testing data samples
for MNIST, and 32,561 training and 16,281 testing samples for a9a. Additionally, we used the MNIST
large dataset, which contains 8,000,000 image samples, solely for the post-evolution evaluation.
Specifically, we asked GEVO to optimize the c_smo_solve kernel for both training time and
inference prediction accuracy of the trained model. We present the results in Section 6.2.1.

Many popular deep learning frameworks, like TensorFlow [3], PyTorch [75], and Caffe2 [31],
rely heavily on the NVIDIA closed source cuDNN library to drive the GPU and cannot be directly
targeted by GEVO. However, a few frameworks maintain a small custom CUDA implementation
when required functionality has no direct mapping from the cuDNN library. For example, in Caffe2,

Under Review of ACM TACO

GEVO: GPU Code Optimization using Evolutionary Computation

11

stochastic gradient decent with momentum (momentumSGD) is custom implemented as a CUDA
kernel and open sourced within Caffe2 source repository. This provides an opportunity for us to
include Caffe2 in our evaluation.

We evaluate Caffe2 using an 18-layer residual neural network (refered as ResNet18) to perform
image classification against the CIFAR-10 dataset [44] with 50000 training and 10000 testing images.
We used GEVO to optimize the momentumSGD kernel because it is the only major operator used
in ResNet that is open-sourced to us. This kernel updates the weight of the neural network based
on the loss function, evaluating the difference between the true label and predicted label. Since
the search space is constrained to a single operator, we include this application to demonstrate
GEVO’s capability and do not attempt a sophisticated solution for image classification. The results
are given in Section 6.2.2.

4.3 Error Metric
For the Rodinia benchmarks, error represents the maximum difference between outputs produced
by the unmodified, original kernel implementation and that of GEVO-mO, across all tested inputs.
Kernel variants are eliminated if the error rate of any test case exceeds the prespecified threshold,
i.e. 1%.

For both SVM and ResNet18, we consider the runtime to train the model and the accuracy of the
trained model’s performance. For SVM, we use two-fold cross validation on the training dataset to
report the error to GEVO during optimization. In ResNet18, we also report the training error for
GEVO when the model is trained for three epochs, which shortens the training time to one minute.
However, even with this simplification, GEVO required seven days to search for 20 generations,
which is a low number of generations for an evolutionary search. The testing dataset regardless of
which framework and application is only for reporting the testing error and is never be presented
to GEVO.

Similar to Rodinia, the ML kernel variants are rejected if the training error exceeds the error
achieved from the original kernel by the 1% threshold. For example, if the the unmodified kernel
achieves 3% training error, then a GEVO kernel variant with 4.1% training error will be rejected,
and another one with 3.9% training error will be accepted. In ResNet18, we set the threshold to
10% because we trained for only three epochs, which is generally not long enough for the model
to converge. Thus, the training error is noisier with this training regime, so we require a more
generous error tolerance.

5 EVALUATION OF GEVO-DEFAULT
We first present the results of our experimental evaluation on the Rodinia benchmark suite, with the
goal of evaluating GEVO’s applicability across a variety of programs (GEVO-default). Next, we take
an in-depth look at the most common architecture-specific and application-specific optimizations
that GEVO discovered (Section 5.1). In Section 6.2, we consider dataset-specific optimizations.

Figure 6 reports the overall performance improvement for GEVO-default by comparing to the
default baseline with full compilation optimization for the Rodinia benchmarks. GEVO-default
improves the performance of the Rodinia benchmark suite by an average of 49.48% and by as much
as 412% for b+t. As figure 6 shows, there is significant variability in the achieved improvement
among programs, including three, cfd, gau and nn, for which we found no optimizations. There are
several possible explanations for this variability. It could be a feature of the program itself, it could
be that we did not let GEVO search long enough, or perhaps the program was perfectly optimized
by the original programmer. However, this variability is consistent with results reported using
evolutionary methods on the related problem of reducing energy use by assembly programs [90].

Under Review of ACM TACO

12

Jhe-Yu Liou, Xiaodong Wang, Stephanie Forrest, and Carole-Jean Wu

Fig. 6. Normalized performance improvement over the default baseline with full compilation optimization for
GEVO-default in the Rodinia Benchmark. (For example, the 1.27X improvement in hot reduces runtime from
1.07 seconds to 1.07/1.27 = 0.84 seconds.)

5.1 Architecture-specific Optimizations
GEVO discovered several different optimizations related to GPU architecture design in the evolved
Rodinia Benchmarks, including synchronization issues and memory order issues. Some of these
optimizations arise from a combined effect of the architecture and the particular application/algo-
rithm.

5.1.1 Eliminating synchronization primitives.
One of the most common GEVO optimizations
removed synchronization primitives, specifi-
cally syncthread() calls in CUDA. For exam-
ple, when a programmer wants to exchange
data between threads in a thread block through
the shared or global memory, synchronization
primitives are used to synchronize the progress
of GPU threads. There are multiple reasons why
a syncthread() call might not be required and
could be removed without damaging the appli-
cation. We give several examples, taken from
GEVO runs on the Rodinia benchmarks.

1

2

3

4

5

6

7

8

9

10

11

12

13

14

__shared__
__shared__
int tid = threadId .x;

int temp [...][...];
int ref [...];

ref [ tid ] = referrence [...];
__syncthreads () ;
temp [ tid +1][0] = matrix_cuda [...];
__syncthreads () ;
temp [0][ tid +1] = matrix_cuda [...];
__syncthreads () ;

for ( int i =0; i < BLOCK_SIZE ; i ++)

temp [ tid ][ tid ] =

temp [i ][0] + temp [0][ i] + ref [i ];

Fig. 7. Simplified code snippet from nw with conserva-
tive syncthread() calls.

nw: Figure 7 shows a simplified code snip-
pet taken from nw. The syncthread function is
used three times in this particular kernel (Lines 6, 8, and 10). The first two syncthread calls (Lines
6 and 8) can be eliminated because neither ref nor temp are read before a new value is written
into the same memory location. It appears that the programmer was unnecessarily conservative
in this case, which increased performance cost without additional semantic value. Most of the
performance improvements discovered by GEVO for nw eliminated similarly overly-conservative
uses of syncthread. Such optimizations are, of course, somewhat risky in general. However, they
illustrate the value of tailoring a kernel for exactly the workloads it will experience. As part of a
wide deployment, additional post-hoc methods, such as test-case generation or program analysis,
could be employed to double-check that specific optimizations are indeed safe under the relevant
use cases.

Under Review of ACM TACO

b+tnwscbfshotludpfpathsv2hwcfdgaunnAvgRodiniabenchmark1.01.21.41.61.82.0PerformanceImprovement5.12GEVO: GPU Code Optimization using Evolutionary Computation

13

Fig. 8. Code snippet from lud illustrates a GEVO optimization, which removed redundant store instructions.
(a) is the original implementation, (b) is the LLVM/Clang compiled version, and (c) is the optimized kernel
variant with GEVO.

lud: Other synchronization-related optimizations found by GEVO are architecture-specific and
concern scope. In a GPGPU application, a massive number of parallel threads are created to execute
the same piece of code in a kernel. At runtime, multiple threads form a thread-block or a cooperative
thread array. A thread-block is the basic unit of execution—all threads within a thread-block have
the same life-cycle and are dispatched onto a GPU streaming multiprocessor at the same time.
Depending on the width of the vector functional units/SIMD lanes, threads within a thread-block
are grouped into small batches (typically 32 or 64 threads), called a warp or a wavefront. At every
cycle, the GPU hardware warp scheduler selects a ready warp from the warp pool for execution
(known as the SIMT execution). Warps within a thread-block and threads within a warp are tightly
coordinated, bounded by the same synchronization barrier (architecture-specific). To explicitly
synchronize threads within a thread-block, syncthread can be used. For the particular case of lud,
the programmer specifies exactly the same number of threads in a thread-block as the warp thread
size. Instead of explicitly synchronizing threads with syncthread, GEVO finds a kernel variant
that leverages the implicit synchronization boundary implemented at the warp granularity and
eliminates the syncthread call.

All: Depending on the specific implementation of warp and thread-block scheduling policies,
additional syncthread calls can often be eliminated without altering the execution order between
GPU threads (hotspot, lud, nw).

5.1.2 Removing redundant store. Another optimized kernel variant discovered by GEVO removed
redundant store instructions, illustrated with a code snippet from lud in Figure 8. We show three
versions of the code snippet: (a) is the original implementation, (b) is the LLVM-IR after compilation
with the clang compiler, and (c) depicts the optimized kernel variant found by GEVO. Variable s is
a variable stored in the GPU shared memory (Line 1, Figure 8(a)) and is initialized in Line 5. Each
parallel thread accumulates its own s and reads/writes to s in the shared memory directly (Lines
9-10). Finally, the value of s is written back to the shared memory (Line 12). Compared to updating
values in the GPU register file, updating s in the shared memory (Line 10) can incur significant
latency and stress the memory subsystem unnecessarily.

Instead of constantly reading and writing the value of s to the shared memory, the post-compiled
LLVM-IR version eliminates the variable reuse patterns for s and replaces s with a temporary
variable (temp) which is stored in the register file. To preserve semantic correctness, s in the
shared memory is updated with the new value of temp (Line 11). Interestingly, this instruction is
removed by GEVO. While in theory other threads could access s and receive a stale value, this
does not change kernel outputs. GEVO, in this case, trades off program semantics for improved

Under Review of ACM TACO

1 __shared__ s[BLOCK];2 intc = CONST;3 inttid= ThreadId.x;4 for(i=0; i< 16; i++)5   s[tid] = init(tid);6 __syncthread();7 8 9 for(i=0; i< 16; i++)10 s[tid] = s[tid] -s[i]*s[i];11 12 s[tid] = s[tid] / c;13 __syncthread();1 __shared__ s[BLOCK];2 intc = CONST;3 inttid= ThreadId.x;4 for(i=0; i< 16; i++)5   s[tid] = init(tid);6 __syncthread();78 float temp = s[tid];9 for(i=0; i< 16; i++)10 temp = temp -s[i]*s[i];11   s[tid] = temp;12 s[tid] = temp / c;13 __syncthread();1 __shared__ s[BLOCK];2 intc = CONST;3 inttid= ThreadId.x;4 for(i=0; i< 16; i++)5   s[tid] = init(tid);6 __syncthread();78 float temp= s[tid];9 for(i=0; i< 16; i++) {10 temp= temp-s[i]*s[i];11   s[tid] = temp; }12 s[tid] = temp/ c;13 __syncthread();(a) Unmodified(b) Post-Compilation(c) GEVO Optimized14

Jhe-Yu Liou, Xiaodong Wang, Stephanie Forrest, and Carole-Jean Wu

kernel execution time. We conjecture that such optimization opportunities, although not completely
generalizable, are well-suited for GPUs. This is because GPUs implement more relaxed memory
models. General-purpose programs are inherently more sequential and might be less likely to
benefit from GPU offloading. If strict ordering between memory operations needs to be enforced,
threadfence or syncthread could be inserted.

5.2 Application-specific optimizations
GEVO discovers optimizations related to the particular application. We highlight four such opti-
mizations next.

5.2.1 Removing conditional execution. GEVO removes dead code that does not affect program
output. In the case of GPGPUs, GEVO could eliminate code blocks in the conditional path entirely if
the input space does not touch that portion of the kernel. Such kernel variants have been identified
for workloads such as hot, lud and pf.

5.2.2 Removing redundant load. In bfs, GEVO removed certain load instructions from a loop
which repeatedly loaded data from the same address. In this case, the compiler inserts these load
instructions to guarantee the latest updates to the particular memory address will be loaded back
correctly in different iterations of the loop. Programmers can avoid these redundant loads if they
declare the corresponding variable using a constant modifier, indicating that the variable is read-
only for the entire program execution. In this case, GEVO discoverd the data characteristics and
addressed the inefficiency without the programmer’s involvement.

Loop perforation. Loop perforation is an optimization technique that skips iterations of a loop
5.2.3
based on the skip factor and has been explored for approximate computing [95]. GEVO discovers
similar optimizations, for example, when loops have been unrolled heavily post-compilation. GEVO
then removes some part(s) of the unrolled loop while optimizing the fitness function. We observed
this behavior in sc, lud, and hot.

5.2.4 Memoization. Memoization is an optimization technique that stores results of expensive
function calls and returns the stored value without re-computation when the same inputs occur
again. At the LLVM-IR level, GEVO sometimes identifies similar memoization opportunities by
eliminating unneeded instructions and using stored results directly. We find this optimization in the
HotSpot temperature modeling tool (hot). A kernel in the HotSpot tool performs pre-processing
based on the physical dimension of a processor chip. Since the shape of simulated chips is the same
across all loop iterations, GEVO discovers memoization opportunities to reuse the preprocessing
results of the x-dimension for the y-dimension. Another extreme case was found in b+tree, where
one of the input arguments to the program already represents the desired indices in the program
output. Thus, GEVO omit almost the entire kernel, leading to more than 5 times performance
speedup.

In summary, we have identified several categories of performance improvements found by GEVO,
but we have not studied all such optimizations, and in some cases, we require additional domain-
specific knowledge to complete a full analysis. Because GEVO is stochastic, it is not guaranteed to
find every possible optimization on every run.

6 EVALUATION OF GEVO-MO
In this section, we evaluate GEVO (GEVO-mO) in settings where exact output fidelity is not required.
First we consider GEVO-mO running the Rodinia benchmarks and compare its performance to
GEVO-default. We then consider ML workloads and report how GEVO-mo can extract significant

Under Review of ACM TACO

GEVO: GPU Code Optimization using Evolutionary Computation

15

Fig. 9. Comparison of normalized performance im-
provement between GEVO-default and GEVO-mO
in the Rodinia Benchmark.

Fig. 10. Temporal evolution of a hot kernel variant.

performance improvement when domain-specific metrics (model prediction error) are included
and co-optimized.

6.1 Rodinia benchmarks with error tolerance
Figure 9 reports overall performance improvement from GEVO-default and GEVO-mO. When ac-
cepting up to 1% kernel output difference, GEVO-mO scavenges additional improvements, reducing
run-time by an average of 51.08% over the baseline. This is mainly achieved by the additional
performance improvement in hot and lud, from 27.3% to 38% and from 17% to 26.5% respectively.

6.1.1 Temporal Analysis. To better understand how GEVO-mO co-optimizes runtime and output
error, we consider one run of GEVO in closer detail for the program hot, as shown in Figure 10.
On each generation, the figure plots runtime (primary y-axis) and error rate (minor y-axis) for
the most fit kernel variant in that generation. As expected, runtime decreases over the run, but
the corresponding error rate increases at Generations 5 and 34. This illustrates the design space
tradeoff between performance and accuracy. In both cases, GEVO-mO then "repairs" the error
rate by introducing other mutations, a phenomenon known as compensatory evolution [99] in
evolutionary biology.

There are three key mutations in the last generation. When combined, they reduce the error
rate to less than 0.1%, whereas if individually applied, the error rate is much higher at 0.3%. This
highlights the strength of a population-based search method like GEVO—sub-optimal individuals
in one generation can be combined and/or serve as a stepping stones to the discovery of successful
combinations of mutations. Further, the best kernel variant would not be found if a tighter error
bound had been enforced from the beginning.

6.1.2 Optimization analysis. For hot and lud, mutation analysis reveals how additional improve-
ments are achieved.

hot: Additional performance improvement is achieved by removing additional synchronization
primitives. This optimization raises the possibility of a race condition, because the outputs vary
slightly from run to run but always remain under the 1% threshold. Although race conditions are a
potential concern, earlier work proposes lock-free approaches for specific algorithms and includes
a proof that the algorithm can converge even with a race condition [81].

Our analysis of the hot optimization provided two possible explanations for how removing
the synchronizations leaves a viable program. First, in hot, each thread updates the temperature
of a spot in a 2-dimension grid, based on the ambient temperature and the temperature of the
surrounding spots. Synchronization on each time step allows every other thread to calculate and

Under Review of ACM TACO

b+tnwscbfshotludpfpathsv2hwcfdgaunnAvgRodiniabenchmark1.01.21.41.61.82.0PerformanceImprovement5.12GEVO-defaultGEVO-mO(1%)16

Jhe-Yu Liou, Xiaodong Wang, Stephanie Forrest, and Carole-Jean Wu

Fig. 11. Pareto-frontiers and other kernel variant measurements for (a) the handwriting recognition (SVM
with MNIST) and (b) the income prediction (SVM with a9a).

update its temperature based on up-to-date temperature values nearby. However, there are two
levels of synchronization in hot: in-kernel synchronization using the syncthreads function and
a global synchronization when the kernel is relaunched. Removing the syncthreads call inside
the kernel implies that the temperature over the grid will be synchronized only every other time
step, which might leave the simulation within its error tolerance. The second explanation derives
from the simulation setting. In hot, the temperature difference between the ambient and initial
grid temperature (ambient is set to 80°K while the grid is mostly between 320°K and 345°K) is much
larger than the difference between a given spot and its neighbors (usually within 10°K). As a result,
the ambient temperature contributes more than surrounding temperature to the thermal simulation.
This effect mitigates the effect of the inaccuracy introduced by removing the synchronization.

lud: GEVO finds performance improvement by reusing the result from an earlier iteration of
a loop and avoiding computation in the latter iteration because the loop has been unrolled by
the compiler. This optimization is an example of memoization introduced in the previous section.
lud, standing for Lower-Upper decomposition decomposes a given matrix into a product of two
triangular matrices where each one has the lower/upper part of matrix filled with zeroes. Although
it might seem unacceptable to tolerate any error in the solution of a linear system, a method known
as incomplete LU factorization [68] approximates the solution of LU decomposition for lower
computational cost. We suspect that GEVO accidentally re-discovered this technique for improving
lud’s performance, providing a nice example of approximate computing.

In other Rodinia benchmarks, GEVO failed to find significant improvements when output fidelity
was relaxed. Although we don’t know why these applications were more challenging, there are
several possibilities, including the most obvious one that the 1% error tolerance based only on
the raw kernel output from the GPU is too constrained to allow appreciable expansion of the
optimization search space. Therefore, in the next section, we change the error definition from GPU
kernel output difference to application-defined error. For ML, the natural application error is model
prediction error. This change allows GEVO to find application-specific optimizations that produce
significantly different kernel output while maintaining model accuracy.

6.2 Evaluation of Machine Learning Applications (Dataset-specific optimizations)
Machine learning (ML) is a popular class of intrinsically error-tolerant applications, which consume
large computational resources, and is particularly suitable for the GEVO approach. We consider two
ML models, SVM and ResNet18, and use them to illustrate how performance and accuracy can be
co-optimized. Although earlier work examined accuracy/runtime tradeoffs of implementations [39],
we are unaware of earlier work targeting genetic improvement of ML LLVM-IR kernels.

Under Review of ACM TACO

(a) Handwriting recognition -mnist(b) Income prediction -a9a1.522.533.512345678910Prediction Error (%)Runtime (s)Pareto fontierKernel VariantsUnmodified1515.51616.5012345678Prediction Error (%)Runtime (s)Pareto fontierKernel VariantsUnmodifiedGEVO: GPU Code Optimization using Evolutionary Computation

17

SVM. Figure 11 shows the Pareto frontiers found by GEVO for handwriting recognition
6.2.1
(SVM with MNIST) and income prediction (SVM with a9a). The x-axis represents the measured
kernel runtime and the y-axis represents the training inference prediction error in %. We report
results for each kernel variant in GEVO’s final generation, relative to the original unmodified
kernel. Figure 11 also shows how GEVO-mO navigates away from the original, sub-optimal, kernel
implementation and explores the better performing part of the search space.

Considering the kernel variant in the Pareto
frontier that represents the best combined im-
provement, we find that GEVO-mO achieves
3.24X improvement for handwriting recogni-
tion (MNIST) and 2.93X performance improve-
ment for income prediction (a9a)’s kernel per-
formance, which increases overall model train-
ing speed by 50% and 24.8% respectively. At
the same time, accuracy on the training set
improved from 97.86% to 98.03% (MNIST) and
from 84.61% to 84.65% (a9a), which was unex-
pected as we imagined the optimization would
tradeoff accuracy against training time. Next,
we tested the trained GEVO-optimized models
on their official testing datasets, where we find
accuracy is improved slightly, from 98.37% to
98.5% (MNIST) and from 84.59% to 84.64% (a9a).
We also consider whether the SVM evolved

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

...
while (1)

// select f Up
if ( is_I_up (...) )

f_val_reduce [ tid ] = f;
up_val = f_val_reduce [...];

// select f Low
if ( is_I_low (...) )

// f_val_reduce [ tid ] = -f ;
f_val_reduce [ tid ] = 1 - f;
down_val = f_val_reduce [...];

if ( up_val - down_val < epsilon )

break ;

Fig. 12. Code snippet from ThunderSVM illustrates an
optimization discovered by GEVO. The comment at
line 10 is the original code and line 11 indicates the
GEVO modification.

for training a specific dataset can achieve similar improvements on a different dataset in the
same class (after all, that would be the main advantage of optimizing the training procedure for a
particular type of application). We tested SVM optimized for the MNIST common dataset (60,000
samples) by using it to train the large MNIST dataset (8,000,000 handwriting samples). Since the
large MNIST dataset does not have a separate testing dataset, we report the 10-fold cross validation
accuracy for the model from unmodified and optimized ThunderSVM, which are 100% and 99.997%
with the respective training time in 1182 and 121 minutes.

Our optimization analysis, shown in Figure 12, shows how GEVO changes the termination
condition of a while loop, by increasing the lower bound by 1 in line 11. As a result, there is a
chance of producing a smaller value in the if statement in line 14, causing the execution to exit
the while loop sooner. This loop implements a SVM solver using sequential minimal optimization,
which iteratively approaches the optimal solution, terminating when progress has slowed. Thus,
GEVO relaxes the convergence condition, which would normally be expected to reduce solution
correctness. However, for MINST, this change actually improves model accuracy, perhaps by
avoiding overfitting. We leave further analysis of this surprising result for future work.

6.2.2 ResNet18. Similar to SVM, figure 13(a) presents the Pareto-frontier for image classification
(ResNet18 with CIFAR-10). Here we select the kernel variant that gives the best training accuracy
on the third epoch (56% compared to 47% in the Baseline). This variant is also 1.79X faster than
original kernel. However, the kernel contributes less than 1% of the entire training time. Recall that
we do not have access to the other kernels for ResNet18 operators (Section 4.2).

Recalling that we train ResNet18 for only three epochs during GEVO’s optimization searches
and only on the momentumSGD kernel, we first examine the kernel performance throughout the
training process until the point where model accuracy has converged. Figures 13(b) and 13(c) report

Under Review of ACM TACO

18

Jhe-Yu Liou, Xiaodong Wang, Stephanie Forrest, and Carole-Jean Wu

Fig. 13. (a) Pareto-frontiers for the image classification (ResNet18 with CIFAR-10). The kernel in the circle is
manually selected to retrain the model until model converges, with its (b) training accuracy and (c) testing
accuracy across epochs.

2

1

/*

N = number of parameter

training and testing accuracy across epochs for the original baseline kernel and a GEVO-optimized
variant. Considering training accuracy, the GEVO-optimized kernel consistently beats the baseline
across epochs by up to 7% until epoch 30, when both kernels achieve 100% training accuracy. The
sudden jump in training accuracy around epoch 30 is caused by a learning rate change in epoch 29,
which occurs in code that is not available to GEVO. If we ignore that external learning rate change,
the GEVO-optimized kernel would converge at epoch 25, and the baseline would converge at epoch
28, with 2% lower training accuracy. Turning to testing accuracy, both kernels have comparable
accuracy through epoch 30 when the learning rate is changed. After epoch 30, the baseline is 1%
more accurate than the variant (73.24% to 72.31%).
Figure 14 shows an important code opti-
mization found by GEVO in the Caffe2 mo-
mentumSGD operator. There are two modifica-
tions leading to the accuracy and performance
improvements. First, GEVO changes the loop
boundary so the loop is executed only once
(line 7 in Figure 14). The momentumSGD ker-
nel updates the parameters (weight and bias)
of the neural network and the loop here rep-
resents how many parameters need to be up-
dated. Thus, GEVO’s success when reducing
the number of loop iterations suggests that
the ResNet18 model is overly complicated for
the CIFAR-10 dataset. This is similar to weight
pruning [71] or hyperparameter search [14] for
a particular dataset. GEVO also changes how
the momentum is calculated by using only the
current gradient and not considering the prior gradient. This optimization illustrates how GEVO
can tailor an algorithm to a particular dataset.

* m[i] = momentum
* g[i] = gradient
* BETA = momentum decay rate
*
*/

Fig. 14. Code snippet from Caffe2 momentumSGD
operator illustrates two optimization discovered by
GEVO.

float mi = m[i ];
float mi_new = BETA * mi + LR *g[i ];
m[i] = mi_new LR *g[i] ;
g[i] = (1+ BETA )* mi_new - BETA * mi ;

for (i= tid ; i <N; i += GRID_SIZE N) {

LR = learning rate

param [i] -= g[i ];

if ( param )

15

12

10

14

11

13

}

9

7

8

6

5

3

4

7 DISCUSSION
This paper presents GEVO, a new method that uses stochastic population-based search to discover
optimizations of GPGPU kernels. GEVO trades off absolute program semantics for other important

Under Review of ACM TACO

3040506070809010033040Accuracy (%)EpochBaselineGEVO-ResNet18(b) Training accuracy(c) Testing accuracy4045505560650.10.20.3Error Rate in Epoch 3 (%)Runtime (s)Pareto frontierUnmodified(a) All kernel variant3040506070809010033040Accuracy (%)EpochBaselineGEVO-ResNet18GEVO-ResNet18GEVO: GPU Code Optimization using Evolutionary Computation

19

non-functional design aspects. The experimental results demonstrate that by relaxing program
semantics, GEVO can find novel and substantial improvements, both for runtime alone, and for
the case of multiple optimization objectives, e.g., accuracy and runtime. The proposed approach,
while not intended for applications with critical correctness requirements (e.g., inner loops of
avionics software or some systems programs), is suitable for many other applications, including
the important class of ML codes. When we consider handwriting recognition, income prediction,
and image recognition ML workloads, our results show that GEVO explores the optimization
search space and finds multiple points along the Pareto frontier that maximize trade offs between
performance and accuracy. In some cases, however, GEVO can “have the best of both worlds" by
finding a significant 3.24x speedup of the handwriting recognition kernel (SVM with MNIST and
achieve modest improvements of prediction accuracy. This translates to 50% training time reduction
with 0.17% improvement on the prediction accuracy, reflecting absolute improvements in both
dimensions.

By design, GEVO does not aspire to preserve exact program semantics, and in many cases, it
can identify algorithmic improvements that are inaccessible to methods that require complete
semantic consistency with the original program. In other circumstances, however, GEVO could
potentially find optimizations that break required semantic properties which are not enforced
by the test suite. Optimizations that relax memory synchronization requirements provide a good
example. In the cases we examined, eliminating redundant synchronizations did not affect program
behavior. However, this strategy is risky in general because it depends on specific memory access
patterns, which in turn rely on the combined effect of the target application and its execution
environment (hardware architecture and system software). There is currently a great deal of
research interest in studying how memory accessing order can be relaxed for better performance.
This includes application-specific approaches, e.g., to schedule and prioritize memory access for
specific tasks [4, 74] and system-level approaches such as non-blocking or wait-free synchronization
with system or architecture support [23, 111]. GEVO could potentially be applied to identify these
optimization spots for researchers to further analyze when necessary.

More generally, as we learn more about when and how GEVO succeeds and fails, we foresee
new methods for post-hoc validation of evolved codes, e.g., by synthesizing new test cases on the
fly to test synchronization, or ultimately, using program analysis methods to highlight semantic
differences between original and evolved kernels [19].

We have also explored the idea of enhancing the proposed design by considering system-specific
architecture features. Cache efficiencies concern the performance of GPUs. Thus, we extended the
scope of GEVO to explore the performance optimization space of the GPU cache configuration. In
this case, we enabled GEVO to control cache bypassing by introducing ld.cg (for caching at the
L2 cache but bypassing the L1 cache) and ld.ca (for caching at both the L1 and L2 caches) to the
genetic operations. By doing so, the mutation operation can specify whether data are bypassed from
the GPU L1 cache at the granularity of instructions in the NVIDIA PTX ISA (By injecting inline-
assembly in LLVM-IR) and discover performance speedup opportunities, similar to on-demand
cache fetching [40] or cache bypassing optimization [7, 56]. Overall, this mutation operator did not
produce frequent enough performance improvements to justify adding it to GEVO’s mutation suite.
It seems that GEVO often finds equivalent optimizations without explicitly using the cache-specific
mutation, simply by moving load instructions.

The results reported here are specific to the programs, inputs, and the particular GEVO runs we
studied. There were some programs for which GEVO was unable to find improvement. Thus, further
experimentation is required to understand the generality of our results. GEVO found application-
specific, architecture-specific, and dataset-specific optimizations. In future work, we plan to test
GEVO on other applications and analyze more carefully why some programs admit significant

Under Review of ACM TACO

20

Jhe-Yu Liou, Xiaodong Wang, Stephanie Forrest, and Carole-Jean Wu

improvements and others do not. Since GEVO’s approach is agnostic about optimization criteria,
it is easy to imagine other compelling optimizations. For example, GEVO could customize the
LLVM-IR for particular classes of inputs, or even generate diverse versions of the kernel, each of
which uses a different power budget, to defeat some power side channel attacks.

GEVO itself has many possible parameter settings, including population size, mutation and
crossover rates, and there are many existing evolutionary algorithms with different strategies for
selection and multi-objective function optimization. We began with the most popular multi-objective
framework (DEAP), modified it for our application, and conducted several initial experiments to
find a configuration that works well for GPGPU optimization. However, it is certainly possible that
other evolutionary algorithms or other parameter settings for GEVO would produce better results.
Similarly, we chose a 1% error tolerance arbitrarily for the GEVO-mO experiments. Acceptable
errors may vary across programs, and in some cases, could translate into improved optimizations.
An example can be found in Yazdanbakhsh’s work [113] where srad from the Rodinia benchmark
could accept up to 10% error, with additional optimizations being revealed. Increasing GEVO’s error
tolerance to 10% for applications such as this could lead to additional optimizations.

Our mutation operators are more expensive than those used in earlier work on genetic improve-
ment of software. The additional cost arises from the nature of the single static assignment discipline
in the LLVM-IR. As a result, as Table 1 shows, GEVO searches for a very low number of generations
on many of the benchmarks. A general rule-of-thumb would suggest running the EC search for at
least as many generations as there are individuals in the population (250 in our experimental setup).
With additional computational resources, we could expect much better performance improvements,
especially on the benchmarks that ran for fewer than thirty generations.

It is well-known that significant human expertise is required to tune a ML model to extract the
best performance on a particular task. For instance, in SVM, the regularization parameter known
as C is manually determined to balance the generalization and the training error (underfitting
versus overfitting). Similarly, in neural networks human expertise and experimentation is used
to find an appropriate network architecture, which determines how many neurons are used and
how they are connected. Currently, these design decisions are determined empirically for each
dataset, and often tested repeatedly. Automating these design decisions, commonly referred as
hyperparameter search [14] or AutoML [100], to reduce human effort is a current research direction,
and many algorithms have been proposed, including simple grid search [50], random search [14],
reinforcement learning [12, 116], evolutionary computation [98], and gradient decent [61]. These
hyperparameter search algorithms differ from GEVO in that they do not touch the underlying code
implementation. The results presented here show that GEVO can discover effects that are similar
to those found with hyperparameter search, at the same time that it improves the implementation
itself. This suggests that GEVO is capable of performing hyperparameter search along with network
optimizations. We plan to conduct additional experiments expanding the work described here, with
the MLPerf Training and Inference Benchmark Suites [66, 67, 82].

8 CONCLUSION
Programmers today develop software that is expected to meet functional correctness, to avoid
opening up new security vulnerabilities, and to execute efficiently. The software is often developed
on complex programming stacks, is compiled to run on complex proprietary architectures which
lack transparency, and it often has unanticipated interactions with runtime environments and
workloads. This paper presents one approach to managing this complexity, focusing on code
optimization for GPUs. GPUs are an appealing target because they are widely used to accelerate
compute-intensive applications and because GPU codes are often error-tolerant and amenable

Under Review of ACM TACO

GEVO: GPU Code Optimization using Evolutionary Computation

21

to approximate optimization methods that do not guarantee exact semantic equivalence to the
original program.

Our approach, implemented as GEVO, uses population-based stochastic search on LLVM-IR GPU
programs. GEVO finds versions of programs that retain required functionality, as assessed by test
cases, and optimize one or more fitness criteria. We focus on the dual objectives of minimizing
runtime and application error, finding significant reductions in runtime for most programs with little
or no penalty in output error. GEVO finds optimizations that leverage details about the architecture,
the application design, and even particular workloads. For large-scale computation-intensive
applications such as ML, we hope that the methods presented here can contribute to improved
software deployments. We also hope that some of the unusual optimization opportunities identified
by GEVO will lead to improved software development practices, whether through improved tools
or through improved awareness on the part of application developers.

ACKNOWLEDGMENTS
We thank F. Esponda, W. Weimer, E. Schulte, and the reviewers for many insights, code and helpful
comments. This work is supported in part by the National Science Foundation under CCF-1618039
SHF-1652132, NSF CCF 1908633; DARPA FA8750-19C-0003, and AFRL FA8750-19-1-0501.

REFERENCES

[1] 2018. XLA is a compiler that optimizes TensorFlow computations. https://www.tensorflow.org/xla/.
[2] 2020. AMD Exascale Supercomputer. https://www.amd.com/en/products/exascale-era.
[3] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, et al. 2016. TensorFlow: A System for Large-scale Machine Learning.

In Proc. of the 12th USENIX Conf. on Operating Systems Design and Implementation.

[4] D. Alistarh, J. Kopinsky, J. Li, and N. Shavit. 2015. The spraylist: A scalable relaxed priority queue. In ACM SIGPLAN

Notices.

[5] J. A. Anderson, C. D. Lorenz, and A. Travesset. 2008. General purpose molecular dynamics simulations fully

implemented on graphics processing units. Journal of computational physics 227, 10 (2008), 5342–5359.

[6] A. Arunkumar, E. Bolotin, B. Cho, U. Milic, E. Ebrahimi, et al. 2017. MCM-GPU: Multi-chip-module GPUs for continued

performance scalability. ACM SIGARCH Computer Architecture News (2017).

[7] A. Arunkumar, S.-Y. Lee, and C.-J. Wu. 2016. ID-cache: instruction and memory divergence based cache management

for GPUs. In 2016 IEEE Intl. Symp. on Workload Characterization (IISWC).

[8] S. Baluja and R. Caruana. 1995. Removing the genetics from the standard genetic algorithm. In Machine Learning

Proc. Elsevier.

[9] S. Bansal and A. Aiken. 2006. Automatic generation of peephole superoptimizers. ACM SIGARCH Computer Architecture

News (2006).

[10] M. Batty, K. Memarian, K. Nienhuis, J. Pichon-Pharabod, and P. Sewell. 2015. The problem of programming language

concurrency semantics. In European Symp. on Programming Languages and Systems.

[11] B. Baudry, S. Allier, M. Rodriguez-Cancio, and M. Monperrus. 2015. Automatic software diversity in the light of test

suites. arXiv preprint arXiv:1509.00144 (2015).

[12] I. Bello, H. Pham, Q. V. Le, M. Norouzi, and S. Bengio. 2016. Neural combinatorial optimization with reinforcement

learning. arXiv preprint arXiv:1611.09940 (2016).

[13] G. Bender, P.-J. Kindermans, B. Zoph, V. Vasudevan, and Q. Le. 2018. Understanding and simplifying one-shot

architecture search. In Intl. Conf. on Machine Learning.

[14] J. Bergstra and Y. Bengio. 2012. Random search for hyper-parameter optimization. Journal of Machine Learning

Research 13, Feb (2012), 281–305.

[15] B. R. Bruce, J. Petke, and M. Harman. 2015. Reducing Energy Consumption Using Genetic Improvement. In Proc. of

the 17th Annual Conf. on Genetic and Evolutionary Computation.

[16] B. R. Bruce, J. Petke, M. Harman, and E. T. Barr. 2018. Approximate oracles and synergy in software energy search

spaces. IEEE Transactions on Software Engineering (2018).

[17] F. J. Burkowski. 1999. Shuffle crossover and mutual information. In Proc. of the 1999 Congress on Evolutionary

Computation-CEC99.

[18] N. Burles, E. Bowles, A. E. Brownlee, Z. A. Kocsis, J. Swan, and N. Veerapen. 2015. Object-oriented genetic improvement
for improved energy consumption in Google Guava. In Proc. of Intl. Symp. on Search Based Software Engineering.

Under Review of ACM TACO

22

Jhe-Yu Liou, Xiaodong Wang, Stephanie Forrest, and Carole-Jean Wu

[19] P. Cashin, C. Martinez, S. Forrest, and W. Weimer. To be appeared. Understanding Automatically-Generated Patches
Through Symbolic Invariant Differences. In Proc. of the 34rd ACM/IEEE Intl. Conf. on Automated Software Engineering.
[20] C.-C. Chang and C.-J. Lin. 2011. LIBSVM: A Library for Support Vector Machines. ACM Trans. Intell. Syst. Technol.

(2011).

[21] T. Chen, M. Li, Y. Li, M. Lin, N. Wang, et al. 2015. Mxnet: A flexible and efficient machine learning library for

heterogeneous distributed systems. arXiv preprint arXiv:1512.01274 (2015).

[22] T. Chen, T. Moreau, Z. Jiang, L. Zheng, E. Yan, et al. 2018. TVM: An Automated End-to-End Optimizing Compiler for

Deep Learning. In Proc. of 13th {USENIX} Symp. on Operating Systems Design and Implementation.

[23] J. Chung, L. Yen, S. Diestelhorst, M. Pohlack, M. Hohmuth, et al. 2010. ASF: AMD64 extension for lock-free data
structures and transactional memory. In Proc. of the 2010 43rd Annual IEEE/ACM Intl. Symp. on Microarchitecture. IEEE
Computer Society.

[24] B. Churchill, R. Sharma, J. Bastien, and A. Aiken. 2017. Sound Loop Superoptimization for Google Native Client.

SIGARCH Comput. Archit. News (2017).

[25] F.-M. De Rainville, F.-A. Fortin, M.-A. Gardner, M. Parizeau, and C. Gagné. 2012. DEAP: A Python Framework for
Evolutionary Algorithms. In Proc. of the 14th Annual Conf. Companion on Genetic and Evolutionary Computation.
[26] K. Deb, S. Agrawal, A. Pratap, and T. Meyarivan. 2002. A fast and elitist multiobjective genetic algorithm: NSGA-II.

IEEE Transactions on Evolutionary Computation (2002).

[27] V. Debroy and W. E. Wong. 2010. Using Mutation to Automatically Suggest Fixes for Faulty Programs. In Proc. of 3rd

Intl. Conf. on Software Testing, Verification and Validation.

[28] I. S. Dhillon and D. S. Modha. 2002. A data-clustering algorithm on distributed memory multiprocessors. In Large-scale

parallel data mining. Springer, 245–260.

[29] J. Dorn, J. Lacomis, W. Weimer, and S. Forrest. 2017. Automatically Exploring Tradeoffs Between Software Output

Fidelity and Energy Costs. ACM Transactions on Software Engineering (2017), to appear.

[30] Facebook. 2018. Finding and Fixing Software Bugs Automatically With Sapfix and Sapienz. https://code.fb.com/

developer-tools/finding-and-fixing-software-bugs-automatically-with-sapfix-and-sapienz/.

[31] Facebook. 2019. Caffe2. https://caffe2.ai/.
[32] S. Forrest, T. Nguyen, W. Weimer, and C. Le Goues. 2009. A Genetic Programming Approach to Automated Software

Repair. In Proc. of the 11th Annual Conf. on Genetic and Evolutionary Computation.

[33] C. L. Goues, T. Nguyen, S. Forrest, and W. Weimer. 2012. GenProg: A Generic Method for Automatic Software Repair.

IEEE Transactions on Software Engineering (2012).

[34] S. Gulwani, S. Jha, A. Tiwari, and R. Venkatesan. 2011. Synthesis of loop-free programs. ACM SIGPLAN Notices (2011).
[35] A. Haj-Ali, Q. Huang, W. Moses, J. Xiang, J. Wawrzynek, et al. 2020. AutoPhase: Juggling HLS Phase Orderings in
Random Forests with Deep Reinforcement Learning. In 3rd Conf. on Machine Learning and Systems (ML-Sys).
[36] S. O. Haraldsson, J. R. Woodward, Alexander, E. Brownlee, A. V. Smith, and V. Gudnason. 2017. Genetic improvement of
runtime and its fitness landscape in a bioinformatics application. In Proc. of the Genetic and Evolutionary Computation
Conf. Companion.

[37] S. O. Haraldsson, J. R. Woodward, A. E. I. Brownlee, and K. Siggeirsdottir. 2017. Fixing Bugs in Your Sleep: How
Genetic Improvement Became an Overnight Success. In Proc. of the Genetic and Evolutionary Computation Conf.
Companion.

[38] K. Hazelwood, S. Bird, D. Brooks, S. Chintala, U. Diril, et al. 2018. Applied Machine Learning at Facebook: A Datacenter

Infrastructure Perspective. In Proc. of IEEE Intl. Symp. on High Performance Computer Architecture.

[39] J. Huang, V. Rathod, C. Sun, M. Zhu, A. Korattikara, et al. 2017. Speed/accuracy trade-offs for modern convolutional

object detectors. In Proc. of the IEEE Conf. on computer vision and pattern recognition.

[40] W. Jia, K. A. Shaw, and M. Martonosi. 2012. Characterizing and Improving the Use of Demand-Fetched Caches in

GPUs. In Proc. of the 26th ACM Intl. Conf. on Supercomputing (ICS âĂŹ12).

[41] Z. Jia, O. Padon, J. Thomas, T. Warszawski, M. Zaharia, and A. Aiken. 2019. TASO: Optimizing Deep Learning
Computation with Automatic Generation of Graph Substitutions. In Proc. of the 27th ACM Symp. on Operating Systems
Principles (SOSP âĂŹ19).

[42] D. Judd, P. K. McKinley, and A. K. Jain. 1998. Large-scale parallel data clustering. IEEE Transactions on Pattern Analysis

and Machine Intelligence 20, 8 (1998), 871–876.

[43] K. Kandasamy, W. Neiswanger, J. Schneider, B. Poczos, and E. P. Xing. 2018. Neural architecture search with bayesian

optimisation and optimal transport. In Advances in Neural Information Processing Systems.
[44] A. Krizhevsky. 2009. Learning multiple layers of features from tiny images. Technical Report.
[45] A. Krizhevsky, I. Sutskever, and G. E. Hinton. 2012. Imagenet classification with deep convolutional neural networks.

In Advances in neural information processing systems. 1097–1105.

[46] W. B. Langdon and M. Harman. 2010. Evolving a CUDA kernel from an nVidia template. In Proc. of IEEE Congress on

Evolutionary Computation.

Under Review of ACM TACO

GEVO: GPU Code Optimization using Evolutionary Computation

23

[47] W. B. Langdon and M. Harman. 2014. Genetically Improved CUDA C++ Software. In Proc. of 17th European Conf. on

Genetic Programming.

[48] W. B. Langdon and M. Harman. 2015. Grow and Graft a Better CUDA pknotsRG for RNA Pseudoknot Free Energy
Calculation. In Proc. of the Companion Publication of the 17th Annual Conf. on Genetic and Evolutionary Computation.
[49] W. B. Langdon, B. Y. H. Lam, J. Petke, and M. Harman. 2015. Improving CUDA DNA Analysis Software with Genetic

Programming. In Proc. of the 17th Annual Conf. on Genetic and Evolutionary Computation.

[50] H. Larochelle, D. Erhan, A. Courville, J. Bergstra, and Y. Bengio. 2007. An Empirical Evaluation of Deep Architectures

on Problems with Many Factors of Variation. In Proc. of the 24th Intl. Conf. on Machine Learning.

[51] Y. Le Cun, L. Bottou, Y. Bengio, and P. Haffner. 1998. Gradient-based learning applied to document recognition. Proc.

of the IEEE (1998).

[52] C. Le Goues, M. Dewey-Vogt, S. Forrest, and W. Weimer. 2012. A Systematic Study of Automated Program Repair:

Fixing 55 out of 105 Bugs for $8 Each. In Proc. of the 34th Int. Conf. on Software Engineering.

[53] C. Le Goues, T. Nguyen, S. Forrest, and W. Weimer. 2012. GenProg: A Generic Method for Automated Software Repair.

Transactions on Software Engineering (2012).

[54] H. Leather, E. Bonilla, and M. O’Boyle. 2009. Automatic feature generation for machine learning based optimizing

compilation. In 2009 Intl. Symp. on Code Generation and Optimization. 81–91.

[55] C.-Y. Lee and E. K. Antonsson. 2000. Variable Length Genomes for Evolutionary Algorithms. In Proc. of 2nd Annual

Conf. on the Genetic and Evolutionary Computation Conf.

[56] S.-Y. Lee and C.-J. Wu. 2016. Ctrl-C: Instruction-aware control loop based adaptive cache bypassing for GPUs. In 2016

IEEE 34th Intl. Conf. on Computer Design (ICCD).

[57] J.-Y. Liou, S. Forrest, and C.-J. Wu. 2019. Genetic Improvement of GPU Code. In Proc. of the 6th Intl. Workshop on

Genetic Improvement (GI âĂŹ19).

[58] J.-Y. Liou, S. Forrest, and C.-J. Wu. 2019. Uncovering Performance Opportunities by Relaxing Program Semantics
of GPGPU Kernels. Wild and Crazy Idea session at the 24th Intl. Conf. on Architectural Support for Programming
Languages and Operating Systems.

[59] C. Liu, B. Zoph, M. Neumann, J. Shlens, W. Hua, et al. 2018. Progressive neural architecture search. In Proc. of the

European Conf. on Computer Vision (ECCV).

[60] H. Liu, K. Simonyan, O. Vinyals, C. Fernando, and K. Kavukcuoglu. 2017. Hierarchical representations for efficient

architecture search. arXiv preprint arXiv:1711.00436 (2017).

[61] H. Liu, K. Simonyan, and Y. Yang. 2018. Darts: Differentiable architecture search. arXiv preprint arXiv:1806.09055

(2018).

[62] Z. Liu, J. Li, Z. Shen, G. Huang, S. Yan, and C. Zhang. 2017. Learning efficient convolutional networks through

network slimming. In Proc. of the IEEE Intl. Conf. on Computer Vision.

[63] L. Madeyski, W. Orzeszyna, R. Torkar, and M. Jozala. 2014. Overcoming the Equivalent Mutant Problem: A Systematic
Literature Review and a Comparative Experiment of Second Order Mutation. IEEE Transactions on Software Engineering
(2014).

[64] I. Manotas, L. Pollock, and J. Clause. 2014. SEEDS: a software engineer’s energy-optimization decision support

framework. In Proc. of the 36th Intl. Conf. on Software Engineering.

[65] H. Massalin. 1987. Superoptimizer: A Look at the Smallest Program. In Proc. of the 2nd Intl. Conf. on Architectual

Support for Programming Languages and Operating Systems.

[66] P. Mattson, C. Cheng, C. Coleman, G. Diamos, P. Micikevicius, et al. 2019. MLPerf Training Benchmark. arXiv preprint

arXiv:1910.01500 (2019).

[67] P. Mattson, V. J. Reddi, C. Cheng, C. Coleman, G. Diamos, et al. 2020. MLPerf: An industry standard benchmark suite

for machine learning performance. IEEE Micro (2020).

[68] J. A. Meijerink and H. A. Van Der Vorst. 1977. An iterative solution method for linear systems of which the coefficient

matrix is a symmetric M-matrix. Mathematics of computation (1977).

[69] C. Mendis, C. Yang, Y. Pu, S. Amarasinghe, and M. Carbin. 2019. Compiler Auto-Vectorization with Imitation Learning.

In Advances in Neural Information Processing Systems. 14598–14609.

[70] B. L. Miller, D. E. Goldberg, and others. 1995. Genetic algorithms, tournament selection, and the effects of noise.

Complex systems (1995).

[71] P. Molchanov, S. Tyree, T. Karras, T. Aila, and J. Kautz. 2016. Pruning Convolutional Neural Networks for Resource

Efficient Inference. In Proc. of Intl. Conf. on Learning Representations.

[72] D. J. Montana and L. Davis. 1989. Training Feedforward Neural Networks Using Genetic Algorithms.. In IJCAI.
[73] L. D. Moura and N. BjÃÿrner. 2008. Z3: an efficient SMT solver. In Proc. of the Theory and practice of software, 14th

intl. Conf. on Tools and algorithms for the construction and analysis of systems.

[74] D. Nguyen, A. Lenharth, and K. Pingali. 2013. A lightweight infrastructure for graph analytics. In Proc. of the

Twenty-Fourth ACM Symp. on Operating Systems Principles. ACM, 456–471.

Under Review of ACM TACO

24

Jhe-Yu Liou, Xiaodong Wang, Stephanie Forrest, and Carole-Jean Wu

[75] A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, et al. 2017. Automatic differentiation in PyTorch. (2017).
[76] K. Pettis and R. C. Hansen. 1990. Profile guided code positioning. In Proc. of the ACM SIGPLAN Conf. on Programming

language design and implementation.

[77] H. Pham, M. Y. Guan, B. Zoph, Q. V. Le, and J. Dean. 2018. Efficient neural architecture search via parameter sharing.

arXiv preprint arXiv:1802.03268 (2018).

[78] J. C. Platt. 1999. Advances in Kernel Methods. Chapter Fast Training of Support Vector Machines Using Sequential

Minimal Optimization.

[79] E. Real, A. Aggarwal, Y. Huang, and Q. V. Le. 2019. Regularized evolution for image classifier architecture search. In

Proc. of the AAAI Conf. on Artificial Intelligence, Vol. 33. 4780–4789.

[80] E. Real, S. Moore, A. Selle, S. Saxena, Y. L. Suematsu, et al. 2017. Large-scale evolution of image classifiers. In Proc. of

the 34th Intl. Conf. on Machine Learning-Volume 70. JMLR. org.

[81] B. Recht, C. Re, S. Wright, and F. Niu. 2011. Hogwild: A lock-free approach to parallelizing stochastic gradient descent.

In Advances in neural information processing systems.

[82] V. J. Reddi, C. Cheng, D. Kanter, P. Mattson, G. Schmuelling, et al. 2019. MLPerf Inference Benchmark. arXiv preprint

arXiv:1911.02549 (2019).

[83] N. Rotem, J. Fix, S. Abdulrasool, S. Deng, R. Dzhabarov, et al. 2018. Glow: Graph Lowering Compiler Techniques for

Neural Networks. arXiv preprint arXiv:1805.00907 (2018).

[84] S. Ryoo, C. I. Rodrigues, S. S. Baghsorkhi, S. S. Stone, D. B. Kirk, and W.-m. W. Hwu. 2008. Optimization principles
and application performance evaluation of a multithreaded GPU using CUDA. In Proc. of the 13th ACM SIGPLAN
Symp. on Principles and practice of parallel programming. 73–82.

[85] D. Saad. 1998. Online algorithms and stochastic approximations. Online Learning 5 (1998), 6–3.
[86] E. Schkufza, R. Sharma, and A. Aiken. 2013. Stochastic superoptimization. In Proc. of ACM SIGARCH Computer

Architecture News.

[87] E. Schkufza, R. Sharma, and A. Aiken. 2014. Stochastic optimization of floating-point programs with tunable precision.

ACM SIGPLAN Notices (2014).

[88] E. Schulte. 2014. Neutral Networks of Real-World Programs and their Application to Automated Software Evolution.

Ph.D. Dissertation. University of New Mexico, Albuquerque, USA.

[89] E. Schulte, J. DiLorenzo, S. Forrest, and W. Weimer. 2013. Automated Repair of Binary and Assembly Programs
for Cooperating Embedded Devices. In Proc. of Intl. Conf. on Architectural Support for Programming Languages and
Operating Systems.

[90] E. Schulte, J. Dorn, S. Harding, S. Forrest, and W. Weimer. 2014. Post-compiler Software Optimization for Reducing

Energy. In Proc. of the 19th Intl. Conf. on Architectural Support for Programming Languages and Operating Systems.

[91] E. Schulte, Z. P. Fry, E. Fast, W. Weimer, and S. Forrest. 2014. Software Mutational Robustness. Genetic Programming

and Evolvable Machines (2014).

[92] E. M. Schulte, W. Weimer, and S. Forrest. 2015. Repairing COTS Router Firmware without Access to Source Code or
Test Suites: A Case Study in Evolutionary Software Repair. In Proc. of the 1st Genetic Improvement Workshop.
[93] M. J. Schulte, M. Ignatowski, G. H. Loh, B. M. Beckmann, W. C. Brantley, et al. 2015. Achieving exascale capabilities

through heterogeneous computing. IEEE Micro (2015).

[94] R. Sharma, E. Schkufza, B. Churchill, and A. Aiken. 2015. Conditionally Correct Superoptimization. In Proc. of ACM

SIGPLAN Intl. Conf. on Object-Oriented Programming, Systems, Languages, and Applications.

[95] S. Sidiroglou-Douskos, S. Misailovic, H. Hoffmann, and M. Rinard. 2011. Managing Performance vs. Accuracy
Trade-offs with Loop Perforation. In Proc. of the 19th ACM SIGSOFT Symp. and the 13th European Conf. on Foundations
of Software Engineering.

[96] P. Sitthi-Amorn, N. Modly, W. Weimer, and J. Lawrence. 2011. Genetic Programming for Shader Simplification. In

Proc. of the 2011 SIGGRAPH Asia Conf.

[97] K. O. Stanley, D. B. D’Ambrosio, and J. Gauci. 2009. A hypercube-based encoding for evolving large-scale neural

networks. Artificial life (2009).

[98] K. O. Stanley and R. Miikkulainen. 2002. Evolving Neural Networks through Augmenting Topologies. Evolutionary

Computation 10, 2 (2002), 99–127.

[99] W. Stephan. 1996. The Rate of Compensatory Evolution. Genetics (1996), 419–426.
[100] C. Thornton, F. Hutter, H. H. Hoos, and K. Leyton-Brown. 2013. Auto-WEKA: Combined Selection and Hyperparameter
Optimization of Classification Algorithms. In Proc. of the 19th ACM SIGKDD Intl. Conf. on Knowledge Discovery and
Data Mining (KDD ’13).

[101] E. Torlak and R. Bodik. 2013. Growing Solver-Aided Languages with Rosette. In Proc. of the 2013 ACM Intl. Symp. on

New Ideas, New Paradigms, and Reflections on Programming and Software (Onward! 2013).

[102] E. Torlak and R. Bodik. 2014. A Lightweight Symbolic Virtual Machine for Solver-Aided Host Languages. In Proc. of

the 35th ACM SIGPLAN Conf. on Programming Language Design and Implementation (PLDI âĂŹ14).

Under Review of ACM TACO

GEVO: GPU Code Optimization using Evolutionary Computation

25

[103] L. Van Put, D. Chanet, B. De Bus, B. De Sutter, and K. De Bosschere. 2005. Diablo: a reliable, retargetable and extensible
link-time rewriting framework. In Proc. of the 5th IEEE Intl. Symp. on Signal Processing and Information Technology.
[104] N. Veerapen, F. Daolio, and G. Ochoa. 2017. Modelling genetic improvement landscapes with local optima networks.

In Proc. of the Genetic and Evolutionary Computation Conf. Companion.

[105] P. Verbancsics and K. O. Stanley. 2011. Constraining connectivity to encourage modularity in HyperNEAT. In Proc. of

the 13th annual Conf. on Genetic and evolutionary computation. ACM.

[106] L. Wang, J. Tao, M. Kunze, A. C. Castellanos, D. Kramer, and W. Karl. 2008. Scientific cloud computing: Early definition
and experience. In 2008 10th ieee Intl. Conf. on high performance computing and communications. Ieee, 825–830.
[107] W. Weimer, T. Nguyen, C. Le Goues, and S. Forrest. 2009. Automatically Finding Patches Using Genetic Programming.

In Proc. of the 31st Intl. Conf. on Software Engineering.

[108] Z. Wen, J. Shi, Q. Li, B. He, and J. Chen. 2018. ThunderSVM: A Fast SVM Library on GPUs and CPUs. Journal of

Machine Learning Research (2018).

[109] D. R. White, A. Arcuri, and J. A. Clark. 2011. Evolutionary Improvement of Programs. IEEE Transactions on Evolutionary

Computation (2011).

[110] J. Wu, A. Belevich, E. Bendersky, M. Heffernan, C. Leary, et al. 2016. Gpucc: An Open-source GPGPU Compiler. In

Proc. of the 2016 Intl. Symp. on Code Generation and Optimization (CGO ’16).

[111] S. Xiao and W.-c. Feng. 2010. Inter-block GPU communication via fast barrier synchronization. In 2010 IEEE Intl.

Symp. on Parallel & Distributed Processing (IPDPS). IEEE.

[112] L. Xie and A. Yuille. 2017. Genetic cnn. In Proc. of the IEEE Intl. Conf. on Computer Vision.
[113] A. Yazdanbakhsh, D. Mahajan, H. Esmaeilzadeh, and P. Lotfi-Kamran. 2016. AxBench: A multiplatform benchmark

suite for approximate computing. IEEE Design & Test (2016).

[114] J. Yin, Z. Lin, O. Kayiran, M. Poremba, M. S. B. Altaf, et al. 2018. Modular routing design for chiplet-based systems. In

2018 ACM/IEEE 45th Annual Intl. Symp. on Computer Architecture (ISCA).

[115] S. Zhang, A. E. Choromanska, and Y. LeCun. 2015. Deep learning with elastic averaging SGD. In Advances in neural

information processing systems. 685–693.

[116] B. Zoph and Q. V. Le. 2016. Neural architecture search with reinforcement learning. arXiv preprint arXiv:1611.01578

(2016).

[117] B. Zoph, V. Vasudevan, J. Shlens, and Q. V. Le. 2018. Learning transferable architectures for scalable image recognition.

In Proc. of the IEEE Conf. on computer vision and pattern recognition.

Under Review of ACM TACO

