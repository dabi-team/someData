Accepted in Int. Conf. on High Perf. Computing and Simulation (HPCS - WEHA)
https://ieeexplore.ieee.org/document/9188188

Towards Co-execution on Commodity Heterogeneous
Systems: Optimizations for Time-Constrained
Scenarios

Raúl Nozal, Jose Luis Bosque and Ramón Beivide
Computer Science and Electronics Department, Universidad de Cantabria, Spain
{raul.nozal,joseluis.bosque,ramon.beivide}@unican.es

0
2
0
2

t
c
O
3
2

]

C
D
.
s
c
[

1
v
7
0
6
2
1
.
0
1
0
2
:
v
i
X
r
a

Abstract—Heterogeneous systems are present from
powerful supercomputers, to mobile devices, including
desktop computers, thanks to their excellent perfor-
mance and energy consumption. The ubiquity of these
architectures in both desktop systems and medium-
sized service servers allow enough variability to exploit
a wide range of problems, such as multimedia work-
loads, video encoding, image ﬁltering and inference
in machine learning. Due to the heterogeneity, some
eﬀorts have been done to reduce the programming
eﬀort and preserve performance portability, but these
systems include a set of challenges. The context in
which applications oﬄoad the workload along with
the management overheads introduced when doing
co-execution, penalize the performance gains under
time-constrained scenarios. Therefore, this paper pro-
poses optimizations for the EngineCL runtime to re-
duce the penalization when co-executing in commodity
systems, as well as algorithmic improvements when
load balancing. An exhaustive experimental evaluation
is performed, showing optimization improvements of
7.5% and 17.4% for binary and ROI-based oﬄoading
modes, respectively. Thanks to all the optimizations,
the new load balancing algorithm is always the most
eﬃcient scheduling conﬁguration, achieving an average
eﬃciency of 0.84 under a pessimistic scenario.

Index Terms—Heterogeneous Computing, Co-
execution, Commodity Systems, OpenCL, Load
Balancing, CPU, GPU, Scheduling.

I. Introduction

Heterogeneous systems made up of a general purpose
CPU and a set of hardware accelerators are increasingly
present in a great number of compute devices. Thus, we
can ﬁnd them from powerful computing nodes in great
supercomputers, to mobile devices, including in this range
commodity computers. Desktop computers usually have
an integrated heterogeneous systems, composed of CPU
cores, together with GPU compute units in a single chip.
Along with them, it is common to ﬁnd discrete GPUs.

The ubiquity of these devices allows enough variability
of heterogeneous systems that, together with their archi-
tectures, make it easier to exploit a wide range of prob-
lems, such as multimedia workloads, video encoding, image
ﬁltering and inference in machine learning. The availability
of these systems in both commodity infrastructures and
medium-sized service servers facilitate a new ﬁeld of work,

but involves great challenges. The scenario in which these
oﬄoading functions are launched is determined by execu-
tions of hundreds of milliseconds, sometimes a few seconds,
where every management operation or the minimum over-
head completely penalizes the oﬄoading to devices.

In addition, these functions are usually carried out in
two operating modes. On the one hand, integrated in a
main program, directly consuming the data and making
only the transfer and computation through the use of other
technologies such as OpenMP or OpenCL. This function
is executed in parallel while the main program continues
operating, such as the server managing requests or the
GUI rendering charts. On the other hand, by launching
this function as a process independently to the main
program, serializing and exchanging the data and results.
it is important to take into account the
context in which the applications are executed, as it has
been done in other cases with devices such as FPGAs [2],
knowing that we are facing the worst possible scenario to
do co-execution. Furthermore, it is necessary to exploit
techniques and optimizations to allow an eﬃcient execu-
tion that takes advantage of all the available resources.

Therefore,

A key aspect of maximizing the performance of such
systems is co-execution. That is, all devices in the system
cooperate to execute a single massively data-parallel task,
improving its response time. The co-execution allows to
extract the maximum performance of the system, as well
as to optimize its energetic consumption, since all the de-
vices contribute useful work to solve the problem, instead
of remaining idle. However, the programming models cur-
rently used do not have adequate support for co-execution.
For instance, OpenCL [7] provides low abstraction level
that forces the programmer to know the system in detail
and manually do a set of operations, such as managing
the host-device communication or explicitly partitioning
the data among the devices.

To solve these problems and provide eﬀortless co-
execution it is necessary to overcome two important chal-
lenges: abstraction and load balancing. Abstraction means
that the programmer should always work in the same
way, regardless of the system in which his application is
executed. Therefore, all system-dependent tasks should be
hidden from him. Load balancing refers to a distribution of

 
 
 
 
 
 
work proportional to the computational capacity of each
of the devices. Thus, everyone should ﬁnish their work
approximately at the same time, avoiding that none of
them remain idle but consuming energy.

To overcome these problems this paper improves some
features of EngineCL [1] to desktop systems, composed by
a multi-core CPU, an integrated GPU and a middle-range
discrete GPU. EngineCL is an OpenCL-based C++ run-
time API that signiﬁcantly improves the usability of the
heterogeneous systems without any loss of performance.
It acts as a wrapper to facilitate the programming while
providing ﬂexibility and a system to evaluate scheduling
algorithms. It accomplishes complex operations transpar-
ently for the programmer, such as discovery of platforms
and devices, data management, load balancing and robust-
ness throughout a set of eﬃcient techniques. Following the
Host-Device programming model, the runtime manages a
single data-parallel kernel among all the devices in the
heterogeneous system.

Two types of optimizations have been researched:
runtime-centered to allow using load balancing under more
problem sizes, competing against the fastest device in
the system, and algorithmically, proposing a new algo-
rithm and tuning its parameters to boost the average
eﬃciency in a wide range of program types. The run-
time improvements have decreased the management and
synchronization overheads due to initialization and buﬀer
optimizations, increasing the general eﬃciency in 7.5% and
17.4% for binary and ROI-based oﬄoading modes. Finally,
thanks to the new proposals, when using all the devices in
the system to solve a problem, the performance is greatly
improved, increasing around 3% on average with respect
to the default HGuided algorithm, yielding an eﬃciency
of 0.84 and a balance eﬀectiveness of 0.97.

The main contributions of this paper are the following:

• New EngineCL optimizations are proposed to miti-
gate the overhead of the initialization and ﬁnalization
stages, as well as buﬀer management, caused during
the co-execution by the use of OpenCL drivers in
commodity computers.

• An exhaustive

experimental

the
HGuided algorithm, searching for the best tuning of
its parameters to optimize its performance in desktop
systems.

evaluation of

The rest of this paper is organized as follows. Section
II describe the design and implementation of EngineCL,
along with the new HGuided algorithm. The proposed
optimizations are explained in Section III. The method-
ology used for the validation is explained in Section IV,
while the experimental results are shown in Section V.
Finally, Section VI explains similar works while Section
VII, the most important conclusions and future work are
presented.

II. EngineCL Overview

A. Principles of Design and Implementation

EngineCL is designed with many principles in mind, all
around three pillars: OpenCL, Usability and Performance.
It is tightly coupled to OpenCL and how it works. The
system modules and their relationships have been deﬁned
according to the most eﬃcient and stable patterns. Every
design decision has been benchmarked and proﬁled to
achieve the most optimal solution in every of its parts,
but mainly promoting the modules related with the data
management, synchronization and API abstraction.

EngineCL is designed to achieve high external usability
and internal adaptability to support new runtime features
when the performance is not penalized.

Fig. 1. EngineCL Tiers and modules.

While OpenCL allows code portability on diﬀerent types
of devices, the programmer is responsible for managing
many concepts related to the architecture, such as plat-
forms, contexts, buﬀers, queues or data transfers. When
the number of devices, operations and data management
processes increases, the code grows quickly with OpenCL,
decreasing the productivity and increasing the maintain-
ability eﬀort. EngineCL solves these issues by providing a
runtime with a higher-level API that eﬃciently manages
all the OpenCL resources of the system.

EngineCL redeﬁnes the concept of program to facilitate
its usage and the understanding of a kernel execution.
Because a program is associated with the application
domain, it has data inputs and outputs, a kernel and an
output pattern. It is designed to support massive data-
parallel kernels, but thanks to the program abstraction the
runtime will be able to orchestrate multi-kernel executions,
prefetching of data inputs, optimal data transfer distribu-
tion, iterative kernels and track kernel dependencies and
act accordingly. Therefore, the architecture of the runtime
is not constrained to a single program.

The runtime follows Architectural Principles with well-
known Design Patterns to strengthen the ﬂexibility in the
face of changes, as can be seen in Figure 1. Tier-1 and
Tier-2 are accessible by the programmer. The lower the

HGuidedHGuidedHGuidedTier, the more functionalities and advanced features can
be manipulated. Most programs can be implemented in
EngineCL with just the Tier-1, by using the EngineCL
and Program classes. The Tier-2 should be accessed if the
programmer wants to select a speciﬁc Device and provide a
specialized kernel, use the Conﬁgurator to obtain statistics
and optimize the internal behavior of the runtime or set
options for the Scheduler. Tier-3 contains the hidden inner
parts of the runtime that allows a ﬂexible system regarding
memory management, pluggable schedulers, work distri-
bution, high concurrency and OpenCL encapsulation.

B. HGuided

The architecture allows to easily incorporate a set of
schedulers, as it is shown in Figure 1. Three well-known
load balancing algorithms, Static, Dynamic and HGuided,
are implemented in EngineCL [3] [14].

Static and Dynamic strategies have their strong points
and their weak spots. The HGuided algorithm is an at-
tempt to reduce the synchronization points of the Dynamic
while retaining most of its adaptiveness.

HGuided oﬀers a variation over the Dynamic algorithm
by establishing how the data-set is divided. The algorithm
makes larger packages at the beginning and reduces the
size of the subsequent ones as the execution progresses.
Thus, the number of synchronization points and the cor-
responding overhead is reduced, while retaining a small
package granularity towards the end of the execution to
allow all devices to ﬁnish simultaneously.

Since it is an algorithm for heterogeneous systems the
size of the packets is also dependent on the computing
power of the devices. The size of the package for device i
is calculated as follows:

packet_sizei =

(cid:37)

(cid:36)

Gr Pi
ki n (cid:80)n

j=1 Pj

where ki
is an arbitrary constant. The smaller the k
constant, the faster decreases the packet size. Tweaking
this constant prevents too large packet sizes when there
are only a few devices, with cases such as giving half the
workload in the ﬁrst packet to a device, unbalancing the
load. Gr is the number of pending work-groups and is
updated with every package launch. The parameters of
the HGuided are the computing powers and the minimum
package size of the devices to be used. The minimum
package size is a lower bound for the packet_sizei and
the minimum package sizes are usually dependent on the
computing power of the devices, being bigger package sizes
in the most powerful devices.

HGuided is optimized by applying a combined tweaking
to both the k constant and the minimum package size,
inversely related. For each device, a pair of minimum
package size and ki constant is given. The former is a
multiplier of the local work size and it increases with more
powerful devices, while the latter decreases in such cases.

The ki, although related with the computing power of each
device, it is established with values between 1 and 4 to
avoid crossing the border penalties: neither too large nor
too small packages.

Fig. 2. Scheduling overview.

III. Optimizations of EngineCL

EngineCL has been developed in C++, mostly using
C++11 modern features to reduce the overhead and code
size introduced by providing a higher abstraction level.
When there is a trade-oﬀ between internal maintainabil-
ity of the runtime and a performance penalty seen by
proﬁling, it has been chosen an implementation with the
minimal overhead in performance.

EngineCL has a multi-threaded architecture that com-
bines the best measured techniques regarding OpenCL
management of queues, devices and buﬀers. Some of the
decisions involve atomic queues, paralleled operations, cus-
tom buﬀer implementations, reusability of costly OpenCL
functions, eﬃcient asynchronous enqueueing of operations
based on callbacks and event chaining. These mechanisms
are used internally by the runtime and hidden from the
programmer to achieve eﬃcient executions and transpar-
ent management of devices and data.

Figure 2 depicts a simpliﬁed view of the scheduling
and work distribution, while showing a key design in the
architecture: the low-level OpenCL API is encapsulated
within the concept of Device, managed by a thread.

Two design decisions have been aﬀected to support
optimizations that reduce overheads produced both in the
initialization and closing stages of the program, mainly
due to the use of OpenCL drivers for commodity infras-
tructures. These modiﬁcations are tagged as initialization
and buﬀer optimizations.

The ﬁrst optimization focuses on taking advantage of
the discovery, listing and initialization of platforms and
devices by the same thread (Runtime). In parallel, both
the thread in charge of load balancing (Scheduler) and the
threads associated with devices (Device) take advantage

of this time interval to start conﬁguring and preparing
their resources as part of the execution environment.
These threads will wait only if they have ﬁnished their
tasks independent of the OpenCL primitives, instantiated
by the Runtime. The runtime takes advantage of the
same discovery and initialization structures to conﬁgure
the devices before delegating them to the Scheduler and
Device threads, which will be able to continue with the
following stages. These optimizations reduce the execution
time aﬀecting the beginning and end of the program, due
to the increase of the parallel fraction of the program as
well as the reuse of the structures in memory, liberating
the redundant OpenCL primitives.

On the other hand, some modiﬁcations have been made
when instantiating and using both input and output
buﬀers (Buﬀer). The variety of architectures as well as the
importance of sharing memory strategies save costs when
doing transfers and unnecessary complete bulk copies of
memory regions, usually between main memory and device
memory, but also between reserved parts of the same
main memory (CPU - integrated GPU). By tweaking
OpenCL buﬀer ﬂags that set the direction and use of the
memory block with respect to the device and program,
OpenCL drivers are able, if possible, to apply underlying
optimizations to the memory management.

IV. Methodology

The experiments are carried in a machine composed of
an AMD A10-7850K APU and Nvidia GeForce GTX 950
GPU. The CPU has 2 cores and 2 threads per core at
3142 Mhz with only two cache levels, exposing 4 OpenCL
compute units. The APU’s on-chip GPU is a GCN 2.0
Kaveri R7 DDR3 with 512 cores at 720 Mhz with 8
compute units, denoted as iGPU from now on. Finally,
the Nvidia discrete GPU has 768 cores at 1240 Mhz with
GDDR5, providing 6 compute units, denoted as GPU.

Five benchmarks have been used to show a variety of
computations regarding the performance gains when mul-
tiple heterogeneous devices are co-executed. Table I shows
the properties of every benchmark. Gaussian, Binomial,
Mandelbrot and NBody are part of the AMD APP SDK,
while Ray, providing two diﬀerent scenes, is an open source
implementation of a Raytracer [4]. They provide enough
variety in terms of OpenCL development issues, regarding
many parameter types, local and global memory usage,
custom struts and types, number of buﬀers and arguments,
diﬀerent local work sizes and output patterns.

The performance evaluation of EngineCL is done by
analyzing the co-execution when using diﬀerent scheduling
conﬁgurations in a heterogeneous system composed of
three diﬀerent devices. Each program uses a single problem
size, given by the completion time of around 2 seconds in
the fastest device (GPU).

The scheduling conﬁgurations are grouped by algorithm.
The ﬁrst two bars represent the Static algorithm varying
the order of delivering the packages to the devices. The

TABLE I
Benchmarks and their variety of properties.

n
sia
s
u
a
G

128

2:1

1:1

6

no

no

mial

o

Bin

255

1:1

1:255

5

yes

no

y
d
o
B
N

64

2:2

1:1

7

no

no

y
a
R

128

1:1

1:1

11

yes

yes

t
o
r
elb
d
n
a
M

256

0:1

4:1

8

no

no

8192px

4194304

229376

4096px

14336px

Property

Local Work
Size
Read:Write
buﬀers

Out pattern

Kernel args

Use local
memory
Use custom
types

Size

Other params

31px

scene

5000

one labelled Static delivers the ﬁrst chunk to the CPU, the
second to the iGPU and the last one to the GPU, while
in the Static rev the order is GPU-iGPU-CPU. The next
three show the Dynamic scheduler conﬁgured to run with
64, 128 and 512 chunks. Finally, the latter two present the
HGuided algorithm and its new optimized version.

To guarantee integrity of the results, 50 executions are
performed per case. An initial execution is discarded for
every set of iterations to avoid warm-up penalties in some
OpenCL drivers and devices.

To evaluate the performance of the load balancing al-
gorithms the total response time is measured, including
kernel computing and buﬀer operations (reading and writ-
ing), but excluding program initialization and releasing.

Three metrics are used to evaluate the performance of

EngineCL: balance, speedup and eﬃciency.

To measure the eﬀectiveness of load balancing, we cal-
culate the balance as TF D
, where TF D and TLD are the
TLD
execution time of the device that ﬁnish at ﬁrst and last,
respectively. Thus, it is 1 if all ﬁnish at the same time.

For the latter two metrics, the baseline is always the
fastest device running a single invocation of the kernel
(GPU). Due to the heterogeneity of the system and the dif-
ferent behaviour of the benchmarks, the maximum achiev-
able speedups depend on each program. These values are
derived from the response time Ti of each device:

Smax =

1
maxn
i=1{Ti}

n
(cid:88)

i=1

Ti

Additionally, the eﬃciency of the heterogeneous system
has been computed as the ratio between the maximum
achievable speedup and the empirically obtained speedup
for each benchmark. Ef f = Sreal
Smax

.

Fig. 3. Speedups (left) and Eﬃciency (right) for every scheduler and program compared with a single GPU.

V. Experimental Results

This section presents results of experiments carried out
to evaluate the performance when using all the devices in
the system with the load balancing algorithms, including
the new runtime and HGuided optimizations.

A. Performance Results

The performance results achieved in the heterogeneous
system with diﬀerent load balancing algorithms are shown
in Figure 3, where the speedups and eﬃciency are de-
picted. The abscissa axis contains the benchmarks deﬁned
in Section IV, each one with seven scheduling conﬁgura-
tions. The last group of bars shows the average (geometric
mean) per scheduler.

The ﬁgures reveal that, for all benchmarks, HGuided
achieves the best results. Classifying the programs as
regular (Gaussian, Binomial and Nbody) and irregular
(Ray and Mandelbrot), there is a tendency that shows how
the Static is better for the former, while the Dynamic for
the latter. In any case, the Static would be the second best
option, indicating the importance of taking into account
the computing power of each device in the heterogeneous
system, feature not present in the dynamic algorithm.
The results show how the dynamic is penalized when an
inappropriate number of packages is selected, as can be
seen with bigger package sizes in Binomial, Ray2 and
Mandelbrot, and smaller ones in NBody.

These overheads introduced by Dynamic are mostly
mitigated when using HGuided, being always better than
using the fastest device (GPU), with average eﬃciencies
of 0.81 and 0.84, when using the default and the new
optimized version, respectively. The previous version of
HGuided obtained the best speedups on average compared
with Static and Dynamic, except in NBody, where a Static
combination obtains the same performance. Due to the
optimizations applied, the results of the HGuided improve
3% for regular problems and 3.5% for the irregular ones,
being ahead of the rest scheduling conﬁgurations and
reaching eﬃciencies of up to 0.89 and 0.93 for Binomial
and Ray2, respectively.

Fig. 4. Balance for every scheduler compared with a single GPU.

Figure 4 depicts the balance metric obtained per sched-
uler, as it is deﬁned in Section IV, achieving near the
best balance when using HGuided, in all applications. This
is a consequence of the computation of smaller packages
at the end of the execution. For regular problems, the
balance is directly related with the performance of its
scheduling conﬁguration, but it is not completely fulﬁlled
for irregular ones, with cases like Mandelbrot. It has
higher performance in Static than in its reversed version,
but it suﬀers imbalance. These variations are produced
because a slow device (CPU) ﬁnishes working and no
more packages need to be computed, waiting for the other
devices, but ﬁnishing the total problem computation in
less time, because faster devices compute more work.

B. Optimizations Evaluation

Taking into consideration the global vision of the prob-
lem as well as the excellent results obtained with the new
proposal of the HGuided, it is necessary to emphasize the
optimization work performed at the algorithmic level as
well as in the runtime, as it was detailed in Section III.

The changes in the HGuided algorithm introduce
enough variability to obtain an explosion of combinations
in the search for the most optimal parameters, both in
average and maximum cases per problem. Figure 5 shows
how the performance is aﬀected by the combination of
pairs m, k, multiplier value to obtain the minimum pack-
age size and k constant, both for each device in the het-
erogeneous system. The Z axis sets the program execution
time for the problem size indicated in the Section IV. The
X and Y axes show the multiplier for minimum package

GaussianBinomialNBodyRay1Ray2Mandelbrotaverage0.00.20.40.60.81.01.21.4Speedup (gpu)staticstatic revdyn 64dyn 128dyn 512hguidedhguided optGaussianBinomialNBodyRay1Ray2Mandelbrotaverage0.00.20.40.60.81.0EfficiencyGaussianBinomialNBodyRay1Ray2Mandelbrotaverage0.00.20.40.60.81.0BalanceFig. 5. HGuided scheduler performance: m multiplier (minimum package size) and k constant parameter combination.

size and k constant for each device, respectively. The order
of the three values represent the CPU, iGPU and GPU.
For example, a Gaussian execution with the values k3, 3, 1
and m1, 15, 30 means that the HGuided has scheduled the
workload by distributing smaller packages to the CPU
and iGPU but larger to the GPU. This k variation aﬀects
the ﬁrst packages delivered. In addition, as packages are
distributed and their size decrease is when the minimum
package size limitation occurs. In this case, because of the
m selected values, the CPU is not limited, but the iGPU
and GPU minimum package sizes are 15 and 30 times
larger than the lws (128 in Gaussian), respectively.

For all the programs there is a correlation between the
m multipliers and k constants used, inversely related. The
charts show how the k constants have a greater impact
on performance than the minimum packet size, except
in NBody, where the limitation of the minimum package
size for the CPU is completely relevant to avoid syn-
chronization overheads. The more packages are created,
the more management needs to be performed, and both
Runtime and Scheduler units are CPU-managed (host
thread), incurring in more overheads when dealing with
transfers and computations. Although this eﬀect can be
appreciated in every application, in NBody it is even more
highlighted due to its communications.

Considering all programs, by classifying the results
based on the performance average, several conclusions can
be extracted to improve the general eﬃciency: a) the more

powerful the device, the greater the minimum package size;
b) the more powerful the device, the fewer the k constant;
c) there is not a perfect choice for every program, but the
combination of mi = {1, 15, 30} and ki = {3.5, 1.5, 1} give
the best results; d) if a single k constant should be selected
for every device, k = 2 is the best option; e) if the CPU is
involved in the computation and no previous proﬁling can
be performed, it should maintain m = 1 to avoid major
penalties in performance.

On the other hand, taking into account the runtime, two
tasks have been carried out: the initialization optimization
aﬀects the execution of the complete program (binary),
while the buﬀers optimization improves both binary and
based on the region of interest (ROI). The ROI discards
the initialization and release stages, considering only the
transfer and computation, where a minor management
overhead or synchronization call highly penalizes the gen-
eral performance.

Figure 6 depicts the evolution of the execution time
as the problem size increases for each program, as well
as the trade-oﬀ between single or multi-device execution.
The abscissa axis represents the problem size expressed as
total work items (gws). The green (top) and blue (bottom)
lines show how the execution time increases as the size
of the problem grows, for binary and ROI, respectively.
Every vertical line represents a inﬂection point when it
crosses the previous continuous lines associated with its
execution type, indicating when it is worthwhile to balance

m multipliers30,30,11,15,301,30,11,30,301,1,3030,30,301,1,130,1,1k constants3.5,1.5,13,1.5,13,3,13,2,13.5,2,12,3,12.5,2.5,11.5,1.5,1.53,3,32,2,22.5,2.5,2.51,1,12,1,1Time (s)1.971.982.002.012.032.042.062.072.092.10Gaussianm multipliers1,1,11,30,301,30,11,15,301,1,3030,30,3030,1,130,30,1k constants3,2,13,1.5,13,3,12.5,2.5,13.5,1.5,12,3,13.5,2,12.5,2.5,2.52,2,21.5,1.5,1.53,3,32,1,11,1,1Time (s)2.362.382.402.422.442.462.482.502.522.54Binomialm multipliers1,30,301,1,301,15,301,30,11,1,130,30,3030,30,130,1,1k constants3,1.5,13,2,13.5,2,11,1,12,1,13.5,1.5,11.5,1.5,1.52.5,2.5,13,3,12,3,12,2,22.5,2.5,2.53,3,3Time (s)1.911.962.012.062.112.162.212.262.312.36NBodym multipliers1,30,301,30,11,1,11,15,301,1,3030,30,3030,30,130,1,1k constants3.5,1.5,13.5,2,13,1.5,13,2,13,3,12.5,2.5,12,3,12.5,2.5,2.51.5,1.5,1.53,3,32,2,22,1,11,1,1Time (s)2.302.332.362.382.412.442.472.502.522.55Raym multipliers1,30,301,1,11,1,301,30,11,15,3030,30,130,1,130,30,30k constants3,1.5,13.5,1.5,13.5,2,12,1,11,1,13,2,12.5,2.5,13,3,13,3,32,3,12.5,2.5,2.52,2,21.5,1.5,1.5Time (s)2.022.032.042.062.072.092.102.112.132.14MandelbrotFig. 6. HGuided execution time per problem size (global work size units) when launching the binary and only the region of interest (transfer
and compute). Vertical lines cross the inﬂection point when load balancing is better than executing in the fastest device (GPU) and how
the runtime optimizations aﬀect this trade-oﬀ.

the load with HGuided than execute only in the fastest
device (GPU). The dotted lines show the previous version,
while the dashed lines the new optimized one.

Analyzing the results in detail, all programs show a
similar increasing linear trend in their ﬁrst seconds of
execution, except NBody, which grows exponentially. The
diﬀerence between executions is practically a constant
value, due to the amount of common operations during
initialization and end of execution, although inﬂuenced by
the type of kernel (compilation and arguments conﬁgura-
tion) but also the amount and size of buﬀers involved.

The initialization optimization has a strong impact on
its constant, saving 131 milliseconds on average when
reusing OpenCL primitives and the conﬁguration stages
are highly parallelized until they are limited by their own
dependencies (Buﬀer, Context, Queue, etc). On the other
hand, buﬀers optimization aﬀects both execution modes,
but has a greater impact on ROI, as it aﬀects transfers.
Devices that share the same main memory can reuse
the buﬀers without penalty. Nevertheless, its impact is
minimal for such small problem sizes, since the transfers
are practically negligible compared to the rest operations.
The inﬂection points improve, on average and taking
into account the two types of execution, 7.5% when op-
timizing the initialization and 17.4% when facilitating
the recognition of buﬀers types and avoiding unnecessary
copies. These two optimizations are fundamental consider-
ing the scenario in which these applications are evaluated.
Considering the experimental setup, a set of conclusions
can be indicated: a) the average time it is worthwhile
balancing the load has to exceed 15 milliseconds when
considering the region of interest, and 1.75 seconds when

executing the complete program; b) the bigger the problem
size, the better it performs load balancing, and therefore,
it excels over a single execution over the fastest device;
c) the amount of potential optimizations and time savings
that can be achieved in the runtime are limited by the
gains obtained by applying optimizations on the slowest
device and being executed alone (single mode).

In summary, we can conclude that both EngineCL and
its load balancing algorithms, thanks to the exhaustive
analysis and evaluation, support optimizations and ﬁne-
grained work focused on speciﬁc scenarios, signiﬁcantly
improving their results.

VI. Related Work

Similar eﬀorts have been performed to integrate a vari-
ety of devices to compute a single data-parallel kernel, but
the optimizations are focused at the device level by using
more complex and problem-speciﬁc architectures [8], [2].
Regarding the trade-oﬀ between usability and perfor-
mance, there are projects aiming at high-level parallel
programming in C++, but most of them provide an API
similar to the STL to ease the parallel programming, like
Boost.Compute [20], HPX [10], Thrust [11], SYCL [9] and
the C++ Extensions for Parallelism TS [12]. Thrust, tied
to CUDA devices, HPX, which extends C++ Parallelism
TS with future types for distributed computing, or C++
TS are not OpenCL-centered.

Projects like HPX.Compute [5] and SYCLParallelSTL
[15] provide backends for OpenCL via SYCL. SYCLParal-
lelSTL exposes ParallelSTL on CPU and GPU. Proposals
like SkelCL [19] and SkePU [6] provide data management
and skeletons to build parallel applications, but the pro-
grammer is responsible of using their own data containers.

010203040506070Problem size (gws, 1e6)0.000.250.500.751.001.251.501.752.00Time (s)GaussianBinaryBalance/GPU (opt)Balance/GPUROIBalance/GPU (opt)Balance/GPU020406080100Problem size (gws, 1e4)0.00.51.01.52.02.5Time (s)Binomial510152025Problem size (gws, 1e4)0.00.51.01.52.02.5Time (s)NBody0255075100125150175Problem size (gws, 1e5)0.00.51.01.52.0Time (s)Ray0255075100125150175200Problem size (gws, 1e6)0.00.51.01.52.0Time (s)MandelbrotWorks like VirtCL [16], MultiCL [17] and SOCL [18] do
address load balancing while abstracting the underlying
system and managing data movement. Nevertheless, their
focus is on task-parallelism instead of on the co-execution
of a single data-parallel kernel.

Also, there are C-programmed libraries with similar
objectives, but they provide low-level APIs where the
programmer needs to specify many parameters and the
density of the code is considerable. While Maat [14] uses
OpenCL to achieve the code portability, Multi-Controllers
[13] is CUDA and OpenMP-targeted.

On the other side, EngineCL is tightly coupled to
OpenCL, oﬀers a higher-level layered API with high us-
ability, and its approach is to provide constructs that oﬀer
greater abstraction of the data-parallel problem while it
has adaptiveness to diﬀerent scenarios.

VII. Conclusions and Future Work

Given the great relevance of heterogeneous systems in
all sectors of computing, it is necessary to provide the
community with tools that facilitate their programming
without performance overheads. EngineCL is an OpenCL-
based runtime that greatly simpliﬁes the programming
eﬀort while frees the programmer from tasks that require a
speciﬁc knowledge of the underlying architecture. Thanks
to its load balancing capabilities,
it can make use of
all the available resources in the system, reducing the
computation time.

This paper focuses on commodity systems and programs
with small execution times, where it is a challenge to make
co-execution cost-eﬀective due to runtime overheads and
the workload distribution. To overcome these diﬃculties
two diﬀerent approaches are researched. First, a number
of optimizations have been designed and implemented
on EngineCL that address the initialization and buﬀer
management. Second, an eﬀort has been made to optimize
the HGuided scheduler, provided in EngineCL. For this
purpose, an exhaustive experimental evaluation has been
carried out to tune the values of the parameters of this
algorithm under the worst-case scenario for load balancing.
A number of conclusions can be drawn from the experi-
mental results. Firstly, the proposed optimizations reduce
the execution time of a program by 7.5% and 17.4%
to make co-execution successful for the binary and ROI
operation modes, respectively. Regarding the HGuided
parameters, it can be concluded that the more powerful
the device, the larger the minimum packet size and the
lower the k parameter value should be. Thus, the best
result is always obtained if the minimum packet size is not
limited for the CPU, when being the less powerful device
in the system. Finally, thanks to all the optimizations, the
new load balancing algorithm is always the fastest and
most eﬃcient scheduling conﬁguration, yielding an average
eﬃciency of 0.84. Thus, opportunities to compete in time-
constrained scenarios against the fastest device increase.

In the future, it is intended to extend the EngineCL to
support iterative and multi-kernel executions, imitating
the ROI operation mode of real applications. Also, new
commodity architectures and load balancing algorithms
will be provided and studied, focusing on performance and
energy eﬃciency.

Acknowledgement

This work has been supported by the the Spanish
Ministry of Education (FPU16/ 03299 grant), the Spanish
Science and Technology Commission (TIN2016-76635-C2-
2-R), the European Union’s Horizon 2020 research and in-
novation programme and HiPEAC Network of Excellence
(Mont-Blanc project under grant 671697).

References

[1] Nozal, R. et al.: EngineCL: Usability and Performance in Het-
erogeneous Computing. arXiv (May 2018), https://arxiv.org/
abs/1805.02755 (Oﬃcial EngineCL repository https://github.
com/EngineCL/EngineCL)

[2] Guzmán, M.A. et al.: Cooperative CPU, GPU, and FPGA
heterogeneous execution with EngineCL. The Journal of Super-
computing (Mar 2019)

[3] Nozal, R. et al.: Load balancing in a heterogeneous world: CPU-
Xeon Phi co-execution of data-parallel kernels. The Journal of
Supercomputing (Mar 2018)

[4] AMD, Becker, M., Brown, C.: EngineCL Benchsuite. https://

github.com/EngineCL/Benchsuite

[5] Copik, M. et al.: Using SYCL As an Implementation Framework
for HPX.Compute. Proceedings of the 5th Int. Workshop on
OpenCL, IWOCL (2017)

[6] Enmyren, J. et al.: SkePU: A multi-backend skeleton program-
ming library for multi-gpu systems. Proc. 4th Int. Workshop on
High-Level Parallel Programming and Applications (2010)
[7] Gaster, B.R. et al. : Heterogeneous Computing with OpenCL -

Revised OpenCL 1.2 Edition, Morgan Kaufmann (2013)

[8] Guzman, M.A. et a.: Towards the inclusion of FPGAs on com-

modity heterogeneous systems. HPCS 2018. (July 2018)

[9] Group, T.K. et al.: SYCL: C++ Single-source Heterogeneous
Programming for OpenCL. SYCL 1.2.1 Speciﬁcation, accessed
on Feb 2018

[10] Heller, T. et al. : HPX – An open source C++ Standard Library
for Parallelism and Concurrency. Workshop on Open Source
Supercomputing (2017)

[11] Hoberock, J. et al.: Thrust: A Parallel Template Library for

C++ (2009)

[12] ISO/IEC: Technical Speciﬁcation for C++ Extensions for Par-

allelism (2015)

[13] Moreton-fernandez, A. et al. : Multi-Device Controllers : A
Library To Simplify The Parallel Heterogeneous Programming.
Int. J. of Parallel Programming (2017)

[14] Pérez, B. et al. : Simplifying programming and load balancing
of data parallel applications on heterogeneous systems. Proc. of
the 9th Workshop on General Purpose Processing using GPU
(2016)

[15] Ruyman Reyes et al.: SyclParallelSTL: Implementing Parallel-
STL using SYCL. Int. Workshop on OpenCL (2015), accessed
on Feb 2018

[16] Wang, G. et al.: Virtcl: A framework for OpenCL device ab-

straction and management. PPoPP 2015, ACM (2015)

[17] Aji, A.M. et al.: MultiCL: Enabling automatic scheduling for
task-parallel workloads in OpenCL. Parallel Comput. 58 (c), 37-
55 (2016)

[18] S. Henry et al.: Toward OpenCL automatic multi-device sup-
port. Euro-Par Parallel Processing, Springer, 2014, pp. 776-787
[19] Steuwer, M. et al.: SkelCL - A portable skeleton library for high-

level GPU programming. IEEE IPDPSW (2011)

[20] Szuppe, J.: Boost.compute: A parallel computing library for
C++ based on OpenCL. Int. Workshop on OpenCL (2016),
accessed on Feb 2018

