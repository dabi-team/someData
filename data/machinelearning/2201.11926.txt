2
2
0
2

n
a
J

8
2

]

C
O
.
h
t
a
m

[

1
v
6
2
9
1
1
.
1
0
2
2
:
v
i
X
r
a

Simplifying deﬂation for non-convex optimization
with applications in Bayesian inference and topology
optimization

Mohamed Tarek
Pumas-AI Inc., U.S.
The University of Sydney Business School, Australia
mohamed82008@gmail.com

Yijiang Huang
Department of Architecture, Massachusetts Institute of Technology, U.S.
yijiangh@mit.edu

Abstract

Non-convex optimization problems have multiple local optimal solutions. Non-
convex optimization problems are commonly found in numerous applications. One
of the methods recently proposed to efﬁciently explore multiple local optimal
solutions without random re-initialization relies on the concept of deﬂation. In this
paper, different ways to use deﬂation in non-convex optimization and nonlinear
system solving are discussed. A simple, general and novel deﬂation constraint is
proposed to enable the use of deﬂation together with existing nonlinear program-
ming solvers or nonlinear system solvers. The connection between the proposed
deﬂation constraint and a minimum distance constraint is presented. Additionally,
a number of variations of deﬂation constraints and their limitations are discussed.
Finally, a number of applications of the proposed methodology in the ﬁelds of
approximate Bayesian inference and topology optimization are presented.

1

Introduction

Non-convex optimization problems are used in numerous applications including: machine learning,
mechanical design, economics, and the design of clinical trials, among many other applications.
One of the fundamental challenges of non-convex optimization is the existence of multiple local
minimizers. Local ﬁrst and second order optimization algorithms often get stuck in a particular local
minimizer without any guarantees that this is the best solution that can be found. The ability to
explore multiple local minimizers is often important in practice to ﬁnd better solutions or to provide
more diverse choices to decision makers if all the choices are nearly equally good or the optimization
objectives cannot capture users’ preferences completely. For example, multiple car body designs can
be reported and the decision-makers can choose one based on the subjective aesthetic appeal.

Despite the popularity of using standard non-convex optimization techniques with various random
or heuristic restart strategies to ﬁnd multiple optima [Rinnooy Kan and Timmer, 1987, Kaelo and
Ali, 2006, Arnoud et al., 2019], these methods can be computationally inefﬁcient because they
don’t protect against converging to the same solution from different starting points. In contrast,
deﬂation-based methods [Papadopoulos et al., 2021] have the beneﬁt of provably converging to
distinct solutions under certain assumptions, even when starting from the same initial guess. However,
originally developed for solving nonlinear equation system [Brow and Gearhart, 1971, Farrell et al.,
2016], adapting deﬂation to non-convex optimization problems requires signiﬁcant adaptation of the

Preprint. Under review.

 
 
 
 
 
 
non-convex optimization algorithm [Papadopoulos et al., 2021], which prevents it from being used
with a broader class of problems, algorithms and applications.

In this paper, we propose a simple, yet effective and provably correct way of making use of deﬂation
by reformulating the non-convex optimization problem, instead of adapting the backend optimization
algorithm. We then prove the equivalence of this approach to a minimum distance constraint under
certain assumptions. The proposed approach has the beneﬁt of (1) being simpler to implement since
it’s a formulation change rather than an algorithmic change; (2) being more ﬂexible allowing the
use of arbitrary optimization algorithms that are suitable for the problem class at hand. We show a
number of examples from different applications, each using deﬂation together with the most suitable
and/or popular optimization algorithm for the respective application, which is not achievable by
previous deﬂation-based approaches.

One limitation of the proposed approach is that it requires the handling of a non-convex, inequality
constraint even if the original problem was unconstrained. However, one way to workaround this
limitation is demonstrated in the examples section.

2 Related work

Systematic multi-start. Systematically restarting the optimization multiple times from random or
deterministically diverse [McKay M. D., 1979, Kucherenko and Sytsko, 2005] initial solutions is
a common strategy to ﬁnd multiple local minimizers in non-convex optimization. Some popular
algorithms following this approach are the multi-level single-linkage (MLSL) algorithm [Rinnooy Kan
and Timmer, 1987], the controlled random search (CRS) [Kaelo and Ali, 2006] algorithm, and the
TikTak algorithm [Arnoud et al., 2019]. However, all the approaches above can be computationally
expensive and wasteful since restarting the optimization algorithm from a different initial solution
may not give a different local minimizer.

Divide and conquer Other similar algorithms rely on sub-dividing the search space into smaller
hyper-rectangles to narrow down the search space for each sub-problem. Algorithms in this category
include the StoGo algorithm [Gudmundsson, 1998, K. Madsen and Zilinskas, 1998] and the DIviding
RECTangles (DIRECT) algorithm [Jones et al., 1993, Gablonsky and Kelley, 2001]. However, these
approaches don’t scale well with the number of decision variables m since the number of ﬁxed size
hyper-rectangles one can divide an m dimensional solution space into grows exponentially with m.

Hyperparameter and bilevel optimization. Alternatively, techniques from hyper-parameter opti-
mization [Li et al., 2018, Falkner et al., 2018] or bilevel optimization [Sinha et al., 2018] can be used
to optimize the starting point of the lower level optimization algorithm. One can compose a global
search algorithm such as an evolutionary algorithm [Gendreau and Potvin, 2010] and a local search
algorithm together to create an algorithm that can explore different initial solutions and ﬁnd best local
minimizers in different neighbourhoods. This family of global-local algorithms is also sometimes
termed memetic algorithms [Moscato and Cotta, 2010].

Global metaheuristics. Beside their use in memetic algorithms, global metaheuristic optimization
algorithms [Gendreau and Potvin, 2010] can also be used as standalone algorithms but these algo-
rithms don’t tend to scale well to large problems since they usually don’t exploit the often available
gradients and sometimes Hessians of objective and constraint functions.

Tunneling-based multi-start. Tunneling [Levy and Gomez, 1981, Gomez and Levy, 1982, Barron
and Gomez, 1991, Gomez et al., 2003, Zhang and Norato, 2018] is another heuristic technique often
used to ﬁnd multiple local minimizers by ﬁnding a sufﬁciently different starting point with a similar
or better objective value as the best solution found so far. The optimization problem is then re-solved
starting from this new point hoping to converge to a different solution. However, this is a 2 step
approach consisting of ﬁrst solving the optimization problem and then ﬁnding a new, sufﬁciently
different initial point. And the success to ﬁnd distinct minimizers depends on the success to ﬁnd a
sufﬁciently different starting point.

Exact global optimization. Beside the use of restarts, there are also some well known exact global
optimization algorithms for some classes of non-convex optimization [Tawarmalani and Sahinidis,
2005, Sahinidis, 2017, Belotti et al., 2009, Vigerske and Gleixner, 2018, Wilhelm and Stuber,
2020, Nagarajan et al., 2019, 2016, Ratschek and Rokne, 2007, Gecode Team]. These approaches
however tend to require the explicit analytical mathematical expressions of the objective and constraint

2

functions so they are not suitable for black-box non-convex optimization, and they typically don’t scale
well to large problems in practice, where the exactness guarantee has an exponential computational
time complexity in the number of variables.

Deﬂation-based multi-start. Deﬂation is a recently proposed technique that employs Newton-like
methods to ﬁnd multiple solutions of a nonlinear systems of equations [Brow and Gearhart, 1971,
Farrell et al., 2016, 2020]. Assuming the underlying Newton-like algorithm converges, under certain
assumptions, a deﬂation-based solver is guaranteed to converge to a unique solution each time the
solver is started from the same initial solution. This has the promise of being much less wasteful
than multi-start optimization approaches. However, one problem with deﬂation is that often the
assumptions under which convergence to a different solution is guaranteed are not easy to verify in
practice. That said, the method was shown to perform well in practical applications.

Deﬂation was also used in a primal-dual interior point optimization algorithm [Wright, 1997] to ﬁnd
multiple locally optimal designs in mechanical design optimization problems [Papadopoulos et al.,
2021]. However, this deﬂated optimizer had to re-invent a primal-dual interior point optimization
algorithm [Wright, 1997] since off-the-shelf solvers such as the Interior Point OPTimizer (IPOPT)
[W¨achter and Biegler, 2006] could not be used directly for reasons to be presented in this work. Not
being able to use existing optimization solvers is a huge limitation of this approach since different
optimization algorithms tend to be more suitable for different problems and applications.

3 Background

3.1 Sufﬁcient optimality conditions for regular points

We aim to ﬁnd multiple solutions for the following nonlinear program (NLP):

f (x)

minimize
x ∈ Rn
subject to
c(x) = 0 ,
l ≤ x ≤ u

(1)

where l ∈ (−∞, ∞)n, u ∈ (−∞, ∞)n are the ﬁnite (for simplicity) lower and upper bounds of
the variable x. The objective function f : Rn −→ R and the equality constraints c : Rn −→ Rm,
with m ≤ n are assumed to be twice continuously differentiable. Problems with general nonlinear
inequality constraints d(x) ≤ 0 can be converted to equality constraints by adding slack variables.

Let:

L(x, λ, z+, z−) = f (x) + c(x)T λ+
(x − u)T z+ − (x − l)T z−

(2)

where λ ∈ Rm is the Lagrangian multiplier vector of the equality constraints, z− ∈ Rn
are the Lagrangian multiplier vectors of the bound constraints.

+, z+ ∈ Rn
+

If x is regular and is a local minimizer of the NLP, then ∃(λ, z+, z−) such that:

∇xL(x, λ, z+, z−) = 0
c(x) = 0
l ≤ x ≤ u
z+ ≥ 0
z− ≥ 0
(x − u)T z+ = 0
(x − l)T z− = 0

and

∇c(x)T ∇2

xxL(x, λ, z+, z−)∇c(x) (cid:60) 0

3

(3a)
(3b)
(3c)
(3d)
(3e)

(3f)

(3g)

(4)

Equations (3) and (4) are known as the ﬁrst and second order Karush-Kuhn-Tucker (KKT) sufﬁcient
conditions for optimality respectively. A point x that satisﬁes Equation (3) is typically called a KKT
point [Nocedal and Wright, 2006]. Finding multiple solutions of the NLP can be reduced to ﬁnding
solutions that satisfy Equation (3), while indirectly enforcing Equation (4) via following descent
directions.

3.2 Deﬂation

Deﬂation is a technique that systematically modiﬁes a nonlinear problem to guarantee that Newton’s
method will not converge to a known root, thus enabling unknown roots to be discovered from the
same initial guess [Farrell et al., 2016].

Deﬂation for nonlinear equation solving Farrell et al. [2016] proved that under certain conditions,
solving a system of n nonlinear equations:

F (x) = 0

starting from the same initial solution x0 can converge to multiple locally optimal solutions by
applying a deﬂation operator whenever a solution is found. Let the ﬁrst solution found be x1. The
deﬂation operator can then be deﬁned as:

M (x; x1) = m(x; x1)I
m(x; x1) = ||x − x1||−p + σ

for some power p and shift σ, where I is the n × n identity matrix. The deﬂated nonlinear system of
equations is given by:

M (x; x1)F (x) = 0

After solving the system once, one can solve the deﬂated system and obtain a new solution x2. One
of the assumptions required to prove the convergence of the proposed algorithm to a different solution
x2 is:

lim
x→x1

||M (x; x1)F (x)|| > 0

(6)

To deﬂate away from multiple found solutions, the original method proposes multiplying the operators
and solve (cid:81) ˜K
k=1 M (x; xk) F (x) = 0, where ˜K is the number of found solutions. To improve
numerical stability, summation instead of multiplication can also be used.

Deﬂation for NLP optimization To apply deﬂation to ﬁnding multiple solutions of NLP, one can
write most of Equation (3) as F (x, λ) = 0 (see the appendix for more details) and solve for different
solutions of the deﬂated system:

M (x; x1)F (x, λ) = 0

while ensuring a descent direction is taken at every step. However, solving this nonlinear system of
equations using Newton-like algorithms requires evaluating the Jacobian of the residual of the deﬂated
nonlinear system of equations. One of the most popular existing implementations of the primal-dual
interior point algorithm in IPOPT assumes the Jacobian of the top block of F to be symmetric (since
it’s the Hessian of the Lagrangian). This makes it difﬁcult to reuse IPOPT with deﬂation directly.
Arguably, this is also the main motivation for Papadopoulos et al. [2021] developing a specialized
primal-dual interior point algorithm from scratch for use with deﬂation. For more details on the
derivations relevant to this discussion see Appendix A.

4 Method

In this section, the use of deﬂation and the choice of the optimization algorithm to use will be
decoupled by making use of a deﬂation constraint that only requires a change in the formulation of
the optimization problem without specifying the algorithm.

4

4.1 Formulating deﬂation as a constraint

Instead of deﬂating the optimality conditions, one can create a new constraint and variable that
enforce the same deﬂation effect. Let y ≥ 0 be a new variable. One possible constraint to add is:
m(x; x1) = ||x − x1||−p + σ ≤ y
(7)
If after adding this constraint, the optimal solution x2 obtained has a ﬁnite y in exact arithmetic, then
x1 (cid:54)= x2 since limx→x1 m(x; x1) = ∞. One can further show that every KKT point of the new
NLP with a ﬁnite y is a KKT point of the original formulation.
Lemma 4.1. If (x∗, y∗) is a regular KKT point to the following NLP:

f (x)

minimize
x, y
subject to
c(x) = 0,
m(x; x1) ≤ y,
l ≤ x ≤ u

(8)

for a ﬁnite y∗, and m is bounded from below, then x∗ is a regular KKT point to problem 1 and
x∗ (cid:54)= x1.

Proof. Let the Lagrangian multipliers of the equality constraints be λ, z− be those of the ≥ bound
constraints, and z+ be those of the ≤ bound constraints. Let the additional Lagrangian multiplier of
the deﬂation constraint be η. The stationary conditions of problem 8 are:

∇xf (x) + ∇xc(x)T λ + z+ + z− + η∇xm(x; x1) = 0
η = 0

Since η will be 0 at any KKT point, the stationarity conditions of problem 1 will be satisﬁed.

∇xf (x) + ∇xc(x)T λ + z+ − z− = 0
(10)
Additionally, the complementarity condition of the deﬂation constraint and the dual feasibility
constraint η ≥ 0 are trivially satisﬁed at η = 0. Since the constraints of problem 1 are a subset of
the constraints of problem 8, x∗ must be feasible to the original problem and the complementarity
conditions of those constraints must be satisﬁed.
Given that y∗ is ﬁnite, (x∗, y∗) is feasible to the deﬂation constraint in problem 8 and m is bounded
from below, then m(x∗; x1) must be ﬁnite which implies that x∗ (cid:54)= x1. This completes the
proof.

Note that the proof above can be trivially generalized to inequality constrained and even conic
constrained nonlinear programs. Therefore, this deﬂation constraint approach is a completely generic
and non-invasive way to use deﬂation in optimization.

Sine the deﬂation constraint approach only requires a change in the formulation optimized rather
than the optimization routine, any KKT seeking nonlinear programming algorithm, e.g. the method
of moving asymptotes [Svanberg, 1987, 2002] or the augmented Lagrangian algorithm [Bertsekas,
1996] can be used to solve the deﬂated formulation. This is a much more generic and simpler way to
use deﬂation than deﬂating all of the optimality conditions.

4.2 Alternative deﬂation constraint

One can also avoid the introduction of an additional variable y replacing it with a large ﬁnite constant
M .
Lemma 4.2. If (x∗) is a regular KKT point to the following NLP:

f (x)

minimize
x
subject to
c(x) = 0,
m(x; x1) ≤ M,
l ≤ x ≤ u

5

(11)

for some ﬁnite constant M , the constraint m(x; x1) ≤ M is satisﬁed at a strict inequality, and m is
bounded from below, then x∗ is a regular KKT point to problem 1 and x∗ (cid:54)= x1.

Proof. Let the Lagrangian multipliers of the equality constraints be λ, z− be those of the ≥ bound
constraints, and z+ be those of the ≤ bound constraints. Let the additional Lagrangian multiplier of
the deﬂation constraint be η. The stationary conditions of problem 11 are:

∇xf (x) + ∇xc(x)T λ + z+ − z− + η∇xm(x; x1) = 0

By the complimentarity slackness conditions, since the deﬂation constraint is satisﬁed at a strict
inequality, η must be equal to 0 at any KKT point. The rest of the proof is identical to the proof of
Lemma 4.1

4.3 Simple deﬂation for nonlinear systems

Much like in optimization, the following deﬂation equality constraint can be added to a nonlinear
system of equations:

solving for both x and y. It is trivial to see that if the algorithm converges to a solution (x∗, y∗) with
a ﬁnite y∗, then x∗ will satisfy the original set of equations and x∗ (cid:54)= x1.

m(x; x1) = y

(13)

4.4 Deﬂating multiple intermediate solutions

In Papadopoulos et al. [2021], the deﬂation operator was used to deﬂate away from the barrier
sub-problems’ intermediate solutions. This is a nice way to automatically adapt the deﬂation power
by ensuring that we deﬂate away from the entire critical path of the interior point optimizer next time
the system is solved. It can also be used to provide accelerated convergence by encouraging solutions
to intermediate barrier sub-problems to be more different from the previous barrier sub-problems.
The same approach can be used in any nonlinear programming algorithm by using a manual callback
and adding new ”known solutions” to the deﬂation operator every ﬁxed number of iterations.

4.5 Deﬂation constraint is a minimum distance constraint

The deﬂation constraint is equivalent to the following distance constraint assuming ﬁnite non-zero
m > 0 and y > σ:

||x − x1||p ≥ z

(14)

where z = 1
y−σ . In this case, it is clear what the deﬂation algorithm does. It just puts a constraint on
the distance to known solutions. If the NLP optimizer approaches z = 0 or y = ∞, then the deﬂation
operator may not be swaying the solution enough away from known solutions. When using the ﬁxed,
large M formulation from equation 11, instead of y tending to inﬁnity, the deﬂation constraint will
be satisﬁed at equality when deﬂation fails to make the algorithm converge to a different solution.
The main hyperparameters that can be tuned in the deﬂation constraint are the distance measure used
and p to ensure convergence to a different solution.

4.6 Different distance measures

One can change the distance measure used in the deﬂation function to more interesting choices than
a simple power of a 2-norm. The following are different ways to change the distance measure to
achieve different desired effect:

1. Use a (cid:96)q norm distance measure instead of a power p of a (cid:96)2 norm, or use a power p of a (cid:96)q

norm distance measure.

2. Use a positive semi-deﬁnite weight matrix Q and deﬁne the distance as the generalized (cid:96)2
norm distance: (x − x1)T Q(x − x1). If Q is diagonal, it can be used to give different
weights to different deviation terms.

6

3. The distance measure can detect symmetries in the solution space if 2 solutions are numeri-
cally different but practically identical. In topology optimization for example, it may make
more sense to deﬁne the distance measure in the pseudo-densities ρ space after applying
density ﬁltering, interpolation and Heaviside projection to the solution x, rather than calcu-
lating distance in the x space. This more accurately reﬂects the desire of the optimizer to
obtain different designs rather than different, symmetric representations of the same design.

4. In topology optimization also, the number of design variables can be extremely large with
many similar looking designs that have slightly different numerical values. A particular
modiﬁcation to the distance measure can therefore be useful to workaround this curse of
dimensionality problem. Let σ = 0 and consider the following deﬂation function:

m(x, x1) = max(||x − x1|| − r, 0)−p

(15)

This deﬂation function treats all solutions in the hyper-ball of radius r around x1 as identical
to x1, i.e. the distance between them is 0. This function is smooth and twice differentiable
for all x ∈ {x : ||x − x1|| > r}. A KKT solution with a ﬁnite y (in exact arithmetic) can
be similarly shown to be equivalent to ﬁnding a new optimal solution outside the hyper-ball.
This new parameter r can be useful for high dimensional problems in topology optimization
where 2 designs can be numerically different but visually and practically identical. Another
side advantage of using r > 0 is that even if deﬂation fails to push the optimization algorithm
away from x1, the new solution obtained is guaranteed to be outside the hyper-ball.

5. In variational inference, the Kullback-Leibler (K-L) divergence can be used to deﬂate
away from known distributions that locally optimize the K-L divergence to the posterior
distribution.

6. In deep learning, a distance measure between the neuron values can be used instead of the

weights and biases to account for symmetries in the weights.

4.7 Potential problems with deﬂation

While deﬂation has proven rather successful in a number of root ﬁnding and optimization applications,
it is not free of limitations which need to be addressed or acknowledged when implementing or using
the algorithm. The following are some common problems associated with the proposed deﬂation
constraint most of which are also concerns when using the traditional deﬂation method.

1. The deﬂation effect may not be strong enough where the algorithm can still approach x1,
asymptotically increasing y to ∞. This is similar to what can happen in the classic deﬂation
when assumption 6 is violated.

2. The optimization is not done in exact arithmetic but rather up to machine precision. This can
make the algorithm converge to a solution with a ﬁnite but large value value of y∗ instead of
overﬂowing to ∞. Therefore, the ﬁniteness of y∗ may not be a good enough indication that
the algorithm has converged to a solution other than x1.

3. Deﬂation guarantees that if convergence happens, the solution will be different. However, it
doesn’t guarantee that convergence will happen to begin with. Even more so, deﬂating away
from 1 solution is likely to push the optimizer away from other nearby locally optimal solu-
tions if they exist. This can make it particularly challenging to ﬁne-tune the hyperparameters
of the algorithm. However arguably this can also be a desirable effect of deﬂation since it
means that more diverse solutions are naturally more likely to be output by the algorithm.

4. Careful selection of the power p and other hyperparameters used in the chosen distance

measure is required.

5 Examples

In this section, a number of applications of deﬂation and non-convex optimization are showcased
from machine learning and topology optimization. The main highlight of this section is that known
popular algorithms were used or minimally modiﬁed to solve the deﬂation sub-problems. In all of the
examples, the same initial solution was used in the deﬂation sub-problems to showcase the efﬁcacy

7

of the approach proposed. Implementations, including detailed hyperparameter settings, can be found
in the supplementary code1.

5.1 Classical variational inference

In this section, an example of the use of deﬂation in variational inference will be demonstrated.
For simplicity, the log joint probability in variational inference is replaced by the log probability
of a 1D mixture of 10 Gaussian distributions. The variational family used is a 1D Gaussian. The
automatic differentiation variational inference (ADVI) [Kucukelbir et al., 2015] algorithm was used
together with the decayed ADAGrad [Duchi et al., 2011] stochastic optimization algorithm from the
AdvancedVI.jl 2 package to minimize a stochastic estimator of the negative of the evidence lower
bound (ELBO). Since there is no data, the negative of the ELBO is equal to the K-L divergence.
Distributions.jl 3 was used to deﬁne the mixture of Gaussians, the variational family, and the estimator
of the K-L divergence objective function. The deﬂated variational approximation problem can be
formulated using the loss function L(θ) as follows:

minimize
θ, y

L(θ)

subject to

˜K
(cid:88)

k=1

m(θ; θk)≤ y

(16)

where θ is the vector of parameters of the variational family and θk is the previously found local
minimizer of the loss function from subproblem k, and ˜K is the total number of found solutions so
far. m and y are the deﬂation function and variable respectively as described in the previous sections.

Since the objective is a stochastic estimator of the K-L divergence and the constraint is non-convex, a
log-barrier approach [Fiacco and Mccormick, 1968] is used to transform the stochastic constrained
problem to an unconstrained one. The log-barrier formulation becomes:

L(θ) − r × log

(cid:18)

minimize
θ, y

y − (cid:80) ˜K

k=1 m(θ; θk)

(cid:19)

(17)

where r is deﬁned as a decaying coefﬁcient approaching 0. The above problem was solved 10 times
from the same initial solution θ0 each time converging to different Gaussian approximations and
appending it to the list of found solutions. The distance function used between solutions in the
deﬂation function was the analytic K-L divergence between the 2 Gaussian distributions offset by
a radius r. Let d(θ) = N (µ = θ[1], σ = exp(θ[2])) be the Gaussian distribution obtained from
solution θ. The K-L divergence based deﬂation function m used was therefore:

m(θ; θk) = max

div

(cid:32)

(cid:16)

d(θ), d(θk)

(cid:17)

− 1, 0

(cid:33)−3

(18)

where div is the K-L divergence between 2 Gaussian distributions. Note that the minimum radius of 1
was used to enforce convergence to a different distribution even if the convergence assumptions of
deﬂation were violated. The optimal Gaussian distributions’ obtained and the target distribution’s
probability density functions are shown in ﬁgure 1. The results indicate that deﬂation was successful
at generating reasonable mode-seeking approximations of the target mixture of Gaussians.

5.2 Pathﬁnder algorithm for variational inference

The pathﬁnder algorithm [Zhang et al., 2021] is a recently proposed algorithm for approximate
Bayesian inference. The pathﬁnder algorithm relies on multi-start optimization of the log joint
probability, reusing the trajectory of intermediate solutions and gradients from the optimization to
construct a Gaussian approximation per trajectory. Re-starting the optimization from a different
initial point can result in a different optimal solution and trajectory, leading to a potentially different
local Gaussian approximation. These Gaussian approximations are then combined and weighted in

1https://github.com/JuliaTopOpt/deflation_examples/
2https://github.com/TuringLang/AdvancedVI.jl
3https://github.com/JuliaStats/Distributions.jl

8

Figure 1: The ﬁgure shows the target probability density function (pdf) of the mixture of Gaussians and
the pdf curves of the multiple Gaussian approximations obtained by solving the deﬂated variational
inference problem 10 times from the same initial Gaussian solution N (µ = 0, σ = exp(5.0)).

a mixture of Gaussians which is used to approximate the posterior distribution. For more details,
please refer to Zhang et al. [2021]. For simplicity, a target mixture of Gaussians distribution was used
in the experiments instead of an unknown posterior distribution. The Pathﬁnder.jl 4 package was
adapted to use IPOPT [W¨achter and Biegler, 2006] as an optimizer as wrapped in the Nonconvex.jl 5
package. Instead of random restarts, the same initial solution of 0.0 was used in all the deﬂation-based
pathﬁnder sub-problems. The target (blue) and approximate (orange) mixtures of Gaussians are
shown in ﬁgure 2. The results are almost perfect for a target mixture of 2, 4 and 6 Gaussians. Given
that all the optimization sub-problems were started from the same initial solution, this is a fairly
positive result. For the target mixture of 8 Gaussians, deﬂation on its own (without random restarts)
fails to accurately approximate the target distribution, however this is not entirely surprising.

5.3 Topology optimization - volume constrained compliance minimization

The volume-constrained compliance minimization problem from topology optimization (TO) seeks
to ﬁnd designs for physical structures that are as stiff as possible (i.e. least compliant) with respect to
known boundary conditions and loading forces while adhering to a given material demand. It has been
well studied and widely applied in mechanical, aerospace, and architectural engineering [Bendsoe
and Sigmund, 2003]. However, because TO problems are high-dimensional, partial differential
equation (PDE) constrained, and non-convex, ﬁnding multiple local minima that are visually different
has been challenging and rarely studied, despite its practical values. A compliance-minimizing,
volume-constrained TO problem can be formulated as:

f · u

minimize
x ∈ Rn
subject to
K(x)u(x) = f ,
(cid:80)n

≤ ˜V ,

i=1 xi
n
0 ≤ x ≤ 1

(19)

4https://github.com/sethaxen/Pathfinder.jl
5https://github.com/JuliaNonconvex/Nonconvex.jl

9

Figure 2: Target (blue) and approximate (red) mixtures of Gaussian probability density functions
using the same initial solution of 0.0 in all of the deﬂation-based sub-problems in the pathﬁnder
algorithm.

where x is the pseudo-density of cells in the domain, f the given load vector, K(x) the stiffness
matrix from the ﬁnite-element discretization, ˜V is the user-speciﬁed volume fraction. When xi = 0,
the corresponding cell is removed and when xi = 1 the cell is kept.

We apply our deﬂation technique by adding an extra constraint to problem 19, using the distance
measure that encourages visually different designs mentioned in Section 4.6:

˜K
(cid:88)

k=1

m(x; xk) =

˜K
(cid:88)

k=1

max((cid:107)x − xk(cid:107) − r, 0)−p ≤ y

(20)

where ˜K is the number of found local minima from previous deﬂation iterations. In our experiments,
p = 4, r = 20, y ∈ (0, 100).

Two classic topology optimization benchmark problems are tested here: a continuum MBB beam
domain of dimension 120 × 40 and a cantilevering truss domain of dimension 40 × 10 (Figure 3).
TopOpt.jl6 is used for the implementation of problem modeling, ﬁnite-element analysis, and density
ﬁlters. We use the widely used Method of Moving Asymptotes (MMA) algorithm [Svanberg, 1987]
to solve both the undeﬂated and deﬂated problems. Runtime results are presented in Table 1. Figure 4
and Figure 5 visualize the results of running 20 deﬂation iterations on both domains. The results
show that the proposed deﬂation formulation generates visually different, near-optimal designs
deterministically, all starting from the same initial guess. The runtime results suggest no signiﬁcant
change in the running time due to adding a deﬂation constraint to an already constrained optimization
problem.

6https://github.com/JuliaTopOpt/TopOpt.jl

10

Table 1: Deﬂated topology optimization runtime. ∗: deﬂated problem runtime is averaged over all the
20 deﬂation iteration.

TopOpt problems

x dim undeﬂated

deﬂated∗

Continuum (Figure 4)
Truss (Figure 5)

4800
3608

121s
1.9s

122s
1.6s

Figure 3: Topology optimization domains: (a) half MBB beam continuum domain; (b) cantilevering
truss domain.

6 Conclusion and future work

In this work, a new way to use deﬂation was proposed to ﬁnd diverse solutions of non-convex
optimization problems. With the proposed problem re-formulation, the deﬂation technique can be
easily applied to any non-convex problems using existing, off-the-shelf optimizers. Promising results
of applying the proposed technique on solving problems from topology optimization and variational
inference are presented. We hope our work can enable applications of this simple, yet powerful idea
of deﬂation to a broader set of problems where multiple local optimal solutions are required. In the
future, we hope to make use of deﬂation-based optimization to enhance optimization-based machine
learning algorithms such as maximum likelihood estimation, and to use it for model-based design of
experiments in clinical trials to explore multiple possible designs.

11

Figure 4: Deﬂated results of the continuum half MBB beam problem. Iteration 0 is the solution found
by solving the undeﬂated problem.

References

A. Arnoud, F. Guvenen, and T. Kleineberg. Benchmarking Global Optimizers. Technical Report
w26340, National Bureau of Economic Research, Cambridge, MA, Oct. 2019. URL http:
//www.nber.org/papers/w26340.pdf.

C. Barron and S. Gomez. The exponential tunneling method. 1991.

P. Belotti, J. Lee, L. Liberti, F. Margot, and A. W¨achter. Branching and bounds tightening techniques

for non-convex MINLP. Optimization Methods and Software, 24(4-5):597–634, 2009.

M. P. Bendsoe and O. Sigmund. Topology optimization: theory, methods, and applications. Springer

Science & Business Media, 2003.

D. P. Bertsekas. Constrained Optimization and Lagrange Multiplier Methods. Athena Scientiﬁc,

1996.

K. M. Brow and W. B. Gearhart. Deﬂation techniques for the calculation of further solutions of a

nonlinear system. Numerische Mathematik, 16(4):334–342, 1971.

J. Duchi, E. Hazan, and Y. Singer. Adaptive subgradient methods for online learning and stochastic
optimization. Journal of Machine Learning Research, 12(61):2121–2159, 2011. URL http:
//jmlr.org/papers/v12/duchi11a.html.

S. Falkner, A. Klein, and F. Hutter. Bohb: Robust and efﬁcient hyperparameter optimization at scale,

2018.

12

Figure 5: Deﬂated results of the discrete, cantilevering truss problem. Iteration 0 is the solution found
by solving the undeﬂated problem.

P. E. Farrell, C. H. L. Beentjes, and A. Birkisson. The computation of disconnected bifurcation
diagrams. arXiv:1603.00809 [math], Mar. 2016. URL http://arxiv.org/abs/1603.00809.
arXiv: 1603.00809.

P. E. Farrell, M. Croci, and T. M. Surowiec. Deﬂation for semismooth equations. Optimization

Methods and Software, 35(6):1248–1271, 2020.

A. Fiacco and G. Mccormick. Nonlinear Programming: Sequential Unconstrained Minimization

Techniques. John Wiley, New York, 1968.

J. M. Gablonsky and C. T. Kelley. A Locally-Biased form of the DIRECT Algorithm. Journal of

Global Optimization, 21:27–37, 2001.

Gecode Team.

Gecode: Generic constraint development environment.

Available from

http://www.gecode.org.

M. Gendreau and J.-Y. Potvin, editors. Handbook of metaheuristics. Springer, New York, NY, USA,

2 edition, 2010.

S. Gomez and A. V. Levy. The tunnelling method for solving the constrained global optimization
problem with several non-connected feasible regions. Numerical analysis, page 34–47, 1982.

S. Gomez, N. del Castillo, L. Castellanos, and J. Solano. The parallel tunneling method. Parallel

Computing, page 523–533, 2003.

S. Gudmundsson. Parallel Global Optimization, M.Sc. Thesis, IMM, Technical University of Denmark,

1998.

D. R. Jones, C. D. Perttunen, and B. E. Stuckman. Lipschitzian optimization without the Lipschitz
constant. Journal of Optimization Theory and Applications, 79(1):157–181, Oct. 1993. ISSN
0022-3239, 1573-2878. doi: 10.1007/BF00941892. URL http://link.springer.com/10.
1007/BF00941892.

S. Z. K. Madsen and A. Zilinskas. Global Optimization using Branch-and-Bound, 1998.

P. Kaelo and M. M. Ali. Some Variants of the Controlled Random Search Algorithm for Global
Optimization. Journal of Optimization Theory and Applications, 130(2):253–264, Dec. 2006.
ISSN 0022-3239, 1573-2878. doi: 10.1007/s10957-006-9101-0. URL http://link.springer.
com/10.1007/s10957-006-9101-0.

13

S. Kucherenko and Y. Sytsko. Application of Deterministic Low-Discrepancy Sequences in Global
Optimization. Computational Optimization and Applications, 30(3):297–318, Mar. 2005. ISSN
0926-6003, 1573-2894. doi: 10.1007/s10589-005-4615-1. URL http://link.springer.com/
10.1007/s10589-005-4615-1.

A. Kucukelbir, R. Ranganath, A. Gelman, and D. Blei. Automatic variational inference in stan. In
C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Informa-
tion Processing Systems, volume 28. Curran Associates, Inc., 2015. URL https://proceedings.
neurips.cc/paper/2015/file/352fe25daf686bdb4edca223c921acea-Paper.pdf.

A. V. Levy and S. Gomez. The tunneling method applied to global optimization. Numerical

optimization, page 213–244, 1981.

L. Li, K. Jamieson, G. DeSalvo, A. Rostamizadeh, and A. Talwalkar. Hyperband: A novel bandit-

based approach to hyperparameter optimization, 2018.

C. W. J. McKay M. D., Beckman R. J. A comparison of three methods for selecting values of input
variables in the analysis of output from a computer code. Technometrics, 21(2):239–245, 1979.
doi: 10.2307/1268522.

P. Moscato and C. Cotta. A Modern Introduction to Memetic Algorithms, pages 141–183. Springer
US, Boston, MA, 2010. ISBN 978-1-4419-1665-5. doi: 10.1007/978-1-4419-1665-5 6. URL
https://doi.org/10.1007/978-1-4419-1665-5_6.

H. Nagarajan, M. Lu, E. Yamangil, and R. Bent. Tightening McCormick relaxations for
In International Conference on
nonlinear programs via dynamic multivariate partitioning.
Principles and Practice of Constraint Programming, pages 369–387. Springer, 2016. doi:
10.1007/978-3-319-44953-1 24.

H. Nagarajan, M. Lu, S. Wang, R. Bent, and K. Sundar. An adaptive, multivariate partitioning
algorithm for global optimization of nonconvex programs. Journal of Global Optimization, 2019.
ISSN 1573-2916. doi: 10.1007/s10898-018-00734-1.

J. Nocedal and S. Wright. Numerical optimization. Springer Science & Business Media, 2006.

I. P. A. Papadopoulos, P. E. Farrell, and T. M. Surowiec. Computing multiple solutions of topology
optimization problems. arXiv:2004.11797 [cs, math], Jan. 2021. URL http://arxiv.org/abs/
2004.11797. arXiv: 2004.11797.

H. Ratschek and J. Rokne. New computer methods for global optimization, 2007.

A. H. G. Rinnooy Kan and G. T. Timmer. Stochastic global optimization methods part I: Clustering
methods. Mathematical Programming, 39(1):27–56, Sept. 1987. ISSN 0025-5610, 1436-4646.
doi: 10.1007/BF02592070. URL http://link.springer.com/10.1007/BF02592070.

N. V. Sahinidis. BARON 21.1.13: Global Optimization of Mixed-Integer Nonlinear Programs, User’s

Manual, 2017.

A. Sinha, P. Malo, and K. Deb. A review on bilevel optimization: From classical to evolutionary
approaches and applications. IEEE Transactions on Evolutionary Computation, 22(2):276–295,
2018. doi: 10.1109/TEVC.2017.2712906.

K. Svanberg. The method of moving asymptotes - a new method for structural optimization. Interna-

tional Journal for Numerical Methods in Engineering, 24(2):359–373, 1987.

K. Svanberg. A Class of Globally Convergent Optimization Methods Based on Conservative Convex

Separable Approximations. SIAM Journal on Optimization, 12(2):555–573, 2002.

M. Tawarmalani and N. V. Sahinidis. A polyhedral branch-and-cut approach to global opti-
mization. Mathematical Programming, 103(2):225–249, June 2005. ISSN 0025-5610, 1436-
4646.
doi: 10.1007/s10107-005-0581-8. URL http://link.springer.com/10.1007/
s10107-005-0581-8.

14

S. Vigerske and A. Gleixner. Scip: global optimization of mixed-integer nonlinear programs in a
branch-and-cut framework. Optimization Methods and Software, 33(3):563–593, 2018. doi: 10.
1080/10556788.2017.1335312. URL https://doi.org/10.1080/10556788.2017.1335312.

A. W¨achter and L. T. Biegler. On the implementation of an interior-point ﬁlter line-search algorithm

for large-scale nonlinear programming. Mathematical programming, 106(1):25–57, 2006.

M. E. Wilhelm and M. D. Stuber. Eago.jl: easy advanced global optimization in julia. Optimization
Methods and Software, pages 1–26, 2020. doi: 10.1080/10556788.2020.1786566. URL https:
//doi.org/10.1080/10556788.2020.1786566.

S. Wright. Primal-dual interior-point methods. 1997. doi: 10.1137/1.9781611971453. URL

https://epubs.siam.org/doi/abs/10.1137/1.9781611971453.

L. Zhang, B. Carpenter, A. Gelman, and A. Vehtari. Pathﬁnder: Parallel quasi-newton variational

inference, 2021.

S. Zhang and J. A. Norato. Finding Better Local Optima in Topology Optimization via Tunneling.
In Volume 2B: 44th Design Automation Conference, page V02BT03A014, Quebec City, Quebec,
Canada, Aug. 2018. American Society of Mechanical Engineers. ISBN 978-0-7918-5176-0. doi: 10.
1115/DETC2018-86116. URL https://asmedigitalcollection.asme.org/IDETC-CIE/
proceedings/IDETC-CIE2018/51760/Quebec%20City,%20Quebec,%20Canada/274787.

15

A Deﬂated KKT system of NLP’s barrier subproblems

In this section, derivations for the deﬂated KKT system of the barrier sub-problem used by the interior
point method [Wright, 1997] as implemented in the IPOPT software [W¨achter and Biegler, 2006] are
presented.

A.1 KKT system of the barrier problem

In IPOPT, a log barrier method is used to guarantee that l ≤ x ≤ u remains satisﬁed at every
intermediate solution if the initial solution is within the bounds. The barrier function is deﬁned as:

Bµ(x, l, u) = −µ

(cid:16) (cid:88)

log (xi − li) +

i

log (ui − xi)

(cid:17)

(cid:88)

i

for some µ > 0 which would go to ∞ if any of the decision variables approaches one of its ﬁnite
bounds. This creates a barrier stopping the optimizer from every reaching the ﬁnite bound. The
barrier sub-problem is deﬁned as:

minimize
x

φµ(x) = f (x) + Bµ(x, l, u)

subject to c(x) = 0

The KKT stationarity condition is therefore:

∇f (x) + ∇c(x)T λ − zl − zu = 0

and zu is a vector whose ith element is zui = µ

where λ is the vector Lagrangian multipliers associated with the equality constraint c(x) = 0, zl is a
vector whose ith element is zli = µ
Additionally, let Zl be the diagonal matrix whose diagonal is zl, Zu be the diagonal matrix whose
diagonal is zu, Xl be the diagonal matrix whose diagonal is: ˜xli = xi − li and Xu be the diagonal
matrix whose diagonal is: ˜xui = ui − xi.
The ﬁrst-order KKT sufﬁcient conditions for optimality of the barrier problem, assuming the constraint
qualiﬁcations are satisﬁed, can be written as:

ui−xi

xi−li

.

∇f (x) + ∇c(x)T λ − zl − zu = 0
c(x) = 0
XlZl1 − µ1 = 0
XuZu1 − µ1 = 0
l ≤ x ≤ u
zl ≥ 0
zu ≥ 0

(21a)
(21b)
(21c)
(21d)
(21e)
(21f)
(21g)

where 1 is a vector of ones. Conditions 21c and 21d ensure that the relationship between Xl, Zl, Xu
and Zu is maintained according to the deﬁnitions of zl and zu. In an interior point algorithm (e.g.
IPOPT W¨achter and Biegler [2006]), primal-dual solutions to the equality KKT conditions are found
using a Newton-like method while ensuing that the inequality conditions are satisﬁed by projection.

In order to solve the barrier problem for a given value µ = µj, a damped Newton’s method is usually
applied to the primal-dual optimality conditions. Here we use k to denote the iteration counter for
the inner iterations when solving the barrier problem. Given an iterate (xk, λk, zl,k, zu,k) with
l < xk < u and zl,k, zu,k > 0, some search directions (dx
k ) are obtained using the
regularized linearization of the optimality conditions (excluding the inequality conditions):

k , dzu

k , dzl

k , dλ






Wk Ak −I
AT
0
0
k
0 Xl,k
Zl,k
0
Zu,k

−I
0
0











dx
k
dλ
k
dzl
k
dzu
k






 = −




∇f (xk) + AT

k λk − zl,k − zu,k
c(xk)
Xl,kZl,k1 − µj1
Xu,kZu,k1 − µj1






(22)

0 Xu,k

where Ak := ∇c(xk)T and Wk := ∇2
xx(f (xk) + c(xk)T λk) is the Hessian of the Lagrangian
function of the original problem. The Lagrangian terms from the bounds constraints are ignored

16

because they don’t contribute to the Hessian. When the Hessian of the Lagrangian is not available, a
l-BFGS approximation [Nocedal and Wright, 2006] of the Hessian can be used instead. This changes
the IPOPT algorithm from a second order algorithm to a ﬁrst order one. And the Newton update
becomes a quasi-Newton update.

Instead of solving the non-symmetric system of equations above, one can instead change the system
as such:












∇f (xk) + AT

Wk
AT
k
X −1
l Zl,k
X −1
u Zu,k




Ak −I −I
0
0
0
0
I
0
I
0
0

dx
k
dλ
k
dzl
k
dzu
k








 = −




k λk − zl,k − zu,k
c(xk)
zl,k − µjX −1
l 1
zu,k − µjX −1
u 1




(23)

Adding the third and fourth equations to the ﬁrst one, the third and fourth blocks of coefﬁcients of the
ﬁrst equation will be eliminated.






Wk + Σk Ak 0 0
0 0
I 0
0 I

AT
k
X −1
l Zl,k
X −1
u Zu,k

0
0
0











dx
k
dλ
k
dzl
k
dzu
k


 = −




k λk − µjX −1
c(xk)
zl,k − µjX −1
l 1
zu,k − µjX −1
u 1





∇f (xk) + AT

l 1 − µjX −1
u 1




 (24)

u Zu,k. Therefore, one can now solve for dx

k and dλ

k by solving the

l Zl,k + X −1

where Σk = X −1
following symmetric linear system:
(cid:20)Wk + Σk Ak
(cid:19)
(cid:21) (cid:18)dx
k
dλ
0
k

AT
k

(cid:18)∇f (xk) + AT

= −

k λk − µjX −1
c(xk)

l 1 − µjX −1
u 1

(cid:19)

then use the value of dx

k using:

k to ﬁnd dzl
k and dzu
dzl
k = −zl,k + µjX −1
dzu
k = −zu,k + µjX −1

l 1 − X −1
u 1 − X −1

l Zl,kdx
k
u Zu,kdx
k

A.2 Deﬂating the KKT system

If we deﬁne the RHS of Equation (25) as:

F (x, λ) =

(cid:18)∇f (x) + AT λ − µjX −1

l 1 − µjX −1
u 1

(cid:19)

c(x)

(25)

(26a)

(26b)

(27)

Then the goal of the primal-dual optimizer then becomes solving for F (x, λ) = 0.

If we apply the deﬂation operator to the entire F (x, λ), we will obtain G(x, λ) =
M (x; x1)F (x, λ) = 0, whose Jacobian is:

∇xG(x) = m(x; x1)∇xF (x, λ) + diag(F (x, λ))1(∇xm(x; x1))T

where ∇xm(x; x1) is the gradient vector of the deﬂation function, 1 is a column vector of 1s and
diag(F (x)) is a diagonal matrix with diagonal F (x). The Jacobian of this function wrt x is:

(cid:21)

(cid:20)W + Σ
AT

(28)

where W , Σ and A are deﬁned as Wk, Σk and Ak in the last section. The top matrix is symmetric
because it is the Hessian matrix of the barrier objective function. However, Ak := ∇c(xk)T in
general is not symmetric, and thus prevents the usage of efﬁcient linear algebra algorithms for
symmetric linear system.

17

